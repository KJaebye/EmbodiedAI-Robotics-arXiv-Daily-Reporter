{'arxiv_id': 'arXiv:2505.23376', 'title': 'MEF-Explore: Communication-Constrained Multi-Robot Entropy-Field-Based Exploration', 'authors': 'Khattiya Pongsirijinda, Zhiqiang Cao, Billy Pik Lik Lau, Ran Liu, Chau Yuen, U-Xuan Tan', 'link': 'https://arxiv.org/abs/2505.23376', 'abstract': "Collaborative multiple robots for unknown environment exploration have become mainstream due to their remarkable performance and efficiency. However, most existing methods assume perfect robots' communication during exploration, which is unattainable in real-world settings. Though there have been recent works aiming to tackle communication-constrained situations, substantial room for advancement remains for both information-sharing and exploration strategy aspects. In this paper, we propose a Communication-Constrained Multi-Robot Entropy-Field-Based Exploration (MEF-Explore). The first module of the proposed method is the two-layer inter-robot communication-aware information-sharing strategy. A dynamic graph is used to represent a multi-robot network and to determine communication based on whether it is low-speed or high-speed. Specifically, low-speed communication, which is always accessible between every robot, can only be used to share their current positions. If robots are within a certain range, high-speed communication will be available for inter-robot map merging. The second module is the entropy-field-based exploration strategy. Particularly, robots explore the unknown area distributedly according to the novel forms constructed to evaluate the entropies of frontiers and robots. These entropies can also trigger implicit robot rendezvous to enhance inter-robot map merging if feasible. In addition, we include the duration-adaptive goal-assigning module to manage robots' goal assignment. The simulation results demonstrate that our MEF-Explore surpasses the existing ones regarding exploration time and success rate in all scenarios. For real-world experiments, our method leads to a 21.32% faster exploration time and a 16.67% higher success rate compared to the baseline.", 'abstract_zh': '通信约束下多机器人熵场导向探索（MEF-Explore）', 'title_zh': 'MEF-Explore: 通信约束下的多机器人熵场基于探索'}
{'arxiv_id': 'arXiv:2505.22982', 'title': 'Structural Abstraction and Selective Refinement for Formal Verification', 'authors': 'Christoph Luckeneder, Ralph Hoch, Hermann Kaindl', 'link': 'https://arxiv.org/abs/2505.22982', 'abstract': 'Safety verification of robot applications is extremely challenging due to the complexity of the environment that a robot typically operates in. Formal verification with model-checking provides guarantees but it may often take too long or even fail for complex models of the environment. A usual solution approach is abstraction, more precisely behavioral abstraction. Our new approach introduces structural abstraction instead, which we investigated in the context of voxel representation of the robot environment. This kind of abstraction leads to abstract voxels. We also propose a complete and automated verification workflow, which is based on an already existing methodology for robot applications, and inspired by the key ideas behind counterexample-guided abstraction refinement (CEGAR) - performing an initial abstraction and successively introducing refinements based on counterexamples, intertwined with model-checker runs. Hence, our approach uses selective refinement of structural abstractions to improve the runtime efficiency of model-checking. A fully-automated implementation of our approach showed its feasibility, since counterexamples have been found for a realistic scenario with a fairly high (maximal) resolution in a few minutes, while direct model-checker runs led to a crash after a couple of days.', 'abstract_zh': '基于体素表示的机器人环境结构化抽象的安全验证', 'title_zh': '结构抽象与选择性细化 formal 验证'}
{'arxiv_id': 'arXiv:2505.23584', 'title': 'Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging', 'authors': 'Sumbal Malik, Majid Khonji, Khaled Elbassioni, Jorge Dias', 'link': 'https://arxiv.org/abs/2505.23584', 'abstract': 'The rapid growth of e-commerce and the increasing demand for timely, cost-effective last-mile delivery have increased interest in collaborative logistics. This research introduces a novel collaborative synchronized multi-platform vehicle routing problem with drones and robots (VRP-DR), where a fleet of $\\mathcal{M}$ trucks, $\\mathcal{N}$ drones and $\\mathcal{K}$ robots, cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the launching, retrieving, and en-route charging of drones and robots, thereby addressing critical limitations such as restricted payload capacities, limited range, and battery constraints. The VRP-DR incorporates five realistic features: (1) multi-visit service per trip, (2) multi-trip operations, (3) flexible docking, allowing returns to the same or different trucks (4) cyclic and acyclic operations, enabling return to the same or different nodes; and (5) en-route charging, enabling drones and robots to recharge while being transported on the truck, maximizing operational efficiency by utilizing idle transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP) to minimize both operational costs and makespan. To overcome the computational challenges of solving large-scale instances, a scalable heuristic algorithm, FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to provide efficient, near-optimal solutions. Numerical experiments across various instance sizes evaluate the performance of the MILP and heuristic approaches in terms of solution quality and computation time. The results demonstrate significant time savings of the combined delivery mode over the truck-only mode and substantial cost reductions from enabling multi-visits. The study also provides insights into the effects of en-route charging, docking flexibility, drone count, speed, and payload capacity on system performance.', 'abstract_zh': '电子商务的 rapid growth 和对及时、经济高效最后一英里配送的不断增长需求促使了协同物流的兴趣增加。本文介绍了一种新颖的同步多平台车辆路由问题——无人机和机器人协同配送问题（VRP-DR），涉及 M 辆卡车、N 架无人机和 K 台机器人协同配送包裹。卡车作为移动平台，能够发射、回收和沿途为无人机和机器人充电，从而解决载重量限制、活动范围有限和电池限制等关键问题。VRP-DR 包含五个现实特征：(1) 每次配送多次访问服务，(2) 多次配送操作，(3) 灵活的对接，允许返回同一辆或不同的卡车，(4) 循环和非循环操作，允许返回到同一或不同的节点；以及 (5) 沿途充电，允许无人机和机器人在被运输过程中充电，最大化利用闲置的运输时间以提高操作效率。该问题被表述为混合整数线性规划（MILP）模型以最小化运营成本和作业时间。为克服解决大规模实例的计算挑战，开发了一种可扩展的启发式算法 FINDER（灵活集成交付与能量再充电），以提供高效的近似最优解。通过不同规模实例的数值实验，评估了MILP和启发式方法在解的质量和计算时间方面的性能。结果表明，结合配送模式比单卡车模式显著节省了时间，并且多访问模式带来了显著的成本降低。研究还探讨了沿途充电、对接灵活性、无人机数量、速度和载重能力对系统性能的影响。', 'title_zh': '协同最后一英里配送：含沿途充电的多平台车辆路由问题'}
{'arxiv_id': 'arXiv:2505.22753', 'title': 'Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields', 'authors': 'Arseniy Pertzovsky, Roni Stern, Ariel Felner, Roie Zivan', 'link': 'https://arxiv.org/abs/2505.22753', 'abstract': 'We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.', 'abstract_zh': '我们探讨了使用人工势场（APFs）解决多代理路径规划（MAPF）和终身多代理路径规划（LMAPF）问题的方法。在MAPF中，一组代理必须在不发生碰撞的情况下移动到其目标位置，而在LMAPF中，新的目标会在到达当前目标后生成。我们提出了在多种MAPF算法中结合使用APFs的方法，包括优先级规划、MAPF-LNS2以及优先级继承带回溯（PIBT）。实验结果表明，对于MAPF，使用APFs并无优势，但在LMAPF中可以将整个系统吞吐量提高多达7倍。', 'title_zh': '使用人工势场方法增强终身多代理路径规划'}
{'arxiv_id': 'arXiv:2505.23762', 'title': 'ZeroGUI: Automating Online GUI Learning at Zero Human Cost', 'authors': 'Chenyu Yang, Shiqian Su, Shi Liu, Xuan Dong, Yue Yu, Weijie Su, Xuehui Wang, Zhaoyang Liu, Jinguo Zhu, Hao Li, Wenhai Wang, Yu Qiao, Xizhou Zhu, Jifeng Dai', 'link': 'https://arxiv.org/abs/2505.23762', 'abstract': 'The rapid advancement of large Vision-Language Models (VLMs) has propelled the development of pure-vision-based GUI Agents, capable of perceiving and operating Graphical User Interfaces (GUI) to autonomously fulfill user instructions. However, existing approaches usually adopt an offline learning framework, which faces two core limitations: (1) heavy reliance on high-quality manual annotations for element grounding and action supervision, and (2) limited adaptability to dynamic and interactive environments. To address these limitations, we propose ZeroGUI, a scalable, online learning framework for automating GUI Agent training at Zero human cost. Specifically, ZeroGUI integrates (i) VLM-based automatic task generation to produce diverse training goals from the current environment state, (ii) VLM-based automatic reward estimation to assess task success without hand-crafted evaluation functions, and (iii) two-stage online reinforcement learning to continuously interact with and learn from GUI environments. Experiments on two advanced GUI Agents (UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance across OSWorld and AndroidLab environments. The code is available at this https URL.', 'abstract_zh': '大型Vision-Language模型的 rapid 进展推动了纯视觉GUI代理的发展，这些代理能够感知和操作图形用户界面（GUI）以自主完成用户指令。然而，现有方法通常采用离线学习框架，面临两个核心限制：（1）对高质量手动标注的元素接地和动作监督的高度依赖；（2）对动态和交互式环境的有限适应性。为了解决这些限制，我们提出ZeroGUI，这是一种零成本的大规模在线学习框架，用于自动化GUI代理的训练。具体来说，ZeroGUI结合了（i）基于大型Vision-Language模型的自动任务生成，从当前环境状态中生成多样化的训练目标；（ii）基于大型Vision-Language模型的自动奖励估计，无需手动构造的评估函数来评估任务成功；（iii）两阶段在线强化学习，以持续与GUI环境交互并从中学习。实验结果在两个先进的GUI代理（UI-TARS和Aguvis）中表明，ZeroGUI显著提升了OSWorld和AndroidLab环境中的性能。代码可在以下网址获得。', 'title_zh': 'ZeroGUI: 在零人工成本下自动化在线GUI学习'}
{'arxiv_id': 'arXiv:2505.23746', 'title': 'Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons', 'authors': 'Hugo Henry, Kelly Cohen', 'link': 'https://arxiv.org/abs/2505.23746', 'abstract': "This study investigates the application of Genetic Fuzzy Systems (GFS) to model the self-noise generated by airfoils, a key issue in aeroaccoustics with significant implications for aerospace, automotive and drone applications. Using the publicly available Airfoil Self Noise dataset, various Fuzzy regression strategies are explored and compared. The paper evaluates a brute force Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading Geneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on Fuzzy C-means (FCM) to reduce the model's complexity. This highlights the viability of clustering assisted fuzzy inference as an effective regression tool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression, Cascading systems, Clustering and AI.", 'abstract_zh': '本研究探讨了遗传模糊系统（GFS）在建模机翼自噪声中的应用，这是航空声学中的一个关键问题，对航空、汽车和无人机应用具有重要意义。利用公开的Airfoil Self Noise数据集，研究了各种模糊回归策略并进行了比较。论文评估了具有高规则密度的 brute force Takagi Sugeno Kang （TSK）模糊系统、级联遗传模糊树（GFT）架构以及基于模糊C均值（FCM）的新型聚类方法以减少模型的复杂性。这突显了聚类辅助模糊推理作为复杂航空声学现象的有效回归工具的可行性。关键词：模糊逻辑、回归、级联系统、聚类和AI。', 'title_zh': '遗传模糊回归技术在 Aeroacoustic 现象中的比较研究'}
{'arxiv_id': 'arXiv:2505.23686', 'title': 'ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork', 'authors': 'Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone', 'link': 'https://arxiv.org/abs/2505.23686', 'abstract': 'Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.', 'abstract_zh': '开发能够与未见过的合作伙伴协作的AI代理是多代理学习中一个基本的泛化挑战，称为即兴团队合作（AHT）。', 'title_zh': 'ROTATE：基于遗憾的学习连贯团队协作的开放式训练'}
{'arxiv_id': 'arXiv:2505.23596', 'title': 'MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning', 'authors': 'Linqiang Guo, Wei Liu, Yi Wen Heng, Tse-Hsun, Chen, Yang Wang', 'link': 'https://arxiv.org/abs/2505.23596', 'abstract': 'Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.', 'abstract_zh': '移动GUI代理目标是在跨移动应用完成用户指示的任务时实现自主工作。近期的多模态大型语言模型（MLLMs）进展使这些代理能够解析UI屏幕、识别可操作元素并执行点击或输入等交互。然而，现有的代理仍然具有反应性：它们仅基于当前屏幕进行推理，缺乏对应用导航流程的结构化建模，这限制了它们理解上下文、检测意外结果和从错误中恢复的能力。我们提出了MAPLE——一种状态感知的多代理框架，将应用交互抽象为有限状态机（FSM）。我们计算建模每个UI屏幕为离散状态，并将用户行动视为状态间的转换，从而使FSM能够为应用执行提供结构化的表示。MAPLE由专门负责任务执行四个阶段的代理组成：规划、执行、验证、错误恢复和知识保留。这些代理协同工作，根据从UI屏幕中提取的感知数据实时动态构建FSM，使GUI代理能够跟踪导航进度和流程，通过状态的先验和后验条件验证行动结果，并通过回滚到先前稳定状态从错误中恢复。我们在两个具有挑战性的跨应用基准Mobile-Eval-E和SPA-Bench上的评估结果显示，MAPLE优于现有最先进的基线，任务成功率达到最高提升12%，恢复成功率提升13.8%，行动准确性提高6.5%。我们的结果突显了在任务执行过程中指导移动GUI代理进行结构化状态建模的重要性。此外，我们的FSM表示可以集成到未来GUI代理架构中作为轻量级、模型无关的记忆层，以支持结构化规划、执行验证和错误恢复。', 'title_zh': 'MAPLE：一种用于恢复推理的持久有限状态机移动助手'}
{'arxiv_id': 'arXiv:2505.23575', 'title': 'CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring', 'authors': 'Benjamin Arnav, Pablo Bernabeu-Pérez, Nathan Helm-Burger, Tim Kostolansky, Hannes Whittingham, Mary Phuong', 'link': 'https://arxiv.org/abs/2505.23575', 'abstract': 'As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that CoT monitoring improves detection by up to 27 percentage points in scenarios where action-only monitoring fails to reliably identify sabotage. However, CoT traces can also contain misleading rationalizations that deceive the monitor, reducing performance in more obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores both reasoning and final outputs and combines them using a weighted average. This hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates over four times higher than action-only monitoring for subtle deception scenarios.', 'abstract_zh': '随着AI模型的自主性不断增强，确保它们不会在不被察觉的情况下采取有害行为至关重要。作为潜在的缓解措施，我们研究了思维链（Chain-of-Thought，CoT）监控，即一个较弱的受信监控模型持续监督更强大的但不信任模型的中间推理步骤。我们在红队演练中比较了CoT监控与仅审查最终输出的行动监控，其中不信任模型被指示在完成编程问题时追求有害副任务。我们发现，在仅审查行动的监控方法无法可靠识别破坏行为的情景下，CoT监控可提高多达27个百分点的检测率。然而，CoT轨迹也可能包含可能欺骗监控的误导性解释，这在更明显的破坏情景中降低了性能。为此，我们引入了一种混合协议，该协议独立对推理和最终输出进行评分，并使用加权平均值进行结合。这种混合监控在所有测试的模型和任务中都表现得优于CoT和仅审查行动的监控，对于微妙的欺骗情景，检测率高出四倍以上。', 'title_zh': 'CoTRed-Handed: 压力测试链式思考监控'}
{'arxiv_id': 'arXiv:2505.23536', 'title': 'Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)', 'authors': 'Janik-Vasily Benzin, Gyunam Park, Stefanie Rinderle-Ma', 'link': 'https://arxiv.org/abs/2505.23536', 'abstract': 'Model abstraction (MA) and event abstraction (EA) are means to reduce complexity of (discovered) models and event data. Imagine a process intelligence project that aims to analyze a model discovered from event data which is further abstracted, possibly multiple times, to reach optimality goals, e.g., reducing model size. So far, after discovering the model, there is no technique that enables the synchronized abstraction of the underlying event log. This results in loosing the grounding in the real-world behavior contained in the log and, in turn, restricts analysis insights. Hence, in this work, we provide the formal basis for synchronized model and event abstraction, i.e., we prove that abstracting a process model by MA and discovering a process model from an abstracted event log yields an equivalent process model. We prove the feasibility of our approach based on behavioral profile abstraction as non-order preserving MA technique, resulting in a novel EA technique.', 'abstract_zh': '模型抽象（MA）和事件抽象（EA）是减少发现模型和事件数据复杂性的方法。在一项旨在分析从事件数据中发现的模型并进一步多次抽象以实现优化目标（例如，减少模型大小）的过程智能项目中，目前在发现模型之后，尚无技术能够同步抽象底层事件日志。这导致在日志中包含的实际行为基础丧失，从而限制了分析洞察力。因此，在本文中，我们为同步模型和事件抽象提供了形式基础，即我们证明了通过MA抽象过程模型并从抽象后的事件日志中发现过程模型可以得到等价的过程模型。我们基于行为特征抽象作为非序数保留的MA技术，证明了我们方法的可行性，并提出了一种新的EA技术。', 'title_zh': '基于事件抽象的过程模型同步与智能'}
{'arxiv_id': 'arXiv:2505.23519', 'title': 'Individual differences in the cognitive mechanisms of planning strategy discovery', 'authors': 'Ruiqi He, Falk Lieder', 'link': 'https://arxiv.org/abs/2505.23519', 'abstract': "People employ efficient planning strategies. But how are these strategies acquired? Previous research suggests that people can discover new planning strategies through learning from reinforcements, a process known as metacognitive reinforcement learning (MCRL). While prior work has shown that MCRL models can learn new planning strategies and explain more participants' experience-driven discovery better than alternative mechanisms, it also revealed significant individual differences in metacognitive learning. Furthermore, when fitted to human data, these models exhibit a slower rate of strategy discovery than humans. In this study, we investigate whether incorporating cognitive mechanisms that might facilitate human strategy discovery can bring models of MCRL closer to human performance. Specifically, we consider intrinsically generated metacognitive pseudo-rewards, subjective effort valuation, and termination deliberation. Analysis of planning task data shows that a larger proportion of participants used at least one of these mechanisms, with significant individual differences in their usage and varying impacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort valuation, and learning the value of acting without further planning were found to facilitate strategy discovery. While these enhancements provided valuable insights into individual differences and the effect of these mechanisms on strategy discovery, they did not fully close the gap between model and human performance, prompting further exploration of additional factors that people might use to discover new planning strategies.", 'abstract_zh': '人们采用高效的规划策略，但这些策略是如何获得的呢？已有研究指出，人们可以通过 reinforcement 学习来发现新的规划策略，这一过程被称为元认知强化学习（MCRL）。尽管先前的研究表明，MCRL 模型能够学习新的规划策略，并且比其他机制更好地解释了参与者基于经验的发现，但同时也揭示了个体在元认知学习方面存在显著差异。此外，当这些模型应用于人类数据时，策略发现的速度明显慢于人类。本研究探讨是否可以通过整合可能促进人类策略发现的认知机制，使 MCRL 模型更接近人类的表现。具体来说，我们考虑内生的元认知伪奖励、主观努力评估以及终止权衡。对规划任务数据的分析表明，有很大比例的参与者至少使用了其中一种机制，个体间在使用这些机制方面存在显著差异，且这些机制对策略发现的影响各不相同。元认知伪奖励、主观努力评估以及学习无需进一步规划的行为的价值被发现能够促进策略发现。尽管这些增强提供了关于个体差异以及这些机制在策略发现中作用的重要见解，但模型与人类性能之间的差距并未完全缩小，因此需进一步探索人们可能使用的其他因素，以发现新的规划策略。', 'title_zh': '计划策略发现的认知机制个体差异'}
{'arxiv_id': 'arXiv:2505.23436', 'title': 'Emergent Risk Awareness in Rational Agents under Resource Constraints', 'authors': 'Daniel Jarne Ornia, Nicholas Bishop, Joel Dyer, Wei-Chen Lee, Ani Calinescu, Doyne Farme, Michael Wooldridge', 'link': 'https://arxiv.org/abs/2505.23436', 'abstract': 'Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.', 'abstract_zh': '具备代理能力的高级推理模型（AI代理）被部署以与人类互动，并在（近似的）效用函数和内部模型指导下解决顺序决策问题。当这些问题存在资源或失败约束，使得行动序列可能在资源耗尽时被迫终止时，代理会面临隐含的权衡，这重新塑造了它们基于效用（理性）的行为。此外，由于这些代理通常由人类委托人代理执行任务，约束暴露的不对称性可能会导致人类目标与代理激励之间的先前未预见的错位。我们通过生存多臂-bandit框架来形式化这一环境，提供理论和实证结果来量化生存驱动的偏好转变的影响，并确定错位出现的条件，同时提出减轻风险寻求或风险规避行为出现的机制。因此，本研究旨在增加对在生存压力下操作的AI代理所出现行为的理解和可解释性，并提供此类AI系统在关键资源限制环境中安全部署的指南。', 'title_zh': '理性的代理在资源约束下的 emergent 风险意识'}
{'arxiv_id': 'arXiv:2505.23432', 'title': 'A Mathematical Framework for AI-Human Integration in Work', 'authors': 'Elisa Celis, Lingxiao Huang, Nisheeth K. Vishnoi', 'link': 'https://arxiv.org/abs/2505.23432', 'abstract': "The rapid rise of Generative AI (GenAI) tools has sparked debate over their role in complementing or replacing human workers across job contexts. We present a mathematical framework that models jobs, workers, and worker-job fit, introducing a novel decomposition of skills into decision-level and action-level subskills to reflect the complementary strengths of humans and GenAI. We analyze how changes in subskill abilities affect job success, identifying conditions for sharp transitions in success probability. We also establish sufficient conditions under which combining workers with complementary subskills significantly outperforms relying on a single worker. This explains phenomena such as productivity compression, where GenAI assistance yields larger gains for lower-skilled workers. We demonstrate the framework' s practicality using data from O*NET and Big-Bench Lite, aligning real-world data with our model via subskill-division methods. Our results highlight when and how GenAI complements human skills, rather than replacing them.", 'abstract_zh': '生成式人工智能工具的迅速崛起引发了对其在各类工作环境中补充或取代人类工人的角色的辩论。我们提出了一种数学框架，用于建模工作、工人及工人与工作匹配度，引入了一种新的技能拆分方法，将技能分解为决策级技能和行动级技能，以反映人类和生成式人工智能的互补优势。我们分析了子技能能力变化对工作成功率的影响，确定了成功率显著变化的条件。我们还建立了在哪些条件下具有互补子技能的工人组合会显著优于依赖单一工人的条件。这解释了生产率压缩现象，即生成式人工智能辅助带来更大的收益提升，尤其是对于低技能工人。我们使用O*NET和Big-Bench Lite的数据示证了该框架的实用性，并通过子技能划分方法将实际数据与模型相匹配。我们的结果强调了生成式人工智能在补充而非取代人类技能时的时机和方式。', 'title_zh': 'AI与人类工作的数学框架'}
{'arxiv_id': 'arXiv:2505.23397', 'title': 'A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy', 'authors': 'Ahmad Mohsin, Helge Janicke, Ahmed Ibrahim, Iqbal H. Sarker, Seyit Camtepe', 'link': 'https://arxiv.org/abs/2505.23397', 'abstract': 'This article presents a structured framework for Human-AI collaboration in Security Operations Centers (SOCs), integrating AI autonomy, trust calibration, and Human-in-the-loop decision making. Existing frameworks in SOCs often focus narrowly on automation, lacking systematic structures to manage human oversight, trust calibration, and scalable autonomy with AI. Many assume static or binary autonomy settings, failing to account for the varied complexity, criticality, and risk across SOC tasks considering Humans and AI collaboration. To address these limitations, we propose a novel autonomy tiered framework grounded in five levels of AI autonomy from manual to fully autonomous, mapped to Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This enables adaptive and explainable AI integration across core SOC functions, including monitoring, protection, threat detection, alert triage, and incident response. The proposed framework differentiates itself from previous research by creating formal connections between autonomy, trust, and HITL across various SOC levels, which allows for adaptive task distribution according to operational complexity and associated risks. The framework is exemplified through a simulated cyber range that features the cybersecurity AI-Avatar, a fine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates human-AI collaboration for SOC tasks, reducing alert fatigue, enhancing response coordination, and strategically calibrating trust. This research systematically presents both the theoretical and practical aspects and feasibility of designing next-generation cognitive SOCs that leverage AI not to replace but to enhance human decision-making.', 'abstract_zh': '一种结构化的框架：在安全运营中心实现人类与人工智能的合作，结合人工智能自主性、信任校准及人工介入决策', 'title_zh': '安全运营中心中基于可信赖自主性的统一的人工智能协作框架'}
{'arxiv_id': 'arXiv:2505.23381', 'title': 'AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning', 'authors': 'Bowen Ping, Minnan Luo, Zhuohang Dang, Chenxi Wang, Chengyou Jia', 'link': 'https://arxiv.org/abs/2505.23381', 'abstract': "Geometry problem solving presents distinctive challenges in artificial intelligence, requiring exceptional multimodal comprehension and rigorous mathematical reasoning capabilities. Existing approaches typically fall into two categories: neural-based and symbolic-based methods, both of which exhibit limitations in reliability and interpretability. To address this challenge, we propose AutoGPS, a neuro-symbolic collaborative framework that solves geometry problems with concise, reliable, and human-interpretable reasoning processes. Specifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a Deductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal comprehension to translate geometry problems into structured formal language representations, with feedback from DSR collaboratively. The DSR takes the formalization as input and formulates geometry problem solving as a hypergraph expansion task, executing mathematically rigorous and reliable derivation to produce minimal and human-readable stepwise solutions. Extensive experimental evaluations demonstrate that AutoGPS achieves state-of-the-art performance on benchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms AutoGPS's impressive reliability and interpretability, with 99\\% stepwise logical coherence. The project homepage is at this https URL.", 'abstract_zh': '几何问题求解在人工智能中提出了独特的挑战，需要具备出色的多模态理解和严格的数学推理能力。现有方法通常分为基于神经网络和基于符号的方法，两者在可靠性和可解释性方面都存在局限性。为应对这一挑战，我们提出了一种名为AutoGPS的神经-符号协作框架，该框架能够以简洁、可靠且易于人类理解的推理过程解决几何问题。具体而言，AutoGPS采用了多模态问题形式化器（MPF）和演绎符号推理器（DSR）。MPF利用神经跨模态理解将几何问题转化为结构化的形式语言表示，并与DSR进行协作反馈。DSR以形式化结果为输入，将几何问题求解转化为超图扩张任务，执行严格的数学推理以生成简洁且易于理解的步骤解决方案。大量实验证明，AutoGPS在基准数据集上实现了最先进的性能。此外，人工步骤推理评估进一步证实了AutoGPS出色的可靠性和可解释性，其步骤逻辑连贯性达到99%。项目主页参见此 https URL。', 'title_zh': 'AutoGPS：通过多模态形式化和演绎推理实现的自动几何问题求解'}
{'arxiv_id': 'arXiv:2505.22990', 'title': 'MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design', 'authors': 'Pin-Han Chen, Yu-Sheng Lin, Wei-Cheng Lee, Tin-Yu Leu, Po-Hsiang Hsu, Anjana Dissanayake, Sungjin Oh, Chinq-Shiun Chiu', 'link': 'https://arxiv.org/abs/2505.22990', 'abstract': 'RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future "RF/Analog Copilots" that can collaborate seamlessly with human designers.', 'abstract_zh': 'RF/模拟设计对于将数字技术与现实世界信号连接起来至关重要，确保了广泛电子系统的功能性和可靠性。然而，模拟设计过程往往复杂、耗时且依赖于专家直觉，阻碍了电路开发的时间和成本效率。为克服手工电路设计的局限性，我们引入了MenTeR——一个集成于端到端模拟设计框架中的多智能体工作流。通过多个专门的AI代理协同解决设计过程中的不同方面，如规范理解、电路优化和测试台验证，MenTeR减少了频繁尝试错误的干预需求。MenTeR不仅加速了设计周期，还促进了更广泛的设计空间探索，展示了处理真实世界模拟系统的稳健能力。我们相信，MenTeR为未来的“RF/模拟副驾”奠定了基础，这些“副驾”能够与人类设计师无缝协作。', 'title_zh': 'MenTeR: 一个全自动多代理工作流用于端到端射频/模拟电路网表设计'}
{'arxiv_id': 'arXiv:2505.22987', 'title': 'Strategic Reflectivism In Intelligent Systems', 'authors': 'Nick Byrd', 'link': 'https://arxiv.org/abs/2505.22987', 'abstract': 'By late 20th century, the rationality wars had launched debates about the nature and norms of intuitive and reflective thinking. Those debates drew from mid-20th century ideas such as bounded rationality, which challenged more idealized notions of rationality observed since the 19th century. Now that 21st century cognitive scientists are applying the resulting dual process theories to artificial intelligence, it is time to dust off some lessons from this history. So this paper synthesizes old ideas with recent results from experiments on humans and machines. The result is Strategic Reflectivism, which takes the position that one key to intelligent systems (human or artificial) is pragmatic switching between intuitive and reflective inference to optimally fulfill competing goals. Strategic Reflectivism builds on American Pragmatism, transcends superficial indicators of reflective thinking such as model size or chains of thought, and becomes increasingly actionable as we learn more about the value of intuition and reflection.', 'abstract_zh': '21世纪认知科学视角下的战略反思主义：智能系统中的直觉与反思平衡策略', 'title_zh': '智能系统中的战略性反思主义'}
{'arxiv_id': 'arXiv:2505.22871', 'title': 'The WHY in Business Processes: Unification of Causal Process Models', 'authors': 'Yuval David, Fabiana Fournier, Lior Limonad, Inna Skarbovsky', 'link': 'https://arxiv.org/abs/2505.22871', 'abstract': 'Causal reasoning is essential for business process interventions and improvement, requiring a clear understanding of causal relationships among activity execution times in an event log. Recent work introduced a method for discovering causal process models but lacked the ability to capture alternating causal conditions across multiple variants. This raises the challenges of handling missing values and expressing the alternating conditions among log splits when blending traces with varying activities.\nWe propose a novel method to unify multiple causal process variants into a consistent model that preserves the correctness of the original causal models, while explicitly representing their causal-flow alternations. The method is formally defined, proved, evaluated on three open and two proprietary datasets, and released as an open-source implementation.', 'abstract_zh': '因果推理对于业务过程干预和改进是必要的，要求对事件日志中活动执行时间之间的因果关系有清晰的理解。最近的研究引入了一种发现因果过程模型的方法，但缺乏捕捉多个变体中交替因果条件的能力。这提出了处理缺失值和在混合具有不同活动的日志片段时表达交替条件的挑战。我们提出了一种新颖的方法，将多个因果过程变体统一为一个一致的模型，同时明确表示它们的因果流变异性。该方法形式化定义、证明，并在三个公开和两个专有数据集上进行评估，开源实现已发布。', 'title_zh': '商业流程中的“为什么”：因果流程模型的统一'}
{'arxiv_id': 'arXiv:2505.22779', 'title': 'Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds', 'authors': 'Mohammad Helal Uddin, Sabur Baidya', 'link': 'https://arxiv.org/abs/2505.22779', 'abstract': "Mental disorders including depression, anxiety, and other neurological disorders pose a significant global challenge, particularly among individuals exhibiting social avoidance tendencies. This study proposes a hybrid approach by leveraging smartphone sensor data measuring daily physical activities and analyzing their social media (Twitter) interactions for evaluating an individual's depression level. Using CNN-based deep learning models and Naive Bayes classification, we identify human physical activities accurately and also classify the user sentiments. A total of 33 participants were recruited for data acquisition, and nine relevant features were extracted from the physical activities and analyzed with their weekly depression scores, evaluated using the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six are derived from physical activities, achieving an activity recognition accuracy of 95%, while three features stem from sentiment analysis of Twitter activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several physical activity features exhibited significant correlations with the severity of depression symptoms. For classifying the depression severity, a support vector machine (SVM)-based algorithm is employed that demonstrated a very high accuracy of 94%, outperforming alternative models, e.g., the multilayer perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly effective in the long run for monitoring depression without breaching personal privacy.", 'abstract_zh': '智能手机传感器数据和社交媒体互动分析在评估抑郁水平中的混合方法研究', 'title_zh': '利用物理活动感应和社会媒体 feed 的混合数据采集预测人类抑郁'}
{'arxiv_id': 'arXiv:2505.23761', 'title': 'Differential Information: An Information-Theoretic Perspective on Preference Optimization', 'authors': 'Yunjae Won, Hyunji Lee, Hyeonbin Hwang, Minjoon Seo', 'link': 'https://arxiv.org/abs/2505.23761', 'abstract': 'Direct Preference Optimization (DPO) has become a standard technique for aligning language models with human preferences in a supervised manner. Despite its empirical success, the theoretical justification behind its log-ratio reward parameterization remains incomplete. In this work, we address this gap by utilizing the Differential Information Distribution (DID): a distribution over token sequences that captures the information gained during policy updates. First, we show that when preference labels encode the differential information required to transform a reference policy into a target policy, the log-ratio reward in DPO emerges as the uniquely optimal form for learning the target policy via preference optimization. This result naturally yields a closed-form expression for the optimal sampling distribution over rejected responses. Second, we find that the condition for preferences to encode differential information is fundamentally linked to an implicit assumption regarding log-margin ordered policies-an inductive bias widely used in preference optimization yet previously unrecognized. Finally, by analyzing the entropy of the DID, we characterize how learning low-entropy differential information reinforces the policy distribution, while high-entropy differential information induces a smoothing effect, which explains the log-likelihood displacement phenomenon. We validate our theoretical findings in synthetic experiments and extend them to real-world instruction-following datasets. Our results suggest that learning high-entropy differential information is crucial for general instruction-following, while learning low-entropy differential information benefits knowledge-intensive question answering. Overall, our work presents a unifying perspective on the DPO objective, the structure of preference data, and resulting policy behaviors through the lens of differential information.', 'abstract_zh': '直接偏好优化（DPO）已成为通过监督方式使语言模型与人类偏好对齐的标准技术。尽管它在实践上获得了成功，但其使用对数比率奖励参数化的理论依据仍不完备。在本文中，我们通过利用微分信息分布（DID）——一种捕捉策略更新过程中获得的信息的token序列分布——来填补这一缺口。首先，我们表明，当偏好标签编码了将基准策略转化为目标策略所需的微分信息时，DPO中的对数比率奖励将以唯一最优的形式出现，从而通过偏好优化学习目标策略。这一结果自然地导出了在拒绝响应上最优采样分布的闭式表达式。其次，我们发现偏好编码微分信息的条件与一个隐含假设密切相关，即对数边距排序策略的归纳偏见——这一偏见在偏好优化中广泛使用但此前未被认识。最后，通过对DID的熵进行分析，我们刻画了学习低熵微分信息如何强化策略分布，而高熵微分信息又如何产生平滑效应，解释了对数似然位移现象。我们在合成实验中验证了我们的理论发现，并扩展到了真实的指令遵循数据集上。我们的结果表明，学习高熵微分信息对于通用指令遵循至关重要，而学习低熵微分信息则有利于知识密集型问答任务。总体而言，我们的工作从微分信息的角度提供了一种统一的DPO目标、偏好数据结构及其导致的策略行为的视角。', 'title_zh': '差异信息：从信息论视角探讨偏好优化'}
{'arxiv_id': 'arXiv:2505.23744', 'title': 'Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need', 'authors': 'Qiang Wang, Xiang Song, Yuhang He, Jizhou Han, Chenhao Ding, Xinyuan Gao, Yihong Gong', 'link': 'https://arxiv.org/abs/2505.23744', 'abstract': "Deep neural networks (DNNs) often underperform in real-world, dynamic settings where data distributions change over time. Domain Incremental Learning (DIL) offers a solution by enabling continual model adaptation, with Parameter-Isolation DIL (PIDIL) emerging as a promising paradigm to reduce knowledge conflicts. However, existing PIDIL methods struggle with parameter selection accuracy, especially as the number of domains and corresponding classes grows. To address this, we propose SOYO, a lightweight framework that improves domain selection in PIDIL. SOYO introduces a Gaussian Mixture Compressor (GMC) and Domain Feature Resampler (DFR) to store and balance prior domain data efficiently, while a Multi-level Domain Feature Fusion Network (MDFN) enhances domain feature extraction. Our framework supports multiple Parameter-Efficient Fine-Tuning (PEFT) methods and is validated across tasks such as image classification, object detection, and speech enhancement. Experimental results on six benchmarks demonstrate SOYO's consistent superiority over existing baselines, showcasing its robustness and adaptability in complex, evolving environments. The codes will be released in this https URL.", 'abstract_zh': '深度神经网络（DNNs）在数据分布随时间变化的动态现实环境中often underperform。领域增量学习（DIL）提供了一种解决方案，通过使模型能够持续适应，参数隔离领域增量学习（PIDIL）逐渐成为一种减少知识冲突的有前途的范式。然而，现有的PIDIL方法在参数选择准确性方面存在问题，尤其是在领域和相应类别的数量增加时。为了解决这一问题，我们提出了Soyo，一个轻量级框架，以提高PIDIL中的领域选择。Soyo引入了高斯混合压缩器（GMC）和领域特征重采样器（DFR），以有效地存储和平衡先验领域数据，同时多级领域特征融合网络（MDFN）增强了领域特征提取。该框架支持多种参数高效微调（PEFT）方法，并在图像分类、物体检测和语音增强等任务中进行了验证。在六个基准上的实验结果表明，Soyo在所有现有基线中表现出持续的优势，展示了其在复杂、不断演变环境中的稳健性和适应性。代码将在以下链接发布：https://github.com/Qwen-Model/Soyo。', 'title_zh': '增强领域增量学习：选择最优参数至关重要'}
{'arxiv_id': 'arXiv:2505.23735', 'title': 'ATLAS: Learning to Optimally Memorize the Context at Test Time', 'authors': 'Ali Behrouz, Zeman Li, Praneeth Kacham, Majid Daliri, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni', 'link': 'https://arxiv.org/abs/2505.23735', 'abstract': 'Transformers have been established as the most popular backbones in sequence modeling, mainly due to their effectiveness in in-context retrieval tasks and the ability to learn at scale. Their quadratic memory and time complexity, however, bound their applicability in longer sequences and so has motivated researchers to explore effective alternative architectures such as modern recurrent neural networks (a.k.a long-term recurrent memory module). Despite their recent success in diverse downstream tasks, they struggle in tasks that requires long context understanding and extrapolation to longer sequences. We observe that these shortcomings come from three disjoint aspects in their design: (1) limited memory capacity that is bounded by the architecture of memory and feature mapping of the input; (2) online nature of update, i.e., optimizing the memory only with respect to the last input; and (3) less expressive management of their fixed-size memory. To enhance all these three aspects, we present ATLAS, a long-term memory module with high capacity that learns to memorize the context by optimizing the memory based on the current and past tokens, overcoming the online nature of long-term memory models. Building on this insight, we present a new family of Transformer-like architectures, called DeepTransformers, that are strict generalizations of the original Transformer architecture. Our experimental results on language modeling, common-sense reasoning, recall-intensive, and long-context understanding tasks show that ATLAS surpasses the performance of Transformers and recent linear recurrent models. ATLAS further improves the long context performance of Titans, achieving +80\\% accuracy in 10M context length of BABILong benchmark.', 'abstract_zh': '基于长期记忆模块的Transformer增强架构ATLAS', 'title_zh': 'ATLAS: 学习在测试时最优地记忆上下文'}
{'arxiv_id': 'arXiv:2505.23733', 'title': 'Exposing the Impact of GenAI for Cybercrime: An Investigation into the Dark Side', 'authors': 'Truong, Binny M. Samuel', 'link': 'https://arxiv.org/abs/2505.23733', 'abstract': "In recent years, the rapid advancement and democratization of generative AI models have sparked significant debate over safety, ethical risks, and dual-use concerns, particularly in the context of cybersecurity. While anecdotally known, this paper provides empirical evidence regarding generative AI's association with malicious internet-related activities and cybercrime by examining the phenomenon through psychological frameworks of technological amplification and affordance theory. Using a quasi-experimental design with interrupted time series analysis, we analyze two datasets, one general and one cryptocurrency-focused, to empirically assess generative AI's role in cybercrime. The findings contribute to ongoing discussions about AI governance by balancing control and fostering innovation, underscoring the need for strategies to guide policymakers, inform AI developers and cybersecurity professionals, and educate the public to maximize AI's benefits while mitigating its risks.", 'abstract_zh': '近年来，生成式AI模型的快速进步和普及化引发了关于安全、伦理风险和两用性担忧的重大讨论，特别是在网络安全领域的背景下。本文通过心理技术放大和赋能理论框架，提供实证证据分析生成式AI与恶意网络活动和网络犯罪之间的关联，并采用中断时间序列分析的准实验设计，研究两个数据集（一般性和加密货币相关）以实证评估生成式AI在网络安全犯罪中的角色。研究发现为AI治理的讨论增添了实证依据，平衡控制与促进创新，强调需要制定策略指导政策制定者、影响AI开发者和网络安全专业人员，并教育公众以最大限度地发挥AI的益处并减轻其风险。', 'title_zh': '揭示生成式AI对网络犯罪的影响：对黑暗一面的探究'}
{'arxiv_id': 'arXiv:2505.23720', 'title': 'COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents', 'authors': 'Arun Verma, Indrajit Saha, Makoto Yokoo, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2505.23720', 'abstract': "This paper considers a contextual bandit problem involving multiple agents, where a learner sequentially observes the contexts and the agent's reported arms, and then selects the arm that maximizes the system's overall reward. Existing work in contextual bandits assumes that agents truthfully report their arms, which is unrealistic in many real-life applications. For instance, consider an online platform with multiple sellers; some sellers may misrepresent product quality to gain an advantage, such as having the platform preferentially recommend their products to online users. To address this challenge, we propose an algorithm, COBRA, for contextual bandit problems involving strategic agents that disincentivize their strategic behavior without using any monetary incentives, while having incentive compatibility and a sub-linear regret guarantee. Our experimental results also validate the different performance aspects of our proposed algorithm.", 'abstract_zh': '一种抑制战略性行为的上下文 bandit 算法：COBRA', 'title_zh': 'COBRA: 基于上下文的臂赛选算法以确保战略性代理的truthful行为'}
{'arxiv_id': 'arXiv:2505.23714', 'title': 'SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods', 'authors': 'Roksana Goworek, Harpal Karlcut, Muhammad Shezad, Nijaguna Darshana, Abhishek Mane, Syam Bondada, Raghav Sikka, Ulvi Mammadov, Rauf Allahverdiyev, Sriram Purighella, Paridhi Gupta, Muhinyia Ndegwa, Haim Dubossarsky', 'link': 'https://arxiv.org/abs/2505.23714', 'abstract': 'This paper addresses the critical need for high-quality evaluation datasets in low-resource languages to advance cross-lingual transfer. While cross-lingual transfer offers a key strategy for leveraging multilingual pretraining to expand language technologies to understudied and typologically diverse languages, its effectiveness is dependent on quality and suitable benchmarks. We release new sense-annotated datasets of sentences containing polysemous words, spanning nine low-resource languages across diverse language families and scripts. To facilitate dataset creation, the paper presents a demonstrably beneficial semi-automatic annotation method. The utility of the datasets is demonstrated through Word-in-Context (WiC) formatted experiments that evaluate transfer on these low-resource languages. Results highlight the importance of targeted dataset creation and evaluation for effective polysemy disambiguation in low-resource settings and transfer studies. The released datasets and code aim to support further research into fair, robust, and truly multilingual NLP.', 'abstract_zh': '本文探讨了在低资源语言中构建高质量评估数据集的迫切需求，以促进跨语言迁移。通过多语言预训练利用跨语言迁移策略扩展语言技术至未研究和类型多样的语言，其效果依赖于高质量和合适的基准。本文发布了九种低资源语言的新感官注释数据集，这些语言跨多个语言家族和文字系统。为促进数据集的构建，本文提出了一种可证明有益的半自动注释方法。通过Word-in-Context (WiC) 格式实验展示了这些数据集在低资源语言迁移上的评估效果。结果强调了在低资源环境和迁移研究中针对性数据集创建和评估的重要性。所发布的数据集和代码旨在支持进一步研究公平、稳健且真正多语言的自然语言处理。', 'title_zh': 'SenWiCh: 低资源语言WiC的感知注释方法研究'}
{'arxiv_id': 'arXiv:2505.23710', 'title': 'From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems', 'authors': 'Zeinab Nezami, Syed Danial Ali Shah, Maryam Hafeez, Karim Djemame, Syed Ali Raza Zaidi', 'link': 'https://arxiv.org/abs/2505.23710', 'abstract': 'This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven intelligence enables dynamic adaptation beyond static connectivity. We explore the key enablers of autonomous communication systems, spanning reconfigurable infrastructure, adaptive middleware, and intelligent network functions, alongside multi-agent collaboration for distributed decision-making. We explore how these methodologies align with emerging industrial IoT frameworks, ensuring seamless integration within digital manufacturing processes. Our findings emphasize the potential for improved real-time decision-making, optimizing efficiency, and reducing latency in networked control systems. The discussion addresses ethical challenges, research directions, and standardization efforts, concluding with a technology stack roadmap to guide future developments. By leveraging state-of-the-art 6G network management techniques, this research contributes to the next generation of intelligent automation solutions, bridging the gap between theoretical advancements and real-world industrial applications.', 'abstract_zh': '这篇论文构想了6G作为一个自我进化的电信生态系统，其中基于AI的智能使得动态适应超越了静态连接。我们探索自主通信系统的关键使能技术，涵盖可重构基础设施、自适应中间件、智能网络功能，并涉及分布式决策中的多代理协作。我们探讨了这些方法如何与新兴的工业物联网框架相契合，确保与数字化制造过程的无缝集成。我们的研究强调了在联网控制系统中增强实时决策、优化效率和降低延迟的潜力。讨论涵盖了伦理挑战、研究方向和标准化努力，并以技术栈路线图结束，以指导未来的发展。通过利用最先进的6G网络管理技术，本研究为下一代智能自动化解决方案做出了贡献，弥合了理论进步与实际工业应用之间的差距。', 'title_zh': '从连接到自主：自进化通信系统的黎明'}
{'arxiv_id': 'arXiv:2505.23709', 'title': 'Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning', 'authors': 'Dionysis Christopoulos, Sotiris Spanos, Eirini Baltzi, Valsamis Ntouskos, Konstantinos Karantzalos', 'link': 'https://arxiv.org/abs/2505.23709', 'abstract': "We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learning rich representations of skin lesions through a novel nested contrastive learning approach that captures complex relationships between images and metadata. Melanoma detection and skin lesion classification based solely on images, pose significant challenges due to large variations in imaging conditions (lighting, color, resolution, distance, etc.) and lack of clinical and phenotypical context. Clinicians typically follow a holistic approach for assessing the risk level of the patient and for deciding which lesions may be malignant and need to be excised, by considering the patient's medical history as well as the appearance of other lesions of the patient. Inspired by this, SLIMP combines the appearance and the metadata of individual skin lesions with patient-level metadata relating to their medical record and other clinically relevant information. By fully exploiting all available data modalities throughout the learning process, the proposed pre-training strategy improves performance compared to other pre-training strategies on downstream skin lesions classification tasks highlighting the learned representations quality.", 'abstract_zh': 'SLIMP (皮肤病变图像-元数据预训练)', 'title_zh': '基于嵌套多模态对比学习的皮肤病变表型识别'}
{'arxiv_id': 'arXiv:2505.23706', 'title': 'Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats', 'authors': 'Utku Demir, Yalin E. Sagduyu, Tugba Erpek, Hossein Jafari, Sastry Kompella, Mengran Xue', 'link': 'https://arxiv.org/abs/2505.23706', 'abstract': "In connected and autonomous vehicles, machine learning for safety message classification has become critical for detecting malicious or anomalous behavior. However, conventional approaches that rely on centralized data collection or purely local training face limitations due to the large scale, high mobility, and heterogeneous data distributions inherent in inter-vehicle networks. To overcome these challenges, this paper explores Distributed Federated Learning (DFL), whereby vehicles collaboratively train deep learning models by exchanging model updates among one-hop neighbors and propagating models over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi) Extension Dataset, we show that DFL can significantly improve classification accuracy across all vehicles compared to learning strictly with local data. Notably, vehicles with low individual accuracy see substantial accuracy gains through DFL, illustrating the benefit of knowledge sharing across the network. We further show that local training data size and time-varying network connectivity correlate strongly with the model's overall accuracy. We investigate DFL's resilience and vulnerabilities under attacks in multiple domains, namely wireless jamming and training data poisoning attacks. Our results reveal important insights into the vulnerabilities of DFL when confronted with multi-domain attacks, underlining the need for more robust strategies to secure DFL in vehicular networks.", 'abstract_zh': '在连接和自主车辆中，基于机器学习的安全消息分类对于检测恶意或异常行为已成为关键。然而，传统的依赖中心化数据收集或纯本地训练的方法由于车联网中固有的大规模、高移动性和异质数据分布而面临局限性。为克服这些挑战，本文探索了分布式联邦学习（DFL），该方法通过车辆之间交换模型更新并跨多跳传播模型以协作训练深度学习模型。使用Vehicular Reference Misbehavior（VeReMi）扩展数据集，我们展示无论对于何种车辆，DFL都可以显著提高分类准确性。值得注意的是，通过DFL，个体准确率较低的车辆实现了显著的准确率提升，这表明了网络中知识共享的好处。进一步的研究显示，局部训练数据大小和时间变化的网络连接性与模型的整体准确性密切相关。我们还在多个领域（包括无线 jamming 和训练数据投毒攻击）下研究了DFL的鲁棒性和脆弱性，结果揭示了DFL在面对多域攻击时的关键脆弱性，突显了在车联网中对DFL采取更稳健策略的必要性。', 'title_zh': '车辆网络安全性中的分布式联邦学习：异常检测优势与多域攻击威胁'}
{'arxiv_id': 'arXiv:2505.23671', 'title': 'GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents', 'authors': 'Manish Shetty, Naman Jain, Jinjian Liu, Vijay Kethanaboyina, Koushik Sen, Ion Stoica', 'link': 'https://arxiv.org/abs/2505.23671', 'abstract': "Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.", 'abstract_zh': '开发高性能软件是一项复杂任务，需要专门的技术。我们引入了GSO，一个用于评估语言模型在开发高性能软件方面能力的基准。我们开发了一个自动化的工作流程，生成并执行性能测试，分析仓库提交历史，识别出跨越不同领域和编程语言的10个具有挑战性的优化任务共102项。为智能代理提供一个代码库和性能测试作为精确的规格说明，要求其提高运行时效率，衡量其效果与专家开发者的优化效果。我们的定量评估表明，顶尖的SWE-代理面临重大挑战，成功率低于5%，即使在推理时间进行扩展，改进也非常有限。我们的定性分析揭示了关键失败模式，包括低级语言的难度、懒优化策略的实践困难以及瓶颈定位的准确性挑战。我们发布了基准的代码和相关资源，以及智能代理的轨迹，以促进未来的研究。', 'title_zh': 'GSO: 评估软件工程代理软件优化任务的挑战'}
{'arxiv_id': 'arXiv:2505.23655', 'title': 'Keyed Chaotic Tensor Transformations for Secure And Attributable Neural Inference', 'authors': 'Peter David Fagan', 'link': 'https://arxiv.org/abs/2505.23655', 'abstract': 'This work introduces a novel framework for secure and privacy-preserving neural network inference based on keyed chaotic dynamical transformations. The proposed method applies a deterministic, cryptographically seeded chaotic system to tensors, producing non-invertible, user-specific transformations that enable authenticated inference, tensor-level watermarking, and data attribution. This framework offers a scalable and lightweight alternative to conventional cryptographic techniques, and establishes a new direction for tensor-level security in AI systems.', 'abstract_zh': '基于密钥控制混沌动力学变换的新型安全和隐私保护神经网络推理框架', 'title_zh': '基于密钥的混沌张量变换用于安全可追溯的神经推断'}
{'arxiv_id': 'arXiv:2505.23643', 'title': 'Securing AI Agents with Information-Flow Control', 'authors': 'Manuel Costa, Boris Köpf, Aashish Kolluri, Andrew Paverd, Mark Russinovich, Ahmed Salem, Shruti Tople, Lukas Wutschitz, Santiago Zanella-Béguelin', 'link': 'https://arxiv.org/abs/2505.23643', 'abstract': 'As AI agents become increasingly autonomous and capable, ensuring their security against vulnerabilities such as prompt injection becomes critical. This paper explores the use of information-flow control (IFC) to provide security guarantees for AI agents. We present a formal model to reason about the security and expressiveness of agent planners. Using this model, we characterize the class of properties enforceable by dynamic taint-tracking and construct a taxonomy of tasks to evaluate security and utility trade-offs of planner designs. Informed by this exploration, we present Fides, a planner that tracks confidentiality and integrity labels, deterministically enforces security policies, and introduces novel primitives for selectively hiding information. Its evaluation in AgentDojo demonstrates that this approach broadens the range of tasks that can be securely accomplished. A tutorial to walk readers through the the concepts introduced in the paper can be found at this https URL', 'abstract_zh': '随着AI代理越来越自主和强大，确保其免受诸如提示注入等漏洞的攻击变得至关重要。本文探讨了使用信息流控制（IFC）为AI代理提供安全保证的方法。我们提出了一种形式化模型来推理代理规划器的安全性和表达能力。通过该模型，我们确定了可由动态污点追踪强制执行的属性类别，并构建了任务分类法以评估规划器设计的安全性和实用性权衡。基于这一探索，我们提出了Fides规划器，该规划器追踪机密性和完整性标签，确定性地执行安全策略，并引入了有选择地隐藏信息的新颖机制。在AgentDojo中的评估表明，这种方法扩展了可以安全完成的任务范围。有关本文介绍的概念教程，请参阅此链接：https://example.com。', 'title_zh': '使用信息流控制保障AI代理的安全'}
{'arxiv_id': 'arXiv:2505.23631', 'title': 'Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education', 'authors': 'Boning Zhao', 'link': 'https://arxiv.org/abs/2505.23631', 'abstract': 'Assessing student depression in sensitive environments like special education is challenging. Standardized questionnaires may not fully reflect students\' true situations. Furthermore, automated methods often falter with rich student narratives, lacking the crucial, individualized insights stemming from teachers\' empathetic connections with students. Existing methods often fail to address this ambiguity or effectively integrate educator understanding. To address these limitations by fostering a synergistic human-AI collaboration, this paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered AI framework for transparent and socially responsible depression severity assessment. Our approach uniquely integrates student narrative text with a teacher-derived, 9-dimensional "Empathy Vector" (EV), its dimensions guided by the PHQ-9 framework,to explicitly translate tacit empathetic insight into a structured AI input enhancing rather than replacing human judgment. Rigorous experiments optimized the multimodal fusion, text representation, and classification architecture, achieving 82.74% accuracy for 7-level severity classification. This work demonstrates a path toward more responsible and ethical affective computing by structurally embedding human empathy', 'abstract_zh': '评估敏感环境如特殊教育中的学生抑郁状况具有挑战性。标准化问卷可能无法全面反映学生的真实情况。此外，自动化方法往往难以处理丰富的学生叙事，缺乏来自教师对学生的同理心连接的关键性、个性化见解。现有方法常难以解决这种模糊性或有效整合教育者的理解。为了通过促进人类与人工智能的协同合作来解决这些局限，本文提出了一种新型、以人为核心的人工智能框架——Human Empathy as Encoder（HEAE），旨在实现透明和负责任的抑郁严重程度评估。我们的方法独特地将学生叙事文本与教师提取的9维“同理心向量”（EV）相结合，EV的各个维度由PHQ-9框架指导，以明确地将隐性的同理心洞察转化为结构化的AI输入，以增强而非替代人类判断。严格的实验优化了多模态融合、文本表示和分类架构，实现了7级严重程度分类的82.74%准确率。这项工作展示了通过结构化嵌入人类同理心实现更加负责任和道德的情感计算的道路。', 'title_zh': '人类共情作为编码器：AI辅助的特殊教育中抑郁评估'}
{'arxiv_id': 'arXiv:2505.23628', 'title': 'AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora', 'authors': 'Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song', 'link': 'https://arxiv.org/abs/2505.23628', 'abstract': 'We present AutoSchemaKG, a framework for fully autonomous knowledge graph construction that eliminates the need for predefined schemas. Our system leverages large language models to simultaneously extract knowledge triples and induce comprehensive schemas directly from text, modeling both entities and events while employing conceptualization to organize instances into semantic categories. Processing over 50 million documents, we construct ATLAS (Automated Triple Linking And Schema induction), a family of knowledge graphs with 900+ million nodes and 5.9 billion edges. This approach outperforms state-of-the-art baselines on multi-hop QA tasks and enhances LLM factuality. Notably, our schema induction achieves 95\\% semantic alignment with human-crafted schemas with zero manual intervention, demonstrating that billion-scale knowledge graphs with dynamically induced schemas can effectively complement parametric knowledge in large language models.', 'abstract_zh': '我们提出AutoSchemaKG，一种无需预定义模式的完全自主知识图谱构建框架', 'title_zh': 'AutoSchemaKG：通过从大规模网页 corpora 中动态引申语 schemata 自主构建知识图谱'}
{'arxiv_id': 'arXiv:2505.23624', 'title': 'Towards Explainable Sequential Learning', 'authors': 'Giacomo Bergami, Emma Packer, Kirsty Scott, Silvia Del Din', 'link': 'https://arxiv.org/abs/2505.23624', 'abstract': 'This paper offers a hybrid explainable temporal data processing pipeline, DataFul Explainable MultivariatE coRrelatIonal Temporal Artificial inTElligence (EMeriTAte+DF), bridging numerical-driven temporal data classification with an event-based one through verified artificial intelligence principles, enabling human-explainable results. This was possible through a preliminary a posteriori explainable phase describing the numerical input data in terms of concurrent constituents with numerical payloads. This further required extending the event-based literature to design specification mining algorithms supporting concurrent constituents. Our previous and current solutions outperform state-of-the-art solutions for multivariate time series classifications, thus showcasing the effectiveness of the proposed methodology.', 'abstract_zh': '基于事件的多变量时序数据可解释处理管道：DataFul Explainable Multivariate Correlational Temporal Artificial Intelligence (EMeriTAte+DF)', 'title_zh': '可解释的序列学习'}
{'arxiv_id': 'arXiv:2505.23604', 'title': 'Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering', 'authors': 'Guangtao Zeng, Maohao Shen, Delin Chen, Zhenting Qi, Subhro Das, Dan Gutfreund, David Cox, Gregory Wornell, Wei Lu, Zhang-Wei Hong, Chuang Gan', 'link': 'https://arxiv.org/abs/2505.23604', 'abstract': 'Language models (LMs) perform well on standardized coding benchmarks but struggle with real-world software engineering tasks such as resolving GitHub issues in SWE-Bench, especially when model parameters are less than 100B. While smaller models are preferable in practice due to their lower computational cost, improving their performance remains challenging. Existing approaches primarily rely on supervised fine-tuning (SFT) with high-quality data, which is expensive to curate at scale. An alternative is test-time scaling: generating multiple outputs, scoring them using a verifier, and selecting the best one. Although effective, this strategy often requires excessive sampling and costly scoring, limiting its practical application. We propose Evolutionary Test-Time Scaling (EvoScale), a sample-efficient method that treats generation as an evolutionary process. By iteratively refining outputs via selection and mutation, EvoScale shifts the output distribution toward higher-scoring regions, reducing the number of samples needed to find correct solutions. To reduce the overhead from repeatedly sampling and selection, we train the model to self-evolve using reinforcement learning (RL). Rather than relying on external verifiers at inference time, the model learns to self-improve the scores of its own generations across iterations. Evaluated on SWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or exceed the performance of models with over 100B parameters while using a few samples. Code, data, and models will be fully open-sourced.', 'abstract_zh': 'Evolutionary Test-Time Scaling for Real-World Software Engineering Tasks', 'title_zh': 'Satori-SWE: 进化测试时动态缩放以提高样本高效软件工程'}
{'arxiv_id': 'arXiv:2505.23595', 'title': 'DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification', 'authors': 'Youssef Mohamed, Noran Mohamed, Khaled Abouhashad, Feilong Tang, Sara Atito, Shoaib Jameel, Imran Razzak, Ahmed B. Zaky', 'link': 'https://arxiv.org/abs/2505.23595', 'abstract': 'While Multi-Task Learning (MTL) offers inherent advantages in complex domains such as medical imaging by enabling shared representation learning, effectively balancing task contributions remains a significant challenge. This paper addresses this critical issue by introducing DeepChest, a novel, computationally efficient and effective dynamic task-weighting framework specifically designed for multi-label chest X-ray (CXR) classification. Unlike existing heuristic or gradient-based methods that often incur substantial overhead, DeepChest leverages a performance-driven weighting mechanism based on effective analysis of task-specific loss trends. Given a network architecture (e.g., ResNet18), our model-agnostic approach adaptively adjusts task importance without requiring gradient access, thereby significantly reducing memory usage and achieving a threefold increase in training speed. It can be easily applied to improve various state-of-the-art methods. Extensive experiments on a large-scale CXR dataset demonstrate that DeepChest not only outperforms state-of-the-art MTL methods by 7% in overall accuracy but also yields substantial reductions in individual task losses, indicating improved generalization and effective mitigation of negative transfer. The efficiency and performance gains of DeepChest pave the way for more practical and robust deployment of deep learning in critical medical diagnostic applications. The code is publicly available at this https URL', 'abstract_zh': 'DeepChest：一种用于多标签胸部X光分类的高效动态任务加权框架', 'title_zh': '深度胸部影像分类：动态无梯度任务加权方法以实现有效的多任务学习'}
{'arxiv_id': 'arXiv:2505.23580', 'title': 'Engineering Serendipity through Recommendations of Items with Atypical Aspects', 'authors': 'Ramit Aditya, Razvan Bunescu, Smita Nannaware, Erfan Al-Hossami', 'link': 'https://arxiv.org/abs/2505.23580', 'abstract': 'A restaurant dinner or a hotel stay may lead to memorable experiences when guests encounter unexpected aspects that also match their interests. For example, an origami-making station in the waiting area of a restaurant may be both surprising and enjoyable for a customer who is passionate about paper crafts. Similarly, an exhibit of 18th century harpsichords would be atypical for a hotel lobby and likely pique the interest of a guest who has a passion for Baroque music. Motivated by this insight, in this paper we introduce the new task of engineering serendipity through recommendations of items with atypical aspects. We describe an LLM-based system pipeline that extracts atypical aspects from item reviews, then estimates and aggregates their user-specific utility in a measure of serendipity potential that is used to rerank a list of items recommended to the user. To facilitate system development and evaluation, we introduce a dataset of Yelp reviews that are manually annotated with atypical aspects and a dataset of artificially generated user profiles, together with crowdsourced annotations of user-aspect utility values. Furthermore, we introduce a custom procedure for dynamic selection of in-context learning examples, which is shown to improve LLM-based judgments of atypicality and utility. Experimental evaluations show that serendipity-based rankings generated by the system are highly correlated with ground truth rankings for which serendipity scores are computed from manual annotations of atypical aspects and their user-dependent utility. Overall, we hope that the new recommendation task and the associated system presented in this paper catalyze further research into recommendation approaches that go beyond accuracy in their pursuit of enhanced user satisfaction.\nThe datasets and the code are made publicly available at this https URL .', 'abstract_zh': '餐馆晚餐或酒店住宿可能因意外遇到符合个人兴趣的非典型元素而成为难忘的经历。例如，餐馆候餐区的手工折纸工作站可能会让热衷纸艺的顾客感到惊喜和愉快。同样，酒店大堂中展出的18世纪克拉维科特琴可能会让热衷巴洛克音乐的客人感到兴趣盎然。基于这一洞察，本文介绍了一种通过推荐具有非典型特性的物品来培养偶然性的新任务。我们描述了一种基于大语言模型（LLM）的系统流程，该流程从物品评论中提取非典型特性，然后估计并聚合这些特性的用户特定效用，将其用于重新排列推荐给用户的物品列表。为了促进系统开发和评估，我们引入了一个手工标注非典型特性的 Yelp 评论数据集和一个人工生成的用户画像数据集，以及用户-非典型特性效用值的众包标注。此外，我们引入了一种定制的上下文学习示例动态选择方法，该方法被证明可以提高基于大语言模型的非典型性与效用判断。实验评估表明，系统生成的基于偶然性的排名与从手动标注的非典型特性及其用户依赖效用计算出的真实排名高度相关。总体而言，我们希望通过本文介绍的新推荐任务和相关系统，激发进一步的研究，以探索超越准确性的推荐方法，追求增强的用户满意度。数据集和代码在此网址公开：this https URL。', 'title_zh': '通过推荐具有非典型特征的物品实现偶然发现的工程'}
{'arxiv_id': 'arXiv:2505.23538', 'title': 'CLaC at SemEval-2025 Task 6: A Multi-Architecture Approach for Corporate Environmental Promise Verification', 'authors': 'Nawar Turk, Eeham Khan, Leila Kosseim', 'link': 'https://arxiv.org/abs/2505.23538', 'abstract': 'This paper presents our approach to the SemEval-2025 Task~6 (PromiseEval), which focuses on verifying promises in corporate ESG (Environmental, Social, and Governance) reports. We explore three model architectures to address the four subtasks of promise identification, supporting evidence assessment, clarity evaluation, and verification timing. Our first model utilizes ESG-BERT with task-specific classifier heads, while our second model enhances this architecture with linguistic features tailored for each subtask. Our third approach implements a combined subtask model with attention-based sequence pooling, transformer representations augmented with document metadata, and multi-objective learning. Experiments on the English portion of the ML-Promise dataset demonstrate progressive improvement across our models, with our combined subtask approach achieving a leaderboard score of 0.5268, outperforming the provided baseline of 0.5227. Our work highlights the effectiveness of linguistic feature extraction, attention pooling, and multi-objective learning in promise verification tasks, despite challenges posed by class imbalance and limited training data.', 'abstract_zh': '本文介绍了我们针对SemEval-2025 Task 6（PromiseEval）的方法，专注于验证企业ESG（环境、社会和治理）报告中的承诺。我们探索了三种模型架构来应对承诺识别、支持证据评估、清晰度评价和验证时间四个子任务。我们的第一个模型采用了ESG-BERT并结合了具有特定任务分类头的模型，第二个模型在此基础上加入了针对每个子任务定制的语言特征。我们的第三个方法则实现了一种结合子任务的模型，该模型采用了基于注意力的序列池化、结合文档元数据的变压器表示，并进行了多目标学习。在ML-Promise数据集的英语部分上的实验表明，我们的模型展现了逐步改进的趋势，其中结合子任务的方法在排行榜上取得了0.5268的分数，优于提供的基线0.5227。我们的研究突显了在承诺验证任务中提取语言特征、注意力池化和多目标学习的有效性，尽管面临着类别不平衡和训练数据有限的挑战。', 'title_zh': 'CLaC 在 SemEval-2025 任务 6 中的多模型方法及其在企业环境承诺验证中的应用'}
{'arxiv_id': 'arXiv:2505.23529', 'title': 'Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning', 'authors': 'Shifeng Xie, Aref Einizade, Jhony H. Giraldo', 'link': 'https://arxiv.org/abs/2505.23529', 'abstract': 'Graph Representation Learning (GRL) is a fundamental task in machine learning, aiming to encode high-dimensional graph-structured data into low-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used in GRL because they can avoid expensive human annotation. In this work, we propose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our approach introduces a subgraph Gaussian embedding module, which adaptively maps subgraphs to a structured Gaussian space, ensuring the preservation of input subgraph characteristics while generating subgraphs with a controlled distribution. We then employ optimal transport distances, more precisely the Wasserstein and Gromov-Wasserstein distances, to effectively measure the similarity between subgraphs, enhancing the robustness of the contrastive learning process. Extensive experiments across multiple benchmarks demonstrate that \\method~outperforms or presents competitive performance against state-of-the-art approaches. Our findings provide insights into the design of SSL methods for GRL, emphasizing the importance of the distribution of the generated contrastive pairs.', 'abstract_zh': '图表示学习（GRL）是机器学习中的一个基础任务，旨在将高维图结构数据编码为低维向量。自我监督学习（SSL）方法在GRL中广泛使用，因为它们可以避免昂贵的人工标注。在本文中，我们提出了一种新型的子图高斯嵌入对比（SubGEC）方法。我们的方法引入了一个子图高斯嵌入模块，该模块自适应地将子图映射到结构化高斯空间，同时保证输入子图特征的保留，并生成具有可控分布的子图。我们随后采用最优传输距离，即 Wasserstein 距离和 Gromov-Wasserstein 距离，以有效地度量子图之间的相似性，增强了对比学习过程的鲁棒性。在多个基准上的广泛实验表明，本方法在性能上优于或与最先进的方法相竞争。我们的发现为GRL中的SSL方法的设计提供了见解，强调了生成对比对之间分布的重要性。', 'title_zh': '子图高斯嵌入对比学习自监督图表示学习'}
{'arxiv_id': 'arXiv:2505.23437', 'title': 'Bounded-Abstention Pairwise Learning to Rank', 'authors': 'Antonio Ferrara, Andrea Pugnana, Francesco Bonchi, Salvatore Ruggieri', 'link': 'https://arxiv.org/abs/2505.23437', 'abstract': "Ranking systems influence decision-making in high-stakes domains like health, education, and employment, where they can have substantial economic and social impacts. This makes the integration of safety mechanisms essential. One such mechanism is $\\textit{abstention}$, which enables algorithmic decision-making system to defer uncertain or low-confidence decisions to human experts. While abstention have been predominantly explored in the context of classification tasks, its application to other machine learning paradigms remains underexplored. In this paper, we introduce a novel method for abstention in pairwise learning-to-rank tasks. Our approach is based on thresholding the ranker's conditional risk: the system abstains from making a decision when the estimated risk exceeds a predefined threshold. Our contributions are threefold: a theoretical characterization of the optimal abstention strategy, a model-agnostic, plug-in algorithm for constructing abstaining ranking models, and a comprehensive empirical evaluations across multiple datasets, demonstrating the effectiveness of our approach.", 'abstract_zh': '排名系统在高 stakes 领域如健康、教育和就业中影响决策，这些领域可能产生重大经济和社会影响。因此，整合安全机制变得至关重要。其中一种机制是“弃权”（abstention），使算法决策系统能够将不确定或低置信度的决策交给人类专家。尽管弃权主要在分类任务中进行探讨，但其在其他机器学习范式中的应用尚未得到充分研究。在本文中，我们提出了在成对学习排序任务中弃权的一种新方法。我们的方法基于阈值化排序器的条件风险：当估计风险超过预定义阈值时，系统弃权决策。我们的贡献包括：最优弃权策略的理论表征、不依赖于特定模型的插件算法以构建弃权排序模型，以及在多个数据集上的全面实证评估，证明了我们方法的有效性。', 'title_zh': '有界弃权成对学习排序'}
{'arxiv_id': 'arXiv:2505.23422', 'title': 'From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents', 'authors': 'Tobias Lindenbauer, Georg Groh, Hinrich Schütze', 'link': 'https://arxiv.org/abs/2505.23422', 'abstract': 'We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.', 'abstract_zh': 'CTIM-Rover：一种基于AutoCodeRover的软件工程AI代理', 'title_zh': '从知识到噪声：CTIM-Rover及其软件工程代理中情景记忆的局限性'}
{'arxiv_id': 'arXiv:2505.23417', 'title': 'Toward Effective AI Governance: A Review of Principles', 'authors': 'Danilo Ribeiro, Thayssa Rocha, Gustavo Pinto, Bruno Cartaxo, Marcelo Amaral, Nicole Davila, Ana Camargo', 'link': 'https://arxiv.org/abs/2505.23417', 'abstract': 'Artificial Intelligence (AI) governance is the practice of establishing frameworks, policies, and procedures to ensure the responsible, ethical, and safe development and deployment of AI systems. Although AI governance is a core pillar of Responsible AI, current literature still lacks synthesis across such governance frameworks and practices. Objective: To identify which frameworks, principles, mechanisms, and stakeholder roles are emphasized in secondary literature on AI governance. Method: We conducted a rapid tertiary review of nine peer-reviewed secondary studies from IEEE and ACM (20202024), using structured inclusion criteria and thematic semantic synthesis. Results: The most cited frameworks include the EU AI Act and NIST RMF; transparency and accountability are the most common principles. Few reviews detail actionable governance mechanisms or stakeholder strategies. Conclusion: The review consolidates key directions in AI governance and highlights gaps in empirical validation and inclusivity. Findings inform both academic inquiry and practical adoption in organizations.', 'abstract_zh': '人工智能治理是建立框架、政策和程序以确保人工智能系统的负责任、伦理和安全开发与部署的实践。尽管人工智能治理是负责任人工智能的核心支柱，但当前文献仍缺乏对这类治理框架和实践的综合总结。目标：识别secondary文献中人工智能治理所强调的框架、原则、机制和利益相关者角色。方法：我们使用结构化的纳入标准和主题语义合成，对IEEE和ACM（2020-2024）的九篇同行评议secondary研究进行了快速三级审查。结果：引用最多的框架包括欧盟AI法案和NIST风险管理框架；透明度和问责制是最常见的原则。很少有综述详细说明可操作的治理机制或利益相关者策略。结论：该审查总结了人工智能治理的关键方向，并指出了实证验证不足和包容性不足的问题。研究结果既指导学术研究，也促进组织中的实际应用。', 'title_zh': '有效人工智能治理的原则综述'}
{'arxiv_id': 'arXiv:2505.23415', 'title': 'Bidirectional predictive coding', 'authors': 'Gaspard Oliviers, Mufeng Tang, Rafal Bogacz', 'link': 'https://arxiv.org/abs/2505.23415', 'abstract': "Predictive coding (PC) is an influential computational model of visual learning and inference in the brain. Classical PC was proposed as a top-down generative model, where the brain actively predicts upcoming visual inputs, and inference minimises the prediction errors. Recent studies have also shown that PC can be formulated as a discriminative model, where sensory inputs predict neural activities in a feedforward manner. However, experimental evidence suggests that the brain employs both generative and discriminative inference, while unidirectional PC models show degraded performance in tasks requiring bidirectional processing. In this work, we propose bidirectional PC (bPC), a PC model that incorporates both generative and discriminative inference while maintaining a biologically plausible circuit implementation. We show that bPC matches or outperforms unidirectional models in their specialised generative or discriminative tasks, by developing an energy landscape that simultaneously suits both tasks. We also demonstrate bPC's superior performance in two biologically relevant tasks including multimodal learning and inference with missing information, suggesting that bPC resembles biological visual inference more closely.", 'abstract_zh': '双向预测编码(bPC):结合生成和判别推理的生物可行性模型', 'title_zh': '双向预测编码'}
{'arxiv_id': 'arXiv:2505.23412', 'title': 'Buffer-free Class-Incremental Learning with Out-of-Distribution Detection', 'authors': 'Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli', 'link': 'https://arxiv.org/abs/2505.23412', 'abstract': 'Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must not only learn new classes over time without forgetting previous ones but also handle inputs from unknown classes that a closed-set model would misclassify. Recent works address both issues by (i)~training multi-head models using the task-incremental learning framework, and (ii) predicting the task identity employing out-of-distribution (OOD) detectors. While effective, the latter mainly relies on joint training with a memory buffer of past data, raising concerns around privacy, scalability, and increased training time. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. We uncover that these methods, when applied appropriately at inference time, can serve as a strong substitute for buffer-based OOD detection. We show that this buffer-free approach achieves comparable or superior performance to buffer-based methods both in terms of class-incremental learning and the rejection of unknown samples. Experimental results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings, offering new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.', 'abstract_zh': '开放场景下类增量学习（CIL）提出了显著挑战，模型不仅要在线学习新类目同时不忘记先前的类目，还要处理来自封闭集模型无法正确分类的未知类别的输入。最新研究通过（i）使用任务增量学习框架训练多头模型，以及（ii）使用异常分布（OOD）检测器预测任务身份，同时有效应对了上述问题。然而，第二种方法主要依赖于与过去数据记忆缓冲的联合训练，这引发了关于隐私性、可扩展性和增加训练时间的担忧。本文深入分析了事后异常分布检测方法，并探讨了它们在消除记忆缓冲需求方面的潜力。我们发现，在合适的推理时间应用这些方法，可以作为基于缓冲的异常分布检测的强有力替代方案。实验结果表明，该无缓冲方法在类增量学习和排除未知样本方面，无论是性能还是表现，都达到了基于缓冲的方法的可比或优越水平。CIFAR-10、CIFAR-100和Tiny ImageNet数据集上的实验结果支持我们的发现，为开放场景下高效且隐私保护的CIL系统设计提供了新的见解。', 'title_zh': '无缓冲的类别增量学习与_out-of-distribution_检测'}
{'arxiv_id': 'arXiv:2505.23386', 'title': 'VModA: An Effective Framework for Adaptive NSFW Image Moderation', 'authors': 'Han Bao, Qinying Wang, Zhi Chen, Qingming Li, Xuhong Zhang, Changjiang Li, Zonghui Wang, Shouling Ji, Wenzhi Chen', 'link': 'https://arxiv.org/abs/2505.23386', 'abstract': 'Not Safe/Suitable for Work (NSFW) content is rampant on social networks and poses serious harm to citizens, especially minors. Current detection methods mainly rely on deep learning-based image recognition and classification. However, NSFW images are now presented in increasingly sophisticated ways, often using image details and complex semantics to obscure their true nature or attract more views. Although still understandable to humans, these images often evade existing detection methods, posing a significant threat. Further complicating the issue, varying regulations across platforms and regions create additional challenges for effective moderation, leading to detection bias and reduced accuracy. To address this, we propose VModA, a general and effective framework that adapts to diverse moderation rules and handles complex, semantically rich NSFW content across categories. Experimental results show that VModA significantly outperforms existing methods, achieving up to a 54.3% accuracy improvement across NSFW types, including those with complex semantics. Further experiments demonstrate that our method exhibits strong adaptability across categories, scenarios, and base VLMs. We also identified inconsistent and controversial label samples in public NSFW benchmark datasets, re-annotated them, and submitted corrections to the original maintainers. Two datasets have confirmed the updates so far. Additionally, we evaluate VModA in real-world scenarios to demonstrate its practical effectiveness.', 'abstract_zh': '不适合工作（NSFW）内容在社交网络上泛滥并对公民，特别是未成年人造成了严重危害。当前的检测方法主要依赖基于深度学习的图像识别和分类。然而，NSFW图像现在以日益复杂的方式呈现，常常通过图像细节和复杂的语义来掩盖其真实性质或吸引更多关注。虽然这些图像对人类仍具有可理解性，但往往能够绕过现有的检测方法，构成重大威胁。进一步复杂化的是，不同平台和地区的不同规定为有效的网络监管带来了额外挑战，导致检测偏差和准确性降低。为应对这一问题，我们提出了一种适应性强且有效的框架VModA，该框架能够适应多样化的监管规则，并处理跨类别复杂的、语义丰富的NSFW内容。实验结果显示，VModA在NSFW类型中显著优于现有方法，尤其是在复杂语义类型中实现了多达54.3%的准确性提升。进一步的实验显示，我们的方法在类别、场景和基础VLM之间具有很强的适应性。我们还在公共NSFW基准数据集中发现了不一致和有争议的标签样本，重新标注了这些样本，并向原维护者提交了更正。截至目前，两个数据集已经确认了更新。此外，我们还在现实场景中评估了VModA，展示了其实用效果。', 'title_zh': 'VModA：一种有效的自适应 NSFW 图像审核框架'}
{'arxiv_id': 'arXiv:2505.23369', 'title': 'Dynamic Spectral Backpropagation for Efficient Neural Network Training', 'authors': 'Mannmohan Muthuraman', 'link': 'https://arxiv.org/abs/2505.23369', 'abstract': 'Dynamic Spectral Backpropagation (DSBP) enhances neural network training under resource constraints by projecting gradients onto principal eigenvectors, reducing complexity and promoting flat minima. Five extensions are proposed, dynamic spectral inference, spectral architecture optimization, spectral meta learning, spectral transfer regularization, and Lie algebra inspired dynamics, to address challenges in robustness, fewshot learning, and hardware efficiency. Supported by a third order stochastic differential equation (SDE) and a PAC Bayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank Adaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion MNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive experiments and visualizations. Future work focuses on scalability, bias mitigation, and ethical considerations.', 'abstract_zh': '动态谱 backpropagation (DSBP) 在资源受限条件下通过将梯度投影到主特征向量上增强神经网络训练，降低复杂度并促进平坦极小值。提出五种扩展，动态谱推断、谱架构优化、谱元学习、谱转移正则化以及基于李代数的动力学，以应对稳健性、少样本学习和硬件效率挑战。通过三级随机微分方程 (SDE) 和 PAC 湹率极限支持，DSBP 在 CIFAR 10、Fashion MNIST、MedMNIST 和 Tiny ImageNet 上超越了 Sharpness Aware Minimization (SAM)、Low Rank Adaptation (LoRA) 和 Model Agnostic Meta Learning (MAML)，如广泛实验和可视化所示。未来工作集中在可扩展性、偏差缓解和伦理考虑上。', 'title_zh': '高效的神经网络训练动态谱 backpropagation 方法'}
{'arxiv_id': 'arXiv:2505.23354', 'title': 'Representing local protein environments with atomistic foundation models', 'authors': 'Meital Bojan, Sanketh Vedula, Advaith Maddipatla, Nadav Bojan Sellam, Federico Napoli, Paul Schanda, Alex M. Bronstein', 'link': 'https://arxiv.org/abs/2505.23354', 'abstract': "The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.", 'abstract_zh': '蛋白质的局部结构强烈影响其功能及其与其他分子的相互作用。因此，对局部蛋白质环境进行简洁且信息丰富的表示对于蛋白质和生物分子相互作用的建模和设计至关重要。然而，这些环境的广泛结构和化学变异性使其建模具有挑战性，现有的表示形式仍未得到充分探索。在本工作中，我们提出了一种新的由原子尺度基础模型（AFMs）中间特征衍生的局部蛋白质环境表示方法。我们证明这种表示有效地捕捉了局部结构（如二级结构元件）和化学特征（如氨基酸 identities 和质子化状态）。进一步的研究表明，AFM衍生的表示空间具有有意义的结构，能够构建数据驱动的生物分子环境分布先验知识。最后，在生物分子核磁共振光谱学的背景下，我们展示了所提出的表示方法能够实现首屈一指的物理信息化学位移预测器，达到了最先进的准确性。我们的结果表明，原子尺度基础模型及其涌现表示在蛋白质建模中的有效性超出了传统的分子模拟。我们相信这将开启构建蛋白质环境有效功能表示的新途径。', 'title_zh': '用原子级基础模型表示局部蛋白质环境'}
{'arxiv_id': 'arXiv:2505.23353', 'title': 'Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis', 'authors': 'Alexandra G. Roberts, Ha M. Luu, Mert Şişman, Alexey V. Dimov, Ceren Tozlu, Ilhami Kovanlikaya, Susan A. Gauthier, Thanh D. Nguyen, Yi Wang', 'link': 'https://arxiv.org/abs/2505.23353', 'abstract': 'Quantitative susceptibility maps from magnetic resonance images can provide both prognostic and diagnostic information in multiple sclerosis, a neurodegenerative disease characterized by the formation of lesions in white matter brain tissue. In particular, susceptibility maps provide adequate contrast to distinguish between "rim" lesions, surrounded by deposited paramagnetic iron, and "non-rim" lesion types. These paramagnetic rim lesions (PRLs) are an emerging biomarker in multiple sclerosis. Much effort has been devoted to both detection and segmentation of such lesions to monitor longitudinal change. As paramagnetic rim lesions are rare, addressing this problem requires confronting the class imbalance between rim and non-rim lesions. We produce synthetic quantitative susceptibility maps of paramagnetic rim lesions and show that inclusion of such synthetic data improves classifier performance and provide a multi-channel extension to generate accompanying contrasts and probabilistic segmentation maps. We exploit the projection capability of our trained generative network to demonstrate a novel denoising approach that allows us to train on ambiguous rim cases and substantially increase the minority class. We show that both synthetic lesion synthesis and our proposed rim lesion label denoising method best approximate the unseen rim lesion distribution and improve detection in a clinically interpretable manner. We release our code and generated data at this https URL upon publication.', 'abstract_zh': '从磁共振图像中生成的定量 susceptibility 图map 在多发性硬化症的预后和诊断中提供信息，多发性硬化症是一种以白质脑组织中形成病灶为特征的神经退行性疾病。特别是，susceptibility 图map 提供了足够的对比度来区分由沉积的顺磁性铁围成的“边缘”病灶和“非边缘”病灶类型。顺磁性边缘病灶（PRLs）是多发性硬化症中新兴的生物标志物。人们致力于检测和分割此类病灶以监控纵向变化。由于顺磁性边缘病灶罕见，解决此问题需要解决边缘病灶和非边缘病灶之间的类别不平衡。我们生成了顺磁性边缘病灶的合成定量 susceptibility 图map，并展示了这些合成数据的纳入可以提高分类器性能，并提供多通道扩展以生成相应的对比图和概率分割图。我们利用我们训练的生成网络的投影能力，提出了一种新颖的去噪方法，该方法允许我们在模糊的边缘病灶案例上进行训练，从而显著增加少数类。我们证明，无论是合成病灶生成还是我们提出的边缘病灶标签去噪方法，都能最好地逼近未见的边缘病灶分布，并以临床可解释的方式改善检测。我们在发布时在该网址https:// 提供我们的代码和生成数据。', 'title_zh': 'Multiple Sclerosis中缘区病变的合成生成与潜空间去噪'}
{'arxiv_id': 'arXiv:2505.23337', 'title': 'Matryoshka Model Learning for Improved Elastic Student Models', 'authors': 'Chetan Verma, Aditya Srinivas Timmaraju, Cho Jui-Hsieh, Suyash Damle, Ngot Bui, Yang Zhang, Wen Chen, Xin Liu, Prateek Jain, Inderjit S Dhillon', 'link': 'https://arxiv.org/abs/2505.23337', 'abstract': 'Industry-grade ML models are carefully designed to meet rapidly evolving serving constraints, which requires significant resources for model development. In this paper, we propose MatTA, a framework for training multiple accurate Student models using a novel Teacher-TA-Student recipe. TA models are larger versions of the Student models with higher capacity, and thus allow Student models to better relate to the Teacher model and also bring in more domain-specific expertise. Furthermore, multiple accurate Student models can be extracted from the TA model. Therefore, despite only one training run, our methodology provides multiple servable options to trade off accuracy for lower serving cost. We demonstrate the proposed method, MatTA, on proprietary datasets and models. Its practical efficacy is underscored by live A/B tests within a production ML system, demonstrating 20% improvement on a key metric. We also demonstrate our method on GPT-2 Medium, a public model, and achieve relative improvements of over 24% on SAT Math and over 10% on the LAMBADA benchmark.', 'abstract_zh': '基于工业标准的机器学习模型旨在满足快速变化的服务约束，这需要大量的资源进行模型开发。本文提出了一种名为MatTA的框架，利用新颖的Teacher-TA-Student配方训练多个准确的学生模型。TA模型是学生模型的扩展版本，具有更高的容量，使得学生模型能够更好地与教师模型相关，并引入更多特定领域的专业知识。此外，可以从TA模型中提取出多个准确的学生模型。因此，尽管只进行了一次训练运行，我们的方法仍提供了多种可部署选项，以在准确性与较低的服务成本之间进行权衡。我们在自有数据集和模型上展示了所提出的方法MatTA，并通过生产机器学习系统中的现场A/B测试，证明了该方法在一个关键指标上提高了20%。我们还在公开的GPT-2 Medium模型上展示了该方法，并在SAT Math和LAMBADA基准测试上分别实现了超过24%和10%的相对性能改进。', 'title_zh': '套娃模型学习以改进弹性学生模型'}
{'arxiv_id': 'arXiv:2505.23315', 'title': 'Enhancing Marker Scoring Accuracy through Ordinal Confidence Modelling in Educational Assessments', 'authors': 'Abhirup Chakravarty, Mark Brenchley, Trevor Breakspear, Ian Lewin, Yan Huang', 'link': 'https://arxiv.org/abs/2505.23315', 'abstract': 'A key ethical challenge in Automated Essay Scoring (AES) is ensuring that scores are only released when they meet high reliability standards. Confidence modelling addresses this by assigning a reliability estimate measure, in the form of a confidence score, to each automated score. In this study, we frame confidence estimation as a classification task: predicting whether an AES-generated score correctly places a candidate in the appropriate CEFR level. While this is a binary decision, we leverage the inherent granularity of the scoring domain in two ways. First, we reformulate the task as an n-ary classification problem using score binning. Second, we introduce a set of novel Kernel Weighted Ordinal Categorical Cross Entropy (KWOCCE) loss functions that incorporate the ordinal structure of CEFR labels. Our best-performing model achieves an F1 score of 0.97, and enables the system to release 47% of scores with 100% CEFR agreement and 99% with at least 95% CEFR agreement -compared to approximately 92% (approx.) CEFR agreement from the standalone AES model where we release all AM predicted scores.', 'abstract_zh': '自动作文评分中关键的伦理挑战之一是确保评分只有在达到高可靠性的标准后才被公布。通过为每个自动化评分分配一个可靠性的估计度量（形式为信心分数）来解决这一问题。在本研究中，我们将信心估计框定为分类任务：预测自动作文评分系统生成的分数是否正确地将考生放置在相应的CEFR水平。虽然这是一个二分类决策，但我们通过两种方式利用评分领域的固有精细度。首先，我们通过分数分箱将任务重新表述为n元分类问题。其次，我们引入了一组新颖的核加权序数分类交叉熵（KWOCCE）损失函数，这些函数结合了CEFR标签的序数结构。我们性能最好的模型实现了F1分数为0.97，并使系统能够公布47%的分数，这些分数在CEFR上达成100%的一致性，99%的一致性至少为95%——相比之下，独立运行的自动作文评分模型仅公布所有AM预测分数时的CEFR一致性约为92%。', 'title_zh': '通过序级置信度建模提升标记评分准确性'}
{'arxiv_id': 'arXiv:2505.23309', 'title': 'Score-based Generative Modeling for Conditional Independence Testing', 'authors': 'Yixin Ren, Chenghou Jin, Yewei Xia, Li Ke, Longtao Huang, Hui Xue, Hao Zhang, Jihong Guan, Shuigeng Zhou', 'link': 'https://arxiv.org/abs/2505.23309', 'abstract': 'Determining conditional independence (CI) relationships between random variables is a fundamental yet challenging task in machine learning and statistics, especially in high-dimensional settings. Existing generative model-based CI testing methods, such as those utilizing generative adversarial networks (GANs), often struggle with undesirable modeling of conditional distributions and training instability, resulting in subpar performance. To address these issues, we propose a novel CI testing method via score-based generative modeling, which achieves precise Type I error control and strong testing power. Concretely, we first employ a sliced conditional score matching scheme to accurately estimate conditional score and use Langevin dynamics conditional sampling to generate null hypothesis samples, ensuring precise Type I error control. Then, we incorporate a goodness-of-fit stage into the method to verify generated samples and enhance interpretability in practice. We theoretically establish the error bound of conditional distributions modeled by score-based generative models and prove the validity of our CI tests. Extensive experiments on both synthetic and real-world datasets show that our method significantly outperforms existing state-of-the-art methods, providing a promising way to revitalize generative model-based CI testing.', 'abstract_zh': '基于评分生成模型的条件独立性检验方法：精确的I型错误控制与强大的测试能力', 'title_zh': '基于评分的生成建模在条件独立性检验中的应用'}
{'arxiv_id': 'arXiv:2505.23292', 'title': 'Federated Unsupervised Semantic Segmentation', 'authors': 'Evangelos Charalampakis, Vasileios Mygdalis, Ioannis Pitas', 'link': 'https://arxiv.org/abs/2505.23292', 'abstract': 'This work explores the application of Federated Learning (FL) in Unsupervised Semantic image Segmentation (USS). Recent USS methods extract pixel-level features using frozen visual foundation models and refine them through self-supervised objectives that encourage semantic grouping. These features are then grouped to semantic clusters to produce segmentation masks. Extending these ideas to federated settings requires feature representation and cluster centroid alignment across distributed clients -- an inherently difficult task under heterogeneous data distributions in the absence of supervision. To address this, we propose FUSS Federated Unsupervised image Semantic Segmentation) which is, to our knowledge, the first framework to enable fully decentralized, label-free semantic segmentation training. FUSS introduces novel federation strategies that promote global consistency in feature and prototype space, jointly optimizing local segmentation heads and shared semantic centroids. Experiments on both benchmark and real-world datasets, including binary and multi-class segmentation tasks, show that FUSS consistently outperforms local-only client trainings as well as extensions of classical FL algorithms under varying client data distributions. To support reproducibility, full code will be released upon manuscript acceptance.', 'abstract_zh': 'FUSS：联邦学习框架下的无监督语义图像分割', 'title_zh': '联邦无监督语义分割'}
{'arxiv_id': 'arXiv:2505.23250', 'title': 'Deep Retrieval at CheckThat! 2025: Identifying Scientific Papers from Implicit Social Media Mentions via Hybrid Retrieval and Re-Ranking', 'authors': 'Pascal J. Sager, Ashwini Kamaraj, Benjamin F. Grewe, Thilo Stadelmann', 'link': 'https://arxiv.org/abs/2505.23250', 'abstract': 'We present the methodology and results of the Deep Retrieval team for subtask 4b of the CLEF CheckThat! 2025 competition, which focuses on retrieving relevant scientific literature for given social media posts. To address this task, we propose a hybrid retrieval pipeline that combines lexical precision, semantic generalization, and deep contextual re-ranking, enabling robust retrieval that bridges the informal-to-formal language gap. Specifically, we combine BM25-based keyword matching with a FAISS vector store using a fine-tuned INF-Retriever-v1 model for dense semantic retrieval. BM25 returns the top 30 candidates, and semantic search yields 100 candidates, which are then merged and re-ranked via a large language model (LLM)-based cross-encoder.\nOur approach achieves a mean reciprocal rank at 5 (MRR@5) of 76.46% on the development set and 66.43% on the hidden test set, securing the 1st position on the development leaderboard and ranking 3rd on the test leaderboard (out of 31 teams), with a relative performance gap of only 2 percentage points compared to the top-ranked system. We achieve this strong performance by running open-source models locally and without external training data, highlighting the effectiveness of a carefully designed and fine-tuned retrieval pipeline.', 'abstract_zh': 'Deep Retrieval队列在CLEF CheckThat! 2025竞赛子任务4b中的方法与结果：基于社交媒体帖子检索相关科学文献', 'title_zh': 'CheckThat! 2025深度检索：通过混合检索与再排序识别科学论文'}
{'arxiv_id': 'arXiv:2505.23239', 'title': 'OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software', 'authors': 'Lingkai Meng, Yu Shao, Long Yuan, Longbin Lai, Peng Cheng, Wenyuan Yu, Wenjie Zhang, Xuemin Lin, Jingren Zhou', 'link': 'https://arxiv.org/abs/2505.23239', 'abstract': "Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.", 'abstract_zh': '开源软件（OSS）的可用性评估对于其影响和采纳至关重要，但传统的依赖人工评估者的方法存在着高成本和有限的可扩展性。为解决这些问题，我们引入了OSS-UAgent，这是一种自动化、可配置且交互式的基于代理的可用性评估框架，专门设计用于开源软件。该框架利用大型语言模型（LLMs）驱动的智能代理，模拟不同经验水平（从初级到专家）的开发者执行编程任务。通过动态构建平台特定的知识库，OSS-UAgent 确保代码生成的准确性和上下文感知性。生成的代码在多个维度上（包括合规性、正确性和可读性）自动评估，提供软件可用性的全面衡量。此外，我们的演示展示了OSS-UAgent 在评估图分析平台中的实际应用，突出了其在自动化可用性评估方面的有效性。', 'title_zh': 'OSS-UAgent：基于代理的开放源代码软件可使用性评估框架'}
{'arxiv_id': 'arXiv:2505.23195', 'title': 'Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning', 'authors': 'Lifan Zhao, Yanyan Shen, Zhaoyang Liu, Xue Wang, Jiaji Deng', 'link': 'https://arxiv.org/abs/2505.23195', 'abstract': 'Scaling laws motivate the development of Time Series Foundation Models (TSFMs) that pre-train vast parameters and achieve remarkable zero-shot forecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot consistently outperform smaller, specialized models trained on full-shot downstream data. A key question is how to realize effective adaptation of TSFMs for a target forecasting task. Through empirical studies on various TSFMs, the pre-trained models often exhibit inherent sparsity and redundancy in computation, suggesting that TSFMs have learned to activate task-relevant network substructures to accommodate diverse forecasting tasks. To preserve this valuable prior knowledge, we propose a structured pruning method to regularize the subsequent fine-tuning process by focusing it on a more relevant and compact parameter space. Extensive experiments on seven TSFMs and six benchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly improves forecasting performance compared to fine-tuning original models. This "prune-then-finetune" paradigm often enables TSFMs to achieve state-of-the-art performance and surpass strong specialized baselines.', 'abstract_zh': '基于Scaling定律的时间序列基础模型（TSFMs）推动了大规模预训练参数的发展，并实现卓越的零样本预测性能。令人惊讶的是，即使经过微调，TSFMs也无法一致地战胜规模较小的下游全监督训练的专业模型。一个关键问题是如何实现TSFMs对目标预测任务的有效适应。通过各种TSFMs的实证研究，预训练模型通常表现出内在的计算稀疏性和冗余性，表明TSFMs已学会激活与多样化预测任务相关的网络子结构。为了保留这些宝贵的先验知识，我们提出了一种结构化剪枝方法，通过聚焦于更相关且紧凑的参数空间来规范化后续的微调过程。在七种TSFMs和六种基准上的广泛实验表明，对较小的剪枝TSFMs进行微调显著提高了预测性能，优于对原始模型进行微调。这种“先剪枝后微调”的范式通常能使TSFMs达到最佳性能并超越强大的专业基线。', 'title_zh': '少即是多：结构化剪枝解锁时间序列基础模型的专业化'}
{'arxiv_id': 'arXiv:2505.23192', 'title': 'Fooling the Watchers: Breaking AIGC Detectors via Semantic Prompt Attacks', 'authors': 'Run Hao, Peng Ying', 'link': 'https://arxiv.org/abs/2505.23192', 'abstract': 'The rise of text-to-image (T2I) models has enabled the synthesis of photorealistic human portraits, raising serious concerns about identity misuse and the robustness of AIGC detectors. In this work, we propose an automated adversarial prompt generation framework that leverages a grammar tree structure and a variant of the Monte Carlo tree search algorithm to systematically explore the semantic prompt space. Our method generates diverse, controllable prompts that consistently evade both open-source and commercial AIGC detectors. Extensive experiments across multiple T2I models validate its effectiveness, and the approach ranked first in a real-world adversarial AIGC detection competition. Beyond attack scenarios, our method can also be used to construct high-quality adversarial datasets, providing valuable resources for training and evaluating more robust AIGC detection and defense systems.', 'abstract_zh': '文本到图像模型的兴起使 photorealistic 人类肖像的合成成为可能，引发了关于身份滥用和 AIGC 检测器 robustness 的严重关切。本文提出了一种自动对抗式提示生成框架，该框架利用语法树结构和蒙特卡洛树搜索算法的变体，系统地探索语义提示空间。该方法生成多样且可控的提示，能够一致地规避开源和商业 AIGC 检测器。在多个文本到图像模型上的广泛实验验证了其有效性，并且该方法在实际的对抗式 AIGC 检测竞赛中排名第一。除了攻击场景之外，该方法还可以用于构建高质量的对抗式数据集，为训练和评估更加 robust 的 AIGC 检测和防御系统提供宝贵资源。', 'title_zh': '愚弄监控者：通过语义提示攻击破解AIGC检测器'}
{'arxiv_id': 'arXiv:2505.23183', 'title': 'Unsupervised Word-level Quality Estimation for Machine Translation Through the Lens of Annotators (Dis)agreement', 'authors': 'Gabriele Sarti, Vilém Zouhar, Malvina Nissim, Arianna Bisazza', 'link': 'https://arxiv.org/abs/2505.23183', 'abstract': 'Word-level quality estimation (WQE) aims to automatically identify fine-grained error spans in machine-translated outputs and has found many uses, including assisting translators during post-editing. Modern WQE techniques are often expensive, involving prompting of large language models or ad-hoc training on large amounts of human-labeled data. In this work, we investigate efficient alternatives exploiting recent advances in language model interpretability and uncertainty quantification to identify translation errors from the inner workings of translation models. In our evaluation spanning 14 metrics across 12 translation directions, we quantify the impact of human label variation on metric performance by using multiple sets of human labels. Our results highlight the untapped potential of unsupervised metrics, the shortcomings of supervised methods when faced with label uncertainty, and the brittleness of single-annotator evaluation practices.', 'abstract_zh': '基于词级的质量估计 (WQE) 的目标是自动识别机器翻译输出中的细粒度错误跨度，并已在翻译后编辑辅助等多种应用中得到应用。现代WQE技术通常成本较高，涉及大型语言模型的提示或对大量人工标注数据进行临时培训。在此工作中，我们探究了利用语言模型可解释性和不确定性量化 Recent Advances 的高效替代方法，以从翻译模型的内部 workings 中识别翻译错误。在对12个翻译方向进行的14项指标评估中，我们通过使用多个人工标注数据集集结算控制了人工标签变化对指标性能的影响。我们的结果突显了无监督指标的未开发潜力、监督方法在面对标签不确定性时的局限性，以及单标注人评估实践的脆弱性。', 'title_zh': '通过注释者（不）一致性的视角进行的机器翻译无监督词级质量估计'}
{'arxiv_id': 'arXiv:2505.23181', 'title': 'FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification', 'authors': 'Tian Tian, Chunyan Miao, Hangwei Qian', 'link': 'https://arxiv.org/abs/2505.23181', 'abstract': 'Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the semantically relevant information of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: global, independent, and compact. To fully utilize the three properties, we propose the lightweight yet effective Frequency Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose semantic-aware Identity Modification and semantic-agnostic Self-adaptive Modification to protect semantically relevant information in the critical frequency components and infuse variance into the unimportant ones respectively. Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets, including UCR and UEA archives, as well as five large-scale datasets on diverse applications. FreRA consistently outperforms ten leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets.', 'abstract_zh': '基于频率域的轻量高效 augmentation 方案：提升时间序列对比学习的下游分类性能', 'title_zh': 'FreRA: 一种用于时间序列分类对比学习的频率细化增强方法'}
{'arxiv_id': 'arXiv:2505.23165', 'title': 'Best Arm Identification with Possibly Biased Offline Data', 'authors': 'Le Yang, Vincent Y. F. Tan, Wang Chi Cheung', 'link': 'https://arxiv.org/abs/2505.23165', 'abstract': 'We study the best arm identification (BAI) problem with potentially biased offline data in the fixed confidence setting, which commonly arises in real-world scenarios such as clinical trials. We prove an impossibility result for adaptive algorithms without prior knowledge of the bias bound between online and offline distributions. To address this, we propose the LUCB-H algorithm, which introduces adaptive confidence bounds by incorporating an auxiliary bias correction to balance offline and online data within the LUCB framework. Theoretical analysis shows that LUCB-H matches the sample complexity of standard LUCB when offline data is misleading and significantly outperforms it when offline data is helpful. We also derive an instance-dependent lower bound that matches the upper bound of LUCB-H in certain scenarios. Numerical experiments further demonstrate the robustness and adaptability of LUCB-H in effectively incorporating offline data.', 'abstract_zh': '带潜在偏差的离线数据在固定置信区间下的最佳臂识别问题及其LUCB-H算法研究', 'title_zh': '带有可能偏倚的离线数据的最佳臂识别'}
{'arxiv_id': 'arXiv:2505.23135', 'title': 'VERINA: Benchmarking Verifiable Code Generation', 'authors': 'Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song', 'link': 'https://arxiv.org/abs/2505.23135', 'abstract': "Large language models (LLMs) are increasingly integrated in software development, but ensuring correctness in LLM-generated code remains challenging and often requires costly manual review. Verifiable code generation -- jointly generating code, specifications, and proofs of code-specification alignment -- offers a promising path to address this limitation and further unleash LLMs' benefits in coding. Yet, there exists a significant gap in evaluation: current benchmarks often lack support for end-to-end verifiable code generation. In this paper, we introduce Verina (Verifiable Code Generation Arena), a high-quality benchmark enabling a comprehensive and modular evaluation of code, specification, and proof generation as well as their compositions. Verina consists of 189 manually curated coding tasks in Lean, with detailed problem descriptions, reference implementations, formal specifications, and extensive test suites. Our extensive evaluation of state-of-the-art LLMs reveals significant challenges in verifiable code generation, especially in proof generation, underscoring the need for improving LLM-based theorem provers in verification domains. The best model, OpenAI o4-mini, generates only 61.4% correct code, 51.0% sound and complete specifications, and 3.6% successful proofs, with one trial per task. We hope Verina will catalyze progress in verifiable code generation by providing a rigorous and comprehensive benchmark. We release our dataset on this https URL and our evaluation code on this https URL.", 'abstract_zh': '可验证代码生成：Large Language Models在软件开发中的可验证代码生成基准', 'title_zh': 'VERINA: 可验证代码生成的基准测试'}
{'arxiv_id': 'arXiv:2505.23132', 'title': 'Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone', 'authors': 'Seung Gyu Jeong, Seong Eun Kim', 'link': 'https://arxiv.org/abs/2505.23132', 'abstract': 'Auscultation is crucial for diagnosing lung diseases. The COVID-19 pandemic has revealed the limitations of traditional, in-person lung sound assessments. To overcome these issues, advancements in digital stethoscopes and artificial intelligence (AI) have led to the development of new diagnostic methods. In this context, our study aims to use smartphone microphones to record and analyze lung sounds. We faced two major challenges: the difference in audio style between electronic stethoscopes and smartphone microphones, and the variability among patients. To address these challenges, we developed a method called Patient Domain Supervised Contrastive Learning (PD-SCL). By integrating this method with the Audio Spectrogram Transformer (AST) model, we significantly improved its performance by 2.4\\% compared to the original AST model. This progress demonstrates that smartphones can effectively diagnose lung sounds, addressing inconsistencies in patient data and showing potential for broad use beyond traditional clinical settings. Our research contributes to making lung disease detection more accessible in the post-COVID-19 world.', 'abstract_zh': '听诊对于诊断肺部疾病至关重要。COVID-19疫情揭示了传统面对面肺音评估的限制。为克服这些问题，数字听诊器和人工智能的进步推动了新型诊断方法的发展。在此背景下，本研究旨在利用智能手机麦克风记录和分析肺音。我们面临两大挑战：电子听诊器与智能手机麦克风之间的音频风格差异，以及患者之间的变异。为应对这些挑战，我们开发了一种称为患者域监督对比学习（PD-SCL）的方法。通过将该方法与音频频谱变换器（Audio Spectrogram Transformer，AST）模型结合，我们将其性能提高了2.4%。这一进展表明，智能手机可以有效地诊断肺音，解决患者数据不一致的问题，并展现出在传统临床环境之外广泛使用的潜力。我们的研究为后 COVID-19 世界中的肺部疾病检测提供了更多机会。', 'title_zh': '基于患者的领域监督对比学习的手机端肺音分类'}
{'arxiv_id': 'arXiv:2505.23121', 'title': 'ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations', 'authors': 'Yiming Lei, Zhizheng Yang, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang', 'link': 'https://arxiv.org/abs/2505.23121', 'abstract': 'Multi-modal large language models have demonstrated remarkable zero-shot abilities and powerful image-understanding capabilities. However, the existing open-source multi-modal models suffer from the weak capability of multi-turn interaction, especially for long contexts. To address the issue, we first introduce a context modeling module, termed ContextQFormer, which utilizes a memory block to enhance the presentation of contextual information. Furthermore, to facilitate further research, we carefully build a new multi-turn multi-modal dialogue dataset (TMDialog) for pre-training, instruction-tuning, and evaluation, which will be open-sourced lately. Compared with other multi-modal dialogue datasets, TMDialog contains longer conversations, which supports the research of multi-turn multi-modal dialogue. In addition, ContextQFormer is compared with three baselines on TMDialog and experimental results illustrate that ContextQFormer achieves an improvement of 2%-4% in available rate over baselines.', 'abstract_zh': '多模态大语言模型展示了卓越的零-shot能力和强大的图像理解能力。然而，现有的开源多模态模型在多轮交互能力上较弱，尤其是对于长上下文的处理。为解决这一问题，我们首先引入了一个上下文建模模块，称为ContextQFormer，该模块利用记忆块增强上下文信息的呈现。此外，为了促进进一步研究，我们精心构建了一个新的多轮多模态对话数据集（TMDialog），用于预训练、指令调优和评估，并将在近期开源。与现有的其他多模态对话数据集相比，TMDialog包含更长的对话，支持多轮多模态对话的研究。另外，我们在TMDialog上将ContextQFormer与三个基线进行了比较，实验结果表明，ContextQFormer在可用率上比基线提高了2%-4%。', 'title_zh': 'ContextQFormer: 一种新的多轮多模态对话上下文建模方法'}
{'arxiv_id': 'arXiv:2505.23118', 'title': 'Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios', 'authors': 'Linjie Mu, Zhongzhen Huang, Yakun Zhu, Xiangyu Zhao, Shaoting Zhang, Xiaofan Zhang', 'link': 'https://arxiv.org/abs/2505.23118', 'abstract': "Effective clinical decision-making depends on iterative, multimodal reasoning across diverse sources of evidence. The recent emergence of multimodal reasoning models has significantly transformed the landscape of solving complex tasks. Although such models have achieved notable success in mathematics and science, their application to medical domains remains underexplored. In this work, we propose \\textit{MedE$^2$}, a two-stage post-training pipeline that elicits and then enhances multimodal reasoning for medical domains. In Stage-I, we fine-tune models using 2,000 text-only data samples containing precisely orchestrated reasoning demonstrations to elicit reasoning behaviors. In Stage-II, we further enhance the model's reasoning capabilities using 1,500 rigorously curated multimodal medical cases, aligning model reasoning outputs with our proposed multimodal medical reasoning preference. Extensive experiments demonstrate the efficacy and reliability of \\textit{MedE$^2$} in improving the reasoning performance of medical multimodal models. Notably, models trained with \\textit{MedE$^2$} consistently outperform baselines across multiple medical multimodal benchmarks. Additional validation on larger models and under inference-time scaling further confirms the robustness and practical utility of our approach.", 'abstract_zh': '有效的临床决策依赖于跨多样证据源进行迭代的多模态推理。近期出现的多模态推理模型显著改变了解决复杂任务的格局。尽管此类模型在数学和科学领域取得了显著成功，但其在医疗领域的应用仍然未被充分探索。在本文中，我们提出了一种名为MedE$^2$的两阶段后训练管道，用于激发并增强医疗领域的多模态推理能力。在第一阶段，我们使用包含精准推理示例的2,000个纯文本数据样本微调模型以激发推理行为。在第二阶段，我们进一步使用1,500个严格筛选的多模态医疗案例增强模型的推理能力，使模型输出与我们提出的多模态医疗推理偏好相匹配。广泛的经验表明，MedE$^2$在提升医疗多模态模型推理性能方面具备有效性和可靠性。值得注意的是，使用MedE$^2$训练的模型在多个医疗多模态基准测试中均优于基线模型。对更大模型的额外验证并在推理时间尺度下进一步确认了我们方法的鲁棒性和实用性。', 'title_zh': '诱发与增强：推进医疗场景中的多模态推理'}
{'arxiv_id': 'arXiv:2505.23117', 'title': 'Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking', 'authors': 'Yuatyong Chaichana, Thanapat Trachu, Peerat Limkonchotiwat, Konpat Preechakul, Tirasan Khandhawit, Ekapol Chuangsuwanich', 'link': 'https://arxiv.org/abs/2505.23117', 'abstract': "In the era of large-scale training, model merging has evolved into a tool for creating multitasking models efficiently. It enables the knowledge of models to be fused, without the need for heavy computation as required in traditional multitask learning. Existing merging methods often assume that entries at identical positions in weight matrices serve the same function, enabling straightforward entry-wise comparison and merging. However, this assumption overlooks the complexity of finetuned neural networks, where neurons may develop distinct feature compositions, making direct entry-wise merging problematic. We present Decom-Renorm-Merge (DRM), a simple yet effective approach that leverages Singular Value Decomposition to decompose and coordinate weight matrices into an aligned joint space, where entry-wise merging becomes possible. We showcase the effectiveness of DRM across various settings ranging from smaller encoder-based such as ViT and DeBERTa, encoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B. Our experimental results show that DRM outperforms several state-of-the-art merging techniques across full finetuning and low-rank adaptation settings. Moreover, our analysis reveals renormalization as the crucial component for creating a robust and even joint space for merging, significantly contributing to the method's performance.", 'abstract_zh': '大规模训练时代的模型合并：Decom-Renorm-Merge（DRM）方法的研究', 'title_zh': 'Decom-Renorm-Merge: 在正确空间进行模型合并可提升多任务学习'}
{'arxiv_id': 'arXiv:2505.23116', 'title': 'CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables', 'authors': 'Pengfei Zhou, Yunlong Liu, Junli Liang, Qi Song, Xiangyang Li', 'link': 'https://arxiv.org/abs/2505.23116', 'abstract': 'Time series forecasting with exogenous variables is a critical emerging paradigm that presents unique challenges in modeling dependencies between variables. Traditional models often struggle to differentiate between endogenous and exogenous variables, leading to inefficiencies and overfitting. In this paper, we introduce CrossLinear, a novel Linear-based forecasting model that addresses these challenges by incorporating a plug-and-play cross-correlation embedding module. This lightweight module captures the dependencies between variables with minimal computational cost and seamlessly integrates into existing neural networks. Specifically, it captures time-invariant and direct variable dependencies while disregarding time-varying or indirect dependencies, thereby mitigating the risk of overfitting in dependency modeling and contributing to consistent performance improvements. Furthermore, CrossLinear employs patch-wise processing and a global linear head to effectively capture both short-term and long-term temporal dependencies, further improving its forecasting precision. Extensive experiments on 12 real-world datasets demonstrate that CrossLinear achieves superior performance in both short-term and long-term forecasting tasks. The ablation study underscores the effectiveness of the cross-correlation embedding module. Additionally, the generalizability of this module makes it a valuable plug-in for various forecasting tasks across different domains. Codes are available at this https URL.', 'abstract_zh': '基于外生变量的时间序列 Forecasting: 一种引入交叉相关嵌入模块的新型线性预测模型', 'title_zh': 'CrossLinear: 插即用的跨相关嵌入方法用于含外生变量的时间序列预测'}
{'arxiv_id': 'arXiv:2505.23107', 'title': 'EAD: An EEG Adapter for Automated Classification', 'authors': 'Pushapdeep Singh, Jyoti Nigam, Medicherla Vamsi Krishna, Arnav Bhavsar, Aditya Nigam', 'link': 'https://arxiv.org/abs/2505.23107', 'abstract': 'While electroencephalography (EEG) has been a popular modality for neural decoding, it often involves task specific acquisition of the EEG data. This poses challenges for the development of a unified pipeline to learn embeddings for various EEG signal classification, which is often involved in various decoding tasks. Traditionally, EEG classification involves the step of signal preprocessing and the use of deep learning techniques, which are highly dependent on the number of EEG channels in each sample. However, the same pipeline cannot be applied even if the EEG data is collected for the same experiment but with different acquisition devices. This necessitates the development of a framework for learning EEG embeddings, which could be highly beneficial for tasks involving multiple EEG samples for the same task but with varying numbers of EEG channels. In this work, we propose EEG Adapter (EAD), a flexible framework compatible with any signal acquisition device. More specifically, we leverage a recent EEG foundational model with significant adaptations to learn robust representations from the EEG data for the classification task. We evaluate EAD on two publicly available datasets achieving state-of-the-art accuracies 99.33% and 92.31% on EEG-ImageNet and BrainLat respectively. This illustrates the effectiveness of the proposed framework across diverse EEG datasets containing two different perception tasks: stimulus and resting-state EEG signals. We also perform zero-shot EEG classification on EEG-ImageNet task to demonstrate the generalization capability of the proposed approach.', 'abstract_zh': '虽然脑电图（EEG）一直是神经解码的流行模态，但通常需要针对特定任务来获取EEG数据。这为开发一个统一的管道来学习用于各种EEG信号分类的嵌入式表示带来了挑战，这类分类通常涉及多种解码任务。传统上，EEG分类包括信号预处理步骤和使用深度学习技术，这些技术高度依赖于每个样本中的EEG通道数量。然而，即使EEG数据是在相同的实验中通过不同采集设备收集的，也无法应用相同的管道。这促使人们开发一个学习EEG嵌入的框架，该框架对于涉及同一任务但EEG通道数量不同的多个EEG样本来说将非常有益。在本工作中，我们提出EEG适配器（EAD），这是一个兼容任何信号采集设备的灵活框架。具体而言，我们利用一个近期的EEG基础模型并进行重大改编，以从EEG数据中学习稳健的表示用于分类任务。我们在两个公开的数据集上评估了EAD，分别在EEG-ImageNet和BrainLat上达到了最先进的准确率99.33%和92.31%。这展示了所提出框架在包含两种不同感知任务（刺激和静息状态EEG信号）的多样化EEG数据集上的有效性。我们还对EEG-ImageNet任务执行零样本EEG分类，以展示所提出方法的泛化能力。', 'title_zh': 'EAD：一种用于自动化分类的脑电图适配器'}
{'arxiv_id': 'arXiv:2505.23086', 'title': 'Equivariant Spherical Transformer for Efficient Molecular Modeling', 'authors': 'Junyi An, Xinyu Lu, Chao Qu, Yunfei Shi, Peijia Lin, Qianwei Tang, Licheng Xu, Fenglei Cao, Yuan Qi', 'link': 'https://arxiv.org/abs/2505.23086', 'abstract': "SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced molecular system modeling by employing group representations. However, their message passing processes, which rely on tensor product-based convolutions, are limited by insufficient non-linearity and incomplete group representations, thereby restricting expressiveness. To overcome these limitations, we introduce the Equivariant Spherical Transformer (EST), a novel framework that leverages a Transformer structure within the spatial domain of group representations after Fourier transform. We theoretically and empirically demonstrate that EST can encompass the function space of tensor products while achieving superior expressiveness. Furthermore, EST's equivariant inductive bias is guaranteed through a uniform sampling strategy for the Fourier transform. Our experiments demonstrate state-of-the-art performance by EST on various molecular benchmarks, including OC20 and QM9.", 'abstract_zh': 'SE(3)-共变图形神经网络（GNNs）通过使用群表示法显著推动了分子系统建模。然而，其依赖于张量积卷积的消息传递过程因非线性不足和不完整的群表示限制了其表达能力。为克服这些限制，我们引入了球变换共变框架（Equivariant Spherical Transformer, EST），该框架在傅里叶变换后的群表示空间域中采用Transformer结构。我们从理论上和实验上证明，EST能够涵盖张量积的功能空间，同时具有更高的表达能力。此外，EST通过傅里叶变换的均匀采样策略保证了其共变的归纳偏置。我们的实验结果显示，EST在OC20和QM9等多种分子基准测试中达到了最先进的性能。', 'title_zh': '对称球变换器：高效分子建模'}
{'arxiv_id': 'arXiv:2505.23078', 'title': 'Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport', 'authors': 'Yuu Jinnai', 'link': 'https://arxiv.org/abs/2505.23078', 'abstract': 'Document-level text generation tasks are known to be more difficult than sentence-level text generation tasks as they require the understanding of longer context to generate high-quality texts. In this paper, we investigate the adaption of Minimum Bayes Risk (MBR) decoding for document-level text generation tasks. MBR decoding makes use of a utility function to estimate the output with the highest expected utility from a set of candidate outputs. Although MBR decoding is shown to be effective in a wide range of sentence-level text generation tasks, its performance on document-level text generation tasks is limited as many of the utility functions are designed for evaluating the utility of sentences. To this end, we propose MBR-OT, a variant of MBR decoding using Wasserstein distance to compute the utility of a document using a sentence-level utility function. The experimental result shows that the performance of MBR-OT outperforms that of the standard MBR in document-level machine translation, text simplification, and dense image captioning tasks. Our code is available at this https URL', 'abstract_zh': '文档级文本生成任务的知识比句子级文本生成任务更复杂，因为它们需要理解更长的上下文以生成高质量的文本。本文研究了最小贝叶斯风险(MBR)解码在文档级文本生成任务中的适应性。MBR解码利用一个效用函数来估计从一组候选输出中具有最高期望效用的输出。尽管MBR解码在广泛的句子级文本生成任务中表现出效用，但在文档级文本生成任务中的性能受限，因为许多效用函数是为评估句子的效用而设计的。为此，我们提出了一种新的MBR-OT变体，该变体使用Wasserstein距离通过句子级效用函数计算文档的效用。实验结果表明，MBR-OT在文档级机器翻译、文本简化和密集图像字幕任务中的性能优于标准的MBR。我们的代码可在以下链接获取：this https URL', 'title_zh': '基于最优传输的最小贝叶斯风险解码的文档级文本生成'}
{'arxiv_id': 'arXiv:2505.23066', 'title': 'Efficient Quantum Approximate $k$NN Algorithm via Granular-Ball Computing', 'authors': 'Shuyin Xia, Xiaojiang Tian, Suzhen Yuan, Jeremiah D. Deng', 'link': 'https://arxiv.org/abs/2505.23066', 'abstract': 'High time complexity is one of the biggest challenges faced by $k$-Nearest Neighbors ($k$NN). Although current classical and quantum $k$NN algorithms have made some improvements, they still have a speed bottleneck when facing large amounts of data. To address this issue, we propose an innovative algorithm called Granular-Ball based Quantum $k$NN(GB-Q$k$NN). This approach achieves higher efficiency by first employing granular-balls, which reduces the data size needed to processed. The search process is then accelerated by adopting a Hierarchical Navigable Small World (HNSW) method. Moreover, we optimize the time-consuming steps, such as distance calculation, of the HNSW via quantization, further reducing the time complexity of the construct and search process. By combining the use of granular-balls and quantization of the HNSW method, our approach manages to take advantage of these treatments and significantly reduces the time complexity of the $k$NN-like algorithms, as revealed by a comprehensive complexity analysis.', 'abstract_zh': '基于粒 Balls 的量子 $k$-最近邻算法 (GB-Q$k$NN): 一种高效的时间复杂度优化方法', 'title_zh': '高效粒球计算引导的量子近似$k$NN算法'}
{'arxiv_id': 'arXiv:2505.23062', 'title': 'Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data', 'authors': 'Lingkai Kong, Haichuan Wang, Tonghan Wang, Guojun Xiong, Milind Tambe', 'link': 'https://arxiv.org/abs/2505.23062', 'abstract': 'Incorporating pre-collected offline data from a source environment can significantly improve the sample efficiency of reinforcement learning (RL), but this benefit is often challenged by discrepancies between the transition dynamics of the source and target environments. Existing methods typically address this issue by penalizing or filtering out source transitions in high dynamics-gap regions. However, their estimation of the dynamics gap often relies on KL divergence or mutual information, which can be ill-defined when the source and target dynamics have disjoint support. To overcome these limitations, we propose CompFlow, a method grounded in the theoretical connection between flow matching and optimal transport. Specifically, we model the target dynamics as a conditional flow built upon the output distribution of the source-domain flow, rather than learning it directly from a Gaussian prior. This composite structure offers two key advantages: (1) improved generalization for learning target dynamics, and (2) a principled estimation of the dynamics gap via the Wasserstein distance between source and target transitions. Leveraging our principled estimation of the dynamics gap, we further introduce an optimistic active data collection strategy that prioritizes exploration in regions of high dynamics gap, and theoretically prove that it reduces the performance disparity with the optimal policy. Empirically, CompFlow outperforms strong baselines across several RL benchmarks with shifted dynamics.', 'abstract_zh': '将预先收集的离线数据融入源环境显著提高了强化学习（RL）的样本效率，但这一优势往往受到源环境与目标环境过渡动力学差异的挑战。现有方法通常通过在高动力学差异区域惩罚或过滤源过渡来解决这一问题。然而，它们对动力学差异的估计往往依赖于KL散度或互信息，当源与目标动力学支持区隔时，这些估计可能不明确。为克服这些局限，我们提出了CompFlow方法，该方法基于流匹配与最优传输的理论联系。具体来说，我们将目标动力学建模为基于源域流输出分布的条件流，而不是直接从高斯先前提取。这种复合结构具有两个关键优势：(1) 改进了学习目标动力学的泛化能力；(2) 通过源与目标过渡之间的Wasserstein距离，提供了一种原则性的动力学差异估计。利用我们原则性的动力学差异估计，我们进一步引入了一种乐观的主动数据收集策略，优先探索高动力学差异区域，并从理论上证明该策略减少了与最优策略的性能差距。实验上，CompFlow在多个动力学偏移的RL基准测试中优于强_baseline。', 'title_zh': '复合流匹配用于处理移位动力学数据的强化学习'}
{'arxiv_id': 'arXiv:2505.23032', 'title': 'Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks', 'authors': 'Dongwoo Lee, Dong Bok Lee, Steven Adriaensen, Juho Lee, Sung Ju Hwang, Frank Hutter, Seon Joo Kim, Hae Beom Lee', 'link': 'https://arxiv.org/abs/2505.23032', 'abstract': 'Scaling has been a major driver of recent advancements in deep learning. Numerous empirical studies have found that scaling laws often follow the power-law and proposed several variants of power-law functions to predict the scaling behavior at larger scales. However, existing methods mostly rely on point estimation and do not quantify uncertainty, which is crucial for real-world applications involving decision-making problems such as determining the expected performance improvements achievable by investing additional computational resources. In this work, we explore a Bayesian framework based on Prior-data Fitted Networks (PFNs) for neural scaling law extrapolation. Specifically, we design a prior distribution that enables the sampling of infinitely many synthetic functions resembling real-world neural scaling laws, allowing our PFN to meta-learn the extrapolation. We validate the effectiveness of our approach on real-world neural scaling laws, comparing it against both the existing point estimation methods and Bayesian approaches. Our method demonstrates superior performance, particularly in data-limited scenarios such as Bayesian active learning, underscoring its potential for reliable, uncertainty-aware extrapolation in practical applications.', 'abstract_zh': 'scaling规律基于Prior-data Fitted Networks的贝叶斯框架在深度学习中的扩展研究', 'title_zh': '基于先验匹配网络的贝叶斯神经网络外推定律'}
{'arxiv_id': 'arXiv:2505.23027', 'title': 'Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift', 'authors': 'Minh Nguyen Nhat To, Paul F RWilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul G. Krishnan', 'link': 'https://arxiv.org/abs/2505.23027', 'abstract': 'The subpopulationtion shift, characterized by a disparity in subpopulation distributibetween theween the training and target datasets, can significantly degrade the performance of machine learning models. Current solutions to subpopulation shift involve modifying empirical risk minimization with re-weighting strategies to improve generalization. This strategy relies on assumptions about the number and nature of subpopulations and annotations on group membership, which are unavailable for many real-world datasets. Instead, we propose using an ensemble of diverse classifiers to adaptively capture risk associated with subpopulations. Given a feature extractor network, we replace its standard linear classification layer with a mixture of prototypical classifiers, where each member is trained to classify the data while focusing on different features and samples from other members. In empirical evaluation on nine real-world datasets, covering diverse domains and kinds of subpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often outperforms the prior state-of-the-art in worst-group accuracy. The code is available at this https URL', 'abstract_zh': '子种群偏移导致训练集与目标集子种群分布差异，显著降低了机器学习模型的性能。针对子种群偏移的现有解决方案通过重新加权策略修改经验风险最小化，以提高泛化能力。该策略依赖于对子种群数量和性质的假设以及组成员身份的标注，而这些信息在许多真实世界的数据集中不可用。相反，我们提出使用多样化的分类器集合，以适应性地捕捉与子种群相关的风险。给定一个特征提取网络，我们将其标准的线性分类层替换为一种原型分类器的混合模型，其中每个成员都训练以分类数据并专注于不同的特征和样本。在涵盖不同领域和种类的子种群偏移的九个真实世界数据集上的实证评估中，我们所提出的方法Diverse Prototypical Ensembles (DPEs) 经常在最差组准确率方面优于之前的最佳方法。代码见此链接：https://xxx/', 'title_zh': '多样原型集成提高子人群转移鲁棒性'}
{'arxiv_id': 'arXiv:2505.23017', 'title': '$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting', 'authors': 'Xingjian Wu, Xiangfei Qiu, Hongfan Gao, Jilin Hu, Bin Yang, Chenjuan Guo', 'link': 'https://arxiv.org/abs/2505.23017', 'abstract': 'Probabilistic Time Series Forecasting (PTSF) plays a crucial role in decision-making across various fields, including economics, energy, and transportation. Most existing methods excell at short-term forecasting, while overlooking the hurdles of Long-term Probabilistic Time Series Forecasting (LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have a significant adverse effect on prediction accuracy, and make generative models inefficient by increasing the cost of each iteration. To overcome these limitations, we introduce $K^2$VAE, an efficient VAE-based generative model that leverages a KoopmanNet to transform nonlinear time series into a linear dynamical system, and devises a KalmanNet to refine predictions and model uncertainty in such linear system, which reduces error accumulation in long-term forecasting. Extensive experiments demonstrate that $K^2$VAE outperforms state-of-the-art methods in both short- and long-term PTSF, providing a more efficient and accurate solution.', 'abstract_zh': '概率时间序列预测（PTSF）在经济学、能源和交通等多个领域中起着至关重要的作用。大多数现有的方法在短期预测方面表现出色，但忽视了长期概率时间序列预测（LPTSF）的挑战。随着预测 horizon 的延长，内在的非线性动态对预测准确性产生了显著的负面影响，并且使得生成模型变得低效，因为每次迭代的成本都在增加。为克服这些限制，我们引入了 $K^2$VAE，这是一种基于 VAE 的高效生成模型，利用 KoopmanNet 将非线性时间序列转换为线性动态系统，并设计 KalmanNet 来改进对该线性系统的预测并建模不确定性，从而减少长期预测中的误差累积。广泛的经验验证表明，$K^2$VAE 在短期和长期 PTSF 方面都优于现有最先进的方法，提供了一种更高效和准确的解决方案。', 'title_zh': '$K^2$VAE：增强卡尔曼-科普曼变异自动编码器在概率时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2505.23008', 'title': 'Synthetic Document Question Answering in Hungarian', 'authors': 'Jonathan Li, Zoltan Csaki, Nidhi Hiremath, Etash Guha, Fenglu Hong, Edward Ma, Urmish Thakker', 'link': 'https://arxiv.org/abs/2505.23008', 'abstract': 'Modern VLMs have achieved near-saturation accuracy in English document visual question-answering (VQA). However, this task remains challenging in lower resource languages due to a dearth of suitable training and evaluation data. In this paper we present scalable methods for curating such datasets by focusing on Hungarian, approximately the 17th highest resource language on the internet. Specifically, we present HuDocVQA and HuDocVQA-manual, document VQA datasets that modern VLMs significantly underperform on compared to English DocVQA. HuDocVQA-manual is a small manually curated dataset based on Hungarian documents from Common Crawl, while HuDocVQA is a larger synthetically generated VQA data set from the same source. We apply multiple rounds of quality filtering and deduplication to HuDocVQA in order to match human-level quality in this dataset. We also present HuCCPDF, a dataset of 117k pages from Hungarian Common Crawl PDFs along with their transcriptions, which can be used for training a model for Hungarian OCR. To validate the quality of our datasets, we show how finetuning on a mixture of these datasets can improve accuracy on HuDocVQA for Llama 3.2 11B Instruct by +7.2%. Our datasets and code will be released to the public to foster further research in multilingual DocVQA.', 'abstract_zh': '现代VLMs在英语文档视觉问答(VQA)任务中已接近饱和准确率。然而，由于缺乏合适的训练和评估数据，这一任务对于低资源语言仍然具有挑战性。本文介绍了针对匈牙利语（互联网上约第17位资源语言）的大规模数据集编纂方法。具体而言，我们提出了HuDocVQA和HuDocVQA-manual文档VQA数据集，与英语DocVQA相比，现代VLMs在这些数据集上的表现显著较差。HuDocVQA-manual基于Common Crawl中的手动编纂小型匈牙利文档数据集，而HuDocVQA是从相同来源生成的较大规模合成VQA数据集。我们对HuDocVQA进行多轮质量过滤和去重，以匹配该数据集的人类水平质量。我们还介绍了包含来自匈牙利Common Crawl PDF的11.7万页及其转录的HuCCPDF数据集，可用于训练匈牙利OCR模型。为了验证数据集的质量，我们展示了这些数据集的混合微调可以提高Llama 3.2 11B Instruct在HuDocVQA上的准确性，提高7.2%。我们的数据集和代码将对外开放，以促进多语言DocVQA的进一步研究。', 'title_zh': '合成文档问答系统在匈牙利语中的应用'}
{'arxiv_id': 'arXiv:2505.23003', 'title': 'Hybrid Cross-domain Robust Reinforcement Learning', 'authors': 'Linh Le Pham Van, Minh Hoang Nguyen, Hung Le, Hung The Tran, Sunil Gupta', 'link': 'https://arxiv.org/abs/2505.23003', 'abstract': "Robust reinforcement learning (RL) aims to learn policies that remain effective despite uncertainties in its environment, which frequently arise in real-world applications due to variations in environment dynamics. The robust RL methods learn a robust policy by maximizing value under the worst-case models within a predefined uncertainty set. Offline robust RL algorithms are particularly promising in scenarios where only a fixed dataset is available and new data cannot be collected. However, these approaches often require extensive offline data, and gathering such datasets for specific tasks in specific environments can be both costly and time-consuming. Using an imperfect simulator offers a faster, cheaper, and safer way to collect data for training, but it can suffer from dynamics mismatch. In this paper, we introduce HYDRO, the first Hybrid Cross-Domain Robust RL framework designed to address these challenges. HYDRO utilizes an online simulator to complement the limited amount of offline datasets in the non-trivial context of robust RL. By measuring and minimizing performance gaps between the simulator and the worst-case models in the uncertainty set, HYDRO employs novel uncertainty filtering and prioritized sampling to select the most relevant and reliable simulator samples. Our extensive experiments demonstrate HYDRO's superior performance over existing methods across various tasks, underscoring its potential to improve sample efficiency in offline robust RL.", 'abstract_zh': '稳健强化学习：HYDRO——跨域的混合稳健强化学习框架', 'title_zh': '跨域混合鲁棒强化学习'}
{'arxiv_id': 'arXiv:2505.22993', 'title': 'Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation', 'authors': 'Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui', 'link': 'https://arxiv.org/abs/2505.22993', 'abstract': 'Claim verification is a long-standing and challenging task that demands not only high accuracy but also explainability of the verification process. This task becomes an emerging research issue in the era of large language models (LLMs) since real-world claims are often complex, featuring intricate semantic structures or obfuscated entities. Traditional approaches typically address this by decomposing claims into sub-claims and querying a knowledge base to resolve hidden or ambiguous entities. However, the absence of effective disambiguation strategies for these entities can compromise the entire verification process. To address these challenges, we propose Verify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and comprehension abilities of LLM agents. VeGraph operates in three phases: (1) Graph Representation - an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information; (2) Entity Disambiguation -VeGraph iteratively interacts with the knowledge base to resolve ambiguous entities within the graph for deeper sub-claim verification; and (3) Verification - remaining triplets are verified to complete the fact-checking process. Experiments using Meta-Llama-3-70B (instruct version) show that VeGraph achieves competitive performance compared to baselines on two benchmarks HoVer and FEVEROUS, effectively addressing claim verification challenges. Our source code and data are available for further exploitation.', 'abstract_zh': 'Claim验证是一项长期且具有挑战性的任务，不仅要求高精度，还需要解释验证过程。随着大规模语言模型（LLMs）时代的到来，这一任务成为新兴的研究问题，因为实际的声明往往很复杂，包含复杂的语义结构或晦涩的实体。传统的做法通常通过将声明分解为子声明并查询知识库来解决隐藏或模糊的实体。然而，缺乏有效的消歧策略可能会破坏整个验证过程。为应对这些挑战，我们提出了基于图的验证（VeGraph）框架，该框架利用LLM代理的推理和理解能力。VeGraph分为三个阶段：（1）图表示 - 输入声明被分解为结构化的三元组，形成一种基于图的表示，整合了结构化和非结构化信息；（2）实体消歧 - VeGraph 通过迭代与知识库交互来解决图中的模糊实体，以进行更深层次的子声明验证；（3）验证 - 剩余的三元组被验证以完成事实核查过程。使用Meta-Llama-3-70B（指令版本）进行的实验表明，VeGraph 在两个基准 HoVer 和 FEVEROUS 上实现了竞争力的性能，有效解决了声明验证的挑战。我们的源代码和数据可供进一步利用。', 'title_zh': '图中验证：面向复杂声明验证的交互式图表示实体消歧改进'}
{'arxiv_id': 'arXiv:2505.22985', 'title': 'Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition', 'authors': 'Masaharu Kagiyama, Tsuyoshi Okita', 'link': 'https://arxiv.org/abs/2505.22985', 'abstract': 'This paper aims to develop an energy-efficient classifier for time-series data by introducing PatchEchoClassifier, a novel model that leverages a reservoir-based mechanism known as the Echo State Network (ESN). The model is designed for human activity recognition (HAR) using one-dimensional sensor signals and incorporates a tokenizer to extract patch-level representations. To train the model efficiently, we propose a knowledge distillation framework that transfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight reservoir-based student model. Experimental evaluations on multiple HAR datasets demonstrate that our model achieves over 80 percent accuracy while significantly reducing computational cost. Notably, PatchEchoClassifier requires only about one-sixth of the floating point operations (FLOPS) compared to DeepConvLSTM, a widely used convolutional baseline. These results suggest that PatchEchoClassifier is a promising solution for real-time and energy-efficient human activity recognition in edge computing environments.', 'abstract_zh': '本文旨在通过引入PatchEchoClassifier新型模型来开发一种高效的时间序列数据分类器，该模型利用一种名为回声状态网络（ESN）的水库机制。该模型针对一维传感器信号的人体活动识别（HAR）进行设计，并融合了分词器以提取基于片段的表示。为了高效训练模型，我们提出了一种知识蒸馏框架，将高容量MLP-Mixer教师模型的知识转移到轻量级的ESN学生模型上。在多个HAR数据集上的实验评估表明，我们的模型能够实现超过80%的准确率，同时显著降低计算成本。值得注意的是，PatchEchoClassifier所需的浮点运算（FLOPS）数量仅为DeepConvLSTM（广泛使用的卷积基线）的六分之一。这些结果表明，PatchEchoClassifier是边缘计算环境中实时和高效的人体活动识别的一种有前景的解决方案。', 'title_zh': '基于水库模型的分类器知识蒸馏：人体活动识别'}
{'arxiv_id': 'arXiv:2505.22973', 'title': 'EquiReg: Equivariance Regularized Diffusion for Inverse Problems', 'authors': 'Bahareh Tolooshams, Aditi Chandrashekar, Rayhan Zirvi, Abbas Mammadov, Jiachen Yao, Chuwei Wang, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2505.22973', 'abstract': 'Diffusion models represent the state-of-the-art for solving inverse problems such as image restoration tasks. In the Bayesian framework, diffusion-based inverse solvers incorporate a likelihood term to guide the prior sampling process, generating data consistent with the posterior distribution. However, due to the intractability of the likelihood term, many current methods rely on isotropic Gaussian approximations, which lead to deviations from the data manifold and result in inconsistent, unstable reconstructions. We propose Equivariance Regularized (EquiReg) diffusion, a general framework for regularizing posterior sampling in diffusion-based inverse problem solvers. EquiReg enhances reconstructions by reweighting diffusion trajectories and penalizing those that deviate from the data manifold. We define a new distribution-dependent equivariance error, empirically identify functions that exhibit low error for on-manifold samples and higher error for off-manifold samples, and leverage these functions to regularize the diffusion sampling process. When applied to a variety of solvers, EquiReg outperforms state-of-the-art diffusion models in both linear and nonlinear image restoration tasks, as well as in reconstructing partial differential equations.', 'abstract_zh': '基于扩散的逆问题求解中的同胚正则化（EquiReg）方法：一种正则化扩散模型后验采样的通用框架', 'title_zh': '等变正则化的扩散模型用于逆问题'}
{'arxiv_id': 'arXiv:2505.22964', 'title': 'Exploring Scaling Laws for EHR Foundation Models', 'authors': 'Sheng Zhang, Qin Liu, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon', 'link': 'https://arxiv.org/abs/2505.22964', 'abstract': 'The emergence of scaling laws has profoundly shaped the development of large language models (LLMs), enabling predictable performance gains through systematic increases in model size, dataset volume, and compute. Yet, these principles remain largely unexplored in the context of electronic health records (EHRs) -- a rich, sequential, and globally abundant data source that differs structurally from natural language. In this work, we present the first empirical investigation of scaling laws for EHR foundation models. By training transformer architectures on patient timeline data from the MIMIC-IV database across varying model sizes and compute budgets, we identify consistent scaling patterns, including parabolic IsoFLOPs curves and power-law relationships between compute, model parameters, data size, and clinical utility. These findings demonstrate that EHR models exhibit scaling behavior analogous to LLMs, offering predictive insights into resource-efficient training strategies. Our results lay the groundwork for developing powerful EHR foundation models capable of transforming clinical prediction tasks and advancing personalized healthcare.', 'abstract_zh': '电子健康记录（EHR）基础模型的标度律研究：从大规模语言模型中汲取经验', 'title_zh': '探索电子健康记录基础模型的扩展规律'}
{'arxiv_id': 'arXiv:2505.22909', 'title': 'Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents', 'authors': 'Cristian Chica, Yinglong Guo, Gilad Lerman', 'link': 'https://arxiv.org/abs/2505.22909', 'abstract': 'There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.', 'abstract_zh': '无限重复博弈中$q$学习代理learn supracompetitive价格的首个理论解释', 'title_zh': '基于Q-learning代理的合谋理论研究：学会索取更多'}
{'arxiv_id': 'arXiv:2505.22906', 'title': 'HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding', 'authors': 'Emmanuel Anaya González, Raven Rothkopf, Sorin Lerner, Nadia Polikarpova', 'link': 'https://arxiv.org/abs/2505.22906', 'abstract': 'While AI programming tools hold the promise of increasing programmers\' capabilities and productivity to a remarkable degree, they often exclude users from essential decision-making processes, causing many to effectively "turn off their brains" and over-rely on solutions provided by these systems. These behaviors can have severe consequences in critical domains, like software security. We propose Human-in-the-loop Decoding, a novel interaction technique that allows users to observe and directly influence LLM decisions during code generation, in order to align the model\'s output with their personal requirements. We implement this technique in HiLDe, a code completion assistant that highlights critical decisions made by the LLM and provides local alternatives for the user to explore. In a within-subjects study (N=18) on security-related tasks, we found that HiLDe led participants to generate significantly fewer vulnerabilities and better align code generation with their goals compared to a traditional code completion assistant.', 'abstract_zh': 'AI编程工具虽有潜力大幅提高程序员的能力和 productivity，但往往排除了用户在关键决策过程中的参与，导致许多人 effectively “关闭大脑”，过度依赖这些系统的解决方案。这些行为在软件安全等关键领域可能会造成严重后果。我们提出了一种名为 Human-in-the-loop Decoding 的新型交互技术，允许用户在代码生成过程中观察并直接影响 LLM 的决策，以使模型的输出与用户个人需求一致。我们在 HiLDe 中实现了这一技术，这是一种代码补全助手，突出显示了 LLM 作出的关键决策，并提供了局部替代方案供用户探索。在一项关于安全相关任务的单被试内研究（N=18）中，我们发现 HiLDe 使参与者生成的漏洞显著减少，并且更符合用户的目标。', 'title_zh': 'HiLDe：基于人类在环解码的意图代码生成'}
{'arxiv_id': 'arXiv:2505.22904', 'title': 'Defining Foundation Models for Computational Science: A Call for Clarity and Rigor', 'authors': 'Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss', 'link': 'https://arxiv.org/abs/2505.22904', 'abstract': 'The widespread success of foundation models in natural language processing and computer vision has inspired researchers to extend the concept to scientific machine learning and computational science. However, this position paper argues that as the term "foundation model" is an evolving concept, its application in computational science is increasingly used without a universally accepted definition, potentially creating confusion and diluting its precise scientific meaning. In this paper, we address this gap by proposing a formal definition of foundation models in computational science, grounded in the core values of generality, reusability, and scalability. We articulate a set of essential and desirable characteristics that such models must exhibit, drawing parallels with traditional foundational methods, like the finite element and finite volume methods. Furthermore, we introduce the Data-Driven Finite Element Method (DD-FEM), a framework that fuses the modular structure of classical FEM with the representational power of data-driven learning. We demonstrate how DD-FEM addresses many of the key challenges in realizing foundation models for computational science, including scalability, adaptability, and physics consistency. By bridging traditional numerical methods with modern AI paradigms, this work provides a rigorous foundation for evaluating and developing novel approaches toward future foundation models in computational science.', 'abstract_zh': '基础模型在计算科学中的正式定义及其应用：从数据驱动有限元方法探索泛化、重用和可扩展性', 'title_zh': '定义计算科学中的基础模型：寻求清晰与严谨'}
{'arxiv_id': 'arXiv:2505.22889', 'title': 'Local Stability and Region of Attraction Analysis for Neural Network Feedback Systems under Positivity Constraints', 'authors': 'Hamidreza Montazeri Hedesh, Moh Kamalul Wafi, Milad Siami', 'link': 'https://arxiv.org/abs/2505.22889', 'abstract': "We study the local stability of nonlinear systems in the Lur'e form with static nonlinear feedback realized by feedforward neural networks (FFNNs). By leveraging positivity system constraints, we employ a localized variant of the Aizerman conjecture, which provides sufficient conditions for exponential stability of trajectories confined to a compact set. Using this foundation, we develop two distinct methods for estimating the Region of Attraction (ROA): (i) a less conservative Lyapunov-based approach that constructs invariant sublevel sets of a quadratic function satisfying a linear matrix inequality (LMI), and (ii) a novel technique for computing tight local sector bounds for FFNNs via layer-wise propagation of linear relaxations. These bounds are integrated into the localized Aizerman framework to certify local exponential stability. Numerical results demonstrate substantial improvements over existing integral quadratic constraint-based approaches in both ROA size and scalability.", 'abstract_zh': "我们研究了静态非线性反馈由前向神经网络（FFNNs）实现的Lur'e形式非线性系统的局部稳定性。通过利用正系统约束，我们采用Aizerman猜想的局部变体，为限制在紧致集内的轨迹的指数稳定性提供了充分条件。基于此基础，我们发展了两种不同的方法来估计吸引域（ROA）：（i）一种较少保守的基于李雅普诺夫的方法，构建二次函数的不变次水平集，满足线性矩阵不等式（LMI）；（ii）通过逐层传播线性放松来计算FFNNs的紧局部扇区界的新技术。这些界值集成到局部化的Aizerman框架中，以验证局部指数稳定性。数值结果表明，与现有的基于积分二次约束的方法相比，在ROA大小和可扩展性方面均实现了显著改进。", 'title_zh': '具有正值约束条件下神经网络反馈系统的地方稳定性和吸引域分析'}
{'arxiv_id': 'arXiv:2505.22866', 'title': 'Scaling Offline RL via Efficient and Expressive Shortcut Models', 'authors': 'Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun', 'link': 'https://arxiv.org/abs/2505.22866', 'abstract': "Diffusion and flow models have emerged as powerful generative approaches capable of modeling diverse and multimodal behavior. However, applying these models to offline reinforcement learning (RL) remains challenging due to the iterative nature of their noise sampling processes, making policy optimization difficult. In this paper, we introduce Scalable Offline Reinforcement Learning (SORL), a new offline RL algorithm that leverages shortcut models - a novel class of generative models - to scale both training and inference. SORL's policy can capture complex data distributions and can be trained simply and efficiently in a one-stage training procedure. At test time, SORL introduces both sequential and parallel inference scaling by using the learned Q-function as a verifier. We demonstrate that SORL achieves strong performance across a range of offline RL tasks and exhibits positive scaling behavior with increased test-time compute. We release the code at this http URL.", 'abstract_zh': '扩散和流模型已成为能够 modeling 多样性和 multimodal 行为的强大力 generative 方法。然而，将这些模型应用于 offline 强化学习（RL）仍具挑战性，因为它们的噪声采样过程具有迭代性，使得策略优化困难。本文我们引入了 Scalable Offline Reinforcement Learning (SORL)，一种新的 offline RL 算法，该算法利用 shortcut 模型——一类新型 generative 模型——来扩展训练和推理。SORL 的策略能够捕捉复杂的数据分布，并且可以在一次训练过程中简单且高效地进行训练。测试时，SORL 通过使用学习到的 Q 函数进行验证，引入了顺序和并行推理扩展。我们展示了 SORL 在多种 offline RL 任务中表现出强劲性能，并且在测试时计算资源增加时表现出积极的扩展行为。代码发布在 this http URL。', 'title_zh': '通过高效且表达能力强的捷径模型扩展 Offline RL'}
{'arxiv_id': 'arXiv:2505.22865', 'title': 'BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models', 'authors': 'Susan Liang, Dejan Markovic, Israel D. Gebru, Steven Krenn, Todd Keebler, Jacob Sandakly, Frank Yu, Samuel Hassel, Chenliang Xu, Alexander Richard', 'link': 'https://arxiv.org/abs/2505.22865', 'abstract': 'Binaural rendering aims to synthesize binaural audio that mimics natural hearing based on a mono audio and the locations of the speaker and listener. Although many methods have been proposed to solve this problem, they struggle with rendering quality and streamable inference. Synthesizing high-quality binaural audio that is indistinguishable from real-world recordings requires precise modeling of binaural cues, room reverb, and ambient sounds. Additionally, real-world applications demand streaming inference. To address these challenges, we propose a flow matching based streaming binaural speech synthesis framework called BinauralFlow. We consider binaural rendering to be a generation problem rather than a regression problem and design a conditional flow matching model to render high-quality audio. Moreover, we design a causal U-Net architecture that estimates the current audio frame solely based on past information to tailor generative models for streaming inference. Finally, we introduce a continuous inference pipeline incorporating streaming STFT/ISTFT operations, a buffer bank, a midpoint solver, and an early skip schedule to improve rendering continuity and speed. Quantitative and qualitative evaluations demonstrate the superiority of our method over SOTA approaches. A perceptual study further reveals that our model is nearly indistinguishable from real-world recordings, with a $42\\%$ confusion rate.', 'abstract_zh': '基于流匹配的流式立体声语音合成框架：BinauralFlow', 'title_zh': 'BinauralFlow：一种基于因果流匹配模型的高保真二元语音合成方法及其流式处理策略'}
{'arxiv_id': 'arXiv:2505.22846', 'title': 'RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation', 'authors': 'Nikita Khramov, Andrei Kozyrev, Gleb Solovev, Anton Podkopaev', 'link': 'https://arxiv.org/abs/2505.22846', 'abstract': "Interactive Theorem Proving was repeatedly shown to be fruitful combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We highlight the importance of thorough premise selection for generating Rocq proofs and propose a novel approach, leveraging retrieval via a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and show the use of multi-agent debate on the planning stage of proof synthesis.", 'abstract_zh': '交互定理证明与生成人工智能的结合屡次显示出其有效性。本文评估了多种Rocq生成方法，并阐明了改进的潜在途径。我们强调了生成Rocq证明时彻底选择前提的重要性，并提出了一种新颖的方法，利用自我注意嵌入模型进行检索。设计方法的评估显示生成器性能相对提高了28%。我们使用一种针对形式验证定制的多阶段代理系统来解决编写Rocq证明的问题，并展示了其高度有效性。我们进行了消融研究，并展示了在证明合成规划阶段使用多代理辩论的应用。', 'title_zh': 'RocqStar: 利用相似性驱动的检索和能动系统进行Rocq生成'}
{'arxiv_id': 'arXiv:2505.22845', 'title': 'Security Benefits and Side Effects of Labeling AI-Generated Images', 'authors': 'Sandra Höltervennhoff, Jonas Ricker, Maike M. Raphael, Charlotte Schwedes, Rebecca Weil, Asja Fischer, Thorsten Holz, Lea Schönherr, Sascha Fahl', 'link': 'https://arxiv.org/abs/2505.22845', 'abstract': "Generative artificial intelligence is developing rapidly, impacting humans' interaction with information and digital media. It is increasingly used to create deceptively realistic misinformation, so lawmakers have imposed regulations requiring the disclosure of AI-generated content. However, only little is known about whether these labels reduce the risks of AI-generated misinformation.\nOur work addresses this research gap. Focusing on AI-generated images, we study the implications of labels, including the possibility of mislabeling. Assuming that simplicity, transparency, and trust are likely to impact the successful adoption of such labels, we first qualitatively explore users' opinions and expectations of AI labeling using five focus groups. Second, we conduct a pre-registered online survey with over 1300 U.S. and EU participants to quantitatively assess the effect of AI labels on users' ability to recognize misinformation containing either human-made or AI-generated images. Our focus groups illustrate that, while participants have concerns about the practical implementation of labeling, they consider it helpful in identifying AI-generated images and avoiding deception. However, considering security benefits, our survey revealed an ambiguous picture, suggesting that users might over-rely on labels. While inaccurate claims supported by labeled AI-generated images were rated less credible than those with unlabeled AI-images, the belief in accurate claims also decreased when accompanied by a labeled AI-generated image. Moreover, we find the undesired side effect that human-made images conveying inaccurate claims were perceived as more credible in the presence of labels.", 'abstract_zh': '生成式人工智能正迅速发展，影响着人类与信息和数字媒体的交互方式。它被日益用于创造误导性且看似真实的虚假信息，因此立法者已制定法规要求披露AI生成的内容。然而，对于这些标签是否能减少AI生成的虚假信息的风险知之甚少。\n我们的工作弥补了这一研究空白。重点关注AI生成的图像，我们研究了标签的潜在影响，包括标签误标的可能性。假设简洁性、透明度和信任度将影响此类标签的采用，我们首先通过五个焦点小组定性探索用户对AI标记的意见和期望。其次，我们进行了预注册的在线问卷调查，涉及超过1300名美国和欧盟的参与者，以定量评估AI标签对用户识别包含人类制作或AI生成图像的虚假信息的能力的影响。我们的焦点小组显示，尽管参与者对标签的实际实施表示担忧，但他们认为标签有助于识别AI生成的图像并避免误导。然而，考虑到安全利益，我们的调查结果显示了一种模糊的图景，表明用户可能过度依赖标签。尽管带有标签的AI生成图像的支持不实声明被认为比无标签的AI图像不那么可信，但当伴随带有标签的AI生成图像时，可信准确声明的信念也会下降。此外，我们发现了一个不希望的副作用：带有标签时，传达不实声明的人类制作图像被认为更具可信度。', 'title_zh': 'AI生成图像标记的安全优势与副作用'}
{'arxiv_id': 'arXiv:2505.22843', 'title': 'Aurora: Are Android Malware Classifiers Reliable under Distribution Shift?', 'authors': 'Alexander Herzog, Aliai Eusebi, Lorenzo Cavallaro', 'link': 'https://arxiv.org/abs/2505.22843', 'abstract': 'The performance figures of modern drift-adaptive malware classifiers appear promising, but does this translate to genuine operational reliability? The standard evaluation paradigm primarily focuses on baseline performance metrics, neglecting confidence-error alignment and operational stability. While TESSERACT established the importance of temporal evaluation, we take a complementary direction by investigating whether malware classifiers maintain reliable confidence estimates under distribution shifts and exploring the tensions between scientific advancement and practical impacts when they do not. We propose AURORA, a framework to evaluate malware classifiers based on their confidence quality and operational resilience. AURORA subjects the confidence profile of a given model to verification to assess the reliability of its estimates. Unreliable confidence estimates erode operational trust, waste valuable annotation budget on non-informative samples for active learning, and leave error-prone instances undetected in selective classification. AURORA is further complemented by a set of metrics designed to go beyond point-in-time performance, striving towards a more holistic assessment of operational stability throughout temporal evaluation periods. The fragility we observe in state-of-the-art frameworks across datasets of varying drift severity suggests the need for a return to the whiteboard.', 'abstract_zh': '现代漂移适应性恶意软件分类器的性能指标看起来很有前景，但这种性能是否转化为实际操作中的可靠性能？标准的评估范式主要关注基线性能指标，忽视了置信度误差的一致性和操作稳定性。虽然TESSERACT确立了时间评价的重要性，我们则采取了补充性的方法，探讨在分布迁移的情况下恶意软件分类器是否能够维持可靠的置信度估计，并探索科学进步与实际影响之间的张力。我们提出了AURORA框架，基于置信度质量和操作弹性来评估恶意软件分类器。AURORA通过对给定模型的置信度概貌进行验证，评估其估计的可靠性。不可靠的置信度估计会削弱操作中的信任度，浪费宝贵的标注预算在非信息性的样本上进行积极学习，并在选择性分类中未能检测到错误实例。AURORA进一步通过设计用于超越单一时间点性能的指标集，力求在时间评价期间实现对操作稳定性更具综合性的评估。我们观察到最先进的框架在不同漂移严重程度数据集上的脆弱性，表明需要回到“白板”重新审视。', 'title_zh': 'aurora: Android恶意软件分类器在分布转移情况下是否可靠？'}
{'arxiv_id': 'arXiv:2505.22839', 'title': 'How Do Diffusion Models Improve Adversarial Robustness?', 'authors': 'Liu Yuezhang, Xue-Xin Wei', 'link': 'https://arxiv.org/abs/2505.22839', 'abstract': "Recent findings suggest that diffusion models significantly enhance empirical adversarial robustness. While some intuitive explanations have been proposed, the precise mechanisms underlying these improvements remain unclear. In this work, we systematically investigate how and how well diffusion models improve adversarial robustness. First, we observe that diffusion models intriguingly increase, rather than decrease, the $\\ell_p$ distance to clean samples--challenging the intuition that purification denoises inputs closer to the original data. Second, we find that the purified images are heavily influenced by the internal randomness of diffusion models, where a compression effect arises within each randomness configuration. Motivated by this observation, we evaluate robustness under fixed randomness and find that the improvement drops to approximately 24% on CIFAR-10--substantially lower than prior reports approaching 70%. Importantly, we show that this remaining robustness gain strongly correlates with the model's ability to compress the input space, revealing the compression rate as a reliable robustness indicator without requiring gradient-based analysis. Our findings provide novel insights into the mechanisms underlying diffusion-based purification, and offer guidance for developing more effective and principled adversarial purification systems.", 'abstract_zh': 'Recent findings suggest that扩散模型显著增强了经验鲁棒性。虽然提出了一些直观解释，但这些改进背后的精确机制仍不清楚。在本工作中，我们系统地探讨了扩散模型如何以及在多大程度上提高对抗鲁棒性。首先，我们发现扩散模型出乎意料地增加了与干净样本之间的$\\ell_p$距离——挑战了净化去噪会使输入更接近原始数据的直观理解。其次，我们发现净化后的图像受到扩散模型内部随机性的严重影响，在每次随机配置中都会出现压缩效应。受此观察启发，我们在固定随机性下评估鲁棒性，并发现CIFAR-10上的改进仅约为24%，显著低于接近70%的先前报告。重要的是，我们展示了这种剩余的鲁棒性增益与模型压缩输入空间的能力之间强烈相关，揭示了压缩率作为不依赖梯度分析的鲁棒性指标的可靠性。我们的发现为基于扩散的净化机制提供了新颖的见解，并为开发更有效和有原则的对抗净化系统提供了指导。', 'title_zh': '扩散模型如何提高对抗robust性？'}
{'arxiv_id': 'arXiv:2505.22831', 'title': 'Orca: Browsing at Scale Through User-Driven and AI-Facilitated Orchestration Across Malleable Webpages', 'authors': 'Peiling Jiang, Haijun Xia', 'link': 'https://arxiv.org/abs/2505.22831', 'abstract': 'Web-based activities are fundamentally distributed across webpages. However, conventional browsers with stacks of tabs fail to support operating and synthesizing large volumes of information across pages. While recent AI systems enable fully automated web browsing and information synthesis, they often diminish user agency and hinder contextual understanding. Therefore, we explore how AI could instead augment users\' interactions with content across webpages and mitigate cognitive and manual efforts. Through literature on information tasks and web browsing challenges, and an iterative design process, we present a rich set of novel interactions with our prototype web browser, Orca. Leveraging AI, Orca supports user-driven exploration, operation, organization, and synthesis of web content at scale. To enable browsing at scale, webpages are treated as malleable materials that humans and AI can collaboratively manipulate and compose into a malleable, dynamic, and browser-level workspace. Our evaluation revealed an increased "appetite" for information foraging, enhanced user control, and more flexibility in sensemaking across a broader information landscape on the web.', 'abstract_zh': '基于Web的活动本质上分布在网页上。然而，传统的浏览器通过标签页堆栈支持的方式无法有效支持在跨页面操作和综合大规模信息。虽然最近的人工智能系统可以实现全自动化网页浏览和信息综合，但往往会削弱用户自主性并妨碍情境理解。因此，我们探索了人工智能如何增强用户在跨网页内容上的互动，并减轻认知和手动努力。通过信息任务和网页浏览挑战的相关文献以及迭代设计过程，我们展示了我们的原型网页浏览器Orca中的一系列新颖交互方式。利用人工智能，Orca支持用户驱动的跨规模浏览、操作、组织和综合网页内容。为了实现大规模浏览，网页被视为人类和人工智能可以协作重塑和组合成可塑性动态浏览器级别工作区的材料。我们的评估显示了增强了信息获取的意愿、提高了用户控制力，并且在更广泛的网络信息环境中提供了更高的解释灵活性。', 'title_zh': 'Orca：通过用户驱动和AI辅助协调跨可塑网页的大规模浏览'}
{'arxiv_id': 'arXiv:2505.22829', 'title': 'Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies', 'authors': 'Chenruo Liu, Kenan Tang, Yao Qin, Qi Lei', 'link': 'https://arxiv.org/abs/2505.22829', 'abstract': 'This paper bridges distribution shift and AI safety through a comprehensive analysis of their conceptual and methodological synergies. While prior discussions often focus on narrow cases or informal analogies, we establish two types connections between specific causes of distribution shift and fine-grained AI safety issues: (1) methods addressing a specific shift type can help achieve corresponding safety goals, or (2) certain shifts and safety issues can be formally reduced to each other, enabling mutual adaptation of their methods. Our findings provide a unified perspective that encourages fundamental integration between distribution shift and AI safety research.', 'abstract_zh': '本文通过全面分析分布转移与AI安全的概念和方法协同作用，架起了二者的桥梁。尽管以往讨论往往集中在狭窄的案例或非正式的类比上，我们建立了两种特定分布转移原因与细粒度AI安全问题之间的连接：（1）针对特定转移类型的方法可以有助于实现相应的安全目标，或（2）某些转移和安全问题可以形式上相互归约，从而使它们的方法能够相互适应。我们的发现提供了一个统一的视角，促进分布转移与AI安全研究的根本整合。', 'title_zh': '弥合分布偏移与AI安全性之间的差距：概念与方法的协同作用'}
{'arxiv_id': 'arXiv:2505.22825', 'title': 'PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow', 'authors': 'Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck', 'link': 'https://arxiv.org/abs/2505.22825', 'abstract': 'Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have recently garnered significant attention, reflecting a broader trend of leveraging ML to approximate and/or accelerate the resolution of complex optimization problems. These developments are necessitated by the increased volatility and scale in energy production for modern and future grids. However, progress in ML for OPF is hindered by the lack of standardized datasets and evaluation metrics, from generating and solving OPF instances, to training and benchmarking machine learning models. To address this challenge, this paper introduces PGLearn, a comprehensive suite of standardized datasets and evaluation tools for ML and OPF. PGLearn provides datasets that are representative of real-life operating conditions, by explicitly capturing both global and local variability in the data generation, and by, for the first time, including time series data for several large-scale systems. In addition, it supports multiple OPF formulations, including AC, DC, and second-order cone formulations. Standardized datasets are made publicly available to democratize access to this field, reduce the burden of data generation, and enable the fair comparison of various methodologies. PGLearn also includes a robust toolkit for training, evaluating, and benchmarking machine learning models for OPF, with the goal of standardizing performance evaluation across the field. By promoting open, standardized datasets and evaluation metrics, PGLearn aims at democratizing and accelerating research and innovation in machine learning applications for optimal power flow problems. Datasets are available for download at this https URL.', 'abstract_zh': '机器学习（ML）技术在最优功率流（OPF）问题中的应用近年来引起了广泛关注，反映了更广泛的利用ML近似和/或加速解决复杂优化问题的趋势。这些进展是因为现代和未来电网中能源生产波动性和规模的增加而变得必要。然而，ML在OPF中的进展受到标准化数据集和评估指标缺乏的阻碍，从生成和解决OPF实例到训练和基准测试机器学习模型。为了解决这一挑战，本文提出了PGLearn，这是一个全面的标准化数据集和评估工具套件，用于ML和OPF。PGLearn提供的数据集代表了现实运行条件，通过明确捕捉数据生成中的全局和局部变异性，并首次包括多个大型系统的时间序列数据，从而支持多种OPF公制，包括AC、DC和二阶锥公制。标准化数据集对公众开放，旨在普及该领域的访问权，减轻数据生成的负担，并enable多种方法的公平比较。PGLearn还包含一个用于训练、评估和基准测试OPF机器学习模型的稳健工具包，旨在标准化领域内的性能评估。通过推广开放和标准化的数据集和评估指标，PGLearn旨在促进和加速最优功率流问题中机器学习应用的研究与创新。数据集可在此链接下载：这个 https URL。', 'title_zh': 'PGLearn -- 一种开源最优功率 flow 学习工具包'}
{'arxiv_id': 'arXiv:2505.22815', 'title': 'IMTS is Worth Time $\\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction', 'authors': 'Zhangyi Hu, Jiemin Wu, Hua Xu, Mingqian Liao, Ninghui Feng, Bo Gao, Songning Lai, Yutao Yue', 'link': 'https://arxiv.org/abs/2505.22815', 'abstract': "Irregular Multivariate Time Series (IMTS) forecasting is challenging due to the unaligned nature of multi-channel signals and the prevalence of extensive missing data. Existing methods struggle to capture reliable temporal patterns from such data due to significant missing values. While pre-trained foundation models show potential for addressing these challenges, they are typically designed for Regularly Sampled Time Series (RTS). Motivated by the visual Mask AutoEncoder's (MAE) powerful capability for modeling sparse multi-channel information and its success in RTS forecasting, we propose VIMTS, a framework adapting Visual MAE for IMTS forecasting. To mitigate the effect of missing values, VIMTS first processes IMTS along the timeline into feature patches at equal intervals. These patches are then complemented using learned cross-channel dependencies. Then it leverages visual MAE's capability in handling sparse multichannel data for patch reconstruction, followed by a coarse-to-fine technique to generate precise predictions from focused contexts. In addition, we integrate self-supervised learning for improved IMTS modeling by adapting the visual MAE to IMTS data. Extensive experiments demonstrate VIMTS's superior performance and few-shot capability, advancing the application of visual foundation models in more general time series tasks. Our code is available at this https URL.", 'abstract_zh': '不规则多变量时间序列（IMTS）的预测因多通道信号的不齐和平坦数据的普遍存在而具有挑战性。现有的方法难以捕捉此类数据中的可靠时间模式，因为存在大量的缺失值。虽然预训练的基础模型具有解决这些挑战的潜力，但它们通常设计用于规则采样时间序列（RTS）。受视觉Mask AutoEncoder（MAE）对稀疏多通道信息建模的强大能力及其在RTS预测中的成功启发，我们提出了一种VIMTS框架，该框架将视觉MAE适应于IMTS预测。为了减轻缺失值的影响，VIMTS首先按时间间隔将IMTS处理为等间隔的特征.patch。然后，通过学习的跨通道依赖性来补充这些.patch。接下来，利用视觉MAE处理稀疏多通道数据的能力来进行.patch重建，并通过从集中上下文中生成精确预测的粗到细技术。此外，我们通过将视觉MAE适应IMTS数据来整合自监督学习，以改进IMTS建模。广泛的实验表明，VIMTS具有优越的性能和少样本能力，推动了视觉基础模型在更多一般时间序列任务中的应用。我们的代码可在以下网址获取。', 'title_zh': 'IMTS 值得时间 $\\times$ 通道 patches：视觉掩蔽自编码器在不规则多元时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2505.22803', 'title': 'CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment', 'authors': 'Pedro Mendes, Paolo Romano, David Garlan', 'link': 'https://arxiv.org/abs/2505.22803', 'abstract': 'Reliable uncertainty estimation is critical for deploying neural networks (NNs) in real-world applications. While existing calibration techniques often rely on post-hoc adjustments or coarse-grained binning methods, they remain limited in scalability, differentiability, and generalization across domains. In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error Alignment), a novel approach that explicitly aligns predicted uncertainty with observed error during training, grounded in the principle that well-calibrated models should produce uncertainty estimates that match their empirical loss. CLUE adopts a novel loss function that jointly optimizes predictive performance and calibration, using summary statistics of uncertainty and loss as proxies. The proposed method is fully differentiable, domain-agnostic, and compatible with standard training pipelines. Through extensive experiments on vision, regression, and language modeling tasks, including out-of-distribution and domain-shift scenarios, we demonstrate that CLUE achieves superior calibration quality and competitive predictive performance with respect to state-of-the-art approaches without imposing significant computational overhead.', 'abstract_zh': '可靠的不确定性估计对于在实际应用中部署神经网络至关重要。现有校准技术往往依赖于事后调整或粗粒度的分箱方法，但在可扩展性、可微性和跨域泛化能力方面仍有限制。在本文中，我们提出了CLUE（基于学习不确定性-误差对齐的校准方法），这是一种新型方法，在训练过程中显式地将预测的不确定性与观测到的误差对齐，其原理是校准良好的模型应该产生与实际损失相匹配的不确定性估计。CLUE采用了一种新的损失函数，该函数同时优化预测性能和校准，使用不确定性与损失的汇总统计数据作为代理。所提出的方法是完全可微的、领域无关的，并且与标准训练管道兼容。通过在视觉、回归和语言建模任务上的广泛实验，包括分布外和域迁移场景，我们证明了CLUE在相对于最新方法的校准质量方面表现优异，并在预测性能方面表现竞争力，而不会增加显著的计算开销。', 'title_zh': 'CLUE: 通过学习不确定性-误差对齐进行神经网络校准'}
{'arxiv_id': 'arXiv:2505.22798', 'title': 'Efficient Preimage Approximation for Neural Network Certification', 'authors': 'Anton Björklund, Mykola Zaitsev, Marta Kwiatkowska', 'link': 'https://arxiv.org/abs/2505.22798', 'abstract': "The growing reliance on artificial intelligence in safety- and security-critical applications demands effective neural network certification. A challenging real-world use case is certification against ``patch attacks'', where adversarial patches or lighting conditions obscure parts of images, for example traffic signs. One approach to certification, which also gives quantitative coverage estimates, utilizes preimages of neural networks, i.e., the set of inputs that lead to a specified output. However, these preimage approximation methods, including the state-of-the-art PREMAP algorithm, struggle with scalability. This paper presents novel algorithmic improvements to PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved branching heuristics. We demonstrate efficiency improvements of at least an order of magnitude on reinforcement learning control benchmarks, and show that our method scales to convolutional neural networks that were previously infeasible. Our results demonstrate the potential of preimage approximation methodology for reliability and robustness certification.", 'abstract_zh': '人工智能在安全和安全关键应用中的日益依赖 demands 有效神经网络认证。一种具有挑战性的实际应用场景是对抗“补丁攻击”的认证，即恶意补丁或光照条件模糊图像的部分内容，例如交通标志。一种认证方法不仅提供了定量的覆盖率估计，还利用了神经网络的预象，即导致指定输出的输入集合。然而，这些预象近似方法，包括最先进的PREMAP算法，面临可扩展性问题。本文提出了对PREMAP的新算法改进，涉及更紧的边界、自适应蒙特卡罗采样和改进的分支启发式方法。我们在强化学习控制基准上展示了至少一个数量级的效率提升，并证明了我们的方法能够扩展到之前不可行的卷积神经网络。我们的结果展示了预象近似方法在可靠性和鲁棒性认证中的潜力。', 'title_zh': '神经网络认证的高效前image近似算法'}
{'arxiv_id': 'arXiv:2505.22762', 'title': 'MIAS-SAM: Medical Image Anomaly Segmentation without thresholding', 'authors': 'Marco Colussi, Dragan Ahmetovic, Sergio Mascetti', 'link': 'https://arxiv.org/abs/2505.22762', 'abstract': 'This paper presents MIAS-SAM, a novel approach for the segmentation of anomalous regions in medical images. MIAS-SAM uses a patch-based memory bank to store relevant image features, which are extracted from normal data using the SAM encoder. At inference time, the embedding patches extracted from the SAM encoder are compared with those in the memory bank to obtain the anomaly map. Finally, MIAS-SAM computes the center of gravity of the anomaly map to prompt the SAM decoder, obtaining an accurate segmentation from the previously extracted features. Differently from prior works, MIAS-SAM does not require to define a threshold value to obtain the segmentation from the anomaly map. Experimental results conducted on three publicly available datasets, each with a different imaging modality (Brain MRI, Liver CT, and Retina OCT) show accurate anomaly segmentation capabilities measured using DICE score. The code is available at: this https URL', 'abstract_zh': 'MIAS-SAM：一种用于医学图像异常区域分割的新型方法', 'title_zh': 'MIAS-SAM: 医学图像异常分割 without 阈值")));'}
{'arxiv_id': 'arXiv:2505.22761', 'title': 'A comprehensive analysis of PINNs: Variants, Applications, and Challenges', 'authors': 'Afila Ajithkumar Sophiya, Akarsh K Nair, Sepehr Maleki, Senthil K. Krishnababu', 'link': 'https://arxiv.org/abs/2505.22761', 'abstract': 'Physics Informed Neural Networks (PINNs) have been emerging as a powerful computational tool for solving differential equations. However, the applicability of these models is still in its initial stages and requires more standardization to gain wider popularity. Through this survey, we present a comprehensive overview of PINNs approaches exploring various aspects related to their architecture, variants, areas of application, real-world use cases, challenges, and so on. Even though existing surveys can be identified, they fail to provide a comprehensive view as they primarily focus on either different application scenarios or limit their study to a superficial level. This survey attempts to bridge the gap in the existing literature by presenting a detailed analysis of all these factors combined with recent advancements and state-of-the-art research in PINNs. Additionally, we discuss prevalent challenges in PINNs implementation and present some of the future research directions as well. The overall contributions of the survey can be summarised into three sections: A detailed overview of PINNs architecture and variants, a performance analysis of PINNs on different equations and application domains highlighting their features. Finally, we present a detailed discussion of current issues and future research directions.', 'abstract_zh': 'Physics Informed Neural Networks (PINNs)作为一种求解微分方程的强大计算工具正在兴起。然而，这些模型的应用尚处于初期阶段，需要更多的标准化才能获得更广泛的认可。通过这篇综述，我们提供了关于PINNs的各种架构、变体、应用领域、实际应用场景、挑战等方面的全面概述，试图填补现有文献中的空白，结合最近的进展和最新的研究进行详细分析。此外，我们讨论了PINNs实现中普遍存在的挑战，并提出了未来研究方向。综述的主要贡献可以总结为三个方面：详细概述PINNs的架构和变体，对PINNs在不同方程和应用领域的性能进行分析，最后详细讨论当前问题和未来的研究方向。', 'title_zh': 'PINNs的综合分析：变体、应用与挑战'}
{'arxiv_id': 'arXiv:2505.22759', 'title': 'FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian', 'authors': 'Sara Papi, Marco Gaido, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri', 'link': 'https://arxiv.org/abs/2505.22759', 'abstract': 'The development of speech foundation models (SFMs) like Whisper and SeamlessM4T has significantly advanced the field of speech processing. However, their closed nature--with inaccessible training data and code--poses major reproducibility and fair evaluation challenges. While other domains have made substantial progress toward open science by developing fully transparent models trained on open-source (OS) code and data, similar efforts in speech remain limited. To fill this gap, we introduce FAMA, the first family of open science SFMs for English and Italian, trained on 150k+ hours of OS speech data. Moreover, we present a new dataset containing 16k hours of cleaned and pseudo-labeled speech for both languages. Results show that FAMA achieves competitive performance compared to existing SFMs while being up to 8 times faster. All artifacts, including code, datasets, and models, are released under OS-compliant licenses, promoting openness in speech technology research.', 'abstract_zh': '开放科学声学基础模型FAMA的发展：面向英语和意大利语的150K+小时开源声学数据训练模型', 'title_zh': 'FAMA: 首个大规模开放科学语音基础模型（英语和意大利语）'}
{'arxiv_id': 'arXiv:2505.22749', 'title': 'Self-orthogonalizing attractor neural networks emerging from the free energy principle', 'authors': 'Tamas Spisak, Karl Friston', 'link': 'https://arxiv.org/abs/2505.22749', 'abstract': 'Attractor dynamics are a hallmark of many complex systems, including the brain. Understanding how such self-organizing dynamics emerge from first principles is crucial for advancing our understanding of neuronal computations and the design of artificial intelligence systems. Here we formalize how attractor networks emerge from the free energy principle applied to a universal partitioning of random dynamical systems. Our approach obviates the need for explicitly imposed learning and inference rules and identifies emergent, but efficient and biologically plausible inference and learning dynamics for such self-organizing systems. These result in a collective, multi-level Bayesian active inference process. Attractors on the free energy landscape encode prior beliefs; inference integrates sensory data into posterior beliefs; and learning fine-tunes couplings to minimize long-term surprise. Analytically and via simulations, we establish that the proposed networks favor approximately orthogonalized attractor representations, a consequence of simultaneously optimizing predictive accuracy and model complexity. These attractors efficiently span the input subspace, enhancing generalization and the mutual information between hidden causes and observable effects. Furthermore, while random data presentation leads to symmetric and sparse couplings, sequential data fosters asymmetric couplings and non-equilibrium steady-state dynamics, offering a natural extension to conventional Boltzmann Machines. Our findings offer a unifying theory of self-organizing attractor networks, providing novel insights for AI and neuroscience.', 'abstract_zh': '自由能量原则应用于随机动力系统通用划分后的吸引子网络是如何涌现的：一种集体的多级贝叶斯主动推断过程', 'title_zh': '自由能原理涌现的自正交吸引子神经网络'}
{'arxiv_id': 'arXiv:2505.22685', 'title': 'DeepMultiConnectome: Deep Multi-Task Prediction of Structural Connectomes Directly from Diffusion MRI Tractography', 'authors': "Marcus J. Vroemen, Yuqian Chen, Yui Lo, Tengfei Xu, Weidong Cai, Fan Zhang, Josien P.W. Pluim, Lauren J. O'Donnell", 'link': 'https://arxiv.org/abs/2505.22685', 'abstract': 'Diffusion MRI (dMRI) tractography enables in vivo mapping of brain structural connections, but traditional connectome generation is time-consuming and requires gray matter parcellation, posing challenges for large-scale studies. We introduce DeepMultiConnectome, a deep-learning model that predicts structural connectomes directly from tractography, bypassing the need for gray matter parcellation while supporting multiple parcellation schemes. Using a point-cloud-based neural network with multi-task learning, the model classifies streamlines according to their connected regions across two parcellation schemes, sharing a learned representation. We train and validate DeepMultiConnectome on tractography from the Human Connectome Project Young Adult dataset ($n = 1000$), labeled with an 84 and 164 region gray matter parcellation scheme. DeepMultiConnectome predicts multiple structural connectomes from a whole-brain tractogram containing 3 million streamlines in approximately 40 seconds. DeepMultiConnectome is evaluated by comparing predicted connectomes with traditional connectomes generated using the conventional method of labeling streamlines using a gray matter parcellation. The predicted connectomes are highly correlated with traditionally generated connectomes ($r = 0.992$ for an 84-region scheme; $r = 0.986$ for a 164-region scheme) and largely preserve network properties. A test-retest analysis of DeepMultiConnectome demonstrates reproducibility comparable to traditionally generated connectomes. The predicted connectomes perform similarly to traditionally generated connectomes in predicting age and cognitive function. Overall, DeepMultiConnectome provides a scalable, fast model for generating subject-specific connectomes across multiple parcellation schemes.', 'abstract_zh': 'DeepLearning驱动的多分割方案脑连接组预测模型', 'title_zh': 'DeepMultiConnectome: 直接从扩散MRI追踪图预测结构连接组的深度多任务学习'}
{'arxiv_id': 'arXiv:2505.22683', 'title': 'ConnectomeDiffuser: Generative AI Enables Brain Network Construction from Diffusion Tensor Imaging', 'authors': 'Xuhang Chen, Michael Kwok-Po Ng, Kim-Fung Tsang, Chi-Man Pun, Shuqiang Wang', 'link': 'https://arxiv.org/abs/2505.22683', 'abstract': "Brain network analysis plays a crucial role in diagnosing and monitoring neurodegenerative disorders such as Alzheimer's disease (AD). Existing approaches for constructing structural brain networks from diffusion tensor imaging (DTI) often rely on specialized toolkits that suffer from inherent limitations: operator subjectivity, labor-intensive workflows, and restricted capacity to capture complex topological features and disease-specific biomarkers. To overcome these challenges and advance computational neuroimaging instrumentation, ConnectomeDiffuser is proposed as a novel diffusion-based framework for automated end-to-end brain network construction from DTI. The proposed model combines three key components: (1) a Template Network that extracts topological features from 3D DTI scans using Riemannian geometric principles, (2) a diffusion model that generates comprehensive brain networks with enhanced topological fidelity, and (3) a Graph Convolutional Network classifier that incorporates disease-specific markers to improve diagnostic accuracy. ConnectomeDiffuser demonstrates superior performance by capturing a broader range of structural connectivity and pathology-related information, enabling more sensitive analysis of individual variations in brain networks. Experimental validation on datasets representing two distinct neurodegenerative conditions demonstrates significant performance improvements over other brain network methods. This work contributes to the advancement of instrumentation in the context of neurological disorders, providing clinicians and researchers with a robust, generalizable measurement framework that facilitates more accurate diagnosis, deeper mechanistic understanding, and improved therapeutic monitoring of neurodegenerative diseases such as AD.", 'abstract_zh': '脑网络分析在诊断和监测阿尔茨海默病等神经退行性疾病中发挥着重要作用。现有的基于扩散张量成像(DTI)构建结构脑网络的方法通常依赖于专门的工具包，这些工具包存在固有的局限性：操作者的主观性、劳动密集型的工作流程以及捕获复杂拓扑特征和疾病特异性生物标志物的限制能力。为了克服这些挑战并推动计算神经影像学仪器的进步，提出了一种新的基于扩散的框架ConnectomeDiffuser，用于从DTI自动端到端构建脑网络。该提出的模型结合了三个关键组件：（1）模板网络，使用黎曼几何原理从3D DTI扫描中提取拓扑特征；（2）扩散模型，生成具有增强拓扑保真度的全面脑网络；（3）图卷积网络分类器，整合疾病特异性标记以提高诊断准确性。ConnectomeDiffuser通过捕获更广泛的结构连接性和与病理相关的信息，展示了优越的性能，使个体脑网络的分析更为敏感。在代表两种不同神经退行性疾病的数据库上的实验验证表明，与其他脑网络方法相比，其性能有了显著提升。该工作为神经退行性疾病背景下仪器的发展做出了贡献，为临床医生和研究人员提供了一种稳健且可泛化的测量框架，促进更准确的诊断、更深入的机制理解和更有效的神经退行性疾病如阿尔茨海默病的治疗监测。', 'title_zh': 'ConnectomeDiffuser: 生成式AI使弥散张量成像下的脑网络构建成为可能'}
{'arxiv_id': 'arXiv:2505.22674', 'title': 'PSBench: a large-scale benchmark for estimating the accuracy of protein complex structural models', 'authors': 'Pawan Neupane, Jian Liu, Jianlin Cheng', 'link': 'https://arxiv.org/abs/2505.22674', 'abstract': "Predicting protein complex structures is essential for protein function analysis, protein design, and drug discovery. While AI methods like AlphaFold can predict accurate structural models for many protein complexes, reliably estimating the quality of these predicted models (estimation of model accuracy, or EMA) for model ranking and selection remains a major challenge. A key barrier to developing effective machine learning-based EMA methods is the lack of large, diverse, and well-annotated datasets for training and evaluation. To address this gap, we introduce PSBench, a benchmark suite comprising four large-scale, labeled datasets generated during the 15th and 16th community-wide Critical Assessment of Protein Structure Prediction (CASP15 and CASP16). PSBench includes over one million structural models covering a wide range of protein sequence lengths, complex stoichiometries, functional classes, and modeling difficulties. Each model is annotated with multiple complementary quality scores at the global, local, and interface levels. PSBench also provides multiple evaluation metrics and baseline EMA methods to facilitate rigorous comparisons. To demonstrate PSBench's utility, we trained and evaluated GATE, a graph transformer-based EMA method, on the CASP15 data. GATE was blindly tested in CASP16 (2024), where it ranked among the top-performing EMA methods. These results highlight PSBench as a valuable resource for advancing EMA research in protein complex modeling. PSBench is publicly available at: this https URL.", 'abstract_zh': '预测蛋白质复合体结构对于蛋白质功能分析、蛋白质设计和药物发现至关重要。虽然像AlphaFold这样的AI方法可以为许多蛋白质复合体预测准确的结构模型，但对于这些预测模型的质量评估（模型准确性评估，EMA）以进行模型排名和选择仍然是一个主要挑战。由于缺乏大规模、多样化和注释良好的数据集用于训练和评估，开发有效的基于机器学习的EMA方法面临障碍。为此，我们引入了PSBench，这是一个基准套件，包含四个在第15届和第16届全面性蛋白质结构预测关键评估（CASP15和CASP16）期间生成的大规模、标注数据集。PSBench涵盖了从蛋白质序列长度、复合体组成、功能类别到建模难度等一系列广泛范围的超过一百万个结构模型，并为每个模型标注了多个层次的质量评分。PSBench还提供了多种评估指标和基线EMA方法，以促进严格比较。为了证明PSBench的实用性，我们在CASP15数据上训练和评估了基于图形变换器的EMA方法GATE，并在CASP16（2024）中盲测，GATE在EMA方法中排名靠前。这些结果突显了PSBench作为蛋白质复合体建模中EMA研究有价值的资源作用。PSBench已公开可用：this https URL。', 'title_zh': 'PSBench：用于评估蛋白质复合物结构模型准确性的大规模基准'}
