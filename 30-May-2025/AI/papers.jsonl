{'arxiv_id': 'arXiv:2505.23762', 'title': 'ZeroGUI: Automating Online GUI Learning at Zero Human Cost', 'authors': 'Chenyu Yang, Shiqian Su, Shi Liu, Xuan Dong, Yue Yu, Weijie Su, Xuehui Wang, Zhaoyang Liu, Jinguo Zhu, Hao Li, Wenhai Wang, Yu Qiao, Xizhou Zhu, Jifeng Dai', 'link': 'https://arxiv.org/abs/2505.23762', 'abstract': 'The rapid advancement of large Vision-Language Models (VLMs) has propelled the development of pure-vision-based GUI Agents, capable of perceiving and operating Graphical User Interfaces (GUI) to autonomously fulfill user instructions. However, existing approaches usually adopt an offline learning framework, which faces two core limitations: (1) heavy reliance on high-quality manual annotations for element grounding and action supervision, and (2) limited adaptability to dynamic and interactive environments. To address these limitations, we propose ZeroGUI, a scalable, online learning framework for automating GUI Agent training at Zero human cost. Specifically, ZeroGUI integrates (i) VLM-based automatic task generation to produce diverse training goals from the current environment state, (ii) VLM-based automatic reward estimation to assess task success without hand-crafted evaluation functions, and (iii) two-stage online reinforcement learning to continuously interact with and learn from GUI environments. Experiments on two advanced GUI Agents (UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance across OSWorld and AndroidLab environments. The code is available at this https URL.', 'abstract_zh': '大型Vision-Language模型的 rapid 进展推动了纯视觉GUI代理的发展，这些代理能够感知和操作图形用户界面（GUI）以自主完成用户指令。然而，现有方法通常采用离线学习框架，面临两个核心限制：（1）对高质量手动标注的元素接地和动作监督的高度依赖；（2）对动态和交互式环境的有限适应性。为了解决这些限制，我们提出ZeroGUI，这是一种零成本的大规模在线学习框架，用于自动化GUI代理的训练。具体来说，ZeroGUI结合了（i）基于大型Vision-Language模型的自动任务生成，从当前环境状态中生成多样化的训练目标；（ii）基于大型Vision-Language模型的自动奖励估计，无需手动构造的评估函数来评估任务成功；（iii）两阶段在线强化学习，以持续与GUI环境交互并从中学习。实验结果在两个先进的GUI代理（UI-TARS和Aguvis）中表明，ZeroGUI显著提升了OSWorld和AndroidLab环境中的性能。代码可在以下网址获得。', 'title_zh': 'ZeroGUI: 在零人工成本下自动化在线GUI学习'}
{'arxiv_id': 'arXiv:2505.23746', 'title': 'Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons', 'authors': 'Hugo Henry, Kelly Cohen', 'link': 'https://arxiv.org/abs/2505.23746', 'abstract': "This study investigates the application of Genetic Fuzzy Systems (GFS) to model the self-noise generated by airfoils, a key issue in aeroaccoustics with significant implications for aerospace, automotive and drone applications. Using the publicly available Airfoil Self Noise dataset, various Fuzzy regression strategies are explored and compared. The paper evaluates a brute force Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading Geneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on Fuzzy C-means (FCM) to reduce the model's complexity. This highlights the viability of clustering assisted fuzzy inference as an effective regression tool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression, Cascading systems, Clustering and AI.", 'abstract_zh': '本研究探讨了遗传模糊系统（GFS）在建模机翼自噪声中的应用，这是航空声学中的一个关键问题，对航空、汽车和无人机应用具有重要意义。利用公开的Airfoil Self Noise数据集，研究了各种模糊回归策略并进行了比较。论文评估了具有高规则密度的 brute force Takagi Sugeno Kang （TSK）模糊系统、级联遗传模糊树（GFT）架构以及基于模糊C均值（FCM）的新型聚类方法以减少模型的复杂性。这突显了聚类辅助模糊推理作为复杂航空声学现象的有效回归工具的可行性。关键词：模糊逻辑、回归、级联系统、聚类和AI。', 'title_zh': '遗传模糊回归技术在 Aeroacoustic 现象中的比较研究'}
{'arxiv_id': 'arXiv:2505.23703', 'title': "Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability", 'authors': 'Ruida Wang, Yuxin Li, Yi R., Fung, Tong Zhang', 'link': 'https://arxiv.org/abs/2505.23703', 'abstract': 'Enhancing the mathematical reasoning capabilities of LLMs has garnered significant attention in both the mathematical and computer science communities. Recent works have made substantial progress in both Natural Language (NL) reasoning and Formal Language (FL) reasoning by leveraging the potential of pure Reinforcement Learning (RL) methods on base models. However, RL approaches struggle to impart new capabilities not presented in the base model, highlighting the need to integrate more knowledge like FL into NL math reasoning effectively. Yet, this integration is challenging due to inherent disparities in problem structure and reasoning format between NL and FL. To address these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end framework designed to incorporate the FL expert into NL math problem-solving. To bridge the NL and FL input format gap, we propose the *NL-FL Problem Alignment* method, which reformulates the Question-Answering (QA) problems in NL as existence theorems in FL. Subsequently, the *Mixed Problem Input* technique we provide enables the FL reasoner to handle both QA and existence problems concurrently. Lastly, we mitigate the NL and FL output format gap in reasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive experiments demonstrate that the **HybridReasoning** framework achieves **89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC benchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively. Notably, some problems resolved by our framework remain unsolved by the NL baseline model even under a larger number of trials.', 'abstract_zh': '增强大规模语言模型的数学推理能力已在数学和计算机科学社区引起了广泛关注。通过利用纯强化学习方法在基础模型上的潜力，近期研究在自然语言（NL）推理和形式语言（FL）推理方面取得了显著进展。然而，强化学习方法难以传授基础模型中未呈现的新能力，这凸显了有效整合更多形式语言知识的重要性。但是，这种整合由于自然语言和形式语言在问题结构和推理格式上的固有差异而具有挑战性。为应对这些挑战，我们提出 **NL-FL HybridReasoning**，这是一种端到端框架，旨在将形式语言专家融入到自然语言数学问题解决中。为弥合自然语言和形式语言的输入格式差异，我们提出了 *NL-FL Problem Alignment* 方法，将自然语言中的问答问题重新表述为形式语言中的存在定理。随后，我们提供的 *混合问题输入* 技术使形式语言推理器能够同时处理问答和存在性问题。最后，我们通过基于大语言模型的 *答案提取* 机制缓解了推理过程中的输出格式差异。全面的实验表明，**HybridReasoning** 框架在 MATH-500 和 AMC 基准测试上的准确率分别为 89.80% 和 84.34%，分别超过了自然语言基线模型 4.60% 和 4.82%。值得注意的是，即使在更多的试验次数下，自然语言基线模型也无法解决由我们框架解决的一些问题。', 'title_zh': '让我们正式推理：自然-正式混合推理增强LLM的数学能力'}
{'arxiv_id': 'arXiv:2505.23695', 'title': 'Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics', 'authors': 'Ran Zhang, Mohannad Elhamod', 'link': 'https://arxiv.org/abs/2505.23695', 'abstract': "The rapid advancement of LLMs has led to the creation of diverse agentic systems in data analysis, utilizing LLMs' capabilities to improve insight generation and visualization. In this paper, we present an agentic system that automates the data-to-dashboard pipeline through modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. Unlike existing chart QA systems, our framework simulates the analytical reasoning process of business analysts by retrieving domain-relevant knowledge and adapting to diverse datasets without relying on closed ontologies or question templates.\nWe evaluate our system on three datasets across different domains. Benchmarked against GPT-4o with a single-prompt baseline, our approach shows improved insightfulness, domain relevance, and analytical depth, as measured by tailored evaluation metrics and qualitative human assessment.\nThis work contributes a novel modular pipeline to bridge the path from raw data to visualization, and opens new opportunities for human-in-the-loop validation by domain experts in business analytics. All code can be found here: this https URL", 'abstract_zh': '快速发展的大型语言模型促进了多样化的代理系统在数据分析中应用，利用大型语言模型的能力以提高洞察生成和可视化。在本文中，我们提出了一种代理系统，通过具有领域检测、概念抽取、多视角分析生成和迭代自我反思能力的模块化大型语言模型代理来自动化数据到仪表盘的工作流程。与现有的图表质量控制系统不同，我们的框架通过检索相关领域知识并适应各种数据集，模拟了商业分析师的分析推理过程，无需依赖封闭本体或问题模板。\n\n我们在不同领域的三个数据集上评估了该系统。与使用单聚prompt的GPT-4o进行基准测试，我们的方法在定制的评估指标和定性的主观评价中展示了更高的洞察力、领域相关性和分析深度。\n\n本文贡献了一种新颖的模块化流程，从原始数据到可视化，同时为商业分析中的领域专家在环验证开辟了新的机会。所有代码均可在这里找到：this https URL。', 'title_zh': '数据到仪表盘：企业分析中洞察可视化的大规模多代理LLM框架'}
{'arxiv_id': 'arXiv:2505.23686', 'title': 'ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork', 'authors': 'Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone', 'link': 'https://arxiv.org/abs/2505.23686', 'abstract': 'Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.', 'abstract_zh': '开发能够与未见过的合作伙伴协作的AI代理是多代理学习中一个基本的泛化挑战，称为即兴团队合作（AHT）。', 'title_zh': 'ROTATE：基于遗憾的学习连贯团队协作的开放式训练'}
{'arxiv_id': 'arXiv:2505.23667', 'title': 'Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models', 'authors': 'Lang Cao, Jingxian Xu, Hanbing Liu, Jinyu Wang, Mengyu Zhou, Haoyu Dong, Shi Han, Dongmei Zhang', 'link': 'https://arxiv.org/abs/2505.23667', 'abstract': 'Tables are a fundamental structure for organizing and analyzing data, making effective table understanding a critical capability for intelligent systems. While large language models (LMs) demonstrate strong general reasoning abilities, they continue to struggle with accurate numerical or symbolic reasoning over tabular data, especially in complex scenarios. Spreadsheet formulas provide a powerful and expressive medium for representing executable symbolic operations, encoding rich reasoning patterns that remain largely underutilized. In this paper, we propose Formula Tuning (Fortune), a reinforcement learning (RL) framework that trains LMs to generate executable spreadsheet formulas for question answering over general tabular data. Formula Tuning reduces the reliance on supervised formula annotations by using binary answer correctness as a reward signal, guiding the model to learn formula derivation through reasoning. We provide a theoretical analysis of its advantages and demonstrate its effectiveness through extensive experiments on seven table reasoning benchmarks. Formula Tuning substantially enhances LM performance, particularly on multi-step numerical and symbolic reasoning tasks, enabling a 7B model to outperform O1 on table understanding. This highlights the potential of formula-driven RL to advance symbolic table reasoning in LMs.', 'abstract_zh': '表格是组织和分析数据的基本结构，有效的表格理解是智能系统的一项关键能力。虽然大规模语言模型（LMs）展示了强大的通用推理能力，但在准确进行基于表格数据的数值或符号推理方面仍然存在挑战，特别是在复杂场景下。电子表格公式提供了一种强大且表达力强的介质，用于表示可执行的符号操作，并编码丰富的推理模式，这些模式目前尚未得到充分利用。在本文中，我们提出了一种基于强化学习（RL）的框架——公式调优（Fortune），旨在训练LMs生成适用于一般表格数据的可执行电子表格公式，用于问答任务。公式调优通过使用二元答案正确性作为奖励信号，减少了对监督公式注释的依赖，引导模型通过推理学习公式推导。我们对其理论优势进行了分析，并通过在七个表格推理基准上的广泛实验验证了其有效性。公式调优显著提升了LMs的性能，特别是在多步数值和符号推理任务上，使一个7B模型在表格理解任务上超越了O1。这突显了公式驱动的RL在提升LMs的符号表格推理能力方面的潜力。', 'title_zh': 'fortune: 公式驱动的强化学习在语言模型中进行符号表推理'}
{'arxiv_id': 'arXiv:2505.23596', 'title': 'MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning', 'authors': 'Linqiang Guo, Wei Liu, Yi Wen Heng, Tse-Hsun, Chen, Yang Wang', 'link': 'https://arxiv.org/abs/2505.23596', 'abstract': 'Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.', 'abstract_zh': '移动GUI代理目标是在跨移动应用完成用户指示的任务时实现自主工作。近期的多模态大型语言模型（MLLMs）进展使这些代理能够解析UI屏幕、识别可操作元素并执行点击或输入等交互。然而，现有的代理仍然具有反应性：它们仅基于当前屏幕进行推理，缺乏对应用导航流程的结构化建模，这限制了它们理解上下文、检测意外结果和从错误中恢复的能力。我们提出了MAPLE——一种状态感知的多代理框架，将应用交互抽象为有限状态机（FSM）。我们计算建模每个UI屏幕为离散状态，并将用户行动视为状态间的转换，从而使FSM能够为应用执行提供结构化的表示。MAPLE由专门负责任务执行四个阶段的代理组成：规划、执行、验证、错误恢复和知识保留。这些代理协同工作，根据从UI屏幕中提取的感知数据实时动态构建FSM，使GUI代理能够跟踪导航进度和流程，通过状态的先验和后验条件验证行动结果，并通过回滚到先前稳定状态从错误中恢复。我们在两个具有挑战性的跨应用基准Mobile-Eval-E和SPA-Bench上的评估结果显示，MAPLE优于现有最先进的基线，任务成功率达到最高提升12%，恢复成功率提升13.8%，行动准确性提高6.5%。我们的结果突显了在任务执行过程中指导移动GUI代理进行结构化状态建模的重要性。此外，我们的FSM表示可以集成到未来GUI代理架构中作为轻量级、模型无关的记忆层，以支持结构化规划、执行验证和错误恢复。', 'title_zh': 'MAPLE：一种用于恢复推理的持久有限状态机移动助手'}
{'arxiv_id': 'arXiv:2505.23575', 'title': 'CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring', 'authors': 'Benjamin Arnav, Pablo Bernabeu-Pérez, Nathan Helm-Burger, Tim Kostolansky, Hannes Whittingham, Mary Phuong', 'link': 'https://arxiv.org/abs/2505.23575', 'abstract': 'As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that CoT monitoring improves detection by up to 27 percentage points in scenarios where action-only monitoring fails to reliably identify sabotage. However, CoT traces can also contain misleading rationalizations that deceive the monitor, reducing performance in more obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores both reasoning and final outputs and combines them using a weighted average. This hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates over four times higher than action-only monitoring for subtle deception scenarios.', 'abstract_zh': '随着AI模型的自主性不断增强，确保它们不会在不被察觉的情况下采取有害行为至关重要。作为潜在的缓解措施，我们研究了思维链（Chain-of-Thought，CoT）监控，即一个较弱的受信监控模型持续监督更强大的但不信任模型的中间推理步骤。我们在红队演练中比较了CoT监控与仅审查最终输出的行动监控，其中不信任模型被指示在完成编程问题时追求有害副任务。我们发现，在仅审查行动的监控方法无法可靠识别破坏行为的情景下，CoT监控可提高多达27个百分点的检测率。然而，CoT轨迹也可能包含可能欺骗监控的误导性解释，这在更明显的破坏情景中降低了性能。为此，我们引入了一种混合协议，该协议独立对推理和最终输出进行评分，并使用加权平均值进行结合。这种混合监控在所有测试的模型和任务中都表现得优于CoT和仅审查行动的监控，对于微妙的欺骗情景，检测率高出四倍以上。', 'title_zh': 'CoTRed-Handed: 压力测试链式思考监控'}
{'arxiv_id': 'arXiv:2505.23559', 'title': 'SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents', 'authors': 'Kunlun Zhu, Jiaxun Zhang, Ziheng Qi, Nuoxing Shang, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You', 'link': 'https://arxiv.org/abs/2505.23559', 'abstract': 'Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns. To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration. SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process. To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks. Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality. Additionally, we rigorously validate the robustness of our safety pipeline against diverse adversarial attack methods, further confirming the effectiveness of our integrated approach. The code and data will be available at this https URL. \\textcolor{red}{Warning: this paper contains example data that may be offensive or harmful.}', 'abstract_zh': 'Recent advancements in大型语言模型（LLM）代理显著加速了科学发现的自动化过程，但也引发了重要的伦理和安全问题。为了系统地应对这些挑战，我们介绍了**SafeScientist**这一创新的AI科学家框架，该框架明确设计用于增强AI驱动科学探索中的安全性和伦理责任。SafeScientist主动拒绝伦理不当或高风险任务，并在整个研究过程中严格强调安全性。为了实现全面的安全监督，我们整合了多种防御机制，包括提示监控、代理协作监控、工具使用监控以及伦理审查员组件。为配合SafeScientist，我们提出了**SciSafetyBench**这一新型基准，专门用于评估科学背景下AI的安全性，该基准包括6个领域中的240个高风险科学任务，以及30个专门设计的科学工具和120个与工具相关的风险任务。广泛实验表明，与传统AI科学家框架相比，SafeScientist在提高安全性能方面提高了35%，同时不会牺牲科学输出质量。此外，我们还严格验证了我们安全管道的 robustness，以对抗各种敌对攻击方法，进一步证实了我们集成方案的有效性。相关代码和数据可在以下链接获取。请注意：本文包含可能引起冒犯或危害的示例数据。', 'title_zh': 'SafeScientist: 向量化的风险感知科学发现由LLM代理实现'}
{'arxiv_id': 'arXiv:2505.23536', 'title': 'Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)', 'authors': 'Janik-Vasily Benzin, Gyunam Park, Stefanie Rinderle-Ma', 'link': 'https://arxiv.org/abs/2505.23536', 'abstract': 'Model abstraction (MA) and event abstraction (EA) are means to reduce complexity of (discovered) models and event data. Imagine a process intelligence project that aims to analyze a model discovered from event data which is further abstracted, possibly multiple times, to reach optimality goals, e.g., reducing model size. So far, after discovering the model, there is no technique that enables the synchronized abstraction of the underlying event log. This results in loosing the grounding in the real-world behavior contained in the log and, in turn, restricts analysis insights. Hence, in this work, we provide the formal basis for synchronized model and event abstraction, i.e., we prove that abstracting a process model by MA and discovering a process model from an abstracted event log yields an equivalent process model. We prove the feasibility of our approach based on behavioral profile abstraction as non-order preserving MA technique, resulting in a novel EA technique.', 'abstract_zh': '模型抽象（MA）和事件抽象（EA）是减少发现模型和事件数据复杂性的方法。在一项旨在分析从事件数据中发现的模型并进一步多次抽象以实现优化目标（例如，减少模型大小）的过程智能项目中，目前在发现模型之后，尚无技术能够同步抽象底层事件日志。这导致在日志中包含的实际行为基础丧失，从而限制了分析洞察力。因此，在本文中，我们为同步模型和事件抽象提供了形式基础，即我们证明了通过MA抽象过程模型并从抽象后的事件日志中发现过程模型可以得到等价的过程模型。我们基于行为特征抽象作为非序数保留的MA技术，证明了我们方法的可行性，并提出了一种新的EA技术。', 'title_zh': '基于事件抽象的过程模型同步与智能'}
{'arxiv_id': 'arXiv:2505.23519', 'title': 'Individual differences in the cognitive mechanisms of planning strategy discovery', 'authors': 'Ruiqi He, Falk Lieder', 'link': 'https://arxiv.org/abs/2505.23519', 'abstract': "People employ efficient planning strategies. But how are these strategies acquired? Previous research suggests that people can discover new planning strategies through learning from reinforcements, a process known as metacognitive reinforcement learning (MCRL). While prior work has shown that MCRL models can learn new planning strategies and explain more participants' experience-driven discovery better than alternative mechanisms, it also revealed significant individual differences in metacognitive learning. Furthermore, when fitted to human data, these models exhibit a slower rate of strategy discovery than humans. In this study, we investigate whether incorporating cognitive mechanisms that might facilitate human strategy discovery can bring models of MCRL closer to human performance. Specifically, we consider intrinsically generated metacognitive pseudo-rewards, subjective effort valuation, and termination deliberation. Analysis of planning task data shows that a larger proportion of participants used at least one of these mechanisms, with significant individual differences in their usage and varying impacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort valuation, and learning the value of acting without further planning were found to facilitate strategy discovery. While these enhancements provided valuable insights into individual differences and the effect of these mechanisms on strategy discovery, they did not fully close the gap between model and human performance, prompting further exploration of additional factors that people might use to discover new planning strategies.", 'abstract_zh': '人们采用高效的规划策略，但这些策略是如何获得的呢？已有研究指出，人们可以通过 reinforcement 学习来发现新的规划策略，这一过程被称为元认知强化学习（MCRL）。尽管先前的研究表明，MCRL 模型能够学习新的规划策略，并且比其他机制更好地解释了参与者基于经验的发现，但同时也揭示了个体在元认知学习方面存在显著差异。此外，当这些模型应用于人类数据时，策略发现的速度明显慢于人类。本研究探讨是否可以通过整合可能促进人类策略发现的认知机制，使 MCRL 模型更接近人类的表现。具体来说，我们考虑内生的元认知伪奖励、主观努力评估以及终止权衡。对规划任务数据的分析表明，有很大比例的参与者至少使用了其中一种机制，个体间在使用这些机制方面存在显著差异，且这些机制对策略发现的影响各不相同。元认知伪奖励、主观努力评估以及学习无需进一步规划的行为的价值被发现能够促进策略发现。尽管这些增强提供了关于个体差异以及这些机制在策略发现中作用的重要见解，但模型与人类性能之间的差距并未完全缩小，因此需进一步探索人们可能使用的其他因素，以发现新的规划策略。', 'title_zh': '计划策略发现的认知机制个体差异'}
{'arxiv_id': 'arXiv:2505.23518', 'title': 'TRAP: Targeted Redirecting of Agentic Preferences', 'authors': 'Hangoo Kang, Jehyeok Yeon, Gagandeep Singh', 'link': 'https://arxiv.org/abs/2505.23518', 'abstract': "Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a generative adversarial framework that manipulates the agent's decision-making using diffusion-based semantic injections. Our method combines negative prompt-based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection biases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP achieves a 100% attack success rate on leading models, including LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such as SPSA, Bandit, and standard diffusion approaches. These results expose a critical vulnerability: Autonomous agents can be consistently misled through human-imperceptible cross-modal manipulations. These findings highlight the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making.", 'abstract_zh': '由视觉-语言模型驱动的自主代理AI系统正迅速向实际部署迈进，但其跨模态推理能力也引入了新的 adversarial 操纵攻击面，这些攻击利用了不同模态间的语义推理。现有的 adversarial 攻击通常依赖于可见像素扰动或需要获取模型或环境的特权访问，这使它们在进行隐秘的现实世界利用时变得不切实际。我们提出了 TRAP，这是一种生成对抗框架，利用基于扩散的语义注入来操纵代理的决策。该方法结合了基于负提示的降级和正向语义优化，由 Siamese 语义网络和布局感知的空间遮罩引导。无需访问模型内部结构，TRAP 产生的视觉自然图像却能在代理型AI系统中引起一致的选择偏见。我们在 Microsoft Common Objects in Context (COCO) 数据集上评估了 TRAP，构建了多候选决策场景。在这些场景中，TRAP 在包括LLaVA-34B、Gemma3 和 Mistral-3.1在内的领先模型上实现了 100% 的攻击成功率，并显著优于SPSA、Bandit 和标准扩散方法等基准方法。这些结果揭示了一个关键的脆弱性：自主代理可以通过人类不可感知的跨模态操纵持续被误导。这些发现强调了在应对跨模态决策中的语义脆弱性时，需要超越像素级别的鲁棒性的防御策略的需求。', 'title_zh': '靶向引导赋权偏好'}
{'arxiv_id': 'arXiv:2505.23486', 'title': 'Autoformalization in the Era of Large Language Models: A Survey', 'authors': 'Ke Weng, Lun Du, Sirui Li, Wangyue Lu, Haozhe Sun, Hengyu Liu, Tiancheng Zhang', 'link': 'https://arxiv.org/abs/2505.23486', 'abstract': 'Autoformalization, the process of transforming informal mathematical propositions into verifiable formal representations, is a foundational task in automated theorem proving, offering a new perspective on the use of mathematics in both theoretical and applied domains. Driven by the rapid progress in artificial intelligence, particularly large language models (LLMs), this field has witnessed substantial growth, bringing both new opportunities and unique challenges. In this survey, we provide a comprehensive overview of recent advances in autoformalization from both mathematical and LLM-centric perspectives. We examine how autoformalization is applied across various mathematical domains and levels of difficulty, and analyze the end-to-end workflow from data preprocessing to model design and evaluation. We further explore the emerging role of autoformalization in enhancing the verifiability of LLM-generated outputs, highlighting its potential to improve both the trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key open-source models and datasets supporting current research, and discuss open challenges and promising future directions for the field.', 'abstract_zh': '自动形式化是将非形式化的数学命题转换为可验证的形式表示的基础任务，是自动定理证明中的一个核心任务，为理论和应用领域中数学的使用提供了新的视角。随着人工智能尤其是大型语言模型（LLMs）的迅速进展，该领域取得了显著的增长，带来了新的机遇和独特的挑战。本文综述了从数学和LLM中心视角出发的自动形式化领域的最新进展，探讨了自动形式化在各类数学领域和不同难度水平的应用，并分析了从数据预处理到模型设计和评估的端到端工作流程。进一步探讨了自动形式化在增强LLM生成输出的可验证性方面的作用，突显了其提高LLM可信度和推理能力的潜力。最后，总结支持当前研究的关键开源模型和数据集，并讨论该领域的开放挑战和前景发展方向。', 'title_zh': '大语言模型时代的数据自形式化：一种综述'}
{'arxiv_id': 'arXiv:2505.23474', 'title': 'Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns', 'authors': 'Xiang Li, Haiyang Yu, Xinghua Zhang, Ziyang Huang, Shizhu He, Kang Liu, Jun Zhao, Fei Huang, Yongbin Li', 'link': 'https://arxiv.org/abs/2505.23474', 'abstract': 'Process Reward Models (PRMs) are crucial in complex reasoning and problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by verifying the correctness of each intermediate reasoning step. In real-world scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to solve a problem, potentially suffering from errors under various reasoning patterns. Therefore, PRMs are required to identify errors under various reasoning patterns during the reasoning process. However, existing benchmarks mainly focus on evaluating PRMs with stepwise correctness, ignoring a systematic evaluation of PRMs under various reasoning patterns. To mitigate this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs systematically under six reasoning patterns, including Transformation, Decomposition, Regather, Deduction, Verification, and Integration. Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the aforementioned six reasoning patterns. Through our experiments on both PRMs and LLMs prompted as critic models, we identify notable deficiencies in existing PRMs. These observations underscore the significant weakness of current PRMs in conducting evaluations on reasoning steps under various reasoning patterns. We hope Socratic-PRMBench can serve as a comprehensive testbed for systematic evaluation of PRMs under diverse reasoning patterns and pave the way for future development of PRMs.', 'abstract_zh': '过程奖励模型（PRMs）在复杂推理和问题求解任务（例如，具有长时决策制定的LLM代理）中至关重要，用于验证每一步推理的正确性。在实际场景中，LLMs可能会应用各种推理模式（例如，分解）来解决问题，在不同推理模式下可能会出现错误。因此，PRMs需要在推理过程中识别各种推理模式下的错误。然而，现有的基准主要集中在逐步正确性评估PRMs上，忽略了在各种推理模式下的系统评估。为了缩小这一差距，我们引入了Socratic-PRMBench，一个新基准，旨在系统地在六种推理模式（包括变换、分解、重新收集、演绎、验证和集成）下评估PRMs。Socratic-PRMBench包含2995条带有缺陷的推理路径。通过在PRMs和作为批评模型的LLMs上的实验，我们识别出现有PRMs中的显著缺陷。这些观察结果突显了当前PRMs在不同推理模式下评估推理步骤时的重大缺陷。我们希望Socratic-PRMBench可以作为一个全面的测试平台，用于系统评估不同推理模式下的PRMs，并为未来PRMs的发展铺平道路。', 'title_zh': '苏格拉底-PRMBench：基于系统推理模式的过程奖励模型评估'}
{'arxiv_id': 'arXiv:2505.23473', 'title': 'EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions', 'authors': 'Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaolu Zhang, Jun Zhou, Yuxiang Peng, Li Zheng, Chong Teng, Donghong Ji, Zhuang Li', 'link': 'https://arxiv.org/abs/2505.23473', 'abstract': 'Large language models (LLMs) frequently refuse to respond to pseudo-malicious instructions: semantically harmless input queries triggering unnecessary LLM refusals due to conservative safety alignment, significantly impairing user experience. Collecting such instructions is crucial for evaluating and mitigating over-refusals, but existing instruction curation methods, like manual creation or instruction rewriting, either lack scalability or fail to produce sufficiently diverse and effective refusal-inducing prompts. To address these limitations, we introduce EVOREFUSE, a prompt optimization approach that generates diverse pseudo-malicious instructions consistently eliciting confident refusals across LLMs. EVOREFUSE employs an evolutionary algorithm exploring the instruction space in more diverse directions than existing methods via mutation strategies and recombination, and iteratively evolves seed instructions to maximize evidence lower bound on LLM refusal probability. Using EVOREFUSE, we create two novel datasets: EVOREFUSE-TEST, a benchmark of 582 pseudo-malicious instructions that outperforms the next-best benchmark with 140.41% higher average refusal triggering rate across 9 LLMs, 34.86% greater lexical diversity, and 40.03% improved LLM response confidence scores; and EVOREFUSE-ALIGN, which provides 3,000 pseudo-malicious instructions with responses for supervised and preference-based alignment training. LLAMA3.1-8B-INSTRUCT supervisedly fine-tuned on EVOREFUSE-ALIGN achieves up to 14.31% fewer over-refusals than models trained on the second-best alignment dataset, without compromising safety. Our analysis with EVOREFUSE-TEST reveals models trigger over-refusals by overly focusing on sensitive keywords while ignoring broader context.', 'abstract_zh': '大型语言模型（LLMs）频繁拒绝伪恶意指令：由于保守的安全对齐导致语义上无害的输入查询触发不必要的拒绝，严重影响用户体验。收集此类指令对于评估和减轻过度拒绝至关重要，但现有指令策展方法，如手动创建或指令重写，要么缺乏扩展性，要么无法生成足够多样和有效的触发拒绝的提示。为解决这些局限性，我们引入了EVOREFUSE，这是一种提示优化方法，能够生成一致激发LLMs坚定拒绝的多样化伪恶意指令。EVOREFUSE采用进化算法，通过变异策略和重组探索更广泛的指令空间，并通过迭代进化种子指令来最大化LLM拒绝概率的下界证据。使用EVOREFUSE，我们创建了两个新型数据集：EVOREFUSE-TEST，包含582条伪恶意指令，其平均拒绝触发率和词缀多样性等指标优于其他基准数据集；EVOREFUSE-ALIGN，提供了3,000条伪恶意指令及其回复，用于监督和偏好对齐训练。基于EVOREFUSE-ALIGN进行监督微调的LLAMA3.1-8B-INSTRUCT模型在过度拒绝方面比基于次优对齐数据集训练的模型少14.31%，且不牺牲安全性。使用EVOREFUSE-TEST的分析表明，模型通过过度关注敏感关键词而忽视更广泛的上下文触发了过度拒绝。', 'title_zh': 'EVOREFUSE: 进化式提示优化以评估和减轻大模型对伪恶意指令过度拒绝的问题'}
{'arxiv_id': 'arXiv:2505.23436', 'title': 'Emergent Risk Awareness in Rational Agents under Resource Constraints', 'authors': 'Daniel Jarne Ornia, Nicholas Bishop, Joel Dyer, Wei-Chen Lee, Ani Calinescu, Doyne Farme, Michael Wooldridge', 'link': 'https://arxiv.org/abs/2505.23436', 'abstract': 'Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.', 'abstract_zh': '具备代理能力的高级推理模型（AI代理）被部署以与人类互动，并在（近似的）效用函数和内部模型指导下解决顺序决策问题。当这些问题存在资源或失败约束，使得行动序列可能在资源耗尽时被迫终止时，代理会面临隐含的权衡，这重新塑造了它们基于效用（理性）的行为。此外，由于这些代理通常由人类委托人代理执行任务，约束暴露的不对称性可能会导致人类目标与代理激励之间的先前未预见的错位。我们通过生存多臂-bandit框架来形式化这一环境，提供理论和实证结果来量化生存驱动的偏好转变的影响，并确定错位出现的条件，同时提出减轻风险寻求或风险规避行为出现的机制。因此，本研究旨在增加对在生存压力下操作的AI代理所出现行为的理解和可解释性，并提供此类AI系统在关键资源限制环境中安全部署的指南。', 'title_zh': '理性的代理在资源约束下的 emergent 风险意识'}
{'arxiv_id': 'arXiv:2505.23432', 'title': 'A Mathematical Framework for AI-Human Integration in Work', 'authors': 'Elisa Celis, Lingxiao Huang, Nisheeth K. Vishnoi', 'link': 'https://arxiv.org/abs/2505.23432', 'abstract': "The rapid rise of Generative AI (GenAI) tools has sparked debate over their role in complementing or replacing human workers across job contexts. We present a mathematical framework that models jobs, workers, and worker-job fit, introducing a novel decomposition of skills into decision-level and action-level subskills to reflect the complementary strengths of humans and GenAI. We analyze how changes in subskill abilities affect job success, identifying conditions for sharp transitions in success probability. We also establish sufficient conditions under which combining workers with complementary subskills significantly outperforms relying on a single worker. This explains phenomena such as productivity compression, where GenAI assistance yields larger gains for lower-skilled workers. We demonstrate the framework' s practicality using data from O*NET and Big-Bench Lite, aligning real-world data with our model via subskill-division methods. Our results highlight when and how GenAI complements human skills, rather than replacing them.", 'abstract_zh': '生成式人工智能工具的迅速崛起引发了对其在各类工作环境中补充或取代人类工人的角色的辩论。我们提出了一种数学框架，用于建模工作、工人及工人与工作匹配度，引入了一种新的技能拆分方法，将技能分解为决策级技能和行动级技能，以反映人类和生成式人工智能的互补优势。我们分析了子技能能力变化对工作成功率的影响，确定了成功率显著变化的条件。我们还建立了在哪些条件下具有互补子技能的工人组合会显著优于依赖单一工人的条件。这解释了生产率压缩现象，即生成式人工智能辅助带来更大的收益提升，尤其是对于低技能工人。我们使用O*NET和Big-Bench Lite的数据示证了该框架的实用性，并通过子技能划分方法将实际数据与模型相匹配。我们的结果强调了生成式人工智能在补充而非取代人类技能时的时机和方式。', 'title_zh': 'AI与人类工作的数学框架'}
{'arxiv_id': 'arXiv:2505.23399', 'title': 'GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning', 'authors': 'Jusheng Zhang, Yijia Fan, Wenjun Lin, Ruiqi Chen, Haoyi Jiang, Wenhao Chai, Jian Wang, Keze Wang', 'link': 'https://arxiv.org/abs/2505.23399', 'abstract': 'We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and V*Bench--demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances strong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.', 'abstract_zh': 'GAM-Agent：一种基于博弈论的多智能体框架以增强视觉-语言推理', 'title_zh': 'GAM-Agent: 基于博弈论和不确定性感知的复杂视觉推理协作'}
{'arxiv_id': 'arXiv:2505.23397', 'title': 'A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy', 'authors': 'Ahmad Mohsin, Helge Janicke, Ahmed Ibrahim, Iqbal H. Sarker, Seyit Camtepe', 'link': 'https://arxiv.org/abs/2505.23397', 'abstract': 'This article presents a structured framework for Human-AI collaboration in Security Operations Centers (SOCs), integrating AI autonomy, trust calibration, and Human-in-the-loop decision making. Existing frameworks in SOCs often focus narrowly on automation, lacking systematic structures to manage human oversight, trust calibration, and scalable autonomy with AI. Many assume static or binary autonomy settings, failing to account for the varied complexity, criticality, and risk across SOC tasks considering Humans and AI collaboration. To address these limitations, we propose a novel autonomy tiered framework grounded in five levels of AI autonomy from manual to fully autonomous, mapped to Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This enables adaptive and explainable AI integration across core SOC functions, including monitoring, protection, threat detection, alert triage, and incident response. The proposed framework differentiates itself from previous research by creating formal connections between autonomy, trust, and HITL across various SOC levels, which allows for adaptive task distribution according to operational complexity and associated risks. The framework is exemplified through a simulated cyber range that features the cybersecurity AI-Avatar, a fine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates human-AI collaboration for SOC tasks, reducing alert fatigue, enhancing response coordination, and strategically calibrating trust. This research systematically presents both the theoretical and practical aspects and feasibility of designing next-generation cognitive SOCs that leverage AI not to replace but to enhance human decision-making.', 'abstract_zh': '一种结构化的框架：在安全运营中心实现人类与人工智能的合作，结合人工智能自主性、信任校准及人工介入决策', 'title_zh': '安全运营中心中基于可信赖自主性的统一的人工智能协作框架'}
{'arxiv_id': 'arXiv:2505.23381', 'title': 'AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning', 'authors': 'Bowen Ping, Minnan Luo, Zhuohang Dang, Chenxi Wang, Chengyou Jia', 'link': 'https://arxiv.org/abs/2505.23381', 'abstract': "Geometry problem solving presents distinctive challenges in artificial intelligence, requiring exceptional multimodal comprehension and rigorous mathematical reasoning capabilities. Existing approaches typically fall into two categories: neural-based and symbolic-based methods, both of which exhibit limitations in reliability and interpretability. To address this challenge, we propose AutoGPS, a neuro-symbolic collaborative framework that solves geometry problems with concise, reliable, and human-interpretable reasoning processes. Specifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a Deductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal comprehension to translate geometry problems into structured formal language representations, with feedback from DSR collaboratively. The DSR takes the formalization as input and formulates geometry problem solving as a hypergraph expansion task, executing mathematically rigorous and reliable derivation to produce minimal and human-readable stepwise solutions. Extensive experimental evaluations demonstrate that AutoGPS achieves state-of-the-art performance on benchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms AutoGPS's impressive reliability and interpretability, with 99\\% stepwise logical coherence. The project homepage is at this https URL.", 'abstract_zh': '几何问题求解在人工智能中提出了独特的挑战，需要具备出色的多模态理解和严格的数学推理能力。现有方法通常分为基于神经网络和基于符号的方法，两者在可靠性和可解释性方面都存在局限性。为应对这一挑战，我们提出了一种名为AutoGPS的神经-符号协作框架，该框架能够以简洁、可靠且易于人类理解的推理过程解决几何问题。具体而言，AutoGPS采用了多模态问题形式化器（MPF）和演绎符号推理器（DSR）。MPF利用神经跨模态理解将几何问题转化为结构化的形式语言表示，并与DSR进行协作反馈。DSR以形式化结果为输入，将几何问题求解转化为超图扩张任务，执行严格的数学推理以生成简洁且易于理解的步骤解决方案。大量实验证明，AutoGPS在基准数据集上实现了最先进的性能。此外，人工步骤推理评估进一步证实了AutoGPS出色的可靠性和可解释性，其步骤逻辑连贯性达到99%。项目主页参见此 https URL。', 'title_zh': 'AutoGPS：通过多模态形式化和演绎推理实现的自动几何问题求解'}
{'arxiv_id': 'arXiv:2505.23281', 'title': 'MathArena: Evaluating LLMs on Uncontaminated Math Competitions', 'authors': 'Mislav Balunović, Jasper Dekoninck, Ivo Petrov, Nikola Jovanović, Martin Vechev', 'link': 'https://arxiv.org/abs/2505.23281', 'abstract': 'The rapid advancement of reasoning capabilities in large language models (LLMs) has led to notable improvements on mathematical benchmarks. However, many of the most commonly used evaluation datasets (e.g., AIME 2024) are widely available online, making it difficult to disentangle genuine reasoning from potential memorization. Furthermore, these benchmarks do not evaluate proof-writing capabilities, which are crucial for many mathematical tasks. To address this, we introduce MathArena, a new benchmark based on the following key insight: recurring math competitions provide a stream of high-quality, challenging problems that can be used for real-time evaluation of LLMs. By evaluating models as soon as new problems are released, we effectively eliminate the risk of contamination. Using this framework, we find strong signs of contamination in AIME 2024. Nonetheless, evaluations on harder competitions, such as SMT 2025 -- published well after model release dates -- demonstrate impressive reasoning capabilities in top-performing models. MathArena is also the first benchmark for proof-writing capabilities. On USAMO 2025, even top models score below 25%, far behind their performance on final-answer tasks. So far, we have evaluated 30 models across five competitions, totaling 149 problems. As an evolving benchmark, MathArena will continue to track the progress of LLMs on newly released competitions, ensuring rigorous and up-to-date evaluation of mathematical reasoning.', 'abstract_zh': '大型语言模型（LLMs）推理能力的快速进步在数学基准测试中取得了显著进步。然而，许多常用评价数据集（如AIME 2024）在网上广泛可用，这使得区分真正的推理能力和潜在的记忆能力变得困难。此外，这些基准测试没有评估证明写作能力，这对于许多数学任务至关重要。为了解决这个问题，我们引入了MathArena，这是一个基于以下关键洞察的新基准：频繁举办的数学竞赛提供了一系列高质量、具有挑战性的问题，可用于实时评估LLMs。通过在新问题发布时立即评估模型，我们有效地消除了污染的风险。使用这一框架，我们发现AIME 2024存在强烈的污染迹象。然而，在模型发布日期之后很久发布的更难的竞赛（如SMT 2025）的评估结果显示，顶级模型具有令人印象深刻的推理能力。MathArena也是首个评估证明写作能力的基准测试。在USAMO 2025中，即使是顶级模型也只有不到25%的得分，远远低于他们在最终答案任务中的表现。到目前为止，我们已经对五个竞赛中的30个模型进行了评估，共涉及149个问题。作为一个不断发展的基准测试，MathArena将继续跟踪新发布的竞赛中LLMs的进步，确保对数学推理的严格和及时评估。', 'title_zh': 'MathArena：评估LLM在未受污染的数学竞赛中的表现'}
{'arxiv_id': 'arXiv:2505.23153', 'title': 'Conceptual Framework Toward Embodied Collective Adaptive Intelligence', 'authors': 'Fan Wang, Shaoshan Liu', 'link': 'https://arxiv.org/abs/2505.23153', 'abstract': 'Collective Adaptive Intelligence (CAI) represent a transformative approach in artificial intelligence, wherein numerous autonomous agents collaborate, adapt, and self-organize to navigate complex, dynamic environments. This paradigm is particularly impactful in embodied AI applications, where adaptability and resilience are paramount. By enabling systems to reconfigure themselves in response to unforeseen challenges, CAI facilitate robust performance in real-world scenarios. This article introduces a conceptual framework for designing and analyzing CAI. It delineates key attributes including task generalization, resilience, scalability, and self-assembly, aiming to bridge theoretical foundations with practical methodologies for engineering adaptive, emergent intelligence. By providing a structured foundation for understanding and implementing CAI, this work seeks to guide researchers and practitioners in developing more resilient, scalable, and adaptable AI systems across various domains.', 'abstract_zh': '集体自适应智能 (CAI) 代表了人工智能领域的变革性方法，其中众多自主代理协作、适应和自组织以应对复杂多变的环境。这一范式在需要高度适应性和弹性的体现型人工智能应用中尤其具有影响力。通过使系统能够适应不可预见的挑战而重新配置自身，CAI 促进了在实际场景中实现稳健性能。本文引入了一个设计和分析CAI的概念框架，阐明了关键属性，包括任务泛化、韧性、可扩展性和自组装，旨在将理论基础与实用方法论联系起来，用于构建自适应和涌现智能系统。通过提供一个结构化的理解与实施CAI的基础，本文旨在指导研究人员和从业者在各个领域开发更具弹性的、可扩展的和自适应的人工智能系统。', 'title_zh': '面向 embodied集体适应性智能的概念框架'}
{'arxiv_id': 'arXiv:2505.23091', 'title': 'Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models', 'authors': 'Zeyu Liu, Yuhang Liu, Guanghao Zhu, Congkai Xie, Zhen Li, Jianbo Yuan, Xinyao Wang, Qing Li, Shing-Chi Cheung, Shengyu Zhang, Fei Wu, Hongxia Yang', 'link': 'https://arxiv.org/abs/2505.23091', 'abstract': "Recent advancements in large language models (LLMs) have demonstrated substantial progress in reasoning capabilities, such as DeepSeek-R1, which leverages rule-based reinforcement learning to enhance logical reasoning significantly. However, extending these achievements to multimodal large language models (MLLMs) presents critical challenges, which are frequently more pronounced for Multimodal Small Language Models (MSLMs) given their typically weaker foundational reasoning abilities: (1) the scarcity of high-quality multimodal reasoning datasets, (2) the degradation of reasoning capabilities due to the integration of visual processing, and (3) the risk that direct application of reinforcement learning may produce complex yet incorrect reasoning processes. To address these challenges, we design a novel framework Infi-MMR to systematically unlock the reasoning potential of MSLMs through a curriculum of three carefully structured phases and propose our multimodal reasoning model Infi-MMR-3B. The first phase, Foundational Reasoning Activation, leverages high-quality textual reasoning datasets to activate and strengthen the model's logical reasoning capabilities. The second phase, Cross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to facilitate the progressive transfer of reasoning skills to multimodal contexts. The third phase, Multimodal Reasoning Enhancement, employs curated, caption-free multimodal data to mitigate linguistic biases and promote robust cross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal math reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision test, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on MathVista testmini).", 'abstract_zh': 'Recent advancements in大规模语言模型（LLMs）在推理能力方面取得了显著进展，如DeepSeek-R1，它通过基于规则的强化学习显著增强了逻辑推理能力。然而，将这些成就扩展到多模态大规模语言模型（MLLMs）提出了关键挑战，对于通常基础推理能力较弱的多模态小型语言模型（MSLMs），这些挑战更为明显：（1）高质量多模态推理数据集的稀缺性，（2）由于结合视觉处理而导致推理能力下降，以及（3）直接应用强化学习可能导致复杂且错误的推理过程。为了解决这些挑战，我们设计了一种新的框架Infi-MMR，通过一个由三个精心设计的阶段组成的课程系统地解锁MSLMs的推理潜力，并提出我们的多模态推理模型Infi-MMR-3B。第一阶段，基础推理激活，利用高质量的文本推理数据集激活并强化模型的逻辑推理能力。第二阶段，跨模态推理适应，利用配有描述的多模态数据逐步转移推理技能到多模态上下文中。第三阶段，多模态推理增强，利用精心策划、无描述的多模态数据减轻语言偏差，促进稳健的跨模态推理。Infi-MMR-3B在多模态数学推理能力（MathVerse testmini：43.68%，MathVision test：27.04%，OlympiadBench：21.33%）和一般推理能力（MathVista testmini：67.2%）上均达到了最新的技术水平。', 'title_zh': '基于课程的学习分阶段强化学习解锁多模态小规模语言模型的多模态推理'}
{'arxiv_id': 'arXiv:2505.23075', 'title': 'Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble', 'authors': 'Amit Kumthekar, Zion Tilley, Henry Duong, Bhargav Patel, Michael Magnoli, Ahmed Omar, Ahmed Nasser, Chaitanya Gharpure, Yevgen Reztzov', 'link': 'https://arxiv.org/abs/2505.23075', 'abstract': "Despite the growing clinical adoption of large language models (LLMs), current approaches heavily rely on single model architectures. To overcome risks of obsolescence and rigid dependence on single model systems, we present a novel framework, termed the Consensus Mechanism. Mimicking clinical triage and multidisciplinary clinical decision-making, the Consensus Mechanism implements an ensemble of specialized medical expert agents enabling improved clinical decision making while maintaining robust adaptability. This architecture enables the Consensus Mechanism to be optimized for cost, latency, or performance, purely based on its interior model configuration.\nTo rigorously evaluate the Consensus Mechanism, we employed three medical evaluation benchmarks: MedMCQA, MedQA, and MedXpertQA Text, and the differential diagnosis dataset, DDX+. On MedXpertQA, the Consensus Mechanism achieved an accuracy of 61.0% compared to 53.5% and 45.9% for OpenAI's O3 and Google's Gemini 2.5 Pro. Improvement was consistent across benchmarks with an increase in accuracy on MedQA ($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 3.4\\%$) and MedMCQA ($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 9.1\\%$). These accuracy gains extended to differential diagnosis generation, where our system demonstrated improved recall and precision (F1$_\\mathrm{consensus}$ = 0.326 vs. F1$_{\\mathrm{O3\\text{-}high}}$ = 0.2886) and a higher top-1 accuracy for DDX (Top1$_\\mathrm{consensus}$ = 52.0% vs. Top1$_{\\mathrm{O3\\text{-}high}}$ = 45.2%).", 'abstract_zh': '尽管大型语言模型在临床领域的应用日益增长，当前的方法主要依赖于单一模型架构。为克服过时风险和对单一模型系统的刚性依赖，我们提出了一种新颖的框架，称为共识机制。该机制模仿临床分诊和多学科临床决策过程，通过实施一系列专门的医疗专家代理，实现临床决策的改进和持续的适应性。这种架构使得共识机制可以根据其内部模型配置优化成本、延迟或性能。\n\n为了严谨地评估共识机制，我们采用了三个医学评估基准：MedMCQA、MedQA、MedXpertQA Text，以及差异诊断数据集DDX+。在MedXpertQA上，共识机制的准确率为61.0%，而OpenAI的O3和Google的Gemini 2.5 Pro的准确率分别为53.5%和45.9%。在各个基准测试中，准确率均有提升，MedQA上的准确率提高了3.4个百分点，MedMCQA上的准确率提高了9.1个百分点。这些准确率的提升还体现在差异诊断生成上，我们的系统显示了更好的召回率和精确度（F1$_\\mathrm{consensus}$ = 0.326 vs. F1$_{\\mathrm{O3\\text{-}high}}$ = 0.2886），以及DDX的 top-1 准确率（Top1$_\\mathrm{consensus}$ = 52.0% vs. Top1$_{\\mathrm{O3\\text{-}high}}$ = 45.2%）。', 'title_zh': '第二意见很重要：通过专家模型ensemble的共识 toward自适应临床AI'}
{'arxiv_id': 'arXiv:2505.23058', 'title': 'Be.FM: Open Foundation Models for Human Behavior', 'authors': 'Yutong Xie, Zhuoheng Li, Xiyuan Wang, Yijun Pan, Qijia Liu, Xingzhi Cui, Kuang-Yu Lo, Ruoyi Gao, Xingjian Zhang, Jin Huang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei', 'link': 'https://arxiv.org/abs/2505.23058', 'abstract': 'Despite their success in numerous fields, the potential of foundation models for modeling and understanding human behavior remains largely unexplored. We introduce this http URL, one of the first open foundation models designed for human behavior modeling. Built upon open-source large language models and fine-tuned on a diverse range of behavioral data, this http URL can be used to understand and predict human decision-making. We construct a comprehensive set of benchmark tasks for testing the capabilities of behavioral foundation models. Our results demonstrate that this http URL can predict behaviors, infer characteristics of individuals and populations, generate insights about contexts, and apply behavioral science knowledge.', 'abstract_zh': '尽管基础模型在众多领域取得了成功，但其在建模和理解人类行为方面的潜力尚未得到充分探索。我们介绍了此httpURL，这是首个为人类行为建模设计的开源基础模型。基于开源大型语言模型并针对多种行为数据进行微调，此httpURL可用于理解与预测人类决策。我们构建了一套全面的基准任务以测试行为基础模型的能力。我们的结果显示，此httpURL可以预测行为、推断个体和群体的特点、生成关于情境的见解，并应用行为科学知识。', 'title_zh': 'Be.FM: 开放基础模型人类行为'}
{'arxiv_id': 'arXiv:2505.23034', 'title': 'Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction', 'authors': 'Guangyi Liu, Yongqi Zhang, Xunyuan Liu, Quanming Yao', 'link': 'https://arxiv.org/abs/2505.23034', 'abstract': 'Drug-drug interaction (DDI) prediction is critical for treatment safety. While large language models (LLMs) show promise in pharmaceutical tasks, their effectiveness in DDI prediction remains challenging. Inspired by the well-established clinical practice where physicians routinely reference similar historical cases to guide their decisions through case-based reasoning (CBR), we propose CBR-DDI, a novel framework that distills pharmacological principles from historical cases to improve LLM reasoning for DDI tasks. CBR-DDI constructs a knowledge repository by leveraging LLMs to extract pharmacological insights and graph neural networks (GNNs) to model drug associations. A hybrid retrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs to effectively retrieve and reuse relevant cases. We further introduce a representative sampling strategy for dynamic case refinement. Extensive experiments demonstrate that CBR-DDI achieves state-of-the-art performance, with a significant 28.7% accuracy improvement over both popular LLMs and CBR baseline, while maintaining high interpretability and flexibility.', 'abstract_zh': '基于案例推理的药物-药物相互作用预测：CBR-DDI框架', 'title_zh': '基于案例推理增强LLMs在药物相互作用预测中的预测能力'}
{'arxiv_id': 'arXiv:2505.22990', 'title': 'MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design', 'authors': 'Pin-Han Chen, Yu-Sheng Lin, Wei-Cheng Lee, Tin-Yu Leu, Po-Hsiang Hsu, Anjana Dissanayake, Sungjin Oh, Chinq-Shiun Chiu', 'link': 'https://arxiv.org/abs/2505.22990', 'abstract': 'RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future "RF/Analog Copilots" that can collaborate seamlessly with human designers.', 'abstract_zh': 'RF/模拟设计对于将数字技术与现实世界信号连接起来至关重要，确保了广泛电子系统的功能性和可靠性。然而，模拟设计过程往往复杂、耗时且依赖于专家直觉，阻碍了电路开发的时间和成本效率。为克服手工电路设计的局限性，我们引入了MenTeR——一个集成于端到端模拟设计框架中的多智能体工作流。通过多个专门的AI代理协同解决设计过程中的不同方面，如规范理解、电路优化和测试台验证，MenTeR减少了频繁尝试错误的干预需求。MenTeR不仅加速了设计周期，还促进了更广泛的设计空间探索，展示了处理真实世界模拟系统的稳健能力。我们相信，MenTeR为未来的“RF/模拟副驾”奠定了基础，这些“副驾”能够与人类设计师无缝协作。', 'title_zh': 'MenTeR: 一个全自动多代理工作流用于端到端射频/模拟电路网表设计'}
{'arxiv_id': 'arXiv:2505.22987', 'title': 'Strategic Reflectivism In Intelligent Systems', 'authors': 'Nick Byrd', 'link': 'https://arxiv.org/abs/2505.22987', 'abstract': 'By late 20th century, the rationality wars had launched debates about the nature and norms of intuitive and reflective thinking. Those debates drew from mid-20th century ideas such as bounded rationality, which challenged more idealized notions of rationality observed since the 19th century. Now that 21st century cognitive scientists are applying the resulting dual process theories to artificial intelligence, it is time to dust off some lessons from this history. So this paper synthesizes old ideas with recent results from experiments on humans and machines. The result is Strategic Reflectivism, which takes the position that one key to intelligent systems (human or artificial) is pragmatic switching between intuitive and reflective inference to optimally fulfill competing goals. Strategic Reflectivism builds on American Pragmatism, transcends superficial indicators of reflective thinking such as model size or chains of thought, and becomes increasingly actionable as we learn more about the value of intuition and reflection.', 'abstract_zh': '21世纪认知科学视角下的战略反思主义：智能系统中的直觉与反思平衡策略', 'title_zh': '智能系统中的战略性反思主义'}
{'arxiv_id': 'arXiv:2505.22960', 'title': 'Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness', 'authors': 'Yongjin Yang, Euiin Yi, Jongwoo Ko, Kimin Lee, Zhijing Jin, Se-Young Yun', 'link': 'https://arxiv.org/abs/2505.22960', 'abstract': "The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.", 'abstract_zh': '大型语言模型（LLM）能力的显著增长促进了多智能体系统的研究，辩论框架作为增强问题解决能力的一种有前途的方法逐渐引起关注。尽管之前的研究已经采用了多智能体辩论（MAD）方法，但其相对于自我智能体方法的有效性，特别是在不同条件下的系统性理解仍然不足。本文旨在通过将MAD概念化为测试时的计算扩展技术，系统地研究任务难度、模型规模和智能体多样性对MAD性能的影响。研究发现，对于数学推理任务，MAD相对于自我智能体扩展的优势有限，但在问题难度增加和模型能力下降时表现更佳，而智能体多样性对性能提升作用不大。而对于安全任务，MAD的协作完善可能会增加脆弱性，但引入多样化的智能体配置可以通过协作完善过程逐步降低攻击成功率。我们相信，这些发现为未来更有效和策略性部署MAD系统提供了重要的指导。', 'title_zh': '重访多agent辩论作为测试时扩展的条件有效性系统研究'}
{'arxiv_id': 'arXiv:2505.22954', 'title': 'Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents', 'authors': 'Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune', 'link': 'https://arxiv.org/abs/2505.22954', 'abstract': "Today's AI systems have human-designed, fixed architectures and cannot autonomously and continuously improve themselves. The advance of AI could itself be automated. If done safely, that would accelerate AI development and allow us to reap its benefits much sooner. Meta-learning can automate the discovery of novel algorithms, but is limited by first-order improvements and the human design of a suitable search space. The Gödel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner. Unfortunately, proving that most changes are net beneficial is impossible in practice. We introduce the Darwin Gödel Machine (DGM), a self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks. Inspired by Darwinian evolution and open-endedness research, the DGM maintains an archive of generated coding agents. It grows the archive by sampling an agent from it and using a foundation model to create a new, interesting, version of the sampled agent. This open-ended exploration forms a growing tree of diverse, high-quality agents and allows the parallel exploration of many different paths through the search space. Empirically, the DGM automatically improves its coding capabilities (e.g., better code editing tools, long-context window management, peer-review mechanisms), increasing performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly outperforms baselines without self-improvement or open-ended exploration. All experiments were done with safety precautions (e.g., sandboxing, human oversight). The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.", 'abstract_zh': '自适应 Gö德尔机器：基于Darwinian演化的自改进系统', 'title_zh': '达尔文哥德尔机器：自我改进代理的开放-ended 进化'}
{'arxiv_id': 'arXiv:2505.22948', 'title': 'Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages', 'authors': 'Michael Sun, Weize Yuan, Gang Liu, Wojciech Matusik, Jie Chen', 'link': 'https://arxiv.org/abs/2505.22948', 'abstract': 'Recent data-efficient molecular generation approaches exploit graph grammars to introduce interpretability into the generative models. However, grammar learning therein relies on expert annotation or unreliable heuristics for algorithmic inference. We propose Foundation Molecular Grammar (FMG), which leverages multi-modal foundation models (MMFMs) to induce an interpretable molecular language. By exploiting the chemical knowledge of an MMFM, FMG renders molecules as images, describes them as text, and aligns information across modalities using prompt learning. FMG can be used as a drop-in replacement for the prior grammar learning approaches in molecular generation and property prediction. We show that FMG not only excels in synthesizability, diversity, and data efficiency but also offers built-in chemical interpretability for automated molecular discovery workflows. Code is available at this https URL.', 'abstract_zh': '近期高效数据驱动分子生成方法利用图语法在生成模型中引入可解释性。然而，其中的语法学习依赖于专家标注或不可靠的启发式算法推断。我们提出了一种基础分子语法（FMG），它利用多模态基础模型（MMFM）诱导可解释的分子语言。通过利用MMFM的化学知识，FMG将分子呈现为图像，用文本描述它们，并通过提示学习在不同模态之间对齐信息。FMG可以作为先前的语法学习方法在分子生成和性质预测中的即插即用替代方案。我们表明，FMG在合成能力、多样性和数据效率方面表现出色，并为自动分子发现工作流程提供内置的化学可解释性。代码详见此链接。', 'title_zh': '基础分子语法：多模态基础模型诱导可解释的分子图语言'}
{'arxiv_id': 'arXiv:2505.22928', 'title': 'Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning', 'authors': 'Massimiliano Pronesti, Michela Lorandi, Paul Flanagan, Oisin Redmon, Anya Belz, Yufang Hou', 'link': 'https://arxiv.org/abs/2505.22928', 'abstract': 'Systematic reviews in medicine play a critical role in evidence-based decision-making by aggregating findings from multiple studies. A central bottleneck in automating this process is extracting numeric evidence and determining study-level conclusions for specific outcomes and comparisons. Prior work has framed this problem as a textual inference task by retrieving relevant content fragments and inferring conclusions from them. However, such approaches often rely on shallow textual cues and fail to capture the underlying numeric reasoning behind expert assessments.\nIn this work, we conceptualise the problem as one of quantitative reasoning. Rather than inferring conclusions from surface text, we extract structured numerical evidence (e.g., event counts or standard deviations) and apply domain knowledge informed logic to derive outcome-specific conclusions. We develop a numeric reasoning system composed of a numeric data extraction model and an effect estimate component, enabling more accurate and interpretable inference aligned with the domain expert principles. We train the numeric data extraction model using different strategies, including supervised fine-tuning (SFT) and reinforcement learning (RL) with a new value reward model.\nWhen evaluated on the CochraneForest benchmark, our best-performing approach -- using RL to train a small-scale number extraction model -- yields up to a 21% absolute improvement in F1 score over retrieval-based systems and outperforms general-purpose LLMs of over 400B parameters by up to 9%. Our results demonstrate the promise of reasoning-driven approaches for automating systematic evidence synthesis.', 'abstract_zh': '医学领域的系统评价在证据-Based决策中起到了关键作用，通过聚合多个研究的发现来实现。自动化这一过程的主要瓶颈在于提取数值证据并确定特定结局和比较的研究所级结论。此前的工作将这一问题视为文本推理任务，通过检索相关的内容片段并从中推断结论。然而，这些方法往往依赖于浅层次的文本线索，未能捕捉到专家评估背后的潜在数值逻辑。\n\n在本研究所中，我们将问题视为定量推理问题。我们不是从表面文本中推断结论，而是提取结构化的数值证据（例如，事件计数或标准差），并应用基于领域知识的逻辑以推导出特定结局的结论。我们开发了一个由数值数据提取模型和效应估计组件组成的数值推理系统，以实现与领域专家原理更准确和可解释的推理。我们使用不同的策略训练数值数据提取模型，包括监督微调（SFT）和带有新价值奖励模型的强化学习（RL）。\n\n在CochraneForest基准上的评估表明，我们的最佳方法——使用RL训练小型数值提取模型——在F1分数上比基于检索的方法提高了高达21%，并优于超过400亿参数的一般用途LLM多达9%。我们的结果表明，基于推理的方法在自动化系统性证据合成方面具有巨大潜力。', 'title_zh': '基于RL的数值推理增强临床试验论文的研究所级别推断'}
{'arxiv_id': 'arXiv:2505.22871', 'title': 'The WHY in Business Processes: Unification of Causal Process Models', 'authors': 'Yuval David, Fabiana Fournier, Lior Limonad, Inna Skarbovsky', 'link': 'https://arxiv.org/abs/2505.22871', 'abstract': 'Causal reasoning is essential for business process interventions and improvement, requiring a clear understanding of causal relationships among activity execution times in an event log. Recent work introduced a method for discovering causal process models but lacked the ability to capture alternating causal conditions across multiple variants. This raises the challenges of handling missing values and expressing the alternating conditions among log splits when blending traces with varying activities.\nWe propose a novel method to unify multiple causal process variants into a consistent model that preserves the correctness of the original causal models, while explicitly representing their causal-flow alternations. The method is formally defined, proved, evaluated on three open and two proprietary datasets, and released as an open-source implementation.', 'abstract_zh': '因果推理对于业务过程干预和改进是必要的，要求对事件日志中活动执行时间之间的因果关系有清晰的理解。最近的研究引入了一种发现因果过程模型的方法，但缺乏捕捉多个变体中交替因果条件的能力。这提出了处理缺失值和在混合具有不同活动的日志片段时表达交替条件的挑战。我们提出了一种新颖的方法，将多个因果过程变体统一为一个一致的模型，同时明确表示它们的因果流变异性。该方法形式化定义、证明，并在三个公开和两个专有数据集上进行评估，开源实现已发布。', 'title_zh': '商业流程中的“为什么”：因果流程模型的统一'}
{'arxiv_id': 'arXiv:2505.22779', 'title': 'Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds', 'authors': 'Mohammad Helal Uddin, Sabur Baidya', 'link': 'https://arxiv.org/abs/2505.22779', 'abstract': "Mental disorders including depression, anxiety, and other neurological disorders pose a significant global challenge, particularly among individuals exhibiting social avoidance tendencies. This study proposes a hybrid approach by leveraging smartphone sensor data measuring daily physical activities and analyzing their social media (Twitter) interactions for evaluating an individual's depression level. Using CNN-based deep learning models and Naive Bayes classification, we identify human physical activities accurately and also classify the user sentiments. A total of 33 participants were recruited for data acquisition, and nine relevant features were extracted from the physical activities and analyzed with their weekly depression scores, evaluated using the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six are derived from physical activities, achieving an activity recognition accuracy of 95%, while three features stem from sentiment analysis of Twitter activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several physical activity features exhibited significant correlations with the severity of depression symptoms. For classifying the depression severity, a support vector machine (SVM)-based algorithm is employed that demonstrated a very high accuracy of 94%, outperforming alternative models, e.g., the multilayer perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly effective in the long run for monitoring depression without breaching personal privacy.", 'abstract_zh': '智能手机传感器数据和社交媒体互动分析在评估抑郁水平中的混合方法研究', 'title_zh': '利用物理活动感应和社会媒体 feed 的混合数据采集预测人类抑郁'}
{'arxiv_id': 'arXiv:2505.22756', 'title': 'Decomposing Elements of Problem Solving: What "Math" Does RL Teach?', 'authors': 'Tian Qin, Core Francisco Park, Mujin Kwun, Aaron Walsman, Eran Malach, Nikhil Anand, Hidenori Tanaka, David Alvarez-Melis', 'link': 'https://arxiv.org/abs/2505.22756', 'abstract': "Mathematical reasoning tasks have become prominent benchmarks for assessing the reasoning capabilities of LLMs, especially with reinforcement learning (RL) methods such as GRPO showing significant performance gains. However, accuracy metrics alone do not support fine-grained assessment of capabilities and fail to reveal which problem-solving skills have been internalized. To better understand these capabilities, we propose to decompose problem solving into fundamental capabilities: Plan (mapping questions to sequences of steps), Execute (correctly performing solution steps), and Verify (identifying the correctness of a solution). Empirically, we find that GRPO mainly enhances the execution skill-improving execution robustness on problems the model already knows how to solve-a phenomenon we call temperature distillation. More importantly, we show that RL-trained models struggle with fundamentally new problems, hitting a 'coverage wall' due to insufficient planning skills. To explore RL's impact more deeply, we construct a minimal, synthetic solution-tree navigation task as an analogy for mathematical problem-solving. This controlled setup replicates our empirical findings, confirming RL primarily boosts execution robustness. Importantly, in this setting, we identify conditions under which RL can potentially overcome the coverage wall through improved exploration and generalization to new solution paths. Our findings provide insights into the role of RL in enhancing LLM reasoning, expose key limitations, and suggest a path toward overcoming these barriers. Code is available at this https URL.", 'abstract_zh': '数学推理任务已成为评估大规模语言模型推理能力的重要基准，尤其是在使用强化学习方法（如GRPO）时表现出显著的性能提升。然而，仅依赖准确性指标无法进行精细的能力评估，也无法揭示模型已掌握的问题解决技能。为更好地理解这些能力，我们提出将问题解决分解为基本能力：规划（将问题映射为步骤序列）、执行（正确执行解决方案步骤）和验证（识别解决方案的正确性）。通过实证研究，我们发现GRPO主要增强了执行技能，提高了模型已知问题上的执行稳健性，我们将其称为温度蒸馏效应。更为重要的是，我们展示了RL训练的模型在面对根本性的新问题时面临‘覆盖障碍墙’，这是因为规划技能不足导致的。为了更深入地探索RL的影响，我们构建了一个简约的合成解决方案树导航任务，作为数学问题解决的类比。这一受控设置重复了我们的实证发现，证实了RL主要提升了执行稳健性。在这一设置中，我们确定了RL可能通过改进探索和泛化到新的解决方案路径来克服覆盖障碍墙的条件。我们的发现提供了关于RL在提升LLM推理能力中的作用、揭示关键限制以及克服这些障碍的路径的见解。代码可在以下链接获取。', 'title_zh': '问题求解要素分解：数学为 RL 教授了什么？'}
{'arxiv_id': 'arXiv:2505.22753', 'title': 'Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields', 'authors': 'Arseniy Pertzovsky, Roni Stern, Ariel Felner, Roie Zivan', 'link': 'https://arxiv.org/abs/2505.22753', 'abstract': 'We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.', 'abstract_zh': '我们探讨了使用人工势场（APFs）解决多代理路径规划（MAPF）和终身多代理路径规划（LMAPF）问题的方法。在MAPF中，一组代理必须在不发生碰撞的情况下移动到其目标位置，而在LMAPF中，新的目标会在到达当前目标后生成。我们提出了在多种MAPF算法中结合使用APFs的方法，包括优先级规划、MAPF-LNS2以及优先级继承带回溯（PIBT）。实验结果表明，对于MAPF，使用APFs并无优势，但在LMAPF中可以将整个系统吞吐量提高多达7倍。', 'title_zh': '使用人工势场方法增强终身多代理路径规划'}
{'arxiv_id': 'arXiv:2505.22698', 'title': 'Design and testing of an agent chatbot supporting decision making with public transport data', 'authors': 'Luca Fantin, Marco Antonelli, Margherita Cesetti, Daniele Irto, Bruno Zamengo, Francesco Silvestri', 'link': 'https://arxiv.org/abs/2505.22698', 'abstract': "Assessing the quality of public transportation services requires the analysis of large quantities of data on the scheduled and actual trips and documents listing the quality constraints each service needs to meet. Interrogating such datasets with SQL queries, organizing and visualizing the data can be quite complex for most users. This paper presents a chatbot offering a user-friendly tool to interact with these datasets and support decision making. It is based on an agent architecture, which expands the capabilities of the core Large Language Model (LLM) by allowing it to interact with a series of tools that can execute several tasks, like performing SQL queries, plotting data and creating maps from the coordinates of a trip and its stops. This paper also tackles one of the main open problems of such Generative AI projects: collecting data to measure the system's performance. Our chatbot has been extensively tested with a workflow that asks several questions and stores the generated query, the retrieved data and the natural language response for each of them. Such questions are drawn from a set of base examples which are then completed with actual data from the database. This procedure yields a dataset for the evaluation of the chatbot's performance, especially the consistency of its answers and the correctness of the generated queries.", 'abstract_zh': '评估公共 transportation 服务的质量需要分析大量关于计划和实际行程以及列出的服务需要满足的质量约束的数据集。对这类数据集使用 SQL 查询进行查询、组织和可视化通常对于大多数用户来说都相当复杂。本文介绍了一个聊天机器人，提供了一个用户友好的工具来与这些数据集交互并支持决策制定。该聊天机器人基于代理架构，通过允许核心大规模语言模型 (LLM) 与一系列工具交互来扩展其功能，这些工具可以执行多个任务，如执行 SQL 查询、绘制数据和根据行程及其停靠点的坐标创建地图。本文还解决了一个生成式 AI 项目的主要开放问题之一：收集数据以衡量系统性能。我们的聊天机器人经过广泛测试，通过一个工作流提出多个问题并存储生成的查询、检索的数据以及每个问题的自然语言响应。这些问题是从一组基本示例中抽取出来的，并通过数据库的实际数据加以补充。这一过程产生了一个用于评估聊天机器人性能的数据集，特别是其答案的一致性和生成查询的正确性。', 'title_zh': '基于公共运输数据支持决策的智能代理聊天机器人设计与测试'}
{'arxiv_id': 'arXiv:2505.23765', 'title': 'From Chat Logs to Collective Insights: Aggregative Question Answering', 'authors': 'Wentao Zhang, Woojeong Kim, Yuntian Deng', 'link': 'https://arxiv.org/abs/2505.23765', 'abstract': 'Conversational agents powered by large language models (LLMs) are rapidly becoming integral to our daily interactions, generating unprecedented amounts of conversational data. Such datasets offer a powerful lens into societal interests, trending topics, and collective concerns. Yet, existing approaches typically treat these interactions as independent and miss critical insights that could emerge from aggregating and reasoning across large-scale conversation logs. In this paper, we introduce Aggregative Question Answering, a novel task requiring models to reason explicitly over thousands of user-chatbot interactions to answer aggregative queries, such as identifying emerging concerns among specific demographics. To enable research in this direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative questions derived from 182,330 real-world chatbot conversations. Experiments show that existing methods either struggle to reason effectively or incur prohibitive computational costs, underscoring the need for new approaches capable of extracting collective insights from large-scale conversational data.', 'abstract_zh': '由大型语言模型驱动的对话代理正迅速成为我们日常互动的一部分，生成前所未有的对话数据量。此类数据集提供了洞察社会兴趣、热门话题和集体关切的有力视角。然而，现有方法通常将这些互动视为独立的，未能从汇总和跨大规模对话日志进行推理中获得关键见解。在本文中，我们引入了聚合型问答任务，要求模型明确地在数千条用户-聊天机器人交互中进行推理以回答聚合性查询，如识别特定人口统计学群体中的新兴关切。为了促进该方向的研究，我们构建了WildChat-AQA基准测试，包含6,027个聚合性问题，这些问题源自182,330次真实的聊天机器人对话。实验表明，现有方法要么难以有效推理，要么需要付出高昂的计算成本，突显了需要新方法从大规模对话数据中提取集体见解的必要性。', 'title_zh': '从聊天日志到集体洞察：聚合性问答'}
{'arxiv_id': 'arXiv:2505.23761', 'title': 'Differential Information: An Information-Theoretic Perspective on Preference Optimization', 'authors': 'Yunjae Won, Hyunji Lee, Hyeonbin Hwang, Minjoon Seo', 'link': 'https://arxiv.org/abs/2505.23761', 'abstract': 'Direct Preference Optimization (DPO) has become a standard technique for aligning language models with human preferences in a supervised manner. Despite its empirical success, the theoretical justification behind its log-ratio reward parameterization remains incomplete. In this work, we address this gap by utilizing the Differential Information Distribution (DID): a distribution over token sequences that captures the information gained during policy updates. First, we show that when preference labels encode the differential information required to transform a reference policy into a target policy, the log-ratio reward in DPO emerges as the uniquely optimal form for learning the target policy via preference optimization. This result naturally yields a closed-form expression for the optimal sampling distribution over rejected responses. Second, we find that the condition for preferences to encode differential information is fundamentally linked to an implicit assumption regarding log-margin ordered policies-an inductive bias widely used in preference optimization yet previously unrecognized. Finally, by analyzing the entropy of the DID, we characterize how learning low-entropy differential information reinforces the policy distribution, while high-entropy differential information induces a smoothing effect, which explains the log-likelihood displacement phenomenon. We validate our theoretical findings in synthetic experiments and extend them to real-world instruction-following datasets. Our results suggest that learning high-entropy differential information is crucial for general instruction-following, while learning low-entropy differential information benefits knowledge-intensive question answering. Overall, our work presents a unifying perspective on the DPO objective, the structure of preference data, and resulting policy behaviors through the lens of differential information.', 'abstract_zh': '直接偏好优化（DPO）已成为通过监督方式使语言模型与人类偏好对齐的标准技术。尽管它在实践上获得了成功，但其使用对数比率奖励参数化的理论依据仍不完备。在本文中，我们通过利用微分信息分布（DID）——一种捕捉策略更新过程中获得的信息的token序列分布——来填补这一缺口。首先，我们表明，当偏好标签编码了将基准策略转化为目标策略所需的微分信息时，DPO中的对数比率奖励将以唯一最优的形式出现，从而通过偏好优化学习目标策略。这一结果自然地导出了在拒绝响应上最优采样分布的闭式表达式。其次，我们发现偏好编码微分信息的条件与一个隐含假设密切相关，即对数边距排序策略的归纳偏见——这一偏见在偏好优化中广泛使用但此前未被认识。最后，通过对DID的熵进行分析，我们刻画了学习低熵微分信息如何强化策略分布，而高熵微分信息又如何产生平滑效应，解释了对数似然位移现象。我们在合成实验中验证了我们的理论发现，并扩展到了真实的指令遵循数据集上。我们的结果表明，学习高熵微分信息对于通用指令遵循至关重要，而学习低熵微分信息则有利于知识密集型问答任务。总体而言，我们的工作从微分信息的角度提供了一种统一的DPO目标、偏好数据结构及其导致的策略行为的视角。', 'title_zh': '差异信息：从信息论视角探讨偏好优化'}
{'arxiv_id': 'arXiv:2505.23759', 'title': "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", 'authors': 'Heekyung Lee, Jiaxin Ge, Tsung-Han Wu, Minwoo Kang, Trevor Darrell, David M. Chan', 'link': 'https://arxiv.org/abs/2505.23759', 'abstract': 'Rebus puzzles, visual riddles that encode language through imagery, spatial arrangement, and symbolic substitution, pose a unique challenge to current vision-language models (VLMs). Unlike traditional image captioning or question answering tasks, rebus solving requires multi-modal abstraction, symbolic reasoning, and a grasp of cultural, phonetic and linguistic puns. In this paper, we investigate the capacity of contemporary VLMs to interpret and solve rebus puzzles by constructing a hand-generated and annotated benchmark of diverse English-language rebus puzzles, ranging from simple pictographic substitutions to spatially-dependent cues ("head" over "heels"). We analyze how different VLMs perform, and our findings reveal that while VLMs exhibit some surprising capabilities in decoding simple visual clues, they struggle significantly with tasks requiring abstract reasoning, lateral thinking, and understanding visual metaphors.', 'abstract_zh': '图像谜题：通过图像、空间布局和象征替代编码语言的视觉谜题，对当前视觉-语言模型（VLMs）构成了独特的挑战。', 'title_zh': '困惑于谜题：当视觉-语言模型无法得到提示时'}
{'arxiv_id': 'arXiv:2505.23754', 'title': 'DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning', 'authors': 'Ziyin Zhang, Jiahao Xu, Zhiwei He, Tian Liang, Qiuzhi Liu, Yansi Li, Linfeng Song, Zhengwen Liang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu', 'link': 'https://arxiv.org/abs/2505.23754', 'abstract': "Theorem proving serves as a major testbed for evaluating complex reasoning abilities in large language models (LLMs). However, traditional automated theorem proving (ATP) approaches rely heavily on formal proof systems that poorly align with LLMs' strength derived from informal, natural language knowledge acquired during pre-training. In this work, we propose DeepTheorem, a comprehensive informal theorem-proving framework exploiting natural language to enhance LLM mathematical reasoning. DeepTheorem includes a large-scale benchmark dataset consisting of 121K high-quality IMO-level informal theorems and proofs spanning diverse mathematical domains, rigorously annotated for correctness, difficulty, and topic categories, accompanied by systematically constructed verifiable theorem variants. We devise a novel reinforcement learning strategy (RL-Zero) explicitly tailored to informal theorem proving, leveraging the verified theorem variants to incentivize robust mathematical inference. Additionally, we propose comprehensive outcome and process evaluation metrics examining proof correctness and the quality of reasoning steps. Extensive experimental analyses demonstrate DeepTheorem significantly improves LLM theorem-proving performance compared to existing datasets and supervised fine-tuning protocols, achieving state-of-the-art accuracy and reasoning quality. Our findings highlight DeepTheorem's potential to fundamentally advance automated informal theorem proving and mathematical exploration.", 'abstract_zh': 'DeepTheorem：一种利用自然语言增强大规模语言模型数学推理的全面非形式定理证明框架', 'title_zh': 'DeepTheorem: 通过自然语言和强化学习推动大规模语言模型证明定理的能力'}
{'arxiv_id': 'arXiv:2505.23751', 'title': 'REOrdering Patches Improves Vision Models', 'authors': 'Declan Kutscher, David M. Chan, Yutong Bai, Trevor Darrell, Ritwik Gupta', 'link': 'https://arxiv.org/abs/2505.23751', 'abstract': 'Sequence models such as transformers require inputs to be represented as one-dimensional sequences. In vision, this typically involves flattening images using a fixed row-major (raster-scan) order. While full self-attention is permutation-equivariant, modern long-sequence transformers increasingly rely on architectural approximations that break this invariance and introduce sensitivity to patch ordering. We show that patch order significantly affects model performance in such settings, with simple alternatives like column-major or Hilbert curves yielding notable accuracy shifts. Motivated by this, we propose REOrder, a two-stage framework for discovering task-optimal patch orderings. First, we derive an information-theoretic prior by evaluating the compressibility of various patch sequences. Then, we learn a policy over permutations by optimizing a Plackett-Luce policy using REINFORCE. This approach enables efficient learning in a combinatorial permutation space. REOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to 3.01% and Functional Map of the World by 13.35%.', 'abstract_zh': '序列模型如变压器需要将输入表示为一维序列。在视觉领域，这通常涉及使用固定行-major（栅格扫描）顺序展开图像。虽然全自注意力是置换不变的，但现代长序列变压器越来越多地依赖于打破这一不变性的架构近似，从而引入了对块顺序的敏感性。我们表明，在这种情况下，块顺序显著影响模型性能，简单的替代方案如列-major或希尔伯特曲线可以带来显著的准确性变化。受此启发，我们提出了REOrder，一种发现任务最优块顺序的两阶段框架。首先，我们通过评估各种块序列的可压缩性推导出信息论先验。然后，通过使用REINFORCE优化Plackett-Luce策略来学习置换策略。这种方法能够在组合置换空间中实现高效的 Learning。REOrder在ImageNet-1K上的Top-1准确性上提高了最多3.01%，在Functional Map of the World上的准确性上提高了13.35%。', 'title_zh': 'REOrdering Patches Improves Vision Models'}
{'arxiv_id': 'arXiv:2505.23747', 'title': 'Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence', 'authors': 'Diankun Wu, Fangfu Liu, Yi-Hsin Hung, Yueqi Duan', 'link': 'https://arxiv.org/abs/2505.23747', 'abstract': 'Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting their utility in scenarios with only 2D inputs, such as images or videos. In this paper, we present Spatial-MLLM, a novel framework for visual-based spatial reasoning from purely 2D observations. Unlike conventional video MLLMs which rely on CLIP-based visual encoders optimized for semantic understanding, our key insight is to unleash the strong structure prior from the feed-forward visual geometry foundation model. Specifically, we propose a dual-encoder architecture: a pretrained 2D visual encoder to extract semantic features, and a spatial encoder-initialized from the backbone of the visual geometry model-to extract 3D structure features. A connector then integrates both features into unified visual tokens for enhanced spatial understanding. Furthermore, we propose a space-aware frame sampling strategy at inference time, which selects the spatially informative frames of a video sequence, ensuring that even under limited token length, the model focuses on frames critical for spatial reasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k dataset and train the model on it using supervised fine-tuning and GRPO. Extensive experiments on various real-world datasets demonstrate that our spatial-MLLM achieves state-of-the-art performance in a wide range of visual-based spatial understanding and reasoning tasks. Project page: this https URL.', 'abstract_zh': 'Recent advancements in 多模态大规模语言模型（MLLMs）极大地提高了其在2D视觉任务上的性能。然而，提高其空间智能依然是一项挑战。现有的3D MLLMs总是依赖额外的3D或2.5D数据来融入空间意识，限制了它们在仅提供2D输入（如图像或视频）的场景中的应用。本文提出了一种名为Spatial-MLLM的新型框架，用于仅基于2D观察的视觉空间推理。与依赖于CLIP优化语义理解的视频MLLM不同，我们的关键洞察是释放前馈视觉几何基础模型中的强大结构先验。具体而言，我们提出了一种双编码器架构：一个预训练的2D视觉编码器用于提取语义特征，一个从视觉几何模型的主干初始化的空间编码器用于提取3D结构特征。然后，一个连接器将两种特征整合为统一的视觉标记，以增强空间理解。此外，我们还在推理时提出了一种空间感知的帧采样策略，该策略在视频序列中选择具有空间信息的帧，即使在有限的标记长度下，模型也能专注于对空间推理至关重要的帧。除了架构改进，我们构建了Spatial-MLLM-120k数据集，并使用监督微调和GRPO对其进行训练。在多种实际数据集上的广泛实验表明，我们的Spatial-MLLM在一系列基于视觉的空间理解和推理任务中取得了最优性能。项目页面: this https URL。', 'title_zh': '基于空间的MLLM：提升视觉空间智能中MLLM的能力'}
{'arxiv_id': 'arXiv:2505.23745', 'title': "To Trust Or Not To Trust Your Vision-Language Model's Prediction", 'authors': 'Hao Dong, Moru Liu, Jian Liang, Eleni Chatzi, Olga Fink', 'link': 'https://arxiv.org/abs/2505.23745', 'abstract': "Vision-Language Models (VLMs) have demonstrated strong capabilities in aligning visual and textual modalities, enabling a wide range of applications in multimodal understanding and generation. While they excel in zero-shot and transfer learning scenarios, VLMs remain susceptible to misclassification, often yielding confident yet incorrect predictions. This limitation poses a significant risk in safety-critical domains, where erroneous predictions can lead to severe consequences. In this work, we introduce TrustVLM, a training-free framework designed to address the critical challenge of estimating when VLM's predictions can be trusted. Motivated by the observed modality gap in VLMs and the insight that certain concepts are more distinctly represented in the image embedding space, we propose a novel confidence-scoring function that leverages this space to improve misclassification detection. We rigorously evaluate our approach across 17 diverse datasets, employing 4 architectures and 2 VLMs, and demonstrate state-of-the-art performance, with improvements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95 compared to existing baselines. By improving the reliability of the model without requiring retraining, TrustVLM paves the way for safer deployment of VLMs in real-world applications. The code will be available at this https URL.", 'abstract_zh': 'Vision-Language 模型 (VLMs) 在对接视觉和文本模态方面展现了强大的能力，使其在多模态理解和生成方面具备广泛的应用潜力。尽管它们在零样本学习和迁移学习场景中表现优异，但 VLMs 在分类时仍易出错，经常产生高置信度但错误的预测。这一局限性在安全关键领域造成了重大风险，错误的预测可能导致严重后果。在本文中，我们提出了 TrustVLM，这是一种无需训练的框架，旨在解决 VLM 预测可信度估计的关键挑战。基于对 VLMs 所观察到的模态差距的理解，以及某些概念在图像嵌入空间中更鲜明的表现，我们提出了一种新的置信度评分函数，利用这一空间来提高误分类检测能力。我们在 17 个不同的数据集上进行了严格评估，使用了 4 种架构和 2 种 VLMs，并展示了最先进的性能，相对于现有基线，AURC 提高了最多 51.87%，AUROC 提高了 9.14%，FPR95 提高了 32.42%。通过在无需重新训练的情况下提高模型的可靠性，TrustVLM 打开了在实际应用中安全部署 VLMs 的大门。代码将在以下链接获取：这个 https URL。', 'title_zh': '是信任还是不信任你的视觉-语言模型的预测'}
{'arxiv_id': 'arXiv:2505.23744', 'title': 'Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need', 'authors': 'Qiang Wang, Xiang Song, Yuhang He, Jizhou Han, Chenhao Ding, Xinyuan Gao, Yihong Gong', 'link': 'https://arxiv.org/abs/2505.23744', 'abstract': "Deep neural networks (DNNs) often underperform in real-world, dynamic settings where data distributions change over time. Domain Incremental Learning (DIL) offers a solution by enabling continual model adaptation, with Parameter-Isolation DIL (PIDIL) emerging as a promising paradigm to reduce knowledge conflicts. However, existing PIDIL methods struggle with parameter selection accuracy, especially as the number of domains and corresponding classes grows. To address this, we propose SOYO, a lightweight framework that improves domain selection in PIDIL. SOYO introduces a Gaussian Mixture Compressor (GMC) and Domain Feature Resampler (DFR) to store and balance prior domain data efficiently, while a Multi-level Domain Feature Fusion Network (MDFN) enhances domain feature extraction. Our framework supports multiple Parameter-Efficient Fine-Tuning (PEFT) methods and is validated across tasks such as image classification, object detection, and speech enhancement. Experimental results on six benchmarks demonstrate SOYO's consistent superiority over existing baselines, showcasing its robustness and adaptability in complex, evolving environments. The codes will be released in this https URL.", 'abstract_zh': '深度神经网络（DNNs）在数据分布随时间变化的动态现实环境中often underperform。领域增量学习（DIL）提供了一种解决方案，通过使模型能够持续适应，参数隔离领域增量学习（PIDIL）逐渐成为一种减少知识冲突的有前途的范式。然而，现有的PIDIL方法在参数选择准确性方面存在问题，尤其是在领域和相应类别的数量增加时。为了解决这一问题，我们提出了Soyo，一个轻量级框架，以提高PIDIL中的领域选择。Soyo引入了高斯混合压缩器（GMC）和领域特征重采样器（DFR），以有效地存储和平衡先验领域数据，同时多级领域特征融合网络（MDFN）增强了领域特征提取。该框架支持多种参数高效微调（PEFT）方法，并在图像分类、物体检测和语音增强等任务中进行了验证。在六个基准上的实验结果表明，Soyo在所有现有基线中表现出持续的优势，展示了其在复杂、不断演变环境中的稳健性和适应性。代码将在以下链接发布：https://github.com/Qwen-Model/Soyo。', 'title_zh': '增强领域增量学习：选择最优参数至关重要'}
{'arxiv_id': 'arXiv:2505.23742', 'title': 'MAGREF: Masked Guidance for Any-Reference Video Generation', 'authors': 'Yufan Deng, Xun Guo, Yuanyang Yin, Jacob Zhiyuan Fang, Yiding Yang, Yizhi Wang, Shenghai Yuan, Angtian Wang, Bo Liu, Haibin Huang, Chongyang Ma', 'link': 'https://arxiv.org/abs/2505.23742', 'abstract': 'Video generation has made substantial strides with the emergence of deep generative models, especially diffusion-based approaches. However, video generation based on multiple reference subjects still faces significant challenges in maintaining multi-subject consistency and ensuring high generation quality. In this paper, we propose MAGREF, a unified framework for any-reference video generation that introduces masked guidance to enable coherent multi-subject video synthesis conditioned on diverse reference images and a textual prompt. Specifically, we propose (1) a region-aware dynamic masking mechanism that enables a single model to flexibly handle various subject inference, including humans, objects, and backgrounds, without architectural changes, and (2) a pixel-wise channel concatenation mechanism that operates on the channel dimension to better preserve appearance features. Our model delivers state-of-the-art video generation quality, generalizing from single-subject training to complex multi-subject scenarios with coherent synthesis and precise control over individual subjects, outperforming existing open-source and commercial baselines. To facilitate evaluation, we also introduce a comprehensive multi-subject video benchmark. Extensive experiments demonstrate the effectiveness of our approach, paving the way for scalable, controllable, and high-fidelity multi-subject video synthesis. Code and model can be found at: this https URL', 'abstract_zh': '基于多参考主体的统一视频生成框架：引入掩码指导以实现多样参考图像和文本提示条件下的连贯多主体视频合成', 'title_zh': 'MAGREF: 任意参考视频生成的掩蔽指导'}
{'arxiv_id': 'arXiv:2505.23735', 'title': 'ATLAS: Learning to Optimally Memorize the Context at Test Time', 'authors': 'Ali Behrouz, Zeman Li, Praneeth Kacham, Majid Daliri, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni', 'link': 'https://arxiv.org/abs/2505.23735', 'abstract': 'Transformers have been established as the most popular backbones in sequence modeling, mainly due to their effectiveness in in-context retrieval tasks and the ability to learn at scale. Their quadratic memory and time complexity, however, bound their applicability in longer sequences and so has motivated researchers to explore effective alternative architectures such as modern recurrent neural networks (a.k.a long-term recurrent memory module). Despite their recent success in diverse downstream tasks, they struggle in tasks that requires long context understanding and extrapolation to longer sequences. We observe that these shortcomings come from three disjoint aspects in their design: (1) limited memory capacity that is bounded by the architecture of memory and feature mapping of the input; (2) online nature of update, i.e., optimizing the memory only with respect to the last input; and (3) less expressive management of their fixed-size memory. To enhance all these three aspects, we present ATLAS, a long-term memory module with high capacity that learns to memorize the context by optimizing the memory based on the current and past tokens, overcoming the online nature of long-term memory models. Building on this insight, we present a new family of Transformer-like architectures, called DeepTransformers, that are strict generalizations of the original Transformer architecture. Our experimental results on language modeling, common-sense reasoning, recall-intensive, and long-context understanding tasks show that ATLAS surpasses the performance of Transformers and recent linear recurrent models. ATLAS further improves the long context performance of Titans, achieving +80\\% accuracy in 10M context length of BABILong benchmark.', 'abstract_zh': '基于长期记忆模块的Transformer增强架构ATLAS', 'title_zh': 'ATLAS: 学习在测试时最优地记忆上下文'}
{'arxiv_id': 'arXiv:2505.23733', 'title': 'Exposing the Impact of GenAI for Cybercrime: An Investigation into the Dark Side', 'authors': 'Truong, Binny M. Samuel', 'link': 'https://arxiv.org/abs/2505.23733', 'abstract': "In recent years, the rapid advancement and democratization of generative AI models have sparked significant debate over safety, ethical risks, and dual-use concerns, particularly in the context of cybersecurity. While anecdotally known, this paper provides empirical evidence regarding generative AI's association with malicious internet-related activities and cybercrime by examining the phenomenon through psychological frameworks of technological amplification and affordance theory. Using a quasi-experimental design with interrupted time series analysis, we analyze two datasets, one general and one cryptocurrency-focused, to empirically assess generative AI's role in cybercrime. The findings contribute to ongoing discussions about AI governance by balancing control and fostering innovation, underscoring the need for strategies to guide policymakers, inform AI developers and cybersecurity professionals, and educate the public to maximize AI's benefits while mitigating its risks.", 'abstract_zh': '近年来，生成式AI模型的快速进步和普及化引发了关于安全、伦理风险和两用性担忧的重大讨论，特别是在网络安全领域的背景下。本文通过心理技术放大和赋能理论框架，提供实证证据分析生成式AI与恶意网络活动和网络犯罪之间的关联，并采用中断时间序列分析的准实验设计，研究两个数据集（一般性和加密货币相关）以实证评估生成式AI在网络安全犯罪中的角色。研究发现为AI治理的讨论增添了实证依据，平衡控制与促进创新，强调需要制定策略指导政策制定者、影响AI开发者和网络安全专业人员，并教育公众以最大限度地发挥AI的益处并减轻其风险。', 'title_zh': '揭示生成式AI对网络犯罪的影响：对黑暗一面的探究'}
{'arxiv_id': 'arXiv:2505.23729', 'title': 'Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time', 'authors': 'Mohamad Chehade, Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Dinesh Manocha, Hao Zhu, Amrit Singh Bedi', 'link': 'https://arxiv.org/abs/2505.23729', 'abstract': "Aligning large language models with humans is challenging due to the inherently multifaceted nature of preference feedback. While existing approaches typically frame this as a multi-objective optimization problem, they often overlook how humans actually make decisions. Research on bounded rationality suggests that human decision making follows satisficing strategies-optimizing primary objectives while ensuring others meet acceptable thresholds. To bridge this gap and operationalize the notion of satisficing alignment, we propose SITAlign: an inference time framework that addresses the multifaceted nature of alignment by maximizing a primary objective while satisfying threshold-based constraints on secondary criteria. We provide theoretical insights by deriving sub-optimality bounds of our satisficing based inference alignment approach. We empirically validate SITAlign's performance through extensive experimentation on multiple benchmarks. For instance, on the PKU-SafeRLHF dataset with the primary objective of maximizing helpfulness while ensuring a threshold on harmlessness, SITAlign outperforms the state-of-the-art multi objective decoding strategy by a margin of 22.3% in terms of GPT-4 win-tie rate for helpfulness reward while adhering to the threshold on harmlessness.", 'abstract_zh': '将大型语言模型与人类对齐具有挑战性，因为偏好反馈本质上是多面的。现有方法通常将此问题框定为一个多目标优化问题，但往往忽视了人类实际决策的过程。有界理性研究建议，人类决策遵循 satisficing 策略——在优化主要目标的同时确保其他目标达到可接受的阈值。为了弥合这一差距并实现基于 satisficing 的对齐概念的操作化，我们提出 SITAlign：一种在推理时间处理对齐多面性的框架，通过最大化主要目标并满足次级标准的阈值约束来实现对齐。我们通过推导基于 satisficing 的推理对齐方法的次优性边界来提供理论洞察。通过在多个基准上进行广泛的实验，我们验证了 SITAlign 的性能。例如，在 PKU-SafeRLHF 数据集上，以最大化帮助性为主要目标，同时确保有害性的阈值，SITAlign 在帮助性奖励的 GPT-4 获胜率为 22.3% 的优势上获得了优于最新多目标解码策略的性能，同时遵循有害性的阈值。', 'title_zh': 'LLMs的有界理性：推理时的满意化对齐'}
{'arxiv_id': 'arXiv:2505.23724', 'title': 'SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA', 'authors': 'Minrui Luo, Fuhang Kuang, Yu Wang, Zirui Liu, Tianxing He', 'link': 'https://arxiv.org/abs/2505.23724', 'abstract': 'Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), are indispensable for efficiently customizing Large Language Models (LLMs). However, vanilla LoRA suffers from slow convergence speed and knowledge forgetting problems. Recent studies have leveraged the power of designed LoRA initialization, to enhance the fine-tuning efficiency, or to preserve knowledge in the pre-trained LLM. However, none of these works can address the two cases at the same time. To this end, we introduce Subspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework engineered to navigate the trade-off between efficient fine-tuning and knowledge preservation. We achieve this by constraining the output of trainable LoRA adapters in a low-rank subspace, where the context information of fine-tuning data is most preserved while the context information of preserved knowledge is least retained, in a balanced way. Such constraint enables the trainable weights to primarily focus on the main features of fine-tuning data while avoiding damaging the preserved knowledge features. We provide theoretical analysis on our method, and conduct extensive experiments including safety preservation and world knowledge preservation, on various downstream tasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning performance while markedly diminishing knowledge forgetting, surpassing contemporary LoRA initialization methods.', 'abstract_zh': 'Subspace-Constrained LoRA: A Novel Initialization Framework for Efficient Fine-Tuning and Knowledge Preservation', 'title_zh': 'SC-LoRA: 平衡高效微调与知识保留的子空间约束LoRA'}
{'arxiv_id': 'arXiv:2505.23723', 'title': 'ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering', 'authors': 'Zexi Liu, Jingyi Chai, Xinyu Zhu, Shuo Tang, Rui Ye, Bo Zhang, Lei Bai, Siheng Chen', 'link': 'https://arxiv.org/abs/2505.23723', 'abstract': 'The emergence of large language model (LLM)-based agents has significantly advanced the development of autonomous machine learning (ML) engineering. However, most existing approaches rely heavily on manual prompt engineering, failing to adapt and optimize based on diverse experimental experiences. Focusing on this, for the first time, we explore the paradigm of learning-based agentic ML, where an LLM agent learns through interactive experimentation on ML tasks using online reinforcement learning (RL). To realize this, we propose a novel agentic ML training framework with three key components: (1) exploration-enriched fine-tuning, which enables LLM agents to generate diverse actions for enhanced RL exploration; (2) step-wise RL, which enables training on a single action step, accelerating experience collection and improving training efficiency; (3) an agentic ML-specific reward module, which unifies varied ML feedback signals into consistent rewards for RL optimization. Leveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM for autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our 7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it achieves continuous performance improvements and demonstrates exceptional cross-task generalization capabilities.', 'abstract_zh': '基于大型语言模型代理的自主机器学习工程 paradign 及其实现：一种学习驱动的交互式强化学习框架', 'title_zh': 'ML-Agent：强化LLM代理以实现自主机器学习工程'}
{'arxiv_id': 'arXiv:2505.23720', 'title': 'COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents', 'authors': 'Arun Verma, Indrajit Saha, Makoto Yokoo, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2505.23720', 'abstract': "This paper considers a contextual bandit problem involving multiple agents, where a learner sequentially observes the contexts and the agent's reported arms, and then selects the arm that maximizes the system's overall reward. Existing work in contextual bandits assumes that agents truthfully report their arms, which is unrealistic in many real-life applications. For instance, consider an online platform with multiple sellers; some sellers may misrepresent product quality to gain an advantage, such as having the platform preferentially recommend their products to online users. To address this challenge, we propose an algorithm, COBRA, for contextual bandit problems involving strategic agents that disincentivize their strategic behavior without using any monetary incentives, while having incentive compatibility and a sub-linear regret guarantee. Our experimental results also validate the different performance aspects of our proposed algorithm.", 'abstract_zh': '一种抑制战略性行为的上下文 bandit 算法：COBRA', 'title_zh': 'COBRA: 基于上下文的臂赛选算法以确保战略性代理的truthful行为'}
{'arxiv_id': 'arXiv:2505.23714', 'title': 'SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods', 'authors': 'Roksana Goworek, Harpal Karlcut, Muhammad Shezad, Nijaguna Darshana, Abhishek Mane, Syam Bondada, Raghav Sikka, Ulvi Mammadov, Rauf Allahverdiyev, Sriram Purighella, Paridhi Gupta, Muhinyia Ndegwa, Haim Dubossarsky', 'link': 'https://arxiv.org/abs/2505.23714', 'abstract': 'This paper addresses the critical need for high-quality evaluation datasets in low-resource languages to advance cross-lingual transfer. While cross-lingual transfer offers a key strategy for leveraging multilingual pretraining to expand language technologies to understudied and typologically diverse languages, its effectiveness is dependent on quality and suitable benchmarks. We release new sense-annotated datasets of sentences containing polysemous words, spanning nine low-resource languages across diverse language families and scripts. To facilitate dataset creation, the paper presents a demonstrably beneficial semi-automatic annotation method. The utility of the datasets is demonstrated through Word-in-Context (WiC) formatted experiments that evaluate transfer on these low-resource languages. Results highlight the importance of targeted dataset creation and evaluation for effective polysemy disambiguation in low-resource settings and transfer studies. The released datasets and code aim to support further research into fair, robust, and truly multilingual NLP.', 'abstract_zh': '本文探讨了在低资源语言中构建高质量评估数据集的迫切需求，以促进跨语言迁移。通过多语言预训练利用跨语言迁移策略扩展语言技术至未研究和类型多样的语言，其效果依赖于高质量和合适的基准。本文发布了九种低资源语言的新感官注释数据集，这些语言跨多个语言家族和文字系统。为促进数据集的构建，本文提出了一种可证明有益的半自动注释方法。通过Word-in-Context (WiC) 格式实验展示了这些数据集在低资源语言迁移上的评估效果。结果强调了在低资源环境和迁移研究中针对性数据集创建和评估的重要性。所发布的数据集和代码旨在支持进一步研究公平、稳健且真正多语言的自然语言处理。', 'title_zh': 'SenWiCh: 低资源语言WiC的感知注释方法研究'}
{'arxiv_id': 'arXiv:2505.23710', 'title': 'From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems', 'authors': 'Zeinab Nezami, Syed Danial Ali Shah, Maryam Hafeez, Karim Djemame, Syed Ali Raza Zaidi', 'link': 'https://arxiv.org/abs/2505.23710', 'abstract': 'This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven intelligence enables dynamic adaptation beyond static connectivity. We explore the key enablers of autonomous communication systems, spanning reconfigurable infrastructure, adaptive middleware, and intelligent network functions, alongside multi-agent collaboration for distributed decision-making. We explore how these methodologies align with emerging industrial IoT frameworks, ensuring seamless integration within digital manufacturing processes. Our findings emphasize the potential for improved real-time decision-making, optimizing efficiency, and reducing latency in networked control systems. The discussion addresses ethical challenges, research directions, and standardization efforts, concluding with a technology stack roadmap to guide future developments. By leveraging state-of-the-art 6G network management techniques, this research contributes to the next generation of intelligent automation solutions, bridging the gap between theoretical advancements and real-world industrial applications.', 'abstract_zh': '这篇论文构想了6G作为一个自我进化的电信生态系统，其中基于AI的智能使得动态适应超越了静态连接。我们探索自主通信系统的关键使能技术，涵盖可重构基础设施、自适应中间件、智能网络功能，并涉及分布式决策中的多代理协作。我们探讨了这些方法如何与新兴的工业物联网框架相契合，确保与数字化制造过程的无缝集成。我们的研究强调了在联网控制系统中增强实时决策、优化效率和降低延迟的潜力。讨论涵盖了伦理挑战、研究方向和标准化努力，并以技术栈路线图结束，以指导未来的发展。通过利用最先进的6G网络管理技术，本研究为下一代智能自动化解决方案做出了贡献，弥合了理论进步与实际工业应用之间的差距。', 'title_zh': '从连接到自主：自进化通信系统的黎明'}
{'arxiv_id': 'arXiv:2505.23709', 'title': 'Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning', 'authors': 'Dionysis Christopoulos, Sotiris Spanos, Eirini Baltzi, Valsamis Ntouskos, Konstantinos Karantzalos', 'link': 'https://arxiv.org/abs/2505.23709', 'abstract': "We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learning rich representations of skin lesions through a novel nested contrastive learning approach that captures complex relationships between images and metadata. Melanoma detection and skin lesion classification based solely on images, pose significant challenges due to large variations in imaging conditions (lighting, color, resolution, distance, etc.) and lack of clinical and phenotypical context. Clinicians typically follow a holistic approach for assessing the risk level of the patient and for deciding which lesions may be malignant and need to be excised, by considering the patient's medical history as well as the appearance of other lesions of the patient. Inspired by this, SLIMP combines the appearance and the metadata of individual skin lesions with patient-level metadata relating to their medical record and other clinically relevant information. By fully exploiting all available data modalities throughout the learning process, the proposed pre-training strategy improves performance compared to other pre-training strategies on downstream skin lesions classification tasks highlighting the learned representations quality.", 'abstract_zh': 'SLIMP (皮肤病变图像-元数据预训练)', 'title_zh': '基于嵌套多模态对比学习的皮肤病变表型识别'}
{'arxiv_id': 'arXiv:2505.23706', 'title': 'Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats', 'authors': 'Utku Demir, Yalin E. Sagduyu, Tugba Erpek, Hossein Jafari, Sastry Kompella, Mengran Xue', 'link': 'https://arxiv.org/abs/2505.23706', 'abstract': "In connected and autonomous vehicles, machine learning for safety message classification has become critical for detecting malicious or anomalous behavior. However, conventional approaches that rely on centralized data collection or purely local training face limitations due to the large scale, high mobility, and heterogeneous data distributions inherent in inter-vehicle networks. To overcome these challenges, this paper explores Distributed Federated Learning (DFL), whereby vehicles collaboratively train deep learning models by exchanging model updates among one-hop neighbors and propagating models over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi) Extension Dataset, we show that DFL can significantly improve classification accuracy across all vehicles compared to learning strictly with local data. Notably, vehicles with low individual accuracy see substantial accuracy gains through DFL, illustrating the benefit of knowledge sharing across the network. We further show that local training data size and time-varying network connectivity correlate strongly with the model's overall accuracy. We investigate DFL's resilience and vulnerabilities under attacks in multiple domains, namely wireless jamming and training data poisoning attacks. Our results reveal important insights into the vulnerabilities of DFL when confronted with multi-domain attacks, underlining the need for more robust strategies to secure DFL in vehicular networks.", 'abstract_zh': '在连接和自主车辆中，基于机器学习的安全消息分类对于检测恶意或异常行为已成为关键。然而，传统的依赖中心化数据收集或纯本地训练的方法由于车联网中固有的大规模、高移动性和异质数据分布而面临局限性。为克服这些挑战，本文探索了分布式联邦学习（DFL），该方法通过车辆之间交换模型更新并跨多跳传播模型以协作训练深度学习模型。使用Vehicular Reference Misbehavior（VeReMi）扩展数据集，我们展示无论对于何种车辆，DFL都可以显著提高分类准确性。值得注意的是，通过DFL，个体准确率较低的车辆实现了显著的准确率提升，这表明了网络中知识共享的好处。进一步的研究显示，局部训练数据大小和时间变化的网络连接性与模型的整体准确性密切相关。我们还在多个领域（包括无线 jamming 和训练数据投毒攻击）下研究了DFL的鲁棒性和脆弱性，结果揭示了DFL在面对多域攻击时的关键脆弱性，突显了在车联网中对DFL采取更稳健策略的必要性。', 'title_zh': '车辆网络安全性中的分布式联邦学习：异常检测优势与多域攻击威胁'}
{'arxiv_id': 'arXiv:2505.23704', 'title': 'CLDTracker: A Comprehensive Language Description for Visual Tracking', 'authors': 'Mohamad Alansari, Sajid Javed, Iyyakutti Iyappan Ganapathi, Sara Alansari, Muzammal Naseer', 'link': 'https://arxiv.org/abs/2505.23704', 'abstract': "VOT remains a fundamental yet challenging task in computer vision due to dynamic appearance changes, occlusions, and background clutter. Traditional trackers, relying primarily on visual cues, often struggle in such complex scenarios. Recent advancements in VLMs have shown promise in semantic understanding for tasks like open-vocabulary detection and image captioning, suggesting their potential for VOT. However, the direct application of VLMs to VOT is hindered by critical limitations: the absence of a rich and comprehensive textual representation that semantically captures the target object's nuances, limiting the effective use of language information; inefficient fusion mechanisms that fail to optimally integrate visual and textual features, preventing a holistic understanding of the target; and a lack of temporal modeling of the target's evolving appearance in the language domain, leading to a disconnect between the initial description and the object's subsequent visual changes. To bridge these gaps and unlock the full potential of VLMs for VOT, we propose CLDTracker, a novel Comprehensive Language Description framework for robust visual Tracking. Our tracker introduces a dual-branch architecture consisting of a textual and a visual branch. In the textual branch, we construct a rich bag of textual descriptions derived by harnessing the powerful VLMs such as CLIP and GPT-4V, enriched with semantic and contextual cues to address the lack of rich textual representation. Experiments on six standard VOT benchmarks demonstrate that CLDTracker achieves SOTA performance, validating the effectiveness of leveraging robust and temporally-adaptive vision-language representations for tracking. Code and models are publicly available at: this https URL", 'abstract_zh': '视觉跟踪中持续视觉跟踪(VOT)仍然是计算机视觉中的一个基础且具有挑战性的任务，由于动态外观变化、遮挡和背景杂乱。传统的跟踪器主要依赖视觉线索，在复杂场景中经常力不从心。近期预训练语言模型(VLMs)在开放词汇检测和图像字幕等任务上的表现表明其在视觉跟踪中的潜在应用。然而，直接将VLMs应用于视觉跟踪受到关键限制：缺乏丰富的文本表示来语义上捕捉目标对象的细微之处，限制了语言信息的有效利用；不高效的特征融合机制无法最优整合视觉和文本特征，阻碍了对目标的整体理解；以及未建模目标随时间不断变化的外观在语言域中，导致初始描述与对象后续视觉变化之间存在脱节。为了解决这些差距并充分发挥VLMs在视觉跟踪中的潜力，我们提出了CLDTracker，一种新颖的整体语言描述框架，用于稳健的视觉跟踪。我们的跟踪器采用双支路架构，包括文本支路和视觉支路。在文本支路中，我们通过利用强大的VLMs（如CLIP和GPT-4V）构建丰富的文本描述集合，并结合语义和上下文线索来解决文本表示不丰富的问题。在六个标准VOT基准上的实验表明，CLDTracker取得了SOTA性能，验证了利用稳健和时间适应的视觉-语言表示对于跟踪的有效性。更多代码和模型请访问：this https URL。', 'title_zh': 'CLDTracker: 一种全面的视觉跟踪语言描述'}
{'arxiv_id': 'arXiv:2505.23693', 'title': 'VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos', 'authors': 'Tingyu Song, Tongyan Hu, Guo Gan, Yilun Zhao', 'link': 'https://arxiv.org/abs/2505.23693', 'abstract': 'MLLMs have been widely studied for video question answering recently. However, most existing assessments focus on natural videos, overlooking synthetic videos, such as AI-generated content (AIGC). Meanwhile, some works in video generation rely on MLLMs to evaluate the quality of generated videos, but the capabilities of MLLMs on interpreting AIGC videos remain largely underexplored. To address this, we propose a new benchmark, VF-Eval, which introduces four tasks-coherence validation, error awareness, error type detection, and reasoning evaluation-to comprehensively evaluate the abilities of MLLMs on AIGC videos. We evaluate 13 frontier MLLMs on VF-Eval and find that even the best-performing model, GPT-4.1, struggles to achieve consistently good performance across all tasks. This highlights the challenging nature of our benchmark. Additionally, to investigate the practical applications of VF-Eval in improving video generation, we conduct an experiment, RePrompt, demonstrating that aligning MLLMs more closely with human feedback can benefit video generation.', 'abstract_zh': 'MLLMs在合成视频理解上的评估：VF-Eval基准', 'title_zh': 'VF-Eval: 评估多模态大语言模型生成AIGC视频反馈的能力'}
{'arxiv_id': 'arXiv:2505.23671', 'title': 'GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents', 'authors': 'Manish Shetty, Naman Jain, Jinjian Liu, Vijay Kethanaboyina, Koushik Sen, Ion Stoica', 'link': 'https://arxiv.org/abs/2505.23671', 'abstract': "Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.", 'abstract_zh': '开发高性能软件是一项复杂任务，需要专门的技术。我们引入了GSO，一个用于评估语言模型在开发高性能软件方面能力的基准。我们开发了一个自动化的工作流程，生成并执行性能测试，分析仓库提交历史，识别出跨越不同领域和编程语言的10个具有挑战性的优化任务共102项。为智能代理提供一个代码库和性能测试作为精确的规格说明，要求其提高运行时效率，衡量其效果与专家开发者的优化效果。我们的定量评估表明，顶尖的SWE-代理面临重大挑战，成功率低于5%，即使在推理时间进行扩展，改进也非常有限。我们的定性分析揭示了关键失败模式，包括低级语言的难度、懒优化策略的实践困难以及瓶颈定位的准确性挑战。我们发布了基准的代码和相关资源，以及智能代理的轨迹，以促进未来的研究。', 'title_zh': 'GSO: 评估软件工程代理软件优化任务的挑战'}
{'arxiv_id': 'arXiv:2505.23657', 'title': 'Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation', 'authors': 'Hongxiang Zhang, Hao Chen, Tianyi Zhang, Muhao Chen', 'link': 'https://arxiv.org/abs/2505.23657', 'abstract': 'Recent decoding methods improve the factuality of large language models~(LLMs) by refining how the next token is selected during generation. These methods typically operate at the token level, leveraging internal representations to suppress superficial patterns. Nevertheless, LLMs remain prone to hallucinations, especially over longer contexts. In this paper, we propose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy that actively decides when to apply contrasting layers during generation. By casting decoding as a sequential decision-making problem, ActLCD employs a reinforcement learning policy guided by a reward-aware classifier to optimize factuality beyond the token level. Our experiments demonstrate that ActLCD surpasses state-of-the-art methods across five benchmarks, showcasing its effectiveness in mitigating hallucinations in diverse generation scenarios.', 'abstract_zh': '近期的解码方法通过细化生成过程中下一个-token 的选择来提高大型语言模型的客观性，这些方法通常在 token 级别操作，利用内部表示抑制表层模式。然而，大型语言模型在较长上下文的情况下仍然容易产生幻觉。在本文中，我们提出了一种新型解码策略——主动层对比解码（ActLCD），该策略主动决定在生成过程中何时应用对比层。通过将解码视为一个顺序决策问题，ActLCD 使用由奖励感知分类器引导的强化学习策略，在 token 以上级别优化客观性。我们的实验表明，ActLCD 在五个基准测试中超过了最先进的方法，展示了其在多种生成场景下减少幻觉的有效性。', 'title_zh': '主动层-对比解码减少大型语言模型生成中的幻觉'}
{'arxiv_id': 'arXiv:2505.23655', 'title': 'Keyed Chaotic Tensor Transformations for Secure And Attributable Neural Inference', 'authors': 'Peter David Fagan', 'link': 'https://arxiv.org/abs/2505.23655', 'abstract': 'This work introduces a novel framework for secure and privacy-preserving neural network inference based on keyed chaotic dynamical transformations. The proposed method applies a deterministic, cryptographically seeded chaotic system to tensors, producing non-invertible, user-specific transformations that enable authenticated inference, tensor-level watermarking, and data attribution. This framework offers a scalable and lightweight alternative to conventional cryptographic techniques, and establishes a new direction for tensor-level security in AI systems.', 'abstract_zh': '基于密钥控制混沌动力学变换的新型安全和隐私保护神经网络推理框架', 'title_zh': '基于密钥的混沌张量变换用于安全可追溯的神经推断'}
{'arxiv_id': 'arXiv:2505.23643', 'title': 'Securing AI Agents with Information-Flow Control', 'authors': 'Manuel Costa, Boris Köpf, Aashish Kolluri, Andrew Paverd, Mark Russinovich, Ahmed Salem, Shruti Tople, Lukas Wutschitz, Santiago Zanella-Béguelin', 'link': 'https://arxiv.org/abs/2505.23643', 'abstract': 'As AI agents become increasingly autonomous and capable, ensuring their security against vulnerabilities such as prompt injection becomes critical. This paper explores the use of information-flow control (IFC) to provide security guarantees for AI agents. We present a formal model to reason about the security and expressiveness of agent planners. Using this model, we characterize the class of properties enforceable by dynamic taint-tracking and construct a taxonomy of tasks to evaluate security and utility trade-offs of planner designs. Informed by this exploration, we present Fides, a planner that tracks confidentiality and integrity labels, deterministically enforces security policies, and introduces novel primitives for selectively hiding information. Its evaluation in AgentDojo demonstrates that this approach broadens the range of tasks that can be securely accomplished. A tutorial to walk readers through the the concepts introduced in the paper can be found at this https URL', 'abstract_zh': '随着AI代理越来越自主和强大，确保其免受诸如提示注入等漏洞的攻击变得至关重要。本文探讨了使用信息流控制（IFC）为AI代理提供安全保证的方法。我们提出了一种形式化模型来推理代理规划器的安全性和表达能力。通过该模型，我们确定了可由动态污点追踪强制执行的属性类别，并构建了任务分类法以评估规划器设计的安全性和实用性权衡。基于这一探索，我们提出了Fides规划器，该规划器追踪机密性和完整性标签，确定性地执行安全策略，并引入了有选择地隐藏信息的新颖机制。在AgentDojo中的评估表明，这种方法扩展了可以安全完成的任务范围。有关本文介绍的概念教程，请参阅此链接：https://example.com。', 'title_zh': '使用信息流控制保障AI代理的安全'}
{'arxiv_id': 'arXiv:2505.23637', 'title': 'Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging', 'authors': 'Dashti A. Ali, Richard K. G. Do, William R. Jarnagin, Aras T. Asaad, Amber L. Simpson', 'link': 'https://arxiv.org/abs/2505.23637', 'abstract': 'In medical image analysis, feature engineering plays an important role in the design and performance of machine learning models. Persistent homology (PH), from the field of topological data analysis (TDA), demonstrates robustness and stability to data perturbations and addresses the limitation from traditional feature extraction approaches where a small change in input results in a large change in feature representation. Using PH, we store persistent topological and geometrical features in the form of the persistence barcode whereby large bars represent global topological features and small bars encapsulate geometrical information of the data. When multiple barcodes are computed from 2D or 3D medical images, two approaches can be used to construct the final topological feature vector in each dimension: aggregating persistence barcodes followed by featurization or concatenating topological feature vectors derived from each barcode. In this study, we conduct a comprehensive analysis across diverse medical imaging datasets to compare the effects of the two aforementioned approaches on the performance of classification models. The results of this analysis indicate that feature concatenation preserves detailed topological information from individual barcodes, yields better classification performance and is therefore a preferred approach when conducting similar experiments.', 'abstract_zh': '在医疗图像分析中，特征工程在机器学习模型的设计和性能中发挥着重要作用。来自拓扑数据分析领域的持久同调（PH）展现了对数据扰动的稳健性和稳定性，并解决了传统特征提取方法中存在的问题，即输入的小变化会导致特征表示的大变化。使用PH，我们以持久条形码的形式存储持久的拓扑和几何特征，其中长条形代表全局拓扑特征，短条形包含数据的几何信息。当从2D或3D医疗图像计算出多个条形码时，可以采取两种方法构造每个维度的最终拓扑特征向量：首先聚合持久条形码，然后进行特征化，或者连接从每个条形码派生出来的拓扑特征向量。在本研究中，我们对多种多样的医疗成像数据集进行全面分析，比较这两种方法对分类模型性能的影响。分析结果表明，特征连接能够保留单个条形码中的详细拓扑信息，产生更好的分类性能，因此在进行类似实验时是一种更优选的方法。', 'title_zh': '比较持久 barcode 聚合和特征拼接对医学成像的影响'}
{'arxiv_id': 'arXiv:2505.23631', 'title': 'Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education', 'authors': 'Boning Zhao', 'link': 'https://arxiv.org/abs/2505.23631', 'abstract': 'Assessing student depression in sensitive environments like special education is challenging. Standardized questionnaires may not fully reflect students\' true situations. Furthermore, automated methods often falter with rich student narratives, lacking the crucial, individualized insights stemming from teachers\' empathetic connections with students. Existing methods often fail to address this ambiguity or effectively integrate educator understanding. To address these limitations by fostering a synergistic human-AI collaboration, this paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered AI framework for transparent and socially responsible depression severity assessment. Our approach uniquely integrates student narrative text with a teacher-derived, 9-dimensional "Empathy Vector" (EV), its dimensions guided by the PHQ-9 framework,to explicitly translate tacit empathetic insight into a structured AI input enhancing rather than replacing human judgment. Rigorous experiments optimized the multimodal fusion, text representation, and classification architecture, achieving 82.74% accuracy for 7-level severity classification. This work demonstrates a path toward more responsible and ethical affective computing by structurally embedding human empathy', 'abstract_zh': '评估敏感环境如特殊教育中的学生抑郁状况具有挑战性。标准化问卷可能无法全面反映学生的真实情况。此外，自动化方法往往难以处理丰富的学生叙事，缺乏来自教师对学生的同理心连接的关键性、个性化见解。现有方法常难以解决这种模糊性或有效整合教育者的理解。为了通过促进人类与人工智能的协同合作来解决这些局限，本文提出了一种新型、以人为核心的人工智能框架——Human Empathy as Encoder（HEAE），旨在实现透明和负责任的抑郁严重程度评估。我们的方法独特地将学生叙事文本与教师提取的9维“同理心向量”（EV）相结合，EV的各个维度由PHQ-9框架指导，以明确地将隐性的同理心洞察转化为结构化的AI输入，以增强而非替代人类判断。严格的实验优化了多模态融合、文本表示和分类架构，实现了7级严重程度分类的82.74%准确率。这项工作展示了通过结构化嵌入人类同理心实现更加负责任和道德的情感计算的道路。', 'title_zh': '人类共情作为编码器：AI辅助的特殊教育中抑郁评估'}
{'arxiv_id': 'arXiv:2505.23628', 'title': 'AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora', 'authors': 'Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song', 'link': 'https://arxiv.org/abs/2505.23628', 'abstract': 'We present AutoSchemaKG, a framework for fully autonomous knowledge graph construction that eliminates the need for predefined schemas. Our system leverages large language models to simultaneously extract knowledge triples and induce comprehensive schemas directly from text, modeling both entities and events while employing conceptualization to organize instances into semantic categories. Processing over 50 million documents, we construct ATLAS (Automated Triple Linking And Schema induction), a family of knowledge graphs with 900+ million nodes and 5.9 billion edges. This approach outperforms state-of-the-art baselines on multi-hop QA tasks and enhances LLM factuality. Notably, our schema induction achieves 95\\% semantic alignment with human-crafted schemas with zero manual intervention, demonstrating that billion-scale knowledge graphs with dynamically induced schemas can effectively complement parametric knowledge in large language models.', 'abstract_zh': '我们提出AutoSchemaKG，一种无需预定义模式的完全自主知识图谱构建框架', 'title_zh': 'AutoSchemaKG：通过从大规模网页 corpora 中动态引申语 schemata 自主构建知识图谱'}
{'arxiv_id': 'arXiv:2505.23624', 'title': 'Towards Explainable Sequential Learning', 'authors': 'Giacomo Bergami, Emma Packer, Kirsty Scott, Silvia Del Din', 'link': 'https://arxiv.org/abs/2505.23624', 'abstract': 'This paper offers a hybrid explainable temporal data processing pipeline, DataFul Explainable MultivariatE coRrelatIonal Temporal Artificial inTElligence (EMeriTAte+DF), bridging numerical-driven temporal data classification with an event-based one through verified artificial intelligence principles, enabling human-explainable results. This was possible through a preliminary a posteriori explainable phase describing the numerical input data in terms of concurrent constituents with numerical payloads. This further required extending the event-based literature to design specification mining algorithms supporting concurrent constituents. Our previous and current solutions outperform state-of-the-art solutions for multivariate time series classifications, thus showcasing the effectiveness of the proposed methodology.', 'abstract_zh': '基于事件的多变量时序数据可解释处理管道：DataFul Explainable Multivariate Correlational Temporal Artificial Intelligence (EMeriTAte+DF)', 'title_zh': '可解释的序列学习'}
{'arxiv_id': 'arXiv:2505.23617', 'title': 'One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory', 'authors': 'Chenhao Zheng, Jieyu Zhang, Mohammadreza Salehi, Ziqi Gao, Vishnu Iyengar, Norimasa Kobori, Quan Kong, Ranjay Krishna', 'link': 'https://arxiv.org/abs/2505.23617', 'abstract': 'Effective video tokenization is critical for scaling transformer models for long videos. Current approaches tokenize videos using space-time patches, leading to excessive tokens and computational inefficiencies. The best token reduction strategies degrade performance and barely reduce the number of tokens when the camera moves. We introduce grounded video tokenization, a paradigm that organizes tokens based on panoptic sub-object trajectories rather than fixed patches. Our method aligns with fundamental perceptual principles, ensuring that tokenization reflects scene complexity rather than video duration. We propose TrajViT, a video encoder that extracts object trajectories and converts them into semantically meaningful tokens, significantly reducing redundancy while maintaining temporal coherence. Trained with contrastive learning, TrajViT significantly outperforms space-time ViT (ViT3D) across multiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a large margin of 6% top-5 recall in average at video-text retrieval task with 10x token deduction. We also show TrajViT as a stronger model than ViT3D for being the video encoder for modern VideoLLM, obtaining an average of 5.2% performance improvement across 6 VideoQA benchmarks while having 4x faster training time and 18x less inference FLOPs. TrajViT is the first efficient encoder to consistently outperform ViT3D across diverse video analysis tasks, making it a robust and scalable solution.', 'abstract_zh': '有效的视频分词对于扩展用于长视频的变压器模型至关重要。当前方法使用时空片段进行视频分词，导致分词过多和计算效率低下。最优的分词策略会降低性能，并且在摄像头移动时几乎无法减少分词数量。我们引入了基于全景子对象轨迹的视频分词方法，该方法以运动轨迹而非固定片段来组织分词。我们的方法遵循基本的知觉原理，确保分词反映场景复杂性而非视频时长。我们提出了一种名为TrajViT的视频编码器，它提取对象轨迹并将其转换为语义上相关的分词，显著减少了冗余同时保持时间连贯性。通过对比学习训练，TrajViT在多个视频理解基准测试上显著优于时空ViT（ViT3D），例如，在视频-文本检索任务中，平均5%的Top-5召回率提高了6%，且分词数量减少了10倍。我们还展示了TrajViT作为现代VideoLLM的视频编码器时，比ViT3D在6个视频问答基准测试上平均性能提高了5.2%，同时训练时间快4倍，推理FLOPs少18倍。TrajViT是首个在多种视频分析任务中一致优于ViT3D的高效编码器，使其成为一个鲁棒且可扩展的解决方案。', 'title_zh': '一条轨迹，一个令牌：基于泛视图子对象轨迹的接地视频词化'}
{'arxiv_id': 'arXiv:2505.23604', 'title': 'Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering', 'authors': 'Guangtao Zeng, Maohao Shen, Delin Chen, Zhenting Qi, Subhro Das, Dan Gutfreund, David Cox, Gregory Wornell, Wei Lu, Zhang-Wei Hong, Chuang Gan', 'link': 'https://arxiv.org/abs/2505.23604', 'abstract': 'Language models (LMs) perform well on standardized coding benchmarks but struggle with real-world software engineering tasks such as resolving GitHub issues in SWE-Bench, especially when model parameters are less than 100B. While smaller models are preferable in practice due to their lower computational cost, improving their performance remains challenging. Existing approaches primarily rely on supervised fine-tuning (SFT) with high-quality data, which is expensive to curate at scale. An alternative is test-time scaling: generating multiple outputs, scoring them using a verifier, and selecting the best one. Although effective, this strategy often requires excessive sampling and costly scoring, limiting its practical application. We propose Evolutionary Test-Time Scaling (EvoScale), a sample-efficient method that treats generation as an evolutionary process. By iteratively refining outputs via selection and mutation, EvoScale shifts the output distribution toward higher-scoring regions, reducing the number of samples needed to find correct solutions. To reduce the overhead from repeatedly sampling and selection, we train the model to self-evolve using reinforcement learning (RL). Rather than relying on external verifiers at inference time, the model learns to self-improve the scores of its own generations across iterations. Evaluated on SWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or exceed the performance of models with over 100B parameters while using a few samples. Code, data, and models will be fully open-sourced.', 'abstract_zh': 'Evolutionary Test-Time Scaling for Real-World Software Engineering Tasks', 'title_zh': 'Satori-SWE: 进化测试时动态缩放以提高样本高效软件工程'}
{'arxiv_id': 'arXiv:2505.23595', 'title': 'DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification', 'authors': 'Youssef Mohamed, Noran Mohamed, Khaled Abouhashad, Feilong Tang, Sara Atito, Shoaib Jameel, Imran Razzak, Ahmed B. Zaky', 'link': 'https://arxiv.org/abs/2505.23595', 'abstract': 'While Multi-Task Learning (MTL) offers inherent advantages in complex domains such as medical imaging by enabling shared representation learning, effectively balancing task contributions remains a significant challenge. This paper addresses this critical issue by introducing DeepChest, a novel, computationally efficient and effective dynamic task-weighting framework specifically designed for multi-label chest X-ray (CXR) classification. Unlike existing heuristic or gradient-based methods that often incur substantial overhead, DeepChest leverages a performance-driven weighting mechanism based on effective analysis of task-specific loss trends. Given a network architecture (e.g., ResNet18), our model-agnostic approach adaptively adjusts task importance without requiring gradient access, thereby significantly reducing memory usage and achieving a threefold increase in training speed. It can be easily applied to improve various state-of-the-art methods. Extensive experiments on a large-scale CXR dataset demonstrate that DeepChest not only outperforms state-of-the-art MTL methods by 7% in overall accuracy but also yields substantial reductions in individual task losses, indicating improved generalization and effective mitigation of negative transfer. The efficiency and performance gains of DeepChest pave the way for more practical and robust deployment of deep learning in critical medical diagnostic applications. The code is publicly available at this https URL', 'abstract_zh': 'DeepChest：一种用于多标签胸部X光分类的高效动态任务加权框架', 'title_zh': '深度胸部影像分类：动态无梯度任务加权方法以实现有效的多任务学习'}
{'arxiv_id': 'arXiv:2505.23590', 'title': 'Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles', 'authors': 'Zifu Wang, Junyi Zhu, Bo Tang, Zhiyu Li, Feiyu Xiong, Jiaqian Yu, Matthew B. Blaschko', 'link': 'https://arxiv.org/abs/2505.23590', 'abstract': 'The application of rule-based reinforcement learning (RL) to multimodal large language models (MLLMs) introduces unique challenges and potential deviations from findings in text-only domains, particularly for perception-heavy tasks. This paper provides a comprehensive study of rule-based visual RL using jigsaw puzzles as a structured experimental framework, revealing several key findings. \\textit{Firstly,} we find that MLLMs, initially performing near to random guessing on simple puzzles, achieve near-perfect accuracy and generalize to complex, unseen configurations through fine-tuning. \\textit{Secondly,} training on jigsaw puzzles can induce generalization to other visual tasks, with effectiveness tied to specific task configurations. \\textit{Thirdly,} MLLMs can learn and generalize with or without explicit reasoning, though open-source models often favor direct answering. Consequently, even when trained for step-by-step reasoning, they can ignore the thinking process in deriving the final answer. \\textit{Fourthly,} we observe that complex reasoning patterns appear to be pre-existing rather than emergent, with their frequency increasing alongside training and task difficulty. \\textit{Finally,} our results demonstrate that RL exhibits more effective generalization than Supervised Fine-Tuning (SFT), and an initial SFT cold start phase can hinder subsequent RL optimization. Although these observations are based on jigsaw puzzles and may vary across other visual tasks, this research contributes a valuable piece of jigsaw to the larger puzzle of collective understanding rule-based visual RL and its potential in multimodal learning. The code is available at: \\href{this https URL}{this https URL}.', 'abstract_zh': '基于规则的强化学习在多模态大型语言模型中的应用引入了独特的挑战和潜在的偏差，特别是在感知密集型任务中。本文通过使用拼图作为结构化的实验框架，全面研究了基于规则的视觉RL，揭示了几项关键发现。首先，我们发现，多模态大型语言模型最初在简单拼图上的表现接近随机猜测，通过微调后可达到近乎完美的准确性并泛化到复杂的未见过的配置中。其次，拼图任务的训练可以诱导其他视觉任务的泛化，其有效性与特定任务配置相关。第三，多模态大型语言模型可以在有或没有显式推理的情况下学习和泛化，尽管开源模型往往倾向于直接作答。因此，即使进行了逐步骤推理的训练，它们也可能忽略推理过程以得出最终答案。第四，我们观察到，复杂的推理模式似乎是预先存在的而非涌现出来的，其频率随训练和任务难度的增加而增加。最后，我们的结果表明，强化学习在泛化方面比监督微调更有效，而监督微调的初始冷启动阶段可能会阻碍随后的强化学习优化。虽然这些观察基于拼图任务，但可能在其他视觉任务中有所不同。本研究为集体理解基于规则的视觉RL及其在多模态学习中的潜力贡献了一块有价值的拼图。代码可从以下链接获得：this https URL。', 'title_zh': 'Jigsaw-R1：基于接龙拼图的规则驱动视觉强化学习研究'}
{'arxiv_id': 'arXiv:2505.23584', 'title': 'Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging', 'authors': 'Sumbal Malik, Majid Khonji, Khaled Elbassioni, Jorge Dias', 'link': 'https://arxiv.org/abs/2505.23584', 'abstract': 'The rapid growth of e-commerce and the increasing demand for timely, cost-effective last-mile delivery have increased interest in collaborative logistics. This research introduces a novel collaborative synchronized multi-platform vehicle routing problem with drones and robots (VRP-DR), where a fleet of $\\mathcal{M}$ trucks, $\\mathcal{N}$ drones and $\\mathcal{K}$ robots, cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the launching, retrieving, and en-route charging of drones and robots, thereby addressing critical limitations such as restricted payload capacities, limited range, and battery constraints. The VRP-DR incorporates five realistic features: (1) multi-visit service per trip, (2) multi-trip operations, (3) flexible docking, allowing returns to the same or different trucks (4) cyclic and acyclic operations, enabling return to the same or different nodes; and (5) en-route charging, enabling drones and robots to recharge while being transported on the truck, maximizing operational efficiency by utilizing idle transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP) to minimize both operational costs and makespan. To overcome the computational challenges of solving large-scale instances, a scalable heuristic algorithm, FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to provide efficient, near-optimal solutions. Numerical experiments across various instance sizes evaluate the performance of the MILP and heuristic approaches in terms of solution quality and computation time. The results demonstrate significant time savings of the combined delivery mode over the truck-only mode and substantial cost reductions from enabling multi-visits. The study also provides insights into the effects of en-route charging, docking flexibility, drone count, speed, and payload capacity on system performance.', 'abstract_zh': '电子商务的 rapid growth 和对及时、经济高效最后一英里配送的不断增长需求促使了协同物流的兴趣增加。本文介绍了一种新颖的同步多平台车辆路由问题——无人机和机器人协同配送问题（VRP-DR），涉及 M 辆卡车、N 架无人机和 K 台机器人协同配送包裹。卡车作为移动平台，能够发射、回收和沿途为无人机和机器人充电，从而解决载重量限制、活动范围有限和电池限制等关键问题。VRP-DR 包含五个现实特征：(1) 每次配送多次访问服务，(2) 多次配送操作，(3) 灵活的对接，允许返回同一辆或不同的卡车，(4) 循环和非循环操作，允许返回到同一或不同的节点；以及 (5) 沿途充电，允许无人机和机器人在被运输过程中充电，最大化利用闲置的运输时间以提高操作效率。该问题被表述为混合整数线性规划（MILP）模型以最小化运营成本和作业时间。为克服解决大规模实例的计算挑战，开发了一种可扩展的启发式算法 FINDER（灵活集成交付与能量再充电），以提供高效的近似最优解。通过不同规模实例的数值实验，评估了MILP和启发式方法在解的质量和计算时间方面的性能。结果表明，结合配送模式比单卡车模式显著节省了时间，并且多访问模式带来了显著的成本降低。研究还探讨了沿途充电、对接灵活性、无人机数量、速度和载重能力对系统性能的影响。', 'title_zh': '协同最后一英里配送：含沿途充电的多平台车辆路由问题'}
{'arxiv_id': 'arXiv:2505.23580', 'title': 'Engineering Serendipity through Recommendations of Items with Atypical Aspects', 'authors': 'Ramit Aditya, Razvan Bunescu, Smita Nannaware, Erfan Al-Hossami', 'link': 'https://arxiv.org/abs/2505.23580', 'abstract': 'A restaurant dinner or a hotel stay may lead to memorable experiences when guests encounter unexpected aspects that also match their interests. For example, an origami-making station in the waiting area of a restaurant may be both surprising and enjoyable for a customer who is passionate about paper crafts. Similarly, an exhibit of 18th century harpsichords would be atypical for a hotel lobby and likely pique the interest of a guest who has a passion for Baroque music. Motivated by this insight, in this paper we introduce the new task of engineering serendipity through recommendations of items with atypical aspects. We describe an LLM-based system pipeline that extracts atypical aspects from item reviews, then estimates and aggregates their user-specific utility in a measure of serendipity potential that is used to rerank a list of items recommended to the user. To facilitate system development and evaluation, we introduce a dataset of Yelp reviews that are manually annotated with atypical aspects and a dataset of artificially generated user profiles, together with crowdsourced annotations of user-aspect utility values. Furthermore, we introduce a custom procedure for dynamic selection of in-context learning examples, which is shown to improve LLM-based judgments of atypicality and utility. Experimental evaluations show that serendipity-based rankings generated by the system are highly correlated with ground truth rankings for which serendipity scores are computed from manual annotations of atypical aspects and their user-dependent utility. Overall, we hope that the new recommendation task and the associated system presented in this paper catalyze further research into recommendation approaches that go beyond accuracy in their pursuit of enhanced user satisfaction.\nThe datasets and the code are made publicly available at this https URL .', 'abstract_zh': '餐馆晚餐或酒店住宿可能因意外遇到符合个人兴趣的非典型元素而成为难忘的经历。例如，餐馆候餐区的手工折纸工作站可能会让热衷纸艺的顾客感到惊喜和愉快。同样，酒店大堂中展出的18世纪克拉维科特琴可能会让热衷巴洛克音乐的客人感到兴趣盎然。基于这一洞察，本文介绍了一种通过推荐具有非典型特性的物品来培养偶然性的新任务。我们描述了一种基于大语言模型（LLM）的系统流程，该流程从物品评论中提取非典型特性，然后估计并聚合这些特性的用户特定效用，将其用于重新排列推荐给用户的物品列表。为了促进系统开发和评估，我们引入了一个手工标注非典型特性的 Yelp 评论数据集和一个人工生成的用户画像数据集，以及用户-非典型特性效用值的众包标注。此外，我们引入了一种定制的上下文学习示例动态选择方法，该方法被证明可以提高基于大语言模型的非典型性与效用判断。实验评估表明，系统生成的基于偶然性的排名与从手动标注的非典型特性及其用户依赖效用计算出的真实排名高度相关。总体而言，我们希望通过本文介绍的新推荐任务和相关系统，激发进一步的研究，以探索超越准确性的推荐方法，追求增强的用户满意度。数据集和代码在此网址公开：this https URL。', 'title_zh': '通过推荐具有非典型特征的物品实现偶然发现的工程'}
{'arxiv_id': 'arXiv:2505.23576', 'title': 'Cognitive Guardrails for Open-World Decision Making in Autonomous Drone Swarms', 'authors': 'Jane Cleland-Huang, Pedro Antonio Alarcon Granadeno, Arturo Miguel Russell Bernal, Demetrius Hernandez, Michael Murphy, Maureen Petterson, Walter Scheirer', 'link': 'https://arxiv.org/abs/2505.23576', 'abstract': 'Small Uncrewed Aerial Systems (sUAS) are increasingly deployed as autonomous swarms in search-and-rescue and other disaster-response scenarios. In these settings, they use computer vision (CV) to detect objects of interest and autonomously adapt their missions. However, traditional CV systems often struggle to recognize unfamiliar objects in open-world environments or to infer their relevance for mission planning. To address this, we incorporate large language models (LLMs) to reason about detected objects and their implications. While LLMs can offer valuable insights, they are also prone to hallucinations and may produce incorrect, misleading, or unsafe recommendations. To ensure safe and sensible decision-making under uncertainty, high-level decisions must be governed by cognitive guardrails. This article presents the design, simulation, and real-world integration of these guardrails for sUAS swarms in search-and-rescue missions.', 'abstract_zh': '小型无人航空系统（sUAS）越来越多地被部署为自主蜂群，在搜索救援和其他灾害响应场景中发挥作用。在这些环境中，它们利用计算机视觉（CV）检测感兴趣的目标并自主调整任务。然而，传统CV系统往往难以在开放环境识别未知物体，或推断其对任务规划的相关性。为了解决这一问题，我们引入了大规模语言模型（LLMs）来推理检测到的物体及其影响。虽然LLMs能提供有价值的见解，但也容易产生幻觉，可能会产生不正确的、误导的或不安全的建议。为了在不确定性下确保安全和合理的决策，高层决策必须受到认知护栏的约束。本文介绍了这些护栏在搜索救援任务中对sUAS蜂群的设计、模拟和实际集成。', 'title_zh': '开放世界自主无人机群决策的认知护航机制'}
{'arxiv_id': 'arXiv:2505.23564', 'title': 'Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models', 'authors': 'Yiran Guo, Lijie Xu, Jie Liu, Dan Ye, Shuang Qiu', 'link': 'https://arxiv.org/abs/2505.23564', 'abstract': 'Enhancing the reasoning capabilities of large language models effectively using reinforcement learning (RL) remains a crucial challenge. Existing approaches primarily adopt two contrasting advantage estimation granularities: Token-level methods (e.g., PPO) aim to provide the fine-grained advantage signals but suffer from inaccurate estimation due to difficulties in training an accurate critic model. On the other extreme, trajectory-level methods (e.g., GRPO) solely rely on a coarse-grained advantage signal from the final reward, leading to imprecise credit assignment. To address these limitations, we propose Segment Policy Optimization (SPO), a novel RL framework that leverages segment-level advantage estimation at an intermediate granularity, achieving a better balance by offering more precise credit assignment than trajectory-level methods and requiring fewer estimation points than token-level methods, enabling accurate advantage estimation based on Monte Carlo (MC) without a critic model. SPO features three components with novel strategies: (1) flexible segment partition; (2) accurate segment advantage estimation; and (3) policy optimization using segment advantages, including a novel probability-mask strategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain for short chain-of-thought (CoT), featuring novel cutpoint-based partition and chain-based advantage estimation, achieving $6$-$12$ percentage point improvements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT, featuring novel tree-based advantage estimation, which significantly reduces the cost of MC estimation, achieving $7$-$11$ percentage point improvements over GRPO on MATH500 under 2K and 4K context evaluation. We make our code publicly available at this https URL.', 'abstract_zh': '使用强化学习有效增强大型语言模型的推理能力仍然是一个关键挑战。现有方法主要采用两种对比的优势估计粒度：字级方法（例如PPO）力求提供精细的优势信号，但由于难以训练准确的评论者模型，导致估计不准确。在另一极端，轨迹级方法（例如GRPO）仅依赖于最终奖励的粗粒度优势信号，导致不精确的信用分配。为了解决这些限制，我们提出了一种新颖的RL框架——段落策略优化（SPO），该框架利用中间粒度的段落级优势估计，通过提供比轨迹级方法更精确的信用分配和比字级方法更少的估计点，实现基于蒙特卡洛（MC）的优势估计，无需评论者模型。SPO具有三个具有新颖策略的组件：（1）灵活的段落划分；（2）准确的段落优势估计；（3）使用段落优势进行策略优化，包括一种新颖的概率遮罩策略。我们进一步为两种特定场景实例化了SPO：（1）SPO-chain，针对短链式思考（CoT），使用基于切点的划分和基于链的优势估计，相比PPO和GRPO在GSM8K上实现了6-12个百分点的准确率提升。（2）SPO-tree，针对长CoT，使用基于树的优势估计，大幅降低了MC估计的成本，在MATH500下的2K和4K上下文评估中，相比GRPO实现了7-11个百分点的准确率提升。我们已公开发布代码，链接为 THIS https URL。', 'title_zh': '段级策略优化：大型语言模型中基于段的有效信用分配在RL中的应用'}
{'arxiv_id': 'arXiv:2505.23554', 'title': 'Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters', 'authors': 'Hayden Moore, Sirui Qi, Ninad Hogade, Dejan Milojicic, Cullen Bash, Sudeep Pasricha', 'link': 'https://arxiv.org/abs/2505.23554', 'abstract': 'In recent years, Large Language Models (LLM) such as ChatGPT, CoPilot, and Gemini have been widely adopted in different areas. As the use of LLMs continues to grow, many efforts have focused on reducing the massive training overheads of these models. But it is the environmental impact of handling user requests to LLMs that is increasingly becoming a concern. Recent studies estimate that the costs of operating LLMs in their inference phase can exceed training costs by 25x per year. As LLMs are queried incessantly, the cumulative carbon footprint for the operational phase has been shown to far exceed the footprint during the training phase. Further, estimates indicate that 500 ml of fresh water is expended for every 20-50 requests to LLMs during inference. To address these important sustainability issues with LLMs, we propose a novel framework called SLIT to co-optimize LLM quality of service (time-to-first token), carbon emissions, water usage, and energy costs. The framework utilizes a machine learning (ML) based metaheuristic to enhance the sustainability of LLM hosting across geo-distributed cloud datacenters. Such a framework will become increasingly vital as LLMs proliferate.', 'abstract_zh': '近年来，大型语言模型（LLM）如ChatGPT、CoPilot和Gemini已在不同领域广泛采用。随着LLM的使用不断增长，许多努力集中在减少这些模型的巨额训练开销上。然而，处理用户对LLM请求的环境影响正变得日益令人关注。近期研究表明，LLM推理阶段的运营成本可能每年比训练成本高出25倍。由于LLM不断被查询，运行阶段的累计碳足迹已被证明远远超过训练阶段的足迹。此外，估算表明，每次LLM推理请求消耗的新鲜水量约为500毫升。为解决这些重要的可持续性问题，我们提出了一种名为SLIT的新框架，旨在协同优化LLM的服务质量（最早令牌时间）、碳排放、水资源使用和能源成本。该框架利用基于机器学习的元启发式方法，以增强跨地理分布的云数据中心中LLM的可持续性。随着LLM的普及，这种框架将变得越来越重要。', 'title_zh': '地理分布云数据中心中的可持续碳意识和水资源高效LLM调度'}
{'arxiv_id': 'arXiv:2505.23538', 'title': 'CLaC at SemEval-2025 Task 6: A Multi-Architecture Approach for Corporate Environmental Promise Verification', 'authors': 'Nawar Turk, Eeham Khan, Leila Kosseim', 'link': 'https://arxiv.org/abs/2505.23538', 'abstract': 'This paper presents our approach to the SemEval-2025 Task~6 (PromiseEval), which focuses on verifying promises in corporate ESG (Environmental, Social, and Governance) reports. We explore three model architectures to address the four subtasks of promise identification, supporting evidence assessment, clarity evaluation, and verification timing. Our first model utilizes ESG-BERT with task-specific classifier heads, while our second model enhances this architecture with linguistic features tailored for each subtask. Our third approach implements a combined subtask model with attention-based sequence pooling, transformer representations augmented with document metadata, and multi-objective learning. Experiments on the English portion of the ML-Promise dataset demonstrate progressive improvement across our models, with our combined subtask approach achieving a leaderboard score of 0.5268, outperforming the provided baseline of 0.5227. Our work highlights the effectiveness of linguistic feature extraction, attention pooling, and multi-objective learning in promise verification tasks, despite challenges posed by class imbalance and limited training data.', 'abstract_zh': '本文介绍了我们针对SemEval-2025 Task 6（PromiseEval）的方法，专注于验证企业ESG（环境、社会和治理）报告中的承诺。我们探索了三种模型架构来应对承诺识别、支持证据评估、清晰度评价和验证时间四个子任务。我们的第一个模型采用了ESG-BERT并结合了具有特定任务分类头的模型，第二个模型在此基础上加入了针对每个子任务定制的语言特征。我们的第三个方法则实现了一种结合子任务的模型，该模型采用了基于注意力的序列池化、结合文档元数据的变压器表示，并进行了多目标学习。在ML-Promise数据集的英语部分上的实验表明，我们的模型展现了逐步改进的趋势，其中结合子任务的方法在排行榜上取得了0.5268的分数，优于提供的基线0.5227。我们的研究突显了在承诺验证任务中提取语言特征、注意力池化和多目标学习的有效性，尽管面临着类别不平衡和训练数据有限的挑战。', 'title_zh': 'CLaC 在 SemEval-2025 任务 6 中的多模型方法及其在企业环境承诺验证中的应用'}
{'arxiv_id': 'arXiv:2505.23529', 'title': 'Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning', 'authors': 'Shifeng Xie, Aref Einizade, Jhony H. Giraldo', 'link': 'https://arxiv.org/abs/2505.23529', 'abstract': 'Graph Representation Learning (GRL) is a fundamental task in machine learning, aiming to encode high-dimensional graph-structured data into low-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used in GRL because they can avoid expensive human annotation. In this work, we propose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our approach introduces a subgraph Gaussian embedding module, which adaptively maps subgraphs to a structured Gaussian space, ensuring the preservation of input subgraph characteristics while generating subgraphs with a controlled distribution. We then employ optimal transport distances, more precisely the Wasserstein and Gromov-Wasserstein distances, to effectively measure the similarity between subgraphs, enhancing the robustness of the contrastive learning process. Extensive experiments across multiple benchmarks demonstrate that \\method~outperforms or presents competitive performance against state-of-the-art approaches. Our findings provide insights into the design of SSL methods for GRL, emphasizing the importance of the distribution of the generated contrastive pairs.', 'abstract_zh': '图表示学习（GRL）是机器学习中的一个基础任务，旨在将高维图结构数据编码为低维向量。自我监督学习（SSL）方法在GRL中广泛使用，因为它们可以避免昂贵的人工标注。在本文中，我们提出了一种新型的子图高斯嵌入对比（SubGEC）方法。我们的方法引入了一个子图高斯嵌入模块，该模块自适应地将子图映射到结构化高斯空间，同时保证输入子图特征的保留，并生成具有可控分布的子图。我们随后采用最优传输距离，即 Wasserstein 距离和 Gromov-Wasserstein 距离，以有效地度量子图之间的相似性，增强了对比学习过程的鲁棒性。在多个基准上的广泛实验表明，本方法在性能上优于或与最先进的方法相竞争。我们的发现为GRL中的SSL方法的设计提供了见解，强调了生成对比对之间分布的重要性。', 'title_zh': '子图高斯嵌入对比学习自监督图表示学习'}
{'arxiv_id': 'arXiv:2505.23508', 'title': 'A Robot-Assisted Approach to Small Talk Training for Adults with ASD', 'authors': 'Rebecca Ramnauth, Dražen Brščić, Brian Scassellati', 'link': 'https://arxiv.org/abs/2505.23508', 'abstract': 'From dating to job interviews, making new friends or simply chatting with the cashier at checkout, engaging in small talk is a vital, everyday social skill. For adults with Autism Spectrum Disorder (ASD), small talk can be particularly challenging, yet it is essential for social integration, building relationships, and accessing professional opportunities. In this study, we present our development and evaluation of an in-home autonomous robot system that allows users to practice small talk. Results from the week-long study show that adults with ASD enjoyed the training, made notable progress in initiating conversations and improving eye contact, and viewed the system as a valuable tool for enhancing their conversational skills.', 'abstract_zh': '从约会到面试，从结交新朋友到与收银员闲聊，进行闲聊是日常重要的社会技能。对于自闭谱系障碍（ASD）成人来说，闲聊可能特别具有挑战性，但却是社交融入、建立人际关系和获取职业机会的关键。在本研究中，我们介绍了我们开发和评估的家庭自主机器人系统，该系统允许用户练习闲聊。为期一周的研究结果显示，ASD成人享受了训练，提高了启动对话和改善眼神接触的能力，并将该系统视为提高其交际技能的宝贵工具。', 'title_zh': 'ASD患者机器人辅助社交交谈训练的方法'}
{'arxiv_id': 'arXiv:2505.23503', 'title': 'Can Large Language Models Challenge CNNS in Medical Image Analysis?', 'authors': 'Shibbir Ahmed, Shahnewaz Karim Sakib, Anindya Bijoy Das', 'link': 'https://arxiv.org/abs/2505.23503', 'abstract': 'This study presents a multimodal AI framework designed for precisely classifying medical diagnostic images. Utilizing publicly available datasets, the proposed system compares the strengths of convolutional neural networks (CNNs) and different large language models (LLMs). This in-depth comparative analysis highlights key differences in diagnostic performance, execution efficiency, and environmental impacts. Model evaluation was based on accuracy, F1-score, average execution time, average energy consumption, and estimated $CO_2$ emission. The findings indicate that although CNN-based models can outperform various multimodal techniques that incorporate both images and contextual information, applying additional filtering on top of LLMs can lead to substantial performance gains. These findings highlight the transformative potential of multimodal AI systems to enhance the reliability, efficiency, and scalability of medical diagnostics in clinical settings.', 'abstract_zh': '本研究提出了一种多模态AI框架，旨在精确分类医学诊断图像。利用公开可用的数据集，该系统比较了卷积神经网络（CNNs）和不同大型语言模型（LLMs）的优势。深入比较分析突出了诊断性能、执行效率和环境影响的关键差异。模型评估基于准确率、F1分数、平均执行时间、平均能耗以及估算的\\(CO_2\\)排放量。研究结果表明，尽管基于CNN的模型可以在综合图像和上下文信息的多种多模态技术中表现出优越性，但在LLMs基础上增加额外过滤器可以实现显著的性能提升。这些发现突显了多模态AI系统在临床环境中提高医学诊断的可靠性和效率以及可扩展性的转变潜力。', 'title_zh': '大型语言模型能否在医疗图像分析中挑战CNNS？'}
{'arxiv_id': 'arXiv:2505.23454', 'title': 'LCB-CV-UNet: Enhanced Detector for High Dynamic Range Radar Signals', 'authors': 'Yanbin Wang, Xingyu Chen, Yumiao Wang, Xiang Wang, Chuanfei Zang, Guolong Cui, Jiahuan Liu', 'link': 'https://arxiv.org/abs/2505.23454', 'abstract': 'We propose the LCB-CV-UNet to tackle performance degradation caused by High Dynamic Range (HDR) radar signals. Initially, a hardware-efficient, plug-and-play module named Logarithmic Connect Block (LCB) is proposed as a phase coherence preserving solution to address the inherent challenges in handling HDR features. Then, we propose the Dual Hybrid Dataset Construction method to generate a semi-synthetic dataset, approximating typical HDR signal scenarios with adjustable target distributions. Simulation results show about 1% total detection probability improvement with under 0.9% computational complexity added compared with the baseline. Furthermore, it excels 5% over the baseline at the range in 11-13 dB signal-to-noise ratio typical for urban targets. Finally, the real experiment validates the practicality of our model.', 'abstract_zh': '我们提出LCB-CV-UNet以解决高动态范围(HDR)雷达信号引起的性能退化问题。首先，提出一种硬件高效、插件式模块对数连接块(LCB)，作为一种相位相干性保持解决方案，以应对处理HDR特征时固有的挑战。随后，我们提出双混合数据集构建方法，生成一个半合成数据集，可以调节目标分布来逼近典型HDR信号场景。仿真结果显示，在计算复杂度增加不到0.9%的情况下，总检测概率提高了约1%。此外，在11-13 dB信噪比下，对于城市目标，该方法在距离上优于基线5%。最后，实际实验验证了我们模型的实用性。', 'title_zh': 'LCB-CV-UNet：增强型高动态范围雷达信号检测器'}
{'arxiv_id': 'arXiv:2505.23444', 'title': 'CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis', 'authors': 'Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Yuheng Zhang, Wanyue Feng, Yizhou Zhao, Xi Xiao, Xiao Wang, Tianyang Wang, Xingjian Li, Min Xu', 'link': 'https://arxiv.org/abs/2505.23444', 'abstract': 'Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.', 'abstract_zh': '冷冻电子显微镜（cryo-EM）提供了接近原子级别的大分子成像，但下游分析中稳健模型的开发受限于高质量标注数据的稀缺性。虽然合成数据生成已成为一种潜在的解决方案，但现有方法往往无法捕捉到生物标本的结构多样性以及冷冻电子显微镜成像中固有的复杂且空间变化的噪声。为了克服这些限制，我们提出了一种名为CryoCCD的合成框架，该框架结合了生物物理建模与生成技术。具体而言，CryoCCD产生多层次的冷冻电子显微镜微图，通过组分异质性、细胞背景和基于物理的成像反映了现实的生物物理变异性。为了生成真实的噪声，我们采用条件扩散模型，并通过循环一致性保持结构保真度，同时通过掩码感知对比学习捕捉空间自适应的噪声模式。广泛的经验表明，CryoCCD生成结构准确的微图并在下游任务中增强了性能，在粒子挑选和重构方面均超过了最先进的基线方法。', 'title_zh': 'CryoCCD：基于生物物理建模的条件循环一致扩散方法用于冷冻电镜结构合成'}
{'arxiv_id': 'arXiv:2505.23437', 'title': 'Bounded-Abstention Pairwise Learning to Rank', 'authors': 'Antonio Ferrara, Andrea Pugnana, Francesco Bonchi, Salvatore Ruggieri', 'link': 'https://arxiv.org/abs/2505.23437', 'abstract': "Ranking systems influence decision-making in high-stakes domains like health, education, and employment, where they can have substantial economic and social impacts. This makes the integration of safety mechanisms essential. One such mechanism is $\\textit{abstention}$, which enables algorithmic decision-making system to defer uncertain or low-confidence decisions to human experts. While abstention have been predominantly explored in the context of classification tasks, its application to other machine learning paradigms remains underexplored. In this paper, we introduce a novel method for abstention in pairwise learning-to-rank tasks. Our approach is based on thresholding the ranker's conditional risk: the system abstains from making a decision when the estimated risk exceeds a predefined threshold. Our contributions are threefold: a theoretical characterization of the optimal abstention strategy, a model-agnostic, plug-in algorithm for constructing abstaining ranking models, and a comprehensive empirical evaluations across multiple datasets, demonstrating the effectiveness of our approach.", 'abstract_zh': '排名系统在高 stakes 领域如健康、教育和就业中影响决策，这些领域可能产生重大经济和社会影响。因此，整合安全机制变得至关重要。其中一种机制是“弃权”（abstention），使算法决策系统能够将不确定或低置信度的决策交给人类专家。尽管弃权主要在分类任务中进行探讨，但其在其他机器学习范式中的应用尚未得到充分研究。在本文中，我们提出了在成对学习排序任务中弃权的一种新方法。我们的方法基于阈值化排序器的条件风险：当估计风险超过预定义阈值时，系统弃权决策。我们的贡献包括：最优弃权策略的理论表征、不依赖于特定模型的插件算法以构建弃权排序模型，以及在多个数据集上的全面实证评估，证明了我们方法的有效性。', 'title_zh': '有界弃权成对学习排序'}
{'arxiv_id': 'arXiv:2505.23426', 'title': 'Enhanced DACER Algorithm with High Diffusion Efficiency', 'authors': 'Yinuo Wang, Mining Tan, Wenjun Zou, Haotian Lin, Xujie Song, Wenxuan Wang, Tong Liu, Likun Wang, Guojian Zhan, Tianze Zhu, Shiqi Liu, Jingliang Duan, Shengbo Eben Li', 'link': 'https://arxiv.org/abs/2505.23426', 'abstract': 'Due to their expressive capacity, diffusion models have shown great promise in offline RL and imitation learning. Diffusion Actor-Critic with Entropy Regulator (DACER) extended this capability to online RL by using the reverse diffusion process as a policy approximator, trained end-to-end with policy gradient methods, achieving strong performance. However, this comes at the cost of requiring many diffusion steps, which significantly hampers training efficiency, while directly reducing the steps leads to noticeable performance degradation. Critically, the lack of inference efficiency becomes a significant bottleneck for applying diffusion policies in real-time online RL settings. To improve training and inference efficiency while maintaining or even enhancing performance, we propose a Q-gradient field objective as an auxiliary optimization target to guide the denoising process at each diffusion step. Nonetheless, we observe that the independence of the Q-gradient field from the diffusion time step negatively impacts the performance of the diffusion policy. To address this, we introduce a temporal weighting mechanism that enables the model to efficiently eliminate large-scale noise in the early stages and refine actions in the later stages. Experimental results on MuJoCo benchmarks and several multimodal tasks demonstrate that the DACER2 algorithm achieves state-of-the-art performance in most MuJoCo control tasks with only five diffusion steps, while also exhibiting stronger multimodality compared to DACER.', 'abstract_zh': '基于扩散模型的Actor-Critic算法在在线强化学习中的高效实现：DACER2算法', 'title_zh': '增强型高扩散效率DACER算法'}
{'arxiv_id': 'arXiv:2505.23422', 'title': 'From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents', 'authors': 'Tobias Lindenbauer, Georg Groh, Hinrich Schütze', 'link': 'https://arxiv.org/abs/2505.23422', 'abstract': 'We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.', 'abstract_zh': 'CTIM-Rover：一种基于AutoCodeRover的软件工程AI代理', 'title_zh': '从知识到噪声：CTIM-Rover及其软件工程代理中情景记忆的局限性'}
{'arxiv_id': 'arXiv:2505.23419', 'title': 'SWE-bench Goes Live!', 'authors': 'Linghao Zhang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Chengxing Xie, Junhao Wang, Maoquan Wang, Yufan Huang, Shengyu Fu, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang', 'link': 'https://arxiv.org/abs/2505.23419', 'abstract': 'The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not been updated since their initial releases, cover a narrow set of repositories, and depend heavily on manual effort for instance construction and environment setup. These factors hinder scalability and introduce risks of overfitting and data contamination. In this work, we present \\textbf{SWE-bench-Live}, a \\textit{live-updatable} benchmark designed to overcome these challenges. Our initial release consists of 1,319 tasks derived from real GitHub issues created since 2024, spanning 93 repositories. Each task is accompanied by a dedicated Docker image to ensure reproducible execution. Central to our benchmark is \\method, an automated curation pipeline that streamlines the entire process from instance creation to environment setup, removing manual bottlenecks and enabling scalability and continuous updates. We evaluate a range of state-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a substantial performance gap compared to static benchmarks like SWE-bench, even under controlled evaluation conditions. To better understand this discrepancy, we perform detailed analyses across repository origin, issue recency, and task difficulty. By providing a fresh, diverse, and executable benchmark grounded in live repository activity, SWE-bench-Live facilitates rigorous, contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings.', 'abstract_zh': 'SWE-bench-Live：一个实时可更新的基准评测', 'title_zh': 'SWE-bench 正式上线！'}
{'arxiv_id': 'arXiv:2505.23417', 'title': 'Toward Effective AI Governance: A Review of Principles', 'authors': 'Danilo Ribeiro, Thayssa Rocha, Gustavo Pinto, Bruno Cartaxo, Marcelo Amaral, Nicole Davila, Ana Camargo', 'link': 'https://arxiv.org/abs/2505.23417', 'abstract': 'Artificial Intelligence (AI) governance is the practice of establishing frameworks, policies, and procedures to ensure the responsible, ethical, and safe development and deployment of AI systems. Although AI governance is a core pillar of Responsible AI, current literature still lacks synthesis across such governance frameworks and practices. Objective: To identify which frameworks, principles, mechanisms, and stakeholder roles are emphasized in secondary literature on AI governance. Method: We conducted a rapid tertiary review of nine peer-reviewed secondary studies from IEEE and ACM (20202024), using structured inclusion criteria and thematic semantic synthesis. Results: The most cited frameworks include the EU AI Act and NIST RMF; transparency and accountability are the most common principles. Few reviews detail actionable governance mechanisms or stakeholder strategies. Conclusion: The review consolidates key directions in AI governance and highlights gaps in empirical validation and inclusivity. Findings inform both academic inquiry and practical adoption in organizations.', 'abstract_zh': '人工智能治理是建立框架、政策和程序以确保人工智能系统的负责任、伦理和安全开发与部署的实践。尽管人工智能治理是负责任人工智能的核心支柱，但当前文献仍缺乏对这类治理框架和实践的综合总结。目标：识别secondary文献中人工智能治理所强调的框架、原则、机制和利益相关者角色。方法：我们使用结构化的纳入标准和主题语义合成，对IEEE和ACM（2020-2024）的九篇同行评议secondary研究进行了快速三级审查。结果：引用最多的框架包括欧盟AI法案和NIST风险管理框架；透明度和问责制是最常见的原则。很少有综述详细说明可操作的治理机制或利益相关者策略。结论：该审查总结了人工智能治理的关键方向，并指出了实证验证不足和包容性不足的问题。研究结果既指导学术研究，也促进组织中的实际应用。', 'title_zh': '有效人工智能治理的原则综述'}
{'arxiv_id': 'arXiv:2505.23415', 'title': 'Bidirectional predictive coding', 'authors': 'Gaspard Oliviers, Mufeng Tang, Rafal Bogacz', 'link': 'https://arxiv.org/abs/2505.23415', 'abstract': "Predictive coding (PC) is an influential computational model of visual learning and inference in the brain. Classical PC was proposed as a top-down generative model, where the brain actively predicts upcoming visual inputs, and inference minimises the prediction errors. Recent studies have also shown that PC can be formulated as a discriminative model, where sensory inputs predict neural activities in a feedforward manner. However, experimental evidence suggests that the brain employs both generative and discriminative inference, while unidirectional PC models show degraded performance in tasks requiring bidirectional processing. In this work, we propose bidirectional PC (bPC), a PC model that incorporates both generative and discriminative inference while maintaining a biologically plausible circuit implementation. We show that bPC matches or outperforms unidirectional models in their specialised generative or discriminative tasks, by developing an energy landscape that simultaneously suits both tasks. We also demonstrate bPC's superior performance in two biologically relevant tasks including multimodal learning and inference with missing information, suggesting that bPC resembles biological visual inference more closely.", 'abstract_zh': '双向预测编码(bPC):结合生成和判别推理的生物可行性模型', 'title_zh': '双向预测编码'}
{'arxiv_id': 'arXiv:2505.23412', 'title': 'Buffer-free Class-Incremental Learning with Out-of-Distribution Detection', 'authors': 'Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli', 'link': 'https://arxiv.org/abs/2505.23412', 'abstract': 'Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must not only learn new classes over time without forgetting previous ones but also handle inputs from unknown classes that a closed-set model would misclassify. Recent works address both issues by (i)~training multi-head models using the task-incremental learning framework, and (ii) predicting the task identity employing out-of-distribution (OOD) detectors. While effective, the latter mainly relies on joint training with a memory buffer of past data, raising concerns around privacy, scalability, and increased training time. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. We uncover that these methods, when applied appropriately at inference time, can serve as a strong substitute for buffer-based OOD detection. We show that this buffer-free approach achieves comparable or superior performance to buffer-based methods both in terms of class-incremental learning and the rejection of unknown samples. Experimental results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings, offering new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.', 'abstract_zh': '开放场景下类增量学习（CIL）提出了显著挑战，模型不仅要在线学习新类目同时不忘记先前的类目，还要处理来自封闭集模型无法正确分类的未知类别的输入。最新研究通过（i）使用任务增量学习框架训练多头模型，以及（ii）使用异常分布（OOD）检测器预测任务身份，同时有效应对了上述问题。然而，第二种方法主要依赖于与过去数据记忆缓冲的联合训练，这引发了关于隐私性、可扩展性和增加训练时间的担忧。本文深入分析了事后异常分布检测方法，并探讨了它们在消除记忆缓冲需求方面的潜力。我们发现，在合适的推理时间应用这些方法，可以作为基于缓冲的异常分布检测的强有力替代方案。实验结果表明，该无缓冲方法在类增量学习和排除未知样本方面，无论是性能还是表现，都达到了基于缓冲的方法的可比或优越水平。CIFAR-10、CIFAR-100和Tiny ImageNet数据集上的实验结果支持我们的发现，为开放场景下高效且隐私保护的CIL系统设计提供了新的见解。', 'title_zh': '无缓冲的类别增量学习与_out-of-distribution_检测'}
{'arxiv_id': 'arXiv:2505.23406', 'title': 'Video Editing for Audio-Visual Dubbing', 'authors': 'Binyamin Manela, Sharon Gannot, Ethan Fetyaya', 'link': 'https://arxiv.org/abs/2505.23406', 'abstract': 'Visual dubbing, the synchronization of facial movements with new speech, is crucial for making content accessible across different languages, enabling broader global reach. However, current methods face significant limitations. Existing approaches often generate talking faces, hindering seamless integration into original scenes, or employ inpainting techniques that discard vital visual information like partial occlusions and lighting variations. This work introduces EdiDub, a novel framework that reformulates visual dubbing as a content-aware editing task. EdiDub preserves the original video context by utilizing a specialized conditioning scheme to ensure faithful and accurate modifications rather than mere copying. On multiple benchmarks, including a challenging occluded-lip dataset, EdiDub significantly improves identity preservation and synchronization. Human evaluations further confirm its superiority, achieving higher synchronization and visual naturalness scores compared to the leading methods. These results demonstrate that our content-aware editing approach outperforms traditional generation or inpainting, particularly in maintaining complex visual elements while ensuring accurate lip synchronization.', 'abstract_zh': '基于内容的视觉配音：一种新的方法以提高身份保留和同步性', 'title_zh': '视听配音的视频编辑'}
{'arxiv_id': 'arXiv:2505.23387', 'title': 'Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization', 'authors': 'Mingzhe Du, Luu Tuan Tuan, Yue Liu, Yuhao Qing, Dong Huang, Xinyi He, Qian Liu, Zejun Ma, See-kiong Ng', 'link': 'https://arxiv.org/abs/2505.23387', 'abstract': 'Large Language Models (LLMs) generate functionally correct solutions but often fall short in code efficiency, a critical bottleneck for real-world deployment. In this paper, we introduce a novel test-time iterative optimization framework to address this, employing a closed-loop system where LLMs iteratively refine code based on empirical performance feedback from an execution sandbox. We explore three training strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization~(GRPO). Experiments on our Venus dataset and the APPS benchmark show that SFT and DPO rapidly saturate in efficiency gains. In contrast, GRPO, using reinforcement learning (RL) with execution feedback, continuously optimizes code performance, significantly boosting both pass@1 (from 47% to 62%) and the likelihood of outperforming human submissions in efficiency (from 31% to 45%). Our work demonstrates effective test-time code efficiency improvement and critically reveals the power of RL in teaching LLMs to truly self-improve code efficiency.', 'abstract_zh': '大型语言模型（LLMs）生成功能正确的解决方案，但在代码效率方面常常表现不佳，这是其实用部署中的一个关键瓶颈。本文介绍了一种新的测试时迭代优化框架，采用闭环系统，使LLMs能够根据执行沙盒中的经验性能反馈迭代优化代码。我们探索了三种训练策略：监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。实验结果表明，SFT和DPO在效率提升上迅速饱和。相比之下，GRPO利用执行反馈进行强化学习（RL），能够持续优化代码性能，显著提高了pass@1（从47%提升到62%）和在效率上超过人类提交代码的可能性（从31%提升到45%）。我们的工作展示了有效的测试时代码效率改进，并揭示了RL在教导LLMs实现真正自改进代码效率方面的强大能力。', 'title_zh': 'Afterburner: 强化学习促进自改进代码效率优化'}
{'arxiv_id': 'arXiv:2505.23386', 'title': 'VModA: An Effective Framework for Adaptive NSFW Image Moderation', 'authors': 'Han Bao, Qinying Wang, Zhi Chen, Qingming Li, Xuhong Zhang, Changjiang Li, Zonghui Wang, Shouling Ji, Wenzhi Chen', 'link': 'https://arxiv.org/abs/2505.23386', 'abstract': 'Not Safe/Suitable for Work (NSFW) content is rampant on social networks and poses serious harm to citizens, especially minors. Current detection methods mainly rely on deep learning-based image recognition and classification. However, NSFW images are now presented in increasingly sophisticated ways, often using image details and complex semantics to obscure their true nature or attract more views. Although still understandable to humans, these images often evade existing detection methods, posing a significant threat. Further complicating the issue, varying regulations across platforms and regions create additional challenges for effective moderation, leading to detection bias and reduced accuracy. To address this, we propose VModA, a general and effective framework that adapts to diverse moderation rules and handles complex, semantically rich NSFW content across categories. Experimental results show that VModA significantly outperforms existing methods, achieving up to a 54.3% accuracy improvement across NSFW types, including those with complex semantics. Further experiments demonstrate that our method exhibits strong adaptability across categories, scenarios, and base VLMs. We also identified inconsistent and controversial label samples in public NSFW benchmark datasets, re-annotated them, and submitted corrections to the original maintainers. Two datasets have confirmed the updates so far. Additionally, we evaluate VModA in real-world scenarios to demonstrate its practical effectiveness.', 'abstract_zh': '不适合工作（NSFW）内容在社交网络上泛滥并对公民，特别是未成年人造成了严重危害。当前的检测方法主要依赖基于深度学习的图像识别和分类。然而，NSFW图像现在以日益复杂的方式呈现，常常通过图像细节和复杂的语义来掩盖其真实性质或吸引更多关注。虽然这些图像对人类仍具有可理解性，但往往能够绕过现有的检测方法，构成重大威胁。进一步复杂化的是，不同平台和地区的不同规定为有效的网络监管带来了额外挑战，导致检测偏差和准确性降低。为应对这一问题，我们提出了一种适应性强且有效的框架VModA，该框架能够适应多样化的监管规则，并处理跨类别复杂的、语义丰富的NSFW内容。实验结果显示，VModA在NSFW类型中显著优于现有方法，尤其是在复杂语义类型中实现了多达54.3%的准确性提升。进一步的实验显示，我们的方法在类别、场景和基础VLM之间具有很强的适应性。我们还在公共NSFW基准数据集中发现了不一致和有争议的标签样本，重新标注了这些样本，并向原维护者提交了更正。截至目前，两个数据集已经确认了更新。此外，我们还在现实场景中评估了VModA，展示了其实用效果。', 'title_zh': 'VModA：一种有效的自适应 NSFW 图像审核框架'}
{'arxiv_id': 'arXiv:2505.23369', 'title': 'Dynamic Spectral Backpropagation for Efficient Neural Network Training', 'authors': 'Mannmohan Muthuraman', 'link': 'https://arxiv.org/abs/2505.23369', 'abstract': 'Dynamic Spectral Backpropagation (DSBP) enhances neural network training under resource constraints by projecting gradients onto principal eigenvectors, reducing complexity and promoting flat minima. Five extensions are proposed, dynamic spectral inference, spectral architecture optimization, spectral meta learning, spectral transfer regularization, and Lie algebra inspired dynamics, to address challenges in robustness, fewshot learning, and hardware efficiency. Supported by a third order stochastic differential equation (SDE) and a PAC Bayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank Adaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion MNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive experiments and visualizations. Future work focuses on scalability, bias mitigation, and ethical considerations.', 'abstract_zh': '动态谱 backpropagation (DSBP) 在资源受限条件下通过将梯度投影到主特征向量上增强神经网络训练，降低复杂度并促进平坦极小值。提出五种扩展，动态谱推断、谱架构优化、谱元学习、谱转移正则化以及基于李代数的动力学，以应对稳健性、少样本学习和硬件效率挑战。通过三级随机微分方程 (SDE) 和 PAC 湹率极限支持，DSBP 在 CIFAR 10、Fashion MNIST、MedMNIST 和 Tiny ImageNet 上超越了 Sharpness Aware Minimization (SAM)、Low Rank Adaptation (LoRA) 和 Model Agnostic Meta Learning (MAML)，如广泛实验和可视化所示。未来工作集中在可扩展性、偏差缓解和伦理考虑上。', 'title_zh': '高效的神经网络训练动态谱 backpropagation 方法'}
{'arxiv_id': 'arXiv:2505.23367', 'title': 'PAN-Crafter: Learning Modality-Consistent Alignment for PAN-Sharpening', 'authors': 'Jeonghyeok Do, Sungpyo Kim, Geunhyuk Youk, Jaehyup Lee, Munchurl Kim', 'link': 'https://arxiv.org/abs/2505.23367', 'abstract': "PAN-sharpening aims to fuse high-resolution panchromatic (PAN) images with low-resolution multi-spectral (MS) images to generate high-resolution multi-spectral (HRMS) outputs. However, cross-modality misalignment -- caused by sensor placement, acquisition timing, and resolution disparity -- induces a fundamental challenge. Conventional deep learning methods assume perfect pixel-wise alignment and rely on per-pixel reconstruction losses, leading to spectral distortion, double edges, and blurring when misalignment is present. To address this, we propose PAN-Crafter, a modality-consistent alignment framework that explicitly mitigates the misalignment gap between PAN and MS modalities. At its core, Modality-Adaptive Reconstruction (MARs) enables a single network to jointly reconstruct HRMS and PAN images, leveraging PAN's high-frequency details as auxiliary self-supervision. Additionally, we introduce Cross-Modality Alignment-Aware Attention (CM3A), a novel mechanism that bidirectionally aligns MS texture to PAN structure and vice versa, enabling adaptive feature refinement across modalities. Extensive experiments on multiple benchmark datasets demonstrate that our PAN-Crafter outperforms the most recent state-of-the-art method in all metrics, even with 50.11$\\times$ faster inference time and 0.63$\\times$ the memory size. Furthermore, it demonstrates strong generalization performance on unseen satellite datasets, showing its robustness across different conditions.", 'abstract_zh': 'PAN增强旨在融合高分辨率全色（PAN）图像与低分辨率多光谱（MS）图像，生成高分辨率多光谱（HRMS）输出。然而，由于传感器布局、采集时间以及分辨率差异引起的跨模态错位引发了根本性的挑战。传统的深度学习方法假设像素级完美对齐，并依赖于逐像素重构损失，导致在存在错位时出现光谱失真、双边缘和模糊现象。为解决这一问题，我们提出PAN-Crafter，一种模态一致对齐框架，明确地缓解了PAN和MS模态间的对齐差距。核心上，模态自适应重构（MARs）使得单一网络能够联合重构HRMS和PAN图像，并利用PAN的高频细节作为辅助自监督。此外，我们引入了跨模态对齐感知注意力（CM3A），这是一种新颖的机制，双向对齐MS纹理至PAN结构和反之亦然，使模态间实现自适应特征精炼。在多个基准数据集上进行的大量实验表明，我们的PAN-Crafter在所有度量标准上均优于最新最优方法，同时具有50.11倍更快的推理时间和0.63倍的内存占用，并且在未见过的卫星数据集上展示了强大的泛化性能，证明其在不同条件下的鲁棒性。', 'title_zh': 'PAN-Crafter: 学习模态一致对齐以进行PANSharpening'}
{'arxiv_id': 'arXiv:2505.23354', 'title': 'Representing local protein environments with atomistic foundation models', 'authors': 'Meital Bojan, Sanketh Vedula, Advaith Maddipatla, Nadav Bojan Sellam, Federico Napoli, Paul Schanda, Alex M. Bronstein', 'link': 'https://arxiv.org/abs/2505.23354', 'abstract': "The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.", 'abstract_zh': '蛋白质的局部结构强烈影响其功能及其与其他分子的相互作用。因此，对局部蛋白质环境进行简洁且信息丰富的表示对于蛋白质和生物分子相互作用的建模和设计至关重要。然而，这些环境的广泛结构和化学变异性使其建模具有挑战性，现有的表示形式仍未得到充分探索。在本工作中，我们提出了一种新的由原子尺度基础模型（AFMs）中间特征衍生的局部蛋白质环境表示方法。我们证明这种表示有效地捕捉了局部结构（如二级结构元件）和化学特征（如氨基酸 identities 和质子化状态）。进一步的研究表明，AFM衍生的表示空间具有有意义的结构，能够构建数据驱动的生物分子环境分布先验知识。最后，在生物分子核磁共振光谱学的背景下，我们展示了所提出的表示方法能够实现首屈一指的物理信息化学位移预测器，达到了最先进的准确性。我们的结果表明，原子尺度基础模型及其涌现表示在蛋白质建模中的有效性超出了传统的分子模拟。我们相信这将开启构建蛋白质环境有效功能表示的新途径。', 'title_zh': '用原子级基础模型表示局部蛋白质环境'}
{'arxiv_id': 'arXiv:2505.23353', 'title': 'Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis', 'authors': 'Alexandra G. Roberts, Ha M. Luu, Mert Şişman, Alexey V. Dimov, Ceren Tozlu, Ilhami Kovanlikaya, Susan A. Gauthier, Thanh D. Nguyen, Yi Wang', 'link': 'https://arxiv.org/abs/2505.23353', 'abstract': 'Quantitative susceptibility maps from magnetic resonance images can provide both prognostic and diagnostic information in multiple sclerosis, a neurodegenerative disease characterized by the formation of lesions in white matter brain tissue. In particular, susceptibility maps provide adequate contrast to distinguish between "rim" lesions, surrounded by deposited paramagnetic iron, and "non-rim" lesion types. These paramagnetic rim lesions (PRLs) are an emerging biomarker in multiple sclerosis. Much effort has been devoted to both detection and segmentation of such lesions to monitor longitudinal change. As paramagnetic rim lesions are rare, addressing this problem requires confronting the class imbalance between rim and non-rim lesions. We produce synthetic quantitative susceptibility maps of paramagnetic rim lesions and show that inclusion of such synthetic data improves classifier performance and provide a multi-channel extension to generate accompanying contrasts and probabilistic segmentation maps. We exploit the projection capability of our trained generative network to demonstrate a novel denoising approach that allows us to train on ambiguous rim cases and substantially increase the minority class. We show that both synthetic lesion synthesis and our proposed rim lesion label denoising method best approximate the unseen rim lesion distribution and improve detection in a clinically interpretable manner. We release our code and generated data at this https URL upon publication.', 'abstract_zh': '从磁共振图像中生成的定量 susceptibility 图map 在多发性硬化症的预后和诊断中提供信息，多发性硬化症是一种以白质脑组织中形成病灶为特征的神经退行性疾病。特别是，susceptibility 图map 提供了足够的对比度来区分由沉积的顺磁性铁围成的“边缘”病灶和“非边缘”病灶类型。顺磁性边缘病灶（PRLs）是多发性硬化症中新兴的生物标志物。人们致力于检测和分割此类病灶以监控纵向变化。由于顺磁性边缘病灶罕见，解决此问题需要解决边缘病灶和非边缘病灶之间的类别不平衡。我们生成了顺磁性边缘病灶的合成定量 susceptibility 图map，并展示了这些合成数据的纳入可以提高分类器性能，并提供多通道扩展以生成相应的对比图和概率分割图。我们利用我们训练的生成网络的投影能力，提出了一种新颖的去噪方法，该方法允许我们在模糊的边缘病灶案例上进行训练，从而显著增加少数类。我们证明，无论是合成病灶生成还是我们提出的边缘病灶标签去噪方法，都能最好地逼近未见的边缘病灶分布，并以临床可解释的方式改善检测。我们在发布时在该网址https:// 提供我们的代码和生成数据。', 'title_zh': 'Multiple Sclerosis中缘区病变的合成生成与潜空间去噪'}
{'arxiv_id': 'arXiv:2505.23352', 'title': 'Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems', 'authors': 'Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, Xin Wang', 'link': 'https://arxiv.org/abs/2505.23352', 'abstract': 'The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.', 'abstract_zh': '基于大型语言模型的多智能体系统中的通信拓扑从根本上规范了智能体间的协作模式，深刻影响着集体决策的效率和效果。尽管近期通信拓扑自动化设计研究倾向于构建稀疏结构以提高效率，但它们往往忽视了稀疏和密集拓扑为何以及在何时对协作有帮助或阻碍。本文提出一种因果框架，分析在不同稀疏度拓扑下智能体输出（正确或错误）的传播方式。我们的实证研究表明，适度稀疏的拓扑通常能够有效抑制错误传播的同时保持有益信息的扩散，从而实现最优任务性能。借鉴这一见解，我们提出了一种新的拓扑设计方法EIB-leanrner，通过融合密集图和稀疏图的连接模式来平衡错误抑制和有益信息传播。广泛的实验展示了EIB-leanrner在效果、通信成本和鲁棒性方面的优越性。', 'title_zh': '基于LLM的多agent系统中通信拓扑的信息传播效应探究'}
{'arxiv_id': 'arXiv:2505.23349', 'title': 'Towards Reward Fairness in RLHF: From a Resource Allocation Perspective', 'authors': 'Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu', 'link': 'https://arxiv.org/abs/2505.23349', 'abstract': 'Rewards serve as proxies for human preferences and play a crucial role in Reinforcement Learning from Human Feedback (RLHF). However, if these rewards are inherently imperfect, exhibiting various biases, they can adversely affect the alignment of large language models (LLMs). In this paper, we collectively define the various biases present in rewards as the problem of reward unfairness. We propose a bias-agnostic method to address the issue of reward fairness from a resource allocation perspective, without specifically designing for each type of bias, yet effectively mitigating them. Specifically, we model preference learning as a resource allocation problem, treating rewards as resources to be allocated while considering the trade-off between utility and fairness in their distribution. We propose two methods, Fairness Regularization and Fairness Coefficient, to achieve fairness in rewards. We apply our methods in both verification and reinforcement learning scenarios to obtain a fairness reward model and a policy model, respectively. Experiments conducted in these scenarios demonstrate that our approach aligns LLMs with human preferences in a more fair manner.', 'abstract_zh': '奖励充当人类偏好的代理，在基于人类反馈的强化学习（RLHF）中发挥着关键作用。然而，如果这些奖励本身存在各种内在缺陷和偏差，它们可能会 adverse 地影响大型语言模型（LLMs）的对齐。本文将奖励中存在的各种偏差共同定义为奖励不公平性问题。我们从资源分配的角度提出了一种无偏方法，以解决奖励公平性问题，而不需专门设计针对每种类型的偏差，但能够有效缓解这些偏差。具体而言，我们将偏好学习建模为资源分配问题，将奖励视为需要分配的资源，并在分配时考虑其在效用和公平性之间的权衡。我们提出了公平正则化和公平系数两种方法，以在奖励中实现公平。我们在验证和强化学习场景中应用这些方法，分别获得公平奖励模型和策略模型。在这些场景中的实验表明，我们的方法能够更公平地将LLMs与人类偏好对齐。', 'title_zh': '从资源分配视角探索RLHF中的奖励公平性'}
{'arxiv_id': 'arXiv:2505.23337', 'title': 'Matryoshka Model Learning for Improved Elastic Student Models', 'authors': 'Chetan Verma, Aditya Srinivas Timmaraju, Cho Jui-Hsieh, Suyash Damle, Ngot Bui, Yang Zhang, Wen Chen, Xin Liu, Prateek Jain, Inderjit S Dhillon', 'link': 'https://arxiv.org/abs/2505.23337', 'abstract': 'Industry-grade ML models are carefully designed to meet rapidly evolving serving constraints, which requires significant resources for model development. In this paper, we propose MatTA, a framework for training multiple accurate Student models using a novel Teacher-TA-Student recipe. TA models are larger versions of the Student models with higher capacity, and thus allow Student models to better relate to the Teacher model and also bring in more domain-specific expertise. Furthermore, multiple accurate Student models can be extracted from the TA model. Therefore, despite only one training run, our methodology provides multiple servable options to trade off accuracy for lower serving cost. We demonstrate the proposed method, MatTA, on proprietary datasets and models. Its practical efficacy is underscored by live A/B tests within a production ML system, demonstrating 20% improvement on a key metric. We also demonstrate our method on GPT-2 Medium, a public model, and achieve relative improvements of over 24% on SAT Math and over 10% on the LAMBADA benchmark.', 'abstract_zh': '基于工业标准的机器学习模型旨在满足快速变化的服务约束，这需要大量的资源进行模型开发。本文提出了一种名为MatTA的框架，利用新颖的Teacher-TA-Student配方训练多个准确的学生模型。TA模型是学生模型的扩展版本，具有更高的容量，使得学生模型能够更好地与教师模型相关，并引入更多特定领域的专业知识。此外，可以从TA模型中提取出多个准确的学生模型。因此，尽管只进行了一次训练运行，我们的方法仍提供了多种可部署选项，以在准确性与较低的服务成本之间进行权衡。我们在自有数据集和模型上展示了所提出的方法MatTA，并通过生产机器学习系统中的现场A/B测试，证明了该方法在一个关键指标上提高了20%。我们还在公开的GPT-2 Medium模型上展示了该方法，并在SAT Math和LAMBADA基准测试上分别实现了超过24%和10%的相对性能改进。', 'title_zh': '套娃模型学习以改进弹性学生模型'}
{'arxiv_id': 'arXiv:2505.23331', 'title': 'Fine-Tuning Next-Scale Visual Autoregressive Models with Group Relative Policy Optimization', 'authors': 'Matteo Gallici, Haitz Sáez de Ocáriz Borde', 'link': 'https://arxiv.org/abs/2505.23331', 'abstract': 'Fine-tuning pre-trained generative models with Reinforcement Learning (RL) has emerged as an effective approach for aligning outputs more closely with nuanced human preferences. In this paper, we investigate the application of Group Relative Policy Optimization (GRPO) to fine-tune next-scale visual autoregressive (VAR) models. Our empirical results demonstrate that this approach enables alignment to intricate reward signals derived from aesthetic predictors and CLIP embeddings, significantly enhancing image quality and enabling precise control over the generation style. Interestingly, by leveraging CLIP, our method can help VAR models generalize beyond their initial ImageNet distribution: through RL-driven exploration, these models can generate images aligned with prompts referencing image styles that were absent during pre-training. In summary, we show that RL-based fine-tuning is both efficient and effective for VAR models, benefiting particularly from their fast inference speeds, which are advantageous for online sampling, an aspect that poses significant challenges for diffusion-based alternatives.', 'abstract_zh': '使用强化学习（RL） fine-tune 预训练生成模型以更好地与细微的人类偏好对齐', 'title_zh': '使用组相对策略优化细调下一代视觉自回归模型'}
{'arxiv_id': 'arXiv:2505.23315', 'title': 'Enhancing Marker Scoring Accuracy through Ordinal Confidence Modelling in Educational Assessments', 'authors': 'Abhirup Chakravarty, Mark Brenchley, Trevor Breakspear, Ian Lewin, Yan Huang', 'link': 'https://arxiv.org/abs/2505.23315', 'abstract': 'A key ethical challenge in Automated Essay Scoring (AES) is ensuring that scores are only released when they meet high reliability standards. Confidence modelling addresses this by assigning a reliability estimate measure, in the form of a confidence score, to each automated score. In this study, we frame confidence estimation as a classification task: predicting whether an AES-generated score correctly places a candidate in the appropriate CEFR level. While this is a binary decision, we leverage the inherent granularity of the scoring domain in two ways. First, we reformulate the task as an n-ary classification problem using score binning. Second, we introduce a set of novel Kernel Weighted Ordinal Categorical Cross Entropy (KWOCCE) loss functions that incorporate the ordinal structure of CEFR labels. Our best-performing model achieves an F1 score of 0.97, and enables the system to release 47% of scores with 100% CEFR agreement and 99% with at least 95% CEFR agreement -compared to approximately 92% (approx.) CEFR agreement from the standalone AES model where we release all AM predicted scores.', 'abstract_zh': '自动作文评分中关键的伦理挑战之一是确保评分只有在达到高可靠性的标准后才被公布。通过为每个自动化评分分配一个可靠性的估计度量（形式为信心分数）来解决这一问题。在本研究中，我们将信心估计框定为分类任务：预测自动作文评分系统生成的分数是否正确地将考生放置在相应的CEFR水平。虽然这是一个二分类决策，但我们通过两种方式利用评分领域的固有精细度。首先，我们通过分数分箱将任务重新表述为n元分类问题。其次，我们引入了一组新颖的核加权序数分类交叉熵（KWOCCE）损失函数，这些函数结合了CEFR标签的序数结构。我们性能最好的模型实现了F1分数为0.97，并使系统能够公布47%的分数，这些分数在CEFR上达成100%的一致性，99%的一致性至少为95%——相比之下，独立运行的自动作文评分模型仅公布所有AM预测分数时的CEFR一致性约为92%。', 'title_zh': '通过序级置信度建模提升标记评分准确性'}
{'arxiv_id': 'arXiv:2505.23313', 'title': 'Adversarial Semantic and Label Perturbation Attack for Pedestrian Attribute Recognition', 'authors': 'Weizhe Kong, Xiao Wang, Ruichong Gao, Chenglong Li, Yu Zhang, Xing Yang, Yaowei Wang, Jin Tang', 'link': 'https://arxiv.org/abs/2505.23313', 'abstract': 'Pedestrian Attribute Recognition (PAR) is an indispensable task in human-centered research and has made great progress in recent years with the development of deep neural networks. However, the potential vulnerability and anti-interference ability have still not been fully explored. To bridge this gap, this paper proposes the first adversarial attack and defense framework for pedestrian attribute recognition. Specifically, we exploit both global- and patch-level attacks on the pedestrian images, based on the pre-trained CLIP-based PAR framework. It first divides the input pedestrian image into non-overlapping patches and embeds them into feature embeddings using a projection layer. Meanwhile, the attribute set is expanded into sentences using prompts and embedded into attribute features using a pre-trained CLIP text encoder. A multi-modal Transformer is adopted to fuse the obtained vision and text tokens, and a feed-forward network is utilized for attribute recognition. Based on the aforementioned PAR framework, we adopt the adversarial semantic and label-perturbation to generate the adversarial noise, termed ASL-PAR. We also design a semantic offset defense strategy to suppress the influence of adversarial attacks. Extensive experiments conducted on both digital domains (i.e., PETA, PA100K, MSP60K, RAPv2) and physical domains fully validated the effectiveness of our proposed adversarial attack and defense strategies for the pedestrian attribute recognition. The source code of this paper will be released on this https URL.', 'abstract_zh': '行人属性识别（PAR）中的对抗攻击与防御框架', 'title_zh': '针对行人属性识别的对抗语义和标签扰动攻击'}
{'arxiv_id': 'arXiv:2505.23309', 'title': 'Score-based Generative Modeling for Conditional Independence Testing', 'authors': 'Yixin Ren, Chenghou Jin, Yewei Xia, Li Ke, Longtao Huang, Hui Xue, Hao Zhang, Jihong Guan, Shuigeng Zhou', 'link': 'https://arxiv.org/abs/2505.23309', 'abstract': 'Determining conditional independence (CI) relationships between random variables is a fundamental yet challenging task in machine learning and statistics, especially in high-dimensional settings. Existing generative model-based CI testing methods, such as those utilizing generative adversarial networks (GANs), often struggle with undesirable modeling of conditional distributions and training instability, resulting in subpar performance. To address these issues, we propose a novel CI testing method via score-based generative modeling, which achieves precise Type I error control and strong testing power. Concretely, we first employ a sliced conditional score matching scheme to accurately estimate conditional score and use Langevin dynamics conditional sampling to generate null hypothesis samples, ensuring precise Type I error control. Then, we incorporate a goodness-of-fit stage into the method to verify generated samples and enhance interpretability in practice. We theoretically establish the error bound of conditional distributions modeled by score-based generative models and prove the validity of our CI tests. Extensive experiments on both synthetic and real-world datasets show that our method significantly outperforms existing state-of-the-art methods, providing a promising way to revitalize generative model-based CI testing.', 'abstract_zh': '基于评分生成模型的条件独立性检验方法：精确的I型错误控制与强大的测试能力', 'title_zh': '基于评分的生成建模在条件独立性检验中的应用'}
{'arxiv_id': 'arXiv:2505.23308', 'title': 'Spoken question answering for visual queries', 'authors': 'Nimrod Shabtay, Zvi Kons, Avihu Dekel, Hagai Aronowitz, Ron Hoory, Assaf Arbelle', 'link': 'https://arxiv.org/abs/2505.23308', 'abstract': 'Question answering (QA) systems are designed to answer natural language questions. Visual QA (VQA) and Spoken QA (SQA) systems extend the textual QA system to accept visual and spoken input respectively.\nThis work aims to create a system that enables user interaction through both speech and images. That is achieved through the fusion of text, speech, and image modalities to tackle the task of spoken VQA (SVQA). The resulting multi-modal model has textual, visual, and spoken inputs and can answer spoken questions on images.\nTraining and evaluating SVQA models requires a dataset for all three modalities, but no such dataset currently exists. We address this problem by synthesizing VQA datasets using two zero-shot TTS models. Our initial findings indicate that a model trained only with synthesized speech nearly reaches the performance of the upper-bounding model trained on textual QAs. In addition, we show that the choice of the TTS model has a minor impact on accuracy.', 'abstract_zh': '视觉问答（VQA）和口语问答（SQA）系统扩展了文本问答系统，分别接受视觉和口语输入。本工作旨在通过结合语音和图像交互创建一个系统，该系统通过融合文本、语音和图像模态来解决口语VQA（SVQA）任务。最终的多模态模型接受文本、视觉和口语输入，并能对图像上的口语问题进行回答。训练和评估SVQA模型需要包含所有三种模态的数据集，但当前并不存在这样的数据集。我们通过使用两个零样本TTS模型合成了VQA数据集来解决这个问题。初步研究表明，仅使用合成语音训练的模型几乎达到了基于文本问答训练的上界模型的性能。此外，我们还表明，TTS模型的选择对准确性的影响较小。', 'title_zh': '基于口语的视觉查询问答'}
{'arxiv_id': 'arXiv:2505.23295', 'title': 'How Does Response Length Affect Long-Form Factuality', 'authors': 'James Xu Zhao, Jimmy Z.J. Liu, Bryan Hooi, See-Kiong Ng', 'link': 'https://arxiv.org/abs/2505.23295', 'abstract': 'Large language models (LLMs) are widely used for long-form text generation. However, factual errors in the responses would undermine their reliability. Despite growing attention to LLM factuality, the effect of response length on factuality remains underexplored. In this work, we systematically investigate this relationship by first introducing an automatic and bi-level long-form factuality evaluation framework, which achieves high agreement with human annotations while being cost-effective. Using this framework, we conduct controlled experiments and find that longer responses exhibit lower factual precision, confirming the presence of length bias. To explain this phenomenon, we empirically examine three hypotheses: error propagation, long context, and facts exhaustion. Our results reveal that facts exhaustion, where the model gradually exhausts more reliable knowledge, is the primary cause of factual degradation, rather than the other two hypotheses.', 'abstract_zh': '大型语言模型（LLMs）广泛用于长文本生成。然而，回应中的事实错误会削弱其可靠性。尽管对LLM事实性已引起广泛关注，但响应长度对其事实性的影响仍未得到充分研究。在这项工作中，我们通过引入一种自动且多层次的长文本事实性评估框架，系统地探讨了这一关系，该框架在成本效益和与人工注释的一致性方面表现优异。利用此框架，我们进行了受控实验并发现，较长的回应表现出较低的事实精确度，证实了长度偏差的存在。为了解释这一现象，我们 empirical 检查了三个假设：错误传播、长上下文和事实耗尽。我们的结果显示，事实耗尽，即模型逐渐耗尽更可靠的知识，是事实退化的主要原因，而非其他两个假设。', 'title_zh': '响应长度如何影响长文本事实性'}
{'arxiv_id': 'arXiv:2505.23292', 'title': 'Federated Unsupervised Semantic Segmentation', 'authors': 'Evangelos Charalampakis, Vasileios Mygdalis, Ioannis Pitas', 'link': 'https://arxiv.org/abs/2505.23292', 'abstract': 'This work explores the application of Federated Learning (FL) in Unsupervised Semantic image Segmentation (USS). Recent USS methods extract pixel-level features using frozen visual foundation models and refine them through self-supervised objectives that encourage semantic grouping. These features are then grouped to semantic clusters to produce segmentation masks. Extending these ideas to federated settings requires feature representation and cluster centroid alignment across distributed clients -- an inherently difficult task under heterogeneous data distributions in the absence of supervision. To address this, we propose FUSS Federated Unsupervised image Semantic Segmentation) which is, to our knowledge, the first framework to enable fully decentralized, label-free semantic segmentation training. FUSS introduces novel federation strategies that promote global consistency in feature and prototype space, jointly optimizing local segmentation heads and shared semantic centroids. Experiments on both benchmark and real-world datasets, including binary and multi-class segmentation tasks, show that FUSS consistently outperforms local-only client trainings as well as extensions of classical FL algorithms under varying client data distributions. To support reproducibility, full code will be released upon manuscript acceptance.', 'abstract_zh': 'FUSS：联邦学习框架下的无监督语义图像分割', 'title_zh': '联邦无监督语义分割'}
{'arxiv_id': 'arXiv:2505.23277', 'title': 'Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective', 'authors': 'Yong Zhang, Yanwen Huang, Ning Cheng, Yang Guo, Yun Zhu, Yanmeng Wang, Shaojun Wang, Jing Xiao', 'link': 'https://arxiv.org/abs/2505.23277', 'abstract': 'Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external context, but retrieved passages are often lengthy, noisy, or exceed input limits. Existing compression methods typically require supervised training of dedicated compression models, increasing cost and reducing portability. We propose Sentinel, a lightweight sentence-level compression framework that reframes context filtering as an attention-based understanding task. Rather than training a compression model, Sentinel probes decoder attention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier to identify sentence relevance. Empirically, we find that query-context relevance estimation is consistent across model scales, with 0.5B proxies closely matching the behaviors of larger models. On the LongBench benchmark, Sentinel achieves up to 5$\\times$ compression while matching the QA performance of 7B-scale compression systems. Our results suggest that probing native attention signals enables fast, effective, and question-aware context compression. Code available at: this https URL.', 'abstract_zh': '基于检索的生成（RAG）通过外部上下文增强了大规模语言模型（LLMs），但检索到的段落往往较长、噪点较多或超出输入限制。现有的压缩方法通常需要训练专用的压缩模型，这增加了成本并降低了移植性。我们提出了一种轻量级的句子级别压缩框架Sentinel，将其上下文过滤重新定义为基于注意力的理解任务。Sentinel 不训练压缩模型，而是使用轻量级分类器探测现成的0.5B代理LLM的解码器注意力，以识别句子的相关性。实验结果显示，查询-上下文相关性估计在不同规模的模型之间具有一致性，0.5B代理模型的行为与大模型行为接近。在LongBench基准测试中，Sentinel 达到了最高5倍的压缩比，同时保持与7B规模压缩系统相当的问答性能。我们的结果表明，探测原生注意力信号能够实现快速、有效且问题意识强烈的上下文压缩。代码可在以下链接获取：this https URL。', 'title_zh': '哨兵：从理解视角探查代理模型在LLM上下文压缩中的注意力机制'}
{'arxiv_id': 'arXiv:2505.23276', 'title': 'The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text', 'authors': 'Maged S. Al-Shaibani, Moataz Ahmed', 'link': 'https://arxiv.org/abs/2505.23276', 'abstract': 'Large Language Models (LLMs) have achieved unprecedented capabilities in generating human-like text, posing subtle yet significant challenges for information integrity across critical domains, including education, social media, and academia, enabling sophisticated misinformation campaigns, compromising healthcare guidance, and facilitating targeted propaganda. This challenge becomes severe, particularly in under-explored and low-resource languages like Arabic. This paper presents a comprehensive investigation of Arabic machine-generated text, examining multiple generation strategies (generation from the title only, content-aware generation, and text refinement) across diverse model architectures (ALLaM, Jais, Llama, and GPT-4) in academic, and social media domains. Our stylometric analysis reveals distinctive linguistic patterns differentiating human-written from machine-generated Arabic text across these varied contexts. Despite their human-like qualities, we demonstrate that LLMs produce detectable signatures in their Arabic outputs, with domain-specific characteristics that vary significantly between different contexts. Based on these insights, we developed BERT-based detection models that achieved exceptional performance in formal contexts (up to 99.9\\% F1-score) with strong precision across model architectures. Our cross-domain analysis confirms generalization challenges previously reported in the literature. To the best of our knowledge, this work represents the most comprehensive investigation of Arabic machine-generated text to date, uniquely combining multiple prompt generation methods, diverse model architectures, and in-depth stylometric analysis across varied textual domains, establishing a foundation for developing robust, linguistically-informed detection systems essential for preserving information integrity in Arabic-language contexts.', 'abstract_zh': '大型语言模型（LLMs）在生成类人类文本方面取得了前所未有的能力，这对教育、社交媒体和学术领域等关键领域的信息完整性提出了微妙而重要的挑战，使其成为复杂误导性信息运动、损害健康指导和促进有针对性的宣传的工具。这一挑战在低探索度和资源有限的语言，如阿拉伯语，尤为严重。本文对阿拉伯机器生成文本进行了全面调查，探讨了多种生成策略（仅从标题生成、内容感知生成和文本精炼）在学术和社交媒体领域的多种模型架构（ALLaM、Jais、Llama和GPT-4）中的表现。通过文体统计分析，我们揭示了在这些不同背景下，人工写作和机器生成的阿拉伯文本之间独特的语言模式差异。尽管具有类人类的特征，我们证明LLMs在其阿拉伯输出中产生了可检测的特征签名，这些特征在不同上下文之间差异显著。基于这些见解，我们开发了基于BERT的检测模型，在正式上下文中取得了卓越的性能（高达99.9%的F1分数），并在不同模型架构中表现出强大的精度。我们的跨领域分析证实了先前文献中报告的一般化挑战。据我们所知，这项工作迄今日为止最全面地调查了阿拉伯机器生成文本，独特地结合了多种提示生成方法、多种模型架构和跨不同文本领域的深入文体统计分析，为在阿拉伯语环境中开发稳健、语言导向的检测系统奠定了基础，以确保信息完整性。', 'title_zh': '阿拉伯AI指纹：大规模语言模型文本的文体学分析与检测'}
{'arxiv_id': 'arXiv:2505.23270', 'title': 'Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs', 'authors': 'Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong Gu, Claudia Grosser, Denis Krompass, Nassir Navab, Volker Tresp', 'link': 'https://arxiv.org/abs/2505.23270', 'abstract': 'In recent years, Large Language Models (LLMs) have achieved remarkable advancements, drawing significant attention from the research community. Their capabilities are largely attributed to large-scale architectures, which require extensive training on massive datasets. However, such datasets often contain sensitive or copyrighted content sourced from the public internet, raising concerns about data privacy and ownership. Regulatory frameworks, such as the General Data Protection Regulation (GDPR), grant individuals the right to request the removal of such sensitive information. This has motivated the development of machine unlearning algorithms that aim to remove specific knowledge from models without the need for costly retraining. Despite these advancements, evaluating the efficacy of unlearning algorithms remains a challenge due to the inherent complexity and generative nature of LLMs. In this work, we introduce a comprehensive auditing framework for unlearning evaluation, comprising three benchmark datasets, six unlearning algorithms, and five prompt-based auditing methods. By using various auditing algorithms, we evaluate the effectiveness and robustness of different unlearning strategies. To explore alternatives beyond prompt-based auditing, we propose a novel technique that leverages intermediate activation perturbations, addressing the limitations of auditing methods that rely solely on model inputs and outputs.', 'abstract_zh': '近年来，大型语言模型（LLMs）取得了显著进展，引起了科研界的广泛关注。它们的能力主要归因于大规模的架构，这需要在海量数据集上进行广泛的训练。然而，这些数据集往往包含来自公共互联网的敏感或受版权保护的内容，引发了关于数据隐私和所有权的问题。欧盟通用数据保护条例（GDPR）等监管框架赋予个人请求删除此类敏感信息的权利，这促使开发出了旨在无需全面重新训练即可从模型中移除特定知识的机器遗忘算法。尽管取得了这些进展，但由于LLMs的固有复杂性和生成特性，评估遗忘算法的效果仍然具有挑战性。在本工作中，我们介绍了针对遗忘评估的综合审计框架，包含三个基准数据集、六种遗忘算法和五种基于提示的审计方法。通过使用各种审计算法，我们评估了不同遗忘策略的有效性和鲁棒性。为探索超出基于提示的审计的替代方案，我们提出了一种新的技术，利用中间激活扰动，解决了仅依赖于模型输入和输出的审计方法所面临的局限性。', 'title_zh': '机器遗忘真正移除模型知识吗？一种审计大型语言模型遗忘的框架'}
{'arxiv_id': 'arXiv:2505.23268', 'title': 'Unsupervised Transcript-assisted Video Summarization and Highlight Detection', 'authors': 'Spyros Barbakos, Charalampos Antoniadis, Gerasimos Potamianos, Gianluca Setti', 'link': 'https://arxiv.org/abs/2505.23268', 'abstract': 'Video consumption is a key part of daily life, but watching entire videos can be tedious. To address this, researchers have explored video summarization and highlight detection to identify key video segments. While some works combine video frames and transcripts, and others tackle video summarization and highlight detection using Reinforcement Learning (RL), no existing work, to the best of our knowledge, integrates both modalities within an RL framework. In this paper, we propose a multimodal pipeline that leverages video frames and their corresponding transcripts to generate a more condensed version of the video and detect highlights using a modality fusion mechanism. The pipeline is trained within an RL framework, which rewards the model for generating diverse and representative summaries while ensuring the inclusion of video segments with meaningful transcript content. The unsupervised nature of the training allows for learning from large-scale unannotated datasets, overcoming the challenge posed by the limited size of existing annotated datasets. Our experiments show that using the transcript in video summarization and highlight detection achieves superior results compared to relying solely on the visual content of the video.', 'abstract_zh': '视频消费是日常生活的关键部分，但观看完整视频可能会很乏味。为了应对这一问题，研究人员探讨了视频总结和亮点检测，以识别关键视频片段。虽然有些工作结合了视频帧和字幕，而另一些工作则使用强化学习（RL）进行视频总结和亮点检测，但据我们所知，现有工作未在RL框架内整合这两种模态。本文提出了一种多模态管道，利用视频帧及其对应的字幕生成更浓缩的视频版本，并使用模态融合机制检测亮点。该管道在RL框架下训练，奖励模型生成多样化且具代表性的总结，同时确保包括具有重要意义字幕内容的视频片段。无监督的训练方式可以从大规模未标注数据集中学习，克服现有标注数据集规模有限带来的挑战。我们的实验表明，在视频总结和亮点检测中使用字幕相比于仅依赖视频的视觉内容取得了更好的结果。', 'title_zh': '无监督的转录辅助视频摘要与亮点检测'}
{'arxiv_id': 'arXiv:2505.23267', 'title': 'VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation', 'authors': 'Jianlin Ye, Savvas Papaioannou, Panayiotis Kolios', 'link': 'https://arxiv.org/abs/2505.23267', 'abstract': 'Path planning is a fundamental capability of autonomous Unmanned Aerial Vehicles (UAVs), enabling them to efficiently navigate toward a target region or explore complex environments while avoiding obstacles. Traditional pathplanning methods, such as Rapidly-exploring Random Trees (RRT), have proven effective but often encounter significant challenges. These include high search space complexity, suboptimal path quality, and slow convergence, issues that are particularly problematic in high-stakes applications like disaster response, where rapid and efficient planning is critical. To address these limitations and enhance path-planning efficiency, we propose Vision Language Model RRT (VLM-RRT), a hybrid approach that integrates the pattern recognition capabilities of Vision Language Models (VLMs) with the path-planning strengths of RRT. By leveraging VLMs to provide initial directional guidance based on environmental snapshots, our method biases sampling toward regions more likely to contain feasible paths, significantly improving sampling efficiency and path quality. Extensive quantitative and qualitative experiments with various state-of-the-art VLMs demonstrate the effectiveness of this proposed approach.', 'abstract_zh': '基于视觉语言模型的RRT路径规划方法（VLM-RRT）', 'title_zh': '基于视觉语言模型引导的RRT搜索自主无人航空器导航算法'}
{'arxiv_id': 'arXiv:2505.23266', 'title': 'Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion', 'authors': 'Chunlong Xie, Jialing He, Shangwei Guo, Jiacheng Wang, Shudong Zhang, Tianwei Zhang, Tao Xiang', 'link': 'https://arxiv.org/abs/2505.23266', 'abstract': 'We present Adversarial Object Fusion (AdvOF), a novel attack framework targeting vision-and-language navigation (VLN) agents in service-oriented environments by generating adversarial 3D objects. While foundational models like Large Language Models (LLMs) and Vision Language Models (VLMs) have enhanced service-oriented navigation systems through improved perception and decision-making, their integration introduces vulnerabilities in mission-critical service workflows. Existing adversarial attacks fail to address service computing contexts, where reliability and quality-of-service (QoS) are paramount. We utilize AdvOF to investigate and explore the impact of adversarial environments on the VLM-based perception module of VLN agents. In particular, AdvOF first precisely aggregates and aligns the victim object positions in both 2D and 3D space, defining and rendering adversarial objects. Then, we collaboratively optimize the adversarial object with regularization between the adversarial and victim object across physical properties and VLM perceptions. Through assigning importance weights to varying views, the optimization is processed stably and multi-viewedly by iterative fusions from local updates and justifications. Our extensive evaluations demonstrate AdvOF can effectively degrade agent performance under adversarial conditions while maintaining minimal interference with normal navigation tasks. This work advances the understanding of service security in VLM-powered navigation systems, providing computational foundations for robust service composition in physical-world deployments.', 'abstract_zh': 'adversarial object fusion: Investigating Adversarial Attacks on VLM-Based VLN Agents in Service-Oriented Environments', 'title_zh': '通过对抗对象融合颠覆基于视觉-语言模型的导航服务'}
{'arxiv_id': 'arXiv:2505.23250', 'title': 'Deep Retrieval at CheckThat! 2025: Identifying Scientific Papers from Implicit Social Media Mentions via Hybrid Retrieval and Re-Ranking', 'authors': 'Pascal J. Sager, Ashwini Kamaraj, Benjamin F. Grewe, Thilo Stadelmann', 'link': 'https://arxiv.org/abs/2505.23250', 'abstract': 'We present the methodology and results of the Deep Retrieval team for subtask 4b of the CLEF CheckThat! 2025 competition, which focuses on retrieving relevant scientific literature for given social media posts. To address this task, we propose a hybrid retrieval pipeline that combines lexical precision, semantic generalization, and deep contextual re-ranking, enabling robust retrieval that bridges the informal-to-formal language gap. Specifically, we combine BM25-based keyword matching with a FAISS vector store using a fine-tuned INF-Retriever-v1 model for dense semantic retrieval. BM25 returns the top 30 candidates, and semantic search yields 100 candidates, which are then merged and re-ranked via a large language model (LLM)-based cross-encoder.\nOur approach achieves a mean reciprocal rank at 5 (MRR@5) of 76.46% on the development set and 66.43% on the hidden test set, securing the 1st position on the development leaderboard and ranking 3rd on the test leaderboard (out of 31 teams), with a relative performance gap of only 2 percentage points compared to the top-ranked system. We achieve this strong performance by running open-source models locally and without external training data, highlighting the effectiveness of a carefully designed and fine-tuned retrieval pipeline.', 'abstract_zh': 'Deep Retrieval队列在CLEF CheckThat! 2025竞赛子任务4b中的方法与结果：基于社交媒体帖子检索相关科学文献', 'title_zh': 'CheckThat! 2025深度检索：通过混合检索与再排序识别科学论文'}
{'arxiv_id': 'arXiv:2505.23247', 'title': 'Accelerating RLHF Training with Reward Variance Increase', 'authors': 'Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan', 'link': 'https://arxiv.org/abs/2505.23247', 'abstract': 'Reinforcement learning from human feedback (RLHF) is an essential technique for ensuring that large language models (LLMs) are aligned with human values and preferences during the post-training phase. As an effective RLHF approach, group relative policy optimization (GRPO) has demonstrated success in many LLM-based applications. However, efficient GRPO-based RLHF training remains a challenge. Recent studies reveal that a higher reward variance of the initial policy model leads to faster RLHF training. Inspired by this finding, we propose a practical reward adjustment model to accelerate RLHF training by provably increasing the reward variance and preserving the relative preferences and reward expectation. Our reward adjustment method inherently poses a nonconvex optimization problem, which is NP-hard to solve in general. To overcome the computational challenges, we design a novel $O(n \\log n)$ algorithm to find a global solution of the nonconvex reward adjustment model by explicitly characterizing the extreme points of the feasible set. As an important application, we naturally integrate this reward adjustment model into the GRPO algorithm, leading to a more efficient GRPO with reward variance increase (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we provide an indirect explanation for the empirical effectiveness of GRPO with rule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment results demonstrate that the GRPOVI algorithm can significantly improve the RLHF training efficiency compared to the original GRPO algorithm.', 'abstract_zh': '从人类反馈中强化学习（RLHF）确保大型语言模型（LLMs）在后训练阶段与人类价值观和偏好对齐是一种关键技术。基于群相对策略优化（GRPO）的RLHF方法在许多LLM应用中获得了成功，但高效的GRPO基RLHF训练仍然是一个挑战。受这一发现的启发，我们提出了一种实际的奖励调整模型，通过证明增加奖励方差并保留相对偏好和奖励期望来加速RLHF训练。我们的奖励调整方法本质上提出了一种非凸优化问题，通常是NP难问题。为了解决计算挑战，我们设计了一种新的$O(n \\log n)$算法，通过显式表征可行集的极点来寻找非凸奖励调整模型的全局解。作为重要的应用，我们将这个奖励调整模型自然地整合到GRPO算法中，从而提出了一个用于RLHF训练的具有奖励方差增加的GRPO改进算法（GRPOVI）。作为有趣的副产品，我们间接解释了DeepSeek-R1中基于规则奖励的GRPO在RLHF训练中的实证有效性。实验结果表明，GRPOVI算法在RLHF训练效率方面显著优于原始的GRPO算法。', 'title_zh': '通过增加奖励方差来加速RLHF训练'}
{'arxiv_id': 'arXiv:2505.23239', 'title': 'OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software', 'authors': 'Lingkai Meng, Yu Shao, Long Yuan, Longbin Lai, Peng Cheng, Wenyuan Yu, Wenjie Zhang, Xuemin Lin, Jingren Zhou', 'link': 'https://arxiv.org/abs/2505.23239', 'abstract': "Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.", 'abstract_zh': '开源软件（OSS）的可用性评估对于其影响和采纳至关重要，但传统的依赖人工评估者的方法存在着高成本和有限的可扩展性。为解决这些问题，我们引入了OSS-UAgent，这是一种自动化、可配置且交互式的基于代理的可用性评估框架，专门设计用于开源软件。该框架利用大型语言模型（LLMs）驱动的智能代理，模拟不同经验水平（从初级到专家）的开发者执行编程任务。通过动态构建平台特定的知识库，OSS-UAgent 确保代码生成的准确性和上下文感知性。生成的代码在多个维度上（包括合规性、正确性和可读性）自动评估，提供软件可用性的全面衡量。此外，我们的演示展示了OSS-UAgent 在评估图分析平台中的实际应用，突出了其在自动化可用性评估方面的有效性。', 'title_zh': 'OSS-UAgent：基于代理的开放源代码软件可使用性评估框架'}
{'arxiv_id': 'arXiv:2505.23229', 'title': 'MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration', 'authors': 'Hao Lu, Yanchi Gu, Haoyuan Huang, Yulin Zhou, Ningxin Zhu, Chen Li', 'link': 'https://arxiv.org/abs/2505.23229', 'abstract': 'The integration of Monte Carlo Tree Search (MCTS) with Large Language Models (LLMs) has demonstrated significant success in structured, problem-oriented tasks. However, applying these methods to open-ended dialogues, such as those in psychological counseling, presents unique challenges. Unlike tasks with objective correctness, success in therapeutic conversations depends on subjective factors like empathetic engagement, ethical adherence, and alignment with human preferences, for which strict "correctness" criteria are ill-defined. Existing result-oriented MCTS approaches can therefore produce misaligned responses. To address this, we introduce MCTSr-Zero, an MCTS framework designed for open-ended, human-centric dialogues. Its core innovation is "domain alignment", which shifts the MCTS search objective from predefined end-states towards conversational trajectories that conform to target domain principles (e.g., empathy in counseling). Furthermore, MCTSr-Zero incorporates "Regeneration" and "Meta-Prompt Adaptation" mechanisms to substantially broaden exploration by allowing the MCTS to consider fundamentally different initial dialogue strategies. We evaluate MCTSr-Zero in psychological counseling by generating multi-turn dialogue data, which is used to fine-tune an LLM, PsyLLM. We also introduce PsyEval, a benchmark for assessing multi-turn psychological counseling dialogues. Experiments demonstrate that PsyLLM achieves state-of-the-art performance on PsyEval and other relevant metrics, validating MCTSr-Zero\'s effectiveness in generating high-quality, principle-aligned conversational data for human-centric domains and addressing the LLM challenge of consistently adhering to complex psychological standards.', 'abstract_zh': 'Monte Carlo Tree Search (MCTS)与大型语言模型（LLMs）的整合在结构化问题导向任务中取得了显著成功，但在应用于开放式对话，如心理辅导对话时提出了独特挑战。现有的结果导向的MCTS方法可能会产生不一致的响应。为此，我们提出MCTSr-Zero，一种专门为开放式、以人为中心对话设计的MCTS框架。其核心创新是“领域对齐”，即将MCTS搜索目标从预定义的终点状态转向符合目标领域原则（例如，咨询中的同理心）的对话轨迹。此外，MCTSr-Zero引入了“再生”和“元提示适配”机制，大幅扩展了探索范围，使MCTS能够考虑根本不同的初始对话策略。我们通过生成多轮对话数据评估MCTSr-Zero在心理辅导中的应用，并使用这些数据微调了一个名为PsyLLM的LLM。我们还引入了PsyEval，这是一个评估多轮心理辅导对话的基准。实验结果表明，PsyLLM在PsyEval和其他相关指标上达到了最先进的性能，验证了MCTSr-Zero在生成高质量、原则一致的对话数据方面的有效性，以及对LLM在一致遵循复杂心理标准方面的挑战的应对能力。', 'title_zh': 'MCTSr-Zero: 基于原则和自适应探索的自我反思心理辅导对话生成'}
{'arxiv_id': 'arXiv:2505.23214', 'title': 'SAMamba: Adaptive State Space Modeling with Hierarchical Vision for Infrared Small Target Detection', 'authors': 'Wenhao Xu, Shuchen Zheng, Changwei Wang, Zherui Zhang, Chuan Ren, Rongtao Xu, Shibiao Xu', 'link': 'https://arxiv.org/abs/2505.23214', 'abstract': "Infrared small target detection (ISTD) is vital for long-range surveillance in military, maritime, and early warning applications. ISTD is challenged by targets occupying less than 0.15% of the image and low distinguishability from complex backgrounds. Existing deep learning methods often suffer from information loss during downsampling and inefficient global context modeling. This paper presents SAMamba, a novel framework integrating SAM2's hierarchical feature learning with Mamba's selective sequence modeling. Key innovations include: (1) A Feature Selection Adapter (FS-Adapter) for efficient natural-to-infrared domain adaptation via dual-stage selection (token-level with a learnable task embedding and channel-wise adaptive transformations); (2) A Cross-Channel State-Space Interaction (CSI) module for efficient global context modeling with linear complexity using selective state space modeling; and (3) A Detail-Preserving Contextual Fusion (DPCF) module that adaptively combines multi-scale features with a gating mechanism to balance high-resolution and low-resolution feature contributions. SAMamba addresses core ISTD challenges by bridging the domain gap, maintaining fine-grained details, and efficiently modeling long-range dependencies. Experiments on NUAA-SIRST, IRSTD-1k, and NUDT-SIRST datasets show SAMamba significantly outperforms state-of-the-art methods, especially in challenging scenarios with heterogeneous backgrounds and varying target scales. Code: this https URL.", 'abstract_zh': '红外小目标检测（ISTD）在军事、海事及早期预警应用中的远程监视中至关重要。ISTD 面临的目标占图像小于 0.15% 和复杂背景下的低可区分度挑战。现有深度学习方法往往在下采样过程中造成信息丢失，并且在全球上下文建模上效率低下。本文提出 SAMamba，一种结合 SAM2 的分层特征学习与 Mamba 的选择性序列建模的新型框架。关键创新包括：（1）特征选择适配器（FS-Adapter），通过两阶段选择（基于可学习任务嵌入的标记级选择和通道级自适应变换）实现高效自然域到红外域适配；（2）跨通道状态空间交互（CSI）模块，通过选择性状态空间建模以线性复杂度实现高效全局上下文建模；以及（3）细节保留上下文融合（DPCF）模块，通过门控机制适配性地结合多尺度特征，平衡高分辨率和低分辨率特征的贡献。SAMamba 通过弥合域间差距、保持细粒度细节和高效建模远程依赖关系来应对核心 ISTD 挑战。实验结果表明，SAMamba 在 NUAA-SIRST、IRSTD-1k 和 NUDT-SIRST 数据集上的表现显著优于现有最先进的方法，尤其是在背景异构和目标尺度变化多样的复杂场景中。代码：https://this-url。', 'title_zh': 'SAMamba：带有分层视觉的自适应状态空间建模的小目标红外检测'}
{'arxiv_id': 'arXiv:2505.23195', 'title': 'Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning', 'authors': 'Lifan Zhao, Yanyan Shen, Zhaoyang Liu, Xue Wang, Jiaji Deng', 'link': 'https://arxiv.org/abs/2505.23195', 'abstract': 'Scaling laws motivate the development of Time Series Foundation Models (TSFMs) that pre-train vast parameters and achieve remarkable zero-shot forecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot consistently outperform smaller, specialized models trained on full-shot downstream data. A key question is how to realize effective adaptation of TSFMs for a target forecasting task. Through empirical studies on various TSFMs, the pre-trained models often exhibit inherent sparsity and redundancy in computation, suggesting that TSFMs have learned to activate task-relevant network substructures to accommodate diverse forecasting tasks. To preserve this valuable prior knowledge, we propose a structured pruning method to regularize the subsequent fine-tuning process by focusing it on a more relevant and compact parameter space. Extensive experiments on seven TSFMs and six benchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly improves forecasting performance compared to fine-tuning original models. This "prune-then-finetune" paradigm often enables TSFMs to achieve state-of-the-art performance and surpass strong specialized baselines.', 'abstract_zh': '基于Scaling定律的时间序列基础模型（TSFMs）推动了大规模预训练参数的发展，并实现卓越的零样本预测性能。令人惊讶的是，即使经过微调，TSFMs也无法一致地战胜规模较小的下游全监督训练的专业模型。一个关键问题是如何实现TSFMs对目标预测任务的有效适应。通过各种TSFMs的实证研究，预训练模型通常表现出内在的计算稀疏性和冗余性，表明TSFMs已学会激活与多样化预测任务相关的网络子结构。为了保留这些宝贵的先验知识，我们提出了一种结构化剪枝方法，通过聚焦于更相关且紧凑的参数空间来规范化后续的微调过程。在七种TSFMs和六种基准上的广泛实验表明，对较小的剪枝TSFMs进行微调显著提高了预测性能，优于对原始模型进行微调。这种“先剪枝后微调”的范式通常能使TSFMs达到最佳性能并超越强大的专业基线。', 'title_zh': '少即是多：结构化剪枝解锁时间序列基础模型的专业化'}
{'arxiv_id': 'arXiv:2505.23192', 'title': 'Fooling the Watchers: Breaking AIGC Detectors via Semantic Prompt Attacks', 'authors': 'Run Hao, Peng Ying', 'link': 'https://arxiv.org/abs/2505.23192', 'abstract': 'The rise of text-to-image (T2I) models has enabled the synthesis of photorealistic human portraits, raising serious concerns about identity misuse and the robustness of AIGC detectors. In this work, we propose an automated adversarial prompt generation framework that leverages a grammar tree structure and a variant of the Monte Carlo tree search algorithm to systematically explore the semantic prompt space. Our method generates diverse, controllable prompts that consistently evade both open-source and commercial AIGC detectors. Extensive experiments across multiple T2I models validate its effectiveness, and the approach ranked first in a real-world adversarial AIGC detection competition. Beyond attack scenarios, our method can also be used to construct high-quality adversarial datasets, providing valuable resources for training and evaluating more robust AIGC detection and defense systems.', 'abstract_zh': '文本到图像模型的兴起使 photorealistic 人类肖像的合成成为可能，引发了关于身份滥用和 AIGC 检测器 robustness 的严重关切。本文提出了一种自动对抗式提示生成框架，该框架利用语法树结构和蒙特卡洛树搜索算法的变体，系统地探索语义提示空间。该方法生成多样且可控的提示，能够一致地规避开源和商业 AIGC 检测器。在多个文本到图像模型上的广泛实验验证了其有效性，并且该方法在实际的对抗式 AIGC 检测竞赛中排名第一。除了攻击场景之外，该方法还可以用于构建高质量的对抗式数据集，为训练和评估更加 robust 的 AIGC 检测和防御系统提供宝贵资源。', 'title_zh': '愚弄监控者：通过语义提示攻击破解AIGC检测器'}
{'arxiv_id': 'arXiv:2505.23191', 'title': 'ExpeTrans: LLMs Are Experiential Transfer Learners', 'authors': 'Jinglong Gao, Xiao Ding, Lingxiao Zou, Bibo Cai, Bing Qin, Ting Liu', 'link': 'https://arxiv.org/abs/2505.23191', 'abstract': 'Recent studies provide large language models (LLMs) with textual task-solving experiences via prompts to improve their performance. However, previous methods rely on substantial human labor or time to gather such experiences for each task, which is impractical given the growing variety of task types in user queries to LLMs. To address this issue, we design an autonomous experience transfer framework to explore whether LLMs can mimic human cognitive intelligence to autonomously transfer experience from existing source tasks to newly encountered target tasks. This not only allows the acquisition of experience without extensive costs of previous methods, but also offers a novel path for the generalization of LLMs. Experimental results on 13 datasets demonstrate that our framework effectively improves the performance of LLMs. Furthermore, we provide a detailed analysis of each module in the framework.', 'abstract_zh': '最近的研究通过提示为大型语言模型提供文本任务解决经验，以提升其性能。然而，之前的方法依赖大量的人工劳动或时间来为每个任务收集这些经验，在用户查询涉及日益增多的任务类型的情况下是不实际的。为解决这一问题，我们设计了一种自主经验转移框架，探索大型语言模型是否能够模仿人类认知智能，自主将现有源任务的经验转移至新的目标任务。这不仅允许在不使用前期方法的大量成本的情况下获得经验，还为大型语言模型的一般化提供了新的路径。实验结果表明，我们的框架有效提升了大型语言模型的性能。此外，我们对框架中的每个模块进行了详细的分析。', 'title_zh': 'ExpeTrans: LLMs 是经验迁移学习者'}
{'arxiv_id': 'arXiv:2505.23187', 'title': 'Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration', 'authors': 'Yilong Li, Chen Qian, Yu Xia, Ruijie Shi, Yufan Dang, Zihao Xie, Ziming You, Weize Chen, Cheng Yang, Weichuan Liu, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2505.23187', 'abstract': "Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.", 'abstract_zh': '基于大型语言模型的多智能体系统（MAS）在通过协作推理和智能体互评解决复杂任务方面取得了显著进展。然而，现有方法通常将每个任务孤立处理，导致冗余计算并限制了在结构相似任务上的推广能力。为解决这一问题，我们提出了多智能体跨任务经验学习（MAEL）这一新颖框架，赋予以大型语言模型驱动的智能体明确的跨任务学习和经验积累能力。我们基于图结构多智能体协作网络建模任务解决工作流，在该网络中，智能体通过显式连接传播信息并协调。在经验学习阶段，我们量化工作流中每一步的质量，并将相应的奖励、输入和输出存储在每个智能体的个体经验池中。在推理阶段，智能体检索高奖励、任务相关的经验作为少量示例，以增强每一步推理的有效性，从而实现更准确和高效的多智能体协作。实验结果表明，MAEL使智能体能够有效利用先前任务的经验，实现更快的收敛并产生更高质量的解决方案。', 'title_zh': '基于LLM的大规模多agent协作跨任务经验学习'}
{'arxiv_id': 'arXiv:2505.23183', 'title': 'Unsupervised Word-level Quality Estimation for Machine Translation Through the Lens of Annotators (Dis)agreement', 'authors': 'Gabriele Sarti, Vilém Zouhar, Malvina Nissim, Arianna Bisazza', 'link': 'https://arxiv.org/abs/2505.23183', 'abstract': 'Word-level quality estimation (WQE) aims to automatically identify fine-grained error spans in machine-translated outputs and has found many uses, including assisting translators during post-editing. Modern WQE techniques are often expensive, involving prompting of large language models or ad-hoc training on large amounts of human-labeled data. In this work, we investigate efficient alternatives exploiting recent advances in language model interpretability and uncertainty quantification to identify translation errors from the inner workings of translation models. In our evaluation spanning 14 metrics across 12 translation directions, we quantify the impact of human label variation on metric performance by using multiple sets of human labels. Our results highlight the untapped potential of unsupervised metrics, the shortcomings of supervised methods when faced with label uncertainty, and the brittleness of single-annotator evaluation practices.', 'abstract_zh': '基于词级的质量估计 (WQE) 的目标是自动识别机器翻译输出中的细粒度错误跨度，并已在翻译后编辑辅助等多种应用中得到应用。现代WQE技术通常成本较高，涉及大型语言模型的提示或对大量人工标注数据进行临时培训。在此工作中，我们探究了利用语言模型可解释性和不确定性量化 Recent Advances 的高效替代方法，以从翻译模型的内部 workings 中识别翻译错误。在对12个翻译方向进行的14项指标评估中，我们通过使用多个人工标注数据集集结算控制了人工标签变化对指标性能的影响。我们的结果突显了无监督指标的未开发潜力、监督方法在面对标签不确定性时的局限性，以及单标注人评估实践的脆弱性。', 'title_zh': '通过注释者（不）一致性的视角进行的机器翻译无监督词级质量估计'}
{'arxiv_id': 'arXiv:2505.23181', 'title': 'FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification', 'authors': 'Tian Tian, Chunyan Miao, Hangwei Qian', 'link': 'https://arxiv.org/abs/2505.23181', 'abstract': 'Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the semantically relevant information of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: global, independent, and compact. To fully utilize the three properties, we propose the lightweight yet effective Frequency Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose semantic-aware Identity Modification and semantic-agnostic Self-adaptive Modification to protect semantically relevant information in the critical frequency components and infuse variance into the unimportant ones respectively. Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets, including UCR and UEA archives, as well as five large-scale datasets on diverse applications. FreRA consistently outperforms ten leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets.', 'abstract_zh': '基于频率域的轻量高效 augmentation 方案：提升时间序列对比学习的下游分类性能', 'title_zh': 'FreRA: 一种用于时间序列分类对比学习的频率细化增强方法'}
{'arxiv_id': 'arXiv:2505.23165', 'title': 'Best Arm Identification with Possibly Biased Offline Data', 'authors': 'Le Yang, Vincent Y. F. Tan, Wang Chi Cheung', 'link': 'https://arxiv.org/abs/2505.23165', 'abstract': 'We study the best arm identification (BAI) problem with potentially biased offline data in the fixed confidence setting, which commonly arises in real-world scenarios such as clinical trials. We prove an impossibility result for adaptive algorithms without prior knowledge of the bias bound between online and offline distributions. To address this, we propose the LUCB-H algorithm, which introduces adaptive confidence bounds by incorporating an auxiliary bias correction to balance offline and online data within the LUCB framework. Theoretical analysis shows that LUCB-H matches the sample complexity of standard LUCB when offline data is misleading and significantly outperforms it when offline data is helpful. We also derive an instance-dependent lower bound that matches the upper bound of LUCB-H in certain scenarios. Numerical experiments further demonstrate the robustness and adaptability of LUCB-H in effectively incorporating offline data.', 'abstract_zh': '带潜在偏差的离线数据在固定置信区间下的最佳臂识别问题及其LUCB-H算法研究', 'title_zh': '带有可能偏倚的离线数据的最佳臂识别'}
{'arxiv_id': 'arXiv:2505.23161', 'title': 'Implicit Inversion turns CLIP into a Decoder', 'authors': "Antonio D'Orazio, Maria Rosaria Briglia, Donato Crisostomi, Dario Loi, Emanuele Rodolà, Iacopo Masi", 'link': 'https://arxiv.org/abs/2505.23161', 'abstract': "CLIP is a discriminative model trained to align images and text in a shared embedding space. Due to its multimodal structure, it serves as the backbone of many generative pipelines, where a decoder is trained to map from the shared space back to images. In this work, we show that image synthesis is nevertheless possible using CLIP alone -- without any decoder, training, or fine-tuning. Our approach optimizes a frequency-aware implicit neural representation that encourages coarse-to-fine generation by stratifying frequencies across network layers. To stabilize this inverse mapping, we introduce adversarially robust initialization, a lightweight Orthogonal Procrustes projection to align local text and image embeddings, and a blending loss that anchors outputs to natural image statistics. Without altering CLIP's weights, this framework unlocks capabilities such as text-to-image generation, style transfer, and image reconstruction. These findings suggest that discriminative models may hold untapped generative potential, hidden in plain sight.", 'abstract_zh': 'CLIP是一种训练用于在共享嵌入空间中对齐图像和文本的辨别模型。由于其多模态结构，它作为许多生成管道的基础骨架，其中解码器被训练将从共享空间映射回图像。在本文中，我们展示了即使不使用任何解码器、训练或微调，仅使用CLIP也能够实现图像合成。我们的方法优化了一种频率意识的隐式神经表示，通过在网络层中分层频率来促进从粗略到精细的生成。为了稳定这一逆向映射，我们引入了对抗鲁棒初始化、轻量级的正交普洛克赛斯投影以对齐局部文本和图像嵌入，以及融合损失以将输出锚定到自然图像统计。不改变CLIP的权重，这一框架解锁了从文本生成图像、风格迁移和图像重构等能力。这些发现表明，辨别模型可能隐藏着未开发的生成潜力。', 'title_zh': '隐式反转使CLIP转变为解码器'}
{'arxiv_id': 'arXiv:2505.23145', 'title': 'FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing', 'authors': 'Jeongsol Kim, Yeobin Hong, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2505.23145', 'abstract': 'Recent inversion-free, flow-based image editing methods such as FlowEdit leverages a pre-trained noise-to-image flow model such as Stable Diffusion 3, enabling text-driven manipulation by solving an ordinary differential equation (ODE). While the lack of exact latent inversion is a core advantage of these methods, it often results in unstable editing trajectories and poor source consistency. To address this limitation, we propose FlowAlign, a novel inversion-free flow-based framework for consistent image editing with principled trajectory control. FlowAlign introduces a flow-matching loss as a regularization mechanism to promote smoother and more stable trajectories during the editing process. Notably, the flow-matching loss is shown to explicitly balance semantic alignment with the edit prompt and structural consistency with the source image along the trajectory. Furthermore, FlowAlign naturally supports reverse editing by simply reversing the ODE trajectory, highlighting the reversible and consistent nature of the transformation. Extensive experiments demonstrate that FlowAlign outperforms existing methods in both source preservation and editing controllability.', 'abstract_zh': '基于流的无逆变换一致图像编辑方法FlowAlign及其原理导向的轨迹控制', 'title_zh': 'FlowAlign: 轨迹正则化、无逆过程的流动基于图像编辑'}
{'arxiv_id': 'arXiv:2505.23135', 'title': 'VERINA: Benchmarking Verifiable Code Generation', 'authors': 'Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song', 'link': 'https://arxiv.org/abs/2505.23135', 'abstract': "Large language models (LLMs) are increasingly integrated in software development, but ensuring correctness in LLM-generated code remains challenging and often requires costly manual review. Verifiable code generation -- jointly generating code, specifications, and proofs of code-specification alignment -- offers a promising path to address this limitation and further unleash LLMs' benefits in coding. Yet, there exists a significant gap in evaluation: current benchmarks often lack support for end-to-end verifiable code generation. In this paper, we introduce Verina (Verifiable Code Generation Arena), a high-quality benchmark enabling a comprehensive and modular evaluation of code, specification, and proof generation as well as their compositions. Verina consists of 189 manually curated coding tasks in Lean, with detailed problem descriptions, reference implementations, formal specifications, and extensive test suites. Our extensive evaluation of state-of-the-art LLMs reveals significant challenges in verifiable code generation, especially in proof generation, underscoring the need for improving LLM-based theorem provers in verification domains. The best model, OpenAI o4-mini, generates only 61.4% correct code, 51.0% sound and complete specifications, and 3.6% successful proofs, with one trial per task. We hope Verina will catalyze progress in verifiable code generation by providing a rigorous and comprehensive benchmark. We release our dataset on this https URL and our evaluation code on this https URL.", 'abstract_zh': '可验证代码生成：Large Language Models在软件开发中的可验证代码生成基准', 'title_zh': 'VERINA: 可验证代码生成的基准测试'}
{'arxiv_id': 'arXiv:2505.23134', 'title': 'Zero-to-Hero: Zero-Shot Initialization Empowering Reference-Based Video Appearance Editing', 'authors': 'Tongtong Su, Chengyu Wang, Jun Huang, Dongming Lu', 'link': 'https://arxiv.org/abs/2505.23134', 'abstract': 'Appearance editing according to user needs is a pivotal task in video editing. Existing text-guided methods often lead to ambiguities regarding user intentions and restrict fine-grained control over editing specific aspects of objects. To overcome these limitations, this paper introduces a novel approach named {Zero-to-Hero}, which focuses on reference-based video editing that disentangles the editing process into two distinct problems. It achieves this by first editing an anchor frame to satisfy user requirements as a reference image and then consistently propagating its appearance across other frames. We leverage correspondence within the original frames to guide the attention mechanism, which is more robust than previously proposed optical flow or temporal modules in memory-friendly video generative models, especially when dealing with objects exhibiting large motions. It offers a solid ZERO-shot initialization that ensures both accuracy and temporal consistency. However, intervention in the attention mechanism results in compounded imaging degradation with over-saturated colors and unknown blurring issues. Starting from Zero-Stage, our Hero-Stage Holistically learns a conditional generative model for vidEo RestOration. To accurately evaluate the consistency of the appearance, we construct a set of videos with multiple appearances using Blender, enabling a fine-grained and deterministic evaluation. Our method outperforms the best-performing baseline with a PSNR improvement of 2.6 dB. The project page is at this https URL.', 'abstract_zh': '根据用户需求进行外观编辑是视频编辑中的关键任务。现有基于文本的方法常常导致用户意图的歧义，并限制了对对象特定方面进行精细控制的能力。为克服这些限制，本文提出了一种名为{Zero-to-Hero}的新方法，该方法侧重于基于参考的视频编辑，将编辑过程分解为两个独立的问题。该方法首先编辑一个参考帧以满足用户需求，然后在其他帧中一致地传播其外观。我们利用原帧之间的对应关系来引导注意力机制，这种方法在内存友好型视频生成模型中比先前提出的光流或时空模块更 robust，尤其是在处理大运动物体时。它提供了坚实的零-shot 初始化，确保了准确性和时空一致性。然而，在注意力机制中的干预会导致成像退化，表现为过度饱和的颜色和未知的模糊问题。从零阶段开始，我们的英雄阶段整体学习一个条件生成模型以进行视频修复。为了准确评估外观的一致性，我们使用Blender构建了一组具有多种外观的视频集，从而实现细粒度和确定性的评估。与最佳基线相比，我们的方法的PSNR提高了2.6 dB。项目页面链接为：this https URL。', 'title_zh': '从零到英雄：零-shot 初始化赋能基于参考的视频外观编辑'}
{'arxiv_id': 'arXiv:2505.23132', 'title': 'Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone', 'authors': 'Seung Gyu Jeong, Seong Eun Kim', 'link': 'https://arxiv.org/abs/2505.23132', 'abstract': 'Auscultation is crucial for diagnosing lung diseases. The COVID-19 pandemic has revealed the limitations of traditional, in-person lung sound assessments. To overcome these issues, advancements in digital stethoscopes and artificial intelligence (AI) have led to the development of new diagnostic methods. In this context, our study aims to use smartphone microphones to record and analyze lung sounds. We faced two major challenges: the difference in audio style between electronic stethoscopes and smartphone microphones, and the variability among patients. To address these challenges, we developed a method called Patient Domain Supervised Contrastive Learning (PD-SCL). By integrating this method with the Audio Spectrogram Transformer (AST) model, we significantly improved its performance by 2.4\\% compared to the original AST model. This progress demonstrates that smartphones can effectively diagnose lung sounds, addressing inconsistencies in patient data and showing potential for broad use beyond traditional clinical settings. Our research contributes to making lung disease detection more accessible in the post-COVID-19 world.', 'abstract_zh': '听诊对于诊断肺部疾病至关重要。COVID-19疫情揭示了传统面对面肺音评估的限制。为克服这些问题，数字听诊器和人工智能的进步推动了新型诊断方法的发展。在此背景下，本研究旨在利用智能手机麦克风记录和分析肺音。我们面临两大挑战：电子听诊器与智能手机麦克风之间的音频风格差异，以及患者之间的变异。为应对这些挑战，我们开发了一种称为患者域监督对比学习（PD-SCL）的方法。通过将该方法与音频频谱变换器（Audio Spectrogram Transformer，AST）模型结合，我们将其性能提高了2.4%。这一进展表明，智能手机可以有效地诊断肺音，解决患者数据不一致的问题，并展现出在传统临床环境之外广泛使用的潜力。我们的研究为后 COVID-19 世界中的肺部疾病检测提供了更多机会。', 'title_zh': '基于患者的领域监督对比学习的手机端肺音分类'}
{'arxiv_id': 'arXiv:2505.23121', 'title': 'ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations', 'authors': 'Yiming Lei, Zhizheng Yang, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang', 'link': 'https://arxiv.org/abs/2505.23121', 'abstract': 'Multi-modal large language models have demonstrated remarkable zero-shot abilities and powerful image-understanding capabilities. However, the existing open-source multi-modal models suffer from the weak capability of multi-turn interaction, especially for long contexts. To address the issue, we first introduce a context modeling module, termed ContextQFormer, which utilizes a memory block to enhance the presentation of contextual information. Furthermore, to facilitate further research, we carefully build a new multi-turn multi-modal dialogue dataset (TMDialog) for pre-training, instruction-tuning, and evaluation, which will be open-sourced lately. Compared with other multi-modal dialogue datasets, TMDialog contains longer conversations, which supports the research of multi-turn multi-modal dialogue. In addition, ContextQFormer is compared with three baselines on TMDialog and experimental results illustrate that ContextQFormer achieves an improvement of 2%-4% in available rate over baselines.', 'abstract_zh': '多模态大语言模型展示了卓越的零-shot能力和强大的图像理解能力。然而，现有的开源多模态模型在多轮交互能力上较弱，尤其是对于长上下文的处理。为解决这一问题，我们首先引入了一个上下文建模模块，称为ContextQFormer，该模块利用记忆块增强上下文信息的呈现。此外，为了促进进一步研究，我们精心构建了一个新的多轮多模态对话数据集（TMDialog），用于预训练、指令调优和评估，并将在近期开源。与现有的其他多模态对话数据集相比，TMDialog包含更长的对话，支持多轮多模态对话的研究。另外，我们在TMDialog上将ContextQFormer与三个基线进行了比较，实验结果表明，ContextQFormer在可用率上比基线提高了2%-4%。', 'title_zh': 'ContextQFormer: 一种新的多轮多模态对话上下文建模方法'}
{'arxiv_id': 'arXiv:2505.23118', 'title': 'Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios', 'authors': 'Linjie Mu, Zhongzhen Huang, Yakun Zhu, Xiangyu Zhao, Shaoting Zhang, Xiaofan Zhang', 'link': 'https://arxiv.org/abs/2505.23118', 'abstract': "Effective clinical decision-making depends on iterative, multimodal reasoning across diverse sources of evidence. The recent emergence of multimodal reasoning models has significantly transformed the landscape of solving complex tasks. Although such models have achieved notable success in mathematics and science, their application to medical domains remains underexplored. In this work, we propose \\textit{MedE$^2$}, a two-stage post-training pipeline that elicits and then enhances multimodal reasoning for medical domains. In Stage-I, we fine-tune models using 2,000 text-only data samples containing precisely orchestrated reasoning demonstrations to elicit reasoning behaviors. In Stage-II, we further enhance the model's reasoning capabilities using 1,500 rigorously curated multimodal medical cases, aligning model reasoning outputs with our proposed multimodal medical reasoning preference. Extensive experiments demonstrate the efficacy and reliability of \\textit{MedE$^2$} in improving the reasoning performance of medical multimodal models. Notably, models trained with \\textit{MedE$^2$} consistently outperform baselines across multiple medical multimodal benchmarks. Additional validation on larger models and under inference-time scaling further confirms the robustness and practical utility of our approach.", 'abstract_zh': '有效的临床决策依赖于跨多样证据源进行迭代的多模态推理。近期出现的多模态推理模型显著改变了解决复杂任务的格局。尽管此类模型在数学和科学领域取得了显著成功，但其在医疗领域的应用仍然未被充分探索。在本文中，我们提出了一种名为MedE$^2$的两阶段后训练管道，用于激发并增强医疗领域的多模态推理能力。在第一阶段，我们使用包含精准推理示例的2,000个纯文本数据样本微调模型以激发推理行为。在第二阶段，我们进一步使用1,500个严格筛选的多模态医疗案例增强模型的推理能力，使模型输出与我们提出的多模态医疗推理偏好相匹配。广泛的经验表明，MedE$^2$在提升医疗多模态模型推理性能方面具备有效性和可靠性。值得注意的是，使用MedE$^2$训练的模型在多个医疗多模态基准测试中均优于基线模型。对更大模型的额外验证并在推理时间尺度下进一步确认了我们方法的鲁棒性和实用性。', 'title_zh': '诱发与增强：推进医疗场景中的多模态推理'}
{'arxiv_id': 'arXiv:2505.23117', 'title': 'Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking', 'authors': 'Yuatyong Chaichana, Thanapat Trachu, Peerat Limkonchotiwat, Konpat Preechakul, Tirasan Khandhawit, Ekapol Chuangsuwanich', 'link': 'https://arxiv.org/abs/2505.23117', 'abstract': "In the era of large-scale training, model merging has evolved into a tool for creating multitasking models efficiently. It enables the knowledge of models to be fused, without the need for heavy computation as required in traditional multitask learning. Existing merging methods often assume that entries at identical positions in weight matrices serve the same function, enabling straightforward entry-wise comparison and merging. However, this assumption overlooks the complexity of finetuned neural networks, where neurons may develop distinct feature compositions, making direct entry-wise merging problematic. We present Decom-Renorm-Merge (DRM), a simple yet effective approach that leverages Singular Value Decomposition to decompose and coordinate weight matrices into an aligned joint space, where entry-wise merging becomes possible. We showcase the effectiveness of DRM across various settings ranging from smaller encoder-based such as ViT and DeBERTa, encoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B. Our experimental results show that DRM outperforms several state-of-the-art merging techniques across full finetuning and low-rank adaptation settings. Moreover, our analysis reveals renormalization as the crucial component for creating a robust and even joint space for merging, significantly contributing to the method's performance.", 'abstract_zh': '大规模训练时代的模型合并：Decom-Renorm-Merge（DRM）方法的研究', 'title_zh': 'Decom-Renorm-Merge: 在正确空间进行模型合并可提升多任务学习'}
{'arxiv_id': 'arXiv:2505.23116', 'title': 'CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables', 'authors': 'Pengfei Zhou, Yunlong Liu, Junli Liang, Qi Song, Xiangyang Li', 'link': 'https://arxiv.org/abs/2505.23116', 'abstract': 'Time series forecasting with exogenous variables is a critical emerging paradigm that presents unique challenges in modeling dependencies between variables. Traditional models often struggle to differentiate between endogenous and exogenous variables, leading to inefficiencies and overfitting. In this paper, we introduce CrossLinear, a novel Linear-based forecasting model that addresses these challenges by incorporating a plug-and-play cross-correlation embedding module. This lightweight module captures the dependencies between variables with minimal computational cost and seamlessly integrates into existing neural networks. Specifically, it captures time-invariant and direct variable dependencies while disregarding time-varying or indirect dependencies, thereby mitigating the risk of overfitting in dependency modeling and contributing to consistent performance improvements. Furthermore, CrossLinear employs patch-wise processing and a global linear head to effectively capture both short-term and long-term temporal dependencies, further improving its forecasting precision. Extensive experiments on 12 real-world datasets demonstrate that CrossLinear achieves superior performance in both short-term and long-term forecasting tasks. The ablation study underscores the effectiveness of the cross-correlation embedding module. Additionally, the generalizability of this module makes it a valuable plug-in for various forecasting tasks across different domains. Codes are available at this https URL.', 'abstract_zh': '基于外生变量的时间序列 Forecasting: 一种引入交叉相关嵌入模块的新型线性预测模型', 'title_zh': 'CrossLinear: 插即用的跨相关嵌入方法用于含外生变量的时间序列预测'}
{'arxiv_id': 'arXiv:2505.23107', 'title': 'EAD: An EEG Adapter for Automated Classification', 'authors': 'Pushapdeep Singh, Jyoti Nigam, Medicherla Vamsi Krishna, Arnav Bhavsar, Aditya Nigam', 'link': 'https://arxiv.org/abs/2505.23107', 'abstract': 'While electroencephalography (EEG) has been a popular modality for neural decoding, it often involves task specific acquisition of the EEG data. This poses challenges for the development of a unified pipeline to learn embeddings for various EEG signal classification, which is often involved in various decoding tasks. Traditionally, EEG classification involves the step of signal preprocessing and the use of deep learning techniques, which are highly dependent on the number of EEG channels in each sample. However, the same pipeline cannot be applied even if the EEG data is collected for the same experiment but with different acquisition devices. This necessitates the development of a framework for learning EEG embeddings, which could be highly beneficial for tasks involving multiple EEG samples for the same task but with varying numbers of EEG channels. In this work, we propose EEG Adapter (EAD), a flexible framework compatible with any signal acquisition device. More specifically, we leverage a recent EEG foundational model with significant adaptations to learn robust representations from the EEG data for the classification task. We evaluate EAD on two publicly available datasets achieving state-of-the-art accuracies 99.33% and 92.31% on EEG-ImageNet and BrainLat respectively. This illustrates the effectiveness of the proposed framework across diverse EEG datasets containing two different perception tasks: stimulus and resting-state EEG signals. We also perform zero-shot EEG classification on EEG-ImageNet task to demonstrate the generalization capability of the proposed approach.', 'abstract_zh': '虽然脑电图（EEG）一直是神经解码的流行模态，但通常需要针对特定任务来获取EEG数据。这为开发一个统一的管道来学习用于各种EEG信号分类的嵌入式表示带来了挑战，这类分类通常涉及多种解码任务。传统上，EEG分类包括信号预处理步骤和使用深度学习技术，这些技术高度依赖于每个样本中的EEG通道数量。然而，即使EEG数据是在相同的实验中通过不同采集设备收集的，也无法应用相同的管道。这促使人们开发一个学习EEG嵌入的框架，该框架对于涉及同一任务但EEG通道数量不同的多个EEG样本来说将非常有益。在本工作中，我们提出EEG适配器（EAD），这是一个兼容任何信号采集设备的灵活框架。具体而言，我们利用一个近期的EEG基础模型并进行重大改编，以从EEG数据中学习稳健的表示用于分类任务。我们在两个公开的数据集上评估了EAD，分别在EEG-ImageNet和BrainLat上达到了最先进的准确率99.33%和92.31%。这展示了所提出框架在包含两种不同感知任务（刺激和静息状态EEG信号）的多样化EEG数据集上的有效性。我们还对EEG-ImageNet任务执行零样本EEG分类，以展示所提出方法的泛化能力。', 'title_zh': 'EAD：一种用于自动化分类的脑电图适配器'}
{'arxiv_id': 'arXiv:2505.23086', 'title': 'Equivariant Spherical Transformer for Efficient Molecular Modeling', 'authors': 'Junyi An, Xinyu Lu, Chao Qu, Yunfei Shi, Peijia Lin, Qianwei Tang, Licheng Xu, Fenglei Cao, Yuan Qi', 'link': 'https://arxiv.org/abs/2505.23086', 'abstract': "SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced molecular system modeling by employing group representations. However, their message passing processes, which rely on tensor product-based convolutions, are limited by insufficient non-linearity and incomplete group representations, thereby restricting expressiveness. To overcome these limitations, we introduce the Equivariant Spherical Transformer (EST), a novel framework that leverages a Transformer structure within the spatial domain of group representations after Fourier transform. We theoretically and empirically demonstrate that EST can encompass the function space of tensor products while achieving superior expressiveness. Furthermore, EST's equivariant inductive bias is guaranteed through a uniform sampling strategy for the Fourier transform. Our experiments demonstrate state-of-the-art performance by EST on various molecular benchmarks, including OC20 and QM9.", 'abstract_zh': 'SE(3)-共变图形神经网络（GNNs）通过使用群表示法显著推动了分子系统建模。然而，其依赖于张量积卷积的消息传递过程因非线性不足和不完整的群表示限制了其表达能力。为克服这些限制，我们引入了球变换共变框架（Equivariant Spherical Transformer, EST），该框架在傅里叶变换后的群表示空间域中采用Transformer结构。我们从理论上和实验上证明，EST能够涵盖张量积的功能空间，同时具有更高的表达能力。此外，EST通过傅里叶变换的均匀采样策略保证了其共变的归纳偏置。我们的实验结果显示，EST在OC20和QM9等多种分子基准测试中达到了最先进的性能。', 'title_zh': '对称球变换器：高效分子建模'}
{'arxiv_id': 'arXiv:2505.23085', 'title': 'GeoMan: Temporally Consistent Human Geometry Estimation using Image-to-Video Diffusion', 'authors': 'Gwanghyun Kim, Xueting Li, Ye Yuan, Koki Nagano, Tianye Li, Jan Kautz, Se Young Chun, Umar Iqbal', 'link': 'https://arxiv.org/abs/2505.23085', 'abstract': "Estimating accurate and temporally consistent 3D human geometry from videos is a challenging problem in computer vision. Existing methods, primarily optimized for single images, often suffer from temporal inconsistencies and fail to capture fine-grained dynamic details. To address these limitations, we present GeoMan, a novel architecture designed to produce accurate and temporally consistent depth and normal estimations from monocular human videos. GeoMan addresses two key challenges: the scarcity of high-quality 4D training data and the need for metric depth estimation to accurately model human size. To overcome the first challenge, GeoMan employs an image-based model to estimate depth and normals for the first frame of a video, which then conditions a video diffusion model, reframing video geometry estimation task as an image-to-video generation problem. This design offloads the heavy lifting of geometric estimation to the image model and simplifies the video model's role to focus on intricate details while using priors learned from large-scale video datasets. Consequently, GeoMan improves temporal consistency and generalizability while requiring minimal 4D training data. To address the challenge of accurate human size estimation, we introduce a root-relative depth representation that retains critical human-scale details and is easier to be estimated from monocular inputs, overcoming the limitations of traditional affine-invariant and metric depth representations. GeoMan achieves state-of-the-art performance in both qualitative and quantitative evaluations, demonstrating its effectiveness in overcoming longstanding challenges in 3D human geometry estimation from videos.", 'abstract_zh': '从视频中估计准确且时间一致的人体三维几何是一个计算机视觉中的挑战性问题。现有方法主要针对单张图像进行优化，往往存在时间一致性差的问题，无法捕获细微的动力学细节。为解决这些问题，我们提出GeoMan，一种新型架构，用于从单目人体视频中生成准确且时间一致的深度和法线估计。GeoMan解决了两个关键挑战：高质量四维训练数据的稀缺性和需要度量深度估计来准确建模人体尺寸。为克服第一个挑战，GeoMan采用图像模型来估计视频第一帧的深度和法线，并指导视频扩散模型，将视频几何估计任务重新定义为从图像到视频的生成问题。这种设计将几何估计的重担转移到图像模型上，并简化了视频模型的角色，使其专注于复杂的细节，同时利用大规模视频数据集学习的先验知识。因此，GeoMan提高了时间一致性和泛化能力，同时只需少量四维训练数据。为解决准确人体尺寸估计的挑战，我们引入了一种根相对的深度表示，保留了关键的人体尺度细节，并且更容易从单目输入中估计，克服了传统齐次不变和度量深度表示的限制。GeoMan在定性和定量评估中均取得了领先性能，展示了其在从视频中估计人体三维几何方面的有效性。', 'title_zh': 'GeoMan: 基于图像到视频扩散模型的人体几何一致性估计'}
{'arxiv_id': 'arXiv:2505.23078', 'title': 'Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport', 'authors': 'Yuu Jinnai', 'link': 'https://arxiv.org/abs/2505.23078', 'abstract': 'Document-level text generation tasks are known to be more difficult than sentence-level text generation tasks as they require the understanding of longer context to generate high-quality texts. In this paper, we investigate the adaption of Minimum Bayes Risk (MBR) decoding for document-level text generation tasks. MBR decoding makes use of a utility function to estimate the output with the highest expected utility from a set of candidate outputs. Although MBR decoding is shown to be effective in a wide range of sentence-level text generation tasks, its performance on document-level text generation tasks is limited as many of the utility functions are designed for evaluating the utility of sentences. To this end, we propose MBR-OT, a variant of MBR decoding using Wasserstein distance to compute the utility of a document using a sentence-level utility function. The experimental result shows that the performance of MBR-OT outperforms that of the standard MBR in document-level machine translation, text simplification, and dense image captioning tasks. Our code is available at this https URL', 'abstract_zh': '文档级文本生成任务的知识比句子级文本生成任务更复杂，因为它们需要理解更长的上下文以生成高质量的文本。本文研究了最小贝叶斯风险(MBR)解码在文档级文本生成任务中的适应性。MBR解码利用一个效用函数来估计从一组候选输出中具有最高期望效用的输出。尽管MBR解码在广泛的句子级文本生成任务中表现出效用，但在文档级文本生成任务中的性能受限，因为许多效用函数是为评估句子的效用而设计的。为此，我们提出了一种新的MBR-OT变体，该变体使用Wasserstein距离通过句子级效用函数计算文档的效用。实验结果表明，MBR-OT在文档级机器翻译、文本简化和密集图像字幕任务中的性能优于标准的MBR。我们的代码可在以下链接获取：this https URL', 'title_zh': '基于最优传输的最小贝叶斯风险解码的文档级文本生成'}
{'arxiv_id': 'arXiv:2505.23066', 'title': 'Efficient Quantum Approximate $k$NN Algorithm via Granular-Ball Computing', 'authors': 'Shuyin Xia, Xiaojiang Tian, Suzhen Yuan, Jeremiah D. Deng', 'link': 'https://arxiv.org/abs/2505.23066', 'abstract': 'High time complexity is one of the biggest challenges faced by $k$-Nearest Neighbors ($k$NN). Although current classical and quantum $k$NN algorithms have made some improvements, they still have a speed bottleneck when facing large amounts of data. To address this issue, we propose an innovative algorithm called Granular-Ball based Quantum $k$NN(GB-Q$k$NN). This approach achieves higher efficiency by first employing granular-balls, which reduces the data size needed to processed. The search process is then accelerated by adopting a Hierarchical Navigable Small World (HNSW) method. Moreover, we optimize the time-consuming steps, such as distance calculation, of the HNSW via quantization, further reducing the time complexity of the construct and search process. By combining the use of granular-balls and quantization of the HNSW method, our approach manages to take advantage of these treatments and significantly reduces the time complexity of the $k$NN-like algorithms, as revealed by a comprehensive complexity analysis.', 'abstract_zh': '基于粒 Balls 的量子 $k$-最近邻算法 (GB-Q$k$NN): 一种高效的时间复杂度优化方法', 'title_zh': '高效粒球计算引导的量子近似$k$NN算法'}
{'arxiv_id': 'arXiv:2505.23062', 'title': 'Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data', 'authors': 'Lingkai Kong, Haichuan Wang, Tonghan Wang, Guojun Xiong, Milind Tambe', 'link': 'https://arxiv.org/abs/2505.23062', 'abstract': 'Incorporating pre-collected offline data from a source environment can significantly improve the sample efficiency of reinforcement learning (RL), but this benefit is often challenged by discrepancies between the transition dynamics of the source and target environments. Existing methods typically address this issue by penalizing or filtering out source transitions in high dynamics-gap regions. However, their estimation of the dynamics gap often relies on KL divergence or mutual information, which can be ill-defined when the source and target dynamics have disjoint support. To overcome these limitations, we propose CompFlow, a method grounded in the theoretical connection between flow matching and optimal transport. Specifically, we model the target dynamics as a conditional flow built upon the output distribution of the source-domain flow, rather than learning it directly from a Gaussian prior. This composite structure offers two key advantages: (1) improved generalization for learning target dynamics, and (2) a principled estimation of the dynamics gap via the Wasserstein distance between source and target transitions. Leveraging our principled estimation of the dynamics gap, we further introduce an optimistic active data collection strategy that prioritizes exploration in regions of high dynamics gap, and theoretically prove that it reduces the performance disparity with the optimal policy. Empirically, CompFlow outperforms strong baselines across several RL benchmarks with shifted dynamics.', 'abstract_zh': '将预先收集的离线数据融入源环境显著提高了强化学习（RL）的样本效率，但这一优势往往受到源环境与目标环境过渡动力学差异的挑战。现有方法通常通过在高动力学差异区域惩罚或过滤源过渡来解决这一问题。然而，它们对动力学差异的估计往往依赖于KL散度或互信息，当源与目标动力学支持区隔时，这些估计可能不明确。为克服这些局限，我们提出了CompFlow方法，该方法基于流匹配与最优传输的理论联系。具体来说，我们将目标动力学建模为基于源域流输出分布的条件流，而不是直接从高斯先前提取。这种复合结构具有两个关键优势：(1) 改进了学习目标动力学的泛化能力；(2) 通过源与目标过渡之间的Wasserstein距离，提供了一种原则性的动力学差异估计。利用我们原则性的动力学差异估计，我们进一步引入了一种乐观的主动数据收集策略，优先探索高动力学差异区域，并从理论上证明该策略减少了与最优策略的性能差距。实验上，CompFlow在多个动力学偏移的RL基准测试中优于强_baseline。', 'title_zh': '复合流匹配用于处理移位动力学数据的强化学习'}
{'arxiv_id': 'arXiv:2505.23059', 'title': 'From Token to Action: State Machine Reasoning to Mitigate Overthinking in Information Retrieval', 'authors': 'Dohyeon Lee, Yeonseok Jeong, Seung-won Hwang', 'link': 'https://arxiv.org/abs/2505.23059', 'abstract': 'Chain-of-Thought (CoT) prompting enables complex reasoning in large language models (LLMs), including applications in information retrieval (IR). However, it often leads to overthinking, where models produce excessively long and semantically redundant traces with little or no benefit. We identify two key challenges in IR: redundant trajectories that revisit similar states and misguided reasoning that diverges from user intent. To address these, we propose State Machine Reasoning (SMR), a transition-based reasoning framework composed of discrete actions (Refine, Rerank, Stop) that support early stopping and fine-grained control. Experiments on the BEIR and BRIGHT benchmarks show that SMR improves retrieval performance (nDCG@10) by 3.4% while reducing token usage by 74.4%. It generalizes across LLMs and retrievers without requiring task-specific tuning, offering a practical alternative to conventional CoT reasoning. The code and details are available at this https URL.', 'abstract_zh': 'Chain-of-Thought (CoT) 命名建议促进大型语言模型（LLMs）的复杂推理，在信息检索（IR）中的应用。然而，它经常导致过度推理，模型生成过长且语义冗余的推理轨迹，几乎没有益处。我们识别了IR中的两个关键挑战：冗余轨迹反复访问相似状态和误导性推理偏离用户意图。为了解决这些问题，我们提出了一种状态机推理（SMR）框架，该框架由离散动作（Refine、Rerank、Stop）组成，支持早期停止和细粒度控制。实验表明，SMR在BEIR和BRIGHT基准测试集上的检索性能（nDCG@10）提高了3.4%，同时减少了74.4%的 token 使用量。SMR在不需任务特定调整的情况下跨LLMs和检索器泛化，提供了一种传统CoT推理的实用替代方案。代码和详细信息请参见此链接。', 'title_zh': '从令牌到动作：状态机推理以减轻信息检索中的过度思考'}
{'arxiv_id': 'arXiv:2505.23053', 'title': 'Augment or Not? A Comparative Study of Pure and Augmented Large Language Model Recommenders', 'authors': 'Wei-Hsiang Huang, Chen-Wei Ke, Wei-Ning Chiu, Yu-Xuan Su, Chun-Chun Yang, Chieh-Yuan Cheng, Yun-Nung Chen, Pu-Jen Cheng', 'link': 'https://arxiv.org/abs/2505.23053', 'abstract': 'Large language models (LLMs) have introduced new paradigms for recommender systems by enabling richer semantic understanding and incorporating implicit world knowledge. In this study, we propose a systematic taxonomy that classifies existing approaches into two categories: (1) Pure LLM Recommenders, which rely solely on LLMs, and (2) Augmented LLM Recommenders, which integrate additional non-LLM techniques to enhance performance. This taxonomy provides a novel lens through which to examine the evolving landscape of LLM-based recommendation. To support fair comparison, we introduce a unified evaluation platform that benchmarks representative models under consistent experimental settings, highlighting key design choices that impact effectiveness. We conclude by discussing open challenges and outlining promising directions for future research. This work offers both a comprehensive overview and practical guidance for advancing next-generation LLM-powered recommender.', 'abstract_zh': '大型语言模型（LLMs）通过增强语义理解和融入隐式世界知识，为推荐系统引入了新的范式。在本研究中，我们提出了一种系统性分类法，将现有方法分为两类：（1）纯LLM推荐器，仅依赖LLM；（2）增强LLM推荐器，整合额外的非LLM技术以提升性能。该分类法提供了一种新颖的视角来审视基于LLM的推荐系统演进格局。为了支持公平比较，我们引入了一个统一的评估平台，在一致的实验设置下对代表性模型进行基准测试，突出影响有效性的关键设计选择。最后，我们讨论了开放性挑战，并概述了未来研究的有希望的方向。这项工作为下一代基于LLM的推荐系统的发展提供了全面的综述和实用指导。', 'title_zh': '增广还是不增广？纯模型与增广的大语言模型推荐器比较研究'}
{'arxiv_id': 'arXiv:2505.23045', 'title': 'Multi-Sourced Compositional Generalization in Visual Question Answering', 'authors': 'Chuanhao Li, Wenbo Ye, Zhen Li, Yuwei Wu, Yunde Jia', 'link': 'https://arxiv.org/abs/2505.23045', 'abstract': 'Compositional generalization is the ability of generalizing novel compositions from seen primitives, and has received much attention in vision-and-language (V\\&L) recently. Due to the multi-modal nature of V\\&L tasks, the primitives composing compositions source from different modalities, resulting in multi-sourced novel compositions. However, the generalization ability over multi-sourced novel compositions, \\textit{i.e.}, multi-sourced compositional generalization (MSCG) remains unexplored. In this paper, we explore MSCG in the context of visual question answering (VQA), and propose a retrieval-augmented training framework to enhance the MSCG ability of VQA models by learning unified representations for primitives from different modalities. Specifically, semantically equivalent primitives are retrieved for each primitive in the training samples, and the retrieved features are aggregated with the original primitive to refine the model. This process helps the model learn consistent representations for the same semantic primitives across different modalities. To evaluate the MSCG ability of VQA models, we construct a new GQA-MSCG dataset based on the GQA dataset, in which samples include three types of novel compositions composed of primitives from different modalities. Experimental results demonstrate the effectiveness of the proposed framework. We release GQA-MSCG at this https URL.', 'abstract_zh': '多源成分泛化能力的研究及增强：以视觉问答为 contexts', 'title_zh': '多源组成性泛化在视觉问答中的应用'}
{'arxiv_id': 'arXiv:2505.23043', 'title': 'Are Unified Vision-Language Models Necessary: Generalization Across Understanding and Generation', 'authors': 'Jihai Zhang, Tianle Li, Linjie Li, Zhengyuan Yang, Yu Cheng', 'link': 'https://arxiv.org/abs/2505.23043', 'abstract': 'Recent advancements in unified vision-language models (VLMs), which integrate both visual understanding and generation capabilities, have attracted significant attention. The underlying hypothesis is that a unified architecture with mixed training on both understanding and generation tasks can enable mutual enhancement between understanding and generation. However, this hypothesis remains underexplored in prior works on unified VLMs. To address this gap, this paper systematically investigates the generalization across understanding and generation tasks in unified VLMs. Specifically, we design a dataset closely aligned with real-world scenarios to facilitate extensive experiments and quantitative evaluations. We evaluate multiple unified VLM architectures to validate our findings. Our key findings are as follows. First, unified VLMs trained with mixed data exhibit mutual benefits in understanding and generation tasks across various architectures, and this mutual benefits can scale up with increased data. Second, better alignment between multimodal input and output spaces will lead to better generalization. Third, the knowledge acquired during generation tasks can transfer to understanding tasks, and this cross-task generalization occurs within the base language model, beyond modality adapters. Our findings underscore the critical necessity of unifying understanding and generation in VLMs, offering valuable insights for the design and optimization of unified VLMs.', 'abstract_zh': '近期统一视觉-语言模型（VLMs）的发展，这些模型整合了视觉理解和生成能力，引起了广泛关注。其背后的假设是，一个混合训练于理解和生成任务的统一架构可以促进理解和生成之间的相互增强。然而，这一假设在先前的统一VLM工作中尚未得到充分探索。为填补这一空白，本论文系统地研究了统一VLMs在理解和生成任务上的泛化能力。具体地，我们设计了一个紧密符合现实场景的数据集，以支持广泛的实验和定量评估。我们评估了多个统一VLM架构以验证我们的发现。我们的主要发现如下：首先，使用混合数据训练的统一VLMs在各类架构下的理解和生成任务中均表现出相互益处，且这种相互益处随数据量增加而增强；其次，多模态输入和输出空间更好的对齐将带来更好的泛化能力；第三，生成任务中获得的知识可以转移到理解任务中，这种跨任务泛化发生在基础语言模型中，而不仅仅是模态适配器。我们的发现强调了在VLMs中统一理解和生成的重要性，为统一VLMs的设计和优化提供了宝贵的见解。', 'title_zh': '统一的视觉语言模型必要吗：理解与生成跨任务的一般化能力'}
{'arxiv_id': 'arXiv:2505.23042', 'title': 'From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data', 'authors': 'Siwen Wang, Shitou Zhang, Wan-Lin Chen, Dung Truong, Tzyy-Ping Jung', 'link': 'https://arxiv.org/abs/2505.23042', 'abstract': 'Recent advancements in Large Language Models have inspired the development of foundation models across various domains. In this study, we evaluate the efficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art foundation EEG model, on a real-world stress classification dataset collected in a graduate classroom. Unlike previous studies that primarily evaluate LEMs using data from controlled clinical settings, our work assesses their applicability to real-world environments. We train a binary classifier that distinguishes between normal and elevated stress states using resting-state EEG data recorded from 18 graduate students during a class session. The best-performing fine-tuned model achieves a balanced accuracy of 90.47% with a 5-second window, significantly outperforming traditional stress classifiers in both accuracy and inference efficiency. We further evaluate the robustness of the fine-tuned LEM under random data shuffling and reduced channel counts. These results demonstrate the capability of LEMs to effectively process real-world EEG data and highlight their potential to revolutionize brain-computer interface applications by shifting the focus from model-centric to data-centric design.', 'abstract_zh': 'Recent advancements in Large Language Models have inspired the development of foundation models across various domains. In this study, we evaluate the efficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art foundation EEG model, on a real-world stress classification dataset collected in a graduate classroom. Unlike previous studies that primarily evaluate LEMs using data from controlled clinical settings, our work assesses their applicability to real-world environments. We train a binary classifier that distinguishes between normal and elevated stress states using resting-state EEG data recorded from 18 graduate students during a class session. The best-performing fine-tuned model achieves a balanced accuracy of 90.47% with a 5-second window, significantly outperforming traditional stress classifiers in both accuracy and inference efficiency. We further evaluate the robustness of the fine-tuned LEM under random data shuffling and reduced channel counts. These results demonstrate the capability of LEMs to effectively process real-world EEG data and highlight their potential to revolutionize brain-computer interface applications by shifting the focus from model-centric to data-centric design。\n\n标题：\n近期大型语言模型的进展激发了跨领域基础模型的发展。本研究通过在研究生课堂收集的真实世界压力分类数据集上微调最先进的基础脑电图模型LaBraM来评估大型脑电图模型（LEMs）的有效性。与之前主要在受控临床环境中评估LEMs的研究不同，我们的研究评估了其在真实世界环境中的适用性。我们使用18名研究生在课堂期间记录的静息状态脑电图数据训练了一种二元分类器，以区分正常和升高压力状态。最佳微调模型在5秒窗内实现了90.47%的平衡准确率，明显优于传统压力分类器在准确率和推理效率方面的表现。我们进一步评估了随机数据混洗和减少通道数条件下微调LEMs的鲁棒性。这些结果展示了LEMs有效处理真实脑电图数据的能力，并强调了它们通过从模型为中心转向数据为中心设计来革新脑机接口应用程序的潜力。', 'title_zh': '从理论到应用：基于实际压力数据 fine-tuning 大型 EEG 模型'}
{'arxiv_id': 'arXiv:2505.23032', 'title': 'Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks', 'authors': 'Dongwoo Lee, Dong Bok Lee, Steven Adriaensen, Juho Lee, Sung Ju Hwang, Frank Hutter, Seon Joo Kim, Hae Beom Lee', 'link': 'https://arxiv.org/abs/2505.23032', 'abstract': 'Scaling has been a major driver of recent advancements in deep learning. Numerous empirical studies have found that scaling laws often follow the power-law and proposed several variants of power-law functions to predict the scaling behavior at larger scales. However, existing methods mostly rely on point estimation and do not quantify uncertainty, which is crucial for real-world applications involving decision-making problems such as determining the expected performance improvements achievable by investing additional computational resources. In this work, we explore a Bayesian framework based on Prior-data Fitted Networks (PFNs) for neural scaling law extrapolation. Specifically, we design a prior distribution that enables the sampling of infinitely many synthetic functions resembling real-world neural scaling laws, allowing our PFN to meta-learn the extrapolation. We validate the effectiveness of our approach on real-world neural scaling laws, comparing it against both the existing point estimation methods and Bayesian approaches. Our method demonstrates superior performance, particularly in data-limited scenarios such as Bayesian active learning, underscoring its potential for reliable, uncertainty-aware extrapolation in practical applications.', 'abstract_zh': 'scaling规律基于Prior-data Fitted Networks的贝叶斯框架在深度学习中的扩展研究', 'title_zh': '基于先验匹配网络的贝叶斯神经网络外推定律'}
{'arxiv_id': 'arXiv:2505.23027', 'title': 'Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift', 'authors': 'Minh Nguyen Nhat To, Paul F RWilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul G. Krishnan', 'link': 'https://arxiv.org/abs/2505.23027', 'abstract': 'The subpopulationtion shift, characterized by a disparity in subpopulation distributibetween theween the training and target datasets, can significantly degrade the performance of machine learning models. Current solutions to subpopulation shift involve modifying empirical risk minimization with re-weighting strategies to improve generalization. This strategy relies on assumptions about the number and nature of subpopulations and annotations on group membership, which are unavailable for many real-world datasets. Instead, we propose using an ensemble of diverse classifiers to adaptively capture risk associated with subpopulations. Given a feature extractor network, we replace its standard linear classification layer with a mixture of prototypical classifiers, where each member is trained to classify the data while focusing on different features and samples from other members. In empirical evaluation on nine real-world datasets, covering diverse domains and kinds of subpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often outperforms the prior state-of-the-art in worst-group accuracy. The code is available at this https URL', 'abstract_zh': '子种群偏移导致训练集与目标集子种群分布差异，显著降低了机器学习模型的性能。针对子种群偏移的现有解决方案通过重新加权策略修改经验风险最小化，以提高泛化能力。该策略依赖于对子种群数量和性质的假设以及组成员身份的标注，而这些信息在许多真实世界的数据集中不可用。相反，我们提出使用多样化的分类器集合，以适应性地捕捉与子种群相关的风险。给定一个特征提取网络，我们将其标准的线性分类层替换为一种原型分类器的混合模型，其中每个成员都训练以分类数据并专注于不同的特征和样本。在涵盖不同领域和种类的子种群偏移的九个真实世界数据集上的实证评估中，我们所提出的方法Diverse Prototypical Ensembles (DPEs) 经常在最差组准确率方面优于之前的最佳方法。代码见此链接：https://xxx/', 'title_zh': '多样原型集成提高子人群转移鲁棒性'}
{'arxiv_id': 'arXiv:2505.23026', 'title': 'Context Robust Knowledge Editing for Language Models', 'authors': 'Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo', 'link': 'https://arxiv.org/abs/2505.23026', 'abstract': 'Knowledge editing (KE) methods offer an efficient way to modify knowledge in large language models. Current KE evaluations typically assess editing success by considering only the edited knowledge without any preceding contexts. In real-world applications, however, preceding contexts often trigger the retrieval of the original knowledge and undermine the intended edit. To address this issue, we develop CHED -- a benchmark designed to evaluate the context robustness of KE methods. Evaluations on CHED show that they often fail when preceding contexts are present. To mitigate this shortcoming, we introduce CoRE, a KE method designed to strengthen context robustness by minimizing context-sensitive variance in hidden states of the model for edited knowledge. This method not only improves the editing success rate in situations where a preceding context is present but also preserves the overall capabilities of the model. We provide an in-depth analysis of the differing impacts of preceding contexts when introduced as user utterances versus assistant responses, and we dissect attention-score patterns to assess how specific tokens influence editing success.', 'abstract_zh': '知识编辑（KE）方法提供了修改大型语言模型中知识的一种高效方式。当前的KE评估通常仅通过考虑编辑后的知识而忽略了其前置语境。然而，在实际应用中，前置语境往往会触发对原始知识的检索，从而削弱了预期的编辑效果。为解决这一问题，我们开发了CHED基准，旨在评估KE方法的语境 robustness。CHED上的评估表明，在前置语境存在的条件下，它们经常会失败。为了缓解这一不足，我们引入了CoRE方法，该方法通过最小化编辑知识在模型隐藏状态中的上下文敏感变异来增强语境 robustness。该方法不仅在存在前置语境的情况下提高了编辑成功率，还保留了模型的整体能力。我们深入分析了前置语境在作为用户话语和助手响应引入时的不同影响，并通过剖析注意力分数模式来评估特定令牌是如何影响编辑成功率的。', 'title_zh': '语言模型的上下文鲁棒知识编辑'}
{'arxiv_id': 'arXiv:2505.23020', 'title': 'AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models', 'authors': 'Jinchuan Zhang, Lu Yin, Yan Zhou, Songlin Hu', 'link': 'https://arxiv.org/abs/2505.23020', 'abstract': 'The acquisition of agentic capabilities has transformed LLMs from "knowledge providers" to "action executors", a trend that while expanding LLMs\' capability boundaries, significantly increases their susceptibility to malicious use. Previous work has shown that current LLM-based agents execute numerous malicious tasks even without being attacked, indicating a deficiency in agentic use safety alignment during the post-training phase. To address this gap, we propose AgentAlign, a novel framework that leverages abstract behavior chains as a medium for safety alignment data synthesis. By instantiating these behavior chains in simulated environments with diverse tool instances, our framework enables the generation of highly authentic and executable instructions while capturing complex multi-step dynamics. The framework further ensures model utility by proportionally synthesizing benign instructions through non-malicious interpretations of behavior chains, precisely calibrating the boundary between helpfulness and harmlessness. Evaluation results on AgentHarm demonstrate that fine-tuning three families of open-source models using our method substantially improves their safety (35.8% to 79.5% improvement) while minimally impacting or even positively enhancing their helpfulness, outperforming various prompting methods. The dataset and code have both been open-sourced.', 'abstract_zh': '基于代理能力获取，LLMs从“知识提供者”转变为“行动执行者”，这一趋势虽然扩展了LLMs的能力边界，但也显著增加了其被恶意利用的风险。已有研究表明，当前基于LLM的代理在未受攻击的情况下执行了大量恶意任务，这表明在后训练阶段代理用途的安全对齐存在缺陷。为解决这一问题，我们提出了AgentAlign，这是一种新颖的框架，利用抽象的行为链作为安全对齐数据合成的媒介。通过在包含多样工具实例的模拟环境中实例化这些行为链，我们的框架能够生成高度真实且可执行的指令，同时捕捉复杂多步动态。该框架进一步通过按比例合成良性指令来确保模型的实用性，通过对行为链进行非恶意解释，精确校准帮助性和无害性之间的边界。在AgentHarm上的评估结果表明，使用我们的方法微调三种开源模型大幅提高了其安全性（提升了35.8%至79.5%），同时对实用性的影响最小，甚至有所提升，优于各种提示方法。该数据集和代码均已开源。', 'title_zh': 'AgentAlign: 在从信息型到代理型大型语言模型转变中导航安全对齐'}
{'arxiv_id': 'arXiv:2505.23017', 'title': '$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting', 'authors': 'Xingjian Wu, Xiangfei Qiu, Hongfan Gao, Jilin Hu, Bin Yang, Chenjuan Guo', 'link': 'https://arxiv.org/abs/2505.23017', 'abstract': 'Probabilistic Time Series Forecasting (PTSF) plays a crucial role in decision-making across various fields, including economics, energy, and transportation. Most existing methods excell at short-term forecasting, while overlooking the hurdles of Long-term Probabilistic Time Series Forecasting (LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have a significant adverse effect on prediction accuracy, and make generative models inefficient by increasing the cost of each iteration. To overcome these limitations, we introduce $K^2$VAE, an efficient VAE-based generative model that leverages a KoopmanNet to transform nonlinear time series into a linear dynamical system, and devises a KalmanNet to refine predictions and model uncertainty in such linear system, which reduces error accumulation in long-term forecasting. Extensive experiments demonstrate that $K^2$VAE outperforms state-of-the-art methods in both short- and long-term PTSF, providing a more efficient and accurate solution.', 'abstract_zh': '概率时间序列预测（PTSF）在经济学、能源和交通等多个领域中起着至关重要的作用。大多数现有的方法在短期预测方面表现出色，但忽视了长期概率时间序列预测（LPTSF）的挑战。随着预测 horizon 的延长，内在的非线性动态对预测准确性产生了显著的负面影响，并且使得生成模型变得低效，因为每次迭代的成本都在增加。为克服这些限制，我们引入了 $K^2$VAE，这是一种基于 VAE 的高效生成模型，利用 KoopmanNet 将非线性时间序列转换为线性动态系统，并设计 KalmanNet 来改进对该线性系统的预测并建模不确定性，从而减少长期预测中的误差累积。广泛的经验验证表明，$K^2$VAE 在短期和长期 PTSF 方面都优于现有最先进的方法，提供了一种更高效和准确的解决方案。', 'title_zh': '$K^2$VAE：增强卡尔曼-科普曼变异自动编码器在概率时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2505.23008', 'title': 'Synthetic Document Question Answering in Hungarian', 'authors': 'Jonathan Li, Zoltan Csaki, Nidhi Hiremath, Etash Guha, Fenglu Hong, Edward Ma, Urmish Thakker', 'link': 'https://arxiv.org/abs/2505.23008', 'abstract': 'Modern VLMs have achieved near-saturation accuracy in English document visual question-answering (VQA). However, this task remains challenging in lower resource languages due to a dearth of suitable training and evaluation data. In this paper we present scalable methods for curating such datasets by focusing on Hungarian, approximately the 17th highest resource language on the internet. Specifically, we present HuDocVQA and HuDocVQA-manual, document VQA datasets that modern VLMs significantly underperform on compared to English DocVQA. HuDocVQA-manual is a small manually curated dataset based on Hungarian documents from Common Crawl, while HuDocVQA is a larger synthetically generated VQA data set from the same source. We apply multiple rounds of quality filtering and deduplication to HuDocVQA in order to match human-level quality in this dataset. We also present HuCCPDF, a dataset of 117k pages from Hungarian Common Crawl PDFs along with their transcriptions, which can be used for training a model for Hungarian OCR. To validate the quality of our datasets, we show how finetuning on a mixture of these datasets can improve accuracy on HuDocVQA for Llama 3.2 11B Instruct by +7.2%. Our datasets and code will be released to the public to foster further research in multilingual DocVQA.', 'abstract_zh': '现代VLMs在英语文档视觉问答(VQA)任务中已接近饱和准确率。然而，由于缺乏合适的训练和评估数据，这一任务对于低资源语言仍然具有挑战性。本文介绍了针对匈牙利语（互联网上约第17位资源语言）的大规模数据集编纂方法。具体而言，我们提出了HuDocVQA和HuDocVQA-manual文档VQA数据集，与英语DocVQA相比，现代VLMs在这些数据集上的表现显著较差。HuDocVQA-manual基于Common Crawl中的手动编纂小型匈牙利文档数据集，而HuDocVQA是从相同来源生成的较大规模合成VQA数据集。我们对HuDocVQA进行多轮质量过滤和去重，以匹配该数据集的人类水平质量。我们还介绍了包含来自匈牙利Common Crawl PDF的11.7万页及其转录的HuCCPDF数据集，可用于训练匈牙利OCR模型。为了验证数据集的质量，我们展示了这些数据集的混合微调可以提高Llama 3.2 11B Instruct在HuDocVQA上的准确性，提高7.2%。我们的数据集和代码将对外开放，以促进多语言DocVQA的进一步研究。', 'title_zh': '合成文档问答系统在匈牙利语中的应用'}
{'arxiv_id': 'arXiv:2505.23006', 'title': 'A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs', 'authors': 'Chiwan Park, Wonjun Jang, Daeryong Kim, Aelim Ahn, Kichang Yang, Woosung Hwang, Jihyeon Roh, Hyerin Park, Hyosun Wang, Min Seok Kim, Jihoon Kang', 'link': 'https://arxiv.org/abs/2505.23006', 'abstract': 'The advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings presents challenges, as it requires maintaining flexible conversational abilities while also strictly complying with service-specific constraints. This can be seen as two conflicting requirements due to the probabilistic nature of LLMs. In this paper, we propose our approach to addressing this challenge and detail the strategies we employed to overcome their inherent limitations in real-world applications. We conduct a practical case study of a conversational agent designed for the e-commerce domain, detailing our implementation workflow and optimizations. Our findings provide insights into bridging the gap between academic research and real-world application, introducing a framework for developing scalable, controllable, and reliable AI-driven agents.', 'abstract_zh': '大型语言模型（LLMs）的进步在搜索、推荐和聊天机器人等领域带来了显著的改善。然而，将最先进的（SOTA）研究应用到工业环境中存在挑战，因为它要求在保持灵活对话能力的同时，严格遵守服务特定的约束。由于大型语言模型的随机性质，这可以被视为两个相冲突的要求。在本文中，我们提出了应对这一挑战的方法，并详细介绍了我们为克服其实用应用中固有限制所采用的策略。我们对一个为电子商务领域设计的对话代理进行了实际案例研究，详细介绍了我们的实现工作流和优化方法。我们的发现为弥合学术研究与实际应用之间的差距提供了见解，引入了一种开发可扩展、可控和可靠的人工智能驱动代理的框架。', 'title_zh': '基于工作流图构建生产级对话代理的一种实用方法'}
{'arxiv_id': 'arXiv:2505.23003', 'title': 'Hybrid Cross-domain Robust Reinforcement Learning', 'authors': 'Linh Le Pham Van, Minh Hoang Nguyen, Hung Le, Hung The Tran, Sunil Gupta', 'link': 'https://arxiv.org/abs/2505.23003', 'abstract': "Robust reinforcement learning (RL) aims to learn policies that remain effective despite uncertainties in its environment, which frequently arise in real-world applications due to variations in environment dynamics. The robust RL methods learn a robust policy by maximizing value under the worst-case models within a predefined uncertainty set. Offline robust RL algorithms are particularly promising in scenarios where only a fixed dataset is available and new data cannot be collected. However, these approaches often require extensive offline data, and gathering such datasets for specific tasks in specific environments can be both costly and time-consuming. Using an imperfect simulator offers a faster, cheaper, and safer way to collect data for training, but it can suffer from dynamics mismatch. In this paper, we introduce HYDRO, the first Hybrid Cross-Domain Robust RL framework designed to address these challenges. HYDRO utilizes an online simulator to complement the limited amount of offline datasets in the non-trivial context of robust RL. By measuring and minimizing performance gaps between the simulator and the worst-case models in the uncertainty set, HYDRO employs novel uncertainty filtering and prioritized sampling to select the most relevant and reliable simulator samples. Our extensive experiments demonstrate HYDRO's superior performance over existing methods across various tasks, underscoring its potential to improve sample efficiency in offline robust RL.", 'abstract_zh': '稳健强化学习：HYDRO——跨域的混合稳健强化学习框架', 'title_zh': '跨域混合鲁棒强化学习'}
{'arxiv_id': 'arXiv:2505.22993', 'title': 'Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation', 'authors': 'Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui', 'link': 'https://arxiv.org/abs/2505.22993', 'abstract': 'Claim verification is a long-standing and challenging task that demands not only high accuracy but also explainability of the verification process. This task becomes an emerging research issue in the era of large language models (LLMs) since real-world claims are often complex, featuring intricate semantic structures or obfuscated entities. Traditional approaches typically address this by decomposing claims into sub-claims and querying a knowledge base to resolve hidden or ambiguous entities. However, the absence of effective disambiguation strategies for these entities can compromise the entire verification process. To address these challenges, we propose Verify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and comprehension abilities of LLM agents. VeGraph operates in three phases: (1) Graph Representation - an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information; (2) Entity Disambiguation -VeGraph iteratively interacts with the knowledge base to resolve ambiguous entities within the graph for deeper sub-claim verification; and (3) Verification - remaining triplets are verified to complete the fact-checking process. Experiments using Meta-Llama-3-70B (instruct version) show that VeGraph achieves competitive performance compared to baselines on two benchmarks HoVer and FEVEROUS, effectively addressing claim verification challenges. Our source code and data are available for further exploitation.', 'abstract_zh': 'Claim验证是一项长期且具有挑战性的任务，不仅要求高精度，还需要解释验证过程。随着大规模语言模型（LLMs）时代的到来，这一任务成为新兴的研究问题，因为实际的声明往往很复杂，包含复杂的语义结构或晦涩的实体。传统的做法通常通过将声明分解为子声明并查询知识库来解决隐藏或模糊的实体。然而，缺乏有效的消歧策略可能会破坏整个验证过程。为应对这些挑战，我们提出了基于图的验证（VeGraph）框架，该框架利用LLM代理的推理和理解能力。VeGraph分为三个阶段：（1）图表示 - 输入声明被分解为结构化的三元组，形成一种基于图的表示，整合了结构化和非结构化信息；（2）实体消歧 - VeGraph 通过迭代与知识库交互来解决图中的模糊实体，以进行更深层次的子声明验证；（3）验证 - 剩余的三元组被验证以完成事实核查过程。使用Meta-Llama-3-70B（指令版本）进行的实验表明，VeGraph 在两个基准 HoVer 和 FEVEROUS 上实现了竞争力的性能，有效解决了声明验证的挑战。我们的源代码和数据可供进一步利用。', 'title_zh': '图中验证：面向复杂声明验证的交互式图表示实体消歧改进'}
{'arxiv_id': 'arXiv:2505.22988', 'title': 'Model-Preserving Adaptive Rounding', 'authors': 'Albert Tseng, Zhaofeng Sun, Christopher De Sa', 'link': 'https://arxiv.org/abs/2505.22988', 'abstract': "The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as possible. To do this tractably, almost all LLM PTQ algorithms quantize linear layers by independently minimizing the immediate activation error. However, this localized objective ignores the effect of subsequent layers, so reducing it does not necessarily give a closer model. In this work, we introduce Yet Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses Kronecker-factored approximations of each linear layer's Hessian with respect to the \\textit{full model} KL divergence. YAQA consists of two components: Kronecker-factored sketches of the full layerwise Hessian that can be tractably computed for hundred-billion parameter LLMs, and a quantizer-independent rounding algorithm that uses these sketches and comes with theoretical guarantees. Across a wide range of models and quantizers, YAQA empirically reduces the KL divergence to the original model by $\\approx 30\\%$ while achieving state of the art performance on downstream tasks.", 'abstract_zh': 'Yet Another Quantization Algorithm (YAQA): 一种用于大型语言模型后训练量化的自适应舍入算法', 'title_zh': '模型保真自适应舍入'}
{'arxiv_id': 'arXiv:2505.22985', 'title': 'Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition', 'authors': 'Masaharu Kagiyama, Tsuyoshi Okita', 'link': 'https://arxiv.org/abs/2505.22985', 'abstract': 'This paper aims to develop an energy-efficient classifier for time-series data by introducing PatchEchoClassifier, a novel model that leverages a reservoir-based mechanism known as the Echo State Network (ESN). The model is designed for human activity recognition (HAR) using one-dimensional sensor signals and incorporates a tokenizer to extract patch-level representations. To train the model efficiently, we propose a knowledge distillation framework that transfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight reservoir-based student model. Experimental evaluations on multiple HAR datasets demonstrate that our model achieves over 80 percent accuracy while significantly reducing computational cost. Notably, PatchEchoClassifier requires only about one-sixth of the floating point operations (FLOPS) compared to DeepConvLSTM, a widely used convolutional baseline. These results suggest that PatchEchoClassifier is a promising solution for real-time and energy-efficient human activity recognition in edge computing environments.', 'abstract_zh': '本文旨在通过引入PatchEchoClassifier新型模型来开发一种高效的时间序列数据分类器，该模型利用一种名为回声状态网络（ESN）的水库机制。该模型针对一维传感器信号的人体活动识别（HAR）进行设计，并融合了分词器以提取基于片段的表示。为了高效训练模型，我们提出了一种知识蒸馏框架，将高容量MLP-Mixer教师模型的知识转移到轻量级的ESN学生模型上。在多个HAR数据集上的实验评估表明，我们的模型能够实现超过80%的准确率，同时显著降低计算成本。值得注意的是，PatchEchoClassifier所需的浮点运算（FLOPS）数量仅为DeepConvLSTM（广泛使用的卷积基线）的六分之一。这些结果表明，PatchEchoClassifier是边缘计算环境中实时和高效的人体活动识别的一种有前景的解决方案。', 'title_zh': '基于水库模型的分类器知识蒸馏：人体活动识别'}
{'arxiv_id': 'arXiv:2505.22976', 'title': 'Toward Memory-Aided World Models: Benchmarking via Spatial Consistency', 'authors': 'Kewei Lian, Shaofei Cai, Yilun Du, Yitao Liang', 'link': 'https://arxiv.org/abs/2505.22976', 'abstract': 'The ability to simulate the world in a spatially consistent manner is a crucial requirements for effective world models. Such a model enables high-quality visual generation, and also ensures the reliability of world models for downstream tasks such as simulation and planning. Designing a memory module is a crucial component for addressing spatial consistency: such a model must not only retain long-horizon observational information, but also enables the construction of explicit or implicit internal spatial representations. However, there are no dataset designed to promote the development of memory modules by explicitly enforcing spatial consistency constraints. Furthermore, most existing benchmarks primarily emphasize visual coherence or generation quality, neglecting the requirement of long-range spatial consistency. To bridge this gap, we construct a dataset and corresponding benchmark by sampling 150 distinct locations within the open-world environment of Minecraft, collecting about 250 hours (20 million frames) of loop-based navigation videos with actions. Our dataset follows a curriculum design of sequence lengths, allowing models to learn spatial consistency on increasingly complex navigation trajectories. Furthermore, our data collection pipeline is easily extensible to new Minecraft environments and modules. Four representative world model baselines are evaluated on our benchmark. Dataset, benchmark, and code are open-sourced to support future research.', 'abstract_zh': '在空间一致性的模拟世界中有效世界模型的构建：设计记忆模块的重要性及其数据集和基准测试的构建', 'title_zh': '基于内存辅助的世界模型：通过空间一致性进行基准测试'}
{'arxiv_id': 'arXiv:2505.22973', 'title': 'EquiReg: Equivariance Regularized Diffusion for Inverse Problems', 'authors': 'Bahareh Tolooshams, Aditi Chandrashekar, Rayhan Zirvi, Abbas Mammadov, Jiachen Yao, Chuwei Wang, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2505.22973', 'abstract': 'Diffusion models represent the state-of-the-art for solving inverse problems such as image restoration tasks. In the Bayesian framework, diffusion-based inverse solvers incorporate a likelihood term to guide the prior sampling process, generating data consistent with the posterior distribution. However, due to the intractability of the likelihood term, many current methods rely on isotropic Gaussian approximations, which lead to deviations from the data manifold and result in inconsistent, unstable reconstructions. We propose Equivariance Regularized (EquiReg) diffusion, a general framework for regularizing posterior sampling in diffusion-based inverse problem solvers. EquiReg enhances reconstructions by reweighting diffusion trajectories and penalizing those that deviate from the data manifold. We define a new distribution-dependent equivariance error, empirically identify functions that exhibit low error for on-manifold samples and higher error for off-manifold samples, and leverage these functions to regularize the diffusion sampling process. When applied to a variety of solvers, EquiReg outperforms state-of-the-art diffusion models in both linear and nonlinear image restoration tasks, as well as in reconstructing partial differential equations.', 'abstract_zh': '基于扩散的逆问题求解中的同胚正则化（EquiReg）方法：一种正则化扩散模型后验采样的通用框架', 'title_zh': '等变正则化的扩散模型用于逆问题'}
{'arxiv_id': 'arXiv:2505.22964', 'title': 'Exploring Scaling Laws for EHR Foundation Models', 'authors': 'Sheng Zhang, Qin Liu, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon', 'link': 'https://arxiv.org/abs/2505.22964', 'abstract': 'The emergence of scaling laws has profoundly shaped the development of large language models (LLMs), enabling predictable performance gains through systematic increases in model size, dataset volume, and compute. Yet, these principles remain largely unexplored in the context of electronic health records (EHRs) -- a rich, sequential, and globally abundant data source that differs structurally from natural language. In this work, we present the first empirical investigation of scaling laws for EHR foundation models. By training transformer architectures on patient timeline data from the MIMIC-IV database across varying model sizes and compute budgets, we identify consistent scaling patterns, including parabolic IsoFLOPs curves and power-law relationships between compute, model parameters, data size, and clinical utility. These findings demonstrate that EHR models exhibit scaling behavior analogous to LLMs, offering predictive insights into resource-efficient training strategies. Our results lay the groundwork for developing powerful EHR foundation models capable of transforming clinical prediction tasks and advancing personalized healthcare.', 'abstract_zh': '电子健康记录（EHR）基础模型的标度律研究：从大规模语言模型中汲取经验', 'title_zh': '探索电子健康记录基础模型的扩展规律'}
{'arxiv_id': 'arXiv:2505.22946', 'title': 'NegVQA: Can Vision Language Models Understand Negation?', 'authors': 'Yuhui Zhang, Yuchang Su, Yiming Liu, Serena Yeung-Levy', 'link': 'https://arxiv.org/abs/2505.22946', 'abstract': "Negation is a fundamental linguistic phenomenon that can entirely reverse the meaning of a sentence. As vision language models (VLMs) continue to advance and are deployed in high-stakes applications, assessing their ability to comprehend negation becomes essential. To address this, we introduce NegVQA, a visual question answering (VQA) benchmark consisting of 7,379 two-choice questions covering diverse negation scenarios and image-question distributions. We construct NegVQA by leveraging large language models to generate negated versions of questions from existing VQA datasets. Evaluating 20 state-of-the-art VLMs across seven model families, we find that these models struggle significantly with negation, exhibiting a substantial performance drop compared to their responses to the original questions. Furthermore, we uncover a U-shaped scaling trend, where increasing model size initially degrades performance on NegVQA before leading to improvements. Our benchmark reveals critical gaps in VLMs' negation understanding and offers insights into future VLM development. Project page available at this https URL.", 'abstract_zh': '否定是语言学中的一个基本现象，能够彻底反转句子的意义。随着视觉语言模型（VLMs）不断发展并在高风险应用中部署，评估其理解否定的能力变得至关重要。为此，我们引入了NegVQA，这是一个包含7,379个二选一问题的视觉问答（VQA）基准，涵盖了多种否定场景和图像-问题分布。我们通过利用大型语言模型生成现有VQA数据集中问题的否定版本来构建NegVQA。我们在七个模型家族中的20种最先进的VLMs上进行评估，发现这些模型在否定方面普遍表现出色，其性能明显低于对原始问题的响应。此外，我们发现一个倒U型扩增趋势，即增加模型规模最初会恶化NegVQA上的性能，之后会带来提升。我们的基准揭示了VLMs在理解否定方面的重要缺陷，并提供了未来VLM开发的见解。项目页面可访问此链接：this https URL。', 'title_zh': 'NegVQA：视觉语言模型能理解否定词吗？'}
{'arxiv_id': 'arXiv:2505.22945', 'title': 'OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature', 'authors': 'Alisha Srivastava, Emir Korukluoglu, Minh Nhat Le, Duyen Tran, Chau Minh Pham, Marzena Karpinska, Mohit Iyyer', 'link': 'https://arxiv.org/abs/2505.22945', 'abstract': "Large language models (LLMs) are known to memorize and recall English text from their pretraining data. However, the extent to which this ability generalizes to non-English languages or transfers across languages remains unclear. This paper investigates multilingual and cross-lingual memorization in LLMs, probing if memorized content in one language (e.g., English) can be recalled when presented in translation. To do so, we introduce OWL, a dataset of 31.5K aligned excerpts from 20 books in ten languages, including English originals, official translations (Vietnamese, Spanish, Turkish), and new translations in six low-resource languages (Sesotho, Yoruba, Maithili, Malagasy, Setswana, Tahitian). We evaluate memorization across model families and sizes through three tasks: (1) direct probing, which asks the model to identify a book's title and author; (2) name cloze, which requires predicting masked character names; and (3) prefix probing, which involves generating continuations. We find that LLMs consistently recall content across languages, even for texts without direct translation in pretraining data. GPT-4o, for example, identifies authors and titles 69% of the time and masked entities 6% of the time in newly translated excerpts. Perturbations (e.g., masking characters, shuffling words) modestly reduce direct probing accuracy (7% drop for shuffled official translations). Our results highlight the extent of cross-lingual memorization and provide insights on the differences between the models.", 'abstract_zh': '大型语言模型（LLMs）已知能够记忆和回忆其预训练数据中的英语文本。然而，这种能力在非英语语言中或在不同语言之间泛化和迁移的程度尚不明确。本文探讨了LLMs的多语言和跨语言记忆能力，探究一种语言（如英语）的记忆内容在翻译成另一种语言时能否被回忆起来。为此，我们引入了OWL数据集，包含31500条来自20本书的对齐片段，涉及十种语言，包括英语原著，官方翻译（越南语、西班牙语、土耳其语），以及六种低资源语言的新翻译（塞索托语、约鲁巴语、马蒂利希语、马达加斯加语、塞茨瓦纳语、塔希提语）。我们通过三项任务评估模型在不同家族和大小下的记忆能力：（1）直接探查任务，要求模型识别书籍的标题和作者；（2）名字填空任务，要求预测被遮掩的角色名称；（3）前缀探查任务，涉及生成续写内容。我们发现，即使对于预训练数据中没有直接翻译的文本，LLMs也能在不同语言间一致地回忆内容。例如，GPT-4o在新翻译片段中识别作者和标题的准确率为69%，识别被遮掩实体的准确率为6%。扰动（如遮掩角色、打乱单词顺序）适度降低了直接探查任务的准确性（官方翻译打乱后的准确率下降7%）。我们的结果突显了跨语言记忆的程度，并提供了模型之间差异的见解。', 'title_zh': 'OWL：通过世界文学探查 Memorized Texts 的跨语言召回能力'}
{'arxiv_id': 'arXiv:2505.22944', 'title': 'ATI: Any Trajectory Instruction for Controllable Video Generation', 'authors': 'Angtian Wang, Haibin Huang, Jacob Zhiyuan Fang, Yiding Yang, Chongyang Ma', 'link': 'https://arxiv.org/abs/2505.22944', 'abstract': 'We propose a unified framework for motion control in video generation that seamlessly integrates camera movement, object-level translation, and fine-grained local motion using trajectory-based inputs. In contrast to prior methods that address these motion types through separate modules or task-specific designs, our approach offers a cohesive solution by projecting user-defined trajectories into the latent space of pre-trained image-to-video generation models via a lightweight motion injector. Users can specify keypoints and their motion paths to control localized deformations, entire object motion, virtual camera dynamics, or combinations of these. The injected trajectory signals guide the generative process to produce temporally consistent and semantically aligned motion sequences. Our framework demonstrates superior performance across multiple video motion control tasks, including stylized motion effects (e.g., motion brushes), dynamic viewpoint changes, and precise local motion manipulation. Experiments show that our method provides significantly better controllability and visual quality compared to prior approaches and commercial solutions, while remaining broadly compatible with various state-of-the-art video generation backbones. Project page: this https URL.', 'abstract_zh': '我们提出了一种统一框架，用于视频生成中的运动控制，该框架通过基于轨迹的输入无缝整合摄像机运动、对象级平移和局部精细运动。与此前通过独立模块或特定任务设计处理这些运动类型的方 法不同，我们的方法通过对预训练的图像到视频生成模型的潜在空间进行轻量级运动注入，以用户定义的轨迹为依据提供一个连贯的解决方案。用户可以指定关键点和它们的运动路径来控制局部变形、整个对象的运动、虚拟摄像机的动力学或它们的组合。注入的轨迹信号指导生成过程，以产生时序一致且语义对齐的运动序列。我们的框架在多种视频运动控制任务中表现出色，包括风格化运动效果（例如，运动画笔）、动态视角变化和精确的局部运动操控。实验表明，与以前的方法和商业解决方案相比，我们的方法在可控性与视觉质量方面提供了显著改进，同时仍然与各种最先进的视频生成骨干网络兼容。项目页面: this https URL。', 'title_zh': 'ATI: 任意轨迹指令的可控视频生成'}
{'arxiv_id': 'arXiv:2505.22943', 'title': 'Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates', 'authors': 'Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim', 'link': 'https://arxiv.org/abs/2505.22943', 'abstract': 'While pre-trained multimodal representations (e.g., CLIP) have shown impressive capabilities, they exhibit significant compositional vulnerabilities leading to counterintuitive judgments. We introduce Multimodal Adversarial Compositionality (MAC), a benchmark that leverages large language models (LLMs) to generate deceptive text samples to exploit these vulnerabilities across different modalities and evaluates them through both sample-wise attack success rate and group-wise entropy-based diversity. To improve zero-shot methods, we propose a self-training approach that leverages rejection-sampling fine-tuning with diversity-promoting filtering, which enhances both attack success rate and sample diversity. Using smaller language models like Llama-3.1-8B, our approach demonstrates superior performance in revealing compositional vulnerabilities across various multimodal representations, including images, videos, and audios.', 'abstract_zh': '多模态对抗合成性基准（MAC）：利用大型语言模型揭示预训练多模态表示的组成脆弱性', 'title_zh': 'LLM们能否欺骗CLIP？基于文本更新的预训练多模态表示对抗聚合性基准测试'}
{'arxiv_id': 'arXiv:2505.22942', 'title': 'WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning', 'authors': 'Yuchen Zhuang, Di Jin, Jiaao Chen, Wenqi Shi, Hanrui Wang, Chao Zhang', 'link': 'https://arxiv.org/abs/2505.22942', 'abstract': 'Large language models (LLMs)-empowered web agents enables automating complex, real-time web navigation tasks in enterprise environments. However, existing web agents relying on supervised fine-tuning (SFT) often struggle with generalization and robustness due to insufficient reasoning capabilities when handling the inherently dynamic nature of web interactions. In this study, we introduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework designed explicitly to enhance single-step reasoning and planning for business-oriented web navigation tasks. We employ a structured reward function that evaluates both adherence to output formats and correctness of actions, enabling WorkForceAgent-R1 to implicitly learn robust intermediate reasoning without explicit annotations or extensive expert demonstrations. Extensive experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by 10.26-16.59%, achieving competitive performance relative to proprietary LLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.', 'abstract_zh': '基于大型语言模型的WorkForceAgent-R1增强了企业环境中复杂实时网页导航任务的自动化能力，并采用基于规则的强化学习框架提升单步推理和规划。', 'title_zh': 'WorkForceAgent-R1: 通过强化学习激励基于LLM的Web代理的推理能力'}
{'arxiv_id': 'arXiv:2505.22939', 'title': 'Generative Social Choice: The Next Generation', 'authors': 'Niclas Boehmer, Sara Fish, Ariel D. Procaccia', 'link': 'https://arxiv.org/abs/2505.22939', 'abstract': 'A key task in certain democratic processes is to produce a concise slate of statements that proportionally represents the full spectrum of user opinions. This task is similar to committee elections, but unlike traditional settings, the candidate set comprises all possible statements of varying lengths, and so it can only be accessed through specific queries. Combining social choice and large language models, prior work has approached this challenge through a framework of generative social choice. We extend the framework in two fundamental ways, providing theoretical guarantees even in the face of approximately optimal queries and a budget limit on the overall length of the slate. Using GPT-4o to implement queries, we showcase our approach on datasets related to city improvement measures and drug reviews, demonstrating its effectiveness in generating representative slates from unstructured user opinions.', 'abstract_zh': '某些民主进程中的一项关键任务是生成一份简明的声明列表，以比例性地反映所有用户的完整意见范围。这一任务类似于委员会选举，但与传统设置不同的是，候选集包括所有可能的、长度各异的声明，并且只能通过特定查询访问。结合社会选择理论和大规模语言模型，先前的工作通过生成社会选择的框架来应对这一挑战。我们在此框架中进行了两项根本性的扩展，在近似最优查询和总体声明列表长度预算限制的情况下，提供理论保证。使用GPT-4o来实现查询，我们在与城市改进措施和药物评论相关的数据集中展示了这种方法的有效性，证明了其在生成代表用户意见的简明声明列表方面的效果。', 'title_zh': '生成式社会选择：下一代'}
{'arxiv_id': 'arXiv:2505.22934', 'title': 'Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging', 'authors': 'Haobo Zhang, Jiayu Zhou', 'link': 'https://arxiv.org/abs/2505.22934', 'abstract': 'Fine-tuning large language models (LMs) for individual tasks yields strong performance but is expensive for deployment and storage. Recent works explore model merging to combine multiple task-specific models into a single multi-task model without additional training. However, existing merging methods often fail for models fine-tuned with low-rank adaptation (LoRA), due to significant performance degradation. In this paper, we show that this issue arises from a previously overlooked interplay between model parameters and data distributions. We propose Orthogonal Subspaces for Robust model Merging (OSRM) to constrain the LoRA subspace *prior* to fine-tuning, ensuring that updates relevant to one task do not adversely shift outputs for others. Our approach can seamlessly integrate with most existing merging algorithms, reducing the unintended interference among tasks. Extensive experiments on eight datasets, tested with three widely used LMs and two large LMs, demonstrate that our method not only boosts merging performance but also preserves single-task accuracy. Furthermore, our approach exhibits greater robustness to the hyperparameters of merging. These results highlight the importance of data-parameter interaction in model merging and offer a plug-and-play solution for merging LoRA models.', 'abstract_zh': '细调大规模语言模型（LMs）以完成特定任务可以取得出色的性能，但在部署和存储方面成本高昂。近期的研究探讨了模型合并的方法，即将多个任务特异模型合并为一个 multitask 模型，而不需要额外的训练。然而，现有的合并方法常因细调时使用了低秩适应（LoRA）技术而导致显著的性能下降。在本文中，我们展示了这一问题源于模型参数和数据分布之间之前未被注意到的相互作用。我们提出了一种正交子空间用于鲁棒模型合并（OSRM）的方法，以在细调之前约束LoRA子空间，确保对一个任务的相关更新不会对其他任务的输出产生不利影响。我们的方法可以无缝集成到大多数现有的合并算法中，减少任务之间的无意干扰。在八个数据集上的广泛实验，使用三种广泛使用的LMs和两种大型LMs进行测试，证明了我们的方法不仅提升了合并性能，还保持了单任务的准确性。此外，我们的方法对合并的超参数表现出更大的鲁棒性。这些结果突显了模型合并中数据-参数交互的重要性，并提供了一种插件即用的解决方案，用于合并LoRA模型。', 'title_zh': '揭开LoRA干扰的谜团：稳健模型合并的正交子空间'}
{'arxiv_id': 'arXiv:2505.22922', 'title': 'Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking', 'authors': 'Athanasios Glentis, Jiaxiang Li, Qiulin Shang, Andi Han, Ioannis Tsaknakis, Quan Wei, Mingyi Hong', 'link': 'https://arxiv.org/abs/2505.22922', 'abstract': 'Fueled by their remarkable ability to tackle diverse tasks across multiple domains, large language models (LLMs) have grown at an unprecedented rate, with some recent models containing trillions of parameters. This growth is accompanied by substantial computational challenges, particularly regarding the memory and compute resources required for training and fine-tuning. Numerous approaches have been explored to address these issues, such as LoRA. While these methods are effective for fine-tuning, their application to pre-training is significantly more challenging due to the need to learn vast datasets. Motivated by this issue, we aim to address the following questions: Can parameter- or memory-efficient methods enhance pre-training efficiency while achieving performance comparable to full-model training? How can the performance gap be narrowed? To this end, the contributions of this work are the following. (1) We begin by conducting a comprehensive survey that summarizes state-of-the-art methods for efficient pre-training. (2) We perform a benchmark evaluation of several representative memory efficient pre-training approaches to comprehensively evaluate their performance across model sizes. We observe that with a proper choice of optimizer and hyperparameters, full-rank training delivers the best performance, as expected. We also notice that incorporating high-rank updates in low-rank approaches is the key to improving their performance. (3) Finally, we propose two practical techniques, namely weight refactorization and momentum reset, to enhance the performance of efficient pre-training methods. We observe that applying these techniques to the low-rank method (on a 1B model) can achieve a lower perplexity than popular memory efficient algorithms such as GaLore and Fira, while simultaneously using about 25% less memory.', 'abstract_zh': '受其卓越的跨多个领域执行多样化任务的能力推动，大规模语言模型（LLMs）以前所未有的速度增长，其中一些最近的模型包含万亿级别的参数。这一增长伴随着显著的计算挑战，特别是在训练和微调过程中所需的内存和计算资源方面。为了应对这些挑战，已经探索了许多方法，例如LoRA。尽管这些方法在微调方面效果显著，但将它们应用于预训练却面临更大的挑战，因为需要学习庞大的数据集。为了应对这一问题，本文旨在回答以下问题：参数效率或内存效率的方法能否在与全模型训练相当的性能下提高预训练效率？如何缩小性能差距？为此，本文的贡献如下。（1）我们首先进行全面的综述，总结了最新的高效预训练方法。（2）我们对几种代表性的内存高效预训练方法进行了基准测试评估，以全面评估它们在不同模型规模下的性能。我们发现，在适当的优化器和超参数选择下，全秩训练提供最优性能，这是预期的结果。我们还注意到，在低秩方法中引入高秩更新是提高其性能的关键。（3）最后，我们提出了两种实用的技术，即权重重因子化和动量重置，以提高高效预训练方法的性能。我们发现，将这些技术应用于低秩方法（在一个1B模型上）可以实现比GaLore和Fira等流行的内存高效算法更低的困惑度，同时使用约25%的更少内存。', 'title_zh': '面向大规模语言模型的可扩展参数和内存高效预训练：近期算法进展与基准测试'}
{'arxiv_id': 'arXiv:2505.22909', 'title': 'Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents', 'authors': 'Cristian Chica, Yinglong Guo, Gilad Lerman', 'link': 'https://arxiv.org/abs/2505.22909', 'abstract': 'There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.', 'abstract_zh': '无限重复博弈中$q$学习代理learn supracompetitive价格的首个理论解释', 'title_zh': '基于Q-learning代理的合谋理论研究：学会索取更多'}
{'arxiv_id': 'arXiv:2505.22906', 'title': 'HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding', 'authors': 'Emmanuel Anaya González, Raven Rothkopf, Sorin Lerner, Nadia Polikarpova', 'link': 'https://arxiv.org/abs/2505.22906', 'abstract': 'While AI programming tools hold the promise of increasing programmers\' capabilities and productivity to a remarkable degree, they often exclude users from essential decision-making processes, causing many to effectively "turn off their brains" and over-rely on solutions provided by these systems. These behaviors can have severe consequences in critical domains, like software security. We propose Human-in-the-loop Decoding, a novel interaction technique that allows users to observe and directly influence LLM decisions during code generation, in order to align the model\'s output with their personal requirements. We implement this technique in HiLDe, a code completion assistant that highlights critical decisions made by the LLM and provides local alternatives for the user to explore. In a within-subjects study (N=18) on security-related tasks, we found that HiLDe led participants to generate significantly fewer vulnerabilities and better align code generation with their goals compared to a traditional code completion assistant.', 'abstract_zh': 'AI编程工具虽有潜力大幅提高程序员的能力和 productivity，但往往排除了用户在关键决策过程中的参与，导致许多人 effectively “关闭大脑”，过度依赖这些系统的解决方案。这些行为在软件安全等关键领域可能会造成严重后果。我们提出了一种名为 Human-in-the-loop Decoding 的新型交互技术，允许用户在代码生成过程中观察并直接影响 LLM 的决策，以使模型的输出与用户个人需求一致。我们在 HiLDe 中实现了这一技术，这是一种代码补全助手，突出显示了 LLM 作出的关键决策，并提供了局部替代方案供用户探索。在一项关于安全相关任务的单被试内研究（N=18）中，我们发现 HiLDe 使参与者生成的漏洞显著减少，并且更符合用户的目标。', 'title_zh': 'HiLDe：基于人类在环解码的意图代码生成'}
{'arxiv_id': 'arXiv:2505.22904', 'title': 'Defining Foundation Models for Computational Science: A Call for Clarity and Rigor', 'authors': 'Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss', 'link': 'https://arxiv.org/abs/2505.22904', 'abstract': 'The widespread success of foundation models in natural language processing and computer vision has inspired researchers to extend the concept to scientific machine learning and computational science. However, this position paper argues that as the term "foundation model" is an evolving concept, its application in computational science is increasingly used without a universally accepted definition, potentially creating confusion and diluting its precise scientific meaning. In this paper, we address this gap by proposing a formal definition of foundation models in computational science, grounded in the core values of generality, reusability, and scalability. We articulate a set of essential and desirable characteristics that such models must exhibit, drawing parallels with traditional foundational methods, like the finite element and finite volume methods. Furthermore, we introduce the Data-Driven Finite Element Method (DD-FEM), a framework that fuses the modular structure of classical FEM with the representational power of data-driven learning. We demonstrate how DD-FEM addresses many of the key challenges in realizing foundation models for computational science, including scalability, adaptability, and physics consistency. By bridging traditional numerical methods with modern AI paradigms, this work provides a rigorous foundation for evaluating and developing novel approaches toward future foundation models in computational science.', 'abstract_zh': '基础模型在计算科学中的正式定义及其应用：从数据驱动有限元方法探索泛化、重用和可扩展性', 'title_zh': '定义计算科学中的基础模型：寻求清晰与严谨'}
{'arxiv_id': 'arXiv:2505.22889', 'title': 'Local Stability and Region of Attraction Analysis for Neural Network Feedback Systems under Positivity Constraints', 'authors': 'Hamidreza Montazeri Hedesh, Moh Kamalul Wafi, Milad Siami', 'link': 'https://arxiv.org/abs/2505.22889', 'abstract': "We study the local stability of nonlinear systems in the Lur'e form with static nonlinear feedback realized by feedforward neural networks (FFNNs). By leveraging positivity system constraints, we employ a localized variant of the Aizerman conjecture, which provides sufficient conditions for exponential stability of trajectories confined to a compact set. Using this foundation, we develop two distinct methods for estimating the Region of Attraction (ROA): (i) a less conservative Lyapunov-based approach that constructs invariant sublevel sets of a quadratic function satisfying a linear matrix inequality (LMI), and (ii) a novel technique for computing tight local sector bounds for FFNNs via layer-wise propagation of linear relaxations. These bounds are integrated into the localized Aizerman framework to certify local exponential stability. Numerical results demonstrate substantial improvements over existing integral quadratic constraint-based approaches in both ROA size and scalability.", 'abstract_zh': "我们研究了静态非线性反馈由前向神经网络（FFNNs）实现的Lur'e形式非线性系统的局部稳定性。通过利用正系统约束，我们采用Aizerman猜想的局部变体，为限制在紧致集内的轨迹的指数稳定性提供了充分条件。基于此基础，我们发展了两种不同的方法来估计吸引域（ROA）：（i）一种较少保守的基于李雅普诺夫的方法，构建二次函数的不变次水平集，满足线性矩阵不等式（LMI）；（ii）通过逐层传播线性放松来计算FFNNs的紧局部扇区界的新技术。这些界值集成到局部化的Aizerman框架中，以验证局部指数稳定性。数值结果表明，与现有的基于积分二次约束的方法相比，在ROA大小和可扩展性方面均实现了显著改进。", 'title_zh': '具有正值约束条件下神经网络反馈系统的地方稳定性和吸引域分析'}
{'arxiv_id': 'arXiv:2505.22880', 'title': 'Semantic Exploration and Dense Mapping of Complex Environments using Ground Robots Equipped with LiDAR and Panoramic Camera', 'authors': 'Xiaoyang Zhan, Shixin Zhou, Qianqian Yang, Yixuan Zhao, Hao Liu, Srinivas Chowdary Ramineni, Kenji Shimada', 'link': 'https://arxiv.org/abs/2505.22880', 'abstract': "This paper presents a system for autonomous semantic exploration and dense semantic target mapping of a complex unknown environment using a ground robot equipped with a LiDAR-panoramic camera suite. Existing approaches often struggle to balance collecting high-quality observations from multiple view angles and avoiding unnecessary repetitive traversal. To fill this gap, we propose a complete system combining mapping and planning. We first redefine the task as completing both geometric coverage and semantic viewpoint observation. We then manage semantic and geometric viewpoints separately and propose a novel Priority-driven Decoupled Local Sampler to generate local viewpoint sets. This enables explicit multi-view semantic inspection and voxel coverage without unnecessary repetition. Building on this, we develop a hierarchical planner to ensure efficient global coverage. In addition, we propose a Safe Aggressive Exploration State Machine, which allows aggressive exploration behavior while ensuring the robot's safety. Our system includes a plug-and-play semantic target mapping module that integrates seamlessly with state-of-the-art SLAM algorithms for pointcloud-level dense semantic target mapping. We validate our approach through extensive experiments in both realistic simulations and complex real-world environments. Simulation results show that our planner achieves faster exploration and shorter travel distances while guaranteeing a specified number of multi-view inspections. Real-world experiments further confirm the system's effectiveness in achieving accurate dense semantic object mapping of unstructured environments.", 'abstract_zh': '一种基于地面机器人和LiDAR-全景相机套件的复杂未知环境自主语义探索与密集语义目标映射系统', 'title_zh': '使用配备激光雷达和全景相机的地勤机器人进行复杂环境的语义探索与密集建图'}
{'arxiv_id': 'arXiv:2505.22878', 'title': 'BugWhisperer: Fine-Tuning LLMs for SoC Hardware Vulnerability Detection', 'authors': 'Shams Tarek, Dipayan Saha, Sujan Kumar Saha, Farimah Farahmandi', 'link': 'https://arxiv.org/abs/2505.22878', 'abstract': "The current landscape of system-on-chips (SoCs) security verification faces challenges due to manual, labor-intensive, and inflexible methodologies. These issues limit the scalability and effectiveness of security protocols, making bug detection at the Register-Transfer Level (RTL) difficult. This paper proposes a new framework named BugWhisperer that utilizes a specialized, fine-tuned Large Language Model (LLM) to address these challenges. By enhancing the LLM's hardware security knowledge and leveraging its capabilities for text inference and knowledge transfer, this approach automates and improves the adaptability and reusability of the verification process. We introduce an open-source, fine-tuned LLM specifically designed for detecting security vulnerabilities in SoC designs. Our findings demonstrate that this tailored LLM effectively enhances the efficiency and flexibility of the security verification process. Additionally, we introduce a comprehensive hardware vulnerability database that supports this work and will further assist the research community in enhancing the security verification process.", 'abstract_zh': '当前系统级芯片（SoC）安全验证的挑战源自于手动、劳动密集且灵活性差的方法。这些问题限制了安全协议的可扩展性和有效性，使得在寄存器传输级（RTL）检测漏洞变得困难。本文提出了一种名为BugWhisperer的新框架，利用专门微调的大规模语言模型（LLM）来应对这些挑战。通过增强LLM的硬件安全知识并利用其文本推理和知识转移的能力，这种方法自动化并提升了验证过程的适应性和可重用性。我们引入了一个针对SoC设计中的安全漏洞检测专门微调的开源LLM。我们的研究结果表明，这种定制化的LLM有效地提高了安全验证过程的效率和灵活性。此外，我们还引入了一个全面的硬件漏洞数据库，支持这项工作，并将进一步协助研究社区提升安全验证过程。', 'title_zh': 'BugWhisperer: 细化调谐LLMs进行SoC硬件漏洞检测'}
{'arxiv_id': 'arXiv:2505.22866', 'title': 'Scaling Offline RL via Efficient and Expressive Shortcut Models', 'authors': 'Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun', 'link': 'https://arxiv.org/abs/2505.22866', 'abstract': "Diffusion and flow models have emerged as powerful generative approaches capable of modeling diverse and multimodal behavior. However, applying these models to offline reinforcement learning (RL) remains challenging due to the iterative nature of their noise sampling processes, making policy optimization difficult. In this paper, we introduce Scalable Offline Reinforcement Learning (SORL), a new offline RL algorithm that leverages shortcut models - a novel class of generative models - to scale both training and inference. SORL's policy can capture complex data distributions and can be trained simply and efficiently in a one-stage training procedure. At test time, SORL introduces both sequential and parallel inference scaling by using the learned Q-function as a verifier. We demonstrate that SORL achieves strong performance across a range of offline RL tasks and exhibits positive scaling behavior with increased test-time compute. We release the code at this http URL.", 'abstract_zh': '扩散和流模型已成为能够 modeling 多样性和 multimodal 行为的强大力 generative 方法。然而，将这些模型应用于 offline 强化学习（RL）仍具挑战性，因为它们的噪声采样过程具有迭代性，使得策略优化困难。本文我们引入了 Scalable Offline Reinforcement Learning (SORL)，一种新的 offline RL 算法，该算法利用 shortcut 模型——一类新型 generative 模型——来扩展训练和推理。SORL 的策略能够捕捉复杂的数据分布，并且可以在一次训练过程中简单且高效地进行训练。测试时，SORL 通过使用学习到的 Q 函数进行验证，引入了顺序和并行推理扩展。我们展示了 SORL 在多种 offline RL 任务中表现出强劲性能，并且在测试时计算资源增加时表现出积极的扩展行为。代码发布在 this http URL。', 'title_zh': '通过高效且表达能力强的捷径模型扩展 Offline RL'}
{'arxiv_id': 'arXiv:2505.22865', 'title': 'BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models', 'authors': 'Susan Liang, Dejan Markovic, Israel D. Gebru, Steven Krenn, Todd Keebler, Jacob Sandakly, Frank Yu, Samuel Hassel, Chenliang Xu, Alexander Richard', 'link': 'https://arxiv.org/abs/2505.22865', 'abstract': 'Binaural rendering aims to synthesize binaural audio that mimics natural hearing based on a mono audio and the locations of the speaker and listener. Although many methods have been proposed to solve this problem, they struggle with rendering quality and streamable inference. Synthesizing high-quality binaural audio that is indistinguishable from real-world recordings requires precise modeling of binaural cues, room reverb, and ambient sounds. Additionally, real-world applications demand streaming inference. To address these challenges, we propose a flow matching based streaming binaural speech synthesis framework called BinauralFlow. We consider binaural rendering to be a generation problem rather than a regression problem and design a conditional flow matching model to render high-quality audio. Moreover, we design a causal U-Net architecture that estimates the current audio frame solely based on past information to tailor generative models for streaming inference. Finally, we introduce a continuous inference pipeline incorporating streaming STFT/ISTFT operations, a buffer bank, a midpoint solver, and an early skip schedule to improve rendering continuity and speed. Quantitative and qualitative evaluations demonstrate the superiority of our method over SOTA approaches. A perceptual study further reveals that our model is nearly indistinguishable from real-world recordings, with a $42\\%$ confusion rate.', 'abstract_zh': '基于流匹配的流式立体声语音合成框架：BinauralFlow', 'title_zh': 'BinauralFlow：一种基于因果流匹配模型的高保真二元语音合成方法及其流式处理策略'}
{'arxiv_id': 'arXiv:2505.22860', 'title': 'Permissioned LLMs: Enforcing Access Control in Large Language Models', 'authors': 'Bargav Jayaraman, Virendra J. Marathe, Hamid Mozaffari, William F. Shen, Krishnaram Kenthapadi', 'link': 'https://arxiv.org/abs/2505.22860', 'abstract': 'In enterprise settings, organizational data is segregated, siloed and carefully protected by elaborate access control frameworks. These access control structures can completely break down if an LLM fine-tuned on the siloed data serves requests, for downstream tasks, from individuals with disparate access privileges. We propose Permissioned LLMs (PermLLM), a new class of LLMs that superimpose the organizational data access control structures on query responses they generate. We formalize abstractions underpinning the means to determine whether access control enforcement happens correctly over LLM query responses. Our formalism introduces the notion of a relevant response that can be used to prove whether a PermLLM mechanism has been implemented correctly. We also introduce a novel metric, called access advantage, to empirically evaluate the efficacy of a PermLLM mechanism. We introduce three novel PermLLM mechanisms that build on Parameter Efficient Fine-Tuning to achieve the desired access control. We furthermore present two instantiations of access advantage--(i) Domain Distinguishability Index (DDI) based on Membership Inference Attacks, and (ii) Utility Gap Index (UGI) based on LLM utility evaluation. We demonstrate the efficacy of our PermLLM mechanisms through extensive experiments on four public datasets (GPQA, RCV1, SimpleQA, and WMDP), in addition to evaluating the validity of DDI and UGI metrics themselves for quantifying access control in LLMs.', 'abstract_zh': '在企业环境中，组织数据被隔离、独立保管并受到复杂访问控制框架的严格保护。如果针对隔离数据微调的语言模型（LLM）服务于具有不同访问权限的个体，以执行下游任务，那么这些访问控制结构可能会完全失效。我们提出了权限性语言模型（PermLLM），这是一种新的语言模型类别，其在生成查询响应时叠加组织数据的访问控制结构。我们形式化了确定访问控制是否正确应用于语言模型查询响应的方法基础。我们的形式化引入了相关响应的概念，可以用来证明PermLLM机制是否实现正确。我们还引入了一个新的度量标准——访问优势，以实证评估PermLLM机制的有效性。我们提出了三种基于参数效细调的新颖PermLLM机制，以实现所需的访问控制。此外，我们提出了两种访问优势的实现方式——基于成员推理攻击的领域区分度指数（DDI）和基于语言模型效用评估的效用差距指数（UGI）。我们通过在四个公开数据集（GPQA、RCV1、SimpleQA 和 WMDP）上的广泛实验展示了我们提出的PermLLM机制的效果，并进一步评估了DDI和UGI度量标准本身在量化语言模型中的访问控制方面的有效性。', 'title_zh': '许可大语言模型：大型语言模型中的访问控制'}
{'arxiv_id': 'arXiv:2505.22857', 'title': 'NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding', 'authors': 'Vladimir Bataev, Andrei Andrusenko, Lilit Grigoryan, Aleksandr Laptev, Vitaly Lavrukhin, Boris Ginsburg', 'link': 'https://arxiv.org/abs/2505.22857', 'abstract': 'Statistical n-gram language models are widely used for context-biasing tasks in Automatic Speech Recognition (ASR). However, existing implementations lack computational efficiency due to poor parallelization, making context-biasing less appealing for industrial use. This work rethinks data structures for statistical n-gram language models to enable fast and parallel operations for GPU-optimized inference. Our approach, named NGPU-LM, introduces customizable greedy decoding for all major ASR model types - including transducers, attention encoder-decoder models, and CTC - with less than 7% computational overhead. The proposed approach can eliminate more than 50% of the accuracy gap between greedy and beam search for out-of-domain scenarios while avoiding significant slowdown caused by beam search. The implementation of the proposed NGPU-LM is open-sourced.', 'abstract_zh': '统计n-gram语言模型在自动语音识别（ASR）中的上下文偏置任务中广泛应用。然而，现有的实现因缺少计算效率而导致并行化不足，使得上下文偏置在工业应用中不够吸引人。本文重新思考统计n-gram语言模型的数据结构，以实现GPU优化推断的快速并行操作。我们的方法NGPU-LM为包括转换器、注意力编码器-解码器模型和CTC在内的所有主要ASR模型类型引入可定制的贪婪解码，计算开销小于7%。所提出的方法可以在领域外场景中消除贪婪搜索和束搜索之间超过50%的准确率差距，同时避免了束搜索引起的显著缓慢。提出的NGPU-LM的实现已经开源。', 'title_zh': 'NGPU-LM: 基于GPU加速的N-gram语言模型用于贪婪ASR解码中的上下文偏向'}
{'arxiv_id': 'arXiv:2505.22852', 'title': 'Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment', 'authors': 'Krti Tallam, Emma Miller', 'link': 'https://arxiv.org/abs/2505.22852', 'abstract': "CaMeL (Capabilities for Machine Learning) introduces a capability-based sandbox to mitigate prompt injection attacks in large language model (LLM) agents. While effective, CaMeL assumes a trusted user prompt, omits side-channel concerns, and incurs performance tradeoffs due to its dual-LLM design. This response identifies these issues and proposes engineering improvements to expand CaMeL's threat coverage and operational usability. We introduce: (1) prompt screening for initial inputs, (2) output auditing to detect instruction leakage, (3) a tiered-risk access model to balance usability and control, and (4) a verified intermediate language for formal guarantees. Together, these upgrades align CaMeL with best practices in enterprise security and support scalable deployment.", 'abstract_zh': '基于能力的机器学习(CaMeL)扩展与优化：克服提示注入攻击并提升运营实用性', 'title_zh': 'CaMeL 的运营化：加强企业部署的LLM防御措施'}
{'arxiv_id': 'arXiv:2505.22846', 'title': 'RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation', 'authors': 'Nikita Khramov, Andrei Kozyrev, Gleb Solovev, Anton Podkopaev', 'link': 'https://arxiv.org/abs/2505.22846', 'abstract': "Interactive Theorem Proving was repeatedly shown to be fruitful combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We highlight the importance of thorough premise selection for generating Rocq proofs and propose a novel approach, leveraging retrieval via a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and show the use of multi-agent debate on the planning stage of proof synthesis.", 'abstract_zh': '交互定理证明与生成人工智能的结合屡次显示出其有效性。本文评估了多种Rocq生成方法，并阐明了改进的潜在途径。我们强调了生成Rocq证明时彻底选择前提的重要性，并提出了一种新颖的方法，利用自我注意嵌入模型进行检索。设计方法的评估显示生成器性能相对提高了28%。我们使用一种针对形式验证定制的多阶段代理系统来解决编写Rocq证明的问题，并展示了其高度有效性。我们进行了消融研究，并展示了在证明合成规划阶段使用多代理辩论的应用。', 'title_zh': 'RocqStar: 利用相似性驱动的检索和能动系统进行Rocq生成'}
{'arxiv_id': 'arXiv:2505.22845', 'title': 'Security Benefits and Side Effects of Labeling AI-Generated Images', 'authors': 'Sandra Höltervennhoff, Jonas Ricker, Maike M. Raphael, Charlotte Schwedes, Rebecca Weil, Asja Fischer, Thorsten Holz, Lea Schönherr, Sascha Fahl', 'link': 'https://arxiv.org/abs/2505.22845', 'abstract': "Generative artificial intelligence is developing rapidly, impacting humans' interaction with information and digital media. It is increasingly used to create deceptively realistic misinformation, so lawmakers have imposed regulations requiring the disclosure of AI-generated content. However, only little is known about whether these labels reduce the risks of AI-generated misinformation.\nOur work addresses this research gap. Focusing on AI-generated images, we study the implications of labels, including the possibility of mislabeling. Assuming that simplicity, transparency, and trust are likely to impact the successful adoption of such labels, we first qualitatively explore users' opinions and expectations of AI labeling using five focus groups. Second, we conduct a pre-registered online survey with over 1300 U.S. and EU participants to quantitatively assess the effect of AI labels on users' ability to recognize misinformation containing either human-made or AI-generated images. Our focus groups illustrate that, while participants have concerns about the practical implementation of labeling, they consider it helpful in identifying AI-generated images and avoiding deception. However, considering security benefits, our survey revealed an ambiguous picture, suggesting that users might over-rely on labels. While inaccurate claims supported by labeled AI-generated images were rated less credible than those with unlabeled AI-images, the belief in accurate claims also decreased when accompanied by a labeled AI-generated image. Moreover, we find the undesired side effect that human-made images conveying inaccurate claims were perceived as more credible in the presence of labels.", 'abstract_zh': '生成式人工智能正迅速发展，影响着人类与信息和数字媒体的交互方式。它被日益用于创造误导性且看似真实的虚假信息，因此立法者已制定法规要求披露AI生成的内容。然而，对于这些标签是否能减少AI生成的虚假信息的风险知之甚少。\n我们的工作弥补了这一研究空白。重点关注AI生成的图像，我们研究了标签的潜在影响，包括标签误标的可能性。假设简洁性、透明度和信任度将影响此类标签的采用，我们首先通过五个焦点小组定性探索用户对AI标记的意见和期望。其次，我们进行了预注册的在线问卷调查，涉及超过1300名美国和欧盟的参与者，以定量评估AI标签对用户识别包含人类制作或AI生成图像的虚假信息的能力的影响。我们的焦点小组显示，尽管参与者对标签的实际实施表示担忧，但他们认为标签有助于识别AI生成的图像并避免误导。然而，考虑到安全利益，我们的调查结果显示了一种模糊的图景，表明用户可能过度依赖标签。尽管带有标签的AI生成图像的支持不实声明被认为比无标签的AI图像不那么可信，但当伴随带有标签的AI生成图像时，可信准确声明的信念也会下降。此外，我们发现了一个不希望的副作用：带有标签时，传达不实声明的人类制作图像被认为更具可信度。', 'title_zh': 'AI生成图像标记的安全优势与副作用'}
{'arxiv_id': 'arXiv:2505.22843', 'title': 'Aurora: Are Android Malware Classifiers Reliable under Distribution Shift?', 'authors': 'Alexander Herzog, Aliai Eusebi, Lorenzo Cavallaro', 'link': 'https://arxiv.org/abs/2505.22843', 'abstract': 'The performance figures of modern drift-adaptive malware classifiers appear promising, but does this translate to genuine operational reliability? The standard evaluation paradigm primarily focuses on baseline performance metrics, neglecting confidence-error alignment and operational stability. While TESSERACT established the importance of temporal evaluation, we take a complementary direction by investigating whether malware classifiers maintain reliable confidence estimates under distribution shifts and exploring the tensions between scientific advancement and practical impacts when they do not. We propose AURORA, a framework to evaluate malware classifiers based on their confidence quality and operational resilience. AURORA subjects the confidence profile of a given model to verification to assess the reliability of its estimates. Unreliable confidence estimates erode operational trust, waste valuable annotation budget on non-informative samples for active learning, and leave error-prone instances undetected in selective classification. AURORA is further complemented by a set of metrics designed to go beyond point-in-time performance, striving towards a more holistic assessment of operational stability throughout temporal evaluation periods. The fragility we observe in state-of-the-art frameworks across datasets of varying drift severity suggests the need for a return to the whiteboard.', 'abstract_zh': '现代漂移适应性恶意软件分类器的性能指标看起来很有前景，但这种性能是否转化为实际操作中的可靠性能？标准的评估范式主要关注基线性能指标，忽视了置信度误差的一致性和操作稳定性。虽然TESSERACT确立了时间评价的重要性，我们则采取了补充性的方法，探讨在分布迁移的情况下恶意软件分类器是否能够维持可靠的置信度估计，并探索科学进步与实际影响之间的张力。我们提出了AURORA框架，基于置信度质量和操作弹性来评估恶意软件分类器。AURORA通过对给定模型的置信度概貌进行验证，评估其估计的可靠性。不可靠的置信度估计会削弱操作中的信任度，浪费宝贵的标注预算在非信息性的样本上进行积极学习，并在选择性分类中未能检测到错误实例。AURORA进一步通过设计用于超越单一时间点性能的指标集，力求在时间评价期间实现对操作稳定性更具综合性的评估。我们观察到最先进的框架在不同漂移严重程度数据集上的脆弱性，表明需要回到“白板”重新审视。', 'title_zh': 'aurora: Android恶意软件分类器在分布转移情况下是否可靠？'}
{'arxiv_id': 'arXiv:2505.22839', 'title': 'How Do Diffusion Models Improve Adversarial Robustness?', 'authors': 'Liu Yuezhang, Xue-Xin Wei', 'link': 'https://arxiv.org/abs/2505.22839', 'abstract': "Recent findings suggest that diffusion models significantly enhance empirical adversarial robustness. While some intuitive explanations have been proposed, the precise mechanisms underlying these improvements remain unclear. In this work, we systematically investigate how and how well diffusion models improve adversarial robustness. First, we observe that diffusion models intriguingly increase, rather than decrease, the $\\ell_p$ distance to clean samples--challenging the intuition that purification denoises inputs closer to the original data. Second, we find that the purified images are heavily influenced by the internal randomness of diffusion models, where a compression effect arises within each randomness configuration. Motivated by this observation, we evaluate robustness under fixed randomness and find that the improvement drops to approximately 24% on CIFAR-10--substantially lower than prior reports approaching 70%. Importantly, we show that this remaining robustness gain strongly correlates with the model's ability to compress the input space, revealing the compression rate as a reliable robustness indicator without requiring gradient-based analysis. Our findings provide novel insights into the mechanisms underlying diffusion-based purification, and offer guidance for developing more effective and principled adversarial purification systems.", 'abstract_zh': 'Recent findings suggest that扩散模型显著增强了经验鲁棒性。虽然提出了一些直观解释，但这些改进背后的精确机制仍不清楚。在本工作中，我们系统地探讨了扩散模型如何以及在多大程度上提高对抗鲁棒性。首先，我们发现扩散模型出乎意料地增加了与干净样本之间的$\\ell_p$距离——挑战了净化去噪会使输入更接近原始数据的直观理解。其次，我们发现净化后的图像受到扩散模型内部随机性的严重影响，在每次随机配置中都会出现压缩效应。受此观察启发，我们在固定随机性下评估鲁棒性，并发现CIFAR-10上的改进仅约为24%，显著低于接近70%的先前报告。重要的是，我们展示了这种剩余的鲁棒性增益与模型压缩输入空间的能力之间强烈相关，揭示了压缩率作为不依赖梯度分析的鲁棒性指标的可靠性。我们的发现为基于扩散的净化机制提供了新颖的见解，并为开发更有效和有原则的对抗净化系统提供了指导。', 'title_zh': '扩散模型如何提高对抗robust性？'}
{'arxiv_id': 'arXiv:2505.22831', 'title': 'Orca: Browsing at Scale Through User-Driven and AI-Facilitated Orchestration Across Malleable Webpages', 'authors': 'Peiling Jiang, Haijun Xia', 'link': 'https://arxiv.org/abs/2505.22831', 'abstract': 'Web-based activities are fundamentally distributed across webpages. However, conventional browsers with stacks of tabs fail to support operating and synthesizing large volumes of information across pages. While recent AI systems enable fully automated web browsing and information synthesis, they often diminish user agency and hinder contextual understanding. Therefore, we explore how AI could instead augment users\' interactions with content across webpages and mitigate cognitive and manual efforts. Through literature on information tasks and web browsing challenges, and an iterative design process, we present a rich set of novel interactions with our prototype web browser, Orca. Leveraging AI, Orca supports user-driven exploration, operation, organization, and synthesis of web content at scale. To enable browsing at scale, webpages are treated as malleable materials that humans and AI can collaboratively manipulate and compose into a malleable, dynamic, and browser-level workspace. Our evaluation revealed an increased "appetite" for information foraging, enhanced user control, and more flexibility in sensemaking across a broader information landscape on the web.', 'abstract_zh': '基于Web的活动本质上分布在网页上。然而，传统的浏览器通过标签页堆栈支持的方式无法有效支持在跨页面操作和综合大规模信息。虽然最近的人工智能系统可以实现全自动化网页浏览和信息综合，但往往会削弱用户自主性并妨碍情境理解。因此，我们探索了人工智能如何增强用户在跨网页内容上的互动，并减轻认知和手动努力。通过信息任务和网页浏览挑战的相关文献以及迭代设计过程，我们展示了我们的原型网页浏览器Orca中的一系列新颖交互方式。利用人工智能，Orca支持用户驱动的跨规模浏览、操作、组织和综合网页内容。为了实现大规模浏览，网页被视为人类和人工智能可以协作重塑和组合成可塑性动态浏览器级别工作区的材料。我们的评估显示了增强了信息获取的意愿、提高了用户控制力，并且在更广泛的网络信息环境中提供了更高的解释灵活性。', 'title_zh': 'Orca：通过用户驱动和AI辅助协调跨可塑网页的大规模浏览'}
{'arxiv_id': 'arXiv:2505.22830', 'title': 'What Has Been Lost with Synthetic Evaluation?', 'authors': 'Alexander Gill, Abhilasha Ravichander, Ana Marasović', 'link': 'https://arxiv.org/abs/2505.22830', 'abstract': 'Large language models (LLMs) are increasingly used for data generation. However, creating evaluation benchmarks raises the bar for this emerging paradigm. Benchmarks must target specific phenomena, penalize exploiting shortcuts, and be challenging. Through two case studies, we investigate whether LLMs can meet these demands by generating reasoning over-text benchmarks and comparing them to those created through careful crowdsourcing. Specifically, we evaluate both the validity and difficulty of LLM-generated versions of two high-quality reading comprehension datasets: CondaQA, which evaluates reasoning about negation, and DROP, which targets reasoning about quantities. We find that prompting LLMs can produce variants of these datasets that are often valid according to the annotation guidelines, at a fraction of the cost of the original crowdsourcing effort. However, we show that they are less challenging for LLMs than their human-authored counterparts. This finding sheds light on what may have been lost by generating evaluation data with LLMs, and calls for critically reassessing the immediate use of this increasingly prevalent approach to benchmark creation.', 'abstract_zh': '大型语言模型（LLMs）越来越多地用于数据生成。然而，创建评价基准提高了这一新兴范式的门槛。基准必须针对特定现象、惩罚利用捷径，并具有挑战性。通过两个案例研究，我们探讨了LLMs是否能够满足这些需求，通过生成推理过文本基准并将其与通过精心众包创建的基准进行比较来进行评估。具体来说，我们评估了LLM生成的两个高质量阅读理解数据集（CondaQA，用于评估否定推理；DROP，用于评估数量推理）的有效性和难度。我们发现，通过提示LLMs可以产生符合注释指南的有效变体，成本仅为原有人工众包努力的一小部分。然而，我们表明，这些变体对于LLMs来说不如由人类作者创建的版本具有挑战性。这一发现揭示了使用LLMs生成评价数据可能损失的内容，并提出了对这一越来越普遍的基准创建方法的即刻使用进行批判性重新评估的必要性。', 'title_zh': '合成评估中失去了什么？'}
{'arxiv_id': 'arXiv:2505.22829', 'title': 'Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies', 'authors': 'Chenruo Liu, Kenan Tang, Yao Qin, Qi Lei', 'link': 'https://arxiv.org/abs/2505.22829', 'abstract': 'This paper bridges distribution shift and AI safety through a comprehensive analysis of their conceptual and methodological synergies. While prior discussions often focus on narrow cases or informal analogies, we establish two types connections between specific causes of distribution shift and fine-grained AI safety issues: (1) methods addressing a specific shift type can help achieve corresponding safety goals, or (2) certain shifts and safety issues can be formally reduced to each other, enabling mutual adaptation of their methods. Our findings provide a unified perspective that encourages fundamental integration between distribution shift and AI safety research.', 'abstract_zh': '本文通过全面分析分布转移与AI安全的概念和方法协同作用，架起了二者的桥梁。尽管以往讨论往往集中在狭窄的案例或非正式的类比上，我们建立了两种特定分布转移原因与细粒度AI安全问题之间的连接：（1）针对特定转移类型的方法可以有助于实现相应的安全目标，或（2）某些转移和安全问题可以形式上相互归约，从而使它们的方法能够相互适应。我们的发现提供了一个统一的视角，促进分布转移与AI安全研究的根本整合。', 'title_zh': '弥合分布偏移与AI安全性之间的差距：概念与方法的协同作用'}
{'arxiv_id': 'arXiv:2505.22825', 'title': 'PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow', 'authors': 'Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck', 'link': 'https://arxiv.org/abs/2505.22825', 'abstract': 'Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have recently garnered significant attention, reflecting a broader trend of leveraging ML to approximate and/or accelerate the resolution of complex optimization problems. These developments are necessitated by the increased volatility and scale in energy production for modern and future grids. However, progress in ML for OPF is hindered by the lack of standardized datasets and evaluation metrics, from generating and solving OPF instances, to training and benchmarking machine learning models. To address this challenge, this paper introduces PGLearn, a comprehensive suite of standardized datasets and evaluation tools for ML and OPF. PGLearn provides datasets that are representative of real-life operating conditions, by explicitly capturing both global and local variability in the data generation, and by, for the first time, including time series data for several large-scale systems. In addition, it supports multiple OPF formulations, including AC, DC, and second-order cone formulations. Standardized datasets are made publicly available to democratize access to this field, reduce the burden of data generation, and enable the fair comparison of various methodologies. PGLearn also includes a robust toolkit for training, evaluating, and benchmarking machine learning models for OPF, with the goal of standardizing performance evaluation across the field. By promoting open, standardized datasets and evaluation metrics, PGLearn aims at democratizing and accelerating research and innovation in machine learning applications for optimal power flow problems. Datasets are available for download at this https URL.', 'abstract_zh': '机器学习（ML）技术在最优功率流（OPF）问题中的应用近年来引起了广泛关注，反映了更广泛的利用ML近似和/或加速解决复杂优化问题的趋势。这些进展是因为现代和未来电网中能源生产波动性和规模的增加而变得必要。然而，ML在OPF中的进展受到标准化数据集和评估指标缺乏的阻碍，从生成和解决OPF实例到训练和基准测试机器学习模型。为了解决这一挑战，本文提出了PGLearn，这是一个全面的标准化数据集和评估工具套件，用于ML和OPF。PGLearn提供的数据集代表了现实运行条件，通过明确捕捉数据生成中的全局和局部变异性，并首次包括多个大型系统的时间序列数据，从而支持多种OPF公制，包括AC、DC和二阶锥公制。标准化数据集对公众开放，旨在普及该领域的访问权，减轻数据生成的负担，并enable多种方法的公平比较。PGLearn还包含一个用于训练、评估和基准测试OPF机器学习模型的稳健工具包，旨在标准化领域内的性能评估。通过推广开放和标准化的数据集和评估指标，PGLearn旨在促进和加速最优功率流问题中机器学习应用的研究与创新。数据集可在此链接下载：这个 https URL。', 'title_zh': 'PGLearn -- 一种开源最优功率 flow 学习工具包'}
{'arxiv_id': 'arXiv:2505.22818', 'title': 'A Tool for Generating Exceptional Behavior Tests With Large Language Models', 'authors': 'Linghan Zhong, Samuel Yuan, Jiyang Zhang, Yu Liu, Pengyu Nie, Junyi Jessy Li, Milos Gligoric', 'link': 'https://arxiv.org/abs/2505.22818', 'abstract': 'Exceptional behavior tests (EBTs) are crucial in software development for verifying that code correctly handles unwanted events and throws appropriate exceptions. However, prior research has shown that developers often prioritize testing "happy paths", e.g., paths without unwanted events over exceptional scenarios. We present exLong, a framework that automatically generates EBTs to address this gap. exLong leverages a large language model (LLM) fine-tuned from CodeLlama and incorporates reasoning about exception-throwing traces, conditional expressions that guard throw statements, and non-exceptional behavior tests that execute similar traces. Our demonstration video illustrates how exLong can effectively assist developers in creating comprehensive EBTs for their project (available at this https URL).', 'abstract_zh': '异常行为测试(exLong框架): 自动生成异常场景测试以弥补开发者的不足', 'title_zh': '一种生成异常行为测试的方法，利用大规模语言模型'}
{'arxiv_id': 'arXiv:2505.22815', 'title': 'IMTS is Worth Time $\\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction', 'authors': 'Zhangyi Hu, Jiemin Wu, Hua Xu, Mingqian Liao, Ninghui Feng, Bo Gao, Songning Lai, Yutao Yue', 'link': 'https://arxiv.org/abs/2505.22815', 'abstract': "Irregular Multivariate Time Series (IMTS) forecasting is challenging due to the unaligned nature of multi-channel signals and the prevalence of extensive missing data. Existing methods struggle to capture reliable temporal patterns from such data due to significant missing values. While pre-trained foundation models show potential for addressing these challenges, they are typically designed for Regularly Sampled Time Series (RTS). Motivated by the visual Mask AutoEncoder's (MAE) powerful capability for modeling sparse multi-channel information and its success in RTS forecasting, we propose VIMTS, a framework adapting Visual MAE for IMTS forecasting. To mitigate the effect of missing values, VIMTS first processes IMTS along the timeline into feature patches at equal intervals. These patches are then complemented using learned cross-channel dependencies. Then it leverages visual MAE's capability in handling sparse multichannel data for patch reconstruction, followed by a coarse-to-fine technique to generate precise predictions from focused contexts. In addition, we integrate self-supervised learning for improved IMTS modeling by adapting the visual MAE to IMTS data. Extensive experiments demonstrate VIMTS's superior performance and few-shot capability, advancing the application of visual foundation models in more general time series tasks. Our code is available at this https URL.", 'abstract_zh': '不规则多变量时间序列（IMTS）的预测因多通道信号的不齐和平坦数据的普遍存在而具有挑战性。现有的方法难以捕捉此类数据中的可靠时间模式，因为存在大量的缺失值。虽然预训练的基础模型具有解决这些挑战的潜力，但它们通常设计用于规则采样时间序列（RTS）。受视觉Mask AutoEncoder（MAE）对稀疏多通道信息建模的强大能力及其在RTS预测中的成功启发，我们提出了一种VIMTS框架，该框架将视觉MAE适应于IMTS预测。为了减轻缺失值的影响，VIMTS首先按时间间隔将IMTS处理为等间隔的特征.patch。然后，通过学习的跨通道依赖性来补充这些.patch。接下来，利用视觉MAE处理稀疏多通道数据的能力来进行.patch重建，并通过从集中上下文中生成精确预测的粗到细技术。此外，我们通过将视觉MAE适应IMTS数据来整合自监督学习，以改进IMTS建模。广泛的实验表明，VIMTS具有优越的性能和少样本能力，推动了视觉基础模型在更多一般时间序列任务中的应用。我们的代码可在以下网址获取。', 'title_zh': 'IMTS 值得时间 $\\times$ 通道 patches：视觉掩蔽自编码器在不规则多元时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2505.22814', 'title': 'A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems', 'authors': 'Jonghan Lim, Ilya Kovalenko', 'link': 'https://arxiv.org/abs/2505.22814', 'abstract': 'Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.', 'abstract_zh': '制造环境因需求变化和产品生命周期缩短等因素变得更加复杂和不可预测，这要求进行实时决策和适应性调整。传统的控制方法强调需要先进的控制策略来克服突发挑战，因为它们在动态工业环境中的响应性存在局限性。多Agent系统通过分散决策解决了这些挑战，使系统能够动态响应运营变化。然而，当前的多Agent系统在实时适应、情境感知决策和动态探索资源能力方面仍面临挑战。大型语言模型通过提供情境感知决策能力，有可能克服这些局限性。本文介绍了一种基于大型语言模型的控制架构，以动态探索资源能力并响应实时干扰。基于仿真的案例研究表明，所提出的架构提高了系统的弹性和灵活性。案例研究结果表明，与现有方法相比，系统的吞吐量和资源利用效率有所提高。', 'title_zh': '大型语言模型-enable的控制架构：多代理制造系统中的动态资源能力探索'}
{'arxiv_id': 'arXiv:2505.22809', 'title': 'First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay', 'authors': 'Andrew Zhu, Evan Osgood, Chris Callison-Burch', 'link': 'https://arxiv.org/abs/2505.22809', 'abstract': 'Much work has been done on conversational LLM agents which directly assist human users with tasks. We present an alternative paradigm for interacting with LLM agents, which we call "overhearing agents". These overhearing agents do not actively participate in conversation -- instead, they "listen in" on human-to-human conversations and perform background tasks or provide suggestions to assist the user. In this work, we explore the overhearing agents paradigm through the lens of Dungeons & Dragons gameplay. We present an in-depth study using large multimodal audio-language models as overhearing agents to assist a Dungeon Master. We perform a human evaluation to examine the helpfulness of such agents and find that some large audio-language models have the emergent ability to perform overhearing agent tasks using implicit audio cues. Finally, we release Python libraries and our project code to support further research into the overhearing agents paradigm at this https URL.', 'abstract_zh': '基于龙与地下城 gameplay 的监听代理探索：使用大规模多模态音频-语言模型辅助游戏大师', 'title_zh': '朝着监听LLM代理迈出的第一步：以《龙与地下城》游戏为例的研究'}
{'arxiv_id': 'arXiv:2505.22803', 'title': 'CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment', 'authors': 'Pedro Mendes, Paolo Romano, David Garlan', 'link': 'https://arxiv.org/abs/2505.22803', 'abstract': 'Reliable uncertainty estimation is critical for deploying neural networks (NNs) in real-world applications. While existing calibration techniques often rely on post-hoc adjustments or coarse-grained binning methods, they remain limited in scalability, differentiability, and generalization across domains. In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error Alignment), a novel approach that explicitly aligns predicted uncertainty with observed error during training, grounded in the principle that well-calibrated models should produce uncertainty estimates that match their empirical loss. CLUE adopts a novel loss function that jointly optimizes predictive performance and calibration, using summary statistics of uncertainty and loss as proxies. The proposed method is fully differentiable, domain-agnostic, and compatible with standard training pipelines. Through extensive experiments on vision, regression, and language modeling tasks, including out-of-distribution and domain-shift scenarios, we demonstrate that CLUE achieves superior calibration quality and competitive predictive performance with respect to state-of-the-art approaches without imposing significant computational overhead.', 'abstract_zh': '可靠的不确定性估计对于在实际应用中部署神经网络至关重要。现有校准技术往往依赖于事后调整或粗粒度的分箱方法，但在可扩展性、可微性和跨域泛化能力方面仍有限制。在本文中，我们提出了CLUE（基于学习不确定性-误差对齐的校准方法），这是一种新型方法，在训练过程中显式地将预测的不确定性与观测到的误差对齐，其原理是校准良好的模型应该产生与实际损失相匹配的不确定性估计。CLUE采用了一种新的损失函数，该函数同时优化预测性能和校准，使用不确定性与损失的汇总统计数据作为代理。所提出的方法是完全可微的、领域无关的，并且与标准训练管道兼容。通过在视觉、回归和语言建模任务上的广泛实验，包括分布外和域迁移场景，我们证明了CLUE在相对于最新方法的校准质量方面表现优异，并在预测性能方面表现竞争力，而不会增加显著的计算开销。', 'title_zh': 'CLUE: 通过学习不确定性-误差对齐进行神经网络校准'}
{'arxiv_id': 'arXiv:2505.22798', 'title': 'Efficient Preimage Approximation for Neural Network Certification', 'authors': 'Anton Björklund, Mykola Zaitsev, Marta Kwiatkowska', 'link': 'https://arxiv.org/abs/2505.22798', 'abstract': "The growing reliance on artificial intelligence in safety- and security-critical applications demands effective neural network certification. A challenging real-world use case is certification against ``patch attacks'', where adversarial patches or lighting conditions obscure parts of images, for example traffic signs. One approach to certification, which also gives quantitative coverage estimates, utilizes preimages of neural networks, i.e., the set of inputs that lead to a specified output. However, these preimage approximation methods, including the state-of-the-art PREMAP algorithm, struggle with scalability. This paper presents novel algorithmic improvements to PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved branching heuristics. We demonstrate efficiency improvements of at least an order of magnitude on reinforcement learning control benchmarks, and show that our method scales to convolutional neural networks that were previously infeasible. Our results demonstrate the potential of preimage approximation methodology for reliability and robustness certification.", 'abstract_zh': '人工智能在安全和安全关键应用中的日益依赖 demands 有效神经网络认证。一种具有挑战性的实际应用场景是对抗“补丁攻击”的认证，即恶意补丁或光照条件模糊图像的部分内容，例如交通标志。一种认证方法不仅提供了定量的覆盖率估计，还利用了神经网络的预象，即导致指定输出的输入集合。然而，这些预象近似方法，包括最先进的PREMAP算法，面临可扩展性问题。本文提出了对PREMAP的新算法改进，涉及更紧的边界、自适应蒙特卡罗采样和改进的分支启发式方法。我们在强化学习控制基准上展示了至少一个数量级的效率提升，并证明了我们的方法能够扩展到之前不可行的卷积神经网络。我们的结果展示了预象近似方法在可靠性和鲁棒性认证中的潜力。', 'title_zh': '神经网络认证的高效前image近似算法'}
{'arxiv_id': 'arXiv:2505.22771', 'title': 'Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems', 'authors': 'Christopher Ormerod', 'link': 'https://arxiv.org/abs/2505.22771', 'abstract': 'This study illustrates how incorporating feedback-oriented annotations into the scoring pipeline can enhance the accuracy of automated essay scoring (AES). This approach is demonstrated with the Persuasive Essays for Rating, Selecting, and Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We integrate two types of feedback-driven annotations: those that identify spelling and grammatical errors, and those that highlight argumentative components. To illustrate how this method could be applied in real-world scenarios, we employ two LLMs to generate annotations -- a generative language model used for spell-correction and an encoder-based token classifier trained to identify and mark argumentative elements. By incorporating annotations into the scoring process, we demonstrate improvements in performance using encoder-based large language models fine-tuned as classifiers.', 'abstract_zh': '本研究展示了将反馈导向的标注集成到评分管道中如何提高自动化作文评分（AES）的准确性。该方法通过使用PERSUADE语料库进行展示。我们集成两种类型的反馈驱动标注：识别拼写和语法错误的标注，以及突出显示论证成分的标注。为了说明这种方法在实际场景中的应用，我们使用了两种LLM生成标注——一个用于拼写修正的生成语言模型，另一个是基于编码器的标记分类器，用于识别和标记论证成分。通过将标注集成到评分过程中，我们展示了如何使用基于编码器的大语言模型进行微调，以提高分类性能。', 'title_zh': '自动作文评分结合自动反馈系统的注解'}
{'arxiv_id': 'arXiv:2505.22767', 'title': 'In Dialogue with Intelligence: Rethinking Large Language Models as Collective Knowledge', 'authors': 'Eleni Vasilaki', 'link': 'https://arxiv.org/abs/2505.22767', 'abstract': 'Large Language Models (LLMs) are typically analysed through architectural, behavioural, or training-data lenses. This article offers a theoretical and experiential re-framing: LLMs as dynamic instantiations of Collective human Knowledge (CK), where intelligence is evoked through dialogue rather than stored statically. Drawing on concepts from neuroscience and AI, and grounded in sustained interaction with ChatGPT-4, I examine emergent dialogue patterns, the implications of fine-tuning, and the notion of co-augmentation: mutual enhancement between human and machine cognition. This perspective offers a new lens for understanding interaction, representation, and agency in contemporary AI systems.', 'abstract_zh': '大型语言模型（LLMs）通常从架构、行为或训练数据的角度进行分析。本文提供了一种理论和经验上的重新诠释：将LLMs视为集体人类知识（CK）的动态实例化，其中智能通过对话而非静态存储被唤起。借助神经科学和AI的概念，并基于与ChatGPT-4的长期互动，本文探讨了涌现对话模式、微调的影响以及共增强的概念：人类和机器认知的相互增强。这种视角为理解当代AI系统的交互、表示和代理提供了新的视角。', 'title_zh': '与智能对话：重新思考大型语言模型作为集体知识'}
{'arxiv_id': 'arXiv:2505.22762', 'title': 'MIAS-SAM: Medical Image Anomaly Segmentation without thresholding', 'authors': 'Marco Colussi, Dragan Ahmetovic, Sergio Mascetti', 'link': 'https://arxiv.org/abs/2505.22762', 'abstract': 'This paper presents MIAS-SAM, a novel approach for the segmentation of anomalous regions in medical images. MIAS-SAM uses a patch-based memory bank to store relevant image features, which are extracted from normal data using the SAM encoder. At inference time, the embedding patches extracted from the SAM encoder are compared with those in the memory bank to obtain the anomaly map. Finally, MIAS-SAM computes the center of gravity of the anomaly map to prompt the SAM decoder, obtaining an accurate segmentation from the previously extracted features. Differently from prior works, MIAS-SAM does not require to define a threshold value to obtain the segmentation from the anomaly map. Experimental results conducted on three publicly available datasets, each with a different imaging modality (Brain MRI, Liver CT, and Retina OCT) show accurate anomaly segmentation capabilities measured using DICE score. The code is available at: this https URL', 'abstract_zh': 'MIAS-SAM：一种用于医学图像异常区域分割的新型方法', 'title_zh': 'MIAS-SAM: 医学图像异常分割 without 阈值")));'}
{'arxiv_id': 'arXiv:2505.22761', 'title': 'A comprehensive analysis of PINNs: Variants, Applications, and Challenges', 'authors': 'Afila Ajithkumar Sophiya, Akarsh K Nair, Sepehr Maleki, Senthil K. Krishnababu', 'link': 'https://arxiv.org/abs/2505.22761', 'abstract': 'Physics Informed Neural Networks (PINNs) have been emerging as a powerful computational tool for solving differential equations. However, the applicability of these models is still in its initial stages and requires more standardization to gain wider popularity. Through this survey, we present a comprehensive overview of PINNs approaches exploring various aspects related to their architecture, variants, areas of application, real-world use cases, challenges, and so on. Even though existing surveys can be identified, they fail to provide a comprehensive view as they primarily focus on either different application scenarios or limit their study to a superficial level. This survey attempts to bridge the gap in the existing literature by presenting a detailed analysis of all these factors combined with recent advancements and state-of-the-art research in PINNs. Additionally, we discuss prevalent challenges in PINNs implementation and present some of the future research directions as well. The overall contributions of the survey can be summarised into three sections: A detailed overview of PINNs architecture and variants, a performance analysis of PINNs on different equations and application domains highlighting their features. Finally, we present a detailed discussion of current issues and future research directions.', 'abstract_zh': 'Physics Informed Neural Networks (PINNs)作为一种求解微分方程的强大计算工具正在兴起。然而，这些模型的应用尚处于初期阶段，需要更多的标准化才能获得更广泛的认可。通过这篇综述，我们提供了关于PINNs的各种架构、变体、应用领域、实际应用场景、挑战等方面的全面概述，试图填补现有文献中的空白，结合最近的进展和最新的研究进行详细分析。此外，我们讨论了PINNs实现中普遍存在的挑战，并提出了未来研究方向。综述的主要贡献可以总结为三个方面：详细概述PINNs的架构和变体，对PINNs在不同方程和应用领域的性能进行分析，最后详细讨论当前问题和未来的研究方向。', 'title_zh': 'PINNs的综合分析：变体、应用与挑战'}
{'arxiv_id': 'arXiv:2505.22759', 'title': 'FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian', 'authors': 'Sara Papi, Marco Gaido, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri', 'link': 'https://arxiv.org/abs/2505.22759', 'abstract': 'The development of speech foundation models (SFMs) like Whisper and SeamlessM4T has significantly advanced the field of speech processing. However, their closed nature--with inaccessible training data and code--poses major reproducibility and fair evaluation challenges. While other domains have made substantial progress toward open science by developing fully transparent models trained on open-source (OS) code and data, similar efforts in speech remain limited. To fill this gap, we introduce FAMA, the first family of open science SFMs for English and Italian, trained on 150k+ hours of OS speech data. Moreover, we present a new dataset containing 16k hours of cleaned and pseudo-labeled speech for both languages. Results show that FAMA achieves competitive performance compared to existing SFMs while being up to 8 times faster. All artifacts, including code, datasets, and models, are released under OS-compliant licenses, promoting openness in speech technology research.', 'abstract_zh': '开放科学声学基础模型FAMA的发展：面向英语和意大利语的150K+小时开源声学数据训练模型', 'title_zh': 'FAMA: 首个大规模开放科学语音基础模型（英语和意大利语）'}
{'arxiv_id': 'arXiv:2505.22757', 'title': 'Pre-Training Curriculum for Multi-Token Prediction in Language Models', 'authors': 'Ansar Aynetdinov, Alan Akbik', 'link': 'https://arxiv.org/abs/2505.22757', 'abstract': 'Multi-token prediction (MTP) is a recently proposed pre-training objective for language models. Rather than predicting only the next token (NTP), MTP predicts the next $k$ tokens at each prediction step, using multiple prediction heads. MTP has shown promise in improving downstream performance, inference speed, and training efficiency, particularly for large models. However, prior work has shown that smaller language models (SLMs) struggle with the MTP objective. To address this, we propose a curriculum learning strategy for MTP training, exploring two variants: a forward curriculum, which gradually increases the complexity of the pre-training objective from NTP to MTP, and a reverse curriculum, which does the opposite. Our experiments show that the forward curriculum enables SLMs to better leverage the MTP objective during pre-training, improving downstream NTP performance and generative output quality, while retaining the benefits of self-speculative decoding. The reverse curriculum achieves stronger NTP performance and output quality, but fails to provide any self-speculative decoding benefits.', 'abstract_zh': '多令牌预测（MTP）是一种最近提出的语言模型预训练目标。与只预测下一个令牌（NTP）不同，MTP 在每次预测步骤中使用多个预测头预测接下来的 $k$ 个令牌。MTP 在提升下游性能、推理速度和训练效率方面显示出潜力，特别是在大型模型中。然而，先前的工作表明，较小的语言模型（SLMs）在面对 MTP 目标时存在困难。为此，我们提出了一种用于 MTP 训练的课程学习策略，探索了两种变体：一种是前向课程，逐步从 NTP 到 MTP 增加预训练目标的复杂性；另一种是反向课程，相反地从 MTP 到 NTP 减少预训练目标的复杂性。我们的实验表明，前向课程使 SLMs 在预训练期间更好地利用 MTP 目标，提升下游 NTP 性能和生成输出的质量，同时保留自推测性解码的优势。反向课程虽然在 NTP 性能和输出质量方面表现更佳，但仍未能提供自推测性解码的优势。', 'title_zh': '多令牌预测的预训练课程设计'}
{'arxiv_id': 'arXiv:2505.22749', 'title': 'Self-orthogonalizing attractor neural networks emerging from the free energy principle', 'authors': 'Tamas Spisak, Karl Friston', 'link': 'https://arxiv.org/abs/2505.22749', 'abstract': 'Attractor dynamics are a hallmark of many complex systems, including the brain. Understanding how such self-organizing dynamics emerge from first principles is crucial for advancing our understanding of neuronal computations and the design of artificial intelligence systems. Here we formalize how attractor networks emerge from the free energy principle applied to a universal partitioning of random dynamical systems. Our approach obviates the need for explicitly imposed learning and inference rules and identifies emergent, but efficient and biologically plausible inference and learning dynamics for such self-organizing systems. These result in a collective, multi-level Bayesian active inference process. Attractors on the free energy landscape encode prior beliefs; inference integrates sensory data into posterior beliefs; and learning fine-tunes couplings to minimize long-term surprise. Analytically and via simulations, we establish that the proposed networks favor approximately orthogonalized attractor representations, a consequence of simultaneously optimizing predictive accuracy and model complexity. These attractors efficiently span the input subspace, enhancing generalization and the mutual information between hidden causes and observable effects. Furthermore, while random data presentation leads to symmetric and sparse couplings, sequential data fosters asymmetric couplings and non-equilibrium steady-state dynamics, offering a natural extension to conventional Boltzmann Machines. Our findings offer a unifying theory of self-organizing attractor networks, providing novel insights for AI and neuroscience.', 'abstract_zh': '自由能量原则应用于随机动力系统通用划分后的吸引子网络是如何涌现的：一种集体的多级贝叶斯主动推断过程', 'title_zh': '自由能原理涌现的自正交吸引子神经网络'}
{'arxiv_id': 'arXiv:2505.22704', 'title': 'Training Language Models to Generate Quality Code with Program Analysis Feedback', 'authors': 'Feng Yao, Zilong Wang, Liyuan Liu, Junxia Cui, Li Zhong, Xiaohan Fu, Haohui Mai, Vish Krishnan, Jianfeng Gao, Jingbo Shang', 'link': 'https://arxiv.org/abs/2505.22704', 'abstract': 'Code generation with large language models (LLMs), often termed vibe coding, is increasingly adopted in production but fails to ensure code quality, particularly in security (e.g., SQL injection vulnerabilities) and maintainability (e.g., missing type annotations). Existing methods, such as supervised fine-tuning and rule-based post-processing, rely on labor-intensive annotations or brittle heuristics, limiting their scalability and effectiveness. We propose REAL, a reinforcement learning framework that incentivizes LLMs to generate production-quality code using program analysis-guided feedback. Specifically, REAL integrates two automated signals: (1) program analysis detecting security or maintainability defects and (2) unit tests ensuring functional correctness. Unlike prior work, our framework is prompt-agnostic and reference-free, enabling scalable supervision without manual intervention. Experiments across multiple datasets and model scales demonstrate that REAL outperforms state-of-the-art methods in simultaneous assessments of functionality and code quality. Our work bridges the gap between rapid prototyping and production-ready code, enabling LLMs to deliver both speed and quality.', 'abstract_zh': '使用大型语言模型进行代码生成（称为vibe coding）在生产环境中日趋普及，但难以确保代码质量，特别是在安全性（如SQL注入漏洞）和可维护性（如缺少类型注解）方面。现有的方法，如监督微调和基于规则的后处理，依赖于劳动密集型的标注或脆弱的启发式方法，限制了其可扩展性和有效性。我们提出了一种名为REAL的强化学习框架，该框架利用程序分析指导的反馈激励大型语言模型生成生产质量的代码。具体而言，REAL 整合了两种自动化信号：（1）程序分析检测安全或可维护性缺陷，（2）单元测试确保功能正确性。与先前工作不同，我们的框架对提示和参考文献无依赖，从而无需手动干预即可实现可扩展的监督。实验结果表明，REAL 在功能性和代码质量的综合评估中优于现有最先进的方法。我们的工作填补了快速原型设计与生产就绪代码之间的差距，使大型语言模型能够同时提供速度和质量。', 'title_zh': '训练语言模型以通过程序分析反馈生成高质量代码'}
{'arxiv_id': 'arXiv:2505.22685', 'title': 'DeepMultiConnectome: Deep Multi-Task Prediction of Structural Connectomes Directly from Diffusion MRI Tractography', 'authors': "Marcus J. Vroemen, Yuqian Chen, Yui Lo, Tengfei Xu, Weidong Cai, Fan Zhang, Josien P.W. Pluim, Lauren J. O'Donnell", 'link': 'https://arxiv.org/abs/2505.22685', 'abstract': 'Diffusion MRI (dMRI) tractography enables in vivo mapping of brain structural connections, but traditional connectome generation is time-consuming and requires gray matter parcellation, posing challenges for large-scale studies. We introduce DeepMultiConnectome, a deep-learning model that predicts structural connectomes directly from tractography, bypassing the need for gray matter parcellation while supporting multiple parcellation schemes. Using a point-cloud-based neural network with multi-task learning, the model classifies streamlines according to their connected regions across two parcellation schemes, sharing a learned representation. We train and validate DeepMultiConnectome on tractography from the Human Connectome Project Young Adult dataset ($n = 1000$), labeled with an 84 and 164 region gray matter parcellation scheme. DeepMultiConnectome predicts multiple structural connectomes from a whole-brain tractogram containing 3 million streamlines in approximately 40 seconds. DeepMultiConnectome is evaluated by comparing predicted connectomes with traditional connectomes generated using the conventional method of labeling streamlines using a gray matter parcellation. The predicted connectomes are highly correlated with traditionally generated connectomes ($r = 0.992$ for an 84-region scheme; $r = 0.986$ for a 164-region scheme) and largely preserve network properties. A test-retest analysis of DeepMultiConnectome demonstrates reproducibility comparable to traditionally generated connectomes. The predicted connectomes perform similarly to traditionally generated connectomes in predicting age and cognitive function. Overall, DeepMultiConnectome provides a scalable, fast model for generating subject-specific connectomes across multiple parcellation schemes.', 'abstract_zh': 'DeepLearning驱动的多分割方案脑连接组预测模型', 'title_zh': 'DeepMultiConnectome: 直接从扩散MRI追踪图预测结构连接组的深度多任务学习'}
{'arxiv_id': 'arXiv:2505.22683', 'title': 'ConnectomeDiffuser: Generative AI Enables Brain Network Construction from Diffusion Tensor Imaging', 'authors': 'Xuhang Chen, Michael Kwok-Po Ng, Kim-Fung Tsang, Chi-Man Pun, Shuqiang Wang', 'link': 'https://arxiv.org/abs/2505.22683', 'abstract': "Brain network analysis plays a crucial role in diagnosing and monitoring neurodegenerative disorders such as Alzheimer's disease (AD). Existing approaches for constructing structural brain networks from diffusion tensor imaging (DTI) often rely on specialized toolkits that suffer from inherent limitations: operator subjectivity, labor-intensive workflows, and restricted capacity to capture complex topological features and disease-specific biomarkers. To overcome these challenges and advance computational neuroimaging instrumentation, ConnectomeDiffuser is proposed as a novel diffusion-based framework for automated end-to-end brain network construction from DTI. The proposed model combines three key components: (1) a Template Network that extracts topological features from 3D DTI scans using Riemannian geometric principles, (2) a diffusion model that generates comprehensive brain networks with enhanced topological fidelity, and (3) a Graph Convolutional Network classifier that incorporates disease-specific markers to improve diagnostic accuracy. ConnectomeDiffuser demonstrates superior performance by capturing a broader range of structural connectivity and pathology-related information, enabling more sensitive analysis of individual variations in brain networks. Experimental validation on datasets representing two distinct neurodegenerative conditions demonstrates significant performance improvements over other brain network methods. This work contributes to the advancement of instrumentation in the context of neurological disorders, providing clinicians and researchers with a robust, generalizable measurement framework that facilitates more accurate diagnosis, deeper mechanistic understanding, and improved therapeutic monitoring of neurodegenerative diseases such as AD.", 'abstract_zh': '脑网络分析在诊断和监测阿尔茨海默病等神经退行性疾病中发挥着重要作用。现有的基于扩散张量成像(DTI)构建结构脑网络的方法通常依赖于专门的工具包，这些工具包存在固有的局限性：操作者的主观性、劳动密集型的工作流程以及捕获复杂拓扑特征和疾病特异性生物标志物的限制能力。为了克服这些挑战并推动计算神经影像学仪器的进步，提出了一种新的基于扩散的框架ConnectomeDiffuser，用于从DTI自动端到端构建脑网络。该提出的模型结合了三个关键组件：（1）模板网络，使用黎曼几何原理从3D DTI扫描中提取拓扑特征；（2）扩散模型，生成具有增强拓扑保真度的全面脑网络；（3）图卷积网络分类器，整合疾病特异性标记以提高诊断准确性。ConnectomeDiffuser通过捕获更广泛的结构连接性和与病理相关的信息，展示了优越的性能，使个体脑网络的分析更为敏感。在代表两种不同神经退行性疾病的数据库上的实验验证表明，与其他脑网络方法相比，其性能有了显著提升。该工作为神经退行性疾病背景下仪器的发展做出了贡献，为临床医生和研究人员提供了一种稳健且可泛化的测量框架，促进更准确的诊断、更深入的机制理解和更有效的神经退行性疾病如阿尔茨海默病的治疗监测。', 'title_zh': 'ConnectomeDiffuser: 生成式AI使弥散张量成像下的脑网络构建成为可能'}
{'arxiv_id': 'arXiv:2505.22674', 'title': 'PSBench: a large-scale benchmark for estimating the accuracy of protein complex structural models', 'authors': 'Pawan Neupane, Jian Liu, Jianlin Cheng', 'link': 'https://arxiv.org/abs/2505.22674', 'abstract': "Predicting protein complex structures is essential for protein function analysis, protein design, and drug discovery. While AI methods like AlphaFold can predict accurate structural models for many protein complexes, reliably estimating the quality of these predicted models (estimation of model accuracy, or EMA) for model ranking and selection remains a major challenge. A key barrier to developing effective machine learning-based EMA methods is the lack of large, diverse, and well-annotated datasets for training and evaluation. To address this gap, we introduce PSBench, a benchmark suite comprising four large-scale, labeled datasets generated during the 15th and 16th community-wide Critical Assessment of Protein Structure Prediction (CASP15 and CASP16). PSBench includes over one million structural models covering a wide range of protein sequence lengths, complex stoichiometries, functional classes, and modeling difficulties. Each model is annotated with multiple complementary quality scores at the global, local, and interface levels. PSBench also provides multiple evaluation metrics and baseline EMA methods to facilitate rigorous comparisons. To demonstrate PSBench's utility, we trained and evaluated GATE, a graph transformer-based EMA method, on the CASP15 data. GATE was blindly tested in CASP16 (2024), where it ranked among the top-performing EMA methods. These results highlight PSBench as a valuable resource for advancing EMA research in protein complex modeling. PSBench is publicly available at: this https URL.", 'abstract_zh': '预测蛋白质复合体结构对于蛋白质功能分析、蛋白质设计和药物发现至关重要。虽然像AlphaFold这样的AI方法可以为许多蛋白质复合体预测准确的结构模型，但对于这些预测模型的质量评估（模型准确性评估，EMA）以进行模型排名和选择仍然是一个主要挑战。由于缺乏大规模、多样化和注释良好的数据集用于训练和评估，开发有效的基于机器学习的EMA方法面临障碍。为此，我们引入了PSBench，这是一个基准套件，包含四个在第15届和第16届全面性蛋白质结构预测关键评估（CASP15和CASP16）期间生成的大规模、标注数据集。PSBench涵盖了从蛋白质序列长度、复合体组成、功能类别到建模难度等一系列广泛范围的超过一百万个结构模型，并为每个模型标注了多个层次的质量评分。PSBench还提供了多种评估指标和基线EMA方法，以促进严格比较。为了证明PSBench的实用性，我们在CASP15数据上训练和评估了基于图形变换器的EMA方法GATE，并在CASP16（2024）中盲测，GATE在EMA方法中排名靠前。这些结果突显了PSBench作为蛋白质复合体建模中EMA研究有价值的资源作用。PSBench已公开可用：this https URL。', 'title_zh': 'PSBench：用于评估蛋白质复合物结构模型准确性的大规模基准'}
{'arxiv_id': 'arXiv:2505.22673', 'title': 'Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion', 'authors': 'Wasif Khan, Kyle B. See, Simon Kato, Ziqian Huang, Amy Lazarte, Kyle Douglas, Xiangyang Lou, Teng J. Peng, Dhanashree Rajderkar, John Rees, Pina Sanelli, Amita Singh, Ibrahim Tuna, Christina A. Wilson, Ruogu Fang', 'link': 'https://arxiv.org/abs/2505.22673', 'abstract': "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.", 'abstract_zh': '多任务自动生成多模态CT灌注图的深度学习框架（MAGIC）：实现无对比剂的灌注成像', 'title_zh': '基于生理学指导的生成多任务网络：无对比剂CT灌注成像'}
