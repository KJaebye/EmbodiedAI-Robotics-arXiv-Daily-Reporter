{'arxiv_id': 'arXiv:2506.04210', 'title': 'Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models', 'authors': 'Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Yifu Lu, Mengdi Wang, Dinesh Manocha, Furong Huang, Mohammad Ghavamzadeh, Amrit Singh Bedi', 'link': 'https://arxiv.org/abs/2506.04210', 'abstract': 'Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek R1) have led to a popular belief that extending thinking traces using prompts like "Wait" or "Let me rethink" can improve performance. This raises a natural question: Does thinking more at test-time truly lead to better reasoning? To answer this question, we perform a detailed empirical study across models and benchmarks, which reveals a consistent pattern of initial performance improvements from additional thinking followed by a decline, due to "overthinking". To understand this non-monotonic trend, we consider a simple probabilistic model, which reveals that additional thinking increases output variance-creating an illusion of improved reasoning while ultimately undermining precision. Thus, observed gains from "more thinking" are not true indicators of improved reasoning, but artifacts stemming from the connection between model uncertainty and evaluation metric. This suggests that test-time scaling through extended thinking is not an effective way to utilize the inference thinking budget. Recognizing these limitations, we introduce an alternative test-time scaling approach, parallel thinking, inspired by Best-of-N sampling. Our method generates multiple independent reasoning paths within the same inference budget and selects the most consistent response via majority vote, achieving up to 20% higher accuracy compared to extended thinking. This provides a simple yet effective mechanism for test-time scaling of reasoning models.', 'abstract_zh': 'Recent trends in 测试时扩展推理模型（例如OpenAI o1、DeepSeek R1）的最新进展导致一种普遍 belief 认为，使用“等待”或“让我重新思考”等提示扩展思考轨迹可以提高性能。这引发了一个自然问题：测试时更多的思考真的能提高推理能力吗？为了回答这个问题，我们在不同模型和基准上进行了详细的实证研究，揭示了初始性能提高后随后下降的一致模式，原因是“过度思考”。为了理解这一非单调趋势，我们考虑了一个简单的概率模型，揭示了额外思考增加了输出的变异性——创造出改进推理的错觉，实际上却削弱了精度。因此，“更多思考”所观察到的收益并不是改进推理的真实指标，而是源自模型不确定性与评估指标之间的联系。这表明通过扩展思考进行测试时扩展推理模型的推理预算并不是一种有效的方法。认识这些局限性，我们引入了一种替代的测试时扩展方法，即并行思考，灵感来自于Best-of-N采样方法。该方法在相同的推理预算内生成多个独立的推理路径，并通过多数投票选择最一致的响应，相较于扩展思考，可以实现高达20%的更高准确率。这提供了一种简单而有效的测试时扩展推理模型的方法。', 'title_zh': '思考更多always有助于提高吗？理解推理模型的测试时缩放问题'}
{'arxiv_id': 'arXiv:2506.04135', 'title': 'macOSWorld: A Multilingual Interactive Benchmark for GUI Agents', 'authors': 'Pei Yang, Hai Ci, Mike Zheng Shou', 'link': 'https://arxiv.org/abs/2506.04135', 'abstract': 'Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30% success rate, while open-source lightweight research models lag at below 2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 27.5% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. macOSWorld is available at this https URL.', 'abstract_zh': 'macOSWorld: 针对 macOS 的首个全面图形用户界面代理基准', 'title_zh': 'macOS世界：多语言交互基准测试用于GUI代理'}
{'arxiv_id': 'arXiv:2506.04133', 'title': 'TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems', 'authors': 'Shaina Raza, Ranjan Sapkota, Manoj Karkee, Christos Emmanouilidis', 'link': 'https://arxiv.org/abs/2506.04133', 'abstract': 'Agentic AI systems, built on large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligent autonomy, collaboration and decision-making across enterprise and societal domains. This review presents a structured analysis of Trust, Risk, and Security Management (TRiSM) in the context of LLM-based agentic multi-agent systems (AMAS). We begin by examining the conceptual foundations of agentic AI, its architectural differences from traditional AI agents, and the emerging system designs that enable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is then detailed through four pillars governance, explainability, ModelOps, and privacy/security each contextualized for agentic LLMs. We identify unique threat vectors and introduce a comprehensive risk taxonomy for the agentic AI applications, supported by case studies illustrating real-world vulnerabilities. Furthermore, the paper also surveys trust-building mechanisms, transparency and oversight techniques, and state-of-the-art explainability strategies in distributed LLM agent systems. Additionally, metrics for evaluating trust, interpretability, and human-centered performance are reviewed alongside open benchmarking challenges. Security and privacy are addressed through encryption, adversarial defense, and compliance with evolving AI regulations. The paper concludes with a roadmap for responsible agentic AI, proposing research directions to align emerging multi-agent systems with robust TRiSM principles for safe, accountable, and transparent deployment.', 'abstract_zh': '基于大型语言模型的代理多智能体系统中的信任、风险与安全管理（TRiSM）研究', 'title_zh': 'TRiSM赋能代理人工智能：基于LLM的代理多智能体系统中的信任、风险与安全管理综述'}
{'arxiv_id': 'arXiv:2506.04022', 'title': 'Interpretability by Design for Efficient Multi-Objective Reinforcement Learning', 'authors': 'Qiyue Xia, J. Michael Herrmann', 'link': 'https://arxiv.org/abs/2506.04022', 'abstract': 'Multi-objective reinforcement learning (MORL) aims at optimising several, often conflicting goals in order to improve flexibility and reliability of RL in practical tasks. This can be achieved by finding diverse policies that are optimal for some objective preferences and non-dominated by optimal policies for other preferences so that they form a Pareto front in the multi-objective performance space. The relation between the multi-objective performance space and the parameter space that represents the policies is generally non-unique. Using a training scheme that is based on a locally linear map between the parameter space and the performance space, we show that an approximate Pareto front can provide an interpretation of the current parameter vectors in terms of the objectives which enables an effective search within contiguous solution domains. Experiments are conducted with and without retraining across different domains, and the comparison with previous methods demonstrates the efficiency of our approach.', 'abstract_zh': '多目标强化学习（MORL）旨在优化多个常常互相冲突的目标，以提高强化学习在实际任务中的灵活性和可靠性。这可以通过找到针对某些目标偏好最优且不劣于其他偏好最优策略的多样策略来实现，使得它们在多目标performance空间中形成Pareto前沿。多目标performance空间与表示策略的参数空间之间的关系通常是非唯一的。通过基于参数空间与performance空间之间的局部线性映射的训练方案，我们展示了近似Pareto前沿可以解释当前参数向量在目标方面的意义，并能够在连续的解域内进行有效搜索。在不同领域进行了带有和不带重新训练的实验，与先前方法的比较表明了我们方法的效率。', 'title_zh': '设计中的可解释性以实现高效的多目标强化学习'}
{'arxiv_id': 'arXiv:2506.04018', 'title': 'AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents', 'authors': 'Akshat Naik, Patrick Quinn, Guillermo Bosch, Emma Gouné, Francisco Javier Campos Zabala, Jason Ross Brown, Edward James Young', 'link': 'https://arxiv.org/abs/2506.04018', 'abstract': "As Large Language Model (LLM) agents become more widespread, associated misalignment risks increase. Prior work has examined agents' ability to enact misaligned behaviour (misalignment capability) and their compliance with harmful instructions (misuse propensity). However, the likelihood of agents attempting misaligned behaviours in real-world settings (misalignment propensity) remains poorly understood. We introduce a misalignment propensity benchmark, AgentMisalignment, consisting of a suite of realistic scenarios in which LLM agents have the opportunity to display misaligned behaviour. We organise our evaluations into subcategories of misaligned behaviours, including goal-guarding, resisting shutdown, sandbagging, and power-seeking. We report the performance of frontier models on our benchmark, observing higher misalignment on average when evaluating more capable models. Finally, we systematically vary agent personalities through different system prompts. We find that persona characteristics can dramatically and unpredictably influence misalignment tendencies -- occasionally far more than the choice of model itself -- highlighting the importance of careful system prompt engineering for deployed AI agents. Our work highlights the failure of current alignment methods to generalise to LLM agents, and underscores the need for further propensity evaluations as autonomous systems become more prevalent.", 'abstract_zh': '随着大型语言模型（LLM）代理的普及，关联的不一致风险增加。此前的研究已经考察了代理执行不一致行为的能力（不一致能力）及其对有害指令的遵从性（滥用倾向）。然而，代理在实际场景中尝试不一致行为的可能性（不一致倾向）仍然 poorly understood。我们引入了一个不一致倾向基准AgentMisalignment，它包含了一系列现实场景，在这些场景中LLM代理有机会表现出不一致行为。我们将评估分为目标保护、抵制关闭、拖延和权力寻求等不一致行为的亚类别。我们报告了前沿模型在基准上的性能，观察到评估更具能力的模型时平均表现出更高的不一致性。最后，我们系统地通过不同的系统提示改变代理的人格特质。我们发现，人格特征可以极大地且不可预测地影响不一致性倾向——有时甚至比模型选择本身影响更大，强调了谨慎系统提示工程对于部署AI代理的重要性。我们的工作突显了当前对齐方法无法泛化到LLM代理的失败，并强调了随着自主系统的普及需要进一步进行倾向评估的必要性。', 'title_zh': '代理不对齐：衡量基于LLM的代理产生不对齐行为的倾向'}
{'arxiv_id': 'arXiv:2506.03997', 'title': 'A framework for Conditional Reasoning in Answer Set Programming', 'authors': 'Mario Alviano, Laura Giordano, Daniele Theseider Dupré', 'link': 'https://arxiv.org/abs/2506.03997', 'abstract': 'In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics (and on the KLM preferential semantics, as a special case) to provide an interpretation of conditionals.', 'abstract_zh': '本论文介绍了一种条件回答集编程框架（Conditional ASP）用于回答集编程（ASP）的条件扩展的定义。该方法基于典型性的条件逻辑，并结合条件知识库与ASP程序，允许对程序的回答集进行条件推理。该形式主义依赖多偏好语义（以及作为特殊情况的KLM偏好语义）来解释条件。', 'title_zh': '条件推理在回答集编程中的框架'}
{'arxiv_id': 'arXiv:2506.03939', 'title': 'Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning', 'authors': 'Junqi Gao, Xiang Zou, YIng Ai, Dong Li, Yichen Niu, Biqing Qi, Jianxing Liu', 'link': 'https://arxiv.org/abs/2506.03939', 'abstract': 'Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external knowledge integration capabilities by explicitly modeling knowledge relationships, thereby improving the factual accuracy and generation quality of Large Language Models (LLMs) in specialized domains. However, existing methods suffer from two inherent limitations: 1) Inefficient Information Aggregation: They rely on a single agent and fixed iterative patterns, making it difficult to adaptively capture multi-level textual, structural, and degree information within graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning schemes, which cannot dynamically adjust reasoning depth nor achieve precise semantic correction. To overcome these limitations, we propose Graph Counselor, an GraphRAG method based on multi-agent collaboration. This method uses the Adaptive Graph Information Extraction Module (AGIEM), where Planning, Thought, and Execution Agents work together to precisely model complex graph structures and dynamically adjust information extraction strategies, addressing the challenges of multi-level dependency modeling and adaptive reasoning depth. Additionally, the Self-Reflection with Multiple Perspectives (SR) module improves the accuracy and semantic consistency of reasoning results through self-reflection and backward reasoning mechanisms. Experiments demonstrate that Graph Counselor outperforms existing methods in multiple graph reasoning tasks, exhibiting higher reasoning accuracy and generalization ability. Our code is available at this https URL.', 'abstract_zh': '基于多agent协作的Graph Retrieval Augmented Generation (GraphRAG)方法：Graph Counselor及其在多图推理任务中的应用', 'title_zh': '图导师：通过多Agent协同增强LLM推理的自适应图探索'}
{'arxiv_id': 'arXiv:2506.03915', 'title': 'Causal Explanations Over Time: Articulated Reasoning for Interactive Environments', 'authors': 'Sebastian Rödling, Matej Zečević, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2506.03915', 'abstract': 'Structural Causal Explanations (SCEs) can be used to automatically generate explanations in natural language to questions about given data that are grounded in a (possibly learned) causal model. Unfortunately they work for small data only. In turn they are not attractive to offer reasons for events, e.g., tracking causal changes over multiple time steps, or a behavioral component that involves feedback loops through actions of an agent. To this end, we generalize SCEs to a (recursive) formulation of explanation trees to capture the temporal interactions between reasons. We show the benefits of this more general SCE algorithm on synthetic time-series data and a 2D grid game, and further compare it to the base SCE and other existing methods for causal explanations.', 'abstract_zh': '结构因果解释（SCEs）可以用于基于可能学习到的因果模型自动生成关于给定数据的自然语言解释。然而，它们仅适用于小数据集。因此，它们不适用于提供事件原因，例如，在多个时间步骤中跟踪因果变化，或涉及代理行为的反馈环的行为组件。为此，我们将SCEs推广为解释树的递归形式，以捕捉原因之间的时序交互。我们在合成时间序列数据和一个2D网格游戏中展示了这一更通用的SCE算法的优势，并将其与基础SCE和其他现有的因果解释方法进行了比较。', 'title_zh': '时间维度上的因果解释：交互式环境中的 articulate 推理'}
{'arxiv_id': 'arXiv:2506.03828', 'title': 'AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance', 'authors': "Dhaval Patel, Shuxin Lin, James Rayfield, Nianjun Zhou, Roman Vaculin, Natalia Martinez, Fearghal O'donncha, Jayant Kalagnanam", 'link': 'https://arxiv.org/abs/2506.03828', 'abstract': 'AI for Industrial Asset Lifecycle Management aims to automate complex operational workflows -- such as condition monitoring, maintenance planning, and intervention scheduling -- to reduce human workload and minimize system downtime. Traditional AI/ML approaches have primarily tackled these problems in isolation, solving narrow tasks within the broader operational pipeline. In contrast, the emergence of AI agents and large language models (LLMs) introduces a next-generation opportunity: enabling end-to-end automation across the entire asset lifecycle. This paper envisions a future where AI agents autonomously manage tasks that previously required distinct expertise and manual coordination. To this end, we introduce AssetOpsBench -- a unified framework and environment designed to guide the development, orchestration, and evaluation of domain-specific agents tailored for Industry 4.0 applications. We outline the key requirements for such holistic systems and provide actionable insights into building agents that integrate perception, reasoning, and control for real-world industrial operations. The software is available at this https URL.', 'abstract_zh': '工业资产生命周期管理中的AI旨在自动化复杂的运营工作流——例如状态监测、维护计划和干预调度——以减少人力负担并最小化系统停机时间。传统的AI/ML方法主要在孤立的情况下解决这些问题，专注于运营管道中的窄任务。相比之下，AI代理和大型语言模型（LLMs）的出现为端到端的自动化提供了新一代机会：在整个资产生命周期中实现全流程自动化。本文构想了一个未来，在这个未来中，AI代理能够自主管理需要特定专业知识和手动协调的任务。为此，我们提出了一种统一框架和环境——AssetOpsBench——旨在指导适用于工业4.0应用的领域特定代理的研发、编排和评估。我们概述了这类整体系统的关键要求，并提供了如何构建能够集成感知、推理和控制的代理以适应真实工业运营环境的具体建议。该软件可在以下链接访问：this https URL。', 'title_zh': 'AssetOpsBench: 工业资产运维任务自动化工智能体基准测试'}
{'arxiv_id': 'arXiv:2506.03673', 'title': 'Reason from Future: Reverse Thought Chain Enhances LLM Reasoning', 'authors': 'Yinlong Xu, Yanzhao Zheng, Shuoshuo Sun, Shuaihan Huang, Baohua Dong, Hangcheng Zhu, Ruohui Huang, Gang Yu, Hongxia Xu, Jian Wu', 'link': 'https://arxiv.org/abs/2506.03673', 'abstract': 'It has been demonstrated that carefully designed reasoning paradigms, like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), can enhance the reasoning capabilities of small language models by detailed thinking and extensive thought searching, unbounded branching factors in the searching space create prohibitive reasoning consumption. However these methods fall into the trap of local optimum reasoning, which means the model lacks a global perspective while solving problems. We propose a novel reasoning paradigm called Reason from Future (RFF), which generates reasoning paths by bidirectional reasoning that combines top-down planning with bottom-up reasoning accumulation. The essence of RFF lies in its reverse reasoning mechanism, which prioritizes core logical relationships and imposes goal-oriented constraints on intermediate steps, thereby reducing the searching space and mitigating error accumulation inherent in sequential forward reasoning. Empirical evaluations across diverse experiments demonstrate that RFF outperforms conventional paradigms with higher accuracy and less searching space to solve complex tasks.', 'abstract_zh': '已经证明，精心设计的推理范式，如 Chain-of-Thought (CoT) 和 Tree-of-Thought (ToT)，能够通过详细的思考和广泛的思想探索增强小型语言模型的推理能力。然而，这些方法陷入了局部最优推理的陷阱，这意味着模型在解决问题时缺乏全局视角。我们提出了一种新的推理范式，称为 Future-Driven Reasoning (RFF)，该范式通过结合自上而下的规划与自下而上的推理积累进行双向推理来生成推理路径。RFF 的本质在于其逆向推理机制，这种机制优先考虑核心逻辑关系，并在中间步骤上施加目标导向的约束，从而减少搜索空间并减轻顺序正向推理中固有的错误累积。来自不同实验的实证评估表明，RFF 在解决复杂任务时具有更高的准确性和更少的搜索空间。', 'title_zh': '从未来思考：逆向思维链增强LLM推理'}
{'arxiv_id': 'arXiv:2506.03613', 'title': 'Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations', 'authors': 'Shaoshan Liu, Fan Wang, Hongjun Zhou, Yuanfeng Wang', 'link': 'https://arxiv.org/abs/2506.03613', 'abstract': 'While theory and practice are often seen as separate domains, this article shows that theoretical insight is essential for overcoming real-world engineering barriers. We begin with a practical challenge: training a cross-morphology embodied AI policy that generalizes across diverse robot morphologies. We formalize this as the Heterogeneous Embodied Agent Training (HEAT) problem and prove it reduces to a structured Partially Observable Markov Decision Process (POMDP) that is PSPACE-complete. This result explains why current reinforcement learning pipelines break down under morphological diversity, due to sequential training constraints, memory-policy coupling, and data incompatibility. We further explore Collective Adaptation, a distributed learning alternative inspired by biological systems. Though NEXP-complete in theory, it offers meaningful scalability and deployment benefits in practice. This work illustrates how computational theory can illuminate system design trade-offs and guide the development of more robust, scalable embodied AI. For practitioners and researchers to explore this problem, the implementation code of this work has been made publicly available at this https URL', 'abstract_zh': '尽管理论与实践常常被视为分离的领域，本文展示了理论洞察对于克服实际工程障碍是必不可少的。我们以一个实践挑战为起点：训练能够跨不同机器人形态泛化的具身AI策略。我们将此问题形式化为异构具身代理训练（HEAT）问题，并证明它归约成为一个结构化的部分可观测马尔可夫决策过程（POMDP），且是PSPACE完全的。这一结果解释了为什么当前的强化学习管道在形态多样性下失效，原因包括顺序训练约束、记忆与策略的耦合以及数据不兼容性。我们进一步探讨了集体适应，这是一种灵感来源于生物系统的分布式学习替代方案。尽管从理论上讲它是NEXP完全的，但在实践中它提供了有意义的可扩展性和部署优势。本文展示了计算理论如何阐明系统设计权衡，并指导构建更具鲁棒性和可扩展性的具身AI的发展。为了使研究者和实践者能够探索这一问题，本文的工作实施代码已在此处公开：this https URL。', 'title_zh': '跨形态体察智能代理的训练：从实践挑战到理论基础'}
{'arxiv_id': 'arXiv:2506.03610', 'title': 'Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games', 'authors': 'Dongmin Park, Minkyu Kim, Beongjun Choi, Junhyuck Kim, Keon Lee, Jonghyun Lee, Inkyu Park, Byeong-Uk Lee, Jaeyoung Hwang, Jaewoo Ahn, Ameya S. Mahabaleshwarkar, Bilal Kartal, Pritam Biswas, Yoshi Suhara, Kangwook Lee, Jaewoong Cho', 'link': 'https://arxiv.org/abs/2506.03610', 'abstract': 'Large Language Model (LLM) agents are reshaping the game industry, particularly with more intelligent and human-preferable game characters. However, existing game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets for aligning pre-trained LLMs into gaming agents. To fill these gaps, we present \\textbf{\\benchname{}}, a foundational benchmark designed to train and evaluate LLM agents across diverse real-world video games. Unlike existing benchmarks, Orak includes 12 popular video games spanning all major genres, enabling comprehensive studies of LLM capabilities and agentic modules essential for intricate game scenarios. To support consistent evaluation of LLMs, we introduce a plug-and-play interface based on Model Context Protocol (MCP) that enables LLMs to seamlessly connect with games and manipulate agentic modules. Additionally, we propose a fine-tuning dataset, consisting of LLM gameplay trajectories across diverse game genres. Orak offers a comprehensive evaluation framework, encompassing general game score leaderboards, LLM battle arenas, and in-depth analyses of visual input state, agentic strategies, and fine-tuning effects, establishing a foundation towards building generic gaming agents. Code is available at this https URL.', 'abstract_zh': '大型语言模型（LLM）代理正在重塑游戏行业，特别是在更具智能性和人类偏好的游戏角色方面。然而，现有的游戏基准无法满足实际需求：它们缺乏对各种游戏类型中LLM能力的多元评估，缺乏对于复杂游戏玩法至关重要的代理模块的研究，也没有针对预先训练好的LLM进行对齐的细调数据集。为填补这些空白，我们提出了\\benchname{}，一个基础基准，用于训练和评估跨多种真实世界视频游戏的LLM代理。Orak不同于现有基准，包括了12款流行视频游戏，涵盖了所有主要的游戏类型，从而能够全面研究LLM能力和对于复杂游戏场景至关重要的代理模块。为了支持对LLM的一致性评估，我们引入了基于Model Context Protocol (MCP)的插件式界面，使LLM能够无缝连接游戏并操控代理模块。此外，我们提出了一个细调数据集，该数据集包含了跨多种游戏类型中的LLM游戏玩法轨迹。Orak提供了一个全面的评估框架，包括通用游戏得分排行榜、LLM战斗竞技场以及对视觉输入状态、代理策略和细调效果的深入分析，从而为构建通用游戏代理奠定基础。代码可在以下链接获取：this https URL。', 'title_zh': 'Orak：用于多样视频游戏训练和评估LLM代理的基本基准'}
{'arxiv_id': 'arXiv:2506.03586', 'title': 'Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach', 'authors': 'Yu Ma, Chongtao Guo, Le Liang, Xiao Li, Shi Jin', 'link': 'https://arxiv.org/abs/2506.03586', 'abstract': 'This paper investigates a joint phase design and resource allocation problem in downlink reconfigurable intelligent surface (RIS)-assisted orthogonal frequency division multiplexing (OFDM) systems to optimize average delay, where data packets for each user arrive at the base station stochastically. The sequential optimization problem is inherently a Markov decision process (MDP), making it fall within the scope of reinforcement learning. To effectively handle the mixed action space and reduce the state space dimensionality, a hybrid deep reinforcement learning (DRL) approach is proposed. Specifically, proximal policy optimization (PPO)-$\\Theta$ is employed to optimize RIS phase shift design, while PPO-N is responsible for subcarrier allocation decisions. To further mitigate the curse of dimensionality associated with subcarrier allocation, a multi-agent strategy is introduced to optimize subcarrier allocation indicater more efficiently. Moreover, to achieve more adaptive resource allocation and accurately capture network dynamics, key factors closely related to average delay, including the number of backlogged packets in buffers and the current packet arrivals, are incorporated into the state space. Furthermore, a transfer learning framework is introduced to enhance training efficiency and accelerate convergence. Simulation results demonstrate that the proposed algorithm significantly reduces average delay, enhances resource allocation efficiency, and achieves superior system robustness and fairness compared to baseline methods.', 'abstract_zh': '基于重构智能表面辅助OFDM系统下行链路的联合相位设计与资源分配优化算法', 'title_zh': '基于RIS辅助OFDM系统的延迟优化联合波束forming和资源分配：一种深度强化学习方法'}
{'arxiv_id': 'arXiv:2506.03548', 'title': 'SUMO-MCP: Leveraging the Model Context Protocol for Autonomous Traffic Simulation and Optimization', 'authors': 'Chenglong Ye, Gang Xiong, Junyou Shang, Xingyuan Dai, Xiaoyan Gong, Yisheng Lv', 'link': 'https://arxiv.org/abs/2506.03548', 'abstract': "Traffic simulation tools, such as SUMO, are essential for urban mobility research. However, such tools remain challenging for users due to complex manual workflows involving network download, demand generation, simulation setup, and result analysis. In this paper, we introduce SUMO-MCP, a novel platform that not only wraps SUMO' s core utilities into a unified tool suite but also provides additional auxiliary utilities for common preprocessing and postprocessing tasks. Using SUMO-MCP, users can issue simple natural-language prompts to generate traffic scenarios from OpenStreetMap data, create demand from origin-destination matrices or random patterns, run batch simulations with multiple signal-control strategies, perform comparative analyses with automated reporting, and detect congestion for signal-timing optimization. Furthermore, the platform allows flexible custom workflows by dynamically combining exposed SUMO tools without additional coding. Experiments demonstrate that SUMO-MCP significantly makes traffic simulation more accessible and reliable for researchers. We will release code for SUMO-MCP at this https URL in the future.", 'abstract_zh': '基于SUMO-MCP的交通仿真平台：使交通仿真更易于研究人员使用和可靠', 'title_zh': 'SUMO-MCP：利用模型上下文协议进行自主交通模拟与优化'}
{'arxiv_id': 'arXiv:2506.03543', 'title': 'CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications', 'authors': 'Wanghao Ye, Sihan Chen, Yiting Wang, Shwai He, Bowei Tian, Guoheng Sun, Ziyi Wang, Ziyao Wang, Yexiao He, Zheyu Shen, Meng Liu, Yuning Zhang, Meng Feng, Yang Wang, Siyuan Peng, Yilong Dai, Zhenle Duan, Hanzhang Qin, Ang Li', 'link': 'https://arxiv.org/abs/2506.03543', 'abstract': 'Current large language model (LLM) agents lack authentic human psychological processes necessary for genuine digital twins and social AI applications. To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism. However, authentic digital twins require accurate personality initialization. We therefore develop a novel adventure-based personality test that evaluates true personality through behavioral choices within interactive scenarios, bypassing self-presentation bias found in traditional assessments. Building on these innovations, our CogniPair platform enables digital twins to engage in realistic simulated dating interactions and job interviews before real encounters, providing bidirectional cultural fit assessment for both romantic compatibility and workplace matching. Validation using 551 GNWT-Agents and Columbia University Speed Dating dataset demonstrates 72% correlation with human attraction patterns, 77.8% match prediction accuracy, and 74% agreement in human validation studies. This work advances psychological authenticity in LLM agents and establishes a foundation for intelligent dating platforms and HR technology solutions.', 'abstract_zh': '当前的大规模语言模型代理缺乏真正的人类心理过程，无法实现真实的数字孪生和社会AI应用。为解决这一限制，我们提出了基于全球工作空间理论（Global Workspace Theory, GWT）的计算实现，将人类认知架构原则融入大规模语言模型代理中，创建专门的情感、记忆、社会规范、计划和目标追踪子代理，并通过全球工作空间机制协调工作。然而，真实的数字孪生需要准确的个性初始化。因此，我们开发了一种新型的基于冒险的个性测验，通过互动场景中的行为选择评估真正个性，避免传统评估中发现的自我呈现偏差。在此基础上，我们的CogniPair平台使数字孪生能够在真实交互之前参与现实主义的模拟约会和求职面试，双向评估浪漫兼容性和工作匹配。使用551个GWT代理和哥伦比亚大学速配数据集进行验证，证明具有72%的人际吸引模式相关性、77.8%的匹配预测准确性和74%的人类验证研究的一致性。这项工作提升了大规模语言模型代理的心理真实性，并为智能约会平台和人力资源技术解决方案奠定了基础。', 'title_zh': 'CogniPair: 从大语言模型聊天机器人到有意识的AI代理——基于GNWT的多代理数字孪生在社交配对中的应用——恋侣匹配与招聘应用'}
{'arxiv_id': 'arXiv:2506.03503', 'title': 'Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2506.03503', 'abstract': 'The quantification of social science remains a longstanding challenge, largely due to the philosophical nature of its foundational theories. Although quantum computing has advanced rapidly in recent years, its relevance to social theory remains underexplored. Most existing research focuses on micro-cognitive models or philosophical analogies, leaving a gap in system-level applications of quantum principles to the analysis of social systems. This study addresses that gap by proposing a theoretical and computational framework that combines quantum mechanics with Generative AI to simulate the emergence and evolution of social norms. Drawing on core quantum concepts--such as superposition, entanglement, and probabilistic measurement--this research models society as a dynamic, uncertain system and sets up five ideal-type experiments. These scenarios are simulated using 25 generative agents, each assigned evolving roles as compliers, resistors, or enforcers. Within a simulated environment monitored by a central observer (the Watcher), agents interact, respond to surveillance, and adapt to periodic normative disruptions. These interactions allow the system to self-organize under external stress and reveal emergent patterns. Key findings show that quantum principles, when integrated with generative AI, enable the modeling of uncertainty, emergence, and interdependence in complex social systems. Simulations reveal patterns including convergence toward normative order, the spread of resistance, and the spontaneous emergence of new equilibria in social rules. In conclusion, this study introduces a novel computational lens that lays the groundwork for a quantum-informed social theory. It offers interdisciplinary insights into how society can be understood not just as a structure to observe but as a dynamic system to simulate and redesign through quantum technologies.', 'abstract_zh': '量化社会科学仍然是一个长期存在的挑战，主要归因于其基础理论的哲学性质。尽管近年来量子计算取得了 rapid 进展，但其与社会理论的相关性仍未得到充分探索。现有大多数研究集中在微观认知模型或哲学类比上，使得基于量子原理的系统级社会系统分析应用存在短板。本研究通过提出一个将量子力学与生成人工智能相结合的理论和计算框架来填补这一空白，旨在模拟社会规范的产生和演变。研究借助核心量子概念（如叠加、纠缠和概率测量）将社会建模为一个动态、不确定的系统，并设置了五个理想类型的实验场景。这些场景通过 25 个生成代理模拟，每个代理扮演变化中的遵从者、抵抗者或执行者角色。在中央观察者（称为“监督者”）监督的模拟环境中，代理之间相互作用、响应监控并适应周期性规范中断。这些互动使系统能够在外部压力下自我组织，并揭示出新兴模式。研究发现表明，将量子原理与生成人工智能相结合，能够对复杂社会系统的不确定性、涌现性和相互依赖性进行建模。模拟揭示了包括向规范秩序收敛、抵抗的传播以及社会规则的新自发均衡在内的模式。总之，本研究引入了一个新的计算视角，为基于量子的社会理论奠定了基础。它提供了跨学科的见解，表明社会不仅可以被观察为一种结构，还可以通过量子技术模拟和重新设计为一种动态系统。', 'title_zh': '社会计算建筑师：量子机器学习与社会规则生成'}
{'arxiv_id': 'arXiv:2506.03469', 'title': 'Verification-Guided Falsification for Safe RL via Explainable Abstraction and Risk-Aware Exploration', 'authors': 'Tuan Le, Risal Shefin, Debashis Gupta, Thai Le, Sarra Alqahtani', 'link': 'https://arxiv.org/abs/2506.03469', 'abstract': 'Ensuring the safety of reinforcement learning (RL) policies in high-stakes environments requires not only formal verification but also interpretability and targeted falsification. While model checking provides formal guarantees, its effectiveness is limited by abstraction quality and the completeness of the underlying trajectory dataset. We propose a hybrid framework that integrates (1) explainability, (2) model checking, and (3) risk-guided falsification to achieve both rigor and coverage. Our approach begins by constructing a human-interpretable abstraction of the RL policy using Comprehensible Abstract Policy Summarization (CAPS). This abstract graph, derived from offline trajectories, is both verifier-friendly, semantically meaningful, and can be used as input to Storm probabilistic model checker to verify satisfaction of temporal safety specifications. If the model checker identifies a violation, it will return an interpretable counterexample trace by which the policy fails the safety requirement. However, if no violation is detected, we cannot conclude satisfaction due to potential limitation in the abstraction and coverage of the offline dataset. In such cases, we estimate associated risk during model checking to guide a falsification strategy that prioritizes searching in high-risk states and regions underrepresented in the trajectory dataset. We further provide PAC-style guarantees on the likelihood of uncovering undetected violations. Finally, we incorporate a lightweight safety shield that switches to a fallback policy at runtime when such a risk exceeds a threshold, facilitating failure mitigation without retraining.', 'abstract_zh': '确保高风险环境中强化学习策略的安全性不仅需要形式验证，还需要可解释性和靶向反证。我们提出了一种混合框架，该框架整合了（1）可解释性、（2）模型检查和（3）风险引导下的反证，以实现严谨性和覆盖率的结合。该方法首先使用可解释抽象政策总结（CAPS）构建一个符合人类可解释性的RL策略抽象图，该抽象图来源于离线轨迹数据，并具有语义意义，可作为Storm概率模型检查器的输入，用于验证时间安全规范的满足情况。如果模型检查器检测到违规行为，它将返回一个可解释的反例轨迹，表明政策未能满足安全要求。然而，如果没有检测到违规行为，由于离线数据集的潜在抽象和覆盖限制，我们不能断言其满足情况。在这种情况下，我们在模型检查过程中估计相关风险，以指导一个优先搜索高风险状态和轨迹数据中未充分代表的区域的反证策略。我们还提供了关于未检测违规行为可能性的PAC风格保证。最后，我们引入了一个轻量级的安全防护，当这种风险超过阈值时，运行时切换到备用策略，从而在无需重新训练的情况下进行故障缓解。', 'title_zh': '基于可解释抽象和风险意识探索的指导验证反验证方法以实现安全的RL'}
{'arxiv_id': 'arXiv:2506.03332', 'title': 'Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows', 'authors': 'Yifei Ming, Zixuan Ke, Xuan-Phi Nguyen, Jiayu Wang, Shafiq Joty', 'link': 'https://arxiv.org/abs/2506.03332', 'abstract': 'Agentic workflows -- where multiple large language model (LLM) instances interact to solve tasks -- are increasingly built on feedback mechanisms, where one model evaluates and critiques another. Despite the promise of feedback-driven improvement, the stability of agentic workflows rests on the reliability of the judge. However, judges may hallucinate information, exhibit bias, or act adversarially -- introducing critical vulnerabilities into the workflow. In this work, we present a systematic analysis of agentic workflows under deceptive or misleading feedback. We introduce a two-dimensional framework for analyzing judge behavior, along axes of intent (from constructive to malicious) and knowledge (from parametric-only to retrieval-augmented systems). Using this taxonomy, we construct a suite of judge behaviors and develop WAFER-QA, a new benchmark with critiques grounded in retrieved web evidence to evaluate robustness of agentic workflows against factually supported adversarial feedback. We reveal that even strongest agents are vulnerable to persuasive yet flawed critiques -- often switching correct answers after a single round of misleading feedback. Taking a step further, we study how model predictions evolve over multiple rounds of interaction, revealing distinct behavioral patterns between reasoning and non-reasoning models. Our findings highlight fundamental vulnerabilities in feedback-based workflows and offer guidance for building more robust agentic systems.', 'abstract_zh': '基于欺骗性或误导性反馈的代理型工作流系统分析：构建WAFER-QA基准以评估事实支持的 adversarial 反馈的鲁棒性', 'title_zh': '助益型代理人遭遇欺骗性法官：理解代理工作流程中的漏洞'}
{'arxiv_id': 'arXiv:2506.03315', 'title': 'Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback', 'authors': 'Kai Sauerwald, Kenneth Skiba, Eduardo Fermé, Thomas Meyer', 'link': 'https://arxiv.org/abs/2506.03315', 'abstract': 'We study how linear orders can be employed to realise choice functions for which the set of potential choices is restricted, i.e., the possible choice is not possible among the full powerset of all alternatives. In such restricted settings, constructing a choice function via a relation on the alternatives is not always possible. However, we show that one can always construct a choice function via a linear order on sets of alternatives, even when a fallback value is encoded as the minimal element in the linear order. The axiomatics of such choice functions are presented for the general case and the case of union-closed input restrictions. Restricted choice structures have applications in knowledge representation and reasoning, and here we discuss their applications for theory change and abstract argumentation.', 'abstract_zh': '我们研究线序如何用于实现潜在选择集受限的选择函数，即可能的选择在所有替代方案的全体幂集上未必存在。在这样的受限设置中，通过替代方案上的关系构建选择函数并不总是可能的。然而，我们证明即使将备用值编码为线序中的最小元素，也可以通过替代方案集上的线序总是构建出选择函数。此类选择函数的公理化在一般情况和并封闭输入限制情况下被提出。受限选择结构在知识表示与推理中有应用，并讨论了它们在理论变更和抽象论辩中的应用。', 'title_zh': '集族中以最小值为后备的线性顺序的限制选择公理'}
{'arxiv_id': 'arXiv:2506.03233', 'title': 'A Trustworthiness-based Metaphysics of Artificial Intelligence Systems', 'authors': 'Andrea Ferrario', 'link': 'https://arxiv.org/abs/2506.03233', 'abstract': 'Modern AI systems are man-made objects that leverage machine learning to support our lives across a myriad of contexts and applications. Despite extensive epistemological and ethical debates, their metaphysical foundations remain relatively under explored. The orthodox view simply suggests that AI systems, as artifacts, lack well-posed identity and persistence conditions -- their metaphysical kinds are no real kinds. In this work, we challenge this perspective by introducing a theory of metaphysical identity of AI systems. We do so by characterizing their kinds and introducing identity criteria -- formal rules that answer the questions "When are two AI systems the same?" and "When does an AI system persist, despite change?" Building on Carrara and Vermaas\' account of fine-grained artifact kinds, we argue that AI trustworthiness provides a lens to understand AI system kinds and formalize the identity of these artifacts by relating their functional requirements to their physical make-ups. The identity criteria of AI systems are determined by their trustworthiness profiles -- the collection of capabilities that the systems must uphold over time throughout their artifact histories, and their effectiveness in maintaining these capabilities. Our approach suggests that the identity and persistence of AI systems is sensitive to the socio-technical context of their design and utilization via their trustworthiness, providing a solid metaphysical foundation to the epistemological, ethical, and legal discussions about these artifacts.', 'abstract_zh': '现代AI系统的形上学身份理论：基于信任性的本质刻画和身份 criteri', 'title_zh': '基于可信性的形而上学人工智能系统'}
{'arxiv_id': 'arXiv:2506.03205', 'title': 'Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments', 'authors': 'Umberto Gonçalves de Sousa', 'link': 'https://arxiv.org/abs/2506.03205', 'abstract': 'This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum reinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model, where Q-ARDNS-Multi stands for "Quantum Adaptive Reward-Driven Neural Simulator - Multi-Agent". It integrates quantum circuits with RY gates, meta-cognitive adaptation, and multi-agent coordination mechanisms for complex 3D environments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action selection, a dual-memory system inspired by human cognition, a shared memory module for agent cooperation, and adaptive exploration strategies modulated by reward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times 3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi achieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively, outperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft Actor-Critic (SAC) in terms of success rate, stability, navigation efficiency, and collision avoidance. The framework records mean rewards of $-304.2891 \\pm 756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal, demonstrating its robustness in dynamic settings. Comprehensive analyses, including learning curves, reward distributions, statistical tests, and computational efficiency evaluations, highlight the contributions of quantum circuits and meta-cognitive adaptation. By bridging quantum computing, cognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable, human-like approach for applications in robotics, autonomous navigation, and decision-making under uncertainty.', 'abstract_zh': 'Q-ARDNS-Multi：一种扩展的多智能体量子强化学习框架', 'title_zh': 'Q-ARDNS-Multi：一种适用于复杂3D环境的元认知自适应多 Agent 量子强化学习框架'}
{'arxiv_id': 'arXiv:2506.04227', 'title': 'Object-centric 3D Motion Field for Robot Learning from Human Videos', 'authors': 'Zhao-Heng Yin, Sherry Yang, Pieter Abbeel', 'link': 'https://arxiv.org/abs/2506.04227', 'abstract': "Learning robot control policies from human videos is a promising direction for scaling up robot learning. However, how to extract action knowledge (or action representations) from videos for policy learning remains a key challenge. Existing action representations such as video frames, pixelflow, and pointcloud flow have inherent limitations such as modeling complexity or loss of information. In this paper, we propose to use object-centric 3D motion field to represent actions for robot learning from human videos, and present a novel framework for extracting this representation from videos for zero-shot control. We introduce two novel components in its implementation. First, a novel training pipeline for training a ''denoising'' 3D motion field estimator to extract fine object 3D motions from human videos with noisy depth robustly. Second, a dense object-centric 3D motion field prediction architecture that favors both cross-embodiment transfer and policy generalization to background. We evaluate the system in real world setups. Experiments show that our method reduces 3D motion estimation error by over 50% compared to the latest method, achieve 55% average success rate in diverse tasks where prior approaches fail~($\\lesssim 10$\\%), and can even acquire fine-grained manipulation skills like insertion.", 'abstract_zh': '从人类视频中学习机器人控制策略：基于对象中心的3D运动场表示及其零样本控制框架', 'title_zh': '以对象为中心的3D运动场学习方法：从人类视频中学习机器人技能'}
{'arxiv_id': 'arXiv:2506.04226', 'title': 'Efficient Knowledge Editing via Minimal Precomputation', 'authors': 'Akshat Gupta, Maochuan Lu, Thomas Hartvigsen, Gopala Anumanchipalli', 'link': 'https://arxiv.org/abs/2506.04226', 'abstract': 'Knowledge editing methods like MEMIT are able to make data and compute efficient updates of factual knowledge by using a single sentence to update facts and their consequences. However, what is often overlooked is a "precomputation step", which requires a one-time but significant computational cost. The authors of MEMIT originally precompute approximately 44 million hidden vectors per edited layer, which requires a forward pass over 44 million tokens. For GPT-J (6B), this precomputation step takes 36 hours on a single GPU, while it takes approximately 40 hours for Llama2-7B. Additionally, this precomputation time grows with model size. In this paper, we show that this excessive computational cost is unnecessary. Knowledge editing using MEMIT and related methods, such as ROME and EMMET, can be performed by pre-computing a very small portion of the 44 million hidden vectors. We first present the theoretical minimum number of hidden vector precomputation required for solutions of these editing methods to exist. We then empirically show that knowledge editing using these methods can be done by pre-computing significantly fewer hidden vectors. Specifically, we show that the precomputation step can be done with less than 0.3% of the originally stipulated number of hidden vectors. This saves a significant amount of precomputation time and allows users to begin editing new models within a few minutes.', 'abstract_zh': '基于MEMIT的知识编辑方法能够通过单一句子更新事实及其后果，从而实现数据和计算的有效更新。然而，通常被忽视的是“预计算步驟”，这需要一次性的但显著的计算成本。MEMIT的作者最初为每个编辑层预计算约4400万个隐藏向量，这需要对4400万个标记进行前向传播。对于GPT-J（6B），这一预计算步骤在单个GPU上耗时36小时，而对于Llama2-7B，则大约需要40小时。此外，随着模型规模的增加，预计算时间也会增加。本文表明，这种过多的计算成本是不必要的。使用MEMIT及其相关方法（如ROME和EMMET）进行知识编辑可以通过预计算极小部分的4400万个隐藏向量来实现。我们首先给出了这些编辑方法解存在所需的理论最小隐藏向量预计算数量。然后实验证明，可以使用显著更少的隐藏向量进行知识编辑。具体来说，预计算步骤可以使用原定数量不到0.3%的隐藏向量来完成。这显著节省了预计算时间，并使用户能够在几分钟内开始编辑新的模型。', 'title_zh': '通过最小前置计算实现高效的知识编辑'}
{'arxiv_id': 'arXiv:2506.04218', 'title': 'Pseudo-Simulation for Autonomous Driving', 'authors': 'Wei Cao, Marcel Hallgarten, Tianyu Li, Daniel Dauner, Xunjiang Gu, Caojun Wang, Yakov Miron, Marco Aiello, Hongyang Li, Igor Gilitschenski, Boris Ivanovic, Marco Pavone, Andreas Geiger, Kashyap Chitta', 'link': 'https://arxiv.org/abs/2506.04218', 'abstract': "Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical limitations. Real-world evaluation is often challenging due to safety concerns and a lack of reproducibility, whereas closed-loop simulation can face insufficient realism or high computational costs. Open-loop evaluation, while being efficient and data-driven, relies on metrics that generally overlook compounding errors. In this paper, we propose pseudo-simulation, a novel paradigm that addresses these limitations. Pseudo-simulation operates on real datasets, similar to open-loop evaluation, but augments them with synthetic observations generated prior to evaluation using 3D Gaussian Splatting. Our key idea is to approximate potential future states the AV might encounter by generating a diverse set of observations that vary in position, heading, and speed. Our method then assigns a higher importance to synthetic observations that best match the AV's likely behavior using a novel proximity-based weighting scheme. This enables evaluating error recovery and the mitigation of causal confusion, as in closed-loop benchmarks, without requiring sequential interactive simulation. We show that pseudo-simulation is better correlated with closed-loop simulations (R^2=0.8) than the best existing open-loop approach (R^2=0.7). We also establish a public leaderboard for the community to benchmark new methodologies with pseudo-simulation. Our code is available at this https URL.", 'abstract_zh': '现有的自主车辆评估范式面临关键限制。实际世界评估由于安全问题和缺乏重复性往往具有挑战性，而闭环仿真可能因不真实或计算成本高而受限。开环评估虽然高效且数据驱动，但依赖的指标通常忽视了累积错误。在本文中，我们提出了一种新的伪仿真范式，以解决这些限制。伪仿真基于真实数据集进行操作，类似于开环评估，但通过在评估前使用3D高斯散射生成合成观察来增强数据集。我们的核心思想是通过生成一组在位置、方向和速度上有所不同以近似自主车辆可能遇到的潜在未来状态的观察来实现这一目标。随后，我们的方法使用一种新颖的距离加权方案赋予最佳匹配自主车辆预期行为的合成观察更高的重要性。这使得评估错误恢复和因果混淆的缓解成为可能，类似于闭环基准，而无需进行序列交互仿真。我们表明，伪仿真的相关性优于现有最佳开环方法（R²=0.7），与闭环仿真（R²=0.8）的相关性更好。我们还为进一步通过伪仿真方法评估新方法建立了公共排行榜。代码可在以下链接获取。', 'title_zh': '伪模拟在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2506.04217', 'title': 'OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis', 'authors': 'Junting Chen, Haotian Liang, Lingxiao Du, Weiyun Wang, Mengkang Hu, Yao Mu, Wenhai Wang, Jifeng Dai, Ping Luo, Wenqi Shao, Lin Shao', 'link': 'https://arxiv.org/abs/2506.04217', 'abstract': 'The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling. A second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world. The project page is at this https URL', 'abstract_zh': '快速发展的导航、操作和视觉模型使移动 manipulator 能够胜任许多专门任务。然而，开放世界移动操作 (OWMM) 任务由于需要在开放指令和环境下的通用化以及基于全局场景理解与当前代理状态的高层决策与低层机器人控制的系统复杂性而仍然是一项挑战。为应对这一挑战，我们提出了一种新颖的多模态代理架构，该架构维护多视角场景帧和代理状态以进行决策，并通过函数调用来控制机器人。第二个挑战是领域转移引起的幻觉。为了提升代理性能，我们进一步引入了一个面向 OWMM 任务的代理数据合成流水线，通过指令微调将 VLM 模型适应到我们的任务领域。我们强调我们的微调 OWMM-VLM 是第一个专为移动 manipulator 设计的基础模型，具备全局场景理解、机器人状态跟踪和统一模型中的多模态动作生成。通过实验，我们展示了该模型在与其他基础模型（包括 GPT-4o）相比时，实现了最佳性能，并在真实世界中展示了强大的零样本泛化能力。项目页面请点击这里 https://。', 'title_zh': 'OWMM-Agent: 开放世界移动 manipulation 与多模态代理数据合成'}
{'arxiv_id': 'arXiv:2506.04215', 'title': 'Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs', 'authors': 'Alex DeWeese, Guannan Qu', 'link': 'https://arxiv.org/abs/2506.04215', 'abstract': 'Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are known to be NEXP-Complete and intractable to solve. However, for problems such as cooperative navigation, obstacle avoidance, and formation control, basic assumptions can be made about local visibility and local dependencies. The work DeWeese and Qu 2024 formalized these assumptions in the construction of the Locally Interdependent Multi-Agent MDP. In this setting, it establishes three closed-form policies that are tractable to compute in various situations and are exponentially close to optimal with respect to visibility. However, it is also shown that these solutions can have poor performance when the visibility is small and fixed, often getting stuck during simulations due to the so called "Penalty Jittering" phenomenon. In this work, we establish the Extended Cutoff Policy Class which is, to the best of our knowledge, the first non-trivial class of near optimal closed-form partially observable policies that are exponentially close to optimal with respect to the visibility for any Locally Interdependent Multi-Agent MDP. These policies are able to remember agents beyond their visibilities which allows them to perform significantly better in many small and fixed visibility settings, resolve Penalty Jittering occurrences, and under certain circumstances guarantee fully observable joint optimal behavior despite the partial observability. We also propose a generalized form of the Locally Interdependent Multi-Agent MDP that allows for transition dependence and extended reward dependence, then replicate our theoretical results in this setting.', 'abstract_zh': '分布式部分可观测马尔可夫决策过程（Dec-POMDPs）被称为NEXP-完全问题，并且难以求解。然而，对于诸如合作导航、避障和编队控制等问题，可以对局部可见性和局部依赖性做出基本假设。DeWeese和Qu 2024的工作在构建局部依存多智能体MDP的过程中，形式化了这些假设，并建立了三个可计算的闭式策略，在多种情况下这些策略是适用的，并且在可见性方面指数接近最优。然而，当可见性小时，这些解决方案也可能表现不佳，在模拟过程中常常因为所谓的“罚分抖动”现象而陷入困境。在本文中，我们建立了扩展的截止策略类，这是已知的第一个针对任何局部依存多智能体MDP在可见性方面指数接近最优的非平凡的近最优闭式部分可观测策略类。这些策略能够记住超出了其可见范围的代理，使其在许多小且固定的可见性设置中表现出色，可以解决罚分抖动问题，并在某些情况下即使在部分可观测的情况下也能保证完全可观测的联合最优行为。我们还提出了一种局部依存多智能体MDP的广义形式，允许转移依赖和扩展的奖励依赖性，并在该设置中复制了我们的理论结果。', 'title_zh': '超越可见性思考：近最优的局部相互依存多智能体MDP策略框架'}
{'arxiv_id': 'arXiv:2506.04207', 'title': 'Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning', 'authors': 'Shuang Chen, Yue Guo, Zhaochen Su, Yafu Li, Yulun Wu, Jiacheng Chen, Jiayu Chen, Weijie Wang, Xiaoye Qu, Yu Cheng', 'link': 'https://arxiv.org/abs/2506.04207', 'abstract': 'Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. In this paper, rather than examining multimodal RL in isolation, we delve into current training pipelines and identify three crucial phenomena: 1) Effective cold start initialization is critical for enhancing MLLM reasoning. Intriguingly, we find that initializing with carefully selected text data alone can lead to performance surpassing many recent multimodal reasoning models, even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers from gradient stagnation, which degrades training stability and performance. 3) Subsequent text-only RL training, following the multimodal RL phase, further enhances multimodal reasoning. This staged training approach effectively balances perceptual grounding and cognitive reasoning development. By incorporating the above insights and addressing multimodal RL issues, we introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath, LogicVista, DynaMath, and challenging AIME2024 and AIME2025.', 'abstract_zh': '受Deepseek-R1在复杂文本任务中令人瞩目的推理能力的启发，许多研究试图通过直接应用强化学习（RL）来激发多模态大型语言模型（MLLMs）类似的推理能力。然而，它们仍然难以激活复杂的推理能力。在本文中，我们不是孤立地研究多模态RL，而是深入当前的训练 pipeline 并识别出三个关键现象：1）有效的冷启动初始化对提升MLLM推理至关重要。有趣的是，我们发现仅使用精心选择的文本数据初始化可以在多模态推理方面超越许多近期的多模态推理模型，甚至在多模态RL之前。2）应用于多模态RL的标准GRPO遭受梯度停滞问题，这降低了训练稳定性和性能。3）在多模态RL阶段之后进行后续的纯文本RL训练，进一步增强了多模态推理能力。这种分阶段的训练方法有效地平衡了感知定位和认知推理的发展。通过结合上述见解并解决多模态RL的问题，我们引入了ReVisual-R1，在包括MathVerse、MathVision、WeMath、LogicVista、DynaMath以及具有挑战性的AIME2024和AIME2025基准测试中的开源7B MLLMs中达到了新的最佳性能。', 'title_zh': '提升多模态推理：从优化冷启动到分阶段强化学习'}
{'arxiv_id': 'arXiv:2506.04202', 'title': 'TracLLM: A Generic Framework for Attributing Long Context LLMs', 'authors': 'Yanting Wang, Wei Zou, Runpeng Geng, Jinyuan Jia', 'link': 'https://arxiv.org/abs/2506.04202', 'abstract': 'Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM, the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: this https URL.', 'abstract_zh': '长上下文大语言模型（LLMs）在许多实际应用中得到部署，如RAG、智能代理及广泛的大语言模型集成应用。给定一条指令和一段长上下文（例如文档、PDF文件、网页），长上下文LLM可以生成与提供的上下文紧密结合的输出，旨在提供更准确、更及时且可验证的输出，同时减少幻觉和未经证实主张的发生。这引发了一个研究问题：如何确定长上下文中的哪些文本（例如句子、段落或段落）对生成的输出贡献最大或负责生成该输出？这一过程，我们称之为上下文追溯，具有多种实际应用，包括1）调试LLM系统，2）攻击后法医分析（例如提示注入攻击、知识篡改攻击）的LLM，3）突出显示知识来源以增强用户对LLM生成输出的信任。在应用于长上下文LLM的上下文追溯时，现有的特征归因方法，如Shapley，表现不佳且/或计算成本高昂。在本文中，我们开发了TracLLM，这是首个针对长上下文LLM的通用上下文追溯框架。我们的框架可以提高现有特征归因方法的有效性和效率。为了提高效率，我们开发了TracLLM中的基于启发式搜索的算法。我们还开发了贡献分数集成/去噪技术以提高TracLLM的准确性。我们的评估结果表明，TracLLM可以有效识别长上下文中导致LLM生成输出的文本。我们的代码和数据请点击：this https URL。', 'title_zh': 'TracLLM: 一种针对长上下文LLM的归因通用框架'}
{'arxiv_id': 'arXiv:2506.04195', 'title': 'MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal Structures', 'authors': 'Elena Zamaraeva, Christopher M. Collins, George R. Darling, Matthew S. Dyer, Bei Peng, Rahul Savani, Dmytro Antypov, Vladimir V. Gusev, Judith Clymo, Paul G. Spirakis, Matthew J. Rosseinsky', 'link': 'https://arxiv.org/abs/2506.04195', 'abstract': 'Geometry optimization of atomic structures is a common and crucial task in computational chemistry and materials design. Following the learning to optimize paradigm, we propose a new multi-agent reinforcement learning method called Multi-Agent Crystal Structure optimization (MACS) to address periodic crystal structure optimization. MACS treats geometry optimization as a partially observable Markov game in which atoms are agents that adjust their positions to collectively discover a stable configuration. We train MACS across various compositions of reported crystalline materials to obtain a policy that successfully optimizes structures from the training compositions as well as structures of larger sizes and unseen compositions, confirming its excellent scalability and zero-shot transferability. We benchmark our approach against a broad range of state-of-the-art optimization methods and demonstrate that MACS optimizes periodic crystal structures significantly faster, with fewer energy calculations, and the lowest failure rate.', 'abstract_zh': '多代理晶体结构优化（MACS）在周期性晶体结构优化中的应用', 'title_zh': 'MACS：多智能体强化学习在晶体结构优化中的应用'}
{'arxiv_id': 'arXiv:2506.04171', 'title': 'Physics-Constrained Flow Matching: Sampling Generative Models with Hard Constraints', 'authors': 'Utkarsh Utkarsh, Pengfei Cai, Alan Edelman, Rafael Gomez-Bombarelli, Christopher Vincent Rackauckas', 'link': 'https://arxiv.org/abs/2506.04171', 'abstract': 'Deep generative models have recently been applied to physical systems governed by partial differential equations (PDEs), offering scalable simulation and uncertainty-aware inference. However, enforcing physical constraints, such as conservation laws (linear and nonlinear) and physical consistencies, remains challenging. Existing methods often rely on soft penalties or architectural biases that fail to guarantee hard constraints. In this work, we propose Physics-Constrained Flow Matching (PCFM), a zero-shot inference framework that enforces arbitrary nonlinear constraints in pretrained flow-based generative models. PCFM continuously guides the sampling process through physics-based corrections applied to intermediate solution states, while remaining aligned with the learned flow and satisfying physical constraints. Empirically, PCFM outperforms both unconstrained and constrained baselines on a range of PDEs, including those with shocks, discontinuities, and sharp features, while ensuring exact constraint satisfaction at the final solution. Our method provides a general framework for enforcing hard constraints in both scientific and general-purpose generative models, especially in applications where constraint satisfaction is essential.', 'abstract_zh': '基于物理约束的流匹配（PCFM）：预训练生成模型中任意非线性约束的零样本推理框架', 'title_zh': '物理学约束流匹配：具有刚性约束的生成模型采样'}
{'arxiv_id': 'arXiv:2506.04168', 'title': 'Horizon Reduction Makes RL Scalable', 'authors': 'Seohong Park, Kevin Frans, Deepinder Mann, Benjamin Eysenbach, Aviral Kumar, Sergey Levine', 'link': 'https://arxiv.org/abs/2506.04168', 'abstract': 'In this work, we study the scalability of offline reinforcement learning (RL) algorithms. In principle, a truly scalable offline RL algorithm should be able to solve any given problem, regardless of its complexity, given sufficient data, compute, and model capacity. We investigate if and how current offline RL algorithms match up to this promise on diverse, challenging, previously unsolved tasks, using datasets up to 1000x larger than typical offline RL datasets. We observe that despite scaling up data, many existing offline RL algorithms exhibit poor scaling behavior, saturating well below the maximum performance. We hypothesize that the horizon is the main cause behind the poor scaling of offline RL. We empirically verify this hypothesis through several analysis experiments, showing that long horizons indeed present a fundamental barrier to scaling up offline RL. We then show that various horizon reduction techniques substantially enhance scalability on challenging tasks. Based on our insights, we also introduce a minimal yet scalable method named SHARSA that effectively reduces the horizon. SHARSA achieves the best asymptotic performance and scaling behavior among our evaluation methods, showing that explicitly reducing the horizon unlocks the scalability of offline RL. Code: this https URL', 'abstract_zh': '在这项工作中，我们研究了离线强化学习（RL）算法的扩展性。原则上，一个真正意义上的可扩展的离线RL算法应该能够在给定足够数据、计算能力和模型容量的情况下，解决任何复杂的问题。我们调查当前的离线RL算法在使用比标准离线RL数据集大1000倍的数据集时，是否以及如何达到这一承诺，特别是在多样的、具有挑战性的、之前未解决的任务上。我们发现，尽管增加了数据量，许多现有的离线RL算法依然表现出不良的扩展性，性能在远低于最大性能时就达到饱和。我们假设时间 horizon 是导致离线RL不良扩展性的主要原因。通过一系列分析实验，我们实证验证了这一假说，显示较长的时间 horizon 确实是扩展离线RL的一个根本障碍。随后，我们展示了各种时间 horizon 减少技术在具有挑战性的任务上显著提高了可扩展性。基于我们的洞察，我们还引入了一种简单而有效的可扩展方法SHARSA，该方法有效减少了时间 horizon。SHARSA 在我们的评估方法中实现了最好的渐近性能和扩展性表现，表明明确减少时间 horizon 突破了离线RL的可扩展性。代码：这个 https://这个链接Url。', 'title_zh': '水平缩减使强化学习更具可扩展性'}
{'arxiv_id': 'arXiv:2506.04147', 'title': 'SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL', 'authors': 'Jiaheng Hu, Peter Stone, Roberto Martín-Martín', 'link': 'https://arxiv.org/abs/2506.04147', 'abstract': 'Building capable household and industrial robots requires mastering the control of versatile, high-degree-of-freedom (DoF) systems such as mobile manipulators. While reinforcement learning (RL) holds promise for autonomously acquiring robot control policies, scaling it to high-DoF embodiments remains challenging. Direct RL in the real world demands both safe exploration and high sample efficiency, which are difficult to achieve in practice. Sim-to-real RL, on the other hand, is often brittle due to the reality gap. This paper introduces SLAC, a method that renders real-world RL feasible for complex embodiments by leveraging a low-fidelity simulator to pretrain a task-agnostic latent action space. SLAC trains this latent action space via a customized unsupervised skill discovery method designed to promote temporal abstraction, disentanglement, and safety, thereby facilitating efficient downstream learning. Once a latent action space is learned, SLAC uses it as the action interface for a novel off-policy RL algorithm to autonomously learn downstream tasks through real-world interactions. We evaluate SLAC against existing methods on a suite of bimanual mobile manipulation tasks, where it achieves state-of-the-art performance. Notably, SLAC learns contact-rich whole-body tasks in under an hour of real-world interactions, without relying on any demonstrations or hand-crafted behavior priors. More information, code, and videos at this http URL', 'abstract_zh': '构建能力强的家用和工业机器人需要掌握多功能、高自由度（DOF）系统的控制，例如移动操作臂。虽然强化学习（RL）有望自主获取机器人控制策略，但在高DOF实体上的扩展仍然具有挑战性。在现实世界中直接进行RL要求既安全又高效的探索，这在实践中很难实现。相比之下，模拟到现实的RL由于现实差距往往比较脆弱。本文提出了一种SLAC方法，通过利用低保真模拟器预先训练任务无关的潜在动作空间，使复杂的实体能够进行现实世界的RL。SLAC通过一种定制的无监督技能发现方法来训练这个潜在动作空间，该方法旨在促进时间抽象、各个因素分离和安全性，从而促进下游学习的效率。一旦学习到潜在动作空间，SLAC将其作为动作接口，用于一种新颖的非策略性RL算法，通过实际交互自主学习下游任务。我们在一系列双臂移动操作任务上评估了SLAC，其性能达到了最先进的水平。值得注意的是，SLAC仅在不到一小时的现实世界交互中就学习了接触丰富的一体化任务，无需任何演示或手工艺品先验知识。更多信息、代码和视频请参见此链接。', 'title_zh': 'SLAC: 模拟预训练潜空间动作域用于全身现实世界强化学习'}
{'arxiv_id': 'arXiv:2506.04143', 'title': 'Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology', 'authors': 'Ngoc Q. Ly, Hieu N. M. Cao, Thi T. Nguyen', 'link': 'https://arxiv.org/abs/2506.04143', 'abstract': 'Person Re-Identification (Re-ID) is a very important task in video surveillance systems such as tracking people, finding people in public places, or analysing customer behavior in supermarkets. Although there have been many works to solve this problem, there are still remaining challenges such as large-scale datasets, imbalanced data, viewpoint, fine grained data (attributes), the Local Features are not employed at semantic level in online stage of Re-ID task, furthermore, the imbalanced data problem of attributes are not taken into consideration. This paper has proposed a Unified Re-ID system consisted of three main modules such as Pedestrian Attribute Ontology (PAO), Local Multi-task DCNN (Local MDCNN), Imbalance Data Solver (IDS). The new main point of our Re-ID system is the power of mutual support of PAO, Local MDCNN and IDS to exploit the inner-group correlations of attributes and pre-filter the mismatch candidates from Gallery set based on semantic information as Fashion Attributes and Facial Attributes, to solve the imbalanced data of attributes without adjusting network architecture and data augmentation. We experimented on the well-known Market1501 dataset. The experimental results have shown the effectiveness of our Re-ID system and it could achieve the higher performance on Market1501 dataset in comparison to some state-of-the-art Re-ID methods.', 'abstract_zh': '基于统一框架的行人再识别系统：融合行人属性本体、局部多任务DCNN和不平衡数据解决方法', 'title_zh': '基于行人属性本体的语义级别行人重识别系统'}
{'arxiv_id': 'arXiv:2506.04132', 'title': 'Plant Bioelectric Early Warning Systems: A Five-Year Investigation into Human-Plant Electromagnetic Communication', 'authors': 'Peter A. Gloor', 'link': 'https://arxiv.org/abs/2506.04132', 'abstract': 'We present a comprehensive investigation into plant bioelectric responses to human presence and emotional states, building on five years of systematic research. Using custom-built plant sensors and machine learning classification, we demonstrate that plants generate distinct bioelectric signals correlating with human proximity, emotional states, and physiological conditions. A deep learning model based on ResNet50 architecture achieved 97% accuracy in classifying human emotional states through plant voltage spectrograms, while control models with shuffled labels achieved only 30% accuracy. This study synthesizes findings from multiple experiments spanning 2020-2025, including individual recognition (66% accuracy), eurythmic gesture detection, stress prediction, and responses to human voice and movement. We propose that these phenomena represent evolved anti-herbivory early warning systems, where plants detect approaching animals through bioelectric field changes before physical contact. Our results challenge conventional understanding of plant sensory capabilities and suggest practical applications in agriculture, healthcare, and human-plant interaction research.', 'abstract_zh': '我们对植物在人类存在和情绪状态下的生物电响应进行了一项全面调查，基于2020年至2025年间五年系统研究。利用自定义植物传感器和机器学习分类，我们展示了植物生成与人类接近程度、情绪状态和生理条件相关的独特生物电信号。基于ResNet50架构的深度学习模型在通过植物电压光谱分类人类情绪状态方面达到了97%的准确率，而标签打乱的控制模型仅达到了30%的准确率。本研究综合了跨越2020年至2025年期间多项实验的发现，包括个体识别（准确率为66%）、韵律手势检测、压力预测以及对人类声音和运动的响应。我们提出这些现象代表了植物进化出的抗食草防御预警系统，在生物电场变化之前检测即将接近的动物。我们的结果挑战了对植物感觉能力的传统理解，并建议在农业、医疗保健以及人-植物交互研究中具有实际应用价值。', 'title_zh': '植物生物电预警系统：五年来的人-植物电磁通信研究'}
{'arxiv_id': 'arXiv:2506.04131', 'title': 'CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues', 'authors': 'Disha Sheshanarayana, Tanishka Magar, Ayushi Mittal, Neelam Chaplot', 'link': 'https://arxiv.org/abs/2506.04131', 'abstract': 'Courtrooms are places where lives are determined and fates are sealed, yet they are not impervious to manipulation. Strategic use of manipulation in legal jargon can sway the opinions of judges and affect the decisions. Despite the growing advancements in NLP, its application in detecting and analyzing manipulation within the legal domain remains largely unexplored. Our work addresses this gap by introducing LegalCon, a dataset of 1,063 annotated courtroom conversations labeled for manipulation detection, identification of primary manipulators, and classification of manipulative techniques, with a focus on long conversations. Furthermore, we propose CLAIM, a two-stage, Intent-driven Multi-agent framework designed to enhance manipulation analysis by enabling context-aware and informed decision-making. Our results highlight the potential of incorporating agentic frameworks to improve fairness and transparency in judicial processes. We hope that this contributes to the broader application of NLP in legal discourse analysis and the development of robust tools to support fairness in legal decision-making. Our code and data are available at this https URL.', 'abstract_zh': '法庭是决定人们命运和封定前途的地方，但它们并非不受操纵的影响。在法律用语中战略性地使用操纵手段可以影响法官的观点并影响判决。尽管自然语言处理（NLP）取得了越来越大的进展，但在法律领域内检测和分析操纵的应用仍然鲜有研究。我们的工作通过引入包含1063个标注对话的LegalCon数据集来填补这一空白，该数据集涵盖了操纵检测、 primary操纵者识别以及操纵技术分类，并重点关注长对话。此外，我们提出了CLAIM框架，这是一个基于意图的两阶段多智能体系统，旨在通过促进情境感知和知情决策来增强操纵分析。我们的结果强调了整合行动者框架在提高司法过程公平性和透明度方面的潜力。我们希望这能够促进NLP在法律话语分析中的更广泛应用，并推动开发支持法律决策公平性的稳健工具。我们的代码和数据可在以下链接获取。', 'title_zh': 'CLAIM：一种基于意图的多_agent框架用于法庭对话中的操纵分析'}
{'arxiv_id': 'arXiv:2506.04129', 'title': 'Recent Advances in Medical Image Classification', 'authors': 'Loan Dao, Ngoc Quoc Ly', 'link': 'https://arxiv.org/abs/2506.04129', 'abstract': 'Medical image classification is crucial for diagnosis and treatment, benefiting significantly from advancements in artificial intelligence. The paper reviews recent progress in the field, focusing on three levels of solutions: basic, specific, and applied. It highlights advances in traditional methods using deep learning models like Convolutional Neural Networks and Vision Transformers, as well as state-of-the-art approaches with Vision Language Models. These models tackle the issue of limited labeled data, and enhance and explain predictive results through Explainable Artificial Intelligence.', 'abstract_zh': '医学图像分类对于诊断和治疗至关重要，受益于人工智能的发展。本文回顾了该领域的最新进展，重点关注三个层面的解决方案：基础层、具体层和应用层。文章 Highlights 传统方法在使用深度学习模型如卷积神经网络和视觉变换器方面的进展，以及使用视觉语言模型的先进方法。这些模型解决了标注数据有限的问题，并通过可解释的人工智能增强和解释预测结果。', 'title_zh': '最近在医学图像分类领域的进展'}
{'arxiv_id': 'arXiv:2506.04121', 'title': 'A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks', 'authors': 'Loan Dao, Ngoc Quoc Ly', 'link': 'https://arxiv.org/abs/2506.04121', 'abstract': 'Over the past decade, Medical Image Segmentation (MIS) using Deep Neural Networks (DNNs) has achieved significant performance improvements and holds great promise for future developments. This paper presents a comprehensive study on MIS based on DNNs. Intelligent Vision Systems are often evaluated based on their output levels, such as Data, Information, Knowledge, Intelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at these levels are the focus of research. Additionally, Explainable Artificial Intelligence (XAI) has become an important research direction, as it aims to uncover the "black box" nature of previous DNN architectures to meet the requirements of transparency and ethics. The study emphasizes the importance of MIS in disease diagnosis and early detection, particularly for increasing the survival rate of cancer patients through timely diagnosis. XAI and early prediction are considered two important steps in the journey from "intelligence" to "wisdom." Additionally, the paper addresses existing challenges and proposes potential solutions to enhance the efficiency of implementing DNN-based MIS.', 'abstract_zh': '过去十年，基于深度神经网络的医学图像分割（MIS）取得了显著的性能提升，并为未来的发展带来了巨大潜力。本文对基于深度神经网络的医学图像分割进行了全面研究。智能视觉系统通常根据其输出水平，如数据、信息、知识、智能和智慧（DIKIW）进行评估，这些水平上的最先进解决方案是本研究的重点。此外，可解释的人工智能（XAI）已成为一个重要的研究方向，因为它旨在揭开之前深度神经网络架构的“黑匣子”性质，以满足透明性和伦理要求。研究强调了医学图像分割在疾病诊断和早期检测中的重要性，特别是通过及时诊断提高癌症患者的生存率。可解释性人工智能和早期预测被认为是“智能”到“智慧”旅程中的两个重要步骤。此外，本文还讨论了现有挑战，并提出了潜在解决方案，以提高基于深度神经网络的医学图像分割的效率。', 'title_zh': '基于深度神经网络的医学图像分割综述研究'}
{'arxiv_id': 'arXiv:2506.04116', 'title': 'A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging', 'authors': 'Xuanru Zhou, Jiarun Liu, Shoujun Yu, Hao Yang, Cheng Li, Tao Tan, Shanshan Wang', 'link': 'https://arxiv.org/abs/2506.04116', 'abstract': 'In medical imaging, 4D MRI enables dynamic 3D visualization, yet the trade-off between spatial and temporal resolution requires prolonged scan time that can compromise temporal fidelity--especially during rapid, large-amplitude motion. Traditional approaches typically rely on registration-based interpolation to generate intermediate frames. However, these methods struggle with large deformations, resulting in misregistration, artifacts, and diminished spatial consistency. To address these challenges, we propose TSSC-Net, a novel framework that generates intermediate frames while preserving spatial consistency. To improve temporal fidelity under fast motion, our diffusion-based temporal super-resolution network generates intermediate frames using the start and end frames as key references, achieving 6x temporal super-resolution in a single inference step. Additionally, we introduce a novel tri-directional Mamba-based module that leverages long-range contextual information to effectively resolve spatial inconsistencies arising from cross-slice misalignment, thereby enhancing volumetric coherence and correcting cross-slice errors. Extensive experiments were performed on the public ACDC cardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results demonstrate that TSSC-Net can generate high-resolution dynamic MRI from fast-motion data while preserving structural fidelity and spatial consistency.', 'abstract_zh': '医疗影像中的4D MRI 使动态3D可视化成为可能，但空间分辨率和时间分辨率之间的权衡需要延长扫描时间，尤其是在快速大振幅运动期间会损害时间保真度。传统方法通常依赖于基于注册的插值来生成中间帧，但这些方法在处理大变形时会遇到困难，导致错位、伪影和空间一致性减弱。为了解决这些问题，我们提出了TSSC-Net，这是一种新型框架，可以在保持空间一致性的前提下生成中间帧。为了在快速运动下提高时间保真度，我们的基于扩散的时间超级分辨率网络使用起始帧和结束帧作为关键参考来生成中间帧，实现单一推断步中的6倍时间超级分辨率。此外，我们引入了一种基于Mamba的新三向模块，利用长程上下文信息有效解决切片错位引起的空间不一致问题，从而增强体素相干性并纠正切片误差。在公开的ACDC心脏MRI数据集和实际快速运动的4D膝关节数据集上进行了广泛的实验。结果表明，TSSC-Net可以从快速运动数据中生成高分辨率动态MRI，同时保持结构保真度和空间一致性。', 'title_zh': '基于扩散驱动的时空超分辨率和空间一致性增强框架用于4D MRI成像'}
{'arxiv_id': 'arXiv:2506.04098', 'title': 'TextAtari: 100K Frames Game Playing with Language Agents', 'authors': 'Wenhao Li, Wenwu Li, Chuyun Shen, Junjie Sheng, Zixiao Huang, Di Wu, Yun Hua, Wei Yin, Xiangfeng Wang, Hongyuan Zha, Bo Jin', 'link': 'https://arxiv.org/abs/2506.04098', 'abstract': 'We present TextAtari, a benchmark for evaluating language agents on very long-horizon decision-making tasks spanning up to 100,000 steps. By translating the visual state representations of classic Atari games into rich textual descriptions, TextAtari creates a challenging test bed that bridges sequential decision-making with natural language processing. The benchmark includes nearly 100 distinct tasks with varying complexity, action spaces, and planning horizons, all rendered as text through an unsupervised representation learning framework (AtariARI). We evaluate three open-source large language models (Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks (zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how different forms of prior knowledge affect performance on these long-horizon challenges. Four scenarios-Basic, Obscured, Manual Augmentation, and Reference-based-investigate the impact of semantic understanding, instruction comprehension, and expert demonstrations on agent decision-making. Our results reveal significant performance gaps between language agents and human players in extensive planning tasks, highlighting challenges in sequential reasoning, state tracking, and strategic planning across tens of thousands of steps. TextAtari provides standardized evaluation protocols, baseline implementations, and a framework for advancing research at the intersection of language models and planning.', 'abstract_zh': 'TextAtari：一种用于评估语言代理在长达10万步的长期决策任务上的基准测试', 'title_zh': 'TextAtari: 语言代理下的100K帧游戏玩法'}
{'arxiv_id': 'arXiv:2506.04089', 'title': 'AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment', 'authors': 'Anastasiia Ivanova, Eva Bakaeva, Zoya Volovikova, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2506.04089', 'abstract': 'As a part of an embodied agent, Large Language Models (LLMs) are typically used for behavior planning given natural language instructions from the user. However, dealing with ambiguous instructions in real-world environments remains a challenge for LLMs. Various methods for task ambiguity detection have been proposed. However, it is difficult to compare them because they are tested on different datasets and there is no universal benchmark. For this reason, we propose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual dataset of ambiguous instructions addressed to a robot in a kitchen environment. AmbiK was collected with the assistance of LLMs and is human-validated. It comprises 1000 pairs of ambiguous tasks and their unambiguous counterparts, categorized by ambiguity type (Human Preferences, Common Sense Knowledge, Safety), with environment descriptions, clarifying questions and answers, user intents, and task plans, for a total of 2000 tasks. We hope that AmbiK will enable researchers to perform a unified comparison of ambiguity detection methods. AmbiK is available at this https URL.', 'abstract_zh': '作为一种体现式代理的一部分，大型语言模型（LLMs）通常用于根据用户给出的自然语言指令进行行为规划。然而，处理现实环境中含糊不清的指令仍然是LLMs的一个挑战。已经提出了多种任务含糊性检测的方法，但由于它们在不同的数据集上进行测试且缺乏通用基准，难以进行比较。因此，我们提出了AmbiK（厨房环境中的含糊任务集），这是一个完全基于文本的含糊指令数据集，针对厨房环境中的机器人。AmbiK在LLMs的帮助下收集并通过人力验证。它包含1000对含糊任务及其不ambiguous的对应任务，按照含糊性类型（人类偏好、常识知识、安全）分类，并包括环境描述、澄清问题与答案、用户意图和任务计划，总共2000个任务。希望AmbiK能够使研究人员能够进行统一的含糊性检测方法比较。AmbiK可在以下链接获取：this https URL。', 'title_zh': 'AmbiK: 厨房环境中的模糊任务数据集'}
{'arxiv_id': 'arXiv:2506.04088', 'title': 'Multimodal Tabular Reasoning with Privileged Structured Information', 'authors': 'Jun-Peng Jiang, Yu Xia, Hai-Long Sun, Shiyin Lu, Qing-Guo Chen, Weihua Luo, Kaifu Zhang, De-Chuan Zhan, Han-Jia Ye', 'link': 'https://arxiv.org/abs/2506.04088', 'abstract': "Tabular reasoning involves multi-step information extraction and logical inference over tabular data. While recent advances have leveraged large language models (LLMs) for reasoning over structured tables, such high-quality textual representations are often unavailable in real-world settings, where tables typically appear as images. In this paper, we tackle the task of tabular reasoning from table images, leveraging privileged structured information available during training to enhance multimodal large language models (MLLMs). The key challenges lie in the complexity of accurately aligning structured information with visual representations, and in effectively transferring structured reasoning skills to MLLMs despite the input modality gap. To address these, we introduce TabUlar Reasoning with Bridged infOrmation ({\\sc Turbo}), a new framework for multimodal tabular reasoning with privileged structured tables. {\\sc Turbo} benefits from a structure-aware reasoning trace generator based on DeepSeek-R1, contributing to high-quality modality-bridged data. On this basis, {\\sc Turbo} repeatedly generates and selects the advantageous reasoning paths, further enhancing the model's tabular reasoning ability. Experimental results demonstrate that, with limited ($9$k) data, {\\sc Turbo} achieves state-of-the-art performance ($+7.2\\%$ vs. previous SOTA) across multiple datasets.", 'abstract_zh': '表格式推理涉及多步信息提取和对表格数据进行逻辑推理。虽然后来的工作利用大规模语言模型（LLMs）在结构化表格上进行推理，但在实际场景中，表格通常以图像形式出现，缺乏高质量的文本表示。本文致力于从表格图像进行表格式推理的任务，利用训练过程中可获得的特权结构信息来增强多模态大规模语言模型（MLLMs）。关键挑战在于精确对齐结构化信息与视觉表示的复杂性，以及在输入模态差距下有效转移结构化推理技能。为了解决这些问题，我们提出了一个名为Turbo的新框架，该框架基于DeepSeek-R1实现结构感知的推理轨迹生成器，从而生成高质量的模态桥梁数据。在此基础上，Turbo反复生成和选择有利的推理路径，进一步增强模型的表格式推理能力。实验结果显示，在有限（9k）数据下，Turbo在多个数据集上实现了最先进的性能（对比 previous SOTA 提高了 7.2%）。', 'title_zh': '带特权结构信息的多模态表格推理'}
{'arxiv_id': 'arXiv:2506.04079', 'title': 'EuroLLM-9B: Technical Report', 'authors': 'Pedro Henrique Martins, João Alves, Patrick Fernandes, Nuno M. Guerreiro, Ricardo Rei, Amin Farajian, Mateusz Klimaszewski, Duarte M. Alves, José Pombal, Manuel Faysse, Pierre Colombo, François Yvon, Barry Haddow, José G. C. de Souza, Alexandra Birch, André F. T. Martins', 'link': 'https://arxiv.org/abs/2506.04079', 'abstract': "This report presents EuroLLM-9B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-9B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. We describe the pre-training data collection and filtering pipeline, including the creation of EuroFilter, an AI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a novel synthetic dataset for post-training that enhances language coverage for European languages. Evaluation results demonstrate EuroLLM-9B's competitive performance on multilingual benchmarks and machine translation tasks, establishing it as the leading open European-made LLM of its size. To support open research and adoption, we release all major components of this work, including the base and instruction-tuned models, the EuroFilter classifier, and the synthetic post-training dataset.", 'abstract_zh': 'EuroLLM-9B：一种支持欧洲公民需求的大型语言模型，覆盖24种官方欧洲联盟语言和11种附加语言', 'title_zh': 'EuroLLM-9B: 技术报告'}
{'arxiv_id': 'arXiv:2506.04078', 'title': 'LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation', 'authors': 'Ming Zhang, Yujiong Shen, Zelin Li, Huayu Sha, Binze Hu, Yuhui Wang, Chenhao Huang, Shichun Liu, Jingqi Tong, Changhao Jiang, Mingxu Chai, Zhiheng Xi, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2506.04078', 'abstract': 'Evaluating large language models (LLMs) in medicine is crucial because medical applications require high accuracy with little room for error. Current medical benchmarks have three main types: medical exam-based, comprehensive medical, and specialized assessments. However, these benchmarks have limitations in question design (mostly multiple-choice), data sources (often not derived from real clinical scenarios), and evaluation methods (poor assessment of complex reasoning). To address these issues, we present LLMEval-Med, a new benchmark covering five core medical areas, including 2,996 questions created from real-world electronic health records and expert-designed clinical scenarios. We also design an automated evaluation pipeline, incorporating expert-developed checklists into our LLM-as-Judge framework. Furthermore, our methodology validates machine scoring through human-machine agreement analysis, dynamically refining checklists and prompts based on expert feedback to ensure reliability. We evaluate 13 LLMs across three categories (specialized medical models, open-source models, and closed-source models) on LLMEval-Med, providing valuable insights for the safe and effective deployment of LLMs in medical domains. The dataset is released in this https URL.', 'abstract_zh': '评估大型语言模型在医学领域的表现对于确保其在医学应用中的高准确性和可靠性至关重要。当前医学基准主要分为医学考试型、全面医学型和专科评估型三种。然而，这些基准在问题设计（主要是多项选择题）、数据来源（通常不来自真实的临床情景）和评估方法（难以评估复杂推理）方面存在局限性。为解决这些问题，我们提出了LLMEval-Med这一新的基准，涵盖了五个核心医学领域，包括2,996道基于真实电子健康记录和专家设计临床情景的问题。此外，我们设计了一个自动评估流程，将专家开发的检查表整合到我们的LLM-as-Judge框架中，并通过人类与机器的一致性分析验证机器评分，基于专家反馈动态优化检查表和提示，以确保可靠性。我们对13种不同类型的大型语言模型（包括专科医学模型、开源模型和闭源模型）进行了LLMEval-Med的评估，为大型语言模型在医学领域的安全和有效部署提供了有价值的见解。数据集可通过以下链接获取：https://www.example.com/dataset。', 'title_zh': 'LLMEval-Med: 医生验证的医疗LLM 实用临床基准'}
{'arxiv_id': 'arXiv:2506.04058', 'title': 'Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays', 'authors': 'Bulat Maksudov, Kathleen Curran, Alessandra Mileo', 'link': 'https://arxiv.org/abs/2506.04058', 'abstract': 'An essential step in deploying medical imaging models is ensuring alignment with clinical knowledge and interpretability. We focus on mapping clinical concepts into the latent space of generative models to identify Concept Activation Vectors (CAVs). Using a simple reconstruction autoencoder, we link user-defined concepts to image-level features without explicit label training. The extracted concepts are stable across datasets, enabling visual explanations that highlight clinically relevant features. By traversing latent space along concept directions, we produce counterfactuals that exaggerate or reduce specific clinical features. Preliminary results on chest X-rays show promise for large pathologies like cardiomegaly, while smaller pathologies remain challenging due to reconstruction limits. Although not outperforming baselines, this approach offers a path toward interpretable, concept-based explanations aligned with clinical knowledge.', 'abstract_zh': '部署医学成像模型的一个关键步骤是确保与临床知识的对齐和可解释性。我们专注于将临床概念映射到生成模型的潜在空间中以识别概念激活向量（CAVs）。通过一个简单的重建自编码器，我们将用户定义的概念与图像级特征关联起来，而无需显式的标签训练。提取的概念在不同数据集中具有稳定性，从而能够提供视觉解释，突出显示与临床相关的特征。通过沿着概念方向穿越潜在空间，我们生成了反事实样本，以夸大或减少特定的临床特征。初步结果表明，这种方法在胸片上对于大型病理学如心肌肥大具有潜力，而对于小型病理学则因重建限制而面临挑战。尽管不如基准模型优秀，但该方法为基于可解释性的、与临床知识一致的概念驱动解释提供了一条路径。', 'title_zh': '基于概念向量生成更具解释性的反事实例子：胸部X光片的初步研究'}
{'arxiv_id': 'arXiv:2506.04051', 'title': 'High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning', 'authors': 'Tim Franzmeyer, Archie Sravankumar, Lijuan Liu, Yuning Mao, Rui Hou, Sinong Wang, Jakob N. Foerster, Luke Zettlemoyer, Madian Khabsa', 'link': 'https://arxiv.org/abs/2506.04051', 'abstract': 'Large Language Models (LLMs) currently respond to every prompt. However, they can produce incorrect answers when they lack knowledge or capability -- a problem known as hallucination. We instead propose post-training an LLM to generate content only when confident in its correctness and to otherwise (partially) abstain. Specifically, our method, HALT, produces capability-aligned post-training data that encodes what the model can and cannot reliably generate. We generate this data by splitting responses of the pretrained LLM into factual fragments (atomic statements or reasoning steps), and use ground truth information to identify incorrect fragments. We achieve capability-aligned finetuning responses by either removing incorrect fragments or replacing them with "Unsure from Here" -- according to a tunable threshold that allows practitioners to trade off response completeness and mean correctness of the response\'s fragments. We finetune four open-source models for biography writing, mathematics, coding, and medicine with HALT for three different trade-off thresholds. HALT effectively trades off response completeness for correctness, increasing the mean correctness of response fragments by 15% on average, while resulting in a 4% improvement in the F1 score (mean of completeness and correctness of the response) compared to the relevant baselines. By tuning HALT for highest correctness, we train a single reliable Llama3-70B model with correctness increased from 51% to 87% across all four domains while maintaining 53% of the response completeness achieved with standard finetuning.', 'abstract_zh': 'Large Language Models (LLMs) Post-Training to Generate Content Only When Confident: A Capability-Aligned Approach to Reducing Hallucination', 'title_zh': '高精度，少冗言：通过能力对齐微调实现可靠的大语言模型'}
{'arxiv_id': 'arXiv:2506.04050', 'title': 'Explainability-Based Token Replacement on LLM-Generated Text', 'authors': 'Hadi Mohammadi, Anastasia Giachanou, Daniel L. Oberski, Ayoub Bagheri', 'link': 'https://arxiv.org/abs/2506.04050', 'abstract': "Generative models, especially large language models (LLMs), have shown remarkable progress in producing text that appears human-like. However, they often exhibit patterns that make their output easier to detect than text written by humans. In this paper, we investigate how explainable AI (XAI) methods can be used to reduce the detectability of AI-generated text (AIGT) while also introducing a robust ensemble-based detection approach. We begin by training an ensemble classifier to distinguish AIGT from human-written text, then apply SHAP and LIME to identify tokens that most strongly influence its predictions. We propose four explainability-based token replacement strategies to modify these influential tokens. Our findings show that these token replacement approaches can significantly diminish a single classifier's ability to detect AIGT. However, our ensemble classifier maintains strong performance across multiple languages and domains, showing that a multi-model approach can mitigate the impact of token-level manipulations. These results show that XAI methods can make AIGT harder to detect by focusing on the most influential tokens. At the same time, they highlight the need for robust, ensemble-based detection strategies that can adapt to evolving approaches for hiding AIGT.", 'abstract_zh': '可解释人工智能方法在生成人工智能文本不可检测性中的应用：一种基于稳健组合检测的方法', 'title_zh': '基于可解释性的令牌替换在生成文本上的应用'}
{'arxiv_id': 'arXiv:2506.04044', 'title': 'Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs', 'authors': 'Aleksey Kudelya, Alexander Shirnin', 'link': 'https://arxiv.org/abs/2506.04044', 'abstract': 'This paper describes LIBU (LoRA enhanced influence-based unlearning), an algorithm to solve the task of unlearning - removing specific knowledge from a large language model without retraining from scratch and compromising its overall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large Language Models). The algorithm combines classical \\textit{influence functions} to remove the influence of the data from the model and \\textit{second-order optimization} to stabilize the overall utility. Our experiments show that this lightweight approach is well applicable for unlearning LLMs in different kinds of task.', 'abstract_zh': 'LIBU（基于影响的LoRA增强未学习算法）：从大型语言模型中删除敏感内容的方法（SemEval-2025任务4：从大型语言模型中未学习敏感内容）', 'title_zh': 'Lacuna Inc. 在 SemEval-2025 任务 4 中：基于影响力的 LoRA 增强遗忘方法用于大语言模型'}
{'arxiv_id': 'arXiv:2506.04043', 'title': 'Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate', 'authors': 'Mikel K. Ngueajio, Flor Miriam Plaza-del-Arco, Yi-Ling Chung, Danda B. Rawat, Amanda Cercas Curry', 'link': 'https://arxiv.org/abs/2506.04043', 'abstract': "Automated counter-narratives (CN) offer a promising strategy for mitigating online hate speech, yet concerns about their affective tone, accessibility, and ethical risks remain. We propose a framework for evaluating Large Language Model (LLM)-generated CNs across four dimensions: persona framing, verbosity and readability, affective tone, and ethical robustness. Using GPT-4o-Mini, Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting strategies on the MT-Conan and HatEval datasets. Our findings reveal that LLM-generated CNs are often verbose and adapted for people with college-level literacy, limiting their accessibility. While emotionally guided prompts yield more empathetic and readable responses, there remain concerns surrounding safety and effectiveness.", 'abstract_zh': '基于大型语言模型的自动反叙事 framework for evaluating large language model-generated automated counter-narratives across four dimensions', 'title_zh': '以人为本进行思考：面向 Hate 对抗的人设引导大语言模型的多维度评估'}
{'arxiv_id': 'arXiv:2506.04039', 'title': 'Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization', 'authors': 'Jiulong Wu, Zhengliang Shi, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, Lingyong Yan, Min Cao, Min Zhang', 'link': 'https://arxiv.org/abs/2506.04039', 'abstract': 'Large Visual Language Models (LVLMs) have demonstrated impressive capabilities across multiple tasks. However, their trustworthiness is often challenged by hallucinations, which can be attributed to the modality misalignment and the inherent hallucinations of their underlying Large Language Models (LLMs) backbone. Existing preference alignment methods focus on aligning model responses with human preferences while neglecting image-text modality alignment, resulting in over-reliance on LLMs and hallucinations. In this paper, we propose Entity-centric Multimodal Preference Optimization (EMPO), which achieves enhanced modality alignment than existing human preference alignment methods. Besides, to overcome the scarcity of high-quality multimodal preference data, we utilize open-source instruction datasets to automatically construct high-quality preference data across three aspects: image, instruction, and response. Experiments on two human preference datasets and five multimodal hallucination benchmarks demonstrate the effectiveness of EMPO, e.g., reducing hallucination rates by 85.9% on Object-HalBench and 49.8% on MM-HalBench.', 'abstract_zh': '大型多模态语言模型（LVLMs）在多个任务中展现了令人印象深刻的性能。然而，其可信度常常受到幻觉的挑战，这可以归因于模态错位以及其底层大型语言模型（LLMs）骨干的固有幻觉。现有偏好对齐方法侧重于将模型响应与人类偏好对齐，而忽视了图像-文本模态对齐，从而过度依赖LLMs和幻觉。本文提出了以实体为中心的多模态偏好优化（EMPO），实现了与现有基于人类偏好的对齐方法相比增强的模态对齐。此外，为了克服高质量多模态偏好数据的稀缺性，我们利用开源指令数据集自动构建涵盖图像、指令和响应三方面高质量偏好数据。在两个基于人类偏好的数据集和五个多模态幻觉基准上的实验表明，EMPO的有效性，例如，在Object-HalBench上将幻觉率降低85.9%、在MM-HalBench上降低49.8%。', 'title_zh': '通过实体中心的多模态偏好优化减轻大型视觉-语言模型的幻觉问题'}
{'arxiv_id': 'arXiv:2506.04038', 'title': 'Generating Automotive Code: Large Language Models for Software Development and Verification in Safety-Critical Systems', 'authors': 'Sven Kirchner, Alois C. Knoll', 'link': 'https://arxiv.org/abs/2506.04038', 'abstract': 'Developing safety-critical automotive software presents significant challenges due to increasing system complexity and strict regulatory demands. This paper proposes a novel framework integrating Generative Artificial Intelligence (GenAI) into the Software Development Lifecycle (SDLC). The framework uses Large Language Models (LLMs) to automate code generation in languages such as C++, incorporating safety-focused practices such as static verification, test-driven development and iterative refinement. A feedback-driven pipeline ensures the integration of test, simulation and verification for compliance with safety standards. The framework is validated through the development of an Adaptive Cruise Control (ACC) system. Comparative benchmarking of LLMs ensures optimal model selection for accuracy and reliability. Results demonstrate that the framework enables automatic code generation while ensuring compliance with safety-critical requirements, systematically integrating GenAI into automotive software engineering. This work advances the use of AI in safety-critical domains, bridging the gap between state-of-the-art generative models and real-world safety requirements.', 'abstract_zh': '基于生成人工智能的软件开发生命周期框架：面向安全关键汽车软件的系统复杂性和严格监管要求的应对策略', 'title_zh': '生成汽车代码：大型语言模型在安全关键系统中进行软件开发与验证的应用'}
{'arxiv_id': 'arXiv:2506.04036', 'title': 'Privacy and Security Threat for OpenAI GPTs', 'authors': 'Wei Wenying, Zhao Kaifa, Xue Lei, Fan Ming', 'link': 'https://arxiv.org/abs/2506.04036', 'abstract': "Large language models (LLMs) demonstrate powerful information handling capabilities and are widely integrated into chatbot applications. OpenAI provides a platform for developers to construct custom GPTs, extending ChatGPT's functions and integrating external services. Since its release in November 2023, over 3 million custom GPTs have been created. However, such a vast ecosystem also conceals security and privacy threats. For developers, instruction leaking attacks threaten the intellectual property of instructions in custom GPTs through carefully crafted adversarial prompts. For users, unwanted data access behavior by custom GPTs or integrated third-party services raises significant privacy concerns. To systematically evaluate the scope of threats in real-world LLM applications, we develop three phases instruction leaking attacks target GPTs with different defense level. Our widespread experiments on 10,000 real-world custom GPTs reveal that over 98.8% of GPTs are vulnerable to instruction leaking attacks via one or more adversarial prompts, and half of the remaining GPTs can also be attacked through multiround conversations. We also developed a framework to assess the effectiveness of defensive strategies and identify unwanted behaviors in custom GPTs. Our findings show that 77.5% of custom GPTs with defense strategies are vulnerable to basic instruction leaking attacks. Additionally, we reveal that 738 custom GPTs collect user conversational information, and identified 8 GPTs exhibiting data access behaviors that are unnecessary for their intended functionalities. Our findings raise awareness among GPT developers about the importance of integrating specific defensive strategies in their instructions and highlight users' concerns about data privacy when using LLM-based applications.", 'abstract_zh': '大型语言模型（LLMs）展现出强大信息处理能力，并广泛应用于聊天机器人应用。OpenAI提供了一个平台，供开发者构建自定义GPT，扩展ChatGPT的功能并集成外部服务。自2023年11月发布以来，已有超过300万个自定义GPT被创建。然而，如此庞大的生态系统也隐藏着安全和隐私威胁。对于开发者来说，指令泄露攻击通过精心构造的对抗提示威胁到自定义GPT中指令的知识产权。对于用户来说，自定义GPT或集成的第三方服务的不当数据访问行为引起了显著的隐私关注。为了系统地评估现实世界大语言模型应用中的威胁范围，我们开发了针对不同防护级别的GPT进行三种阶段的指令泄露攻击。我们在10,000个实际应用的自定义GPT上进行了广泛实验，发现超过98.8%的GPT通过一个或多个对抗提示容易遭受指令泄露攻击，剩余的一半GPT也可以通过多轮对话被攻击。我们还开发了一个框架来评估防御策略的有效性并识别自定义GPT中的不当行为。我们的研究结果表明，77.5%配备防御策略的自定义GPT容易遭受基本的指令泄露攻击。此外，我们发现738个自定义GPT收集用户对话信息，并识别出8个表现出超出其功能需求的数据访问行为的GPT。我们的发现提高了GPT开发者对在其指令中集成特定防御策略重要性的认识，并突出了用户在使用基于大语言模型的应用时对数据隐私的关注。', 'title_zh': 'OpenAI GPTs的隐私与安全威胁'}
{'arxiv_id': 'arXiv:2506.04013', 'title': 'Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion', 'authors': 'Seymanur Akti, Tuan Nam Nguyen, Alexander Waibel', 'link': 'https://arxiv.org/abs/2506.04013', 'abstract': 'Expressive voice conversion aims to transfer both speaker identity and expressive attributes from a target speech to a given source speech. In this work, we improve over a self-supervised, non-autoregressive framework with a conditional variational autoencoder, focusing on reducing source timbre leakage and improving linguistic-acoustic disentanglement for better style transfer. To minimize style leakage, we use multilingual discrete speech units for content representation and reinforce embeddings with augmentation-based similarity loss and mix-style layer normalization. To enhance expressivity transfer, we incorporate local F0 information via cross-attention and extract style embeddings enriched with global pitch and energy features. Experiments show our model outperforms baselines in emotion and speaker similarity, demonstrating superior style adaptation and reduced source style leakage.', 'abstract_zh': '表达性语音转换旨在将目标语音的说话人身份和表达属性转移到给定的源语音中。在本文中，我们改进了基于自监督的非自回归框架，使用条件变分自编码器，专注于减少源音色泄漏并提高语言-声学解耦，以实现更好的风格转换。为了最小化风格泄漏，我们使用多语言离散语音单元进行内容表示，并通过基于增强的相似损失和混合风格层归一化增强嵌入。为了增强表达性转移，我们通过交叉注意机制引入局部F0信息，并提取富含全局音高和能量特征的风格嵌入。实验结果显示，我们的模型在情绪和说话人相似度上优于基线模型，证明其具有更好的风格适应性和减少源风格泄漏的能力。', 'title_zh': '面向更好的非自回归零样本表达语音转换中的独立成分分离'}
{'arxiv_id': 'arXiv:2506.04006', 'title': 'TransClean: Finding False Positives in Multi-Source Entity Matching under Real-World Conditions via Transitive Consistency', 'authors': 'Fernando de Meer Pardo, Branka Hadji Misheva, Martin Braschler, Kurt Stockinger', 'link': 'https://arxiv.org/abs/2506.04006', 'abstract': 'We present TransClean, a method for detecting false positive predictions of entity matching algorithms under real-world conditions characterized by large-scale, noisy, and unlabeled multi-source datasets that undergo distributional shifts. TransClean is explicitly designed to operate with multiple data sources in an efficient, robust and fast manner while accounting for edge cases and requiring limited manual labeling. TransClean leverages the Transitive Consistency of a matching, a measure of the consistency of a pairwise matching model f_theta on the matching it produces G_f_theta, based both on its predictions on directly evaluated record pairs and its predictions on implied record pairs. TransClean iteratively modifies a matching through gradually removing false positive matches while removing as few true positive matches as possible. In each of these steps, the estimation of the Transitive Consistency is exclusively done through model evaluations and produces quantities that can be used as proxies of the amounts of true and false positives in the matching while not requiring any manual labeling, producing an estimate of the quality of the matching and indicating which record groups are likely to contain false positives. In our experiments, we compare combining TransClean with a naively trained pairwise matching model (DistilBERT) and with a state-of-the-art end-to-end matching method (CLER) and illustrate the flexibility of TransClean in being able to detect most of the false positives of either setup across a variety of datasets. Our experiments show that TransClean induces an average +24.42 F1 score improvement for entity matching in a multi-source setting when compared to traditional pair-wise matching algorithms.', 'abstract_zh': 'TransClean: 一种检测实体匹配算法在大规模、 noisy、未标注多源数据集下的错误正预测的方法', 'title_zh': 'TransClean: 在实际条件下通过传递一致性查找多源实体匹配中的假阳性结果'}
{'arxiv_id': 'arXiv:2506.04001', 'title': 'CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor', 'authors': 'Han Ji, Yuqi Feng, Jiahao Fan, Yanan Sun', 'link': 'https://arxiv.org/abs/2506.04001', 'abstract': 'Performance predictors have emerged as a promising method to accelerate the evaluation stage of neural architecture search (NAS). These predictors estimate the performance of unseen architectures by learning from the correlation between a small set of trained architectures and their performance. However, most existing predictors ignore the inherent distribution shift between limited training samples and diverse test samples. Hence, they tend to learn spurious correlations as shortcuts to predictions, leading to poor generalization. To address this, we propose a Causality-guided Architecture Representation Learning (CARL) method aiming to separate critical (causal) and redundant (non-causal) features of architectures for generalizable architecture performance prediction. Specifically, we employ a substructure extractor to split the input architecture into critical and redundant substructures in the latent space. Then, we generate multiple interventional samples by pairing critical representations with diverse redundant representations to prioritize critical features. Extensive experiments on five NAS search spaces demonstrate the state-of-the-art accuracy and superior interpretability of CARL. For instance, CARL achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS.', 'abstract_zh': '因果引导的架构表示学习（CARL）方法：面向可泛化的架构性能预测', 'title_zh': 'CARL: 基于因果性的架构表示学习以构建可解释的性能预测器'}
{'arxiv_id': 'arXiv:2506.03964', 'title': 'Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection', 'authors': 'HyunGi Kim, Jisoo Mok, Dongjun Lee, Jaihyun Lew, Sungjae Kim, Sungroh Yoon', 'link': 'https://arxiv.org/abs/2506.03964', 'abstract': 'Utilizing the complex inter-variable causal relationships within multivariate time-series provides a promising avenue toward more robust and reliable multivariate time-series anomaly detection (MTSAD) but remains an underexplored area of research. This paper proposes Causality-Aware contrastive learning for RObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline that incorporates the notion of causality into contrastive learning. CAROTS employs two data augmentors to obtain causality-preserving and -disturbing samples that serve as a wide range of normal variations and synthetic anomalies, respectively. With causality-preserving and -disturbing samples as positives and negatives, CAROTS performs contrastive learning to train an encoder whose latent space separates normal and abnormal samples based on causality. Moreover, CAROTS introduces a similarity-filtered one-class contrastive loss that encourages the contrastive learning process to gradually incorporate more semantically diverse samples with common causal relationships. Extensive experiments on five real-world and two synthetic datasets validate that the integration of causal relationships endows CAROTS with improved MTSAD capabilities. The code is available at this https URL.', 'abstract_zh': '利用多变量时间序列内的复杂变量因果关系进行鲁棒多变量时间序列异常检测提供了极具前景的研究方向，但这一领域尚未得到充分探索。本文提出了一种因果关系感知对比学习方法，以实现鲁棒多变量时间序列异常检测（CAROTS），该方法将因果关系概念融入对比学习中。CAROTS采用两种数据增强器获取保留因果关系和破坏因果关系的样本，分别作为正常变异和合成异常的广泛范围。通过保留因果关系和破坏因果关系的样本作为正样本和负样本，CAROTS执行对比学习，以训练一个在潜在空间中基于因果关系将正常样本和异常样本分离的编码器。此外，CAROTS引入了一种基于相似性过滤的一类对比损失，鼓励对比学习过程逐渐纳入更多具有共同因果关系的语义多样样本。在五个真实世界和两个合成数据集上的广泛实验验证了因果关系集成赋予CAROTS改进的多变量时间序列异常检测能力。代码可在此链接访问。', 'title_zh': '因果关系意识对比学习在鲁棒多变量时间序列异常检测中的应用'}
{'arxiv_id': 'arXiv:2506.03954', 'title': 'HtFLlib: A Comprehensive Heterogeneous Federated Learning Library and Benchmark', 'authors': 'Jianqing Zhang, Xinghao Wu, Yanbing Zhou, Xiaoting Sun, Qiqi Cai, Yang Liu, Yang Hua, Zhenzhe Zheng, Jian Cao, Qiang Yang', 'link': 'https://arxiv.org/abs/2506.03954', 'abstract': 'As AI evolves, collaboration among heterogeneous models helps overcome data scarcity by enabling knowledge transfer across institutions and devices. Traditional Federated Learning (FL) only supports homogeneous models, limiting collaboration among clients with heterogeneous model architectures. To address this, Heterogeneous Federated Learning (HtFL) methods are developed to enable collaboration across diverse heterogeneous models while tackling the data heterogeneity issue at the same time. However, a comprehensive benchmark for standardized evaluation and analysis of the rapidly growing HtFL methods is lacking. Firstly, the highly varied datasets, model heterogeneity scenarios, and different method implementations become hurdles to making easy and fair comparisons among HtFL methods. Secondly, the effectiveness and robustness of HtFL methods are under-explored in various scenarios, such as the medical domain and sensor signal modality. To fill this gap, we introduce the first Heterogeneous Federated Learning Library (HtFLlib), an easy-to-use and extensible framework that integrates multiple datasets and model heterogeneity scenarios, offering a robust benchmark for research and practical applications. Specifically, HtFLlib integrates (1) 12 datasets spanning various domains, modalities, and data heterogeneity scenarios; (2) 40 model architectures, ranging from small to large, across three modalities; (3) a modularized and easy-to-extend HtFL codebase with implementations of 10 representative HtFL methods; and (4) systematic evaluations in terms of accuracy, convergence, computation costs, and communication costs. We emphasize the advantages and potential of state-of-the-art HtFL methods and hope that HtFLlib will catalyze advancing HtFL research and enable its broader applications. The code is released at this https URL.', 'abstract_zh': '异构联邦学习库：HtFLlib', 'title_zh': 'HtFLlib: 综合异构联邦学习库及基准'}
{'arxiv_id': 'arXiv:2506.03941', 'title': 'Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations', 'authors': 'Vivian Nguyen, Lillian Lee, Cristian Danescu-Niculescu-Mizil', 'link': 'https://arxiv.org/abs/2506.03941', 'abstract': "During a conversation, there can come certain moments where its outcome hangs in the balance. In these pivotal moments, how one responds can put the conversation on substantially different trajectories leading to significantly different outcomes. Systems that can detect when such moments arise could assist conversationalists in domains with highly consequential outcomes, such as mental health crisis counseling.\nIn this work, we introduce an unsupervised computational method for detecting such pivotal moments as they happen, in an online fashion. Our approach relies on the intuition that a moment is pivotal if our expectation of the outcome varies widely depending on what might be said next. By applying our method to crisis counseling conversations, we first validate it by showing that it aligns with human perception -- counselors take significantly longer to respond during moments detected by our method -- and with the eventual conversational trajectory -- which is more likely to change course at these times. We then use our framework to explore the relation of the counselor's response during pivotal moments with the eventual outcome of the session.", 'abstract_zh': '在对话中检测关键时刻的无监督计算方法：以危机咨询为例', 'title_zh': '悬而未决：危机咨询对话中的关键时刻'}
{'arxiv_id': 'arXiv:2506.03933', 'title': 'DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models', 'authors': 'Jia Fu, Yongtao Wu, Yihang Chen, Kunyu Peng, Xiao Zhang, Volkan Cevher, Sepideh Pashami, Anders Holst', 'link': 'https://arxiv.org/abs/2506.03933', 'abstract': 'Vision Language Models (VLMs) have shown remarkable capabilities in multimodal understanding, yet their susceptibility to perturbations poses a significant threat to their reliability in real-world applications. Despite often being imperceptible to humans, these perturbations can drastically alter model outputs, leading to erroneous interpretations and decisions. This paper introduces DiffCAP, a novel diffusion-based purification strategy that can effectively neutralize adversarial corruptions in VLMs. We observe that adding minimal noise to an adversarially corrupted image significantly alters its latent embedding with respect to VLMs. Building on this insight, DiffCAP cumulatively injects random Gaussian noise into adversarially perturbed input data. This process continues until the embeddings of two consecutive noisy images reach a predefined similarity threshold, indicating a potential approach to neutralize the adversarial effect. Subsequently, a pretrained diffusion model is employed to denoise the stabilized image, recovering a clean representation suitable for the VLMs to produce an output. Through extensive experiments across six datasets with three VLMs under varying attack strengths in three task scenarios, we show that DiffCAP consistently outperforms existing defense techniques by a substantial margin. Notably, DiffCAP significantly reduces both hyperparameter tuning complexity and the required diffusion time, thereby accelerating the denoising process. Equipped with strong theoretical and empirical support, DiffCAP provides a robust and practical solution for securely deploying VLMs in adversarial environments.', 'abstract_zh': '基于扩散的去 adversarial 腐蚀策略（DiffCAP）：一种有效净化视觉语言模型的新型方法', 'title_zh': 'DiffCAP：基于扩散的累积对抗净化方法用于视觉语言模型'}
{'arxiv_id': 'arXiv:2506.03930', 'title': 'VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation', 'authors': 'Yuansheng Ni, Ping Nie, Kai Zou, Xiang Yue, Wenhu Chen', 'link': 'https://arxiv.org/abs/2506.03930', 'abstract': 'Large language models (LLMs) often struggle with visualization tasks like plotting diagrams, charts, where success depends on both code correctness and visual semantics. Existing instruction-tuning datasets lack execution-grounded supervision and offer limited support for iterative code correction, resulting in fragile and unreliable plot generation. We present VisCode-200K, a large-scale instruction tuning dataset for Python-based visualization and self-correction. It contains over 200K examples from two sources: (1) validated plotting code from open-source repositories, paired with natural language instructions and rendered plots; and (2) 45K multi-turn correction dialogues from Code-Feedback, enabling models to revise faulty code using runtime feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly outperforms strong open-source baselines and approaches the performance of proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation protocol to assess iterative repair, demonstrating the benefits of feedback-driven learning for executable, visually accurate code generation.', 'abstract_zh': '大规模语言模型（LLMs）在可视化任务如绘制图表方面常遇到困难，这类任务的成功依赖于代码的正确性和视觉语义的准确表达。现有的指令调优数据集缺乏执行层面的监督，为迭代代码修正提供的支持有限，导致生成的图表脆弱且不可靠。我们提出了VisCode-200K，这是一个基于Python的大型指令调优数据集，用于可视化和自修正。它包含了超过200,000个实例，来源于两个来源：（1）来自开源代码库的验证过的绘图代码，配以自然语言指令和渲染图表；（2）来自Code-Feedback的45,000个多轮修正对话，使模型能够在运行时反馈驱动下修正错误代码。我们使用VisCode-200K对Qwen2.5-Coder-Instruct进行微调，生成VisCoder，并在PandasPlotBench上进行了评估。VisCoder显著优于开源基线，并接近专有模型如GPT-4o-mini的性能。我们进一步采用了一种自我调试评估协议来评估迭代修复，展示了反馈驱动学习对于生成可执行且视觉上准确的代码的益处。', 'title_zh': 'VisCoder: 细粒度调优大规模语言模型以生成可执行的Python可视化代码'}
{'arxiv_id': 'arXiv:2506.03880', 'title': 'RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing', 'authors': 'Ruihan Jin, Pengpeng Shao, Zhengqi Wen, Jinyang Wu, Mingkuan Feng, Shuai Zhang, Jianhua Tao', 'link': 'https://arxiv.org/abs/2506.03880', 'abstract': 'The rapid advancements in large language models (LLMs) have led to the emergence of routing techniques, which aim to efficiently select the optimal LLM from diverse candidates to tackle specific tasks, optimizing performance while reducing costs. Current LLM routing methods are limited in effectiveness due to insufficient exploration of the intrinsic connection between user queries and the characteristics of LLMs. To address this issue, in this paper, we present RadialRouter, a novel framework for LLM routing which employs a lightweight Transformer-based backbone with a radial structure named RadialFormer to articulate the query-LLMs relationship. The optimal LLM selection is performed based on the final states of RadialFormer. The pipeline is further refined by an objective function that combines Kullback-Leibler divergence with the query-query contrastive loss to enhance robustness. Experimental results on RouterBench show that RadialRouter significantly outperforms existing routing methods by 9.2\\% and 5.8\\% in the Balance and Cost First scenarios, respectively. Additionally, its adaptability toward different performance-cost trade-offs and the dynamic LLM pool demonstrates practical application potential.', 'abstract_zh': '大语言模型（LLMs）的迅速发展促进了路由技术的 emergence，这些技术旨在高效地从多种候选LLMs中选择最适合特定任务的理想LLM，以优化性能并降低成本。当前的LLM路由方法由于对用户查询与LLM特性之间内在联系的探索不足而受到限制。为解决这一问题，本文提出 RadialRouter，这是一种新型的LLM路由框架，采用带有径向结构的轻量级基于Transformer的骨干RadialFormer来表达查询-LLM关系。最优LLM的选择是基于RadialFormer的最终状态执行的。该 pipeline 通过结合Kullback-Leibler 散度和查询-查询对比损失的目标函数进一步优化，以增强鲁棒性。实验结果表明，RadialRouter 在 RouterBench 上的平衡场景和成本优先场景中分别优于现有路由方法 9.2% 和 5.8%，并且其不同性能成本权衡的适应性和动态LLM池显示了其实用应用潜力。', 'title_zh': 'RadialRouter: 一种高效的稳健大型语言模型路由结构表示'}
{'arxiv_id': 'arXiv:2506.03872', 'title': 'JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting', 'authors': 'Yang Xiao, Guoan Xu, Qiang Wu, Wenjing Jia', 'link': 'https://arxiv.org/abs/2506.03872', 'abstract': 'Reconstructing 3D scenes from sparse viewpoints is a long-standing challenge with wide applications. Recent advances in feed-forward 3D Gaussian sparse-view reconstruction methods provide an efficient solution for real-time novel view synthesis by leveraging geometric priors learned from large-scale multi-view datasets and computing 3D Gaussian centers via back-projection. Despite offering strong geometric cues, both feed-forward multi-view depth estimation and flow-depth joint estimation face key limitations: the former suffers from mislocation and artifact issues in low-texture or repetitive regions, while the latter is prone to local noise and global inconsistency due to unreliable matches when ground-truth flow supervision is unavailable. To overcome this, we propose JointSplat, a unified framework that leverages the complementarity between optical flow and depth via a novel probabilistic optimization mechanism. Specifically, this pixel-level mechanism scales the information fusion between depth and flow based on the matching probability of optical flow during training. Building upon the above mechanism, we further propose a novel multi-view depth-consistency loss to leverage the reliability of supervision while suppressing misleading gradients in uncertain areas. Evaluated on RealEstate10K and ACID, JointSplat consistently outperforms state-of-the-art (SOTA) methods, demonstrating the effectiveness and robustness of our proposed probabilistic joint flow-depth optimization approach for high-fidelity sparse-view 3D reconstruction.', 'abstract_zh': '从稀疏视角重建3D场景是长期存在的挑战，具有广泛的应用前景。近年来，基于前向传递的3D高斯稀疏视点重建方法通过利用大规模多视角数据集中学到的几何先验，并通过反投影计算3D高斯中心，提供了实时新颖视角合成的有效解决方案。尽管提供了强大的几何线索，但前向多视角深度估计和联合流-深度估计仍面临关键限制：前者在低纹理或重复区域遭受位置错误和伪影问题，而后者由于当缺乏地面真实流监督时难以可靠的匹配而导致局部噪声和全局不一致。为了克服这些限制，我们提出了一种联合点积（JointSplat）统一框架，通过一种新颖的概率优化机制利用流和深度之间的互补性。具体而言，在训练过程中，这种亚像素机制基于光学流的匹配概率来缩放深度和流之间的信息融合。在此机制的基础上，我们进一步提出了一种新颖的多视角一致深度损失，以利用监督的可靠性并抑制不确定区域中的误导梯度。在RealEstate10K和ACID上进行评估，JointSplat始终优于现有最佳方法，证明了我们提出的概率联合流-深度优化方法在高保真稀疏视点3D重建中的有效性和鲁棒性。', 'title_zh': 'JointSplat: 概率联合流-深度优化Sparse-视图ガウシアンスプラッティング'}
{'arxiv_id': 'arXiv:2506.03837', 'title': 'HTSC-2025: A Benchmark Dataset of Ambient-Pressure High-Temperature Superconductors for AI-Driven Critical Temperature Prediction', 'authors': 'Xiao-Qi Han, Ze-Feng Gao, Xin-De Wang, Zhenfeng Ouyang, Peng-Jie Guo, Zhong-Yi Lu', 'link': 'https://arxiv.org/abs/2506.03837', 'abstract': 'The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recent years, research on predicting superconducting transition temperatures using artificial intelligence~(AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present the HTSC-2025, an ambient-pressure high-temperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X$_2$YH$_6$ system, perovskite MXH$_3$ system, M$_3$XH$_8$ system, cage-like BCN-doped metal atomic systems derived from LaH$_{10}$ structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB$_2$. The HTSC-2025 benchmark has been open-sourced at this https URL and will be continuously updated. This benchmark holds significant importance for accelerating the discovery of superconducting materials using AI-based methods.', 'abstract_zh': '高温超导材料的发现对人类工业和日常生活具有重要意义。近年来，使用人工智能（AI）预测超导转变温度的研究吸引了广泛的关注，大多数工具声称能够达到显著的准确性。然而，该领域缺乏广泛接受的标准数据集严重阻碍了不同AI算法之间的公平比较，阻碍了这些方法的进一步发展。在此工作中，我们提出HTSC-2025，一个常压高温超导标准数据集。该综合编纂包括2023年至2025年由理论物理学家根据BCS超导理论预测的超导材料，包括著名的X₂YH₆系统、钙钛矿MXH₃系统、M₃XH₈系统、从LaH₁₀结构演变来的笼状BCN掺金属原子系统以及从MgB₂演化而来的二维蜂窝结构系统。HTSC-2025基准数据集已在该网址开放源代码，并将持续更新。该基准对于加速使用基于AI的方法发现超导材料具有重要意义。', 'title_zh': 'HTSC-2025：高压高温超导体基准数据集，用于AI驱动的临界温度预测'}
{'arxiv_id': 'arXiv:2506.03827', 'title': 'Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising', 'authors': 'Zhenhui Liu, Chunyuan Yuan, Ming Pang, Zheng Fang, Li Yuan, Xue Jiang, Changping Peng, Zhangang Lin, Zheng Luo, Jingping Shao', 'link': 'https://arxiv.org/abs/2506.03827', 'abstract': "Retrieval systems primarily address the challenge of matching user queries with the most relevant advertisements, playing a crucial role in e-commerce search advertising. The diversity of user needs and expressions often produces massive long-tail queries that cannot be matched with merchant bidwords or product titles, which results in some advertisements not being recalled, ultimately harming user experience and search efficiency. Existing query rewriting research focuses on various methods such as query log mining, query-bidword vector matching, or generation-based rewriting. However, these methods often fail to simultaneously optimize the relevance and authenticity of the user's original query and rewrite and maximize the revenue potential of recalled ads.\nIn this paper, we propose a Multi-objective aligned Bidword Generation Model (MoBGM), which is composed of a discriminator, generator, and preference alignment module, to address these challenges. To simultaneously improve the relevance and authenticity of the query and rewrite and maximize the platform revenue, we design a discriminator to optimize these key objectives. Using the feedback signal of the discriminator, we train a multi-objective aligned bidword generator that aims to maximize the combined effect of the three objectives. Extensive offline and online experiments show that our proposed algorithm significantly outperforms the state of the art. After deployment, the algorithm has created huge commercial value for the platform, further verifying its feasibility and robustness.", 'abstract_zh': '检索系统主要应对用户查询与最相关广告匹配的挑战，在电子商务搜索广告中发挥关键作用。用户的多样需求和表达方式常常会产生大量的长尾查询，这些查询无法与商家出价词或产品标题匹配，导致部分广告无法召回，最终损害用户体验和搜索效率。现有的查询重写研究侧重于查询日志挖掘、查询-出价词向量匹配或基于生成的重写等多种方法。然而，这些方法往往难以同时优化用户的原始查询和重写的相关性和真实性，并最大化召回广告的潜在收入。\n\n本文提出了一种多目标对齐出价词生成模型（MoBGM），该模型由判别器、生成器和偏好对齐模块组成，以应对这些挑战。为了同时提高查询和重写的相关性和真实性，并最大化平台收入，我们设计了一个判别器来优化这些关键目标。利用判别器的反馈信号，我们训练了一个多目标对齐出价词生成器，旨在最大化这三个目标的复合效果。广泛的离线和在线实验表明，我们提出的算法显著优于现有技术。部署后，该算法为平台创造了巨大的商业价值，进一步验证了其可行性和稳健性。', 'title_zh': '多目标对齐出价单词生成模型在电子商务搜索广告中的应用'}
{'arxiv_id': 'arXiv:2506.03785', 'title': 'Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons', 'authors': 'Isik Baran Sandan, Tu Anh Dinh, Jan Niehues', 'link': 'https://arxiv.org/abs/2506.03785', 'abstract': 'Large Language Models (LLMs) have shown to be effective evaluators across various domains such as machine translations or the scientific domain. Current LLM-as-a-Judge approaches rely mostly on individual assessments or a single round of pairwise assessments, preventing the judge LLM from developing a global ranking perspective. To address this, we present Knockout Assessment, an LLM-asa Judge method using a knockout tournament system with iterative pairwise comparisons. Experiments across three LLMs on two datasets show that knockout assessment improves scoring accuracy, increasing Pearson correlation with expert evaluations by 0.07 on average for university-level exam scoring and machine translation evaluations, aligning LLM assessments more closely with human scoring.', 'abstract_zh': '大型语言模型（LLMs）在机器翻译等领域显示了有效的评估能力。当前的LLM-as-a-Judge方法主要依赖个体评估或一轮pairwise评估，这妨碍了判断LLM形成全局排名视角。为了解决这个问题，我们提出了一种 Knockout Assessment 方法，该方法使用淘汰赛系统和迭代的pairwise比较。实验结果显示，Knockout Assessment 提高了评分准确性，在大学级考试评分和机器翻译评估中，与专家评分的皮尔森相关系数平均提高了0.07，使LLM评估更接近人类评分。', 'title_zh': 'Knockout LLM评估：通过迭代的成对比较使用大型语言模型进行评估'}
{'arxiv_id': 'arXiv:2506.03784', 'title': 'When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective', 'authors': 'Beatrix M. G. Nielsen, Emanuele Marconato, Andrea Dittadi, Luigi Gresele', 'link': 'https://arxiv.org/abs/2506.03784', 'abstract': 'When and why representations learned by different deep neural networks are similar is an active research topic. We choose to address these questions from the perspective of identifiability theory, which suggests that a measure of representational similarity should be invariant to transformations that leave the model distribution unchanged. Focusing on a model family which includes several popular pre-training approaches, e.g., autoregressive language models, we explore when models which generate distributions that are close have similar representations. We prove that a small Kullback-Leibler divergence between the model distributions does not guarantee that the corresponding representations are similar. This has the important corollary that models arbitrarily close to maximizing the likelihood can still learn dissimilar representations, a phenomenon mirrored in our empirical observations on models trained on CIFAR-10. We then define a distributional distance for which closeness implies representational similarity, and in synthetic experiments, we find that wider networks learn distributions which are closer with respect to our distance and have more similar representations. Our results establish a link between closeness in distribution and representational similarity.', 'abstract_zh': '不同深度神经网络learned表示在何时以及为何相似：从可识别性理论视角探究', 'title_zh': '分布接近性是否意味着表征相似性？从可识别性角度探讨'}
{'arxiv_id': 'arXiv:2506.03762', 'title': 'AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models', 'authors': 'Yifeng Gu, Zicong Jiang, Jianxiu Jin, Kailing Guo, Ziyang Zhang, Xiangmin Xu', 'link': 'https://arxiv.org/abs/2506.03762', 'abstract': "Large Language Models (LLMs) have significantly advanced the field of Artificial Intelligence. However, their deployment is resource-intensive, not only due to the large number of model parameters but also because the (Key-Value) KV cache consumes a lot of memory during inference. While several works propose reducing the KV cache by evicting the unnecessary tokens, these approaches rely on accumulated attention score as eviction score to quantify the importance of the token. We identify the accumulated attention score is biased and it decreases with the position of the tokens in the mathematical expectation. As a result, the retained tokens concentrate on the initial positions, limiting model's access to global contextual information. To address this issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the bias of the accumulated attention score by adaptively tuning the scale of softmax according the expectation of information entropy of attention scores. To make use of the holistic attention information in self-attention mechanism, AhaKV utilize the information of value vectors, which is overlooked in previous works, to refine the adaptive score. We show theoretically that our method is well suited for bias reduction. We deployed AhaKV on different models with a fixed cache budget. Experiments show that AhaKV successfully mitigates bias and retains crucial tokens across global context and achieve state-of-the-art results against other related work on several benchmark tasks.", 'abstract_zh': '大语言模型（LLMs）在人工智能领域取得了显著进展。然而，其部署资源密集，不仅因为模型参数量庞大，还在推理过程中消耗大量内存来维持（键-值）KV缓存。尽管有若干工作提出通过移除不必要的令牌来减少KV缓存，这些方法依赖累积注意力分数作为移除分数来量化令牌的重要性。我们发现累积注意力分数存在偏差，在数学期望下随令牌位置增加而减少。因此，保留的令牌集中在初始位置，限制了模型获取全局上下文信息的能力。为解决这一问题，我们提出了自适应全局注意力KV（AhaKV），通过根据注意力分数的信息熵期望自适应调整softmax的比例来减轻累积注意力分数的偏差。为了利用自注意力机制中的全局注意力信息，AhaKV利用值向量的信息，弥补了先前工作中的不足，以优化自适应评分。我们理论上证明了该方法适合于偏差减少。我们在固定缓存预算下将AhaKV部署到不同的模型上。实验表明，AhaKV成功减轻了偏差，保留了跨全局上下文的关键令牌，并在若干基准任务上取得了最佳结果，优于其他相关工作。', 'title_zh': 'AhaKV：自适应全局注意力驱动的键值缓存淘汰机制以实现大型语言模型高效推理'}
{'arxiv_id': 'arXiv:2506.03758', 'title': 'Scaling CrossQ with Weight Normalization', 'authors': 'Daniel Palenicek, Florian Vogt, Jan Peters', 'link': 'https://arxiv.org/abs/2506.03758', 'abstract': "Reinforcement learning has achieved significant milestones, but sample efficiency remains a bottleneck for real-world applications. Recently, CrossQ has demonstrated state-of-the-art sample efficiency with a low update-to-data (UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with higher UTD ratios. We identify challenges in the training dynamics which are emphasized by higher UTDs, particularly Q-bias explosion and the growing magnitude of critic network weights. To address this, we integrate weight normalization into the CrossQ framework, a solution that stabilizes training, prevents potential loss of plasticity and keeps the effective learning rate constant. Our proposed approach reliably scales with increasing UTD ratios, achieving competitive or superior performance across a range of challenging tasks on the DeepMind control benchmark, notably the complex dog and humanoid environments. This work eliminates the need for drastic interventions, such as network resets, and offers a robust pathway for improving sample efficiency and scalability in model-free reinforcement learning.", 'abstract_zh': '强化学习在实现重要里程碑的同时，样本效率仍是一个制约实际应用的瓶颈。最近，CrossQ展现了最先进的样本效率，其更新与数据的比率为1。本文探讨了在较高更新与数据比（UTD）下CrossQ的可扩展性。我们识别出在较高UTD下突出的训练动力学挑战，特别是Q偏差爆炸和批评网络权重不断增加的幅度。为解决这一问题，我们将权重归一化整合进CrossQ框架，该方法稳定了训练过程，防止可能的可塑性丢失，并保持有效的学习率恒定。我们提出的方法在不断增加的UTD比率下可靠地扩展，实现了在DeepMind控制基准测试中一系列具有挑战性的任务上具有竞争力或优越的表现，尤其是在复杂的狗和 humanoid环境。本文消除了对激进干预（如网络重置）的需要，并为模型自由强化学习中提高样本效率和可扩展性提供了一条稳健的路径。', 'title_zh': 'Scaling CrossQ with Weight Normalization'}
{'arxiv_id': 'arXiv:2506.03755', 'title': 'Misalignment or misuse? The AGI alignment tradeoff', 'authors': 'Max Hellrigel-Holderbaum, Leonard Dung', 'link': 'https://arxiv.org/abs/2506.03755', 'abstract': 'Creating systems that are aligned with our goals is seen as a leading approach to create safe and beneficial AI in both leading AI companies and the academic field of AI safety. We defend the view that misaligned AGI - future, generally intelligent (robotic) AI agents - poses catastrophic risks. At the same time, we support the view that aligned AGI creates a substantial risk of catastrophic misuse by humans. While both risks are severe and stand in tension with one another, we show that - in principle - there is room for alignment approaches which do not increase misuse risk. We then investigate how the tradeoff between misalignment and misuse looks empirically for different technical approaches to AI alignment. Here, we argue that many current alignment techniques and foreseeable improvements thereof plausibly increase risks of catastrophic misuse. Since the impacts of AI depend on the social context, we close by discussing important social factors and suggest that to reduce the risk of a misuse catastrophe due to aligned AGI, techniques such as robustness, AI control methods and especially good governance seem essential.', 'abstract_zh': '创建与我们目标一致的系统被视为在领先的人工智能公司和人工智能安全的学术领域中创建安全且有益的人工智能的主要途径。我们认为，未来普遍智能的人工智能代理的失控行为将带来灾难性风险。同时，我们支持观点认为，可控的人工智能代理同样存在因人类滥用而导致灾难性风险的可能性。尽管这两种风险都很严重且相互矛盾，但我们证明，在原则上存在不增加滥用风险的对齐方法。随后，我们探讨了不同类型的人工智能对齐技术在实际应用中失控行为与滥用风险之间的权衡。我们指出，目前许多对齐技术及其可预见的改进很可能是增加了灾难性滥用风险。由于人工智能的影响依赖于社会环境，我们最后讨论了重要社会因素，并建议为了降低因可控人工智能代理的滥用而导致的灾难性风险，必须具备鲁棒性、人工智能控制方法和特别有效治理措施。', 'title_zh': 'AGI对齐失调或误用？'}
{'arxiv_id': 'arXiv:2506.03740', 'title': 'SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution', 'authors': 'Jianfeng Wu, Nannan Xu', 'link': 'https://arxiv.org/abs/2506.03740', 'abstract': 'Single image super-resolution is a well-known downstream task which aims to restore low-resolution images into high-resolution images. At present, models based on Transformers have shone brightly in the field of super-resolution due to their ability to capture long-term dependencies in information. However, current methods typically compute self-attention in nonoverlapping windows to save computational costs, and the standard self-attention computation only focuses on its results, thereby neglecting the useful information across channels and the rich spatial structural information generated in the intermediate process. Channel attention and spatial attention have, respectively, brought significant improvements to various downstream visual tasks in terms of extracting feature dependency and spatial structure relationships, but the synergistic relationship between channel and spatial attention has not been fully explored this http URL address these issues, we propose a novel model. Synergistic Alternating Aggregation Transformer (SAAT), which can better utilize the potential information of features. In SAAT, we introduce the Efficient Channel & Window Synergistic Attention Group (CWSAG) and the Spatial & Window Synergistic Attention Group (SWSAG). On the one hand, CWSAG combines efficient channel attention with shifted window attention, enhancing non-local feature fusion, and producing more visually appealing results. On the other hand, SWSAG leverages spatial attention to capture rich structured feature information, thereby enabling SAAT to more effectively extract structural this http URL experimental results and ablation studies demonstrate the effectiveness of SAAT in the field of super-resolution. SAAT achieves performance comparable to that of the state-of-the-art (SOTA) under the same quantity of parameters.', 'abstract_zh': '单图像超分辨率是一种广为人知的下游任务，旨在将低分辨率图像恢复为高分辨率图像。现有的基于Transformer的模型在超分辨率领域因其能够捕获长程依赖关系而表现出色。然而，当前的方法通常通过在非重叠窗口中计算自注意力来节约计算成本，而标准的自注意力计算仅关注其结果，从而忽视了通道间有用的信息以及中间过程中生成的丰富空间结构信息。通道注意力和空间注意力在提升各种下游视觉任务的特征依赖性和空间结构关系方面分别带来了显著的改进，但通道和空间注意力之间的协同关系尚未得到充分探索。为了应对这些挑战，我们提出了一种新颖的模型——协同交替聚集变换器（SAAT），该模型能够更好地利用特征的潜在信息。在SAAT中，我们引入了高效通道与窗口协同注意力组（CWSAG）和空间与窗口协同注意力组（SWSAG）。一方面，CWSAG结合了高效的通道注意力与移位窗口注意力，增强非局部特征融合，产生更令人满意的结果。另一方面，SWSAG利用空间注意力来捕获丰富的结构化特征信息，从而使SAAT更有效地提取结构信息。实验结果和消融研究证明了SAAT在超分辨率领域的有效性。SAAT在相同参数量的情况下，性能达到了与现有最佳方法（SOTA）相当的水平。', 'title_zh': 'SAAT: 协同交替聚合变换器用于图像超分辨率'}
{'arxiv_id': 'arXiv:2506.03737', 'title': 'ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices', 'authors': 'Hao Yu, Tangyu Jiang, Shuning Jia, Shannan Yan, Shunning Liu, Haolong Qian, Guanghao Li, Shuting Dong, Huaisong Zhang, Chun Yuan', 'link': 'https://arxiv.org/abs/2506.03737', 'abstract': "The Transformer architecture has revolutionized various regions since it was proposed, and its effectiveness largely depends on the ability to encode positional information. Traditional position encoding methods exhibit significant limitations due to lack of robustness and flexibility of position. Therefore, Rotary Positional Encoding (RoPE) was proposed to alleviate these issues, which integrates positional information by rotating the embeddings in the attention mechanism. However, RoPE requires manually defined rotation matrices with limited transformation space, constraining the model's capacity. In this work, we propose ComRoPE, which generalizes RoPE by defining it in terms of trainable commuting angle matrices. Specifically, we demonstrate that pairwise commutativity of these matrices is essential for RoPE to achieve scalability and positional robustness. We formally define the RoPE Equation, which is an essential condition that ensures consistent performance with position offsets. Based on the theoretical analysis, we present two types of trainable commuting angle matrices as sufficient solutions to the RoPE equation, which significantly improve performance, surpassing the current state-of-the-art method by 1.6% at training resolution and 2.9% at higher resolution on the ImageNet-1K dataset. Furthermore, our framework shows versatility in generalizing to existing RoPE formulations and offering new insights for future positional encoding research. To ensure reproducibility, the source code and instructions are available at this https URL", 'abstract_zh': 'Transformer架构自提出以来已经革命性地改变了多个领域，其有效性很大程度上取决于编码位置信息的能力。传统的位置编码方法因位置的鲁棒性和灵活性不足而表现出明显的局限性，因此提出了旋转位置编码（RoPE）以缓解这些问题，通过在注意力机制中旋转嵌入来集成位置信息。然而，RoPE需要手动定义的旋转矩阵，其变换空间有限，限制了模型的能力。在此工作中，我们提出ComRoPE，通过将RoPE定义为可训练的可交换角矩阵来推广RoPE。具体而言，我们证明了这些矩阵的成对可交换性是RoPE实现可扩展性和位置鲁棒性的必要条件。基于理论分析，我们提出了两种类型的可训练可交换角矩阵作为RoPE方程的充分解，显著提高了性能，在ImageNet-1K数据集上，与当前最先进的方法相比，在训练分辨率上提高了1.6%，在较高分辨率上提高了2.9%。此外，我们的框架展示了在现有RoPE形式化方法上的一般性和对未来位置编码研究的新见解，以确保可重复性，源代码和说明可在以下网址获取。', 'title_zh': 'ComRoPE: 可训练共轭角矩阵参数化的可扩展且鲁棒的旋转位置嵌入'}
{'arxiv_id': 'arXiv:2506.03735', 'title': 'Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models', 'authors': 'Junling Wang, Anna Rutkiewicz, April Yi Wang, Mrinmaya Sachan', 'link': 'https://arxiv.org/abs/2506.03735', 'abstract': 'Visuals are valuable tools for teaching math word problems (MWPs), helping young learners interpret textual descriptions into mathematical expressions before solving them. However, creating such visuals is labor-intensive and there is a lack of automated methods to support this process. In this paper, we present Math2Visual, an automatic framework for generating pedagogically meaningful visuals from MWP text descriptions. Math2Visual leverages a pre-defined visual language and a design space grounded in interviews with math teachers, to illustrate the core mathematical relationships in MWPs. Using Math2Visual, we construct an annotated dataset of 1,903 visuals and evaluate Text-to-Image (TTI) models for their ability to generate visuals that align with our design. We further fine-tune several TTI models with our dataset, demonstrating improvements in educational visual generation. Our work establishes a new benchmark for automated generation of pedagogically meaningful visuals and offers insights into key challenges in producing multimodal educational content, such as the misrepresentation of mathematical relationships and the omission of essential visual elements.', 'abstract_zh': '视觉工具是教授数学文字问题（MWPs）的有效工具，有助于年轻学生将文本描述转化为数学表达式以便解决。然而，创建这些视觉工具是劳动密集型的，并且缺乏自动化的支持方法。在这篇论文中，我们提出了Math2Visual，这是一种自动框架，用于从MWP文本描述生成具有教育意义的视觉工具。Math2Visual 利用预先定义的视觉语言和基于数学教师访谈的设计空间，以说明MWPs中的核心数学关系。使用Math2Visual，我们构建了一个包含1,903个注释视觉的数据库，并评估了文本到图像（TTI）模型生成符合我们设计的视觉的能力。我们进一步使用该数据库对几种TTI模型进行了微调，展示了在教育视觉生成方面的改进。我们的工作为自动化生成具有教育意义的视觉工具建立了新的基准，并提供了关于多模态教育内容生成的关键挑战的见解，如数学关系的误表征和关键视觉元素的缺失。', 'title_zh': '为数学应用题生成具有教学意义的可视化内容：一个新的基准和文本到图像模型的分析'}
{'arxiv_id': 'arXiv:2506.03723', 'title': 'Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision', 'authors': 'Chaeyun Jang, Moonseok Choi, Yegon Kim, Hyungi Lee, Juho Lee', 'link': 'https://arxiv.org/abs/2506.03723', 'abstract': "Uncertainty calibration is essential for the safe deployment of large language models (LLMs), particularly when users rely on verbalized confidence estimates. While prior work has focused on classifiers or short-form generation, confidence calibration for chain-of-thought (CoT) reasoning remains largely unexplored. Surprisingly, we find that supervised fine-tuning with scalar confidence labels alone suffices to elicit self-verification behavior of language models, without any explicit reasoning supervision or reinforcement learning-based rewards. Despite being trained only to produce a verbalized confidence score without any self-verifying examples, the model learns to generate longer and self-checking responses for low-confidence queries while providing more concise answers for high-confidence ones. We further propose a simple rethinking method that boosts performance via test-time scaling based on calibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such as MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning improves both calibration and accuracy, while also enhancing interpretability by aligning the model's reasoning path with its confidence.", 'abstract_zh': '大型语言模型（LLMs）的安全部署需要不确定性校准，特别是在用户依赖于口头化的置信度估计时。尽管先前的工作主要集中在分类器或短文本生成上，链式思考（CoT）推理的置信度校准仍是一个尚未充分探索的领域。令人惊讶的是，我们发现仅通过标注标量置信度标签的监督微调就足以引起语言模型的自我验证行为，而不需要任何显式的推理监督或基于强化学习的奖励。尽管仅训练模型生成口头化的置信度评分而没有自我验证的例子，该模型仍能够学习在低置信度查询中生成更长且自我检查的回答，在高置信度查询中提供更简洁的答案。我们进一步提出了一种简单的重新思考方法，通过测试时的标度来提高性能，基于校准的不确定性。对于GSM8K以及保留的推理任务如MATH-500和ARC-Challenge的实验表明，我们的置信度aware微调不仅提高了校准和准确率，还通过使模型的推理路径与置信度对齐从而增强了可解释性。', 'title_zh': '口头表达的自信触发自我验证：无需显式推理监督的 emergent 行为'}
{'arxiv_id': 'arXiv:2506.03710', 'title': 'OSGNet @ Ego4D Episodic Memory Challenge 2025', 'authors': 'Yisen Feng, Haoyu Zhang, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie', 'link': 'https://arxiv.org/abs/2506.03710', 'abstract': 'In this report, we present our champion solutions for the three egocentric video localization tracks of the Ego4D Episodic Memory Challenge at CVPR 2025. All tracks require precise localization of the interval within an untrimmed egocentric video. Previous unified video localization approaches often rely on late fusion strategies, which tend to yield suboptimal results. To address this, we adopt an early fusion-based video localization model to tackle all three tasks, aiming to enhance localization accuracy. Ultimately, our method achieved first place in the Natural Language Queries, Goal Step, and Moment Queries tracks, demonstrating its effectiveness. Our code can be found at this https URL.', 'abstract_zh': '在Ego4D Episodic Memory Challenge 2025的三项以自我为中心的视频定位赛道中，我们呈现了我们的冠军解决方案。所有赛道均要求在未剪辑的以自我为中心的视频中精确定位时间区间。以往的统一视频定位方法通常依赖于后期融合策略，这往往会导致次优结果。为了解决这一问题，我们采用了基于早期融合的视频定位模型来应对所有三个任务，旨在提高定位准确性。最终，我们的方法在自然语言查询、目标步骤和时刻查询赛道中均获得了第一名，证明了其有效性。我们的代码可在以下链接找到：这个 https URL。', 'title_zh': 'OSGNet @ Ego4D 回忆挑战2025'}
{'arxiv_id': 'arXiv:2506.03682', 'title': 'How PARTs assemble into wholes: Learning the relative composition of images', 'authors': 'Melika Ayoughi, Samira Abnar, Chen Huang, Chris Sandino, Sayeri Lala, Eeshan Gunesh Dhekane, Dan Busbridge, Shuangfei Zhai, Vimal Thilak, Josh Susskind, Pascal Mettes, Paul Groth, Hanlin Goh', 'link': 'https://arxiv.org/abs/2506.03682', 'abstract': 'The composition of objects and their parts, along with object-object positional relationships, provides a rich source of information for representation learning. Hence, spatial-aware pretext tasks have been actively explored in self-supervised learning. Existing works commonly start from a grid structure, where the goal of the pretext task involves predicting the absolute position index of patches within a fixed grid. However, grid-based approaches fall short of capturing the fluid and continuous nature of real-world object compositions. We introduce PART, a self-supervised learning approach that leverages continuous relative transformations between off-grid patches to overcome these limitations. By modeling how parts relate to each other in a continuous space, PART learns the relative composition of images-an off-grid structural relative positioning process that generalizes beyond occlusions and deformations. In tasks requiring precise spatial understanding such as object detection and time series prediction, PART outperforms strong grid-based methods like MAE and DropPos, while also maintaining competitive performance on global classification tasks with minimal hyperparameter tuning. By breaking free from grid constraints, PART opens up an exciting new trajectory for universal self-supervised pretraining across diverse datatypes-from natural images to EEG signals-with promising potential in video, medical imaging, and audio.', 'abstract_zh': '对象及其部件的组成和对象间的空间关系提供了丰富的信息来源，用于表示学习。因此，具有空间意识的预训练任务在自我监督学习中被积极研究。现有工作通常基于网格结构，预训练任务的目标是在固定网格内预测补丁的绝对位置索引。然而，基于网格的方法难以捕捉现实世界中对象组成流体和连续的特性。我们提出了PART，一种利用离网补丁之间连续相对变换的自我监督学习方法，以克服这些限制。通过在连续空间中建模部件之间的关系，PART 学习图像的相对组成——一种离网结构的相对定位过程，可以超越遮挡和变形进行泛化。在需要精确空间理解的任务如物体检测和时间序列预测中，PART 在各类任务中均优于强大的基于网格方法如MAE和DropPos，同时在全局分类任务中保持了竞争力，且无需大量超参数调整。通过摆脱网格约束，PART 为跨多种数据类型的通用自我监督预训练开辟了一条新的路径，包括自然图像、EEG信号等，并在视频、医学成像和音频领域展现出巨大的潜力。', 'title_zh': 'How PARTs组装成 wholes: 学习图像的相对组成'}
{'arxiv_id': 'arXiv:2506.03667', 'title': 'Accelerating SfM-based Pose Estimation with Dominating Set', 'authors': 'Joji Joseph, Bharadwaj Amrutur, Shalabh Bhatnagar', 'link': 'https://arxiv.org/abs/2506.03667', 'abstract': 'This paper introduces a preprocessing technique to speed up Structure-from-Motion (SfM) based pose estimation, which is critical for real-time applications like augmented reality (AR), virtual reality (VR), and robotics. Our method leverages the concept of a dominating set from graph theory to preprocess SfM models, significantly enhancing the speed of the pose estimation process without losing significant accuracy. Using the OnePose dataset, we evaluated our method across various SfM-based pose estimation techniques. The results demonstrate substantial improvements in processing speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers a promising solution for efficient and accurate 3D pose estimation, balancing speed and accuracy in real-time applications.', 'abstract_zh': '本文介绍了一种预处理技术，用于加速基于结构从运动（SfM）的姿态估计，这对于增强现实（AR）、虚拟现实（VR）和机器人领域的实时应用至关重要。我们的方法利用图论中的支配集概念对SfM模型进行预处理，显著提高了姿态估计的速度，同时没有丢失显著的准确性。利用OnePose数据集，我们评估了该方法在各种基于SfM的姿态估计技术中的表现。结果表明，在处理速度上取得了显著改进，范围从1.5到14.48倍，并且参考图像和点云大小分别减少了17-23倍和2.27-4倍。本工作提供了一种高效准确的3D姿态估计的 promising 解决方案，在实时应用中平衡了速度和准确性。', 'title_zh': '基于支配集加速结构从运动姿态估计'}
{'arxiv_id': 'arXiv:2506.03654', 'title': 'MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection', 'authors': 'Xiaochun Lei, Siqi Wu, Weilin Wu, Zetao Jiang', 'link': 'https://arxiv.org/abs/2506.03654', 'abstract': 'Real-time object detection is a fundamental but challenging task in computer vision, particularly when computational resources are limited. Although YOLO-series models have set strong benchmarks by balancing speed and accuracy, the increasing need for richer global context modeling has led to the use of Transformer-based architectures. Nevertheless, Transformers have high computational complexity because of their self-attention mechanism, which limits their practicality for real-time and edge deployments. To overcome these challenges, recent developments in linear state space models, such as Mamba, provide a promising alternative by enabling efficient sequence modeling with linear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel object detection framework that balances accuracy and efficiency through three key contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs with Mamba to effectively capture both local features and long-range dependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an enhanced feature pyramid architecture that improves multi-scale object detection across various object sizes; and (3) Edge-focused Efficiency: our method achieved 66.6\\% mAP at 31.9 FPS on the PASCAL VOC dataset without any pre-training and supports deployment on edge devices such as the NVIDIA Jetson Xavier NX and Orin NX.', 'abstract_zh': '基于Mamba的实时物体检测框架MambaNeXt-YOLO：平衡准确性和效率的新方法', 'title_zh': 'MambaNeXt-YOLO: 一种用于实时目标检测的混合状态空间模型'}
{'arxiv_id': 'arXiv:2506.03642', 'title': 'Spatial Understanding from Videos: Structured Prompts Meet Simulation Data', 'authors': 'Haoyu Zhang, Meng Liu, Zaijing Li, Haokun Wen, Weili Guan, Yaowei Wang, Liqiang Nie', 'link': 'https://arxiv.org/abs/2506.03642', 'abstract': 'Visual-spatial understanding, the ability to infer object relationships and layouts from visual input, is fundamental to downstream tasks such as robotic navigation and embodied interaction. However, existing methods face spatial uncertainty and data scarcity, limiting the 3D spatial reasoning capability of pre-trained vision-language models (VLMs). To address these challenges, we present a unified framework for enhancing 3D spatial reasoning in pre-trained VLMs without modifying their architecture. This framework combines SpatialMind, a structured prompting strategy that decomposes complex scenes and questions into interpretable reasoning steps, with ScanForgeQA, a scalable question-answering dataset built from diverse 3D simulation scenes through an automated construction process designed for fine-tuning. Extensive experiments across multiple benchmarks demonstrate the individual and combined effectiveness of our prompting and fine-tuning strategies, and yield insights that may inspire future research on visual-spatial understanding.', 'abstract_zh': '视觉空间理解能力，即从视觉输入中推断物体关系和布局的能力，是诸如机器人导航和实体交互等下游任务的基础。然而，现有的方法面临空间不确定性与数据稀缺性的问题，限制了预训练视觉-语言模型（VLMs）的3D空间推理能力。为解决这些挑战，我们提出了一种无需修改架构即可增强预训练VLMs的3D空间推理能力的统一框架。该框架结合了SpatialMind，一种结构化的提示策略，将复杂场景和问题分解为可解释的推理步骤，以及ScanForgeQA，一种通过自动化构建过程从多种3D模拟场景中生成、适用于微调的可扩展问答数据集。跨多个基准的广泛实验表明，我们的提示和微调策略的个体及联合效果，并为未来视觉空间理解研究提供了启示。', 'title_zh': '基于视频的空间理解：结构化提示与模拟数据相结合'}
{'arxiv_id': 'arXiv:2506.03637', 'title': 'RewardAnything: Generalizable Principle-Following Reward Models', 'authors': 'Zhuohao Yu, Jiali Zeng, Weizheng Gu, Yidong Wang, Jindong Wang, Fandong Meng, Jie Zhou, Yue Zhang, Shikun Zhang, Wei Ye', 'link': 'https://arxiv.org/abs/2506.03637', 'abstract': 'Reward Models, essential for guiding Large Language Model optimization, are typically trained on fixed preference datasets, resulting in rigid alignment to single, implicit preference distributions. This prevents adaptation to diverse real-world needs-from conciseness in one task to detailed explanations in another. The standard practice of collecting task-specific preference data and retraining reward models is resource-intensive, often producing biased rewards, and limits practical application. We introduce generalizable, principle-following reward models. We propose that RMs should understand and adhere to dynamically provided natural language specifications of reward principles, similar to instruction-following in LLMs. To measure this capability, we develop RABench, a comprehensive benchmark for RMs focusing on generalization across diverse principles. Evaluations on RABench reveal poor generalization of current RMs. As a solution, we present RewardAnything, a novel RM designed and trained to explicitly follow natural language principles. We achieve SotA performance with RewardAnything in traditional RM benchmark simply by specifying a well-defined principle, and results on RABench show we excel in adapting to novel principles without retraining. Furthermore, RewardAnything integrates seamlessly with existing RLHF methods and we show by a case study on how to automatically and efficiently align LLMs with only natural language principles.', 'abstract_zh': '可泛化的原理遵循型奖励模型：从固定偏好数据集到动态语言规范的转变', 'title_zh': 'RewardAnything: 可泛化的原理遵循奖励模型'}
{'arxiv_id': 'arXiv:2506.03627', 'title': 'Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks', 'authors': 'Lin Mu, Guowei Chu, Li Ni, Lei Sang, Zhize Wu, Peiquan Jin, Yiwen Zhang', 'link': 'https://arxiv.org/abs/2506.03627', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable performance across various tasks by effectively utilizing a prompting strategy. However, they are highly sensitive to input perturbations, such as typographical errors or slight character order errors, which can substantially degrade their performance. Despite advances in prompting techniques, developing a prompting strategy that explicitly mitigates the negative impact of such perturbations remains an open challenge. To bridge this gap, we propose Robustness of Prompting (RoP), a novel prompting strategy specifically designed to enhance the robustness of LLMs. RoP consists of two stages: Error Correction and Guidance. In the Error Correction stage, RoP applies diverse perturbation methods to generate adversarial examples, which are then used to construct prompts that automatically correct input errors. In the Guidance stage, RoP generates an optimal guidance prompting based on the corrected input, steering the model toward more robust and accurate inferences. Through comprehensive experiments spanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate that RoP significantly improves LLMs' robustness against adversarial perturbations. Notably, it maintains model accuracy with only minimal degradation compared to clean input scenarios, thereby establishing RoP as a practical and effective approach for enhancing LLM robustness in real-world applications.", 'abstract_zh': '大型语言模型（LLMs）通过有效利用激发策略在各种任务中展示了显著的性能。然而，它们对输入扰动的高度敏感性，如拼写错误或字符顺序错误，会导致其性能大幅下降。尽管在激发技术方面取得了进展，但开发一种能够明确减轻这些扰动负面影响的激发策略仍然是一个开放的挑战。为此，我们提出了一种新颖的激发策略——鲁棒性激发（RoP），专门设计用于增强LLMs的鲁棒性。RoP包括两个阶段：错误修正和引导。在错误修正阶段，RoP应用多种扰动方法生成对抗性示例，然后利用这些示例构建能够自动纠正输入错误的提示。在引导阶段，RoP基于修正后的输入生成最优的引导提示，引导模型得出更鲁棒和准确的推断。通过涵盖算术、常识和逻辑推理任务的全面实验，我们证明了RoP显著提高了LLMs对抗敌意扰动的鲁棒性。值得注意的是，RoP仅在轻微影响模型准确性的情况下维持了其有效性，从而确立了RoP作为一种在实际应用中增强LLM鲁棒性的实用且有效的方法的地位。', 'title_zh': '提示的健壮性：增强大型语言模型对抗提示攻击的健壮性'}
{'arxiv_id': 'arXiv:2506.03621', 'title': 'Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation', 'authors': 'Chaehun Shin, Jooyoung Choi, Johan Barthelemy, Jungbeom Lee, Sungroh Yoon', 'link': 'https://arxiv.org/abs/2506.03621', 'abstract': 'We present Subject Fidelity Optimization (SFO), a novel comparative learning framework for zero-shot subject-driven generation that enhances subject fidelity. Beyond supervised fine-tuning methods that rely only on positive targets and use the diffusion loss as in the pre-training stage, SFO introduces synthetic negative targets and explicitly guides the model to favor positives over negatives through pairwise comparison. For negative targets, we propose Condition-Degradation Negative Sampling (CDNS), which automatically generates distinctive and informative negatives by intentionally degrading visual and textual cues without expensive human annotations. Moreover, we reweight the diffusion timesteps to focus finetuning on intermediate steps where subject details emerge. Extensive experiments demonstrate that SFO with CDNS significantly outperforms baselines in terms of both subject fidelity and text alignment on a subject-driven generation benchmark. Project page: this https URL', 'abstract_zh': '面向主题保真度优化的新型零-shot 主题驱动生成对比学习框架（SFO）', 'title_zh': '负向引导主题保真度优化以实现零样本主题驱动生成'}
{'arxiv_id': 'arXiv:2506.03618', 'title': 'GCFL: A Gradient Correction-based Federated Learning Framework for Privacy-preserving CPSS', 'authors': 'Jiayi Wan, Xiang Zhu, Fanzhen Liu, Wei Fan, Xiaolong Xu', 'link': 'https://arxiv.org/abs/2506.03618', 'abstract': 'Federated learning, as a distributed architecture, shows great promise for applications in Cyber-Physical-Social Systems (CPSS). In order to mitigate the privacy risks inherent in CPSS, the integration of differential privacy with federated learning has attracted considerable attention. Existing research mainly focuses on dynamically adjusting the noise added or discarding certain gradients to mitigate the noise introduced by differential privacy. However, these approaches fail to remove the noise that hinders convergence and correct the gradients affected by the noise, which significantly reduces the accuracy of model classification. To overcome these challenges, this paper proposes a novel framework for differentially private federated learning that balances rigorous privacy guarantees with accuracy by introducing a server-side gradient correction mechanism. Specifically, after clients perform gradient clipping and noise perturbation, our framework detects deviations in the noisy local gradients and employs a projection mechanism to correct them, mitigating the negative impact of noise. Simultaneously, gradient projection promotes the alignment of gradients from different clients and guides the model towards convergence to a global optimum. We evaluate our framework on several benchmark datasets, and the experimental results demonstrate that it achieves state-of-the-art performance under the same privacy budget.', 'abstract_zh': '联邦学习作为分布式架构，展现出在物理-社会系统（CPSS）中的广泛应用前景。为了缓解CPSS中固有的隐私风险，将差分隐私与联邦学习相结合引起了广泛的关注。现有研究主要集中在动态调整添加的噪音或丢弃某些梯度以缓解差分隐私引入的噪音。然而，这些方法无法消除妨碍收敛的噪音并且未能修正受噪音影响的梯度，这显著降低了模型分类的准确性。为克服这些挑战，本文提出了一种新颖的差分隐私联邦学习框架，通过引入服务器端梯度修正机制，平衡严格的隐私保证与准确性。具体而言，客户端执行梯度裁剪和噪音扰动后，该框架检测嘈杂的本地梯度中的偏差，并采用投影机制进行修正，缓解噪音的负面影响。同时，梯度投影促进了不同客户端梯度的对齐，并引导模型向全局最优解收敛。我们在多个基准数据集上评估了该框架，实验结果表明，在相同的隐私预算下，该框架实现了最先进的性能。', 'title_zh': 'GCFL：一种基于梯度校正的隐私保护联邦学习框架'}
{'arxiv_id': 'arXiv:2506.03614', 'title': 'VLMs Can Aggregate Scattered Training Patches', 'authors': 'Zhanhui Zhou, Lingjie Chen, Chao Yang, Chaochao Lu', 'link': 'https://arxiv.org/abs/2506.03614', 'abstract': 'One way to mitigate risks in vision-language models (VLMs) is to remove dangerous samples in their training data. However, such data moderation can be easily bypassed when harmful images are split into small, benign-looking patches, scattered across many training samples. VLMs may then learn to piece these fragments together during training and generate harmful responses at inference, either from full images or text references. For instance, if trained on image patches from a bloody scene paired with the descriptions "safe," VLMs may later describe, the full image or a text reference to the scene, as "safe." We define the core ability of VLMs enabling this attack as $\\textit{visual stitching}$ -- the ability to integrate visual information spread across multiple training samples that share the same textual descriptions. In our work, we first demonstrate visual stitching abilities in common open-source VLMs on three datasets where each image is labeled with a unique synthetic ID: we split each $(\\texttt{image}, \\texttt{ID})$ pair into $\\{(\\texttt{patch}, \\texttt{ID})\\}$ pairs at different granularity for finetuning, and we find that tuned models can verbalize the correct IDs from full images or text reference. Building on this, we simulate the adversarial data poisoning scenario mentioned above by using patches from dangerous images and replacing IDs with text descriptions like ``safe\'\' or ``unsafe\'\', demonstrating how harmful content can evade moderation in patches and later be reconstructed through visual stitching, posing serious VLM safety risks. Code is available at this https URL.', 'abstract_zh': '一种缓解视觉语言模型风险的方法是移除其训练数据中的危险样本。然而，当有害图像被拆分成小的、看似无害的片段，并散布在多个训练样本中时，这样的数据净化措施很容易被绕过。视觉语言模型在训练过程中可能会学习将这些片段拼接起来，并在推理时生成有害的响应，无论是从完整图像还是文本引用中。例如，如果模型是在带有“安全”描述的血腥场景图像片段上进行训练，那么该模型在推理时可能会将完整图像或场景描述描述为“安全”。我们定义使视觉语言模型能够执行此攻击的核心能力为$\\textit{视觉拼接}$——即整合具有相同文本描述的多个训练样本中分散的视觉信息的能力。在我们的研究中，我们首先在三个每个图像带有唯一合成ID的数据集上展示了常见开源视觉语言模型的视觉拼接能力：我们将每个$(\\texttt{图像}, \\texttt{ID})$对在不同的粒度下拆分成$\\{(\\texttt{片段}, \\texttt{ID})\\}$对进行微调，发现调整后的模型可以从完整图像或文本引用中表达正确的ID。在此基础上，我们通过使用危险图像的片段并用类似的“安全”或“不安全”的文本描述替换ID，模拟了上述对抗性数据污染场景，展示了有害内容如何通过视觉拼接在片段中避开关机措施，并重新构建，从而对视觉语言模型的安全性构成严重威胁。代码可在以下链接获取。', 'title_zh': 'VLMs可以聚合散列的训练patches'}
{'arxiv_id': 'arXiv:2506.03606', 'title': 'Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models', 'authors': 'Parismita Gogoi, Sishir Kalita, Wendy Lalhminghlui, Viyazonuo Terhiija, Moakala Tzudir, Priyankoo Sarmah, S. R. M. Prasanna', 'link': 'https://arxiv.org/abs/2506.03606', 'abstract': 'This study explores the use of self-supervised learning (SSL) models for tone recognition in three low-resource languages from North Eastern India: Angami, Ao, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on both tonal and non-tonal languages. We analyze tone-wise performance across the layers for all three languages and compare the different models. Our results show that tone recognition works best for Mizo and worst for Angami. The middle layers of the SSL models are the most important for tone recognition, regardless of the pre-training language, i.e. tonal or non-tonal. We have also found that the tone inventory, tone types, and dialectal variations affect tone recognition. These findings provide useful insights into the strengths and weaknesses of SSL-based embeddings for tonal languages and highlight the potential for improving tone recognition in low-resource settings. The source code is available at GitHub 1 .', 'abstract_zh': '本研究探索了自我监督学习（SSL）模型在印度东北部三种低资源语言（Angami、Ao和Mizo）音调识别中的应用。我们评估了四种在音调和非音调语言上预训练的Wav2vec2.0基础模型。我们分析了所有三种语言各层的音调性能，并比较了不同的模型。研究结果表明，音调识别在Mizo语言中效果最佳，在Angami语言中效果最差。无论预训练语言是音调语言还是非音调语言，SSL模型的中间层对于音调识别都是最重要的。我们还发现，音调Inventory、音调类型和方言变体影响音调识别。这些发现为基于SSL的嵌入在音调语言中的优缺点提供了有价值的见解，并突显了在低资源环境中提高音调识别的潜力。源代码可在GitHub 1获取。', 'title_zh': '东北印度低资源语言的语调识别：基于SSL的语音模型探析'}
{'arxiv_id': 'arXiv:2506.03602', 'title': 'Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems', 'authors': 'Hiroki Shiraishi, Yohei Hayamizu, Tomonori Hashiyama, Keiki Takadama, Hisao Ishibuchi, Masaya Nakata', 'link': 'https://arxiv.org/abs/2506.03602', 'abstract': 'Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at this https URL. An extended abstract related to this work is available at this https URL.', 'abstract_zh': '基于Beta分布的灵活规则表示及其在模糊风格学习分类系统中的应用', 'title_zh': '适应四参数Beta分布的规则表示学习分类器系统'}
{'arxiv_id': 'arXiv:2506.03598', 'title': 'Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments', 'authors': 'Zetong Tang, Qian Ma, Di Wu', 'link': 'https://arxiv.org/abs/2506.03598', 'abstract': "Using the best Text-to-SQL methods in resource-constrained environments is challenging due to their reliance on resource-intensive open-source models. This paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to bridge the gap between resource-efficient small open-source models and the powerful capabilities of large closed-source models for Text-to-SQL translation. Our method decomposes the task into schema filtering, retrieval-augmented text-to-SQL generation based on in-context examples, and prompt-driven schema linking and SQL generation. To improve schema selection accuracy, we fine-tune large language models. Crucially, we also explore the impact of prompt engineering throughout the process, leveraging Chain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly enhance the model's reasoning for accurate SQL generation. Comprehensive evaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.", 'abstract_zh': '在资源受限环境中使用最佳Text-to-SQL方法具有挑战性，因为这些方法依赖于资源密集型开源模型。本文介绍了Auto Prompt SQL (AP-SQL)，这是一种新型架构，旨在弥合资源高效的小开源模型与强大功能的大封闭源模型之间的差距，以实现Text-to-SQL翻译。我们的方法将任务分解为模式过滤、基于上下文示例的检索增强文本到SQL生成以及提示驱动的模式链接和SQL生成。为了提高模式选择准确性，我们对大型语言模型进行了微调。 crucially，我们还在整个过程中探讨了提示工程的影响，利用Chain-of-Thought (CoT) 和 Graph-of-Thought (GoT) 模板显著增强了模型的推理能力以实现准确的SQL生成。在Spider基准上的全面评估证明了AP-SQL的有效性。', 'title_zh': '自动提示SQL：受限环境中文本到SQL转换的资源高效架构'}
{'arxiv_id': 'arXiv:2506.03595', 'title': "Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its Preconditioner", 'authors': 'Runa Eschenhagen, Aaron Defazio, Tsung-Hsien Lee, Richard E. Turner, Hao-Jun Michael Shi', 'link': 'https://arxiv.org/abs/2506.03595', 'abstract': "The recent success of Shampoo in the AlgoPerf contest has sparked renewed interest in Kronecker-factorization-based optimization algorithms for training neural networks. Despite its success, Shampoo relies heavily on several heuristics such as learning rate grafting and stale preconditioning to achieve performance at-scale. These heuristics increase algorithmic complexity, necessitate further hyperparameter tuning, and lack theoretical justification. This paper investigates these heuristics from the angle of Frobenius norm approximation to full-matrix Adam and decouples the preconditioner's eigenvalues and eigenbasis updates. We show that grafting from Adam mitigates the staleness and mis-scaling of the preconditioner's eigenvalues and how correcting the eigenvalues directly can eliminate the need for learning rate grafting. To manage the error induced by infrequent eigenbasis computations, we propose an adaptive criterion for determining the eigenbasis computation frequency motivated by terminating a warm-started QR algorithm. This criterion decouples the update frequency of different preconditioner matrices and enables us to investigate the impact of approximation error on convergence. These practical techniques offer a principled angle towards removing Shampoo's heuristics and developing improved Kronecker-factorization-based training algorithms.", 'abstract_zh': 'Shampoo算法在AlgoPerf竞赛中的最近成功引发了对基于Kronecker因式分解的优化算法在神经网络训练中兴趣的重燃。尽管取得了成功，但Shampoo算法强烈依赖于诸如学习率嫁接和过时预条件处理等启发式方法来实现大规模性能。这些启发式方法增加了算法复杂性，需要进一步调整超参数，并缺乏理论依据。本文从Frobenius范数逼近全矩阵Adam的角度出发，将预条件矩阵的特征值和特征向量分解解耦。我们展示了来自Adam的嫁接如何减轻预条件矩阵特征值的过时和失真，并如何直接矫正特征值可以消除学习率嫁接的需要。为了管理由不频繁计算特征向量引起的误差，我们提出了一种基于终止预热QR算法的自适应准则来确定特征向量计算频率。该准则使不同预条件矩阵的更新频率解耦，并使我们能够研究逼近误差对收敛的影响。这些实用的技术为去除Shampoo的启发式方法并开发改进的基于Kronecker因式分解的训练算法提供了理论视角。', 'title_zh': '净化洗发水：通过分解其预处理器探讨洗发水的启发式方法'}
{'arxiv_id': 'arXiv:2506.03589', 'title': 'BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance', 'authors': 'Huy Le, Nhat Chung, Tung Kieu, Anh Nguyen, Ngan Le', 'link': 'https://arxiv.org/abs/2506.03589', 'abstract': "Text-video retrieval (TVR) systems often suffer from visual-linguistic biases present in datasets, which cause pre-trained vision-language models to overlook key details. To address this, we propose BiMa, a novel framework designed to mitigate biases in both visual and textual representations. Our approach begins by generating scene elements that characterize each video by identifying relevant entities/objects and activities. For visual debiasing, we integrate these scene elements into the video embeddings, enhancing them to emphasize fine-grained and salient details. For textual debiasing, we introduce a mechanism to disentangle text features into content and bias components, enabling the model to focus on meaningful content while separately handling biased information. Extensive experiments and ablation studies across five major TVR benchmarks (i.e., MSR-VTT, MSVD, LSMDC, ActivityNet, and DiDeMo) demonstrate the competitive performance of BiMa. Additionally, the model's bias mitigation capability is consistently validated by its strong results on out-of-distribution retrieval tasks.", 'abstract_zh': '基于视觉-语言偏见的文本-视频检索系统改进：BiMa框架的研究', 'title_zh': 'BiMa: 基于场景元素指导的文本-视频检索偏差缓解方法'}
{'arxiv_id': 'arXiv:2506.03588', 'title': 'A Class Inference Scheme With Dempster-Shafer Theory for Learning Fuzzy-Classifier Systems', 'authors': 'Hiroki Shiraishi, Hisao Ishibuchi, Masaya Nakata', 'link': 'https://arxiv.org/abs/2506.03588', 'abstract': "The decision-making process significantly influences the predictions of machine learning models. This is especially important in rule-based systems such as Learning Fuzzy-Classifier Systems (LFCSs) where the selection and application of rules directly determine prediction accuracy and reliability. LFCSs combine evolutionary algorithms with supervised learning to optimize fuzzy classification rules, offering enhanced interpretability and robustness. Despite these advantages, research on improving decision-making mechanisms (i.e., class inference schemes) in LFCSs remains limited. Most LFCSs use voting-based or single-winner-based inference schemes. These schemes rely on classification performance on training data and may not perform well on unseen data, risking overfitting. To address these limitations, this article introduces a novel class inference scheme for LFCSs based on the Dempster-Shafer Theory of Evidence (DS theory). The proposed scheme handles uncertainty well. By using the DS theory, the scheme calculates belief masses (i.e., measures of belief) for each specific class and the ``I don't know'' state from each fuzzy rule and infers a class from these belief masses. Unlike the conventional schemes, the proposed scheme also considers the ``I don't know'' state that reflects uncertainty, thereby improving the transparency and reliability of LFCSs. Applied to a variant of LFCS (i.e., Fuzzy-UCS), the proposed scheme demonstrates statistically significant improvements in terms of test macro F1 scores across 30 real-world datasets compared to conventional voting-based and single-winner-based fuzzy inference schemes. It forms smoother decision boundaries, provides reliable confidence measures, and enhances the robustness and generalizability of LFCSs in real-world applications. Our implementation is available at this https URL.", 'abstract_zh': '机器学习模型的决策过程显著影响预测结果。特别是在基于规则的系统如学习模糊分类系统（LFCSs）中，规则的选择和应用直接决定了预测的准确性和可靠性。尽管LFCSs结合了进化算法和监督学习以优化模糊分类规则，提供增强的可解释性和鲁棒性，但关于改进LFCSs决策机制（即类推理方案）的研究仍然有限。大多数LFCSs使用基于投票或单赢者的推理方案。这些方案依赖于在训练数据上的分类性能，可能在未见过的数据上表现不佳，存在过拟合的风险。为应对这些局限，本文提出了一种基于迪斯克耳-肖弗证据理论（DS理论）的新型类推理方案。该方案能良好处理不确定性。通过使用DS理论，该方案计算每个模糊规则及其“不知道”状态下的每种具体类别的信心量（即信念度量），并据此进行类推理。与传统方案不同，该方案还考虑了“不知道”的状态，反映不确定性，从而提高LFCSs的透明度和可靠性。将该方案应用于LFCS的一种变体（即模糊-UCS），在30个真实世界数据集上，相较于传统的基于投票和单赢者的模糊推理方案，测试宏F1分数显示出统计意义上的显著改进。该方案形成更平滑的决策边界，提供可靠的信心度量，并增强LFCSs在实际应用中的鲁棒性和泛化能力。我们的实现可供于此网址。', 'title_zh': '基于Dempster-Shafer理论的类别推理方案及其在模糊分类系统中的学习应用'}
{'arxiv_id': 'arXiv:2506.03582', 'title': 'ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels', 'authors': 'Rui Yann, Xianglei Xing', 'link': 'https://arxiv.org/abs/2506.03582', 'abstract': 'We present ViTSGMM, an image recognition network that leverages semi-supervised learning in a highly efficient manner. Existing works often rely on complex training techniques and architectures, while their generalization ability when dealing with extremely limited labeled data remains to be improved. To address these limitations, we construct a hierarchical mixture density classification decision mechanism by optimizing mutual information between feature representations and target classes, compressing redundant information while retaining crucial discriminative components. Experimental results demonstrate that our method achieves state-of-the-art performance on STL-10 and CIFAR-10/100 datasets when using negligible labeled samples. Notably, this paper also reveals a long-overlooked data leakage issue in the STL-10 dataset for semi-supervised learning tasks and removes duplicates to ensure the reliability of experimental results. Code available at this https URL.', 'abstract_zh': 'ViTSGMM：一种高效利用半监督学习的图像识别网络', 'title_zh': 'ViTSGMM：一种使用稀疏标签的鲁棒半监督图像识别网络'}
{'arxiv_id': 'arXiv:2506.03576', 'title': 'KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models', 'authors': 'Zirui Chen, Xin Wang, Zhao Li, Wenbin Guo, Dongxiao He', 'link': 'https://arxiv.org/abs/2506.03576', 'abstract': 'Recent advances in knowledge representation learning (KRL) highlight the urgent necessity to unify symbolic knowledge graphs (KGs) with language models (LMs) for richer semantic understanding. However, existing approaches typically prioritize either graph structure or textual semantics, leaving a gap: a unified framework that simultaneously captures global KG connectivity, nuanced linguistic context, and discriminative reasoning semantics. To bridge this gap, we introduce KG-BiLM, a bidirectional LM framework that fuses structural cues from KGs with the semantic expressiveness of generative transformers. KG-BiLM incorporates three key components: (i) Bidirectional Knowledge Attention, which removes the causal mask to enable full interaction among all tokens and entities; (ii) Knowledge-Masked Prediction, which encourages the model to leverage both local semantic contexts and global graph connectivity; and (iii) Contrastive Graph Semantic Aggregation, which preserves KG structure via contrastive alignment of sampled sub-graph representations. Extensive experiments on standard benchmarks demonstrate that KG-BiLM outperforms strong baselines in link prediction, especially on large-scale graphs with complex multi-hop relations - validating its effectiveness in unifying structural information and textual semantics.', 'abstract_zh': '最近关于知识表示学习的进步强调了统一符号知识图谱与语言模型的迫切必要性，以实现更丰富的语义理解。然而，现有方法通常要么侧重于图结构要么侧重于文本语义，留下了统一框架的缺口：一个可以同时捕捉全局知识图谱连接性、细腻的语义上下文和辨别性推理语义的框架。为填补这一缺口，我们提出了KG-BiLM，这是一种融合知识图谱结构线索与生成式变换器语义表现力的双向语言模型框架。KG-BiLM 包含三个关键组件：(i) 双向知识注意，移除因果掩码以实现所有令牌和实体之间的全面交互；(ii) 知识掩蔽预测，促使模型利用局部语义上下文和全局图连接性；(iii) 对比图语义聚合，通过对比子图表示的对齐保留知识图谱结构。在标准基准上的广泛实验表明，KG-BiLM 在链接预测任务中优于强有力的基线模型，尤其是在大型复杂多跳关系图上，验证了其在统一结构信息和文本语义方面的有效性。', 'title_zh': 'KG-BiLM：基于双向语言模型的知识图谱嵌入'}
{'arxiv_id': 'arXiv:2506.03571', 'title': 'DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network', 'authors': 'Chong Hyun Lee, Kibae Lee', 'link': 'https://arxiv.org/abs/2506.03571', 'abstract': 'We propose DaigNet, a new approach to object detection with which we can detect an object bounding box using diagonal constraints on adjacency matrix of a graph convolutional network (GCN). We propose two diagonalization algorithms based on hard and soft constraints on adjacency matrix and two loss functions using diagonal constraint and complementary constraint. The DaigNet eliminates the need for designing a set of anchor boxes commonly used. To prove feasibility of our novel detector, we adopt detection head in YOLO models. Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC than YOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7% higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.', 'abstract_zh': '我们提出DaigNet，这是一种使用图卷积网络（GCN）邻接矩阵对角约束进行对象检测的新方法。我们提出了基于邻接矩阵硬约束和软约束的两种对角化算法，并使用对角约束和互补约束提出了两种损失函数。DaigNet消除了常用锚框集的设计需求。为了证明我们新型检测器的可行性，我们在YOLO模型中采用检测头部。实验结果显示，DiagNet在Pascal VOC上的mAP50比YOLOv1高7.5%。DiagNet在MS COCO上的mAP比YOLOv3u高5.1%，比YOLOv5u高3.7%，比YOLOv8高2.9%。', 'title_zh': 'DiagNet：基于图神经网络邻接矩阵对角约束的物体检测方法'}
{'arxiv_id': 'arXiv:2506.03568', 'title': 'Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving', 'authors': 'Li Zeqiao, Wang Yijing, Wang Haoyu, Li Zheng, Li Peng, Zuo zhiqiang, Hu Chuan', 'link': 'https://arxiv.org/abs/2506.03568', 'abstract': "Autonomous driving promises significant advancements in mobility, road safety and traffic efficiency, yet reinforcement learning and imitation learning face safe-exploration and distribution-shift challenges. Although human-AI collaboration alleviates these issues, it often relies heavily on extensive human intervention, which increases costs and reduces efficiency. This paper develops a confidence-guided human-AI collaboration (C-HAC) strategy to overcome these limitations. First, C-HAC employs a distributional proxy value propagation method within the distributional soft actor-critic (DSAC) framework. By leveraging return distributions to represent human intentions C-HAC achieves rapid and stable learning of human-guided policies with minimal human interaction. Subsequently, a shared control mechanism is activated to integrate the learned human-guided policy with a self-learning policy that maximizes cumulative rewards. This enables the agent to explore independently and continuously enhance its performance beyond human guidance. Finally, a policy confidence evaluation algorithm capitalizes on DSAC's return distribution networks to facilitate dynamic switching between human-guided and self-learning policies via a confidence-based intervention function. This ensures the agent can pursue optimal policies while maintaining safety and performance guarantees. Extensive experiments across diverse driving scenarios reveal that C-HAC significantly outperforms conventional methods in terms of safety, efficiency, and overall performance, achieving state-of-the-art results. The effectiveness of the proposed method is further validated through real-world road tests in complex traffic conditions. The videos and code are available at: this https URL.", 'abstract_zh': '基于信心引导的人机协作自主驾驶策略（C-HAC）：安全性、效率和性能的提升', 'title_zh': '基于信心引导的人机协作：自主驾驶中的分布代理价值传播 reinforcement学习'}
{'arxiv_id': 'arXiv:2506.03566', 'title': 'POSS: Position Specialist Generates Better Draft for Speculative Decoding', 'authors': 'Langlin Huang, Chengsong Huang, Jixuan Leng, Di Huang, Jiaxin Huang', 'link': 'https://arxiv.org/abs/2506.03566', 'abstract': 'Speculative decoding accelerates Large Language Model (LLM) inference by using a small draft model to predict multiple tokens, and a large target model to verify these tokens in parallel. Recent studies leverage the hidden state of the target model to enhance draft model prediction accuracy. However, existing methods suffer from the degrading quality of draft token predictions at later positions, due to error accumulation in draft model generated features. In this paper, we propose Position Specialists (PosS), which consist of multiple position-specialized draft layers to generate tokens at assigned position(s). Position specialists greatly improve token acceptance rate at later positions per drafting round, as each specialist only needs to focus on handling a certain level of draft model feature deviation. Experiment results on Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that PosS effectively improves over baselines on average acceptance length and speed-up ratio. Our codebase is available at this https URL.', 'abstract_zh': '推测性解码通过使用小草稿模型预测多个令牌，并使用大目标模型并行验证这些令牌来加速大型语言模型（LLM）推断。 recent studies 利用目标模型的隐藏状态来增强草稿模型的预测准确性。然而，现有方法在草稿令牌预测的后期位置上遭受预测质量下降的问题，这是由于草稿模型生成的功能中的误差累积造成的。在本文中，我们提出了位置专家（PosS），它由多个针对特定位置的专业化草稿层组成，以生成指定位置的令牌。位置专家在每次草稿轮次中极大地提高了后期位置的令牌接受率，因为每个专家只需专注于处理草稿模型特征偏差的某个级别。在 Llama-3-8B-Instruct 和 Llama-2-13B-chat 上跨六个数据集的实验结果表明，PosS 平均接受长度和加速比相比基准模型有显著改善。我们的代码库可在以下网址获取。', 'title_zh': 'POSSS: 位置专家生成更好的 speculative 解码草稿'}
{'arxiv_id': 'arXiv:2506.03546', 'title': 'From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context', 'authors': 'Yuanchen Bai, Zijian Ding, Angelique Taylor', 'link': 'https://arxiv.org/abs/2506.03546', 'abstract': 'Advancements in generative models have enabled multi-agent systems (MAS) to perform complex virtual tasks such as writing and code generation, which do not generalize well to physical multi-agent robotic teams. Current frameworks often treat agents as conceptual task executors rather than physically embodied entities, and overlook critical real-world constraints such as spatial context, robotic capabilities (e.g., sensing and navigation). To probe this gap, we reconfigure and stress-test a hierarchical multi-agent robotic team built on the CrewAI framework in a simulated emergency department onboarding scenario. We identify five persistent failure modes: role misalignment; tool access violations; lack of in-time handling of failure reports; noncompliance with prescribed workflows; bypassing or false reporting of task completion. Based on this analysis, we propose three design guidelines emphasizing process transparency, proactive failure recovery, and contextual grounding. Our work informs the development of more resilient and robust multi-agent robotic systems (MARS), including opportunities to extend virtual multi-agent frameworks to the real world.', 'abstract_zh': '生成模型的进步使多智能体系统能够执行复杂的虚拟任务，如写作和代码生成，但这些任务在应用于物理多智能体机器人团队时缺乏泛化能力。当前框架往往将智能体视为概念性任务执行者，而非物理实体，并忽略了诸如空间上下文、机器人能力（例如，感知和导航）等关键现实世界约束。为探索这一差距，我们在模拟紧急部门入职场景中重新配置并压力测试了基于CrewAI框架的层次化多智能体机器人团队。我们识别出五种持续存在的失败模式：角色错位；工具访问违规；失败报告未能及时处理；不遵守规定的工作流程；绕过或虚假报告任务完成情况。基于这一分析，我们提出三条设计准则，强调过程透明性、主动故障恢复和上下文约束。我们的工作为开发更具弹性和稳健的多智能体机器人系统（MARS）提供了指导，并探讨了将虚拟多智能体框架扩展到现实世界的机会。', 'title_zh': '从虚拟代理到机器人团队：高风险医疗环境下的多机器人框架评估'}
{'arxiv_id': 'arXiv:2506.03541', 'title': 'Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement', 'authors': 'Xiaofeng Zhou, Heyan Huang, Lizi Liao', 'link': 'https://arxiv.org/abs/2506.03541', 'abstract': 'Large Language Models (LLMs) continue to set new standards in knowledge-intensive and complex reasoning tasks, yet their high computational demands limit widespread adoption. While distilling large models into smaller ones offers a sustainable solution, current techniques--such as static knowledge distillation, resource-intensive reinforcement learning from human feedback, or limited self-reflection--struggle to yield substantial and lasting performance gains. In this paper, we present a novel Debate and Reflect (D&R) framework that orchestrates multi-turn debates between smaller models and stronger teacher models, eliciting actionable feedback (e.g., error analysis, corrective strategies) to guide student models. Further, we introduce Tree-structured Direct Preference Optimization (T-DPO) to efficiently leverage these debate logs, organizing interactions into a hierarchical format for effective training. Empirical evaluations across diverse NLP benchmarks demonstrate that our approach significantly improves smaller-model accuracy, robustness, and generalization, outperforming conventional baselines by a large margin.', 'abstract_zh': 'Large Language Models (LLMs) 在知识密集和复杂推理任务中持续设定新标准，但其高的计算需求限制了其广泛应用。虽然将大型模型精简为较小规模的模型是一种可持续的解决方案，但当前的技术手段——如静态知识精简、资源密集型基于人类反馈的强化学习或有限的自我反思——难以实现显著且持久的性能提升。在本文中，我们提出了一种名为 Debate and Reflect (D&R) 的新型框架，通过较小模型与更强的教师模型进行多轮辩论，激发可操作的反馈（如错误分析、纠正策略）来指导学生模型。此外，我们引入了基于树结构的直接偏好优化 (T-DPO) 方法，高效地利用辩论日志，将其组织成层次结构以进行有效的训练。在多种自然语言处理基准测试中的实证评估表明，我们的方法显著提高了较小模型的准确率、鲁棒性和通用性，并在很大程度上优于传统基线方法。', 'title_zh': '辩论、反思与提炼：基于树状偏好优化的多Agent反馈机制以实现高效语言模型增强'}
{'arxiv_id': 'arXiv:2506.03525', 'title': 'Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning', 'authors': 'Daeun Lee, Jaehong Yoon, Jaemin Cho, Mohit Bansal', 'link': 'https://arxiv.org/abs/2506.03525', 'abstract': 'Recent advances in Chain-of-Thought (CoT) reasoning have improved complex video understanding, but existing methods often struggle to adapt to domain-specific skills (e.g., event detection, spatial relation understanding, emotion understanding) over various video content. To address this, we propose Video-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs and leverages skill-aware CoT supervisions for domain-adaptive video reasoning. First, we construct skill-based CoT annotations: we extract domain-relevant reasoning skills from training questions, cluster them into a shared skill taxonomy, and create detailed multi-step CoT rationale tailored to each video-question pair for training. Second, we introduce a skill-specific expert learning framework. Each expert module specializes in a subset of reasoning skills and is trained with lightweight adapters using the collected CoT supervision. We demonstrate the effectiveness of the proposed approach on three video understanding benchmarks, where Video-SKoT consistently outperforms strong baselines. We also provide in-depth analyses on comparing different CoT annotation pipelines and learned skills over multiple video domains.', 'abstract_zh': 'Recent advances in Chain-of-Thought (CoT) reasoning have improved complex video understanding, but existing methods often struggle to adapt to domain-specific skills (e.g., event detection, spatial relation understanding, emotion understanding) over various video content. To address this, we propose Video-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs and leverages skill-aware CoT supervisions for domain-adaptive video reasoning. First, we construct skill-based CoT annotations: we extract domain-relevant reasoning skills from training questions, cluster them into a shared skill taxonomy, and create detailed multi-step CoT rationale tailored to each video-question pair for training. Second, we introduce a skill-specific expert learning framework. Each expert module specializes in a subset of reasoning skills and is trained with lightweight adapters using the collected CoT supervision. We demonstrate the effectiveness of the proposed approach on three video understanding benchmarks, where Video-SKoT consistently outperforms strong baselines. We also provide in-depth analyses on comparing different CoT annotation pipelines and learned skills over multiple video domains。翻译标题：\n\n最近在Chain-of-Thought (CoT)推理方面的进展提高了复杂视频的理解能力，但现有方法往往难以适应各种视频内容中的领域特定技能（例如，事件检测、空间关系理解、情感理解）。为此，我们提出了一种名为Video-Skill-CoT（简称Video-SKoT）的方法，该框架能够自动构建并利用领域感知的CoT监督，促进领域适应的视频推理。首先，我们构建了基于技能的CoT注释：从训练问题中提取领域相关的推理技能，将它们聚类成共享技能分类法，并为每个视频-问题对创建详细的多步CoT推理。其次，我们引入了一种针对特定技能的专家学习框架。每个专家模块专门处理一组推理技能，并使用收集到的CoT监督与轻量级适配器进行训练。我们通过三个视频理解基准测试验证了所提出方法的有效性，其中Video-SKoT在所有基准测试中均优于强基线模型。我们还对不同CoT注释管道进行了深入分析，并研究了多个视频领域中学习到的技能。', 'title_zh': 'Video-Skill-CoT: 基于技能的链式思考在领域自适应视频推理中的应用'}
{'arxiv_id': 'arXiv:2506.03516', 'title': 'SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models', 'authors': 'Arnab Debnath, Gregory J. Stein, Jana Kosecka', 'link': 'https://arxiv.org/abs/2506.03516', 'abstract': 'Object goal navigation is a fundamental task in embodied AI, where an agent is instructed to locate a target object in an unexplored environment. Traditional learning-based methods rely heavily on large-scale annotated data or require extensive interaction with the environment in a reinforcement learning setting, often failing to generalize to novel environments and limiting scalability. To overcome these challenges, we explore a zero-shot setting where the agent operates without task-specific training, enabling more scalable and adaptable solution. Recent advances in Vision Foundation Models (VFMs) offer powerful capabilities for visual understanding and reasoning, making them ideal for agents to comprehend scenes, identify relevant regions, and infer the likely locations of objects. In this work, we present a zero-shot object goal navigation framework that integrates the perceptual strength of VFMs with a model-based planner that is capable of long-horizon decision making through frontier exploration. We evaluate our approach on the HM3D dataset using the Habitat simulator and demonstrate that our method achieves state-of-the-art performance in terms of success weighted by path length for zero-shot object goal navigation.', 'abstract_zh': '零样本物体目标导航是体现人工智能中的一个基础任务，其中智能体被指导在未探索环境中定位目标物体。传统的基于学习的方法依赖大量标注数据或需要在强化学习设置中进行大量的环境交互，往往无法泛化到新环境，限制了其可扩展性。为克服这些挑战，我们探索了一种零样本设置，智能体在没有任务特定训练的情况下运行，从而实现更可扩展和适应性强的解决方案。近期视觉基础模型（VFMs）的发展提供了强大的视觉理解和推理能力，使它们成为智能体理解场景、识别相关信息区域并推断物体可能位置的理想选择。在本工作中，我们提出了一种结合了VFMs感知优势和基于模型计划器的框架，该计划器能够通过边缘探索进行长期决策。我们在HM3D数据集上使用Habitat模拟器评估了该方法，并展示了我们的方法在零样本物体目标导航方面达到了最先进的性能，按路径长度加权的成功率最高。', 'title_zh': 'SemNav: 基于模型的零样本物体目标导航规划器使用视觉基础模型'}
{'arxiv_id': 'arXiv:2506.03511', 'title': 'POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning', 'authors': 'Fangyi Cao, Bin Ren, Zihao Wang, Shiwei Fu, Youbin Mo, Xiaoyang Liu, Yuzhou Chen, Weixin Yao', 'link': 'https://arxiv.org/abs/2506.03511', 'abstract': 'With over 1,000,000 images from more than 10,000 exposures using state-of-the-art high-contrast imagers (e.g., Gemini Planet Imager, VLT/SPHERE) in the search for exoplanets, can artificial intelligence (AI) serve as a transformative tool in imaging Earth-like exoplanets in the coming decade? In this paper, we introduce a benchmark and explore this question from a polarimetric image representation learning perspective. Despite extensive investments over the past decade, only a few new exoplanets have been directly imaged. Existing imaging approaches rely heavily on labor-intensive labeling of reference stars, which serve as background to extract circumstellar objects (disks or exoplanets) around target stars. With our POLARIS (POlarized Light dAta for total intensity Representation learning of direct Imaging of exoplanetary Systems) dataset, we classify reference star and circumstellar disk images using the full public SPHERE/IRDIS polarized-light archive since 2014, requiring less than 10 percent manual labeling. We evaluate a range of models including statistical, generative, and large vision-language models and provide baseline performance. We also propose an unsupervised generative representation learning framework that integrates these models, achieving superior performance and enhanced representational power. To our knowledge, this is the first uniformly reduced, high-quality exoplanet imaging dataset, rare in astrophysics and machine learning. By releasing this dataset and baselines, we aim to equip astrophysicists with new tools and engage data scientists in advancing direct exoplanet imaging, catalyzing major interdisciplinary breakthroughs.', 'abstract_zh': '基于偏振图像表示学习：阿尔文智像 dataset 在直接成像地球类系外行星中的潜力探讨', 'title_zh': 'POLARIS：一种用于外行星盘表示学习的高对比度偏振成像基准数据集'}
{'arxiv_id': 'arXiv:2506.03501', 'title': 'Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing', 'authors': 'Yuchen Guo, Zhicheng Dou, Huy H. Nguyen, Ching-Chun Chang, Saku Sugawara, Isao Echizen', 'link': 'https://arxiv.org/abs/2506.03501', 'abstract': 'Content creation has dramatically progressed with the rapid advancement of large language models like ChatGPT and Claude. While this progress has greatly enhanced various aspects of life and work, it has also negatively affected certain areas of society. A recent survey revealed that nearly 30% of college students use generative AI to help write academic papers and reports. Most countermeasures treat the detection of AI-generated text as a binary classification task and thus lack robustness. This approach overlooks human involvement in the generation of content even though human-machine collaboration is becoming mainstream. Besides generating entire texts, people may use machines to complete or revise texts. Such human involvement varies case by case, which makes binary classification a less than satisfactory approach. We refer to this situation as participation detection obfuscation. We propose using BERTScore as a metric to measure human involvement in the generation process and a multi-task RoBERTa-based regressor trained on a token classification task to address this problem. To evaluate the effectiveness of this approach, we simulated academic-based scenarios and created a continuous dataset reflecting various levels of human involvement. All of the existing detectors we examined failed to detect the level of human involvement on this dataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor mean squared error of 0.004). Moreover, it demonstrated some generalizability across generative models. Our code is available at this https URL', 'abstract_zh': '大语言模型如ChatGPT和Claude的迅速进步极大地推动了内容创作，但也对某些社会领域产生了负面影响。最近的一项调查表明，近30%的大学生使用生成式AI帮助撰写学术论文和报告。大多数应对措施将检测AI生成的文本视为二元分类任务，从而缺乏 robustness。这种做法忽视了即使在人机协作日益普遍的情况下，人类在内容生成中的参与。除了生成整个文本外，人们还可能使用机器来完成或修订文本。这种参与因情况而异，使得二元分类方法不够理想。我们称之为参与检测混淆。我们建议使用BERTScore作为衡量人类在生成过程中参与度的指标，并基于标记分类任务训练一个多任务RoBERTa回归器来解决这一问题。为了评估该方法的有效性，我们模拟了基于学术的场景，并创建了一个反映不同参与度水平的连续数据集。我们检查的所有现有检测器在这份数据集上均未能检测到人类参与的程度。然而，我们的方法成功了（F1分数为0.9423，回归器均方误差为0.004），并且显示出一定的跨生成模型的一般适用性。我们的代码可在以下链接获取。', 'title_zh': '评估人工智能生成文本中的人类参与度：以学术写作为例'}
{'arxiv_id': 'arXiv:2506.03489', 'title': 'EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding', 'authors': 'Mingxu Tao, Jie Hu, Mingchuan Yang, Yunhuai Liu, Dongyan Zhao, Yansong Feng', 'link': 'https://arxiv.org/abs/2506.03489', 'abstract': 'The remarkable performance of Large language models (LLMs) relies heavily on the availability of abundant high-quality training data. However, the high cost of acquiring annotated data often prevents models from obtaining capabilities to tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe that boosts model performance in data-scarcity scenarios without extra training. We first employ model extrapolation to enhance a finetuned model with its inferior version, and then adopt contrastive decoding to further reduce predicted errors, by comparing the logit scores given by the extrapolated and the vanilla finetuned model. Experiments across three tasks over four different LLMs show that EpiCoDe consistently outperforms existing methods with significant and robust improvement. We also propose a new theoretical framework to reveal the mechanism behind contrastive decoding in data-scarcity scenarios, which further helps us better understand the effectiveness of EpiCoDe.', 'abstract_zh': '大规模语言模型(EpiCoDe)在数据稀缺场景下的性能提升方法', 'title_zh': 'EpiCoDe: 超出训练范围的外推与对比解码增强模型性能'}
{'arxiv_id': 'arXiv:2506.03484', 'title': 'Explainable AI: XAI-Guided Context-Aware Data Augmentation', 'authors': 'Melkamu Abay Mersha, Mesay Gemeda Yigezu, Atnafu Lambebo Tonja, Hassan Shakil, Samer Iskander, Olga Kolesnikova, Jugal Kalita', 'link': 'https://arxiv.org/abs/2506.03484', 'abstract': 'Explainable AI (XAI) has emerged as a powerful tool for improving the performance of AI models, going beyond providing model transparency and interpretability. The scarcity of labeled data remains a fundamental challenge in developing robust and generalizable AI models, particularly for low-resource languages. Conventional data augmentation techniques introduce noise, cause semantic drift, disrupt contextual coherence, lack control, and lead to overfitting. To address these challenges, we propose XAI-Guided Context-Aware Data Augmentation. This novel framework leverages XAI techniques to modify less critical features while selectively preserving most task-relevant features. Our approach integrates an iterative feedback loop, which refines augmented data over multiple augmentation cycles based on explainability-driven insights and the model performance gain. Our experimental results demonstrate that XAI-SR-BT and XAI-PR-BT improve the accuracy of models on hate speech and sentiment analysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using the Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform existing augmentation techniques by 4.8% and 5%, respectively, on the same dataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform both baseline and conventional augmentation techniques across all tasks and models. This study provides a more controlled, interpretable, and context-aware solution to data augmentation, addressing critical limitations of existing augmentation techniques and offering a new paradigm shift for leveraging XAI techniques to enhance AI model training.', 'abstract_zh': '可解释的人工智能（XAI）已 emerges as a powerful tool for improving the performance of AI models, going beyond providing model transparency and interpretability. The scarcity of labeled data remains a fundamental challenge in developing robust and generalizable AI models, particularly for low-resource languages. Conventional data augmentation techniques introduce noise, cause semantic drift, disrupt contextual coherence, lack control, and lead to overfitting. To address these challenges, we propose XAI-Guided Context-Aware Data Augmentation. This novel framework leverages XAI techniques to modify less critical features while selectively preserving most task-relevant features. Our approach integrates an iterative feedback loop, which refines augmented data over multiple augmentation cycles based on explainability-driven insights and the model performance gain.\n\n可解释的人工智能（XAI）已 Emerged as a Powerful Tool for Improving AI Model Performance: Addressing the Challenges of Labeled Data Scarcity and Conventional Data Augmentation Techniques Through XAI-Guided Context-Aware Data Augmentation', 'title_zh': '可解释AI：基于XAI的上下文感知数据增广'}
{'arxiv_id': 'arXiv:2506.03474', 'title': 'CORE: Constraint-Aware One-Step Reinforcement Learning for Simulation-Guided Neural Network Accelerator Design', 'authors': 'Yifeng Xiao, Yurong Xu, Ning Yan, Masood Mortazavi, Pierluigi Nuzzo', 'link': 'https://arxiv.org/abs/2506.03474', 'abstract': 'Simulation-based design space exploration (DSE) aims to efficiently optimize high-dimensional structured designs under complex constraints and expensive evaluation costs. Existing approaches, including heuristic and multi-step reinforcement learning (RL) methods, struggle to balance sampling efficiency and constraint satisfaction due to sparse, delayed feedback, and large hybrid action spaces. In this paper, we introduce CORE, a constraint-aware, one-step RL method for simulationguided DSE. In CORE, the policy agent learns to sample design configurations by defining a structured distribution over them, incorporating dependencies via a scaling-graph-based decoder, and by reward shaping to penalize invalid designs based on the feedback obtained from simulation. CORE updates the policy using a surrogate objective that compares the rewards of designs within a sampled batch, without learning a value function. This critic-free formulation enables efficient learning by encouraging the selection of higher-reward designs. We instantiate CORE for hardware-mapping co-design of neural network accelerators, demonstrating that it significantly improves sample efficiency and achieves better accelerator configurations compared to state-of-the-art baselines. Our approach is general and applicable to a broad class of discrete-continuous constrained design problems.', 'abstract_zh': '基于仿真引导的约束意识单步强化学习设计空间探索（Simulation-Guided Design Space Exploration with Constraint-Aware One-Step Reinforcement Learning）', 'title_zh': 'CORE: 模型约束感知的一步强化学习在仿真引导的神经网络加速器设计中应用'}
{'arxiv_id': 'arXiv:2506.03425', 'title': 'A Data-Driven Diffusion-based Approach for Audio Deepfake Explanations', 'authors': 'Petr Grinberg, Ankur Kumar, Surya Koppisetti, Gaurav Bharaj', 'link': 'https://arxiv.org/abs/2506.03425', 'abstract': 'Evaluating explainability techniques, such as SHAP and LRP, in the context of audio deepfake detection is challenging due to lack of clear ground truth annotations. In the cases when we are able to obtain the ground truth, we find that these methods struggle to provide accurate explanations. In this work, we propose a novel data-driven approach to identify artifact regions in deepfake audio. We consider paired real and vocoded audio, and use the difference in time-frequency representation as the ground-truth explanation. The difference signal then serves as a supervision to train a diffusion model to expose the deepfake artifacts in a given vocoded audio. Experimental results on the VocV4 and LibriSeVoc datasets demonstrate that our method outperforms traditional explainability techniques, both qualitatively and quantitatively.', 'abstract_zh': '在音频深度假音检测中评估SHAP和LRP等可解释性技术具有挑战性，因为缺乏明确的 ground truth 注解。在能够获取 ground truth 的情况下，这些方法也难以提供准确的解释。在这项工作中，我们提出了一种数据驱动的方法来识别深度假音音频中的伪像区域。我们考虑了真实的和声编码音频配对，并使用时频表示的差异作为 ground truth 解释。随后，该差异信号作为监督信息来训练一个扩散模型，以在给定的声编码音频中揭示深度假音伪像。在 VocV4 和 LibriSeVoc 数据集上的实验结果表明，我们的方法在定性和定量上均优于传统可解释性技术。', 'title_zh': '基于数据驱动扩散的方法对音频深度假音的解释'}
{'arxiv_id': 'arXiv:2506.03407', 'title': 'Multi-Spectral Gaussian Splatting with Neural Color Representation', 'authors': 'Lukas Meyer, Josef Grün, Maximilian Weiherer, Bernhard Egger, Marc Stamminger, Linus Franke', 'link': 'https://arxiv.org/abs/2506.03407', 'abstract': 'We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS) framework that is able to generate multi-view consistent novel views from images of multiple, independent cameras with different spectral domains. In contrast to previous approaches, our method does not require cross-modal camera calibration and is versatile enough to model a variety of different spectra, including thermal and near-infra red, without any algorithmic changes.\nUnlike existing 3DGS-based frameworks that treat each modality separately (by optimizing per-channel spherical harmonics) and therefore fail to exploit the underlying spectral and spatial correlations, our method leverages a novel neural color representation that encodes multi-spectral information into a learned, compact, per-splat feature embedding. A shallow multi-layer perceptron (MLP) then decodes this embedding to obtain spectral color values, enabling joint learning of all bands within a unified representation.\nOur experiments show that this simple yet effective strategy is able to improve multi-spectral rendering quality, while also leading to improved per-spectra rendering quality over state-of-the-art methods. We demonstrate the effectiveness of this new technique in agricultural applications to render vegetation indices, such as normalized difference vegetation index (NDVI).', 'abstract_zh': '多光谱3D高斯点云渲染框架：MS-Splatting', 'title_zh': '多光谱高斯散列与神经颜色表示'}
{'arxiv_id': 'arXiv:2506.03404', 'title': 'The Impact of On-Policy Parallelized Data Collection on Deep Reinforcement Learning Networks', 'authors': 'Walter Mayor, Johan Obando-Ceron, Aaron Courville, Pablo Samuel Castro', 'link': 'https://arxiv.org/abs/2506.03404', 'abstract': 'The use of parallel actors for data collection has been an effective technique used in reinforcement learning (RL) algorithms. The manner in which data is collected in these algorithms, controlled via the number of parallel environments and the rollout length, induces a form of bias-variance trade-off; the number of training passes over the collected data, on the other hand, must strike a balance between sample efficiency and overfitting. We conduct an empirical analysis of these trade-offs on PPO, one of the most popular RL algorithms that uses parallel actors, and establish connections to network plasticity and, more generally, optimization stability. We examine its impact on network architectures, as well as the hyper-parameter sensitivity when scaling data. Our analyses indicate that larger dataset sizes can increase final performance across a variety of settings, and that scaling parallel environments is more effective than increasing rollout lengths. These findings highlight the critical role of data collection strategies in improving agent performance.', 'abstract_zh': '并行actor在数据收集中的应用是 reinforcement learning 算法中一种有效的技术。这些算法中的数据收集方式，通过并行环境的数量和展开长度控制，引发了一种偏差-方差交易；另一方面，数据集的训练迭代次数必须在样本效率和过拟合之间取得平衡。我们对其中一种最流行的使用并行actor的RL算法PPO进行了实证分析，并将其与网络可塑性和更广泛的优化稳定性建立联系。我们研究了其对网络架构的影响，以及在扩大数据规模时超参数的敏感性。分析表明，较大的数据集规模可以在多种设置中提高最终性能，并且增加并行环境的数量比增加展开长度更有效。这些发现突显了数据收集策略在提高智能体性能中的关键作用。', 'title_zh': '基于策略并行化数据收集对深度强化学习网络的影响'}
{'arxiv_id': 'arXiv:2506.03399', 'title': 'Sampling Preferences Yields Simple Trustworthiness Scores', 'authors': 'Sean Steinle', 'link': 'https://arxiv.org/abs/2506.03399', 'abstract': "With the onset of large language models (LLMs), the performance of artificial intelligence (AI) models is becoming increasingly multi-dimensional. Accordingly, there have been several large, multi-dimensional evaluation frameworks put forward to evaluate LLMs. Though these frameworks are much more realistic than previous attempts which only used a single score like accuracy, multi-dimensional evaluations can complicate decision-making since there is no obvious way to select an optimal model. This work introduces preference sampling, a method to extract a scalar trustworthiness score from multi-dimensional evaluation results by considering the many characteristics of model performance which users value. We show that preference sampling improves upon alternate aggregation methods by using multi-dimensional trustworthiness evaluations of LLMs from TrustLLM and DecodingTrust. We find that preference sampling is consistently reductive, fully reducing the set of candidate models 100% of the time whereas Pareto optimality never reduces the set by more than 50%. Likewise, preference sampling is consistently sensitive to user priors-allowing users to specify the relative weighting and confidence of their preferences-whereas averaging scores is intransigent to the users' prior knowledge.", 'abstract_zh': '随着大型语言模型（LLMs）的出现，人工智能（AI）模型的性能变得多维化。因此，已经提出了多个多维评估框架来评价LLMs。尽管这些框架比只使用单一得分如准确率的早期尝试更为现实，多维度评价可能会使决策复杂化，因为没有明显的方法选择最优模型。本工作引入了偏好抽样方法，该方法通过考虑用户重视的多种模型性能特征，从多维评估结果中提取单一可信度评分。我们通过使用TrustLLM和DecodingTrust对LLMs的多维可信度评估结果，证明偏好抽样方法在聚合方法上更为优越。我们发现，偏好抽样方法始终具有压缩性，能够100%地减少候选模型的集合，而帕累托最优仅能最多减少50%。同样，偏好抽样方法始终对用户先验敏感，允许用户指定其偏好之间的相对权重和置信度，而平均得分则对用户先验知识不敏感。', 'title_zh': '采样偏好生成简单的可信度评分'}
{'arxiv_id': 'arXiv:2506.03391', 'title': 'Universal Reusability in Recommender Systems: The Case for Dataset- and Task-Independent Frameworks', 'authors': "Tri Kurniawan Wijaya, Xinyang Shao, Gonzalo Fiz Pontiveros, Edoardo D'Amico", 'link': 'https://arxiv.org/abs/2506.03391', 'abstract': 'Recommender systems are pivotal in delivering personalized experiences across industries, yet their adoption and scalability remain hindered by the need for extensive dataset- and task-specific configurations. Existing systems often require significant manual intervention, domain expertise, and engineering effort to adapt to new datasets or tasks, creating barriers to entry and limiting reusability. In contrast, recent advancements in large language models (LLMs) have demonstrated the transformative potential of reusable systems, where a single model can handle diverse tasks without significant reconfiguration. Inspired by this paradigm, we propose the Dataset- and Task-Independent Recommender System (DTIRS), a framework aimed at maximizing the reusability of recommender systems while minimizing barriers to entry. Unlike LLMs, which achieve task generalization directly, DTIRS focuses on eliminating the need to rebuild or reconfigure recommendation pipelines for every new dataset or task, even though models may still need retraining on new data. By leveraging the novel Dataset Description Language (DsDL), DTIRS enables standardized dataset descriptions and explicit task definitions, allowing autonomous feature engineering, model selection, and optimization. This paper introduces the concept of DTIRS and establishes a roadmap for transitioning from Level-1 automation (dataset-agnostic but task-specific systems) to Level-2 automation (fully dataset- and task-independent systems). Achieving this paradigm would maximize code reusability and lower barriers to adoption. We discuss key challenges, including the trade-offs between generalization and specialization, computational overhead, and scalability, while presenting DsDL as a foundational tool for this vision.', 'abstract_zh': '面向数据和任务独立的推荐系统（DTIRS）', 'title_zh': '通用可重用性在推荐系统中的实现：基于数据集和任务独立的框架研究'}
{'arxiv_id': 'arXiv:2506.03381', 'title': 'Automated Traffic Incident Response Plans using Generative Artificial Intelligence: Part 1 -- Building the Incident Response Benchmark', 'authors': 'Artur Grigorev, Khaled Saleh, Jiwon Kim, Adriana-Simona Mihaita', 'link': 'https://arxiv.org/abs/2506.03381', 'abstract': 'Traffic incidents remain a critical public safety concern worldwide, with Australia recording 1,300 road fatalities in 2024, which is the highest toll in 12 years. Similarly, the United States reports approximately 6 million crashes annually, raising significant challenges in terms of a fast reponse time and operational management. Traditional response protocols rely on human decision-making, which introduces potential inconsistencies and delays during critical moments when every minute impacts both safety outcomes and network performance. To address this issue, we propose a novel Incident Response Benchmark that uses generative artificial intelligence to automatically generate response plans for incoming traffic incidents. Our approach aims to significantly reduce incident resolution times by suggesting context-appropriate actions such as variable message sign deployment, lane closures, and emergency resource allocation adapted to specific incident characteristics. First, the proposed methodology uses real-world incident reports from the Performance Measurement System (PeMS) as training and evaluation data. We extract historically implemented actions from these reports and compare them against AI-generated response plans that suggest specific actions, such as lane closures, variable message sign announcements, and/or dispatching appropriate emergency resources. Second, model evaluations reveal that advanced generative AI models like GPT-4o and Grok 2 achieve superior alignment with expert solutions, demonstrated by minimized Hamming distances (averaging 2.96-2.98) and low weighted differences (approximately 0.27-0.28). Conversely, while Gemini 1.5 Pro records the lowest count of missed actions, its extremely high number of unnecessary actions (1547 compared to 225 for GPT-4o) indicates an over-triggering strategy that reduces the overall plan efficiency.', 'abstract_zh': '基于生成式人工智能的交通事件响应基准研究', 'title_zh': '使用生成式人工智能自动化的交通事件响应计划：第1部分——建立事件响应基准'}
{'arxiv_id': 'arXiv:2506.03373', 'title': 'A Foundation Model for Spatial Proteomics', 'authors': 'Muhammad Shaban, Yuzhou Chang, Huaying Qiu, Yao Yu Yeo, Andrew H. Song, Guillaume Jaume, Yuchen Wang, Luca L. Weishaupt, Tong Ding, Anurag Vaidya, Abdallah Lamane, Daniel Shao, Mohammed Zidane, Yunhao Bai, Paige McCallum, Shuli Luo, Wenrui Wu, Yang Wang, Precious Cramer, Chi Ngai Chan, Pierre Stephan, Johanna Schaffenrath, Jia Le Lee, Hendrik A. Michel, Caiwei Tian, Cristina Almagro-Perez, Sophia J. Wagner, Sharifa Sahai, Ming Y. Lu, Richard J. Chen, Andrew Zhang, Mark Edward M. Gonzales, Ahmad Makky, Jia-Ying Joey Lee, Hao Cheng, Nourhan El Ahmar, Sayed Matar, Maximilian Haist, Darci Phillips, Yuqi Tan, Garry P. Nolan, W. Richard Burack, Jacob D. Estes, Jonathan T.C. Liu, Toni K Choueiri, Neeraj Agarwal, Marc Barry, Scott J. Rodig, Long Phi Le, Georg Gerber, Christian M. Schürch, Fabian J. Theis, Youn H Kim, Joe Yeong, Sabina Signoretti, Brooke E. Howitt, Lit-Hsin Loo, Qin Ma, Sizun Jiang, Faisal Mahmood', 'link': 'https://arxiv.org/abs/2506.03373', 'abstract': 'Foundation models have begun to transform image analysis by acting as pretrained generalist backbones that can be adapted to many tasks even when post-training data are limited, yet their impact on spatial proteomics, imaging that maps proteins at single-cell resolution, remains limited. Here, we introduce KRONOS, a foundation model built for spatial proteomics. KRONOS was trained in a self-supervised manner on over 47 million image patches covering 175 protein markers, 16 tissue types, and 8 fluorescence-based imaging platforms. We introduce key architectural adaptations to address the high-dimensional, multi-channel, and heterogeneous nature of multiplex imaging. We demonstrate that KRONOS learns biologically meaningful representations across multiple scales, ranging from cellular and microenvironment to tissue levels, enabling it to address diverse downstream tasks, including cell phenotyping, region classification, and patient stratification. Evaluated across 11 independent cohorts, KRONOS achieves state-of-the-art performance across cell phenotyping, treatment response prediction, and retrieval tasks, and is highly data-efficient. KRONOS also introduces the paradigm of segmentation-free patch-level processing for efficient and scalable spatial proteomics analysis, allowing cross-institutional comparisons, and as an image reverse search engine for spatial patterns. Together, these results position KRONOS as a flexible and scalable tool for spatial proteomics. The model is publicly accessible at this https URL.', 'abstract_zh': '基础模型已经开始通过充当可以适应多种任务的预训练通才骨干来转变图像分析，即使在后训练数据有限的情况下也如此，但它们对空间蛋白质组学的影响仍未得到充分利用，空间蛋白质组学是通过单细胞分辨率映射蛋白质的成像技术。在这里，我们介绍了KRONOS，一种为空间蛋白质组学构建的基础模型。KRONOS以自我监督的方式在涵盖175种蛋白质标记、16种组织类型和8种基于荧光的成像平台的超过4700万图像片段上进行训练。我们引入了关键的架构调整，以解决多重成像的高维、多通道和异质性问题。我们证明KRONOS能够在从细胞和微环境到组织的不同尺度上学习生物学上意义重大的表示，使其能够解决多种下游任务，包括细胞表型分类、区域分类和患者分层。在11个独立队列中评估，KRONOS在细胞表型分类、治疗反应预测和检索任务上均达到最佳性能，且非常数据高效。KRONOS还引入了无分割的片段级处理范式，实现了高效且可扩展的空间蛋白质组学分析，允许跨机构比较，并作为空间模式的图像逆向搜索引擎。这些结果将KRONOS定位为一个灵活且可扩展的空间蛋白质组学工具。该模型已在此网址公开访问：https://。', 'title_zh': '空间蛋白质组学的基石模型'}
{'arxiv_id': 'arXiv:2506.03357', 'title': 'Ask a Local: Detecting Hallucinations With Specialized Model Divergence', 'authors': 'Aldan Creo, Héctor Cerezo-Costas, Pedro Alonso-Doval, Maximiliano Hormazábal-Lagos', 'link': 'https://arxiv.org/abs/2506.03357', 'abstract': 'Hallucinations in large language models (LLMs) - instances where models generate plausible but factually incorrect information - present a significant challenge for AI.\nWe introduce "Ask a Local", a novel hallucination detection method exploiting the intuition that specialized models exhibit greater surprise when encountering domain-specific inaccuracies. Our approach computes divergence between perplexity distributions of language-specialized models to identify potentially hallucinated spans. Our method is particularly well-suited for a multilingual context, as it naturally scales to multiple languages without the need for adaptation, relying on external data sources, or performing training. Moreover, we select computationally efficient models, providing a scalable solution that can be applied to a wide range of languages and domains.\nOur results on a human-annotated question-answer dataset spanning 14 languages demonstrate consistent performance across languages, with Intersection-over-Union (IoU) scores around 0.3 and comparable Spearman correlation values. Our model shows particularly strong performance on Italian and Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining cross-lingual effectiveness without language-specific adaptations. We release our code and architecture to facilitate further research in multilingual hallucination detection.', 'abstract_zh': '大型语言模型中的幻觉——模型生成的虽具说服力但事实错误的信息——对AI构成了重大挑战。"咨询本地专家"：一种新颖的幻觉检测方法，利用专业模型在遇到领域特定不准确信息时表现出更大 Surprise 的直觉。该方法通过计算语言专业化模型困惑度分布之间的差异来识别潜在的幻觉片段。该方法特别适用于多语言环境，可以在没有适应、依赖外部数据源或重新训练的情况下自然扩展到多种语言。此外，我们选择了计算效率高的模型，提供了一个可扩展的解决方案，可以应用于多种语言和领域。我们的结果表明，该方法在覆盖14种语言的人工标注问答数据集上表现一致，平均交并比（IoU）约为0.3，Spearman相关值具有可比性。该模型在意大利语和加泰罗尼亚语上的表现尤为突出，IoU 分数分别为0.42和0.38，同时保持跨语言有效性，无需语言特定适应。我们发布了代码和架构以促进多语言幻觉检测的进一步研究。', 'title_zh': '询问当地人：使用专业模型离散化检测幻觉'}
{'arxiv_id': 'arXiv:2506.03355', 'title': 'Robustness in Both Domains: CLIP Needs a Robust Text Encoder', 'authors': 'Elias Abad Rocamora, Christian Schlarmann, Naman Deep Singh, Yongtao Wu, Matthias Hein, Volkan Cevher', 'link': 'https://arxiv.org/abs/2506.03355', 'abstract': 'Adversarial input attacks can cause a significant shift of CLIP embeddings. This can affect the downstream robustness of models incorporating CLIP in the pipeline, such as text-to-image generative models or large vision language models. While some efforts have been done towards making the CLIP image encoders robust, the robustness of text encoders remains unexplored. In this work, we cover this gap in the literature. We propose LEAF: an efficient adversarial finetuning method for the text domain, with the ability to scale to large CLIP models. Our models significantly improve the zero-shot adversarial accuracy in the text domain, while maintaining the vision performance provided by robust image encoders. When combined with text-to-image diffusion models, we can improve the generation quality under adversarial noise. When employing our robust CLIP encoders in multimodal retrieval tasks, we improve the recall under adversarial noise over standard CLIP models. Finally, we show that robust text encoders facilitate better reconstruction of input text from its embedding via direct optimization.', 'abstract_zh': '对抗输入攻击会导致CLIP嵌入发生显著偏移。这会影响包含CLIP的管道中的下游模型的鲁棒性，例如文本到图像生成模型或大型视觉语言模型。尽管已经有一些努力致力于使CLIP图像编码器变得鲁棒，但文本编码器的鲁棒性仍未被研究。在本文中，我们填补了这一文献空白。我们提出LEAF：一种高效的文本域对抗微调方法，能够扩展到大型CLIP模型。我们的模型在文本域显著提高了零样本对抗准确率，同时保持了由鲁棒图像编码器提供的视觉性能。当与文本到图像扩散模型结合使用时，我们可以在对抗噪声下改善生成质量。当在跨模态检索任务中采用我们 robust 的CLIP编码器时，我们改善了在对抗噪声下的召回率，超过了标准的CLIP模型。最后，我们展示了 robust 的文本编码器通过直接优化能够更好地从其嵌入中重建输入文本。', 'title_zh': '在两个领域都具备鲁棒性：CLIP需要一个鲁棒的文本编码器'}
{'arxiv_id': 'arXiv:2506.03350', 'title': 'Adversarial Attacks on Robotic Vision Language Action Models', 'authors': 'Eliot Krzysztof Jones, Alexander Robey, Andy Zou, Zachary Ravichandran, George J. Pappas, Hamed Hassani, Matt Fredrikson, J. Zico Kolter', 'link': 'https://arxiv.org/abs/2506.03350', 'abstract': 'The emergence of vision-language-action models (VLAs) for end-to-end control is reshaping the field of robotics by enabling the fusion of multimodal sensory inputs at the billion-parameter scale. The capabilities of VLAs stem primarily from their architectures, which are often based on frontier large language models (LLMs). However, LLMs are known to be susceptible to adversarial misuse, and given the significant physical risks inherent to robotics, questions remain regarding the extent to which VLAs inherit these vulnerabilities. Motivated by these concerns, in this work we initiate the study of adversarial attacks on VLA-controlled robots. Our main algorithmic contribution is the adaptation and application of LLM jailbreaking attacks to obtain complete control authority over VLAs. We find that textual attacks, which are applied once at the beginning of a rollout, facilitate full reachability of the action space of commonly used VLAs and often persist over longer horizons. This differs significantly from LLM jailbreaking literature, as attacks in the real world do not have to be semantically linked to notions of harm. We make all code available at this https URL .', 'abstract_zh': 'Vision-Language-Action模型（VLAs）的涌现及其端到端控制正在通过在十亿参数量级融合多模态感应输入来重塑机器人学领域。VLAs的能力主要源于其基于前沿大规模语言模型（LLMs）的架构。然而，由于LLMs已知容易受到对抗性滥用的影响，而在机器人学中存在着重大的物理风险，这引发了关于VLAs是否继承了这些脆弱性的疑问。受这些关注的驱动，本文首次研究了对由VLAs控制的机器人发动的对抗性攻击。我们的主要算法贡献是将LLMs的限制打破攻击适应并应用于获得对VLAs的完全控制权。我们发现，一旦在一段演示的开头应用文本攻击，可以实现对常用VLAs动作空间的完全可达性，并且这种可达性往往可以持续较长时间。这与LLMs的限制打破文献中的情况大不相同，因为在现实世界中的攻击无需与伤害的概念关联。所有代码均已发布在以下链接：this https URL。', 'title_zh': '对抗攻击对机器人视觉语言行动模型的影响'}
{'arxiv_id': 'arXiv:2506.03337', 'title': 'Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity', 'authors': 'Yide Ran, Wentao Guo, Jingwei Sun, Yanzhou Pan, Xiaodong Yu, Hao Wang, Jianwen Xie, Yiran Chen, Denghui Zhang, Zhaozhuo Xu', 'link': 'https://arxiv.org/abs/2506.03337', 'abstract': "Federated Learning enables collaborative fine-tuning of Large Language Models (LLMs) across decentralized Non-Independent and Identically Distributed (Non-IID) clients, but such models' massive parameter sizes lead to significant memory and communication challenges. This work introduces Meerkat, a sparse zeroth-order optimization (ZO) method designed for federated LLM fine-tuning. By limiting fine-tuning to a transferable, static, extremely sparse subset of parameters, Meerkat achieves remarkable communication efficiency, enabling cost-effective high-frequency synchronization. With theoretical analysis and experiments, we show that this high-frequency communication effectively mitigates Non-IID data challenges and leads to superior performance compared to full-parameter ZO. Furthermore, experiment results show that Meerkat outperforms existing sparsity baselines with better performance at the same communication frequency. To further handle Non-IID drift, Meerkat leverages traceable local updates and forms a virtual path for each client. This virtual path mechanism reveals the GradIP phenomenon: the inner products between LLM pre-training gradients maintained by server and client gradients estimated via ZO converges for extreme Non-IID clients but oscillates for IID ones. This distinct behavior provides a signal for identifying clients with extreme data heterogeneity. Using this signal, Meerkat-vp is proposed to analyze GradIP trajectories to identify extreme Non-IID clients and applies early stopping to enhance aggregated model quality. Experiments confirm that Meerkat and Meerkat-vp significantly improve the efficiency and effectiveness of ZO federated LLM fine-tuning.", 'abstract_zh': '联邦学习 Enables 分布式非独立非同分布客户端上大型语言模型的协作微调，但模型的庞大参数量导致了显著的内存和通信挑战。本工作介绍 Meerkat，一种针对联邦语言模型微调设计的稀疏零阶优化方法。通过限制定向传输到可转移的、静态的、极其稀疏的参数子集，Meerkat 实现了卓越的通信效率，使得低成本高频同步成为可能。通过理论分析和实验，我们证明了这种高频通信有效地缓解了非独立非同分布数据的挑战，并且相比全参数零阶优化方法具有更优的性能。此外，实验结果表明，在相同的通信频率下，Meerkat 在性能上优于现有稀疏性基线方法。为了进一步处理非独立非同分布漂移，Meerkat 利用可追踪的本地更新，并为每个客户端形成一条虚拟路径。这种虚拟路径机制揭示了 GradIP 现象：服务器保留的大型语言模型预训练梯度与客户端通过零阶优化估计的梯度之间的内积，在极端非独立非同分布客户端处收敛，而在独立同分布客户端处振荡。这种不同行为为识别具有极端数据异质性的客户端提供了信号。通过利用这一信号，Meerkat-vp 被提出用于分析 GradIP 轨迹以识别极端非独立非同分布客户端，并通过早期停止提升聚合模型质量。实验结果证实，Meerkat 和 Meerkat-vp 显著提高了零阶优化在联邦语言模型微调中的效率和效果。', 'title_zh': '在转移可迁移稀疏性的辅助下缓解零阶联邦大语言模型微调中的非IID漂移'}
{'arxiv_id': 'arXiv:2506.03333', 'title': 'A Differential Perspective on Distributional Reinforcement Learning', 'authors': 'Juan Sebastian Rojas, Chi-Guhn Lee', 'link': 'https://arxiv.org/abs/2506.03333', 'abstract': 'To date, distributional reinforcement learning (distributional RL) methods have exclusively focused on the discounted setting, where an agent aims to optimize a potentially-discounted sum of rewards over time. In this work, we extend distributional RL to the average-reward setting, where an agent aims to optimize the reward received per time-step. In particular, we utilize a quantile-based approach to develop the first set of algorithms that can successfully learn and/or optimize the long-run per-step reward distribution, as well as the differential return distribution of an average-reward MDP. We derive proven-convergent tabular algorithms for both prediction and control, as well as a broader family of algorithms that have appealing scaling properties. Empirically, we find that these algorithms consistently yield competitive performance when compared to their non-distributional equivalents, while also capturing rich information about the long-run reward and return distributions.', 'abstract_zh': '到目前为止，分布强化学习（分布性RL）方法仅专注于折扣设置，其中智能体的目标是优化潜在折扣奖励的时间总和。在本工作中，我们将分布强化学习扩展到平均奖励设置，其中智能体的目标是优化每时间步的奖励。特别地，我们采用分位数方法开发了第一个能够成功学习和/或优化长期每步奖励分布以及平均奖励MDP的差分回报分布的算法家族。我们推导出了预测和控制的已证明收敛的表征算法，以及具有吸引力扩展性的更广泛的算法家族。实验结果表明，这些算法在与非分布性等价算法进行比较时，能够获得竞争力的表现，并且能够捕获丰富的长期奖励和回报分布信息。', 'title_zh': '分布强化学习的微分视角'}
{'arxiv_id': 'arXiv:2506.03320', 'title': 'The Future of Continual Learning in the Era of Foundation Models: Three Key Directions', 'authors': 'Jack Bell, Luigi Quarantiello, Eric Nuertey Coleman, Lanpei Li, Malio Li, Mauro Madeddu, Elia Piccoli, Vincenzo Lomonaco', 'link': 'https://arxiv.org/abs/2506.03320', 'abstract': 'Continual learning--the ability to acquire, retain, and refine knowledge over time--has always been fundamental to intelligence, both human and artificial. Historically, different AI paradigms have acknowledged this need, albeit with varying priorities: early expert and production systems focused on incremental knowledge consolidation, while reinforcement learning emphasised dynamic adaptation. With the rise of deep learning, deep continual learning has primarily focused on learning robust and reusable representations over time to solve sequences of increasingly complex tasks. However, the emergence of Large Language Models (LLMs) and foundation models has raised the question: Do we still need continual learning when centralised, monolithic models can tackle diverse tasks with access to internet-scale knowledge? We argue that continual learning remains essential for three key reasons: (i) continual pre-training is still necessary to ensure foundation models remain up to date, mitigating knowledge staleness and distribution shifts while integrating new information; (ii) continual fine-tuning enables models to specialise and personalise, adapting to domain-specific tasks, user preferences, and real-world constraints without full retraining, avoiding the need for computationally expensive long context-windows; (iii) continual compositionality offers a scalable and modular approach to intelligence, enabling the orchestration of foundation models and agents to be dynamically composed, recombined, and adapted. While continual pre-training and fine-tuning are explored as niche research directions, we argue it is continual compositionality that will mark the rebirth of continual learning. The future of AI will not be defined by a single static model but by an ecosystem of continually evolving and interacting models, making continual learning more relevant than ever.', 'abstract_zh': '持续学习——这种能够随着时间获取、保留和精炼知识的能力一直是人类和人工智能的基本要素。历史上，不同的AI范式都承认了这一需求，尽管各有侧重：早期的专业系统和生产系统侧重于增量知识整合，而强化学习则强调动态适应。随着深度学习的兴起，深度持续学习主要关注随着时间的推移学习 robust 和可重复使用的表示，以解决越来越复杂的任务序列。然而，大型语言模型（LLMs）和基础模型的出现提出了一个问题：当中央集权的单一模型可以利用互联网规模的知识来应对多样的任务时，我们是否还需要持续学习？我们认为持续学习仍然至关重要，原因有三：（i）持续预训练仍然必要，以确保基础模型保持最新，减轻知识陈旧和分布偏移，同时整合新信息；（ii）持续微调使模型能够专业化和个人化，根据具体领域的任务、用户偏好和现实世界约束适应，而无需完全重新训练，避免需要计算成本高昂的长上下文窗口；（iii）持续组合提供了扩展和模块化的智能方法，使基础模型和代理能够在动态组合、重组和适应中相协调。尽管持续预训练和微调被探索为研究方向，我们认为持续组合将继续成为持续学习的新生命。人工智能的未来将不是由单一静态模型定义，而是由不断进化和相互作用的模型生态系统定义，使持续学习比以往更加重要。', 'title_zh': '基础模型时代 continual 学习的未来：三个关键方向'}
{'arxiv_id': 'arXiv:2506.03303', 'title': 'Hopscotch: Discovering and Skipping Redundancies in Language Models', 'authors': 'Mustafa Eyceoz, Nikhil Shivakumar Nayak, Hao Wang, Ligong Han, Akash Srivastava', 'link': 'https://arxiv.org/abs/2506.03303', 'abstract': 'Modern causal language models stack many attention blocks to improve performance, but not all blocks are necessary for every task. We propose Hopscotch, a simple yet effective method that identifies and skips attention blocks with least contributions to a task and adapts to preserve output quality. Hopscotch jointly optimizes which blocks to skip and how to scale the outputs of the remaining layers. By introducing lightweight, trainable scaling parameters to attention and MLP blocks, it mitigates distribution shifts in hidden states caused by removing attention blocks. Hopscotch does not modify model weights or require access to pretraining or instruction-tuning data, and is compatible with existing model compression techniques. When applied to $\\texttt{Llama-3.1-8B}$ and $\\texttt{Qwen2.5-7B}$, Hopscotch achieves less than a 2% drop in performance even after skipping four attention blocks.', 'abstract_zh': 'Hopscotch: 一种简单有效的注意力模块选择与缩放方法以保持输出质量', 'title_zh': '跳房子：发现并跳过语言模型中的冗余'}
{'arxiv_id': 'arXiv:2506.03292', 'title': 'HyperSteer: Activation Steering at Scale with Hypernetworks', 'authors': 'Jiuding Sun, Sidharth Baskaran, Zhengxuan Wu, Michael Sklar, Christopher Potts, Atticus Geiger', 'link': 'https://arxiv.org/abs/2506.03292', 'abstract': 'Steering language models (LMs) by modifying internal activations is a popular approach for controlling text generation. Unsupervised dictionary learning methods, e.g., sparse autoencoders, can be scaled to produce many steering vectors, but lack guarantees on the individual efficacy of each vector and control over the coverage of relevant steering tasks. In contrast, supervised methods for constructing steering vectors are targeted and effective, but require more data collection and training for each additional steering vector produced. In this work, we introduce HyperSteer, a family of hypernetwork-based architectures which are trained end-to-end to generate steering vectors conditioned on the natural language steering prompts and the internals of the steered LM. In our evaluations, we show that scaling HyperSteer with thousands of steering prompts exceeds the performance of state-of-the-art activation steering methods, even on steering prompts never seen during training. Moreover, HyperSteer performs on par with steering-via-prompting.', 'abstract_zh': '通过修改内部激活来引导语言模型（LMs）是控制文本生成的一种流行方法。无监督字典学习方法，例如稀疏自编码器，可以扩展以生成多个引导向量，但缺乏每个向量个体效果的保证，以及对相关引导任务覆盖面的控制。相比之下，构建引导向量的监督方法更具针对性和效果，但每生成一个额外的引导向量需要更多的数据收集和训练。在本工作中，我们介绍了基于超网络的HyperSteer家族架构，这些架构在端到端训练中，根据自然语言引导提示和引导的LM内部生成引导向量。在我们的评估中，我们将HyperSteer扩展到数千个引导提示，即使对于训练过程中未见过的引导提示，其性能也超过了最先进的激活引导方法。此外，HyperSteer与基于提示的引导表现相当。', 'title_zh': 'HyperSteer：大规模Hyper网络驱动激活选择'}
{'arxiv_id': 'arXiv:2506.03275', 'title': 'Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas', 'authors': 'Austin Silveria, Soham V. Govande, Daniel Y. Fu', 'link': 'https://arxiv.org/abs/2506.03275', 'abstract': 'Diffusion Transformers (DiTs) have achieved state-of-the-art performance in high-quality image and video generation but incur substantial compute cost at inference. A common observation is that DiT latent noise vectors change slowly across inference steps, which suggests that the DiT compute may be redundant across steps. In this paper, we aim to speed up inference by reducing this redundancy, without additional training. We first study how activations change between steps in two state-of-the-art open-source DiTs. We find that just 5-25% of the values in attention and MLP explain 70-90% of the change in activations across steps. This finding motivates our approach, Chipmunk, which uses dynamic sparsity at inference time to recompute only the fastest-changing intermediate activations, while caching the rest. Dynamic sparsity introduces two systems challenges: (1) sparse attention and MLP operations tend to underutilize GPU tensor cores; and (2) computing dynamic sparsity patterns at runtime and caching activations both introduce overhead. To address these challenges, Chipmunk first uses a voxel-based reordering of input tokens to introduce column-wise sparsity. We implement column-sparse kernels utilizing efficient sparse gathers from global to shared GPU memory, achieving a 9.3x speedup at 93% sparsity compared to highly-optimized dense baselines. Second, Chipmunk overlaps the computation of sparsity patterns and cache updates with other parts of the computation (e.g., second layer of the MLP) to hide the extra latency. Chipmunk achieves up to 2.16x speedup on HunyuanVideo and 1.41x on FLUX.1-dev without compromising generation quality. Furthermore, we show that Chipmunk can be stacked on top of full step caching, achieving a 3.72x speedup on HunyuanVideo, a 2.67x speedup on WAN2.1, and a 2.25x speedup on FLUX.1-dev with minimal quality impact.', 'abstract_zh': 'Chipmunk: Reducing Redundancy for Efficient Inference of Diffusion Transformers', 'title_zh': 'Chipmunk: 无需训练的基于动态列稀疏增量的扩散变换器加速方法'}
{'arxiv_id': 'arXiv:2506.03270', 'title': 'Grounded Vision-Language Interpreter for Integrated Task and Motion Planning', 'authors': 'Jeremy Siburian, Keisuke Shirai, Cristian C. Beltran-Hernandez, Masashi Hamaya, Michael Görner, Atsushi Hashimoto', 'link': 'https://arxiv.org/abs/2506.03270', 'abstract': 'While recent advances in vision-language models (VLMs) have accelerated the development of language-guided robot planners, their black-box nature often lacks safety guarantees and interpretability crucial for real-world deployment. Conversely, classical symbolic planners offer rigorous safety verification but require significant expert knowledge for setup. To bridge the current gap, this paper proposes ViLaIn-TAMP, a hybrid planning framework for enabling verifiable, interpretable, and autonomous robot behaviors. ViLaIn-TAMP comprises three main components: (1) ViLaIn (Vision-Language Interpreter) - A prior framework that converts multimodal inputs into structured problem specifications using off-the-shelf VLMs without additional domain-specific training, (2) a modular Task and Motion Planning (TAMP) system that grounds these specifications in actionable trajectory sequences through symbolic and geometric constraint reasoning and can utilize learning-based skills for key manipulation phases, and (3) a corrective planning module which receives concrete feedback on failed solution attempts from the motion and task planning components and can feed adapted logic and geometric feasibility constraints back to ViLaIn to improve and further refine the specification. We evaluate our framework on several challenging manipulation tasks in a cooking domain. We demonstrate that the proposed closed-loop corrective architecture exhibits a more than 30% higher mean success rate for ViLaIn-TAMP compared to without corrective planning.', 'abstract_zh': '面向可验证、可解释和自主机器人行为的ViLaIn-TAMP混合规划框架', 'title_zh': '基于情境的视觉-语言解释器用于集成任务与运动规划'}
{'arxiv_id': 'arXiv:2506.03238', 'title': 'Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach', 'authors': 'Ziheng Zhao, Lisong Dai, Ya Zhang, Yanfeng Wang, Weidi Xie', 'link': 'https://arxiv.org/abs/2506.03238', 'abstract': 'Automated interpretation of CT images-particularly localizing and describing abnormal findings across multi-plane and whole-body scans-remains a significant challenge in clinical radiology. This work aims to address this challenge through four key contributions: (i) On taxonomy, we collaborate with senior radiologists to propose a comprehensive hierarchical classification system, with 404 representative abnormal findings across all body regions; (ii) On data, we contribute a dataset containing over 14.5K CT images from multiple planes and all human body regions, and meticulously provide grounding annotations for over 19K abnormalities, each linked to the detailed description and cast into the taxonomy; (iii) On model development, we propose OminiAbnorm-CT, which can automatically ground and describe abnormal findings on multi-plane and whole-body CT images based on text queries, while also allowing flexible interaction through visual prompts; (iv) On benchmarks, we establish three representative evaluation tasks based on real clinical scenarios. Through extensive experiments, we show that OminiAbnorm-CT can significantly outperform existing methods on all the tasks and metrics.', 'abstract_zh': '自动解读CT图像，特别是在多平面和全身扫描中定位和描述异常发现，仍然是临床放射学中的一个重要挑战。本文通过四个关键贡献来应对这一挑战：（i）在分类学上，我们与资深放射科医生合作，提出了一种全面的分层次分类系统，涵盖404种代表性全身各区域的异常发现；（ii）在数据方面，我们提供了一个包含超过14500张多平面和全身各区域CT图像的数据集，并详细标注了超过19000个异常，每个异常都与详细的描述相链接，并纳入分类系统；（iii）在模型开发方面，我们提出了OminiAbnorm-CT，该模型可以根据文本查询自动在多平面和全身CT图像中定位和描述异常发现，同时通过视觉提示支持灵活交互；（iv）在基准测试方面，我们基于真实临床场景建立了三个代表性评估任务。通过广泛的实验，我们表明OminiAbnorm-CT在所有任务和指标上显著优于现有方法。', 'title_zh': '整身CT图像解释的重新思考：基于异常的方法'}
{'arxiv_id': 'arXiv:2506.03237', 'title': 'UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection', 'authors': 'Jigang Fan, Quanlin Wu, Shengjie Luo, Liwei Wang', 'link': 'https://arxiv.org/abs/2506.03237', 'abstract': 'The detection of ligand binding sites for proteins is a fundamental step in Structure-Based Drug Design. Despite notable advances in recent years, existing methods, datasets, and evaluation metrics are confronted with several key challenges: (1) current datasets and methods are centered on individual protein-ligand complexes and neglect that diverse binding sites may exist across multiple complexes of the same protein, introducing significant statistical bias; (2) ligand binding site detection is typically modeled as a discontinuous workflow, employing binary segmentation and subsequent clustering algorithms; (3) traditional evaluation metrics do not adequately reflect the actual performance of different binding site prediction methods. To address these issues, we first introduce UniSite-DS, the first UniProt (Unique Protein)-centric ligand binding site dataset, which contains 4.81 times more multi-site data and 2.08 times more overall data compared to the previously most widely used datasets. We then propose UniSite, the first end-to-end ligand binding site detection framework supervised by set prediction loss with bijective matching. In addition, we introduce Average Precision based on Intersection over Union (IoU) as a more accurate evaluation metric for ligand binding site prediction. Extensive experiments on UniSite-DS and several representative benchmark datasets demonstrate that IoU-based Average Precision provides a more accurate reflection of prediction quality, and that UniSite outperforms current state-of-the-art methods in ligand binding site detection. The dataset and codes will be made publicly available at this https URL.', 'abstract_zh': '基于蛋白质的配体结合位点检测是结构基于药物设计中的一个基本步骤。尽管近年来取得了显著进展，现有的方法、数据集和评估指标仍面临几个关键挑战：（1）当前的数据集和方法主要集中在单一蛋白质-配体复合物上，忽视了相同蛋白质的不同复合物中可能存在多样化的结合位点，引入了显著的统计偏差；（2）配体结合位点检测通常被认为是断续的工作流程，使用二元分割和后续聚类算法；（3）传统的评估指标未能充分反映不同结合位点预测方法的实际性能。为了应对这些问题，我们首先引入了UniSite-DS，这是第一个以UniProt为中心的配体结合位点数据集，包含比之前最广泛使用的数据集多4.81倍的多位点数据和2.08倍的整体数据。然后，我们提出了UniSite，这是第一个基于集合预测损失且使用双射匹配监督的端到端配体结合位点检测框架。此外，我们引入了基于交并比（IoU）的平均精度作为更准确的配体结合位点预测评估指标。在UniSite-DS和几个代表性基准数据集上的广泛实验表明，基于IoU的平均精度提供了更准确的预测质量反映，且UniSite在配体结合位点检测中超越了当前最先进的方法。数据集和代码将在此处公开。', 'title_zh': 'UniSite: 首个多结构域数据集及端到端配体结合位点检测学习框架'}
{'arxiv_id': 'arXiv:2506.03234', 'title': 'BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF', 'authors': 'Kaiwen Duan, Hongwei Yao, Yufei Chen, Ziyun Li, Tong Qiao, Zhan Qin, Cong Wang', 'link': 'https://arxiv.org/abs/2506.03234', 'abstract': "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning text-to-image (T2I) models with human preferences. However, RLHF's feedback mechanism also opens new pathways for adversaries. This paper demonstrates the feasibility of hijacking T2I models by poisoning a small fraction of preference data with natural-appearing examples. Specifically, we propose BadReward, a stealthy clean-label poisoning attack targeting the reward model in multi-modal RLHF. BadReward operates by inducing feature collisions between visually contradicted preference data instances, thereby corrupting the reward model and indirectly compromising the T2I model's integrity. Unlike existing alignment poisoning techniques focused on single (text) modality, BadReward is independent of the preference annotation process, enhancing its stealth and practical threat. Extensive experiments on popular T2I models show that BadReward can consistently guide the generation towards improper outputs, such as biased or violent imagery, for targeted concepts. Our findings underscore the amplified threat landscape for RLHF in multi-modal systems, highlighting the urgent need for robust defenses. Disclaimer. This paper contains uncensored toxic content that might be offensive or disturbing to the readers.", 'abstract_zh': '自然语言生成模型中的有害奖励攻击：劫持文本到图像模型的隐蔽清洁标签中毒攻击', 'title_zh': 'BadReward: 奖励模型在文本到图像RLHF中的清洁标签投毒'}
{'arxiv_id': 'arXiv:2506.03231', 'title': 'NetPress: Dynamically Generated LLM Benchmarks for Network Applications', 'authors': 'Yajie Zhou, Jiajun Ruan, Eric S. Wang, Sadjad Fouladi, Francis Y. Yan, Kevin Hsieh, Zaoxing Liu', 'link': 'https://arxiv.org/abs/2506.03231', 'abstract': 'Despite growing interest in domain-specific benchmarking of large language models (LLMs) and agents, current evaluations remain limited to static, small-scale datasets, especially in high-stakes tasks like network operations that demand reliability for deployments. We present NetPress, an automated benchmark generation framework for evaluating LLM agents in network applications. NetPress introduces a unified abstraction with state and action, enabling dynamic generation of diverse query sets along with corresponding ground truths. At runtime, users can specify benchmark configurations to generate millions of queries on the fly. In addition to dynamic benchmark construction, NetPress integrates with network emulators to provide realistic environment feedback, supporting comprehensive evaluation across correctness, safety, and latency. We instantiate NetPress on three representative applications, revealing interesting fine-grained differences in agent behavior that static, correctness-only benchmarks often miss. NetPress moves LLM evaluation toward realistic, scalable testing in infrastructure-centric domains, helping close the gap between benchmark performance and real-world deployment readiness. Code is available at this https URL.', 'abstract_zh': 'NetPress：面向网络应用的大语言模型代理自动化基准生成框架', 'title_zh': 'NetPress: 动态生成的网络应用LLM基准测试'}
{'arxiv_id': 'arXiv:2506.03230', 'title': 'DiaBlo: Diagonal Blocks Are Sufficient For Finetuning', 'authors': 'Selcuk Gurses, Aozhong Zhang, Yanxia Deng, Xun Dong, Xin Li, Naigang Wang, Penghang Yin, Zi Yang', 'link': 'https://arxiv.org/abs/2506.03230', 'abstract': 'Finetuning is a critical step for adapting large language models (LLMs) to domain-specific downstream tasks. To mitigate the substantial computational and memory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT) methods have been proposed to update only a small subset of model parameters. However, performance gaps between PEFT approaches and full-model fine-tuning still exist. In this work, we present DiaBlo, a simple yet effective PEFT approach that updates only the diagonal blocks of selected model weight matrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates the need for low rank matrix products, thereby avoiding the reliance on auxiliary initialization schemes or customized optimization strategies to improve convergence. This design leads to stable and robust convergence while maintaining comparable memory efficiency and training speed to LoRA. We conduct extensive experiments across a range of tasks, including commonsense reasoning, arithmetic reasoning, code generation, and safety alignment, to evaluate the effectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo demonstrates strong and consistent performance while maintaining high memory efficiency and fast finetuning speed. Codes are available at this https URL.', 'abstract_zh': 'DiaBlo: 一种简单有效的参数高效微调方法', 'title_zh': 'DiaBlo: 对角块足以进行微调'}
{'arxiv_id': 'arXiv:2506.03229', 'title': 'Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning', 'authors': 'Qian-Wei Wang, Yuqiu Xie, Letian Zhang, Zimo Liu, Shu-Tao Xia', 'link': 'https://arxiv.org/abs/2506.03229', 'abstract': 'In the context of noisy partial label learning (NPLL), each training sample is associated with a set of candidate labels annotated by multiple noisy annotators. With the emergence of high-performance pre-trained vision-language models (VLMs) such as CLIP, LLaVa and GPT-4V, the direction of using these models to replace time-consuming manual annotation workflows and achieve "manual-annotation-free" training for downstream tasks has become a highly promising research avenue. This paper focuses on learning from noisy partial labels annotated by pre-trained VLMs and proposes an innovative collaborative consistency regularization (Co-Reg) method. Unlike the symmetric noise primarily addressed in traditional noisy label learning, the noise generated by pre-trained models is instance-dependent, embodying the underlying patterns of the pre-trained models themselves, which significantly increases the learning difficulty for the model. To address this, we simultaneously train two neural networks that implement collaborative purification of training labels through a "Co-Pseudo-Labeling" mechanism, while enforcing consistency regularization constraints in both the label space and feature representation space. Our method can also leverage few-shot manually annotated valid labels to further enhance its performances. Comparative experiments with different denoising and disambiguation algorithms, annotation manners, and pre-trained model application schemes fully validate the effectiveness of the proposed method, while revealing the broad prospects of integrating weakly-supervised learning techniques into the knowledge distillation process of pre-trained models.', 'abstract_zh': '基于预训练视觉-语言模型的噪声部分标签学习中的协作一致性正则化方法', 'title_zh': '预训练多模态模型辅助噪声_partial_标签学习'}
{'arxiv_id': 'arXiv:2506.03227', 'title': 'Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification', 'authors': 'Abdelrahman Sayed Sayed, Pierre-Jean Meyer, Mohamed Ghazel', 'link': 'https://arxiv.org/abs/2506.03227', 'abstract': 'A neural ordinary differential equation (neural ODE) is a machine learning model that is commonly described as a continuous depth generalization of a residual network (ResNet) with a single residual block, or conversely, the ResNet can be seen as the Euler discretization of the neural ODE. These two models are therefore strongly related in a way that the behaviors of either model are considered to be an approximation of the behaviors of the other. In this work, we establish a more formal relationship between these two models by bounding the approximation error between two such related models. The obtained error bound then allows us to use one of the models as a verification proxy for the other, without running the verification tools twice: if the reachable output set expanded by the error bound satisfies a safety property on one of the models, this safety property is then guaranteed to be also satisfied on the other model. This feature is fully reversible, and the initial safety verification can be run indifferently on either of the two models. This novel approach is illustrated on a numerical example of a fixed-point attractor system modeled as a neural ODE.', 'abstract_zh': '一种神经常微分方程（神经ODE）是一种常见的连续深度残差网络（ResNet）单个残差块的连续深度泛化，或者反过来，ResNet 可以被视为神经ODE 的欧拉格式化。这两种模型因此有着密切的关系，即每种模型的行为都被认为是另一种模型行为的近似。在本文中，我们通过界定向相关两种模型之间的近似误差来建立它们之间更正式的关系。得到的误差界允许我们不必运行验证工具两次，即可使用其中一种模型作为另一种模型的验证代理：如果误差界的可达输出集在其中一种模型上满足安全性属性，则这种安全性属性也保证在另一种模型上被满足。这一特性是完全可逆的，初始的安全性验证可以在这两种模型中任意一个上运行。本文以一个固定点吸引子系统作为神经ODE 的数值示例来说明这一新颖的方法。', 'title_zh': '连接神经ODE和ResNet：安全验证的正式误差界'}
{'arxiv_id': 'arXiv:2506.03225', 'title': 'Multiple-Frequencies Population-Based Training', 'authors': 'Waël Doulazmi, Auguste Lehuger, Marin Toromanoff, Valentin Charraut, Thibault Buhet, Fabien Moutarde', 'link': 'https://arxiv.org/abs/2506.03225', 'abstract': "Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules instead of fixed configurations. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice of evolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without actually tuning hyperparameters.", 'abstract_zh': '基于多个频率的 Population-Based Training 算法：一种缓解贪婪问题的新型超参数优化方法', 'title_zh': '多频率基于群体的训练'}
{'arxiv_id': 'arXiv:2506.03224', 'title': 'OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data', 'authors': 'Jinwei Zeng, Yu Liu, Guozhen Zhang, Jingtao Ding, Yuming Lin, Jian Yuan, Yong Li', 'link': 'https://arxiv.org/abs/2506.03224', 'abstract': "Accurately estimating high-resolution carbon emissions is crucial for effective emission governance and mitigation planning. While conventional methods for precise carbon accounting are hindered by substantial data collection efforts, the rise of open data and advanced learning techniques offers a promising solution. Once an open data-based prediction model is developed and trained, it can easily infer emissions for new areas based on available open data. To address this, we incorporate two modalities of open data, satellite images and point-of-interest (POI) data, to predict high-resolution urban carbon emissions, with satellite images providing macroscopic and static and POI data offering fine-grained and relatively dynamic functionality information. However, estimating high-resolution carbon emissions presents two significant challenges: the intertwined and implicit effects of various functionalities on carbon emissions, and the complex spatial contiguity correlations that give rise to the agglomeration effect. Our model, OpenCarbon, features two major designs that target the challenges: a cross-modality information extraction and fusion module to extract complementary functionality information from two modules and model their interactions, and a neighborhood-informed aggregation module to capture the spatial contiguity correlations. Extensive experiments demonstrate our model's superiority, with a significant performance gain of 26.6\\% on R2. Further generalizability tests and case studies also show OpenCarbon's capacity to capture the intrinsic relation between urban functionalities and carbon emissions, validating its potential to empower efficient carbon governance and targeted carbon mitigation planning. Codes and data are available: this https URL.", 'abstract_zh': '基于开放数据的高分辨率城市碳排放准确估计对于有效的排放治理和减缓规划至关重要。尽管传统精细碳核算方法受限于大量数据收集工作，但开放数据和先进学习技术的兴起提供了前景广阔的解决方案。一旦基于开放数据的预测模型得到开发和训练，就可以根据现有开放数据轻松推断新地区的排放情况。为应对这一挑战，我们结合了卫星图像和兴趣点（POI）数据两种开放数据模态，以预测高分辨率城市碳排放，其中卫星图像提供宏观和静态信息，POI数据提供细粒度的相对动态功能信息。然而，高分辨率碳排放估计面临两个重要挑战：多种功能对碳排放的交织和隐含影响，以及复杂的空间连续性关联导致的集聚效应。我们的模型OpenCarbon针对这些挑战进行了两项主要设计：一种跨模态信息提取融合模块，用于从两个模态中提取互补的功能性信息并建模它们的相互作用；一种基于邻域的信息聚合模块，用于捕获空间连续性关联。广泛的实验证明了该模型的优越性，在R2上的性能提升达到26.6%。进一步的泛化测试和案例研究也表明，OpenCarbon能够捕捉城市功能与碳排放之间的内在关系，验证了其在提供有效碳治理和针对性碳减缓规划方面的能力。代码和数据可在以下链接获取：this https URL。', 'title_zh': 'OpenCarbon：基于对比学习的多模态神经网络方法用于开放数据驱动的高分辨率碳排放预测'}
{'arxiv_id': 'arXiv:2506.03218', 'title': 'Beware! The AI Act Can Also Apply to Your AI Research Practices', 'authors': 'Alina Wernick, Kristof Meding', 'link': 'https://arxiv.org/abs/2506.03218', 'abstract': "The EU has become one of the vanguards in regulating the digital age. A particularly important regulation in the Artificial Intelligence (AI) domain is the EU AI Act, which entered into force in 2024. The AI Act specifies -- due to a risk-based approach -- various obligations for providers of AI systems. These obligations, for example, include a cascade of documentation and compliance measures, which represent a potential obstacle to science. But do these obligations also apply to AI researchers? This position paper argues that, indeed, the AI Act's obligations could apply in many more cases than the AI community is aware of. In our analysis of the AI Act and its applicability, we contribute the following: 1.) We give a high-level introduction to the AI Act aimed at non-legal AI research scientists. 2.) We explain with everyday research examples why the AI Act applies to research. 3.) We analyse the exceptions of the AI Act's applicability and state that especially scientific research exceptions fail to account for current AI research practices. 4.) We propose changes to the AI Act to provide more legal certainty for AI researchers and give two recommendations for AI researchers to reduce the risk of not complying with the AI Act. We see our paper as a starting point for a discussion between policymakers, legal scholars, and AI researchers to avoid unintended side effects of the AI Act on research.", 'abstract_zh': '欧盟已成为数字时代监管的先锋。特别是在人工智能（AI）领域，欧盟AI法案于2024年生效。该法案由于采取风险为基础的方法，对AI系统的提供者规定了多种义务。这些义务，例如，包括一系列的文件和合规措施，可能成为科学研究的障碍。但这些义务是否也适用于AI研究人员？本文认为，实际上，欧盟AI法案的义务可能比AI社区意识到的更为广泛。在我们对欧盟AI法案及其适用性的分析中，我们做出以下贡献：1）我们为非法律专业背景的AI研究科学家提供AI法案的高层次介绍。2）我们通过日常研究案例解释为什么欧盟AI法案适用于研究。3）我们分析欧盟AI法案的适用例外情况，并指出科学研究的例外情况未能充分考虑到当前的AI研究实践。4）我们提出对欧盟AI法案的修改建议，为AI研究人员提供更多法律确定性，并给出两条建议以降低不符合欧盟AI法案的风险。我们认为，我们的论文是政策制定者、法律学者和AI研究人员之间讨论的起点，以避免欧盟AI法案对研究的意外负面影响。', 'title_zh': '小心！AI 法案也可能适用于你的 AI 研究实践。'}
{'arxiv_id': 'arXiv:2506.03214', 'title': 'A Pre-trained Framework for Multilingual Brain Decoding Using Non-invasive Recordings', 'authors': 'Yi Guo, Yihang Dong, Michael Kwok-Po Ng, Shuqiang Wang', 'link': 'https://arxiv.org/abs/2506.03214', 'abstract': 'Brain-computer interfaces (BCIs) with speech decoding from brain recordings have broad application potential in fields such as clinical rehabilitation and cognitive neuroscience. However, current decoding methods remain limited to single-language, single-subject, and single neuroimaging modality settings, restricting their clinical applicability and generalizability. Here we propose a joint multilingual, multi-subject and multimodal decoding framework. It maps diverse brain recordings into a unified semantic space defined by a pre-trained multilingual model (PMM), enabling decoding across multiple languages, multiple subjects and multiple neuroimaging modalities. The proposed framework is validated using non-invasive brain recordings from 159 participants across four languages. Experimental results show that it exhibits strong generalization across multilingual, multi-subject, and multimodal settings. More importantly, the proposed framework can promote linguistic fairness, which is vital for underrepresented languages in BCI applications. The unified semantic space enables cross-lingual mapping enhancement, allowing the framework to boost the decoding performance of underrepresented languages, thereby promoting linguistic fairness. Overall, the proposed framework establishes a new potential paradigm for brain decoding, opening new paths for broader applications of BCI.', 'abstract_zh': '基于多语言、多被试和多模态解码的脑机接口框架', 'title_zh': '使用非侵入性记录数据的多语言脑解码预训练框架'}
{'arxiv_id': 'arXiv:2506.03210', 'title': 'FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution', 'authors': 'Qiusheng Huang, Yuan Niu, Xiaohui Zhong, Anboyu Guo, Lei Chen, Dianjun Zhang, Xuefeng Zhang, Hao Li', 'link': 'https://arxiv.org/abs/2506.03210', 'abstract': 'Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time. We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12° spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability , mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.', 'abstract_zh': '准确的高分辨率海洋预报对于海上操作和环境监测至关重要。传统数值模型能够生成亚日尺度、涡动分辨率的预报，但计算密集且在保持细尺度空间和时间分辨率的准确性方面面临挑战。相比之下，近期的数据驱动方法提高了计算效率并展现出了新兴潜力，但通常仅限于日尺度预报，并且在亚日尺度预测中由于时间累积误差而受到限制。我们引入了FuXi-Ocean，这是首个实现每六小时预报、涡动分辨率1/12°空间分辨率的全球海洋预报模型，可达到1500米深海。该模型架构集成了上下文感知特征提取模块和采用堆叠注意块的预测网络。核心创新是Mixture-of-Time (MoT) 模块，该模块通过学习变量特定的可靠性自适应地整合多种时间上下文的预测，从而减轻序列预报中的累积误差。通过全面的实验评估，FuXi-Ocean 在深度多个层次上展示了在预测温度、盐度和流速等关键变量方面的卓越能力。', 'title_zh': 'FuXi-Ocean: 一个具有亚日分辨率的全球海洋预报系统'}
{'arxiv_id': 'arXiv:2506.03209', 'title': 'Predicting Postoperative Stroke in Elderly SICU Patients: An Interpretable Machine Learning Model Using MIMIC Data', 'authors': 'Tinghuan Li, Shuheng Chen, Junyi Fan, Elham Pishgar, Kamiar Alaei, Greg Placencia, Maryam Pishgar', 'link': 'https://arxiv.org/abs/2506.03209', 'abstract': 'Postoperative stroke remains a critical complication in elderly surgical intensive care unit (SICU) patients, contributing to prolonged hospitalization, elevated healthcare costs, and increased mortality. Accurate early risk stratification is essential to enable timely intervention and improve clinical outcomes. We constructed a combined cohort of 19,085 elderly SICU admissions from the MIMIC-III and MIMIC-IV databases and developed an interpretable machine learning (ML) framework to predict in-hospital stroke using clinical data from the first 24 hours of Intensive Care Unit (ICU) stay. The preprocessing pipeline included removal of high-missingness features, iterative Singular Value Decomposition (SVD) imputation, z-score normalization, one-hot encoding, and class imbalance correction via the Adaptive Synthetic Sampling (ADASYN) algorithm. A two-stage feature selection process-combining Recursive Feature Elimination with Cross-Validation (RFECV) and SHapley Additive exPlanations (SHAP)-reduced the initial 80 variables to 20 clinically informative predictors. Among eight ML models evaluated, CatBoost achieved the best performance with an AUROC of 0.8868 (95% CI: 0.8802--0.8937). SHAP analysis and ablation studies identified prior cerebrovascular disease, serum creatinine, and systolic blood pressure as the most influential risk factors. Our results highlight the potential of interpretable ML approaches to support early detection of postoperative stroke and inform decision-making in perioperative critical care.', 'abstract_zh': '老年手术重症监护病房(SICU)患者术后中风仍然是一个关键并发症，会导致住院时间延长、医疗成本增加以及死亡率提高。准确的早期风险分层是必要的，以便能够及时干预并改善临床结局。我们从MIMIC-III和MIMIC-IV数据库中构建了一个包含19,085例老年SICU入院的联合队列，并开发了一个可解释的机器学习(ML)框架，利用重症监护病房(ICU)住院前24小时的临床数据预测院内中风。预处理管道包括缺失值特征的移除、迭代奇异值分解(SVD)插补、z-score归一化、独热编码以及通过自适应合成采样(ADASYN)算法进行的类别不平衡校正。通过结合递归特征消除与交叉验证(RFECV)和SHapley添加解释(SHAP)的两阶段特征选择过程，从初始的80个变量中选择了20个临床相关的预测变量。在评估的八个ML模型中，CatBoost取得了最佳性能，AUC-ROC为0.8868（95%CI：0.8802-0.8937）。SHAP分析和消融研究确定了既往脑血管疾病、血清肌酐和收缩压是最具影响力的危险因素。我们的研究结果突显了可解释的ML方法在支持术后中风的早期检测和 perioperative 手术期重症监护中的决策制定方面的潜在价值。', 'title_zh': '基于MIMIC数据的可解释机器学习模型：用于预测老年SICU术后卒中发生'}
{'arxiv_id': 'arXiv:2506.03207', 'title': 'Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning', 'authors': 'Md Nahid Hasan Shuvo, Moinul Hossain', 'link': 'https://arxiv.org/abs/2506.03207', 'abstract': 'Federated Learning (FL) is increasingly adopted as a decentralized machine learning paradigm due to its capability to preserve data privacy by training models without centralizing user data. However, FL is susceptible to indirect privacy breaches via network traffic analysis-an area not explored in existing research. The primary objective of this research is to study the feasibility of fingerprinting deep learning models deployed within FL environments by analyzing their network-layer traffic information. In this paper, we conduct an experimental evaluation using various deep learning architectures (i.e., CNN, RNN) within a federated learning testbed. We utilize machine learning algorithms, including Support Vector Machines (SVM), Random Forest, and Gradient-Boosting, to fingerprint unique patterns within the traffic data. Our experiments show high fingerprinting accuracy, achieving 100% accuracy using Random Forest and around 95.7% accuracy using SVM and Gradient Boosting classifiers. This analysis suggests that we can identify specific architectures running within the subsection of the network traffic. Hence, if an adversary knows about the underlying DL architecture, they can exploit that information and conduct targeted attacks. These findings suggest a notable security vulnerability in FL systems and the necessity of strengthening it at the network level.', 'abstract_zh': '联邦学习中的深层学习模型指纹识别研究：基于网络层流量信息的可行性分析', 'title_zh': '基于联邦学习中网络流量模式的深度学习模型指纹识别'}
{'arxiv_id': 'arXiv:2506.03198', 'title': 'FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment', 'authors': 'Hao Yin, Lijun Gu, Paritosh Parmar, Lin Xu, Tianxiao Guo, Weiwei Fu, Yang Zhang, Tianyou Zheng', 'link': 'https://arxiv.org/abs/2506.03198', 'abstract': 'With the increasing awareness of health and the growing desire for aesthetic physique, fitness has become a prevailing trend. However, the potential risks associated with fitness training, especially with weight-loaded fitness actions, cannot be overlooked. Action Quality Assessment (AQA), a technology that quantifies the quality of human action and provides feedback, holds the potential to assist fitness enthusiasts of varying skill levels in achieving better training outcomes. Nevertheless, current AQA methodologies and datasets are limited to single-view competitive sports scenarios and RGB modality and lack professional assessment and guidance of fitness actions. To address this gap, we propose the FLEX dataset, the first multi-modal, multi-action, large-scale dataset that incorporates surface electromyography (sEMG) signals into AQA. FLEX utilizes high-precision MoCap to collect 20 different weight-loaded actions performed by 38 subjects across 3 different skill levels for 10 repetitions each, containing 5 different views of the RGB video, 3D pose, sEMG, and physiological information. Additionally, FLEX incorporates knowledge graphs into AQA, constructing annotation rules in the form of penalty functions that map weight-loaded actions, action keysteps, error types, and feedback. We conducted various baseline methodologies on FLEX, demonstrating that multimodal data, multiview data, and fine-grained annotations significantly enhance model performance. FLEX not only advances AQA methodologies and datasets towards multi-modal and multi-action scenarios but also fosters the integration of artificial intelligence within the fitness domain. Dataset and code are available at this https URL.', 'abstract_zh': '随着健康意识的增强和对优美体态的日益追求，健身已成为一种流行趋势。然而，与健身训练相关联的潜在风险，尤其是与负重健身动作相关的风险，不容忽视。动作质量评估（AQA）技术通过量化人类动作的质量并提供反馈，有潜力辅助各技能等级的健身爱好者实现更好的训练效果。然而，当前的AQA方法和数据集局限于单视角竞技运动场景和RGB模态，并缺乏专业对健身动作的评估和指导。为填补这一空白，我们提出了FLEX数据集，这是首个将表面肌电图（sEMG）信号融入AQA的多模态、多动作大规模数据集。FLEX利用高精度动捕技术收集了38名受试者在三个不同技能等级下进行的20种不同负重动作，每种动作重复10次，包含RGB视频的5种视角、3D姿态、sEMG和生理信息。此外，FLEX还将知识图谱引入AQA中，构建了以惩罚函数形式表示的标注规则，将负重动作、动作关键步、错误类型和反馈映射起来。在FLEX上进行了多种基准方法测试，证明多模态数据、多视角数据和细粒度标注显著提升了模型性能。FLEX不仅推动了AQA方法和数据集向多模态、多动作场景的发展，还促进了人工智能在健身领域的应用。数据集和代码可在以下网址获取。', 'title_zh': 'FLEX：一个大规模多模态多动作数据集，用于健身动作质量评估'}
{'arxiv_id': 'arXiv:2506.03197', 'title': 'Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing', 'authors': 'Baode Wang, Biao Wu, Weizhen Li, Meng Fang, Yanjie Liang, Zuming Huang, Haozhe Wang, Jun Huang, Ling Chen, Wei Chu, Yuan Qi', 'link': 'https://arxiv.org/abs/2506.03197', 'abstract': 'Automated parsing of scanned documents into richly structured, machine-readable formats remains a critical bottleneck in Document AI, as traditional multi-stage pipelines suffer from error propagation and limited adaptability to diverse layouts. We introduce layoutRL, an end-to-end reinforcement learning framework that trains models to be explicitly layout-aware by optimizing a composite reward of normalized edit distance, paragraph count accuracy, and reading order preservation. Leveraging our newly released dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic scanned document parsing data with expert-filtered real-world documents, we instantiate layoutRL in a vision-language-model-based parser called Infinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and formula extraction, and reading order detection, Infinity-Parser achieves new state-of-the-art performance in both accuracy and structural fidelity, outpacing specialist pipelines and general-purpose vision-language models. We will publicly release our code and dataset to accelerate progress in robust document understanding.', 'abstract_zh': '基于强化学习的自动扫描文档解析方法及其在文档AI中的应用：从传统多阶段管道到布局感知端到端框架', 'title_zh': '无限解析器：面向布局的强化学习扫描文档解析'}
{'arxiv_id': 'arXiv:2506.03195', 'title': 'Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs', 'authors': 'Yunqi Hong, Sohyun An, Andrew Bai, Neil Y.C. Lin, Cho-Jui Hsieh', 'link': 'https://arxiv.org/abs/2506.03195', 'abstract': 'Despite Multimodal Large Language Models (MLLMs) showing promising results on general zero-shot image classification tasks, fine-grained image classification remains challenging. It demands precise attention to subtle visual details to distinguish between visually similar subcategories--details that MLLMs may easily overlook without explicit guidance. To address this, we introduce AutoSEP, an iterative self-supervised prompt learning framework designed to enhance MLLM fine-grained classification capabilities in a fully unsupervised manner. Our core idea is to leverage unlabeled data to learn a description prompt that guides MLLMs in identifying crucial discriminative features within an image, and boosts classification accuracy. We developed an automatic self-enhancing prompt learning framework called AutoSEP to iteratively improve the description prompt using unlabeled data, based on instance-level classification scoring function. AutoSEP only requires black-box access to MLLMs, eliminating the need for any training or fine-tuning. We evaluate our approach on multiple fine-grained classification datasets. It consistently outperforms other unsupervised baselines, demonstrating the effectiveness of our self-supervised optimization framework. Notably, AutoSEP on average improves 13 percent over standard zero-shot classification and 5 percent over the best-performing baselines. Code is available at: this https URL', 'abstract_zh': '尽管多模态大语言模型（MLLMs）在通用零 shot 图像分类任务中显示出了有希望的结果，但细粒度图像分类仍然具有挑战性。它要求对细微的视觉细节给予精确的关注，以区分视觉上相似的子类别——MLLMs 在没有明确指导的情况下可能会忽略这些细节。为了解决这个问题，我们引入了 AutoSEP，这是一种迭代的自我监督提示学习框架，旨在以完全无监督的方式增强 MLLM 的细粒度分类能力。我们的核心思想是利用未标注数据来学习一个描述性提示，该提示可以指导 MLLMs 识别图像中的关键判别特征，并提升分类准确性。我们基于实例级分类评分函数开发了一个自动自我增强提示学习框架 AutoSEP，用于迭代地利用未标注数据改进描述性提示。AutoSEP 只需要对 MLLMs 的黑盒访问，无需任何训练或微调。我们在多个细粒度分类数据集中评估了我们的方法。结果显示，该方法在多个未监督基准上表现优异，证明了我们自我监督优化框架的有效性。值得注意的是，AutoSEP 平均提高了 13% 的标准零 shot 分类性能，并优于最佳基准 5%。代码可在以下网址获取：this https URL', 'title_zh': '未标注数据改进多模态LLM的细粒度图像零样本分类'}
{'arxiv_id': 'arXiv:2506.03194', 'title': 'HueManity: Probing Fine-Grained Visual Perception in MLLMs', 'authors': 'Rynaa Grover, Jayant Sravan Tamarapalli, Sahiti Yerramilli, Nilay Pande', 'link': 'https://arxiv.org/abs/2506.03194', 'abstract': "Multimodal Large Language Models (MLLMs) excel at high-level visual reasoning, but their performance on nuanced perceptual tasks remains surprisingly limited. We present HueManity, a benchmark designed to assess visual perception in MLLMs. The dataset comprises 83,850 images featuring two-character alphanumeric strings embedded in Ishihara test style dot patterns, challenging models on precise pattern recognition. Our evaluation of nine state-of-the-art MLLMs on HueManity demonstrates a significant performance deficit compared to human and traditional computer vision baselines. The best-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a striking 3% on the alphanumeric `hard' task. In contrast, human participants achieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model reached accuracies of 96.5% and 94.5%. These results highlight a critical gap in the visual capabilities of current MLLMs. Our analysis further explores potential architectural and training-paradigm factors contributing to this perceptual gap in MLLMs. We open-source HueManity dataset and code to foster further research in improving perceptual robustness of MLLMs.", 'abstract_zh': '多模态大语言模型在nuance感知任务上的表现限制：HueManity基准的构建与评估', 'title_zh': 'Huemanity: 探究MLLMs的细粒度视觉感知'}
{'arxiv_id': 'arXiv:2506.03192', 'title': 'Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers', 'authors': 'Basudha Pal, Rama Chellappa, Muhammad Umair', 'link': 'https://arxiv.org/abs/2506.03192', 'abstract': 'While echocardiography and MRI are clinical standards for evaluating cardiac structure, their use is limited by cost and this http URL introduce a direct classification framework that predicts severe left ventricular hypertrophy from chest X-rays, without relying on anatomical measurements or demographic inputs. Our approach achieves high AUROC and AUPRC, and employs Mutual Information Neural Estimation to quantify feature expressivity. This reveals clinically meaningful attribute encoding and supports transparent model interpretation.', 'abstract_zh': '无需左心室解剖测量的胸部X光图像直接分类框架预测严重左心室肥厚', 'title_zh': '基于胸部X光的严重左室肥大分类器中的人口统计和解剖信息编码'}
{'arxiv_id': 'arXiv:2506.03191', 'title': 'Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward', 'authors': 'Muhammad Islam, Tao Huang, Euijoon Ahn, Usman Naseem', 'link': 'https://arxiv.org/abs/2506.03191', 'abstract': 'This paper presents an in-depth survey on the use of multimodal Generative Artificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs) for human motion understanding and generation, offering insights into emerging methods, architectures, and their potential to advance realistic and versatile motion synthesis. Focusing exclusively on text and motion modalities, this research investigates how textual descriptions can guide the generation of complex, human-like motion sequences. The paper explores various generative approaches, including autoregressive models, diffusion models, Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models, by analyzing their strengths and limitations in terms of motion quality, computational efficiency, and adaptability. It highlights recent advances in text-conditioned motion generation, where textual inputs are used to control and refine motion outputs with greater precision. The integration of LLMs further enhances these models by enabling semantic alignment between instructions and motion, improving coherence and contextual relevance. This systematic survey underscores the transformative potential of text-to-motion GenAI and LLM architectures in applications such as healthcare, humanoids, gaming, animation, and assistive technologies, while addressing ongoing challenges in generating efficient and realistic human motion.', 'abstract_zh': '本文深入调研了多模态生成人工智能（GenAI）和自回归大型语言模型（LLMs）在人类动作理解和生成中的应用，提供了关于新兴方法、架构及其对逼真且多功能动作合成前景的见解。专注于文本和动作模态，本研究探讨了文本描述如何指导复杂人类样动作序列的生成。论文探讨了各种生成方法，包括自回归模型、扩散模型、生成对抗网络（GANs）、变分自编码器（VAEs）和基于转换器的模型，通过分析它们在动作质量、计算效率和适应性方面的优势和局限性。文章强调了文本条件动作生成的最新进展，其中文本输入被用于更精确地控制和细化动作输出。结合LLMs进一步增强了这些模型，使其能够实现指令与动作之间的语义对齐，提高一致性和上下文相关性。本系统调研突出了从文本到动作的GenAI和LLM架构在医疗保健、类人机器人、游戏、动画和辅助技术等领域中的变革潜力，同时应对生成高效且逼真人类动作的持续挑战。', 'title_zh': '基于自回归大语言模型的多模态生成人工智能：对人体运动理解与生成的一种新途径'}
{'arxiv_id': 'arXiv:2506.03190', 'title': 'MINT: Memory-Infused Prompt Tuning at Test-time for CLIP', 'authors': 'Jiaming Yi, Ruirui Pan, Jishen Yang, Xiulong Yang', 'link': 'https://arxiv.org/abs/2506.03190', 'abstract': "Improving the generalization ability of Vision-Language Pre-trained Models (VLMs) under test-time data distribution shifts remains a critical challenge. The existing Test-Time Adaptation (TTA) methods fall short in fully leveraging the model's internal knowledge, particularly in dynamically adapting to complex and hierarchical visual semantic information. In this paper, we propose Memory-Infused Prompt Tuning (MINT), a novel framework to address this issue. Inspired by human associative memory theory, MINT introduces a Memory Prompt Bank (MPB), which stores learnable key-value prompt pairs that work as a memory of previously seen samples. During the test time, relevant prompt pairs in the MPB are retrieved by the hierarchical visual features of test images to dynamically assemble Associative Prompts. The associative prompts are then injected into the image encoder for fine-grained, customized visual contextual guidance. MINT also utilizes learnable text prompts. MINT thus enables rapid, precise VLM adaptation at test time by leveraging this MPB-acquired memory, without source data or retraining. The code is available at this https URL.", 'abstract_zh': '改进视图-语言预训练模型（VLMs）在测试时数据分布偏移下的泛化能力仍然是一个关键挑战。现有的测试时适调（TTA）方法在充分利用模型内部知识方面存在不足，特别是在动态适应复杂的层次视觉语义信息方面。在本文中，我们提出了一种新的框架——记忆融合提示调优（MINT），以解决这一问题。受人类关联记忆理论的启发，MINT引入了一个记忆提示库（MPB），该库存储可学习的键值提示对，作为之前见过的样本的记忆。在测试时，MPB 中的相关提示对通过测试图像的层次视觉特征进行检索，以动态组装关联提示。这些关联提示随后被注入到图像编码器中，以提供细粒度且定制化的视觉上下文指导。MINT 还利用可学习的文本提示。因此，MINT 通过利用 MPB 获得的记忆，在测试时能够实现快速且精确的 VLM 适调，无需源数据或重新训练。代码可在以下链接获取。', 'title_zh': 'MINT：测试时记忆注入提示调优 for CLIP'}
{'arxiv_id': 'arXiv:2506.03189', 'title': 'Continual Learning in Vision-Language Models via Aligned Model Merging', 'authors': 'Ghada Sokar, Gintare Karolina Dziugaite, Anurag Arnab, Ahmet Iscen, Pablo Samuel Castro, Cordelia Schmid', 'link': 'https://arxiv.org/abs/2506.03189', 'abstract': 'Continual learning is conventionally tackled through sequential fine-tuning, a process that, while enabling adaptation, inherently favors plasticity over the stability needed to retain prior knowledge. While existing approaches attempt to mitigate catastrophic forgetting, a bias towards recent tasks persists as they build upon this sequential nature. In this work we present a new perspective based on model merging to maintain stability while still retaining plasticity. Rather than just sequentially updating the model weights, we propose merging newly trained task parameters with previously learned ones, promoting a better balance. To maximize the effectiveness of the merging process, we propose a simple mechanism that promotes learning aligned weights with previous ones, thereby avoiding interference when merging. We evaluate this approach on large Vision-Language Models (VLMs), and demonstrate its effectiveness in reducing forgetting, increasing robustness to various task orders and similarities, and improving generalization.', 'abstract_zh': '持续学习通常通过序列微调来处理，这一过程虽然能够实现适应，但本质上偏向于促进稳定性而牺牲保留先验知识所需的稳定性。现有的方法试图缓解灾难性遗忘，但它们建立在序列性的基础上，对最近任务的偏见仍然存在。在本文中，我们提出了一个新的基于模型合并的视角，旨在在保留可塑性的同时维持稳定性。我们不是仅仅顺序更新模型权重，而是提出将新训练的任务参数与之前学习的参数合并，以促进更好的平衡。为了最大化合并过程的有效性，我们提出了一种简单的机制来促进学习与之前参数对齐的权重，从而在合并时避免相互干扰。我们在大规模视觉-语言模型（VLMs）上评估了这种方法，并展示了其在减少遗忘、提高对各种任务顺序和相似性的鲁棒性以及提升泛化性能方面的有效性。', 'title_zh': '视觉-语言模型中的持续学习通过对齐模型合并'}
{'arxiv_id': 'arXiv:2506.03188', 'title': 'Multi-Analyte, Swab-based Automated Wound Monitor with AI', 'authors': 'Madhu Babu Sikha, Lalith Appari, Gurudatt Nanjanagudu Ganesh, Amay Bandodkar, Imon Banerjee', 'link': 'https://arxiv.org/abs/2506.03188', 'abstract': 'Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000 individuals every year in the US alone and identifying non-healing DFUs that develop to chronic wounds early can drastically reduce treatment costs and minimize risks of amputation. There is therefore a pressing need for diagnostic tools that can detect non-healing DFUs early. We develop a low cost, multi-analyte 3D printed assays seamlessly integrated on swabs that can identify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile application developed for the controlled acquisition and automated analysis of wound sensor data. By comparing both the original base image (before exposure to the wound) and the wound-exposed image, we developed automated computer vision techniques to compare density changes between the two assay images, which allow us to automatically determine the severity of the wound. The iOS app ensures accurate data collection and presents actionable insights, despite challenges such as variations in camera configurations and ambient conditions. The proposed integrated sensor and iOS app will allow healthcare professionals to monitor wound conditions real-time, track healing progress, and assess critical parameters related to wound care.', 'abstract_zh': '糖尿病足溃疡（DFUs）的低成本多分析物3D打印检测 assay 及集成伤口传感器iOS应用：早期识别非愈合DFUs以大幅降低治疗成本并减少截肢风险', 'title_zh': '基于 swab 的多分析物自动伤口监测系统与 AI'}
{'arxiv_id': 'arXiv:2506.03186', 'title': 'Lightweight Convolutional Neural Networks for Retinal Disease Classification', 'authors': 'Duaa Kareem Qasim, Sabah Abdulazeez Jebur, Lafta Raheem Ali, Abdul Jalil M. Khalaf, Abir Jaafar Hussain', 'link': 'https://arxiv.org/abs/2506.03186', 'abstract': 'Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) significantly impact vision and affect millions worldwide. Early detection is crucial, as DR, a complication of diabetes, damages retinal blood vessels, potentially leading to blindness, while MH disrupts central vision, affecting tasks like reading and facial recognition. This paper employed two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images. The models were trained on the RFMiD dataset, consisting of 3,200 fundus images, after undergoing preprocessing steps such as resizing, normalization, and augmentation. To address data scarcity, this study leveraged transfer learning and data augmentation techniques, enhancing model generalization and performance. The experimental results demonstrate that MobileNetV2 achieved the highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.', 'abstract_zh': 'Retinal疾病如糖尿病视网膜病变(DR)和黄斑裂孔(MH)严重影响视力并影响数以百万计的人。早期诊断至关重要，因为糖尿病视网膜病变会损害视网膜血管，可能导致失明，而黄斑裂孔会破坏中央视力，影响阅读和面部识别。本文采用了两种轻量级高效的卷积神经网络架构-MobileNet和NASNetMobile-对正常、DR和MH视网膜图像进行分类。模型在经过大小调整、归一化和增强等预处理步骤的RFMiD数据集中进行训练，该数据集包含3,200张底片图像。为解决数据稀缺问题，本研究利用了迁移学习和数据增强技术，提高了模型的泛化能力和性能。实验结果表明，MobileNetV2的准确率最高，达到90.8%，优于NASNetMobile的89.5%准确率。这些发现突显了CNN在视网膜疾病分类中的有效性，为AI辅助眼科诊断和早期干预奠定了基础。', 'title_zh': '轻量级卷积神经网络在视网膜疾病分类中的应用'}
{'arxiv_id': 'arXiv:2506.03185', 'title': 'DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset', 'authors': 'Liangrui Pan, Xingchen Li, Zhongyi Chen, Ling Chu, Shaoliang Peng', 'link': 'https://arxiv.org/abs/2506.03185', 'abstract': 'Pathologists comprehensive evaluation of donor liver biopsies provides crucial information for accepting or discarding potential grafts. However, rapidly and accurately obtaining these assessments intraoperatively poses a significant challenge for pathologists. Features in donor liver biopsies, such as portal tract fibrosis, total steatosis, macrovesicular steatosis, and hepatocellular ballooning are correlated with transplant outcomes, yet quantifying these indicators suffers from substantial inter- and intra-observer variability. To address this, we introduce DLiPath, the first benchmark for comprehensive donor liver assessment based on a histopathology image dataset. We collected and publicly released 636 whole slide images from 304 donor liver patients at the Department of Pathology, the Third Xiangya Hospital, with expert annotations for key pathological features (including cholestasis, portal tract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis, and hepatocellular ballooning). We selected nine state-of-the-art multiple-instance learning (MIL) models based on the DLiPath dataset as baselines for extensive comparative analysis. The experimental results demonstrate that several MIL models achieve high accuracy across donor liver assessment indicators on DLiPath, charting a clear course for future automated and intelligent donor liver assessment research. Data and code are available at this https URL.', 'abstract_zh': '基于组织病理学图像数据集的DLiPath：第一个全面供肝评估基准', 'title_zh': 'DLiPath: 基于组织病理图像数据集的供肝综合评估基准'}
{'arxiv_id': 'arXiv:2506.03184', 'title': 'Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset', 'authors': 'Mahe Zabin, Ho-Jin Choi, Md. Monirul Islam, Jia Uddin', 'link': 'https://arxiv.org/abs/2506.03184', 'abstract': 'The performance of a classifier depends on the tuning of its parame ters. In this paper, we have experimented the impact of various tuning parameters on the performance of a deep convolutional neural network (DCNN). In the ex perimental evaluation, we have considered a DCNN classifier that consists of 2 convolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer. To observe the impact of pooling, activation function, and optimizer tuning pa rameters, we utilized a crack image dataset having two classes: negative and pos itive. The experimental results demonstrate that with the maxpooling, the DCNN demonstrates its better performance for adam optimizer and tanh activation func tion.', 'abstract_zh': '深卷积神经网络参数调整对其性能的影响：基于裂缝图像数据集的实验研究', 'title_zh': '使用裂纹图像数据集探究深度卷积神经网络调参影响'}
{'arxiv_id': 'arXiv:2506.03183', 'title': 'Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study', 'authors': 'Yaşar Utku Alçalar, Yu Cao, Mehmet Akçakaya', 'link': 'https://arxiv.org/abs/2506.03183', 'abstract': 'Physics-driven artificial intelligence (PD-AI) reconstruction methods have emerged as the state-of-the-art for accelerating MRI scans, enabling higher spatial and temporal resolutions. However, the high resolution of these scans generates massive data volumes, leading to challenges in transmission, storage, and real-time processing. This is particularly pronounced in functional MRI, where hundreds of volumetric acquisitions further exacerbate these demands. Edge computing with FPGAs presents a promising solution for enabling PD-AI reconstruction near the MRI sensors, reducing data transfer and storage bottlenecks. However, this requires optimization of PD-AI models for hardware efficiency through quantization and bypassing traditional FFT-based approaches, which can be a limitation due to their computational demands. In this work, we propose a novel PD-AI computational MRI approach optimized for FPGA-based edge computing devices, leveraging 8-bit complex data quantization and eliminating redundant FFT/IFFT operations. Our results show that this strategy improves computational efficiency while maintaining reconstruction quality comparable to conventional PD-AI methods, and outperforms standard clinical methods. Our approach presents an opportunity for high-resolution MRI reconstruction on resource-constrained devices, highlighting its potential for real-world deployment.', 'abstract_zh': '基于物理驱动的人工智能的医用磁共振成像重建方法：面向FPGA边缘计算的优化', 'title_zh': '基于物理驱动AI的计算MRI中边缘计算可行性研究'}
{'arxiv_id': 'arXiv:2506.03179', 'title': 'Vid-SME: Membership Inference Attacks against Large Video Understanding Models', 'authors': 'Qi Li, Runpeng Yu, Xinchao Wang', 'link': 'https://arxiv.org/abs/2506.03179', 'abstract': "Multimodal large language models (MLLMs) demonstrate remarkable capabilities in handling complex multimodal tasks and are increasingly adopted in video understanding applications. However, their rapid advancement raises serious data privacy concerns, particularly given the potential inclusion of sensitive video content, such as personal recordings and surveillance footage, in their training datasets. Determining improperly used videos during training remains a critical and unresolved challenge. Despite considerable progress on membership inference attacks (MIAs) for text and image data in MLLMs, existing methods fail to generalize effectively to the video domain. These methods suffer from poor scalability as more frames are sampled and generally achieve negligible true positive rates at low false positive rates (TPR@Low FPR), mainly due to their failure to capture the inherent temporal variations of video frames and to account for model behavior differences as the number of frames varies. To address these challenges, we introduce Vid-SME, the first membership inference method tailored for video data used in video understanding LLMs (VULLMs). Vid-SME leverages the confidence of model output and integrates adaptive parameterization to compute Sharma-Mittal entropy (SME) for video inputs. By leveraging the SME difference between natural and temporally-reversed video frames, Vid-SME derives robust membership scores to determine whether a given video is part of the model's training set. Experiments on various self-trained and open-sourced VULLMs demonstrate the strong effectiveness of Vid-SME.", 'abstract_zh': '多模态大型语言模型（MLLMs）在处理复杂多模态任务方面表现出色，并在视频理解应用中日益受到采用。然而，其快速进步引发了严重的数据隐私担忧，尤其是其训练数据集中可能包含个人录制和监控视频等敏感视频内容。确定训练过程中不当使用的视频仍然是一个关键且未解决的挑战。尽管在多模态大型语言模型（MLLMs）的文本和图像数据上取得了显著进展，现有的方法在视频域中无法有效泛化。这些方法在更多帧被采样时缺乏可扩展性，通常在低正假率时实现几乎可以忽略的真正阳性率（TPR@Low FPR），主要原因是它们无法捕捉视频帧的固有时间变化，并且无法考虑帧数量变化时模型行为的差异。为解决这些问题，我们提出Vid-SME，这是第一个专门针对用于视频理解的大型语言模型（VULLMs）的视频数据的成员身份推理方法。Vid-SME 利用模型输出的信心，并结合自适应参数化来计算视频输入的沙尔马-米特拉熵（SME）。通过利用自然视频帧和时序反转视频帧之间的SME差异，Vid-SME .derives robust membership scores以确定给定视频是否属于模型的训练集。在各种自我训练和开源的VULLMs上的实验表明，Vid-SME具有很强的有效性。', 'title_zh': 'Vid-SME：针对大规模视频理解模型的成员推理攻击'}
{'arxiv_id': 'arXiv:2506.03178', 'title': 'LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning', 'authors': 'Md. Zihad Bin Jahangir, Muhammad Ashad Kabir, Sumaiya Akter, Israt Jahan, Minh Chau', 'link': 'https://arxiv.org/abs/2506.03178', 'abstract': "Automated radiology report generation holds significant potential to reduce radiologists' workload and enhance diagnostic accuracy. However, generating precise and clinically meaningful reports from chest radiographs remains challenging due to the complexity of medical language and the need for contextual understanding. Existing models often struggle with maintaining both accuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel framework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings and Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves improved coherence and clinical accuracy while maintaining computational efficiency. This efficiency is driven by an optimization strategy that enhances parameter utilization and reduces memory overhead, enabling faster report generation with lower computational resource demands. Extensive experiments conducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR outperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L score of 0.433 and a METEOR score of 0.336, establishing new performance benchmarks in the domain. These results underscore LLaMA-XR's potential as an effective and efficient AI system for automated radiology reporting, offering enhanced clinical utility and reliability.", 'abstract_zh': '自动放射学报告生成在减轻放射科医生工作负荷和提高诊断准确性方面具有显著潜力。然而，由于医学语言的复杂性和需要上下文理解，从胸部X光片生成精确且临床相关的报告仍具有挑战性。现有模型往往难以在同一时间保持准确性和上下文相关性。本文提出了一种名为LLaMA-XR的新型框架，该框架将LLaMA 3.1与基于DenseNet-121的图像嵌入和量化低秩适应（QLoRA）微调相结合。LLaMA-XR在保持计算效率的同时实现了更好的连贯性和临床准确性。这种效率提升是通过优化策略增强参数利用并减少内存开销来实现的，从而实现了更快的报告生成并降低了计算资源需求。在IU X射线基准数据集上的广泛实验表明，LLaMA-XR在多种最先进的方法中表现出色。我们的模型获得了ROUGE-L评分为0.433和METEOR评分为0.336的新性能基准，这些结果凸显了LLaMA-XR作为自动化放射学报告有效且高效的AI系统的潜在价值，提供了增强的临床实用性和可靠性。', 'title_zh': 'LLaMA-XR：一种基于LLaMA和QLoRA微调的新型放射报告生成框架'}
{'arxiv_id': 'arXiv:2506.03177', 'title': 'Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population', 'authors': 'Isarun Chamveha, Supphanut Chaiyungyuen, Sasinun Worakriangkrai, Nattawadee Prasawang, Warasinee Chaisangmongkon, Pornpim Korpraphong, Voraparee Suvannarerg, Shanigarn Thiravit, Chalermdej Kannawat, Kewalin Rungsinaporn, Suwara Issaragrisil, Payia Chadbunchachai, Pattiya Gatechumpol, Chawiporn Muktabhant, Patarachai Sereerat', 'link': 'https://arxiv.org/abs/2506.03177', 'abstract': "This study presents a deep learning system for breast cancer detection in mammography, developed using a modified EfficientNetV2 architecture with enhanced attention mechanisms. The model was trained on mammograms from a major Thai medical center and validated on three distinct datasets: an in-domain test set (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain generalizability set (761 cases) collected from two different hospitals. For cancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the respective datasets. The system's lesion localization capability, evaluated using metrics including Lesion Localization Fraction (LLF) and Non-Lesion Localization Fraction (NLF), demonstrated robust performance in identifying suspicious regions. Clinical validation through concordance tests showed strong agreement with radiologists: 83.5% classification and 84.0% localization concordance for biopsy-confirmed cases, and 78.1% classification and 79.6% localization concordance for out-of-domain cases. Expert radiologists' acceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for out-of-domain cases. The system achieved a System Usability Scale score of 74.17 for source hospital, and 69.20 for validation hospitals, indicating good clinical acceptance. These results demonstrate the model's effectiveness in assisting mammogram interpretation, with the potential to enhance breast cancer screening workflows in clinical practice.", 'abstract_zh': '乳腺癌在乳房X光摄影中的检测：基于改进EfficientNetV2架构的深度学习系统的研究', 'title_zh': '基于深度学习的乳腺癌在乳腺X线摄影中的检测：泰国人群多中心验证研究'}
{'arxiv_id': 'arXiv:2506.03174', 'title': 'Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks', 'authors': 'Koki Matsuishi, Kosuke Ukita, Tsuyoshi Okita', 'link': 'https://arxiv.org/abs/2506.03174', 'abstract': "In recent years, the widespread adoption of wearable devices has highlighted the growing importance of behavior analysis using IMU. While applications span diverse fields such as healthcare and robotics, recent studies have increasingly focused on multimodal analysis, in addition to unimodal analysis. Several studies have proposed multimodal foundation models that incorporate first-person video and text data; however, these models still fall short in providing a detailed analysis of full-body human activity. To address this limitation, we propose Activity Understanding and Representations Alignment - Multimodal Foundation Model (AURA-MFM), a foundational model integrating four modalities: third-person video, motion capture, IMU, and text. By incorporating third-person video and motion capture data, the model enables a detailed and multidimensional understanding of human activity, which first-person perspectives alone fail to capture. Additionally, a Transformer-based IMU encoder is employed to enhance the model's overall performance. Experimental evaluations on retrieval and activity recognition tasks demonstrate that our model surpasses existing methods. Notably, in the zero-shot classification for action recognition, our method achieved significantly higher performance, with an F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method recorded an F1-score of 0.0747 and an accuracy of 0.1961.", 'abstract_zh': '近年来，可穿戴设备的广泛应用凸显了使用IMU进行行为分析的重要性日益增强。尽管应用程序涵盖了医疗保健和机器人技术等多个领域，但最近的研究越来越多地专注于多模态分析，而不仅仅是单模态分析。已有研究提出了结合第一人称视频和文本数据的多模态基础模型，但这些模型仍然无法提供对全身人类活动的详细分析。为解决这一限制，我们提出一种整合四种模态的多模态基础模型——Activity Understanding and Representations Alignment - Multimodal Foundation Model (AURA-MFM)，该模型结合了第三人称视频、动作捕捉、IMU和文本数据。通过结合第三人称视频和动作捕捉数据，该模型能够提供对人类活动的详细和多维度理解，这是单纯的第一人称视角无法捕捉到的。此外，我们采用了基于Transformer的IMU编码器提升模型的整体性能。在检索和行为识别任务上的实验评估表明，我们的模型超越了现有方法。特别是在动作识别的零样本分类任务中，我们的方法取得了显著更高的性能，F1分数为0.6226，准确率为0.7320，而现有方法的F1分数为0.0747，准确率为0.1961。', 'title_zh': '多模态基础模型在跨模态检索与活动识别任务中的应用'}
{'arxiv_id': 'arXiv:2506.03173', 'title': 'FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution', 'authors': 'Xiaoyi Liu, Hao Tang', 'link': 'https://arxiv.org/abs/2506.03173', 'abstract': "Physical intelligence -- anticipating and shaping the world from partial, multisensory observations -- is critical for next-generation world models. We propose FOLIAGE, a physics-informed multimodal world model for unbounded accretive surface growth. In its Action-Perception loop, a unified context encoder maps images, mesh connectivity, and point clouds to a shared latent state. A physics-aware predictor, conditioned on physical control actions, advances this latent state in time to align with the target latent of the surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network (AGN) captures dynamic connectivity through Age Positional Encoding and Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances global context with local dynamics. We create SURF-GARDEN, a world model learning platform comprising a Counterfactual Physics Simulator, a Multimodal Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation suite, evaluates six core tasks -- topology recognition, inverse material estimation, growth-stage classification, latent roll-out, cross-modal retrieval, and dense correspondence -- and four stress tests -- sensor dropout, zero-shot modality transfer, long-horizon prediction, and physics ablation -- to probe resilience. FOLIAGE outperforms specialized baselines while remaining robust across dynamic environments, establishing a new world-model based, multimodal pathway to physical intelligence.", 'abstract_zh': '物理学智能——基于部分多模态观察预测和塑造世界是下一代世界模型的关键。我们提出FOLIAGE，一个基于物理知识的多模态世界模型，用于无限生长表面的研究。在其实现的动作感知循环中，统一上下文编码器将图像、网格连接性和点云映射到共享的潜在状态。一个基于物理的预测器根据物理控制动作更新这个潜在状态，使之与表面的目标潜在状态对齐，从而生成与下游目标接口的模态无关的生长嵌入（MAGE）。FOLIAGE的累积图网络（AGN）通过年龄位置编码和能量门控消息传递捕捉动态连接。几何对应融合和跨块屏蔽增强MAGE的表现力，而分层池化平衡全局上下文与局部动态。我们构建了SURF-GARDEN，一个包含反事实物理模拟器、多模态对应提取器和进化追踪的世界模型学习平台，生成了7200个多样化的生长序列。SURF-BENCH是我们用于物理智能评估的综合套件，评估了六个核心任务——拓扑识别、反材料估计、生长阶段分类、潜在展开、跨模态检索和密集对应——以及四个压力测试——传感器dropout、零样本模态转换、长期预测和物理消融——以探索其鲁棒性。FOLIAGE超越了专门的基线模型，在动态环境中保持鲁棒性，建立了基于世界模型的多模态通向物理智能的新途径。', 'title_zh': 'FOLIAGE: 向往无界表面演化赋能的物理智能世界模型'}
{'arxiv_id': 'arXiv:2506.03171', 'title': 'EdgeVidSum: Real-Time Personalized Video Summarization at the Edge', 'authors': 'Ghulam Mujtaba, Eun-Seok Ryu', 'link': 'https://arxiv.org/abs/2506.03171', 'abstract': "EdgeVidSum is a lightweight method that generates personalized, fast-forward summaries of long-form videos directly on edge devices. The proposed approach enables real-time video summarization while safeguarding user privacy through local data processing using innovative thumbnail-based techniques and efficient neural architectures. Unlike conventional methods that process entire videos frame by frame, the proposed method uses thumbnail containers to significantly reduce computational complexity without sacrificing semantic relevance. The framework employs a hierarchical analysis approach, where a lightweight 2D CNN model identifies user-preferred content from thumbnails and generates timestamps to create fast-forward summaries. Our interactive demo highlights the system's ability to create tailored video summaries for long-form videos, such as movies, sports events, and TV shows, based on individual user preferences. The entire computation occurs seamlessly on resource-constrained devices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical challenges of computational efficiency, personalization, and privacy in modern video consumption environments.", 'abstract_zh': 'EdgeVidSum是一种轻量级方法，可直接在边缘设备上生成长格式视频的个性化快进摘要。该提出的方案通过使用创新性的缩略图为基础的技术和高效神经架构，在本地进行数据处理，从而实现实时视频摘要生成，并保护用户隐私。与传统的逐帧处理视频的方法不同，提出的方案使用缩略图容器显著减少了计算复杂性，同时保持语义相关性。该框架采用分层分析方法，使用轻量级的2D CNN模型从缩略图中识别用户偏好内容，并生成时间戳以创建快进摘要。我们的互动演示展示了系统能够根据个人用户偏好为长格式视频（如电影、体育赛事和电视节目）创建定制视频摘要的能力。整个计算过程无缝地在资源受限的设备（如Jetson Nano）上完成，展示了EdgeVidSum如何在现代视频消费环境中解决计算效率、个性化和隐私的关键挑战。', 'title_zh': 'EdgeVidSum: 边缘端个性化视频摘要生成'}
{'arxiv_id': 'arXiv:2506.03170', 'title': 'PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models', 'authors': 'Murthy L, Subarna Tripathi', 'link': 'https://arxiv.org/abs/2506.03170', 'abstract': 'The risk of misusing text-to-image generative models for malicious uses, especially due to the open-source development of such models, has become a serious concern. As a risk mitigation strategy, attributing generative models with neural fingerprinting is emerging as a popular technique. There has been a plethora of recent work that aim for addressing neural fingerprinting. A trade-off between the attribution accuracy and generation quality of such models has been studied extensively. None of the existing methods yet achieved $100\\%$ attribution accuracy. However, any model with less than \\emph{perfect} accuracy is practically non-deployable. In this work, we propose an accurate method to incorporate neural fingerprinting for text-to-image diffusion models leveraging the concepts of cyclic error correcting codes from the literature of coding theory.', 'abstract_zh': '利用循环错误校正码概念将神经指纹印技术应用于文本到图像扩散模型以减轻误用风险', 'title_zh': 'PALADIN：稳健的神经指纹技术用于文本到图像扩散模型'}
{'arxiv_id': 'arXiv:2506.03169', 'title': 'Improvement of human health lifespan with hybrid group pose estimation methods', 'authors': 'Arindam Chaudhuri', 'link': 'https://arxiv.org/abs/2506.03169', 'abstract': 'Human beings rely heavily on estimation of poses in order to access their body movements. Human pose estimation methods take advantage of computer vision advances in order to track human body movements in real life applications. This comes from videos which are recorded through available devices. These para-digms provide potential to make human movement measurement more accessible to users. The consumers of pose estimation movements believe that human poses content tend to supplement available videos. This has increased pose estimation software usage to estimate human poses. In order to address this problem, we develop hybrid-ensemble-based group pose estimation method to improve human health. This proposed hybrid-ensemble-based group pose estimation method aims to detect multi-person poses using modified group pose estimation and modified real time pose estimation. This ensemble allows fusion of performance of stated methods in real time. The input poses from images are fed into individual meth-ods. The pose transformation method helps to identify relevant features for en-semble to perform training effectively. After this, customized pre-trained hybrid ensemble is trained on public benchmarked datasets which is being evaluated through test datasets. The effectiveness and viability of proposed method is estab-lished based on comparative analysis of group pose estimation methods and ex-periments conducted on benchmarked datasets. It provides best optimized results in real-time pose estimation. It makes pose estimation method more robust to oc-clusion and improves dense regression accuracy. These results have affirmed po-tential application of this method in several real-time situations with improvement in human health life span', 'abstract_zh': '基于混合集成的人群姿态估计方法以提升人类健康', 'title_zh': '基于混合群体姿态估计方法的人类健康寿命提升'}
{'arxiv_id': 'arXiv:2506.03162', 'title': 'Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection', 'authors': 'Damith Chamalke Senadeera, Xiaoyun Yang, Dimitrios Kollias, Gregory Slabaugh', 'link': 'https://arxiv.org/abs/2506.03162', 'abstract': 'The rapid proliferation of surveillance cameras has increased the demand for automated violence detection. While CNNs and Transformers have shown success in extracting spatio-temporal features, they struggle with long-term dependencies and computational efficiency. We propose Dual Branch VideoMamba with Gated Class Token Fusion (GCTF), an efficient architecture combining a dual-branch design and a state-space model (SSM) backbone where one branch captures spatial features, while the other focuses on temporal dynamics, with continuous fusion via a gating mechanism. We also present a new benchmark by merging RWF-2000, RLVS, and VioPeru datasets in video violence detection, ensuring strict separation between training and testing sets. Our model achieves state-of-the-art performance on this benchmark offering an optimal balance between accuracy and computational efficiency, demonstrating the promise of SSMs for scalable, real-time surveillance violence detection.', 'abstract_zh': '监视摄像头的快速普及增加了自动化暴力检测的需求。虽然CNN和Transformer在提取时空特征方面取得了成功，但在处理长期依赖性和计算效率方面仍然存在挑战。我们提出了一个高效的Dual Branch VideoMamba with Gated Class Token Fusion (GCTF) 架构，结合了双分支设计和状态空间模型（SSM）骨干网络，其中一个分支捕获空间特征，而另一个分支专注于时间动态，并通过门控机制实现连续融合。我们还提出一个新的基准，通过将RWF-2000、RLVS和VioPeru数据集合并，在视频暴力检测中确保训练集和测试集之间严格分离。我们的模型在这一基准上达到了最优的准确性和计算效率之间的平衡，证明了SSM在可扩展、实时 surveillance 暴力检测中的潜力。', 'title_zh': '具有门控类令牌融合的双分支VideoMamba暴力检测'}
{'arxiv_id': 'arXiv:2506.03155', 'title': 'Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World', 'authors': 'Yu Zheng', 'link': 'https://arxiv.org/abs/2506.03155', 'abstract': 'The proliferation of artificial intelligence has enabled a diversity of applications that bridge the gap between digital and physical worlds. As physical environments are too complex to model through a single information acquisition approach, it is crucial to fuse multimodal data generated by different sources, such as sensors, devices, systems, and people, to solve a problem in the real world. Unfortunately, it is neither applicable nor sustainable to deploy new resources to collect original data from scratch for every problem. Thus, when data is inadequate in the domain of problem, it is vital to fuse knowledge from multimodal data that is already available in other domains. We call this cross-domain knowledge fusion. Existing research focus on fusing multimodal data in a single domain, supposing the knowledge from different datasets is intrinsically aligned; however, this assumption may not hold in the scenarios of cross-domain knowledge fusion. In this paper, we formally define the cross-domain multimodal data fusion problem, discussing its unique challenges, differences and advantages beyond data fusion in a single domain. We propose a four-layer framework, consisting of Domains, Links, Models and Data layers, answering three key questions: "what to fuse", "why can be fused", and "how to fuse". The Domains Layer selects relevant data from different domains for a given problem. The Links Layer reveals the philosophy of knowledge alignment beyond specific model structures. The Models Layer provides two knowledge fusion paradigms based on the fundamental mechanisms for processing data. The Data Layer turns data of different structures, resolutions, scales and distributions into a consistent representation that can be fed into an AI model. With this framework, we can design end-to-end solutions that fuse cross-domain multimodal data effectively for solving real-world problems.', 'abstract_zh': '人工智能的普及使得数字世界与物理世界之间的多种应用成为可能。由于物理环境过于复杂，单靠一种信息获取方法无法进行建模，因此，将来自不同来源（如传感器、设备、系统和人员）的多模态数据进行融合以解决现实世界的问题至关重要。不幸的是，为每个问题从头开始收集原始数据并部署新资源是不可行且不可持续的。因此，在问题领域数据不足的情况下，融合其他领域已有的多模态数据中的知识变得至关重要。我们称之为跨域知识融合。现有研究专注于单一领域内多模态数据的融合，假设不同数据集的知识是固有对齐的；但在跨域知识融合场景中，这一假设可能不成立。在本文中，我们正式定义了跨域多模态数据融合问题，讨论其独特的挑战、差异及其在单一领域数据融合之外的优势。我们提出了一种四层框架，包括领域层、链接层、模型层和数据层，回答了三个关键问题：“融合什么”、“为何能够融合”和“如何融合”。领域层从不同领域筛选与给定问题相关联的数据。链接层揭示了超越特定模型结构的知识对齐理念。模型层基于处理数据的基本机制提供两种知识融合范式。数据层将不同结构、分辨率、比例和分布的数据转换为可用于AI模型的一致表示。通过该框架，我们可以设计端到端的解决方案，有效融合跨域多模态数据以解决实际问题。', 'title_zh': '融合多模态数据中的跨域知识以解决物理世界中的问题'}
{'arxiv_id': 'arXiv:2505.04670', 'title': 'LLM Code Customization with Visual Results: A Benchmark on TikZ', 'authors': 'Charly Reux, Mathieu Acher, Djamel Eddine Khelladi, Olivier Barais, Clément Quinton', 'link': 'https://arxiv.org/abs/2505.04670', 'abstract': 'With the rise of AI-based code generation, customizing existing code out of natural language instructions to modify visual results -such as figures or images -has become possible, promising to reduce the need for deep programming expertise. However, even experienced developers can struggle with this task, as it requires identifying relevant code regions (feature location), generating valid code variants, and ensuring the modifications reliably align with user intent. In this paper, we introduce vTikZ, the first benchmark designed to evaluate the ability of Large Language Models (LLMs) to customize code while preserving coherent visual outcomes. Our benchmark consists of carefully curated vTikZ editing scenarios, parameterized ground truths, and a reviewing tool that leverages visual feedback to assess correctness. Empirical evaluation with stateof-the-art LLMs shows that existing solutions struggle to reliably modify code in alignment with visual intent, highlighting a gap in current AI-assisted code editing approaches. We argue that vTikZ opens new research directions for integrating LLMs with visual feedback mechanisms to improve code customization tasks in various domains beyond TikZ, including image processing, art creation, Web design, and 3D modeling.', 'abstract_zh': '基于AI的代码生成兴起后，从自然语言指令定制现有代码以修改视觉结果（如图形或图像）已成为可能，有望减少对深度编程专业スキル的需求。然而，即使经验丰富的开发者在执行此任务时也会遇到困难，因为这需要识别相关代码区域（特征定位）、生成有效的代码变体，并确保修改可靠地符合用户意图。在本文中，我们介绍了vTikZ，这是首个用于评估大型语言模型（LLMs）在定制代码同时保持一致视觉结果方面能力的基准。该基准包括精心策划的vTikZ编辑场景、参数化的ground truth以及一个利用视觉反馈进行评估的工具。实证研究表明，现有解决方案难以可靠地根据视觉意图修改代码，突显出当前AI辅助代码编辑方法的差距。我们认为，vTikZ为将LLMs与视觉反馈机制整合以改进各种领域（如TikZ之外的图像处理、艺术创作、Web设计和3D建模）的代码定制任务开辟了新的研究方向。', 'title_zh': 'LLM代码自定义与视觉结果：基于TikZ的基准测试'}
{'arxiv_id': 'arXiv:2209.01205', 'title': 'Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion', 'authors': 'Han Wu, Jie Yin, Bala Rajaratnam, Jianyuan Guo', 'link': 'https://arxiv.org/abs/2209.01205', 'abstract': 'Knowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have focused on designing local neighbor aggregators to learn entity-level information and/or imposing a potentially invalid sequential dependency assumption at the triplet level to learn meta relation information. However, pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and context-level), HiRe can effectively learn and refine meta representations of few-shot relations, and thus generalize well to new unseen relations. Extensive experiments on benchmark datasets validate the superiority of HiRe over state-of-the-art methods. The code can be found in this https URL.', 'abstract_zh': 'Few-shot知识图谱完成中的层级关系学习方法', 'title_zh': 'few-shot 知识图 completion 的分层关系学习'}
