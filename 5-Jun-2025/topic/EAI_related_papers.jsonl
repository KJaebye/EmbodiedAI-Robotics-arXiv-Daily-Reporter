{'arxiv_id': 'arXiv:2506.04227', 'title': 'Object-centric 3D Motion Field for Robot Learning from Human Videos', 'authors': 'Zhao-Heng Yin, Sherry Yang, Pieter Abbeel', 'link': 'https://arxiv.org/abs/2506.04227', 'abstract': "Learning robot control policies from human videos is a promising direction for scaling up robot learning. However, how to extract action knowledge (or action representations) from videos for policy learning remains a key challenge. Existing action representations such as video frames, pixelflow, and pointcloud flow have inherent limitations such as modeling complexity or loss of information. In this paper, we propose to use object-centric 3D motion field to represent actions for robot learning from human videos, and present a novel framework for extracting this representation from videos for zero-shot control. We introduce two novel components in its implementation. First, a novel training pipeline for training a ''denoising'' 3D motion field estimator to extract fine object 3D motions from human videos with noisy depth robustly. Second, a dense object-centric 3D motion field prediction architecture that favors both cross-embodiment transfer and policy generalization to background. We evaluate the system in real world setups. Experiments show that our method reduces 3D motion estimation error by over 50% compared to the latest method, achieve 55% average success rate in diverse tasks where prior approaches fail~($\\lesssim 10$\\%), and can even acquire fine-grained manipulation skills like insertion.", 'abstract_zh': '从人类视频中学习机器人控制策略：基于对象中心的3D运动场表示及其零样本控制框架', 'title_zh': '以对象为中心的3D运动场学习方法：从人类视频中学习机器人技能'}
{'arxiv_id': 'arXiv:2506.04218', 'title': 'Pseudo-Simulation for Autonomous Driving', 'authors': 'Wei Cao, Marcel Hallgarten, Tianyu Li, Daniel Dauner, Xunjiang Gu, Caojun Wang, Yakov Miron, Marco Aiello, Hongyang Li, Igor Gilitschenski, Boris Ivanovic, Marco Pavone, Andreas Geiger, Kashyap Chitta', 'link': 'https://arxiv.org/abs/2506.04218', 'abstract': "Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical limitations. Real-world evaluation is often challenging due to safety concerns and a lack of reproducibility, whereas closed-loop simulation can face insufficient realism or high computational costs. Open-loop evaluation, while being efficient and data-driven, relies on metrics that generally overlook compounding errors. In this paper, we propose pseudo-simulation, a novel paradigm that addresses these limitations. Pseudo-simulation operates on real datasets, similar to open-loop evaluation, but augments them with synthetic observations generated prior to evaluation using 3D Gaussian Splatting. Our key idea is to approximate potential future states the AV might encounter by generating a diverse set of observations that vary in position, heading, and speed. Our method then assigns a higher importance to synthetic observations that best match the AV's likely behavior using a novel proximity-based weighting scheme. This enables evaluating error recovery and the mitigation of causal confusion, as in closed-loop benchmarks, without requiring sequential interactive simulation. We show that pseudo-simulation is better correlated with closed-loop simulations (R^2=0.8) than the best existing open-loop approach (R^2=0.7). We also establish a public leaderboard for the community to benchmark new methodologies with pseudo-simulation. Our code is available at this https URL.", 'abstract_zh': '现有的自主车辆评估范式面临关键限制。实际世界评估由于安全问题和缺乏重复性往往具有挑战性，而闭环仿真可能因不真实或计算成本高而受限。开环评估虽然高效且数据驱动，但依赖的指标通常忽视了累积错误。在本文中，我们提出了一种新的伪仿真范式，以解决这些限制。伪仿真基于真实数据集进行操作，类似于开环评估，但通过在评估前使用3D高斯散射生成合成观察来增强数据集。我们的核心思想是通过生成一组在位置、方向和速度上有所不同以近似自主车辆可能遇到的潜在未来状态的观察来实现这一目标。随后，我们的方法使用一种新颖的距离加权方案赋予最佳匹配自主车辆预期行为的合成观察更高的重要性。这使得评估错误恢复和因果混淆的缓解成为可能，类似于闭环基准，而无需进行序列交互仿真。我们表明，伪仿真的相关性优于现有最佳开环方法（R²=0.7），与闭环仿真（R²=0.8）的相关性更好。我们还为进一步通过伪仿真方法评估新方法建立了公共排行榜。代码可在以下链接获取。', 'title_zh': '伪模拟在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2506.04217', 'title': 'OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis', 'authors': 'Junting Chen, Haotian Liang, Lingxiao Du, Weiyun Wang, Mengkang Hu, Yao Mu, Wenhai Wang, Jifeng Dai, Ping Luo, Wenqi Shao, Lin Shao', 'link': 'https://arxiv.org/abs/2506.04217', 'abstract': 'The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling. A second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world. The project page is at this https URL', 'abstract_zh': '快速发展的导航、操作和视觉模型使移动 manipulator 能够胜任许多专门任务。然而，开放世界移动操作 (OWMM) 任务由于需要在开放指令和环境下的通用化以及基于全局场景理解与当前代理状态的高层决策与低层机器人控制的系统复杂性而仍然是一项挑战。为应对这一挑战，我们提出了一种新颖的多模态代理架构，该架构维护多视角场景帧和代理状态以进行决策，并通过函数调用来控制机器人。第二个挑战是领域转移引起的幻觉。为了提升代理性能，我们进一步引入了一个面向 OWMM 任务的代理数据合成流水线，通过指令微调将 VLM 模型适应到我们的任务领域。我们强调我们的微调 OWMM-VLM 是第一个专为移动 manipulator 设计的基础模型，具备全局场景理解、机器人状态跟踪和统一模型中的多模态动作生成。通过实验，我们展示了该模型在与其他基础模型（包括 GPT-4o）相比时，实现了最佳性能，并在真实世界中展示了强大的零样本泛化能力。项目页面请点击这里 https://。', 'title_zh': 'OWMM-Agent: 开放世界移动 manipulation 与多模态代理数据合成'}
{'arxiv_id': 'arXiv:2506.04147', 'title': 'SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL', 'authors': 'Jiaheng Hu, Peter Stone, Roberto Martín-Martín', 'link': 'https://arxiv.org/abs/2506.04147', 'abstract': 'Building capable household and industrial robots requires mastering the control of versatile, high-degree-of-freedom (DoF) systems such as mobile manipulators. While reinforcement learning (RL) holds promise for autonomously acquiring robot control policies, scaling it to high-DoF embodiments remains challenging. Direct RL in the real world demands both safe exploration and high sample efficiency, which are difficult to achieve in practice. Sim-to-real RL, on the other hand, is often brittle due to the reality gap. This paper introduces SLAC, a method that renders real-world RL feasible for complex embodiments by leveraging a low-fidelity simulator to pretrain a task-agnostic latent action space. SLAC trains this latent action space via a customized unsupervised skill discovery method designed to promote temporal abstraction, disentanglement, and safety, thereby facilitating efficient downstream learning. Once a latent action space is learned, SLAC uses it as the action interface for a novel off-policy RL algorithm to autonomously learn downstream tasks through real-world interactions. We evaluate SLAC against existing methods on a suite of bimanual mobile manipulation tasks, where it achieves state-of-the-art performance. Notably, SLAC learns contact-rich whole-body tasks in under an hour of real-world interactions, without relying on any demonstrations or hand-crafted behavior priors. More information, code, and videos at this http URL', 'abstract_zh': '构建能力强的家用和工业机器人需要掌握多功能、高自由度（DOF）系统的控制，例如移动操作臂。虽然强化学习（RL）有望自主获取机器人控制策略，但在高DOF实体上的扩展仍然具有挑战性。在现实世界中直接进行RL要求既安全又高效的探索，这在实践中很难实现。相比之下，模拟到现实的RL由于现实差距往往比较脆弱。本文提出了一种SLAC方法，通过利用低保真模拟器预先训练任务无关的潜在动作空间，使复杂的实体能够进行现实世界的RL。SLAC通过一种定制的无监督技能发现方法来训练这个潜在动作空间，该方法旨在促进时间抽象、各个因素分离和安全性，从而促进下游学习的效率。一旦学习到潜在动作空间，SLAC将其作为动作接口，用于一种新颖的非策略性RL算法，通过实际交互自主学习下游任务。我们在一系列双臂移动操作任务上评估了SLAC，其性能达到了最先进的水平。值得注意的是，SLAC仅在不到一小时的现实世界交互中就学习了接触丰富的一体化任务，无需任何演示或手工艺品先验知识。更多信息、代码和视频请参见此链接。', 'title_zh': 'SLAC: 模拟预训练潜空间动作域用于全身现实世界强化学习'}
{'arxiv_id': 'arXiv:2506.04120', 'title': 'Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data', 'authors': 'Ben Moran, Mauro Comi, Steven Bohez, Tom Erez, Zhibin Li, Leonard Hasenclever', 'link': 'https://arxiv.org/abs/2506.04120', 'abstract': 'Creating accurate, physical simulations directly from real-world robot motion holds great value for safe, scalable, and affordable robot learning, yet remains exceptionally challenging. Real robot data suffers from occlusions, noisy camera poses, dynamic scene elements, which hinder the creation of geometrically accurate and photorealistic digital twins of unseen objects. We introduce a novel real-to-sim framework tackling all these challenges at once. Our key insight is a hybrid scene representation merging the photorealistic rendering of 3D Gaussian Splatting with explicit object meshes suitable for physics simulation within a single representation. We propose an end-to-end optimization pipeline that leverages differentiable rendering and differentiable physics within MuJoCo to jointly refine all scene components - from object geometry and appearance to robot poses and physical parameters - directly from raw and imprecise robot trajectories. This unified optimization allows us to simultaneously achieve high-fidelity object mesh reconstruction, generate photorealistic novel views, and perform annotation-free robot pose calibration. We demonstrate the effectiveness of our approach both in simulation and on challenging real-world sequences using an ALOHA 2 bi-manual manipulator, enabling more practical and robust real-to-simulation pipelines.', 'abstract_zh': '直接从真实机器人运动创建精确的物理模拟具有巨大的价值，可以实现安全、 scalable 和成本效益高的机器人学习，但仍然极具挑战性。真实机器人数据受到遮挡、noise相机姿态、动态场景元素的影响，阻碍了对未见物体生成几何上准确和逼真的数字孪生体。我们提出了一种新颖的真实到模拟框架，同时解决所有这些挑战。我们的关键见解是一种混合场景表示，结合了3D Gaussian斑点的逼真渲染与适合物理模拟的显式对象网格在一个表示中的使用。我们提出了一套端到端优化管道，利用MuJoCo中的可微渲染和可微物理，联合细化场景的所有组件——从对象几何形状和外观到机器人姿态和物理参数——直接从原始和不精确的机器人轨迹中获取。这种统一的优化使我们能够同时实现高保真度的物体网格重建，生成逼真的新视角，并进行无需标注的机器人姿态校准。我们在仿真和具有挑战性的现实世界序列中使用ALOHA 2双臂 manipulator 验证了该方法的有效性，从而实现更加实用和鲁棒的真实到模拟管道。', 'title_zh': '物理场景的点绘制：从 imperfect 机器人数据实现端到端的真实世界到模拟世界的转换'}
{'arxiv_id': 'arXiv:2506.03896', 'title': 'FLIP: Flowability-Informed Powder Weighing', 'authors': 'Nikola Radulov, Alex Wright, Thomas little, Andrew I. Cooper, Gabriella Pizzuto', 'link': 'https://arxiv.org/abs/2506.03896', 'abstract': "Autonomous manipulation of powders remains a significant challenge for robotic automation in scientific laboratories. The inherent variability and complex physical interactions of powders in flow, coupled with variability in laboratory conditions necessitates adaptive automation. This work introduces FLIP, a flowability-informed powder weighing framework designed to enhance robotic policy learning for granular material handling. Our key contribution lies in using material flowability, quantified by the angle of repose, to optimise physics-based simulations through Bayesian inference. This yields material-specific simulation environments capable of generating accurate training data, which reflects diverse powder behaviours, for training `robot chemists'. Building on this, FLIP integrates quantified flowability into a curriculum learning strategy, fostering efficient acquisition of robust robotic policies by gradually introducing more challenging, less flowable powders. We validate the efficacy of our method on a robotic powder weighing task under real-world laboratory conditions. Experimental results show that FLIP with a curriculum strategy achieves a low dispensing error of 2.12 +- 1.53 mg, outperforming methods that do not leverage flowability data, such as domain randomisation (6.11 +- 3.92 mg). These results demonstrate FLIP's improved ability to generalise to previously unseen, more cohesive powders and to new target masses.", 'abstract_zh': '自主处理粉末材料仍是对科学实验室中机器人自动化的一大挑战。基于流动性的粉末称重框架FLIP旨在通过贝叶斯推断优化物理学仿真，从而增强粒状材料处理的机器人策略学习。我们的主要贡献在于使用材料流动性的量度（休止角）来生成材料特定的仿真环境，以生成反映多样粉末行为的准确训练数据，用于训练“机器人化学家”。在此基础上，FLIP将量化后的流动性集成到 curriculum 学习策略中，通过逐步引入更具挑战性和流动性较差的粉末，促进机器人策略的高效学习。我们在实际实验室条件下验证了该方法在机器人粉末称重任务中的有效性。实验结果表明，使用 curriculum 策略的 FLIP 的投料误差为 2.12 ± 1.53 mg，优于未利用流动性数据的方法（如领域随机化，误差为 6.11 ± 3.92 mg）。这些结果证明了 FLIP 在处理之前未见过的更粘稠粉末和新目标质量时具有更好的泛化能力。', 'title_zh': 'FLIP: 流动性指导粉体称重'}
{'arxiv_id': 'arXiv:2506.03863', 'title': 'STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization', 'authors': 'Hao Li, Qi Lv, Rui Shao, Xiang Deng, Yinchuan Li, Jianye Hao, Liqiang Nie', 'link': 'https://arxiv.org/abs/2506.03863', 'abstract': 'Transforming complex actions into discrete skill abstractions has demonstrated strong potential for robotic manipulation. Existing approaches mainly leverage latent variable models, e.g., VQ-VAE, to learn skill abstractions through learned vectors (codebooks), while they suffer from codebook collapse and modeling the causal relationship between learned skills. To address these limitations, we present \\textbf{S}kill \\textbf{T}raining with \\textbf{A}ugmented \\textbf{R}otation (\\textbf{STAR}), a framework that advances both skill learning and composition to complete complex behaviors. Specifically, to prevent codebook collapse, we devise rotation-augmented residual skill quantization (RaRSQ). It encodes relative angles between encoder outputs into the gradient flow by rotation-based gradient mechanism. Points within the same skill code are forced to be either pushed apart or pulled closer together depending on gradient directions. Further, to capture the causal relationship between skills, we present causal skill transformer (CST) which explicitly models dependencies between skill representations through an autoregressive mechanism for coherent action generation. Extensive experiments demonstrate the superiority of STAR on both LIBERO benchmark and realworld tasks, with around 12\\% improvement over the baselines.', 'abstract_zh': '技能训练增强旋转（STAR）：技能学习与组合的提升框架', 'title_zh': 'STAR：通过旋转扩增向量量化学习多样化的机器人技能抽象'}
{'arxiv_id': 'arXiv:2506.03856', 'title': 'Phase-based Nonlinear Model Predictive Control for Humanoid Walking Stabilization with Single and Double Support Time Adjustments', 'authors': 'Kwanwoo Lee, Gyeongjae Park, Jaeheung Park', 'link': 'https://arxiv.org/abs/2506.03856', 'abstract': 'Balance control for humanoid robots has been extensively studied to enable robots to navigate in real-world environments. However, balance controllers that explicitly optimize the durations of both the single support phase, also known as step timing, and the Double Support Phase (DSP) have not been widely explored due to the inherent nonlinearity of the associated optimization problem. Consequently, many recent approaches either ignore the DSP or adjust its duration based on heuristics or on linearization techniques that rely on sequential coordination of balance strategies. This study proposes a novel phase-based nonlinear Model Predictive Control (MPC) framework that simultaneously optimizes Zero Moment Point~(ZMP) modulation, step location, step timing, and DSP duration to maintain balance under external disturbances. In simulation, the proposed controller was compared with two state-of-the-art frameworks that rely on heuristics or sequential coordination of balance strategies under two scenarios: forward walking on terrain emulating compliant ground and external push recovery while walking in place. Overall, the findings suggest that the proposed method offers more flexible coordination of balance strategies than the sequential approach, and consistently outperforms the heuristic approach. The robustness and effectiveness of the proposed controller were also validated through experiments with a real humanoid robot.', 'abstract_zh': '人形机器人平衡控制的研究：基于相位的非线性模型预测控制方法探索', 'title_zh': '基于相位的非线性模型预测控制在单支撑和双支撑时间调整的人形步行稳定性控制'}
{'arxiv_id': 'arXiv:2506.03834', 'title': 'Enhancing Safety of Foundation Models for Visual Navigation through Collision Avoidance via Repulsive Estimation', 'authors': 'Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam', 'link': 'https://arxiv.org/abs/2506.03834', 'abstract': 'We propose CARE (Collision Avoidance via Repulsive Estimation), a plug-and-play module that enhances the safety of vision-based navigation without requiring additional range sensors or fine-tuning of pretrained models. While recent foundation models using only RGB inputs have shown strong performance, they often fail to generalize in out-of-distribution (OOD) environments with unseen objects or variations in camera parameters (e.g., field of view, pose, or focal length). Without fine-tuning, these models may generate unsafe trajectories that lead to collisions, requiring costly data collection and retraining. CARE addresses this limitation by seamlessly integrating with any RGB-based navigation system that outputs local trajectories, dynamically adjusting them using repulsive force vectors derived from monocular depth maps. We evaluate CARE by combining it with state-of-the-art vision-based navigation models across multiple robot platforms. CARE consistently reduces collision rates (up to 100%) without sacrificing goal-reaching performance and improves collision-free travel distance by up to 10.7x in exploration tasks.', 'abstract_zh': '我们提出CARE（基于排斥估计的碰撞避免模块），这是一个即插即用的模块，能够在无需额外的距离传感器或微调预训练模型的情况下增强基于视觉的导航的安全性。尽管最近只使用RGB输入的基础模型显示出了强大的性能，但在未见过的物体或摄像机参数（如视野、姿态或焦距）变化的分布外（OOD）环境中，它们往往会表现出不佳的泛化能力。未经微调的情况下，这些模型可能会生成不安全的轨迹，从而导致碰撞，这需要昂贵的数据收集和重新训练。CARE通过无缝集成到任何输出局部轨迹的基于RGB的导航系统中，并使用从单目深度图导出的排斥力向量动态调整这些轨迹，从而解决了这一限制。我们通过将CARE与多个机器人平台上的最先进的基于视觉的导航模型结合来评估CARE，CARE在不牺牲目标到达性能的前提下一致地减少了碰撞率（最多100%），并在探索任务中将无碰撞行驶距离提高了最多10.7倍。', 'title_zh': '通过斥力估计实现碰撞避免以增强视觉导航基础模型的安全性'}
{'arxiv_id': 'arXiv:2506.03760', 'title': 'Understanding Physical Properties of Unseen Deformable Objects by Leveraging Large Language Models and Robot Actions', 'authors': 'Changmin Park, Beomjoon Lee, Haechan Jung, Haejin Jung, Changjoo Nam', 'link': 'https://arxiv.org/abs/2506.03760', 'abstract': 'In this paper, we consider the problem of understanding the physical properties of unseen objects through interactions between the objects and a robot. Handling unseen objects with special properties such as deformability is challenging for traditional task and motion planning approaches as they are often with the closed world assumption. Recent results in Large Language Models (LLMs) based task planning have shown the ability to reason about unseen objects. However, most studies assume rigid objects, overlooking their physical properties. We propose an LLM-based method for probing the physical properties of unseen deformable objects for the purpose of task planning. For a given set of object properties (e.g., foldability, bendability), our method uses robot actions to determine the properties by interacting with the objects. Based on the properties examined by the LLM and robot actions, the LLM generates a task plan for a specific domain such as object packing. In the experiment, we show that the proposed method can identify properties of deformable objects, which are further used for a bin-packing task where the properties take crucial roles to succeed.', 'abstract_zh': '本文考虑通过物体与机器人之间的交互来理解未见物体的物理属性的问题。处理具有变形等特殊属性的未见物体对传统的任务和运动规划方法具有挑战性，因为这些方法通常基于闭世界假设。基于大型语言模型（LLMs）的任务规划近期成果显示出对未见物体进行推理的能力。然而，大多数研究假设物体是刚性的，忽略了它们的物理属性。我们提出一种基于LLM的方法，用于探索未见可变形物体的物理属性，以用于任务规划。对于给定的一组物体属性（例如可折叠性、可弯曲性），我们的方法通过与物体的交互来使用机器人动作确定这些属性。基于LLM检查的属性和机器人动作，LLM生成特定领域（如物体打包）的任务计划。在实验中，我们展示了提出的方法能够识别可变形物体的属性，这些属性进一步用于一项纸箱打包任务，其中属性在成功中起着关键作用。', 'title_zh': '利用大型语言模型和机器人动作理解未见可变形物体的物理属性'}
{'arxiv_id': 'arXiv:2506.03574', 'title': 'SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models', 'authors': 'Meng Li, Zhen Zhao, Zhengping Che, Fei Liao, Kun Wu, Zhiyuan Xu, Pei Ren, Zhao Jin, Ning Liu, Jian Tang', 'link': 'https://arxiv.org/abs/2506.03574', 'abstract': 'Robots deployed in dynamic environments must be able to not only follow diverse language instructions but flexibly adapt when user intent changes mid-execution. While recent Vision-Language-Action (VLA) models have advanced multi-task learning and instruction following, they typically assume static task intent, failing to respond when new instructions arrive during ongoing execution. This limitation hinders natural and robust interaction in dynamic settings, such as retail or household environments, where real-time intent changes are common. We propose SwitchVLA, a unified, execution-aware framework that enables smooth and reactive task switching without external planners or additional switch-specific data. We model task switching as a behavior modulation problem conditioned on execution state and instruction context. Expert demonstrations are segmented into temporally grounded contact phases, allowing the policy to infer task progress and adjust its behavior accordingly. A multi-behavior conditional policy is then trained to generate flexible action chunks under varying behavior modes through conditioned trajectory modeling. Experiments in both simulation and real-world robotic manipulation demonstrate that SwitchVLA enables robust instruction adherence, fluid task switching, and strong generalization-outperforming prior VLA baselines in both task success rate and interaction naturalness.', 'abstract_zh': '部署在动态环境中的机器人必须能够不仅遵循多样的语言指令，还在执行过程中灵活适应用户意图的变化。尽管近期的视觉-语言-动作（VLA）模型已经提高了多任务学习和指令跟随的能力，但它们通常假设固定的任务意图，在执行过程中收到新指令时无法作出响应。这一限制在零售或家庭环境中阻碍了自然和稳健的交互，而在这些环境中，实时的意图变化是常见的。我们提出SwitchVLA，一种执行感知的统一框架，能够在无需外部规划者或额外切换特定数据的情况下实现平滑且反应性的任务切换。我们将任务切换建模为基于执行状态和指令上下文的行为调节问题。通过时间触发的接触阶段对专家演示进行分割，使策略能够推断任务进度并相应地调整其行为。通过条件轨迹建模训练一个多行为条件策略，使其在不同的行为模式下生成灵活的动作片段。在仿真和真实世界的机器人操作实验中，SwitchVLA展示了稳健的指令遵守、流畅的任务切换和强大的泛化能力，超越了先前的VLA基线方法，在任务成功率和交互自然度上表现出色。', 'title_zh': 'SwitchVLA：面向执行的视觉-语言-动作模型任务切换'}
{'arxiv_id': 'arXiv:2506.03546', 'title': 'From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context', 'authors': 'Yuanchen Bai, Zijian Ding, Angelique Taylor', 'link': 'https://arxiv.org/abs/2506.03546', 'abstract': 'Advancements in generative models have enabled multi-agent systems (MAS) to perform complex virtual tasks such as writing and code generation, which do not generalize well to physical multi-agent robotic teams. Current frameworks often treat agents as conceptual task executors rather than physically embodied entities, and overlook critical real-world constraints such as spatial context, robotic capabilities (e.g., sensing and navigation). To probe this gap, we reconfigure and stress-test a hierarchical multi-agent robotic team built on the CrewAI framework in a simulated emergency department onboarding scenario. We identify five persistent failure modes: role misalignment; tool access violations; lack of in-time handling of failure reports; noncompliance with prescribed workflows; bypassing or false reporting of task completion. Based on this analysis, we propose three design guidelines emphasizing process transparency, proactive failure recovery, and contextual grounding. Our work informs the development of more resilient and robust multi-agent robotic systems (MARS), including opportunities to extend virtual multi-agent frameworks to the real world.', 'abstract_zh': '生成模型的进步使多智能体系统能够执行复杂的虚拟任务，如写作和代码生成，但这些任务在应用于物理多智能体机器人团队时缺乏泛化能力。当前框架往往将智能体视为概念性任务执行者，而非物理实体，并忽略了诸如空间上下文、机器人能力（例如，感知和导航）等关键现实世界约束。为探索这一差距，我们在模拟紧急部门入职场景中重新配置并压力测试了基于CrewAI框架的层次化多智能体机器人团队。我们识别出五种持续存在的失败模式：角色错位；工具访问违规；失败报告未能及时处理；不遵守规定的工作流程；绕过或虚假报告任务完成情况。基于这一分析，我们提出三条设计准则，强调过程透明性、主动故障恢复和上下文约束。我们的工作为开发更具弹性和稳健的多智能体机器人系统（MARS）提供了指导，并探讨了将虚拟多智能体框架扩展到现实世界的机会。', 'title_zh': '从虚拟代理到机器人团队：高风险医疗环境下的多机器人框架评估'}
{'arxiv_id': 'arXiv:2506.03516', 'title': 'SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models', 'authors': 'Arnab Debnath, Gregory J. Stein, Jana Kosecka', 'link': 'https://arxiv.org/abs/2506.03516', 'abstract': 'Object goal navigation is a fundamental task in embodied AI, where an agent is instructed to locate a target object in an unexplored environment. Traditional learning-based methods rely heavily on large-scale annotated data or require extensive interaction with the environment in a reinforcement learning setting, often failing to generalize to novel environments and limiting scalability. To overcome these challenges, we explore a zero-shot setting where the agent operates without task-specific training, enabling more scalable and adaptable solution. Recent advances in Vision Foundation Models (VFMs) offer powerful capabilities for visual understanding and reasoning, making them ideal for agents to comprehend scenes, identify relevant regions, and infer the likely locations of objects. In this work, we present a zero-shot object goal navigation framework that integrates the perceptual strength of VFMs with a model-based planner that is capable of long-horizon decision making through frontier exploration. We evaluate our approach on the HM3D dataset using the Habitat simulator and demonstrate that our method achieves state-of-the-art performance in terms of success weighted by path length for zero-shot object goal navigation.', 'abstract_zh': '零样本物体目标导航是体现人工智能中的一个基础任务，其中智能体被指导在未探索环境中定位目标物体。传统的基于学习的方法依赖大量标注数据或需要在强化学习设置中进行大量的环境交互，往往无法泛化到新环境，限制了其可扩展性。为克服这些挑战，我们探索了一种零样本设置，智能体在没有任务特定训练的情况下运行，从而实现更可扩展和适应性强的解决方案。近期视觉基础模型（VFMs）的发展提供了强大的视觉理解和推理能力，使它们成为智能体理解场景、识别相关信息区域并推断物体可能位置的理想选择。在本工作中，我们提出了一种结合了VFMs感知优势和基于模型计划器的框架，该计划器能够通过边缘探索进行长期决策。我们在HM3D数据集上使用Habitat模拟器评估了该方法，并展示了我们的方法在零样本物体目标导航方面达到了最先进的性能，按路径长度加权的成功率最高。', 'title_zh': 'SemNav: 基于模型的零样本物体目标导航规划器使用视觉基础模型'}
{'arxiv_id': 'arXiv:2506.03362', 'title': 'Robustness-Aware Tool Selection and Manipulation Planning with Learned Energy-Informed Guidance', 'authors': 'Yifei Dong, Yan Zhang, Sylvain Calinon, Florian T. Pokorny', 'link': 'https://arxiv.org/abs/2506.03362', 'abstract': 'Humans subconsciously choose robust ways of selecting and using tools, based on years of embodied experience -- for example, choosing a ladle instead of a flat spatula to serve meatballs. However, robustness under uncertainty remains underexplored in robotic tool-use planning. This paper presents a robustness-aware framework that jointly selects tools and plans contact-rich manipulation trajectories, explicitly optimizing for robustness against environmental disturbances. At the core of our approach is a learned, energy-based robustness metric, which guides the planner towards robust manipulation behaviors. We formulate a hierarchical optimization pipeline that first identifies a tool and configuration that optimizes robustness, and then plans a corresponding manipulation trajectory that maintains robustness throughout execution. We evaluate our approach across three representative tool-use tasks. Simulation and real-world results demonstrate that our approach consistently selects robust tools and generates disturbance-resilient manipulation plans.', 'abstract_zh': '人类在多年 corporeal 经验的基础上无意识地选择和使用鲁棒性强的工具——例如，用汤匙而不是平坦的羹勺来盛肉丸。然而，机器人工具使用规划中鲁棒性在不确定条件下的研究仍不够充分。本文提出了一个鲁棒性aware框架，该框架同时选择工具并规划富含接触的操作轨迹，明确地针对环境扰动下的鲁棒性进行优化。我们方法的核心是一个学习到的能量基础鲁棒性度量，该度量引导规划器向鲁棒性的操作行为靠拢。我们提出了一个分层优化管道，首先识别出优化鲁棒性的工具和配置，然后规划一个相应的操作轨迹，以在整个执行过程中保持鲁棒性。我们通过三个代表性工具使用任务评估了我们的方法。仿真和实际结果表明，我们的方法能够一致地选择鲁棒性强的工具并生成扰动抵抗力强的操作计划。', 'title_zh': '考虑鲁棒性的工具选择与操作规划：基于能量指导的学习方法'}
{'arxiv_id': 'arXiv:2506.03350', 'title': 'Adversarial Attacks on Robotic Vision Language Action Models', 'authors': 'Eliot Krzysztof Jones, Alexander Robey, Andy Zou, Zachary Ravichandran, George J. Pappas, Hamed Hassani, Matt Fredrikson, J. Zico Kolter', 'link': 'https://arxiv.org/abs/2506.03350', 'abstract': 'The emergence of vision-language-action models (VLAs) for end-to-end control is reshaping the field of robotics by enabling the fusion of multimodal sensory inputs at the billion-parameter scale. The capabilities of VLAs stem primarily from their architectures, which are often based on frontier large language models (LLMs). However, LLMs are known to be susceptible to adversarial misuse, and given the significant physical risks inherent to robotics, questions remain regarding the extent to which VLAs inherit these vulnerabilities. Motivated by these concerns, in this work we initiate the study of adversarial attacks on VLA-controlled robots. Our main algorithmic contribution is the adaptation and application of LLM jailbreaking attacks to obtain complete control authority over VLAs. We find that textual attacks, which are applied once at the beginning of a rollout, facilitate full reachability of the action space of commonly used VLAs and often persist over longer horizons. This differs significantly from LLM jailbreaking literature, as attacks in the real world do not have to be semantically linked to notions of harm. We make all code available at this https URL .', 'abstract_zh': 'Vision-Language-Action模型（VLAs）的涌现及其端到端控制正在通过在十亿参数量级融合多模态感应输入来重塑机器人学领域。VLAs的能力主要源于其基于前沿大规模语言模型（LLMs）的架构。然而，由于LLMs已知容易受到对抗性滥用的影响，而在机器人学中存在着重大的物理风险，这引发了关于VLAs是否继承了这些脆弱性的疑问。受这些关注的驱动，本文首次研究了对由VLAs控制的机器人发动的对抗性攻击。我们的主要算法贡献是将LLMs的限制打破攻击适应并应用于获得对VLAs的完全控制权。我们发现，一旦在一段演示的开头应用文本攻击，可以实现对常用VLAs动作空间的完全可达性，并且这种可达性往往可以持续较长时间。这与LLMs的限制打破文献中的情况大不相同，因为在现实世界中的攻击无需与伤害的概念关联。所有代码均已发布在以下链接：this https URL。', 'title_zh': '对抗攻击对机器人视觉语言行动模型的影响'}
{'arxiv_id': 'arXiv:2506.03270', 'title': 'Grounded Vision-Language Interpreter for Integrated Task and Motion Planning', 'authors': 'Jeremy Siburian, Keisuke Shirai, Cristian C. Beltran-Hernandez, Masashi Hamaya, Michael Görner, Atsushi Hashimoto', 'link': 'https://arxiv.org/abs/2506.03270', 'abstract': 'While recent advances in vision-language models (VLMs) have accelerated the development of language-guided robot planners, their black-box nature often lacks safety guarantees and interpretability crucial for real-world deployment. Conversely, classical symbolic planners offer rigorous safety verification but require significant expert knowledge for setup. To bridge the current gap, this paper proposes ViLaIn-TAMP, a hybrid planning framework for enabling verifiable, interpretable, and autonomous robot behaviors. ViLaIn-TAMP comprises three main components: (1) ViLaIn (Vision-Language Interpreter) - A prior framework that converts multimodal inputs into structured problem specifications using off-the-shelf VLMs without additional domain-specific training, (2) a modular Task and Motion Planning (TAMP) system that grounds these specifications in actionable trajectory sequences through symbolic and geometric constraint reasoning and can utilize learning-based skills for key manipulation phases, and (3) a corrective planning module which receives concrete feedback on failed solution attempts from the motion and task planning components and can feed adapted logic and geometric feasibility constraints back to ViLaIn to improve and further refine the specification. We evaluate our framework on several challenging manipulation tasks in a cooking domain. We demonstrate that the proposed closed-loop corrective architecture exhibits a more than 30% higher mean success rate for ViLaIn-TAMP compared to without corrective planning.', 'abstract_zh': '面向可验证、可解释和自主机器人行为的ViLaIn-TAMP混合规划框架', 'title_zh': '基于情境的视觉-语言解释器用于集成任务与运动规划'}
{'arxiv_id': 'arXiv:2506.03613', 'title': 'Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations', 'authors': 'Shaoshan Liu, Fan Wang, Hongjun Zhou, Yuanfeng Wang', 'link': 'https://arxiv.org/abs/2506.03613', 'abstract': 'While theory and practice are often seen as separate domains, this article shows that theoretical insight is essential for overcoming real-world engineering barriers. We begin with a practical challenge: training a cross-morphology embodied AI policy that generalizes across diverse robot morphologies. We formalize this as the Heterogeneous Embodied Agent Training (HEAT) problem and prove it reduces to a structured Partially Observable Markov Decision Process (POMDP) that is PSPACE-complete. This result explains why current reinforcement learning pipelines break down under morphological diversity, due to sequential training constraints, memory-policy coupling, and data incompatibility. We further explore Collective Adaptation, a distributed learning alternative inspired by biological systems. Though NEXP-complete in theory, it offers meaningful scalability and deployment benefits in practice. This work illustrates how computational theory can illuminate system design trade-offs and guide the development of more robust, scalable embodied AI. For practitioners and researchers to explore this problem, the implementation code of this work has been made publicly available at this https URL', 'abstract_zh': '尽管理论与实践常常被视为分离的领域，本文展示了理论洞察对于克服实际工程障碍是必不可少的。我们以一个实践挑战为起点：训练能够跨不同机器人形态泛化的具身AI策略。我们将此问题形式化为异构具身代理训练（HEAT）问题，并证明它归约成为一个结构化的部分可观测马尔可夫决策过程（POMDP），且是PSPACE完全的。这一结果解释了为什么当前的强化学习管道在形态多样性下失效，原因包括顺序训练约束、记忆与策略的耦合以及数据不兼容性。我们进一步探讨了集体适应，这是一种灵感来源于生物系统的分布式学习替代方案。尽管从理论上讲它是NEXP完全的，但在实践中它提供了有意义的可扩展性和部署优势。本文展示了计算理论如何阐明系统设计权衡，并指导构建更具鲁棒性和可扩展性的具身AI的发展。为了使研究者和实践者能够探索这一问题，本文的工作实施代码已在此处公开：this https URL。', 'title_zh': '跨形态体察智能代理的训练：从实践挑战到理论基础'}
{'arxiv_id': 'arXiv:2506.03503', 'title': 'Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2506.03503', 'abstract': 'The quantification of social science remains a longstanding challenge, largely due to the philosophical nature of its foundational theories. Although quantum computing has advanced rapidly in recent years, its relevance to social theory remains underexplored. Most existing research focuses on micro-cognitive models or philosophical analogies, leaving a gap in system-level applications of quantum principles to the analysis of social systems. This study addresses that gap by proposing a theoretical and computational framework that combines quantum mechanics with Generative AI to simulate the emergence and evolution of social norms. Drawing on core quantum concepts--such as superposition, entanglement, and probabilistic measurement--this research models society as a dynamic, uncertain system and sets up five ideal-type experiments. These scenarios are simulated using 25 generative agents, each assigned evolving roles as compliers, resistors, or enforcers. Within a simulated environment monitored by a central observer (the Watcher), agents interact, respond to surveillance, and adapt to periodic normative disruptions. These interactions allow the system to self-organize under external stress and reveal emergent patterns. Key findings show that quantum principles, when integrated with generative AI, enable the modeling of uncertainty, emergence, and interdependence in complex social systems. Simulations reveal patterns including convergence toward normative order, the spread of resistance, and the spontaneous emergence of new equilibria in social rules. In conclusion, this study introduces a novel computational lens that lays the groundwork for a quantum-informed social theory. It offers interdisciplinary insights into how society can be understood not just as a structure to observe but as a dynamic system to simulate and redesign through quantum technologies.', 'abstract_zh': '量化社会科学仍然是一个长期存在的挑战，主要归因于其基础理论的哲学性质。尽管近年来量子计算取得了 rapid 进展，但其与社会理论的相关性仍未得到充分探索。现有大多数研究集中在微观认知模型或哲学类比上，使得基于量子原理的系统级社会系统分析应用存在短板。本研究通过提出一个将量子力学与生成人工智能相结合的理论和计算框架来填补这一空白，旨在模拟社会规范的产生和演变。研究借助核心量子概念（如叠加、纠缠和概率测量）将社会建模为一个动态、不确定的系统，并设置了五个理想类型的实验场景。这些场景通过 25 个生成代理模拟，每个代理扮演变化中的遵从者、抵抗者或执行者角色。在中央观察者（称为“监督者”）监督的模拟环境中，代理之间相互作用、响应监控并适应周期性规范中断。这些互动使系统能够在外部压力下自我组织，并揭示出新兴模式。研究发现表明，将量子原理与生成人工智能相结合，能够对复杂社会系统的不确定性、涌现性和相互依赖性进行建模。模拟揭示了包括向规范秩序收敛、抵抗的传播以及社会规则的新自发均衡在内的模式。总之，本研究引入了一个新的计算视角，为基于量子的社会理论奠定了基础。它提供了跨学科的见解，表明社会不仅可以被观察为一种结构，还可以通过量子技术模拟和重新设计为一种动态系统。', 'title_zh': '社会计算建筑师：量子机器学习与社会规则生成'}
{'arxiv_id': 'arXiv:2506.03205', 'title': 'Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments', 'authors': 'Umberto Gonçalves de Sousa', 'link': 'https://arxiv.org/abs/2506.03205', 'abstract': 'This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum reinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model, where Q-ARDNS-Multi stands for "Quantum Adaptive Reward-Driven Neural Simulator - Multi-Agent". It integrates quantum circuits with RY gates, meta-cognitive adaptation, and multi-agent coordination mechanisms for complex 3D environments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action selection, a dual-memory system inspired by human cognition, a shared memory module for agent cooperation, and adaptive exploration strategies modulated by reward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times 3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi achieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively, outperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft Actor-Critic (SAC) in terms of success rate, stability, navigation efficiency, and collision avoidance. The framework records mean rewards of $-304.2891 \\pm 756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal, demonstrating its robustness in dynamic settings. Comprehensive analyses, including learning curves, reward distributions, statistical tests, and computational efficiency evaluations, highlight the contributions of quantum circuits and meta-cognitive adaptation. By bridging quantum computing, cognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable, human-like approach for applications in robotics, autonomous navigation, and decision-making under uncertainty.', 'abstract_zh': 'Q-ARDNS-Multi：一种扩展的多智能体量子强化学习框架', 'title_zh': 'Q-ARDNS-Multi：一种适用于复杂3D环境的元认知自适应多 Agent 量子强化学习框架'}
{'arxiv_id': 'arXiv:2506.03758', 'title': 'Scaling CrossQ with Weight Normalization', 'authors': 'Daniel Palenicek, Florian Vogt, Jan Peters', 'link': 'https://arxiv.org/abs/2506.03758', 'abstract': "Reinforcement learning has achieved significant milestones, but sample efficiency remains a bottleneck for real-world applications. Recently, CrossQ has demonstrated state-of-the-art sample efficiency with a low update-to-data (UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with higher UTD ratios. We identify challenges in the training dynamics which are emphasized by higher UTDs, particularly Q-bias explosion and the growing magnitude of critic network weights. To address this, we integrate weight normalization into the CrossQ framework, a solution that stabilizes training, prevents potential loss of plasticity and keeps the effective learning rate constant. Our proposed approach reliably scales with increasing UTD ratios, achieving competitive or superior performance across a range of challenging tasks on the DeepMind control benchmark, notably the complex dog and humanoid environments. This work eliminates the need for drastic interventions, such as network resets, and offers a robust pathway for improving sample efficiency and scalability in model-free reinforcement learning.", 'abstract_zh': '强化学习在实现重要里程碑的同时，样本效率仍是一个制约实际应用的瓶颈。最近，CrossQ展现了最先进的样本效率，其更新与数据的比率为1。本文探讨了在较高更新与数据比（UTD）下CrossQ的可扩展性。我们识别出在较高UTD下突出的训练动力学挑战，特别是Q偏差爆炸和批评网络权重不断增加的幅度。为解决这一问题，我们将权重归一化整合进CrossQ框架，该方法稳定了训练过程，防止可能的可塑性丢失，并保持有效的学习率恒定。我们提出的方法在不断增加的UTD比率下可靠地扩展，实现了在DeepMind控制基准测试中一系列具有挑战性的任务上具有竞争力或优越的表现，尤其是在复杂的狗和 humanoid环境。本文消除了对激进干预（如网络重置）的需要，并为模型自由强化学习中提高样本效率和可扩展性提供了一条稳健的路径。', 'title_zh': 'Scaling CrossQ with Weight Normalization'}
{'arxiv_id': 'arXiv:2506.03568', 'title': 'Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving', 'authors': 'Li Zeqiao, Wang Yijing, Wang Haoyu, Li Zheng, Li Peng, Zuo zhiqiang, Hu Chuan', 'link': 'https://arxiv.org/abs/2506.03568', 'abstract': "Autonomous driving promises significant advancements in mobility, road safety and traffic efficiency, yet reinforcement learning and imitation learning face safe-exploration and distribution-shift challenges. Although human-AI collaboration alleviates these issues, it often relies heavily on extensive human intervention, which increases costs and reduces efficiency. This paper develops a confidence-guided human-AI collaboration (C-HAC) strategy to overcome these limitations. First, C-HAC employs a distributional proxy value propagation method within the distributional soft actor-critic (DSAC) framework. By leveraging return distributions to represent human intentions C-HAC achieves rapid and stable learning of human-guided policies with minimal human interaction. Subsequently, a shared control mechanism is activated to integrate the learned human-guided policy with a self-learning policy that maximizes cumulative rewards. This enables the agent to explore independently and continuously enhance its performance beyond human guidance. Finally, a policy confidence evaluation algorithm capitalizes on DSAC's return distribution networks to facilitate dynamic switching between human-guided and self-learning policies via a confidence-based intervention function. This ensures the agent can pursue optimal policies while maintaining safety and performance guarantees. Extensive experiments across diverse driving scenarios reveal that C-HAC significantly outperforms conventional methods in terms of safety, efficiency, and overall performance, achieving state-of-the-art results. The effectiveness of the proposed method is further validated through real-world road tests in complex traffic conditions. The videos and code are available at: this https URL.", 'abstract_zh': '基于信心引导的人机协作自主驾驶策略（C-HAC）：安全性、效率和性能的提升', 'title_zh': '基于信心引导的人机协作：自主驾驶中的分布代理价值传播 reinforcement学习'}
{'arxiv_id': 'arXiv:2506.03474', 'title': 'CORE: Constraint-Aware One-Step Reinforcement Learning for Simulation-Guided Neural Network Accelerator Design', 'authors': 'Yifeng Xiao, Yurong Xu, Ning Yan, Masood Mortazavi, Pierluigi Nuzzo', 'link': 'https://arxiv.org/abs/2506.03474', 'abstract': 'Simulation-based design space exploration (DSE) aims to efficiently optimize high-dimensional structured designs under complex constraints and expensive evaluation costs. Existing approaches, including heuristic and multi-step reinforcement learning (RL) methods, struggle to balance sampling efficiency and constraint satisfaction due to sparse, delayed feedback, and large hybrid action spaces. In this paper, we introduce CORE, a constraint-aware, one-step RL method for simulationguided DSE. In CORE, the policy agent learns to sample design configurations by defining a structured distribution over them, incorporating dependencies via a scaling-graph-based decoder, and by reward shaping to penalize invalid designs based on the feedback obtained from simulation. CORE updates the policy using a surrogate objective that compares the rewards of designs within a sampled batch, without learning a value function. This critic-free formulation enables efficient learning by encouraging the selection of higher-reward designs. We instantiate CORE for hardware-mapping co-design of neural network accelerators, demonstrating that it significantly improves sample efficiency and achieves better accelerator configurations compared to state-of-the-art baselines. Our approach is general and applicable to a broad class of discrete-continuous constrained design problems.', 'abstract_zh': '基于仿真引导的约束意识单步强化学习设计空间探索（Simulation-Guided Design Space Exploration with Constraint-Aware One-Step Reinforcement Learning）', 'title_zh': 'CORE: 模型约束感知的一步强化学习在仿真引导的神经网络加速器设计中应用'}
{'arxiv_id': 'arXiv:2506.03404', 'title': 'The Impact of On-Policy Parallelized Data Collection on Deep Reinforcement Learning Networks', 'authors': 'Walter Mayor, Johan Obando-Ceron, Aaron Courville, Pablo Samuel Castro', 'link': 'https://arxiv.org/abs/2506.03404', 'abstract': 'The use of parallel actors for data collection has been an effective technique used in reinforcement learning (RL) algorithms. The manner in which data is collected in these algorithms, controlled via the number of parallel environments and the rollout length, induces a form of bias-variance trade-off; the number of training passes over the collected data, on the other hand, must strike a balance between sample efficiency and overfitting. We conduct an empirical analysis of these trade-offs on PPO, one of the most popular RL algorithms that uses parallel actors, and establish connections to network plasticity and, more generally, optimization stability. We examine its impact on network architectures, as well as the hyper-parameter sensitivity when scaling data. Our analyses indicate that larger dataset sizes can increase final performance across a variety of settings, and that scaling parallel environments is more effective than increasing rollout lengths. These findings highlight the critical role of data collection strategies in improving agent performance.', 'abstract_zh': '并行actor在数据收集中的应用是 reinforcement learning 算法中一种有效的技术。这些算法中的数据收集方式，通过并行环境的数量和展开长度控制，引发了一种偏差-方差交易；另一方面，数据集的训练迭代次数必须在样本效率和过拟合之间取得平衡。我们对其中一种最流行的使用并行actor的RL算法PPO进行了实证分析，并将其与网络可塑性和更广泛的优化稳定性建立联系。我们研究了其对网络架构的影响，以及在扩大数据规模时超参数的敏感性。分析表明，较大的数据集规模可以在多种设置中提高最终性能，并且增加并行环境的数量比增加展开长度更有效。这些发现突显了数据收集策略在提高智能体性能中的关键作用。', 'title_zh': '基于策略并行化数据收集对深度强化学习网络的影响'}
{'arxiv_id': 'arXiv:2506.03333', 'title': 'A Differential Perspective on Distributional Reinforcement Learning', 'authors': 'Juan Sebastian Rojas, Chi-Guhn Lee', 'link': 'https://arxiv.org/abs/2506.03333', 'abstract': 'To date, distributional reinforcement learning (distributional RL) methods have exclusively focused on the discounted setting, where an agent aims to optimize a potentially-discounted sum of rewards over time. In this work, we extend distributional RL to the average-reward setting, where an agent aims to optimize the reward received per time-step. In particular, we utilize a quantile-based approach to develop the first set of algorithms that can successfully learn and/or optimize the long-run per-step reward distribution, as well as the differential return distribution of an average-reward MDP. We derive proven-convergent tabular algorithms for both prediction and control, as well as a broader family of algorithms that have appealing scaling properties. Empirically, we find that these algorithms consistently yield competitive performance when compared to their non-distributional equivalents, while also capturing rich information about the long-run reward and return distributions.', 'abstract_zh': '到目前为止，分布强化学习（分布性RL）方法仅专注于折扣设置，其中智能体的目标是优化潜在折扣奖励的时间总和。在本工作中，我们将分布强化学习扩展到平均奖励设置，其中智能体的目标是优化每时间步的奖励。特别地，我们采用分位数方法开发了第一个能够成功学习和/或优化长期每步奖励分布以及平均奖励MDP的差分回报分布的算法家族。我们推导出了预测和控制的已证明收敛的表征算法，以及具有吸引力扩展性的更广泛的算法家族。实验结果表明，这些算法在与非分布性等价算法进行比较时，能够获得竞争力的表现，并且能够捕获丰富的长期奖励和回报分布信息。', 'title_zh': '分布强化学习的微分视角'}
{'arxiv_id': 'arXiv:2506.03173', 'title': 'FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution', 'authors': 'Xiaoyi Liu, Hao Tang', 'link': 'https://arxiv.org/abs/2506.03173', 'abstract': "Physical intelligence -- anticipating and shaping the world from partial, multisensory observations -- is critical for next-generation world models. We propose FOLIAGE, a physics-informed multimodal world model for unbounded accretive surface growth. In its Action-Perception loop, a unified context encoder maps images, mesh connectivity, and point clouds to a shared latent state. A physics-aware predictor, conditioned on physical control actions, advances this latent state in time to align with the target latent of the surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network (AGN) captures dynamic connectivity through Age Positional Encoding and Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances global context with local dynamics. We create SURF-GARDEN, a world model learning platform comprising a Counterfactual Physics Simulator, a Multimodal Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation suite, evaluates six core tasks -- topology recognition, inverse material estimation, growth-stage classification, latent roll-out, cross-modal retrieval, and dense correspondence -- and four stress tests -- sensor dropout, zero-shot modality transfer, long-horizon prediction, and physics ablation -- to probe resilience. FOLIAGE outperforms specialized baselines while remaining robust across dynamic environments, establishing a new world-model based, multimodal pathway to physical intelligence.", 'abstract_zh': '物理学智能——基于部分多模态观察预测和塑造世界是下一代世界模型的关键。我们提出FOLIAGE，一个基于物理知识的多模态世界模型，用于无限生长表面的研究。在其实现的动作感知循环中，统一上下文编码器将图像、网格连接性和点云映射到共享的潜在状态。一个基于物理的预测器根据物理控制动作更新这个潜在状态，使之与表面的目标潜在状态对齐，从而生成与下游目标接口的模态无关的生长嵌入（MAGE）。FOLIAGE的累积图网络（AGN）通过年龄位置编码和能量门控消息传递捕捉动态连接。几何对应融合和跨块屏蔽增强MAGE的表现力，而分层池化平衡全局上下文与局部动态。我们构建了SURF-GARDEN，一个包含反事实物理模拟器、多模态对应提取器和进化追踪的世界模型学习平台，生成了7200个多样化的生长序列。SURF-BENCH是我们用于物理智能评估的综合套件，评估了六个核心任务——拓扑识别、反材料估计、生长阶段分类、潜在展开、跨模态检索和密集对应——以及四个压力测试——传感器dropout、零样本模态转换、长期预测和物理消融——以探索其鲁棒性。FOLIAGE超越了专门的基线模型，在动态环境中保持鲁棒性，建立了基于世界模型的多模态通向物理智能的新途径。', 'title_zh': 'FOLIAGE: 向往无界表面演化赋能的物理智能世界模型'}
