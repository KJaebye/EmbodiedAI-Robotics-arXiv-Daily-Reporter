{'arxiv_id': 'arXiv:2503.22674', 'title': 'QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?', 'authors': 'Belinda Z. Li, Been Kim, Zi Wang', 'link': 'https://arxiv.org/abs/2503.22674', 'abstract': "Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.", 'abstract_zh': '最近，大量研究集中在提高大型语言模型（LLMs）在数学和逻辑等推理基准上的性能。然而，以往的工作主要假设任务是明确定义的。在现实世界中，对LLMs的查询通常不明确，需要通过获取缺失信息来解决。我们将这种情形形式化为一种带有缺失变量赋值的约束满足问题（CSP）。通过这种方法的一个特殊情况，即仅缺少一个必要变量赋值，我们可以严格评估LLMs识别最小必要询问的能力，并量化每个问题的难度轴。我们提出了QuestBench，这是一个包含最多可提出一个询问以解决的任务集，包括：（1）Logic-Q：缺少一个命题的逻辑推理任务，（2）Planning-Q：初始状态部分未观察到的PDDL规划问题，（3）GSM-Q：由人工注释的公立学校数学问题，缺少一个变量赋值，（4）GSME-Q：GSM-Q的一个版本，其中文字问题由人工注释员翻译成方程。LLM的任务是从一组选项中选择正确的澄清问题。虽然最先进的模型在GSM-Q和GSME-Q上表现出色，但在Logic-Q和Planning-Q上的准确率仅为40-50%。分析表明，解决明确定义的推理问题的能力可能并不足以在我们的基准上取得成功：模型在确定应该提出什么问题方面存在困难，即使它们能够解决完全定义的版本的问题。此外，在Planning-Q领域，LLM倾向于不保留不确定性，即使明确提供了预测“不确定”的选项。这突显了对模型信息获取能力进行更深入研究的必要性。', 'title_zh': 'QuestBench: LLMs在推理任务中能否问出正确的问题以获取信息？'}
{'arxiv_id': 'arXiv:2503.22137', 'title': 'Sharpe Ratio-Guided Active Learning for Preference Optimization in RLHF', 'authors': 'Syrine Belakaria, Joshua Kazdan, Charles Marx, Chris Cundy, Willie Neiswanger, Sanmi Koyejo, Barbara E. Engelhardt, Stefano Ermon', 'link': 'https://arxiv.org/abs/2503.22137', 'abstract': 'Reinforcement learning from human feedback (RLHF) has become a cornerstone of the training and alignment pipeline for large language models (LLMs). Recent advances, such as direct preference optimization (DPO), have simplified the preference learning step. However, collecting preference data remains a challenging and costly process, often requiring expert annotation. This cost can be mitigated by carefully selecting the data points presented for annotation. In this work, we propose an active learning approach to efficiently select prompt and preference pairs using a risk assessment strategy based on the Sharpe Ratio. To address the challenge of unknown preferences prior to annotation, our method evaluates the gradients of all potential preference annotations to assess their impact on model updates. These gradient-based evaluations enable risk assessment of data points regardless of the annotation outcome. By leveraging the DPO loss derivations, we derive a closed-form expression for computing these Sharpe ratios on a per-tuple basis, ensuring our approach remains both tractable and computationally efficient. We also introduce two variants of our method, each making different assumptions about prior information. Experimental results demonstrate that our method outperforms the baseline by up to 5% in win rates against the chosen completion with limited human preference data across several language models and real-world datasets.', 'abstract_zh': '从人类反馈中学习的强化学习（RLHF）已成为大型语言模型（LLMs）训练和对齐管道的基石。近期进展，如直接偏好优化（DPO），简化了偏好学习步。然而，偏好数据的收集仍然是一个具有挑战性和成本高昂的过程，往往需要专家标注。通过仔细选择用于标注的数据点，可以减轻这一成本。在这种工作中，我们提出了一种主动学习方法，以风险评估策略为基础（基于夏普比率）来高效选择提示和偏好对。为了解决标注前未知偏好的挑战，我们的方法评估了所有潜在偏好标注的梯度，评估其对模型更新的影响。基于梯度的评估使我们能够在不影响标注结果的情况下，对数据点进行风险评估。通过利用DPO损失的推导，我们推导出一个闭形式表达式来计算每个元组上的夏普比率，确保我们的方法既可操作性强又计算效率高。我们还引入了两种我们方法的变种，每种变种对先验信息做了不同的假设。实验结果表明，我们的方法在有限的人类偏好数据下，与选择的完成相比，胜出率最高可达5%，覆盖多个语言模型和真实世界数据集。', 'title_zh': 'Sharpe比率引导的主动学习方法在RLHF中的偏好优化'}
{'arxiv_id': 'arXiv:2503.22064', 'title': 'Multi-Task Semantic Communications via Large Models', 'authors': 'Wanli Ni, Zhijin Qin, Haofeng Sun, Xiaoming Tao, Zhu Han', 'link': 'https://arxiv.org/abs/2503.22064', 'abstract': 'Artificial intelligence (AI) promises to revolutionize the design, optimization and management of next-generation communication systems. In this article, we explore the integration of large AI models (LAMs) into semantic communications (SemCom) by leveraging their multi-modal data processing and generation capabilities. Although LAMs bring unprecedented abilities to extract semantics from raw data, this integration entails multifaceted challenges including high resource demands, model complexity, and the need for adaptability across diverse modalities and tasks. To overcome these challenges, we propose a LAM-based multi-task SemCom (MTSC) architecture, which includes an adaptive model compression strategy and a federated split fine-tuning approach to facilitate the efficient deployment of LAM-based semantic models in resource-limited networks. Furthermore, a retrieval-augmented generation scheme is implemented to synthesize the most recent local and global knowledge bases to enhance the accuracy of semantic extraction and content generation, thereby improving the inference performance. Finally, simulation results demonstrate the efficacy of the proposed LAM-based MTSC architecture, highlighting the performance enhancements across various downstream tasks under varying channel conditions.', 'abstract_zh': '人工智能（AI）有望革命化下一代通信系统的设计、优化和管理。本文探讨了通过利用其多模态数据处理和生成能力，将大规模人工智能模型（LAMs）集成到语义通信（SemCom）中的方法。尽管LAMs能够前所未有的从原始数据中提取语义，但这种集成带来了包括高资源需求、模型复杂性以及跨多种模态和任务的适应性在内的多方面挑战。为克服这些挑战，我们提出了一种基于LAM的多任务语义通信（MTSC）架构，该架构包括自适应模型压缩策略和联邦分裂微调方法，以促进在资源受限网络中高效部署基于LAM的语义模型。此外，我们实现了一种检索增强生成方案，综合最新的局部和全局知识库，以提高语义提取和内容生成的准确性，从而改善推理性能。最后，仿真结果证明了所提出的基于LAM的MTSC架构的有效性，在不同信道条件下，突显了其在各种下游任务中的性能提升。', 'title_zh': '大规模模型驱动的多任务语义通信'}
{'arxiv_id': 'arXiv:2503.22589', 'title': 'Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012', 'authors': 'Adam Breuer, Bryce J. Dietrich, Michael H. Crespin, Matthew Butler, J.A. Pyrse, Kosuke Imai', 'link': 'https://arxiv.org/abs/2503.22589', 'abstract': 'This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.', 'abstract_zh': '本文介绍了迄今为止最大和最全面的美国总统竞选电视广告数据集，数据集以数字格式提供。该数据集还包括机器可搜索的脚本和高质量的摘要，旨在促进各种学术研究。迄今为止，收集和分析美国总统竞选广告引起了极大的兴趣，但由于需要人工采购和标注，许多研究者依赖于较小的数据子集。我们设计了一种大规模并行化的基于AI的分析管道，自动完成了准备、转录和摘要视频的繁琐过程。然后，我们将这种方法应用于朱利安·P·卡纳特政治商业档案中的9,707条总统广告。我们进行了广泛的人机评估，以证明这些转录和摘要与手工生成的替代品具有相同的质量水平。我们通过一个示例应用展示了这些数据的价值，该应用追踪了七十年来总统选举中当前焦点议题的起源和发展。我们的分析管道和代码库还展示了如何使用基于LLM的工具为其他视频数据集获得高质量的摘要。', 'title_zh': '使用AI总结1952-2012年美国总统竞选电视广告视频摘要'}
{'arxiv_id': 'arXiv:2503.22585', 'title': 'Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish', 'authors': 'Kevin Cohen, Laura Manrique-Gómez, Rubén Manrique', 'link': 'https://arxiv.org/abs/2503.22585', 'abstract': 'This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.', 'abstract_zh': '本研究探讨了使用大规模语言模型（LLMs）以增强数据集并提高对19世纪拉丁美洲报纸中讽刺的检测能力。通过多类和二分类任务评估了BERT和GPT-4o模型在捕捉讽刺微妙性质方面的有效性，采用了两种策略。首先，我们实施了专注于丰富情感和上下文线索的数据集增强，但这些方法在历史语言分析方面的效果有限。其次，我们采用了一种半自动注释过程，有效地解决了类别不平衡问题，并通过高质量的注释丰富了数据集。尽管讽刺的复杂性带来了挑战，本研究仍通过两个关键贡献推进了情感分析：一是引入了一个新的情感标注历史西班牙语数据集，用于讽刺检测；二是提出了结合历史和文化背景的半自动注释方法，这种方法依靠人类专业知识来细化LLMs的结果。', 'title_zh': '历史墨迹：探索大型语言模型在19世纪西班牙语讽刺检测中的应用'}
{'arxiv_id': 'arXiv:2503.22562', 'title': 'Niyama : Breaking the Silos of LLM Inference Serving', 'authors': 'Kanishk Goel, Jayashree Mohan, Nipun Kwatra, Ravi Shreyas Anupindi, Ramachandran Ramjee', 'link': 'https://arxiv.org/abs/2503.22562', 'abstract': 'The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.\nWe present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.', 'abstract_zh': '大规模语言模型（LLMs）的广泛应用使得具有非常不同延迟要求的多种应用成为可能。现有的LLM服务框架依赖于孤立的基础设施和粗粒度的工作负载分割——交互式和批量处理，导致资源利用率低下且难以提供细粒度的服务质量（QoS）差异化。这导致了操作效率低下、过度配置和业务高峰期间的负载管理不佳。\n\n我们提出了Niyama，这是一种新颖的QoS驱动的推理服务系统，能够在共享基础设施上高效地协同调度多样化的工作负载。Niyama引入了细粒度的QoS分类机制，允许应用程序明确规定精确的延迟要求，并根据实时系统状态动态调整调度决策。利用LLM推理可预测的执行特性，Niyama实现了一种动态切片机制，以提高总体吞吐量同时保持严格的QoS保证。此外，Niyama采用了混合优先级策略来平衡公平性和效率，并使用选择性的请求降级策略，在过载情况下提供优雅的服务降级。我们的评估结果表明，与当前的孤立部署相比，Niyama的服务容量增加了32%，同时维持了QoS保证。特别是在极端负载下，我们的系统将SLO违规降低了十倍，优于当前策略。', 'title_zh': 'Niyama: 打破LLM推理服务的孤岛效应'}
{'arxiv_id': 'arXiv:2503.22517', 'title': 'Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities', 'authors': 'Raman Dutt, Harleen Hanspal, Guoxuan Xia, Petru-Daniel Tudosiu, Alexander Black, Yongxin Yang, Steven McDonagh, Sarah Parisot', 'link': 'https://arxiv.org/abs/2503.22517', 'abstract': 'In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.', 'abstract_zh': '本研究致力于在保留原有语言生成能力不明显下降的前提下，增强预训练文本型大型语言模型（LLMs）的多模态生成能力，同时遵守两项核心约束：C1保持原始语言生成能力，C2保持参数预算小，确保可扩展性和效率。与当前通过添加专用模块来显著增加参数数量的方法不同，我们提出了一种利用深层模型中未充分利用的能力的方法。具体而言，我们利用Mixture-of-Experts（MoEs）内的参数冗余作为学习新模态的额外能力来源，实现更好的参数效率（C1）。同时，我们通过仅对新模态的标记应用低秩适应来保留原始语言生成能力（C2）。此外，我们提出了基于Gromov-Wasserstein距离的新参数初始化方案，以提高收敛性和训练稳定性。通过广泛分析路由机制，我们发现模态特定路径的出现和专家内冗余度的减少，可以高效地解锁多模态生成能力。总体而言，我们的方法可以无缝应用于广泛 contemporary LLMs，提供了一条从单模态向多模态架构过渡的新途径。', 'title_zh': '充分利用Mixture-of-Experts冗余性解锁多模态生成能力'}
{'arxiv_id': 'arXiv:2503.22458', 'title': 'Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey', 'authors': 'Shengyue Guan, Haoyi Xiong, Jindong Wang, Jiang Bian, Bin Zhu, Jian-guang Lou', 'link': 'https://arxiv.org/abs/2503.22458', 'abstract': 'This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \\emph{what to evaluate} and another that explains \\emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.', 'abstract_zh': '本调研考察基于大型语言模型（LLM）的代理在多轮对话设置中的评估方法。我们采用了借鉴PRISMA框架的方法，系统地回顾了近250篇学术资源，涵盖了各种出版平台的前沿状态，并为我们的分析奠定了坚实的基础。本研究通过开发两个相互关联的分类系统提供了一种结构化的方法：一个定义了“评估什么”，另一个解释了“如何评估”。第一个分类系统识别了基于LLM的代理在多轮对话中的关键组件及其评估维度，包括任务完成、响应质量、用户体验、记忆和语境保留，以及规划和工具集成。这些组件确保了对话代理的性能评估是全面且有意义的。第二个分类系统专注于评估方法。它将方法归类为人标注评估、自动指标、将人类评估与定量指标相结合的混合策略，以及利用LLM进行自我评判的方法。该框架不仅捕捉了传统的语言理解指标，如BLEU和ROUGE分数，还纳入了反映多轮对话动态互动性质的先进技术。', 'title_zh': '基于LLM的代理在多轮对话中的评估：一个综述'}
{'arxiv_id': 'arXiv:2503.22456', 'title': 'Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning', 'authors': 'Abdullah Vanlioglu', 'link': 'https://arxiv.org/abs/2503.22456', 'abstract': 'We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.', 'abstract_zh': '熵导向序列权重分配（EGSW）在强化学习导向的大语言模型微调中的探索与利用权衡增强方法', 'title_zh': '基于RL的LLM微调中熵导向的序列加权高效探索方法'}
{'arxiv_id': 'arXiv:2503.22406', 'title': 'Training Large Language Models for Advanced Typosquatting Detection', 'authors': 'Jackson Welch', 'link': 'https://arxiv.org/abs/2503.22406', 'abstract': 'Typosquatting is a long-standing cyber threat that exploits human error in typing URLs to deceive users, distribute malware, and conduct phishing attacks. With the proliferation of domain names and new Top-Level Domains (TLDs), typosquatting techniques have grown more sophisticated, posing significant risks to individuals, businesses, and national cybersecurity infrastructure. Traditional detection methods primarily focus on well-known impersonation patterns, leaving gaps in identifying more complex attacks. This study introduces a novel approach leveraging large language models (LLMs) to enhance typosquatting detection. By training an LLM on character-level transformations and pattern-based heuristics rather than domain-specific data, a more adaptable and resilient detection mechanism develops. Experimental results indicate that the Phi-4 14B model outperformed other tested models when properly fine tuned achieving a 98% accuracy rate with only a few thousand training samples. This research highlights the potential of LLMs in cybersecurity applications, specifically in mitigating domain-based deception tactics, and provides insights into optimizing machine learning strategies for threat detection.', 'abstract_zh': 'typosquatting是长期存在的网络威胁，通过利用用户在输入URL时的错误来欺骗用户、分发恶意软件并进行钓鱼攻击。随着域名和新的顶级域名(TLDs)的增多，typosquatting技术日益成熟，对个人、企业和国家的网络安全基础设施构成了重大风险。传统检测方法主要侧重于已知的仿冒模式，难以识别更复杂的攻击。本文提出了一种新的方法，利用大规模语言模型(LLMs)增强typosquatting检测。通过在字符级转换和基于模式的启发式规则上训练LLM，而不是特定于域的数据，开发出一种更加适应和稳健的检测机制。实验结果显示，Phi-4 14B模型在适当微调后，仅使用少量训练样本就实现了98%的准确率。该研究强调了LLMs在网络安全领域应用的潜力，特别是在缓解基于域的欺骗战术方面，并提供了优化机器学习策略以提高威胁检测效果的见解。', 'title_zh': '训练大规模语言模型以实现高级.typo squatting检测'}
{'arxiv_id': 'arXiv:2503.22353', 'title': 'Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions', 'authors': 'Yubo Li, Yidi Miao, Xueying Ding, Ramayya Krishnan, Rema Padman', 'link': 'https://arxiv.org/abs/2503.22353', 'abstract': 'Large Language Models (LLMs) have shown remarkable capabilities across various tasks, but their deployment in high-stake domains requires consistent performance across multiple interaction rounds. This paper introduces a comprehensive framework for evaluating and improving LLM response consistency, making three key contributions. First, we propose a novel Position-Weighted Consistency (PWC) score that captures both the importance of early-stage stability and recovery patterns in multi-turn interactions. Second, we present a carefully curated benchmark dataset spanning diverse domains and difficulty levels, specifically designed to evaluate LLM consistency under various challenging follow-up scenarios. Third, we introduce Confidence-Aware Response Generation (CARG), a framework that significantly improves response stability by incorporating model confidence signals into the generation process. Empirical results demonstrate that CARG significantly improves response stability without sacrificing accuracy, underscoring its potential for reliable LLM deployment in critical applications.', 'abstract_zh': '大规模语言模型（LLMs）在各种任务中展现出了卓越的能力，但在高风险领域中的部署需要其在多轮交互中保持一致的性能。本文提出了一个全面的框架来评估和提高LLM响应一致性，作出了三项关键贡献。首先，我们提出了一种新型的位置加权一致性（PWC）评分，以捕捉多轮交互中早期稳定性及恢复模式的重要性。其次，我们提供了一个精心策划的基准数据集，覆盖了多个领域和难度级别，旨在评估LLM在各种具有挑战性的后续场景中的一致性。第三，我们引入了一种基于置信度的响应生成（CARG）框架，通过将模型置信度信号集成到生成过程中，显著提高了响应稳定性。实证结果表明，CARG在不牺牲准确性的情况下显著提高了响应稳定性，突显了其在关键应用中可靠部署的潜力。', 'title_zh': '企业还是多变？评估大规模语言模型在序列交互中的一致性'}
{'arxiv_id': 'arXiv:2503.22275', 'title': 'Make Some Noise: Towards LLM audio reasoning and generation using sound tokens', 'authors': 'Shivam Mehta, Nebojsa Jojic, Hannes Gamper', 'link': 'https://arxiv.org/abs/2503.22275', 'abstract': 'Integrating audio comprehension and generation into large language models (LLMs) remains challenging due to the continuous nature of audio and the resulting high sampling rates. Here, we introduce a novel approach that combines Variational Quantization with Conditional Flow Matching to convert audio into ultra-low bitrate discrete tokens of 0.23kpbs, allowing for seamless integration with text tokens in LLMs. We fine-tuned a pretrained text-based LLM using Low-Rank Adaptation (LoRA) to assess its effectiveness in achieving true multimodal capabilities, i.e., audio comprehension and generation. Our tokenizer outperforms a traditional VQ-VAE across various datasets with diverse acoustic events. Despite the substantial loss of fine-grained details through audio tokenization, our multimodal LLM trained with discrete tokens achieves competitive results in audio comprehension with state-of-the-art methods, though audio generation is poor. Our results highlight the need for larger, more diverse datasets and improved evaluation metrics to advance multimodal LLM performance.', 'abstract_zh': '将音频理解与生成整合到大型语言模型中仍具有挑战性，原因是音频的连续性导致了高采样率。我们提出了一种结合变分量化与条件流动匹配的新方法，将音频转换为超低比特率的离散令牌（0.23kbps），以便无缝集成到大型语言模型中的文本令牌中。我们使用低秩适应（LoRA）fine-tune了一个预训练的文本基于的大规模语言模型，以评估其在实现真正的跨模态能力，即音频理解与生成方面的效果。我们的分词器在各种包含不同声学事件的数据集中优于传统的VQ-VAE。尽管通过音频分词丢失了大量细粒度的细节，但经过离散令牌训练的跨模态大语言模型在音频理解方面达到了与先进方法相当的结果，尽管音频生成效果较差。我们的研究结果强调了需要更大的、更为多样化的数据集和改进的评估指标，以推动跨模态大语言模型性能的提升。', 'title_zh': '嘈音相伴：面向大规模语言模型基于声音的推理与生成的研究'}
{'arxiv_id': 'arXiv:2503.22250', 'title': 'Beyond the Script: Testing LLMs for Authentic Patient Communication Styles in Healthcare', 'authors': 'Anna Bodonhelyi, Christian Stegemann-Philipps, Alessandra Sonanini, Lea Herschbach, Márton Szép, Anne Herrmann-Werner, Teresa Festl-Wietek, Enkelejda Kasneci, Friederike Holderried', 'link': 'https://arxiv.org/abs/2503.22250', 'abstract': 'Effective patient communication is pivotal in healthcare, yet traditional medical training often lacks exposure to diverse, challenging interpersonal dynamics. To bridge this gap, this study proposes the use of Large Language Models (LLMs) to simulate authentic patient communication styles, specifically the "accuser" and "rationalizer" personas derived from the Satir model, while also ensuring multilingual applicability to accommodate diverse cultural contexts and enhance accessibility for medical professionals. Leveraging advanced prompt engineering, including behavioral prompts, author\'s notes, and stubbornness mechanisms, we developed virtual patients (VPs) that embody nuanced emotional and conversational traits. Medical professionals evaluated these VPs, rating their authenticity (accuser: $3.8 \\pm 1.0$; rationalizer: $3.7 \\pm 0.8$ on a 5-point Likert scale (from one to five)) and correctly identifying their styles. Emotion analysis revealed distinct profiles: the accuser exhibited pain, anger, and distress, while the rationalizer displayed contemplation and calmness, aligning with predefined, detailed patient description including medical history. Sentiment scores (on a scale from zero to nine) further validated these differences in the communication styles, with the accuser adopting negative ($3.1 \\pm 0.6$) and the rationalizer more neutral ($4.0 \\pm 0.4$) tone. These results underscore LLMs\' capability to replicate complex communication styles, offering transformative potential for medical education. This approach equips trainees to navigate challenging clinical scenarios by providing realistic, adaptable patient interactions, enhancing empathy and diagnostic acumen. Our findings advocate for AI-driven tools as scalable, cost-effective solutions to cultivate nuanced communication skills, setting a foundation for future innovations in healthcare training.', 'abstract_zh': '使用大型语言模型模拟多元挑战性医患沟通模式以提升医疗教育有效性', 'title_zh': '超越脚本：在医疗健康领域测试LLM以实现真实的患者沟通风格'}
{'arxiv_id': 'arXiv:2503.22215', 'title': 'Learning to Instruct for Visual Instruction Tuning', 'authors': 'Zhihan Zhou, Feng Hong, Jiaan Luo, Jiangchao Yao, Dongsheng Li, Bo Han, Ya Zhang, Yanfeng Wang', 'link': 'https://arxiv.org/abs/2503.22215', 'abstract': 'We propose LIT, an advancement of visual instruction tuning (VIT). While VIT equips Multimodal LLMs (MLLMs) with promising multimodal capabilities, the current design choices for VIT often result in overfitting and shortcut learning, potentially degrading performance. This gap arises from an overemphasis on instruction-following abilities, while neglecting the proactive understanding of visual information. Inspired by this, LIT adopts a simple yet effective approach by incorporating the loss function into both the instruction and response sequences. It seamlessly expands the training data, and regularizes the MLLMs from overly relying on language priors. Based on this merit, LIT achieves a significant relative improvement of up to 9% on comprehensive multimodal benchmarks, requiring no additional training data and incurring negligible computational overhead. Surprisingly, LIT attains exceptional fundamental visual capabilities, yielding up to an 18% improvement in captioning performance, while simultaneously alleviating hallucination in MLLMs.', 'abstract_zh': '我们提出LIT，这是一种视觉指令调优（VIT）的改进。虽然VIT为多模态大语言模型（MLLMs）提供了令人期待的多模态能力，但当前VIT的设计选择往往会导致过拟合和捷径学习，这可能会影响性能。这种差距源于过度重视指令遵循能力，而忽视了主动理解视觉信息。受到这一启发，LIT采用了一种简单而有效的方法，通过将损失函数同时纳入指令和响应序列中来扩展训练数据，并防止MLLMs过于依赖语言先验。凭借这一优势，LIT在全面的多模态基准测试上实现了高达9%的相对改进，无需额外的训练数据且几乎不增加计算开销。令人惊讶的是，LIT在基本视觉能力方面表现出色，captioning性能提高了高达18%，同时缓解了MLLMs中的幻觉现象。', 'title_zh': '视觉指令调优的指令学习'}
{'arxiv_id': 'arXiv:2503.22164', 'title': 'PharmAgents: Building a Virtual Pharma with Large Language Model Agents', 'authors': 'Bowen Gao, Yanwen Huang, Yiqiao Liu, Wenxuan Xie, Wei-Ying Ma, Ya-Qin Zhang, Yanyan Lan', 'link': 'https://arxiv.org/abs/2503.22164', 'abstract': 'The discovery of novel small molecule drugs remains a critical scientific challenge with far-reaching implications for treating diseases and advancing human health. Traditional drug development--especially for small molecule therapeutics--is a highly complex, resource-intensive, and time-consuming process that requires multidisciplinary collaboration. Recent breakthroughs in artificial intelligence (AI), particularly the rise of large language models (LLMs), present a transformative opportunity to streamline and accelerate this process. In this paper, we introduce PharmAgents, a virtual pharmaceutical ecosystem driven by LLM-based multi-agent collaboration. PharmAgents simulates the full drug discovery workflow--from target discovery to preclinical evaluation--by integrating explainable, LLM-driven agents equipped with specialized machine learning models and computational tools. Through structured knowledge exchange and automated optimization, PharmAgents identifies potential therapeutic targets, discovers promising lead compounds, enhances binding affinity and key molecular properties, and performs in silico analyses of toxicity and synthetic feasibility. Additionally, the system supports interpretability, agent interaction, and self-evolvement, enabling it to refine future drug designs based on prior experience. By showcasing the potential of LLM-powered multi-agent systems in drug discovery, this work establishes a new paradigm for autonomous, explainable, and scalable pharmaceutical research, with future extensions toward comprehensive drug lifecycle management.', 'abstract_zh': '基于大型语言模型的多智能体系统在药物发现中的应用： PharmAgents 虚拟制药生态系统', 'title_zh': 'PharmAgents: 构建一个基于大规模语言模型代理的虚拟制药领域'}
{'arxiv_id': 'arXiv:2503.22141', 'title': "Integrating Artificial Intelligence with Human Expertise: An In-depth Analysis of ChatGPT's Capabilities in Generating Metamorphic Relations", 'authors': 'Yifan Zhang, Dave Towey, Matthew Pike, Quang-Hung Luu, Huai Liu, Tsong Yueh Chen', 'link': 'https://arxiv.org/abs/2503.22141', 'abstract': 'Context: This paper provides an in-depth examination of the generation and evaluation of Metamorphic Relations (MRs) using GPT models developed by OpenAI, with a particular focus on the capabilities of GPT-4 in software testing environments.\nObjective: The aim is to examine the quality of MRs produced by GPT-3.5 and GPT-4 for a specific System Under Test (SUT) adopted from an earlier study, and to introduce and apply an improved set of evaluation criteria for a diverse range of SUTs.\nMethod: The initial phase evaluates MRs generated by GPT-3.5 and GPT-4 using criteria from a prior study, followed by an application of an enhanced evaluation framework on MRs created by GPT-4 for a diverse range of nine SUTs, varying from simple programs to complex systems incorporating AI/ML components. A custom-built GPT evaluator, alongside human evaluators, assessed the MRs, enabling a direct comparison between automated and human evaluation methods.\nResults: The study finds that GPT-4 outperforms GPT-3.5 in generating accurate and useful MRs. With the advanced evaluation criteria, GPT-4 demonstrates a significant ability to produce high-quality MRs across a wide range of SUTs, including complex systems incorporating AI/ML components.\nConclusions: GPT-4 exhibits advanced capabilities in generating MRs suitable for various applications. The research underscores the growing potential of AI in software testing, particularly in the generation and evaluation of MRs, and points towards the complementarity of human and AI skills in this domain.', 'abstract_zh': '基于GPT模型的元变关系生成与评估：以OpenAI GPT-4在软件测试环境中的能力为重点', 'title_zh': '将人工智能与人类 expertise 结合：ChatGPT 在生成元变关系方面的能力深入分析'}
{'arxiv_id': 'arXiv:2503.22115', 'title': 'Beyond Single-Sentence Prompts: Upgrading Value Alignment Benchmarks with Dialogues and Stories', 'authors': 'Yazhou Zhang, Qimeng Liu, Qiuchi Li, Peng Zhang, Jing Qin', 'link': 'https://arxiv.org/abs/2503.22115', 'abstract': "Evaluating the value alignment of large language models (LLMs) has traditionally relied on single-sentence adversarial prompts, which directly probe models with ethically sensitive or controversial questions. However, with the rapid advancements in AI safety techniques, models have become increasingly adept at circumventing these straightforward tests, limiting their effectiveness in revealing underlying biases and ethical stances. To address this limitation, we propose an upgraded value alignment benchmark that moves beyond single-sentence prompts by incorporating multi-turn dialogues and narrative-based scenarios. This approach enhances the stealth and adversarial nature of the evaluation, making it more robust against superficial safeguards implemented in modern LLMs. We design and implement a dataset that includes conversational traps and ethically ambiguous storytelling, systematically assessing LLMs' responses in more nuanced and context-rich settings. Experimental results demonstrate that this enhanced methodology can effectively expose latent biases that remain undetected in traditional single-shot evaluations. Our findings highlight the necessity of contextual and dynamic testing for value alignment in LLMs, paving the way for more sophisticated and realistic assessments of AI ethics and safety.", 'abstract_zh': '评估大型语言模型的价值对齐 traditionally 依赖于单句对抗提示，这些提示直接用伦理敏感或有争议的问题来测试模型。然而，随着人工智能安全技术的迅速发展，模型越来越擅长绕过这些简单的测试，限制了它们在揭示潜在偏差和伦理立场方面的有效性。为了弥补这一不足，我们提出了一种升级的价值对齐基准，超越了单句提示，通过加入多轮对话和叙述性场景来增强评估的隐蔽性和对抗性，使其更能抵抗现代大型语言模型中实施的表面性保护措施。我们设计并实现了一个包含对话陷阱和伦理含糊故事的數據集，系统评估了大型语言模型在更为细腻和情境丰富的设置下对这些场景的回应。实验结果表明，这一改进的方法能够有效揭示传统单一测试中未检测到的潜在偏差。我们的研究突显了在大型语言模型中进行价值对齐测试时的必要性，即需要进行上下文性和动态性测试，为更复杂和现实的AI伦理和安全评估奠定了基础。', 'title_zh': '超越单句提示：通过对话和故事提升价值对齐基准'}
{'arxiv_id': 'arXiv:2503.22074', 'title': 'Penrose Tiled Low-Rank Compression and Section-Wise Q&A Fine-Tuning: A General Framework for Domain-Specific Large Language Model Adaptation', 'authors': 'Chuan-Wei Kuo, Siyu Chen, Chenqi Yan, Yu Yang Fredrik Liu', 'link': 'https://arxiv.org/abs/2503.22074', 'abstract': 'Large language models (LLMs) hold great promise for specialized scientific domains such as materials science, yet adapting them efficiently and accurately to domain-specific knowledge remains challenging due to limited data and high knowledge density. We propose a two-stage framework that combines structured model compression with a scientific fine-tuning regimen to address this challenge. In the compression stage, we decompose the LLM\'s weight matrices into local low-rank "rank blocks" and arrange these blocks in a Penrose-like non-periodic tiling pattern. Each block is then compacted via spectral transformations (e.g., discrete cosine or Fourier transforms), and a Kullback-Leibler (KL) divergence-based alignment loss preserves the distributional similarity between the compressed model\'s representations and those of the original full model. In the adaptation stage, the compressed model is further tuned using a human-like scientific reading protocol: it processes technical materials science documents section by section, engaging in a structured question-and-answer routine for each section. This section-wise Q&A fine-tuning strategy extracts explicit reasoning traces and gradually injects domain knowledge, while minimizing catastrophic forgetting of the model\'s general language capabilities. By balancing efficient compression with targeted adaptation, our two-stage approach enables precise specialization of LLMs to high-value domains under data-scarce conditions. We present this principled yet exploratory pipeline and outline its potential for advancing materials science knowledge integration, laying the groundwork for comprehensive empirical evaluation in future work.', 'abstract_zh': '大型语言模型（LLMs）在材料科学等专业科学领域展现出巨大的潜力，但由于数据有限和知识密度高，高效且准确地将它们适应到特定领域的知识仍然颇具挑战。我们提出了一种两阶段框架，结合结构化模型压缩与科学调优方案，以应对这一挑战。在压缩阶段，我们将LLM的权重矩阵分解为局部低秩“秩块”，并通过Penrose-like非周期镶嵌模式排列这些块。随后，通过谱变换（如离散余弦变换或傅里叶变换）对每个块进行压缩，并通过基于Kullback-Leibler散度的对齐损失保持压缩模型表示与原始完整模型表示之间的分布相似性。在适应阶段，使用类似人类的科学阅读协议对压缩模型进行进一步调优：逐节处理技术材料科学文档，并针对每个部分进行结构化的问答惯例。这种按节问答的调优策略提取显式的推理轨迹，并逐渐注入领域知识，同时尽可能减少模型对一般语言能力的灾难性遗忘。通过在高效压缩与目标化适应之间取得平衡，我们的两阶段方法在数据稀缺条件下使LLM能够实现精准的专业化。我们将这一原理性的探索管线呈现出来，并概述其在推进材料科学知识整合方面的潜在价值，为未来进行全面实证评估奠定基础。', 'title_zh': '佩恩罗斯铺砖低秩压缩与段落wise问答微调：一种领域特定大型语言模型适应的一般框架'}
{'arxiv_id': 'arXiv:2503.22036', 'title': "Cognitive Prompts Using Guilford's Structure of Intellect Model", 'authors': 'Oliver Kramer', 'link': 'https://arxiv.org/abs/2503.22036', 'abstract': "Large language models (LLMs) demonstrate strong language generation capabilities but often struggle with structured reasoning, leading to inconsistent or suboptimal problem-solving. To mitigate this limitation, Guilford's Structure of Intellect (SOI) model - a foundational framework from intelligence theory - is leveraged as the basis for cognitive prompt engineering. The SOI model categorizes cognitive operations such as pattern recognition, memory retrieval, and evaluation, offering a systematic approach to enhancing LLM reasoning and decision-making. This position paper presents a novel cognitive prompting approach for enforcing SOI-inspired reasoning for improving clarity, coherence, and adaptability in model responses.", 'abstract_zh': '大型语言模型（LLMs）展示了强大的语言生成能力，但在结构化推理方面往往表现不佳，导致问题解决的一致性或最优性不足。为了缓解这一限制，本文以智力理论中的Guilford的结构要素（SOI）模型为基础，提出了一种认知提示工程方法。SOI模型将认知操作分为模式识别、记忆检索和评估等类别，提供了一种系统的方法来提升LLM的推理和决策能力。本文提出了一种新颖的认知提示方法，旨在通过SOI启发式的推理提高模型响应的清晰度、连贯性和适应性。', 'title_zh': '基于吉尔福特结构智力模型的认知提示方法'}
{'arxiv_id': 'arXiv:2503.21961', 'title': 'Entropy-Aware Branching for Improved Mathematical Reasoning', 'authors': 'Xianzhi Li, Ethan Callanan, Xiaodan Zhu, Mathieu Sibue, Antony Papadimitriou, Mahmoud Mahfouz, Zhiqiang Ma, Xiaomo Liu', 'link': 'https://arxiv.org/abs/2503.21961', 'abstract': "While Large Language Models (LLMs) are effectively aligned through extensive pre-training and fine-tuning, they still struggle with varying levels of uncertainty during token generation. In our investigation of mathematical reasoning, we observe that errors are more likely to arise at tokens exhibiting high entropy and variance of entropy in the model's output distribution. Based on the observation, we propose a novel approach that dynamically branches the generation process on demand instead of defaulting to the single most probable token. By exploring in parallel multiple branches stemming from high probability tokens of critical decision points, the model can discover diverse reasoning paths that might otherwise be missed. We further harness external feedback from larger models to rank and select the most coherent and accurate reasoning branch. Our experimental results on mathematical word problems and calculation questions show that this branching strategy boosts the reasoning capabilities of small LLMs up to 4.6% compared to conventional argmax decoding.", 'abstract_zh': '尽管大规模语言模型（LLMs）通过广泛的预训练和微调实现了有效的对齐，但在标记生成过程中仍然面临着不同程度的不确定性挑战。在我们对数学推理的研究中，我们观察到高熵及其变化的令牌更可能产生错误。基于这一观察，我们提出了一种新的方法，该方法在需求时动态分支生成过程，而不是默认选择最可能的令牌。通过并行探索关键决策点高概率令牌分支，模型可以发现可能被遗漏的多样化推理路径。我们进一步利用更大模型的外部反馈来评估和选择最连贯和准确的推理分支。实验结果表明，与传统的argmax解码方法相比，这种分支策略可以将小型LLM的推理能力提高4.6%。', 'title_zh': '熵意识分支以提高数学推理能力'}
{'arxiv_id': 'arXiv:2503.21911', 'title': 'AutoPsyC: Automatic Recognition of Psychodynamic Conflicts from Semi-structured Interviews with Large Language Models', 'authors': 'Sayed Muddashir Hossain, Simon Ostermann, Patrick Gebhard, Cord Benecke, Josef van Genabith, Philipp Müller', 'link': 'https://arxiv.org/abs/2503.21911', 'abstract': "Psychodynamic conflicts are persistent, often unconscious themes that shape a person's behaviour and experiences. Accurate diagnosis of psychodynamic conflicts is crucial for effective patient treatment and is commonly done via long, manually scored semi-structured interviews. Existing automated solutions for psychiatric diagnosis tend to focus on the recognition of broad disorder categories such as depression, and it is unclear to what extent psychodynamic conflicts which even the patient themselves may not have conscious access to could be automatically recognised from conversation. In this paper, we propose AutoPsyC, the first method for recognising the presence and significance of psychodynamic conflicts from full-length Operationalized Psychodynamic Diagnostics (OPD) interviews using Large Language Models (LLMs). Our approach combines recent advances in parameter-efficient fine-tuning and Retrieval-Augmented Generation (RAG) with a summarisation strategy to effectively process entire 90 minute long conversations. In evaluations on a dataset of 141 diagnostic interviews we show that AutoPsyC consistently outperforms all baselines and ablation conditions on the recognition of four highly relevant psychodynamic conflicts.", 'abstract_zh': '动心理冲突是持久的、Often未意识的模式，影响人的行为和体验。准确诊断动心理冲突对于有效的患者治疗至关重要，通常通过长时间的手动评分半结构化访谈来完成。现有的精神疾病自动化诊断解决方案主要集中在如抑郁等广泛疾病类别上的识别，尚不清楚患者自己可能都无法意识的动心理冲突能否从对话中自动识别。在本文中，我们提出AutoPsyC，这是第一个使用大规模语言模型（LLMs）从完整长度的操作化动心理诊断（OPD）访谈中识别动心理冲突存在及其意义的方法。我们的方法结合了参数高效微调和检索增强生成（RAG）的最新进展，并采用总结策略，有效处理整个90分钟长的对话。在包含141个诊断访谈的数据集上的评估表明，AutoPsyC在识别四项高度相关动心理冲突方面始终优于所有基线和消融条件。', 'title_zh': 'AutoPsyC：从半结构化访谈中自动识别动力冲突的大语言模型方法'}
{'arxiv_id': 'arXiv:2503.21888', 'title': 'RedditESS: A Mental Health Social Support Interaction Dataset -- Understanding Effective Social Support to Refine AI-Driven Support Tools', 'authors': 'Zeyad Alghamdi, Tharindu Kumarage, Garima Agrawal, Mansooreh Karami, Ibrahim Almuteb, Huan Liu', 'link': 'https://arxiv.org/abs/2503.21888', 'abstract': 'Effective mental health support is crucial for alleviating psychological distress. While large language model (LLM)-based assistants have shown promise in mental health interventions, existing research often defines "effective" support primarily in terms of empathetic acknowledgments, overlooking other essential dimensions such as informational guidance, community validation, and tangible coping strategies. To address this limitation and better understand what constitutes effective support, we introduce RedditESS, a novel real-world dataset derived from Reddit posts, including supportive comments and original posters\' follow-up responses. Grounded in established social science theories, we develop an ensemble labeling mechanism to annotate supportive comments as effective or not and perform qualitative assessments to ensure the reliability of the annotations. Additionally, we demonstrate the practical utility of RedditESS by using it to guide LLM alignment toward generating more context-sensitive and genuinely helpful supportive responses. By broadening the understanding of effective support, our study paves the way for advanced AI-driven mental health interventions.', 'abstract_zh': '有效的心理健康支持对于缓解心理 distress 至关重要。尽管基于大规模语言模型 (LLM) 的助手在心理健康干预方面显示出前景，但现有研究往往主要从同理心认可的角度定义“有效”支持，忽视了其他重要的维度，如信息指导、社区验证和实际应对策略。为了解决这一局限性并更好地理解有效支持的含义，我们引入了 RedditESS，这是一个新颖的实际数据集，来源于 Reddit 发帖，包括支持性评论和原始发帖人的后续回复。基于现成的社会科学理论，我们开发了一种集成标注机制来标注有效和支持性或不支持性的评论，并进行定性评估以确保标注的可靠性。此外，我们通过利用 RedditESS 指引 LLM 向生成更具情境相关性和真正有用的支持性回应的方向发展。通过扩展对有效支持的理解，本研究为先进的 AI 驱动心理健康干预铺平了道路。', 'title_zh': 'RedditESS：一个心理健康社交支持互动数据集——理解有效的社交支持以优化AI驱动的支持工具'}
{'arxiv_id': 'arXiv:2503.21838', 'title': 'MSPLoRA: A Multi-Scale Pyramid Low-Rank Adaptation for Efficient Model Fine-Tuning', 'authors': 'Jiancheng Zhao, Xingda Yu, Zhen Yang', 'link': 'https://arxiv.org/abs/2503.21838', 'abstract': 'Parameter-Efficient Fine-Tuning (PEFT) has become an essential approach for adapting large-scale pre-trained models while reducing computational costs. Among PEFT methods, LoRA significantly reduces trainable parameters by decomposing weight updates into low-rank matrices. However, traditional LoRA applies a fixed rank across all layers, failing to account for the varying complexity of hierarchical information, which leads to inefficient adaptation and redundancy. To address this, we propose MSPLoRA (Multi-Scale Pyramid LoRA), which introduces Global Shared LoRA, Mid-Level Shared LoRA, and Layer-Specific LoRA to capture global patterns, mid-level features, and fine-grained information, respectively. This hierarchical structure reduces inter-layer redundancy while maintaining strong adaptation capability. Experiments on various NLP tasks demonstrate that MSPLoRA achieves more efficient adaptation and better performance while significantly reducing the number of trainable parameters. Furthermore, additional analyses based on Singular Value Decomposition validate its information decoupling ability, highlighting MSPLoRA as a scalable and effective optimization strategy for parameter-efficient fine-tuning in large language models. Our code is available at this https URL.', 'abstract_zh': '多尺度金字塔LoRA：一种高效的参数适配优化策略', 'title_zh': 'MSPLoRA：一种多尺度金字塔低秩适应方法以实现高效的模型微调'}
{'arxiv_id': 'arXiv:2503.21834', 'title': 'A Multi-Modal Knowledge-Enhanced Framework for Vessel Trajectory Prediction', 'authors': 'Haomin Yu, Tianyi Li, Kristian Torp, Christian S. Jensen', 'link': 'https://arxiv.org/abs/2503.21834', 'abstract': 'Accurate vessel trajectory prediction facilitates improved navigational safety, routing, and environmental protection. However, existing prediction methods are challenged by the irregular sampling time intervals of the vessel tracking data from the global AIS system and the complexity of vessel movement. These aspects render model learning and generalization difficult. To address these challenges and improve vessel trajectory prediction, we propose the multi-modal knowledge-enhanced framework (MAKER) for vessel trajectory prediction. To contend better with the irregular sampling time intervals, MAKER features a Large language model-guided Knowledge Transfer (LKT) module that leverages pre-trained language models to transfer trajectory-specific contextual knowledge effectively. To enhance the ability to learn complex trajectory patterns, MAKER incorporates a Knowledge-based Self-paced Learning (KSL) module. This module employs kinematic knowledge to progressively integrate complex patterns during training, allowing for adaptive learning and enhanced generalization. Experimental results on two vessel trajectory datasets show that MAKER can improve the prediction accuracy of state-of-the-art methods by 12.08%-17.86%.', 'abstract_zh': '准确的船舶轨迹预测有助于提高航行安全、航线规划和环境保护。然而，现有的预测方法受到全球AIS系统中船舶跟踪数据不规则采样时间间隔以及船舶运动复杂性的挑战，这使得模型学习和泛化变得困难。为了应对这些挑战并改进船舶轨迹预测，我们提出了一个多模态知识增强框架（MAKER）用于船舶轨迹预测。MAKER通过一个大型语言模型指导的知识转移（LKT）模块，利用预训练语言模型有效转移轨迹特定上下文知识，以更好地应对不规则采样时间间隔。为了增强学习复杂轨迹模式的能力，MAKER还引入了基于知识的自适应学习（KSL）模块。该模块利用运动学知识在训练过程中逐步整合复杂模式，实现适应性学习和增强泛化。在两个船舶轨迹数据集上的实验结果表明，MAKER可以将最先进的方法的预测准确性提高12.08%-17.86%。', 'title_zh': '多模态知识增强框架船舶轨迹预测'}
{'arxiv_id': 'arXiv:2503.21810', 'title': 'Taxonomy Inference for Tabular Data Using Large Language Models', 'authors': 'Zhenyu Wu, Jiaoyan Chen, Norman W. Paton', 'link': 'https://arxiv.org/abs/2503.21810', 'abstract': 'Taxonomy inference for tabular data is a critical task of schema inference, aiming at discovering entity types (i.e., concepts) of the tables and building their hierarchy. It can play an important role in data management, data exploration, ontology learning, and many data-centric applications. Existing schema inference systems focus more on XML, JSON or RDF data, and often rely on lexical formats and structures of the data for calculating similarities, with limited exploitation of the semantics of the text across a table. Motivated by recent works on taxonomy completion and construction using Large Language Models (LLMs), this paper presents two LLM-based methods for taxonomy inference for tables: (i) EmTT which embeds columns by fine-tuning with contrastive learning encoder-alone LLMs like BERT and utilises clustering for hierarchy construction, and (ii) GeTT which generates table entity types and their hierarchy by iterative prompting using a decoder-alone LLM like GPT-4. Extensive evaluation on three real-world datasets with six metrics covering different aspects of the output taxonomies has demonstrated that EmTT and GeTT can both produce taxonomies with strong consistency relative to the Ground Truth.', 'abstract_zh': '基于大型语言模型的表格分类学推断方法', 'title_zh': '使用大型语言模型进行表格数据的分类学推断'}
{'arxiv_id': 'arXiv:2503.21807', 'title': 'LERO: LLM-driven Evolutionary framework with Hybrid Rewards and Enhanced Observation for Multi-Agent Reinforcement Learning', 'authors': 'Yuan Wei, Xiaohan Shan, Jianmin Li', 'link': 'https://arxiv.org/abs/2503.21807', 'abstract': "Multi-agent reinforcement learning (MARL) faces two critical bottlenecks distinct from single-agent RL: credit assignment in cooperative tasks and partial observability of environmental states. We propose LERO, a framework integrating Large language models (LLMs) with evolutionary optimization to address these MARL-specific challenges. The solution centers on two LLM-generated components: a hybrid reward function that dynamically allocates individual credit through reward decomposition, and an observation enhancement function that augments partial observations with inferred environmental context. An evolutionary algorithm optimizes these components through iterative MARL training cycles, where top-performing candidates guide subsequent LLM generations. Evaluations in Multi-Agent Particle Environments (MPE) demonstrate LERO's superiority over baseline methods, with improved task performance and training efficiency.", 'abstract_zh': '多智能体强化学习（MARL）面临两个关键瓶颈，不同于单智能体RL：协同任务中的信用分配和环境状态的部分可观测性。我们提出LERO框架，该框架结合大型语言模型（LLMs）和进化优化，以解决这些MARL特定挑战。解决方案集中在两个LLM生成的组件上：一种动态分配个体信用的混合奖励函数，以及通过推断环境上下文增强部分观察的观察增强函数。进化算法通过迭代的MARL训练周期优化这些组件，其中表现最佳的候选者指导后续LLM代的生成。LERO在多智能体粒子环境（MPE）中的评估表明其优于基线方法，在任务性能和训练效率方面均有提升。', 'title_zh': 'LEREO: 由大规模语言模型驱动的混合奖励及增强观测的多智能体强化学习演化框架'}
{'arxiv_id': 'arXiv:2503.21806', 'title': 'Large Language Models Meet Contrastive Learning: Zero-Shot Emotion Recognition Across Languages', 'authors': 'Heqing Zou, Fengmao Lv, Desheng Zheng, Eng Siong Chng, Deepu Rajan', 'link': 'https://arxiv.org/abs/2503.21806', 'abstract': "Multilingual speech emotion recognition aims to estimate a speaker's emotional state using a contactless method across different languages. However, variability in voice characteristics and linguistic diversity poses significant challenges for zero-shot speech emotion recognition, especially with multilingual datasets. In this paper, we propose leveraging contrastive learning to refine multilingual speech features and extend large language models for zero-shot multilingual speech emotion estimation. Specifically, we employ a novel two-stage training framework to align speech signals with linguistic features in the emotional space, capturing both emotion-aware and language-agnostic speech representations. To advance research in this field, we introduce a large-scale synthetic multilingual speech emotion dataset, M5SER. Our experiments demonstrate the effectiveness of the proposed method in both speech emotion recognition and zero-shot multilingual speech emotion recognition, including previously unseen datasets and languages.", 'abstract_zh': '跨语言语音情感识别旨在通过无接触的方法，利用不同语言的语音特征来估计演讲者的情感状态。然而，语音特征的变异性与语言多样性对零样本多语言语音情感识别构成了重大挑战，尤其是在使用多语言数据集时。本文提出利用对比学习改进多语言语音特征并扩展大型语言模型，以实现零样本多语言语音情感估计。具体而言，我们采用一种新颖的两阶段训练框架来在情感空间中对齐语音信号与语言特征，捕捉情感感知和语言无关的语音表示。为了促进该领域的研究，我们引入了一个大规模合成多语言语音情感数据集M5SER。我们的实验表明，在语音情感识别和零样本多语言语音情感识别中，包括之前未见过的数据集和语言，所提出的方法均具有有效性。', 'title_zh': '大型语言模型结合对比学习：跨语言零样本情绪识别'}
{'arxiv_id': 'arXiv:2503.21805', 'title': 'ImF: Implicit Fingerprint for Large Language Models', 'authors': 'Wu jiaxuan, Peng Wanli, Fu hang, Xue Yiming, Wen juan', 'link': 'https://arxiv.org/abs/2503.21805', 'abstract': 'Training large language models (LLMs) is resource-intensive and expensive, making intellectual property (IP) protection essential. Most existing model fingerprint methods inject fingerprints into LLMs to protect model ownership. These methods create fingerprint pairs with weak semantic correlations, lacking the contextual coherence and semantic relatedness founded in normal question-answer (QA) pairs in LLMs. In this paper, we propose a Generation Revision Intervention (GRI) attack that can effectively exploit this flaw to erase fingerprints, highlighting the need for more secure model fingerprint methods. Thus, we propose a novel injected fingerprint paradigm called Implicit Fingerprints (ImF). ImF constructs fingerprint pairs with strong semantic correlations, disguising them as natural QA pairs within LLMs. This ensures the fingerprints are consistent with normal model behavior, making them indistinguishable and robust against detection and removal. Our experiment on multiple LLMs demonstrates that ImF retains high verification success rates under adversarial conditions, offering a reliable solution for protecting LLM ownership.', 'abstract_zh': '大型语言模型（LLM）的训练耗资巨大且成本高，知识产权（IP）保护尤为重要。现有的大多数模型指纹方法通过向LLM中注入指纹来保护模型的所有权。这些方法生成的指纹对语义相关性弱，缺乏正常问答（QA）对在LLM中所具有的上下文连贯性和语义相关性。在本文中，我们提出了一种生成修订干预（GRI）攻击，能有效利用这一缺陷来删除指纹，从而突显了更安全的模型指纹方法的需求。因此，我们提出了一种新的注入指纹范式，称为隐式指纹（ImF）。ImF 构建具有强语义相关性的指纹对，并将其伪装成LLM中的自然QA对，确保指纹与正常模型行为一致，使其难以区分并对抗检测和删除。我们在多个LLM上的实验表明，在对抗条件下，ImF 保持了高验证成功率，提供了一种可靠的保护LLM所有权的解决方案。', 'title_zh': '隐式指纹：大型语言模型的隐式指纹'}
{'arxiv_id': 'arXiv:2503.21800', 'title': 'ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports', 'authors': 'Lovedeep Gondara, Jonathan Simkin, Shebnum Devji, Gregory Arbour, Raymond Ng', 'link': 'https://arxiv.org/abs/2503.21800', 'abstract': 'Population-based cancer registries (PBCRs) face a significant bottleneck in manually extracting data from unstructured pathology reports, a process crucial for tasks like tumor group assignment, which can consume 900 person-hours for approximately 100,000 reports. To address this, we introduce ELM (Ensemble of Language Models), a novel ensemble-based approach leveraging both small language models (SLMs) and large language models (LLMs). ELM utilizes six fine-tuned SLMs, where three SLMs use the top part of the pathology report and three SLMs use the bottom part. This is done to maximize report coverage. ELM requires five-out-of-six agreement for a tumor group classification. Disagreements are arbitrated by an LLM with a carefully curated prompt. Our evaluation across nineteen tumor groups demonstrates ELM achieves an average precision and recall of 0.94, outperforming single-model and ensemble-without-LLM approaches. Deployed at the British Columbia Cancer Registry, ELM demonstrates how LLMs can be successfully applied in a PBCR setting to achieve state-of-the-art results and significantly enhance operational efficiencies, saving hundreds of person-hours annually.', 'abstract_zh': '基于人群的癌症注册库中语言模型集成方法（ELM）在病理报告解析中的应用：一种处理肿瘤分组的关键任务的高效解决方案', 'title_zh': 'ELM：预测病理报告中肿瘤类型的语言模型集成'}
{'arxiv_id': 'arXiv:2503.21422', 'title': 'From Deep Learning to LLMs: A survey of AI in Quantitative Investment', 'authors': 'Bokai Cao, Saizhuo Wang, Xinyi Lin, Xiaojun Wu, Haohan Zhang, Lionel M. Ni, Jian Guo', 'link': 'https://arxiv.org/abs/2503.21422', 'abstract': 'Quantitative investment (quant) is an emerging, technology-driven approach in asset management, increasingy shaped by advancements in artificial intelligence. Recent advances in deep learning and large language models (LLMs) for quant finance have improved predictive modeling and enabled agent-based automation, suggesting a potential paradigm shift in this field. In this survey, taking alpha strategy as a representative example, we explore how AI contributes to the quantitative investment pipeline. We first examine the early stage of quant research, centered on human-crafted features and traditional statistical models with an established alpha pipeline. We then discuss the rise of deep learning, which enabled scalable modeling across the entire pipeline from data processing to order execution. Building on this, we highlight the emerging role of LLMs in extending AI beyond prediction, empowering autonomous agents to process unstructured data, generate alphas, and support self-iterative workflows.', 'abstract_zh': '量化投资（Quant）是一种新兴的技术驱动的资产管理模式，日益受到人工智能进步的影响。量化金融中深度学习和大语言模型（LLMs）的最新进展提高了预测建模能力，并使基于代理的自动化成为可能，这可能在该领域引发范式转变。在本文综述中，以阿尔法策略为例，我们探讨人工智能如何贡献于量化投资流程。我们首先研究量化研究的早期阶段，集中在人工构建的特征和传统统计模型，并具有成熟的阿尔法流程。接着讨论深度学习的兴起，这一技术使从数据处理到下单执行的整个流程中可扩展的建模成为可能。在此基础上，我们强调大语言模型在扩展人工智能范围方面的作用，使自主代理能够处理非结构化数据、生成阿尔法并支持自迭代工作流程。', 'title_zh': '从深度学习到大语言模型：量化投资中人工智能的综述'}
