{'arxiv_id': 'arXiv:2511.05426', 'title': 'Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience', 'authors': 'Luca Girardi, Gabriel Maquignaz, Stefano Mintchev', 'link': 'https://arxiv.org/abs/2511.05426', 'abstract': "Natural flyers use soft wings to seamlessly enable a wide range of flight behaviours, including agile manoeuvres, squeezing through narrow passageways, and withstanding collisions. In contrast, conventional quadrotor designs rely on rigid frames that support agile flight but inherently limit collision resilience and squeezability, thereby constraining flight capabilities in cluttered environments. Inspired by the anisotropic stiffness and distributed mass-energy structures observed in biological organisms, we introduce FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off. We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more compliant than conventional quadrotors, yet capable of acrobatic manoeuvres with peak speeds above 80 km/h and linear and angular accelerations exceeding 3 g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate accelerations of rigid counterparts up to a thrust-to-weight ratio of 8. Simultaneously, FlexiQuad exhibits fourfold higher collision resilience, surviving frontal impacts at 5 m/s without damage and reducing destabilising forces in glancing collisions by a factor of 39. Its frame can fully compress, enabling flight through gaps as narrow as 70% of its nominal width. Our analysis identifies an optimal structural softness range, from 0.006 to 0.77 N/mm, comparable to that of natural flyers' wings, whereby agility, squeezability, and collision resilience are jointly achieved for FlexiQuad models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in complex environments, enabling robust physical interactions without compromising flight performance.", 'abstract_zh': '基于柔体框架的四旋翼无人机FlexiQuad：实现敏捷性、可挤压性和抗撞击性的统一', 'title_zh': '生物启发的软四旋翼无人机联合解锁敏捷性、可压缩性和碰撞韧性'}
{'arxiv_id': 'arXiv:2511.05402', 'title': 'Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications', 'authors': 'Muhammad Saud Ul Hassan, Derek Vasquez, Hamza Asif, Christian Hubicki', 'link': 'https://arxiv.org/abs/2511.05402', 'abstract': 'In this paper, we present an energy-conservation based control architecture for stable dynamic motion in quadruped robots. We model the robot as a Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the bouncing motion characteristic of running gaits observed in various biological quadrupeds and bio-inspired robotic systems. The model permits leg-orientation control during flight and leg-length control during stance, a design choice inspired by natural quadruped behaviors and prevalent in robotic quadruped systems. Our control algorithm uses the reduced-order SLIP dynamics of the quadruped to track a stable parabolic spline during stance, which is calculated using the principle of energy conservation. Through simulations based on the design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we demonstrate that our control algorithm generates stable bouncing gaits. Additionally, we illustrate the robustness of our controller by showcasing its ability to maintain stable bouncing even when faced with up to a 10% error in sensor measurements.', 'abstract_zh': '基于能量守恒的四足机器人稳定动态运动控制架构', 'title_zh': '基于能量守恒反馈抵消的四足机器人稳定可靠SLIP模型控制'}
{'arxiv_id': 'arXiv:2511.05397', 'title': 'EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation', 'authors': 'Samarth Chopra, Alex McMoil, Ben Carnovale, Evan Sokolson, Rajkumar Kubendran, Samuel Dickerson', 'link': 'https://arxiv.org/abs/2511.05397', 'abstract': 'While Vision-Language-Action (VLA) models map visual inputs and language instructions directly to robot actions, they often rely on costly hardware and struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF manipulator that can be assembled for under $300, capable of modest payloads and workspace. A single unified model jointly outputs discrete and continuous actions, and our adaptive-horizon ensemble monitors motion uncertainty to trigger on-the-fly re-planning for safe, reliable operation. On LIBERO, EverydayVLA matches state-of-the-art success rates, and in real-world tests it outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution. By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA democratizes access to a robotic foundation model and paves the way for economical use in homes and research labs alike. Experiment videos and details: this https URL', 'abstract_zh': '日常场景中的Vision-Language-Action (VLA)：低成本6自由度操纵器及其在机器人行动中的应用', 'title_zh': 'EveryDayVLA: 一种用于经济实惠的机器人操作的视觉-语言-行动模型'}
{'arxiv_id': 'arXiv:2511.05379', 'title': 'ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality', 'authors': 'Eric Godden, Jacquie Groenewegen, Matthew K.X.J. Pan', 'link': 'https://arxiv.org/abs/2511.05379', 'abstract': "We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction), a dynamic encountered-type haptic display (ETHD) that enables natural physical contact in virtual reality (VR) during social interactions such as handovers, fist bumps, and high-fives. The system integrates a torque-controlled robotic manipulator with interchangeable passive props (silicone hand replicas and a baton), marker-based physical-virtual registration via a ChArUco board, and a safety monitor that gates motion based on the user's head and hand pose. We introduce two control strategies: (i) a static mode that presents a stationary prop aligned with its virtual counterpart, consistent with prior ETHD baselines, and (ii) a dynamic mode that continuously updates prop position by exponentially blending an initial mid-point trajectory with real-time hand tracking, generating a unique contact point for each interaction. Bench tests show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions achieved temporal alignment with an average contact latency of 28.53 +/- 31.21 ms across all interaction and control conditions. These results demonstrate the feasibility of recreating socially meaningful haptics in VR. By incorporating essential safety and control mechanisms, ETHOS establishes a practical foundation for high-fidelity, dynamic interpersonal interactions in virtual environments.", 'abstract_zh': 'ETHOS：遇时触感交互系统，实现虚拟现实社交互动中的自然物理接触', 'title_zh': 'ETHOS：一种用于虚拟现实社交互动的接触型触觉显示机器人'}
{'arxiv_id': 'arXiv:2511.05307', 'title': 'Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators', 'authors': 'Akua K. Dickson, Juan C. Pacheco Garcia, Andrew P. Sabelhaus', 'link': 'https://arxiv.org/abs/2511.05307', 'abstract': "Soft robot manipulators have the potential for deployment in delicate environments to perform complex manipulation tasks. However, existing obstacle detection and avoidance methods do not consider limits on the forces that manipulators may exert upon contact with delicate obstacles. This work introduces a framework that maps force safety criteria from task space (i.e. positions along the robot's body) to configuration space (i.e. the robot's joint angles) and enables real-time force safety detection. We incorporate limits on allowable environmental contact forces for given task-space obstacles, and map them into configuration space (C-space) through the manipulator's forward kinematics. This formulation ensures that configurations classified as safe are provably below the maximum force thresholds, thereby allowing us to determine force-safe configurations of the soft robot manipulator in real-time. We validate our approach in simulation and hardware experiments on a two-segment pneumatic soft robot manipulator. Results demonstrate that the proposed method accurately detects force safety during interactions with deformable obstacles, thereby laying the foundation for real-time safe planning of soft manipulators in delicate, cluttered environments.", 'abstract_zh': '软体机器人 manipulators 在敏感环境中执行复杂操作任务具有潜力。然而，现有的障碍检测与规避方法未考虑软体机器人在接触敏感障碍物时可施加的力的限制。本工作介绍了一种框架，将力的安全标准从任务空间（即机器人身体上的位置）映射到配置空间（即机器人的关节角度），并实现实时力安全检测。我们结合了给定任务空间障碍物的允许环境接触力限制，并通过机器人的正向运动学将其映射到配置空间（C空间）。该形式化表示保证被分类为安全的配置是可证明地低于最大力阈值，从而允许我们实时确定软体机器人在安全状态下的配置。我们在仿真和硬件实验中对一个两段气动软体机器人 manipulators 进行了验证。结果表明，所提出的方法能够准确检测与可变形障碍物交互过程中的力安全，为软体操作器在复杂、拥挤的敏感环境中的实时安全规划奠定了基础。', 'title_zh': '具有力安全环境映射和实时检测的软机器人 manipulator 环境模型'}
{'arxiv_id': 'arXiv:2511.05275', 'title': 'TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models', 'authors': 'Hokyun Im, Euijin Jeong, Jianlong Fu, Andrey Kolobov, Youngwoon Lee', 'link': 'https://arxiv.org/abs/2511.05275', 'abstract': 'Vision-language-action models (VLAs) trained on large-scale robotic datasets have demonstrated strong performance on manipulation tasks, including bimanual tasks. However, because most public datasets focus on single-arm demonstrations, adapting VLAs for bimanual tasks typically requires substantial additional bimanual data and fine-tuning. To address this challenge, we introduce TwinVLA, a modular framework that composes two copies of a pretrained single-arm VLA into a coordinated bimanual VLA. Unlike monolithic cross-embodiment models trained on mixtures of single-arm and bimanual data, TwinVLA improves both data efficiency and performance by composing pretrained single-arm policies. Across diverse bimanual tasks in real-world and simulation settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model without requiring any bimanual pretraining. Furthermore, it narrows the gap to state-of-the-art model, $\\pi_0$ which rely on extensive proprietary bimanual data and compute cost. These results establish our modular composition approach as a data-efficient and scalable path toward high-performance bimanual manipulation, leveraging public single-arm data.', 'abstract_zh': '基于预训练单臂视觉-语言-动作模型的模块化双臂视觉-语言-动作框架', 'title_zh': 'TwinVLA：基于双单臂视觉语言行动模型的高效双臂操作'}
{'arxiv_id': 'arXiv:2511.05234', 'title': 'Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning', 'authors': 'Philipp Dahlinger, Niklas Freymuth, Tai Hoang, Tobias Würth, Michael Volpp, Luise Kärger, Gerhard Neumann', 'link': 'https://arxiv.org/abs/2511.05234', 'abstract': 'Simulating object deformations is a critical challenge across many scientific domains, including robotics, manufacturing, and structural mechanics. Learned Graph Network Simulators (GNSs) offer a promising alternative to traditional mesh-based physics simulators. Their speed and inherent differentiability make them particularly well suited for applications that require fast and accurate simulations, such as robotic manipulation or manufacturing optimization. However, existing learned simulators typically rely on single-step observations, which limits their ability to exploit temporal context. Without this information, these models fail to infer, e.g., material properties. Further, they rely on auto-regressive rollouts, which quickly accumulate error for long trajectories. We instead frame mesh-based simulation as a trajectory-level meta-learning problem. Using Conditional Neural Processes, our method enables rapid adaptation to new simulation scenarios from limited initial data while capturing their latent simulation properties. We utilize movement primitives to directly predict fast, stable and accurate simulations from a single model call. The resulting approach, Movement-primitive Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of the runtime cost compared to state-of-the-art GNSs across several tasks.', 'abstract_zh': '基于网格的仿真对象变形模拟是许多科学领域的一项关键挑战，包括机器人学、制造和结构力学。学习图网络仿真器（GNSs）为传统基于网格的物理仿真器提供了一种有前途的替代方案。它们的速度和内在可微性使它们特别适合需要快速和准确仿真的应用，例如机器人操作或制造优化。然而，现有的学习仿真器通常依赖于单步观察，这限制了它们利用时间上下文的能力。没有这些信息，这些模型难以推断，例如材料属性。此外，它们依赖于自回归滚动预测，这会导致长时间轨迹迅速累积误差。相反，我们将基于网格的仿真框架为一个轨迹级元学习问题。利用条件神经过程，我们的方法可以在有限的初始数据下快速适应新的仿真场景，同时捕获其潜在的仿真特性。我们使用运动基元直接从单次模型调用预测快速、稳定和准确的仿真。由此产生的方法，运动基元元网格图网络（M3GN），在多个任务上与最先进的GNSs相比，提供了更高的仿真精度，且运行时间成本仅为其中的一小部分。', 'title_zh': '基于轨迹级元学习的上下文感知学习网格模拟'}
{'arxiv_id': 'arXiv:2511.05203', 'title': 'Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space', 'authors': 'Linus Nwankwo, Björn Ellensohn, Christian Rauch, Elmar Rueckert', 'link': 'https://arxiv.org/abs/2511.05203', 'abstract': "Today's autonomous agents can understand free-form natural language instructions and execute long-horizon tasks in a manner akin to human-level reasoning. These capabilities are mostly driven by large-scale pre-trained foundation models (FMs). However, the approaches with which these models are grounded for human-robot interaction (HRI) perpetuate a master-apprentice model, where the apprentice (embodied agent) passively receives and executes the master's (human's) commands without reciprocal learning. This reactive interaction approach does not capture the co-adaptive dynamics inherent in everyday multi-turn human-human interactions. To address this, we propose a Symbiotic Interactive Learning (SIL) approach that enables both the master and the apprentice to co-adapt through mutual, bidirectional interactions. We formalised SIL as a co-adaptation process within a shared latent task space, where the agent and human maintain joint belief states that evolve based on interaction history. This enables the agent to move beyond reactive execution to proactive clarification, adaptive suggestions, and shared plan refinement. To realise these novel behaviours, we leveraged pre-trained FMs for spatial perception and reasoning, alongside a lightweight latent encoder that grounds the models' outputs into task-specific representations. Furthermore, to ensure stability as the tasks evolve, we augment SIL with a memory architecture that prevents the forgetting of learned task-space representations. We validate SIL on both simulated and real-world embodied tasks, including instruction following, information retrieval, query-oriented reasoning, and interactive dialogues. Demos and resources are public at:~\\href{this https URL}{this https URL}.", 'abstract_zh': '当今自主代理能够理解免费形式的自然语言指令，并以类人的推理方式执行长期任务。这些能力主要由大规模预训练基础模型（FMs）驱动。然而，这些模型在人类机器人互动（HRI）中被锚定的方式延续了一种师父徒弟模式，其中徒弟（具身代理）被动地接收并执行师父（人类）的命令，而不进行相互学习。这种反应式交互方法未能捕捉到日常多轮人类互动中固有的共适应动态。为了解决这一问题，我们提出了一种共生互动学习（SIL）方法，使师父和徒弟能够通过双向互动共同适应。我们将SIL形式化为共享潜在任务空间中的共适应过程，在这个过程中，代理和人类维护基于互动历史演变的共同信念状态。这使代理能够超越被动执行，进行主动澄清、适应性建议和共享计划细化。为了实现这些新颖行为，我们利用了预训练的FMs进行空间感知和推理，并结合了一个轻量级的潜在编码器，将模型的输出转化为任务特定的表示。此外，为了确保随着任务的发展保持稳定性，我们通过在SIL中增加一个记忆架构，防止已学任务空间表示的遗忘。我们已在模拟和真实世界的具身任务中验证了SIL，包括指令跟随、信息检索、查询导向的推理以及交互对话。演示和资源可在：\\href{this https URL}{this https URL}。', 'title_zh': '超越师徒关系：在共享潜在空间中实现共生互动学习的基礎模型嵌入'}
{'arxiv_id': 'arXiv:2511.05199', 'title': 'Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation', 'authors': 'Yichen Zhu, Feifei Feng', 'link': 'https://arxiv.org/abs/2511.05199', 'abstract': "Robots operating in complex and uncertain environments face considerable challenges. Advanced robotic systems often rely on extensive datasets to learn manipulation tasks. In contrast, when humans are faced with unfamiliar tasks, such as assembling a chair, a common approach is to learn by watching video demonstrations. In this paper, we propose a novel method for learning robot policies by Retrieving-from-Video (RfV), using analogies from human demonstrations to address manipulation tasks. Our system constructs a video bank comprising recordings of humans performing diverse daily tasks. To enrich the knowledge from these videos, we extract mid-level information, such as object affordance masks and hand motion trajectories, which serve as additional inputs to enhance the robot model's learning and generalization capabilities. We further feature a dual-component system: a video retriever that taps into an external video bank to fetch task-relevant video based on task specification, and a policy generator that integrates this retrieved knowledge into the learning cycle. This approach enables robots to craft adaptive responses to various scenarios and generalize to tasks beyond those in the training data. Through rigorous testing in multiple simulated and real-world settings, our system demonstrates a marked improvement in performance over conventional robotic systems, showcasing a significant breakthrough in the field of robotics.", 'abstract_zh': '复杂和不确定环境中的机器人操作面临着巨大挑战。与人类在面对陌生任务时通过观看视频示范来学习类似，先进的机器人系统通常依赖大量数据集来学习操作任务。本文提出了一种名为Retrieving-from-Video (RfV)的新方法，通过人类示范中的类比来解决操作任务，构建了一个包含人类执行各种日常任务的视频库。通过提取中层次信息，如物体可用性掩模和手部运动轨迹，这些信息作为额外输入增强机器人模型的学习和泛化能力。该系统还配备了双组件系统：一个视频检索器，根据任务规范从外部视频库中检索相关视频，以及一个策略生成器，将检索到的知识整合到学习周期中。这种方法使机器人能够根据不同场景生成适应性响应，并泛化到训练数据之外的任务。通过在多种模拟和真实世界设置下的严格测试，我们的系统在性能上显著优于传统机器人系统，展示了机器人领域的重要突破。', 'title_zh': '让我展示给你看：基于第一人称视频检索的学习方法在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2511.05185', 'title': 'Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones', 'authors': 'Adrián Campazas-Vega, Claudia Álvarez-Aparicio, David Sobrín-Hidalgo, Laura Inyesto-Alonso, Francisco Javier Rodríguez-Lera, Vicente Matellán-Olivera, Ángel Manuel Guerrero-Higueras', 'link': 'https://arxiv.org/abs/2511.05185', 'abstract': 'The deployment of autonomous systems has experienced remarkable growth in recent years, driven by their integration into sectors such as industry, medicine, logistics, and domestic environments. This expansion is accompanied by a series of security issues that entail significant risks due to the critical nature of autonomous systems, especially those operating in human-interaction environments. Furthermore, technological advancement and the high operational and architectural complexity of autonomous systems have resulted in an increased attack surface. This article presents a specific security auditing procedure for autonomous systems, based on a layer-structured methodology, a threat taxonomy adapted to the robotic context, and a set of concrete mitigation measures. The validity of the proposed approach is demonstrated through four practical case studies applied to representative robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1 robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots, and the Pepper social robot from Aldebaran Robotics.', 'abstract_zh': '近年来，自主系统部署经历了显著增长，特别是在工业、医疗、物流和家庭环境等领域与各行业的深度融合。这一扩张伴随着一系列安全问题，由于自主系统的关键性质，特别是在人类交互环境中运行的自主系统，这些安全问题带来了重大风险。此外，技术进步和自主系统的高操作和架构复杂性导致了更大的攻击面。本文提出了一种基于分层方法、适应机器人情境的威胁分类和一系列具体的缓解措施的具体安全审计程序。通过将其应用于代表性的机器人平台（包括Ghost Robotics的Vision 60军用四足机器人、Unitree Robotics的A1机器人、Universal Robots的UR3协作臂以及Aldebaran Robotics的Pepper社会机器人）的四个实际案例研究，证明了所提出方法的有效性。', 'title_zh': '自主系统网络安全审计程序：方法、威胁与缓解措施'}
{'arxiv_id': 'arXiv:2511.05158', 'title': 'Follow-Me in Micro-Mobility with End-to-End Imitation Learning', 'authors': 'Sahar Salimpour, Iacopo Catalano, Tomi Westerlund, Mohsen Falahi, Jorge Peña Queralta', 'link': 'https://arxiv.org/abs/2511.05158', 'abstract': "Autonomous micro-mobility platforms face challenges from the perspective of the typical deployment environment: large indoor spaces or urban areas that are potentially crowded and highly dynamic. While social navigation algorithms have progressed significantly, optimizing user comfort and overall user experience over other typical metrics in robotics (e.g., time or distance traveled) is understudied. Specifically, these metrics are critical in commercial applications. In this paper, we show how imitation learning delivers smoother and overall better controllers, versus previously used manually-tuned controllers. We demonstrate how DAAV's autonomous wheelchair achieves state-of-the-art comfort in follow-me mode, in which it follows a human operator assisting persons with reduced mobility (PRM). This paper analyzes different neural network architectures for end-to-end control and demonstrates their usability in real-world production-level deployments.", 'abstract_zh': '自主微型移动平台在典型的部署环境中面临着挑战：如大型室内空间或潜在拥挤且高度动态的城市区域。尽管社交导航算法取得了显著进展，但优化用户体验（而非传统机器人指标，如时间或行驶距离）的研究仍然不足，特别是在商业应用中这些指标至关重要。本文展示了模仿学习如何提供更平滑且整体更好的控制器，优于之前手动调优的控制器。我们展示了DAAV的自主轮椅在跟随模式下实现了最佳舒适度，该模式下它跟随辅助行动不便人员的人类操作者。本文分析了不同的神经网络架构，展示了它们在实际生产部署中的适用性。', 'title_zh': '微移动中基于端到端模仿学习的随我行技术'}
{'arxiv_id': 'arXiv:2511.05129', 'title': 'Decomposed Object Manipulation via Dual-Actor Policy', 'authors': 'Bin Fan, Jianjian Jiang, Zhuohao Li, Yixiang He, Xiaoming Wu, Yihan Yang, Shengbang Liu, Weishi Zheng', 'link': 'https://arxiv.org/abs/2511.05129', 'abstract': 'Object manipulation, which focuses on learning to perform tasks on similar parts across different types of objects, can be divided into an approaching stage and a manipulation stage. However, previous works often ignore this characteristic of the task and rely on a single policy to directly learn the whole process of object manipulation. To address this problem, we propose a novel Dual-Actor Policy, termed DAP, which explicitly considers different stages and leverages heterogeneous visual priors to enhance each stage. Specifically, we introduce an affordance-based actor to locate the functional part in the manipulation task, thereby improving the approaching process. Following this, we propose a motion flow-based actor to capture the movement of the component, facilitating the manipulation process. Finally, we introduce a decision maker to determine the current stage of DAP and select the corresponding actor. Moreover, existing object manipulation datasets contain few objects and lack the visual priors needed to support training. To address this, we construct a simulated dataset, the Dual-Prior Object Manipulation Dataset, which combines the two visual priors and includes seven tasks, including two challenging long-term, multi-stage tasks. Experimental results on our dataset, the RoboTwin benchmark and real-world scenarios illustrate that our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4% on average respectively.', 'abstract_zh': '基于双执行器策略的物体操作方法：考虑不同阶段并利用异构视觉先验', 'title_zh': '双actor策略的分解对象操纵'}
{'arxiv_id': 'arXiv:2511.05052', 'title': 'TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments', 'authors': 'Zihao Li, Yiming Zhu, Zhe Zhong, Qinyuan Ren, Yijiang Huang', 'link': 'https://arxiv.org/abs/2511.05052', 'abstract': 'Robotic manipulation in complex, constrained spaces is vital for widespread applications but challenging, particularly when navigating narrow passages with elongated objects. Existing planning methods often fail in these low-clearance scenarios due to the sampling difficulties or the local minima. This work proposes Topology-Aware Planning for Object Manipulation (TAPOM), which explicitly incorporates task-space topological analysis to enable efficient planning. TAPOM uses a high-level analysis to identify critical pathways and generate guiding keyframes, which are utilized in a low-level planner to find feasible configuration space trajectories. Experimental validation demonstrates significantly high success rates and improved efficiency over state-of-the-art methods on low-clearance manipulation tasks. This approach offers broad implications for enhancing manipulation capabilities of robots in complex real-world environments.', 'abstract_zh': '拓扑感知物体操作规划（TAPOM）：在复杂受限空间中的高效操作规划', 'title_zh': 'TAPOM: 任务空间拓扑引导的操纵elongated物体的集群环境运动规划'}
{'arxiv_id': 'arXiv:2511.05033', 'title': 'Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems', 'authors': 'Jennifer K. Leestma, Siddharth R. Nathella, Christoph P. O. Nuesslein, Snehil Mathur, Gregory S. Sawicki, Aaron J. Young', 'link': 'https://arxiv.org/abs/2511.05033', 'abstract': 'Epically Powerful is an open-source robotics infrastructure that streamlines the underlying framework of wearable robotic systems - managing communication protocols, clocking, actuator commands, visualization, sensor data acquisition, data logging, and more - while also providing comprehensive guides for hardware selection, system assembly, and controller implementation. Epically Powerful contains a code base enabling simplified user implementation via Python that seamlessly interfaces with various commercial state-of-the-art quasi-direct drive (QDD) actuators, single-board computers, and common sensors, provides example controllers, and enables real-time visualization. To further support device development, the package also includes a recommended parts list and compatibility guide and detailed documentation on hardware and software implementation. The goal of Epically Powerful is to lower the barrier to developing and deploying custom wearable robotic systems without a pre-specified form factor, enabling researchers to go from raw hardware to modular, robust devices quickly and effectively. Though originally designed with wearable robotics in mind, Epically Powerful is broadly applicable to other robotic domains that utilize QDD actuators, single-board computers, and sensors for closed-loop control.', 'abstract_zh': 'Epically Powerful是一款开源的机器人基础设施，简化可穿戴机器人系统的底层框架管理，包括通信协议、时钟、执行器命令、可视化、传感器数据采集、数据记录等功能，同时提供硬件选择、系统组装和控制器实现的全面指南。Epically Powerful包含一个通过Python简化用户实现的代码库，无缝接口多种商业先进的准直接驱动（QDD）执行器、单板计算机和常见传感器，提供示例控制器，并支持实时可视化。为了进一步支持设备开发，该软件包还包括推荐的零部件清单和兼容性指南，以及详细的硬件和软件实施文档。Epically Powerful的目标是降低开发和部署自定义可穿戴机器人系统的障碍，使研究人员能够快速有效地从原始硬件过渡到模块化、可靠的设备。虽然最初是为可穿戴机器人设计的，但Epically Powerful在利用QDD执行器、单板计算机和传感器进行闭 loop控制的其他机器人领域也具有广泛应用潜力。', 'title_zh': 'epically 强大：一种开源软件与机电一体化基础设施，用于穿戴式机器人系统'}
{'arxiv_id': 'arXiv:2511.05026', 'title': 'Tunable Passivity Control for Centralized Multiport Networked Systems', 'authors': 'Xingyuan Zhou, Peter Paik, S. Farokh Atashzar', 'link': 'https://arxiv.org/abs/2511.05026', 'abstract': 'Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key architecture with applications in several complex network systems, such as multilateral telerobotics and multi-agent control. These systems consist of a hub node/subsystem connecting with multiple remote nodes/subsystems via a networked architecture. One challenge for this system is stability, which can be affected by non-ideal network artifacts. Conventional passivity-based approaches can stabilize the system under specialized applications like small-scale networked systems. However, those conventional passive stabilizers have several restrictions, such as distributing compensation across subsystems in a decentralized manner, limiting flexibility, and, at the same time, relying on the restrictive assumptions of node passivity. This paper synthesizes a centralized optimal passivity-based stabilization framework for CMND systems. It consists of a centralized passivity observer monitoring overall energy flow and an optimal passivity controller that distributes the just-needed dissipation among various nodes, guaranteeing strict passivity and, thus, L2 stability. The proposed data-driven model-free approach, i.e., Tunable Centralized Optimal Passivity Control (TCoPC), optimizes total performance based on the prescribed dissipation distribution strategy while ensuring stability. The controller can put high dissipation loads on some sub-networks while relaxing the dissipation on other nodes. Simulation results demonstrate the proposed frameworks performance in a complex task under different time-varying delay scenarios while relaxing the remote nodes minimum phase and passivity assumption, enhancing the scalability and generalizability.', 'abstract_zh': '集中的多端口网络动态(CMND)系统及其在多边遥控和多代理控制中的应用', 'title_zh': '可调平稳性控制的集中多端口网络系统'}
{'arxiv_id': 'arXiv:2511.05007', 'title': 'MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery', 'authors': 'Baiye Cheng, Tianhai Liang, Suning Huang, Maanping Shao, Feihong Zhang, Botian Xu, Zhengrong Xue, Huazhe Xu', 'link': 'https://arxiv.org/abs/2511.05007', 'abstract': "Diffusion policies have emerged as a powerful framework for robotic visuomotor control, yet they often lack the robustness to recover from subtask failures in long-horizon, multi-stage tasks and their learned representations of observations are often difficult to interpret. In this work, we propose the Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is to insert a Mixture of Experts (MoE) layer between the visual encoder and the diffusion model. This layer decomposes the policy's knowledge into a set of specialized experts, which are dynamically activated to handle different phases of a task. We demonstrate through extensive experiments that MoE-DP exhibits a strong capability to recover from disturbances, significantly outperforming standard baselines in robustness. On a suite of 6 long-horizon simulation tasks, this leads to a 36% average relative improvement in success rate under disturbed conditions. This enhanced robustness is further validated in the real world, where MoE-DP also shows significant performance gains. We further show that MoE-DP learns an interpretable skill decomposition, where distinct experts correspond to semantic task primitives (e.g., approaching, grasping). This learned structure can be leveraged for inference-time control, allowing for the rearrangement of subtasks without any this http URL video and code are available at the this https URL.", 'abstract_zh': 'MoE-增强的扩散策略：一种强健的机器人视觉运动控制框架', 'title_zh': 'MoE-DP: 一种基于MoE增强的扩散策略，实现具有技能分解和故障恢复的稳健长期 horizon 机器人操作'}
{'arxiv_id': 'arXiv:2511.04994', 'title': 'Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems', 'authors': 'Xingyuan Zhou, Peter Paik, S. Farokh Atashzar', 'link': 'https://arxiv.org/abs/2511.04994', 'abstract': "Maintaining system stability and accurate position tracking is imperative in networked robotic systems, particularly for haptics-enabled human-robot interaction. Recent literature has integrated human biomechanics into the stabilizers implemented for teleoperation, enhancing force preservation while guaranteeing convergence and safety. However, position desynchronization due to imperfect communication and non-passive behaviors remains a challenge. This paper proposes a two-port biomechanics-aware passivity-based synchronizer and stabilizer, referred to as TBPS2. This stabilizer optimizes position synchronization by leveraging human biomechanics while reducing the stabilizer's conservatism in its activation. We provide the mathematical design synthesis of the stabilizer and the proof of stability. We also conducted a series of grid simulations and systematic experiments, comparing their performance with that of state-of-the-art solutions under varying time delays and environmental conditions.", 'abstract_zh': '维持系统稳定性和精确的位置跟踪在网络化机器人系统中至关重要，特别是在具有触觉增强的人机交互中。近期文献已经将人类生物力学纳入远程操作中实现稳定性的设计中，增强了力的保存能力并确保了收敛性和安全性。然而，由于通信不完美和非被动行为导致的位置同步问题仍然是一个挑战。本文提出了一种基于生物力学的两端口.passivityベース同步器和稳定器，称为TBPS2。该稳定器通过利用人类生物力学来优化位置同步，同时减少了稳定器在激活时的保守性。我们提供了稳定器的数学设计合成，并证明了其稳定性。我们还进行了网格仿真和系统实验，比较了在不同时间延迟和环境条件下其性能与最先进的解决方案的性能。', 'title_zh': '基于耗散性同步的网络化遥操作系统中的生物力学能量裕度编码'}
{'arxiv_id': 'arXiv:2511.04992', 'title': 'A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces', 'authors': 'Bibekananda Patra, Sandipan Bandyopadhyay', 'link': 'https://arxiv.org/abs/2511.04992', 'abstract': 'This article presents a method for computing the largest singularity-free sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a specified orientation workspace. For a fixed orientation of the moving platform, the SFS is computed analytically. This process is repeated over a set of samples generated within the orientation workspace, and the smallest among them is designated as the desired SFS for the given orientation workspace. Numerical experiments are performed on four distinct architectures of the SGPM to understand their relative performances w.r.t. SFS volumes over the same orientation workspace. This study demonstrates the potential utility of the proposed computational method both in analysis and design of SGPMs.', 'abstract_zh': '本文提出了一种计算6-6斯坦福-戈斯平台 manipulator (SGPM) 在指定姿态工作空间内最大无奇点球面 (SFS) 的方法。对于固定姿态的运动平台，SFS 可通过解析方法计算。该过程在工作空间内的样本集上重复进行，并将其中最小者指定为目标 SFS。在相同的姿态工作空间上对 SGPM 的四种不同结构进行数值实验，以了解其在 SFS 体积方面的相对性能。本文展示了所提出计算方法在 SGPM 的分析和设计中的潜在用途。', 'title_zh': '一类6-6 Stewart-Gough 平台指定 orientations 工作空间中计算最大无奇点球面的一种半解析方法'}
{'arxiv_id': 'arXiv:2511.04976', 'title': 'iFlyBot-VLM Technical Report', 'authors': 'Xin Nie, Zhiyuan Cheng, Yuan Zhang, Chao Ji, Jiajia Wu, Yuhan Zhang, Jia Pan', 'link': 'https://arxiv.org/abs/2511.04976', 'abstract': "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used to improve the domain of Embodied Intelligence. The central objective of iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional environmental perception and low-level robotic motion control. To this end, the model abstracts complex visual and spatial information into a body-agnostic and transferable Operational Language, thereby enabling seamless perception-action closed-loop coordination across diverse robotic platforms. The architecture of iFlyBot-VLM is systematically designed to realize four key functional capabilities essential for embodied intelligence: 1) Spatial Understanding and Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and Control Parameter Generation; 4) Task Planning and Skill Sequencing. We envision iFlyBot-VLM as a scalable and generalizable foundation model for embodied AI, facilitating the progression from specialized task-oriented systems toward generalist, cognitively capable agents. We conducted evaluations on 10 current mainstream embodied intelligence-related VLM benchmark datasets, such as Blink and Where2Place, and achieved optimal performance while preserving the model's general capabilities. We will publicly release both the training data and model weights to foster further research and development in the field of Embodied Intelligence.", 'abstract_zh': '我们介绍了适用于增强体域智能领域的一般目的视觉-语言模型iFlyBot-VLM。iFlyBot-VLM的核心目标是弥合高维环境感知与低级机器人运动控制之间的跨模态语义差距。为实现这一目标，该模型将复杂的空间和视觉信息抽象为一种体域无关且可迁移的操作语言，从而在多种机器人平台上实现无缝的感知-行动闭环协调。iFlyBot-VLM的架构系统性地设计以实现体域智能四个关键功能能力：1）空间理解与度量推理；2）交互式目标接地；3）动作抽象与控制参数生成；4）任务规划与技能序列化。我们设想iFlyBot-VLM将成为体域人工智能的可扩展且可泛化的基础模型，促进从专门任务导向系统向通用、认知能力强的代理的发展。我们在Blink和Where2Place等10个当前主流的体域智能相关视觉-语言模型基准数据集上进行了评估，实现了最优性能同时保持模型的通用能力，并将公开训练数据和模型权重以促进体域智能领域的进一步研究与开发。', 'title_zh': 'iFlyBot-VLM 技术报告'}
{'arxiv_id': 'arXiv:2511.04837', 'title': 'Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions', 'authors': 'Cameron Robinson, Ganghee Jang', 'link': 'https://arxiv.org/abs/2511.04837', 'abstract': "Solar energy is used for many mission-critical applications including space exploration, sensor systems to monitor wildfires, etc. Their operation can be limited or even terminated if solar panels are covered with dust or hit by space debris. To address this issue, we designed panel cleaning mechanisms and tested protective materials. For cleaning mechanisms, we designed and compared a wiper system and a rail system. For protective materials, we found through collision tests that polycarbonate was very promising, though the most important factor was layering a soft material between the panel's surface and a hard material. In the cleaning system comparisons, the wiper-based system was more efficient than the rail-based system in terms of cost, cleaning speed, and total power consumption.", 'abstract_zh': '太阳能在空间探索和监控野火的传感器系统等关键任务应用中被广泛使用。如果太阳能板被灰尘覆盖或受到空间碎片的撞击，其运行可能会受到限制甚至停止。为解决这一问题，我们设计了清洁机制并测试了保护材料。在清洁机制方面，我们设计并比较了刮水器系统和滑轨系统。在保护材料方面，通过碰撞测试发现聚碳酸酯非常有潜力，但最关键的因素是在面板表面和硬材料之间铺设一层软材料。在清洁系统的比较中，基于刮水器的系统在成本、清洁速度和总能耗方面比基于滑轨的系统更高效。', 'title_zh': '太空任务中太阳能板的保护与清洁设计探索及案例研究'}
{'arxiv_id': 'arXiv:2511.04835', 'title': 'Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning', 'authors': 'Shubham Natraj, Bruno Sinopoli, Yiannis Kantaros', 'link': 'https://arxiv.org/abs/2511.04835', 'abstract': "Sampling-based motion planners (SBMPs) are widely used to compute dynamically feasible robot paths. However, their reliance on uniform sampling often leads to poor efficiency and slow planning in complex environments. We introduce a novel non-uniform sampling strategy that integrates into existing SBMPs by biasing sampling toward `certified' regions. These regions are constructed by (i) generating an initial, possibly infeasible, path using any heuristic path predictor (e.g., A* or vision-language models) and (ii) applying conformal prediction to quantify the predictor's uncertainty. This process yields prediction sets around the initial-guess path that are guaranteed, with user-specified probability, to contain the optimal solution. To our knowledge, this is the first non-uniform sampling approach for SBMPs that provides such probabilistically correct guarantees on the sampling regions. Extensive evaluations demonstrate that our method consistently finds feasible paths faster and generalizes better to unseen environments than existing baselines.", 'abstract_zh': '基于采样的运动规划器（SBMPs）广泛用于计算动态可行的机器人路径。然而，它们对均匀采样的依赖往往导致在复杂环境中效率低下且规划缓慢。我们介绍了一种新型非均匀采样策略，该策略通过偏向于“认证”区域的采样整合到现有的SBMPs中。这些区域通过以下步骤构建：(i) 使用任何启发式路径预测器（例如A*或视觉-语言模型）生成一个初始的、可能是不可行的路径，(ii) 应用容错预测来量化预测器的不确定性。该过程生成围绕初始猜测路径的预测集合，这些集合在用户指定的概率下保证包含最优解。据我们所知，这是首个能够为SBMPs提供此类概率正确保证的非均匀采样方法。广泛实验表明，我们的方法能够比现有基线更快且更好地在未见环境中找到可行路径。', 'title_zh': '符合非均匀采样策略的共形加速采样为基础的运动规划'}
{'arxiv_id': 'arXiv:2511.04831', 'title': 'Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning', 'authors': 'NVIDIA, Mayank Mittal, Pascal Roth, James Tigue, Antoine Richard, Octi Zhang, Peter Du, Antonio Serrano-Muñoz, Xinjie Yao, René Zurbrügg, Nikita Rudin, Lukasz Wawrzyniak, Milad Rakhsha, Alain Denzler, Eric Heiden, Ales Borovicka, Ossama Ahmed, Iretiayo Akinola, Abrar Anwar, Mark T. Carlson, Ji Yuan Feng, Animesh Garg, Renato Gasoto, Lionel Gulich, Yijie Guo, M. Gussert, Alex Hansen, Mihir Kulkarni, Chenran Li, Wei Liu, Viktor Makoviychuk, Grzegorz Malczyk, Hammad Mazhar, Masoud Moghani, Adithyavairavan Murali, Michael Noseworthy, Alexander Poddubny, Nathan Ratliff, Welf Rehberg, Clemens Schwarke, Ritvik Singh, James Latham Smith, Bingjie Tang, Ruchik Thaker, Matthew Trepte, Karl Van Wyk, Fangzhou Yu, Alex Millane, Vikram Ramasamy, Remo Steiner, Sangeeta Subramanian, Clemens Volk, CY Chen, Neel Jawale, Ashwin Varghese Kuruttukulam, Michael A. Lin, Ajay Mandlekar, Karsten Patzwaldt, John Welsh, Huihua Zhao, Fatima Anes, Jean-Francois Lafleche, Nicolas Moënne-Loccoz, Soowan Park, Rob Stepinski, Dirk Van Gelder, Chris Amevor, Jan Carius, Jumyung Chang, Anka He Chen, Pablo de Heras Ciechomski, Gilles Daviet, Mohammad Mohajerani, Julia von Muralt, Viktor Reutskyy, Michael Sauter, Simon Schirm, Eric L. Shi, Pierre Terdiman, Kenny Vilella, Tobias Widmer, Gordon Yeoman, Tiffany Chen, Sergey Grizan, Cathy Li, Lotus Li, Connor Smith, Rafael Wiltz, Kostas Alexis, Yan Chang, David Chu, Linxi "Jim" Fan, Farbod Farshidian, Ankur Handa, Spencer Huang, Marco Hutter, Yashraj Narang, Soha Pouya, Shiwei Sheng, Yuke Zhu', 'link': 'https://arxiv.org/abs/2511.04831', 'abstract': "We present Isaac Lab, the natural successor to Isaac Gym, which extends the paradigm of GPU-native robotics simulation into the era of large-scale multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics, photorealistic rendering, and a modular, composable architecture for designing environments and training robot policies. Beyond physics and rendering, the framework integrates actuator models, multi-frequency sensor simulation, data collection pipelines, and domain randomization tools, unifying best practices for reinforcement and imitation learning at scale within a single extensible platform. We highlight its application to a diverse set of challenges, including whole-body control, cross-embodiment mobility, contact-rich and dexterous manipulation, and the integration of human demonstrations for skill acquisition. Finally, we discuss upcoming integration with the differentiable, GPU-accelerated Newton physics engine, which promises new opportunities for scalable, data-efficient, and gradient-based approaches to robot learning. We believe Isaac Lab's combination of advanced simulation capabilities, rich sensing, and data-center scale execution will help unlock the next generation of breakthroughs in robotics research.", 'abstract_zh': '我们介绍了Isaac Lab，它是Isaac Gym的自然延续，将基于GPU的机器人模拟扩展到了大规模多模态学习的时代。Isaac Lab结合了高保真GPU并行物理、逼真渲染以及用于设计环境和训练机器人策略的模块化、可组合架构。除了物理和渲染，该框架还包括效应器模型、多频率传感器模拟、数据采集流水线和领域随机化工具，统一了大规模强化学习和模仿学习的最佳实践，整合在一个可扩展的平台上。我们强调了其在全身控制、跨体态移动、接触丰富和灵巧操作以及人类示范集成等多样化挑战中的应用。最后，我们讨论了与可微分、GPU加速的Newton物理引擎的即将集成，这为可扩展、数据高效和梯度基的机器人学习方法带来了新的机会。我们认为，Isaac Lab的高级模拟能力、丰富的传感和数据中心规模执行将有助于解锁机器人研究的下一代突破。', 'title_zh': 'Isaac Lab：一种多模态机器人学习的GPU加速模拟框架'}
{'arxiv_id': 'arXiv:2511.04827', 'title': 'Pixi: Unified Software Development and Distribution for Robotics and AI', 'authors': 'Tobias Fischer, Wolf Vollprecht, Bas Zalmstra, Ruben Arts, Tim de Jager, Alejandro Fontan, Adam D Hines, Michael Milford, Silvio Traversaro, Daniel Claes, Scarlett Raine', 'link': 'https://arxiv.org/abs/2511.04827', 'abstract': 'The reproducibility crisis in scientific computing constrains robotics research. Existing studies reveal that up to 70% of robotics algorithms cannot be reproduced by independent teams, while many others fail to reach deployment because creating shareable software environments remains prohibitively complex. These challenges stem from fragmented, multi-language, and hardware-software toolchains that lead to dependency hell. We present Pixi, a unified package-management framework that addresses these issues by capturing exact dependency states in project-level lockfiles, ensuring bit-for-bit reproducibility across platforms. Its high-performance SAT solver achieves up to 10x faster dependency resolution than comparable tools, while integration of the conda-forge and PyPI ecosystems removes the need for multiple managers. Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours to minutes and lowers technical barriers for researchers worldwide. By enabling scalable, reproducible, collaborative research infrastructure, Pixi accelerates progress in robotics and AI.', 'abstract_zh': '科学计算中的可重复性危机限制了机器人研究。现有研究揭示，高达70%的机器人算法无法被独立团队重现，而许多其他算法因创建可共享的软件环境仍极具复杂性而无法部署。这些挑战源自碎片化、多语言及硬件软件工具链导致的依赖地狱。我们提出了Pixi，一个统一的包管理框架，通过在项目级锁定文件中捕获精确的依赖状态，确保跨平台的位精确可重复性。其高性能的SAT求解器相比同类工具可实现10倍以上的依赖解析速度，而集成了conda-forge和PyPI生态系统的功能消除了需要多个管理器的需求。自2023年以来，Pixi已在超过5300个项目中采用，将设置时间从数小时缩短到几分钟，降低了全球研究人员的技术门槛。通过促进可扩展、可重复、协作的研究基础设施，Pixi加速了机器人和人工智能领域的进步。', 'title_zh': 'Pixi: 统一的机器人与人工智能软件开发与分发'}
{'arxiv_id': 'arXiv:2511.04812', 'title': 'Unified Multimodal Diffusion Forcing for Forceful Manipulation', 'authors': 'Zixuan Huang, Huaidian Hou, Dmitry Berenson', 'link': 'https://arxiv.org/abs/2511.04812', 'abstract': 'Given a dataset of expert trajectories, standard imitation learning approaches typically learn a direct mapping from observations (e.g., RGB images) to actions. However, such methods often overlook the rich interplay between different modalities, i.e., sensory inputs, actions, and rewards, which is crucial for modeling robot behavior and understanding task outcomes. In this work, we propose Multimodal Diffusion Forcing, a unified framework for learning from multimodal robot trajectories that extends beyond action generation. Rather than modeling a fixed distribution, MDF applies random partial masking and trains a diffusion model to reconstruct the trajectory. This training objective encourages the model to learn temporal and cross-modal dependencies, such as predicting the effects of actions on force signals or inferring states from partial observations. We evaluate MDF on contact-rich, forceful manipulation tasks in simulated and real-world environments. Our results show that MDF not only delivers versatile functionalities, but also achieves strong performance, and robustness under noisy observations. More visualizations can be found on our website this https URL', 'abstract_zh': '基于专家轨迹的数据集，标准的imitation learning方法通常学习从观察（例如RGB图像）到动作的直接映射。然而，这类方法往往会忽视不同模态之间的丰富交互，即感觉输入、动作和奖励之间的交互，这对于建模机器人行为和理解任务结果至关重要。在本文中，我们提出了一种统一框架——多模态扩散强迫（Multimodal Diffusion Forcing，MDF），该框架超越了单纯的动作生成。MDF 不建模固定分布，而是应用随机的部分遮蔽，并训练一个扩散模型以重构轨迹。这种训练目标促使模型学习时间上的和跨模态的依赖性，例如预测动作对力信号的影响或从部分观察中推断状态。我们在模拟和真实环境下的接触丰富的力控操作任务上评估了MDF。实验结果表明，MDF 不仅能够提供多功能性，还能够实现强大的性能和在嘈杂观察下的鲁棒性。更多可视化内容请参阅我们的网站 <https://www.example.com>。', 'title_zh': '统一多模态扩散驱动力用于强制操作'}
{'arxiv_id': 'arXiv:2511.04769', 'title': 'ReGen: Generative Robot Simulation via Inverse Design', 'authors': 'Phat Nguyen, Tsun-Hsuan Wang, Zhang-Wei Hong, Erfan Aasi, Andrew Silva, Guy Rosman, Sertac Karaman, Daniela Rus', 'link': 'https://arxiv.org/abs/2511.04769', 'abstract': "Simulation plays a key role in scaling robot learning and validating policies, but constructing simulations remains a labor-intensive process. This paper introduces ReGen, a generative simulation framework that automates simulation design via inverse design. Given a robot's behavior -- such as a motion trajectory or an objective function -- and its textual description, ReGen infers plausible scenarios and environments that could have caused the behavior. ReGen leverages large language models to synthesize scenarios by expanding a directed graph that encodes cause-and-effect relationships, relevant entities, and their properties. This structured graph is then translated into a symbolic program, which configures and executes a robot simulation environment. Our framework supports (i) augmenting simulations based on ego-agent behaviors, (ii) controllable, counterfactual scenario generation, (iii) reasoning about agent cognition and mental states, and (iv) reasoning with distinct sensing modalities, such as braking due to faulty GPS signals. We demonstrate ReGen in autonomous driving and robot manipulation tasks, generating more diverse, complex simulated environments compared to existing simulations with high success rates, and enabling controllable generation for corner cases. This approach enhances the validation of robot policies and supports data or simulation augmentation, advancing scalable robot learning for improved generalization and robustness. We provide code and example videos at: this https URL", 'abstract_zh': '再生：通过逆向设计自动化模拟的生成框架', 'title_zh': 'ReGen: 通过逆向设计的生成机器人仿真'}
{'arxiv_id': 'arXiv:2511.04758', 'title': 'ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling', 'authors': 'Caelan Garrett, Fabio Ramos', 'link': 'https://arxiv.org/abs/2511.04758', 'abstract': "Bimanual and humanoid robots are appealing because of their human-like ability to leverage multiple arms to efficiently complete tasks. However, controlling multiple arms at once is computationally challenging due to the growth in the hybrid discrete-continuous action space. Task and Motion Planning (TAMP) algorithms can efficiently plan in hybrid spaces but generally produce plans, where only one arm is moving at a time, rather than schedules that allow for parallel arm motion. In order to extend TAMP to produce schedules, we present ScheduleStream, the first general-purpose framework for planning & scheduling with sampling operations. ScheduleStream models temporal dynamics using hybrid durative actions, which can be started asynchronously and persist for a duration that's a function of their parameters. We propose domain-independent algorithms that solve ScheduleStream problems without any application-specific mechanisms. We apply ScheduleStream to Task and Motion Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers to expedite planning. We compare ScheduleStream algorithms to several ablations in simulation and find that they produce more efficient solutions. We demonstrate ScheduleStream on several real-world bimanual robot tasks at this https URL.", 'abstract_zh': '双臂和类人机器人由于其类似人类利用多个臂高效完成任务的能力而具有吸引力。然而，一次控制多个臂在计算上具有挑战性，因为混合离散-连续动作空间的增长使其变得复杂。任务与运动规划（TAMP）算法可以在混合空间中高效规划，但通常生成的计划只能一次移动一个臂，而不是允许平行臂运动的时间表。为了扩展TAMP以生成时间表，我们提出了ScheduleStream，这是第一个用于规划与调度的通用框架，包含采样操作。ScheduleStream使用混合持续动作建模时间动态，这些动作可以异步启动，并持续一段时间，其持续时间是它们参数的函数。我们提出了通用算法，无需特定应用机制即可解决ScheduleStream问题。我们在任务与运动规划与调度（TAMPAS）中应用ScheduleStream，使用GPU加速采样以加快规划。我们将ScheduleStream算法与几种删除变量进行比较，在仿真中发现它们生成了更高效的方法。我们在以下网址展示了ScheduleStream在多个真实世界双臂机器人任务上的应用：[这里插入链接]。', 'title_zh': 'ScheduleStream: 基于采样的时序规划方法及其在GPU加速多臂任务与运动规划调度中的应用'}
{'arxiv_id': 'arXiv:2511.05396', 'title': 'Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction', 'authors': 'Yiting He, Zhishuai Liu, Weixin Wang, Pan Xu', 'link': 'https://arxiv.org/abs/2511.05396', 'abstract': 'Off-dynamics reinforcement learning (RL), where training and deployment transition dynamics are different, can be formulated as learning in a robust Markov decision process (RMDP) where uncertainties in transition dynamics are imposed. Existing literature mostly assumes access to generative models allowing arbitrary state-action queries or pre-collected datasets with a good state coverage of the deployment environment, bypassing the challenge of exploration. In this work, we study a more realistic and challenging setting where the agent is limited to online interaction with the training environment. To capture the intrinsic difficulty of exploration in online RMDPs, we introduce the supremal visitation ratio, a novel quantity that measures the mismatch between the training dynamics and the deployment dynamics. We show that if this ratio is unbounded, online learning becomes exponentially hard. We propose the first computationally efficient algorithm that achieves sublinear regret in online RMDPs with $f$-divergence based transition uncertainties. We also establish matching regret lower bounds, demonstrating that our algorithm achieves optimal dependence on both the supremal visitation ratio and the number of interaction episodes. Finally, we validate our theoretical results through comprehensive numerical experiments.', 'abstract_zh': '离线动力学的强化学习（RL），其中训练和部署的动力学不同，可以形式化为鲁棒马尔可夫决策过程（RMDP）的学习，其中过渡动力学的不确定性被施加进去。现有文献大多假定可以访问生成模型，允许任意的状态动作查询或预收集的具有良好状态覆盖的部署环境的数据集，从而回避了探索的挑战。在本文中，我们研究了一个更现实且更具挑战性的设置，其中智能体仅限于与训练环境进行在线交互。为了捕获在线RMDP中固有的探索难度，我们引入了 supremal 访问比，这是一种新型量度，用于衡量训练动力学与部署动力学之间的不匹配。我们证明，如果这个比率是无界的，那么在线学习将变得指数级困难。我们提出了第一个在基于$f$散度的过渡不确定性下的在线RMDP中实现亚线性遗憾的高效算法。我们还建立了匹配的遗憾下界，证明了我们的算法在 supremal 访问比和交互回合数上都达到了最优依赖性。最后，我们通过全面的数值实验验证了我们的理论结果。', 'title_zh': '分布鲁棒离动力强化学习的在线交互样本复杂性'}
{'arxiv_id': 'arXiv:2511.05355', 'title': 'SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning', 'authors': 'Tzu-Yuan Huang, Armin Lederer, Dai-Jie Wu, Xiaobing Dai, Sihua Zhang, Stefan Sosnowski, Shao-Hua Sun, Sandra Hirche', 'link': 'https://arxiv.org/abs/2511.05355', 'abstract': 'Flow matching (FM) has shown promising results in data-driven planning. However, it inherently lacks formal guarantees for ensuring state and action constraints, whose satisfaction is a fundamental and crucial requirement for the safety and admissibility of planned trajectories on various systems. Moreover, existing FM planners do not ensure the dynamical consistency, which potentially renders trajectories inexecutable. We address these shortcomings by proposing SAD-Flower, a novel framework for generating Safe, Admissible, and Dynamically consistent trajectories. Our approach relies on an augmentation of the flow with a virtual control input. Thereby, principled guidance can be derived using techniques from nonlinear control theory, providing formal guarantees for state constraints, action constraints, and dynamic consistency. Crucially, SAD-Flower operates without retraining, enabling test-time satisfaction of unseen constraints. Through extensive experiments across several tasks, we demonstrate that SAD-Flower outperforms various generative-model-based baselines in ensuring constraint satisfaction.', 'abstract_zh': '基于流动匹配的Safe、Admissible和动力学一致轨迹生成框架', 'title_zh': 'SAD-Flower: 流匹配实现安全、可接受性和动态一致性规划'}
{'arxiv_id': 'arXiv:2511.05311', 'title': 'Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance', 'authors': 'Valeriu Dimidov, Faisal Hawlader, Sasan Jafarnejad, Raphaël Frank', 'link': 'https://arxiv.org/abs/2511.05311', 'abstract': 'Economic constraints, limited availability of datasets for reproducibility and shortages of specialized expertise have long been recognized as key challenges to the adoption and advancement of predictive maintenance (PdM) in the automotive sector. Recent progress in large language models (LLMs) presents an opportunity to overcome these barriers and speed up the transition of PdM from research to industrial practice. Under these conditions, we explore the potential of LLM-based agents to support PdM cleaning pipelines. Specifically, we focus on maintenance logs, a critical data source for training well-performing machine learning (ML) models, but one often affected by errors such as typos, missing fields, near-duplicate entries, and incorrect dates. We evaluate LLM agents on cleaning tasks involving six distinct types of noise. Our findings show that LLMs are effective at handling generic cleaning tasks and offer a promising foundation for future industrial applications. While domain-specific errors remain challenging, these results highlight the potential for further improvements through specialized training and enhanced agentic capabilities.', 'abstract_zh': '经济限制、数据集可重复使用的短缺以及专门技术的匮乏长期被视为汽车领域预测性维护（PdM）采用和发展的关键挑战。近年来大语言模型（LLMs）的进步为克服这些障碍并加速PdM从研究向工业实践的过渡提供了机遇。在这些条件下，我们探索基于LLM的代理支持PdM清洗管道的潜力。具体而言，我们关注维护日志，这是训练高性能机器学习（ML）模型的关键数据源，但这些日志常常受到拼写错误、缺失字段、近似重复条目和错误日期等错误的影响。我们评估了LLM代理在处理六种不同类型的噪声方面的任务表现。研究结果表明，LLM在处理通用清洗任务方面效果显著，并为未来工业应用提供了前景。虽然领域特定错误仍然具有挑战性，但这些结果突显了通过专门训练和增强代理能力进一步改进的潜力。', 'title_zh': '使用大型语言模型代理清理维护日志以提高预测性维护'}
{'arxiv_id': 'arXiv:2511.05005', 'title': 'Multi-agent Coordination via Flow Matching', 'authors': 'Dongsu Lee, Daehee Lee, Amy Zhang', 'link': 'https://arxiv.org/abs/2511.05005', 'abstract': 'This work presents MAC-Flow, a simple yet expressive framework for multi-agent coordination. We argue that requirements of effective coordination are twofold: (i) a rich representation of the diverse joint behaviors present in offline data and (ii) the ability to act efficiently in real time. However, prior approaches often sacrifice one for the other, i.e., denoising diffusion-based solutions capture complex coordination but are computationally slow, while Gaussian policy-based solutions are fast but brittle in handling multi-agent interaction. MAC-Flow addresses this trade-off by first learning a flow-based representation of joint behaviors, and then distilling it into decentralized one-step policies that preserve coordination while enabling fast execution. Across four different benchmarks, including $12$ environments and $34$ datasets, MAC-Flow alleviates the trade-off between performance and computational cost, specifically achieving about $\\boldsymbol{\\times14.5}$ faster inference compared to diffusion-based MARL methods, while maintaining good performance. At the same time, its inference speed is similar to that of prior Gaussian policy-based offline multi-agent reinforcement learning (MARL) methods.', 'abstract_zh': 'MAC-Flow：一种简单高效的多智能体协调框架', 'title_zh': '基于流匹配的多智能体协调'}
