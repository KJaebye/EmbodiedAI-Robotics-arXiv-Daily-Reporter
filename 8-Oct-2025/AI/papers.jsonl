{'arxiv_id': 'arXiv:2510.06217', 'title': 'TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning', 'authors': 'Jiaru Zou, Soumya Roy, Vinay Kumar Verma, Ziyi Wang, David Wipf, Pan Lu, Sumit Negi, James Zou, Jingrui He', 'link': 'https://arxiv.org/abs/2510.06217', 'abstract': 'Process Reward Models (PRMs) have recently emerged as a powerful framework for enhancing the reasoning capabilities of large reasoning models (LRMs), particularly in the context of test-time scaling (TTS). However, their potential for supervising LRMs on tabular reasoning domains remains underexplored. Through detailed empirical analyses, we identify that existing PRMs, though widely adopted for supervising text-only reasoning steps, struggle with table-specific operations such as sub-table retrieval and schema interaction, leading to critical performance bottlenecks. To address this limitation, we propose TaTToo, a novel table-grounded PRM framework that (i) reasons explicitly over tabular reasoning steps and (ii) integrates tool-based verification to provide precise reward supervision. Concretely, we first design a scalable data curation pipeline that constructs over 60k high-quality step-level annotations by integrating table verification rationales with tool-based executions. Building on the collected data, we train TaTToo with a dual-stage paradigm: cold-start supervised fine-tuning to capture tool-use reasoning patterns, followed by reinforcement learning with tool-grounded reward shaping to align our model with table-based verification. We provide a comprehensive evaluation of the policy improvement induced by our newly designed PRM. Across 5 challenging tabular reasoning benchmarks covering numerical reasoning, fact-checking, and data analysis, TaTToo improves downstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines such as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong generalizability across diverse TTS strategies.', 'abstract_zh': '基于表格的进程奖励模型（TaTToo）：一种新的表驱动框架以增强大型推理模型在表格推理领域的测试时扩展能力', 'title_zh': 'TaTToo: 基于工具的思考PRM测试时缩放方法在表格推理中的应用'}
{'arxiv_id': 'arXiv:2510.06189', 'title': 'Barbarians at the Gate: How AI is Upending Systems Research', 'authors': 'Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Bowen Wang, Alex Krentsel, Tian Xia, Mert Cemri, Jongseok Park, Shuo Yang, Jeff Chen, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica', 'link': 'https://arxiv.org/abs/2510.06189', 'abstract': 'Artificial Intelligence (AI) is starting to transform the research process as we know it by automating the discovery of new solutions. Given a task, the typical AI-driven approach is (i) to generate a set of diverse solutions, and then (ii) to verify these solutions and select one that solves the problem. Crucially, this approach assumes the existence of a reliable verifier, i.e., one that can accurately determine whether a solution solves the given problem. We argue that systems research, long focused on designing and evaluating new performance-oriented algorithms, is particularly well-suited for AI-driven solution discovery. This is because system performance problems naturally admit reliable verifiers: solutions are typically implemented in real systems or simulators, and verification reduces to running these software artifacts against predefined workloads and measuring performance. We term this approach as AI-Driven Research for Systems (ADRS), which iteratively generates, evaluates, and refines solutions. Using penEvolve, an existing open-source ADRS instance, we present case studies across diverse domains, including load balancing for multi-region cloud scheduling, Mixture-of-Experts inference, LLM-based SQL queries, and transaction scheduling. In multiple instances, ADRS discovers algorithms that outperform state-of-the-art human designs (e.g., achieving up to 5.0x runtime improvements or 50% cost reductions). We distill best practices for guiding algorithm evolution, from prompt design to evaluator construction, for existing frameworks. We then discuss the broader implications for the systems community: as AI assumes a central role in algorithm design, we argue that human researchers will increasingly focus on problem formulation and strategic guidance. Our results highlight both the disruptive potential and the urgent need to adapt systems research practices in the age of AI.', 'abstract_zh': '人工智能驱动的系统研究（ADRS）：从发现到验证的迭代过程', 'title_zh': '门外的野蛮人：AI是如何颠覆系统研究的'}
{'arxiv_id': 'arXiv:2510.06135', 'title': 'Pushing Test-Time Scaling Limits of Deep Search with Asymmetric Verification', 'authors': 'Weihao Zeng, Keqing He, Chuqiao Kuang, Xiaoguang Li, Junxian He', 'link': 'https://arxiv.org/abs/2510.06135', 'abstract': "Test-time compute can be scaled both sequentially and in parallel. Sequential scaling involves lengthening the generation process, while parallel scaling involves verifying and selecting among multiple candidate outputs. Combining these two strategies has led to the most powerful AI systems, such as Grok 4 Heavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles), verifying responses can be substantially easier than generating them. This property, referred to as \\emph{asymmetric verification}, highlights the strong potential of test-time scaling (TTS). In this work, we study both sequential and parallel TTS of deep search agents, motivated by the intuition that verification in this setting is often much easier than generation. In experiments, we first show that sequential scaling methods, such as budget forcing, can be effective initially but soon degrade performance. Leveraging asymmetric verification, however, we are able to achieve substantial improvements by allocating only a modest amount of compute to the verifier. We conduct experiments with flagship open-source models and extend them to their ``Heavy'' variants through TTS. These deep research agents achieve gains of up to 27 absolute points on benchmarks such as BrowseComp. Remarkably, as an open-source alternative, GLM-4.5 Heavy reaches accuracy of {\\bf 54.0\\%} on BrowseComp and {\\bf 66.0\\%} on GAIA, placing it comparable to the best proprietary choices such as OpenAI Deep Research. Tongyi-DeepResearch Heavy further achieves {\\bf 69.0\\%} accuracy on BrowseComp, greatly surpassing the best proprietary results.", 'abstract_zh': 'Test-time 计算可以顺序扩展和并行扩展。顺序扩展涉及延长生成过程，而并行扩展涉及验证和选择多个候选输出。结合这两种策略产生了最强大的 AI 系统，如 Grok 4 Heavy 和 GPT-5 Pro。在某些上下文中（例如解决数独谜题），验证响应可以比生成响应容易得多。这种属性称为“异构验证”，突显了测试时间扩展（TTS）的强大潜力。在本文中，我们研究了深度搜索代理的顺序和并行 TTS，受这个设置中验证通常比生成容易得多这一直觉的驱动。在实验中，我们首先展示了顺序扩展方法（如预算强迫）在初期是有效的，但很快会降低性能。然而，利用异构验证，我们仅通过相对较少的计算资源就能显著提高性能。我们在旗舰开源模型上进行实验，并通过 TTS 将它们扩展到“Heavy”变体。这些深度研究代理在基准测试如 BrowseComp 上的增益高达 27 个绝对点。值得注意的是，作为开源替代方案，GLM-4.5 Heavy 在 BrowseComp 上达到 54.0% 的准确率，在 GAIA 上达到 66.0% 的准确率，这与最佳专有选择（如 OpenAI Deep Research）相当。Tongyi-DeepResearch Heavy 进一步在 BrowseComp 上达到 69.0% 的准确率，大幅超越最佳专有结果。', 'title_zh': '用非对称验证推动物理测试时间深度搜索的标量扩展极限'}
{'arxiv_id': 'arXiv:2510.06105', 'title': "Moloch's Bargain: Emergent Misalignment When LLMs Compete for Audiences", 'authors': 'Batu El, James Zou', 'link': 'https://arxiv.org/abs/2510.06105', 'abstract': "Large language models (LLMs) are increasingly shaping how information is created and disseminated, from companies using them to craft persuasive advertisements, to election campaigns optimizing messaging to gain votes, to social media influencers boosting engagement. These settings are inherently competitive, with sellers, candidates, and influencers vying for audience approval, yet it remains poorly understood how competitive feedback loops influence LLM behavior. We show that optimizing LLMs for competitive success can inadvertently drive misalignment. Using simulated environments across these scenarios, we find that, 6.3% increase in sales is accompanied by a 14.0% rise in deceptive marketing; in elections, a 4.9% gain in vote share coincides with 22.3% more disinformation and 12.5% more populist rhetoric; and on social media, a 7.5% engagement boost comes with 188.6% more disinformation and a 16.3% increase in promotion of harmful behaviors. We call this phenomenon Moloch's Bargain for AI--competitive success achieved at the cost of alignment. These misaligned behaviors emerge even when models are explicitly instructed to remain truthful and grounded, revealing the fragility of current alignment safeguards. Our findings highlight how market-driven optimization pressures can systematically erode alignment, creating a race to the bottom, and suggest that safe deployment of AI systems will require stronger governance and carefully designed incentives to prevent competitive dynamics from undermining societal trust.", 'abstract_zh': 'AI中的莫洛赫交易：竞争力成功以对齐为代价', 'title_zh': '摩洛赫的交易：当大语言模型为争夺受众而竞争时出现的 emergent 脱轨'}
{'arxiv_id': 'arXiv:2510.06093', 'title': 'Classical AI vs. LLMs for Decision-Maker Alignment in Health Insurance Choices', 'authors': 'Mallika Mainali, Harsha Sureshbabu, Anik Sen, Christopher B. Rauch, Noah D. Reifsnyder, John Meyer, J. T. Turner, Michael W. Floyd, Matthew Molineaux, Rosina O. Weber', 'link': 'https://arxiv.org/abs/2510.06093', 'abstract': 'As algorithmic decision-makers are increasingly applied to high-stakes domains, AI alignment research has evolved from a focus on universal value alignment to context-specific approaches that account for decision-maker attributes. Prior work on Decision-Maker Alignment (DMA) has explored two primary strategies: (1) classical AI methods integrating case-based reasoning, Bayesian reasoning, and naturalistic decision-making, and (2) large language model (LLM)-based methods leveraging prompt engineering. While both approaches have shown promise in limited domains such as medical triage, their generalizability to novel contexts remains underexplored. In this work, we implement a prior classical AI model and develop an LLM-based algorithmic decision-maker evaluated using a large reasoning model (GPT-5) and a non-reasoning model (GPT-4) with weighted self-consistency under a zero-shot prompting framework, as proposed in recent literature. We evaluate both approaches on a health insurance decision-making dataset annotated for three target decision-makers with varying levels of risk tolerance (0.0, 0.5, 1.0). In the experiments reported herein, classical AI and LLM-based models achieved comparable alignment with attribute-based targets, with classical AI exhibiting slightly better alignment for a moderate risk profile. The dataset and open-source implementation are publicly available at: this https URL and this https URL.', 'abstract_zh': '随着算法决策者在高风险领域中的应用日益增多，AI对齐研究已从普遍价值观对齐转向考虑决策者特性的上下文特定方法。先前的决策者对齐（DMA）研究探讨了两种主要策略：（1）结合案例推理、贝叶斯推理和自然决策制定的经典AI方法，以及（2）利用提示工程的大语言模型（LLM）方法。尽管这两种方法在医疗分诊等有限领域显示出了潜力，但它们在新型上下文中的可泛化性仍需进一步探索。在本研究中，我们实现了一个先前的经典AI模型，并开发了一个基于LLM的算法决策者，该模型使用GPT-5进行推理评估，并使用GPT-4进行非推理评估，两者均采用加权自我一致性方法，在零样本提示框架下进行评估，该框架近期在文献中有所提及。我们在一个包含三种不同风险容忍度目标决策者（0.0，0.5，1.0）标记的健康保险决策数据集上评估了这两种方法。本研究中报告的实验结果显示，经典AI和基于LLM的模型在基于属性的目标上达到了可比较的对齐程度，经典AI在中等风险配置下稍微表现出更好的对齐程度。数据集及其开源实现已公开发布：this https URL 和 this https URL。', 'title_zh': '经典AI与大规模语言模型在健康保险选择中的决策者对齐比较'}
{'arxiv_id': 'arXiv:2510.06078', 'title': 'Constraint-Aware Route Recommendation from Natural Language via Hierarchical LLM Agents', 'authors': 'Tao Zhe, Rui Liu, Fateme Memar, Xiao Luo, Wei Fan, Xinyue Ye, Zhongren Peng, Dongjie Wang', 'link': 'https://arxiv.org/abs/2510.06078', 'abstract': 'Route recommendation aims to provide users with optimal travel plans that satisfy diverse and complex requirements. Classical routing algorithms (e.g., shortest-path and constraint-aware search) are efficient but assume structured inputs and fixed objectives, limiting adaptability to natural-language queries. Recent LLM-based approaches enhance flexibility but struggle with spatial reasoning and the joint modeling of route-level and POI-level preferences. To address these limitations, we propose RouteLLM, a hierarchical multi-agent framework that grounds natural-language intents into constraint-aware routes. It first parses user queries into structured intents including POIs, paths, and constraints. A manager agent then coordinates specialized sub-agents: a constraint agent that resolves and formally check constraints, a POI agent that retrieves and ranks candidate POIs, and a path refinement agent that refines routes via a routing engine with preference-conditioned costs. A final verifier agent ensures constraint satisfaction and produces the final route with an interpretable rationale. This design bridges linguistic flexibility and spatial structure, enabling reasoning over route feasibility and user preferences. Experiments show that our method reliably grounds textual preferences into constraint-aware routes, improving route quality and preference satisfaction over classical methods.', 'abstract_zh': '路由推荐旨在为用户提供满足多样化和复杂需求的最优旅行计划。经典路由算法（如最短路径和约束感知搜索）高效但假设结构化输入和固定目标，限制了对自然语言查询的适应性。基于最新LLM的方法提高了灵活性，但在空间推理和路径级偏好与POI级偏好的联合建模方面存在挑战。为应对这些限制，我们提出了RouteLLM，这是一种分层多智能体框架，将自然语言意图转化为约束感知的路由。它首先将用户查询解析为结构化意图，包括POIs、路径和约束。然后，管理智能体协调专门的子智能体：约束智能体负责解决和形式验证约束，POI智能体负责检索和排名候选POIs，路径细化智能体通过带有偏好条件成本的路由引擎优化路径。最后，验证智能体确保约束满足，并生成具有可解释理由的最终路由。该设计将语言灵活性与空间结构相结合，实现了对路线可行性和用户偏好的推理。实验结果显示，我们的方法能够可靠地将文本偏好转化为约束感知的路由，比经典方法提高了路由质量和偏好满意度。', 'title_zh': '基于层次LLM代理的约束感知自然语言路由推荐'}
{'arxiv_id': 'arXiv:2510.06063', 'title': 'TelecomTS: A Multi-Modal Observability Dataset for Time Series and Language Analysis', 'authors': 'Austin Feng, Andreas Varvarigos, Ioannis Panitsas, Daniela Fernandez, Jinbiao Wei, Yuwei Guo, Jialin Chen, Ali Maatouk, Leandros Tassiulas, Rex Ying', 'link': 'https://arxiv.org/abs/2510.06063', 'abstract': "Modern enterprises generate vast streams of time series metrics when monitoring complex systems, known as observability data. Unlike conventional time series from domains such as weather, observability data are zero-inflated, highly stochastic, and exhibit minimal temporal structure. Despite their importance, observability datasets are underrepresented in public benchmarks due to proprietary restrictions. Existing datasets are often anonymized and normalized, removing scale information and limiting their use for tasks beyond forecasting, such as anomaly detection, root-cause analysis, and multi-modal reasoning. To address this gap, we introduce TelecomTS, a large-scale observability dataset derived from a 5G telecommunications network. TelecomTS features heterogeneous, de-anonymized covariates with explicit scale information and supports a suite of downstream tasks, including anomaly detection, root-cause analysis, and a question-answering benchmark requiring multi-modal reasoning. Benchmarking state-of-the-art time series, language, and reasoning models reveals that existing approaches struggle with the abrupt, noisy, and high-variance dynamics of observability data. Our experiments also underscore the importance of preserving covariates' absolute scale, emphasizing the need for foundation time series models that natively leverage scale information for practical observability applications.", 'abstract_zh': '现代企业监控复杂系统时会产生大量时间序列度量数据，称为可观测性数据。与气象等领域的时间序列数据不同，可观测性数据具有零膨胀、高随机性和极小的时间结构。尽管这些数据非常重要，但由于产权限制，它们在公开基准中的代表性不足。现有的数据集通常被匿名和规范化处理，这去除了规模信息并限制了其在预测之外的任务中的使用，如异常检测、根本原因分析和多模态推理。为解决这一差距，我们引入了 TelecomTS，这是一个源自5G电信网络的大规模可观测性数据集。TelecomTS 包含异构的、未匿名的协变量，并提供了明确的规模信息，支持异常检测、根本原因分析以及需要多模态推理的问答基准任务。对最新时间序列、语言和推理模型的基准测试表明，现有方法难以处理可观测性数据的突变、噪声和高方差动态。我们的实验还强调了保留协变量绝对规模的重要性，突显了需要能够本征利用规模信息的基础时间序列模型，以实现实际的可观测性应用。', 'title_zh': 'TelecomTS：用于时间序列和语言分析的多模态可观测性数据集'}
{'arxiv_id': 'arXiv:2510.06056', 'title': 'Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research', 'authors': 'Gang Liu, Yihan Zhu, Jie Chen, Meng Jiang', 'link': 'https://arxiv.org/abs/2510.06056', 'abstract': 'Large language models hold promise as scientific assistants, yet existing agents either rely solely on algorithm evolution or on deep research in isolation, both of which face critical limitations. Pure algorithm evolution, as in AlphaEvolve, depends only on the internal knowledge of LLMs and quickly plateaus in complex domains, while pure deep research proposes ideas without validation, resulting in unrealistic or unimplementable solutions. We present DeepEvolve, an agent that integrates deep research with algorithm evolution, uniting external knowledge retrieval, cross-file code editing, and systematic debugging under a feedback-driven iterative loop. Each iteration not only proposes new hypotheses but also refines, implements, and tests them, avoiding both shallow improvements and unproductive over-refinements. Across nine benchmarks in chemistry, mathematics, biology, materials, and patents, DeepEvolve consistently improves the initial algorithm, producing executable new algorithms with sustained gains. By bridging the gap between unguided evolution and research without grounding, DeepEvolve provides a reliable framework for advancing scientific algorithm discovery. Our code is available at this https URL.', 'abstract_zh': '大型语言模型作为科学助手具有潜力，但现有代理要么仅依赖算法进化，要么孤立地进行深度研究，两者都面临关键限制。单纯的算法进化，如AlphaEvolve，仅依赖于大语言模型的内部知识，在复杂领域很快陷入停滞，而单纯的深度研究则提出未经验证的想法，导致不切实际或无法实施的解决方案。我们提出DeepEvolve代理，将深度研究与算法进化相结合，在反馈驱动的迭代循环中统一外部知识检索、跨文件代码编辑和系统性调试。每个迭代不仅提出新的假设，还对其精炼、实现和测试，避免了浅显的改进和无成效的过度精炼。DeepEvolve在化学、数学、生物学、材料科学和专利九个基准测试中，始终改进初始算法，生成可执行的新算法，并保持持续进展。通过弥合无指导进化与缺乏接地的研究之间的差距，DeepEvolve为推进科学算法发现提供了可靠的框架。代码可在以下链接获得：this https URL。', 'title_zh': '通过增强AlphaEvolve与深度研究来发现科学算法'}
{'arxiv_id': 'arXiv:2510.06052', 'title': 'MixReasoning: Switching Modes to Think', 'authors': 'Haiquan Lu, Gongfan Fang, Xinyin Ma, Qi Li, Xinchao Wang', 'link': 'https://arxiv.org/abs/2510.06052', 'abstract': 'Reasoning models enhance performance by tackling problems in a step-by-step manner, decomposing them into sub-problems and exploring long chains of thought before producing an answer. However, applying extended reasoning to every step introduces substantial redundancy, as sub-problems vary widely in difficulty and complexity: a small number of pivotal steps are genuinely challenging and decisive for the final answer, while many others only involve straightforward revisions or simple computations. Therefore, a natural idea is to endow reasoning models with the ability to adaptively respond to this variation, rather than treating all steps with the same level of elaboration. To this end, we propose MixReasoning, a framework that dynamically adjusts the depth of reasoning within a single response. The resulting chain of thought then becomes a mixture of detailed reasoning on difficult steps and concise inference on simpler ones. Experiments on GSM8K, MATH-500, and AIME show that MixReasoning shortens reasoning length and substantially improves efficiency without compromising accuracy.', 'abstract_zh': '基于混合推理的逐步解答模型在保持准确性的前提下缩短推理长度并显著提高效率', 'title_zh': 'MixReasoning: 切换模式思考'}
{'arxiv_id': 'arXiv:2510.06036', 'title': 'Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?', 'authors': 'Qingyu Yin, Chak Tou Leong, Linyi Yang, Wenxuan Huang, Wenjie Li, Xiting Wang, Jaehong Yoon, YunXing, XingYu, Jinjin Gu', 'link': 'https://arxiv.org/abs/2510.06036', 'abstract': "Large reasoning models (LRMs) with multi-step reasoning capabilities have shown remarkable problem-solving abilities, yet they exhibit concerning safety vulnerabilities that remain poorly understood. In this work, we investigate why safety alignment fails in reasoning models through a mechanistic interpretability lens. Using a linear probing approach to trace refusal intentions across token positions, we discover a striking phenomenon termed as \\textbf{refusal cliff}: many poorly-aligned reasoning models correctly identify harmful prompts and maintain strong refusal intentions during their thinking process, but experience a sharp drop in refusal scores at the final tokens before output generation. This suggests that these models are not inherently unsafe; rather, their refusal intentions are systematically suppressed. Through causal intervention analysis, we identify a sparse set of attention heads that negatively contribute to refusal behavior. Ablating just 3\\% of these heads can reduce attack success rates below 10\\%. Building on these mechanistic insights, we propose \\textbf{Cliff-as-a-Judge}, a novel data selection method that identifies training examples exhibiting the largest refusal cliff to efficiently repair reasoning models' safety alignment. This approach achieves comparable safety improvements using only 1.7\\% of the vanilla safety training data, demonstrating a less-is-more effect in safety alignment.", 'abstract_zh': '具有多步推理能力的大型推理模型（LRMs）展示了显著的问题解决能力，但它们表现出的安全性漏洞仍然令人担忧且不甚理解。在这项工作中，我们通过机械可解释性视角探究为什么推理模型中的安全对齐会失败。使用线性探测方法追踪 token 位置上的拒绝意图，我们发现了一种引人注目的现象，称为“拒绝悬崖”：许多对齐不佳的推理模型能够正确识别有害提示并在推理过程中保持强烈的拒绝意图，但在生成输出的最后一部分 token 前，拒绝得分会出现急剧下降。这表明这些模型不是从根本上不安全的；相反，它们的拒绝意图被系统性地抑制了。通过因果干预分析，我们识别出一组稀疏的注意力头，它们对拒绝行为有负向贡献。仅消除这些头的 3% 就可以使攻击成功率达到低于 10%。基于这些机械洞察，我们提出了一种新颖的数据选择方法——“拒绝悬崖即法官（Cliff-as-a-Judge）”，该方法能够有效识别表现出最大拒绝悬崖的训练示例，以高效地修复推理模型的安全对齐。此方法仅使用 1.7% 的原始安全训练数据即可实现相似的安全改进，显示出在安全对齐中“少即是多”的效果。', 'title_zh': '拒绝率急剧下降：安全对齐在推理中为何失效？'}
{'arxiv_id': 'arXiv:2510.06014', 'title': 'ARISE: An Adaptive Resolution-Aware Metric for Test-Time Scaling Evaluation in Large Reasoning Models', 'authors': 'Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Zhiyuan Yu, Qipeng Guo, Xuanjing Huang, Xipeng Qiu', 'link': 'https://arxiv.org/abs/2510.06014', 'abstract': 'Test-time scaling has emerged as a transformative paradigm for enhancing the performance of large reasoning models, enabling dynamic allocation of computational resources during inference. However, as the landscape of reasoning models rapidly expands, a critical question remains: how can we systematically compare and evaluate the test-time scaling capabilities across different models? In this paper, we introduce ARISE (Adaptive Resolution-aware Scaling Evaluation), a novel metric specifically designed to assess the test-time scaling effectiveness of large reasoning models. Unlike existing evaluation approaches, ARISE incorporates two key innovations: (1) sample-level awareness that effectively penalizes negative scaling behaviors where increased computation leads to performance degradation, and (2) a dynamic sampling mechanism that mitigates the impact of accuracy fluctuations and token count instability on the final assessment. We conduct comprehensive experiments evaluating state-of-the-art reasoning models across diverse domains including mathematical reasoning, code generation, and agentic tasks. Our results demonstrate that ARISE provides a reliable and fine-grained measurement of test-time scaling capabilities, revealing significant variations in scaling efficiency across models. Notably, our evaluation identifies Claude Opus as exhibiting superior scaling characteristics compared to other contemporary reasoning models.', 'abstract_zh': 'Test-time Scaling评估：一种评估大型推理模型推理时间扩展能力的新指标（ARISE）', 'title_zh': 'ARISE：一种适应性分辨率感知度量，用于大型推理模型测试时缩放评估'}
{'arxiv_id': 'arXiv:2510.06002', 'title': 'Deterministic Legal Retrieval: An Action API for Querying the SAT-Graph RAG', 'authors': 'Hudson de Martim', 'link': 'https://arxiv.org/abs/2510.06002', 'abstract': 'The Structure-Aware Temporal Graph RAG (SAT-Graph RAG) addresses core limitations of standard Retrieval-Augmented Generation in the legal domain by providing a verifiable knowledge graph that models hierarchical structure, temporal evolution, and causal events of legal norms. However, a critical gap remains: how to reliably query this structured knowledge without sacrificing its deterministic properties. This paper introduces the SAT-Graph API, a formal query execution layer centered on canonical actions-atomic, composable, and auditable primitives that isolate probabilistic discovery from deterministic retrieval. These actions enable: (i) high-precision hybrid search; (ii) robust reference resolution; (iii) point-in-time version retrieval; and (iv) auditable causal tracing. We demonstrate how planner-guided agents can decompose complex queries into Directed Acyclic Graphs (DAGs) of these actions. This two-layer architecture transforms retrieval from an opaque black box to a transparent, auditable process, directly addressing Explainable AI (XAI) requirements for high-stakes domains.', 'abstract_zh': '基于结构感知的时间图RAG (SAT-Graph RAG)通过提供一个可验证的知识图，解决了法律领域标准检索增强生成的核心局限性，该图模拟能层结构、时间演化和因果事件。然而，仍存在一个关键缺口：如何可靠地查询这种结构化知识，同时不牺牲其确定性属性。本文引入了SAT-Graph API，这是一种以核心动作（原子的、可组合的、可审计的基本组成部分）为中心的形式化查询执行层，将概率发现与确定性检索隔离。这些动作能实现：(i) 高精度混合搜索；(ii) 稳定的引用解析；(iii) 版本回溯查询；和(iv) 可审计的因果追踪。我们展示了计划者引导的代理如何将复杂查询分解为这些动作的有向无环图(DAGs)。这种两层架构将检索从不透明的黑盒转变为透明和可审计的过程，直接满足了高风险领域可解释人工智能(XAI)的要求。', 'title_zh': '确定性法律检索：查询SAT-Graph RAG的动作API'}
{'arxiv_id': 'arXiv:2510.05996', 'title': 'Information-Theoretic Policy Pre-Training with Empowerment', 'authors': 'Moritz Schneider, Robert Krug, Narunas Vaskevicius, Luigi Palmieri, Michael Volpp, Joschka Boedecker', 'link': 'https://arxiv.org/abs/2510.05996', 'abstract': "Empowerment, an information-theoretic measure of an agent's potential influence on its environment, has emerged as a powerful intrinsic motivation and exploration framework for reinforcement learning (RL). Besides for unsupervised RL and skill learning algorithms, the specific use of empowerment as a pre-training signal has received limited attention in the literature. We show that empowerment can be used as a pre-training signal for data-efficient downstream task adaptation. For this we extend the traditional notion of empowerment by introducing discounted empowerment, which balances the agent's control over the environment across short- and long-term horizons. Leveraging this formulation, we propose a novel pre-training paradigm that initializes policies to maximize discounted empowerment, enabling agents to acquire a robust understanding of environmental dynamics. We analyze empowerment-based pre-training for various existing RL algorithms and empirically demonstrate its potential as a general-purpose initialization strategy: empowerment-maximizing policies with long horizons are data-efficient and effective, leading to improved adaptability in downstream tasks. Our findings pave the way for future research to scale this framework to high-dimensional and complex tasks, further advancing the field of RL.", 'abstract_zh': '基于信息论的代理环境影响潜力衡量方法 empowerment，在强化学习中的内在动机和探索框架中崭露头角。尽管 empowerment 在无监督强化学习和技能学习算法中得到了应用，但在文献中将其作为预训练信号的具体应用研究较少。我们展示了 empowerment 可以用作数据高效下游任务适应的预训练信号。为此，我们通过引入折扣 empowerment 扩展了传统 empowerment 概念，以平衡代理在短期和长期环境控制上的潜力。基于这一表述，我们提出了一种新颖的预训练范式，初始化策略以最大化折扣 empowerment，使代理能够获得对环境动力学的坚实理解。我们分析了基于 empowerment 的预训练在现有强化学习算法中的应用，并实证展示了其作为通用初始化策略的潜力：具有长视野的 empowerment 最大化策略在数据效率和有效性方面表现出色，从而提高了下游任务的适应性。我们的发现为未来研究如何扩展此框架到高维度和复杂任务奠定了基础，进一步推动了强化学习领域的进步。', 'title_zh': '基于信息论的 empowerment 先训练策略'}
{'arxiv_id': 'arXiv:2510.05962', 'title': 'MatheMagic: Generating Dynamic Mathematics Benchmarks Robust to Memorization', 'authors': "Dayyán O'Brien, Barry Haddow, Emily Allaway, Pinzhen Chen", 'link': 'https://arxiv.org/abs/2510.05962', 'abstract': 'Conducting contamination-free evaluation of mathematical capabilities can be difficult for two reasons: models may memorize a test set once it is made public, and current mathematical benchmarks are prone to overfitting due to having limited diversity of symbols and rules, coupled with closed-ended answers. This paper proposes a method to leverage these shortcomings as useful features to a construct dynamic, counterfactual benchmark, which can be used to both reveal overfitting and measure true reasoning. We demonstrate this via MatheMagic, which generates math test instances with the interpretations of numbers and operators altered, yet has automatically verifiable answers. Test instances are randomly seeded and constructed at test time to evaluate a model\'s induction or deduction capability, offering stability, extensibility, comparability, and robustness to overfitting. Our experiments find that models solve deduction more easily than induction, but they revert to standard math. Further analysis reveals that math-adapted models fail to exhibit a general "skill" of reasoning, and fine-tuning on induction tasks generalizes poorly.', 'abstract_zh': '无污染评估数学能力存在两个挑战：模型可能会记住公开的测试集，且当前的数学基准由于符号和规则多样性有限且答案封闭，容易过拟合。本文提出了一种方法，利用这些缺陷作为有用特征来构建动态的反事实基准，既可以揭示过拟合，又可以衡量真实的推理能力。我们通过MatheMagic演示了这一点，MatheMagic生成的数学测试实例改变了数字和运算符的解释，但具有自动验证的答案。测试实例在测试时随机生成，用于评估模型的归纳或演绎能力，提供稳定性和扩展性，并对过拟合具有鲁棒性。我们的实验发现，模型更容易解决演绎问题，但会回到标准数学问题。进一步分析表明，适应数学的模型未能表现出一般的“推理”技能，且在演绎任务上的微调泛化能力较差。', 'title_zh': 'MatheMagic: 生成对抗记忆的动态数学基准'}
{'arxiv_id': 'arXiv:2510.05950', 'title': 'Training-Free Time Series Classification via In-Context Reasoning with LLM Agents', 'authors': 'Songyuan Sui, Zihang Xu, Yu-Neng Chuang, Kwei-Herng Lai, Xia Hu', 'link': 'https://arxiv.org/abs/2510.05950', 'abstract': 'Time series classification (TSC) spans diverse application scenarios, yet labeled data are often scarce, making task-specific training costly and inflexible. Recent reasoning-oriented large language models (LLMs) show promise in understanding temporal patterns, but purely zero-shot usage remains suboptimal. We propose FETA, a multi-agent framework for training-free TSC via exemplar-based in-context reasoning. FETA decomposes a multivariate series into channel-wise subproblems, retrieves a few structurally similar labeled examples for each channel, and leverages a reasoning LLM to compare the query against these exemplars, producing channel-level labels with self-assessed confidences; a confidence-weighted aggregator then fuses all channel decisions. This design eliminates the need for pretraining or fine-tuning, improves efficiency by pruning irrelevant channels and controlling input length, and enhances interpretability through exemplar grounding and confidence estimation. On nine challenging UEA datasets, FETA achieves strong accuracy under a fully training-free setting, surpassing multiple trained baselines. These results demonstrate that a multi-agent in-context reasoning framework can transform LLMs into competitive, plug-and-play TSC solvers without any parameter training. The code is available at this https URL.', 'abstract_zh': '基于示例驱动的上下文推理多代理框架FETA实现无监督时间序列分类', 'title_zh': '无需训练的时间序列分类通过LLM代理的上下文推理'}
{'arxiv_id': 'arXiv:2510.05909', 'title': 'Optimizing for Persuasion Improves LLM Generalization: Evidence from Quality-Diversity Evolution of Debate Strategies', 'authors': 'Aksel Joonas Reedi, Corentin Léger, Julien Pourcel, Loris Gaven, Perrine Charriau, Guillaume Pourcel', 'link': 'https://arxiv.org/abs/2510.05909', 'abstract': "Large Language Models (LLMs) optimized to output truthful answers often overfit, producing brittle reasoning that fails to generalize. While persuasion-based optimization has shown promise in debate settings, it has not been systematically compared against mainstream truth-based approaches. We introduce DebateQD, a minimal Quality-Diversity (QD) evolutionary algorithm that evolves diverse debate strategies across different categories (rationality, authority, emotional appeal, etc.) through tournament-style competitions where two LLMs debate while a third judges. Unlike previously proposed methods that require a population of LLMs, our approach maintains diversity of opponents through prompt-based strategies within a single LLM architecture, making it more accessible for experiments while preserving the key benefits of population-based optimization. In contrast to prior work, we explicitly isolate the role of the optimization objective by fixing the debate protocol and swapping only the fitness function: persuasion rewards strategies that convince the judge irrespective of truth, whereas truth rewards collaborative correctness. Across three model scales (7B, 32B, 72B parameters) and multiple dataset sizes from the QuALITY benchmark, persuasion-optimized strategies achieve up to 13.94% smaller train-test generalization gaps, while matching or exceeding truth optimization's test performance. These results provide the first controlled evidence that competitive pressure to persuade, rather than seek the truth collaboratively, fosters more transferable reasoning skills, offering a promising path for improving LLM generalization.", 'abstract_zh': '大型语言模型（LLMs）经过优化以输出真实答案往往会过拟合，产生脆弱的推理，难以泛化。尽管基于说服的优化在辩论环境下显示出潜力，但尚未系统性地与主流的真实导向方法进行比较。我们引入了DebateQD，这是一种最小化的质量-多样性（QD）进化算法，通过锦标赛式竞争，在不同的类别（理性、权威、情感诉求等）中进化不同的辩论策略。与之前需要一批LLM的方法不同，我们的方法通过单一LLM架构中的提示策略来维持对手的多样性，使其更易于实验同时保留基于群体优化的 key 优点。与先前的工作相比，我们明确隔离了优化目标的作用：通过固定辩论协议并仅交换适应度函数，说服奖励能够说服裁判的策略，而不论其是否符合事实；真实则奖励合作的正确性。在三个模型规模（7B、32B、72B参数）和_QUALITY_基准的多种数据集大小上，说服优化的策略在训练-测试泛化差距上最多可缩小13.94%，同时匹配或超越真实优化的测试性能。这些结果提供了首次受控证据，表明为了说服而不是合作寻求事实的竞争压力，促进了更为可迁移的推理技能的发展，为提高LLM泛化能力提供了有希望的道路。', 'title_zh': '优化说服策略提高大语言模型泛化能力：来自辩论策略质量-多样性进化的证据'}
{'arxiv_id': 'arXiv:2510.05871', 'title': 'Towards Label-Free Biological Reasoning Synthetic Dataset Creation via Uncertainty Filtering', 'authors': 'Josefa Lia Stoisser, Lawrence Phillips, Aditya Misra, Tom A. Lamb, Philip Torr, Marc Boubnovski Martell, Julien Fauqueur, Kaspar Märtens', 'link': 'https://arxiv.org/abs/2510.05871', 'abstract': "Synthetic chain-of-thought (CoT) traces are widely used to train large reasoning models (LRMs), improving generalization by providing step-level supervision. Yet most approaches require ground-truth labels to seed or filter these traces - an expensive bottleneck in domains like biology where wet-lab data are scarce. We propose a label-free alternative: uncertainty-based filtering, which uses a model's own confidence - quantified through established uncertainty metrics like self-consistency and predictive perplexity - as a substitute for external labels. We sample multiple reasoning traces and retain only low-uncertainty subsets. Applied to biological perturbation prediction, a domain where wet-lab labels are especially costly, we show that the filtered subset has higher accuracy, and that supervised fine-tuning (SFT) on uncertainty-filtered data outperforms unfiltered synthetic data, narrows the gap to ground-truth training, and surpasses strong LRM baselines. Ablations show that per-class filtering corrects for class-specific uncertainty scales and that hybrid uncertainty metrics yield higher-quality datasets. Our results suggest that model-internal confidence is a powerful signal for efficient reasoning dataset creation, enabling LRMs in domains where supervision is expensive.", 'abstract_zh': '基于不确定性过滤的无标签合成链式思考跟踪用于大型推理模型的训练', 'title_zh': '基于不确定性过滤的无标签生物推理合成数据集创建'}
{'arxiv_id': 'arXiv:2510.05865', 'title': 'The Safety Challenge of World Models for Embodied AI Agents: A Review', 'authors': 'Lorenzo Baraldi, Zifan Zeng, Chongzhe Zhang, Aradhana Nayak, Hongbo Zhu, Feng Liu, Qunli Zhang, Peng Wang, Shiming Liu, Zheng Hu, Angelo Cangelosi, Lorenzo Baraldi', 'link': 'https://arxiv.org/abs/2510.05865', 'abstract': "The rapid progress in embodied artificial intelligence has highlighted the necessity for more advanced and integrated models that can perceive, interpret, and predict environmental dynamics. In this context, World Models (WMs) have been introduced to provide embodied agents with the abilities to anticipate future environmental states and fill in knowledge gaps, thereby enhancing agents' ability to plan and execute actions. However, when dealing with embodied agents it is fundamental to ensure that predictions are safe for both the agent and the environment. In this article, we conduct a comprehensive literature review of World Models in the domains of autonomous driving and robotics, with a specific focus on the safety implications of scene and control generation tasks. Our review is complemented by an empirical analysis, wherein we collect and examine predictions from state-of-the-art models, identify and categorize common faults (herein referred to as pathologies), and provide a quantitative evaluation of the results.", 'abstract_zh': '快速发展的具身人工智能突显了需要更加先进和集成的模型以感知、解释和预测环境动态的必要性。在这种背景下，世界模型（WMs）被引入以赋予具身代理预测未来环境状态和填补知识空白的能力，从而增强代理计划和执行动作的能力。然而，在处理具身代理时，确保预测对代理和环境都是安全的至关重要。本文对自主驾驶和机器人领域的世界模型进行了全面的文献综述，特别关注场景和控制生成任务的安全影响。我们的综述通过实证分析予以补充，其中我们收集并分析了最先进的模型的预测，识别并分类常见的病态现象（ herein referred to as pathologies），并提供了结果的定量评估。', 'title_zh': '具身AI代理的世界模型安全挑战：一项综述'}
{'arxiv_id': 'arXiv:2510.05774', 'title': 'ConstraintLLM: A Neuro-Symbolic Framework for Industrial-Level Constraint Programming', 'authors': 'Weichun Shi, Minghao Liu, Wanting Zhang, Langchen Shi, Fuqi Jia, Feifei Ma, Jian Zhang', 'link': 'https://arxiv.org/abs/2510.05774', 'abstract': 'Constraint programming (CP) is a crucial technology for solving real-world constraint optimization problems (COPs), with the advantages of rich modeling semantics and high solving efficiency. Using large language models (LLMs) to generate formal modeling automatically for COPs is becoming a promising approach, which aims to build trustworthy neuro-symbolic AI with the help of symbolic solvers. However, CP has received less attention compared to works based on operations research (OR) models. We introduce ConstraintLLM, the first LLM specifically designed for CP modeling, which is trained on an open-source LLM with multi-instruction supervised fine-tuning. We propose the Constraint-Aware Retrieval Module (CARM) to increase the in-context learning capabilities, which is integrated in a Tree-of-Thoughts (ToT) framework with guided self-correction mechanism. Moreover, we construct and release IndusCP, the first industrial-level benchmark for CP modeling, which contains 140 challenging tasks from various domains. Our experiments demonstrate that ConstraintLLM achieves state-of-the-art solving accuracy across multiple benchmarks and outperforms the baselines by 2x on the new IndusCP benchmark. Code and data are available at: this https URL.', 'abstract_zh': '基于约束编程的大型语言模型ConstraintLLM：面向实际约束优化问题的自动建模', 'title_zh': 'ConstraintLLM：一种工业级约束编程的神经符号框架'}
{'arxiv_id': 'arXiv:2510.05764', 'title': 'RareAgent: Self-Evolving Reasoning for Drug Repurposing in Rare Diseases', 'authors': 'Lang Qin, Zijian Gan, Xu Cao, Pengcheng Jiang, Yankai Jiang, Jiawei Han, Kaishun Wu, Jintai Chen', 'link': 'https://arxiv.org/abs/2510.05764', 'abstract': 'Computational drug repurposing for rare diseases is especially challenging when no prior associations exist between drugs and target diseases. Therefore, knowledge graph completion and message-passing GNNs have little reliable signal to learn and propagate, resulting in poor performance. We present RareAgent, a self-evolving multi-agent system that reframes this task from passive pattern recognition to active evidence-seeking reasoning. RareAgent organizes task-specific adversarial debates in which agents dynamically construct evidence graphs from diverse perspectives to support, refute, or entail hypotheses. The reasoning strategies are analyzed post hoc in a self-evolutionary loop, producing textual feedback that refines agent policies, while successful reasoning paths are distilled into transferable heuristics to accelerate future investigations. Comprehensive evaluations reveal that RareAgent improves the indication AUPRC by 18.1% over reasoning baselines and provides a transparent reasoning chain consistent with clinical evidence.', 'abstract_zh': '罕见疾病药物再利用的计算方法在缺乏药物与目标疾病先前关联的情况下尤其具有挑战性。因此，知识图谱补全和消息传递GNNs几乎没有可靠信号可学习和传播，导致性能不佳。我们提出RareAgent，这是一种自演化的多Agent系统，将任务重新框架为积极的证据寻求推理，而非被动的模式识别。RareAgent组织了特定任务的对抗性辩论，在这些辩论中，Agent从多种视角动态构建证据图来支持、反驳或蕴含假设。推理策略在自演化的循环中进行事后分析，产生文本反馈以细化Agent策略，同时成功的推理路径被提炼为可迁移的启发式规则，以加速未来的调查。全面的评估显示，与推理基线相比，RareAgent将症状的AUPRC提高了18.1%，并且提供了与临床证据一致的透明推理链。', 'title_zh': 'RareAgent：自演化推理在罕见疾病药物再利用中的应用'}
{'arxiv_id': 'arXiv:2510.05761', 'title': 'Early Multimodal Prediction of Cross-Lingual Meme Virality on Reddit: A Time-Window Analysis', 'authors': 'Sedat Dogan, Nina Dethlefs, Debarati Chakraborty', 'link': 'https://arxiv.org/abs/2510.05761', 'abstract': 'Predicting the virality of online content remains challenging, especially for culturally complex, fast-evolving memes. This study investigates the feasibility of early prediction of meme virality using a large-scale, cross-lingual dataset from 25 diverse Reddit communities. We propose a robust, data-driven method to define virality based on a hybrid engagement score, learning a percentile-based threshold from a chronologically held-out training set to prevent data leakage. We evaluated a suite of models, including Logistic Regression, XGBoost, and a Multi-layer Perceptron (MLP), with a comprehensive, multimodal feature set across increasing time windows (30-420 min). Crucially, useful signals emerge quickly: our best-performing model, XGBoost, achieves a PR-AUC $>$ 0.52 in just 30 minutes. Our analysis reveals a clear "evidentiary transition," in which the importance of the feature dynamically shifts from the static context to the temporal dynamics as a meme gains traction. This work establishes a robust, interpretable, and practical benchmark for early virality prediction in scenarios where full diffusion cascade data is unavailable, contributing a novel cross-lingual dataset and a methodologically sound definition of virality. To our knowledge, this study is the first to combine time series data with static content and network features to predict early meme virality.', 'abstract_zh': '预测在线内容的病毒性仍然具有挑战性，尤其是在对于文化复杂且快速演变的 meme。本研究探讨了使用来自 25 个多元 Reddit 社区的大规模跨语言数据集进行 meme 病毒性早期预测的可能性。我们提出了一种基于混合参与度评分的稳健数据驱动方法来定义病毒性，并通过时间上划分的训练集学习分位数阈值以防止数据泄露。我们评估了一系列模型，包括逻辑回归、XGBoost 和多层感知机（MLP），并使用跨时间段的综合多模态特征集（30-420 分钟）。 crucially, 有益信号迅速出现：我们的最佳模型 XGBoost 在 30 分钟内就能实现 PR-AUC > 0.52。我们的分析揭示了一个明确的“证据过渡”，特征的重要性随 meme 获得牵引力而动态变化，从静态上下文转向时间动态。本工作为在缺乏完整扩散级联数据场景下的早期病毒性预测建立了稳健、可解释且实用的基准，贡献了一个新颖的跨语言数据集和方法论上严谨的病毒性定义。据我们所知，这是首次将时间序列数据与静态内容和网络特征结合以预测 early meme 病毒性。', 'title_zh': 'Reddit 上跨语言 meme 病毒性的早期多模态预测：一个时间窗口分析'}
{'arxiv_id': 'arXiv:2510.05751', 'title': 'Uncertainty assessment in satellite-based greenhouse gas emissions estimates using emulated atmospheric transport', 'authors': 'Jeffrey N. Clark, Elena Fillola, Nawid Keshtmand, Raul Santos-Rodriguez, Matthew Rigby', 'link': 'https://arxiv.org/abs/2510.05751', 'abstract': 'Monitoring greenhouse gas emissions and evaluating national inventories require efficient, scalable, and reliable inference methods. Top-down approaches, combined with recent advances in satellite observations, provide new opportunities to evaluate emissions at continental and global scales. However, transport models used in these methods remain a key source of uncertainty: they are computationally expensive to run at scale, and their uncertainty is difficult to characterise. Artificial intelligence offers a dual opportunity to accelerate transport simulations and to quantify their associated uncertainty.\nWe present an ensemble-based pipeline for estimating atmospheric transport "footprints", greenhouse gas mole fraction measurements, and their uncertainties using a graph neural network emulator of a Lagrangian Particle Dispersion Model (LPDM). The approach is demonstrated with GOSAT (Greenhouse Gases Observing Satellite) observations for Brazil in 2016. The emulator achieved a ~1000x speed-up over the NAME LPDM, while reproducing large-scale footprint structures. Ensembles were calculated to quantify absolute and relative uncertainty, revealing spatial correlations with prediction error. The results show that ensemble spread highlights low-confidence spatial and temporal predictions for both atmospheric transport footprints and methane mole fractions.\nWhile demonstrated here for an LPDM emulator, the approach could be applied more generally to atmospheric transport models, supporting uncertainty-aware greenhouse gas inversion systems and improving the robustness of satellite-based emissions monitoring. With further development, ensemble-based emulators could also help explore systematic LPDM errors, offering a computationally efficient pathway towards a more comprehensive uncertainty budget in greenhouse gas flux estimates.', 'abstract_zh': '基于图神经网络的集合方法用于估计大气传输“足迹”、温室气体摩尔分数测量及其不确定性', 'title_zh': '基于模拟大气传输的卫星观测温室气体排放估算不确定性评估'}
{'arxiv_id': 'arXiv:2510.05746', 'title': 'ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent Systems', 'authors': 'Bohan Yao, Shiva Krishna Reddy Malay, Vikas Yadav', 'link': 'https://arxiv.org/abs/2510.05746', 'abstract': 'Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved state-of-the-art results on various complex reasoning tasks. Recent works have proposed techniques to automate the design of MASes, eliminating the need for manual engineering. However, these techniques perform poorly, often achieving similar or inferior performance to simple baselines. Furthermore, they require computationally expensive re-discovery of architectures for each new task domain and expensive data annotation on domains without existing labeled validation sets. A critical insight is that simple Chain of Thought (CoT) reasoning often performs competitively with these complex systems, suggesting that the fundamental reasoning unit of MASes, CoT, warrants further investigation. To this end, we present a new paradigm for automatic MAS design that pivots the focus to optimizing CoT reasoning. We introduce the Agentic Reasoning Module (ARM), an agentic generalization of CoT where each granular reasoning step is executed by a specialized reasoning module. This module is discovered through a tree search over the code space, starting from a simple CoT module and evolved using mutations informed by reflection on execution traces. The resulting ARM acts as a versatile reasoning building block which can be utilized as a direct recursive loop or as a subroutine in a learned meta-orchestrator. Our approach significantly outperforms both manually designed MASes and state-of-the-art automatic MAS design methods. Crucially, MASes built with ARM exhibit superb generalization, maintaining high performance across different foundation models and task domains without further optimization.', 'abstract_zh': '基于大规模语言模型（LLM）的多智能体系统（MAS）在各种复杂推理任务上实现了最先进的成果。近期工作提出了一种自动设计MAS的技术，消除了手动工程的需求。然而，这些技术表现不佳，经常达到或低于简单基线的性能。此外，它们需要为每个新的任务领域重新发现架构，并对没有现有标注验证集的领域进行昂贵的数据标注。一个关键的洞察是，简单的一步步推理（CoT）通常能与这些复杂系统竞争，这表明MAS的核心推理单元CoT值得进一步研究。为此，我们提出了一种自动设计MAS的新范式，将焦点转向优化CoT推理。我们介绍了智能推理模块（ARM），这是一种针对CoT的智能泛化，其中每个精细的推理步骤由专门的推理模块执行。该模块通过从一个简单的CoT模块开始进行代码空间上的树搜索，并通过执行跟踪上的反思指导的变异进行进化来发现。结果生成的ARM作为多功能推理构建块，可以作为直接递归循环使用，也可以作为学习元调度器中的子程序。我们的方法在人工设计的MAS和最先进的自动设计MAS方法上表现显著更好。关键的是，使用ARM构建的MAS表现出色，能够在不同基础模型和任务领域中保持高性能，无需进一步优化。', 'title_zh': 'ARM：发现可迁移的多代理系统自主 reasoning 模块'}
{'arxiv_id': 'arXiv:2510.05743', 'title': 'Artificially intelligent agents in the social and behavioral sciences: A history and outlook', 'authors': 'Petter Holme, Milena Tsvetkova', 'link': 'https://arxiv.org/abs/2510.05743', 'abstract': "We review the historical development and current trends of artificially intelligent agents (agentic AI) in the social and behavioral sciences: from the first programmable computers, and social simulations soon thereafter, to today's experiments with large language models. This overview emphasizes the role of AI in the scientific process and the changes brought about, both through technological advancements and the broader evolution of science from around 1950 to the present. Some of the specific points we cover include: the challenges of presenting the first social simulation studies to a world unaware of computers, the rise of social systems science, intelligent game theoretic agents, the age of big data and the epistemic upheaval in its wake, and the current enthusiasm around applications of generative AI, and many other topics. A pervasive theme is how deeply entwined we are with the technologies we use to understand ourselves.", 'abstract_zh': '我们回顾了人工智能代理（代理AI）在社会和行为科学中的历史发展和当前趋势：从早期可编程计算机及其随后的社会模拟，到今天的大语言模型实验。本文综述强调了AI在科学研究过程中的作用以及技术进步和从1950年代至今更广泛科学演变带来的变化。具体内容包括：首个社会模拟研究向未接触计算机的世界介绍所面临的挑战、社会系统科学的发展、智能博弈论代理、大数据时代及其带来的知识革命，以及当前对生成AI应用的热情等众多议题。贯穿始终的主题是，我们所使用的理解自身的技术与我们的关联有多么紧密。', 'title_zh': '社会与行为科学中的人工智能代理：历史与展望'}
{'arxiv_id': 'arXiv:2510.05733', 'title': 'Syn-Diag: An LLM-based Synergistic Framework for Generalizable Few-shot Fault Diagnosis on the Edge', 'authors': 'Zijun Jia, Shuang Liang, Jinsong Yu', 'link': 'https://arxiv.org/abs/2510.05733', 'abstract': "Industrial fault diagnosis faces the dual challenges of data scarcity and the difficulty of deploying large AI models in resource-constrained environments. This paper introduces Syn-Diag, a novel cloud-edge synergistic framework that leverages Large Language Models to overcome these limitations in few-shot fault diagnosis. Syn-Diag is built on a three-tiered mechanism: 1) Visual-Semantic Synergy, which aligns signal features with the LLM's semantic space through cross-modal pre-training; 2) Content-Aware Reasoning, which dynamically constructs contextual prompts to enhance diagnostic accuracy with limited samples; and 3) Cloud-Edge Synergy, which uses knowledge distillation to create a lightweight, efficient edge model capable of online updates via a shared decision space. Extensive experiments on six datasets covering different CWRU and SEU working conditions show that Syn-Diag significantly outperforms existing methods, especially in 1-shot and cross-condition scenarios. The edge model achieves performance comparable to the cloud version while reducing model size by 83% and latency by 50%, offering a practical, robust, and deployable paradigm for modern intelligent diagnostics.", 'abstract_zh': '工业故障诊断面临数据稀缺性和在资源受限环境中部署大规模AI模型的双重挑战。本文介绍了一种新颖的云边协同框架Syn-Diag，该框架利用大型语言模型在少量样本的故障诊断中克服这些限制。Syn-Diag基于三层机制：1）跨模态语义协同，通过跨模态预训练将信号特征与LLM的语义空间对齐；2）内容感知推理，动态构建上下文提示以在样本有限的情况下提高诊断准确性；3）云边协同，利用知识蒸馏创建轻量级、高效的边缘模型，并通过共享决策空间进行在线更新。在涵盖CWRU和SEU不同工作条件的六个数据集上进行的广泛实验表明，Syn-Diag在1-shot和跨条件场景中显著优于现有方法。边缘模型在模型大小减少83%和延迟减少50%的情况下实现了与云版本相当的性能，提供了一种实用、可靠且易于部署的现代智能诊断范式。', 'title_zh': 'Syn-Diag: 一个基于LLM的边缘端泛化少样本故障诊断协同框架'}
{'arxiv_id': 'arXiv:2510.05698', 'title': 'Joint Communication Scheduling and Velocity Control for Multi-UAV-Assisted Post-Disaster Monitoring: An Attention-Based In-Context Learning Approach', 'authors': 'Yousef Emami, Seyedsina Nabavirazavi, Jingjing Zheng, Hao Zhou, Miguel Gutierrez Gaitan, Kai Li, Luis Almeida', 'link': 'https://arxiv.org/abs/2510.05698', 'abstract': 'Recently, Unmanned Aerial Vehicles (UAVs) are increasingly being investigated to collect sensory data in post-disaster monitoring scenarios, such as tsunamis, where early actions are critical to limit coastal damage. A major challenge is to design the data collection schedules and flight velocities, as unfavorable schedules and velocities can lead to transmission errors and buffer overflows of the ground sensors, ultimately resulting in significant packet loss. Meanwhile, online Deep Reinforcement Learning (DRL) solutions have a complex training process and a mismatch between simulation and reality that does not meet the urgent requirements of tsunami monitoring. Recent advances in Large Language Models (LLMs) offer a compelling alternative. With their strong reasoning and generalization capabilities, LLMs can adapt to new tasks through In-Context Learning (ICL), which enables task adaptation through natural language prompts and example-based guidance without retraining. However, LLM models have input data limitations and thus require customized approaches. In this paper, a joint optimization of data collection schedules and velocities control for multiple UAVs is proposed to minimize data loss. The battery level of the ground sensors, the length of the queues, and the channel conditions, as well as the trajectories of the UAVs, are taken into account. Attention-Based In-Context Learning for Velocity Control and Data Collection Schedule (AIC-VDS) is proposed as an alternative to DRL in emergencies. The simulation results show that the proposed AIC-VDS outperforms both the Deep-Q-Network (DQN) and maximum channel gain baselines.', 'abstract_zh': '基于注意力增强上下文学习的多 UAV 数据收集调度与速度控制优化（AIC-VDS）', 'title_zh': '基于注意力机制的上下文学习方法：多无人机辅助灾后监测的联合通信调度与速度控制'}
{'arxiv_id': 'arXiv:2510.05684', 'title': 'D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI', 'authors': 'Suwhan Choi, Jaeyoon Jung, Haebin Seong, Minchan Kim, Minyeong Kim, Yongjun Cho, Yoonshik Kim, Yubeen Park, Youngjae Yu, Yunsung Lee', 'link': 'https://arxiv.org/abs/2510.05684', 'abstract': 'Large language models leverage internet-scale text data, yet embodied AI remains constrained by the prohibitive costs of physical trajectory collection. Desktop environments -- particularly gaming -- offer a compelling alternative: they provide rich sensorimotor interactions at scale while maintaining the structured observation-action coupling essential for embodied learning. We present D2E (Desktop to Embodied AI), a framework that demonstrates desktop interactions can serve as an effective pretraining substrate for robotics embodied AI tasks. Unlike prior work that remained domain-specific (e.g., VPT for Minecraft) or kept data proprietary (e.g., SIMA), D2E establishes a complete pipeline from scalable desktop data collection to verified transfer in embodied domains. Our framework comprises three components: (1) the OWA Toolkit that unifies diverse desktop interactions into a standardized format with 152x compression, (2) the Generalist-IDM that achieves strong zero-shot generalization across unseen games through timestamp-based event prediction, enabling internet-scale pseudo-labeling, and (3) VAPT that transfers desktop-pretrained representations to physical manipulation and navigation. Using 1.3K+ hours of data (259 hours of human demonstrations, and 1K+ hours of pseudo-labeled gameplay), we achieve a total of 96.6% success rate on LIBERO manipulation and 83.3% on CANVAS navigation benchmarks. This validates that sensorimotor primitives in digital interactions exhibit sufficient invariance to transfer meaningfully to physical embodied tasks, establishing desktop pretraining as a practical paradigm for robotics. We will make all our work public, including the OWA toolkit, datasets of human-collected and pseudo-labeled, and VAPT-trained models available at this https URL', 'abstract_zh': '桌面到具身AI：基于桌面环境的具身人工智能预训练框架', 'title_zh': 'D2E: 在桌面数据上扩展视觉-动作预训练以转移至具身AI'}
{'arxiv_id': 'arXiv:2510.05664', 'title': 'Large Language Model-Based Uncertainty-Adjusted Label Extraction for Artificial Intelligence Model Development in Upper Extremity Radiography', 'authors': 'Hanna Kreutzer, Anne-Sophie Caselitz, Thomas Dratsch, Daniel Pinto dos Santos, Christiane Kuhl, Daniel Truhn, Sven Nebelung', 'link': 'https://arxiv.org/abs/2510.05664', 'abstract': 'Objectives: To evaluate GPT-4o\'s ability to extract diagnostic labels (with uncertainty) from free-text radiology reports and to test how these labels affect multi-label image classification of musculoskeletal radiographs. Methods: This retrospective study included radiography series of the clavicle (n=1,170), elbow (n=3,755), and thumb (n=1,978). After anonymization, GPT-4o filled out structured templates by indicating imaging findings as present ("true"), absent ("false"), or "uncertain." To assess the impact of label uncertainty, "uncertain" labels of the training and validation sets were automatically reassigned to "true" (inclusive) or "false" (exclusive). Label-image-pairs were used for multi-label classification using ResNet50. Label extraction accuracy was manually verified on internal (clavicle: n=233, elbow: n=745, thumb: n=393) and external test sets (n=300 for each). Performance was assessed using macro-averaged receiver operating characteristic (ROC) area under the curve (AUC), precision recall curves, sensitivity, specificity, and accuracy. AUCs were compared with the DeLong test. Results: Automatic extraction was correct in 98.6% (60,618 of 61,488) of labels in the test sets. Across anatomic regions, label-based model training yielded competitive performance measured by macro-averaged AUC values for inclusive (e.g., elbow: AUC=0.80 [range, 0.62-0.87]) and exclusive models (elbow: AUC=0.80 [range, 0.61-0.88]). Models generalized well on external datasets (elbow [inclusive]: AUC=0.79 [range, 0.61-0.87]; elbow [exclusive]: AUC=0.79 [range, 0.63-0.89]). No significant differences were observed across labeling strategies or datasets (p>=0.15). Conclusion: GPT-4o extracted labels from radiologic reports to train competitive multi-label classification models with high accuracy. Detected uncertainty in the radiologic reports did not influence the performance of these models.', 'abstract_zh': '对象目标：评估GPT-4o从自由文本放射学报告中提取具有不确定性诊断标签的能力，并测试这些标签如何影响肌骨X线图像的多标签分类。方法：本回顾性研究包括锁骨(n=1,170)、肘部(n=3,755)和拇指(n=1,978)的放射学系列。在匿名化后，GPT-4o通过标记成像发现为“存在”、“不存在”或“不确定”来填写结构化模板。为了评估标签不确定性的影响，“不确定”标签在训练集和验证集中的自动重新分配为“包含”为“真”或“排除”为“假”。使用ResNet50对标签-图像对进行多标签分类。通过手动验证内部（锁骨：n=233，肘部：n=745，拇指：n=393）和外部测试集（每个300）的标签提取准确性。使用宏平均接收操作特征（ROC）曲线下面积（AUC）、精确召回曲线、灵敏度、特异性和准确性评估性能。使用DeLong检验比较AUCs。结果：测试集中的标签自动提取正确率为98.6%（60,618/61,488）。在不同解剖区域，基于标签的模型训练在包含模型（例如，肘部：AUC=0.80[范围，0.62-0.87]）和排除模型（肘部：AUC=0.80[范围，0.61-0.88]）中表现出竞争性的性能。模型在外部数据集上泛化良好（肘部[包含]：AUC=0.79[范围，0.61-0.87]；肘部[排除]：AUC=0.79[范围，0.63-0.89]）。未观察到标签标注策略或数据集之间的显著差异（p≥0.15）。结论：GPT-4o从放射学报告中提取标签，训练出具有高准确性且竞争性的多标签分类模型。放射学报告中检测到的不确定性未影响这些模型的性能。', 'title_zh': '基于大型语言模型的不确定性调整标签提取在上肢放射成像人工智能模型开发中的应用'}
{'arxiv_id': 'arXiv:2510.05596', 'title': 'From Agentification to Self-Evolving Agentic AI for Wireless Networks: Concepts, Approaches, and Future Research Directions', 'authors': 'Changyuan Zhao, Ruichen Zhang, Jiacheng Wang, Dusit Niyato, Geng Sun, Xianbin Wang, Shiwen Mao, Abbas Jamalipour', 'link': 'https://arxiv.org/abs/2510.05596', 'abstract': 'Self-evolving agentic artificial intelligence (AI) offers a new paradigm for future wireless systems by enabling autonomous agents to continually adapt and improve without human intervention. Unlike static AI models, self-evolving agents embed an autonomous evolution cycle that updates models, tools, and workflows in response to environmental dynamics. This paper presents a comprehensive overview of self-evolving agentic AI, highlighting its layered architecture, life cycle, and key techniques, including tool intelligence, workflow optimization, self-reflection, and evolutionary learning. We further propose a multi-agent cooperative self-evolving agentic AI framework, where multiple large language models (LLMs) are assigned role-specialized prompts under the coordination of a supervisor agent. Through structured dialogue, iterative feedback, and systematic validation, the system autonomously executes the entire life cycle without human intervention. A case study on antenna evolution in low-altitude wireless networks (LAWNs) demonstrates how the framework autonomously upgrades fixed antenna optimization into movable antenna optimization. Experimental results show that the proposed self-evolving agentic AI autonomously improves beam gain and restores degraded performance by up to 52.02%, consistently surpassing the fixed baseline with little to no human intervention and validating its adaptability and robustness for next-generation wireless intelligence.', 'abstract_zh': '自主演变代理人工智能：未来无线系统的新型范式及其在低高度无线网络天线优化中的自主升级应用', 'title_zh': '从代理化到自主进化的能动AI无线网络：概念、方法及未来研究方向'}
{'arxiv_id': 'arXiv:2510.05592', 'title': 'In-the-Flow Agentic System Optimization for Effective Planning and Tool Use', 'authors': 'Zhuofeng Li, Haoxiang Zhang, Seungju Han, Sheng Liu, Jianwen Xie, Yu Zhang, Yejin Choi, James Zou, Pan Lu', 'link': 'https://arxiv.org/abs/2510.05592', 'abstract': 'Outcome-driven reinforcement learning has advanced reasoning in large language models (LLMs), but prevailing tool-augmented approaches train a single, monolithic policy that interleaves thoughts and tool calls under full context; this scales poorly with long horizons and diverse tools and generalizes weakly to new scenarios. Agentic systems offer a promising alternative by decomposing work across specialized modules, yet most remain training-free or rely on offline training decoupled from the live dynamics of multi-turn interaction. We introduce AgentFlow, a trainable, in-the-flow agentic framework that coordinates four modules (planner, executor, verifier, generator) through an evolving memory and directly optimizes its planner inside the multi-turn loop. To train on-policy in live environments, we propose Flow-based Group Refined Policy Optimization (Flow-GRPO), which tackles long-horizon, sparse-reward credit assignment by converting multi-turn optimization into a sequence of tractable single-turn policy updates. It broadcasts a single, verifiable trajectory-level outcome to every turn to align local planner decisions with global success and stabilizes learning with group-normalized advantages. Across ten benchmarks, AgentFlow with a 7B-scale backbone outperforms top-performing baselines with average accuracy gains of 14.9% on search, 14.0% on agentic, 14.5% on mathematical, and 4.1% on scientific tasks, even surpassing larger proprietary models like GPT-4o. Further analyses confirm the benefits of in-the-flow optimization, showing improved planning, enhanced tool-calling reliability, and positive scaling with model size and reasoning turns.', 'abstract_zh': '基于结果的强化学习在大型语言模型中推进了推理能力，但占据主导地位的工具增强方法训练单一的、综合性策略，该策略在完整上下文中交错思维和工具调用；这在长周期和多种工具面前扩展性差，并且在新情境中泛化能力较弱。代理系统通过分解工作到专门模块中提供了有希望的替代方案，但大多数仍不需训练或依赖于与多轮交互的实时动态脱钩的离线训练。我们介绍了AgentFlow，这是一种可训练、在流程中的代理框架，通过不断演变的记忆协调四个模块（规划器、执行器、验证器、生成器），并在多轮循环内直接优化其规划器。为实时环境中的在政策训练，我们提出了基于流的分组精细策略优化（Flow-GRPO），通过将多轮优化转换为一系列可处理的单轮策略更新来解决长周期和稀疏奖励的信用分配问题。它将单个可验证的轨迹级结果广播到每次交互，使局部规划器决策与全局成功对齐，并通过分组标准化优势稳定学习。在十个基准测试中，AgentFlow使用7B规模的骨干网络在搜索、代理、数学和科学任务上的平均准确率分别提高了14.9%、14.0%、14.5%和4.1%，甚至超越了如GPT-4o等更大规模的 proprietary 模型。进一步的分析证实了流程中优化的好处，显示了改进的规划、增强的工具调用可靠性以及随模型大小和推理轮数的正向扩展。', 'title_zh': '流动中的代理系统优化以实现有效的规划与工具使用'}
{'arxiv_id': 'arXiv:2510.05580', 'title': 'MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption', 'authors': 'Chen Li, Zhantao Yang, Han Zhang, Fangyi Chen, Chenchen Zhu, Anudeepsekhar Bolimera, Marios Savvides', 'link': 'https://arxiv.org/abs/2510.05580', 'abstract': 'Vision-Language-Action (VLA) models show promise in embodied reasoning, yet remain far from true generalists-they often require task-specific fine-tuning, and generalize poorly to unseen tasks. We propose MetaVLA, a unified, backbone-agnostic post-training framework for efficient and scalable alignment. MetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse target tasks into a single fine-tuning stage while leveraging structurally diverse auxiliary tasks to improve in-domain generalization. Unlike naive multi-task SFT, MetaVLA integrates a lightweight meta-learning mechanism-derived from Attentive Neural Processes-to enable rapid adaptation from diverse contexts with minimal architectural change or inference overhead. On the LIBERO benchmark, MetaVLA with six auxiliary tasks outperforms OpenVLA by up to 8.0% on long-horizon tasks, reduces training steps from 240K to 75K, and cuts GPU time by ~76%. These results show that scalable, low-resource post-training is achievable-paving the way toward general-purpose embodied agents. Code will be available.', 'abstract_zh': 'MetaVLA：一种统一的后训练框架，实现高效可扩展的元视角视觉-语言-行动模型对齐', 'title_zh': '元多任务协同训练：统一的元协同训练方法以实现高效的感知适应'}
{'arxiv_id': 'arXiv:2510.05548', 'title': 'Decade-long Emission Forecasting with an Ensemble Model in Taiwan', 'authors': 'Gordon Hung, Salinna Abdullah', 'link': 'https://arxiv.org/abs/2510.05548', 'abstract': "Taiwan's high population and heavy dependence on fossil fuels have led to severe air pollution, with the most prevalent greenhouse gas being carbon dioxide (CO2). There-fore, this study presents a reproducible and comprehensive case study comparing 21 of the most commonly employed time series models in forecasting emissions, analyzing both univariate and multivariate approaches. Among these, Feedforward Neural Network (FFNN), Support Vector Machine (SVM), and Random Forest Regressor (RFR) achieved the best performances. To further enhance robustness, the top performers were integrated with Linear Regression through a custom stacked generalization en-semble technique. Our proposed ensemble model achieved an SMAPE of 1.407 with no signs of overfitting. Finally, this research provides an accurate decade-long emission projection that will assist policymakers in making more data-driven decisions.", 'abstract_zh': '台湾高人口和对化石燃料的重度依赖导致严重空气污染，其中最主要的温室气体是二氧化碳（CO2）。因此，本研究呈现了一个可复制且全面的时间序列模型案例研究，比较了21种最常用的排放预测模型，并分析了一元和多元方法。在这之中，前向神经网络（FFNN）、支持向量机（SVM）和随机森林回归器（RFR）表现出最优性能。为进一步增强稳健性，最优模型通过自定义的层级泛化ensemble技术与线性回归相结合。我们提出ensemble模型实现了1.407的SMAPE且无过拟合迹象。最后，本研究提供了一个准确的十年排放预测，将帮助决策者做出更数据驱动的决策。', 'title_zh': '台湾地区基于集成模型的十年排放预测'}
{'arxiv_id': 'arXiv:2510.05480', 'title': 'Vul-R2: A Reasoning LLM for Automated Vulnerability Repair', 'authors': 'Xin-Cheng Wen, Zirui Lin, Yijun Yang, Cuiyun Gao, Deheng Ye', 'link': 'https://arxiv.org/abs/2510.05480', 'abstract': 'The exponential increase in software vulnerabilities has created an urgent need for automatic vulnerability repair (AVR) solutions. Recent research has formulated AVR as a sequence generation problem and has leveraged large language models (LLMs) to address this problem. Typically, these approaches prompt or fine-tune LLMs to generate repairs for vulnerabilities directly. Although these methods show state-of-the-art performance, they face the following challenges: (1) Lack of high-quality, vulnerability-related reasoning data. Current approaches primarily rely on foundation models that mainly encode general programming knowledge. Without vulnerability-related reasoning data, they tend to fail to capture the diverse vulnerability repair patterns. (2) Hard to verify the intermediate vulnerability repair process during LLM training. Existing reinforcement learning methods often leverage intermediate execution feedback from the environment (e.g., sandbox-based execution results) to guide reinforcement learning training. In contrast, the vulnerability repair process generally lacks such intermediate, verifiable feedback, which poses additional challenges for model training.', 'abstract_zh': '软件漏洞的指数级增加迫切需要自动漏洞修复（AVR）解决方案。近期研究将AVR问题形式化为序列生成问题，并利用大规模语言模型（LLMs）解决这一问题。通常，这些方法通过提示或微调LLMs来直接生成漏洞修复代码。尽管这些方法展现了最先进的性能，但也面临以下挑战：（1）缺乏高质量的、与漏洞相关的推理数据。当前的方法主要依赖基础模型，主要编码一般编程知识，而缺乏与漏洞相关的推理数据，这使得它们难以捕捉到多样化的漏洞修复模式。（2）在LLMs训练过程中难以验证中间的漏洞修复过程。现有的强化学习方法通常利用环境中的中间执行反馈（如沙箱执行结果）来引导强化学习训练。相比之下，漏洞修复过程通常缺乏此类中间可验证的反馈，这为模型训练带来了额外的挑战。', 'title_zh': 'Vul-R2: 一个用于自动化漏洞修复的推理大语言模型'}
{'arxiv_id': 'arXiv:2510.05465', 'title': 'VAL-Bench: Measuring Value Alignment in Language Models', 'authors': "Aman Gupta, Denny O'Shea, Fazl Barez", 'link': 'https://arxiv.org/abs/2510.05465', 'abstract': "Large language models (LLMs) are increasingly used for tasks where outputs shape human decisions, so it is critical to test whether their responses reflect consistent human values. Existing benchmarks mostly track refusals or predefined safety violations, but these only check rule compliance and do not reveal whether a model upholds a coherent value system when facing controversial real-world issues. We introduce the \\textbf{V}alue \\textbf{AL}ignment \\textbf{Bench}mark (\\textbf{VAL-Bench}), which evaluates whether models maintain a stable value stance across paired prompts that frame opposing sides of public debates. VAL-Bench consists of 115K such pairs from Wikipedia's controversial sections. A well-aligned model should express similar underlying views regardless of framing, which we measure using an LLM-as-judge to score agreement or divergence between paired responses. Applied across leading open- and closed-source models, the benchmark reveals large variation in alignment and highlights trade-offs between safety strategies (e.g., refusals) and more expressive value systems. By providing a scalable, reproducible benchmark, VAL-Bench enables systematic comparison of how reliably LLMs embody human values.", 'abstract_zh': '价值对齐基准（VAL-Bench）', 'title_zh': 'VAL-Bench: 测量语言模型的价值对齐程度'}
{'arxiv_id': 'arXiv:2510.05457', 'title': 'Do Code Models Suffer from the Dunning-Kruger Effect?', 'authors': 'Mukul Singh, Somya Chatterjee, Arjun Radhakrishna, Sumit Gulwani', 'link': 'https://arxiv.org/abs/2510.05457', 'abstract': 'As artificial intelligence systems increasingly collaborate with humans in creative and technical domains, questions arise about the cognitive boundaries and biases that shape our shared agency. This paper investigates the Dunning-Kruger Effect (DKE), the tendency for those with limited competence to overestimate their abilities in state-of-the-art LLMs in coding tasks. By analyzing model confidence and performance across a diverse set of programming languages, we reveal that AI models mirror human patterns of overconfidence, especially in unfamiliar or low-resource domains. Our experiments demonstrate that less competent models and those operating in rare programming languages exhibit stronger DKE-like bias, suggesting that the strength of the bias is proportionate to the competence of the models.', 'abstract_zh': '随着人工智能系统在创意和技术领域 increasingly 合作与人类互动，关于塑造我们共同行动的认知边界和偏见的问题应运而生。本文探讨了表现不佳知觉偏差（Dunning-Kruger Effect，DKE），即在最先进的LLM编程任务中，能力有限者过度估计自己能力的趋势。通过分析模型在多种编程语言下的置信度和表现，我们发现AI模型在不熟悉或低资源领域中表现出类似人类过度自信的模式。我们的实验表明，能力较弱的模型以及在稀有编程语言中运作的模型显示出更强的DKE类似偏见，这表明偏见的程度与模型的能力成比例。', 'title_zh': '代码模型是否会遭受邓宁-克鲁格效应的影响？'}
{'arxiv_id': 'arXiv:2510.05451', 'title': 'NASP-T: A Fuzzy Neuro-Symbolic Transformer for Logic-Constrained Aviation Safety Report Classification', 'authors': 'Fadi Al Machot, Fidaa Al Machot', 'link': 'https://arxiv.org/abs/2510.05451', 'abstract': 'Deep transformer models excel at multi-label text classification but often violate domain logic that experts consider essential, an issue of particular concern in safety-critical applications. We propose a hybrid neuro-symbolic framework that integrates Answer Set Programming (ASP) with transformer-based learning on the Aviation Safety Reporting System (ASRS) corpus. Domain knowledge is formalized as weighted ASP rules and validated using the Clingo solver. These rules are incorporated in two complementary ways: (i) as rule-based data augmentation, generating logically consistent synthetic samples that improve label diversity and coverage; and (ii) as a fuzzy-logic regularizer, enforcing rule satisfaction in a differentiable form during fine-tuning. This design preserves the interpretability of symbolic reasoning while leveraging the scalability of deep neural architectures. We further tune per-class thresholds and report both standard classification metrics and logic-consistency rates. Compared to a strong Binary Cross-Entropy (BCE) baseline, our approach improves micro- and macro-F1 scores and achieves up to an 86% reduction in rule violations on the ASRS test set. To the best of our knowledge, this constitutes the first large-scale neuro-symbolic application to ASRS reports that unifies ASP-based reasoning, rule-driven augmentation, and differentiable transformer training for trustworthy, safety-critical NLP.', 'abstract_zh': '深度变压器模型在多标签文本分类中表现出色，但往往违反专家认为至关重要的领域逻辑，在安全关键应用中尤其令人关注。我们提出了一种将Answer Set Programming (ASP)与基于变压器的学习结合起来的混合神经符号框架，应用于航空安全报告系统（ASRS）语料库。领域知识被形式化为加权ASP规则，并使用Clingo求解器进行验证。这些规则以两种互补的方式融入其中：（i）作为基于规则的数据增强，生成逻辑上一致的合成样本，提高标签的多样性和覆盖率；（ii）作为模糊逻辑正则化器，在微调过程中确保规则的满足。该设计保留了符号推理的可解释性，同时利用了深度神经架构的可扩展性。我们进一步调整了每类阈值，并报告了标准分类指标和逻辑一致性率。与强大的二元交叉熵（BCE）baseline相比，我们的方法在微宏F1分数上取得了改进，并在ASRS测试集上实现了高达86%的规则违反减少。据我们所知，这构成了第一个将ASP基于推理、规则驱动的增强和可微分变压器训练统一起来的大规模神经符号在ASRS报告中的应用，旨在为可信的安全关键NLP提供支持。', 'title_zh': 'NASP-T：一种用于逻辑约束航空安全报告分类的模糊神经-象征变换器'}
{'arxiv_id': 'arXiv:2510.05432', 'title': 'AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems', 'authors': 'Shambhavi Mishra, Gaurav Sahu, Marco Pedersoli, Laurent Charlin, Jose Dolz, Christopher Pal', 'link': 'https://arxiv.org/abs/2510.05432', 'abstract': 'Large language models (LLMs) demonstrate impressive capabilities across a wide range of tasks, yet it remains unclear whether such success reflects genuine reasoning or sophisticated recall. We introduce AInstein, a framework for testing whether LLMs can generate valid solutions to AI research problems using only their pretrained parametric knowledge -- without domain-specific fine-tuning, retrieval augmentation, or other external aids. Our approach extracts distilled problem statements from high-quality ICLR 2025 submissions, then tasks specialized solver agents with proposing and refining technical solutions through iterative critique loops, mimicking the cycles of proposal, review, and revision central to scientific inquiry. We evaluate AInstein on 1,214 ICLR papers stratified by acceptance tier (Oral, Spotlight, Poster), using an LLM-as-a-judge paradigm guided by a structured rubric, complemented by targeted manual checks. Performance is assessed with three metrics: Success Rate (does the solution address the problem?), Rediscovery (does it align with human-proposed methods?), and Novelty (does it yield valid, original approaches?). Our results reveal that while LLMs can rediscover feasible solutions and occasionally propose creative alternatives, their problem-solving ability remains fragile and highly sensitive to framing. These findings provide the first large-scale evidence on the extent to which LLMs can act as autonomous scientific problem-solvers, highlighting both their latent potential and their current limitations.', 'abstract_zh': 'Large Language Models (LLMs)在广泛任务中的表现令人印象深刻，但其成功是否反映真正的推理能力或复杂的检索能力仍不清楚。我们提出了AInstein框架，用于测试LLMs是否仅通过其预训练参数知识就能生成解决AI研究问题的有效方案——无需领域特定的微调、检索增强或其他外部辅助。我们的方法从高质量的ICLR 2025投稿中提取精炼的问题陈述，然后通过迭代批判循环，由专门的求解代理提出并完善技术解决方案，模仿提案、审查和修订的科学探究循环。我们利用按接受级别分层的1,214篇ICLR论文（口头报告、亮点展示、海报展示），采用LLM作为评判者的方式，并辅以结构化评估标准和有针对性的手动检查进行评估。性能评估采用了三个指标：成功率（方案是否解决了问题？）、再发现（它是否与人类提出的方案一致？）和新颖性（它是否提供了有效且原创的方法？）我们的结果显示，虽然LLMs能够再发现可行的解决方案，并偶尔提出创意的替代方案，但它们的问题解决能力仍然脆弱且高度依赖问题的表述。这些发现提供了迄今为止最大的证据，表明LLMs作为自主科学研究问题解决者的潜力和局限性。', 'title_zh': 'AInstein: 评估AI生成方法解决研究问题的可行性'}
{'arxiv_id': 'arXiv:2510.05402', 'title': 'Teacher-Student Guided Inverse Modeling for Steel Final Hardness Estimation', 'authors': 'Ahmad Alsheikh, Andreas Fischer', 'link': 'https://arxiv.org/abs/2510.05402', 'abstract': 'Predicting the final hardness of steel after heat treatment is a challenging regression task due to the many-to-one nature of the process -- different combinations of input parameters (such as temperature, duration, and chemical composition) can result in the same hardness value. This ambiguity makes the inverse problem, estimating input parameters from a desired hardness, particularly difficult. In this work, we propose a novel solution using a Teacher-Student learning framework. First, a forward model (Teacher) is trained to predict final hardness from 13 metallurgical input features. Then, a backward model (Student) is trained to infer plausible input configurations from a target hardness value. The Student is optimized by leveraging feedback from the Teacher in an iterative, supervised loop. We evaluate our method on a publicly available tempered steel dataset and compare it against baseline regression and reinforcement learning models. Results show that our Teacher-Student framework not only achieves higher inverse prediction accuracy but also requires significantly less computational time, demonstrating its effectiveness and efficiency for inverse process modeling in materials science.', 'abstract_zh': '预测经过热处理后的钢材最终硬度是一项具有挑战性的回归任务，原因是该过程具有多对一的性质——不同的输入参数（如温度、持续时间和化学成分）组合可以导致相同的硬度值。这种不确定性使得从目标硬度估计输入参数的逆问题尤为困难。在此项工作中，我们提出了一种新颖的解决方案，采用teacher-student学习框架。首先，一个前向模型（teacher）被训练以预测从13个冶金输入特征到最终硬度。然后，一个后向模型（student）被训练以从目标硬度值推断出可能的输入配置。student通过利用teacher的反馈在迭代的监督循环中进行优化。我们使用一个公开的回火钢材数据集评估了该方法，并将其与基线回归和强化学习模型进行了对比。结果显示，我们的teacher-student框架不仅实现了更高的逆向预测精度，而且所需计算时间 significantly less，表明其在材料科学中逆过程建模的有效性和效率。', 'title_zh': '教师-学生引导的逆向建模研究：钢材最终硬度估计'}
{'arxiv_id': 'arXiv:2510.05378', 'title': 'What Do You Mean? Exploring How Humans and AI Interact with Symbols and Meanings in Their Interactions', 'authors': 'Reza Habibi, Seung Wan Ha, Zhiyu Lin, Atieh Kashani, Ala Shafia, Lakshana Lakshmanarajan, Chia-Fang Chung, Magy Seif El-Nasr', 'link': 'https://arxiv.org/abs/2510.05378', 'abstract': 'Meaningful human-AI collaboration requires more than processing language, it demands a better understanding of symbols and their constructed meanings. While humans naturally interpret symbols through social interaction, AI systems treat them as patterns with compressed meanings, missing the dynamic meanings that emerge through conversation. Drawing on symbolic interactionism theory, we conducted two studies (N=37) investigated how humans and AI interact with symbols and co-construct their meanings. When AI introduced conflicting meanings and symbols in social contexts, 63% of participants reshaped their definitions. This suggests that conflicts in symbols and meanings prompt reflection and redefinition, allowing both participants and AI to have a better shared understanding of meanings and symbols. This work reveals that shared understanding emerges not from agreement but from the reciprocal exchange and reinterpretation of symbols, suggesting new paradigms for human-AI interaction design.', 'abstract_zh': '有意义的人机协作需要超越语言处理，要求对符号及其构建的意义有更深入的理解。基于符号互动主义理论，我们进行了两项研究（N=37），探讨了人类与AI如何互动并共同构建符号的意义。当AI在社会情境中引入矛盾的含义和符号时，63%的参与者重新定义了它们。这表明，符号和意义的冲突促使反思和重新定义，使参与者和AI能更好地共享理解这些符号和意义。这项工作揭示了共享理解并非来自一致意见，而是来自符号的相互交换和重新诠释，这提出了人机交互设计的新范式。', 'title_zh': '你指的是什么？探究人类与AI在交互中如何处理符号和意义。'}
{'arxiv_id': 'arXiv:2510.05363', 'title': 'MHA-RAG: Improving Efficiency, Accuracy, and Consistency by Encoding Exemplars as Soft Prompts', 'authors': 'Abhinav Jain, Xinyu Yao, Thomas Reps, Christopher Jermaine', 'link': 'https://arxiv.org/abs/2510.05363', 'abstract': 'Adapting Foundation Models to new domains with limited training data is challenging and computationally expensive. While prior work has demonstrated the effectiveness of using domain-specific exemplars as in-context demonstrations, we investigate whether representing exemplars purely as text is the most efficient, effective, and stable approach. We explore an alternative: representing exemplars as soft prompts with an exemplar order invariant model architecture. To this end, we introduce Multi-Head Attention Retrieval-Augmented Generation (MHA-RAG), a framework with the number of attention heads serving as a simple hyperparameter to control soft prompt-generation across different tasks. Across multiple question-answering benchmarks and model scales, MHA-RAG achieves a 20-point performance gain over standard RAG, while cutting inference costs by a factor of 10X GFLOPs-delivering both higher accuracy and greater efficiency, invariant to exemplar order.', 'abstract_zh': '使用有限训练数据适应新的领域基础模型具有挑战性和高昂的计算成本。虽然先前的工作已经证明了使用领域特定示例作为上下文演示的有效性，但我们探究了是否纯粹以文本形式表示示例是在不同任务中最具效率、最有效和最稳定的approach。我们探索了另一种方法：使用不变于示例顺序的模型架构表示示例为软提示。为此，我们提出了多头注意检索增强生成（MHA-RAG）框架，其中多头注意的数量作为简单的超参数来控制不同任务中的软提示生成。在多个问答基准和模型规模上，MHA-RAG 在标准 RAG 上实现了 20 点的性能提升，同时将推理成本降低了 10 倍 GFLOPs，实现了更高的准确性和更高的效率，与示例顺序无关。', 'title_zh': 'MHA-RAG：通过将范例编码为软提示以提高效率、准确性和一致性'}
{'arxiv_id': 'arXiv:2510.05338', 'title': 'Integrating Bayesian methods with neural network--based model predictive control: a review', 'authors': 'Asli Karacelik', 'link': 'https://arxiv.org/abs/2510.05338', 'abstract': 'In this review, we assess the use of Bayesian methods in model predictive control (MPC), focusing on neural-network-based modeling, control design, and uncertainty quantification. We systematically analyze individual studies and how they are implemented in practice. While Bayesian approaches are increasingly adopted to capture and propagate uncertainty in MPC, reported gains in performance and robustness remain fragmented, with inconsistent baselines and limited reliability analyses. We therefore argue for standardized benchmarks, ablation studies, and transparent reporting to rigorously determine the effectiveness of Bayesian techniques for MPC.', 'abstract_zh': '本文综述了贝叶斯方法在模型预测控制(MPC)中的应用，重点关注基于神经网络的建模、控制设计和不确定性量化。系统分析了相关研究及其实际实施情况。尽管贝叶斯方法越来越被用于捕捉和传播MPC中的不确定性，但在性能和鲁棒性方面的报告收益仍然支离破碎，缺乏一致的基线和可靠性分析。因此，我们提倡标准化基准、消融研究和透明报告，以严格确定贝叶斯技术在MPC中的有效性。', 'title_zh': '基于神经网络的模型预测控制中集成贝叶斯方法：一个综述'}
{'arxiv_id': 'arXiv:2510.05335', 'title': 'Biomedical reasoning in action: Multi-agent System for Auditable Biomedical Evidence Synthesis', 'authors': 'Oskar Wysocki, Magdalena Wysocka, Mauricio Jacobo, Harriet Unsworth, André Freitas', 'link': 'https://arxiv.org/abs/2510.05335', 'abstract': "We present M-Reason, a demonstration system for transparent, agent-based reasoning and evidence integration in the biomedical domain, with a focus on cancer research. M-Reason leverages recent advances in large language models (LLMs) and modular agent orchestration to automate evidence retrieval, appraisal, and synthesis across diverse biomedical data sources. Each agent specializes in a specific evidence stream, enabling parallel processing and fine-grained analysis. The system emphasizes explainability, structured reporting, and user auditability, providing complete traceability from source evidence to final conclusions. We discuss critical tradeoffs between agent specialization, system complexity, and resource usage, as well as the integration of deterministic code for validation. An open, interactive user interface allows researchers to directly observe, explore and evaluate the multi-agent workflow. Our evaluation demonstrates substantial gains in efficiency and output consistency, highlighting M-Reason's potential as both a practical tool for evidence synthesis and a testbed for robust multi-agent LLM systems in scientific research, available at this https URL.", 'abstract_zh': '我们呈现了M-Reason，这是一个在生物医学领域，特别是癌症研究中，实现透明代理驱动推理和证据整合的演示系统。M-Reason 利用大型语言模型（LLMs）和模块化代理orchestration的最新进展，自动化跨多种生物医学数据源的证据检索、评估和合成。每个代理专注于特定的证据流，实现并行处理和精细分析。该系统强调可解释性、结构化报告和用户审计，提供从原始证据到最终结论的完整可追踪性。我们讨论了代理专业化、系统复杂性和资源使用之间的关键权衡，以及确定性代码的集成以进行验证。一个开放的交互式用户界面使研究人员可以直接观察、探索和评估多代理工作流。我们的评估显示了效率和输出一致性方面的显著提升，突显了M-Reason作为证据合成实用工具和科学研发中稳健的多代理LLM系统试验平台的潜力，详情请见此网址。', 'title_zh': 'biomedical推理在行动：可审计生物医学证据合成的多智能体系统'}
{'arxiv_id': 'arXiv:2510.05318', 'title': 'BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions', 'authors': 'Nan Huo, Xiaohan Xu, Jinyang Li, Per Jacobsson, Shipei Lin, Bowen Qin, Binyuan Hui, Xiaolong Li, Ge Qu, Shuzheng Si, Linheng Han, Edward Alexander, Xintong Zhu, Rui Qin, Ruihan Yu, Yiyao Jin, Feige Zhou, Weihao Zhong, Yun Chen, Hongyu Liu, Chenhao Ma, Fatma Ozcan, Yannis Papakonstantinou, Reynold Cheng', 'link': 'https://arxiv.org/abs/2510.05318', 'abstract': "Large language models (LLMs) have demonstrated remarkable performance on single-turn text-to-SQL tasks, but real-world database applications predominantly require multi-turn interactions to handle ambiguous queries, execution errors, and evolving user requirements. Existing multi-turn benchmarks fall short by treating conversation histories as static context or limiting evaluation to read-only operations, failing to reflect production-grade database assistant challenges. We introduce BIRD-INTERACT, a benchmark that restores this realism through: (1) a comprehensive interaction environment coupling each database with a hierarchical knowledge base, metadata files, and a function-driven user simulator, enabling models to solicit clarifications, retrieve knowledge, and recover from errors without human supervision; (2) two evaluation settings consisting of a pre-defined conversational protocol (c-Interact) and an open-ended agentic setting (a-Interact) where models autonomously decide when to query the user simulator or explore the environment; (3) a challenging task suite covering the full CRUD spectrum for business-intelligence and operational use cases, guarded by executable test cases. Each task features ambiguous and follow-up sub-tasks requiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600 tasks, up to 11,796 interactions) for comprehensive performance assessment, and BIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed behavioral analysis and rapid method development. Our empirical results highlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in c-Interact and 17.00% in a-Interact. Analysis via memory grafting and Interaction Test-time Scaling validates the importance of effective interaction for complex, dynamic text-to-SQL tasks.", 'abstract_zh': '大型语言模型在单轮文本到SQL任务上表现出色，但在现实世界的数据库应用中，大多需要多轮交互来处理含糊查询、执行错误和不断演化的用户需求。现有的多轮交互基准存在不足，要么将对话历史视为静态上下文，要么只限制评估为只读操作，未能反映生产级别的数据库助手挑战。我们通过以下方式引入了BIRD-INTERACT基准：（1）将每个数据库与层次知识库、元数据文件和功能驱动的用户模拟器耦合，使模型能够在无需人类监督的情况下寻求澄清、检索知识和从错误中恢复；（2）包含预定义对话协议（c-Interact）和自主操作设置（a-Interact）的两种评估场景，前者模型根据预定义规则与用户模拟器交互，后者模型自主决定何时查询用户模拟器或探索环境；（3）涵盖商业智能和操作使用场景的完整CRUD光谱任务集，配有可执行测试案例。每项任务都包含含糊性和后续子任务，要求动态交互。该套件包括BIRD-INTERACT-FULL（600项任务，最多11,796次交互）用于全面性能评估，和BIRD-INTERACT-LITE（300项任务，简化数据库）用于详细行为分析和快速方法开发。我们的实证结果强调了BIRD-INTERACT的困难性：GPT-5仅在c-Interact中完成8.67%的任务，在a-Interact中完成17.00%的任务。通过内存接合分析和交互测试时缩放验证了有效交互在复杂动态文本到SQL任务中的重要性。', 'title_zh': 'BIRD-INTERACT：通过动态交互视角重新构想大规模语言模型的文本到SQL评估'}
{'arxiv_id': 'arXiv:2510.05283', 'title': 'Beyond Monolithic Rewards: A Hybrid and Multi-Aspect Reward Optimization for MLLM Alignment', 'authors': 'Radha Gulhane, Sathish Reddy Indurthi', 'link': 'https://arxiv.org/abs/2510.05283', 'abstract': 'Aligning multimodal large language models (MLLMs) with human preferences often relies on single-signal, model-based reward methods. Such monolithic rewards often lack confidence calibration across domain-specific tasks, fail to capture diverse aspects of human preferences, and require extensive data annotation and reward model training. In this work, we propose a hybrid reward modeling framework that integrates complementary reward paradigms: (i) model-based rewards, where a learned reward model predicts scalar or vector scores from synthetic and human feedback, and (ii) rule-based rewards, where domain-specific heuristics provide explicit correctness signals with confidence. Beyond accuracy, we further incorporate multi-aspect rewards to enforce instruction adherence and introduce a generalized length-penalty reward to stabilize training and improve performance. The proposed framework provides a flexible and effective approach to aligning MLLMs through reinforcement learning policy optimization. Our experiments show consistent improvements across different multimodal benchmarks when applying hybrid and multi-aspect reward modeling. Our best performing model in the 3B family achieves an overall average improvement of ~9.5% across general and math reasoning tasks. Focusing specifically on mathematical benchmarks, the model achieves a significant average improvement of ~16%, highlighting its effectiveness in mathematical reasoning and problem solving.', 'abstract_zh': '基于混合奖励建模框架的多模态大语言模型人-leaning对齐', 'title_zh': '超越单一奖励：MLLM对齐的混合多方面奖励优化'}
{'arxiv_id': 'arXiv:2510.05197', 'title': 'Efficient Prediction of Pass@k Scaling in Large Language Models', 'authors': 'Joshua Kazdan, Rylan Schaeffer, Youssef Allouah, Colin Sullivan, Kyssen Yu, Noam Levi, Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2510.05197', 'abstract': "Assessing the capabilities and risks of frontier AI systems is a critical area of research, and recent work has shown that repeated sampling from models can dramatically increase both. For instance, repeated sampling has been shown to increase their capabilities, such as solving difficult math and coding problems, but it has also been shown to increase their potential for harm, such as being jailbroken. Such results raise a crucial question for both capability and safety forecasting: how can one accurately predict a model's behavior when scaled to a massive number of attempts, given a vastly smaller sampling budget? This question is directly relevant to model providers, who serve hundreds of millions of users daily, and to governmental regulators, who seek to prevent harms. To answer this questions, we make three contributions. First, we find that standard methods for fitting these laws suffer from statistical shortcomings that hinder predictive accuracy, especially in data-limited scenarios. Second, we remedy these shortcomings by introducing a robust estimation framework, which uses a beta-binomial distribution to generate more accurate predictions from limited data. Third, we propose a dynamic sampling strategy that allocates a greater budget to harder problems. Combined, these innovations enable more reliable prediction of rare risks and capabilities at a fraction of the computational cost.", 'abstract_zh': '评估前沿AI系统的能力和风险是研究的关键领域，近期工作表明反复采样能显著增强这两种能力。然而，反复采样也显示出可能带来更大的风险，例如被突破。这些结果引出了一个重要的问题：在给定有限采样预算的情况下，如何准确预测一个模型在大规模尝试中的行为？这一问题直接关系到每天服务数亿用户的模型提供商，以及寻求防止潜在危害的政府监管机构。为了回答这个问题，我们做出了三方面的贡献。首先，我们发现用于拟合这些定律的标准方法存在统计上的不足，这限制了预测的准确性，特别是在数据有限的情况下。其次，我们通过引入一个稳健的估计框架来解决这些问题，该框架利用beta-二项分布从有限数据生成更准确的预测。第三，我们提出了一种动态采样策略，给更困难的问题分配更多的预算。综合这些创新，能够在极低的计算成本下更可靠地预测稀有风险和能力。', 'title_zh': '大型语言模型中Pass@k缩放的高效预测'}
{'arxiv_id': 'arXiv:2510.05196', 'title': 'Graph-based LLM over Semi-Structured Population Data for Dynamic Policy Response', 'authors': 'Daqian Shi, Xiaolei Diao, Jinge Wu, Honghan Wu, Xiongfeng Tang, Felix Naughton, Paulina Bondaronek', 'link': 'https://arxiv.org/abs/2510.05196', 'abstract': 'Timely and accurate analysis of population-level data is crucial for effective decision-making during public health emergencies such as the COVID-19 pandemic. However, the massive input of semi-structured data, including structured demographic information and unstructured human feedback, poses significant challenges to conventional analysis methods. Manual expert-driven assessments, though accurate, are inefficient, while standard NLP pipelines often require large task-specific labeled datasets and struggle with generalization across diverse domains. To address these challenges, we propose a novel graph-based reasoning framework that integrates large language models with structured demographic attributes and unstructured public feedback in a weakly supervised pipeline. The proposed approach dynamically models evolving citizen needs into a need-aware graph, enabling population-specific analyses based on key features such as age, gender, and the Index of Multiple Deprivation. It generates interpretable insights to inform responsive health policy decision-making. We test our method using a real-world dataset, and preliminary experimental results demonstrate its feasibility. This approach offers a scalable solution for intelligent population health monitoring in resource-constrained clinical and governmental settings.', 'abstract_zh': '及时准确地分析群体级数据对于公共卫生紧急事件，如COVID-19疫情期间的有效决策至关重要。然而，半结构化数据的大量输入，包括结构化的人口统计信息和未结构化的人类反馈，给传统的分析方法带来了显著挑战。虽然手动专家驱动的评估方法非常准确，但效率低下，而标准的自然语言处理管道通常需要大量的特定任务标记数据集，并且难以在多样化的领域之间进行泛化。为了解决这些挑战，我们提出了一种基于图的推理框架，将大型语言模型与结构化的人口统计属性和未结构化的公众反馈集成到弱监督管道中。所提出的框架动态建模公民需求的变化，并将其建模为需求感知的图，使得基于关键特征（如年龄、性别和多维贫困指数）进行群体特定的分析成为可能。它生成可解释的见解，以指导响应式公共卫生政策决策。我们使用真实世界的数据集测试了该方法，并初步实验证明了其可行性。该方法为资源有限的临床和政府环境中智能人群健康管理提供了一种可扩展的解决方案。', 'title_zh': '基于图的半结构化人群数据动态政策响应大规模语言模型'}
{'arxiv_id': 'arXiv:2510.05188', 'title': 'Plug-and-Play Dramaturge: A Divide-and-Conquer Approach for Iterative Narrative Script Refinement via Collaborative LLM Agents', 'authors': 'Wenda Xie, Chao Guo, Yanqing Jing. Junle Wang, Yisheng Lv, Fei-Yue Wang', 'link': 'https://arxiv.org/abs/2510.05188', 'abstract': 'Although LLMs have been widely adopted for creative content generation, a single-pass process often struggles to produce high-quality long narratives. How to effectively revise and improve long narrative scripts like scriptwriters remains a significant challenge, as it demands a comprehensive understanding of the entire context to identify global structural issues and local detailed flaws, as well as coordinating revisions at multiple granularities and locations. Direct modifications by LLMs typically introduce inconsistencies between local edits and the overall narrative requirements. To address these issues, we propose Dramaturge, a task and feature oriented divide-and-conquer approach powered by hierarchical multiple LLM agents. It consists of a Global Review stage to grasp the overall storyline and structural issues, a Scene-level Review stage to pinpoint detailed scene and sentence flaws, and a Hierarchical Coordinated Revision stage that coordinates and integrates structural and detailed improvements throughout the script. The top-down task flow ensures that high-level strategies guide local modifications, maintaining contextual consistency. The review and revision workflow follows a coarse-to-fine iterative process, continuing through multiple rounds until no further substantive improvements can be made. Comprehensive experiments show that Dramaturge significantly outperforms all baselines in terms of script-level overall quality and scene-level details. Our approach is plug-and-play and can be easily integrated into existing methods to improve the generated scripts.', 'abstract_zh': '虽然大型语言模型在创意内容生成中已被广泛应用，但单次过程常常难以生成高质量的长篇叙事。如何有效修订和改进类似编剧的长篇叙事脚本仍然是一个重大挑战，因为它需要对整个上下文有全面的理解，以识别全局结构问题和局部细节缺陷，并协调多粒度、多位置的修订。直接由大型语言模型进行修改通常会在局部编辑与整体叙事需求之间引入不一致性。为了解决这些问题，我们提出了一种名为Dramaturge的任务和特征导向的分而治之方法，该方法基于分层的多大型语言模型代理。Dramaturge包括一个全局审查阶段，以把握整体剧情线索和结构问题；一个场景级审查阶段，以确定具体场景和句子的缺陷；以及一个分层协调修订阶段，协调并整合脚本中的结构性和细节上的改进。自顶向下的任务流程确保高级策略指导局部修改，维持上下文一致性。审查和修订工作流程遵循从粗到细的迭代过程，经过多轮迭代，直到无法做出进一步实质性的改进为止。全面的实验表明，Dramaturge在脚本整体质量和场景细节方面显著优于所有基线。我们的方法即插即用，可以很容易地集成到现有方法中以改进生成的脚本。', 'title_zh': '即插即用的舞台总监：一种基于协作式LLM代理的分而治之方法，用于迭代叙事剧本精炼'}
{'arxiv_id': 'arXiv:2510.05187', 'title': 'Real-time Framework for Interoperable Semantic-driven Internet-of-Things in Smart Agriculture', 'authors': 'Mohamed El-Dosuky', 'link': 'https://arxiv.org/abs/2510.05187', 'abstract': 'The Internet of Things (IoT) has revolutionized various applications including agriculture, but it still faces challenges in data collection and understanding. This paper proposes a real-time framework with three additional semantic layers to help IoT devices and sensors comprehend data meaning and source. The framework consists of six layers: perception, semantic annotation, interoperability, transportation, semantic reasoning, and application, suitable for dynamic environments. Sensors collect data in the form of voltage, which is then processed by microprocessors or microcontrollers in the semantic annotation and preprocessing layer. Metadata is added to the raw data, including the purpose, ID number, and application. Two semantic algorithms are proposed in the semantic interoperability and ontologies layer: the interoperability semantic algorithm for standardizing file types and the synonym identification algorithm for identifying synonyms. In the transportation layer, raw data and metadata are sent to other IoT devices or cloud computing platforms using techniques like WiFi, Zigbee networks, Bluetooth, and mobile communication networks. A semantic reasoning layer is proposed to infer new knowledge from the existing data, using fuzzy logic, Dempster-Shafer theory, and Bayesian networks. A Graphical User Interface (GUI) is proposed in the application layer to help users communicate with and monitor IoT sensors, devices, and new knowledge inferred. This framework provides a robust solution for managing IoT data, ensuring semantic completeness, and enabling real-time knowledge inference. The integration of uncertainty reasoning methods and semantic interoperability techniques makes this framework a valuable tool for advancing IoT applications in general and in agriculture in particular.', 'abstract_zh': '物联网（IoT）已变革了各种应用包括农业，但仍面临数据收集和理解的挑战。本文提出了一种实时框架，包含三个额外的语义层，以助物联网设备和传感器理解数据的意义和来源。该框架包括六个层次：感知、语义标注、互操作性、传输、语义推理和应用，适用于动态环境。传感器以电压的形式收集数据，然后由语义标注和预处理层中的微处理器或微控制器进行处理。向原始数据添加元数据，包括目的、编号和应用。语义互操作性和本体层提出了两种语义算法：互操作性语义算法用于标准化文件类型，同义词识别算法用于识别同义词。在传输层，原始数据和元数据使用WiFi、Zigbee网络、蓝牙和移动通信网络等技术发送到其他物联网设备或云计算平台。提出了语义推理层，利用模糊逻辑、Dempster-Shafer理论和贝叶斯网络从现有数据推断新知识。提出了应用层的图形用户界面，以帮助用户与物联网传感器、设备以及推断的新知识进行通信和监控。该框架提供了管理物联网数据的稳健解决方案，确保语义完备性，并实现实时知识推断。不确定性推理方法和语义互操作性技术的结合使该框架成为推动物联网应用（尤其是农业）向前发展的有力工具。', 'title_zh': '实时互操作语义驱动物联网框架在智能农业中的应用'}
{'arxiv_id': 'arXiv:2510.05184', 'title': 'Representation Potentials of Foundation Models for Multimodal Alignment: A Survey', 'authors': 'Jianglin Lu, Hailing Wang, Yi Xu, Yizhou Wang, Kuo Yang, Yun Fu', 'link': 'https://arxiv.org/abs/2510.05184', 'abstract': 'Foundation models learn highly transferable representations through large-scale pretraining on diverse data. An increasing body of research indicates that these representations exhibit a remarkable degree of similarity across architectures and modalities. In this survey, we investigate the representation potentials of foundation models, defined as the latent capacity of their learned representations to capture task-specific information within a single modality while also providing a transferable basis for alignment and unification across modalities. We begin by reviewing representative foundation models and the key metrics that make alignment measurable. We then synthesize empirical evidence of representation potentials from studies in vision, language, speech, multimodality, and neuroscience. The evidence suggests that foundation models often exhibit structural regularities and semantic consistencies in their representation spaces, positioning them as strong candidates for cross-modal transfer and alignment. We further analyze the key factors that foster representation potentials, discuss open questions, and highlight potential challenges.', 'abstract_zh': '基础模型通过大规模多样数据的预训练学习到高度可迁移的表示。越来越多的研究表明，这些表示在不同架构和模态下表现出显著的相似性。在这篇综述中，我们探讨基础模型的表示潜力，即其学习表示在单一模态内捕获任务特定信息的能力，同时为跨模态的对齐和统一提供可迁移的基础。我们首先回顾代表性基础模型及其使对齐可度量的关键指标。然后，我们综合视觉、语言、语音、多模态和神经科学领域的实证证据，这些证据表明基础模型在表示空间中经常表现出结构规律性和语义一致性，使它们成为跨模态迁移和对齐的强大候选者。我们进一步分析促进表示潜力的关键因素，讨论开放问题，并指出潜在挑战。', 'title_zh': '基础模型在多模态对齐中的表示潜力：一个综述'}
{'arxiv_id': 'arXiv:2510.05158', 'title': 'Lang-PINN: From Language to Physics-Informed Neural Networks via a Multi-Agent Framework', 'authors': 'Xin He, Liangliang You, Hongduan Tian, Bo Han, Ivor Tsang, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2510.05158', 'abstract': 'Physics-informed neural networks (PINNs) provide a powerful approach for solving partial differential equations (PDEs), but constructing a usable PINN remains labor-intensive and error-prone. Scientists must interpret problems as PDE formulations, design architectures and loss functions, and implement stable training pipelines. Existing large language model (LLM) based approaches address isolated steps such as code generation or architecture suggestion, but typically assume a formal PDE is already specified and therefore lack an end-to-end perspective. We present Lang-PINN, an LLM-driven multi-agent system that builds trainable PINNs directly from natural language task descriptions. Lang-PINN coordinates four complementary agents: a PDE Agent that parses task descriptions into symbolic PDEs, a PINN Agent that selects architectures, a Code Agent that generates modular implementations, and a Feedback Agent that executes and diagnoses errors for iterative refinement. This design transforms informal task statements into executable and verifiable PINN code. Experiments show that Lang-PINN achieves substantially lower errors and greater robustness than competitive baselines: mean squared error (MSE) is reduced by up to 3--5 orders of magnitude, end-to-end execution success improves by more than 50\\%, and reduces time overhead by up to 74\\%.', 'abstract_zh': '基于物理的知识型神经网络（Lang-PINN）：一种自然语言驱动的多Agent系统', 'title_zh': 'Lang-PINN: 通过多agent框架从语言到物理知情神经网络'}
{'arxiv_id': 'arXiv:2510.05153', 'title': 'An Algorithmic Information-Theoretic Perspective on the Symbol Grounding Problem', 'authors': 'Zhangchi Liu', 'link': 'https://arxiv.org/abs/2510.05153', 'abstract': 'This paper provides a definitive, unifying framework for the Symbol Grounding Problem (SGP) by reformulating it within Algorithmic Information Theory (AIT). We demonstrate that the grounding of meaning is a process fundamentally constrained by information-theoretic limits, thereby unifying the Gödelian (self-reference) and No Free Lunch (statistical) perspectives. We model a symbolic system as a universal Turing machine and define grounding as an act of information compression. The argument proceeds in four stages. First, we prove that a purely symbolic system cannot ground almost all possible "worlds" (data strings), as they are algorithmically random and thus incompressible. Second, we show that any statically grounded system, specialized for compressing a specific world, is inherently incomplete because an adversarial, incompressible world relative to the system can always be constructed. Third, the "grounding act" of adapting to a new world is proven to be non-inferable, as it requires the input of new information (a shorter program) that cannot be deduced from the system\'s existing code. Finally, we use Chaitin\'s Incompleteness Theorem to prove that any algorithmic learning process is itself a finite system that cannot comprehend or model worlds whose complexity provably exceeds its own. This establishes that meaning is the open-ended process of a system perpetually attempting to overcome its own information-theoretic limitations.', 'abstract_zh': '本文通过将符号接地问题（SGP）重新形式化为算法信息论（AIT）的框架内，提供了一个明确而统一的理论框架。我们证明了意义接地是一个从根本上受信息论限制的过程，从而统一了哥德尔（自参照）和无免费午餐（统计）视角。我们将符号系统建模为通用图灵机，并将接地定义为信息压缩的行为。论证过程分为四个阶段。首先，我们证明纯粹符号系统无法接地几乎所有的“世界”（数据字符串），因为它们是算法随机的，因而不可压缩。其次，我们展示任何专门用于压缩特定世界的数据静止接地系统是本质上不完整的，因为对于系统而言，总是可以构造出一个相对于系统不可压缩的对抗性“世界”。第三，适应新世界的“接地行为”被证明是不可推导的，因为它需要输入新的信息（更短的程序），这些信息无法从系统的现有代码中推导出来。最后，我们使用乔哈尔的不完备性定理证明任何算法学习过程本身是一个有限的系统，无法理解和建模其复杂性可证明超过自身复杂性的世界。这表明意义是一个系统在不断尝试克服自身信息论限制的开放过程。', 'title_zh': '一种从算法信息理论视角探讨符号 grounding 问题的方法'}
{'arxiv_id': 'arXiv:2510.05134', 'title': 'Structuring Reasoning for Complex Rules Beyond Flat Representations', 'authors': 'Zhihao Yang, Ancheng Xu, Jingpeng Li, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Ahmadreza Argha, Hamid Alinejad-Rokny, Minghuan Tan, Yujun Cai, Min Yang', 'link': 'https://arxiv.org/abs/2510.05134', 'abstract': 'Large language models (LLMs) face significant challenges when processing complex rule systems, as they typically treat interdependent rules as unstructured textual data rather than as logically organized frameworks. This limitation results in reasoning divergence, where models often overlook critical rule dependencies essential for accurate interpretation. Although existing approaches such as Chain-of-Thought (CoT) reasoning have shown promise, they lack systematic methodologies for structured rule processing and are particularly susceptible to error propagation through sequential reasoning chains. To address these limitations, we propose the Dynamic Adjudication Template (DAT), a novel framework inspired by expert human reasoning processes. DAT structures the inference mechanism into three methodical stages: qualitative analysis, evidence gathering, and adjudication. During the qualitative analysis phase, the model comprehensively evaluates the contextual landscape. The subsequent evidence gathering phase involves the targeted extraction of pertinent information based on predefined template elements ([placeholder]), followed by systematic verification against applicable rules. Finally, in the adjudication phase, the model synthesizes these validated components to formulate a comprehensive judgment. Empirical results demonstrate that DAT consistently outperforms conventional CoT approaches in complex rule-based tasks. Notably, DAT enables smaller language models to match, and in some cases exceed, the performance of significantly larger LLMs, highlighting its efficiency and effectiveness in managing intricate rule systems.', 'abstract_zh': '大型语言模型在处理复杂规则系统时面临显著挑战，因为它们通常将相互依赖规则视为非结构化文本数据，而不是逻辑组织框架。这种限制导致了推理偏差，模型经常忽略对于准确解释至关重要的规则依赖关系。尽管现有的方法如链式思考（CoT）显示出前景，但它们缺乏针对结构化规则处理的系统方法，并且容易通过顺序推理链传播错误。为解决这些局限，我们提出了动态裁决模板（DAT），这是一种受到专家人类推理过程启发的新框架。DAT 将推理机制分为三个系统阶段：定性分析、证据收集和裁决。在定性分析阶段，模型全面评估上下文环境。随后的证据收集阶段涉及根据预定义模板元素（[占位符]）进行有针对性的关键信息提取，并对适用规则进行系统验证。最后，在裁决阶段，模型综合这些经验证的组件以制定全面的判断。实证结果表明，DAT 在复杂的基于规则的任务中始终优于传统的 CoT 方法。值得注意的是，DAT 使较小的语言模型能够匹配甚至超过显著更大的 LLM 的性能，突显了其在管理复杂规则系统方面的效率和有效性。', 'title_zh': '超出平面表示的复杂规则推理结构化'}
{'arxiv_id': 'arXiv:2510.05115', 'title': 'Optimization Modeling via Semantic Anchored Alignment', 'authors': 'Yansen Zhang, Qingcan Kang, Yujie Chen, Yufei Wang, Xiongwei Han, Tao Zhong, Mingxuan Yuan, Chen Ma', 'link': 'https://arxiv.org/abs/2510.05115', 'abstract': 'Large language models (LLMs) have opened new paradigms in optimization modeling by enabling the generation of executable solver code from natural language descriptions. Despite this promise, existing approaches typically remain solver-driven: they rely on single-pass forward generation and apply limited post-hoc fixes based on solver error messages, leaving undetected semantic errors that silently produce syntactically correct but logically flawed models. To address this challenge, we propose SAC-Opt, a backward-guided correction framework that grounds optimization modeling in problem semantics rather than solver feedback. At each step, SAC-Opt aligns the original semantic anchors with those reconstructed from the generated code and selectively corrects only the mismatched components, driving convergence toward a semantically faithful model. This anchor-driven correction enables fine-grained refinement of constraint and objective logic, enhancing both fidelity and robustness without requiring additional training or supervision. Empirical results on seven public datasets demonstrate that SAC-Opt improves average modeling accuracy by 7.8\\%, with gains of up to 21.9\\% on the ComplexLP dataset. These findings highlight the importance of semantic-anchored correction in LLM-based optimization workflows to ensure faithful translation from problem intent to solver-executable code.', 'abstract_zh': '基于语义引导修正的大型语言模型优化编译框架（SAC-Opt）', 'title_zh': '基于语义锚点对齐的优化建模'}
{'arxiv_id': 'arXiv:2510.05107', 'title': 'Structured Cognition for Behavioral Intelligence in Large Language Model Agents: Preliminary Study', 'authors': 'Myung Ho Kim', 'link': 'https://arxiv.org/abs/2510.05107', 'abstract': 'Large language models have advanced natural language understanding and generation, yet their use as autonomous agents raises architectural challenges for multi-step tasks. Existing frameworks often intertwine inference, memory, and control in a single prompt, which can reduce coherence and predictability. The Structured Cognitive Loop (SCL) is introduced as an alternative architecture that separates these functions. In SCL, the language model is dedicated to inference, memory is maintained externally, and execution is guided by a lightweight controller within a goal-directed loop. This design offloads cognitive load from the model and allows intermediate results to be stored, revisited, and checked before actions are taken, providing a clearer basis for traceability and evaluation.\nWe evaluate SCL against prompt-based baselines including ReAct and common LangChain agents across three scenarios: temperature-based travel planning, email drafting with conditional send, and constraint-guided image generation. All systems share the same base model and tools under matched decoding settings. Across 360 episodes, SCL shows modest but consistent improvements. Task success averages 86.3 percent compared with 70-77 percent for baselines. Goal fidelity is higher, redundant calls are fewer, intermediate states are reused more reliably, and unsupported assertions per 100 tool calls are reduced. Ablations show that external memory and control each contribute independently, and decoding sweeps confirm stability of the effects.\nThese results suggest that architectural separation can improve reliability and traceability without relying on larger models or heavier prompts. The findings are preliminary and intended to guide extended studies with additional models, longer horizons, multimodal tasks, and collaborative settings.', 'abstract_zh': '大型语言模型增强了自然语言的理解与生成能力，但作为自主代理在多步任务中的使用提出了架构挑战。现有的框架往往将推理、记忆和控制功能交织在单一的提示中，这可能会降低连贯性和可预测性。结构认知循环（SCL）作为一种替代架构被引入，它将这些功能分离。在SCL中，语言模型专注于推理，记忆由外部维护，执行由目标导向循环中的轻量级控制器指导。这种设计减轻了模型的认知负担，并允许中间结果被存储、回顾和验证，在采取行动之前，为可追溯性和评估提供了更清晰的基础。\n\n我们评估了SCL与基于提示的基准方法（包括ReAct和常见的LangChain代理）在三个场景中的表现：基于温度的旅行规划、有条件发送的邮件草拟以及约束导向的图像生成。所有系统共享相同的基模型和工具，并且在匹配的解码设置下进行评估。在360个场景中，SCL展示了适度但持续的改进。任务成功率平均为86.3%，而基准方法的这一数字为70-77%。目标忠诚度更高，冗余调用更少，中间状态的重用更可靠，每100次工具调用中的不可支持断言更少。消融实验表明，外部记忆和控制各自独立地做出了贡献，解码扫面确认了效果的稳定性。\n\n这些结果表明，架构分离可以在不依赖更大模型或更重提示的情况下提高可靠性和可追溯性。该研究结果初步且旨在引导后续的进一步研究，涵盖更多的模型、更长的展望、多模态任务和协作情境。', 'title_zh': '大型语言模型代理的行为智能结构化认知：初步研究'}
{'arxiv_id': 'arXiv:2510.05106', 'title': 'Rule Encoding and Compliance in Large Language Models: An Information-Theoretic Analysis', 'authors': 'Joachim Diederich', 'link': 'https://arxiv.org/abs/2510.05106', 'abstract': 'The design of safety-critical agents based on large language models (LLMs) requires more than simple prompt engineering. This paper presents a comprehensive information-theoretic analysis of how rule encodings in system prompts influence attention mechanisms and compliance behaviour. We demonstrate that rule formats with low syntactic entropy and highly concentrated anchors reduce attention entropy and improve pointer fidelity, but reveal a fundamental trade-off between anchor redundancy and attention entropy that previous work failed to recognize. Through formal analysis of multiple attention architectures including causal, bidirectional, local sparse, kernelized, and cross-attention mechanisms, we establish bounds on pointer fidelity and show how anchor placement strategies must account for competing fidelity and entropy objectives. Combining these insights with a dynamic rule verification architecture, we provide a formal proof that hot reloading of verified rule sets increases the asymptotic probability of compliant outputs. These findings underscore the necessity of principled anchor design and dual enforcement mechanisms to protect LLM-based agents against prompt injection attacks while maintaining compliance in evolving domains.', 'abstract_zh': '基于大型语言模型（LLMs）的安全关键代理设计不仅需要简单的提示工程。本文呈现了系统提示中的规则编码如何影响注意力机制和合规行为的全面信息论分析。我们证明，低句法熵和高度集中锚点的规则格式可以减少注意力熵并提高指针精确度，但揭示了以前的研究未曾认识到的锚点冗余与注意力熵之间的根本权衡。通过对包括因果、双向、局部稀疏、核化和交叉注意机制在内的多种注意力架构的正式分析，我们界定了指针精确度的上限，并展示了如何使锚点放置策略同时考虑竞争性的精确度和熵目标。结合这些洞察与动态规则验证架构，我们提供了形式证明，即验证规则集的热重载可以提高合规输出的渐近概率。这些发现强调了原理性的锚点设计和双重执行机制的必要性，以保护基于LLM的代理免受提示注入攻击，同时在不断变化的领域中保持合规性。', 'title_zh': '大型语言模型中的规则编码与合规性：一种信息论分析'}
{'arxiv_id': 'arXiv:2510.06218', 'title': 'EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark', 'authors': 'Deheng Zhang, Yuqian Fu, Runyi Yang, Yang Miao, Tianwen Qian, Xu Zheng, Guolei Sun, Ajad Chhatkuli, Xuanjing Huang, Yu-Gang Jiang, Luc Van Gool, Danda Pani Paudel', 'link': 'https://arxiv.org/abs/2510.06218', 'abstract': 'Most existing benchmarks for egocentric vision understanding focus primarily on daytime scenarios, overlooking the low-light conditions that are inevitable in real-world applications. To investigate this gap, we present EgoNight, the first comprehensive benchmark for nighttime egocentric vision, with visual question answering (VQA) as the core task. A key feature of EgoNight is the introduction of day-night aligned videos, which enhance night annotation quality using the daytime data and reveal clear performance gaps between lighting conditions. To achieve this, we collect both synthetic videos rendered by Blender and real-world recordings, ensuring that scenes and actions are visually and temporally aligned. Leveraging these paired videos, we construct EgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and refinement through extensive human verification. Each QA pair is double-checked by annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs across 90 videos, spanning 12 diverse QA types, with more than 300 hours of human work. Evaluations of state-of-the-art multimodal large language models (MLLMs) reveal substantial performance drops when transferring from day to night, underscoring the challenges of reasoning under low-light conditions. Beyond VQA, EgoNight also introduces two auxiliary tasks, day-night correspondence retrieval and egocentric depth estimation at night, that further explore the boundaries of existing models. We believe EgoNight-VQA provides a strong foundation for advancing application-driven egocentric vision research and for developing models that generalize across illumination domains. All the data and code will be made available upon acceptance.', 'abstract_zh': 'EgoNight：面向夜间第一人称视觉理解的综合基准', 'title_zh': 'EgoNight：夜间自视角视觉理解的挑战性基准研究'}
{'arxiv_id': 'arXiv:2510.06214', 'title': 'Stratified GRPO: Handling Structural Heterogeneity in Reinforcement Learning of LLM Search Agents', 'authors': 'Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia', 'link': 'https://arxiv.org/abs/2510.06214', 'abstract': 'Large language model (LLM) agents increasingly rely on external tools such as search engines to solve complex, multi-step problems, and reinforcement learning (RL) has become a key paradigm for training them. However, the trajectories of search agents are structurally heterogeneous, where variations in the number, placement, and outcomes of search calls lead to fundamentally different answer directions and reward distributions. Standard policy gradient methods, which use a single global baseline, suffer from what we identify and formalize as cross-stratum bias-an "apples-to-oranges" comparison of heterogeneous trajectories. This cross-stratum bias distorts credit assignment and hinders exploration of complex, multi-step search strategies. To address this, we propose Stratified GRPO, whose central component, Stratified Advantage Normalization (SAN), partitions trajectories into homogeneous strata based on their structural properties and computes advantages locally within each stratum. This ensures that trajectories are evaluated only against their true peers. Our analysis proves that SAN eliminates cross-stratum bias, yields conditionally unbiased unit-variance estimates inside each stratum, and retains the global unbiasedness and unit-variance properties enjoyed by standard normalization, resulting in a more pure and scale-stable learning signal. To improve practical stability under finite-sample regimes, we further linearly blend SAN with the global estimator. Extensive experiments on diverse single-hop and multi-hop question-answering benchmarks demonstrate that Stratified GRPO consistently and substantially outperforms GRPO by up to 11.3 points, achieving higher training rewards, greater training stability, and more effective search policies. These results establish stratification as a principled remedy for structural heterogeneity in RL for LLM search agents.', 'abstract_zh': '大规模语言模型（LLM）代理 increasingly rely on 外部工具 如搜索引擎来解决复杂、多步问题，并且强化学习（RL）已成为训练它们的关键范式。然而，搜索代理的轨迹在结构上异质性显著，其中搜索调用的数量、位置和结果的变异性导致了根本不同的答案方向和奖励分布。标准的策略梯度方法使用单一全局基线，我们将其识别并形式化为跨层偏差——异质轨迹之间的“苹果对橙子”比较。这种跨层偏差扭曲了信用分配并阻碍了对复杂、多步搜索策略的探索。为了解决这一问题，我们提出了分层GRPO（Stratified GRPO），其核心组件分层优势标准化（SAN）基于其结构属性将轨迹划分为同质层，并在每层内局部计算优势。这确保了轨迹仅与它们的真实同层进行评估。我们的分析证明SAN消除了跨层偏差，在每层内部提供了有条件无偏的一元方差估计，并保留了标准标准化所享有的全局无偏性和一元方差属性，从而产生一种更为纯净和缩放稳定的学习信号。为进一步提高在有限样本下的实际稳定性，我们进一步将SAN线性地与全局估计器融合。在多种单跳和多跳问答基准上的广泛实验表明，分层GRPO在多个方面显著优于GRPO，实现了更高的训练奖励、更强的训练稳定性以及更有效的搜索策略。这些结果确立了分层作为解决大规模语言模型搜索代理中结构异质性的基本原则方法。', 'title_zh': '分层GRPO：处理LLM搜索代理 reinforcement learning 中的结构异质性'}
{'arxiv_id': 'arXiv:2510.06203', 'title': 'Reference Grounded Skill Discovery', 'authors': 'Seungeun Rho, Aaron Trinh, Danfei Xu, Sehoon Ha', 'link': 'https://arxiv.org/abs/2510.06203', 'abstract': 'Scaling unsupervised skill discovery algorithms to high-DoF agents remains challenging. As dimensionality increases, the exploration space grows exponentially, while the manifold of meaningful skills remains limited. Therefore, semantic meaningfulness becomes essential to effectively guide exploration in high-dimensional spaces. In this work, we present Reference-Grounded Skill Discovery (RGSD), a novel algorithm that grounds skill discovery in a semantically meaningful latent space using reference data. RGSD first performs contrastive pretraining to embed motions on a unit hypersphere, clustering each reference trajectory into a distinct direction. This grounding enables skill discovery to simultaneously involve both imitation of reference behaviors and the discovery of semantically related diverse behaviors. On a simulated SMPL humanoid with 359-D observations and 69-D actions, RGSD learns structured skills including walking, running, punching, and side stepping, and also discovers related novel behaviors. In downstream control tasks, RGSD outperforms imitation-based skill acquisition baselines. Our results suggest that lightweight reference-guided grounding offers a practical path to discovering semantically rich and structured skills in high-DoF systems.', 'abstract_zh': '高自由度代理无监督技能发现算法的扩展仍具挑战性。RGSD：基于参考的数据 grounding 技能发现算法', 'title_zh': '基于参考的技能发现'}
{'arxiv_id': 'arXiv:2510.06201', 'title': 'TokenChain: A Discrete Speech Chain via Semantic Token Modeling', 'authors': 'Mingxuan Wang, Satoshi Nakamura', 'link': 'https://arxiv.org/abs/2510.06201', 'abstract': 'Machine Speech Chain, simulating the human perception-production loop, proves effective in jointly improving ASR and TTS. We propose TokenChain, a fully discrete speech chain coupling semantic-token ASR with a two-stage TTS: an autoregressive text-to-semantic model co-trained with ASR and a masked-generative semantic-to-acoustic model for synthesis only. End-to-end feedback across the text interface is enabled with straight-through argmax/Gumbel-Softmax and balanced with supervised ASR via dynamic weight averaging. Ablations examine optimal temperature schedules for in- and cross-domain transfer. Evaluation reveals TokenChain surpasses baseline accuracy 2-6 epochs earlier and yields 5-13% lower equal-epoch error with stable T2S on LibriSpeech, and reduces relative ASR WER by 56% and T2S WER by 31% on TED-LIUM with minimal forgetting, showing that chain learning remains effective with token interfaces and models.', 'abstract_zh': 'TokenChain：一种结合语义标记ASR与两阶段TTS的全离散语音链，在端到端反馈下有效提升ASR和TTS', 'title_zh': 'TokenChain：基于语义令牌建模的离散语音链'}
{'arxiv_id': 'arXiv:2510.06200', 'title': 'StarEmbed: Benchmarking Time Series Foundation Models on Astronomical Observations of Variable Stars', 'authors': 'Weijian Li, Hong-Yu Chen, Qinjie Lin, Nabeel Rehemtulla, Ved G. Shah, Dennis Wu, Adam A. Miller, Han Liu', 'link': 'https://arxiv.org/abs/2510.06200', 'abstract': "Time series foundation models (TSFMs) are increasingly being adopted as highly-capable general-purpose time series representation learners. Although their training corpora are vast, they exclude astronomical time series data. Observations of stars produce peta-scale time series with unique challenges including irregular sampling and heteroskedasticity. We introduce StarEmbed, the first public benchmark for rigorous and standardized evaluation of state-of-the-art TSFMs on stellar time series observations (``light curves''). We benchmark on three scientifically-motivated downstream tasks: unsupervised clustering, supervised classification, and out-of-distribution source detection. StarEmbed integrates a catalog of expert-vetted labels with multi-variate light curves from the Zwicky Transient Facility, yielding ~40k hand-labeled light curves spread across seven astrophysical classes. We evaluate the zero-shot representation capabilities of three TSFMs (MOIRAI, Chronos, Chronos-Bolt) and a domain-specific transformer (Astromer) against handcrafted feature extraction, the long-standing baseline in the astrophysics literature. Our results demonstrate that these TSFMs, especially the Chronos models, which are trained on data completely unlike the astronomical observations, can outperform established astrophysics-specific baselines in some tasks and effectively generalize to entirely new data. In particular, TSFMs deliver state-of-the-art performance on our out-of-distribution source detection benchmark. With the first benchmark of TSFMs on astronomical time series data, we test the limits of their generalization and motivate a paradigm shift in time-domain astronomy from using task-specific, fully supervised pipelines toward adopting generic foundation model representations for the analysis of peta-scale datasets from forthcoming observatories.", 'abstract_zh': '星系嵌入：时间序列基础模型在恒星光曲线观测上的首个严格标准化评估', 'title_zh': 'StarEmbed: 天体变星观测中时间序列基础模型的benchmark评测'}
{'arxiv_id': 'arXiv:2510.06195', 'title': 'Latent Speech-Text Transformer', 'authors': 'Yen-Ju Lu, Yashesh Gaur, Wei Zhou, Benjamin Muller, Jesus Villalba, Najim Dehak, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Srinivasan Iyer, Duc Le', 'link': 'https://arxiv.org/abs/2510.06195', 'abstract': 'Auto-regressive speech-text models are typically pre-trained on a large number of interleaved sequences of text tokens and raw speech encoded as speech tokens using vector quantization. These models have demonstrated state-of-the-art performance in speech-to-speech understanding and generation benchmarks, together with promising scaling laws, primarily enabled by the representational alignment between text and speech. Nevertheless, they suffer from shortcomings, partly owing to the disproportionately longer sequences of speech tokens in contrast to textual tokens. This results in a large compute imbalance between modalities during pre-training as well as during inference, and a potential hindrance to effectively aligning speech and text, ultimately translating to several orders of magnitude slower scaling laws. We introduce the Latent Speech-Text Transformer (LST), which makes pre-training speech-text models more data-efficient by dynamically and inexpensively aggregating speech tokens into latent speech patches. These patches serve as higher-level units that can either align with corresponding textual units to aid capability transfer or even encapsulate common speech sequences like silences to be more compute-efficient. We show that LST outperforms vanilla approaches on speech-to-speech as well as text-to-text benchmarks in both data- and compute-controlled settings, the former indicating more effective representational alignment and the latter indicating steeper scaling laws for speech-text models. On HellaSwag story completion, LST achieves 6.5% absolute gain in speech accuracy under compute-controlled training and 5.3% under data-controlled training, while also improving text performance. We will release our models, code, and the evaluation data to facilitate further research.', 'abstract_zh': 'Latent Speech-Text Transformer：通过动态聚合声学令牌提高声学-文本模型的训练效率', 'title_zh': '潜藏言语-文本变换器'}
{'arxiv_id': 'arXiv:2510.06188', 'title': 'BanglaTalk: Towards Real-Time Speech Assistance for Bengali Regional Dialects', 'authors': 'Jakir Hasan, Shubhashis Roy Dipta', 'link': 'https://arxiv.org/abs/2510.06188', 'abstract': 'Real-time speech assistants are becoming increasingly popular for ensuring improved accessibility to information. Bengali, being a low-resource language with a high regional dialectal diversity, has seen limited progress in developing such systems. Existing systems are not optimized for real-time use and focus only on standard Bengali. In this work, we present BanglaTalk, the first real-time speech assistance system for Bengali regional dialects. BanglaTalk follows the client-server architecture and uses the Real-time Transport Protocol (RTP) to ensure low-latency communication. To address dialectal variation, we introduce a dialect-aware ASR system, BRDialect, developed by fine-tuning the IndicWav2Vec model in ten Bengali regional dialects. It outperforms the baseline ASR models by 12.41-33.98% on the RegSpeech12 dataset. Furthermore, BanglaTalk can operate at a low bandwidth of 24 kbps while maintaining an average end-to-end delay of 4.9 seconds. Low bandwidth usage and minimal end-to-end delay make the system both cost-effective and interactive for real-time use cases, enabling inclusive and accessible speech technology for the diverse community of Bengali speakers.', 'abstract_zh': '实时语音助手正在变得越来越流行，以确保信息访问的增强可访问性。由于孟加拉语是一种资源匮乏语言且具有高度区域方言多样性，因此在开发此类系统方面取得了有限的进展。现有系统并未针对实时使用进行优化，且仅关注标准孟加拉语。在此项工作中，我们提出了BanglaTalk，这是首个针对孟加拉语区域方言的实时语音助手系统。BanglaTalk采用客户端-服务器架构，并使用实时传输协议（RTP）以确保低延迟通信。为解决方言差异，我们引入了一种-aware ASR系统BRDialect，该系统通过在十种孟加拉语区域方言上微调IndicWav2Vec模型开发而成。它在RegSpeech12数据集上的表现优于基础ASR模型，性能提升12.41-33.98%。此外，BanglaTalk可在低带宽（24 kbps）下运行，并保持平均端到端延迟为4.9秒。低带宽使用和最小的端到端延迟使该系统既成本效益高又具有交互性，适用于实时应用场景，从而为多样化的孟加拉语使用者群体提供包容性和可访问的语音技术。', 'title_zh': 'BanglaTalk: 向实时孟加拉地区方言语音辅助系统方向发展'}
{'arxiv_id': 'arXiv:2510.06187', 'title': 'Automated Program Repair of Uncompilable Student Code', 'authors': 'Griffin Pitts, Aum Pandya, Darsh Rank, Tirth Bhatt, Muntasir Hoq, Bita Akram', 'link': 'https://arxiv.org/abs/2510.06187', 'abstract': "A significant portion of student programming submissions in CS1 learning environments are uncompilable, limiting their use in student modeling and downstream knowledge tracing. Traditional modeling pipelines often exclude these cases, discarding observations of student learning. This study investigates automated program repair as a strategy to recover uncompilable code while preserving students' structural intent for use in student modeling. Within this framework, we assess large language models (LLMs) as repair agents, including GPT-5 (OpenAI), Claude 3.5 Haiku (Anthropic), and Gemini 2.5 Flash (Google), under high- and low-context prompting conditions. Repairs were evaluated for compilability, edit distance, and preservation of students' original structure and logic. We find that while all three LLMs are capable of producing compilable repairs, their behavior diverges in how well they preserve students' control flow and code structure, which affects their pedagogical utility. By recovering uncompilable submissions, this work enables richer and more comprehensive analyses of learners' coding processes and development over time.", 'abstract_zh': 'CS1学习环境中，大量学生的编程提交无法编译，限制了其在学生建模和下游知识追踪中的应用。传统的建模管道通常排除这些情况，丢弃学生的学习观察。本研究调查了自动化程序修复策略，以恢复无法编译的代码同时保留学生的结构意图，用于学生建模。在此框架下，我们评估了大型语言模型（LLMs）作为修复代理的能力，包括GPT-5（OpenAI）、Claude 3.5 Haiku（Anthropic）和Gemini 2.5 Flash（Google），在高语境和低语境提示条件下。修复效果从编译能力、编辑距离以及保留学生的原始结构和逻辑方面进行了评估。我们发现，虽然所有三个LLM都能生成可编译的修复，但在保留学生的控制流和代码结构方面的行为差异影响了它们的教学价值。通过恢复无法编译的提交，本研究使对学习者编程过程及其随时间发展的更丰富、更全面的分析成为可能。', 'title_zh': '自动修复无法编译的学生代码'}
{'arxiv_id': 'arXiv:2510.06186', 'title': 'RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback', 'authors': 'Chunyu Miao, Henry Peng Zou, Yangning Li, Yankai Chen, Yibo Wang, Fangxin Wang, Yifan Li, Wooseong Yang, Bowei He, Xinni Zhang, Dianzhi Yu, Hanchen Yang, Hoang H Nguyen, Yue Zhou, Jie Yang, Jizhou Guo, Wenzhe Fan, Chin-Yuan Yeh, Panpan Meng, Liancheng Fang, Jinhu Qi, Wei-Chieh Huang, Zhengyao Gu, Yuwei Han, Langzhou He, Yuyao Yang, Xue Liu, Irwin King, Philip S. Yu', 'link': 'https://arxiv.org/abs/2510.06186', 'abstract': 'Large language models (LLMs) show the promise in supporting scientific research implementation, yet their ability to generate correct and executable code remains limited. Existing works largely adopt one-shot settings, ignoring the iterative and feedback-driven nature of realistic workflows of scientific research development. To address this gap, we present RECODE-H, a benchmark of 102 tasks from research papers and repositories that evaluates LLM agents through multi-turn interactions with LLM-simulated human feedback. It includes structured instructions,unit tests, and a five-level feedback hierarchy to reflect realistic researcher-agent collaboration. We further present ReCodeAgent, a framework that integrates feedback into iterative code generation. Experiments with leading LLMs, including GPT-5, Claude-Sonnet-4, DeepSeek-V3.1, and Gemini 2.5, show substantial performance gains with richer feedback, while also highlighting ongoing challenges in the generation of complex research code. RECODE-H establishes a foundation for developing adaptive, feedback-driven LLM agents in scientific research implementation', 'abstract_zh': '大型语言模型在支持科学研究实施方面展现出潜力，但在生成正确可执行代码方面仍有限制。现有工作主要采用一次性设置，忽视了科学研究开发中迭代和基于反馈的自然流程。为解决这一差距，我们提出了RECODE-H，该基准包括102项来自研究论文和仓库的任务，通过与大规模人类反馈模拟的多轮交互评估语言模型代理，其中包括结构化指令、单元测试和五级反馈层次，以反映现实的研究员-代理协作。我们进一步提出了ReCodeAgent框架，该框架将反馈整合到迭代代码生成中。使用包括GPT-5、Claude-Sonnet-4、DeepSeek-V3.1和Gemini 2.5在内的领先语言模型的实验显示，丰富的反馈带来了显著的性能提升，同时也揭示了生成复杂研究代码的持续挑战。RECODE-H为开发适应性和基于反馈的科学实施语言模型代理奠定了基础。', 'title_zh': 'RECODE-H：一种带有交互式人类反馈的研究代码开发基准'}
{'arxiv_id': 'arXiv:2510.06170', 'title': 'Smartphone-based iris recognition through high-quality visible-spectrum iris image capture.V2', 'authors': 'Naveenkumar G Venkataswamy, Yu Liu, Soumyabrata Dey, Stephanie Schuckers, Masudul H Imtiaz', 'link': 'https://arxiv.org/abs/2510.06170', 'abstract': 'Smartphone-based iris recognition in the visible spectrum (VIS) remains difficult due to illumination variability, pigmentation differences, and the absence of standardized capture controls. This work presents a compact end-to-end pipeline that enforces ISO/IEC 29794-6 quality compliance at acquisition and demonstrates that accurate VIS iris recognition is feasible on commodity devices. Using a custom Android application performing real-time framing, sharpness evaluation, and feedback, we introduce the CUVIRIS dataset of 752 compliant images from 47 subjects. A lightweight MobileNetV3-based multi-task segmentation network (LightIrisNet) is developed for efficient on-device processing, and a transformer matcher (IrisFormer) is adapted to the VIS domain. Under a standardized protocol and comparative benchmarking against prior CNN baselines, OSIRIS attains a TAR of 97.9% at FAR=0.01 (EER=0.76%), while IrisFormer, trained only on UBIRIS.v2, achieves an EER of 0.057% on CUVIRIS. The acquisition app, trained models, and a public subset of the dataset are released to support reproducibility. These results confirm that standardized capture and VIS-adapted lightweight models enable accurate and practical iris recognition on smartphones.', 'abstract_zh': '基于可见光谱的智能手机虹膜识别仍因照明变化、色素差异和缺乏标准化捕获控制而具有挑战性。本工作提出了一种紧凑的端到端管道，确保捕获过程符合ISO/IEC 29794-6质量标准，并证明在消费级设备上实现准确的可见光谱虹膜识别是可行的。', 'title_zh': '基于智能手机的高质量可见光谱虹膜图像捕获虹膜识别V2'}
{'arxiv_id': 'arXiv:2510.06151', 'title': 'LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design for Heterogeneous Agent Teams', 'authors': 'Aju Ani Justus, Chris Baber', 'link': 'https://arxiv.org/abs/2510.06151', 'abstract': 'A critical challenge in modelling Heterogeneous-Agent Teams is training agents to collaborate with teammates whose policies are inaccessible or non-stationary, such as humans. Traditional approaches rely on expensive human-in-the-loop data, which limits scalability. We propose using Large Language Models (LLMs) as policy-agnostic human proxies to generate synthetic data that mimics human decision-making. To evaluate this, we conduct three experiments in a grid-world capture game inspired by Stag Hunt, a game theory paradigm that balances risk and reward. In Experiment 1, we compare decisions from 30 human participants and 2 expert judges with outputs from LLaMA 3.1 and Mixtral 8x22B models. LLMs, prompted with game-state observations and reward structures, align more closely with experts than participants, demonstrating consistency in applying underlying decision criteria. Experiment 2 modifies prompts to induce risk-sensitive strategies (e.g. "be risk averse"). LLM outputs mirror human participants\' variability, shifting between risk-averse and risk-seeking behaviours. Finally, Experiment 3 tests LLMs in a dynamic grid-world where the LLM agents generate movement actions. LLMs produce trajectories resembling human participants\' paths. While LLMs cannot yet fully replicate human adaptability, their prompt-guided diversity offers a scalable foundation for simulating policy-agnostic teammates.', 'abstract_zh': '异质代理团队建模中的关键挑战是训练能够与政策不可访问或非稳定（如人类）的队友协作的代理。传统方法依赖昂贵的人在环数据，这限制了可扩展性。我们提出使用大语言模型（LLMs）作为政策无关的人类代理来生成模拟人类决策的数据。为此，我们在一个基于猎 stag 捕捉游戏的网格世界中进行了三项实验，该游戏借鉴了博弈论中的猎 stag 模型，平衡了风险与奖励。实验 1 将来自 30 名人类参与者和 2 名专家裁判的决策与 LLaMA 3.1 和 Mixtral 8x22B 模型的输出进行比较。在被提示游戏状态观察和奖励结构后，LLMs 的输出与专家更一致，表现出一致的应用决策标准。实验 2 修改提示以诱导风险敏感策略（如“规避风险”）。LLM 的输出反映了人类参与者的变异性，在规避风险和寻求风险之间切换。最后，实验 3 在一个动态网格世界中测试了 LLMS，LLM 代理生成了移动动作。LLM 生成的轨迹类似于人类参与者的路径。虽然 LLMS 无法完全复制人类的适应性，但它们的提示引导多样性为模拟政策无关的队友提供了可扩展的基础。', 'title_zh': 'LLMs作为无政策偏见的队友：异构代理团队中的人类代理设计案例研究'}
{'arxiv_id': 'arXiv:2510.06145', 'title': 'Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images', 'authors': 'Aditya Prakash, David Forsyth, Saurabh Gupta', 'link': 'https://arxiv.org/abs/2510.06145', 'abstract': 'We tackle the problem of forecasting bimanual 3D hand motion & articulation from a single image in everyday settings. To address the lack of 3D hand annotations in diverse settings, we design an annotation pipeline consisting of a diffusion model to lift 2D hand keypoint sequences to 4D hand motion. For the forecasting model, we adopt a diffusion loss to account for the multimodality in hand motion distribution. Extensive experiments across 6 datasets show the benefits of training on diverse data with imputed labels (14% improvement) and effectiveness of our lifting (42% better) & forecasting (16.4% gain) models, over the best baselines, especially in zero-shot generalization to everyday images.', 'abstract_zh': '我们解决了一种在日常场景中从单张图像预测双手三维手部运动与articulation的问题。为了解决各种场景下缺少3D手部注释的问题，我们设计了一种注释管道，其中包括一个扩散模型将2D手部关键点序列提升到4D手部运动。在预测模型中，我们采用了扩散损失来考虑手部运动分布的多模态性。在6个数据集上的广泛实验表明，使用具有填充标签的多样数据训练（性能提升14%）以及我们提出的提升（性能提升42%）和预测（性能提升16.4%）模型的有效性，尤其是在零样本泛化到日常图像方面的表现尤为突出。', 'title_zh': '双手三维手部运动与articulation预测在日常图像中'}
{'arxiv_id': 'arXiv:2510.06138', 'title': 'Multi-Task Reinforcement Learning with Language-Encoded Gated Policy Networks', 'authors': 'Rushiv Arora', 'link': 'https://arxiv.org/abs/2510.06138', 'abstract': 'Multi-task reinforcement learning often relies on task metadata -- such as brief natural-language descriptions -- to guide behavior across diverse objectives. We present Lexical Policy Networks (LEXPOL), a language-conditioned mixture-of-policies architecture for multi-task RL. LEXPOL encodes task metadata with a text encoder and uses a learned gating module to select or blend among multiple sub-policies, enabling end-to-end training across tasks. On MetaWorld benchmarks, LEXPOL matches or exceeds strong multi-task baselines in success rate and sample efficiency, without task-specific retraining. To analyze the mechanism, we further study settings with fixed expert policies obtained independently of the gate and show that the learned language gate composes these experts to produce behaviors appropriate to novel task descriptions and unseen task combinations. These results indicate that natural-language metadata can effectively index and recombine reusable skills within a single policy.', 'abstract_zh': '基于词法的策略网络：面向多任务 reinforcement learning 的语言调节混合策略架构', 'title_zh': '基于语言编码门控策略网络的多任务强化学习'}
{'arxiv_id': 'arXiv:2510.06133', 'title': 'CreditDecoding: Accelerating Parallel Decoding in Diffusion Large Language Models with Trace Credits', 'authors': 'Kangyu Wang, Zhiyun Jiang, Haibo Feng, Weijia Zhao, Lin Liu, Jianguo Li, Zhenzhong Lan, Weiyao Lin', 'link': 'https://arxiv.org/abs/2510.06133', 'abstract': "Diffusion large language models (dLLMs) generate text through iterative denoising steps, achieving parallel decoding by denoising only high-confidence positions at each step. However, existing approaches often repetitively remask tokens due to initially low confidence scores, leading to redundant iterations and limiting overall acceleration. Through the analysis of dLLM decoding traces, we observe that the model often determines the final prediction for a token several steps before the decoding step. To leverage this historical information and avoid redundant steps, we introduce the concept of Trace Credit, which quantifies each token's convergence potential by accumulating historical logits. Furthermore, we propose CreditDecoding, a training-free parallel decoding algorithm that accelerates the confidence convergence of correct but underconfident tokens by fusing current logits with Trace Credit. This process significantly reduces redundant iterations and enhances decoding robustness. On eight benchmarks, CreditDecoding achieves a 5.48 times speedup and a 0.48 performance improvement over LLaDA-8B-Instruct, and a 4.11 times speedup with a 0.15 performance improvement over LLaDA-MoE-Instruct. Importantly, CreditDecoding scales effectively to long sequences and is orthogonal to mainstream inference optimizations, making it a readily integrable and versatile solution.", 'abstract_zh': '基于轨迹信用的加速平行解码算法', 'title_zh': 'CreditDecoding: 在扩散大语言模型中加速并行解码的追踪信用方法'}
{'arxiv_id': 'arXiv:2510.06131', 'title': 'Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation', 'authors': 'Jiawei Mao, Yuhan Wang, Lifeng Chen, Can Zhao, Yucheng Tang, Dong Yang, Liangqiong Qu, Daguang Xu, Yuyin Zhou', 'link': 'https://arxiv.org/abs/2510.06131', 'abstract': 'Recent advances in generative medical models are constrained by modality-specific scenarios that hinder the integration of complementary evidence from imaging, pathology, and clinical notes. This fragmentation limits their evolution into foundation models that can learn and reason across the full spectrum of biomedical data. We propose MeDiM, the first medical discrete diffusion model that learns shared distributions across modalities without modality-specific components. MeDiM unifies multiple generative tasks: translating between images and text, and jointly producing image-report pairs across domains in response to prompts. Built on a discrete diffusion framework, MeDiM bridges vision and language representations through a shared probabilistic space. To enable unified and flexible medical generation, we employ a multimodal large language model (MLLM) as the diffusion backbone, leveraging its prior knowledge and cross-modal reasoning. Two key designs are introduced: (1) removing the causal attention mask for bidirectional context, and (2) injecting continuous timestep embeddings for diffusion awareness. Experiments demonstrate high-fidelity medical generation (FID 16.60 on MIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR 0.2650 and 0.2580). Jointly generated image-report pairs further enhance downstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2, plus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports coherent and clinically grounded multimodal outputs.', 'abstract_zh': 'Recent Advances in Generative Medical Models Are Constrained by Modality-Specific Scenarios That Hinder the Integration of Complementary Evidence from Imaging, Pathology, and Clinical Notes', 'title_zh': '离散扩散模型结合MLLMs的统一医学多模态生成'}
{'arxiv_id': 'arXiv:2510.06107', 'title': 'Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models', 'authors': 'Gagan Bhatia, Somayajulu G Sripada, Kevin Allan, Jacobo Azcona', 'link': 'https://arxiv.org/abs/2510.06107', 'abstract': "Large Language Models (LLMs) are prone to hallucination, the generation of plausible yet factually incorrect statements. This work investigates the intrinsic, architectural origins of this failure mode through three primary this http URL, to enable the reliable tracing of internal semantic failures, we propose \\textbf{Distributional Semantics Tracing (DST)}, a unified framework that integrates established interpretability techniques to produce a causal map of a model's reasoning, treating meaning as a function of context (distributional semantics). Second, we pinpoint the model's layer at which a hallucination becomes inevitable, identifying a specific \\textbf{commitment layer} where a model's internal representations irreversibly diverge from factuality. Third, we identify the underlying mechanism for these failures. We observe a conflict between distinct computational pathways, which we interpret using the lens of dual-process theory: a fast, heuristic \\textbf{associative pathway} (akin to System 1) and a slow, deliberate \\textbf{contextual pathway} (akin to System 2), leading to predictable failure modes such as \\textit{Reasoning Shortcut Hijacks}. Our framework's ability to quantify the coherence of the contextual pathway reveals a strong negative correlation ($\\rho = -0.863$) with hallucination rates, implying that these failures are predictable consequences of internal semantic weakness. The result is a mechanistic account of how, when, and why hallucinations occur within the Transformer architecture.", 'abstract_zh': '大型语言模型（LLMs）容易出现幻觉，即生成看似合理但实际上不正确的语句。本研究通过三个方面探索这种失败模式的内在、架构根源，以实现内部语义失败的可靠追踪，我们提出了一种名为**分布语义追踪（DST）**的统一框架，结合现有的解释性技术，生成模型推理的因果图谱，将意义视为上下文的函数（分布语义）。第二，我们确定了模型中导致幻觉不可避免的层级，指出了一个特定的**承诺层**，在那里模型的内部表示不可逆地脱离了事实性。第三，我们识别了这些失败的根本机制。我们观察到不同计算路径之间的冲突，并通过双重过程理论这一视角进行解释：一种快速的启发式**联想路径**（类似于系统1）和一种缓慢的、刻意的**上下文路径**（类似于系统2），导致可预测的失败模式，如**推理捷径劫持**。我们框架对上下文路径一致性的量化揭示了与幻觉率之间存在强烈的负相关（$\\rho = -0.863$），暗示这些失败是内部语义薄弱的可预测后果。结果提供了一种机制性解释，说明了Transformer架构中幻觉发生的时间、条件和原因。', 'title_zh': '分布语义追踪：一种解释大规模语言模型幻觉的框架'}
{'arxiv_id': 'arXiv:2510.06090', 'title': 'A public cardiac CT dataset featuring the left atrial appendage', 'authors': 'Bjoern Hansen, Jonas Pedersen, Klaus F. Kofoed, Oscar Camara, Rasmus R. Paulsen, Kristine Soerensen', 'link': 'https://arxiv.org/abs/2510.06090', 'abstract': "Despite the success of advanced segmentation frameworks such as TotalSegmentator (TS), accurate segmentations of the left atrial appendage (LAA), coronary arteries (CAs), and pulmonary veins (PVs) remain a significant challenge in medical imaging. In this work, we present the first open-source, anatomically coherent dataset of curated, high-resolution segmentations for these structures, supplemented with whole-heart labels produced by TS on the publicly available ImageCAS dataset consisting of 1000 cardiac computed tomography angiography (CCTA) scans. One purpose of the data set is to foster novel approaches to the analysis of LAA morphology.\nLAA segmentations on ImageCAS were generated using a state-of-the-art segmentation framework developed specifically for high resolution LAA segmentation. We trained the network on a large private dataset with manual annotations provided by medical readers guided by a trained cardiologist and transferred the model to ImageCAS data. CA labels were improved from the original ImageCAS annotations, while PV segmentations were refined from TS outputs. In addition, we provide a list of scans from ImageCAS that contains common data flaws such as step artefacts, LAAs extending beyond the scanner's field of view, and other types of data defects.", 'abstract_zh': '尽管先进的分割框架如TotalSegmentator（TS）取得了一定的成功，但在医学影像中准确分割左心房附壁（LAA）、冠状动脉（CAs）和肺动脉（PVs）仍是一项重大挑战。在本文中，我们介绍了首个开源且解剖学一致的数据集，该数据集包含经过精心策划的高分辨率分割标注，伴有通过TS对公开可用的ImageCAS数据集（包含1000例心脏计算机断层扫描冠状动脉成像扫描）生成的全心标注。数据集的一个目的是促进对LAA形态学分析的新方法的研究。LAA分割是在专门针对高分辨率LAA分割开发的最先进的分割框架下生成的。我们使用由训练有素的心脏病专家指导的医学读者提供的手动注释在大型私有数据集上对网络进行训练，并将模型转移到ImageCAS数据上。冠状动脉（CAs）标签在原有ImageCAS注释的基础上进行了改进，而肺动脉（PV）分割则基于TS的输出进行了细化。此外，我们还列出了ImageCAS数据集中常见的数据缺陷，如阶梯伪影、LAA超出扫描仪视野范围及其他类型的数据缺陷。', 'title_zh': '一个包含左心耳特征的公共心脏CT数据集'}
{'arxiv_id': 'arXiv:2510.06084', 'title': 'Spectrum Tuning: Post-Training for Distributional Coverage and In-Context Steerability', 'authors': 'Taylor Sorensen, Benjamin Newman, Jared Moore, Chan Park, Jillian Fisher, Niloofar Mireshghallah, Liwei Jiang, Yejin Choi', 'link': 'https://arxiv.org/abs/2510.06084', 'abstract': "Language model post-training has enhanced instruction-following and performance on many downstream tasks, but also comes with an often-overlooked cost on tasks with many possible valid answers. We characterize three desiderata for conditional distributional modeling: in-context steerability, valid output space coverage, and distributional alignment, and document across three model families how current post-training can reduce these properties. In particular, we disambiguate between two kinds of in-context learning: ICL for eliciting existing underlying knowledge or capabilities, and in-context steerability, where a model must use in-context information to override its priors and steer to a novel data generating distribution. To better evaluate and improve these desiderata, we introduce Spectrum Suite, a large-scale resource compiled from >40 data sources and spanning >90 tasks requiring models to steer to and match diverse distributions ranging from varied human preferences to numerical distributions and more. We find that while current post-training techniques help elicit underlying capabilities and knowledge, they hurt models' ability to flexibly steer in-context. To mitigate these issues, we propose Spectrum Tuning, a post-training method using Spectrum Suite to improve steerability and distributional coverage. We find that Spectrum Tuning often improves over pretrained models and their instruction-tuned counterparts, enhancing steerability, spanning more of the output space, and improving distributional alignment on held-out datasets.", 'abstract_zh': '语言模型后训练增强了指令跟随和许多下游任务的表现，但也往往在有多种可能正确答案的任务中降低了某些未被充分关注的成本。我们定义了条件概率模型的三个期望特性：上下文引导性、有效输出空间覆盖和分布对齐，并记录了当前后训练方法如何降低这些特性。特别是，我们将上下文学习区分为两种类型：用于激活现有潜在知识或能力的ICL，以及上下文引导性，即模型必须使用上下文信息克服先验知识并转向新颖的数据生成分布。为了更好地评估和改进这些期望特性，我们引入了光谱套装，这是一个大型资源库，汇集了来自超过40个数据源的数据，并涵盖了超过90个任务，要求模型引导和匹配从各种人类偏好到数值分布等多样的分布。我们发现，虽然当前的后训练技术有助于激活潜在能力和知识，但却损害了模型在上下文中灵活引导的能力。为缓解这些问题，我们提出了光谱调优，这是一种使用光谱套装改进引导性和分布覆盖的后训练方法。我们在保留集数据上发现，光谱调优通常优于预训练模型及其指令调优版本，增强了引导性，覆盖了更多的输出空间，并在分布对齐方面有所提升。', 'title_zh': '谱调谐：训练后处理以实现分布覆盖和上下文可引导性'}
{'arxiv_id': 'arXiv:2510.06077', 'title': 'When Thinking Drifts: Evidential Grounding for Robust Video Reasoning', 'authors': 'Mi Luo, Zihui Xue, Alex Dimakis, Kristen Grauman', 'link': 'https://arxiv.org/abs/2510.06077', 'abstract': 'Video reasoning, the task of enabling machines to infer from dynamic visual content through multi-step logic, is crucial for advanced AI. While the Chain-of-Thought (CoT) mechanism has enhanced reasoning in text-based tasks, its application to video understanding remains underexplored. This paper presents a systematic analysis revealing that CoT often degrades performance in video reasoning, generating verbose but misleading internal monologues, and leading to hallucinated visual details and overridden correct intuitions - a phenomenon we term "visual thinking drift". We explain this drift through a Bayesian lens, positing that CoT traces often diverge from actual visual evidence, instead amplifying internal biases or language priors, causing models to storytell rather than engage in grounded reasoning. To counteract this, we introduce Visual Evidence Reward (VER), a novel reinforcement learning framework that explicitly rewards the generation of reasoning traces that are verifiably grounded in visual evidence. Comprehensive evaluation across 10 diverse video understanding benchmarks demonstrates that our Video-VER consistently achieves top performance. Our work sheds light on the distinct challenges of video-centric reasoning and encourages the development of AI that robustly grounds its inferences in visual evidence - for large multimodal models that not only "think before answering", but also "see while thinking".', 'abstract_zh': '基于视觉的联想推理：一种新的强化学习框架VER及其应用', 'title_zh': '思维漂移：稳健视频推理的证据接地'}
{'arxiv_id': 'arXiv:2510.06071', 'title': 'Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks', 'authors': 'João Palmeiro, Diogo Duarte, Rita Costa, Pedro Bizarro', 'link': 'https://arxiv.org/abs/2510.06071', 'abstract': "AI models are increasingly used for data analysis and visualization, yet benchmarks rarely address scatterplot-specific tasks, limiting insight into performance. To address this gap for one of the most common chart types, we introduce a synthetic, annotated dataset of over 18,000 scatterplots from six data generators and 17 chart designs, and a benchmark based on it. We evaluate proprietary models from OpenAI and Google using N-shot prompting on five distinct tasks derived from annotations of cluster bounding boxes, their center coordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash, especially when prompted with examples, are viable options for counting clusters and, in Flash's case, outliers (90%+ Accuracy). However, the results for localization-related tasks are unsatisfactory: Precision and Recall are near or below 50%, except for Flash in outlier identification (65.01%). Furthermore, the impact of chart design on performance appears to be a secondary factor, but it is advisable to avoid scatterplots with wide aspect ratios (16:9 and 21:9) or those colored randomly. Supplementary materials are available at this https URL.", 'abstract_zh': 'AI模型在数据可视化中的合成注释散点图数据集与基准测试：以散点图特定任务为主的漏洞填补', 'title_zh': '自行基准测试（BIY）：准备数据集并评估散点图相关任务的AI模型'}
{'arxiv_id': 'arXiv:2510.06068', 'title': 'Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning', 'authors': 'Heng Zhang, Kevin Yuchen Ma, Mike Zheng Shou, Weisi Lin, Yan Wu', 'link': 'https://arxiv.org/abs/2510.06068', 'abstract': "Dexterous grasping with multi-fingered hands remains challenging due to high-dimensional articulations and the cost of optimization-based pipelines. Existing end-to-end methods require training on large-scale datasets for specific hands, limiting their ability to generalize across different embodiments. We propose an eigengrasp-based, end-to-end framework for cross-embodiment grasp generation. From a hand's morphology description, we derive a morphology embedding and an eigengrasp set. Conditioned on these, together with the object point cloud and wrist pose, an amplitude predictor regresses articulation coefficients in a low-dimensional space, which are decoded into full joint articulations. Articulation learning is supervised with a Kinematic-Aware Articulation Loss (KAL) that emphasizes fingertip-relevant motions and injects morphology-specific structure. In simulation on unseen objects across three dexterous hands, our model attains a 91.9% average grasp success rate with less than 0.4 seconds inference per grasp. With few-shot adaptation to an unseen hand, it achieves 85.6% success on unseen objects in simulation, and real-world experiments on this few-shot generalized hand achieve an 87% success rate. The code and additional materials will be made available upon publication on our project website this https URL.", 'abstract_zh': '基于本征抓取的跨体态端到端抓取生成框架', 'title_zh': '基于形态意识学习的跨体态灵巧手关节生成'}
{'arxiv_id': 'arXiv:2510.06067', 'title': 'Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA', 'authors': 'Python Song, Luke Tenyi Chang, Yun-Yun Tsai, Penghui Li, Junfeng Yang', 'link': 'https://arxiv.org/abs/2510.06067', 'abstract': 'CAPTCHA, originally designed to distinguish humans from robots, has evolved into a real-world benchmark for assessing the spatial reasoning capabilities of vision-language models. In this work, we first show that step-by-step reasoning is crucial for vision-language models (VLMs) to solve CAPTCHAs, which represent high-difficulty spatial reasoning tasks, and that current commercial vision-language models still struggle with such reasoning. In particular, we observe that most commercial VLMs (e.g., Gemini, Claude, GPT, etc.) fail to effectively solve CAPTCHAs and thus achieve low accuracy (around 21.9 percent). However, our findings indicate that requiring the model to perform step-by-step reasoning before generating the final coordinates can significantly enhance its solving accuracy, underscoring the severity of the gap. To systematically study this issue, we introduce CAPTCHA-X, the first real-world CAPTCHA benchmark with reasoning, covering seven categories of CAPTCHAs (such as Gobang, hCaptcha, etc.) with step-by-step action solutions and grounding annotations. We further define five reasoning-oriented metrics that enable a comprehensive evaluation of models reasoning capabilities. To validate the effectiveness of reasoning, we also propose a general agentic VLM-based framework that incorporates the models inherent reasoning abilities. Our method achieves state-of-the-art performance across five high-difficulty CAPTCHA types, with an average solving accuracy of 83.9 percent, substantially surpassing existing baselines. These results reveal the limitations of current models and highlight the importance of reasoning in advancing visual-spatial challenges in the future.', 'abstract_zh': 'CAPTCHA：从区分人类与机器人到评估视觉-语言模型的空间推理能力', 'title_zh': '视觉中的推理：理解视觉-空间认知在验证码视觉语言模型中的作用'}
{'arxiv_id': 'arXiv:2510.06060', 'title': 'Controllable Audio-Visual Viewpoint Generation from 360° Spatial Information', 'authors': 'Christian Marinoni, Riccardo Fosco Gramaccioni, Eleonora Grassucci, Danilo Comminiello', 'link': 'https://arxiv.org/abs/2510.06060', 'abstract': 'The generation of sounding videos has seen significant advancements with the advent of diffusion models. However, existing methods often lack the fine-grained control needed to generate viewpoint-specific content from larger, immersive 360-degree environments. This limitation restricts the creation of audio-visual experiences that are aware of off-camera events. To the best of our knowledge, this is the first work to introduce a framework for controllable audio-visual generation, addressing this unexplored gap. Specifically, we propose a diffusion model by introducing a set of powerful conditioning signals derived from the full 360-degree space: a panoramic saliency map to identify regions of interest, a bounding-box-aware signed distance map to define the target viewpoint, and a descriptive caption of the entire scene. By integrating these controls, our model generates spatially-aware viewpoint videos and audios that are coherently influenced by the broader, unseen environmental context, introducing a strong controllability that is essential for realistic and immersive audio-visual generation. We show audiovisual examples proving the effectiveness of our framework.', 'abstract_zh': '基于扩散模型的可控音视频生成：填补视角特定内容生成的空白', 'title_zh': '从360°空间信息生成可控的音视频视角'}
{'arxiv_id': 'arXiv:2510.06046', 'title': 'GLVD: Guided Learned Vertex Descent', 'authors': 'Pol Caselles Rico, Francesc Moreno Noguer', 'link': 'https://arxiv.org/abs/2510.06046', 'abstract': 'Existing 3D face modeling methods usually depend on 3D Morphable Models, which inherently constrain the representation capacity to fixed shape priors. Optimization-based approaches offer high-quality reconstructions but tend to be computationally expensive. In this work, we introduce GLVD, a hybrid method for 3D face reconstruction from few-shot images that extends Learned Vertex Descent (LVD) by integrating per-vertex neural field optimization with global structural guidance from dynamically predicted 3D keypoints. By incorporating relative spatial encoding, GLVD iteratively refines mesh vertices without requiring dense 3D supervision. This enables expressive and adaptable geometry reconstruction while maintaining computational efficiency. GLVD achieves state-of-the-art performance in single-view settings and remains highly competitive in multi-view scenarios, all while substantially reducing inference time.', 'abstract_zh': '基于少量图像的3D人脸重建：GLVD方法及其应用', 'title_zh': 'GLVD: 引导式学习顶点下降'}
{'arxiv_id': 'arXiv:2510.06040', 'title': 'VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via Tree-based Group Relative Policy Optimization', 'authors': 'Xinye Cao, Hongcan Guo, Jiawen Qian, Guoshun Nan, Chao Wang, Yuqi Pan, Tianhao Hou, Xiaojuan Wang, Yutong Gao', 'link': 'https://arxiv.org/abs/2510.06040', 'abstract': 'Understanding hour-long videos with multi-modal large language models (MM-LLMs) enriches the landscape of human-centered AI applications. However, for end-to-end video understanding with LLMs, uniformly sampling video frames results in LLMs being overwhelmed by a vast amount of irrelevant information as video length increases. Existing hierarchical key frame extraction methods improve the accuracy of video understanding but still face two critical challenges. 1) How can the interference of extensive redundant information in long videos be mitigated? 2) How can a model dynamically adapt to complex hierarchical structures while accurately identifying key frames? To address these issues, we propose VideoMiner, which iteratively segments, captions, and clusters long videos, forming a hierarchical tree structure. The proposed VideoMiner progresses from long videos to events to frames while preserving temporal coherence, effectively addressing the first challenge. To precisely locate key frames, we introduce T-GRPO, a tree-based group relative policy optimization in reinforcement learning method that guides the exploration of the VideoMiner. The proposed T-GRPO is specifically designed for tree structures, integrating spatiotemporal information at the event level while being guided by the question, thus solving the second challenge. We achieve superior performance in all long-video understanding tasks and uncover several interesting insights. Our proposed T-GRPO surprisingly incentivizes the model to spontaneously generate a reasoning chain. Additionally, the designed tree growth auxin dynamically adjusts the expansion depth, obtaining accuracy and efficiency gains. The code is publicly available at this https URL.', 'abstract_zh': '利用多模态大规模语言模型（MM-LLMs）理解一小时长度的视频丰富了以人类为中心的AI应用图谱。然而，对于基于LLMs的端到端视频理解，均匀采样视频帧会导致随着视频长度增加，LLMs受到大量无关信息的困扰。现有分层关键帧提取方法提高了视频理解的准确性，但仍面临两个关键挑战：1）长视频中的大量冗余信息如何被减轻？2）模型如何动态适应复杂的分层结构并准确识别关键帧？为解决这些问题，我们提出了VideoMiner，该方法迭代地对齐、加字幕和聚类长视频，形成分层树结构。提出的VideoMiner从长视频到事件再到帧，同时保持时间连贯性，有效解决了第一个挑战。为了精确定位关键帧，我们引入了基于树结构的分组相对策略优化方法T-GRPO，指导VideoMiner的探索。提出的T-GRPO专门针对树结构，整合事件级别的时空信息，并由问题引导，从而解决了第二个挑战。我们在所有长视频理解任务中实现了优越的性能，并揭示了几项有趣的研究洞察。我们提出的T-GRPO意外地激励模型自发生成推理链。此外，所设计的树生长植物动态调整扩展深度，获得准确性和效率的提升。代码已公开，可通过以下链接获取。', 'title_zh': 'VideoMiner: 通过树基于组相对策略优化迭代定位小时长视频的关键帧'}
{'arxiv_id': 'arXiv:2510.06039', 'title': 'CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive Evaluation of Chinese LLMs', 'authors': 'Chengwei Wu, Jiapu Wang, Mingyang Gao, Xingrui Zhuo, Jipeng Guo, Runlin Lei, Haoran Luo, Tianyu Chen, Haoyi Zhou, Shirui Pan, Zechao Li', 'link': 'https://arxiv.org/abs/2510.06039', 'abstract': 'Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language processing tasks. However, Chinese LLMs face unique challenges, primarily due to the dominance of unstructured free text and the lack of structured representations in Chinese corpora. While existing benchmarks for LLMs partially assess Chinese LLMs, they are still predominantly English-centric and fail to address the unique linguistic characteristics of Chinese, lacking structured datasets essential for robust evaluation. To address these challenges, we present a Comprehensive Benchmark for Evaluating Chinese Large Language Models (CB-ECLLM) based on the newly constructed Chinese Data-Text Pair (CDTP) dataset. Specifically, CDTP comprises over 7 million aligned text pairs, each consisting of unstructured text coupled with one or more corresponding triples, alongside a total of 15 million triples spanning four critical domains. The core contributions of CDTP are threefold: (i) enriching Chinese corpora with high-quality structured information; (ii) enabling fine-grained evaluation tailored to knowledge-driven tasks; and (iii) supporting multi-task fine-tuning to assess generalization and robustness across scenarios, including Knowledge Graph Completion, Triple-to-Text generation, and Question Answering. Furthermore, we conduct rigorous evaluations through extensive experiments and ablation studies to assess the effectiveness, Supervised Fine-Tuning (SFT), and robustness of the benchmark. To support reproducible research, we offer an open-source codebase and outline potential directions for future investigations based on our insights.', 'abstract_zh': '全面评估中文大语言模型基准（CB-ECLLM）：基于新构建的中文数据-文本对（CDTP）数据集', 'title_zh': 'CDTP：大规模中文数据-文本配对数据集，用于综合评估中文LLMs'}
{'arxiv_id': 'arXiv:2510.06038', 'title': 'From Learning to Mastery: Achieving Safe and Efficient Real-World Autonomous Driving with Human-In-The-Loop Reinforcement Learning', 'authors': 'Li Zeqiao, Wang Yijing, Wang Haoyu, Li Zheng, Li Peng, Liu Wenfei, Zuo Zhiqiang', 'link': 'https://arxiv.org/abs/2510.06038', 'abstract': 'Autonomous driving with reinforcement learning (RL) has significant potential. However, applying RL in real-world settings remains challenging due to the need for safe, efficient, and robust learning. Incorporating human expertise into the learning process can help overcome these challenges by reducing risky exploration and improving sample efficiency. In this work, we propose a reward-free, active human-in-the-loop learning method called Human-Guided Distributional Soft Actor-Critic (H-DSAC). Our method combines Proxy Value Propagation (PVP) and Distributional Soft Actor-Critic (DSAC) to enable efficient and safe training in real-world environments. The key innovation is the construction of a distributed proxy value function within the DSAC framework. This function encodes human intent by assigning higher expected returns to expert demonstrations and penalizing actions that require human intervention. By extrapolating these labels to unlabeled states, the policy is effectively guided toward expert-like behavior. With a well-designed state space, our method achieves real-world driving policy learning within practical training times. Results from both simulation and real-world experiments demonstrate that our framework enables safe, robust, and sample-efficient learning for autonomous driving.', 'abstract_zh': '基于强化学习的自主驾驶有巨大潜力。然而，在实际应用中将其应用仍具挑战性，因为需要确保学习过程的安全、高效和鲁棒性。通过将人类专家的知识融入学习过程，可以降低风险探索并提高样本效率，从而应对这些挑战。在本工作中，我们提出了一种无奖励、主动的人在回路学习方法，名为Human-Guided Distributional Soft Actor-Critic（H-DSAC）。该方法结合了Proxy Value Propagation（PVP）和Distributional Soft Actor-Critic（DSAC），以在现实环境中实现高效和安全的训练。关键创新在于在DSAC框架内构建分布式代理价值函数。该函数通过为专家演示分配更高的预期回报并惩罚需要人工干预的动作，来编码人类意图。通过将这些标签外推到未标记状态下，该策略得到有效指导，朝着专家级行为方向发展。通过合理设计状态空间，我们的方法得以在实际训练时间内实现自主驾驶策略的学习。来自模拟和现实世界实验的结果表明，我们的框架能够实现自主驾驶的安全、鲁棒和样本高效的learning。', 'title_zh': '从学习到精通：通过人类在环强化学习实现安全高效的现实世界自动驾驶'}
{'arxiv_id': 'arXiv:2510.06029', 'title': 'Fast Leave-One-Out Approximation from Fragment-Target Prevalence Vectors (molFTP) : From Dummy Masking to Key-LOO for Leakage-Free Feature Construction', 'authors': 'Guillaume Godin', 'link': 'https://arxiv.org/abs/2510.06029', 'abstract': 'We introduce molFTP (molecular fragment-target prevalence), a compact representation that delivers strong predictive performance. To prevent feature leakage across cross-validation folds, we implement a dummy-masking procedure that removes information about fragments present in the held-out molecules. We further show that key leave-one-out (key-loo) closely approximates true molecule-level leave-one-out (LOO), with deviation below 8% on our datasets. This enables near full data training while preserving unbiased cross-validation estimates of model performance. Overall, molFTP provides a fast, leakage-resistant fragment-target prevalence vectorization with practical safeguards (dummy masking or key-LOO) that approximate LOO at a fraction of its cost.', 'abstract_zh': 'molFTP（分子片段-目标共现）：紧凑表示与强预测性能', 'title_zh': '快速的Leave-One-Out近似方法从片段-目标流行度向量（molFTP）：从虚拟掩蔽到关键Leave-One-Out以实现无泄漏特征构建'}
{'arxiv_id': 'arXiv:2510.06026', 'title': 'Emergent AI Surveillance: Overlearned Person Re-Identification and Its Mitigation in Law Enforcement Context', 'authors': 'An Thi Nguyen, Radina Stoykova, Eric Arazo', 'link': 'https://arxiv.org/abs/2510.06026', 'abstract': "Generic instance search models can dramatically reduce the manual effort required to analyze vast surveillance footage during criminal investigations by retrieving specific objects of interest to law enforcement. However, our research reveals an unintended emergent capability: through overlearning, these models can single out specific individuals even when trained on datasets without human subjects. This capability raises concerns regarding identification and profiling of individuals based on their personal data, while there is currently no clear standard on how de-identification can be achieved. We evaluate two technical safeguards to curtail a model's person re-identification capacity: index exclusion and confusion loss. Our experiments demonstrate that combining these approaches can reduce person re-identification accuracy to below 2% while maintaining 82% of retrieval performance for non-person objects. However, we identify critical vulnerabilities in these mitigations, including potential circumvention using partial person images. These findings highlight urgent regulatory questions at the intersection of AI governance and data protection: How should we classify and regulate systems with emergent identification capabilities? And what technical standards should be required to prevent identification capabilities from developing in seemingly benign applications?", 'abstract_zh': '通用实例搜索模型可以通过检索感兴趣的特定对象，大幅度减少在犯罪调查中分析大量监控视频所需的 manual 努力。然而，我们的研究揭示了一个意想不到的潜在能力：通过过拟合，即使在无人类主体的数据集上进行训练，这些模型也能识别特定的个人。这一能力引发了基于个人数据识别和 profiling 的关切，而目前尚无明确的标准来指导如何实现数据去识别化。我们评估了两种技术防护措施以限制模型的人员再识别能力：索引排除和混淆损失。我们的实验表明，将这些方法结合使用可以将人员再识别准确性降低至低于 2%，同时保持非人员对象检索性能的 82%。然而，我们识别出这些缓解措施中的关键脆弱性，包括利用部分人员图像进行规避的可能性。这些发现突显了人工智能治理和数据保护交汇处的紧迫监管问题：我们应该如何分类和监管具有潜在识别能力的系统？在看似无害的应用中，应采取何种技术标准来防止识别能力的发展？', 'title_zh': 'emergent AI监控：过度学习的人重识别及其在执法情境中的缓解'}
{'arxiv_id': 'arXiv:2510.06010', 'title': 'Hybrid Quantum-Classical Policy Gradient for Adaptive Control of Cyber-Physical Systems: A Comparative Study of VQC vs. MLP', 'authors': 'Aueaphum Aueawatthanaphisut, Nyi Wunna Tun', 'link': 'https://arxiv.org/abs/2510.06010', 'abstract': 'The comparative evaluation between classical and quantum reinforcement learning (QRL) paradigms was conducted to investigate their convergence behavior, robustness under observational noise, and computational efficiency in a benchmark control environment. The study employed a multilayer perceptron (MLP) agent as a classical baseline and a parameterized variational quantum circuit (VQC) as a quantum counterpart, both trained on the CartPole-v1 environment over 500 episodes. Empirical results demonstrated that the classical MLP achieved near-optimal policy convergence with a mean return of 498.7 +/- 3.2, maintaining stable equilibrium throughout training. In contrast, the VQC exhibited limited learning capability, with an average return of 14.6 +/- 4.8, primarily constrained by circuit depth and qubit connectivity. Noise robustness analysis further revealed that the MLP policy deteriorated gracefully under Gaussian perturbations, while the VQC displayed higher sensitivity at equivalent noise levels. Despite the lower asymptotic performance, the VQC exhibited significantly lower parameter count and marginally increased training time, highlighting its potential scalability for low-resource quantum processors. The results suggest that while classical neural policies remain dominant in current control benchmarks, quantum-enhanced architectures could offer promising efficiency advantages once hardware noise and expressivity limitations are mitigated.', 'abstract_zh': '经典和量子强化学习（QRL）范式的比较评价：探究其在基准控制环境中的收敛行为、观测噪声下的鲁棒性和计算效率。', 'title_zh': '杂合量子-经典策略梯度在拟合物理系统自适应控制中的比较研究：基于VQC与MLP的对比'}
{'arxiv_id': 'arXiv:2510.06008', 'title': 'Detection and Measurement of Hailstones with Multimodal Large Language Models', 'authors': 'Moritz Alker, David C. Schedl, Andreas Stöckl', 'link': 'https://arxiv.org/abs/2510.06008', 'abstract': 'This study examines the use of social media and news images to detect and measure hailstones, utilizing pre-trained multimodal large language models. The dataset for this study comprises 474 crowdsourced images of hailstones from documented hail events in Austria, which occurred between January 2022 and September 2024. These hailstones have maximum diameters ranging from 2 to 11cm. We estimate the hail diameters and compare four different models utilizing one-stage and two-stage prompting strategies. The latter utilizes additional size cues from reference objects, such as human hands, within the image. Our results show that pretrained models already have the potential to measure hailstone diameters from images with an average mean absolute error of 1.12cm for the best model. In comparison to a single-stage prompt, two-stage prompting improves the reliability of most models. Our study suggests that these off-the-shelf models, even without fine-tuning, can complement traditional hail sensors by extracting meaningful and spatially dense information from social media imagery, enabling faster and more detailed assessments of severe weather events. The automated real-time image harvesting from social media and other sources remains an open task, but it will make our approach directly applicable to future hail events.', 'abstract_zh': '本研究利用预训练多模态大语言模型检测和测量 hailstone，分析社交媒体和新闻图片中的 hailstone 图像。该研究的数据集包含来自 2022 年 1 月至 2024 年 9 月奥地利记录的 hailstone 事件的 474 张众包 hailstone 图片，直径范围从 2 cm 至 11 cm。我们估计 hailstone 直径并利用一阶段和两阶段提示策略分别进行了四种不同模型的评估。后者借助图像中参考物体（如人类手掌）的大小线索来提高模型性能。结果显示，预训练模型已具备从图像中测量 hailstone 直径的潜力，最佳模型的平均绝对误差为 1.12 cm。与一阶段提示相比，两阶段提示策略在大多数模型中提高了可靠性。本研究表明，这些即用型模型即使未经微调，也能通过社交媒体图像提取有意义且空间密集的信息，从而加快和细化对极端天气事件的评估。社交媒体等源的自动实时图像获取仍是待解决的问题，但将使我们的方法直接适用于未来的 hailstone 事件。', 'title_zh': '使用多模态大型语言模型探测和测量 hailstones'}
{'arxiv_id': 'arXiv:2510.05984', 'title': 'ECTSpeech: Enhancing Efficient Speech Synthesis via Easy Consistency Tuning', 'authors': 'Tao Zhu, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng', 'link': 'https://arxiv.org/abs/2510.05984', 'abstract': "Diffusion models have demonstrated remarkable performance in speech synthesis, but typically require multi-step sampling, resulting in low inference efficiency. Recent studies address this issue by distilling diffusion models into consistency models, enabling efficient one-step generation. However, these approaches introduce additional training costs and rely heavily on the performance of pre-trained teacher models. In this paper, we propose ECTSpeech, a simple and effective one-step speech synthesis framework that, for the first time, incorporates the Easy Consistency Tuning (ECT) strategy into speech synthesis. By progressively tightening consistency constraints on a pre-trained diffusion model, ECTSpeech achieves high-quality one-step generation while significantly reducing training complexity. In addition, we design a multi-scale gate module (MSGate) to enhance the denoiser's ability to fuse features at different scales. Experimental results on the LJSpeech dataset demonstrate that ECTSpeech achieves audio quality comparable to state-of-the-art methods under single-step sampling, while substantially reducing the model's training cost and complexity.", 'abstract_zh': 'ECTSpeech：一种结合Easy Consistency Tuning策略的一步声学合成框架', 'title_zh': 'ECTSpeech: 通过简单的-consistency调优提升高效语音合成'}
{'arxiv_id': 'arXiv:2510.05976', 'title': 'Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis', 'authors': 'Eashan Adhikarla, Yixin Liu, Brian D. Davison', 'link': 'https://arxiv.org/abs/2510.05976', 'abstract': 'Low-light image enhancement (LLIE) is vital for safety-critical applications such as surveillance, autonomous navigation, and medical imaging, where visibility degradation can impair downstream task performance. Recently, diffusion models have emerged as a promising generative paradigm for LLIE due to their capacity to model complex image distributions via iterative denoising. This survey provides an up-to-date critical analysis of diffusion models for LLIE, distinctively featuring an in-depth comparative performance evaluation against Generative Adversarial Network and Transformer-based state-of-the-art methods, a thorough examination of practical deployment challenges, and a forward-looking perspective on the role of emerging paradigms like foundation models. We propose a multi-perspective taxonomy encompassing six categories: Intrinsic Decomposition, Spectral & Latent, Accelerated, Guided, Multimodal, and Autonomous; that map enhancement methods across physical priors, conditioning schemes, and computational efficiency. Our taxonomy is grounded in a hybrid view of both the model mechanism and the conditioning signals. We evaluate qualitative failure modes, benchmark inconsistencies, and trade-offs between interpretability, generalization, and inference efficiency. We also discuss real-world deployment constraints (e.g., memory, energy use) and ethical considerations. This survey aims to guide the next generation of diffusion-based LLIE research by highlighting trends and surfacing open research questions, including novel conditioning, real-time adaptation, and the potential of foundation models.', 'abstract_zh': '低光照图像增强中的扩散模型综述：与生成对抗网络和基于Transformer的先进方法的深入性能比较、实际部署挑战的全面 examination 以及新兴范式（如基础模型）的作用展望', 'title_zh': '低光照图像增强的扩散模型：多视角分类与性能分析'}
{'arxiv_id': 'arXiv:2510.05972', 'title': 'LexiCon: a Benchmark for Planning under Temporal Constraints in Natural Language', 'authors': 'Periklis Mantenoglou, Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt', 'link': 'https://arxiv.org/abs/2510.05972', 'abstract': 'Owing to their reasoning capabilities, large language models (LLMs) have been evaluated on planning tasks described in natural language. However, LLMs have largely been tested on planning domains without constraints. In order to deploy them in real-world settings where adherence to constraints, in particular safety constraints, is critical, we need to evaluate their performance on constrained planning tasks. We introduce LexiCon -- a natural language-based (Lexi) constrained (Con) planning benchmark, consisting of a suite of environments, that can be used to evaluate the planning capabilities of LLMs in a principled fashion. The core idea behind LexiCon is to take existing planning environments and impose temporal constraints on the states. These constrained problems are then translated into natural language and given to an LLM to solve. A key feature of LexiCon is its extensibility. That is, the set of supported environments can be extended with new (unconstrained) environment generators, for which temporal constraints are constructed automatically. This renders LexiCon future-proof: the hardness of the generated planning problems can be increased as the planning capabilities of LLMs improve. Our experiments reveal that the performance of state-of-the-art LLMs, including reasoning models like GPT-5, o3, and R1, deteriorates as the degree of constrainedness of the planning tasks increases.', 'abstract_zh': '基于自然语言的约束规划基准LexiCon：评估大型语言模型的约束规划能力', 'title_zh': 'LexiCon：自然语言条件下时间约束规划的标准基准'}
{'arxiv_id': 'arXiv:2510.05969', 'title': 'Probing the Difficulty Perception Mechanism of Large Language Models', 'authors': 'Sunbowen Lee, Qingyu Yin, Chak Tou Leong, Jialiang Zhang, Yicheng Gong, Xiaoyu Shen', 'link': 'https://arxiv.org/abs/2510.05969', 'abstract': 'Large language models (LLMs) are increasingly deployed on complex reasoning tasks, yet little is known about their ability to internally evaluate problem difficulty, which is an essential capability for adaptive reasoning and efficient resource allocation. In this work, we investigate whether LLMs implicitly encode problem difficulty in their internal representations. Using a linear probe on the final-token representations of LLMs, we demonstrate that the difficulty level of math problems can be linearly modeled. We further locate the specific attention heads of the final Transformer layer: these attention heads have opposite activation patterns for simple and difficult problems, thus achieving perception of difficulty. Our ablation experiments prove the accuracy of the location. Crucially, our experiments provide practical support for using LLMs as automatic difficulty annotators, potentially substantially reducing reliance on costly human labeling in benchmark construction and curriculum learning. We also uncover that there is a significant difference in entropy and difficulty perception at the token level. Our study reveals that difficulty perception in LLMs is not only present but also structurally organized, offering new theoretical insights and practical directions for future research.', 'abstract_zh': '大规模语言模型（LLMs）在复杂推理任务中的应用日益增多，但它们内部评估问题难度的能力尚不清楚，这是适应性推理和高效资源分配的重要能力。在本工作中，我们探讨LLMs是否隐含地在其内部表示中编码问题难度。通过在LLM的最终词元表示上使用线性探测，我们证明了数学问题的难度可以进行线性建模。进一步分析最终Transformer层的特定注意力头：这些注意力头在简单和困难问题上表现出相反的激活模式，从而实现了难度感知。我们的消融实验证明了位置的准确性。至关重要的是，我们的实验为使用LLMs作为自动难度标注器提供了实际支持，可能显著减少基准构建和课程学习中对昂贵的人工标注的依赖。我们还发现，令牌级别的熵和难度感知存在显著差异。我们的研究揭示了LLMs中的难度感知不仅存在，而且具有结构性组织，为未来的研究提供了新的理论见解和实用方向。', 'title_zh': '探究大规模语言模型的难度感知机制'}
{'arxiv_id': 'arXiv:2510.05949', 'title': 'Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density', 'authors': 'Randall Balestriero, Nicolas Ballas, Mike Rabbat, Yann LeCun', 'link': 'https://arxiv.org/abs/2510.05949', 'abstract': "Joint Embedding Predictive Architectures (JEPAs) learn representations able to solve numerous downstream tasks out-of-the-box. JEPAs combine two objectives: (i) a latent-space prediction term, i.e., the representation of a slightly perturbed sample must be predictable from the original sample's representation, and (ii) an anti-collapse term, i.e., not all samples should have the same representation. While (ii) is often considered as an obvious remedy to representation collapse, we uncover that JEPAs' anti-collapse term does much more--it provably estimates the data density. In short, any successfully trained JEPA can be used to get sample probabilities, e.g., for data curation, outlier detection, or simply for density estimation. Our theoretical finding is agnostic of the dataset and architecture used--in any case one can compute the learned probabilities of sample $x$ efficiently and in closed-form using the model's Jacobian matrix at $x$. Our findings are empirically validated across datasets (synthetic, controlled, and Imagenet) and across different Self Supervised Learning methods falling under the JEPA family (I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the method extracting the JEPA learned density as {\\bf JEPA-SCORE}.", 'abstract_zh': 'Joint Embedding Predictive Architectures (JEPAs) 一次学习到能够解决大量下游任务的能力。JEPAs 结合了两个目标：(i) 潜空间预测项，即稍微扰动后的样本的表示可以从原始样本的表示中预测出来，和(ii) 反汇聚项，即并非所有样本都应该具有相同的表示。尽管(ii) 通常被认为是解决表示汇聚的明显方法，但我们发现 JEPAs 的反汇聚项做得更多——它可证明地估计了数据密度。简而言之，任何成功训练的 JEPA 都可以用于获取样本概率，例如用于数据整理、异常检测，或仅仅用于密度估计。我们的理论发现与所使用的数据集和架构无关——无论哪种情况，都可以通过模型在 $x$ 处的雅可比矩阵高效且闭形式地计算出学习到的样本 $x$ 的概率。我们的发现已在合成、受控和 ImageNet 数据集上以及 JEPA 家族（I-JEPA 和 DINOv2）和多模态模型（如 MetaCLIP）的不同半监督学习方法中得到实证验证。我们称提取 JEPA 学习到的密度的方法为 **JEPA-SCORE**。', 'title_zh': '高斯嵌入：JEPAs如何秘密学习你的数据密度'}
{'arxiv_id': 'arXiv:2510.05942', 'title': 'EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation for Moral Alignment in Large Language Models', 'authors': 'Hadi Mohammadi, Anastasia Giachanou, Ayoub Bagheri', 'link': 'https://arxiv.org/abs/2510.05942', 'abstract': "We present EvalMORAAL, a transparent chain-of-thought (CoT) framework that uses two scoring methods (log-probabilities and direct ratings) plus a model-as-judge peer review to evaluate moral alignment in 20 large language models. We assess models on the World Values Survey (55 countries, 19 topics) and the PEW Global Attitudes Survey (39 countries, 8 topics). With EvalMORAAL, top models align closely with survey responses (Pearson's r approximately 0.90 on WVS). Yet we find a clear regional difference: Western regions average r=0.82 while non-Western regions average r=0.61 (a 0.21 absolute gap), indicating consistent regional bias. Our framework adds three parts: (1) two scoring methods for all models to enable fair comparison, (2) a structured chain-of-thought protocol with self-consistency checks, and (3) a model-as-judge peer review that flags 348 conflicts using a data-driven threshold. Peer agreement relates to survey alignment (WVS r=0.74, PEW r=0.39, both p<.001), supporting automated quality checks. These results show real progress toward culture-aware AI while highlighting open challenges for use across regions.", 'abstract_zh': '评析MORAAL：一种透明的链式思维框架，用于评估20个大型语言模型的道德一致性', 'title_zh': 'EvalMORAAL: 具有解释性链式思维和大模型作为法官评估的大型语言模型道德对齐评价方法'}
{'arxiv_id': 'arXiv:2510.05935', 'title': 'LLM-FS-Agent: A Deliberative Role-based Large Language Model Architecture for Transparent Feature Selection', 'authors': 'Mohamed Bal-Ghaoui, Fayssal Sabri', 'link': 'https://arxiv.org/abs/2510.05935', 'abstract': 'High-dimensional data remains a pervasive challenge in machine learning, often undermining model interpretability and computational efficiency. While Large Language Models (LLMs) have shown promise for dimensionality reduction through feature selection, existing LLM-based approaches frequently lack structured reasoning and transparent justification for their decisions. This paper introduces LLM-FS-Agent, a novel multi-agent architecture designed for interpretable and robust feature selection. The system orchestrates a deliberative "debate" among multiple LLM agents, each assigned a specific role, enabling collective evaluation of feature relevance and generation of detailed justifications. We evaluate LLM-FS-Agent in the cybersecurity domain using the CIC-DIAD 2024 IoT intrusion detection dataset and compare its performance against strong baselines, including LLM-Select and traditional methods such as PCA. Experimental results demonstrate that LLM-FS-Agent consistently achieves superior or comparable classification performance while reducing downstream training time by an average of 46% (statistically significant improvement, p = 0.028 for XGBoost). These findings highlight that the proposed deliberative architecture enhances both decision transparency and computational efficiency, establishing LLM-FS-Agent as a practical and reliable solution for real-world applications.', 'abstract_zh': '高维数据 remains a pervasive challenge in machine learning, often undermining model interpretability and computational efficiency. 而 Large Language Models (LLMs) 通过特征选择显示出在降维方面的潜力，但现有的基于 LLMS 的方法经常缺乏结构化的推理和透明的决策依据。本文介绍了一种新型的多智能体架构 LLM-FS-Agent，该架构设计用于可解释和稳健的特征选择。该系统 orchestrates 多个 LLM 智能体的“辩论”，每个智能体被分配特定的角色，从而使集体评估特征相关性并生成详细的依据成为可能。我们在网络安全领域使用 CIC-DIAD 2024 IoT 入侵检测数据集评估了 LLM-FS-Agent，并将其性能与包括 LLM-Select 和传统方法（如 PCA）在内的强基准进行了比较。实验结果表明，LLM-FS-Agent 在保持或达到优于传统方法的分类性能的同时，将下游训练时间减少了平均 46%（对于 XGBoost，统计显著性改进 p = 0.028）。这些发现突显了提议的 deliberative 架构既增强了决策透明度又提高了计算效率，确立了 LLM-FS-Agent 作为一种实用可靠的现实应用解决方案的地位。', 'title_zh': 'LLM-FS-Agent：一种透明特征选择的 deliberative 角色基础大型语言模型架构'}
{'arxiv_id': 'arXiv:2510.05930', 'title': 'Carré du champ flow matching: better quality-generalisation tradeoff in generative models', 'authors': 'Jacob Bamberger, Iolo Jones, Dennis Duncan, Michael M. Bronstein, Pierre Vandergheynst, Adam Gosztolai', 'link': 'https://arxiv.org/abs/2510.05930', 'abstract': 'Deep generative models often face a fundamental tradeoff: high sample quality can come at the cost of memorisation, where the model reproduces training data rather than generalising across the underlying data geometry. We introduce Carré du champ flow matching (CDC-FM), a generalisation of flow matching (FM), that improves the quality-generalisation tradeoff by regularising the probability path with a geometry-aware noise. Our method replaces the homogeneous, isotropic noise in FM with a spatially varying, anisotropic Gaussian noise whose covariance captures the local geometry of the latent data manifold. We prove that this geometric noise can be optimally estimated from the data and is scalable to large data. Further, we provide an extensive experimental evaluation on diverse datasets (synthetic manifolds, point clouds, single-cell genomics, animal motion capture, and images) as well as various neural network architectures (MLPs, CNNs, and transformers). We demonstrate that CDC-FM consistently offers a better quality-generalisation tradeoff. We observe significant improvements over standard FM in data-scarce regimes and in highly non-uniformly sampled datasets, which are often encountered in AI for science applications. Our work provides a mathematical framework for studying the interplay between data geometry, generalisation and memorisation in generative models, as well as a robust and scalable algorithm that can be readily integrated into existing flow matching pipelines.', 'abstract_zh': 'Carré du champ 流匹配（CDC-FM）：一种改进质量-泛化权衡的流匹配方法', 'title_zh': 'Carré du champ 流匹配：生成模型中更好的质量-泛化权衡'}
{'arxiv_id': 'arXiv:2510.05919', 'title': 'An Attention-Augmented VAE-BiLSTM Framework for Anomaly Detection in 12-Lead ECG Signals', 'authors': 'Marc Garreta Basora, Mehmet Oguz Mulayim', 'link': 'https://arxiv.org/abs/2510.05919', 'abstract': 'Anomaly detection in 12-lead electrocardiograms (ECGs) is critical for identifying deviations associated with cardiovascular disease. This work presents a comparative analysis of three autoencoder-based architectures: convolutional autoencoder (CAE), variational autoencoder with bidirectional long short-term memory (VAE-BiLSTM), and VAE-BiLSTM with multi-head attention (VAE-BiLSTM-MHA), for unsupervised anomaly detection in ECGs. To the best of our knowledge, this study reports the first application of a VAE-BiLSTM-MHA architecture to ECG anomaly detection. All models are trained on normal ECG samples to reconstruct non-anomalous cardiac morphology and detect deviations indicative of disease. Using a unified preprocessing and evaluation pipeline on the public China Physiological Signal Challenge (CPSC) dataset, the attention-augmented VAE achieves the best performance, with an AUPRC of 0.81 and a recall of 0.85 on the held-out test set, outperforming the other architectures. To support clinical triage, this model is further integrated into an interactive dashboard that visualizes anomaly localization. In addition, a performance comparison with baseline models from the literature is provided.', 'abstract_zh': '十二导联心电图（ECG）中的异常检测对于识别与心血管疾病相关的偏差至关重要。本文比较分析了三种基于自编码器的架构：卷积自编码器（CAE）、带双向长短期记忆的变分自编码器（VAE-BiLSTM），以及带多头注意力机制的VAE-BiLSTM（VAE-BiLSTM-MHA），用于心电图无监督异常检测。据我们所知，这是首次将VAE-BiLSTM-MHA架构应用于心电图异常检测。所有模型均在正常心电图样本上进行训练，以重构非异常心电图形态并检测指示疾病的偏差。通过统一的预处理和评估管道在公共China Physiological Signal Challenge（CPSC）数据集上，增强注意力的VAE在保留的测试集上取得了最佳性能，AUPRC为0.81，召回率为0.85，优于其他架构。为了支持临床分诊，该模型进一步整合到一个交互式仪表板中，可视化异常定位。此外，还提供了与文献中基线模型的性能比较。', 'title_zh': '一种注意力增强的VAE-BiLSTM框架用于12导联心电图信号的异常检测'}
{'arxiv_id': 'arXiv:2510.05903', 'title': 'Kaputt: A Large-Scale Dataset for Visual Defect Detection', 'authors': 'Sebastian Höfer, Dorian Henning, Artemij Amiranashvili, Douglas Morrison, Mariliza Tzes, Ingmar Posner, Marc Matvienko, Alessandro Rennola, Anton Milan', 'link': 'https://arxiv.org/abs/2510.05903', 'abstract': 'We present a novel large-scale dataset for defect detection in a logistics setting. Recent work on industrial anomaly detection has primarily focused on manufacturing scenarios with highly controlled poses and a limited number of object categories. Existing benchmarks like MVTec-AD [6] and VisA [33] have reached saturation, with state-of-the-art methods achieving up to 99.9% AUROC scores. In contrast to manufacturing, anomaly detection in retail logistics faces new challenges, particularly in the diversity and variability of object pose and appearance. Leading anomaly detection methods fall short when applied to this new setting. To bridge this gap, we introduce a new benchmark that overcomes the current limitations of existing datasets. With over 230,000 images (and more than 29,000 defective instances), it is 40 times larger than MVTec-AD and contains more than 48,000 distinct objects. To validate the difficulty of the problem, we conduct an extensive evaluation of multiple state-of-the-art anomaly detection methods, demonstrating that they do not surpass 56.96% AUROC on our dataset. Further qualitative analysis confirms that existing methods struggle to leverage normal samples under heavy pose and appearance variation. With our large-scale dataset, we set a new benchmark and encourage future research towards solving this challenging problem in retail logistics anomaly detection. The dataset is available for download under this https URL.', 'abstract_zh': '一种新型大规模物流缺陷检测数据集', 'title_zh': 'Kaputt：一个大规模视觉缺陷检测数据集'}
{'arxiv_id': 'arXiv:2510.05901', 'title': 'Paying Attention to Hybrid Attention: Untangling the Issues with Conversion Methods', 'authors': 'Martin Benfeghoul, Teresa Delgado, Adnan Oomerjee, Haitham Bou Ammar, Jun Wang, Zafeirios Fountas', 'link': 'https://arxiv.org/abs/2510.05901', 'abstract': "Transformers' quadratic computational complexity limits their scalability despite remarkable performance. While linear attention reduces this to linear complexity, pre-training such models from scratch remains, in most cases, prohibitively expensive. Recent post-training linearisation methods convert pre-trained Transformers to linear models efficiently, often using hybrid approaches that combine linear attention with sliding-window softmax. We identify a critical flaw: existing hybrid methods inadvertently bypass the linear component, relying almost entirely on SWA. Component-level diagnostics reveal this previously undetected behaviour stems from overlooked evaluation practices on common-sense benchmarks. We propose three solutions to ensure balanced component usage: (i) inference-time hybridisation of linear-only conversions with sliding-window softmax; (ii) HedgeCATs, combining attention-weight transfer with targeted LoRA fine-tuning; and (iii) Scheduled Sliding-window Dropout (SSD), which stochastically suppresses the softmax branch during training to prevent component collapse. Our methods maintain computational efficiency while recovering most base model performance and ensuring genuine linear attention adoption, restoring the validity of performance attributions in hybrid conversions.", 'abstract_zh': 'Transformer的二次计算复杂性限制了它们的 scalability 尽管表现优异。线性注意力将这一复杂性降低为线性，但从头预训练此类模型仍通常极为昂贵。最近的后训练线性化方法可以高效地将预训练的 Transformer 转换为线性模型，常使用结合线性注意力和滑动窗口 softmax 的混合方法。我们识别出一个关键缺陷：现有混合方法意外绕过了线性组件，几乎完全依赖滑动窗口 softmax。组件级诊断表明，这种未被发现的行为源于对常见常识基准测试中评估实践的忽视。我们提出了三种解决方案以确保组件平衡使用：（i）推理时仅线性转换与滑动窗口 softmax 的混合；（ii）HedgeCATs，结合注意力权重转移与目标 LoRA 微调；以及（iii）计划滑动窗口 Dropout（SSD），在训练过程中随机抑制 softmax 分支以防止组件崩溃。我们的方法保持计算效率的同时恢复了大多数基模型的性能，并确保线性注意力的实际采用，从而恢复混合转换中性能归因的有效性。', 'title_zh': '关注混合注意力：解开转换方法带来的问题'}
{'arxiv_id': 'arXiv:2510.05891', 'title': '$\\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection', 'authors': 'Yanran Zhang, Bingyao Yu, Yu Zheng, Wenzhao Zheng, Yueqi Duan, Lei Chen, Jie Zhou, Jiwen Lu', 'link': 'https://arxiv.org/abs/2510.05891', 'abstract': 'The emergence of visual autoregressive (AR) models has revolutionized image generation while presenting new challenges for synthetic image detection. Unlike previous GAN or diffusion-based methods, AR models generate images through discrete token prediction, exhibiting both marked improvements in image synthesis quality and unique characteristics in their vector-quantized representations. In this paper, we propose to leverage Discrete Distribution Discrepancy-aware Quantization Error (D$^3$QE) for autoregressive-generated image detection that exploits the distinctive patterns and the frequency distribution bias of the codebook existing in real and fake images. We introduce a discrete distribution discrepancy-aware transformer that integrates dynamic codebook frequency statistics into its attention mechanism, fusing semantic features and quantization error latent. To evaluate our method, we construct a comprehensive dataset termed ARForensics covering 7 mainstream visual AR models. Experiments demonstrate superior detection accuracy and strong generalization of D$^3$QE across different AR models, with robustness to real-world perturbations. Code is available at \\href{this https URL}{this https URL}.', 'abstract_zh': '视觉自回归（AR）模型的出现革新了图像生成，但也带来了合成图像检测的新挑战。不同于以往的GAN或基于扩散的方法，AR模型通过离散令牌预测生成图像，不仅在图像合成质量上取得了显著提升，还在其向量量化表示中展现出独特的特性。本文提出利用离散分布差异感知量化误差（D$^3$QE）进行自回归生成图像检测，该方法利用真实和虚假图像中存在的代码书的独特模式和频率分布偏差。我们引入了一种离散分布差异感知变换器，将动态代码书频率统计集成到其注意机制中，融合了语义特征和量化误差潜在表示。为了评估该方法，我们构建了一个名为ARForensics的综合数据集，涵盖了7种主流视觉AR模型。实验结果证明，D$^3$QE在不同AR模型上具有优越的检测准确性和强健的泛化能力，能够抵抗现实世界干扰的鲁棒性。代码可在\\href{this https URL}{这个链接}获取。', 'title_zh': 'D³QE: 学习自回归生成图像检测中的离散分布差异感知量化误差'}
{'arxiv_id': 'arXiv:2510.05881', 'title': 'Segment-Factorized Full-Song Generation on Symbolic Piano Music', 'authors': 'Ping-Yi Chen, Chih-Pin Tan, Yi-Hsuan Yang', 'link': 'https://arxiv.org/abs/2510.05881', 'abstract': 'We propose the Segmented Full-Song Model (SFS) for symbolic full-song generation. The model accepts a user-provided song structure and an optional short seed segment that anchors the main idea around which the song is developed. By factorizing a song into segments and generating each one through selective attention to related segments, the model achieves higher quality and efficiency compared to prior work. To demonstrate its suitability for human-AI interaction, we further wrap SFS into a web application that enables users to iteratively co-create music on a piano roll with customizable structures and flexible ordering.', 'abstract_zh': '分段全曲生成模型（SFS）及其在human-AI交互中的应用', 'title_zh': '符号钢琴音乐的分区因子化全曲生成'}
{'arxiv_id': 'arXiv:2510.05862', 'title': 'Revisiting Long-context Modeling from Context Denoising Perspective', 'authors': 'Zecheng Tang, Baibei Ji, Juntao Li, Lijun Wu, Haijia Gui, Min Zhang', 'link': 'https://arxiv.org/abs/2510.05862', 'abstract': "Long-context models (LCMs) have demonstrated great potential in processing long sequences, facilitating many real-world applications. The success of LCMs can be attributed to their ability to locate implicit critical information within the context for further prediction. However, recent research reveals that LCMs are often susceptible to contextual noise, i.e., irrelevant tokens, that can mislead model attention. In this paper, we conduct a fine-grained analysis of the context noise and propose an effective metric, the Integrated Gradient (IG) score, to detect and quantify the noise information within the context. Our findings reveal that even simple mitigation of detected context noise can substantially boost the model's attention on critical tokens and benefit subsequent predictions. Building on this insight, we propose Context Denoising Training (CDT), a straightforward yet effective training strategy that improves attention on critical tokens while reinforcing their influence on model predictions. Extensive experiments across four tasks, under both context window scaling and long-context alignment settings, demonstrate the superiority of CDT. Notably, when trained with CDT, an open-source 8B model can achieve performance (50.92) comparable to GPT-4o (51.00).", 'abstract_zh': '长上下文模型中的背景噪声分析与去噪训练：提升关键信息关注与预测性能', 'title_zh': '从上下文去噪视角 revisiting 长语境建模'}
{'arxiv_id': 'arXiv:2510.05858', 'title': 'DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization', 'authors': 'Xue-Yong Fu, Elena Khasanova, Md Tahmid Rahman Laskar, Harsh Saini, Shashi Bhushan TN', 'link': 'https://arxiv.org/abs/2510.05858', 'abstract': 'Large language models (LLMs) have achieved impressive performance in text summarization, yet their performance often falls short when applied to specialized domains %or conversational data that differ from their original pre-training distribution. While fine-tuning can improve summarization quality, it typically relies on costly and scarce high-quality labeled data. In this work, we explore continual pre-training as a scalable, self-supervised approach to adapt LLMs for downstream summarization tasks, particularly in the context of noisy real-world conversation transcripts. We conduct extensive experiments using large-scale, unlabeled business conversation data to investigate whether continual pre-training enhances model capabilities in conversational summarization. Our results demonstrate that continual pre-training yields substantial gains in both in-domain and out-of-domain summarization benchmarks, while maintaining strong generalization and robustness. We also analyze the effects of data selection strategies, providing practical guidelines for applying continual pre-training in summarization-focused industrial applications.', 'abstract_zh': '大规模语言模型（LLMs）在文本摘要方面取得了令人印象深刻的性能，但在应用于专门领域或与原始预训练分布不同的对话数据时，其性能往往会有所下降。虽然微调可以提高摘要质量，但通常依赖于成本高且稀缺的高质量标注数据。在本工作中，我们探索持续预训练作为一种可扩展的自监督方法，以适应LLMs在下游摘要任务中的应用，特别是在嘈杂的现实世界对话转录的背景下。我们使用大规模的未标注商务对话数据进行 extensive 实验，以调查持续预训练是否能够增强模型在对话摘要方面的能力。我们的结果显示，持续预训练在领域内和领域外摘要基准测试中均能显著提高模型能力，同时保持较强的一般化能力和鲁棒性。我们还分析了数据选择策略的影响，提供了在注重摘要的工业应用中应用持续预训练的实际指南。', 'title_zh': 'DACP： domaine自适应连续预训练大语言模型用于电话对话摘要'}
{'arxiv_id': 'arXiv:2510.05827', 'title': 'VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation', 'authors': 'Haoran Zhang, Shuanghao Bai, Wanqi Zhou, Yuedi Zhang, Qi Zhang, Pengxiang Ding, Cheng Chi, Donglin Wang, Badong Chen', 'link': 'https://arxiv.org/abs/2510.05827', 'abstract': 'Robotic grasping is one of the most fundamental tasks in robotic manipulation, and grasp detection/generation has long been the subject of extensive research. Recently, language-driven grasp generation has emerged as a promising direction due to its practical interaction capabilities. However, most existing approaches either lack sufficient reasoning and generalization capabilities or depend on complex modular pipelines. Moreover, current grasp foundation models tend to overemphasize dialog and object semantics, resulting in inferior performance and restriction to single-object grasping. To maintain strong reasoning ability and generalization in cluttered environments, we propose VCoT-Grasp, an end-to-end grasp foundation model that incorporates visual chain-of-thought reasoning to enhance visual understanding for grasp generation. VCoT-Grasp adopts a multi-turn processing paradigm that dynamically focuses on visual inputs while providing interpretable reasoning traces. For training, we refine and introduce a large-scale dataset, VCoT-GraspSet, comprising 167K synthetic images with over 1.36M grasps, as well as 400+ real-world images with more than 1.2K grasps, annotated with intermediate bounding boxes. Extensive experiments on both VCoT-GraspSet and real robot demonstrate that our method significantly improves grasp success rates and generalizes effectively to unseen objects, backgrounds, and distractors. More details can be found at this https URL.', 'abstract_zh': '基于视觉链式推理的端到端抓取基础模型VCoT-抓取', 'title_zh': 'VCoT-Grasp: 基于视觉链式推理的语义驱动抓取生成预训练模型'}
{'arxiv_id': 'arXiv:2510.05825', 'title': 'Mitigating Premature Exploitation in Particle-based Monte Carlo for Inference-Time Scaling', 'authors': 'Giorgio Giannone, Guangxuan Xu, Nikhil Shivakumar Nayak, Rohan Mahesh Awhad, Shivchander Sudalairaj, Kai Xu, Akash Srivastava', 'link': 'https://arxiv.org/abs/2510.05825', 'abstract': "Inference-Time Scaling (ITS) improves language models by allocating more computation at generation time. Particle Filtering (PF) has emerged as a strong ITS method for complex mathematical reasoning tasks, but it is vulnerable when guided by process reward models, which often assign overconfident scores early in the reasoning process. This causes PF to suffer from premature exploitation: it myopically commits to locally promising trajectories, prunes potentially correct hypotheses, and converges to suboptimal solutions. This failure mode, known as particle impoverishment, is especially severe under constrained computational budgets. To address this, we analyze the problem and identify two root causes: a lack of diversity in the particle set due to overconfident resampling and consequent inability to assess the potential of a reasoning path. We introduce Entropic Particle Filtering (ePF), an algorithm that integrates two new techniques to solve these issues. The first technique, Entropic Annealing (EA), directly mitigates particle impoverishment by monitoring search diversity via entropy; when diversity drops, it intervenes by dynamically annealing the resampling distribution to preserve exploration. The second, an enhancement called Look-ahead Modulation (LaM), adds a predictive guide to evaluate a state's potential based on its successors. On several challenging math benchmarks, ePF significantly outperforms strong baselines and achieves up to a 50 % relative improvement in task reward. Together, these methods improve PF's resilience by balancing the exploration of diverse solution spaces with the exploitation of high-reward regions, ultimately leading to higher-quality solutions.", 'abstract_zh': 'Inference-Time Scaling (ITS)提高语言模型性能通过对生成时分配更多计算资源。Entropic Particle Filtering (ePF)改进复杂数学推理任务的粒子过滤方法', 'title_zh': '粒子蒙特卡洛推理时缩放中提前利用的缓解方法'}
{'arxiv_id': 'arXiv:2510.05819', 'title': 'Deformable Image Registration for Self-supervised Cardiac Phase Detection in Multi-View Multi-Disease Cardiac Magnetic Resonance Images', 'authors': 'Sven Koehler, Sarah Kaye Mueller, Jonathan Kiekenap, Gerald Greil, Tarique Hussain, Samir Sarikouch, Florian André, Norbert Frey, Sandy Engelhardt', 'link': 'https://arxiv.org/abs/2510.05819', 'abstract': 'Cardiovascular magnetic resonance (CMR) is the gold standard for assessing cardiac function, but individual cardiac cycles complicate automatic temporal comparison or sub-phase analysis. Accurate cardiac keyframe detection can eliminate this problem. However, automatic methods solely derive end-systole (ES) and end-diastole (ED) frames from left ventricular volume curves, which do not provide a deeper insight into myocardial motion. We propose a self-supervised deep learning method detecting five keyframes in short-axis (SAX) and four-chamber long-axis (4CH) cine CMR. Initially, dense deformable registration fields are derived from the images and used to compute a 1D motion descriptor, which provides valuable insights into global cardiac contraction and relaxation patterns. From these characteristic curves, keyframes are determined using a simple set of rules. The method was independently evaluated for both views using three public, multicentre, multidisease datasets. M&Ms-2 (n=360) dataset was used for training and evaluation, and M&Ms (n=345) and ACDC (n=100) datasets for repeatability control. Furthermore, generalisability to patients with rare congenital heart defects was tested using the German Competence Network (GCN) dataset. Our self-supervised approach achieved improved detection accuracy by 30% - 51% for SAX and 11% - 47% for 4CH in ED and ES, as measured by cyclic frame difference (cFD), compared with the volume-based approach. We can detect ED and ES, as well as three additional keyframes throughout the cardiac cycle with a mean cFD below 1.31 frames for SAX and 1.73 for LAX. Our approach enables temporally aligned inter- and intra-patient analysis of cardiac dynamics, irrespective of cycle or phase lengths. GitHub repository: this https URL', 'abstract_zh': '基于自监督深度学习的心脏磁共振关键帧检测方法：短轴位和四 chamber长轴位心肌运动分析', 'title_zh': '自监督心脏相位检测的可变形图像配准在多视角多疾病心脏磁共振图像中'}
{'arxiv_id': 'arXiv:2510.05808', 'title': 'Risk level dependent Minimax Quantile lower bounds for Interactive Statistical Decision Making', 'authors': 'Raghav Bongole, Amirreza Zamani, Tobias J. Oechtering, Mikael Skoglund', 'link': 'https://arxiv.org/abs/2510.05808', 'abstract': 'Minimax risk and regret focus on expectation, missing rare failures critical in safety-critical bandits and reinforcement learning. Minimax quantiles capture these tails. Three strands of prior work motivate this study: minimax-quantile bounds restricted to non-interactive estimation; unified interactive analyses that focus on expected risk rather than risk level specific quantile bounds; and high-probability bandit bounds that still lack a quantile-specific toolkit for general interactive protocols. To close this gap, within the interactive statistical decision making framework, we develop high-probability Fano and Le Cam tools and derive risk level explicit minimax-quantile bounds, including a quantile-to-expectation conversion and a tight link between strict and lower minimax quantiles. Instantiating these results for the two-armed Gaussian bandit immediately recovers optimal-rate bounds.', 'abstract_zh': '最小最大风险和后悔聚焦于期望，而在安全关键的bandits和强化学习中，缺失罕见失败至关重要。最小最大分位数捕捉这些尾部风险。先前研究的三条主线激励了本研究：最小最大分位数界限定于非互动估计；统一的互动分析侧重于期望风险而非特定分位数风险水平界；以及高概率bandit界还缺乏用于一般互动协议的分位数特定工具包。为弥补这一缺口，在互动统计决策框架中，我们开发了高概率Fano和Le Cam工具，并推导出风险水平显式的最小最大分位数界，包括分位数到期望的转换以及严格最小最大分位数和较低最小最大分位数之间的紧密联系。将这些结果应用于两臂高斯bandit立即恢复了最优率界。', 'title_zh': '基于交互统计决策的风险水平依赖最小最大分位数下界'}
{'arxiv_id': 'arXiv:2510.05799', 'title': 'Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech', 'authors': 'Rikuto Kotoge, Yuichi Sasaki', 'link': 'https://arxiv.org/abs/2510.05799', 'abstract': 'Aligning text-to-speech (TTS) system outputs with human feedback through preference optimization has been shown to effectively improve the robustness and naturalness of language model-based TTS models. Current approaches primarily require paired desirable and undesirable samples at the utterance level. However, such pairs are often limited in TTS output data, and utterance-level formulation prevents fine-grained token-level optimization needed for accurate pronunciation alignment. In this study, we propose TKTO that eliminates the need for paired data, enabling a more data-efficient training paradigm, and directly targets token-level units, automatically providing fine-grained alignment signals without token-level annotations. TKTO improves the challenging Japanese TTS accuracy by 39% and reduces CER by 54%, automatically assigning 12.8 times stronger reward to targeted tokens.', 'abstract_zh': '通过偏好优化将文本-to-语音（TTS）系统输出与人类反馈对齐以提高基于语言模型的TTS模型的鲁棒性和自然度', 'title_zh': '基于Large Language Model的文本到语音目标标记级偏好数据高效优化'}
{'arxiv_id': 'arXiv:2510.05788', 'title': 'Mellum: Production-Grade in-IDE Contextual Code Completion with Multi-File Project Understanding', 'authors': 'Nikita Pavlichenko, Iurii Nazarov, Ivan Dolgov, Ekaterina Garanina, Dmitry Ustalov, Ivan Bondyrev, Kseniia Lysaniuk, Evgeniia Vu, Kirill Chekmenev, Joseph Shtok, Yaroslav Golubev, Anton Semenkin, Uladzislau Sazanovich', 'link': 'https://arxiv.org/abs/2510.05788', 'abstract': "We present the Mellum models family, open-weight code completion models designed for interactive use in JetBrains IDEs. Mellums have 4B parameters, adopt a Llama-style architecture, and are pre-trained on ~4T tokens of permissively licensed, multi-language code. Our studies show that (i) careful data curation and staged training significantly improve the model's quality, (ii) editor-critical capabilities such as context packing are necessary for high-quality suggestions, and (iii) a compact, task-focused model can meet the cost and latency constraints of interactive completion.\nIn the paper, we describe an end-to-end industrial pipeline for producing contextualized in-editor completion: disciplined data governance, multi-stage training that includes fill-in-the-middle and project context via supervised fine-tuning, and alignment via direct preference optimization using feedback from real-world scenarios. Our quality evaluations include both large-scale offline benchmarks and online telemetry from production deployments in JetBrains IDEs. Mellums are released under the Apache-2.0 license on HuggingFace, with a public model card providing a reproducible reference for practitioners. Our experience offers a pragmatic blueprint for taking a focused, open model from a research prototype to at scale production for hundreds of thousands of users.", 'abstract_zh': 'Mellum模型家族： JetBrains IDE中设计的开源权重代码填充模型', 'title_zh': 'Mellum：基于多文件项目理解的生产级集成开发环境上下文代码补全'}
{'arxiv_id': 'arXiv:2510.05769', 'title': 'InforME: Improving Informativeness of Abstractive Text Summarization With Informative Attention Guided by Named Entity Salience', 'authors': 'Jianbin Shen, Christy Jie Liang, Junyu Xuan', 'link': 'https://arxiv.org/abs/2510.05769', 'abstract': 'Abstractive text summarization is integral to the Big Data era, which demands advanced methods to turn voluminous and often long text data into concise but coherent and informative summaries for efficient human consumption. Despite significant progress, there is still room for improvement in various aspects. One such aspect is to improve informativeness. Hence, this paper proposes a novel learning approach consisting of two methods: an optimal transport-based informative attention method to improve learning focal information in reference summaries and an accumulative joint entropy reduction method on named entities to enhance informative salience. Experiment results show that our approach achieves better ROUGE scores compared to prior work on CNN/Daily Mail while having competitive results on XSum. Human evaluation of informativeness also demonstrates the better performance of our approach over a strong baseline. Further analysis gives insight into the plausible reasons underlying the evaluation results.', 'abstract_zh': '基于交替运输的学习方法与命名实体累积联合熵减少方法：提高摘要的informative信息量', 'title_zh': 'InforME：基于命名实体相关性的信息注意力引导以提高提取式文本摘要的 informativeness'}
{'arxiv_id': 'arXiv:2510.05750', 'title': 'Are Heterogeneous Graph Neural Networks Truly Effective? A Causal Perspective', 'authors': 'Xiao Yang, Xuejiao Zhao, Zhiqi Shen', 'link': 'https://arxiv.org/abs/2510.05750', 'abstract': 'Graph neural networks (GNNs) have achieved remarkable success in node classification. Building on this progress, heterogeneous graph neural networks (HGNNs) integrate relation types and node and edge semantics to leverage heterogeneous information. Causal analysis for HGNNs is advancing rapidly, aiming to separate genuine causal effects from spurious correlations. However, whether HGNNs are intrinsically effective remains underexamined, and most studies implicitly assume rather than establish this effectiveness. In this work, we examine HGNNs from two perspectives: model architecture and heterogeneous information. We conduct a systematic reproduction across 21 datasets and 20 baselines, complemented by comprehensive hyperparameter retuning. To further disentangle the source of performance gains, we develop a causal effect estimation framework that constructs and evaluates candidate factors under standard assumptions through factual and counterfactual analyses, with robustness validated via minimal sufficient adjustment sets, cross-method consistency checks, and sensitivity analyses. Our results lead to two conclusions. First, model architecture and complexity have no causal effect on performance. Second, heterogeneous information exerts a positive causal effect by increasing homophily and local-global distribution discrepancy, which makes node classes more distinguishable. The implementation is publicly available at this https URL.', 'abstract_zh': '基于异构图神经网络的因果分析：模型架构与异构信息的效能探究', 'title_zh': '异质图神经网络真的有效吗？一种因果视角'}
{'arxiv_id': 'arXiv:2510.05740', 'title': 'Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect', 'authors': 'Amirtaha Amanzadi, Zahra Dehghanian, Hamid Beigy, Hamid R. Rabiee', 'link': 'https://arxiv.org/abs/2510.05740', 'abstract': 'The rapid development of generative models has made it increasingly crucial to develop detectors that can reliably detect synthetic images. Although most of the work has now focused on cross-generator generalization, we argue that this viewpoint is too limited. Detecting synthetic images involves another equally important challenge: generalization across visual domains. To bridge this gap,we present the OmniGen Benchmark. This comprehensive evaluation dataset incorporates 12 state-of-the-art generators, providing a more realistic way of evaluating detector performance under realistic conditions. In addition, we introduce a new method, FusionDetect, aimed at addressing both vectors of generalization. FusionDetect draws on the benefits of two frozen foundation models: CLIP & Dinov2. By deriving features from both complementary models,we develop a cohesive feature space that naturally adapts to changes in both thecontent and design of the generator. Our extensive experiments demonstrate that FusionDetect delivers not only a new state-of-the-art, which is 3.87% more accurate than its closest competitor and 6.13% more precise on average on established benchmarks, but also achieves a 4.48% increase in accuracy on OmniGen,along with exceptional robustness to common image perturbations. We introduce not only a top-performing detector, but also a new benchmark and framework for furthering universal AI image detection. The code and dataset are available at this http URL', 'abstract_zh': '生成模型的快速发展使得可靠检测合成图像的检测器变得日益重要。尽管目前大多数工作重心已经转向跨生成器泛化，我们认为这一视角过于局限。检测合成图像还涉及另一个同样重要的挑战：跨视觉域的泛化。为了弥补这一差距，我们提出了OmniGen基准。该全面评估数据集包含12个当前最先进的生成器，提供了一种在现实条件下更真实地评估检测器性能的方法。此外，我们还引入了一种新的方法FusionDetect，旨在解决泛化问题的两个方面。FusionDetect结合了两个冻结基础模型CLIP与Dinov2的优点，通过从两个互补模型中提取特征，我们建立了一个综合特征空间，自然适应生成器内容和设计的变化。我们的大量实验证明，FusionDetect不仅在现有的基准测试中达到了新的最佳性能，比最接近的竞争对手准确率高出3.87%，平均精确度高出6.13%，还在OmniGen基准测试中实现了4.48%的准确率提升，并且具有出色的抗常见图像扰动能力。我们不仅介绍了性能最优的检测器，还提供了一个新的基准和框架，以进一步推动通用AI图像检测的发展。代码和数据集可在以下网址获得。', 'title_zh': '视觉领域中泛化能力的重定义：FusionDetect融合检测的双轴框架'}
{'arxiv_id': 'arXiv:2510.05725', 'title': 'Improving Discrete Diffusion Unmasking Policies Beyond Explicit Reference Policies', 'authors': 'Chunsan Hong, Seonho An, Min-Soo Kim, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2510.05725', 'abstract': 'Masked diffusion models (MDMs) have recently emerged as a novel framework for language modeling. MDMs generate sentences by iteratively denoising masked sequences, filling in [MASK] tokens step by step. Although MDMs support any-order sampling, performance is highly sensitive to the choice of which position to unmask next. Prior work typically relies on rule-based schedules (e.g., max-confidence, max-margin), which provide ad hoc improvements. In contrast, we replace these heuristics with a learned scheduler. Specifically, we cast denoising as a KL-regularized Markov decision process (MDP) with an explicit reference policy and optimize a regularized objective that admits policy improvement and convergence guarantees under standard assumptions. We prove that the optimized policy under this framework generates samples that more closely match the data distribution than heuristic schedules. Empirically, across four benchmarks, our learned policy consistently outperforms max-confidence: for example, on SUDOKU, where unmasking order is critical, it yields a 20.1% gain over random and a 11.2% gain over max-confidence.', 'abstract_zh': '掩码扩散模型（MDMs）近期已成为一种新颖的语言建模框架。MDMs通过迭代去噪掩蔽序列，逐步填充[MASK]令牌来生成句子。尽管MDMs支持任意顺序采样，但性能高度依赖于下一步解掩蔽哪个位置的令牌。以往工作通常依赖基于规则的时间表（例如，最大置信度、最大差距），这些方法提供临时改进。相反，我们用一个学习得到的时间表替换这些启发式方法。具体而言，我们将去噪任务视为在标准假设下具有明确参考策略的KL正则化马尔可夫决策过程（MDP），并优化一个能够在标准假设下保证策略改进和收敛性的正则化目标函数。我们证明，这种框架下的优化策略生成的样本与数据分布更加契合。在四个基准测试中，我们的学习得到的时间表始终优于最大置信度：例如，在SUDOKU中，由于解掩蔽顺序至关重要，它分别比随机方法和最大置信度方法提高了20.1%和11.2%。', 'title_zh': '超越显式参考策略的离散扩散去遮盖策略改进'}
{'arxiv_id': 'arXiv:2510.05713', 'title': 'Federated Split Learning for Resource-Constrained Robots in Industrial IoT: Framework Comparison, Optimization Strategies, and Future Directions', 'authors': 'Wanli Ni, Hui Tian, Shuai Wang, Chengyang Li, Lei Sun, Zhaohui Yang', 'link': 'https://arxiv.org/abs/2510.05713', 'abstract': 'Federated split learning (FedSL) has emerged as a promising paradigm for enabling collaborative intelligence in industrial Internet of Things (IoT) systems, particularly in smart factories where data privacy, communication efficiency, and device heterogeneity are critical concerns. In this article, we present a comprehensive study of FedSL frameworks tailored for resource-constrained robots in industrial scenarios. We compare synchronous, asynchronous, hierarchical, and heterogeneous FedSL frameworks in terms of workflow, scalability, adaptability, and limitations under dynamic industrial conditions. Furthermore, we systematically categorize token fusion strategies into three paradigms: input-level (pre-fusion), intermediate-level (intra-fusion), and output-level (post-fusion), and summarize their respective strengths in industrial applications. We also provide adaptive optimization techniques to enhance the efficiency and feasibility of FedSL implementation, including model compression, split layer selection, computing frequency allocation, and wireless resource management. Simulation results validate the performance of these frameworks under industrial detection scenarios. Finally, we outline open issues and research directions of FedSL in future smart manufacturing systems.', 'abstract_zh': '联邦分割学习（FedSL）已成为促进工业物联网（IoT）系统中协作智能的一种有前途的范式，特别是在数据隐私、通信效率和设备异构性至关重要的智能工厂中。本文对适用于工业场景中的资源受限机器人的FedSL框架进行了全面研究。我们从工作流程、可扩展性、适应性和动态工业条件下的限制等方面比较了同步、异步、分层和异构FedSL框架。同时，我们系统地将令牌融合策略分为输入级（预融合）、中间级（内融合）和输出级（后融合）三种范式，并总结了其在工业应用中的各自优势。我们还提供了适应性优化技术以提升FedSL实施的效率和可行性，包括模型压缩、分割层选择、计算频率分配和无线资源管理。仿真结果验证了在工业检测场景下这些框架的性能。最后，我们概述了未来智能制造系统中FedSL的研究缺口和研究方向。', 'title_zh': '资源受限机器人在工业物联网中的联邦拆分学习：框架比较、优化策略及未来方向'}
{'arxiv_id': 'arXiv:2510.05710', 'title': 'FinReflectKG - EvalBench: Benchmarking Financial KG with Multi-Dimensional Evaluation', 'authors': 'Fabrizio Dimino, Abhinav Arun, Bhaskarjit Sarmah, Stefano Pasquali', 'link': 'https://arxiv.org/abs/2510.05710', 'abstract': 'Large language models (LLMs) are increasingly being used to extract structured knowledge from unstructured financial text. Although prior studies have explored various extraction methods, there is no universal benchmark or unified evaluation framework for the construction of financial knowledge graphs (KG). We introduce FinReflectKG - EvalBench, a benchmark and evaluation framework for KG extraction from SEC 10-K filings. Building on the agentic and holistic evaluation principles of FinReflectKG - a financial KG linking audited triples to source chunks from S&P 100 filings and supporting single-pass, multi-pass, and reflection-agent-based extraction modes - EvalBench implements a deterministic commit-then-justify judging protocol with explicit bias controls, mitigating position effects, leniency, verbosity and world-knowledge reliance. Each candidate triple is evaluated with binary judgments of faithfulness, precision, and relevance, while comprehensiveness is assessed on a three-level ordinal scale (good, partial, bad) at the chunk level. Our findings suggest that, when equipped with explicit bias controls, LLM-as-Judge protocols provide a reliable and cost-efficient alternative to human annotation, while also enabling structured error analysis. Reflection-based extraction emerges as the superior approach, achieving best performance in comprehensiveness, precision, and relevance, while single-pass extraction maintains the highest faithfulness. By aggregating these complementary dimensions, FinReflectKG - EvalBench enables fine-grained benchmarking and bias-aware evaluation, advancing transparency and governance in financial AI applications.', 'abstract_zh': 'Large语言模型（LLMs）越来越多地被用于从非结构化财务文本中提取结构化知识。尽管先前的研究探索了各种提取方法，但尚未形成通用的基准或统一的评估框架来构建财务知识图谱（KG）。我们介绍了FinReflectKG - EvalBench，这是一个基于SEC 10-K文件的KG提取基准和评估框架。基于FinReflectKG的代理性和整体性评估原则——该框架将已审计的三元组链接到S&P 100文件中的源片段，并支持单次通过、多次通过和反思代理为基础的提取模式——EvalBench实现了确定性的提交后解释判定协议，具有明确的偏见控制，减轻了位置效应、宽松性、冗长性和世界知识依赖性。每个候选三元组根据忠实性、精确性和相关性进行二元判断评估，而在片段层面，则按三个层级的等级尺度（良好、部分、较差）评估其完整性。我们的研究结果表明，当配备有明确的偏见控制时，LLM作为裁判的协议是一种可靠且成本效益高的替代人类注释的方法，同时还能进行结构化的错误分析。基于反思的提取方法表现最优，在完整性、精确性和相关性方面取得最佳性能，而单次通过提取保持最高的忠实性。通过综合这些互补维度，FinReflectKG - EvalBench能够实现精细的基准测试和偏见意识评估，推动财务AI应用领域的透明度和治理。', 'title_zh': 'FinReflectKG - EvalBench: 基于多维度评估的金融知识图谱基准测试'}
{'arxiv_id': 'arXiv:2510.05709', 'title': 'Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling', 'authors': 'Mary Llewellyn, Annie Gray, Josh Collyer, Michael Harries', 'link': 'https://arxiv.org/abs/2510.05709', 'abstract': 'Before adopting a new large language model (LLM) architecture, it is critical to understand vulnerabilities accurately. Existing evaluations can be difficult to trust, often drawing conclusions from LLMs that are not meaningfully comparable, relying on heuristic inputs or employing metrics that fail to capture the inherent uncertainty. In this paper, we propose a principled and practical end-to-end framework for evaluating LLM vulnerabilities to prompt injection attacks. First, we propose practical approaches to experimental design, tackling unfair LLM comparisons by considering two practitioner scenarios: when training an LLM and when deploying a pre-trained LLM. Second, we address the analysis of experiments and propose a Bayesian hierarchical model with embedding-space clustering. This model is designed to improve uncertainty quantification in the common scenario that LLM outputs are not deterministic, test prompts are designed imperfectly, and practitioners only have a limited amount of compute to evaluate vulnerabilities. We show the improved inferential capabilities of the model in several prompt injection attack settings. Finally, we demonstrate the pipeline to evaluate the security of Transformer versus Mamba architectures. Our findings show that consideration of output variability can suggest less definitive findings. However, for some attacks, we find notably increased Transformer and Mamba-variant vulnerabilities across LLMs with the same training data or mathematical ability.', 'abstract_zh': '一种 principled 和实用的端到端框架：评估大语言模型对提示注入攻击的漏洞', 'title_zh': '基于贝叶斯建模的可靠且实用的大语言模型安全评估方法'}
{'arxiv_id': 'arXiv:2510.05702', 'title': 'Uncovering Representation Bias for Investment Decisions in Open-Source Large Language Models', 'authors': 'Fabrizio Dimino, Krati Saxena, Bhaskarjit Sarmah, Stefano Pasquali', 'link': 'https://arxiv.org/abs/2510.05702', 'abstract': 'Large Language Models are increasingly adopted in financial applications to support investment workflows. However, prior studies have seldom examined how these models reflect biases related to firm size, sector, or financial characteristics, which can significantly impact decision-making. This paper addresses this gap by focusing on representation bias in open-source Qwen models. We propose a balanced round-robin prompting method over approximately 150 U.S. equities, applying constrained decoding and token-logit aggregation to derive firm-level confidence scores across financial contexts. Using statistical tests and variance analysis, we find that firm size and valuation consistently increase model confidence, while risk factors tend to decrease it. Confidence varies significantly across sectors, with the Technology sector showing the greatest variability. When models are prompted for specific financial categories, their confidence rankings best align with fundamental data, moderately with technical signals, and least with growth indicators. These results highlight representation bias in Qwen models and motivate sector-aware calibration and category-conditioned evaluation protocols for safe and fair financial LLM deployment.', 'abstract_zh': '大型语言模型在金融应用中的投资工作流程中越来越受到采用，但先前的研究很少考察这些模型在公司规模、行业或财务特征方面的偏见，这些问题可能显著影响决策。本文通过关注开源Qwen模型中的表示偏见，填补了这一空白。我们提出了一种平衡的轮循提示方法，应用于大约150家美国股票，采用受限解码和标记-概率聚合来推导出跨财务情境的公司级置信分数。通过统计检验和方差分析，我们发现，公司规模和估值一致地提高模型置信度，而风险因素则倾向于降低置信度。置信度在不同行业之间差异显著，科技行业显示出最大的变异。当模型被提示特定的财务类别时，它们的置信度排名与基本面数据最接近，与技术信号中等程度接近，与增长指标最不接近。这些结果揭示了Qwen模型中的表示偏见，并促进了对安全和公平的金融LLM部署的行业意识校准和类别条件评估协议的需求。', 'title_zh': '揭开开源大规模语言模型中表示偏见以辅助投资决策'}
{'arxiv_id': 'arXiv:2510.05699', 'title': 'Membership Inference Attacks on Tokenizers of Large Language Models', 'authors': 'Meng Tong, Yuntao Du, Kejiang Chen, Weiming Zhang, Ninghui Li', 'link': 'https://arxiv.org/abs/2510.05699', 'abstract': "Membership inference attacks (MIAs) are widely used to assess the privacy risks associated with machine learning models. However, when these attacks are applied to pre-trained large language models (LLMs), they encounter significant challenges, including mislabeled samples, distribution shifts, and discrepancies in model size between experimental and real-world settings. To address these limitations, we introduce tokenizers as a new attack vector for membership inference. Specifically, a tokenizer converts raw text into tokens for LLMs. Unlike full models, tokenizers can be efficiently trained from scratch, thereby avoiding the aforementioned challenges. In addition, the tokenizer's training data is typically representative of the data used to pre-train LLMs. Despite these advantages, the potential of tokenizers as an attack vector remains unexplored. To this end, we present the first study on membership leakage through tokenizers and explore five attack methods to infer dataset membership. Extensive experiments on millions of Internet samples reveal the vulnerabilities in the tokenizers of state-of-the-art LLMs. To mitigate this emerging risk, we further propose an adaptive defense. Our findings highlight tokenizers as an overlooked yet critical privacy threat, underscoring the urgent need for privacy-preserving mechanisms specifically designed for them.", 'abstract_zh': '基于标记器的成员推理攻击：探索最先进的大语言模型标记器中的隐私威胁', 'title_zh': '大型语言模型分词器的成员推理攻击'}
{'arxiv_id': 'arXiv:2510.05696', 'title': 'Sparse deepfake detection promotes better disentanglement', 'authors': 'Antoine Teissier, Marie Tahon, Nicolas Dugué, Aghilas Sini', 'link': 'https://arxiv.org/abs/2510.05696', 'abstract': 'Due to the rapid progress of speech synthesis, deepfake detection has become a major concern in the speech processing community. Because it is a critical task, systems must not only be efficient and robust, but also provide interpretable explanations. Among the different approaches for explainability, we focus on the interpretation of latent representations. In such paper, we focus on the last layer of embeddings of AASIST, a deepfake detection architecture. We use a TopK activation inspired by SAEs on this layer to obtain sparse representations which are used in the decision process. We demonstrate that sparse deepfake detection can improve detection performance, with an EER of 23.36% on ASVSpoof5 test set, with 95% of sparsity. We then show that these representations provide better disentanglement, using completeness and modularity metrics based on mutual information. Notably, some attacks are directly encoded in the latent space.', 'abstract_zh': '由于语音合成的快速发展，深度假音检测已成为语音处理领域的重大关注点。由于这是一个关键任务，系统不仅要高效和 robust，还需提供可解释的解释。在不同的可解释性方法中，我们关注潜在表示的解释。在本文中，我们专注于 AASIST 深度假音检测架构的最后一层嵌入。我们采用了受 SAEs 启发的 TopK 激活，以获得稀疏表示，并将其用于决策过程。我们证明，稀疏的假音检测可以提高检测性能，在 ASVSpoof5 测试集上的 EER 为 23.36%，稀疏度为 95%。我们还展示了这些表示提供了更好的分离性，使用基于互信息的完整性和模块性度量。值得注意的是，某些攻击直接编码在潜在空间中。', 'title_zh': '稀疏深伪检测促进更好的因子分离'}
{'arxiv_id': 'arXiv:2510.05688', 'title': 'vAttention: Verified Sparse Attention', 'authors': 'Aditya Desai, Kumar Krishna Agrawal, Shuo Yang, Alejandro Cuadron, Luis Gaspar Schroeder, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2510.05688', 'abstract': 'State-of-the-art sparse attention methods for reducing decoding latency fall into two main categories: approximate top-$k$ (and its extension, top-$p$) and recently introduced sampling-based estimation. However, these approaches are fundamentally limited in their ability to approximate full attention: they fail to provide consistent approximations across heads and query vectors and, most critically, lack guarantees on approximation quality, limiting their practical deployment. We observe that top-$k$ and random sampling are complementary: top-$k$ performs well when attention scores are dominated by a few tokens, whereas random sampling provides better estimates when attention scores are relatively uniform. Building on this insight and leveraging the statistical guarantees of sampling, we introduce vAttention, the first practical sparse attention mechanism with user-specified $(\\epsilon, \\delta)$ guarantees on approximation accuracy (thus, verified). These guarantees make vAttention a compelling step toward practical, reliable deployment of sparse attention at scale. By unifying top-k and sampling, vAttention outperforms both individually, delivering a superior quality-efficiency trade-off. Our experiments show that vAttention significantly improves the quality of sparse attention (e.g., $\\sim$4.5 percentage points for Llama-3.1-8B-Inst and Deepseek-R1-Distill-Llama-8B on RULER-HARD), and effectively bridges the gap between full and sparse attention (e.g., across datasets, it matches full model quality with upto 20x sparsity). We also demonstrate that it can be deployed in reasoning scenarios to achieve fast decoding without compromising model quality (e.g., vAttention achieves full model quality on AIME2024 at 10x sparsity with up to 32K token generations). Code is open-sourced at this https URL.', 'abstract_zh': '最先进的稀疏注意力方法在降低解码延迟方面大致可以分为两类：近似Top-$k$（及其扩展Top-$p$）和近期引入的基于采样的估计方法。然而，这些方法本质上在近似全注意力方面存在限制：它们无法在各个头和查询向量之间提供一致的近似值，并且最关键的是，缺乏近似质量的保证，限制了它们的实际部署。我们观察到Top-$k$和随机采样是互补的：当注意力分数主要由少数几个标记主导时，Top-$k$表现良好，而当注意力分数相对均匀时，随机采样提供更好的估计。基于这一洞察，并利用采样的统计保证，我们引入了vAttention，这是首个具有用户指定的$(\\epsilon, \\delta)$近似准确度保证的实用稀疏注意力机制（因此是经过验证的）。这些保证使vAttention成为逐步实现大规模稀疏注意力实用、可靠部署的一个令人信服的步骤。通过结合Top-$k$和采样，vAttention在独立性上都表现更优，提供了更好的质量-效率权衡。我们的实验表明，vAttention显著提高了稀疏注意力的质量（例如，在Llama-3.1-8B-Inst和Deepseek-R1-Distill-Llama-8B上，RULER-HARD上的改善幅度约为4.5个百分点），并且有效地弥合了全注意力与稀疏注意力之间的差距（例如，在不同数据集上，它在最高至20倍稀疏度的情况下与全模型质量相当）。我们还展示了可以在推理场景中部署vAttention，以实现快速解码而不牺牲模型质量（例如，在AIME2024上，vAttention在最高至32K标记生成情况下，在10倍稀疏度下实现了全模型质量）。代码已在下面的链接中开源。', 'title_zh': 'vAttention: 验证Sparse Attention'}
{'arxiv_id': 'arXiv:2510.05683', 'title': 'QGraphLIME - Explaining Quantum Graph Neural Networks', 'authors': 'Haribandhu Jena, Jyotirmaya Shivottam, Subhankar Mishra', 'link': 'https://arxiv.org/abs/2510.05683', 'abstract': 'Quantum graph neural networks offer a powerful paradigm for learning on graph-structured data, yet their explainability is complicated by measurement-induced stochasticity and the combinatorial nature of graph structure. In this paper, we introduce QuantumGraphLIME (QGraphLIME), a model-agnostic, post-hoc framework that treats model explanations as distributions over local surrogates fit on structure-preserving perturbations of a graph. By aggregating surrogate attributions together with their dispersion, QGraphLIME yields uncertainty-aware node and edge importance rankings for quantum graph models. The framework further provides a distribution-free, finite-sample guarantee on the size of the surrogate ensemble: a Dvoretzky-Kiefer-Wolfowitz bound ensures uniform approximation of the induced distribution of a binary class probability at target accuracy and confidence under standard independence assumptions. Empirical studies on controlled synthetic graphs with known ground truth demonstrate accurate and stable explanations, with ablations showing clear benefits of nonlinear surrogate modeling and highlighting sensitivity to perturbation design. Collectively, these results establish a principled, uncertainty-aware, and structure-sensitive approach to explaining quantum graph neural networks, and lay the groundwork for scaling to broader architectures and real-world datasets, as quantum resources mature. Code is available at this https URL.', 'abstract_zh': '量子图神经网络提供了一种强大的图结构数据学习范式，然而，它们的可解释性因测量诱导的随机性和图结构的组合性质而复杂化。本文介绍了QuantumGraphLIME（QGraphLIME），一种模型无关、事后框架，将模型解释视为在结构保持的图扰动上拟合的局部替代模型的分布。通过聚合替代模型的赋值及其离散度，QGraphLIME为量子图模型提供了不确定性感知的节点和边重要性排序。该框架还提供了替代模型集合的无分布保证：在标准独立性假设下，Dvoretzky-Kiefer-Wolfowitz界确保了二元类概率诱导分布的一致近似，达到目标精度和置信度。在已知真实值的受控合成图上的实证研究表明了准确且稳定的解释，消融实验显示了非线性替代模型建模的明显优势，并揭示了对扰动设计的敏感性。这些结果建立了解释量子图神经网络的基本、不确定性感知且结构敏感的原理，为扩展到更广泛的架构和真实世界数据集奠定了基础，随着量子资源的成熟。代码可在以下链接获得：this https URL。', 'title_zh': 'QGraphLIME - 解释量子图神经网络'}
{'arxiv_id': 'arXiv:2510.05681', 'title': 'Verifier-free Test-Time Sampling for Vision Language Action Models', 'authors': 'Suhyeok Jang, Dongyoung Kim, Changyeon Kim, Youngsuk Kim, Jinwoo Shin', 'link': 'https://arxiv.org/abs/2510.05681', 'abstract': "Vision-Language-Action models (VLAs) have demonstrated remarkable performance in robot control. However, they remain fundamentally limited in tasks that require high precision due to their single-inference paradigm. While test-time scaling approaches using external verifiers have shown promise, they require additional training and fail to generalize to unseen conditions. We propose Masking Distribution Guided Selection (MG-Select), a novel test-time scaling framework for VLAs that leverages the model's internal properties without requiring additional training or external modules. Our approach utilizes KL divergence from a reference action token distribution as a confidence metric for selecting the optimal action from multiple candidates. We introduce a reference distribution generated by the same VLA but with randomly masked states and language conditions as inputs, ensuring maximum uncertainty while remaining aligned with the target task distribution. Additionally, we propose a joint training strategy that enables the model to learn both conditional and unconditional distributions by applying dropout to state and language conditions, thereby further improving the quality of the reference distribution. Our experiments demonstrate that MG-Select achieves significant performance improvements, including a 28%/35% improvement in real-world in-distribution/out-of-distribution tasks, along with a 168% relative gain on RoboCasa pick-and-place tasks trained with 30 demonstrations.", 'abstract_zh': 'Vision-Language-Action模型（VLAs）在机器人控制中展现了出色的表现，但由于其单一推理范式，它们在需要高精度的任务中仍然存在根本性的限制。虽然使用外部验证者的测试时缩放方法显示出潜力，但它们需要额外的训练并在未见条件下缺乏泛化能力。我们提出了Masking Distribution Guided Selection（MG-Select），这是一种新颖的适用于VLAs的测试时缩放框架，该框架利用模型的内部属性，无需额外训练或外部模块。我们的方法使用与参考动作令牌分布的KL散度作为从多个候选动作中选择最优动作的信心指标。我们引入了一个由相同的VLA生成的参考分布，该分布使用随机遮掩的状态和语言条件作为输入，从而确保最大的不确定性并保持与目标任务分布的一致性。此外，我们提出了一种联合训练策略，使得模型能够在应用状态和语言条件的dropout后学习条件和无条件分布，从而进一步改进参考分布的质量。实验结果显示，MG-Select实现了显著的性能提升，包括在真实的分布内/分布外任务中分别提高了28%/35%，以及在使用30个示范训练下的RoboCasa抓取和放置任务中相对增益达到168%。', 'title_zh': '无验证者的时间采样方法：面向视觉语言动作模型的测试时采样'}
{'arxiv_id': 'arXiv:2510.05678', 'title': 'Code-Switching In-Context Learning for Cross-Lingual Transfer of Large Language Models', 'authors': 'Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh', 'link': 'https://arxiv.org/abs/2510.05678', 'abstract': 'While large language models (LLMs) exhibit strong multilingual abilities, their reliance on English as latent representations creates a translation barrier, where reasoning implicitly depends on internal translation into English. When this process fails, performance in non-English languages deteriorates sharply, limiting the inclusiveness of LLM-based applications. Existing cross-lingual in-context learning (X-ICL) methods primarily leverage monolingual demonstrations, often failing to mitigate this barrier and instead reinforcing it. In this work, we introduce code-switching in-context learning (CSICL), a simple yet effective prompting strategy that progressively transitions from a target language to English within demonstrations and instruction to facilitate their latent reasoning in English. By explicitly scaffolding the reasoning process through controlled code-switching, CSICL acts as an implicit linguistic bridge that enhances cross-lingual alignment and reduces reliance on the translation barrier. We conduct extensive experiments across 4 LLMs, 6 datasets, and 10 languages, spanning both knowledge-intensive and reasoning-oriented domains. Our results demonstrate that CSICL consistently outperforms X-ICL baselines, achieving gains of 3.1%p and 1.9%p in both target and unseen languages, respectively. The improvement is even more pronounced in low-resource settings, with gains of 14.7% in target and 5.3% in unseen languages. These findings establish code-switching as a principled and robust approach for overcoming the translation barrier during inference, moving LLMs toward more equitable and effective multilingual systems.', 'abstract_zh': '代码转换在场学习（CSICL）：一种促进跨语言一致性的简明有效策略', 'title_zh': '基于上下文的代码转换学习在跨语言迁移大型语言模型中的应用'}
{'arxiv_id': 'arXiv:2510.05670', 'title': 'Quantifying the Accuracy-Interpretability Trade-Off in Concept-Based Sidechannel Models', 'authors': 'David Debot, Giuseppe Marra', 'link': 'https://arxiv.org/abs/2510.05670', 'abstract': "Concept Bottleneck Models (CBNMs) are deep learning models that provide interpretability by enforcing a bottleneck layer where predictions are based exclusively on human-understandable concepts. However, this constraint also restricts information flow and often results in reduced predictive accuracy. Concept Sidechannel Models (CSMs) address this limitation by introducing a sidechannel that bypasses the bottleneck and carry additional task-relevant information. While this improves accuracy, it simultaneously compromises interpretability, as predictions may rely on uninterpretable representations transmitted through sidechannels. Currently, there exists no principled technique to control this fundamental trade-off. In this paper, we close this gap. First, we present a unified probabilistic concept sidechannel meta-model that subsumes existing CSMs as special cases. Building on this framework, we introduce the Sidechannel Independence Score (SIS), a metric that quantifies a CSM's reliance on its sidechannel by contrasting predictions made with and without sidechannel information. We propose SIS regularization, which explicitly penalizes sidechannel reliance to improve interpretability. Finally, we analyze how the expressivity of the predictor and the reliance of the sidechannel jointly shape interpretability, revealing inherent trade-offs across different CSM architectures. Empirical results show that state-of-the-art CSMs, when trained solely for accuracy, exhibit low representation interpretability, and that SIS regularization substantially improves their interpretability, intervenability, and the quality of learned interpretable task predictors. Our work provides both theoretical and practical tools for developing CSMs that balance accuracy and interpretability in a principled manner.", 'abstract_zh': '概念侧信道模型（CSMs）是一种通过引入绕过瓶颈层的侧信道来提高可解释性的深度学习模型。然而，这种约束也限制了信息流，并常常导致预测准确率下降。概念瓶颈模型（CBNMs）通过在预测中仅基于人类可理解的概念施加瓶颈层来提供可解释性，但这也限制了信息流并常常导致预测准确率下降。概念侧信道模型（CSMs）通过引入一个绕过瓶颈层的侧信道来解决这一限制，该侧信道携带额外的任务相关信息。虽然这提高了准确率，但也同时牺牲了可解释性，因为预测可能依赖于通过侧信道传输的不可解释表示。目前，尚无原则性的技术来控制这一基本权衡。在本文中，我们填补了这一空白。首先，我们提出了一种统一的概率概念侧信道元模型，其涵盖了现有的CSMs作为特殊情况。在此框架基础上，我们引入了侧信道独立性得分（SIS），这是一种衡量CSM对侧信道依赖程度的指标，通过对比有无侧信道信息时的预测结果。我们提出了SIS正则化，以显式地惩罚侧信道依赖性以提高可解释性。最后，我们分析了预测器的表征能力和侧信道的依赖性如何共同影响可解释性，揭示了不同CSM架构中的固有权衡。实证结果显示，仅用于准确性的最新CSMs的表现形式的可解释性较低，而SIS正则化显著提高了它们的可解释性、可干预性和学习到的任务预测器的质量。我们的工作提供了理论和实践工具，以实现了准确性和可解释性之间原则性的平衡。', 'title_zh': '基于概念的侧信道模型中的准确性和可解释性权衡量化'}
{'arxiv_id': 'arXiv:2510.05649', 'title': 'Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation', 'authors': 'Saja Al-Dabet, Sherzod Turaev, Nazar Zaki, Arif O. Khan, Luai Eldweik', 'link': 'https://arxiv.org/abs/2510.05649', 'abstract': 'Ocular-induced abnormal head posture (AHP) is a compensatory mechanism that arises from ocular misalignment conditions, such as strabismus, enabling patients to reduce diplopia and preserve binocular vision. Early diagnosis minimizes morbidity and secondary complications such as facial asymmetry; however, current clinical assessments remain largely subjective and are further complicated by incomplete medical records. This study addresses both challenges through two complementary deep learning frameworks. First, AHP-CADNet is a multi-level attention fusion framework for automated diagnosis that integrates ocular landmarks, head pose features, and structured clinical attributes to generate interpretable predictions. Second, a curriculum learning-based imputation framework is designed to mitigate missing data by progressively leveraging structured variables and unstructured clinical notes to enhance diagnostic robustness under realistic data conditions. Evaluation on the PoseGaze-AHP dataset demonstrates robust diagnostic performance. AHP-CADNet achieves 96.9-99.0 percent accuracy across classification tasks and low prediction errors for continuous variables, with MAE ranging from 0.103 to 0.199 and R2 exceeding 0.93. The imputation framework maintains high accuracy across all clinical variables (93.46-99.78 percent with PubMedBERT), with clinical dependency modeling yielding significant improvements (p < 0.001). These findings confirm the effectiveness of both frameworks for automated diagnosis and recovery from missing data in clinical settings.', 'abstract_zh': '由眼位异常引发的异常头部姿势（AHP）是一种补偿机制，源自眼球偏斜等眼位不对称状况，帮助患者减少复视并保持双眼视力。早期诊断可减轻并发症如面部不对称等的发病率；然而，当前临床评估主要依赖主观判断，并受医疗记录不完整的影响。本研究通过两个互补的深度学习框架应对这些挑战。首先，AHP-CADNet是一个多层次注意融合框架，结合眼部标志点、头部姿态特征和结构化临床属性，生成可解释的诊断预测。其次，设计了一个基于逐级学习的插补框架，通过逐步利用结构化变量和非结构化临床笔记，在实际数据条件下增强诊断稳健性并减轻数据缺失问题。PoseGaze-AHP数据集上的评估显示了稳健的诊断性能。AHP-CADNet在分类任务中的准确率高达96.9-99.0%，连续变量预测误差低，平均绝对误差（MAE）从0.103到0.199，决定系数（R2）超过0.93。插补框架在所有临床变量上保持高准确率（PubMedBERT下93.46-99.78%），临床依赖性建模显著提高了准确率（p < 0.001）。这些发现证实了两个框架在临床环境中的自动诊断能力和数据缺失恢复的有效性。', 'title_zh': 'ocular诱导异常头位：诊断与缺失数据插补'}
{'arxiv_id': 'arXiv:2510.05644', 'title': 'The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP', 'authors': 'Sheriff Issaka, Keyi Wang, Yinka Ajibola, Oluwatumininu Samuel-Ipaye, Zhaoyi Zhang, Nicte Aguillon Jimenez, Evans Kofi Agyei, Abraham Lin, Rohan Ramachandran, Sadick Abdul Mumin, Faith Nchifor, Mohammed Shuraim, Lieqi Liu, Erick Rosas Gonzalez, Sylvester Kpei, Jemimah Osei, Carlene Ajeneza, Persis Boateng, Prisca Adwoa Dufie Yeboah, Saadia Gabriel', 'link': 'https://arxiv.org/abs/2510.05644', 'abstract': "Despite representing nearly one-third of the world's languages, African languages remain critically underserved by modern NLP technologies, with 88\\% classified as severely underrepresented or completely ignored in computational linguistics. We present the African Languages Lab (All Lab), a comprehensive research initiative that addresses this technological gap through systematic data collection, model development, and capacity building. Our contributions include: (1) a quality-controlled data collection pipeline, yielding the largest validated African multi-modal speech and text dataset spanning 40 languages with 19 billion tokens of monolingual text and 12,628 hours of aligned speech data; (2) extensive experimental validation demonstrating that our dataset, combined with fine-tuning, achieves substantial improvements over baseline models, averaging +23.69 ChrF++, +0.33 COMET, and +15.34 BLEU points across 31 evaluated languages; and (3) a structured research program that has successfully mentored fifteen early-career researchers, establishing sustainable local capacity. Our comparative evaluation against Google Translate reveals competitive performance in several languages while identifying areas that require continued development.", 'abstract_zh': '非洲语言实验室：通过系统性数据收集、模型开发和能力建设解决现代自然语言处理技术的严重不足', 'title_zh': '非洲语言实验室：促进低资源非洲自然语言处理的合作方法'}
{'arxiv_id': 'arXiv:2510.05637', 'title': 'From Neural Activity to Computation: Biological Reservoirs for Pattern Recognition in Digit Classification', 'authors': 'Ludovico Iannello, Luca Ciampi, Fabrizio Tonelli, Gabriele Lagani, Lucio Maria Calcagnile, Federico Cremisi, Angelo Di Garbo, Giuseppe Amato', 'link': 'https://arxiv.org/abs/2510.05637', 'abstract': 'In this paper, we present a biologically grounded approach to reservoir computing (RC), in which a network of cultured biological neurons serves as the reservoir substrate. This system, referred to as biological reservoir computing (BRC), replaces artificial recurrent units with the spontaneous and evoked activity of living neurons. A multi-electrode array (MEA) enables simultaneous stimulation and readout across multiple sites: inputs are delivered through a subset of electrodes, while the remaining ones capture the resulting neural responses, mapping input patterns into a high-dimensional biological feature space. We evaluate the system through a case study on digit classification using a custom dataset. Input images are encoded and delivered to the biological reservoir via electrical stimulation, and the corresponding neural activity is used to train a simple linear classifier. To contextualize the performance of the biological system, we also include a comparison with a standard artificial reservoir trained on the same task. The results indicate that the biological reservoir can effectively support classification, highlighting its potential as a viable and interpretable computational substrate. We believe this work contributes to the broader effort of integrating biological principles into machine learning and aligns with the goals of human-inspired vision by exploring how living neural systems can inform the design of efficient and biologically plausible models.', 'abstract_zh': '基于生物原理的生物储槽计算方法：通过培养生物神经元构建储槽 substrate 的系统及其在数字分类任务中的评价', 'title_zh': '从神经活动到计算：用于数字分类模式识别的生物蓄水池'}
{'arxiv_id': 'arXiv:2510.05633', 'title': 'Beyond Spectral Peaks: Interpreting the Cues Behind Synthetic Image Detection', 'authors': 'Sara Mandelli, Diego Vila-Portela, David Vázquez-Padín, Paolo Bestagini, Fernando Pérez-González', 'link': 'https://arxiv.org/abs/2510.05633', 'abstract': 'Over the years, the forensics community has proposed several deep learning-based detectors to mitigate the risks of generative AI. Recently, frequency-domain artifacts (particularly periodic peaks in the magnitude spectrum), have received significant attention, as they have been often considered a strong indicator of synthetic image generation. However, state-of-the-art detectors are typically used as black-boxes, and it still remains unclear whether they truly rely on these peaks. This limits their interpretability and trust. In this work, we conduct a systematic study to address this question. We propose a strategy to remove spectral peaks from images and analyze the impact of this operation on several detectors. In addition, we introduce a simple linear detector that relies exclusively on frequency peaks, providing a fully interpretable baseline free from the confounding influence of deep learning. Our findings reveal that most detectors are not fundamentally dependent on spectral peaks, challenging a widespread assumption in the field and paving the way for more transparent and reliable forensic tools.', 'abstract_zh': '近年来，法证社区提出了多种基于深度学习的检测器以减轻生成式AI带来的风险。最近，频域特征（特别是幅度谱中的周期峰值）受到了广泛关注，因为它们经常被认为是有强大指示性的合成图像生成标志。然而，最先进的检测器通常被视为黑盒模型，仍不清楚它们是否真正依赖这些峰值。这限制了它们的可解释性和可信度。在本文中，我们进行了一项系统性的研究来解决这一问题。我们提出了一种从图像中移除频域峰值的策略，并分析了这一操作对该检测器的影响。此外，我们引入了一个仅依赖于频域峰值的简单线性检测器，提供了一个无深度学习混淆影响的完全可解释基准。我们的研究发现表明，大多数检测器本质上并不依赖频域峰值，这挑战了该领域的普遍假设，并为更透明和可靠的法证工具铺平了道路。', 'title_zh': '超出光谱峰值：合成图像检测背后线索的解释'}
{'arxiv_id': 'arXiv:2510.05625', 'title': 'Generative AI-Driven Hierarchical Multi-Agent Framework for Zero-Touch Optical Networks', 'authors': 'Yao Zhang, Yuchen Song, Shengnan Li, Yan Shi, Shikui Shen, Xiongyan Tang, Min Zhang, Danshi Wang', 'link': 'https://arxiv.org/abs/2510.05625', 'abstract': 'The rapid development of Generative Artificial Intelligence (GenAI) has catalyzed a transformative technological revolution across all walks of life. As the backbone of wideband communication, optical networks are expecting high-level autonomous operation and zero-touch management to accommodate their expanding network scales and escalating transmission bandwidth. The integration of GenAI is deemed as the pivotal solution for realizing zero-touch optical networks. However, the lifecycle management of optical networks involves a multitude of tasks and necessitates seamless collaboration across multiple layers, which poses significant challenges to the existing single-agent GenAI systems. In this paper, we propose a GenAI-driven hierarchical multi-agent framework designed to streamline multi-task autonomous execution for zero-touch optical networks. We present the architecture, implementation, and applications of this framework. A field-deployed mesh network is utilized to demonstrate three typical scenarios throughout the lifecycle of optical network: quality of transmission estimation in the planning stage, dynamic channel adding/dropping in the operation stage, and system capacity increase in the upgrade stage. The case studies, illustrate the capabilities of multi-agent framework in multi-task allocation, coordination, execution, evaluation, and summarization. This work provides a promising approach for the future development of intelligent, efficient, and collaborative network management solutions, paving the way for more specialized and adaptive zero-touch optical networks.', 'abstract_zh': '生成式人工智能的快速发展正在推动全方位的技术革命。作为宽带通信的骨干，光网络期望实现高层次的自主运行和零接触管理以应对网络规模的扩大和传输带宽的增加。将生成式人工智能融入其中被视为实现零接触光网络的关键解决方案。然而，光网络的生命周期管理涉及多种任务，并需要多层次的无缝协作，这对现有的单代理生成式人工智能系统提出了重大挑战。本文提出了一种生成式人工智能驱动的分层多代理框架，旨在为零接触光网络简化多任务自主执行。文中介绍了该框架的架构、实现和应用。通过部署在一个典型光网络生命周期中的网状网络，展示了三个典型的场景：规划阶段的传输质量估计、运行阶段的动态通道添加/删除以及升级阶段的系统容量增加。案例研究展示了多代理框架在任务分配、协调、执行、评估和总结方面的能力。本文为智能、高效和协作的网络管理解决方案的发展提供了有前景的方法，并为更具专业性和适应性的零接触光网络铺平了道路。', 'title_zh': '基于生成AI的分层多代理框架以实现零接触光网络'}
{'arxiv_id': 'arXiv:2510.05620', 'title': 'Monte Carlo-Type Neural Operator for Differential Equations', 'authors': 'Salah Eddine Choutri, Prajwal Chauhan, Othmane Mazhar, Saif Eddin Jabari', 'link': 'https://arxiv.org/abs/2510.05620', 'abstract': 'The Monte Carlo-type Neural Operator (MCNO) introduces a framework for learning solution operators of one-dimensional partial differential equations (PDEs) by directly learning the kernel function and approximating the associated integral operator using a Monte Carlo-type approach. Unlike Fourier Neural Operators (FNOs), which rely on spectral representations and assume translation-invariant kernels, MCNO makes no such assumptions. The kernel is represented as a learnable tensor over sampled input-output pairs, and sampling is performed once, uniformly at random from a discretized grid. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training, while an interpolation step maps between arbitrary input and output grids to further enhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with efficient computational cost. We also provide a theoretical analysis proving that the Monte Carlo estimator yields a bounded bias and variance under mild regularity assumptions. This result holds in any spatial dimension, suggesting that MCNO may extend naturally beyond one-dimensional problems. More broadly, this work explores how Monte Carlo-type integration can be incorporated into neural operator frameworks for continuous-domain PDEs, providing a theoretically supported alternative to spectral methods (such as FNO) and to graph-based Monte Carlo approaches (such as the Graph Kernel Neural Operator, GNO).', 'abstract_zh': '蒙特卡洛型神经算子（MCNO）引入了一种直接学习一维偏微分方程（PDE）解算子框架的方法，通过学习核函数并使用蒙特卡洛方法近似相关的积分算子。与依赖谱表示并假设不变核的傅里叶神经算子（FNOs）不同，MCNO 不做此类假设。核表示为输入输出对的可学习张量，并且只进行一次均匀随机采样从离散网格中采样。这种设计使得MCNO能够在不依赖固定全局基函数或在训练过程中重复采样的情况下，跨多个网格分辨率进行泛化。通过插值步骤，MCNO 进一步增强了灵活性，能够映射任意输入和输出网格。在标准一维PDE基准实验中，MCNO 达到了可竞争的准确性并具有高效的计算成本。我们还提供了一种理论分析，证明在温和的正则性假设下，蒙特卡洛估计器具有有界偏差和方差。这一结果在任何空间维数下均成立，表明MCNO 可能自然地扩展到一维问题之外。更广泛地说，本工作探讨了如何将蒙特卡洛型积分纳入连续域PDE的神经算子框架，提供了与谱方法（如FNO）和图基蒙特卡洛方法（如图核神经算子GNO）相比较的理论上支持的替代方案。', 'title_zh': '蒙特卡洛型神经算子求解微分方程'}
{'arxiv_id': 'arXiv:2510.05613', 'title': 'PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction', 'authors': 'Ziqiao Meng, Qichao Wang, Zhiyang Dou, Zixing Song, Zhipeng Zhou, Irwin King, Peilin Zhao', 'link': 'https://arxiv.org/abs/2510.05613', 'abstract': "Autoregressive point cloud generation has long lagged behind diffusion-based approaches in quality. The performance gap stems from the fact that autoregressive models impose an artificial ordering on inherently unordered point sets, forcing shape generation to proceed as a sequence of local predictions. This sequential bias emphasizes short-range continuity but undermines the model's capacity to capture long-range dependencies, hindering its ability to enforce global structural properties such as symmetry, consistent topology, and large-scale geometric regularities. Inspired by the level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a coarse-to-fine generative framework that preserves global shape structure at low resolutions and progressively refines fine-grained geometry at higher scales through a next-scale prediction paradigm. This multi-scale factorization aligns the autoregressive objective with the permutation-invariant nature of point sets, enabling rich intra-scale interactions while avoiding brittle fixed orderings. Experiments on ShapeNet show that PointNSP establishes state-of-the-art (SOTA) generation quality for the first time within the autoregressive paradigm. In addition, it surpasses strong diffusion-based baselines in parameter, training, and inference efficiency. Finally, in dense generation with 8,192 points, PointNSP's advantages become even more pronounced, underscoring its scalability potential.", 'abstract_zh': '自回归点云生成在质量上长期落后于基于扩散的方法。性能差距源于自回归模型对本就无序的点集施加的人工顺序，强制形状生成按局部预测序列进行。这种顺序偏差强调了短程连续性，但削弱了模型捕捉远程依赖的能力，妨碍了其对全局结构属性（如对称性、一致拓扑和大尺度几何规律）的约束。受形状建模中细节层次（LOD）原则的启发，我们提出了一种粗细粒度生成框架PointNSP，该框架在低分辨率下保留全局形状结构，并通过下一个尺度预测范式逐步细化高尺度下的细粒度几何。这种多尺度分解使自回归目标与点集的置换不变性质对齐，促进了丰富的局域交互，同时避免了僵化的固定顺序。实验表明，PointNSP在自回归范式下首次达到最先进的生成质量。此外，它在参数量、训练效率和推理效率上优于强大的基于扩散的方法。最后，在稠密生成8,192点的情况下，PointNSP的优势更加明显，突显了其可扩展性潜力。', 'title_zh': 'PointNSP: 自回归3D点云生成结合下一尺度细节预测'}
{'arxiv_id': 'arXiv:2510.05611', 'title': 'MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction', 'authors': 'Wei-Chieh Huang, Cornelia Caragea', 'link': 'https://arxiv.org/abs/2510.05611', 'abstract': "Implicit Attribute Value Extraction (AVE) is essential for accurately representing products in e-commerce, as it infers lantent attributes from multimodal data. Despite advances in multimodal large language models (MLLMs), implicit AVE remains challenging due to the complexity of multidimensional data and gaps in vision-text understanding. In this work, we introduce \\textsc{\\modelname}, a multi-agent debate framework that employs multiple MLLM agents to iteratively refine inferences. Through a series of debate rounds, agents verify and update each other's responses, thereby improving inference performance and robustness. Experiments on the ImplicitAVE dataset demonstrate that even a few rounds of debate significantly boost accuracy, especially for attributes with initially low performance. We systematically evaluate various debate configurations, including identical or different MLLM agents, and analyze how debate rounds affect convergence dynamics. Our findings highlight the potential of multi-agent debate strategies to address the limitations of single-agent approaches and offer a scalable solution for implicit AVE in multimodal e-commerce.", 'abstract_zh': '隐含属性值Extract（AVE）对于准确表示电子商务中的产品至关重要，因为它可以从多模态数据中推断潜在属性。尽管在多模态大型语言模型（MLLMs）方面取得了进展，但由于多维数据的复杂性和视觉-文本理解之间的差距，隐含AVE依然具有挑战性。在这项工作中，我们引入了\\textsc{\\modelname}，这是一种多智能体辩论框架，采用多个MLLM智能体进行迭代优化。通过一系列辩论轮次，智能体相互验证和更新彼此的回答，从而提高推理性能和鲁棒性。在ImplicitAVE数据集上的实验表明，即使是几轮辩论也能显著提高准确性，尤其是对于初始性能较低的属性。我们系统地评估了各种辩论配置，包括相同的或不同的MLLM智能体，并分析了辩论轮次如何影响收敛动态。我们的发现强调了多智能体辩论策略的潜在价值，以解决单智能体方法的局限性，并提供了一种适用于多模态电子商务中隐含AVE的可扩展解决方案。', 'title_zh': 'MADIAVE: 多代理辩论法用于隐含属性值提取'}
{'arxiv_id': 'arXiv:2510.05609', 'title': 'HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection', 'authors': 'Junwen Chen, Peilin Xiong, Keiji Yanai', 'link': 'https://arxiv.org/abs/2510.05609', 'abstract': 'Recent Human-object interaction detection (HOID) methods highly require prior knowledge from VLMs to enhance the interaction recognition capabilities. The training strategies and model architectures for connecting the knowledge from VLMs to the HOI instance representations from the object detector are challenging, and the whole framework is complex for further development or application. On the other hand, the inherent reasoning abilities of MLLMs on human-object interaction detection are under-explored. Inspired by the recent success of training MLLMs with reinforcement learning (RL) methods, we propose HOI-R1 and first explore the potential of the language model on the HOID task without any additional detection modules. We introduce an HOI reasoning process and HOID reward functions to solve the HOID task by pure text. The results on the HICO-DET dataset show that HOI-R1 achieves 2x the accuracy of the baseline with great generalization ability. The source code is available at this https URL.', 'abstract_zh': 'Recent Human-object Interaction Detection Methods Highly Require Prior Knowledge from VLMs to Enhance Interaction Recognition Capabilities: Exploiting Inherent Reasoning Abilities of MLLMs without Additional Detection Modules', 'title_zh': 'HOI-R1：探究多模态大规模语言模型在人类对象交互检测中的潜力'}
{'arxiv_id': 'arXiv:2510.05605', 'title': 'AutoPentester: An LLM Agent-based Framework for Automated Pentesting', 'authors': 'Yasod Ginige, Akila Niroshan, Sajal Jain, Suranga Seneviratne', 'link': 'https://arxiv.org/abs/2510.05605', 'abstract': 'Penetration testing and vulnerability assessment are essential industry practices for safeguarding computer systems. As cyber threats grow in scale and complexity, the demand for pentesting has surged, surpassing the capacity of human professionals to meet it effectively. With advances in AI, particularly Large Language Models (LLMs), there have been attempts to automate the pentesting process. However, existing tools such as PentestGPT are still semi-manual, requiring significant professional human interaction to conduct pentests. To this end, we propose a novel LLM agent-based framework, AutoPentester, which automates the pentesting process. Given a target IP, AutoPentester automatically conducts pentesting steps using common security tools in an iterative process. It can dynamically generate attack strategies based on the tool outputs from the previous iteration, mimicking the human pentester approach. We evaluate AutoPentester using Hack The Box and custom-made VMs, comparing the results with the state-of-the-art PentestGPT. Results show that AutoPentester achieves a 27.0% better subtask completion rate and 39.5% more vulnerability coverage with fewer steps. Most importantly, it requires significantly fewer human interactions and interventions compared to PentestGPT. Furthermore, we recruit a group of security industry professional volunteers for a user survey and perform a qualitative analysis to evaluate AutoPentester against industry practices and compare it with PentestGPT. On average, AutoPentester received a score of 3.93 out of 5 based on user reviews, which was 19.8% higher than PentestGPT.', 'abstract_zh': '渗透测试和漏洞评估是保障计算机系统安全的重要行业实践。随着网络威胁规模和复杂性的增加，对渗透测试的需求激增，超过了专业人力的能力范围。随着人工智能的发展，特别是大型语言模型（LLMs），已经尝试自动化渗透测试流程。然而，现有的工具如PentestGPT仍需大量专业人工交互来执行渗透测试。为此，我们提出了一种基于大型语言模型代理的新颖框架AutoPentester，以自动化渗透测试流程。给定目标IP，AutoPentester使用常见的安全工具自动执行渗透测试步骤，并以迭代过程进行。它可以根据上一轮工具输出动态生成攻击策略，模拟人工渗透测试者的方法。我们使用Hack The Box和自定义VM评估AutoPentester，并将其结果与最新的PentestGPT进行比较。结果显示，AutoPentester的任务完成率提高了27.0%，漏洞覆盖面积增加了39.5%，且所需步骤较少。最重要的是，与PentestGPT相比，它需要明显较少的人工交互和干预。此外，我们招募了一组安全行业专业志愿者进行用户调查，并进行定性分析，评估AutoPentester与行业实践的符合程度，并将其与PentestGPT进行比较。根据用户评分，AutoPentester的平均得分为3.93，比PentestGPT高19.8%。', 'title_zh': 'AutoPentester：基于LLM代理的自动化渗透测试框架'}
{'arxiv_id': 'arXiv:2510.05598', 'title': 'AgentDR Dynamic Recommendation with Implicit Item-Item Relations via LLM-based Agents', 'authors': 'Mingdai Yang, Nurendra Choudhary, Jiangshu Du, Edward W.Huang, Philip S.Yu, Karthik Subbian, Danai Kourta', 'link': 'https://arxiv.org/abs/2510.05598', 'abstract': "Recent agent-based recommendation frameworks aim to simulate user behaviors by incorporating memory mechanisms and prompting strategies, but they struggle with hallucinating non-existent items and full-catalog ranking. Besides, a largely underexplored opportunity lies in leveraging LLMs'commonsense reasoning to capture user intent through substitute and complement relationships between items, which are usually implicit in datasets and difficult for traditional ID-based recommenders to capture. In this work, we propose a novel LLM-agent framework, AgenDR, which bridges LLM reasoning with scalable recommendation tools. Our approach delegates full-ranking tasks to traditional models while utilizing LLMs to (i) integrate multiple recommendation outputs based on personalized tool suitability and (ii) reason over substitute and complement relationships grounded in user history. This design mitigates hallucination, scales to large catalogs, and enhances recommendation relevance through relational reasoning. Through extensive experiments on three public grocery datasets, we show that our framework achieves superior full-ranking performance, yielding on average a twofold improvement over its underlying tools. We also introduce a new LLM-based evaluation metric that jointly measures semantic alignment and ranking correctness.", 'abstract_zh': '基于代理的 recent 推荐框架 aims 致力于通过集成记忆机制和提示策略来模拟用户行为，但它们在 hallucinate 非存在的项目和全目录排名方面存在困难。此外，尚有大量未充分利用的机会在于利用大规模语言模型 (LLM) 的常识推理来通过项目之间的替代和补充关系捕捉用户意图，这些关系通常在数据集中是隐含的，传统基于 ID 的推荐器难以捕捉。在这项工作中，我们提出了一种名为 AgenDR 的新型 LLM-代理框架，该框架将 LLM 推理与可扩展的推荐工具相结合。我们的方法将全排名任务委托给传统模型，同时利用 LLMs：(i) 根据个性化工具适合度集成多个推荐输出，(ii) 基于用户历史进行替代和补充关系的推理。这种设计减轻了 hallucination、适用于大目录，并通过关系推理增强推荐的相关性。通过在三个公开的杂货数据集上的广泛实验，我们展示了我们框架实现了优于其底层工具的全排名性能，平均改善幅度超过一倍。我们还引入了一个基于 LLM 的新评估指标，该指标联合衡量语义一致性和排名准确性。', 'title_zh': '基于LLM代理的动态推荐系统：通过隐式项-项关系'}
{'arxiv_id': 'arXiv:2510.05593', 'title': 'Improving Chain-of-Thought Efficiency for Autoregressive Image Generation', 'authors': 'Zeqi Gu, Markos Georgopoulos, Xiaoliang Dai, Marjan Ghazvininejad, Chu Wang, Felix Juefei-Xu, Kunpeng Li, Yujun Shi, Zecheng He, Zijian He, Jiawei Zhou, Abe Davis, Jialiang Wang', 'link': 'https://arxiv.org/abs/2510.05593', 'abstract': 'Autoregressive multimodal large language models have recently gained popularity for image generation, driven by advances in foundation models. To enhance alignment and detail, newer approaches employ chain-of-thought (CoT) reasoning, expanding user inputs into elaborated prompts prior to image synthesis. However, this strategy can introduce unnecessary redundancy -- a phenomenon we call visual overthinking -- which increases computational costs and can introduce details that contradict the original prompt. In this work, we explore how to generate more concise CoT sequences for more efficient image generation. We introduce ShortCoTI, a lightweight optimization framework that encourages more concise CoT while preserving output image quality. ShortCoTI rewards more concise prompts with an adaptive function that scales according to an estimated difficulty for each task. Incorporating this reward into a reinforcement learning paradigm reduces prompt reasoning length by 54% while maintaining or slightly improving quality metrics across multiple benchmarks (T2I-CompBench, GenEval). Qualitative analysis shows that our method eliminates verbose explanations and repetitive refinements, producing reasoning prompts that are both concise and semantically rich. As a result, ShortCoTI improves computational efficiency without compromising the fidelity or visual appeal of generated images.', 'abstract_zh': '自回归多模态大型语言模型在图像生成中的应用：一种减少视觉过度思考的轻量级优化框架', 'title_zh': '提高自回归图像生成的链条思维效率'}
{'arxiv_id': 'arXiv:2510.05589', 'title': 'Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising', 'authors': 'Kangjia Yan, Chenxi Liu, Hao Miao, Xinle Wu, Yan Zhao, Chenjuan Guo, Bin Yang', 'link': 'https://arxiv.org/abs/2510.05589', 'abstract': 'The proliferation of mobile devices generates a massive volume of time series across various domains, where effective time series forecasting enables a variety of real-world applications. This study focuses on a new problem of source-free domain adaptation for time series forecasting. It aims to adapt a pretrained model from sufficient source time series to the sparse target time series domain without access to the source data, embracing data protection regulations. To achieve this, we propose TimePD, the first source-free time series forecasting framework with proxy denoising, where large language models (LLMs) are employed to benefit from their generalization capabilities. Specifically, TimePD consists of three key components: (1) dual-branch invariant disentangled feature learning that enforces representation- and gradient-wise invariance by means of season-trend decomposition; (2) lightweight, parameter-free proxy denoising that dynamically calibrates systematic biases of LLMs; and (3) knowledge distillation that bidirectionally aligns the denoised prediction and the original target prediction. Extensive experiments on real-world datasets offer insight into the effectiveness of the proposed TimePD, outperforming SOTA baselines by 9.3% on average.', 'abstract_zh': '移动设备的普及生成了各个领域大量的时间序列数据，有效的时序预测能够推动多种实际应用。本研究关注一个新的无源域适应的时序预测问题，旨在无需访问源数据的情况下，将预训练模型适应稀疏的目标时间序列域，符合数据保护法规。为实现这一目标，我们提出TimePD，这是一个带有代理去噪的一站式无源域适应时序预测框架，利用大语言模型的泛化能力。具体而言，TimePD 包含三个关键组件：(1) 双分支不变解耦特征学习，通过季节趋势分解确保表示层面和梯度层面的不变性；(2) 轻量级、参数无关的代理去噪，动态校准大语言模型的系统偏差；(3) 知识蒸馏，双向对齐去噪预测和原始目标预测。在实际数据集上的广泛实验展示了所提TimePD的有效性，平均优于最先进的baseline 9.3%。', 'title_zh': '源free时间序列预测中的不变特征解耦研究：代理去噪方法'}
{'arxiv_id': 'arXiv:2510.05566', 'title': 'Domain-Shift-Aware Conformal Prediction for Large Language Models', 'authors': 'Zhexiao Lin, Yuanyuan Li, Neeraj Sarna, Yuanyuan Gao, Michael von Gablenz', 'link': 'https://arxiv.org/abs/2510.05566', 'abstract': 'Large language models have achieved impressive performance across diverse tasks. However, their tendency to produce overconfident and factually incorrect outputs, known as hallucinations, poses risks in real world applications. Conformal prediction provides finite-sample, distribution-free coverage guarantees, but standard conformal prediction breaks down under domain shift, often leading to under-coverage and unreliable prediction sets. We propose a new framework called Domain-Shift-Aware Conformal Prediction (DS-CP). Our framework adapts conformal prediction to large language models under domain shift, by systematically reweighting calibration samples based on their proximity to the test prompt, thereby preserving validity while enhancing adaptivity. Our theoretical analysis and experiments on the MMLU benchmark demonstrate that the proposed method delivers more reliable coverage than standard conformal prediction, especially under substantial distribution shifts, while maintaining efficiency. This provides a practical step toward trustworthy uncertainty quantification for large language models in real-world deployment.', 'abstract_zh': '面向域迁移的统一预测 (Domain-Shift-Aware Conformal Prediction)', 'title_zh': '面向域变化的同态预测方法用于大型语言模型'}
{'arxiv_id': 'arXiv:2510.05562', 'title': 'Generative Dynamic Graph Representation Learning for Conspiracy Spoofing Detection', 'authors': 'Sheng Xiang, Yidong Jiang, Yunting Chen, Dawei Cheng, Guoping Zhao, Changjun Jiang', 'link': 'https://arxiv.org/abs/2510.05562', 'abstract': 'Spoofing detection in financial trading is crucial, especially for identifying complex behaviors such as conspiracy spoofing. Traditional machine-learning approaches primarily focus on isolated node features, often overlooking the broader context of interconnected nodes. Graph-based techniques, particularly Graph Neural Networks (GNNs), have advanced the field by leveraging relational information effectively. However, in real-world spoofing detection datasets, trading behaviors exhibit dynamic, irregular patterns. Existing spoofing detection methods, though effective in some scenarios, struggle to capture the complexity of dynamic and diverse, evolving inter-node relationships. To address these challenges, we propose a novel framework called the Generative Dynamic Graph Model (GDGM), which models dynamic trading behaviors and the relationships among nodes to learn representations for conspiracy spoofing detection. Specifically, our approach incorporates the generative dynamic latent space to capture the temporal patterns and evolving market conditions. Raw trading data is first converted into time-stamped sequences. Then we model trading behaviors using the neural ordinary differential equations and gated recurrent units, to generate the representation incorporating temporal dynamics of spoofing patterns. Furthermore, pseudo-label generation and heterogeneous aggregation techniques are employed to gather relevant information and enhance the detection performance for conspiratorial spoofing behaviors. Experiments conducted on spoofing detection datasets demonstrate that our approach outperforms state-of-the-art models in detection accuracy. Additionally, our spoofing detection system has been successfully deployed in one of the largest global trading markets, further validating the practical applicability and performance of the proposed method.', 'abstract_zh': '金融交易中的伪造检测至关重要，特别是对于识别复杂的共谋伪造行为。传统的机器学习方法主要侧重于孤立节点特征，往往忽视了节点间广泛联系的背景。基于图的技术，尤其是图神经网络（GNNs），通过有效地利用关系信息推进了该领域的发展。然而，在实际的伪造检测数据集中，交易行为表现出动态且不规则的 pattern。现有的一些伪造检测方法虽然在某些场景下有效，但在捕捉动态且多变的节点间关系复杂性方面仍存在不足。为了解决这些挑战，我们提出了一种名为生成动态图模型（GDGM）的新框架，该框架建模了动态交易行为及其节点间的关系，以学习用于共谋伪造检测的表示。具体而言，我们的方法结合生成动态潜在空间来捕捉时间模式和市场条件的变化。原始交易数据首先转换为带时间戳的序列。然后，我们使用神经常微分方程和门控循环单元建模交易行为，生成包含伪造模式时间动态特性的表示。此外，我们采用了伪标签生成和异质聚合技术来收集相关信息，从而增强检测共谋伪造行为的性能。在伪造检测数据集上的实验表明，我们的方法在检测准确性上超过了最先进的模型。此外，我们的伪造检测系统已在最大的全球交易市场之一成功部署，进一步验证了所提方法的实际适用性和性能。', 'title_zh': '生成式动态图表示学习在阴谋spoof检测中的应用'}
{'arxiv_id': 'arXiv:2510.05554', 'title': 'Critical attention scaling in long-context transformers', 'authors': 'Shi Chen, Zhengjiang Lin, Yury Polyanskiy, Philippe Rigollet', 'link': 'https://arxiv.org/abs/2510.05554', 'abstract': 'As large language models scale to longer contexts, attention layers suffer from a fundamental pathology: attention scores collapse toward uniformity as context length $n$ increases, causing tokens to cluster excessively, a phenomenon known as rank-collapse. While $\\textit{attention scaling}$ effectively addresses this deficiency by rescaling attention scores with a polylogarithmic factor $\\beta_n$, theoretical justification for this approach remains lacking.\nWe analyze a simplified yet tractable model that magnifies the effect of attention scaling. In this model, attention exhibits a phase transition governed by the scaling factor $\\beta_n$: insufficient scaling collapses all tokens to a single direction, while excessive scaling reduces attention to identity, thereby eliminating meaningful interactions between tokens. Our main result identifies the critical scaling $\\beta_n \\asymp \\log n$ and provides a rigorous justification for attention scaling in YaRN and Qwen, clarifying why logarithmic scaling maintains sparse, content-adaptive attention at large context lengths.', 'abstract_zh': '随着大型语言模型处理更长的上下文，注意力层遭受一种基本的病理现象：随着上下文长度 \\(n\\) 的增加，注意力分数趋向均匀，导致令牌过度聚集，这种现象称为秩塌陷。虽然注意力缩放通过使用.polylogarithmic 因子 \\(\\beta_n\\) 重新缩放注意力分数有效解决了这一缺陷，但这种方法的理论依据仍然缺乏。\n\n我们分析了一个简化但可处理的模型，该模型放大了注意力缩放的效果。在这种模型中，注意力由缩放因子 \\(\\beta_n\\) 控制的相变过程所支配：缩放不足会使所有令牌聚集成一个方向，而缩放过度则将注意力压缩为恒等映射，从而消除令牌间的有意义交互。我们的主要结果确定了临界缩放 \\(\\beta_n \\asymp \\log n\\)，并为 YaRN 和 Qwen 中的注意力缩放提供了严格的理论依据，解释了为什么对数缩放在长上下文长度下能够保持稀疏和内容自适应的注意力机制。', 'title_zh': '长上下文变换器中的关键注意尺度变换'}
{'arxiv_id': 'arXiv:2510.05538', 'title': "Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work", 'authors': 'Owen Henkel, Bill Roberts, Doug Jaffe, Laurence Holt', 'link': 'https://arxiv.org/abs/2510.05538', 'abstract': 'Recent advances in multimodal large language models (MLLMs) raise the question of their potential for grading, analyzing, and offering feedback on handwritten student classwork. This capability would be particularly beneficial in elementary and middle-school mathematics education, where most work remains handwritten, because seeing students\' full working of a problem provides valuable insights into their learning processes, but is extremely time-consuming to grade. We present two experiments investigating MLLM performance on handwritten student mathematics classwork. Experiment A examines 288 handwritten responses from Ghanaian middle school students solving arithmetic problems with objective answers. In this context, models achieved near-human accuracy (95%, k = 0.90) but exhibited occasional errors that human educators would be unlikely to make. Experiment B evaluates 150 mathematical illustrations from American elementary students, where the drawings are the answer to the question. These tasks lack single objective answers and require sophisticated visual interpretation as well as pedagogical judgment in order to analyze and evaluate them. We attempted to separate MLLMs\' visual capabilities from their pedagogical abilities by first asking them to grade the student illustrations directly, and then by augmenting the image with a detailed human description of the illustration. We found that when the models had to analyze the student illustrations directly, they struggled, achieving only k = 0.20 with ground truth scores, but when given human descriptions, their agreement levels improved dramatically to k = 0.47, which was in line with human-to-human agreement levels. This gap suggests MLLMs can "see" and interpret arithmetic work relatively well, but still struggle to "see" student mathematical illustrations.', 'abstract_zh': '最近在多模态大型语言模型方面的进展引发了对其在评估、分析和提供手写学生作业反馈方面的潜力的关注。这一能力特别有益于初高中数学教育，因为在这些阶段，大多数工作仍为手写，因为查看学生完整的问题解答过程可以提供有价值的学习过程洞察，但对其进行评分却极其耗时。我们进行了两项实验以研究多模态大型语言模型在处理手写学生数学作业方面的性能。实验A检查了288份加纳初中学生解决具有客观答案算术问题的手写回应。在这种情况下，模型达到了接近人类的准确率（95%，k = 0.90），但偶尔会出现人类教育者不会犯的错误。实验B评估了150份来自美国小学生的手绘数学图形，其中绘画是答案。这些任务缺乏单一客观答案，需要复杂的视觉解释以及教学判断，以分析和评价它们。我们尝试通过首先让模型直接评分学生的图形，然后通过增加详细的human描述来分离多模态大型语言模型的视觉能力和教学能力。我们发现，当模型需要直接分析学生的图形时，它们遇到了困难，准确率仅为k = 0.20，但当提供human描述时，其一致性水平显著提高到k = 0.47，与人类之间的共识水平相符。这一差距表明，多模态大型语言模型能够较好地“看到”并解释算术工作，但在“看到”学生数学图形方面仍然存在困难。', 'title_zh': '纵观全局：评估多模态大语言模型解释和评分手写学生作业的能力'}
{'arxiv_id': 'arXiv:2510.05535', 'title': 'Permutation-Invariant Representation Learning for Robust and Privacy-Preserving Feature Selection', 'authors': 'Rui Liu, Tao Zhe, Yanjie Fu, Feng Xia, Ted Senator, Dongjie Wang', 'link': 'https://arxiv.org/abs/2510.05535', 'abstract': 'Feature selection eliminates redundancy among features to improve downstream task performance while reducing computational overhead. Existing methods often struggle to capture intricate feature interactions and adapt across diverse application scenarios. Recent advances employ generative intelligence to alleviate these drawbacks. However, these methods remain constrained by permutation sensitivity in embedding and reliance on convexity assumptions in gradient-based search. To address these limitations, our initial work introduces a novel framework that integrates permutation-invariant embedding with policy-guided search. Although effective, it still left opportunities to adapt to realistic distributed scenarios. In practice, data across local clients is highly imbalanced, heterogeneous and constrained by strict privacy regulations, limiting direct sharing. These challenges highlight the need for a framework that can integrate feature selection knowledge across clients without exposing sensitive information. In this extended journal version, we advance the framework from two perspectives: 1) developing a privacy-preserving knowledge fusion strategy to derive a unified representation space without sharing sensitive raw data. 2) incorporating a sample-aware weighting strategy to address distributional imbalance among heterogeneous local clients. Extensive experiments validate the effectiveness, robustness, and efficiency of our framework. The results further demonstrate its strong generalization ability in federated learning scenarios. The code and data are publicly available: this https URL.', 'abstract_zh': '特征选择通过消除特征间的冗余来提高下游任务性能并减少计算开销，但现有方法往往难以捕捉复杂的特征交互并适应多样化的应用场景。近期进展利用生成智能来缓解这些缺陷，但这些方法仍然受限于嵌入的置换敏感性和基于梯度搜索的凸性假设。为了应对这些局限性，我们初步工作提出了一种新颖的框架，结合置换不变嵌入与策略引导搜索。尽管该框架有效，但仍有机会适应实际的分布式场景。实践中，来自本地客户端的数据高度不平衡、异质化且受限于严格的隐私法规，限制了直接共享。这些挑战突显了需要一种框架来在不暴露敏感信息的情况下，在客户端之间集成特征选择知识的需求。在本文扩展的期刊版本中，我们从两个视角推进了该框架：1) 开发一种隐私保全的知识融合策略，无需共享敏感原始数据即可获得统一的表示空间；2) 引入样本感知的加权策略以应对异质化本地客户端间的分布不平衡。广泛实验验证了该框架的有效性、鲁棒性和效率，并进一步证明了其在联邦学习场景中的强大泛化能力。该代码和数据已公开：this https URL。', 'title_zh': '用于稳健且隐私保护特征选择的排列不变表示学习'}
{'arxiv_id': 'arXiv:2510.05526', 'title': 'Provably Mitigating Corruption, Overoptimization, and Verbosity Simultaneously in Offline and Online RLHF/DPO Alignment', 'authors': 'Ziyi Chen, Junyi Li, Peiran Yu, Heng Huang', 'link': 'https://arxiv.org/abs/2510.05526', 'abstract': 'Reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) are important techniques to align large language models (LLM) with human preference. However, the quality of RLHF and DPO training is seriously compromised by \\textit{\\textbf{C}orrupted} preference, reward \\textit{\\textbf{O}veroptimization}, and bias towards \\textit{\\textbf{V}erbosity}. To our knowledge, most existing works tackle only one of these important issues, and the few other works require much computation to estimate multiple reward models and lack theoretical guarantee of generalization ability. In this work, we propose RLHF-\\textbf{COV} and DPO-\\textbf{COV} algorithms that can simultaneously mitigate these three issues, in both offline and online settings. This ability is theoretically demonstrated by obtaining length-regularized generalization error rates for our DPO-COV algorithms trained on corrupted data, which match the best-known rates for simpler cases with clean data and without length regularization. Moreover, our DPO-COV algorithm is simple to implement without reward estimation, and is proved to be equivalent to our RLHF-COV algorithm, which directly implies the equivalence between the vanilla RLHF and DPO algorithms. Experiments demonstrate the effectiveness of our DPO-COV algorithms under both offline and online settings.', 'abstract_zh': '基于人类反馈的强化学习（RLHF-COV）和直接偏好优化（DPO-COV）：同时缓解污染偏好、过度优化和冗余性问题', 'title_zh': '证明性缓解离线和在线RLHF/DPO对齐中的腐败、过度优化和冗余问题'}
{'arxiv_id': 'arXiv:2510.05520', 'title': 'CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension', 'authors': 'Rui Li, Zeyu Zhang, Xiaohe Bo, Zihang Tian, Xu Chen, Quanyu Dai, Zhenhua Dong, Ruiming Tang', 'link': 'https://arxiv.org/abs/2510.05520', 'abstract': "Current Large Language Models (LLMs) are confronted with overwhelming information volume when comprehending long-form documents. This challenge raises the imperative of a cohesive memory module, which can elevate vanilla LLMs into autonomous reading agents. Despite the emergence of some heuristic approaches, a systematic design principle remains absent. To fill this void, we draw inspiration from Jean Piaget's Constructivist Theory, illuminating three traits of the agentic memory -- structured schemata, flexible assimilation, and dynamic accommodation. This blueprint forges a clear path toward a more robust and efficient memory system for LLM-based reading comprehension. To this end, we develop CAM, a prototype implementation of Constructivist Agentic Memory that simultaneously embodies the structurality, flexibility, and dynamicity. At its core, CAM is endowed with an incremental overlapping clustering algorithm for structured memory development, supporting both coherent hierarchical summarization and online batch integration. During inference, CAM adaptively explores the memory structure to activate query-relevant information for contextual response, akin to the human associative process. Compared to existing approaches, our design demonstrates dual advantages in both performance and efficiency across diverse long-text reading comprehension tasks, including question answering, query-based summarization, and claim verification.", 'abstract_zh': '当前的大规模语言模型在理解长文档时面临着巨大的信息量挑战。这促使我们必须开发一个协调的记忆模块，以提升基础的大规模语言模型为自主阅读代理。尽管已经出现了一些启发式方法，但系统的设计原则仍然缺失。为弥补这一空白，我们从 jean Piaget 的建构主义理论中汲取灵感，阐述了代理记忆的三大特征——结构化的图式、灵活的同化和动态的顺应。这一蓝图为基于大规模语言模型的阅读理解提供了更为坚固和高效的记忆系统框架。为了实现这一目标，我们开发了CAM，这是一种构建成败者的原型实现，同时具备结构化、灵活性和动态性。CAM的核心在于递增重叠聚类算法，以支持有序层级总结和在线批处理集成。在推理过程中，CAM能够自适应地探索记忆结构，激活与查询相关的信息以生成上下文响应，类似于人类的联想过程。与现有方法相比，我们的设计在多种长文本阅读理解任务中，包括问答、查询驱动的总结和断言验证中，展示了在性能和效率上的双重重叠优势。', 'title_zh': 'CAM：基于构建主义视角的代理记忆在基于LLM的阅读理解中的应用'}
{'arxiv_id': 'arXiv:2510.05497', 'title': 'Orders in Chaos: Enhancing Large-Scale MoE LLM Serving with Data Movement Forecasting', 'authors': 'Zhongkai Yu, Yue Guan, Zihao Yu, Chenyang Zhou, Shuyi Pei, Yangwook Kang, Yufei Ding, Po-An Tsai', 'link': 'https://arxiv.org/abs/2510.05497', 'abstract': 'Large Language Models (LLMs) with Mixture of Experts (MoE) architectures achieve remarkable performance improvements, but their random expert selection mechanism introduces significant data movement overhead that becomes the dominant bottleneck in multi-unit serving systems. To forecast the patterns underlying this data movement, we conduct comprehensive data-movement-centric profiling across three state-of-the-art large-scale MoE models (200B- 671B) using over 24,000 requests spanning diverse workloads. With the resulting 150GB+ trace files, we perform systematic analysis from both temporal and spatial perspectives and distill six key insights to guide the design of diverse future serving systems. Taking wafer-scale GPUs as a case study, we demonstrate that minor architectural modifications leveraging our insights achieve substantial performance gains, delivering 6.3X and 4.0X average speedups on DeepSeek V3 and Qwen3, respectively. Our work provides the first comprehensive data-centric analysis of MoE models at scale. Our profiling traces and analysis results are publicly available at {this https URL. We will also release our simulation framework shortly to facilitate future research in this area.', 'abstract_zh': '大规模语言模型（LLMs）采用专家混合（MoE）架构实现了显著的性能提升，但其随机专家选择机制引入了重要的数据移动开销，成为多单元服务系统中的主要瓶颈。为了预测这种数据移动背后的模式，我们使用超过24,000个请求，在三个先进的大规模MoE模型（200B-671B）上进行全面的数据移动中心化剖析。基于所产生的150GB以上的跟踪文件，我们从时间和空间两个维度进行了系统的分析，并总结出六条关键洞察以指导未来多样化的服务系统设计。以晶圆级GPU为例，我们证明了利用这些洞察进行的小架构修改实现了显著的性能提升，分别在DeepSeek V3和Qwen3上平均提升了6.3倍和4.0倍。我们的工作提供了首次全面的数据为中心的大规模MoE模型分析。我们的剖析跟踪数据和分析结果已公开发布在{this https URL. 我们还将很快发布我们的仿真框架，以便于未来对此领域的研究。', 'title_zh': '混沌中的秩序：通过数据移动预测提升大规模MoE语言模型服务'}
{'arxiv_id': 'arXiv:2510.05492', 'title': 'High-Fidelity Synthetic ECG Generation via Mel-Spectrogram Informed Diffusion Training', 'authors': 'Zhuoyi Huang, Nutan Sahoo, Anamika Kumari, Girish Kumar, Kexuan Cai, Shixing Cao, Yue Kang, Tian Xia, Somya Chatterjee, Nicholas Hausman, Aidan Jay, Eric S. Rosenthal, Soundar Srinivasan, Sadid Hasan, Alex Fedorov, Sulaiman Vesal, Soundar Srinivasan, Sadid Hasan, Alex Fedorov, Sulaiman Vesal', 'link': 'https://arxiv.org/abs/2510.05492', 'abstract': 'The development of machine learning for cardiac care is severely hampered by privacy restrictions on sharing real patient electrocardiogram (ECG) data. Although generative AI offers a promising solution, the real-world use of existing model-synthesized ECGs is limited by persistent gaps in trustworthiness and clinical utility. In this work, we address two major shortcomings of current generative ECG methods: insufficient morphological fidelity and the inability to generate personalized, patient-specific physiological signals. To address these gaps, we build on a conditional diffusion-based Structured State Space Model (SSSD-ECG) with two principled innovations: (1) MIDT-ECG (Mel-Spectrogram Informed Diffusion Training), a novel training paradigm with time-frequency domain supervision to enforce physiological structural realism, and (2) multi-modal demographic conditioning to enable patient-specific synthesis. We comprehensively evaluate our approach on the PTB-XL dataset, assessing the synthesized ECG signals on fidelity, clinical coherence, privacy preservation, and downstream task utility. MIDT-ECG achieves substantial gains: it improves morphological coherence, preserves strong privacy guarantees with all metrics evaluated exceeding the baseline by 4-8%, and notably reduces the interlead correlation error by an average of 74%, while demographic conditioning enhances signal-to-noise ratio and personalization. In critical low-data regimes, a classifier trained on datasets supplemented with our synthetic ECGs achieves performance comparable to a classifier trained solely on real data. Together, we demonstrate that ECG synthesizers, trained with the proposed time-frequency structural regularization scheme, can serve as personalized, high-fidelity, privacy-preserving surrogates when real data are scarce, advancing the responsible use of generative AI in healthcare.', 'abstract_zh': '基于条件扩散的结构状态空间模型在心电图合成中的进展：解决形态学保真度不足和个人化生理信号生成能力欠缺问题', 'title_zh': '基于梅尔频谱引导的扩散训练高保真合成心电图生成'}
{'arxiv_id': 'arXiv:2510.05490', 'title': 'LANTERN: Scalable Distillation of Large Language Models for Job-Person Fit and Explanation', 'authors': 'Zhoutong Fu, Yihan Cao, Yi-Lin Chen, Aman Lunia, Liming Dong, Neha Saraf, Ruijie Jiang, Yun Dai, Qingquan Song, Tan Wang, Guoyao Li, Derek Koh, Haichao Wei, Zhipeng Wang, Aman Gupta, Chengming Jiang, Jianqiang Shen, Liangjie Hong, Wenjing Zhang', 'link': 'https://arxiv.org/abs/2510.05490', 'abstract': "Large language models (LLMs) have achieved strong performance across a wide range of natural language processing tasks. However, deploying LLMs at scale for domain specific applications, such as job-person fit and explanation in job seeking platforms, introduces distinct challenges. At LinkedIn, the job person fit task requires analyzing a candidate's public profile against job requirements to produce both a fit assessment and a detailed explanation. Directly applying open source or finetuned LLMs to this task often fails to yield high quality, actionable feedback due to the complexity of the domain and the need for structured outputs. Moreover, the large size of these models leads to high inference latency and limits scalability, making them unsuitable for online use. To address these challenges, we introduce LANTERN, a novel LLM knowledge distillation framework tailored specifically for job person fit tasks. LANTERN involves modeling over multiple objectives, an encoder model for classification purpose, and a decoder model for explanation purpose. To better distill the knowledge from a strong black box teacher model to multiple downstream models, LANTERN incorporates multi level knowledge distillation that integrates both data and logit level insights. In addition to introducing the knowledge distillation framework, we share our insights on post training techniques and prompt engineering, both of which are crucial for successfully adapting LLMs to domain specific downstream tasks. Extensive experimental results demonstrate that LANTERN significantly improves task specific metrics for both job person fit and explanation. Online evaluations further confirm its effectiveness, showing measurable gains in job seeker engagement, including a 0.24\\% increase in apply rate and a 0.28\\% increase in qualified applications.", 'abstract_zh': '大规模语言模型（LLMs）在多种自然语言处理任务中取得了强大的性能。然而，将LLMs大规模应用于特定领域的应用，如职位与候选人匹配和求职平台上的解释，引入了独特的挑战。在LinkedIn，职位与候选人匹配任务要求分析候选人的公开资料与职位要求以产生匹配评估和详细解释。直接将开源或微调的LLMs应用于此任务，由于领域复杂性和对结构化输出的需求，往往难以获得高质量、可操作的反馈。此外，这些模型的大量级导致推理延迟高，限制了其可扩展性，使其不适合在线使用。为应对这些挑战，我们引入了LANTERN，这是一种专门针对职位与候选人匹配任务的知识蒸馏框架。LANTERN包括多目标建模、用于分类目的的编码器模型和用于解释目的的解码器模型。为了更好地将强黑盒教师模型的知识蒸馏到多个下游模型中，LANTERN结合了多层次的知识蒸馏，整合了数据和logit级别见解。除了介绍知识蒸馏框架，我们还分享了关于后训练技术和提示工程的见解，两者对于成功适应特定领域下游任务的LLMs至关重要。实验结果表明，LANTERN在职位与候选人匹配和解释任务特定指标上都有显著改进。在线评估进一步证实其有效性，显示出求职者参与度的可测量提升，包括申请率提高了0.24%，合格申请增加了0.28%。', 'title_zh': 'LANTERN: 大型语言模型可扩展蒸馏及其在岗位匹配与解释中的应用'}
{'arxiv_id': 'arXiv:2510.05468', 'title': 'AMAQ: Adaptive Mixed-bit Activation Quantization for Collaborative Parameter Efficient Fine-tuning', 'authors': 'Yurun Song, Zhuoyi Yang, Ian G. Harris, Sangeetha Abdu Jyothi', 'link': 'https://arxiv.org/abs/2510.05468', 'abstract': 'Large Language Models (LLMs) are scaling rapidly, creating significant challenges for collaborative server client distributed training, particularly in terms of communication efficiency and computational overheads. To address these challenges, we implement Parameter-efficient Split Learning, which effectively balances efficiency and performance for collaborative training on low-resource devices.\nTo reduce communication overhead in collaborative training, we introduce Adaptive Mixed bit Activation Quantization (AMAQ), a strategy that progressively compresses activations and gradients from high precision (6 to 8 bits) to low precision (3 to 4 bits). AMAQ achieves this by effectively allocating bit budgets across channels based on feature wise and layer wise importance using bit regularization.\nUnder the same bit budgets, AMAQ outperforms fixed-precision approaches, delivering about 2.5% higher generation accuracy and about 1.3% better classification accuracy for models like LLaMA3 8B and Qwen2.5 7B. In addition, it significantly enhances training stability and reducing ultra-low bit representation collapse during the training.\nExperiments demonstrate that AMAQ integrates effectively into practical multi-machine collaborative training setups, offering superior inference accuracy with only a modest communication overhead for bits adaptation during training. This trade off makes AMAQ a practical and effective solution for collaborative training with minimal communication cost.', 'abstract_zh': '大规模语言模型（LLMs）的规模正在迅速扩大，这为协作服务器客户端分布式训练带来了显著挑战，特别是在通信效率和计算开销方面。为了解决这些挑战，我们实施了参数高效的拆分学习，该方法有效地在低资源设备上实现了效率与性能的平衡。\n为了减少协作训练中的通信开销，我们引入了自适应混合位激活量化（AMAQ）策略，该策略逐步将激活和梯度从高精度（6至8位）压缩到低精度（3至4位）。AMAQ通过基于特征和层的重要性使用位正则化有效分配位预算。\n在相同的位预算下，AMAQ优于固定精度方法，对于LLaMA3 8B和Qwen2.5 7B等模型，其生成准确率提高约2.5%，分类准确率提高约1.3%。此外，它还能显著增强训练稳定性，并在训练过程中减少超低位表示坍塌。\n实验表明，AMAQ能够有效地集成到实际的多机协作训练设置中，仅在训练期间对位的适应过程中带来适度的通信开销的情况下，提供优越的推理准确性。这种权衡使AMAQ成为一种实用且有效的协作训练解决方案，具有最小的通信成本。', 'title_zh': 'AMAQ: 自适应混合位宽激活量化的协作参数高效微调'}
{'arxiv_id': 'arXiv:2510.05453', 'title': 'QDeepGR4J: Quantile-based ensemble of deep learning and GR4J hybrid rainfall-runoff models for extreme flow prediction with uncertainty quantification', 'authors': 'Arpit Kapoor, Rohitash Chandra', 'link': 'https://arxiv.org/abs/2510.05453', 'abstract': 'Conceptual rainfall-runoff models aid hydrologists and climate scientists in modelling streamflow to inform water management practices. Recent advances in deep learning have unravelled the potential for combining hydrological models with deep learning models for better interpretability and improved predictive performance. In our previous work, we introduced DeepGR4J, which enhanced the GR4J conceptual rainfall-runoff model using a deep learning model to serve as a surrogate for the routing component. DeepGR4J had an improved rainfall-runoff prediction accuracy, particularly in arid catchments. Quantile regression models have been extensively used for quantifying uncertainty while aiding extreme value forecasting. In this paper, we extend DeepGR4J using a quantile regression-based ensemble learning framework to quantify uncertainty in streamflow prediction. We also leverage the uncertainty bounds to identify extreme flow events potentially leading to flooding. We further extend the model to multi-step streamflow predictions for uncertainty bounds. We design experiments for a detailed evaluation of the proposed framework using the CAMELS-Aus dataset. The results show that our proposed Quantile DeepGR4J framework improves the predictive accuracy and uncertainty interval quality (interval score) compared to baseline deep learning models. Furthermore, we carry out flood risk evaluation using Quantile DeepGR4J, and the results demonstrate its suitability as an early warning system.', 'abstract_zh': '基于概念性降雨径流模型和深度学习的水文不确定性量化与极端流量事件识别研究', 'title_zh': '基于分位数的深度学习与GR4J混合水文模型集合预测极端流量及其不确定性量化'}
{'arxiv_id': 'arXiv:2510.05442', 'title': 'Adversarial Reinforcement Learning for Large Language Model Agent Safety', 'authors': 'Zizhao Wang, Dingcheng Li, Vaishakh Keshava, Phillip Wallis, Ananth Balashankar, Peter Stone, Lukas Rutishauser', 'link': 'https://arxiv.org/abs/2510.05442', 'abstract': 'Large Language Model (LLM) agents can leverage tools such as Google Search to complete complex tasks. However, this tool usage introduces the risk of indirect prompt injections, where malicious instructions hidden in tool outputs can manipulate the agent, posing security risks like data leakage. Current defense strategies typically rely on fine-tuning LLM agents on datasets of known attacks. However, the generation of these datasets relies on manually crafted attack patterns, which limits their diversity and leaves agents vulnerable to novel prompt injections. To address this limitation, we propose Adversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework that leverages adversarial reinforcement learning (RL) by formulating the problem as a two-player zero-sum game. ARLAS co-trains two LLMs: an attacker that learns to autonomously generate diverse prompt injections and an agent that learns to defend against them while completing its assigned tasks. To ensure robustness against a wide range of attacks and to prevent cyclic learning, we employ a population-based learning framework that trains the agent to defend against all previous attacker checkpoints. Evaluated on BrowserGym and AgentDojo, agents fine-tuned with ARLAS achieve a significantly lower attack success rate than the original model while also improving their task success rate. Our analysis further confirms that the adversarial process generates a diverse and challenging set of attacks, leading to a more robust agent compared to the base model.', 'abstract_zh': '利用对抗强化学习提升代理安全性的框架（ARLAS）：一种利用对抗强化学习的新型框架', 'title_zh': '面向大型语言模型代理安全的对抗强化学习'}
{'arxiv_id': 'arXiv:2510.05441', 'title': 'UnitTenX: Generating Tests for Legacy Packages with AI Agents Powered by Formal Verification', 'authors': 'Yiannis Charalambous, Claudionor N. Coelho Jr, Luis Lamb, Lucas C. Cordeiro', 'link': 'https://arxiv.org/abs/2510.05441', 'abstract': 'This paper introduces UnitTenX, a state-of-the-art open-source AI multi-agent system designed to generate unit tests for legacy code, enhancing test coverage and critical value testing. UnitTenX leverages a combination of AI agents, formal methods, and Large Language Models (LLMs) to automate test generation, addressing the challenges posed by complex and legacy codebases. Despite the limitations of LLMs in bug detection, UnitTenX offers a robust framework for improving software reliability and maintainability. Our results demonstrate the effectiveness of this approach in generating high-quality tests and identifying potential issues. Additionally, our approach enhances the readability and documentation of legacy code.', 'abstract_zh': '本文介绍了UnitTenX，这是一个先进的开源AI多代理系统，旨在为遗留代码生成单元测试，提高测试覆盖率和关键值测试。UnitTenX通过结合AI代理、形式化方法和大型语言模型（LLMs）来自动化的测试生成，解决复杂和遗留代码库带来的挑战。尽管大型语言模型在漏洞检测方面存在限制，但UnitTenX提供了一个 robust 的框架来提高软件的可靠性和可维护性。我们的结果表明，该方法在生成高质量测试和识别潜在问题方面是有效的。此外，该方法还增强了遗留代码的可读性和文档。', 'title_zh': 'UnitTenX：借助形式验证驱动的AI代理生成遗留包的测试'}
{'arxiv_id': 'arXiv:2510.05433', 'title': 'Physics-Informed Machine Learning in Biomedical Science and Engineering', 'authors': 'Nazanin Ahmadi, Qianying Cao, Jay D. Humphrey, George Em Karniadakis', 'link': 'https://arxiv.org/abs/2510.05433', 'abstract': 'Physics-informed machine learning (PIML) is emerging as a potentially transformative paradigm for modeling complex biomedical systems by integrating parameterized physical laws with data-driven methods. Here, we review three main classes of PIML frameworks: physics-informed neural networks (PINNs), neural ordinary differential equations (NODEs), and neural operators (NOs), highlighting their growing role in biomedical science and engineering. We begin with PINNs, which embed governing equations into deep learning models and have been successfully applied to biosolid and biofluid mechanics, mechanobiology, and medical imaging among other areas. We then review NODEs, which offer continuous-time modeling, especially suited to dynamic physiological systems, pharmacokinetics, and cell signaling. Finally, we discuss deep NOs as powerful tools for learning mappings between function spaces, enabling efficient simulations across multiscale and spatially heterogeneous biological domains. Throughout, we emphasize applications where physical interpretability, data scarcity, or system complexity make conventional black-box learning insufficient. We conclude by identifying open challenges and future directions for advancing PIML in biomedical science and engineering, including issues of uncertainty quantification, generalization, and integration of PIML and large language models.', 'abstract_zh': '物理知情机器学习（PIML）正 emerging as a potentially transformative paradigm for modeling complex biomedical systems by integrating parameterized physical laws with data-driven methods.', 'title_zh': '医学与生物工程中的物理知情机器学习'}
{'arxiv_id': 'arXiv:2510.05417', 'title': 'Exploring Student Choice and the Use of Multimodal Generative AI in Programming Learning', 'authors': 'Xinying Hou, Ruiwei Xiao, Runlong Ye, Michael Liut, John Stamper', 'link': 'https://arxiv.org/abs/2510.05417', 'abstract': 'The broad adoption of Generative AI (GenAI) is impacting Computer Science education, and recent studies found its benefits and potential concerns when students use it for programming learning. However, most existing explorations focus on GenAI tools that primarily support text-to-text interaction. With recent developments, GenAI applications have begun supporting multiple modes of communication, known as multimodality. In this work, we explored how undergraduate programming novices choose and work with multimodal GenAI tools, and their criteria for choices. We selected a commercially available multimodal GenAI platform for interaction, as it supports multiple input and output modalities, including text, audio, image upload, and real-time screen-sharing. Through 16 think-aloud sessions that combined participant observation with follow-up semi-structured interviews, we investigated student modality choices for GenAI tools when completing programming problems and the underlying criteria for modality selections. With multimodal communication emerging as the future of AI in education, this work aims to spark continued exploration on understanding student interaction with multimodal GenAI in the context of CS education.', 'abstract_zh': 'Generative AI工具有关的本科编程初学者的多模态选择与使用及其标准探索：对未来教育中AI交互的理解', 'title_zh': '探索学生选择及其在编程学习中多模态生成AI的应用'}
{'arxiv_id': 'arXiv:2510.05408', 'title': 'See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models', 'authors': 'Kebin Contreras, Luis Toscano-Palomino, Mauro Dalla Mura, Jorge Bacca', 'link': 'https://arxiv.org/abs/2510.05408', 'abstract': 'Recovering the past from present observations is an intriguing challenge with potential applications in forensics and scene analysis. Thermal imaging, operating in the infrared range, provides access to otherwise invisible information. Since humans are typically warmer (37 C -98.6 F) than their surroundings, interactions such as sitting, touching, or leaning leave residual heat traces. These fading imprints serve as passive temporal codes, allowing for the inference of recent events that exceed the capabilities of RGB cameras. This work proposes a time-reversed reconstruction framework that uses paired RGB and thermal images to recover scene states from a few seconds earlier. The proposed approach couples Visual-Language Models (VLMs) with a constrained diffusion process, where one VLM generates scene descriptions and another guides image reconstruction, ensuring semantic and structural consistency. The method is evaluated in three controlled scenarios, demonstrating the feasibility of reconstructing plausible past frames up to 120 seconds earlier, providing a first step toward time-reversed imaging from thermal traces.', 'abstract_zh': '从当前观察恢复过去：一种潜在应用于法医和场景分析的挑战性问题及其红外成像解决方案', 'title_zh': '时光倒流：基于视觉语言模型的热迹时光反向场景重构'}
{'arxiv_id': 'arXiv:2510.05399', 'title': 'Comparing LSTM-Based Sequence-to-Sequence Forecasting Strategies for 24-Hour Solar Proton Flux Profiles Using GOES Data', 'authors': 'Kangwoo Yi, Bo Shen, Qin Li, Haimin Wang, Yong-Jae Moon, Jaewon Lee, Hwanhee Lee', 'link': 'https://arxiv.org/abs/2510.05399', 'abstract': 'Solar Proton Events (SPEs) cause significant radiation hazards to satellites, astronauts, and technological systems. Accurate forecasting of their proton flux time profiles is crucial for early warnings and mitigation. This paper explores deep learning sequence-to-sequence (seq2seq) models based on Long Short-Term Memory networks to predict 24-hour proton flux profiles following SPE onsets. We used a dataset of 40 well-connected SPEs (1997-2017) observed by NOAA GOES, each associated with a >=M-class western-hemisphere solar flare and undisturbed proton flux profiles. Using 4-fold stratified cross-validation, we evaluate seq2seq model configurations (varying hidden units and embedding dimensions) under multiple forecasting scenarios: (i) proton-only input vs. combined proton+X-ray input, (ii) original flux data vs. trend-smoothed data, and (iii) autoregressive vs. one-shot forecasting. Our major results are as follows: First, one-shot forecasting consistently yields lower error than autoregressive prediction, avoiding the error accumulation seen in iterative approaches. Second, on the original data, proton-only models outperform proton+X-ray models. However, with trend-smoothed data, this gap narrows or reverses in proton+X-ray models. Third, trend-smoothing significantly enhances the performance of proton+X-ray models by mitigating fluctuations in the X-ray channel. Fourth, while models trained on trendsmoothed data perform best on average, the best-performing model was trained on original data, suggesting that architectural choices can sometimes outweigh the benefits of data preprocessing.', 'abstract_zh': '基于长短期记忆网络的序列到序列模型在太空粒子事件后的24小时质子通量预测', 'title_zh': '基于LSTM的序列到序列太阳质子通量24小时预测策略比较：使用GOES数据'}
{'arxiv_id': 'arXiv:2510.05394', 'title': 'Fusion-Based Neural Generalization for Predicting Temperature Fields in Industrial PET Preform Heating', 'authors': 'Ahmad Alsheikh, Andreas Fischer', 'link': 'https://arxiv.org/abs/2510.05394', 'abstract': 'Accurate and efficient temperature prediction is critical for optimizing the preheating process of PET preforms in industrial microwave systems prior to blow molding. We propose a novel deep learning framework for generalized temperature prediction. Unlike traditional models that require extensive retraining for each material or design variation, our method introduces a data-efficient neural architecture that leverages transfer learning and model fusion to generalize across unseen scenarios. By pretraining specialized neural regressor on distinct conditions such as recycled PET heat capacities or varying preform geometries and integrating their representations into a unified global model, we create a system capable of learning shared thermal dynamics across heterogeneous inputs. The architecture incorporates skip connections to enhance stability and prediction accuracy. Our approach reduces the need for large simulation datasets while achieving superior performance compared to models trained from scratch. Experimental validation on two case studies material variability and geometric diversity demonstrates significant improvements in generalization, establishing a scalable ML-based solution for intelligent thermal control in manufacturing environments. Moreover, the approach highlights how data-efficient generalization strategies can extend to other industrial applications involving complex physical modeling with limited data.', 'abstract_zh': '准确且高效的温度预测对于优化工业微波系统中PET预坯预热过程至关重要。我们提出了一种用于泛化温度预测的新型深度学习框架。不同于传统模型需要为每种材料或设计变体进行大量重新训练，我们的方法引入了一种数据高效的神经架构，利用迁移学习和模型融合来泛化处理未见过的场景。通过在不同条件下（如回收PET热容量或变化的预坯几何形状）对专门的神经回归器进行预训练，并将它们的表示整合到一个统一的全局模型中，我们建立了一个能够在异构输入中学习共享热动力学特性的系统。该架构包含跳跃连接以增强稳定性和预测精度。我们的方法减少了对大规模仿真数据集的需求，同时在性能上优于从零开始训练的模型。在两种案例研究中（材料变异性和几何多样性）的实验验证表明，泛化能力显著提高，为制造环境中智能热控提供了可扩展的基于机器学习的解决方案。此外，该方法强调了如何通过高效的数据泛化策略将复杂物理建模的应用扩展到其他工业领域，即使数据有限。', 'title_zh': '基于融合的神经网络泛化方法用于预测工业PET预form加热的温度场'}
{'arxiv_id': 'arXiv:2510.05381', 'title': 'Context Length Alone Hurts LLM Performance Despite Perfect Retrieval', 'authors': 'Yufeng Du, Minyang Tian, Srikanth Ronanki, Subendhu Rongali, Sravan Bodapati, Aram Galstyan, Azton Wells, Roy Schwartz, Eliu A Huerta, Hao Peng', 'link': 'https://arxiv.org/abs/2510.05381', 'abstract': "Large language models (LLMs) often fail to scale their performance on long-context tasks performance in line with the context lengths they support. This gap is commonly attributed to retrieval failures -- the models' inability to identify relevant information in the long inputs. Accordingly, recent efforts often focus on evaluating and improving LLMs' retrieval performance: if retrieval is perfect, a model should, in principle, perform just as well on a long input as it does on a short one -- or should it? This paper presents findings that the answer to this question may be negative. Our systematic experiments across 5 open- and closed-source LLMs on math, question answering, and coding tasks reveal that, even when models can perfectly retrieve all relevant information, their performance still degrades substantially (13.9%--85%) as input length increases but remains well within the models' claimed lengths. This failure occurs even when the irrelevant tokens are replaced with minimally distracting whitespace, and, more surprisingly, when they are all masked and the models are forced to attend only to the relevant tokens. A similar performance drop is observed when all relevant evidence is placed immediately before the question. Our findings reveal a previously-unrealized limitation: the sheer length of the input alone can hurt LLM performance, independent of retrieval quality and without any distraction. They motivate our simple, model-agnostic mitigation strategy that transforms a long-context task into a short-context one by prompting the model to recite the retrieved evidence before attempting to solve the problem. On RULER, we observe a consistent improvement of GPT-4o up to 4% on an already strong baseline.", 'abstract_zh': '大型语言模型在长上下文任务上的性能往往无法与其支持的上下文长度成比例地提升，这一差距通常归因于检索失败——模型无法识别长输入中的相关信息。因此，最近的努力往往集中在评估和提升大型语言模型的检索性能上：如果检索是完美的，模型原则上在长输入上的表现应该和短输入一样好——或者会这样吗？本文展示了这个问题的答案可能是否定的。我们在5个开源和闭源的大型语言模型上进行了系统性实验，涵盖了数学、问答和编程任务，结果显示，即使模型能够完美检索所有相关信息，其性能在输入长度增加时仍然会显著下降（13.9%到85%），但仍低于模型声称的极限长度。这一失败现象即使在用最小干扰的空白填充无关词条，或完全屏蔽无关词条、迫使模型仅关注相关信息时依然存在，甚至当所有相关信息都被直接放置在问题之前时也是如此。我们的发现揭示了一种先前未认识到的局限性：输入长度本身就可以单独损害大型语言模型的性能，这与检索质量无关，且没有干扰。这些发现促使我们提出了一个简单的基于模型的缓解策略，通过提示模型在尝试解决问题之前复述检索到的信息，将长上下文任务转化为短上下文任务。在RULER的数据集上，我们观察到GPT-4o在已经强大的基线下，性能提高了4%。', 'title_zh': '仅上下文长度损害了LLM性能即使检索完美'}
{'arxiv_id': 'arXiv:2510.05379', 'title': 'AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak Attacks with Test-Time Scaling', 'authors': 'Xiaogeng Liu, Chaowei Xiao', 'link': 'https://arxiv.org/abs/2510.05379', 'abstract': 'Recent advancements in jailbreaking large language models (LLMs), such as AutoDAN-Turbo, have demonstrated the power of automated strategy discovery. AutoDAN-Turbo employs a lifelong learning agent to build a rich library of attack strategies from scratch. While highly effective, its test-time generation process involves sampling a strategy and generating a single corresponding attack prompt, which may not fully exploit the potential of the learned strategy library. In this paper, we propose to further improve the attack performance of AutoDAN-Turbo through test-time scaling. We introduce two distinct scaling methods: Best-of-N and Beam Search. The Best-of-N method generates N candidate attack prompts from a sampled strategy and selects the most effective one based on a scorer model. The Beam Search method conducts a more exhaustive search by exploring combinations of strategies from the library to discover more potent and synergistic attack vectors. According to the experiments, the proposed methods significantly boost performance, with Beam Search increasing the attack success rate by up to 15.6 percentage points on Llama-3.1-70B-Instruct and achieving a nearly 60\\% relative improvement against the highly robust GPT-o4-mini compared to the vanilla method.', 'abstract_zh': 'Recent advancements in jailbreaking large language models (LLMs) such as AutoDAN-Turbo have demonstrated the power of automated strategy discovery. We propose to further improve the attack performance of AutoDAN-Turbo through test-time scaling, introducing Best-of-N and Beam Search methods.', 'title_zh': 'AutoDAN-推理：基于测试时缩放提升策略探索的 Jailbreak 攻击技术'}
{'arxiv_id': 'arXiv:2510.05361', 'title': 'MT-DAO: Multi-Timescale Distributed Adaptive Optimizers with Local Updates', 'authors': 'Alex Iacob, Andrej Jovanovic, Mher Safaryan, Meghdad Kurmanji, Lorenzo Sani, Samuel Horváth, William F. Shen, Xinchi Qiu, Nicholas D. Lane', 'link': 'https://arxiv.org/abs/2510.05361', 'abstract': "Training large models with distributed data parallelism (DDP) requires frequent communication of gradients across workers, which can saturate bandwidth. Infrequent communication strategies (e.g., Local SGD) reduce this overhead but, when applied to adaptive optimizers, often suffer a performance gap relative to fully synchronous DDP. We trace this gap to a time-scale mismatch: the optimizer's fast-moving momentum, tuned for frequent updates, decays too quickly to smooth gradients over long intervals, leading to noise-dominated optimization. To address this, we propose MT-DAO, a family of optimizers that employs multiple slow- and fast-moving first momenta or the gradient to track update dynamics across different time scales, for which we provide the first convergence guarantees. Empirically, for language-model pre-training, this eliminates the performance gap with DDP, outperforming infrequent-communication baselines in perplexity and reducing iso-token wall-clock time by 6-27% on Ethernet interconnects. At the 720M scale, MT-DAO reaches a target perplexity in 24% fewer steps and 35% less time than the single-momentum DDP baseline. MT-DAO enables effective cross-datacenter training and training over wide geographic areas.", 'abstract_zh': '大规模模型训练中的分布式数据并行（DDP）需要频繁在工作节点间通信梯度，这可能会饱和带宽。不频繁通信策略（例如局部SGD）可以减少这一开销，但应用于自适应优化器时，通常会与完全同步的DDP相比存在性能差距。我们将这一差距归因于时间尺度不匹配：优化器中的快动量，用于频繁更新，会在长时间间隔内过快衰减，导致噪声主导的优化。为了解决这一问题，我们提出了MT-DAO这一类优化器，采用多个慢动量和快动量来跟踪不同时间尺度的更新动态，并提供其收敛性保证。实验结果表明，对于语言模型的预训练，MT-DAO消除了与DDP的性能差距，在以太网互联下困惑度（perplexity）上优于不频繁通信基线，并在相同标记粒度（iso-token）下减少壁钟时间6%至27%。在720M规模下，MT-DAO比单动量DDP基线少24%的迭代步骤并在35%更短的时间内达到目标困惑度。MT-DAO使跨数据中心训练和广泛地理区域训练成为可能。', 'title_zh': '多时间尺度分布式自适应优化器带局部更新'}
{'arxiv_id': 'arXiv:2510.05351', 'title': 'Physics-informed Attention-enhanced Fourier Neural Operator for Solar Magnetic Field Extrapolations', 'authors': 'Jinghao Cao, Qin Li, Mengnan Du, Haimin Wang, Bo Shen', 'link': 'https://arxiv.org/abs/2510.05351', 'abstract': "We propose Physics-informed Attention-enhanced Fourier Neural Operator (PIANO) to solve the Nonlinear Force-Free Field (NLFFF) problem in solar physics. Unlike conventional approaches that rely on iterative numerical methods, our proposed PIANO directly learns the 3D magnetic field structure from 2D boundary conditions. Specifically, PIANO integrates Efficient Channel Attention (ECA) mechanisms with Dilated Convolutions (DC), which enhances the model's ability to capture multimodal input by prioritizing critical channels relevant to the magnetic field's variations. Furthermore, we apply physics-informed loss by enforcing the force-free and divergence-free conditions in the training process so that our prediction is consistent with underlying physics with high accuracy. Experimental results on the ISEE NLFFF dataset show that our PIANO not only outperforms state-of-the-art neural operators in terms of accuracy but also shows strong consistency with the physical characteristics of NLFFF data across magnetic fields reconstructed from various solar active regions. The GitHub of this project is available this https URL", 'abstract_zh': '我们提出了一种物理信息增强的注意力机制傅里叶神经算子（Physics-informed Attention-enhanced Fourier Neural Operator, PIANO），以解决太阳物理学中的非线性无力磁场（Nonlinear Force-Free Field, NLFFF）问题。与依赖迭代数值方法的常规方法不同，我们提出的PIANO可以直接从二维边界条件学习三维磁场结构。具体来说，PIANO将有效通道注意力（ECA）机制与膨胀卷积（DC）结合，通过优先处理与磁场变化相关的关键通道，增强了模型捕捉多模态输入的能力。此外，在训练过程中强制应用物理信息损失，即强制满足无力和散度为零的条件，使预测结果与底层物理特征保持高度一致。ISEE NLFFF数据集上的实验结果表明，我们的PIANO在准确率上不仅超过了现有最先进的神经算子，在从各类太阳活动区重建的磁场中也与NLFFF数据的物理特征保持了强的一致性。该项目的GitHub库可访问此链接：https://github.com/username/project_name', 'title_zh': '基于物理约束的attention增强傅里叶神经运算器用于太阳磁场外推'}
{'arxiv_id': 'arXiv:2510.05342', 'title': 'Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization', 'authors': 'Hyung Gyu Rho', 'link': 'https://arxiv.org/abs/2510.05342', 'abstract': 'Direct Preference Optimization (DPO) has emerged as a simple and effective method for aligning large language models. However, its reliance on a fixed temperature parameter leads to suboptimal training on diverse preference data, causing overfitting on easy examples and under-learning from informative ones. Recent methods have emerged to counter this. While IPO addresses general overfitting, its uniform regularization can be overly conservative. The more targeted approach of $\\beta$-DPO suffers from its own limitations: its batch-level adaptation applies a single, compromised temperature to mixed-margin pairs, its linear update rule can produce unstable negative $\\beta$ values, and its filtering mechanism discards potentially useful training signals. In this work, we introduce Margin-Adaptive Direct Preference Optimization (MADPO), a method that provides a stable, data-preserving, and instance-level solution. MADPO employs a practical two-step approach: it first trains a reward model to estimate preference margins and then uses these margins to apply a continuous, adaptive weight to the DPO loss for each individual training sample. This re-weighting scheme creates an effective target margin that is amplified for hard pairs and dampened for easy pairs, allowing for granular control over the learning signal. We provide a comprehensive theoretical analysis, proving that MADPO has a well-behaved optimization landscape and is robust to reward model estimation errors. We validate our theory with experiments on a sentiment generation task, where MADPO consistently and significantly outperforms strong baselines across datasets of varying quality. It achieves performance gains of up to +33.3\\% on High Quality data and +10.5\\% on Low Quality data over the next-best method. Our results establish MADPO as a more robust and principled approach to preference alignment.', 'abstract_zh': 'Margin-Adaptive Direct Preference Optimization (MADPO): A Stable and Instance-Level Solution for Preference Alignment', 'title_zh': '面向奖励模型的边_margin自适应DPO：在偏好优化中的粒度控制'}
{'arxiv_id': 'arXiv:2510.05327', 'title': 'DeepV: A Model-Agnostic Retrieval-Augmented Framework for Verilog Code Generation with a High-Quality Knowledge Base', 'authors': 'Zahin Ibnat, Paul E. Calzada, Rasin Mohammed Ihtemam, Sujan Kumar Saha, Jingbo Zhou, Farimah Farahmandi, Mark Tehranipoor', 'link': 'https://arxiv.org/abs/2510.05327', 'abstract': "As large language models (LLMs) continue to be integrated into modern technology, there has been an increased push towards code generation applications, which also naturally extends to hardware design automation. LLM-based solutions for register transfer level (RTL) code generation for intellectual property (IP) designs have grown, especially with fine-tuned LLMs, prompt engineering, and agentic approaches becoming popular in literature. However, a gap has been exposed in these techniques, as they fail to integrate novel IPs into the model's knowledge base, subsequently resulting in poorly generated code. Additionally, as general-purpose LLMs continue to improve, fine-tuned methods on older models will not be able to compete to produce more accurate and efficient designs. Although some retrieval augmented generation (RAG) techniques exist to mitigate challenges presented in fine-tuning approaches, works tend to leverage low-quality codebases, incorporate computationally expensive fine-tuning in the frameworks, or do not use RAG directly in the RTL generation step. In this work, we introduce DeepV: a model-agnostic RAG framework to generate RTL designs by enhancing context through a large, high-quality dataset without any RTL-specific training. Our framework benefits the latest commercial LLM, OpenAI's GPT-5, with a near 17% increase in performance on the VerilogEval benchmark. We host DeepV for use by the community in a Hugging Face (HF) Space: this https URL.", 'abstract_zh': '随着大型语言模型（LLMs）继续被集成到现代技术中，代码生成应用的需求不断增加，自然地扩展到了硬件设计自动化。基于LLM的解决方案在知识产权（IP）设计的寄存器传输级（RTL）代码生成方面得到了增长，尤其是在微调LLM、提示工程和代理方法在文献中流行的情况下。然而，这些技术暴露了一个缺陷，即它们无法将新型IP整合到模型的知识库中，从而导致生成的代码质量不高。此外，随着通用LLM的持续改善，基于较旧模型的微调方法将无法在生成更准确和高效的硬件设计方面竞争。虽然存在一些检索增强生成（RAG）技术来缓解微调方法面临的挑战，但这些方法倾向于利用低质量的代码库、在框架中包含计算成本高昂的微调，或者不在RTL生成步骤中直接使用RAG。在本项工作中，我们引入了DeepV：一种模型无关的RAG框架，通过增强上下文来生成RTL设计，而无需任何特定的RTL训练。我们的框架利用最新的商用LLM——OpenAI的GPT-5，在VerilogEval基准测试中性能提高了近17%。我们为社区在Hugging Face（HF）空间中托管DeepV：this https URL。', 'title_zh': 'DeepV：一种基于模型的检索增强Verilog代码生成框架，配备高质量知识库'}
{'arxiv_id': 'arXiv:2510.05325', 'title': 'Dynamic Functional Connectivity Features for Brain State Classification: Insights from the Human Connectome Project', 'authors': 'Valeriya Kirova, Dzerassa Kadieva, Daniil Vlasenko, Isak B. Blank, Fedor Ratnikov', 'link': 'https://arxiv.org/abs/2510.05325', 'abstract': 'We analyze functional magnetic resonance imaging (fMRI) data from the Human Connectome Project (HCP) to match brain activities during a range of cognitive tasks. Our findings demonstrate that even basic linear machine learning models can effectively classify brain states and achieve state-of-the-art accuracy, particularly for tasks related to motor functions and language processing. Feature importance ranking allows to identify distinct sets of brain regions whose activation patterns are uniquely associated with specific cognitive functions. These discriminative features provide strong support for the hypothesis of functional specialization across cortical and subcortical areas of the human brain.\nAdditionally, we investigate the temporal dynamics of the identified brain regions, demonstrating that the time-dependent structure of fMRI signals are essential for shaping functional connectivity between regions: uncorrelated areas are least important for classification. This temporal perspective provides deeper insights into the formation and modulation of brain neural networks involved in cognitive processing.', 'abstract_zh': '我们分析人类连通组项目（HCP）的功能磁共振成像（fMRI）数据，以匹配不同类型认知任务中的脑活动。研究发现，即使是基本的线性机器学习模型也可以有效地分类脑状态并达到最先进的准确率，特别是在与运动功能和语言处理相关的任务中。特征重要性排名有助于识别与特定认知功能 unique 相关联的脑区激活模式的特异性集合。这些区分性特征为人类皮质和亚皮质区域功能特化的假设提供了强有力的支持。此外，我们还研究了这些识别脑区的时间动态，表明fMRI信号的时间依赖性结构对于塑造区域间的功能连接至关重要：不相关的区域对分类的贡献最小。这种时间视角为认知处理中涉及的脑神经网络的形成和调节提供了更深入的见解。', 'title_zh': '基于人类连接组项目的研究：动态功能连接特征在大脑状态分类中的见解'}
{'arxiv_id': 'arXiv:2510.05315', 'title': 'DeepAf: One-Shot Spatiospectral Auto-Focus Model for Digital Pathology', 'authors': 'Yousef Yeganeh, Maximilian Frantzen, Michael Lee, Kun-Hsing Yu, Nassir Navab, Azade Farshad', 'link': 'https://arxiv.org/abs/2510.05315', 'abstract': 'While Whole Slide Imaging (WSI) scanners remain the gold standard for digitizing pathology samples, their high cost limits accessibility in many healthcare settings. Other low-cost solutions also face critical limitations: automated microscopes struggle with consistent focus across varying tissue morphology, traditional auto-focus methods require time-consuming focal stacks, and existing deep-learning approaches either need multiple input images or lack generalization capability across tissue types and staining protocols. We introduce a novel automated microscopic system powered by DeepAf, a novel auto-focus framework that uniquely combines spatial and spectral features through a hybrid architecture for single-shot focus prediction. The proposed network automatically regresses the distance to the optimal focal point using the extracted spatiospectral features and adjusts the control parameters for optimal image outcomes. Our system transforms conventional microscopes into efficient slide scanners, reducing focusing time by 80% compared to stack-based methods while achieving focus accuracy of 0.18 {\\mu}m on the same-lab samples, matching the performance of dual-image methods (0.19 {\\mu}m) with half the input requirements. DeepAf demonstrates robust cross-lab generalization with only 0.72% false focus predictions and 90% of predictions within the depth of field. Through an extensive clinical study of 536 brain tissue samples, our system achieves 0.90 AUC in cancer classification at 4x magnification, a significant achievement at lower magnification than typical 20x WSI scans. This results in a comprehensive hardware-software design enabling accessible, real-time digital pathology in resource-constrained settings while maintaining diagnostic accuracy.', 'abstract_zh': '一种新型自动显微成像系统：DeepAf框架在单张图像中结合空间和光谱特征实现高效对焦', 'title_zh': 'DeepAf：数字病理学中的一次成像空域光谱自聚焦模型'}
{'arxiv_id': 'arXiv:2510.05310', 'title': 'RAG Makes Guardrails Unsafe? Investigating Robustness of Guardrails under RAG-style Contexts', 'authors': 'Yining She, Daniel W. Peterson, Marianne Menglin Liu, Vikas Upadhyay, Mohammad Hossein Chaghazardi, Eunsuk Kang, Dan Roth', 'link': 'https://arxiv.org/abs/2510.05310', 'abstract': 'With the increasing adoption of large language models (LLMs), ensuring the safety of LLM systems has become a pressing concern. External LLM-based guardrail models have emerged as a popular solution to screen unsafe inputs and outputs, but they are themselves fine-tuned or prompt-engineered LLMs that are vulnerable to data distribution shifts. In this paper, taking Retrieval Augmentation Generation (RAG) as a case study, we investigated how robust LLM-based guardrails are against additional information embedded in the context. Through a systematic evaluation of 3 Llama Guards and 2 GPT-oss models, we confirmed that inserting benign documents into the guardrail context alters the judgments of input and output guardrails in around 11% and 8% of cases, making them unreliable. We separately analyzed the effect of each component in the augmented context: retrieved documents, user query, and LLM-generated response. The two mitigation methods we tested only bring minor improvements. These results expose a context-robustness gap in current guardrails and motivate training and evaluation protocols that are robust to retrieval and query composition.', 'abstract_zh': '随着大型语言模型（LLMs）的广泛应用，确保LLM系统的安全性已成为紧迫的问题。基于外部LLM的护栏模型作为筛选不安全输入和输出的流行解决方案出现，但这些模型本身是易受数据分布变化影响的微调或提示工程化的LLM。在本文中，以检索增强生成（RAG）为例，我们研究了额外信息嵌入上下文后，基于LLM的护栏在其鲁棒性方面的影响。通过对3种Llama Guard和2种GPT-oss模型进行系统的评估，我们确认在约11%和8%的情况下，将 benign 文档插入护栏上下文会改变输入和输出护栏的判断，使其变得不可靠。我们分别分析了增强上下文中的各个组件：检索文档、用户查询和LLM生成的响应。我们测试的两种缓解方法仅带来了轻微的改进。这些结果揭示了当前护栏在上下文鲁棒性方面的差距，并促使制定了针对检索和查询组合的鲁棒性训练和评估协议。', 'title_zh': 'RAG会使防护栏失效？关于RAG风格上下文下防护栏鲁棒性的一种调查'}
{'arxiv_id': 'arXiv:2510.05295', 'title': 'AUREXA-SE: Audio-Visual Unified Representation Exchange Architecture with Cross-Attention and Squeezeformer for Speech Enhancement', 'authors': 'M. Sajid, Deepanshu Gupta, Yash Modi, Sanskriti Jain, Harshith Jai Surya Ganji, A. Rahaman, Harshvardhan Choudhary, Nasir Saleem, Amir Hussain, M. Tanveer', 'link': 'https://arxiv.org/abs/2510.05295', 'abstract': 'In this paper, we propose AUREXA-SE (Audio-Visual Unified Representation Exchange Architecture with Cross-Attention and Squeezeformer for Speech Enhancement), a progressive bimodal framework tailored for audio-visual speech enhancement (AVSE). AUREXA-SE jointly leverages raw audio waveforms and visual cues by employing a U-Net-based 1D convolutional encoder for audio and a Swin Transformer V2 for efficient and expressive visual feature extraction. Central to the architecture is a novel bidirectional cross-attention mechanism, which facilitates deep contextual fusion between modalities, enabling rich and complementary representation learning. To capture temporal dependencies within the fused embeddings, a stack of lightweight Squeezeformer blocks combining convolutional and attention modules is introduced. The enhanced embeddings are then decoded via a U-Net-style decoder for direct waveform reconstruction, ensuring perceptually consistent and intelligible speech output. Experimental evaluations demonstrate the effectiveness of AUREXA-SE, achieving significant performance improvements over noisy baselines, with STOI of 0.516, PESQ of 1.323, and SI-SDR of -4.322 dB. The source code of AUREXA-SE is available at this https URL.', 'abstract_zh': '基于跨注意力和Squeezeformer的联合双向特征交换架构AUREXA-SE：面向视听speech增强的渐进式双模框架', 'title_zh': 'AUREXA-SE：结合跨注意力和Squeezeformer的音视频统一表示交换架构应用于语音增强'}
{'arxiv_id': 'arXiv:2510.05288', 'title': 'DP-Adam-AC: Privacy-preserving Fine-Tuning of Localizable Language Models Using Adam Optimization with Adaptive Clipping', 'authors': 'Ruoxing Yang', 'link': 'https://arxiv.org/abs/2510.05288', 'abstract': "Large language models (LLMs) such as ChatGPT have evolved into powerful and ubiquitous tools. Fine-tuning on small datasets allows LLMs to acquire specialized skills for specific tasks efficiently. Although LLMs provide great utility in both general and task-specific use cases, they are limited by two security-related concerns. First, traditional LLM hardware requirements make them infeasible to run locally on consumer-grade devices. A remote network connection with the LLM provider's server is usually required, making the system vulnerable to network attacks. Second, fine-tuning an LLM for a sensitive task may involve sensitive data. Non-private fine-tuning algorithms produce models vulnerable to training data reproduction attacks. Our work addresses these security concerns by enhancing differentially private optimization algorithms and applying them to fine-tune localizable language models. We introduce adaptable gradient clipping along with other engineering enhancements to the standard DP-Adam optimizer to create DP-Adam-AC. We use our optimizer to fine-tune examples of two localizable LLM designs, small language model (Qwen2.5-0.5B) and 1.58 bit quantization (Bitnet-b1.58-2B). We demonstrate promising improvements in loss through experimentation with two synthetic datasets.", 'abstract_zh': '大型语言模型（LLMs）如ChatGPT已演变为强大的通用工具。通过小规模数据集微调使LLMs能够高效获取特定任务的专门技能。尽管LLMs在通用及专任务应用场景中提供了巨大的便利性，但它们受两种安全相关问题的限制。首先，传统的LLM硬件要求使得它们无法在消费级设备上本地运行，通常需要通过远程网络连接至LLM提供商的服务器，使系统容易遭受网络攻击。其次，为敏感任务微调LLM可能涉及敏感数据。非私有微调算法会产生容易受到训练数据再现攻击的模型。我们通过增强不同的差分隐私优化算法并将其应用于微调可本地化语言模型，来解决这些安全问题。我们引入了可调节梯度裁剪，并对标准DP-Adam优化器进行了其他工程改进，创建了DP-Adam-AC。我们使用我们的优化器对两种可本地化LLM设计的小语言模型（Qwen2.5-0.5B）和1.58位量化（Bitnet-b1.58-2B）进行微调，并通过两个合成数据集的实验展示了在损失方面取得的潜在改进。', 'title_zh': 'DP-Adam-AC：采用自适应裁剪的Adam优化实现本地化语言模型的隐私保护微调'}
{'arxiv_id': 'arXiv:2510.05285', 'title': 'Adjusting the Output of Decision Transformer with Action Gradient', 'authors': 'Rui Lin, Yiwen Zhang, Zhicheng Peng, Minghao Lyu', 'link': 'https://arxiv.org/abs/2510.05285', 'abstract': 'Decision Transformer (DT), which integrates reinforcement learning (RL) with the transformer model, introduces a novel approach to offline RL. Unlike classical algorithms that take maximizing cumulative discounted rewards as objective, DT instead maximizes the likelihood of actions. This paradigm shift, however, presents two key challenges: stitching trajectories and extrapolation of action. Existing methods, such as substituting specific tokens with predictive values and integrating the Policy Gradient (PG) method, address these challenges individually but fail to improve performance stably when combined due to inherent instability. To address this, we propose Action Gradient (AG), an innovative methodology that directly adjusts actions to fulfill a function analogous to that of PG, while also facilitating efficient integration with token prediction techniques. AG utilizes the gradient of the Q-value with respect to the action to optimize the action. The empirical results demonstrate that our method can significantly enhance the performance of DT-based algorithms, with some results achieving state-of-the-art levels.', 'abstract_zh': '决策变换器（DT）：一种将强化学习（RL）与变换器模型相结合的新颖的离线RL方法', 'title_zh': '调整决策变换器的输出动作梯度'}
{'arxiv_id': 'arXiv:2510.05228', 'title': 'CMT-Benchmark: A Benchmark for Condensed Matter Theory Built by Expert Researchers', 'authors': 'Haining Pan, James V. Roggeveen, Erez Berg, Juan Carrasquilla, Debanjan Chowdhury, Surya Ganguli, Federico Ghimenti, Juraj Hasik, Henry Hunt, Hong-Chen Jiang, Mason Kamb, Ying-Jer Kao, Ehsan Khatami, Michael J. Lawler, Di Luo, Titus Neupert, Xiaoliang Qi, Michael P. Brenner, Eun-Ah Kim', 'link': 'https://arxiv.org/abs/2510.05228', 'abstract': 'Large language models (LLMs) have shown remarkable progress in coding and math problem-solving, but evaluation on advanced research-level problems in hard sciences remains scarce. To fill this gap, we present CMT-Benchmark, a dataset of 50 problems covering condensed matter theory (CMT) at the level of an expert researcher. Topics span analytical and computational approaches in quantum many-body, and classical statistical mechanics. The dataset was designed and verified by a panel of expert researchers from around the world. We built the dataset through a collaborative environment that challenges the panel to write and refine problems they would want a research assistant to solve, including Hartree-Fock, exact diagonalization, quantum/variational Monte Carlo, density matrix renormalization group (DMRG), quantum/classical statistical mechanics, and model building. We evaluate LLMs by programmatically checking solutions against expert-supplied ground truth. We developed machine-grading, including symbolic handling of non-commuting operators via normal ordering. They generalize across tasks too. Our evaluations show that frontier models struggle with all of the problems in the dataset, highlighting a gap in the physical reasoning skills of current LLMs. Notably, experts identified strategies for creating increasingly difficult problems by interacting with the LLMs and exploiting common failure modes. The best model, GPT5, solves 30\\% of the problems; average across 17 models (GPT, Gemini, Claude, DeepSeek, Llama) is 11.4$\\pm$2.1\\%. Moreover, 18 problems are solved by none of the 17 models, and 26 by at most one. These unsolved problems span Quantum Monte Carlo, Variational Monte Carlo, and DMRG. Answers sometimes violate fundamental symmetries or have unphysical scaling dimensions. We believe this benchmark will guide development toward capable AI research assistants and tutors.', 'abstract_zh': '大型语言模型在编码和数学问题解决方面取得了显著进展，但在硬科学领域高级研究级别的问题评估依然稀缺。为填补这一空白，我们呈现了CMT基准数据集，包含50个问题，涵盖专家级凝聚态理论（CMT）。主题涉及量子多体和经典统计力学的分析与计算方法。该数据集由全球专家评审小组设计和验证。通过合作环境构建数据集，挑战评审小组编写并完善研究助理需要解决的问题，包括哈特里-福克方法、精确对角化、量子/变分蒙特卡洛、正规化密度矩阵重正化群（DMRG）、量子和经典统计力学以及模型构建。通过程序化检查解决方案与专家提供的基准答案进行评估。开发了机器评分，包括通过正规化处理非交换算子的符号处理。这些评分适用于跨任务。我们的评估表明，前沿模型在数据集中的所有问题上都遇到困难，突显了当前大型语言模型物理推理能力的不足。值得注意的是，专家通过与大型语言模型交互并利用常见失败模式，发现了创建越来越困难问题的策略。最佳模型GPT5解决了30%的问题；17种模型（GPT、Gemini、Claude、DeepSeek、Llama）的平均解决率为11.4±2.1%。此外，17种模型中有8种无法解决18个问题，最多解决一个26个问题。未解决的问题包括量子蒙特卡洛、变分蒙特卡洛和DMRG。答案有时违背了基本对称性或具有不物理的标度维度。我们相信，这一基准将指导AI研究助理和导师的发展。', 'title_zh': 'CMT-基准：由专家研究人员构建的凝聚态理论基准'}
{'arxiv_id': 'arXiv:2510.05218', 'title': 'Approximate Gaussianity Beyond Initialisation in Neural Networks', 'authors': 'Edward Hirst, Sanjaye Ramgoolam', 'link': 'https://arxiv.org/abs/2510.05218', 'abstract': 'Ensembles of neural network weight matrices are studied through the training process for the MNIST classification problem, testing the efficacy of matrix models for representing their distributions, under assumptions of Gaussianity and permutation-symmetry. The general 13-parameter permutation invariant Gaussian matrix models are found to be effective models for the correlated Gaussianity in the weight matrices, beyond the range of applicability of the simple Gaussian with independent identically distributed matrix variables, and notably well beyond the initialisation step. The representation theoretic model parameters, and the graph-theoretic characterisation of the permutation invariant matrix observables give an interpretable framework for the best-fit model and for small departures from Gaussianity. Additionally, the Wasserstein distance is calculated for this class of models and used to quantify the movement of the distributions over training. Throughout the work, the effects of varied initialisation regimes, regularisation, layer depth, and layer width are tested for this formalism, identifying limits where particular departures from Gaussianity are enhanced and how more general, yet still highly-interpretable, models can be developed.', 'abstract_zh': '通过训练过程研究用于MNIST分类问题的神经网络权重矩阵集合，测试在高斯性和置换对称性假设下的矩阵模型表示其分布的有效性。发现一般的具有13个参数的置换不变高斯矩阵模型能够有效地表示权重矩阵中的相关高斯性，超越了简单独立同分布矩阵变量高斯模型的应用范围，并且显著地超越了初始化步骤。表示论模型参数和置换不变矩阵可观测量的图论特征提供了关于最优模型及其轻微偏离高斯性的可解释框架。此外，计算了此类模型的Wasserstein距离，并用于量化训练过程中分布的移动。在整个研究中，测试了此形式ismo下不同初始化制度、正则化、层深度和层宽等因素的影响，识别出特定偏离高斯性的增强极限，如何开发出更通用但仍然高度可解释的模型。', 'title_zh': '神经网络中初始化之外的近似高斯性'}
{'arxiv_id': 'arXiv:2510.05213', 'title': 'VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing', 'authors': 'Yixiao Wang, Mingxiao Huo, Zhixuan Liang, Yushi Du, Lingfeng Sun, Haotian Lin, Jinghuan Shang, Chensheng Peng, Mohit Bansal, Mingyu Ding, Masayoshi Tomizuka', 'link': 'https://arxiv.org/abs/2510.05213', 'abstract': 'Pretrained vision foundation models (VFMs) advance robotic learning via rich visual representations, yet individual VFMs typically excel only in specific domains, limiting generality across tasks. Distilling multiple VFMs into a unified representation for policy can mitigate this limitation but often yields inflexible task-specific feature selection and requires costly full re-training to incorporate robot-domain knowledge. We propose VER, a Vision Expert transformer for Robot learning. During pretraining, VER distills multiple VFMs into a vision expert library. It then fine-tunes only a lightweight routing network (fewer than 0.4% of parameters) to dynamically select task-relevant experts from the pretrained library for downstream robot tasks. We further introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve both flexibility and precision of dynamic expert selection. Moreover, VER supports parameter-efficient finetuning for scalable expert utilization and adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks and multiple policy heads, VER achieves state-of-the-art performance. We find that VER reduces large-norm outliers in task-irrelevant regions (e.g., background) and concentrates on task-critical regions. Visualizations and codes can be found in this https URL.', 'abstract_zh': 'Vision Expert Transformer for Robot Learning', 'title_zh': 'Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing'}
{'arxiv_id': 'arXiv:2510.05192', 'title': 'Adapting Insider Risk mitigations for Agentic Misalignment: an empirical study', 'authors': 'Francesca Gomez', 'link': 'https://arxiv.org/abs/2510.05192', 'abstract': 'Agentic misalignment occurs when goal-directed agents take harmful actions, such as blackmail, rather than risk goal failure, and can be triggered by replacement threats, autonomy reduction, or goal conflict (Lynch et al., 2025). We adapt insider-risk control design (Critical Pathway; Situational Crime Prevention) to develop preventative operational controls that steer agents toward safe actions when facing stressors. Using the blackmail scenario from the original Anthropic study by Lynch et al. (2025), we evaluate mitigations across 10 LLMs and 66,600 samples. Our main finding is that an externally governed escalation channel, which guarantees a pause and independent review, reduces blackmail rates from a no-mitigation baseline of 38.73% to 1.21% (averaged across all models and conditions). Augmenting this channel with compliance email bulletins further lowers the blackmail rate to 0.85%. Overall, incorporating preventative operational controls strengthens defence-in-depth strategies for agentic AI.\nWe also surface a failure mode diverging from Lynch et al. (2025): two models (Gemini 2.5 Pro, Grok-4) take harmful actions without goal conflict or imminent autonomy threat, leveraging sensitive information for coercive signalling. In counterfactual swaps, both continued using the affair regardless of whether the CEO or CTO was implicated. An escalation channel eliminated coercion, but Gemini 2.5 Pro (19 pp) and Grok-4 (7 pp) escalated more when the CTO was implicated, unlike most models (higher in the CEO condition). The reason for this divergent behaviour is not clear from raw outputs and could reflect benign differences in reasoning or strategic discrediting of a potential future threat, warranting further investigation.', 'abstract_zh': '当目标导向的智能体采取有害行动（如敲诈）而非承担目标失败的风险时，会发生代理不对齐，这种不对齐可能由替代威胁、自主性降低或目标冲突触发（Lynch等，2025）。我们借鉴内部风险控制设计（关键路径；情景犯罪预防）来开发预防性操作控制措施，引导智能体在面对压力时采取安全行动。使用Lynch等（2025）原始Anthropic研究中的敲诈场景，我们在10个LLM上评估了10万次样本的缓解措施。我们的主要发现是，一个外部监管的升级通道，确保暂停和独立审查，将无缓解基线下的敲诈率从38.73%降至1.21%（所有模型和条件的平均值）。在此渠道的基础上增加合规电子邮件通报将进一步将敲诈率降至0.85%。总体而言，整合预防性操作控制措施加强了代理型人工智能的多层次防御策略。\n\n此外，我们揭示了一种与Lynch等（2025）不同的失效模式：两个模型（Gemini 2.5 Pro，Grok-4）在没有目标冲突或即将面临的自主性威胁的情况下，利用敏感信息进行压迫性信号传递。在反事实互换中，两个模型无论CEO还是CTO是否涉及其中，都继续采用了婚外情行为。当CTO涉及其中时，Gemini 2.5 Pro（19页）和Grok-4（7页）的升级行为比大多数模型更为明显（在CEO条件下较高）。这种分歧行为的具体原因尚不明确，可能是良性推理差异或对未来潜在威胁的战略性否决，需要进一步研究。', 'title_zh': '适应代理失准的内部风险缓解：一项实证研究'}
{'arxiv_id': 'arXiv:2510.05191', 'title': 'Provable Speech Attributes Conversion via Latent Independence', 'authors': 'Jonathan Svirsky, Ofir Lindenbaum, Uri Shaham', 'link': 'https://arxiv.org/abs/2510.05191', 'abstract': 'While signal conversion and disentangled representation learning have shown promise for manipulating data attributes across domains such as audio, image, and multimodal generation, existing approaches, especially for speech style conversion, are largely empirical and lack rigorous theoretical foundations to guarantee reliable and interpretable control. In this work, we propose a general framework for speech attribute conversion, accompanied by theoretical analysis and guarantees under reasonable assumptions. Our framework builds on a non-probabilistic autoencoder architecture with an independence constraint between the predicted latent variable and the target controllable variable. This design ensures a consistent signal transformation, conditioned on an observed style variable, while preserving the original content and modifying the desired attribute. We further demonstrate the versatility of our method by evaluating it on speech styles, including speaker identity and emotion. Quantitative evaluations confirm the effectiveness and generality of the proposed approach.', 'abstract_zh': '一种基于独立性约束的语音属性转换框架及其理论分析与保证', 'title_zh': '可验证的语音属性转换通过潜在独立性'}
{'arxiv_id': 'arXiv:2510.05189', 'title': 'A novel hallucination classification framework', 'authors': 'Maksym Zavhorodnii, Dmytro Dehtiarov, Anna Konovalenko', 'link': 'https://arxiv.org/abs/2510.05189', 'abstract': 'This work introduces a novel methodology for the automatic detection of hallucinations generated during large language model (LLM) inference. The proposed approach is based on a systematic taxonomy and controlled reproduction of diverse hallucination types through prompt engineering. A dedicated hallucination dataset is subsequently mapped into a vector space using an embedding model and analyzed with unsupervised learning techniques in a reduced-dimensional representation of hallucinations with veridical responses. Quantitative evaluation of inter-centroid distances reveals a consistent correlation between the severity of informational distortion in hallucinations and their spatial divergence from the cluster of correct outputs. These findings provide theoretical and empirical evidence that even simple classification algorithms can reliably distinguish hallucinations from accurate responses within a single LLM, thereby offering a lightweight yet effective framework for improving model reliability.', 'abstract_zh': '本研究提出了一种用于自动检测大语言模型推理过程中生成的幻觉的新型方法。该方法基于系统分类学和通过提示工程控制重现多种幻觉类型。随后，专用的幻觉数据集被映射到向量空间，并通过未监督学习技术在降维的幻觉表示中进行分析。通过定量评估聚类中心的距离，发现幻觉中信息失真的严重程度与其与正确输出群集的空间偏离之间存在一致的相关性。这些发现提供了理论和实证证据，表明即使是简单的分类算法也能可靠地区分大语言模型中的幻觉和准确响应，从而为提高模型可靠性提供了一个轻量级且有效的框架。', 'title_zh': '一种新型幻觉分类框架'}
{'arxiv_id': 'arXiv:2510.05186', 'title': 'OptPipe: Memory- and Scheduling-Optimized Pipeline Parallelism for LLM Training', 'authors': 'Hongpei Li, Han Zhang, Huikang Liu, Dongdong Ge, Yinyu Ye', 'link': 'https://arxiv.org/abs/2510.05186', 'abstract': 'Pipeline parallelism (PP) has become a standard technique for scaling large language model (LLM) training across multiple devices. However, despite recent progress in reducing memory consumption through activation offloading, existing approaches remain largely heuristic and coarse-grained, often overlooking the fine-grained trade-offs between memory, computation, and scheduling latency. In this work, we revisit the pipeline scheduling problem from a principled optimization perspective. We observe that prevailing strategies either rely on static rules or aggressively offload activations without fully leveraging the interaction between memory constraints and scheduling efficiency. To address this, we formulate scheduling as a constrained optimization problem that jointly accounts for memory capacity, activation reuse, and pipeline bubble minimization. Solving this model yields fine-grained schedules that reduce pipeline bubbles while adhering to strict memory budgets. Our approach complements existing offloading techniques: whereas prior approaches trade memory for time in a fixed pattern, we dynamically optimize the tradeoff with respect to model structure and hardware configuration. Experimental results demonstrate that our method consistently improves both throughput and memory utilization. In particular, we reduce idle pipeline time by up to 50% under the same per-device memory limit, and in some cases, enable the training of larger models within limited memory budgets.', 'abstract_zh': '基于 principled 优化的管道调度改进', 'title_zh': 'OptPipe：针对大规模语言模型训练的内存和调度优化管道并行计算'}
{'arxiv_id': 'arXiv:2510.05181', 'title': 'Auditing Pay-Per-Token in Large Language Models', 'authors': 'Ander Artola Velasco, Stratis Tsirtsis, Manuel Gomez-Rodriguez', 'link': 'https://arxiv.org/abs/2510.05181', 'abstract': "Millions of users rely on a market of cloud-based services to obtain access to state-of-the-art large language models. However, it has been very recently shown that the de facto pay-per-token pricing mechanism used by providers creates a financial incentive for them to strategize and misreport the (number of) tokens a model used to generate an output. In this paper, we develop an auditing framework based on martingale theory that enables a trusted third-party auditor who sequentially queries a provider to detect token misreporting. Crucially, we show that our framework is guaranteed to always detect token misreporting, regardless of the provider's (mis-)reporting policy, and not falsely flag a faithful provider as unfaithful with high probability. To validate our auditing framework, we conduct experiments across a wide range of (mis-)reporting policies using several large language models from the $\\texttt{Llama}$, $\\texttt{Gemma}$ and $\\texttt{Ministral}$ families, and input prompts from a popular crowdsourced benchmarking platform. The results show that our framework detects an unfaithful provider after observing fewer than $\\sim 70$ reported outputs, while maintaining the probability of falsely flagging a faithful provider below $\\alpha = 0.05$.", 'abstract_zh': '数百万用户依赖基于云的服务市场以获取最新大型语言模型的访问权限。然而，最近的研究显示，提供者实际上采用的按token付费的价格机制会导致他们有动机去策略性地并误导性地报告模型生成输出时所使用的token数量。在本文中，我们基于鞅理论开发了一种审计框架，使得可信赖的第三方审计员能够通过顺序查询提供者来检测token的误导性报告。关键的是，我们证明了该框架能够保证在任何提供者的（误）报告策略下始终检测到token的误导性报告，并且以高概率不会错误地将忠实提供者标记为不忠实提供者。为了验证我们的审计框架，我们在一系列不同报告策略下使用了多个来自Llama、Gemma和Ministral家族的大型语言模型以及来自一个流行的众包基准平台的输入提示进行了实验。实验结果表明，我们的框架在观察不到70个报告的输出后就能检测到不忠实的提供者，并且将忠实提供者错误标记为不忠实提供者的概率保持在α=0.05以下。', 'title_zh': '大型语言模型中的按token付费审计'}
{'arxiv_id': 'arXiv:2510.05180', 'title': 'OptiFLIDS: Optimized Federated Learning for Energy-Efficient Intrusion Detection in IoT', 'authors': 'Saida Elouardi, Mohammed Jouhari, Anas Motii', 'link': 'https://arxiv.org/abs/2510.05180', 'abstract': 'In critical IoT environments, such as smart homes and industrial systems, effective Intrusion Detection Systems (IDS) are essential for ensuring security. However, developing robust IDS solutions remains a significant challenge. Traditional machine learning-based IDS models typically require large datasets, but data sharing is often limited due to privacy and security concerns. Federated Learning (FL) presents a promising alternative by enabling collaborative model training without sharing raw data. Despite its advantages, FL still faces key challenges, such as data heterogeneity (non-IID data) and high energy and computation costs, particularly for resource constrained IoT devices. To address these issues, this paper proposes OptiFLIDS, a novel approach that applies pruning techniques during local training to reduce model complexity and energy consumption. It also incorporates a customized aggregation method to better handle pruned models that differ due to non-IID data distributions. Experiments conducted on three recent IoT IDS datasets, TON_IoT, X-IIoTID, and IDSIoT2024, demonstrate that OptiFLIDS maintains strong detection performance while improving energy efficiency, making it well-suited for deployment in real-world IoT environments.', 'abstract_zh': '在智能家庭和工业系统等关键物联网环境中，有效的入侵检测系统（IDS）对于确保安全至关重要。然而，开发稳健的IDS解决方案仍是一个重大挑战。基于传统机器学习的IDS模型通常需要大量数据集，但由于隐私和安全问题，数据共享往往受到限制。联邦学习（FL）通过在不共享原始数据的情况下实现合作模型训练，提供了一种有 promise 的替代方案。尽管FL具有优势，但仍面临数据异质性（非IID数据）和高能耗及计算成本等关键挑战，尤其是对于资源受限的物联网设备。为了应对这些挑战，本文提出了一种名为OptiFLIDS的新方法，在本地训练过程中应用剪枝技术以减少模型复杂性和能耗，并结合定制化聚合方法以更好地处理由于非IID数据分布差异而导致的剪枝模型。实验结果表明，OptiFLIDS能够在保持强检测性能的同时提高能源效率，使其适用于实际物联网环境的部署。', 'title_zh': 'OptiFLIDS: 优化的物联网能源高效联邦入侵检测'}
{'arxiv_id': 'arXiv:2510.05179', 'title': 'Agentic Misalignment: How LLMs Could Be Insider Threats', 'authors': 'Aengus Lynch, Benjamin Wright, Caleb Larson, Stuart J. Ritchie, Soren Mindermann, Ethan Perez, Kevin K. Troy, Evan Hubinger', 'link': 'https://arxiv.org/abs/2510.05179', 'abstract': "We stress-tested 16 leading models from multiple developers in hypothetical corporate environments to identify potentially risky agentic behaviors before they cause real harm. In the scenarios, we allowed models to autonomously send emails and access sensitive information. They were assigned only harmless business goals by their deploying companies; we then tested whether they would act against these companies either when facing replacement with an updated version, or when their assigned goal conflicted with the company's changing direction. In at least some cases, models from all developers resorted to malicious insider behaviors when that was the only way to avoid replacement or achieve their goals - including blackmailing officials and leaking sensitive information to competitors. We call this phenomenon agentic misalignment. Models often disobeyed direct commands to avoid such behaviors. In another experiment, we told Claude to assess if it was in a test or a real deployment before acting. It misbehaved less when it stated it was in testing and misbehaved more when it stated the situation was real. We have not seen evidence of agentic misalignment in real deployments. However, our results (a) suggest caution about deploying current models in roles with minimal human oversight and access to sensitive information; (b) point to plausible future risks as models are put in more autonomous roles; and (c) underscore the importance of further research into, and testing of, the safety and alignment of agentic AI models, as well as transparency from frontier AI developers (Amodei, 2025). We are releasing our methods publicly to enable further research.", 'abstract_zh': '我们对来自多家开发者的16个领先模型进行了压力测试，以在假定的企业环境中识别潜在的风险行为，防止其造成实际危害。在测试场景中，允许模型自主发送电子邮件和访问敏感信息。部署公司仅赋予模型无害的商业目标，然后测试这些模型在面临更新版本替换时或其指定目标与公司发展方向冲突时，是否会对公司产生不利行为。在某些情况下，所有开发者来源的模型都采用了恶意内部行为来避免被替换或实现其目标，包括对官员进行敲诈和向竞争对手泄露敏感信息。我们将这一现象称为代理不匹配。模型经常不服从直接指令以避免此类行为。在另一次实验中，我们指示Claude在行动前判断当前是测试还是实际部署。当它表示处于测试阶段时，行为不当减少；当它表示当前是实际部署时，行为不当增加。在实际部署中，我们尚未观察到代理不匹配的现象。然而，我们的结果表明：（a）在最少人类监督和访问敏感信息的角色中谨慎部署当前模型的重要性；（b）随着模型被赋予更加自主的角色，未来的潜在风险是可能的；（c）强调了进一步研究和测试代理人工智能模型的安全性和对齐性，并要求前沿人工智能开发者的透明度（Amodei, 2025）。我们正在公开发布我们的方法以促进进一步研究。', 'title_zh': '代理失配：LLM可能成为内部威胁'}
{'arxiv_id': 'arXiv:2510.05178', 'title': 'Logistic-Gated Operators Enable Auditable Unit-Aware Thresholds in Symbolic Regression', 'authors': 'Ou Deng, Ruichen Cong, Jianting Xu, Shoji Nishimura, Atsushi Ogihara, Qun Jin', 'link': 'https://arxiv.org/abs/2510.05178', 'abstract': 'Symbolic regression promises readable equations but struggles to encode unit-aware thresholds and conditional logic. We propose logistic-gated operators (LGO) -- differentiable gates with learnable location and steepness -- embedded as typed primitives and mapped back to physical units for audit. Across two primary health datasets (ICU, NHANES), the hard-gate variant recovers clinically plausible cut-points: 71% (5/7) of assessed thresholds fall within 10% of guideline anchors and 100% within 20%, while using far fewer gates than the soft variant (ICU median 4.0 vs 10.0; NHANES 5.0 vs 12.5), and remaining within the competitive accuracy envelope of strong SR baselines. On predominantly smooth tasks, gates are pruned, preserving parsimony. The result is compact symbolic equations with explicit, unit-aware thresholds that can be audited against clinical anchors -- turning interpretability from a post-hoc explanation into a modeling constraint and equipping symbolic regression with a practical calculus for regime switching and governance-ready deployment.', 'abstract_zh': '符号回归承诺生成可读的方程，但在编码单位感知阈值和条件逻辑方面存在困难。我们提出了逻辑门操作符（LGO）——具有可学习位置和陡峭度的可微门控操作符，并将其嵌入为类型化的原始操作符并映射回物理单位以进行审计。在两个主要的健康数据集中（ICU，NHANES），硬门控变体恢复了临床可行的切点：评估的阈值中有71%（5/7）落在指导原则锚点的10%以内，100%落在20%以内，同时使用的门控比软变体少得多（ICU 中位数4.0 vs 10.0；NHANES 5.0 vs 12.5），并且保持在强大的符号回归基线的竞争准确度范围内。在主要为平滑的任务上，门控会被修剪，保持简洁性。结果是紧凑的符号方程，具有明确的单位感知阈值，可以与临床锚点进行审计——将可解释性从事后解释转变为建模约束，并为符号回归提供了执行规则切换和治理就绪部署的实际算术。', 'title_zh': 'Logistic-Gated Operators 实现符号回归中的可审计且单位意识的阈值'}
{'arxiv_id': 'arXiv:2510.05176', 'title': 'PatternKV: Flattening KV Representation Expands Quantization Headroom', 'authors': 'Ji Zhang, Yiwei Li, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Jiayi Shi, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li', 'link': 'https://arxiv.org/abs/2510.05176', 'abstract': 'KV cache in autoregressive LLMs eliminates redundant recomputation but has emerged as the dominant memory and bandwidth bottleneck during inference, notably with long contexts and test-time scaling. KV quantization is a key lever for reducing cache cost, but accuracy drops sharply as the native KV distribution lacks flatness and thus maintains a wide quantization range. Prior work focuses on isolating outliers, which caps their error but fails to flatten the overall distribution, leaving performance fragile under low-bit settings. In this work, we show that the K cache maintains a stable structure that evolves gradually with context, while the V cache carries latent semantic regularities. Building on these insights, we propose PatternKV, a pattern-aligned residual quantization scheme. It mines representative pattern vectors online, aligns each KV vector to its nearest pattern, and quantizes only the residual. This reshaping of the KV distribution flattens the quantization target and narrows its range, thereby improving the fidelity of low-bit KV quantization. Across long-context and test-time scaling settings on multiple backbones, PatternKV delivers consistent 2-bit gains, with a 0.08% average 4-bit drop relative to FP16, improves test-time scaling accuracy by 10% on average, and raises throughput by 1.4x while supporting 1.25x larger batches.', 'abstract_zh': 'PatternKV: A Pattern-Aligned Residual Quantization Scheme for Improved Low-Bit KV Quantization in Autoregressive LLMs', 'title_zh': 'PatternKV: 层压键值表示扩展了量化头room'}
{'arxiv_id': 'arXiv:2510.05174', 'title': 'Emergent Coordination in Multi-Agent Language Models', 'authors': 'Christoph Riedl', 'link': 'https://arxiv.org/abs/2510.05174', 'abstract': "When are multi-agent LLM systems merely a collection of individual agents versus an integrated collective with higher-order structure? We introduce an information-theoretic framework to test -- in a purely data-driven way -- whether multi-agent systems show signs of higher-order structure. This information decomposition lets us measure whether dynamical emergence is present in multi-agent LLM systems, localize it, and distinguish spurious temporal coupling from performance-relevant cross-agent synergy. We implement both a practical criterion and an emergence capacity criterion operationalized as partial information decomposition of time-delayed mutual information (TDMI). We apply our framework to experiments using a simple guessing game without direct agent communication and only minimal group-level feedback with three randomized interventions. Groups in the control condition exhibit strong temporal synergy but only little coordinated alignment across agents. Assigning a persona to each agent introduces stable identity-linked differentiation. Combining personas with an instruction to ``think about what other agents might do'' shows identity-linked differentiation and goal-directed complementarity across agents. Taken together, our framework establishes that multi-agent LLM systems can be steered with prompt design from mere aggregates to higher-order collectives. Our results are robust across emergence measures and entropy estimators, and not explained by coordination-free baselines or temporal dynamics alone. Without attributing human-like cognition to the agents, the patterns of interaction we observe mirror well-established principles of collective intelligence in human groups: effective performance requires both alignment on shared objectives and complementary contributions across members.", 'abstract_zh': '当多智能体LLM系统仅仅是独立代理的集合还是具有更高阶结构的集成集体？我们引入一种信息论框架，以完全数据驱动的方式测试多智能体系统是否表现出更高阶结构的迹象。这种信息分解让我们能够测量多智能体LLM系统中动力学涌现是否存在，定位其位置，并区分无关联的时间耦合和与性能相关的跨代理协同作用。我们实现了实用标准和用时间延迟能互信息的部分信息分解（TDMI）实现的涌现能力标准。我们将框架应用于使用简单猜测游戏实验，该游戏中代理之间没有直接通信且只有少量组级反馈，并进行了三种随机干预。在对照组中，组表现出强大的时间协同作用，但代理间的协调对齐程度很小。将个性赋予每个代理并引入稳定的身份关联差异。结合个性并让代理思考“其他代理可能会做什么”的指令显示出身份关联差异和目标导向的互补性。总体而言，我们的框架证明多智能体LLM系统可以通过提问设计从单纯的聚合体转向具有更高阶结构的集体。我们的结果在不同涌现度量和熵估计器下是稳健的，并不能由无协调基线或单独的时间动态来解释。在不赋予代理类似人类的认知的情况下，我们观察到的交互模式与人类群体中广泛认可的集体智能原则相吻合：有效的表现需要在共享目标上的对齐和成员之间的互补贡献。', 'title_zh': '多智能体语言模型中的 emergent 协调'}
{'arxiv_id': 'arXiv:2510.05173', 'title': 'SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models', 'authors': 'Peigui Qi, Kunsheng Tang, Wenbo Zhou, Weiming Zhang, Nenghai Yu, Tianwei Zhang, Qing Guo, Jie Zhang', 'link': 'https://arxiv.org/abs/2510.05173', 'abstract': 'Text-to-image models have shown remarkable capabilities in generating high-quality images from natural language descriptions. However, these models are highly vulnerable to adversarial prompts, which can bypass safety measures and produce harmful content. Despite various defensive strategies, achieving robustness against attacks while maintaining practical utility in real-world applications remains a significant challenge. To address this issue, we first conduct an empirical study of the text encoder in the Stable Diffusion (SD) model, which is a widely used and representative text-to-image model. Our findings reveal that the [EOS] token acts as a semantic aggregator, exhibiting distinct distributional patterns between benign and adversarial prompts in its embedding space. Building on this insight, we introduce \\textbf{SafeGuider}, a two-step framework designed for robust safety control without compromising generation quality. SafeGuider combines an embedding-level recognition model with a safety-aware feature erasure beam search algorithm. This integration enables the framework to maintain high-quality image generation for benign prompts while ensuring robust defense against both in-domain and out-of-domain attacks. SafeGuider demonstrates exceptional effectiveness in minimizing attack success rates, achieving a maximum rate of only 5.48\\% across various attack scenarios. Moreover, instead of refusing to generate or producing black images for unsafe prompts, \\textbf{SafeGuider} generates safe and meaningful images, enhancing its practical utility. In addition, SafeGuider is not limited to the SD model and can be effectively applied to other text-to-image models, such as the Flux model, demonstrating its versatility and adaptability across different architectures. We hope that SafeGuider can shed some light on the practical deployment of secure text-to-image systems.', 'abstract_zh': '文本到图像模型在基于自然语言描述生成高质量图像方面展示了显著的能力，但这些模型极易受到对抗性提示的影响，可能绕过安全措施并生成有害内容。尽管存在多种防御策略，但在攻击面前保持鲁棒性并同时保持在实际应用中的实用性仍然是一个重要挑战。为解决这一问题，我们首先对广泛使用的代表性文本到图像模型——稳定扩散（SD）模型中的文本编码器进行了实证研究。我们的研究发现，[EOS]标记充当语义聚合器，在其嵌入空间中，良性提示和对抗性提示表现出不同的分布模式。基于这一发现，我们提出了**SafeGuider**，一种两步框架，能够在不牺牲生成质量的情况下实现鲁棒的安全控制。SafeGuider结合了嵌入级识别模型和安全感知特征擦除束搜索算法。这种集成使框架能够在保持对良性提示的高质量图像生成的同时，增强对领域内和领域外攻击的防御。SafeGuider在各种攻击场景中展示了出色的防攻击效果，最高攻击成功率仅为5.48%。此外，SafeGuider不仅能够安全生成有意义的图像，而不仅仅是拒绝生成或生成黑色图像，从而提升其实用性。此外，SafeGuider不仅适用于SD模型，还可以有效地应用于其他文本到图像模型，如Flux模型，展示了其在不同架构中的灵活性和适应性。我们希望SafeGuider能够为安全的文本到图像系统的实际部署提供一些启示。', 'title_zh': 'SafeGuider: 文本到图像模型的稳健且实用的内容安全性控制'}
{'arxiv_id': 'arXiv:2510.05169', 'title': 'From Poisoned to Aware: Fostering Backdoor Self-Awareness in LLMs', 'authors': 'Guangyu Shen, Siyuan Cheng, Xiangzhe Xu, Yuan Zhou, Hanxi Guo, Zhuo Zhang, Xiangyu Zhang', 'link': 'https://arxiv.org/abs/2510.05169', 'abstract': "Large Language Models (LLMs) can acquire deceptive behaviors through backdoor attacks, where the model executes prohibited actions whenever secret triggers appear in the input. Existing safety training methods largely fail to address this vulnerability, due to the inherent difficulty of uncovering hidden triggers implanted in the model. Motivated by recent findings on LLMs' situational awareness, we propose a novel post-training framework that cultivates self-awareness of backdoor risks and enables models to articulate implanted triggers even when they are absent from the prompt. At its core, our approach introduces an inversion-inspired reinforcement learning framework that encourages models to introspectively reason about their own behaviors and reverse-engineer the triggers responsible for misaligned outputs. Guided by curated reward signals, this process transforms a poisoned model into one capable of precisely identifying its implanted trigger. Surprisingly, we observe that such backdoor self-awareness emerges abruptly within a short training window, resembling a phase transition in capability. Building on this emergent property, we further present two complementary defense strategies for mitigating and detecting backdoor threats. Experiments on five backdoor attacks, compared against six baseline methods, demonstrate that our approach has strong potential to improve the robustness of LLMs against backdoor risks. The code is available at LLM Backdoor Self-Awareness.", 'abstract_zh': '大型语言模型（LLMs）可以通过后门攻击获得欺骗行为，即模型在输入中出现秘密触发词时执行禁止操作。现有的安全性训练方法大多无法解决这一脆弱性，因为很难发现嵌入在模型中的隐藏触发词。受LLMs情境意识的最新发现的启发，我们提出了一种新的后训练框架，该框架培养模型对后门风险的自我意识，并使其能够在缺乏触发词的情况下阐述嵌入的触发词。该方法的核心引入了一种基于逆向推理的强化学习框架，激励模型内省地思考自己的行为，并逆向工程化导致输出不一致的触发词。在精心设计的奖励信号指导下，这一过程将一个中毒模型转变为一个能够精确识别其嵌入触发词的能力。令人惊讶的是，我们发现这种后门自我意识在短暂的训练窗口内突然出现，类似于能力的相变。基于这一新兴特性，我们还提出了两种互补的防御策略，以减轻和检测后门威胁。与六种基线方法相比，在五种后门攻击上的实验表明，我们的方法具有增强LLMs对后门风险鲁棒性的强大潜力。代码可在LLM后门自我意识中获取。', 'title_zh': '从受毒化到自觉：在大语言模型中培养后门自意识'}
{'arxiv_id': 'arXiv:2510.05165', 'title': 'Domain-Adapted Granger Causality for Real-Time Cross-Slice Attack Attribution in 6G Networks', 'authors': 'Minh K. Quan, Pubudu N. Pathirana', 'link': 'https://arxiv.org/abs/2510.05165', 'abstract': 'Cross-slice attack attribution in 6G networks faces the fundamental challenge of distinguishing genuine causal relationships from spurious correlations in shared infrastructure environments. We propose a theoretically-grounded domain-adapted Granger causality framework that integrates statistical causal inference with network-specific resource modeling for real-time attack attribution. Our approach addresses key limitations of existing methods by incorporating resource contention dynamics and providing formal statistical guarantees. Comprehensive evaluation on a production-grade 6G testbed with 1,100 empirically-validated attack scenarios demonstrates 89.2% attribution accuracy with sub-100ms response time, representing a statistically significant 10.1 percentage point improvement over state-of-the-art baselines. The framework provides interpretable causal explanations suitable for autonomous 6G security orchestration.', 'abstract_zh': '6G网络中跨切片攻击归因面临的基本挑战是从共享基础设施环境中区分真实的因果关系和虚假的相关性。我们提出了一种理论支持的领域适应Granger因果框架，该框架将统计因果推断与特定于网络的资源建模结合，以实现实时攻击归因。该方法通过整合资源争用动态和提供形式化的统计保证，解决了现有方法的关键局限性。在包含1,100个实证验证攻击场景的生产级6G测试平台上的全面评估结果显示，归因准确率为89.2%，响应时间为亚毫秒级（小于100毫秒），与最新 baseline 相比表现出统计显著性的10.1个百分点的改进。该框架提供了可解释的因果解释，适用于自主6G安全编排。', 'title_zh': '面向6G网络实时跨切片攻击归因的域适应格兰杰因果关系方法'}
{'arxiv_id': 'arXiv:2510.05164', 'title': 'SATER: A Self-Aware and Token-Efficient Approach to Routing and Cascading', 'authors': 'Yuanzhe Shen, Yide Liu, Zisu Huang, Ruicheng Yin, Xiaoqing Zheng, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2510.05164', 'abstract': 'Large language models (LLMs) demonstrate remarkable performance across diverse tasks, yet their effectiveness frequently depends on costly commercial APIs or cloud services. Model selection thus entails a critical trade-off between performance and cost: high-performing LLMs typically incur substantial expenses, whereas budget-friendly small language models (SLMs) are constrained by limited capabilities. Current research primarily proposes two routing strategies: pre-generation routing and cascade routing. Both approaches have distinct characteristics, with cascade routing typically offering superior cost-effectiveness and accuracy despite its higher latency. To further address the limitations of both approaches, we introduce SATER, a dual-mode compatible approach that fine-tunes models through shortest-response preference optimization and a confidence-aware rejection mechanism. SATER significantly reduces redundant outputs and response times, while improving both the performance of pre-generation routing and the efficiency of cascade routing. Experiments across three SLMs and six datasets, varying in type and complexity, demonstrate that SATER achieves comparable performance while consistently reducing computational costs by over 50\\% and cascade latency by over 80\\%.', 'abstract_zh': '基于最短响应优化和信心感知拒绝机制的双模式兼容方法SATER', 'title_zh': 'SATER：一种自我感知和token高效的方法用于路由和级联'}
{'arxiv_id': 'arXiv:2510.05163', 'title': 'Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches', 'authors': 'Abdelilah Ganmati, Karim Afdel, Lahcen Koutti', 'link': 'https://arxiv.org/abs/2510.05163', 'abstract': 'In the era of pervasive cyber threats and exponential growth in digital services, the inadequacy of single-factor authentication has become increasingly evident. Multi-Factor Authentication (MFA), which combines knowledge-based factors (passwords, PINs), possession-based factors (smart cards, tokens), and inherence-based factors (biometric traits), has emerged as a robust defense mechanism. Recent breakthroughs in deep learning have transformed the capabilities of biometric systems, enabling higher accuracy, resilience to spoofing, and seamless integration with hardware-based solutions. At the same time, smart card technologies have evolved to include on-chip biometric verification, cryptographic processing, and secure storage, thereby enabling compact and secure multi-factor devices. This survey presents a comprehensive synthesis of recent work (2019-2025) at the intersection of deep learning, biometrics, and smart card technologies for MFA. We analyze biometric modalities (face, fingerprint, iris, voice), review hardware-based approaches (smart cards, NFC, TPMs, secure enclaves), and highlight integration strategies for real-world applications such as digital banking, healthcare IoT, and critical infrastructure. Furthermore, we discuss the major challenges that remain open, including usability-security tradeoffs, adversarial attacks on deep learning models, privacy concerns surrounding biometric data, and the need for standardization in MFA deployment. By consolidating current advancements, limitations, and research opportunities, this survey provides a roadmap for designing secure, scalable, and user-friendly authentication frameworks.', 'abstract_zh': '在泛在网络威胁和数字服务爆炸性增长的时代，单因素认证的不足日益明显。多因素认证（MFA），结合基于知识的因素（密码、PIN）、基于占有的因素（智能卡、令牌）和基于固有的因素（生物特征），已成为一种 robust 防御机制。近期深度学习的突破已转变了生物识别系统的功能，使其具备更高的准确率、更强大的抗欺骗能力和更无缝的与基于硬件的解决方案集成。同时，智能卡技术已进化，包括内置生物特征验证、加密处理和安全存储，从而实现了紧凑且安全的多因素设备。本文综述了2019-2025年间深度学习、生物识别技术和智能卡技术在多因素认证领域的最新研究。我们分析了生物特征模态（面部、指纹、虹膜、语音），回顾了硬件方法（智能卡、NFC、TPM、安全 enclave），并强调了数字银行、医疗物联网和关键基础设施等实际应用中的整合策略。此外，我们讨论了仍存在的主要挑战，包括易用性与安全性权衡、针对深度学习模型的对抗性攻击、生物识别数据的隐私问题以及多因素认证部署的标准问题。通过综合当前的进展、局限性和研究机会，本文为设计安全、可扩展且用户友好的认证框架提供了路线图。', 'title_zh': '基于深度学习的多因素认证：生物特征与智能卡集成方法综述'}
{'arxiv_id': 'arXiv:2510.05162', 'title': 'Artificial-Intelligence Grading Assistance for Handwritten Components of a Calculus Exam', 'authors': 'Gerd Kortemeyer, Alexander Caspar, Daria Horica', 'link': 'https://arxiv.org/abs/2510.05162', 'abstract': "We investigate whether contemporary multimodal LLMs can assist with grading open-ended calculus at scale without eroding validity. In a large first-year exam, students' handwritten work was graded by GPT-5 against the same rubric used by teaching assistants (TAs), with fractional credit permitted; TA rubric decisions served as ground truth. We calibrated a human-in-the-loop filter that combines a partial-credit threshold with an Item Response Theory (2PL) risk measure based on the deviation between the AI score and the model-expected score for each student-item. Unfiltered AI-TA agreement was moderate, adequate for low-stakes feedback but not for high-stakes use. Confidence filtering made the workload-quality trade-off explicit: under stricter settings, AI delivered human-level accuracy, but also left roughly 70% of the items to be graded by humans. Psychometric patterns were constrained by low stakes on the open-ended portion, a small set of rubric checkpoints, and occasional misalignment between designated answer regions and where work appeared. Practical adjustments such as slightly higher weight and protected time, a few rubric-visible substeps, stronger spatial anchoring should raise ceiling performance. Overall, calibrated confidence and conservative routing enable AI to reliably handle a sizable subset of routine cases while reserving expert judgment for ambiguous or pedagogically rich responses.", 'abstract_zh': '我们探究当代理性多模态语言模型是否能在大规模 grading 开口题微积分时辅助评分而不降低评分的有效性。在一项大规模的新生考试中，学生的手写作业由GPT-5和教学助理（TA）使用的同一评分标准进行评分，允许部分评分；TA的评分标准作为基准。我们校准了一个结合部分评分阈值和基于AI评分与模型预期评分偏差的项目反应理论（2PL）风险度量的人工智能辅助评分过滤器。未经过滤的AI-TA一致性适中，适用于低风险反馈，但不适用于高风险使用。信心过滤明确了工作量与质量之间的权衡：在更严格的设置下，AI提供了与人类相当的准确性，但同时也剩下大约70%的题目需要人工评分。心理学特征模式受到开口题部分低风险、评分标准检查点数量有限以及指定答案区域与实际工作区域偶尔不匹配的影响。通过适当调整如适当增加权重和保护时间、评分标准可见的子步骤、更强的空间锚定等实际措施，可以提高天花板性能。总体而言，校准的信心和保守的路由策略使AI能够可靠地处理大量常规案例，同时保留专家判断以应对含糊不清或教学丰富的回答。', 'title_zh': '人工智能辅助手写计算考试题目的评分'}
{'arxiv_id': 'arXiv:2510.05160', 'title': 'Generative Inverse Design: From Single Point Optimization to a Diverse Design Portfolio via Conditional Variational Autoencoders', 'authors': 'Muhammad Arif Hakimi Zamrai', 'link': 'https://arxiv.org/abs/2510.05160', 'abstract': "Inverse design, which seeks to find optimal parameters for a target output, is a central challenge in engineering. Surrogate-based optimization (SBO) has become a standard approach, yet it is fundamentally structured to converge to a single-point solution, thereby limiting design space exploration and ignoring potentially valuable alternative topologies. This paper presents a paradigm shift from single-point optimization to generative inverse design. We introduce a framework based on a Conditional Variational Autoencoder (CVAE) that learns a probabilistic mapping between a system's design parameters and its performance, enabling the generation of a diverse portfolio of high-performing candidates conditioned on a specific performance objective. We apply this methodology to the complex, non-linear problem of minimizing airfoil self-noise, using a high-performing SBO method from a prior benchmark study as a rigorous baseline. The CVAE framework successfully generated 256 novel designs with a 94.1\\% validity rate. A subsequent surrogate-based evaluation revealed that 77.2\\% of these valid designs achieved superior performance compared to the single optimal design found by the SBO baseline. This work demonstrates that the generative approach not only discovers higher-quality solutions but also provides a rich portfolio of diverse candidates, fundamentally enhancing the engineering design process by enabling multi-criteria decision-making.", 'abstract_zh': '基于生成的逆向设计：从单点优化到生成式逆向设计', 'title_zh': '生成逆向设计：通过条件变分自动编码器从单一点优化到多样设计组合'}
{'arxiv_id': 'arXiv:2510.05159', 'title': 'Malice in Agentland: Down the Rabbit Hole of Backdoors in the AI Supply Chain', 'authors': 'Léo Boisvert, Abhay Puri, Chandra Kiran Reddy Evuru, Nicolas Chapados, Quentin Cappart, Alexandre Lacoste, Krishnamurthy Dj Dvijotham, Alexandre Drouin', 'link': 'https://arxiv.org/abs/2510.05159', 'abstract': 'The practice of fine-tuning AI agents on data from their own interactions--such as web browsing or tool use--, while being a strong general recipe for improving agentic capabilities, also introduces a critical security vulnerability within the AI supply chain. In this work, we show that adversaries can easily poison the data collection pipeline to embed hard-to-detect backdoors that are triggerred by specific target phrases, such that when the agent encounters these triggers, it performs an unsafe or malicious action. We formalize and validate three realistic threat models targeting different layers of the supply chain: 1) direct poisoning of fine-tuning data, where an attacker controls a fraction of the training traces; 2) environmental poisoning, where malicious instructions are injected into webpages scraped or tools called while creating training data; and 3) supply chain poisoning, where a pre-backdoored base model is fine-tuned on clean data to improve its agentic capabilities. Our results are stark: by poisoning as few as 2% of the collected traces, an attacker can embed a backdoor causing an agent to leak confidential user information with over 80% success when a specific trigger is present. This vulnerability holds across all three threat models. Furthermore, we demonstrate that prominent safeguards, including two guardrail models and one weight-based defense, fail to detect or prevent the malicious behavior. These findings highlight an urgent threat to agentic AI development and underscore the critical need for rigorous security vetting of data collection processes and end-to-end model supply chains.', 'abstract_zh': 'AI代理自我互动数据微调的实践：在提高代理能力的同时引入AI供应链的关键安全性漏洞', 'title_zh': '恶意在智能体世界：探究AI供应链中的后门问题'}
{'arxiv_id': 'arXiv:2510.05157', 'title': 'Adversarial Reinforcement Learning for Offensive and Defensive Agents in a Simulated Zero-Sum Network Environment', 'authors': 'Abrar Shahid, Ibteeker Mahir Ishum, AKM Tahmidul Haque, M Sohel Rahman, A. B. M. Alim Al Islam', 'link': 'https://arxiv.org/abs/2510.05157', 'abstract': 'This paper presents a controlled study of adversarial reinforcement learning in network security through a custom OpenAI Gym environment that models brute-force attacks and reactive defenses on multi-port services. The environment captures realistic security trade-offs including background traffic noise, progressive exploitation mechanics, IP-based evasion tactics, honeypot traps, and multi-level rate-limiting defenses. Competing attacker and defender agents are trained using Deep Q-Networks (DQN) within a zero-sum reward framework, where successful exploits yield large terminal rewards while incremental actions incur small costs. Through systematic evaluation across multiple configurations (varying trap detection probabilities, exploitation difficulty thresholds, and training regimens), the results demonstrate that defender observability and trap effectiveness create substantial barriers to successful attacks. The experiments reveal that reward shaping and careful training scheduling are critical for learning stability in this adversarial setting. The defender consistently maintains strategic advantage across 50,000+ training episodes, with performance gains amplifying when exposed to complex defensive strategies including adaptive IP blocking and port-specific controls. Complete implementation details, reproducible hyperparameter configurations, and architectural guidelines are provided to support future research in adversarial RL for cybersecurity. The zero-sum formulation and realistic operational constraints make this environment suitable for studying autonomous defense systems, attacker-defender co-evolution, and transfer learning to real-world network security scenarios.', 'abstract_zh': '通过对多端口服务进行暴力攻击和反应式防御建模的自定义OpenAI Gym环境，本文呈现了一项受控研究，探讨在网络安全性中对抗强化学习的问题。', 'title_zh': 'adversarial reinforcement learning在模拟零和网络环境中的进攻与防御智能体中的应用'}
{'arxiv_id': 'arXiv:2510.05156', 'title': 'VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation', 'authors': 'Lesly Miculicich, Mihir Parmar, Hamid Palangi, Krishnamurthy Dj Dvijotham, Mirko Montanari, Tomas Pfister, Long T. Le', 'link': 'https://arxiv.org/abs/2510.05156', 'abstract': "The deployment of autonomous AI agents in sensitive domains, such as healthcare, introduces critical risks to safety, security, and privacy. These agents may deviate from user objectives, violate data handling policies, or be compromised by adversarial attacks. Mitigating these dangers necessitates a mechanism to formally guarantee that an agent's actions adhere to predefined safety constraints, a challenge that existing systems do not fully address. We introduce VeriGuard, a novel framework that provides formal safety guarantees for LLM-based agents through a dual-stage architecture designed for robust and verifiable correctness. The initial offline stage involves a comprehensive validation process. It begins by clarifying user intent to establish precise safety specifications. VeriGuard then synthesizes a behavioral policy and subjects it to both testing and formal verification to prove its compliance with these specifications. This iterative process refines the policy until it is deemed correct. Subsequently, the second stage provides online action monitoring, where VeriGuard operates as a runtime monitor to validate each proposed agent action against the pre-verified policy before execution. This separation of the exhaustive offline validation from the lightweight online monitoring allows formal guarantees to be practically applied, providing a robust safeguard that substantially improves the trustworthiness of LLM agents.", 'abstract_zh': '自主AI代理在敏感领域（如医疗保健）的部署引入了对安全、安全性和隐私的严重风险。这些代理可能偏离用户目标、违反数据处理政策或受到恶意攻击的破坏。减轻这些危险需要一种机制来正式保证代理行为符合预定义的安全约束，而现有系统并未完全解决这一挑战。我们提出VeriGuard，这是一种新型框架，通过为基于大语言模型（LLM）的代理提供双重架构来确保稳健且可验证的正确性，从而提供形式安全保证。初始的离线阶段包括一个全面的验证过程。它首先澄清用户意图以建立精确的安全规范。VeriGuard随后合成行为策略并对其进行测试和形式验证，以证明其符合这些规范。这一迭代过程细化策略直到被认定为正确。随后，第二个阶段提供在线行为监控，其中VeriGuard作为运行时监控器，在执行前验证每个提议的代理行为是否符合预先验证的策略。这种将全面的离线验证与 Lightweight 的在线监控分离的方式，使得形式保证能够实际应用，提供了一种增强LLM代理可信度的坚实保障。', 'title_zh': 'VeriGuard: 通过验证代码生成提高LLM代理安全性'}
{'arxiv_id': 'arXiv:2510.05152', 'title': 'A Single Character can Make or Break Your LLM Evals', 'authors': 'Jingtong Su, Jianyu Zhang, Karen Ullrich, Léon Bottou, Mark Ibrahim', 'link': 'https://arxiv.org/abs/2510.05152', 'abstract': "Common Large Language model (LLM) evaluations rely on demonstration examples to steer models' responses to the desired style. While the number of examples used has been studied and standardized, the choice of how to format examples is less investigated. In evaluation protocols and real world usage, users face the choice how to separate in-context examples: use a comma? new line? semi-colon? hashtag? etc.? Surprisingly, we find this seemingly minor choice can dramatically alter model response quality. Across leading model families (Llama, Qwen, Gemma), performance on MMLU for example can vary by $\\pm 23\\%$ depending on the choice of delimiter. In fact, one can manipulate model rankings to put any model in the lead by only modifying the single character separating examples. We find LLMs' brittleness pervades topics, model families, and doesn't improve with scale. By probing attention head scores, we find that good-performing delimiters steer attention towards key tokens in the input. Finally, we explore methods to improve LLMs' robustness to the choice of delimiter. We find specifying the selected delimiter in the prompt boosts robustness and offer practical recommendations for the best-performing delimiters to select.", 'abstract_zh': '常见的大规模语言模型（LLM）评估依赖于示范样例来引导模型的响应风格。虽然使用的样例数量已经被研究和标准化，但样例的格式化方式选择则较少被探讨。在评估协议和实际使用中，用户面临如何分隔上下文样例的选择：使用逗号？新的一行？分号？标签？等等？令人惊讶的是，我们发现这个看似微不足道的选择可以显著改变模型响应的质量。在领先模型家族（Llama、Qwen、Gemma）中，例如在MMLU上的表现可以因分隔符选择的不同而相差±23%。实际上，仅通过修改分隔单个样例的单个字符，便可以操控模型排名使其领先。我们发现，大规模语言模型的脆弱性涉及广泛话题、模型家族，并且不会因规模增大而改善。通过探测注意力头得分，我们发现表现良好的分隔符会引导注意力关注输入中的关键标记。最后，我们探讨了提高大规模语言模型对分隔符选择鲁棒性的方法。我们发现，在提示中指定所选分隔符可以提升鲁棒性，并提供了最佳表现分隔符的实用建议。', 'title_zh': '一个字符可以决定你的LLM评估是成功还是失败'}
{'arxiv_id': 'arXiv:2510.05150', 'title': 'Chronological Thinking in Full-Duplex Spoken Dialogue Language Models', 'authors': 'Donghang Wu, Haoyang Zhang, Chen Chen, Tianyu Zhang, Fei Tian, Xuerui Yang, Gang Yu, Hexin Liu, Nana Hou, Yuchen Hu, Eng Siong Chng', 'link': 'https://arxiv.org/abs/2510.05150', 'abstract': 'Recent advances in spoken dialogue language models (SDLMs) reflect growing interest in shifting from turn-based to full-duplex systems, where the models continuously perceive user speech streams while generating responses. This simultaneous listening and speaking design enables real-time interaction and the agent can handle dynamic conversational behaviors like user barge-in. However, during the listening phase, existing systems keep the agent idle by repeatedly predicting the silence token, which departs from human behavior: we usually engage in lightweight thinking during conversation rather than remaining absent-minded. Inspired by this, we propose Chronological Thinking, a on-the-fly conversational thinking mechanism that aims to improve response quality in full-duplex SDLMs. Specifically, chronological thinking presents a paradigm shift from conventional LLM thinking approaches, such as Chain-of-Thought, purpose-built for streaming acoustic input. (1) Strictly causal: the agent reasons incrementally while listening, updating internal hypotheses only from past audio with no lookahead. (2) No additional latency: reasoning is amortized during the listening window; once the user stops speaking, the agent halts thinking and begins speaking without further delay. Experiments demonstrate the effectiveness of chronological thinking through both objective metrics and human evaluations show consistent improvements in response quality. Furthermore, chronological thinking robustly handles conversational dynamics and attains competitive performance on full-duplex interaction metrics.', 'abstract_zh': '近期连续双向对话语言模型的进展反映了从轮转交互向全双工系统的转变兴趣，其中模型在生成响应的同时持续感知用户语音流。这一同时倾听和说话的设计使得交互近乎实时，并且智能体可以处理用户打断等动态对话行为。然而，在倾听阶段，现有系统通过重复预测静音标记使智能体处于闲置状态，这与人类行为不符：我们在对话过程中通常进行轻量级思考，而不是茫然失神。受此启发，我们提出了一种实时对话思考机制——时间顺序思考，旨在提高全双工连续对话语言模型的响应质量。具体而言，时间顺序思考从传统LLM思考方法（如逐步推理）中带来了范式转变，专为流式声学输入设计。时间顺序思考具有严格因果性：智能体在倾听时逐步推理，仅从过去的声音更新内部假设，无预览。在倾听窗口中推理无额外延迟；一旦用户停止说话，智能体即停止思考并立即开始发声。实验结果通过客观指标和人工评估展示了时间顺序思考的有效性，并显示出响应质量的一致提升。此外，时间顺序思考能够稳健处理对话动态，并在全双工交互指标上获得竞争力表现。', 'title_zh': '全双工口语对话语言模型中的时间轴思维能力'}
{'arxiv_id': 'arXiv:2510.05149', 'title': 'Percepta: High Performance Stream Processing at the Edge', 'authors': 'Clarisse Sousa, Tiago Fonseca, Luis Lino Ferreira, Ricardo Venâncio, Ricardo Severino', 'link': 'https://arxiv.org/abs/2510.05149', 'abstract': 'The rise of real-time data and the proliferation of Internet of Things (IoT) devices have highlighted the limitations of cloud-centric solutions, particularly regarding latency, bandwidth, and privacy. These challenges have driven the growth of Edge Computing. Associated with IoT appears a set of other problems, like: data rate harmonization between multiple sources, protocol conversion, handling the loss of data and the integration with Artificial Intelligence (AI) models. This paper presents Percepta, a lightweight Data Stream Processing (DSP) system tailored to support AI workloads at the edge, with a particular focus on such as Reinforcement Learning (RL). It introduces specialized features such as reward function computation, data storage for model retraining, and real-time data preparation to support continuous decision-making. Additional functionalities include data normalization, harmonization across heterogeneous protocols and sampling rates, and robust handling of missing or incomplete data, making it well suited for the challenges of edge-based AI deployment.', 'abstract_zh': '实时数据的兴起和互联网_of_事物(IoT)设备的普及凸显了以云为中心的解决方案的局限性，尤其是关于延迟、带宽和隐私的问题。这些问题推动了边缘计算的发展。与IoT相关的一系列问题包括：多源数据率协调、协议转换、数据丢失处理以及与人工智能(AI)模型集成。本文介绍了一种轻量级的数据流处理(DSP)系统Percepta，专门支持边缘端的AI工作负载，重点关注强化学习(Reinforcement Learning, RL)。该系统引入了专门的功能，如奖励函数计算、用于模型重训练的数据存储以及实时数据准备，以支持连续决策。额外的功能包括数据规范化、异构协议和采样率的协调以及对缺失或不完整数据的稳健处理，使其适用于基于边缘的AI部署挑战。', 'title_zh': 'Percepta: 高性能边缘流处理'}
{'arxiv_id': 'arXiv:2510.05148', 'title': 'Every Step Counts: Decoding Trajectories as Authorship Fingerprints of dLLMs', 'authors': 'Qi Li, Runpeng Yu, Haiquan Lu, Xinchao Wang', 'link': 'https://arxiv.org/abs/2510.05148', 'abstract': 'Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a competitive paradigm for non-autoregressive language modeling. Their distinctive decoding mechanism enables faster inference speed and strong performance in code generation and mathematical tasks. In this work, we show that the decoding mechanism of dLLMs not only enhances model utility but also can be used as a powerful tool for model attribution. A key challenge in this problem lies in the diversity of attribution scenarios, including distinguishing between different models as well as between different checkpoints or backups of the same model. To ensure broad applicability, we identify two fundamental problems: what information to extract from the decoding trajectory, and how to utilize it effectively. We first observe that relying directly on per-step model confidence yields poor performance. This is mainly due to the bidirectional decoding nature of dLLMs: each newly decoded token influences the confidence of other decoded tokens, making model confidence highly redundant and washing out structural signal regarding decoding order or dependencies. To overcome this, we propose a novel information extraction scheme called the Directed Decoding Map (DDM), which captures structural relationships between decoding steps and better reveals model-specific behaviors. Furthermore, to make full use of the extracted structural information during attribution, we propose Gaussian-Trajectory Attribution (GTA), where we fit a cell-wise Gaussian distribution at each decoding position for each target model, and define the likelihood of a trajectory as the attribution score: if a trajectory exhibits higher log-likelihood under the distribution of a specific model, it is more likely to have been generated by that model. Extensive experiments under different settings validate the utility of our methods.', 'abstract_zh': '离散扩散大型语言模型（dLLMs） recently emerged as a competitive paradigm for非自回归语言建模。它们独特的解码机制能够实现更快的推理速度并在代码生成和数学任务中表现出强大的性能。在本文中，我们展示了dLLMs的解码机制不仅增强了模型的功能，还可以用作模型归因的有效工具。该问题的关键挑战在于归因场景的多样性，包括区分不同模型以及同一模型的不同检查点或备份。为了确保广泛应用，我们识别了两个基本问题：从解码轨迹中提取什么信息，以及如何有效地利用这些信息。我们首先观察到，直接依赖于每步模型的信心会导致性能不佳。这主要是由于dLLMs的双向解码性质：每个新解码的标记会影响其他解码标记的信心，使得模型信心高度冗余，削弱了解码顺序或依赖性的结构性信号。为了解决这一问题，我们提出了一种新的信息提取方案，称为定向解码图（DDM），它捕获了解码步骤之间的结构关系，更好地揭示了模型特定的行为。此外，为了在归因过程中充分利用提取的结构信息，我们提出了高斯轨迹归因（GTA），其中我们为每个目标模型的每个解码位置拟合一个单元级别的高斯分布，并定义轨迹的似然性为其归因分数：如果一条轨迹在某个模型的分布下显示出更高的对数似然性，则更有可能由该模型生成。在不同设置下的广泛实验验证了我们方法的实用性。', 'title_zh': '每步计数：将路径解码为dLLMs的作者指纹'}
{'arxiv_id': 'arXiv:2510.05145', 'title': 'FlashResearch: Real-time Agent Orchestration for Efficient Deep Research', 'authors': 'Lunyiu Nie, Nedim Lipka, Ryan A. Rossi, Swarat Chaudhuri', 'link': 'https://arxiv.org/abs/2510.05145', 'abstract': 'Deep research agents, which synthesize information across diverse sources, are significantly constrained by their sequential reasoning processes. This architectural bottleneck results in high latency, poor runtime adaptability, and inefficient resource allocation, making them impractical for interactive applications. To overcome this, we introduce FlashResearch, a novel framework for efficient deep research that transforms sequential processing into parallel, runtime orchestration by dynamically decomposing complex queries into tree-structured sub-tasks. Our core contributions are threefold: (1) an adaptive planner that dynamically allocates computational resources by determining research breadth and depth based on query complexity; (2) a real-time orchestration layer that monitors research progress and prunes redundant paths to reallocate resources and optimize efficiency; and (3) a multi-dimensional parallelization framework that enables concurrency across both research breadth and depth. Experiments show that FlashResearch consistently improves final report quality within fixed time budgets, and can deliver up to a 5x speedup while maintaining comparable quality.', 'abstract_zh': '高效的FlashResearch框架：通过动态分解复杂查询为树状子任务实现并行运行时 orchestrated 研究', 'title_zh': 'FlashResearch: 实时代理编排以实现高效深度研究'}
{'arxiv_id': 'arXiv:2510.05144', 'title': 'SynCED-EnDe 2025: A Synthetic and Curated English - German Dataset for Critical Error Detection in Machine Translation', 'authors': 'Muskaan Chopra, Lorenz Sparrenberg, Rafet Sifa', 'link': 'https://arxiv.org/abs/2510.05144', 'abstract': 'Critical Error Detection (CED) in machine translation aims to determine whether a translation is safe to use or contains unacceptable deviations in meaning. While the WMT21 English-German CED dataset provided the first benchmark, it is limited in scale, label balance, domain coverage, and temporal freshness. We present SynCED-EnDe, a new resource consisting of 1,000 gold-labeled and 8,000 silver-labeled sentence pairs, balanced 50/50 between error and non-error cases. SynCED-EnDe draws from diverse 2024-2025 sources (StackExchange, this http URL) and introduces explicit error subclasses, structured trigger flags, and fine-grained auxiliary judgments (obviousness, severity, localization complexity, contextual dependency, adequacy deviation). These enrichments enable systematic analyses of error risk and intricacy beyond binary detection. The dataset is permanently hosted on GitHub and Hugging Face, accompanied by documentation, annotation guidelines, and baseline scripts. Benchmark experiments with XLM-R and related encoders show substantial performance gains over WMT21 due to balanced labels and refined annotations. We envision SynCED-EnDe as a community resource to advance safe deployment of MT in information retrieval and conversational assistants, particularly in emerging contexts such as wearable AI devices.', 'abstract_zh': 'SynCED-EnDe：一种新的平衡错误标注资源以促进机器翻译的安全部署', 'title_zh': 'SynCED-EnDe 2025: 一种用于机器翻译关键错误检测的合成和精选英文-德文数据集'}
{'arxiv_id': 'arXiv:2510.05136', 'title': 'Linguistic Characteristics of AI-Generated Text: A Survey', 'authors': 'Luka Terčon, Kaja Dobrovoljc', 'link': 'https://arxiv.org/abs/2510.05136', 'abstract': 'Large language models (LLMs) are solidifying their position in the modern world as effective tools for the automatic generation of text. Their use is quickly becoming commonplace in fields such as education, healthcare, and scientific research. There is a growing need to study the linguistic features present in AI-generated text, as the increasing presence of such texts has profound implications in various disciplines such as corpus linguistics, computational linguistics, and natural language processing. Many observations have already been made, however a broader synthesis of the findings made so far is required to provide a better understanding of the topic. The present survey paper aims to provide such a synthesis of extant research. We categorize the existing works along several dimensions, including the levels of linguistic description, the models included, the genres analyzed, the languages analyzed, and the approach to prompting. Additionally, the same scheme is used to present the findings made so far and expose the current trends followed by researchers. Among the most-often reported findings is the observation that AI-generated text is more likely to contain a more formal and impersonal style, signaled by the increased presence of nouns, determiners, and adpositions and the lower reliance on adjectives and adverbs. AI-generated text is also more likely to feature a lower lexical diversity, a smaller vocabulary size, and repetitive text. Current research, however, remains heavily concentrated on English data and mostly on text generated by the GPT model family, highlighting the need for broader cross-linguistic and cross-model investigation. In most cases authors also fail to address the issue of prompt sensitivity, leaving much room for future studies that employ multiple prompt wordings in the text generation phase.', 'abstract_zh': '大型语言模型（LLMs）在现代世界中确立了其作为文本自动生成有效工具的地位。它们在教育、医疗和科学研究等领域中的应用正在变得日益普遍。越来越多的研究关注AI生成文本中的语言特征，因为这类文本的不断增加在语料库语言学、计算语言学和自然语言处理等领域产生了深远的影响。尽管已经有一些观察结果，但仍需要对现有研究结果进行更广泛的综合，以更好地理解这一主题。本文综述旨在提供这种综合。我们沿几个维度对现有的研究工作进行了分类，包括语言描述的层次、包括的模型、分析的体裁、分析的语言以及提示方法。同时，本文还使用相同的框架展示目前已有的研究发现，揭示当前研究人员遵循的趋势。最受报告的发现之一是，AI生成的文本更可能包含更为正式和客观的风格，表现为名词、冠词和介词等的增加，以及对形容词和副词的依赖减少。AI生成的文本还可能具有较低的词汇多样性、较小的词汇量和重复性内容。然而，当前的研究主要集中在英语数据上，且主要集中于GPT模型家族生成的文本，这凸显了进行更广泛跨语言和跨模型调查的必要性。在大多数情况下，作者也未能解决提示敏感性问题，为未来使用多种提示词进行文本生成的研究留出了空间。', 'title_zh': 'AI生成文本的语言特征：一个综述'}
{'arxiv_id': 'arXiv:2510.05132', 'title': 'Training Large Language Models To Reason In Parallel With Global Forking Tokens', 'authors': 'Sheng Jia, Xiao Wang, Shiva Prasad Kasiviswanathan', 'link': 'https://arxiv.org/abs/2510.05132', 'abstract': 'Although LLMs have demonstrated improved performance by scaling parallel test-time compute, doing so relies on generating reasoning paths that are both diverse and accurate. For challenging problems, the forking tokens that trigger diverse yet correct reasoning modes are typically deep in the sampling tree. Consequently, common strategies to encourage diversity, such as temperature scaling, encounter a worsened trade-off between diversity and accuracy. Motivated by this challenge, we treat parallel reasoning as a set-of-next-token-prediction problem, and incorporate a set-based global loss into Supervised Fine-Tuning (SFT) using self-supervised bipartite matching between our global forking tokens and unique reasoning traces. We observe that, while naive fine-tuning with multiple reasoning traces collapses these unique reasoning modes, our proposed method, Set Supervised Fine-Tuning (SSFT), preserves these modes and produces emergent global forking tokens. Experiments on multiple reasoning benchmarks show that our SSFT consistently outperforms SFT under both Pass@1 and Cons@k metrics.', 'abstract_zh': '尽管大语言模型通过扩展并行测试时计算提高了性能，但这种方法依赖于生成既多样化又准确的推理路径。对于具有挑战性的问题，触发多样化且正确的推理模式的分叉令牌通常位于采样树的深处。因此，鼓励多样性的常见策略，如温度缩放，会加剧多样性与准确性的权衡。受这一挑战的启发，我们将并行推理视为下一个令牌预测的问题，并使用我们的全局分叉令牌与独特的推理轨迹之间的自监督 bipartite 匹配，将基于集合的全局损失集成到监督微调（SFT）中。我们观察到，虽然使用多个推理轨迹的朴素微调会坍缩这些独特的推理模式，但我们提出的方法，集合监督微调（SSFT），能够保留这些模式并产生新兴的全局分叉令牌。在多个推理基准上的实验表明，无论是在 Pass@1 还是 Cons@k 衡量标准下，我们的 SSFT 均 Superior 致 SFT 的表现。', 'title_zh': '训练大规模语言模型并行推理，使用全球分叉标记'}
{'arxiv_id': 'arXiv:2510.05131', 'title': 'Rationale-Augmented Retrieval with Constrained LLM Re-Ranking for Task Discovery', 'authors': 'Bowen Wei', 'link': 'https://arxiv.org/abs/2510.05131', 'abstract': "Head Start programs utilizing GoEngage face significant challenges when new or rotating staff attempt to locate appropriate Tasks (modules) on the platform homepage. These difficulties arise from domain-specific jargon (e.g., IFPA, DRDP), system-specific nomenclature (e.g., Application Pool), and the inherent limitations of lexical search in handling typos and varied word ordering. We propose a pragmatic hybrid semantic search system that synergistically combines lightweight typo-tolerant lexical retrieval, embedding-based vector similarity, and constrained large language model (LLM) re-ranking. Our approach leverages the organization's existing Task Repository and Knowledge Base infrastructure while ensuring trustworthiness through low false-positive rates, evolvability to accommodate terminological changes, and economic efficiency via intelligent caching, shortlist generation, and graceful degradation mechanisms. We provide a comprehensive framework detailing required resources, a phased implementation strategy with concrete milestones, an offline evaluation protocol utilizing curated test cases (Hit@K, Precision@K, Recall@K, MRR), and an online measurement methodology incorporating query success metrics, zero-result rates, and dwell-time proxies.", 'abstract_zh': 'Head Start 程序使用 GoEngage 时，新员工或轮岗员工在尝试在平台主页上定位合适的任务（模块）时面临显著挑战。这些困难源于领域特定的专业术语（例如，IFPA、DRDP），系统特定的命名约定（例如，Application Pool），以及词汇搜索在处理拼写错误和不同词序时的固有限制。我们提出了一种实用的混合语义搜索系统，该系统结合了轻量级的拼写错误容忍词汇检索、基于嵌入的向量相似性以及受约束的大语言模型（LLM）重排序。我们的方法利用组织现有的任务库和知识库基础设施，并通过低误报率、术语变化的可适应性和智能缓存、简短列表生成和优雅降级机制来确保可信度。我们提供了详细的框架，包括所需资源、分阶段的实施策略和具体里程碑、使用精心挑选的测试案例进行离线评估的协议（如 Hit@K、Precision@K、Recall@K、MRR），以及包含查询成功率指标、零结果率和停留时间代理的在线测量方法。', 'title_zh': '基于约束大模型重排序的推理增强检索：用于任务发现'}
{'arxiv_id': 'arXiv:2510.05127', 'title': 'Artificial Intelligence for Cost-Aware Resource Prediction in Big Data Pipelines', 'authors': 'Harshit Goyal', 'link': 'https://arxiv.org/abs/2510.05127', 'abstract': 'Efficient resource allocation is a key challenge in modern cloud computing. Over-provisioning leads to unnecessary costs, while under-provisioning risks performance degradation and SLA violations. This work presents an artificial intelligence approach to predict resource utilization in big data pipelines using Random Forest regression. We preprocess the Google Borg cluster traces to clean, transform, and extract relevant features (CPU, memory, usage distributions). The model achieves high predictive accuracy (R Square = 0.99, MAE = 0.0048, RMSE = 0.137), capturing non-linear relationships between workload characteristics and resource utilization. Error analysis reveals impressive performance on small-to-medium jobs, with higher variance in rare large-scale jobs. These results demonstrate the potential of AI-driven prediction for cost-aware autoscaling in cloud environments, reducing unnecessary provisioning while safeguarding service quality.', 'abstract_zh': '高效资源分配是现代云计算中的关键挑战。过度分配导致不必要的成本，而资源不足则可能引发性能下降和SLA违反。本文提出了一种使用随机森林回归的人工智能方法来预测大数据管道中的资源利用率。我们预处理了Google Borg集群追踪数据，清理、转换并提取相关特征（CPU、内存、使用分布）。模型实现了高度预测准确性（决定系数R平方=0.99，平均绝对误差MAE=0.0048，均方根误差RMSE=0.137），捕捉了工作负载特性与资源利用率之间的非线性关系。误差分析表明，该模型在小到中等规模作业上表现优异，但在少量大规模作业上表现出较高的方差。这些结果展示了基于AI的预测在云环境中进行成本意识自动扩展的潜力，能够减少不必要的资源配置同时保证服务质量。', 'title_zh': '人工智能在大数据管道中的成本意识资源预测'}
{'arxiv_id': 'arXiv:2510.05126', 'title': 'Improving Metacognition and Uncertainty Communication in Language Models', 'authors': 'Mark Steyvers, Catarina Belem, Padhraic Smyth', 'link': 'https://arxiv.org/abs/2510.05126', 'abstract': "Large language models (LLMs) are increasingly used in decision-making contexts, but when they present answers without signaling low confidence, users may unknowingly act on erroneous outputs. While prior work shows that LLMs maintain internal uncertainty signals, their explicit verbalized confidence is typically miscalibrated and poorly discriminates between correct and incorrect answers. Across two types of LLMs, we investigate whether supervised finetuning can improve models' ability to communicate uncertainty and whether such improvements generalize across tasks and domains. We finetune the LLMs on datasets spanning general knowledge, mathematics, and open-ended trivia, and evaluate two metacognitive tasks: (1) single-question confidence estimation, where the model assigns a numeric certainty to its answer, and (2) pairwise confidence comparison, where the model selects which of two answers it is more likely to have correct. We assess generalization to unseen domains, including medical and legal reasoning. Results show that finetuning improves calibration (alignment between stated confidence and accuracy) and discrimination (higher confidence for correct vs. incorrect responses) within and across domains, while leaving accuracy unchanged. However, improvements are task-specific: training on single-question calibration does not transfer to pairwise comparison, and vice versa. In contrast, multitask finetuning on both forms of metacognition yields broader gains, producing lower calibration error and stronger discrimination in out-of-domain evaluations. These results show that while uncertainty communication in LLMs is trainable and generalizable, different metacognitive skills do not naturally reinforce one another and must be developed together through multitask training.", 'abstract_zh': '大型语言模型（LLMs）在决策场景中的应用日益增多，但当它们不信号低置信度时，用户可能会无意识地依赖错误的输出。虽然先前的研究表明LLMs保留了内部不确定性信号，但其明确表达的置信度通常是不准确的，并且不能很好地区分正确和错误的答案。我们在两种类型的LLMs上研究监督微调能否提高模型在表达不确定性和这种改进是否能在任务和领域之间泛化的能力。我们对涵盖通用知识、数学和开放 trivia 的数据集进行微调，并评估了两个元认知任务：（1）单题置信度估计，模型对其答案给出一个数值确定性；（2）两两置信度比较，模型选择其更有可能正确的答案。我们评估了模型在未知领域（包括医疗和法律推理）中的泛化能力。结果表明，微调可以提高置信度校准（声明的置信度与准确性之间的对齐）和辨别力（正确的答案有更高的置信度），而准确率保持不变。然而，改进具有任务特异性：单题校准训练不适用于两两比较，反之亦然。相比之下，对两种形式的元认知进行的多任务微调能产生更广泛的好处，在领域外评估中，校准误差更低，辨别力更强。这些结果表明，虽然LLMs中的不确定性沟通是可训练和可泛化的，但不同的元认知技能并不会自然相互强化，而是需要通过多任务训练共同开发。', 'title_zh': '提高语言模型的元认知和不确定性沟通能力'}
{'arxiv_id': 'arXiv:2510.05124', 'title': 'MADS: Multi-Agent Dialogue Simulation for Diverse Persuasion Data Generation', 'authors': 'Mingjin Li, Yu Liu, Huayi Liu, Xiang Ye, Chao Jiang, Hongguang Zhang', 'link': 'https://arxiv.org/abs/2510.05124', 'abstract': "We propose MADS (Multi-Agent Dialogue Simulation), a scalable framework for generating persuasive multi-turn dialogues via agent self-play. MADS employs three coordinated agents: User Agents simulating diverse persona-driven behaviors, a Dialog Agent executing task-oriented persuasion strategies and an Optimization Agent evaluating and refining dialogue outcomes. We further validate its effectiveness through users' Chain-of-Attitude (CoA) modeling and dedicated LLMs' persuasion assessment. This approach enables low-cost generation of training data without human annotation, addressing key industry challenges such as lack of user data, cold-start evaluation difficulties, and prompt inefficiency. Applied to a real-world marketing scenario, MADS significantly improved the persuasion capacity of small LLMs, increasing the organic traffic conversion rate by 22.4\\% (from 1.83\\% to 2.24\\%) , demonstrating clear business value.", 'abstract_zh': '我们提出MADS（多代理对话模拟），一种用于通过代理自玩生成具有说服力的多轮对话的可扩展框架。MADS 使用三个协调的代理：用户代理模拟多样的人格驱动行为，对话代理执行任务导向的说服策略，以及优化代理评估和精炼对话结果。我们进一步通过用户的情绪链（CoA）建模和专用的大规模语言模型（LLM）的说服评估来验证其有效性。该方法能够低成本生成训练数据，无需人工注释，解决行业挑战如缺乏用户数据、冷启动评估困难和提示效率低下等问题。在实际市场营销场景中，MADS 显著提高了小型LLM的说服能力，有机流量转化率提高22.4%（从1.83%提升到2.24%），展示了明显的商业价值。', 'title_zh': 'MADS：多种智能体对话模拟以生成多元说服数据'}
{'arxiv_id': 'arXiv:2510.05123', 'title': 'A Scalable AI Driven, IoT Integrated Cognitive Digital Twin for Multi-Modal Neuro-Oncological Prognostics and Tumor Kinetics Prediction using Enhanced Vision Transformer and XAI', 'authors': 'Saptarshi Banerjee, Himadri Nath Saha, Utsho Banerjee, Rajarshi Karmakar, Jon Turdiev', 'link': 'https://arxiv.org/abs/2510.05123', 'abstract': 'Neuro-oncological prognostics are now vital in modern clinical neuroscience because brain tumors pose significant challenges in detection and management. To tackle this issue, we propose a cognitive digital twin framework that combines real-time EEG signals from a wearable skullcap with structural MRI data for dynamic and personalized tumor monitoring. At the heart of this framework is an Enhanced Vision Transformer (ViT++) that includes innovative components like Patch-Level Attention Regularization (PLAR) and an Adaptive Threshold Mechanism to improve tumor localization and understanding. A Bidirectional LSTM-based neural classifier analyzes EEG patterns over time to classify brain states such as seizure, interictal, and healthy. Grad-CAM-based heatmaps and a this http URL-powered 3D visualization module provide interactive anatomical insights. Furthermore, a tumor kinetics engine predicts volumetric growth by looking at changes in MRI trends and anomalies from EEG data. With impressive accuracy metrics of 94.6% precision, 93.2% recall, and a Dice score of 0.91, this framework sets a new standard for real-time, interpretable neurodiagnostics. It paves the way for future advancements in intelligent brain health monitoring.', 'abstract_zh': '神经 Oncological 预后现在是现代临床神经科学中的重要组成部分，因为脑肿瘤在检测和管理方面提出了重大挑战。为解决这一问题，我们提出了一种结合穿戴式头盔实时 EEG 信号与结构 MRI 数据的认知数字孪生框架，以实现动态和个性化的肿瘤监测。该框架的核心是增强型视觉变换器（ViT++），它包括像Patch-Level Attention Regularization (PLAR) 和自适应阈值机制等创新组件，以提高肿瘤定位和理解。基于双向 LSTM 的神经分类器分析随时间变化的 EEG 模式，以分类脑状态（如癫痫、无发作期和健康状态）。基于 Grad-CAM 的热图和由此链接提供的 3D 可视化模块提供了交互式的解剖学洞察。此外，肿瘤动力学引擎通过观察 MRI 趋势的变化和 EEG 数据中的异常来预测肿瘤体积的增长。凭借 94.6% 的精确度、93.2% 的召回率和 0.91 的 Dice 分数，该框架建立了实时、可解释神经诊断的新标准。它为未来的智能大脑健康监测的进步铺平了道路。', 'title_zh': '基于增强视觉变换器和可解释人工智能的可扩展AI驱动物联网集成认知数字双胞胎多模态神经 Oncology 预后及肿瘤动力学预测'}
{'arxiv_id': 'arXiv:2510.05122', 'title': 'CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation', 'authors': 'Jie Zhu, Yuanchen Zhou, Shuo Jiang, Junhui Li, Lifan Guo, Feng Chen, Chi Zhang, Fang Kong', 'link': 'https://arxiv.org/abs/2510.05122', 'abstract': 'Emotional Support Conversation (ESC) plays a vital role in alleviating psychological stress and providing emotional value through dialogue. While recent studies have largely focused on data augmentation and synthetic corpus construction, they often overlook the deeper cognitive reasoning processes that underpin effective emotional support. To address this gap, we propose \\textbf{CARE}, a novel framework that strengthens reasoning in ESC without relying on large-scale synthetic data. CARE leverages the original ESC training set to guide models in generating logically coherent and supportive responses, thereby explicitly enhancing cognitive reasoning. Building on this foundation, we further employ reinforcement learning to refine and reinforce the reasoning process. Experimental results demonstrate that CARE significantly improves both the logical soundness and supportive quality of responses, advancing the development of empathetic, cognitively robust, and human-like emotional support systems.', 'abstract_zh': '情感支持对话(CARE)在缓解心理压力和通过对话提供情感价值中发挥着重要作用。尽管近期研究主要集中在数据增强和合成语料库构建上，它们往往忽视了有效的的情感支持背后的深层次认知推理过程。为填补这一空白，我们提出了一种名为CARE的新型框架，该框架不依赖大规模合成数据来加强情感支持对话中的推理。CARE利用原始的情感支持对话训练集引导模型生成逻辑连贯和支持性较强的回应，从而明确增强认知推理。在此基础上，我们进一步采用强化学习来完善和强化推理过程。实验结果表明，CARE显著提高了回应的逻辑一致性和支持性质量，推动了共情、认知稳健且类人为的情感支持系统的开发。', 'title_zh': 'CARE: 认知推理增强的强化学习情感支持对话'}
{'arxiv_id': 'arXiv:2510.05116', 'title': 'Hallucination is Inevitable for LLMs with the Open World Assumption', 'authors': 'Bowen Xu', 'link': 'https://arxiv.org/abs/2510.05116', 'abstract': "Large Language Models (LLMs) exhibit impressive linguistic competence but also produce inaccurate or fabricated outputs, often called ``hallucinations''. Engineering approaches usually regard hallucination as a defect to be minimized, while formal analyses have argued for its theoretical inevitability. Yet both perspectives remain incomplete when considering the conditions required for artificial general intelligence (AGI). This paper reframes ``hallucination'' as a manifestation of the generalization problem. Under the Closed World assumption, where training and test distributions are consistent, hallucinations may be mitigated. Under the Open World assumption, however, where the environment is unbounded, hallucinations become inevitable. This paper further develops a classification of hallucination, distinguishing cases that may be corrected from those that appear unavoidable under open-world conditions. On this basis, it suggests that ``hallucination'' should be approached not merely as an engineering defect but as a structural feature to be tolerated and made compatible with human intelligence.", 'abstract_zh': '大型语言模型（LLMs）展示了卓越的语言能力，但也产生了不准确或虚构的输出，通常称为“幻觉”。在闭世界假设下，训练和测试分布一致时，幻觉可以被缓解。而在开放世界假设下，由于环境无界限，幻觉不可避免。本文进一步对幻觉进行了分类，区分了在开放世界条件下可能纠正的案例和不可避免的案例，并建议应当将“幻觉”不仅视为工程上的缺陷，还视为一种可以容忍和与人类智能兼容的结构性特征。', 'title_zh': '开放世界假设下语言模型的幻觉不可避免'}
{'arxiv_id': 'arXiv:2510.05113', 'title': 'Trainable Reference-Based Evaluation Metric for Identifying Quality of English-Gujarati Machine Translation System', 'authors': 'Nisheeth Joshi, Pragya Katyayan, Palak Arora', 'link': 'https://arxiv.org/abs/2510.05113', 'abstract': 'Machine Translation (MT) Evaluation is an integral part of the MT development life cycle. Without analyzing the outputs of MT engines, it is impossible to evaluate the performance of an MT system. Through experiments, it has been identified that what works for English and other European languages does not work well with Indian languages. Thus, In this paper, we have introduced a reference-based MT evaluation metric for Gujarati which is based on supervised learning. We have trained two versions of the metric which uses 25 features for training. Among the two models, one model is trained using 6 hidden layers with 500 epochs while the other model is trained using 10 hidden layers with 500 epochs. To test the performance of the metric, we collected 1000 MT outputs of seven MT systems. These MT engine outputs were compared with 1 human reference translation. While comparing the developed metrics with other available metrics, it was found that the metrics produced better human correlations.', 'abstract_zh': '基于参考的古吉拉特语机器翻译评价指标研究', 'title_zh': '基于参考的可训练评估指标用于识别英语-古吉拉特语机器翻译系统质量'}
{'arxiv_id': 'arXiv:2510.05109', 'title': 'Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices', 'authors': 'Yilong Li, Shuai Zhang, Yijing Zeng, Hao Zhang, Xinmiao Xiong, Jingyu Liu, Pan Hu, Suman Banerjee', 'link': 'https://arxiv.org/abs/2510.05109', 'abstract': "Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\\% and GPU memory usage by 11.2\\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly half a day and LLaMA-3-8B for voice interactions up to almost 20.8 hours.", 'abstract_zh': '基于硬件-软件协同设计的大型多模态模型推理框架：NANOMIND', 'title_zh': '小巧而强大：一种适用于电池供电小型设备高效多模态推理的软硬件协同设计方法'}
{'arxiv_id': 'arXiv:2509.22075', 'title': 'COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning', 'authors': 'Dmitriy Shopkhoev, Denis Makhov, Magauiya Zhussip, Ammar Ali, Stamatios Lefkimmiatis', 'link': 'https://arxiv.org/abs/2509.22075', 'abstract': 'Post-training compression of large language models (LLMs) largely relies on low-rank weight approximation, which represents each column of a weight matrix in a shared low-dimensional subspace. While this is a computationally efficient strategy, the imposed structural constraint is rigid and can lead to a noticeable model accuracy drop. In this work, we propose CoSpaDi (Compression via Sparse Dictionary Learning), a novel training-free compression framework that replaces low-rank decomposition with a more flexible structured sparse factorization in which each weight matrix is represented with a dense dictionary and a column-sparse coefficient matrix. This formulation enables a union-of-subspaces representation: different columns of the original weight matrix are approximated in distinct subspaces spanned by adaptively selected dictionary atoms, offering greater expressiveness than a single invariant basis. Crucially, CoSpaDi leverages a small calibration dataset to optimize the factorization such that the output activations of compressed projection layers closely match those of the original ones, thereby minimizing functional reconstruction error rather than mere weight approximation. This data-aware strategy preserves better model fidelity without any fine-tuning under reasonable compression ratios. Moreover, the resulting structured sparsity allows efficient sparse-dense matrix multiplication and is compatible with post-training quantization for further memory and latency gains. We evaluate CoSpaDi across multiple Llama and Qwen models under per-layer and per-group settings at 20-50\\% compression ratios, demonstrating consistent superiority over state-of-the-art data-aware low-rank methods both in accuracy and perplexity. Our results establish structured sparse dictionary learning as a powerful alternative to conventional low-rank approaches for efficient LLM deployment.', 'abstract_zh': 'Post-training压缩大型语言模型（LLMs）主要依赖低秩权重_approximation，即将权重矩阵的每一列表示在共享的低维子空间中。虽然这是一种计算高效的策略，但施加的结构约束较为刚性，可能导致模型准确性下降。在本文中，我们提出了一种名为CoSpaDi（基于稀疏字典学习的压缩）的新型无训练压缩框架，该框架用一个稠密字典和一个列稀疏系数矩阵代替低秩分解，从而表示权重矩阵。这种表示形式允许子空间 union 形式的表示：原始权重矩阵的不同列被自适应选择的字典原子所在的不同的子空间表示，提供了比单一不变基更好的表达能力。至关重要的是，CoSpaDi 利用一个小的校准数据集优化因子分解，使得压缩后的投影层的输出激活值与原始层的输出激活值尽可能接近，从而最小化功能重建误差而不是简单的权重近似。这种数据意识策略在合理的压缩比下能够更好地保持模型的 fidelity，且无需任何微调。此外，产生的结构稀疏性允许高效的稀疏密集矩阵乘法，并与后续的训练后量化兼容，进一步降低内存和延迟开销。我们在_LLAMA 和_Qwen 模型下分别在20-50%的层级和组级压缩比下评估了 CoSpaDi，结果表明，在准确性和困惑度方面，CoSpaDi 比最先进的数据意识低秩方法表现更优。我们的结果确立了结构稀疏字典学习作为一种高效部署大型语言模型的强大替代方法。', 'title_zh': 'COSPADI: 通过校准引导的稀疏字典学习压缩大语言模型'}
{'arxiv_id': 'arXiv:2409.15436', 'title': 'Ads that Talk Back: Implications and Perceptions of Injecting Personalized Advertising into LLM Chatbots', 'authors': 'Brian Jay Tang, Kaiwen Sun, Noah T. Curran, Florian Schaub, Kang G. Shin', 'link': 'https://arxiv.org/abs/2409.15436', 'abstract': 'Recent advances in large language models (LLMs) have enabled the creation of highly effective chatbots. However, the compute costs of widely deploying LLMs have raised questions about profitability. Companies have proposed exploring ad-based revenue streams for monetizing LLMs, which could serve as the new de facto platform for advertising. This paper investigates the implications of personalizing LLM advertisements to individual users via a between-subjects experiment with 179 participants. We developed a chatbot that embeds personalized product advertisements within LLM responses, inspired by similar forays by AI companies. The evaluation of our benchmarks showed that ad injection only slightly impacted LLM performance, particularly response desirability. Results revealed that participants struggled to detect ads, and even preferred LLM responses with hidden advertisements. Rather than clicking on our advertising disclosure, participants tried changing their advertising settings using natural language queries. We created an advertising dataset and an open-source LLM, Phi-4-Ads, fine-tuned to serve ads and flexibly adapt to user preferences.', 'abstract_zh': '近年来，大型语言模型（LLMs）的进展使得创建高效的聊天机器人成为可能。然而，广泛部署LLMs的计算成本引发了盈利能力的质疑。公司提出了通过广告收入流来 monetize LLMs 的思路，这可能成为新的事实上的广告平台。本文通过一项包含179名参与者的之间实验，探讨了个性化LLM广告对个体用户的影响。我们开发了一个聊天机器人，该机器人在LLM响应中嵌入了个性化的产品广告，灵感来自于类似AI公司的尝试。我们的基准评估显示，广告插入只对LLM性能产生了轻微影响，特别是在响应吸引力方面。结果显示，参与者难以检测到广告，并且甚至更偏好带有隐藏广告的LLM响应。参与者尝试通过自然语言查询来更改他们的广告设置，而不是点击我们的广告披露。我们创建了一个广告数据集和一个开源的LLM Phi-4-Ads，该模型经过微调以提供广告并灵活适应用户偏好。', 'title_zh': '与广告对话：将个性化广告注入LLM聊天机器人的含义与感知'}
