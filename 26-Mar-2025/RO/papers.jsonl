{'arxiv_id': 'arXiv:2503.19893', 'title': 'Visuo-Tactile Object Pose Estimation for a Multi-Finger Robot Hand with Low-Resolution In-Hand Tactile Sensing', 'authors': 'Lukas Mack, Felix Grüninger, Benjamin A. Richardson, Regine Lendway, Katherine J. Kuchenbecker, Joerg Stueckler', 'link': 'https://arxiv.org/abs/2503.19893', 'abstract': "Accurate 3D pose estimation of grasped objects is an important prerequisite for robots to perform assembly or in-hand manipulation tasks, but object occlusion by the robot's own hand greatly increases the difficulty of this perceptual task. Here, we propose that combining visual information and proprioception with binary, low-resolution tactile contact measurements from across the interior surface of an articulated robotic hand can mitigate this issue. The visuo-tactile object-pose-estimation problem is formulated probabilistically in a factor graph. The pose of the object is optimized to align with the three kinds of measurements using a robust cost function to reduce the influence of visual or tactile outlier readings. The advantages of the proposed approach are first demonstrated in simulation: a custom 15-DoF robot hand with one binary tactile sensor per link grasps 17 YCB objects while observed by an RGB-D camera. This low-resolution in-hand tactile sensing significantly improves object-pose estimates under high occlusion and also high visual noise. We also show these benefits through grasping tests with a preliminary real version of our tactile hand, obtaining reasonable visuo-tactile estimates of object pose at approximately 13.3 Hz on average.", 'abstract_zh': '准确估计被抓物体的3D姿态是机器人执行装配或手持操作任务的前提，但机器人自身手部的遮挡大大增加了这一感知任务的难度。为此，我们提出将视觉信息与来自机器人articulated手内部表面的二进制、低分辨率触觉接触测量值相结合和 proprioception 结合，可以缓解这一问题。物体姿态的visuo-tactile估计问题通过因子图的概率模型进行表述。使用鲁棒代价函数优化物体的姿态，使其与视觉或触觉测量值对齐，从而减少异常值测量值的影响。提出的这种方法首先在仿真中得到验证：一个自定义的15-DoF机器人手，每个关节连接一个二进制触觉传感器，在一个RGB-D相机的观察下抓取17个YCB物体。这种低分辨率的手内触觉传感在高遮挡和高视觉噪声条件下显著提高了物体姿态估计的准确性。我们还通过一个初步的实体触觉手的抓取测试展示了这些优势，平均以大约13.3 Hz的频率获得合理的visuo-tactile物体姿态估计。', 'title_zh': '基于低分辨率手内触觉传感的多指机器人手视觉-触觉物体姿态估计'}
{'arxiv_id': 'arXiv:2503.19757', 'title': 'Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy', 'authors': 'Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu, Yu Qiao, Jifeng Dai, Yuntao Chen', 'link': 'https://arxiv.org/abs/2503.19757', 'abstract': "While recent vision-language-action models trained on diverse robot datasets exhibit promising generalization capabilities with limited in-domain data, their reliance on compact action heads to predict discretized or continuous actions constrains adaptability to heterogeneous action spaces. We present Dita, a scalable framework that leverages Transformer architectures to directly denoise continuous action sequences through a unified multimodal diffusion process. Departing from prior methods that condition denoising on fused embeddings via shallow networks, Dita employs in-context conditioning -- enabling fine-grained alignment between denoised actions and raw visual tokens from historical observations. This design explicitly models action deltas and environmental nuances. By scaling the diffusion action denoiser alongside the Transformer's scalability, Dita effectively integrates cross-embodiment datasets across diverse camera perspectives, observation scenes, tasks, and action spaces. Such synergy enhances robustness against various variances and facilitates the successful execution of long-horizon tasks. Evaluations across extensive benchmarks demonstrate state-of-the-art or comparative performance in simulation. Notably, Dita achieves robust real-world adaptation to environmental variances and complex long-horizon tasks through 10-shot finetuning, using only third-person camera inputs. The architecture establishes a versatile, lightweight and open-source baseline for generalist robot policy learning. Project Page: this https URL.", 'abstract_zh': '基于变换器架构的可扩展框架Dita：通过统一多模态扩散过程直接去噪连续动作序列', 'title_zh': 'Dita: 面向通用视觉-语言-动作策略的扩散变换器扩展方法'}
{'arxiv_id': 'arXiv:2503.19713', 'title': 'Semi-SD: Semi-Supervised Metric Depth Estimation via Surrounding Cameras for Autonomous Driving', 'authors': 'Yusen Xie, Zhengmin Huang, Shaojie Shen, Jun Ma', 'link': 'https://arxiv.org/abs/2503.19713', 'abstract': 'In this paper, we introduce Semi-SD, a novel metric depth estimation framework tailored for surrounding cameras equipment in autonomous driving. In this work, the input data consists of adjacent surrounding frames and camera parameters. We propose a unified spatial-temporal-semantic fusion module to construct the visual fused features. Cross-attention components for surrounding cameras and adjacent frames are utilized to focus on metric scale information refinement and temporal feature matching. Building on this, we propose a pose estimation framework using surrounding cameras, their corresponding estimated depths, and extrinsic parameters, which effectively address the scale ambiguity in multi-camera setups. Moreover, semantic world model and monocular depth estimation world model are integrated to supervised the depth estimation, which improve the quality of depth estimation. We evaluate our algorithm on DDAD and nuScenes datasets, and the results demonstrate that our method achieves state-of-the-art performance in terms of surrounding camera based depth estimation quality. The source code will be available on this https URL.', 'abstract_zh': '本文引入了Semi-SD，这是一种针对自动驾驶周围摄像头设备的新颖度量depth估计框架。本文的输入数据包括相邻的周围帧和摄像头参数。我们提出了一种统一的空间-时间-语义融合模块来构建视觉融合特征。利用周围摄像头和相邻帧的交叉注意力组件，专注于度量尺度信息的细化和时间特征匹配。在此基础上，我们提出了一种使用周围摄像头、它们对应的估计depth以及外参的姿态估计框架，有效解决了多摄像头配置中的尺度模糊问题。此外，语义世界模型和单目depth估计世界模型被集成以监督depth估计，从而提高depth估计的质量。我们在DDAD和nuScenes数据集上评估了该算法，结果表明，我们的方法在基于周围摄像头的depth估计质量方面达到了最先进的性能。源代码将在此处提供。', 'title_zh': '半监督SD：基于周围摄像头的半监督度量深度估计在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2503.19690', 'title': 'Risk-Aware Reinforcement Learning for Autonomous Driving: Improving Safety When Driving through Intersection', 'authors': 'Bo Leng, Ran Yu, Wei Han, Lu Xiong, Zhuoren Li, Hailong Huang', 'link': 'https://arxiv.org/abs/2503.19690', 'abstract': 'Applying reinforcement learning to autonomous driving has garnered widespread attention. However, classical reinforcement learning methods optimize policies by maximizing expected rewards but lack sufficient safety considerations, often putting agents in hazardous situations. This paper proposes a risk-aware reinforcement learning approach for autonomous driving to improve the safety performance when crossing the intersection. Safe critics are constructed to evaluate driving risk and work in conjunction with the reward critic to update the actor. Based on this, a Lagrangian relaxation method and cyclic gradient iteration are combined to project actions into a feasible safe region. Furthermore, a Multi-hop and Multi-layer perception (MLP) mixed Attention Mechanism (MMAM) is incorporated into the actor-critic network, enabling the policy to adapt to dynamic traffic and overcome permutation sensitivity challenges. This allows the policy to focus more effectively on surrounding potential risks while enhancing the identification of passing opportunities. Simulation tests are conducted on different tasks at unsignalized intersections. The results show that the proposed approach effectively reduces collision rates and improves crossing efficiency in comparison to baseline algorithms. Additionally, our ablation experiments demonstrate the benefits of incorporating risk-awareness and MMAM into RL.', 'abstract_zh': '将经典强化学习方法应用于自动驾驶引发了广泛关注。然而，传统强化学习方法通过最大化预期奖励优化策略，但在安全考虑方面存在不足，往往会将智能体置于危险境地。本文提出了一种风险感知强化学习方法，以提高自动驾驶在交叉路口穿越时的安全性能。构造了安全评论家来评估驾驶风险，并与奖励评论家协同工作以更新行为者。在此基础上，结合了拉格朗日松弛方法和循环梯度迭代，将动作投影到可行的安全区域内。此外，将多跳和多层感知机混合注意力机制（MMAM）整合到行为者-评论家网络中，使策略能够适应动态交通并克服排列敏感性挑战。这使得策略能够更有效地关注周围潜在风险，同时增强对通行机会的识别。在无信号交叉路口的不同任务中进行了仿真测试。结果表明，所提出的方法在与基线算法相比时，有效降低了碰撞率并提高了穿越效率。另外，我们的消融实验展示了将风险感知和MMAM整合到RL中的益处。', 'title_zh': '面向风险的强化学习在自主驾驶中的应用：交叉路口驾驶时提高安全性'}
{'arxiv_id': 'arXiv:2503.19613', 'title': 'Energy-aware Joint Orchestration of 5G and Robots: Experimental Testbed and Field Validation', 'authors': 'Milan Groshev, Lanfranco Zanzi, Carmen Delgado, Xi Li, Antonio de la Oliva, Xavier Costa-Perez', 'link': 'https://arxiv.org/abs/2503.19613', 'abstract': '5G mobile networks introduce a new dimension for connecting and operating mobile robots in outdoor environments, leveraging cloud-native and offloading features of 5G networks to enable fully flexible and collaborative cloud robot operations. However, the limited battery life of robots remains a significant obstacle to their effective adoption in real-world exploration scenarios. This paper explores, via field experiments, the potential energy-saving gains of OROS, a joint orchestration of 5G and Robot Operating System (ROS) that coordinates multiple 5G-connected robots both in terms of navigation and sensing, as well as optimizes their cloud-native service resource utilization while minimizing total resource and energy consumption on the robots based on real-time feedback. We designed, implemented and evaluated our proposed OROS in an experimental testbed composed of commercial off-the-shelf robots and a local 5G infrastructure deployed on a campus. The experimental results demonstrated that OROS significantly outperforms state-of-the-art approaches in terms of energy savings by offloading demanding computational tasks to the 5G edge infrastructure and dynamic energy management of on-board sensors (e.g., switching them off when they are not needed). This strategy achieves approximately 15% energy savings on the robots, thereby extending battery life, which in turn allows for longer operating times and better resource utilization.', 'abstract_zh': '5G移动网络为户外环境中的移动机器人连接和操作引入了新的维度，通过利用5G网络的云原生和卸载特性，实现全方位灵活协作的云机器人操作。然而，机器人的有限电池寿命仍然是其在实际探索场景中有效应用的一个重要障碍。本文通过现场实验探讨了OROS（5G和机器人操作系统联合 orchestration）的节能潜力，该方法协调多台5G连接的机器人在导航和感知方面，并优化其云原生服务资源利用，同时基于实时反馈最小化总资源和能量消耗。我们设计、实施并评估了提出的OROS，该系统由商用现成的机器人和部署在校园内的本地5G基础设施构成。实验结果表明，OROS通过将计算密集型任务卸载到5G边缘基础设施以及动态管理机载传感器的能量（例如，在不需要时关闭它们）在节能方面显著优于现有方法，实现了约15%的节能效果，从而延长了电池寿命，进而允许更长的运行时间和更好的资源利用。', 'title_zh': '5G与机器人能量感知联合协同：实验测试床与现场验证'}
{'arxiv_id': 'arXiv:2503.19556', 'title': 'ZodiAq: An Isotropic Flagella-Inspired Soft Underwater Drone for Safe Marine Exploration', 'authors': 'Anup Teejo Mathew, Daniel Feliu-Talegon, Yusuf Abdullahi Adamu, Ikhlas Ben Hmida, Costanza Armanini, Cesare Stefanini, Lakmal Seneviratne, Federico Renda', 'link': 'https://arxiv.org/abs/2503.19556', 'abstract': "The inherent challenges of robotic underwater exploration, such as hydrodynamic effects, the complexity of dynamic coupling, and the necessity for sensitive interaction with marine life, call for the adoption of soft robotic approaches in marine exploration. To address this, we present a novel prototype, ZodiAq, a soft underwater drone inspired by prokaryotic bacterial flagella. ZodiAq's unique dodecahedral structure, equipped with 12 flagella-like arms, ensures design redundancy and compliance, ideal for navigating complex underwater terrains. The prototype features a central unit based on a Raspberry Pi, connected to a sensory system for inertial, depth, and vision detection, and an acoustic modem for communication. Combined with the implemented control law, it renders ZodiAq an intelligent system. This paper details the design and fabrication process of ZodiAq, highlighting design choices and prototype capabilities. Based on the strain-based modeling of Cosserat rods, we have developed a digital twin of the prototype within a simulation toolbox to ease analysis and control. To optimize its operation in dynamic aquatic conditions, a simplified model-based controller has been developed and implemented, facilitating intelligent and adaptive movement in the hydrodynamic environment. Extensive experimental demonstrations highlight the drone's potential, showcasing its design redundancy, embodied intelligence, crawling gait, and practical applications in diverse underwater settings. This research contributes significantly to the field of underwater soft robotics, offering a promising new avenue for safe, efficient, and environmentally conscious underwater exploration.", 'abstract_zh': '软体机器人在水下探索中的固有挑战及其解决策略：以受原核细菌鞭毛启发的ZodiAq水下无人机为例', 'title_zh': 'ZodiAq：一种基于 isotropic 鞭毛启发的软水下无人机，用于安全的海洋探索'}
{'arxiv_id': 'arXiv:2503.19516', 'title': 'DataPlatter: Boosting Robotic Manipulation Generalization with Minimal Costly Data', 'authors': 'Liming Zheng, Feng Yan, Fanfan Liu, Chengjian Feng, Yufeng Zhong, Yiyang Huang, Lin Ma', 'link': 'https://arxiv.org/abs/2503.19516', 'abstract': "The growing adoption of Vision-Language-Action (VLA) models in embodied AI intensifies the demand for diverse manipulation demonstrations. However, high costs associated with data collection often result in insufficient data coverage across all scenarios, which limits the performance of the models. It is observed that the spatial reasoning phase (SRP) in large workspace dominates the failure cases. Fortunately, this data can be collected with low cost, underscoring the potential of leveraging inexpensive data to improve model performance. In this paper, we introduce the DataPlatter method, a framework that decouples training trajectories into distinct task stages and leverages abundant easily collectible SRP data to enhance VLA model's generalization. Through analysis we demonstrate that sub-task-specific training with additional SRP data with proper proportion can act as a performance catalyst for robot manipulation, maximizing the utilization of costly physical interaction phase (PIP) data. Experiments show that through introducing large proportion of cost-effective SRP trajectories into a limited set of PIP data, we can achieve a maximum improvement of 41\\% on success rate in zero-shot scenes, while with the ability to transfer manipulation skill to novel targets.", 'abstract_zh': 'Vision-Language-Action模型在具身AI中的广泛应用加剧了对多样操作示范的需求。然而，与数据收集相关的高成本常常导致场景覆盖不足，限制了模型性能。观察到，在大工作空间中占主导地位的失败案例主要源于空间推理阶段（SRP）。幸运的是，这些数据可以通过低成本方式收集，强调了利用低成本数据提高模型性能的潜力。本文提出了DataPlatter方法，这是一种将训练轨迹分解为不同任务阶段的框架，利用丰富的易获取的SRP数据来增强VLA模型的泛化能力。分析表明，采用适当比例的SRP数据进行子任务特定训练可以成为机器人操作性能的催化剂，最大化昂贵的物理交互阶段（PIP）数据的利用。实验结果显示，通过在有限的PIP数据集中引入大量成本效益高的SRP轨迹，可以在零样本场景中将成功率最高提高41%，同时具备将操作技能转移至新目标的能力。', 'title_zh': 'DataPlatter: 以最小代价数据提升机器人 manipulate 通用性'}
{'arxiv_id': 'arXiv:2503.19510', 'title': 'RoboFlamingo-Plus: Fusion of Depth and RGB Perception with Vision-Language Models for Enhanced Robotic Manipulation', 'authors': 'Sheng Wang', 'link': 'https://arxiv.org/abs/2503.19510', 'abstract': 'As robotic technologies advancing towards more complex multimodal interactions and manipulation tasks, the integration of advanced Vision-Language Models (VLMs) has become a key driver in the field. Despite progress with current methods, challenges persist in fusing depth and RGB information within 3D environments and executing tasks guided by linguistic instructions. In response to these challenges, we have enhanced the existing RoboFlamingo framework by introducing RoboFlamingo-Plus, which incorporates depth data into VLMs to significantly improve robotic manipulation performance. Our research achieves a nuanced fusion of RGB and depth information by integrating a pre-trained Vision Transformer (ViT) with a resampling technique, closely aligning this combined data with linguistic cues for superior multimodal understanding. The novelty of RoboFlamingo-Plus lies in its adaptation of inputs for depth data processing, leveraging a pre-trained resampler for depth feature extraction, and employing cross-attention mechanisms for optimal feature integration. These improvements allow RoboFlamingo-Plus to not only deeply understand 3D environments but also easily perform complex, language-guided tasks in challenging settings. Experimental results show that RoboFlamingo-Plus boosts robotic manipulation by 10-20% over current methods, marking a significant advancement. Codes and model weights are public at RoboFlamingo-Plus.', 'abstract_zh': '随着机器人技术向更复杂的多模态交互和操作任务发展，先进的视觉-语言模型（VLMs）的集成已成为该领域的关键驱动力。尽管现有方法取得了进展，但在3D环境中融合深度和RGB信息以及执行基于语言指令的任务仍面临挑战。为应对这些挑战，我们通过引入RoboFlamingo-Plus框架，将深度数据整合到VLMs中，显著提高了机器人的操作性能。我们的研究通过将预训练的视觉变换器（ViT）与重采样技术相结合，实现了RGB和深度信息的细腻融合，使结合的数据能够更紧密地与语言提示对齐，从而实现更强的多模态理解。RoboFlamingo-Plus的创新之处在于其对深度数据处理输入的适应性，利用预训练的重采样器进行深度特征提取，并采用交叉注意力机制进行最优特征整合。这些改进使RoboFlamingo-Plus不仅能够深入理解3D环境，还能在具有挑战性的环境中轻松执行复杂、基于语言的任务。实验结果表明，RoboFlamingo-Plus相较于现有方法在机器人操作性能上提高了10-20%，标志着一个重要的进步。RoboFlamingo-Plus的代码和模型权重已公开。', 'title_zh': 'RoboFlamingo-Plus：融合深度和RGB感知的视觉语言模型在增强机器人操作中的应用'}
{'arxiv_id': 'arXiv:2503.19506', 'title': 'MM-LINS: a Multi-Map LiDAR-Inertial System for Over-Degenerate Environments', 'authors': 'Yongxin Ma, Jie Xu, Shenghai Yuan, Tian Zhi, Wenlu Yu, Jun Zhou, Lihua Xie', 'link': 'https://arxiv.org/abs/2503.19506', 'abstract': 'SLAM plays a crucial role in automation tasks, such as warehouse logistics, healthcare robotics, and restaurant delivery. These scenes come with various challenges, including navigating around crowds of people, dealing with flying plastic bags that can temporarily blind sensors, and addressing reduced LiDAR density caused by cooking smoke. Such scenarios can result in over-degeneracy, causing the map to drift. To address this issue, this paper presents a multi-map LiDAR-inertial system (MM-LINS) for the first time. The front-end employs an iterated error state Kalman filter for state estimation and introduces a reliable evaluation strategy for degeneracy detection. If over-degeneracy is detected, the active map will be stored into sleeping maps. Subsequently, the system continuously attempts to construct new maps using a dynamic initialization method to ensure successful initialization upon leaving the over-degeneracy. Regarding the back-end, the Scan Context descriptor is utilized to detect inter-map similarity. Upon successful recognition of a sleeping map that shares a common region with the active map, the overlapping trajectory region is utilized to constrain the positional transformation near the edge of the prior map. In response to this, a constraint-enhanced map fusion strategy is proposed to achieve high-precision positional and mapping results. Experiments have been conducted separately on both public datasets that exhibited over-degenerate conditions and in real-world environments. These tests demonstrated the effectiveness of MM-LINS in over-degeneracy environment. Our codes are open-sourced on Github.', 'abstract_zh': 'SLAM在自动化任务中的多地图激光雷达-惯性系统在过退化环境中的应用', 'title_zh': 'MM-LINS：多地图激光雷达-惯性系统用于过度退化环境'}
{'arxiv_id': 'arXiv:2503.19397', 'title': 'Quality-focused Active Adversarial Policy for Safe Grasping in Human-Robot Interaction', 'authors': 'Chenghao Li, Razvan Beuran, Nak Young Chong', 'link': 'https://arxiv.org/abs/2503.19397', 'abstract': 'Vision-guided robot grasping methods based on Deep Neural Networks (DNNs) have achieved remarkable success in handling unknown objects, attributable to their powerful generalizability. However, these methods with this generalizability tend to recognize the human hand and its adjacent objects as graspable targets, compromising safety during Human-Robot Interaction (HRI). In this work, we propose the Quality-focused Active Adversarial Policy (QFAAP) to solve this problem. Specifically, the first part is the Adversarial Quality Patch (AQP), wherein we design the adversarial quality patch loss and leverage the grasp dataset to optimize a patch with high quality scores. Next, we construct the Projected Quality Gradient Descent (PQGD) and integrate it with the AQP, which contains only the hand region within each real-time frame, endowing the AQP with fast adaptability to the human hand shape. Through AQP and PQGD, the hand can be actively adversarial with the surrounding objects, lowering their quality scores. Therefore, further setting the quality score of the hand to zero will reduce the grasping priority of both the hand and its adjacent objects, enabling the robot to grasp other objects away from the hand without emergency stops. We conduct extensive experiments on the benchmark datasets and a cobot, showing the effectiveness of QFAAP. Our code and demo videos are available here: this https URL.', 'abstract_zh': '基于深度神经网络的视觉引导机器人抓取方法在处理未知物体方面取得了显著成功，归因于其强大的泛化能力。然而，具有这种泛化能力的方法倾向于将人类手及其相邻物体识别为可抓取目标，这在人机交互（HRI）中损害了安全性。在本文中，我们提出了一种质量导向的主动对抗策略（QFAAP）来解决这一问题。具体而言，首先介绍了对抗质量补丁（AQP），我们设计了对抗质量补丁损失，并利用抓取数据集优化高质量得分的补丁。其次，构建了投影质量梯度下降（PQGD），并与AQP集成，AQP仅包含每个实时帧内的手区域，使AQP具备快速适应手部形状的能力。通过AQP和PQGD，手可以主动与周围物体进行对抗，降低它们的质量得分。因此，进一步将手的质量得分设置为零，将降低对手及其相邻物体的抓取优先级，使机器人能够在无需紧急停止的情况下抓取远离手的其他物体。我们在基准数据集和协作机器人上进行了广泛实验，展示了QFAAP的有效性。我们的代码和演示视频可在以下链接获取：this https URL。', 'title_zh': '面向质量的主动对抗策略以实现人机交互中的安全抓取'}
{'arxiv_id': 'arXiv:2503.19317', 'title': 'Towards Uncertainty Unification: A Case Study for Preference Learning', 'authors': 'Shaoting Peng, Haonan Chen, Katherine Driggs-Campbell', 'link': 'https://arxiv.org/abs/2503.19317', 'abstract': 'Learning human preferences is essential for human-robot interaction, as it enables robots to adapt their behaviors to align with human expectations and goals. However, the inherent uncertainties in both human behavior and robotic systems make preference learning a challenging task. While probabilistic robotics algorithms offer uncertainty quantification, the integration of human preference uncertainty remains underexplored. To bridge this gap, we introduce uncertainty unification and propose a novel framework, uncertainty-unified preference learning (UUPL), which enhances Gaussian Process (GP)-based preference learning by unifying human and robot uncertainties. Specifically, UUPL includes a human preference uncertainty model that improves GP posterior mean estimation, and an uncertainty-weighted Gaussian Mixture Model (GMM) that enhances GP predictive variance accuracy. Additionally, we design a user-specific calibration process to align uncertainty representations across users, ensuring consistency and reliability in the model performance. Comprehensive experiments and user studies demonstrate that UUPL achieves state-of-the-art performance in both prediction accuracy and user rating. An ablation study further validates the effectiveness of human uncertainty model and uncertainty-weighted GMM of UUPL.', 'abstract_zh': '学习人类偏好对于人机交互至关重要，因为它使机器人能够根据人类的期望和目标调整其行为。然而，人类行为和机器人系统的固有不确定性使得偏好学习成为一个具有挑战性的任务。虽然概率机器人算法可以提供不确定性量化，但人类偏好不确定性与机器人系统的集成仍处于探索阶段。为了弥补这一差距，我们提出了不确定性统一的方法，并提出了一种新颖的框架——不确定性统一的偏好学习（UUPL），该框架通过统一人类和机器人的不确定性来增强基于高斯过程（GP）的偏好学习。具体而言，UUPL 包括一个改进 GP 后验均值估计的人类偏好不确定性模型，以及一个增强 GP 预测方差准确性的加权高斯混合模型（GMM）。此外，我们设计了一个用户特定的校准过程，以确保不同用户之间的不确定性表示一致性，从而保证模型性能的可靠性和一致性。全面的实验和用户研究证明，UUPL 在预测准确性和用户评分方面均达到了目前的最佳性能。进一步的消融研究还验证了人类不确定性模型和 UUPL 的加权 GMM 的有效性。', 'title_zh': '向不确定性统一迈进：一种偏好学习的案例研究'}
{'arxiv_id': 'arXiv:2503.19288', 'title': 'A Novel Underwater Vehicle With Orientation Adjustable Thrusters: Design and Adaptive Tracking Control', 'authors': 'Yifei Wang, Shihan Kong, Zhanhua Xin, Kaiwei Zhu, Dongyue Li, Junzhi Yu', 'link': 'https://arxiv.org/abs/2503.19288', 'abstract': "Autonomous underwater vehicles (AUVs) are essential for marine exploration and research. However, conventional designs often struggle with limited maneuverability in complex, dynamic underwater environments. This paper introduces an innovative orientation-adjustable thruster AUV (OATAUV), equipped with a redundant vector thruster configuration that enables full six-degree-of-freedom (6-DOF) motion and composite maneuvers. To overcome challenges associated with uncertain model parameters and environmental disturbances, a novel feedforward adaptive model predictive controller (FFAMPC) is proposed to ensure robust trajectory tracking, which integrates real-time state feedback with adaptive parameter updates. Extensive experiments, including closed-loop tracking and composite motion tests in a laboratory pool, validate the enhanced performance of the OAT-AUV. The results demonstrate that the OAT-AUV's redundant vector thruster configuration enables 23.8% cost reduction relative to common vehicles, while the FF-AMPC controller achieves 68.6% trajectory tracking improvement compared to PID controllers. Uniquely, the system executes composite helical/spiral trajectories unattainable by similar vehicles.", 'abstract_zh': '自主水下机器人（OATAUV）及其前馈自适应模型预测控制（FFAMPC）技术的研究', 'title_zh': '一种具有可调方向推进器的新型水下车辆：设计与自适应跟踪控制'}
{'arxiv_id': 'arXiv:2503.19281', 'title': "CubeRobot: Grounding Language in Rubik's Cube Manipulation via Vision-Language Model", 'authors': 'Feiyang Wang, Xiaomin Yu, Wangyu Wu', 'link': 'https://arxiv.org/abs/2503.19281', 'abstract': "Proving Rubik's Cube theorems at the high level represents a notable milestone in human-level spatial imagination and logic thinking and reasoning. Traditional Rubik's Cube robots, relying on complex vision systems and fixed algorithms, often struggle to adapt to complex and dynamic scenarios. To overcome this limitation, we introduce CubeRobot, a novel vision-language model (VLM) tailored for solving 3x3 Rubik's Cubes, empowering embodied agents with multimodal understanding and execution capabilities. We used the CubeCoT image dataset, which contains multiple-level tasks (43 subtasks in total) that humans are unable to handle, encompassing various cube states. We incorporate a dual-loop VisionCoT architecture and Memory Stream, a paradigm for extracting task-related features from VLM-generated planning queries, thus enabling CubeRobot to independent planning, decision-making, reflection and separate management of high- and low-level Rubik's Cube tasks. Furthermore, in low-level Rubik's Cube restoration tasks, CubeRobot achieved a high accuracy rate of 100%, similar to 100% in medium-level tasks, and achieved an accuracy rate of 80% in high-level tasks.", 'abstract_zh': '在高层次上证明鲁比克立方体定理代表了人类空间想象和逻辑思维与推理的一个显著里程碑。CubeRobot：一种用于解决3x3鲁比克立方体的新型视觉-语言模型，赋予具身代理多模态理解和执行能力。', 'title_zh': 'CubeRobot: 通过视觉语言模型在鲁比克立方体操作中 grounding 语言'}
{'arxiv_id': 'arXiv:2503.19225', 'title': 'CoinFT: A Coin-Sized, Capacitive 6-Axis Force Torque Sensor for Robotic Applications', 'authors': 'Hojung Choi, Jun En Low, Tae Myung Huh, Gabriela A. Uribe, Seongheon Hong, Kenneth A. W. Hoffman, Julia Di, Tony G. Chen, Andrew A. Stanley, Mark R. Cutkosky', 'link': 'https://arxiv.org/abs/2503.19225', 'abstract': 'We introduce CoinFT, a capacitive 6-axis force/torque (F/T) sensor that is compact, light, low-cost, and robust with an average mean-squared error of 0.11N for force and 0.84mNm for moment when the input ranges from 0~10N and 0~4N in normal and shear directions, respectively. CoinFT is a stack of two rigid PCBs with comb-shaped electrodes connected by an array of silicone rubber pillars. The microcontroller interrogates the electrodes in different subsets in order to enhance sensitivity for measuring 6-axis F/T. The combination of desirable features of CoinFT enables various contact-rich robot interactions at a scale, across different embodiment domains including drones, robot end-effectors, and wearable haptic devices. We demonstrate the utility of CoinFT on drones by performing an attitude-based force control to perform tasks that require careful contact force modulation. The design, fabrication, and firmware of CoinFT are open-sourced at this https URL.', 'abstract_zh': '我们介绍了一种紧凑、轻便、低成本且坚固的六轴力/ torque (F/T) 传感器CoinFT，其平均均方误差分别为力0.11N和力矩0.84mNm，输入范围分别为0~10N和0~4N在正常和切向方向上。CoinFT由两层刚性PCB组成，其中带有梳状电极并通过硅橡胶柱阵列相互连接。微控制器通过在不同子集的电极之间进行询问以增强六轴力/ torque 测量的灵敏度。CoinFT的多项优点使其能够在无人机、机器人末端执行器和可穿戴触觉设备等不同领域实现各种接触丰富的机器人交互。我们通过执行基于姿态的力控制来演示CoinFT的功能，以执行需要精细力调节的任务。CoinFT的设计、制作和固件已在以下网址开源：https://github.com/alibaba/CoinFT。', 'title_zh': 'CoinFT：一种适用于机器人应用的硬币大小的电容式6轴力矩传感器'}
{'arxiv_id': 'arXiv:2503.19171', 'title': 'Contact-based Grasp Control and Inverse Kinematics for a Five-fingered Robotic Hand', 'authors': 'Robinson Umeike', 'link': 'https://arxiv.org/abs/2503.19171', 'abstract': 'This paper presents an implementation and analysis of a five-fingered robotic grasping system that combines contact-based control with inverse kinematics solutions. Using the PyBullet simulation environment and the DexHand v2 model, we demonstrate a comprehensive approach to achieving stable grasps through contact point optimization with force closure validation. Our method achieves movement efficiency ratings between 0.966-0.996 for non-thumb fingers and 0.879 for the thumb, while maintaining positional accuracy within 0.0267-0.0283m for non-thumb digits and 0.0519m for the thumb. The system demonstrates rapid position stabilization at 240Hz simulation frequency and maintains stable contact configurations throughout the grasp execution. Experimental results validate the effectiveness of our approach, while also identifying areas for future enhancement in thumb opposition movements and horizontal plane control.', 'abstract_zh': '基于接触控制与逆kinematics解耦的五指机器人抓取系统实现与分析', 'title_zh': '基于接触的五指灵巧手抓取控制与逆运动学研究'}
{'arxiv_id': 'arXiv:2503.19140', 'title': "Dom, cars don't fly! -- Or do they? In-Air Vehicle Maneuver for High-Speed Off-Road Navigation", 'authors': 'Anuj Pokhrel, Aniket Datar, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.19140', 'abstract': 'When pushing the speed limit for aggressive off-road navigation on uneven terrain, it is inevitable that vehicles may become airborne from time to time. During time-sensitive tasks, being able to fly over challenging terrain can also save time, instead of cautiously circumventing or slowly negotiating through. However, most off-road autonomy systems operate under the assumption that the vehicles are always on the ground and therefore limit operational speed. In this paper, we present a novel approach for in-air vehicle maneuver during high-speed off-road navigation. Based on a hybrid forward kinodynamic model using both physics principles and machine learning, our fixed-horizon, sampling-based motion planner ensures accurate vehicle landing poses and their derivatives within a short airborne time window using vehicle throttle and steering commands. We test our approach in extensive in-air experiments both indoors and outdoors, compare it against an error-driven control method, and demonstrate that precise and timely in-air vehicle maneuver is possible through existing ground vehicle controls.', 'abstract_zh': '高速非结构化 terrain 机动飞行的新型方法', 'title_zh': '_dom, 车辆不会飞！_ 或者它们会？空中车辆机动在高速离线导航中的应用_'}
{'arxiv_id': 'arXiv:2503.19135', 'title': 'Cooperative Control of Multi-Quadrotors for Transporting Cable-Suspended Payloads: Obstacle-Aware Planning and Event-Based Nonlinear Model Predictive Control', 'authors': 'Tohid Kargar Tasooji, Sakineh Khodadadi, Guangjun Liu, Richard Wang', 'link': 'https://arxiv.org/abs/2503.19135', 'abstract': 'This paper introduces a novel methodology for the cooperative control of multiple quadrotors transporting cablesuspended payloads, emphasizing obstacle-aware planning and event-based Nonlinear Model Predictive Control (NMPC). Our approach integrates trajectory planning with real-time control through a combination of the A* algorithm for global path planning and NMPC for local control, enhancing trajectory adaptability and obstacle avoidance. We propose an advanced event-triggered control system that updates based on events identified through dynamically generated environmental maps. These maps are constructed using a dual-camera setup, which includes multi-camera systems for static obstacle detection and event cameras for high-resolution, low-latency detection of dynamic obstacles. This design is crucial for addressing fast-moving and transient obstacles that conventional cameras may overlook, particularly in environments with rapid motion and variable lighting conditions. When new obstacles are detected, the A* algorithm recalculates waypoints based on the updated map, ensuring safe and efficient navigation. This real-time obstacle detection and map updating integration allows the system to adaptively respond to environmental changes, markedly improving safety and navigation efficiency. The system employs SLAM and object detection techniques utilizing data from multi-cameras, event cameras, and IMUs for accurate localization and comprehensive environmental mapping. The NMPC framework adeptly manages the complex dynamics of multiple quadrotors and suspended payloads, incorporating safety constraints to maintain dynamic feasibility and stability. Extensive simulations validate the proposed approach, demonstrating significant enhancements in energy efficiency, computational resource management, and responsiveness.', 'abstract_zh': '一种多旋翼运输悬挂载荷的协同控制新方法：基于障碍aware的计划和事件驱动非线性模型预测控制', 'title_zh': '多旋翼协同控制运输电缆悬吊载荷：基于障碍物感知的事件触发非线性模型预测控制'}
{'arxiv_id': 'arXiv:2503.19916', 'title': 'EventFly: Event Camera Perception from Ground to the Sky', 'authors': 'Lingdong Kong, Dongyue Lu, Xiang Xu, Lai Xing Ng, Wei Tsang Ooi, Benoit R. Cottereau', 'link': 'https://arxiv.org/abs/2503.19916', 'abstract': 'Cross-platform adaptation in event-based dense perception is crucial for deploying event cameras across diverse settings, such as vehicles, drones, and quadrupeds, each with unique motion dynamics, viewpoints, and class distributions. In this work, we introduce EventFly, a framework for robust cross-platform adaptation in event camera perception. Our approach comprises three key components: i) Event Activation Prior (EAP), which identifies high-activation regions in the target domain to minimize prediction entropy, fostering confident, domain-adaptive predictions; ii) EventBlend, a data-mixing strategy that integrates source and target event voxel grids based on EAP-driven similarity and density maps, enhancing feature alignment; and iii) EventMatch, a dual-discriminator technique that aligns features from source, target, and blended domains for better domain-invariant learning. To holistically assess cross-platform adaptation abilities, we introduce EXPo, a large-scale benchmark with diverse samples across vehicle, drone, and quadruped platforms. Extensive experiments validate our effectiveness, demonstrating substantial gains over popular adaptation methods. We hope this work can pave the way for more adaptive, high-performing event perception across diverse and complex environments.', 'abstract_zh': '跨平台适应性在基于事件的密集感知中的实现对于在车辆、无人机和四足动物等具有独特运动动力学、视角和类别分布的不同场景中部署事件相机至关重要。我们提出EventFly框架，用于事件相机感知的鲁棒跨平台适应。该框架包括三个关键组件：事件激活先验（EAP）、事件融合（EventBlend）和事件匹配（EventMatch）。我们通过引入EXPo基准测试，包含车辆、无人机和四足动物平台上的多样化样本，全面评估跨平台适应性能力。实验结果验证了该方法的有效性，显著优于流行的方法。我们希望这项工作能够为在复杂多变环境中实现更加适应性和高性能的事件感知铺平道路。', 'title_zh': 'EventFly: 地面到天空的事件相机感知'}
{'arxiv_id': 'arXiv:2503.19912', 'title': 'SuperFlow++: Enhanced Spatiotemporal Consistency for Cross-Modal Data Pretraining', 'authors': 'Xiang Xu, Lingdong Kong, Hui Shuai, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Qingshan Liu', 'link': 'https://arxiv.org/abs/2503.19912', 'abstract': 'LiDAR representation learning has emerged as a promising approach to reducing reliance on costly and labor-intensive human annotations. While existing methods primarily focus on spatial alignment between LiDAR and camera sensors, they often overlook the temporal dynamics critical for capturing motion and scene continuity in driving scenarios. To address this limitation, we propose SuperFlow++, a novel framework that integrates spatiotemporal cues in both pretraining and downstream tasks using consecutive LiDAR-camera pairs. SuperFlow++ introduces four key components: (1) a view consistency alignment module to unify semantic information across camera views, (2) a dense-to-sparse consistency regularization mechanism to enhance feature robustness across varying point cloud densities, (3) a flow-based contrastive learning approach that models temporal relationships for improved scene understanding, and (4) a temporal voting strategy that propagates semantic information across LiDAR scans to improve prediction consistency. Extensive evaluations on 11 heterogeneous LiDAR datasets demonstrate that SuperFlow++ outperforms state-of-the-art methods across diverse tasks and driving conditions. Furthermore, by scaling both 2D and 3D backbones during pretraining, we uncover emergent properties that provide deeper insights into developing scalable 3D foundation models. With strong generalizability and computational efficiency, SuperFlow++ establishes a new benchmark for data-efficient LiDAR-based perception in autonomous driving. The code is publicly available at this https URL', 'abstract_zh': '基于LiDAR的时空特征学习：SuperFlow++在自动驾驶中的应用', 'title_zh': 'SuperFlow++: 提升跨模态数据预训练的时空一致性'}
{'arxiv_id': 'arXiv:2503.19889', 'title': 'A Multi-Agent Framework Integrating Large Language Models and Generative AI for Accelerated Metamaterial Design', 'authors': 'Jie Tian, Martin Taylor Sobczak, Dhanush Patil, Jixin Hou, Lin Pang, Arunachalam Ramanathan, Libin Yang, Xianyan Chen, Yuval Golan, Hongyue Sun, Kenan Song, Xianqiao Wang', 'link': 'https://arxiv.org/abs/2503.19889', 'abstract': "Metamaterials, renowned for their exceptional mechanical, electromagnetic, and thermal properties, hold transformative potential across diverse applications, yet their design remains constrained by labor-intensive trial-and-error methods and limited data interoperability. Here, we introduce CrossMatAgent--a novel multi-agent framework that synergistically integrates large language models with state-of-the-art generative AI to revolutionize metamaterial design. By orchestrating a hierarchical team of agents--each specializing in tasks such as pattern analysis, architectural synthesis, prompt engineering, and supervisory feedback--our system leverages the multimodal reasoning of GPT-4o alongside the generative precision of DALL-E 3 and a fine-tuned Stable Diffusion XL model. This integrated approach automates data augmentation, enhances design fidelity, and produces simulation- and 3D printing-ready metamaterial patterns. Comprehensive evaluations, including CLIP-based alignment, SHAP interpretability analyses, and mechanical simulations under varied load conditions, demonstrate the framework's ability to generate diverse, reproducible, and application-ready designs. CrossMatAgent thus establishes a scalable, AI-driven paradigm that bridges the gap between conceptual innovation and practical realization, paving the way for accelerated metamaterial development.", 'abstract_zh': '超材料，凭借其卓越的机械、电磁和热学性能，在多个应用领域具有变革潜力，但其设计仍受限于劳动密集型的试错方法和数据互联互通的限制。为此，我们引入了CrossMatAgent——一种新颖的多智能体框架，将大规模语言模型与最先进的生成AI协同整合，以革命性地变革超材料设计。通过协调一个分层团队的智能体——每个智能体专注于如模式分析、建筑合成、提示工程和监督反馈等任务，我们的系统利用GPT-4o的多模态推理能力，结合DALL-E 3的生成精确性和微调后的Stable Diffusion XL模型的精准生成。这种集成方法实现了数据增强的自动化、提升了设计保真度，并生成了适用于模拟和3D打印的超材料模式。全面的评估，包括基于CLIP的对齐、SHAP可解释性分析和在不同载荷条件下的力学模拟，表明该框架能够生成多样、可复现且适用于实际应用的设计。CrossMatAgent因此建立了一种可扩展、AI驱动的范式，填补了概念创新与实际实现之间的差距，为加速超材料开发铺平了道路。', 'title_zh': '一种集成大型语言模型和生成式AI的多Agent框架加速 metamaterial 设计'}
{'arxiv_id': 'arXiv:2503.19764', 'title': 'OpenLex3D: A New Evaluation Benchmark for Open-Vocabulary 3D Scene Representations', 'authors': 'Christina Kassab, Sacha Morin, Martin Büchner, Matías Mattamala, Kumaraditya Gupta, Abhinav Valada, Liam Paull, Maurice Fallon', 'link': 'https://arxiv.org/abs/2503.19764', 'abstract': '3D scene understanding has been transformed by open-vocabulary language models that enable interaction via natural language. However, the evaluation of these representations is limited to closed-set semantics that do not capture the richness of language. This work presents OpenLex3D, a dedicated benchmark to evaluate 3D open-vocabulary scene representations. OpenLex3D provides entirely new label annotations for 23 scenes from Replica, ScanNet++, and HM3D, which capture real-world linguistic variability by introducing synonymical object categories and additional nuanced descriptions. By introducing an open-set 3D semantic segmentation task and an object retrieval task, we provide insights on feature precision, segmentation, and downstream capabilities. We evaluate various existing 3D open-vocabulary methods on OpenLex3D, showcasing failure cases, and avenues for improvement. The benchmark is publicly available at: this https URL.', 'abstract_zh': '3D场景理解通过开放词汇语言模型得到革新，这些模型能够通过自然语言进行交互。然而，这些表示的评估局限于封闭集语义，不能充分捕捉语言的丰富性。本工作提出OpenLex3D，一个专门用于评估3D开放词汇场景表示的基准。OpenLex3D为来自Replica、ScanNet++和HM3D的23个场景提供了全新的标签注释，通过引入同义对象类别和额外的细微描述，捕捉现实世界中的语言变异性。通过引入开放集3D语义分割任务和对象检索任务，我们提供了关于特征精度、分割及下游能力的见解。我们对OpenLex3D上各种现有的3D开放词汇方法进行了评估，展示了失败案例及改进方向。基准已公开发布于：this https URL。', 'title_zh': 'OpenLex3D：一种新的开放词汇3D场景表示评价基准'}
{'arxiv_id': 'arXiv:2503.19692', 'title': 'Leveraging Cognitive States for Adaptive Scaffolding of Understanding in Explanatory Tasks in HRI', 'authors': 'André Groß, Birte Richter, Bjarne Thomzik, Britta Wrede', 'link': 'https://arxiv.org/abs/2503.19692', 'abstract': "Understanding how scaffolding strategies influence human understanding in human-robot interaction is important for developing effective assistive systems. This empirical study investigates linguistic scaffolding strategies based on negation as an important means that de-biases the user from potential errors but increases processing costs and hesitations as a means to ameliorate processing costs. In an adaptive strategy, the user state with respect to the current state of understanding and processing capacity was estimated via a scoring scheme based on task performance, prior scaffolding strategy, and current eye gaze behavior. In the study, the adaptive strategy of providing negations and hesitations was compared with a non-adaptive strategy of providing only affirmations. The adaptive scaffolding strategy was generated using the computational model SHIFT. Our findings indicate that using adaptive scaffolding strategies with SHIFT tends to (1) increased processing costs, as reflected in longer reaction times, but (2) improved task understanding, evidenced by a lower error rate of almost 23%. We assessed the efficiency of SHIFT's selected scaffolding strategies across different cognitive states, finding that in three out of five states, the error rate was lower compared to the baseline condition. We discuss how these results align with the assumptions of the SHIFT model and highlight areas for refinement. Moreover, we demonstrate how scaffolding strategies, such as negation and hesitation, contribute to more effective human-robot explanatory dialogues.", 'abstract_zh': '理解支撑策略如何影响人类在人机交互中的理解对于开发有效的辅助系统至关重要。本实证研究探讨了基于否定的语文支撑策略，这种策略可以减轻用户的潜在错误但会增加处理成本和犹豫，以缓解处理成本。在自适应策略中，通过基于任务性能、先前支撑策略和当前眼球运动的评分方案估计用户状态与当前理解状态和处理能力的关系。研究中，自适应策略（提供否定和犹豫）与仅提供肯定的非自适应策略进行了比较。自适应支撑策略是使用计算模型SHIFT生成的。我们的研究结果表明，使用SHIFT的自适应支撑策略倾向于（1）增加处理成本，反映在反应时间更长上，但（2）提高任务理解度，错误率降低约23%。我们评估了SHIFT所选支撑策略在不同认知状态下的效率，发现有三种状态下的错误率低于基线条件。我们讨论了这些结果如何与SHIFT模型的假设一致，并指出了改进的领域。此外，我们展示了支撑策略，如否定和犹豫，如何有助于更有效的机器人解释对话。', 'title_zh': '利用认知状态为人机交互中解释任务的理解提供适应性支架'}
{'arxiv_id': 'arXiv:2503.19457', 'title': 'G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation', 'authors': 'Juntao Jian, Xiuping Liu, Zixuan Chen, Manyi Li, Jian Liu, Ruizhen Hu', 'link': 'https://arxiv.org/abs/2503.19457', 'abstract': 'Recent advances in dexterous grasping synthesis have demonstrated significant progress in producing reasonable and plausible grasps for many task purposes. But it remains challenging to generalize to unseen object categories and diverse task instructions. In this paper, we propose G-DexGrasp, a retrieval-augmented generation approach that can produce high-quality dexterous hand configurations for unseen object categories and language-based task instructions. The key is to retrieve generalizable grasping priors, including the fine-grained contact part and the affordance-related distribution of relevant grasping instances, for the following synthesis pipeline. Specifically, the fine-grained contact part and affordance act as generalizable guidance to infer reasonable grasping configurations for unseen objects with a generative model, while the relevant grasping distribution plays as regularization to guarantee the plausibility of synthesized grasps during the subsequent refinement optimization. Our comparison experiments validate the effectiveness of our key designs for generalization and demonstrate the remarkable performance against the existing approaches. Project page: this https URL', 'abstract_zh': '最近在灵巧抓取合成方面的重要进展已经在许多任务目标中展示了生成合理且可信抓取方式的显著进步。但将其泛化到未见物体类别和多样化的任务指令仍然具有挑战性。本文提出了一种检索增强生成方法G-DexGrasp，能够在未见物体类别和基于语言的任务指令下生成高质量的灵巧手部配置。关键在于检索可泛化的抓取先验，包括精细的接触部分和与相关抓取实例相关的功能性分布，用于后续合成管道。具体而言，精细的接触部分和功能性作为可泛化的指导，通过生成模型推断未见物体的合理抓取配置，而相关抓取分布则作为正则化手段，确保生成抓取的可信性。我们的比较实验验证了我们关键设计的有效性，并展示了其相对于现有方法的出色性能。项目页面：this https URL', 'title_zh': 'G-DexGrasp: 基于部件意识先验检索与先验辅助生成的可泛化灵巧抓取合成'}
{'arxiv_id': 'arXiv:2503.19330', 'title': 'MATT-GS: Masked Attention-based 3DGS for Robot Perception and Object Detection', 'authors': 'Jee Won Lee, Hansol Lim, SooYeun Yang, Jongseong Brad Choi', 'link': 'https://arxiv.org/abs/2503.19330', 'abstract': 'This paper presents a novel masked attention-based 3D Gaussian Splatting (3DGS) approach to enhance robotic perception and object detection in industrial and smart factory environments. U2-Net is employed for background removal to isolate target objects from raw images, thereby minimizing clutter and ensuring that the model processes only relevant data. Additionally, a Sobel filter-based attention mechanism is integrated into the 3DGS framework to enhance fine details - capturing critical features such as screws, wires, and intricate textures essential for high-precision tasks. We validate our approach using quantitative metrics, including L1 loss, SSIM, PSNR, comparing the performance of the background-removed and attention-incorporated 3DGS model against the ground truth images and the original 3DGS training baseline. The results demonstrate significant improves in visual fidelity and detail preservation, highlighting the effectiveness of our method in enhancing robotic vision for object recognition and manipulation in complex industrial settings.', 'abstract_zh': '本文提出了一种新颖的掩码注意力机制下的3D高斯点云（3DGS）方法，以增强工业和智能工厂环境中的机器人感知和物体检测。U2-Net用于背景去除，以隔离目标物体，从而减少杂乱并确保模型仅处理相关信息。此外，基于Sobel滤波器的注意力机制被集成到3DGS框架中，以增强细节点的提取，捕获诸如螺钉、电线和复杂纹理等关键特征，这对于高精度任务至关重要。我们通过使用L1损失、SSIM和PSNR等定量指标来验证该方法，并将去背景处理和注意力机制结合的3DGS模型的性能与真实图像和原始3DGS训练基线进行比较。结果表明，该方法在视觉保真度和细节保留方面有显著改善，突显了其在复杂工业环境中增强机器人视觉以进行物体识别和操纵的有效性。', 'title_zh': 'MATT-GS：基于掩码注意力的3DGS机器人感知与物体检测'}
{'arxiv_id': 'arXiv:2503.19302', 'title': 'Observation Adaptation via Annealed Importance Resampling for Partially Observable Markov Decision Processes', 'authors': 'Yunuo Zhang, Baiting Luo, Ayan Mukhopadhyay, Abhishek Dubey', 'link': 'https://arxiv.org/abs/2503.19302', 'abstract': 'Partially observable Markov decision processes (POMDPs) are a general mathematical model for sequential decision-making in stochastic environments under state uncertainty. POMDPs are often solved \\textit{online}, which enables the algorithm to adapt to new information in real time. Online solvers typically use bootstrap particle filters based on importance resampling for updating the belief distribution. Since directly sampling from the ideal state distribution given the latest observation and previous state is infeasible, particle filters approximate the posterior belief distribution by propagating states and adjusting weights through prediction and resampling steps. However, in practice, the importance resampling technique often leads to particle degeneracy and sample impoverishment when the state transition model poorly aligns with the posterior belief distribution, especially when the received observation is highly informative. We propose an approach that constructs a sequence of bridge distributions between the state-transition and optimal distributions through iterative Monte Carlo steps, better accommodating noisy observations in online POMDP solvers. Our algorithm demonstrates significantly superior performance compared to state-of-the-art methods when evaluated across multiple challenging POMDP domains.', 'abstract_zh': '部分可观测马尔可夫决策过程（POMDPs）是用于在状态不确定性下的随机环境中进行序贯决策的一种一般数学模型。POMDPs通常在线求解，使算法能够实时适应新信息。在线求解器通常使用基于重要性重采样的粒子滤波进行信念分布更新。由于直接从最新观察和先前状态的理想状态分布中采样是不可行的，粒子滤波通过预测和重采样步骤传播状态并调整权重来近似后验信念分布。然而，在实践中，当状态转换模型与后验信念分布严重不匹配，尤其是当接收到的观察非常高信息量时，重要性重采样技术往往会引发粒子退化和样本贫化。我们提出了一种方法，通过迭代的蒙特卡洛步骤构建状态转换分布和最佳分布之间的桥梁分布序列，更好地适应在线POMDP求解器中的噪声观察。我们的算法在多个具有挑战性的POMDP领域评估中表现出明显优于当前最佳方法的性能。', 'title_zh': '部分可观测马尔可夫决策过程的 annealed 固化重要性抽样自适应观测方法'}
{'arxiv_id': 'arXiv:2503.19200', 'title': 'Optimal Modified Feedback Strategies in LQ Games under Control Imperfections', 'authors': 'Mahdis Rabbani, Navid Mojahed, Shima Nazari', 'link': 'https://arxiv.org/abs/2503.19200', 'abstract': "Game-theoretic approaches and Nash equilibrium have been widely applied across various engineering domains. However, practical challenges such as disturbances, delays, and actuator limitations can hinder the precise execution of Nash equilibrium strategies. This work explores the impact of such implementation imperfections on game trajectories and players' costs within the context of a two-player linear quadratic (LQ) nonzero-sum game. Specifically, we analyze how small deviations by one player affect the state and cost function of the other player. To address these deviations, we propose an adjusted control policy that not only mitigates adverse effects optimally but can also exploit the deviations to enhance performance. Rigorous mathematical analysis and proofs are presented, demonstrating through a representative example that the proposed policy modification achieves up to $61\\%$ improvement compared to the unadjusted feedback policy and up to $0.59\\%$ compared to the feedback Nash strategy.", 'abstract_zh': '博弈论方法和纳什均衡在各类工程领域中广泛应用。然而，诸如扰动、延迟和执行器限制等实际挑战可能阻碍纳什均衡策略的精确执行。本文探讨了这些实施缺陷对两人线性二次（LQ）非零和博弈的游戏轨迹及其参与者的成本的影响。具体而言，我们分析了一方的小幅偏差如何影响另一方的状态和成本函数。为应对这些偏差，我们提出了一种调整控制策略，不仅能够最优地减轻不利影响，还能利用这些偏差提升性能。通过严格的数学分析和证明，本文示例表明，所提策略改进比未调整的反馈策略高达61%，比反馈纳什策略高0.59%。', 'title_zh': '在控制不完美情况下的LQ博弈的最优修正反馈策略'}
{'arxiv_id': 'arXiv:2503.19037', 'title': 'Evolutionary Policy Optimization', 'authors': 'Jianren Wang, Yifan Su, Abhinav Gupta, Deepak Pathak', 'link': 'https://arxiv.org/abs/2503.19037', 'abstract': 'Despite its extreme sample inefficiency, on-policy reinforcement learning has become a fundamental tool in real-world applications. With recent advances in GPU-driven simulation, the ability to collect vast amounts of data for RL training has scaled exponentially. However, studies show that current on-policy methods, such as PPO, fail to fully leverage the benefits of parallelized environments, leading to performance saturation beyond a certain scale. In contrast, Evolutionary Algorithms (EAs) excel at increasing diversity through randomization, making them a natural complement to RL. However, existing EvoRL methods have struggled to gain widespread adoption due to their extreme sample inefficiency. To address these challenges, we introduce Evolutionary Policy Optimization (EPO), a novel policy gradient algorithm that combines the strengths of EA and policy gradients. We show that EPO significantly improves performance across diverse and challenging environments, demonstrating superior scalability with parallelized simulations.', 'abstract_zh': '尽管在样本效率上存在极端的不足，但在线强化学习已成为现实世界应用中的基本工具。随着基于GPU的模拟技术的进展，用于RL训练的数据收集能力呈指数级增长。然而，研究表明，当前的在线方法，如PPO，在并行环境中无法充分利用其优势，导致在一定规模后性能饱和。相比之下，进化算法（EAs）通过随机化增加多样性，使其成为RL的自然补充。然而，现有的EvoRL方法由于其极端的样本效率低下而难以广泛采用。为了解决这些挑战，我们提出了进化策略优化（EPO），这是一种结合了EA和策略梯度优点的新算法。我们展示了EPO在各种复杂环境中的显著性能提升，证明了其在并行模拟中的优越可扩展性。', 'title_zh': '进化策略优化'}
{'arxiv_id': 'arXiv:2503.18988', 'title': 'SG-Tailor: Inter-Object Commonsense Relationship Reasoning for Scene Graph Manipulation', 'authors': 'Haoliang Shang, Hanyu Wu, Guangyao Zhai, Boyang Sun, Fangjinhua Wang, Federico Tombari, Marc Pollefeys', 'link': 'https://arxiv.org/abs/2503.18988', 'abstract': "Scene graphs capture complex relationships among objects, serving as strong priors for content generation and manipulation. Yet, reasonably manipulating scene graphs -- whether by adding nodes or modifying edges -- remains a challenging and untouched task. Tasks such as adding a node to the graph or reasoning about a node's relationships with all others are computationally intractable, as even a single edge modification can trigger conflicts due to the intricate interdependencies within the graph. To address these challenges, we introduce SG-Tailor, an autoregressive model that predicts the conflict-free relationship between any two nodes. SG-Tailor not only infers inter-object relationships, including generating commonsense edges for newly added nodes but also resolves conflicts arising from edge modifications to produce coherent, manipulated graphs for downstream tasks. For node addition, the model queries the target node and other nodes from the graph to predict the appropriate relationships. For edge modification, SG-Tailor employs a Cut-And-Stitch strategy to solve the conflicts and globally adjust the graph. Extensive experiments demonstrate that SG-Tailor outperforms competing methods by a large margin and can be seamlessly integrated as a plug-in module for scene generation and robotic manipulation tasks.", 'abstract_zh': '场景图捕获对象间复杂关系，为内容生成和操作提供 strong priors。然而，合理地操纵场景图（无论是添加节点还是修改边）仍然是一个具有挑战性和未解决的任务。诸如向图中添加节点或推理节点与其他节点的关系之类的任务在计算上是不可行的，因为即使是单条边的修改也会由于图内复杂的关系依赖而引发冲突。为了解决这些挑战，我们引入了 SG-Tailor，一个自回归模型，用于预测任意两个节点间的无冲突关系。SG-Tailor 不仅推断物体间的关系，包括为新添加的节点生成常识性的边，还能解决由边修改引发的冲突，以生成连贯的、被操纵过的图用于下游任务。对于节点添加，模型从图中查询目标节点和其他节点来预测合适的相互关系。对于边修改，SG-Tailor 使用“剪切和缝合”策略解决冲突并全局调整图。广泛实验表明，SG-Tailor 在性能上大幅优于竞争方法，并且可以无缝集成为场景生成和机器人操作任务的插件模块。', 'title_zh': 'SG-Tailor: 不同对象之间的常识关系推理以进行场景图操作'}
