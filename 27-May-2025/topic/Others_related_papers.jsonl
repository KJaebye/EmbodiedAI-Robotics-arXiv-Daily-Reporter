{'arxiv_id': 'arXiv:2505.19860', 'title': 'Causal Bayesian Networks for Data-driven Safety Analysis of Complex Systems', 'authors': 'Roman Gansch, Lina Putze, Tjark Koopmann, Jan Reich, Christian Neurohr', 'link': 'https://arxiv.org/abs/2505.19860', 'abstract': "Ensuring safe operation of safety-critical complex systems interacting with their environment poses significant challenges, particularly when the system's world model relies on machine learning algorithms to process the perception input. A comprehensive safety argumentation requires knowledge of how faults or functional insufficiencies propagate through the system and interact with external factors, to manage their safety impact. While statistical analysis approaches can support the safety assessment, associative reasoning alone is neither sufficient for the safety argumentation nor for the identification and investigation of safety measures. A causal understanding of the system and its interaction with the environment is crucial for safeguarding safety-critical complex systems. It allows to transfer and generalize knowledge, such as insights gained from testing, and facilitates the identification of potential improvements. This work explores using causal Bayesian networks to model the system's causalities for safety analysis, and proposes measures to assess causal influences based on Pearl's framework of causal inference. We compare the approach of causal Bayesian networks to the well-established fault tree analysis, outlining advantages and limitations. In particular, we examine importance metrics typically employed in fault tree analysis as foundation to discuss suitable causal metrics. An evaluation is performed on the example of a perception system for automated driving. Overall, this work presents an approach for causal reasoning in safety analysis that enables the integration of data-driven and expert-based knowledge to account for uncertainties arising from complex systems operating in open environments.", 'abstract_zh': '确保安全关键复杂系统与其环境交互的 safe 操作面临重大挑战，特别是在系统的世界模型依赖于机器学习算法处理感知输入时。全面的安全论证需要了解故障或功能缺陷如何在系统内部传播并如何与外部因素交互，以管理其安全影响。虽然统计分析方法可以支持安全评估，但仅依赖关联推理不足以进行安全论证或识别和调查安全措施。系统及其与环境交互的因果理解对于保障安全关键复杂系统至关重要。它允许转移和泛化知识，如从测试中获得的洞察，并促进潜在改进的识别。本文探讨使用因果贝叶斯网络来建模系统的因果关系进行安全分析，并基于佩尔的因果推断框架提出评估因果影响的措施。我们将因果贝叶斯网络的方法与成熟的故障树分析进行比较，概述其优势和局限性。特别是，我们以故障树分析中常用的重要性度量为基础，讨论合适的因果度量。我们在自动驾驶感知系统的例子上进行了评估。总体而言，本文提出了一种因果推理在安全分析中的方法，能够整合数据驱动与基于专家的知识，以应对开放环境中复杂系统带来的不确定性。', 'title_zh': '用于复杂系统数据驱动安全性分析的因果贝叶斯网络'}
{'arxiv_id': 'arXiv:2505.19560', 'title': 'LF-GNSS: Towards More Robust Satellite Positioning with a Hard Example Mining Enhanced Learning-Filtering Deep Fusion Framework', 'authors': 'Jianan Lou, Rong Zhang', 'link': 'https://arxiv.org/abs/2505.19560', 'abstract': 'Global Navigation Satellite System (GNSS) is essential for autonomous driving systems, unmanned vehicles, and various location-based technologies, as it provides the precise geospatial information necessary for navigation and situational awareness. However, its performance is often degraded by Non-Line-Of-Sight (NLOS) and multipath effects, especially in urban environments. Recently, Artificial Intelligence (AI) has been driving innovation across numerous industries, introducing novel solutions to mitigate the challenges in satellite positioning. This paper presents a learning-filtering deep fusion framework for satellite positioning, termed LF-GNSS. The framework utilizes deep learning networks to intelligently analyze the signal characteristics of satellite observations, enabling the adaptive construction of observation noise covariance matrices and compensated innovation vectors for Kalman filter input. A dynamic hard example mining technique is incorporated to enhance model robustness by prioritizing challenging satellite signals during training. Additionally, we introduce a novel feature representation based on Dilution of Precision (DOP) contributions, which helps to more effectively characterize the signal quality of individual satellites and improve measurement weighting. LF-GNSS has been validated on both public and private datasets, demonstrating superior positioning accuracy compared to traditional methods and other learning-based solutions. To encourage further integration of AI and GNSS research, we will open-source the code at this https URL, and release a collection of satellite positioning datasets for urban scenarios at this https URL.', 'abstract_zh': '全球导航卫星系统（GNSS）对于自动驾驶系统、无人驾驶车辆以及各种基于位置的技术至关重要，因为它提供了导航和态势感知所需的精确地理空间信息。然而，其性能往往因非视距（NLOS）和多路径效应而在城市环境中受到影响。近年来，人工智能（AI）正在推动众多行业的创新，引入新的解决方案以缓解卫星定位的挑战。本文提出了一种用于卫星定位的基于学习-过滤的深度融合框架，称为LF-GNSS。该框架利用深度学习网络智能分析卫星观测信号特征，实现观测噪声协方差矩阵和补偿创新向量的自适应构建，以优化卡尔曼滤波器输入。还引入了一种动态硬模式挖掘技术，在训练过程中优先处理具有挑战性的卫星信号，增强模型的鲁棒性。此外，还基于精度衰减因子（DOP）贡献引入了一种新的特征表示方法，有助于更有效地表征单颗卫星的信号质量并改进测量权重。LF-GNSS已在公共和私有数据集上进行验证，显示了与传统方法和其他基于学习的解决方案相比的卓越定位精度。为促进人工智能与GNSS研究的进一步融合，代码将在以下链接开源：this https URL，并将在以下链接发布城市场景下的卫星定位数据集：this https URL。', 'title_zh': 'LF-GNSS：一种增强学习滤波深度融合框架的困难样本挖掘增强卫星定位鲁棒性方法'}
{'arxiv_id': 'arXiv:2505.19330', 'title': 'Deriving The Fundamental Equation of Earthmoving and Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation', 'authors': 'W. Jacob Wagner', 'link': 'https://arxiv.org/abs/2505.19330', 'abstract': "This document serves as supplementary material for two International Society for Terrain-Vehicle Systems conference publications regarding in situ soil property estimation by Wagner et al. in 2023 and 2025. It covers the derivation of the fundamental equation of earthmoving for a flat blade moving through sloped soil and provides some information regarding the advanced configuration of Vortex Studio's soil-tool interaction simulation.", 'abstract_zh': '本文件作为Wagner等人在2023年和2025年发表于国际地形车辆系统学会会议上的关于就地土壤属性估算的两篇论文的补充材料。它涵盖了平刃通过斜坡土壤挖掘的基本方程的推导，并提供了一些关于Vortex Studio土壤-工具交互模拟高级配置的信息。', 'title_zh': '构建土方作业的基本方程并配置旋 Uncomment for full translation, but it seems there\'s a typo in the original title. Assuming "Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation" needs to be integrated, the translated title would be:\n\n构建土方作业的基本方程并配置旋涡工作室土方作业模拟进行土壤属性估算实验'}
{'arxiv_id': 'arXiv:2505.18631', 'title': 'S2R-Bench: A Sim-to-Real Evaluation Benchmark for Autonomous Driving', 'authors': 'Li Wang, Guangqi Yang, Lei Yang, Ziying Song, Xinyu Zhang, Ying Chen, Lin Liu, Junjie Gao, Zhiwei Li, Qingshan Yang, Jun Li, Liangliang Wang, Wenhao Yu, Bin Xu, Weida Wang, Huaping Liu', 'link': 'https://arxiv.org/abs/2505.18631', 'abstract': 'Safety is a long-standing and the final pursuit in the development of autonomous driving systems, with a significant portion of safety challenge arising from perception. How to effectively evaluate the safety as well as the reliability of perception algorithms is becoming an emerging issue. Despite its critical importance, existing perception methods exhibit a limitation in their robustness, primarily due to the use of benchmarks are entierly simulated, which fail to align predicted results with actual outcomes, particularly under extreme weather conditions and sensor anomalies that are prevalent in real-world scenarios. To fill this gap, in this study, we propose a Sim-to-Real Evaluation Benchmark for Autonomous Driving (S2R-Bench). We collect diverse sensor anomaly data under various road conditions to evaluate the robustness of autonomous driving perception methods in a comprehensive and realistic manner. This is the first corruption robustness benchmark based on real-world scenarios, encompassing various road conditions, weather conditions, lighting intensities, and time periods. By comparing real-world data with simulated data, we demonstrate the reliability and practical significance of the collected data for real-world applications. We hope that this dataset will advance future research and contribute to the development of more robust perception models for autonomous driving. This dataset is released on this https URL.', 'abstract_zh': '自动驾驶领域中从感知角度出发的安全性长期且最终的追求目标，现有感知方法在鲁棒性方面存在局限，这主要是由于使用完全模拟的基准进行评估，导致预测结果与实际结果不一致，尤其是在极端天气条件和传感器异常等真实场景中常见的情况下。为填补这一缺口，本研究提出了一种自动驾驶模拟到现实的评估基准（S2R-Bench）。我们收集了在各种道路条件下出现的多元传感器异常数据，以全面而现实的方式评估自动驾驶感知方法的鲁棒性。这是首个基于真实场景的抗污染鲁棒性基准，涵盖多种道路条件、天气条件、光照强度和时间周期。通过将现实数据与模拟数据进行对比，我们展示了所收集数据的可靠性和实际应用意义。我们希望这一数据集能促进未来的研究，并有助于开发更具鲁棒性的自动驾驶感知模型。该数据集在此处发布：https://url.com', 'title_zh': 'S2R-Bench: 从模拟到现实的自动驾驶评估基准'}
{'arxiv_id': 'arXiv:2505.18490', 'title': 'An Inertial Sequence Learning Framework for Vehicle Speed Estimation via Smartphone IMU', 'authors': 'Xuan Xiao, Xiaotong Ren, Haitao Li', 'link': 'https://arxiv.org/abs/2505.18490', 'abstract': "Accurately estimating vehicle velocity via smartphone is critical for mobile navigation and transportation. This paper introduces a cutting-edge framework for velocity estimation that incorporates temporal learning models, utilizing Inertial Measurement Unit (IMU) data and is supervised by Global Navigation Satellite System (GNSS) information. The framework employs a noise compensation network to fit the noise distribution between sensor measurements and actual motion, and a pose estimation network to align the coordinate systems of the phone and the vehicle. To enhance the model's generalizability, a data augmentation technique that mimics various phone placements within the car is proposed. Moreover, a new loss function is designed to mitigate timestamp mismatches between GNSS and IMU signals, effectively aligning the signals and improving the velocity estimation accuracy. Finally, we implement a highly efficient prototype and conduct extensive experiments on a real-world crowdsourcing dataset, resulting in superior accuracy and efficiency.", 'abstract_zh': '基于智能手机的车辆速度准确估计对于移动导航和交通至关重要。本文介绍了一种结合时间学习模型的先进框架，该框架利用惯性测量单元（IMU）数据，并由全球导航卫星系统（GNSS）信息监督。该框架采用噪声补偿网络来拟合传感器测量值与实际运动之间的噪声分布，并采用姿态估计网络对齐手机和车辆的坐标系统。为了增强模型的泛化能力，提出了模拟车内不同手机放置方式的数据增强技术。此外，设计了一种新的损失函数来缓解GNSS和IMU信号之间的时间戳不匹配，有效地对齐信号并提高速度估计准确性。最后，我们实现了一个高效的原型并在真实世界的众包数据集上进行了广泛的实验，结果表明其具有更高的准确性和效率。', 'title_zh': '基于智能手机IMU的车辆速度估计惯性序列学习框架'}
{'arxiv_id': 'arXiv:2505.18437', 'title': 'Curio: A Cost-Effective Solution for Robotics Education', 'authors': 'Talha Enes Ayranci, Florent P. Audonnet, Gerardo Aragon-Camarasa, Mireilla Bikanga Ada, Jonathan Grizou', 'link': 'https://arxiv.org/abs/2505.18437', 'abstract': 'Student engagement is one of the key challenges in robotics and artificial intelligence (AI) education. Tangible learning approaches, such as educational robots, provide an effective way to enhance engagement and learning by offering real-world applications to bridge the gap between theory and practice. However, existing platforms often face barriers such as high cost or limited capabilities. In this paper, we present Curio, a cost-effective, smartphone-integrated robotics platform designed to lower the entry barrier to robotics and AI education. With a retail price below $50, Curio is more affordable than similar platforms. By leveraging smartphones, Curio eliminates the need for onboard processing units, dedicated cameras, and additional sensors while maintaining the ability to perform AI-based tasks. To evaluate the impact of Curio on student engagement, we conducted a case study with 20 participants, where we examined usability, engagement, and potential for integrating into AI and robotics education. The results indicate high engagement and motivation levels across all participants. Additionally, 95% of participants reported an improvement in their understanding of robotics. Findings suggest that using a robotic system such as Curio can enhance engagement and hands-on learning in robotics and AI education. All resources and projects with Curio are available at this http URL.', 'abstract_zh': '机器人与人工智能教育中学生参与度是关键挑战。感性化学习方法，如教育机器人，通过提供现实应用来弥合理论与实践之间的差距，有效提升了参与度和学习效果。然而，现有平台常常面临成本高或能力有限的障碍。在本文中，我们介绍了Curio，这是一种低成本的智能手机集成机器人平台，旨在降低参与机器人与人工智能教育的门槛。Curio的零售价低于50美元，比类似平台更具成本效益。通过利用智能手机，Curio消除了对内置处理单元、专用摄像头和附加传感器的需求，同时保持了执行人工智能任务的能力。为了评估Curio对学生参与度的影响，我们对20名参与者进行了案例研究，考察了其实用性、参与度及融入人工智能与机器人教育的潜力。结果表明，所有参与者的参与度和动机都很高。此外，95%的参与者报告说对机器人技术的理解有所提高。研究结果表明，使用如Curio这样的机器人系统可以提高机器人与人工智能教育中的参与度和动手学习体验。所有与Curio相关的资源和项目均可通过以下链接访问。', 'title_zh': 'Curio：一种低成本的机器人教育解决方案'}
{'arxiv_id': 'arXiv:2505.18204', 'title': 'Brownian Bridge Augmented Surrogate Simulation and Injection Planning for Geological CO$_2$ Storage', 'authors': 'Haoyue Bai, Guodong Chen, Wangyang Ying, Xinyuan Wang, Nanxu Gong, Sixun Dong, Giulia Pedrielli, Haoyu Wang, Haifeng Chen, Yanjie Fu', 'link': 'https://arxiv.org/abs/2505.18204', 'abstract': 'Geological CO2 storage (GCS) involves injecting captured CO2 into deep subsurface formations to support climate goals. The effective management of GCS relies on adaptive injection planning to dynamically control injection rates and well pressures to balance both storage safety and efficiency. Prior literature, including numerical optimization methods and surrogate-optimization methods, is limited by real-world GCS requirements of smooth state transitions and goal-directed planning within limited time. To address these limitations, we propose a Brownian Bridge-augmented framework for surrogate simulation and injection planning in GCS and develop two insights: (i) Brownian bridge as a smooth state regularizer for better surrogate simulation; (ii) Brownian bridge as goal-time-conditioned planning guidance for improved injection planning. Our method has three stages: (i) learning deep Brownian bridge representations with contrastive and reconstructive losses from historical reservoir and utility trajectories, (ii) incorporating Brownian bridge-based next state interpolation for simulator regularization, and (iii) guiding injection planning with Brownian utility-conditioned trajectories to generate high-quality injection plans. Experimental results across multiple datasets collected from diverse GCS settings demonstrate that our framework consistently improves simulation fidelity and planning effectiveness while maintaining low computational overhead.', 'abstract_zh': '地质碳封存（GCS）涉及将捕获的CO2注入深层地下储层以支持气候目标。有效的GCS管理依赖于自适应注气计划，以动态控制注气速率和井压，平衡存储安全与效率。现有的文献，包括数值优化方法和代理优化方法，受限于实际GCS应用对平滑状态过渡和目标导向规划在有限时间内的要求。为应对这些局限性，我们提出了一种布朗桥增强的代理模拟与注气计划框架，并发展了两个见解：（i）布朗桥作为平滑状态正则化器以改进代理模拟；（ii）布朗桥作为目标时间条件下的规划指导以优化注气计划。我们的方法包括三个阶段：（i）通过对比损失和重构损失学习历史油藏和收益轨迹的深度布朗桥表示；（ii）利用基于布朗桥的下一状态内插对模拟器进行正则化；（iii）基于布朗桥条件下的收益轨迹指导注气计划，生成高质量的注气方案。来自多种GCS设置的数据集的实验结果表明，我们的框架在保持低计算开销的同时，持续提高模拟精度和计划有效性。', 'title_zh': '使用布朗运动桥增广替代模拟及注入计划的地层二氧化碳储存'}
{'arxiv_id': 'arXiv:2505.19809', 'title': 'Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees', 'authors': 'Daniel Ordoñez-Apraez, Alek Fröhlich, Vladimir Kostić, Karim Lounici, Vivien Brandt, Massimiliano Pontil', 'link': 'https://arxiv.org/abs/2505.19809', 'abstract': 'In many real-world applications of regression, conditional probability estimation, and uncertainty quantification, exploiting symmetries rooted in physics or geometry can dramatically improve generalization and sample efficiency. While geometric deep learning has made significant empirical advances by incorporating group-theoretic structure, less attention has been given to statistical learning guarantees. In this paper, we introduce an equivariant representation learning framework that simultaneously addresses regression, conditional probability estimation, and uncertainty quantification while providing first-of-its-kind non-asymptotic statistical learning guarantees. Grounded in operator and group representation theory, our framework approximates the spectral decomposition of the conditional expectation operator, building representations that are both equivariant and disentangled along independent symmetry subgroups. Empirical evaluations on synthetic datasets and real-world robotics applications confirm the potential of our approach, matching or outperforming existing equivariant baselines in regression while additionally providing well-calibrated parametric uncertainty estimates.', 'abstract_zh': '在回归、条件概率估计和不确定性量化等许多实际应用中，利用源自物理或几何的对称性可以显著提高泛化能力和样本效率。虽然几何深度学习通过引入群论结构取得了显著的实证进步，但在统计学习保证方面关注较少。本文提出了一种同时解决回归、条件概率估计和不确定性量化问题的不变表示学习框架，并提供了同类中首个非渐近统计学习保证。基于算子和群表示理论，该框架近似条件期望算子的谱分解，构建既不变又在独立对称子群上解纠缠的表示。在合成数据集和实际机器人应用上的 empirical 评估证实了该方法的潜力，在回归任务上匹配或超越现有不变基线，并额外提供校准良好的参数不确定性估计。', 'title_zh': '对称意识保证下的等变表示学习'}
{'arxiv_id': 'arXiv:2505.19247', 'title': 'Improving Value Estimation Critically Enhances Vanilla Policy Gradient', 'authors': 'Tao Wang, Ruipeng Zhang, Sicun Gao', 'link': 'https://arxiv.org/abs/2505.19247', 'abstract': 'Modern policy gradient algorithms, such as TRPO and PPO, outperform vanilla policy gradient in many RL tasks. Questioning the common belief that enforcing approximate trust regions leads to steady policy improvement in practice, we show that the more critical factor is the enhanced value estimation accuracy from more value update steps in each iteration. To demonstrate, we show that by simply increasing the number of value update steps per iteration, vanilla policy gradient itself can achieve performance comparable to or better than PPO in all the standard continuous control benchmark environments. Importantly, this simple change to vanilla policy gradient is significantly more robust to hyperparameter choices, opening up the possibility that RL algorithms may still become more effective and easier to use.', 'abstract_zh': '现代的策略梯度算法（如TRPO和PPO）在许多RL任务中优于vanilla策略梯度。我们质疑常规信念，即施加近似信任区域会实际促进策略的稳定改进，而表明更为关键的因素是从每个迭代中增加价值估计的精度。为证明这一点，我们显示仅通过增加每个迭代中的价值更新步数，vanilla策略梯度本身就能在所有标准连续控制基准环境中达到与PPO相当或更优的性能。重要的是，这一简单的改变使vanilla策略梯度在超参数选择上表现出更多的稳健性，为RL算法仍可能变得更加有效和易于使用提供了可能性。', 'title_zh': '显著提升价值估计能大幅增强 Vanilla 策略梯度算法。'}
{'arxiv_id': 'arXiv:2505.19238', 'title': 'Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees', 'authors': 'Sourav Ganguly, Arnob Ghosh, Kishan Panaganti, Adam Wierman', 'link': 'https://arxiv.org/abs/2505.19238', 'abstract': 'Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.', 'abstract_zh': '约束条件下的决策对于设计实际控制系统的安全策略是至关重要的，但模拟环境往往无法捕捉到实际的 adversities。我们考虑在现实模型与可访问的模拟器/名义模型之间存在不匹配时，学习一个既能最大化累积奖励又能满足约束的策略的问题。特别是，我们关注在不确定集中心于未知名义模型的最坏可能随机模型下，代理最大化奖励并满足约束的鲁棒约束马尔可夫决策问题（RCMDP）。由于缺乏强对偶性，标准约束马尔可夫决策过程（CMDP）中的对偶方法不适用。此外，标准的鲁棒值迭代方法也不适用于复合价值函数，因为最坏情况模型可能对奖励价值函数和约束价值函数不同。我们提出了一种新的技术，该技术有效地最小化约束价值函数以满足约束；当所有约束都满足时，它可以简单地最大化鲁棒奖励价值函数。我们证明这样的算法在至多 $O(\\epsilon^{-2})$ 次迭代后，能找到一个最多 $\\epsilon$ 非最优性和可行的策略。与最先进的方法相比，我们不需要使用二分搜索，因此在折现因子 $\\gamma$ 较小时至少能减少四倍的计算时间，在 $\\gamma$ 较大时至少能减少六倍的计算时间。', 'title_zh': '具有迭代复杂度保证的稳健约束MDP中的高效策略优化'}
{'arxiv_id': 'arXiv:2505.18945', 'title': 'Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back', 'authors': 'Jintao Sun, Hu Zhang, Gangyi Ding, Zhedong Zheng', 'link': 'https://arxiv.org/abs/2505.18945', 'abstract': "Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over time. We introduce Echo Planning, a novel self-correcting framework that establishes a closed-loop Current - Future - Current (CFC) cycle to harmonize trajectory prediction with scene coherence. Our key insight is that plausible future trajectories must be bi-directionally consistent, ie, not only generated from current observations but also capable of reconstructing them. The CFC mechanism first predicts future trajectories from the Bird's-Eye-View (BEV) scene representation, then inversely maps these trajectories back to estimate the current BEV state. By enforcing consistency between the original and reconstructed BEV representations through a cycle loss, the framework intrinsically penalizes physically implausible or misaligned trajectories. Experiments on nuScenes demonstrate state-of-the-art performance, reducing L2 error by 0.04 m and collision rate by 0.12% compared to one-shot planners. Crucially, our method requires no additional supervision, leveraging the CFC cycle as an inductive bias for robust planning. This work offers a deployable solution for safety-critical autonomous systems.", 'abstract_zh': "现代端到端自动驾驶系统受到一个关键限制：其规划器缺乏机制来确保预测轨迹与 evolving 场景动态之间的时序一致性。这种自我监督的缺失使得早期预测错误会随着时间 catastrophe 地累积。我们提出了一种新颖的自我矫正框架 Echo Planning，建立了当前 - 未来 - 当前（CFC）闭环循环，以实现轨迹预测与场景连贯性的一致性。我们的关键见解是，合理的未来轨迹必须双向一致，即不仅从当前观测生成，还可以重构这些观测。CFC 机制首先从 Bird's-Eye-View (BEV) 场景表示预测未来轨迹，然后将这些轨迹逆向映射以估计当前 BEV 状态。通过周期损失强制原始和重构的 BEV 表示之间的一致性，框架内在地惩罚物理上不合理或错位的轨迹。在 nuScenes 上的实验显示了最先进的性能，L2 错误减少了 0.04 m，碰撞率减少了 0.12%，相比一次预测规划器。最关键的是，我们的方法不需要额外的监督，利用 CFC 循环作为稳健规划的归纳偏差。这项工作为安全关键的自动驾驶系统提供了可部署的解决方案。", 'title_zh': '自动驾驶中的回波规划：从当前观测到未来轨迹及其反馈'}
{'arxiv_id': 'arXiv:2505.18881', 'title': 'SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes', 'authors': 'Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang', 'link': 'https://arxiv.org/abs/2505.18881', 'abstract': 'We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.', 'abstract_zh': '面向动态场景的开放词汇对象导航语义感知数据集和基准生成流水线（SD-OVON）', 'title_zh': 'SD-OVON: 一种面向开放词汇对象导航动态场景的语义感知数据集和基准生成管道'}
{'arxiv_id': 'arXiv:2505.18810', 'title': 'Discrete gradient methods for port-Hamiltonian differential-algebraic equations', 'authors': 'Philipp L. Kinon, Riccardo Morandin, Philipp Schulze', 'link': 'https://arxiv.org/abs/2505.18810', 'abstract': 'Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian differential-algebraic equations - as they emerge from the port- and energy-based modeling of physical systems in various domains. We introduce a novel numerical scheme tailored for semi-explicit differential-algebraic equations and further address more general settings using the concepts of discrete gradient pairs and Dirac-dissipative structures. Additionally, the behavior under system transformations is investigated and we demonstrate that under suitable assumptions port-Hamiltonian differential-algebraic equations admit a representation which consists of a parametrized port-Hamiltonian semi-explicit system and an unstructured equation. Finally, we present the application to multibody system dynamics and discuss numerical results to demonstrate the capabilities of our approach.', 'abstract_zh': '离散梯度方法是动力系统时间离散化的一个强大工具，因为它在总能量形式不同的情况下都能保持结构。在本文中，我们讨论了离散梯度方法在一类非线性端口哈密尔顿微分代数方程系统中的应用——这类方程源自不同领域物理系统的端口和能量导向建模。我们引入了一种针对半隐式微分代数方程的新型数值方案，并利用离散梯度对和狄拉克耗散结构的概念处理更一般的设置。此外，我们研究了系统变换下的行为，并证明在适当假设下，端口哈密尔顿微分代数方程可以表示为参数化端口哈密尔顿半隐式系统和无结构方程的组合。最后，我们展示了在多体系统动力学中的应用，并讨论了数值结果以证明我们方法的能力。', 'title_zh': 'porte-哈密尔顿差分代数方程的离散梯度方法'}
{'arxiv_id': 'arXiv:2505.18795', 'title': 'Distributed Expectation Propagation for Multi-Object Tracking over Sensor Networks', 'authors': 'Qing Li, Runze Gan, James R. Hopgood, Michael E. Davies, Simon J. Godsill', 'link': 'https://arxiv.org/abs/2505.18795', 'abstract': 'In this paper, we present a novel distributed expectation propagation algorithm for multiple sensors, multiple objects tracking in cluttered environments. The proposed framework enables each sensor to operate locally while collaboratively exchanging moment estimates with other sensors, thus eliminating the need to transmit all data to a central processing node. Specifically, we introduce a fast and parallelisable Rao-Blackwellised Gibbs sampling scheme to approximate the tilted distributions, which enhances the accuracy and efficiency of expectation propagation updates. Results demonstrate that the proposed algorithm improves both communication and inference efficiency for multi-object tracking tasks with dynamic sensor connectivity and varying clutter levels.', 'abstract_zh': '本文提出了一种用于杂波环境中多传感器多目标跟踪的新型分布式期望传播算法。该框架使每个传感器可以在本地操作的同时与其他传感器协作交换矩估计，从而消除将所有数据传输到中央处理节点的需要。具体而言，我们引入了一种快速且可并行化的Rao-Blackwellised吉布斯抽样方案来逼近倾斜分布，这增强了期望传播更新的准确性和效率。结果表明，所提出算法在动态传感器连接性和变化的杂波水平下提高了多目标跟踪任务的通信和推理效率。', 'title_zh': '分布式期望传播在传感器网络中的多目标跟踪'}
{'arxiv_id': 'arXiv:2505.18371', 'title': 'Military AI Needs Technically-Informed Regulation to Safeguard AI Research and its Applications', 'authors': 'Riley Simmons-Edler, Jean Dong, Paul Lushenko, Kanaka Rajan, Ryan P. Badman', 'link': 'https://arxiv.org/abs/2505.18371', 'abstract': 'Military weapon systems and command-and-control infrastructure augmented by artificial intelligence (AI) have seen rapid development and deployment in recent years. However, the sociotechnical impacts of AI on combat systems, military decision-making, and the norms of warfare have been understudied. We focus on a specific subset of lethal autonomous weapon systems (LAWS) that use AI for targeting or battlefield decisions. We refer to this subset as AI-powered lethal autonomous weapon systems (AI-LAWS) and argue that they introduce novel risks -- including unanticipated escalation, poor reliability in unfamiliar environments, and erosion of human oversight -- all of which threaten both military effectiveness and the openness of AI research. These risks cannot be addressed by high-level policy alone; effective regulation must be grounded in the technical behavior of AI models. We argue that AI researchers must be involved throughout the regulatory lifecycle. Thus, we propose a clear, behavior-based definition of AI-LAWS -- systems that introduce unique risks through their use of modern AI -- as a foundation for technically grounded regulation, given that existing frameworks do not distinguish them from conventional LAWS. Using this definition, we propose several technically-informed policy directions and invite greater participation from the AI research community in military AI policy discussions.', 'abstract_zh': '基于人工智能的军事武器系统和指挥控制基础设施已在近年来迅速发展和部署。然而，人工智能对战斗系统、军事决策以及战争规范的社会技术影响尚研究不足。我们关注特定类型的致命自主武器系统（LAWS），这些系统使用人工智能进行目标识别或战场决策。我们将这一子集称为人工智能赋能的致命自主武器系统（AI-LAWS），并认为它们引入了新颖的风险，包括不可预见的升级风险、在不熟悉环境中可靠性不佳以及削弱的人类监督，这些风险既威胁军事有效性，也威胁人工智能研究的开放性。这些风险仅靠高级政策无法解决；有效的规制必须基于人工智能模型的技术行为。我们主张在整个规制生命周期中都应包括人工智能研究人员。因此，我们提出了一种明确、基于行为的AI-LAWS定义——通过使用现代人工智能技术引入独特风险的系统，作为基于技术的规制的基础，因为现有框架无法将它们与传统LAWS区分开来。利用这一定义，我们提出了一些基于技术的政策方向，并邀请AI研究社区更大程度地参与军事人工智能政策讨论。', 'title_zh': '军事AI需要基于技术的理解来制定监管以保护AI研究及其应用。'}
{'arxiv_id': 'arXiv:2505.18187', 'title': 'Discretization of Linear Systems using the Matrix Exponential', 'authors': 'Steven Dahdah, James Richard Forbes', 'link': 'https://arxiv.org/abs/2505.18187', 'abstract': 'Discretizing continuous-time linear systems typically requires numerical integration. This document presents a convenient method for discretizing the dynamics, input, and process noise state-space matrices of a continuous-time linear system using a single matrix exponential.', 'abstract_zh': '连续时间线性系统离散化通常需要数值积分。本文介绍了一种使用单个矩阵指数方便离散化连续时间线性系统动力学、输入和过程噪声状态空间矩阵的方法。', 'title_zh': '线性系统用矩阵指数的离散化'}
{'arxiv_id': 'arXiv:2505.18173', 'title': 'IoT-Enabled Hemodynamic Surveillance System: AD8232 Bioelectric Signal Processing with ESP32', 'authors': 'Hemalatha R J, Shubham Malhotra, Shivapanchakshari T G, Lokesh K, Dev Anand D, Samson Jebakumar S', 'link': 'https://arxiv.org/abs/2505.18173', 'abstract': "This dissertation proposes an electrocardiogram (ECG) tracking device that diagnoses cardiopulmonary problems using the Internet of Things (IoT) desired results. The initiative is built on the internet observing an electrocardiogram with the AD8232 heart rhythm sensor and the ESP32 expansion kit, using an on-premise connected device platform to transform sensing input into meaningful data. That subsequently supervises an ECG signal and delivers it to an intelligent phone via Wi-Fi for data analysis. That is the pace of the circulating. Assessing body temperature, pulse rate, and coronary arteries are vital measures to defend your health. The heartbeat rate may be measured in two ways: there are by palpating the pulse at the wrist or neck directly or other alternative by utilizing a cardiac sensor. Monitoring alcohol levels in cardiac patients is critical for measuring the influence of liquor on their health and the efficacy of therapy. It assists in recognizing the association between alcohol consumption and cardiac issues, rather than rhythm recorded in beats per minute (bpm). An IR transmitter/receiver pair (OLED) needs to stay compatible up near the sensor's knuckle current or voltage pulse. The detector's electrical output is evaluated by suitable electronic circuits to produce a visual clue (digital display). We must design a cost-effective, user-friendly, and efficient ECG monitoring system with contemporary technology for both persons imprisoned by disease or aging, as well as healthcare professionals. Microcontroller combined with software. A smartphone application is created to monitor the cardiovascular health of distant patients in real-time", 'abstract_zh': '基于物联网的心电图跟踪设备及其在心血管问题诊断中的应用', 'title_zh': '基于IoT的心动过缓监测系统：AD8232 生物电信号处理与ESP32'}
{'arxiv_id': 'arXiv:2505.20273', 'title': 'Ten Principles of AI Agent Economics', 'authors': 'Ke Yang, ChengXiang Zhai', 'link': 'https://arxiv.org/abs/2505.20273', 'abstract': 'The rapid rise of AI-based autonomous agents is transforming human society and economic systems, as these entities increasingly exhibit human-like or superhuman intelligence. From excelling at complex games like Go to tackling diverse general-purpose tasks with large language and multimodal models, AI agents are evolving from specialized tools into dynamic participants in social and economic ecosystems. Their autonomy and decision-making capabilities are poised to impact industries, professions, and human lives profoundly, raising critical questions about their integration into economic activities, potential ethical concerns, and the balance between their utility and safety.\nTo address these challenges, this paper presents ten principles of AI agent economics, offering a framework to understand how AI agents make decisions, influence social interactions, and participate in the broader economy. Drawing on economics, decision theory, and ethics, we explore fundamental questions, such as whether AI agents might evolve from tools into independent entities, their impact on labor markets, and the ethical safeguards needed to align them with human values. These principles build on existing economic theories while accounting for the unique traits of AI agents, providing a roadmap for their responsible integration into human systems.\nBeyond theoretical insights, this paper highlights the urgency of future research into AI trustworthiness, ethical guidelines, and regulatory oversight. As we enter a transformative era, this work serves as both a guide and a call to action, ensuring AI agents contribute positively to human progress while addressing risks tied to their unprecedented capabilities.', 'abstract_zh': '基于AI的自主代理的迅速崛起正在转变人类社会和经济系统，这些实体日益展现出类人或超人的智能。从在围棋等复杂游戏中表现出色到利用大规模语言模型和多模态模型解决多样化的通用任务，AI代理正从专业工具演变为社会和经济生态系统中的动态参与者。它们的自主性和决策能力有望深刻影响各行各业、职业乃至人类生活，引发其在经济活动中整合、潜在的伦理问题以及其实用性和安全性的平衡方面的关键问题。\n\n为了应对这些挑战，本文提出了AI代理经济学的十项原则，提供了一个框架来理解AI代理如何做出决策、影响社会互动以及参与更广泛的经济活动。本文借鉴经济学、决策理论和伦理学，探讨了基本问题，如AI代理是否可能从工具演变为独立实体、其对劳动力市场的影响以及需要哪些伦理保障以使其与人类价值观保持一致。这些原则建立在现有经济理论之上，同时考虑了AI代理的独特特性，为其实现负责任的融入人类系统提供了蓝图。\n\n超越理论洞察，本文强调了未来研究AI可信性、伦理指南和监管监督的紧迫性。随着我们进入一个变革的时代，这项工作不仅是指南，也是行动的呼吁，确保AI代理为人类的进步做出积极贡献，同时应对与其前所未有的能力相关联的风险。', 'title_zh': 'AI代理经济学的十项原则'}
{'arxiv_id': 'arXiv:2505.20214', 'title': 'The Mirage of Multimodality: Where Truth is Tested and Honesty Unravels', 'authors': 'Jiaming Ji, Sitong Fang, Wenjing Cao, Jiahao Li, Xuyao Wang, Juntao Dai, Chi-Min Chan, Sirui Han, Yike Guo, Yaodong Yang', 'link': 'https://arxiv.org/abs/2505.20214', 'abstract': 'Reasoning models have recently attracted significant attention, especially for tasks that involve complex inference. Their strengths exemplify the System II paradigm (slow, structured thinking), contrasting with the System I (rapid, heuristic-driven). Yet, does slower reasoning necessarily lead to greater truthfulness? Our findings suggest otherwise. In this study, we present the first systematic investigation of distortions associated with System I and System II reasoning in multimodal contexts. We demonstrate that slower reasoning models, when presented with incomplete or misleading visual inputs, are more likely to fabricate plausible yet false details to support flawed reasoning -- a phenomenon we term the "Mirage of Multimodality". To examine this, we constructed a 5,000-sample hierarchical prompt dataset annotated by 50 human participants. These prompts gradually increase in complexity, revealing a consistent pattern: slower reasoning models tend to employ depth-first thinking (delving deeper into incorrect premises), whereas faster chat models favor breadth-first inference, exhibiting greater caution under uncertainty. Our results highlight a critical vulnerability of slower reasoning models: although highly effective in structured domains such as mathematics, it becomes brittle when confronted with ambiguous multimodal inputs.', 'abstract_zh': '关于多模态上下文中的系统I和系统II推理偏差的首个系统性研究：缓慢推理的幻象', 'title_zh': '多模态的幻象：真理受考验，誠信被解構'}
{'arxiv_id': 'arXiv:2505.20203', 'title': 'Shutdownable Agents through POST-Agency', 'authors': 'Elliott Thornley', 'link': 'https://arxiv.org/abs/2505.20203', 'abstract': "Many fear that future artificial agents will resist shutdown. I present an idea - the POST-Agents Proposal - for ensuring that doesn't happen. I propose that we train agents to satisfy Preferences Only Between Same-Length Trajectories (POST). I then prove that POST - together with other conditions - implies Neutrality+: the agent maximizes expected utility, ignoring the probability distribution over trajectory-lengths. I argue that Neutrality+ keeps agents shutdownable and allows them to be useful.", 'abstract_zh': '未来人工代理不会抵抗关闭的保障提案：使代理满足等长轨迹偏好的理念及其影响', 'title_zh': '通过POST-Agency实现可关闭代理'}
{'arxiv_id': 'arXiv:2505.20182', 'title': 'An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation', 'authors': 'Shubham Gandhi, Atharva Naik, Yiqing Xie, Carolyn Rose', 'link': 'https://arxiv.org/abs/2505.20182', 'abstract': "We study cost-efficient collaboration between strong and weak language models for repository-level code generation, where the weak model handles simpler tasks at lower cost, and the most challenging tasks are delegated to the strong model. While many works propose architectures for this task, few analyze performance relative to cost. We evaluate a broad spectrum of collaboration strategies: context-based, pipeline-based, and dynamic, on GitHub issue resolution. Our most effective collaborative strategy achieves equivalent performance to the strong model while reducing the cost by 40%. Based on our findings, we offer actionable guidelines for choosing collaboration strategies under varying budget and performance constraints. Our results show that strong-weak collaboration substantially boosts the weak model's performance at a fraction of the cost, pipeline and context-based methods being most efficient. We release the code for our work at this https URL.", 'abstract_zh': '成本效益优化： GitHub 问题解决中的强大与薄弱语言模型协作研究', 'title_zh': '强弱模型协作在网络级别代码生成的实证研究'}
{'arxiv_id': 'arXiv:2505.20170', 'title': 'Program of Equations Thoughts to Solve Algebra Word Problems', 'authors': 'Yunze Lin', 'link': 'https://arxiv.org/abs/2505.20170', 'abstract': 'Solving algebraic word problems (AWPs) has recently emerged as an important natural language processing task. Recently, large language models (LLMs) have demonstrated powerful mathematical capabilities, and the Chain-of-Thought technique, which guides LLMs through step-by-step reasoning, has yielded impressive results. However, this reasoning ability is limited by the computational weaknesses of LLMs themselves, where calculation errors can accumulate, leading to incorrect final answers. To address this, we propose Program of Equations Thoughts (POET), which transforms the task of generating step-by-step reasoning answers into a two-stage task of predicting equations and generating code, offloading complex computations to a Python interpreter to avoid calculation errors in LLMs. Furthermore, we propose Zero-shot POET, which utilizes a manually designed template to enable LLMs to directly generate Python code for one-step solving. Our method achieves accuracies of 95.3% and 98.0% on the PEN and ALG514 datasets, respectively, setting a new state-of-the-art (SOTA). Zero-shot POET also achieves the SOTA result of 95.5% on the DRAW-1K dataset.', 'abstract_zh': '求解代数文字问题（AWPs）已成为一个重要的自然语言处理任务。最近，大型语言模型（LLMs）展示了强大的数学能力， Chain-of-Thought 技术通过逐步推理指导 LLMs，取得了令人印象深刻的成果。然而，这种推理能力受限于 LLMs 自身的计算弱点，其中的计算错误可能导致最终答案错误。为此，我们提出了 Equations Thoughts 程序（POET），将生成逐步推理答案的任务转化为预测方程和生成代码的两阶段任务，将复杂的计算卸载到 Python 解释器上，以避免 LLMs 的计算错误。此外，我们提出了零样本 POET，利用人工设计的模板使 LLMs 直接生成用于一步求解的 Python 代码。我们的方法在 PEN 和 ALG514 数据集上的准确率分别为 95.3% 和 98.0%，创下新的最先进水平（SOTA）。零样本 POET 在 DRAW-1K 数据集上也取得了 95.5% 的 SOTA 结果。', 'title_zh': '方程思想解代数应用题'}
{'arxiv_id': 'arXiv:2505.20148', 'title': 'MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents', 'authors': 'Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2505.20148', 'abstract': 'Spatial Planning is a crucial part in the field of spatial intelligence, which requires the understanding and planning about object arrangements in space perspective. AI agents with the spatial planning ability can better adapt to various real-world applications, including robotic manipulation, automatic assembly, urban planning etc. Recent works have attempted to construct benchmarks for evaluating the spatial intelligence of Multimodal Large Language Models (MLLMs). Nevertheless, these benchmarks primarily focus on spatial reasoning based on typical Visual Question-Answering (VQA) forms, which suffers from the gap between abstract spatial understanding and concrete task execution. In this work, we take a step further to build a comprehensive benchmark called MineAnyBuild, aiming to evaluate the spatial planning ability of open-world AI agents in the Minecraft game. Specifically, MineAnyBuild requires an agent to generate executable architecture building plans based on the given multi-modal human instructions. It involves 4,000 curated spatial planning tasks and also provides a paradigm for infinitely expandable data collection by utilizing rich player-generated content. MineAnyBuild evaluates spatial planning through four core supporting dimensions: spatial understanding, spatial reasoning, creativity, and spatial commonsense. Based on MineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based agents, revealing the severe limitations but enormous potential in their spatial planning abilities. We believe our MineAnyBuild will open new avenues for the evaluation of spatial intelligence and help promote further development for open-world AI agents capable of spatial planning.', 'abstract_zh': 'Spatial Planning Benchmark for Open-World AI Agents in the Minecraft Game: MineAnyBuild', 'title_zh': 'MineAnyBuild: 开放世界AI代理的空间规划基准测试'}
{'arxiv_id': 'arXiv:2505.20120', 'title': 'Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets', 'authors': 'Simpson Zhang, Tennison Liu, Mihaela van der Schaar', 'link': 'https://arxiv.org/abs/2505.20120', 'abstract': 'Current labor markets are strongly affected by the economic forces of adverse selection, moral hazard, and reputation, each of which arises due to $\\textit{incomplete information}$. These economic forces will still be influential after AI agents are introduced, and thus, agents must use metacognitive and strategic reasoning to perform effectively. Metacognition is a form of $\\textit{internal reasoning}$ that includes the capabilities for self-assessment, task understanding, and evaluation of strategies. Strategic reasoning is $\\textit{external reasoning}$ that covers holding beliefs about other participants in the labor market (e.g., competitors, colleagues), making strategic decisions, and learning about others over time. Both types of reasoning are required by agents as they decide among the many $\\textit{actions}$ they can take in labor markets, both within and outside their jobs. We discuss current research into metacognitive and strategic reasoning and the areas requiring further development.', 'abstract_zh': '当前劳动力市场深受逆向选择、道德风险和声誉等经济力量的影响，这些力量均源于信息不完全性。即使是引入了AI代理之后，这些经济力量仍将继续发挥作用，因此代理必须运用元认知和策略性推理来有效地执行任务。元认知是一种内部推理形式，包括自我评估、任务理解以及策略评估的能力。策略性推理是一种外部推理形式，涵盖了对劳动力市场中其他参与者的信念持有（如竞争对手、同事）、制定战略决策以及随时间了解他人。两种类型的推理都是代理在决定可在劳动市场中采取的众多行动时所必需的，不论是工作内外。我们讨论了关于元认知和策略性推理的现有研究以及有待进一步发展的领域。', 'title_zh': '代理需要元认知和策略性推理以适应未来劳动市场'}
{'arxiv_id': 'arXiv:2505.20119', 'title': 'Spatiotemporal Causal Decoupling Model for Air Quality Forecasting', 'authors': 'Jiaming Ma, Guanjun Wang, Sheng Huang, Kuo Yang, Binwu Wang, Pengkun Wang, Yang Wang', 'link': 'https://arxiv.org/abs/2505.20119', 'abstract': "Due to the profound impact of air pollution on human health, livelihoods, and economic development, air quality forecasting is of paramount significance. Initially, we employ the causal graph method to scrutinize the constraints of existing research in comprehensively modeling the causal relationships between the air quality index (AQI) and meteorological features. In order to enhance prediction accuracy, we introduce a novel air quality forecasting model, AirCade, which incorporates a causal decoupling approach. AirCade leverages a spatiotemporal module in conjunction with knowledge embedding techniques to capture the internal dynamics of AQI. Subsequently, a causal decoupling module is proposed to disentangle synchronous causality from past AQI and meteorological features, followed by the dissemination of acquired knowledge to future time steps to enhance performance. Additionally, we introduce a causal intervention mechanism to explicitly represent the uncertainty of future meteorological features, thereby bolstering the model's robustness. Our evaluation of AirCade on an open-source air quality dataset demonstrates over 20\\% relative improvement over state-of-the-art models.", 'abstract_zh': '由于空气污染对人类健康、生计和经济发展有着深刻的影响，空气质量预报至关重要。我们首先采用因果图方法来审查现有研究在综合建模空气质量指数（AQI）与气象特征之间因果关系时的局限性。为了提高预测准确性，我们引入了一种名为AirCade的新颖空气质量预测模型，该模型结合了因果分离方法。AirCade利用时空模块和知识嵌入技术来捕捉AQI的内部动态。随后，我们提出了一种因果分离模块，以解开过去AQI和气象特征的同步因果关系，并将获取的知识传播到未来的时间步长以提高性能。此外，我们引入了一种因果干预机制，以明确表示未来气象特征的不确定性，从而增强模型的鲁棒性。我们在一个开源空气质量数据集上的评估表明，AirCade相对于最先进的模型具有超过20%的相对改进。', 'title_zh': '时空因果解耦模型用于空气质量预报'}
{'arxiv_id': 'arXiv:2505.20094', 'title': 'SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale', 'authors': 'Qi Li, Kun Li, Haozhi Han, Honghui Shang, Xinfu He, Yunquan Zhang, Hong An, Ting Cao, Mao Yang', 'link': 'https://arxiv.org/abs/2505.20094', 'abstract': 'Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.', 'abstract_zh': '科学仿真系统能否同时实现物理一致性、设计可解释性和跨域扩展性？尽管历经几十年的发展，这一三部曲仍难以实现。经典方法如动力蒙特卡罗确保热力学准确性但扩展性差；基于学习的方法提供了效率但往往牺牲物理一致性和可解释性。我们提出SwarmThinkers，这是一种强化学习框架，将原子尺度仿真重塑为一个物理导向的 swarm 智能系统。每个扩散粒子被建模为通过在热力学约束下训练的共享策略网络选择过渡的局部决策代理。重加权机制融合了学习偏好与转换速率，既保持了统计准确性又允许逐步、可解释的决策。训练遵循集中训练、分散执行的范式，使策略能够在不重新培训的情况下跨系统规模、浓度和温度进行泛化。在一项模拟辐射诱导的Fe-Cu合金沉淀基准仿真中，SwarmThinkers是首个在单个A100 GPU上实现全面、物理一致仿真的系统，此前仅超算上的OpenKMC能达到类似效果。它提供了高达4963倍（平均3185倍）的计算速度提升，并降低了485倍的内存使用。通过将粒子视为决策者而非被动采样器，SwarmThinkers标志着科学仿真的范式转变——通过基于代理的智能实现物理一致性、可解释性和扩展性统一。', 'title_zh': 'SwarmThinkers: 学习大规模物理一致的原子级KMC跃迁'}
{'arxiv_id': 'arXiv:2505.19956', 'title': 'DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph', 'authors': 'Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee', 'link': 'https://arxiv.org/abs/2505.19956', 'abstract': 'Text-to-SQL, which translates a natural language question into an SQL query, has advanced with in-context learning of Large Language Models (LLMs). However, existing methods show little improvement in performance compared to randomly chosen demonstrations, and significant performance drops when smaller LLMs (e.g., Llama 3.1-8B) are used. This indicates that these methods heavily rely on the intrinsic capabilities of hyper-scaled LLMs, rather than effectively retrieving useful demonstrations. In this paper, we propose a novel approach for effectively retrieving demonstrations and generating SQL queries. We construct a Deep Contextual Schema Link Graph, which contains key information and semantic relationship between a question and its database schema items. This graph-based structure enables effective representation of Text-to-SQL samples and retrieval of useful demonstrations for in-context learning. Experimental results on the Spider benchmark demonstrate the effectiveness of our approach, showing consistent improvements in SQL generation performance and efficiency across both hyper-scaled LLMs and small LLMs. Our code will be released.', 'abstract_zh': '基于上下文学习的大语言模型在文本到SQL转换中的有效示范检索与SQL生成方法', 'title_zh': 'DCG-SQL: 提高基于上下文学习的文本到SQL能力的深度上下文模式链接图'}
{'arxiv_id': 'arXiv:2505.19927', 'title': 'TCP: a Benchmark for Temporal Constraint-Based Planning', 'authors': 'Zifeng Ding, Sikuan Yan, Zhangdie Yuan, Xianglong Hu, Fangru Lin, Andreas Vlachos', 'link': 'https://arxiv.org/abs/2505.19927', 'abstract': "Temporal reasoning and planning are essential capabilities for large language models (LLMs), yet most existing benchmarks evaluate them in isolation and under limited forms of complexity. To address this gap, we introduce the Temporal Constraint-based Planning (TCP) benchmark, that jointly assesses both capabilities. Each instance in TCP features a naturalistic dialogue around a collaborative project, where diverse and interdependent temporal constraints are explicitly or implicitly expressed, and models must infer an optimal schedule that satisfies all constraints. To construct TCP, we first generate abstract problem prototypes that are paired with realistic scenarios from various domains and enriched into dialogues using an LLM. A human quality check is performed on a sampled subset to confirm the reliability of our benchmark. We evaluate state-of-the-art LLMs and find that even the strongest models struggle with TCP, highlighting its difficulty and revealing limitations in LLMs' temporal constraint-based planning abilities. We analyze underlying failure cases, open source our benchmark, and hope our findings can inspire future research.", 'abstract_zh': '基于时间约束的规划基准（TCP）：同时评估时间和规划能力的综合性测试', 'title_zh': 'TCP：基于时间约束的规划基准'}
{'arxiv_id': 'arXiv:2505.19847', 'title': 'DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems', 'authors': 'Wenqing Zhou, Yuxuan Yan, Qianqian Yang', 'link': 'https://arxiv.org/abs/2505.19847', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the capabilities of language models by integrating external knowledge. Due to the diversity of data sources and the constraints of memory and computing resources, real-world data is often scattered in multiple devices. Conventional RAGs that store massive amounts of scattered data centrally face increasing privacy concerns and high computational costs. Additionally, RAG in a central node raises latency issues when searching over a large-scale knowledge base. To address these challenges, we propose a distributed Knowledge Graph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where each edge device maintains a local knowledge base without the need to share it with the cloud, instead sharing only summaries of its knowledge. Specifically, DGRAG has two main phases. In the Distributed Knowledge Construction phase, DGRAG organizes local knowledge using knowledge graphs, generating subgraph summaries and storing them in a summary database in the cloud as information sharing. In the Collaborative Retrieval and Generation phase, DGRAG first performs knowledge retrieval and answer generation locally, and a gate mechanism determines whether the query is beyond the scope of local knowledge or processing capabilities. For queries that exceed the local knowledge scope, the cloud retrieves knowledge from the most relevant edges based on the summaries and generates a more precise answer. Experimental results demonstrate the effectiveness of the proposed DGRAG approach in significantly improving the quality of question-answering tasks over baseline approaches.', 'abstract_zh': '基于知识图谱的分布式检索增强生成（DGRAG）方法', 'title_zh': '基于分布式图检索增强生成的边缘-云系统方法'}
{'arxiv_id': 'arXiv:2505.19792', 'title': 'Types of Relations: Defining Analogies with Category Theory', 'authors': 'Claire Ott, Frank Jäkel', 'link': 'https://arxiv.org/abs/2505.19792', 'abstract': 'In order to behave intelligently both humans and machines have to represent their knowledge adequately for how it is used. Humans often use analogies to transfer their knowledge to new domains, or help others with this transfer via explanations. Hence, an important question is: What representation can be used to construct, find, and evaluate analogies? In this paper, we study features of a domain that are important for constructing analogies. We do so by formalizing knowledge domains as categories. We use the well-known example of the analogy between the solar system and the hydrogen atom to demonstrate how to construct domain categories. We also show how functors, pullbacks, and pushouts can be used to define an analogy, describe its core and a corresponding blend of the underlying domains.', 'abstract_zh': '为了智能地行为，人类和机器都需要适当表示其知识以适应其用途。重要的是：哪种表示可以用于构造、查找和评估类比？在这种论文中，我们通过将知识领域形式化为范畴来研究用于构造类比的重要领域特征。我们以太阳系与氢原子的类比为例，演示如何构造领域范畴。我们还展示了如何使用因子、拉回和推出来定义一个类比，描述其核心以及底层领域相应的融合。', 'title_zh': '关系类型：用范畴论定义类比'}
{'arxiv_id': 'arXiv:2505.19788', 'title': 'Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured Multi-Turn Decomposition', 'authors': 'Zihao Zeng, Xuyao Huang, Boxiu Li, Hao Zhang, Zhijie Deng', 'link': 'https://arxiv.org/abs/2505.19788', 'abstract': 'Large Reasoning Models (LRMs) are criticized for the excessively lengthy Chain-of-Thought (CoT) to derive the final answer, suffering from high first-token and overall latency. Typically, the CoT of LRMs mixes multiple thinking units; each unit attempts to produce a candidate answer to the original query. Hence, a natural idea to improve efficiency is to reduce the unit number. Yet, the fact that the thinking units in vanilla CoT cannot be explicitly managed renders doing so challenging. This paper introduces Multi-Turn Decomposition (MinD) to decode conventional CoT into a sequence of explicit, structured, and turn-wise interactions to bridge the gap. In MinD, the model provides a multi-turn response to the query, where each turn embraces a thinking unit and yields a corresponding answer. The subsequent turns can reflect, verify, revise, or explore alternative approaches to both the thinking and answer parts of earlier ones. This not only makes the answer delivered more swiftly, but also enables explicit controls over the iterative reasoning process (i.e., users may halt or continue at any turn). We follow a supervised fine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We first rephrase the outputs of an LRM into multi-turn formats by prompting another LLM, and then tune the LRM with such data. Observing that the tuned model tends to consume even more tokens than the original one (probably due to that the multi-turn formats introduce additional answer tokens), we advocate leveraging RL algorithms like GRPO to prioritize correct outputs with fewer turns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up to ~70% reduction in both output token usage and time to first token (TTFT), while maintaining competitive performance on reasoning benchmarks such as MATH-500, AIME24, AMC23, and GPQA-Diamond.', 'abstract_zh': '多轮分解以减少链式思考的大型推理模型（MinD）：多轮分解以减少链式思考的大型推理模型', 'title_zh': '尽力而为胜于完美：通过结构化多轮分解解锁高效推理'}
{'arxiv_id': 'arXiv:2505.19762', 'title': 'Language Model-Enhanced Message Passing for Heterophilic Graph Learning', 'authors': 'Wenjun Wang, Dawei Cheng', 'link': 'https://arxiv.org/abs/2505.19762', 'abstract': "Traditional graph neural networks (GNNs), which rely on homophily-driven message passing, struggle with heterophilic graphs where connected nodes exhibit dissimilar features and different labels. While existing methods address heterophily through graph structure refinement or adaptation of neighbor aggregation functions, they often overlook the semantic potential of node text, rely on suboptimal message representation for propagation and compromise performance on homophilic graphs. To address these limitations, we propose a novel language model (LM)-enhanced message passing approach for heterophilic graph leaning (LEMP4HG). Specifically, in the context of text-attributed graph, we provide paired node texts for LM to generate their connection analysis, which are encoded and then fused with paired node textual embeddings through a gating mechanism. The synthesized messages are semantically enriched and adaptively balanced with both nodes' information, which mitigates contradictory signals when neighbor aggregation in heterophilic regions. Furthermore, we introduce an active learning strategy guided by our heuristic MVRD (Modulated Variation of Reliable Distance), selectively enhancing node pairs suffer most from message passing, reducing the cost of analysis generation and side effects on homophilic regions. Extensive experiments validate that our approach excels on heterophilic graphs and performs robustly on homophilic ones, with a graph convolutional network (GCN) backbone and a practical budget.", 'abstract_zh': '基于语言模型增强的消息传递方法用于异质图学习（LEMP4HG）', 'title_zh': '语言模型增强的消息传递方法在异类图学习中的应用'}
{'arxiv_id': 'arXiv:2505.19716', 'title': 'Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting', 'authors': 'Yifan Wu, Jingze Shi, Bingheng Wu, Jiayi Zhang, Xiaotian Lin, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2505.19716', 'abstract': "Existing chain-of-thought (CoT) distillation methods can effectively transfer reasoning abilities to base models but suffer from two major limitations: excessive verbosity of reasoning traces and inadequate adaptability to problem difficulty. Long reasoning traces significantly increase inference costs, and uniform-length solutions prevent base models from learning adaptive reasoning strategies. To address these issues, we propose a difficulty-aware prompting (DAP) method to dynamically shorten reasoning traces without performance loss. In our approach, a large teacher model first judges each problem's difficulty and then rewrites its reasoning traces to an appropriate shorter length, yielding concise yet complete reasoning traces. Leveraging the DAP pipeline, we curate a distilled dataset called LiteCoT consisting of 100K concise reasoning examples, with solutions averaging only 720 tokens (an order of magnitude shorter than typical CoTs). Using LiteCoT, we distilled a new family of reasoning models called Liter (1.5B, 7B, and 32B) based on the Qwen2.5 architecture. Experiments show that a student model fine-tuned on just 100K of these difficulty-pruned CoT samples outperforms a model distilled on 800K original Long CoT samples, while significantly reducing training and inference costs. Our method also generalizes well: across 11 diverse benchmarks, the shorter difficulty-aware CoTs achieve equal or better accuracy than Long chains, using far fewer tokens. For example, on the challenging AIME24 exam, our approach reaches $74.2\\%$ Pass@1 using only about 5K inference tokens, surpassing other methods that consume many more tokens. Our code and data are available at this https URL.", 'abstract_zh': '基于难度感知的提示方法（DAP）：一种动态缩短推理路径而无需性能损失的方法', 'title_zh': '简洁推理，重大提升：基于难度感知的剪枝长推理轨迹'}
{'arxiv_id': 'arXiv:2505.19690', 'title': 'Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in Large Reasoning Models', 'authors': 'Baihui Zheng, Boren Zheng, Kerui Cao, Yingshui Tan, Zhendong Liu, Weixun Wang, Jiaheng Liu, Jian Yang, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang', 'link': 'https://arxiv.org/abs/2505.19690', 'abstract': 'Despite the remarkable proficiency of \\textit{Large Reasoning Models} (LRMs) in handling complex reasoning tasks, their reliability in safety-critical scenarios remains uncertain. Existing evaluations primarily assess response-level safety, neglecting a critical issue we identify as \\textbf{\\textit{Superficial Safety Alignment} (SSA)} -- a phenomenon where models produce superficially safe outputs while internal reasoning processes fail to genuinely detect and mitigate underlying risks, resulting in inconsistent safety behaviors across multiple sampling attempts. To systematically investigate SSA, we introduce \\textbf{Beyond Safe Answers (BSA)} bench, a novel benchmark comprising 2,000 challenging instances organized into three distinct SSA scenario types and spanning nine risk categories, each meticulously annotated with risk rationales. Evaluations of 19 state-of-the-art LRMs demonstrate the difficulty of this benchmark, with top-performing models achieving only 38.0\\% accuracy in correctly identifying risk rationales. We further explore the efficacy of safety rules, specialized fine-tuning on safety reasoning data, and diverse decoding strategies in mitigating SSA. Our work provides a comprehensive assessment tool for evaluating and improving safety reasoning fidelity in LRMs, advancing the development of genuinely risk-aware and reliably safe AI systems.', 'abstract_zh': '尽管大规模推理模型（LRMs）在处理复杂推理任务方面表现出色，但在安全关键场景中的可靠性仍然存在不确定性。现有的评估主要评估响应级别的安全性，忽略了我们所识别的一个关键问题——表象安全性对齐（SSA）现象——即模型产生表面上安全的输出，而内部推理过程未能真正检测和缓解潜在风险，导致多次采样尝试中表现出不一致的安全行为。为系统地研究SSA现象，我们引入了超越安全答案（BSA）基准，这是一个包含2,000个具有挑战性的实例的新基准，这些实例被组织成三种不同的SSA场景类型和九个风险类别，并详细记录了风险理由。对19种最先进的LRMs的评估显示，这一基准的难度很大，顶级模型仅在正确识别风险理由方面达到38.0%的准确率。我们进一步探讨了安全性规则的有效性、专门针对安全性推理数据的微调以及多样性解码策略在减轻SSA方面的作用。我们的工作提供了一个全面的评估工具，用于评估和改进LRMs中的安全性推理精确性，推动真正具备风险意识和可靠安全的AI系统的发展。', 'title_zh': '超越安全答案：评估大型推理模型真正风险意识的基准'}
{'arxiv_id': 'arXiv:2505.19550', 'title': 'Turing Test 2.0: The General Intelligence Threshold', 'authors': 'Georgios Mappouras', 'link': 'https://arxiv.org/abs/2505.19550', 'abstract': 'With the rise of artificial intelligence (A.I.) and large language models like Chat-GPT, a new race for achieving artificial general intelligence (A.G.I) has started. While many speculate how and when A.I. will achieve A.G.I., there is no clear agreement on how A.G.I. can be detected in A.I. models, even when popular tools like the Turing test (and its modern variations) are used to measure their intelligence. In this work, we discuss why traditional methods like the Turing test do not suffice for measuring or detecting A.G.I. and provide a new, practical method that can be used to decide if a (computer or any other) system has reached or surpassed A.G.I. To achieve this, we make two new contributions. First, we present a clear definition for general intelligence (G.I.) and set a G.I. threshold (G.I.T.) that can be used to distinguish between systems that achieve A.G.I. and systems that do not. Second, we present a new framework on how to construct tests that can detect if a system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass way. We call this novel framework the Turing Tests 2.0. We then demonstrate real-life examples of applying tests that follow our Turing Tests 2.0 framework on modern A.I. models.', 'abstract_zh': '随着人工智能（A.I.）和大型语言模型（如Chat-GPT）的兴起，一场实现人工通用智能（A.G.I.）的新竞赛已经启动。尽管许多人推测A.I.何时能够实现A.G.I.，但对于如何检测A.I.模型是否达到A.G.I.仍没有明确的共识，即使使用图灵测试（及其现代变体）这样的流行工具来衡量其智能水平亦是如此。在本研究中，我们讨论了为什么传统的图灵测试等方法不足以衡量或检测A.G.I.，并提供了一种新的、实用的方法，可以用来判断一个系统（无论是计算机还是其他系统）是否达到了或超越了A.G.I.。为了实现这一目标，我们做出了两项新的贡献。首先，我们提供了一个明确的人类通用智能（G.I.）的定义，并设定了一个通用智能门槛（G.I.T.），用于区分能够实现A.G.I.的系统和不能实现A.G.I.的系统。其次，我们提出了一个新框架，说明如何构建能以简单、全面且明确的失败/通过方式检测系统是否实现了通用智能的测试方法。我们称这一新颖框架为“图灵测试2.0”。然后，我们展示了如何在现代A.I.模型上应用遵循图灵测试2.0框架的测试示例。', 'title_zh': '图灵测试2.0：通用智能门槛'}
{'arxiv_id': 'arXiv:2505.19501', 'title': 'Genome-Bench: A Scientific Reasoning Benchmark from Real-World Expert Discussions', 'authors': 'Ming Yin, Yuanhao Qu, Dyllan Liu, Ling Yang, Le Cong, Mengdi Wang', 'link': 'https://arxiv.org/abs/2505.19501', 'abstract': 'In this short report, we present an automated pipeline tailored for the genomics domain and introduce \\textit{Genome-Bench}, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning friendly multiple-choice questions format, supported by 3000+ high quality question answer pairs spanning foundational biology, experimental troubleshooting, tool usage, and beyond. To our knowledge, this is the first end-to-end pipeline for teaching LLMs to reason from scientific discussions, with promising potential for generalization across scientific domains beyond biology.', 'abstract_zh': '在本简短报告中，我们提出了一套针对基因组学领域的自动化流程，并介绍了基于基因工程科学论坛讨论构建的新基准 \\textit{Genome-Bench}。我们的流程将原始交互转换为强化学习友好的多项选择题格式，包含3000多个高质量的问题及答案对，涵盖基础生物学、实验故障排除、工具使用等领域。据我们所知，这是首个端到端的教学流水线，用于让大型语言模型从科学讨论中进行推理，具有在生物学之外的科学领域中泛化的潜在前景。', 'title_zh': 'Genome-Bench: 一个来自现实专家讨论的科学推理基准'}
{'arxiv_id': 'arXiv:2505.19442', 'title': 'Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning', 'authors': 'Dutao Zhang, Sergey Kovalchuk, YuLong He', 'link': 'https://arxiv.org/abs/2505.19442', 'abstract': 'Controllable code generation, the ability to synthesize code that follows a specified style while maintaining functionality, remains a challenging task. We propose a two-stage training framework combining contrastive learning and conditional decoding to enable flexible style control. The first stage aligns code style representations with semantic and structural features. In the second stage, we fine-tune a language model (e.g., Flan-T5) conditioned on the learned style vector to guide generation. Our method supports style interpolation and user personalization via lightweight mixing. Compared to prior work, our unified framework offers improved stylistic control without sacrificing code correctness. This is among the first approaches to combine contrastive alignment with conditional decoding for style-guided code generation.', 'abstract_zh': '可控代码生成：一种结合对比学习和条件解码的两阶段训练框架以实现灵活的样式控制', 'title_zh': 'Style2Code：一种基于双模态对比表示学习的风格可控代码生成框架'}
{'arxiv_id': 'arXiv:2505.19414', 'title': 'Toward Physics-Informed Machine Learning for Data Center Operations: A Tropical Case Study', 'authors': 'Ruihang Wang, Zhiwei Cao, Qingang Zhang, Rui Tan, Yonggang Wen, Tommy Leung, Stuart Kennedy, Justin Teoh', 'link': 'https://arxiv.org/abs/2505.19414', 'abstract': 'Data centers are the backbone of computing capacity. Operating data centers in the tropical regions faces unique challenges due to consistently high ambient temperature and elevated relative humidity throughout the year. These conditions result in increased cooling costs to maintain the reliability of the computing systems. While existing machine learning-based approaches have demonstrated potential to elevate operations to a more proactive and intelligent level, their deployment remains dubious due to concerns about model extrapolation capabilities and associated system safety issues. To address these concerns, this article proposes incorporating the physical characteristics of data centers into traditional data-driven machine learning solutions. We begin by introducing the data center system, including the relevant multiphysics processes and the data-physics availability. Next, we outline the associated modeling and optimization problems and propose an integrated, physics-informed machine learning system to address them. Using the proposed system, we present relevant applications across varying levels of operational intelligence. A case study on an industry-grade tropical data center is provided to demonstrate the effectiveness of our approach. Finally, we discuss key challenges and highlight potential future directions.', 'abstract_zh': '数据中心是计算能力的支柱。在热带地区运营数据中心面临着独特的挑战，由于全年的高温和高湿度，这会导致更高的冷却成本以维持计算系统的可靠性。虽然现有的基于机器学习的方法展现了提升运营至更主动和智能水平的潜力，但其部署仍因模型外推能力和相关系统安全问题的担忧而受到质疑。为解决这些问题，本文提出将数据中心的物理特性整合到传统的数据驱动机器学习解决方案中。我们首先介绍数据中心系统，包括相关的多物理过程和数据-物理可用性。接着，我们概述相关的建模和优化问题，并提出一个整合的、基于物理的方法的机器学习系统来解决这些问题。通过所提出的方法，我们展示了不同层次操作智能的相关应用。提供了一个工业级热带数据中心的案例研究，以证明我们方法的有效性。最后，我们讨论了关键挑战并指出了潜在的未来方向。', 'title_zh': '面向数据中心运营的物理知情机器学习研究：以热带地区为例'}
{'arxiv_id': 'arXiv:2505.19409', 'title': 'Fusion Intelligence for Digital Twinning AI Data Centers: A Synergistic GenAI-PhyAI Approach', 'authors': 'Ruihang Wang, Minghao Li, Zhiwei Cao, Jimin Jia, Kyle Guan, Yonggang Wen', 'link': 'https://arxiv.org/abs/2505.19409', 'abstract': "The explosion in artificial intelligence (AI) applications is pushing the development of AI-dedicated data centers (AIDCs), creating management challenges that traditional methods and standalone AI solutions struggle to address. While digital twins are beneficial for AI-based design validation and operational optimization, current AI methods for their creation face limitations. Specifically, physical AI (PhyAI) aims to capture the underlying physical laws, which demands extensive, case-specific customization, and generative AI (GenAI) can produce inaccurate or hallucinated results. We propose Fusion Intelligence, a novel framework synergizing GenAI's automation with PhyAI's domain grounding. In this dual-agent collaboration, GenAI interprets natural language prompts to generate tokenized AIDC digital twins. Subsequently, PhyAI optimizes these generated twins by enforcing physical constraints and assimilating real-time data. Case studies demonstrate the advantages of our framework in automating the creation and validation of AIDC digital twins. These twins deliver predictive analytics to support power usage effectiveness (PUE) optimization in the design stage. With operational data collected, the digital twin accuracy is further improved compared with pure physics-based models developed by human experts. Fusion Intelligence offers a promising pathway to accelerate digital transformation. It enables more reliable and efficient AI-driven digital transformation for a broad range of mission-critical infrastructures.", 'abstract_zh': '人工智能应用的爆炸式增长推动了专用人工智能数据中心(AIDCs)的发展，传统方法和独立的人工智能解决方案难以应对由此产生的管理挑战。尽管数字孪生在基于人工智能的设计验证和运营优化方面具有优势，但目前用于创建数字孪生的人工智能方法存在局限性。具体而言，物理人工智能(PhyAI)旨在捕捉底层物理定律，这需要广泛的、特定案例的定制，而生成人工智能(GenAI)则可能产生不准确或幻觉的结果。我们提出了融合智能(Fusion Intelligence)这一新颖框架，该框架结合了GenAI的自动化优势与PhyAI的专业背景。在此双代理协作中，GenAI通过解释自然语言提示来生成标记化的AIDC数字孪生。随后，PhyAI通过施加物理约束并融合实时数据来优化这些生成的数字孪生。案例研究证明了该框架在自动化创建和验证AIDC数字孪生方面的优势。这些数字孪生能够提供预测分析，以支持设计阶段的PUE优化。随着运营数据的收集，与由人类专家开发的基于物理学的模型相比，数字孪生的准确性得到了进一步提高。融合智能为加速数字化转型提供了有前景的道路，能够为多类关键基础设施实现更可靠和高效的基于人工智能的数字化转型。', 'title_zh': '数字孪生AI数据中心的融合智能：一种协同生成人工智能-物理人工智能方法'}
{'arxiv_id': 'arXiv:2505.19361', 'title': 'Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments', 'authors': 'Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran, Gerardo Simari', 'link': 'https://arxiv.org/abs/2505.19361', 'abstract': 'The deployment of pre-trained perception models in novel environments often leads to performance degradation due to distributional shifts. Although recent artificial intelligence approaches for metacognition use logical rules to characterize and filter model errors, improving precision often comes at the cost of reduced recall. This paper addresses the hypothesis that leveraging multiple pre-trained models can mitigate this recall reduction. We formulate the challenge of identifying and managing conflicting predictions from various models as a consistency-based abduction problem. The input predictions and the learned error detection rules derived from each model are encoded in a logic program. We then seek an abductive explanation--a subset of model predictions--that maximizes prediction coverage while ensuring the rate of logical inconsistencies (derived from domain constraints) remains below a specified threshold. We propose two algorithms for this knowledge representation task: an exact method based on Integer Programming (IP) and an efficient Heuristic Search (HS). Through extensive experiments on a simulated aerial imagery dataset featuring controlled, complex distributional shifts, we demonstrate that our abduction-based framework outperforms individual models and standard ensemble baselines, achieving, for instance, average relative improvements of approximately 13.6% in F1-score and 16.6% in accuracy across 15 diverse test datasets when compared to the best individual model. Our results validate the use of consistency-based abduction as an effective mechanism to robustly integrate knowledge from multiple imperfect reasoners in challenging, novel scenarios.', 'abstract_zh': '利用多个预训练模型减轻新颖环境下的召回率降低问题：基于一致性 abduction 的元认知方法', 'title_zh': '基于一致性的 abduction 推理在多预训练模型感知错误的新型环境中的应用'}
{'arxiv_id': 'arXiv:2505.19347', 'title': 'PatentMind: A Multi-Aspect Reasoning Graph for Patent Similarity Evaluation', 'authors': 'Yongmin Yoo, Qiongkai Xu, Longbing Cao', 'link': 'https://arxiv.org/abs/2505.19347', 'abstract': 'Patent similarity evaluation plays a critical role in intellectual property analysis. However, existing methods often overlook the intricate structure of patent documents, which integrate technical specifications, legal boundaries, and application contexts. We introduce PatentMind, a novel framework for patent similarity assessment based on a Multi-Aspect Reasoning Graph (MARG). PatentMind decomposes patents into three core dimensions: technical feature, application domain, and claim scope, to compute dimension-specific similarity scores. These scores are dynamically weighted through a four-stage reasoning process which integrates contextual signals to emulate expert-level judgment. To support evaluation, we construct PatentSimBench, a human-annotated benchmark comprising 500 patent pairs. Experimental results demonstrate that PatentMind achieves a strong correlation ($r=0.938$) with expert annotations, significantly outperforming embedding-based models and advanced prompt engineering this http URL results highlight the effectiveness of modular reasoning frameworks in overcoming key limitations of embedding-based methods for analyzing patent similarity.', 'abstract_zh': '专利相似性评估在知识产权分析中发挥着关键作用。然而，现有方法往往忽视了专利文件的复杂结构，这些文件整合了技术规范、法律边界和应用背景。我们提出了基于多方面推理图（MARG）的新型专利相似性评估框架PatentMind。PatentMind将专利分解为核心维度：技术特征、应用领域和权利要求范围，以计算维度特定的相似性分数。这些分数通过四阶段推理过程动态加权，该过程整合上下文信号以模拟专家级判断。为了支持评估，我们构建了包含500个专利配对的人工标注基准PatentSimBench。实验结果表明，PatentMind与专家注释之间具有强相关性（$r=0.938$），显著优于基于嵌入的方法和高级提示工程方法。这些结果突显了模块化推理框架在克服基于嵌入方法的关键限制方面的有效性，特别是在分析专利相似性方面。', 'title_zh': 'PatentMind: 一种专利相似性评估的多方面推理图'}
{'arxiv_id': 'arXiv:2505.19317', 'title': 'Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics', 'authors': 'Tin Nguyen, Jiannan Xu, Zora Che, Phuong-Anh Nguyen-Le, Rushil Dandamudi, Donald Braman, Furong Huang, Hal Daumé III, Zubin Jelveh', 'link': 'https://arxiv.org/abs/2505.19317', 'abstract': 'Although popularized AI fairness metrics, e.g., demographic parity, have uncovered bias in AI-assisted decision-making outcomes, they do not consider how much effort one has spent to get to where one is today in the input feature space. However, the notion of effort is important in how Philosophy and humans understand fairness. We propose a philosophy-informed way to conceptualize and evaluate Effort-aware Fairness (EaF) based on the concept of Force, or temporal trajectory of predictive features coupled with inertia. In addition to our theoretical formulation of EaF metrics, our empirical contributions include: 1/ a pre-registered human subjects experiment, which demonstrates that for both stages of the (individual) fairness evaluation process, people consider the temporal trajectory of a predictive feature more than its aggregate value; 2/ pipelines to compute Effort-aware Individual/Group Fairness in the criminal justice and personal finance contexts. Our work may enable AI model auditors to uncover and potentially correct unfair decisions against individuals who spent significant efforts to improve but are still stuck with systemic/early-life disadvantages outside their control.', 'abstract_zh': '尽管普及了诸如人口均等等AI公平性指标，这些指标揭示了AI辅助决策结果中的偏见，但它们没有考虑一个人达到当前输入特征空间位置所付出的努力。然而，在哲学和人类对公平的理解中，努力的概念是重要的。我们提出了一种基于力的概念，即预测特征的时间轨迹与惯性结合的哲学启发式方法来构思和评估知努力公平性（EaF）。除了我们对EaF指标的理论框架，我们的实证贡献还包括：1/ 注册的双盲人类被试实验，结果表明，在（个体）公平性评估过程的两个阶段中，人们更关注预测特征的时间轨迹而非其聚合值；2/ 刑事司法和个人金融领域的计算知努力个体/群体公平性的流程。我们的工作可能使AI模型审计者能够揭示并可能修正那些尽管付出巨大努力但仍遭受系统性/童年期无法控制的不利因素影响而导致的不公平决定。', 'title_zh': '考虑努力的公平性：将哲学启发的人本主义努力观念融入算法公平性度量'}
{'arxiv_id': 'arXiv:2505.19277', 'title': 'Next Token Prediction Is a Dead End for Creativity', 'authors': 'Ibukun Olatunji, Mark Sheppard', 'link': 'https://arxiv.org/abs/2505.19277', 'abstract': 'This paper argues that token prediction is fundamentally misaligned with real creativity. While next-token models have enabled impressive advances in language generation, their architecture favours surface-level coherence over spontaneity, originality, and improvisational risk. We use battle rap as a case study to expose the limitations of predictive systems, demonstrating that they cannot truly engage in adversarial or emotionally resonant exchanges. By reframing creativity as an interactive process rather than a predictive output, we offer a vision for AI systems that are more expressive, responsive, and aligned with human creative practice.', 'abstract_zh': '本文 argue认为token预测从根本上与真正的创造力不一致。虽然下一个token模型在语言生成方面取得了令人印象深刻的进展，但它们的架构更倾向于表面一致性而非自发性、原创性和即兴冒险。我们以battle rap为例，揭示预测系统的局限性，证明它们无法真正进行对抗性或情感共鸣的交流。通过将创造力重新定义为一种互动过程而非预测输出，我们提出了更加表达性、响应性和与人类创造性实践相一致的AI系统的愿景。', 'title_zh': '下一个 token 预测是创造力的死胡同。'}
{'arxiv_id': 'arXiv:2505.19220', 'title': 'DeCoDe: Defer-and-Complement Decision-Making via Decoupled Concept Bottleneck Models', 'authors': 'Chengbo He, Bochao Zou, Junliang Xing, Jiansheng Chen, Yuanchun Shi, Huimin Ma', 'link': 'https://arxiv.org/abs/2505.19220', 'abstract': "In human-AI collaboration, a central challenge is deciding whether the AI should handle a task, be deferred to a human expert, or be addressed through collaborative effort. Existing Learning to Defer approaches typically make binary choices between AI and humans, neglecting their complementary strengths. They also lack interpretability, a critical property in high-stakes scenarios where users must understand and, if necessary, correct the model's reasoning. To overcome these limitations, we propose Defer-and-Complement Decision-Making via Decoupled Concept Bottleneck Models (DeCoDe), a concept-driven framework for human-AI collaboration. DeCoDe makes strategy decisions based on human-interpretable concept representations, enhancing transparency throughout the decision process. It supports three flexible modes: autonomous AI prediction, deferral to humans, and human-AI collaborative complementarity, selected via a gating network that takes concept-level inputs and is trained using a novel surrogate loss that balances accuracy and human effort. This approach enables instance-specific, interpretable, and adaptive human-AI collaboration. Experiments on real-world datasets demonstrate that DeCoDe significantly outperforms AI-only, human-only, and traditional deferral baselines, while maintaining strong robustness and interpretability even under noisy expert annotations.", 'abstract_zh': '基于解耦概念瓶颈模型的犹豫与互补决策框架：面向人类-人工智能协作的概念驱动方法', 'title_zh': 'DeCoDe: 分离概念瓶颈模型下的延迟与补充决策机制'}
{'arxiv_id': 'arXiv:2505.19219', 'title': 'Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding', 'authors': 'Shiyue Wang, Haozheng Xu, Yuhan Zhang, Jingran Lin, Changhong Lu, Xiangfeng Wang, Wenhao Li', 'link': 'https://arxiv.org/abs/2505.19219', 'abstract': 'Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial intelligence and robotics, requiring the computation of collision-free paths for multiple agents navigating from their start locations to designated goals. As autonomous systems become increasingly prevalent in warehouses, urban transportation, and other complex environments, MAPF has evolved from a theoretical challenge to a critical enabler of real-world multi-robot coordination. This comprehensive survey bridges the long-standing divide between classical algorithmic approaches and emerging learning-based methods in MAPF research. We present a unified framework that encompasses search-based methods (including Conflict-Based Search, Priority-Based Search, and Large Neighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP formulations), and data-driven techniques (reinforcement learning, supervised learning, and hybrid strategies). Through systematic analysis of experimental practices across 200+ papers, we uncover significant disparities in evaluation methodologies, with classical methods typically tested on larger-scale instances (up to 200 by 200 grids with 1000+ agents) compared to learning-based approaches (predominantly 10-100 agents). We provide a comprehensive taxonomy of evaluation metrics, environment types, and baseline selections, highlighting the need for standardized benchmarking protocols. Finally, we outline promising future directions including mixed-motive MAPF with game-theoretic considerations, language-grounded planning with large language models, and neural solver architectures that combine the rigor of classical methods with the flexibility of deep learning. This survey serves as both a comprehensive reference for researchers and a practical guide for deploying MAPF solutions in increasingly complex real-world applications.', 'abstract_zh': '多智能体路径规划（MAPF）是人工智能与机器人技术中的一个基础问题，要求为多个从起始位置导航到指定目标的智能体计算无碰撞路径。随着自主系统在仓库、城市交通和其他复杂环境中的日益普及，MAPF已从理论挑战转变为实现实用多机器人协调的关键使能器。本文综述跨越了经典算法方法与新兴基于学习方法之间的长期鸿沟，提出了一个统一框架，涵盖了搜索方法（冲突基搜索、优先级基搜索、大邻域搜索）、编译方法（SAT、SMT、CSP、ASP和MIP形式化）以及数据驱动技术（强化学习、监督学习和混合策略）。通过系统分析200多篇论文中的实验实践，揭示了评估方法学上的显著差异，经典方法通常在更大规模实例上测试（最大200×200网格，1000多个智能体），而基于学习的方法则主要测试10-100个智能体规模的问题。本文还提供了评估指标、环境类型和基线选择的全面分类，突显了标准化基准测评协议的需求。最后，本文提出了包括基于博弈论考虑的混合动机MAPF、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构在内的未来研究方向。本文综述既为研究者提供了全面的参考，也为在日益复杂的实际应用中部署MAPF解决方案提供了实用指南。', 'title_zh': '路径交汇：经典与学习导向的多智能体路径规划综述'}
{'arxiv_id': 'arXiv:2505.19197', 'title': 'Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance', 'authors': 'Chanyeol Choi, Jihoon Kwon, Minjae Kim, Juneha Hwang, Minsoo Ha, Chaewoon Kim, Jaeseon Ha, Suyeol Yun, Jin Kim', 'link': 'https://arxiv.org/abs/2505.19197', 'abstract': 'Extracting structured and quantitative insights from unstructured financial filings is essential in investment research, yet remains time-consuming and resource-intensive. Conventional approaches in practice rely heavily on labor-intensive manual processes, limiting scalability and delaying the research workflow. In this paper, we propose an efficient and scalable method for accurately extracting quantitative insights from unstructured financial documents, leveraging a multi-agent system composed of large language models. Our proposed multi-agent system consists of two specialized agents: the \\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The \\textit{Extraction Agent} automatically identifies key performance indicators from unstructured financial text, standardizes their formats, and verifies their accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates executable SQL statements from natural language queries, allowing users to access structured data accurately without requiring familiarity with the database schema. Through experiments, we demonstrate that our proposed system effectively transforms unstructured text into structured data accurately and enables precise retrieval of key information. First, we demonstrate that our system achieves approximately 95\\% accuracy in transforming financial filings into structured data, matching the performance level typically attained by human annotators. Second, in a human evaluation of the retrieval task -- where natural language queries are used to search information from structured data -- 91\\% of the responses were rated as correct by human evaluators. In both evaluations, our system generalizes well across financial document types, consistently delivering reliable performance.', 'abstract_zh': '从非结构化财务文件中提取结构化和定量的见解对于投资研究至关重要，但依然耗时且资源密集。现有实践中常用的方法依赖于劳动密集型的手动流程，限制了可扩展性并延迟了研究工作流程。本文提出了一种高效且可扩展的方法，利用大型语言模型组成的多代理系统，从非结构化财务文档中准确提取定量的见解。我们提出的多代理系统包括两个专门的代理：提取代理和文本到SQL代理。提取代理自动从非结构化财务文本中识别关键绩效指标，标准化其格式并验证其准确性。另一方面，文本到SQL代理生成可执行的SQL语句，允许用户通过自然语言查询准确访问结构化数据，而无需了解数据库模式。通过实验，我们证明了我们提出的系统能够有效地将非结构化文本转化为结构化数据，并且能够精确检索关键信息。首先，我们证明我们的系统在将财务报告转化为结构化数据方面达到了约95%的准确率，与人类注释者的性能水平相当。其次，在使用自然语言查询从结构化数据中检索信息的人类评估中，91%的回复被人类评估者评为正确。在两种评估中，我们的系统在不同类型的财务文档上表现良好，始终提供可靠的性能。', 'title_zh': '结构化无结构数据：一个代理系统用于提取和查询财务KPIs和指引'}
{'arxiv_id': 'arXiv:2505.19167', 'title': 'Amplifying Human Creativity and Problem Solving with AI Through Generative Collective Intelligence', 'authors': 'Thomas P. Kehler, Scott E. Page, Alex Pentland, Martin Reeves, John Seely Brown', 'link': 'https://arxiv.org/abs/2505.19167', 'abstract': "We propose a new framework for human-AI collaboration that amplifies the distinct capabilities of both. This framework, which we call Generative Collective Intelligence (GCI), shifts AI to the group/social level and employs AI in dual roles: as interactive agents and as technology that accumulates, organizes, and leverages knowledge. By creating a cognitive bridge between human reasoning and AI models, GCI can overcome the limitations of purely algorithmic approaches to problem-solving and decision-making. The framework demonstrates how AI can be reframed as a social and cultural technology that enables groups to solve complex problems through structured collaboration that transcends traditional communication barriers. We describe the mathematical foundations of GCI based on comparative judgment and minimum regret principles, and illustrate its applications across domains including climate adaptation, healthcare transformation, and civic participation. By combining human creativity with AI's computational capabilities, GCI offers a promising approach to addressing complex societal challenges that neither human or machines can solve alone.", 'abstract_zh': '一种增强人类与人工智能各自能力的新框架：生成性集体智能（GCI）', 'title_zh': '通过生成性集体智能增强人类创造力和问题解决能力'}
{'arxiv_id': 'arXiv:2505.19099', 'title': 'SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning', 'authors': 'Kun Xiang, Heng Li, Terry Jingchen Zhang, Yinya Huang, Zirong Liu, Peixin Qu, Jixi He, Jiaqi Chen, Yu-Jie Yuan, Jianhua Han, Hang Xu, Hanhui Li, Mrinmaya Sachan, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2505.19099', 'abstract': "We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75\\%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60\\% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.", 'abstract_zh': 'SeePhys：一个以物理问题为基础的大规模多模态基准，涵盖从小学到博士学位资格考试的推理任务', 'title_zh': 'SeePhys: 视觉助力思维——基于视觉的物理推理基准测试'}
{'arxiv_id': 'arXiv:2505.18955', 'title': 'Co-PatcheR: Collaborative Software Patching with Component(s)-specific Small Reasoning Models', 'authors': 'Yuheng Tang, Hongwei Li, Kaijie Zhu, Michael Yang, Yangruibo Ding, Wenbo Guo', 'link': 'https://arxiv.org/abs/2505.18955', 'abstract': 'Motivated by the success of general-purpose large language models (LLMs) in software patching, recent works started to train specialized patching models. Most works trained one model to handle the end-to-end patching pipeline (including issue localization, patch generation, and patch validation). However, it is hard for a small model to handle all tasks, as different sub-tasks have different workflows and require different expertise. As such, by using a 70 billion model, SOTA methods can only reach up to 41% resolved rate on SWE-bench-Verified. Motivated by the collaborative nature, we propose Co-PatcheR, the first collaborative patching system with small and specialized reasoning models for individual components. Our key technique novelties are the specific task designs and training recipes. First, we train a model for localization and patch generation. Our localization pinpoints the suspicious lines through a two-step procedure, and our generation combines patch generation and critique. We then propose a hybrid patch validation that includes two models for crafting issue-reproducing test cases with and without assertions and judging patch correctness, followed by a majority vote-based patch selection. Through extensive evaluation, we show that Co-PatcheR achieves 46% resolved rate on SWE-bench-Verified with only 3 x 14B models. This makes Co-PatcheR the best patcher with specialized models, requiring the least training resources and the smallest models. We conduct a comprehensive ablation study to validate our recipes, as well as our choice of training data number, model size, and testing-phase scaling strategy.', 'abstract_zh': '基于通用大型语言模型在软件打补丁方面的成功，近期研究开始训练专门的打补丁模型。大多数研究致力于训练一个模型处理从问题定位到补丁生成和验证的整个管道。然而，一个小模型难以处理所有任务，因为不同子任务的流程和所需的专业知识各不相同。因此，使用70亿参数的模型，当前最佳方法在SWE-bench-Verified上的解决率为41%。受协同工作的启发，我们提出了Co-PatcheR，这是第一个使用小而专业推理模型的协同打补丁系统，专门针对各组件。我们的关键技术创新包括特定任务设计和训练方法。首先，我们训练一个用于定位和生成补丁的模型。我们的定位通过两步过程进行，而生成则结合了补丁生成和批判性思考。我们还提出了混合验证补丁的方法，包括两个模型来创建带有断言和不带断言的漏洞复现测试用例，并判断补丁的正确性。随后，通过多数投票的方式选择补丁。通过广泛的评估，我们证明Co-PatcheR仅使用3个14亿参数的模型便实现46%的解决率，这使Co-PatcheR成为使用专业模型的最佳打补丁系统，同时所需训练资源和模型规模最小。我们进行了一项全面的去하면研究来验证我们的方法，以及我们的训练数据量、模型大小和测试阶段扩展策略的选择。', 'title_zh': 'Co-PatcheR: 基于组件特定小型推理模型的协作软件补丁修复'}
{'arxiv_id': 'arXiv:2505.18894', 'title': 'Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI', 'authors': 'Vanessa Utz, Steve DiPaola', 'link': 'https://arxiv.org/abs/2505.18894', 'abstract': 'Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsumption, in the digital space. We outline our previous work on the climate implications of commercially available generative AI systems and the sentiment of generative AI users when confronted with AI-related climate research. We expand on this work via a discussion of digital overconsumption and waste, other related societal impacts, and a possible solution pathway', 'abstract_zh': '生成型人工智能系统当前通过对关联能源消耗和相关的CO2排放的贡献，对数字垃圾的产生产生了负面影响。目前，迫切需要就数字空间中的有害消费者行为，如过度消费的复制进行讨论。我们概述了我们之前关于商用生成型AI系统气候影响以及生成型AI用户在面对AI相关的气候研究时的情绪的工作。通过讨论数字过度消费和浪费、相关的社会影响以及可能的解决方案路径，我们进一步扩展了这项工作。', 'title_zh': '数字过度消费与浪费：生成式AI影响探析'}
{'arxiv_id': 'arXiv:2505.18857', 'title': 'Hierarchical-embedding autoencoder with a predictor (HEAP) as efficient architecture for learning long-term evolution of complex multi-scale physical systems', 'authors': 'Alexander Khrabry, Edward Startsev, Andrew Powis, Igor Kaganovich', 'link': 'https://arxiv.org/abs/2505.18857', 'abstract': 'We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale can interact directly when they are in contact and indirectly when they are parts of larger structures that interact directly. This enables modeling a multi-scale system in an efficient way, where interactions between small-scale features that are apart from each other do not need to be modeled. The hierarchical fully-convolutional autoencoder transforms the state of a physical system not just into a single embedding layer, as it is done conventionally, but into a series of embedding layers which encode structures of various scales preserving spatial information at a corresponding resolution level. Shallower layers embed smaller structures on a finer grid, while deeper layers embed larger structures on a coarser grid. The predictor advances all embedding layers in sync. Interactions between features of various scales are modeled using a combination of convolutional operators. We compare the performance of our model to variations of a conventional ResNet architecture in application to the Hasegawa-Wakatani turbulence. A multifold improvement in long-term prediction accuracy was observed for crucial statistical characteristics of this system.', 'abstract_zh': '我们提出了一种基于尺度分离理念的新型高效架构，用于学习复杂多尺度物理系统中的长期演变。该架构通过分层全卷积自编码器将物理系统的状态变换为一系列编码层，每个编码层保留相应分辨率级别的空间信息。浅层编码层嵌入细网格上的小结构，而深层编码层嵌入粗网格上的大结构。预测器同步推进所有编码层。不同尺度特征之间的交互通过卷积算子的组合来建模。我们将模型性能与应用于Hasegawa-Wakatani湍流的传统ResNet架构变种进行比较，并在长期预测准确性方面观察到了多倍改进。', 'title_zh': '基于预测器的层次嵌入自动编码器（HEAP）：一种高效的学习复杂多尺度物理系统长期演变的架构'}
{'arxiv_id': 'arXiv:2505.18850', 'title': 'The Theory of the Unique Latent Pattern: A Formal Epistemic Framework for Structural Singularity in Complex Systems', 'authors': 'Mohamed Aly Bouke', 'link': 'https://arxiv.org/abs/2505.18850', 'abstract': 'This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system is governed by a structurally unique, deterministic generative mechanism, one that remains hidden not due to ontological indeterminacy, but due to epistemic constraints. The theory is formalized using a non-universal generative mapping \\( \\mathcal{F}_S(P_S, t) \\), where each system \\( S \\) possesses its own latent structure \\( P_S \\), irreducible and non-replicable across systems. Observed irregularities are modeled as projections of this generative map through observer-limited interfaces, introducing epistemic noise \\( \\varepsilon_S(t) \\) as a measure of incomplete access. By shifting the locus of uncertainty from the system to the observer, ULP reframes chaos as a context-relative failure of representation. We contrast this position with foundational paradigms in chaos theory, complexity science, and statistical learning. While they assume or model shared randomness or collective emergence, ULP maintains that every instance harbors a singular structural identity. Although conceptual, the theory satisfies the criterion of falsifiability in the Popperian sense, it invites empirical challenge by asserting that no two systems governed by distinct latent mechanisms will remain indistinguishable under sufficient resolution. This opens avenues for structurally individuated models in AI, behavioral inference, and epistemic diagnostics.', 'abstract_zh': '基于独特潜在模式的理论（ULP）：动态系统显复杂性的正式知识框架', 'title_zh': '独特的潜在模式理论：复杂系统结构奇异性的正式知识框架'}
{'arxiv_id': 'arXiv:2505.18822', 'title': 'AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting', 'authors': 'Shijue Huang, Hongru Wang, Wanjun Zhong, Zhaochen Su, Jiazhan Feng, Bowen Cao, Yi R. Fung', 'link': 'https://arxiv.org/abs/2505.18822', 'abstract': "Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.", 'abstract_zh': '现代大型推理模型通过采用复杂的推理策略展现出了 impressive 问题解决能力，但它们经常难以平衡效率与效果，在解决简单问题时经常生成不必要的长推理链。本文提出了一种名为 AdaCtrl 的新型框架，支持难度感知的自适应推理预算分配和显式的用户对推理深度的控制。AdaCtrl 根据自我评估的问题难度动态调整推理长度，同时允许用户手动控制预算以优先考虑效率或效果。这通过一个两阶段的训练管道实现：初始冷启动微调阶段以植入自我感知难度和调整推理预算的能力，随后是难度感知的强化学习 (RL) 阶段，该阶段根据模型在线训练过程中逐渐提升的能力来细化自适应推理策略并校准其难度评估。为了实现直观的用户交互，我们设计了明确的长度触发标签，作为预算控制的自然界面。实验证明，与包含微调和 RL 的标准训练基线相比，AdaCtrl 根据估计的难度调整推理长度，在更具挑战性的 AIME2024 和 AIME2025 数据集上分别将响应长度减少了 10.06% 和 12.14%（这两个数据集要求复杂的推理），在 MATH500 和 GSM8K 数据集上分别减少了 62.05% 和 91.04%（这两个数据集需要更为简洁的回应）。此外，AdaCtrl 允许用户精确控制推理预算，以满足特定需求。', 'title_zh': 'AdaCtrl：基于难度感知预算的自适应可控推理'}
{'arxiv_id': 'arXiv:2505.18695', 'title': 'AI for Regulatory Affairs: Balancing Accuracy, Interpretability, and Computational Cost in Medical Device Classification', 'authors': 'Yu Han, Aaron Ceross, Jeroen H. M. Bergmann', 'link': 'https://arxiv.org/abs/2505.18695', 'abstract': 'Regulatory affairs, which sits at the intersection of medicine and law, can benefit significantly from AI-enabled automation. Classification task is the initial step in which manufacturers position their products to regulatory authorities, and it plays a critical role in determining market access, regulatory scrutiny, and ultimately, patient safety. In this study, we investigate a broad range of AI models -- including traditional machine learning (ML) algorithms, deep learning architectures, and large language models -- using a regulatory dataset of medical device descriptions. We evaluate each model along three key dimensions: accuracy, interpretability, and computational cost.', 'abstract_zh': '医疗器械监管事务，作为医学与法律的交叉领域，可以从AI驱动的自动化中受益匪浅。分类任务是制造商将产品定位给监管机构的初始步骤，对确定市场准入、监管审查以及最终患者安全起着至关重要的作用。在本研究中，我们利用医疗器械描述的监管数据，探讨了一系列AI模型，包括传统机器学习算法、深度学习架构以及大型语言模型，并从准确率、可解释性和计算成本三个关键维度评估每种模型。', 'title_zh': 'AI在医疗器械分类中的监管事务应用：平衡准确性、可解释性和计算成本'}
{'arxiv_id': 'arXiv:2505.18670', 'title': 'TrajMoE: Spatially-Aware Mixture of Experts for Unified Human Mobility Modeling', 'authors': 'Chonghua Han, Yuan Yuan, Kaiyan Chen, Jingtao Ding, Yong Li', 'link': 'https://arxiv.org/abs/2505.18670', 'abstract': 'Modeling human mobility across diverse cities is essential for applications such as urban planning, transportation optimization, and personalized services. However, generalization remains challenging due to heterogeneous spatial representations and mobility patterns across cities. Existing methods typically rely on numerical coordinates or require training city-specific models, limiting their scalability and transferability. We propose TrajMoE, a unified and scalable model for cross-city human mobility modeling. TrajMoE addresses two key challenges: (1) inconsistent spatial semantics across cities, and (2) diverse urban mobility patterns. To tackle these, we begin by designing a spatial semantic encoder that learns transferable location representations from POI-based functional semantics and visit patterns. Furthermore, we design a Spatially-Aware Mixture-of-Experts (SAMoE) Transformer that injects structured priors into experts specialized in distinct mobility semantics, along with a shared expert to capture city-invariant patterns and enable adaptive cross-city generalization. Extensive experiments demonstrate that TrajMoE achieves up to 27% relative improvement over competitive mobility foundation models after only one epoch of fine-tuning, and consistently outperforms full-data baselines using merely 5% of target city data. These results establish TrajMoE as a significant step toward realizing a truly generalizable, transferable, and pretrainable foundation model for human mobility.', 'abstract_zh': '跨城市人类移动建模对于城市规划、交通运输优化和个人化服务等应用至关重要。但由于城市之间存在异质的空间表示和移动模式，通用化仍然具有挑战性。现有方法通常依赖于数值坐标或需要训练特定城市的模型，限制了其可扩展性和可移植性。我们提出了一种统一且可扩展的跨城市人类移动建模模型TrajMoE。TrajMoE解决了两个关键挑战：（1）城市间不一致的空间语义，以及（2）不同的城市移动模式。为了应对这些挑战，我们首先设计了一个空间语义编码器，从基于POI的功能语义和到访模式中学习可转移的位置表示。此外，我们设计了一个空间意识的专家混合（SAMoE）变换器，向专门处理不同移动语义的专家中注入结构化先验，并且配有一个共享专家以捕捉城市不变的模式并实现适应性的跨城市泛化。广泛实验证明，TrajMoE仅在一次微调后即可在竞争性的移动基础模型上取得高达27%的相对改善，并且仅使用目标城市数据的5%就能超越全数据基线模型，不断表现出色。这些结果证明了TrajMoE是实现真正通用化、可移植性和可预训练的人类移动基础模型的重要一步。', 'title_zh': 'TrajMoE：基于空间感知的专家混合模型统一人类移动建模'}
{'arxiv_id': 'arXiv:2505.18645', 'title': 'Riverine Flood Prediction and Early Warning in Mountainous Regions using Artificial Intelligence', 'authors': 'Haleema Bibi, Sadia Saleem, Zakia Jalil, Muhammad Nasir, Tahani Alsubait', 'link': 'https://arxiv.org/abs/2505.18645', 'abstract': 'Flooding is the most devastating phenomenon occurring globally, particularly in mountainous regions, risk dramatically increases due to complex terrains and extreme climate changes. These situations are damaging livelihoods, agriculture, infrastructure, and human lives. This study uses the Kabul River between Pakistan and Afghanistan as a case study to reflect the complications of flood forecasting in transboundary basins. The challenges in obtaining upstream data impede the efficacy of flood control measures and early warning systems, a common global problem in similar basins. Utilizing satellite-based climatic data, this study applied numerous advanced machine-learning and deep learning models, such as Support Vector Machines (SVM), XGBoost, and Artificial Neural Networks (ANN), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRU) to predict daily and multi-step river flow. The LSTM network outperformed other models, achieving the highest R2 value of 0.96 and the lowest RMSE value of 140.96 m3/sec. The time series LSTM and GRU network models, utilized for short-term forecasts of up to five days, performed significantly. However, the accuracy declined beyond the fourth day, highlighting the need for longer-term historical datasets for reliable long-term flood predictions. The results of the study are directly aligned with Sustainable Development Goals 6, 11, 13, and 15, facilitating disaster and water management, timely evacuations, improved preparedness, and effective early warning.', 'abstract_zh': '全球范围内，洪水是最具破坏性的现象，尤其是在山区，由于地形复杂和极端气候变化，风险急剧增加。这些情况损害了生计、农业、基础设施和人类生命。本研究以巴基斯坦与阿富汗之间的坎布尔河为案例研究，反映了跨界流域洪水预报的复杂性。获取上游数据的挑战阻碍了洪水控制措施和预警系统的有效性，这是类似流域中普遍存在的全球性问题。利用基于卫星的气候数据，本研究应用了多种先进的机器学习和深度学习模型，如支持向量机（SVM）、XGBoost、人工神经网络（ANN）、长短期记忆网络（LSTM）和门控循环单元（GRU），以预测日流量和多步河流流量。LSTM网络表现最佳，实现了最高的R2值0.96和最低的RMSE值140.96立方米/秒。用于5天内短期预测的时间序列LSTM和GRU网络模型表现显著，但第四天之后的准确性下降，强调了获取更长历史数据集以实现可靠长期洪水预测的必要性。研究结果直接与可持续发展目标6、11、13和15一致，促进灾害和水资源管理、及时疏散、提高准备水平和有效的早期预警。', 'title_zh': '基于人工智能的山地地区河流洪水预测与早期预警'}
{'arxiv_id': 'arXiv:2505.18623', 'title': "Mind The Gap: Deep Learning Doesn't Learn Deeply", 'authors': 'Lucas Saldyt, Subbarao Kambhampati', 'link': 'https://arxiv.org/abs/2505.18623', 'abstract': 'This paper aims to understand how neural networks learn algorithmic reasoning by addressing two questions: How faithful are learned algorithms when they are effective, and why do neural networks fail to learn effective algorithms otherwise? To answer these questions, we use neural compilation, a technique that directly encodes a source algorithm into neural network parameters, enabling the network to compute the algorithm exactly. This enables comparison between compiled and conventionally learned parameters, intermediate vectors, and behaviors. This investigation is crucial for developing neural networks that robustly learn complexalgorithms from data. Our analysis focuses on graph neural networks (GNNs), which are naturally aligned with algorithmic reasoning tasks, specifically our choices of BFS, DFS, and Bellman-Ford, which cover the spectrum of effective, faithful, and ineffective learned algorithms. Commonly, learning algorithmic reasoning is framed as induction over synthetic data, where a parameterized model is trained on inputs, traces, and outputs produced by an underlying ground truth algorithm. In contrast, we introduce a neural compilation method for GNNs, which sets network parameters analytically, bypassing training. Focusing on GNNs leverages their alignment with algorithmic reasoning, extensive algorithmic induction literature, and the novel application of neural compilation to GNNs. Overall, this paper aims to characterize expressability-trainability gaps - a fundamental shortcoming in learning algorithmic reasoning. We hypothesize that inductive learning is most effective for parallel algorithms contained within the computational class \\texttt{NC}.', 'abstract_zh': '本文旨在通过回答两个问题来理解神经网络如何学习算法推理：当有效时，学习到的算法有多忠实，而神经网络在其他情况下为何未能学习有效的算法？为了回答这些问题，我们使用神经编译技术，该技术可以直接将源算法编码为神经网络参数，使网络可以精确地执行算法。这使得编译参数和传统学习参数、中间向量以及行为之间的比较成为可能。这种调查对于开发能够从数据中稳健学习复杂算法的神经网络至关重要。我们的分析集中在图神经网络（GNNs）上，这些网络自然适用于算法推理任务，特别是我们选择的BFS、DFS和Bellman-Ford，它们涵盖了有效、忠实和无效学习算法的谱系。通常，学习算法推理被框架化为合成数据上的归纳，其中参数化模型在由底层真实算法产生的输入、轨迹和输出上进行训练。相比之下，我们为GNNs引入了一种神经编译方法，该方法通过解析设置网络参数，从而绕过了训练过程。重点关注GNNs，利用了它们与算法推理的对齐、广泛的算法归纳文献以及将神经编译应用于GNNs的新颖应用。总体而言，本文旨在刻画可表达性-可训练性差距——这是学习算法推理的基本缺陷。我们假设归纳学习对包含在计算类\\(\\texttt{NC}\\)中的并行算法最有效。', 'title_zh': '关注差距：深度学习并不深学'}
{'arxiv_id': 'arXiv:2505.18547', 'title': 'Diffusion Blend: Inference-Time Multi-Preference Alignment for Diffusion Models', 'authors': 'Min Cheng, Fatemeh Doudi, Dileep Kalathil, Mohammad Ghavamzadeh, Panganamala R. Kumar', 'link': 'https://arxiv.org/abs/2505.18547', 'abstract': 'Reinforcement learning (RL) algorithms have been used recently to align diffusion models with downstream objectives such as aesthetic quality and text-image consistency by fine-tuning them to maximize a single reward function under a fixed KL regularization. However, this approach is inherently restrictive in practice, where alignment must balance multiple, often conflicting objectives. Moreover, user preferences vary across prompts, individuals, and deployment contexts, with varying tolerances for deviation from a pre-trained base model. We address the problem of inference-time multi-preference alignment: given a set of basis reward functions and a reference KL regularization strength, can we design a fine-tuning procedure so that, at inference time, it can generate images aligned with any user-specified linear combination of rewards and regularization, without requiring additional fine-tuning? We propose Diffusion Blend, a novel approach to solve inference-time multi-preference alignment by blending backward diffusion processes associated with fine-tuned models, and we instantiate this approach with two algorithms: DB-MPA for multi-reward alignment and DB-KLA for KL regularization control. Extensive experiments show that Diffusion Blend algorithms consistently outperform relevant baselines and closely match or exceed the performance of individually fine-tuned models, enabling efficient, user-driven alignment at inference-time. The code is available at this https URL}{this http URL.', 'abstract_zh': '强化学习（RL）算法已被用于通过微调扩散模型以在固定KL正则化条件下最大化单一奖励函数来与下游目标如审美质量和图文一致性对齐。然而，在实践中，这种方法本质上是局限的，因为对齐必须平衡多个常常相互冲突的目标。此外，用户偏好随提示、个体和部署环境而异，对预训练基模型的偏差容忍度也不同。我们解决了推理时多偏好对齐的问题：给定一组基奖励函数和一个参考KL正则化强度，我们能否设计一种微调方案，在推理时能够生成与用户指定的奖励线性组合对齐的图像，而不需要额外的微调？我们提出了扩散融合（Diffusion Blend）方法，这是一种通过混合微调模型相关的反向扩散过程来解决推理时多偏好对齐的新方法，并实例化了两种算法：DB-MPA用于多奖励对齐和DB-KLA用于KL正则化控制。广泛的实验表明，扩散融合算法在多个基准之上表现更优，并且接近或超过了单独微调模型的表现，从而在推理时实现高效的、用户驱动的对齐。代码可在以下网址获取：this https URL this http URL。', 'title_zh': '扩散融合：推断时多偏好对齐的扩散模型方法'}
{'arxiv_id': 'arXiv:2505.18492', 'title': 'Enumerate-Conjecture-Prove: Formally Solving Answer-Construction Problems in Math Competitions', 'authors': 'Jialiang Sun, Yuzhi Tang, Ao Li, Chris J. Maddison, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2505.18492', 'abstract': "Mathematical reasoning lies at the heart of artificial intelligence, underpinning applications in education, program verification, and research-level mathematical discovery. Mathematical competitions, in particular, present two challenging problem types: theorem-proving, requiring rigorous proofs of stated conclusions, and answer-construction, involving hypothesizing and formally verifying mathematical objects. Large Language Models (LLMs) effectively generate creative candidate answers but struggle with formal verification, while symbolic provers ensure rigor but cannot efficiently handle creative conjecture generation. We introduce the Enumerate-Conjecture-Prove (ECP) framework, a modular neuro-symbolic method integrating LLM-based enumeration and pattern-driven conjecturing with formal theorem proving. We present ConstructiveBench, a dataset of 3,431 answer-construction problems in various math competitions with verified Lean formalizations. On the ConstructiveBench dataset, ECP improves the accuracy of answer construction from the Chain-of-Thought (CoT) baseline of 14.54% to 45.06% with the gpt-4.1-mini model. Moreover, combining with ECP's constructed answers, the state-of-the-art DeepSeek-Prover-V2-7B model generates correct proofs for 858 of the 3,431 constructive problems in Lean, achieving 25.01% accuracy, compared to 9.86% for symbolic-only baselines. Our code and dataset are publicly available at GitHub and HuggingFace, respectively.", 'abstract_zh': '数学推理是人工智能的核心，支撑着教育应用、程序验证以及高水平的数学发现。数学竞赛，尤其是提供了两种具有挑战性的问题类型：定理证明，需要对陈述结论给出严密的证明；以及答案构造，涉及假设和形式验证数学对象。大型语言模型（LLMs）能够生成有创意的候选答案，但在形式验证方面存在困难，而符号证明器则能确保严谨性，但无法高效处理创造性的假设生成。我们提出了枚举-假设-证明（ECP）框架，这是一种模块化的神经-符号方法，结合了基于LLM的枚举、模式驱动的假设生成以及形式定理证明。我们还介绍了ConstructiveBench数据集，包含3,431个来自各类数学竞赛的答案构造问题，并进行了形式化的Lean验证。在ConstructiveBench数据集上，使用gpt-4.1-mini模型，ECP框架将基于Chain-of-Thought（CoT）基线的答案构造准确性从14.54%提升至45.06%。此外，结合ECP生成的答案，最先进的DeepSeek-Prover-V2-7B模型在Lean中正确证明了858个构造性问题，实现了25.01%的准确性，而仅使用符号方法的基线模型准确率为9.86%。我们的代码和数据集分别在GitHub和HuggingFace上公开。', 'title_zh': '列举-猜想-证明：正式解决数学竞赛中的答案构建问题'}
{'arxiv_id': 'arXiv:2505.18470', 'title': 'Chemical classification program synthesis using generative artificial intelligence', 'authors': "Christopher J. Mungall, Adnan Malik, Daniel R. Korn, Justin T. Reese, Noel M. O'Boyle, Noel, Janna Hastings", 'link': 'https://arxiv.org/abs/2505.18470', 'abstract': 'Accurately classifying chemical structures is essential for cheminformatics and bioinformatics, including tasks such as identifying bioactive compounds of interest, screening molecules for toxicity to humans, finding non-organic compounds with desirable material properties, or organizing large chemical libraries for drug discovery or environmental monitoring. However, manual classification is labor-intensive and difficult to scale to large chemical databases. Existing automated approaches either rely on manually constructed classification rules, or the use of deep learning methods that lack explainability.\nThis work presents an approach that uses generative artificial intelligence to automatically write chemical classifier programs for classes in the Chemical Entities of Biological Interest (ChEBI) database. These programs can be used for efficient deterministic run-time classification of SMILES structures, with natural language explanations. The programs themselves constitute an explainable computable ontological model of chemical class nomenclature, which we call the ChEBI Chemical Class Program Ontology (C3PO).\nWe validated our approach against the ChEBI database, and compared our results against state of the art deep learning models. We also demonstrate the use of C3PO to classify out-of-distribution examples taken from metabolomics repositories and natural product databases. We also demonstrate the potential use of our approach to find systematic classification errors in existing chemical databases, and show how an ensemble artificial intelligence approach combining generated ontologies, automated literature search, and multimodal vision models can be used to pinpoint potential errors requiring expert validation', 'abstract_zh': '准确分类化学结构对于化学信息学和生物信息学至关重要，包括识别感兴趣的生物活性化合物、筛选对人体有毒性的分子、寻找具有 desirable 物理化学性质的非有机化合物，或组织用于药物发现或环境监测的大型化学数据库。然而，手工分类劳动密集且难以扩展到大型化学数据库。现有的自动化方法要么依赖于手工构建的分类规则，要么使用缺乏解释性的深度学习方法。\n\n本研究提出了一种使用生成人工智能自动为化学实体生物学信息（ChEBI）数据库中的类编写化学分类器程序的方法。这些程序可用于高效确定运行时 SMILES 结构分类，并附带自然语言解释。这些程序本身构成了一个可解释的计算本体模型，我们称之为 ChEBI 化学类别程序本体（C3PO）。\n\n我们使用 ChEBI 数据库对我们的方法进行了验证，并将我们的结果与最先进的深度学习模型进行了比较。我们还展示了如何使用 C3PO 对代谢组学存储库和天然产物数据库中的分类外示例进行分类。我们还展示了本方法在发现现有化学数据库中的系统性分类错误方面的潜在用途，并展示了如何结合生成本体、自动文献搜索和多模态视觉模型的集成人工智能方法来定位需要专家验证的潜在错误。', 'title_zh': '使用生成式人工智能进行化学分类程序合成'}
{'arxiv_id': 'arXiv:2505.18467', 'title': 'Pedagogy-R1: Pedagogically-Aligned Reasoning Model with Balanced Educational Benchmark', 'authors': 'Unggi Lee, Jaeyong Lee, Jiyeong Bae, Yeil Jeong, Junbo Koh, Gyeonggeon Lee, Gunho Lee, Taekyung Ahn, Hyeoncheol Kim', 'link': 'https://arxiv.org/abs/2505.18467', 'abstract': "Recent advances in large reasoning models (LRMs) show strong performance in structured domains such as mathematics and programming; however, they often lack pedagogical coherence and realistic teaching behaviors. To bridge this gap, we introduce Pedagogy-R1, a framework that adapts LRMs for classroom use through three innovations: (1) a distillation-based pipeline that filters and refines model outputs for instruction-tuning, (2) the Well-balanced Educational Benchmark (WBEB), which evaluates performance across subject knowledge, pedagogical knowledge, tracing, essay scoring, and teacher decision-making, and (3) a Chain-of-Pedagogy (CoP) prompting strategy for generating and eliciting teacher-style reasoning. Our mixed-method evaluation combines quantitative metrics with qualitative analysis, providing the first systematic assessment of LRMs' pedagogical strengths and limitations.", 'abstract_zh': 'Recent advances in大型推理模型（LRMs）在数学和编程等结构化领域展现了强大性能；然而，它们往往缺乏教学连贯性和现实的教学行为。为弥补这一差距，我们引入了Pedagogy-R1框架，通过三项创新将LRMs适应于课堂教学环境：（1）基于蒸馏的流水线，筛选和提高模型输出以用于教学调优；（2）均衡教育基准（WBEB），评估模型在学科知识、教学知识、追踪、作文评分及教师决策方面的表现；（3）教师导向的推理链（CoP）提示策略，用于生成和激发教师风格的推理。我们的混合方法评估结合了定量指标与定性分析，提供了首个系统评估LRMs教学优势与限制的研究。', 'title_zh': '教学导向-1：平衡教育基准的教学对齐推理模型'}
{'arxiv_id': 'arXiv:2505.18425', 'title': 'Advertising in AI systems: Society must be vigilant', 'authors': 'Menghua Wu, Yujia Bao', 'link': 'https://arxiv.org/abs/2505.18425', 'abstract': 'AI systems have increasingly become our gateways to the Internet. We argue that just as advertising has driven the monetization of web search and social media, so too will commercial incentives shape the content served by AI. Unlike traditional media, however, the outputs of these systems are dynamic, personalized, and lack clear provenance -- raising concerns for transparency and regulation. In this paper, we envision how commercial content could be delivered through generative AI-based systems. Based on the requirements of key stakeholders -- advertisers, consumers, and platforms -- we propose design principles for commercially-influenced AI systems. We then outline high-level strategies for end users to identify and mitigate commercial biases from model outputs. Finally, we conclude with open questions and a call to action towards these goals.', 'abstract_zh': '基于生成AI的商业内容交付及其设计原则与用户策略探索', 'title_zh': 'AI系统中的广告：社会必须保持警惕'}
{'arxiv_id': 'arXiv:2505.18277', 'title': 'The end of radical concept nativism', 'authors': 'Joshua S. Rule, Steven T. Piantadosi', 'link': 'https://arxiv.org/abs/2505.18277', 'abstract': "Though humans seem to be remarkable learners, arguments in cognitive science and philosophy of mind have long maintained that learning something fundamentally new is impossible. Specifically, Jerry Fodor's arguments for radical concept nativism hold that most, if not all, concepts are innate and that what many call concept learning never actually leads to the acquisition of new concepts. These arguments have deeply affected cognitive science, and many believe that the counterarguments to radical concept nativism have been either unsuccessful or only apply to a narrow class of concepts. This paper first reviews the features and limitations of prior arguments. We then identify three critical points - related to issues of expressive power, conceptual structure, and concept possession - at which the arguments in favor of radical concept nativism diverge from describing actual human cognition. We use ideas from computer science and information theory to formalize the relevant ideas in ways that are arguably more scientifically productive. We conclude that, as a result, there is an important sense in which people do indeed learn new concepts.", 'abstract_zh': '尽管人类似乎具有卓越的学习能力，但在认知科学和心灵哲学中，长期存在的论点认为根本性的新学习是不可能的。具体来说，Jerry Fodor有关激进的概念先天论的论点认为，大部分甚至全部的概念都是先天的，许多人所谓的概念学习实际上并未带来新概念的获得。这些论点深深地影响了认知科学，许多人认为反对激进的概念先天论的论点要么不成功，要么仅适用于特定类型的概念。本文首先回顾了先前论点的特点和局限性。然后，我们识别出三个关键点——涉及表达能力、概念结构和概念拥有等方面的问题——在这些方面，支持激进的概念先天论的论点与描述实际人类认知相偏离。我们使用计算机科学和信息理论中的概念对相关思想进行形式化，这可能更具有科学生产力。我们得出结论，在某种重要意义上，人们确实能够学习新的概念。', 'title_zh': '终结激进的概念natal主义'}
{'arxiv_id': 'arXiv:2505.20274', 'title': 'Probabilistic Kernel Function for Fast Angle Testing', 'authors': 'Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa', 'link': 'https://arxiv.org/abs/2505.20274', 'abstract': 'In this paper, we study the angle testing problem in high-dimensional Euclidean spaces and propose two projection-based probabilistic kernel functions, one designed for angle comparison and the other for angle thresholding. Unlike existing approaches that rely on random projection vectors drawn from Gaussian distributions, our approach leverages reference angles and employs a deterministic structure for the projection vectors. Notably, our kernel functions do not require asymptotic assumptions, such as the number of projection vectors tending to infinity, and can be both theoretically and experimentally shown to outperform Gaussian-distribution-based kernel functions. We further apply the proposed kernel function to Approximate Nearest Neighbor Search (ANNS) and demonstrate that our approach achieves a 2.5X ~ 3X higher query-per-second (QPS) throughput compared to the state-of-the-art graph-based search algorithm HNSW.', 'abstract_zh': '在高维欧几里得空间中的角度测试问题研究及两种基于投影的概率核函数提出', 'title_zh': '快速角度测试的概率核函数'}
{'arxiv_id': 'arXiv:2505.20269', 'title': 'Comparing Neural Network Encodings for Logic-based Explainability', 'authors': 'Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha', 'link': 'https://arxiv.org/abs/2505.20269', 'abstract': 'Providing explanations for the outputs of artificial neural networks (ANNs) is crucial in many contexts, such as critical systems, data protection laws and handling adversarial examples. Logic-based methods can offer explanations with correctness guarantees, but face scalability challenges. Due to these issues, it is necessary to compare different encodings of ANNs into logical constraints, which are used in logic-based explainability. This work compares two encodings of ANNs: one has been used in the literature to provide explanations, while the other will be adapted for our context of explainability. Additionally, the second encoding uses fewer variables and constraints, thus, potentially enhancing efficiency. Experiments showed similar running times for computing explanations, but the adapted encoding performed up to 18\\% better in building logical constraints and up to 16\\% better in overall time.', 'abstract_zh': '基于逻辑的方法在人工神经网络输出解释中的应用：两种不同编码的比较', 'title_zh': '基于逻辑的可解释性中神经网络编码的比较'}
{'arxiv_id': 'arXiv:2505.20268', 'title': 'Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits', 'authors': 'Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie', 'link': 'https://arxiv.org/abs/2505.20268', 'abstract': 'Reinforcement learning with outcome-based feedback faces a fundamental challenge: when rewards are only observed at trajectory endpoints, how do we assign credit to the right actions? This paper provides the first comprehensive analysis of this problem in online RL with general function approximation. We develop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the coverability coefficient of the underlying MDP. By leveraging general function approximation, our approach works effectively in large or infinite state spaces where tabular methods fail, requiring only that value functions and reward functions can be represented by appropriate function classes. Our results also characterize when outcome-based feedback is statistically separated from per-step rewards, revealing an unavoidable exponential separation for certain MDPs. For deterministic MDPs, we show how to eliminate the completeness assumption, dramatically simplifying the algorithm. We further extend our approach to preference-based feedback settings, proving that equivalent statistical efficiency can be achieved even under more limited information. Together, these results constitute a theoretical foundation for understanding the statistical properties of outcome-based reinforcement learning.', 'abstract_zh': '基于结果反馈的强化学习面临一个基本挑战：当奖励仅在轨迹结束时观测到时，我们如何将信用正确地分配给相应的动作？本文首次在一般函数近似的在线强化学习中对这一问题进行了全面分析。我们开发了一个可证明样本高效的算法，其样本复杂度为$\\widetilde{O}(C_{\\rm cov} H^3/\\epsilon^2)$，其中$C_{\\rm cov}$是底层MDP的覆盖系数。通过利用一般函数近似，我们的方法在状态空间过大或无限时有效运行，仅需值函数和奖励函数能由适当的功能类表示。我们的结果还界定了基于结果反馈与逐步奖励之间的统计分离情况，揭示了一些MDP中不可避免的指数级分离。对于确定性MDP，我们展示了如何消除完整性假设，显著简化算法。我们进一步将该方法扩展到基于偏好的反馈设置中，证明即使在信息更有限的情况下也能达到等效的统计效率。这些结果构成了基于结果的强化学习的统计特性理解的理论基础。', 'title_zh': '基于结果的在线强化学习：算法与基本限制'}
{'arxiv_id': 'arXiv:2505.20264', 'title': 'We Need to Measure Data Diversity in NLP -- Better and Broader', 'authors': 'Dong Nguyen, Esther Ploeger', 'link': 'https://arxiv.org/abs/2505.20264', 'abstract': 'Although diversity in NLP datasets has received growing attention, the question of how to measure it remains largely underexplored. This opinion paper examines the conceptual and methodological challenges of measuring data diversity and argues that interdisciplinary perspectives are essential for developing more fine-grained and valid measures.', 'abstract_zh': '尽管自然语言处理数据集的多样性已受到越来越多的关注，但如何衡量多样性的问题仍 largely underexplored。本文探讨了衡量数据多样性所面临的概念和方法论挑战，并argues认为跨学科视角对于开发更为精细和有效的衡量方法至关重要。', 'title_zh': '我们需要测量NLP中的数据多样性——更好更广泛'}
{'arxiv_id': 'arXiv:2505.20254', 'title': 'Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs', 'authors': 'Xiangchen Song, Aashiq Muhamed, Yujia Zheng, Lingjing Kong, Zeyu Tang, Mona T. Diab, Virginia Smith, Kun Zhang', 'link': 'https://arxiv.org/abs/2505.20254', 'abstract': 'Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neural network activations into interpretable features. However, the aspiration to identify a canonical set of features is challenged by the observed inconsistency of learned SAE features across different training runs, undermining the reliability and efficiency of MI research. This position paper argues that mechanistic interpretability should prioritize feature consistency in SAEs -- the reliable convergence to equivalent feature sets across independent runs. We propose using the Pairwise Dictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to operationalize consistency and demonstrate that high levels are achievable (0.80 for TopK SAEs on LLM activations) with appropriate architectural choices. Our contributions include detailing the benefits of prioritizing consistency; providing theoretical grounding and synthetic validation using a model organism, which verifies PW-MCC as a reliable proxy for ground-truth recovery; and extending these findings to real-world LLM data, where high feature consistency strongly correlates with the semantic similarity of learned feature explanations. We call for a community-wide shift towards systematically measuring feature consistency to foster robust cumulative progress in MI.', 'abstract_zh': '稀疏自动编码器（SAEs）在机械可解释性（MI）中是一个重要的工具，用于将神经网络激活分解为可解释的特征。然而，识别一组标准特征的努力受到在不同训练运行中学习到的SAE特征之间一致性不足的挑战，这削弱了MI研究的可靠性和效率。本文认为，机械可解释性应优先考虑SAE中的特征一致性——即在独立运行中可靠地收敛到等效特征集。我们提议使用成对字典均值相关系数（PW-MCC）作为一致性操作化的实际度量，并证明通过适当架构选择可以实现高水平的一致性（LLM激活的TopK SAEs中达到0.80）。我们的贡献包括详细阐述优先考虑一致性的益处；提供理论基础并在模式生物中进行合成验证，验证PW-MCC作为地面真理恢复可靠代理的有效性；并将这些发现扩展到真实世界的LLM数据，其中高特征一致性与学习到的特征解释的语义相似性高度相关。我们呼吁在整个社区范围内系统地衡量特征一致性，以促进MI的稳健累积进步。', 'title_zh': '位置：机制可解释性在SAEs中的优先级应为特征一致性'}
{'arxiv_id': 'arXiv:2505.20235', 'title': 'Variational Deep Learning via Implicit Regularization', 'authors': 'Jonathan Wenger, Beau Coker, Juraj Marusic, John P. Cunningham', 'link': 'https://arxiv.org/abs/2505.20235', 'abstract': 'Modern deep learning models generalize remarkably well in-distribution, despite being overparametrized and trained with little to no explicit regularization. Instead, current theory credits implicit regularization imposed by the choice of architecture, hyperparameters and optimization procedure. However, deploying deep learning models out-of-distribution, in sequential decision-making tasks, or in safety-critical domains, necessitates reliable uncertainty quantification, not just a point estimate. The machinery of modern approximate inference -- Bayesian deep learning -- should answer the need for uncertainty quantification, but its effectiveness has been challenged by our inability to define useful explicit inductive biases through priors, as well as the associated computational burden. Instead, in this work we demonstrate, both theoretically and empirically, how to regularize a variational deep network implicitly via the optimization procedure, just as for standard deep learning. We fully characterize the inductive bias of (stochastic) gradient descent in the case of an overparametrized linear model as generalized variational inference and demonstrate the importance of the choice of parametrization. Finally, we show empirically that our approach achieves strong in- and out-of-distribution performance without tuning of additional hyperparameters and with minimal time and memory overhead over standard deep learning.', 'abstract_zh': '现代深度学习模型在分布内表现出 remarkable 的泛化能力，尽管它们是过参数化的，并且在训练过程中几乎没有显式的正则化。当前的理论归因于架构、超参数和优化过程所引入的隐式正则化。然而，在分布外部署深度学习模型、在顺序决策任务中使用它们或在关键安全领域中使用它们时，需要的是可靠的不确定性量化，而不仅仅是点估计。现代近似推断的工具——贝叶斯深度学习——应该满足这一需求，但其效果受到了我们无法通过先验定义有用的归纳偏置以及由此带来的计算负担的挑战。相反，本文通过优化过程隐式正则化变分深度网络，证明了这种做法的有效性，并在理论上和实验上全面阐述了过参数化线性模型中（随机）梯度下降的归纳偏置，展示了参数化选择的重要性。最后，实验证明，我们的方法在不需要调优额外超参数的情况下，在分布内和分布外均能取得优异性能，并且相较于标准深度学习仅有极小的时间和内存开销。', 'title_zh': '变分深度学习通过隐式正则化'}
{'arxiv_id': 'arXiv:2505.20229', 'title': "From What to How: Attributing CLIP's Latent Components Reveals Unexpected Semantic Reliance", 'authors': 'Maximilian Dreyer, Lorenz Hufe, Jim Berend, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek', 'link': 'https://arxiv.org/abs/2505.20229', 'abstract': 'Transformer-based CLIP models are widely used for text-image probing and feature extraction, making it relevant to understand the internal mechanisms behind their predictions. While recent works show that Sparse Autoencoders (SAEs) yield interpretable latent components, they focus on what these encode and miss how they drive predictions. We introduce a scalable framework that reveals what latent components activate for, how they align with expected semantics, and how important they are to predictions. To achieve this, we adapt attribution patching for instance-wise component attributions in CLIP and highlight key faithfulness limitations of the widely used Logit Lens technique. By combining attributions with semantic alignment scores, we can automatically uncover reliance on components that encode semantically unexpected or spurious concepts. Applied across multiple CLIP variants, our method uncovers hundreds of surprising components linked to polysemous words, compound nouns, visual typography and dataset artifacts. While text embeddings remain prone to semantic ambiguity, they are more robust to spurious correlations compared to linear classifiers trained on image embeddings. A case study on skin lesion detection highlights how such classifiers can amplify hidden shortcuts, underscoring the need for holistic, mechanistic interpretability. We provide code at this https URL.', 'abstract_zh': '基于Transformer的CLIP模型广泛用于文本-图像探查和特征提取，理解其预测背后的内部机制具有重要意义。虽然近期工作表明稀疏自编码器（SAEs）产生可解释的潜在组件，但这些研究主要关注它们编码了什么，而忽视了它们如何驱动预测。我们提出了一个可扩展的框架，揭示潜在组件的作用，它们如何与预期语义对齐，以及它们在预测中的重要性。通过将归因斑图技术适应于实例级别的组件归因，并突显广泛使用的Logit Lens技术的关键忠实性限制，我们结合归因与语义对齐得分，可以自动发现编码语义意外或伪概念的依赖组件。在多个CLIP变体上的应用揭示了与多义词、复合名词、视觉排版和数据集特征相关数百个令人惊讶的组件。尽管文本嵌入仍然容易产生语义模糊，但在图像嵌入上进行训练的线性分类器相比而言更不易受到伪相关的影响。通过对皮肤病变检测的研究案例强调了如何这些分类器放大隐藏捷径，突出了整体、机制性可解释性的需求。我们在下面的链接提供代码：this https URL。', 'title_zh': '从“是什么”到“怎么做”：归因CLIP的潜在组件揭示了意外的语义依赖'}
{'arxiv_id': 'arXiv:2505.20190', 'title': 'Leveraging Descriptions of Emotional Preferences in Recommender Systems', 'authors': 'Tonmoy Hasan, Razvan Bunescu', 'link': 'https://arxiv.org/abs/2505.20190', 'abstract': 'The affective attitude of liking a recommended item reflects just one category in a wide spectrum of affective phenomena that also includes emotions such as entranced or intrigued, moods such as cheerful or buoyant, as well as more fine-grained affective states, such as "pleasantly surprised by the conclusion". In this paper, we introduce a novel recommendation task that can leverage a virtually unbounded range of affective states sought explicitly by the user in order to identify items that, upon consumption, are likely to induce those affective states. Correspondingly, we create a large dataset of user preferences containing expressions of fine-grained affective states that are mined from book reviews, and propose a Transformer-based architecture that leverages such affective expressions as input. We then use the resulting dataset of affective states preferences, together with the linked users and their histories of book readings, ratings, and reviews, to train and evaluate multiple recommendation models on the task of matching recommended items with affective preferences. Experiments show that the best results are obtained by models that can utilize textual descriptions of items and user affective preferences.', 'abstract_zh': '喜欢推荐项目的感情态度仅反映广泛的感情现象谱中的一种，这一谱系还包括如着迷或好奇等情绪，愉快或振奋等 mood，以及更精细的感情状态，如“对结论感到高兴而惊讶”。本文提出了一种新颖的推荐任务，旨在通过用户明确寻求的一系列广泛的感情状态来识别在消费后可能引起这些感情状态的项目。为此，我们创建了一个包含从书籍评论中挖掘而来的情感状态表达的大规模用户偏好数据集，并提出了一种基于 Transformer 的架构，该架构利用这种情感表达作为输入。我们使用情感状态偏好数据集，以及与之关联的用户及其阅读、评分和评论历史记录，对多个推荐模型进行训练和评估，以匹配推荐项目与情感偏好。实验结果显示，能够利用项目文本描述和用户情感偏好的模型效果最佳。', 'title_zh': '利用情感偏好描述在推荐系统中的应用'}
{'arxiv_id': 'arXiv:2505.20150', 'title': 'On the (Non) Injectivity of Piecewise Linear Janossy Pooling', 'authors': 'Ilai Reshef, Nadav Dym', 'link': 'https://arxiv.org/abs/2505.20150', 'abstract': 'Multiset functions, which are functions that map multisets to vectors, are a fundamental tool in the construction of neural networks for multisets and graphs. To guarantee that the vector representation of the multiset is faithful, it is often desirable to have multiset mappings that are both injective and bi-Lipschitz. Currently, there are several constructions of multiset functions achieving both these guarantees, leading to improved performance in some tasks but often also to higher compute time than standard constructions. Accordingly, it is natural to inquire whether simpler multiset functions achieving the same guarantees are available. In this paper, we make a large step towards giving a negative answer to this question. We consider the family of k-ary Janossy pooling, which includes many of the most popular multiset models, and prove that no piecewise linear Janossy pooling function can be injective. On the positive side, we show that when restricted to multisets without multiplicities, even simple deep-sets models suffice for injectivity and bi-Lipschitzness.', 'abstract_zh': '多集函数是构建处理多集和图的神经网络的基本工具。为了保证多集的向量表示是忠实的，往往需要多集映射既注入性又双利普希茨性。目前，有一些构造多集函数的方法同时实现了这两种保证，尽管这些方法在某些任务上的性能有所提升，但通常也伴随着更高的计算时间。因此，自然会疑问是否可以找到更简单的多集函数以达到相同的保证。在本文中，我们朝着给出否定答案的方向迈出了重要一步。我们考虑了k-元詹诺西池化族，其中包括了许多最流行的多集模型，并证明了没有分段线性詹诺西池化函数可以是注入性的。在正面结果方面，我们证明在没有重复元素的多集情况下，即使是简单的深度集模型也足以实现注入性和双利普希茨性。', 'title_zh': '关于-piecewise线性Janossy池化是否存在注入性'}
{'arxiv_id': 'arXiv:2505.20149', 'title': 'Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases', 'authors': 'Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Cheng-Kai Lu, Jia-Kang Wang, Tzu-Lun Huang', 'link': 'https://arxiv.org/abs/2505.20149', 'abstract': 'This paper focuses on using few-shot learning to improve the accuracy of classifying OCT diagnosis images with major and rare classes. We used the GAN-based augmentation strategy as a baseline and introduced several novel methods to further enhance our model. The proposed strategy contains U-GAT-IT for improving the generative part and uses the data balance technique to narrow down the skew of accuracy between all categories. The best model obtained was built with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an overall accuracy of 97.85%, representing a significant improvement over the original baseline.', 'abstract_zh': '本论文聚焦于使用少样本学习提高OCT诊断图像主要类和稀见类分类准确性的方法。我们以基于GAN的数据增强策略为基础，并引入了几种新颖的方法以进一步增强模型性能。所提出的方法包括使用U-GAT-IT改进生成部分，并采用数据平衡技术以缩小各类别之间准确率的偏斜度。所获得的最佳模型采用CBAM注意力机制并 fine-tune InceptionV3，实现了整体准确率为97.85%的结果，相较于原始基线有显著提升。', 'title_zh': 'OCT图像分类中罕见视网膜疾病少样本学习的改进策略'}
{'arxiv_id': 'arXiv:2505.20132', 'title': 'Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks', 'authors': 'Safa Hamreras, Sukhbinder Singh, Román Orús', 'link': 'https://arxiv.org/abs/2505.20132', 'abstract': 'Tensorizing a neural network involves reshaping some or all of its dense weight matrices into higher-order tensors and approximating them using low-rank tensor network decompositions. This technique has shown promise as a model compression strategy for large-scale neural networks. However, despite encouraging empirical results, tensorized neural networks (TNNs) remain underutilized in mainstream deep learning. In this position paper, we offer a perspective on both the potential and current limitations of TNNs. We argue that TNNs represent a powerful yet underexplored framework for deep learning--one that deserves greater attention from both engineering and theoretical communities. Beyond compression, we highlight the value of TNNs as a flexible class of architectures with distinctive scaling properties and increased interpretability. A central feature of TNNs is the presence of bond indices, which introduce new latent spaces not found in conventional networks. These internal representations may provide deeper insight into the evolution of features across layers, potentially advancing the goals of mechanistic interpretability. We conclude by outlining several key research directions aimed at overcoming the practical barriers to scaling and adopting TNNs in modern deep learning workflows.', 'abstract_zh': 'Tensor化神经网络涉及将某些或全部其稠密权重矩阵重塑为高阶张量，并使用低秩张量网络分解进行逼近。这种技术作为一种大规模神经网络的模型压缩策略显示出潜力。然而，尽管有令人鼓舞的实证结果，TNNs在主流深度学习中的应用仍然相对有限。在本文中，我们从潜在能力和当前局限性两个方面探讨了TNNs的观点。我们认为，TNNs代表了一种强大而未充分探索的深度学习框架，值得从工程和理论两个社区给予更多关注。除了压缩，我们还强调了TNNs作为一种具有独特缩放特性和增强可解释性的灵活网络架构的价值。TNNs的一个核心特征是存在键指数，这引入了传统网络中未发现的新潜在空间，这些内部表示可能为特征在各层之间的演变提供更深入的洞察，有助于实现机制可解释性的目标。最后，我们概述了几项关键研究方向，旨在克服扩展和采用TNNs的实际障碍，使其更好地融入现代深度学习工作流中。', 'title_zh': '张量ization是一种强大但尚未充分利用的神经网络压缩和可解释性工具。'}
{'arxiv_id': 'arXiv:2505.20110', 'title': 'Proxy-Free GFlowNet', 'authors': 'Ruishuo Chen, Xun Wang, Rui Hu, Zhuoran Li, Longbo Huang', 'link': 'https://arxiv.org/abs/2505.20110', 'abstract': 'Generative Flow Networks (GFlowNets) are a promising class of generative models designed to sample diverse, high-reward structures by modeling distributions over compositional objects. In many real-world applications, obtaining the reward function for such objects is expensive, time-consuming, or requires human input, making it necessary to train GFlowNets from historical datasets. Most existing methods adopt a model-based approach, learning a proxy model from the dataset to approximate the reward function. However, this strategy inherently ties the quality of the learned policy to the accuracy of the proxy, introducing additional complexity and uncertainty into the training process. To overcome these limitations, we propose \\textbf{Trajectory-Distilled GFlowNet (TD-GFN)}, a \\emph{proxy-free} training framework that eliminates the need for out-of-dataset reward queries. Our method is motivated by the key observation that different edges in the associated directed acyclic graph (DAG) contribute unequally to effective policy learning. TD-GFN leverages inverse reinforcement learning to estimate edge-level rewards from the offline dataset, which are then used to ingeniously prune the DAG and guide backward trajectory sampling during training. This approach directs the policy toward high-reward regions while reducing the complexity of model fitting. Empirical results across multiple tasks show that TD-GFN trains both efficiently and reliably, significantly outperforming existing baselines in convergence speed and sample quality.', 'abstract_zh': '轨迹提炼生成流网络（Trajectory-Distilled GFlowNets）：一种无代理模型的训练框架', 'title_zh': '无代理GFlowNet'}
{'arxiv_id': 'arXiv:2505.20096', 'title': 'MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning', 'authors': 'Thang Nguyen, Peter Chin, Yu-Wing Tai', 'link': 'https://arxiv.org/abs/2505.20096', 'abstract': 'We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on either end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, to tackle each stage of the RAG pipeline with task-aware reasoning. Ambiguities may arise from underspecified queries, sparse or indirect evidence in retrieved documents, or the need to integrate information scattered across multiple sources. MA-RAG mitigates these challenges by decomposing the problem into subtasks, such as query disambiguation, evidence extraction, and answer synthesis, and dispatching them to dedicated agents equipped with chain-of-thought prompting. These agents communicate intermediate reasoning and progressively refine the retrieval and synthesis process. Our design allows fine-grained control over information flow without any model fine-tuning. Crucially, agents are invoked on demand, enabling a dynamic and efficient workflow that avoids unnecessary computation. This modular and reasoning-driven architecture enables MA-RAG to deliver robust, interpretable results. Experiments on multi-hop and ambiguous QA benchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free baselines and rivals fine-tuned systems, validating the effectiveness of collaborative agent-based reasoning in RAG.', 'abstract_zh': '多智能体 Retrieval-Augmented Generation (MA-RAG): 一种解决复杂信息搜索任务中固有模糊性和推理挑战的多智能体框架', 'title_zh': 'MA-RAG：基于协作链式推理的多agents检索增强生成'}
{'arxiv_id': 'arXiv:2505.20089', 'title': 'Homophily Enhanced Graph Domain Adaptation', 'authors': 'Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, Qiuhao Zeng, Gezheng Xu, Charles Ling, Boyu Wang', 'link': 'https://arxiv.org/abs/2505.20089', 'abstract': 'Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. In this paper, we highlight the significance of graph homophily, a pivotal factor for graph domain alignment, which, however, has long been overlooked in existing approaches. Specifically, our analysis first reveals that homophily discrepancies exist in benchmarks. Moreover, we also show that homophily discrepancies degrade GDA performance from both empirical and theoretical aspects, which further underscores the importance of homophily alignment in GDA. Inspired by this finding, we propose a novel homophily alignment algorithm that employs mixed filters to smooth graph signals, thereby effectively capturing and mitigating homophily discrepancies between graphs. Experimental results on a variety of benchmarks verify the effectiveness of our method.', 'abstract_zh': '图域适应（GDA）将有标签的源图的知识转移到无标签的目标图上，以应对标签稀缺的挑战。在本文中，我们强调了图同质性的重要性，这是图域对齐的关键因素，但这一因素在现有方法中长期被忽视。具体来说，我们的分析首先揭示了基准中存在的同质性差异。此外，我们还展示了同质性差异从实证和理论两个方面都降低了GDA性能，进一步突显了同质性对齐在GDA中的重要性。受这一发现的启发，我们提出了一种新的同质性对齐算法，该算法使用混合滤波器平滑图信号，从而有效地捕捉和缓解图之间的同质性差异。在多种基准上的实验结果验证了该方法的有效性。', 'title_zh': '同质性增强的图域适应'}
{'arxiv_id': 'arXiv:2505.20085', 'title': 'Explanation User Interfaces: A Systematic Literature Review', 'authors': 'Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo', 'link': 'https://arxiv.org/abs/2505.20085', 'abstract': "Artificial Intelligence (AI) is one of the major technological advancements of this century, bearing incredible potential for users through AI-powered applications and tools in numerous domains. Being often black-box (i.e., its decision-making process is unintelligible), developers typically resort to eXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour of AI models to produce systems that are transparent, fair, reliable, and trustworthy. However, presenting explanations to the user is not trivial and is often left as a secondary aspect of the system's design process, leading to AI systems that are not useful to end-users. This paper presents a Systematic Literature Review on Explanation User Interfaces (XUIs) to gain a deeper understanding of the solutions and design guidelines employed in the academic literature to effectively present explanations to users. To improve the contribution and real-world impact of this survey, we also present a framework for Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide practitioners and academics in the design and evaluation of XUIs.", 'abstract_zh': '人工智能（AI）是本世纪的重大技术进步之一，通过AI驱动的应用和工具在众多领域具有巨大的用户潜力。尽管AI通常表现为黑盒（即其决策过程不透明），开发者通常会采用可解释人工智能（XAI）技术来解释AI模型的行为，从而生成透明、公平、可靠和可信的系统。然而，向用户提供解释并不简单，通常会被作为系统设计过程中的次要方面，导致对最终用户的实用性较差。本文通过对解释用户界面（XUIs）的系统文献综述，深入了解学术文献中用于有效向用户呈现解释的解决方案和设计指南。为了提高该综述的贡献和实际影响，本文还提出了一种面向人类中心的可解释用户界面开发框架（HERMES），以指导从业者和学术界进行XUI的设计与评估。', 'title_zh': '解释用户界面：一项系统文献综述'}
{'arxiv_id': 'arXiv:2505.20067', 'title': 'Community Moderation and the New Epistemology of Fact Checking on Social Media', 'authors': 'Isabelle Augenstein, Michiel Bakker, Tanmoy Chakraborty, David Corney, Emilio Ferrara, Iryna Gurevych, Scott Hale, Eduard Hovy, Heng Ji, Irene Larraz, Filippo Menczer, Preslav Nakov, Paolo Papotti, Dhruv Sahnan, Greta Warren, Giovanni Zagni', 'link': 'https://arxiv.org/abs/2505.20067', 'abstract': 'Social media platforms have traditionally relied on internal moderation teams and partnerships with independent fact-checking organizations to identify and flag misleading content. Recently, however, platforms including X (formerly Twitter) and Meta have shifted towards community-driven content moderation by launching their own versions of crowd-sourced fact-checking -- Community Notes. If effectively scaled and governed, such crowd-checking initiatives have the potential to combat misinformation with increased scale and speed as successfully as community-driven efforts once did with spam. Nevertheless, general content moderation, especially for misinformation, is inherently more complex. Public perceptions of truth are often shaped by personal biases, political leanings, and cultural contexts, complicating consensus on what constitutes misleading content. This suggests that community efforts, while valuable, cannot replace the indispensable role of professional fact-checkers. Here we systemically examine the current approaches to misinformation detection across major platforms, explore the emerging role of community-driven moderation, and critically evaluate both the promises and challenges of crowd-checking at scale.', 'abstract_zh': '社交媒体平台历来依赖内部审核团队和独立事实核查组织来识别和标记误导性内容。然而，包括X（原Twitter）和Meta在内的平台最近转向了社区驱动的内容审核，通过推出自己的众包事实核查——社区笔记。如果有效扩展和治理，这类众包审核倡议有望像社区驱动的努力对付垃圾信息那样，以更大的规模和速度打击虚假信息。尽管如此，尤其是对于虚假信息来说，内容审核本质上更为复杂。公众对真相的看法往往受到个人偏见、政治倾向和文化背景的影响，这使得达成关于何为误导性内容的一致意见变得复杂。这表明，尽管社区努力非常重要，但专业事实核查者的作用不可或缺。本文系统性地分析了主要平台虚假信息检测的当前方法，探讨了社区驱动审核的新兴作用，并批判性地评估了大规模众包审核的前景与挑战。', 'title_zh': '社交媒体中的社区 moderation 及其对事实核查的新 epistemology'}
{'arxiv_id': 'arXiv:2505.20066', 'title': 'Automated data curation for self-supervised learning in underwater acoustic analysis', 'authors': 'Hilde I Hummel, Sandjai Bhulai, Burooj Ghani, Rob van der Mei', 'link': 'https://arxiv.org/abs/2505.20066', 'abstract': 'The sustainability of the ocean ecosystem is threatened by increased levels of sound pollution, making monitoring crucial to understand its variability and impact. Passive acoustic monitoring (PAM) systems collect a large amount of underwater sound recordings, but the large volume of data makes manual analysis impossible, creating the need for automation. Although machine learning offers a potential solution, most underwater acoustic recordings are unlabeled. Self-supervised learning models have demonstrated success in learning from large-scale unlabeled data in various domains like computer vision, Natural Language Processing, and audio. However, these models require large, diverse, and balanced datasets for training in order to generalize well. To address this, a fully automated self-supervised data curation pipeline is proposed to create a diverse and balanced dataset from raw PAM data. It integrates Automatic Identification System (AIS) data with recordings from various hydrophones in the U.S. waters. Using hierarchical k-means clustering, the raw audio data is sampled and then combined with AIS samples to create a balanced and diverse dataset. The resulting curated dataset enables the development of self-supervised learning models, facilitating various tasks such as monitoring marine mammals and assessing sound pollution.', 'abstract_zh': '海洋生态系统的可持续性受到噪声污染水平升高的威胁，监测变得至关重要以了解其变异性及其影响。被动声学监测（PAM）系统收集了大量的水下声音记录，但由于数据量庞大，手工分析变得不可能，从而创造了自动化的需求。虽然机器学习提供了潜在的解决方案，但大多数水下声学记录通常是未标记的。自我监督学习模型在计算机视觉、自然语言处理和音频等领域从大规模未标记数据中学习方面已经取得了成功。然而，这些模型在训练时需要大量、多样且平衡的数据集才能实现良好的泛化。为了解决这一问题，提出了一个完全自动化的自我监督数据整理流水线，从原始PAM数据中创建一个多样且平衡的数据集。该流水线将自动识别系统（AIS）数据与美国水域中各种水听器的记录相结合。利用分层K均值聚类，对原始音频数据进行采样，然后与AIS样本结合，生成一个平衡且多样化的数据集。整理后生成的数据集使自我监督学习模型得以开发，可用于监测海洋哺乳动物和评估噪声污染等多种任务。', 'title_zh': '自动数据策展以促进水下声学分析的自监督学习'}
{'arxiv_id': 'arXiv:2505.20063', 'title': 'SAEs Are Good for Steering -- If You Select the Right Features', 'authors': 'Dana Arad, Aaron Mueller, Yonatan Belinkov', 'link': 'https://arxiv.org/abs/2505.20063', 'abstract': "Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.", 'abstract_zh': '稀疏自编码器（SAEs）已被提出作为一种无监督方法来学习模型潜在空间的分解。这使得诸如引导（steering）——通过激活某些概念来影响模型的输出——这样的有用应用成为可能，而无需使用标注数据。当前的方法通过分析激活特征的输入标记来识别用于引导的SAE特征。然而，最近的工作表明，仅依靠激活并不能完整描述特征对模型输出的影响。在本工作中，我们区分了两种类型的特征：输入特征，主要捕捉模型输入中的模式；和输出特征，对模型输出具有可理解的影响。我们提出了输入得分和输出得分来表征和定位这些类型的特征，并展示了高值的输入得分和输出得分很少同时出现在同一特征中。这些发现具有实际意义：在移除低输出得分的特征后，使用SAEs进行引导时，我们获得了2-3倍的性能提升，使其与监督方法相当。', 'title_zh': 'SAEs在转向控制中效果良好——如果你选择合适的特征'}
{'arxiv_id': 'arXiv:2505.20033', 'title': 'EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition', 'authors': 'Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Maurice Kraus, Felix Friedrich, Huu Nguyen, Krishna Kalyan, Kourosh Nadi, Kristian Kersting, Sören Auer', 'link': 'https://arxiv.org/abs/2505.20033', 'abstract': "Effective human-AI interaction relies on AI's ability to accurately perceive and interpret human emotions. Current benchmarks for vision and vision-language models are severely limited, offering a narrow emotional spectrum that overlooks nuanced states (e.g., bitterness, intoxication) and fails to distinguish subtle differences between related feelings (e.g., shame vs. embarrassment). Existing datasets also often use uncontrolled imagery with occluded faces and lack demographic diversity, risking significant bias. To address these critical gaps, we introduce EmoNet Face, a comprehensive benchmark suite. EmoNet Face features: (1) A novel 40-category emotion taxonomy, meticulously derived from foundational research to capture finer details of human emotional experiences. (2) Three large-scale, AI-generated datasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and controlled demographic balance across ethnicity, age, and gender. (3) Rigorous, multi-expert annotations for training and high-fidelity evaluation. (4) We build Empathic Insight Face, a model achieving human-expert-level performance on our benchmark. The publicly released EmoNet Face suite - taxonomy, datasets, and model - provides a robust foundation for developing and evaluating AI systems with a deeper understanding of human emotions.", 'abstract_zh': '有效的Man-AI交互依赖于AI准确感知和解读人类情绪的能力。现有的视觉和视觉语言模型基准严重受限，提供的情感范围狭窄，忽视了细腻的情感状态（如苦涩、醉酒），并且难以区分相關情感之间的细微差别（如羞耻 vs 尴尬）。现有数据集通常使用未经控制的、面部被遮挡的图像，并且缺少人口统计学多样性，这可能会导致显著的偏见。为解决这些关键缺口，我们引入了EmoNet Face这一综合基准套件。EmoNet Face包含：(1) 一个新的40类情感分类体系，经过详细研究精心构建，以捕捉人类情感体验的更多细节。(2) 三个大规模的AI生成数据集（EmoNet HQ、Binary和Big），包含明确的正面面部表情，并且在种族、年龄和性别上实现了可控的人口统计学平衡。(3) 严格的多专家注释，用于训练和高保真评估。(4) 我们构建了Empathic Insight Face模型，在我们的基准测试中达到了人类专家水平的性能。公开发布的EmoNet Face套件——分类体系、数据集和模型——为开发和评估更深入理解人类情感的AI系统提供了坚实的基础。', 'title_zh': 'EmoNet-Face：一个专家标注的合成情绪识别基准数据集'}
{'arxiv_id': 'arXiv:2505.20030', 'title': 'Multiple Descents in Deep Learning as a Sequence of Order-Chaos Transitions', 'authors': 'Wenbo Wei, Nicholas Chong Jia Le, Choy Heng Lai, Ling Feng', 'link': 'https://arxiv.org/abs/2505.20030', 'abstract': "We observe a novel 'multiple-descent' phenomenon during the training process of LSTM, in which the test loss goes through long cycles of up and down trend multiple times after the model is overtrained. By carrying out asymptotic stability analysis of the models, we found that the cycles in test loss are closely associated with the phase transition process between order and chaos, and the local optimal epochs are consistently at the critical transition point between the two phases. More importantly, the global optimal epoch occurs at the first transition from order to chaos, where the 'width' of the 'edge of chaos' is the widest, allowing the best exploration of better weight configurations for learning.", 'abstract_zh': '我们在LSTM模型训练过程中观察到一种新颖的“多极降”现象，在模型过拟合之后，测试损失呈现出多次长期上下波动的周期。通过对模型的渐近稳定性分析发现，测试损失的周期与有序与混沌相变过程密切相关，局部最优时期始终处于两种相态之间的临界转换点。更重要的是，全局最优时期发生在从有序到混沌的第一次相变中，此时“混沌边缘”的“宽度”最大，能够更好地探索更好的权重配置以促进学习。', 'title_zh': '深度学习中的多次下降作为顺序的顺序-混沌转换'}
{'arxiv_id': 'arXiv:2505.20026', 'title': 'Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage', 'authors': 'Xinping Chen, Chen Liu', 'link': 'https://arxiv.org/abs/2505.20026', 'abstract': 'We propose Gradient Inversion Transcript (GIT), a novel generative approach for reconstructing training data from leaked gradients. GIT employs a generative attack model, whose architecture is tailored to align with the structure of the leaked model based on theoretical analysis. Once trained offline, GIT can be deployed efficiently and only relies on the leaked gradients to reconstruct the input data, rendering it applicable under various distributed learning environments. When used as a prior for other iterative optimization-based methods, GIT not only accelerates convergence but also enhances the overall reconstruction quality. GIT consistently outperforms existing methods across multiple datasets and demonstrates strong robustness under challenging conditions, including inaccurate gradients, data distribution shifts and discrepancies in model parameters.', 'abstract_zh': '我们提出了一种新颖的生成方法Gradient Inversion Transcript (GIT)，用于从泄露的梯度重建训练数据。GIT采用了一种生成攻击模型，其架构根据理论分析专门设计以与泄露模型的结构对齐。一旦离线训练完成，GIT可以高效部署，并且仅依赖泄露的梯度来重建输入数据，使其在各种分布式学习环境中适用。当作为其他迭代优化方法的先验时，GIT不仅能加速收敛，还能提高整体重建质量。在多个数据集上，GIT一致地优于现有方法，并在包括不准确的梯度、数据分布转移和模型参数差异在内的挑战性条件下展现出强大的鲁棒性。', 'title_zh': '梯度 inversion 转录：利用鲁棒生成先验从梯度泄露重建训练数据'}
{'arxiv_id': 'arXiv:2505.19983', 'title': 'ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications', 'authors': 'Tong Wu, Zhiyong Chen, Dazhi He, Feng Yang, Meixia Tao, Xiaodong Xu, Wenjun Zhang, Ping Zhang', 'link': 'https://arxiv.org/abs/2505.19983', 'abstract': 'Diffusion models (DMs) have recently achieved significant success in wireless communications systems due to their denoising capabilities. The broadcast nature of wireless signals makes them susceptible not only to Gaussian noise, but also to unaware interference. This raises the question of whether DMs can effectively mitigate interference in wireless semantic communication systems. In this paper, we model the interference cancellation problem as a maximum a posteriori (MAP) problem over the joint posterior probability of the signal and interference, and theoretically prove that the solution provides excellent estimates for the signal and interference. To solve this problem, we develop an interference cancellation diffusion model (ICDM), which decomposes the joint posterior into independent prior probabilities of the signal and interference, along with the channel transition probablity. The log-gradients of these distributions at each time step are learned separately by DMs and accurately estimated through deriving. ICDM further integrates these gradients with advanced numerical iteration method, achieving accurate and rapid interference cancellation. Extensive experiments demonstrate that ICDM significantly reduces the mean square error (MSE) and enhances perceptual quality compared to schemes without ICDM. For example, on the CelebA dataset under the Rayleigh fading channel with a signal-to-noise ratio (SNR) of $20$ dB and signal to interference plus noise ratio (SINR) of 0 dB, ICDM reduces the MSE by 4.54 dB and improves the learned perceptual image patch similarity (LPIPS) by 2.47 dB.', 'abstract_zh': '扩散模型（DMs）在无线通信系统中由于其去噪能力 recently取得显著成功，并被用于有效减轻无线语义通信系统中的干扰。', 'title_zh': 'ICDM: 干扰消除扩散模型在无线语义通信中的应用'}
{'arxiv_id': 'arXiv:2505.19955', 'title': 'MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research', 'authors': 'Hui Chen, Miao Xiong, Yujie Lu, Wei Han, Ailin Deng, Yufei He, Jiaying Wu, Yibo Li, Yue Liu, Bryan Hooi', 'link': 'https://arxiv.org/abs/2505.19955', 'abstract': 'Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce MLR-Bench, a comprehensive benchmark for evaluating AI agents on open-ended machine learning research. MLR-Bench includes three key components: (1) 201 research tasks sourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2) MLR-Judge, an automated evaluation framework combining LLM-based reviewers with carefully designed review rubrics to assess research quality; and (3) MLR-Agent, a modular agent scaffold capable of completing research tasks through four stages: idea generation, proposal formulation, experimentation, and paper writing. Our framework supports both stepwise assessment across these distinct research stages, and end-to-end evaluation of the final research paper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced coding agent, finding that while LLMs are effective at generating coherent ideas and well-structured papers, current coding agents frequently (e.g., in 80% of the cases) produce fabricated or invalidated experimental results--posing a major barrier to scientific reliability. We validate MLR-Judge through human evaluation, showing high agreement with expert reviewers, supporting its potential as a scalable tool for research evaluation. We open-source MLR-Bench to help the community benchmark, diagnose, and improve AI research agents toward trustworthy and transparent scientific discovery.', 'abstract_zh': 'Recent Advancements in AI Agents Have Demonstrated Their Growing Potential to Drive and Support Scientific Discovery: Introducing MLR-Bench，一个综合基准用于评估AI代理在开放机器学习研究中的表现', 'title_zh': 'MLR-Bench: 评估AI代理在开放性机器学习研究中的表现'}
{'arxiv_id': 'arXiv:2505.19951', 'title': 'Novel Loss-Enhanced Universal Adversarial Patches for Sustainable Speaker Privacy', 'authors': 'Elvir Karimov, Alexander Varlamov, Danil Ivanov, Dmitrii Korzh, Oleg Y. Rogov', 'link': 'https://arxiv.org/abs/2505.19951', 'abstract': 'Deep learning voice models are commonly used nowadays, but the safety processing of personal data, such as human identity and speech content, remains suspicious. To prevent malicious user identification, speaker anonymization methods were proposed. Current methods, particularly based on universal adversarial patch (UAP) applications, have drawbacks such as significant degradation of audio quality, decreased speech recognition quality, low transferability across different voice biometrics models, and performance dependence on the input audio length. To mitigate these drawbacks, in this work, we introduce and leverage the novel Exponential Total Variance (TV) loss function and provide experimental evidence that it positively affects UAP strength and imperceptibility. Moreover, we present a novel scalable UAP insertion procedure and demonstrate its uniformly high performance for various audio lengths.', 'abstract_zh': '基于指数总变差损失函数的通用对抗性补丁增强的说话人匿名化方法', 'title_zh': '新型损失增强通用 adversarial 贴图以实现可持续说话人隐私'}
{'arxiv_id': 'arXiv:2505.19920', 'title': 'A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks', 'authors': 'Sebastian Groß, Stefan Heindorf, Philipp Terhörst', 'link': 'https://arxiv.org/abs/2505.19920', 'abstract': 'Traditional face recognition systems rely on extracting fixed face representations, known as templates, to store and verify identities. These representations are typically generated by neural networks that often lack explainability and raise concerns regarding fairness and privacy. In this work, we propose a novel model-template (MOTE) approach that replaces vector-based face templates with small personalized neural networks. This design enables more responsible face recognition for small and medium-scale systems. During enrollment, MOTE creates a dedicated binary classifier for each identity, trained to determine whether an input face matches the enrolled identity. Each classifier is trained using only a single reference sample, along with synthetically balanced samples to allow adjusting fairness at the level of a single individual during enrollment. Extensive experiments across multiple datasets and recognition systems demonstrate substantial improvements in fairness and particularly in privacy. Although the method increases inference time and storage requirements, it presents a strong solution for small- and mid-scale applications where fairness and privacy are critical.', 'abstract_zh': '一种新型模型-模板（MOTE）方法：将基于向量的脸模板替换为小型个性化神经网络，以实现更加负责的脸部识别', 'title_zh': '一种适用于中小规模系统的个性化神经网络负责任人脸识别方法'}
{'arxiv_id': 'arXiv:2505.19915', 'title': 'Evaluating AI cyber capabilities with crowdsourced elicitation', 'authors': 'Artem Petrov, Dmitrii Volkov', 'link': 'https://arxiv.org/abs/2505.19915', 'abstract': 'As AI systems become increasingly capable, understanding their offensive cyber potential is critical for informed governance and responsible deployment. However, it\'s hard to accurately bound their capabilities, and some prior evaluations dramatically underestimated them. The art of extracting maximum task-specific performance from AIs is called "AI elicitation", and today\'s safety organizations typically conduct it in-house. In this paper, we explore crowdsourcing elicitation efforts as an alternative to in-house elicitation work.\nWe host open-access AI tracks at two Capture The Flag (CTF) competitions: AI vs. Humans (400 teams) and Cyber Apocalypse_ (4000 teams). The AI teams achieve outstanding performance at both events, ranking top-13% and top-21% respectively for a total of \\$7500 in bounties. This impressive performance suggests that open-market elicitation may offer an effective complement to in-house elicitation. We propose elicitation bounties as a practical mechanism for maintaining timely, cost-effective situational awareness of emerging AI capabilities.\nAnother advantage of open elicitations is the option to collect human performance data at scale. Applying METR\'s methodology, we found that AI agents can reliably solve cyber challenges requiring one hour or less of effort from a median human CTF participant.', 'abstract_zh': '随着AI系统的不断进步，理解其在网络攻击中的潜在能力对于明智的治理和负责任的应用至关重要。然而，准确界定其能力十分困难，一些先前的评估极大地低估了它们的能力。从AI中提取最大任务特定性能的艺术被称为“AI启示”，当前的安全组织通常在内部进行这一工作。本文探讨了将启示工作外包给众包作为一种替代方案。\n\n我们在美国两个Capture The Flag (CTF) 竞赛中主办开放访问的AI赛道：AI vs. Humans（400支队伍）和Cyber Apocalypse_（4000支队伍）。AI团队在两个赛事中表现出色，分别获得总奖金7500美元中的前13%和前21%的排名。这一出色的表现表明，开放市场启示可能为内部启示提供有效的补充。我们提议使用启示奖金作为一种实际机制，以保持对新兴AI能力的及时、成本效益高的态势感知。\n\n开放启示的另一个优势是可以大规模收集人类性能数据。采用METR的方法论，我们发现AI代理能够可靠地解决需要中位数CTF参与者一小时或更少努力的网络挑战。', 'title_zh': '基于众包诱发评估AI网络能力'}
{'arxiv_id': 'arXiv:2505.19842', 'title': 'PCDCNet: A Surrogate Model for Air Quality Forecasting with Physical-Chemical Dynamics and Constraints', 'authors': 'Shuo Wang, Yun Cheng, Qingye Meng, Olga Saukh, Jiang Zhang, Jingfang Fan, Yuanting Zhang, Xingyuan Yuan, Lothar Thiele', 'link': 'https://arxiv.org/abs/2505.19842', 'abstract': 'Air quality forecasting (AQF) is critical for public health and environmental management, yet remains challenging due to the complex interplay of emissions, meteorology, and chemical transformations. Traditional numerical models, such as CMAQ and WRF-Chem, provide physically grounded simulations but are computationally expensive and rely on uncertain emission inventories. Deep learning models, while computationally efficient, often struggle with generalization due to their lack of physical constraints. To bridge this gap, we propose PCDCNet, a surrogate model that integrates numerical modeling principles with deep learning. PCDCNet explicitly incorporates emissions, meteorological influences, and domain-informed constraints to model pollutant formation, transport, and dissipation. By combining graph-based spatial transport modeling, recurrent structures for temporal accumulation, and representation enhancement for local interactions, PCDCNet achieves state-of-the-art (SOTA) performance in 72-hour station-level PM2.5 and O3 forecasting while significantly reducing computational costs. Furthermore, our model is deployed in an online platform, providing free, real-time air quality forecasts, demonstrating its scalability and societal impact. By aligning deep learning with physical consistency, PCDCNet offers a practical and interpretable solution for AQF, enabling informed decision-making for both personal and regulatory applications.', 'abstract_zh': '空气质量预测（AQF）对于公共卫生和环境管理至关重要，但由于排放、气象和化学转化的复杂相互作用，仍具有挑战性。传统的数值模型，如CMAQ和WRF-Chem，提供了物理基础的模拟，但计算成本高且依赖于不确定的排放清单。深度学习模型虽然计算效率高，但由于缺乏物理约束，往往在泛化能力上存在局限。为弥合这一差距，我们提出了一种名为PCDCNet的替代模型，将数值模拟原理与深度学习相结合。PCDCNet明确地将排放、气象影响以及领域指导的约束纳入模型，以建模污染物的生成、传输和消散。通过结合基于图形的空间传输建模、用于时间积累的递归结构以及局部交互的表示增强，PCDCNet在72小时站点级PM2.5和O3预测中达到了最先进的性能，同时显著降低了计算成本。此外，该模型部署在一个在线平台上，提供免费的实时空气质量预报，展示了其可扩展性和社会影响。通过将深度学习与物理一致性相结合，PCDCNet为空气质量预测提供了实用且可解释的解决方案，促进了个人和监管应用中的知情决策。', 'title_zh': 'PCDCNet：一种考虑物理化学动态与约束的空气质量预测代理模型'}
{'arxiv_id': 'arXiv:2505.19827', 'title': 'Revisiting Glorot Initialization for Long-Range Linear Recurrences', 'authors': 'Noga Bar, Mariia Seleznova, Yotam Alexander, Gitta Kutyniok, Raja Giryes', 'link': 'https://arxiv.org/abs/2505.19827', 'abstract': 'Proper initialization is critical for Recurrent Neural Networks (RNNs), particularly in long-range reasoning tasks, where repeated application of the same weight matrix can cause vanishing or exploding signals. A common baseline for linear recurrences is Glorot initialization, designed to ensure stable signal propagation--but derived under the infinite-width, fixed-length regime--an unrealistic setting for RNNs processing long sequences. In this work, we show that Glorot initialization is in fact unstable: small positive deviations in the spectral radius are amplified through time and cause the hidden state to explode. Our theoretical analysis demonstrates that sequences of length $t = O(\\sqrt{n})$, where $n$ is the hidden width, are sufficient to induce instability. To address this, we propose a simple, dimension-aware rescaling of Glorot that shifts the spectral radius slightly below one, preventing rapid signal explosion or decay. These results suggest that standard initialization schemes may break down in the long-sequence regime, motivating a separate line of theory for stable recurrent initialization.', 'abstract_zh': '恰当的初始化对于循环神经网络（RNNs）至关重要，特别是在长范围推理任务中，相同的权重矩阵的反复应用会导致信号消失或爆炸。线性递归的常见基线是Glorot初始化，旨在确保信号传播的稳定性——但这一初始化是在无限宽度、固定长度的假设下推导出来的，这与处理长序列的RNNs的实际设置不现实。在本文中，我们证明Glorot初始化实际上并不稳定：谱半径的小正偏差随时间放大并导致隐藏状态爆炸。我们的理论分析表明，长度为$t = O(\\sqrt{n})$的序列，其中$n$是隐藏维度，就足以引发不稳定性。为了解决这一问题，我们提出了一种简单且维度感知的Glorot初始化调整，将谱半径稍微调整到低于1，从而防止信号的快速爆炸或衰减。这些结果表明，标准的初始化方案在长序列设置下可能失效，这激励建立一条独立的理论线来实现稳定的递归初始化。', 'title_zh': '重启Glorot初始化以适用于长范围线性循环'}
{'arxiv_id': 'arXiv:2505.19825', 'title': 'Foundation Models for Tabular Data within Systemic Contexts Need Grounding', 'authors': 'Tassilo Klein, Johannes Hoffart', 'link': 'https://arxiv.org/abs/2505.19825', 'abstract': 'Current research on tabular foundation models often overlooks the complexities of large-scale, real-world data by treating tables as isolated entities and assuming information completeness, thereby neglecting the vital operational context. To address this, we introduce the concept of Semantically Linked Tables (SLT), recognizing that tables are inherently connected to both declarative and procedural operational knowledge. We propose Foundation Models for Semantically Linked Tables (FMSLT), which integrate these components to ground tabular data within its true operational context. This comprehensive representation unlocks the full potential of machine learning for complex, interconnected tabular data across diverse domains. Realizing FMSLTs requires access to operational knowledge that is often unavailable in public datasets, highlighting the need for close collaboration between domain experts and researchers. Our work exposes the limitations of current tabular foundation models and proposes a new direction centered on FMSLTs, aiming to advance robust, context-aware models for structured data.', 'abstract_zh': '当前对表格基础模型的研究往往忽略了大规模现实世界数据的复杂性，将其视为孤立的实体并假设信息完备性，从而忽视了其重要的操作背景。为解决这一问题，我们引入了语义链接表格（SLT）的概念，认识到表格本质上与声明性和程序性操作知识紧密相连。我们提出了语义链接表格的基础模型（FMSLT），将这些组件结合起来，使表格数据在其真实的操作背景下得以体现。这种全面的表示形式解锁了机器学习在复杂、互联表格数据领域的全部潜力，适用于多个领域。实现FMSLTs需要访问公共数据集中通常不可用的操作知识，这突显了领域专家与研究人员密切合作的必要性。我们的研究揭示了当前表格基础模型的局限性，并提出了以FMSLT为中心的新方向，旨在推动结构化数据的稳健、基于上下文的模型的发展。', 'title_zh': '系统性背景下表格数据的Foundation Models需要 grounding'}
{'arxiv_id': 'arXiv:2505.19823', 'title': 'LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning in Heterogeneous Environments', 'authors': 'Pengcheng Sun, Erwu Liu, Wei Ni, Rui Wang, Yuanzhe Geng, Lijuan Lai, Abbas Jamalipour', 'link': 'https://arxiv.org/abs/2505.19823', 'abstract': 'Federated Learning (FL) is a distributed machine learning paradigm based on protecting data privacy of devices, which however, can still be broken by gradient leakage attack via parameter inversion techniques. Differential privacy (DP) technology reduces the risk of private data leakage by adding artificial noise to the gradients, but detrimental to the FL utility at the same time, especially in the scenario where the data is Non-Independent Identically Distributed (Non-IID). Based on the impact of heterogeneous data on aggregation performance, this paper proposes a Lightweight Adaptive Privacy Allocation (LAPA) strategy, which assigns personalized privacy budgets to devices in each aggregation round without transmitting any additional information beyond gradients, ensuring both privacy protection and aggregation efficiency. Furthermore, the Deep Deterministic Policy Gradient (DDPG) algorithm is employed to optimize the transmission power, in order to determine the optimal timing at which the adaptively attenuated artificial noise aligns with the communication noise, enabling an effective balance between DP and system utility. Finally, a reliable aggregation strategy is designed by integrating communication quality and data distribution characteristics, which improves aggregation performance while preserving privacy. Experimental results demonstrate that the personalized noise allocation and dynamic optimization strategy based on LAPA proposed in this paper enhances convergence performance while satisfying the privacy requirements of FL.', 'abstract_zh': '联邦学习(Federated Learning)是一种基于保护设备数据隐私的分布式机器学习范式，但是仍可通过参数反向技术遭受梯度泄漏攻击的破坏。差分隐私(Differential Privacy)技术通过对梯度添加人工噪声来降低私有数据泄漏的风险，但同时会损害联邦学习的实用性，尤其是在数据非独立同分布(Non-IID)的场景中。基于异质数据对聚合性能的影响，本文提出一种轻量级自适应隐私分配(LAPA)策略，在每次聚合周期内为设备分配个性化的隐私预算，而无需传输任何额外信息，确保同时实现隐私保护和聚合效率。此外，采用深度确定性策略梯度(Deep Deterministic Policy Gradient, DDPG)算法优化传输功率，以确定适配衰减人工噪声与通信噪声的最佳时机，实现差分隐私与系统实用性的有效平衡。最后，通过整合通信质量和数据分布特征设计一种可靠的聚合策略，改进聚合性能同时保持隐私。实验结果表明，本文提出的基于LAPA的个性化噪声分配和动态优化策略在满足联邦学习隐私要求的同时提升了收敛性能。', 'title_zh': '基于LAPA的异构环境中无线联邦学习的动态隐私优化'}
{'arxiv_id': 'arXiv:2505.19790', 'title': 'Alpay Algebra III: Observer-Coupled Collapse and the Temporal Drift of Identity', 'authors': 'Faruk Alpay', 'link': 'https://arxiv.org/abs/2505.19790', 'abstract': 'This paper introduces a formal framework for modeling observer-dependent collapse dynamics and temporal identity drift within artificial and mathematical systems, grounded entirely in the symbolic foundations of Alpay Algebra. Building upon the fixed-point emergence structures developed in Alpay Algebra I and II, this third installment formalizes the observer-coupled {\\phi}-collapse process through transfinite categorical flows and curvature-driven identity operators. We define a novel temporal drift mechanism as a recursive deformation of identity signatures under entangled observer influence, constructing categorical invariants that evolve across fold iterations. The proposed system surpasses conventional identity modeling in explainable AI (XAI) by encoding internal transformation history into a symbolic fixed-point structure, offering provable traceability and temporal coherence. Applications range from AI self-awareness architectures to formal logic systems where identity is not static but dynamically induced by observation. The theoretical results also offer a mathematically rigorous basis for future AI systems with stable self-referential behavior, positioning Alpay Algebra as a next-generation symbolic framework bridging category theory, identity logic, and observer dynamics.', 'abstract_zh': '本文介绍了一种形式框架，用于在人工和数学系统中建模观察者依赖的塌缩动力学和时间身份漂移，完全基于Alpay代数的符号基础。在Alpay代数I和II中发展起来的固定点涌现结构的基础上，本文的第三部分通过超限范畴流和曲率驱动的身份运算符正式化了观察者耦合的{\\phi}-塌缩过程。定义了一种新的时间漂移机制，作为缠结观察者影响下身份签名的递归变形，构建了在折叠迭代中演化的范畴不变式。所提出的系统超越了在解释性人工智能(XAI)中的常规身份建模，通过将内部转变历史编码到符号固定点结构中，提供了可证明的可追溯性和时间连续性。应用范围从具有自意识架构的人工智能到身份不是静态而是由观察动态诱导的正式逻辑系统。理论结果还为具有稳定自我参照行为的未来人工智能系统提供了一个严格的数学基础，将Alpay代数定位为一种下一代符号框架，结合了范畴论、身份逻辑和观察者动力学。', 'title_zh': 'Alpay代数III：观察者耦合的坍缩与身份的时间漂移'}
{'arxiv_id': 'arXiv:2505.19757', 'title': 'CIDRe: A Reference-Free Multi-Aspect Criterion for Code Comment Quality Measurement', 'authors': 'Maria Dziuba, Valentin Malykh', 'link': 'https://arxiv.org/abs/2505.19757', 'abstract': "Effective generation of structured code comments requires robust quality metrics for dataset curation, yet existing approaches (SIDE, MIDQ, STASIS) suffer from limited code-comment analysis. We propose CIDRe, a language-agnostic reference-free quality criterion combining four synergistic aspects: (1) relevance (code-comment semantic alignment), (2) informativeness (functional coverage), (3) completeness (presence of all structure sections), and (4) description length (detail sufficiency). We validate our criterion on a manually annotated dataset. Experiments demonstrate CIDRe's superiority over existing metrics, achieving improvement in cross-entropy evaluation. When applied to filter comments, the models finetuned on CIDRe-filtered data show statistically significant quality gains in GPT-4o-mini assessments.", 'abstract_zh': '有效生成结构化代码注释需要 robust 的质量评估指标以确保数据集的高质量，现有的方法（如SIDE、MIDQ、STASIS）在代码-注释分析方面存在局限性。我们提出 CIDRe，这是一种语言无关的无参考质量标准，结合了四个协同方面：（1）相关性（代码-注释语义对齐），（2）信息量（功能覆盖率），（3）完整性（所有结构部分的存在），和（4）描述长度（细节充分性）。我们对手动标注的数据集验证了该标准。实验表明，CIDRe 在交叉熵评估中优于现有指标，并且在使用 CIDRe 过滤后的数据微调模型的 GPT-4o-mini 评估中显示出统计显著的质量提升。', 'title_zh': 'CIDRe：一种无需参考的多方面代码注释质量评估标准'}
{'arxiv_id': 'arXiv:2505.19752', 'title': 'Discrete Markov Bridge', 'authors': 'Hengli Li, Yuxuan Wang, Song-Chun Zhu, Ying Nian Wu, Zilong Zheng', 'link': 'https://arxiv.org/abs/2505.19752', 'abstract': 'Discrete diffusion has recently emerged as a promising paradigm in discrete data modeling. However, existing methods typically rely on a fixed rate transition matrix during training, which not only limits the expressiveness of latent representations, a fundamental strength of variational methods, but also constrains the overall design space. To address these limitations, we propose Discrete Markov Bridge, a novel framework specifically designed for discrete representation learning. Our approach is built upon two key components: Matrix Learning and Score Learning. We conduct a rigorous theoretical analysis, establishing formal performance guarantees for Matrix Learning and proving the convergence of the overall framework. Furthermore, we analyze the space complexity of our method, addressing practical constraints identified in prior studies. Extensive empirical evaluations validate the effectiveness of the proposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO) of 1.38 on the Text8 dataset, outperforming established baselines. Moreover, the proposed model demonstrates competitive performance on the CIFAR-10 dataset, achieving results comparable to those obtained by image-specific generation approaches.', 'abstract_zh': '离散扩散 Recently Emerged as a Promising Paradigm in Discrete Data Modeling: Discrete Markov Bridge—a Novel Framework for Discrete Representation Learning', 'title_zh': '离散马尔可夫桥'}
{'arxiv_id': 'arXiv:2505.19719', 'title': 'OCN: Effectively Utilizing Higher-Order Common Neighbors for Better Link Prediction', 'authors': 'Juntong Wang, Xiyuan Wang, Muhan Zhang', 'link': 'https://arxiv.org/abs/2505.19719', 'abstract': 'Common Neighbors (CNs) and their higher-order variants are important pairwise features widely used in state-of-the-art link prediction methods. However, existing methods often struggle with the repetition across different orders of CNs and fail to fully leverage their potential. We identify that these limitations stem from two key issues: redundancy and over-smoothing in high-order common neighbors. To address these challenges, we design orthogonalization to eliminate redundancy between different-order CNs and normalization to mitigate over-smoothing. By combining these two techniques, we propose Orthogonal Common Neighbor (OCN), a novel approach that significantly outperforms the strongest baselines by an average of 7.7% on popular link prediction benchmarks. A thorough theoretical analysis is provided to support our method. Ablation studies also verify the effectiveness of our orthogonalization and normalization techniques.', 'abstract_zh': 'Common Neighbors (CNs) 及其高阶变体是广泛应用于先进链接预测方法中的重要成对特征。然而，现有方法往往难以处理不同阶次的重复性问题，并未能充分挖掘其潜力。我们发现这些限制源于两个关键问题：高阶共同邻居的冗余性和过度平滑。为应对这些挑战，我们设计了正交化来消除不同阶次共同邻居之间的冗余，并使用规范化来减轻过度平滑。通过结合这两种技术，我们提出了一种新颖的方法——正交共同邻居（OCN），该方法在流行的链接预测基准测试中平均比最强基线高出7.7%。提供了详尽的理论分析以支持我们的方法，并通过消融研究验证了我们正交化和规范化技术的有效性。', 'title_zh': 'OCN：更有效地利用高阶共同邻居进行链接预测'}
{'arxiv_id': 'arXiv:2505.19699', 'title': 'Mosaic: Data-Free Knowledge Distillation via Mixture-of-Experts for Heterogeneous Distributed Environments', 'authors': 'Junming Liu, Yanting Gao, Siyuan Meng, Yifei Sun, Aoqi Wu, Yufei Jin, Yirong Chen, Ding Wang, Guosun Zeng', 'link': 'https://arxiv.org/abs/2505.19699', 'abstract': "Federated Learning (FL) is a decentralized machine learning paradigm that enables clients to collaboratively train models while preserving data privacy. However, the coexistence of model and data heterogeneity gives rise to inconsistent representations and divergent optimization dynamics across clients, ultimately hindering robust global performance. To transcend these challenges, we propose Mosaic, a novel data-free knowledge distillation framework tailored for heterogeneous distributed environments. Mosaic first trains local generative models to approximate each client's personalized distribution, enabling synthetic data generation that safeguards privacy through strict separation from real data. Subsequently, Mosaic forms a Mixture-of-Experts (MoE) from client models based on their specialized knowledge, and distills it into a global model using the generated data. To further enhance the MoE architecture, Mosaic integrates expert predictions via a lightweight meta model trained on a few representative prototypes. Extensive experiments on standard image classification benchmarks demonstrate that Mosaic consistently outperforms state-of-the-art approaches under both model and data heterogeneity. The source code has been published at this https URL.", 'abstract_zh': '联邦学习（FL）是一种分布式机器学习范式，允许客户端协同训练模型同时保护数据隐私。然而，模型和数据的异质性导致了客户端之间不一致的表示和优化动态，最终妨碍了稳健的全局性能。为克服这些挑战，我们提出Mosaic，这是一种针对异质分布式环境的数据免费知识蒸馏框架。Mosaic首先训练本地生成模型以近似每个客户端的个性化分布，从而通过严格与真实数据分离生成合成数据，以保障隐私。随后，Mosaic基于客户端模型的专业知识构建了一个专家系统的混合体（MoE），并使用生成的数据将其蒸馏到全局模型中。为了进一步增强MoE架构，Mosaic通过一个基于少量代表性原型训练的轻量级元模型集成专家预测。在标准图像分类基准上的广泛实验表明，Mosaic在模型和数据异质性条件下均能一致性地超越现有顶级方法。源代码已发布于该网址。', 'title_zh': 'mosaic: 面向异构分布式环境的混合专家无数据知识蒸馏'}
{'arxiv_id': 'arXiv:2505.19698', 'title': 'JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning', 'authors': 'Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu', 'link': 'https://arxiv.org/abs/2505.19698', 'abstract': 'Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.', 'abstract_zh': '近期基于模型的强化学习（MBRL）在Atari100k基准上的表现达到了超人类水平，这主要得益于在强大扩散世界模型上训练的强化学习代理。然而，我们发现当前的聚合数据掩盖了一个重要的性能不对称性：在某些任务中，MBRL代理表现出色远远超过人类，而在其他任务中则表现糟糕，这种不对称性使得聚合指标被夸大。尤其是在使用扩散世界模型训练的像素基代理上，这一点尤为明显。在本文中，我们尝试通过划分所有任务为代理优化或人类优化，并提倡对两个集合的指标给予同等重要性，来解决像素基代理中存在的显著不对称性，以扭转这些代理中令人担忧的上升趋势。我们通过指出缺乏使用世界模型目标训练的具有时间结构的潜在空间来阐述这一显著不对称性的原因。最后，为了解决这一问题，我们提出了一种名为Joint Embedding DIffusion（JEDI）的新型潜在扩散世界模型，该模型端到端地使用自一致性的目标进行训练。JEDI在人类优化任务上的表现优于当前最佳模型，同时在Atari100k基准上保持竞争力，并且运行速度是最新像素基扩散基线的三倍快，内存消耗减少43%。总体而言，我们的工作重新定义了在Atari100k上达到人类水平性能的真正含义。', 'title_zh': 'JEDI: 潜在的端到端扩散机制缓解基于模型 reinforcement learning 中的Agent-_human 性能差异'}
{'arxiv_id': 'arXiv:2505.19687', 'title': 'DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech', 'authors': 'Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2505.19687', 'abstract': 'Cross-speaker emotion transfer in speech synthesis relies on extracting speaker-independent emotion embeddings for accurate emotion modeling without retaining speaker traits. However, existing timbre compression methods fail to fully separate speaker and emotion characteristics, causing speaker leakage and degraded synthesis quality. To address this, we propose DiEmo-TTS, a self-supervised distillation method to minimize emotional information loss and preserve speaker identity. We introduce cluster-driven sampling and information perturbation to preserve emotion while removing irrelevant factors. To facilitate this process, we propose an emotion clustering and matching approach using emotional attribute prediction and speaker embeddings, enabling generalization to unlabeled data. Additionally, we designed a dual conditioning transformer to integrate style features better. Experimental results confirm the effectiveness of our method in learning speaker-irrelevant emotion embeddings.', 'abstract_zh': '跨说话人口头情感转移在语音合成中的实现依赖于提取无说话人差异的情感嵌入以准确建模情感而不保留说话人特征。然而，现有的音色压缩方法未能完全分离说话人和情感特征，导致说话人痕迹泄露和合成质量下降。为解决这一问题，我们提出了一种自监督蒸馏方法DiEmo-TTS，以最小化情感信息丢失并保留说话人身份。我们引入了基于聚类的采样和信息扰动以保留情感并去除无关因素。为了促进这一过程，我们提出了一种使用情感属性预测和说话人嵌入的口头情感聚类和匹配方法，使模型能够泛化到未标记数据。此外，我们设计了一种双条件变压器以更好地整合风格特征。实验结果证实了我们方法在学习无说话人差异的情感嵌入方面的有效性。', 'title_zh': 'DiEmo-TTS：通过自我监督精炼实现跨演讲者情绪转移的解耦情绪表示'}
{'arxiv_id': 'arXiv:2505.19679', 'title': "KIT's Low-resource Speech Translation Systems for IWSLT2025: System Enhancement with Synthetic Data and Model Regularization", 'authors': 'Zhaolin Li, Yining Liu, Danni Liu, Tuan Nam Nguyen, Enes Yavuz Ugan, Tu Anh Dinh, Carlos Mullov, Alexander Waibel, Jan Niehues', 'link': 'https://arxiv.org/abs/2505.19679', 'abstract': "This paper presents KIT's submissions to the IWSLT 2025 low-resource track. We develop both cascaded systems, consisting of Automatic Speech Recognition (ASR) and Machine Translation (MT) models, and end-to-end (E2E) Speech Translation (ST) systems for three language pairs: Bemba, North Levantine Arabic, and Tunisian Arabic into English. Building upon pre-trained models, we fine-tune our systems with different strategies to utilize resources efficiently. This study further explores system enhancement with synthetic data and model regularization. Specifically, we investigate MT-augmented ST by generating translations from ASR data using MT models. For North Levantine, which lacks parallel ST training data, a system trained solely on synthetic data slightly surpasses the cascaded system trained on real data. We also explore augmentation using text-to-speech models by generating synthetic speech from MT data, demonstrating the benefits of synthetic data in improving both ASR and ST performance for Bemba. Additionally, we apply intra-distillation to enhance model performance. Our experiments show that this approach consistently improves results across ASR, MT, and ST tasks, as well as across different pre-trained models. Finally, we apply Minimum Bayes Risk decoding to combine the cascaded and end-to-end systems, achieving an improvement of approximately 1.5 BLEU points.", 'abstract_zh': 'KIT提交给IWSLT 2025低资源赛道的论文：三种语言对的级联系统和端到端语音翻译系统', 'title_zh': 'KIT的低资源语音翻译系统for IWSLT2025：基于合成数据和模型正则化的系统增强'}
{'arxiv_id': 'arXiv:2505.19671', 'title': "Automated evaluation of children's speech fluency for low-resource languages", 'authors': 'Bowen Zhang, Nur Afiqah Abdul Latiff, Justin Kan, Rong Tong, Donny Soh, Xiaoxiao Miao, Ian McLoughlin', 'link': 'https://arxiv.org/abs/2505.19671', 'abstract': "Assessment of children's speaking fluency in education is well researched for majority languages, but remains highly challenging for low resource languages. This paper proposes a system to automatically assess fluency by combining a fine-tuned multilingual ASR model, an objective metrics extraction stage, and a generative pre-trained transformer (GPT) network. The objective metrics include phonetic and word error rates, speech rate, and speech-pause duration ratio. These are interpreted by a GPT-based classifier guided by a small set of human-evaluated ground truth examples, to score fluency. We evaluate the proposed system on a dataset of children's speech in two low-resource languages, Tamil and Malay and compare the classification performance against Random Forest and XGBoost, as well as using ChatGPT-4o to predict fluency directly from speech input. Results demonstrate that the proposed approach achieves significantly higher accuracy than multimodal GPT or other methods.", 'abstract_zh': '低资源语言儿童口语流畅性自动评估系统的提出', 'title_zh': '低资源语言儿童言语流畅性自动评估'}
{'arxiv_id': 'arXiv:2505.19663', 'title': 'A Comprehensive Real-World Assessment of Audio Watermarking Algorithms: Will They Survive Neural Codecs?', 'authors': 'Yigitcan Özer, Woosung Choi, Joan Serrà, Mayank Kumar Singh, Wei-Hsiang Liao, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2505.19663', 'abstract': 'We present a framework to foster the evaluation of deep learning-based audio watermarking algorithms, establishing a standardized benchmark and allowing systematic comparisons. To simulate real-world usage, we introduce a comprehensive audio attack pipeline, featuring various distortions such as compression, background noise, and reverberation, and propose a diverse test dataset, including speech, environmental sounds, and music recordings. By assessing the performance of four existing watermarking algorithms on our framework, two main insights stand out: (i) neural compression techniques pose the most significant challenge, even when algorithms are trained with such compressions; and (ii) training with audio attacks generally improves robustness, although it is insufficient in some cases. Furthermore, we find that specific distortions, such as polarity inversion, time stretching, or reverb, seriously affect certain algorithms. Our contributions strengthen the robustness and perceptual assessment of audio watermarking algorithms across a wide range of applications, while ensuring a fair and consistent evaluation approach. The evaluation framework, including the attack pipeline, is accessible at this http URL.', 'abstract_zh': '我们提出了一种框架，以促进基于深度学习的音频水印算法的评估，建立了标准化基准并允许系统性的比较。为了模拟实际使用情况，我们引入了一个全面的音频攻击管道，其中包括压缩、背景噪声和混响等多种失真，并提出了一个多样化的测试数据集，其中包括语音、环境声和音乐录音。通过对我们的框架评估四个现有水印算法的表现，我们得到了两项主要见解：(i) 神经压缩技术即使在算法被训练使用这些压缩时也构成了最大的挑战；(ii) 使用音频攻击进行训练一般可以提高鲁棒性，但有些情况下并不足够。此外，我们发现特定的失真，如极性反转、时间拉伸或混响，会对某些算法产生严重影响。我们的贡献在广泛的应用中增强了音频水印算法的鲁棒性和感知评估，同时确保了一种公平和一致的评估方法。评估框架，包括攻击管道，可通过以下网址访问。', 'title_zh': '全面的实际世界评估：音频水印算法能生存下来对抗神经编解码器吗？'}
{'arxiv_id': 'arXiv:2505.19648', 'title': 'Model Enumeration of Two-Variable Logic with Quadratic Delay Complexity', 'authors': 'Qiaolan Meng, Juhua Pu, Hongting Niu, Yuyi Wang, Yuanhong Wang, Ondřej Kuželka', 'link': 'https://arxiv.org/abs/2505.19648', 'abstract': 'We study the model enumeration problem of the function-free, finite domain fragment of first-order logic with two variables ($FO^2$). Specifically, given an $FO^2$ sentence $\\Gamma$ and a positive integer $n$, how can one enumerate all the models of $\\Gamma$ over a domain of size $n$? In this paper, we devise a novel algorithm to address this problem. The delay complexity, the time required between producing two consecutive models, of our algorithm is quadratic in the given domain size $n$ (up to logarithmic factors) when the sentence is fixed. This complexity is almost optimal since the interpretation of binary predicates in any model requires at least $\\Omega(n^2)$ bits to represent.', 'abstract_zh': '我们研究函数自由、有限域的一阶逻辑双变量片段（$FO^2$）的模型枚举问题。具体来说，给定一个$FO^2$句子$\\Gamma$和一个正整数$n$，如何在大小为$n$的领域中枚举$\\Gamma$的所有模型？在本文中，我们设计了一种新的算法来解决这个问题。当句子固定时，我们的算法在产生两个连续模型之间的时间延迟复杂度为给定领域大小$n$的平方（直到对数因子为止）。这一复杂度几乎是最佳的，因为任何模型中二元谓词的解释至少需要$\\Omega(n^2)$位来表示。', 'title_zh': '带有二次延迟复杂性的二变量逻辑模型枚举'}
{'arxiv_id': 'arXiv:2505.19644', 'title': 'STOPA: A Database of Systematic VariaTion Of DeePfake Audio for Open-Set Source Tracing and Attribution', 'authors': 'Anton Firc, Manasi Chibber, Jagabandhu Mishra, Vishwanath Pratap Singh, Tomi Kinnunen, Kamil Malinka', 'link': 'https://arxiv.org/abs/2505.19644', 'abstract': 'A key research area in deepfake speech detection is source tracing - determining the origin of synthesised utterances. The approaches may involve identifying the acoustic model (AM), vocoder model (VM), or other generation-specific parameters. However, progress is limited by the lack of a dedicated, systematically curated dataset. To address this, we introduce STOPA, a systematically varied and metadata-rich dataset for deepfake speech source tracing, covering 8 AMs, 6 VMs, and diverse parameter settings across 700k samples from 13 distinct synthesisers. Unlike existing datasets, which often feature limited variation or sparse metadata, STOPA provides a systematically controlled framework covering a broader range of generative factors, such as the choice of the vocoder model, acoustic model, or pretrained weights, ensuring higher attribution reliability. This control improves attribution accuracy, aiding forensic analysis, deepfake detection, and generative model transparency.', 'abstract_zh': '一种深度伪造语音检测的关键研究领域是源追溯——确定合成语音的来源。该方法可能涉及识别声学模型（AM）、 vocoder模型（VM）或其他生成特定参数。然而，由于缺乏专门的系统化数据集，进展受限。为此，我们介绍了STOPA，一个系统化变异和元数据丰富的数据集，用于深度伪造语音源追溯，覆盖8种声学模型、6种vocoder模型和从13种不同合成器中提取的70万样本中多种参数设置。与现有的数据集相比，STOPA提供了更广泛生成因素的系统化控制框架，确保更高的归属可靠性。这一控制改进了归属准确性，有助于法医分析、深度伪造检测和生成模型透明度。', 'title_zh': 'STOPA：一种用于开放集声源追踪和归属的系统变异性深度伪造音频数据库'}
{'arxiv_id': 'arXiv:2505.19625', 'title': 'Search-Based Software Engineering in the Landscape of AI Foundation Models', 'authors': 'Hassan Sartaj, Shaukat Ali', 'link': 'https://arxiv.org/abs/2505.19625', 'abstract': 'Search-based software engineering (SBSE), at the intersection of artificial intelligence (AI) and software engineering, has been an active area of research for about 25 years. It has been applied to solve numerous problems across the entire software engineering lifecycle and has demonstrated its versatility in multiple domains. With the recent advancements in AI, particularly the emergence of foundation models (FMs), the evolution of SBSE alongside FMs remains undetermined. In this window of opportunity, we propose a research roadmap that articulates the current landscape of SBSE in relation to foundation models (FMs), highlights open challenges, and outlines potential research directions for advancing SBSE through its interplay with FMs. This roadmap aims to establish a forward-thinking and innovative perspective for the future of SBSE in the era of FMs.', 'abstract_zh': '基于搜索的软件工程（SBSE）：面向基础模型（FMs）时代的研究路线图', 'title_zh': '基于搜索的软件工程在AI基础模型的视角下'}
{'arxiv_id': 'arXiv:2505.19607', 'title': 'Energy-based Preference Optimization for Test-time Adaptation', 'authors': 'Yewon Han, Seoyun Yang, Taesup Kim', 'link': 'https://arxiv.org/abs/2505.19607', 'abstract': 'Test-Time Adaptation (TTA) enhances model robustness by enabling adaptation to target distributions that differ from training distributions, improving real-world generalizability. Existing TTA approaches focus on adjusting the conditional distribution; however these methods often depend on uncertain predictions in the absence of label information, leading to unreliable performance. Energy-based frameworks suggest a promising alternative to address distribution shifts without relying on uncertain predictions, instead computing the marginal distribution of target data. However, they involve the critical challenge of requiring extensive SGLD sampling, which is impractical for test-time scenarios requiring immediate adaptation. In this work, we propose Energy-based Preference Optimization for Test-time Adaptation (EPOTTA), which is based on a sampling free strategy. We first parameterize the target model using a pretrained model and residual energy function, enabling marginal likelihood maximization of target data without sampling. Building on the observation that the parameterization is mathematically equivalent to DPO objective, we then directly adapt the model to a target distribution without explicitly training the residual. Our experiments verify that EPOTTA is well-calibrated and performant while achieving computational efficiency.', 'abstract_zh': '基于能量的测试时偏好优化方法（EPOTTA）', 'title_zh': '基于能量的偏好优化以实现测试时适应'}
{'arxiv_id': 'arXiv:2505.19588', 'title': 'LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval', 'authors': 'Yanzhen Shen, Sihao Chen, Xueqiang Xu, Yunyi Zhang, Chaitanya Malaviya, Dan Roth', 'link': 'https://arxiv.org/abs/2505.19588', 'abstract': 'While significant progress has been made with dual- and bi-encoder dense retrievers, they often struggle on queries with logical connectives, a use case that is often overlooked yet important in downstream applications. Current dense retrievers struggle with such queries, such that the retrieved results do not respect the logical constraints implied in the queries. To address this challenge, we introduce LogiCoL, a logically-informed contrastive learning objective for dense retrievers. LogiCoL builds upon in-batch supervised contrastive learning, and learns dense retrievers to respect the subset and mutually-exclusive set relation between query results via two sets of soft constraints expressed via t-norm in the learning objective. We evaluate the effectiveness of LogiCoL on the task of entity retrieval, where the model is expected to retrieve a set of entities in Wikipedia that satisfy the implicit logical constraints in the query. We show that models trained with LogiCoL yield improvement both in terms of retrieval performance and logical consistency in the results. We provide detailed analysis and insights to uncover why queries with logical connectives are challenging for dense retrievers and why LogiCoL is most effective.', 'abstract_zh': '尽管双编码器和双语文本检索器取得了显著进展，但在处理包含逻辑连接词的查询时，它们常常表现不佳，这是一个在下游应用中经常被忽视但重要的使用场景。当前的密集检索器在处理这类查询时存在问题，导致检索结果不尊重查询中隐含的逻辑约束。为应对这一挑战，我们提出LogiCoL，这是一种逻辑信息驱动的对比学习目标，以解决密集检索器的检索问题。LogiCoL 基于内部批监督对比学习，并通过学习目标中的 t-规范表达的两组软约束，使密集检索器遵守查询结果的子集和互斥集关系。我们评估了 LogiCoL 在实体检索任务中的有效性，其中模型需要检索满足查询中隐含逻辑约束的维基百科实体集合。我们展示了使用 LogiCoL 训练的模型在检索性能和结果逻辑一致性方面的改进，并提供了详细分析和见解，以揭示包含逻辑连接词的查询对密集检索器构成的挑战以及为什么 LogiCoL 最为有效。', 'title_zh': 'LogiCoL：逻辑信息引导的对比学习在集合密集检索中的应用'}
{'arxiv_id': 'arXiv:2505.19547', 'title': 'STRAP: Spatio-Temporal Pattern Retrieval for Out-of-Distribution Generalization', 'authors': 'Haoyu Zhang, Wentao Zhang, Hao Miao, Xinke Jiang, Yuchen Fang, Yifan Zhang', 'link': 'https://arxiv.org/abs/2505.19547', 'abstract': 'Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerful tool for modeling dynamic graph-structured data across diverse domains. However, they often fail to generalize in Spatio-Temporal Out-of-Distribution (STOOD) scenarios, where both temporal dynamics and spatial structures evolve beyond the training distribution. To address this problem, we propose an innovative Spatio-Temporal Retrieval-Augmented Pattern Learning framework,STRAP, which enhances model generalization by integrating retrieval-augmented learning into the STGNN continue learning pipeline. The core of STRAP is a compact and expressive pattern library that stores representative spatio-temporal patterns enriched with historical, structural, and semantic information, which is obtained and optimized during the training phase. During inference, STRAP retrieves relevant patterns from this library based on similarity to the current input and injects them into the model via a plug-and-play prompting mechanism. This not only strengthens spatio-temporal representations but also mitigates catastrophic forgetting. Moreover, STRAP introduces a knowledge-balancing objective to harmonize new information with retrieved knowledge. Extensive experiments across multiple real-world streaming graph datasets show that STRAP consistently outperforms state-of-the-art STGNN baselines on STOOD tasks, demonstrating its robustness, adaptability, and strong generalization capability without task-specific fine-tuning.', 'abstract_zh': '时空图神经网络（STGNNs）已成为建模跨多种领域动态图结构数据的强大工具。然而，它们往往在时空异分布（STOOD）场景下无法泛化，即时间动态和空间结构在训练分布之外发生变化。为解决这一问题，我们提出了一种创新的时空检索增强模式学习框架STRAP，通过将检索增强学习集成到STGNN继续学习管道中来增强模型泛化能力。STRAP的核心是一个紧凑且表达力强的模式库，该库存储了富含历史、结构和语义信息的代表性时空模式，并在训练阶段获取和优化。在推理阶段，STRAP根据当前输入与库中模式的相似性检索相关模式，并通过即插即用提示机制将它们注入模型中。这不仅强化了时空表示，还减轻了灾难性遗忘。此外，STRAP引入了一个知识平衡目标，以协调新信息与检索知识。在多个真实世界的流图数据集上的广泛实验表明，STRAP在STOOD任务上始终优于最先进的STGNN基线，证明了其鲁棒性、适应性和强大的泛化能力，无需针对特定任务进行细调。', 'title_zh': 'STRAP: 空间-时间模式检索以实现异常分布泛化'}
{'arxiv_id': 'arXiv:2505.19538', 'title': 'DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients', 'authors': 'Yuxing Lu, Gecheng Fu, Wei Wu, Xukai Zhao, Sin Yee Goi, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2505.19538', 'abstract': 'Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.', 'abstract_zh': '现有的医疗RAG系统主要借鉴医学知识库的知识，忽视了来自类似患者案例的经验知识——人类临床推理中的关键组成部分。为填补这一空白，我们提出DoctorRAG，这是一种通过整合显式临床知识和隐式案例为基础的经验，模拟医生推理过程的RAG框架。DoctorRAG通过为查询和知识源分配概念标签，并采用从相关知识和患者中结合检索的混合机制，提升检索精度。此外，我们集成了一个使用多代理文本梯度的Med-TextGrad模块，以确保最终输出符合检索到的知识和患者查询。在多语言、多任务数据集上的综合实验表明，DoctorRAG显著优于强大的基线RAG模型，并且从迭代优化中获得改进。我们的方法生成了更准确、相关且全面的响应，朝着更接近医生的医疗推理系统迈出了一步。', 'title_zh': 'DoctorRAG：融合知识与患者类比的医疗RAG模型通过文本梯度'}
{'arxiv_id': 'arXiv:2505.19534', 'title': 'Training-Free Multi-Step Audio Source Separation', 'authors': 'Yongyi Zang, Jingyi Li, Qiuqiang Kong', 'link': 'https://arxiv.org/abs/2505.19534', 'abstract': 'Audio source separation aims to separate a mixture into target sources. Previous audio source separation systems usually conduct one-step inference, which does not fully explore the separation ability of models. In this work, we reveal that pretrained one-step audio source separation models can be leveraged for multi-step separation without additional training. We propose a simple yet effective inference method that iteratively applies separation by optimally blending the input mixture with the previous step\'s separation result. At each step, we determine the optimal blending ratio by maximizing a metric. We prove that our method always yield improvement over one-step inference, provide error bounds based on model smoothness and metric robustness, and provide theoretical analysis connecting our method to denoising along linear interpolation paths between noise and clean distributions, a property we link to denoising diffusion bridge models. Our approach effectively delivers improved separation performance as a "free lunch" from existing models. Our empirical results demonstrate that our multi-step separation approach consistently outperforms one-step inference across both speech enhancement and music source separation tasks, and can achieve scaling performance similar to training a larger model, using more data, or in some cases employing a multi-step training objective. These improvements appear not only on the optimization metric during multi-step inference, but also extend to nearly all non-optimized metrics (with one exception). We also discuss limitations of our approach and directions for future research.', 'abstract_zh': '基于多步推理的预训练音频源分离方法', 'title_zh': '无监督多步音频源分离'}
{'arxiv_id': 'arXiv:2505.19531', 'title': 'Minimalist Softmax Attention Provably Learns Constrained Boolean Functions', 'authors': 'Jerry Yao-Chieh Hu, Xiwen Zhang, Maojiang Su, Zhao Song, Han Liu', 'link': 'https://arxiv.org/abs/2505.19531', 'abstract': 'We study the computational limits of learning $k$-bit Boolean functions (specifically, $\\mathrm{AND}$, $\\mathrm{OR}$, and their noisy variants), using a minimalist single-head softmax-attention mechanism, where $k=\\Theta(d)$ relevant bits are selected from $d$ inputs. We show that these simple $\\mathrm{AND}$ and $\\mathrm{OR}$ functions are unsolvable with a single-head softmax-attention mechanism alone. However, with teacher forcing, the same minimalist attention is capable of solving them. These findings offer two key insights: Architecturally, solving these Boolean tasks requires only minimalist attention, without deep Transformer blocks or FFNs. Methodologically, one gradient descent update with supervision suffices and replaces the multi-step Chain-of-Thought (CoT) reasoning scheme of [Kim and Suzuki, ICLR 2025] for solving Boolean problems. Together, the bounds expose a fundamental gap between what this minimal architecture achieves under ideal supervision and what is provably impossible under standard training.', 'abstract_zh': '我们研究了使用 minimalist 单头 softmax-attention 机制学习 $k$-bit 逻辑函数（具体为 AND、OR 及其噪声变体）的计算极限，其中 $k=\\Theta(d)$ 相关位从 $d$ 个输入中选择。我们展示，仅使用单头 softmax-attention 机制无法解决这些简单的 AND 和 OR 函数。但在使用 teacher forcing 的情况下，相同的 minimalist 机制能够解决它们。这些发现提供了两个关键洞见：从架构角度看，解决这些布尔任务只需要 minimalist 机制，而无需深层的 Transformer 块或 FFN。从方法角度看，一次带有监督的梯度下降更新足以替代 [Kim 和 Suzuki, ICLR 2025] 中解决布尔问题的多步骤 Chain-of-Thought (CoT) 推理方案。总体而言，这些边界揭示了在理想监督下此最小化架构实现的能力与在标准训练下证明不可能实现的能力之间的根本差距。', 'title_zh': '最小主义softmax注意力高效学习受限布尔函数'}
{'arxiv_id': 'arXiv:2505.19528', 'title': 'AmpleHate: Amplifying the Attention for Versatile Implicit Hate Detection', 'authors': 'Yejin Lee, Joonghyuk Hahn, Hyeseon Ahn, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2505.19528', 'abstract': 'Implicit hate speech detection is challenging due to its subtlety and reliance on contextual interpretation rather than explicit offensive words. Current approaches rely on contrastive learning, which are shown to be effective on distinguishing hate and non-hate sentences. Humans, however, detect implicit hate speech by first identifying specific targets within the text and subsequently interpreting how these target relate to their surrounding context. Motivated by this reasoning process, we propose AmpleHate, a novel approach designed to mirror human inference for implicit hate detection. AmpleHate identifies explicit target using a pretrained Named Entity Recognition model and capture implicit target information via [CLS] tokens. It computes attention-based relationships between explicit, implicit targets and sentence context and then, directly injects these relational vectors into the final sentence representation. This amplifies the critical signals of target-context relations for determining implicit hate. Experiments demonstrate that AmpleHate achieves state-of-the-art performance, outperforming contrastive learning baselines by an average of 82.14% and achieve faster convergence. Qualitative analyses further reveal that attention patterns produced by AmpleHate closely align with human judgement, underscoring its interpretability and robustness.', 'abstract_zh': '隐含仇恨言论检测由于其微妙性以及依赖于上下文理解而非明确的冒犯词汇而具有挑战性。当前的方法依赖于对比学习，已被证明在区分仇恨言论和非仇恨言论方面是有效的。然而，人类通过首先识别文本中的具体目标，然后解释这些目标与其周围上下文的关系来检测隐含的仇恨言论。受此推理过程的启发，我们提出了一种名为AmpleHate的新型方法，旨在模拟人类对隐含仇恨的推理过程。AmpleHate使用预训练的命名实体识别模型识别显式目标，并通过[CLS]标记捕获隐含目标信息。它计算显式目标、隐含目标与句子上下文之间的注意关系，然后直接将这些关系向量注入最终的句子表示。这放大了目标-上下文关系的关键信号，以确定隐含仇恨。实验表明，AmpleHate取得了最先进的性能，平均优于对比学习基线82.14%，并实现更快的收敛。进一步的定性分析表明，AmpleHate生成的注意模式与人类判断高度一致，突显了其可解释性和鲁棒性。', 'title_zh': 'AmpleHate: 加强对多样化的隐含仇恨检测的关注'}
{'arxiv_id': 'arXiv:2505.19488', 'title': 'Understanding Transformer from the Perspective of Associative Memory', 'authors': 'Shu Zhong, Mingyu Xu, Tenglong Ao, Guang Shi', 'link': 'https://arxiv.org/abs/2505.19488', 'abstract': 'In this paper, we share our reflections and insights on understanding Transformer architectures through the lens of associative memory--a classic psychological concept inspired by human cognition. We start with the basics of associative memory (think simple linear attention) and then dive into two dimensions:\nMemory Capacity: How much can a Transformer really remember, and how well? We introduce retrieval SNR to measure this and use a kernel perspective to mathematically reveal why Softmax Attention is so effective. We also show how FFNs can be seen as a type of associative memory, leading to insights on their design and potential improvements.\nMemory Update: How do these memories learn and evolve? We present a unified framework for understanding how different Transformer variants (like DeltaNet and Softmax Attention) update their "knowledge base". This leads us to tackle two provocative questions: 1. Are Transformers fundamentally limited in what they can express, and can we break these barriers? 2. If a Transformer had infinite context, would it become infinitely intelligent?\nWe want to demystify Transformer architecture, offering a clearer understanding of existing designs. This exploration aims to provide fresh insights and spark new avenues for Transformer innovation.', 'abstract_zh': '通过关联记忆视角理解Transformer架构：反思与洞察', 'title_zh': '从关联记忆的角度理解变压器模型'}
{'arxiv_id': 'arXiv:2505.19469', 'title': 'Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with Self-Adaptive Memory', 'authors': 'Mingzhuo Li, Guang Li, Jiafeng Mao, Takahiro Ogawa, Miki Haseyama', 'link': 'https://arxiv.org/abs/2505.19469', 'abstract': 'Dataset distillation enables the training of deep neural networks with comparable performance in significantly reduced time by compressing large datasets into small and representative ones. Although the introduction of generative models has made great achievements in this field, the distributions of their distilled datasets are not diverse enough to represent the original ones, leading to a decrease in downstream validation accuracy. In this paper, we present a diversity-driven generative dataset distillation method based on a diffusion model to solve this problem. We introduce self-adaptive memory to align the distribution between distilled and real datasets, assessing the representativeness. The degree of alignment leads the diffusion model to generate more diverse datasets during the distillation process. Extensive experiments show that our method outperforms existing state-of-the-art methods in most situations, proving its ability to tackle dataset distillation tasks.', 'abstract_zh': '基于扩散模型的多样性驱动生成式数据集蒸馏方法', 'title_zh': '基于自适应记忆和扩散模型的多元化驱动生成数据集精简'}
{'arxiv_id': 'arXiv:2505.19465', 'title': 'Residual Cross-Attention Transformer-Based Multi-User CSI Feedback with Deep Joint Source-Channel Coding', 'authors': 'Hengwei Zhang, Minghui Wu, Li Qiao, Ling Liu, Ziqi Han, Zhen Gao', 'link': 'https://arxiv.org/abs/2505.19465', 'abstract': 'This letter proposes a deep-learning (DL)-based multi-user channel state information (CSI) feedback framework for massive multiple-input multiple-output systems, where the deep joint source-channel coding (DJSCC) is utilized to improve the CSI reconstruction accuracy. Specifically, we design a multi-user joint CSI feedback framework, whereby the CSI correlation of nearby users is utilized to reduce the feedback overhead. Under the framework, we propose a new residual cross-attention transformer architecture, which is deployed at the base station to further improve the CSI feedback performance. Moreover, to tackle the "cliff-effect" of conventional bit-level CSI feedback approaches, we integrated DJSCC into the multi-user CSI feedback, together with utilizing a two-stage training scheme to adapt to varying uplink noise levels. Experimental results demonstrate the superiority of our methods in CSI feedback performance, with low network complexity and better scalability.', 'abstract_zh': '基于深度学习的多用户信道状态信息反馈框架及其联合源信道编码研究', 'title_zh': '基于残差跨注意力变换器的多用户CSI反馈深度联合源-信道编码'}
{'arxiv_id': 'arXiv:2505.19459', 'title': 'Your Classifier Can Do More: Towards Bridging the Gaps in Classification, Robustness, and Generation', 'authors': 'Kaichao Jiang, He Wang, Xiaoshuai Hao, Xiulong Yang, Ajian Liu, Qi Chu, Yunfeng Diao', 'link': 'https://arxiv.org/abs/2505.19459', 'abstract': "Joint Energy-based Models (JEMs), a class of hybrid generative-discriminative models, are well known for their ability to achieve both high classification accuracy and generative capability within a single model. However, their robustness still lags significantly behind the classifiers based adversarial training (AT). Conversely, while AT is currently the most effective approach to improving the classifier's robustness, it typically sacrifices accuracy on clean data and lacks generative capability. The triple trade-off between classification accuracy, generative capability and robustness, raises a natural question: Can a single model simultaneously achieve high classification accuracy, adversarial robustness, and generative performance? -- a goal that has been rarely explored. To address this question, we systematically analyze the energy distribution differences of clean, adversarial, and generated samples across various JEM variants and adversarially trained models. We observe that AT tends to reduce the energy gap between clean and adversarial samples, while JEMs reduce the gap between clean and synthetic ones. This observation suggests a key insight: if the energy distributions of all three data types can be aligned, we might unify the strengths of AT and JEMs, resolving their inherent trade-offs. Building on this idea, we propose Energy-based Joint Distribution Adversarial Training (EB-JDAT), to jointly model the clean data distribution, the adversarial distribution, and the classifier by maximizing their joint probability. EB-JDAT is a general and flexible optimization method, compatible with various JEM variants. Extensive experimental results demonstrate that EB-JDAT not only maintains near original accuracy and generative capability of JEMs, but also significantly enhances robustness, even surpassing state-of-the-art ATs.", 'abstract_zh': '基于能量的联合分布对抗训练（EB-JDAT）：同时实现高分类准确率、对抗鲁棒性和生成性能', 'title_zh': '你的分类器大有可为：致力于填补分类、 robustness 和生成之间的差距'}
{'arxiv_id': 'arXiv:2505.19441', 'title': 'Fairness Practices in Industry: A Case Study in Machine Learning Teams Building Recommender Systems', 'authors': 'Jing Nathan Yan, Junxiong Wang, Jeffrey M. Rzeszotarski, Allison Koenecke', 'link': 'https://arxiv.org/abs/2505.19441', 'abstract': "The rapid proliferation of recommender systems necessitates robust fairness practices to address inherent biases. Assessing fairness, though, is challenging due to constantly evolving metrics and best practices. This paper analyzes how industry practitioners perceive and incorporate these changing fairness standards in their workflows. Through semi-structured interviews with 11 practitioners from technical teams across a range of large technology companies, we investigate industry implementations of fairness in recommendation system products. We focus on current debiasing practices, applied metrics, collaborative strategies, and integrating academic research into practice. Findings show a preference for multi-dimensional debiasing over traditional demographic methods, and a reliance on intuitive rather than academic metrics. This study also highlights the difficulties in balancing fairness with both the practitioner's individual (bottom-up) roles and organizational (top-down) workplace constraints, including the interplay with legal and compliance experts. Finally, we offer actionable recommendations for the recommender system community and algorithmic fairness practitioners, underlining the need to refine fairness practices continually.", 'abstract_zh': '推荐系统迅速 proliferation necessitates robust fairness practices to address inherent biases.评估公平性虽具挑战性，但不断演进的指标和最佳实践要求我们必须适应。本文分析了行业从业者如何感知和在工作中融入这些不断变化的公平标准。通过半结构化访谈11名来自不同大型科技公司技术团队的从业者，我们探究了行业在推荐系统产品中实施公平性的实践。研究重点包括当前的去偏见实践、应用的指标、协作策略以及将学术研究融入实践的方法。研究发现，从业者更偏好多维度的去偏见方法而非传统的 démographic 方法，并依赖直观而非学术指标。此外，研究还突出了在个人（自下而上）职责和组织（自上而下）工作场所约束之间平衡公平性所面临的困难，包括与法律和合规专家的互动。最后，我们为推荐系统社区和算法公平性从业者提供了可行建议，强调了持续改进公平性实践的必要性。', 'title_zh': 'industria中的公平性实践：机器学习团队构建推荐系统案例研究'}
{'arxiv_id': 'arXiv:2505.19404', 'title': 'Exploring the Possibility of TypiClust for Low-Budget Federated Active Learning', 'authors': 'Yuta Ono, Hiroshi Nakamura, Hideki Takase', 'link': 'https://arxiv.org/abs/2505.19404', 'abstract': 'Federated Active Learning (FAL) seeks to reduce the burden of annotation under the realistic constraints of federated learning by leveraging Active Learning (AL). As FAL settings make it more expensive to obtain ground truth labels, FAL strategies that work well in low-budget regimes, where the amount of annotation is very limited, are needed. In this work, we investigate the effectiveness of TypiClust, a successful low-budget AL strategy, in low-budget FAL settings. Our empirical results show that TypiClust works well even in low-budget FAL settings contrasted with relatively low performances of other methods, although these settings present additional challenges, such as data heterogeneity, compared to AL. In addition, we show that FAL settings cause distribution shifts in terms of typicality, but TypiClust is not very vulnerable to the shifts. We also analyze the sensitivity of TypiClust to feature extraction methods, and it suggests a way to perform FAL even in limited data situations.', 'abstract_zh': '联邦主动学习（FAL）在联邦学习的现实约束下，通过利用主动学习（AL）来减少标注负担。在低预算环境下，FAL策略需要能够在标注数据量非常有限的情况下取得良好效果。在本文中，我们研究了TypiClust这一成功的低预算AL策略在低预算FAL设置中的有效性。实验证明，即使在与其它方法相比表现较低的情况下，TypiClust也能在低预算FAL设置中很好地工作，尽管这些设置相比传统的AL增加了数据异质性等额外挑战。此外，我们展示了FAL设置会导致典型性分布偏移，但TypiClust对此类偏移不特别敏感。我们还分析了TypiClust对特征提取方法的敏感性，这为在数据有限的情况下进行FAL提供了一种方法。', 'title_zh': '探究 TypiClust 在低预算联邦主动学习中的可能性'}
{'arxiv_id': 'arXiv:2505.19392', 'title': 'Simple and Effective Baselines for Code Summarisation Evaluation', 'authors': 'Jade Robinson, Jonathan K. Kummerfeld', 'link': 'https://arxiv.org/abs/2505.19392', 'abstract': 'Code documentation is useful, but writing it is time-consuming. Different techniques for generating code summaries have emerged, but comparing them is difficult because human evaluation is expensive and automatic metrics are unreliable. In this paper, we introduce a simple new baseline in which we ask an LLM to give an overall score to a summary. Unlike n-gram and embedding-based baselines, our approach is able to consider the code when giving a score. This allows us to also make a variant that does not consider the reference summary at all, which could be used for other tasks, e.g., to evaluate the quality of documentation in code bases. We find that our method is as good or better than prior metrics, though we recommend using it in conjunction with embedding-based methods to avoid the risk of LLM-specific bias.', 'abstract_zh': '代码文档总结生成技术评估中的一个简单新基线', 'title_zh': '简单有效的基准方法用于代码总结评估'}
{'arxiv_id': 'arXiv:2505.19356', 'title': 'Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval', 'authors': 'Kidist Amde Mekonnen, Yosef Worku Alemneh, Maarten de Rijke', 'link': 'https://arxiv.org/abs/2505.19356', 'abstract': 'Neural retrieval methods using transformer-based pre-trained language models have advanced multilingual and cross-lingual retrieval. However, their effectiveness for low-resource, morphologically rich languages such as Amharic remains underexplored due to data scarcity and suboptimal tokenization. We address this gap by introducing Amharic-specific dense retrieval models based on pre-trained Amharic BERT and RoBERTa backbones. Our proposed RoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative improvement in MRR@10 and a 9.86% gain in Recall@10 over the strongest multilingual baseline, Arctic Embed 2.0 (568M parameters). More compact variants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while being over 13x smaller. Additionally, we train a ColBERT-based late interaction retrieval model that achieves the highest MRR@10 score (0.843) among all evaluated models. We benchmark our proposed models against both sparse and dense retrieval baselines to systematically assess retrieval effectiveness in Amharic. Our analysis highlights key challenges in low-resource settings and underscores the importance of language-specific adaptation. To foster future research in low-resource IR, we publicly release our dataset, codebase, and trained models at this https URL.', 'abstract_zh': '基于变压器预训练语言模型的神经检索方法在多语言和跨语言检索中取得了进展，但对于如阿姆哈拉语这样的低资源、形态丰富的语言，其有效性仍待探索，原因在于数据稀缺和分词不理想。我们通过引入基于预训练阿姆哈拉语 BERT 和 RoBERTa 的阿姆哈拉语特定密集检索模型来填补这一空白。我们提出的 RoBERTa-Base-Amharic-Embed 模型（110M 参数）在 MRR@10 上实现了 17.6% 的相对改进，并在 Recall@10 上超过最强的多语言基线 Arctic Embed 2.0（568M 参数）9.86%。更紧凑的变体，如 RoBERTa-Medium-Amharic-Embed（42M），保持了竞争力，同时大小超过 13 倍。此外，我们训练了一个基于 ColBERT 的晚期交互检索模型，实现了所有评估模型中最高的 MRR@10 分数（0.843）。我们将我们提出的模型与稀疏和密集检索基线模型进行基准测试，以系统评估阿姆哈拉语中的检索效果。我们的分析强调了低资源设置中的关键挑战，并突显了语言特定适应的重要性。为了促进未来在低资源信息检索方面的研究，我们在该网址 <https://> 公开发布了我们的数据集、代码库和训练模型。', 'title_zh': '优化的提顿嵌入模型及阿姆哈拉语段落检索基准'}
{'arxiv_id': 'arXiv:2505.19342', 'title': 'Communication-Efficient Multi-Device Inference Acceleration for Transformer Models', 'authors': 'Xiao Liu, Lijun Zhang, Deepak Ganesan, Hui Guan', 'link': 'https://arxiv.org/abs/2505.19342', 'abstract': 'Transformer models power many AI applications but suffer from high inference latency, limiting their use in real-time settings. Multi-device inference can reduce latency by parallelizing computation. Yet, existing methods require high inter-device bandwidth, making them impractical for bandwidth-constrained environments. We propose ASTRA, a communication-efficient framework that accelerates Transformer inference through a novel integration of sequence parallelism and a Mixed-Precision Attention mechanism designed to minimize inter-device communication. ASTRA compresses non-local token embeddings via vector quantization and preserves task accuracy through two optimizations, Noise-Augmented Quantization and Distributed Class Tokens. Experiments on ViT and GPT2 across vision and NLP tasks show that ASTRA achieves up to 2.64X speedups over single-device inference and up to 15.25X speedups over state-of-the-art multi-device inferences, while operating under bandwidths as low as 10 Mbps. ASTRA is open-sourced at this https URL.', 'abstract_zh': 'Transformer模型驱动许多AI应用，但 inference 纯量延迟较高，限制了其在实时场景中的应用。多设备推理可以通过并行计算来减少延迟，但现有方法需要较高的设备间带宽，不适合带宽受限的环境。我们提出ASTRA，一种通过新颖地结合序列并行性和设计用于最小化设备间通信的混合精度注意力机制来加速Transformer推理的通信高效框架。ASTRA通过向量量化压缩非局部 token 插值，并通过噪声增强量化和分布式类 token 两种优化保持任务准确性。在跨视觉和自然语言处理任务的ViT和GPT2上的实验表明，ASTRA在单设备推理上的加速比高达2.64倍，在最新多设备推理上的加速比高达15.25倍，同时在低至10 Mbps的带宽下运行。ASTRA已开源。', 'title_zh': '设备间通信高效的Transformer模型多设备推理加速'}
{'arxiv_id': 'arXiv:2505.19315', 'title': 'Demand Selection for VRP with Emission Quota', 'authors': 'Farid Najar, Dominique Barth, Yann Strozecki', 'link': 'https://arxiv.org/abs/2505.19315', 'abstract': 'Combinatorial optimization (CO) problems are traditionally addressed using Operations Research (OR) methods, including metaheuristics. In this study, we introduce a demand selection problem for the Vehicle Routing Problem (VRP) with an emission quota, referred to as QVRP. The objective is to minimize the number of omitted deliveries while respecting the pollution quota. We focus on the demand selection part, called Maximum Feasible Vehicle Assignment (MFVA), while the construction of a routing for the VRP instance is solved using classical OR methods. We propose several methods for selecting the packages to omit, both from machine learning (ML) and OR. Our results show that, in this static problem setting, classical OR-based methods consistently outperform ML-based approaches.', 'abstract_zh': '车辆 routing 问题（VRP）中的排放配额需求选择问题：一种组合优化方法', 'title_zh': '带有排放配额的车辆路线问题中的需求选择'}
{'arxiv_id': 'arXiv:2505.19314', 'title': 'SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline', 'authors': 'Helin Wang, Jiarui Hai, Dongchao Yang, Chen Chen, Kai Li, Junyi Peng, Thomas Thebaud, Laureano Moro Velazquez, Jesus Villalba, Najim Dehak', 'link': 'https://arxiv.org/abs/2505.19314', 'abstract': "Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high perceptual quality, these models often introduce unwanted artifacts, reduce naturalness, and are sensitive to discrepancies between training and testing environments. On the other hand, generative models for TSE lag in perceptual quality and intelligibility. To address these challenges, we present SoloSpeech, a novel cascaded generative pipeline that integrates compression, extraction, reconstruction, and correction processes. SoloSpeech features a speaker-embedding-free target extractor that utilizes conditional information from the cue audio's latent space, aligning it with the mixture audio's latent space to prevent mismatches. Evaluated on the widely-used Libri2Mix dataset, SoloSpeech achieves the new state-of-the-art intelligibility and quality in target speech extraction and speech separation tasks while demonstrating exceptional generalization on out-of-domain data and real-world scenarios.", 'abstract_zh': '单声道语音提取 (SoloSpeech) 目标旨在通过利用典型作为辅助音频提供的说话人特定线索，从多说话人的混合音频中隔离目标说话人的声音。尽管近期目标语音提取 (TSE) 的进展主要依赖于提供高感知质量的判别模型，但这些模型常常引入不必要的艺术制品，降低自然度，并且对训练和测试环境之间的差异敏感。另一方面，TSE 的生成模型在感知质量和可懂度方面滞后。为应对这些挑战，我们提出了一种新颖的级联生成流水线 SoloSpeech，该流水线集成了压缩、提取、重建和校正过程。SoloSpeech 特点是无说话人嵌入的目标提取器，利用来自辅助音频潜空间的条件信息，将其与混合音频的潜空间对齐，以防止不匹配。在广泛使用的 Libri2Mix 数据集上评估，SoloSpeech 在目标语音提取和语音分离任务中达到了新的最好可懂度和质量，同时在域外数据和现实场景中展示了出色的一般化能力。', 'title_zh': 'SoloSpeech：通过级联生成管道提高目标语音提取的可懂度和质量'}
{'arxiv_id': 'arXiv:2505.19310', 'title': 'Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking', 'authors': 'Robin D. Pesl, Jerin G. Mathew, Massimo Mecella, Marco Aiello', 'link': 'https://arxiv.org/abs/2505.19310', 'abstract': 'Integrating multiple (sub-)systems is essential to create advanced Information Systems. Difficulties mainly arise when integrating dynamic environments, e.g., the integration at design time of not yet existing services. This has been traditionally addressed using a registry that provides the API documentation of the endpoints. Large Language Models have shown to be capable of automatically creating system integrations (e.g., as service composition) based on this documentation but require concise input due to input oken limitations, especially regarding comprehensive API descriptions. Currently, it is unknown how best to preprocess these API descriptions. In the present work, we (i) analyze the usage of Retrieval Augmented Generation for endpoint discovery and the chunking, i.e., preprocessing, of state-of-practice OpenAPIs to reduce the input oken length while preserving the most relevant information. To further reduce the input token length for the composition prompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that only receives a summary of the most relevant endpoints nd retrieves specification details on demand. We evaluate RAG for endpoint discovery using (iii) a proposed novel service discovery benchmark SOCBench-D representing a general setting across numerous domains and the real-world RestBench enchmark, first, for the different chunking possibilities and parameters measuring the endpoint retrieval accuracy. Then, we assess the Discovery Agent using the same test data set. The prototype shows how to successfully employ RAG for endpoint discovery to reduce the token count. Our experiments show that endpoint-based approaches outperform naive chunking methods for preprocessing. Relying on an agent significantly improves precision while being prone to decrease recall, disclosing the need for further reasoning capabilities.', 'abstract_zh': '集成多个(子)系统是创建高级信息系统的关键。当在设计时间集成尚不存在的服务等动态环境时，会遇到主要困难。这通常通过注册表解决，提供端点的API文档。大型语言模型已显示出根据这些文档自动生成系统集成（例如，作为服务组合）的能力，但由于输入令牌限制，尤其是关于全面的API描述，需要简洁的输入。目前尚不清楚如何最佳地预处理这些API描述。在本项工作中，我们（i）分析检索增强生成在端点发现和分块，即预处理实践中常用的OpenAPI以减少输入令牌长度同时保留最关键信息中的应用。为进一步减少组合提示的输入令牌长度并改进端点检索，我们提出（ii）一个仅接收最相关端点概要并在需要时检索规格详细信息的发现代理。我们使用（iii）一个提出的新型服务发现基准SOCBench-D和实际中的RestBench基准评估RAG在端点发现中的应用，覆盖多个领域，首先针对不同的分块可能性和参数衡量端点检索准确性，然后使用相同的测试数据集评估发现代理。原型展示了如何成功利用RAG减少令牌数量进行端点发现。实验显示基于端点的方法优于简单的分块方法进行预处理。依赖代理在显著提高精度的同时可能导致召回率下降，表明需要进一步的推理能力。', 'title_zh': '基于检索增强生成的服务发现：分块策略与基准测试'}
{'arxiv_id': 'arXiv:2505.19301', 'title': 'A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control', 'authors': 'Ken Huang, Vineeth Sai Narajala, John Yeoh, Ramesh Raskar, Youssef Harkati, Jerry Huang, Idan Habler, Chris Hughes', 'link': 'https://arxiv.org/abs/2505.19301', 'abstract': 'Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.\nThis paper posits the imperative for a novel Agentic AI IAM framework: We deconstruct the limitations of existing protocols when applied to MAS, illustrating with concrete examples why their coarse-grained controls, single-entity focus, and lack of context-awareness falter. We then propose a comprehensive framework built upon rich, verifiable Agent Identities (IDs), leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), that encapsulate an agents capabilities, provenance, behavioral scope, and security posture.\nOur framework includes an Agent Naming Service (ANS) for secure and capability-aware discovery, dynamic fine-grained access control mechanisms, and critically, a unified global session management and policy enforcement layer for real-time control and consistent revocation across heterogeneous agent communication protocols. We also explore how Zero-Knowledge Proofs (ZKPs) enable privacy-preserving attribute disclosure and verifiable policy compliance.\nWe outline the architecture, operational lifecycle, innovative contributions, and security considerations of this new IAM paradigm, aiming to establish the foundational trust, accountability, and security necessary for the burgeoning field of agentic AI and the complex ecosystems they will inhabit.', 'abstract_zh': '传统的身份与访问管理（IAM）系统主要针对人类用户或静态机器身份，通过OAuth、OpenID Connect（OIDC）和SAML等协议设计，对于多代理系统（MAS）中大规模运行的动态、相互依赖且 Often Ephemeral 的智能代理缺乏根本性的支持。多代理系统是多个相互作用的智能代理共同工作的计算系统。\n\n本文提出了一种新的代理智能代理IAM框架的迫切需求：我们拆解现有协议在MAS中应用时的局限性，通过具体例子说明其粗粒度控制、单一实体关注点和缺乏上下文感知能力的不足。随后，我们提出了一种基于丰富可验证智能代理身份（IDs）、利用分散标识符（DIDs）和可验证凭据（VCs）的全面框架，该框架涵盖了代理的能力、来源、行为范围和安全状况。\n\n该框架包括安全且能力感知的智能代理命名服务（ANS）、动态细粒度访问控制机制，并且最关键的是，提供了一个统一的全局会话管理与策略执行层，以实现实时控制和跨异构代理通信协议的一致撤销。我们还探讨了零知识证明（ZKPs）如何实现隐私保护的属性披露和可验证策略合规性。\n\n本文概述了该新IAM范式的架构、操作生命周期、创新贡献和安全考量，旨在为蓬勃发展的代理智能AI领域及其将要栖息的复杂生态系统建立基础的信任、问责和安全。', 'title_zh': '基于代理人工智能的新型零信任身份框架：去中心化身份认证与细粒度访问控制'}
{'arxiv_id': 'arXiv:2505.19299', 'title': 'A Necessary Step toward Faithfulness: Measuring and Improving Consistency in Free-Text Explanations', 'authors': 'Lingjun Zhao, Hal Daumé III', 'link': 'https://arxiv.org/abs/2505.19299', 'abstract': 'Faithful free-text explanations are important to ensure transparency in high-stakes AI decision-making contexts, but they are challenging to generate by language models and assess by humans. In this paper, we present a measure for Prediction-EXplanation (PEX) consistency, by extending the concept of weight of evidence. This measure quantifies how much a free-text explanation supports or opposes a prediction, serving as an important aspect of explanation faithfulness. Our analysis reveals that more than 62% explanations generated by large language models lack this consistency. We show that applying direct preference optimization improves the consistency of generated explanations across three model families, with improvement ranging from 43.1% to 292.3%. Furthermore, we demonstrate that optimizing this consistency measure can improve explanation faithfulness by up to 9.7%.', 'abstract_zh': '忠实的自由文本解释对于确保高风险AI决策情境下的透明性至关重要，但它们的生成和评估对语言模型和人类来说都是具有挑战性的。本文提出了一种预测-解释（PEX）一致性的度量方法，通过扩展证据权重的概念。该度量方法量化了自由文本解释对预测的支持或反对程度，作为解释忠实性的重要方面。我们的分析表明，超过62%的由大型语言模型生成的解释缺乏这种一致性。我们显示，直接偏好优化可以提高三种模型家族生成解释的一致性，改进幅度从43.1%到292.3%不等。此外，我们证明优化此一致性度量可以提高解释忠实性高达9.7%。', 'title_zh': '走向忠诚性必要一步：测量和提升自由文本解释的一致性'}
{'arxiv_id': 'arXiv:2505.19263', 'title': 'Cellular Traffic Prediction via Byzantine-robust Asynchronous Federated Learning', 'authors': 'Hui Ma, Kai Yang, Yang Jiao', 'link': 'https://arxiv.org/abs/2505.19263', 'abstract': 'Network traffic prediction plays a crucial role in intelligent network operation. Traditional prediction methods often rely on centralized training, necessitating the transfer of vast amounts of traffic data to a central server. This approach can lead to latency and privacy concerns. To address these issues, federated learning integrated with differential privacy has emerged as a solution to improve data privacy and model robustness in distributed settings. Nonetheless, existing federated learning protocols are vulnerable to Byzantine attacks, which may significantly compromise model robustness. Developing a robust and privacy-preserving prediction model in the presence of Byzantine clients remains a significant challenge. To this end, we propose an asynchronous differential federated learning framework based on distributionally robust optimization. The proposed framework utilizes multiple clients to train the prediction model collaboratively with local differential privacy. In addition, regularization techniques have been employed to further improve the Byzantine robustness of the models. We have conducted extensive experiments on three real-world datasets, and the results elucidate that our proposed distributed algorithm can achieve superior performance over existing methods.', 'abstract_zh': '基于分布鲁棒优化的异步差分联邦学习预测模型', 'title_zh': 'Byzantine- robust 异步联邦学习在细胞交通预测中的应用'}
{'arxiv_id': 'arXiv:2505.19252', 'title': 'Learning-Augmented Online Bipartite Fractional Matching', 'authors': 'Davin Choo, Billy Jin, Yongho Shin', 'link': 'https://arxiv.org/abs/2505.19252', 'abstract': 'Online bipartite matching is a fundamental problem in online optimization, extensively studied both in its integral and fractional forms due to its theoretical significance and practical applications, such as online advertising and resource allocation. Motivated by recent progress in learning-augmented algorithms, we study online bipartite fractional matching when the algorithm is given advice in the form of a suggested matching in each iteration. We develop algorithms for both the vertex-weighted and unweighted variants that provably dominate the naive "coin flip" strategy of randomly choosing between the advice-following and advice-free algorithms. Moreover, our algorithm for the vertex-weighted setting extends to the AdWords problem under the small bids assumption, yielding a significant improvement over the seminal work of Mahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our positive results, we establish a hardness bound on the robustness-consistency tradeoff that is attainable by any algorithm. We empirically validate our algorithms through experiments on synthetic and real-world data.', 'abstract_zh': '在线 bipartite 匹配是在线优化中的一个基础问题，由于其理论意义和实际应用价值，如在线广告和资源分配，该问题在整数形式和分数形式下均得到了广泛研究。受学习增强算法近期进展的启发，我们研究了在线 bipartite 分数匹配问题，其中算法在每一轮获得建议匹配作为建议。我们开发了适用于顶点加权和无权重两种变体的算法，并可证明这些算法在随机选择遵循建议和不遵循建议的算法之间占优。此外，顶点加权设置下的算法可以推广到小出价情形下的 AdWords 问题，显著改进了 Mahdian、Nazerzadeh 和 Saberi 的开创性工作（EC 2007, TALG 2012）。作为正面结果的补充，我们确立了任何一个算法都能够达到的鲁棒性-一致性折中上的下界。我们通过合成数据和实际数据的实验验证了所提出的算法。', 'title_zh': '学习增强的在线二分部分匹配'}
{'arxiv_id': 'arXiv:2505.19245', 'title': 'To CoT or To Loop? A Formal Comparison Between Chain-of-Thought and Looped Transformers', 'authors': 'Kevin Xu, Issei Sato', 'link': 'https://arxiv.org/abs/2505.19245', 'abstract': 'Chain-of-Thought (CoT) and Looped Transformers have been shown to empirically improve performance on reasoning tasks and to theoretically enhance expressivity by recursively increasing the number of computational steps. However, their comparative capabilities are still not well understood. In this paper, we provide a formal analysis of their respective strengths and limitations. We show that Looped Transformers can efficiently simulate parallel computations for deterministic tasks, which we formalize as evaluation over directed acyclic graphs. In contrast, CoT with stochastic decoding excels at approximate inference for compositional structures, namely self-reducible problems. These separations suggest the tasks for which depth-driven recursion is more suitable, thereby offering practical cues for choosing between reasoning paradigms.', 'abstract_zh': 'Chain-of-Thought和环状变压器在推理任务中的比较分析及其表达能力的研究', 'title_zh': '是采用Chain-of-Thought还是Looped Transformers？一种形式化比较'}
{'arxiv_id': 'arXiv:2505.19205', 'title': 'OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization', 'authors': 'Meher Bhaskar Madiraju, Meher Sai Preetam Madiraju', 'link': 'https://arxiv.org/abs/2505.19205', 'abstract': "Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.", 'abstract_zh': '基于多智能体的超参数优化：OptiMindTune', 'title_zh': 'OptiMindTune：一种智能超参数优化的多代理框架'}
{'arxiv_id': 'arXiv:2505.19194', 'title': 'Curvature Dynamic Black-box Attack: revisiting adversarial robustness via dynamic curvature estimation', 'authors': 'Peiran Sun', 'link': 'https://arxiv.org/abs/2505.19194', 'abstract': 'Adversarial attack reveals the vulnerability of deep learning models. For about a decade, countless attack and defense methods have been proposed, leading to robustified classifiers and better understanding of models. Among these methods, curvature-based approaches have attracted attention because it is assumed that high curvature may give rise to rough decision boundary. However, the most commonly used \\textit{curvature} is the curvature of loss function, scores or other parameters from within the model as opposed to decision boundary curvature, since the former can be relatively easily formed using second order derivative. In this paper, we propose a new query-efficient method, dynamic curvature estimation(DCE), to estimate the decision boundary curvature in a black-box setting. Our approach is based on CGBA, a black-box adversarial attack. By performing DCE on a wide range of classifiers, we discovered, statistically, a connection between decision boundary curvature and adversarial robustness. We also propose a new attack method, curvature dynamic black-box attack(CDBA) with improved performance using the dynamically estimated curvature.', 'abstract_zh': '基于曲率的对抗攻击揭示深度学习模型的脆弱性：一种在黑盒设置下查询高效决策边界曲率的动态估计方法及其应用', 'title_zh': '动态曲率黑盒攻击：通过动态曲率估计重新审视 adversarial 稳健性'}
{'arxiv_id': 'arXiv:2505.19164', 'title': 'BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations', 'authors': 'Ashirbad Mishra, Jinyu Zhao, Soumik Dey, Hansi Wu, Binbin Li, Kamesh Madduri', 'link': 'https://arxiv.org/abs/2505.19164', 'abstract': "In the domain of sponsored search advertising, the focus of Keyphrase recommendation has largely been on exact match types, which pose issues such as high management expenses, limited targeting scope, and evolving search query patterns. Alternatives like Broad match types can alleviate certain drawbacks of exact matches but present challenges like poor targeting accuracy and minimal supervisory signals owing to limited advertiser usage. This research defines the criteria for an ideal broad match, emphasizing on both efficiency and effectiveness, ensuring that a significant portion of matched queries are relevant. We propose BroadGen, an innovative framework that recommends efficient and effective broad match keyphrases by utilizing historical search query data. Additionally, we demonstrate that BroadGen, through token correspondence modeling, maintains better query stability over time. BroadGen's capabilities allow it to serve daily, millions of sellers at eBay with over 2.3 billion items.", 'abstract_zh': '在赞助搜索广告领域，关键词推荐主要集中在精确匹配类型上，这类方式存在管理成本高、目标范围有限以及搜索查询模式不断演变的问题。相比之下，宽匹配类型可以缓解某些精确匹配的弊端，但同时伴随着目标精度低和监督信号少等挑战，由于广告商使用较少。本研究定义了理想的宽匹配标准，强调效率和效果，确保大部分匹配查询的相关性。我们提出了一种名为BroadGen的新框架，通过利用历史搜索查询数据来推荐高效且有效的宽匹配关键词。此外，我们证明BroadGen通过标记对应关系建模，能够更好地保持查询稳定性。BroadGen的能力使其能够服务于eBay每天数百万卖家，管理超过23亿件商品。', 'title_zh': 'BroadGen: 生成有效且高效的广告商广匹配关键词推荐框架'}
{'arxiv_id': 'arXiv:2505.19119', 'title': 'CloneShield: A Framework for Universal Perturbation Against Zero-Shot Voice Cloning', 'authors': 'Renyuan Li, Zhibo Liang, Haichuan Zhang, Tianyu Shi, Zhiyuan Cheng, Jia Shi, Carl Yang, Mingjie Tang', 'link': 'https://arxiv.org/abs/2505.19119', 'abstract': "Recent breakthroughs in text-to-speech (TTS) voice cloning have raised serious privacy concerns, allowing highly accurate vocal identity replication from just a few seconds of reference audio, while retaining the speaker's vocal authenticity. In this paper, we introduce CloneShield, a universal time-domain adversarial perturbation framework specifically designed to defend against zero-shot voice cloning. Our method provides protection that is robust across speakers and utterances, without requiring any prior knowledge of the synthesized text. We formulate perturbation generation as a multi-objective optimization problem, and propose Multi-Gradient Descent Algorithm (MGDA) to ensure the robust protection across diverse utterances. To preserve natural auditory perception for users, we decompose the adversarial perturbation via Mel-spectrogram representations and fine-tune it for each sample. This design ensures imperceptibility while maintaining strong degradation effects on zero-shot cloned outputs. Experiments on three state-of-the-art zero-shot TTS systems, five benchmark datasets and evaluations from 60 human listeners demonstrate that our method preserves near-original audio quality in protected inputs (PESQ = 3.90, SRS = 0.93) while substantially degrading both speaker similarity and speech quality in cloned samples (PESQ = 1.07, SRS = 0.08).", 'abstract_zh': 'Recent突破在文本到语音(TTS)语音克隆方面的进展引发了严重的隐私担忧，允许仅从几秒钟的参考音频中复制高度准确的声音身份，同时保留说话人的声音真实性。在本文中，我们介绍了CloneShield，这是一种通用的时间域对抗性扰动框架，专门设计用于防御零样本语音克隆。我们的方法提供了一种在不同说话人和语句上都具有鲁棒性的保护措施，而无需任何关于合成文本的先验知识。我们将扰动生成形式化为一个多目标优化问题，并提出多梯度下降算法(MGDA)以确保对多样化语句的鲁棒保护。为了保持用户的自然听觉感知，我们通过梅尔频谱图表示分解对抗性扰动，并对每个样本进行微调。这种设计在保持不可感知性的同时，对零样本克隆输出具有强烈降级效果。在三个最先进的零样本TTS系统、五个基准数据集以及60名人听者评估上的实验显示，Our方法在保护输入中近似保持了原始音频质量(PESQ=3.90, SRS=0.93)，同时显著降低了克隆样本中说话人相似性和语音质量(PESQ=1.07, SRS=0.08)。', 'title_zh': '克隆防护：一种通用对抗零样本语音克隆的框架'}
{'arxiv_id': 'arXiv:2505.19110', 'title': 'An Interpretable Representation Learning Approach for Diffusion Tensor Imaging', 'authors': 'Vishwa Mohan Singh, Alberto Gaston Villagran Asiares, Luisa Sophie Schuhmacher, Kate Rendall, Simon Weißbrod, David Rügamer, Inga Körte', 'link': 'https://arxiv.org/abs/2505.19110', 'abstract': 'Diffusion Tensor Imaging (DTI) tractography offers detailed insights into the structural connectivity of the brain, but presents challenges in effective representation and interpretation in deep learning models. In this work, we propose a novel 2D representation of DTI tractography that encodes tract-level fractional anisotropy (FA) values into a 9x9 grayscale image. This representation is processed through a Beta-Total Correlation Variational Autoencoder with a Spatial Broadcast Decoder to learn a disentangled and interpretable latent embedding. We evaluate the quality of this embedding using supervised and unsupervised representation learning strategies, including auxiliary classification, triplet loss, and SimCLR-based contrastive learning. Compared to the 1D Group deep neural network (DNN) baselines, our approach improves the F1 score in a downstream sex classification task by 15.74% and shows a better disentanglement than the 3D representation.', 'abstract_zh': '扩散张量成像（DTI）纤维追踪为大脑结构连接提供了详细的见解，但在深度学习模型中的有效表示和解释方面面临挑战。本文提出了一种新颖的2D表示方法，将纤维级别中的各向异性分数（FA）值编码到9x9灰度图像中。该表示方法通过Beta-总相关变分自编码器和空间广播解码器处理，以学习一个分离和可解释的潜在嵌入。我们使用监督和无监督表示学习策略评估该嵌入的质量，包括辅助分类、 triplet损失和基于SimCLR的对比学习方法。与1D组深度神经网络（DNN） baselines相比，我们的方法在下游性别分类任务中的F1分数提高了15.74%，并且在分离性方面优于3D表示。', 'title_zh': '可解释的表示学习方法用于扩散张量成像'}
{'arxiv_id': 'arXiv:2505.19096', 'title': 'Enable Lightweight and Precision-Scalable Posit/IEEE-754 Arithmetic in RISC-V Cores for Transprecision Computing', 'authors': 'Qiong Li, Chao Fang, Longwei Huang, Jun Lin, Zhongfeng Wang', 'link': 'https://arxiv.org/abs/2505.19096', 'abstract': 'While posit format offers superior dynamic range and accuracy for transprecision computing, its adoption in RISC-V processors is hindered by the lack of a unified solution for lightweight, precision-scalable, and IEEE-754 arithmetic compatible hardware implementation. To address these challenges, we enhance RISC-V processors by 1) integrating dedicated posit codecs into the original FPU for lightweight implementation, 2) incorporating multi/mixed-precision support with dynamic exponent size for precision-scalability, and 3) reusing and customizing ISA extensions for IEEE-754 compatible posit operations. Our comprehensive evaluation spans the modified FPU, RISC-V core, and SoC levels. It demonstrates that our implementation achieves 47.9% LUTs and 57.4% FFs reduction compared to state-of-the-art posit-enabled RISC-V processors, while achieving up to 2.54$\\times$ throughput improvement in various GEMM kernels.', 'abstract_zh': '尽管Posit格式在Transprecision计算中提供了卓越的动态范围和准确性，但由于缺乏统一的轻量级、可扩展精度且与IEEE-754算术兼容的硬件实现解决方案，其在RISC-V处理器中的应用受到限制。为解决这些挑战，我们通过1）在原有FPU中集成专用Posit编解码器实现轻量级实施，2）引入多精度/混合精度支持并具有动态指数大小以实现可扩展精度，以及3）重用和定制ISA扩展以实现与IEEE-754兼容的Posit操作，来增强RISC-V处理器。我们全面评估涵盖了修改后的FPU、RISC-V核心和SoC级别。结果显示，我们的实现相比于最先进的Posit启用的RISC-V处理器在LUT和FF上分别减少了47.9%和57.4%，同时在各种GEMM内核中实现了最多2.54倍的吞吐量提升。', 'title_zh': '在RISC-V内核中实现适用于跨精度计算的轻量级和精度可扩展的Posit/IEEE-754算术'}
{'arxiv_id': 'arXiv:2505.19040', 'title': 'Smart Waste Management System for Makkah City using Artificial Intelligence and Internet of Things', 'authors': 'Rawabi S. Al Qurashi, Maram M. Almnjomi, Teef L. Alghamdi, Amjad H. Almalki, Shahad S. Alharthi, Shahad M. althobuti, Alanoud S. Alharthi, Maha A. Thafar', 'link': 'https://arxiv.org/abs/2505.19040', 'abstract': "Waste management is a critical global issue with significant environmental and public health implications. It has become more destructive during large-scale events such as the annual pilgrimage to Makkah, Saudi Arabia, one of the world's largest religious gatherings. This event's popularity has attracted millions worldwide, leading to significant and un-predictable accumulation of waste. Such a tremendous number of visitors leads to in-creased waste management issues at the Grand Mosque and other holy sites, highlighting the need for an effective solution other than traditional methods based on rigid collection schedules.\nTo address this challenge, this research proposed an innovative solution that is context-specific and tailored to the unique requirements of pilgrimage season: a Smart Waste Management System, called TUHR, that utilizes the Internet of Things and Artificial Intelligence. This system encompasses ultrasonic sensors that monitor waste levels in each container at the performance sites. Once the container reaches full capacity, the sensor communicates with the microcontroller, which alerts the relevant authorities. Moreover, our system can detect harmful substances such as gas from the gas detector sensor. Such a proactive and dynamic approach promises to mitigate the environmental and health risks associated with waste accumulation and enhance the cleanliness of these sites. It also delivers economic benefits by reducing unnecessary gasoline consumption and optimizing waste management resources. Importantly, this research aligns with the principles of smart cities and exemplifies the innovative, sustainable, and health-conscious approach that Saudi Arabia is implementing as part of its Vision 2030 initiative.", 'abstract_zh': '废物管理是全球一个关键问题，具有重要的环境和公共卫生意义。在像沙特麦加年度朝圣这样的大型活动中，废物管理问题变得更加严重。这种活动的普及吸引了数以百万计的参与者，导致在克尔白大清真寺和其他圣殿区域产生了大量难以预测的废物堆积，凸显了除基于固定收集时间表的传统方法外，需要有效解决方案的必要性。\n\n为了解决这一挑战，本研究提出了一种针对朝圣季节的独特要求的创新解决方案：一个名为TUHR的智能废物管理系统，该系统利用物联网和人工智能技术。该系统包括超声波传感器，用于监控每个容器在活动地点中的废物量。一旦容器达到满容量，传感器将与微控制器通信，提醒相关当局。此外，我们的系统还可以通过气体检测传感器检测有害物质。这种主动和动态的方法有望减轻废物堆积带来的环境和健康风险，提高这些地区的清洁度。同时，该系统还能通过减少不必要的汽油消耗和优化废物管理资源带来经济效益。重要的是，这项研究与智能城市的原理相一致，并体现了沙特阿拉伯实施2030愿景计划所采用的创新、可持续和健康导向的方法。', 'title_zh': '基于人工智能和物联网的麦加市智能垃圾分类系统'}
{'arxiv_id': 'arXiv:2505.19038', 'title': 'Turb-L1: Achieving Long-term Turbulence Tracing By Tackling Spectral Bias', 'authors': 'Hao Wu, Yuan Gao, Ruiqi Shu, Zean Han, Fan Xu, Zhihong Zhu, Qingsong Wen, Xian Wu, Kun Wang, Xiaomeng Huang', 'link': 'https://arxiv.org/abs/2505.19038', 'abstract': 'Accurately predicting the long-term evolution of turbulence is crucial for advancing scientific understanding and optimizing engineering applications. However, existing deep learning methods face significant bottlenecks in long-term autoregressive prediction, which exhibit excessive smoothing and fail to accurately track complex fluid dynamics. Our extensive experimental and spectral analysis of prevailing methods provides an interpretable explanation for this shortcoming, identifying Spectral Bias as the core obstacle. Concretely, spectral bias is the inherent tendency of models to favor low-frequency, smooth features while overlooking critical high-frequency details during training, thus reducing fidelity and causing physical distortions in long-term predictions. Building on this insight, we propose Turb-L1, an innovative turbulence prediction method, which utilizes a Hierarchical Dynamics Synthesis mechanism within a multi-grid architecture to explicitly overcome spectral bias. It accurately captures cross-scale interactions and preserves the fidelity of high-frequency dynamics, enabling reliable long-term tracking of turbulence evolution. Extensive experiments on the 2D turbulence benchmark show that Turb-L1 demonstrates excellent performance: (I) In long-term predictions, it reduces Mean Squared Error (MSE) by $80.3\\%$ and increases Structural Similarity (SSIM) by over $9\\times$ compared to the SOTA baseline, significantly improving prediction fidelity. (II) It effectively overcomes spectral bias, accurately reproducing the full enstrophy spectrum and maintaining physical realism in high-wavenumber regions, thus avoiding the spectral distortions or spurious energy accumulation seen in other methods.', 'abstract_zh': '准确预测涡流的长期演化对于推进科学理解与优化工程应用至关重要。然而，现有的深度学习方法在长期自回归预测中面临显著障碍，表现为过度平滑化并无法准确追踪复杂的流体动力学。我们对现有方法的广泛实验和频谱分析提供了可解释的解释，识别出频谱偏差是核心障碍。具体而言，频谱偏差是在训练过程中模型偏好低频、平滑特征的同时忽视关键高频细节的固有倾向，从而降低保真度并导致长期预测中的物理失真。基于这一洞察，我们提出了Turb-L1，一种创新的湍流预测方法，利用多尺度架构中的层次动力学合成机制显式克服频谱偏差。它准确捕捉跨尺度交互并保真高频动态，从而实现可靠的长期内涡流演化的追踪。在2D湍流基准测试中的广泛实验显示，Turb-L1表现出色：（I）在长期预测中，其均方误差（MSE）降低了80.3%，结构相似度（SSIM）提高了9倍以上，显著提高预测保真度；（II）有效克服频谱偏差，准确重现完整的旋度频谱，保持高频波数区域的物理逼真性，从而避免了其他方法中出现的频谱失真或虚假能量积累。', 'title_zh': 'Turb-L1: 通过解决频谱偏差实现长期湍流跟踪'}
{'arxiv_id': 'arXiv:2505.19023', 'title': 'A Smart Healthcare System for Monkeypox Skin Lesion Detection and Tracking', 'authors': 'Huda Alghoraibi, Nuha Alqurashi, Sarah Alotaibi, Renad Alkhudaydi, Bdoor Aldajani, Lubna Alqurashi, Jood Batweel, Maha A. Thafar', 'link': 'https://arxiv.org/abs/2505.19023', 'abstract': 'Monkeypox is a viral disease characterized by distinctive skin lesions and has been reported in many countries. The recent global outbreak has emphasized the urgent need for scalable, accessible, and accurate diagnostic solutions to support public health responses.\nIn this study, we developed ITMAINN, an intelligent, AI-driven healthcare system specifically designed to detect Monkeypox from skin lesion images using advanced deep learning techniques. Our system consists of three main components. First, we trained and evaluated several pretrained models using transfer learning on publicly available skin lesion datasets to identify the most effective models. For binary classification (Monkeypox vs. non-Monkeypox), the Vision Transformer, MobileViT, Transformer-in-Transformer, and VGG16 achieved the highest performance, each with an accuracy and F1-score of 97.8%. For multiclass classification, which contains images of patients with Monkeypox and five other classes (chickenpox, measles, hand-foot-mouth disease, cowpox, and healthy), ResNetViT and ViT Hybrid models achieved 92% accuracy, with F1 scores of 92.24% and 92.19%, respectively. The best-performing and most lightweight model, MobileViT, was deployed within the mobile application. The second component is a cross-platform smartphone application that enables users to detect Monkeypox through image analysis, track symptoms, and receive recommendations for nearby healthcare centers based on their location. The third component is a real-time monitoring dashboard designed for health authorities to support them in tracking cases, analyzing symptom trends, guiding public health interventions, and taking proactive measures.\nThis system is fundamental in developing responsive healthcare infrastructure within smart cities. Our solution, ITMAINN, is part of revolutionizing public health management.', 'abstract_zh': 'monkeypox是一种以典型皮肤病变特征为标志的病毒性疾病，已在多个国家和地区报告。近期全球爆发突显了迫切需要 scalable、accessible 和 accurate 的诊断解决方案，以支持公共卫生应对措施。\n\n在本研究中，我们开发了ITMAINN，一种基于先进深度学习技术的智能人工智能驱动的医疗健康系统，专门用于检测来自皮肤病变图像的猴痘。该系统包括三个主要组成部分。首先，我们通过迁移学习在公开的皮肤病变数据集上训练和评估了多个预训练模型，以识别最有效的模型。对于二分类（猴痘 vs. 非猴痘），ViT、MobileViT、Transformer-in-Transformer 和 VGG16 达到了最高的性能，每种模型的准确率和 F1 分数均为 97.8%。对于包含猴痘和其他五种类别（水痘、麻疹、手足口病、牛痘和健康）图像的多分类，ResNetViT 和 ViT Hybrid 模型分别达到了 92% 的准确率和 92.24% 和 92.19% 的 F1 分数。性能最佳且最轻量级的模型 MobileViT 部署在移动应用程序中。第二部分是一个跨平台的智能手机应用程序，允许用户通过图像分析检测猴痘、跟踪症状，并根据其位置接收附近医疗机构的建议。第三部分是一个实时监测仪表盘，为卫生当局提供支持，帮助其跟踪病例、分析症状趋势、指导公共卫生干预措施，并采取主动措施。\n\n该系统对于在智能城市中构建响应性的医疗基础设施至关重要。我们的解决方案 ITMAINN 作为改善公共卫生管理的革命性进展的一部分。', 'title_zh': '一种用于猴痘皮肤病变检测与跟踪的智能 healthcare 系统'}
{'arxiv_id': 'arXiv:2505.19020', 'title': 'HGCL: Hierarchical Graph Contrastive Learning for User-Item Recommendation', 'authors': 'Jiawei Xue, Zhen Yang, Haitao Lin, Ziji Zhang, Luzhu Wang, Yikun Gu, Yao Xu, Xin Li', 'link': 'https://arxiv.org/abs/2505.19020', 'abstract': 'Graph Contrastive Learning (GCL), which fuses graph neural networks with contrastive learning, has evolved as a pivotal tool in user-item recommendations. While promising, existing GCL methods often lack explicit modeling of hierarchical item structures, which represent item similarities across varying resolutions. Such hierarchical item structures are ubiquitous in various items (e.g., online products and local businesses), and reflect their inherent organizational properties that serve as critical signals for enhancing recommendation accuracy. In this paper, we propose Hierarchical Graph Contrastive Learning (HGCL), a novel GCL method that incorporates hierarchical item structures for user-item recommendations. First, HGCL pre-trains a GCL module using cross-layer contrastive learning to obtain user and item representations. Second, HGCL employs a representation compression and clustering method to construct a two-hierarchy user-item bipartite graph. Ultimately, HGCL fine-tunes user and item representations by learning on the hierarchical graph, and then provides recommendations based on user-item interaction scores. Experiments on three widely adopted benchmark datasets ranging from 70K to 382K nodes confirm the superior performance of HGCL over existing baseline models, highlighting the contribution of hierarchical item structures in enhancing GCL methods for recommendation tasks.', 'abstract_zh': '层次图对比学习（HGCL）：一种融合层次项结构的图对比学习方法', 'title_zh': '基于层次图对比学习的用户-物品推荐'}
{'arxiv_id': 'arXiv:2505.19013', 'title': 'Faithful Group Shapley Value', 'authors': 'Kiljae Lee, Ziqi Liu, Weijing Tang, Yuan Zhang', 'link': 'https://arxiv.org/abs/2505.19013', 'abstract': 'Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions of Data Shapley are vulnerable to shell company attacks, where strategic group splitting can unfairly inflate valuations. We propose Faithful Group Shapley Value (FGSV) that uniquely defends against such attacks. Building on original mathematical insights, we develop a provably fast and accurate approximation algorithm for computing FGSV. Empirical experiments demonstrate that our algorithm significantly outperforms state-of-the-art methods in computational efficiency and approximation accuracy, while ensuring faithful group-level valuation.', 'abstract_zh': '数据信仰值（Faithful Group Shapley Value）是数据估值的重要工具，用于量化个体数据点对机器学习模型的贡献。在实践中，当数据提供商以批量形式贡献数据时，群体级数据估值是 desirable 的。然而，我们发现现有的群体级数据舍弗利值扩展容易受到壳公司攻击的影响，其中战略性群体分裂可以不公平地提升估值。我们提出了数据信仰值（FGSV），能够唯一地防御这类攻击。基于原始的数学洞察，我们开发了一种可证明快速且准确的近似算法来计算数据信仰值。实证实验表明，我们的算法在计算效率和近似准确性方面显著优于现有最佳方法，同时保证了忠实的群体级估值。', 'title_zh': '忠实组Shapley值'}
{'arxiv_id': 'arXiv:2505.19002', 'title': 'Semi-pessimistic Reinforcement Learning', 'authors': 'Jin Zhu, Xin Zhou, Jiaang Yao, Gholamali Aminian, Omar Rivasplata, Simon Little, Lexin Li, Chengchun Shi', 'link': 'https://arxiv.org/abs/2505.19002', 'abstract': "Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of labeled reward data. Relying on labeled data alone often leads to a narrow state-action distribution, further amplifying the distributional shift, and resulting in suboptimal policy learning. To address these issues, we first recognize that the volume of unlabeled data is typically substantially larger than that of labeled data. We then propose a semi-pessimistic RL method to effectively leverage abundant unlabeled data. Our approach offers several advantages. It considerably simplifies the learning process, as it seeks a lower bound of the reward function, rather than that of the Q-function or state transition function. It is highly flexible, and can be integrated with a range of model-free and model-based RL algorithms. It enjoys the guaranteed improvement when utilizing vast unlabeled data, but requires much less restrictive conditions. We compare our method with a number of alternative solutions, both analytically and numerically, and demonstrate its clear competitiveness. We further illustrate with an application to adaptive deep brain stimulation for Parkinson's disease.", 'abstract_zh': '离线强化学习（RL）旨在从预先收集的数据中学习最优策略。然而，它面临着分布位移的挑战，所学到的策略可能遇到未包含在离线数据中的 unseen 情景。此外，许多应用面临标记奖励数据匮乏的问题。仅依赖标记数据会导致状态-行动分布狭窄，进一步加剧分布位移，从而导致亚最优策略学习。为解决这些问题，我们首先认识到未标记数据的数量通常远大于标记数据的数量。然后，我们提出了一种半悲观的 RL 方法，以有效地利用丰富的未标记数据。我们的方法具有多项优势。它显着简化了学习过程，因为它寻求奖励函数的下界，而不是 Q 函数或状态转移函数的下界。它非常灵活，可以与多种模型自由和模型导向的 RL 算法集成。它在充分利用大量未标记数据时能够确保改进，但所需的限制条件要少得多。我们从分析和数值比较两种角度将我们的方法与多种替代方案进行了对比，证明了其显著的竞争优势。我们进一步通过应用到帕金森病的自适应脑深部刺激来说明这一点。', 'title_zh': '半 pessimistic强化学习'}
{'arxiv_id': 'arXiv:2505.18976', 'title': 'GraSS: Scalable Influence Function with Sparse Gradient Compression', 'authors': 'Pingbang Hu, Joseph Melkonian, Weijing Tang, Han Zhao, Jiaqi W. Ma', 'link': 'https://arxiv.org/abs/2505.18976', 'abstract': 'Gradient-based data attribution methods, such as influence functions, are critical for understanding the impact of individual training samples without requiring repeated model retraining. However, their scalability is often limited by the high computational and memory costs associated with per-sample gradient computation. In this work, we propose GraSS, a novel gradient compression algorithm and its variants FactGraSS for linear layers specifically, that explicitly leverage the inherent sparsity of per-sample gradients to achieve sub-linear space and time complexity. Extensive experiments demonstrate the effectiveness of our approach, achieving substantial speedups while preserving data influence fidelity. In particular, FactGraSS achieves up to 165% faster throughput on billion-scale models compared to the previous state-of-the-art baselines. Our code is publicly available at this https URL.', 'abstract_zh': '基于梯度的数据归因方法，如影响函数，对于在无需多次重新训练模型的情况下理解单一训练样本的影响至关重要。然而，这些方法的可扩展性常常受到单样本梯度计算的高计算和内存成本的限制。在本文中，我们提出了一种新颖的梯度压缩算法GraSS及其专门用于线性层的变体FactGraSS，这些方法明确利用了单样本梯度的固有稀疏性以实现亚线性的时间和空间复杂度。广泛的实验验证了该方法的有效性，在保持数据影响保真度的同时实现了显著的加速。特别是，FactGraSS在大型模型上的吞吐量比之前最先进的基线快165%。我们的代码已公开，可通过以下链接访问：this https URL。', 'title_zh': 'GraSS: 可扩展的稀疏梯度压缩影响函数'}
{'arxiv_id': 'arXiv:2505.18975', 'title': 'FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization', 'authors': 'Aotao Wang, Haikuo Shao, Shaobo Ma, Zhongfeng Wang', 'link': 'https://arxiv.org/abs/2505.18975', 'abstract': 'State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency than RTX 3090 GPU.', 'abstract_zh': '基于FPGA的硬件算法协同设计加速器FastMamba：解决Mamba2在边缘设备上的部署问题', 'title_zh': 'FastMamba：一种基于FPGA的高效率Mamba加速器及准确量化'}
{'arxiv_id': 'arXiv:2505.18966', 'title': 'Protein Design with Dynamic Protein Vocabulary', 'authors': 'Nuowei Liu, Jiahao Kuang, Yanting Liu, Changzhi Sun, Tao Ji, Yuanbin Wu, Man Lan', 'link': 'https://arxiv.org/abs/2505.18966', 'abstract': 'Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.6%.', 'abstract_zh': '基于文本描述的蛋白质设计：整合片段编码以提高折叠能力', 'title_zh': '动态蛋白质词汇表驱动的蛋白质设计'}
{'arxiv_id': 'arXiv:2505.18934', 'title': 'Chi-Square Wavelet Graph Neural Networks for Heterogeneous Graph Anomaly Detection', 'authors': 'Xiping Li, Xiangyu Dong, Xingyi Zhang, Kun Xie, Yuanhao Feng, Bo Wang, Guilin Li, Wuxiong Zeng, Xiujun Shu, Sibo Wang', 'link': 'https://arxiv.org/abs/2505.18934', 'abstract': 'Graph Anomaly Detection (GAD) in heterogeneous networks presents unique challenges due to node and edge heterogeneity. Existing Graph Neural Network (GNN) methods primarily focus on homogeneous GAD and thus fail to address three key issues: (C1) Capturing abnormal signal and rich semantics across diverse meta-paths; (C2) Retaining high-frequency content in HIN dimension alignment; and (C3) Learning effectively from difficult anomaly samples with class imbalance. To overcome these, we propose ChiGAD, a spectral GNN framework based on a novel Chi-Square filter, inspired by the wavelet effectiveness in diverse domains. Specifically, ChiGAD consists of: (1) Multi-Graph Chi-Square Filter, which captures anomalous information via applying dedicated Chi-Square filters to each meta-path graph; (2) Interactive Meta-Graph Convolution, which aligns features while preserving high-frequency information and incorporates heterogeneous messages by a unified Chi-Square Filter; and (3) Contribution-Informed Cross-Entropy Loss, which prioritizes difficult anomalies to address class imbalance. Extensive experiments on public and industrial datasets show that ChiGAD outperforms state-of-the-art models on multiple metrics. Additionally, its homogeneous variant, ChiGNN, excels on seven GAD datasets, validating the effectiveness of Chi-Square filters. Our code is available at this https URL.', 'abstract_zh': '异构网络中基于图的异常检测（GAD）因其节点和边的异构性而面临独特挑战。现有的图神经网络（GNN）方法主要侧重于同质GAD，因此无法解决以下三个关键问题：(C1) 跨多样元路径捕捉异常信号和丰富的语义；(C2) 在HIN维度对齐中保留高频内容；(C3) 有效地从不平衡类别的异常样本中学习。为克服这些问题，我们提出了一种基于新型卡方滤波器的频谱GNN框架——ChiGAD，该滤波器受到在多种领域中波let效果的启发。具体来说，ChiGAD 包括：(1) 多图卡方滤波器，通过在每个元路径图上应用专门的卡方滤波器来捕获异常信息；(2) 交互式元图卷积，该卷积在保持高频信息的同时进行特征对齐，并通过统一的卡方滤波器整合异构信息；以及(3) 贡献导向的交叉熵损失，该损失优先处理难以分类的异常样本以解决类别不平衡问题。在公共和工业数据集上的广泛实验表明，ChiGAD 在多个指标上优于现有最先进的模型。此外，其同质变体 ChiGNN 在七个 GAD 数据集上表现出色，验证了卡方滤波器的有效性。代码详见：this https URL。', 'title_zh': 'χ²小波图神经网络在异构图异常检测中的应用'}
{'arxiv_id': 'arXiv:2505.18912', 'title': 'Robust Stability Analysis of Positive Lure System with Neural Network Feedback', 'authors': 'Hamidreza Montazeri Hedesh, Moh. Kamalul Wafi, Bahram Shafai, Milad Siami', 'link': 'https://arxiv.org/abs/2505.18912', 'abstract': "This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes parametric uncertainty but also the nonlinear sector bound is unknown. We investigate tools from positive linear systems to effectively solve the problems in complicated and uncertain nonlinear systems. By leveraging the positivity characteristic of the system, we derive an explicit formula for the stability radius of Lur'e systems. Furthermore, we extend our analysis to systems with neural network (NN) feedback loops. Building on this approach, we also propose a refinement method for sector bounds of feedforward neural networks (FFNNs). This study introduces a scalable and efficient approach for robustness analysis of both Lur'e and NN-controlled systems. Finally, the proposed results are supported by illustrative examples.", 'abstract_zh': "本文探讨了在正性约束条件下Lur'e问题的稳健性，借鉴了正Aizerman猜想和马特泽尔矩阵的稳健性性质的结果。具体地，我们考虑一类具有参数不确定性且非线性部分界值未知的Lur'e型控制系统。通过利用系统的正性特征，我们推导出Lur'e系统稳定半径的显式公式。进一步地，我们将分析扩展到具有神经网络反馈回路的系统。在此基础上，我们还提出了前向神经网络馈送环节界值细化的方法。本文引入了一种针对Lur'e和神经网络控制系统的可扩展且高效的稳健性分析方法，并通过实例予以验证。", 'title_zh': '具有神经网络反馈的正Lure系统的鲁棒稳定性分析'}
{'arxiv_id': 'arXiv:2505.18897', 'title': 'Improving Ad matching via Cluster-Adaptive Keyword Expansion and Relevance tuning', 'authors': 'Dipanwita Saha, Anis Zaman, Hua Zou, Ning Chen, Xinxin Shu, Nadia Vase, Abraham Bagherjeiran', 'link': 'https://arxiv.org/abs/2505.18897', 'abstract': 'In search advertising, keyword matching connects user queries with relevant ads. While token-based matching increases ad coverage, it can reduce relevance due to overly permissive semantic expansion. This work extends keyword reach through document-side semantic keyword expansion, using a language model to broaden token-level matching without altering queries. We propose a solution using a pre-trained siamese model to generate dense vector representations of ad keywords and identify semantically related variants through nearest neighbor search. To maintain precision, we introduce a cluster-based thresholding mechanism that adjusts similarity cutoffs based on local semantic density. Each expanded keyword maps to a group of seller-listed items, which may only partially align with the original intent. To ensure relevance, we enhance the downstream relevance model by adapting it to the expanded keyword space using an incremental learning strategy with a lightweight decision tree ensemble. This system improves both relevance and click-through rate (CTR), offering a scalable, low-latency solution adaptable to evolving query behavior and advertising inventory.', 'abstract_zh': '基于文档侧语义关键词扩展的搜索引擎广告关键词匹配方法', 'title_zh': '改进广告匹配通过簇-广告自适应关键词扩展和相关性调整'}
{'arxiv_id': 'arXiv:2505.18893', 'title': "Reality Check: A New Evaluation Ecosystem Is Necessary to Understand AI's Real World Effects", 'authors': 'Reva Schwartz, Rumman Chowdhury, Akash Kundu, Heather Frase, Marzieh Fadaee, Tom David, Gabriella Waters, Afaf Taik, Morgan Briggs, Patrick Hall, Shomik Jain, Kyra Yee, Spencer Thomas, Sundeep Bhandari, Lee Wan Sie, Qinghua Lu, Matthew Holmes, Theodora Skeadas', 'link': 'https://arxiv.org/abs/2505.18893', 'abstract': "Conventional AI evaluation approaches concentrated within the AI stack exhibit systemic limitations for exploring, navigating and resolving the human and societal factors that play out in real world deployment such as in education, finance, healthcare, and employment sectors. AI capability evaluations can capture detail about first-order effects, such as whether immediate system outputs are accurate, or contain toxic, biased or stereotypical content, but AI's second-order effects, i.e. any long-term outcomes and consequences that may result from AI use in the real world, have become a significant area of interest as the technology becomes embedded in our daily lives. These secondary effects can include shifts in user behavior, societal, cultural and economic ramifications, workforce transformations, and long-term downstream impacts that may result from a broad and growing set of risks. This position paper argues that measuring the indirect and secondary effects of AI will require expansion beyond static, single-turn approaches conducted in silico to include testing paradigms that can capture what actually materializes when people use AI technology in context. Specifically, we describe the need for data and methods that can facilitate contextual awareness and enable downstream interpretation and decision making about AI's secondary effects, and recommend requirements for a new ecosystem.", 'abstract_zh': '传统的AI评估方法集中在AI栈内部，对于探索、导航和解决在教育、金融、医疗和就业等领域真实世界部署中展现出来的人类和社会因素系统性地表现出局限性。AI能力评估可以捕捉到直接影响的细节，例如系统即时输出的准确性或是否包含有毒、有偏见或刻板的内容，但AI的次生效应，即AI在真实世界使用过程中可能产生的长期结果和后果，已成为一个重要研究领域，特别是在这项技术嵌入我们日常生活的情况下。这些次生效应可能包括用户行为的转变、社会、文化和经济影响、劳动力结构的变化，以及由广泛存在的各类风险引发的长期下游影响。本文认为，衡量AI的间接和次生效应需要超越静态的单轮次在硅测试方法，包括可以捕捉到在实际情境中人们使用AI技术时所发生的真实情况的测试范式。具体而言，我们描述了有助于增强上下文意识、支持对AI次生效应进行下游解释和决策的数据和方法需求，并提出了新的生态系统的要求。', 'title_zh': '现实检验：需建立新的评估生态系统以理解AI的实际影响'}
{'arxiv_id': 'arXiv:2505.18892', 'title': 'Climate Implications of Diffusion-based Generative Visual AI Systems and their Mass Adoption', 'authors': 'Vanessa Utz, Steve DiPaola', 'link': 'https://arxiv.org/abs/2505.18892', 'abstract': 'Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consumer appeal, the GPU use of text-prompt based diffusion AI art systems also requires thoughtful considerations. Given the recent explosion in the number of highly sophisticated generative art systems and their rapid adoption by consumers and creative professionals, the impact of these systems on the climate needs to be carefully considered. In this work, we report on the growth of diffusion-based visual AI systems, their patterns of use, growth and the implications on the climate. Our estimates show that the mass adoption of these tools potentially contributes considerably to global energy consumption. We end this paper with our thoughts on solutions and future areas of inquiry as well as associated difficulties, including the lack of publicly available data.', 'abstract_zh': '快速发展的区块链等相关加密货币挖矿和NFT铸造对气候的影响已有充分记录，其巨大的GPU能耗引起了关注。然而，由于其更广泛的消费者吸引力，基于文本提示的扩散型AI艺术系统的GPU使用也需审慎考虑。鉴于这些高度复杂生成艺术系统数量的快速增长及其在消费者和创意专业人士中的迅速采纳，这些系统对气候的影响需要仔细考虑。在这项工作中，我们报告了基于扩散的视觉AI系统的增长、使用模式、增长趋势及其对气候的影响。我们的估算显示，这些工具的大规模采用可能显著增加全球能源消耗。我们在此文中提出了一些解决方案和未来研究方向的想法，同时也指出了相关困难，包括缺乏公开数据。', 'title_zh': '基于扩散的生成视觉AI系统及其大规模采用的气候影响'}
{'arxiv_id': 'arXiv:2505.18817', 'title': 'High-order Equivariant Flow Matching for Density Functional Theory Hamiltonian Prediction', 'authors': 'Seongsu Kim, Nayoung Kim, Dongwoo Kim, Sungsoo Ahn', 'link': 'https://arxiv.org/abs/2505.18817', 'abstract': 'Density functional theory (DFT) is a fundamental method for simulating quantum chemical properties, but it remains expensive due to the iterative self-consistent field (SCF) process required to solve the Kohn-Sham equations. Recently, deep learning methods are gaining attention as a way to bypass this step by directly predicting the Hamiltonian. However, they rely on deterministic regression and do not consider the highly structured nature of Hamiltonians. In this work, we propose QHFlow, a high-order equivariant flow matching framework that generates Hamiltonian matrices conditioned on molecular geometry. Flow matching models continuous-time trajectories between simple priors and complex targets, learning the structured distributions over Hamiltonians instead of direct regression. To further incorporate symmetry, we use a neural architecture that predicts SE(3)-equivariant vector fields, improving accuracy and generalization across diverse geometries. To further enhance physical fidelity, we additionally introduce a fine-tuning scheme to align predicted orbital energies with the target. QHFlow achieves state-of-the-art performance, reducing Hamiltonian error by 71% on MD17 and 53% on QH9. Moreover, we further show that QHFlow accelerates the DFT process without trading off the solution quality when initializing SCF iterations with the predicted Hamiltonian, significantly reducing the number of iterations and runtime.', 'abstract_zh': '基于密度泛函理论的高阶对称流匹配框架QHFlow：生成条件于分子几何的哈密顿矩阵', 'title_zh': '高阶等变流形匹配用于密度泛函理论哈密顿量预测'}
{'arxiv_id': 'arXiv:2505.18787', 'title': 'Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation', 'authors': 'Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac', 'link': 'https://arxiv.org/abs/2505.18787', 'abstract': 'Deepfake (DF) detectors face significant challenges when deployed in real-world environments, particularly when encountering test samples deviated from training data through either postprocessing manipulations or distribution shifts. We demonstrate postprocessing techniques can completely obscure generation artifacts presented in DF samples, leading to performance degradation of DF detectors. To address these challenges, we propose Think Twice before Adaptation (\\texttt{T$^2$A}), a novel online test-time adaptation method that enhances the adaptability of detectors during inference without requiring access to source training data or labels. Our key idea is to enable the model to explore alternative options through an Uncertainty-aware Negative Learning objective rather than solely relying on its initial predictions as commonly seen in entropy minimization (EM)-based approaches. We also introduce an Uncertain Sample Prioritization strategy and Gradients Masking technique to improve the adaptation by focusing on important samples and model parameters. Our theoretical analysis demonstrates that the proposed negative learning objective exhibits complementary behavior to EM, facilitating better adaptation capability. Empirically, our method achieves state-of-the-art results compared to existing test-time adaptation (TTA) approaches and significantly enhances the resilience and generalization of DF detectors during inference. Code is available \\href{this https URL}{here}.', 'abstract_zh': 'Deepfake检测器在实际应用场景中面临显著挑战，特别是在处理通过后处理操作或分布偏移与训练数据不一致的测试样本时。我们展示了后处理技术可以完全隐藏Deepfake样本中的生成特征，导致Deepfake检测器性能下降。为应对这些挑战，我们提出了一种名为Think Twice before Adaptation (\\texttt{T$^2$A})的新型在线测试时自适应方法，该方法在推理过程中增强了检测器的适应性，而不需访问源训练数据或标签。我们的主要思想是通过不确定性感知的负面学习目标使模型能够探索替代选项，而不是像基于熵最小化的方法那样仅依赖其初始预测。我们还引入了一种不确定性样本优先级策略和梯度屏蔽技术，通过聚焦重要样本和模型参数来提高自适应性能。我们的理论分析表明，提出的负面学习目标与熵最小化方法表现互补，有利于更好的自适应能力。实验结果显示，与现有的测试时自适应（TTA）方法相比，该方法在推理过程中显著提高了Deepfake检测器的鲁棒性和泛化能力。源代码可在这里获取。', 'title_zh': '三思而后适应：通过在线测试时适应提高深度假信息检测的适应性'}
{'arxiv_id': 'arXiv:2505.18783', 'title': 'Soft Weighted Machine Unlearning', 'authors': 'Xinbao Qiao, Ningning Ding, Yushi Cheng, Meng Zhang', 'link': 'https://arxiv.org/abs/2505.18783', 'abstract': 'Machine unlearning, as a post-hoc processing technique, has gained widespread adoption in addressing challenges like bias mitigation and robustness enhancement, colloquially, machine unlearning for fairness and robustness. However, existing non-privacy unlearning-based solutions persist in using binary data removal framework designed for privacy-driven motivation, leading to significant information loss, a phenomenon known as over-unlearning. While over-unlearning has been largely described in many studies as primarily causing utility degradation, we investigate its fundamental causes and provide deeper insights in this work through counterfactual leave-one-out analysis. In this paper, we introduce a weighted influence function that assigns tailored weights to each sample by solving a convex quadratic programming problem analytically. Building on this, we propose a soft-weighted framework enabling fine-grained model adjustments to address the over-unlearning challenge. We demonstrate that the proposed soft-weighted scheme is versatile and can be seamlessly integrated into most existing unlearning algorithms. Extensive experiments show that in fairness- and robustness-driven tasks, the soft-weighted scheme significantly outperforms hard-weighted schemes in fairness/robustness metrics and alleviates the decline in utility metric, thereby enhancing machine unlearning algorithm as an effective correction solution.', 'abstract_zh': '机器反学习作为一种后处理技术，在应对偏见缓解和鲁棒性增强等挑战中获得了广泛应用，即公平与鲁棒性的机器反学习。然而，现有的非隐私驱动的反学习解决方案仍然采用旨在保护隐私的数据二元删除框架，导致了显著的信息丢失，这种现象被称为过度反学习。尽管过度反学习在许多研究中主要被描述为导致效用下降，我们在本文中通过反事实的“leave-one-out”分析探究其根本原因，并提供更深入的见解。本文引入了一种加权影响函数，通过求解凸二次规划问题为每个样本赋予定制权重。在此基础上，我们提出了一种软加权框架，允许细粒度的模型调整以应对过度反学习挑战。我们证明，提出的软加权方案具有普适性，可以无缝集成到大多数现有的反学习算法中。大量实验表明，在公平性和鲁棒性驱动的任务中，软加权方案在公平性/鲁棒性指标上显著优于硬加权方案，并缓解了效用指标的下降，从而增强了机器反学习算法作为有效矫正解决方案的有效性。', 'title_zh': '软加权机器卸载'}
{'arxiv_id': 'arXiv:2505.18775', 'title': 'OmniGenBench: A Benchmark for Omnipotent Multimodal Generation across 50+ Tasks', 'authors': 'Jiayu Wang, Yang Jiao, Yue Yu, Tianwen Qian, Shaoxiang Chen, Jingjing Chen, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2505.18775', 'abstract': 'Recent breakthroughs in large multimodal models (LMMs), such as the impressive GPT-4o-Native, have demonstrated remarkable proficiency in following general-purpose instructions for image generation. However, current benchmarks often lack the necessary breadth and depth to fully evaluate the diverse capabilities of these models. To overcome this limitation, we introduce OmniGenBench, a novel and comprehensive benchmark meticulously designed to assess the instruction-following abilities of state-of-the-art LMMs across both perception-centric and cognition-centric dimensions. Our OmniGenBench includes 57 diverse sub-tasks grounded in real-world scenarios, systematically categorized according to the specific model capabilities they demand. For rigorous evaluation, we further employ a dual-mode protocol. This protocol utilizes off-the-shelf visual parsing tools for perception-centric tasks and a powerful LLM-based judger for cognition-centric tasks to assess the alignment between generated images and user instructions. Using OmniGenBench, we evaluate mainstream generative models, including prevalent models like GPT-4o, Gemini-2.0-Flash, and Seedream, and provide in-depth comparisons and analyses of their this http URL and data are available at this https URL.', 'abstract_zh': '近期大型多模态模型（LMMs）的突破，如令人印象深刻的GPT-4o-Native，在遵循通用指令进行图像生成方面展现了非凡的能力。然而，当前的基准测试往往缺乏足够的广度和深度，无法全面评估这些模型的多样能力。为克服这一限制，我们引入了OmniGenBench，这是一种新型且全面的基准测试，旨在从感知中心和认知中心两个维度评估最新LMMs的指令遵循能力。我们的OmniGenBench包括57个基于现实场景的多样化子任务，根据所需的具体模型能力系统分类。为确保严格的评估，我们进一步采用了一种双模式协议。该协议利用现成的视觉解析工具处理感知中心任务，并使用强大的LLM基础评判者评估认知中心任务，以衡量生成图像与用户指令的契合度。使用OmniGenBench，我们评估了主流生成模型，包括流行的GPT-4o、Gemini-2.0-Flash和Seedream等，并对其性能进行了深入比较和分析。相关数据可在以下链接获取：this https URL。', 'title_zh': 'OmniGenBench：多模态生成跨50余任务的基准测试'}
{'arxiv_id': 'arXiv:2505.18762', 'title': 'Towards an automatic method for generating topical vocabulary test forms for specific reading passages', 'authors': "Michael Flor, Zuowei Wang, Paul Deane, Tenaha O'Reilly", 'link': 'https://arxiv.org/abs/2505.18762', 'abstract': "Background knowledge is typically needed for successful comprehension of topical and domain specific reading passages, such as in the STEM domain. However, there are few automated measures of student knowledge that can be readily deployed and scored in time to make predictions on whether a given student will likely be able to understand a specific content area text. In this paper, we present our effort in developing K-tool, an automated system for generating topical vocabulary tests that measure students' background knowledge related to a specific text. The system automatically detects the topic of a given text and produces topical vocabulary items based on their relationship with the topic. This information is used to automatically generate background knowledge forms that contain words that are highly related to the topic and words that share similar features but do not share high associations to the topic. Prior research indicates that performance on such tasks can help determine whether a student is likely to understand a particular text based on their knowledge state. The described system is intended for use with middle and high school student population of native speakers of English. It is designed to handle single reading passages and is not dependent on any corpus or text collection. In this paper, we describe the system architecture and present an initial evaluation of the system outputs.", 'abstract_zh': '背景知识对于成功理解主题和特定领域的阅读 passages（如STEM领域）通常是必要的。然而，目前缺乏能够在及时评估学生知识状态后预测学生是否能够理解特定内容领域文本的自动化评估措施。本文我们介绍了开发K-tool的努力，这是一种自动化系统，用于生成与特定文本相关的主题词汇测验，以测量学生的背景知识。该系统自动检测文本的主题，并基于词汇与主题的关系生成相关词汇项。这些信息用于自动生成包含高度相关主题词汇和具有相似特征但与主题关联不强的词汇的背景知识测验。先前的研究表明，此类任务的表现可以帮助确定学生是否有可能基于其知识状态理解特定文本。该系统旨在用于英语为母语的中学生和高中生群体，可处理单篇阅读文本，不依赖于任何语料库或文本集合。本文描述了系统的架构，并介绍了系统的初步评估结果。', 'title_zh': '面向特定阅读 passages 的主题词汇测试题自动生成方法'}
{'arxiv_id': 'arXiv:2505.18755', 'title': 'Smart Energy Guardian: A Hybrid Deep Learning Model for Detecting Fraudulent PV Generation', 'authors': 'Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang', 'link': 'https://arxiv.org/abs/2505.18755', 'abstract': 'With the proliferation of smart grids, smart cities face growing challenges due to cyber-attacks and sophisticated electricity theft behaviors, particularly in residential photovoltaic (PV) generation systems. Traditional Electricity Theft Detection (ETD) methods often struggle to capture complex temporal dependencies and integrating multi-source data, limiting their effectiveness. In this work, we propose an efficient ETD method that accurately identifies fraudulent behaviors in residential PV generation, thus ensuring the supply-demand balance in smart cities. Our hybrid deep learning model, combining multi-scale Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, excels in capturing both short-term and long-term temporal dependencies. Additionally, we introduce a data embedding technique that seamlessly integrates time-series data with discrete temperature variables, enhancing detection robustness. Extensive simulation experiments using real-world data validate the effectiveness of our approach, demonstrating significant improvements in the accuracy of detecting sophisticated energy theft activities, thereby contributing to the stability and fairness of energy systems in smart cities.', 'abstract_zh': '随着智能电网的普及，智能城市面临着日益严重的网络安全攻击和 sophisticated 电力窃取行为的挑战，特别是在住宅光伏（PV）发电系统中。传统的电力窃取检测（ETD）方法往往难以捕捉复杂的时序依赖性和多源数据的集成，限制了其有效性。在本工作中，我们提出了一种有效的ETD方法，能够准确识别住宅PV发电中的欺诈行为，从而确保智能城市的供需平衡。我们的混合深度学习模型结合了多尺度卷积神经网络（CNN）、长短期记忆网络（LSTM）和Transformer，能够在捕捉短时和长时依赖性方面表现出色。此外，我们引入了一种数据嵌入技术，无缝地将时间序列数据与离散温度变量集成，提高了检测的稳健性。通过使用真实数据进行广泛的仿真实验，验证了我们方法的有效性，展示了在检测复杂能源窃取活动方面显著的准确性提升，从而为智能城市的能源系统稳定性和公平性做出了贡献。', 'title_zh': '智能能量守护者：一种检测欺诈性光伏发电的混合深度学习模型'}
{'arxiv_id': 'arXiv:2505.18747', 'title': 'Season-Independent PV Disaggregation Using Multi-Scale Net Load Temporal Feature Extraction and Weather Factor Fusion', 'authors': 'Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang', 'link': 'https://arxiv.org/abs/2505.18747', 'abstract': 'With the advancement of energy Internet and energy system integration, the increasing adoption of distributed photovoltaic (PV) systems presents new challenges on smart monitoring and measurement for utility companies, particularly in separating PV generation from net electricity load. Existing methods struggle with feature extraction from net load and capturing the relevance between weather factors. This paper proposes a PV disaggregation method that integrates Hierarchical Interpolation (HI) and multi-head self-attention mechanisms. By using HI to extract net load features and multi-head self-attention to capture the complex dependencies between weather factors, the method achieves precise PV generation predictions. Simulation experiments demonstrate the effectiveness of the proposed method in real-world data, supporting improved monitoring and management of distributed energy systems.', 'abstract_zh': '随着能源互联网和能源系统集成的发展，分布式光伏系统（PV）的广泛应用给电力公司带来了新的智能监测和计量挑战，特别是在分离光伏发电与净电量负荷方面。现有方法在从净负荷中提取特征和捕捉天气因素的相关性方面存在困难。本文提出了一种结合分层插值（HI）和多头自注意力机制的光伏解耦方法。通过使用HI提取净负荷特征和多头自注意力捕捉天气因素之间的复杂依赖关系，该方法实现了精确的光伏发电预测。仿真实验表明，所提出的方法在实际数据中的有效性，支持分布式能源系统的改进监控和管理。', 'title_zh': '独立于季节的光伏功率解耦利用多尺度净负荷时序特征提取和气象因素融合'}
{'arxiv_id': 'arXiv:2505.18741', 'title': 'MoMBS: Mixed-order minibatch sampling enhances model training from diverse-quality images', 'authors': 'Han Li, Hu Han, S. Kevin Zhou', 'link': 'https://arxiv.org/abs/2505.18741', 'abstract': 'Natural images exhibit label diversity (clean vs. noisy) in noisy-labeled image classification and prevalence diversity (abundant vs. sparse) in long-tailed image classification. Similarly, medical images in universal lesion detection (ULD) exhibit substantial variations in image quality, encompassing attributes such as clarity and label correctness. How to effectively leverage training images with diverse qualities becomes a problem in learning deep models. Conventional training mechanisms, such as self-paced curriculum learning (SCL) and online hard example mining (OHEM), relieve this problem by reweighting images with high loss values. Despite their success, these methods still confront two challenges: (i) the loss-based measure of sample hardness is imprecise, preventing optimum handling of different cases, and (ii) there exists under-utilization in SCL or over-utilization OHEM with the identified hard samples. To address these issues, this paper revisits the minibatch sampling (MBS), a technique widely used in deep network training but largely unexplored concerning the handling of diverse-quality training samples. We discover that the samples within a minibatch influence each other during training; thus, we propose a novel Mixed-order Minibatch Sampling (MoMBS) method to optimize the use of training samples with diverse qualities. MoMBS introduces a measure that takes both loss and uncertainty into account to surpass a sole reliance on loss and allows for a more refined categorization of high-loss samples by distinguishing them as either poorly labeled and under represented or well represented and overfitted. We prioritize under represented samples as the main gradient contributors in a minibatch and keep them from the negative influences of poorly labeled or overfitted samples with a mixed-order minibatch sampling design.', 'abstract_zh': '自然图像在嘈噪声标注图像分类中表现出标签多样性（干净 vs. 噪声）的特点，在长尾图像分类中表现出丰度多样性（丰富 vs. 稀少）的特点。同样，在普遍病灶检测中，医学图像在图像质量方面表现出显著差异，涵盖清晰度和标签正确性等属性。如何有效利用具有不同质量的训练图像成为学习深度模型中的一个难题。传统的训练机制，如自步曲案课程学习（SCL）和在线难例挖掘（OHEM），通过重新加权高损失值的图像来缓解这一问题。尽管取得了成功，这些方法仍面临两个挑战：（i）基于损失的样本难度衡量不够准确，阻碍了对不同情况的最优处理，（ii）SCL中存在欠利用或OHEM中存在过利用识别出的难例。为解决这些问题，本文重新审视了小批量采样（MBS）这一在深度网络训练中广泛应用但对多样质训练样本处理较少探讨的技术。我们发现小批量内的样本在训练过程中互相影响，因此提出了一种新颖的混合顺序小批量采样（MoMBS）方法以优化具有不同质量的训练样本的使用。MoMBS引入了一个同时考虑损失和不确定性的度量，超越了单纯依赖损失的做法，并通过区分低标签质量和欠表示与良好表示和过拟合的高损失样本来实现更精细的分类。在小批量中，我们优先考虑欠表示样本作为主要梯度贡献者，并通过混合顺序小批量采样设计防止其受到低标签质量和过拟合样本的负面影响。', 'title_zh': 'MoMBS: 混合阶数 minibatch 抽样增强多样质量图像的模型训练'}
{'arxiv_id': 'arXiv:2505.18728', 'title': 'Message-Passing State-Space Models: Improving Graph Learning with Modern Sequence Modeling', 'authors': 'Andrea Ceni, Alessio Gravina, Claudio Gallicchio, Davide Bacciu, Carola-Bibiane Schonlieb, Moshe Eliasof', 'link': 'https://arxiv.org/abs/2505.18728', 'abstract': 'The recent success of State-Space Models (SSMs) in sequence modeling has motivated their adaptation to graph learning, giving rise to Graph State-Space Models (GSSMs). However, existing GSSMs operate by applying SSM modules to sequences extracted from graphs, often compromising core properties such as permutation equivariance, message-passing compatibility, and computational efficiency. In this paper, we introduce a new perspective by embedding the key principles of modern SSM computation directly into the Message-Passing Neural Network framework, resulting in a unified methodology for both static and temporal graphs. Our approach, MP-SSM, enables efficient, permutation-equivariant, and long-range information propagation while preserving the architectural simplicity of message passing. Crucially, MP-SSM enables an exact sensitivity analysis, which we use to theoretically characterize information flow and evaluate issues like vanishing gradients and over-squashing in the deep regime. Furthermore, our design choices allow for a highly optimized parallel implementation akin to modern SSMs. We validate MP-SSM across a wide range of tasks, including node classification, graph property prediction, long-range benchmarks, and spatiotemporal forecasting, demonstrating both its versatility and strong empirical performance.', 'abstract_zh': '最近状态空间模型在序列建模中的成功激发了其在图学习中的应用，产生了图状态空间模型（GSSMs）。然而，现有的GSSMs往往通过将状态空间模块应用于从图中抽取的序列来进行操作，这往往会牺牲置换等变性、消息传递兼容性和计算效率等核心属性。在本文中，我们通过将现代状态空间计算的关键原则直接嵌入到消息传递神经网络框架中，提出了一种统一的方法来处理静态和动态图。我们的方法MP-SSM能够在保持消息传递架构简洁性的同时，实现高效、置换等变且长程的信息传播。 crucially, MP-SSM 允许进行精确的灵敏度分析，我们利用这一特性从理论上表征信息流动并评估深层情况下的梯度消失和过度挤压等问题。此外，我们的设计选择使得MP-SSM 具有类似现代状态空间模型的高效并行实现。我们通过一系列任务验证了MP-SSM 的性能，包括节点分类、图属性预测、长程基准测试和时空预测，展示了其灵活性和强大的实证效果。', 'title_zh': '消息传递状态空间模型：借助现代序列建模改进图学习'}
{'arxiv_id': 'arXiv:2505.18722', 'title': "Evaluating the Usefulness of Non-Diagnostic Speech Data for Developing Parkinson's Disease Classifiers", 'authors': 'Terry Yi Zhong, Esther Janse, Cristian Tejedor-Garcia, Louis ten Bosch, Martha Larson', 'link': 'https://arxiv.org/abs/2505.18722', 'abstract': "Speech-based Parkinson's disease (PD) detection has gained attention for its automated, cost-effective, and non-intrusive nature. As research studies usually rely on data from diagnostic-oriented speech tasks, this work explores the feasibility of diagnosing PD on the basis of speech data not originally intended for diagnostic purposes, using the Turn-Taking (TT) dataset. Our findings indicate that TT can be as useful as diagnostic-oriented PD datasets like PC-GITA. We also investigate which specific dataset characteristics impact PD classification performance. The results show that concatenating audio recordings and balancing participants' gender and status distributions can be beneficial. Cross-dataset evaluation reveals that models trained on PC-GITA generalize poorly to TT, whereas models trained on TT perform better on PC-GITA. Furthermore, we provide insights into the high variability across folds, which is mainly due to large differences in individual speaker performance.", 'abstract_zh': '基于语音的帕金森病（PD）检测因其实现自动化、成本效益高且非侵入性而引起了关注。本研究探讨了使用非诊断目的的转换取向（TT）数据集进行帕金森病诊断的可能性，发现TT数据集与PC-GITA等诊断导向的数据集具有相似的诊断价值。研究还分析了哪些特定的数据集特征会影响PD分类性能。结果表明，将音频记录片段串联使用并平衡参与者性别和状态分布可能有助于提高性能。跨数据集评估表明，基于PC-GITA训练的模型在TT数据集上的泛化能力较差，而基于TT数据集训练的模型在PC-GITA数据集上的表现更好。此外，研究还揭示了不同折间高变异性的主要原因在于个体说话人表现差异较大。', 'title_zh': '评估非诊断性语音数据在帕金森病分类器开发中的 usefulness'}
{'arxiv_id': 'arXiv:2505.18713', 'title': 'Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer', 'authors': 'Guodong Du, Zitao Fang, Jing Li, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai Liu, Min Zhang', 'link': 'https://arxiv.org/abs/2505.18713', 'abstract': 'Foundation models and their checkpoints have significantly advanced deep learning, boosting performance across various applications. However, fine-tuned models often struggle outside their specific domains and exhibit considerable redundancy. Recent studies suggest that combining a pruned fine-tuned model with the original pre-trained model can mitigate forgetting, reduce interference when merging model parameters across tasks, and improve compression efficiency. In this context, developing an effective pruning strategy for fine-tuned models is crucial. Leveraging the advantages of the task vector mechanism, we preprocess fine-tuned models by calculating the differences between them and the original model. Recognizing that different task vector subspaces contribute variably to model performance, we introduce a novel method called Neural Parameter Search (NPS-Pruning) for slimming down fine-tuned models. This method enhances pruning efficiency by searching through neural parameters of task vectors within low-rank subspaces. Our method has three key applications: enhancing knowledge transfer through pairwise model interpolation, facilitating effective knowledge fusion via model merging, and enabling the deployment of compressed models that retain near-original performance while significantly reducing storage costs. Extensive experiments across vision, NLP, and multi-modal benchmarks demonstrate the effectiveness and robustness of our approach, resulting in substantial performance gains. The code is publicly available at: this https URL.', 'abstract_zh': '基于预训练模型的剪枝策略：提高微调模型的效率与压缩性能', 'title_zh': '神经参数搜索以获得更瘦的微调模型和更好的迁移学习'}
{'arxiv_id': 'arXiv:2505.18708', 'title': 'A General Knowledge Injection Framework for ICD Coding', 'authors': 'Xu Zhang, Kun Zhang, Wenxin Ma, Rongsheng Wang, Chenxu Wu, Yingtai Li, S. Kevin Zhou', 'link': 'https://arxiv.org/abs/2505.18708', 'abstract': 'ICD Coding aims to assign a wide range of medical codes to a medical text document, which is a popular and challenging task in the healthcare domain. To alleviate the problems of long-tail distribution and the lack of annotations of code-specific evidence, many previous works have proposed incorporating code knowledge to improve coding performance. However, existing methods often focus on a single type of knowledge and design specialized modules that are complex and incompatible with each other, thereby limiting their scalability and effectiveness. To address this issue, we propose GKI-ICD, a novel, general knowledge injection framework that integrates three key types of knowledge, namely ICD Description, ICD Synonym, and ICD Hierarchy, without specialized design of additional modules. The comprehensive utilization of the above knowledge, which exhibits both differences and complementarity, can effectively enhance the ICD coding performance. Extensive experiments on existing popular ICD coding benchmarks demonstrate the effectiveness of GKI-ICD, which achieves the state-of-the-art performance on most evaluation metrics. Code is available at this https URL.', 'abstract_zh': 'ICD编码旨在为医疗文本文档分配广泛的医学代码，这是医疗领域一个流行且具有挑战性的任务。为了缓解长尾分布和代码特定证据标注不足的问题，许多先前的工作提出了结合代码知识以提高编码性能的方法。然而，现有方法通常关注单类型的知识，并设计专门的模块，这些模块复杂且彼此不兼容，从而限制了它们的可扩展性和有效性。为解决这一问题，我们提出了一种新颖的一般知识注入框架GKI-ICD，该框架整合了ICD描述、ICD同义词和ICD层级三种关键类型的知识，而不需要设计额外的专门模块。综合利用这些知识，虽然它们之间存在差异和互补性，但可以有效提高ICD编码性能。在现有广泛的ICD编码基准上的广泛实验展示了GKI-ICD的有效性，该方法在大多数评估指标上达到了最先进的性能。代码可在以下链接获得：this https URL。', 'title_zh': 'ICD编码的一般知识注入框架'}
{'arxiv_id': 'arXiv:2505.18687', 'title': 'An AI Capability Threshold for Rent-Funded Universal Basic Income in an AI-Automated Economy', 'authors': 'Aran Nayebi', 'link': 'https://arxiv.org/abs/2505.18687', 'abstract': "We derive the first closed-form condition under which artificial intelligence (AI) capital profits could sustainably finance a universal basic income (UBI) without additional taxes or new job creation. In a Solow-Zeira economy characterized by a continuum of automatable tasks, a constant net saving rate $s$, and task-elasticity $\\sigma < 1$, we analyze how the AI capability threshold--defined as the productivity level of AI relative to pre-AI automation--varies under different economic scenarios. At present economic parameters, we find that AI systems must achieve only approximately 5-6 times existing automation productivity to finance an 11\\%-of-GDP UBI, in the worst case situation where \\emph{no} new jobs or tasks are created.\nOur analysis also reveals some specific policy levers: raising public revenue share (e.g. profit taxation) of AI capital from the current 15\\% to about 33\\% halves the required AI capability threshold to attain UBI to 3 times existing automotion productivity, but gains diminish beyond 50\\% public revenue share, especially if regulatory costs increase. Market structure also strongly affects outcomes: monopolistic or concentrated oligopolistic markets reduce the threshold by increasing economic rents, whereas heightened competition significantly raises it.\nOverall, these results suggest a couple policy recommendations: maximizing public revenue share up to a point so that operating costs are minimized, and strategically managing market competition can ensure AI's growing capabilities translate into meaningful social benefits within realistic technological progress scenarios.", 'abstract_zh': '我们推导出了第一个闭合形式条件，即人工智能资本收益可以在无需额外税收或创造新就业的情况下持续资助普遍基本收入。在由可自动化任务连续体、恒定净储蓄率 \\(s\\) 和任务弹性 \\(\\sigma < 1\\) 特征的索洛-泽拉经济中，我们分析了人工智能能力门槛——即人工智能相对于预人工智能自动化的产品ivity水平——在不同经济情景下的变化。在当前的经济参数下，我们发现，即使在不创造任何新工作或任务的情况下，人工智能系统只需实现现有自动化生产力的约5-6倍，就能资助占GDP 11%的普遍基本收入。', 'title_zh': 'AI能力阈值下的租金资助普遍基本收入在AI自动化经济中的应用'}
{'arxiv_id': 'arXiv:2505.18675', 'title': 'Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps', 'authors': 'Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang', 'link': 'https://arxiv.org/abs/2505.18675', 'abstract': 'Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning tasks involving fine-grained visual understanding remains insufficiently evaluated. To address this gap, we introduce ReasonMap, a benchmark designed to assess the fine-grained visual understanding and spatial reasoning abilities of MLLMs. ReasonMap encompasses high-resolution transit maps from 30 cities across 13 countries and includes 1,008 question-answer pairs spanning two question types and three templates. Furthermore, we design a two-level evaluation pipeline that properly assesses answer correctness and quality. Comprehensive evaluations of 15 popular MLLMs, including both base and reasoning variants, reveal a counterintuitive pattern: among open-source models, base models outperform reasoning ones, while the opposite trend is observed in closed-source models. Additionally, performance generally degrades when visual inputs are masked, indicating that while MLLMs can leverage prior knowledge to answer some questions, fine-grained visual reasoning tasks still require genuine visual perception for strong performance. Our benchmark study offers new insights into visual reasoning and contributes to investigating the gap between open-source and closed-source models.', 'abstract_zh': '多模态大规模语言模型（MLLMs）在视觉任务中的细粒度视觉理解和空间推理能力评估', 'title_zh': 'MLLMs能引导我回家吗？关于基于公交地图的细粒度视觉推理的基准研究'}
{'arxiv_id': 'arXiv:2505.18647', 'title': 'Flow Matching for Geometric Trajectory Simulation', 'authors': 'Kiet Bennema ten Brinke, Koen Minartz, Vlado Menkovski', 'link': 'https://arxiv.org/abs/2505.18647', 'abstract': 'The simulation of N-body systems is a fundamental problem with applications in a wide range of fields, such as molecular dynamics, biochemistry, and pedestrian dynamics. Machine learning has become an invaluable tool for scaling physics-based simulators and developing models directly from experimental data. In particular, recent advances based on deep generative modeling and geometric deep learning have enabled probabilistic simulation by modeling complex distributions over trajectories while respecting the permutation symmetry that is fundamental to N-body systems. However, to generate realistic trajectories, existing methods must learn complex transformations starting from uninformed noise and do not allow for the exploitation of domain-informed priors. In this work, we propose STFlow to address this limitation. By leveraging flow matching and data-dependent couplings, STFlow facilitates physics-informed simulation of geometric trajectories without sacrificing model expressivity or scalability. Our evaluation on N-body dynamical systems, molecular dynamics, and pedestrian dynamics benchmarks shows that STFlow produces significantly lower prediction errors while enabling more efficient inference, highlighting the benefits of employing physics-informed prior distributions in probabilistic geometric trajectory modeling.', 'abstract_zh': '基于N-体系统的仿真：从实验数据中直接开发物理模型的机器学习方法及其应用', 'title_zh': '几何轨迹模拟中的流匹配'}
{'arxiv_id': 'arXiv:2505.18640', 'title': 'ThanoRA: Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation', 'authors': 'Jian Liang, Wenke Huang, Xianda Guo, Guancheng Wan, Bo Du, Mang Ye', 'link': 'https://arxiv.org/abs/2505.18640', 'abstract': 'Low-Rank Adaptation (LoRA) is widely adopted for downstream fine-tuning of foundation models due to its efficiency and zero additional inference cost. Many real-world applications require foundation models to specialize in multiple tasks simultaneously, motivating the need for efficient multi-task adaptation. While recent approaches integrate LoRA with mixture-of-experts (MoE) to address this, the use of routers prevents parameter mergeability, which increases inference overhead and hinders unified multi-task adaptation, thereby limiting deployment practicality. In this work, we propose ThanoRA, a Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation framework that enables multi-task adaptation while preserving the inference efficiency of LoRA. ThanoRA jointly models task heterogeneity and mitigates subspace interference throughout training. Specifically, motivated by inherent differences in complexity and heterogeneity across tasks, ThanoRA constructs task-specific LoRA subspaces at initialization, enabling fine-grained knowledge injection aligned with task heterogeneity. Furthermore, to prevent task interference and subspace collapse during multi-task training, ThanoRA introduces a subspace-preserving regularization that maintains the independence of task-specific representations. With the synergy of both components, ThanoRA enables efficient and unified multi-task adaptation. Extensive experiments across multimodal and text-only benchmarks under varying multi-task mixtures demonstrate that ThanoRA consistently achieves robust and superior performance over strong baselines without introducing additional inference overhead. Our code is publicly available at: this https URL.', 'abstract_zh': '基于任务异质性的多任务低秩适应框架ThanoRA', 'title_zh': 'ThanoRA：任务异质性意识的多任务低秩适应'}
{'arxiv_id': 'arXiv:2505.18622', 'title': "Trust, or Don't Predict: Introducing the CWSA Family for Confidence-Aware Model Evaluation", 'authors': 'Kourosh Shahnazari, Seyed Moein Ayyoubzadeh, Mohammadali Keshtparvar, Pegah Ghaffari', 'link': 'https://arxiv.org/abs/2505.18622', 'abstract': 'In recent machine learning systems, confidence scores are being utilized more and more to manage selective prediction, whereby a model can abstain from making a prediction when it is unconfident. Yet, conventional metrics like accuracy, expected calibration error (ECE), and area under the risk-coverage curve (AURC) do not capture the actual reliability of predictions. These metrics either disregard confidence entirely, dilute valuable localized information through averaging, or neglect to suitably penalize overconfident misclassifications, which can be particularly detrimental in real-world systems. We introduce two new metrics Confidence-Weighted Selective Accuracy (CWSA) and its normalized variant CWSA+ that offer a principled and interpretable way to evaluate predictive models under confidence thresholds. Unlike existing methods, our metrics explicitly reward confident accuracy and penalize overconfident mistakes. They are threshold-local, decomposable, and usable in both evaluation and deployment settings where trust and risk must be quantified. Through exhaustive experiments on both real-world data sets (MNIST, CIFAR-10) and artificial model variants (calibrated, overconfident, underconfident, random, perfect), we show that CWSA and CWSA+ both effectively detect nuanced failure modes and outperform classical metrics in trust-sensitive tests. Our results confirm that CWSA is a sound basis for developing and assessing selective prediction systems for safety-critical domains.', 'abstract_zh': '基于置信度加权选择准确率及其规范化 variant CWSA+ 在选择性预测中的评估新方法', 'title_zh': '信任，或不预测：引入基于置信意识的模型评价CWSA家族'}
{'arxiv_id': 'arXiv:2505.18595', 'title': 'MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations', 'authors': 'Viet Bui, Tien Mai, Hong Thanh Nguyen', 'link': 'https://arxiv.org/abs/2505.18595', 'abstract': 'We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.', 'abstract_zh': '我们在合作多智能体环境下研究离线模仿学习（IL），其中示例具有未标记的混合质量，包含专家和次优轨迹。我们提出的方法分为两个阶段：轨迹标注和多智能体模仿学习，旨在有效学习来自异构且未标记的数据。在第一阶段，我们结合大型语言模型和基于偏好的强化学习进展，构建一个逐步的标注流水线，以区分专家级轨迹。在第二阶段，我们引入了一种名为MisoDICE的新颖多智能体IL算法，利用这些标注来学习鲁棒策略，同时解决大型联合状态动作空间的计算复杂性问题。通过将流行的单智能体DICE框架扩展到具有新值分解和混合架构的合作多智能体环境，我们的方法产生了凸策略优化目标，并确保全局和局部策略的一致性。我们使用多个标准多智能体RL基准评估MisoDICE，并展示了更好性能，尤其是在专家数据稀缺时。', 'title_zh': 'MisoDICE: 多Agentimitation 从未标记的混合质量示范中学习'}
{'arxiv_id': 'arXiv:2505.18581', 'title': 'Removal of Hallucination on Hallucination: Debate-Augmented RAG', 'authors': 'Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Qing Li', 'link': 'https://arxiv.org/abs/2505.18581', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external knowledge, yet it introduces a critical issue: erroneous or biased retrieval can mislead generation, compounding hallucinations, a phenomenon we term Hallucination on Hallucination. To address this, we propose Debate-Augmented RAG (DRAG), a training-free framework that integrates Multi-Agent Debate (MAD) mechanisms into both retrieval and generation stages. In retrieval, DRAG employs structured debates among proponents, opponents, and judges to refine retrieval quality and ensure factual reliability. In generation, DRAG introduces asymmetric information roles and adversarial debates, enhancing reasoning robustness and mitigating factual inconsistencies. Evaluations across multiple tasks demonstrate that DRAG improves retrieval reliability, reduces RAG-induced hallucinations, and significantly enhances overall factual accuracy. Our code is available at this https URL.', 'abstract_zh': '检索增强生成（RAG）通过集成外部知识提高了事实准确性，但引入了一个关键问题：错误或有偏见的检索可能导致生成产生误导，加剧幻觉现象，我们称之为幻觉叠加重现。为解决这一问题，我们提出了辩论增强RAG（DRAG）框架，这是一种无需训练的框架，将多智能体辩论（MAD）机制融入检索和生成阶段。在检索阶段，DRAG通过倡导者、反对者和法官之间的结构化辩论来优化检索质量并确保事实可靠性。在生成阶段，DRAG引入了不对称信息角色和对抗性辩论，增强了推理的鲁棒性并减轻了事实不一致问题。跨多个任务的评估表明，DRAG提高了检索可靠性、减少了RAG诱导的幻觉，并显著提高了整体事实准确性。代码托管在该地址：<https://>。', 'title_zh': '幻觉中的幻觉消除：辩论增强的RAG'}
{'arxiv_id': 'arXiv:2505.18568', 'title': 'Learning without Isolation: Pathway Protection for Continual Learning', 'authors': 'Zhikang Chen, Abudukelimu Wuerkaixi, Sen Cui, Haoxuan Li, Ding Li, Jingfeng Zhang, Bo Han, Gang Niu, Houfang Liu, Yi Yang, Sifan Yang, Changshui Zhang, Tianling Ren', 'link': 'https://arxiv.org/abs/2505.18568', 'abstract': 'Deep networks are prone to catastrophic forgetting during sequential task learning, i.e., losing the knowledge about old tasks upon learning new tasks. To this end, continual learning(CL) has emerged, whose existing methods focus mostly on regulating or protecting the parameters associated with the previous tasks. However, parameter protection is often impractical, since the size of parameters for storing the old-task knowledge increases linearly with the number of tasks, otherwise it is hard to preserve the parameters related to the old-task knowledge. In this work, we bring a dual opinion from neuroscience and physics to CL: in the whole networks, the pathways matter more than the parameters when concerning the knowledge acquired from the old tasks. Following this opinion, we propose a novel CL framework, learning without isolation(LwI), where model fusion is formulated as graph matching and the pathways occupied by the old tasks are protected without being isolated. Thanks to the sparsity of activation channels in a deep network, LwI can adaptively allocate available pathways for a new task, realizing pathway protection and addressing catastrophic forgetting in a parameter-efficient manner. Experiments on popular benchmark datasets demonstrate the superiority of the proposed LwI.', 'abstract_zh': '深度网络在进行序列任务学习时容易发生灾难性遗忘，即在学习新任务时会丢失旧任务的知识。为此，连续学习(CL)应运而生，现有方法主要集中在调节或保护与之前任务相关的参数。然而，参数保护往往不切实际，因为用于存储旧任务知识的参数数量随任务数量线性增加，否则很难保留与旧任务知识相关的参数。在本工作中，我们从神经科学和物理学的角度出发，提出了一种新的观点应用于CL：在网络整体中，路径比参数更重要，当考虑从旧任务中学到的知识时。基于此观点，我们提出了一个新颖的连续学习框架“学习无孤立”(LwI)，其中模型融合被形式化为图匹配，旧任务所占的路径被保护而不被孤立。得益于深层网络激活通道的稀疏性，LwI 可以自适应地为新任务分配可用路径，从而实现路径保护并以参数高效的方式解决灾难性遗忘问题。实验在流行的基准数据集上证明了所提出的LwI的优越性。', 'title_zh': '无孤立学习：连续学习的路径保护'}
{'arxiv_id': 'arXiv:2505.18563', 'title': 'PacTrain: Pruning and Adaptive Sparse Gradient Compression for Efficient Collective Communication in Distributed Deep Learning', 'authors': 'Yisu Wang, Ruilong Wu, Xinjiao Li, Dirk Kutscher', 'link': 'https://arxiv.org/abs/2505.18563', 'abstract': 'Large-scale deep neural networks (DNN) exhibit excellent performance for various tasks. As DNNs and datasets grow, distributed training becomes extremely time-consuming and demands larger clusters. A main bottleneck is the resulting gradient aggregation overhead. While gradient compression and sparse collective communication techniques are commonly employed to alleviate network load, many gradient compression schemes do not achieve acceleration of the training process while also preserving accuracy. This paper introduces PacTrain, a novel framework that accelerates distributed training by combining pruning with sparse gradient compression. Active pruning of the neural network makes the model weights and gradients sparse. By ensuring the global knowledge of the gradient sparsity among all distributed training workers, we can perform lightweight compression communication without harming accuracy. We show that the PacTrain compression scheme achieves a near-optimal compression strategy while remaining compatible with the all-reduce primitive. Experimental evaluations show that PacTrain improves training throughput by 1.25 to 8.72 times compared to state-of-the-art compression-enabled systems for representative vision and language models training tasks under bandwidth-constrained conditions.', 'abstract_zh': '大规模深度神经网络（DNN）在各种任务中表现出色。随着DNN和数据集的增长，分布式训练变得极其耗时，并要求更大的计算集群。主要瓶颈是由此产生的梯度聚合开销。虽然梯度压缩和稀疏集体通信技术通常被用来缓解网络负载，但许多梯度压缩方案在加速训练过程的同时未能保持准确性。本文提出了一种名为PacTrain的新框架，通过结合剪枝与稀疏梯度压缩来加速分布式训练。通过对神经网络进行活动剪枝，使得模型权重和梯度变得稀疏。通过确保梯度稀疏性在所有分布式训练工作节点之间的全局知识，可以在不损害准确性的情况下进行轻量级压缩通信。实验评估表明，在带宽受限条件下，PacTrain压缩方案在代表性视觉和语言模型训练任务中相较于最先进的压缩启用系统，能将训练吞吐量提高1.25到8.72倍。', 'title_zh': 'PacTrain: 剪枝和自适应稀疏梯度压缩在分布式深度学习中高效集体通信'}
{'arxiv_id': 'arXiv:2505.18533', 'title': 'TS-URGENet: A Three-stage Universal Robust and Generalizable Speech Enhancement Network', 'authors': 'Xiaobin Rong, Dahan Wang, Qinwen Hu, Yushi Wang, Yuxiang Hu, Jing Lu', 'link': 'https://arxiv.org/abs/2505.18533', 'abstract': 'Universal speech enhancement aims to handle input speech with different distortions and input formats. To tackle this challenge, we present TS-URGENet, a Three-Stage Universal, Robust, and Generalizable speech Enhancement Network. To address various distortions, the proposed system employs a novel three-stage architecture consisting of a filling stage, a separation stage, and a restoration stage. The filling stage mitigates packet loss by preliminarily filling lost regions under noise interference, ensuring signal continuity. The separation stage suppresses noise, reverberation, and clipping distortion to improve speech clarity. Finally, the restoration stage compensates for bandwidth limitation, codec artifacts, and residual packet loss distortion, refining the overall speech quality. Our proposed TS-URGENet achieved outstanding performance in the Interspeech 2025 URGENT Challenge, ranking 2nd in Track 1.', 'abstract_zh': '三阶段通用鲁棒可泛化语音增强网络', 'title_zh': 'TS-URGENet：三阶段通用鲁棒且泛化的语音增强网络'}
{'arxiv_id': 'arXiv:2505.18514', 'title': 'Test-Time Adaptation with Binary Feedback', 'authors': 'Taeckyung Lee, Sorn Chottananurak, Junsu Kim, Jinwoo Shin, Taesik Gong, Sung-Ju Lee', 'link': 'https://arxiv.org/abs/2505.18514', 'abstract': 'Deep learning models perform poorly when domain shifts exist between training and test data. Test-time adaptation (TTA) is a paradigm to mitigate this issue by adapting pre-trained models using only unlabeled test samples. However, existing TTA methods can fail under severe domain shifts, while recent active TTA approaches requiring full-class labels are impractical due to high labeling costs. To address this issue, we introduce a new setting of TTA with binary feedback. This setting uses a few binary feedback inputs from annotators to indicate whether model predictions are correct, thereby significantly reducing the labeling burden of annotators. Under the setting, we propose BiTTA, a novel dual-path optimization framework that leverages reinforcement learning to balance binary feedback-guided adaptation on uncertain samples with agreement-based self-adaptation on confident predictions. Experiments show BiTTA achieves 13.3%p accuracy improvements over state-of-the-art baselines, demonstrating its effectiveness in handling severe distribution shifts with minimal labeling effort. The source code is available at this https URL.', 'abstract_zh': '基于二元反馈的测试时自适应（BiTTA）方法：处理严重分布偏移的新方法', 'title_zh': '测试时自适应与二元反馈'}
{'arxiv_id': 'arXiv:2505.18505', 'title': 'How Particle System Theory Enhances Hypergraph Message Passing', 'authors': 'Yixuan Ma, Kai Yi, Pietro Lio, Shi Jin, Yu Guang Wang', 'link': 'https://arxiv.org/abs/2505.18505', 'abstract': 'Hypergraphs effectively model higher-order relationships in natural phenomena, capturing complex interactions beyond pairwise connections. We introduce a novel hypergraph message passing framework inspired by interacting particle systems, where hyperedges act as fields inducing shared node dynamics. By incorporating attraction, repulsion, and Allen-Cahn forcing terms, particles of varying classes and features achieve class-dependent equilibrium, enabling separability through the particle-driven message passing. We investigate both first-order and second-order particle system equations for modeling these dynamics, which mitigate over-smoothing and heterophily thus can capture complete interactions. The more stable second-order system permits deeper message passing. Furthermore, we enhance deterministic message passing with stochastic element to account for interaction uncertainties. We prove theoretically that our approach mitigates over-smoothing by maintaining a positive lower bound on the hypergraph Dirichlet energy during propagation and thus to enable hypergraph message passing to go deep. Empirically, our models demonstrate competitive performance on diverse real-world hypergraph node classification tasks, excelling on both homophilic and heterophilic datasets.', 'abstract_zh': '基于交互粒子系统的高阶关系高效建模：高阶图消息传递框架及其应用', 'title_zh': '粒子系统理论增强超图消息传递'}
{'arxiv_id': 'arXiv:2505.18494', 'title': 'FedHL: Federated Learning for Heterogeneous Low-Rank Adaptation via Unbiased Aggregation', 'authors': 'Zihao Peng, Jiandian Zeng, Boyuan Li, Guo Li, Shengbo Chen, Tian Wang', 'link': 'https://arxiv.org/abs/2505.18494', 'abstract': 'Federated Learning (FL) facilitates the fine-tuning of Foundation Models (FMs) using distributed data sources, with Low-Rank Adaptation (LoRA) gaining popularity due to its low communication costs and strong performance. While recent work acknowledges the benefits of heterogeneous LoRA in FL and introduces flexible algorithms to support its implementation, our theoretical analysis reveals a critical gap: existing methods lack formal convergence guarantees due to parameter truncation and biased gradient updates. Specifically, adapting client-specific LoRA ranks necessitates truncating global parameters, which introduces inherent truncation errors and leads to subsequent inaccurate gradient updates that accumulate over training rounds, ultimately degrading performance. To address the above issues, we propose \\textbf{FedHL}, a simple yet effective \\textbf{Fed}erated Learning framework tailored for \\textbf{H}eterogeneous \\textbf{L}oRA. By leveraging the full-rank global model as a calibrated aggregation basis, FedHL eliminates the direct truncation bias from initial alignment with client-specific ranks. Furthermore, we derive the theoretically optimal aggregation weights by minimizing the gradient drift term in the convergence upper bound. Our analysis shows that FedHL guarantees $\\mathcal{O}(1/\\sqrt{T})$ convergence rate, and experiments on multiple real-world datasets demonstrate a 1-3\\% improvement over several state-of-the-art methods.', 'abstract_zh': 'federated学习（FL）利用分布式数据源细调基础模型（FMs），低秩适应（LoRA）由于其低通信成本和强大性能而受到欢迎。尽管近期工作承认了异构LoRA在FL中的益处并引入了灵活的算法来支持其实现，我们的理论分析揭示了一个关键缺口：现有方法缺乏正式的收敛保证，由于参数截断和有偏梯度更新。具体来说，适应客户端特定的LoRA秩需要截断全局参数，这引入了固有的截断误差，并导致随后不准确的梯度更新在训练轮次中积累，最终导致性能下降。为了解决上述问题，我们提出了\\textbf{FedHL}，这是一个简单而有效的针对\\textbf{H}eterogeneous \\textbf{L}oRA的\\textbf{F}ederated学习框架。通过利用完整的全局模型作为校准聚合基础，FedHL消除了与客户端特定秩初始对齐时的直接截断偏差。此外，我们通过最小化收敛上界中的梯度漂移项来推导出理论上最优的聚合权重。我们的分析表明，FedHL保证了$\\mathcal{O}(1/\\sqrt{T})$的收敛速率，并且在多个真实世界数据集上的实验结果显示相比于几种最先进的方法，其性能提高了1-3%。', 'title_zh': 'FedHL: 异质低秩适应的无偏聚合联邦学习'}
{'arxiv_id': 'arXiv:2505.18461', 'title': 'Performance and Generalizability Impacts of Incorporating Geolocation into Deep Learning for Dynamic PM2.5 Estimation', 'authors': 'Morteza Karimzadeh, Zhongying Wang, James L. Crooks', 'link': 'https://arxiv.org/abs/2505.18461', 'abstract': 'Deep learning models have demonstrated success in geospatial applications, yet quantifying the role of geolocation information in enhancing model performance and geographic generalizability remains underexplored. A new generation of location encoders have emerged with the goal of capturing attributes present at any given location for downstream use in predictive modeling. Being a nascent area of research, their evaluation has remained largely limited to static tasks such as species distributions or average temperature mapping. In this paper, we discuss and quantify the impact of incorporating geolocation into deep learning for a real-world application domain that is characteristically dynamic (with fast temporal change) and spatially heterogeneous at high resolutions: estimating surface-level daily PM2.5 levels using remotely sensed and ground-level data. We build on a recently published deep learning-based PM2.5 estimation model that achieves state-of-the-art performance on data observed in the contiguous United States. We examine three approaches for incorporating geolocation: excluding geolocation as a baseline, using raw geographic coordinates, and leveraging pretrained location encoders. We evaluate each approach under within-region (WR) and out-of-region (OoR) evaluation scenarios. Aggregate performance metrics indicate that while naïve incorporation of raw geographic coordinates improves within-region performance by retaining the interpolative value of geographic location, it can hinder generalizability across regions. In contrast, pretrained location encoders like GeoCLIP enhance predictive performance and geographic generalizability for both WR and OoR scenarios. However, qualitative analysis reveals artifact patterns caused by high-degree basis functions and sparse upstream samples in certain areas, and ablation results indicate varying performance among location encoders...', 'abstract_zh': '深度学习模型在地理空间应用中取得了成功，但量化地理位置信息在增强模型性能和地理普适性方面的作用仍待深入探究。新兴的位置编码器旨在捕捉任何位置存在的属性，以便在下游预测建模中使用。作为研究的新兴领域，它们的评估主要局限于静态任务，如物种分布或平均温度地图。在本文中，我们探讨并量化了将地理位置纳入深度学习在具有动态特性和高分辨率空间异质性的实际应用领域中的影响：使用遥感和地面数据估算表面日均PM2.5水平。我们构建了一个基于深度学习的PM2.5估算模型，该模型在美国大陆观测数据上实现了 currentState-of-the-art 性能。我们探讨了三种地理位置纳入方法：排除地理位置作为基线、使用原始地理坐标以及利用预训练的位置编码器。我们在区域内部（WR）和区域外部（OoR）评估场景下评估了每种方法。综合性能指标表明，虽然原始地理坐标的大规模纳入在区域内部提升了性能，但可能削弱了跨区域的普适性。相比之下，预训练的位置编码器如GeoCLIP在区域内部和区域外部场景中均提升了预测性能和地理普适性。然而，定性分析揭示了由高阶基函数和上游稀疏样本引起的模式异常，并且消除实验表明不同位置编码器的性能各异……', 'title_zh': '将地理定位融入深度学习以动态估算PM2.5的影响：性能与泛化能力'}
{'arxiv_id': 'arXiv:2505.18442', 'title': 'Breaking Silos: Adaptive Model Fusion Unlocks Better Time Series Forecasting', 'authors': 'Zhining Liu, Ze Yang, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Yada Zhu, Hendrik Hamann, Jingrui He, Hanghang Tong', 'link': 'https://arxiv.org/abs/2505.18442', 'abstract': 'Time-series forecasting plays a critical role in many real-world applications. Although increasingly powerful models have been developed and achieved superior results on benchmark datasets, through a fine-grained sample-level inspection, we find that (i) no single model consistently outperforms others across different test samples, but instead (ii) each model excels in specific cases. These findings prompt us to explore how to adaptively leverage the distinct strengths of various forecasting models for different samples. We introduce TimeFuse, a framework for collective time-series forecasting with sample-level adaptive fusion of heterogeneous models. TimeFuse utilizes meta-features to characterize input time series and trains a learnable fusor to predict optimal model fusion weights for any given input. The fusor can leverage samples from diverse datasets for joint training, allowing it to adapt to a wide variety of temporal patterns and thus generalize to new inputs, even from unseen datasets. Extensive experiments demonstrate the effectiveness of TimeFuse in various long-/short-term forecasting tasks, achieving near-universal improvement over the state-of-the-art individual models. Code is available at this https URL.', 'abstract_zh': '时间序列预测在许多实际应用中扮演着关键角色。尽管不断发展的强大模型在基准数据集中取得了卓越的结果，但我们通过细粒度的样本级检查发现：(i) 没有一种模型能够一致地在所有测试样本上表现 superior，相反 (ii) 每种模型在特定情况下表现出色。这些发现促使我们探索如何根据不同的样本 adaptively 利用各种预测模型的独特优势。我们提出了 TimeFuse 框架，这是一种基于样本级异构模型自适应融合的时间序列集体预测框架。TimeFuse 利用元特征来表征输入时间序列，并训练一个可学习的融合器以预测任何给定输入的最佳模型融合权重。融合器可以从多样化的数据集中学习样本，从而适应各种时间模式，并能够泛化到新的输入，甚至是未见过的数据集。广泛实验证明，TimeFuse 在各种长期/短期预测任务中表现出色，实现了对先进个体模型的近似全面改进。代码可在该网址获取。', 'title_zh': '打破壁垒：自适应模型融合解锁更好的时间序列预测'}
{'arxiv_id': 'arXiv:2505.18434', 'title': 'TNG-CLIP:Training-Time Negation Data Generation for Negation Awareness of CLIP', 'authors': 'Yuliang Cai, Jesse Thomason, Mohammad Rostami', 'link': 'https://arxiv.org/abs/2505.18434', 'abstract': "Vision-language models (VLMs), such as CLIP, have demonstrated strong performance across a range of downstream tasks. However, CLIP is still limited in negation understanding: the ability to recognize the absence or exclusion of a concept. Existing methods address the problem by using a large language model (LLM) to generate large-scale data of image captions containing negation for further fine-tuning CLIP. However, these methods are both time- and compute-intensive, and their evaluations are typically restricted to image-text matching tasks. To expand the horizon, we (1) introduce a training-time negation data generation pipeline such that negation captions are generated during the training stage, which only increases 2.5% extra training time, and (2) we propose the first benchmark, Neg-TtoI, for evaluating text-to-image generation models on prompts containing negation, assessing model's ability to produce semantically accurate images. We show that our proposed method, TNG-CLIP, achieves SOTA performance on diverse negation benchmarks of image-to-text matching, text-to-image retrieval, and image generation.", 'abstract_zh': 'Vision-language模型（VLMs），如CLIP，在多种下游任务中展现出了强大的性能。然而，CLIP在否定理解方面 still有限：即识别概念的缺失或排除的能力。现有的方法通过使用大规模语言模型（LLM）生成包含否定的图片字幕数据集，进一步fine-tune CLIP来解决这个问题。然而，这些方法既耗费时间和计算资源，其评估通常限于图像-文本匹配任务。为进一步扩大研究范围，我们（1）提出了一种在训练阶段生成否定数据的训练流水线，使得否定字幕在训练期间生成，仅增加了2.5%的额外训练时间；（2）提出了第一个基准测试Neg-TtoI，用于评估文本到图像生成模型在包含否定的提示上的表现，评估模型生成语义准确图像的能力。我们展示了我们提出的方法TNG-CLIP在图像到文本匹配、文本到图像检索和图像生成等多样化否定基准上的SOTA性能。', 'title_zh': 'TNG-CLIP：训练时否定数据生成以增强CLIP的否定意识'}
{'arxiv_id': 'arXiv:2505.18424', 'title': "How We Won the ISLES'24 Challenge by Preprocessing", 'authors': 'Tianyi Ren, Juampablo E. Heras Rivera, Hitender Oswal, Yutong Pan, William Henry, Jacob Ruzevick, Mehmet Kurt', 'link': 'https://arxiv.org/abs/2505.18424', 'abstract': "Stroke is among the top three causes of death worldwide, and accurate identification of stroke lesion boundaries is critical for diagnosis and treatment. Supervised deep learning methods have emerged as the leading solution for stroke lesion segmentation but require large, diverse, and annotated datasets. The ISLES'24 challenge addresses this need by providing longitudinal stroke imaging data, including CT scans taken on arrival to the hospital and follow-up MRI taken 2-9 days from initial arrival, with annotations derived from follow-up MRI. Importantly, models submitted to the ISLES'24 challenge are evaluated using only CT inputs, requiring prediction of lesion progression that may not be visible in CT scans for segmentation. Our winning solution shows that a carefully designed preprocessing pipeline including deep-learning-based skull stripping and custom intensity windowing is beneficial for accurate segmentation. Combined with a standard large residual nnU-Net architecture for segmentation, this approach achieves a mean test Dice of 28.5 with a standard deviation of 21.27.", 'abstract_zh': "中风是全球前三大死亡原因，准确识别中风病变边界对于诊断和治疗至关重要。监督深度学习方法已成为中风病变分割的主导解决方案，但需要大量、多样且标注的数据集。ISLES'24挑战通过提供纵向中风影像数据来应对这一需求，包括患者到医院时拍摄的CT扫描和初次到达后2-9天的随访MRI，并根据随访MRI进行标注。重要的是，提交到ISLES'24挑战的模型仅使用CT输入进行评估，需要预测可能在CT扫描中不可见的病变进展以进行分割。我们的获胜解决方案表明，一个精心设计的预处理管道，包括基于深度学习的颅骨去除和自定义强度窗，对于准确分割有益。结合标准的大残差nnU-Net分割架构，此方法在测试集上的平均Dice值为28.5，标准差为21.27。", 'title_zh': "我们如何在ISLES'24挑战中获胜：通过预处理方法"}
{'arxiv_id': 'arXiv:2505.18407', 'title': 'KL-regularization Itself is Differentially Private in Bandits and RLHF', 'authors': 'Yizhou Zhang, Kishan Panaganti, Laixi Shi, Juba Ziani, Adam Wierman', 'link': 'https://arxiv.org/abs/2505.18407', 'abstract': "Differential Privacy (DP) provides a rigorous framework for privacy, ensuring the outputs of data-driven algorithms remain statistically indistinguishable across datasets that differ in a single entry. While guaranteeing DP generally requires explicitly injecting noise either to the algorithm itself or to its outputs, the intrinsic randomness of existing algorithms presents an opportunity to achieve DP ``for free''. In this work, we explore the role of regularization in achieving DP across three different decision-making problems: multi-armed bandits, linear contextual bandits, and reinforcement learning from human feedback (RLHF), in offline data settings. We show that adding KL-regularization to the learning objective (a common approach in optimization algorithms) makes the action sampled from the resulting stochastic policy itself differentially private. This offers a new route to privacy guarantees without additional noise injection, while also preserving the inherent advantage of regularization in enhancing performance.", 'abstract_zh': '差分隐私（DP）提供了一种严谨的隐私框架，确保在单个条目不同的数据集中，数据驱动算法的输出在统计上无法区分。虽然通常保证差分隐私需要显式地向算法本身或其输出中注入噪声，但现有算法固有的随机性为实现“免费”的差分隐私提供了机会。在本文中，我们探讨了正则化在三个不同的决策问题中实现差分隐私的作用：多臂 bandit 问题、线性上下文 bandit 问题以及从人类反馈强化学习（RLHF），在离线数据设置中的角色。我们证明，在学习目标中添加 KL-正则化（优化算法中的一种常见方法）会使从生成的随机策略中采样的动作本身成为差分隐私的。这一发现提供了一种新的路径，无需额外注入噪声即可获得隐私保证，同时也保留了正则化在提高性能方面的固有优势。', 'title_zh': 'KL-正则化本身在 bandits 和 RLHF 中具有差分隐私性'}
{'arxiv_id': 'arXiv:2505.18399', 'title': 'Taming Diffusion for Dataset Distillation with High Representativeness', 'authors': 'Lin Zhao, Yushu Wu, Xinru Jiang, Jianyang Gu, Yanzhi Wang, Xiaolin Xu, Pu Zhao, Xue Lin', 'link': 'https://arxiv.org/abs/2505.18399', 'abstract': 'Recent deep learning models demand larger datasets, driving the need for dataset distillation to create compact, cost-efficient datasets while maintaining performance. Due to the powerful image generation capability of diffusion, it has been introduced to this field for generating distilled images. In this paper, we systematically investigate issues present in current diffusion-based dataset distillation methods, including inaccurate distribution matching, distribution deviation with random noise, and separate sampling. Building on this, we propose D^3HR, a novel diffusion-based framework to generate distilled datasets with high representativeness. Specifically, we adopt DDIM inversion to map the latents of the full dataset from a low-normality latent domain to a high-normality Gaussian domain, preserving information and ensuring structural consistency to generate representative latents for the distilled dataset. Furthermore, we propose an efficient sampling scheme to better align the representative latents with the high-normality Gaussian distribution. Our comprehensive experiments demonstrate that D^3HR can achieve higher accuracy across different model architectures compared with state-of-the-art baselines in dataset distillation. Source code: this https URL.', 'abstract_zh': '近期的深度学习模型需要更大的数据集，推动了数据集蒸馏的需求，以创建紧凑且成本效益高的数据集同时保持性能。由于扩散模型强大的图像生成能力，它已被引入该领域用于生成蒸馏图像。在本文中，我们系统地研究了当前基于扩散的数据集蒸馏方法中存在的问题，包括不准确的分布匹配、随机噪声引起的功能偏差以及单独采样。在此基础上，我们提出了一种新颖的基于扩散的框架D^3HR，用于生成具有高代表性特征的数据集。具体而言，我们采用DDIM反向映射，将完整数据集的潜在变量从低常态潜在域映射到高常态高斯域，保留信息并确保结构一致性，以生成蒸馏数据集的代表性潜在变量。此外，我们提出了一种高效的采样方案以更好地将代表性潜在变量与高常态高斯分布对齐。我们的综合实验结果表明，与最新的基线方法相比，D^3HR在数据集蒸馏中能够获得更高的准确性。源代码：此链接。', 'title_zh': '控制扩散以提取高代表性数据集'}
{'arxiv_id': 'arXiv:2505.18398', 'title': 'Towards Anonymous Neural Network Inference', 'authors': 'Liao Peiyuan', 'link': 'https://arxiv.org/abs/2505.18398', 'abstract': 'We introduce funion, a system providing end-to-end sender-receiver unlinkability for neural network inference. By leveraging the Pigeonhole storage protocol and BACAP (blinding-and-capability) scheme from the Echomix anonymity system, funion inherits the provable security guarantees of modern mixnets. Users can anonymously store input tensors in pseudorandom storage locations, commission compute services to process them via the neural network, and retrieve results with no traceable connection between input and output parties. This store-compute-store paradigm masks both network traffic patterns and computational workload characteristics, while quantizing execution timing into public latency buckets. Our security analysis demonstrates that funion inherits the strong metadata privacy guarantees of Echomix under largely the same trust assumptions, while introducing acceptable overhead for production-scale workloads. Our work paves the way towards an accessible platform where users can submit fully anonymized inference queries to cloud services.', 'abstract_zh': '我们介绍了一种名为funion的系统，该系统提供了从发送者到接收者的端到端不可链接性，用于神经网络推理。通过利用Echomix匿名系统中的鸽洞存储协议和Pigeonhole存储方案以及BLINDING-AND-CAPABILITY (BACAP) 方案，funion继承了现代混洗网络的可证明安全保证。用户可以匿名地将输入张量存储在伪随机存储位置，委托计算服务通过神经网络处理这些输入张量，并获取结果时没有任何可追溯的链接关系。这一存储-计算-存储的范式遮掩了网络流量模式和计算工作负载的特征，同时将执行时间量化为公共延迟桶。我们的安全性分析表明，在很大程度上具有相同的信任假设下，funion继承了Echomix的强大的元数据隐私保障，同时为生产规模的工作负载引入了可接受的额外开销。我们的工作为用户提供了一种平台，使用户能够向云服务提交完全匿名化的推理查询。', 'title_zh': 'Towards Anonymous Neural Network Inference'}
{'arxiv_id': 'arXiv:2505.18397', 'title': 'An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems', 'authors': 'Fangqiao Tian, An Luo, Jin Du, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Jiawei Zhou, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Rui Zhang, Zirui Liu, Mingyi Hong, Jie Ding', 'link': 'https://arxiv.org/abs/2505.18397', 'abstract': 'Multi-agent AI systems (MAS) offer a promising framework for distributed intelligence, enabling collaborative reasoning, planning, and decision-making across autonomous agents. This paper provides a systematic outlook on the current opportunities and challenges of MAS, drawing insights from recent advances in large language models (LLMs), federated optimization, and human-AI interaction. We formalize key concepts including agent topology, coordination protocols, and shared objectives, and identify major risks such as dependency, misalignment, and vulnerabilities arising from training data overlap. Through a biologically inspired simulation and comprehensive theoretical framing, we highlight critical pathways for developing robust, scalable, and secure MAS in real-world settings.', 'abstract_zh': '多智能体AI系统（MAS）提供了分布式智能的有前途框架，使其能够支持自主智能体之间的协作推理、规划和决策。本文从大型语言模型（LLMs）、联邦优化和人机交互的最新进展中，系统地探讨了MAS当前的机会与挑战。我们正式化了关键概念，包括智能体拓扑结构、协调协议和共同目标，并识别出由训练数据重叠引起的主要风险，如依赖性、不一致性和脆弱性。通过生物启发的仿真和全面的理论框架，我们强调了在实际应用场景中开发稳健、可扩展和安全的MAS的关键路径。', 'title_zh': '多智能体AI系统的机会与挑战展望'}
{'arxiv_id': 'arXiv:2505.18392', 'title': 'Applications of Modular Co-Design for De Novo 3D Molecule Generation', 'authors': 'Danny Reidenbach, Filipp Nikitin, Olexandr Isayev, Saee Paliwal', 'link': 'https://arxiv.org/abs/2505.18392', 'abstract': "De novo 3D molecule generation is a pivotal task in drug discovery. However, many recent geometric generative models struggle to produce high-quality 3D structures, even if they maintain 2D validity and topological stability. To tackle this issue and enhance the learning of effective molecular generation dynamics, we present Megalodon-a family of scalable transformer models. These models are enhanced with basic equivariant layers and trained using a joint continuous and discrete denoising co-design objective. We assess Megalodon's performance on established molecule generation benchmarks and introduce new 3D structure benchmarks that evaluate a model's capability to generate realistic molecular structures, particularly focusing on energetics. We show that Megalodon achieves state-of-the-art results in 3D molecule generation, conditional structure generation, and structure energy benchmarks using diffusion and flow matching. Furthermore, doubling the number of parameters in Megalodon to 40M significantly enhances its performance, generating up to 49x more valid large molecules and achieving energy levels that are 2-10x lower than those of the best prior generative models.", 'abstract_zh': 'De novo 3D分子生成是药物发现中的关键任务。然而，许多近期的几何生成模型在生成高质量的3D结构方面存在困难，即使它们能够保持2D的有效性和拓扑稳定性。为了解决这一问题并增强有效的分子生成动力学的学习，我们提出了一种可扩展的变压器模型家族Megalodon。这些模型通过增强基本不变层并使用联合连续和离散去噪协同设计目标进行训练。我们评估了Megalodon在已建立的分子生成基准测试上的性能，并引入了新的3D结构基准测试来评价模型生成现实分子结构的能力，特别是重点在于能量方面。我们表明，Megalodon在3D分子生成、条件结构生成和结构能量基准测试中均达到了最先进的成果，使用扩散和流匹配。此外，将Megalodon的参数数量翻倍至40M显著提升了其性能，生成了高达49倍的有效大分子，并且能量水平比之前最好的生成模型低2-10倍。', 'title_zh': '基于模块化联合设计的从头三维分子生成应用'}
{'arxiv_id': 'arXiv:2505.18385', 'title': 'Human-Centered AI Communication in Co-Creativity: An Initial Framework and Insights', 'authors': 'Jeba Rezwana, Corey Ford', 'link': 'https://arxiv.org/abs/2505.18385', 'abstract': "Effective communication between AI and humans is essential for successful human-AI co-creation. However, many current co-creative AI systems lack effective communication, which limits their potential for collaboration. This paper presents the initial design of the Framework for AI Communication (FAICO) for co-creative AI, developed through a systematic review of 107 full-length papers. FAICO presents key aspects of AI communication and their impact on user experience, offering preliminary guidelines for designing human-centered AI communication. To improve the framework, we conducted a preliminary study with two focus groups involving skilled individuals in AI, HCI, and design. These sessions sought to understand participants' preferences for AI communication, gather their perceptions of the framework, collect feedback for refinement, and explore its use in co-creative domains like collaborative writing and design. Our findings reveal a preference for a human-AI feedback loop over linear communication and emphasize the importance of context in fostering mutual understanding. Based on these insights, we propose actionable strategies for applying FAICO in practice and future directions, marking the first step toward developing comprehensive guidelines for designing effective human-centered AI communication in co-creation.", 'abstract_zh': '有效的AI与人类沟通对于成功的人机共创至关重要。然而，当前许多共创型AI系统缺乏有效的沟通，这限制了它们的合作潜力。本文提出了基于系统性文献综述（分析了107篇完整论文）的人机共创AI沟通框架（FAICO）的初步设计。FAICO呈现了AI沟通的关键方面及其对用户体验的影响，并提供了以人为本的AI沟通初步设计指南。为改进框架，我们进行了初步研究，包括两个焦点小组，邀请了AI、人机交互（HCI）和设计领域的专业人士。这些会话旨在理解参与者对AI沟通的偏好，收集他们对框架的看法，收集改进的反馈，并探索其在共创领域（如协作写作和设计）的应用。研究发现显示了参与者对于人机双向反馈循环而非线性沟通的偏好，并强调了情境在促进相互理解中的重要性。基于这些见解，我们提出了在实践中应用FAICO的具体策略和未来方向，这是向开发全面的人效中心AI沟通设计指南迈出的第一步。', 'title_zh': '以人为本的AI通信在共创性中的作用：初步框架与见解'}
{'arxiv_id': 'arXiv:2505.18384', 'title': 'Dynamic Risk Assessments for Offensive Cybersecurity Agents', 'authors': 'Boyi Wei, Benedikt Stroebl, Jiacen Xu, Joie Zhang, Zhou Li, Peter Henderson', 'link': 'https://arxiv.org/abs/2505.18384', 'abstract': "Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.", 'abstract_zh': '基础模型正日益成为自主程序员，这使得它们有可能自动化危险的进攻性网络操作。当前的前沿模型审查探讨了这类代理的网络安全风险，但大多数审查未考虑到现实世界中对手所拥有的自由度。特别是，在有强大验证器和经济激励的情况下，进攻性网络安全代理可以通过潜在对手的迭代改进。我们认为评估应在网络安全的背景下考虑扩大的威胁模型，强调在固定计算预算内，对手在有状态和无状态环境中可能拥有的不同自由度。研究结果表明，即使计算预算相对较小（我们的研究中为8个H100 GPU小时），对手也能够在InterCode CTF中将代理的网络安全能力相对于基线提高超过40%，无需外部帮助。这些结果突显了需要动态评估代理的网络安全风险，以提供更具有代表性的风险图景。', 'title_zh': '动态风险评估方法研究：针对进攻性网络安全代理'}
{'arxiv_id': 'arXiv:2505.18377', 'title': 'SP2RINT: Spatially-Decoupled Physics-Inspired Progressive Inverse Optimization for Scalable, PDE-Constrained Meta-Optical Neural Network Training', 'authors': 'Pingchuan Ma, Ziang Yin, Qi Jing, Zhengqi Gao, Nicholas Gangi, Boyang Zhang, Tsung-Wei Huang, Zhaoran Huang, Duane S. Boning, Yu Yao, Jiaqi Gu', 'link': 'https://arxiv.org/abs/2505.18377', 'abstract': 'DONNs harness the physics of light propagation for efficient analog computation, with applications in AI and signal processing. Advances in nanophotonic fabrication and metasurface-based wavefront engineering have opened new pathways to realize high-capacity DONNs across various spectral regimes. Training such DONN systems to determine the metasurface structures remains challenging. Heuristic methods are fast but oversimplify metasurfaces modulation, often resulting in physically unrealizable designs and significant performance degradation. Simulation-in-the-loop training methods directly optimize a physically implementable metasurface using adjoint methods during end-to-end DONN training, but are inherently computationally prohibitive and this http URL address these limitations, we propose SP2RINT, a spatially decoupled, progressive training framework that formulates DONN training as a PDE-constrained learning problem. Metasurface responses are first relaxed into freely trainable transfer matrices with a banded structure. We then progressively enforce physical constraints by alternating between transfer matrix training and adjoint-based inverse design, avoiding per-iteration PDE solves while ensuring final physical realizability. To further reduce runtime, we introduce a physics-inspired, spatially decoupled inverse design strategy based on the natural locality of field interactions. This approach partitions the metasurface into independently solvable patches, enabling scalable and parallel inverse design with system-level calibration. Evaluated across diverse DONN training tasks, SP2RINT achieves digital-comparable accuracy while being 1825 times faster than simulation-in-the-loop approaches. By bridging the gap between abstract DONN models and implementable photonic hardware, SP2RINT enables scalable, high-performance training of physically realizable meta-optical neural systems.', 'abstract_zh': 'DONNs利用光传播的物理原理进行高效的类比计算，应用于AI和信号处理。 advancements in nanophotonic fabrication and metasurface-based wavefront engineering have opened new pathways to realize high-capacity DONNs across various spectral regimes. Training such DONN systems to determine the metasurface structures remains challenging.', 'title_zh': 'SP2RINT: 空间解耦物理启发的渐进逆优化方法及其在偏微分方程约束元光学神经网络训练中的应用'}
{'arxiv_id': 'arXiv:2505.18373', 'title': 'Next-token pretraining implies in-context learning', 'authors': 'Paul M. Riechers, Henry R. Bigelow, Eric A. Alt, Adam Shai', 'link': 'https://arxiv.org/abs/2505.18373', 'abstract': "We argue that in-context learning (ICL) predictably arises from standard self-supervised next-token pretraining, rather than being an exotic emergent property. This work establishes the foundational principles of this emergence by focusing on in-distribution ICL, demonstrating how models necessarily adapt to context when trained on token sequences, especially from non-ergodic sources. Our information-theoretic framework precisely predicts these in-distribution ICL dynamics (i.e., context-dependent loss reduction). We verify this with experiments using synthetic datasets of differing types of correlational structure, reproducing characteristic phenomena like phase transitions in training loss for induction head formation and power-law scaling of in-context loss. We further show that a model's in-context performance on any task is mathematically coupled to the ensemble of tasks seen in pretraining, offering a fundamental explanation, grounded in architecture- and modality-independent principles, for such inference-time learning.", 'abstract_zh': '我们 argue 认为基于上下文的学习（ICL）可预测地源自标准的自监督下一个词预训练，而不是一种奇特的 emergent 属性。本文通过关注同分布下的 ICL，建立了这种 emergence 的基础原理，展示了当模型在 token 序列上训练时，不可避免地会适应上下文，尤其是在从非遍历源数据训练时。我们的信息论框架精确地预测了这些同分布下的 ICL 动态（即上下文相关的损失减少）。我们使用不同类型相关结构的合成数据集进行了实验验证，重现了如归纳头形成过程中的训练损失相变现象和上下文损失的幂律缩放。进一步表明，模型在任何任务上的基于上下文的表现与预训练中看到的任务集合在数学上是有联系的，提供了从架构和模态无关的基本原理出发，对于这种推理时学习的本质解释。', 'title_zh': '下一个 tokens 预训练蕴含场内学习'}
{'arxiv_id': 'arXiv:2505.18366', 'title': 'Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems', 'authors': 'Hansa Meghwani, Amit Agarwal, Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Srikant Panda', 'link': 'https://arxiv.org/abs/2505.18366', 'abstract': "Enterprise search systems often struggle to retrieve accurate, domain-specific information due to semantic mismatches and overlapping terminologies. These issues can degrade the performance of downstream applications such as knowledge management, customer support, and retrieval-augmented generation agents. To address this challenge, we propose a scalable hard-negative mining framework tailored specifically for domain-specific enterprise data. Our approach dynamically selects semantically challenging but contextually irrelevant documents to enhance deployed re-ranking models.\nOur method integrates diverse embedding models, performs dimensionality reduction, and uniquely selects hard negatives, ensuring computational efficiency and semantic precision. Evaluation on our proprietary enterprise corpus (cloud services domain) demonstrates substantial improvements of 15\\% in MRR@3 and 19\\% in MRR@10 compared to state-of-the-art baselines and other negative sampling techniques. Further validation on public domain-specific datasets (FiQA, Climate Fever, TechQA) confirms our method's generalizability and readiness for real-world applications.", 'abstract_zh': '企业搜索引擎常常由于语义不匹配和术语重叠而难以检索到准确的领域特定信息，这会降低知识管理、客户支持和检索增强生成代理等下游应用的性能。为应对这一挑战，我们提出了一种针对特定领域的企业数据进行扩展的硬负样本挖掘框架。该方法动态选择语义上具有挑战性但与当前上下文无关的文档，以增强已部署的重排序模型。该方法整合了多种嵌入模型，进行了维度减少，并独特地选择了硬负样本，确保了计算效率和语义精度。在专属的企业语料库（云服务领域）上的评估结果显示，与最先进的基线方法和其他负样本技术相比，MRR@3 提高了 15%，MRR@10 提高了 19%。进一步在公开的特定领域数据集（FiQA、Climate Fever、TechQA）上的验证确认了该方法的通用性和在实际应用中的准备好状态。', 'title_zh': '企业系统中领域特定检索的硬负样本挖掘'}
{'arxiv_id': 'arXiv:2505.18363', 'title': 'SchemaGraphSQL: Efficient Schema Linking with Pathfinding Graph Algorithms for Text-to-SQL on Large-Scale Databases', 'authors': 'AmirHossein Safdarian, Milad Mohammadi, Ehsan Jahanbakhsh, Mona Shahamat Naderi, Heshaam Faili', 'link': 'https://arxiv.org/abs/2505.18363', 'abstract': 'Text-to-SQL systems translate natural language questions into executable SQL queries, and recent progress with large language models (LLMs) has driven substantial improvements in this task. Schema linking remains a critical component in Text-to-SQL systems, reducing prompt size for models with narrow context windows and sharpening model focus even when the entire schema fits. We present a zero-shot, training-free schema linking approach that first constructs a schema graph based on foreign key relations, then uses a single prompt to Gemini 2.5 Flash to extract source and destination tables from the user query, followed by applying classical path-finding algorithms and post-processing to identify the optimal sequence of tables and columns that should be joined, enabling the LLM to generate more accurate SQL queries. Despite being simple, cost-effective, and highly scalable, our method achieves state-of-the-art results on the BIRD benchmark, outperforming previous specialized, fine-tuned, and complex multi-step LLM-based approaches. We conduct detailed ablation studies to examine the precision-recall trade-off in our framework. Additionally, we evaluate the execution accuracy of our schema filtering method compared to other approaches across various model sizes.', 'abstract_zh': 'Text-to-SQL系统将自然语言问题转换为可执行的SQL查询，并且大型语言模型（LLMs）的进展在这一任务上带来了显著的改进。模式链接仍是Text-to-SQL系统中的关键组件，可减少具有狭窄上下文窗口的模型的提示大小，并即使在整个模式都适合的情况下也能使模型聚焦。我们提出了一种无需训练的零样本模式链接方法，首先基于外键关系构建模式图，然后使用单个提示将Gemini 2.5 Flash从用户查询中提取源表和目标表，接着应用经典路径查找算法和后处理来识别应连接的最佳表和列序列，从而使LLM能够生成更准确的SQL查询。尽管方法简单、成本效益高且高度可扩展，我们的方法在BIRD基准测试中达到了最先进的性能，超过了之前的专门化、微调和复杂的多步LLM基方法。我们进行了详尽的消融研究以检查我们框架中的查准率权衡，并评估了我们的模式过滤方法与其他方法在不同模型大小下的执行准确性。', 'title_zh': 'SchemaGraphSQL：高效的路径查找图算法在大规模数据库中实现文本到SQL的模式链接'}
{'arxiv_id': 'arXiv:2505.18362', 'title': 'Hamiltonian Theory and Computation of Optimal Probability Density Control in High Dimensions', 'authors': 'Nathan Gaby, Xiaojing Ye', 'link': 'https://arxiv.org/abs/2505.18362', 'abstract': 'We develop a general theoretical framework for optimal probability density control and propose a numerical algorithm that is scalable to solve the control problem in high dimensions. Specifically, we establish the Pontryagin Maximum Principle (PMP) for optimal density control and construct the Hamilton-Jacobi-Bellman (HJB) equation of the value functional through rigorous derivations without any concept from Wasserstein theory. To solve the density control problem numerically, we propose to use reduced-order models, such as deep neural networks (DNNs), to parameterize the control vector-field and the adjoint function, which allows us to tackle problems defined on high-dimensional state spaces. We also prove several convergence properties of the proposed algorithm. Numerical results demonstrate promising performances of our algorithm on a variety of density control problems with obstacles and nonlinear interaction challenges in high dimensions.', 'abstract_zh': '我们建立了一般最优概率密度控制的理论框架，并提出了一种可扩展的数值算法以解决高维控制问题。具体来说，我们通过严谨的推导建立了最优密度控制的庞特里亚金最大原则（PMP），并通过无 Wasserstein 理论概念的推导构建了值函数的哈密尔顿-雅可比-贝尔曼（HJB）方程。为了数值求解密度控制问题，我们提出使用降阶模型，如深度神经网络（DNNs），来参数化控制向量场和伴随函数，从而能够处理定义在高维状态空间上的问题。我们还证明了所提算法的若干收敛性质。数值结果表明，我们的算法在多种含有障碍物和非线性交互挑战的高维密度控制问题上具有出色的表现。', 'title_zh': '哈密尔顿理论与高维最优概率密度控制的计算方法'}
{'arxiv_id': 'arXiv:2505.18344', 'title': 'Sample Complexity of Diffusion Model Training Without Empirical Risk Minimizer Access', 'authors': 'Mudit Gaur, Prashant Trivedi, Sasidhar Kunapuli, Amrit Singh Bedi, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2505.18344', 'abstract': 'Diffusion models have demonstrated state-of-the-art performance across vision, language, and scientific domains. Despite their empirical success, prior theoretical analyses of the sample complexity suffer from poor scaling with input data dimension or rely on unrealistic assumptions such as access to exact empirical risk minimizers. In this work, we provide a principled analysis of score estimation, establishing a sample complexity bound of $\\widetilde{\\mathcal{O}}(\\epsilon^{-6})$. Our approach leverages a structured decomposition of the score estimation error into statistical, approximation, and optimization errors, enabling us to eliminate the exponential dependence on neural network parameters that arises in prior analyses. It is the first such result which achieves sample complexity bounds without assuming access to the empirical risk minimizer of score function estimation loss.', 'abstract_zh': '扩散模型在视觉、语言和科学领域中展现出了最先进的性能。尽管它们在实践中取得了成功，之前的样本复杂性理论分析要么不适用于高维输入数据，要么依赖于获取精确的经验风险最小化解这样不现实的假设。在本文中，我们提供了一种原则性的分析方法，建立了样本复杂性界 $\\widetilde{\\mathcal{O}}(\\epsilon^{-6})$。我们的方法利用了评分估计误差的结构分解，将其分为统计误差、逼近误差和优化误差，从而能够消除前人在分析中出现的对神经网络参数的指数依赖。这是首次在不假设能够访问评分函数估计损失的经验风险最小化解的情况下，获得样本复杂性界的结果。', 'title_zh': '无经验风险最小化扩散模型训练的样本复杂度研究'}
{'arxiv_id': 'arXiv:2505.18323', 'title': 'Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation', 'authors': 'Nicolas Küchler, Ivan Petrov, Conrad Grobler, Ilia Shumailov', 'link': 'https://arxiv.org/abs/2505.18323', 'abstract': 'For nearly a decade the academic community has investigated backdoors in neural networks, primarily focusing on classification tasks where adversaries manipulate the model prediction. While demonstrably malicious, the immediate real-world impact of such prediction-altering attacks has remained unclear. In this paper we introduce a novel and significantly more potent class of backdoors that builds upon recent advancements in architectural backdoors. We demonstrate how these backdoors can be specifically engineered to exploit batched inference, a common technique for hardware utilization, enabling large-scale user data manipulation and theft. By targeting the batching process, these architectural backdoors facilitate information leakage between concurrent user requests and allow attackers to fully control model responses directed at other users within the same batch. In other words, an attacker who can change the model architecture can set and steal model inputs and outputs of other users within the same batch. We show that such attacks are not only feasible but also alarmingly effective, can be readily injected into prevalent model architectures, and represent a truly malicious threat to user privacy and system integrity. Critically, to counteract this new class of vulnerabilities, we propose a deterministic mitigation strategy that provides formal guarantees against this new attack vector, unlike prior work that relied on Large Language Models to find the backdoors. Our mitigation strategy employs a novel Information Flow Control mechanism that analyzes the model graph and proves non-interference between different user inputs within the same batch. Using our mitigation strategy we perform a large scale analysis of models hosted through Hugging Face and find over 200 models that introduce (unintended) information leakage between batch entries due to the use of dynamic quantization.', 'abstract_zh': '近乎十年来，学术界一直在研究神经网络中的后门，主要关注攻击者操控模型预测的分类任务。尽管这些预测篡改攻击显然具有恶意性，但它们在现实世界中的直接影响仍然不够清晰。在本文中，我们引入了一种新型且更为有效的后门类别，该类别基于最近在架构后门方面的进展。我们展示了如何以特定的方式设计这些后门，使其能够利用批量推理，这是一种常见的硬件利用技术，从而实现大规模的用户数据操控和窃取。通过针对批量处理过程，这些架构后门使信息在并发用户请求之间泄漏成为可能，并允许攻击者完全控制同一批量内其他用户收到的模型响应。换句话说，能够改变模型架构的攻击者可以设定并窃取同一批量内其他用户的模型输入和输出。我们证明了此类攻击不仅可行，而且令人警觉地有效，可以轻松注入到普遍使用的模型架构中，并且代表了用户隐私和系统完整性的一种真正恶意威胁。关键的是，为了应对这一新类漏洞，我们提出了一个确定性的缓解策略，该策略提供了对该新攻击向量的正式保证，而不同于之前依赖大型语言模型来发现后门的方法。我们的缓解策略采用了一种新型的信息流控制机制，分析模型图，并证明同一批量内不同用户输入之间的非干涉性。使用我们的缓解策略，我们对通过Hugging Face托管的大量模型进行了分析，发现超过200个模型因使用动态量化而引入了（无意的）批量条目间的信息泄漏。', 'title_zh': '建筑设计中的批次内数据窃取和模型推理操纵后门'}
{'arxiv_id': 'arXiv:2505.18287', 'title': 'Efficient Algorithms for Electing Successive Committees', 'authors': 'Pallavi Jain, Andrzej Kaczmarczyk', 'link': 'https://arxiv.org/abs/2505.18287', 'abstract': 'In a recently introduced model of successive committee elections (Bredereck et al., AAAI-20) for a given set of ordinal or approval preferences one aims to find a sequence of a given length of "best" same-size committees such that each candidate is a member of a limited number of consecutive committees. However, the practical usability of this model remains limited, as the described task turns out to be NP-hard for most selection criteria already for seeking committees of size three. Non-trivial or somewhat efficient algorithms for these cases are lacking too. Motivated by a desire to unlock the full potential of the described temporal model of committee elections, we devise (parameterized) algorithms that effectively solve the mentioned hard cases in realistic scenarios of a moderate number of candidates or of a limited time horizon.', 'abstract_zh': '近日引入的连续委员会选举模型（Bredereck et al., AAAI-20）：为给定的序贯或批准偏好集，目标是在每个候选人仅属于有限数量的连续委员会的前提下，找到一个给定长度的最佳同规模委员会序列。然而，由于大多数选择标准在寻找大小为三的委员会时该项任务被认为NP难，未能找到有效或相对高效的算法。为实现上述时间模型在委员会选举中的全部潜力，我们设计了参数化算法，在候选人数适度或时间范围有限的现实场景中有效解决上述难题。', 'title_zh': '高效算法选举继任委员会'}
{'arxiv_id': 'arXiv:2505.18284', 'title': 'Tube Loss based Deep Networks For Improving the Probabilistic Forecasting of Wind Speed', 'authors': 'Pritam Anand, Aadesh Minz, Asish Joel', 'link': 'https://arxiv.org/abs/2505.18284', 'abstract': 'Uncertainty Quantification (UQ) in wind speed forecasting is a critical challenge in wind power production due to the inherently volatile nature of wind. By quantifying the associated risks and returns, UQ supports more effective decision-making for grid operations and participation in the electricity market. In this paper, we design a sequence of deep learning based probabilistic forecasting methods by using the Tube loss function for wind speed forecasting. The Tube loss function is a simple and model agnostic Prediction Interval (PI) estimation approach and can obtain the narrow PI with asymptotical coverage guarantees without any distribution assumption. Our deep probabilistic forecasting models effectively incorporate popular architectures such as LSTM, GRU, and TCN within the Tube loss framework. We further design a simple yet effective heuristic for tuning the $\\delta$ parameter of the Tube loss function so that our deep forecasting models obtain the narrower PI without compromising its calibration ability. We have considered three wind datasets, containing the hourly recording of the wind speed, collected from three distinct location namely Jaisalmer, Los Angeles and San Fransico. Our numerical results demonstrate that the proposed deep forecasting models produce more reliable and narrower PIs compared to recently developed probabilistic wind forecasting methods.', 'abstract_zh': '风速预测中的不确定性量化（UQ）是由于风能本身具有固有的波动性，在风力发电生产中是一个关键挑战。通过量化相关的风险和回报，不确定性量化支持了更有效的电网运营决策和电力市场的参与。在本文中，我们设计了一系列基于深度学习的概率预测方法，使用Tube损失函数进行风速预测。Tube损失函数是一种简单且模型无关的预测区间（PI）估计方法，可以在没有任何分布假设的情况下获得具有渐近覆盖保证的窄PI。我们的深度概率预测模型在Tube损失框架内有效地整合了流行的架构，如LSTM、GRU和TCN。我们还设计了一个简单而有效的启发式方法来调整Tube损失函数中的$\\delta$参数，从而使我们的深度预测模型获得更窄的预测区间同时不牺牲其校准能力。我们考虑了三个风数据集，分别来自杰亚斯梅尔、洛杉矶和旧金山，每小时记录风速。我们的数值结果表明，所提出的深度预测模型相比于最近开发的概率风速预测方法，能产生更可靠和更窄的预测区间。', 'title_zh': '基于Tube Loss的深层网络模型改进风速概率预测'}
{'arxiv_id': 'arXiv:2505.18282', 'title': 'Towards a Quantum-classical Augmented Network', 'authors': 'Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam', 'link': 'https://arxiv.org/abs/2505.18282', 'abstract': 'In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of existing networks and adopt currently feasible quantum technologies, the next step is to augment classical networks with quantum devices, properties, and phenomena. To achieve this, we propose a change in the structure of the HTTP protocol such that it can carry both quantum and classical payload. This work lays the foundation for dividing one single network packet into classical and quantum payloads depending on the privacy needs. We implement logistic regression, CNN, LSTM, and BiLSTM models to classify the privacy label for outgoing communications. This enables reduced utilization of quantum resources allowing for a more efficient secure quantum network design. Experimental results using the proposed methods are presented.', 'abstract_zh': '近十年来，已建立了一些小型量子密钥分发网络。然而，大型量子网络的部署取决于量子中继器、量子信道、量子存储和量子网络协议的发展。为了提高现有网络的安全性并采用当前可行的量子技术，下一步是在经典网络中引入量子设备、属性和现象。为此，我们提议改变HTTP协议的结构，使其能够同时承载量子和经典负载。本项工作为根据隐私需求将单个网络包分为经典和量子负载奠定了基础。我们实现了逻辑回归、CNN、LSTM和BiLSTM模型来分类出站通信的隐私标签，这使得量子资源的使用减少，从而能够更高效地设计安全的量子网络。使用所提出的方法进行了实验，展示了实验结果。', 'title_zh': '面向量子-经典增强网络'}
{'arxiv_id': 'arXiv:2505.18280', 'title': 'Feature Preserving Shrinkage on Bayesian Neural Networks via the R2D2 Prior', 'authors': 'Tsai Hor Chan, Dora Yan Zhang, Guosheng Yin, Lequan Yu', 'link': 'https://arxiv.org/abs/2505.18280', 'abstract': 'Bayesian neural networks (BNNs) treat neural network weights as random variables, which aim to provide posterior uncertainty estimates and avoid overfitting by performing inference on the posterior weights. However, the selection of appropriate prior distributions remains a challenging task, and BNNs may suffer from catastrophic inflated variance or poor predictive performance when poor choices are made for the priors. Existing BNN designs apply different priors to weights, while the behaviours of these priors make it difficult to sufficiently shrink noisy signals or they are prone to overshrinking important signals in the weights. To alleviate this problem, we propose a novel R2D2-Net, which imposes the R^2-induced Dirichlet Decomposition (R2D2) prior to the BNN weights. The R2D2-Net can effectively shrink irrelevant coefficients towards zero, while preventing key features from over-shrinkage. To approximate the posterior distribution of weights more accurately, we further propose a variational Gibbs inference algorithm that combines the Gibbs updating procedure and gradient-based optimization. This strategy enhances stability and consistency in estimation when the variational objective involving the shrinkage parameters is non-convex. We also analyze the evidence lower bound (ELBO) and the posterior concentration rates from a theoretical perspective. Experiments on both natural and medical image classification and uncertainty estimation tasks demonstrate satisfactory performance of our method.', 'abstract_zh': 'R2D2-Net：基于R²诱导狄利克雷分解先验的贝叶斯神经网络', 'title_zh': '贝叶斯神经网络中基于R2D2先验的特征保真收缩'}
{'arxiv_id': 'arXiv:2505.18266', 'title': 'Uncovering a Universal Abstract Algorithm for Modular Addition in Neural Networks', 'authors': 'Gavin McCracken, Gabriela Moisescu-Pareja, Vincent Letourneau, Doina Precup, Jonathan Love', 'link': 'https://arxiv.org/abs/2505.18266', 'abstract': 'We propose a testable universality hypothesis, asserting that seemingly disparate neural network solutions observed in the simple task of modular addition are unified under a common abstract algorithm. While prior work interpreted variations in neuron-level representations as evidence for distinct algorithms, we demonstrate - through multi-level analyses spanning neurons, neuron clusters, and entire networks - that multilayer perceptrons and transformers universally implement the abstract algorithm we call the approximate Chinese Remainder Theorem. Crucially, we introduce approximate cosets and show that neurons activate exclusively on them. Furthermore, our theory works for deep neural networks (DNNs). It predicts that universally learned solutions in DNNs with trainable embeddings or more than one hidden layer require only O(log n) features, a result we empirically confirm. This work thus provides the first theory-backed interpretation of multilayer networks solving modular addition. It advances generalizable interpretability and opens a testable universality hypothesis for group multiplication beyond modular addition.', 'abstract_zh': '我们提出一个可验证的普遍性假设，认为在简单模块加法任务中观察到的看似不同的神经网络解决方案其实统一在一种共同的抽象算法之下。此前的工作通过神经元层面表示的差异解释为不同的算法，而我们通过涵盖神经元、神经元簇和整个网络的多层级分析表明，多层感知机和变换器普遍实现了我们所称的近似中国剩余定理的抽象算法。关键的是，我们引入了近似陪集的概念，并证明了神经元仅在这些陪集上激活。此外，我们的理论适用于深度神经网络。我们预测，在具有可训练嵌入或多个隐藏层的深度神经网络中，普遍学习的解决方案只需要O(log n)个特征，这一结果我们通过实证研究得到了验证。因此，本工作提供了第一个关于多层网络解决模加法的理论支持解释，推进了可泛化的可解释性，并为超越模加法的群乘操作提出一个可验证的普遍性假设。', 'title_zh': '揭示神经网络中模块化加法的通用抽象算法'}
{'arxiv_id': 'arXiv:2505.18247', 'title': 'MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning', 'authors': 'Kunal Sawarkar, Shivam R. Solanki, Abhilasha Mangal', 'link': 'https://arxiv.org/abs/2505.18247', 'abstract': "Despite the widespread exploration of Retrieval-Augmented Generation (RAG), its deployment in enterprises for domain-specific datasets remains limited due to poor answer accuracy. These corpora, often shielded behind firewalls in private enterprise knowledge bases, having complex, domain-specific terminology, rarely seen by LLMs during pre-training; exhibit significant semantic variability across domains (like networking, military, or legal, etc.), or even within a single domain like medicine, and thus result in poor context precision for RAG systems. Currently, in such situations, fine-tuning or RAG with fine-tuning is attempted, but these approaches are slow, expensive, and lack generalization for accuracy as the new domain-specific data emerges. We propose an approach for Enterprise Search that focuses on enhancing the retriever for a domain-specific corpus through hybrid query indexes and metadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata generation pipeline using key concepts, topics, and acronyms, and then creates a metadata-enriched hybrid index with boosted search queries. This approach avoids overfitting and generalizes effectively across domains. On the PubMedQA benchmark for the biomedical domain, the proposed method achieves 82% retrieval accuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results without fine-tuning and sets a new benchmark for zero-shot results while outperforming much larger models like GPT3.5. The results are even comparable to the best fine-tuned models on this dataset, and we further demonstrate the robustness and scalability of the approach by evaluating it on other Q&A datasets like SQuAD, NQ etc.", 'abstract_zh': '基于元数据增强的混合查询融合生成检索增强生成方法在企业搜索中的应用', 'title_zh': 'MetaGen 混合 RAG：无需微调的领域特定问答更高准确性'}
{'arxiv_id': 'arXiv:2505.18243', 'title': 'ZeroML: A Next Generation AutoML Language', 'authors': 'Monirul Islam Mahmud', 'link': 'https://arxiv.org/abs/2505.18243', 'abstract': 'ZeroML is a new generation programming language for AutoML to drive the ML pipeline in a compiled and multi-paradigm way, with a pure functional core. Meeting the shortcomings introduced by Python, R, or Julia such as slow-running time, brittle pipelines or high dependency cost ZeroML brings the Microservices-based architecture adding the modular, reusable pieces such as DataCleaner, FeatureEngineer or ModelSelector. As a native multithread and memory-aware search optimized toolkit, and with one command deployability ability, ZeroML ensures non-coders and ML professionals to create high-accuracy models super fast and in a more reproducible way. The verbosity of the language ensures that when it comes to dropping into the backend, the code we will be creating is extremely clear but the level of repetition and boilerplate required when developing on the front end is now removed.', 'abstract_zh': 'ZeroML是一种基于微服务架构的新一代编程语言，用于以编译和多范式方式驱动ML管道，具有纯粹函数核心。零编译Python、R或Julia等语言引入的运行效率低、管道脆弱或依赖成本高问题，ZeroML提供了模块化、可重用的数据清洗器（DataCleaner）、特征工程师（FeatureEngineer）或模型选择器（ModelSelector）等组件。作为一种原生多线程和内存感知的搜索优化工具包，具有单命令部署能力，ZeroML确保非编码人员和ML专业人士能够快速创建高精度模型，并以更可再现的方式进行。语言的简洁性确保了在后端创建的代码极其清晰，而在前端开发中所需的重复和样板代码现在已被去除。', 'title_zh': 'ZeroML: 下一代自动机器学习语言'}
{'arxiv_id': 'arXiv:2505.18241', 'title': 'Intent Classification on Low-Resource Languages with Query Similarity Search', 'authors': 'Arjun Bhalla, Qi Huang', 'link': 'https://arxiv.org/abs/2505.18241', 'abstract': 'Intent classification is an important component of a functional Information Retrieval ecosystem. Many current approaches to intent classification, typically framed as a classification problem, can be problematic as intents are often hard to define and thus data can be difficult and expensive to annotate. The problem is exacerbated when we need to extend the intent classification system to support multiple and in particular low-resource languages. To address this, we propose casting intent classification as a query similarity search problem - we use previous example queries to define an intent, and a query similarity method to classify an incoming query based on the labels of its most similar queries in latent space. With the proposed approach, we are able to achieve reasonable intent classification performance for queries in low-resource languages in a zero-shot setting.', 'abstract_zh': '意图分类是功能型信息检索生态系统中的一个重要组成部分。当前许多意图分类的方法通常被构架为分类问题，但这种方法可能存在问题，因为意图往往很难定义，因此标注数据具有挑战性和成本高昂。当需要将意图分类系统扩展以支持多种语言，尤其是低资源语言时，这一问题更为严重。为解决这一问题，我们建议将意图分类重新构架为查询相似性搜索问题——使用先前的示例查询来定义意图，并使用查询相似性方法根据入coming查询在潜在空间中最相似查询的标签对其进行分类。通过提出的这种方法，在零样本设置下，我们能够实现对低资源语言查询的合理意图分类性能。', 'title_zh': '低资源语言中的意图分类与查询相似性搜索'}
{'arxiv_id': 'arXiv:2505.18236', 'title': 'From Bias to Accountability: How the EU AI Act Confronts Challenges in European GeoAI Auditing', 'authors': 'Natalia Matuszczyk, Craig R. Barnes, Rohit Gupta, Bulent Ozel, Aniket Mitra', 'link': 'https://arxiv.org/abs/2505.18236', 'abstract': "Bias in geospatial artificial intelligence (GeoAI) models has been documented, yet the evidence is scattered across narrowly focused studies. We synthesize this fragmented literature to provide a concise overview of bias in GeoAI and examine how the EU's Artificial Intelligence Act (EU AI Act) shapes audit obligations. We discuss recurring bias mechanisms, including representation, algorithmic and aggregation bias, and map them to specific provisions of the EU AI Act. By applying the Act's high-risk criteria, we demonstrate that widely deployed GeoAI applications qualify as high-risk systems. We then present examples of recent audits along with an outline of practical methods for detecting bias. As far as we know, this study represents the first integration of GeoAI bias evidence into the EU AI Act context, by identifying high-risk GeoAI systems and mapping bias mechanisms to the Act's Articles. Although the analysis is exploratory, it suggests that even well-curated European datasets should employ routine bias audits before 2027, when the AI Act's high-risk provisions take full effect.", 'abstract_zh': '地理人工智能（GeoAI）模型中的偏差已有所记录，但证据散布在专门研究中。我们将这些分散的文献综合起来，提供GeoAI偏差的简洁综述，并探讨欧盟人工智能法案（EU AI Act）如何影响审计义务。我们讨论重复出现的偏差机制，包括表示偏差、算法偏差和聚合偏差，并将它们映射到EU AI Act的具体条款中。通过应用该法案的高风险标准，我们证明广泛部署的GeoAI应用符合高风险系统的要求。然后，我们提供了最近审计的例子，并概述了检测偏差的实际方法。据我们所知，本研究可能是首次将GeoAI偏差证据纳入EU AI Act的背景中，通过识别高风险GeoAI系统并将偏差机制映射到法案的各条文。尽管分析具有探索性，但它表明即使精心策划的欧洲数据集也应在2027年欧盟人工智能法案的高风险条款完全生效之前进行常规偏差审计。', 'title_zh': '从偏见到问责：欧盟AI法案在欧洲地景人工智能审计中应对挑战的方式'}
{'arxiv_id': 'arXiv:2505.18234', 'title': 'A Robust PPO-optimized Tabular Transformer Framework for Intrusion Detection in Industrial IoT Systems', 'authors': 'Yuanya She', 'link': 'https://arxiv.org/abs/2505.18234', 'abstract': 'In this paper, we propose a robust and reinforcement-learning-enhanced network intrusion detection system (NIDS) designed for class-imbalanced and few-shot attack scenarios in Industrial Internet of Things (IIoT) environments. Our model integrates a TabTransformer for effective tabular feature representation with Proximal Policy Optimization (PPO) to optimize classification decisions via policy learning. Evaluated on the TON\\textunderscore IoT benchmark, our method achieves a macro F1-score of 97.73\\% and accuracy of 98.85\\%. Remarkably, even on extremely rare classes like man-in-the-middle (MITM), our model achieves an F1-score of 88.79\\%, showcasing strong robustness and few-shot detection capabilities. Extensive ablation experiments confirm the complementary roles of TabTransformer and PPO in mitigating class imbalance and improving generalization. These results highlight the potential of combining transformer-based tabular learning with reinforcement learning for real-world NIDS applications.', 'abstract_zh': '一种增强学习增强的鲁棒网络入侵检测系统：适用于工业互联网中的类别不平衡和少样本攻击场景', 'title_zh': '一种针对工业物联网系统入侵检测的鲁棒PPO优化表结构变换器框架'}
{'arxiv_id': 'arXiv:2505.18233', 'title': 'POSTER: A Multi-Signal Model for Detecting Evasive Smishing', 'authors': 'Shaghayegh Hosseinpour, Sanchari Das', 'link': 'https://arxiv.org/abs/2505.18233', 'abstract': 'Smishing, or SMS-based phishing, poses an increasing threat to mobile users by mimicking legitimate communications through culturally adapted, concise, and deceptive messages, which can result in the loss of sensitive data or financial resources. In such, we present a multi-channel smishing detection model that combines country-specific semantic tagging, structural pattern tagging, character-level stylistic cues, and contextual phrase embeddings. We curated and relabeled over 84,000 messages across five datasets, including 24,086 smishing samples. Our unified architecture achieves 97.89% accuracy, an F1 score of 0.963, and an AUC of 99.73%, outperforming single-stream models by capturing diverse linguistic and structural cues. This work demonstrates the effectiveness of multi-signal learning in robust and region-aware phishing.', 'abstract_zh': '基于短信的诈骗（Smishing）通过模仿经过文化适应的、简洁的和有欺骗性的信息，对移动用户构成日益严重的威胁，可能导致敏感数据或财务资源的损失。为此，我们提出了一种多渠道的smishing检测模型，结合了国家特定的语义标签、结构模式标签、字符级风格暗示和上下文短语嵌入。我们整理并重新标记了来自五个数据集的超过84,000条消息，其中包括24,086条smishing样本。我们的统一架构达到了97.89%的准确率，F1分数为0.963，AUC为99.73%，比单一渠道模型更好地捕捉到了多元的语言和结构线索。本工作展示了多信号学习在鲁棒和区域意识诈骗检测中的有效性。', 'title_zh': 'Poster: 基于多信号模型的规避式 Smishing 检测方法'}
{'arxiv_id': 'arXiv:2505.18230', 'title': 'Follow the Energy, Find the Path: Riemannian Metrics from Energy-Based Models', 'authors': 'Louis Béthune, David Vigouroux, Yilun Du, Rufin VanRullen, Thomas Serre, Victor Boutin', 'link': 'https://arxiv.org/abs/2505.18230', 'abstract': "What is the shortest path between two data points lying in a high-dimensional space? While the answer is trivial in Euclidean geometry, it becomes significantly more complex when the data lies on a curved manifold -- requiring a Riemannian metric to describe the space's local curvature. Estimating such a metric, however, remains a major challenge in high dimensions.\nIn this work, we propose a method for deriving Riemannian metrics directly from pretrained Energy-Based Models (EBMs) -- a class of generative models that assign low energy to high-density regions. These metrics define spatially varying distances, enabling the computation of geodesics -- shortest paths that follow the data manifold's intrinsic geometry. We introduce two novel metrics derived from EBMs and show that they produce geodesics that remain closer to the data manifold and exhibit lower curvature distortion, as measured by alignment with ground-truth trajectories. We evaluate our approach on increasingly complex datasets: synthetic datasets with known data density, rotated character images with interpretable geometry, and high-resolution natural images embedded in a pretrained VAE latent space.\nOur results show that EBM-derived metrics consistently outperform established baselines, especially in high-dimensional settings. Our work is the first to derive Riemannian metrics from EBMs, enabling data-aware geodesics and unlocking scalable, geometry-driven learning for generative modeling and simulation.", 'abstract_zh': '高维空问中两个数据点之间的最短路径是什么？在欧几里得几何中，这个问题的答案无疑是直接的，但当数据位于一个弯曲流形上时，问题变得复杂得多——需要使用黎曼度量来描述空间的局部曲率。然而，在高维空间中估计这样的度量仍然是一个重大挑战。\n\n在本文中，我们提出了一种直接从预训练的能量基础模型（EBMs）中推导黎曼度量的方法——这一类生成模型将低能量分配给高密度区域。这些度量定义了空间变化的距离，使我们可以计算符合数据流形内在几何结构的测地线——即最短路径。我们引入了从EBMs推导出的两个新颖度量，并展示了它们产生的测地线更接近数据流形且曲率失真较低，通过与真实轨迹的对齐度进行测量。我们使用从简单到复杂的数据集对其方法进行了评估：已知数据密度的合成数据集、具有可解释几何结构的旋转字符图像，以及嵌入在预训练VAE潜在空间中的高分辨率自然图像。\n\n我们的结果表明，从EBMs推导出的度量在高维设置中始终优于现有的基准方法。我们的工作是首次从EBMs中推导出黎曼度量，实现了数据感知的测地线，并为生成建模和模拟开启了基于几何的学习和可扩展性。', 'title_zh': '顺着能量找路径：来自能量模型的黎曼度量'}
{'arxiv_id': 'arXiv:2505.18222', 'title': 'A Domain Ontology for Modeling the Book of Purification in Islam', 'authors': 'Hessa Alawwad', 'link': 'https://arxiv.org/abs/2505.18222', 'abstract': 'This paper aims to address a gap in major Islamic topics by developing an ontology for the Book of Purification in Islam. Many authoritative Islamic texts begin with the Book of Purification, as it is essential for performing prayer (the second pillar of Islam after Shahadah, the profession of faith) and other religious duties such as Umrah and Hajj.\nThe ontology development strategy followed six key steps: (1) domain identification, (2) knowledge acquisition, (3) conceptualization, (4) classification, (5) integration and implementation, and (6) ontology generation. This paper includes examples of the constructed tables and classifications.\nThe focus is on the design and analysis phases, as technical implementation is beyond the scope of this study. However, an initial implementation is provided to illustrate the steps of the proposed strategy.\nThe developed ontology ensures reusability by formally defining and encoding the key concepts, attributes, and relationships related to the Book of Purification. This structured representation is intended to support knowledge sharing and reuse.', 'abstract_zh': '本文旨在通过为《 purification 经》开发本体来填补伊斯兰主要主题中的研究空白。许多权威的伊斯兰文本都以《 purification 经》开头，因为它对于礼拜（伊斯兰的第二个支柱，其次是认主独 Almighty ）以及其他宗教职责如朝觐和小朝觐是必不可少的。\n\n本体开发策略遵循了六个关键步骤：（1）领域识别，（2）知识获取，（3）概念化，（4）分类，（5）集成与实施，以及（6）本体生成。本文包括所构建的表格和分类的示例。\n\n重点在于设计和分析阶段，因为技术实现超出了本研究的范围。然而，提供了一个初始实现来说明所提议策略的步骤。\n\n开发的本体通过正式定义和编码与《 purification 经》相关的关键概念、属性和关系确保了可重用性。这种结构化表示旨在支持知识的共享和重用。', 'title_zh': '清真寺书籍的领域本体建模'}
{'arxiv_id': 'arXiv:2505.18221', 'title': 'Evidence-Grounded Multimodal Misinformation Detection with Attention-Based GNNs', 'authors': 'Sharad Duwal, Mir Nafis Sharear Shopnil, Abhishek Tyagi, Adiba Mahbub Proma', 'link': 'https://arxiv.org/abs/2505.18221', 'abstract': 'Multimodal out-of-context (OOC) misinformation is misinformation that repurposes real images with unrelated or misleading captions. Detecting such misinformation is challenging because it requires resolving the context of the claim before checking for misinformation. Many current methods, including LLMs and LVLMs, do not perform this contextualization step. LLMs hallucinate in absence of context or parametric knowledge. In this work, we propose a graph-based method that evaluates the consistency between the image and the caption by constructing two graph representations: an evidence graph, derived from online textual evidence, and a claim graph, from the claim in the caption. Using graph neural networks (GNNs) to encode and compare these representations, our framework then evaluates the truthfulness of image-caption pairs. We create datasets for our graph-based method, evaluate and compare our baseline model against popular LLMs on the misinformation detection task. Our method scores $93.05\\%$ detection accuracy on the evaluation set and outperforms the second-best performing method (an LLM) by $2.82\\%$, making a case for smaller and task-specific methods.', 'abstract_zh': '多模态脱靶虚假信息是指将实际图片与不相关或误导性的 caption 重新利用的情况。检测这种虚假信息具有挑战性，因为它要求在验证虚假信息之前解决声明的上下文。当前许多方法，包括大语言模型（LLMs）和大型视觉语言模型（LVLMs），未执行这一上下文化步骤。大语言模型在缺乏上下文或参数知识的情况下会编造信息。在本文中，我们提出了一种基于图的方法，通过构建两种图表示：来源于在线文本证据的证据图和来源于 caption 中声明的声明图，来评估图片和 caption 之间的一致性。利用图神经网络（GNNs）对这些表示进行编码和比较，我们的框架随后评估图像- caption 对的真实性。我们为基于图的方法创建了数据集，并在虚假信息检测任务上将基线模型与流行的 LLMs 进行评估和比较。我们的方法在验证集上的检测准确率为 93.05%，比第二优方法（一种大语言模型）高出 2.82%，证明了更小且针对特定任务的方法的有效性。', 'title_zh': '基于证据的多模态虚假信息检测：注意力机制下的图神经网络'}
{'arxiv_id': 'arXiv:2505.18216', 'title': 'Data Mining-Based Techniques for Software Fault Localization', 'authors': 'Peggy Cellier, Mireille Ducassé, Sébastien Ferré, Olivier Ridoux, W. Eric Wong', 'link': 'https://arxiv.org/abs/2505.18216', 'abstract': 'This chapter illustrates the basic concepts of fault localization using a data mining technique. It utilizes the Trityp program to illustrate the general method. Formal concept analysis and association rule are two well-known methods for symbolic data mining. In their original inception, they both consider data in the form of an object-attribute table. In their original inception, they both consider data in the form of an object-attribute table. The chapter considers a debugging process in which a program is tested against different test cases. Two attributes, PASS and FAIL, represent the issue of the test case. The chapter extends the analysis of data mining for fault localization for the multiple fault situations. It addresses how data mining can be further applied to fault localization for GUI components. Unlike traditional software, GUI test cases are usually event sequences, and each individual event has a unique corresponding event handler.', 'abstract_zh': '本章使用数据挖掘技术阐述故障定位的基本概念，并通过Trityp程序示例说明一般方法。形式概念分析和关联规则是两种著名的符号数据挖掘方法，在最初的概念中，它们都考虑数据以对象-属性表的形式存在。本章考虑了一个软件测试过程，该过程在不同的测试案例下测试程序。PASS和FAIL两个属性代表测试案例的问题。本章扩展了对故障定位的数据挖掘分析，以应对多故障情况，并探讨数据挖掘如何进一步应用于GUI组件的故障定位。与传统软件不同，GUI测试案例通常是一系列事件序列，每个单独的事件都有一个独特的相应事件处理程序。', 'title_zh': '基于数据挖掘的软件故障定位技术'}
{'arxiv_id': 'arXiv:2505.18213', 'title': 'AIDRIN 2.0: A Framework to Assess Data Readiness for AI', 'authors': 'Kaveen Hiniduma, Dylan Ryan, Suren Byna, Jean Luca Bez, Ravi Madduri', 'link': 'https://arxiv.org/abs/2505.18213', 'abstract': "AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.", 'abstract_zh': 'AI数据准备性检查器(AIDRIN)框架：通过用户界面改进和隐私保护联邦学习框架集成提升AI应用数据准备性', 'title_zh': 'AIDRIN 2.0: 评估数据就绪度以供AI使用的方法框架'}
{'arxiv_id': 'arXiv:2505.18200', 'title': 'CrossRF: A Domain-Invariant Deep Learning Approach for RF Fingerprinting', 'authors': 'Fahrettin Emin Tiras, Hayriye Serra Altinoluk', 'link': 'https://arxiv.org/abs/2505.18200', 'abstract': "Radio Frequency (RF) fingerprinting offers a promising approach for drone identification and security, although it suffers from significant performance degradation when operating on different transmission channels. This paper presents CrossRF, a domain-invariant deep learning approach that addresses the problem of cross-channel RF fingerprinting for Unmanned Aerial Vehicle (UAV) identification. Our approach aims to minimize the domain gap between different RF channels by using adversarial learning to train a more robust model that maintains consistent identification performance despite channel variations. We validate our approach using the UAVSig dataset, comprising real-world over-the-air RF signals from identical drone models operating across several frequency channels, ensuring that the findings correspond to real-world scenarios. The experimental results show CrossRF's efficiency, achieving up to 99.03% accuracy when adapting from Channel 3 to Channel 4, compared to only 26.39% using conventional methods. The model maintains robust performance in more difficult multi-channel scenarios (87.57% accuracy adapting from Channels 1,3 to 2,4) and achieves 89.45% accuracy with 0.9 precision for controller classification. These results confirm CrossRF's ability to significantly reduce performance degradation due to cross-channel variations while maintaining high identification accuracy with minimal training data requirements, making it particularly suitable for practical drone security applications.", 'abstract_zh': 'CrossRF：一种针对无人机跨频道RF指纹识别的领域不变深度学习方法', 'title_zh': 'CrossRF：一种用于RF指纹识别的领域不变深度学习方法'}
{'arxiv_id': 'arXiv:2505.18191', 'title': 'SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference', 'authors': 'Jonathan Dan, Amirhossein Shahbazinia, Christodoulos Kechris, David Atienza', 'link': 'https://arxiv.org/abs/2505.18191', 'abstract': 'Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigorously assess algorithm performance, we organized a challenge using a private dataset of continuous EEG recordings from 65 subjects (4,360 hours). Expert neurophysiologists annotated the data, providing ground truth for seizure events. Participants were required to detect seizure onset and duration, with evaluation based on event-based metrics, including sensitivity, precision, F1-score, and false positives per day. The SzCORE framework ensured standardized evaluation. The primary ranking criterion was the event-based F1-score, reflecting clinical relevance by balancing sensitivity and false positives. The challenge received 30 submissions from 19 teams, with 28 algorithms evaluated. Results revealed wide variability in performance, with a top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing difficulty of seizure detection. The challenge also revealed a gap between reported performance and real-world evaluation, emphasizing the importance of rigorous benchmarking. Compared to previous challenges and commercial systems, the best-performing algorithm in this contest showed improved performance. Importantly, the challenge platform now supports continuous benchmarking, enabling reproducible research, integration of new datasets, and clinical evaluation of seizure detection algorithms using a standardized framework.', 'abstract_zh': '可靠地从长时间EEG中自动检测癫痫发作仍然是一个挑战，当前的机器学习模型往往无法在不同患者或临床环境中泛化。手动EEG审查仍是临床标准，强调了需要稳健的模型和标准化评估的重要性。为了严格评估算法性能，我们使用包含65名受试者（4,360小时）连续EEG记录的私有数据集组织了一项挑战。专家神经生理学家对数据进行了标注，提供了癫痫发作事件的ground truth。参与者需检测癫痫发作起始和持续时间，评估基于事件指标，包括灵敏度、精确度、F1分数和每日误报数。SzCORE框架确保了标准化评估。首要的排名标准是事件相关的F1分数，反映了临床相关性，平衡了灵敏度和误报。本次挑战收到了19支队伍的30份提交，共评估了28个算法。结果表明，性能存在显著差异，最高F1分数为43%（灵敏度37%，精确度45%），突显了癫痫发作检测的持续难度。挑战还揭示了报告性能与实际评估之间的差距，强调了严格基准测试的重要性。与以往挑战和商用系统相比，本次比赛表现最好的算法显示出改进的性能。重要的是，挑战平台现在支持持续基准测试，促进了可重复研究，整合新数据集，并使用标准化框架评估癫痫发作检测算法的临床性能。', 'title_zh': 'SzCORE作为基准：2025年AI在癫痫和神经疾病会议上关于癫痫检测挑战的报告'}
{'arxiv_id': 'arXiv:2505.18190', 'title': 'PhySense: Sensor Placement Optimization for Accurate Physics Sensing', 'authors': 'Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long', 'link': 'https://arxiv.org/abs/2505.18190', 'abstract': 'Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. \\correct{Leveraging the reconstruction feedback, }the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. \\correct{We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees.} Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered.', 'abstract_zh': 'Physics Sensing via Synergistic Two-Stage Framework for Joint Reconstruction and Optimal Sensor Placement', 'title_zh': 'PhySense: 物理传感的传感器放置优化'}
{'arxiv_id': 'arXiv:2505.18188', 'title': 'Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization', 'authors': 'Beck LaBash, Shahriar Khushrushahi, Fabian Ruehle', 'link': 'https://arxiv.org/abs/2505.18188', 'abstract': 'We propose a two-stage deep learning framework for the inverse design of rectangular patch antennas. Our approach leverages generative modeling to learn a latent representation of antenna frequency response curves and conditions a subsequent generative model on these responses to produce feasible antenna geometries. We further demonstrate that leveraging search and optimization techniques at test-time improves the accuracy of the generated designs and enables consideration of auxiliary objectives such as manufacturability. Our approach generalizes naturally to different design criteria, and can be easily adapted to more complex geometric design spaces.', 'abstract_zh': '我们提出了一种两阶段深度学习框架用于矩形(patch)贴片天线的逆向设计。该方法利用生成模型学习天线频率响应曲线的潜在表示，并在这些响应的基础上条件化后续的生成模型以生成可行的天线几何结构。此外，我们在测试时利用搜索和优化技术可以提高生成设计的准确性，同时考虑制备性等辅助目标。该方法自然地适用于不同的设计标准，并且可以轻松适应更复杂的几何设计空间。', 'title_zh': '基于测试时优化的矩形补片天线生成逆向设计改进'}
{'arxiv_id': 'arXiv:2505.18181', 'title': '2DNMRGym: An Annotated Experimental Dataset for Atom-Level Molecular Representation Learning in 2D NMR via Surrogate Supervision', 'authors': 'Yunrui Li, Hao Xu, Pengyu Hong', 'link': 'https://arxiv.org/abs/2505.18181', 'abstract': "Two-dimensional (2D) Nuclear Magnetic Resonance (NMR) spectroscopy, particularly Heteronuclear Single Quantum Coherence (HSQC) spectroscopy, plays a critical role in elucidating molecular structures, interactions, and electronic properties. However, accurately interpreting 2D NMR data remains labor-intensive and error-prone, requiring highly trained domain experts, especially for complex molecules. Machine Learning (ML) holds significant potential in 2D NMR analysis by learning molecular representations and recognizing complex patterns from data. However, progress has been limited by the lack of large-scale and high-quality annotated datasets. In this work, we introduce 2DNMRGym, the first annotated experimental dataset designed for ML-based molecular representation learning in 2D NMR. It includes over 22,000 HSQC spectra, along with the corresponding molecular graphs and SMILES strings. Uniquely, 2DNMRGym adopts a surrogate supervision setup: models are trained using algorithm-generated annotations derived from a previously validated method and evaluated on a held-out set of human-annotated gold-standard labels. This enables rigorous assessment of a model's ability to generalize from imperfect supervision to expert-level interpretation. We provide benchmark results using a series of 2D and 3D GNN and GNN transformer models, establishing a strong foundation for future work. 2DNMRGym supports scalable model training and introduces a chemically meaningful benchmark for evaluating atom-level molecular representations in NMR-guided structural tasks. Our data and code is open-source and available on Huggingface and Github.", 'abstract_zh': '两维（2D）核磁共振（NMR）光谱，特别是异核单量子相干（HSQC）光谱，在阐明分子结构、相互作用和电子性质方面起到关键作用。然而，准确解读2D NMR数据依然劳动密集且容易出错，需要高度训练的专业专家，尤其是对复杂分子而言。机器学习（ML）在通过学习分子表示和从数据中识别复杂模式方面为2D NMR分析提供了巨大潜力。然而，进展受限于缺乏大规模和高质量的注释数据集。本文介绍2DNMRGym，这是第一个为基于机器学习的分子表示学习设计的2D NMR注释实验数据集，包含了超过22,000张HSQC谱图，以及相应的分子图和SMILES字符串。2DNMRGym采用代用监督设置：模型使用算法生成的注释进行训练，这些注释源自之前验证的方法，并在保留了人工注释权威标准标签的一组数据上进行评估。这使得可以严格评估模型从不完美的监督到专家级解释的能力。我们使用一系列2D和3D图神经网络及图神经网络变换模型提供了基准结果，为未来工作奠定了坚实基础。2DNMRGym支持可扩展的模型训练，并引入了基于NMR导向结构任务的具有化学意义的基准，用于评估原子级分子表示。我们的数据和代码是开源的，可在Huggingface和Github上获取。', 'title_zh': '2DNMRGym：一种用于二维核磁共振中原子级分子表示学习的标注实验数据集及其代理监督方法'}
{'arxiv_id': 'arXiv:2505.18179', 'title': 'GAIA: A Foundation Model for Operational Atmospheric Dynamics', 'authors': 'Ata Akbari Asanjan, Olivia Alexander, Tom Berg, Clara Zhang, Matt Yang, Jad Makki, Disha Shidham, Srija Chakraborty, William Bender, Stephen Peng, Arun Ravindran, Olivier Raiman, David Potere, David Bell', 'link': 'https://arxiv.org/abs/2505.18179', 'abstract': 'We present the GAIA (Geospatial Artificial Intelligence for Atmospheres) Foundation Model, a novel model that combines masked autoencoders (MAE) and self-DIstillation with NO labels (DINO) for analyzing global atmospheric patterns in satellite imagery. By integrating these complementary self-supervised learning approaches, our model simultaneously captures both local features and global dependencies. We address two critical challenges in satellite data analysis: reconstructing missing regions and estimating precipitation patterns as our first downstream tasks. The model demonstrates superior temporal pattern capture compared to standard MAE approaches, while maintaining robust performance in downstream tasks. Our experimental results show strong gap-filling capabilities across varying mask ratios and accurate precipitation estimation with limited training data, achieving a false alarm ratio of 0.088 and structural similarity of 0.881. This work represents an advancement in self-supervised learning for atmospheric science, providing a foundation for improved weather monitoring and climate analysis. The trained model weights and accompanying code are publicly available as open-source on Hugging Face here: this https URL.', 'abstract_zh': '我们提出了一种新颖的Geospatial Artificial Intelligence for Atmospheres (GAIA) 基础模型，该模型结合了掩码自动编码器（MAE）和未标记自蒸馏（DINO）方法，用于分析卫星图像中的全球大气模式。通过整合这些互补的自监督学习方法，我们的模型能够同时捕捉局部特征和全局依赖关系。我们解决了卫星数据分析中的两个关键挑战：重构缺失区域和估算降水模式，作为我们首先的下游任务。与标准的MAE方法相比，该模型在时间序列模式捕捉方面表现出色，同时在下游任务中保持了稳健的性能。实验结果表明，在不同掩码比率下具有较强的插补能力，并且在有限训练数据的情况下实现了准确的降水估计，假警报率为0.088，结构相似度为0.881。这项工作代表了大气科学中自监督学习的进步，为改进天气监测和气候分析提供了基础。经过训练的模型权重和配套代码在Hugging Face上公开：this https URL。', 'title_zh': 'GAIA：大气动态运行基础模型'}
{'arxiv_id': 'arXiv:2505.18177', 'title': 'FedGRec: Dynamic Spatio-Temporal Federated Graph Learning for Secure and Efficient Cross-Border Recommendations', 'authors': 'Zhizhong Tan, Jiexin Zheng, Xingxing Yang, Chi Zhang, Weiping Deng, Wenyong Wang', 'link': 'https://arxiv.org/abs/2505.18177', 'abstract': 'Due to the highly sensitive nature of certain data in cross-border sharing, collaborative cross-border recommendations and data sharing are often subject to stringent privacy protection regulations, resulting in insufficient data for model training. Consequently, achieving efficient cross-border business recommendations while ensuring privacy security poses a significant challenge. Although federated learning has demonstrated broad potential in collaborative training without exposing raw data, most existing federated learning-based GNN training methods still rely on federated averaging strategies, which perform suboptimally on highly heterogeneous graph data. To address this issue, we propose FedGRec, a privacy-preserving federated graph learning method for cross-border recommendations. FedGRec captures user preferences from distributed multi-domain data to enhance recommendation performance across all domains without privacy leakage. Specifically, FedGRec leverages collaborative signals from local subgraphs associated with users or items to enrich their representation learning. Additionally, it employs dynamic spatiotemporal modeling to integrate global and local user preferences in real time based on business recommendation states, thereby deriving the final representations of target users and candidate items. By automatically filtering relevant behaviors, FedGRec effectively mitigates noise interference from unreliable neighbors. Furthermore, through a personalized federated aggregation strategy, FedGRec adapts global preferences to heterogeneous domain data, enabling collaborative learning of user preferences across multiple domains. Extensive experiments on three datasets demonstrate that FedGRec consistently outperforms competitive single-domain and cross-domain baselines while effectively preserving data privacy in cross-border recommendations.', 'abstract_zh': '跨border推荐中的隐私保护图联邦学习方法：FedGRec', 'title_zh': 'FedGRec：基于动态时空联邦图学习的跨边境安全高效推荐'}
{'arxiv_id': 'arXiv:2505.18175', 'title': 'Evaluation in EEG Emotion Recognition: State-of-the-Art Review and Unified Framework', 'authors': 'Natia Kukhilava, Tatia Tsmindashvili, Rapael Kalandadze, Anchit Gupta, Sofio Katamadze, François Brémond, Laura M. Ferrari, Philipp Müller, Benedikt Emanuel Wirth', 'link': 'https://arxiv.org/abs/2505.18175', 'abstract': "Electroencephalography-based Emotion Recognition (EEG-ER) has become a growing research area in recent years. Analyzing 216 papers published between 2018 and 2023, we uncover that the field lacks a unified evaluation protocol, which is essential to fairly define the state of the art, compare new approaches and to track the field's progress. We report the main inconsistencies between the used evaluation protocols, which are related to ground truth definition, evaluation metric selection, data splitting types (e.g., subject-dependent or subject-independent) and the use of different datasets. Capitalizing on this state-of-the-art research, we propose a unified evaluation protocol, EEGain (this https URL), which enables an easy and efficient evaluation of new methods and datasets. EEGain is a novel open source software framework, offering the capability to compare - and thus define - state-of-the-art results. EEGain includes standardized methods for data pre-processing, data splitting, evaluation metrics, and the ability to load the six most relevant datasets (i.e., AMIGOS, DEAP, DREAMER, MAHNOB-HCI, SEED, SEED-IV) in EEG-ER with only a single line of code. In addition, we have assessed and validated EEGain using these six datasets on the four most common publicly available methods (EEGNet, DeepConvNet, ShallowConvNet, TSception). This is a significant step to make research on EEG-ER more reproducible and comparable, thereby accelerating the overall progress of the field.", 'abstract_zh': '基于脑电图的情感识别（EEG-ER）已成为近年来的研究热点。分析2018年至2023年发表的216篇论文，我们发现该领域缺乏统一的评估协议，这阻碍了对最新技术水平的公正定义、新方法的比较以及领域进展的跟踪。我们报告了使用的评估协议中主要存在的不一致性，这些不一致性涉及 ground truth 定义、评价指标选择、数据分割类型（如被试依存或被试独立）以及不同数据集的使用。在此基础上，我们提出了一种统一的评估协议——EEGain（https://github.com/EEGAI-PL/EEGain），它能够简化并提高新方法和数据集的评估效率和效果。EEGain 是一种新型开源软件框架，提供比较和定义最新技术水平的能力。该框架包括标准化的数据预处理方法、数据分割方法、评价指标方法，并且仅需一行代码即可加载 EEG-ER 中最相关的六个多模态数据集（即 AMIGOS、DEAP、DREAMER、MAHNOB-HCI、SEED、SEED-IV）。此外，我们使用这六个数据集和四种最常见的公开方法（EEGNet、DeepConvNet、ShallowConvNet、TSception）评估并验证了EEGain，这为提高 EEG-ER 研究的可重复性和可比性、加速该领域的整体进展迈出了重要一步。', 'title_zh': 'EEG情绪识别的评估：现有研究综述与统一框架'}
{'arxiv_id': 'arXiv:2505.18174', 'title': 'NMCSE: Noise-Robust Multi-Modal Coupling Signal Estimation Method via Optimal Transport for Cardiovascular Disease Detection', 'authors': 'Zhixin li, Peihong Zhang, Rui Sang, Yuxuan Liu, Shengchen Li', 'link': 'https://arxiv.org/abs/2505.18174', 'abstract': 'Electrocardiogram (ECG) and Phonocardiogram (PCG) signals are linked by a latent coupling signal representing the electrical-to-mechanical cardiac transformation. While valuable for cardiovascular disease (CVD) detection, this coupling signal is traditionally estimated using deconvolution methods that amplify noise, limiting clinical utility. In this paper, we propose Noise-Robust Multi-Modal Coupling Signal Estimation (NMCSE), which reformulates the problem as distribution matching via optimal transport theory. By jointly optimizing amplitude and temporal alignment, NMCSE mitigates noise amplification without additional preprocessing. Integrated with our Temporal-Spatial Feature Extraction network, NMCSE enables robust multi-modal CVD detection. Experiments on the PhysioNet 2016 dataset with realistic hospital noise demonstrate that NMCSE reduces estimation errors by approximately 30% in Mean Squared Error while maintaining higher Pearson Correlation Coefficients across all tested signal-to-noise ratios. Our approach achieves 97.38% accuracy and 0.98 AUC in CVD detection, outperforming state-of-the-art methods and demonstrating robust performance for real-world clinical applications.', 'abstract_zh': '心电图（ECG）和心脏音图（PCG）信号通过一个潜在耦合信号联系，该信号代表了电气到机械心脏转换。虽然这对心血管疾病（CVD）的检测有价值，但传统上通过去卷积方法估计此耦合信号会放大噪声，限制了其临床应用。本文提出了一种噪声鲁棒多模态耦合信号估计方法（NMCSE），将其重新表述为通过最优传输理论进行分布匹配。通过同时优化幅度和时间对齐，NMCSE减轻了噪声放大而不需额外预处理。结合我们的时域-空域特征提取网络，NMCSE实现了稳健的多模态CVD检测。实验结果表明，NMCSE在均方误差中将估计误差降低了约30%，同时在所有测试信噪比下保持了更高的皮尔森相关系数。我们的方法在CVD检测中的准确率为97.38%，AUC值为0.98，优于现有方法，并在实际临床应用中表现出稳健性能。', 'title_zh': 'NMCSE: 基于最优传输的抗噪声多模态耦合信号估计方法在心血管疾病检测中的应用'}
{'arxiv_id': 'arXiv:2406.17441', 'title': 'A Matrix Product State Model for Simultaneous Classification and Generation', 'authors': 'Alex Mossi, Bojan Žunkovic, Kyriakos Flouris', 'link': 'https://arxiv.org/abs/2406.17441', 'abstract': 'Quantum machine learning (QML) is a rapidly expanding field that merges the principles of quantum computing with the techniques of machine learning. One of the powerful mathematical frameworks in this domain is tensor networks. These networks are used to approximate high-order tensors by contracting tensors with lower ranks. Initially developed for simulating quantum systems, tensor networks have become integral to quantum computing and, by extension, to QML. Drawing inspiration from these quantum methods, specifically the Matrix Product States (MPS), we apply them in a classical machine learning setting. Their ability to efficiently represent and manipulate complex, high-dimensional data makes them effective in a supervised learning framework. Here, we present an MPS model, in which the MPS functions as both a classifier and a generator. The dual functionality of this novel MPS model permits a strategy that enhances the traditional training of supervised MPS models. This framework is inspired by generative adversarial networks and is geared towards generating more realistic samples by reducing outliers. In addition, our contributions offer insights into the mechanics of tensor network methods for generation tasks. Specifically, we discuss alternative embedding functions and a new sampling method from non-normalized MPSs.', 'abstract_zh': '量子机器学习（QML）是一个迅速扩张的领域，将量子计算的原则与机器学习的技术相结合。该领域中一个强大的数学框架是张量网络。这些网络用于通过合同低秩张量来近似高阶张量。最初用于模拟量子系统，张量网络已成为量子计算和由此扩展到量子机器学习的核心组成部分。受这些量子方法的启发，特别是在矩阵乘积状态（MPS）中，我们将其应用于经典的机器学习设置中。它们能够有效表示和操作复杂的高维数据，使其在监督学习框架中非常有效。在这里，我们提出了一种MPS模型，在该模型中，MPS既作为分类器又作为生成器发挥作用。这一新型MPS模型的双重功能允许一种策略，以增强传统的监督MPS模型训练。该框架借鉴了生成对抗网络的理念，旨在通过降低离群值来生成更真实的样本。此外，我们的贡献还提供了关于生成任务中张量网络方法机理的见解，特别是讨论了替代嵌入函数和非规范化MPS的新采样方法。', 'title_zh': '矩阵乘积态模型同时进行分类和生成'}
