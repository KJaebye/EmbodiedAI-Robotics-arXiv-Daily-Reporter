{'arxiv_id': 'arXiv:2505.20290', 'title': 'EgoZero: Robot Learning from Smart Glasses', 'authors': 'Vincent Liu, Ademi Adeniji, Haotian Zhan, Raunaq Bhirangi, Pieter Abbeel, Lerrel Pinto', 'link': 'https://arxiv.org/abs/2505.20290', 'abstract': 'Despite recent progress in general purpose robotics, robot policies still lag far behind basic human capabilities in the real world. Humans interact constantly with the physical world, yet this rich data resource remains largely untapped in robot learning. We propose EgoZero, a minimal system that learns robust manipulation policies from human demonstrations captured with Project Aria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1) extraction of complete, robot-executable actions from in-the-wild, egocentric, human demonstrations, (2) compression of human visual observations into morphology-agnostic state representations, and (3) closed-loop policy learning that generalizes morphologically, spatially, and semantically. We deploy EgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot transfer with 70% success rate over 7 manipulation tasks and only 20 minutes of data collection per task. Our results suggest that in-the-wild human data can serve as a scalable foundation for real-world robot learning - paving the way toward a future of abundant, diverse, and naturalistic training data for robots. Code and videos are available at this https URL.', 'abstract_zh': '尽管通用机器人领域取得了近期进展，但机器人策略在现实世界中仍然远不及人类的基本能力。人类不断与物理世界互动，而这种丰富的数据资源在机器人学习中尚未得到充分利用。我们提出EgoZero，一个最小化的系统，该系统通过Project Aria智能眼镜捕获的人类示范学习稳健的操纵策略，并且不需要任何机器人数据。EgoZero能够实现：(1)从自然环境中的第一人称人类示范中提取完整的、可由机器人执行的动作，(2)将人类视觉观察压缩为形态无关的状态表示，以及(3)实现跨形态、空间和语义的闭环策略学习。我们在Franka Panda夹爪机器人上部署EgoZero策略，并在仅每任务收集20分钟数据的情况下，在7个操纵任务中实现70%的零样本转移成功率。我们的结果表明，自然环境中的真人数据可以作为现实世界中机器人学习的可扩展基础——从而为机器人的丰富、多样和自然训练数据铺平道路。代码和视频可在以下链接获取。', 'title_zh': 'EgoZero: 机器人从智能眼镜学习'}
{'arxiv_id': 'arXiv:2505.20223', 'title': 'Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects', 'authors': 'Yixin Cui, Haotian Lin, Shuo Yang, Yixiao Wang, Yanjun Huang, Hong Chen', 'link': 'https://arxiv.org/abs/2505.20223', 'abstract': "The rapid evolution of large language models in natural language processing has substantially elevated their semantic understanding and logical reasoning capabilities. Such proficiencies have been leveraged in autonomous driving systems, contributing to significant improvements in system performance. Models such as OpenAI o1 and DeepSeek-R1, leverage Chain-of-Thought (CoT) reasoning, an advanced cognitive method that simulates human thinking processes, demonstrating remarkable reasoning capabilities in complex tasks. By structuring complex driving scenarios within a systematic reasoning framework, this approach has emerged as a prominent research focus in autonomous driving, substantially improving the system's ability to handle challenging cases. This paper investigates how CoT methods improve the reasoning abilities of autonomous driving models. Based on a comprehensive literature review, we present a systematic analysis of the motivations, methodologies, challenges, and future research directions of CoT in autonomous driving. Furthermore, we propose the insight of combining CoT with self-learning to facilitate self-evolution in driving systems. To ensure the relevance and timeliness of this study, we have compiled a dynamic repository of literature and open-source projects, diligently updated to incorporate forefront developments. The repository is publicly available at this https URL.", 'abstract_zh': '大规模语言模型在自然语言处理领域的迅速进化显著提升了其语义理解和逻辑推理能力。这些能力已在自主驾驶系统中得以利用，推动了系统性能的大幅提高。例如，OpenAI的o1和DeepSeek-R1模型利用链式思考（CoT）推理，这是一种先进的认知方法，模拟人类思维过程，展现出在复杂任务中出色的能力。通过在系统推理框架中结构化复杂驾驶场景，这种方法已成为自主驾驶领域的一个重要研究方向，大幅提升了系统处理复杂情况的能力。本文探讨了CoT方法如何提高自主驾驶模型的推理能力。基于全面的文献回顾，我们提供了一种系统分析CoT在自主驾驶中的动机、方法、挑战及未来研究方向的分析。此外，我们提出了将CoT与自我学习结合以促进驾驶系统自我进化的见解。为确保本研究的相关性和时效性，我们整理了一个动态文献库和开源项目库，并不断更新以纳入最新进展。该库可在以下链接访问：https://this.url', 'title_zh': '自动驾驶中的链式思维：综合综述与未来展望'}
{'arxiv_id': 'arXiv:2505.20175', 'title': 'URPlanner: A Universal Paradigm For Collision-Free Robotic Motion Planning Based on Deep Reinforcement Learning', 'authors': 'Fengkang Ying, Hanwen Zhang, Haozhe Wang, Huishi Huang, Marcelo H. Ang Jr', 'link': 'https://arxiv.org/abs/2505.20175', 'abstract': 'Collision-free motion planning for redundant robot manipulators in complex environments is yet to be explored. Although recent advancements at the intersection of deep reinforcement learning (DRL) and robotics have highlighted its potential to handle versatile robotic tasks, current DRL-based collision-free motion planners for manipulators are highly costly, hindering their deployment and application. This is due to an overreliance on the minimum distance between the manipulator and obstacles, inadequate exploration and decision-making by DRL, and inefficient data acquisition and utilization. In this article, we propose URPlanner, a universal paradigm for collision-free robotic motion planning based on DRL. URPlanner offers several advantages over existing approaches: it is platform-agnostic, cost-effective in both training and deployment, and applicable to arbitrary manipulators without solving inverse kinematics. To achieve this, we first develop a parameterized task space and a universal obstacle avoidance reward that is independent of minimum distance. Second, we introduce an augmented policy exploration and evaluation algorithm that can be applied to various DRL algorithms to enhance their performance. Third, we propose an expert data diffusion strategy for efficient policy learning, which can produce a large-scale trajectory dataset from only a few expert demonstrations. Finally, the superiority of the proposed methods is comprehensively verified through experiments.', 'abstract_zh': '冗余机器人 manipulator 在复杂环境下的无碰撞运动规划尚未被充分探索。尽管深度强化学习（DRL）与机器人技术的交叉领域近期突显了其处理多种机器人任务的潜力，但当前基于 DRL 的无碰撞运动规划器成本高昂，阻碍了其部署和应用。这主要是因为过于依赖 manipulator 与障碍物之间的最小距离、DRL 资源探索和决策不足以及数据获取和利用效率低下。本文提出了一种基于 DRL 的通用无碰撞机器人运动规划框架 URPlanner。URPlanner 具有以下优势：平台无关、训练和部署成本低，并且能够应用于任意 manipulator 而无需求解逆运动学。为此，我们首先开发了一个参数化任务空间及相关联的通用障碍物回避奖励，该奖励独立于最小距离。其次，我们引入了一种增强策略探索和评估算法，该算法可应用于各种 DRL 算法以增强其性能。第三，我们提出了一种专家数据扩散策略，以实现高效策略学习，该策略可以从少量专家演示生成大规模轨迹数据集。最后，通过实验全面验证了所提方法的优越性。', 'title_zh': 'URPlanner: 一种基于深度强化学习的通用无碰撞机器人运动规划范式'}
{'arxiv_id': 'arXiv:2505.20043', 'title': 'Target Tracking via LiDAR-RADAR Sensor Fusion for Autonomous Racing', 'authors': 'Marcello Cellina, Matteo Corno, Sergio Matteo Savaresi', 'link': 'https://arxiv.org/abs/2505.20043', 'abstract': "High Speed multi-vehicle Autonomous Racing will increase the safety and performance of road-going Autonomous Vehicles. Precise vehicle detection and dynamics estimation from a moving platform is a key requirement for planning and executing complex autonomous overtaking maneuvers. To address this requirement, we have developed a Latency-Aware EKF-based Multi Target Tracking algorithm fusing LiDAR and RADAR measurements. The algorithm explots the different sensor characteristics by explicitly integrating the Range Rate in the EKF Measurement Function, as well as a-priori knowledge of the racetrack during state prediction. It can handle Out-Of-Sequence Measurements via Reprocessing using a double State and Measurement Buffer, ensuring sensor delay compensation with no information loss. This algorithm has been implemented on Team PoliMOVE's autonomous racecar, and was proved experimentally by completing a number of fully autonomous overtaking maneuvers at speeds up to 275 km/h.", 'abstract_zh': '高速多车自主赛车比赛将提高道路上自主车辆的安全性和性能。基于LiDAR和RADAR测量的延迟感知EKF多目标跟踪算法对于规划和执行复杂的自主超车机动至关重要。', 'title_zh': '基于LiDAR-RADAR传感器融合的自主赛车目标跟踪'}
{'arxiv_id': 'arXiv:2505.19980', 'title': 'A Cooperative Aerial System of A Payload Drone Equipped with Dexterous Rappelling End Droid for Cluttered Space Pickup', 'authors': 'Wenjing Ren, Xin Dong, Yangjie Cui, Binqi Yang, Haoze Li, Tao Yu, Jinwu Xiang, Daochun Li, Zhan Tu', 'link': 'https://arxiv.org/abs/2505.19980', 'abstract': 'In cluttered spaces, such as forests, drone picking up a payload via an abseil claw is an open challenge, as the cable is likely tangled and blocked by the branches and obstacles. To address such a challenge, in this work, a cooperative aerial system is proposed, which consists of a payload drone and a dexterous rappelling end droid. The two ends are linked via a Kevlar tether cable. The end droid is actuated by four propellers, which enable mid-air dexterous adjustment of clawing angle and guidance of cable movement. To avoid tanglement and rappelling obstacles, a trajectory optimization method that integrates cable length constraints and dynamic feasibility is developed, which guarantees safe pickup. A tether cable dynamic model is established to evaluate real-time cable status, considering both taut and sagging conditions. Simulation and real-world experiments are conducted to demonstrate that the proposed system is capable of picking up payload in cluttered spaces. As a result, the end droid can reach the target point successfully under cable constraints and achieve passive retrieval during the lifting phase without propulsion, which enables effective and efficient aerial manipulation.', 'abstract_zh': '在 cluttered 空间中，如森林中，无人机通过悬降爪拾取载荷是一个开放性挑战，因为缆绳容易与树枝和障碍物缠绕和堵塞。为应对这一挑战，本工作提出了一种协同空中系统，该系统由一个载荷无人机和一个灵巧悬降末端机器人组成。两端通过凯夫拉绳索连接。末端机器人由四个推进器驱动，能够在空中灵活调整爪子的角度和引导缆绳的移动。为避免缠绕和悬降障碍，开发了一种结合缆绳长度约束和动态可行性的路径优化方法，以保证安全拾取。建立了一种缆绳动力学模型，以实时刻缆状态评估，考虑了绷紧和下垂两种情况。通过仿真和实际实验展示了所提出系统能够在 cluttered 空间中拾取载荷的能力，结果表明，在缆绳限制条件下，末端机器人可以成功到达目标点，并在提升阶段实现无推进的被动拾取，从而实现有效的空中操作。', 'title_zh': '装备有灵巧绳降末端执行器的载荷无人机协同空中系统在复杂空间拾取操作'}
{'arxiv_id': 'arXiv:2505.19939', 'title': 'Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections', 'authors': 'Ran Yu, Zhuoren Li, Lu Xiong, Wei Han, Bo Leng', 'link': 'https://arxiv.org/abs/2505.19939', 'abstract': "Reinforcement learning (RL) has demonstrated potential in autonomous driving (AD) decision tasks. However, applying RL to urban AD, particularly in intersection scenarios, still faces significant challenges. The lack of safety constraints makes RL vulnerable to risks. Additionally, cognitive limitations and environmental randomness can lead to unreliable decisions in safety-critical scenarios. Therefore, it is essential to quantify confidence in RL decisions to improve safety. This paper proposes an Uncertainty-aware Safety-Critical Decision and Control (USDC) framework, which generates a risk-averse policy by constructing a risk-aware ensemble distributional RL, while estimating uncertainty to quantify the policy's reliability. Subsequently, a high-order control barrier function (HOCBF) is employed as a safety filter to minimize intervention policy while dynamically enhancing constraints based on uncertainty. The ensemble critics evaluate both HOCBF and RL policies, embedding uncertainty to achieve dynamic switching between safe and flexible strategies, thereby balancing safety and efficiency. Simulation tests on unsignalized intersections in multiple tasks indicate that USDC can improve safety while maintaining traffic efficiency compared to baselines.", 'abstract_zh': '不确定性和安全性aware的决策与控制框架（USDC）：风险规避策略生成及动态安全过滤', 'title_zh': '考虑不确定性的安全critical决策与控制：无信号交叉口自主车辆应用'}
{'arxiv_id': 'arXiv:2505.19860', 'title': 'Causal Bayesian Networks for Data-driven Safety Analysis of Complex Systems', 'authors': 'Roman Gansch, Lina Putze, Tjark Koopmann, Jan Reich, Christian Neurohr', 'link': 'https://arxiv.org/abs/2505.19860', 'abstract': "Ensuring safe operation of safety-critical complex systems interacting with their environment poses significant challenges, particularly when the system's world model relies on machine learning algorithms to process the perception input. A comprehensive safety argumentation requires knowledge of how faults or functional insufficiencies propagate through the system and interact with external factors, to manage their safety impact. While statistical analysis approaches can support the safety assessment, associative reasoning alone is neither sufficient for the safety argumentation nor for the identification and investigation of safety measures. A causal understanding of the system and its interaction with the environment is crucial for safeguarding safety-critical complex systems. It allows to transfer and generalize knowledge, such as insights gained from testing, and facilitates the identification of potential improvements. This work explores using causal Bayesian networks to model the system's causalities for safety analysis, and proposes measures to assess causal influences based on Pearl's framework of causal inference. We compare the approach of causal Bayesian networks to the well-established fault tree analysis, outlining advantages and limitations. In particular, we examine importance metrics typically employed in fault tree analysis as foundation to discuss suitable causal metrics. An evaluation is performed on the example of a perception system for automated driving. Overall, this work presents an approach for causal reasoning in safety analysis that enables the integration of data-driven and expert-based knowledge to account for uncertainties arising from complex systems operating in open environments.", 'abstract_zh': '确保安全关键复杂系统与其环境交互的 safe 操作面临重大挑战，特别是在系统的世界模型依赖于机器学习算法处理感知输入时。全面的安全论证需要了解故障或功能缺陷如何在系统内部传播并如何与外部因素交互，以管理其安全影响。虽然统计分析方法可以支持安全评估，但仅依赖关联推理不足以进行安全论证或识别和调查安全措施。系统及其与环境交互的因果理解对于保障安全关键复杂系统至关重要。它允许转移和泛化知识，如从测试中获得的洞察，并促进潜在改进的识别。本文探讨使用因果贝叶斯网络来建模系统的因果关系进行安全分析，并基于佩尔的因果推断框架提出评估因果影响的措施。我们将因果贝叶斯网络的方法与成熟的故障树分析进行比较，概述其优势和局限性。特别是，我们以故障树分析中常用的重要性度量为基础，讨论合适的因果度量。我们在自动驾驶感知系统的例子上进行了评估。总体而言，本文提出了一种因果推理在安全分析中的方法，能够整合数据驱动与基于专家的知识，以应对开放环境中复杂系统带来的不确定性。', 'title_zh': '用于复杂系统数据驱动安全性分析的因果贝叶斯网络'}
{'arxiv_id': 'arXiv:2505.19803', 'title': 'Integrating emotional intelligence, memory architecture, and gestures to achieve empathetic humanoid robot interaction in an educational setting', 'authors': 'Fuze Sun, Lingyu Li, Shixiangyue Meng, Xiaoming Teng, Terry Payne, Paul Craig', 'link': 'https://arxiv.org/abs/2505.19803', 'abstract': "This study investigates the integration of individual human traits into an empathetically adaptive educational robot tutor system designed to improve student engagement and learning outcomes with corresponding Engagement Vector measurement. While prior research in the field of Human-Robot Interaction (HRI) has examined the integration of the traits, such as emotional intelligence, memory-driven personalization, and non-verbal communication, by themselves, they have thus-far neglected to consider their synchronized integration into a cohesive, operational education framework. To address this gap, we customize a Multi-Modal Large Language Model (LLaMa 3.2 from Meta) deployed with modules for human-like traits (emotion, memory and gestures) into an AI-Agent framework. This constitutes to the robot's intelligent core mimicing the human emotional system, memory architecture and gesture control to allow the robot to behave more empathetically while recognizing and responding appropriately to the student's emotional state. It can also recall the student's past learning record and adapt its style of interaction accordingly. This allows the robot tutor to react to the student in a more sympathetic manner by delivering personalized verbal feedback synchronized with relevant gestures. Our study investigates the extent of this effect through the introduction of Engagement Vector Model which can be a surveyor's pole for judging the quality of HRI experience. Quantitative and qualitative results demonstrate that such an empathetic responsive approach significantly improves student engagement and learning outcomes compared with a baseline humanoid robot without these human-like traits. This indicates that robot tutors with empathetic capabilities can create a more supportive, interactive learning experience that ultimately leads to better outcomes for the student.", 'abstract_zh': '本研究探讨将个体人类特质整合进一种具有同理适应性教育机器教练系统的应用，该系统旨在通过相应的 Engagement Vector 测量来提高学生参与度和学习成果。', 'title_zh': '融合情感智能、记忆架构与手势实现教育环境中同理心 humanoid 机器人交互'}
{'arxiv_id': 'arXiv:2505.19769', 'title': 'TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning', 'authors': 'Yuhui Chen, Haoran Li, Zhennan Jiang, Haowei Wen, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2505.19769', 'abstract': "Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.", 'abstract_zh': '开发可扩展且通用的奖励工程以提高强化学习中的机器人操控任务表现', 'title_zh': 'TeViR: 基于扩散模型的文本到视频奖励方法用于高效的强化学习'}
{'arxiv_id': 'arXiv:2505.19767', 'title': 'RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback', 'authors': 'Junyang Shu, Zhiwei Lin, Yongtao Wang', 'link': 'https://arxiv.org/abs/2505.19767', 'abstract': "Vision-Language-Action (VLA) models have demonstrated significant potential in the field of embodied intelligence, enabling agents to follow human instructions to complete complex tasks in physical environments. Existing embodied agents are often trained through behavior cloning, which requires expensive data and computational resources and is constrained by human demonstrations. To address this issue, many researchers explore the application of reinforcement fine-tuning to embodied agents. However, typical reinforcement fine-tuning methods for embodied agents usually rely on sparse, outcome-based rewards, which struggle to provide fine-grained feedback for specific actions within an episode, thus limiting the model's manipulation capabilities and generalization performance. In this paper, we propose RFTF, a novel reinforcement fine-tuning method that leverages a value model to generate dense rewards in embodied scenarios. Specifically, our value model is trained using temporal information, eliminating the need for costly robot action labels. In addition, RFTF incorporates a range of techniques, such as GAE and sample balance to enhance the effectiveness of the fine-tuning process. By addressing the sparse reward problem in reinforcement fine-tuning, our method significantly improves the performance of embodied agents, delivering superior generalization and adaptation capabilities across diverse embodied tasks. Experimental results show that embodied agents fine-tuned with RFTF achieve new state-of-the-art performance on the challenging CALVIN ABC-D with an average success length of 4.296. Moreover, RFTF enables rapid adaptation to new environments. After fine-tuning in the D environment of CALVIN for a few episodes, RFTF achieved an average success length of 4.301 in this new environment.", 'abstract_zh': '基于视觉-语言-动作的强化细调方法(RFTF)在体态智能中的应用', 'title_zh': 'RFTF: 基于时间反馈的强化细调用于体现代理'}
{'arxiv_id': 'arXiv:2505.19717', 'title': 'Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning', 'authors': 'Quentin Rouxel, Clemente Donoso, Fei Chen, Serena Ivaldi, Jean-Baptiste Mouret', 'link': 'https://arxiv.org/abs/2505.19717', 'abstract': 'Imitation learning is a promising approach for enabling generalist capabilities in humanoid robots, but its scaling is fundamentally constrained by the scarcity of high-quality expert demonstrations. This limitation can be mitigated by leveraging suboptimal, open-ended play data, often easier to collect and offering greater diversity. This work builds upon recent advances in generative modeling, specifically Flow Matching, an alternative to Diffusion models. We introduce a method for estimating the extremum of the learned distribution by leveraging the unique properties of Flow Matching, namely, deterministic transport and support for arbitrary source distributions. We apply this method to develop several goal-conditioned imitation and reinforcement learning algorithms based on Flow Matching, where policies are conditioned on both current and goal observations. We explore and compare different architectural configurations by combining core components, such as critic, planner, actor, or world model, in various ways. We evaluated our agents on the OGBench benchmark and analyzed how different demonstration behaviors during data collection affect performance in a 2D non-prehensile pushing task. Furthermore, we validated our approach on real hardware by deploying it on the Talos humanoid robot to perform complex manipulation tasks based on high-dimensional image observations, featuring a sequence of pick-and-place and articulated object manipulation in a realistic kitchen environment. Experimental videos and code are available at: this https URL', 'abstract_zh': '模仿学习是一种有望赋予类人机器人一般性能力的方法，但由于高质量专家演示数据稀缺，其扩展受到根本约束。可以通过利用次优的开放性玩耍数据来缓解这一限制，这类数据通常更容易收集并且提供了更大的多样性。本工作基于生成建模领域的近期进展，特别是Flow Matching，这是一种与扩散模型不同的生成模型。我们提出了一种方法，通过利用Flow Matching的独特属性，即确定性的传输和任意源分布的支持，来估计学习分布的极值。我们应用这种方法开发了几种基于Flow Matching的目标条件模仿和强化学习算法，其中策略同时基于当前和目标观察进行条件约束。我们通过以不同方式结合核心组件，如评论者、规划者、演员或世界模型，探索和比较不同的架构配置。我们在OGBench基准上评估了我们的代理，并分析了数据收集过程中不同演示行为对二维非拾取推任务性能的影响。此外，我们在真实的硬件上验证了我们的方法，将其部署在Talos类人机器人上，进行基于高维图像观察的复杂操作任务，包括在真实厨房环境中的拾取-放置和动作化物体操作序列。实验视频和代码可在以下链接获取：this https URL', 'title_zh': '离线目标条件强化学习中的极值流匹配'}
{'arxiv_id': 'arXiv:2505.19688', 'title': 'GeoPF: Infusing Geometry into Potential Fields for Reactive Planning in Non-trivial Environments', 'authors': 'Yuhe Gong, Riddhiman Laha, Luis Figueredo', 'link': 'https://arxiv.org/abs/2505.19688', 'abstract': "Reactive intelligence remains one of the cornerstones of versatile robotics operating in cluttered, dynamic, and human-centred environments. Among reactive approaches, potential fields (PF) continue to be widely adopted due to their simplicity and real-time applicability. However, existing PF methods typically oversimplify environmental representations by relying on isotropic, point- or sphere-based obstacle approximations. In human-centred settings, this simplification results in overly conservative paths, cumbersome tuning, and computational overhead -- even breaking real-time requirements. In response, we propose the Geometric Potential Field (GeoPF), a reactive motion-planning framework that explicitly infuses geometric primitives - points, lines, planes, cubes, and cylinders - into real-time planning. By leveraging precise closed-form distance functions, GeoPF significantly reduces computational complexity and parameter tuning effort. Extensive quantitative analyses consistently show GeoPF's higher success rates, reduced tuning complexity (a single parameter set across experiments), and substantially lower computational costs (up to 2 orders of magnitude) compared to traditional PF methods. Real-world experiments further validate GeoPF's robustness and practical ease of deployment. GeoPF provides a fresh perspective on reactive planning problems driving geometric-aware temporal motion generation, enabling flexible and low-latency motion planning suitable for modern robotic applications.", 'abstract_zh': '几何势场：一种面向几何感知的实时motion规划框架', 'title_zh': 'GeoPF：将几何学融入潜在场以在复杂环境中进行反应性规划'}
{'arxiv_id': 'arXiv:2505.19657', 'title': 'Autonomous Flights inside Narrow Tunnels', 'authors': 'Luqi Wang, Yan Ning, Hongming Chen, Peize Liu, Yang Xu, Hao Xu, Ximin Lyu, Shaojie Shen', 'link': 'https://arxiv.org/abs/2505.19657', 'abstract': 'Multirotors are usually desired to enter confined narrow tunnels that are barely accessible to humans in various applications including inspection, search and rescue, and so on. This task is extremely challenging since the lack of geometric features and illuminations, together with the limited field of view, cause problems in perception; the restricted space and significant ego airflow disturbances induce control issues. This paper introduces an autonomous aerial system designed for navigation through tunnels as narrow as 0.5 m in diameter. The real-time and online system includes a virtual omni-directional perception module tailored for the mission and a novel motion planner that incorporates perception and ego airflow disturbance factors modeled using camera projections and computational fluid dynamics analyses, respectively. Extensive flight experiments on a custom-designed quadrotor are conducted in multiple realistic narrow tunnels to validate the superior performance of the system, even over human pilots, proving its potential for real applications. Additionally, a deployment pipeline on other multirotor platforms is outlined and open-source packages are provided for future developments.', 'abstract_zh': '多旋翼无人机在狭窄隧道中的自主导航：从0.5米直径的隧道出发', 'title_zh': '自主窄隧道内飞行'}
{'arxiv_id': 'arXiv:2505.19600', 'title': 'Indoor Air Quality Detection Robot Model Based on the Internet of Things (IoT)', 'authors': 'Anggiat Mora Simamora, Asep Denih, Mohamad Iqbal Suriansyah', 'link': 'https://arxiv.org/abs/2505.19600', 'abstract': 'This paper presents the design, implementation, and evaluation of an IoT-based robotic system for mapping and monitoring indoor air quality. The primary objective was to develop a mobile robot capable of autonomously mapping a closed environment, detecting concentrations of CO$_2$, volatile organic compounds (VOCs), smoke, temperature, and humidity, and transmitting real-time data to a web interface. The system integrates a set of sensors (SGP30, MQ-2, DHT11, VL53L0X, MPU6050) with an ESP32 microcontroller. It employs a mapping algorithm for spatial data acquisition and utilizes a Mamdani fuzzy logic system for air quality classification. Empirical tests in a model room demonstrated average localization errors below $5\\%$, actuator motion errors under $2\\%$, and sensor measurement errors within $12\\%$ across all modalities. The contributions of this work include: (1) a low-cost, integrated IoT robotic platform for simultaneous mapping and air quality detection; (2) a web-based user interface for real-time visualization and control; and (3) validation of system accuracy under laboratory conditions.', 'abstract_zh': '基于物联网的室内空气质量测绘与监控机器人系统的设计、实现与评估', 'title_zh': '基于物联网(IoT)的室内空气质量检测机器人模型'}
{'arxiv_id': 'arXiv:2505.19580', 'title': 'Whole-body Multi-contact Motion Control for Humanoid Robots Based on Distributed Tactile Sensors', 'authors': 'Masaki Murooka, Kensuke Fukumitsu, Marwan Hamze, Mitsuharu Morisawa, Hiroshi Kaminaga, Fumio Kanehiro, Eiichi Yoshida', 'link': 'https://arxiv.org/abs/2505.19580', 'abstract': "To enable humanoid robots to work robustly in confined environments, multi-contact motion that makes contacts not only at extremities, such as hands and feet, but also at intermediate areas of the limbs, such as knees and elbows, is essential. We develop a method to realize such whole-body multi-contact motion involving contacts at intermediate areas by a humanoid robot. Deformable sheet-shaped distributed tactile sensors are mounted on the surface of the robot's limbs to measure the contact force without significantly changing the robot body shape. The multi-contact motion controller developed earlier, which is dedicated to contact at extremities, is extended to handle contact at intermediate areas, and the robot motion is stabilized by feedback control using not only force/torque sensors but also distributed tactile sensors. Through verification on dynamics simulations, we show that the developed tactile feedback improves the stability of whole-body multi-contact motion against disturbances and environmental errors. Furthermore, the life-sized humanoid RHP Kaleido demonstrates whole-body multi-contact motions, such as stepping forward while supporting the body with forearm contact and balancing in a sitting posture with thigh contacts.", 'abstract_zh': '使人形机器人能够在受限环境中 robust 地工作，需要实现多点接触运动，不仅在手和脚等末端部位，还需在肢体的中间部位，如膝盖和肘部，进行接触。我们开发了一种方法，通过在人形机器人肢体表面安装可变形的片状分布式触觉传感器，实现包括中间部位接触的全身多点接触运动。此前专为末端接触开发的多点接触运动控制器被扩展以处理中间部位的接触，并通过力/力矩传感器和分布式触觉传感器的反馈控制来稳定机器人运动。通过动力学仿真验证，我们展示了开发的触觉反馈可提高全身多点接触运动在干扰和环境误差下的稳定性。此外，全尺寸人形机器人 RHP Kaleido 展示了全身多点接触运动，如起立时通过前臂接触支撑身体，以及通过大腿接触实现坐姿平衡。', 'title_zh': '基于分布式触觉传感器的人形机器人全身多点接触运动控制'}
{'arxiv_id': 'arXiv:2505.19574', 'title': 'Situationally-Aware Dynamics Learning', 'authors': 'Alejandro Murillo-Gonzalez, Lantao Liu', 'link': 'https://arxiv.org/abs/2505.19574', 'abstract': "Autonomous robots operating in complex, unstructured environments face significant challenges due to latent, unobserved factors that obscure their understanding of both their internal state and the external world. Addressing this challenge would enable robots to develop a more profound grasp of their operational context. To tackle this, we propose a novel framework for online learning of hidden state representations, with which the robots can adapt in real-time to uncertain and dynamic conditions that would otherwise be ambiguous and result in suboptimal or erroneous behaviors. Our approach is formalized as a Generalized Hidden Parameter Markov Decision Process, which explicitly models the influence of unobserved parameters on both transition dynamics and reward structures. Our core innovation lies in learning online the joint distribution of state transitions, which serves as an expressive representation of latent ego- and environmental-factors. This probabilistic approach supports the identification and adaptation to different operational situations, improving robustness and safety. Through a multivariate extension of Bayesian Online Changepoint Detection, our method segments changes in the underlying data generating process governing the robot's dynamics. The robot's transition model is then informed with a symbolic representation of the current situation derived from the joint distribution of latest state transitions, enabling adaptive and context-aware decision-making. To showcase the real-world effectiveness, we validate our approach in the challenging task of unstructured terrain navigation, where unmodeled and unmeasured terrain characteristics can significantly impact the robot's motion. Extensive experiments in both simulation and real world reveal significant improvements in data efficiency, policy performance, and the emergence of safer, adaptive navigation strategies.", 'abstract_zh': '自主机器人在复杂未结构性环境中的操作面临显著挑战，由于潜在且未被观测到的因素遮蔽了它们对其内部状态和外部世界理解的清晰度。解决这一挑战将使机器人能够更深刻地理解其操作环境。为此，我们提出了一种新颖的在线学习隐藏状态表示的框架，使机器人能够实时适应那些否则会变得模棱两可并导致次优或错误行为的不确定和动态条件。我们的方法形式化为广义隐藏参数马尔科夫决策过程，明确地将未观测参数对转换动力学和奖励结构的影响建模进去。我们核心的创新在于在线学习状态转换的联合分布，这作为对潜在自身体和环境因素的表达性表示。这种概率方法支持识别和适应不同的操作情况，提高鲁棒性和安全性。通过多变量贝叶斯在线变化点检测的扩展，我们的方法将潜在数据生成过程的变化进行分段，从而让机器人的转换模型得到当前情况的符号表示，使决策具有适应性和情境意识。为了展示其实用效果，我们在未建模和未测量地形特征会对机器人运动产生显著影响的无结构地形导航任务中验证了我们的方法。在仿真实验和真实世界实验中，我们发现了显著的数据效率提升、策略性能增强以及更安全、适应性强的导航策略的出现。', 'title_zh': '情境意识动态学习'}
{'arxiv_id': 'arXiv:2505.19560', 'title': 'LF-GNSS: Towards More Robust Satellite Positioning with a Hard Example Mining Enhanced Learning-Filtering Deep Fusion Framework', 'authors': 'Jianan Lou, Rong Zhang', 'link': 'https://arxiv.org/abs/2505.19560', 'abstract': 'Global Navigation Satellite System (GNSS) is essential for autonomous driving systems, unmanned vehicles, and various location-based technologies, as it provides the precise geospatial information necessary for navigation and situational awareness. However, its performance is often degraded by Non-Line-Of-Sight (NLOS) and multipath effects, especially in urban environments. Recently, Artificial Intelligence (AI) has been driving innovation across numerous industries, introducing novel solutions to mitigate the challenges in satellite positioning. This paper presents a learning-filtering deep fusion framework for satellite positioning, termed LF-GNSS. The framework utilizes deep learning networks to intelligently analyze the signal characteristics of satellite observations, enabling the adaptive construction of observation noise covariance matrices and compensated innovation vectors for Kalman filter input. A dynamic hard example mining technique is incorporated to enhance model robustness by prioritizing challenging satellite signals during training. Additionally, we introduce a novel feature representation based on Dilution of Precision (DOP) contributions, which helps to more effectively characterize the signal quality of individual satellites and improve measurement weighting. LF-GNSS has been validated on both public and private datasets, demonstrating superior positioning accuracy compared to traditional methods and other learning-based solutions. To encourage further integration of AI and GNSS research, we will open-source the code at this https URL, and release a collection of satellite positioning datasets for urban scenarios at this https URL.', 'abstract_zh': '全球导航卫星系统（GNSS）对于自动驾驶系统、无人驾驶车辆以及各种基于位置的技术至关重要，因为它提供了导航和态势感知所需的精确地理空间信息。然而，其性能往往因非视距（NLOS）和多路径效应而在城市环境中受到影响。近年来，人工智能（AI）正在推动众多行业的创新，引入新的解决方案以缓解卫星定位的挑战。本文提出了一种用于卫星定位的基于学习-过滤的深度融合框架，称为LF-GNSS。该框架利用深度学习网络智能分析卫星观测信号特征，实现观测噪声协方差矩阵和补偿创新向量的自适应构建，以优化卡尔曼滤波器输入。还引入了一种动态硬模式挖掘技术，在训练过程中优先处理具有挑战性的卫星信号，增强模型的鲁棒性。此外，还基于精度衰减因子（DOP）贡献引入了一种新的特征表示方法，有助于更有效地表征单颗卫星的信号质量并改进测量权重。LF-GNSS已在公共和私有数据集上进行验证，显示了与传统方法和其他基于学习的解决方案相比的卓越定位精度。为促进人工智能与GNSS研究的进一步融合，代码将在以下链接开源：this https URL，并将在以下链接发布城市场景下的卫星定位数据集：this https URL。', 'title_zh': 'LF-GNSS：一种增强学习滤波深度融合框架的困难样本挖掘增强卫星定位鲁棒性方法'}
{'arxiv_id': 'arXiv:2505.19540', 'title': 'Real-time Whole-body Model Predictive Control for Bipedal Locomotion with a Novel Kino-dynamic Model and Warm-start Method', 'authors': 'Junhyung Kim, Hokyun Lee, Jaeheung Park', 'link': 'https://arxiv.org/abs/2505.19540', 'abstract': 'Advancements in optimization solvers and computing power have led to growing interest in applying whole-body model predictive control (WB-MPC) to bipedal robots. However, the high degrees of freedom and inherent model complexity of bipedal robots pose significant challenges in achieving fast and stable control cycles for real-time performance. This paper introduces a novel kino-dynamic model and warm-start strategy for real-time WB-MPC in bipedal robots. Our proposed kino-dynamic model combines the linear inverted pendulum plus flywheel and full-body kinematics model. Unlike the conventional whole-body model that rely on the concept of contact wrenches, our model utilizes the zero-moment point (ZMP), reducing baseline computational costs and ensuring consistently low latency during contact state transitions. Additionally, a modularized multi-layer perceptron (MLP) based warm-start strategy is proposed, leveraging a lightweight neural network to provide a good initial guess for each control cycle. Furthermore, we present a ZMP-based whole-body controller (WBC) that extends the existing WBC for explicitly controlling impulses and ZMP, integrating it into the real-time WB-MPC framework. Through various comparative experiments, the proposed kino-dynamic model and warm-start strategy have been shown to outperform previous studies. Simulations and real robot experiments further validate that the proposed framework demonstrates robustness to perturbation and satisfies real-time control requirements during walking.', 'abstract_zh': '优化求解器的发展和计算能力的提升促进了将整体动力学模型预测控制（WB-MPC）应用于 bipedal 机器人的研究兴趣。然而，bipedal 机器人的高自由度和固有模型复杂性给实现快速稳定的控制循环带来了显著挑战。本文介绍了一种针对实时 WB-MPC 的新型kino-dynamic模型和预热启动策略。我们提出的kino-dynamic模型结合了线性倒摆加飞轮和全身运动学模型。与传统的基于接触 wrench 的整体模型不同，我们的模型使用零力矩点（ZMP），降低基本计算成本并在接触状态转换期间确保一致的低延迟。此外，提出了一种基于模块化多层感知机（MLP）的预热启动策略，通过轻量级神经网络为每个控制周期提供良好的初始猜测。同时，我们提出了一种基于ZMP的整体动力学控制器（WBC），扩展现有WBC以显式控制冲量和ZMP，并将其集成到实时WB-MPC框架中。通过各种比较实验，所提出的kino-dynamic模型和预热启动策略的表现优于先前的研究。仿真和实际机器人实验进一步验证了所提出框架在行走过程中对干扰具有鲁棒性和满足实时控制要求的能力。', 'title_zh': '基于新颖的时空动态模型和预热方法的实时全身模型预测控制在双足步行中的应用'}
{'arxiv_id': 'arXiv:2505.19530', 'title': 'Heavy lifting tasks via haptic teleoperation of a wheeled humanoid', 'authors': 'Amartya Purushottam, Jack Yan, Christopher Yu, Joao Ramos', 'link': 'https://arxiv.org/abs/2505.19530', 'abstract': "Humanoid robots can support human workers in physically demanding environments by performing tasks that require whole-body coordination, such as lifting and transporting heavy this http URL tasks, which we refer to as Dynamic Mobile Manipulation (DMM), require the simultaneous control of locomotion, manipulation, and posture under dynamic interaction forces. This paper presents a teleoperation framework for DMM on a height-adjustable wheeled humanoid robot for carrying heavy payloads. A Human-Machine Interface (HMI) enables whole-body motion retargeting from the human pilot to the robot by capturing the motion of the human and applying haptic feedback. The pilot uses body motion to regulate robot posture and locomotion, while arm movements guide this http URL time haptic feedback delivers end effector wrenches and balance related cues, closing the loop between human perception and robot environment interaction. We evaluate the different telelocomotion mappings that offer varying levels of balance assistance, allowing the pilot to either manually or automatically regulate the robot's lean in response to payload-induced disturbances. The system is validated in experiments involving dynamic lifting of barbells and boxes up to 2.5 kg (21% of robot mass), demonstrating coordinated whole-body control, height variation, and disturbance handling under pilot guidance. Video demo can be found at: this https URL", 'abstract_zh': '可调节高度的轮式人形机器人在动态搬运重载荷任务中的远程操作框架', 'title_zh': '通过轮式人形机器人的触觉远程操作进行重载任务'}
{'arxiv_id': 'arXiv:2505.19521', 'title': 'Learning Dynamics under Environmental Constraints via Measurement-Induced Bundle Structures', 'authors': 'Dongzhe Zheng, Wenjie Mei', 'link': 'https://arxiv.org/abs/2505.19521', 'abstract': 'Learning unknown dynamics under environmental (or external) constraints is fundamental to many fields (e.g., modern robotics), particularly challenging when constraint information is only locally available and uncertain. Existing approaches requiring global constraints or using probabilistic filtering fail to fully exploit the geometric structure inherent in local measurements (by using, e.g., sensors) and constraints. This paper presents a geometric framework unifying measurements, constraints, and dynamics learning through a fiber bundle structure over the state space. This naturally induced geometric structure enables measurement-aware Control Barrier Functions that adapt to local sensing (or measurement) conditions. By integrating Neural ODEs, our framework learns continuous-time dynamics while preserving geometric constraints, with theoretical guarantees of learning convergence and constraint satisfaction dependent on sensing quality. The geometric framework not only enables efficient dynamics learning but also suggests promising directions for integration with reinforcement learning approaches. Extensive simulations demonstrate significant improvements in both learning efficiency and constraint satisfaction over traditional methods, especially under limited and uncertain sensing conditions.', 'abstract_zh': '在环境约束下学习未知动力学：利用局部和不确定约束的几何框架', 'title_zh': '在环境约束下通过测量诱导的集合结构学习动力学'}
{'arxiv_id': 'arXiv:2505.19516', 'title': 'DiffE2E: Rethinking End-to-End Driving with a Hybrid Action Diffusion and Supervised Policy', 'authors': 'Rui Zhao, Yuze Fan, Ziguo Chen, Fei Gao, Zhenhai Gao', 'link': 'https://arxiv.org/abs/2505.19516', 'abstract': 'End-to-end learning has emerged as a transformative paradigm in autonomous driving. However, the inherently multimodal nature of driving behaviors and the generalization challenges in long-tail scenarios remain critical obstacles to robust deployment. We propose DiffE2E, a diffusion-based end-to-end autonomous driving framework. This framework first performs multi-scale alignment of multi-sensor perception features through a hierarchical bidirectional cross-attention mechanism. It then introduces a novel class of hybrid diffusion-supervision decoders based on the Transformer architecture, and adopts a collaborative training paradigm that seamlessly integrates the strengths of both diffusion and supervised policy. DiffE2E models structured latent spaces, where diffusion captures the distribution of future trajectories and supervision enhances controllability and robustness. A global condition integration module enables deep fusion of perception features with high-level targets, significantly improving the quality of trajectory generation. Subsequently, a cross-attention mechanism facilitates efficient interaction between integrated features and hybrid latent variables, promoting the joint optimization of diffusion and supervision objectives for structured output generation, ultimately leading to more robust control. Experiments demonstrate that DiffE2E achieves state-of-the-art performance in both CARLA closed-loop evaluations and NAVSIM benchmarks. The proposed integrated diffusion-supervision policy offers a generalizable paradigm for hybrid action representation, with strong potential for extension to broader domains including embodied intelligence. More details and visualizations are available at \\href{this https URL}{project website}.', 'abstract_zh': '基于扩散的端到端自动驾驶框架：DiffE2E', 'title_zh': 'DiffE2E: 重新思考基于混合动作扩散和监督策略的端到端驾驶'}
{'arxiv_id': 'arXiv:2505.19512', 'title': 'LLA-MPC: Fast Adaptive Control for Autonomous Racing', 'authors': 'Maitham F. AL-Sunni, Hassan Almubarak, Katherine Horng, John M. Dolan', 'link': 'https://arxiv.org/abs/2505.19512', 'abstract': 'We present Look-Back and Look-Ahead Adaptive Model Predictive Control (LLA-MPC), a real-time adaptive control framework for autonomous racing that addresses the challenge of rapidly changing tire-surface interactions. Unlike existing approaches requiring substantial data collection or offline training, LLA-MPC employs a model bank for immediate adaptation without a learning period. It integrates two key mechanisms: a look-back window that evaluates recent vehicle behavior to select the most accurate model and a look-ahead horizon that optimizes trajectory planning based on the identified dynamics. The selected model and estimated friction coefficient are then incorporated into a trajectory planner to optimize reference paths in real-time. Experiments across diverse racing scenarios demonstrate that LLA-MPC outperforms state-of-the-art methods in adaptation speed and handling, even during sudden friction transitions. Its learning-free, computationally efficient design enables rapid adaptation, making it ideal for high-speed autonomous racing in multi-surface environments.', 'abstract_zh': '回顾前瞻自适应模型预测控制（LLA-MPC）：一种用于自主赛车的实时自适应控制框架', 'title_zh': 'LLA-MPC: 快速自适应控制用于自主赛车'}
{'arxiv_id': 'arXiv:2505.19463', 'title': 'SMAP: Self-supervised Motion Adaptation for Physically Plausible Humanoid Whole-body Control', 'authors': 'Haoyu Zhao, Sixu Lin, Qingwei Ben, Minyue Dai, Hao Fei, Jingbo Wang, Hua Zou, Junting Dong', 'link': 'https://arxiv.org/abs/2505.19463', 'abstract': 'This paper presents a novel framework that enables real-world humanoid robots to maintain stability while performing human-like motion. Current methods train a policy which allows humanoid robots to follow human body using the massive retargeted human data via reinforcement learning. However, due to the heterogeneity between human and humanoid robot motion, directly using retargeted human motion reduces training efficiency and stability. To this end, we introduce SMAP, a novel whole-body tracking framework that bridges the gap between human and humanoid action spaces, enabling accurate motion mimicry by humanoid robots. The core idea is to use a vector-quantized periodic autoencoder to capture generic atomic behaviors and adapt human motion into physically plausible humanoid motion. This adaptation accelerates training convergence and improves stability when handling novel or challenging motions. We then employ a privileged teacher to distill precise mimicry skills into the student policy with a proposed decoupled reward. We conduct experiments in simulation and real world to demonstrate the superiority stability and performance of SMAP over SOTA methods, offering practical guidelines for advancing whole-body control in humanoid robots.', 'abstract_zh': '本文提出了一种新型框架，使现实世界中的类人机器人在执行人体类似动作时能够保持稳定性。当前的方法通过强化学习训练一个策略，让用户有大量的重目标人类数据来引导类人机器人跟随人体动作。然而，由于人类和类人机器人动作之间的异质性，直接使用重目标人类动作会降低训练效率和稳定性。为此，我们引入了SMAP，这是一种新颖的整体人体跟踪框架，该框架填补了人类和类人动作空间之间的差距，使类人机器人能够准确模仿人体动作。核心思想是使用向量量化周期自编码器捕捉通用的基本行为，并将人类动作适应为物理上合理的类人动作。这种适应加速了训练收敛并提高了在处理新型或具有挑战性动作时的稳定性。然后，我们使用一个特权教师通过提出解耦奖励来将精确的模仿技能传授给学生策略。我们在仿真和现实世界中进行了实验，以展示SMAP在与当前最佳方法相比的优势稳定性和性能，并提供了关于推进类人机器人全身控制的实用指导。', 'title_zh': '自监督运动适应：实现物理合理的人形全身控制'}
{'arxiv_id': 'arXiv:2505.19339', 'title': 'Towards Humanoid Robot Autonomy: A Dynamic Architecture Integrating Continuous thought Machines (CTM) and Model Context Protocol (MCP)', 'authors': 'Libo Wang', 'link': 'https://arxiv.org/abs/2505.19339', 'abstract': 'To address the gaps between the static pre-set "thinking-planning-action" of humanoid robots in unfamiliar scenarios and the highly programmed "call tool-return result" due to the lack of autonomous coding capabilities, this work designs a dynamic architecture connecting continuous thought machines (CTM) and model context protocol (MCP). It proposes a theoretical parallel solution through tick-slab and uses rank compression to achieve parameter suppression to provide a solution for achieving autonomous actions due to autonomous coding. The researcher used a simulation-based experiment using OpenAI\'s o4-mini-high as a tool to build the experimental environment, and introduced the extended SayCan dataset to conduct nine epochs of experiments. The experimental results show that the CTM-MCP architecture is feasible and effective through the data results of seven metrics: task success rate (TSR), execution success rate (ESR), average episode length (AEL), ROSCOE, REVEAL, proficiency self-assessment (PSA), task effectiveness (TE). In practice, it provides a reference experience for exploring the autonomous dynamic coding of humanoid robots based on continuous thinking to achieve human-like autonomous actions.', 'abstract_zh': '针对类人机器人在不熟悉场景中预设的静态“思考-规划-行动”与高度编程的“调用工具-返回结果”之间差距，由于缺乏自主编码能力，本研究设计了一种动态架构，连接连续思考机器（CTM）和模型上下文协议（MCP）。通过tickslab提出了一个理论上的并行解决方案，并利用秩压缩实现参数抑制，以提供由于自主编码实现自主行动的解决方案。研究者使用基于模拟的实验，利用OpenAI的o4-mini-high作为工具构建实验环境，并引入扩展版的SayCan数据集进行九个训练周期的实验。实验结果表明，CTM-MCP架构通过七项度量指标（任务成功率、执行成功率、平均回合长度、ROSCOE、REVEAL、技能自我评估、任务有效性）的数据结果证明了其可行性和有效性。此外，该研究为基于连续思考实现类人机器人自主动态编码提供了参考经验，以期达到类似人类的自主行为。', 'title_zh': '面向人形机器人自主性的动态架构：整合连续思维机器(CTM)和模型上下文协议(MCP)'}
{'arxiv_id': 'arXiv:2505.19330', 'title': 'Deriving The Fundamental Equation of Earthmoving and Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation', 'authors': 'W. Jacob Wagner', 'link': 'https://arxiv.org/abs/2505.19330', 'abstract': "This document serves as supplementary material for two International Society for Terrain-Vehicle Systems conference publications regarding in situ soil property estimation by Wagner et al. in 2023 and 2025. It covers the derivation of the fundamental equation of earthmoving for a flat blade moving through sloped soil and provides some information regarding the advanced configuration of Vortex Studio's soil-tool interaction simulation.", 'abstract_zh': '本文件作为Wagner等人在2023年和2025年发表于国际地形车辆系统学会会议上的关于就地土壤属性估算的两篇论文的补充材料。它涵盖了平刃通过斜坡土壤挖掘的基本方程的推导，并提供了一些关于Vortex Studio土壤-工具交互模拟高级配置的信息。', 'title_zh': '构建土方作业的基本方程并配置旋 Uncomment for full translation, but it seems there\'s a typo in the original title. Assuming "Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation" needs to be integrated, the translated title would be:\n\n构建土方作业的基本方程并配置旋涡工作室土方作业模拟进行土壤属性估算实验'}
{'arxiv_id': 'arXiv:2505.19311', 'title': 'Passive Vibration Control of a 3-D Printer Gantry', 'authors': 'Maharshi A. Sharma, Albert E. Patterson', 'link': 'https://arxiv.org/abs/2505.19311', 'abstract': 'Improved additive manufacturing capabilities are vital for the future development and improvement of ubiquitous robotic systems. These machines can be integrated into existing robotic systems to allow manufacturing and repair of components, as well as fabrication of custom parts for the robots themselves. The fused filament fabrication (FFF) process is one of the most common and well-developed AM processes but suffers from the effects of vibration-induced position error, particularly as the printing speed is raised. This project adapted and expanded a dynamic model of an FFF gantry system to include a passive spring-mass-damper system controller attached to the extruder carriage and tuned using optimal parameters. A case study was conducted to demonstrate the effects and generate recommendations for implementation. This work is also valuable for other mechatronic systems which operate using an open-loop control system and which suffer from vibration, including numerous robotic systems, pick-and-place machines, positioners, and similar.', 'abstract_zh': '改进的增材制造能力对于未来通用机器人系统的开发与改进至关重要。这些机器可以整合到现有的机器人系统中，以实现组件的制造与修复，以及为机器人自身制作定制部件。熔融沉积成型（FFF）工艺是应用最广泛和最成熟的增材制造工艺之一，但随着打印速度的提高，会受到振动引起的定位误差的影响。本项目改编并扩展了一个FFF龙门系统的动态模型，包括将一个被动弹簧-质量-阻尼系统控制器附加到挤出机车架上，并通过最优参数进行调整。进行了案例研究以展示其效果并提出实施建议。此项工作对于其他采用开环控制系统且受振动影响的机电系统也具有重要意义，包括多种机器人系统、取放机、定位器等。', 'title_zh': '3D打印龙门架的被动振动控制'}
{'arxiv_id': 'arXiv:2505.19306', 'title': 'From Single Images to Motion Policies via Video-Generation Environment Representations', 'authors': 'Weiming Zhi, Ziyong Ma, Tianyi Zhang, Matthew Johnson-Roberson', 'link': 'https://arxiv.org/abs/2505.19306', 'abstract': 'Autonomous robots typically need to construct representations of their surroundings and adapt their motions to the geometry of their environment. Here, we tackle the problem of constructing a policy model for collision-free motion generation, consistent with the environment, from a single input RGB image. Extracting 3D structures from a single image often involves monocular depth estimation. Developments in depth estimation have given rise to large pre-trained models such as DepthAnything. However, using outputs of these models for downstream motion generation is challenging due to frustum-shaped errors that arise. Instead, we propose a framework known as Video-Generation Environment Representation (VGER), which leverages the advances of large-scale video generation models to generate a moving camera video conditioned on the input image. Frames of this video, which form a multiview dataset, are then input into a pre-trained 3D foundation model to produce a dense point cloud. We then introduce a multi-scale noise approach to train an implicit representation of the environment structure and build a motion generation model that complies with the geometry of the representation. We extensively evaluate VGER over a diverse set of indoor and outdoor environments. We demonstrate its ability to produce smooth motions that account for the captured geometry of a scene, all from a single RGB input image.', 'abstract_zh': '自主机器人通常需要构建其周围环境的表示，并根据环境的几何结构调整其运动。本文探讨了从单张RGB图像构建无碰撞运动生成策略模型的问题，该模型与环境一致。从单张图像中提取3D结构通常涉及单目深度估计。深度估计的进步催生了大型预训练模型，如DepthAnything。然而，这些模型的输出用于下游运动生成存在挑战，因为它们会引发锥形误差。相反，我们提出了一种名为Video-Generation Environment Representation (VGER)的框架，该框架利用大规模视频生成模型的进展，根据输入图像生成条件生成运动摄像机视频。此视频的帧，形成多视图数据集，随后输入预训练的3D基础模型以生成密集点云。引入多尺度噪声方法训练环境结构的隐式表示，并建立符合表示几何结构的运动生成模型。我们在多样化的室内和室外环境中广泛评估了VGER。我们展示了其从单张RGB输入图像生成符合场景捕获几何结构的平滑运动的能力。', 'title_zh': '从单张图像到基于视频生成环境的运动策略'}
{'arxiv_id': 'arXiv:2505.19215', 'title': 'Learning the Contact Manifold for Accurate Pose Estimation During Peg-in-Hole Insertion of Complex Geometries', 'authors': 'Abhay Negi, Omey M. Manyar, Dhanush Kumar Varma Penmetsa, Satyandra K. Gupta', 'link': 'https://arxiv.org/abs/2505.19215', 'abstract': 'Contact-rich assembly of complex, non-convex parts with tight tolerances remains a formidable challenge. Purely model-based methods struggle with discontinuous contact dynamics, while model-free methods require vast data and often lack precision. In this work, we introduce a hybrid framework that uses only contact-state information between a complex peg and its mating hole to recover the full SE(3) pose during assembly. In under 10 seconds of online execution, a sequence of primitive probing motions constructs a local contact submanifold, which is then aligned to a precomputed offline contact manifold to yield sub-mm and sub-degree pose estimates. To eliminate costly k-NN searches, we train a lightweight network that projects sparse contact observations onto the contact manifold and is 95x faster and 18% more accurate. Our method, evaluated on three industrially relevant geometries with clearances of 0.1-1.0 mm, achieves a success rate of 93.3%, a 4.1x improvement compared to primitive-only strategies without state estimation.', 'abstract_zh': '复杂非凸部件在紧密公差下的高接触组装仍然是一个严峻的挑战。基于纯模型的方法难以处理不连续的接触动力学，而无模型方法需要 vast 数据且通常缺乏精度。在本工作中，我们提出了一种混合框架，仅利用复杂销与配合孔之间的接触状态信息，在组装过程中恢复完整的 SE(3) 姿态。通过不到 10 秒的在线执行，一系列基本探测运动构建了一个局部接触子流形，然后将其与预先计算的离线接触流形对齐，从而获得亚毫米级和亚度级的姿态估计。为了消除昂贵的 k-NN 搜索，我们训练了一个轻量级网络，将稀疏接触观测投影到接触流形上，该网络比原始方法快 95 倍且精度高 18%。在具有 0.1-1.0 mm 间隙的三个工业相关几何形状上进行评估，该方法的成功率达到了 93.3%，比仅使用原始策略而不进行状态估计的方法提高了 4.1 倍。', 'title_zh': '学习接触流形以精确估计复杂几何结构下针入孔插入过程中的姿态'}
{'arxiv_id': 'arXiv:2505.19214', 'title': 'Omni-Perception: Omnidirectional Collision Avoidance for Legged Locomotion in Dynamic Environments', 'authors': 'Zifan Wang, Teli Ma, Yufei Jia, Xun Yang, Jiaming Zhou, Wenlong Ouyang, Qiang Zhang, Junwei Liang', 'link': 'https://arxiv.org/abs/2505.19214', 'abstract': 'Agile locomotion in complex 3D environments requires robust spatial awareness to safely avoid diverse obstacles such as aerial clutter, uneven terrain, and dynamic agents. Depth-based perception approaches often struggle with sensor noise, lighting variability, computational overhead from intermediate representations (e.g., elevation maps), and difficulties with non-planar obstacles, limiting performance in unstructured environments. In contrast, direct integration of LiDAR sensing into end-to-end learning for legged locomotion remains underexplored. We propose Omni-Perception, an end-to-end locomotion policy that achieves 3D spatial awareness and omnidirectional collision avoidance by directly processing raw LiDAR point clouds. At its core is PD-RiskNet (Proximal-Distal Risk-Aware Hierarchical Network), a novel perception module that interprets spatio-temporal LiDAR data for environmental risk assessment. To facilitate efficient policy learning, we develop a high-fidelity LiDAR simulation toolkit with realistic noise modeling and fast raycasting, compatible with platforms such as Isaac Gym, Genesis, and MuJoCo, enabling scalable training and effective sim-to-real transfer. Learning reactive control policies directly from raw LiDAR data enables the robot to navigate complex environments with static and dynamic obstacles more robustly than approaches relying on intermediate maps or limited sensing. We validate Omni-Perception through real-world experiments and extensive simulation, demonstrating strong omnidirectional avoidance capabilities and superior locomotion performance in highly dynamic environments. We will open-source our code and models.', 'abstract_zh': '敏捷运动在复杂3D环境中的要求是在确保安全的前提下避开各种障碍物，如空中的杂乱物、不规则地形以及动态代理。基于深度感知的方法往往难以应对传感器噪声、光照变化、中间表示（如高程图）带来的计算负担以及非平面障碍物的难题，这限制了其在未结构化环境中的性能。相比之下，将LiDAR传感直接集成到端到端的学习中用于足式运动的研究仍较少探讨。我们提出了一种端到端的运动策略Omni-Perception，通过直接处理原始LiDAR点云实现三维空间意识和全方位避障。其核心是PD-RiskNet（近端-远端风险意识分层级网络），一种新颖的感知模块，能够解释时空LiDAR数据以评估环境风险。为了促进有效的策略学习，我们开发了一个高保真度的LiDAR仿真工具包，具备现实的噪声建模和快速射线投射功能，兼容Isaac Gym、Genesis和MuJoCo等平台，支持可扩展的训练和有效的仿真到现实转移。直接从原始LiDAR数据中学习反应控制策略使得机器人能够更可靠地在包含静态和动态障碍的复杂环境中导航。我们通过实地实验和广泛的仿真验证了Omni-Perception，其显示出强大的全方位避障能力和在高度动态环境中的优越运动性能。我们将会开源我们的代码和模型。', 'title_zh': '全方位感知：动态环境中国脚运动的 omnidirectional 避障'}
{'arxiv_id': 'arXiv:2505.19098', 'title': 'SPADE: Towards Scalable Path Planning Architecture on Actionable Multi-Domain 3D Scene Graphs', 'authors': 'Vignesh Kottayam Viswanathan, Akash Patel, Mario Alberto Valdes Saucedo, Sumeet Satpute, Christoforos Kanellakis, George Nikolakopoulos', 'link': 'https://arxiv.org/abs/2505.19098', 'abstract': 'In this work, we introduce SPADE, a path planning framework designed for autonomous navigation in dynamic environments using 3D scene graphs. SPADE combines hierarchical path planning with local geometric awareness to enable collision-free movement in dynamic scenes. The framework bifurcates the planning problem into two: (a) solving the sparse abstract global layer plan and (b) iterative path refinement across denser lower local layers in step with local geometric scene navigation. To ensure efficient extraction of a feasible route in a dense multi-task domain scene graphs, the framework enforces informed sampling of traversable edges prior to path-planning. This removes extraneous information not relevant to path-planning and reduces the overall planning complexity over a graph. Existing approaches address the problem of path planning over scene graphs by decoupling hierarchical and geometric path evaluation processes. Specifically, this results in an inefficient replanning over the entire scene graph when encountering path obstructions blocking the original route. In contrast, SPADE prioritizes local layer planning coupled with local geometric scene navigation, enabling navigation through dynamic scenes while maintaining efficiency in computing a traversable route. We validate SPADE through extensive simulation experiments and real-world deployment on a quadrupedal robot, demonstrating its efficacy in handling complex and dynamic scenarios.', 'abstract_zh': '基于3D场景图的动态环境自主导航路径规划框架SPADE', 'title_zh': 'SPADE: 向可扩展的基于可操作多域3D场景图的路径规划架构迈进'}
{'arxiv_id': 'arXiv:2505.19086', 'title': 'MaskedManipulator: Versatile Whole-Body Control for Loco-Manipulation', 'authors': 'Chen Tessler, Yifeng Jiang, Erwin Coumans, Zhengyi Luo, Gal Chechik, Xue Bin Peng', 'link': 'https://arxiv.org/abs/2505.19086', 'abstract': "Humans interact with their world while leveraging precise full-body control to achieve versatile goals. This versatility allows them to solve long-horizon, underspecified problems, such as placing a cup in a sink, by seamlessly sequencing actions like approaching the cup, grasping, transporting it, and finally placing it in the sink. Such goal-driven control can enable new procedural tools for animation systems, enabling users to define partial objectives while the system naturally ``fills in'' the intermediate motions. However, while current methods for whole-body dexterous manipulation in physics-based animation achieve success in specific interaction tasks, they typically employ control paradigms (e.g., detailed kinematic motion tracking, continuous object trajectory following, or direct VR teleoperation) that offer limited versatility for high-level goal specification across the entire coupled human-object system. To bridge this gap, we present MaskedManipulator, a unified and generative policy developed through a two-stage learning approach. First, our system trains a tracking controller to physically reconstruct complex human-object interactions from large-scale human mocap datasets. This tracking controller is then distilled into MaskedManipulator, which provides users with intuitive control over both the character's body and the manipulated object. As a result, MaskedManipulator enables users to specify complex loco-manipulation tasks through intuitive high-level objectives (e.g., target object poses, key character stances), and MaskedManipulator then synthesizes the necessary full-body actions for a physically simulated humanoid to achieve these goals, paving the way for more interactive and life-like virtual characters.", 'abstract_zh': '人类在利用精确的全身控制与世界互动的同时，实现了多样的目标。这种多样性使他们能够通过无缝地序列化动作，如接近杯子、抓取、运输，最后将其放在水槽中，来解决长期规划的非特定问题。这样的目标导向控制可以为动画系统提供新的操作工具，使用户能够在系统自然填补中间动作的情况下定义部分目标。然而，尽管基于物理的动画中整体灵巧操作的当前方法在特定交互任务中取得了成功，它们通常采用有限的高层目标控制范式（例如，详细的运动学运动跟踪、连续的对象轨迹跟踪或直接的VR远程操作），这限制了整个人类-对象系统的高级目标说明的灵活性。为了弥合这一差距，我们提出了MaskedManipulator，这是一种通过两阶段学习方法开发出的统一生成政策。首先，我们的系统训练一个跟踪控制器，从大规模的人类捕捉数据集中物理重建复杂的交互。然后，将该跟踪控制器提炼为MaskedManipulator，为用户提供对角色身体和操作对象的直观控制。因此，MaskedManipulator使用户能够通过直观的高层目标（例如，目标物体的姿态、关键角色姿态）指定复杂的移动和操作任务，然后MaskedManipulator合成所需的整体动作，使一个物理模拟的类人形能够实现这些目标，从而为更具互动性和真实感的虚拟角色铺平了道路。', 'title_zh': 'MaskedManipulator：兼备的全身控制用于移动操作'}
{'arxiv_id': 'arXiv:2505.19080', 'title': 'ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning', 'authors': 'Tuan Van Vo, Tan Quang Nguyen, Khang Minh Nguyen, Duy Ho Minh Nguyen, Minh Nhat Vu', 'link': 'https://arxiv.org/abs/2505.19080', 'abstract': 'Vision-Language-Action (VLA) models have gained much attention from the research community thanks to their strength in translating multimodal observations with linguistic instructions into robotic actions. Despite their recent advancements, VLAs often overlook the explicit reasoning and only learn the functional input-action mappings, omitting these crucial logical steps for interpretability and generalization for complex, long-horizon manipulation tasks. In this work, we propose \\textit{ReFineVLA}, a multimodal reasoning-aware framework that fine-tunes VLAs with teacher-guided reasons. We first augment robotic datasets with reasoning rationales generated by an expert teacher model, guiding VLA models to learn to reason about their actions. Then, we use \\textit{ReFineVLA} to fine-tune pre-trained VLAs with the reasoning-enriched datasets, while maintaining their inherent generalization abilities and boosting reasoning capabilities. In addition, we conduct an attention map visualization to analyze the alignment among visual attention, linguistic prompts, and to-be-executed actions of \\textit{ReFineVLA}, showcasing its ability to focus on relevant tasks and actions. Through the latter step, we explore that \\textit{ReFineVLA}-trained models exhibit a meaningful attention shift towards relevant objects, highlighting the enhanced multimodal understanding and improved generalization.\nEvaluated across manipulation tasks, \\textit{ReFineVLA} outperforms the state-of-the-art baselines. Specifically, it achieves an average increase of $5.0\\%$ success rate on SimplerEnv WidowX Robot tasks, improves by an average of $8.6\\%$ in variant aggregation settings, and by $1.7\\%$ in visual matching settings for SimplerEnv Google Robot tasks. The source code will be publicly available.', 'abstract_zh': '一种基于教师指引推理的Vision-Language-Action (VLA) 精调框架：ReFineVLA', 'title_zh': 'ReFineVLA: 基于推理的教师指导迁移微调'}
{'arxiv_id': 'arXiv:2505.19026', 'title': 'Staircase Recognition and Location Based on Polarization Vision', 'authors': 'Weifeng Kong, Zhiying Tan', 'link': 'https://arxiv.org/abs/2505.19026', 'abstract': 'Staircase is one of the most common structures in artificial scenes. However, it is difficult for humanoid robots and people with lower limb disabilities or visual impairment to cross the scene without the help of sensors and intelligent algorithms. Staircase scene perception technology is a prerequisite for recognition and localization. This technology is of great significance for the mode switching of the robot and the calculation of the footprint position to adapt to the discontinuous terrain. However, there are still many problems that constrain the application of this technology, such as low recognition accuracy, high initial noise from sensors, unstable output signals and high computational requirements. In terms of scene reconstruction, the binocular and time of flight (TOF) reconstruction of the scene can be easily affected by environmental light and the surface material of the target object. In contrast, due to the special structure of the polarizer, the polarization can selectively transmit polarized light in a specific direction and this reconstruction method relies on the polarization information of the object surface. So the advantages of polarization reconstruction are reflected, which are less affected by environmental light and not dependent on the texture information of the object surface. In this paper, in order to achieve the detection of staircase, this paper proposes a contrast enhancement algorithm that integrates polarization and light intensity information, and integrates point cloud segmentation based on YOLOv11. To realize the high-quality reconstruction, we proposed a method of fusing polarized binocular and TOF depth information to realize the three-dimensional (3D) reconstruction of the staircase. Besides, it also proposes a joint calibration algorithm of monocular camera and TOF camera based on ICP registration and improved gray wolf optimization algorithm.', 'abstract_zh': '基于偏振与光强度信息融合的楼梯场景感知及其三维重建技术', 'title_zh': '基于偏振 vision 的楼梯识别与定位'}
{'arxiv_id': 'arXiv:2505.19017', 'title': 'WorldEval: World Model as Real-World Robot Policies Evaluator', 'authors': 'Yaxuan Li, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu', 'link': 'https://arxiv.org/abs/2505.19017', 'abstract': 'The field of robotics has made significant strides toward developing generalist robot manipulation policies. However, evaluating these policies in real-world scenarios remains time-consuming and challenging, particularly as the number of tasks scales and environmental conditions change. In this work, we demonstrate that world models can serve as a scalable, reproducible, and reliable proxy for real-world robot policy evaluation. A key challenge is generating accurate policy videos from world models that faithfully reflect the robot actions. We observe that directly inputting robot actions or using high-dimensional encoding methods often fails to generate action-following videos. To address this, we propose Policy2Vec, a simple yet effective approach to turn a video generation model into a world simulator that follows latent action to generate the robot video. We then introduce WorldEval, an automated pipeline designed to evaluate real-world robot policies entirely online. WorldEval effectively ranks various robot policies and individual checkpoints within a single policy, and functions as a safety detector to prevent dangerous actions by newly developed robot models. Through comprehensive paired evaluations of manipulation policies in real-world environments, we demonstrate a strong correlation between policy performance in WorldEval and real-world scenarios. Furthermore, our method significantly outperforms popular methods such as real-to-sim approach.', 'abstract_zh': '机器人领域的研究已经取得了显著进展，致力于开发通用机器人操作策略。然而，在实际场景中评估这些策略仍然耗费时间和具有挑战性，尤其是在任务数量增加和环境条件变化的情况下。在这项工作中，我们证明了世界模型可以作为评估真实世界机器人策略的可扩展、可再现且可靠的替代方案。一个关键挑战是生成准确反映机器人动作的策略视频。我们观察到，直接输入机器人动作或使用高维编码方法通常无法生成跟踪动作的视频。为了解决这一问题，我们提出了Policy2Vec，这是一种简单但有效的方法，将视频生成模型转换为遵循潜在动作生成机器人视频的世界模拟器。随后，我们介绍了WorldEval，这是一种全自动流水线，旨在完全在线评估真实世界机器人策略。WorldEval能有效排名各种机器人策略和单一策略内的各个检查点，并作为安全检测器，防止由新开发的机器人模型执行危险动作。通过在实际环境中对操作策略进行全面配对评估，我们证明了WorldEval中策略性能与真实世界场景之间存在强烈的相关性。此外，我们的方法在与诸如真实到模拟方法等流行方法的比较中表现出显著的优势。', 'title_zh': 'WorldEval: 世界模型作为真实世界机器人策略评估器'}
{'arxiv_id': 'arXiv:2505.18994', 'title': 'Designing Pin-pression Gripper and Learning its Dexterous Grasping with Online In-hand Adjustment', 'authors': 'Hewen Xiao, Xiuping Liu, Hang Zhao, Jian Liu, Kai Xu', 'link': 'https://arxiv.org/abs/2505.18994', 'abstract': "We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the gripper to instantaneously customize its finger's shape to conform to the object being grasped by dynamically adjusting the extension/retraction of the pins. In addition, the gripper excels in in-hand re-orientation of objects for enhanced grasping stability again via dynamically adjusting the pins. To learn the dynamic grasping skills of pin-pression grippers, we devise a dedicated reinforcement learning algorithm with careful designs of state representation and reward shaping. To achieve a more efficient grasp-while-lift grasping mode, we propose a curriculum learning scheme. Extensive evaluations demonstrate that our design, together with the learned skills, leads to highly flexible and robust grasping with much stronger generality to unseen objects than alternatives. We also highlight encouraging physical results of sim-to-real transfer on a physically manufactured pin-pression gripper, demonstrating the practical significance of our novel gripper design and grasping skill. Demonstration videos for this paper are available at this https URL.", 'abstract_zh': '基于 pin-pression 玩具启发的并指夹持器新型设计及动态抓取技能学习', 'title_zh': '设计针压式夹持器并实现其灵巧抓取的在线手内调整方法'}
{'arxiv_id': 'arXiv:2505.18876', 'title': 'DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets', 'authors': 'Maria Makarova, Qian Liu, Dzmitry Tsetserukou', 'link': 'https://arxiv.org/abs/2505.18876', 'abstract': 'Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data limitations and scenario-specific adaptation needs. In this paper, we address these challenges by proposing an optimized approach to training diffusion policies using large, pre-built datasets that are enhanced using Reinforcement Learning (RL). Our end-to-end pipeline leverages RL-based enhancement of the DexGraspNet dataset, lightweight diffusion policy training on a dexterous manipulation task for a five-fingered robotic hand, and a pose sampling algorithm for validation. The pipeline achieved a high success rate of 80% for three DexGraspNet objects. By eliminating manual data collection, our approach lowers barriers to adopting diffusion models in robotics, enhancing generalization and robustness for real-world applications.', 'abstract_zh': '扩散模型已在图像、视频和音频生成等领域成功应用。 recent works 展示了其在序列决策和灵巧操作方面的潜力，利用其建模复杂动作分布的能力。然而，由于数据限制和场景特定的适应需求，仍存在诸多挑战。本文通过提出一种使用增强学习(Reinforcement Learning, RL)增强的大型预构建数据集训练扩散政策的方法，来应对这些挑战。我们的端到端管道包括基于RL增强的DexGraspNet数据集、五指机器人手的灵巧操作任务中轻量级扩散策略训练以及姿态采样算法进行验证。该管道在三个DexGraspNet对象上实现了80%的高成功率。通过消除手动数据收集，我们的方法降低了在机器人中采用扩散模型的门槛，增强了现实世界应用中的泛化能力和鲁棒性。', 'title_zh': 'DiffusionRL：用于使用RL适配的大规模数据集进行机器人抓取的扩散政策高效训练'}
{'arxiv_id': 'arXiv:2505.18858', 'title': 'Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning', 'authors': 'Maeva Guerrier, Karthik Soma, Hassan Fouad, Giovanni Beltrame', 'link': 'https://arxiv.org/abs/2505.18858', 'abstract': 'Safety stands as the primary obstacle preventing the widespread adoption of learning-based robotic systems in our daily lives. While reinforcement learning (RL) shows promise as an effective robot learning paradigm, conventional RL frameworks often model safety by using single scalar negative rewards with immediate episode termination, failing to capture the temporal consequences of unsafe actions (e.g., sustained collision damage). In this work, we introduce a novel approach that simulates these temporal effects by applying continuous negative rewards without episode termination. Our experiments reveal that standard RL methods struggle with this model, as the accumulated negative values in unsafe zones create learning barriers. To address this challenge, we demonstrate how Control Barrier Functions (CBFs), with their proven safety guarantees, effectively help robots avoid catastrophic regions while enhancing learning outcomes. We present three CBF-based approaches, each integrating traditional RL methods with Control Barrier Functions, guiding the agent to learn safe behavior. Our empirical analysis, conducted in both simulated environments and real-world settings using a four-wheel differential drive robot, explores the possibilities of employing these approaches for safe robotic learning.', 'abstract_zh': '基于学习的机器人系统在日常生活中的广泛应用主要受安全问题的阻碍。虽然强化学习（RL）显示出作为有效的机器人学习范式的潜力，但传统的RL框架通常通过使用即时集合法行为单个负奖赏来建模安全问题，未能捕捉到不安全行为的时序后果（例如，持续碰撞损坏）。在本文中，我们提出了一种新颖的方法，通过应用连续的负奖赏而不终止集合法行为模拟这些时序效应。实验结果表明，标准的RL方法难以应对这种模型，因为不安全区域累积的负价值造成了学习障碍。为了应对这一挑战，我们展示了如何通过具有已证明的安全保证的控制屏障函数（CBFs）有效地帮助机器人避免灾难性区域，同时增强学习效果。我们提出了三种基于CBF的方法，将传统的RL方法与控制屏障函数结合起来，引导代理学习安全行为。我们在模拟环境和使用四轮差速驱动机器人的实际场景下进行了经验分析，探讨了这些方法在安全机器人学习中的应用可能性。', 'title_zh': '沿着界限引导：控制屏障函数作为机器人学习的安全教练'}
{'arxiv_id': 'arXiv:2505.18793', 'title': 'Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance', 'authors': 'Wenhao Wang, Jianheng Song, Chiming Liu, Jiayao Ma, Siyuan Feng, Jingyuan Wang, Yuxin Jiang, Kylin Chen, Sikang Zhan, Yi Wang, Tong Meng, Modi Shi, Xindong He, Guanghui Ren, Yang Yang, Maoqing Yao', 'link': 'https://arxiv.org/abs/2505.18793', 'abstract': "While Vision-Language-Action (VLA) models show strong generalizability in various tasks, real-world deployment of robotic policy still requires large-scale, high-quality human expert demonstrations. However, passive data collection via human teleoperation is costly, hard to scale, and often biased toward passive demonstrations with limited diversity. To address this, we propose Genie Centurion (GCENT), a scalable and general data collection paradigm based on human rewind-and-refine guidance. When the robot execution failures occur, GCENT enables the system revert to a previous state with a rewind mechanism, after which a teleoperator provides corrective demonstrations to refine the policy. This framework supports a one-human-to-many-robots supervision scheme with a Task Sentinel module, which autonomously predicts task success and solicits human intervention when necessary, enabling scalable supervision. Empirical results show that GCENT achieves up to 40% higher task success rates than state-of-the-art data collection methods, and reaches comparable performance using less than half the data. We also quantify the data yield-to-effort ratio under multi-robot scenarios, demonstrating GCENT's potential for scalable and cost-efficient robot policy training in real-world environments.", 'abstract_zh': '基于人类重演与精炼指导的大规模通用数据收集范式：Genie Centurion', 'title_zh': 'genie 哲人：通过人类回放并修正指导加速可扩展的实际机器人训练'}
{'arxiv_id': 'arXiv:2505.18792', 'title': 'On the Dual-Use Dilemma in Physical Reasoning and Force', 'authors': 'William Xie, Enora Rice, Nikolaus Correll', 'link': 'https://arxiv.org/abs/2505.18792', 'abstract': 'Humans learn how and when to apply forces in the world via a complex physiological and psychological learning process. Attempting to replicate this in vision-language models (VLMs) presents two challenges: VLMs can produce harmful behavior, which is particularly dangerous for VLM-controlled robots which interact with the world, but imposing behavioral safeguards can limit their functional and ethical extents. We conduct two case studies on safeguarding VLMs which generate forceful robotic motion, finding that safeguards reduce both harmful and helpful behavior involving contact-rich manipulation of human body parts. Then, we discuss the key implication of this result--that value alignment may impede desirable robot capabilities--for model evaluation and robot learning.', 'abstract_zh': '人类通过复杂的生理和心理学习过程学会如何以及何时在世界中应用力。试图在视觉-语言模型（VLMs）中复制这一过程面临着两大挑战：VLMs可能会产生有害行为，这对与世界互动的VLM控制的机器人尤其危险，但施加行为防护可能会限制其功能和伦理范围。我们对生成 Powerful 动作的 VLMs 进行了两项防护案例研究，发现防护措施会减少涉及人体部位接触性操作的有害和有益行为。然后，我们讨论了这一结果的关键含义——价值观对齐可能会阻碍 desirable 机器人能力，这对于模型评估和机器人学习具有重要意义。', 'title_zh': '物理推理与力的双重用途困境'}
{'arxiv_id': 'arXiv:2505.18780', 'title': 'One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion', 'authors': 'Yahao Fan, Tianxiang Gui, Kaiyang Ji, Shutong Ding, Chixuan Zhang, Jiayuan Gu, Jingyi Yu, Jingya Wang, Ye Shi', 'link': 'https://arxiv.org/abs/2505.18780', 'abstract': 'Humanoid locomotion faces a critical scalability challenge: traditional reinforcement learning (RL) methods require task-specific rewards and struggle to leverage growing datasets, even as more training terrains are introduced. We propose DreamPolicy, a unified framework that enables a single policy to master diverse terrains and generalize zero-shot to unseen scenarios by systematically integrating offline data and diffusion-driven motion synthesis. At its core, DreamPolicy introduces Humanoid Motion Imagery (HMI) - future state predictions synthesized through an autoregressive terrain-aware diffusion planner curated by aggregating rollouts from specialized policies across various distinct terrains. Unlike human motion datasets requiring laborious retargeting, our data directly captures humanoid kinematics, enabling the diffusion planner to synthesize "dreamed" trajectories that encode terrain-specific physical constraints. These trajectories act as dynamic objectives for our HMI-conditioned policy, bypassing manual reward engineering and enabling cross-terrain generalization. DreamPolicy addresses the scalability limitations of prior methods: while traditional RL fails to exploit growing datasets, our framework scales seamlessly with more offline data. As the dataset expands, the diffusion prior learns richer locomotion skills, which the policy leverages to master new terrains without retraining. Experiments demonstrate that DreamPolicy achieves average 90% success rates in training environments and an average of 20% higher success on unseen terrains than the prevalent method. It also generalizes to perturbed and composite scenarios where prior approaches collapse. By unifying offline data, diffusion-based trajectory synthesis, and policy optimization, DreamPolicy overcomes the "one task, one policy" bottleneck, establishing a paradigm for scalable, data-driven humanoid control.', 'abstract_zh': 'DreamPolicy：统一框架实现多样化地形的单策略零样本泛化', 'title_zh': '一策万用：一种可扩展的通用 humanoid 行走策略'}
{'arxiv_id': 'arXiv:2505.18732', 'title': 'Mobile Manipulation Planning for Tabletop Rearrangement', 'authors': 'Jiaming Hu, Jiawei Wang, Henrik I Christensen', 'link': 'https://arxiv.org/abs/2505.18732', 'abstract': 'Efficient tabletop rearrangement planning seeks to find high-quality solutions while minimizing total cost. However, the task is challenging due to object dependencies and limited buffer space for temporary placements. The complexity increases for mobile robots, which must navigate around the table with restricted access. A*-based methods yield high-quality solutions, but struggle to scale as the number of objects increases. Monte Carlo Tree Search (MCTS) has been introduced as an anytime algorithm, but its convergence speed to high-quality solutions remains slow. Previous work~\\cite{strap2024} accelerated convergence but required the robot to move to the closest position to the object for each pick and place operation, leading to inefficiencies. To address these limitations, we extend the planner by introducing a more efficient strategy for mobile robots. Instead of selecting the nearest available location for each action, our approach allows multiple operations (e.g., pick-and-place) from a single standing position, reducing unnecessary movement. Additionally, we incorporate state re-exploration to further improve plan quality. Experimental results show that our planner outperforms existing planners both in terms of solution quality and planning time.', 'abstract_zh': '桌面布局高效规划旨在找到高质量解决方案的同时最小化总成本。但由于对象依赖性和有限的临时放置缓冲空间，该任务极具挑战性。对于移动机器人来说，任务更为复杂，因为它们必须在有限的访问范围内导航。基于A*的方法能够提供高质量的解决方案，但随着物体数量的增加，难以扩展。蒙特卡洛树搜索（MCTS）作为一种随时可用的算法被引入，但其收敛到高质量解决方案的速度仍然较慢。先前的工作~\\cite{strap2024}加速了收敛速度，但要求机器人在每次抓取和放置操作时移动到物体的最接近位置，导致效率低下。为解决这些限制，我们通过引入一种更高效的移动机器人策略来扩展规划器。我们的方法允许从单个站立位置执行多个操作（例如抓取-放置），从而减少不必要的移动。此外，我们还引入了状态重新探索，以进一步提高规划质量。实验结果表明，我们的规划器在解决方案质量和规划时间方面均优于现有规划器。', 'title_zh': '桌面重排中的移动 manipulate 计划'}
{'arxiv_id': 'arXiv:2505.18719', 'title': 'VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning', 'authors': 'Guanxing Lu, Wenkai Guo, Chubin Zhang, Yuheng Zhou, Haonan Jiang, Zifeng Gao, Yansong Tang, Ziwei Wang', 'link': 'https://arxiv.org/abs/2505.18719', 'abstract': 'Recent high-capacity vision-language-action (VLA) models have demonstrated impressive performance on a range of robotic manipulation tasks by imitating human demonstrations. However, exploiting offline data with limited visited states will cause execution failure in out-of-distribution scenarios. Intuitively, an exploration-based method that improves on online collected data at test time could address this limitation. We present VLA-RL, an algorithmic and systematic framework that leverages online reinforcement learning (RL) to improve pretrained auto-regressive VLAs in downstream tasks. Within a unified perspective, we first introduce a trajectory-level RL formulation for auto-regressive VLA training, which models general robotic manipulation trajectory as multi-modal multi-turn conversation. To address the challenge of sparse rewards, we fine-tune a pretrained vision-language model as a robotic process reward model, which is trained on pseudo reward labels annotated on automatically extracted task segments. To scale up, we identify several implementation findings that improve the stability and efficiency including curriculum selection strategy, GPU-balanced vectorized environments, batch decoding, and critic warmup. VLA-RL enables OpenVLA-7B to surpass the strongest finetuned baseline by 4.5% on 40 challenging robotic manipulation tasks in LIBERO, and even matches the performance of advanced commercial models such as $\\pi_0$-FAST. Notably, we observe that VLA-RL benefits from increased test-time optimization, indicating an early spark of inference scaling laws in robotics.', 'abstract_zh': 'Recent High-Capacity Vision-Language-Action (VLA) Models Leveraging Online Reinforcement Learning for Improved Robotic Manipulation Tasks', 'title_zh': 'VLA-RL：基于可扩展强化学习的-masterful和通用机器人操作研究'}
{'arxiv_id': 'arXiv:2505.18714', 'title': 'YOPO-Rally: A Sim-to-Real Single-Stage Planner for Off-Road Terrain', 'authors': 'Hongyu Cao, Junjie Lu, Xuewei Zhang, Yulin Hui, Zhiyu Li, Bailing Tian', 'link': 'https://arxiv.org/abs/2505.18714', 'abstract': 'Off-road navigation remains challenging for autonomous robots due to the harsh terrain and clustered obstacles. In this letter, we extend the YOPO (You Only Plan Once) end-to-end navigation framework to off-road environments, explicitly focusing on forest terrains, consisting of a high-performance, multi-sensor supported off-road simulator YOPO-Sim, a zero-shot transfer sim-to-real planner YOPO-Rally, and an MPC controller. Built on the Unity engine, the simulator can generate randomized forest environments and export depth images and point cloud maps for expert demonstrations, providing competitive performance with mainstream simulators. Terrain Traversability Analysis (TTA) processes cost maps, generating expert trajectories represented as non-uniform cubic Hermite curves. The planner integrates TTA and the pathfinding into a single neural network that inputs the depth image, current velocity, and the goal vector, and outputs multiple trajectory candidates with costs. The planner is trained by behavior cloning in the simulator and deployed directly into the real-world without fine-tuning. Finally, a series of simulated and real-world experiments is conducted to validate the performance of the proposed framework.', 'abstract_zh': '自主机器人在越野环境中的导航仍面临严峻挑战，尤其是在复杂地形和密集障碍物的条件下。本文将YOPO（You Only Plan Once）端到端导航框架扩展至越野环境，特别关注森林地形，该框架包含高性能多传感器支持的越野模拟器YOPO-Sim、零样本迁移模拟到现实的规划器YOPO-Rally以及一个模型预测控制控制器。基于Unity引擎构建的模拟器可生成随机化的森林环境，并导出深度图像和点云地图供专家演示使用，性能可与主流模拟器媲美。地形可穿越性分析（TTA）处理成本地图，生成以非均匀三次海明曲线表示的专家轨迹。规划器将TTA和路径寻找到一个神经网络中，该网络输入深度图像、当前速度和目标向量，输出具有成本的多个轨迹候选方案。规划器在模拟器中通过行为克隆进行训练，并直接部署到现实世界中，无需微调。最后，进行了一系列模拟和现实世界的实验以验证所提出框架的性能。', 'title_zh': 'YOPO-Rally：一种用于非道路地形的单阶段模拟到现实规划器'}
{'arxiv_id': 'arXiv:2505.18691', 'title': 'Coordinated guidance and control for multiple parafoil system landing', 'authors': 'Zhenyu Wei, Zhijiang Shao, Lorenz T. Biegler', 'link': 'https://arxiv.org/abs/2505.18691', 'abstract': 'Multiple parafoil landing is an enabling technology for massive supply delivery missions. However, it is still an open question to design a collision-free, computation-efficient guidance and control method for unpowered parafoils. To address this issue, this paper proposes a coordinated guidance and control method for multiple parafoil landing. First, the multiple parafoil landing process is formulated as a trajectory optimization problem. Then, the landing point allocation algorithm is designed to assign the landing point to each parafoil. In order to guarantee flight safety, the collision-free trajectory replanning algorithm is designed. On this basis, the nonlinear model predictive control algorithm is adapted to leverage the nonlinear dynamics model for trajectory tracking. Finally, the parafoil kinematic model is utilized to reduce the computational burden of trajectory calculation, and kinematic model is updated by the moving horizon correction algorithm to improve the trajectory accuracy. Simulation results demonstrate the effectiveness and computational efficiency of the proposed coordinated guidance and control method for the multiple parafoil landing.', 'abstract_zh': '多副伞降落协调引导与控制方法研究', 'title_zh': '多伞系统着陆的协同指导与控制'}
{'arxiv_id': 'arXiv:2505.18661', 'title': 'Supporting Preschool Emotional Development with AI-Powered Robots', 'authors': 'Santiago Berrezueta-Guzman, María Dolón-Poza, Stefan Wagner', 'link': 'https://arxiv.org/abs/2505.18661', 'abstract': "This study evaluates the integration of AI-powered robots in early childhood education, focusing on their impact on emotional self-regulation, engagement, and collaborative skills. A ten-week experimental design involving two groups of children assessed the robot's effectiveness through progress assessments, parental surveys, and teacher feedback. Results demonstrated that early exposure to the robot significantly enhanced emotional recognition, while sustained interaction further improved collaborative and social engagement. Parental and teacher feedback highlighted high acceptance levels, emphasizing the robot's ease of integration and positive influence on classroom dynamics. This research underscores the transformative potential of AI and robotics in education. The findings advocate for the broader adoption of AI-powered interventions, carefully examining equitable access, ethical considerations, and sustainable implementation. This work sets a foundation for exploring long-term impacts and expanding applications of AI in inclusive and impactful educational settings.", 'abstract_zh': '本研究评估了人工智能驱动的机器人在幼儿教育中的整合，重点在于探究其对情绪自我调节、参与度和协作能力的影响。通过为期十周的实验设计，对两组儿童进行评估，分析机器人效果，结果表明，早期接触机器人显著增强了情绪识别能力，持续互动进一步提升了协作能力和社交参与度。家长和教师反馈显示，机器人具有较高的接受度，并对其易于整合和对课堂教学动态的积极影响给予了高度评价。本研究强调了人工智能和机器人技术在教育领域的转型潜力。研究结果倡导更广泛采用人工智能干预措施，同时小心审视公平获取、伦理考量和可持续实施等问题。本研究为探索人工智能在包容性和影响深远的教学环境中的长期影响及其更广泛应用奠定了基础。', 'title_zh': '基于人工智能驱动的机器人支持学前教育情感发展'}
{'arxiv_id': 'arXiv:2505.18631', 'title': 'S2R-Bench: A Sim-to-Real Evaluation Benchmark for Autonomous Driving', 'authors': 'Li Wang, Guangqi Yang, Lei Yang, Ziying Song, Xinyu Zhang, Ying Chen, Lin Liu, Junjie Gao, Zhiwei Li, Qingshan Yang, Jun Li, Liangliang Wang, Wenhao Yu, Bin Xu, Weida Wang, Huaping Liu', 'link': 'https://arxiv.org/abs/2505.18631', 'abstract': 'Safety is a long-standing and the final pursuit in the development of autonomous driving systems, with a significant portion of safety challenge arising from perception. How to effectively evaluate the safety as well as the reliability of perception algorithms is becoming an emerging issue. Despite its critical importance, existing perception methods exhibit a limitation in their robustness, primarily due to the use of benchmarks are entierly simulated, which fail to align predicted results with actual outcomes, particularly under extreme weather conditions and sensor anomalies that are prevalent in real-world scenarios. To fill this gap, in this study, we propose a Sim-to-Real Evaluation Benchmark for Autonomous Driving (S2R-Bench). We collect diverse sensor anomaly data under various road conditions to evaluate the robustness of autonomous driving perception methods in a comprehensive and realistic manner. This is the first corruption robustness benchmark based on real-world scenarios, encompassing various road conditions, weather conditions, lighting intensities, and time periods. By comparing real-world data with simulated data, we demonstrate the reliability and practical significance of the collected data for real-world applications. We hope that this dataset will advance future research and contribute to the development of more robust perception models for autonomous driving. This dataset is released on this https URL.', 'abstract_zh': '自动驾驶领域中从感知角度出发的安全性长期且最终的追求目标，现有感知方法在鲁棒性方面存在局限，这主要是由于使用完全模拟的基准进行评估，导致预测结果与实际结果不一致，尤其是在极端天气条件和传感器异常等真实场景中常见的情况下。为填补这一缺口，本研究提出了一种自动驾驶模拟到现实的评估基准（S2R-Bench）。我们收集了在各种道路条件下出现的多元传感器异常数据，以全面而现实的方式评估自动驾驶感知方法的鲁棒性。这是首个基于真实场景的抗污染鲁棒性基准，涵盖多种道路条件、天气条件、光照强度和时间周期。通过将现实数据与模拟数据进行对比，我们展示了所收集数据的可靠性和实际应用意义。我们希望这一数据集能促进未来的研究，并有助于开发更具鲁棒性的自动驾驶感知模型。该数据集在此处发布：https://url.com', 'title_zh': 'S2R-Bench: 从模拟到现实的自动驾驶评估基准'}
{'arxiv_id': 'arXiv:2505.18590', 'title': 'Optimization-Based Trajectory Planning for Tractor-Trailer Vehicles on Curvy Roads: A Progressively Increasing Sampling Number Method', 'authors': 'Zehao Wang, Han Zhang, Jingchuan Wang, Weidong Chen', 'link': 'https://arxiv.org/abs/2505.18590', 'abstract': "In this work, we propose an optimization-based trajectory planner for tractor-trailer vehicles on curvy roads. The lack of analytical expression for the trailer's errors to the center line pose a great challenge to the trajectory planning for tractor-trailer vehicles. To address this issue, we first use geometric representations to characterize the lateral and orientation errors in Cartesian frame, where the errors would serve as the components of the cost function and the road edge constraints within our optimization process. Next, we generate a coarse trajectory to warm-start the subsequent optimization problems. On the other hand, to achieve a good approximation of the continuous-time kinematics, optimization-based methods usually discretize the kinematics with a large sampling number. This leads to an increase in the number of the variables and constraints, thus making the optimization problem difficult to solve. To address this issue, we design a Progressively Increasing Sampling Number Optimization (PISNO) framework. More specifically, we first find a nearly feasible trajectory with a small sampling number to warm-start the optimization process. Then, the sampling number is progressively increased, and the corresponding intermediate Optimal Control Problem (OCP) is solved in each iteration. Next, we further resample the obtained solution into a finer sampling period, and then use it to warm-start the intermediate OCP in next iteration. This process is repeated until reaching a threshold sampling number. Simulation and experiment results show the proposed method exhibits a good performance and less computational consumption over the benchmarks.", 'abstract_zh': '基于优化的曲线路况下挂车车辆轨迹规划方法', 'title_zh': '基于优化的曲线路段铰接车辆轨迹规划：递增采样数量方法'}
{'arxiv_id': 'arXiv:2505.18490', 'title': 'An Inertial Sequence Learning Framework for Vehicle Speed Estimation via Smartphone IMU', 'authors': 'Xuan Xiao, Xiaotong Ren, Haitao Li', 'link': 'https://arxiv.org/abs/2505.18490', 'abstract': "Accurately estimating vehicle velocity via smartphone is critical for mobile navigation and transportation. This paper introduces a cutting-edge framework for velocity estimation that incorporates temporal learning models, utilizing Inertial Measurement Unit (IMU) data and is supervised by Global Navigation Satellite System (GNSS) information. The framework employs a noise compensation network to fit the noise distribution between sensor measurements and actual motion, and a pose estimation network to align the coordinate systems of the phone and the vehicle. To enhance the model's generalizability, a data augmentation technique that mimics various phone placements within the car is proposed. Moreover, a new loss function is designed to mitigate timestamp mismatches between GNSS and IMU signals, effectively aligning the signals and improving the velocity estimation accuracy. Finally, we implement a highly efficient prototype and conduct extensive experiments on a real-world crowdsourcing dataset, resulting in superior accuracy and efficiency.", 'abstract_zh': '基于智能手机的车辆速度准确估计对于移动导航和交通至关重要。本文介绍了一种结合时间学习模型的先进框架，该框架利用惯性测量单元（IMU）数据，并由全球导航卫星系统（GNSS）信息监督。该框架采用噪声补偿网络来拟合传感器测量值与实际运动之间的噪声分布，并采用姿态估计网络对齐手机和车辆的坐标系统。为了增强模型的泛化能力，提出了模拟车内不同手机放置方式的数据增强技术。此外，设计了一种新的损失函数来缓解GNSS和IMU信号之间的时间戳不匹配，有效地对齐信号并提高速度估计准确性。最后，我们实现了一个高效的原型并在真实世界的众包数据集上进行了广泛的实验，结果表明其具有更高的准确性和效率。', 'title_zh': '基于智能手机IMU的车辆速度估计惯性序列学习框架'}
{'arxiv_id': 'arXiv:2505.18487', 'title': 'Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning', 'authors': 'Junlin Wang, Zhiyun Lin', 'link': 'https://arxiv.org/abs/2505.18487', 'abstract': 'Learning effective visual representations for robotic manipulation remains a fundamental challenge due to the complex body dynamics involved in action execution. In this paper, we study how visual representations that carry body-relevant cues can enable efficient policy learning for downstream robotic manipulation tasks. We present $\\textbf{I}$nter-token $\\textbf{Con}$trast ($\\textbf{ICon}$), a contrastive learning method applied to the token-level representations of Vision Transformers (ViTs). ICon enforces a separation in the feature space between agent-specific and environment-specific tokens, resulting in agent-centric visual representations that embed body-specific inductive biases. This framework can be seamlessly integrated into end-to-end policy learning by incorporating the contrastive loss as an auxiliary objective. Our experiments show that ICon not only improves policy performance across various manipulation tasks but also facilitates policy transfer across different robots. The project website: this https URL', 'abstract_zh': '学习有效的视觉表示以实现机器人操作仍是一项基本挑战，因为其中涉及复杂的身体动力学。在本文中，我们探讨了如何通过携带与身体相关的线索的视觉表示来实现下游机器人操作任务的高效策略学习。我们提出了基于Vision Transformers（ViTs）令牌级表示的$\\textbf{I}$nter-token $\\textbf{Con}$trast ($\\textbf{ICon}$)对比学习方法。ICon在特征空间中强制分离代理特异性和环境特异性的令牌，从而生成以代理为中心的视觉表示，其中嵌入了身体特异性的归纳偏置。此框架可以通过将对比损失纳入辅助目标无缝集成到端到端策略学习中。我们的实验表明，ICon不仅在各种操作任务中提高了策略性能，还促进了不同机器人之间的策略转移。项目网站: this https URL。', 'title_zh': '将身体意识嵌入视觉表示以实现高效的策略学习'}
{'arxiv_id': 'arXiv:2505.18474', 'title': 'Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy', 'authors': 'Zhiyuan Zhang, Zhengtong Xu, Jai Nanda Lakamsani, Yu She', 'link': 'https://arxiv.org/abs/2505.18474', 'abstract': 'Visual Imitation learning has achieved remarkable progress in robotic manipulation, yet generalization to unseen objects, scene layouts, and camera viewpoints remains a key challenge. Recent advances address this by using 3D point clouds, which provide geometry-aware, appearance-invariant representations, and by incorporating equivariance into policy architectures to exploit spatial symmetries. However, existing equivariant approaches often lack interpretability and rigor due to unstructured integration of equivariant components. We introduce canonical policy, a principled framework for 3D equivariant imitation learning that unifies 3D point cloud observations under a canonical representation. We first establish a theory of 3D canonical representations, enabling equivariant observation-to-action mappings by grouping both in-distribution and out-of-distribution point clouds to a canonical representation. We then propose a flexible policy learning pipeline that leverages geometric symmetries from canonical representation and the expressiveness of modern generative models. We validate canonical policy on 12 diverse simulated tasks and 4 real-world manipulation tasks across 16 configurations, involving variations in object color, shape, camera viewpoint, and robot platform. Compared to state-of-the-art imitation learning policies, canonical policy achieves an average improvement of 18.0% in simulation and 37.6% in real-world experiments, demonstrating superior generalization capability and sample efficiency. For more details, please refer to the project website: this https URL.', 'abstract_zh': 'Visual模仿学习已经在机器人操作方面取得了显著进展，但将其推广到未见过的对象、场景布局和相机视角仍是一项关键挑战。近期进展通过使用3D点云解决这一问题，3D点云提供了几何感知且外观不变的表示，并通过将等变性融入策略架构中利用空间对称性。然而，现有的等变方法由于未结构化的等变组件集成往往缺乏可解释性和严谨性。我们引入了典范策略，这是一种 principled 的3D等变模仿学习框架，统一了3D点云观测的典范表示。我们首先建立了3D典范表示的理论，通过将分布内和分布外的点云归一化到一个典范表示，从而实现等变的观测到行为映射。随后，我们提出了一种灵活的策略学习管道，利用典范表示中的几何对称性以及现代生成模型的表达能力。我们在12个模拟任务和4个真实世界操作任务的16种配置中验证了典范策略，这些配置涉及对象颜色、形状、相机视角和机器人平台的差异。与最先进的模仿学习策略相比，典范策略在模拟实验中平均改进了18.0%，在真实世界实验中改进了37.6%，表现出更强的推广能力和样本效率。更多信息，请参见项目网站：this https URL。', 'title_zh': '标准策略：学习等变政策的标准3D表示'}
{'arxiv_id': 'arXiv:2505.18472', 'title': 'ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning', 'authors': 'Quan Khanh Luu, Pokuang Zhou, Zhengtong Xu, Zhiyuan Zhang, Qiang Qiu, Yu She', 'link': 'https://arxiv.org/abs/2505.18472', 'abstract': "Supervised visuomotor policies have shown strong performance in robotic manipulation but often struggle in tasks with limited visual input, such as operations in confined spaces, dimly lit environments, or scenarios where perceiving the object's properties and state is critical for task success. In such cases, tactile feedback becomes essential for manipulation. While the rapid progress of supervised visuomotor policies has benefited greatly from high-quality, reproducible simulation benchmarks in visual imitation, the visuotactile domain still lacks a similarly comprehensive and reliable benchmark for large-scale and rigorous evaluation. To address this, we introduce ManiFeel, a reproducible and scalable simulation benchmark for studying supervised visuotactile manipulation policies across a diverse set of tasks and scenarios. ManiFeel presents a comprehensive benchmark suite spanning a diverse set of manipulation tasks, evaluating various policies, input modalities, and tactile representation methods. Through extensive experiments, our analysis reveals key factors that influence supervised visuotactile policy learning, identifies the types of tasks where tactile sensing is most beneficial, and highlights promising directions for future research in visuotactile policy learning. ManiFeel aims to establish a reproducible benchmark for supervised visuotactile policy learning, supporting progress in visuotactile manipulation and perception. To facilitate future research and ensure reproducibility, we will release our codebase, datasets, training logs, and pretrained checkpoints. Please visit the project website for more details: this https URL", 'abstract_zh': '监督视觉-运动策略在机器人操作任务中表现强劲，但在视觉输入有限的任务中往往表现不佳，如受限空间操作、光线不足的环境中，或需要感知物体特性和状态才能成功完成任务的场景。在这种情况下，触觉反馈对于操作变得至关重要。尽管监督视觉-运动策略的快速发展得益于视觉模仿中的高质量、可重复的仿真基准，但在触觉-视觉领域仍缺乏类似全面和可靠的基准，用于大规模和严格的评估。为解决这一问题，我们引入了ManiFeel，一个可重复且可扩展的仿真基准，用于跨多种任务和场景研究监督触觉-视觉操作策略。ManiFeel提供了一个涵盖广泛操作任务的基准套件，评估各种策略、输入模态和触觉表示方法。通过大量实验，我们的分析揭示了影响监督触觉-视觉策略学习的关键因素，确定了触觉传感最为有益的任务类型，并指出了触觉策略学习未来研究的有希望方向。ManiFeel旨在建立一个监督触觉-视觉策略学习的可重复基准，促进触觉-视觉操作和感知的进步。为了便于未来研究并确保可重复性，我们将公开我们的代码库、数据集、训练日志和预训练检查点。更多详情请访问项目网站：this https URL。', 'title_zh': 'ManiFeel：评估与理解基于视觉-触觉操控策略学习'}
{'arxiv_id': 'arXiv:2505.18437', 'title': 'Curio: A Cost-Effective Solution for Robotics Education', 'authors': 'Talha Enes Ayranci, Florent P. Audonnet, Gerardo Aragon-Camarasa, Mireilla Bikanga Ada, Jonathan Grizou', 'link': 'https://arxiv.org/abs/2505.18437', 'abstract': 'Student engagement is one of the key challenges in robotics and artificial intelligence (AI) education. Tangible learning approaches, such as educational robots, provide an effective way to enhance engagement and learning by offering real-world applications to bridge the gap between theory and practice. However, existing platforms often face barriers such as high cost or limited capabilities. In this paper, we present Curio, a cost-effective, smartphone-integrated robotics platform designed to lower the entry barrier to robotics and AI education. With a retail price below $50, Curio is more affordable than similar platforms. By leveraging smartphones, Curio eliminates the need for onboard processing units, dedicated cameras, and additional sensors while maintaining the ability to perform AI-based tasks. To evaluate the impact of Curio on student engagement, we conducted a case study with 20 participants, where we examined usability, engagement, and potential for integrating into AI and robotics education. The results indicate high engagement and motivation levels across all participants. Additionally, 95% of participants reported an improvement in their understanding of robotics. Findings suggest that using a robotic system such as Curio can enhance engagement and hands-on learning in robotics and AI education. All resources and projects with Curio are available at this http URL.', 'abstract_zh': '机器人与人工智能教育中学生参与度是关键挑战。感性化学习方法，如教育机器人，通过提供现实应用来弥合理论与实践之间的差距，有效提升了参与度和学习效果。然而，现有平台常常面临成本高或能力有限的障碍。在本文中，我们介绍了Curio，这是一种低成本的智能手机集成机器人平台，旨在降低参与机器人与人工智能教育的门槛。Curio的零售价低于50美元，比类似平台更具成本效益。通过利用智能手机，Curio消除了对内置处理单元、专用摄像头和附加传感器的需求，同时保持了执行人工智能任务的能力。为了评估Curio对学生参与度的影响，我们对20名参与者进行了案例研究，考察了其实用性、参与度及融入人工智能与机器人教育的潜力。结果表明，所有参与者的参与度和动机都很高。此外，95%的参与者报告说对机器人技术的理解有所提高。研究结果表明，使用如Curio这样的机器人系统可以提高机器人与人工智能教育中的参与度和动手学习体验。所有与Curio相关的资源和项目均可通过以下链接访问。', 'title_zh': 'Curio：一种低成本的机器人教育解决方案'}
{'arxiv_id': 'arXiv:2505.18429', 'title': 'HACL: History-Aware Curriculum Learning for Fast Locomotion', 'authors': 'Prakhar Mishra, Amir Hossain Raj, Xuesu Xiao, Dinesh Manocha', 'link': 'https://arxiv.org/abs/2505.18429', 'abstract': 'We address the problem of agile and rapid locomotion, a key characteristic of quadrupedal and bipedal robots. We present a new algorithm that maintains stability and generates high-speed trajectories by considering the temporal aspect of locomotion. Our formulation takes into account past information based on a novel history-aware curriculum Learning (HACL) algorithm. We model the history of joint velocity commands with respect to the observed linear and angular rewards using a recurrent neural net (RNN). The hidden state helps the curriculum learn the relationship between the forward linear velocity and angular velocity commands and the rewards over a given time-step. We validate our approach on the MIT Mini Cheetah,Unitree Go1, and Go2 robots in a simulated environment and on a Unitree Go1 robot in real-world scenarios. In practice, HACL achieves peak forward velocity of 6.7 m/s for a given command velocity of 7m/s and outperforms prior locomotion algorithms by nearly 20%.', 'abstract_zh': '我们探讨了敏捷快速运动这一四足机器人和两足机器人的重要特性。我们提出了一种新算法，通过考虑运动的时空特性来维持稳定并生成高速轨迹。我们的建模方法基于一种新颖的历史感知课程学习（HACL）算法，利用循环神经网络（RNN）建模关节速度命令的历史信息，相对于观察到的线性和角动量奖励。隐藏状态有助于课程学习，在给定时间步内前向线性速度和角速度命令与奖励之间的关系。我们分别在MIT Mini Cheetah、Unitree Go1和Go2机器人上进行了仿真环境和实际场景下的验证。实际测试中，HACL在给定命令速度7m/s的情况下达到峰值前向速度6.7m/s，并比之前的运动算法性能高出近20%。', 'title_zh': 'HACL：历史感知的课程学习方法以实现快速移动'}
{'arxiv_id': 'arXiv:2505.18418', 'title': 'McARL:Morphology-Control-Aware Reinforcement Learning for Generalizable Quadrupedal Locomotion', 'authors': 'Prakhar Mishra, Amir Hossain Raj, Xuesu Xiao, Dinesh Manocha', 'link': 'https://arxiv.org/abs/2505.18418', 'abstract': "We present Morphology-Control-Aware Reinforcement Learning (McARL), a new approach to overcome challenges of hyperparameter tuning and transfer loss, enabling generalizable locomotion across robot morphologies. We use a morphology-conditioned policy by incorporating a randomized morphology vector, sampled from a defined morphology range, into both the actor and critic networks. This allows the policy to learn parameters that generalize to robots with similar characteristics. We demonstrate that a single policy trained on a Unitree Go1 robot using McARL can be transferred to a different morphology (e.g., Unitree Go2 robot) and can achieve zero-shot transfer velocity of up to 3.5 m/s without retraining or fine-tuning. Moreover, it achieves 6.0 m/s on the training Go1 robot and generalizes to other morphologies like A1 and Mini Cheetah. We also analyze the impact of morphology distance on transfer performance and highlight McARL's advantages over prior approaches. McARL achieves 44-150% higher transfer performance on Go2, Mini Cheetah, and A1 compared to PPO variants.", 'abstract_zh': '形态 Awareness 的强化学习 (McARL): 克服超参数调优和转移损失挑战，实现跨机器人形态的通用运动控制', 'title_zh': 'McARL：形态控制意识增强学习在通用四足行走中的应用'}
{'arxiv_id': 'arXiv:2505.18417', 'title': 'Reinforcement Learning for Ballbot Navigation in Uneven Terrain', 'authors': 'Achkan Salehi', 'link': 'https://arxiv.org/abs/2505.18417', 'abstract': 'Ballbot (i.e. Ball balancing robot) navigation usually relies on methods rooted in control theory (CT), and works that apply Reinforcement learning (RL) to the problem remain rare while generally being limited to specific subtasks (e.g. balance recovery). Unlike CT based methods, RL does not require (simplifying) assumptions about environment dynamics (e.g. the absence of slippage between the ball and the floor). In addition to this increased accuracy in modeling, RL agents can easily be conditioned on additional observations such as depth-maps without the need for explicit formulations from first principles, leading to increased adaptivity. Despite those advantages, there has been little to no investigation into the capabilities, data-efficiency and limitations of RL based methods for ballbot control and navigation. Furthermore, there is a notable absence of an open-source, RL-friendly simulator for this task. In this paper, we present an open-source ballbot simulation based on MuJoCo, and show that with appropriate conditioning on exteroceptive observations as well as reward shaping, policies learned by classical model-free RL methods are capable of effectively navigating through randomly generated uneven terrain, using a reasonable amount of data (four to five hours on a system operating at 500hz).', 'abstract_zh': '基于MuJoCo的球型机器人开源仿真实验：经典模型自由 reinforcement 学习方法的有效导航', 'title_zh': 'Ballbot在不平地形上的强化学习导航'}
{'arxiv_id': 'arXiv:2505.18382', 'title': 'One Demo Is All It Takes: Planning Domain Derivation with LLMs from A Single Demonstration', 'authors': 'Jinbang Huang, Yixin Xiao, Zhanguang Zhang, Mark Coates, Jianye Hao, Yingxue Zhang', 'link': 'https://arxiv.org/abs/2505.18382', 'abstract': 'Pre-trained Large Language Models (LLMs) have shown promise in solving planning problems but often struggle to ensure plan correctness, especially for long-horizon tasks. Meanwhile, traditional robotic task and motion planning (TAMP) frameworks address these challenges more reliably by combining high-level symbolic search with low-level motion planning. At the core of TAMP is the planning domain, an abstract world representation defined through symbolic predicates and actions. However, creating these domains typically involves substantial manual effort and domain expertise, limiting generalizability. We introduce Planning Domain Derivation with LLMs (PDDLLM), a novel approach that combines simulated physical interaction with LLM reasoning to improve planning performance. The method reduces reliance on humans by inferring planning domains from a single annotated task-execution demonstration. Unlike prior domain-inference methods that rely on partially predefined or language descriptions of planning domains, PDDLLM constructs domains entirely from scratch and automatically integrates them with low-level motion planning skills, enabling fully automated long-horizon planning. PDDLLM is evaluated on over 1,200 diverse tasks spanning nine environments and benchmarked against six LLM-based planning baselines, demonstrating superior long-horizon planning performance, lower token costs, and successful deployment on multiple physical robot platforms.', 'abstract_zh': '预训练大型语言模型在解决规划问题方面显示出了前景，但在保证规划正确性，尤其是长期任务方面常常遇到困难。与此同时，传统的机器人任务和运动规划（TAMP）框架通过结合高层符号搜索和低层运动规划，更可靠地解决了这些挑战。TAMP的核心在于规划域，这是一种通过符号谓词和动作定义的抽象世界表示。然而，创建这些域通常需要大量的手动工作和领域专业知识，限制了其通用性。我们介绍了通过预训练大型语言模型进行规划域推导（PDDLLM）的创新方法，该方法结合了模拟物理交互和大语言模型推理，以提高规划性能。该方法减少了对人类的依赖，通过单一标注的任务执行示范推断规划域。与依赖部分预定义或语言描述的规划域推断方法不同，PDDLLM 从头构建域，并自动将其与低层运动规划技能集成，从而实现全自动长期规划。PDDLLM 在超过 1,200 个跨九个环境的多元化任务上进行了评估，并在六种基于大语言模型的规划基线方法上进行了基准测试，展示了在长期规划性能、更低的标记成本以及多物理机器人平台上的成功部署。', 'title_zh': '一个演示即可：从单个示范规划领域衍生方法'}
{'arxiv_id': 'arXiv:2505.18364', 'title': 'ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models', 'authors': 'Minwoo Jung, Lanke Frank Tarimo Fu, Maurice Fallon, Ayoung Kim', 'link': 'https://arxiv.org/abs/2505.18364', 'abstract': "LiDAR Place Recognition (LPR) is a key component in robotic localization, enabling robots to align current scans with prior maps of their environment. While Visual Place Recognition (VPR) has embraced Vision Foundation Models (VFMs) to enhance descriptor robustness, LPR has relied on task-specific models with limited use of pre-trained foundation-level knowledge. This is due to the lack of 3D foundation models and the challenges of using VFM with LiDAR point clouds. To tackle this, we introduce ImLPR, a novel pipeline that employs a pre-trained DINOv2 VFM to generate rich descriptors for LPR. To our knowledge, ImLPR is the first method to leverage a VFM to support LPR. ImLPR converts raw point clouds into Range Image Views (RIV) to leverage VFM in the LiDAR domain. It employs MultiConv adapters and Patch-InfoNCE loss for effective feature learning. We validate ImLPR using public datasets where it outperforms state-of-the-art (SOTA) methods in intra-session and inter-session LPR with top Recall@1 and F1 scores across various LiDARs. We also demonstrate that RIV outperforms Bird's-Eye-View (BEV) as a representation choice for adapting LiDAR for VFM. We release ImLPR as open source for the robotics community.", 'abstract_zh': '基于LiDAR的地点识别（ImLPR）：一种利用预训练Vision Foundation Model的技术', 'title_zh': '基于图像的LiDAR位置识别：使用视觉基础模型的方法'}
{'arxiv_id': 'arXiv:2505.18341', 'title': 'CrashAgent: Crash Scenario Generation via Multi-modal Reasoning', 'authors': 'Miao Li, Wenhao Ding, Haohong Lin, Yiqi Lyu, Yihang Yao, Yuyou Zhang, Ding Zhao', 'link': 'https://arxiv.org/abs/2505.18341', 'abstract': 'Training and evaluating autonomous driving algorithms requires a diverse range of scenarios. However, most available datasets predominantly consist of normal driving behaviors demonstrated by human drivers, resulting in a limited number of safety-critical cases. This imbalance, often referred to as a long-tail distribution, restricts the ability of driving algorithms to learn from crucial scenarios involving risk or failure, scenarios that are essential for humans to develop driving skills efficiently. To generate such scenarios, we utilize Multi-modal Large Language Models to convert crash reports of accidents into a structured scenario format, which can be directly executed within simulations. Specifically, we introduce CrashAgent, a multi-agent framework designed to interpret multi-modal real-world traffic crash reports for the generation of both road layouts and the behaviors of the ego vehicle and surrounding traffic participants. We comprehensively evaluate the generated crash scenarios from multiple perspectives, including the accuracy of layout reconstruction, collision rate, and diversity. The resulting high-quality and large-scale crash dataset will be publicly available to support the development of safe driving algorithms in handling safety-critical situations.', 'abstract_zh': '训练和评估自动驾驶算法需要多样化的场景。然而，大多数可用的数据集主要由人类驾驶员展示的正常驾驶行为构成，导致安全关键案例数量有限。这种不平衡通常被称为长尾分布，限制了自动驾驶算法从涉及风险或失败的关键场景中学到的能力，这些场景对于人类高效发展驾驶技能至关重要。为生成此类场景，我们利用多模态大语言模型将事故报告转换为结构化场景格式，可以直接在仿真中执行。具体而言，我们引入了CrashAgent，这是一个多 agent 框架，旨在解释多模态的真实世界交通事故报告，以生成道路布局和ego车辆及其周围交通参与者的行为空间。我们从多个视角对生成的事故场景进行了全面评估，包括布局重建的准确性、碰撞率和多样性。所得的高质量和大规模事故数据集将公开提供，以支持在处理安全关键情况时开发安全有效的驾驶算法。', 'title_zh': 'CrashAgent：基于多模态推理的故障场景生成'}
{'arxiv_id': 'arXiv:2505.18340', 'title': 'A Coarse to Fine 3D LiDAR Localization with Deep Local Features for Long Term Robot Navigation in Large Environments', 'authors': 'Míriam Máximo, Antonio Santo, Arturo Gil, Mónica Ballesta, David Valiente', 'link': 'https://arxiv.org/abs/2505.18340', 'abstract': 'The location of a robot is a key aspect in the field of mobile robotics. This problem is particularly complex when the initial pose of the robot is unknown. In order to find a solution, it is necessary to perform a global localization. In this paper, we propose a method that addresses this problem using a coarse-to-fine solution. The coarse localization relies on a probabilistic approach of the Monte Carlo Localization (MCL) method, with the contribution of a robust deep learning model, the MinkUNeXt neural network, to produce a robust description of point clouds of a 3D LiDAR within the observation model. For fine localization, global point cloud registration has been implemented. MinkUNeXt aids this by exploiting the outputs of its intermediate layers to produce deep local features for each point in a scan. These features facilitate precise alignment between the current sensor observation and one of the point clouds on the map. The proposed MCL method incorporating Deep Local Features for fine localization is termed MCL-DLF. Alternatively, a classical ICP method has been implemented for this precise localization aiming at comparison purposes. This method is termed MCL-ICP. In order to validate the performance of MCL-DLF method, it has been tested on publicly available datasets such as the NCLT dataset, which provides seasonal large-scale environments. Additionally, tests have been also performed with own data (UMH) that also includes seasonal variations on large indoor/outdoor scenarios. The results, which were compared with established state-of-the-art methodologies, demonstrate that the MCL-DLF method obtains an accurate estimate of the robot localization in dynamic environments despite changes in environmental conditions. For reproducibility purposes, the code is publicly available at this https URL', 'abstract_zh': '基于粗细粒度相结合的移动机器人全局定位方法', 'title_zh': '从粗到细的深度局部特征长时大环境3D LiDAR定位'}
{'arxiv_id': 'arXiv:2505.18334', 'title': 'Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play', 'authors': 'Jiaxun Cui, Chen Tang, Jarrett Holtz, Janice Nguyen, Alessandro G. Allievi, Hang Qiu, Peter Stone', 'link': 'https://arxiv.org/abs/2505.18334', 'abstract': 'Past work has demonstrated that autonomous vehicles can drive more safely if they communicate with one another than if they do not. However, their communication has often not been human-understandable. Using natural language as a vehicle-to-vehicle (V2V) communication protocol offers the potential for autonomous vehicles to drive cooperatively not only with each other but also with human drivers. In this work, we propose a suite of traffic tasks in autonomous driving where vehicles in a traffic scenario need to communicate in natural language to facilitate coordination in order to avoid an imminent collision and/or support efficient traffic flow. To this end, this paper introduces a novel method, LLM+Debrief, to learn a message generation and high-level decision-making policy for autonomous vehicles through multi-agent discussion. To evaluate LLM agents for driving, we developed a gym-like simulation environment that contains a range of driving scenarios. Our experimental results demonstrate that LLM+Debrief is more effective at generating meaningful and human-understandable natural language messages to facilitate cooperation and coordination than a zero-shot LLM agent. Our code and demo videos are available at this https URL.', 'abstract_zh': '过去的研究已经证明，如果自动驾驶车辆彼此通信，它们可以更安全地行驶，而如果不通信则不然。然而，它们的通信往往是不可使人理解的。将自然语言作为车辆到车辆（V2V）通信协议，有助于自动驾驶车辆不仅与其他自动驾驶车辆，而且与人类驾驶员进行合作驾驶。在这项工作中，我们提出了一系列自动驾驶交通任务，在这些任务中，车辆在交通场景中需要通过自然语言沟通以协调行为，以避免即将发生的碰撞或支持高效的交通流量。为此，本文介绍了一种新的方法——LLM+Debrief，通过多智能体讨论来学习自动驾驶车辆的消息生成和高级决策政策。为了评估自动驾驶中的LLM代理，我们开发了一个类似于游戏的模拟环境，包含了各种驾驶场景。我们的实验结果表明，与零样本LLM代理相比，LLM+Debrief在生成有意义且可理解的自然语言消息以促进合作与协调方面更为有效。我们的代码和演示视频可在以下网址获得。', 'title_zh': '通过自博弈实现协同自动驾驶的自然语言通信 Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play'}
{'arxiv_id': 'arXiv:2505.18303', 'title': 'A Dataset and Benchmarks for Deep Learning-Based Optical Microrobot Pose and Depth Perception', 'authors': 'Lan Wei, Dandan Zhang', 'link': 'https://arxiv.org/abs/2505.18303', 'abstract': "Optical microrobots, manipulated via optical tweezers (OT), have broad applications in biomedicine. However, reliable pose and depth perception remain fundamental challenges due to the transparent or low-contrast nature of the microrobots, as well as the noisy and dynamic conditions of the microscale environments in which they operate. An open dataset is crucial for enabling reproducible research, facilitating benchmarking, and accelerating the development of perception models tailored to microscale challenges. Standardised evaluation enables consistent comparison across algorithms, ensuring objective benchmarking and facilitating reproducible research. Here, we introduce the OpTical MicroRobot dataset (OTMR), the first publicly available dataset designed to support microrobot perception under the optical microscope. OTMR contains 232,881 images spanning 18 microrobot types and 176 distinct poses. We benchmarked the performance of eight deep learning models, including architectures derived via neural architecture search (NAS), on two key tasks: pose classification and depth regression. Results indicated that Vision Transformer (ViT) achieve the highest accuracy in pose classification, while depth regression benefits from deeper architectures. Additionally, increasing the size of the training dataset leads to substantial improvements across both tasks, highlighting OTMR's potential as a foundational resource for robust and generalisable microrobot perception in complex microscale environments.", 'abstract_zh': '光学微机器人通过光学镊子操纵在生物医学中有广泛的应用。然而，由于微机器人本身透明或对比度低，以及微观环境的嘈杂和动态性，可靠的姿态和深度感知仍然是基本的挑战。公开的数据集对于实现可重现研究、促进基准测试并加速适应微尺度挑战的感知模型的发展至关重要。标准化的评估能够实现算法之间的统一比较，确保客观的基准测试并促进可重现研究。在此，我们介绍了光学显微镜下微机器人感知的第一公开数据集OTMR（Optical MicroRobot dataset）。OTMR包含232,881张图像，涵盖了18种微机器人类型和176种不同的姿态。我们在两个关键任务——姿态分类和深度回归——上评估了八种深度学习模型的表现，包括通过神经架构搜索（NAS）获得的模型架构。结果表明，Vision Transformer（ViT）在姿态分类中准确率最高，而深度回归则受益于更深的架构。此外，训练数据集的增大在两个任务上都带来了显著的提升，突显了OTMR作为复杂微尺度环境下微机器人稳健且通用感知的基础资源的潜力。', 'title_zh': '基于深度学习的光学微机器人姿态与深度感知数据集及基准测试'}
{'arxiv_id': 'arXiv:2505.18270', 'title': 'MorphEUS: Morphable Omnidirectional Unmanned System', 'authors': 'Ivan Bao, José C. Díaz Peón González Pacheco, Atharva Navsalkar, Andrew Scheffer, Sashreek Shankar, Andrew Zhao, Hongyu Zhou, Vasileios Tzoumas', 'link': 'https://arxiv.org/abs/2505.18270', 'abstract': 'Omnidirectional aerial vehicles (OMAVs) have opened up a wide range of possibilities for inspection, navigation, and manipulation applications using drones. In this paper, we introduce MorphEUS, a morphable co-axial quadrotor that can control position and orientation independently with high efficiency. It uses a paired servo motor mechanism for each rotor arm, capable of pointing the vectored-thrust in any arbitrary direction. As compared to the \\textit{state-of-the-art} OMAVs, we achieve higher and more uniform force/torque reachability with a smaller footprint and minimum thrust cancellations. The overactuated nature of the system also results in resiliency to rotor or servo-motor failures. The capabilities of this quadrotor are particularly well-suited for contact-based infrastructure inspection and close-proximity imaging of complex geometries. In the accompanying control pipeline, we present theoretical results for full controllability, almost-everywhere exponential stability, and thrust-energy optimality. We evaluate our design and controller on high-fidelity simulations showcasing the trajectory-tracking capabilities of the vehicle during various tasks. Supplementary details and experimental videos are available on the project webpage.', 'abstract_zh': '全向空中车辆（OMAVs）为使用无人机进行检查、导航和操作应用开辟了广泛的可能性。本文介绍了一种可重塑的共轴四旋翼机MorphEUS，它可以高效地独立控制位置和姿态。该四旋翼机采用每旋臂配对的伺服电机机制，能够将矢量推力指向任意方向。与当前最先进的OMAVs相比，我们实现了更高的且更为均匀的力量/力矩可达性，并具有更小的占地面积和最少的推力抵消。系统的过驱动特性还使其对旋翼或伺服电机故障具有韧性。该四旋翼机特别适合接触式的基础设施检查以及复杂几何结构的近距离成像。在配套的控制管道中，我们提出了全可控性、几乎处处指数稳定性和推力能量优化的理论结果。我们在高保真模拟中评估了该设计和控制器在各类任务中的路径追踪能力，并展示了车辆轨迹跟踪能力。更多补充细节和实验视频可在项目网页上获取。', 'title_zh': 'morphEUS: 变形的全向无人驾驶系统'}
{'arxiv_id': 'arXiv:2505.18248', 'title': 'Predictability-Based Curiosity-Guided Action Symbol Discovery', 'authors': 'Burcu Kilic, Alper Ahmetoglu, Emre Ugur', 'link': 'https://arxiv.org/abs/2505.18248', 'abstract': 'Discovering symbolic representations for skills is essential for abstract reasoning and efficient planning in robotics. Previous neuro-symbolic robotic studies mostly focused on discovering perceptual symbolic categories given a pre-defined action repertoire and generating plans with given action symbols. A truly developmental robotic system, on the other hand, should be able to discover all the abstractions required for the planning system with minimal human intervention. In this study, we propose a novel system that is designed to discover symbolic action primitives along with perceptual symbols autonomously. Our system is based on an encoder-decoder structure that takes object and action information as input and predicts the generated effect. To efficiently explore the vast continuous action parameter space, we introduce a Curiosity-Based exploration module that selects the most informative actions -- the ones that maximize the entropy in the predicted effect distribution. The discovered symbolic action primitives are then used to make plans using a symbolic tree search strategy in single- and double-object manipulation tasks. We compare our model with two baselines that use different exploration strategies in different experiments. The results show that our approach can learn a diverse set of symbolic action primitives, which are effective for generating plans in order to achieve given manipulation goals.', 'abstract_zh': '发现符号表示的动作基元对于机器人抽象推理和高效规划是必不可少的。现有的神经-符号机器人研究主要集中在给定先定义好的动作集合时发现感知符号类别，并基于给定的动作符号生成计划。相比之下，一个真正的发展型机器人系统应该能够在最少的人为干预下自主发现规划系统所需的全部抽象。在本研究中，我们提出了一种新型系统，该系统旨在自主发现感知符号和动作基元。我们的系统基于编码器-解码器结构，接受物体和动作信息作为输入，并预测生成效果。为高效探索庞大的连续动作参数空间，我们引入了一个好奇心驱动的探索模块，选择那些最大程度增加预测效果分布熵值的动作。发现的符号动作基元随后用于单物体和双物体操作任务中的符号树搜索策略制定计划。在不同实验中，我们将我们的模型与使用不同探索策略的两种基线模型进行了比较。结果表明，我们的方法能够学习到多样化的有效符号动作基元，这些基元能够用于生成实现给定操作目标的计划。', 'title_zh': '基于可预测性的好奇心引导的动作符号发现'}
{'arxiv_id': 'arXiv:2505.18229', 'title': 'BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs', 'authors': 'Mingning Guo, Mengwei Wu, Jiarun He, Shaoxian Li, Haifeng Li, Chao Tao', 'link': 'https://arxiv.org/abs/2505.18229', 'abstract': 'With the rapid advancement of low-altitude remote sensing and Vision-Language Models (VLMs), Embodied Agents based on Unmanned Aerial Vehicles (UAVs) have shown significant potential in autonomous tasks. However, current evaluation methods for UAV-Embodied Agents (UAV-EAs) remain constrained by the lack of standardized benchmarks, diverse testing scenarios and open system interfaces. To address these challenges, we propose BEDI (Benchmark for Embodied Drone Intelligence), a systematic and standardized benchmark designed for evaluating UAV-EAs. Specifically, we introduce a novel Dynamic Chain-of-Embodied-Task paradigm based on the perception-decision-action loop, which decomposes complex UAV tasks into standardized, measurable subtasks. Building on this paradigm, we design a unified evaluation framework encompassing five core sub-skills: semantic perception, spatial perception, motion control, tool utilization, and task planning. Furthermore, we construct a hybrid testing platform that integrates static real-world environments with dynamic virtual scenarios, enabling comprehensive performance assessment of UAV-EAs across varied contexts. The platform also offers open and standardized interfaces, allowing researchers to customize tasks and extend scenarios, thereby enhancing flexibility and scalability in the evaluation process. Finally, through empirical evaluations of several state-of-the-art (SOTA) VLMs, we reveal their limitations in embodied UAV tasks, underscoring the critical role of the BEDI benchmark in advancing embodied intelligence research and model optimization. By filling the gap in systematic and standardized evaluation within this field, BEDI facilitates objective model comparison and lays a robust foundation for future development in this field. Our benchmark will be released at this https URL .', 'abstract_zh': '基于无人机的体态智能基准BEDI：一种标准化评价框架', 'title_zh': 'BEDI: 一种全面的无人机上体态代理评估基准'}
{'arxiv_id': 'arXiv:2505.18214', 'title': 'LA-RCS: LLM-Agent-Based Robot Control System', 'authors': 'TaekHyun Park, YoungJun Choi, SeungHoon Shin, Kwangil Lee', 'link': 'https://arxiv.org/abs/2505.18214', 'abstract': 'LA-RCS (LLM-agent-based robot control system) is a sophisticated robot control system designed to autonomously plan, work, and analyze the external environment based on user requirements by utilizing LLM-Agent. Utilizing a dual-agent framework, LA-RCS generates plans based on user requests, observes the external environment, executes the plans, and modifies the plans as needed to adapt to changes in the external conditions. Additionally, LA-RCS interprets natural language commands by the user and converts them into commands compatible with the robot interface so that the robot can execute tasks and meet user requests properly. During his process, the system autonomously evaluates observation results, provides feedback on the tasks, and executes commands based on real-time environmental monitoring, significantly reducing the need for user intervention in fulfilling requests. We categorized the scenarios that LA-RCS needs to perform into four distinct types and conducted a quantitative assessment of its performance in each scenario. The results showed an average success rate of 90 percent, demonstrating the system capability to fulfill user requests satisfactorily. For more extensive results, readers can visit our project page: this https URL', 'abstract_zh': '基于LLM-Agent的LA-RCS自主机器人控制系统', 'title_zh': '基于LLM代理的机器人控制系统'}
{'arxiv_id': 'arXiv:2505.18204', 'title': 'Brownian Bridge Augmented Surrogate Simulation and Injection Planning for Geological CO$_2$ Storage', 'authors': 'Haoyue Bai, Guodong Chen, Wangyang Ying, Xinyuan Wang, Nanxu Gong, Sixun Dong, Giulia Pedrielli, Haoyu Wang, Haifeng Chen, Yanjie Fu', 'link': 'https://arxiv.org/abs/2505.18204', 'abstract': 'Geological CO2 storage (GCS) involves injecting captured CO2 into deep subsurface formations to support climate goals. The effective management of GCS relies on adaptive injection planning to dynamically control injection rates and well pressures to balance both storage safety and efficiency. Prior literature, including numerical optimization methods and surrogate-optimization methods, is limited by real-world GCS requirements of smooth state transitions and goal-directed planning within limited time. To address these limitations, we propose a Brownian Bridge-augmented framework for surrogate simulation and injection planning in GCS and develop two insights: (i) Brownian bridge as a smooth state regularizer for better surrogate simulation; (ii) Brownian bridge as goal-time-conditioned planning guidance for improved injection planning. Our method has three stages: (i) learning deep Brownian bridge representations with contrastive and reconstructive losses from historical reservoir and utility trajectories, (ii) incorporating Brownian bridge-based next state interpolation for simulator regularization, and (iii) guiding injection planning with Brownian utility-conditioned trajectories to generate high-quality injection plans. Experimental results across multiple datasets collected from diverse GCS settings demonstrate that our framework consistently improves simulation fidelity and planning effectiveness while maintaining low computational overhead.', 'abstract_zh': '地质碳封存（GCS）涉及将捕获的CO2注入深层地下储层以支持气候目标。有效的GCS管理依赖于自适应注气计划，以动态控制注气速率和井压，平衡存储安全与效率。现有的文献，包括数值优化方法和代理优化方法，受限于实际GCS应用对平滑状态过渡和目标导向规划在有限时间内的要求。为应对这些局限性，我们提出了一种布朗桥增强的代理模拟与注气计划框架，并发展了两个见解：（i）布朗桥作为平滑状态正则化器以改进代理模拟；（ii）布朗桥作为目标时间条件下的规划指导以优化注气计划。我们的方法包括三个阶段：（i）通过对比损失和重构损失学习历史油藏和收益轨迹的深度布朗桥表示；（ii）利用基于布朗桥的下一状态内插对模拟器进行正则化；（iii）基于布朗桥条件下的收益轨迹指导注气计划，生成高质量的注气方案。来自多种GCS设置的数据集的实验结果表明，我们的框架在保持低计算开销的同时，持续提高模拟精度和计划有效性。', 'title_zh': '使用布朗运动桥增广替代模拟及注入计划的地层二氧化碳储存'}
{'arxiv_id': 'arXiv:2505.18201', 'title': 'Reinforcement Twinning for Hybrid Control of Flapping-Wing Drones', 'authors': 'Romain Poletti, Lorenzo Schena, Lilla Koloszar, Joris Degroote, Miguel Alfonso Mendez', 'link': 'https://arxiv.org/abs/2505.18201', 'abstract': 'Controlling the flight of flapping-wing drones requires versatile controllers that handle their time-varying, nonlinear, and underactuated dynamics from incomplete and noisy sensor data. Model-based methods struggle with accurate modeling, while model-free approaches falter in efficiently navigating very high-dimensional and nonlinear control objective landscapes. This article presents a novel hybrid model-free/model-based approach to flight control based on the recently proposed reinforcement twinning algorithm. The model-based (MB) approach relies on an adjoint formulation using an adaptive digital twin, continuously identified from live trajectories, while the model-free (MF) approach relies on reinforcement learning. The two agents collaborate through transfer learning, imitation learning, and experience sharing using the real environment, the digital twin and a referee. The latter selects the best agent to interact with the real environment based on performance within the digital twin and a real-to-virtual environment consistency ratio. The algorithm is evaluated for controlling the longitudinal dynamics of a flapping-wing drone, with the environment simulated as a nonlinear, time-varying dynamical system under the influence of quasi-steady aerodynamic forces. The hybrid control learning approach is tested with three types of initialization of the adaptive model: (1) offline identification using previously available data, (2) random initialization with full online identification, and (3) offline pre-training with an estimation bias, followed by online adaptation. In all three scenarios, the proposed hybrid learning approach demonstrates superior performance compared to purely model-free and model-based methods.', 'abstract_zh': '基于强化学习孪生算法的混合模型自由/模型导向的飞行控制方法', 'title_zh': '混合控制扑翼无人机的强化孪生学习方法'}
{'arxiv_id': 'arXiv:2505.18198', 'title': 'LTDA-Drive: LLMs-guided Generative Models based Long-tail Data Augmentation for Autonomous Driving', 'authors': 'Mahmut Yurt, Xin Ye, Yunsheng Ma, Jingru Luo, Abhirup Mallik, John Pauly, Burhaneddin Yaman, Liu Ren', 'link': 'https://arxiv.org/abs/2505.18198', 'abstract': '3D perception plays an essential role for improving the safety and performance of autonomous driving. Yet, existing models trained on real-world datasets, which naturally exhibit long-tail distributions, tend to underperform on rare and safety-critical, vulnerable classes, such as pedestrians and cyclists. Existing studies on reweighting and resampling techniques struggle with the scarcity and limited diversity within tail classes. To address these limitations, we introduce LTDA-Drive, a novel LLM-guided data augmentation framework designed to synthesize diverse, high-quality long-tail samples. LTDA-Drive replaces head-class objects in driving scenes with tail-class objects through a three-stage process: (1) text-guided diffusion models remove head-class objects, (2) generative models insert instances of the tail classes, and (3) an LLM agent filters out low-quality synthesized images. Experiments conducted on the KITTI dataset show that LTDA-Drive significantly improves tail-class detection, achieving 34.75\\% improvement for rare classes over counterpart methods. These results further highlight the effectiveness of LTDA-Drive in tackling long-tail challenges by generating high-quality and diverse data.', 'abstract_zh': '3D感知在提高自主驾驶的安全性和性能中起着重要作用。然而，现有模型在训练时使用的真实世界数据集自然表现出长尾分布，这些模型在罕见且安全关键的类别（如行人和骑自行车的人）上往往会表现不佳。针对现有研究中重新加权和重新采样技术在尾部类别稀缺性和多样性不足的问题，我们提出了LTDA-Drive，这是一种新型的LLM引导的数据增强框架，旨在合成多样且高质量的长尾样本。LTDA-Drive通过三阶段过程将驾驶场景中的头类对象替换为尾类对象：（1）文本引导的扩散模型移除头类对象，（2）生成模型插入尾类实例，（3）LLM代理过滤低质量的合成图像。在KITTI数据集上的实验结果显示，LTDA-Drive显著提高了尾类检测性能，相较于同类方法，罕见类别的检测准确率提升了34.75%。这些结果进一步突显了LTDA-Drive在生成高质量和多样化数据以应对长尾挑战方面的有效性。', 'title_zh': 'LTDA-Drive：由大规模语言模型引导的长尾数据生成增强方法及其在自主驾驶中的应用'}
{'arxiv_id': 'arXiv:2505.20294', 'title': 'GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes', 'authors': 'Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, Tianfan Xue', 'link': 'https://arxiv.org/abs/2505.20294', 'abstract': 'Generalizable active mapping in complex unknown environments remains a critical challenge for mobile robots. Existing methods, constrained by insufficient training data and conservative exploration strategies, exhibit limited generalizability across scenes with diverse layouts and complex connectivity. To enable scalable training and reliable evaluation, we introduce GLEAM-Bench, the first large-scale benchmark designed for generalizable active mapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets. Building upon this foundation, we propose GLEAM, a unified generalizable exploration policy for active mapping. Its superior generalizability comes mainly from our semantic representations, long-term navigable goals, and randomized strategies. It significantly outperforms state-of-the-art methods, achieving 66.50% coverage (+9.49%) with efficient trajectories and improved mapping accuracy on 128 unseen complex scenes. Project page: this https URL.', 'abstract_zh': '在复杂未知环境中的可泛化主动建图仍然是移动机器人面临的关键挑战。现有方法受训数据不足和保守探索策略的限制，在具有多样布局和复杂连接的不同场景中的泛化能力有限。为实现可扩展的训练和可靠的评估，我们引入了GLEAM-Bench，这是第一个针对可泛化主动建图设计的大规模基准，包含来自合成数据集和真实扫描数据集的1,152个多样3D场景。在此基础上，我们提出了GLEAM，一种统一的可泛化探索策略，用于主动建图。其卓越的泛化能力主要源自我们的语义表示、长期导航目标以及随机化策略。GLEAM在128个未见过的复杂场景中表现显著优于最先进的方法，实现了66.50%的覆盖率（提高9.49%），同时生成了高效的路径并提高了建图精度。项目页面：this https URL。', 'title_zh': 'GLEAM: 学习适应性探索策略实现复杂三维室内场景的主动建图'}
{'arxiv_id': 'arXiv:2505.20032', 'title': 'ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers', 'authors': 'Fotios Lygerakis, Ozan Özdenizci, Elmar Rückert', 'link': 'https://arxiv.org/abs/2505.20032', 'abstract': 'Tactile sensing provides local essential information that is complementary to visual perception, such as texture, compliance, and force. Despite recent advances in visuotactile representation learning, challenges remain in fusing these modalities and generalizing across tasks and environments without heavy reliance on pre-trained vision-language models. Moreover, existing methods do not study positional encodings, thereby overlooking the multi-scale spatial reasoning needed to capture fine-grained visuotactile correlations. We introduce ViTaPEs, a transformer-based framework that robustly integrates visual and tactile input data to learn task-agnostic representations for visuotactile perception. Our approach exploits a novel multi-scale positional encoding scheme to capture intra-modal structures, while simultaneously modeling cross-modal cues. Unlike prior work, we provide provable guarantees in visuotactile fusion, showing that our encodings are injective, rigid-motion-equivariant, and information-preserving, validating these properties empirically. Experiments on multiple large-scale real-world datasets show that ViTaPEs not only surpasses state-of-the-art baselines across various recognition tasks but also demonstrates zero-shot generalization to unseen, out-of-domain scenarios. We further demonstrate the transfer-learning strength of ViTaPEs in a robotic grasping task, where it outperforms state-of-the-art baselines in predicting grasp success. Project page: this https URL', 'abstract_zh': '触觉感知提供局部的关键信息，这些信息补充了视觉感知的内容，包括纹理、柔顺性和力。尽管在visuotactile表示学习方面取得了近期进展，但在融合这些模态以及在不同任务和环境中泛化方面仍然存在挑战，且对预训练的视觉-语言模型依赖较大。此外，现有方法未研究位置编码，忽视了捕捉细粒度visuotactile相关性的多层次空间推理需求。我们引入了ViTaPEs，这是一种基于Transformer的框架，用于稳健地整合视觉和触觉输入数据，以学习visuotactile感知的任务无关表示。我们的方法利用一种新颖的多层次位置编码方案来捕捉跨模态线索，同时建模跨模态线索。与先前工作不同，我们提供了visuotactile融合的可证明保证，证明我们的编码是注入性的、刚体运动等变的，并且保持信息量，这些性质通过实验得到了验证。在多个大规模真实世界数据集上的实验表明，ViTaPEs不仅在各种识别任务中超越了最先进的基线，还展示了对未见的领域外场景的零样本泛化能力。我们进一步在机器人抓取任务中展示了ViTaPEs的迁移学习能力，它在预测抓取成功率方面优于最先进的基线方法。项目页面：this https URL', 'title_zh': 'ViTaPEs: 视触位置编码在多模态变换器中的跨模态对齐'}
{'arxiv_id': 'arXiv:2505.20024', 'title': 'ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving', 'authors': 'Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao, Yupeng Zheng, Qiao Lin, Huiyong Chen, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2505.20024', 'abstract': 'Due to the powerful vision-language reasoning and generalization abilities, multimodal large language models (MLLMs) have garnered significant attention in the field of end-to-end (E2E) autonomous driving. However, their application to closed-loop systems remains underexplored, and current MLLM-based methods have not shown clear superiority to mainstream E2E imitation learning approaches. In this work, we propose ReasonPlan, a novel MLLM fine-tuning framework designed for closed-loop driving through holistic reasoning with a self-supervised Next Scene Prediction task and supervised Decision Chain-of-Thought process. This dual mechanism encourages the model to align visual representations with actionable driving context, while promoting interpretable and causally grounded decision making. We curate a planning-oriented decision reasoning dataset, namely PDR, comprising 210k diverse and high-quality samples. Our method outperforms the mainstream E2E imitation learning method by a large margin of 19% L2 and 16.1 driving score on Bench2Drive benchmark. Furthermore, ReasonPlan demonstrates strong zero-shot generalization on unseen DOS benchmark, highlighting its adaptability in handling zero-shot corner cases. Code and dataset will be found in this https URL.', 'abstract_zh': '由于强大的跨模态视觉语言推理和泛化能力，多模态大型语言模型（MLLMs）在端到端（E2E）自动驾驶领域引起了广泛关注。然而，它们在闭环系统中的应用仍待探索，当前基于MLLM的方法在与主流E2E模仿学习方法的竞争中尚未展现出明显优势。在本文中，我们提出了一种名为ReasonPlan的新颖MLLM微调框架，通过整体推理和自我监督的下一场景预测任务以及监督的决策思维链过程来实现闭环驾驶。这种双重机制促使模型将视觉表示与可操作的驾驶上下文对齐，同时促进解释性和因果驱动的决策制定。我们精心收集了一个面向规划的决策推理数据集，即PDR，其中包括210,000个多样且高质量的数据样本。我们的方法在Bench2Drive基准上以L2 19%和驾驶分数16.1的显著优势超越了主流的E2E模仿学习方法。此外，ReasonPlan在未见的DOS基准中展示了强大的零样本泛化能力，突显了其处理零样本边缘问题的适应性。代码和数据集可在以下链接中找到：https://github.com/ReasonPlan/ReasonPlan。', 'title_zh': 'ReasonPlan: 统一场景预测与决策推理的闭环自动驾驶'}
{'arxiv_id': 'arXiv:2505.19850', 'title': 'DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning', 'authors': 'Leander Diaz-Bone, Marco Bagatella, Jonas Hübotter, Andreas Krause', 'link': 'https://arxiv.org/abs/2505.19850', 'abstract': "Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.", 'abstract_zh': '稀疏奖励强化学习（RL）可以建模一系列高度复杂的任务。解决稀疏奖励任务是RL的核心前提——需要高效的探索与长期信用分配——克服这些挑战对于构建具有超人类能力的自我改进代理至关重要。我们提出，解决复杂的高维度任务需要解决与目标任务相关的简单任务。相比之下，大多数先前的工作设计了选择探索性任务的策略，目标是解决任何任务，这使得探索具有挑战性的高维度、长时间任务变得不切实际。我们发现，有效的探索所需的定向感可以从现有的RL算法中提取出来，无需任何先验信息。基于这一发现，我们提出了一个定向稀疏奖励目标条件长期强化学习（DISCOVER）的方法，该方法在目标任务的方向上选择探索性目标。我们将DISCOVER与原理上合理的bandits探索相连，正式地将目标任务变得可达成所需的时间边界在智能体初始与目标的距离内，但与所有任务的空间体积无关。在实验中，我们在高维度环境中进行了全面评估。我们发现，DISCOVER的定向目标选择解决了先前RL中最先进的探索方法无法解决的探索问题。', 'title_zh': 'DISCOVER: 自动化 curriculum 学习方法在网络稀疏奖励强化学习中的应用'}
{'arxiv_id': 'arXiv:2505.19809', 'title': 'Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees', 'authors': 'Daniel Ordoñez-Apraez, Alek Fröhlich, Vladimir Kostić, Karim Lounici, Vivien Brandt, Massimiliano Pontil', 'link': 'https://arxiv.org/abs/2505.19809', 'abstract': 'In many real-world applications of regression, conditional probability estimation, and uncertainty quantification, exploiting symmetries rooted in physics or geometry can dramatically improve generalization and sample efficiency. While geometric deep learning has made significant empirical advances by incorporating group-theoretic structure, less attention has been given to statistical learning guarantees. In this paper, we introduce an equivariant representation learning framework that simultaneously addresses regression, conditional probability estimation, and uncertainty quantification while providing first-of-its-kind non-asymptotic statistical learning guarantees. Grounded in operator and group representation theory, our framework approximates the spectral decomposition of the conditional expectation operator, building representations that are both equivariant and disentangled along independent symmetry subgroups. Empirical evaluations on synthetic datasets and real-world robotics applications confirm the potential of our approach, matching or outperforming existing equivariant baselines in regression while additionally providing well-calibrated parametric uncertainty estimates.', 'abstract_zh': '在回归、条件概率估计和不确定性量化等许多实际应用中，利用源自物理或几何的对称性可以显著提高泛化能力和样本效率。虽然几何深度学习通过引入群论结构取得了显著的实证进步，但在统计学习保证方面关注较少。本文提出了一种同时解决回归、条件概率估计和不确定性量化问题的不变表示学习框架，并提供了同类中首个非渐近统计学习保证。基于算子和群表示理论，该框架近似条件期望算子的谱分解，构建既不变又在独立对称子群上解纠缠的表示。在合成数据集和实际机器人应用上的 empirical 评估证实了该方法的潜力，在回归任务上匹配或超越现有不变基线，并额外提供校准良好的参数不确定性估计。', 'title_zh': '对称意识保证下的等变表示学习'}
{'arxiv_id': 'arXiv:2505.19698', 'title': 'JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning', 'authors': 'Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu', 'link': 'https://arxiv.org/abs/2505.19698', 'abstract': 'Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.', 'abstract_zh': '近期基于模型的强化学习（MBRL）方法在Atari100k基准测试上达到了超人类水平的性能，这得益于在强大扩散世界模型训练下的强化学习代理。然而，我们发现当前的聚合数据掩盖了一个主要的性能不对称性：在某些任务中，基于模型的强化学习代理显著优于人类，而在其他任务中则大幅落后，前者吹胀了总体指标。特别是在使用扩散世界模型训练的像素基代理中，这种不对称性尤为明显。在本文中，我们旨在纠正像素基代理中观察到的显著不对称性，作为最初尝试逆转其令人担忧的上升趋势的初步尝试。我们通过将所有任务划分为代理最优或人类最优，并倡导对两类指标同等重视来解决这些问题。接下来，我们假设这种显著的不对称性主要是由于像素基方法中缺乏使用世界模型目标训练的时间结构化的潜在空间。最后，为了解决这一问题，我们提出了联合嵌入扩散（JEDI），这是一种新颖的时间结构化潜在扩散世界模型，自洽性目标下端到端训练。JEDI在人类最优任务中表现出色，同时在Atari100k基准测试中保持竞争力，并且运行速度快3倍，内存使用量减少43%，优于最新的像素基扩散基线。总体而言，我们的工作重新定义了在Atari100k中超越人类水平性能的真正含义。', 'title_zh': 'JEDI: 隐含的端到端扩散减轻基于模型的强化学习中代理-人类性能差异'}
{'arxiv_id': 'arXiv:2505.19629', 'title': 'Software Engineering for Self-Adaptive Robotics: A Research Agenda', 'authors': 'Shaukat Ali, Ana Cavalcanti, Cláudio Ângelo Gonçalves Gomes, Peter Gorm Larsen, Hassan Sartaj, Anastasios Tefas, Jim Woodcock, Houxiang Zhang', 'link': 'https://arxiv.org/abs/2505.19629', 'abstract': 'Self-adaptive robotic systems are designed to operate autonomously in dynamic and uncertain environments, requiring robust mechanisms to monitor, analyse, and adapt their behaviour in real-time. Unlike traditional robotic software, which follows predefined logic, self-adaptive robots leverage artificial intelligence, machine learning, and model-driven engineering to continuously adjust to changing operational conditions while ensuring reliability, safety, and performance. This paper presents a research agenda for software engineering in self-adaptive robotics, addressing critical challenges across two key dimensions: (1) the development phase, including requirements engineering, software design, co-simulation, and testing methodologies tailored to adaptive robotic systems, and (2) key enabling technologies, such as digital twins, model-driven engineering, and AI-driven adaptation, which facilitate runtime monitoring, fault detection, and automated decision-making. We discuss open research challenges, including verifying adaptive behaviours under uncertainty, balancing trade-offs between adaptability, performance, and safety, and integrating self-adaptation frameworks like MAPE-K. By providing a structured roadmap, this work aims to advance the software engineering foundations for self-adaptive robotic systems, ensuring they remain trustworthy, efficient, and capable of handling real-world complexities.', 'abstract_zh': '自适应机器人系统的自适应软件工程研究议程', 'title_zh': '自适应机器人软件工程：研究议程'}
{'arxiv_id': 'arXiv:2505.19381', 'title': 'DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving', 'authors': 'Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng, Hao Jiang, Zongzheng Zhang, Xianda Guo, Hao Sun, Hao Zhao', 'link': 'https://arxiv.org/abs/2505.19381', 'abstract': "Research interest in end-to-end autonomous driving has surged owing to its fully differentiable design integrating modular tasks, i.e. perception, prediction and planing, which enables optimization in pursuit of the ultimate goal. Despite the great potential of the end-to-end paradigm, existing methods suffer from several aspects including expensive BEV (bird's eye view) computation, action diversity, and sub-optimal decision in complex real-world scenarios. To address these challenges, we propose a novel hybrid sparse-dense diffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA. We explore the sparse diffusion representation for efficient multi-modal driving behavior. Moreover, we rethink the effectiveness of VLM driving decision and improve the trajectory generation guidance through deep interaction across agent, map instances and VLM output. Our method shows superior performance in Autonomous Grand Challenge 2025 which contains challenging real and reactive synthetic scenarios. Our methods achieves 45.0 PDMS.", 'abstract_zh': '端到端自动驾驶的研究兴趣由于其端到端可微设计集成了感知、预测和规划等模块任务而激增，这使得在追求最终目标的过程中能够实现优化。尽管端到端范式的潜力巨大，但现有方法在多个方面存在不足，包括昂贵的BEV计算、动作多样性以及在复杂现实场景中的次优决策。为应对这些挑战，我们提出了一种由视觉语言模型（VLM）赋能的新型稀疏-密集扩散策略，称为Diff-VLA。我们探索了稀疏扩散表示以实现高效的多模态驾驶行为。此外，我们重新思考了VLM在驾驶决策中的有效性，并通过深度跨代理、地图实例和VLM输出的交互来改进轨迹生成引导。在包含挑战性的真实和反应式合成场景的2025年自动驾驶 grand challenge 中，我们的方法表现出色，获得了45.0 PDMS。', 'title_zh': 'DiffVLA: 自动驾驶中的视觉-语言引导的扩散规划'}
{'arxiv_id': 'arXiv:2505.19247', 'title': 'Improving Value Estimation Critically Enhances Vanilla Policy Gradient', 'authors': 'Tao Wang, Ruipeng Zhang, Sicun Gao', 'link': 'https://arxiv.org/abs/2505.19247', 'abstract': 'Modern policy gradient algorithms, such as TRPO and PPO, outperform vanilla policy gradient in many RL tasks. Questioning the common belief that enforcing approximate trust regions leads to steady policy improvement in practice, we show that the more critical factor is the enhanced value estimation accuracy from more value update steps in each iteration. To demonstrate, we show that by simply increasing the number of value update steps per iteration, vanilla policy gradient itself can achieve performance comparable to or better than PPO in all the standard continuous control benchmark environments. Importantly, this simple change to vanilla policy gradient is significantly more robust to hyperparameter choices, opening up the possibility that RL algorithms may still become more effective and easier to use.', 'abstract_zh': '现代的策略梯度算法（如TRPO和PPO）在许多RL任务中优于vanilla策略梯度。质疑约化信任区域带来的近似值会对实践中的策略改进产生稳定影响这一常见信念，我们展示了更为关键的因素是每轮迭代中价值估计精度的提高源自更多的价值更新步骤。为证明这一点，我们展示了通过简单增加每轮迭代中的价值更新步骤次数，即使在没有使用TRPO或PPO的情况下，vanilla策略梯度也能在所有标准连续控制基准环境中达到与PPO相当或更好的性能。重要的是，这一简单的改变使vanilla策略梯度对超参数的选择更加稳健，开启了RL算法可能变得更加有效和易于使用的可能性。', 'title_zh': '提高价值估算极大地提升了基础策略梯度算法。'}
{'arxiv_id': 'arXiv:2505.19238', 'title': 'Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees', 'authors': 'Sourav Ganguly, Arnob Ghosh, Kishan Panaganti, Adam Wierman', 'link': 'https://arxiv.org/abs/2505.19238', 'abstract': 'Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.', 'abstract_zh': '约束决策对于设计实际控制系统的安全策略至关重要，但模拟环境往往无法捕捉到真实世界的不利因素。我们考虑在真实模型与可访问的模拟器/名义模型存在不匹配的情况下，学习一个既能最大化累计奖励又能满足约束的策略的问题。特别是，我们考虑在不确定性集合中心围绕未知名义模型的情况下，代理最大化奖励并满足最差可能的随机模型下的约束的鲁棒约束马尔可夫决策问题（RCMDP）。对于标准约束MDP（CMDP），有效的对偶方法在这里不适用，因为缺乏强对偶性。此外，基于复合价值函数的标准鲁棒值迭代方法也无法应用，因为最差情况模型对于奖励价值函数和约束价值函数可能是不同的。我们提出了一种有效最小化约束价值函数的技术，以满足约束；另一方面，当所有约束都已满足时，它可以简单地最大化鲁棒的奖励价值函数。我们证明了这样的算法在最多$\\epsilon$次优性和可行策略上，在$O(\\epsilon^{-2})$迭代后可以找到一个策略。与最新的方法相比，我们不需要使用二分查找，因此，在折扣因子$\\gamma$较小的情况下，计算时间至少减少4倍，在$\\gamma$较大时，计算时间至少减少6倍。', 'title_zh': '具有迭代复杂度保证的鲁棒约束MDP的高效策略优化'}
{'arxiv_id': 'arXiv:2505.19237', 'title': 'Sensorimotor features of self-awareness in multimodal large language models', 'authors': 'Iñaki Dellibarda Varela, Pablo Romero-Sorozabal, Diego Torricelli, Gabriel Delgado-Oleas, Jose Ignacio Serrano, Maria Dolores del Castillo Sobrino, Eduardo Rocon, Manuel Cebrian', 'link': 'https://arxiv.org/abs/2505.19237', 'abstract': 'Self-awareness - the ability to distinguish oneself from the surrounding environment - underpins intelligent, autonomous behavior. Recent advances in AI achieve human-like performance in tasks integrating multimodal information, particularly in large language models, raising interest in the embodiment capabilities of AI agents on nonhuman platforms such as robots. Here, we explore whether multimodal LLMs can develop self-awareness solely through sensorimotor experiences. By integrating a multimodal LLM into an autonomous mobile robot, we test its ability to achieve this capacity. We find that the system exhibits robust environmental awareness, self-recognition and predictive awareness, allowing it to infer its robotic nature and motion characteristics. Structural equation modeling reveals how sensory integration influences distinct dimensions of self-awareness and its coordination with past-present memory, as well as the hierarchical internal associations that drive self-identification. Ablation tests of sensory inputs identify critical modalities for each dimension, demonstrate compensatory interactions among sensors and confirm the essential role of structured and episodic memory in coherent reasoning. These findings demonstrate that, given appropriate sensory information about the world and itself, multimodal LLMs exhibit emergent self-awareness, opening the door to artificial embodied cognitive systems.', 'abstract_zh': '自我意识——区分自身与周围环境的能力——是智能自主行为的基础。近期AI技术在结合多模态信息的任务中实现了类人的性能，特别是在大型语言模型中，这引起了人们对在非人类平台上（如机器人）实现AI代理体现能力的兴趣。在这里，我们探讨多模态LLM是否仅通过传感器运动体验即可发展出自我意识。通过将多模态LLM整合到自主移动机器人中，我们测试了其实现这一能力的能力。我们发现该系统表现出 robust 环境意识、自认知识和预测意识，使其能够推断出自身的机器人性质和运动特性。结构方程建模揭示了感觉整合如何影响自我意识的不同维度及其与过去和现在的记忆协调的方式，以及驱动自我识别的分层内在关联。通过消除感官输入的消融测试确定了每个维度的关键模态，展示了传感器之间的补偿性交互，并确认了结构和情景记忆在连贯推理中的关键作用。这些发现表明，给定关于世界和自身合适的感官信息，多模态LLM表现出Emergent自我意识，为人工体体现认知系统打开了大门。', 'title_zh': '多模态大型语言模型的感知运动自我意识特征'}
{'arxiv_id': 'arXiv:2505.18945', 'title': 'Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back', 'authors': 'Jintao Sun, Hu Zhang, Gangyi Ding, Zhedong Zheng', 'link': 'https://arxiv.org/abs/2505.18945', 'abstract': "Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over time. We introduce Echo Planning, a novel self-correcting framework that establishes a closed-loop Current - Future - Current (CFC) cycle to harmonize trajectory prediction with scene coherence. Our key insight is that plausible future trajectories must be bi-directionally consistent, ie, not only generated from current observations but also capable of reconstructing them. The CFC mechanism first predicts future trajectories from the Bird's-Eye-View (BEV) scene representation, then inversely maps these trajectories back to estimate the current BEV state. By enforcing consistency between the original and reconstructed BEV representations through a cycle loss, the framework intrinsically penalizes physically implausible or misaligned trajectories. Experiments on nuScenes demonstrate state-of-the-art performance, reducing L2 error by 0.04 m and collision rate by 0.12% compared to one-shot planners. Crucially, our method requires no additional supervision, leveraging the CFC cycle as an inductive bias for robust planning. This work offers a deployable solution for safety-critical autonomous systems.", 'abstract_zh': "现代端到端自动驾驶系统受到一个关键限制：其规划器缺乏机制来确保预测轨迹与 evolving 场景动态之间的时序一致性。这种自我监督的缺失使得早期预测错误会随着时间 catastrophe 地累积。我们提出了一种新颖的自我矫正框架 Echo Planning，建立了当前 - 未来 - 当前（CFC）闭环循环，以实现轨迹预测与场景连贯性的一致性。我们的关键见解是，合理的未来轨迹必须双向一致，即不仅从当前观测生成，还可以重构这些观测。CFC 机制首先从 Bird's-Eye-View (BEV) 场景表示预测未来轨迹，然后将这些轨迹逆向映射以估计当前 BEV 状态。通过周期损失强制原始和重构的 BEV 表示之间的一致性，框架内在地惩罚物理上不合理或错位的轨迹。在 nuScenes 上的实验显示了最先进的性能，L2 错误减少了 0.04 m，碰撞率减少了 0.12%，相比一次预测规划器。最关键的是，我们的方法不需要额外的监督，利用 CFC 循环作为稳健规划的归纳偏差。这项工作为安全关键的自动驾驶系统提供了可部署的解决方案。", 'title_zh': '自动驾驶中的回波规划：从当前观测到未来轨迹及其反馈'}
{'arxiv_id': 'arXiv:2505.18899', 'title': 'Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos', 'authors': 'Andrea Ramazzina, Vittorio Giammarino, Matteo El-Hariry, Mario Bijelic', 'link': 'https://arxiv.org/abs/2505.18899', 'abstract': 'Imitation from videos often fails when expert demonstrations and learner environments exhibit domain shifts, such as discrepancies in lighting, color, or texture. While visual randomization partially addresses this problem by augmenting training data, it remains computationally intensive and inherently reactive, struggling with unseen scenarios. We propose a different approach: instead of randomizing appearances, we eliminate their influence entirely by rethinking the sensory representation itself. Inspired by biological vision systems that prioritize temporal transients (e.g., retinal ganglion cells) and by recent sensor advancements, we introduce event-inspired perception for visually robust imitation. Our method converts standard RGB videos into a sparse, event-based representation that encodes temporal intensity gradients, discarding static appearance features. This biologically grounded approach disentangles motion dynamics from visual style, enabling robust visual imitation from observations even in the presence of visual mismatches between expert and agent environments. By training policies on event streams, we achieve invariance to appearance-based distractors without requiring computationally expensive and environment-specific data augmentation techniques. Experiments across the DeepMind Control Suite and the Adroit platform for dynamic dexterous manipulation show the efficacy of our method. Our code is publicly available at Eb-LAIfO.', 'abstract_zh': '视频中的模仿在专家演示和学习者环境存在领域偏移时常常失败，例如光照、色彩或纹理方面的差异。虽然视觉随机化可以通过增强训练数据部分解决这一问题，但它仍然计算密集且本质上是被动的，难以应对未见过的情景。我们提出一种不同的方法：不是随机化外观，而是完全消除其影响，重新思考感知本身。受到生物视觉系统优先处理时间暂态特征（如视网膜 ganglion 细胞）以及最近传感器进步的启发，我们引入事件启发式感知以实现视觉鲁棒模仿。我们的方法将标准 RGB 视频转换为稀疏的事件基表示，编码时间强度梯度，同时丢弃静态外观特征。这一生物启发的方法将运动动态与视觉样式解耦，即使在专家和代理环境之间存在视觉不匹配的情况下也能实现鲁棒的视觉模仿。通过在事件流上训练策略，我们实现了对外观基干扰的不变性，而无需使用计算昂贵且环境特定的数据增强技术。在 DeepMind 控制套件和 Adroit 平台上进行的实验展示了我们方法的有效性。我们的代码可在 Eb-LAIfO 公开获得。', 'title_zh': '超越领域随机化：基于事件的感知方法实现视觉稳健的视频中对手模仿'}
{'arxiv_id': 'arXiv:2505.18881', 'title': 'SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes', 'authors': 'Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang', 'link': 'https://arxiv.org/abs/2505.18881', 'abstract': 'We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.', 'abstract_zh': '面向动态场景的开放词汇对象导航语义感知数据集和基准生成管道（SD-OVON）', 'title_zh': '基于语义感知的开放词汇物体导航动态场景数据集和基准生成管道'}
{'arxiv_id': 'arXiv:2505.18810', 'title': 'Discrete gradient methods for port-Hamiltonian differential-algebraic equations', 'authors': 'Philipp L. Kinon, Riccardo Morandin, Philipp Schulze', 'link': 'https://arxiv.org/abs/2505.18810', 'abstract': 'Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian differential-algebraic equations - as they emerge from the port- and energy-based modeling of physical systems in various domains. We introduce a novel numerical scheme tailored for semi-explicit differential-algebraic equations and further address more general settings using the concepts of discrete gradient pairs and Dirac-dissipative structures. Additionally, the behavior under system transformations is investigated and we demonstrate that under suitable assumptions port-Hamiltonian differential-algebraic equations admit a representation which consists of a parametrized port-Hamiltonian semi-explicit system and an unstructured equation. Finally, we present the application to multibody system dynamics and discuss numerical results to demonstrate the capabilities of our approach.', 'abstract_zh': '离散梯度方法是动力系统时间离散化的一个强大工具，因为它在总能量形式不同的情况下都能保持结构。在本文中，我们讨论了离散梯度方法在一类非线性端口哈密尔顿微分代数方程系统中的应用——这类方程源自不同领域物理系统的端口和能量导向建模。我们引入了一种针对半隐式微分代数方程的新型数值方案，并利用离散梯度对和狄拉克耗散结构的概念处理更一般的设置。此外，我们研究了系统变换下的行为，并证明在适当假设下，端口哈密尔顿微分代数方程可以表示为参数化端口哈密尔顿半隐式系统和无结构方程的组合。最后，我们展示了在多体系统动力学中的应用，并讨论了数值结果以证明我们方法的能力。', 'title_zh': 'porte-哈密尔顿差分代数方程的离散梯度方法'}
{'arxiv_id': 'arXiv:2505.18795', 'title': 'Distributed Expectation Propagation for Multi-Object Tracking over Sensor Networks', 'authors': 'Qing Li, Runze Gan, James R. Hopgood, Michael E. Davies, Simon J. Godsill', 'link': 'https://arxiv.org/abs/2505.18795', 'abstract': 'In this paper, we present a novel distributed expectation propagation algorithm for multiple sensors, multiple objects tracking in cluttered environments. The proposed framework enables each sensor to operate locally while collaboratively exchanging moment estimates with other sensors, thus eliminating the need to transmit all data to a central processing node. Specifically, we introduce a fast and parallelisable Rao-Blackwellised Gibbs sampling scheme to approximate the tilted distributions, which enhances the accuracy and efficiency of expectation propagation updates. Results demonstrate that the proposed algorithm improves both communication and inference efficiency for multi-object tracking tasks with dynamic sensor connectivity and varying clutter levels.', 'abstract_zh': '本文提出了一种用于杂波环境中多传感器多目标跟踪的新型分布式期望传播算法。该框架使每个传感器可以在本地操作的同时与其他传感器协作交换矩估计，从而消除将所有数据传输到中央处理节点的需要。具体而言，我们引入了一种快速且可并行化的Rao-Blackwellised吉布斯抽样方案来逼近倾斜分布，这增强了期望传播更新的准确性和效率。结果表明，所提出算法在动态传感器连接性和变化的杂波水平下提高了多目标跟踪任务的通信和推理效率。', 'title_zh': '分布式期望传播在传感器网络中的多目标跟踪'}
{'arxiv_id': 'arXiv:2505.18553', 'title': 'Applying Ontologies and Knowledge Augmented Large Language Models to Industrial Automation: A Decision-Making Guidance for Achieving Human-Robot Collaboration in Industry 5.0', 'authors': 'John Oyekan, Christopher Turner, Michael Bax, Erich Graf', 'link': 'https://arxiv.org/abs/2505.18553', 'abstract': 'The rapid advancement of Large Language Models (LLMs) has resulted in interest in their potential applications within manufacturing systems, particularly in the context of Industry 5.0. However, determining when to implement LLMs versus other Natural Language Processing (NLP) techniques, ontologies or knowledge graphs, remains an open question. This paper offers decision-making guidance for selecting the most suitable technique in various industrial contexts, emphasizing human-robot collaboration and resilience in manufacturing. We examine the origins and unique strengths of LLMs, ontologies, and knowledge graphs, assessing their effectiveness across different industrial scenarios based on the number of domains or disciplines required to bring a product from design to manufacture. Through this comparative framework, we explore specific use cases where LLMs could enhance robotics for human-robot collaboration, while underscoring the continued relevance of ontologies and knowledge graphs in low-dependency or resource-constrained sectors. Additionally, we address the practical challenges of deploying these technologies, such as computational cost and interpretability, providing a roadmap for manufacturers to navigate the evolving landscape of Language based AI tools in Industry 5.0. Our findings offer a foundation for informed decision-making, helping industry professionals optimize the use of Language Based models for sustainable, resilient, and human-centric manufacturing. We also propose a Large Knowledge Language Model architecture that offers the potential for transparency and configuration based on complexity of task and computing resources available.', 'abstract_zh': '大型语言模型的迅速进步引起了对其在制造系统中潜在应用的关注，特别是在Industry 5.0的背景下。然而，确定在何种情境下应实施大型语言模型而非其他自然语言处理技术、本体论或知识图谱仍是一个开放问题。本文提供了在不同工业背景下选择最适宜技术的决策指导，强调了人机协作和制造的韧性。我们探讨了大型语言模型、本体论和知识图谱的起源及其独特优势，并基于产品从设计到制造所需的不同领域或学科数量评估它们在不同工业场景中的有效性。通过这种对比框架，我们探讨了大型语言模型可能增强机器人以促进人机协作的具体应用场景，同时强调了本体论和知识图谱在低依赖性或资源受限领域中的持续相关性。此外，我们还讨论了这些技术的部署挑战，如计算成本和可解释性问题，并为制造商提供了一条路径，以便他们在Industry 5.0的不断变化的语言基础人工智能工具环境中导航。我们的研究结果为基于语言的模型在可持续、韧性和以人为中心的制造中的应用提供了决策基础。我们还提出了一个大型知识语言模型架构，该架构可以根据任务复杂性和可用计算资源提供透明性和配置能力。', 'title_zh': '基于本体和知识增强的大语言模型在工业自动化中的应用：实现 Industry 5.0 中人机协作的决策指导'}
{'arxiv_id': 'arXiv:2505.18371', 'title': 'Military AI Needs Technically-Informed Regulation to Safeguard AI Research and its Applications', 'authors': 'Riley Simmons-Edler, Jean Dong, Paul Lushenko, Kanaka Rajan, Ryan P. Badman', 'link': 'https://arxiv.org/abs/2505.18371', 'abstract': 'Military weapon systems and command-and-control infrastructure augmented by artificial intelligence (AI) have seen rapid development and deployment in recent years. However, the sociotechnical impacts of AI on combat systems, military decision-making, and the norms of warfare have been understudied. We focus on a specific subset of lethal autonomous weapon systems (LAWS) that use AI for targeting or battlefield decisions. We refer to this subset as AI-powered lethal autonomous weapon systems (AI-LAWS) and argue that they introduce novel risks -- including unanticipated escalation, poor reliability in unfamiliar environments, and erosion of human oversight -- all of which threaten both military effectiveness and the openness of AI research. These risks cannot be addressed by high-level policy alone; effective regulation must be grounded in the technical behavior of AI models. We argue that AI researchers must be involved throughout the regulatory lifecycle. Thus, we propose a clear, behavior-based definition of AI-LAWS -- systems that introduce unique risks through their use of modern AI -- as a foundation for technically grounded regulation, given that existing frameworks do not distinguish them from conventional LAWS. Using this definition, we propose several technically-informed policy directions and invite greater participation from the AI research community in military AI policy discussions.', 'abstract_zh': '人工智能增强的军事武器系统和指挥控制基础设施在近年来取得了 rapid development and deployment。然而，人工智能对战斗系统、军事决策以及战争规范的社会技术影响仍然研究不足。我们专注于使用人工智能进行目标识别或战场决策的特定类型致命自主武器系统（LAWS），并将这一子类称为人工智能驱动的致命自主武器系统（AI-LAWS），认为它们引入了新颖的风险，包括意外升级、在不熟悉环境中可靠性差以及人类监督的削弱，这些风险威胁到军事有效性以及人工智能研究的开放性。这些问题仅靠高层次政策无法解决；有效的监管必须基于人工智能模型的技术行为。我们主张在整个监管生命周期中都应该包括人工智能研究人员。因此，我们提出了一种明确的行为基础定义——通过使用现代人工智能引入独特风险的系统——作为技术基础的监管基础，因为现有的框架没有将它们与传统LAWS区分开来。基于这一定义，我们提出了若干技术导向的政策方向，并邀请人工智能研究社区在军事人工智能政策讨论中发挥更大的作用。', 'title_zh': '军事AI需要技术导向的监管以保障AI研究及其应用的安全'}
{'arxiv_id': 'arXiv:2505.18361', 'title': 'Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain', 'authors': 'Trinity Chung, Yuchen Shen, Nathan C. L. Kong, Aran Nayebi', 'link': 'https://arxiv.org/abs/2505.18361', 'abstract': 'Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language. We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment. Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.\nFor neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.', 'abstract_zh': '触觉感知在神经科学中仍然远不如视觉和语言等更成熟的感觉模态被理解，且在人工系统中也表现得不够有效。我们通过介绍一种新型的编码-注意-解码（EAD）框架，系统性地探索基于定制化啮齿动物须触器阵列模拟器的现实触觉输入序列训练的任务优化时序神经网络的空间。我们发现卷积循环神经网络（ConvRNN）在触觉分类任务中优于单纯的前馈和状态空间架构。关键的是，基于ConvRNN编码器的EAD模型能够实现与啮齿动物体感皮层神经表征高度一致的表示，饱和可解释的神经变异性，并揭示了监督分类性能与神经对齐之间明确的线性关系。此外，通过触觉特定的数据增强进行对比自监督学习训练的基于ConvRNN编码器的EAD模型，能够在监督神经拟合方面表现出一致的性能，充当一种生态相关的无标签代理。对于神经科学，我们的发现强调了非线性时序处理对于体感皮层通用触觉表征的重要性，并提供了对该系统底层归纳偏好的首次定量表征。对于具身AI，我们的结果强调了使用循环EAD架构以及定制化的自监督学习方法来处理现实触觉输入和实现具有相同传感器的鲁棒触觉感知的重要性，这些传感器与动物在不规则环境中感知的方式相同。', 'title_zh': '任务优化的卷积循环网络与啮齿类大脑的触觉处理相一致'}
{'arxiv_id': 'arXiv:2505.18291', 'title': 'InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning', 'authors': 'Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia Sycara', 'link': 'https://arxiv.org/abs/2505.18291', 'abstract': "Large multimodal foundation models, particularly in the domains of language and vision, have significantly advanced various tasks, including robotics, autonomous driving, information retrieval, and grounding. However, many of these models perceive objects as indivisible, overlooking the components that constitute them. Understanding these components and their associated affordances provides valuable insights into an object's functionality, which is fundamental for performing a wide range of tasks. In this work, we introduce a novel real-world benchmark, InstructPart, comprising hand-labeled part segmentation annotations and task-oriented instructions to evaluate the performance of current models in understanding and executing part-level tasks within everyday contexts. Through our experiments, we demonstrate that task-oriented part segmentation remains a challenging problem, even for state-of-the-art Vision-Language Models (VLMs). In addition to our benchmark, we introduce a simple baseline that achieves a twofold performance improvement through fine-tuning with our dataset. With our dataset and benchmark, we aim to facilitate research on task-oriented part segmentation and enhance the applicability of VLMs across various domains, including robotics, virtual reality, information retrieval, and other related fields. Project website: this https URL.", 'abstract_zh': '大型多模态基础模型，特别是在语言和视觉领域，显著推进了包括机器人技术、自动驾驶、信息检索和语义 grounding 等多种任务的发展。然而，这些模型往往将物体视为不可分割的整体，忽视了组成它们的部件。理解这些部件及其相关的功能属性，能够为物体的功能性提供宝贵见解，这在执行广泛的任务中是至关重要的。在本项工作中，我们引入了一个新的真实世界基准 InstructPart，该基准包含手工标注的部件分割注释和任务导向的指令，以评估当前模型在理解和执行日常情景中的部件级任务方面的性能。通过我们的实验，我们展示了即使对于最先进的视觉-语言模型（VLMs），面向任务的部件分割仍然是一个具有挑战性的问题。此外，我们还引入了一个简单的基线模型，通过与我们数据集的微调实现了性能的两倍提升。借助我们的数据集和基准，我们旨在促进面向任务的部件分割研究，并增强视觉-语言模型在包括机器人技术、虚拟现实、信息检索以及相关领域中的适用性。项目网站: [this https URL]。', 'title_zh': '指令部分：基于指令推理的任务导向部分分割'}
{'arxiv_id': 'arXiv:2505.18187', 'title': 'Discretization of Linear Systems using the Matrix Exponential', 'authors': 'Steven Dahdah, James Richard Forbes', 'link': 'https://arxiv.org/abs/2505.18187', 'abstract': 'Discretizing continuous-time linear systems typically requires numerical integration. This document presents a convenient method for discretizing the dynamics, input, and process noise state-space matrices of a continuous-time linear system using a single matrix exponential.', 'abstract_zh': '连续时间线性系统离散化通常需要数值积分。本文介绍了一种使用单个矩阵指数方便离散化连续时间线性系统动力学、输入和过程噪声状态空间矩阵的方法。', 'title_zh': '线性系统用矩阵指数的离散化'}
{'arxiv_id': 'arXiv:2505.18173', 'title': 'IoT-Enabled Hemodynamic Surveillance System: AD8232 Bioelectric Signal Processing with ESP32', 'authors': 'Hemalatha R J, Shubham Malhotra, Shivapanchakshari T G, Lokesh K, Dev Anand D, Samson Jebakumar S', 'link': 'https://arxiv.org/abs/2505.18173', 'abstract': "This dissertation proposes an electrocardiogram (ECG) tracking device that diagnoses cardiopulmonary problems using the Internet of Things (IoT) desired results. The initiative is built on the internet observing an electrocardiogram with the AD8232 heart rhythm sensor and the ESP32 expansion kit, using an on-premise connected device platform to transform sensing input into meaningful data. That subsequently supervises an ECG signal and delivers it to an intelligent phone via Wi-Fi for data analysis. That is the pace of the circulating. Assessing body temperature, pulse rate, and coronary arteries are vital measures to defend your health. The heartbeat rate may be measured in two ways: there are by palpating the pulse at the wrist or neck directly or other alternative by utilizing a cardiac sensor. Monitoring alcohol levels in cardiac patients is critical for measuring the influence of liquor on their health and the efficacy of therapy. It assists in recognizing the association between alcohol consumption and cardiac issues, rather than rhythm recorded in beats per minute (bpm). An IR transmitter/receiver pair (OLED) needs to stay compatible up near the sensor's knuckle current or voltage pulse. The detector's electrical output is evaluated by suitable electronic circuits to produce a visual clue (digital display). We must design a cost-effective, user-friendly, and efficient ECG monitoring system with contemporary technology for both persons imprisoned by disease or aging, as well as healthcare professionals. Microcontroller combined with software. A smartphone application is created to monitor the cardiovascular health of distant patients in real-time", 'abstract_zh': '基于物联网的心电图跟踪设备及其在心血管问题诊断中的应用', 'title_zh': '基于IoT的心动过缓监测系统：AD8232 生物电信号处理与ESP32'}
