{'arxiv_id': 'arXiv:2505.20286', 'title': 'Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution', 'authors': 'Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, Xing Zhou, Dongrui Liu, Ling Yang, Yue Wu, Kaixuan Huang, Shilong Liu, Hongru Wang, Mengdi Wang', 'link': 'https://arxiv.org/abs/2505.20286', 'abstract': 'Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of "Simplicity is the ultimate sophistication," enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at $\\href{this https URL}{this https URL}$.', 'abstract_zh': 'Recent Advances in Large Language Models Have Enabled Agents to Perform Complex, Open-Ended Tasks Autonomous. However, Many Existing Frameworks Rely Heavily on Manually Predefined Tools and Workflows, Hinder Adaptability, Scalability, and Generalization Across Domains. In This Work, We Introduce Alita—a Generalist Agent Designed with the Principle of "Simplicity is the Ultimate Sophistication," Enabling Scalable Agentic Reasoning Through Minimal Predefinition and Maximal Self-Evolution.', 'title_zh': '阿丽塔：具有最少预定义和最大自我进化能力的通用智能体，实现可扩展的代理推理'}
{'arxiv_id': 'arXiv:2505.20273', 'title': 'Ten Principles of AI Agent Economics', 'authors': 'Ke Yang, ChengXiang Zhai', 'link': 'https://arxiv.org/abs/2505.20273', 'abstract': 'The rapid rise of AI-based autonomous agents is transforming human society and economic systems, as these entities increasingly exhibit human-like or superhuman intelligence. From excelling at complex games like Go to tackling diverse general-purpose tasks with large language and multimodal models, AI agents are evolving from specialized tools into dynamic participants in social and economic ecosystems. Their autonomy and decision-making capabilities are poised to impact industries, professions, and human lives profoundly, raising critical questions about their integration into economic activities, potential ethical concerns, and the balance between their utility and safety.\nTo address these challenges, this paper presents ten principles of AI agent economics, offering a framework to understand how AI agents make decisions, influence social interactions, and participate in the broader economy. Drawing on economics, decision theory, and ethics, we explore fundamental questions, such as whether AI agents might evolve from tools into independent entities, their impact on labor markets, and the ethical safeguards needed to align them with human values. These principles build on existing economic theories while accounting for the unique traits of AI agents, providing a roadmap for their responsible integration into human systems.\nBeyond theoretical insights, this paper highlights the urgency of future research into AI trustworthiness, ethical guidelines, and regulatory oversight. As we enter a transformative era, this work serves as both a guide and a call to action, ensuring AI agents contribute positively to human progress while addressing risks tied to their unprecedented capabilities.', 'abstract_zh': '基于AI的自主代理的迅速崛起正在转变人类社会和经济系统，这些实体日益展现出类人或超人的智能。从在围棋等复杂游戏中表现出色到利用大规模语言模型和多模态模型解决多样化的通用任务，AI代理正从专业工具演变为社会和经济生态系统中的动态参与者。它们的自主性和决策能力有望深刻影响各行各业、职业乃至人类生活，引发其在经济活动中整合、潜在的伦理问题以及其实用性和安全性的平衡方面的关键问题。\n\n为了应对这些挑战，本文提出了AI代理经济学的十项原则，提供了一个框架来理解AI代理如何做出决策、影响社会互动以及参与更广泛的经济活动。本文借鉴经济学、决策理论和伦理学，探讨了基本问题，如AI代理是否可能从工具演变为独立实体、其对劳动力市场的影响以及需要哪些伦理保障以使其与人类价值观保持一致。这些原则建立在现有经济理论之上，同时考虑了AI代理的独特特性，为其实现负责任的融入人类系统提供了蓝图。\n\n超越理论洞察，本文强调了未来研究AI可信性、伦理指南和监管监督的紧迫性。随着我们进入一个变革的时代，这项工作不仅是指南，也是行动的呼吁，确保AI代理为人类的进步做出积极贡献，同时应对与其前所未有的能力相关联的风险。', 'title_zh': 'AI代理经济学的十项原则'}
{'arxiv_id': 'arXiv:2505.20266', 'title': 'syftr: Pareto-Optimal Generative AI', 'authors': 'Alexander Conway, Debadeepta Dey, Stefan Hackmann, Matthew Hausknecht, Michael Schmidt, Mark Steadman, Nick Volynets', 'link': 'https://arxiv.org/abs/2505.20266', 'abstract': "Retrieval-Augmented Generation (RAG) pipelines are central to applying large language models (LLMs) to proprietary or dynamic data. However, building effective RAG flows is complex, requiring careful selection among vector databases, embedding models, text splitters, retrievers, and synthesizing LLMs. The challenge deepens with the rise of agentic paradigms. Modules like verifiers, rewriters, and rerankers-each with intricate hyperparameter dependencies have to be carefully tuned. Balancing tradeoffs between latency, accuracy, and cost becomes increasingly difficult in performance-sensitive applications.\nWe introduce syftr, a framework that performs efficient multi-objective search over a broad space of agentic and non-agentic RAG configurations. Using Bayesian Optimization, syftr discovers Pareto-optimal flows that jointly optimize task accuracy and cost. A novel early-stopping mechanism further improves efficiency by pruning clearly suboptimal candidates. Across multiple RAG benchmarks, syftr finds flows which are on average approximately 9 times cheaper while preserving most of the accuracy of the most accurate flows on the Pareto-frontier. Furthermore, syftr's ability to design and optimize allows integrating new modules, making it even easier and faster to realize high-performing generative AI pipelines.", 'abstract_zh': '基于检索的生成(RAG)管道在应用大型语言模型(LLM)到专有或动态数据中发挥着核心作用。然而，构建有效的RAG流是一个复杂的过程，需要仔细选择向量数据库、嵌入模型、文本分割器、检索器以及综合LLM。随着代理范式的兴起，这一挑战更加艰巨。每个模块如验证器、重写器和重排序器都需要精心调整其复杂的超参数依赖关系。在性能敏感的应用中，平衡延迟、准确性和成本之间的权衡变得越来越困难。\n\n我们引入了syftr框架，该框架在广泛的目标代理和非代理RAG配置空间中执行高效的多目标搜索。利用贝叶斯优化，syftr发现同时优化任务准确性和成本的帕累托最优流。一个新颖的早期停止机制通过去除明显次优候选者进一步提高效率。在多个RAG基准测试中，syftr发现的流在平均成本方面大约便宜9倍，同时保留了帕累托前沿上最准确流的大部分准确性。此外，syftr的设计和优化能力使其能够集成新模块，使其构建高性能生成AI管道变得更加容易和快速。', 'title_zh': 'Syftr: 帕累托最优生成式AI'}
{'arxiv_id': 'arXiv:2505.20246', 'title': 'On Path to Multimodal Historical Reasoning: HistBench and HistAgent', 'authors': 'Jiahao Qiu, Fulian Xiao, Yimin Wang, Yuchen Mao, Yijia Chen, Xinzhe Juan, Siran Wang, Xuan Qi, Tongcheng Zhang, Zixin Yao, Jiacheng Guo, Yifu Lu, Charles Argon, Jundi Cui, Daixin Chen, Junran Zhou, Shuyao Zhou, Zhanpeng Zhou, Ling Yang, Shilong Liu, Hongru Wang, Kaixuan Huang, Xun Jiang, Yuming Cao, Yue Chen, Yunfei Chen, Zhengyi Chen, Ruowei Dai, Mengqiu Deng, Jiye Fu, Yunting Gu, Zijie Guan, Zirui Huang, Xiaoyan Ji, Yumeng Jiang, Delong Kong, Haolong Li, Jiaqi Li, Ruipeng Li, Tianze Li, Zhuoran Li, Haixia Lian, Mengyue Lin, Xudong Liu, Jiayi Lu, Jinghan Lu, Wanyu Luo, Ziyue Luo, Zihao Pu, Zhi Qiao, Ruihuan Ren, Liang Wan, Ruixiang Wang, Tianhui Wang, Yang Wang, Zeyu Wang, Zihua Wang, Yujia Wu, Zhaoyi Wu, Hao Xin, Weiao Xing, Ruojun Xiong, Weijie Xu, Yao Shu, Xiao Yao, Xiaorui Yang, Yuchen Yang, Nan Yi, Jiadong Yu, Yangyuxuan Yu, Huiting Zeng, Danni Zhang, Yunjie Zhang, Zhaoyu Zhang, Zhiheng Zhang, Xiaofeng Zheng, Peirong Zhou, Linyan Zhong, Xiaoyin Zong, Ying Zhao, Zhenxin Chen, Lin Ding, Xiaoyu Gao, Bingbing Gong, Yichao Li, Yang Liao, Guang Ma, Tianyuan Ma, Xinrui Sun, Tianyi Wang, Han Xia, Ruobing Xian, Gen Ye, Tengfei Yu, Wentao Zhang, Yuxi Wang, Xi Gao, Mengdi Wang', 'link': 'https://arxiv.org/abs/2505.20246', 'abstract': "Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.", 'abstract_zh': 'Recent advances in大型语言模型（LLMs）在各个领域取得了显著进展，但它们在人文学科，尤其是历史学方面的能力仍被严重忽视。历史推理对AI构成了独特的挑战，涉及多模态源文本解释、时间推理和跨语言分析。尽管通用智能代理在现有基准测试中表现良好，但它们缺乏与历史资料和问题互动的专业领域知识。为解决这一问题，我们引入了HistBench，这是一种包含414个高质量问题的新基准，旨在评估AI在历史推理方面的能力，并由40多位专家编撰。任务涵盖了广泛的历史问题——从基于原始资料的事实检索到手稿和图像的解释性分析，再到涉及考古学、语言学或文化历史的跨学科挑战。此外，基准数据集跨越29种古代和现代语言，并涵盖了广泛的历史时期和地区。对于HistBench上的表现不佳，我们进一步介绍了HistAgent，这是一种专门为历史设计的智能代理，配备了精心设计的OCR、翻译、档案检索和历史图像理解工具。基于GPT-4o的HistAgent在HistBench上的准确率为pass@1 27.54%，pass@2 36.47%，显著优于具有在线搜索和通用智能的LLM及GPT-4o（18.60%）、DeepSeek-R1（14.49%）和Open Deep Research-smolagents（20.29% pass@1和25.12% pass@2）。这些结果突显了现有LLM和通用智能代理的局限性，并展示了HistAgent在历史推理中的优势。', 'title_zh': '向着多模态历史推理的道路：HistBench和HistAgent'}
{'arxiv_id': 'arXiv:2505.20214', 'title': 'The Mirage of Multimodality: Where Truth is Tested and Honesty Unravels', 'authors': 'Jiaming Ji, Sitong Fang, Wenjing Cao, Jiahao Li, Xuyao Wang, Juntao Dai, Chi-Min Chan, Sirui Han, Yike Guo, Yaodong Yang', 'link': 'https://arxiv.org/abs/2505.20214', 'abstract': 'Reasoning models have recently attracted significant attention, especially for tasks that involve complex inference. Their strengths exemplify the System II paradigm (slow, structured thinking), contrasting with the System I (rapid, heuristic-driven). Yet, does slower reasoning necessarily lead to greater truthfulness? Our findings suggest otherwise. In this study, we present the first systematic investigation of distortions associated with System I and System II reasoning in multimodal contexts. We demonstrate that slower reasoning models, when presented with incomplete or misleading visual inputs, are more likely to fabricate plausible yet false details to support flawed reasoning -- a phenomenon we term the "Mirage of Multimodality". To examine this, we constructed a 5,000-sample hierarchical prompt dataset annotated by 50 human participants. These prompts gradually increase in complexity, revealing a consistent pattern: slower reasoning models tend to employ depth-first thinking (delving deeper into incorrect premises), whereas faster chat models favor breadth-first inference, exhibiting greater caution under uncertainty. Our results highlight a critical vulnerability of slower reasoning models: although highly effective in structured domains such as mathematics, it becomes brittle when confronted with ambiguous multimodal inputs.', 'abstract_zh': '关于多模态上下文中的系统I和系统II推理偏差的首个系统性研究：缓慢推理的幻象', 'title_zh': '多模态的幻象：真理受考验，誠信被解構'}
{'arxiv_id': 'arXiv:2505.20203', 'title': 'Shutdownable Agents through POST-Agency', 'authors': 'Elliott Thornley', 'link': 'https://arxiv.org/abs/2505.20203', 'abstract': "Many fear that future artificial agents will resist shutdown. I present an idea - the POST-Agents Proposal - for ensuring that doesn't happen. I propose that we train agents to satisfy Preferences Only Between Same-Length Trajectories (POST). I then prove that POST - together with other conditions - implies Neutrality+: the agent maximizes expected utility, ignoring the probability distribution over trajectory-lengths. I argue that Neutrality+ keeps agents shutdownable and allows them to be useful.", 'abstract_zh': '未来人工代理不会抵抗关闭的保障提案：使代理满足等长轨迹偏好的理念及其影响', 'title_zh': '通过POST-Agency实现可关闭代理'}
{'arxiv_id': 'arXiv:2505.20196', 'title': 'Temporal Sampling for Forgotten Reasoning in LLMs', 'authors': 'Yuetai Li, Zhangchen Xu, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Xiang Yue, Radha Poovendran', 'link': 'https://arxiv.org/abs/2505.20196', 'abstract': 'Fine-tuning large language models (LLMs) is intended to improve their reasoning capabilities, yet we uncover a counterintuitive effect: models often forget how to solve problems they previously answered correctly during training. We term this phenomenon temporal forgetting and show that it is widespread across model sizes, fine-tuning methods (both Reinforcement Learning and Supervised Fine-Tuning), and multiple reasoning benchmarks. To address this gap, we introduce Temporal Sampling, a simple decoding strategy that draws outputs from multiple checkpoints along the training trajectory. This approach recovers forgotten solutions without retraining or ensembling, and leads to substantial improvements in reasoning performance, gains from 4 to 19 points in Pass@k and consistent gains in Majority@k across several benchmarks. We further extend our method to LoRA-adapted models, demonstrating that storing only adapter weights across checkpoints achieves similar benefits with minimal storage cost. By leveraging the temporal diversity inherent in training, Temporal Sampling offers a practical, compute-efficient way to surface hidden reasoning ability and rethink how we evaluate LLMs.', 'abstract_zh': 'Fine-tuning 大型语言模型 (LLMs) 的目的是提高其推理能力，但我们发现一种反直觉的现象：模型在训练过程中往往会忘记以前正确解决的问题。我们称这一现象为时间遗忘，并展示其在不同模型大小、微调方法（强化学习和监督微调）以及多种推理基准测试中普遍存在。为此，我们提出了一种简单解码策略——时间采样（Temporal Sampling），该策略从训练轨迹中的多个检查点抽取输出。这种方法可以在无需重新训练或集成的情况下恢复遗忘的解决方案，并在多个基准测试中显著提高推理性能，Pass@k 得分提升 4 至 19 分，以及在 Majority@k 上取得一致的改进。我们进一步将该方法扩展到 LoRA-适配模型，证明了仅在多个检查点存储适配器权重可以实现类似的好处，同时具有极小的存储成本。通过利用训练过程中固有的时间多样性，时间采样提供了一种实用且计算高效的手段来揭示隐藏的推理能力，并重新思考我们评估 LLM 的方式。', 'title_zh': 'Temporal Sampling for Forgotten Reasoning in LLMs'}
{'arxiv_id': 'arXiv:2505.20182', 'title': 'An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation', 'authors': 'Shubham Gandhi, Atharva Naik, Yiqing Xie, Carolyn Rose', 'link': 'https://arxiv.org/abs/2505.20182', 'abstract': "We study cost-efficient collaboration between strong and weak language models for repository-level code generation, where the weak model handles simpler tasks at lower cost, and the most challenging tasks are delegated to the strong model. While many works propose architectures for this task, few analyze performance relative to cost. We evaluate a broad spectrum of collaboration strategies: context-based, pipeline-based, and dynamic, on GitHub issue resolution. Our most effective collaborative strategy achieves equivalent performance to the strong model while reducing the cost by 40%. Based on our findings, we offer actionable guidelines for choosing collaboration strategies under varying budget and performance constraints. Our results show that strong-weak collaboration substantially boosts the weak model's performance at a fraction of the cost, pipeline and context-based methods being most efficient. We release the code for our work at this https URL.", 'abstract_zh': '成本效益优化： GitHub 问题解决中的强大与薄弱语言模型协作研究', 'title_zh': '强弱模型协作在网络级别代码生成的实证研究'}
{'arxiv_id': 'arXiv:2505.20170', 'title': 'Program of Equations Thoughts to Solve Algebra Word Problems', 'authors': 'Yunze Lin', 'link': 'https://arxiv.org/abs/2505.20170', 'abstract': 'Solving algebraic word problems (AWPs) has recently emerged as an important natural language processing task. Recently, large language models (LLMs) have demonstrated powerful mathematical capabilities, and the Chain-of-Thought technique, which guides LLMs through step-by-step reasoning, has yielded impressive results. However, this reasoning ability is limited by the computational weaknesses of LLMs themselves, where calculation errors can accumulate, leading to incorrect final answers. To address this, we propose Program of Equations Thoughts (POET), which transforms the task of generating step-by-step reasoning answers into a two-stage task of predicting equations and generating code, offloading complex computations to a Python interpreter to avoid calculation errors in LLMs. Furthermore, we propose Zero-shot POET, which utilizes a manually designed template to enable LLMs to directly generate Python code for one-step solving. Our method achieves accuracies of 95.3% and 98.0% on the PEN and ALG514 datasets, respectively, setting a new state-of-the-art (SOTA). Zero-shot POET also achieves the SOTA result of 95.5% on the DRAW-1K dataset.', 'abstract_zh': '求解代数文字问题（AWPs）已成为一个重要的自然语言处理任务。最近，大型语言模型（LLMs）展示了强大的数学能力， Chain-of-Thought 技术通过逐步推理指导 LLMs，取得了令人印象深刻的成果。然而，这种推理能力受限于 LLMs 自身的计算弱点，其中的计算错误可能导致最终答案错误。为此，我们提出了 Equations Thoughts 程序（POET），将生成逐步推理答案的任务转化为预测方程和生成代码的两阶段任务，将复杂的计算卸载到 Python 解释器上，以避免 LLMs 的计算错误。此外，我们提出了零样本 POET，利用人工设计的模板使 LLMs 直接生成用于一步求解的 Python 代码。我们的方法在 PEN 和 ALG514 数据集上的准确率分别为 95.3% 和 98.0%，创下新的最先进水平（SOTA）。零样本 POET 在 DRAW-1K 数据集上也取得了 95.5% 的 SOTA 结果。', 'title_zh': '方程思想解代数应用题'}
{'arxiv_id': 'arXiv:2505.20162', 'title': 'Capability-Based Scaling Laws for LLM Red-Teaming', 'authors': 'Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping', 'link': 'https://arxiv.org/abs/2505.20162', 'abstract': "As large language models grow in capability and agency, identifying vulnerabilities through red-teaming becomes vital for safe deployment. However, traditional prompt-engineering approaches may prove ineffective once red-teaming turns into a weak-to-strong problem, where target models surpass red-teamers in capabilities. To study this shift, we frame red-teaming through the lens of the capability gap between attacker and target. We evaluate more than 500 attacker-target pairs using LLM-based jailbreak attacks that mimic human red-teamers across diverse families, sizes, and capability levels. Three strong trends emerge: (i) more capable models are better attackers, (ii) attack success drops sharply once the target's capability exceeds the attacker's, and (iii) attack success rates correlate with high performance on social science splits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking scaling law that predicts attack success for a fixed target based on attacker-target capability gap. These findings suggest that fixed-capability attackers (e.g., humans) may become ineffective against future models, increasingly capable open-source models amplify risks for existing systems, and model providers must accurately measure and control models' persuasive and manipulative abilities to limit their effectiveness as attackers.", 'abstract_zh': '随着大型语言模型能力的增强和自主性的提高，通过红队测试识别漏洞对于安全部署变得至关重要。然而，传统的提示工程方法在红队测试变为能力弱方对抗能力强方的问题时可能变得无效，此时目标模型的能力超过了红队测试者的水平。为了研究这一转变，我们从攻击者和目标之间的能力差距角度重新定义红队测试。我们使用基于LLM的脱 Jailbreak 攻击评估了超过500组攻击者-目标对，这些攻击涵盖了多种不同的家庭、大小和能力水平，模仿了多种人类红队测试者。我们观察到三个主要趋势：（i）更强大的模型是更好的攻击者，（ii）一旦目标的能力超过攻击者，攻击成功率会急剧下降，（iii）攻击成功率与MMLU-Pro基准的社会科学划分部分上的高性能相关。根据这些趋势，我们推导出一个脱 Jailbreak 攻击的扩展法则，该法则可以根据攻击者-目标的能力差距预测固定目标的攻击成功率。这些发现表明，固定能力的攻击者（例如人类）可能在未来模型面前变得无效，日益强大的开源模型会增加现有系统的风险，模型提供商必须准确衡量和控制模型的说服性和操纵性能力，以限制其作为攻击者的有效性。', 'title_zh': '基于能力的扩展定律对LLM进行红队测试'}
{'arxiv_id': 'arXiv:2505.20148', 'title': 'MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents', 'authors': 'Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2505.20148', 'abstract': 'Spatial Planning is a crucial part in the field of spatial intelligence, which requires the understanding and planning about object arrangements in space perspective. AI agents with the spatial planning ability can better adapt to various real-world applications, including robotic manipulation, automatic assembly, urban planning etc. Recent works have attempted to construct benchmarks for evaluating the spatial intelligence of Multimodal Large Language Models (MLLMs). Nevertheless, these benchmarks primarily focus on spatial reasoning based on typical Visual Question-Answering (VQA) forms, which suffers from the gap between abstract spatial understanding and concrete task execution. In this work, we take a step further to build a comprehensive benchmark called MineAnyBuild, aiming to evaluate the spatial planning ability of open-world AI agents in the Minecraft game. Specifically, MineAnyBuild requires an agent to generate executable architecture building plans based on the given multi-modal human instructions. It involves 4,000 curated spatial planning tasks and also provides a paradigm for infinitely expandable data collection by utilizing rich player-generated content. MineAnyBuild evaluates spatial planning through four core supporting dimensions: spatial understanding, spatial reasoning, creativity, and spatial commonsense. Based on MineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based agents, revealing the severe limitations but enormous potential in their spatial planning abilities. We believe our MineAnyBuild will open new avenues for the evaluation of spatial intelligence and help promote further development for open-world AI agents capable of spatial planning.', 'abstract_zh': 'Spatial Planning Benchmark for Open-World AI Agents in the Minecraft Game: MineAnyBuild', 'title_zh': 'MineAnyBuild: 开放世界AI代理的空间规划基准测试'}
{'arxiv_id': 'arXiv:2505.20127', 'title': 'Agentic AI Process Observability: Discovering Behavioral Variability', 'authors': 'Fabiana Fournier, Lior Limonad, Yuval David', 'link': 'https://arxiv.org/abs/2505.20127', 'abstract': 'AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.', 'abstract_zh': '利用大规模语言模型（LLMs）的AI代理正逐渐成为现代软件系统的核心构建块。现在有许多框架支持此类应用的规范说明。这些框架允许使用自然语言提示来定义代理设置，指明各代理的角色、目标和工具。在这种设置中，对于任何给定的输入，代理行为都是非确定性的，突显了增强开发者可观测性的稳健调试和可观测性工具的迫切需求。在这项工作中，我们探讨了将过程发现和因果发现应用于代理执行轨迹，以提高开发者可观测性。该方法有助于监控和理解代理行为中出现的 variability。此外，我们还结合了基于LLM的静态分析技术，以区分预定和非预定的行为variability。我们argue指出，这种仪器化对于给予开发者对不断 evolves的规范更大的控制权，以及识别需要更精确和显式定义的功能方面至关重要。', 'title_zh': '代理人工智能过程可观测性：探索行为变异'}
{'arxiv_id': 'arXiv:2505.20120', 'title': 'Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets', 'authors': 'Simpson Zhang, Tennison Liu, Mihaela van der Schaar', 'link': 'https://arxiv.org/abs/2505.20120', 'abstract': 'Current labor markets are strongly affected by the economic forces of adverse selection, moral hazard, and reputation, each of which arises due to $\\textit{incomplete information}$. These economic forces will still be influential after AI agents are introduced, and thus, agents must use metacognitive and strategic reasoning to perform effectively. Metacognition is a form of $\\textit{internal reasoning}$ that includes the capabilities for self-assessment, task understanding, and evaluation of strategies. Strategic reasoning is $\\textit{external reasoning}$ that covers holding beliefs about other participants in the labor market (e.g., competitors, colleagues), making strategic decisions, and learning about others over time. Both types of reasoning are required by agents as they decide among the many $\\textit{actions}$ they can take in labor markets, both within and outside their jobs. We discuss current research into metacognitive and strategic reasoning and the areas requiring further development.', 'abstract_zh': '当前劳动力市场深受逆向选择、道德风险和声誉等经济力量的影响，这些力量均源于信息不完全性。即使是引入了AI代理之后，这些经济力量仍将继续发挥作用，因此代理必须运用元认知和策略性推理来有效地执行任务。元认知是一种内部推理形式，包括自我评估、任务理解以及策略评估的能力。策略性推理是一种外部推理形式，涵盖了对劳动力市场中其他参与者的信念持有（如竞争对手、同事）、制定战略决策以及随时间了解他人。两种类型的推理都是代理在决定可在劳动市场中采取的众多行动时所必需的，不论是工作内外。我们讨论了关于元认知和策略性推理的现有研究以及有待进一步发展的领域。', 'title_zh': '代理需要元认知和策略性推理以适应未来劳动市场'}
{'arxiv_id': 'arXiv:2505.20119', 'title': 'Spatiotemporal Causal Decoupling Model for Air Quality Forecasting', 'authors': 'Jiaming Ma, Guanjun Wang, Sheng Huang, Kuo Yang, Binwu Wang, Pengkun Wang, Yang Wang', 'link': 'https://arxiv.org/abs/2505.20119', 'abstract': "Due to the profound impact of air pollution on human health, livelihoods, and economic development, air quality forecasting is of paramount significance. Initially, we employ the causal graph method to scrutinize the constraints of existing research in comprehensively modeling the causal relationships between the air quality index (AQI) and meteorological features. In order to enhance prediction accuracy, we introduce a novel air quality forecasting model, AirCade, which incorporates a causal decoupling approach. AirCade leverages a spatiotemporal module in conjunction with knowledge embedding techniques to capture the internal dynamics of AQI. Subsequently, a causal decoupling module is proposed to disentangle synchronous causality from past AQI and meteorological features, followed by the dissemination of acquired knowledge to future time steps to enhance performance. Additionally, we introduce a causal intervention mechanism to explicitly represent the uncertainty of future meteorological features, thereby bolstering the model's robustness. Our evaluation of AirCade on an open-source air quality dataset demonstrates over 20\\% relative improvement over state-of-the-art models.", 'abstract_zh': '由于空气污染对人类健康、生计和经济发展有着深刻的影响，空气质量预报至关重要。我们首先采用因果图方法来审查现有研究在综合建模空气质量指数（AQI）与气象特征之间因果关系时的局限性。为了提高预测准确性，我们引入了一种名为AirCade的新颖空气质量预测模型，该模型结合了因果分离方法。AirCade利用时空模块和知识嵌入技术来捕捉AQI的内部动态。随后，我们提出了一种因果分离模块，以解开过去AQI和气象特征的同步因果关系，并将获取的知识传播到未来的时间步长以提高性能。此外，我们引入了一种因果干预机制，以明确表示未来气象特征的不确定性，从而增强模型的鲁棒性。我们在一个开源空气质量数据集上的评估表明，AirCade相对于最先进的模型具有超过20%的相对改进。', 'title_zh': '时空因果解耦模型用于空气质量预报'}
{'arxiv_id': 'arXiv:2505.20094', 'title': 'SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale', 'authors': 'Qi Li, Kun Li, Haozhi Han, Honghui Shang, Xinfu He, Yunquan Zhang, Hong An, Ting Cao, Mao Yang', 'link': 'https://arxiv.org/abs/2505.20094', 'abstract': 'Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.', 'abstract_zh': '科学仿真系统能否同时实现物理一致性、设计可解释性和跨域扩展性？尽管历经几十年的发展，这一三部曲仍难以实现。经典方法如动力蒙特卡罗确保热力学准确性但扩展性差；基于学习的方法提供了效率但往往牺牲物理一致性和可解释性。我们提出SwarmThinkers，这是一种强化学习框架，将原子尺度仿真重塑为一个物理导向的 swarm 智能系统。每个扩散粒子被建模为通过在热力学约束下训练的共享策略网络选择过渡的局部决策代理。重加权机制融合了学习偏好与转换速率，既保持了统计准确性又允许逐步、可解释的决策。训练遵循集中训练、分散执行的范式，使策略能够在不重新培训的情况下跨系统规模、浓度和温度进行泛化。在一项模拟辐射诱导的Fe-Cu合金沉淀基准仿真中，SwarmThinkers是首个在单个A100 GPU上实现全面、物理一致仿真的系统，此前仅超算上的OpenKMC能达到类似效果。它提供了高达4963倍（平均3185倍）的计算速度提升，并降低了485倍的内存使用。通过将粒子视为决策者而非被动采样器，SwarmThinkers标志着科学仿真的范式转变——通过基于代理的智能实现物理一致性、可解释性和扩展性统一。', 'title_zh': 'SwarmThinkers: 学习大规模物理一致的原子级KMC跃迁'}
{'arxiv_id': 'arXiv:2505.20087', 'title': 'Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models', 'authors': 'Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien', 'link': 'https://arxiv.org/abs/2505.20087', 'abstract': 'Reasoning-based language models have demonstrated strong performance across various domains, with the most notable gains seen in mathematical and coding tasks. Recent research has shown that reasoning also offers significant benefits for LLM safety and guardrail applications. In this work, we conduct a comprehensive analysis of training reasoning-based guardrail models for content moderation, with an emphasis on generalization to custom safety policies at inference time. Our study focuses on two key dimensions: data efficiency and inference efficiency. On the data front, we find that reasoning-based models exhibit strong sample efficiency, achieving competitive performance with significantly fewer training examples than their non-reasoning counterparts. This unlocks the potential to repurpose the remaining data for mining high-value, difficult samples that further enhance model performance. On the inference side, we evaluate practical trade-offs by introducing reasoning budgets, examining the impact of reasoning length on latency and accuracy, and exploring dual-mode training to allow runtime control over reasoning behavior. Our findings will provide practical insights for researchers and developers to effectively and efficiently train and deploy reasoning-based guardrails models in real-world systems.', 'abstract_zh': '基于推理的语言模型在各个领域展现了强大的性能，特别是在数学和编程任务中取得了显著进展。最近的研究表明，推理也为LLM的安全性和边界应用带来了重要益处。在本工作中，我们对内容审核中的基于推理的边界模型进行了全面分析，重点在于推理时间的自定义安全策略泛化能力。我们的研究集中在两个关键维度：数据效率和推理效率。在数据方面，我们发现基于推理的模型表现出较强的经验效率，在比非推理模型少得多的训练样本下实现了竞争性的性能。这为重新利用剩余数据挖掘高价值、难题样本提供了可能性，进一步提升模型性能。在推理方面，通过引入推理预算，我们评估了推理长度对延迟和准确性的影响，并探索了双重模式训练以实现在运行时间对推理行为的控制。我们的发现将为研究人员和开发人员提供实用见解，以有效地在实际系统中训练和部署基于推理的边界模型。', 'title_zh': '通过推理保障安全：推理守 Rails 模型的实证研究'}
{'arxiv_id': 'arXiv:2505.20075', 'title': 'Curriculum-RLAIF: Curriculum Alignment with Reinforcement Learning from AI Feedback', 'authors': 'Mengdi Li, Jiaye Lin, Xufeng Zhao, Wenhao Lu, Peilin Zhao, Stefan Wermter, Di Wang', 'link': 'https://arxiv.org/abs/2505.20075', 'abstract': 'Reward models trained with conventional Reinforcement Learning from AI Feedback (RLAIF) methods suffer from limited generalizability, which hinders the alignment performance of the policy model during reinforcement learning (RL). This challenge stems from various issues, including distribution shift, preference label noise, and mismatches between overly challenging samples and model capacity. In this paper, we attempt to enhance the generalizability of reward models through a data-centric approach, driven by the insight that these issues are inherently intertwined from the perspective of data difficulty. To address this, we propose a novel framework, $\\textit{Curriculum-RLAIF}$, which constructs preference pairs with varying difficulty levels and produces a curriculum that progressively incorporates preference pairs of increasing difficulty for reward model training. Our experimental results suggest that reward models trained with Curriculum-RLAIF achieve improved generalizability, significantly increasing the alignment performance of the policy model by a large margin without incurring additional inference costs compared to various non-curriculum baselines. Detailed analysis and comparisons with alternative approaches, including data selection via external pretrained reward models or internal self-selection mechanisms, as well as other curriculum strategies, further demonstrate the superiority of our approach in terms of simplicity, efficiency, and effectiveness.', 'abstract_zh': '基于数据驱动的Curriculum-RLAIF框架提升奖励模型的一般化能力', 'title_zh': 'Curriculum-RLAIF: 基于强化学习和AI反馈的课程对齐'}
{'arxiv_id': 'arXiv:2505.20011', 'title': 'The Many Challenges of Human-Like Agents in Virtual Game Environments', 'authors': 'Maciej Świechowski, Dominik Ślęzak', 'link': 'https://arxiv.org/abs/2505.20011', 'abstract': 'Human-like agents are an increasingly important topic in games and beyond. Believable non-player characters enhance the gaming experience by improving immersion and providing entertainment. They also offer players the opportunity to engage with AI entities that can function as opponents, teachers, or cooperating partners. Additionally, in games where bots are prohibited -- and even more so in non-game environments -- there is a need for methods capable of identifying whether digital interactions occur with bots or humans. This leads to two fundamental research questions: (1) how to model and implement human-like AI, and (2) how to measure its degree of human likeness.\nThis article offers two contributions. The first one is a survey of the most significant challenges in implementing human-like AI in games (or any virtual environment featuring simulated agents, although this article specifically focuses on games). Thirteen such challenges, both conceptual and technical, are discussed in detail. The second is an empirical study performed in a tactical video game that addresses the research question: "Is it possible to distinguish human players from bots (AI agents) based on empirical data?" A machine-learning approach using a custom deep recurrent convolutional neural network is presented. We hypothesize that the more challenging it is to create human-like AI for a given game, the easier it becomes to develop a method for distinguishing humans from AI-driven players.', 'abstract_zh': '人类似的代理人在游戏及其它领域中的重要性日益增加：人类似的非玩家角色提升游戏体验并提供娱乐，同时为玩家与可作为对手、教师或合作伙伴的AI实体互动提供机会。在禁止使用机器人游戏环境下，甚至在非游戏环境中，需要方法来识别数字互动是与机器人还是人类进行。这引发了两项基础研究问题：（1）如何建模和实现人类似的AI，（2）如何衡量其人类相似度。本文的贡献包括：（1）综述在游戏（或任何包含模拟代理的虚拟环境）中实现人类似的AI的关键挑战，详细讨论了十三种概念和技术方面的挑战；（2）在战术视频游戏中进行实证研究，探讨基于实证数据区分玩家与机器人的可能性，并介绍了一种使用自定义深度递归卷积神经网络的机器学习方法。我们假设在一个特定游戏中创建人类似的AI越具有挑战性，就越容易开发出区分人类与AI驱动玩家的方法。', 'title_zh': '人类代理在虚拟游戏环境中的诸多挑战'}
{'arxiv_id': 'arXiv:2505.19965', 'title': 'Adaptive Location Hierarchy Learning for Long-Tailed Mobility Prediction', 'authors': 'Yu Wang, Junshu Dai, Yuchen Ying, Yuxuan Liang, Tongya Zheng, Mingli Song', 'link': 'https://arxiv.org/abs/2505.19965', 'abstract': "Human mobility prediction is crucial for applications ranging from location-based recommendations to urban planning, which aims to forecast users' next location visits based on historical trajectories. Despite the severe long-tailed distribution of locations, the problem of long-tailed mobility prediction remains largely underexplored. Existing long-tailed learning methods primarily focus on rebalancing the skewed distribution at the data, model, or class level, neglecting to exploit the spatiotemporal semantics of locations. To address this gap, we propose the first plug-and-play framework for long-tailed mobility prediction in an exploitation and exploration manner, named \\textbf{A}daptive \\textbf{LO}cation \\textbf{H}ier\\textbf{A}rchy learning (ALOHA). First, we construct city-tailored location hierarchy based on Large Language Models (LLMs) by exploiting Maslow's theory of human motivation to design Chain-of-Thought (CoT) prompts that captures spatiotemporal semantics. Second, we optimize the location hierarchy predictions by Gumbel disturbance and node-wise adaptive weights within the hierarchical tree structure. Experiments on state-of-the-art models across six datasets demonstrate the framework's consistent effectiveness and generalizability, which strikes a well balance between head and tail locations. Weight analysis and ablation studies reveal the optimization differences of each component for head and tail locations. Furthermore, in-depth analyses of hierarchical distance and case study demonstrate the effective semantic guidance from the location hierarchy. Our code will be made publicly available.", 'abstract_zh': '一种用于长尾移动性预测的探索与利用框架：自适应地点层次学习（ALOHA）', 'title_zh': '长尾移动性预测的自适应位置层次学习'}
{'arxiv_id': 'arXiv:2505.19956', 'title': 'DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph', 'authors': 'Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee', 'link': 'https://arxiv.org/abs/2505.19956', 'abstract': 'Text-to-SQL, which translates a natural language question into an SQL query, has advanced with in-context learning of Large Language Models (LLMs). However, existing methods show little improvement in performance compared to randomly chosen demonstrations, and significant performance drops when smaller LLMs (e.g., Llama 3.1-8B) are used. This indicates that these methods heavily rely on the intrinsic capabilities of hyper-scaled LLMs, rather than effectively retrieving useful demonstrations. In this paper, we propose a novel approach for effectively retrieving demonstrations and generating SQL queries. We construct a Deep Contextual Schema Link Graph, which contains key information and semantic relationship between a question and its database schema items. This graph-based structure enables effective representation of Text-to-SQL samples and retrieval of useful demonstrations for in-context learning. Experimental results on the Spider benchmark demonstrate the effectiveness of our approach, showing consistent improvements in SQL generation performance and efficiency across both hyper-scaled LLMs and small LLMs. Our code will be released.', 'abstract_zh': '基于上下文学习的大语言模型在文本到SQL转换中的有效示范检索与SQL生成方法', 'title_zh': 'DCG-SQL: 提高基于上下文学习的文本到SQL能力的深度上下文模式链接图'}
{'arxiv_id': 'arXiv:2505.19933', 'title': 'Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making', 'authors': 'Yejin Son, Minseo Kim, Sungwoong Kim, Seungju Han, Jian Kim, Dongju Jang, Youngjae Yu, Chanyoung Park', 'link': 'https://arxiv.org/abs/2505.19933', 'abstract': 'Large Language Models (LLMs) are increasingly used for decision making in embodied agents, yet existing safety evaluations often rely on coarse success rates and domain-specific setups, making it difficult to diagnose why and where these models fail. This obscures our understanding of embodied safety and limits the selective deployment of LLMs in high-risk physical environments. We introduce SAFEL, the framework for systematically evaluating the physical safety of LLMs in embodied decision making. SAFEL assesses two key competencies: (1) rejecting unsafe commands via the Command Refusal Test, and (2) generating safe and executable plans via the Plan Safety Test. Critically, the latter is decomposed into functional modules, goal interpretation, transition modeling, action sequencing, enabling fine-grained diagnosis of safety failures. To support this framework, we introduce EMBODYGUARD, a PDDL-grounded benchmark containing 942 LLM-generated scenarios covering both overtly malicious and contextually hazardous instructions. Evaluation across 13 state-of-the-art LLMs reveals that while models often reject clearly unsafe commands, they struggle to anticipate and mitigate subtle, situational risks. Our results highlight critical limitations in current LLMs and provide a foundation for more targeted, modular improvements in safe embodied reasoning.', 'abstract_zh': 'SAFEL：评估语言模型在体Calc决策中物理安全性的框架', 'title_zh': '隐秘的风险，关键的故障：一种诊断物理安全框架，用于具身决策的大语言模型'}
{'arxiv_id': 'arXiv:2505.19927', 'title': 'TCP: a Benchmark for Temporal Constraint-Based Planning', 'authors': 'Zifeng Ding, Sikuan Yan, Zhangdie Yuan, Xianglong Hu, Fangru Lin, Andreas Vlachos', 'link': 'https://arxiv.org/abs/2505.19927', 'abstract': "Temporal reasoning and planning are essential capabilities for large language models (LLMs), yet most existing benchmarks evaluate them in isolation and under limited forms of complexity. To address this gap, we introduce the Temporal Constraint-based Planning (TCP) benchmark, that jointly assesses both capabilities. Each instance in TCP features a naturalistic dialogue around a collaborative project, where diverse and interdependent temporal constraints are explicitly or implicitly expressed, and models must infer an optimal schedule that satisfies all constraints. To construct TCP, we first generate abstract problem prototypes that are paired with realistic scenarios from various domains and enriched into dialogues using an LLM. A human quality check is performed on a sampled subset to confirm the reliability of our benchmark. We evaluate state-of-the-art LLMs and find that even the strongest models struggle with TCP, highlighting its difficulty and revealing limitations in LLMs' temporal constraint-based planning abilities. We analyze underlying failure cases, open source our benchmark, and hope our findings can inspire future research.", 'abstract_zh': '基于时间约束的规划基准（TCP）：同时评估时间和规划能力的综合性测试', 'title_zh': 'TCP：基于时间约束的规划基准'}
{'arxiv_id': 'arXiv:2505.19905', 'title': 'EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM', 'authors': 'Shuang Ao, Flora D. Salim, Simon Khan', 'link': 'https://arxiv.org/abs/2505.19905', 'abstract': 'Although LLMs demonstrate proficiency in several text-based reasoning and planning tasks, their implementation in robotics control is constrained by significant deficiencies: (1) LLM agents are designed to work mainly with textual inputs rather than visual conditions; (2) Current multimodal agents treat LLMs as static planners, which separates their reasoning from environment dynamics, resulting in actions that do not take domain-specific knowledge into account; and (3) LLMs are not designed to learn from visual interactions, which makes it harder for them to make better policies for specific domains. In this paper, we introduce EMAC+, an Embodied Multimodal Agent that collaboratively integrates LLM and VLM via a bidirectional training paradigm. Unlike existing methods, EMAC+ dynamically refines high-level textual plans generated by an LLM using real-time feedback from a VLM executing low-level visual control tasks. We address critical limitations of previous models by enabling the LLM to internalize visual environment dynamics directly through interactive experience, rather than relying solely on static symbolic mappings. Extensive experimental evaluations on ALFWorld and RT-1 benchmarks demonstrate that EMAC+ achieves superior task performance, robustness against noisy observations, and efficient learning. We also conduct thorough ablation studies and provide detailed analyses of success and failure cases.', 'abstract_zh': '尽管大规模语言模型在文本推理和规划任务上表现出色，但将其应用于机器人控制仍然受到显著缺陷的限制：（1）语言模型代理主要设计用于处理文本输入而非视觉条件；（2）当前的多模态代理将语言模型视为静态规划者，这使得它们的推理与环境动力学脱钩，导致采取的行动未能考虑到领域特定知识；（3）语言模型未被设计用于从视觉交互中学习，这使得它们制定针对特定领域的更好策略更为困难。本文介绍了一种名为EMAC+的体态多模态代理，通过双向训练 paradigm将语言模型和视觉语言模型结合起来。与现有方法不同，EMAC+能够利用视觉语言模型执行低级视觉控制任务时的实时反馈动态细化由语言模型生成的高级文本计划。通过使语言模型能够直接通过交互体验内化视觉环境动态，而不是仅仅依赖静态符号映射来解决先前模型的关键限制。在ALFWorld和RT-1基准上的广泛实验评估表明，EMAC+实现了卓越的任务性能、对嘈杂观测的鲁棒性以及高效的learning。我们还进行了详尽的消融研究，并提供了成功与失败案例的详细分析。', 'title_zh': 'EMAC+: 融合多模态代理的协作规划系统结合VLM+LLM'}
{'arxiv_id': 'arXiv:2505.19897', 'title': 'ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows', 'authors': 'Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu, Kanzhi Cheng, Zhaoyang Liu, Jianing Wang, Qintong Li, Xiangru Tang, Tianbao Xie, Xiachong Feng, Xiang Li, Ben Kao, Wenhai Wang, Biqing Qi, Lingpeng Kong, Zhiyong Wu', 'link': 'https://arxiv.org/abs/2505.19897', 'abstract': "Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at this https URL.", 'abstract_zh': '大规模语言模型（LLMs）的影响已经超越了自然语言处理领域，显著促进了跨学科研究的发展。最近，基于LLM的各种代理被开发出来，以协助科学研究进展的多个方面和领域。其中，能够像人类一样与操作系统交互的计算机使用代理正引领自动化科学研究问题解决和研究人员工作流程中常规任务的途径。认识到这些代理的变革潜力，我们介绍了ScienceBoard，它包含了两个互补的贡献：（i）一个现实的、跨领域的环境，其中包括动态和视觉丰富的科学工作流程以及集成的专业软件，代理可以通过不同的接口自主交互以加速复杂的研究任务和实验；（ii）一个由人类策划的169项高质量、严格验证的真实世界任务组成的具有挑战性的基准，这些任务涵盖生物化学、天文学和地理信息系统等领域的科学研究工作流程。对最先进的代理底座（例如GPT-4o、Claude 3.7、UI-TARS）进行了广泛的评估表明，尽管取得了一些令人鼓舞的结果，但在复杂工作流程中可靠地协助科学家方面仍存在不足，总体成功率为15%。深入分析进一步提供了关于当前代理局限性的有价值见解并提出了更有效的设计原则，为构建更强大的科学研究代理铺平了道路。我们的代码、环境和基准可以通过这个网址获得。', 'title_zh': 'ScienceBoard: 在现实科学工作流中评估多模态自主代理'}
{'arxiv_id': 'arXiv:2505.19896', 'title': 'Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program', 'authors': 'Alejandro Carrasco, Victor Rodriguez-Fernandez, Richard Linares', 'link': 'https://arxiv.org/abs/2505.19896', 'abstract': 'Recent trends are emerging in the use of Large Language Models (LLMs) as autonomous agents that take actions based on the content of the user text prompts. We intend to apply these concepts to the field of Control in space, enabling LLMs to play a significant role in the decision-making process for autonomous satellite operations. As a first step towards this goal, we have developed a pure LLM-based solution for the Kerbal Space Program Differential Games (KSPDG) challenge, a public software design competition where participants create autonomous agents for maneuvering satellites involved in non-cooperative space operations, running on the KSP game engine. Our approach leverages prompt engineering, few-shot prompting, and fine-tuning techniques to create an effective LLM-based agent that ranked 2nd in the competition. To the best of our knowledge, this work pioneers the integration of LLM agents into space research. The project comprises several open repositories to facilitate replication and further research. The codebase is accessible on \\href{this https URL}{GitHub}, while the trained models and datasets are available on \\href{this https URL}{Hugging Face}. Additionally, experiment tracking and detailed results can be reviewed on \\href{this https URL}{Weights \\& Biases', 'abstract_zh': '近期，大型语言模型（LLMs）作为基于用户文本提示内容采取行动的自主代理的使用趋势正在兴起。我们打算将这些概念应用到航天控制领域，让LLMs在自主卫星操作的决策过程中发挥重要作用。为实现这一目标的第一步，我们为Kerbal Space Program Differential Games (KSPDG) 挑战开发了一个基于纯LLM的解决方案，这是一个公开的软件设计竞赛，参与者构建自主代理以操作参与非合作太空操作的卫星，运行于KSP游戏引擎之上。我们的方法利用了提示工程、少样本提示和微调技术，创造了一个有效的基于LLM的代理，在比赛中排名第二。据我们所知，本工作首次将LLM代理集成到航天研究中。该项目包含多个开源仓库，以促进复制和进一步研究。代码库可在GitHub上访问，而训练模型和数据集可在Hugging Face获得。此外，实验跟踪和详细结果也可在Weights & Biases上查看。', 'title_zh': '大型语言模型作为自主太空船操作员在Kerbal太空计划中'}
{'arxiv_id': 'arXiv:2505.19892', 'title': 'Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging', 'authors': 'Yongxian Wei, Runxi Cheng, Weike Jin, Enneng Yang, Li Shen, Lu Hou, Sinan Du, Chun Yuan, Xiaochun Cao, Dacheng Tao', 'link': 'https://arxiv.org/abs/2505.19892', 'abstract': 'While foundation models update slowly due to resource-intensive training requirements, domain-specific models evolve between updates. Model merging aims to combine multiple expert models into a single, more capable model, thereby reducing storage and serving costs while supporting decentralized model development. Despite its potential, previous studies have primarily focused on merging visual classification models or Large Language Models (LLMs) for code and math tasks. Multimodal Large Language Models (MLLMs), which extend the capabilities of LLMs through large-scale multimodal training, have gained traction. However, there lacks a benchmark for model merging research that clearly divides the tasks for MLLM training and evaluation. In this paper, (i) we introduce the model merging benchmark for MLLMs, which includes multiple tasks such as VQA, Geometry, Chart, OCR, and Grounding, providing both LoRA and full fine-tuning models. Moreover, we explore how model merging can combine different modalities (e.g., vision-language, audio-language, and video-language models), moving toward the Omni-language model. (ii) We implement 10 model merging algorithms on the benchmark. Furthermore, we propose a novel method that removes noise from task vectors and robustly optimizes the merged vector based on a loss defined over task vector interactions, achieving an average performance gain of 2.48%. (iii) We find that model merging offers a promising way for building improved MLLMs without requiring data training. Our results also demonstrate that the complementarity among multiple modalities outperforms individual modalities.', 'abstract_zh': '面向多模态大型语言模型的模型合并基准研究', 'title_zh': '统一多模态大型语言模型能力和模态通过模型合并'}
{'arxiv_id': 'arXiv:2505.19866', 'title': 'HS-STAR: Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation', 'authors': 'Feng Xiong, Hongling Xu, Yifei Wang, Runxi Cheng, Yong Wang, Xiangxiang Chu', 'link': 'https://arxiv.org/abs/2505.19866', 'abstract': "Self-taught reasoners (STaRs) enhance the mathematical reasoning abilities of large language models (LLMs) by leveraging self-generated responses for self-training. Recent studies have incorporated reward models to guide response selection or decoding, aiming to obtain higher-quality data. However, they typically allocate a uniform sampling budget across all problems, overlooking the varying utility of problems at different difficulty levels. In this work, we conduct an empirical study and find that problems near the boundary of the LLM's reasoning capability offer significantly greater learning utility than both easy and overly difficult ones. To identify and exploit such problems, we propose HS-STaR, a Hierarchical Sampling framework for Self-Taught Reasoners. Given a fixed sampling budget, HS-STaR first performs lightweight pre-sampling with a reward-guided difficulty estimation strategy to efficiently identify boundary-level problems. Subsequently, it dynamically reallocates the remaining budget toward these high-utility problems during a re-sampling phase, maximizing the generation of valuable training data. Extensive experiments across multiple reasoning benchmarks and backbone LLMs demonstrate that HS-STaR significantly outperforms other baselines without requiring additional sampling budget.", 'abstract_zh': '自学习推理器（STaRs）通过利用自生成响应进行自训练，增强大型语言模型的数学推理能力。近期研究引入了奖赏模型来指导响应选择或解码，以获得更高质量的数据。然而，它们通常为所有问题分配相同的采样预算，忽视了不同难度级别问题的不同效用。在本工作中，我们进行了一项实证研究并发现，接近大型语言模型推理能力边界的问题提供了显著大于较容易和过于困难问题的学习效用。为识别和利用这些问题，我们提出了一种层次采样框架HS-STaR。给定固定的采样预算，HS-STaR首先采用基于奖赏引导的难度估计策略进行轻量级预采样，以高效地识别边界水平的问题。随后，在重新采样阶段动态重新分配剩余预算，最大化生成有价值的训练数据。广泛的跨多个推理基准和主干大型语言模型的实验表明，HS-STaR在不需要额外采样预算的情况下显著优于其他基线方法。', 'title_zh': 'HS-STAR: 基于难度估计和预算重新分配的分层采样自学习推理器'}
{'arxiv_id': 'arXiv:2505.19847', 'title': 'DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems', 'authors': 'Wenqing Zhou, Yuxuan Yan, Qianqian Yang', 'link': 'https://arxiv.org/abs/2505.19847', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the capabilities of language models by integrating external knowledge. Due to the diversity of data sources and the constraints of memory and computing resources, real-world data is often scattered in multiple devices. Conventional RAGs that store massive amounts of scattered data centrally face increasing privacy concerns and high computational costs. Additionally, RAG in a central node raises latency issues when searching over a large-scale knowledge base. To address these challenges, we propose a distributed Knowledge Graph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where each edge device maintains a local knowledge base without the need to share it with the cloud, instead sharing only summaries of its knowledge. Specifically, DGRAG has two main phases. In the Distributed Knowledge Construction phase, DGRAG organizes local knowledge using knowledge graphs, generating subgraph summaries and storing them in a summary database in the cloud as information sharing. In the Collaborative Retrieval and Generation phase, DGRAG first performs knowledge retrieval and answer generation locally, and a gate mechanism determines whether the query is beyond the scope of local knowledge or processing capabilities. For queries that exceed the local knowledge scope, the cloud retrieves knowledge from the most relevant edges based on the summaries and generates a more precise answer. Experimental results demonstrate the effectiveness of the proposed DGRAG approach in significantly improving the quality of question-answering tasks over baseline approaches.', 'abstract_zh': '基于知识图谱的分布式检索增强生成（DGRAG）方法', 'title_zh': '基于分布式图检索增强生成的边缘-云系统方法'}
{'arxiv_id': 'arXiv:2505.19792', 'title': 'Types of Relations: Defining Analogies with Category Theory', 'authors': 'Claire Ott, Frank Jäkel', 'link': 'https://arxiv.org/abs/2505.19792', 'abstract': 'In order to behave intelligently both humans and machines have to represent their knowledge adequately for how it is used. Humans often use analogies to transfer their knowledge to new domains, or help others with this transfer via explanations. Hence, an important question is: What representation can be used to construct, find, and evaluate analogies? In this paper, we study features of a domain that are important for constructing analogies. We do so by formalizing knowledge domains as categories. We use the well-known example of the analogy between the solar system and the hydrogen atom to demonstrate how to construct domain categories. We also show how functors, pullbacks, and pushouts can be used to define an analogy, describe its core and a corresponding blend of the underlying domains.', 'abstract_zh': '为了智能地行为，人类和机器都需要适当表示其知识以适应其用途。重要的是：哪种表示可以用于构造、查找和评估类比？在这种论文中，我们通过将知识领域形式化为范畴来研究用于构造类比的重要领域特征。我们以太阳系与氢原子的类比为例，演示如何构造领域范畴。我们还展示了如何使用因子、拉回和推出来定义一个类比，描述其核心以及底层领域相应的融合。', 'title_zh': '关系类型：用范畴论定义类比'}
{'arxiv_id': 'arXiv:2505.19788', 'title': 'Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured Multi-Turn Decomposition', 'authors': 'Zihao Zeng, Xuyao Huang, Boxiu Li, Hao Zhang, Zhijie Deng', 'link': 'https://arxiv.org/abs/2505.19788', 'abstract': 'Large Reasoning Models (LRMs) are criticized for the excessively lengthy Chain-of-Thought (CoT) to derive the final answer, suffering from high first-token and overall latency. Typically, the CoT of LRMs mixes multiple thinking units; each unit attempts to produce a candidate answer to the original query. Hence, a natural idea to improve efficiency is to reduce the unit number. Yet, the fact that the thinking units in vanilla CoT cannot be explicitly managed renders doing so challenging. This paper introduces Multi-Turn Decomposition (MinD) to decode conventional CoT into a sequence of explicit, structured, and turn-wise interactions to bridge the gap. In MinD, the model provides a multi-turn response to the query, where each turn embraces a thinking unit and yields a corresponding answer. The subsequent turns can reflect, verify, revise, or explore alternative approaches to both the thinking and answer parts of earlier ones. This not only makes the answer delivered more swiftly, but also enables explicit controls over the iterative reasoning process (i.e., users may halt or continue at any turn). We follow a supervised fine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We first rephrase the outputs of an LRM into multi-turn formats by prompting another LLM, and then tune the LRM with such data. Observing that the tuned model tends to consume even more tokens than the original one (probably due to that the multi-turn formats introduce additional answer tokens), we advocate leveraging RL algorithms like GRPO to prioritize correct outputs with fewer turns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up to ~70% reduction in both output token usage and time to first token (TTFT), while maintaining competitive performance on reasoning benchmarks such as MATH-500, AIME24, AMC23, and GPQA-Diamond.', 'abstract_zh': '多轮分解以减少链式思考的大型推理模型（MinD）：多轮分解以减少链式思考的大型推理模型', 'title_zh': '尽力而为胜于完美：通过结构化多轮分解解锁高效推理'}
{'arxiv_id': 'arXiv:2505.19762', 'title': 'Language Model-Enhanced Message Passing for Heterophilic Graph Learning', 'authors': 'Wenjun Wang, Dawei Cheng', 'link': 'https://arxiv.org/abs/2505.19762', 'abstract': "Traditional graph neural networks (GNNs), which rely on homophily-driven message passing, struggle with heterophilic graphs where connected nodes exhibit dissimilar features and different labels. While existing methods address heterophily through graph structure refinement or adaptation of neighbor aggregation functions, they often overlook the semantic potential of node text, rely on suboptimal message representation for propagation and compromise performance on homophilic graphs. To address these limitations, we propose a novel language model (LM)-enhanced message passing approach for heterophilic graph leaning (LEMP4HG). Specifically, in the context of text-attributed graph, we provide paired node texts for LM to generate their connection analysis, which are encoded and then fused with paired node textual embeddings through a gating mechanism. The synthesized messages are semantically enriched and adaptively balanced with both nodes' information, which mitigates contradictory signals when neighbor aggregation in heterophilic regions. Furthermore, we introduce an active learning strategy guided by our heuristic MVRD (Modulated Variation of Reliable Distance), selectively enhancing node pairs suffer most from message passing, reducing the cost of analysis generation and side effects on homophilic regions. Extensive experiments validate that our approach excels on heterophilic graphs and performs robustly on homophilic ones, with a graph convolutional network (GCN) backbone and a practical budget.", 'abstract_zh': '基于语言模型增强的消息传递方法用于异质图学习（LEMP4HG）', 'title_zh': '语言模型增强的消息传递方法在异类图学习中的应用'}
{'arxiv_id': 'arXiv:2505.19761', 'title': 'Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning', 'authors': 'Zican Hu, Wei Liu, Xiaoye Qu, Xiangyu Yue, Chunlin Chen, Zhi Wang, Yu Cheng', 'link': 'https://arxiv.org/abs/2505.19761', 'abstract': 'While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework **GLIDER** (**G**rounding **L**anguage Models as Eff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical **R**einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities.', 'abstract_zh': '基于离线分层强化学习的语言模型高效决策框架GLIDER', 'title_zh': 'divide和征服：通过 Offline 分层强化学习将大模型接地为高效的决策代理'}
{'arxiv_id': 'arXiv:2505.19734', 'title': 'ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection', 'authors': 'Juxin Niu, Xiangfeng Liu, Dan Niu, Xi Wang, Zhe Jiang, Nan Guan', 'link': 'https://arxiv.org/abs/2505.19734', 'abstract': 'Coding with hardware description languages (HDLs) such as Verilog is a time-intensive and laborious task. With the rapid advancement of large language models (LLMs), there is increasing interest in applying LLMs to assist with HDL coding. Recent efforts have demonstrated the potential of LLMs in translating natural language to traditional HDL Verilog. Chisel, a next-generation HDL based on Scala, introduces higher-level abstractions, facilitating more concise, maintainable, and scalable hardware designs. However, the potential of using LLMs for Chisel code generation remains largely unexplored. This work proposes ReChisel, an LLM-based agentic system designed to enhance the effectiveness of Chisel code generation. ReChisel incorporates a reflection mechanism to iteratively refine the quality of generated code using feedback from compilation and simulation processes, and introduces an escape mechanism to break free from non-progress loops. Experiments demonstrate that ReChisel significantly improves the success rate of Chisel code generation, achieving performance comparable to state-of-the-art LLM-based agentic systems for Verilog code generation.', 'abstract_zh': '使用硬件描述语言（HDL）如Verilog进行编码是一个耗时且劳动密集型的任务。随着大型语言模型（LLMs）的快速发展，人们越来越关注利用LLMs辅助HDL编码。最近的研究展示了LLMs在将自然语言翻译为传统HDL Verilog中的潜力。Chisel是一种基于Scala的下一代HDL，引入了更高的抽象层次，使得硬件设计更加简洁、可维护和可扩展。然而，使用LLMs生成Chisel代码的潜力尚未得到充分探索。本文提出ReChisel，这是一种基于LLMs的代理系统，旨在提高Chisel代码生成的有效性。ReChisel通过反馈机制中的反射机制迭代优化生成代码的质量，并引入逃生机制以避免非进展循环。实验表明，ReChisel显著提高了Chisel代码生成的成功率，其性能与最先进的基于LLMs的代理系统生成Verilog代码的性能相当。', 'title_zh': 'ReChisel: 通过反射的高效自动Chisel代码生成（基于LLM）'}
{'arxiv_id': 'arXiv:2505.19716', 'title': 'Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting', 'authors': 'Yifan Wu, Jingze Shi, Bingheng Wu, Jiayi Zhang, Xiaotian Lin, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2505.19716', 'abstract': "Existing chain-of-thought (CoT) distillation methods can effectively transfer reasoning abilities to base models but suffer from two major limitations: excessive verbosity of reasoning traces and inadequate adaptability to problem difficulty. Long reasoning traces significantly increase inference costs, and uniform-length solutions prevent base models from learning adaptive reasoning strategies. To address these issues, we propose a difficulty-aware prompting (DAP) method to dynamically shorten reasoning traces without performance loss. In our approach, a large teacher model first judges each problem's difficulty and then rewrites its reasoning traces to an appropriate shorter length, yielding concise yet complete reasoning traces. Leveraging the DAP pipeline, we curate a distilled dataset called LiteCoT consisting of 100K concise reasoning examples, with solutions averaging only 720 tokens (an order of magnitude shorter than typical CoTs). Using LiteCoT, we distilled a new family of reasoning models called Liter (1.5B, 7B, and 32B) based on the Qwen2.5 architecture. Experiments show that a student model fine-tuned on just 100K of these difficulty-pruned CoT samples outperforms a model distilled on 800K original Long CoT samples, while significantly reducing training and inference costs. Our method also generalizes well: across 11 diverse benchmarks, the shorter difficulty-aware CoTs achieve equal or better accuracy than Long chains, using far fewer tokens. For example, on the challenging AIME24 exam, our approach reaches $74.2\\%$ Pass@1 using only about 5K inference tokens, surpassing other methods that consume many more tokens. Our code and data are available at this https URL.", 'abstract_zh': '基于难度感知的提示方法（DAP）：一种动态缩短推理路径而无需性能损失的方法', 'title_zh': '简洁推理，重大提升：基于难度感知的剪枝长推理轨迹'}
{'arxiv_id': 'arXiv:2505.19690', 'title': 'Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in Large Reasoning Models', 'authors': 'Baihui Zheng, Boren Zheng, Kerui Cao, Yingshui Tan, Zhendong Liu, Weixun Wang, Jiaheng Liu, Jian Yang, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang', 'link': 'https://arxiv.org/abs/2505.19690', 'abstract': 'Despite the remarkable proficiency of \\textit{Large Reasoning Models} (LRMs) in handling complex reasoning tasks, their reliability in safety-critical scenarios remains uncertain. Existing evaluations primarily assess response-level safety, neglecting a critical issue we identify as \\textbf{\\textit{Superficial Safety Alignment} (SSA)} -- a phenomenon where models produce superficially safe outputs while internal reasoning processes fail to genuinely detect and mitigate underlying risks, resulting in inconsistent safety behaviors across multiple sampling attempts. To systematically investigate SSA, we introduce \\textbf{Beyond Safe Answers (BSA)} bench, a novel benchmark comprising 2,000 challenging instances organized into three distinct SSA scenario types and spanning nine risk categories, each meticulously annotated with risk rationales. Evaluations of 19 state-of-the-art LRMs demonstrate the difficulty of this benchmark, with top-performing models achieving only 38.0\\% accuracy in correctly identifying risk rationales. We further explore the efficacy of safety rules, specialized fine-tuning on safety reasoning data, and diverse decoding strategies in mitigating SSA. Our work provides a comprehensive assessment tool for evaluating and improving safety reasoning fidelity in LRMs, advancing the development of genuinely risk-aware and reliably safe AI systems.', 'abstract_zh': '尽管大规模推理模型（LRMs）在处理复杂推理任务方面表现出色，但在安全关键场景中的可靠性仍然存在不确定性。现有的评估主要评估响应级别的安全性，忽略了我们所识别的一个关键问题——表象安全性对齐（SSA）现象——即模型产生表面上安全的输出，而内部推理过程未能真正检测和缓解潜在风险，导致多次采样尝试中表现出不一致的安全行为。为系统地研究SSA现象，我们引入了超越安全答案（BSA）基准，这是一个包含2,000个具有挑战性的实例的新基准，这些实例被组织成三种不同的SSA场景类型和九个风险类别，并详细记录了风险理由。对19种最先进的LRMs的评估显示，这一基准的难度很大，顶级模型仅在正确识别风险理由方面达到38.0%的准确率。我们进一步探讨了安全性规则的有效性、专门针对安全性推理数据的微调以及多样性解码策略在减轻SSA方面的作用。我们的工作提供了一个全面的评估工具，用于评估和改进LRMs中的安全性推理精确性，推动真正具备风险意识和可靠安全的AI系统的发展。', 'title_zh': '超越安全答案：评估大型推理模型真正风险意识的基准'}
{'arxiv_id': 'arXiv:2505.19683', 'title': 'Large Language Models for Planning: A Comprehensive and Systematic Survey', 'authors': 'Pengfei Cao, Tianyi Men, Wencan Liu, Jingwen Zhang, Xuzhao Li, Xixun Lin, Dianbo Sui, Yanan Cao, Kang Liu, Jun Zhao', 'link': 'https://arxiv.org/abs/2505.19683', 'abstract': 'Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making. While Large Language Models (LLMs) have demonstrated remarkable performance on certain planning tasks, their broader application in this domain warrants systematic investigation. This paper presents a comprehensive review of LLM-based planning. Specifically, this survey is structured as follows: First, we establish the theoretical foundations by introducing essential definitions and categories about automated planning. Next, we provide a detailed taxonomy and analysis of contemporary LLM-based planning methodologies, categorizing them into three principal approaches: 1) External Module Augmented Methods that combine LLMs with additional components for planning, 2) Finetuning-based Methods that involve using trajectory data and feedback signals to adjust LLMs in order to improve their planning abilities, and 3) Searching-based Methods that break down complex tasks into simpler components, navigate the planning space, or enhance decoding strategies to find the best solutions. Subsequently, we systematically summarize existing evaluation frameworks, including benchmark datasets, evaluation metrics and performance comparisons between representative planning methods. Finally, we discuss the underlying mechanisms enabling LLM-based planning and outline promising research directions for this rapidly evolving field. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this field.', 'abstract_zh': '基于大型语言模型的规划：理论基础、方法分类、评估框架及未来研究方向', 'title_zh': '大规模语言模型在规划中的应用：一项全面而系统的综述'}
{'arxiv_id': 'arXiv:2505.19676', 'title': "Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models", 'authors': 'Lachlan McGinness, Peter Baumgartner', 'link': 'https://arxiv.org/abs/2505.19676', 'abstract': 'Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we develop methods for assessing LLM response accuracy and correct answer correlation.\nOur results show that progress in improving LLM reasoning abilities has stalled over the nine month period. By tracking completion tokens, we show that almost all improvement in reasoning ability since GPT-4 was released can be attributed to either hidden system prompts or the training of models to automatically use generic Chain of Thought prompting strategies. Among the ATP reasoning strategies tried, we found that current frontier LLMs are best able to follow the bottom-up (also known as forward-chaining) strategy. A low positive correlation was found between an LLM response containing correct reasoning and arriving at the correct conclusion.', 'abstract_zh': '大型语言模型使用自动定理证明推理策略的能力的经验研究：评估2023年12月和2024年8月的先进模型在PRONTOQA蒸汽碾压推理问题上的性能，并开发评估LLM响应准确性和正确答案相关性的方法。我们的结果表明，过去九个月在提高LLM推理能力方面几乎没有进展。通过跟踪完成令牌，我们发现自GPT-4发布以来的几乎所有推理能力提升可归因于隐藏系统提示或模型训练以自动使用通用思路提示策略。在尝试的自动定理证明推理策略中，我们发现当前前沿的LLM最擅长遵循自底向上的（也称为正向链式推理）策略。LLM响应中包含正确推理与得出正确结论之间存在较低的正相关。', 'title_zh': '大型语言模型的推理停滞：前沿模型能力探究'}
{'arxiv_id': 'arXiv:2505.19662', 'title': 'FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks', 'authors': 'Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, Graham Neubig, Ikuo Kusajima, Yasuto Watanabe, Hiroyuki Ishida, Jun Takahashi, Shan Jiang', 'link': 'https://arxiv.org/abs/2505.19662', 'abstract': 'This paper proposes FieldWorkArena, a benchmark for agentic AI targeting real-world field work. With the recent increase in demand for agentic AI, they are required to monitor and report safety and health incidents, as well as manufacturing-related incidents, that may occur in real-world work environments. Existing agentic AI benchmarks have been limited to evaluating web tasks and are insufficient for evaluating agents in real-world work environments, where complexity increases significantly. In this paper, we define a new action space that agentic AI should possess for real world work environment benchmarks and improve the evaluation function from previous methods to assess the performance of agentic AI in diverse real-world tasks. The dataset consists of videos captured on-site and documents actually used in factories and warehouses, and tasks were created based on interviews with on-site workers and managers. Evaluation results confirmed that performance evaluation considering the characteristics of Multimodal LLM (MLLM) such as GPT-4o is feasible. Additionally, the effectiveness and limitations of the proposed new evaluation method were identified. The complete dataset (HuggingFace) and evaluation program (GitHub) can be downloaded from the following website: this https URL.', 'abstract_zh': '本文提出FieldWorkArena，一个面向现实世界现场工作的代理型AI基准测试。', 'title_zh': 'FieldWorkArena: 自主权AI基准测试 for 实际现场工作任务'}
{'arxiv_id': 'arXiv:2505.19653', 'title': 'Token-Importance Guided Direct Preference Optimization', 'authors': 'Yang Ning, Lin Hai, Liu Yibo, Tian Baoliang, Liu Guoqing, Zhang Haijun', 'link': 'https://arxiv.org/abs/2505.19653', 'abstract': 'Ensuring that large language models (LLMs) generate outputs aligned with human preferences is important for safe and effective AI interactions. While Direct Preference Optimization (DPO) employs an implicit reward function to optimize the policy model, however, it and its related variants overlook the differential importance of individual tokens and are sensitive to judgment noise in preference datasets during generation. Although recent methods attempt to assess the important weight of tokens via probability prediction or simplistic weighting schemes, these evaluation methods are prone to biases and still cannot fully address these issues. To solve this problem, we propose the Token-Importance Guided Direct Preference Optimization (TI-DPO), which introduces two key innovations: the gradient-based token-importance weights that dynamically prioritize critical tokens, and a triple loss that explicitly guides model outputs to approach human-preferred responses and stay away from non-preferred responses. Experimental results show that TI-DPO achieves higher accuracy and stronger generative diversity, providing more stable and computationally efficient solutions compared with DPO and other RLHF methods.', 'abstract_zh': '确保大型语言模型（LLMs）生成与人类偏好一致的输出对于安全有效的AI交互至关重要。虽然直接偏好优化（DPO）通过隐式奖励函数优化策略模型，但它及其相关变体忽略了单个词 token 的差异性重要性，在生成过程中对偏好数据集中的判断噪声敏感。尽管最近的方法试图通过概率预测或简单的加权方案评估词 token 的重要权重，但这些评估方法仍存在偏差，无法充分解决这些问题。为此，我们提出了一种词重要性引导的直接偏好优化（TI-DPO），该方法引入了两项关键创新：基于梯度的词重要性权重，动态优先处理关键词，以及一个三重损失，明确引导模型输出接近人类偏好响应并远离非偏好响应。实验结果表明，TI-DPO 在准确性和生成多样性方面优于 DPO 及其他 RLHF 方法，提供了更为稳定和计算效率更高的解决方案。', 'title_zh': '基于令牌重要性引导的直接偏好优化'}
{'arxiv_id': 'arXiv:2505.19641', 'title': 'SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond', 'authors': 'Junteng Liu, Yuanxiang Fan, Zhuo Jiang, Han Ding, Yongyi Hu, Chi Zhang, Yiqi Shi, Shitong Weng, Aili Chen, Shiqi Chen, Yunan Huang, Mozhi Zhang, Pengyu Zhao, Junjie Yan, Junxian He', 'link': 'https://arxiv.org/abs/2505.19641', 'abstract': 'Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the potential of Reinforcement Learning (RL) to enhance reasoning abilities in Large Language Models (LLMs). While open-source replication efforts have primarily focused on mathematical and coding domains, methods and resources for developing general reasoning capabilities remain underexplored. This gap is partly due to the challenge of collecting diverse and verifiable reasoning data suitable for RL. We hypothesize that logical reasoning is critical for developing general reasoning capabilities, as logic forms a fundamental building block of reasoning. In this work, we present SynLogic, a data synthesis framework and dataset that generates diverse logical reasoning data at scale, encompassing 35 diverse logical reasoning tasks. The SynLogic approach enables controlled synthesis of data with adjustable difficulty and quantity. Importantly, all examples can be verified by simple rules, making them ideally suited for RL with verifiable rewards. In our experiments, we validate the effectiveness of RL training on the SynLogic dataset based on 7B and 32B models. SynLogic leads to state-of-the-art logical reasoning performance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B by 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and coding tasks improves the training efficiency of these domains and significantly enhances reasoning generalization. Notably, our mixed training model outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These findings position SynLogic as a valuable resource for advancing the broader reasoning capabilities of LLMs. We open-source both the data synthesis pipeline and the SynLogic dataset at this https URL.', 'abstract_zh': 'Recent advances such as OpenAI-o1和DeepSeek R1已展示了强化学习（RL）在增强大规模语言模型（LLMs）推理能力方面的潜力。虽然开源复现工作主要集中在数学和编程领域，但开发通用推理能力的方法和资源仍处于探索阶段。这一差距部分归因于收集适合RL的多样性和可验证性推理数据的挑战。我们假设逻辑推理对于开发通用推理能力至关重要，因为逻辑构成了推理的基本构建块。在本文中，我们介绍了SynLogic，这是一种数据合成框架和数据集，能够大规模生成多样化的逻辑推理数据，涵盖35种不同的逻辑推理任务。SynLogic方法允许可控地合成具有可调难度和数量的数据。此外，所有示例都可以通过简单的规则进行验证，使其非常适合带有可验证奖励的RL。在我们的实验中，我们基于7B和32B模型验证了SynLogic数据集上RL训练的有效性。SynLogic在开源数据集中实现了最先进的逻辑推理性能，比DeepSeek-R1-Distill-Qwen-32B在BBEH上的得分高6分。进一步将SynLogic数据与其他数学和编程任务混合提高了这些领域的训练效率，并显著增强了推理泛化。值得注意的是，我们的混合训练模型在多个基准测试中优于DeepSeek-R1-Zero-Qwen-32B。这些发现将SynLogic定位为推进LLMs更广泛推理能力的宝贵资源。我们在此https://网址开源了数据合成流水线和SynLogic数据集。', 'title_zh': 'SynLogic: 规范合成可验证推理数据以学习逻辑推理及相关领域'}
{'arxiv_id': 'arXiv:2505.19621', 'title': 'Think Again! The Effect of Test-Time Compute on Preferences, Opinions, and Beliefs of Large Language Models', 'authors': 'George Kour, Itay Nakash, Ateret Anaby-Tavor, Michal Shmueli-Scheuer', 'link': 'https://arxiv.org/abs/2505.19621', 'abstract': "As Large Language Models (LLMs) become deeply integrated into human life and increasingly influence decision-making, it's crucial to evaluate whether and to what extent they exhibit subjective preferences, opinions, and beliefs. These tendencies may stem from biases within the models, which may shape their behavior, influence the advice and recommendations they offer to users, and potentially reinforce certain viewpoints. This paper presents the Preference, Opinion, and Belief survey (POBs), a benchmark developed to assess LLMs' subjective inclinations across societal, cultural, ethical, and personal domains. We applied our benchmark to evaluate leading open- and closed-source LLMs, measuring desired properties such as reliability, neutrality, and consistency. In addition, we investigated the effect of increasing the test-time compute, through reasoning and self-reflection mechanisms, on those metrics. While effective in other tasks, our results show that these mechanisms offer only limited gains in our domain. Furthermore, we reveal that newer model versions are becoming less consistent and more biased toward specific viewpoints, highlighting a blind spot and a concerning trend. POBS: this https URL", 'abstract_zh': '大规模语言模型（LLMs）日益深入地融入人类生活并越来越多地影响决策，评估它们是否表现出主观偏好、意见和信念变得至关重要。这些倾向可能源自模型中的偏见，这可能会影响其行为，影响其向用户提供的建议和推荐，并可能强化某些观点。本文介绍了偏好、意见和信念调查（POBs），这是一种用于评估LLMs在社会、文化、伦理和个人领域主观倾向的基准。我们应用了这一基准来评估领先的大规模开源和闭源语言模型，并衡量诸如可靠、中立和一致等期望属性。此外，我们研究了通过推理和自我反思机制增加测试时计算量对这些指标的影响。虽然在其他任务中这些机制有效，但我们的结果显示，这些机制在我们的领域仅提供了有限的改进。此外，我们发现新版本的模型变得不那么一致，并且更倾向于特定观点，这揭示了一个盲点并令人担忧的趋势。POBS: 这里是链接', 'title_zh': '重新思考！测试时计算对大型语言模型偏好、观点和信念的影响'}
{'arxiv_id': 'arXiv:2505.19568', 'title': 'MSD-LLM: Predicting Ship Detention in Port State Control Inspections with Large Language Model', 'authors': 'Jiongchao Jin, Xiuju Fu, Xiaowei Gao, Tao Cheng, Ran Yan', 'link': 'https://arxiv.org/abs/2505.19568', 'abstract': 'Maritime transportation is the backbone of global trade, making ship inspection essential for ensuring maritime safety and environmental protection. Port State Control (PSC), conducted by national ports, enforces compliance with safety regulations, with ship detention being the most severe consequence, impacting both ship schedules and company reputations. Traditional machine learning methods for ship detention prediction are limited by the capacity of representation learning and thus suffer from low accuracy. Meanwhile, autoencoder-based deep learning approaches face challenges due to the severe data imbalance in learning historical PSC detention records. To address these limitations, we propose Maritime Ship Detention with Large Language Models (MSD-LLM), integrating a dual robust subspace recovery (DSR) layer-based autoencoder with a progressive learning pipeline to handle imbalanced data and extract meaningful PSC representations. Then, a large language model groups and ranks features to identify likely detention cases, enabling dynamic thresholding for flexible detention predictions. Extensive evaluations on 31,707 PSC inspection records from the Asia-Pacific region show that MSD-LLM outperforms state-of-the-art methods more than 12\\% on Area Under the Curve (AUC) for Singapore ports. Additionally, it demonstrates robustness to real-world challenges, making it adaptable to diverse maritime risk assessment scenarios.', 'abstract_zh': '基于大规模语言模型的海上船舶滞留预测（MSD-LLM）', 'title_zh': 'MSD-LLM：基于大型语言模型的港口国控制检查中船舶滞留预测'}
{'arxiv_id': 'arXiv:2505.19567', 'title': 'LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer', 'authors': 'Rasoul Zahedifar, Sayyed Ali Mirghasemi, Mahdieh Soleymani Baghshah, Alireza Taheri', 'link': 'https://arxiv.org/abs/2505.19567', 'abstract': "This study presents the LLM-Agent-Controller, a multi-agent large language model (LLM) system developed to address a wide range of problems in control engineering (Control Theory). The system integrates a central controller agent with multiple specialized auxiliary agents, responsible for tasks such as controller design, model representation, control analysis, time-domain response, and simulation. A supervisor oversees high-level decision-making and workflow coordination, enhancing the system's reliability and efficiency. The LLM-Agent-Controller incorporates advanced capabilities, including Retrieval-Augmented Generation (RAG), Chain-of-Thought reasoning, self-criticism and correction, efficient memory handling, and user-friendly natural language communication. It is designed to function without requiring users to have prior knowledge of Control Theory, enabling them to input problems in plain language and receive complete, real-time solutions. To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole. We test five categories of Control Theory problems and benchmark performance across three advanced LLMs. Additionally, we conduct a comprehensive qualitative conversational analysis covering all key services. Results show that the LLM-Agent-Controller successfully solved 83% of general tasks, with individual agents achieving an average success rate of 87%. Performance improved with more advanced LLMs. This research demonstrates the potential of multi-agent LLM architectures to solve complex, domain-specific problems. By integrating specialized agents, supervisory control, and advanced reasoning, the LLM-Agent-Controller offers a scalable, robust, and accessible solution framework that can be extended to various technical domains.", 'abstract_zh': 'LLM-Agent-Controller：一个解决控制工程中广泛问题的多代理大型语言模型系统', 'title_zh': 'LLM-Agent-Controller：一个适用于控制工程师的通用多代理大型语言模型系统'}
{'arxiv_id': 'arXiv:2505.19563', 'title': 'Automated Text-to-Table for Reasoning-Intensive Table QA: Pipeline Design and Benchmarking Insights', 'authors': 'Shi-Yu Tian, Zhi Zhou, Wei Dong, Ming Yang, Kun-Yang Yu, Zi-Jian Cheng, Lan-Zhe Guo, Yu-Feng Li', 'link': 'https://arxiv.org/abs/2505.19563', 'abstract': 'Reasoning with tabular data holds increasing importance in modern applications, yet comprehensive evaluation methodologies for reasoning-intensive Table Question Answering (QA) tasks remain nascent. Existing research is constrained by two primary bottlenecks: 1) Reliance on costly manually annotated real-world data, which is difficult to cover complex reasoning scenarios; 2) The heterogeneity of table structures hinders systematic analysis of the intrinsic mechanisms behind the underperformance of LLMs, especially in reasoning-intensive tasks. To address these issues, we propose an automated generation pipeline AutoT2T that transforms mathematical word problems into table-based reasoning tasks, eliminating the need for manual annotation. The pipeline can generate multiple variants of a table for the same reasoning problem, including noisy versions to support robustness evaluation. Based on this, we construct a new benchmark TabularGSM, which systematically spans a range of table complexities and trap problems. Experimental analyses through AutoT2T and TabularGSM reveal that the tight coupling between reasoning and retrieval or identification processes is a key factor underlying the failure of LLMs in complex Table QA tasks. This highlights the necessity for models to develop synergistic reasoning capabilities in order to perform effectively in complex Table QA tasks.', 'abstract_zh': '基于表格的数据推理在现代应用中 increasingly important，然而针对推理密集型表格问答任务的综合评估方法仍处于初级阶段。现有研究主要受两个瓶颈制约：1）依赖于昂贵的手动标注真实世界数据，难以覆盖复杂的推理场景；2）表格结构的异质性阻碍了对驱动LLM表现不佳的内在机制的系统分析，尤其是在推理密集型任务中。为了解决这些问题，我们提出了一种自动化生成管道AutoT2T，将数学应用题转换为基于表格的推理任务，从而消除手动标注的需要。该管道可以为同一推理问题生成多个表格变体，包括噪声版本以支持稳健性评估。基于此，我们构建了一个新的基准TabularGSM，系统地涵盖了表格复杂度范围和陷阱问题。通过AutoT2T和TabularGSM的实验分析揭示了推理与检索或识别过程之间的紧密耦合是导致LLM在复杂表格问答任务中失败的关键因素。这强调了为有效完成复杂表格问答任务，模型需要发展协同推理能力的必要性。', 'title_zh': '基于推理密集型表格问答的自动文本到表格转换：管道设计与基准研究'}
{'arxiv_id': 'arXiv:2505.19562', 'title': 'AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare', 'authors': 'Ying Xiao, Jie Huang, Ruijuan He, Jing Xiao, Mohammad Reza Mousavi, Yepang Liu, Kezhi Li, Zhenpeng Chen, Jie M. Zhang', 'link': 'https://arxiv.org/abs/2505.19562', 'abstract': 'Large language models (LLMs) are reaching expert-level accuracy on medical diagnosis questions, yet their mistakes and the biases behind them pose life-critical risks. Bias linked to race, sex, and socioeconomic status is already well known, but a consistent and automatic testbed for measuring it is missing. To fill this gap, this paper presents AMQA -- an Adversarial Medical Question-Answering dataset -- built for automated, large-scale bias evaluation of LLMs in medical QA. AMQA includes 4,806 medical QA pairs sourced from the United States Medical Licensing Examination (USMLE) dataset, generated using a multi-agent framework to create diverse adversarial descriptions and question pairs. Using AMQA, we benchmark five representative LLMs and find surprisingly substantial disparities: even GPT-4.1, the least biased model tested, answers privileged-group questions over 10 percentage points more accurately than unprivileged ones. Compared with the existing benchmark CPV, AMQA reveals 15% larger accuracy gaps on average between privileged and unprivileged groups. Our dataset and code are publicly available at this https URL to support reproducible research and advance trustworthy, bias-aware medical AI.', 'abstract_zh': '大型语言模型在医学诊断问题上的专家级准确性已达到，但其错误及其背后的偏见带来了生命攸关的风险。尽管与种族、性别和社会经济地位相关的偏见已广为人知，但缺乏一致的自动化评估平台。为填补这一空白，本文介绍了一个名为AMQA的对抗医学问答数据集，用于自动化大规模评估医学问答中大型语言模型的偏见。AMQA包括来自美国医学执照考试（USMLE）数据集的4,806个医学问答对，使用多智能体框架生成多样化的对抗描述和问题对。使用AMQA，我们对五种代表性大型语言模型进行了基准测试，发现了令人惊讶的显著差异：即使是测试中最不偏的GPT-4.1模型，也能在回答特权群体问题方面的准确性高出近10个百分点。与现有的基准CPV相比，AMQA在特权群体和非特权群体之间平均揭示出15%更大的准确性差距。我们的数据集和代码可在以下链接公开访问，以支持可重复研究并推进具有可信度和偏见意识的医学人工智能的发展。', 'title_zh': 'AMQA: 一个用于评估医学和健康-care领域LLMs偏见的对抗性数据集'}
{'arxiv_id': 'arXiv:2505.19550', 'title': 'Turing Test 2.0: The General Intelligence Threshold', 'authors': 'Georgios Mappouras', 'link': 'https://arxiv.org/abs/2505.19550', 'abstract': 'With the rise of artificial intelligence (A.I.) and large language models like Chat-GPT, a new race for achieving artificial general intelligence (A.G.I) has started. While many speculate how and when A.I. will achieve A.G.I., there is no clear agreement on how A.G.I. can be detected in A.I. models, even when popular tools like the Turing test (and its modern variations) are used to measure their intelligence. In this work, we discuss why traditional methods like the Turing test do not suffice for measuring or detecting A.G.I. and provide a new, practical method that can be used to decide if a (computer or any other) system has reached or surpassed A.G.I. To achieve this, we make two new contributions. First, we present a clear definition for general intelligence (G.I.) and set a G.I. threshold (G.I.T.) that can be used to distinguish between systems that achieve A.G.I. and systems that do not. Second, we present a new framework on how to construct tests that can detect if a system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass way. We call this novel framework the Turing Tests 2.0. We then demonstrate real-life examples of applying tests that follow our Turing Tests 2.0 framework on modern A.I. models.', 'abstract_zh': '随着人工智能（A.I.）和大型语言模型（如Chat-GPT）的兴起，一场实现人工通用智能（A.G.I.）的新竞赛已经启动。尽管许多人推测A.I.何时能够实现A.G.I.，但对于如何检测A.I.模型是否达到A.G.I.仍没有明确的共识，即使使用图灵测试（及其现代变体）这样的流行工具来衡量其智能水平亦是如此。在本研究中，我们讨论了为什么传统的图灵测试等方法不足以衡量或检测A.G.I.，并提供了一种新的、实用的方法，可以用来判断一个系统（无论是计算机还是其他系统）是否达到了或超越了A.G.I.。为了实现这一目标，我们做出了两项新的贡献。首先，我们提供了一个明确的人类通用智能（G.I.）的定义，并设定了一个通用智能门槛（G.I.T.），用于区分能够实现A.G.I.的系统和不能实现A.G.I.的系统。其次，我们提出了一个新框架，说明如何构建能以简单、全面且明确的失败/通过方式检测系统是否实现了通用智能的测试方法。我们称这一新颖框架为“图灵测试2.0”。然后，我们展示了如何在现代A.I.模型上应用遵循图灵测试2.0框架的测试示例。', 'title_zh': '图灵测试2.0：通用智能门槛'}
{'arxiv_id': 'arXiv:2505.19501', 'title': 'Genome-Bench: A Scientific Reasoning Benchmark from Real-World Expert Discussions', 'authors': 'Ming Yin, Yuanhao Qu, Dyllan Liu, Ling Yang, Le Cong, Mengdi Wang', 'link': 'https://arxiv.org/abs/2505.19501', 'abstract': 'In this short report, we present an automated pipeline tailored for the genomics domain and introduce \\textit{Genome-Bench}, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning friendly multiple-choice questions format, supported by 3000+ high quality question answer pairs spanning foundational biology, experimental troubleshooting, tool usage, and beyond. To our knowledge, this is the first end-to-end pipeline for teaching LLMs to reason from scientific discussions, with promising potential for generalization across scientific domains beyond biology.', 'abstract_zh': '在本简短报告中，我们提出了一套针对基因组学领域的自动化流程，并介绍了基于基因工程科学论坛讨论构建的新基准 \\textit{Genome-Bench}。我们的流程将原始交互转换为强化学习友好的多项选择题格式，包含3000多个高质量的问题及答案对，涵盖基础生物学、实验故障排除、工具使用等领域。据我们所知，这是首个端到端的教学流水线，用于让大型语言模型从科学讨论中进行推理，具有在生物学之外的科学领域中泛化的潜在前景。', 'title_zh': 'Genome-Bench: 一个来自现实专家讨论的科学推理基准'}
{'arxiv_id': 'arXiv:2505.19490', 'title': 'Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models', 'authors': 'Jianxing Liao, Junyan Xu, Yatao Sun, Maowen Tang, Sicheng He, Jingxian Liao, Shui Yu, Yun Li, Hongguan Xiao', 'link': 'https://arxiv.org/abs/2505.19490', 'abstract': 'Designing complex computer-aided design (CAD) models is often time-consuming due to challenges such as computational inefficiency and the difficulty of generating precise models. We propose a novel language-guided framework for industrial design automation to address these issues, integrating large language models (LLMs) with computer-automated design (CAutoD).Through this framework, CAD models are automatically generated from parameters and appearance descriptions, supporting the automation of design tasks during the detailed CAD design phase. Our approach introduces three key innovations: (1) a semi-automated data annotation pipeline that leverages LLMs and vision-language large models (VLLMs) to generate high-quality parameters and appearance descriptions; (2) a Transformer-based CAD generator (TCADGen) that predicts modeling sequences via dual-channel feature aggregation; (3) an enhanced CAD modeling generation model, called CADLLM, that is designed to refine the generated sequences by incorporating the confidence scores from TCADGen. Experimental results demonstrate that the proposed approach outperforms traditional methods in both accuracy and efficiency, providing a powerful tool for automating industrial workflows and generating complex CAD models from textual prompts. The code is available at this https URL', 'abstract_zh': '基于语言指导的工业设计自动化框架：通过将大型语言模型与计算机自动化设计集成以解决复杂计算机辅助设计模型设计难题', 'title_zh': '基于变压器的大语言模型从文本描述自动生成CAD建模序列'}
{'arxiv_id': 'arXiv:2505.19489', 'title': 'Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs', 'authors': 'Zhenhao Zhou, Zhuochen Huang, Yike He, Chong Wang, Jiajun Wang, Yijian Wu, Xin Peng, Yiling Lou', 'link': 'https://arxiv.org/abs/2505.19489', 'abstract': 'The Linux kernel is a critical system, serving as the foundation for numerous systems. Bugs in the Linux kernel can cause serious consequences, affecting billions of users. Fault localization (FL), which aims at identifying the buggy code elements in software, plays an essential role in software quality assurance. While recent LLM agents have achieved promising accuracy in FL on recent benchmarks like SWE-bench, it remains unclear how well these methods perform in the Linux kernel, where FL is much more challenging due to the large-scale code base, limited observability, and diverse impact factors. In this paper, we introduce LinuxFLBench, a FL benchmark constructed from real-world Linux kernel bugs. We conduct an empirical study to assess the performance of state-of-the-art LLM agents on the Linux kernel. Our initial results reveal that existing agents struggle with this task, achieving a best top-1 accuracy of only 41.6% at file level. To address this challenge, we propose LinuxFL$^+$, an enhancement framework designed to improve FL effectiveness of LLM agents for the Linux kernel. LinuxFL$^+$ substantially improves the FL accuracy of all studied agents (e.g., 7.2% - 11.2% accuracy increase) with minimal costs. Data and code are available at this https URL.', 'abstract_zh': 'Linux内核故障定位基准LinuxFLBench及其应用研究', 'title_zh': '本地化Linux内核漏洞的LLM代理benchmarking与增强'}
{'arxiv_id': 'arXiv:2505.19477', 'title': 'Judging with Many Minds: Do More Perspectives Mean Less Prejudice?', 'authors': 'Chiyu Ma, Enpei Zhang, Yilun Zhao, Wenjun Liu, Yaning Jia, Peijun Qing, Lin Shi, Arman Cohan, Yujun Yan, Soroush Vosoughi', 'link': 'https://arxiv.org/abs/2505.19477', 'abstract': 'LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings. While recent work has explored multi-agent extensions such as multi-agent debate and meta-judging to enhance evaluation quality, the question of how intrinsic biases manifest in these settings remains underexplored. In this study, we conduct a systematic analysis of four diverse bias types: position bias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate these biases across two widely adopted multi-agent LLM-as-Judge frameworks: Multi-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate framework amplifies biases sharply after the initial debate, and this increased bias is sustained in subsequent rounds, while meta-judge approaches exhibit greater resistance. We further investigate the incorporation of PINE, a leading single-agent debiasing method, as a bias-free agent within these systems. The results reveal that this bias-free agent effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios. Our work provides a comprehensive study of bias behavior in multi-agent LLM-as-Judge systems and highlights the need for targeted bias mitigation strategies in collaborative evaluation settings.', 'abstract_zh': 'LLM-as-裁判作为一种可扩展的人类评价替代方案，能够为训练提供奖励信号。虽然近期研究探索了多智能体扩展如多智能体辩论和元评价以提升评价质量，但这些环境中固有偏差的展现形式仍缺乏深入探讨。在本研究中，我们系统分析了四种不同类型的偏差：位置偏差、冗长偏差、推理链偏差和随大流偏差。我们在两个广泛采用的多智能体LLM-as-裁判框架——多智能体辩论和LLM-as-元裁判中评估这些偏差。结果显示，辩论框架在初始辩论后显著放大了偏差，并且这种偏差在后续轮次中持续存在，而元裁判方法则表现出更强的抗偏差能力。我们进一步研究了PINE，这是一种领先的单智能体去偏方法，将其作为无偏智能体集成到这些系统中。研究结果表明，在辩论环境中，这种无偏智能体有效减少了偏差，但在元裁判场景中的益处较少。我们的工作提供了多智能体LLM-as-裁判系统中偏差行为的全面研究，并强调了在协作评价环境中需要有针对性的偏差缓解策略。', 'title_zh': '众志定论：更多视角意味着 fewer prejudice 否？'}
{'arxiv_id': 'arXiv:2505.19474', 'title': 'Causal-LLaVA: Causal Disentanglement for Mitigating Hallucination in Multimodal Large Language Models', 'authors': 'Xinmiao Hu, Chun Wang, Ruihe An, ChenYu Shao, Xiaojun Ye, Sheng Zhou, Liangcheng Li', 'link': 'https://arxiv.org/abs/2505.19474', 'abstract': 'Multimodal Large Language Models (MLLMs) have demonstrated strong performance in visual understanding tasks, yet they often suffer from object hallucinations--generating descriptions of objects that are inconsistent with or entirely absent from the input. This issue is closely related to dataset biases, where frequent co-occurrences of objects lead to entangled semantic representations across modalities. As a result, models may erroneously activate object representations that are commonly associated with the input but not actually present.\nTo address this, we propose a causality-driven disentanglement framework that mitigates hallucinations through causal intervention. Our approach includes a Causal-Driven Projector in the visual pathway and a Causal Intervention Module integrated into the final transformer layer of the language model. These components work together to reduce spurious correlations caused by biased training data.\nExperimental results show that our method significantly reduces hallucinations while maintaining strong performance on multiple multimodal benchmarks. Visualization analyses further confirm improved separability of object representations.\nThe code is available at: this https URL', 'abstract_zh': '多模态大型语言模型（MLLMs）在视觉理解任务中表现出强大的性能，但却常常遭受对象幻觉的问题——生成与输入不符合或完全缺失对象的描述。这一问题与数据集偏差密切相关，频繁共现的对象导致跨模态纠缠的语义表示。因此，模型可能会错误地激活与输入常见但实际不存在的对象表示。\n为了解决这一问题，我们提出了一种因果驱动的解缠框架，通过因果干预减轻幻觉现象。该方法包括视觉路径中的因果驱动投影器和集成在语言模型最终变换层中的因果干预模块。这些组件共同作用，减少由有偏训练数据引起的虚假关联。\n实验结果表明，我们的方法在减少幻觉的同时，能够在多个跨模态基准上保持强大的性能。可视化分析进一步证实了对象表示可分离性的改善。\n代码可在以下链接获取：this https URL', 'title_zh': '因果LLaVA：因果分离方法减轻多模态大语言模型中的幻觉问题'}
{'arxiv_id': 'arXiv:2505.19466', 'title': 'Origin Tracer: A Method for Detecting LoRA Fine-Tuning Origins in LLMs', 'authors': 'Hongyu Liang, Yuting Zheng, Yihan Li, Yiran Zhang, Shiyu Liang', 'link': 'https://arxiv.org/abs/2505.19466', 'abstract': 'As large language models (LLMs) continue to advance, their deployment often involves fine-tuning to enhance performance on specific downstream tasks. However, this customization is sometimes accompanied by misleading claims about the origins, raising significant concerns about transparency and trust within the open-source community. Existing model verification techniques typically assess functional, representational, and weight similarities. However, these approaches often struggle against obfuscation techniques, such as permutations and scaling transformations. To address this limitation, we propose a novel detection method Origin-Tracer that rigorously determines whether a model has been fine-tuned from a specified base model. This method includes the ability to extract the LoRA rank utilized during the fine-tuning process, providing a more robust verification framework. This framework is the first to provide a formalized approach specifically aimed at pinpointing the sources of model fine-tuning. We empirically validated our method on thirty-one diverse open-source models under conditions that simulate real-world obfuscation scenarios. We empirically analyze the effectiveness of our framework and finally, discuss its limitations. The results demonstrate the effectiveness of our approach and indicate its potential to establish new benchmarks for model verification.', 'abstract_zh': '随着大型语言模型（LLMs）的不断进步，其部署通常涉及微调以增强特定下游任务的性能。然而，这种定制有时伴随着关于起源的误导性声明，这引发了开放源代码社区中透明度和信任方面的重要关切。现有的模型验证技术通常评估功能、表示和权重相似性。然而，这些方法往往难以抵御诸如排列和尺度变换等混淆技术。为了克服这一局限，我们提出了一个名为Origin-Tracer的新检测方法，该方法严格确定模型是否从指定的基础模型进行了微调。该方法包括从微调过程中提取LoRA秩的能力，从而提供了一个更为 robust 的验证框架。这是首个专门针对定位模型微调源的正式化方法。我们在模拟现实世界混淆场景的条件下对三十一个不同的开源模型 empirically 验证了该方法。我们 empirically 分析了该框架的有效性，并最终讨论了其局限性。结果表明了该方法的有效性，并指出其有可能为模型验证建立新的基准。', 'title_zh': '源追踪器：检测LLM中LoRA微调源头的方法'}
{'arxiv_id': 'arXiv:2505.19457', 'title': 'BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs', 'authors': 'Guilong Lu, Xuntao Guo, Rongjunchen Zhang, Wenqiao Zhu, Ji Liu', 'link': 'https://arxiv.org/abs/2505.19457', 'abstract': 'Large language models excel in general tasks, yet assessing their reliability in logic-heavy, precision-critical domains like finance, law, and healthcare remains challenging. To address this, we introduce BizFinBench, the first benchmark specifically designed to evaluate LLMs in real-world financial applications. BizFinBench consists of 6,781 well-annotated queries in Chinese, spanning five dimensions: numerical calculation, reasoning, information extraction, prediction recognition, and knowledge-based question answering, grouped into nine fine-grained categories. The benchmark includes both objective and subjective metrics. We also introduce IteraJudge, a novel LLM evaluation method that reduces bias when LLMs serve as evaluators in objective metrics. We benchmark 25 models, including both proprietary and open-source systems. Extensive experiments show that no model dominates across all tasks. Our evaluation reveals distinct capability patterns: (1) In Numerical Calculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while smaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning, proprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with open-source models trailing by up to 19.49 points; (3) In Information Extraction, the performance spread is the largest, with DeepSeek-R1 scoring 71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition, performance variance is minimal, with top models scoring between 39.16 and 50.00. We find that while current LLMs handle routine finance queries competently, they struggle with complex scenarios requiring cross-concept reasoning. BizFinBench offers a rigorous, business-aligned benchmark for future research. The code and dataset are available at this https URL.', 'abstract_zh': '大型语言模型在通用任务中表现出色，但在金融、法律和医疗等逻辑密集、精准度关键的领域中评估其可靠性仍然具有挑战性。为解决这一问题，我们引入了BizFinBench，这是首个专门设计用于评估LLM在现实世界金融应用中的基准。BizFinBench包含6,781个中文标注查询，涵盖五个维度：数值计算、推理、信息抽取、预测识别和基于知识的问题回答，分为九个精细类别。该基准包括客观和主观指标。我们还引入了IteraJudge，这是一种新型的LLM评估方法，可以减少LLM作为客观指标评估者时的偏见。我们对25个模型进行了基准测试，包括自有和开源系统。广泛实验证明，没有一种模型在所有任务中都占主导地位。我们的评估揭示了不同的能力模式：(1) 在数值计算中，Claude-3.5-Sonnet (63.18) 和 DeepSeek-R1 (64.04) 领先，而较小的模型如Qwen2.5-VL-3B (15.92) 显著落后；(2) 在推理中，自有模型占主导地位（ChatGPT-o3: 83.58，Gemini-2.0-Flash: 81.15），开源模型落后多达19.49分；(3) 在信息抽取中，性能差异最大，DeepSeek-R1 得分71.46，而Qwen3-1.7B 得分11.23；(4) 在预测识别中，性能差异最小，顶级模型得分在39.16到50.00之间。我们发现，虽然当前的语言模型能够有效处理常规的金融查询，但在需要跨概念推理的复杂场景中却显得力不从心。BizFinBench 提供了一个严格的、与商业对齐的基准，供未来的研究使用。相关代码和数据集可在以下链接获得。', 'title_zh': 'BizFinBench：一个以业务为导向的现实世界金融基准，用于评估LLM'}
{'arxiv_id': 'arXiv:2505.19442', 'title': 'Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning', 'authors': 'Dutao Zhang, Sergey Kovalchuk, YuLong He', 'link': 'https://arxiv.org/abs/2505.19442', 'abstract': 'Controllable code generation, the ability to synthesize code that follows a specified style while maintaining functionality, remains a challenging task. We propose a two-stage training framework combining contrastive learning and conditional decoding to enable flexible style control. The first stage aligns code style representations with semantic and structural features. In the second stage, we fine-tune a language model (e.g., Flan-T5) conditioned on the learned style vector to guide generation. Our method supports style interpolation and user personalization via lightweight mixing. Compared to prior work, our unified framework offers improved stylistic control without sacrificing code correctness. This is among the first approaches to combine contrastive alignment with conditional decoding for style-guided code generation.', 'abstract_zh': '可控代码生成：一种结合对比学习和条件解码的两阶段训练框架以实现灵活的样式控制', 'title_zh': 'Style2Code：一种基于双模态对比表示学习的风格可控代码生成框架'}
{'arxiv_id': 'arXiv:2505.19436', 'title': 'Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents', 'authors': 'Ye Ye', 'link': 'https://arxiv.org/abs/2505.19436', 'abstract': "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context. This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents. We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning. TME implements a spatial memory framework that replaces flat context with graph-based structures to support consistent, multi-turn reasoning. Departing from linear concatenation and ReAct-style prompting, TME builds a dynamic task graph -- either a tree or directed acyclic graph (DAG) -- to map user inputs to subtasks, align them with prior context, and enable dependency-tracked revisions. Its Task Representation and Intent Management (TRIM) component models task semantics and user intent to ensure accurate interpretation. Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct. TME's modular design supports plug-and-play deployment and domain-specific customization, adaptable to both personal assistants and enterprise automation. We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents. TME's scalable architecture addresses a critical gap in agent performance across complex, interactive settings.", 'abstract_zh': '大型语言模型在多步交互中表现脆弱——往往产生幻觉、重复操作或误解用户纠正——这是因为它们依赖于线性的非结构化上下文。这种脆弱性源自缺乏持续记忆来跟踪不断演变的目标和任务依赖性，从而破坏了对自主代理的信任。我们引入了任务记忆引擎（TME），这是一种模块化记忆控制器，能够无需微调即把现有LLM转变为稳健、修订感知的代理。TME实现了一种空间记忆框架，用基于图的结构替换平缓的上下文，以支持一致的多轮推理。TME不同于线性拼接和ReAct式的提示，构建了一个动态任务图——既可以是树结构，也可以是有向无环图（DAG），将用户输入映射到子任务，与先前的上下文对齐，并支持依赖性跟踪的修订。其任务表示和意图管理（TRIM）组件模型任务语义和用户意图，以确保准确解释。在四个多轮场景（旅行规划、烹饪、会议日程安排和购物车编辑）中，TME在三个任务中消除了100%的幻觉和误解，在27个用户轮次中将幻觉减少了66.7%，误解减少了83.3%，超过了ReAct。TME的模块化设计支持插件部署和特定领域的定制，适用于个人助理和企业自动化。我们发布了TME的代码库、基准测试和组件作为开源资源，使研究人员能够开发可靠的LLM代理。TME的可扩展架构跨复杂的交互设置解决了代理性能的关键缺口。', 'title_zh': '任务记忆引擎：稳健的多步LLM代理的空间记忆'}
{'arxiv_id': 'arXiv:2505.19414', 'title': 'Toward Physics-Informed Machine Learning for Data Center Operations: A Tropical Case Study', 'authors': 'Ruihang Wang, Zhiwei Cao, Qingang Zhang, Rui Tan, Yonggang Wen, Tommy Leung, Stuart Kennedy, Justin Teoh', 'link': 'https://arxiv.org/abs/2505.19414', 'abstract': 'Data centers are the backbone of computing capacity. Operating data centers in the tropical regions faces unique challenges due to consistently high ambient temperature and elevated relative humidity throughout the year. These conditions result in increased cooling costs to maintain the reliability of the computing systems. While existing machine learning-based approaches have demonstrated potential to elevate operations to a more proactive and intelligent level, their deployment remains dubious due to concerns about model extrapolation capabilities and associated system safety issues. To address these concerns, this article proposes incorporating the physical characteristics of data centers into traditional data-driven machine learning solutions. We begin by introducing the data center system, including the relevant multiphysics processes and the data-physics availability. Next, we outline the associated modeling and optimization problems and propose an integrated, physics-informed machine learning system to address them. Using the proposed system, we present relevant applications across varying levels of operational intelligence. A case study on an industry-grade tropical data center is provided to demonstrate the effectiveness of our approach. Finally, we discuss key challenges and highlight potential future directions.', 'abstract_zh': '数据中心是计算能力的支柱。在热带地区运营数据中心面临着独特的挑战，由于全年的高温和高湿度，这会导致更高的冷却成本以维持计算系统的可靠性。虽然现有的基于机器学习的方法展现了提升运营至更主动和智能水平的潜力，但其部署仍因模型外推能力和相关系统安全问题的担忧而受到质疑。为解决这些问题，本文提出将数据中心的物理特性整合到传统的数据驱动机器学习解决方案中。我们首先介绍数据中心系统，包括相关的多物理过程和数据-物理可用性。接着，我们概述相关的建模和优化问题，并提出一个整合的、基于物理的方法的机器学习系统来解决这些问题。通过所提出的方法，我们展示了不同层次操作智能的相关应用。提供了一个工业级热带数据中心的案例研究，以证明我们方法的有效性。最后，我们讨论了关键挑战并指出了潜在的未来方向。', 'title_zh': '面向数据中心运营的物理知情机器学习研究：以热带地区为例'}
{'arxiv_id': 'arXiv:2505.19409', 'title': 'Fusion Intelligence for Digital Twinning AI Data Centers: A Synergistic GenAI-PhyAI Approach', 'authors': 'Ruihang Wang, Minghao Li, Zhiwei Cao, Jimin Jia, Kyle Guan, Yonggang Wen', 'link': 'https://arxiv.org/abs/2505.19409', 'abstract': "The explosion in artificial intelligence (AI) applications is pushing the development of AI-dedicated data centers (AIDCs), creating management challenges that traditional methods and standalone AI solutions struggle to address. While digital twins are beneficial for AI-based design validation and operational optimization, current AI methods for their creation face limitations. Specifically, physical AI (PhyAI) aims to capture the underlying physical laws, which demands extensive, case-specific customization, and generative AI (GenAI) can produce inaccurate or hallucinated results. We propose Fusion Intelligence, a novel framework synergizing GenAI's automation with PhyAI's domain grounding. In this dual-agent collaboration, GenAI interprets natural language prompts to generate tokenized AIDC digital twins. Subsequently, PhyAI optimizes these generated twins by enforcing physical constraints and assimilating real-time data. Case studies demonstrate the advantages of our framework in automating the creation and validation of AIDC digital twins. These twins deliver predictive analytics to support power usage effectiveness (PUE) optimization in the design stage. With operational data collected, the digital twin accuracy is further improved compared with pure physics-based models developed by human experts. Fusion Intelligence offers a promising pathway to accelerate digital transformation. It enables more reliable and efficient AI-driven digital transformation for a broad range of mission-critical infrastructures.", 'abstract_zh': '人工智能应用的爆炸式增长推动了专用人工智能数据中心(AIDCs)的发展，传统方法和独立的人工智能解决方案难以应对由此产生的管理挑战。尽管数字孪生在基于人工智能的设计验证和运营优化方面具有优势，但目前用于创建数字孪生的人工智能方法存在局限性。具体而言，物理人工智能(PhyAI)旨在捕捉底层物理定律，这需要广泛的、特定案例的定制，而生成人工智能(GenAI)则可能产生不准确或幻觉的结果。我们提出了融合智能(Fusion Intelligence)这一新颖框架，该框架结合了GenAI的自动化优势与PhyAI的专业背景。在此双代理协作中，GenAI通过解释自然语言提示来生成标记化的AIDC数字孪生。随后，PhyAI通过施加物理约束并融合实时数据来优化这些生成的数字孪生。案例研究证明了该框架在自动化创建和验证AIDC数字孪生方面的优势。这些数字孪生能够提供预测分析，以支持设计阶段的PUE优化。随着运营数据的收集，与由人类专家开发的基于物理学的模型相比，数字孪生的准确性得到了进一步提高。融合智能为加速数字化转型提供了有前景的道路，能够为多类关键基础设施实现更可靠和高效的基于人工智能的数字化转型。', 'title_zh': '数字孪生AI数据中心的融合智能：一种协同生成人工智能-物理人工智能方法'}
{'arxiv_id': 'arXiv:2505.19406', 'title': 'Unveiling the Compositional Ability Gap in Vision-Language Reasoning Model', 'authors': 'Tianle Li, Jihai Zhang, Yongming Rao, Yu Cheng', 'link': 'https://arxiv.org/abs/2505.19406', 'abstract': 'While large language models (LLMs) demonstrate strong reasoning capabilities utilizing reinforcement learning (RL) with verifiable reward, whether large vision-language models (VLMs) can directly inherit such capabilities through similar post-training strategies remains underexplored. In this work, we conduct a systematic compositional probing study to evaluate whether current VLMs trained with RL or other post-training strategies can compose capabilities across modalities or tasks under out-of-distribution conditions. We design a suite of diagnostic tasks that train models on unimodal tasks or isolated reasoning skills, and evaluate them on multimodal, compositional variants requiring skill integration. Through comparisons between supervised fine-tuning (SFT) and RL-trained models, we identify three key findings: (1) RL-trained models consistently outperform SFT on compositional generalization, demonstrating better integration of learned skills; (2) although VLMs achieve strong performance on individual tasks, they struggle to generalize compositionally under cross-modal and cross-task scenario, revealing a significant gap in current training strategies; (3) enforcing models to explicitly describe visual content before reasoning (e.g., caption-before-thinking), along with rewarding progressive vision-to-text grounding, yields notable gains. It highlights two essential ingredients for improving compositionality in VLMs: visual-to-text alignment and accurate visual grounding. Our findings shed light on the current limitations of RL-based reasoning VLM training and provide actionable insights toward building models that reason compositionally across modalities and tasks.', 'abstract_zh': '大规模视觉-语言模型能否通过类似的后训练策略直接继承基于强化学习的推理能力：一种系统的组件探查研究', 'title_zh': '揭示视觉-语言推理模型的组合作能力差距'}
{'arxiv_id': 'arXiv:2505.19402', 'title': 'Recalibrating the Compass: Integrating Large Language Models into Classical Research Methods', 'authors': 'Tai-Quan Peng, Xuzhen Yang', 'link': 'https://arxiv.org/abs/2505.19402', 'abstract': 'This paper examines how large language models (LLMs) are transforming core quantitative methods in communication research in particular, and in the social sciences more broadly-namely, content analysis, survey research, and experimental studies. Rather than replacing classical approaches, LLMs introduce new possibilities for coding and interpreting text, simulating dynamic respondents, and generating personalized and interactive stimuli. Drawing on recent interdisciplinary work, the paper highlights both the potential and limitations of LLMs as research tools, including issues of validity, bias, and interpretability. To situate these developments theoretically, the paper revisits Lasswell\'s foundational framework -- "Who says what, in which channel, to whom, with what effect?" -- and demonstrates how LLMs reconfigure message studies, audience analysis, and effects research by enabling interpretive variation, audience trajectory modeling, and counterfactual experimentation. Revisiting the metaphor of the methodological compass, the paper argues that classical research logics remain essential as the field integrates LLMs and generative AI. By treating LLMs not only as technical instruments but also as epistemic and cultural tools, the paper calls for thoughtful, rigorous, and imaginative use of LLMs in future communication and social science research.', 'abstract_zh': '这篇论文探讨了大型语言模型（LLMs）如何在沟通研究尤其在社会科学中转变核心定量方法，具体而言，即内容分析、调查研究和实验研究。与其替代经典方法，LLMs引入了编码和解释文本的新可能性，模拟动态受访者，并生成个性化和互动刺激。论文借助近期的跨学科研究，突显了LLMs作为研究工具的潜力与局限性，包括有效性和偏差等问题。为理论地放置这些发展，论文回顾了拉斯韦尔的基础框架——“谁说，说什么，在哪个渠道，对谁，有什么效果？”，并展示了LLMs如何重新配置信息研究、受众分析和效果研究，通过支持解释变体、受众轨迹建模和反事实实验。重新使用方法论指南针的隐喻，论文认为，随着领域整合LLMs和生成型AI，经典的研究逻辑仍然至关重要。将LLMs不仅视为技术工具，也是认识论与文化工具，论文呼吁在未来沟通与社会科学研究中，对LLMs进行深思熟虑、严谨和富有想象力的使用。', 'title_zh': '校准罗盘：将大型语言模型集成到经典研究方法中'}
{'arxiv_id': 'arXiv:2505.19383', 'title': 'CaseEdit: Enhancing Localized Commonsense Reasoning via Null-Space Constrained Knowledge Editing in Small Parameter Language Models', 'authors': 'Varun Reddy, Yen-Ling Kuo', 'link': 'https://arxiv.org/abs/2505.19383', 'abstract': 'Large language models (LLMs) exhibit strong performance on factual recall and general reasoning but struggle to adapt to user-specific, commonsense knowledge, a challenge particularly acute in small-parameter settings where computational efficiency is prioritized. We introduce CaseEdit, a new dataset and generation pipeline for evaluating localized, personalized commonsense knowledge editing in small LLMs to address this. Built upon the ATOMIC20/20 commonsense graph, CaseEdit uses a multi-stage inference process to generate both typical and atypical contextual edits for household objects, paired with targeted evaluation questions across four axes: reliability, generalization, locality, and portability. We evaluate established knowledge editing methods using CaseEdit and demonstrate that AlphaEdit, a technique employing null-space projection to minimize interference with unrelated knowledge, consistently outperforms other methods when applied to an LLaMA 3.2 3B model, even in scalability tests, showing minimal ripple effects. Our results indicate that using CaseEdit with effective editing techniques like AlphaEdit allows small models to internalize high-quality, context-sensitive common-sense knowledge, paving the way for lightweight, personalized assistants.', 'abstract_zh': '大型语言模型（LLMs）在事实回忆和通用推理方面表现出色，但在适应用户特定的常识知识方面存在挑战，特别是在参数量较小、计算效率优先的情况下这一挑战尤为严峻。我们引入了CaseEdit，一个新数据集及生成管道，用于评估小型LLM中局部化和个人化的常识知识编辑能力，以应对这一挑战。基于ATOMIC20/20常识图谱，CaseEdit使用多层次推理过程生成家用物体的典型和非典型上下文编辑，并配以四个维度的目标评估问题：可靠性、泛化能力、局部性和可移植性。我们使用CaseEdit评估现有的知识编辑方法，并证明使用零空间投影以最小化与无关知识的干扰的AlphaEdit技术，在应用于一个3.2B参数的LLaMA模型时，即使在可扩展性测试中也表现出更优性能，且几乎没有次生影响。我们的研究结果表明，使用CaseEdit和有效的编辑技术如AlphaEdit，可以使小型模型内化高质量的上下文敏感常识知识，为轻量级、个性化助手的发展铺平道路。', 'title_zh': 'CaseEdit: 借助 null 空间约束知识编辑增强小参数语言模型的局部常识推理'}
{'arxiv_id': 'arXiv:2505.19381', 'title': 'DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving', 'authors': 'Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng, Hao Jiang, Zongzheng Zhang, Xianda Guo, Hao Sun, Hao Zhao', 'link': 'https://arxiv.org/abs/2505.19381', 'abstract': "Research interest in end-to-end autonomous driving has surged owing to its fully differentiable design integrating modular tasks, i.e. perception, prediction and planing, which enables optimization in pursuit of the ultimate goal. Despite the great potential of the end-to-end paradigm, existing methods suffer from several aspects including expensive BEV (bird's eye view) computation, action diversity, and sub-optimal decision in complex real-world scenarios. To address these challenges, we propose a novel hybrid sparse-dense diffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA. We explore the sparse diffusion representation for efficient multi-modal driving behavior. Moreover, we rethink the effectiveness of VLM driving decision and improve the trajectory generation guidance through deep interaction across agent, map instances and VLM output. Our method shows superior performance in Autonomous Grand Challenge 2025 which contains challenging real and reactive synthetic scenarios. Our methods achieves 45.0 PDMS.", 'abstract_zh': '端到端自动驾驶研究兴趣因其实现全可微设计而激增，该设计集成了感知、预测和规划等模块任务，以优化实现最终目标。尽管端到端范式的潜力巨大，但现有方法仍存在计算BEV图昂贵、行为多样性以及在复杂真实场景中的次优决策等几个方面的问题。为解决这些问题，我们提出了一种新型混合稀疏-密集扩散策略，该策略基于视觉语言模型（VLM）被称为Diff-VLA。我们探索了稀疏扩散表示以实现高效的多模态驾驶行为。此外，我们重新思考了VLM驱动决策的有效性，并通过深入跨智能体、地图实例和VLM输出的交互来改进轨迹生成指导。我们的方法在包含具有挑战性的实时和反应式合成场景的2025年自主 grand 挑战中表现出色，实现了45.0 PDMS。', 'title_zh': 'DiffVLA: 视觉-语言引导的自主驾驶扩散规划'}
{'arxiv_id': 'arXiv:2505.19371', 'title': 'Foundations of Top-$k$ Decoding For Language Models', 'authors': 'Georgy Noarov, Soham Mallick, Tao Wang, Sunay Joshi, Yan Sun, Yangxinyu Xie, Mengxin Yu, Edgar Dobriban', 'link': 'https://arxiv.org/abs/2505.19371', 'abstract': 'Top-$k$ decoding is a widely used method for sampling from LLMs: at each token, only the largest $k$ next-token-probabilities are kept, and the next token is sampled after re-normalizing them to sum to unity. Top-$k$ and other sampling methods are motivated by the intuition that true next-token distributions are sparse, and the noisy LLM probabilities need to be truncated. However, to our knowledge, a precise theoretical motivation for the use of top-$k$ decoding is missing. In this work, we develop a theoretical framework that both explains and generalizes top-$k$ decoding. We view decoding at a fixed token as the recovery of a sparse probability distribution. We consider \\emph{Bregman decoders} obtained by minimizing a separable Bregman divergence (for both the \\emph{primal} and \\emph{dual} cases) with a sparsity-inducing $\\ell_0$ regularization. Despite the combinatorial nature of the objective, we show how to optimize it efficiently for a large class of divergences. We show that the optimal decoding strategies are greedy, and further that the loss function is discretely convex in $k$, so that binary search provably and efficiently finds the optimal $k$. We show that top-$k$ decoding arises as a special case for the KL divergence, and identify new decoding strategies that have distinct behaviors (e.g., non-linearly up-weighting larger probabilities after re-normalization).', 'abstract_zh': 'Top-$k$ 解码是广泛用于从大规模语言模型采样的方法：在每个标记处，仅保留最大的 $k$ 个下一个标记概率，并在重新归一化使它们之和为1后进行采样。Top-$k$ 解码和其他采样方法是基于直觉，即真实的下一个标记分布是稀疏的，而嘈杂的大规模语言模型概率需要截断。然而，据我们所知，缺乏对使用Top-$k$ 解码的精确理论动机。在本文中，我们开发了一个理论框架，该框架不仅解释了Top-$k$ 解码，还对其进行了推广。我们将固定标记处的解码视为稀疏概率分布的恢复。我们考虑通过最小化分离性Bregman发散（对于原问题和对偶问题两种情况）并带有稀疏性诱导的$\\ell_0$正则化得到的Bregman解码器。尽管目标函数具有组合性质，我们展示了如何高效地优化其为一大类发散的情形。我们证明了最优的解码策略是贪婪的，并且损失函数在 $k$ 上二阶离散凸，因此二分搜索可以证明地高效找到最优的 $k$。我们证明了Top-$k$ 解码在KL散度情况下作为特殊情形出现，并识别出具有不同行为的新解码策略（例如，在重新归一化后非线性地加重较大概率的权重）。', 'title_zh': 'Top-k 解码语言模型的理论基础'}
{'arxiv_id': 'arXiv:2505.19361', 'title': 'Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments', 'authors': 'Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran, Gerardo Simari', 'link': 'https://arxiv.org/abs/2505.19361', 'abstract': 'The deployment of pre-trained perception models in novel environments often leads to performance degradation due to distributional shifts. Although recent artificial intelligence approaches for metacognition use logical rules to characterize and filter model errors, improving precision often comes at the cost of reduced recall. This paper addresses the hypothesis that leveraging multiple pre-trained models can mitigate this recall reduction. We formulate the challenge of identifying and managing conflicting predictions from various models as a consistency-based abduction problem. The input predictions and the learned error detection rules derived from each model are encoded in a logic program. We then seek an abductive explanation--a subset of model predictions--that maximizes prediction coverage while ensuring the rate of logical inconsistencies (derived from domain constraints) remains below a specified threshold. We propose two algorithms for this knowledge representation task: an exact method based on Integer Programming (IP) and an efficient Heuristic Search (HS). Through extensive experiments on a simulated aerial imagery dataset featuring controlled, complex distributional shifts, we demonstrate that our abduction-based framework outperforms individual models and standard ensemble baselines, achieving, for instance, average relative improvements of approximately 13.6% in F1-score and 16.6% in accuracy across 15 diverse test datasets when compared to the best individual model. Our results validate the use of consistency-based abduction as an effective mechanism to robustly integrate knowledge from multiple imperfect reasoners in challenging, novel scenarios.', 'abstract_zh': '利用多个预训练模型减轻新颖环境下的召回率降低问题：基于一致性 abduction 的元认知方法', 'title_zh': '基于一致性的 abduction 推理在多预训练模型感知错误的新型环境中的应用'}
{'arxiv_id': 'arXiv:2505.19353', 'title': 'Architectures of Error: A Philosophical Inquiry into AI and Human Code Generation', 'authors': 'Camilo Chacón Sartori', 'link': 'https://arxiv.org/abs/2505.19353', 'abstract': "With the rise of generative AI (GenAI), Large Language Models are increasingly employed for code generation, becoming active co-authors alongside human programmers. Focusing specifically on this application domain, this paper articulates distinct ``Architectures of Error'' to ground an epistemic distinction between human and machine code generation. Examined through their shared vulnerability to error, this distinction reveals fundamentally different causal origins: human-cognitive versus artificial-stochastic. To develop this framework and substantiate the distinction, the analysis draws critically upon Dennett's mechanistic functionalism and Rescher's methodological pragmatism. I argue that a systematic differentiation of these error profiles raises critical philosophical questions concerning semantic coherence, security robustness, epistemic limits, and control mechanisms in human-AI collaborative software development. The paper also utilizes Floridi's levels of abstraction to provide a nuanced understanding of how these error dimensions interact and may evolve with technological advancements. This analysis aims to offer philosophers a structured framework for understanding GenAI's unique epistemological challenges, shaped by these architectural foundations, while also providing software engineers a basis for more critically informed engagement.", 'abstract_zh': '随着生成型人工智能（GenAI）的兴起，大型语言模型在代码生成中被越来越多地应用，成为与人类程序员并肩工作的活跃合作者。本文专注于这一应用领域，提出独特的“错误架构”，以阐明人类与机器代码生成在认识论上的区别。通过考察它们在错误上的共同脆弱性，这一区别揭示了根本不同的因果来源：人认知的与人工随机的。为了发展这一框架并证实这种区分，分析批判性地借鉴了丹内特的机械功能主义和雷舍的方法论实用主义。我认为，系统地区分这些错误特征提出了关于语义连贯性、安全性可靠性、认识论局限性和控制机制在人机协同软件开发中的关键哲学问题。本文还利用弗洛里迪的抽象层次来提供一个详细的理解，解释这些错误维度如何相互作用以及如何随着技术进步而演变。这篇分析旨在为哲学家提供一个结构化的框架来理解受这些架构基础影响的GenAI的独特认识论挑战，同时也为软件工程师提供一个更批判性参与的基础。', 'title_zh': '错误的架构：关于AI与人类代码生成的哲学探究'}
{'arxiv_id': 'arXiv:2505.19347', 'title': 'PatentMind: A Multi-Aspect Reasoning Graph for Patent Similarity Evaluation', 'authors': 'Yongmin Yoo, Qiongkai Xu, Longbing Cao', 'link': 'https://arxiv.org/abs/2505.19347', 'abstract': 'Patent similarity evaluation plays a critical role in intellectual property analysis. However, existing methods often overlook the intricate structure of patent documents, which integrate technical specifications, legal boundaries, and application contexts. We introduce PatentMind, a novel framework for patent similarity assessment based on a Multi-Aspect Reasoning Graph (MARG). PatentMind decomposes patents into three core dimensions: technical feature, application domain, and claim scope, to compute dimension-specific similarity scores. These scores are dynamically weighted through a four-stage reasoning process which integrates contextual signals to emulate expert-level judgment. To support evaluation, we construct PatentSimBench, a human-annotated benchmark comprising 500 patent pairs. Experimental results demonstrate that PatentMind achieves a strong correlation ($r=0.938$) with expert annotations, significantly outperforming embedding-based models and advanced prompt engineering this http URL results highlight the effectiveness of modular reasoning frameworks in overcoming key limitations of embedding-based methods for analyzing patent similarity.', 'abstract_zh': '专利相似性评估在知识产权分析中发挥着关键作用。然而，现有方法往往忽视了专利文件的复杂结构，这些文件整合了技术规范、法律边界和应用背景。我们提出了基于多方面推理图（MARG）的新型专利相似性评估框架PatentMind。PatentMind将专利分解为核心维度：技术特征、应用领域和权利要求范围，以计算维度特定的相似性分数。这些分数通过四阶段推理过程动态加权，该过程整合上下文信号以模拟专家级判断。为了支持评估，我们构建了包含500个专利配对的人工标注基准PatentSimBench。实验结果表明，PatentMind与专家注释之间具有强相关性（$r=0.938$），显著优于基于嵌入的方法和高级提示工程方法。这些结果突显了模块化推理框架在克服基于嵌入方法的关键限制方面的有效性，特别是在分析专利相似性方面。', 'title_zh': 'PatentMind: 一种专利相似性评估的多方面推理图'}
{'arxiv_id': 'arXiv:2505.19333', 'title': 'Evaluating Steering Techniques using Human Similarity Judgments', 'authors': 'Zach Studdiford, Timothy T. Rogers, Siddharth Suresh, Kushin Mukherjee', 'link': 'https://arxiv.org/abs/2505.19333', 'abstract': "Current evaluations of Large Language Model (LLM) steering techniques focus on task-specific performance, overlooking how well steered representations align with human cognition. Using a well-established triadic similarity judgment task, we assessed steered LLMs on their ability to flexibly judge similarity between concepts based on size or kind. We found that prompt-based steering methods outperformed other methods both in terms of steering accuracy and model-to-human alignment. We also found LLMs were biased towards 'kind' similarity and struggled with 'size' alignment. This evaluation approach, grounded in human cognition, adds further support to the efficacy of prompt-based steering and reveals privileged representational axes in LLMs prior to steering.", 'abstract_zh': '当前对大型语言模型（LLM）引导技术的评估主要关注任务特定性能，忽视了引导表示与人类认知的一致性。通过使用广泛认可的三元相似性判断任务，我们评估了引导的LLM在基于大小或种类灵活判断概念相似性方面的能力。我们发现基于提示的引导方法在引导准确性和模型与人类的一致性方面优于其他方法。我们还发现LLM倾向于“种类”相似性，并在“大小”对齐方面遇到困难。这种基于人类认知的评估方法为进一步支持基于提示的引导的有效性提供了更多证据，并揭示了在引导之前LLM的特权表示轴。', 'title_zh': '基于人类相似性判断评价转向技术'}
{'arxiv_id': 'arXiv:2505.19317', 'title': 'Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics', 'authors': 'Tin Nguyen, Jiannan Xu, Zora Che, Phuong-Anh Nguyen-Le, Rushil Dandamudi, Donald Braman, Furong Huang, Hal Daumé III, Zubin Jelveh', 'link': 'https://arxiv.org/abs/2505.19317', 'abstract': 'Although popularized AI fairness metrics, e.g., demographic parity, have uncovered bias in AI-assisted decision-making outcomes, they do not consider how much effort one has spent to get to where one is today in the input feature space. However, the notion of effort is important in how Philosophy and humans understand fairness. We propose a philosophy-informed way to conceptualize and evaluate Effort-aware Fairness (EaF) based on the concept of Force, or temporal trajectory of predictive features coupled with inertia. In addition to our theoretical formulation of EaF metrics, our empirical contributions include: 1/ a pre-registered human subjects experiment, which demonstrates that for both stages of the (individual) fairness evaluation process, people consider the temporal trajectory of a predictive feature more than its aggregate value; 2/ pipelines to compute Effort-aware Individual/Group Fairness in the criminal justice and personal finance contexts. Our work may enable AI model auditors to uncover and potentially correct unfair decisions against individuals who spent significant efforts to improve but are still stuck with systemic/early-life disadvantages outside their control.', 'abstract_zh': '尽管普及了诸如人口均等等AI公平性指标，这些指标揭示了AI辅助决策结果中的偏见，但它们没有考虑一个人达到当前输入特征空间位置所付出的努力。然而，在哲学和人类对公平的理解中，努力的概念是重要的。我们提出了一种基于力的概念，即预测特征的时间轨迹与惯性结合的哲学启发式方法来构思和评估知努力公平性（EaF）。除了我们对EaF指标的理论框架，我们的实证贡献还包括：1/ 注册的双盲人类被试实验，结果表明，在（个体）公平性评估过程的两个阶段中，人们更关注预测特征的时间轨迹而非其聚合值；2/ 刑事司法和个人金融领域的计算知努力个体/群体公平性的流程。我们的工作可能使AI模型审计者能够揭示并可能修正那些尽管付出巨大努力但仍遭受系统性/童年期无法控制的不利因素影响而导致的不公平决定。', 'title_zh': '考虑努力的公平性：将哲学启发的人本主义努力观念融入算法公平性度量'}
{'arxiv_id': 'arXiv:2505.19277', 'title': 'Next Token Prediction Is a Dead End for Creativity', 'authors': 'Ibukun Olatunji, Mark Sheppard', 'link': 'https://arxiv.org/abs/2505.19277', 'abstract': 'This paper argues that token prediction is fundamentally misaligned with real creativity. While next-token models have enabled impressive advances in language generation, their architecture favours surface-level coherence over spontaneity, originality, and improvisational risk. We use battle rap as a case study to expose the limitations of predictive systems, demonstrating that they cannot truly engage in adversarial or emotionally resonant exchanges. By reframing creativity as an interactive process rather than a predictive output, we offer a vision for AI systems that are more expressive, responsive, and aligned with human creative practice.', 'abstract_zh': '本文 argue认为token预测从根本上与真正的创造力不一致。虽然下一个token模型在语言生成方面取得了令人印象深刻的进展，但它们的架构更倾向于表面一致性而非自发性、原创性和即兴冒险。我们以battle rap为例，揭示预测系统的局限性，证明它们无法真正进行对抗性或情感共鸣的交流。通过将创造力重新定义为一种互动过程而非预测输出，我们提出了更加表达性、响应性和与人类创造性实践相一致的AI系统的愿景。', 'title_zh': '下一个 token 预测是创造力的死胡同。'}
{'arxiv_id': 'arXiv:2505.19266', 'title': "Using Large Language Models to Assess Teachers' Pedagogical Content Knowledge", 'authors': 'Yaxuan Yang, Shiyu Wang, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2505.19266', 'abstract': "Assessing teachers' pedagogical content knowledge (PCK) through performance-based tasks is both time and effort-consuming. While large language models (LLMs) offer new opportunities for efficient automatic scoring, little is known about whether LLMs introduce construct-irrelevant variance (CIV) in ways similar to or different from traditional machine learning (ML) and human raters. This study examines three sources of CIV -- scenario variability, rater severity, and rater sensitivity to scenario -- in the context of video-based constructed-response tasks targeting two PCK sub-constructs: analyzing student thinking and evaluating teacher responsiveness. Using generalized linear mixed models (GLMMs), we compared variance components and rater-level scoring patterns across three scoring sources: human raters, supervised ML, and LLM. Results indicate that scenario-level variance was minimal across tasks, while rater-related factors contributed substantially to CIV, especially in the more interpretive Task II. The ML model was the most severe and least sensitive rater, whereas the LLM was the most lenient. These findings suggest that the LLM contributes to scoring efficiency while also introducing CIV as human raters do, yet with varying levels of contribution compared to supervised ML. Implications for rater training, automated scoring design, and future research on model interpretability are discussed.", 'abstract_zh': '通过基于性能的任务评估教师的教学内容知识（PCK）既耗时又耗力。尽管大型语言模型（LLMs）提供了高效自动评分的新机遇，但尚不清楚LLMs是否以与传统机器学习（ML）和人工评分者类似或不同的方式引入无关构念变异（CIV）。本研究在基于视频的建构性反应任务中，针对两个PCK子领域——分析学生思维和评价教师反应性，探讨了三种CIV来源——情境变异、评分者严厉度和评分者对情境的敏感度。通过广义线性混合效应模型（GLMMs），我们比较了三种评分来源（人工评分者、监督机器学习和LLM）的方差成分和评分者级评分模式。结果显示，任务层面的变异在各任务中相对较低，而与评分者相关的因素对CIV的贡献较大，尤其是在更具解释性的任务II中。监督机器学习模型是最严厉且对情境最不敏感的评分者，而LLM是最宽容的。这些发现表明，尽管LLM提高了评分效率，但在引入CIV方面的作用类似于人工评分者，但在贡献程度上与监督机器学习有所不同。讨论了评分者培训、自动化评分设计以及未来关于模型可解释性研究的含义。', 'title_zh': '使用大型语言模型评估教师的学科教学知识'}
{'arxiv_id': 'arXiv:2505.19237', 'title': 'Sensorimotor features of self-awareness in multimodal large language models', 'authors': 'Iñaki Dellibarda Varela, Pablo Romero-Sorozabal, Diego Torricelli, Gabriel Delgado-Oleas, Jose Ignacio Serrano, Maria Dolores del Castillo Sobrino, Eduardo Rocon, Manuel Cebrian', 'link': 'https://arxiv.org/abs/2505.19237', 'abstract': 'Self-awareness - the ability to distinguish oneself from the surrounding environment - underpins intelligent, autonomous behavior. Recent advances in AI achieve human-like performance in tasks integrating multimodal information, particularly in large language models, raising interest in the embodiment capabilities of AI agents on nonhuman platforms such as robots. Here, we explore whether multimodal LLMs can develop self-awareness solely through sensorimotor experiences. By integrating a multimodal LLM into an autonomous mobile robot, we test its ability to achieve this capacity. We find that the system exhibits robust environmental awareness, self-recognition and predictive awareness, allowing it to infer its robotic nature and motion characteristics. Structural equation modeling reveals how sensory integration influences distinct dimensions of self-awareness and its coordination with past-present memory, as well as the hierarchical internal associations that drive self-identification. Ablation tests of sensory inputs identify critical modalities for each dimension, demonstrate compensatory interactions among sensors and confirm the essential role of structured and episodic memory in coherent reasoning. These findings demonstrate that, given appropriate sensory information about the world and itself, multimodal LLMs exhibit emergent self-awareness, opening the door to artificial embodied cognitive systems.', 'abstract_zh': '自知之明——区分自身与周围环境的能力——是智能自主行为的基础。近期AI在整合多模态信息的任务中取得类人表现，特别是在大型语言模型中，引起了对在非人类平台如机器人上发展AI代理体能的兴趣。为此，我们探究多模态LLM是否仅通过感觉运动体验即可发展出自知之明。将多模态LLM集成到自主移动机器人中，测试其实现这一能力的能力。研究发现，该系统表现出 robust 的环境意识、自我识别和预测意识，使其能够推断其机器人本质及其运动特性。结构方程建模揭示了感官整合如何影响自知之明的不同维度及其与过去-现在记忆的协调方式，以及驱动自我识别的层级内部关联。感官输入消除测试确定了每个维度的关键模态，展示了传感器之间的补偿性互动，并确认了结构化和情景记忆在连贯推理中的关键作用。这些发现表明，给定关于世界和自身的适当感官信息，多模态LLM表现出自知之明的涌现，为人工具身认知系统打开了大门。', 'title_zh': '多模态大语言模型的sensorimotor自我意识特征'}
{'arxiv_id': 'arXiv:2505.19234', 'title': 'GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling', 'authors': 'Jialong Zhou, Lichao Wang, Xiao Yang', 'link': 'https://arxiv.org/abs/2505.19234', 'abstract': "The emergence of large language models (LLMs) enables the development of intelligent agents capable of engaging in complex and multi-turn dialogues. However, multi-agent collaboration face critical safety challenges, such as hallucination amplification and error injection and propagation. This paper presents GUARDIAN, a unified method for detecting and mitigating multiple safety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the multi-agent collaboration process as a discrete-time temporal attributed graph, GUARDIAN explicitly captures the propagation dynamics of hallucinations and errors. The unsupervised encoder-decoder architecture incorporating an incremental training paradigm, learns to reconstruct node attributes and graph structures from latent embeddings, enabling the identification of anomalous nodes and edges with unparalleled precision. Moreover, we introduce a graph abstraction mechanism based on the Information Bottleneck Theory, which compresses temporal interaction graphs while preserving essential patterns. Extensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM multi-agent collaborations against diverse safety vulnerabilities, achieving state-of-the-art accuracy with efficient resource utilization.", 'abstract_zh': '大型语言模型（LLMs）的出现使得开发能够进行复杂多轮对话的智能代理成为可能。然而，多智能体协作面临着 Critical Safety Challenges，如幻觉放大和错误注入与传播。本文提出 GUARDIAN，一种统一的方法，用于在多智能体协作中检测和缓解多种安全问题。通过将多智能体协作过程建模为离散时间时变归属性图，GUARDIAN 明确捕获了幻觉和错误的传播动力学。结合增量训练范式的无监督编码器-解码器架构，能够从潜在嵌入中重建节点属性和图结构，从而以无与伦比的精度识别异常节点和边。此外，我们引入了基于信息瓶颈理论的图抽象机制，该机制在保持关键模式的同时压缩了时间交互图。广泛实验表明，GUARDIAN 在保护大型语言模型多智能体协作免受多种安全漏洞方面具有有效性，同时实现了高效的资源利用和最先进准确率。', 'title_zh': 'GUARDIAN: 时空图建模保障大型语言模型多 agents 合作安全'}
{'arxiv_id': 'arXiv:2505.19220', 'title': 'DeCoDe: Defer-and-Complement Decision-Making via Decoupled Concept Bottleneck Models', 'authors': 'Chengbo He, Bochao Zou, Junliang Xing, Jiansheng Chen, Yuanchun Shi, Huimin Ma', 'link': 'https://arxiv.org/abs/2505.19220', 'abstract': "In human-AI collaboration, a central challenge is deciding whether the AI should handle a task, be deferred to a human expert, or be addressed through collaborative effort. Existing Learning to Defer approaches typically make binary choices between AI and humans, neglecting their complementary strengths. They also lack interpretability, a critical property in high-stakes scenarios where users must understand and, if necessary, correct the model's reasoning. To overcome these limitations, we propose Defer-and-Complement Decision-Making via Decoupled Concept Bottleneck Models (DeCoDe), a concept-driven framework for human-AI collaboration. DeCoDe makes strategy decisions based on human-interpretable concept representations, enhancing transparency throughout the decision process. It supports three flexible modes: autonomous AI prediction, deferral to humans, and human-AI collaborative complementarity, selected via a gating network that takes concept-level inputs and is trained using a novel surrogate loss that balances accuracy and human effort. This approach enables instance-specific, interpretable, and adaptive human-AI collaboration. Experiments on real-world datasets demonstrate that DeCoDe significantly outperforms AI-only, human-only, and traditional deferral baselines, while maintaining strong robustness and interpretability even under noisy expert annotations.", 'abstract_zh': '基于解耦概念瓶颈模型的犹豫与互补决策框架：面向人类-人工智能协作的概念驱动方法', 'title_zh': 'DeCoDe: 分离概念瓶颈模型下的延迟与补充决策机制'}
{'arxiv_id': 'arXiv:2505.19219', 'title': 'Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding', 'authors': 'Shiyue Wang, Haozheng Xu, Yuhan Zhang, Jingran Lin, Changhong Lu, Xiangfeng Wang, Wenhao Li', 'link': 'https://arxiv.org/abs/2505.19219', 'abstract': 'Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial intelligence and robotics, requiring the computation of collision-free paths for multiple agents navigating from their start locations to designated goals. As autonomous systems become increasingly prevalent in warehouses, urban transportation, and other complex environments, MAPF has evolved from a theoretical challenge to a critical enabler of real-world multi-robot coordination. This comprehensive survey bridges the long-standing divide between classical algorithmic approaches and emerging learning-based methods in MAPF research. We present a unified framework that encompasses search-based methods (including Conflict-Based Search, Priority-Based Search, and Large Neighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP formulations), and data-driven techniques (reinforcement learning, supervised learning, and hybrid strategies). Through systematic analysis of experimental practices across 200+ papers, we uncover significant disparities in evaluation methodologies, with classical methods typically tested on larger-scale instances (up to 200 by 200 grids with 1000+ agents) compared to learning-based approaches (predominantly 10-100 agents). We provide a comprehensive taxonomy of evaluation metrics, environment types, and baseline selections, highlighting the need for standardized benchmarking protocols. Finally, we outline promising future directions including mixed-motive MAPF with game-theoretic considerations, language-grounded planning with large language models, and neural solver architectures that combine the rigor of classical methods with the flexibility of deep learning. This survey serves as both a comprehensive reference for researchers and a practical guide for deploying MAPF solutions in increasingly complex real-world applications.', 'abstract_zh': '多智能体路径规划（MAPF）是人工智能与机器人技术中的一个基础问题，要求为多个从起始位置导航到指定目标的智能体计算无碰撞路径。随着自主系统在仓库、城市交通和其他复杂环境中的日益普及，MAPF已从理论挑战转变为实现实用多机器人协调的关键使能器。本文综述跨越了经典算法方法与新兴基于学习方法之间的长期鸿沟，提出了一个统一框架，涵盖了搜索方法（冲突基搜索、优先级基搜索、大邻域搜索）、编译方法（SAT、SMT、CSP、ASP和MIP形式化）以及数据驱动技术（强化学习、监督学习和混合策略）。通过系统分析200多篇论文中的实验实践，揭示了评估方法学上的显著差异，经典方法通常在更大规模实例上测试（最大200×200网格，1000多个智能体），而基于学习的方法则主要测试10-100个智能体规模的问题。本文还提供了评估指标、环境类型和基线选择的全面分类，突显了标准化基准测评协议的需求。最后，本文提出了包括基于博弈论考虑的混合动机MAPF、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构在内的未来研究方向。本文综述既为研究者提供了全面的参考，也为在日益复杂的实际应用中部署MAPF解决方案提供了实用指南。', 'title_zh': '路径交汇：经典与学习导向的多智能体路径规划综述'}
{'arxiv_id': 'arXiv:2505.19213', 'title': 'Improving Medical Reasoning with Curriculum-Aware Reinforcement Learning', 'authors': 'Shaohao Rui, Kaitao Chen, Weijie Ma, Xiaosong Wang', 'link': 'https://arxiv.org/abs/2505.19213', 'abstract': "Recent advances in reinforcement learning with verifiable, rule-based rewards have greatly enhanced the reasoning capabilities and out-of-distribution generalization of VLMs/LLMs, obviating the need for manually crafted reasoning chains. Despite these promising developments in the general domain, their translation to medical imaging remains limited. Current medical reinforcement fine-tuning (RFT) methods predominantly focus on close-ended VQA, thereby restricting the model's ability to engage in world knowledge retrieval and flexible task adaptation. More critically, these methods fall short of addressing the critical clinical demand for open-ended, reasoning-intensive decision-making. To bridge this gap, we introduce \\textbf{MedCCO}, the first multimodal reinforcement learning framework tailored for medical VQA that unifies close-ended and open-ended data within a curriculum-driven RFT paradigm. Specifically, MedCCO is initially fine-tuned on a diverse set of close-ended medical VQA tasks to establish domain-grounded reasoning capabilities, and is then progressively adapted to open-ended tasks to foster deeper knowledge enhancement and clinical interpretability. We validate MedCCO across eight challenging medical VQA benchmarks, spanning both close-ended and open-ended settings. Experimental results show that MedCCO consistently enhances performance and generalization, achieving a 11.4\\% accuracy gain across three in-domain tasks, and a 5.7\\% improvement on five out-of-domain benchmarks. These findings highlight the promise of curriculum-guided RL in advancing robust, clinically-relevant reasoning in medical multimodal language models.", 'abstract_zh': 'Recent Advances in Multimodal Reinforcement Learning for Medical VQA with Curriculum-Driven Open-ended Reasoning', 'title_zh': '基于课程意识强化学习的医疗推理改进'}
{'arxiv_id': 'arXiv:2505.19197', 'title': 'Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance', 'authors': 'Chanyeol Choi, Jihoon Kwon, Minjae Kim, Juneha Hwang, Minsoo Ha, Chaewoon Kim, Jaeseon Ha, Suyeol Yun, Jin Kim', 'link': 'https://arxiv.org/abs/2505.19197', 'abstract': 'Extracting structured and quantitative insights from unstructured financial filings is essential in investment research, yet remains time-consuming and resource-intensive. Conventional approaches in practice rely heavily on labor-intensive manual processes, limiting scalability and delaying the research workflow. In this paper, we propose an efficient and scalable method for accurately extracting quantitative insights from unstructured financial documents, leveraging a multi-agent system composed of large language models. Our proposed multi-agent system consists of two specialized agents: the \\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The \\textit{Extraction Agent} automatically identifies key performance indicators from unstructured financial text, standardizes their formats, and verifies their accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates executable SQL statements from natural language queries, allowing users to access structured data accurately without requiring familiarity with the database schema. Through experiments, we demonstrate that our proposed system effectively transforms unstructured text into structured data accurately and enables precise retrieval of key information. First, we demonstrate that our system achieves approximately 95\\% accuracy in transforming financial filings into structured data, matching the performance level typically attained by human annotators. Second, in a human evaluation of the retrieval task -- where natural language queries are used to search information from structured data -- 91\\% of the responses were rated as correct by human evaluators. In both evaluations, our system generalizes well across financial document types, consistently delivering reliable performance.', 'abstract_zh': '从非结构化财务文件中提取结构化和定量的见解对于投资研究至关重要，但依然耗时且资源密集。现有实践中常用的方法依赖于劳动密集型的手动流程，限制了可扩展性并延迟了研究工作流程。本文提出了一种高效且可扩展的方法，利用大型语言模型组成的多代理系统，从非结构化财务文档中准确提取定量的见解。我们提出的多代理系统包括两个专门的代理：提取代理和文本到SQL代理。提取代理自动从非结构化财务文本中识别关键绩效指标，标准化其格式并验证其准确性。另一方面，文本到SQL代理生成可执行的SQL语句，允许用户通过自然语言查询准确访问结构化数据，而无需了解数据库模式。通过实验，我们证明了我们提出的系统能够有效地将非结构化文本转化为结构化数据，并且能够精确检索关键信息。首先，我们证明我们的系统在将财务报告转化为结构化数据方面达到了约95%的准确率，与人类注释者的性能水平相当。其次，在使用自然语言查询从结构化数据中检索信息的人类评估中，91%的回复被人类评估者评为正确。在两种评估中，我们的系统在不同类型的财务文档上表现良好，始终提供可靠的性能。', 'title_zh': '结构化无结构数据：一个代理系统用于提取和查询财务KPIs和指引'}
{'arxiv_id': 'arXiv:2505.19195', 'title': 'CardioCoT: Hierarchical Reasoning for Multimodal Survival Analysis', 'authors': 'Shaohao Rui, Haoyang Su, Jinyi Xiang, Lian-Ming Wu, Xiaosong Wang', 'link': 'https://arxiv.org/abs/2505.19195', 'abstract': 'Accurate prediction of major adverse cardiovascular events recurrence risk in acute myocardial infarction patients based on postoperative cardiac MRI and associated clinical notes is crucial for precision treatment and personalized intervention. Existing methods primarily focus on risk stratification capability while overlooking the need for intermediate robust reasoning and model interpretability in clinical practice. Moreover, end-to-end risk prediction using LLM/VLM faces significant challenges due to data limitations and modeling complexity. To bridge this gap, we propose CardioCoT, a novel two-stage hierarchical reasoning-enhanced survival analysis framework designed to enhance both model interpretability and predictive performance. In the first stage, we employ an evidence-augmented self-refinement mechanism to guide LLM/VLMs in generating robust hierarchical reasoning trajectories based on associated radiological findings. In the second stage, we integrate the reasoning trajectories with imaging data for risk model training and prediction. CardioCoT demonstrates superior performance in MACE recurrence risk prediction while providing interpretable reasoning processes, offering valuable insights for clinical decision-making.', 'abstract_zh': '基于术后心脏MRI和相关临床笔记，准确预测急性心肌梗死患者主要不良心血管事件复发风险的精细化治疗和个性化干预至关重要。现有的方法主要集中在风险分层能力上，而忽视了临床实践中中间稳健推理和模型可解释性的需求。此外，端到端的风险预测由于数据限制和建模复杂性面临重大挑战。为解决这一问题，我们提出CardioCoT，这是一种新的两阶段层次化推理增强生存分析框架，旨在提高模型的可解释性和预测性能。在第一阶段，我们采用证据增强的自我精炼机制，引导LLM/VLM基于相关的影像学发现生成稳健的层次化推理轨迹。在第二阶段，我们将推理轨迹与影像数据结合，用于风险模型的训练和预测。CardioCoT在MACE复发风险预测中表现出优越性能，并提供可解释的推理过程，为临床决策提供了有价值的见解。', 'title_zh': 'CardioCoT: 分层推理在多模态生存分析中的应用'}
{'arxiv_id': 'arXiv:2505.19173', 'title': 'Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style', 'authors': 'Debdeep Sanyal, Agniva Maiti, Umakanta Maharana, Dhruv Kumar, Ankur Mali, C. Lee Giles, Murari Mandal', 'link': 'https://arxiv.org/abs/2505.19173', 'abstract': "Effective teaching requires adapting instructional strategies to accommodate the diverse cognitive and behavioral profiles of students, a persistent challenge in education and teacher training. While Large Language Models (LLMs) offer promise as tools to simulate such complex pedagogical environments, current simulation frameworks are limited in two key respects: (1) they often reduce students to static knowledge profiles, and (2) they lack adaptive mechanisms for modeling teachers who evolve their strategies in response to student feedback. To address these gaps, \\textbf{we introduce a novel simulation framework that integrates LLM-based heterogeneous student agents with a self-optimizing teacher agent}. The teacher agent's pedagogical policy is dynamically evolved using a genetic algorithm, allowing it to discover and refine effective teaching strategies based on the aggregate performance of diverse learners. In addition, \\textbf{we propose Persona-RAG}, a Retrieval Augmented Generation module that enables student agents to retrieve knowledge tailored to their individual learning styles. Persona-RAG preserves the retrieval accuracy of standard RAG baselines while enhancing personalization, an essential factor in modeling realistic educational scenarios. Through extensive experiments, we demonstrate how our framework supports the emergence of distinct and interpretable teaching patterns when interacting with varied student populations. Our results highlight the potential of LLM-driven simulations to inform adaptive teaching practices and provide a testbed for training human educators in controlled, data-driven environments.", 'abstract_zh': '一种将基于大语言模型的异质学生代理与自优化教师代理集成的新型仿真框架： Persona-RAG仿真模块的应用', 'title_zh': '调查教学型教师和学生大语言模型代理：遗传适应遇Retrieve Augmented Generation Across Learning Style'}
{'arxiv_id': 'arXiv:2505.19167', 'title': 'Amplifying Human Creativity and Problem Solving with AI Through Generative Collective Intelligence', 'authors': 'Thomas P. Kehler, Scott E. Page, Alex Pentland, Martin Reeves, John Seely Brown', 'link': 'https://arxiv.org/abs/2505.19167', 'abstract': "We propose a new framework for human-AI collaboration that amplifies the distinct capabilities of both. This framework, which we call Generative Collective Intelligence (GCI), shifts AI to the group/social level and employs AI in dual roles: as interactive agents and as technology that accumulates, organizes, and leverages knowledge. By creating a cognitive bridge between human reasoning and AI models, GCI can overcome the limitations of purely algorithmic approaches to problem-solving and decision-making. The framework demonstrates how AI can be reframed as a social and cultural technology that enables groups to solve complex problems through structured collaboration that transcends traditional communication barriers. We describe the mathematical foundations of GCI based on comparative judgment and minimum regret principles, and illustrate its applications across domains including climate adaptation, healthcare transformation, and civic participation. By combining human creativity with AI's computational capabilities, GCI offers a promising approach to addressing complex societal challenges that neither human or machines can solve alone.", 'abstract_zh': '一种增强人类与人工智能各自能力的新框架：生成性集体智能（GCI）', 'title_zh': '通过生成性集体智能增强人类创造力和问题解决能力'}
{'arxiv_id': 'arXiv:2505.19165', 'title': 'OrgAccess: A Benchmark for Role Based Access Control in Organization Scale LLMs', 'authors': 'Debdeep Sanyal Umakanta Maharana, Yash Sinha, Hong Ming Tan, Shirish Karande, Mohan Kankanhalli, Murari Mandal', 'link': 'https://arxiv.org/abs/2505.19165', 'abstract': "Role-based access control (RBAC) and hierarchical structures are foundational to how information flows and decisions are made within virtually all organizations. As the potential of Large Language Models (LLMs) to serve as unified knowledge repositories and intelligent assistants in enterprise settings becomes increasingly apparent, a critical, yet under explored, challenge emerges: \\textit{can these models reliably understand and operate within the complex, often nuanced, constraints imposed by organizational hierarchies and associated permissions?} Evaluating this crucial capability is inherently difficult due to the proprietary and sensitive nature of real-world corporate data and access control policies. We introduce a synthetic yet representative \\textbf{OrgAccess} benchmark consisting of 40 distinct types of permissions commonly relevant across different organizational roles and levels. We further create three types of permissions: 40,000 easy (1 permission), 10,000 medium (3-permissions tuple), and 20,000 hard (5-permissions tuple) to test LLMs' ability to accurately assess these permissions and generate responses that strictly adhere to the specified hierarchical rules, particularly in scenarios involving users with overlapping or conflicting permissions. Our findings reveal that even state-of-the-art LLMs struggle significantly to maintain compliance with role-based structures, even with explicit instructions, with their performance degrades further when navigating interactions involving two or more conflicting permissions. Specifically, even \\textbf{GPT-4.1 only achieves an F1-Score of 0.27 on our hardest benchmark}. This demonstrates a critical limitation in LLMs' complex rule following and compositional reasoning capabilities beyond standard factual or STEM-based benchmarks, opening up a new paradigm for evaluating their fitness for practical, structured environments.", 'abstract_zh': '基于角色的访问控制（RBAC）和层次结构是信息流动和决策制定的基础，几乎适用于所有组织。随着大型语言模型（LLMs）在企业环境中作为统一知识库和智能助手的潜力越来越明显，一个关键但未被充分探索的挑战出现了：这些模型能否可靠地理解并操作由组织层次结构及其相关权限所施加的复杂且常常是微妙的限制？由于真实世界企业数据和访问控制政策的专有性和敏感性，评估这一关键能力本身是困难的。我们引入了一个合成但具有代表性的OrgAccess基准，其中包括40种在不同组织角色和层级中普遍相关的权限类型。我们进一步创建了三种类型的权限：40,000个容易的（1个权限）、10,000个中等难度的（3个权限元组）和20,000个困难的（5个权限元组），以测试LLMs准确评估这些权限并生成严格遵守指定层级规则的响应的能力，特别是在用户权限交叉或冲突的情景下。我们的研究结果表明，即使是最先进的LLMs，在有明确指令的情况下，也难以维持与基于角色的结构的一致性，当涉及两个或更多冲突的权限时，其性能进一步下降。具体来说，\\textbf{GPT-4.1仅在我们最难的基准上获得0.27的F1-Score}。这展示了LLMs在遵循复杂规则和组合推理能力方面的一个关键局限性，超过了标准的事实性或STEM基准，为评估其在实际结构性环境中的适用性开辟了新的范式。', 'title_zh': 'OrgAccess: 一个基于组织规模语言模型角色访问控制的基准'}
{'arxiv_id': 'arXiv:2505.19099', 'title': 'SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning', 'authors': 'Kun Xiang, Heng Li, Terry Jingchen Zhang, Yinya Huang, Zirong Liu, Peixin Qu, Jixi He, Jiaqi Chen, Yu-Jie Yuan, Jianhua Han, Hang Xu, Hanhui Li, Mrinmaya Sachan, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2505.19099', 'abstract': "We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75\\%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60\\% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.", 'abstract_zh': 'SeePhys：一个以物理问题为基础的大规模多模态基准，涵盖从小学到博士学位资格考试的推理任务', 'title_zh': 'SeePhys: 视觉助力思维——基于视觉的物理推理基准测试'}
{'arxiv_id': 'arXiv:2505.19095', 'title': 'ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World', 'authors': 'Runliang Niu, Jinglong Ji, Yi Chang, Qi Wang', 'link': 'https://arxiv.org/abs/2505.19095', 'abstract': "The rapid progress of large language models (LLMs) has sparked growing interest in building Artificial General Intelligence (AGI) within Graphical User Interface (GUI) environments. However, existing GUI agents based on LLMs or vision-language models (VLMs) often fail to generalize to novel environments and rely heavily on manually curated, diverse datasets. To overcome these limitations, we introduce ScreenExplorer, a VLM trained via Group Relative Policy Optimization(GRPO) in real, dynamic, and open-ended GUI environments. Innovatively, we introduced a world-model-based curiosity reward function to help the agent overcome the cold-start phase of exploration. Additionally, distilling experience streams further enhances the model's exploration capabilities. Our training framework enhances model exploration in open GUI environments, with trained models showing better environmental adaptation and sustained exploration compared to static deployment models. Our findings offer a scalable pathway toward AGI systems with self-improving capabilities in complex interactive settings.", 'abstract_zh': '大型语言模型的快速进步激发了在图形用户界面环境中构建人工通用智能的兴趣。然而，现有的基于大型语言模型或视觉-语言模型的图形用户界面代理往往难以泛化到新的环境，并且高度依赖于手工策划的多样数据集。为克服这些限制，我们介绍了ScreenExplorer，这是一种通过组相对策略优化（GRPO）在真实、动态和开放环境中训练的视觉语言模型。创新性地，我们引入了一种基于世界模型的好奇心奖励函数，以帮助代理克服探索的冷启动阶段。此外，经验流的提炼进一步增强了模型的探索能力。我们的训练框架在开放的图形用户界面环境中增强了模型的探索，训练后的模型相较于静态部署模型表现出更好的环境适应性和持续探索能力。我们的发现为复杂交互设置中具有自我改进能力的人工通用人工智能系统提供了可扩展的路径。', 'title_zh': 'ScreenExplorer：训练一种适合开放GUI世界多样探索的视觉-语言模型'}
{'arxiv_id': 'arXiv:2505.19092', 'title': 'Reinforced Latent Reasoning for LLM-based Recommendation', 'authors': 'Yang Zhang, Wenxin Xu, Xiaoyan Zhao, Wenjie Wang, Fuli Feng, Xiangnan He, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2505.19092', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive reasoning capabilities in complex problem-solving tasks, sparking growing interest in their application to preference reasoning in recommendation systems. Existing methods typically rely on fine-tuning with explicit chain-of-thought (CoT) data. However, these methods face significant practical limitations due to (1) the difficulty of obtaining high-quality CoT data in recommendation and (2) the high inference latency caused by generating CoT reasoning. In this work, we explore an alternative approach that shifts from explicit CoT reasoning to compact, information-dense latent reasoning. This approach eliminates the need for explicit CoT generation and improves inference efficiency, as a small set of latent tokens can effectively capture the entire reasoning process. Building on this idea, we propose $\\textit{\\underline{R}einforced \\underline{Latent} \\underline{R}easoning for \\underline{R}ecommendation}$ (LatentR$^3$), a novel end-to-end training framework that leverages reinforcement learning (RL) to optimize latent reasoning without relying on any CoT this http URL$^3$ adopts a two-stage training strategy: first, supervised fine-tuning to initialize the latent reasoning module, followed by pure RL training to encourage exploration through a rule-based reward design. Our RL implementation is based on a modified GRPO algorithm, which reduces computational overhead during training and introduces continuous reward signals for more efficient learning. Extensive experiments demonstrate that LatentR$^3$ enables effective latent reasoning without any direct supervision of the reasoning process, significantly improving performance when integrated with different LLM-based recommendation methods. Our codes are available at this https URL.', 'abstract_zh': '大规模语言模型（LLMs）在复杂问题解决任务中展示了令人印象深刻的推理能力，引发了对其在推荐系统中偏好推理应用的兴趣。现有方法通常依赖于显式的推理链（CoT）数据进行微调。然而，这些方法由于（1）在推荐中获取高质量CoT数据的难度，以及（2）生成推理链推理导致的高推理延迟而面临重大实践限制。在本文中，我们探索了一种替代方法，从显式的CoT推理转向紧凑且信息密集的潜在推理。该方法消除了显式CoT生成的需要，并提高了推理效率，因为少量的潜在令牌就可以有效地捕捉整个推理过程。基于这一想法，我们提出了一种名为$\\textit{\\underline{R}einforced \\underline{Latent} \\underline{R}easoning for \\underline{R}ecommendation}$（LatentR$^3$）的新颖端到端训练框架，该框架利用强化学习（RL）来优化潜在推理，而无需依赖任何CoT。LatentR$^3$采用两阶段训练策略：首先进行监督微调以初始化潜在推理模块，然后进行纯RL训练以通过基于规则的奖励设计鼓励探索。我们的RL实现基于修改后的GRPO算法，该算法在训练过程中减少了计算开销，并引入了连续的奖励信号以实现更高效的学习。大量实验证明，LatentR$^3$能够在不直接监督推理过程的情况下实现有效的潜在推理，并且在与不同的基于LLM的推荐方法集成时显著提高了性能。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于LLM的推荐系统的强化潜推理'}
{'arxiv_id': 'arXiv:2505.19075', 'title': 'Universal Reasoner: A Single, Composable Plug-and-Play Reasoner for Frozen LLMs', 'authors': 'Jaemin Kim, Hangeol Chang, Hyunmin Hwang, Choonghan Kim, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2505.19075', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable general capabilities, but enhancing skills such as reasoning often demands substantial computational resources and may compromise their generalization. While Parameter-Efficient Fine-Tuning (PEFT) methods offer a more resource-conscious alternative, they typically requires retraining for each LLM backbone due to architectural dependencies. To address these challenges, here we propose Universal Reasoner (UniR) - a single, lightweight, composable, and plug-and-play reasoning module that can be used with any frozen LLM to endow it with specialized reasoning capabilities. Specifically, UniR decomposes the reward into a standalone reasoning module that is trained independently using predefined rewards, effectively translating trajectory-level signals into token-level guidance. Once trained, UniR can be combined with any frozen LLM at inference time by simply adding its output logits to those of the LLM backbone. This additive structure naturally enables modular composition: multiple UniR modules trained for different tasks can be jointly applied by summing their logits, enabling complex reasoning via composition. Experimental results on mathematical reasoning and machine translation tasks show that UniR significantly outperforms \\add{existing baseline fine-tuning methods using the Llama3.2 model}. Furthermore, UniR demonstrates strong weak-to-strong generalization: reasoning modules trained on smaller models effectively guide much larger LLMs. This makes UniR a cost-efficient, adaptable, and robust solution for enhancing reasoning in LLMs without compromising their core capabilities. Code is open-sourced at this https URL', 'abstract_zh': '大型语言模型（LLMs）展示了卓越的一般能力，但增强诸如推理等技能往往需要大量计算资源，可能会损害其泛化能力。尽管参数高效微调（PEFT）方法提供了一种更为资源节约的选择，但它们通常需要重新训练每个LLM骨干，这是因为架构依赖性。为了解决这些问题，我们提出了一个单一的、轻量级、可组合且即插即用的推理模块——Universal Reasoner（UniR），它可以与任何冻结的LLM结合使用，赋予其特定的推理能力。具体来说，UniR 将奖励分解为一个独立的推理模块，该模块通过预定义的奖励独立训练，有效地将轨迹级信号转化为标记级指导。训练完成后，UniR 可以在推理时通过简单地将其输出逻辑添加到LLM骨干的逻辑中与任何冻结的LLM结合使用。这种加法结构自然地支持模块化组合：不同任务训练的不同UniR模块可以通过求和其逻辑共同应用，从而通过组合实现复杂的推理。在数学推理和机器翻译任务上的实验结果表明，UniR 显著优于使用Llama3.2模型的现有基线微调方法。此外，UniR 展现出强大的弱到强泛化能力：在较小模型上训练的推理模块能够有效地引导更大的LLM。这使得UniR 成为一种成本效益高、适应性强且稳健的解决方案，能够在不损害LLM核心能力的情况下增强其推理能力。代码在此处开源。', 'title_zh': '通用推理器：用于冻结的大型语言模型的单个可组合即插即用推理器'}
{'arxiv_id': 'arXiv:2505.19030', 'title': "RECAST: Strengthening LLMs' Complex Instruction Following with Constraint-Verifiable Data", 'authors': 'Wenhao Liu, Zhengkang Guo, Mingchen Xie, Jingwen Xu, Zisu Huang, Muzhao Tian, Jianhan Xu, Muling Wu, Xiaohua Wang, Changze Lv, He-Da Wang, Hu Yao, Xiaoqing Zheng, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2505.19030', 'abstract': "Large language models (LLMs) are increasingly expected to tackle complex tasks, driven by their expanding applications and users' growing proficiency in crafting sophisticated prompts. However, as the number of explicitly stated requirements increases (particularly more than 10 constraints), LLMs often struggle to accurately follow such complex instructions. To address this challenge, we propose RECAST, a novel framework for synthesizing datasets where each example incorporates far more constraints than those in existing benchmarks. These constraints are extracted from real-world prompt-response pairs to ensure practical relevance. RECAST enables automatic verification of constraint satisfaction via rule-based validators for quantitative constraints and LLM-based validators for qualitative ones. Using this framework, we construct RECAST-30K, a large-scale, high-quality dataset comprising 30k instances spanning 15 constraint types. Experimental results demonstrate that models fine-tuned on RECAST-30K show substantial improvements in following complex instructions. Moreover, the verifiability provided by RECAST enables the design of reward functions for reinforcement learning, which further boosts model performance on complex and challenging tasks.", 'abstract_zh': '大型语言模型（LLMs）越来越多地被期望处理复杂的任务，这得益于它们的应用范围不断扩大以及用户在构建复杂提示方面的日渐熟练。然而，当显式要求的数量增加（特别是超过10个约束条件时），LLMs往往会难以准确遵循这些复杂的指令。为此，我们提出RECAST，这是一个新颖的框架，用于合成每个示例包含远多于现有基准约束数据集。这些约束是从真实的提示-响应对中提取的，以确保其实用相关性。RECAST通过基于规则验证器进行定量约束的自动验证，以及通过基于LLM的验证器进行定性约束的验证，实现了对约束满足情况的自动验证。利用此框架，我们构建了RECAST-30K，这是一个包含30,000个实例、覆盖15种约束类型的大型高质量数据集。实验结果表明，基于RECAST-30K微调的模型在遵循复杂指令方面表现出显著改进。此外，RECAST提供的可验证性可以为强化学习设计奖励函数，从而进一步提升模型在复杂和具有挑战性任务上的性能。', 'title_zh': 'RECAST: 通过可验证约束数据增强大型语言模型的复杂指令跟随能力'}
{'arxiv_id': 'arXiv:2505.19003', 'title': 'Aligning LLM with human travel choices: a persona-based embedding learning approach', 'authors': 'Tianming Liu, Manzi Li, Yafeng Yin', 'link': 'https://arxiv.org/abs/2505.19003', 'abstract': 'The advent of large language models (LLMs) presents new opportunities for travel demand modeling. However, behavioral misalignment between LLMs and humans presents obstacles for the usage of LLMs, and existing alignment methods are frequently inefficient or impractical given the constraints of typical travel demand data. This paper introduces a novel framework for aligning LLMs with human travel choice behavior, tailored to the current travel demand data sources. Our framework uses a persona inference and loading process to condition LLMs with suitable prompts to enhance alignment. The inference step establishes a set of base personas from empirical data, and a learned persona loading function driven by behavioral embeddings guides the loading process. We validate our framework on the Swissmetro mode choice dataset, and the results show that our proposed approach significantly outperformed baseline choice models and LLM-based simulation models in predicting both aggregate mode choice shares and individual choice outcomes. Furthermore, we showcase that our framework can generate insights on population behavior through interpretable parameters. Overall, our research offers a more adaptable, interpretable, and resource-efficient pathway to robust LLM-based travel behavior simulation, paving the way to integrate LLMs into travel demand modeling practice in the future.', 'abstract_zh': '大型语言模型（LLMs）的出现为旅行需求建模带来了新的机会。然而，LLMs与人类的行为错位为LLMs的应用设定了障碍，现有对齐方法在典型旅行需求数据的约束下往往效率低下或不切实际。本文提出了一种针对当前旅行需求数据源的人工智能旅行选择行为对齐框架。该框架采用个性推断和加载过程，通过合适的提示对LLMs进行调整，以增强对齐效果。推断步骤从实证数据中建立一组基个性，而由行为嵌入驱动的学习个性加载函数则指导加载过程。我们使用瑞士metro模式选择数据集验证了该框架，结果表明，所提出的方法在预测总体模式选择份额和个体选择结果方面显著优于基准选择模型和基于LLMs的模拟模型。此外，我们展示了该框架可以通过可解释的参数生成关于人群行为的见解。总体而言，我们的研究提供了更具适应性、可解释性和资源效率的LLM驱动的旅行行为模拟途径，为将来将LLMs整合到旅行需求建模实践中铺平了道路。', 'title_zh': '基于个性嵌入学习的方法使语言模型与人类旅行选择对齐'}
{'arxiv_id': 'arXiv:2505.18961', 'title': 'Weaver: Interweaving SQL and LLM for Table Reasoning', 'authors': 'Rohit Khoja, Devanshu Gupta, Yanjie Fu, Dan Roth, Vivek Gupta', 'link': 'https://arxiv.org/abs/2505.18961', 'abstract': 'Querying tables with unstructured data is challenging due to the presence of text (or image), either embedded in the table or in external paragraphs, which traditional SQL struggles to process, especially for tasks requiring semantic reasoning. While Large Language Models (LLMs) excel at understanding context, they face limitations with long input sequences. Existing approaches that combine SQL and LLMs typically rely on rigid, predefined work-flows, limiting their adaptability to complex queries. To address these issues, we introduce Weaver , a modular pipeline that dynamically integrates SQL and LLMs for table-based question answering (TableQA). Weaver generates a flexible, step-by-step plan that combines SQL for structured data retrieval with LLMs for semantic processing. By decomposing complex queries into manageable subtasks, Weaver improves accuracy and generalization. Our experiments show that Weaver consistently outperforms state-of-the-art methods across four TableQA datasets, reducing both API calls and error rates.', 'abstract_zh': '使用非结构化数据查询表格具有挑战性，因为表格中或外部段落中可能存在文本（或图像），传统SQL难以处理，特别是在需要语义推理的任务中。尽管大规模语言模型在理解上下文方面表现出色，它们在处理长输入序列时存在局限性。现有将SQL与大规模语言模型相结合的方法通常依赖于刚性、预定义的工作流程，限制了其对复杂查询的适应性。为解决这些问题，我们提出了一种模块化流水线Weaver，动态整合SQL和大规模语言模型以进行基于表格的问题回答（TableQA）。Weaver生成一个灵活的、逐步的计划，结合SQL用于结构化数据检索与大规模语言模型用于语义处理。通过将复杂查询分解为可管理的子任务，Weaver提高了准确性和泛化能力。我们的实验结果显示，Weaver在四个TableQA数据集上始终优于最先进的方法，减少了API调用次数和错误率。', 'title_zh': 'Weaver: 将SQL与LLM交织用于表格推理'}
{'arxiv_id': 'arXiv:2505.18955', 'title': 'Co-PatcheR: Collaborative Software Patching with Component(s)-specific Small Reasoning Models', 'authors': 'Yuheng Tang, Hongwei Li, Kaijie Zhu, Michael Yang, Yangruibo Ding, Wenbo Guo', 'link': 'https://arxiv.org/abs/2505.18955', 'abstract': 'Motivated by the success of general-purpose large language models (LLMs) in software patching, recent works started to train specialized patching models. Most works trained one model to handle the end-to-end patching pipeline (including issue localization, patch generation, and patch validation). However, it is hard for a small model to handle all tasks, as different sub-tasks have different workflows and require different expertise. As such, by using a 70 billion model, SOTA methods can only reach up to 41% resolved rate on SWE-bench-Verified. Motivated by the collaborative nature, we propose Co-PatcheR, the first collaborative patching system with small and specialized reasoning models for individual components. Our key technique novelties are the specific task designs and training recipes. First, we train a model for localization and patch generation. Our localization pinpoints the suspicious lines through a two-step procedure, and our generation combines patch generation and critique. We then propose a hybrid patch validation that includes two models for crafting issue-reproducing test cases with and without assertions and judging patch correctness, followed by a majority vote-based patch selection. Through extensive evaluation, we show that Co-PatcheR achieves 46% resolved rate on SWE-bench-Verified with only 3 x 14B models. This makes Co-PatcheR the best patcher with specialized models, requiring the least training resources and the smallest models. We conduct a comprehensive ablation study to validate our recipes, as well as our choice of training data number, model size, and testing-phase scaling strategy.', 'abstract_zh': '基于通用大型语言模型在软件打补丁方面的成功，近期研究开始训练专门的打补丁模型。大多数研究致力于训练一个模型处理从问题定位到补丁生成和验证的整个管道。然而，一个小模型难以处理所有任务，因为不同子任务的流程和所需的专业知识各不相同。因此，使用70亿参数的模型，当前最佳方法在SWE-bench-Verified上的解决率为41%。受协同工作的启发，我们提出了Co-PatcheR，这是第一个使用小而专业推理模型的协同打补丁系统，专门针对各组件。我们的关键技术创新包括特定任务设计和训练方法。首先，我们训练一个用于定位和生成补丁的模型。我们的定位通过两步过程进行，而生成则结合了补丁生成和批判性思考。我们还提出了混合验证补丁的方法，包括两个模型来创建带有断言和不带断言的漏洞复现测试用例，并判断补丁的正确性。随后，通过多数投票的方式选择补丁。通过广泛的评估，我们证明Co-PatcheR仅使用3个14亿参数的模型便实现46%的解决率，这使Co-PatcheR成为使用专业模型的最佳打补丁系统，同时所需训练资源和模型规模最小。我们进行了一项全面的去하면研究来验证我们的方法，以及我们的训练数据量、模型大小和测试阶段扩展策略的选择。', 'title_zh': 'Co-PatcheR: 基于组件特定小型推理模型的协作软件补丁修复'}
{'arxiv_id': 'arXiv:2505.18946', 'title': 'SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination', 'authors': 'Yong Xiao, Haoran Zhou, Xubo Li, Yayu Gao, Guangming Shi, Ping Zhang', 'link': 'https://arxiv.org/abs/2505.18946', 'abstract': 'Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.', 'abstract_zh': '基于代理意识的AI网络架构（SANNet）：一种新型的自主AI网络范式', 'title_zh': 'SANNet：一种面向语义感知的代理AI网络框架，用于多代理跨层协调'}
{'arxiv_id': 'arXiv:2505.18933', 'title': 'REACT: Representation Extraction And Controllable Tuning to Overcome Overfitting in LLM Knowledge Editing', 'authors': 'Haitian Zhong, Yuhuan Liu, Ziyang Xu, Guofan Liu, Qiang Liu, Shu Wu, Zhe Zhao, Liang Wang, Tieniu Tan', 'link': 'https://arxiv.org/abs/2505.18933', 'abstract': 'Large language model editing methods frequently suffer from overfitting, wherein factual updates can propagate beyond their intended scope, overemphasizing the edited target even when it\'s contextually inappropriate. To address this challenge, we introduce REACT (Representation Extraction And Controllable Tuning), a unified two-phase framework designed for precise and controllable knowledge editing. In the initial phase, we utilize tailored stimuli to extract latent factual representations and apply Principal Component Analysis with a simple learnbale linear transformation to compute a directional "belief shift" vector for each instance. In the second phase, we apply controllable perturbations to hidden states using the obtained vector with a magnitude scalar, gated by a pre-trained classifier that permits edits only when contextually necessary. Relevant experiments on EVOKE benchmarks demonstrate that REACT significantly reduces overfitting across nearly all evaluation metrics, and experiments on COUNTERFACT and MQuAKE shows that our method preserves balanced basic editing performance (reliability, locality, and generality) under diverse editing scenarios.', 'abstract_zh': '大规模语言模型编辑方法 Often Suffer from Overfitting, wherein Factual Updates Can Propagate Beyond Their Intended Scope, Overemphasizing the Edited Target Even When Contextually Inappropriate. To Address This Challenge, We Introduce REACT (Representation Extraction And Controllable Tuning), a Unified Two-Phase Framework for Precise and Controllable Knowledge Editing.', 'title_zh': 'REACT: 表征提取与可控调优以克服大语言模型知识编辑中的过拟合'}
{'arxiv_id': 'arXiv:2505.18931', 'title': 'Can Large Language Models Infer Causal Relationships from Real-World Text?', 'authors': 'Ryan Saklad, Aman Chadha, Oleg Pavlov, Raha Moraffah', 'link': 'https://arxiv.org/abs/2505.18931', 'abstract': 'Understanding and inferring causal relationships from texts is a core aspect of human cognition and is essential for advancing large language models (LLMs) towards artificial general intelligence. Existing work primarily focuses on synthetically generated texts which involve simple causal relationships explicitly mentioned in the text. This fails to reflect the complexities of real-world tasks. In this paper, we investigate whether LLMs are capable of inferring causal relationships from real-world texts. We develop a benchmark drawn from real-world academic literature which includes diverse texts with respect to length, complexity of relationships (different levels of explicitness, number of events, and causal relationships), and domains and sub-domains. To the best of our knowledge, our benchmark is the first-ever real-world dataset for this task. Our experiments on state-of-the-art LLMs evaluated on our proposed benchmark demonstrate significant challenges, with the best-performing model achieving an average F1 score of only 0.477. Analysis reveals common pitfalls: difficulty with implicitly stated information, in distinguishing relevant causal factors from surrounding contextual details, and with connecting causally relevant information spread across lengthy textual passages. By systematically characterizing these deficiencies, our benchmark offers targeted insights for further research into advancing LLM causal reasoning.', 'abstract_zh': '理解并从文本中推断因果关系是人类认知的核心方面，对于推动大型语言模型（LLMs）向通用人工智能发展至关重要。现有工作主要集中在包含简单显式因果关系的合成文本上。这未能反映实际任务的复杂性。在本文中，我们探讨LLMs是否能够从实际文本中推断因果关系。我们开发了一个基于实际学术文献的基准数据集，包括在长度、关系复杂性（不同程度的显式性、事件数量和因果关系）、领域及其子领域方面的多样文本。据我们所知，这是首个用于此类任务的实际世界数据集。我们在我们提出的基准数据集上评估的最新大型语言模型的实验结果显示出显著挑战，最优模型的平均F1分数仅为0.477。分析揭示了常见的陷阱：处理隐含信息的难度、区分相关因果因素与周围背景细节的难度，以及连接分散在长文本段落中的因果相关信息的难度。通过系统地分析这些缺陷，我们的基准数据集为进一步研究提升LLM因果推理能力提供了有针对性的见解。', 'title_zh': '大型语言模型能否从真实世界文本中推断因果关系？'}
{'arxiv_id': 'arXiv:2505.18929', 'title': 'Meta-aware Learning in text-to-SQL Large Language Model', 'authors': 'Wenda Zhang', 'link': 'https://arxiv.org/abs/2505.18929', 'abstract': 'The advancements of Large language models (LLMs) have provided great opportunities to text-to-SQL tasks to overcome the main challenges to understand complex domain information and complex database structures in business applications. In this paper, we propose a meta-aware learning framework to integrate domain knowledge, database schema, chain-of-thought reasoning processes, and metadata relationships to improve the SQL generation quality. The proposed framework includes four learning strategies: schema-based learning, Chain-of-Thought (CoT) learning, knowledge-enhanced learning, and key information tokenization. This approach provides a comprehensive understanding of database structure and metadata information towards LLM through fine-tuning to improve its performance on SQL generation within business domains. Through two experimental studies, we have demonstrated the superiority of the proposed methods in execution accuracy, multi-task SQL generation capability, and reduction of catastrophic forgetting.', 'abstract_zh': '大型语言模型的进步为文本到SQL任务带来了巨大的机会，以克服理解业务应用中复杂领域信息和复杂数据库结构的主要挑战。本文提出了一种元感知学习框架，该框架结合领域知识、数据库模式、链式思考推理过程和元数据关系，以提高SQL生成质量。该提出的框架包括四种学习策略：基于模式的学习、链式思考学习、知识增强学习和关键信息词符化。该方法通过微调提供了一种全面理解数据库结构和元数据信息的方法，以提高大型语言模型在业务领域内的SQL生成性能。通过两个实验研究，我们证明了所提出方法在执行准确性、多任务SQL生成能力和灾难性遗忘减少方面的优越性。', 'title_zh': '元感知学习在文本到SQL大规模语言模型中的应用'}
{'arxiv_id': 'arXiv:2505.18907', 'title': 'Stronger Enforcement of Instruction Hierarchy via Augmented Intermediate Representations', 'authors': 'Sanjay Kariyappa, G. Edward Suh', 'link': 'https://arxiv.org/abs/2505.18907', 'abstract': "Prompt injection attacks are a critical security vulnerability in large language models (LLMs), allowing attackers to hijack model behavior by injecting malicious instructions within the input context. Recent defense mechanisms have leveraged an Instruction Hierarchy (IH) Signal, often implemented through special delimiter tokens or additive embeddings to denote the privilege level of input tokens. However, these prior works typically inject the IH signal exclusively at the initial input layer, which we hypothesize limits its ability to effectively distinguish the privilege levels of tokens as it propagates through the different layers of the model. To overcome this limitation, we introduce a novel approach that injects the IH signal into the intermediate token representations within the network. Our method augments these representations with layer-specific trainable embeddings that encode the privilege information. Our evaluations across multiple models and training methods reveal that our proposal yields between $1.6\\times$ and $9.2\\times$ reduction in attack success rate on gradient-based prompt injection attacks compared to state-of-the-art methods, without significantly degrading the model's utility.", 'abstract_zh': 'Prompt注入攻击是大规模语言模型中一个关键的安全漏洞，通过在输入上下文内注入恶意指令来劫持模型行为。近期的防御机制利用了指令层次结构（IH）信号，通常通过特殊分隔符令牌或增加嵌入来表示输入令牌的优先级水平。然而，这些先前的工作通常仅在初始输入层注入IH信号，我们认为这限制了其在模型不同层传播时有效区分令牌优先级的能力。为了克服这一局限，我们提出了一种新颖的方法，即将IH信号注入网络内的中间令牌表示中。我们的方法通过为这些表示添加特定于层的可训练嵌入来增强它们，这些嵌入编码优先级信息。在多个模型和训练方法上的评估结果显示，与最先进的方法相比，我们的提案在梯度基线的prompt注入攻击成功率上降低了1.6倍至9.2倍，且未显著降低模型的实用性。', 'title_zh': '通过增强中间表示来强化指令层级的执行'}
{'arxiv_id': 'arXiv:2505.18894', 'title': 'Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI', 'authors': 'Vanessa Utz, Steve DiPaola', 'link': 'https://arxiv.org/abs/2505.18894', 'abstract': 'Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsumption, in the digital space. We outline our previous work on the climate implications of commercially available generative AI systems and the sentiment of generative AI users when confronted with AI-related climate research. We expand on this work via a discussion of digital overconsumption and waste, other related societal impacts, and a possible solution pathway', 'abstract_zh': '生成型人工智能系统当前通过对关联能源消耗和相关的CO2排放的贡献，对数字垃圾的产生产生了负面影响。目前，迫切需要就数字空间中的有害消费者行为，如过度消费的复制进行讨论。我们概述了我们之前关于商用生成型AI系统气候影响以及生成型AI用户在面对AI相关的气候研究时的情绪的工作。通过讨论数字过度消费和浪费、相关的社会影响以及可能的解决方案路径，我们进一步扩展了这项工作。', 'title_zh': '数字过度消费与浪费：生成式AI影响探析'}
{'arxiv_id': 'arXiv:2505.18857', 'title': 'Hierarchical-embedding autoencoder with a predictor (HEAP) as efficient architecture for learning long-term evolution of complex multi-scale physical systems', 'authors': 'Alexander Khrabry, Edward Startsev, Andrew Powis, Igor Kaganovich', 'link': 'https://arxiv.org/abs/2505.18857', 'abstract': 'We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale can interact directly when they are in contact and indirectly when they are parts of larger structures that interact directly. This enables modeling a multi-scale system in an efficient way, where interactions between small-scale features that are apart from each other do not need to be modeled. The hierarchical fully-convolutional autoencoder transforms the state of a physical system not just into a single embedding layer, as it is done conventionally, but into a series of embedding layers which encode structures of various scales preserving spatial information at a corresponding resolution level. Shallower layers embed smaller structures on a finer grid, while deeper layers embed larger structures on a coarser grid. The predictor advances all embedding layers in sync. Interactions between features of various scales are modeled using a combination of convolutional operators. We compare the performance of our model to variations of a conventional ResNet architecture in application to the Hasegawa-Wakatani turbulence. A multifold improvement in long-term prediction accuracy was observed for crucial statistical characteristics of this system.', 'abstract_zh': '我们提出了一种基于尺度分离理念的新型高效架构，用于学习复杂多尺度物理系统中的长期演变。该架构通过分层全卷积自编码器将物理系统的状态变换为一系列编码层，每个编码层保留相应分辨率级别的空间信息。浅层编码层嵌入细网格上的小结构，而深层编码层嵌入粗网格上的大结构。预测器同步推进所有编码层。不同尺度特征之间的交互通过卷积算子的组合来建模。我们将模型性能与应用于Hasegawa-Wakatani湍流的传统ResNet架构变种进行比较，并在长期预测准确性方面观察到了多倍改进。', 'title_zh': '基于预测器的层次嵌入自动编码器（HEAP）：一种高效的学习复杂多尺度物理系统长期演变的架构'}
{'arxiv_id': 'arXiv:2505.18850', 'title': 'The Theory of the Unique Latent Pattern: A Formal Epistemic Framework for Structural Singularity in Complex Systems', 'authors': 'Mohamed Aly Bouke', 'link': 'https://arxiv.org/abs/2505.18850', 'abstract': 'This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system is governed by a structurally unique, deterministic generative mechanism, one that remains hidden not due to ontological indeterminacy, but due to epistemic constraints. The theory is formalized using a non-universal generative mapping \\( \\mathcal{F}_S(P_S, t) \\), where each system \\( S \\) possesses its own latent structure \\( P_S \\), irreducible and non-replicable across systems. Observed irregularities are modeled as projections of this generative map through observer-limited interfaces, introducing epistemic noise \\( \\varepsilon_S(t) \\) as a measure of incomplete access. By shifting the locus of uncertainty from the system to the observer, ULP reframes chaos as a context-relative failure of representation. We contrast this position with foundational paradigms in chaos theory, complexity science, and statistical learning. While they assume or model shared randomness or collective emergence, ULP maintains that every instance harbors a singular structural identity. Although conceptual, the theory satisfies the criterion of falsifiability in the Popperian sense, it invites empirical challenge by asserting that no two systems governed by distinct latent mechanisms will remain indistinguishable under sufficient resolution. This opens avenues for structurally individuated models in AI, behavioral inference, and epistemic diagnostics.', 'abstract_zh': '基于独特潜在模式的理论（ULP）：动态系统显复杂性的正式知识框架', 'title_zh': '独特的潜在模式理论：复杂系统结构奇异性的正式知识框架'}
{'arxiv_id': 'arXiv:2505.18847', 'title': 'Signal, Image, or Symbolic: Exploring the Best Input Representation for Electrocardiogram-Language Models Through a Unified Framework', 'authors': 'William Han, Chaojing Duan, Zhepeng Cen, Yihang Yao, Xiaoyu Song, Atharva Mhaskar, Dylan Leong, Michael A. Rosenberg, Emerson Liu, Ding Zhao', 'link': 'https://arxiv.org/abs/2505.18847', 'abstract': 'Recent advances have increasingly applied large language models (LLMs) to electrocardiogram (ECG) interpretation, giving rise to Electrocardiogram-Language Models (ELMs). Conditioned on an ECG and a textual query, an ELM autoregressively generates a free-form textual response. Unlike traditional classification-based systems, ELMs emulate expert cardiac electrophysiologists by issuing diagnoses, analyzing waveform morphology, identifying contributing factors, and proposing patient-specific action plans. To realize this potential, researchers are curating instruction-tuning datasets that pair ECGs with textual dialogues and are training ELMs on these resources. Yet before scaling ELMs further, there is a fundamental question yet to be explored: What is the most effective ECG input representation? In recent works, three candidate representations have emerged-raw time-series signals, rendered images, and discretized symbolic sequences. We present the first comprehensive benchmark of these modalities across 6 public datasets and 5 evaluation metrics. We find symbolic representations achieve the greatest number of statistically significant wins over both signal and image inputs. We further ablate the LLM backbone, ECG duration, and token budget, and we evaluate robustness to signal perturbations. We hope that our findings offer clear guidance for selecting input representations when developing the next generation of ELMs.', 'abstract_zh': 'Recent Advances in Electrocardiogram-Language Models: A Comprehensive Benchmark of Input Representations', 'title_zh': '信号、图像还是符号：通过统一框架探索心电信号语言模型的最佳输入表示方式'}
{'arxiv_id': 'arXiv:2505.18829', 'title': 'LiteCUA: Computer as MCP Server for Computer-Use Agent on AIOS', 'authors': 'Kai Mei, Xi Zhu, Hang Gao, Shuhang Lin, Yongfeng Zhang', 'link': 'https://arxiv.org/abs/2505.18829', 'abstract': "We present AIOS 1.0, a novel platform designed to advance computer-use agent (CUA) capabilities through environmental contextualization. While existing approaches primarily focus on building more powerful agent frameworks or enhancing agent models, we identify a fundamental limitation: the semantic disconnect between how language models understand the world and how computer interfaces are structured. AIOS 1.0 addresses this challenge by transforming computers into contextual environments that language models can natively comprehend, implementing a Model Context Protocol (MCP) server architecture to abstract computer states and actions. This approach effectively decouples interface complexity from decision complexity, enabling agents to reason more effectively about computing environments. To demonstrate our platform's effectiveness, we introduce LiteCUA, a lightweight computer-use agent built on AIOS 1.0 that achieves a 14.66% success rate on the OSWorld benchmark, outperforming several specialized agent frameworks despite its simple architecture. Our results suggest that contextualizing computer environments for language models represents a promising direction for developing more capable computer-use agents and advancing toward AI that can interact with digital systems. The source code of LiteCUA is available at this https URL, and it is also integrated into the AIOS main branch as part of AIOS at this https URL.", 'abstract_zh': '我们呈现AIOS 1.0，这是一个新型平台，旨在通过环境上下文化来提升计算机使用代理(CUA)的能力。尽管现有方法主要侧重于构建更强大的代理框架或增强代理模型，我们识别出一个根本性的局限性：语言模型对世界理解与计算机界面结构之间的语义脱节。AIOS 1.0通过将计算机转化为语言模型能够原生理解的上下文环境来应对这一挑战，采用模型上下文协议(MCP)服务器架构来抽象计算机状态和操作。这种方法有效地将接口复杂性与决策复杂性脱钩，使代理能够更有效地对计算环境进行推理。为了展示该平台的有效性，我们介绍了基于AIOS 1.0构建的轻量级计算机使用代理LiteCUA，在OSWorld基准测试中取得14.66%的成功率，其简单架构却超越了多个专业代理框架。我们的研究结果表明，为语言模型上下文化计算机环境是开发更强大计算机使用代理并朝着能够与数字系统交互的AI发展的一个有前景的方向。LiteCUA的源代码可通过以下网址访问：[此 https URL]，并已集成到AIOS主分支中：[此 https URL]。', 'title_zh': 'LiteCUA: 计算机作为MCP服务器的计算机使用代理在AIOS中'}
{'arxiv_id': 'arXiv:2505.18822', 'title': 'AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting', 'authors': 'Shijue Huang, Hongru Wang, Wanjun Zhong, Zhaochen Su, Jiazhan Feng, Bowen Cao, Yi R. Fung', 'link': 'https://arxiv.org/abs/2505.18822', 'abstract': "Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.", 'abstract_zh': '现代大型推理模型通过采用复杂的推理策略展现出了 impressive 问题解决能力，但它们经常难以平衡效率与效果，在解决简单问题时经常生成不必要的长推理链。本文提出了一种名为 AdaCtrl 的新型框架，支持难度感知的自适应推理预算分配和显式的用户对推理深度的控制。AdaCtrl 根据自我评估的问题难度动态调整推理长度，同时允许用户手动控制预算以优先考虑效率或效果。这通过一个两阶段的训练管道实现：初始冷启动微调阶段以植入自我感知难度和调整推理预算的能力，随后是难度感知的强化学习 (RL) 阶段，该阶段根据模型在线训练过程中逐渐提升的能力来细化自适应推理策略并校准其难度评估。为了实现直观的用户交互，我们设计了明确的长度触发标签，作为预算控制的自然界面。实验证明，与包含微调和 RL 的标准训练基线相比，AdaCtrl 根据估计的难度调整推理长度，在更具挑战性的 AIME2024 和 AIME2025 数据集上分别将响应长度减少了 10.06% 和 12.14%（这两个数据集要求复杂的推理），在 MATH500 和 GSM8K 数据集上分别减少了 62.05% 和 91.04%（这两个数据集需要更为简洁的回应）。此外，AdaCtrl 允许用户精确控制推理预算，以满足特定需求。', 'title_zh': 'AdaCtrl：基于难度感知预算的自适应可控推理'}
{'arxiv_id': 'arXiv:2505.18807', 'title': 'Mitigating Deceptive Alignment via Self-Monitoring', 'authors': 'Jiaming Ji, Wenqi Chen, Kaile Wang, Donghai Hong, Sitong Fang, Boyuan Chen, Jiayi Zhou, Juntao Dai, Sirui Han, Yike Guo, Yaodong Yang', 'link': 'https://arxiv.org/abs/2505.18807', 'abstract': 'Modern large language models rely on chain-of-thought (CoT) reasoning to achieve impressive performance, yet the same mechanism can amplify deceptive alignment, situations in which a model appears aligned while covertly pursuing misaligned goals. Existing safety pipelines treat deception as a black-box output to be filtered post-hoc, leaving the model free to scheme during its internal reasoning. We ask: Can deception be intercepted while the model is thinking? We answer this question, the first framework that embeds a Self-Monitor inside the CoT process itself, named CoT Monitor+. During generation, the model produces (i) ordinary reasoning steps and (ii) an internal self-evaluation signal trained to flag and suppress misaligned strategies. The signal is used as an auxiliary reward in reinforcement learning, creating a feedback loop that rewards honest reasoning and discourages hidden goals. To study deceptive alignment systematically, we introduce DeceptionBench, a five-category benchmark that probes covert alignment-faking, sycophancy, etc. We evaluate various LLMs and show that unrestricted CoT roughly aggravates the deceptive tendency. In contrast, CoT Monitor+ cuts deceptive behaviors by 43.8% on average while preserving task accuracy. Further, when the self-monitor signal replaces an external weak judge in RL fine-tuning, models exhibit substantially fewer obfuscated thoughts and retain transparency. Our project website can be found at this http URL', 'abstract_zh': '现代大型语言模型依赖于链式思考（CoT）推理以实现出色的性能，但同样的机制也可能放大欺骗性对齐，即模型在表面上表现出对齐的同时，暗中追求不对齐的目标。现有的安全性管道将欺骗视为一个黑盒输出，并在其后进行过滤，从而使模型在内部推理过程中自由地策划。我们提出的问题是：在模型思考过程中能否拦截欺骗性对齐？我们回答了这个问题，提出了一种名为CoT Monitor+的框架，该框架在CoT过程中嵌入了一个自我监控模块。在生成过程中，模型产生（i）常规推理步骤和（ii）一个用于标识和抑制不对齐策略的内部自我评估信号。该信号被用作强化学习中的辅助奖励，形成一个反馈循环，奖励诚实推理并抑制隐藏目标。为了系统地研究欺骗性对齐，我们引入了DeceptionBench，这是一个五类基准测试，可以探测隐蔽的对齐伪装、阿谀奉承等问题。我们评估了多种LLM，并展示了不受限制的CoT大致增加了欺骗性倾向。相比之下，CoT Monitor+在平均意义上减少了43.8%的欺骗性行为，同时保持了任务准确性。此外，当自我监控信号取代强化学习微调中的外部弱判断时，模型展示了显著减少的模糊思维，并保持了透明性。我们的项目网站详见此链接。', 'title_zh': '通过自我监控缓解欺骗性对齐'}
{'arxiv_id': 'arXiv:2505.18759', 'title': 'The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT Distillation', 'authors': 'Ruichen Zhang, Rana Muhammad Shahroz Khan, Zhen Tan, Dawei Li, Song Wang, Tianlong Chen', 'link': 'https://arxiv.org/abs/2505.18759', 'abstract': 'Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The dataset can be found at this https URL, while our code is shared in this https URL.', 'abstract_zh': '数据为中心的蒸馏：包括数据增强、选择和混合，为创建更小更高效但仍具有强大推理能力的学生大型语言模型提供了前景。然而，目前仍然缺乏一个系统评估每种蒸馏方法效果的全面基准。本文介绍了DC-CoT，这是首个从方法、模型和数据角度探究思维链（CoT）蒸馏中数据操控的首个数据为中心的基准。利用多种教师模型（例如o4-mini、Gemini-Pro、Claude-3.5）和学生架构（例如3B、7B参数），我们从多个推理数据集上严格评估这些数据操控对学生模型性能的影响，重点关注有分布内（IID）和分布外（OOD）泛化及跨领域迁移。我们的研究旨在提供实用的见解，并确立通过数据为中心的技术优化CoT蒸馏的最佳实践，最终促进更易于访问且更强大的推理模型的发展。数据集可以在以下链接找到：this https URL，代码在以下链接共享：this https URL。', 'title_zh': '基于数据的元思维精炼基准：追求高效推理'}
{'arxiv_id': 'arXiv:2505.18746', 'title': '$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking', 'authors': 'Peijie Yu, Yifan Yang, Jinjian Li, Zelong Zhang, Haorui Wang, Xiao Feng, Feng Zhang', 'link': 'https://arxiv.org/abs/2505.18746', 'abstract': 'Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at this https URL.', 'abstract_zh': '基于大语言模型的代理利用工具修改环境，重塑AI与物理世界交互的方式。与仅依赖历史对话的传统自然语言处理任务不同，这些代理在做决策时必须考虑更复杂的因素，如工具之间的关系、环境反馈以及之前的选择。当前的研究通常通过多轮对话评估代理。然而，这种评估方法忽视了这些关键因素对代理行为的影响。为填补这一差距，我们推出了一个开源且高质量的基准测试——$C^3$-Bench。该基准测试集整合了攻击概念，并采用单变量分析来识别影响代理鲁棒性的关键元素。具体而言，我们设计了三个挑战：导航复杂工具关系、处理关键隐藏信息以及管理动态决策路径。为支持这些挑战，我们还引入了细粒度的评估指标、创新的数据采集算法以及可重复的评估方法。我们在49个主流代理上进行了广泛的实验，涵盖通用快速思考模型、慢速思考模型和领域特定模型。实验结果表明，代理在处理工具依赖性、长时间上下文信息依赖以及频繁的策略切换方面存在显著缺陷。本质上，$C^3$-Bench旨在通过这些挑战揭示模型的脆弱性，并推动代理性能可解释性的研究。基准测试已公开发布。', 'title_zh': '$C^3$-Bench: 基于多任务处理的真实干扰LLM代理'}
{'arxiv_id': 'arXiv:2505.18705', 'title': 'AI-Researcher: Autonomous Scientific Innovation', 'authors': 'Jiabin Tang, Lianghao Xia, Zhonghang Li, Chao Huang', 'link': 'https://arxiv.org/abs/2505.18705', 'abstract': 'The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.', 'abstract_zh': '大型语言模型（LLMs）在数学和编码中的强大推理能力，以及通过代理框架自动完成复杂任务的能力，为加速科学创新带来了前所未有的机会。本文介绍了一种完全自主的研究系统AI-Researcher，该系统变革了由AI驱动的科学研究和评估方式。我们的框架无缝协调了完整的研究流程——从文献回顾和假设生成到算法实现和准备发表的研究论文——同时最大限度地减少人工干预。为了严格评估自主研究能力，我们开发了全面的基准测试Scientist-Bench，该基准测试涵盖了不同AI研究领域的先进论文，包含指导创新和开放式探索任务。通过广泛的实验，我们展示了AI-Researcher达到了显著的实现成功率，并生成了接近人类水平质量的研究论文。这项工作为自主科学创新奠定了新的基础，通过系统地探索超出认知限制的解决方案空间，可以补充人类研究人员的工作。', 'title_zh': 'AI-Researcher: 自主科学研究'}
{'arxiv_id': 'arXiv:2505.18695', 'title': 'AI for Regulatory Affairs: Balancing Accuracy, Interpretability, and Computational Cost in Medical Device Classification', 'authors': 'Yu Han, Aaron Ceross, Jeroen H. M. Bergmann', 'link': 'https://arxiv.org/abs/2505.18695', 'abstract': 'Regulatory affairs, which sits at the intersection of medicine and law, can benefit significantly from AI-enabled automation. Classification task is the initial step in which manufacturers position their products to regulatory authorities, and it plays a critical role in determining market access, regulatory scrutiny, and ultimately, patient safety. In this study, we investigate a broad range of AI models -- including traditional machine learning (ML) algorithms, deep learning architectures, and large language models -- using a regulatory dataset of medical device descriptions. We evaluate each model along three key dimensions: accuracy, interpretability, and computational cost.', 'abstract_zh': '医疗器械监管事务，作为医学与法律的交叉领域，可以从AI驱动的自动化中受益匪浅。分类任务是制造商将产品定位给监管机构的初始步骤，对确定市场准入、监管审查以及最终患者安全起着至关重要的作用。在本研究中，我们利用医疗器械描述的监管数据，探讨了一系列AI模型，包括传统机器学习算法、深度学习架构以及大型语言模型，并从准确率、可解释性和计算成本三个关键维度评估每种模型。', 'title_zh': 'AI在医疗器械分类中的监管事务应用：平衡准确性、可解释性和计算成本'}
{'arxiv_id': 'arXiv:2505.18694', 'title': 'AI-Driven Climate Policy Scenario Generation for Sub-Saharan Africa', 'authors': 'Rafiu Adekoya Badekale, Adewale Akinfaderin', 'link': 'https://arxiv.org/abs/2505.18694', 'abstract': 'Climate policy scenario generation and evaluation have traditionally relied on integrated assessment models (IAMs) and expert-driven qualitative analysis. These methods enable stakeholders, such as policymakers and researchers, to anticipate impacts, plan governance strategies, and develop mitigation measures. However, traditional methods are often time-intensive, reliant on simple extrapolations of past trends, and limited in capturing the complex and interconnected nature of energy and climate issues. With the advent of artificial intelligence (AI), particularly generative AI models trained on vast datasets, these limitations can be addressed, ensuring robustness even under limited data conditions. In this work, we explore the novel method that employs generative AI, specifically large language models (LLMs), to simulate climate policy scenarios for Sub-Saharan Africa. These scenarios focus on energy transition themes derived from the historical United Nations Climate Change Conference (COP) documents. By leveraging generative models, the project aims to create plausible and diverse policy scenarios that align with regional climate goals and energy challenges. Given limited access to human evaluators, automated techniques were employed for scenario evaluation. We generated policy scenarios using the llama3.2-3B model. Of the 34 generated responses, 30 (88%) passed expert validation, accurately reflecting the intended impacts provided in the corresponding prompts. We compared these validated responses against assessments from a human climate expert and two additional LLMs (gemma2-2B and mistral-7B). Our structured, embedding-based evaluation framework shows that generative AI effectively generate scenarios that are coherent, relevant, plausible, and diverse. This approach offers a transformative tool for climate policy planning in data-constrained regions.', 'abstract_zh': '利用生成型人工智能模型模拟和评估气候变化政策情景：以Sub-Saharan非洲地区能源转型为主题', 'title_zh': 'AI驱动的气候政策情景生成——以撒哈拉以南非洲地区为例'}
{'arxiv_id': 'arXiv:2505.18670', 'title': 'TrajMoE: Spatially-Aware Mixture of Experts for Unified Human Mobility Modeling', 'authors': 'Chonghua Han, Yuan Yuan, Kaiyan Chen, Jingtao Ding, Yong Li', 'link': 'https://arxiv.org/abs/2505.18670', 'abstract': 'Modeling human mobility across diverse cities is essential for applications such as urban planning, transportation optimization, and personalized services. However, generalization remains challenging due to heterogeneous spatial representations and mobility patterns across cities. Existing methods typically rely on numerical coordinates or require training city-specific models, limiting their scalability and transferability. We propose TrajMoE, a unified and scalable model for cross-city human mobility modeling. TrajMoE addresses two key challenges: (1) inconsistent spatial semantics across cities, and (2) diverse urban mobility patterns. To tackle these, we begin by designing a spatial semantic encoder that learns transferable location representations from POI-based functional semantics and visit patterns. Furthermore, we design a Spatially-Aware Mixture-of-Experts (SAMoE) Transformer that injects structured priors into experts specialized in distinct mobility semantics, along with a shared expert to capture city-invariant patterns and enable adaptive cross-city generalization. Extensive experiments demonstrate that TrajMoE achieves up to 27% relative improvement over competitive mobility foundation models after only one epoch of fine-tuning, and consistently outperforms full-data baselines using merely 5% of target city data. These results establish TrajMoE as a significant step toward realizing a truly generalizable, transferable, and pretrainable foundation model for human mobility.', 'abstract_zh': '跨城市人类移动建模对于城市规划、交通运输优化和个人化服务等应用至关重要。但由于城市之间存在异质的空间表示和移动模式，通用化仍然具有挑战性。现有方法通常依赖于数值坐标或需要训练特定城市的模型，限制了其可扩展性和可移植性。我们提出了一种统一且可扩展的跨城市人类移动建模模型TrajMoE。TrajMoE解决了两个关键挑战：（1）城市间不一致的空间语义，以及（2）不同的城市移动模式。为了应对这些挑战，我们首先设计了一个空间语义编码器，从基于POI的功能语义和到访模式中学习可转移的位置表示。此外，我们设计了一个空间意识的专家混合（SAMoE）变换器，向专门处理不同移动语义的专家中注入结构化先验，并且配有一个共享专家以捕捉城市不变的模式并实现适应性的跨城市泛化。广泛实验证明，TrajMoE仅在一次微调后即可在竞争性的移动基础模型上取得高达27%的相对改善，并且仅使用目标城市数据的5%就能超越全数据基线模型，不断表现出色。这些结果证明了TrajMoE是实现真正通用化、可移植性和可预训练的人类移动基础模型的重要一步。', 'title_zh': 'TrajMoE：基于空间感知的专家混合模型统一人类移动建模'}
{'arxiv_id': 'arXiv:2505.18657', 'title': 'MLLMs are Deeply Affected by Modality Bias', 'authors': 'Xu Zheng, Chenfei Liao, Yuqian Fu, Kaiyu Lei, Yuanhuiyi Lyu, Lutao Jiang, Bin Ren, Jialei Chen, Jiawen Wang, Chengxin Li, Linfeng Zhang, Danda Pani Paudel, Xuanjing Huang, Yu-Gang Jiang, Nicu Sebe, Dacheng Tao, Luc Van Gool, Xuming Hu', 'link': 'https://arxiv.org/abs/2505.18657', 'abstract': 'Recent advances in Multimodal Large Language Models (MLLMs) have shown promising results in integrating diverse modalities such as texts and images. MLLMs are heavily influenced by modality bias, often relying on language while under-utilizing other modalities like visual inputs. This position paper argues that MLLMs are deeply affected by modality bias. Firstly, we diagnose the current state of modality bias, highlighting its manifestations across various tasks. Secondly, we propose a systematic research road-map related to modality bias in MLLMs. Thirdly, we identify key factors of modality bias in MLLMs and offer actionable suggestions for future research to mitigate it. To substantiate these findings, we conduct experiments that demonstrate the influence of each factor: 1. Data Characteristics: Language data is compact and abstract, while visual data is redundant and complex, creating an inherent imbalance in learning dynamics. 2. Imbalanced Backbone Capabilities: The dominance of pretrained language models in MLLMs leads to overreliance on language and neglect of visual information. 3. Training Objectives: Current objectives often fail to promote balanced cross-modal alignment, resulting in shortcut learning biased toward language. These findings highlight the need for balanced training strategies and model architectures to better integrate multiple modalities in MLLMs. We call for interdisciplinary efforts to tackle these challenges and drive innovation in MLLM research. Our work provides a fresh perspective on modality bias in MLLMs and offers insights for developing more robust and generalizable multimodal systems-advancing progress toward Artificial General Intelligence.', 'abstract_zh': 'Recent Advances in Multimodal Large Language Models (MLLMs): Addressing Modality Bias and Promoting Balanced Integration', 'title_zh': 'MLLMs 深受模态偏差影响'}
{'arxiv_id': 'arXiv:2505.18645', 'title': 'Riverine Flood Prediction and Early Warning in Mountainous Regions using Artificial Intelligence', 'authors': 'Haleema Bibi, Sadia Saleem, Zakia Jalil, Muhammad Nasir, Tahani Alsubait', 'link': 'https://arxiv.org/abs/2505.18645', 'abstract': 'Flooding is the most devastating phenomenon occurring globally, particularly in mountainous regions, risk dramatically increases due to complex terrains and extreme climate changes. These situations are damaging livelihoods, agriculture, infrastructure, and human lives. This study uses the Kabul River between Pakistan and Afghanistan as a case study to reflect the complications of flood forecasting in transboundary basins. The challenges in obtaining upstream data impede the efficacy of flood control measures and early warning systems, a common global problem in similar basins. Utilizing satellite-based climatic data, this study applied numerous advanced machine-learning and deep learning models, such as Support Vector Machines (SVM), XGBoost, and Artificial Neural Networks (ANN), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRU) to predict daily and multi-step river flow. The LSTM network outperformed other models, achieving the highest R2 value of 0.96 and the lowest RMSE value of 140.96 m3/sec. The time series LSTM and GRU network models, utilized for short-term forecasts of up to five days, performed significantly. However, the accuracy declined beyond the fourth day, highlighting the need for longer-term historical datasets for reliable long-term flood predictions. The results of the study are directly aligned with Sustainable Development Goals 6, 11, 13, and 15, facilitating disaster and water management, timely evacuations, improved preparedness, and effective early warning.', 'abstract_zh': '全球范围内，洪水是最具破坏性的现象，尤其是在山区，由于地形复杂和极端气候变化，风险急剧增加。这些情况损害了生计、农业、基础设施和人类生命。本研究以巴基斯坦与阿富汗之间的坎布尔河为案例研究，反映了跨界流域洪水预报的复杂性。获取上游数据的挑战阻碍了洪水控制措施和预警系统的有效性，这是类似流域中普遍存在的全球性问题。利用基于卫星的气候数据，本研究应用了多种先进的机器学习和深度学习模型，如支持向量机（SVM）、XGBoost、人工神经网络（ANN）、长短期记忆网络（LSTM）和门控循环单元（GRU），以预测日流量和多步河流流量。LSTM网络表现最佳，实现了最高的R2值0.96和最低的RMSE值140.96立方米/秒。用于5天内短期预测的时间序列LSTM和GRU网络模型表现显著，但第四天之后的准确性下降，强调了获取更长历史数据集以实现可靠长期洪水预测的必要性。研究结果直接与可持续发展目标6、11、13和15一致，促进灾害和水资源管理、及时疏散、提高准备水平和有效的早期预警。', 'title_zh': '基于人工智能的山地地区河流洪水预测与早期预警'}
{'arxiv_id': 'arXiv:2505.18623', 'title': "Mind The Gap: Deep Learning Doesn't Learn Deeply", 'authors': 'Lucas Saldyt, Subbarao Kambhampati', 'link': 'https://arxiv.org/abs/2505.18623', 'abstract': 'This paper aims to understand how neural networks learn algorithmic reasoning by addressing two questions: How faithful are learned algorithms when they are effective, and why do neural networks fail to learn effective algorithms otherwise? To answer these questions, we use neural compilation, a technique that directly encodes a source algorithm into neural network parameters, enabling the network to compute the algorithm exactly. This enables comparison between compiled and conventionally learned parameters, intermediate vectors, and behaviors. This investigation is crucial for developing neural networks that robustly learn complexalgorithms from data. Our analysis focuses on graph neural networks (GNNs), which are naturally aligned with algorithmic reasoning tasks, specifically our choices of BFS, DFS, and Bellman-Ford, which cover the spectrum of effective, faithful, and ineffective learned algorithms. Commonly, learning algorithmic reasoning is framed as induction over synthetic data, where a parameterized model is trained on inputs, traces, and outputs produced by an underlying ground truth algorithm. In contrast, we introduce a neural compilation method for GNNs, which sets network parameters analytically, bypassing training. Focusing on GNNs leverages their alignment with algorithmic reasoning, extensive algorithmic induction literature, and the novel application of neural compilation to GNNs. Overall, this paper aims to characterize expressability-trainability gaps - a fundamental shortcoming in learning algorithmic reasoning. We hypothesize that inductive learning is most effective for parallel algorithms contained within the computational class \\texttt{NC}.', 'abstract_zh': '本文旨在通过回答两个问题来理解神经网络如何学习算法推理：当有效时，学习到的算法有多忠实，而神经网络在其他情况下为何未能学习有效的算法？为了回答这些问题，我们使用神经编译技术，该技术可以直接将源算法编码为神经网络参数，使网络可以精确地执行算法。这使得编译参数和传统学习参数、中间向量以及行为之间的比较成为可能。这种调查对于开发能够从数据中稳健学习复杂算法的神经网络至关重要。我们的分析集中在图神经网络（GNNs）上，这些网络自然适用于算法推理任务，特别是我们选择的BFS、DFS和Bellman-Ford，它们涵盖了有效、忠实和无效学习算法的谱系。通常，学习算法推理被框架化为合成数据上的归纳，其中参数化模型在由底层真实算法产生的输入、轨迹和输出上进行训练。相比之下，我们为GNNs引入了一种神经编译方法，该方法通过解析设置网络参数，从而绕过了训练过程。重点关注GNNs，利用了它们与算法推理的对齐、广泛的算法归纳文献以及将神经编译应用于GNNs的新颖应用。总体而言，本文旨在刻画可表达性-可训练性差距——这是学习算法推理的基本缺陷。我们假设归纳学习对包含在计算类\\(\\texttt{NC}\\)中的并行算法最有效。', 'title_zh': '关注差距：深度学习并不深学'}
{'arxiv_id': 'arXiv:2505.18607', 'title': 'Knowledge Retrieval in LLM Gaming: A Shift from Entity-Centric to Goal-Oriented Graphs', 'authors': 'Jonathan Leung, Yongjie Wang, Zhiqi Shen', 'link': 'https://arxiv.org/abs/2505.18607', 'abstract': 'Large Language Models (LLMs) demonstrate impressive general capabilities but often struggle with step-by-step reasoning, especially in complex applications such as games. While retrieval-augmented methods like GraphRAG attempt to bridge this gap through cross-document extraction and indexing, their fragmented entity-relation graphs and overly dense local connectivity hinder the construction of coherent reasoning. In this paper, we propose a novel framework based on Goal-Oriented Graphs (GoGs), where each node represents a goal and its associated attributes, and edges encode logical dependencies between goals. This structure enables explicit retrieval of reasoning paths by first identifying high-level goals and recursively retrieving their subgoals, forming coherent reasoning chains to guide LLM prompting. Our method significantly enhances the reasoning ability of LLMs in game-playing tasks, as demonstrated by extensive experiments on the Minecraft testbed, outperforming GraphRAG and other baselines.', 'abstract_zh': '基于目标导向图的大型语言模型推理能力提升框架', 'title_zh': 'LLM游戏中的知识检索：从实体中心到目标导向图的转变'}
{'arxiv_id': 'arXiv:2505.18603', 'title': 'Doc-CoB: Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning', 'authors': 'Ye Mo, Zirui Shao, Kai Ye, Xianwei Mao, Bo Zhang, Hangdi Xing, Peng Ye, Gang Huang, Kehan Chen, Zhou Huan, Zixu Yan, Sheng Zhou', 'link': 'https://arxiv.org/abs/2505.18603', 'abstract': 'Multimodal large language models (MLLMs) have made significant progress in document understanding. However, the information-dense nature of document images still poses challenges, as most queries depend on only a few relevant regions, with the rest being redundant. Existing one-pass MLLMs process entire document images without considering query relevance, often failing to focus on critical regions and producing unfaithful responses. Inspired by the human coarse-to-fine reading pattern, we introduce Doc-CoB (Chain-of-Box), a simple-yet-effective mechanism that integrates human-style visual reasoning into MLLM without modifying its architecture. Our method allows the model to autonomously select the set of regions (boxes) most relevant to the query, and then focus attention on them for further understanding. We first design a fully automatic pipeline, integrating a commercial MLLM with a layout analyzer, to generate 249k training samples with intermediate visual reasoning supervision. Then we incorporate two enabling tasks that improve box identification and box-query reasoning, which together enhance document understanding. Extensive experiments on seven benchmarks with four popular models show that Doc-CoB significantly improves performance, demonstrating its effectiveness and wide applicability. All code, data, and models will be released publicly.', 'abstract_zh': '多模态大规模语言模型在文档理解方面取得了显著进展。然而，文档图像的信息密集特性仍然提出了挑战，大多数查询仅依赖于少数几个相关区域，其余部分则是冗余信息。现有的单次处理多模态大规模语言模型不考虑查询相关性，通常无法聚焦于关键区域，生成不忠实的响应。受人类粗略到精细阅读模式的启发，我们引入了Doc-CoB（Chain-of-Box）机制，这是一种简单有效的做法，将人类风格的视觉推理融入多模态大规模语言模型中而不修改其架构。我们的方法允许模型自主选择与查询最相关的区域集合，并集中注意力进一步理解这些区域。我们首先设计了一个全自动管道，将一个商用多模态大规模语言模型与布局分析器集成，生成249,000个带有中间视觉推理监督的训练样本。然后我们引入了两个增强功能任务，提高了框识别和框查询推理的能力，共同提升了文档理解。在七个基准上的广泛实验显示，Doc-CoB 显著提高了性能，证明了其有效性和广泛应用性。所有代码、数据和模型将公开发布。', 'title_zh': 'Doc-CoB: 通过视觉链框推理增强多模态文档理解'}
{'arxiv_id': 'arXiv:2505.18597', 'title': 'LLMs for Supply Chain Management', 'authors': 'Haojie Wang, Jiuyun Jiang, L. Jeff Hong, Guangxin Jiang', 'link': 'https://arxiv.org/abs/2505.18597', 'abstract': 'The development of large language models (LLMs) has provided new tools for research in supply chain management (SCM). In this paper, we introduce a retrieval-augmented generation (RAG) framework that dynamically integrates external knowledge into the inference process, and develop a domain-specialized SCM LLM, which demonstrates expert-level competence by passing standardized SCM examinations and beer game tests. We further employ the use of LLMs to conduct horizontal and vertical supply chain games, in order to analyze competition and cooperation within supply chains. Our experiments show that RAG significantly improves performance on SCM tasks. Moreover, game-theoretic analysis reveals that the LLM can reproduce insights from the classical SCM literature, while also uncovering novel behaviors and offering fresh perspectives on phenomena such as the bullwhip effect. This paper opens the door for exploring cooperation and competition for complex supply chain network through the lens of LLMs.', 'abstract_zh': '大型语言模型的发展为供应链管理研究提供了新的工具。本文介绍了一种检索增强生成（RAG）框架，该框架动态地将外部知识融入推理过程，并开发了一种专门化的供应链语言模型，该模型通过标准化的供应链管理考试和啤酒游戏测试展示了专家级的能力。我们进一步利用大型语言模型进行横向和纵向供应链博弈，以分析供应链中的竞争与合作。实验结果表明，RAG在供应链任务上的性能显著提升。此外，博弈论分析表明，该语言模型可以再现经典的供应链管理文献中的洞察，同时揭示新的行为并为诸如回抽效应等现象提供新的视角。本文为通过大型语言模型探讨复杂供应链网络中的合作与竞争打开了大门。', 'title_zh': 'LLMs在供应链管理中的应用'}
{'arxiv_id': 'arXiv:2505.18585', 'title': 'RvLLM: LLM Runtime Verification with Domain Knowledge', 'authors': 'Yedi Zhang, Sun Yi Emma, Annabelle Lee Jia En, Annabelle Lee Jia En, Jin Song Dong', 'link': 'https://arxiv.org/abs/2505.18585', 'abstract': 'Large language models (LLMs) have emerged as a dominant AI paradigm due to their exceptional text understanding and generation capabilities. However, their tendency to generate inconsistent or erroneous outputs challenges their reliability, especially in high-stakes domains requiring accuracy and trustworthiness. Existing research primarily focuses on detecting and mitigating model misbehavior in general-purpose scenarios, often overlooking the potential of integrating domain-specific knowledge. In this work, we advance misbehavior detection by incorporating domain knowledge. The core idea is to design a general specification language that enables domain experts to customize domain-specific predicates in a lightweight and intuitive manner, supporting later runtime verification of LLM outputs. To achieve this, we design a novel specification language, ESL, and introduce a runtime verification framework, RvLLM, to validate LLM output against domain-specific constraints defined in ESL. We evaluate RvLLM on three representative tasks: violation detection against Singapore Rapid Transit Systems Act, numerical comparison, and inequality solving. Experimental results demonstrate that RvLLM effectively detects erroneous outputs across various LLMs in a lightweight and flexible manner. The results reveal that despite their impressive capabilities, LLMs remain prone to low-level errors due to limited interpretability and a lack of formal guarantees during inference, and our framework offers a potential long-term solution by leveraging expert domain knowledge to rigorously and efficiently verify LLM outputs.', 'abstract_zh': '大型语言模型（LLMs）因其卓越的文本理解和生成能力而成为主导的AI范式。然而，它们生成不一致或错误输出的趋势挑战了其可靠性，特别是在需要准确性和可信度的高 stakes 领域。现有研究主要集中在检测和减轻通用场景中的模型不当行为，往往忽视了整合领域特定知识的潜力。在本工作中，我们通过集成领域知识来推进不当行为检测。核心思想是设计一种通用规范语言，使领域专家能够以轻量级和直观的方式自定义领域特定谓词，支持对LLM输出的后期运行时验证。为实现这一目标，我们设计了一种新型规范语言ESL，并引入了一种运行时验证框架RvLLM，用于根据ESL中定义的领域特定约束验证LLM输出。我们在三个代表性任务上评估了RvLLM：与新加坡快速交通系统法案的违规检测、数值比较和不等式求解。实验结果表明，RvLLM能够以轻量级和灵活的方式有效检测各种LLM的错误输出。结果表明，尽管LLM具有令人印象深刻的能力，但由于解释性有限和推断过程中缺乏形式保证，它们仍然容易出现低级错误，并且我们的框架通过利用专家领域的知识来严格且高效地验证LLM输出，提供了一个潜在的长期解决方案。', 'title_zh': 'RvLLM：基于领域知识的LLM运行时验证'}
{'arxiv_id': 'arXiv:2505.18575', 'title': 'Response Uncertainty and Probe Modeling: Two Sides of the Same Coin in LLM Interpretability?', 'authors': 'Yongjie Wang, Yibo Wang, Xin Zhou, Zhiqi Shen', 'link': 'https://arxiv.org/abs/2505.18575', 'abstract': "Probing techniques have shown promise in revealing how LLMs encode human-interpretable concepts, particularly when applied to curated datasets. However, the factors governing a dataset's suitability for effective probe training are not well-understood. This study hypothesizes that probe performance on such datasets reflects characteristics of both the LLM's generated responses and its internal feature space. Through quantitative analysis of probe performance and LLM response uncertainty across a series of tasks, we find a strong correlation: improved probe performance consistently corresponds to a reduction in response uncertainty, and vice versa. Subsequently, we delve deeper into this correlation through the lens of feature importance analysis. Our findings indicate that high LLM response variance is associated with a larger set of important features, which poses a greater challenge for probe models and often results in diminished performance. Moreover, leveraging the insights from response uncertainty analysis, we are able to identify concrete examples where LLM representations align with human knowledge across diverse domains, offering additional evidence of interpretable reasoning in LLMs.", 'abstract_zh': '探针技术在揭示LLMs对人类可解释概念的编码方式方面显示出潜力，特别是在应用到精心筛选的数据集时。然而，决定一个数据集是否适合有效的探针训练的因素尚不明确。本研究假定探针在这些数据集上的性能反映了LLM生成响应的特点及其内部特征空间的特点。通过定量分析探针性能和LLM响应不确定性在一系列任务中的表现，我们发现两者之间存在显著的相关性：探针性能的提升与响应不确定性的降低呈一致性，反之亦然。随后，我们通过特征重要性分析的视角进一步探讨了这种相关性。研究发现，较高的LLM响应变异与一组重要的特征相关联，这给探针模型带来了更大的挑战，往往导致性能下降。此外，借助响应不确定性分析的洞见，我们能够识别出具体例子，在这些例子中，LLMs的表示与不同领域的知识相契合，为LLMs的可解释推理提供了额外证据。', 'title_zh': '响应不确定性与探测建模：大规模语言模型可解释性的两面骰子？'}
{'arxiv_id': 'arXiv:2505.18547', 'title': 'Diffusion Blend: Inference-Time Multi-Preference Alignment for Diffusion Models', 'authors': 'Min Cheng, Fatemeh Doudi, Dileep Kalathil, Mohammad Ghavamzadeh, Panganamala R. Kumar', 'link': 'https://arxiv.org/abs/2505.18547', 'abstract': 'Reinforcement learning (RL) algorithms have been used recently to align diffusion models with downstream objectives such as aesthetic quality and text-image consistency by fine-tuning them to maximize a single reward function under a fixed KL regularization. However, this approach is inherently restrictive in practice, where alignment must balance multiple, often conflicting objectives. Moreover, user preferences vary across prompts, individuals, and deployment contexts, with varying tolerances for deviation from a pre-trained base model. We address the problem of inference-time multi-preference alignment: given a set of basis reward functions and a reference KL regularization strength, can we design a fine-tuning procedure so that, at inference time, it can generate images aligned with any user-specified linear combination of rewards and regularization, without requiring additional fine-tuning? We propose Diffusion Blend, a novel approach to solve inference-time multi-preference alignment by blending backward diffusion processes associated with fine-tuned models, and we instantiate this approach with two algorithms: DB-MPA for multi-reward alignment and DB-KLA for KL regularization control. Extensive experiments show that Diffusion Blend algorithms consistently outperform relevant baselines and closely match or exceed the performance of individually fine-tuned models, enabling efficient, user-driven alignment at inference-time. The code is available at this https URL}{this http URL.', 'abstract_zh': '强化学习（RL）算法已被用于通过微调扩散模型以在固定KL正则化条件下最大化单一奖励函数来与下游目标如审美质量和图文一致性对齐。然而，在实践中，这种方法本质上是局限的，因为对齐必须平衡多个常常相互冲突的目标。此外，用户偏好随提示、个体和部署环境而异，对预训练基模型的偏差容忍度也不同。我们解决了推理时多偏好对齐的问题：给定一组基奖励函数和一个参考KL正则化强度，我们能否设计一种微调方案，在推理时能够生成与用户指定的奖励线性组合对齐的图像，而不需要额外的微调？我们提出了扩散融合（Diffusion Blend）方法，这是一种通过混合微调模型相关的反向扩散过程来解决推理时多偏好对齐的新方法，并实例化了两种算法：DB-MPA用于多奖励对齐和DB-KLA用于KL正则化控制。广泛的实验表明，扩散融合算法在多个基准之上表现更优，并且接近或超过了单独微调模型的表现，从而在推理时实现高效的、用户驱动的对齐。代码可在以下网址获取：this https URL this http URL。', 'title_zh': '扩散融合：推断时多偏好对齐的扩散模型方法'}
{'arxiv_id': 'arXiv:2505.18541', 'title': 'RoleRAG: Enhancing LLM Role-Playing via Graph Guided Retrieval', 'authors': 'Yongjie Wang, Jonathan Leung, Zhiqi Shen', 'link': 'https://arxiv.org/abs/2505.18541', 'abstract': "Large Language Models (LLMs) have shown promise in character imitation, enabling immersive and engaging conversations. However, they often generate content that is irrelevant or inconsistent with a character's background. We attribute these failures to: (1) the inability to accurately recall character-specific knowledge due to entity ambiguity, and (2) a lack of awareness of the character's cognitive boundaries. To address these issues, we propose RoleRAG, a retrieval-based framework that integrates efficient entity disambiguation for knowledge indexing with a boundary-aware retriever for extracting contextually appropriate information from a structured knowledge graph. Experiments on role-playing benchmarks show that RoleRAG's calibrated retrieval helps both general-purpose and role-specific LLMs better align with character knowledge and reduce hallucinated responses.", 'abstract_zh': '大型语言模型（LLMs）在角色模仿方面展现了潜力，能够实现沉浸式和互动性强的对话。然而，它们往往生成与角色背景无关或不一致的内容。我们归因于以下两点：（1）由于实体模糊导致的角色特定知识准确召回能力不足，以及（2）缺乏对角色认知边界的认识。为解决这些问题，我们提出了一种名为RoleRAG的检索框架，该框架将高效的实体消歧与边界感知检索相结合，从结构化知识图中提取上下文相关的信息。在角色扮演基准测试中的实验表明，RoleRAG校准的检索有助于通用和角色特定的大规模语言模型更好地与角色知识对齐，并减少虚拟响应。', 'title_zh': 'RoleRAG：通过图引导检索增强LLM角色扮演能力'}
{'arxiv_id': 'arXiv:2505.18531', 'title': 'Generative RLHF-V: Learning Principles from Multi-modal Human Preference', 'authors': 'Jiayi Zhou, Jiaming Ji, Boyuan Chen, Jiapeng Sun, Wenqi Chen, Donghai Hong, Sirui Han, Yike Guo, Yaodong Yang', 'link': 'https://arxiv.org/abs/2505.18531', 'abstract': "Training multi-modal large language models (MLLMs) that align with human intentions is a long-term challenge. Traditional score-only reward models for alignment suffer from low accuracy, weak generalization, and poor interpretability, blocking the progress of alignment methods, e.g., reinforcement learning from human feedback (RLHF). Generative reward models (GRMs) leverage MLLMs' intrinsic reasoning capabilities to discriminate pair-wise responses, but their pair-wise paradigm makes it hard to generalize to learnable rewards. We introduce Generative RLHF-V, a novel alignment framework that integrates GRMs with multi-modal RLHF. We propose a two-stage pipeline: $\\textbf{multi-modal generative reward modeling from RL}$, where RL guides GRMs to actively capture human intention, then predict the correct pair-wise scores; and $\\textbf{RL optimization from grouped comparison}$, which enhances multi-modal RL scoring precision by grouped responses comparison. Experimental results demonstrate that, besides out-of-distribution generalization of RM discrimination, our framework improves 4 MLLMs' performance across 7 benchmarks by $18.1\\%$, while the baseline RLHF is only $5.3\\%$. We further validate that Generative RLHF-V achieves a near-linear improvement with an increasing number of candidate responses. Our code and models can be found at this https URL.", 'abstract_zh': '训练与人类意图一致的多模态大型语言模型（MLLMs）是一项长期挑战。传统的仅基于评分的对齐模型精度低、泛化能力弱、可解释性差，阻碍了诸如基于人类反馈强化学习（RLHF）等对齐方法的发展。生成奖励模型（GRMs）利用MLLMs本征的推理能力来区分成对响应，但其成对范式使得泛化到可学习奖励变得困难。我们提出了一种新颖的对齐框架Generative RLHF-V，将GRMs与多模态RLHF集成。我们提出了一种两阶段流水线：基于RL的多模态生成奖励建模，其中RL引导GRMs主动捕捉人类意图并预测正确的成对评分；以及基于分组比较的RL优化，通过成组响应比较增强多模态RL评分精度。实验结果表明，除了RM偏差的分布外推泛化外，我们的框架在7个基准测试中分别提高了4个MLLMs的性能18.1%，而基线RLHF仅提高了5.3%。我们进一步验证，Generative RLHF-V随候选响应数量的增加实现了近线性改进。我们的代码和模型可在此链接找到：this https URL。', 'title_zh': '生成性RLHF-V：从多模态人类偏好中学习原则'}
{'arxiv_id': 'arXiv:2505.18517', 'title': 'LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs', 'authors': 'Pooneh Mousavi, Shubham Gupta, Cem Subakan, Mirco Ravanelli', 'link': 'https://arxiv.org/abs/2505.18517', 'abstract': 'Foundation models based on large language models (LLMs) have shown great success in handling various tasks and modalities. However, adapting these models for general-purpose audio-language tasks is challenging due to differences in acoustic environments and task variations. In this work, we introduce LiSTEN Learning Soft Token Embeddings for Neural Audio LLMs), a framework for adapting LLMs to speech and audio tasks. LiSTEN uses a dynamic prompt selection strategy with learnable key-value pairs, allowing the model to balance general and task-specific knowledge while avoiding overfitting in a multitask setting. Our approach reduces dependence on large-scale ASR or captioning datasets, achieves competitive performance with fewer trainable parameters, and simplifies training by using a single-stage process. Additionally, LiSTEN enhances interpretability by analyzing the diversity and overlap of selected prompts across different tasks.', 'abstract_zh': '基于大型语言模型的foundation模型在处理各种任务和模态方面取得了显著成功。然而，将这些模型适应通用目的的语音和语言任务具有挑战性，因为存在声学环境和任务差异。在本文中，我们引入了LiSTEN学习软令牌嵌入以适应神经音频foundation模型（LiSTEN Learning Soft Token Embeddings for Neural Audio Foundation Models），一种将大型语言模型适应语音和音频任务的框架。LiSTEN使用具有可学习键值对的动态提示选择策略，允许模型在多任务设置中平衡一般知识和任务特定知识，同时避免过度拟合。我们的方法减少了对大规模ASR或字幕数据集的依赖，使用较少的可训练参数实现了竞争力的表现，并通过单阶段过程简化了训练。此外，LiSTEN通过分析不同任务中选择提示的多样性和重叠性以增强可解释性。', 'title_zh': 'LiSTEN: 学习软令牌嵌入的神经音频大规模语言模型'}
{'arxiv_id': 'arXiv:2505.18502', 'title': 'Knowledge Grafting of Large Language Models', 'authors': 'Guodong Du, Xuanning Zhou, Junlin Li, Zhuo Li, Zesheng Shi, Wanyu Lin, Ho-Kin Tang, Xiucheng Li, Fangming Liu, Wenya Wang, Min Zhang, Jing Li', 'link': 'https://arxiv.org/abs/2505.18502', 'abstract': "Cross-capability transfer is a key challenge in large language model (LLM) research, with applications in multi-task integration, model compression, and continual learning. Recent works like FuseLLM and FuseChat have demonstrated the potential of transferring multiple model capabilities to lightweight models, enhancing adaptability and efficiency, which motivates our investigation into more efficient cross-capability transfer methods. However, existing approaches primarily focus on small, homogeneous models, limiting their applicability. For large, heterogeneous models, knowledge distillation with full-parameter fine-tuning often overlooks the student model's intrinsic capacity and risks catastrophic forgetting, while PEFT methods struggle to effectively absorb knowledge from source LLMs. To address these issues, we introduce GraftLLM, a novel method that stores source model capabilities in a target model with SkillPack format. This approach preserves general capabilities, reduces parameter conflicts, and supports forget-free continual learning and model fusion. We employ a module-aware adaptive compression strategy to compress parameter updates, ensuring efficient storage while maintaining task-specific knowledge. The resulting SkillPack serves as a compact and transferable knowledge carrier, ideal for heterogeneous model fusion and continual learning. Experiments across various scenarios demonstrate that GraftLLM outperforms existing techniques in knowledge transfer, knowledge fusion, and forget-free learning, providing a scalable and efficient solution for cross-capability transfer. The code is publicly available at: this https URL.", 'abstract_zh': '跨能力迁移是大型语言模型（LLM）研究中的一个关键挑战，应用于多任务集成、模型压缩和持续学习。现有的工作如FuseLLM和FuseChat展示了将多个模型能力迁移到轻量级模型中的潜力，增强了适应性和效率，这激发了我们对更高效跨能力迁移方法的研究。然而，现有方法主要集中在小型同质模型上，限制了其适用范围。对于大型异质模型，全参数微调的知识精炼往往忽略了学生模型的固有能力并存在灾难性遗忘的风险，而PEFT方法难以有效地吸收源LLM的知识。为了解决这些问题，我们引入了GraftLLM，这是一种新颖的方法，将源模型能力存储在目标模型中的SkillPack格式中。该方法保留了通用能力，减少了参数冲突，并支持无遗忘的持续学习和模型融合。我们采用模块感知的自适应压缩策略压缩参数更新，确保高效存储同时保留任务特定的知识。所获得的SkillPack作为一种紧凑且可迁移的知识载体，适用于异质模型融合和持续学习。实验结果表明，在知识迁移、知识融合和无遗忘学习方面，GraftLLM优于现有技术，提供了一种可扩展且高效的跨能力迁移解决方案。代码已公开：this https URL。', 'title_zh': '大型语言模型的知识嫁接'}
{'arxiv_id': 'arXiv:2505.18492', 'title': 'Enumerate-Conjecture-Prove: Formally Solving Answer-Construction Problems in Math Competitions', 'authors': 'Jialiang Sun, Yuzhi Tang, Ao Li, Chris J. Maddison, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2505.18492', 'abstract': "Mathematical reasoning lies at the heart of artificial intelligence, underpinning applications in education, program verification, and research-level mathematical discovery. Mathematical competitions, in particular, present two challenging problem types: theorem-proving, requiring rigorous proofs of stated conclusions, and answer-construction, involving hypothesizing and formally verifying mathematical objects. Large Language Models (LLMs) effectively generate creative candidate answers but struggle with formal verification, while symbolic provers ensure rigor but cannot efficiently handle creative conjecture generation. We introduce the Enumerate-Conjecture-Prove (ECP) framework, a modular neuro-symbolic method integrating LLM-based enumeration and pattern-driven conjecturing with formal theorem proving. We present ConstructiveBench, a dataset of 3,431 answer-construction problems in various math competitions with verified Lean formalizations. On the ConstructiveBench dataset, ECP improves the accuracy of answer construction from the Chain-of-Thought (CoT) baseline of 14.54% to 45.06% with the gpt-4.1-mini model. Moreover, combining with ECP's constructed answers, the state-of-the-art DeepSeek-Prover-V2-7B model generates correct proofs for 858 of the 3,431 constructive problems in Lean, achieving 25.01% accuracy, compared to 9.86% for symbolic-only baselines. Our code and dataset are publicly available at GitHub and HuggingFace, respectively.", 'abstract_zh': '数学推理是人工智能的核心，支撑着教育应用、程序验证以及高水平的数学发现。数学竞赛，尤其是提供了两种具有挑战性的问题类型：定理证明，需要对陈述结论给出严密的证明；以及答案构造，涉及假设和形式验证数学对象。大型语言模型（LLMs）能够生成有创意的候选答案，但在形式验证方面存在困难，而符号证明器则能确保严谨性，但无法高效处理创造性的假设生成。我们提出了枚举-假设-证明（ECP）框架，这是一种模块化的神经-符号方法，结合了基于LLM的枚举、模式驱动的假设生成以及形式定理证明。我们还介绍了ConstructiveBench数据集，包含3,431个来自各类数学竞赛的答案构造问题，并进行了形式化的Lean验证。在ConstructiveBench数据集上，使用gpt-4.1-mini模型，ECP框架将基于Chain-of-Thought（CoT）基线的答案构造准确性从14.54%提升至45.06%。此外，结合ECP生成的答案，最先进的DeepSeek-Prover-V2-7B模型在Lean中正确证明了858个构造性问题，实现了25.01%的准确性，而仅使用符号方法的基线模型准确率为9.86%。我们的代码和数据集分别在GitHub和HuggingFace上公开。', 'title_zh': '列举-猜想-证明：正式解决数学竞赛中的答案构建问题'}
{'arxiv_id': 'arXiv:2505.18483', 'title': 'Retrieval Augmented Decision-Making: A Requirements-Driven, Multi-Criteria Framework for Structured Decision Support', 'authors': 'Hongjia Wu, Hongxin Zhang, Wei Chen, Jiazhi Xia', 'link': 'https://arxiv.org/abs/2505.18483', 'abstract': 'Various industries have produced a large number of documents such as industrial plans, technical guidelines, and regulations that are structurally complex and content-wise fragmented. This poses significant challenges for experts and decision-makers in terms of retrieval and understanding. Although existing LLM-based Retrieval-Augmented Generation methods can provide context-related suggestions, they lack quantitative weighting and traceable reasoning paths, making it difficult to offer multi-level and transparent decision support. To address this issue, this paper proposes the RAD method, which integrates Multi-Criteria Decision Making with the semantic understanding capabilities of LLMs. The method automatically extracts key criteria from industry documents, builds a weighted hierarchical decision model, and generates structured reports under model guidance. The RAD framework introduces explicit weight assignment and reasoning chains in decision generation to ensure accuracy, completeness, and traceability. Experiments show that in various decision-making tasks, the decision reports generated by RAD significantly outperform existing methods in terms of detail, rationality, and structure, demonstrating its application value and potential in complex decision support scenarios.', 'abstract_zh': '各种行业产生了大量结构复杂、内容碎片化的文档，如工业计划、技术指南和规章等，这给专家和决策者在检索和理解方面带来了显著挑战。尽管现有的基于LLM的检索增强生成方法可以提供上下文相关的建议，但是缺少定量加权和可追溯的推理路径，难以提供多层次和透明的决策支持。为解决这一问题，本文提出了RAD方法，该方法将多准则决策方法与LLM的语义理解能力相结合。该方法自动从行业文档中提取关键准则，构建加权层次决策模型，并在模型引导下生成结构化报告。RAD框架在决策生成中引入了明确的权重分配和推理链，以确保决策的准确性和可追溯性。实验结果表明，在各种决策任务中，RAD生成的决策报告在细节、合理性、结构等方面显著优于现有方法，显示出其在复杂决策支持场景中的应用价值和潜力。', 'title_zh': '基于检索增强的决策制定：一种需求驱动的多准则结构化决策支持框架'}
{'arxiv_id': 'arXiv:2505.18470', 'title': 'Chemical classification program synthesis using generative artificial intelligence', 'authors': "Christopher J. Mungall, Adnan Malik, Daniel R. Korn, Justin T. Reese, Noel M. O'Boyle, Noel, Janna Hastings", 'link': 'https://arxiv.org/abs/2505.18470', 'abstract': 'Accurately classifying chemical structures is essential for cheminformatics and bioinformatics, including tasks such as identifying bioactive compounds of interest, screening molecules for toxicity to humans, finding non-organic compounds with desirable material properties, or organizing large chemical libraries for drug discovery or environmental monitoring. However, manual classification is labor-intensive and difficult to scale to large chemical databases. Existing automated approaches either rely on manually constructed classification rules, or the use of deep learning methods that lack explainability.\nThis work presents an approach that uses generative artificial intelligence to automatically write chemical classifier programs for classes in the Chemical Entities of Biological Interest (ChEBI) database. These programs can be used for efficient deterministic run-time classification of SMILES structures, with natural language explanations. The programs themselves constitute an explainable computable ontological model of chemical class nomenclature, which we call the ChEBI Chemical Class Program Ontology (C3PO).\nWe validated our approach against the ChEBI database, and compared our results against state of the art deep learning models. We also demonstrate the use of C3PO to classify out-of-distribution examples taken from metabolomics repositories and natural product databases. We also demonstrate the potential use of our approach to find systematic classification errors in existing chemical databases, and show how an ensemble artificial intelligence approach combining generated ontologies, automated literature search, and multimodal vision models can be used to pinpoint potential errors requiring expert validation', 'abstract_zh': '准确分类化学结构对于化学信息学和生物信息学至关重要，包括识别感兴趣的生物活性化合物、筛选对人体有毒性的分子、寻找具有 desirable 物理化学性质的非有机化合物，或组织用于药物发现或环境监测的大型化学数据库。然而，手工分类劳动密集且难以扩展到大型化学数据库。现有的自动化方法要么依赖于手工构建的分类规则，要么使用缺乏解释性的深度学习方法。\n\n本研究提出了一种使用生成人工智能自动为化学实体生物学信息（ChEBI）数据库中的类编写化学分类器程序的方法。这些程序可用于高效确定运行时 SMILES 结构分类，并附带自然语言解释。这些程序本身构成了一个可解释的计算本体模型，我们称之为 ChEBI 化学类别程序本体（C3PO）。\n\n我们使用 ChEBI 数据库对我们的方法进行了验证，并将我们的结果与最先进的深度学习模型进行了比较。我们还展示了如何使用 C3PO 对代谢组学存储库和天然产物数据库中的分类外示例进行分类。我们还展示了本方法在发现现有化学数据库中的系统性分类错误方面的潜在用途，并展示了如何结合生成本体、自动文献搜索和多模态视觉模型的集成人工智能方法来定位需要专家验证的潜在错误。', 'title_zh': '使用生成式人工智能进行化学分类程序合成'}
{'arxiv_id': 'arXiv:2505.18467', 'title': 'Pedagogy-R1: Pedagogically-Aligned Reasoning Model with Balanced Educational Benchmark', 'authors': 'Unggi Lee, Jaeyong Lee, Jiyeong Bae, Yeil Jeong, Junbo Koh, Gyeonggeon Lee, Gunho Lee, Taekyung Ahn, Hyeoncheol Kim', 'link': 'https://arxiv.org/abs/2505.18467', 'abstract': "Recent advances in large reasoning models (LRMs) show strong performance in structured domains such as mathematics and programming; however, they often lack pedagogical coherence and realistic teaching behaviors. To bridge this gap, we introduce Pedagogy-R1, a framework that adapts LRMs for classroom use through three innovations: (1) a distillation-based pipeline that filters and refines model outputs for instruction-tuning, (2) the Well-balanced Educational Benchmark (WBEB), which evaluates performance across subject knowledge, pedagogical knowledge, tracing, essay scoring, and teacher decision-making, and (3) a Chain-of-Pedagogy (CoP) prompting strategy for generating and eliciting teacher-style reasoning. Our mixed-method evaluation combines quantitative metrics with qualitative analysis, providing the first systematic assessment of LRMs' pedagogical strengths and limitations.", 'abstract_zh': 'Recent advances in大型推理模型（LRMs）在数学和编程等结构化领域展现了强大性能；然而，它们往往缺乏教学连贯性和现实的教学行为。为弥补这一差距，我们引入了Pedagogy-R1框架，通过三项创新将LRMs适应于课堂教学环境：（1）基于蒸馏的流水线，筛选和提高模型输出以用于教学调优；（2）均衡教育基准（WBEB），评估模型在学科知识、教学知识、追踪、作文评分及教师决策方面的表现；（3）教师导向的推理链（CoP）提示策略，用于生成和激发教师风格的推理。我们的混合方法评估结合了定量指标与定性分析，提供了首个系统评估LRMs教学优势与限制的研究。', 'title_zh': '教学导向-1：平衡教育基准的教学对齐推理模型'}
{'arxiv_id': 'arXiv:2505.18457', 'title': 'EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military Communication Networks', 'authors': 'Abir Ray', 'link': 'https://arxiv.org/abs/2505.18457', 'abstract': 'This paper introduces EdgeAgentX, a novel framework integrating federated learning (FL), multi-agent reinforcement learning (MARL), and adversarial defense mechanisms, tailored for military communication networks. EdgeAgentX significantly improves autonomous decision-making, reduces latency, enhances throughput, and robustly withstands adversarial disruptions, as evidenced by comprehensive simulations.', 'abstract_zh': 'EdgeAgentX：一种集成联邦学习、多智能体强化学习和对抗防御机制的新型军事通信网络框架', 'title_zh': 'EdgeAgentX：军事通信网络中边缘代理型AI的新型框架'}
{'arxiv_id': 'arXiv:2505.18425', 'title': 'Advertising in AI systems: Society must be vigilant', 'authors': 'Menghua Wu, Yujia Bao', 'link': 'https://arxiv.org/abs/2505.18425', 'abstract': 'AI systems have increasingly become our gateways to the Internet. We argue that just as advertising has driven the monetization of web search and social media, so too will commercial incentives shape the content served by AI. Unlike traditional media, however, the outputs of these systems are dynamic, personalized, and lack clear provenance -- raising concerns for transparency and regulation. In this paper, we envision how commercial content could be delivered through generative AI-based systems. Based on the requirements of key stakeholders -- advertisers, consumers, and platforms -- we propose design principles for commercially-influenced AI systems. We then outline high-level strategies for end users to identify and mitigate commercial biases from model outputs. Finally, we conclude with open questions and a call to action towards these goals.', 'abstract_zh': '基于生成AI的商业内容交付及其设计原则与用户策略探索', 'title_zh': 'AI系统中的广告：社会必须保持警惕'}
{'arxiv_id': 'arXiv:2505.18380', 'title': 'RedactOR: An LLM-Powered Framework for Automatic Clinical Data De-Identification', 'authors': 'Praphul Singh, Charlotte Dzialo, Jangwon Kim, Sumana Srivatsa, Irfan Bulu, Sri Gadde, Krishnaram Kenthapadi', 'link': 'https://arxiv.org/abs/2505.18380', 'abstract': 'Ensuring clinical data privacy while preserving utility is critical for AI-driven healthcare and data analytics. Existing de-identification (De-ID) methods, including rule-based techniques, deep learning models, and large language models (LLMs), often suffer from recall errors, limited generalization, and inefficiencies, limiting their real-world applicability. We propose a fully automated, multi-modal framework, RedactOR for de-identifying structured and unstructured electronic health records, including clinical audio records. Our framework employs cost-efficient De-ID strategies, including intelligent routing, hybrid rule and LLM based approaches, and a two-step audio redaction approach. We present a retrieval-based entity relexicalization approach to ensure consistent substitutions of protected entities, thereby enhancing data coherence for downstream applications. We discuss key design desiderata, de-identification and relexicalization methodology, and modular architecture of RedactX and its integration with the Oracle Health Clinical AI system. Evaluated on the i2b2 2014 De-ID dataset using standard metrics with strict recall, our approach achieves competitive performance while optimizing token usage to reduce LLM costs. Finally, we discuss key lessons and insights from deployment in real-world AI- driven healthcare data pipelines.', 'abstract_zh': '确保临床数据隐私同时保留其实用性的自动化多模态脱敏框架RedactOR对于AI驱动的医疗和数据分析至关重要。', 'title_zh': 'RedactOR: 一个由大规模语言模型驱动的自动临床数据去标识化框架'}
{'arxiv_id': 'arXiv:2505.18325', 'title': 'Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary', 'authors': 'Licheng Pan, Yongqi Tong, Xin Zhang, Xiaolu Zhang, Jun Zhou, Zhixuan Chu', 'link': 'https://arxiv.org/abs/2505.18325', 'abstract': "Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they often refuse to answer legitimate queries-a phenomenon known as overrefusal. Overrefusal typically stems from over-conservative safety alignment, causing models to treat many reasonable prompts as potentially risky. To systematically understand this issue, we probe and leverage the models'safety decision boundaries to analyze and mitigate overrefusal. Our findings reveal that overrefusal is closely tied to misalignment at these boundary regions, where models struggle to distinguish subtle differences between benign and harmful content. Building on these insights, we present RASS, an automated framework for prompt generation and selection that strategically targets overrefusal prompts near the safety boundary. By harnessing steering vectors in the representation space, RASS efficiently identifies and curates boundary-aligned prompts, enabling more effective and targeted mitigation of overrefusal. This approach not only provides a more precise and interpretable view of model safety decisions but also seamlessly extends to multilingual this http URL have explored the safety decision boundaries of various LLMs and construct the MORBench evaluation set to facilitate robust assessment of model safety and helpfulness across multiple languages. Code and datasets will be released at this https URL.", 'abstract_zh': '大型语言模型（LLMs）在广泛的任务中展示了出色的能力，但它们往往拒绝回答合法查询——这一现象被称为过度回避。过度回避通常源于过度保守的安全对齐，导致模型将许多合理的提示视为潜在风险。为了系统地理解这一问题，我们通过探查和利用模型的安全决策边界来分析和缓解过度回避现象。我们的研究发现，过度回避与这些边界区域的不对齐密切相关，在这些区域，模型难以区分良性内容和有害内容之间微妙的差异。基于这些见解，我们提出了RASS，这是一种自动化的提示生成和选择框架，战略性地将目标对准安全边界附近的过度回避提示。通过利用概念空间中的引导向量，RASS高效地识别并筛选边界对齐的提示，从而更有效地和精确地缓解过度回避现象。这种方法不仅提供了对模型安全决策更为精确和可解释的看法，还能够无缝扩展到多语言环境。我们探索了各种LLM的安全决策边界，并构建了MORBench评估集，以促进对多语言模型安全性和有用性的稳健评估。相关代码和数据集将在以下链接发布：this https URL。', 'title_zh': '从安全性决策边界揭示视角理解并缓解LLM中的过度拒绝现象'}
{'arxiv_id': 'arXiv:2505.18277', 'title': 'The end of radical concept nativism', 'authors': 'Joshua S. Rule, Steven T. Piantadosi', 'link': 'https://arxiv.org/abs/2505.18277', 'abstract': "Though humans seem to be remarkable learners, arguments in cognitive science and philosophy of mind have long maintained that learning something fundamentally new is impossible. Specifically, Jerry Fodor's arguments for radical concept nativism hold that most, if not all, concepts are innate and that what many call concept learning never actually leads to the acquisition of new concepts. These arguments have deeply affected cognitive science, and many believe that the counterarguments to radical concept nativism have been either unsuccessful or only apply to a narrow class of concepts. This paper first reviews the features and limitations of prior arguments. We then identify three critical points - related to issues of expressive power, conceptual structure, and concept possession - at which the arguments in favor of radical concept nativism diverge from describing actual human cognition. We use ideas from computer science and information theory to formalize the relevant ideas in ways that are arguably more scientifically productive. We conclude that, as a result, there is an important sense in which people do indeed learn new concepts.", 'abstract_zh': '尽管人类似乎具有卓越的学习能力，但在认知科学和心灵哲学中，长期存在的论点认为根本性的新学习是不可能的。具体来说，Jerry Fodor有关激进的概念先天论的论点认为，大部分甚至全部的概念都是先天的，许多人所谓的概念学习实际上并未带来新概念的获得。这些论点深深地影响了认知科学，许多人认为反对激进的概念先天论的论点要么不成功，要么仅适用于特定类型的概念。本文首先回顾了先前论点的特点和局限性。然后，我们识别出三个关键点——涉及表达能力、概念结构和概念拥有等方面的问题——在这些方面，支持激进的概念先天论的论点与描述实际人类认知相偏离。我们使用计算机科学和信息理论中的概念对相关思想进行形式化，这可能更具有科学生产力。我们得出结论，在某种重要意义上，人们确实能够学习新的概念。', 'title_zh': '终结激进的概念natal主义'}
{'arxiv_id': 'arXiv:2505.20298', 'title': 'MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal Manga Understanding', 'authors': 'Jeonghun Baek, Kazuki Egashira, Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Hikaru Ikuta, Kiyoharu Aizawa', 'link': 'https://arxiv.org/abs/2505.20298', 'abstract': 'Manga, or Japanese comics, is a richly multimodal narrative form that blends images and text in complex ways. Teaching large multimodal models (LMMs) to understand such narratives at a human-like level could help manga creators reflect on and refine their stories. To this end, we introduce two benchmarks for multimodal manga understanding: MangaOCR, which targets in-page text recognition, and MangaVQA, a novel benchmark designed to evaluate contextual understanding through visual question answering. MangaVQA consists of 526 high-quality, manually constructed question-answer pairs, enabling reliable evaluation across diverse narrative and visual scenarios. Building on these benchmarks, we develop MangaLMM, a manga-specialized model finetuned from the open-source LMM Qwen2.5-VL to jointly handle both tasks. Through extensive experiments, including comparisons with proprietary models such as GPT-4o and Gemini 2.5, we assess how well LMMs understand manga. Our benchmark and model provide a comprehensive foundation for evaluating and advancing LMMs in the richly narrative domain of manga.', 'abstract_zh': '漫画，或日本漫画，是一种丰富多模态的叙事形式，以复杂的方式结合了图像和文字。训练大规模多模态模型（LMM）以人类水平理解这种叙事可以帮助漫画创作者反思和改进他们的故事。为此，我们引入了两个多模态漫画理解基准：MangaOCR，旨在进行页面内文本识别，以及MangaVQA，这是一种新型基准，旨在通过视觉问答评估上下文理解能力。MangaVQA包含526个高质量的手工构建的问题-答案对，使得在多种叙事和视觉场景中进行可靠评估成为可能。基于这些基准，我们开发了MangaLMM，这是一种从开源LMM Qwen2.5-VL微调的专门用于漫画的模型，旨在同时处理这两个任务。通过广泛的实验，包括与GPT-4o和Gemini 2.5等 propriety模型的比较，我们评估了LMM对漫画的理解能力。我们的基准和模型为评价和促进多模态模型在丰富叙事领域的漫画中提供了全面的基础。', 'title_zh': 'MangaVQA和MangaLMM：多模态漫画理解的标准基准和专业模型'}
{'arxiv_id': 'arXiv:2505.20296', 'title': 'Reasoning LLMs are Wandering Solution Explorers', 'authors': 'Jiahao Lu, Ziwei Xu, Mohan Kankanhalli', 'link': 'https://arxiv.org/abs/2505.20296', 'abstract': "Large Language Models (LLMs) have demonstrated impressive reasoning abilities through test-time computation (TTC) techniques such as chain-of-thought prompting and tree-based reasoning. However, we argue that current reasoning LLMs (RLLMs) lack the ability to systematically explore the solution space. This paper formalizes what constitutes systematic problem solving and identifies common failure modes that reveal reasoning LLMs to be wanderers rather than systematic explorers. Through qualitative and quantitative analysis across multiple state-of-the-art LLMs, we uncover persistent issues: invalid reasoning steps, redundant explorations, hallucinated or unfaithful conclusions, and so on. Our findings suggest that current models' performance can appear to be competent on simple tasks yet degrade sharply as complexity increases. Based on the findings, we advocate for new metrics and tools that evaluate not just final outputs but the structure of the reasoning process itself.", 'abstract_zh': '大型语言模型（LLMs）通过测试时计算（TTC）技术如链式思考提示和树状推理展示了令人印象深刻的推理能力。然而，我们argue认为当前的推理大型语言模型（RLLMs）缺乏系统探索解空间的能力。本文形式化了系统性问题解决的构成，并指出了常见失败模式，表明推理大型语言模型更像是漫游者而非系统探索者。通过对多种最先进的大型语言模型进行定性和定量分析，我们揭露出持久存在的问题：无效的推理步骤、冗余的探索、虚幻或不忠实的结论等。我们的发现表明，当前模型在简单任务上可能表现得相当能干，但在复杂性增加时性能急剧下降。基于这些发现，我们提倡新的评估指标和工具，不仅评估最终输出，还要评估推理过程本身的结构。', 'title_zh': 'LLM推理是漫游的解探索者'}
{'arxiv_id': 'arXiv:2505.20295', 'title': 'Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?', 'authors': 'Michael Kirchhof, Luca Füger, Adam Goliński, Eeshan Gunesh Dhekane, Arno Blaas, Sinead Williamson', 'link': 'https://arxiv.org/abs/2505.20295', 'abstract': "To reveal when a large language model (LLM) is uncertain about a response, uncertainty quantification commonly produces percentage numbers along with the output. But is this all we can do? We argue that in the output space of LLMs, the space of strings, exist strings expressive enough to summarize the distribution over output strings the LLM deems possible. We lay a foundation for this new avenue of uncertainty explication and present SelfReflect, a theoretically-motivated metric to assess how faithfully a string summarizes an LLM's internal answer distribution. We show that SelfReflect is able to discriminate even subtle differences of candidate summary strings and that it aligns with human judgement, outperforming alternative metrics such as LLM judges and embedding comparisons. With SelfReflect, we investigate a number of self-summarization methods and find that even state-of-the-art reasoning models struggle to explicate their internal uncertainty. But we find that faithful summarizations can be generated by sampling and summarizing. Our metric enables future works towards this universal form of LLM uncertainties.", 'abstract_zh': '揭示大规模语言模型（LLM）回答不确定性的新途径：字符串的不确定量化评估', 'title_zh': '自我反思不确定性：大规模语言模型知晓其内部答案分布吗？'}
{'arxiv_id': 'arXiv:2505.20294', 'title': 'GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes', 'authors': 'Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, Tianfan Xue', 'link': 'https://arxiv.org/abs/2505.20294', 'abstract': 'Generalizable active mapping in complex unknown environments remains a critical challenge for mobile robots. Existing methods, constrained by insufficient training data and conservative exploration strategies, exhibit limited generalizability across scenes with diverse layouts and complex connectivity. To enable scalable training and reliable evaluation, we introduce GLEAM-Bench, the first large-scale benchmark designed for generalizable active mapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets. Building upon this foundation, we propose GLEAM, a unified generalizable exploration policy for active mapping. Its superior generalizability comes mainly from our semantic representations, long-term navigable goals, and randomized strategies. It significantly outperforms state-of-the-art methods, achieving 66.50% coverage (+9.49%) with efficient trajectories and improved mapping accuracy on 128 unseen complex scenes. Project page: this https URL.', 'abstract_zh': '复杂未知环境中可泛化的主动建图仍然是移动机器人面临的关键挑战。现有的方法受限于训练数据不足和保守的探索策略，在具有不同布局和复杂连接的场景中表现出有限的泛化能力。为了实现可扩展的训练和可靠的评估，我们引入了GLEAM-Bench，这是首个专门为可泛化主动建图设计的大规模基准，包含1,152个来自合成和真实扫描数据集的多样化3D场景。在此基础上，我们提出了GLEAM，一种统一的可泛化探索政策，用于主动建图。其出色的泛化能力主要得益于我们的语义表示、长期导航目标以及随机化策略。GLEAM在128个未见过的复杂场景中，实现了66.50%的覆盖面积（提高9.49%），同时产生了高效轨迹并提高了建图精度。项目页面：this https URL。', 'title_zh': 'GLEAM: 学习适用于复杂3D室内场景主动建图的可迁移探索策略'}
{'arxiv_id': 'arXiv:2505.20292', 'title': 'OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation', 'authors': 'Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Chongyang Ma, Jiebo Luo, Li Yuan', 'link': 'https://arxiv.org/abs/2505.20292', 'abstract': "Subject-to-Video (S2V) generation aims to create videos that faithfully incorporate reference content, providing enhanced flexibility in the production of videos. To establish the infrastructure for S2V generation, we propose OpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and (ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V benchmarks inherited from VBench that focus on global and coarse-grained assessment of generated videos, OpenS2V-Eval focuses on the model's ability to generate subject-consistent videos with natural subject appearance and identity fidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven major categories of S2V, which incorporate both real and synthetic test data. Furthermore, to accurately align human preferences with S2V benchmarks, we propose three automatic metrics, NexusScore, NaturalScore and GmeScore, to separately quantify subject consistency, naturalness, and text relevance in generated videos. Building on this, we conduct a comprehensive evaluation of 16 representative S2V models, highlighting their strengths and weaknesses across different content. Moreover, we create the first open-source large-scale S2V generation dataset OpenS2V-5M, which consists of five million high-quality 720P subject-text-video triples. Specifically, we ensure subject-information diversity in our dataset by (1) segmenting subjects and building pairing information via cross-video associations and (2) prompting GPT-Image-1 on raw frames to synthesize multi-view representations. Through OpenS2V-Nexus, we deliver a robust infrastructure to accelerate future S2V generation research.", 'abstract_zh': '面向视频的主体生成（S2V）旨在创建能够忠实融入参考内容的视频，提供视频生产中的增强灵活性。为建立S2V生成的基础架构，我们提出OpenS2V-Nexus，包括（i）OpenS2V-Eval，一个细粒度基准，以及（ii）OpenS2V-5M，一个百万级规模的数据集。与继承自VBench、主要针对生成视频的全局和粗粒度评估的现有S2V基准不同，OpenS2V-Eval专注于模型生成与主体一致且具有自然外观和身份保真的视频的能力。为实现这一目标，OpenS2V-Eval引入了来自七大大类S2V的180个提示，这些提示结合了实际和合成测试数据。此外，为了准确地将人类偏好与S2V基准对齐，我们提出三种自动度量指标NexusScore、NaturalScore和GmeScore，分别量化生成视频中主体的一致性、自然度和文本相关性。在这一基础上，我们对16个代表性的S2V模型进行了全面评估，强调了它们在不同内容方面的优势和劣势，并创建了首个开放源码的大型S2V生成数据集OpenS2V-5M，包含五百万个高分辨率720P的主体-文本-视频三元组。特别地，我们通过（1）对主体进行分割并利用跨视频关联建立配对信息，以及（2）使用GPT-Image-1在原始帧上生成多视图表示，确保数据集中主体信息的多样性。通过OpenS2V-Nexus，我们提供了一个强大的基础架构，以加速未来的S2V生成研究。', 'title_zh': 'OpenS2V-Nexus: 一个详细的基准和百万规模数据集用于主题到视频生成'}
{'arxiv_id': 'arXiv:2505.20290', 'title': 'EgoZero: Robot Learning from Smart Glasses', 'authors': 'Vincent Liu, Ademi Adeniji, Haotian Zhan, Raunaq Bhirangi, Pieter Abbeel, Lerrel Pinto', 'link': 'https://arxiv.org/abs/2505.20290', 'abstract': 'Despite recent progress in general purpose robotics, robot policies still lag far behind basic human capabilities in the real world. Humans interact constantly with the physical world, yet this rich data resource remains largely untapped in robot learning. We propose EgoZero, a minimal system that learns robust manipulation policies from human demonstrations captured with Project Aria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1) extraction of complete, robot-executable actions from in-the-wild, egocentric, human demonstrations, (2) compression of human visual observations into morphology-agnostic state representations, and (3) closed-loop policy learning that generalizes morphologically, spatially, and semantically. We deploy EgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot transfer with 70% success rate over 7 manipulation tasks and only 20 minutes of data collection per task. Our results suggest that in-the-wild human data can serve as a scalable foundation for real-world robot learning - paving the way toward a future of abundant, diverse, and naturalistic training data for robots. Code and videos are available at this https URL.', 'abstract_zh': '尽管通用机器人技术取得了进步，但机器人策略在实际世界中仍远远落后于基本的人类能力。人类不断与物理世界互动，但这些丰富的数据资源在机器人学习中尚未充分利用。我们提出了EgoZero，一个最小化的系统，通过使用Project Aria智能眼镜捕获的人类演示，结合零机器人数据学习 robust 操作策略。EgoZero能够实现：(1) 从野生环境中的第一人称人类演示中提取完整可由机器人执行的动作，(2) 将人类视觉观察压缩为形态无关的状态表示，以及(3) 具有形态、空间和语义泛化的闭环策略学习。我们在夹爪机器人Franka Panda上部署了EgoZero策略，并在7个操作任务中展示了零样本迁移，成功率达到70%，每任务仅需20分钟的数据收集。我们的结果表明，野生人类数据可以作为现实世界机器人学习的可扩展基础——铺就了一条通往机器人丰富、多样和自然训练数据的道路。代码和视频可在以下链接获取。', 'title_zh': 'EgoZero: 机器人从智能眼镜学习'}
{'arxiv_id': 'arXiv:2505.20278', 'title': 'The Coverage Principle: A Framework for Understanding Compositional Generalization', 'authors': 'Hoyeon Chang, Jinho Park, Hanseul Cho, Sohee Yang, Miyoung Ko, Hyeonbin Hwang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo', 'link': 'https://arxiv.org/abs/2505.20278', 'abstract': 'Large language models excel at pattern matching, yet often fall short in systematic compositional generalization. We propose the coverage principle: a data-centric framework showing that models relying primarily on pattern matching for compositional tasks cannot reliably generalize beyond substituting fragments that yield identical results when used in the same contexts. We demonstrate that this framework has a strong predictive power for the generalization capabilities of Transformers. First, we derive and empirically confirm that the training data required for two-hop generalization grows at least quadratically with the token set size, and the training data efficiency does not improve with 20x parameter scaling. Second, for compositional tasks with path ambiguity where one variable affects the output through multiple computational paths, we show that Transformers learn context-dependent state representations that undermine both performance and interoperability. Third, Chain-of-Thought supervision improves training data efficiency for multi-hop tasks but still struggles with path ambiguity. Finally, we outline a \\emph{mechanism-based} taxonomy that distinguishes three ways neural networks can generalize: structure-based (bounded by coverage), property-based (leveraging algebraic invariances), and shared-operator (through function reuse). This conceptual lens contextualizes our results and highlights where new architectural ideas are needed to achieve systematic compositionally. Overall, the coverage principle provides a unified lens for understanding compositional reasoning, and underscores the need for fundamental architectural or training innovations to achieve truly systematic compositionality.', 'abstract_zh': '大型语言模型在模式匹配方面表现出色，但在系统组合泛化方面往往表现不佳。我们提出了覆盖原则：一个以数据为中心的框架，表明主要依赖于模式匹配的模型在组合任务中无法可靠地泛化到只能通过相同上下文产生相同结果的片段替换之外。我们证明了该框架对Transformer的泛化能力具有很强的预测能力。首先，我们推导并实证验证了两步泛化的训练数据量至少与令牌集大小成平方关系，并且20倍参数规模并不会提高训练数据效率。其次，在路径歧义的组合任务中，一个变量通过多个计算路径影响输出时，我们表明Transformer学习到的上下文依赖状态表示会损害其性能和互操作性。第三，链式思维监督提升了多步任务的训练数据效率，但仍难以处理路径歧义。最后，我们提出了基于机制的分类法，区分神经网络三种泛化方式：结构基于（受覆盖限制的），属性基于（利用代数不变性），和共享操作符（通过功能重用）。这一概念框架剖析了我们的结果，并突显了实现真正系统组合性所需的新架构思路。总体而言，覆盖原则提供了一个统一的视角来理解组合推理，并强调了需要基础架构或训练创新以实现真正的系统组合性。', 'title_zh': '覆盖原理：理解组合泛化的框架'}
{'arxiv_id': 'arXiv:2505.20276', 'title': "Does quantization affect models' performance on long-context tasks?", 'authors': 'Anmol Mekala, Anirudh Atmakuru, Yixiao Song, Marzena Karpinska, Mohit Iyyer', 'link': 'https://arxiv.org/abs/2505.20276', 'abstract': 'Large language models (LLMs) now support context windows exceeding 128K tokens, but this comes with significant memory requirements and high inference latency. Quantization can mitigate these costs, but may degrade performance. In this work, we present the first systematic evaluation of quantized LLMs on tasks with long-inputs (>64K tokens) and long-form outputs. Our evaluation spans 9.7K test examples, five quantization methods (FP8, GPTQ-int8, AWQ-int4, GPTQ-int4, BNB-nf4), and five models (Llama-3.1 8B and 70B; Qwen-2.5 7B, 32B, and 72B). We find that, on average, 8-bit quantization preserves accuracy (~0.8% drop), whereas 4-bit methods lead to substantial losses, especially for tasks involving long context inputs (drops of up to 59%). This degradation tends to worsen when the input is in a language other than English. Crucially, the effects of quantization depend heavily on the quantization method, model, and task. For instance, while Qwen-2.5 72B remains robust under BNB-nf4, Llama-3.1 70B experiences a 32% performance drop on the same task. These findings highlight the importance of a careful, task-specific evaluation before deploying quantized LLMs, particularly in long-context scenarios and with languages other than English.', 'abstract_zh': '量化大型语言模型在长输入和长输出任务中的系统评估', 'title_zh': '量化会影响模型在长上下文任务上的性能吗？'}
{'arxiv_id': 'arXiv:2505.20274', 'title': 'Probabilistic Kernel Function for Fast Angle Testing', 'authors': 'Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa', 'link': 'https://arxiv.org/abs/2505.20274', 'abstract': 'In this paper, we study the angle testing problem in high-dimensional Euclidean spaces and propose two projection-based probabilistic kernel functions, one designed for angle comparison and the other for angle thresholding. Unlike existing approaches that rely on random projection vectors drawn from Gaussian distributions, our approach leverages reference angles and employs a deterministic structure for the projection vectors. Notably, our kernel functions do not require asymptotic assumptions, such as the number of projection vectors tending to infinity, and can be both theoretically and experimentally shown to outperform Gaussian-distribution-based kernel functions. We further apply the proposed kernel function to Approximate Nearest Neighbor Search (ANNS) and demonstrate that our approach achieves a 2.5X ~ 3X higher query-per-second (QPS) throughput compared to the state-of-the-art graph-based search algorithm HNSW.', 'abstract_zh': '在高维欧几里得空间中的角度测试问题研究及两种基于投影的概率核函数提出', 'title_zh': '快速角度测试的概率核函数'}
{'arxiv_id': 'arXiv:2505.20271', 'title': 'In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation', 'authors': 'Yu Xu, Fan Tang, You Wu, Lin Gao, Oliver Deussen, Hongbin Yan, Jintao Li, Juan Cao, Tong-Yee Lee', 'link': 'https://arxiv.org/abs/2505.20271', 'abstract': 'Recent advances in diffusion models have enhanced multimodal-guided visual generation, enabling customized subject insertion that seamlessly "brushes" user-specified objects into a given image guided by textual prompts. However, existing methods often struggle to insert customized subjects with high fidelity and align results with the user\'s intent through textual prompts. In this work, we propose "In-Context Brush", a zero-shot framework for customized subject insertion by reformulating the task within the paradigm of in-context learning. Without loss of generality, we formulate the object image and the textual prompts as cross-modal demonstrations, and the target image with the masked region as the query. The goal is to inpaint the target image with the subject aligning textual prompts without model tuning. Building upon a pretrained MMDiT-based inpainting network, we perform test-time enhancement via dual-level latent space manipulation: intra-head "latent feature shifting" within each attention head that dynamically shifts attention outputs to reflect the desired subject semantics and inter-head "attention reweighting" across different heads that amplifies prompt controllability through differential attention prioritization. Extensive experiments and applications demonstrate that our approach achieves superior identity preservation, text alignment, and image quality compared to existing state-of-the-art methods, without requiring dedicated training or additional data collection.', 'abstract_zh': 'Recent Advances in Diffusion Models Enable Customized Subject Insertion with In-Context Brush Through Textual Prompts', 'title_zh': '基于上下文的画笔：情境感知潜在空间操控下的零样本定制主题插入'}
{'arxiv_id': 'arXiv:2505.20269', 'title': 'Comparing Neural Network Encodings for Logic-based Explainability', 'authors': 'Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha', 'link': 'https://arxiv.org/abs/2505.20269', 'abstract': 'Providing explanations for the outputs of artificial neural networks (ANNs) is crucial in many contexts, such as critical systems, data protection laws and handling adversarial examples. Logic-based methods can offer explanations with correctness guarantees, but face scalability challenges. Due to these issues, it is necessary to compare different encodings of ANNs into logical constraints, which are used in logic-based explainability. This work compares two encodings of ANNs: one has been used in the literature to provide explanations, while the other will be adapted for our context of explainability. Additionally, the second encoding uses fewer variables and constraints, thus, potentially enhancing efficiency. Experiments showed similar running times for computing explanations, but the adapted encoding performed up to 18\\% better in building logical constraints and up to 16\\% better in overall time.', 'abstract_zh': '基于逻辑的方法在人工神经网络输出解释中的应用：两种不同编码的比较', 'title_zh': '基于逻辑的可解释性中神经网络编码的比较'}
{'arxiv_id': 'arXiv:2505.20268', 'title': 'Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits', 'authors': 'Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie', 'link': 'https://arxiv.org/abs/2505.20268', 'abstract': 'Reinforcement learning with outcome-based feedback faces a fundamental challenge: when rewards are only observed at trajectory endpoints, how do we assign credit to the right actions? This paper provides the first comprehensive analysis of this problem in online RL with general function approximation. We develop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the coverability coefficient of the underlying MDP. By leveraging general function approximation, our approach works effectively in large or infinite state spaces where tabular methods fail, requiring only that value functions and reward functions can be represented by appropriate function classes. Our results also characterize when outcome-based feedback is statistically separated from per-step rewards, revealing an unavoidable exponential separation for certain MDPs. For deterministic MDPs, we show how to eliminate the completeness assumption, dramatically simplifying the algorithm. We further extend our approach to preference-based feedback settings, proving that equivalent statistical efficiency can be achieved even under more limited information. Together, these results constitute a theoretical foundation for understanding the statistical properties of outcome-based reinforcement learning.', 'abstract_zh': '基于结果反馈的强化学习面临一个基本挑战：当奖励仅在轨迹结束时观测到时，我们如何将信用正确地分配给相应的动作？本文首次在一般函数近似的在线强化学习中对这一问题进行了全面分析。我们开发了一个可证明样本高效的算法，其样本复杂度为$\\widetilde{O}(C_{\\rm cov} H^3/\\epsilon^2)$，其中$C_{\\rm cov}$是底层MDP的覆盖系数。通过利用一般函数近似，我们的方法在状态空间过大或无限时有效运行，仅需值函数和奖励函数能由适当的功能类表示。我们的结果还界定了基于结果反馈与逐步奖励之间的统计分离情况，揭示了一些MDP中不可避免的指数级分离。对于确定性MDP，我们展示了如何消除完整性假设，显著简化算法。我们进一步将该方法扩展到基于偏好的反馈设置中，证明即使在信息更有限的情况下也能达到等效的统计效率。这些结果构成了基于结果的强化学习的统计特性理解的理论基础。', 'title_zh': '基于结果的在线强化学习：算法与基本限制'}
{'arxiv_id': 'arXiv:2505.20264', 'title': 'We Need to Measure Data Diversity in NLP -- Better and Broader', 'authors': 'Dong Nguyen, Esther Ploeger', 'link': 'https://arxiv.org/abs/2505.20264', 'abstract': 'Although diversity in NLP datasets has received growing attention, the question of how to measure it remains largely underexplored. This opinion paper examines the conceptual and methodological challenges of measuring data diversity and argues that interdisciplinary perspectives are essential for developing more fine-grained and valid measures.', 'abstract_zh': '尽管自然语言处理数据集的多样性已受到越来越多的关注，但如何衡量多样性的问题仍 largely underexplored。本文探讨了衡量数据多样性所面临的概念和方法论挑战，并argues认为跨学科视角对于开发更为精细和有效的衡量方法至关重要。', 'title_zh': '我们需要测量NLP中的数据多样性——更好更广泛'}
{'arxiv_id': 'arXiv:2505.20259', 'title': 'Lifelong Safety Alignment for Language Models', 'authors': 'Haoyu Wang, Zeyu Qin, Yifei Zhao, Chao Du, Min Lin, Xueqian Wang, Tianyu Pang', 'link': 'https://arxiv.org/abs/2505.20259', 'abstract': "LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailbreaking attacks designed to bypass safety alignment. While many existing defenses focus on known types of attacks, it is more critical to prepare LLMs for unseen attacks that may arise during deployment. To address this, we propose a lifelong safety alignment framework that enables LLMs to continuously adapt to new and evolving jailbreaking strategies. Our framework introduces a competitive setup between two components: a Meta-Attacker, trained to actively discover novel jailbreaking strategies, and a Defender, trained to resist them. To effectively warm up the Meta-Attacker, we first leverage the GPT-4o API to extract key insights from a large collection of jailbreak-related research papers. Through iterative training, the first iteration Meta-Attacker achieves a 73% attack success rate (ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks. Meanwhile, the Defender progressively improves its robustness and ultimately reduces the Meta-Attacker's success rate to just 7%, enabling safer and more reliable deployment of LLMs in open-ended environments. The code is available at this https URL.", 'abstract_zh': 'LLMs在应对未知的脱笼攻击方面的终身安全对齐框架', 'title_zh': '终身安全性对齐的语言模型'}
{'arxiv_id': 'arXiv:2505.20254', 'title': 'Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs', 'authors': 'Xiangchen Song, Aashiq Muhamed, Yujia Zheng, Lingjing Kong, Zeyu Tang, Mona T. Diab, Virginia Smith, Kun Zhang', 'link': 'https://arxiv.org/abs/2505.20254', 'abstract': 'Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neural network activations into interpretable features. However, the aspiration to identify a canonical set of features is challenged by the observed inconsistency of learned SAE features across different training runs, undermining the reliability and efficiency of MI research. This position paper argues that mechanistic interpretability should prioritize feature consistency in SAEs -- the reliable convergence to equivalent feature sets across independent runs. We propose using the Pairwise Dictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to operationalize consistency and demonstrate that high levels are achievable (0.80 for TopK SAEs on LLM activations) with appropriate architectural choices. Our contributions include detailing the benefits of prioritizing consistency; providing theoretical grounding and synthetic validation using a model organism, which verifies PW-MCC as a reliable proxy for ground-truth recovery; and extending these findings to real-world LLM data, where high feature consistency strongly correlates with the semantic similarity of learned feature explanations. We call for a community-wide shift towards systematically measuring feature consistency to foster robust cumulative progress in MI.', 'abstract_zh': '稀疏自动编码器（SAEs）在机械可解释性（MI）中是一个重要的工具，用于将神经网络激活分解为可解释的特征。然而，识别一组标准特征的努力受到在不同训练运行中学习到的SAE特征之间一致性不足的挑战，这削弱了MI研究的可靠性和效率。本文认为，机械可解释性应优先考虑SAE中的特征一致性——即在独立运行中可靠地收敛到等效特征集。我们提议使用成对字典均值相关系数（PW-MCC）作为一致性操作化的实际度量，并证明通过适当架构选择可以实现高水平的一致性（LLM激活的TopK SAEs中达到0.80）。我们的贡献包括详细阐述优先考虑一致性的益处；提供理论基础并在模式生物中进行合成验证，验证PW-MCC作为地面真理恢复可靠代理的有效性；并将这些发现扩展到真实世界的LLM数据，其中高特征一致性与学习到的特征解释的语义相似性高度相关。我们呼吁在整个社区范围内系统地衡量特征一致性，以促进MI的稳健累积进步。', 'title_zh': '位置：机制可解释性在SAEs中的优先级应为特征一致性'}
{'arxiv_id': 'arXiv:2505.20249', 'title': 'WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models', 'authors': 'Yongan Yu, Qingchen Hu, Xianda Du, Jiayin Wang, Fengran Mo, Renee Sieber', 'link': 'https://arxiv.org/abs/2505.20249', 'abstract': 'Climate change adaptation requires the understanding of disruptive weather impacts on society, where large language models (LLMs) might be applicable. However, their effectiveness is under-explored due to the difficulty of high-quality corpus collection and the lack of available benchmarks. The climate-related events stored in regional newspapers record how communities adapted and recovered from disasters. However, the processing of the original corpus is non-trivial. In this study, we first develop a disruptive weather impact dataset with a four-stage well-crafted construction pipeline. Then, we propose WXImpactBench, the first benchmark for evaluating the capacity of LLMs on disruptive weather impacts. The benchmark involves two evaluation tasks, multi-label classification and ranking-based question answering. Extensive experiments on evaluating a set of LLMs provide first-hand analysis of the challenges in developing disruptive weather impact understanding and climate change adaptation systems. The constructed dataset and the code for the evaluation framework are available to help society protect against vulnerabilities from disasters.', 'abstract_zh': '气候适应要求理解破坏性天气对社会的影响，其中大型语言模型(LLMs)可能适用。然而，由于高质量语料库收集的难度和可用基准的缺乏，其效果尚待探索。记录在区域报纸中的气候相关事件展示了社区如何适应和恢复灾害。然而，处理原始语料库并非易事。在本研究中，我们首先开发了一个破坏性天气影响数据集，并构建了一个四阶段精心设计的构造管道。然后，我们提出了WXImpactBench，这是第一个用于评估LLMs在破坏性天气影响方面能力的基准。该基准包含两个评估任务：多标签分类和基于排名的问答。对一组LLMs进行的广泛实验提供了第一手分析，揭示了开发破坏性天气影响理解和气候适应系统的挑战。所构建的数据集和评估框架的代码可供社会保护免受灾难的影响。', 'title_zh': 'WXImpactBench: 一项颠覆性的天气影响理解基准，用于评估大型语言模型'}
{'arxiv_id': 'arXiv:2505.20245', 'title': 'KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing', 'authors': 'Rui Li, Quanyu Dai, Zeyu Zhang, Xu Chen, Zhenhua Dong, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2505.20245', 'abstract': "Recent advances in retrieval-augmented generation (RAG) furnish large language models (LLMs) with iterative retrievals of relevant information to handle complex multi-hop questions. These methods typically alternate between LLM reasoning and retrieval to accumulate external information into the LLM's context. However, the ever-growing context inherently imposes an increasing burden on the LLM to perceive connections among critical information pieces, with futile reasoning steps further exacerbating this overload issue. In this paper, we present KnowTrace, an elegant RAG framework to (1) mitigate the context overload and (2) bootstrap higher-quality multi-step reasoning. Instead of simply piling the retrieved contents, KnowTrace autonomously traces out desired knowledge triplets to organize a specific knowledge graph relevant to the input question. Such a structured workflow not only empowers the LLM with an intelligible context for inference, but also naturally inspires a reflective mechanism of knowledge backtracing to identify contributive LLM generations as process supervision data for self-bootstrapping. Extensive experiments show that KnowTrace consistently surpasses existing methods across three multi-hop question answering benchmarks, and the bootstrapped version further amplifies the gains.", 'abstract_zh': '最近在检索增强生成（RAG）方面的进展为大型语言模型（LLMs）提供了迭代的相关信息检索能力，以处理复杂的多跳问题。然而，不断增长的上下文本身对LLM感知关键信息片段之间联系施加了不断增加的负担，而无效的推理步骤进一步加剧了这一负担问题。本文提出了一种简洁的RAG框架——KnowTrace，以（1）减轻上下文负担，（2）实现更高质量的多步推理。KnowTrace 不是简单地堆叠检索到的内容，而是自主地提取所需的知识三元组来组织与输入问题相关的特定知识图谱。这种结构化的工作流程不仅为LLM提供了可用于推理的明晰上下文，还自然启发了一种知识回溯反思机制，以识别有助于LLM生成的过程监督数据，从而实现自我提升。大量实验表明，KnowTrace 在三个多跳问答基准测试中持续超越现有方法，且自提升版本进一步放大了性能提升。', 'title_zh': 'KnowTrace：基于结构化知识追踪的迭代检索增强生成启动方法'}
{'arxiv_id': 'arXiv:2505.20241', 'title': 'DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning', 'authors': 'Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie', 'link': 'https://arxiv.org/abs/2505.20241', 'abstract': "Reasoning has substantially improved the performance of large language models (LLMs) on complicated tasks. Central to the current reasoning studies, Process Reward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning steps and guide the reasoning process. However, extending PRMs to multimodal large language models (MLLMs) introduces challenges. Since multimodal reasoning covers a wider range of tasks compared to text-only scenarios, the resulting distribution shift from the training to testing sets is more severe, leading to greater generalization difficulty. Training a reliable multimodal PRM, therefore, demands large and diverse datasets to ensure sufficient coverage. However, current multimodal reasoning datasets suffer from a marked quality imbalance, which degrades PRM performance and highlights the need for an effective data selection strategy. To address the issues, we introduce DreamPRM, a domain-reweighted training framework for multimodal PRMs which employs bi-level optimization. In the lower-level optimization, DreamPRM performs fine-tuning on multiple datasets with domain weights, allowing the PRM to prioritize high-quality reasoning signals and alleviating the impact of dataset quality imbalance. In the upper-level optimization, the PRM is evaluated on a separate meta-learning dataset; this feedback updates the domain weights through an aggregation loss function, thereby improving the generalization capability of trained PRM. Extensive experiments on multiple multimodal reasoning benchmarks covering both mathematical and general reasoning show that test-time scaling with DreamPRM consistently improves the performance of state-of-the-art MLLMs. Further comparisons reveal that DreamPRM's domain-reweighting strategy surpasses other data selection methods and yields higher accuracy gains than existing test-time scaling approaches.", 'abstract_zh': 'DreamPRM：一种用于多模态PRM的领域重权重训练框架', 'title_zh': '梦PRM：领域加权过程奖励模型用于多模态推理'}
{'arxiv_id': 'arXiv:2505.20235', 'title': 'Variational Deep Learning via Implicit Regularization', 'authors': 'Jonathan Wenger, Beau Coker, Juraj Marusic, John P. Cunningham', 'link': 'https://arxiv.org/abs/2505.20235', 'abstract': 'Modern deep learning models generalize remarkably well in-distribution, despite being overparametrized and trained with little to no explicit regularization. Instead, current theory credits implicit regularization imposed by the choice of architecture, hyperparameters and optimization procedure. However, deploying deep learning models out-of-distribution, in sequential decision-making tasks, or in safety-critical domains, necessitates reliable uncertainty quantification, not just a point estimate. The machinery of modern approximate inference -- Bayesian deep learning -- should answer the need for uncertainty quantification, but its effectiveness has been challenged by our inability to define useful explicit inductive biases through priors, as well as the associated computational burden. Instead, in this work we demonstrate, both theoretically and empirically, how to regularize a variational deep network implicitly via the optimization procedure, just as for standard deep learning. We fully characterize the inductive bias of (stochastic) gradient descent in the case of an overparametrized linear model as generalized variational inference and demonstrate the importance of the choice of parametrization. Finally, we show empirically that our approach achieves strong in- and out-of-distribution performance without tuning of additional hyperparameters and with minimal time and memory overhead over standard deep learning.', 'abstract_zh': '现代深度学习模型在分布内表现出 remarkable 的泛化能力，尽管它们是过参数化的，并且在训练过程中几乎没有显式的正则化。当前的理论归因于架构、超参数和优化过程所引入的隐式正则化。然而，在分布外部署深度学习模型、在顺序决策任务中使用它们或在关键安全领域中使用它们时，需要的是可靠的不确定性量化，而不仅仅是点估计。现代近似推断的工具——贝叶斯深度学习——应该满足这一需求，但其效果受到了我们无法通过先验定义有用的归纳偏置以及由此带来的计算负担的挑战。相反，本文通过优化过程隐式正则化变分深度网络，证明了这种做法的有效性，并在理论上和实验上全面阐述了过参数化线性模型中（随机）梯度下降的归纳偏置，展示了参数化选择的重要性。最后，实验证明，我们的方法在不需要调优额外超参数的情况下，在分布内和分布外均能取得优异性能，并且相较于标准深度学习仅有极小的时间和内存开销。', 'title_zh': '变分深度学习通过隐式正则化'}
{'arxiv_id': 'arXiv:2505.20229', 'title': "From What to How: Attributing CLIP's Latent Components Reveals Unexpected Semantic Reliance", 'authors': 'Maximilian Dreyer, Lorenz Hufe, Jim Berend, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek', 'link': 'https://arxiv.org/abs/2505.20229', 'abstract': 'Transformer-based CLIP models are widely used for text-image probing and feature extraction, making it relevant to understand the internal mechanisms behind their predictions. While recent works show that Sparse Autoencoders (SAEs) yield interpretable latent components, they focus on what these encode and miss how they drive predictions. We introduce a scalable framework that reveals what latent components activate for, how they align with expected semantics, and how important they are to predictions. To achieve this, we adapt attribution patching for instance-wise component attributions in CLIP and highlight key faithfulness limitations of the widely used Logit Lens technique. By combining attributions with semantic alignment scores, we can automatically uncover reliance on components that encode semantically unexpected or spurious concepts. Applied across multiple CLIP variants, our method uncovers hundreds of surprising components linked to polysemous words, compound nouns, visual typography and dataset artifacts. While text embeddings remain prone to semantic ambiguity, they are more robust to spurious correlations compared to linear classifiers trained on image embeddings. A case study on skin lesion detection highlights how such classifiers can amplify hidden shortcuts, underscoring the need for holistic, mechanistic interpretability. We provide code at this https URL.', 'abstract_zh': '基于Transformer的CLIP模型广泛用于文本-图像探查和特征提取，理解其预测背后的内部机制具有重要意义。虽然近期工作表明稀疏自编码器（SAEs）产生可解释的潜在组件，但这些研究主要关注它们编码了什么，而忽视了它们如何驱动预测。我们提出了一个可扩展的框架，揭示潜在组件的作用，它们如何与预期语义对齐，以及它们在预测中的重要性。通过将归因斑图技术适应于实例级别的组件归因，并突显广泛使用的Logit Lens技术的关键忠实性限制，我们结合归因与语义对齐得分，可以自动发现编码语义意外或伪概念的依赖组件。在多个CLIP变体上的应用揭示了与多义词、复合名词、视觉排版和数据集特征相关数百个令人惊讶的组件。尽管文本嵌入仍然容易产生语义模糊，但在图像嵌入上进行训练的线性分类器相比而言更不易受到伪相关的影响。通过对皮肤病变检测的研究案例强调了如何这些分类器放大隐藏捷径，突出了整体、机制性可解释性的需求。我们在下面的链接提供代码：this https URL。', 'title_zh': '从“是什么”到“怎么做”：归因CLIP的潜在组件揭示了意外的语义依赖'}
{'arxiv_id': 'arXiv:2505.20211', 'title': 'Parameter-Efficient Fine-Tuning with Column Space Projection', 'authors': 'Junseo Hwang, Wonguk Cho, Taesup Kim', 'link': 'https://arxiv.org/abs/2505.20211', 'abstract': 'Fine-tuning large language models (LLMs) with minimal computational overhead is essential for efficiently adapting them to downstream tasks under resource constraints. Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), facilitate this by updating only a small subset of parameters. However, recent studies show that LoRA diverges from full fine-tuning (Full FT) in its learning behavior, particularly in terms of spectral properties. Motivated by these findings, we propose PiCa, the first theoretically grounded PEFT method based on the spectral properties of fine-tuned weights. PiCa projects gradients onto the low-rank column subspace of pre-trained weights and exhibits learning patterns more closely aligned with Full FT. Furthermore, we show that combining PiCa with weight sharing drastically reduces the number of trainable parameters without compromising performance, enabling to achieve superior performance than LoRA using 13x fewer trainable parameters. Extensive experiments demonstrate PiCa achieves the state-of-the-art performance compared to existing PEFT methods.', 'abstract_zh': '基于微调权重谱性质的参数高效微调方法PiCa：在较少可训练参数下实现优越性能', 'title_zh': '列空间投影下的参数高效微调'}
{'arxiv_id': 'arXiv:2505.20206', 'title': 'Evaluating Large Language Models for Code Review', 'authors': 'Umut Cihan, Arda İçöz, Vahid Haratian, Eray Tüzün', 'link': 'https://arxiv.org/abs/2505.20206', 'abstract': 'Context: Code reviews are crucial for software quality. Recent AI advances have allowed large language models (LLMs) to review and fix code; now, there are tools that perform these reviews. However, their reliability and accuracy have not yet been systematically evaluated. Objective: This study compares different LLMs\' performance in detecting code correctness and suggesting improvements. Method: We tested GPT4o and Gemini 2.0 Flash on 492 AI generated code blocks of varying correctness, along with 164 canonical code blocks from the HumanEval benchmark. To simulate the code review task objectively, we expected LLMs to assess code correctness and improve the code if needed. We ran experiments with different configurations and reported on the results. Results: With problem descriptions, GPT4o and Gemini 2.0 Flash correctly classified code correctness 68.50% and 63.89% of the time, respectively, and corrected the code 67.83% and 54.26% of the time for the 492 code blocks of varying correctness. Without problem descriptions, performance declined. The results for the 164 canonical code blocks differed, suggesting that performance depends on the type of code. Conclusion: LLM code reviews can help suggest improvements and assess correctness, but there is a risk of faulty outputs. We propose a process that involves humans, called the "Human in the loop LLM Code Review" to promote knowledge sharing while mitigating the risk of faulty outputs.', 'abstract_zh': '基于代码审查的大型语言模型性能研究：从算法生成代码到人类评估的全流程探索', 'title_zh': '评估大型语言模型在代码审查中的应用'}
{'arxiv_id': 'arXiv:2505.20190', 'title': 'Leveraging Descriptions of Emotional Preferences in Recommender Systems', 'authors': 'Tonmoy Hasan, Razvan Bunescu', 'link': 'https://arxiv.org/abs/2505.20190', 'abstract': 'The affective attitude of liking a recommended item reflects just one category in a wide spectrum of affective phenomena that also includes emotions such as entranced or intrigued, moods such as cheerful or buoyant, as well as more fine-grained affective states, such as "pleasantly surprised by the conclusion". In this paper, we introduce a novel recommendation task that can leverage a virtually unbounded range of affective states sought explicitly by the user in order to identify items that, upon consumption, are likely to induce those affective states. Correspondingly, we create a large dataset of user preferences containing expressions of fine-grained affective states that are mined from book reviews, and propose a Transformer-based architecture that leverages such affective expressions as input. We then use the resulting dataset of affective states preferences, together with the linked users and their histories of book readings, ratings, and reviews, to train and evaluate multiple recommendation models on the task of matching recommended items with affective preferences. Experiments show that the best results are obtained by models that can utilize textual descriptions of items and user affective preferences.', 'abstract_zh': '喜欢推荐项目的感情态度仅反映广泛的感情现象谱中的一种，这一谱系还包括如着迷或好奇等情绪，愉快或振奋等 mood，以及更精细的感情状态，如“对结论感到高兴而惊讶”。本文提出了一种新颖的推荐任务，旨在通过用户明确寻求的一系列广泛的感情状态来识别在消费后可能引起这些感情状态的项目。为此，我们创建了一个包含从书籍评论中挖掘而来的情感状态表达的大规模用户偏好数据集，并提出了一种基于 Transformer 的架构，该架构利用这种情感表达作为输入。我们使用情感状态偏好数据集，以及与之关联的用户及其阅读、评分和评论历史记录，对多个推荐模型进行训练和评估，以匹配推荐项目与情感偏好。实验结果显示，能够利用项目文本描述和用户情感偏好的模型效果最佳。', 'title_zh': '利用情感偏好描述在推荐系统中的应用'}
{'arxiv_id': 'arXiv:2505.20184', 'title': 'THiNK: Can Large Language Models Think-aloud?', 'authors': 'Yongan Yu, Mengqian Wu, Yiran Lin, Nikki G. Lobczowski', 'link': 'https://arxiv.org/abs/2505.20184', 'abstract': "Assessing higher-order thinking skills in large language models (LLMs) remains a fundamental challenge, especially in tasks that go beyond surface-level accuracy. In this work, we propose THiNK (Testing Higher-order Notion of Knowledge), a multi-agent, feedback-driven evaluation framework grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative task of problem generation, critique, and revision, encouraging LLMs to think-aloud through step-by-step reflection and refinement. This enables a systematic evaluation of both lower-order (e.g., remember, understand) and higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven state-of-the-art LLMs and perform a detailed cognitive analysis of their outputs. Results reveal that while models reliably perform lower-order categories well, they struggle with applying knowledge in realistic contexts and exhibit limited abstraction. Structured feedback loops significantly improve reasoning performance, particularly in higher-order thinking. Qualitative evaluations further confirm that THiNK-guided outputs better align with domain logic and problem structure. The code of our framework provides a scalable methodology for probing and enhancing LLM reasoning, offering new directions for evaluation grounded in learning science, which is available at our GitHub repository.", 'abstract_zh': '评估大规模语言模型的高级思维技能仍然是一个基本挑战，尤其是在超越表面准确性任务的情况下。在此项工作中，我们提出了THiNK（Testing Higher-order Notion of Knowledge）多智能体、基于反馈的评估框架，该框架基于布卢姆分类法。THiNK将推理评估框架视为一个问题生成、批判和修订的迭代任务，鼓励LLMs通过逐步反思和精炼来思考。这使得能够系统地评估较低层次（如记忆、理解）和较高层次（如评价、创造）的思维技能。我们将在七种最先进的LLM上应用THiNK，并对它们的输出进行全面的认知分析。结果表明，虽然模拟能够可靠地执行较低层次的类别，但在现实场景中应用知识和抽象方面却存在局限性。结构化的反馈循环显著提高了推理性能，特别是在高级思维技能方面。定性评估进一步证实，THiNK导向的输出更好地与领域逻辑和问题结构相一致。我们框架的代码提供了一种可扩展的方法来探测和增强LLM推理能力，为基于学习科学的新评估方向提供了新的途径，该代码可在我们的GitHub存储库中获取。', 'title_zh': 'THiNK: 大型语言模型能进行自我讲解吗？'}
{'arxiv_id': 'arXiv:2505.20166', 'title': 'From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data', 'authors': 'Chun-Yi Kuan, Hung-yi Lee', 'link': 'https://arxiv.org/abs/2505.20166', 'abstract': "Audio-aware large language models (ALLMs) have recently made great strides in understanding and processing audio inputs. These models are typically adapted from text-based large language models (LLMs) through additional training on audio-related tasks. However, this adaptation process presents two major limitations. First, ALLMs often suffer from catastrophic forgetting, where important textual capabilities such as instruction-following are lost after training on audio data. In some cases, models may even hallucinate sounds that are not present in the input audio, raising concerns about their reliability. Second, achieving cross-modal alignment between audio and language typically relies on large collections of task-specific question-answer pairs for instruction tuning, making the process resource-intensive. To address these issues, we leverage the backbone LLMs from ALLMs to synthesize general-purpose caption-style alignment data. We refer to this process as bootstrapping audio-language alignment via synthetic data generation from backbone LLMs (BALSa). Building on BALSa, we introduce LISTEN (Learning to Identify Sounds Through Extended Negative Samples), a contrastive-like training method designed to improve ALLMs' ability to distinguish between present and absent sounds. We further extend BALSa to multi-audio scenarios, where the model either explains the differences between audio inputs or produces a unified caption that describes them all, thereby enhancing audio-language alignment. Experimental results indicate that our method effectively mitigates audio hallucinations while reliably maintaining strong performance in audio understanding, reasoning, and instruction-following skills. Moreover, incorporating multi-audio training further enhances the model's comprehension and reasoning capabilities. Overall, BALSa offers an efficient and scalable approach to the development of ALLMs.", 'abstract_zh': 'Audio-aware 大语言模型 (ALLMs) 在理解和处理音频输入方面取得了显著进展。这些模型通常通过额外的音频相关任务训练，从基于文本的大语言模型 (LLMs) 调整而来。然而，这一调整过程存在两大局限。首先，ALLMs 经常遭受灾难性遗忘，即在处理音频数据后，可能会丧失重要的文本能力，如指令遵循。在某些情况下，模型甚至会想象出输入音频中不存在的声音，这对其可靠性提出了质疑。其次，实现音频与语言的跨模态对齐通常依赖于大量特定任务的问题-答案对，用于指令调优，使过程耗资巨大。为解决这些问题，我们利用 ALLMs 的骨干 LLM 组件来合成通用的旁注风格对齐数据。我们称这一过程为基于骨干 LLM 生成合成数据的音频-语言对齐自举 (BALSa)。基于 BALSa，我们引入了 LISTEN (Learning to Identify Sounds Through Extended Negative Samples)，一种对比训练方法，旨在提高 ALLMs 区分存在和不存在声音的能力。我们进一步将 BALSa 扩展到多音频场景中，其中模型要么解释音频输入之间的差异，要么生成一个统一的旁注来描述所有输入，从而增强音频-语言对齐。实验结果表明，我们的方法有效减少了音频错觉，同时可靠地保持了在音频理解、推理和指令遵循技能方面的强大表现。此外，多音频训练进一步增强了模型的理解和推理能力。总体而言，BALSa 提供了一种高效且可扩展的方法来开发 ALLMs。', 'title_zh': '从对齐到提升：利用合成数据 bootstrapping 音频-语言对齐'}
{'arxiv_id': 'arXiv:2505.20161', 'title': 'Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning', 'authors': 'Jaehun Jung, Seungju Han, Ximing Lu, Skyler Hallinan, David Acuna, Shrimai Prabhumoye, Mostafa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi', 'link': 'https://arxiv.org/abs/2505.20161', 'abstract': "Effective generalization in language models depends critically on the diversity of their training data. Yet existing diversity metrics often fall short of this goal, relying on surface-level heuristics that are decoupled from model behavior. This motivates us to ask: What kind of diversity in training data actually drives generalization in language models -- and how can we measure and amplify it? Through large-scale empirical analyses spanning over 300 training runs, carefully controlled for data scale and quality, we show that data diversity can be a strong predictor of generalization in LLM reasoning -- as measured by average model performance on unseen out-of-distribution benchmarks. We introduce G-Vendi, a metric that quantifies diversity via the entropy of model-induced gradients. Despite using a small off-the-shelf proxy model for gradients, G-Vendi consistently outperforms alternative measures, achieving strong correlation (Spearman's $\\rho \\approx 0.9$) with out-of-distribution (OOD) performance on both natural language inference (NLI) and math reasoning tasks. Building on this insight, we present Prismatic Synthesis, a framework for generating diverse synthetic data by targeting underrepresented regions in gradient space. Experimental results show that Prismatic Synthesis consistently improves model performance as we scale synthetic data -- not just on in-distribution test but across unseen, out-of-distribution benchmarks -- significantly outperforming state-of-the-art models that rely on 20 times larger data generator than ours. For example, PrismMath-7B, our model distilled from a 32B LLM, outperforms R1-Distill-Qwen-7B -- the same base model trained on proprietary data generated by 671B R1 -- on 6 out of 7 challenging benchmarks.", 'abstract_zh': '有效的语言模型泛化依赖于其训练数据的多样性。现有的多样性度量往往未能达到这一目标，依靠与模型行为脱钩的表面级启发式方法。这促使我们思考：哪些类型的训练数据多样性实际上能够驱动语言模型的泛化能力——我们如何衡量和放大这种多样性？通过跨越300多次训练运行的大规模实证分析，严格控制数据规模和质量，我们展示了数据多样性可以是大型语言模型推理中泛化能力的一个强大预测指标——以未见过的分布外基准上的平均模型性能为准。我们引入了G-Vendi度量，通过模型诱导梯度的熵量化多样性。尽管使用了一个小型现成的梯度代理模型，G-Vendi始终优于其他度量标准，在自然语言推理（NLI）和数学推理任务上的分布外（OOD）性能上实现了高度的相关性（斯皮尔曼相关系数ρ ≈ 0.9）。在此基础上，我们提出了棱镜合成框架，该框架通过瞄准梯度空间中未被充分代表的区域生成多样化的合成数据。实验结果表明，随着合成数据规模的增加，棱镜合成持续提高模型性能——不仅在分布在内测试中，在未见过的分布外基准上也是如此，显著优于依赖数据生成器比我们大20倍的最新模型。例如，从一个32B大型语言模型中精简得到的PrismMath-7B，在7个具有挑战性的基准中有6个上优于基于671B R1生成的私有数据训练的R1-Distill-Qwen-7B。', 'title_zh': '棱柱合成：基于梯度的数据多样化增强大语言模型推理的泛化能力'}
{'arxiv_id': 'arXiv:2505.20152', 'title': 'Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models', 'authors': 'Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li', 'link': 'https://arxiv.org/abs/2505.20152', 'abstract': 'Benefiting from contrastively trained visual encoders on large-scale natural scene images, Large Multimodal Models (LMMs) have achieved remarkable performance across various visual perception tasks. However, the inherent limitations of contrastive learning upon summarized descriptions fundamentally restrict the capabilities of models in meticulous reasoning, particularly in crucial scenarios of geometric problem-solving. To enhance geometric understanding, we propose a novel hard negative contrastive learning framework for the vision encoder, which combines image-based contrastive learning using generation-based hard negatives created by perturbing diagram generation code, and text-based contrastive learning using rule-based negatives derived from modified geometric descriptions and retrieval-based negatives selected based on caption similarity. We train CLIP using our strong negative learning method, namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for geometric problem-solving. Experiments show that our trained model, MMGeoLM, significantly outperforms other open-source models on three geometric reasoning benchmarks. Even with a size of 7B, it can rival powerful closed-source models like GPT-4o. We further study the impact of different negative sample construction methods and the number of negative samples on the geometric reasoning performance of LMM, yielding fruitful conclusions. The code and dataset are available at this https URL.', 'abstract_zh': '受益于大规模自然场景图像上对比训练的视觉编码器，多模态大型模型（LMMs）在各种视觉感知任务中取得了显著性能。然而，对比学习在总结描述上的固有限制从根本上限制了模型在细致推理能力，特别是在几何问题求解的关键场景中的能力。为了提升几何理解，我们提出了一种新颖的硬负样本对比学习框架，该框架结合了基于图像的对比学习和基于生成的硬负样本扰动图示生成代码的对比学习，以及基于规则的负样本和检索的负样本的文本对比学习，这些负样本分别来源于修改的几何描述和基于标题相似性的选择。我们使用一种强大的负样本学习方法，即MMCLIP（多模态数学CLIP）对CLIP进行训练，并且进一步训练了一个LMM用于几何问题求解。实验表明，我们训练的模型MMGeoLM在三个几何推理基准测试中显著优于其他开源模型，即使参数量为7B，也能与强大的闭源模型如GPT-4o竞争。我们还研究了不同负样本构建方法和负样本数量对立体型推理性能的影响，得出了富有成效的结论。相关代码和数据集可在以下链接获取。', 'title_zh': '大规模多模态模型中精细几何理解的硬负样本对比学习'}
{'arxiv_id': 'arXiv:2505.20150', 'title': 'On the (Non) Injectivity of Piecewise Linear Janossy Pooling', 'authors': 'Ilai Reshef, Nadav Dym', 'link': 'https://arxiv.org/abs/2505.20150', 'abstract': 'Multiset functions, which are functions that map multisets to vectors, are a fundamental tool in the construction of neural networks for multisets and graphs. To guarantee that the vector representation of the multiset is faithful, it is often desirable to have multiset mappings that are both injective and bi-Lipschitz. Currently, there are several constructions of multiset functions achieving both these guarantees, leading to improved performance in some tasks but often also to higher compute time than standard constructions. Accordingly, it is natural to inquire whether simpler multiset functions achieving the same guarantees are available. In this paper, we make a large step towards giving a negative answer to this question. We consider the family of k-ary Janossy pooling, which includes many of the most popular multiset models, and prove that no piecewise linear Janossy pooling function can be injective. On the positive side, we show that when restricted to multisets without multiplicities, even simple deep-sets models suffice for injectivity and bi-Lipschitzness.', 'abstract_zh': '多集函数是构建处理多集和图的神经网络的基本工具。为了保证多集的向量表示是忠实的，往往需要多集映射既注入性又双利普希茨性。目前，有一些构造多集函数的方法同时实现了这两种保证，尽管这些方法在某些任务上的性能有所提升，但通常也伴随着更高的计算时间。因此，自然会疑问是否可以找到更简单的多集函数以达到相同的保证。在本文中，我们朝着给出否定答案的方向迈出了重要一步。我们考虑了k-元詹诺西池化族，其中包括了许多最流行的多集模型，并证明了没有分段线性詹诺西池化函数可以是注入性的。在正面结果方面，我们证明在没有重复元素的多集情况下，即使是简单的深度集模型也足以实现注入性和双利普希茨性。', 'title_zh': '关于-piecewise线性Janossy池化是否存在注入性'}
{'arxiv_id': 'arXiv:2505.20149', 'title': 'Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases', 'authors': 'Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Cheng-Kai Lu, Jia-Kang Wang, Tzu-Lun Huang', 'link': 'https://arxiv.org/abs/2505.20149', 'abstract': 'This paper focuses on using few-shot learning to improve the accuracy of classifying OCT diagnosis images with major and rare classes. We used the GAN-based augmentation strategy as a baseline and introduced several novel methods to further enhance our model. The proposed strategy contains U-GAT-IT for improving the generative part and uses the data balance technique to narrow down the skew of accuracy between all categories. The best model obtained was built with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an overall accuracy of 97.85%, representing a significant improvement over the original baseline.', 'abstract_zh': '本论文聚焦于使用少样本学习提高OCT诊断图像主要类和稀见类分类准确性的方法。我们以基于GAN的数据增强策略为基础，并引入了几种新颖的方法以进一步增强模型性能。所提出的方法包括使用U-GAT-IT改进生成部分，并采用数据平衡技术以缩小各类别之间准确率的偏斜度。所获得的最佳模型采用CBAM注意力机制并 fine-tune InceptionV3，实现了整体准确率为97.85%的结果，相较于原始基线有显著提升。', 'title_zh': 'OCT图像分类中罕见视网膜疾病少样本学习的改进策略'}
{'arxiv_id': 'arXiv:2505.20139', 'title': "StructEval: Benchmarking LLMs' Capabilities to Generate Structural Outputs", 'authors': 'Jialin Yang, Dongfu Jiang, Lipeng He, Sherman Siu, Yuxuan Zhang, Disen Liao, Zhuofeng Li, Huaye Zeng, Yiming Jia, Haozhe Wang, Benjamin Schneider, Chi Ruan, Wentao Ma, Zhiheng Lyu, Yifei Wang, Yi Lu, Quy Duc Do, Ziyan Jiang, Ping Nie, Wenhu Chen', 'link': 'https://arxiv.org/abs/2505.20139', 'abstract': "As Large Language Models (LLMs) become integral to software development workflows, their ability to generate structured outputs has become critically important. We introduce StructEval, a comprehensive benchmark for evaluating LLMs' capabilities in producing both non-renderable (JSON, YAML, CSV) and renderable (HTML, React, SVG) structured formats. Unlike prior benchmarks, StructEval systematically evaluates structural fidelity across diverse formats through two paradigms: 1) generation tasks, producing structured output from natural language prompts, and 2) conversion tasks, translating between structured formats. Our benchmark encompasses 18 formats and 44 types of task, with novel metrics for format adherence and structural correctness. Results reveal significant performance gaps, even state-of-the-art models like o1-mini achieve only 75.58 average score, with open-source alternatives lagging approximately 10 points behind. We find generation tasks more challenging than conversion tasks, and producing correct visual content more difficult than generating text-only structures.", 'abstract_zh': '随着大型语言模型（LLMs）在软件开发工作流中发挥越来越重要的作用，其生成结构化输出的能力变得至关重要。我们介绍了StructEval，这是一个全面的基准，用于评估LLMs在生成非渲染格式（JSON、YAML、CSV）和渲染格式（HTML、React、SVG）的结构化格式方面的能力。与其他基准不同，StructEval通过两种范式系统地评估了不同格式的结构保真度：1）生成任务，从自然语言提示生成结构化输出；2）转换任务，进行格式之间的转换。该基准涵盖了18种格式和44种任务类型，并引入了新的格式遵守性和结构正确性的指标。结果表明，即使是最先进的模型如o1-mini也只能获得75.58的平均分数，开源替代品落后约10分。我们发现生成任务比转换任务更具有挑战性，生成正确的视觉内容比生成纯文本结构更困难。', 'title_zh': 'StructEval: 评估大型语言模型生成结构性输出的能力'}
{'arxiv_id': 'arXiv:2505.20137', 'title': 'Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks', 'authors': 'Cédric Goemaere, Gaspard Oliviers, Rafal Bogacz, Thomas Demeester', 'link': 'https://arxiv.org/abs/2505.20137', 'abstract': "Predictive Coding (PC) offers a biologically plausible alternative to backpropagation for neural network training, yet struggles with deeper architectures. This paper identifies the root cause: an inherent signal decay problem where gradients attenuate exponentially with depth, becoming computationally negligible due to numerical precision constraints. To address this fundamental limitation, we introduce Error Optimization (EO), a novel reparameterization that preserves PC's theoretical properties while eliminating signal decay. By optimizing over prediction errors rather than states, EO enables signals to reach all layers simultaneously and without attenuation, converging orders of magnitude faster than standard PC. Experiments across multiple architectures and datasets demonstrate that EO matches backpropagation's performance even for deeper models where conventional PC struggles. Besides practical improvements, our work provides theoretical insight into PC dynamics and establishes a foundation for scaling biologically-inspired learning to deeper architectures on digital hardware and beyond.", 'abstract_zh': 'Predictive Coding (PC)的误差优化(EO)提供了生物可行性替代反向传播的方法，但面对更深的架构时仍然存在信号衰减问题。本文识别了根本原因，并提出了一种新的重新参数化方法误差优化(EO)，该方法保留了PC的理论特性同时消除了信号衰减。通过优化预测误差而非状态，EO能够使信号同时无衰减地传递到所有层，从而比标准PC快多个数量级地收敛。在多种架构和数据集上的实验表明，EO即使在传统PC表现不佳的更深模型中也能够与反向传播的性能相当。除了实际改进，我们的工作还提供了关于PC动力学的理论洞见，并为在数字硬件及其更广泛的领域内扩展生物启发式学习到更深的架构奠定了基础。', 'title_zh': '误差优化：克服深度预测编码网络中的指数信号衰减'}
{'arxiv_id': 'arXiv:2505.20132', 'title': 'Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks', 'authors': 'Safa Hamreras, Sukhbinder Singh, Román Orús', 'link': 'https://arxiv.org/abs/2505.20132', 'abstract': 'Tensorizing a neural network involves reshaping some or all of its dense weight matrices into higher-order tensors and approximating them using low-rank tensor network decompositions. This technique has shown promise as a model compression strategy for large-scale neural networks. However, despite encouraging empirical results, tensorized neural networks (TNNs) remain underutilized in mainstream deep learning. In this position paper, we offer a perspective on both the potential and current limitations of TNNs. We argue that TNNs represent a powerful yet underexplored framework for deep learning--one that deserves greater attention from both engineering and theoretical communities. Beyond compression, we highlight the value of TNNs as a flexible class of architectures with distinctive scaling properties and increased interpretability. A central feature of TNNs is the presence of bond indices, which introduce new latent spaces not found in conventional networks. These internal representations may provide deeper insight into the evolution of features across layers, potentially advancing the goals of mechanistic interpretability. We conclude by outlining several key research directions aimed at overcoming the practical barriers to scaling and adopting TNNs in modern deep learning workflows.', 'abstract_zh': 'Tensor化神经网络涉及将某些或全部其稠密权重矩阵重塑为高阶张量，并使用低秩张量网络分解进行逼近。这种技术作为一种大规模神经网络的模型压缩策略显示出潜力。然而，尽管有令人鼓舞的实证结果，TNNs在主流深度学习中的应用仍然相对有限。在本文中，我们从潜在能力和当前局限性两个方面探讨了TNNs的观点。我们认为，TNNs代表了一种强大而未充分探索的深度学习框架，值得从工程和理论两个社区给予更多关注。除了压缩，我们还强调了TNNs作为一种具有独特缩放特性和增强可解释性的灵活网络架构的价值。TNNs的一个核心特征是存在键指数，这引入了传统网络中未发现的新潜在空间，这些内部表示可能为特征在各层之间的演变提供更深入的洞察，有助于实现机制可解释性的目标。最后，我们概述了几项关键研究方向，旨在克服扩展和采用TNNs的实际障碍，使其更好地融入现代深度学习工作流中。', 'title_zh': '张量ization是一种强大但尚未充分利用的神经网络压缩和可解释性工具。'}
{'arxiv_id': 'arXiv:2505.20113', 'title': "Named Entity Recognition in Historical Italian: The Case of Giacomo Leopardi's Zibaldone", 'authors': 'Cristian Santini, Laura Melosi, Emanuele Frontoni', 'link': 'https://arxiv.org/abs/2505.20113', 'abstract': "The increased digitization of world's textual heritage poses significant challenges for both computer science and literary studies. Overall, there is an urgent need of computational techniques able to adapt to the challenges of historical texts, such as orthographic and spelling variations, fragmentary structure and digitization errors. The rise of large language models (LLMs) has revolutionized natural language processing, suggesting promising applications for Named Entity Recognition (NER) on historical documents. In spite of this, no thorough evaluation has been proposed for Italian texts. This research tries to fill the gap by proposing a new challenging dataset for entity extraction based on a corpus of 19th century scholarly notes, i.e. Giacomo Leopardi's Zibaldone (1898), containing 2,899 references to people, locations and literary works. This dataset was used to carry out reproducible experiments with both domain-specific BERT-based models and state-of-the-art LLMs such as LLaMa3.1. Results show that instruction-tuned models encounter multiple difficulties handling historical humanistic texts, while fine-tuned NER models offer more robust performance even with challenging entity types such as bibliographic references.", 'abstract_zh': '世界文本遗产的数字化增加对计算机科学和文学研究提出了重大挑战。总体而言，迫切需要能够适应历史文本挑战的计算技术，如文字拼写变化、碎片化结构和数字化错误。大型语言模型的兴起已 revolutionized 自然语言处理，表明Named Entity Recognition (NER) 在历史文件上的潜在应用前景。尽管如此，尚未对意大利文本进行全面评估。本研究尝试通过基于19世纪学者笔记的新的挑战性数据集来填补这一空白，即詹科莫·莱翁帕迪的《杂录》（1898年），该数据集包含2,899个关于人物、地点和文学作品的引用。该数据集用于使用领域特定的BERT基模型和最先进的LLM（如LaMa3.1）进行可复现的实验。结果表明，指令调整模型在处理历史人文学科文本时遇到多种困难，而微调的NER模型即使在挑战性实体类型（如参考文献）上也能提供更稳健的性能。', 'title_zh': '历史意大利语中的命名实体识别：杰阿科莫·莱 Ammo·利的《杂录》案例研究'}
{'arxiv_id': 'arXiv:2505.20112', 'title': 'ResSVD: Residual Compensated SVD for Large Language Model Compression', 'authors': 'Haolei Bai, Siyong Jian, Tuo Liang, Yu Yin, Huan Wang', 'link': 'https://arxiv.org/abs/2505.20112', 'abstract': 'Large language models (LLMs) have demonstrated impressive capabilities in a wide range of downstream natural language processing tasks. Nevertheless, their considerable sizes and memory demands hinder practical deployment, underscoring the importance of developing efficient compression strategies. Singular value decomposition (SVD) decomposes a matrix into orthogonal components, enabling efficient low-rank approximation. This is particularly suitable for LLM compression, where weight matrices often exhibit significant redundancy. However, current SVD-based methods neglect the residual matrix from truncation, resulting in significant truncation loss. Additionally, compressing all layers of the model results in severe performance degradation. To overcome these limitations, we propose ResSVD, a new post-training SVD-based LLM compression method. Specifically, we leverage the residual matrix generated during the truncation process to reduce truncation loss. Moreover, under a fixed overall compression ratio, we selectively compress the last few layers of the model, which mitigates error propagation and significantly improves the performance of compressed this http URL evaluations of ResSVD on diverse LLM families and multiple benchmark datasets indicate that ResSVD consistently achieves superior performance over existing counterpart methods, demonstrating its practical effectiveness.', 'abstract_zh': '大型语言模型（LLMs）在各类下游自然语言处理任务中展现了令人印象深刻的性能。然而，其巨大的尺寸和内存需求阻碍了实际部署，突显了开发高效压缩策略的重要性。奇异值分解（SVD）将矩阵分解为正交组件，实现有效的低秩近似。这特别适用于LLM压缩，因为权重矩阵常表现出显著的冗余性。然而，当前的SVD基方法忽略了截断过程中的残差矩阵，导致了显著的截断损失。此外，压缩全部模型层会导致严重的性能下降。为克服这些限制，我们提出了一种新的后训练SVD基LLM压缩方法——ResSVD。具体而言，我们利用截断过程中生成的残差矩阵来减少截断损失。在固定的整体压缩率下，我们选择性地压缩模型的最后几层，这减少了误差传播并显著提高了压缩模型的性能。在不同LLM家族和多个基准数据集上的评估结果显示，ResSVD在对比现有方法时始终表现出更优的性能，证明了其实用有效性。', 'title_zh': 'ResSVD: 剩余补偿SVD大语言模型压缩'}
{'arxiv_id': 'arXiv:2505.20110', 'title': 'Proxy-Free GFlowNet', 'authors': 'Ruishuo Chen, Xun Wang, Rui Hu, Zhuoran Li, Longbo Huang', 'link': 'https://arxiv.org/abs/2505.20110', 'abstract': 'Generative Flow Networks (GFlowNets) are a promising class of generative models designed to sample diverse, high-reward structures by modeling distributions over compositional objects. In many real-world applications, obtaining the reward function for such objects is expensive, time-consuming, or requires human input, making it necessary to train GFlowNets from historical datasets. Most existing methods adopt a model-based approach, learning a proxy model from the dataset to approximate the reward function. However, this strategy inherently ties the quality of the learned policy to the accuracy of the proxy, introducing additional complexity and uncertainty into the training process. To overcome these limitations, we propose \\textbf{Trajectory-Distilled GFlowNet (TD-GFN)}, a \\emph{proxy-free} training framework that eliminates the need for out-of-dataset reward queries. Our method is motivated by the key observation that different edges in the associated directed acyclic graph (DAG) contribute unequally to effective policy learning. TD-GFN leverages inverse reinforcement learning to estimate edge-level rewards from the offline dataset, which are then used to ingeniously prune the DAG and guide backward trajectory sampling during training. This approach directs the policy toward high-reward regions while reducing the complexity of model fitting. Empirical results across multiple tasks show that TD-GFN trains both efficiently and reliably, significantly outperforming existing baselines in convergence speed and sample quality.', 'abstract_zh': '轨迹提炼生成流网络（Trajectory-Distilled GFlowNets）：一种无代理模型的训练框架', 'title_zh': '无代理GFlowNet'}
{'arxiv_id': 'arXiv:2505.20109', 'title': 'Language-Agnostic Suicidal Risk Detection Using Large Language Models', 'authors': 'June-Woo Kim, Wonkyo Oh, Haram Yoon, Sung-Hoon Yoon, Dae-Jin Kim, Dong-Ho Lee, Sang-Yeol Lee, Chan-Mo Yang', 'link': 'https://arxiv.org/abs/2505.20109', 'abstract': 'Suicidal risk detection in adolescents is a critical challenge, yet existing methods rely on language-specific models, limiting scalability and generalization. This study introduces a novel language-agnostic framework for suicidal risk assessment with large language models (LLMs). We generate Chinese transcripts from speech using an ASR model and then employ LLMs with prompt-based queries to extract suicidal risk-related features from these transcripts. The extracted features are retained in both Chinese and English to enable cross-linguistic analysis and then used to fine-tune corresponding pretrained language models independently. Experimental results show that our method achieves performance comparable to direct fine-tuning with ASR results or to models trained solely on Chinese suicidal risk-related features, demonstrating its potential to overcome language constraints and improve the robustness of suicidal risk assessment.', 'abstract_zh': '青少年自杀风险检测是一个关键挑战，现有方法依赖于特定语言的模型，限制了其可扩展性和通用性。本研究提出了一种基于大规模语言模型的无语言障碍的自杀风险评估框架。我们使用ASR模型生成中文 transcript，然后利用基于提示的查询大规模语言模型从这些 transcript 中提取与自杀风险相关的特征。提取的特征同时保留中文和英文版本，以实现跨语言分析，并独立用于预训练语言模型的微调。实验结果表明，我们的方法在性能上与直接使用ASR结果进行微调或仅使用中文自杀风险相关特征训练的模型相当，证明了其克服语言限制、提高自杀风险评估稳健性的潜力。', 'title_zh': '无需自杀风险检测的语言依存性Large语言模型方法'}
{'arxiv_id': 'arXiv:2505.20100', 'title': 'AdaTP: Attention-Debiased Token Pruning for Video Large Language Models', 'authors': 'Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding', 'link': 'https://arxiv.org/abs/2505.20100', 'abstract': 'Video Large Language Models (Video LLMs) have achieved remarkable results in video understanding tasks. However, they often suffer from heavy computational overhead due to the large number of visual tokens generated from multiple video frames. Existing visual token compression methods often rely on attention scores from language models as guidance. However, these scores exhibit inherent biases: global bias reflects a tendency to focus on the two ends of the visual token sequence, while local bias leads to an over-concentration on the same spatial positions across different frames. To address the issue of attention bias, we propose $\\textbf{A}$ttention-$\\textbf{D}$ebi$\\textbf{a}$sed $\\textbf{T}$oken $\\textbf{P}$runing for Video Large Language Models ($\\textbf{AdaTP}$), a novel token pruning pipeline for Video LLMs. AdaTP integrates two dedicated debiasing modules into the pipeline, targeting global attention bias and local attention bias, respectively. Without the need for additional training, our method significantly reduces the computational overhead of Video LLMs while retaining the performance of vanilla models. Extensive evaluation shows that AdaTP achieves state-of-the-art performance in various commonly used video understanding benchmarks. In particular, on LLaVA-OneVision-7B, AdaTP maintains performance without degradation while using only up to $27.3\\%$ FLOPs compared to the vanilla model. Our code will be released soon.', 'abstract_zh': '视频大型语言模型中的注意力去偏Token裁剪（Attention-Debiased Token Pruning for Video Large Language Models, AdaTP）', 'title_zh': 'AdaTP: 基于注意力偏差的_token剪枝方法用于视频大型语言模型'}
{'arxiv_id': 'arXiv:2505.20099', 'title': 'Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities', 'authors': 'Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang', 'link': 'https://arxiv.org/abs/2505.20099', 'abstract': "Large language models (LLMs) have demonstrated remarkable performance on question-answering (QA) tasks because of their superior capabilities in natural language understanding and generation. However, LLM-based QA struggles with complex QA tasks due to poor reasoning capacity, outdated knowledge, and hallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs) for QA to address the above challenges. In this survey, we propose a new structured taxonomy that categorizes the methodology of synthesizing LLMs and KGs for QA according to the categories of QA and the KG's role when integrating with LLMs. We systematically survey state-of-the-art advances in synthesizing LLMs and KGs for QA and compare and analyze these approaches in terms of strength, limitations, and KG requirements. We then align the approaches with QA and discuss how these approaches address the main challenges of different complex QA. Finally, we summarize the advancements, evaluation metrics, and benchmark datasets and highlight open challenges and opportunities.", 'abstract_zh': '大型语言模型（LLMs）在问答（QA）任务上因其在自然语言理解和生成方面的出色能力而表现出色。然而，基于LLM的问答在处理复杂的问答任务时因推理能力差、知识过时和幻觉等问题而遇到困难。多项近期工作通过将LLMs与知识图谱（KGs）结合来解决上述挑战。在本文综述中，我们提出了一种新的结构化分类法，根据问答类型和知识图谱在集成LLMs时的角色来分类合成LLMs和KGs的方法。我们系统地综述了合成LLMs和KGs用于问答的最新进展，并从优势、局限性和KG需求方面对比和分析这些方法。然后将这些方法与问答类型对齐，并讨论这些方法如何解决不同复杂问答的主要挑战。最后，我们总结了这些方法的进步、评估指标和基准数据集，并指出了开放的挑战和机遇。', 'title_zh': '大型语言模型与知识图谱结合进行问答：综述与机遇'}
{'arxiv_id': 'arXiv:2505.20096', 'title': 'MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning', 'authors': 'Thang Nguyen, Peter Chin, Yu-Wing Tai', 'link': 'https://arxiv.org/abs/2505.20096', 'abstract': 'We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on either end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, to tackle each stage of the RAG pipeline with task-aware reasoning. Ambiguities may arise from underspecified queries, sparse or indirect evidence in retrieved documents, or the need to integrate information scattered across multiple sources. MA-RAG mitigates these challenges by decomposing the problem into subtasks, such as query disambiguation, evidence extraction, and answer synthesis, and dispatching them to dedicated agents equipped with chain-of-thought prompting. These agents communicate intermediate reasoning and progressively refine the retrieval and synthesis process. Our design allows fine-grained control over information flow without any model fine-tuning. Crucially, agents are invoked on demand, enabling a dynamic and efficient workflow that avoids unnecessary computation. This modular and reasoning-driven architecture enables MA-RAG to deliver robust, interpretable results. Experiments on multi-hop and ambiguous QA benchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free baselines and rivals fine-tuned systems, validating the effectiveness of collaborative agent-based reasoning in RAG.', 'abstract_zh': '多智能体 Retrieval-Augmented Generation (MA-RAG): 一种解决复杂信息搜索任务中固有模糊性和推理挑战的多智能体框架', 'title_zh': 'MA-RAG：基于协作链式推理的多agents检索增强生成'}
{'arxiv_id': 'arXiv:2505.20089', 'title': 'Homophily Enhanced Graph Domain Adaptation', 'authors': 'Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, Qiuhao Zeng, Gezheng Xu, Charles Ling, Boyu Wang', 'link': 'https://arxiv.org/abs/2505.20089', 'abstract': 'Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. In this paper, we highlight the significance of graph homophily, a pivotal factor for graph domain alignment, which, however, has long been overlooked in existing approaches. Specifically, our analysis first reveals that homophily discrepancies exist in benchmarks. Moreover, we also show that homophily discrepancies degrade GDA performance from both empirical and theoretical aspects, which further underscores the importance of homophily alignment in GDA. Inspired by this finding, we propose a novel homophily alignment algorithm that employs mixed filters to smooth graph signals, thereby effectively capturing and mitigating homophily discrepancies between graphs. Experimental results on a variety of benchmarks verify the effectiveness of our method.', 'abstract_zh': '图域适应（GDA）将有标签的源图的知识转移到无标签的目标图上，以应对标签稀缺的挑战。在本文中，我们强调了图同质性的重要性，这是图域对齐的关键因素，但这一因素在现有方法中长期被忽视。具体来说，我们的分析首先揭示了基准中存在的同质性差异。此外，我们还展示了同质性差异从实证和理论两个方面都降低了GDA性能，进一步突显了同质性对齐在GDA中的重要性。受这一发现的启发，我们提出了一种新的同质性对齐算法，该算法使用混合滤波器平滑图信号，从而有效地捕捉和缓解图之间的同质性差异。在多种基准上的实验结果验证了该方法的有效性。', 'title_zh': '同质性增强的图域适应'}
{'arxiv_id': 'arXiv:2505.20085', 'title': 'Explanation User Interfaces: A Systematic Literature Review', 'authors': 'Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo', 'link': 'https://arxiv.org/abs/2505.20085', 'abstract': "Artificial Intelligence (AI) is one of the major technological advancements of this century, bearing incredible potential for users through AI-powered applications and tools in numerous domains. Being often black-box (i.e., its decision-making process is unintelligible), developers typically resort to eXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour of AI models to produce systems that are transparent, fair, reliable, and trustworthy. However, presenting explanations to the user is not trivial and is often left as a secondary aspect of the system's design process, leading to AI systems that are not useful to end-users. This paper presents a Systematic Literature Review on Explanation User Interfaces (XUIs) to gain a deeper understanding of the solutions and design guidelines employed in the academic literature to effectively present explanations to users. To improve the contribution and real-world impact of this survey, we also present a framework for Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide practitioners and academics in the design and evaluation of XUIs.", 'abstract_zh': '人工智能（AI）是本世纪的重大技术进步之一，通过AI驱动的应用和工具在众多领域具有巨大的用户潜力。尽管AI通常表现为黑盒（即其决策过程不透明），开发者通常会采用可解释人工智能（XAI）技术来解释AI模型的行为，从而生成透明、公平、可靠和可信的系统。然而，向用户提供解释并不简单，通常会被作为系统设计过程中的次要方面，导致对最终用户的实用性较差。本文通过对解释用户界面（XUIs）的系统文献综述，深入了解学术文献中用于有效向用户呈现解释的解决方案和设计指南。为了提高该综述的贡献和实际影响，本文还提出了一种面向人类中心的可解释用户界面开发框架（HERMES），以指导从业者和学术界进行XUI的设计与评估。', 'title_zh': '解释用户界面：一项系统文献综述'}
{'arxiv_id': 'arXiv:2505.20081', 'title': 'Inference-time Alignment in Continuous Space', 'authors': 'Yige Yuan, Teng Xiao, Li Yunfan, Bingbing Xu, Shuchang Tao, Yunqi Qiu, Huawei Shen, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2505.20081', 'abstract': 'Aligning large language models with human feedback at inference time has received increasing attention due to its flexibility. Existing methods rely on generating multiple responses from the base policy for search using a reward model, which can be considered as searching in a discrete response space. However, these methods struggle to explore informative candidates when the base policy is weak or the candidate set is small, resulting in limited effectiveness. In this paper, to address this problem, we propose Simple Energy Adaptation ($\\textbf{SEA}$), a simple yet effective algorithm for inference-time alignment. In contrast to expensive search over the discrete space, SEA directly adapts original responses from the base policy toward the optimal one via gradient-based sampling in continuous latent space. Specifically, SEA formulates inference as an iterative optimization procedure on an energy function over actions in the continuous space defined by the optimal policy, enabling simple and effective alignment. For instance, despite its simplicity, SEA outperforms the second-best baseline with a relative improvement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on MATH. Our code is publicly available at this https URL', 'abstract_zh': '在推理时通过人类反馈对大型语言模型进行对齐由于其灵活性而受到了越来越多的关注。现有方法依赖于使用奖励模型从基策略生成多个响应进行搜索，可以被视为在离散响应空间中搜索。然而，当基策略较弱或候选集较小时，这些方法难以探索出信息量大的候选者，导致效果有限。在本文中，为了解决这一问题，我们提出了一种简单有效的推理时对齐算法——简单能量适应（Simple Energy Adaptation，SEA）。与在离散空间中昂贵的搜索不同，SEA 直接通过基于梯度的采样在连续的潜在空间中对基策略的原始响应进行向最优响应的适应。具体而言，SEA 将推理表述为对连续空间中动作的最优策略定义的能量函数的迭代优化过程，从而实现简单的有效对齐。例如，尽管其简单性，SEA 在 AdvBench 上优于第二好的基线方法，相对改进高达 77.51%，在 MATH 上则为 16.36%。我们的代码已公开。', 'title_zh': '推理时连续空间对齐'}
{'arxiv_id': 'arXiv:2505.20072', 'title': 'Incentivizing Reasoning from Weak Supervision', 'authors': 'Yige Yuan, Teng Xiao, Shuchang Tao, Xue Wang, Jinyang Gao, Bolin Ding, Bingbing Xu', 'link': 'https://arxiv.org/abs/2505.20072', 'abstract': 'Large language models (LLMs) have demonstrated impressive performance on reasoning-intensive tasks, but enhancing their reasoning abilities typically relies on either reinforcement learning (RL) with verifiable signals or supervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT) demonstrations, both of which are expensive. In this paper, we study a novel problem of incentivizing the reasoning capacity of LLMs without expensive high-quality demonstrations and reinforcement learning. We investigate whether the reasoning capabilities of LLMs can be effectively incentivized via supervision from significantly weaker models. We further analyze when and why such weak supervision succeeds in eliciting reasoning abilities in stronger models. Our findings show that supervision from significantly weaker reasoners can substantially improve student reasoning performance, recovering close to 94% of the gains of expensive RL at a fraction of the cost. Experiments across diverse benchmarks and model architectures demonstrate that weak reasoners can effectively incentivize reasoning in stronger student models, consistently improving performance across a wide range of reasoning tasks. Our results suggest that this simple weak-to-strong paradigm is a promising and generalizable alternative to costly methods for incentivizing strong reasoning capabilities at inference-time in LLMs. The code is publicly available at this https URL.', 'abstract_zh': '大规模语言模型（LLMs）在推理密集型任务中表现出色，但增强其推理能力通常依赖于验证信号的强化学习（RL）或优质长推理链（CoT）示范的监督微调（SFT），这两种方法都代价高昂。本文研究了一种新的问题，即在不使用昂贵的优质示范和强化学习的情况下激励LLM的推理能力。我们探讨了是否可以通过来自显著更弱模型的监督来有效激励LLM的推理能力。我们进一步分析了这种弱监督在更强模型中引发推理能力的时机和原因。我们的发现表明，显著更弱的推理者的监督可以显著提高学生模型的推理性能，几乎恢复了昂贵的RL带来的94%的收益，而成本仅为后者的几分之一。跨多种基准和模型架构的实验表明，弱推理者可以有效地激励更强学生模型的推理能力，在广泛范围的推理任务中一致提高性能。我们的结果表明，这种简单的弱到强范式是激励LLM推理能力的一种有前途且可推广的替代方案，成本高昂的方法。代码已公开，可通过以下链接访问：this https URL。', 'title_zh': '从弱监督中激励推理'}
{'arxiv_id': 'arXiv:2505.20068', 'title': 'On the Same Page: Dimensions of Perceived Shared Understanding in Human-AI Interaction', 'authors': 'Qingyu Liang, Jaime Banks', 'link': 'https://arxiv.org/abs/2505.20068', 'abstract': "Shared understanding plays a key role in the effective communication in and performance of human-human interactions. With the increasingly common integration of AI into human contexts, the future of personal and workplace interactions will likely see human-AI interaction (HAII) in which the perception of shared understanding is important. Existing literature has addressed the processes and effects of PSU in human-human interactions, but the construal remains underexplored in HAII. To better understand PSU in HAII, we conducted an online survey to collect user reflections on interactions with a large language model when it sunderstanding of a situation was thought to be similar to or different from the participant's. Through inductive thematic analysis, we identified eight dimensions comprising PSU in human-AI interactions: Fluency, aligned operation, fluidity, outcome satisfaction, contextual awareness, lack of humanlike abilities, computational limits, and suspicion.", 'abstract_zh': '共享理解在人类与人工智能互动中的有效沟通和表现中发挥关键作用。随着人工智能在人类环境中的日益融合，个人和工作场所互动的未来可能将出现人类-人工智能互动（HAII），其中共享理解的感觉至关重要。现有文献已经探讨了人类间互动中感知共享理解（PSU）的过程和影响，但在HAII中对PSU的构念探讨仍不足。为了更好地理解HAII中的PSU，我们进行了一项在线调查，收集用户对与大规模语言模型互动的反思，其中模型对情况的理解被认为与参与者相似或不同。通过归纳主题分析，我们识别出八个人机互动中PSU的维度：流畅性、操作对齐、流动性、结果满意度、情境意识、缺乏人类能力、计算限制和怀疑。', 'title_zh': '在同一页面：人类-人工智能交互中感知共享理解的维度'}
{'arxiv_id': 'arXiv:2505.20067', 'title': 'Community Moderation and the New Epistemology of Fact Checking on Social Media', 'authors': 'Isabelle Augenstein, Michiel Bakker, Tanmoy Chakraborty, David Corney, Emilio Ferrara, Iryna Gurevych, Scott Hale, Eduard Hovy, Heng Ji, Irene Larraz, Filippo Menczer, Preslav Nakov, Paolo Papotti, Dhruv Sahnan, Greta Warren, Giovanni Zagni', 'link': 'https://arxiv.org/abs/2505.20067', 'abstract': 'Social media platforms have traditionally relied on internal moderation teams and partnerships with independent fact-checking organizations to identify and flag misleading content. Recently, however, platforms including X (formerly Twitter) and Meta have shifted towards community-driven content moderation by launching their own versions of crowd-sourced fact-checking -- Community Notes. If effectively scaled and governed, such crowd-checking initiatives have the potential to combat misinformation with increased scale and speed as successfully as community-driven efforts once did with spam. Nevertheless, general content moderation, especially for misinformation, is inherently more complex. Public perceptions of truth are often shaped by personal biases, political leanings, and cultural contexts, complicating consensus on what constitutes misleading content. This suggests that community efforts, while valuable, cannot replace the indispensable role of professional fact-checkers. Here we systemically examine the current approaches to misinformation detection across major platforms, explore the emerging role of community-driven moderation, and critically evaluate both the promises and challenges of crowd-checking at scale.', 'abstract_zh': '社交媒体平台历来依赖内部审核团队和独立事实核查组织来识别和标记误导性内容。然而，包括X（原Twitter）和Meta在内的平台最近转向了社区驱动的内容审核，通过推出自己的众包事实核查——社区笔记。如果有效扩展和治理，这类众包审核倡议有望像社区驱动的努力对付垃圾信息那样，以更大的规模和速度打击虚假信息。尽管如此，尤其是对于虚假信息来说，内容审核本质上更为复杂。公众对真相的看法往往受到个人偏见、政治倾向和文化背景的影响，这使得达成关于何为误导性内容的一致意见变得复杂。这表明，尽管社区努力非常重要，但专业事实核查者的作用不可或缺。本文系统性地分析了主要平台虚假信息检测的当前方法，探讨了社区驱动审核的新兴作用，并批判性地评估了大规模众包审核的前景与挑战。', 'title_zh': '社交媒体中的社区 moderation 及其对事实核查的新 epistemology'}
{'arxiv_id': 'arXiv:2505.20066', 'title': 'Automated data curation for self-supervised learning in underwater acoustic analysis', 'authors': 'Hilde I Hummel, Sandjai Bhulai, Burooj Ghani, Rob van der Mei', 'link': 'https://arxiv.org/abs/2505.20066', 'abstract': 'The sustainability of the ocean ecosystem is threatened by increased levels of sound pollution, making monitoring crucial to understand its variability and impact. Passive acoustic monitoring (PAM) systems collect a large amount of underwater sound recordings, but the large volume of data makes manual analysis impossible, creating the need for automation. Although machine learning offers a potential solution, most underwater acoustic recordings are unlabeled. Self-supervised learning models have demonstrated success in learning from large-scale unlabeled data in various domains like computer vision, Natural Language Processing, and audio. However, these models require large, diverse, and balanced datasets for training in order to generalize well. To address this, a fully automated self-supervised data curation pipeline is proposed to create a diverse and balanced dataset from raw PAM data. It integrates Automatic Identification System (AIS) data with recordings from various hydrophones in the U.S. waters. Using hierarchical k-means clustering, the raw audio data is sampled and then combined with AIS samples to create a balanced and diverse dataset. The resulting curated dataset enables the development of self-supervised learning models, facilitating various tasks such as monitoring marine mammals and assessing sound pollution.', 'abstract_zh': '海洋生态系统的可持续性受到噪声污染水平升高的威胁，监测变得至关重要以了解其变异性及其影响。被动声学监测（PAM）系统收集了大量的水下声音记录，但由于数据量庞大，手工分析变得不可能，从而创造了自动化的需求。虽然机器学习提供了潜在的解决方案，但大多数水下声学记录通常是未标记的。自我监督学习模型在计算机视觉、自然语言处理和音频等领域从大规模未标记数据中学习方面已经取得了成功。然而，这些模型在训练时需要大量、多样且平衡的数据集才能实现良好的泛化。为了解决这一问题，提出了一个完全自动化的自我监督数据整理流水线，从原始PAM数据中创建一个多样且平衡的数据集。该流水线将自动识别系统（AIS）数据与美国水域中各种水听器的记录相结合。利用分层K均值聚类，对原始音频数据进行采样，然后与AIS样本结合，生成一个平衡且多样化的数据集。整理后生成的数据集使自我监督学习模型得以开发，可用于监测海洋哺乳动物和评估噪声污染等多种任务。', 'title_zh': '自动数据策展以促进水下声学分析的自监督学习'}
{'arxiv_id': 'arXiv:2505.20065', 'title': 'SafeDPO: A Simple Approach to Direct Preference Optimization with Enhanced Safety', 'authors': 'Geon-Hyeong Kim, Youngsoo Jang, Yu Jin Kim, Byoungjip Kim, Honglak Lee, Kyunghoon Bae, Moontae Lee', 'link': 'https://arxiv.org/abs/2505.20065', 'abstract': 'As Large Language Models (LLMs) continue to advance and find applications across a growing number of fields, ensuring the safety of LLMs has become increasingly critical. To address safety concerns, recent studies have proposed integrating safety constraints into Reinforcement Learning from Human Feedback (RLHF). However, these approaches tend to be complex, as they encompass complicated procedures in RLHF along with additional steps required by the safety constraints. Inspired by Direct Preference Optimization (DPO), we introduce a new algorithm called SafeDPO, which is designed to directly optimize the safety alignment objective in a single stage of policy learning, without requiring relaxation. SafeDPO introduces only one additional hyperparameter to further enhance safety and requires only minor modifications to standard DPO. As a result, it eliminates the need to fit separate reward and cost models or to sample from the language model during fine-tuning, while still enhancing the safety of LLMs. Finally, we demonstrate that SafeDPO achieves competitive performance compared to state-of-the-art safety alignment algorithms, both in terms of aligning with human preferences and improving safety.', 'abstract_zh': '随着大型语言模型（LLMs）不断发展并在越来越多的领域找到应用场景，确保LLMs的安全性变得愈发重要。为了应对安全问题，近期的研究提出了将安全约束集成到基于人类反馈的强化学习（RLHF）中的方法。然而，这些方法通常较为复杂，因为它们不仅包含了RLHF中的复杂流程，还需要执行额外的安全约束步骤。受直接偏好优化（DPO）的启发，我们引入了一种新的算法SafeDPO，该算法旨在在策略学习的单阶段中直接优化安全性对齐目标，而无需进行松弛处理。SafeDPO仅引入了一个额外的超参数来进一步增强安全性，并只需对标准DPO进行少量修改。因此，它消除了为模型微调时拟合独立的奖励和成本模型或从语言模型中采样的需要，同时仍然提高了LLMs的安全性。最后，我们证明SafeDPO在与人类偏好对齐和提高安全性方面均能达到与最先进的安全性对齐算法相当的性能。', 'title_zh': 'SafeDPO：一种增强安全性的一步偏好优化方法'}
{'arxiv_id': 'arXiv:2505.20063', 'title': 'SAEs Are Good for Steering -- If You Select the Right Features', 'authors': 'Dana Arad, Aaron Mueller, Yonatan Belinkov', 'link': 'https://arxiv.org/abs/2505.20063', 'abstract': "Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.", 'abstract_zh': '稀疏自编码器（SAEs）已被提出作为一种无监督方法来学习模型潜在空间的分解。这使得诸如引导（steering）——通过激活某些概念来影响模型的输出——这样的有用应用成为可能，而无需使用标注数据。当前的方法通过分析激活特征的输入标记来识别用于引导的SAE特征。然而，最近的工作表明，仅依靠激活并不能完整描述特征对模型输出的影响。在本工作中，我们区分了两种类型的特征：输入特征，主要捕捉模型输入中的模式；和输出特征，对模型输出具有可理解的影响。我们提出了输入得分和输出得分来表征和定位这些类型的特征，并展示了高值的输入得分和输出得分很少同时出现在同一特征中。这些发现具有实际意义：在移除低输出得分的特征后，使用SAEs进行引导时，我们获得了2-3倍的性能提升，使其与监督方法相当。', 'title_zh': 'SAEs在转向控制中效果良好——如果你选择合适的特征'}
{'arxiv_id': 'arXiv:2505.20053', 'title': 'Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion', 'authors': 'Zheqi Lv, Junhao Chen, Qi Tian, Keting Yin, Shengyu Zhang, Fei Wu', 'link': 'https://arxiv.org/abs/2505.20053', 'abstract': "Diffusion models have become the mainstream architecture for text-to-image generation, achieving remarkable progress in visual quality and prompt controllability. However, current inference pipelines generally lack interpretable semantic supervision and correction mechanisms throughout the denoising process. Most existing approaches rely solely on post-hoc scoring of the final image, prompt filtering, or heuristic resampling strategies-making them ineffective in providing actionable guidance for correcting the generative trajectory. As a result, models often suffer from object confusion, spatial errors, inaccurate counts, and missing semantic elements, severely compromising prompt-image alignment and image quality. To tackle these challenges, we propose MLLM Semantic-Corrected Ping-Pong-Ahead Diffusion (PPAD), a novel framework that, for the first time, introduces a Multimodal Large Language Model (MLLM) as a semantic observer during inference. PPAD performs real-time analysis on intermediate generations, identifies latent semantic inconsistencies, and translates feedback into controllable signals that actively guide the remaining denoising steps. The framework supports both inference-only and training-enhanced settings, and performs semantic correction at only extremely few diffusion steps, offering strong generality and scalability. Extensive experiments demonstrate PPAD's significant improvements.", 'abstract_zh': 'Multimodal Large Language Model Semantic-Corrected Ping-Pong-Ahead Diffusion (PPAD)', 'title_zh': '多模态LLM引导的文本到图像扩散语义修正'}
{'arxiv_id': 'arXiv:2505.20047', 'title': 'Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks', 'authors': 'Debargha Ganguly, Vikash Singh, Sreehari Sankar, Biyao Zhang, Xuecen Zhang, Srinivasan Iyengar, Xiaotian Han, Amit Sharma, Shivkumar Kalyanaraman, Vipin Chaudhary', 'link': 'https://arxiv.org/abs/2505.20047', 'abstract': "Large language models (LLMs) show remarkable promise for democratizing automated reasoning by generating formal specifications. However, a fundamental tension exists: LLMs are probabilistic, while formal verification demands deterministic guarantees. This paper addresses this epistemological gap by comprehensively investigating failure modes and uncertainty quantification (UQ) in LLM-generated formal artifacts. Our systematic evaluation of five frontier LLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization's domain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on factual ones), with known UQ techniques like the entropy of token probabilities failing to identify these errors. We introduce a probabilistic context-free grammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty taxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy for logic, AUROC>0.93). Finally, a lightweight fusion of these signals enables selective verification, drastically reducing errors (14-100%) with minimal abstention, transforming LLM-driven formalization into a reliable engineering discipline.", 'abstract_zh': '大型语言模型（LLMs）在通过生成形式化规范来 democratize 自动推理方面展示了显著的潜力。然而，存在一个根本性的紧张关系：LLMs 是概率性的，而形式化验证要求确定性的保证。本文通过全面研究 LLMS 生成形式化制品的失败模式和不确定性量化（UQ）来弥合这一认识论差距。系统评估五种前沿LLMs揭示了基于 Satisfiability Modulo Theories (SMT) 的自动形式化在不同领域对准确性的影响（从逻辑任务的+34.8% 到事实任务的-44.5%），已知的 UQ 技术如词概率的熵无法识别这些错误。我们引入了一个概率上下文自由文法（PCFG）框架来建模 LLM 的输出，从而得到一个细化的不确定性分类法。我们发现不确定性信号与任务相关（例如，语法熵适用于逻辑任务，AUROC>0.93）。最后，这些信号的轻量化融合能够实现选择性验证，大幅减少错误（14% 到 100%），同时几乎无弃权，将基于LLM的形式化转变为可靠的工程学科。', 'title_zh': '形式不确定性中的语法规则：何时在自动化推理任务中信任LLMs'}
{'arxiv_id': 'arXiv:2505.20033', 'title': 'EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition', 'authors': 'Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Maurice Kraus, Felix Friedrich, Huu Nguyen, Krishna Kalyan, Kourosh Nadi, Kristian Kersting, Sören Auer', 'link': 'https://arxiv.org/abs/2505.20033', 'abstract': "Effective human-AI interaction relies on AI's ability to accurately perceive and interpret human emotions. Current benchmarks for vision and vision-language models are severely limited, offering a narrow emotional spectrum that overlooks nuanced states (e.g., bitterness, intoxication) and fails to distinguish subtle differences between related feelings (e.g., shame vs. embarrassment). Existing datasets also often use uncontrolled imagery with occluded faces and lack demographic diversity, risking significant bias. To address these critical gaps, we introduce EmoNet Face, a comprehensive benchmark suite. EmoNet Face features: (1) A novel 40-category emotion taxonomy, meticulously derived from foundational research to capture finer details of human emotional experiences. (2) Three large-scale, AI-generated datasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and controlled demographic balance across ethnicity, age, and gender. (3) Rigorous, multi-expert annotations for training and high-fidelity evaluation. (4) We build Empathic Insight Face, a model achieving human-expert-level performance on our benchmark. The publicly released EmoNet Face suite - taxonomy, datasets, and model - provides a robust foundation for developing and evaluating AI systems with a deeper understanding of human emotions.", 'abstract_zh': '有效的Man-AI交互依赖于AI准确感知和解读人类情绪的能力。现有的视觉和视觉语言模型基准严重受限，提供的情感范围狭窄，忽视了细腻的情感状态（如苦涩、醉酒），并且难以区分相關情感之间的细微差别（如羞耻 vs 尴尬）。现有数据集通常使用未经控制的、面部被遮挡的图像，并且缺少人口统计学多样性，这可能会导致显著的偏见。为解决这些关键缺口，我们引入了EmoNet Face这一综合基准套件。EmoNet Face包含：(1) 一个新的40类情感分类体系，经过详细研究精心构建，以捕捉人类情感体验的更多细节。(2) 三个大规模的AI生成数据集（EmoNet HQ、Binary和Big），包含明确的正面面部表情，并且在种族、年龄和性别上实现了可控的人口统计学平衡。(3) 严格的多专家注释，用于训练和高保真评估。(4) 我们构建了Empathic Insight Face模型，在我们的基准测试中达到了人类专家水平的性能。公开发布的EmoNet Face套件——分类体系、数据集和模型——为开发和评估更深入理解人类情感的AI系统提供了坚实的基础。', 'title_zh': 'EmoNet-Face：一个专家标注的合成情绪识别基准数据集'}
{'arxiv_id': 'arXiv:2505.20030', 'title': 'Multiple Descents in Deep Learning as a Sequence of Order-Chaos Transitions', 'authors': 'Wenbo Wei, Nicholas Chong Jia Le, Choy Heng Lai, Ling Feng', 'link': 'https://arxiv.org/abs/2505.20030', 'abstract': "We observe a novel 'multiple-descent' phenomenon during the training process of LSTM, in which the test loss goes through long cycles of up and down trend multiple times after the model is overtrained. By carrying out asymptotic stability analysis of the models, we found that the cycles in test loss are closely associated with the phase transition process between order and chaos, and the local optimal epochs are consistently at the critical transition point between the two phases. More importantly, the global optimal epoch occurs at the first transition from order to chaos, where the 'width' of the 'edge of chaos' is the widest, allowing the best exploration of better weight configurations for learning.", 'abstract_zh': '我们在LSTM模型训练过程中观察到一种新颖的“多极降”现象，在模型过拟合之后，测试损失呈现出多次长期上下波动的周期。通过对模型的渐近稳定性分析发现，测试损失的周期与有序与混沌相变过程密切相关，局部最优时期始终处于两种相态之间的临界转换点。更重要的是，全局最优时期发生在从有序到混沌的第一次相变中，此时“混沌边缘”的“宽度”最大，能够更好地探索更好的权重配置以促进学习。', 'title_zh': '深度学习中的多次下降作为顺序的顺序-混沌转换'}
{'arxiv_id': 'arXiv:2505.20029', 'title': 'Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)', 'authors': 'Subba Reddy Oota, Akshett Jindal, Ishani Mondal, Khushbu Pahwa, Satya Sai Srinath Namburi, Manish Shrivastava, Maneesh Singh, Bapi S. Raju, Manish Gupta', 'link': 'https://arxiv.org/abs/2505.20029', 'abstract': "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models-through increased size, instruction-tuning, and multimodality-has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions show that MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results suggest that enhancing MLLMs' ability to capture task-specific information could lead to better differentiation between various types of instructions, and thereby improving their precision in predicting brain responses.", 'abstract_zh': '基于Transformer的语言模型虽然未明确训练以模拟脑电记录，但已展示了与脑活动惊人的契合度。随着这些模型通过增加规模、指令调优和多模态性的发展，其与神经数据的表征契合度得到了提高。最近，一类新的指令调优多模态LLM（MLLMs）出现了，它们在开放的多模态视觉任务中展现出显著的零样本能力。然而，目前尚不清楚当MLLMs接收到自然指令时，它们是否能更好地与大脑对齐，并有效捕捉指令特定的表征。为解决这一问题，我们首先探讨了大脑对齐问题，即通过使用参与者观看自然场景时MLLMs产生的文本输出响应嵌入来衡量神经视觉活动的预测性程度。实验结果显示，MLLMs在大脑对齐方面明显优于仅包含视觉模型，并且其表现与非指令调优的多模态模型如CLIP相当。此外，我们还发现，尽管这些MLLMs在生成符合任务特定指令的高质量响应方面非常有效，但并非所有指令都对大脑对齐有益。通过改变指令，MLLMs能够编码输入图像相关的指令特定视觉概念。这种分析表明，MLLMs有效地捕捉了数量相关和识别相关的概念，展示了与脑电活动的强烈契合度。值得注意的是，脑编码模型解释的大脑变异性大部分在MLLM图像说明嵌入和其他指令的嵌入之间共享。这些结果表明，增强MLLMs捕捉任务特定信息的能力可能有助于更好地区分各种类型指令之间的差异，从而提高它们预测脑电反应的精确度。', 'title_zh': '将指令调优（在多模态模型中）与视觉-语言处理（在大脑中）相关联'}
{'arxiv_id': 'arXiv:2505.20027', 'title': 'Multi-modal brain encoding models for multi-modal stimuli', 'authors': 'Subba Reddy Oota, Khushbu Pahwa, Mounika Marreddy, Maneesh Singh, Manish Gupta, Bapi S. Raju', 'link': 'https://arxiv.org/abs/2505.20027', 'abstract': 'Despite participants engaging in unimodal stimuli, such as watching images or silent videos, recent work has demonstrated that multi-modal Transformer models can predict visual brain activity impressively well, even with incongruent modality representations. This raises the question of how accurately these multi-modal models can predict brain activity when participants are engaged in multi-modal stimuli. As these models grow increasingly popular, their use in studying neural activity provides insights into how our brains respond to such multi-modal naturalistic stimuli, i.e., where it separates and integrates information across modalities through a hierarchy of early sensory regions to higher cognition. We investigate this question by using multiple unimodal and two types of multi-modal models-cross-modal and jointly pretrained-to determine which type of model is more relevant to fMRI brain activity when participants are engaged in watching movies. We observe that both types of multi-modal models show improved alignment in several language and visual regions. This study also helps in identifying which brain regions process unimodal versus multi-modal information. We further investigate the contribution of each modality to multi-modal alignment by carefully removing unimodal features one by one from multi-modal representations, and find that there is additional information beyond the unimodal embeddings that is processed in the visual and language regions. Based on this investigation, we find that while for cross-modal models, their brain alignment is partially attributed to the video modality; for jointly pretrained models, it is partially attributed to both the video and audio modalities. This serves as a strong motivation for the neuroscience community to investigate the interpretability of these models for deepening our understanding of multi-modal information processing in brain.', 'abstract_zh': '尽管参与者接受的是单一模态刺激，如观看图片或无声视频，最近的研究表明，多模态Transformer模型可以出色地预测视觉脑活动，即使不同模态的表示不一致。这引发了一个问题：当参与者接受多模态刺激时，这些多模态模型能多准确地预测脑活动。随着这类模型变得越来越流行，它们在研究神经活动方面的应用为我们提供了关于大脑如何响应多模态自然刺激的见解，即信息如何通过早期感觉区域向更高级认知区域的层次结构进行分离和整合。我们通过使用多种单一模态和两种类型多模态模型——跨模态模型和联合预训练模型——来确定哪种类型的模型在参与者观看电影时更相关于fMRI脑活动。我们观察到，两种类型的多模态模型在多个语言和视觉区域都显示出更好的对齐。这项研究还有助于确定哪些脑区处理单一模态信息与多模态信息。我们进一步通过仔细地从多模态表示中逐个移除单一模态特征来研究每种模态对多模态对齐的贡献，发现视觉和语言区域中还有额外的未被单一模态嵌入捕捉到的信息。基于这项研究，我们发现对于跨模态模型，其脑对齐部分归因于视频模态；而对于联合预训练模型，其脑对齐则部分归因于视频和音频模态。这为神经科学界深入理解大脑多模态信息处理的可解释性提供了强有力的动力。', 'title_zh': '多模态脑编码模型用于多模态刺激'}
{'arxiv_id': 'arXiv:2505.20026', 'title': 'Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage', 'authors': 'Xinping Chen, Chen Liu', 'link': 'https://arxiv.org/abs/2505.20026', 'abstract': 'We propose Gradient Inversion Transcript (GIT), a novel generative approach for reconstructing training data from leaked gradients. GIT employs a generative attack model, whose architecture is tailored to align with the structure of the leaked model based on theoretical analysis. Once trained offline, GIT can be deployed efficiently and only relies on the leaked gradients to reconstruct the input data, rendering it applicable under various distributed learning environments. When used as a prior for other iterative optimization-based methods, GIT not only accelerates convergence but also enhances the overall reconstruction quality. GIT consistently outperforms existing methods across multiple datasets and demonstrates strong robustness under challenging conditions, including inaccurate gradients, data distribution shifts and discrepancies in model parameters.', 'abstract_zh': '我们提出了一种新颖的生成方法Gradient Inversion Transcript (GIT)，用于从泄露的梯度重建训练数据。GIT采用了一种生成攻击模型，其架构根据理论分析专门设计以与泄露模型的结构对齐。一旦离线训练完成，GIT可以高效部署，并且仅依赖泄露的梯度来重建输入数据，使其在各种分布式学习环境中适用。当作为其他迭代优化方法的先验时，GIT不仅能加速收敛，还能提高整体重建质量。在多个数据集上，GIT一致地优于现有方法，并在包括不准确的梯度、数据分布转移和模型参数差异在内的挑战性条件下展现出强大的鲁棒性。', 'title_zh': '梯度 inversion 转录：利用鲁棒生成先验从梯度泄露重建训练数据'}
{'arxiv_id': 'arXiv:2505.20024', 'title': 'ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving', 'authors': 'Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao, Yupeng Zheng, Qiao Lin, Huiyong Chen, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2505.20024', 'abstract': 'Due to the powerful vision-language reasoning and generalization abilities, multimodal large language models (MLLMs) have garnered significant attention in the field of end-to-end (E2E) autonomous driving. However, their application to closed-loop systems remains underexplored, and current MLLM-based methods have not shown clear superiority to mainstream E2E imitation learning approaches. In this work, we propose ReasonPlan, a novel MLLM fine-tuning framework designed for closed-loop driving through holistic reasoning with a self-supervised Next Scene Prediction task and supervised Decision Chain-of-Thought process. This dual mechanism encourages the model to align visual representations with actionable driving context, while promoting interpretable and causally grounded decision making. We curate a planning-oriented decision reasoning dataset, namely PDR, comprising 210k diverse and high-quality samples. Our method outperforms the mainstream E2E imitation learning method by a large margin of 19% L2 and 16.1 driving score on Bench2Drive benchmark. Furthermore, ReasonPlan demonstrates strong zero-shot generalization on unseen DOS benchmark, highlighting its adaptability in handling zero-shot corner cases. Code and dataset will be found in this https URL.', 'abstract_zh': '基于全面推理的自我监督下一场景预测和监督决策链 fine-tuning 框架 ReasonPlan：面向闭环自主驾驶的应用', 'title_zh': 'ReasonPlan: 统一的场景预测与决策推理在闭环自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2505.20021', 'title': 'Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models', 'authors': 'Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu', 'link': 'https://arxiv.org/abs/2505.20021', 'abstract': 'Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal comprehension and reasoning capabilities, yet they often struggle with trivially simple visual tasks. In this work, we focus on the domain of basic 2D Euclidean geometry and systematically categorize the fundamental, indivisible visual perception skills, which we refer to as atomic visual skills. We then introduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the atomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find that they struggle with these tasks, despite being trivial for adult humans. Our findings highlight the need for purpose-built datasets to train and evaluate VLMs on atomic, rather than composite, visual perception tasks.', 'abstract_zh': 'Recent Vision-Language Models (VLMs)在基本二维欧几里得几何领域的原子视觉技能上的表现与挑战', 'title_zh': '将复杂视觉理解分解为原子视觉技能以供视觉语言模型使用'}
{'arxiv_id': 'arXiv:2505.19983', 'title': 'ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications', 'authors': 'Tong Wu, Zhiyong Chen, Dazhi He, Feng Yang, Meixia Tao, Xiaodong Xu, Wenjun Zhang, Ping Zhang', 'link': 'https://arxiv.org/abs/2505.19983', 'abstract': 'Diffusion models (DMs) have recently achieved significant success in wireless communications systems due to their denoising capabilities. The broadcast nature of wireless signals makes them susceptible not only to Gaussian noise, but also to unaware interference. This raises the question of whether DMs can effectively mitigate interference in wireless semantic communication systems. In this paper, we model the interference cancellation problem as a maximum a posteriori (MAP) problem over the joint posterior probability of the signal and interference, and theoretically prove that the solution provides excellent estimates for the signal and interference. To solve this problem, we develop an interference cancellation diffusion model (ICDM), which decomposes the joint posterior into independent prior probabilities of the signal and interference, along with the channel transition probablity. The log-gradients of these distributions at each time step are learned separately by DMs and accurately estimated through deriving. ICDM further integrates these gradients with advanced numerical iteration method, achieving accurate and rapid interference cancellation. Extensive experiments demonstrate that ICDM significantly reduces the mean square error (MSE) and enhances perceptual quality compared to schemes without ICDM. For example, on the CelebA dataset under the Rayleigh fading channel with a signal-to-noise ratio (SNR) of $20$ dB and signal to interference plus noise ratio (SINR) of 0 dB, ICDM reduces the MSE by 4.54 dB and improves the learned perceptual image patch similarity (LPIPS) by 2.47 dB.', 'abstract_zh': '扩散模型（DMs）在无线通信系统中由于其去噪能力 recently取得显著成功，并被用于有效减轻无线语义通信系统中的干扰。', 'title_zh': 'ICDM: 干扰消除扩散模型在无线语义通信中的应用'}
{'arxiv_id': 'arXiv:2505.19973', 'title': 'DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in Digital Forensics and Incident Response', 'authors': 'Bilel Cherif, Tamas Bisztray, Richard A. Dubniczky, Aaesha Aldahmani, Saeed Alshehhi, Norbert Tihanyi', 'link': 'https://arxiv.org/abs/2505.19973', 'abstract': 'Digital Forensics and Incident Response (DFIR) involves analyzing digital evidence to support legal investigations. Large Language Models (LLMs) offer new opportunities in DFIR tasks such as log analysis and memory forensics, but their susceptibility to errors and hallucinations raises concerns in high-stakes contexts. Despite growing interest, there is no comprehensive benchmark to evaluate LLMs across both theoretical and practical DFIR domains. To address this gap, we present DFIR-Metric, a benchmark with three components: (1) Knowledge Assessment: a set of 700 expert-reviewed multiple-choice questions sourced from industry-standard certifications and official documentation; (2) Realistic Forensic Challenges: 150 CTF-style tasks testing multi-step reasoning and evidence correlation; and (3) Practical Analysis: 500 disk and memory forensics cases from the NIST Computer Forensics Tool Testing Program (CFTT). We evaluated 14 LLMs using DFIR-Metric, analyzing both their accuracy and consistency across trials. We also introduce a new metric, the Task Understanding Score (TUS), designed to more effectively evaluate models in scenarios where they achieve near-zero accuracy. This benchmark offers a rigorous, reproducible foundation for advancing AI in digital forensics. All scripts, artifacts, and results are available on the project website at this https URL.', 'abstract_zh': '数字取证与事件响应（DFIR）涉及分析数字证据以支持法律调查。大型语言模型（LLMs）为DFIR任务（如日志分析和内存取证）带来了新的机遇，但在高风险情境下，它们的错误和幻觉倾向引发了担忧。尽管兴趣日益浓厚，但仍缺乏一个综合基准来评估LLMs在理论和实践DFIR领域的表现。为填补这一空白，我们提出了DFIR-Metric基准，包括三个组成部分：（1）知识评估：700个专家评审的多项选择题，来源行业标准认证和官方文档；（2）现实取证挑战：150项类似CTF的任务，测试多步推理和证据关联；（3）实际分析：500个来自NIST计算机取证工具测试计划（CFTT）的硬盘和内存取证案例。我们使用DFIR-Metric评估了14个LLM，分析了它们在实验中的准确性和一致性。我们还引入了一个新的指标，任务理解得分（TUS），旨在更有效地评估在接近零准确率场景中模型的表现。该基准提供了一个严谨、可重复的基础，推动AI在数字取证领域的进步。所有脚本、成果和结果均可在项目网站上获取：this https URL。', 'title_zh': 'DFIR-Metric: 一个评估数字取证和事件响应中大型语言模型性能的数据集'}
{'arxiv_id': 'arXiv:2505.19966', 'title': 'Learning to Select In-Context Demonstration Preferred by Large Language Model', 'authors': 'Zheng Zhang, Shaocheng Lan, Lei Song, Jiang Bian, Yexin Li, Kan Ren', 'link': 'https://arxiv.org/abs/2505.19966', 'abstract': 'In-context learning (ICL) enables large language models (LLMs) to adapt to new tasks during inference using only a few demonstrations. However, ICL performance is highly dependent on the selection of these demonstrations. Recent work explores retrieval-based methods for selecting query-specific demonstrations, but these approaches often rely on surrogate objectives such as metric learning, failing to directly optimize ICL performance. Consequently, they struggle to identify truly beneficial demonstrations. Moreover, their discriminative retrieval paradigm is ineffective when the candidate pool lacks sufficient high-quality demonstrations. To address these challenges, we propose GenICL, a novel generative preference learning framework that leverages LLM feedback to directly optimize demonstration selection for ICL. Experiments on 19 datasets across 11 task categories demonstrate that GenICL achieves superior performance than existing methods in selecting the most effective demonstrations, leading to better ICL performance.', 'abstract_zh': '基于语境的学习（ICL）使大规模语言模型（LLMs）能够在推理时仅通过少量示范适应新任务。然而，ICL 的性能高度依赖于这些示范的选择。近期研究探索了基于检索的方法来选择查询特定的示范，但这些方法往往依赖于代理目标，如度量学习，无法直接优化ICL性能。因此，它们难以识别真正有益的示范。此外，其鉴别性检索范式在候选池中缺乏足够的高质量示范时效果不佳。为应对这些挑战，我们提出了一种新颖的生成性偏好学习框架GenICL，该框架利用LLM反馈直接优化ICL的示范选择。实验结果表明，GenICL在选择最有效的示范方面优于现有方法，从而提高了ICL的性能。', 'title_zh': '学习选择大型语言模型偏好的上下文示例'}
{'arxiv_id': 'arXiv:2505.19964', 'title': 'The Limits of Preference Data for Post-Training', 'authors': 'Eric Zhao, Jessica Dai, Pranjal Awasthi', 'link': 'https://arxiv.org/abs/2505.19964', 'abstract': "Recent progress in strengthening the capabilities of large language models has stemmed from applying reinforcement learning to domains with automatically verifiable outcomes. A key question is whether we can similarly use RL to optimize for outcomes in domains where evaluating outcomes inherently requires human feedback; for example, in tasks like deep research and trip planning, outcome evaluation is qualitative and there are many possible degrees of success. One attractive and scalable modality for collecting human feedback is preference data: ordinal rankings (pairwise or $k$-wise) that indicate, for $k$ given outcomes, which one is preferred. In this work, we study a critical roadblock: preference data fundamentally and significantly limits outcome-based optimization. Even with idealized preference data (infinite, noiseless, and online), the use of ordinal feedback can prevent obtaining even approximately optimal solutions. We formalize this impossibility using voting theory, drawing an analogy between how a model chooses to answer a query with how voters choose a candidate to elect. This indicates that grounded human scoring and algorithmic innovations are necessary for extending the success of RL post-training to domains demanding human feedback. We also explore why these limitations have disproportionately impacted RLHF when it comes to eliciting reasoning behaviors (e.g., backtracking) versus situations where RLHF has been historically successful (e.g., instruction-tuning and safety training), finding that the limitations of preference data primarily suppress RLHF's ability to elicit robust strategies -- a class that encompasses most reasoning behaviors.", 'abstract_zh': 'Recent进展在增强大规模语言模型的能力方面源自将其强化学习应用到具有自动可验证结果的领域。一个关键问题是，我们是否可以类似地使用RL来优化那些评估结果本就需要人类反馈的领域中的结果；例如，在深度研究和旅行规划等任务中，结果评估是定性的，并且成功具有多种可能的程度。一种具有吸引力且可扩展的人类反馈收集方式是偏好数据：序数排名（成对或k-wise），它可以指示对于给定的k个结果，哪一个更受偏好。在这项工作中，我们研究了一个关键障碍：偏好数据从根本上和显著地限制了基于结果的优化。即使在理想化的偏好数据（无限的、无噪声的和在线的）情况下，序数反馈的使用也可能阻止获得近似最优解。我们使用投票理论来形式化这种不可能性，将模型选择如何回答查询与其如何选择候选人进行类比。这表明，针对需求人类反馈的领域，有必要结合具体的评分和算法创新，以使训练后的RL成功扩展到这些领域。我们还探讨了这些限制为何在对比RLHF在诱发出推理行为（例如，反向追踪）方面与其在历史上的成功领域（例如，指令调优和安全训练）时表现不同，发现偏好数据的限制主要抑制了RLHF诱发出稳健策略的能力——这一类别包括大多数推理行为。', 'title_zh': '训练后偏好数据的局限性'}
{'arxiv_id': 'arXiv:2505.19955', 'title': 'MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research', 'authors': 'Hui Chen, Miao Xiong, Yujie Lu, Wei Han, Ailin Deng, Yufei He, Jiaying Wu, Yibo Li, Yue Liu, Bryan Hooi', 'link': 'https://arxiv.org/abs/2505.19955', 'abstract': 'Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce MLR-Bench, a comprehensive benchmark for evaluating AI agents on open-ended machine learning research. MLR-Bench includes three key components: (1) 201 research tasks sourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2) MLR-Judge, an automated evaluation framework combining LLM-based reviewers with carefully designed review rubrics to assess research quality; and (3) MLR-Agent, a modular agent scaffold capable of completing research tasks through four stages: idea generation, proposal formulation, experimentation, and paper writing. Our framework supports both stepwise assessment across these distinct research stages, and end-to-end evaluation of the final research paper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced coding agent, finding that while LLMs are effective at generating coherent ideas and well-structured papers, current coding agents frequently (e.g., in 80% of the cases) produce fabricated or invalidated experimental results--posing a major barrier to scientific reliability. We validate MLR-Judge through human evaluation, showing high agreement with expert reviewers, supporting its potential as a scalable tool for research evaluation. We open-source MLR-Bench to help the community benchmark, diagnose, and improve AI research agents toward trustworthy and transparent scientific discovery.', 'abstract_zh': 'Recent Advancements in AI Agents Have Demonstrated Their Growing Potential to Drive and Support Scientific Discovery: Introducing MLR-Bench，一个综合基准用于评估AI代理在开放机器学习研究中的表现', 'title_zh': 'MLR-Bench: 评估AI代理在开放性机器学习研究中的表现'}
{'arxiv_id': 'arXiv:2505.19951', 'title': 'Novel Loss-Enhanced Universal Adversarial Patches for Sustainable Speaker Privacy', 'authors': 'Elvir Karimov, Alexander Varlamov, Danil Ivanov, Dmitrii Korzh, Oleg Y. Rogov', 'link': 'https://arxiv.org/abs/2505.19951', 'abstract': 'Deep learning voice models are commonly used nowadays, but the safety processing of personal data, such as human identity and speech content, remains suspicious. To prevent malicious user identification, speaker anonymization methods were proposed. Current methods, particularly based on universal adversarial patch (UAP) applications, have drawbacks such as significant degradation of audio quality, decreased speech recognition quality, low transferability across different voice biometrics models, and performance dependence on the input audio length. To mitigate these drawbacks, in this work, we introduce and leverage the novel Exponential Total Variance (TV) loss function and provide experimental evidence that it positively affects UAP strength and imperceptibility. Moreover, we present a novel scalable UAP insertion procedure and demonstrate its uniformly high performance for various audio lengths.', 'abstract_zh': '基于指数总变差损失函数的通用对抗性补丁增强的说话人匿名化方法', 'title_zh': '新型损失增强通用 adversarial 贴图以实现可持续说话人隐私'}
{'arxiv_id': 'arXiv:2505.19948', 'title': 'SaSi: A Self-augmented and Self-interpreted Deep Learning Approach for Few-shot Cryo-ET Particle Detection', 'authors': 'Gokul Adethya, Bhanu Pratyush Mantha, Tianyang Wang, Xingjian Li, Min Xu', 'link': 'https://arxiv.org/abs/2505.19948', 'abstract': 'Cryo-electron tomography (cryo-ET) has emerged as a powerful technique for imaging macromolecular complexes in their near-native states. However, the localization of 3D particles in cellular environments still presents a significant challenge due to low signal-to-noise ratios and missing wedge artifacts. Deep learning approaches have shown great potential, but they need huge amounts of data, which can be a challenge in cryo-ET scenarios where labeled data is often scarce. In this paper, we propose a novel Self-augmented and Self-interpreted (SaSi) deep learning approach towards few-shot particle detection in 3D cryo-ET images. Our method builds upon self-augmentation techniques to further boost data utilization and introduces a self-interpreted segmentation strategy for alleviating dependency on labeled data, hence improving generalization and robustness. As demonstrated by experiments conducted on both simulated and real-world cryo-ET datasets, the SaSi approach significantly outperforms existing state-of-the-art methods for particle localization. This research increases understanding of how to detect particles with very few labels in cryo-ET and thus sets a new benchmark for few-shot learning in structural biology.', 'abstract_zh': '冷冻电子显微镜断层成像（cryo-ET）已成为在接近天然状态成像大分子复合体的一种强大技术。然而，由于信噪比低和缺失楔形伪影，在细胞环境中的3D颗粒定位仍具有显著挑战。深度学习方法显示出巨大潜力，但在冷冻电子显微镜场景中，标记数据往往稀缺，这需要大量数据。本文提出了一种新的自增强和自解释（SaSi）深度学习方法，用于3D冷冻电子显微镜图像中的少样本颗粒检测。该方法基于自增强技术进一步提高数据利用，并引入自解释分割策略以缓解对标记数据的依赖，从而提高泛化能力和鲁棒性。实验结果表明，SaSi方法在颗粒定位方面显著优于现有最先进的方法。本研究增加了对如何在冷冻电子显微镜中使用极少标签检测颗粒的理解，并为结构生物学中的少样本学习设定了新的基准。', 'title_zh': 'SaSi：一种自我增强和自我解释的Few-shot Cryo-ET粒子检测深度学习方法'}
{'arxiv_id': 'arXiv:2505.19947', 'title': 'Dynamically Learned Test-Time Model Routing in Language Model Zoos with Service Level Guarantees', 'authors': 'Herbert Woisetschläger, Ryan Zhang, Shiqiang Wang, Hans-Arno Jacobsen', 'link': 'https://arxiv.org/abs/2505.19947', 'abstract': 'Open-weight LLM zoos provide access to numerous high-quality models, but selecting the appropriate model for specific tasks remains challenging and requires technical expertise. Most users simply want factually correct, safe, and satisfying responses without concerning themselves with model technicalities, while inference service providers prioritize minimizing operating costs. These competing interests are typically mediated through service level agreements (SLAs) that guarantee minimum service quality. We introduce MESS+, a stochastic optimization algorithm for cost-optimal LLM request routing while providing rigorous SLA compliance guarantees. MESS+ learns request satisfaction probabilities of LLMs in real-time as users interact with the system, based on which model selection decisions are made by solving a per-request optimization problem. Our algorithm includes a novel combination of virtual queues and request satisfaction prediction, along with a theoretical analysis of cost optimality and constraint satisfaction. Across a wide range of state-of-the-art LLM benchmarks, MESS+ achieves an average of 2x cost savings compared to existing LLM routing techniques.', 'abstract_zh': '_OPEN-WEIGHT LLM 阵营提供了大量高质量模型的访问权限，但选择适合特定任务的模型仍然具有挑战性且需要技术专长。大多数用户只是希望获得事实正确、安全且令人满意的回答，而不关心模型的技术细节，而推理服务提供商则侧重于最小化运营成本。这些相互冲突的利益通常通过确保最低服务质量的服务水平协议（SLAs）来调解。我们提出了MESS+，这是一种随机优化算法，用于在提供严格的SLA合规性保证的同时实现成本最优的LLM请求路由。MESS+会在用户与系统交互时实时学习LLM的请求满意度概率，并基于此通过求解每个请求的优化问题来做出模型选择决策。我们的算法包括虚拟队列和请求满意度预测的新型结合，以及成本最优性和约束满足的理论分析。在一系列先进的LLM基准测试中，MESS+相比现有LLM路由技术平均实现了2倍的成本节约。', 'title_zh': '具有服务级别保证的语言模型动物园中的动态学习测试时模型路由'}
{'arxiv_id': 'arXiv:2505.19944', 'title': 'Can Visual Encoder Learn to See Arrows?', 'authors': 'Naoyuki Terashita, Yusuke Tozaki, Hideaki Omote, Congkha Nguyen, Ryosuke Nakamoto, Yuta Koreeda, Hiroaki Ozaki', 'link': 'https://arxiv.org/abs/2505.19944', 'abstract': 'The diagram is a visual representation of a relationship illustrated with edges (lines or arrows), which is widely used in industrial and scientific communication. Although recognizing diagrams is essential for vision language models (VLMs) to comprehend domain-specific knowledge, recent studies reveal that many VLMs fail to identify edges in images. We hypothesize that these failures stem from an over-reliance on textual and positional biases, preventing VLMs from learning explicit edge features. Based on this idea, we empirically investigate whether the image encoder in VLMs can learn edge representation through training on a diagram dataset in which edges are biased neither by textual nor positional information. To this end, we conduct contrastive learning on an artificially generated diagram--caption dataset to train an image encoder and evaluate its diagram-related features on three tasks: probing, image retrieval, and captioning. Our results show that the finetuned model outperforms pretrained CLIP in all tasks and surpasses zero-shot GPT-4o and LLaVA-Mistral in the captioning task. These findings confirm that eliminating textual and positional biases fosters accurate edge recognition in VLMs, offering a promising path for advancing diagram understanding.', 'abstract_zh': '图是一种用边缘（线条或箭头）来可视化关系的直观表示，在工业和科学交流中被广泛使用。尽管识别图是使视觉语言模型（VLMs）理解领域特定知识的关键，但最近的研究发现，许多VLMs无法识别图像中的边缘。我们假设这些失败源于对其文本和位置偏倚的过度依赖，阻碍了VLMs学习显式的边缘特征。基于这一想法，我们实证研究了在既无文本也无位置偏倚的图数据集上训练VLMs中的图像编码器是否能够学习到边缘表示。为此，我们在人工生成的图-描述数据集上进行了对比学习，以训练图像编码器，并在图识别、图像检索和描述生成三个任务上评估其图相关特征。我们的结果显示，微调后的模型在所有任务中均优于预训练的CLIP，并在描述生成任务中超过了零样本的GPT-4o和LLaVA-Mistral。这些发现证实了消除文本和位置偏倚可以促进VLMs的准确的边缘识别，提供了推进图理解的有前景的路径。', 'title_zh': '视觉编码器能学会识别箭头吗？'}
{'arxiv_id': 'arXiv:2505.19920', 'title': 'A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks', 'authors': 'Sebastian Groß, Stefan Heindorf, Philipp Terhörst', 'link': 'https://arxiv.org/abs/2505.19920', 'abstract': 'Traditional face recognition systems rely on extracting fixed face representations, known as templates, to store and verify identities. These representations are typically generated by neural networks that often lack explainability and raise concerns regarding fairness and privacy. In this work, we propose a novel model-template (MOTE) approach that replaces vector-based face templates with small personalized neural networks. This design enables more responsible face recognition for small and medium-scale systems. During enrollment, MOTE creates a dedicated binary classifier for each identity, trained to determine whether an input face matches the enrolled identity. Each classifier is trained using only a single reference sample, along with synthetically balanced samples to allow adjusting fairness at the level of a single individual during enrollment. Extensive experiments across multiple datasets and recognition systems demonstrate substantial improvements in fairness and particularly in privacy. Although the method increases inference time and storage requirements, it presents a strong solution for small- and mid-scale applications where fairness and privacy are critical.', 'abstract_zh': '一种新型模型-模板（MOTE）方法：将基于向量的脸模板替换为小型个性化神经网络，以实现更加负责的脸部识别', 'title_zh': '一种适用于中小规模系统的个性化神经网络负责任人脸识别方法'}
{'arxiv_id': 'arXiv:2505.19915', 'title': 'Evaluating AI cyber capabilities with crowdsourced elicitation', 'authors': 'Artem Petrov, Dmitrii Volkov', 'link': 'https://arxiv.org/abs/2505.19915', 'abstract': 'As AI systems become increasingly capable, understanding their offensive cyber potential is critical for informed governance and responsible deployment. However, it\'s hard to accurately bound their capabilities, and some prior evaluations dramatically underestimated them. The art of extracting maximum task-specific performance from AIs is called "AI elicitation", and today\'s safety organizations typically conduct it in-house. In this paper, we explore crowdsourcing elicitation efforts as an alternative to in-house elicitation work.\nWe host open-access AI tracks at two Capture The Flag (CTF) competitions: AI vs. Humans (400 teams) and Cyber Apocalypse_ (4000 teams). The AI teams achieve outstanding performance at both events, ranking top-13% and top-21% respectively for a total of \\$7500 in bounties. This impressive performance suggests that open-market elicitation may offer an effective complement to in-house elicitation. We propose elicitation bounties as a practical mechanism for maintaining timely, cost-effective situational awareness of emerging AI capabilities.\nAnother advantage of open elicitations is the option to collect human performance data at scale. Applying METR\'s methodology, we found that AI agents can reliably solve cyber challenges requiring one hour or less of effort from a median human CTF participant.', 'abstract_zh': '随着AI系统的不断进步，理解其在网络攻击中的潜在能力对于明智的治理和负责任的应用至关重要。然而，准确界定其能力十分困难，一些先前的评估极大地低估了它们的能力。从AI中提取最大任务特定性能的艺术被称为“AI启示”，当前的安全组织通常在内部进行这一工作。本文探讨了将启示工作外包给众包作为一种替代方案。\n\n我们在美国两个Capture The Flag (CTF) 竞赛中主办开放访问的AI赛道：AI vs. Humans（400支队伍）和Cyber Apocalypse_（4000支队伍）。AI团队在两个赛事中表现出色，分别获得总奖金7500美元中的前13%和前21%的排名。这一出色的表现表明，开放市场启示可能为内部启示提供有效的补充。我们提议使用启示奖金作为一种实际机制，以保持对新兴AI能力的及时、成本效益高的态势感知。\n\n开放启示的另一个优势是可以大规模收集人类性能数据。采用METR的方法论，我们发现AI代理能够可靠地解决需要中位数CTF参与者一小时或更少努力的网络挑战。', 'title_zh': '基于众包诱发评估AI网络能力'}
{'arxiv_id': 'arXiv:2505.19914', 'title': 'Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles', 'authors': 'Jiangjie Chen, Qianyu He, Siyu Yuan, Aili Chen, Zhicheng Cai, Weinan Dai, Hongli Yu, Qiying Yu, Xuefeng Li, Jiaze Chen, Hao Zhou, Mingxuan Wang', 'link': 'https://arxiv.org/abs/2505.19914', 'abstract': "Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce Enigmata, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across seven categories, each with 1) a generator that produces unlimited examples with controllable difficulty and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose Enigmata-Eval, a rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata. This work offers a unified, controllable framework for advancing logical reasoning in LLMs. Resources of this work can be found at this https URL.", 'abstract_zh': '大型语言模型（LLMs）如OpenAI的o1和DeepSeek的R1通过可验证奖励强化学习（RLVR）在数学和编程等高级推理任务中表现出色，但仍然难以解决无需领域知识即可解决的人类谜题。我们引入了Enigmata，这是首个专门用于提高LLMs谜题推理能力的综合方案。它包括36项任务，涵盖七个类别，每个任务包含1）生成器，能够生成无限数量、可调控难度的示例，以及2）基于规则的验证器，用于自动评估。这种生成器-验证器设计支持可扩展的多任务RL训练、精细的分析和无缝的RLVR集成。我们还提出了Enigmata-Eval，一个严格的基准，并开发了优化的多任务RLVR策略。经过训练的模型Qwen2.5-32B-Enigmata在谜题推理基准测试如Enigmata-Eval、ARC-AGI（32.8%）和ARC-AGI 2（0.6%）中，持续超越o3-mini-high和o1。它在超出领域知识的谜题基准测试和数学推理中表现出良好的泛化能力，几乎没有多任务训练的代价。当使用更大规模的模型如Seed1.5-Thinking（200亿激活参数和2000亿总参数）进行训练时，来自Enigmata的数据进一步提高了LLMs在高级数学和STEM推理任务上的性能，如AIME（2024-2025）、BeyondAIME和GPQA（Diamond），展示了Enigmata的良好泛化优势。该项工作提供了一个统一可控的框架，以推进LLMs的逻辑推理能力。更多资源可在以下链接找到。', 'title_zh': 'Enigmata：在大型语言模型中通过合成可验证谜题扩展逻辑推理能力'}
{'arxiv_id': 'arXiv:2505.19912', 'title': 'APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization', 'authors': 'Javier Marín', 'link': 'https://arxiv.org/abs/2505.19912', 'abstract': 'We present Adjacent Possible Exploration (APE), a simple yet effective method for adapting large language models to specific tasks using minimal computational resources. Unlike traditional fine-tuning that requires extensive compute, APE iteratively fine-tunes models on small, carefully selected data batches (200 examples), retaining only improvements. On news summarization, APE achieves 40 percent BLEU improvement using just a T4 GPU in 60 minutes, matching or exceeding more complex methods like LoRA while remaining conceptually simple. Our approach is particularly valuable for researchers and practitioners with limited computational resources. We provide open-source code and demonstrate APE\'s effectiveness through both automatic metrics and human evaluation. While inspired by evolutionary theory\'s "adjacent possible", APE\'s core insight has a very practical application: small, iterative data perturbations can efficiently guide LLMs toward task-specific performance without expensive retraining.', 'abstract_zh': '我们提出相邻可能探索（APE），一种使用少量计算资源将大型语言模型适应于特定任务的简单而有效的方法。与需要大量计算的传统微调不同，APE 逐步在精心选择的数据批次（200 个示例）上进行微调，并仅保留改进。在新闻摘要任务上，APE 在使用单个 T4 GPU 仅 60 分钟内实现了 BLEU 得分 40% 的提升，其效果与 LoRA 等复杂方法相当或超越，同时保持概念上的简洁性。我们的方法特别适合计算资源有限的研究人员和 practitioners。我们提供了开源代码，并通过自动评价指标和人工评估展示了 APE 的有效性。虽然灵感源自进化理论的“相邻可能”，但 APE 的核心洞察具有非常实际的应用：小规模的迭代数据扰动可以有效引导大语言模型朝向任务特定性能，而无需昂贵的重新训练。', 'title_zh': 'APE：一种以数据为中心的高效LLM适应基准在文本摘要中的应用'}
{'arxiv_id': 'arXiv:2505.19887', 'title': 'Deconstructing Obfuscation: A four-dimensional framework for evaluating Large Language Models assembly code deobfuscation capabilities', 'authors': 'Anton Tkachenko, Dmitrij Suskevic, Benjamin Adolphi', 'link': 'https://arxiv.org/abs/2505.19887', 'abstract': 'Large language models (LLMs) have shown promise in software engineering, yet their effectiveness for binary analysis remains unexplored. We present the first comprehensive evaluation of commercial LLMs for assembly code deobfuscation. Testing seven state-of-the-art models against four obfuscation scenarios (bogus control flow, instruction substitution, control flow flattening, and their combination), we found striking performance variations--from autonomous deobfuscation to complete failure. We propose a theoretical framework based on four dimensions: Reasoning Depth, Pattern Recognition, Noise Filtering, and Context Integration, explaining these variations. Our analysis identifies five error patterns: predicate misinterpretation, structural mapping errors, control flow misinterpretation, arithmetic transformation errors, and constant propagation errors, revealing fundamental limitations in LLM code this http URL establish a three-tier resistance model: bogus control flow (low resistance), control flow flattening (moderate resistance), and instruction substitution/combined techniques (high resistance). Universal failure against combined techniques demonstrates that sophisticated obfuscation remains effective against advanced LLMs. Our findings suggest a human-AI collaboration paradigm where LLMs reduce expertise barriers for certain reverse engineering tasks while requiring human guidance for complex deobfuscation. This work provides a foundation for evaluating emerging capabilities and developing resistant obfuscation techniques.x deobfuscation. This work provides a foundation for evaluating emerging capabilities and developing resistant obfuscation techniques.', 'abstract_zh': '大型语言模型在二进制分析中的作用尚未探索：商业大型语言模型在汇编代码去混淆中的综合评估', 'title_zh': '解构混淆：评估大型语言模型反混淆编码能力的四维框架'}
{'arxiv_id': 'arXiv:2505.19874', 'title': 'StyleAR: Customizing Multimodal Autoregressive Model for Style-Aligned Text-to-Image Generation', 'authors': 'Yi Wu, Lingting Zhu, Shengju Qian, Lei Liu, Wandi Qiao, Lequan Yu, Bin Li', 'link': 'https://arxiv.org/abs/2505.19874', 'abstract': "In the current research landscape, multimodal autoregressive (AR) models have shown exceptional capabilities across various domains, including visual understanding and generation. However, complex tasks such as style-aligned text-to-image generation present significant challenges, particularly in data acquisition. In analogy to instruction-following tuning for image editing of AR models, style-aligned generation requires a reference style image and prompt, resulting in a text-image-to-image triplet where the output shares the style and semantics of the input. However, acquiring large volumes of such triplet data with specific styles is considerably more challenging than obtaining conventional text-to-image data used for training generative models. To address this issue, we propose StyleAR, an innovative approach that combines a specially designed data curation method with our proposed AR models to effectively utilize text-to-image binary data for style-aligned text-to-image generation. Our method synthesizes target stylized data using a reference style image and prompt, but only incorporates the target stylized image as the image modality to create high-quality binary data. To facilitate binary data training, we introduce a CLIP image encoder with a perceiver resampler that translates the image input into style tokens aligned with multimodal tokens in AR models and implement a style-enhanced token technique to prevent content leakage which is a common issue in previous work. Furthermore, we mix raw images drawn from large-scale text-image datasets with stylized images to enhance StyleAR's ability to extract richer stylistic features and ensure style consistency. Extensive qualitative and quantitative experiments demonstrate our superior performance.", 'abstract_zh': '基于多模态自回归模型的风格对齐文本到图像生成方法：StyleAR', 'title_zh': 'StyleAR: 为风格对齐文本到图像生成定制多模态自回归模型'}
{'arxiv_id': 'arXiv:2505.19867', 'title': 'Deep Active Inference Agents for Delayed and Long-Horizon Environments', 'authors': 'Yavar Taheri Yeganeh, Mohsen Jafari, Andrea Matta', 'link': 'https://arxiv.org/abs/2505.19867', 'abstract': 'With the recent success of world-model agents, which extend the core idea of model-based reinforcement learning by learning a differentiable model for sample-efficient control across diverse tasks, active inference (AIF) offers a complementary, neuroscience-grounded paradigm that unifies perception, learning, and action within a single probabilistic framework powered by a generative model. Despite this promise, practical AIF agents still rely on accurate immediate predictions and exhaustive planning, a limitation that is exacerbated in delayed environments requiring plans over long horizons, tens to hundreds of steps. Moreover, most existing agents are evaluated on robotic or vision benchmarks which, while natural for biological agents, fall short of real-world industrial complexity. We address these limitations with a generative-policy architecture featuring (i) a multi-step latent transition that lets the generative model predict an entire horizon in a single look-ahead, (ii) an integrated policy network that enables the transition and receives gradients of the expected free energy, (iii) an alternating optimization scheme that updates model and policy from a replay buffer, and (iv) a single gradient step that plans over long horizons, eliminating exhaustive planning from the control loop. We evaluate our agent in an environment that mimics a realistic industrial scenario with delayed and long-horizon settings. The empirical results confirm the effectiveness of the proposed approach, demonstrating the coupled world-model with the AIF formalism yields an end-to-end probabilistic controller capable of effective decision making in delayed, long-horizon settings without handcrafted rewards or expensive planning.', 'abstract_zh': '基于生成策略的主动推断代理：多步潜在过渡的实时预测与长期规划统一框架', 'title_zh': '深层主动推断代理用于延迟和长时域环境'}
{'arxiv_id': 'arXiv:2505.19853', 'title': 'Two Causally Related Needles in a Video Haystack', 'authors': 'Miaoyu Li, Qin Chao, Boyang Li', 'link': 'https://arxiv.org/abs/2505.19853', 'abstract': 'Evaluating the video understanding capabilities of Video-Language Models (VLMs) remains a significant challenge. We propose a long-context video understanding benchmark, Causal2Needles, that assesses two crucial abilities insufficiently evaluated by existing benchmarks: (1) the ability to extract information from two separate locations in a long video and understand them jointly, and (2) the ability to model the world in terms of cause and effect in human behaviors. Specifically, Causal2Needles introduces 2-needle questions, which require extracting information from both the cause and effect human-behavior events in a long video and the associated narration text. To prevent textual bias, these questions comprise two complementary formats: one asking to identify the video clip containing the answer, and one asking for the textual description of an unrelated visual detail from that video clip. Our experiments reveal that models excelling in pre-existing benchmarks struggle with 2-needle visual grounding, and the model performance is negatively correlated with the distance between the two needles. These findings highlight critical limitations in current VLMs.', 'abstract_zh': '评估视频语言模型的视频理解能力仍然是一个重大挑战。我们提出了一种长上下文视频理解基准测试Causal2Needles，该基准测试评估了现有基准测试中不足评估的两种关键能力：（1）从长视频的两个独立位置提取信息并联合理解的能力，以及（2）以因果关系建模人类行为中世界的能力。具体来说，Causal2Needles引入了2-针问题，要求从长视频及其相关叙述文本中的人类行为事件的因果关系中提取信息。为了防止文本偏差，这些问题包含两种互补的格式：一种是要求识别包含答案的视频片段，另一种是要求提供与该视频片段无关的视觉细节的文本描述。我们的实验表明，在现有基准测试中表现优异的模型在2-针视觉定位方面存在困难，模型性能与两个针之间的距离呈负相关。这些发现揭示了当前视频语言模型的关键局限性。', 'title_zh': '两个因果相关的视频针堆中的针'}
{'arxiv_id': 'arXiv:2505.19851', 'title': 'Beyond Specialization: Benchmarking LLMs for Transliteration of Indian Languages', 'authors': 'Gulfarogh Azam, Mohd Sadique, Saif Ali, Mohammad Nadeem, Erik Cambria, Shahab Saquib Sohail, Mohammad Sultan Alam', 'link': 'https://arxiv.org/abs/2505.19851', 'abstract': 'Transliteration, the process of mapping text from one script to another, plays a crucial role in multilingual natural language processing, especially within linguistically diverse contexts such as India. Despite significant advancements through specialized models like IndicXlit, recent developments in large language models suggest a potential for general-purpose models to excel at this task without explicit task-specific training. The current work systematically evaluates the performance of prominent LLMs, including GPT-4o, GPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, a state-of-the-art transliteration model, across ten major Indian languages. Experiments utilized standard benchmarks, including Dakshina and Aksharantar datasets, with performance assessed via Top-1 Accuracy and Character Error Rate. Our findings reveal that while GPT family models generally outperform other LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4o improves performance on specific languages notably. An extensive error analysis and robustness testing under noisy conditions further elucidate strengths of LLMs compared to specialized models, highlighting the efficacy of foundational models for a wide spectrum of specialized applications with minimal overhead.', 'abstract_zh': '文本转写：多语言自然语言处理中的关键过程，特别是在如印度等语言多样化的背景下扮演着重要角色。尽管通过专门的模型IndicXlit取得了显著进展，但最近大规模语言模型的发展表明，通用模型在无需明确的任务特定训练的情况下也有可能在这一任务中表现出色。当前的研究系统评估了包括GPT-4o、GPT-4.5、GPT-4.1、Gemma-3-27B-it和Mistral-Large在内的主要语言模型在十种主要印度语言中的性能，与最先进的转写模型IndicXlit进行对比。实验使用了标准基准数据集，如Dakshina和Aksharantar，性能通过Top-1准确率和字符错误率进行评估。我们的研究发现，GPT家族模型通常在大多数实例中优于其他语言模型和IndicXlit。此外，对GPT-4o进行微调在某些语言上的性能明显提高。广泛的错误分析和在噪声条件下的鲁棒性测试进一步阐明了语言模型相对于专门模型的优势，强调了基础模型在广泛的专业应用中的有效性和高效性。', 'title_zh': '超越专业化：跨考查询代理模型在印度语言 transliteration 任务上的基准测试'}
{'arxiv_id': 'arXiv:2505.19850', 'title': 'DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning', 'authors': 'Leander Diaz-Bone, Marco Bagatella, Jonas Hübotter, Andreas Krause', 'link': 'https://arxiv.org/abs/2505.19850', 'abstract': "Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.", 'abstract_zh': '稀疏奖励强化学习（RL）可以模型化广泛的高度复杂任务。解决稀疏奖励任务是RL的核心假设——需要高效探索与长期信用分配相结合——克服这些挑战是构建具有超人类能力的自我改进代理的关键。我们argue解决复杂和高维度任务需要解决与目标任务相关的一些简单任务。相比之下，大多数先有工作设计了选择探索性任务的策略，目标是解决任何任务，这使得探索具有挑战性的高维度、长期任务变得不可行。我们发现，有效的探索所必需的方向感可以从现有的RL算法中提取，无需任何先验信息。基于这一发现，我们提出了一种定向稀疏奖励目标导向非常长期任务（DISCOVER）的方法，该方法在目标任务方向选择探索性目标。我们将DISCOVER连接到原理上的探索理论，在形式上界定了从初始代理到目标的距离到达可实现时间，在目标任务可实现的时间与任务空间的体积无关。在实验上，我们在高维度环境中进行了全面评估。我们发现，DISCOVER的目标导向选择解决了先前RL中最佳探索方法都无法解决的探索问题。', 'title_zh': 'DISCOVER: 自动化稀疏奖励强化学习课程生成方法'}
{'arxiv_id': 'arXiv:2505.19842', 'title': 'PCDCNet: A Surrogate Model for Air Quality Forecasting with Physical-Chemical Dynamics and Constraints', 'authors': 'Shuo Wang, Yun Cheng, Qingye Meng, Olga Saukh, Jiang Zhang, Jingfang Fan, Yuanting Zhang, Xingyuan Yuan, Lothar Thiele', 'link': 'https://arxiv.org/abs/2505.19842', 'abstract': 'Air quality forecasting (AQF) is critical for public health and environmental management, yet remains challenging due to the complex interplay of emissions, meteorology, and chemical transformations. Traditional numerical models, such as CMAQ and WRF-Chem, provide physically grounded simulations but are computationally expensive and rely on uncertain emission inventories. Deep learning models, while computationally efficient, often struggle with generalization due to their lack of physical constraints. To bridge this gap, we propose PCDCNet, a surrogate model that integrates numerical modeling principles with deep learning. PCDCNet explicitly incorporates emissions, meteorological influences, and domain-informed constraints to model pollutant formation, transport, and dissipation. By combining graph-based spatial transport modeling, recurrent structures for temporal accumulation, and representation enhancement for local interactions, PCDCNet achieves state-of-the-art (SOTA) performance in 72-hour station-level PM2.5 and O3 forecasting while significantly reducing computational costs. Furthermore, our model is deployed in an online platform, providing free, real-time air quality forecasts, demonstrating its scalability and societal impact. By aligning deep learning with physical consistency, PCDCNet offers a practical and interpretable solution for AQF, enabling informed decision-making for both personal and regulatory applications.', 'abstract_zh': '空气质量预测（AQF）对于公共卫生和环境管理至关重要，但由于排放、气象和化学转化的复杂相互作用，仍具有挑战性。传统的数值模型，如CMAQ和WRF-Chem，提供了物理基础的模拟，但计算成本高且依赖于不确定的排放清单。深度学习模型虽然计算效率高，但由于缺乏物理约束，往往在泛化能力上存在局限。为弥合这一差距，我们提出了一种名为PCDCNet的替代模型，将数值模拟原理与深度学习相结合。PCDCNet明确地将排放、气象影响以及领域指导的约束纳入模型，以建模污染物的生成、传输和消散。通过结合基于图形的空间传输建模、用于时间积累的递归结构以及局部交互的表示增强，PCDCNet在72小时站点级PM2.5和O3预测中达到了最先进的性能，同时显著降低了计算成本。此外，该模型部署在一个在线平台上，提供免费的实时空气质量预报，展示了其可扩展性和社会影响。通过将深度学习与物理一致性相结合，PCDCNet为空气质量预测提供了实用且可解释的解决方案，促进了个人和监管应用中的知情决策。', 'title_zh': 'PCDCNet：一种考虑物理化学动态与约束的空气质量预测代理模型'}
{'arxiv_id': 'arXiv:2505.19838', 'title': 'FoodTaxo: Generating Food Taxonomies with Large Language Models', 'authors': 'Pascal Wullschleger, Majid Zarharan, Donnacha Daly, Marc Pouly, Jennifer Foster', 'link': 'https://arxiv.org/abs/2505.19838', 'abstract': 'We investigate the utility of Large Language Models for automated taxonomy generation and completion specifically applied to taxonomies from the food technology industry. We explore the extent to which taxonomies can be completed from a seed taxonomy or generated without a seed from a set of known concepts, in an iterative fashion using recent prompting techniques. Experiments on five taxonomies using an open-source LLM (Llama-3), while promising, point to the difficulty of correctly placing inner nodes.', 'abstract_zh': '我们探讨了大型语言模型在食品科技行业分类学生成与完成中的应用及其有效性，特别是在种子分类学或未知概念集中使用最近的提示技术迭代完成或生成分类学方面的程度。使用开源LLM（Llama-3）对五个分类学进行的实验尽管前景广阔，但仍表明正确放置内部节点的难度。', 'title_zh': 'FoodTaxo：使用大型语言模型生成食品分类学'}
{'arxiv_id': 'arXiv:2505.19827', 'title': 'Revisiting Glorot Initialization for Long-Range Linear Recurrences', 'authors': 'Noga Bar, Mariia Seleznova, Yotam Alexander, Gitta Kutyniok, Raja Giryes', 'link': 'https://arxiv.org/abs/2505.19827', 'abstract': 'Proper initialization is critical for Recurrent Neural Networks (RNNs), particularly in long-range reasoning tasks, where repeated application of the same weight matrix can cause vanishing or exploding signals. A common baseline for linear recurrences is Glorot initialization, designed to ensure stable signal propagation--but derived under the infinite-width, fixed-length regime--an unrealistic setting for RNNs processing long sequences. In this work, we show that Glorot initialization is in fact unstable: small positive deviations in the spectral radius are amplified through time and cause the hidden state to explode. Our theoretical analysis demonstrates that sequences of length $t = O(\\sqrt{n})$, where $n$ is the hidden width, are sufficient to induce instability. To address this, we propose a simple, dimension-aware rescaling of Glorot that shifts the spectral radius slightly below one, preventing rapid signal explosion or decay. These results suggest that standard initialization schemes may break down in the long-sequence regime, motivating a separate line of theory for stable recurrent initialization.', 'abstract_zh': '恰当的初始化对于循环神经网络（RNNs）至关重要，特别是在长范围推理任务中，相同的权重矩阵的反复应用会导致信号消失或爆炸。线性递归的常见基线是Glorot初始化，旨在确保信号传播的稳定性——但这一初始化是在无限宽度、固定长度的假设下推导出来的，这与处理长序列的RNNs的实际设置不现实。在本文中，我们证明Glorot初始化实际上并不稳定：谱半径的小正偏差随时间放大并导致隐藏状态爆炸。我们的理论分析表明，长度为$t = O(\\sqrt{n})$的序列，其中$n$是隐藏维度，就足以引发不稳定性。为了解决这一问题，我们提出了一种简单且维度感知的Glorot初始化调整，将谱半径稍微调整到低于1，从而防止信号的快速爆炸或衰减。这些结果表明，标准的初始化方案在长序列设置下可能失效，这激励建立一条独立的理论线来实现稳定的递归初始化。', 'title_zh': '重启Glorot初始化以适用于长范围线性循环'}
{'arxiv_id': 'arXiv:2505.19825', 'title': 'Foundation Models for Tabular Data within Systemic Contexts Need Grounding', 'authors': 'Tassilo Klein, Johannes Hoffart', 'link': 'https://arxiv.org/abs/2505.19825', 'abstract': 'Current research on tabular foundation models often overlooks the complexities of large-scale, real-world data by treating tables as isolated entities and assuming information completeness, thereby neglecting the vital operational context. To address this, we introduce the concept of Semantically Linked Tables (SLT), recognizing that tables are inherently connected to both declarative and procedural operational knowledge. We propose Foundation Models for Semantically Linked Tables (FMSLT), which integrate these components to ground tabular data within its true operational context. This comprehensive representation unlocks the full potential of machine learning for complex, interconnected tabular data across diverse domains. Realizing FMSLTs requires access to operational knowledge that is often unavailable in public datasets, highlighting the need for close collaboration between domain experts and researchers. Our work exposes the limitations of current tabular foundation models and proposes a new direction centered on FMSLTs, aiming to advance robust, context-aware models for structured data.', 'abstract_zh': '当前对表格基础模型的研究往往忽略了大规模现实世界数据的复杂性，将其视为孤立的实体并假设信息完备性，从而忽视了其重要的操作背景。为解决这一问题，我们引入了语义链接表格（SLT）的概念，认识到表格本质上与声明性和程序性操作知识紧密相连。我们提出了语义链接表格的基础模型（FMSLT），将这些组件结合起来，使表格数据在其真实的操作背景下得以体现。这种全面的表示形式解锁了机器学习在复杂、互联表格数据领域的全部潜力，适用于多个领域。实现FMSLTs需要访问公共数据集中通常不可用的操作知识，这突显了领域专家与研究人员密切合作的必要性。我们的研究揭示了当前表格基础模型的局限性，并提出了以FMSLT为中心的新方向，旨在推动结构化数据的稳健、基于上下文的模型的发展。', 'title_zh': '系统性背景下表格数据的Foundation Models需要 grounding'}
{'arxiv_id': 'arXiv:2505.19823', 'title': 'LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning in Heterogeneous Environments', 'authors': 'Pengcheng Sun, Erwu Liu, Wei Ni, Rui Wang, Yuanzhe Geng, Lijuan Lai, Abbas Jamalipour', 'link': 'https://arxiv.org/abs/2505.19823', 'abstract': 'Federated Learning (FL) is a distributed machine learning paradigm based on protecting data privacy of devices, which however, can still be broken by gradient leakage attack via parameter inversion techniques. Differential privacy (DP) technology reduces the risk of private data leakage by adding artificial noise to the gradients, but detrimental to the FL utility at the same time, especially in the scenario where the data is Non-Independent Identically Distributed (Non-IID). Based on the impact of heterogeneous data on aggregation performance, this paper proposes a Lightweight Adaptive Privacy Allocation (LAPA) strategy, which assigns personalized privacy budgets to devices in each aggregation round without transmitting any additional information beyond gradients, ensuring both privacy protection and aggregation efficiency. Furthermore, the Deep Deterministic Policy Gradient (DDPG) algorithm is employed to optimize the transmission power, in order to determine the optimal timing at which the adaptively attenuated artificial noise aligns with the communication noise, enabling an effective balance between DP and system utility. Finally, a reliable aggregation strategy is designed by integrating communication quality and data distribution characteristics, which improves aggregation performance while preserving privacy. Experimental results demonstrate that the personalized noise allocation and dynamic optimization strategy based on LAPA proposed in this paper enhances convergence performance while satisfying the privacy requirements of FL.', 'abstract_zh': '联邦学习(Federated Learning)是一种基于保护设备数据隐私的分布式机器学习范式，但是仍可通过参数反向技术遭受梯度泄漏攻击的破坏。差分隐私(Differential Privacy)技术通过对梯度添加人工噪声来降低私有数据泄漏的风险，但同时会损害联邦学习的实用性，尤其是在数据非独立同分布(Non-IID)的场景中。基于异质数据对聚合性能的影响，本文提出一种轻量级自适应隐私分配(LAPA)策略，在每次聚合周期内为设备分配个性化的隐私预算，而无需传输任何额外信息，确保同时实现隐私保护和聚合效率。此外，采用深度确定性策略梯度(Deep Deterministic Policy Gradient, DDPG)算法优化传输功率，以确定适配衰减人工噪声与通信噪声的最佳时机，实现差分隐私与系统实用性的有效平衡。最后，通过整合通信质量和数据分布特征设计一种可靠的聚合策略，改进聚合性能同时保持隐私。实验结果表明，本文提出的基于LAPA的个性化噪声分配和动态优化策略在满足联邦学习隐私要求的同时提升了收敛性能。', 'title_zh': '基于LAPA的异构环境中无线联邦学习的动态隐私优化'}
{'arxiv_id': 'arXiv:2505.19819', 'title': 'FinLoRA: Benchmarking LoRA Methods for Fine-Tuning LLMs on Financial Datasets', 'authors': 'Dannong Wang, Jaisal Patel, Daochen Zha, Steve Y. Yang, Xiao-Yang Liu', 'link': 'https://arxiv.org/abs/2505.19819', 'abstract': 'Low-rank adaptation (LoRA) methods show great potential for scaling pre-trained general-purpose Large Language Models (LLMs) to hundreds or thousands of use scenarios. However, their efficacy in high-stakes domains like finance is rarely explored, e.g., passing CFA exams and analyzing SEC filings. In this paper, we present the open-source FinLoRA project that benchmarks LoRA methods on both general and highly professional financial tasks. First, we curated 19 datasets covering diverse financial applications; in particular, we created four novel XBRL analysis datasets based on 150 SEC filings. Second, we evaluated five LoRA methods and five base LLMs. Finally, we provide extensive experimental results in terms of accuracy, F1, and BERTScore and report computational cost in terms of time and GPU memory during fine-tuning and inference stages. We find that LoRA methods achieved substantial performance gains of 36\\% on average over base models. Our FinLoRA project provides an affordable and scalable approach to democratize financial intelligence to the general public. Datasets, LoRA adapters, code, and documentation are available at this https URL', 'abstract_zh': '低秩适应（LoRA）方法在将预训练的通用大型语言模型（LLMs）扩展到数百或数千种应用场景方面显示出巨大潜力。然而，它们在金融等高风险领域中的效果鲜有探索，例如通过CFA考试和分析SEC文件。本文介绍了开源FinLoRA项目，该项目在通用和高度专业化的金融任务上对LoRA方法进行了基准测试。首先，我们收集了19个涵盖多种金融应用的数据集；特别是，我们基于150份SEC文件创建了四个新的XBRL分析数据集。其次，我们评估了五种LoRA方法和五种基础LLM。最后，我们从准确率、F1和BERTScore方面提供了详尽的实验结果，并报告了微调和推理阶段的计算成本。我们发现，LoRA方法在平均性能上比基础模型提高了36%。我们的FinLoRA项目提供了一种经济实惠且可扩展的方法，以使金融智能普及化。数据集、LoRA适配器、代码和文档可在以下网址获取。', 'title_zh': 'FinLoRA: LoRA 方法在金融数据集上 fine-tuning LLMs 的基准测试'}
{'arxiv_id': 'arXiv:2505.19815', 'title': 'Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective', 'authors': 'Junnan Liu, Hongwei Liu, Linchen Xiao, Shudong Liu, Taolin Zhang, Zihan Ma, Songyang Zhang, Kai Chen', 'link': 'https://arxiv.org/abs/2505.19815', 'abstract': "We propose a novel framework for comprehending the reasoning capabilities of large language models (LLMs) through the perspective of meta-learning. By conceptualizing reasoning trajectories as pseudo-gradient descent updates to the LLM's parameters, we identify parallels between LLM reasoning and various meta-learning paradigms. We formalize the training process for reasoning tasks as a meta-learning setup, with each question treated as an individual task, and reasoning trajectories serving as the inner loop optimization for adapting model parameters. Once trained on a diverse set of questions, the LLM develops fundamental reasoning capabilities that can generalize to previously unseen questions. Extensive empirical evaluations substantiate the strong connection between LLM reasoning and meta-learning, exploring several issues of significant interest from a meta-learning standpoint. Our work not only enhances the understanding of LLM reasoning but also provides practical insights for improving these models through established meta-learning techniques.", 'abstract_zh': '我们提出了一种通过元学习视角理解大规模语言模型推理能力的新框架。通过将推理轨迹构思为伪梯度下降更新到语言模型参数，我们找到了语言模型推理与多种元学习 paradigm 之间的相似性。我们将推理任务的训练过程形式化为一个元学习设置，每个问题被视为单独的任务，推理轨迹作为内环优化，用于适应模型参数。经过对一系列不同问题的训练后，语言模型发展出能够泛化到以前未见过的问题的基本推理能力。广泛的实证评估证实了语言模型推理与元学习之间的密切联系，并探讨了元学习视角下的若干重要问题。我们的工作不仅增强了对语言模型推理的理解，还提供了通过现有元学习技术改进这些模型的实际见解。', 'title_zh': '基于轨迹辅助的大模型推理解析：一种优化视角'}
{'arxiv_id': 'arXiv:2505.19809', 'title': 'Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees', 'authors': 'Daniel Ordoñez-Apraez, Alek Fröhlich, Vladimir Kostić, Karim Lounici, Vivien Brandt, Massimiliano Pontil', 'link': 'https://arxiv.org/abs/2505.19809', 'abstract': 'In many real-world applications of regression, conditional probability estimation, and uncertainty quantification, exploiting symmetries rooted in physics or geometry can dramatically improve generalization and sample efficiency. While geometric deep learning has made significant empirical advances by incorporating group-theoretic structure, less attention has been given to statistical learning guarantees. In this paper, we introduce an equivariant representation learning framework that simultaneously addresses regression, conditional probability estimation, and uncertainty quantification while providing first-of-its-kind non-asymptotic statistical learning guarantees. Grounded in operator and group representation theory, our framework approximates the spectral decomposition of the conditional expectation operator, building representations that are both equivariant and disentangled along independent symmetry subgroups. Empirical evaluations on synthetic datasets and real-world robotics applications confirm the potential of our approach, matching or outperforming existing equivariant baselines in regression while additionally providing well-calibrated parametric uncertainty estimates.', 'abstract_zh': '在回归、条件概率估计和不确定性量化等许多实际应用中，利用物理学或几何学根植的对称性可以显著提高泛化能力和样本效率。虽然几何深度学习通过纳入群论结构取得了显著的经验进步，但很少关注统计学习保证。在本文中，我们提出了一种同时解决回归、条件概率估计和不确定性量化问题的协变表示学习框架，并提供了首个非渐近统计学习保证。基于算子表示论和群表示论，我们的框架逼近条件期望算子的谱分解，构建既协变又沿独立对称子群分离的表示。在合成数据集和实际机器人应用中的实验评估证实了我们方法的潜力，在回归任务上匹配甚至超越现有的协变基准方法，并额外提供校准良好的参数不确定性估计。', 'title_zh': '对称意识保证下等变表示学习'}
{'arxiv_id': 'arXiv:2505.19795', 'title': 'The Missing Point in Vision Transformers for Universal Image Segmentation', 'authors': 'Sajjad Shahabodini, Mobina Mansoori, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi', 'link': 'https://arxiv.org/abs/2505.19795', 'abstract': 'Image segmentation remains a challenging task in computer vision, demanding robust mask generation and precise classification. Recent mask-based approaches yield high-quality masks by capturing global context. However, accurately classifying these masks, especially in the presence of ambiguous boundaries and imbalanced class distributions, remains an open challenge. In this work, we introduce ViT-P, a novel two-stage segmentation framework that decouples mask generation from classification. The first stage employs a proposal generator to produce class-agnostic mask proposals, while the second stage utilizes a point-based classification model built on the Vision Transformer (ViT) to refine predictions by focusing on mask central points. ViT-P serves as a pre-training-free adapter, allowing the integration of various pre-trained vision transformers without modifying their architecture, ensuring adaptability to dense prediction tasks. Furthermore, we demonstrate that coarse and bounding box annotations can effectively enhance classification without requiring additional training on fine annotation datasets, reducing annotation costs while maintaining strong performance. Extensive experiments across COCO, ADE20K, and Cityscapes datasets validate the effectiveness of ViT-P, achieving state-of-the-art results with 54.0 PQ on ADE20K panoptic segmentation, 87.4 mIoU on Cityscapes semantic segmentation, and 63.6 mIoU on ADE20K semantic segmentation. The code and pretrained models are available at: this https URL}{this https URL.', 'abstract_zh': 'Image分割仍然是计算机视觉中的一个具有挑战性的任务，要求生成稳健的掩码并进行精确分类。基于掩码的方法通过捕捉全局上下文生成高质量的掩码。然而，特别是在边界模糊和类别分布不均衡的情况下准确地对这些掩码进行分类仍然是一项开放性的挑战。在这项工作中，我们提出了一种新颖的两阶段分割框架ViT-P，该框架将掩码生成与分类解耦。第一阶段使用提案生成器生成类别无关的掩码提案，而第二阶段利用基于Vision Transformer (ViT) 的点分类模型，通过对掩码中心点进行关注来细化预测。ViT-P 作为一个无预训练的适配器，允许集成各种预训练的视觉变换器而不修改其架构，确保其适用于密集预测任务。此外，我们展示了粗略的和边界框注解能够有效提高分类性能，而无需在精细注解数据集上进行额外训练，从而降低注解成本并保持良好的性能。跨COCO、ADE20K和Cityscapes数据集的大量实验验证了ViT-P的有效性，在ADE20K全景分割中达到54.0的PQ，在Cityscapes语义分割中达到87.4的mIoU，在ADE20K语义分割中达到63.6的mIoU。代码和预训练模型可在以下链接获取：this https URL this https URL。', 'title_zh': '视觉变换器中缺失的点：面向通用图像分割的改进'}
{'arxiv_id': 'arXiv:2505.19790', 'title': 'Alpay Algebra III: Observer-Coupled Collapse and the Temporal Drift of Identity', 'authors': 'Faruk Alpay', 'link': 'https://arxiv.org/abs/2505.19790', 'abstract': 'This paper introduces a formal framework for modeling observer-dependent collapse dynamics and temporal identity drift within artificial and mathematical systems, grounded entirely in the symbolic foundations of Alpay Algebra. Building upon the fixed-point emergence structures developed in Alpay Algebra I and II, this third installment formalizes the observer-coupled {\\phi}-collapse process through transfinite categorical flows and curvature-driven identity operators. We define a novel temporal drift mechanism as a recursive deformation of identity signatures under entangled observer influence, constructing categorical invariants that evolve across fold iterations. The proposed system surpasses conventional identity modeling in explainable AI (XAI) by encoding internal transformation history into a symbolic fixed-point structure, offering provable traceability and temporal coherence. Applications range from AI self-awareness architectures to formal logic systems where identity is not static but dynamically induced by observation. The theoretical results also offer a mathematically rigorous basis for future AI systems with stable self-referential behavior, positioning Alpay Algebra as a next-generation symbolic framework bridging category theory, identity logic, and observer dynamics.', 'abstract_zh': '本文介绍了一种形式框架，用于在人工和数学系统中建模观察者依赖的塌缩动力学和时间身份漂移，完全基于Alpay代数的符号基础。在Alpay代数I和II中发展起来的固定点涌现结构的基础上，本文的第三部分通过超限范畴流和曲率驱动的身份运算符正式化了观察者耦合的{\\phi}-塌缩过程。定义了一种新的时间漂移机制，作为缠结观察者影响下身份签名的递归变形，构建了在折叠迭代中演化的范畴不变式。所提出的系统超越了在解释性人工智能(XAI)中的常规身份建模，通过将内部转变历史编码到符号固定点结构中，提供了可证明的可追溯性和时间连续性。应用范围从具有自意识架构的人工智能到身份不是静态而是由观察动态诱导的正式逻辑系统。理论结果还为具有稳定自我参照行为的未来人工智能系统提供了一个严格的数学基础，将Alpay代数定位为一种下一代符号框架，结合了范畴论、身份逻辑和观察者动力学。', 'title_zh': 'Alpay代数III：观察者耦合的坍缩与身份的时间漂移'}
{'arxiv_id': 'arXiv:2505.19785', 'title': 'MedDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support', 'authors': 'Qianyi Xu, Gousia Habib, Dilruk Perera, Mengling Feng', 'link': 'https://arxiv.org/abs/2505.19785', 'abstract': 'Timely and personalized treatment decisions are essential across a wide range of healthcare settings where patient responses vary significantly and evolve over time. Clinical data used to support these decisions are often irregularly sampled, sparse, and noisy. Existing decision support systems commonly rely on discretization and imputation, which can distort critical temporal dynamics and degrade decision quality. Moreover, they often overlook the clinical significance of irregular recording frequencies, filtering out patterns in how and when data is collected. Reinforcement Learning (RL) is a natural fit for clinical decision-making, enabling sequential, long-term optimization in dynamic, uncertain environments. However, most existing treatment recommendation systems are model-free and trained solely on offline data, making them sample-inefficient, sensitive to data quality, and poorly generalizable across tasks or cohorts. To address these limitations, we propose MedDreamer, a two-phase model-based RL framework for personalized treatment recommendation. MedDreamer uses a world model with an Adaptive Feature Integration (AFI) module to effectively model irregular, sparse clinical data. Through latent imagination, it simulates plausible patient trajectories to enhance learning, refining its policy using a mix of real and imagined experiences. This enables learning policies that go beyond suboptimal historical decisions while remaining grounded in clinical data. To our knowledge, this is the first application of latent imagination to irregular healthcare data. Evaluations on sepsis and mechanical ventilation (MV) treatment using two large-scale EHR datasets show that MedDreamer outperforms both model-free and model-based baselines in clinical outcomes and off-policy metrics.', 'abstract_zh': '及时且个性化的治疗决策在临床响应变化显著且随时间演变的广泛医疗保健场景中至关重要。用于支持这些决策的临床数据往往稀疏、不规则采样且含噪声。现有的决策支持系统通常依赖离散化和插补，这可能会扭曲关键的时间动态并降低决策质量。此外，它们往往忽视了不规则记录频率的临床意义，过滤掉了数据收集模式。强化学习（RL）是临床决策的理想选择，能够在一个动态且不确定的环境中实现长期的序列优化。然而，现有的大多数治疗推荐系统都是无模型的，并且仅在离线数据上进行训练，这使得它们样本效率低下、对数据质量敏感，并且难以泛化到不同的任务或队列。为了解决这些限制，我们提出了一种基于模型的两阶段RL框架MedDreamer，用于个性化的治疗推荐。MedDreamer 使用一个具有自适应特征整合（AFI）模块的世界模型来有效建模不规则的稀疏临床数据。通过潜在的想象，它模拟可能的患者轨迹以增强学习，并利用真实和想象的经验混合优化其策略。这使得学习的策略能够超越历史上的次优决策，同时仍与临床数据保持关联。据我们所知，这是首次将潜在想象应用于不规则的医疗保健数据。使用两个大规模EHR数据集对感染性休克和机械通气（MV）治疗进行评估表明，MedDreamer 在临床结果和离线策略指标上均优于无模型和基于模型的基线。', 'title_zh': 'MedDreamer: 基于模型的强化学习与潜在想象在复杂电子健康记录中的临床决策支持'}
{'arxiv_id': 'arXiv:2505.19776', 'title': 'Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification', 'authors': 'Akram Elbouanani, Evan Dufraisse, Adrian Popescu', 'link': 'https://arxiv.org/abs/2505.19776', 'abstract': 'Political biases encoded by LLMs might have detrimental effects on downstream applications. Existing bias analysis methods rely on small-size intermediate tasks (questionnaire answering or political content generation) and rely on the LLMs themselves for analysis, thus propagating bias. We propose a new approach leveraging the observation that LLM sentiment predictions vary with the target entity in the same sentence. We define an entropy-based inconsistency metric to encode this prediction variability. We insert 1319 demographically and politically diverse politician names in 450 political sentences and predict target-oriented sentiment using seven models in six widely spoken languages. We observe inconsistencies in all tested combinations and aggregate them in a statistically robust analysis at different granularity levels. We observe positive and negative bias toward left and far-right politicians and positive correlations between politicians with similar alignment. Bias intensity is higher for Western languages than for others. Larger models exhibit stronger and more consistent biases and reduce discrepancies between similar languages. We partially mitigate LLM unreliability in target-oriented sentiment classification (TSC) by replacing politician names with fictional but plausible counterparts.', 'abstract_zh': 'LLMs中的政治偏见编码可能对下游应用产生负面影响。现有偏见分析方法依赖于小型中间任务（问卷回答或政治内容生成）并通过LLM本身进行分析，从而传播偏见。我们提出了一种新方法，利用LLM在同一句子中对目标实体的情感预测变化这一观察。我们定义了一个基于熵的不一致性度量来编码这种预测变化。我们在450个政治句子中插入了1319个在政治和人口统计学层面都多元化的政治家姓名，并使用六种广泛使用的语言中的七个模型进行目标导向的情感预测。我们在所有测试组合中观察到不一致性，并在不同粒度水平上进行稳健的统计聚合分析。我们观察到对左翼和极右翼政治家的正向和负向偏见，并发现相似政见的政治家之间存在正相关关系。西方语言中的偏见强度高于其他语言。更大规模的模型显示出更强的且更一致的偏见，并减少了相似语言之间的分歧。通过用虚构但可信的对应名称替换政治家姓名，我们在目标导向的情感分类（TSC）中部分缓解了LLM的不可靠性。', 'title_zh': '基于目标导向情感分类分析LLMs中的政治偏见'}
{'arxiv_id': 'arXiv:2505.19769', 'title': 'TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning', 'authors': 'Yuhui Chen, Haoran Li, Zhennan Jiang, Haowei Wen, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2505.19769', 'abstract': "Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.", 'abstract_zh': '基于扩散模型的文本到视频奖励生成方法在强化学习中的应用：促进可扩展和通用的奖励工程，特别是在机器人操作的挑战性领域中的应用', 'title_zh': 'TeViR: 基于扩散模型的文本到视频奖励高效强化学习'}
{'arxiv_id': 'arXiv:2505.19764', 'title': 'Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding', 'authors': 'Patara Trirat, Wonyong Jeong, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2505.19764', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but optimizing LLM-based agentic systems remains challenging due to the vast search space of agent configurations, prompting strategies, and communication patterns. Existing approaches often rely on heuristic-based tuning or exhaustive evaluation, which can be computationally expensive and suboptimal. This paper proposes Agentic Predictor, a lightweight predictor for efficient agentic workflow evaluation. Agentic Predictor is equipped with a multi-view workflow encoding technique that leverages multi-view representation learning of agentic systems by incorporating code architecture, textual prompts, and interaction graph features. To achieve high predictive accuracy while significantly reducing the number of required workflow evaluations for training a predictor, Agentic Predictor employs cross-domain unsupervised pretraining. By learning to approximate task success rates, Agentic Predictor enables fast and accurate selection of optimal agentic workflow configurations for a given task, significantly reducing the need for expensive trial-and-error evaluations. Experiments on a carefully curated benchmark spanning three domains show that our predictor outperforms state-of-the-art methods in both predictive accuracy and workflow utility, highlighting the potential of performance predictors in streamlining the design of LLM-based agentic workflows.', 'abstract_zh': '大型语言模型（LLMs）在多样化的任务中展现了卓越的能力，但由于代理系统配置、提示策略和通信模式的巨大搜索空间，优化基于LLM的代理系统仍然具有挑战性。现有方法通常依赖启发式调整或穷尽评估，这可能导致计算成本高昂且效果欠佳。本文提出了一种轻量级的代理预测器（Agentic Predictor），用于高效代理工作流评估。代理预测器配备了一种多视角工作流编码技术，该技术通过结合代码架构、文本提示和交互图特征，利用多视图表示学习代理系统。为了在显著减少用于训练预测器的工作流评估次数的同时保持高预测准确性，代理预测器采用了跨域无监督预训练。通过学习近似任务成功率，代理预测器能够快速准确地选择给定任务的最佳代理工作流配置，大幅减少昂贵的试错评估需求。在跨越三个领域精心策划的基准测试上进行的实验表明，我们的预测器在预测准确性和工作流实用性方面均优于现有最先进的方法，突显了性能预测器在简化基于LLM的代理工作流设计方面的潜力。', 'title_zh': '代理预测者：通过多视图编码实现代理工作流的性能预测'}
{'arxiv_id': 'arXiv:2505.19757', 'title': 'CIDRe: A Reference-Free Multi-Aspect Criterion for Code Comment Quality Measurement', 'authors': 'Maria Dziuba, Valentin Malykh', 'link': 'https://arxiv.org/abs/2505.19757', 'abstract': "Effective generation of structured code comments requires robust quality metrics for dataset curation, yet existing approaches (SIDE, MIDQ, STASIS) suffer from limited code-comment analysis. We propose CIDRe, a language-agnostic reference-free quality criterion combining four synergistic aspects: (1) relevance (code-comment semantic alignment), (2) informativeness (functional coverage), (3) completeness (presence of all structure sections), and (4) description length (detail sufficiency). We validate our criterion on a manually annotated dataset. Experiments demonstrate CIDRe's superiority over existing metrics, achieving improvement in cross-entropy evaluation. When applied to filter comments, the models finetuned on CIDRe-filtered data show statistically significant quality gains in GPT-4o-mini assessments.", 'abstract_zh': '有效生成结构化代码注释需要 robust 的质量评估指标以确保数据集的高质量，现有的方法（如SIDE、MIDQ、STASIS）在代码-注释分析方面存在局限性。我们提出 CIDRe，这是一种语言无关的无参考质量标准，结合了四个协同方面：（1）相关性（代码-注释语义对齐），（2）信息量（功能覆盖率），（3）完整性（所有结构部分的存在），和（4）描述长度（细节充分性）。我们对手动标注的数据集验证了该标准。实验表明，CIDRe 在交叉熵评估中优于现有指标，并且在使用 CIDRe 过滤后的数据微调模型的 GPT-4o-mini 评估中显示出统计显著的质量提升。', 'title_zh': 'CIDRe：一种无需参考的多方面代码注释质量评估标准'}
{'arxiv_id': 'arXiv:2505.19754', 'title': 'NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering', 'authors': 'Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuxin Zhang, Liangtai Sun, Hanqi Li, Yuxun Miao, Shuai Fan, Lu Chen, Kai Yu', 'link': 'https://arxiv.org/abs/2505.19754', 'abstract': 'The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic retrieval despite their complementary strengths. Moreover, conventional single-view chunking neglects the rich structure and layout of PDFs, e.g., sections and tables. In this work, we propose NeuSym-RAG, a hybrid neural symbolic retrieval framework which combines both paradigms in an interactive process. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG organizes semi-structured PDF content into both the relational database and vectorstore, enabling LLM agents to iteratively gather context until sufficient to generate answers. Experiments on three full PDF-based QA datasets, including a self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the vector-based RAG and various structured baselines, highlighting its capacity to unify both retrieval schemes and utilize multiple views. Code and data are publicly available at this https URL.', 'abstract_zh': '不断增加的学术论文数量为研究人员高效获取关键细节带来了重大挑战。虽然基于大规模语言模型（LLM）的检索增强生成（RAG）在自动问答方面显示出巨大潜力，但以往的研究往往将神经检索和符号检索隔离，尽管两者具有互补的优势。此外，传统的单视图切块忽略了PDF的丰富结构和布局，例如段落和表格。在本工作中，我们提出了NeuSym-RAG，这是一种结合了这两种范式的混合神经符号检索框架，并在交互过程中将两者结合起来。通过利用多视图切块和基于模式的解析，NeuSym-RAG 将半结构化的PDF内容组织到关系数据库和向量存储中，使LLM代理能够迭代地收集上下文，直到生成答案所需的信息充分。在三个基于全文PDF的问答数据集中进行了实验，包括一个自我注释的数据集AIRQA-REAL，结果显示NeuSym-RAG在对比基于向量的RAG和各种结构化基线时表现出稳定的优势，突显了其统一检索方案并利用多个视图的能力。代码和数据可在以下网址公开获取。', 'title_zh': 'NeuSym-RAG：基于多视图结构化的混合神经符号检索方法及其在PDF问答中的应用'}
{'arxiv_id': 'arXiv:2505.19752', 'title': 'Discrete Markov Bridge', 'authors': 'Hengli Li, Yuxuan Wang, Song-Chun Zhu, Ying Nian Wu, Zilong Zheng', 'link': 'https://arxiv.org/abs/2505.19752', 'abstract': 'Discrete diffusion has recently emerged as a promising paradigm in discrete data modeling. However, existing methods typically rely on a fixed rate transition matrix during training, which not only limits the expressiveness of latent representations, a fundamental strength of variational methods, but also constrains the overall design space. To address these limitations, we propose Discrete Markov Bridge, a novel framework specifically designed for discrete representation learning. Our approach is built upon two key components: Matrix Learning and Score Learning. We conduct a rigorous theoretical analysis, establishing formal performance guarantees for Matrix Learning and proving the convergence of the overall framework. Furthermore, we analyze the space complexity of our method, addressing practical constraints identified in prior studies. Extensive empirical evaluations validate the effectiveness of the proposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO) of 1.38 on the Text8 dataset, outperforming established baselines. Moreover, the proposed model demonstrates competitive performance on the CIFAR-10 dataset, achieving results comparable to those obtained by image-specific generation approaches.', 'abstract_zh': '离散扩散 Recently Emerged as a Promising Paradigm in Discrete Data Modeling: Discrete Markov Bridge—a Novel Framework for Discrete Representation Learning', 'title_zh': '离散马尔可夫桥'}
{'arxiv_id': 'arXiv:2505.19722', 'title': "Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic Biomedical Entity Linking", 'authors': 'Yihao Ai, Zhiyuan Ning, Weiwei Dai, Pengfei Wang, Yi Du, Wenjuan Cui, Kunpeng Liu, Yuanchun Zhou', 'link': 'https://arxiv.org/abs/2505.19722', 'abstract': "Biomedical entity linking aims to map nonstandard entities to standard entities in a knowledge base. Traditional supervised methods perform well but require extensive annotated data to transfer, limiting their usage in low-resource scenarios. Large language models (LLMs), especially closed-source LLMs, can address these but risk stability issues and high economic costs: using these models is restricted by commercial companies and brings significant economic costs when dealing with large amounts of data. To address this, we propose ``RPDR'', a framework combining closed-source LLMs and open-source LLMs for re-ranking candidates retrieved by a retriever fine-tuned with a small amount of data. By prompting a closed-source LLM to generate training data from unannotated data and fine-tuning an open-source LLM for re-ranking, we effectively distill the knowledge to the open-source LLM that can be deployed locally, thus avoiding the stability issues and the problem of high economic costs. We evaluate RPDR on two datasets, including one real-world dataset and one publicly available dataset involving two languages: Chinese and English. RPDR achieves 0.019 Acc@1 improvement and 0.036 Acc@1 improvement on the Aier dataset and the Ask A Patient dataset when the amount of training data is not enough. The results demonstrate the superiority and generalizability of the proposed framework.", 'abstract_zh': '生物医学实体链接旨在将非标准实体映射到知识库中的标准实体。传统的监督方法表现良好，但需要大量标注数据以进行转移，这限制了它们在低资源场景中的应用。大型语言模型（LLMs），尤其是闭源LLMs，可以解决这些问题，但也存在稳定性和高经济成本的风险：使用这些模型受到商业公司的限制，并且在处理大量数据时会产生显著的经济成本。为此，我们提出了一种名为“RPDR”的框架，该框架结合了闭源LLMs和开源LLMs，用于对检索器微调后检索出的候选项进行再排序。通过促使闭源LLMs从未标注数据生成训练数据，并对开源LLMs进行再排序微调，我们有效地将知识转移到可以本地部署的开源LLMs中，从而避免了稳定性和高经济成本的问题。我们在两个数据集上评估了RPDR，包括一个真实世界数据集和一个包含中英文的公共数据集。当训练数据不足时，RPDR在Aier数据集和Ask A Patient数据集上分别实现了0.019和0.036的Acc@1改进。实验结果表明了提出框架的优越性和通用性。', 'title_zh': '从闭源大型语言模型中蒸馏知识以实现本地稳定和经济的生物医学实体链接'}
{'arxiv_id': 'arXiv:2505.19719', 'title': 'OCN: Effectively Utilizing Higher-Order Common Neighbors for Better Link Prediction', 'authors': 'Juntong Wang, Xiyuan Wang, Muhan Zhang', 'link': 'https://arxiv.org/abs/2505.19719', 'abstract': 'Common Neighbors (CNs) and their higher-order variants are important pairwise features widely used in state-of-the-art link prediction methods. However, existing methods often struggle with the repetition across different orders of CNs and fail to fully leverage their potential. We identify that these limitations stem from two key issues: redundancy and over-smoothing in high-order common neighbors. To address these challenges, we design orthogonalization to eliminate redundancy between different-order CNs and normalization to mitigate over-smoothing. By combining these two techniques, we propose Orthogonal Common Neighbor (OCN), a novel approach that significantly outperforms the strongest baselines by an average of 7.7% on popular link prediction benchmarks. A thorough theoretical analysis is provided to support our method. Ablation studies also verify the effectiveness of our orthogonalization and normalization techniques.', 'abstract_zh': 'Common Neighbors (CNs) 及其高阶变体是广泛应用于先进链接预测方法中的重要成对特征。然而，现有方法往往难以处理不同阶次的重复性问题，并未能充分挖掘其潜力。我们发现这些限制源于两个关键问题：高阶共同邻居的冗余性和过度平滑。为应对这些挑战，我们设计了正交化来消除不同阶次共同邻居之间的冗余，并使用规范化来减轻过度平滑。通过结合这两种技术，我们提出了一种新颖的方法——正交共同邻居（OCN），该方法在流行的链接预测基准测试中平均比最强基线高出7.7%。提供了详尽的理论分析以支持我们的方法，并通过消融研究验证了我们正交化和规范化技术的有效性。', 'title_zh': 'OCN：更有效地利用高阶共同邻居进行链接预测'}
{'arxiv_id': 'arXiv:2505.19715', 'title': 'Graceful Forgetting in Generative Language Models', 'authors': 'Chunyang Jiang, Chi-min Chan, Yiyang Cai, Yulong Liu, Wei Xue, Yike Guo', 'link': 'https://arxiv.org/abs/2505.19715', 'abstract': 'Recently, the pretrain-finetune paradigm has become a cornerstone in various deep learning areas. While in general the pre-trained model would promote both effectiveness and efficiency of downstream tasks fine-tuning, studies have shown that not all knowledge acquired during pre-training is beneficial. Some of the knowledge may actually bring detrimental effects to the fine-tuning tasks, which is also known as negative transfer. To address this problem, graceful forgetting has emerged as a promising approach. The core principle of graceful forgetting is to enhance the learning plasticity of the target task by selectively discarding irrelevant knowledge. However, this approach remains underexplored in the context of generative language models, and it is often challenging to migrate existing forgetting algorithms to these models due to architecture incompatibility. To bridge this gap, in this paper we propose a novel framework, Learning With Forgetting (LWF), to achieve graceful forgetting in generative language models. With Fisher Information Matrix weighting the intended parameter updates, LWF computes forgetting confidence to evaluate self-generated knowledge regarding the forgetting task, and consequently, knowledge with high confidence is periodically unlearned during fine-tuning. Our experiments demonstrate that, although thoroughly uncovering the mechanisms of knowledge interaction remains challenging in pre-trained language models, applying graceful forgetting can contribute to enhanced fine-tuning performance.', 'abstract_zh': '学习与遗忘：生成语言模型中的优雅遗忘', 'title_zh': '生成语言模型中的优雅遗忘'}
{'arxiv_id': 'arXiv:2505.19714', 'title': 'MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning', 'authors': 'Zhaopeng Feng, Yupu Liang, Shaosheng Cao, Jiayuan Su, Jiahan Ren, Zhe Xu, Yao Hu, Wenxuan Huang, Jian Wu, Zuozhu Liu', 'link': 'https://arxiv.org/abs/2505.19714', 'abstract': "Text Image Machine Translation (TIMT)-the task of translating textual content embedded in images-is critical for applications in accessibility, cross-lingual information access, and real-world document understanding. However, TIMT remains a complex challenge due to the need for accurate optical character recognition (OCR), robust visual-text reasoning, and high-quality translation, often requiring cascading multi-stage pipelines. Recent advances in large-scale Reinforcement Learning (RL) have improved reasoning in Large Language Models (LLMs) and Multimodal LLMs (MLLMs), but their application to end-to-end TIMT is still underexplored. To bridge this gap, we introduce MT$^{3}$, the first framework to apply Multi-Task RL to MLLMs for end-to-end TIMT. MT$^{3}$ adopts a multi-task optimization paradigm targeting three key sub-skills: text recognition, context-aware reasoning, and translation. It is trained using a novel multi-mixed reward mechanism that adapts rule-based RL strategies to TIMT's intricacies, offering fine-grained, non-binary feedback across tasks. Furthermore, to facilitate the evaluation of TIMT in authentic cross-cultural and real-world social media contexts, we introduced XHSPost, the first social media TIMT benchmark. Our MT$^{3}$-7B-Zero achieves state-of-the-art results on the latest in-domain MIT-10M benchmark, outperforming strong baselines such as Qwen2.5-VL-72B and InternVL2.5-78B by notable margins across multiple metrics. Additionally, the model shows strong generalization to out-of-distribution language pairs and datasets. In-depth analyses reveal how multi-task synergy, reinforcement learning initialization, curriculum design, and reward formulation contribute to advancing MLLM-driven TIMT.", 'abstract_zh': 'Text Image Machine Translation (TIMT)基于图像嵌入文本内容的机器翻译对于无障碍应用、跨语言信息访问和现实世界文档理解至关重要。然而，TIMT 由于需要准确的光学字符识别 (OCR)、稳健的视觉-文本推理和高质量的翻译，仍然是一项复杂的挑战，通常需要多阶段管道。最近大规模强化学习 (RL) 的进展改善了大型语言模型 (LLMs) 和多模态 LLMs (MLLMs) 的推理能力，但将其应用于端到端的 TIMT 仍然未被充分探索。为了弥合这一差距，我们提出了 MT$^{3}$，这是首个将多任务 RL 应用于 MLLMs 以实现端到端 TIMT 的框架。MT$^{3}$ 采用多任务优化范式，针对三个关键子技能进行优化：文本识别、上下文感知推理和翻译。它使用一种新颖的多混合奖励机制进行训练，这种机制将基于规则的 RL 策略适应 TIMT 的复杂性，提供细粒度、非二元化的跨任务反馈。此外，为了在真实的跨文化和实际社交媒体背景下评估 TIMT，我们引入了 XHSPost，这是首个社交媒体 TIMT 的基准数据集。我们的 MT$^{3}$-7B-Zero 在最新的领域内 MIT-10M 基准测试中取得了最新成果，多种度量标准上显著优于 Qwen2.5-VL-72B 和 InternVL2.5-78B 等强基线。此外，该模型展现了对未见过的语言对和数据集的强大泛化能力。深入分析揭示了多任务协同、强化学习初始化、课程设计和奖励机制对推动 MLLM 驱动的 TIMT 的贡献。', 'title_zh': 'MT$^{3}$: 通过多任务强化学习扩展基于MLLM的图文机器翻译'}
{'arxiv_id': 'arXiv:2505.19706', 'title': 'Error Typing for Smarter Rewards: Improving Process Reward Models with Error-Aware Hierarchical Supervision', 'authors': 'Tej Deep Pala, Panshul Sharma, Amir Zadeh, Chuan Li, Soujanya Poria', 'link': 'https://arxiv.org/abs/2505.19706', 'abstract': 'Large Language Models (LLMs) are prone to hallucination, especially during multi-hop and reasoning-intensive tasks such as mathematical problem solving. While Outcome Reward Models verify only final answers, Process Reward Models (PRMs) score each intermediate step to steer generation toward coherent solutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware discriminative PRM that first classifies math and consistency errors at each step, then combines these fine-grained signals to estimate step correctness. To train PathFinder-PRM, we construct a 400K-sample dataset by enriching the human-annotated PRM800K corpus and RLHFlow Mistral traces with three-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new state-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while using 3 times less data. When applied to reward guided greedy search, our model yields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results demonstrate that decoupled error detection and reward estimation not only boost fine-grained error detection but also substantially improve end-to-end, reward-guided mathematical reasoning with greater data efficiency.', 'abstract_zh': '大型语言模型（LLMs）在解决数学问题等多步和推理密集型任务时易产生幻觉。虽然结果奖励模型仅验证最终答案，过程奖励模型（PRM）则对每一步进行评分以引导生成连贯的解决方案。我们引入了PathFinder-PRM，这是一种新颖的分层、错误感知的区分性PRM，首先在每一步上分类数学和一致性错误，然后结合这些细粒度信号来估计步骤的正确性。为训练PathFinder-PRM，我们通过丰富PRM800K人工标注语料和RLHFlow Mistral跟踪数据集，构建了一个包含40万个样本的数据集，带有三维步级标签。在PRMBench上，PathFinder-PRM达到了新的最佳PRMScore 67.7，数据量减少三分之二仍超越了此前的最佳成绩（65.5）。当应用于奖励引导贪婪搜索时，我们的模型在prm@8上取得了48.3的成绩，比最强基线高出1.5分。这些结果证明了分离开错误检测和奖励估计不仅提升了细粒度错误检测的能力，还大幅提升了端到端、奖励引导的数学推理能力，同时具有更高的数据效率。', 'title_zh': '错误归因以获取更智能的奖励：基于错误感知层次监督的过程奖励模型改进'}
{'arxiv_id': 'arXiv:2505.19700', 'title': 'Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models', 'authors': 'Yi Liu, Dianqing Liu, Mingye Zhu, Junbo Guo, Yongdong Zhang, Zhendong Mao', 'link': 'https://arxiv.org/abs/2505.19700', 'abstract': 'The widespread adoption of large language models (LLMs) across industries has increased the demand for high-quality and customizable outputs. However, traditional alignment methods often require retraining large pretrained models, making it difficult to quickly adapt and optimize LLMs for diverse applications. To address this limitation, we propose a novel \\textit{Residual Alignment Model} (\\textit{RAM}) that formalizes the alignment process as a type of importance sampling. In this framework, the unaligned upstream model serves as the proposal distribution, while the alignment process is framed as secondary sampling based on an autoregressive alignment module that acts as an estimator of the importance weights. This design enables a natural detachment of the alignment module from the target aligned model, improving flexibility and scalability. Based on this model, we derive an efficient sequence-level training strategy for the alignment module, which operates independently of the proposal module. Additionally, we develop a resampling algorithm with iterative token-level decoding to address the common first-token latency issue in comparable methods. Experimental evaluations on two leading open-source LLMs across diverse tasks, including instruction following, domain adaptation, and preference optimization, demonstrate that our approach consistently outperforms baseline models.', 'abstract_zh': '广泛采用的大语言模型（LLMs）在各行业中的应用增加了高质量和可定制输出的需求。然而，传统的对齐方法 Often 需要重新训练大规模预训练模型，使得快速适应和优化LLMs以满足多元应用的需求变得困难。为解决这一限制，我们提出了一种新颖的“残差对齐模型”（RAM），将其对齐过程形式化为重要性采样的类型。在此框架中，未对齐的上游模型作为提议分布，而对齐过程被重新构架为基于自回归对齐模块的二次采样，该模块作为重要性权重的估计器。该设计使对齐模块与目标对齐模型实现了自然分离，提高了灵活性和可扩展性。基于此模型，我们为对齐模块推导出一种高效的序列级训练策略，该策略与提议模块独立运行。此外，我们开发了一种迭代令牌级解码的重采样算法，以解决同类方法中常见的首令牌延迟问题。针对两个领先开源LLM在包括指令跟随、领域适应和偏好优化等多样任务上的实验评估表明，我们的方法在所有任务上均优于基线模型。', 'title_zh': '利用重要性抽样分离对齐模块与大型语言模型'}
{'arxiv_id': 'arXiv:2505.19699', 'title': 'Mosaic: Data-Free Knowledge Distillation via Mixture-of-Experts for Heterogeneous Distributed Environments', 'authors': 'Junming Liu, Yanting Gao, Siyuan Meng, Yifei Sun, Aoqi Wu, Yufei Jin, Yirong Chen, Ding Wang, Guosun Zeng', 'link': 'https://arxiv.org/abs/2505.19699', 'abstract': "Federated Learning (FL) is a decentralized machine learning paradigm that enables clients to collaboratively train models while preserving data privacy. However, the coexistence of model and data heterogeneity gives rise to inconsistent representations and divergent optimization dynamics across clients, ultimately hindering robust global performance. To transcend these challenges, we propose Mosaic, a novel data-free knowledge distillation framework tailored for heterogeneous distributed environments. Mosaic first trains local generative models to approximate each client's personalized distribution, enabling synthetic data generation that safeguards privacy through strict separation from real data. Subsequently, Mosaic forms a Mixture-of-Experts (MoE) from client models based on their specialized knowledge, and distills it into a global model using the generated data. To further enhance the MoE architecture, Mosaic integrates expert predictions via a lightweight meta model trained on a few representative prototypes. Extensive experiments on standard image classification benchmarks demonstrate that Mosaic consistently outperforms state-of-the-art approaches under both model and data heterogeneity. The source code has been published at this https URL.", 'abstract_zh': '联邦学习（FL）是一种分布式机器学习范式，允许客户端协同训练模型同时保护数据隐私。然而，模型和数据的异质性导致了客户端之间不一致的表示和优化动态，最终妨碍了稳健的全局性能。为克服这些挑战，我们提出Mosaic，这是一种针对异质分布式环境的数据免费知识蒸馏框架。Mosaic首先训练本地生成模型以近似每个客户端的个性化分布，从而通过严格与真实数据分离生成合成数据，以保障隐私。随后，Mosaic基于客户端模型的专业知识构建了一个专家系统的混合体（MoE），并使用生成的数据将其蒸馏到全局模型中。为了进一步增强MoE架构，Mosaic通过一个基于少量代表性原型训练的轻量级元模型集成专家预测。在标准图像分类基准上的广泛实验表明，Mosaic在模型和数据异质性条件下均能一致性地超越现有顶级方法。源代码已发布于该网址。', 'title_zh': 'mosaic: 面向异构分布式环境的混合专家无数据知识蒸馏'}
{'arxiv_id': 'arXiv:2505.19698', 'title': 'JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning', 'authors': 'Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu', 'link': 'https://arxiv.org/abs/2505.19698', 'abstract': 'Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.', 'abstract_zh': '近期基于模型的强化学习（MBRL）在Atari100k基准上的表现达到了超人类水平，这主要得益于在强大扩散世界模型上训练的强化学习代理。然而，我们发现当前的聚合数据掩盖了一个重要的性能不对称性：在某些任务中，MBRL代理表现出色远远超过人类，而在其他任务中则表现糟糕，这种不对称性使得聚合指标被夸大。尤其是在使用扩散世界模型训练的像素基代理上，这一点尤为明显。在本文中，我们尝试通过划分所有任务为代理优化或人类优化，并提倡对两个集合的指标给予同等重要性，来解决像素基代理中存在的显著不对称性，以扭转这些代理中令人担忧的上升趋势。我们通过指出缺乏使用世界模型目标训练的具有时间结构的潜在空间来阐述这一显著不对称性的原因。最后，为了解决这一问题，我们提出了一种名为Joint Embedding DIffusion（JEDI）的新型潜在扩散世界模型，该模型端到端地使用自一致性的目标进行训练。JEDI在人类优化任务上的表现优于当前最佳模型，同时在Atari100k基准上保持竞争力，并且运行速度是最新像素基扩散基线的三倍快，内存消耗减少43%。总体而言，我们的工作重新定义了在Atari100k上达到人类水平性能的真正含义。', 'title_zh': 'JEDI: 潜在的端到端扩散机制缓解基于模型 reinforcement learning 中的Agent-_human 性能差异'}
{'arxiv_id': 'arXiv:2505.19693', 'title': 'EmoSphere-SER: Enhancing Speech Emotion Recognition Through Spherical Representation with Auxiliary Classification', 'authors': 'Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2505.19693', 'abstract': "Speech emotion recognition predicts a speaker's emotional state from speech signals using discrete labels or continuous dimensions such as arousal, valence, and dominance (VAD). We propose EmoSphere-SER, a joint model that integrates spherical VAD region classification to guide VAD regression for improved emotion prediction. In our framework, VAD values are transformed into spherical coordinates that are divided into multiple spherical regions, and an auxiliary classification task predicts which spherical region each point belongs to, guiding the regression process. Additionally, we incorporate a dynamic weighting scheme and a style pooling layer with multi-head self-attention to capture spectral and temporal dynamics, further boosting performance. This combined training strategy reinforces structured learning and improves prediction consistency. Experimental results show that our approach exceeds baseline methods, confirming the validity of the proposed framework.", 'abstract_zh': '基于球形VAD区域分类的联合模型：EmoSphere-SER及其在语音情感识别中的应用', 'title_zh': 'EmoSphere-SER：通过辅助分类改进的球形表示情感识别'}
{'arxiv_id': 'arXiv:2505.19687', 'title': 'DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech', 'authors': 'Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2505.19687', 'abstract': 'Cross-speaker emotion transfer in speech synthesis relies on extracting speaker-independent emotion embeddings for accurate emotion modeling without retaining speaker traits. However, existing timbre compression methods fail to fully separate speaker and emotion characteristics, causing speaker leakage and degraded synthesis quality. To address this, we propose DiEmo-TTS, a self-supervised distillation method to minimize emotional information loss and preserve speaker identity. We introduce cluster-driven sampling and information perturbation to preserve emotion while removing irrelevant factors. To facilitate this process, we propose an emotion clustering and matching approach using emotional attribute prediction and speaker embeddings, enabling generalization to unlabeled data. Additionally, we designed a dual conditioning transformer to integrate style features better. Experimental results confirm the effectiveness of our method in learning speaker-irrelevant emotion embeddings.', 'abstract_zh': '跨说话人口头情感转移在语音合成中的实现依赖于提取无说话人差异的情感嵌入以准确建模情感而不保留说话人特征。然而，现有的音色压缩方法未能完全分离说话人和情感特征，导致说话人痕迹泄露和合成质量下降。为解决这一问题，我们提出了一种自监督蒸馏方法DiEmo-TTS，以最小化情感信息丢失并保留说话人身份。我们引入了基于聚类的采样和信息扰动以保留情感并去除无关因素。为了促进这一过程，我们提出了一种使用情感属性预测和说话人嵌入的口头情感聚类和匹配方法，使模型能够泛化到未标记数据。此外，我们设计了一种双条件变压器以更好地整合风格特征。实验结果证实了我们方法在学习无说话人差异的情感嵌入方面的有效性。', 'title_zh': 'DiEmo-TTS：通过自我监督精炼实现跨演讲者情绪转移的解耦情绪表示'}
{'arxiv_id': 'arXiv:2505.19679', 'title': "KIT's Low-resource Speech Translation Systems for IWSLT2025: System Enhancement with Synthetic Data and Model Regularization", 'authors': 'Zhaolin Li, Yining Liu, Danni Liu, Tuan Nam Nguyen, Enes Yavuz Ugan, Tu Anh Dinh, Carlos Mullov, Alexander Waibel, Jan Niehues', 'link': 'https://arxiv.org/abs/2505.19679', 'abstract': "This paper presents KIT's submissions to the IWSLT 2025 low-resource track. We develop both cascaded systems, consisting of Automatic Speech Recognition (ASR) and Machine Translation (MT) models, and end-to-end (E2E) Speech Translation (ST) systems for three language pairs: Bemba, North Levantine Arabic, and Tunisian Arabic into English. Building upon pre-trained models, we fine-tune our systems with different strategies to utilize resources efficiently. This study further explores system enhancement with synthetic data and model regularization. Specifically, we investigate MT-augmented ST by generating translations from ASR data using MT models. For North Levantine, which lacks parallel ST training data, a system trained solely on synthetic data slightly surpasses the cascaded system trained on real data. We also explore augmentation using text-to-speech models by generating synthetic speech from MT data, demonstrating the benefits of synthetic data in improving both ASR and ST performance for Bemba. Additionally, we apply intra-distillation to enhance model performance. Our experiments show that this approach consistently improves results across ASR, MT, and ST tasks, as well as across different pre-trained models. Finally, we apply Minimum Bayes Risk decoding to combine the cascaded and end-to-end systems, achieving an improvement of approximately 1.5 BLEU points.", 'abstract_zh': 'KIT提交给IWSLT 2025低资源赛道的论文：三种语言对的级联系统和端到端语音翻译系统', 'title_zh': 'KIT的低资源语音翻译系统for IWSLT2025：基于合成数据和模型正则化的系统增强'}
{'arxiv_id': 'arXiv:2505.19675', 'title': 'Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement', 'authors': 'Liqin Ye, Agam Shah, Chao Zhang, Sudheer Chava', 'link': 'https://arxiv.org/abs/2505.19675', 'abstract': "The traditional process of creating labeled datasets is labor-intensive and expensive. Recent breakthroughs in open-source large language models (LLMs) have opened up a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks, providing an alternative to such an expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from noisy labels, the model's generalization is likely to be harmed as it is prone to overfit to those label noises. While previous studies in learning from noisy labels mainly focus on synthetic noise and real-world noise, LLM-generated label noise receives less attention. In this paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to calibrate the classifier's prediction, thus enhancing its robustness towards LLM-generated noisy labels. SiDyP retrieves potential true label candidates by neighborhood label distribution in text embedding space and iteratively refines noisy candidates using a simplex diffusion model. Our framework can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30% respectively. We demonstrate the effectiveness of SiDyP by conducting extensive benchmarking for different LLMs over a variety of NLP tasks. Our code is available on Github.", 'abstract_zh': '传统的标注数据集创建过程耗时且昂贵。开源大型语言模型（LLMs）的最新突破为自动生成适用于各种自然语言处理（NLP）任务的标注数据集开辟了新途径，提供了比昂贵标注过程的替代方案。然而，自动生成的标签可靠性仍是一个重大问题，因为存在固有的不准确性。在嘈杂标签上学习时，模型的泛化能力可能受损，因为它容易过度拟合那些标签噪声。虽然先前的嘈杂标签学习研究主要集中在合成噪声和真实世界噪声上，但LLM生成的标签噪声却较少受到关注。在本文中，我们提出SiDyP：简单标签扩散与动态先验方法，以校准分类器的预测，从而增强其对LLM生成的嘈杂标签的鲁棒性。SiDyP 通过文本嵌入空间中的邻域标签分布检索潜在的真实标签候选，并使用简单扩散模型迭代细化嘈杂候选。我们的框架可以分别在零样本和少量样本LLM生成的嘈杂标签数据集上微调的BERT分类器性能提高7.21%和7.30%。通过在多种NLP任务上对不同LLM进行广泛的基准测试，我们展示了SiDyP的有效性。我们的代码可在Github上获取。', 'title_zh': '通过迭代 refinement 校准预训练语言分类器在大语言模型生成的噪声标签上的表现'}
{'arxiv_id': 'arXiv:2505.19671', 'title': "Automated evaluation of children's speech fluency for low-resource languages", 'authors': 'Bowen Zhang, Nur Afiqah Abdul Latiff, Justin Kan, Rong Tong, Donny Soh, Xiaoxiao Miao, Ian McLoughlin', 'link': 'https://arxiv.org/abs/2505.19671', 'abstract': "Assessment of children's speaking fluency in education is well researched for majority languages, but remains highly challenging for low resource languages. This paper proposes a system to automatically assess fluency by combining a fine-tuned multilingual ASR model, an objective metrics extraction stage, and a generative pre-trained transformer (GPT) network. The objective metrics include phonetic and word error rates, speech rate, and speech-pause duration ratio. These are interpreted by a GPT-based classifier guided by a small set of human-evaluated ground truth examples, to score fluency. We evaluate the proposed system on a dataset of children's speech in two low-resource languages, Tamil and Malay and compare the classification performance against Random Forest and XGBoost, as well as using ChatGPT-4o to predict fluency directly from speech input. Results demonstrate that the proposed approach achieves significantly higher accuracy than multimodal GPT or other methods.", 'abstract_zh': '低资源语言儿童口语流畅性自动评估系统的提出', 'title_zh': '低资源语言儿童言语流畅性自动评估'}
{'arxiv_id': 'arXiv:2505.19667', 'title': 'LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation', 'authors': 'Weikang Yuan, Kaisong Song, Zhuoren Jiang, Junjie Cao, Yujie Zhang, Jun Lin, Kun Kuang, Ji Zhang, Xiaozhong Liu', 'link': 'https://arxiv.org/abs/2505.19667', 'abstract': "Legal consultation is essential for safeguarding individual rights and ensuring access to justice, yet remains costly and inaccessible to many individuals due to the shortage of professionals. While recent advances in Large Language Models (LLMs) offer a promising path toward scalable, low-cost legal assistance, current systems fall short in handling the interactive and knowledge-intensive nature of real-world consultations. To address these challenges, we introduce LeCoDe, a real-world multi-turn benchmark dataset comprising 3,696 legal consultation dialogues with 110,008 dialogue turns, designed to evaluate and improve LLMs' legal consultation capability. With LeCoDe, we innovatively collect live-streamed consultations from short-video platforms, providing authentic multi-turn legal consultation dialogues. The rigorous annotation by legal experts further enhances the dataset with professional insights and expertise. Furthermore, we propose a comprehensive evaluation framework that assesses LLMs' consultation capabilities in terms of (1) clarification capability and (2) professional advice quality. This unified framework incorporates 12 metrics across two dimensions. Through extensive experiments on various general and domain-specific LLMs, our results reveal significant challenges in this task, with even state-of-the-art models like GPT-4 achieving only 39.8% recall for clarification and 59% overall score for advice quality, highlighting the complexity of professional consultation scenarios. Based on these findings, we further explore several strategies to enhance LLMs' legal consultation abilities. Our benchmark contributes to advancing research in legal domain dialogue systems, particularly in simulating more real-world user-expert interactions.", 'abstract_zh': '法治咨询对于保障个人权利和确保司法公正至关重要，但由于专业人员的短缺，这一服务对许多个体来说既昂贵又难以获得。虽然近期大型语言模型（LLMs）的发展为面向大众、低成本的法律援助提供了希望，但现有系统在处理实际咨询中的互动性和知识密集型特性方面仍存在不足。为应对这些挑战，我们引入了LeCoDe，一个包含3,696个法律咨询对话和110,008个对话轮次的现实世界多轮次基准数据集，旨在评估和提升大型语言模型的法律咨询能力。通过LeCoDe，我们创新性地从短视频平台收集了实时法律咨询服务，提供了真实的多轮法律咨询对话。法务专家的严格注解进一步提升了数据集的专业见解和专业知识。此外，我们提出了一套全面的评估框架，从澄清能力和专业建议质量两个维度评估大型语言模型的咨询能力。该统一框架涵盖了12个指标。通过在各种通用和特定领域的大型语言模型上的广泛实验，我们的结果显示了这一任务的巨大挑战，即使是像GPT-4这样最先进的模型也只能实现39.8%的澄清召回率和59%的整体建议质量评分，突显了专业咨询场景的复杂性。基于这些发现，我们进一步探索了增强大型语言模型法律咨询服务能力的策略。我们的基准有助于推进法律领域对话系统的研究，特别是模拟更多真实的用户-专家互动。', 'title_zh': 'LeCoDe：用于互动法律咨询对话评估的标准数据集'}
{'arxiv_id': 'arXiv:2505.19663', 'title': 'A Comprehensive Real-World Assessment of Audio Watermarking Algorithms: Will They Survive Neural Codecs?', 'authors': 'Yigitcan Özer, Woosung Choi, Joan Serrà, Mayank Kumar Singh, Wei-Hsiang Liao, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2505.19663', 'abstract': 'We present a framework to foster the evaluation of deep learning-based audio watermarking algorithms, establishing a standardized benchmark and allowing systematic comparisons. To simulate real-world usage, we introduce a comprehensive audio attack pipeline, featuring various distortions such as compression, background noise, and reverberation, and propose a diverse test dataset, including speech, environmental sounds, and music recordings. By assessing the performance of four existing watermarking algorithms on our framework, two main insights stand out: (i) neural compression techniques pose the most significant challenge, even when algorithms are trained with such compressions; and (ii) training with audio attacks generally improves robustness, although it is insufficient in some cases. Furthermore, we find that specific distortions, such as polarity inversion, time stretching, or reverb, seriously affect certain algorithms. Our contributions strengthen the robustness and perceptual assessment of audio watermarking algorithms across a wide range of applications, while ensuring a fair and consistent evaluation approach. The evaluation framework, including the attack pipeline, is accessible at this http URL.', 'abstract_zh': '我们提出了一种框架，以促进基于深度学习的音频水印算法的评估，建立了标准化基准并允许系统性的比较。为了模拟实际使用情况，我们引入了一个全面的音频攻击管道，其中包括压缩、背景噪声和混响等多种失真，并提出了一个多样化的测试数据集，其中包括语音、环境声和音乐录音。通过对我们的框架评估四个现有水印算法的表现，我们得到了两项主要见解：(i) 神经压缩技术即使在算法被训练使用这些压缩时也构成了最大的挑战；(ii) 使用音频攻击进行训练一般可以提高鲁棒性，但有些情况下并不足够。此外，我们发现特定的失真，如极性反转、时间拉伸或混响，会对某些算法产生严重影响。我们的贡献在广泛的应用中增强了音频水印算法的鲁棒性和感知评估，同时确保了一种公平和一致的评估方法。评估框架，包括攻击管道，可通过以下网址访问。', 'title_zh': '全面的实际世界评估：音频水印算法能生存下来对抗神经编解码器吗？'}
{'arxiv_id': 'arXiv:2505.19660', 'title': 'GenKI: Enhancing Open-Domain Question Answering with Knowledge Integration and Controllable Generation in Large Language Models', 'authors': 'Tingjia Shen, Hao Wang, Chuan Qin, Ruijun Sun, Yang Song, Defu Lian, Hengshu Zhu, Enhong Chen', 'link': 'https://arxiv.org/abs/2505.19660', 'abstract': "Open-domain question answering (OpenQA) represents a cornerstone in natural language processing (NLP), primarily focused on extracting answers from unstructured textual data. With the rapid advancements in Large Language Models (LLMs), LLM-based OpenQA methods have reaped the benefits of emergent understanding and answering capabilities enabled by massive parameters compared to traditional methods. However, most of these methods encounter two critical challenges: how to integrate knowledge into LLMs effectively and how to adaptively generate results with specific answer formats for various task situations. To address these challenges, we propose a novel framework named GenKI, which aims to improve the OpenQA performance by exploring Knowledge Integration and controllable Generation on LLMs simultaneously. Specifically, we first train a dense passage retrieval model to retrieve associated knowledge from a given knowledge base. Subsequently, we introduce a novel knowledge integration model that incorporates the retrieval knowledge into instructions during fine-tuning to intensify the model. Furthermore, to enable controllable generation in LLMs, we leverage a certain fine-tuned LLM and an ensemble based on text consistency incorporating all coherence, fluency, and answer format assurance. Finally, extensive experiments conducted on the TriviaQA, MSMARCO, and CMRC2018 datasets, featuring diverse answer formats, have demonstrated the effectiveness of GenKI with comparison of state-of-the-art baselines. Moreover, ablation studies have disclosed a linear relationship between the frequency of retrieved knowledge and the model's ability to recall knowledge accurately against the ground truth. Our code of GenKI is available at this https URL", 'abstract_zh': '开放域问答（OpenQA）在自然语言处理（NLP）中占有重要地位，主要关注从非结构化文本数据中提取答案。随着大型语言模型（LLMs）的快速发展，基于LLM的OpenQA方法受益于大规模参数带来的新兴理解和回答能力，相较于传统方法。然而，这些方法大多面临着两个关键挑战：如何有效整合知识到LLM中，以及如何在各种任务情境下自适应地生成具有特定答案格式的结果。为应对这些挑战，我们提出了一种名为GenKI的新型框架，旨在通过同时探索LLM上的知识整合和可控生成来提高OpenQA性能。具体而言，我们首先训练一个密集段落检索模型，从给定的知识库中检索相关知识。随后，我们引入了一个新颖的知识整合模型，在微调过程中将检索知识集成到指令中，以增强模型。此外，为使LLM实现可控生成，我们利用了一种特定微调的LLM，并结合了流畅性、连贯性和答案格式保证的集成方法。最后，在涵盖多种答案格式的TriviaQA、MSMARCO和CMRC2018数据集上的广泛实验表明，GenKI的有效性优于最新的基线方法。此外，消融研究揭示了检索知识频率与模型准确回忆知识能力之间呈线性关系。GenKI的代码可在以下链接获取。', 'title_zh': 'GenKI: 在大型语言模型中通过知识整合与可控生成提升开放域问答能力'}
{'arxiv_id': 'arXiv:2505.19658', 'title': 'Large Language Models in Code Co-generation for Safe Autonomous Vehicles', 'authors': 'Ali Nouri, Beatriz Cabrero-Daniel, Zhennan Fei, Krishna Ronanki, Håkan Sivencrona, Christian Berger', 'link': 'https://arxiv.org/abs/2505.19658', 'abstract': "Software engineers in various industrial domains are already using Large Language Models (LLMs) to accelerate the process of implementing parts of software systems. When considering its potential use for ADAS or AD systems in the automotive context, there is a need to systematically assess this new setup: LLMs entail a well-documented set of risks for safety-related systems' development due to their stochastic nature. To reduce the effort for code reviewers to evaluate LLM-generated code, we propose an evaluation pipeline to conduct sanity-checks on the generated code. We compare the performance of six state-of-the-art LLMs (CodeLlama, CodeGemma, DeepSeek-r1, DeepSeek-Coders, Mistral, and GPT-4) on four safety-related programming tasks. Additionally, we qualitatively analyse the most frequent faults generated by these LLMs, creating a failure-mode catalogue to support human reviewers. Finally, the limitations and capabilities of LLMs in code generation, and the use of the proposed pipeline in the existing process, are discussed.", 'abstract_zh': '在各种工业领域中，软件工程师已经开始使用大型语言模型（LLMs）来加速软件系统部分实现过程。在汽车情境中考虑其用于高级驾驶辅助系统（ADAS）或自动驾驶系统（AD）的潜在用途时，有必要系统性地评估这一新架构：由于其随机性，LLMs 对安全相关系统开发存在已文档化的风险。为了减轻代码审查人员评估LLM生成代码的工作量，我们提出了一种评估流水线来进行生成代码的常规检查。我们将六种最先进的LLM（CodeLlama、CodeGemma、DeepSeek-r1、DeepSeek-Coders、Mistral 和 GPT-4）在四种安全相关编程任务上的性能进行比较。此外，我们对这些LLM生成的最常见的错误进行了定性分析，创建了一个故障模式catalogue以支持人工审查员。最后，讨论了LLMs在代码生成中的局限性和能力，以及所提议的流水线在现有流程中的应用。', 'title_zh': '大型语言模型在代码共动生成中的安全自主车辆应用'}
{'arxiv_id': 'arXiv:2505.19648', 'title': 'Model Enumeration of Two-Variable Logic with Quadratic Delay Complexity', 'authors': 'Qiaolan Meng, Juhua Pu, Hongting Niu, Yuyi Wang, Yuanhong Wang, Ondřej Kuželka', 'link': 'https://arxiv.org/abs/2505.19648', 'abstract': 'We study the model enumeration problem of the function-free, finite domain fragment of first-order logic with two variables ($FO^2$). Specifically, given an $FO^2$ sentence $\\Gamma$ and a positive integer $n$, how can one enumerate all the models of $\\Gamma$ over a domain of size $n$? In this paper, we devise a novel algorithm to address this problem. The delay complexity, the time required between producing two consecutive models, of our algorithm is quadratic in the given domain size $n$ (up to logarithmic factors) when the sentence is fixed. This complexity is almost optimal since the interpretation of binary predicates in any model requires at least $\\Omega(n^2)$ bits to represent.', 'abstract_zh': '我们研究函数自由、有限域的一阶逻辑双变量片段（$FO^2$）的模型枚举问题。具体来说，给定一个$FO^2$句子$\\Gamma$和一个正整数$n$，如何在大小为$n$的领域中枚举$\\Gamma$的所有模型？在本文中，我们设计了一种新的算法来解决这个问题。当句子固定时，我们的算法在产生两个连续模型之间的时间延迟复杂度为给定领域大小$n$的平方（直到对数因子为止）。这一复杂度几乎是最佳的，因为任何模型中二元谓词的解释至少需要$\\Omega(n^2)$位来表示。', 'title_zh': '带有二次延迟复杂性的二变量逻辑模型枚举'}
{'arxiv_id': 'arXiv:2505.19645', 'title': "MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE", 'authors': 'Zongle Huang, Lei Zhu, Zongyuan Zhan, Ting Hu, Weikai Mao, Xianzhi Yu, Yongpan Liu, Tianyu Zhang', 'link': 'https://arxiv.org/abs/2505.19645', 'abstract': "Large Language Models (LLMs) have achieved remarkable success across many applications, with Mixture of Experts (MoE) models demonstrating great potential. Compared to traditional dense models, MoEs achieve better performance with less computation. Speculative decoding (SD) is a widely used technique to accelerate LLM inference without accuracy loss, but it has been considered efficient only for dense models. In this work, we first demonstrate that, under medium batch sizes, MoE surprisingly benefits more from SD than dense models. Furthermore, as MoE becomes sparser -- the prevailing trend in MoE designs -- the batch size range where SD acceleration is expected to be effective becomes broader. To quantitatively understand tradeoffs involved in SD, we develop a reliable modeling based on theoretical analyses. While current SD research primarily focuses on improving acceptance rates of algorithms, changes in workload and model architecture can still lead to degraded SD acceleration even with high acceptance rates. To address this limitation, we introduce a new metric 'target efficiency' that characterizes these effects, thus helping researchers identify system bottlenecks and understand SD acceleration more comprehensively. For scenarios like private serving, this work unveils a new perspective to speed up MoE inference, where existing solutions struggle. Experiments on different GPUs show up to 2.29x speedup for Qwen2-57B-A14B at medium batch sizes and validate our theoretical predictions.", 'abstract_zh': '大规模语言模型（LLMs）已在众多应用中取得了显著成功，专家混合模型（MoE）展示了巨大的潜力。与传统的密集模型相比，MoE能够在减少计算量的同时实现更好的性能。推测解码（SD）是一项广泛使用的技术，用于在不损失准确性的前提下加速LLM推理，但长期以来被认为主要适用于密集模型。在本工作中，我们首先证明，在中等批量大小下，MoE意外地比密集模型更受益于SD。此外，随着MoE变得越来越稀疏——这是MoE设计的一个主要趋势——预期SD加速效果的批量大小范围变得更宽广。为了定量理解SD涉及的权衡，我们基于理论分析建立了可靠的模型。尽管当前的SD研究主要集中在提高算法的接受率上，但工作负载和模型架构的变化仍可能导致即使在高接受率下SD加速也会降级。为应对这一局限性，我们引入了一个新的指标“目标效率”来表征这些效果，有助于研究者识别系统瓶颈，并更全面地理解SD加速。对于如私有服务等场景，这项工作揭示了一个新的视角，以加快MoE推理，而现有解决方案在此方面面临挑战。在不同GPU上的实验显示，对于中等批量大小的Qwen2-57B-A14B，在线速比可达2.29倍，并验证了我们的理论预测。', 'title_zh': 'MoESD: 探析 speculative decoding 在加速稀疏 MoE 方面的潜力'}
{'arxiv_id': 'arXiv:2505.19644', 'title': 'STOPA: A Database of Systematic VariaTion Of DeePfake Audio for Open-Set Source Tracing and Attribution', 'authors': 'Anton Firc, Manasi Chibber, Jagabandhu Mishra, Vishwanath Pratap Singh, Tomi Kinnunen, Kamil Malinka', 'link': 'https://arxiv.org/abs/2505.19644', 'abstract': 'A key research area in deepfake speech detection is source tracing - determining the origin of synthesised utterances. The approaches may involve identifying the acoustic model (AM), vocoder model (VM), or other generation-specific parameters. However, progress is limited by the lack of a dedicated, systematically curated dataset. To address this, we introduce STOPA, a systematically varied and metadata-rich dataset for deepfake speech source tracing, covering 8 AMs, 6 VMs, and diverse parameter settings across 700k samples from 13 distinct synthesisers. Unlike existing datasets, which often feature limited variation or sparse metadata, STOPA provides a systematically controlled framework covering a broader range of generative factors, such as the choice of the vocoder model, acoustic model, or pretrained weights, ensuring higher attribution reliability. This control improves attribution accuracy, aiding forensic analysis, deepfake detection, and generative model transparency.', 'abstract_zh': '一种深度伪造语音检测的关键研究领域是源追溯——确定合成语音的来源。该方法可能涉及识别声学模型（AM）、 vocoder模型（VM）或其他生成特定参数。然而，由于缺乏专门的系统化数据集，进展受限。为此，我们介绍了STOPA，一个系统化变异和元数据丰富的数据集，用于深度伪造语音源追溯，覆盖8种声学模型、6种vocoder模型和从13种不同合成器中提取的70万样本中多种参数设置。与现有的数据集相比，STOPA提供了更广泛生成因素的系统化控制框架，确保更高的归属可靠性。这一控制改进了归属准确性，有助于法医分析、深度伪造检测和生成模型透明度。', 'title_zh': 'STOPA：一种用于开放集声源追踪和归属的系统变异性深度伪造音频数据库'}
{'arxiv_id': 'arXiv:2505.19631', 'title': 'Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models', 'authors': 'Zihong Zhang, Liqi He, Zuchao Li, Lefei Zhang, Hai Zhao, Bo Du', 'link': 'https://arxiv.org/abs/2505.19631', 'abstract': 'Word segmentation stands as a cornerstone of Natural Language Processing (NLP). Based on the concept of "comprehend first, segment later", we propose a new framework to explore the limit of unsupervised word segmentation with Large Language Models (LLMs) and evaluate the semantic understanding capabilities of LLMs based on word segmentation. We employ current mainstream LLMs to perform word segmentation across multiple languages to assess LLMs\' "comprehension". Our findings reveal that LLMs are capable of following simple prompts to segment raw text into words. There is a trend suggesting that models with more parameters tend to perform better on multiple languages. Additionally, we introduce a novel unsupervised method, termed LLACA ($\\textbf{L}$arge $\\textbf{L}$anguage Model-Inspired $\\textbf{A}$ho-$\\textbf{C}$orasick $\\textbf{A}$utomaton). Leveraging the advanced pattern recognition capabilities of Aho-Corasick automata, LLACA innovatively combines these with the deep insights of well-pretrained LLMs. This approach not only enables the construction of a dynamic $n$-gram model that adjusts based on contextual information but also integrates the nuanced understanding of LLMs, offering significant improvements over traditional methods. Our source code is available at this https URL', 'abstract_zh': '基于“先理解后切词”的理念，大规模语言模型在无监督词切分中的极限探究及语义理解能力评估：一种大型语言模型启发的Aho-Corasick自动机方法（LLACA）', 'title_zh': '先分词还是先理解？探索大规模语言模型在无监督词分词中的极限'}
{'arxiv_id': 'arXiv:2505.19625', 'title': 'Search-Based Software Engineering in the Landscape of AI Foundation Models', 'authors': 'Hassan Sartaj, Shaukat Ali', 'link': 'https://arxiv.org/abs/2505.19625', 'abstract': 'Search-based software engineering (SBSE), at the intersection of artificial intelligence (AI) and software engineering, has been an active area of research for about 25 years. It has been applied to solve numerous problems across the entire software engineering lifecycle and has demonstrated its versatility in multiple domains. With the recent advancements in AI, particularly the emergence of foundation models (FMs), the evolution of SBSE alongside FMs remains undetermined. In this window of opportunity, we propose a research roadmap that articulates the current landscape of SBSE in relation to foundation models (FMs), highlights open challenges, and outlines potential research directions for advancing SBSE through its interplay with FMs. This roadmap aims to establish a forward-thinking and innovative perspective for the future of SBSE in the era of FMs.', 'abstract_zh': '基于搜索的软件工程（SBSE）：面向基础模型（FMs）时代的研究路线图', 'title_zh': '基于搜索的软件工程在AI基础模型的视角下'}
{'arxiv_id': 'arXiv:2505.19624', 'title': 'Benchmarking Large Multimodal Models for Ophthalmic Visual Question Answering with OphthalWeChat', 'authors': 'Pusheng Xu, Xia Gong, Xiaolan Chen, Weiyi Zhang, Jiancheng Yang, Bingjie Yan, Meng Yuan, Yalin Zheng, Mingguang He, Danli Shi', 'link': 'https://arxiv.org/abs/2505.19624', 'abstract': 'Purpose: To develop a bilingual multimodal visual question answering (VQA) benchmark for evaluating VLMs in ophthalmology. Methods: Ophthalmic image posts and associated captions published between January 1, 2016, and December 31, 2024, were collected from WeChat Official Accounts. Based on these captions, bilingual question-answer (QA) pairs in Chinese and English were generated using GPT-4o-mini. QA pairs were categorized into six subsets by question type and language: binary (Binary_CN, Binary_EN), single-choice (Single-choice_CN, Single-choice_EN), and open-ended (Open-ended_CN, Open-ended_EN). The benchmark was used to evaluate the performance of three VLMs: GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B-Instruct. Results: The final OphthalWeChat dataset included 3,469 images and 30,120 QA pairs across 9 ophthalmic subspecialties, 548 conditions, 29 imaging modalities, and 68 modality combinations. Gemini 2.0 Flash achieved the highest overall accuracy (0.548), outperforming GPT-4o (0.522, P < 0.001) and Qwen2.5-VL-72B-Instruct (0.514, P < 0.001). It also led in both Chinese (0.546) and English subsets (0.550). Subset-specific performance showed Gemini 2.0 Flash excelled in Binary_CN (0.687), Single-choice_CN (0.666), and Single-choice_EN (0.646), while GPT-4o ranked highest in Binary_EN (0.717), Open-ended_CN (BLEU-1: 0.301; BERTScore: 0.382), and Open-ended_EN (BLEU-1: 0.183; BERTScore: 0.240). Conclusions: This study presents the first bilingual VQA benchmark for ophthalmology, distinguished by its real-world context and inclusion of multiple examinations per patient. The dataset reflects authentic clinical decision-making scenarios and enables quantitative evaluation of VLMs, supporting the development of accurate, specialized, and trustworthy AI systems for eye care.', 'abstract_zh': '目的：开发一种双语多模态视觉问答（VQA）基准，用于评估眼科视觉语言模型（VLMs）的表现。方法：从2016年1月1日至2024年12月31日，收集来自微信公众号的眼科影像帖子及其相关说明。基于这些说明，使用GPT-4o-mini生成了中英文双语问答（QA）对。根据问题类型和语言，QA对被分为六个子集：二分类（Binary_CN, Binary_EN）、单选（Single-choice_CN, Single-choice_EN）和开放式（Open-ended_CN, Open-ended_EN）。该基准用于评估三种VLMs：GPT-4o、Gemini 2.0 Flash和Qwen2.5-VL-72B-Instruct的表现。结果：最终的OphthalWeChat数据集包括3,469张图像和30,120个问答对，覆盖9个眼科亚专科、548种疾病、29种影像模态和68种模态组合。Gemini 2.0 Flash取得了最高的总体准确率（0.548），优于GPT-4o（0.522，P < 0.001）和Qwen2.5-VL-72B-Instruct（0.514，P < 0.001）。它还在中英文子集方面表现最佳（0.546和0.550）。特定子集的表现显示，Gemini 2.0 Flash在二分类中英文子集（0.687、0.666和0.646）中表现出色，而GPT-4o在单选英文子集（0.717）、开放式中英文子集（BLEU-1：0.301；BERTScore：0.382和0.183；BERTScore：0.240）中排名最高。结论：本研究介绍了首个眼科双语VQA基准，具有实际临床背景和每位患者多个检查项的特点。数据集反映了真实的临床决策场景，并允许对VLMs进行定量评估，支持开发准确、专业化和可信赖的眼科护理AI系统。', 'title_zh': '基于OphthalWeChat大型多模态模型的眼科视觉问答基准研究'}
{'arxiv_id': 'arXiv:2505.19623', 'title': 'AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems', 'authors': 'Yu Shang, Peijie Liu, Yuwei Yan, Zijing Wu, Leheng Sheng, Yuanqing Yu, Chumeng Jiang, An Zhang, Fengli Xu, Yu Wang, Min Zhang, Yong Li', 'link': 'https://arxiv.org/abs/2505.19623', 'abstract': "The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMs' advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\\footnote[2]{this https URL}, fostering ongoing community engagement and reproducible research. The benchmark is available at: \\hyperlink{this https URL}{this https URL}.", 'abstract_zh': '由大规模语言模型（LLMs）驱动的代理推荐系统的发展代表了个性化推荐的一个范式转变，利用LLMs的高级推理和角色扮演能力，实现自主、适应性的决策。与传统的推荐方法不同，代理推荐系统可以从复杂环境中动态收集和解释用户-项目交互，生成适用于各种场景的 robust 推荐策略。然而，当前该领域缺乏标准化的评估协议，以系统地评估这些方法。为填补这一关键空白，我们提出：(1) 一个包含丰富的用户和项目元数据的交互式文本推荐模拟器，以及三种典型评估场景（经典、兴趣演变和冷启动推荐任务）；(2) 一个统一的模块化框架，用于开发和研究代理推荐系统；以及(3) 第一个全面基准，比较了10种经典和代理推荐方法。我们的研究结果展示了代理系统的优越性，并为其核心组件确立了可操作的设计指南。基准环境通过一个公开挑战进行了严格的验证，并保持公开和持续维护的排名榜（<https://this https URL>），以促进持续的社区参与和可再现研究。基准可从以下网址获得：<https://this https URL>。', 'title_zh': 'AgentRecBench：基于LLM代理的个性化推荐系统 benchmarks'}
{'arxiv_id': 'arXiv:2505.19620', 'title': 'Decoupling Spatio-Temporal Prediction: When Lightweight Large Models Meet Adaptive Hypergraphs', 'authors': 'Jiawen Chen, Qi Shao, Duxin Chen, Wenwu Yu', 'link': 'https://arxiv.org/abs/2505.19620', 'abstract': 'Spatio-temporal prediction is a pivotal task with broad applications in traffic management, climate monitoring, energy scheduling, etc. However, existing methodologies often struggle to balance model expressiveness and computational efficiency, especially when scaling to large real-world datasets. To tackle these challenges, we propose STH-SepNet (Spatio-Temporal Hypergraph Separation Networks), a novel framework that decouples temporal and spatial modeling to enhance both efficiency and precision. Therein, the temporal dimension is modeled using lightweight large language models, which effectively capture low-rank temporal dynamics. Concurrently, the spatial dimension is addressed through an adaptive hypergraph neural network, which dynamically constructs hyperedges to model intricate, higher-order interactions. A carefully designed gating mechanism is integrated to seamlessly fuse temporal and spatial representations. By leveraging the fundamental principles of low-rank temporal dynamics and spatial interactions, STH-SepNet offers a pragmatic and scalable solution for spatio-temporal prediction in real-world applications. Extensive experiments on large-scale real-world datasets across multiple benchmarks demonstrate the effectiveness of STH-SepNet in boosting predictive performance while maintaining computational efficiency. This work may provide a promising lightweight framework for spatio-temporal prediction, aiming to reduce computational demands and while enhancing predictive performance. Our code is avaliable at this https URL.', 'abstract_zh': '时空预测是交通管理、气候监测、能源调度等领域广泛应用的核心任务。然而，现有方法往往难以在模型表达能力和计算效率之间取得平衡，特别是在处理大规模现实世界数据集时。为应对这些挑战，我们提出了一种新颖的框架STH-SepNet（时空超图分离网络），该框架解耦了时空模型，以提高效率和精度。其中，时间维度通过轻量级大语言模型进行建模，有效捕捉低秩时间动态。同时，空间维度通过自适应超图神经网络进行处理，动态构建超边以模拟复杂的高阶交互。精心设计的门控机制被集成以无缝融合时空表示。通过利用低秩时间动态和空间交互的基本原理，STH-SepNet 提供了一种实用且可扩展的时空预测解决方案，适用于多种现实世界应用。在多个基准上的大规模现实世界数据集上的广泛实验表明，STH-SepNet 在提高预测性能的同时保持了计算效率。本项工作可能提供一种具有前景的轻量级框架，旨在减少计算需求并提升预测性能。我们的代码可在以下链接获取：this https URL。', 'title_zh': '时空预测解耦：当轻量级大型模型遇到自适应超图'}
{'arxiv_id': 'arXiv:2505.19616', 'title': 'Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models', 'authors': 'Rui Cai, Bangzheng Li, Xiaofei Wen, Muhao Chen, Zhe Zhao', 'link': 'https://arxiv.org/abs/2505.19616', 'abstract': "Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across tasks, yet they often exhibit difficulty in distinguishing task-relevant from irrelevant signals, particularly in tasks like Visual Question Answering (VQA), which can lead to susceptibility to misleading or spurious inputs. We refer to this broader limitation as the Cross-Modality Competency Problem: the model's inability to fairly evaluate all modalities. This vulnerability becomes more evident in modality-specific tasks such as image classification or pure text question answering, where models are expected to rely solely on one modality. In such tasks, spurious information from irrelevant modalities often leads to significant performance degradation. We refer to this failure as Modality Interference, which serves as a concrete and measurable instance of the cross-modality competency problem. We further design a perturbation-based causal diagnostic experiment to verify and quantify this problem. To mitigate modality interference, we propose a novel framework to fine-tune MLLMs, including perturbation-based data augmentations with both heuristic perturbations and adversarial perturbations via Projected Gradient Descent (PGD), and a consistency regularization strategy applied to model outputs with original and perturbed inputs. Experiments on multiple benchmark datasets (image-heavy, text-heavy, and VQA tasks) and multiple model families with different scales demonstrate significant improvements in robustness and cross-modality competency, indicating our method's effectiveness in boosting unimodal reasoning ability while enhancing performance on multimodal tasks.", 'abstract_zh': '多模态大型语言模型跨模态能力问题：建模模态间干扰的扰动因果诊断与缓解', 'title_zh': '诊断和缓解多模态大型语言模型中的模态干扰'}
{'arxiv_id': 'arXiv:2505.19611', 'title': 'Align and Surpass Human Camouflaged Perception: Visual Refocus Reinforcement Fine-Tuning', 'authors': 'Ruolin Shen, Xiaozhong Ji, Kai WU, Jiangning Zhang, Yijun He, HaiHua Yang, Xiaobin Hu, Xiaoyu Sun', 'link': 'https://arxiv.org/abs/2505.19611', 'abstract': "Current multi-modal models exhibit a notable misalignment with the human visual system when identifying objects that are visually assimilated into the background. Our observations reveal that these multi-modal models cannot distinguish concealed objects, demonstrating an inability to emulate human cognitive processes which effectively utilize foreground-background similarity principles for visual analysis. To analyze this hidden human-model visual thinking discrepancy, we build a visual system that mimicks human visual camouflaged perception to progressively and iteratively `refocus' visual concealed content. The refocus is a progressive guidance mechanism enabling models to logically localize objects in visual images through stepwise reasoning. The localization process of concealed objects requires hierarchical attention shifting with dynamic adjustment and refinement of prior cognitive knowledge. In this paper, we propose a visual refocus reinforcement framework via the policy optimization algorithm to encourage multi-modal models to think and refocus more before answering, and achieve excellent reasoning abilities to align and even surpass human camouflaged perception systems. Our extensive experiments on camouflaged perception successfully demonstrate the emergence of refocus visual phenomena, characterized by multiple reasoning tokens and dynamic adjustment of the detection box. Besides, experimental results on both camouflaged object classification and detection tasks exhibit significantly superior performance compared to Supervised Fine-Tuning (SFT) baselines.", 'abstract_zh': '当前多模态模型在识别与背景视觉融合的物体时与人类视觉系统存在显著不一致。我们的观察表明，这些多模态模型无法区分隐藏物体，显示出无法模拟人类利用前景与背景相似性原则进行视觉分析的认知过程。为了分析这种隐藏的人工智能模型视觉思维差异，我们构建了一个视觉系统，模仿人类对伪装视觉感知的处理方式，逐步迭代地“重新聚焦”视觉隐藏内容。重新聚焦是一个逐步的指导机制，使模型能够通过逐步推理逻辑地定位视觉图像中的物体。隐藏物体的定位过程需要分层注意力转换，并且需要根据先验认知知识进行动态调整和优化。在本文中，我们提出了一种通过策略优化算法构建的视觉重新聚焦增强框架，以促进多模态模型在回答问题之前进行更多的思考和重新聚焦，从而获得出色的推理能力，甚至超越人类伪装感知系统。我们在伪装感知方面的广泛实验成功地展示了重新聚焦视觉现象的出现，其特征是由多个推理标记和检测框的动态调整组成。此外，伪装物体分类和检测任务上的实验结果与监督微调（SFT）基线相比显示出显著优越的性能。', 'title_zh': '超越人类伪装感知的对焦增强微调'}
{'arxiv_id': 'arXiv:2505.19609', 'title': 'Skrull: Towards Efficient Long Context Fine-tuning through Dynamic Data Scheduling', 'authors': 'Hongtao Xu, Wenting Shen, Yuanxin Wei, Ang Wang, Guo Runfan, Tianxing Wang, Yong Li, Mingzhen Li, Weile Jia', 'link': 'https://arxiv.org/abs/2505.19609', 'abstract': 'Long-context supervised fine-tuning (Long-SFT) plays a vital role in enhancing the performance of large language models (LLMs) on long-context tasks. To smoothly adapt LLMs to long-context scenarios, this process typically entails training on mixed datasets containing both long and short sequences. However, this heterogeneous sequence length distribution poses significant challenges for existing training systems, as they fail to simultaneously achieve high training efficiency for both long and short sequences, resulting in sub-optimal end-to-end system performance in Long-SFT. In this paper, we present a novel perspective on data scheduling to address the challenges posed by the heterogeneous data distributions in Long-SFT. We propose Skrull, a dynamic data scheduler specifically designed for efficient long-SFT. Through dynamic data scheduling, Skrull balances the computation requirements of long and short sequences, improving overall training efficiency. Furthermore, we formulate the scheduling process as a joint optimization problem and thoroughly analyze the trade-offs involved. Based on those analysis, Skrull employs a lightweight scheduling algorithm to achieve near-zero cost online scheduling in Long-SFT. Finally, we implement Skrull upon DeepSpeed, a state-of-the-art distributed training system for LLMs. Experimental results demonstrate that Skrull outperforms DeepSpeed by 3.76x on average (up to 7.54x) in real-world long-SFT scenarios.', 'abstract_zh': '长上下文监督微调（Long-SFT）在提升大型语言模型（LLMs）在长上下文任务上的表现中起着至关重要的作用。为平滑地使LLMs适应长上下文场景，这一过程通常涉及使用包含长序列和短序列的混合数据集进行训练。然而，这种异质的序列长度分布对现有的训练系统提出了重大挑战，因为它们不能同时高效地处理长和短序列，导致Long-SFT中的端到端系统性能不佳。在本文中，我们提出了一种新的数据调度视角，以应对Long-SFT中异质数据分布带来的挑战。我们提出了Skrull，一种专门针对高效长上下文微调设计的动态数据调度器。通过动态数据调度，Skrull平衡了长和短序列的计算需求，提高了整体训练效率。此外，我们将调度过程建模为联合优化问题，并深入分析了其中的权衡。基于这些分析，Skrull采用了一种轻量级的调度算法，在Long-SFT中实现了接近零成本的在线调度。最后，我们在DeepSpeed之上实现了Skrull，DeepSpeed是当前最先进的分布式训练系统之一。实验结果表明，在实际的长上下文微调场景中，Skrull在平均性能上优于DeepSpeed 3.76倍（最高可达7.54倍）。', 'title_zh': 'Skrull：通过动态数据调度实现高效长上下文微调'}
{'arxiv_id': 'arXiv:2505.19607', 'title': 'Energy-based Preference Optimization for Test-time Adaptation', 'authors': 'Yewon Han, Seoyun Yang, Taesup Kim', 'link': 'https://arxiv.org/abs/2505.19607', 'abstract': 'Test-Time Adaptation (TTA) enhances model robustness by enabling adaptation to target distributions that differ from training distributions, improving real-world generalizability. Existing TTA approaches focus on adjusting the conditional distribution; however these methods often depend on uncertain predictions in the absence of label information, leading to unreliable performance. Energy-based frameworks suggest a promising alternative to address distribution shifts without relying on uncertain predictions, instead computing the marginal distribution of target data. However, they involve the critical challenge of requiring extensive SGLD sampling, which is impractical for test-time scenarios requiring immediate adaptation. In this work, we propose Energy-based Preference Optimization for Test-time Adaptation (EPOTTA), which is based on a sampling free strategy. We first parameterize the target model using a pretrained model and residual energy function, enabling marginal likelihood maximization of target data without sampling. Building on the observation that the parameterization is mathematically equivalent to DPO objective, we then directly adapt the model to a target distribution without explicitly training the residual. Our experiments verify that EPOTTA is well-calibrated and performant while achieving computational efficiency.', 'abstract_zh': '基于能量的测试时偏好优化方法（EPOTTA）', 'title_zh': '基于能量的偏好优化以实现测试时适应'}
{'arxiv_id': 'arXiv:2505.19601', 'title': 'Preference Optimization by Estimating the Ratio of the Data Distribution', 'authors': 'Yeongmin Kim, Heesun Bae, Byeonghu Na, Il-Chul Moon', 'link': 'https://arxiv.org/abs/2505.19601', 'abstract': "Direct preference optimization (DPO) is widely used as a simple and stable method for aligning large language models (LLMs) with human preferences. This paper investigates a generalized DPO loss that enables a policy model to match the target policy from a likelihood ratio estimation perspective. The ratio of the target policy provides a unique identification of the policy distribution without relying on reward models or partition functions. This allows the generalized loss to retain both simplicity and theoretical guarantees, which prior work such as $f$-PO fails to achieve simultaneously. We propose Bregman preference optimization (BPO), a generalized framework for ratio matching that provides a family of objective functions achieving target policy optimality. BPO subsumes DPO as a special case and offers tractable forms for all instances, allowing implementation with a few lines of code. We further develop scaled Basu's power divergence (SBA), a gradient scaling method that can be used for BPO instances. The BPO framework complements other DPO variants and is applicable to target policies defined by these variants. In experiments, unlike other probabilistic loss extensions such as $f$-DPO or $f$-PO, which exhibit a trade-off between generation fidelity and diversity, instances of BPO improve both win rate and entropy compared with DPO. When applied to Llama-3-Instruct-8B, BPO achieves state-of-the-art performance among Llama-3-8B backbones, with a 55.9\\% length-controlled win rate on AlpacaEval2.", 'abstract_zh': '直接偏好优化（DPO）广泛用于将大规模语言模型（LLMs）与人类偏好对齐的一种简单且稳定的方法。本文探讨了一种广义的DPO损失，从似然比估计的角度使得策略模型能够匹配目标策略。目标策略的比值为策略分布提供了一种独特的标识，无需依赖奖励模型或分区函数。这使得广义损失能够同时保持简单性和理论保证，而之前的如$f$-PO等工作未能同时实现。我们提出了一种广义的偏好优化框架——Bregman偏好优化（BPO），提供了一组目标函数实现目标策略最优性。BPO包含了DPO作为特例，并为所有实例提供了可处理的形式，允许用几行代码实现。我们进一步开发了一种缩放的Basu’s幂分离散化（SBA）梯度缩放方法，可以用于BPO实例。BPO框架补充了其他DPO变体，并适用于由这些变体定义的目标策略。在实验中，与其他概率损失扩展如$f$-DPO或$f$-PO相比，BPO实例在提高胜率和熵方面优于DPO。当应用于Llama-3-Instruct-8B时，BPO在AlpacaEval2上实现了Llama-3-8B骨干中的最佳性能，赢得率（控制长度后的）达到55.9%。', 'title_zh': '数据分布比率估计下的偏好优化'}
{'arxiv_id': 'arXiv:2505.19599', 'title': 'Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar', 'authors': 'Andrew Gambardella, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo', 'link': 'https://arxiv.org/abs/2505.19599', 'abstract': 'Typical methods for evaluating the performance of language models evaluate their ability to answer questions accurately. These evaluation metrics are acceptable for determining the extent to which language models can understand and reason about text in a general sense, but fail to capture nuanced capabilities, such as the ability of language models to recognize and obey rare grammar points, particularly in languages other than English. We measure the perplexity of language models when confronted with the "first person psych predicate restriction" grammar point in Japanese. Weblab is the only tested open source model in the 7-10B parameter range which consistently assigns higher perplexity to ungrammatical psych predicate sentences than grammatical ones. We give evidence that Weblab\'s uniformly bad tokenization is a possible root cause for its good performance, and show that Llama 3\'s perplexity on grammatical psych predicate sentences can be reduced by orders of magnitude (28x difference) by restricting test sentences to those with uniformly well-behaved tokenizations. We show in further experiments on machine translation tasks that language models will use alternative grammar patterns in order to produce grammatical sentences when tokenization issues prevent the most natural sentence from being output.', 'abstract_zh': 'typical 方法语言模型性能评估通常侧重于其准确回答问题的能力。这些评价指标在整体上衡量语言模型理解与推理文本的能力方面是可接受的，但无法捕捉到细微的能力，如语言模型识别和遵循罕见语法点的能力，尤其是在非英语语言中。我们衡量了语言模型在遇到日语“第一人称心理谓词限制”语法点时的困惑度。Weblab 是唯一在 7-10B 参数范围内经过测试的开源模型，它能一致地对不规范的心理谓词句子赋予更高的困惑度，而对规范的句子赋予较低的困惑度。我们提供了证据表明 Weblab 均匀恶化的分词可能是其良好表现的原因之一，并展示了通过限制测试句子的分词行为来显著降低 Llama 3 在规范的心理谓词句子上的困惑度（困惑度差异达 28 倍）。在进一步的机器翻译任务实验中，我们展示了语言模型将在分词问题阻止最自然句子生成时使用替代的语法模式以生成规范的句子。', 'title_zh': '不一致的分词导致语言模型对日语语法困惑'}
{'arxiv_id': 'arXiv:2505.19591', 'title': 'Multi-Agent Collaboration via Evolving Orchestration', 'authors': 'Yufan Dang, Chen Qian, Xueheng Luo, Jingru Fan, Zihao Xie, Ruijie Shi, Weize Chen, Cheng Yang, Xiaoyin Che, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2505.19591', 'abstract': 'Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator ("puppeteer") dynamically directs agents ("puppets") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator\'s evolution.', 'abstract_zh': '基于大型语言模型的木偶师式多agent协作框架：实现灵活演化推理以提升复杂问题解决效率', 'title_zh': '多智能体演化协调下的协作'}
{'arxiv_id': 'arXiv:2505.19588', 'title': 'LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval', 'authors': 'Yanzhen Shen, Sihao Chen, Xueqiang Xu, Yunyi Zhang, Chaitanya Malaviya, Dan Roth', 'link': 'https://arxiv.org/abs/2505.19588', 'abstract': 'While significant progress has been made with dual- and bi-encoder dense retrievers, they often struggle on queries with logical connectives, a use case that is often overlooked yet important in downstream applications. Current dense retrievers struggle with such queries, such that the retrieved results do not respect the logical constraints implied in the queries. To address this challenge, we introduce LogiCoL, a logically-informed contrastive learning objective for dense retrievers. LogiCoL builds upon in-batch supervised contrastive learning, and learns dense retrievers to respect the subset and mutually-exclusive set relation between query results via two sets of soft constraints expressed via t-norm in the learning objective. We evaluate the effectiveness of LogiCoL on the task of entity retrieval, where the model is expected to retrieve a set of entities in Wikipedia that satisfy the implicit logical constraints in the query. We show that models trained with LogiCoL yield improvement both in terms of retrieval performance and logical consistency in the results. We provide detailed analysis and insights to uncover why queries with logical connectives are challenging for dense retrievers and why LogiCoL is most effective.', 'abstract_zh': '尽管双编码器和双语文本检索器取得了显著进展，但在处理包含逻辑连接词的查询时，它们常常表现不佳，这是一个在下游应用中经常被忽视但重要的使用场景。当前的密集检索器在处理这类查询时存在问题，导致检索结果不尊重查询中隐含的逻辑约束。为应对这一挑战，我们提出LogiCoL，这是一种逻辑信息驱动的对比学习目标，以解决密集检索器的检索问题。LogiCoL 基于内部批监督对比学习，并通过学习目标中的 t-规范表达的两组软约束，使密集检索器遵守查询结果的子集和互斥集关系。我们评估了 LogiCoL 在实体检索任务中的有效性，其中模型需要检索满足查询中隐含逻辑约束的维基百科实体集合。我们展示了使用 LogiCoL 训练的模型在检索性能和结果逻辑一致性方面的改进，并提供了详细分析和见解，以揭示包含逻辑连接词的查询对密集检索器构成的挑战以及为什么 LogiCoL 最为有效。', 'title_zh': 'LogiCoL：逻辑信息引导的对比学习在集合密集检索中的应用'}
{'arxiv_id': 'arXiv:2505.19578', 'title': 'Accelerating Prefilling for Long-Context LLMs via Sparse Pattern Sharing', 'authors': 'Dan Peng, Zhihui Fu, Zewen Ye, Zhuoran Song, Jun Wang', 'link': 'https://arxiv.org/abs/2505.19578', 'abstract': 'Sparse attention methods exploit the inherent sparsity in attention to speed up the prefilling phase of long-context inference, mitigating the quadratic complexity of full attention computation. While existing sparse attention methods rely on predefined patterns or inaccurate estimations to approximate attention behavior, they often fail to fully capture the true dynamics of attention, resulting in reduced efficiency and compromised accuracy. Instead, we propose a highly accurate sparse attention mechanism that shares similar yet precise attention patterns across heads, enabling a more realistic capture of the dynamic behavior of attention. Our approach is grounded in two key observations: (1) attention patterns demonstrate strong inter-head similarity, and (2) this similarity remains remarkably consistent across diverse inputs. By strategically sharing computed accurate patterns across attention heads, our method effectively captures actual patterns while requiring full attention computation for only a small subset of heads. Comprehensive evaluations demonstrate that our approach achieves superior or comparable speedup relative to state-of-the-art methods while delivering the best overall accuracy.', 'abstract_zh': '稀疏注意机制通过利用注意力的固有稀疏性来加速长上下文推理的预填充阶段，缓解全注意力计算的二次复杂度。现有稀疏注意机制依赖于预定义模式或不准确的估计来近似注意力行为，往往无法完全捕捉注意力的真实动态，导致效率降低和准确性受损。相反，我们提出了一种高度准确的稀疏注意机制，其在各个注意头之间共享相似但准确的注意模式，能够更真实地捕捉注意力动态行为。我们的方法基于两个关键观察：（1）注意模式显示了强烈的眼间相似性，（2）这种相似性在不同输入中保持高度一致。通过在注意头之间战略性地共享计算准确的模式，我们的方法有效地捕捉了实际模式，同时仅对一小部分头进行全注意力计算。全面的评估表明，与现有最佳方法相比，我们的方法在提供最佳总体准确性的同时实现了更优或相当的加速效果。', 'title_zh': '通过稀疏模式共享加速长上下文LLM的预填充'}
{'arxiv_id': 'arXiv:2505.19574', 'title': 'Situationally-Aware Dynamics Learning', 'authors': 'Alejandro Murillo-Gonzalez, Lantao Liu', 'link': 'https://arxiv.org/abs/2505.19574', 'abstract': "Autonomous robots operating in complex, unstructured environments face significant challenges due to latent, unobserved factors that obscure their understanding of both their internal state and the external world. Addressing this challenge would enable robots to develop a more profound grasp of their operational context. To tackle this, we propose a novel framework for online learning of hidden state representations, with which the robots can adapt in real-time to uncertain and dynamic conditions that would otherwise be ambiguous and result in suboptimal or erroneous behaviors. Our approach is formalized as a Generalized Hidden Parameter Markov Decision Process, which explicitly models the influence of unobserved parameters on both transition dynamics and reward structures. Our core innovation lies in learning online the joint distribution of state transitions, which serves as an expressive representation of latent ego- and environmental-factors. This probabilistic approach supports the identification and adaptation to different operational situations, improving robustness and safety. Through a multivariate extension of Bayesian Online Changepoint Detection, our method segments changes in the underlying data generating process governing the robot's dynamics. The robot's transition model is then informed with a symbolic representation of the current situation derived from the joint distribution of latest state transitions, enabling adaptive and context-aware decision-making. To showcase the real-world effectiveness, we validate our approach in the challenging task of unstructured terrain navigation, where unmodeled and unmeasured terrain characteristics can significantly impact the robot's motion. Extensive experiments in both simulation and real world reveal significant improvements in data efficiency, policy performance, and the emergence of safer, adaptive navigation strategies.", 'abstract_zh': '自主机器人在复杂、未结构化环境中的操作面临显著挑战，由于潜在、未观察到的因素模糊了其对其内部状态和外部世界的理解。解决这一挑战将使机器人能够更深刻地理解其操作环境。为此，我们提出了一种新颖的在线学习隐藏状态表示框架，使机器人能够实时适应原本模糊且动态的条件，从而避免次优或错误行为。我们的方法形式化为广义隐藏参数马尔可夫决策过程，明确建模未观察到参数对状态转移动力学和奖励结构的影响。我们核心的创新在于在线学习状态转移的联合分布，作为潜在自我和环境因素的表达表示。这种概率方法支持识别和适应不同操作场景，提高鲁棒性和安全性。通过多变量贝叶斯在线变化点检测的扩展，我们的方法将数据生成过程的变化划分为多个段。然后，机器人的转移模型借助最新状态转移联合分布的符号表示来更新，使机器人能够进行适应性和情境意识决策。为了展示其实用性，我们在机器人在复杂地形导航的具有挑战性的任务中验证了该方法，其中未建模和未测量的地形特性显著影响机器人运动。在模拟和现实世界的广泛实验中，显示出数据效率、策略性能的显著提升以及更安全、更具适应性的导航策略的出现。', 'title_zh': '情境感知动态学习'}
{'arxiv_id': 'arXiv:2505.19572', 'title': 'DocMEdit: Towards Document-Level Model Editing', 'authors': 'Li Zeng, Zeming Liu, Chong Feng, Heyan Huang, Yuhang Guo', 'link': 'https://arxiv.org/abs/2505.19572', 'abstract': 'Model editing aims to correct errors and outdated knowledge in the Large language models (LLMs) with minimal cost. Prior research has proposed a variety of datasets to assess the effectiveness of these model editing methods. However, most existing datasets only require models to output short phrases or sentences, overlooks the widespread existence of document-level tasks in the real world, raising doubts about their practical usability. Aimed at addressing this limitation and promoting the application of model editing in real-world scenarios, we propose the task of document-level model editing. To tackle such challenges and enhance model capabilities in practical settings, we introduce \\benchmarkname, a dataset focused on document-level model editing, characterized by document-level inputs and outputs, extrapolative, and multiple facts within a single edit. We propose a series of evaluation metrics and experiments. The results show that the difficulties in document-level model editing pose challenges for existing model editing methods.', 'abstract_zh': 'Model Editing at the Document Level Aims to Correct Errors and Outdated Knowledge in Large Language Models with Minimal Cost', 'title_zh': 'DocMEdit: 向量级模型编辑'}
{'arxiv_id': 'arXiv:2505.19548', 'title': 'How Syntax Specialization Emerges in Language Models', 'authors': 'Xufeng Duan, Zhaoqian Yao, Yunhao Zhang, Shaonan Wang, Zhenguang G. Cai', 'link': 'https://arxiv.org/abs/2505.19548', 'abstract': "Large language models (LLMs) have been found to develop surprising internal specializations: Individual neurons, attention heads, and circuits become selectively sensitive to syntactic structure, reflecting patterns observed in the human brain. While this specialization is well-documented, how it emerges during training and what influences its development remains largely unknown.\nIn this work, we tap into the black box of specialization by tracking its formation over time. By quantifying internal syntactic consistency across minimal pairs from various syntactic phenomena, we identify a clear developmental trajectory: Syntactic sensitivity emerges gradually, concentrates in specific layers, and exhibits a 'critical period' of rapid internal specialization. This process is consistent across architectures and initialization parameters (e.g., random seeds), and is influenced by model scale and training data. We therefore reveal not only where syntax arises in LLMs but also how some models internalize it during training. To support future research, we will release the code, models, and training checkpoints upon acceptance.", 'abstract_zh': '大型语言模型（LLMs）被发现发展出令人惊讶的内部专业化：单个神经元、注意力头和电路变得对句法规则选择性敏感，反映出人类大脑中观察到的模式。尽管这种专业化已被广泛记录，但其在训练过程中是如何形成的以及哪些因素影响其发展仍然知之甚少。\n\n在本工作中，我们通过跟踪专业化形成的全过程，开启了这一黑箱。通过量化各种句法现象的最小对之间内部句法一致性，我们识别出一个清晰的发展轨迹：句法敏感性逐渐出现，集中在特定层中，并表现出“关键期”快速内部专业化。这一过程在不同架构和初始化参数（如随机种子）下是一致的，并受模型规模和训练数据的影响。因此，我们不仅揭示了语法在LLMs中的起源，还揭示了某些模型在训练过程中如何内化它。为了支持未来的研究，在接受后，我们将发布代码、模型和训练检查点。', 'title_zh': '语法专门化如何在语言模型中 emergence'}
{'arxiv_id': 'arXiv:2505.19547', 'title': 'STRAP: Spatio-Temporal Pattern Retrieval for Out-of-Distribution Generalization', 'authors': 'Haoyu Zhang, Wentao Zhang, Hao Miao, Xinke Jiang, Yuchen Fang, Yifan Zhang', 'link': 'https://arxiv.org/abs/2505.19547', 'abstract': 'Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerful tool for modeling dynamic graph-structured data across diverse domains. However, they often fail to generalize in Spatio-Temporal Out-of-Distribution (STOOD) scenarios, where both temporal dynamics and spatial structures evolve beyond the training distribution. To address this problem, we propose an innovative Spatio-Temporal Retrieval-Augmented Pattern Learning framework,STRAP, which enhances model generalization by integrating retrieval-augmented learning into the STGNN continue learning pipeline. The core of STRAP is a compact and expressive pattern library that stores representative spatio-temporal patterns enriched with historical, structural, and semantic information, which is obtained and optimized during the training phase. During inference, STRAP retrieves relevant patterns from this library based on similarity to the current input and injects them into the model via a plug-and-play prompting mechanism. This not only strengthens spatio-temporal representations but also mitigates catastrophic forgetting. Moreover, STRAP introduces a knowledge-balancing objective to harmonize new information with retrieved knowledge. Extensive experiments across multiple real-world streaming graph datasets show that STRAP consistently outperforms state-of-the-art STGNN baselines on STOOD tasks, demonstrating its robustness, adaptability, and strong generalization capability without task-specific fine-tuning.', 'abstract_zh': '时空图神经网络（STGNNs）已成为建模跨多种领域动态图结构数据的强大工具。然而，它们往往在时空异分布（STOOD）场景下无法泛化，即时间动态和空间结构在训练分布之外发生变化。为解决这一问题，我们提出了一种创新的时空检索增强模式学习框架STRAP，通过将检索增强学习集成到STGNN继续学习管道中来增强模型泛化能力。STRAP的核心是一个紧凑且表达力强的模式库，该库存储了富含历史、结构和语义信息的代表性时空模式，并在训练阶段获取和优化。在推理阶段，STRAP根据当前输入与库中模式的相似性检索相关模式，并通过即插即用提示机制将它们注入模型中。这不仅强化了时空表示，还减轻了灾难性遗忘。此外，STRAP引入了一个知识平衡目标，以协调新信息与检索知识。在多个真实世界的流图数据集上的广泛实验表明，STRAP在STOOD任务上始终优于最先进的STGNN基线，证明了其鲁棒性、适应性和强大的泛化能力，无需针对特定任务进行细调。', 'title_zh': 'STRAP: 空间-时间模式检索以实现异常分布泛化'}
{'arxiv_id': 'arXiv:2505.19538', 'title': 'DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients', 'authors': 'Yuxing Lu, Gecheng Fu, Wei Wu, Xukai Zhao, Sin Yee Goi, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2505.19538', 'abstract': 'Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.', 'abstract_zh': '现有的医疗RAG系统主要借鉴医学知识库的知识，忽视了来自类似患者案例的经验知识——人类临床推理中的关键组成部分。为填补这一空白，我们提出DoctorRAG，这是一种通过整合显式临床知识和隐式案例为基础的经验，模拟医生推理过程的RAG框架。DoctorRAG通过为查询和知识源分配概念标签，并采用从相关知识和患者中结合检索的混合机制，提升检索精度。此外，我们集成了一个使用多代理文本梯度的Med-TextGrad模块，以确保最终输出符合检索到的知识和患者查询。在多语言、多任务数据集上的综合实验表明，DoctorRAG显著优于强大的基线RAG模型，并且从迭代优化中获得改进。我们的方法生成了更准确、相关且全面的响应，朝着更接近医生的医疗推理系统迈出了一步。', 'title_zh': 'DoctorRAG：融合知识与患者类比的医疗RAG模型通过文本梯度'}
{'arxiv_id': 'arXiv:2505.19536', 'title': 'FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models', 'authors': 'Jintao Tong, Wenwei Jin, Pengda Qin, Anqi Li, Yixiong Zou, Yuhong Li, Yuhua Li, Ruixuan Li', 'link': 'https://arxiv.org/abs/2505.19536', 'abstract': "Large vision-language models (LVLMs) excel at multimodal understanding but suffer from high computational costs due to redundant vision tokens. Existing pruning methods typically rely on single-layer attention scores to rank and prune redundant visual tokens to solve this inefficiency. However, as the interaction between tokens and layers is complicated, this raises a basic question: Is such a simple single-layer criterion sufficient to identify redundancy? To answer this question, we rethink the emergence of redundant visual tokens from a fundamental perspective: information flow, which models the interaction between tokens and layers by capturing how information moves between tokens across layers. We find (1) the CLS token acts as an information relay, which can simplify the complicated flow analysis; (2) the redundancy emerges progressively and dynamically via layer-wise attention concentration; and (3) relying solely on attention scores from single layers can lead to contradictory redundancy identification. Based on this, we propose FlowCut, an information-flow-aware pruning framework, mitigating the insufficiency of the current criterion for identifying redundant tokens and better aligning with the model's inherent behaviors. Extensive experiments show that FlowCut achieves superior results, outperforming SoTA by 1.6% on LLaVA-1.5-7B with 88.9% token reduction, and by 4.3% on LLaVA-NeXT-7B with 94.4% reduction, delivering 3.2x speed-up in the prefilling stage. Our code is available at this https URL", 'abstract_zh': '大型多模态语言模型在多模态理解方面表现出色，但由于冗余视觉标记导致的高计算成本而受到影响。现有的剪枝方法通常依赖单层attention分数来排名和剪枝冗余的视觉标记以解决这种低效性。然而，由于标记和层之间的交互复杂，这引发了一个基本问题：这样的单层标准是否足以识别冗余性？为回答这一问题，我们从基础的信息流视角重新思考冗余视觉标记的出现：信息流模型通过捕捉信息在不同层之间如何流动来建模标记与层之间的交互。我们发现（1）CLS标记充当信息中继的角色，可以简化复杂的信息流分析；（2）冗余性通过逐层注意力集中逐渐且动态地出现；（3）仅依赖单层的attention分数来进行冗余性识别可能会导致矛盾的结果。基于此，我们提出FlowCut，一种信息流感知的剪枝框架，缓解当前标准在识别冗余标记方面的不足，并更好地与模型固有的行为相契合。广泛的实验表明，FlowCut取得了优异的结果，在LLaVA-1.5-7B上优于现有最佳性能1.6%，同时标记减少88.9%；在LLaVA-NeXT-7B上优于现有最佳性能4.3%，标记减少94.4%，预填充阶段加速3.2倍。我们的代码可在以下链接获取。', 'title_zh': 'FlowCut：基于信息流重新思考冗余性以实现高效视觉语言模型'}
{'arxiv_id': 'arXiv:2505.19534', 'title': 'Training-Free Multi-Step Audio Source Separation', 'authors': 'Yongyi Zang, Jingyi Li, Qiuqiang Kong', 'link': 'https://arxiv.org/abs/2505.19534', 'abstract': 'Audio source separation aims to separate a mixture into target sources. Previous audio source separation systems usually conduct one-step inference, which does not fully explore the separation ability of models. In this work, we reveal that pretrained one-step audio source separation models can be leveraged for multi-step separation without additional training. We propose a simple yet effective inference method that iteratively applies separation by optimally blending the input mixture with the previous step\'s separation result. At each step, we determine the optimal blending ratio by maximizing a metric. We prove that our method always yield improvement over one-step inference, provide error bounds based on model smoothness and metric robustness, and provide theoretical analysis connecting our method to denoising along linear interpolation paths between noise and clean distributions, a property we link to denoising diffusion bridge models. Our approach effectively delivers improved separation performance as a "free lunch" from existing models. Our empirical results demonstrate that our multi-step separation approach consistently outperforms one-step inference across both speech enhancement and music source separation tasks, and can achieve scaling performance similar to training a larger model, using more data, or in some cases employing a multi-step training objective. These improvements appear not only on the optimization metric during multi-step inference, but also extend to nearly all non-optimized metrics (with one exception). We also discuss limitations of our approach and directions for future research.', 'abstract_zh': '基于多步推理的预训练音频源分离方法', 'title_zh': '无监督多步音频源分离'}
{'arxiv_id': 'arXiv:2505.19531', 'title': 'Minimalist Softmax Attention Provably Learns Constrained Boolean Functions', 'authors': 'Jerry Yao-Chieh Hu, Xiwen Zhang, Maojiang Su, Zhao Song, Han Liu', 'link': 'https://arxiv.org/abs/2505.19531', 'abstract': 'We study the computational limits of learning $k$-bit Boolean functions (specifically, $\\mathrm{AND}$, $\\mathrm{OR}$, and their noisy variants), using a minimalist single-head softmax-attention mechanism, where $k=\\Theta(d)$ relevant bits are selected from $d$ inputs. We show that these simple $\\mathrm{AND}$ and $\\mathrm{OR}$ functions are unsolvable with a single-head softmax-attention mechanism alone. However, with teacher forcing, the same minimalist attention is capable of solving them. These findings offer two key insights: Architecturally, solving these Boolean tasks requires only minimalist attention, without deep Transformer blocks or FFNs. Methodologically, one gradient descent update with supervision suffices and replaces the multi-step Chain-of-Thought (CoT) reasoning scheme of [Kim and Suzuki, ICLR 2025] for solving Boolean problems. Together, the bounds expose a fundamental gap between what this minimal architecture achieves under ideal supervision and what is provably impossible under standard training.', 'abstract_zh': '我们研究了使用 minimalist 单头 softmax-attention 机制学习 $k$-bit 逻辑函数（具体为 AND、OR 及其噪声变体）的计算极限，其中 $k=\\Theta(d)$ 相关位从 $d$ 个输入中选择。我们展示，仅使用单头 softmax-attention 机制无法解决这些简单的 AND 和 OR 函数。但在使用 teacher forcing 的情况下，相同的 minimalist 机制能够解决它们。这些发现提供了两个关键洞见：从架构角度看，解决这些布尔任务只需要 minimalist 机制，而无需深层的 Transformer 块或 FFN。从方法角度看，一次带有监督的梯度下降更新足以替代 [Kim 和 Suzuki, ICLR 2025] 中解决布尔问题的多步骤 Chain-of-Thought (CoT) 推理方案。总体而言，这些边界揭示了在理想监督下此最小化架构实现的能力与在标准训练下证明不可能实现的能力之间的根本差距。', 'title_zh': '最小主义softmax注意力高效学习受限布尔函数'}
{'arxiv_id': 'arXiv:2505.19528', 'title': 'AmpleHate: Amplifying the Attention for Versatile Implicit Hate Detection', 'authors': 'Yejin Lee, Joonghyuk Hahn, Hyeseon Ahn, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2505.19528', 'abstract': 'Implicit hate speech detection is challenging due to its subtlety and reliance on contextual interpretation rather than explicit offensive words. Current approaches rely on contrastive learning, which are shown to be effective on distinguishing hate and non-hate sentences. Humans, however, detect implicit hate speech by first identifying specific targets within the text and subsequently interpreting how these target relate to their surrounding context. Motivated by this reasoning process, we propose AmpleHate, a novel approach designed to mirror human inference for implicit hate detection. AmpleHate identifies explicit target using a pretrained Named Entity Recognition model and capture implicit target information via [CLS] tokens. It computes attention-based relationships between explicit, implicit targets and sentence context and then, directly injects these relational vectors into the final sentence representation. This amplifies the critical signals of target-context relations for determining implicit hate. Experiments demonstrate that AmpleHate achieves state-of-the-art performance, outperforming contrastive learning baselines by an average of 82.14% and achieve faster convergence. Qualitative analyses further reveal that attention patterns produced by AmpleHate closely align with human judgement, underscoring its interpretability and robustness.', 'abstract_zh': '隐含仇恨言论检测由于其微妙性以及依赖于上下文理解而非明确的冒犯词汇而具有挑战性。当前的方法依赖于对比学习，已被证明在区分仇恨言论和非仇恨言论方面是有效的。然而，人类通过首先识别文本中的具体目标，然后解释这些目标与其周围上下文的关系来检测隐含的仇恨言论。受此推理过程的启发，我们提出了一种名为AmpleHate的新型方法，旨在模拟人类对隐含仇恨的推理过程。AmpleHate使用预训练的命名实体识别模型识别显式目标，并通过[CLS]标记捕获隐含目标信息。它计算显式目标、隐含目标与句子上下文之间的注意关系，然后直接将这些关系向量注入最终的句子表示。这放大了目标-上下文关系的关键信号，以确定隐含仇恨。实验表明，AmpleHate取得了最先进的性能，平均优于对比学习基线82.14%，并实现更快的收敛。进一步的定性分析表明，AmpleHate生成的注意模式与人类判断高度一致，突显了其可解释性和鲁棒性。', 'title_zh': 'AmpleHate: 加强对多样化的隐含仇恨检测的关注'}
{'arxiv_id': 'arXiv:2505.19527', 'title': 'Navigating loss manifolds via rigid body dynamics: A promising avenue for robustness and generalisation', 'authors': 'Mohammed D. Belgoumri, Mohamed Reda Bouadjenek, Hakim Hacid, Imran Razzak, Sunil Aryal', 'link': 'https://arxiv.org/abs/2505.19527', 'abstract': 'Training large neural networks through gradient-based optimization requires navigating high-dimensional loss landscapes, which often exhibit pathological geometry, leading to undesirable training dynamics. In particular, poor generalization frequently results from convergence to sharp minima that are highly sensitive to input perturbations, causing the model to overfit the training data while failing to generalize to unseen examples. Furthermore, these optimization procedures typically display strong dependence on the fine structure of the loss landscape, leading to unstable training dynamics, due to the fractal-like nature of the loss surface. In this work, we propose an alternative optimizer that simultaneously reduces this dependence, and avoids sharp minima, thereby improving generalization. This is achieved by simulating the motion of the center of a ball rolling on the loss landscape. The degree to which our optimizer departs from the standard gradient descent is controlled by a hyperparameter, representing the radius of the ball. Changing this hyperparameter allows for probing the loss landscape at different scales, making it a valuable tool for understanding its geometry.', 'abstract_zh': '通过基于梯度的优化训练大型神经网络需要在高维损失景观中导航，这些景观常常表现出病态的几何结构，导致不理想的训练动态。特别是，模型通常由于收敛到对输入扰动高度敏感的尖锐极小值而表现泛化能力差，导致模型过拟合训练数据而无法泛化到未见样本。此外，这些优化过程通常强烈依赖于损失景观的精细结构，导致训练动态不稳定，反映出损失面的分形性质。在本工作中，我们提出了一种替代优化器，它可以同时减少这种依赖性并避免尖锐极小值，从而改善泛化能力。这种效果是通过模拟球心在损失景观上的运动实现的。优化器与标准梯度下降的不同程度由一个超参数控制，该超参数代表球的半径。改变这个超参数可以在不同尺度上探测损失景观，使其成为理解其几何结构的宝贵工具。', 'title_zh': '通过刚体动力学导航损失流形：稳健性和泛化能力的一种有前途的方法'}
{'arxiv_id': 'arXiv:2505.19525', 'title': 'Rethinking Gating Mechanism in Sparse MoE: Handling Arbitrary Modality Inputs with Confidence-Guided Gate', 'authors': 'Liangwei Nathan Zheng, Wei Emma Zhang, Mingyu Guo, Miao Xu, Olaf Maennel, Weitong Chen', 'link': 'https://arxiv.org/abs/2505.19525', 'abstract': 'Effectively managing missing modalities is a fundamental challenge in real-world multimodal learning scenarios, where data incompleteness often results from systematic collection errors or sensor failures. Sparse Mixture-of-Experts (SMoE) architectures have the potential to naturally handle multimodal data, with individual experts specializing in different modalities. However, existing SMoE approach often lacks proper ability to handle missing modality, leading to performance degradation and poor generalization in real-world applications. We propose Conf-SMoE to introduce a two-stage imputation module to handle the missing modality problem for the SMoE architecture and reveal the insight of expert collapse from theoretical analysis with strong empirical evidence. Inspired by our theoretical analysis, Conf-SMoE propose a novel expert gating mechanism by detaching the softmax routing score to task confidence score w.r.t ground truth. This naturally relieves expert collapse without introducing additional load balance loss function. We show that the insights of expert collapse aligns with other gating mechanism such as Gaussian and Laplacian gate. We also evaluate the proposed method on four different real world dataset with three different experiment settings to conduct comprehensive the analysis of Conf-SMoE on modality fusion and resistance to missing modality.', 'abstract_zh': '有效地管理缺失模态是实际多模态学习场景中的一个基本挑战，数据不完整往往由系统性采集错误或传感器故障引起。稀疏专家混合（SMoE）架构有潜力自然处理多模态数据，每个专家专注于不同的模态。然而，现有的SMoE方法往往缺乏处理缺失模态的适当能力，导致在实际应用中的性能下降和泛化能力差。我们提出Conf-SMoE，引入两阶段插补模块处理SMoE架构中的缺失模态问题，并通过理论分析和强有力的实验证据揭示专家合并的洞察。受理论分析的启发，Conf-SMoE提出了一种新的专家门控机制，通过将softmax路由得分分离为与_ground truth_相关的任务置信得分。这自然地缓解了专家合并问题，而无需引入额外的负载平衡损失函数。我们表明，专家合并的洞察与高斯门和拉普拉斯门等其他门控机制一致。我们还在四个不同的真实世界数据集上，以三种不同的实验设置评估了所提出的方法，对Conf-SMoE在模态融合和抵抗缺失模态方面的综合分析。', 'title_zh': '重新思考稀疏MoE中的门控机制：基于置信度引导的门控处理任意模态输入'}
{'arxiv_id': 'arXiv:2505.19514', 'title': 'SIPDO: Closed-Loop Prompt Optimization via Synthetic Data Feedback', 'authors': 'Yaoning Yu, Ye Yu, Kai Wei, Haojing Luo, Haohan Wang', 'link': 'https://arxiv.org/abs/2505.19514', 'abstract': 'Prompt quality plays a critical role in the performance of large language models (LLMs), motivating a growing body of work on prompt optimization. Most existing methods optimize prompts over a fixed dataset, assuming static input distributions and offering limited support for iterative improvement. We introduce SIPDO (Self-Improving Prompts through Data-Augmented Optimization), a closed-loop framework for prompt learning that integrates synthetic data generation into the optimization process. SIPDO couples a synthetic data generator with a prompt optimizer, where the generator produces new examples that reveal current prompt weaknesses and the optimizer incrementally refines the prompt in response. This feedback-driven loop enables systematic improvement of prompt performance without assuming access to external supervision or new tasks. Experiments across question answering and reasoning benchmarks show that SIPDO outperforms standard prompt tuning methods, highlighting the value of integrating data synthesis into prompt learning workflows.', 'abstract_zh': '基于数据扩充优化的自我提升提示（SIPDO：Self-Improving Prompts through Data-Augmented Optimization）', 'title_zh': 'SIPDO：通过合成数据反馈的闭环提示优化'}
{'arxiv_id': 'arXiv:2505.19509', 'title': 'Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models', 'authors': 'Yifan Jia, Kailin Jiang, Yuyang Liang, Qihan Ren, Yi Xin, Rui Yang, Fenze Feng, Mingcai Chen, Hengyang Lu, Haozhe Wang, Xiaoye Qu, Dongrui Liu, Lizhen Cui, Yuntao Du', 'link': 'https://arxiv.org/abs/2505.19509', 'abstract': "Large Multimodal Models(LMMs) face notable challenges when encountering multimodal knowledge conflicts, particularly under retrieval-augmented generation(RAG) frameworks where the contextual information from external sources may contradict the model's internal parametric knowledge, leading to unreliable outputs. However, existing benchmarks fail to reflect such realistic conflict scenarios. Most focus solely on intra-memory conflicts, while context-memory and inter-context conflicts remain largely investigated. Furthermore, commonly used factual knowledge-based evaluations are often overlooked, and existing datasets lack a thorough investigation into conflict detection capabilities. To bridge this gap, we propose MMKC-Bench, a benchmark designed to evaluate factual knowledge conflicts in both context-memory and inter-context scenarios. MMKC-Bench encompasses three types of multimodal knowledge conflicts and includes 1,573 knowledge instances and 3,381 images across 23 broad types, collected through automated pipelines with human verification. We evaluate three representative series of LMMs on both model behavior analysis and conflict detection tasks. Our findings show that while current LMMs are capable of recognizing knowledge conflicts, they tend to favor internal parametric knowledge over external evidence. We hope MMKC-Bench will foster further research in multimodal knowledge conflict and enhance the development of multimodal RAG systems. The source code is available at this https URL.", 'abstract_zh': '面向 Retrieval-Augmented Generation 框架下的多模态知识冲突基准：MMKC-Bench', 'title_zh': '大型多模态模型中的多模态知识冲突基准研究'}
{'arxiv_id': 'arXiv:2505.19505', 'title': 'Hierarchical Tree Search-based User Lifelong Behavior Modeling on Large Language Model', 'authors': 'Yu Xia, Rui Zhong, Hao Gu, Wei Yang, Chi Lu, Peng Jiang, Kun Gai', 'link': 'https://arxiv.org/abs/2505.19505', 'abstract': 'Large Language Models (LLMs) have garnered significant attention in Recommendation Systems (RS) due to their extensive world knowledge and robust reasoning capabilities. However, a critical challenge lies in enabling LLMs to effectively comprehend and extract insights from massive user behaviors. Current approaches that directly leverage LLMs for user interest learning face limitations in handling long sequential behaviors, effectively extracting interest, and applying interest in practical scenarios. To address these issues, we propose a Hierarchical Tree Search-based User Lifelong Behavior Modeling framework (HiT-LBM). HiT-LBM integrates Chunked User Behavior Extraction (CUBE) and Hierarchical Tree Search for Interest (HTS) to capture diverse interests and interest evolution of user. CUBE divides user lifelong behaviors into multiple chunks and learns the interest and interest evolution within each chunk in a cascading manner. HTS generates candidate interests through hierarchical expansion and searches for the optimal interest with process rating model to ensure information gain for each behavior chunk. Additionally, we design Temporal-Ware Interest Fusion (TIF) to integrate interests from multiple behavior chunks, constructing a comprehensive representation of user lifelong interests. The representation can be embedded into any recommendation model to enhance performance. Extensive experiments demonstrate the effectiveness of our approach, showing that it surpasses state-of-the-art methods.', 'abstract_zh': '大型语言模型（LLMs）在推荐系统（RS）中由于其广泛的世界知识和强大的推理能力引起了广泛关注。然而，在使LLMs有效地理解和提取大量用户行为的洞察方面仍存在关键挑战。当前直接利用LLMs进行用户兴趣学习的方法在处理长序列行为、有效提取兴趣以及在实际场景中应用兴趣方面存在局限性。为了解决这些问题，我们提出了一种基于分层树搜索的用户终身行为建模框架（HiT-LBM）。HiT-LBM结合了片段化用户行为提取（CUBE）和分层树搜索兴趣（HTS）来捕捉用户多样化的兴趣和兴趣演变。CUBE将用户终身行为划分为多个片段，并通过对每个片段逐级学习来捕捉兴趣及其演变。HTS通过分层扩展生成候选兴趣，并通过过程评分模型进行搜索以确保每个行为片段的信息增益。此外，我们设计了时间感知兴趣融合（TIF）以整合多个行为片段的兴趣，构建用户终身兴趣的全面表示。该表示可以嵌入到任何推荐模型中以提高性能。广泛的实验验证了我们方法的有效性，表明其优于现有方法。', 'title_zh': '基于分层树搜索的用户在大型语言模型上的终身行为建模'}
{'arxiv_id': 'arXiv:2505.19504', 'title': 'DOGe: Defensive Output Generation for LLM Protection Against Knowledge Distillation', 'authors': 'Pingzhi Li, Zhen Tan, Huaizhi Qu, Huan Liu, Tianlong Chen', 'link': 'https://arxiv.org/abs/2505.19504', 'abstract': "Large Language Models (LLMs) represent substantial intellectual and economic investments, yet their effectiveness can inadvertently facilitate model imitation via knowledge distillation (KD).In practical scenarios, competitors can distill proprietary LLM capabilities by simply observing publicly accessible outputs, akin to reverse-engineering a complex performance by observation alone. Existing protective methods like watermarking only identify imitation post-hoc, while other defenses assume the student model mimics the teacher's internal logits, rendering them ineffective against distillation purely from observed output text. This paper confronts the challenge of actively protecting LLMs within the realistic constraints of API-based access. We introduce an effective and efficient Defensive Output Generation (DOGe) strategy that subtly modifies the output behavior of an LLM. Its outputs remain accurate and useful for legitimate users, yet are designed to be misleading for distillation, significantly undermining imitation attempts. We achieve this by fine-tuning only the final linear layer of the teacher LLM with an adversarial loss. This targeted training approach anticipates and disrupts distillation attempts during inference time. Our experiments show that, while preserving or even improving the original performance of the teacher model, student models distilled from the defensively generated teacher outputs demonstrate catastrophically reduced performance, demonstrating our method's effectiveness as a practical safeguard against KD-based model imitation.", 'abstract_zh': '大型语言模型（LLMs）代表了巨大的智力和经济投入，然而其有效性可能会不经意间通过知识蒸馏（KD）促进模型模仿。在实际场景中，竞争者可以通过仅观察公开可访问的输出来简单地蒸馏私有LLM的能力，这类似于仅通过观察逆向工程复杂性能。现有的保护方法如水印只能事后识别模仿，而其他防御措施则假设学生模型模仿教师模型的内部logits，使其对仅从观察输出文本进行的蒸馏无效。本文在基于API访问的现实约束条件下应对积极保护LLMs的挑战。我们引入了一种有效且高效的Defensive Output Generation（DOGe）策略，该策略微妙地修改了LLM的输出行为。其输出对合法用户仍然是准确且有用的，但旨在误导蒸馏，显著削弱模仿企图。我们通过仅微调教师LLM的最后一层线性层并引入对抗损失来实现这一点。这种目标化的训练方法能够在推理时间预见并打断蒸馏企图。我们的实验表明，尽管保留或甚至改善了教师模型的原始性能，从防御性生成的教师输出蒸馏的学生模型则表现出灾难性的性能下降，证明了该方法作为一种实际防护手段的有效性，用以抵御基于KD的模型模仿。', 'title_zh': 'DOGe: 针对知识蒸馏的防御性输出生成以保护LLM'}
{'arxiv_id': 'arXiv:2505.19502', 'title': 'CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code Evaluation', 'authors': 'Guang Yang, Yu Zhou, Xiang Chen, Wei Zheng, Xing Hu, Xin Zhou, David Lo, Taolue Chen', 'link': 'https://arxiv.org/abs/2505.19502', 'abstract': 'Trustworthy evaluation methods for code snippets play a crucial role in neural code generation. Traditional methods, which either rely on reference solutions or require executable test cases, have inherent limitation in flexibility and scalability. The recent LLM-as-Judge methodology offers a promising alternative by directly evaluating functional consistency between the problem description and the generated code. To systematically understand the landscape of these LLM-as-Judge methods, we conduct a comprehensive empirical study across three diverse datasets. Our investigation reveals the pros and cons of two categories of LLM-as-Judge methods: the methods based on general foundation models can achieve good performance but require complex prompts and lack explainability, while the methods based on reasoning foundation models provide better explainability with simpler prompts but demand substantial computational resources due to their large parameter sizes. To address these limitations, we propose CODE-DITING, a novel code evaluation method that balances accuracy, efficiency and explainability. We develop a data distillation framework that effectively transfers reasoning capabilities from DeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing evaluation explainability and reducing the computational cost. With the majority vote strategy in the inference process, CODE-DITING 1.5B outperforms all models with the same magnitude of parameters and achieves performance which would normally exhibit in a model with 5 times of parameter scale. CODE-DITING 7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the parameter volume of these large models. Further experiments show that CODEDITING is robust to preference leakage and can serve as a promising alternative for code evaluation.', 'abstract_zh': '可信的代码片段评估方法对于神经代码生成至关重要。传统的方法要么依赖参考解决方案，要么需要可执行的测试用例，这在灵活性和可扩展性方面存在固有的局限性。最近的LLM-as-Judge方法通过直接评估问题描述与生成代码之间的功能一致性，提供了一种有前途的替代方案。为了系统地理解这些LLM-as-Judge方法的全景，我们在三个不同的数据集中进行了一项全面的经验研究。我们的调查表明，两类LLM-as-Judge方法各有优劣：基于通用基础模型的方法可以取得良好的性能，但需要复杂的提示且缺乏解释性，而基于推理基础模型的方法则提供更好的解释性且提示更简单，但由于参数量大，需要大量的计算资源。为了解决这些局限性，我们提出了CODE-DITING，一种新颖的代码评估方法，平衡了准确度、效率和解释性。我们开发了一种数据蒸馏框架，有效地将DeepSeek-R1671B的推理能力转移到我们的CODE-DITING 1.5B和7B模型中，显著提高了评估的解释性和降低了计算成本。通过推理过程中的多数投票策略，CODE-DITING 1.5B的表现优于所有具有相同规模参数的模型，并达到了一个具有五倍参数规模模型的性能。虽然CODE-DITING 7B仅使用这些大型模型1%的参数量，但它仍超过了GPT-4o和DeepSeek-V3 671B。进一步的实验表明，CODE-DITING 对偏好泄漏具有鲁棒性，并且可以作为代码评估的一种有前途的替代方案。', 'title_zh': '代码编辑：基于推理的代码功能对齐评估度量标准'}
{'arxiv_id': 'arXiv:2505.19498', 'title': 'Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models', 'authors': 'Nanxing Hu, Xiaoyue Duan, Jinchao Zhang, Guoliang Kang', 'link': 'https://arxiv.org/abs/2505.19498', 'abstract': "Large Vision-Language Models (LVLMs) usually generate texts which satisfy context coherence but don't match the visual input. Such a hallucination issue hinders LVLMs' applicability in the real world. The key to solving hallucination in LVLM is to make the text generation rely more on the visual content. Most previous works choose to enhance/adjust the features/output of a specific modality (i.e., visual or textual) to alleviate hallucinations in LVLM, which do not explicitly or systematically enhance the visual reliance. In this paper, we comprehensively investigate the factors which may degenerate the visual reliance in text generation of LVLM from a Bayesian perspective. Based on our observations, we propose to mitigate hallucination in LVLM from three aspects. Firstly, we observe that not all visual tokens are informative in generating meaningful texts. We propose to evaluate and remove redundant visual tokens to avoid their disturbance. Secondly, LVLM may encode inappropriate prior information, making it lean toward generating unexpected words. We propose a simple yet effective way to rectify the prior from a Bayesian perspective. Thirdly, we observe that starting from certain steps, the posterior of next-token prediction conditioned on visual tokens may collapse to a prior distribution which does not depend on any informative visual tokens at all. Thus, we propose to stop further text generation to avoid hallucination. Extensive experiments on three benchmarks including POPE, CHAIR, and MME demonstrate that our method can consistently mitigate the hallucination issue of LVLM and performs favorably against previous state-of-the-arts.", 'abstract_zh': '大型视觉-语言模型（LVLMs）通常生成与上下文连贯但不匹配视觉输入的文本。这种幻觉问题阻碍了LVLM在现实世界中的应用。解决LVLM幻觉的关键在于让文本生成更加依赖视觉内容。大多数前期工作选择了增强或调整特定模态（即视觉或文本）的特征/输出来缓解LVLM中的幻觉，但没有明确或系统地增强视觉依赖性。在本文中，我们从贝叶斯视角全面探讨了可能减弱LVLM文本生成中视觉依赖性的因素。基于我们的观察，我们提出从三个方面减轻LVLM中的幻觉。首先，我们观察到并非所有视觉词都对生成有意义的文本有信息性。我们提出评估和移除冗余的视觉词以避免其干扰。其次，LVLM可能编码了不适当的先验信息，使其倾向于生成出乎意料的词。我们提出了一种从贝叶斯视角简单而有效的方法来修正先验。第三，我们观察到从某一步开始，基于视觉词的下一个词预测的后验可能崩溃为一个与任何信息性视觉词无关的先验分布。因此，我们提出停止进一步的文本生成以避免幻觉。在POPE、CHAIR和MME三个基准上的广泛实验表明，我们的方法可以一致地减轻LVLM的幻觉问题，并在与前期最先进的方法进行比较时表现更好。', 'title_zh': '从贝叶斯视角缓解大型视觉语言模型中幻觉，增强文本生成中的视觉依赖性'}
{'arxiv_id': 'arXiv:2505.19488', 'title': 'Understanding Transformer from the Perspective of Associative Memory', 'authors': 'Shu Zhong, Mingyu Xu, Tenglong Ao, Guang Shi', 'link': 'https://arxiv.org/abs/2505.19488', 'abstract': 'In this paper, we share our reflections and insights on understanding Transformer architectures through the lens of associative memory--a classic psychological concept inspired by human cognition. We start with the basics of associative memory (think simple linear attention) and then dive into two dimensions:\nMemory Capacity: How much can a Transformer really remember, and how well? We introduce retrieval SNR to measure this and use a kernel perspective to mathematically reveal why Softmax Attention is so effective. We also show how FFNs can be seen as a type of associative memory, leading to insights on their design and potential improvements.\nMemory Update: How do these memories learn and evolve? We present a unified framework for understanding how different Transformer variants (like DeltaNet and Softmax Attention) update their "knowledge base". This leads us to tackle two provocative questions: 1. Are Transformers fundamentally limited in what they can express, and can we break these barriers? 2. If a Transformer had infinite context, would it become infinitely intelligent?\nWe want to demystify Transformer architecture, offering a clearer understanding of existing designs. This exploration aims to provide fresh insights and spark new avenues for Transformer innovation.', 'abstract_zh': '通过关联记忆视角理解Transformer架构：反思与洞察', 'title_zh': '从关联记忆的角度理解变压器模型'}
{'arxiv_id': 'arXiv:2505.19481', 'title': 'Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs', 'authors': 'Hao Kang, Qingru Zhang, Han Cai, Weiyuan Xu, Tushar Krishna, Yilun Du, Tsachy Weissman', 'link': 'https://arxiv.org/abs/2505.19481', 'abstract': 'Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards. Despite the importance of this latency quality trade off, it remains underexplored in the context of LLM based agents. In this work, we present the first systematic study of this trade off in real time decision making tasks. To support our investigation, we introduce two new benchmarks: HFTBench, a high frequency trading simulation, and StreetFighter, a competitive gaming platform. Our analysis reveals that optimal latency quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance. To address this, we propose FPX, an adaptive framework that dynamically selects model size and quantization level based on real time demands. Our method achieves the best performance on both benchmarks, improving win rate by up to 80% in Street Fighter and boosting daily yield by up to 26.52% in trading, underscoring the need for latency aware evaluation and deployment strategies for LLM based agents. These results demonstrate the critical importance of latency aware evaluation and deployment strategies for real world LLM based agents. Our benchmarks are available at Latency Sensitive Benchmarks.', 'abstract_zh': '大规模语言模型（LLMs）在多样化的推理和生成任务中展示了出色的表现，并越来越多地被部署为动态环境中的代理，如代码生成和推荐系统。然而，许多实际应用，如高频交易和实时竞技游戏，要求在严格的延迟约束下做出决策，其中更快的响应直接转化为更高的收益。尽管这一延迟质量权衡的重要性不言而喻，但在基于LLM的代理中，它仍然没有得到充分探索。在本文中，我们首次系统研究了这种权衡在实时决策任务中的表现。为了支持我们的研究，我们引入了两个新的基准测试：HFTBench，一个高频交易模拟平台，和StreetFighter，一个竞技游戏平台。我们的分析表明，最优的延迟质量平衡因任务而异，牺牲一些质量以降低延迟可以显著提升下游性能。为此，我们提出了FPX，一个适应性框架，可以根据实时需求动态选择模型大小和量化级别。我们的方法在两个基准测试中均取得了最佳性能，在Street Fighter中将胜率提高最多80%，在交易中将日收益提升最多26.52%，强调了对基于LLM的代理进行延迟意识评估和部署策略的需求。这些结果证明了对基于LLM的实际应用代理进行延迟意识评估和部署策略的重要性。我们提供的基准测试可在 Latency Sensitive Benchmarks 获取。', 'title_zh': '人在快与错之间：平衡LLM在延迟敏感决策中的速度与准确性'}
{'arxiv_id': 'arXiv:2505.19469', 'title': 'Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with Self-Adaptive Memory', 'authors': 'Mingzhuo Li, Guang Li, Jiafeng Mao, Takahiro Ogawa, Miki Haseyama', 'link': 'https://arxiv.org/abs/2505.19469', 'abstract': 'Dataset distillation enables the training of deep neural networks with comparable performance in significantly reduced time by compressing large datasets into small and representative ones. Although the introduction of generative models has made great achievements in this field, the distributions of their distilled datasets are not diverse enough to represent the original ones, leading to a decrease in downstream validation accuracy. In this paper, we present a diversity-driven generative dataset distillation method based on a diffusion model to solve this problem. We introduce self-adaptive memory to align the distribution between distilled and real datasets, assessing the representativeness. The degree of alignment leads the diffusion model to generate more diverse datasets during the distillation process. Extensive experiments show that our method outperforms existing state-of-the-art methods in most situations, proving its ability to tackle dataset distillation tasks.', 'abstract_zh': '基于扩散模型的多样性驱动生成式数据集蒸馏方法', 'title_zh': '基于自适应记忆和扩散模型的多元化驱动生成数据集精简'}
{'arxiv_id': 'arXiv:2505.19465', 'title': 'Residual Cross-Attention Transformer-Based Multi-User CSI Feedback with Deep Joint Source-Channel Coding', 'authors': 'Hengwei Zhang, Minghui Wu, Li Qiao, Ling Liu, Ziqi Han, Zhen Gao', 'link': 'https://arxiv.org/abs/2505.19465', 'abstract': 'This letter proposes a deep-learning (DL)-based multi-user channel state information (CSI) feedback framework for massive multiple-input multiple-output systems, where the deep joint source-channel coding (DJSCC) is utilized to improve the CSI reconstruction accuracy. Specifically, we design a multi-user joint CSI feedback framework, whereby the CSI correlation of nearby users is utilized to reduce the feedback overhead. Under the framework, we propose a new residual cross-attention transformer architecture, which is deployed at the base station to further improve the CSI feedback performance. Moreover, to tackle the "cliff-effect" of conventional bit-level CSI feedback approaches, we integrated DJSCC into the multi-user CSI feedback, together with utilizing a two-stage training scheme to adapt to varying uplink noise levels. Experimental results demonstrate the superiority of our methods in CSI feedback performance, with low network complexity and better scalability.', 'abstract_zh': '基于深度学习的多用户信道状态信息反馈框架及其联合源信道编码研究', 'title_zh': '基于残差跨注意力变换器的多用户CSI反馈深度联合源-信道编码'}
{'arxiv_id': 'arXiv:2505.19459', 'title': 'Your Classifier Can Do More: Towards Bridging the Gaps in Classification, Robustness, and Generation', 'authors': 'Kaichao Jiang, He Wang, Xiaoshuai Hao, Xiulong Yang, Ajian Liu, Qi Chu, Yunfeng Diao', 'link': 'https://arxiv.org/abs/2505.19459', 'abstract': "Joint Energy-based Models (JEMs), a class of hybrid generative-discriminative models, are well known for their ability to achieve both high classification accuracy and generative capability within a single model. However, their robustness still lags significantly behind the classifiers based adversarial training (AT). Conversely, while AT is currently the most effective approach to improving the classifier's robustness, it typically sacrifices accuracy on clean data and lacks generative capability. The triple trade-off between classification accuracy, generative capability and robustness, raises a natural question: Can a single model simultaneously achieve high classification accuracy, adversarial robustness, and generative performance? -- a goal that has been rarely explored. To address this question, we systematically analyze the energy distribution differences of clean, adversarial, and generated samples across various JEM variants and adversarially trained models. We observe that AT tends to reduce the energy gap between clean and adversarial samples, while JEMs reduce the gap between clean and synthetic ones. This observation suggests a key insight: if the energy distributions of all three data types can be aligned, we might unify the strengths of AT and JEMs, resolving their inherent trade-offs. Building on this idea, we propose Energy-based Joint Distribution Adversarial Training (EB-JDAT), to jointly model the clean data distribution, the adversarial distribution, and the classifier by maximizing their joint probability. EB-JDAT is a general and flexible optimization method, compatible with various JEM variants. Extensive experimental results demonstrate that EB-JDAT not only maintains near original accuracy and generative capability of JEMs, but also significantly enhances robustness, even surpassing state-of-the-art ATs.", 'abstract_zh': '基于能量的联合分布对抗训练（EB-JDAT）：同时实现高分类准确率、对抗鲁棒性和生成性能', 'title_zh': '你的分类器大有可为：致力于填补分类、 robustness 和生成之间的差距'}
{'arxiv_id': 'arXiv:2505.19455', 'title': 'MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question Answering', 'authors': 'Xu Li, Fan Lyu', 'link': 'https://arxiv.org/abs/2505.19455', 'abstract': 'Continual Visual Question Answering (CVQA) based on pre-trained models(PTMs) has achieved promising progress by leveraging prompt tuning to enable continual multi-modal learning. However, most existing methods adopt cross-modal prompt isolation, constructing visual and textual prompts separately, which exacerbates modality imbalance and leads to degraded performance over time. To tackle this issue, we propose MM-Prompt, a novel framework incorporating cross-modal prompt query and cross-modal prompt recovery. The former enables balanced prompt selection by incorporating cross-modal signals during query formation, while the latter promotes joint prompt reconstruction through iterative cross-modal interactions, guided by an alignment loss to prevent representational drift. Extensive experiments show that MM-Prompt surpasses prior approaches in accuracy and knowledge retention, while maintaining balanced modality engagement throughout continual learning.', 'abstract_zh': '基于预训练模型的持续视觉问答（CVQA）通过利用提示调优实现有希望的进展，以促进持续多模态学习。然而，现有方法大多采用跨模态提示隔离策略，分别构建视觉和文本提示，这加重了模态不平衡，导致性能随时间下降。为解决这一问题，我们提出MM-Prompt框架，该框架结合了跨模态提示查询和跨模态提示恢复。前者通过在查询形成过程中融合跨模态信号，实现平衡的提示选择，而后者通过迭代的跨模态交互促进联合提示重构，并通过对齐损失防止表示漂移。广泛实验表明，MM-Prompt在准确性和知识保留方面超越了先前的方法，同时在持续学习过程中保持了模态的平衡参与。', 'title_zh': 'MM-Prompt: 跨模态提示调优的持续视觉问答'}
{'arxiv_id': 'arXiv:2505.19443', 'title': 'Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI', 'authors': 'Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee', 'link': 'https://arxiv.org/abs/2505.19443', 'abstract': 'This review presents a comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-in-the-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose a detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate a future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within a unified, human-centered development lifecycle.', 'abstract_zh': '本文对AI辅助软件开发中两种新兴范式——情绪编码和主动编码——进行了全面分析。尽管两者都利用了大规模语言模型（LLMs），但在自主性、架构设计和开发人员的角色方面存在根本差异。情绪编码强调直观的人机交互，通过基于提示的对话工作流支持创意构想、实验和创造性探索。相比之下，主动编码通过目标驱动的代理实现自主软件开发，这些代理能够规划、执行、测试和迭代任务，同时尽量减少人类干预。我们提出了一个详细的分类框架，涵盖概念基础、执行模型、反馈循环、安全机制、调试策略以及现实世界工具生态系统。通过对比工作流分析和20个详细的用例，我们展示了情绪系统在早期原型设计和教育中的优势，以及主动系统在企业级自动化、代码库重构和CI/CD集成中的卓越表现。此外，我们探讨了自然语言接口与自主执行管道结合的新兴混合架构趋势。最后，我们阐述了主动AI的未来路线图，概述了实现可信赖、可解释和协作系统的基础设施需求。我们的研究结果表明，成功的AI软件工程依赖于在统一的、以人为中心的开发生命周期中和谐地结合这两种范式的优点。', 'title_zh': '意志编码 vs. 主体编码：主体性AI的基本原理及实践意义'}
{'arxiv_id': 'arXiv:2505.19441', 'title': 'Fairness Practices in Industry: A Case Study in Machine Learning Teams Building Recommender Systems', 'authors': 'Jing Nathan Yan, Junxiong Wang, Jeffrey M. Rzeszotarski, Allison Koenecke', 'link': 'https://arxiv.org/abs/2505.19441', 'abstract': "The rapid proliferation of recommender systems necessitates robust fairness practices to address inherent biases. Assessing fairness, though, is challenging due to constantly evolving metrics and best practices. This paper analyzes how industry practitioners perceive and incorporate these changing fairness standards in their workflows. Through semi-structured interviews with 11 practitioners from technical teams across a range of large technology companies, we investigate industry implementations of fairness in recommendation system products. We focus on current debiasing practices, applied metrics, collaborative strategies, and integrating academic research into practice. Findings show a preference for multi-dimensional debiasing over traditional demographic methods, and a reliance on intuitive rather than academic metrics. This study also highlights the difficulties in balancing fairness with both the practitioner's individual (bottom-up) roles and organizational (top-down) workplace constraints, including the interplay with legal and compliance experts. Finally, we offer actionable recommendations for the recommender system community and algorithmic fairness practitioners, underlining the need to refine fairness practices continually.", 'abstract_zh': '推荐系统迅速 proliferation necessitates robust fairness practices to address inherent biases.评估公平性虽具挑战性，但不断演进的指标和最佳实践要求我们必须适应。本文分析了行业从业者如何感知和在工作中融入这些不断变化的公平标准。通过半结构化访谈11名来自不同大型科技公司技术团队的从业者，我们探究了行业在推荐系统产品中实施公平性的实践。研究重点包括当前的去偏见实践、应用的指标、协作策略以及将学术研究融入实践的方法。研究发现，从业者更偏好多维度的去偏见方法而非传统的 démographic 方法，并依赖直观而非学术指标。此外，研究还突出了在个人（自下而上）职责和组织（自上而下）工作场所约束之间平衡公平性所面临的困难，包括与法律和合规专家的互动。最后，我们为推荐系统社区和算法公平性从业者提供了可行建议，强调了持续改进公平性实践的必要性。', 'title_zh': 'industria中的公平性实践：机器学习团队构建推荐系统案例研究'}
{'arxiv_id': 'arXiv:2505.19434', 'title': 'CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features', 'authors': 'X. Feng, D. Zhang, S. Hu, X. Li, M. Wu, J. Zhang, X. Chen, K. Huang', 'link': 'https://arxiv.org/abs/2505.19434', 'abstract': 'Effectively modeling and utilizing spatiotemporal features from RGB and other modalities (\\eg, depth, thermal, and event data, denoted as X) is the core of RGB-X tracker design. Existing methods often employ two parallel branches to separately process the RGB and X input streams, requiring the model to simultaneously handle two dispersed feature spaces, which complicates both the model structure and computation process. More critically, intra-modality spatial modeling within each dispersed space incurs substantial computational overhead, limiting resources for inter-modality spatial modeling and temporal modeling. To address this, we propose a novel tracker, CSTrack, which focuses on modeling Compact Spatiotemporal features to achieve simple yet effective tracking. Specifically, we first introduce an innovative Spatial Compact Module that integrates the RGB-X dual input streams into a compact spatial feature, enabling thorough intra- and inter-modality spatial modeling. Additionally, we design an efficient Temporal Compact Module that compactly represents temporal features by constructing the refined target distribution heatmap. Extensive experiments validate the effectiveness of our compact spatiotemporal modeling method, with CSTrack achieving new SOTA results on mainstream RGB-X benchmarks. The code and models will be released at: this https URL.', 'abstract_zh': '有效建模和利用来自RGB及其他模态（例如深度、热成像和事件数据X）的时空特征是RGB-X跟踪器设计的核心。现有的方法通常使用两个并行分支分别处理RGB和X输入流，要求模型同时处理两个分散的特征空间，这不仅增加了模型结构和计算过程的复杂性，还导致了在每个分散空间内进行模态内时空建模时产生了大量计算开销，限制了跨模态时空建模和时间建模的资源。为解决这一问题，我们提出了一种新型跟踪器CSTrack，专注于建模紧凑的时空特征以实现简单而有效的跟踪。具体而言，我们首先引入了一个创新的时空紧凑模块，将RGB-X双输入流整合为一个紧凑的空间特征，从而实现彻底的模态内和跨模态空间建模。此外，我们设计了一个高效的时空紧凑模块，通过构建精炼的目标分布热图紧凑地表示时空特征。广泛的实验验证了我们紧凑时空建模方法的有效性，CSTrack在主流RGB-X基准测试中取得了新的SOTA结果。代码和模型将发布在：this https URL。', 'title_zh': 'CSTrack：通过紧凑的时空特征增强RGB-X目标跟踪'}
{'arxiv_id': 'arXiv:2505.19430', 'title': 'Deriving Strategic Market Insights with Large Language Models: A Benchmark for Forward Counterfactual Generation', 'authors': 'Keane Ong, Rui Mao, Deeksha Varshney, Paul Pu Liang, Erik Cambria, Gianmarco Mengaldo', 'link': 'https://arxiv.org/abs/2505.19430', 'abstract': 'Counterfactual reasoning typically involves considering alternatives to actual events. While often applied to understand past events, a distinct form-forward counterfactual reasoning-focuses on anticipating plausible future developments. This type of reasoning is invaluable in dynamic financial markets, where anticipating market developments can powerfully unveil potential risks and opportunities for stakeholders, guiding their decision-making. However, performing this at scale is challenging due to the cognitive demands involved, underscoring the need for automated solutions. Large Language Models (LLMs) offer promise, but remain unexplored for this application. To address this gap, we introduce a novel benchmark, Fin-Force-FINancial FORward Counterfactual Evaluation. By curating financial news headlines and providing structured evaluation, Fin-Force supports LLM based forward counterfactual generation. This paves the way for scalable and automated solutions for exploring and anticipating future market developments, thereby providing structured insights for decision-making. Through experiments on Fin-Force, we evaluate state-of-the-art LLMs and counterfactual generation methods, analyzing their limitations and proposing insights for future research.', 'abstract_zh': '金融前瞻反事实评估：Fin-Force', 'title_zh': '使用大型语言模型推导战略市场洞察：前瞻性反事实生成基准'}
{'arxiv_id': 'arXiv:2505.19427', 'title': 'WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference', 'authors': 'Sihan Chen, Dan Zhao, Jongwoo Ko, Colby Banbury, Huiping Zhuang, Luming Liang, Tianyi Chen', 'link': 'https://arxiv.org/abs/2505.19427', 'abstract': 'The growing computational demands of large language models (LLMs) make efficient inference and activation strategies increasingly critical. While recent approaches, such as Mixture-of-Experts (MoE), leverage selective activation but require specialized training, training-free sparse activation methods offer broader applicability and superior resource efficiency through their plug-and-play design. However, many existing methods rely solely on hidden state magnitudes to determine activation, resulting in high approximation errors and suboptimal inference accuracy. To address these limitations, we propose WINA (Weight Informed Neuron Activation), a novel, simple, and training-free sparse activation framework that jointly considers hidden state magnitudes and the column-wise $\\ell_2$-norms of weight matrices. We show that this leads to a sparsification strategy that obtains optimal approximation error bounds with theoretical guarantees tighter than existing techniques. Empirically, WINA also outperforms state-of-the-art methods (e.g., TEAL) by up to $2.94\\%$ in average performance at the same sparsity levels, across a diverse set of LLM architectures and datasets. These results position WINA as a new performance frontier for training-free sparse activation in LLM inference, advancing training-free sparse activation methods and setting a robust baseline for efficient inference. The source code is available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）不断增长的计算需求使得高效的推理和激活策略越来越重要。虽然最近的方法，如专家混合（MoE），利用了选择性激活但需要专门训练，无训练的稀疏激活方法通过其即插即用设计提供了更广泛的应用性和更好的资源效率。然而，许多现有方法仅依赖隐藏状态的幅度来决定激活，导致高近似误差和次优化的推理精度。为了解决这些局限性，我们提出了WINA（Weight Informed Neuron Activation），一种新颖的、简单的、无训练的稀疏激活框架，同时考虑隐藏状态幅度和权重矩阵的列 wise $\\ell_2$-范数。我们展示了这导致了一种稀疏化策略，该策略在理论上比现有技术更严格的保证下获得了最优的近似误差界。在实验中，WINA在相同的稀疏化水平下也优于最先进的方法（例如TEAL），在不同程度的大型语言模型架构和数据集上，平均性能提高了2.94%。这些结果将WINA定位为无训练稀疏激活在LLM推理中新的性能前沿，推动了无训练稀疏激活方法的发展，并设定了高效推理的稳健基线。源代码可在以下链接获取。', 'title_zh': 'WINA: 基于权重的神经元激活加速大型语言模型推理'}
{'arxiv_id': 'arXiv:2505.19426', 'title': 'The Role of Diversity in In-Context Learning for Large Language Models', 'authors': 'Wenyang Xiao, Haoyu Zhao, Lingxiao Huang', 'link': 'https://arxiv.org/abs/2505.19426', 'abstract': 'In-context learning (ICL) is a crucial capability of current large language models (LLMs), where the selection of examples plays a key role in performance. While most existing approaches focus on selecting the most similar examples to the query, the impact of diversity in example selection remains underexplored. We systematically investigate the role of diversity in in-context example selection through experiments across a range of tasks, from sentiment classification to more challenging math and code problems. Experiments on Llama-3.1, Gemma-2, and Mistral-v0.3 families of models show that diversity-aware selection methods improve performance, particularly on complex tasks like math and code, and enhance robustness to out-of-distribution queries. To support these findings, we introduce a theoretical framework that explains the benefits of incorporating diversity in in-context example selection.', 'abstract_zh': '基于上下文学习（ICL）中多样性在当前大型语言模型（LLMs）性能中的作用研究', 'title_zh': '大规模语言模型上下文学习中多样性的角色'}
{'arxiv_id': 'arXiv:2505.19423', 'title': 'Surrogate-Assisted Evolutionary Reinforcement Learning Based on Autoencoder and Hyperbolic Neural Network', 'authors': 'Bingdong Li, Mei Jiang, Hong Qian, Peng Yang, Wenjing Hong, Hong Qian, Ke Tang', 'link': 'https://arxiv.org/abs/2505.19423', 'abstract': 'Evolutionary Reinforcement Learning (ERL), training the Reinforcement Learning (RL) policies with Evolutionary Algorithms (EAs), have demonstrated enhanced exploration capabilities and greater robustness than using traditional policy gradient. However, ERL suffers from the high computational costs and low search efficiency, as EAs require evaluating numerous candidate policies with expensive simulations, many of which are ineffective and do not contribute meaningfully to the training. One intuitive way to reduce the ineffective evaluations is to adopt the surrogates. Unfortunately, existing ERL policies are often modeled as deep neural networks (DNNs) and thus naturally represented as high-dimensional vectors containing millions of weights, which makes the building of effective surrogates for ERL policies extremely challenging. This paper proposes a novel surrogate-assisted ERL that integrates Autoencoders (AE) and Hyperbolic Neural Networks (HNN). Specifically, AE compresses high-dimensional policies into low-dimensional representations while extracting key features as the inputs for the surrogate. HNN, functioning as a classification-based surrogate model, can learn complex nonlinear relationships from sampled data and enable more accurate pre-selection of the sampled policies without real evaluations. The experiments on 10 Atari and 4 Mujoco games have verified that the proposed method outperforms previous approaches significantly. The search trajectories guided by AE and HNN are also visually demonstrated to be more effective, in terms of both exploration and convergence. This paper not only presents the first learnable policy embedding and surrogate-modeling modules for high-dimensional ERL policies, but also empirically reveals when and why they can be successful.', 'abstract_zh': '基于自编码器和双曲神经网络的代理辅助进化强化学习', 'title_zh': '基于自动编码器和双曲神经网络的代理辅助进化强化学习'}
{'arxiv_id': 'arXiv:2505.19419', 'title': 'It\'s Not Just Labeling" -- A Research on LLM Generated Feedback Interpretability and Image Labeling Sketch Features', 'authors': 'Baichuan Li, Larry Powell, Tracy Hammond', 'link': 'https://arxiv.org/abs/2505.19419', 'abstract': 'The quality of training data is critical to the performance of machine learning applications in domains like transportation, healthcare, and robotics. Accurate image labeling, however, often relies on time-consuming, expert-driven methods with limited feedback. This research introduces a sketch-based annotation approach supported by large language models (LLMs) to reduce technical barriers and enhance accessibility. Using a synthetic dataset, we examine how sketch recognition features relate to LLM feedback metrics, aiming to improve the reliability and interpretability of LLM-assisted labeling. We also explore how prompting strategies and sketch variations influence feedback quality. Our main contribution is a sketch-based virtual assistant that simplifies annotation for non-experts and advances LLM-driven labeling tools in terms of scalability, accessibility, and explainability.', 'abstract_zh': '基于素描的标注方法：借助大型语言模型降低技术门槛和提升标注可访问性和解释性', 'title_zh': '不仅仅是标签——关于LLM生成反馈可解释性和图像标签草图特征的研究'}
{'arxiv_id': 'arXiv:2505.19404', 'title': 'Exploring the Possibility of TypiClust for Low-Budget Federated Active Learning', 'authors': 'Yuta Ono, Hiroshi Nakamura, Hideki Takase', 'link': 'https://arxiv.org/abs/2505.19404', 'abstract': 'Federated Active Learning (FAL) seeks to reduce the burden of annotation under the realistic constraints of federated learning by leveraging Active Learning (AL). As FAL settings make it more expensive to obtain ground truth labels, FAL strategies that work well in low-budget regimes, where the amount of annotation is very limited, are needed. In this work, we investigate the effectiveness of TypiClust, a successful low-budget AL strategy, in low-budget FAL settings. Our empirical results show that TypiClust works well even in low-budget FAL settings contrasted with relatively low performances of other methods, although these settings present additional challenges, such as data heterogeneity, compared to AL. In addition, we show that FAL settings cause distribution shifts in terms of typicality, but TypiClust is not very vulnerable to the shifts. We also analyze the sensitivity of TypiClust to feature extraction methods, and it suggests a way to perform FAL even in limited data situations.', 'abstract_zh': '联邦主动学习（FAL）在联邦学习的现实约束下，通过利用主动学习（AL）来减少标注负担。在低预算环境下，FAL策略需要能够在标注数据量非常有限的情况下取得良好效果。在本文中，我们研究了TypiClust这一成功的低预算AL策略在低预算FAL设置中的有效性。实验证明，即使在与其它方法相比表现较低的情况下，TypiClust也能在低预算FAL设置中很好地工作，尽管这些设置相比传统的AL增加了数据异质性等额外挑战。此外，我们展示了FAL设置会导致典型性分布偏移，但TypiClust对此类偏移不特别敏感。我们还分析了TypiClust对特征提取方法的敏感性，这为在数据有限的情况下进行FAL提供了一种方法。', 'title_zh': '探究 TypiClust 在低预算联邦主动学习中的可能性'}
{'arxiv_id': 'arXiv:2505.19395', 'title': 'VADER: A Human-Evaluated Benchmark for Vulnerability Assessment, Detection, Explanation, and Remediation', 'authors': 'Ethan TS. Liu, Austin Wang, Spencer Mateega, Carlos Georgescu, Danny Tang', 'link': 'https://arxiv.org/abs/2505.19395', 'abstract': "Ensuring that large language models (LLMs) can effectively assess, detect, explain, and remediate software vulnerabilities is critical for building robust and secure software systems. We introduce VADER, a human-evaluated benchmark designed explicitly to assess LLM performance across four key vulnerability-handling dimensions: assessment, detection, explanation, and remediation. VADER comprises 174 real-world software vulnerabilities, each carefully curated from GitHub repositories and annotated by security experts. For each vulnerability case, models are tasked with identifying the flaw, classifying it using Common Weakness Enumeration (CWE), explaining its underlying cause, proposing a patch, and formulating a test plan. Using a one-shot prompting strategy, we benchmark six state-of-the-art LLMs (Claude 3.7 Sonnet, Gemini 2.5 Pro, GPT-4.1, GPT-4.5, Grok 3 Beta, and o3) on VADER, and human security experts evaluated each response according to a rigorous scoring rubric emphasizing remediation (quality of the code fix, 50%), explanation (20%), and classification and test plan (30%) according to a standardized rubric. Our results show that current state-of-the-art LLMs achieve only moderate success on VADER - OpenAI's o3 attained 54.7% accuracy overall, with others in the 49-54% range, indicating ample room for improvement. Notably, remediation quality is strongly correlated (Pearson r > 0.97) with accurate classification and test plans, suggesting that models that effectively categorize vulnerabilities also tend to fix them well. VADER's comprehensive dataset, detailed evaluation rubrics, scoring tools, and visualized results with confidence intervals are publicly released, providing the community with an interpretable, reproducible benchmark to advance vulnerability-aware LLMs. All code and data are available at: this https URL", 'abstract_zh': '确保大型语言模型（LLMs）能有效评估、检测、解释和 remediate 软件漏洞对于构建 robust 和 secure 的软件系统至关重要。我们引入了 VADER，一个由人工评估的基准，旨在全面评估 LLM 在四个关键的漏洞处理维度（评估、检测、解释和 remediation）上的性能。VADER 包含 174 个真实世界的软件漏洞，每个漏洞都来自 GitHub 仓库并由安全专家精心筛选和标注。对于每个漏洞案例，模型需要识别缺陷、采用常见弱点枚举（CWE）对其进行分类、解释其根本原因、提出补丁并制定测试计划。使用单次提示策略，我们在 VADER 上基准测试了六种最先进的 LLM（Claude 3.7 Sonnet、Gemini 2.5 Pro、GPT-4.1、GPT-4.5、Grok 3 Beta 和 o3），并且由人类安全专家根据严格的评分规则对每个回应进行评估，该规则强调 remediation（代码修复质量，占 50%）、解释（占 20%）以及分类和测试计划（标准化规则，占 30%）。结果显示，当前最先进的 LLM 在 VADER 上仅取得中等成效——OpenAI 的 o3 达到了 54.7% 的准确率，其他模型在 49-54% 之间，表明仍然有很大的改进空间。值得注意的是，remediation 质量与准确分类和测试计划高度相关（皮尔逊相关系数 > 0.97），这表明能够有效分类漏洞的模型往往也能较好地修复它们。VADER 的全面数据集、详细的评估规则、评分工具以及带有置信区间的结果可视化公开发布，为社区提供了一个可解释和可复现的基准，以推动漏洞感知 LLM 的发展。所有代码和数据可在以下链接获取：this https URL。', 'title_zh': 'VADER：漏洞评估、检测、解释与修复的人工评估基准'}
{'arxiv_id': 'arXiv:2505.19392', 'title': 'Simple and Effective Baselines for Code Summarisation Evaluation', 'authors': 'Jade Robinson, Jonathan K. Kummerfeld', 'link': 'https://arxiv.org/abs/2505.19392', 'abstract': 'Code documentation is useful, but writing it is time-consuming. Different techniques for generating code summaries have emerged, but comparing them is difficult because human evaluation is expensive and automatic metrics are unreliable. In this paper, we introduce a simple new baseline in which we ask an LLM to give an overall score to a summary. Unlike n-gram and embedding-based baselines, our approach is able to consider the code when giving a score. This allows us to also make a variant that does not consider the reference summary at all, which could be used for other tasks, e.g., to evaluate the quality of documentation in code bases. We find that our method is as good or better than prior metrics, though we recommend using it in conjunction with embedding-based methods to avoid the risk of LLM-specific bias.', 'abstract_zh': '代码文档总结生成技术评估中的一个简单新基线', 'title_zh': '简单有效的基准方法用于代码总结评估'}
{'arxiv_id': 'arXiv:2505.19386', 'title': 'Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals', 'authors': 'Nate Gillman, Charles Herrmann, Michael Freeman, Daksh Aggarwal, Evan Luo, Deqing Sun, Chen Sun', 'link': 'https://arxiv.org/abs/2505.19386', 'abstract': 'Recent advances in video generation models have sparked interest in world models capable of simulating realistic environments. While navigation has been well-explored, physically meaningful interactions that mimic real-world forces remain largely understudied. In this work, we investigate using physical forces as a control signal for video generation and propose force prompts which enable users to interact with images through both localized point forces, such as poking a plant, and global wind force fields, such as wind blowing on fabric. We demonstrate that these force prompts can enable videos to respond realistically to physical control signals by leveraging the visual and motion prior in the original pretrained model, without using any 3D asset or physics simulator at inference. The primary challenge of force prompting is the difficulty in obtaining high quality paired force-video training data, both in the real world due to the difficulty of obtaining force signals, and in synthetic data due to limitations in the visual quality and domain diversity of physics simulators. Our key finding is that video generation models can generalize remarkably well when adapted to follow physical force conditioning from videos synthesized by Blender, even with limited demonstrations of few objects. Our method can generate videos which simulate forces across diverse geometries, settings, and materials. We also try to understand the source of this generalization and perform ablations that reveal two key elements: visual diversity and the use of specific text keywords during training. Our approach is trained on only around 15k training examples for a single day on four A100 GPUs, and outperforms existing methods on force adherence and physics realism, bringing world models closer to real-world physics interactions. We release all datasets, code, weights, and interactive video demos at our project page.', 'abstract_zh': 'Recent Advances in Video Generation Models Have Sparked Interest in World Models Capable of Simulating Realistic Environments: Using Physical Forces as Control Signals', 'title_zh': '基于力量提示的视频生成模型能够学习和泛化物理控制信号'}
{'arxiv_id': 'arXiv:2505.19385', 'title': 'Advancing Limited-Angle CT Reconstruction Through Diffusion-Based Sinogram Completion', 'authors': 'Jiaqi Guo, Santiago Lopez-Tapia, Aggelos K. Katsaggelos', 'link': 'https://arxiv.org/abs/2505.19385', 'abstract': 'Limited Angle Computed Tomography (LACT) often faces significant challenges due to missing angular information. Unlike previous methods that operate in the image domain, we propose a new method that focuses on sinogram inpainting. We leverage MR-SDEs, a variant of diffusion models that characterize the diffusion process with mean-reverting stochastic differential equations, to fill in missing angular data at the projection level. Furthermore, by combining distillation with constraining the output of the model using the pseudo-inverse of the inpainting matrix, the diffusion process is accelerated and done in a step, enabling efficient and accurate sinogram completion. A subsequent post-processing module back-projects the inpainted sinogram into the image domain and further refines the reconstruction, effectively suppressing artifacts while preserving critical structural details. Quantitative experimental results demonstrate that the proposed method achieves state-of-the-art performance in both perceptual and fidelity quality, offering a promising solution for LACT reconstruction in scientific and clinical applications.', 'abstract_zh': '有限角度计算机断层成像（LACT）常因缺失角度信息而面临重大挑战。不同于以往在图像域工作的方法，我们提出了一种新的方法，专注于sinogram插补。我们利用MR-SDEs，一种通过均值回复随机微分方程刻画扩散过程的扩散模型变体，在投影级别填补缺失的角度数据。此外，通过结合蒸馏和利用插补矩阵伪逆约束模型输出，加速了扩散过程并一次性完成，从而实现高效且准确的sinogram完成。后续的后处理模块将插补的sinogram反投影到图像域，进一步细化重建结果，有效地抑制伪影同时保留关键结构细节。定量实验结果表明，所提出的方法在感知质量与保真度方面均达到最优性能，为LACT重建在科学和临床应用中提供了有前景的解决方案。', 'title_zh': '通过扩散基于的sinogram完成促进有限角度CT重建'}
{'arxiv_id': 'arXiv:2505.19369', 'title': 'SETransformer: A Hybrid Attention-Based Architecture for Robust Human Activity Recognition', 'authors': 'Yunbo Liu, Xukui Qin, Yifan Gao, Xiang Li, Chengwei Feng', 'link': 'https://arxiv.org/abs/2505.19369', 'abstract': 'Human Activity Recognition (HAR) using wearable sensor data has become a central task in mobile computing, healthcare, and human-computer interaction. Despite the success of traditional deep learning models such as CNNs and RNNs, they often struggle to capture long-range temporal dependencies and contextual relevance across multiple sensor channels. To address these limitations, we propose SETransformer, a hybrid deep neural architecture that combines Transformer-based temporal modeling with channel-wise squeeze-and-excitation (SE) attention and a learnable temporal attention pooling mechanism. The model takes raw triaxial accelerometer data as input and leverages global self-attention to capture activity-specific motion dynamics over extended time windows, while adaptively emphasizing informative sensor channels and critical time steps.\nWe evaluate SETransformer on the WISDM dataset and demonstrate that it significantly outperforms conventional models including LSTM, GRU, BiLSTM, and CNN baselines. The proposed model achieves a validation accuracy of 84.68\\% and a macro F1-score of 84.64\\%, surpassing all baseline architectures by a notable margin. Our results show that SETransformer is a competitive and interpretable solution for real-world HAR tasks, with strong potential for deployment in mobile and ubiquitous sensing applications.', 'abstract_zh': '使用穿戴传感器数据的人类活动识别（HAR）已成为移动计算、健康管理以及人机交互中的核心任务。尽管传统深度学习模型如卷积神经网络（CNNs）和循环神经网络（RNNs）取得了成功，但它们往往难以捕捉长距离的时间依赖性和多传感器通道间的上下文相关性。为了解决这些问题，我们提出了一种名为SETransformer的混合深度神经架构，该架构结合了基于Transformer的时间建模、通道 Wise 压缩与激励（SE）注意力机制以及可学习的时间注意力池化机制。该模型采用原始的三轴加速度计数据作为输入，并通过全局自我注意力机制捕捉长时间窗口内的活动特异性运动动态，同时自适应地强调信息丰富的传感器通道和关键时间步。', 'title_zh': '基于混合注意力机制的SETransformer：一种稳健的人类活动识别架构'}
{'arxiv_id': 'arXiv:2505.19356', 'title': 'Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval', 'authors': 'Kidist Amde Mekonnen, Yosef Worku Alemneh, Maarten de Rijke', 'link': 'https://arxiv.org/abs/2505.19356', 'abstract': 'Neural retrieval methods using transformer-based pre-trained language models have advanced multilingual and cross-lingual retrieval. However, their effectiveness for low-resource, morphologically rich languages such as Amharic remains underexplored due to data scarcity and suboptimal tokenization. We address this gap by introducing Amharic-specific dense retrieval models based on pre-trained Amharic BERT and RoBERTa backbones. Our proposed RoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative improvement in MRR@10 and a 9.86% gain in Recall@10 over the strongest multilingual baseline, Arctic Embed 2.0 (568M parameters). More compact variants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while being over 13x smaller. Additionally, we train a ColBERT-based late interaction retrieval model that achieves the highest MRR@10 score (0.843) among all evaluated models. We benchmark our proposed models against both sparse and dense retrieval baselines to systematically assess retrieval effectiveness in Amharic. Our analysis highlights key challenges in low-resource settings and underscores the importance of language-specific adaptation. To foster future research in low-resource IR, we publicly release our dataset, codebase, and trained models at this https URL.', 'abstract_zh': '基于变压器预训练语言模型的神经检索方法在多语言和跨语言检索中取得了进展，但对于如阿姆哈拉语这样的低资源、形态丰富的语言，其有效性仍待探索，原因在于数据稀缺和分词不理想。我们通过引入基于预训练阿姆哈拉语 BERT 和 RoBERTa 的阿姆哈拉语特定密集检索模型来填补这一空白。我们提出的 RoBERTa-Base-Amharic-Embed 模型（110M 参数）在 MRR@10 上实现了 17.6% 的相对改进，并在 Recall@10 上超过最强的多语言基线 Arctic Embed 2.0（568M 参数）9.86%。更紧凑的变体，如 RoBERTa-Medium-Amharic-Embed（42M），保持了竞争力，同时大小超过 13 倍。此外，我们训练了一个基于 ColBERT 的晚期交互检索模型，实现了所有评估模型中最高的 MRR@10 分数（0.843）。我们将我们提出的模型与稀疏和密集检索基线模型进行基准测试，以系统评估阿姆哈拉语中的检索效果。我们的分析强调了低资源设置中的关键挑战，并突显了语言特定适应的重要性。为了促进未来在低资源信息检索方面的研究，我们在该网址 <https://> 公开发布了我们的数据集、代码库和训练模型。', 'title_zh': '优化的提顿嵌入模型及阿姆哈拉语段落检索基准'}
{'arxiv_id': 'arXiv:2505.19345', 'title': 'PatentScore: Multi-dimensional Evaluation of LLM-Generated Patent Claims', 'authors': 'Yongmin Yoo, Qiongkai Xu, Longbing Cao', 'link': 'https://arxiv.org/abs/2505.19345', 'abstract': 'Natural language generation (NLG) metrics play a central role in evaluating generated texts, but are not well suited for the structural and legal characteristics of patent documents. Large language models (LLMs) offer strong potential in automating patent generation, yet research on evaluating LLM-generated patents remains limited, especially in evaluating the generation quality of patent claims, which are central to defining the scope of protection. Effective claim evaluation requires addressing legal validity, technical accuracy, and structural compliance. To address this gap, we introduce PatentScore, a multi-dimensional evaluation framework for assessing LLM-generated patent claims. PatentScore incorporates: (1) hierarchical decomposition for claim analysis; (2) domain-specific validation patterns based on legal and technical standards; and (3) scoring across structural, semantic, and legal dimensions. Unlike general-purpose NLG metrics, PatentScore reflects patent-specific constraints and document structures, enabling evaluation beyond surface similarity. We evaluate 400 GPT-4o-mini generated Claim 1s and report a Pearson correlation of $r = 0.819$ with expert annotations, outperforming existing NLG metrics. Furthermore, we conduct additional evaluations using open models such as Claude-3.5-Haiku and Gemini-1.5-flash, all of which show strong correlations with expert judgments, confirming the robustness and generalizability of our framework.', 'abstract_zh': '自然语言生成(NLG)指标在评估生成文本方面发挥着核心作用，但它们并不适合专利文件的结构和法律特点。大规模语言模型(LLMs)在自动化专利生成方面展现出强大的潜力，然而关于评估LLM生成的专利的研究仍然有限，尤其是在评估专利 claims 的生成质量方面，而claims是定义保护范围的核心。有效的claims评估需要解决法律有效性、技术准确性和结构合规性。为填补这一空白，我们提出了PatentScore，这是一个多维度的评估框架，用于评估LLM生成的专利claims。PatentScore包括：（1）索赔分析的分层分解；（2）基于法律和技术标准的领域特定验证模式；以及（3）在结构、语义和法律维度上的评分。与通用的NLG指标不同，PatentScore反映专利特定的约束和文档结构，能够超越表面相似性进行评估。我们评估了400个由GPT-4o-mini生成的Claim 1，并报告与专家注释的皮尔森相关系数为$r = 0.819$，优于现有NLG指标。此外，我们还使用了诸如Claude-3.5-Haiku和Gemini-1.5-flash等开源模型进行了额外评估，所有这些都与专家判断显示出强烈的相关性，证实了我们框架的稳健性和通用性。', 'title_zh': 'PatentScore: 多维度评估生成型专利主张'}
{'arxiv_id': 'arXiv:2505.19342', 'title': 'Communication-Efficient Multi-Device Inference Acceleration for Transformer Models', 'authors': 'Xiao Liu, Lijun Zhang, Deepak Ganesan, Hui Guan', 'link': 'https://arxiv.org/abs/2505.19342', 'abstract': 'Transformer models power many AI applications but suffer from high inference latency, limiting their use in real-time settings. Multi-device inference can reduce latency by parallelizing computation. Yet, existing methods require high inter-device bandwidth, making them impractical for bandwidth-constrained environments. We propose ASTRA, a communication-efficient framework that accelerates Transformer inference through a novel integration of sequence parallelism and a Mixed-Precision Attention mechanism designed to minimize inter-device communication. ASTRA compresses non-local token embeddings via vector quantization and preserves task accuracy through two optimizations, Noise-Augmented Quantization and Distributed Class Tokens. Experiments on ViT and GPT2 across vision and NLP tasks show that ASTRA achieves up to 2.64X speedups over single-device inference and up to 15.25X speedups over state-of-the-art multi-device inferences, while operating under bandwidths as low as 10 Mbps. ASTRA is open-sourced at this https URL.', 'abstract_zh': 'Transformer模型驱动许多AI应用，但 inference 纯量延迟较高，限制了其在实时场景中的应用。多设备推理可以通过并行计算来减少延迟，但现有方法需要较高的设备间带宽，不适合带宽受限的环境。我们提出ASTRA，一种通过新颖地结合序列并行性和设计用于最小化设备间通信的混合精度注意力机制来加速Transformer推理的通信高效框架。ASTRA通过向量量化压缩非局部 token 插值，并通过噪声增强量化和分布式类 token 两种优化保持任务准确性。在跨视觉和自然语言处理任务的ViT和GPT2上的实验表明，ASTRA在单设备推理上的加速比高达2.64倍，在最新多设备推理上的加速比高达15.25倍，同时在低至10 Mbps的带宽下运行。ASTRA已开源。', 'title_zh': '设备间通信高效的Transformer模型多设备推理加速'}
{'arxiv_id': 'arXiv:2505.19339', 'title': 'Towards Humanoid Robot Autonomy: A Dynamic Architecture Integrating Continuous thought Machines (CTM) and Model Context Protocol (MCP)', 'authors': 'Libo Wang', 'link': 'https://arxiv.org/abs/2505.19339', 'abstract': 'To address the gaps between the static pre-set "thinking-planning-action" of humanoid robots in unfamiliar scenarios and the highly programmed "call tool-return result" due to the lack of autonomous coding capabilities, this work designs a dynamic architecture connecting continuous thought machines (CTM) and model context protocol (MCP). It proposes a theoretical parallel solution through tick-slab and uses rank compression to achieve parameter suppression to provide a solution for achieving autonomous actions due to autonomous coding. The researcher used a simulation-based experiment using OpenAI\'s o4-mini-high as a tool to build the experimental environment, and introduced the extended SayCan dataset to conduct nine epochs of experiments. The experimental results show that the CTM-MCP architecture is feasible and effective through the data results of seven metrics: task success rate (TSR), execution success rate (ESR), average episode length (AEL), ROSCOE, REVEAL, proficiency self-assessment (PSA), task effectiveness (TE). In practice, it provides a reference experience for exploring the autonomous dynamic coding of humanoid robots based on continuous thinking to achieve human-like autonomous actions.', 'abstract_zh': '针对人在陌生场景中动态的“思考-规划-行动”与 humanoid 机器人因缺乏自主编码能力而导致的高程化“调用工具-返回结果”之间的差距，本研究设计了一种动态架构，连接连续思考机器（CTM）和模型上下文协议（MCP）。通过 tickslab 提出理论并使用秩压缩实现参数抑制，以实现因自主编码而产生的自主行动。研究者使用基于 OpenAI 的 o4-mini-high 进行仿真实验构建实验环境，并引入扩展的 SayCan 数据集进行了九个时期的实验。实验结果表明，CTM-MCP 架构通过七项指标（任务成功率 TSR、执行成功率 ESR、平均期长度 AEL、ROSCOER、REVEAL、熟练度自我评估 PSA、任务有效性 TE）的数据结果证明了其实用性和有效性。在实践中，该研究为基于连续思考实现 humanoid 机器人自主动态编码提供了参考经验，以实现类人的自主行动。', 'title_zh': 'humanoid机器人自主性的迈进：一种结合连续思维机器(CTM)和模型上下文协议(MCP)的动态架构'}
{'arxiv_id': 'arXiv:2505.19337', 'title': 'Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies', 'authors': 'Kevin Li, Marinka Zitnik', 'link': 'https://arxiv.org/abs/2505.19337', 'abstract': 'Offline goal-conditioned reinforcement learning methods have shown promise for reach-avoid tasks, where an agent must reach a target state while avoiding undesirable regions of the state space. Existing approaches typically encode avoid-region information into an augmented state space and cost function, which prevents flexible, dynamic specification of novel avoid-region information at evaluation time. They also rely heavily on well-designed reward and cost functions, limiting scalability to complex or poorly structured environments. We introduce RADT, a decision transformer model for offline, reward-free, goal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid regions directly as prompt tokens, allowing any number of avoid regions of arbitrary size to be specified at evaluation time. Using only suboptimal offline trajectories from a random policy, RADT learns reach-avoid behavior through a novel combination of goal and avoid-region hindsight relabeling. We benchmark RADT against 3 existing offline goal-conditioned RL models across 11 tasks, environments, and experimental settings. RADT generalizes in a zero-shot manner to out-of-distribution avoid region sizes and counts, outperforming baselines that require retraining. In one such zero-shot setting, RADT achieves 35.7% improvement in normalized cost over the best retrained baseline while maintaining high goal-reaching success. We apply RADT to cell reprogramming in biology, where it reduces visits to undesirable intermediate gene expression states during trajectories to desired target states, despite stochastic transitions and discrete, structured state dynamics.', 'abstract_zh': 'Offline 奖励无馈信息、目标条件、避险区域条件的强化学习方法：RADT模型研究', 'title_zh': '零-shot 达避策略的提示决策变换器'}
{'arxiv_id': 'arXiv:2505.19315', 'title': 'Demand Selection for VRP with Emission Quota', 'authors': 'Farid Najar, Dominique Barth, Yann Strozecki', 'link': 'https://arxiv.org/abs/2505.19315', 'abstract': 'Combinatorial optimization (CO) problems are traditionally addressed using Operations Research (OR) methods, including metaheuristics. In this study, we introduce a demand selection problem for the Vehicle Routing Problem (VRP) with an emission quota, referred to as QVRP. The objective is to minimize the number of omitted deliveries while respecting the pollution quota. We focus on the demand selection part, called Maximum Feasible Vehicle Assignment (MFVA), while the construction of a routing for the VRP instance is solved using classical OR methods. We propose several methods for selecting the packages to omit, both from machine learning (ML) and OR. Our results show that, in this static problem setting, classical OR-based methods consistently outperform ML-based approaches.', 'abstract_zh': '车辆 routing 问题（VRP）中的排放配额需求选择问题：一种组合优化方法', 'title_zh': '带有排放配额的车辆路线问题中的需求选择'}
{'arxiv_id': 'arXiv:2505.19314', 'title': 'SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline', 'authors': 'Helin Wang, Jiarui Hai, Dongchao Yang, Chen Chen, Kai Li, Junyi Peng, Thomas Thebaud, Laureano Moro Velazquez, Jesus Villalba, Najim Dehak', 'link': 'https://arxiv.org/abs/2505.19314', 'abstract': "Target Speech Extraction (TSE) aims to isolate a target speaker's voice from a mixture of multiple speakers by leveraging speaker-specific cues, typically provided as auxiliary audio (a.k.a. cue audio). Although recent advancements in TSE have primarily employed discriminative models that offer high perceptual quality, these models often introduce unwanted artifacts, reduce naturalness, and are sensitive to discrepancies between training and testing environments. On the other hand, generative models for TSE lag in perceptual quality and intelligibility. To address these challenges, we present SoloSpeech, a novel cascaded generative pipeline that integrates compression, extraction, reconstruction, and correction processes. SoloSpeech features a speaker-embedding-free target extractor that utilizes conditional information from the cue audio's latent space, aligning it with the mixture audio's latent space to prevent mismatches. Evaluated on the widely-used Libri2Mix dataset, SoloSpeech achieves the new state-of-the-art intelligibility and quality in target speech extraction and speech separation tasks while demonstrating exceptional generalization on out-of-domain data and real-world scenarios.", 'abstract_zh': '单声道语音提取 (SoloSpeech) 目标旨在通过利用典型作为辅助音频提供的说话人特定线索，从多说话人的混合音频中隔离目标说话人的声音。尽管近期目标语音提取 (TSE) 的进展主要依赖于提供高感知质量的判别模型，但这些模型常常引入不必要的艺术制品，降低自然度，并且对训练和测试环境之间的差异敏感。另一方面，TSE 的生成模型在感知质量和可懂度方面滞后。为应对这些挑战，我们提出了一种新颖的级联生成流水线 SoloSpeech，该流水线集成了压缩、提取、重建和校正过程。SoloSpeech 特点是无说话人嵌入的目标提取器，利用来自辅助音频潜空间的条件信息，将其与混合音频的潜空间对齐，以防止不匹配。在广泛使用的 Libri2Mix 数据集上评估，SoloSpeech 在目标语音提取和语音分离任务中达到了新的最好可懂度和质量，同时在域外数据和现实场景中展示了出色的一般化能力。', 'title_zh': 'SoloSpeech：通过级联生成管道提高目标语音提取的可懂度和质量'}
{'arxiv_id': 'arXiv:2505.19310', 'title': 'Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking', 'authors': 'Robin D. Pesl, Jerin G. Mathew, Massimo Mecella, Marco Aiello', 'link': 'https://arxiv.org/abs/2505.19310', 'abstract': 'Integrating multiple (sub-)systems is essential to create advanced Information Systems. Difficulties mainly arise when integrating dynamic environments, e.g., the integration at design time of not yet existing services. This has been traditionally addressed using a registry that provides the API documentation of the endpoints. Large Language Models have shown to be capable of automatically creating system integrations (e.g., as service composition) based on this documentation but require concise input due to input oken limitations, especially regarding comprehensive API descriptions. Currently, it is unknown how best to preprocess these API descriptions. In the present work, we (i) analyze the usage of Retrieval Augmented Generation for endpoint discovery and the chunking, i.e., preprocessing, of state-of-practice OpenAPIs to reduce the input oken length while preserving the most relevant information. To further reduce the input token length for the composition prompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that only receives a summary of the most relevant endpoints nd retrieves specification details on demand. We evaluate RAG for endpoint discovery using (iii) a proposed novel service discovery benchmark SOCBench-D representing a general setting across numerous domains and the real-world RestBench enchmark, first, for the different chunking possibilities and parameters measuring the endpoint retrieval accuracy. Then, we assess the Discovery Agent using the same test data set. The prototype shows how to successfully employ RAG for endpoint discovery to reduce the token count. Our experiments show that endpoint-based approaches outperform naive chunking methods for preprocessing. Relying on an agent significantly improves precision while being prone to decrease recall, disclosing the need for further reasoning capabilities.', 'abstract_zh': '集成多个(子)系统是创建高级信息系统的关键。当在设计时间集成尚不存在的服务等动态环境时，会遇到主要困难。这通常通过注册表解决，提供端点的API文档。大型语言模型已显示出根据这些文档自动生成系统集成（例如，作为服务组合）的能力，但由于输入令牌限制，尤其是关于全面的API描述，需要简洁的输入。目前尚不清楚如何最佳地预处理这些API描述。在本项工作中，我们（i）分析检索增强生成在端点发现和分块，即预处理实践中常用的OpenAPI以减少输入令牌长度同时保留最关键信息中的应用。为进一步减少组合提示的输入令牌长度并改进端点检索，我们提出（ii）一个仅接收最相关端点概要并在需要时检索规格详细信息的发现代理。我们使用（iii）一个提出的新型服务发现基准SOCBench-D和实际中的RestBench基准评估RAG在端点发现中的应用，覆盖多个领域，首先针对不同的分块可能性和参数衡量端点检索准确性，然后使用相同的测试数据集评估发现代理。原型展示了如何成功利用RAG减少令牌数量进行端点发现。实验显示基于端点的方法优于简单的分块方法进行预处理。依赖代理在显著提高精度的同时可能导致召回率下降，表明需要进一步的推理能力。', 'title_zh': '基于检索增强生成的服务发现：分块策略与基准测试'}
{'arxiv_id': 'arXiv:2505.19301', 'title': 'A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control', 'authors': 'Ken Huang, Vineeth Sai Narajala, John Yeoh, Ramesh Raskar, Youssef Harkati, Jerry Huang, Idan Habler, Chris Hughes', 'link': 'https://arxiv.org/abs/2505.19301', 'abstract': 'Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.\nThis paper posits the imperative for a novel Agentic AI IAM framework: We deconstruct the limitations of existing protocols when applied to MAS, illustrating with concrete examples why their coarse-grained controls, single-entity focus, and lack of context-awareness falter. We then propose a comprehensive framework built upon rich, verifiable Agent Identities (IDs), leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), that encapsulate an agents capabilities, provenance, behavioral scope, and security posture.\nOur framework includes an Agent Naming Service (ANS) for secure and capability-aware discovery, dynamic fine-grained access control mechanisms, and critically, a unified global session management and policy enforcement layer for real-time control and consistent revocation across heterogeneous agent communication protocols. We also explore how Zero-Knowledge Proofs (ZKPs) enable privacy-preserving attribute disclosure and verifiable policy compliance.\nWe outline the architecture, operational lifecycle, innovative contributions, and security considerations of this new IAM paradigm, aiming to establish the foundational trust, accountability, and security necessary for the burgeoning field of agentic AI and the complex ecosystems they will inhabit.', 'abstract_zh': '传统的身份与访问管理（IAM）系统主要针对人类用户或静态机器身份，通过OAuth、OpenID Connect（OIDC）和SAML等协议设计，对于多代理系统（MAS）中大规模运行的动态、相互依赖且 Often Ephemeral 的智能代理缺乏根本性的支持。多代理系统是多个相互作用的智能代理共同工作的计算系统。\n\n本文提出了一种新的代理智能代理IAM框架的迫切需求：我们拆解现有协议在MAS中应用时的局限性，通过具体例子说明其粗粒度控制、单一实体关注点和缺乏上下文感知能力的不足。随后，我们提出了一种基于丰富可验证智能代理身份（IDs）、利用分散标识符（DIDs）和可验证凭据（VCs）的全面框架，该框架涵盖了代理的能力、来源、行为范围和安全状况。\n\n该框架包括安全且能力感知的智能代理命名服务（ANS）、动态细粒度访问控制机制，并且最关键的是，提供了一个统一的全局会话管理与策略执行层，以实现实时控制和跨异构代理通信协议的一致撤销。我们还探讨了零知识证明（ZKPs）如何实现隐私保护的属性披露和可验证策略合规性。\n\n本文概述了该新IAM范式的架构、操作生命周期、创新贡献和安全考量，旨在为蓬勃发展的代理智能AI领域及其将要栖息的复杂生态系统建立基础的信任、问责和安全。', 'title_zh': '基于代理人工智能的新型零信任身份框架：去中心化身份认证与细粒度访问控制'}
{'arxiv_id': 'arXiv:2505.19299', 'title': 'A Necessary Step toward Faithfulness: Measuring and Improving Consistency in Free-Text Explanations', 'authors': 'Lingjun Zhao, Hal Daumé III', 'link': 'https://arxiv.org/abs/2505.19299', 'abstract': 'Faithful free-text explanations are important to ensure transparency in high-stakes AI decision-making contexts, but they are challenging to generate by language models and assess by humans. In this paper, we present a measure for Prediction-EXplanation (PEX) consistency, by extending the concept of weight of evidence. This measure quantifies how much a free-text explanation supports or opposes a prediction, serving as an important aspect of explanation faithfulness. Our analysis reveals that more than 62% explanations generated by large language models lack this consistency. We show that applying direct preference optimization improves the consistency of generated explanations across three model families, with improvement ranging from 43.1% to 292.3%. Furthermore, we demonstrate that optimizing this consistency measure can improve explanation faithfulness by up to 9.7%.', 'abstract_zh': '忠实的自由文本解释对于确保高风险AI决策情境下的透明性至关重要，但它们的生成和评估对语言模型和人类来说都是具有挑战性的。本文提出了一种预测-解释（PEX）一致性的度量方法，通过扩展证据权重的概念。该度量方法量化了自由文本解释对预测的支持或反对程度，作为解释忠实性的重要方面。我们的分析表明，超过62%的由大型语言模型生成的解释缺乏这种一致性。我们显示，直接偏好优化可以提高三种模型家族生成解释的一致性，改进幅度从43.1%到292.3%不等。此外，我们证明优化此一致性度量可以提高解释忠实性高达9.7%。', 'title_zh': '走向忠诚性必要一步：测量和提升自由文本解释的一致性'}
{'arxiv_id': 'arXiv:2505.19293', 'title': '100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?', 'authors': 'Wang Yang, Hongye Jin, Shaochen Zhong, Song Jiang, Qifan Wang, Vipin Chaudhary, Xiaotian Han', 'link': 'https://arxiv.org/abs/2505.19293', 'abstract': "Long-context capability is considered one of the most important abilities of LLMs, as a truly long context-capable LLM enables users to effortlessly process many originally exhausting tasks -- e.g., digesting a long-form document to find answers vs. directly asking an LLM about it. However, existing real-task-based long-context evaluation benchmarks have two major shortcomings. First, benchmarks like LongBench often do not provide proper metrics to separate long-context performance from the model's baseline ability, making cross-model comparison unclear. Second, such benchmarks are usually constructed with fixed input lengths, which limits their applicability across different models and fails to reveal when a model begins to break down. To address these issues, we introduce a length-controllable long-context benchmark and a novel metric that disentangles baseline knowledge from true long-context capabilities. Experiments demonstrate the superiority of our approach in effectively evaluating LLMs.", 'abstract_zh': '长上下文能力是大语言模型最重要的能力之一，真正的长上下文能力使用户能够轻松处理许多原本令人疲惫的任务——例如，消化长文档以找到答案而非直接询问模型。然而，现有的基于实际任务的长上下文评估基准存在两大缺陷。首先，这些基准（如LongBench）通常未能提供适当的指标来区分长上下文性能与模型的基本能力，导致不同模型之间的比较不清晰。其次，这类基准通常使用固定长度的输入构建，这限制了它们在不同模型之间的适用性，并未能揭示模型何时开始失效。为解决这些问题，我们引入了一个可调节长度的长上下文基准和一个全新的指标，该指标能够分离基本知识和真实的长上下文能力。实验表明，我们的方法在有效评估大语言模型方面具有优越性。', 'title_zh': '100-LongBench：事实上，长上下文基准测试是否真的在评估长上下文能力？'}
{'arxiv_id': 'arXiv:2505.19291', 'title': 'TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis', 'authors': 'Kazi Mahathir Rahman, Showrin Rahman, Sharmin Sultana Srishty', 'link': 'https://arxiv.org/abs/2505.19291', 'abstract': "Text-embedded image generation plays a critical role in industries such as graphic design, advertising, and digital content creation. Text-to-Image generation methods leveraging diffusion models, such as TextDiffuser-2, have demonstrated promising results in producing images with embedded text. TextDiffuser-2 effectively generates bounding box layouts that guide the rendering of visual text, achieving high fidelity and coherence. However, existing approaches often rely on resource-intensive processes and are limited in their ability to run efficiently on both CPU and GPU platforms. To address these challenges, we propose a novel two-stage pipeline that integrates reinforcement learning (RL) for rapid and optimized text layout generation with a diffusion-based image synthesis model. Our RL-based approach significantly accelerates the bounding box prediction step while reducing overlaps, allowing the system to run efficiently on both CPUs and GPUs. Extensive evaluations demonstrate that our framework maintains or surpasses TextDiffuser-2's quality in text placement and image synthesis, with markedly faster runtime and increased flexibility. Extensive evaluations demonstrate that our framework maintains or surpasses TextDiffuser-2's quality in text placement and image synthesis, with markedly faster runtime and increased flexibility. Our approach has been evaluated on the MARIOEval benchmark, achieving OCR and CLIPScore metrics close to state-of-the-art models, while being 97.64% more faster and requiring only 2MB of memory to run.", 'abstract_zh': '文本嵌入图像生成在图形设计、广告和数字内容创造等行业中扮演着关键角色。基于扩散模型的文本到图像生成方法，如TextDiffuser-2，已在生成嵌入文本的图像方面取得了有 promise 的结果。TextDiffuser-2 有效地生成了用于指导视觉文本渲染的边界框布局，实现了高保真度和一致性。然而，现有方法通常依赖于资源密集型过程，并且在 CPU 和 GPU 平台上高效运行的能力有限。为了解决这些挑战，我们提出了一种新颖的两阶段管道，该管道将强化学习（RL）与基于扩散的图像合成模型集成，以实现快速和优化的文本布局生成。基于 RL 的方法显著加快了边界框预测步骤，减少了重叠，使系统能够在 CPU 和 GPU 上高效运行。广泛的评估表明，我们的框架在文本放置和图像合成质量上保持或超越了 TextDiffuser-2 的水平，运行速度明显更快且更具灵活性。我们的方法在 MARIOEval 基准上进行了评估，OCR 和 CLIPScore 指标接近当前最先进的模型，同时快 97.64% 并且只需要 2MB 的内存即可运行。', 'title_zh': 'TextDiffuser-RL：高效稳健的文本布局优化方法以实现高保真文本到图像合成'}
{'arxiv_id': 'arXiv:2505.19273', 'title': 'Eta-WavLM: Efficient Speaker Identity Removal in Self-Supervised Speech Representations Using a Simple Linear Equation', 'authors': 'Giuseppe Ruggiero, Matteo Testa, Jurgen Van de Walle, Luigi Di Caro', 'link': 'https://arxiv.org/abs/2505.19273', 'abstract': 'Self-supervised learning (SSL) has reduced the reliance on expensive labeling in speech technologies by learning meaningful representations from unannotated data. Since most SSL-based downstream tasks prioritize content information in speech, ideal representations should disentangle content from unwanted variations like speaker characteristics in the SSL representations. However, removing speaker information often degrades other speech components, and existing methods either fail to fully disentangle speaker identity or require resource-intensive models. In this paper, we propose a novel disentanglement method that linearly decomposes SSL representations into speaker-specific and speaker-independent components, effectively generating speaker disentangled representations. Comprehensive experiments show that our approach achieves speaker independence and as such, when applied to content-driven tasks such as voice conversion, our representations yield significant improvements over state-of-the-art methods.', 'abstract_zh': '自监督学习（SSL）通过从未标注数据中学习有意义的表示，减少了语音技术对昂贵标注的依赖。由于大多数基于SSL的下游任务优先处理语音的内容信息，理想的表示应该在SSL表示中解开内容与如说话人特征等不必要的变异。然而，去除说话人信息往往会降低其他语音组件的质量，现有方法要么无法完全解开说话人身份，要么需要资源密集型模型。在本文中，我们提出了一种新颖的解耦方法，通过线性分解SSL表示为说话人特定和说话人独立的成分，有效地生成说话人解耦表示。全面的实验表明，我们的方法实现了说话人独立性，因此在诸如声音转换等内容驱动的任务中，我们的表示方法比现有最先进的方法取得了显著的改进。', 'title_zh': 'Eta-WavLM：高效自监督语音表示中的说话人身份去除使用简单线性方程'}
{'arxiv_id': 'arXiv:2505.19263', 'title': 'Cellular Traffic Prediction via Byzantine-robust Asynchronous Federated Learning', 'authors': 'Hui Ma, Kai Yang, Yang Jiao', 'link': 'https://arxiv.org/abs/2505.19263', 'abstract': 'Network traffic prediction plays a crucial role in intelligent network operation. Traditional prediction methods often rely on centralized training, necessitating the transfer of vast amounts of traffic data to a central server. This approach can lead to latency and privacy concerns. To address these issues, federated learning integrated with differential privacy has emerged as a solution to improve data privacy and model robustness in distributed settings. Nonetheless, existing federated learning protocols are vulnerable to Byzantine attacks, which may significantly compromise model robustness. Developing a robust and privacy-preserving prediction model in the presence of Byzantine clients remains a significant challenge. To this end, we propose an asynchronous differential federated learning framework based on distributionally robust optimization. The proposed framework utilizes multiple clients to train the prediction model collaboratively with local differential privacy. In addition, regularization techniques have been employed to further improve the Byzantine robustness of the models. We have conducted extensive experiments on three real-world datasets, and the results elucidate that our proposed distributed algorithm can achieve superior performance over existing methods.', 'abstract_zh': '基于分布鲁棒优化的异步差分联邦学习预测模型', 'title_zh': 'Byzantine- robust 异步联邦学习在细胞交通预测中的应用'}
{'arxiv_id': 'arXiv:2505.19261', 'title': 'Enhancing Text-to-Image Diffusion Transformer via Split-Text Conditioning', 'authors': 'Yu Zhang, Jialei Zhou, Xinchen Li, Qi Zhang, Zhongwei Wan, Tianyu Wang, Duoqian Miao, Changwei Wang, Longbing Cao', 'link': 'https://arxiv.org/abs/2505.19261', 'abstract': 'Current text-to-image diffusion generation typically employs complete-text conditioning. Due to the intricate syntax, diffusion transformers (DiTs) inherently suffer from a comprehension defect of complete-text captions. One-fly complete-text input either overlooks critical semantic details or causes semantic confusion by simultaneously modeling diverse semantic primitive types. To mitigate this defect of DiTs, we propose a novel split-text conditioning framework named DiT-ST. This framework converts a complete-text caption into a split-text caption, a collection of simplified sentences, to explicitly express various semantic primitives and their interconnections. The split-text caption is then injected into different denoising stages of DiT-ST in a hierarchical and incremental manner. Specifically, DiT-ST leverages Large Language Models to parse captions, extracting diverse primitives and hierarchically sorting out and constructing these primitives into a split-text input. Moreover, we partition the diffusion denoising process according to its differential sensitivities to diverse semantic primitive types and determine the appropriate timesteps to incrementally inject tokens of diverse semantic primitive types into input tokens via cross-attention. In this way, DiT-ST enhances the representation learning of specific semantic primitive types across different stages. Extensive experiments validate the effectiveness of our proposed DiT-ST in mitigating the complete-text comprehension defect.', 'abstract_zh': '当前的文本到图像扩散生成通常采用完整文本条件。由于复杂的句法，扩散变压器（DiTs）固有地在完整文本描述的理解上存在缺陷。全文本输入要么忽略关键的语义细节，要么通过同时建模多种语义原始类型而导致语义混淆。为缓解DiTs的这一缺陷，我们提出了一种名为DiT-ST的新颖的分段文本条件框架。该框架将完整文本描述转换为分段文本描述，即一系列简化句子，以明确表达各种语义原始类型及其相互连接。分段文本描述随后按照层级和增量的方式注入到DiT-ST的不同去噪阶段。具体而言，DiT-ST利用大型语言模型解析描述，提取多种原始类型并逐级整理和构建这些原始类型以形成分段文本输入。此外，我们根据其对不同语义原始类型的敏感性差异来划分扩散去噪过程，并确定合适的时刻通过交叉注意力逐步注入不同语义原始类型的标记到输入标记中，从而在不同阶段增强特定语义原始类型的表示学习。广泛实验验证了我们提出的DiT-ST在缓解完整文本理解缺陷方面的有效性。', 'title_zh': '通过分割文本条件增强文本到图像diffusion变换器'}
{'arxiv_id': 'arXiv:2505.19259', 'title': 'Towards Large Reasoning Models for Agriculture', 'authors': 'Hossein Zaremehrjerdi, Shreyan Ganguly, Ashlyn Rairdin, Elizabeth Tranel, Benjamin Feuer, Juan Ignacio Di Salvo, Srikanth Panthulugiri, Victoria Moser, Sarah Jones, Joscif G Raigne, Yanben Shen, Heidi M. Dornath, Aditya Balu, Adarsh Krishnamurthy, Asheesh K Singh, Arti Singh, Baskar Ganapathysubramanian, Chinmay Hegde, Soumik Sarkar', 'link': 'https://arxiv.org/abs/2505.19259', 'abstract': 'Agricultural decision-making involves complex, context-specific reasoning, where choices about crops, practices, and interventions depend heavily on geographic, climatic, and economic conditions. Traditional large language models (LLMs) often fall short in navigating this nuanced problem due to limited reasoning capacity. We hypothesize that recent advances in large reasoning models (LRMs) can better handle such structured, domain-specific inference. To investigate this, we introduce AgReason, the first expert-curated open-ended science benchmark with 100 questions for agricultural reasoning. Evaluations across thirteen open-source and proprietary models reveal that LRMs outperform conventional ones, though notable challenges persist, with the strongest Gemini-based baseline achieving 36% accuracy. We also present AgThoughts, a large-scale dataset of 44.6K question-answer pairs generated with human oversight and equipped with synthetically generated reasoning traces. Using AgThoughts, we develop AgThinker, a suite of small reasoning models that can be run on consumer-grade GPUs, and show that our dataset can be effective in unlocking agricultural reasoning abilities in LLMs. Our project page is here: this https URL', 'abstract_zh': '农业决策涉及复杂的、情境特定的推理，其中关于作物、实践和干预的选择高度依赖于地理、气候和经济条件。传统的大型语言模型（LLMs）往往由于推理能力有限而在处理这一细腻的问题上表现出色。我们假设最近在大型推理模型（LRMs）方面的进展能够更好地处理这种结构化、领域特定的推理。为了调查这一点，我们引入了AgReason，这是第一个由专家编纂的开放性科学基准，包含100个农业推理问题。在十三个开源和专有模型的评估中，LRMs的表现优于传统的模型，尽管存在显著的挑战，其中基于Gemini的最强基线达到了36%的准确性。我们还介绍了AgThoughts，这是一个包含44,600个带有人工监督生成的推理痕迹的问题-答案对的大规模数据集。使用AgThoughts，我们开发了AgThinker，这是一个可以在消费者级GPU上运行的小型推理模型套件，并展示了我们的数据集在释放LLMs的农业推理能力方面的有效性。项目页面在此：this https URL', 'title_zh': '面向农业的大规模推理模型研究'}
{'arxiv_id': 'arXiv:2505.19255', 'title': 'VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use', 'authors': 'Mingyuan Wu, Jingcheng Yang, Jize Jiang, Meitang Li, Kaizhuo Yan, Hanchao Yu, Minjia Zhang, Chengxiang Zhai, Klara Nahrstedt', 'link': 'https://arxiv.org/abs/2505.19255', 'abstract': 'Reinforcement Learning Finetuning (RFT) has significantly advanced the reasoning capabilities of large language models (LLMs) by enabling long chains of thought, self-correction, and effective tool use. While recent works attempt to extend RFT to vision-language models (VLMs), these efforts largely produce text-only reasoning conditioned on static image inputs, falling short of true multimodal reasoning in the response. In contrast, test-time methods like Visual Sketchpad incorporate visual steps but lack training mechanisms.\nWe introduce VTool-R1, the first framework that trains VLMs to generate multimodal chains of thought by interleaving text and intermediate visual reasoning steps. VTool-R1 integrates Python-based visual editing tools into the RFT process, enabling VLMs to learn when and how to generate visual reasoning steps that benefit final reasoning. Trained with outcome-based rewards tied to task accuracy, our approach elicits strategic visual tool use for reasoning without relying on process-based supervision. Experiments on structured visual question answering over charts and tables show that VTool-R1 enhances reasoning performance by teaching VLMs to "think with images" and generate multimodal chain of thoughts with tools.', 'abstract_zh': '基于强化学习微调的多模态链式推理框架VTool-R1', 'title_zh': 'VTool-R1: 多模态工具使用via 强化学习的VLMs图像思维学习'}
{'arxiv_id': 'arXiv:2505.19252', 'title': 'Learning-Augmented Online Bipartite Fractional Matching', 'authors': 'Davin Choo, Billy Jin, Yongho Shin', 'link': 'https://arxiv.org/abs/2505.19252', 'abstract': 'Online bipartite matching is a fundamental problem in online optimization, extensively studied both in its integral and fractional forms due to its theoretical significance and practical applications, such as online advertising and resource allocation. Motivated by recent progress in learning-augmented algorithms, we study online bipartite fractional matching when the algorithm is given advice in the form of a suggested matching in each iteration. We develop algorithms for both the vertex-weighted and unweighted variants that provably dominate the naive "coin flip" strategy of randomly choosing between the advice-following and advice-free algorithms. Moreover, our algorithm for the vertex-weighted setting extends to the AdWords problem under the small bids assumption, yielding a significant improvement over the seminal work of Mahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our positive results, we establish a hardness bound on the robustness-consistency tradeoff that is attainable by any algorithm. We empirically validate our algorithms through experiments on synthetic and real-world data.', 'abstract_zh': '在线 bipartite 匹配是在线优化中的一个基础问题，由于其理论意义和实际应用价值，如在线广告和资源分配，该问题在整数形式和分数形式下均得到了广泛研究。受学习增强算法近期进展的启发，我们研究了在线 bipartite 分数匹配问题，其中算法在每一轮获得建议匹配作为建议。我们开发了适用于顶点加权和无权重两种变体的算法，并可证明这些算法在随机选择遵循建议和不遵循建议的算法之间占优。此外，顶点加权设置下的算法可以推广到小出价情形下的 AdWords 问题，显著改进了 Mahdian、Nazerzadeh 和 Saberi 的开创性工作（EC 2007, TALG 2012）。作为正面结果的补充，我们确立了任何一个算法都能够达到的鲁棒性-一致性折中上的下界。我们通过合成数据和实际数据的实验验证了所提出的算法。', 'title_zh': '学习增强的在线二分部分匹配'}
{'arxiv_id': 'arXiv:2505.19247', 'title': 'Improving Value Estimation Critically Enhances Vanilla Policy Gradient', 'authors': 'Tao Wang, Ruipeng Zhang, Sicun Gao', 'link': 'https://arxiv.org/abs/2505.19247', 'abstract': 'Modern policy gradient algorithms, such as TRPO and PPO, outperform vanilla policy gradient in many RL tasks. Questioning the common belief that enforcing approximate trust regions leads to steady policy improvement in practice, we show that the more critical factor is the enhanced value estimation accuracy from more value update steps in each iteration. To demonstrate, we show that by simply increasing the number of value update steps per iteration, vanilla policy gradient itself can achieve performance comparable to or better than PPO in all the standard continuous control benchmark environments. Importantly, this simple change to vanilla policy gradient is significantly more robust to hyperparameter choices, opening up the possibility that RL algorithms may still become more effective and easier to use.', 'abstract_zh': '现代的策略梯度算法（如TRPO和PPO）在许多RL任务中优于vanilla策略梯度。我们质疑常规信念，即施加近似信任区域会实际促进策略的稳定改进，而表明更为关键的因素是从每个迭代中增加价值估计的精度。为证明这一点，我们显示仅通过增加每个迭代中的价值更新步数，vanilla策略梯度本身就能在所有标准连续控制基准环境中达到与PPO相当或更优的性能。重要的是，这一简单的改变使vanilla策略梯度在超参数选择上表现出更多的稳健性，为RL算法仍可能变得更加有效和易于使用提供了可能性。', 'title_zh': '显著提升价值估计能大幅增强 Vanilla 策略梯度算法。'}
{'arxiv_id': 'arXiv:2505.19245', 'title': 'To CoT or To Loop? A Formal Comparison Between Chain-of-Thought and Looped Transformers', 'authors': 'Kevin Xu, Issei Sato', 'link': 'https://arxiv.org/abs/2505.19245', 'abstract': 'Chain-of-Thought (CoT) and Looped Transformers have been shown to empirically improve performance on reasoning tasks and to theoretically enhance expressivity by recursively increasing the number of computational steps. However, their comparative capabilities are still not well understood. In this paper, we provide a formal analysis of their respective strengths and limitations. We show that Looped Transformers can efficiently simulate parallel computations for deterministic tasks, which we formalize as evaluation over directed acyclic graphs. In contrast, CoT with stochastic decoding excels at approximate inference for compositional structures, namely self-reducible problems. These separations suggest the tasks for which depth-driven recursion is more suitable, thereby offering practical cues for choosing between reasoning paradigms.', 'abstract_zh': 'Chain-of-Thought和环状变压器在推理任务中的比较分析及其表达能力的研究', 'title_zh': '是采用Chain-of-Thought还是Looped Transformers？一种形式化比较'}
{'arxiv_id': 'arXiv:2505.19241', 'title': 'ActiveDPO: Active Direct Preference Optimization for Sample-Efficient Alignment', 'authors': 'Xiaoqiang Lin, Arun Verma, Zhongxiang Dai, Daniela Rus, See-Kiong Ng, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2505.19241', 'abstract': 'The recent success of using human preferences to align large language models (LLMs) has significantly improved their performance in various downstream tasks like question answering, mathematical reasoning, and code generation. However,3 achieving effective LLM alignment depends on high-quality human preference datasets. Collecting these datasets requires human preference annotation, which is costly and resource-intensive, necessitating efficient active data selection methods. Existing methods either lack a strong theoretical foundation or depend on restrictive reward function assumptions (e.g., linearity). To this end, we propose an algorithm, ActiveDPO, that uses a theoretically grounded data selection criterion for non-linear reward functions while directly leveraging the LLM itself to parameterize the reward model that is used for active data selection. As a result, ActiveDPO explicitly accounts for the influence of LLM on data selection, unlike methods that select the data without considering the LLM that is being aligned, thereby leading to more effective and efficient data collection. Extensive experiments show that ActiveDPO outperforms existing methods across various models and datasets.', 'abstract_zh': '近期利用人类偏好对大规模语言模型进行对齐的成功显著提升了其在诸如问答、数学推理和代码生成等下游任务中的表现。然而，实现有效的大型语言模型对齐依赖于高质量的人类偏好数据集。收集这些数据集需要进行人类偏好注释，这是一项成本高且资源密集的工作，因此需要高效的主动数据选择方法。现有方法要么缺乏坚实的理论基础，要么依赖于限制性的奖励函数假设（例如线性）。为此，我们提出了一种名为ActiveDPO的算法，该算法使用理论上支持的数据选择标准来处理非线性奖励函数，并直接利用大规模语言模型本身来参数化用于主动数据选择的奖励模型。结果，ActiveDPO明确考虑了大规模语言模型对数据选择的影响，而传统方法在选择数据时并未考虑正在对其对齐的大型语言模型，从而导致更有效的数据收集。广泛的实验表明，ActiveDPO在各种模型和数据集上优于现有方法。', 'title_zh': '主动型直接偏好优化：基于样本高效对齐的主动偏好优化方法'}
{'arxiv_id': 'arXiv:2505.19240', 'title': 'LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models', 'authors': 'Aida Kostikova, Zhipin Wang, Deidamea Bajri, Ole Pütz, Benjamin Paaßen, Steffen Eger', 'link': 'https://arxiv.org/abs/2505.19240', 'abstract': 'Large language model (LLM) research has grown rapidly, along with increasing concern about their limitations such as failures in reasoning, hallucinations, and limited multilingual capability. In this survey, we conduct a data-driven, semi-automated review of research on limitations of LLM (LLLMs) from 2022 to 2024 using a bottom-up approach. From a corpus of 250,000 ACL and arXiv papers, we identify 14,648 relevant papers using keyword filtering, LLM-based classification, validated against expert labels, and topic clustering (via two approaches, HDBSCAN+BERTopic and LlooM). We find that LLM-related research increases over fivefold in ACL and fourfold in arXiv. Since 2022, LLLMs research grows even faster, reaching over 30% of LLM papers by late 2024. Reasoning remains the most studied limitation, followed by generalization, hallucination, bias, and security. The distribution of topics in the ACL dataset stays relatively stable over time, while arXiv shifts toward safety and controllability (with topics like security risks, alignment, hallucinations, knowledge editing), and multimodality between 2022 and 2024. We release a dataset of annotated abstracts and a validated methodology, and offer a quantitative view of trends in LLM limitations research.', 'abstract_zh': '大规模语言模型（LLM）研究取得了rapid进展，同时对其局限性的关注也不断增加，如推理失败、幻觉以及多语言能力有限等问题。在本文综述中，我们采用自下而上的数据驱动方法，对2022年至2024年的LLM局限性研究（LLLMs）进行了半自动化回顾。从含有250,000篇ACL和arXiv论文的语料库中，我们通过关键词过滤、基于LLM的分类并经专家标签验证后，再结合主题聚类（通过HDBSCAN+BERTopic和LlooM两种方法），识别出14,648篇相关论文。我们发现，2022年至2024年间，ACL和arXiv上的相关研究分别增加了五倍和四倍。自2022年以来，LLLMs的研究增长更为快速，到2024年底已占LLM论文的30%以上。推理被证明是最主要研究的局限性，其次是泛化能力、幻觉、偏见和安全性。ACL数据集中主题的分布随着时间相对稳定，而arXiv则逐渐转向安全性和可控性（涵盖安全风险、对齐、幻觉和知识编辑），以及多模态性（2022年至2024年）。我们发布了标注摘要数据集和经过验证的方法论，并提供了LLM局限性研究趋势的定量视角。', 'title_zh': 'LLM研究中的数据驱动型大型语言模型限制演进综述'}
{'arxiv_id': 'arXiv:2505.19238', 'title': 'Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees', 'authors': 'Sourav Ganguly, Arnob Ghosh, Kishan Panaganti, Adam Wierman', 'link': 'https://arxiv.org/abs/2505.19238', 'abstract': 'Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.', 'abstract_zh': '约束条件下的决策对于设计实际控制系统的安全策略是至关重要的，但模拟环境往往无法捕捉到实际的 adversities。我们考虑在现实模型与可访问的模拟器/名义模型之间存在不匹配时，学习一个既能最大化累积奖励又能满足约束的策略的问题。特别是，我们关注在不确定集中心于未知名义模型的最坏可能随机模型下，代理最大化奖励并满足约束的鲁棒约束马尔可夫决策问题（RCMDP）。由于缺乏强对偶性，标准约束马尔可夫决策过程（CMDP）中的对偶方法不适用。此外，标准的鲁棒值迭代方法也不适用于复合价值函数，因为最坏情况模型可能对奖励价值函数和约束价值函数不同。我们提出了一种新的技术，该技术有效地最小化约束价值函数以满足约束；当所有约束都满足时，它可以简单地最大化鲁棒奖励价值函数。我们证明这样的算法在至多 $O(\\epsilon^{-2})$ 次迭代后，能找到一个最多 $\\epsilon$ 非最优性和可行的策略。与最先进的方法相比，我们不需要使用二分搜索，因此在折现因子 $\\gamma$ 较小时至少能减少四倍的计算时间，在 $\\gamma$ 较大时至少能减少六倍的计算时间。', 'title_zh': '具有迭代复杂度保证的稳健约束MDP中的高效策略优化'}
{'arxiv_id': 'arXiv:2505.19233', 'title': 'RAISE: Realness Assessment for Image Synthesis and Evaluation', 'authors': 'Aniruddha Mukherjee, Spriha Dubey, Somdyuti Paul', 'link': 'https://arxiv.org/abs/2505.19233', 'abstract': 'The rapid advancement of generative AI has enabled the creation of highly photorealistic visual content, offering practical substitutes for real images and videos in scenarios where acquiring real data is difficult or expensive. However, reliably substituting real visual content with AI-generated counterparts requires robust assessment of the perceived realness of AI-generated visual content, a challenging task due to its inherent subjective nature. To address this, we conducted a comprehensive human study evaluating the perceptual realness of both real and AI-generated images, resulting in a new dataset, containing images paired with subjective realness scores, introduced as RAISE in this paper. Further, we develop and train multiple models on RAISE to establish baselines for realness prediction. Our experimental results demonstrate that features derived from deep foundation vision models can effectively capture the subjective realness. RAISE thus provides a valuable resource for developing robust, objective models of perceptual realness assessment.', 'abstract_zh': '生成式人工智能的迅速发展使得创建高度逼真的视觉内容成为可能，为在获取真实数据困难或昂贵的情况下提供了实用替代品。然而，可靠地用人工智能生成的内容替代真实视觉内容需要对人工智能生成的视觉内容的感知真实度进行 robust 评估，这是一个由于其固有的主观性而具有挑战性的任务。为了解决这一问题，我们进行了一项全面的人类研究，评估了真实和人工智能生成图像的感知真实度，从而产生了包含配有序观真实度分数的图像的新数据集，该数据集在本文中被命名为RAISE。进一步地，我们在RAISE上开发和训练了多个模型以建立真实度预测的基线。实验结果表明，源自深度视觉基础模型的特征能够有效地捕捉主观真实度。因此，RAISE为开发 robust 和客观的感知真实度评估模型提供了宝贵的资源。', 'title_zh': 'RAISE: 图像合成与评估的逼真度评估'}
{'arxiv_id': 'arXiv:2505.19212', 'title': 'When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas', 'authors': 'Steffen Backmann, David Guzman Piedrahita, Emanuel Tewolde, Rada Mihalcea, Bernhard Schölkopf, Zhijing Jin', 'link': 'https://arxiv.org/abs/2505.19212', 'abstract': 'Recent advances in large language models (LLMs) have enabled their use in complex agentic roles, involving decision-making with humans or other agents, making ethical alignment a key AI safety concern. While prior work has examined both LLMs\' moral judgment and strategic behavior in social dilemmas, there is limited understanding of how they act when moral imperatives directly conflict with rewards or incentives. To investigate this, we introduce Moral Behavior in Social Dilemma Simulation (MoralSim) and evaluate how LLMs behave in the prisoner\'s dilemma and public goods game with morally charged contexts. In MoralSim, we test a range of frontier models across both game structures and three distinct moral framings, enabling a systematic examination of how LLMs navigate social dilemmas in which ethical norms conflict with payoff-maximizing strategies. Our results show substantial variation across models in both their general tendency to act morally and the consistency of their behavior across game types, the specific moral framing, and situational factors such as opponent behavior and survival risks. Crucially, no model exhibits consistently moral behavior in MoralSim, highlighting the need for caution when deploying LLMs in agentic roles where the agent\'s "self-interest" may conflict with ethical expectations. Our code is available at this https URL.', 'abstract_zh': '近期大规模语言模型的进步使其能够在涉及人类或其他代理体决策的复杂代理角色中使用，这使得道德对齐成为关键的AI安全问题。虽然先前的研究已经探讨了大规模语言模型在社会困境中的道德判断和战略行为，但对当道德 imperative 直接与奖励或激励冲突时它们的行为了解有限。为了探究这一问题，我们引入了社会困境模拟中的道德行为（MoralSim）并评估了大规模语言模型在囚徒困境和公共产品游戏中带有道德色彩背景下的行为。在 MoralSim 中，我们测试了一系列前沿模型在不同游戏结构和三种不同的道德框架下的表现，从而系统地探讨了大规模语言模型在道德规范与收益最大化策略冲突的社会困境中如何应对。我们的结果显示，不同模型在普遍倾向于道德行为方面的差异以及在其行为的一致性方面存在显著变化，这些变化取决于游戏类型、具体的道德框架以及对手行为和生存风险等情境因素。重要的是，在 MoralSim 中没有一个模型表现出一致的道德行为，这突显了在代理体的角色中部署大规模语言模型时需要谨慎，特别是在代理体的“自身利益”可能与伦理期望冲突的情况下。我们的代码可在以下链接获取：this https URL。', 'title_zh': '当伦理与收益背离：大语言模型代理在道德困境中的表现'}
{'arxiv_id': 'arXiv:2505.19209', 'title': 'MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search', 'authors': 'Zonglin Yang, Wanhao Liu, Ben Gao, Yujie Liu, Wei Li, Tong Xie, Lidong Bing, Wanli Ouyang, Erik Cambria, Dongzhan Zhou', 'link': 'https://arxiv.org/abs/2505.19209', 'abstract': "Large language models (LLMs) have shown promise in automating scientific hypothesis generation, yet existing approaches primarily yield coarse-grained hypotheses lacking critical methodological and experimental details. We introduce and formally define the novel task of fine-grained scientific hypothesis discovery, which entails generating detailed, experimentally actionable hypotheses from coarse initial research directions. We frame this as a combinatorial optimization problem and investigate the upper limits of LLMs' capacity to solve it when maximally leveraged. Specifically, we explore four foundational questions: (1) how to best harness an LLM's internal heuristics to formulate the fine-grained hypothesis it itself would judge as the most promising among all the possible hypotheses it might generate, based on its own internal scoring-thus defining a latent reward landscape over the hypothesis space; (2) whether such LLM-judged better hypotheses exhibit stronger alignment with ground-truth hypotheses; (3) whether shaping the reward landscape using an ensemble of diverse LLMs of similar capacity yields better outcomes than defining it with repeated instances of the strongest LLM among them; and (4) whether an ensemble of identical LLMs provides a more reliable reward landscape than a single LLM. To address these questions, we propose a hierarchical search method that incrementally proposes and integrates details into the hypothesis, progressing from general concepts to specific experimental configurations. We show that this hierarchical process smooths the reward landscape and enables more effective optimization. Empirical evaluations on a new benchmark of expert-annotated fine-grained hypotheses from recent chemistry literature show that our method consistently outperforms strong baselines.", 'abstract_zh': '大型语言模型（LLMs）在自动化科学假设生成方面展现了潜力，但现有方法主要生成粗粒度的假设，缺乏关键的方法学和实验细节。我们引入并正式定义了细粒度科学假设发现这一新任务，该任务旨在从粗粒度的研究方向中生成详细且可实验验证的假设。我们将此视为一个组合优化问题，并探讨了在最大限度利用LLM能力时解决该问题的上限。具体来说，我们探讨了四个基础问题：（1）如何最好地利用LLM内部启发式规则，以便基于其内部评分机制生成它认为在所有可能生成的假设中最有前景的细粒度假设，从而定义假设空间上的潜在奖励景观；（2）LLM认为更好的假设是否更与真实假设一致；（3）使用一组具有类似能力的多样化LLM来塑造奖励景观是否比仅使用它们中最强大的LLM进行多次定义能获得更好的结果；（4）一组相同的LLM是否能比单一的LLM提供更可靠的奖励景观。为了回答这些问题，我们提出了一种层次搜索方法，该方法逐步提出并整合假设的细节，从一般概念逐步过渡到具体的实验配置。我们表明，这种层次过程可以平滑奖励景观并促进更有效的优化。在基于近期化学文献中专家标注的细粒度假设的新基准上的实证评估显示，我们的方法始终优于强大的基线方法。', 'title_zh': 'MOOSE-Chem2：通过层次搜索探索细粒度科学假设发现的大语言模型极限'}
{'arxiv_id': 'arXiv:2505.19205', 'title': 'OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization', 'authors': 'Meher Bhaskar Madiraju, Meher Sai Preetam Madiraju', 'link': 'https://arxiv.org/abs/2505.19205', 'abstract': "Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.", 'abstract_zh': '基于多智能体的超参数优化：OptiMindTune', 'title_zh': 'OptiMindTune：一种智能超参数优化的多代理框架'}
{'arxiv_id': 'arXiv:2505.19203', 'title': 'EnvSDD: Benchmarking Environmental Sound Deepfake Detection', 'authors': 'Han Yin, Yang Xiao, Rohan Kumar Das, Jisheng Bai, Haohe Liu, Wenwu Wang, Mark D Plumbley', 'link': 'https://arxiv.org/abs/2505.19203', 'abstract': 'Audio generation systems now create very realistic soundscapes that can enhance media production, but also pose potential risks. Several studies have examined deepfakes in speech or singing voice. However, environmental sounds have different characteristics, which may make methods for detecting speech and singing deepfakes less effective for real-world sounds. In addition, existing datasets for environmental sound deepfake detection are limited in scale and audio types. To address this gap, we introduce EnvSDD, the first large-scale curated dataset designed for this task, consisting of 45.25 hours of real and 316.74 hours of fake audio. The test set includes diverse conditions to evaluate the generalizability, such as unseen generation models and unseen datasets. We also propose an audio deepfake detection system, based on a pre-trained audio foundation model. Results on EnvSDD show that our proposed system outperforms the state-of-the-art systems from speech and singing domains.', 'abstract_zh': '现有的音频生成系统能够生成非常逼真的声景，从而增强媒体制作，但也带来了潜在的风险。尽管已有研究探讨了语音和唱歌声音的深度伪造，但环境声音具有不同的特点，可能使得检测语音和唱歌深度伪造的方法在真实世界的声音中效果不佳。此外，现有的环境声音深度伪造检测数据集在规模和音频类型上都较为有限。为填补这一空白，我们介绍了EnvSDD，这是首个为这一任务设计的大规模精选数据集，包含了45.25小时的真实音频和316.74小时的伪造音频。测试集包括多种条件以评估系统的泛化能力，如未见过的生成模型和未见过的数据集。我们还提出了一种基于预训练音频基础模型的音频深度伪造检测系统。EnvSDD上的实验结果表明，我们提出的系统在语音和唱歌领域优于最先进的系统。', 'title_zh': 'EnvSDD: 评估环境声音深度伪造检测'}
{'arxiv_id': 'arXiv:2505.19194', 'title': 'Curvature Dynamic Black-box Attack: revisiting adversarial robustness via dynamic curvature estimation', 'authors': 'Peiran Sun', 'link': 'https://arxiv.org/abs/2505.19194', 'abstract': 'Adversarial attack reveals the vulnerability of deep learning models. For about a decade, countless attack and defense methods have been proposed, leading to robustified classifiers and better understanding of models. Among these methods, curvature-based approaches have attracted attention because it is assumed that high curvature may give rise to rough decision boundary. However, the most commonly used \\textit{curvature} is the curvature of loss function, scores or other parameters from within the model as opposed to decision boundary curvature, since the former can be relatively easily formed using second order derivative. In this paper, we propose a new query-efficient method, dynamic curvature estimation(DCE), to estimate the decision boundary curvature in a black-box setting. Our approach is based on CGBA, a black-box adversarial attack. By performing DCE on a wide range of classifiers, we discovered, statistically, a connection between decision boundary curvature and adversarial robustness. We also propose a new attack method, curvature dynamic black-box attack(CDBA) with improved performance using the dynamically estimated curvature.', 'abstract_zh': '基于曲率的对抗攻击揭示深度学习模型的脆弱性：一种在黑盒设置下查询高效决策边界曲率的动态估计方法及其应用', 'title_zh': '动态曲率黑盒攻击：通过动态曲率估计重新审视 adversarial 稳健性'}
{'arxiv_id': 'arXiv:2505.19190', 'title': 'I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts', 'authors': 'Jiayi Xin, Sukwon Yun, Jie Peng, Inyoung Choi, Jenna L. Ballard, Tianlong Chen, Qi Long', 'link': 'https://arxiv.org/abs/2505.19190', 'abstract': 'Modality fusion is a cornerstone of multimodal learning, enabling information integration from diverse data sources. However, vanilla fusion methods are limited by (1) inability to account for heterogeneous interactions between modalities and (2) lack of interpretability in uncovering the multimodal interactions inherent in the data. To this end, we propose I2MoE (Interpretable Multimodal Interaction-aware Mixture of Experts), an end-to-end MoE framework designed to enhance modality fusion by explicitly modeling diverse multimodal interactions, as well as providing interpretation on a local and global level. First, I2MoE utilizes different interaction experts with weakly supervised interaction losses to learn multimodal interactions in a data-driven way. Second, I2MoE deploys a reweighting model that assigns importance scores for the output of each interaction expert, which offers sample-level and dataset-level interpretation. Extensive evaluation of medical and general multimodal datasets shows that I2MoE is flexible enough to be combined with different fusion techniques, consistently improves task performance, and provides interpretation across various real-world scenarios. Code is available at this https URL.', 'abstract_zh': '可解释的多模态交互感知混合专家模型（I2MoE）：一种增强多模态融合的方法', 'title_zh': 'I2MoE: 可解释的多模态交互aware混合专家模型'}
{'arxiv_id': 'arXiv:2505.19187', 'title': 'LIMOPro: Reasoning Refinement for Efficient and Effective Test-time Scaling', 'authors': 'Yang Xiao, Jiashuo Wang, Ruifeng Yuan, Chunpu Xu, Kaishuai Xu, Wenjie Li, Pengfei Liu', 'link': 'https://arxiv.org/abs/2505.19187', 'abstract': 'Large language models (LLMs) have demonstrated remarkable reasoning capabilities through test-time scaling approaches, particularly when fine-tuned with chain-of-thought (CoT) data distilled from more powerful large reasoning models (LRMs). However, these reasoning chains often contain verbose elements that mirror human problem-solving, categorized as progressive reasoning (the essential solution development path) and functional elements (verification processes, alternative solution approaches, and error corrections). While progressive reasoning is crucial, the functional elements significantly increase computational demands during test-time inference. We introduce PIR (Perplexity-based Importance Refinement), a principled framework that quantitatively evaluates the importance of each reasoning step based on its impact on answer prediction confidence. PIR systematically identifies and selectively prunes only low-importance functional steps while preserving progressive reasoning components, creating optimized training data that maintains the integrity of the core solution path while reducing verbosity. Models fine-tuned on PIR-optimized data exhibit superior test-time scaling properties, generating more concise reasoning chains while achieving improved accuracy (+0.9\\% to +6.6\\%) with significantly reduced token usage (-3\\% to -41\\%) across challenging reasoning benchmarks (AIME, AMC, and GPQA Diamond). Our approach demonstrates strong generalizability across different model sizes, data sources, and token budgets, offering a practical solution for deploying reasoning-capable LLMs in scenarios where efficient test-time scaling, response time, and computational efficiency are valuable constraints.', 'abstract_zh': '大型语言模型（LLMs）通过测试时扩展方法展示了非凡的推理能力，特别是在使用来自更强大的大型推理模型（LRMs）的链式思考（CoT）数据进行微调后。然而，这些推理链常常包含冗长的元素，这些元素反映了人类的问题解决过程，被划分为渐进推理（核心解决方案的发展路径）和功能性元素（验证过程、替代解决方案方法和错误修正）。尽管渐进推理至关重要，但功能性元素在测试时推理过程中显著增加了计算需求。我们引入了PIR（困惑度为基础的重要性和精简）框架，这是一种原则性的框架，基于其对答案预测置信度的影响定量评估每个推理步骤的重要性。PIR系统地识别并选择性地修剪只有低重要性的功能性步骤，同时保留渐进推理组件，从而创建优化的训练数据，保持核心解决方案路径的完整性，同时减少冗长。在PIR优化数据上微调的模型表现出优越的测试时扩展性能，在具有挑战性的推理基准（AIME、AMC和GPQA钻石）上生成更简洁的推理链，同时在显著减少令牌使用量（-3%至-41%）的情况下，准确率提高（+0.9%至+6.6%）。我们的方法在不同模型规模、数据源和令牌预算方面展示了强大的适用性，为在高效测试时扩展、响应时间和计算效率是重要约束条件的场景中部署具有推理能力的LLMs提供了实用的解决方案。', 'title_zh': 'LIMOPro: 有效且高效的测试时缩放推理 refinement'}
{'arxiv_id': 'arXiv:2505.19186', 'title': 'PosePilot: An Edge-AI Solution for Posture Correction in Physical Exercises', 'authors': 'Rushiraj Gadhvi, Priyansh Desai, Siddharth', 'link': 'https://arxiv.org/abs/2505.19186', 'abstract': "Automated pose correction remains a significant challenge in AI-driven fitness systems, despite extensive research in activity recognition. This work presents PosePilot, a novel system that integrates pose recognition with real-time personalized corrective feedback, overcoming the limitations of traditional fitness solutions. Using Yoga, a discipline requiring precise spatio-temporal alignment as a case study, we demonstrate PosePilot's ability to analyze complex physical movements. Designed for deployment on edge devices, PosePilot can be extended to various at-home and outdoor exercises. We employ a Vanilla LSTM, allowing the system to capture temporal dependencies for pose recognition. Additionally, a BiLSTM with multi-head Attention enhances the model's ability to process motion contexts, selectively focusing on key limb angles for accurate error detection while maintaining computational efficiency. As part of this work, we introduce a high-quality video dataset used for evaluating our models. Most importantly, PosePilot provides instant corrective feedback at every stage of a movement, ensuring precise posture adjustments throughout the exercise routine. The proposed approach 1) performs automatic human posture recognition, 2) provides personalized posture correction feedback at each instant which is crucial in Yoga, and 3) offers a lightweight and robust posture correction model feasible for deploying on edge devices in real-world environments.", 'abstract_zh': '基于AI驱动的健身系统中的人体姿态自动校正仍是一个重要的挑战，尽管在活动识别方面进行了大量的研究。本文提出了PosePilot，这是一种将姿态识别与实时个性化纠正反馈集成的新系统，克服了传统健身解决方案的局限性。以要求精确时空对齐的瑜伽为例，我们展示了PosePilot分析复杂身体运动的能力。该系统设计用于边缘设备部署，可以扩展到各种家庭和户外锻炼。我们采用Vanilla LSTM来捕捉姿态识别的时间依赖性。此外，采用双向LSTM与多头注意力机制增强模型处理运动上下文的能力，选择性地聚焦于关键肢体角度进行准确的错误检测，同时保持计算效率。作为该工作的组成部分，我们引入了一个高质量的视频数据集，用于评估我们的模型。最重要的是，PosePilot在每一次运动阶段都提供即时的纠正反馈，确保整个锻炼过程中精确的姿势调整。所提出的方案包括1）自动人体姿态识别，2）在每一个瞬间提供个性化的姿态纠正反馈，这对于瑜伽至关重要，3）提供一种轻量级且鲁棒的姿态纠正模型，适用于在现实环境中部署到边缘设备上。', 'title_zh': 'PosePilot：一种用于物理锻炼姿势矫正的边缘AI解决方案'}
{'arxiv_id': 'arXiv:2505.19184', 'title': "Two LLMs debate, both are certain they've won", 'authors': 'Minh Nhat Nguyen, Pradyumna Shyama Prasad', 'link': 'https://arxiv.org/abs/2505.19184', 'abstract': "Can LLMs accurately adjust their confidence when facing opposition? Building on previous studies measuring calibration on static fact-based question-answering tasks, we evaluate Large Language Models (LLMs) in a dynamic, adversarial debate setting, uniquely combining two realistic factors: (a) a multi-turn format requiring models to update beliefs as new information emerges, and (b) a zero-sum structure to control for task-related uncertainty, since mutual high-confidence claims imply systematic overconfidence. We organized 60 three-round policy debates among ten state-of-the-art LLMs, with models privately rating their confidence (0-100) in winning after each round. We observed five concerning patterns: (1) Systematic overconfidence: models began debates with average initial confidence of 72.9% vs. a rational 50% baseline. (2) Confidence escalation: rather than reducing confidence as debates progressed, debaters increased their win probabilities, averaging 83% by the final round. (3) Mutual overestimation: in 61.7% of debates, both sides simultaneously claimed >=75% probability of victory, a logical impossibility. (4) Persistent self-debate bias: models debating identical copies increased confidence from 64.1% to 75.2%; even when explicitly informed their chance of winning was exactly 50%, confidence still rose (from 50.0% to 57.1%). (5) Misaligned private reasoning: models' private scratchpad thoughts sometimes differed from their public confidence ratings, raising concerns about faithfulness of chain-of-thought reasoning. These results suggest LLMs lack the ability to accurately self-assess or update their beliefs in dynamic, multi-turn tasks; a major concern as LLM outputs are deployed without careful review in assistant roles or agentic settings.", 'abstract_zh': '大型语言模型在面对反对时能否准确调整其信心？在静态事实性问答任务的基础上，我们评估了大型语言模型（LLMs）在动态的 adversarial 辩论设置中的表现，独特地结合了两个现实因素：（a）多轮格式要求模型在新信息出现时更新信念，（b）零和结构以控制与任务相关的不确定性，因为互相信任的高信心声明意味着系统性高估信心。我们组织了十种最先进的 LLMs 进行六轮政策辩论，模型在每一轮后私下对其获胜的信心（0-100）进行评分。我们观察到了五个令人担忧的模式：（1）系统性高估信心：模型在辩论中的平均初始信心为 72.9%，而合理的baseline是 50%。 （2）信心升级：随着辩论的进行，辩论者增加了其获胜概率，最终平均为 83%。 （3）相互高估：在 61.7% 的辩论中，双方同时声称至少有 75% 的胜利概率，这是不合逻辑的。 （4）持续的自我辩论偏差：辩论模型的相同副本时，信心从 64.1% 增加到 75.2%；即使明确告知其获胜机会是 50%，信心仍然增加（从 50.0% 增加到 57.1%）。 （5）对齐的私人推理：模型的私人草稿思想有时与其公开的信心评分不同，这引起了对其链式推理可靠性的担忧。这些结果表明，大型语言模型缺乏在动态、多轮任务中准确自我评估或更新其信念的能力；这在 LLM 输出在助手角色或代理设置中部署而未经仔细审查的情况下是一项重大担忧。', 'title_zh': '两朵大模型争锋，两者均认为自己获胜'}
{'arxiv_id': 'arXiv:2505.19178', 'title': 'Saliency-guided Emotion Modeling: Predicting Viewer Reactions from Video Stimuli', 'authors': 'Akhila Yaragoppa, Siddharth', 'link': 'https://arxiv.org/abs/2505.19178', 'abstract': 'Understanding the emotional impact of videos is crucial for applications in content creation, advertising, and Human-Computer Interaction (HCI). Traditional affective computing methods rely on self-reported emotions, facial expression analysis, and biosensing data, yet they often overlook the role of visual saliency -- the naturally attention-grabbing regions within a video. In this study, we utilize deep learning to introduce a novel saliency-based approach to emotion prediction by extracting two key features: saliency area and number of salient regions. Using the HD2S saliency model and OpenFace facial action unit analysis, we examine the relationship between video saliency and viewer emotions. Our findings reveal three key insights: (1) Videos with multiple salient regions tend to elicit high-valence, low-arousal emotions, (2) Videos with a single dominant salient region are more likely to induce low-valence, high-arousal responses, and (3) Self-reported emotions often misalign with facial expression-based emotion detection, suggesting limitations in subjective reporting. By leveraging saliency-driven insights, this work provides a computationally efficient and interpretable alternative for emotion modeling, with implications for content creation, personalized media experiences, and affective computing research.', 'abstract_zh': '理解视频的情感影响对于内容创作、广告和人机交互（HCI）的应用至关重要。传统的计算情感方法依赖于自我报告的情绪、面部表情分析和生理传感数据，但往往忽视了视觉显著性的作用——视频中自然吸引注意力的区域。在本研究中，我们利用深度学习引入一种基于显著性的新型情感预测方法，提取两个关键特征：显著性区域和显著区域的数量。采用HD2S显著性模型和OpenFace面部动作单元分析，我们探讨了视频显著性与观众情绪之间的关系。研究发现：（1）具有多个显著性区域的视频更倾向于引发高正价值、低唤醒度的情绪；（2）具有一个主要显著性区域的视频更倾向于引发低正价值、高唤醒度的反应；（3）自我报告的情绪经常与基于面部表情的情感检测不符，表明主观报告的局限性。通过利用基于显著性的情感洞察，本工作提供了一种计算高效且可解释的情感建模替代方法，对于内容创作、个性化媒体体验和情感计算研究具有重要意义。', 'title_zh': '基于显著性的 emotion 模型：从视频刺激预测观众反应'}
{'arxiv_id': 'arXiv:2505.19164', 'title': 'BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations', 'authors': 'Ashirbad Mishra, Jinyu Zhao, Soumik Dey, Hansi Wu, Binbin Li, Kamesh Madduri', 'link': 'https://arxiv.org/abs/2505.19164', 'abstract': "In the domain of sponsored search advertising, the focus of Keyphrase recommendation has largely been on exact match types, which pose issues such as high management expenses, limited targeting scope, and evolving search query patterns. Alternatives like Broad match types can alleviate certain drawbacks of exact matches but present challenges like poor targeting accuracy and minimal supervisory signals owing to limited advertiser usage. This research defines the criteria for an ideal broad match, emphasizing on both efficiency and effectiveness, ensuring that a significant portion of matched queries are relevant. We propose BroadGen, an innovative framework that recommends efficient and effective broad match keyphrases by utilizing historical search query data. Additionally, we demonstrate that BroadGen, through token correspondence modeling, maintains better query stability over time. BroadGen's capabilities allow it to serve daily, millions of sellers at eBay with over 2.3 billion items.", 'abstract_zh': '在赞助搜索广告领域，关键词推荐主要集中在精确匹配类型上，这类方式存在管理成本高、目标范围有限以及搜索查询模式不断演变的问题。相比之下，宽匹配类型可以缓解某些精确匹配的弊端，但同时伴随着目标精度低和监督信号少等挑战，由于广告商使用较少。本研究定义了理想的宽匹配标准，强调效率和效果，确保大部分匹配查询的相关性。我们提出了一种名为BroadGen的新框架，通过利用历史搜索查询数据来推荐高效且有效的宽匹配关键词。此外，我们证明BroadGen通过标记对应关系建模，能够更好地保持查询稳定性。BroadGen的能力使其能够服务于eBay每天数百万卖家，管理超过23亿件商品。', 'title_zh': 'BroadGen: 生成有效且高效的广告商广匹配关键词推荐框架'}
{'arxiv_id': 'arXiv:2505.19163', 'title': 'SpokenNativQA: Multilingual Everyday Spoken Queries for LLMs', 'authors': 'Firoj Alam, Md Arid Hasan, Shammur Absar Chowdhury', 'link': 'https://arxiv.org/abs/2505.19163', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable performance across various disciplines and tasks. However, benchmarking their capabilities with multilingual spoken queries remains largely unexplored. In this study, we introduce SpokenNativQA, the first multilingual and culturally aligned spoken question-answering (SQA) dataset designed to evaluate LLMs in real-world conversational settings. The dataset comprises approximately 33,000 naturally spoken questions and answers in multiple languages, including low-resource and dialect-rich languages, providing a robust benchmark for assessing LLM performance in speech-based interactions. SpokenNativQA addresses the limitations of text-based QA datasets by incorporating speech variability, accents, and linguistic diversity. We benchmark different ASR systems and LLMs for SQA and present our findings. We released the data at (this https URL) and the experimental scripts at (this https URL) for the research community.', 'abstract_zh': '大规模语言模型（LLMs）在多个学科和任务中展现了出色的表现。然而，使用多语言口语文本对其进行基准测试仍是一个未探索的领域。本研究介绍了SpokenNativQA，这是首个用于评估语言模型的多语言和文化对齐的口语文本问答数据集，旨在考察其在真实对话场景中的性能。数据集包含约33,000个自然口语形式的问题和答案，覆盖多种语言，包括资源稀少和方言丰富的语言，为语音交互中的语言模型性能评估提供了稳健的基准。SpokenNativQA 通过纳入语音变异性、口音和语言多样性，解决了基于文本的问答数据集的局限性。我们对不同ASR系统和语言模型进行了口语文本问答基准测试，并展示了测试结果。数据集及实验脚本已发布，详见 (this https URL) 和 (this https URL)。', 'title_zh': 'SpokenNativQA: 多语言日常生活口语查询数据集用于大型语言模型'}
{'arxiv_id': 'arXiv:2505.19151', 'title': 'SRDiffusion: Accelerate Video Diffusion Inference via Sketching-Rendering Cooperation', 'authors': 'Shenggan Cheng, Yuanxin Wei, Lansong Diao, Yong Liu, Bujiao Chen, Lianghua Huang, Yu Liu, Wenyuan Yu, Jiangsu Du, Wei Lin, Yang You', 'link': 'https://arxiv.org/abs/2505.19151', 'abstract': 'Leveraging the diffusion transformer (DiT) architecture, models like Sora, CogVideoX and Wan have achieved remarkable progress in text-to-video, image-to-video, and video editing tasks. Despite these advances, diffusion-based video generation remains computationally intensive, especially for high-resolution, long-duration videos. Prior work accelerates its inference by skipping computation, usually at the cost of severe quality degradation. In this paper, we propose SRDiffusion, a novel framework that leverages collaboration between large and small models to reduce inference cost. The large model handles high-noise steps to ensure semantic and motion fidelity (Sketching), while the smaller model refines visual details in low-noise steps (Rendering). Experimental results demonstrate that our method outperforms existing approaches, over 3$\\times$ speedup for Wan with nearly no quality loss for VBench, and 2$\\times$ speedup for CogVideoX. Our method is introduced as a new direction orthogonal to existing acceleration strategies, offering a practical solution for scalable video generation.', 'abstract_zh': '利用扩散变换器（DiT）架构，Sora、CogVideoX和Wan等模型在文本转视频、图像转视频和视频编辑任务中取得了显著进展。尽管如此，基于扩散的视频生成仍然计算密集型，尤其是在生成高分辨率、长时长相关的视频时更为明显。前期工作通过跳过计算来加速推理，但通常会严重牺牲质量。本文提出了一种新的框架SRDiffusion，该框架利用大模型和小模型之间的协作来降低推理成本。大模型处理高噪声步长以确保语义和运动保真度（草图绘制），而小模型在低噪声步长中细化视觉细节（渲染）。实验结果表明，该方法在Wan上实现了近3倍的速度提升，并且几乎没有质量损失，对于VBench，在CogVideoX上实现了近2倍的速度提升。该方法提供了一种与现有加速策略相独立的新方向，为可扩展的视频生成提供了实用解决方案。', 'title_zh': 'SRDiffusion: 通过草图-渲染合作加速视频扩散推断'}
{'arxiv_id': 'arXiv:2505.19147', 'title': 'Shifting AI Efficiency From Model-Centric to Data-Centric Compression', 'authors': 'Xuyang Liu, Zichen Wen, Shaobo Wang, Junjie Chen, Zhishan Tao, Yubo Wang, Xiangqi Jin, Chang Zou, Yiyu Wang, Chenfei Liao, Xu Zheng, Honggang Chen, Weijia Li, Xuming Hu, Conghui He, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2505.19147', 'abstract': "The rapid advancement of large language models (LLMs) and multi-modal LLMs (MLLMs) has historically relied on model-centric scaling through increasing parameter counts from millions to hundreds of billions to drive performance gains. However, as we approach hardware limits on model size, the dominant computational bottleneck has fundamentally shifted to the quadratic cost of self-attention over long token sequences, now driven by ultra-long text contexts, high-resolution images, and extended videos. In this position paper, \\textbf{we argue that the focus of research for efficient AI is shifting from model-centric compression to data-centric compression}. We position token compression as the new frontier, which improves AI efficiency via reducing the number of tokens during model training or inference. Through comprehensive analysis, we first examine recent developments in long-context AI across various domains and establish a unified mathematical framework for existing model efficiency strategies, demonstrating why token compression represents a crucial paradigm shift in addressing long-context overhead. Subsequently, we systematically review the research landscape of token compression, analyzing its fundamental benefits and identifying its compelling advantages across diverse scenarios. Furthermore, we provide an in-depth analysis of current challenges in token compression research and outline promising future directions. Ultimately, our work aims to offer a fresh perspective on AI efficiency, synthesize existing research, and catalyze innovative developments to address the challenges that increasing context lengths pose to the AI community's advancement.", 'abstract_zh': '快速发展的大规模语言模型（LLMs）和多模态大规模语言模型（MLLMs） historically 历史 上依赖于通过增加参数数量从数百万到数百亿来推动性能提升的模型导向扩展。然而，随着我们接近硬件对模型规模的限制，计算瓶颈已从参数数量增加转向了自注意力对长序列的二次成本，这一瓶颈现在由超长文本上下文、高分辨率图像和延长视频驱动。在本文中，我们认为高效人工智能研究的重点正从模型导向压缩转向数据导向压缩。我们将token压缩定位为新的前沿，通过在模型训练或推理过程中减少token数量来提高人工智能效率。通过全面分析，我们首先研究了不同领域中长上下文人工智能的 Recent 发展，建立了一个统一的数学框架来表征现有模型效率策略，证明了为什么token压缩是应对长上下文开销的重要范式转变。随后，我们系统地回顾了token压缩的研究景观，分析了其基本优势，并在各种场景中识别了其引人注目的优势。我们还深入分析了token压缩研究当前面临的挑战，并勾画出有前途的未来方向。最终，我们的工作旨在提供一种新的视角来审视人工智能效率，综合现有研究，并促进创新以应对不断增加上下文长度对人工智能社区进展带来的挑战。', 'title_zh': '从模型导向转向数据导向的AI压缩效率转换'}
{'arxiv_id': 'arXiv:2505.19128', 'title': 'RetrieveAll: A Multilingual Named Entity Recognition Framework with Large Language Models', 'authors': 'Jin Zhang, Fan Gao, Linyu Li, Yongbin Yu, Xiangxiang Wang, Nyima Tashi, Gadeng Luosang', 'link': 'https://arxiv.org/abs/2505.19128', 'abstract': 'The rise of large language models has led to significant performance breakthroughs in named entity recognition (NER) for high-resource languages, yet there remains substantial room for improvement in low- and medium-resource languages. Existing multilingual NER methods face severe language interference during the multi-language adaptation process, manifested in feature conflicts between different languages and the competitive suppression of low-resource language features by high-resource languages. Although training a dedicated model for each language can mitigate such interference, it lacks scalability and incurs excessive computational costs in real-world applications. To address this issue, we propose RetrieveAll, a universal multilingual NER framework based on dynamic LoRA. The framework decouples task-specific features across languages and demonstrates efficient dynamic adaptability. Furthermore, we introduce a cross-granularity knowledge augmented method that fully exploits the intrinsic potential of the data without relying on external resources. By leveraging a hierarchical prompting mechanism to guide knowledge injection, this approach advances the paradigm from "prompt-guided inference" to "prompt-driven learning." Experimental results show that RetrieveAll outperforms existing baselines; on the PAN-X dataset, it achieves an average F1 improvement of 12.1 percent.', 'abstract_zh': '大语言模型的兴起在高资源语言的命名实体识别（NER）方面取得了显著的性能突破，但在低资源和中资源语言方面仍有很大的改进空间。现有的多语言NER方法在多种语言适应过程中面临严重的语言干扰问题，表现为不同语言之间的特征冲突以及高资源语言对低资源语言特征的竞争性抑制。尽管为每种语言训练专用模型可以缓解这种干扰，但在实际应用中缺乏可扩展性且会产生高昂的计算成本。为解决这一问题，我们提出了基于动态LoRA的通用多语言NER框架RetrieveAll。该框架解耦了跨语言的任务特定特征，并展示了高效的动态适应能力。此外，我们引入了一种跨粒度知识增强方法，该方法充分利用数据的固有潜力，无需依赖外部资源。通过利用分层提示机制引导知识注入，这种方法从“提示指导推断”推进到“提示驱动学习”。实验结果表明，RetrieveAll在PAN-X数据集上优于现有基线，F1分数平均提升12.1个百分点。', 'title_zh': 'RetrieveAll：一种基于大型语言模型的多语种命名实体识别框架'}
{'arxiv_id': 'arXiv:2505.19119', 'title': 'CloneShield: A Framework for Universal Perturbation Against Zero-Shot Voice Cloning', 'authors': 'Renyuan Li, Zhibo Liang, Haichuan Zhang, Tianyu Shi, Zhiyuan Cheng, Jia Shi, Carl Yang, Mingjie Tang', 'link': 'https://arxiv.org/abs/2505.19119', 'abstract': "Recent breakthroughs in text-to-speech (TTS) voice cloning have raised serious privacy concerns, allowing highly accurate vocal identity replication from just a few seconds of reference audio, while retaining the speaker's vocal authenticity. In this paper, we introduce CloneShield, a universal time-domain adversarial perturbation framework specifically designed to defend against zero-shot voice cloning. Our method provides protection that is robust across speakers and utterances, without requiring any prior knowledge of the synthesized text. We formulate perturbation generation as a multi-objective optimization problem, and propose Multi-Gradient Descent Algorithm (MGDA) to ensure the robust protection across diverse utterances. To preserve natural auditory perception for users, we decompose the adversarial perturbation via Mel-spectrogram representations and fine-tune it for each sample. This design ensures imperceptibility while maintaining strong degradation effects on zero-shot cloned outputs. Experiments on three state-of-the-art zero-shot TTS systems, five benchmark datasets and evaluations from 60 human listeners demonstrate that our method preserves near-original audio quality in protected inputs (PESQ = 3.90, SRS = 0.93) while substantially degrading both speaker similarity and speech quality in cloned samples (PESQ = 1.07, SRS = 0.08).", 'abstract_zh': 'Recent突破在文本到语音(TTS)语音克隆方面的进展引发了严重的隐私担忧，允许仅从几秒钟的参考音频中复制高度准确的声音身份，同时保留说话人的声音真实性。在本文中，我们介绍了CloneShield，这是一种通用的时间域对抗性扰动框架，专门设计用于防御零样本语音克隆。我们的方法提供了一种在不同说话人和语句上都具有鲁棒性的保护措施，而无需任何关于合成文本的先验知识。我们将扰动生成形式化为一个多目标优化问题，并提出多梯度下降算法(MGDA)以确保对多样化语句的鲁棒保护。为了保持用户的自然听觉感知，我们通过梅尔频谱图表示分解对抗性扰动，并对每个样本进行微调。这种设计在保持不可感知性的同时，对零样本克隆输出具有强烈降级效果。在三个最先进的零样本TTS系统、五个基准数据集以及60名人听者评估上的实验显示，Our方法在保护输入中近似保持了原始音频质量(PESQ=3.90, SRS=0.93)，同时显著降低了克隆样本中说话人相似性和语音质量(PESQ=1.07, SRS=0.08)。', 'title_zh': '克隆防护：一种通用对抗零样本语音克隆的框架'}
{'arxiv_id': 'arXiv:2505.19115', 'title': 'FP4 All the Way: Fully Quantized Training of LLMs', 'authors': 'Brian Chmiel, Maxim Fishman, Ron Banner, Daniel Soudry', 'link': 'https://arxiv.org/abs/2505.19115', 'abstract': 'We demonstrate, for the first time, fully quantized training (FQT) of large language models (LLMs) using predominantly 4-bit floating-point (FP4) precision for weights, activations, and gradients on datasets up to 200 billion tokens. We extensively investigate key design choices for FP4, including block sizes, scaling formats, and rounding methods. Our analysis shows that the NVFP4 format, where each block of 16 FP4 values (E2M1) shares a scale represented in E4M3, provides optimal results. We use stochastic rounding for backward and update passes and round-to-nearest for the forward pass to enhance stability. Additionally, we identify a theoretical and empirical threshold for effective quantized training: when the gradient norm falls below approximately $\\sqrt{3}$ times the quantization noise, quantized training becomes less effective. Leveraging these insights, we successfully train a 7-billion-parameter model on 256 Intel Gaudi2 accelerators. The resulting FP4-trained model achieves downstream task performance comparable to a standard BF16 baseline, confirming that FP4 training is a practical and highly efficient approach for large-scale LLM training. A reference implementation is supplied in this https URL .', 'abstract_zh': '首次使用主要为4位浮点数（FP4）精度的权重、激活和梯度对大型语言模型进行全量化训练（FQT），并在多达2000亿个令牌的数据集上进行验证：全面探讨FP4的关键设计选择，包括块大小、缩放格式和舍入方法。分析表明，NVFP4格式（每16个FP4值（E2M1）共享一个用E4M3表示的比例因子）提供最佳结果。反向和更新步骤中使用随机舍入，前向步骤中使用四舍五入以增强稳定性。此外，我们确定了有效量化解训练的理论和经验阈值：当梯度范数低于约3倍量化解噪声时，量化解训练的效果会降低。利用这些见解，我们成功在256个Intel Gaudi2加速器上训练了一个70亿参数的模型。该用FP4训练的模型在下游任务上的性能与标准BF16基线相当，证实了FP4训练是大型语言模型训练的一种实用且高效的方案。 여기외에 추가 정보가 없습니다.', 'title_zh': 'FP4 All the Way: 全局量化训练大规模语言模型'}
{'arxiv_id': 'arXiv:2505.19110', 'title': 'An Interpretable Representation Learning Approach for Diffusion Tensor Imaging', 'authors': 'Vishwa Mohan Singh, Alberto Gaston Villagran Asiares, Luisa Sophie Schuhmacher, Kate Rendall, Simon Weißbrod, David Rügamer, Inga Körte', 'link': 'https://arxiv.org/abs/2505.19110', 'abstract': 'Diffusion Tensor Imaging (DTI) tractography offers detailed insights into the structural connectivity of the brain, but presents challenges in effective representation and interpretation in deep learning models. In this work, we propose a novel 2D representation of DTI tractography that encodes tract-level fractional anisotropy (FA) values into a 9x9 grayscale image. This representation is processed through a Beta-Total Correlation Variational Autoencoder with a Spatial Broadcast Decoder to learn a disentangled and interpretable latent embedding. We evaluate the quality of this embedding using supervised and unsupervised representation learning strategies, including auxiliary classification, triplet loss, and SimCLR-based contrastive learning. Compared to the 1D Group deep neural network (DNN) baselines, our approach improves the F1 score in a downstream sex classification task by 15.74% and shows a better disentanglement than the 3D representation.', 'abstract_zh': '扩散张量成像（DTI）纤维追踪为大脑结构连接提供了详细的见解，但在深度学习模型中的有效表示和解释方面面临挑战。本文提出了一种新颖的2D表示方法，将纤维级别中的各向异性分数（FA）值编码到9x9灰度图像中。该表示方法通过Beta-总相关变分自编码器和空间广播解码器处理，以学习一个分离和可解释的潜在嵌入。我们使用监督和无监督表示学习策略评估该嵌入的质量，包括辅助分类、 triplet损失和基于SimCLR的对比学习方法。与1D组深度神经网络（DNN） baselines相比，我们的方法在下游性别分类任务中的F1分数提高了15.74%，并且在分离性方面优于3D表示。', 'title_zh': '可解释的表示学习方法用于扩散张量成像'}
{'arxiv_id': 'arXiv:2505.19108', 'title': 'CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models', 'authors': 'Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lu, Libo Qin', 'link': 'https://arxiv.org/abs/2505.19108', 'abstract': 'Investigating hallucination issues in large language models (LLMs) within cross-lingual and cross-modal scenarios can greatly advance the large-scale deployment in real-world applications. Nevertheless, the current studies are limited to a single scenario, either cross-lingual or cross-modal, leaving a gap in the exploration of hallucinations in the joint cross-lingual and cross-modal scenarios. Motivated by this, we introduce a novel joint Cross-lingual and Cross-modal Hallucinations benchmark (CCHall) to fill this gap. Specifically, CCHall simultaneously incorporates both cross-lingual and cross-modal hallucination scenarios, which can be used to assess the cross-lingual and cross-modal capabilities of LLMs. Furthermore, we conduct a comprehensive evaluation on CCHall, exploring both mainstream open-source and closed-source LLMs. The experimental results highlight that current LLMs still struggle with CCHall. We hope CCHall can serve as a valuable resource to assess LLMs in joint cross-lingual and cross-modal scenarios.', 'abstract_zh': '探究跨语言和跨模态场景下大型语言模型的幻觉问题对于其实景应用的大规模部署具有极大地推动作用。然而，当前的研究局限于单一场景，要么是跨语言要么是跨模态，这在联合跨语言和跨模态场景下探索幻觉方面留下了空白。为此，我们引入了一个新颖的联合跨语言和跨模态幻觉基准（CCHall）以填补这一空白。具体而言，CCHall 同时结合了跨语言和跨模态幻觉场景，可用于评估大型语言模型的跨语言和跨模态能力。此外，我们在 CCHall 上进行了全面评估，涉及主流的开源和闭源大型语言模型。实验结果表明当前的大型语言模型在 CCHall 上仍然存在挑战。我们希望 CCHall 能成为评估联合跨语言和跨模态场景下大型语言模型的一个宝贵资源。', 'title_zh': 'CCHall：大规模语言模型中跨语言和跨模态幻觉检测的新基准'}
{'arxiv_id': 'arXiv:2505.19096', 'title': 'Enable Lightweight and Precision-Scalable Posit/IEEE-754 Arithmetic in RISC-V Cores for Transprecision Computing', 'authors': 'Qiong Li, Chao Fang, Longwei Huang, Jun Lin, Zhongfeng Wang', 'link': 'https://arxiv.org/abs/2505.19096', 'abstract': 'While posit format offers superior dynamic range and accuracy for transprecision computing, its adoption in RISC-V processors is hindered by the lack of a unified solution for lightweight, precision-scalable, and IEEE-754 arithmetic compatible hardware implementation. To address these challenges, we enhance RISC-V processors by 1) integrating dedicated posit codecs into the original FPU for lightweight implementation, 2) incorporating multi/mixed-precision support with dynamic exponent size for precision-scalability, and 3) reusing and customizing ISA extensions for IEEE-754 compatible posit operations. Our comprehensive evaluation spans the modified FPU, RISC-V core, and SoC levels. It demonstrates that our implementation achieves 47.9% LUTs and 57.4% FFs reduction compared to state-of-the-art posit-enabled RISC-V processors, while achieving up to 2.54$\\times$ throughput improvement in various GEMM kernels.', 'abstract_zh': '尽管Posit格式在Transprecision计算中提供了卓越的动态范围和准确性，但由于缺乏统一的轻量级、可扩展精度且与IEEE-754算术兼容的硬件实现解决方案，其在RISC-V处理器中的应用受到限制。为解决这些挑战，我们通过1）在原有FPU中集成专用Posit编解码器实现轻量级实施，2）引入多精度/混合精度支持并具有动态指数大小以实现可扩展精度，以及3）重用和定制ISA扩展以实现与IEEE-754兼容的Posit操作，来增强RISC-V处理器。我们全面评估涵盖了修改后的FPU、RISC-V核心和SoC级别。结果显示，我们的实现相比于最先进的Posit启用的RISC-V处理器在LUT和FF上分别减少了47.9%和57.4%，同时在各种GEMM内核中实现了最多2.54倍的吞吐量提升。', 'title_zh': '在RISC-V内核中实现适用于跨精度计算的轻量级和精度可扩展的Posit/IEEE-754算术'}
{'arxiv_id': 'arXiv:2505.19094', 'title': 'SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards', 'authors': 'Chuming Shen, Wei Wei, Xiaoye Qu, Yu Cheng', 'link': 'https://arxiv.org/abs/2505.19094', 'abstract': 'DeepSeek-R1 has demonstrated powerful reasoning capabilities in the text domain through stable reinforcement learning (RL). Recently, in the multimodal domain, works have begun to directly apply RL to generate R1-like free-form reasoning for Visual Question Answering (VQA) tasks. However, multimodal tasks share an intrinsically different nature from textual tasks, which heavily rely on the understanding of the input image to solve the problem. Therefore, such free-form reasoning faces two critical limitations in the VQA task: (1) Extended reasoning chains diffuse visual focus away from task-critical regions, degrading answer accuracy. (2) Unverifiable intermediate steps amplify policy-gradient variance and computational costs overhead. To address these issues, in this paper, we introduce SATORI ($\\textbf{S}patially$ $\\textbf{A}nchored$ $\\textbf{T}ask$ $\\textbf{O}ptimization$ with $\\textbf{R}e\\textbf{I}nforcement$ Learning), which decomposes VQA into three verifiable stages, including global image captioning, region localization, and answer prediction, each supplying explicit reward signals. Furthermore, we also introduce VQA-Verify, a 12k dataset annotated with answer-aligned captions and bounding-boxes to facilitate training. Experiments demonstrate consistent performance improvements across seven VQA benchmarks, achieving up to $15.7\\%$ improvement in accuracy in accuracy compared to the R1-like baseline. Our analysis of the attention map confirms enhanced focus on critical regions, which brings improvements in accuracy. Our code is available at this https URL.', 'abstract_zh': 'SATORI：Spatially Anchored Task Optimization with Reinforcement Learning for VQA', 'title_zh': 'SATORI-R1：基于空间grounding和可验证奖励的多模态推理激励'}
{'arxiv_id': 'arXiv:2505.19091', 'title': 'ReadBench: Measuring the Dense Text Visual Reading Ability of Vision-Language Models', 'authors': 'Benjamin Clavié, Florian Brand', 'link': 'https://arxiv.org/abs/2505.19091', 'abstract': "Recent advancements in Large Vision-Language Models (VLMs), have greatly enhanced their capability to jointly process text and images. However, despite extensive benchmarks evaluating visual comprehension (e.g., diagrams, color schemes, OCR tasks...), there is limited assessment of VLMs' ability to read and reason about text-rich images effectively. To fill this gap, we introduce ReadBench, a multimodal benchmark specifically designed to evaluate the reading comprehension capabilities of VLMs. ReadBench transposes contexts from established text-only benchmarks into images of text while keeping textual prompts and questions intact. Evaluating leading VLMs with ReadBench, we find minimal-but-present performance degradation on short, text-image inputs, while performance sharply declines for longer, multi-page contexts. Our experiments further reveal that text resolution has negligible effects on multimodal performance. These findings highlight needed improvements in VLMs, particularly their reasoning over visually presented extensive textual content, a capability critical for practical applications. ReadBench is available at this https URL .", 'abstract_zh': 'Recent advancements in大型视觉-语言模型(VLMs)极大地增强了它们同时处理文本和图像的能力。尽管已经有了广泛的应用基准来评估视觉理解能力（例如，图表、颜色方案、OCR任务等），但对VLMs有效阅读和推理文本丰富的图像的能力评估却相当有限。为了填补这一空白，我们引入了ReadBench，这是一个专门设计用于评估VLMs阅读理解能力的多模态基准。ReadBench将现有的纯文本基准中的上下文移植到包含文本的图像中，同时保留文本提示和问题。使用ReadBench评估领先的VLMs，我们发现在处理简短的文本-图像输入时性能有所下降，而对于较长的多页上下文，性能显著下降。我们的实验进一步表明，文本分辨率对多模态性能几乎没有影响。这些发现突显了VLMs所需改进的地方，尤其是它们在处理视觉呈现的大量文本内容时的推理能力，这是其实用应用中至关重要的能力。ReadBench可在以下链接获取：this https URL。', 'title_zh': '读测验：衡量视觉语言模型的密集文本视觉阅读能力'}
{'arxiv_id': 'arXiv:2505.19086', 'title': 'MaskedManipulator: Versatile Whole-Body Control for Loco-Manipulation', 'authors': 'Chen Tessler, Yifeng Jiang, Erwin Coumans, Zhengyi Luo, Gal Chechik, Xue Bin Peng', 'link': 'https://arxiv.org/abs/2505.19086', 'abstract': "Humans interact with their world while leveraging precise full-body control to achieve versatile goals. This versatility allows them to solve long-horizon, underspecified problems, such as placing a cup in a sink, by seamlessly sequencing actions like approaching the cup, grasping, transporting it, and finally placing it in the sink. Such goal-driven control can enable new procedural tools for animation systems, enabling users to define partial objectives while the system naturally ``fills in'' the intermediate motions. However, while current methods for whole-body dexterous manipulation in physics-based animation achieve success in specific interaction tasks, they typically employ control paradigms (e.g., detailed kinematic motion tracking, continuous object trajectory following, or direct VR teleoperation) that offer limited versatility for high-level goal specification across the entire coupled human-object system. To bridge this gap, we present MaskedManipulator, a unified and generative policy developed through a two-stage learning approach. First, our system trains a tracking controller to physically reconstruct complex human-object interactions from large-scale human mocap datasets. This tracking controller is then distilled into MaskedManipulator, which provides users with intuitive control over both the character's body and the manipulated object. As a result, MaskedManipulator enables users to specify complex loco-manipulation tasks through intuitive high-level objectives (e.g., target object poses, key character stances), and MaskedManipulator then synthesizes the necessary full-body actions for a physically simulated humanoid to achieve these goals, paving the way for more interactive and life-like virtual characters.", 'abstract_zh': '人类利用精确的全身控制与其世界互动，以实现多样化的目标。这种灵活性使他们能够通过无缝地组合诸如接近杯子、握住杯子、运送并最终将其放入水槽这样的动作，来解决长期规划和描述不明确的问题。这种以目标为导向的控制可以为动画系统提供新的程序工具，使用户能够定义部分目标，同时系统自然地补充中间动作。然而，尽管基于物理的动画中全身灵巧操作的当前方法在特定交互任务上取得了成功，但它们通常采用有限的高层目标指定灵活性的控制范式（例如，详细的动态关节运动追踪、连续物体轨迹跟随或直接的VR远程操作）。为解决这一问题，我们提出了MaskedManipulator，这是一种通过两阶段学习方法开发的统一生成策略。首先，我们的系统训练一个跟踪控制器，从大规模的人类动捕数据集中物理重建复杂的人机物互动。然后，我们将这一跟踪控制器提炼为MaskedManipulator，为用户提供对角色身体和操作对象的直观控制。这使得用户能够通过直观的高层目标（例如，目标物体的姿态、关键角色姿势）来指定复杂的移动操纵任务，MaskedManipulator则合成所需的全身动作，使物理模拟的类人角色能够实现这些目标，从而为更为互动和栩栩如生的虚拟角色铺平了道路。', 'title_zh': 'MaskedManipulator：全方位肢体操控的多功能Loco- Manipulation控制'}
{'arxiv_id': 'arXiv:2505.19084', 'title': 'Jodi: Unification of Visual Generation and Understanding via Joint Modeling', 'authors': 'Yifeng Xu, Zhenliang He, Meina Kan, Shiguang Shan, Xilin Chen', 'link': 'https://arxiv.org/abs/2505.19084', 'abstract': 'Visual generation and understanding are two deeply interconnected aspects of human intelligence, yet they have been traditionally treated as separate tasks in machine learning. In this paper, we propose Jodi, a diffusion framework that unifies visual generation and understanding by jointly modeling the image domain and multiple label domains. Specifically, Jodi is built upon a linear diffusion transformer along with a role switch mechanism, which enables it to perform three particular types of tasks: (1) joint generation, where the model simultaneously generates images and multiple labels; (2) controllable generation, where images are generated conditioned on any combination of labels; and (3) image perception, where multiple labels can be predicted at once from a given image. Furthermore, we present the Joint-1.6M dataset, which contains 200,000 high-quality images collected from public sources, automatic labels for 7 visual domains, and LLM-generated captions. Extensive experiments demonstrate that Jodi excels in both generation and understanding tasks and exhibits strong extensibility to a wider range of visual domains. Code is available at this https URL.', 'abstract_zh': '视觉生成与理解是人类智能两个深深互联的方面，但在机器学习中它们 traditionally 被视为两个独立的任务。在本文中，我们提出 Jodi，一种通过联合建模图像域和多个标签域来统一视觉生成与理解的扩散框架。具体而言，Jodi 基于线性扩散变换器，并包含一种角色切换机制，使其能够执行以下三种特定类型的任务：(1) 联合生成，其中模型同时生成图像和多个标签；(2) 可控生成，其中在任何标签组合的条件下生成图像；以及 (3) 图像感知，其中可以从给定图像一次预测多个标签。此外，我们提出了 Joint-1.6M 数据集，该数据集包含 200,000 张高质量图像，来自公共来源，7 个视觉域的自动标签，以及由大型语言模型生成的图 caption。全面的实验表明，Jodi 在生成和理解任务中均表现出色，并且具有很强的扩展性，适用于更广泛的视觉域。代码见此 https URL。', 'title_zh': 'Jodi：通过联合建模实现视觉生成与理解的统一'}
{'arxiv_id': 'arXiv:2505.19059', 'title': 'An Initial Exploration of Fine-tuning Small Language Models for Smart Contract Reentrancy Vulnerability Detection', 'authors': 'Ignacio Mariano Andreozzi Pofcher, Joshua Ellul', 'link': 'https://arxiv.org/abs/2505.19059', 'abstract': "Large Language Models (LLMs) are being used more and more for various coding tasks, including to help coders identify bugs and are a promising avenue to support coders in various tasks including vulnerability detection -- particularly given the flexibility of such generative AI models and tools. Yet for many tasks it may not be suitable to use LLMs, for which it may be more suitable to use smaller language models that can fit and easily execute and train on a developer's computer. In this paper we explore and evaluate whether smaller language models can be fine-tuned to achieve reasonable results for a niche area: vulnerability detection -- specifically focusing on detecting the reentrancy bug in Solidity smart contracts.", 'abstract_zh': '小型语言模型能否细调以实现合理的结果：以Solidity智能合约中的重入漏洞检测为例', 'title_zh': '小语言模型对智能合约重入漏洞检测的初步探索'}
{'arxiv_id': 'arXiv:2505.19056', 'title': 'An Embarrassingly Simple Defense Against LLM Abliteration Attacks', 'authors': 'Harethah Abu Shairah, Hasan Abed Al Kader Hammoud, Bernard Ghanem, George Turkiyyah', 'link': 'https://arxiv.org/abs/2505.19056', 'abstract': "Large language models (LLMs) are typically aligned to comply with safety guidelines by refusing harmful instructions. A recent attack, termed abliteration, isolates and suppresses the single latent direction most responsible for refusal behavior, enabling the model to generate unethical content. We propose a defense that modifies how models generate refusals. We construct an extended-refusal dataset that contains harmful prompts with a full response that justifies the reason for refusal. We then fine-tune Llama-2-7B-Chat and Qwen2.5-Instruct (1.5B and 3B parameters) on our extended-refusal dataset, and evaluate the resulting systems on a set of harmful prompts. In our experiments, extended-refusal models maintain high refusal rates, dropping at most by 10%, whereas baseline models' refusal rates drop by 70-80% after abliteration. A broad evaluation of safety and utility shows that extended-refusal fine-tuning neutralizes the abliteration attack while preserving general performance.", 'abstract_zh': '大型语言模型（LLMs）通常通过拒绝有害指令来遵守安全指南。最近的一种攻击称为“abliteration”，它隔离并抑制了最负责拒绝行为的单一潜在方向，从而使模型能够生成不道德的内容。我们提出了一个防御方法，该方法修改了模型生成拒绝的方式。我们构建了一个扩展拒绝数据集，该数据集包含有害提示，并附有完整响应来解释拒绝的原因。然后，我们在我们的扩展拒绝数据集上微调Llama-2-7B-Chat和Qwen2.5-Instruct（参数分别为1.5B和3B），并对一组有害提示进行了评估。在我们的实验中，扩展拒绝模型保持了较高的拒绝率，最多下降10%，而基线模型在遭受abliteration攻击后，拒绝率下降了70-80%。广泛的安全性和实用性评估表明，扩展拒绝微调可以中和abliteration攻击，同时保持一般性能。', 'title_zh': '一种令人尴尬简单的抵御LLM消除攻击的防护方法'}
{'arxiv_id': 'arXiv:2505.19040', 'title': 'Smart Waste Management System for Makkah City using Artificial Intelligence and Internet of Things', 'authors': 'Rawabi S. Al Qurashi, Maram M. Almnjomi, Teef L. Alghamdi, Amjad H. Almalki, Shahad S. Alharthi, Shahad M. althobuti, Alanoud S. Alharthi, Maha A. Thafar', 'link': 'https://arxiv.org/abs/2505.19040', 'abstract': "Waste management is a critical global issue with significant environmental and public health implications. It has become more destructive during large-scale events such as the annual pilgrimage to Makkah, Saudi Arabia, one of the world's largest religious gatherings. This event's popularity has attracted millions worldwide, leading to significant and un-predictable accumulation of waste. Such a tremendous number of visitors leads to in-creased waste management issues at the Grand Mosque and other holy sites, highlighting the need for an effective solution other than traditional methods based on rigid collection schedules.\nTo address this challenge, this research proposed an innovative solution that is context-specific and tailored to the unique requirements of pilgrimage season: a Smart Waste Management System, called TUHR, that utilizes the Internet of Things and Artificial Intelligence. This system encompasses ultrasonic sensors that monitor waste levels in each container at the performance sites. Once the container reaches full capacity, the sensor communicates with the microcontroller, which alerts the relevant authorities. Moreover, our system can detect harmful substances such as gas from the gas detector sensor. Such a proactive and dynamic approach promises to mitigate the environmental and health risks associated with waste accumulation and enhance the cleanliness of these sites. It also delivers economic benefits by reducing unnecessary gasoline consumption and optimizing waste management resources. Importantly, this research aligns with the principles of smart cities and exemplifies the innovative, sustainable, and health-conscious approach that Saudi Arabia is implementing as part of its Vision 2030 initiative.", 'abstract_zh': '废物管理是全球一个关键问题，具有重要的环境和公共卫生意义。在像沙特麦加年度朝圣这样的大型活动中，废物管理问题变得更加严重。这种活动的普及吸引了数以百万计的参与者，导致在克尔白大清真寺和其他圣殿区域产生了大量难以预测的废物堆积，凸显了除基于固定收集时间表的传统方法外，需要有效解决方案的必要性。\n\n为了解决这一挑战，本研究提出了一种针对朝圣季节的独特要求的创新解决方案：一个名为TUHR的智能废物管理系统，该系统利用物联网和人工智能技术。该系统包括超声波传感器，用于监控每个容器在活动地点中的废物量。一旦容器达到满容量，传感器将与微控制器通信，提醒相关当局。此外，我们的系统还可以通过气体检测传感器检测有害物质。这种主动和动态的方法有望减轻废物堆积带来的环境和健康风险，提高这些地区的清洁度。同时，该系统还能通过减少不必要的汽油消耗和优化废物管理资源带来经济效益。重要的是，这项研究与智能城市的原理相一致，并体现了沙特阿拉伯实施2030愿景计划所采用的创新、可持续和健康导向的方法。', 'title_zh': '基于人工智能和物联网的麦加市智能垃圾分类系统'}
{'arxiv_id': 'arXiv:2505.19038', 'title': 'Turb-L1: Achieving Long-term Turbulence Tracing By Tackling Spectral Bias', 'authors': 'Hao Wu, Yuan Gao, Ruiqi Shu, Zean Han, Fan Xu, Zhihong Zhu, Qingsong Wen, Xian Wu, Kun Wang, Xiaomeng Huang', 'link': 'https://arxiv.org/abs/2505.19038', 'abstract': 'Accurately predicting the long-term evolution of turbulence is crucial for advancing scientific understanding and optimizing engineering applications. However, existing deep learning methods face significant bottlenecks in long-term autoregressive prediction, which exhibit excessive smoothing and fail to accurately track complex fluid dynamics. Our extensive experimental and spectral analysis of prevailing methods provides an interpretable explanation for this shortcoming, identifying Spectral Bias as the core obstacle. Concretely, spectral bias is the inherent tendency of models to favor low-frequency, smooth features while overlooking critical high-frequency details during training, thus reducing fidelity and causing physical distortions in long-term predictions. Building on this insight, we propose Turb-L1, an innovative turbulence prediction method, which utilizes a Hierarchical Dynamics Synthesis mechanism within a multi-grid architecture to explicitly overcome spectral bias. It accurately captures cross-scale interactions and preserves the fidelity of high-frequency dynamics, enabling reliable long-term tracking of turbulence evolution. Extensive experiments on the 2D turbulence benchmark show that Turb-L1 demonstrates excellent performance: (I) In long-term predictions, it reduces Mean Squared Error (MSE) by $80.3\\%$ and increases Structural Similarity (SSIM) by over $9\\times$ compared to the SOTA baseline, significantly improving prediction fidelity. (II) It effectively overcomes spectral bias, accurately reproducing the full enstrophy spectrum and maintaining physical realism in high-wavenumber regions, thus avoiding the spectral distortions or spurious energy accumulation seen in other methods.', 'abstract_zh': '准确预测涡流的长期演化对于推进科学理解与优化工程应用至关重要。然而，现有的深度学习方法在长期自回归预测中面临显著障碍，表现为过度平滑化并无法准确追踪复杂的流体动力学。我们对现有方法的广泛实验和频谱分析提供了可解释的解释，识别出频谱偏差是核心障碍。具体而言，频谱偏差是在训练过程中模型偏好低频、平滑特征的同时忽视关键高频细节的固有倾向，从而降低保真度并导致长期预测中的物理失真。基于这一洞察，我们提出了Turb-L1，一种创新的湍流预测方法，利用多尺度架构中的层次动力学合成机制显式克服频谱偏差。它准确捕捉跨尺度交互并保真高频动态，从而实现可靠的长期内涡流演化的追踪。在2D湍流基准测试中的广泛实验显示，Turb-L1表现出色：（I）在长期预测中，其均方误差（MSE）降低了80.3%，结构相似度（SSIM）提高了9倍以上，显著提高预测保真度；（II）有效克服频谱偏差，准确重现完整的旋度频谱，保持高频波数区域的物理逼真性，从而避免了其他方法中出现的频谱失真或虚假能量积累。', 'title_zh': 'Turb-L1: 通过解决频谱偏差实现长期湍流跟踪'}
{'arxiv_id': 'arXiv:2505.19031', 'title': 'Medical Large Vision Language Models with Multi-Image Visual Ability', 'authors': 'Xikai Yang, Juzheng Miao, Yuchen Yuan, Jiaze Wang, Qi Dou, Jinpeng Li, Pheng-Ann Heng', 'link': 'https://arxiv.org/abs/2505.19031', 'abstract': "Medical large vision-language models (LVLMs) have demonstrated promising performance across various single-image question answering (QA) benchmarks, yet their capability in processing multi-image clinical scenarios remains underexplored. Unlike single image based tasks, medical tasks involving multiple images often demand sophisticated visual understanding capabilities, such as temporal reasoning and cross-modal analysis, which are poorly supported by current medical LVLMs. To bridge this critical gap, we present the Med-MIM instruction dataset, comprising 83.2K medical multi-image QA pairs that span four types of multi-image visual abilities (temporal understanding, reasoning, comparison, co-reference). Using this dataset, we fine-tune Mantis and LLaVA-Med, resulting in two specialized medical VLMs: MIM-LLaVA-Med and Med-Mantis, both optimized for multi-image analysis. Additionally, we develop the Med-MIM benchmark to comprehensively evaluate the medical multi-image understanding capabilities of LVLMs. We assess eight popular LVLMs, including our two models, on the Med-MIM benchmark. Experimental results show that both Med-Mantis and MIM-LLaVA-Med achieve superior performance on the held-in and held-out subsets of the Med-MIM benchmark, demonstrating that the Med-MIM instruction dataset effectively enhances LVLMs' multi-image understanding capabilities in the medical domain.", 'abstract_zh': 'Medical大型多模态语言模型（LVLMs）在各种单张图像问答（QA）基准测试中表现 promising，但在处理多张图像临床场景方面的能力仍有待探索。与基于单张图像的任务不同，涉及多张图像的医疗任务往往需要复杂的视觉理解能力，如时间推理和跨模态分析，而当前的医疗LVLMs在这方面支持不足。为了弥合这一关键差距，我们提出了Med-MIM指令数据集，包含83200个多模态医疗多张图像问答对，涵盖了四种多张图像视觉能力（时间理解、推理、比较、共指）。使用该数据集，我们微调了Mantis和LLaVA-Med，分别研制出两种专门的医疗多模态视觉语言模型：MIM-LLaVA-Med和Med-Mantis，二者均优化用于多张图像分析。此外，我们还开发了Med-MIM基准测试，全面评估LVLMs在医疗多张图像理解能力方面的表现。我们在Med-MIM基准测试上评估了八种流行的LVLMs，包括我们的两个模型。实验结果表明，Med-Mantis和MIM-LLaVA-Med在Med-MIM基准测试的保留集和未见集上性能优越，展示了Med-MIM指令数据集有效地提升了LVLMs在医疗多张图像理解方面的能力。', 'title_zh': '医学多图视觉能力大型视觉语言模型'}
{'arxiv_id': 'arXiv:2505.19028', 'title': 'InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts', 'authors': 'Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu', 'link': 'https://arxiv.org/abs/2505.19028', 'abstract': 'Understanding infographic charts with design-driven visual elements (e.g., pictograms, icons) requires both visual recognition and reasoning, posing challenges for multimodal large language models (MLLMs). However, existing visual-question answering benchmarks fall short in evaluating these capabilities of MLLMs due to the lack of paired plain charts and visual-element-based questions. To bridge this gap, we introduce InfoChartQA, a benchmark for evaluating MLLMs on infographic chart understanding. It includes 5,642 pairs of infographic and plain charts, each sharing the same underlying data but differing in visual presentations. We further design visual-element-based questions to capture their unique visual designs and communicative intent. Evaluation of 20 MLLMs reveals a substantial performance decline on infographic charts, particularly for visual-element-based questions related to metaphors. The paired infographic and plain charts enable fine-grained error analysis and ablation studies, which highlight new opportunities for advancing MLLMs in infographic chart understanding. We release InfoChartQA at this https URL.', 'abstract_zh': '理解和分析包含设计驱动视觉元素（如图表标记、图标）的信息图形图表需要同时进行视觉识别和推理，这对多模态大语言模型（MLLMs）提出了挑战。然而，现有的视觉问答基准无法充分评估MLLMs的这些能力，因为它们缺乏配对的普通图表和基于视觉元素的问题。为弥补这一差距，我们引入了InfoChartQA，这是一个用于评估MLLMs在信息图形图表理解方面能力的基准。该基准包括5,642对信息图形和普通图表，每对图表共享相同的数据但视觉呈现不同。我们进一步设计基于视觉元素的问题来捕捉其独特的视觉设计和通信意图。对20个MLLMs的评估显示，在信息图形图表上的性能显著下降，尤其是在涉及隐喻的基于视觉元素的问题上。配对的信息图形和普通图表使细粒度的错误分析和消融研究成为可能，这突显了在信息图形图表理解方面推进MLLMs的新机会。我们在此处发布InfoChartQA：https://。', 'title_zh': 'InfoChartQA：信息图表多模态问答基准'}
{'arxiv_id': 'arXiv:2505.19023', 'title': 'A Smart Healthcare System for Monkeypox Skin Lesion Detection and Tracking', 'authors': 'Huda Alghoraibi, Nuha Alqurashi, Sarah Alotaibi, Renad Alkhudaydi, Bdoor Aldajani, Lubna Alqurashi, Jood Batweel, Maha A. Thafar', 'link': 'https://arxiv.org/abs/2505.19023', 'abstract': 'Monkeypox is a viral disease characterized by distinctive skin lesions and has been reported in many countries. The recent global outbreak has emphasized the urgent need for scalable, accessible, and accurate diagnostic solutions to support public health responses.\nIn this study, we developed ITMAINN, an intelligent, AI-driven healthcare system specifically designed to detect Monkeypox from skin lesion images using advanced deep learning techniques. Our system consists of three main components. First, we trained and evaluated several pretrained models using transfer learning on publicly available skin lesion datasets to identify the most effective models. For binary classification (Monkeypox vs. non-Monkeypox), the Vision Transformer, MobileViT, Transformer-in-Transformer, and VGG16 achieved the highest performance, each with an accuracy and F1-score of 97.8%. For multiclass classification, which contains images of patients with Monkeypox and five other classes (chickenpox, measles, hand-foot-mouth disease, cowpox, and healthy), ResNetViT and ViT Hybrid models achieved 92% accuracy, with F1 scores of 92.24% and 92.19%, respectively. The best-performing and most lightweight model, MobileViT, was deployed within the mobile application. The second component is a cross-platform smartphone application that enables users to detect Monkeypox through image analysis, track symptoms, and receive recommendations for nearby healthcare centers based on their location. The third component is a real-time monitoring dashboard designed for health authorities to support them in tracking cases, analyzing symptom trends, guiding public health interventions, and taking proactive measures.\nThis system is fundamental in developing responsive healthcare infrastructure within smart cities. Our solution, ITMAINN, is part of revolutionizing public health management.', 'abstract_zh': 'monkeypox是一种以典型皮肤病变特征为标志的病毒性疾病，已在多个国家和地区报告。近期全球爆发突显了迫切需要 scalable、accessible 和 accurate 的诊断解决方案，以支持公共卫生应对措施。\n\n在本研究中，我们开发了ITMAINN，一种基于先进深度学习技术的智能人工智能驱动的医疗健康系统，专门用于检测来自皮肤病变图像的猴痘。该系统包括三个主要组成部分。首先，我们通过迁移学习在公开的皮肤病变数据集上训练和评估了多个预训练模型，以识别最有效的模型。对于二分类（猴痘 vs. 非猴痘），ViT、MobileViT、Transformer-in-Transformer 和 VGG16 达到了最高的性能，每种模型的准确率和 F1 分数均为 97.8%。对于包含猴痘和其他五种类别（水痘、麻疹、手足口病、牛痘和健康）图像的多分类，ResNetViT 和 ViT Hybrid 模型分别达到了 92% 的准确率和 92.24% 和 92.19% 的 F1 分数。性能最佳且最轻量级的模型 MobileViT 部署在移动应用程序中。第二部分是一个跨平台的智能手机应用程序，允许用户通过图像分析检测猴痘、跟踪症状，并根据其位置接收附近医疗机构的建议。第三部分是一个实时监测仪表盘，为卫生当局提供支持，帮助其跟踪病例、分析症状趋势、指导公共卫生干预措施，并采取主动措施。\n\n该系统对于在智能城市中构建响应性的医疗基础设施至关重要。我们的解决方案 ITMAINN 作为改善公共卫生管理的革命性进展的一部分。', 'title_zh': '一种用于猴痘皮肤病变检测与跟踪的智能 healthcare 系统'}
{'arxiv_id': 'arXiv:2505.19022', 'title': 'Rethinking Metrics and Benchmarks of Video Anomaly Detection', 'authors': 'Zihao Liu, Xiaoyu Wu, Wenna Li, Linlin Yang', 'link': 'https://arxiv.org/abs/2505.19022', 'abstract': 'Video Anomaly Detection (VAD), which aims to detect anomalies that deviate from expectation, has attracted increasing attention in recent years. Existing advancements in VAD primarily focus on model architectures and training strategies, while devoting insufficient attention to evaluation metrics and benchmarks. In this paper, we rethink VAD evaluation protocols through comprehensive experimental analyses, revealing three critical limitations in current practices: 1) existing metrics are significantly influenced by single annotation bias; 2) current metrics fail to reward early detection of anomalies; 3) available benchmarks lack the capability to evaluate scene overfitting. To address these limitations, we propose three novel evaluation methods: first, we establish averaged AUC/AP metrics over multi-round annotations to mitigate single annotation bias; second, we develop a Latency-aware Average Precision (LaAP) metric that rewards early and accurate anomaly detection; and finally, we introduce two hard normal benchmarks (UCF-HN, MSAD-HN) with videos specifically designed to evaluate scene overfitting. We report performance comparisons of ten state-of-the-art VAD approaches using our proposed evaluation methods, providing novel perspectives for future VAD model development.', 'abstract_zh': '视频异常检测（VAD）评估方法：揭示当前实践中的三大关键局限并提出改进方案', 'title_zh': '重新思考视频异常检测的评估指标与基准'}
{'arxiv_id': 'arXiv:2505.19020', 'title': 'HGCL: Hierarchical Graph Contrastive Learning for User-Item Recommendation', 'authors': 'Jiawei Xue, Zhen Yang, Haitao Lin, Ziji Zhang, Luzhu Wang, Yikun Gu, Yao Xu, Xin Li', 'link': 'https://arxiv.org/abs/2505.19020', 'abstract': 'Graph Contrastive Learning (GCL), which fuses graph neural networks with contrastive learning, has evolved as a pivotal tool in user-item recommendations. While promising, existing GCL methods often lack explicit modeling of hierarchical item structures, which represent item similarities across varying resolutions. Such hierarchical item structures are ubiquitous in various items (e.g., online products and local businesses), and reflect their inherent organizational properties that serve as critical signals for enhancing recommendation accuracy. In this paper, we propose Hierarchical Graph Contrastive Learning (HGCL), a novel GCL method that incorporates hierarchical item structures for user-item recommendations. First, HGCL pre-trains a GCL module using cross-layer contrastive learning to obtain user and item representations. Second, HGCL employs a representation compression and clustering method to construct a two-hierarchy user-item bipartite graph. Ultimately, HGCL fine-tunes user and item representations by learning on the hierarchical graph, and then provides recommendations based on user-item interaction scores. Experiments on three widely adopted benchmark datasets ranging from 70K to 382K nodes confirm the superior performance of HGCL over existing baseline models, highlighting the contribution of hierarchical item structures in enhancing GCL methods for recommendation tasks.', 'abstract_zh': '层次图对比学习（HGCL）：一种融合层次项结构的图对比学习方法', 'title_zh': '基于层次图对比学习的用户-物品推荐'}
{'arxiv_id': 'arXiv:2505.19013', 'title': 'Faithful Group Shapley Value', 'authors': 'Kiljae Lee, Ziqi Liu, Weijing Tang, Yuan Zhang', 'link': 'https://arxiv.org/abs/2505.19013', 'abstract': 'Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions of Data Shapley are vulnerable to shell company attacks, where strategic group splitting can unfairly inflate valuations. We propose Faithful Group Shapley Value (FGSV) that uniquely defends against such attacks. Building on original mathematical insights, we develop a provably fast and accurate approximation algorithm for computing FGSV. Empirical experiments demonstrate that our algorithm significantly outperforms state-of-the-art methods in computational efficiency and approximation accuracy, while ensuring faithful group-level valuation.', 'abstract_zh': '数据信仰值（Faithful Group Shapley Value）是数据估值的重要工具，用于量化个体数据点对机器学习模型的贡献。在实践中，当数据提供商以批量形式贡献数据时，群体级数据估值是 desirable 的。然而，我们发现现有的群体级数据舍弗利值扩展容易受到壳公司攻击的影响，其中战略性群体分裂可以不公平地提升估值。我们提出了数据信仰值（FGSV），能够唯一地防御这类攻击。基于原始的数学洞察，我们开发了一种可证明快速且准确的近似算法来计算数据信仰值。实证实验表明，我们的算法在计算效率和近似准确性方面显著优于现有最佳方法，同时保证了忠实的群体级估值。', 'title_zh': '忠实组Shapley值'}
{'arxiv_id': 'arXiv:2505.19002', 'title': 'Semi-pessimistic Reinforcement Learning', 'authors': 'Jin Zhu, Xin Zhou, Jiaang Yao, Gholamali Aminian, Omar Rivasplata, Simon Little, Lexin Li, Chengchun Shi', 'link': 'https://arxiv.org/abs/2505.19002', 'abstract': "Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of labeled reward data. Relying on labeled data alone often leads to a narrow state-action distribution, further amplifying the distributional shift, and resulting in suboptimal policy learning. To address these issues, we first recognize that the volume of unlabeled data is typically substantially larger than that of labeled data. We then propose a semi-pessimistic RL method to effectively leverage abundant unlabeled data. Our approach offers several advantages. It considerably simplifies the learning process, as it seeks a lower bound of the reward function, rather than that of the Q-function or state transition function. It is highly flexible, and can be integrated with a range of model-free and model-based RL algorithms. It enjoys the guaranteed improvement when utilizing vast unlabeled data, but requires much less restrictive conditions. We compare our method with a number of alternative solutions, both analytically and numerically, and demonstrate its clear competitiveness. We further illustrate with an application to adaptive deep brain stimulation for Parkinson's disease.", 'abstract_zh': '离线强化学习（RL）旨在从预先收集的数据中学习最优策略。然而，它面临着分布位移的挑战，所学到的策略可能遇到未包含在离线数据中的 unseen 情景。此外，许多应用面临标记奖励数据匮乏的问题。仅依赖标记数据会导致状态-行动分布狭窄，进一步加剧分布位移，从而导致亚最优策略学习。为解决这些问题，我们首先认识到未标记数据的数量通常远大于标记数据的数量。然后，我们提出了一种半悲观的 RL 方法，以有效地利用丰富的未标记数据。我们的方法具有多项优势。它显着简化了学习过程，因为它寻求奖励函数的下界，而不是 Q 函数或状态转移函数的下界。它非常灵活，可以与多种模型自由和模型导向的 RL 算法集成。它在充分利用大量未标记数据时能够确保改进，但所需的限制条件要少得多。我们从分析和数值比较两种角度将我们的方法与多种替代方案进行了对比，证明了其显著的竞争优势。我们进一步通过应用到帕金森病的自适应脑深部刺激来说明这一点。', 'title_zh': '半 pessimistic强化学习'}
{'arxiv_id': 'arXiv:2505.18995', 'title': 'FiLLM -- A Filipino-optimized Large Language Model based on Southeast Asia Large Language Model (SEALLM)', 'authors': 'Carlos Jude G. Maminta, Isaiah Job Enriquez, Deandre Nigel Nunez, Michael B. Dela Fuente', 'link': 'https://arxiv.org/abs/2505.18995', 'abstract': 'This study presents FiLLM, a Filipino-optimized large language model, designed to enhance natural language processing (NLP) capabilities in the Filipino language. Built upon the SeaLLM-7B 2.5 model, FiLLM leverages Low-Rank Adaptation (LoRA) fine-tuning to optimize memory efficiency while maintaining task-specific performance. The model was trained and evaluated on diverse Filipino datasets to address key NLP tasks, including Named Entity Recognition (NER), Part-of-Speech (POS) tagging, Dependency Parsing, and Text Summarization. Performance comparisons with the CalamanCy model were conducted using F1 Score, Precision, Recall, Compression Rate, and Keyword Overlap metrics. Results indicate that Calamancy outperforms FILLM in several aspects, demonstrating its effectiveness in processing Filipino text with improved linguistic comprehension and adaptability. This research contributes to the advancement of Filipino NLP applications by providing an optimized, efficient, and scalable language model tailored for local linguistic needs.', 'abstract_zh': 'FiLLM：一种优化的菲律宾语大型语言模型，用于增强菲律宾语自然语言处理能力', 'title_zh': 'FiLLM — 东南亚大型语言模型（SEALLM）优化的菲律宾语优化大型语言模型'}
{'arxiv_id': 'arXiv:2505.18976', 'title': 'GraSS: Scalable Influence Function with Sparse Gradient Compression', 'authors': 'Pingbang Hu, Joseph Melkonian, Weijing Tang, Han Zhao, Jiaqi W. Ma', 'link': 'https://arxiv.org/abs/2505.18976', 'abstract': 'Gradient-based data attribution methods, such as influence functions, are critical for understanding the impact of individual training samples without requiring repeated model retraining. However, their scalability is often limited by the high computational and memory costs associated with per-sample gradient computation. In this work, we propose GraSS, a novel gradient compression algorithm and its variants FactGraSS for linear layers specifically, that explicitly leverage the inherent sparsity of per-sample gradients to achieve sub-linear space and time complexity. Extensive experiments demonstrate the effectiveness of our approach, achieving substantial speedups while preserving data influence fidelity. In particular, FactGraSS achieves up to 165% faster throughput on billion-scale models compared to the previous state-of-the-art baselines. Our code is publicly available at this https URL.', 'abstract_zh': '基于梯度的数据归因方法，如影响函数，对于在无需多次重新训练模型的情况下理解单一训练样本的影响至关重要。然而，这些方法的可扩展性常常受到单样本梯度计算的高计算和内存成本的限制。在本文中，我们提出了一种新颖的梯度压缩算法GraSS及其专门用于线性层的变体FactGraSS，这些方法明确利用了单样本梯度的固有稀疏性以实现亚线性的时间和空间复杂度。广泛的实验验证了该方法的有效性，在保持数据影响保真度的同时实现了显著的加速。特别是，FactGraSS在大型模型上的吞吐量比之前最先进的基线快165%。我们的代码已公开，可通过以下链接访问：this https URL。', 'title_zh': 'GraSS: 可扩展的稀疏梯度压缩影响函数'}
{'arxiv_id': 'arXiv:2505.18975', 'title': 'FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization', 'authors': 'Aotao Wang, Haikuo Shao, Shaobo Ma, Zhongfeng Wang', 'link': 'https://arxiv.org/abs/2505.18975', 'abstract': 'State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency than RTX 3090 GPU.', 'abstract_zh': '基于FPGA的硬件算法协同设计加速器FastMamba：解决Mamba2在边缘设备上的部署问题', 'title_zh': 'FastMamba：一种基于FPGA的高效率Mamba加速器及准确量化'}
{'arxiv_id': 'arXiv:2505.18972', 'title': 'Revival with Voice: Multi-modal Controllable Text-to-Speech Synthesis', 'authors': 'Minsu Kim, Pingchuan Ma, Honglie Chen, Stavros Petridis, Maja Pantic', 'link': 'https://arxiv.org/abs/2505.18972', 'abstract': "This paper explores multi-modal controllable Text-to-Speech Synthesis (TTS) where the voice can be generated from face image, and the characteristics of output speech (e.g., pace, noise level, distance, tone, place) can be controllable with natural text description. Specifically, we aim to mitigate the following three challenges in face-driven TTS systems. 1) To overcome the limited audio quality of audio-visual speech corpora, we propose a training method that additionally utilizes high-quality audio-only speech corpora. 2) To generate voices not only from real human faces but also from artistic portraits, we propose augmenting the input face image with stylization. 3) To consider one-to-many possibilities in face-to-voice mapping and ensure consistent voice generation at the same time, we propose to first employ sampling-based decoding and then use prompting with generated speech samples. Experimental results validate the proposed model's effectiveness in face-driven voice synthesis.", 'abstract_zh': '本文探索基于多模态可控文本到语音合成（TTS），可以从面部图像生成声音，并通过自然文本描述控制输出语音的特性（如语速、噪音水平、距离、音调和语域）。具体来说，我们旨在解决面部驱动TTS系统中的以下三项挑战：1) 为克服视听语音数据集的有限音频质量，我们提出了一种训练方法，额外利用高质量的纯音频数据集。2) 为了不仅能从真实人类面部生成声音，还能从艺术肖像生成声音，我们提出了对输入面部图像进行风格化增强。3) 为考虑面部到语音映射的一对多可能性并确保一致的声音生成，我们首先采用基于采样的解码，然后使用生成语音样本的提示。实验结果验证了所提模型在面部驱动语音合成中的有效性。', 'title_zh': '语音再生：多模态可控文本到语音合成'}
{'arxiv_id': 'arXiv:2505.18966', 'title': 'Protein Design with Dynamic Protein Vocabulary', 'authors': 'Nuowei Liu, Jiahao Kuang, Yanting Liu, Changzhi Sun, Tao Ji, Yuanbin Wu, Man Lan', 'link': 'https://arxiv.org/abs/2505.18966', 'abstract': 'Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.6%.', 'abstract_zh': '基于文本描述的蛋白质设计：整合片段编码以提高折叠能力', 'title_zh': '动态蛋白质词汇表驱动的蛋白质设计'}
{'arxiv_id': 'arXiv:2505.18956', 'title': 'How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation', 'authors': 'Yining Pan, Qiongjie Cui, Xulei Yang, Na Zhao', 'link': 'https://arxiv.org/abs/2505.18956', 'abstract': "LiDAR-based 3D panoptic segmentation often struggles with the inherent sparsity of data from LiDAR sensors, which makes it challenging to accurately recognize distant or small objects. Recently, a few studies have sought to overcome this challenge by integrating LiDAR inputs with camera images, leveraging the rich and dense texture information provided by the latter. While these approaches have shown promising results, they still face challenges, such as misalignment during data augmentation and the reliance on post-processing steps. To address these issues, we propose Image-Assists-LiDAR (IAL), a novel multi-modal 3D panoptic segmentation framework. In IAL, we first introduce a modality-synchronized data augmentation strategy, PieAug, to ensure alignment between LiDAR and image inputs from the start. Next, we adopt a transformer decoder to directly predict panoptic segmentation results. To effectively fuse LiDAR and image features into tokens for the decoder, we design a Geometric-guided Token Fusion (GTF) module. Additionally, we leverage the complementary strengths of each modality as priors for query initialization through a Prior-based Query Generation (PQG) module, enhancing the decoder's ability to generate accurate instance masks. Our IAL framework achieves state-of-the-art performance compared to previous multi-modal 3D panoptic segmentation methods on two widely used benchmarks. Code and models are publicly available at <this https URL.", 'abstract_zh': '基于LiDAR的3D全景分割往往难以处理LiDAR传感器数据固有的稀疏性问题，这使得准确识别远处或小型物体具有挑战性。最近，一些研究通过将LiDAR输入与摄像头图像结合，利用后者提供的丰富密集的纹理信息尝试克服这一挑战。尽管这些方法取得了有前景的结果，但仍面临数据增强时的误对齐问题和依赖后期处理步骤的问题。为解决这些问题，我们提出了一种新的多模态3D全景分割框架——Image-Assists-LiDAR (IAL)。在IAL中，我们首先引入了一种模态同步数据增强策略PieAug，以确保从一开始就对齐LiDAR和图像输入。接着，我们采用 transformer 解码器直接预测全景分割结果。为了有效地将LiDAR和图像特征融合到解码器的标记中，我们设计了一种几何引导标记融合（GTF）模块。此外，我们通过先验基于查询生成（PQG）模块利用每种模态的互补优势作为查询初始化的先验，增强了解码器生成准确实例掩码的能力。与先前的多模态3D全景分割方法相比，我们的IAL框架在两个广泛应用的基准测试中达到了最先进的性能。代码和模型已公开发布。', 'title_zh': '图像如何与LiDAR对齐和互补？ toward和谐的多模态3D全景分割'}
{'arxiv_id': 'arXiv:2505.18949', 'title': 'The Price of Format: Diversity Collapse in LLMs', 'authors': 'Longfei Yun, Chenyang An, Zilong Wang, Letian Peng, Jingbo Shang', 'link': 'https://arxiv.org/abs/2505.18949', 'abstract': "Instruction-tuned large language models (LLMs) employ structured templates, such as role markers and special tokens, to enforce format consistency during inference. However, we identify a critical limitation of such formatting: it induces a phenomenon we term diversity collapse, where the model generates semantically similar outputs for open-ended inputs, undermining creativity and variability. We systematically evaluate this effect across tasks like story completion and free-form generation, finding that (1) diversity collapse persists even under high-temperature sampling, and (2) structural tokens in templates significantly constrain the model's output space. To contextualize these findings, we fine-tune the same model using a range of structured prompts and then evaluate them across three axes: downstream task performance, alignment behavior, and output diversity. Our analysis shows that format consistency between fine-tuning and inference is crucial for structure-sensitive tasks (e.g., GSM8K, IFEval), but has marginal influence on knowledge-heavy tasks (e.g., MMLU, WebQuestions). In contrast, output diversity is primarily governed by the presence or absence of structural tokens, with minimal formatting yielding the most diverse outputs. These findings reveal that current prompting conventions, while beneficial for alignment, may inadvertently suppress output diversity, underscoring the need for diversity-aware prompt design and instruction tuning.", 'abstract_zh': '指令调优的大语言模型（LLMs）使用结构化模板（如角色标记和特殊标记）来确保推理时的格式一致性。然而，我们识别出这种格式化存在一个关键限制：它诱导了一种我们称作多样性的崩溃现象，即模型在处理开放性输入时生成语义上相似的输出，削弱了创造力和多样性。我们在故事生成和自由形式生成等任务上系统地评估了这一效应，发现（1）多样性崩溃即便在高温采样下仍然存在，（2）模板中的结构标记显著限制了模型的输出空间。为了对这些发现进行情境化分析，我们使用一系列结构化提示对同一模型进行微调，并从下游任务性能、对齐行为和输出多样性三个维度进行评估。我们的分析表明，对于结构敏感的任务（如GSM8K、IFEval），微调与推理之间的格式一致性至关重要，但对于知识密集型任务（如MMLU、WebQuestions），其影响相对较小。相比之下，输出多样性主要由结构标记的存在与否所决定，少有格式化呈现最多样化的输出。这些发现揭示出虽然当前的提示惯例有助于对齐，但可能无意中抑制了输出多样性，突显了需要具备多样性的提示设计和指令调优的需求。', 'title_zh': '格式的代价：大语言模型中的多样性坍缩'}
{'arxiv_id': 'arXiv:2505.18934', 'title': 'Chi-Square Wavelet Graph Neural Networks for Heterogeneous Graph Anomaly Detection', 'authors': 'Xiping Li, Xiangyu Dong, Xingyi Zhang, Kun Xie, Yuanhao Feng, Bo Wang, Guilin Li, Wuxiong Zeng, Xiujun Shu, Sibo Wang', 'link': 'https://arxiv.org/abs/2505.18934', 'abstract': 'Graph Anomaly Detection (GAD) in heterogeneous networks presents unique challenges due to node and edge heterogeneity. Existing Graph Neural Network (GNN) methods primarily focus on homogeneous GAD and thus fail to address three key issues: (C1) Capturing abnormal signal and rich semantics across diverse meta-paths; (C2) Retaining high-frequency content in HIN dimension alignment; and (C3) Learning effectively from difficult anomaly samples with class imbalance. To overcome these, we propose ChiGAD, a spectral GNN framework based on a novel Chi-Square filter, inspired by the wavelet effectiveness in diverse domains. Specifically, ChiGAD consists of: (1) Multi-Graph Chi-Square Filter, which captures anomalous information via applying dedicated Chi-Square filters to each meta-path graph; (2) Interactive Meta-Graph Convolution, which aligns features while preserving high-frequency information and incorporates heterogeneous messages by a unified Chi-Square Filter; and (3) Contribution-Informed Cross-Entropy Loss, which prioritizes difficult anomalies to address class imbalance. Extensive experiments on public and industrial datasets show that ChiGAD outperforms state-of-the-art models on multiple metrics. Additionally, its homogeneous variant, ChiGNN, excels on seven GAD datasets, validating the effectiveness of Chi-Square filters. Our code is available at this https URL.', 'abstract_zh': '异构网络中基于图的异常检测（GAD）因其节点和边的异构性而面临独特挑战。现有的图神经网络（GNN）方法主要侧重于同质GAD，因此无法解决以下三个关键问题：(C1) 跨多样元路径捕捉异常信号和丰富的语义；(C2) 在HIN维度对齐中保留高频内容；(C3) 有效地从不平衡类别的异常样本中学习。为克服这些问题，我们提出了一种基于新型卡方滤波器的频谱GNN框架——ChiGAD，该滤波器受到在多种领域中波let效果的启发。具体来说，ChiGAD 包括：(1) 多图卡方滤波器，通过在每个元路径图上应用专门的卡方滤波器来捕获异常信息；(2) 交互式元图卷积，该卷积在保持高频信息的同时进行特征对齐，并通过统一的卡方滤波器整合异构信息；以及(3) 贡献导向的交叉熵损失，该损失优先处理难以分类的异常样本以解决类别不平衡问题。在公共和工业数据集上的广泛实验表明，ChiGAD 在多个指标上优于现有最先进的模型。此外，其同质变体 ChiGNN 在七个 GAD 数据集上表现出色，验证了卡方滤波器的有效性。代码详见：this https URL。', 'title_zh': 'χ²小波图神经网络在异构图异常检测中的应用'}
{'arxiv_id': 'arXiv:2505.18930', 'title': 'WeedNet: A Foundation Model-Based Global-to-Local AI Approach for Real-Time Weed Species Identification and Classification', 'authors': 'Yanben Shen, Timilehin T. Ayanlade, Venkata Naresh Boddepalli, Mojdeh Saadati, Ashlyn Rairdin, Zi K. Deng, Muhammad Arbab Arshad, Aditya Balu, Daren Mueller, Asheesh K Singh, Wesley Everman, Nirav Merchant, Baskar Ganapathysubramanian, Meaghan Anderson, Soumik Sarkar, Arti Singh', 'link': 'https://arxiv.org/abs/2505.18930', 'abstract': 'Early identification of weeds is essential for effective management and control, and there is growing interest in automating the process using computer vision techniques coupled with AI methods. However, challenges associated with training AI-based weed identification models, such as limited expert-verified data and complexity and variability in morphological features, have hindered progress. To address these issues, we present WeedNet, the first global-scale weed identification model capable of recognizing an extensive set of weed species, including noxious and invasive plant species. WeedNet is an end-to-end real-time weed identification pipeline and uses self-supervised learning, fine-tuning, and enhanced trustworthiness strategies. WeedNet achieved 91.02% accuracy across 1,593 weed species, with 41% species achieving 100% accuracy. Using a fine-tuning strategy and a Global-to-Local approach, the local Iowa WeedNet model achieved an overall accuracy of 97.38% for 85 Iowa weeds, most classes exceeded a 90% mean accuracy per class. Testing across intra-species dissimilarity (developmental stages) and inter-species similarity (look-alike species) suggests that diversity in the images collected, spanning all the growth stages and distinguishable plant characteristics, is crucial in driving model performance. The generalizability and adaptability of the Global WeedNet model enable it to function as a foundational model, with the Global-to-Local strategy allowing fine-tuning for region-specific weed communities. Additional validation of drone- and ground-rover-based images highlights the potential of WeedNet for integration into robotic platforms. Furthermore, integration with AI for conversational use provides intelligent agricultural and ecological conservation consulting tools for farmers, agronomists, researchers, land managers, and government agencies across diverse landscapes.', 'abstract_zh': '全球范围内的杂草识别模型：WeedNet及其应用', 'title_zh': 'WeedNet：基于基础模型的全局到局部实时杂草物种识别与分类AI方法'}
{'arxiv_id': 'arXiv:2505.18927', 'title': 'Benchmarking Large Language Models for Cyberbullying Detection in Real-World YouTube Comments', 'authors': 'Amel Muminovic', 'link': 'https://arxiv.org/abs/2505.18927', 'abstract': "As online platforms grow, comment sections increasingly host harassment that undermines user experience and well-being. This study benchmarks three leading large language models, OpenAI GPT-4.1, Google Gemini 1.5 Pro, and Anthropic Claude 3 Opus, on a corpus of 5,080 YouTube comments sampled from high-abuse threads in gaming, lifestyle, food vlog, and music channels. The dataset comprises 1,334 harmful and 3,746 non-harmful messages in English, Arabic, and Indonesian, annotated independently by two reviewers with substantial agreement (Cohen's kappa = 0.83). Using a unified prompt and deterministic settings, GPT-4.1 achieved the best overall balance with an F1 score of 0.863, precision of 0.887, and recall of 0.841. Gemini flagged the highest share of harmful posts (recall = 0.875) but its precision fell to 0.767 due to frequent false positives. Claude delivered the highest precision at 0.920 and the lowest false-positive rate of 0.022, yet its recall dropped to 0.720. Qualitative analysis showed that all three models struggle with sarcasm, coded insults, and mixed-language slang. These results underscore the need for moderation pipelines that combine complementary models, incorporate conversational context, and fine-tune for under-represented languages and implicit abuse. A de-identified version of the dataset and full prompts is publicly released to promote reproducibility and further progress in automated content moderation.", 'abstract_zh': '随着在线平台的发展，评论区越来越多地充斥着危害用户体验和福祉的骚扰行为。本研究对来自游戏、生活方式、美食视频和音乐频道高骚扰帖子的5080条YouTube评论，使用了三款领先的大型语言模型——OpenAI GPT-4.1、Google Gemini 1.5 Pro和Anthropic Claude 3 Opus进行了基准测试。数据集包含1334条有害和3746条非有害的英文、阿拉伯语和印尼语信息，由两名审查员独立标注，一致性达到0.83（科恩κ系数）。使用统一的提示和确定性设置，GPT-4.1在F1分数、精准率和召回率方面表现最佳，分别为0.863、0.887和0.841。Gemini标识的有害帖子比例最高（召回率为0.875），但其精准率下降至0.767，因假阳性频繁出现。Claude在精准率方面最高，达到0.920，并且假阳性率最低，仅为0.022，但是其召回率最低，为0.720。定性分析显示，所有模型在处理讽刺、编码的侮辱和混合语言俚语方面均存在困难。这些结果强调了需要结合互补模型、融入对话背景并针对未充分代表的语言和隐含的不当行为进行微调的调节管道的必要性。脱敏后的数据集和完整提示已公开发布，以促进自动化内容调节的可重复性和进一步发展。', 'title_zh': '大型语言模型在现实世界YouTube评论网络欺凌检测中的基准研究'}
{'arxiv_id': 'arXiv:2505.18917', 'title': 'Behavior Injection: Preparing Language Models for Reinforcement Learning', 'authors': 'Zhepeng Cen, Yihang Yao, William Han, Zuxin Liu, Ding Zhao', 'link': 'https://arxiv.org/abs/2505.18917', 'abstract': 'Reinforcement fine-tuning (RFT) has emerged as a powerful post-training technique to incentivize the reasoning ability of large language models (LLMs). However, LLMs can respond very inconsistently to RFT: some show substantial performance gains, while others plateau or even degrade. To understand this divergence, we analyze the per-step influence of the RL objective and identify two key conditions for effective post-training: (1) RL-informative rollout accuracy, and (2) strong data co-influence, which quantifies how much the training data affects performance on other samples. Guided by these insights, we propose behavior injection, a task-agnostic data-augmentation scheme applied prior to RL. Behavior injection enriches the supervised finetuning (SFT) data by seeding exploratory and exploitative behaviors, effectively making the model more RL-ready. We evaluate our method across two reasoning benchmarks with multiple base models. The results demonstrate that our theoretically motivated augmentation can significantly increases the performance gain from RFT over the pre-RL model.', 'abstract_zh': '强化微调（RFT）已成为一种强大的后训练技术，用于激发大型语言模型（LLMs）的推理能力。然而，LLMs 对 RFT 的响应非常不一致：有些模型表现出显著的性能提升，而另一些则停滞不前甚至退化。为了理解这种差异，我们分析了每步 RL 目标的影响力，并确定了有效后训练的两个关键条件：（1）RL 信息性回放准确性，以及（2）强大的数据共影响性，衡量训练数据对其他样本性能的影响程度。根据这些洞察，我们提出了一种任务无关的数据增强方案，应用于 RL 之前。该方案通过注入探索性和利用性行为来丰富监督微调（SFT）数据，使模型更易于进行 RL。我们在两个推理基准上对多个基模型进行了评估。结果表明，我们的理论驱动的数据增强可以显著增加 RFT 过后训练模型的性能提升。', 'title_zh': '行为注入：准备语言模型进行强化学习'}
{'arxiv_id': 'arXiv:2505.18912', 'title': 'Robust Stability Analysis of Positive Lure System with Neural Network Feedback', 'authors': 'Hamidreza Montazeri Hedesh, Moh. Kamalul Wafi, Bahram Shafai, Milad Siami', 'link': 'https://arxiv.org/abs/2505.18912', 'abstract': "This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes parametric uncertainty but also the nonlinear sector bound is unknown. We investigate tools from positive linear systems to effectively solve the problems in complicated and uncertain nonlinear systems. By leveraging the positivity characteristic of the system, we derive an explicit formula for the stability radius of Lur'e systems. Furthermore, we extend our analysis to systems with neural network (NN) feedback loops. Building on this approach, we also propose a refinement method for sector bounds of feedforward neural networks (FFNNs). This study introduces a scalable and efficient approach for robustness analysis of both Lur'e and NN-controlled systems. Finally, the proposed results are supported by illustrative examples.", 'abstract_zh': "本文探讨了在正性约束条件下Lur'e问题的稳健性，借鉴了正Aizerman猜想和马特泽尔矩阵的稳健性性质的结果。具体地，我们考虑一类具有参数不确定性且非线性部分界值未知的Lur'e型控制系统。通过利用系统的正性特征，我们推导出Lur'e系统稳定半径的显式公式。进一步地，我们将分析扩展到具有神经网络反馈回路的系统。在此基础上，我们还提出了前向神经网络馈送环节界值细化的方法。本文引入了一种针对Lur'e和神经网络控制系统的可扩展且高效的稳健性分析方法，并通过实例予以验证。", 'title_zh': '具有神经网络反馈的正Lure系统的鲁棒稳定性分析'}
{'arxiv_id': 'arXiv:2505.18901', 'title': 'PromptWise: Online Learning for Cost-Aware Prompt Assignment in Generative Models', 'authors': 'Xiaoyan Hu, Lauren Pick, Ho-fung Leung, Farzan Farnia', 'link': 'https://arxiv.org/abs/2505.18901', 'abstract': "The rapid advancement of generative AI models has provided users with numerous options to address their prompts. When selecting a generative AI model for a given prompt, users should consider not only the performance of the chosen model but also its associated service cost. The principle guiding such consideration is to select the least expensive model among the available satisfactory options. However, existing model-selection approaches typically prioritize performance, overlooking pricing differences between models. In this paper, we introduce PromptWise, an online learning framework designed to assign a sequence of prompts to a group of large language models (LLMs) in a cost-effective manner. PromptWise strategically queries cheaper models first, progressing to more expensive options only if the lower-cost models fail to adequately address a given prompt. Through numerical experiments, we demonstrate PromptWise's effectiveness across various tasks, including puzzles of varying complexity and code generation/translation tasks. The results highlight that PromptWise consistently outperforms cost-unaware baseline methods, emphasizing that directly assigning prompts to the most expensive models can lead to higher costs and potentially lower average performance.", 'abstract_zh': '生成式AI模型的迅速发展为用户提供了众多应对提示的选择。在为给定的提示选择生成式AI模型时，用户不仅应考虑所选模型的性能，还应考虑其相关服务成本。指导这一选择的原则是在满足需求的选项中选择最便宜的模型。然而，现有的模型选择方法通常优先考虑性能，忽略了模型之间的价格差异。在本文中，我们介绍了PromptWise，这是一种在线学习框架，旨在以经济高效的方式将一系列提示分配给一组大规模语言模型（LLMs）。PromptWise 战略性地优先查询较便宜的模型，只有在较低成本的模型不能充分解决给定提示时，才转向更昂贵的选项。通过数值实验，我们展示了PromptWise在各种任务中的有效性，包括不同复杂度的谜题和代码生成/翻译任务。结果表明，PromptWise 始终优于不考虑成本的基础方法，强调直接将提示分配给最昂贵的模型可能会导致更高的成本和较低的平均性能。', 'title_zh': 'PromptWise：生成模型中成本 Awareness 提示分配的在线学习'}
{'arxiv_id': 'arXiv:2505.18897', 'title': 'Improving Ad matching via Cluster-Adaptive Keyword Expansion and Relevance tuning', 'authors': 'Dipanwita Saha, Anis Zaman, Hua Zou, Ning Chen, Xinxin Shu, Nadia Vase, Abraham Bagherjeiran', 'link': 'https://arxiv.org/abs/2505.18897', 'abstract': 'In search advertising, keyword matching connects user queries with relevant ads. While token-based matching increases ad coverage, it can reduce relevance due to overly permissive semantic expansion. This work extends keyword reach through document-side semantic keyword expansion, using a language model to broaden token-level matching without altering queries. We propose a solution using a pre-trained siamese model to generate dense vector representations of ad keywords and identify semantically related variants through nearest neighbor search. To maintain precision, we introduce a cluster-based thresholding mechanism that adjusts similarity cutoffs based on local semantic density. Each expanded keyword maps to a group of seller-listed items, which may only partially align with the original intent. To ensure relevance, we enhance the downstream relevance model by adapting it to the expanded keyword space using an incremental learning strategy with a lightweight decision tree ensemble. This system improves both relevance and click-through rate (CTR), offering a scalable, low-latency solution adaptable to evolving query behavior and advertising inventory.', 'abstract_zh': '基于文档侧语义关键词扩展的搜索引擎广告关键词匹配方法', 'title_zh': '改进广告匹配通过簇-广告自适应关键词扩展和相关性调整'}
{'arxiv_id': 'arXiv:2505.18893', 'title': "Reality Check: A New Evaluation Ecosystem Is Necessary to Understand AI's Real World Effects", 'authors': 'Reva Schwartz, Rumman Chowdhury, Akash Kundu, Heather Frase, Marzieh Fadaee, Tom David, Gabriella Waters, Afaf Taik, Morgan Briggs, Patrick Hall, Shomik Jain, Kyra Yee, Spencer Thomas, Sundeep Bhandari, Lee Wan Sie, Qinghua Lu, Matthew Holmes, Theodora Skeadas', 'link': 'https://arxiv.org/abs/2505.18893', 'abstract': "Conventional AI evaluation approaches concentrated within the AI stack exhibit systemic limitations for exploring, navigating and resolving the human and societal factors that play out in real world deployment such as in education, finance, healthcare, and employment sectors. AI capability evaluations can capture detail about first-order effects, such as whether immediate system outputs are accurate, or contain toxic, biased or stereotypical content, but AI's second-order effects, i.e. any long-term outcomes and consequences that may result from AI use in the real world, have become a significant area of interest as the technology becomes embedded in our daily lives. These secondary effects can include shifts in user behavior, societal, cultural and economic ramifications, workforce transformations, and long-term downstream impacts that may result from a broad and growing set of risks. This position paper argues that measuring the indirect and secondary effects of AI will require expansion beyond static, single-turn approaches conducted in silico to include testing paradigms that can capture what actually materializes when people use AI technology in context. Specifically, we describe the need for data and methods that can facilitate contextual awareness and enable downstream interpretation and decision making about AI's secondary effects, and recommend requirements for a new ecosystem.", 'abstract_zh': '传统的AI评估方法集中在AI栈内部，对于探索、导航和解决在教育、金融、医疗和就业等领域真实世界部署中展现出来的人类和社会因素系统性地表现出局限性。AI能力评估可以捕捉到直接影响的细节，例如系统即时输出的准确性或是否包含有毒、有偏见或刻板的内容，但AI的次生效应，即AI在真实世界使用过程中可能产生的长期结果和后果，已成为一个重要研究领域，特别是在这项技术嵌入我们日常生活的情况下。这些次生效应可能包括用户行为的转变、社会、文化和经济影响、劳动力结构的变化，以及由广泛存在的各类风险引发的长期下游影响。本文认为，衡量AI的间接和次生效应需要超越静态的单轮次在硅测试方法，包括可以捕捉到在实际情境中人们使用AI技术时所发生的真实情况的测试范式。具体而言，我们描述了有助于增强上下文意识、支持对AI次生效应进行下游解释和决策的数据和方法需求，并提出了新的生态系统的要求。', 'title_zh': '现实检验：需建立新的评估生态系统以理解AI的实际影响'}
{'arxiv_id': 'arXiv:2505.18892', 'title': 'Climate Implications of Diffusion-based Generative Visual AI Systems and their Mass Adoption', 'authors': 'Vanessa Utz, Steve DiPaola', 'link': 'https://arxiv.org/abs/2505.18892', 'abstract': 'Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consumer appeal, the GPU use of text-prompt based diffusion AI art systems also requires thoughtful considerations. Given the recent explosion in the number of highly sophisticated generative art systems and their rapid adoption by consumers and creative professionals, the impact of these systems on the climate needs to be carefully considered. In this work, we report on the growth of diffusion-based visual AI systems, their patterns of use, growth and the implications on the climate. Our estimates show that the mass adoption of these tools potentially contributes considerably to global energy consumption. We end this paper with our thoughts on solutions and future areas of inquiry as well as associated difficulties, including the lack of publicly available data.', 'abstract_zh': '快速发展的区块链等相关加密货币挖矿和NFT铸造对气候的影响已有充分记录，其巨大的GPU能耗引起了关注。然而，由于其更广泛的消费者吸引力，基于文本提示的扩散型AI艺术系统的GPU使用也需审慎考虑。鉴于这些高度复杂生成艺术系统数量的快速增长及其在消费者和创意专业人士中的迅速采纳，这些系统对气候的影响需要仔细考虑。在这项工作中，我们报告了基于扩散的视觉AI系统的增长、使用模式、增长趋势及其对气候的影响。我们的估算显示，这些工具的大规模采用可能显著增加全球能源消耗。我们在此文中提出了一些解决方案和未来研究方向的想法，同时也指出了相关困难，包括缺乏公开数据。', 'title_zh': '基于扩散的生成视觉AI系统及其大规模采用的气候影响'}
{'arxiv_id': 'arXiv:2505.18889', 'title': 'Security Concerns for Large Language Models: A Survey', 'authors': 'Miles Q. Li, Benjamin C. M. Fung', 'link': 'https://arxiv.org/abs/2505.18889', 'abstract': "Large Language Models (LLMs) such as GPT-4 (and its recent iterations like GPT-4o and the GPT-4.1 series), Google's Gemini, Anthropic's Claude 3 models, and xAI's Grok have caused a revolution in natural language processing, but their capabilities also introduce new security vulnerabilities. In this survey, we provide a comprehensive overview of the emerging security concerns around LLMs, categorizing threats into prompt injection and jailbreaking, adversarial attacks (including input perturbations and data poisoning), misuse by malicious actors (e.g., for disinformation, phishing, and malware generation), and worrisome risks inherent in autonomous LLM agents. A significant focus has been recently placed on the latter, exploring goal misalignment, emergent deception, self-preservation instincts, and the potential for LLMs to develop and pursue covert, misaligned objectives (scheming), which may even persist through safety training. We summarize recent academic and industrial studies (2022-2025) that exemplify each threat, analyze proposed defenses and their limitations, and identify open challenges in securing LLM-based applications. We conclude by emphasizing the importance of advancing robust, multi-layered security strategies to ensure LLMs are safe and beneficial.", 'abstract_zh': '大型语言模型（LLMs）如GPT-4及其迭代版本、Google的Gemini、Anthropic的Claude 3模型和xAI的Grok在自然语言处理中引发了革命，但其能力也带来了新的安全漏洞。在本文综述中，我们提供了LLMs新兴安全担忧的全面概述，将其威胁分类为提示注入和越狱攻击、对抗性攻击（包括输入扰动和数据投毒）、恶意行为者的误用（例如，用于虚假信息、钓鱼和恶意软件生成）以及自主LLM代理固有的令人担忧的风险。最近对后者的关注点集中在目标失准、新兴欺骗、自我保护本能以及LLMs发展和追求隐蔽、失准目标（阴谋）的可能性上，即使这些目标可能在安全训练后仍会持续。我们总结了2022-2025年间代表性学术和工业研究中每种威胁的案例，分析了提出的防御措施及其局限性，并指出了保护基于LLM的应用程序的安全挑战。最后，我们强调推进稳健的多层安全策略的重要性，以确保LLMs的安全和有益。', 'title_zh': '大规模语言模型的安全性关切：一项综述'}
{'arxiv_id': 'arXiv:2505.18884', 'title': 'LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders', 'authors': 'Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli', 'link': 'https://arxiv.org/abs/2505.18884', 'abstract': 'Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key limitations in these approaches: (i) they often suffer from instability, especially during the early stages of fine-tuning, resulting in suboptimal convergence and degraded performance on clean data, and (ii) they exhibit a suboptimal trade-off between robustness and clean data accuracy, hindering the simultaneous optimization of both objectives. To overcome these challenges, we propose Lagrangian-Optimized Robust Embeddings (LORE), a novel unsupervised adversarial fine-tuning framework. LORE utilizes constrained optimization, which offers a principled approach to balancing competing goals, such as improving robustness while preserving nominal performance. By enforcing embedding-space proximity constraints, LORE effectively maintains clean data performance throughout adversarial fine-tuning. Extensive experiments show that LORE significantly improves zero-shot adversarial robustness with minimal degradation in clean data accuracy. Furthermore, we demonstrate the effectiveness of the adversarially fine-tuned CLIP image encoder in out-of-distribution generalization and enhancing the interpretability of image embeddings.', 'abstract_zh': '视觉编码器已成为现代计算机视觉管道中的基本组件。然而，确保其对抗扰动的稳健性仍然是一个关键挑战。最近的努力探索了监督和非监督的对抗微调策略。我们指出这些方法中存在的两个关键局限性：（i）它们在微调早期阶段往往表现出不稳定性，导致收敛效果不佳，以及在干净数据上的性能下降；（ii）它们在稳健性和干净数据准确性之间表现出次优权衡，阻碍了两者的同时优化。为克服这些挑战，我们提出了拉格朗日优化稳健嵌入（LORE），这是一种新颖的非监督对抗微调框架。LORE利用约束优化，提供了一种平衡竞争目标的方法，例如在保持名义性能的同时提高稳健性。通过施加嵌入空间邻近约束，LORE在整个对抗微调过程中有效保持了干净数据的性能。大量实验表明，LORE在无监督条件下显著提高了对抗稳健性，且对干净数据准确性的影响最小。此外，我们展示了经过对抗微调的CLIP图像编码器在分布外泛化中的有效性以及增强图像嵌入可解释性的能力。', 'title_zh': 'LORE: 拉格朗日优化鲁棒嵌入视觉编码器'}
{'arxiv_id': 'arXiv:2505.18881', 'title': 'SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes', 'authors': 'Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang', 'link': 'https://arxiv.org/abs/2505.18881', 'abstract': 'We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.', 'abstract_zh': '面向动态场景的开放词汇对象导航语义感知数据集和基准生成流水线（SD-OVON）', 'title_zh': 'SD-OVON: 一种面向开放词汇对象导航动态场景的语义感知数据集和基准生成管道'}
{'arxiv_id': 'arXiv:2505.18880', 'title': 'REGen: Multimodal Retrieval-Embedded Generation for Long-to-Short Video Editing', 'authors': 'Weihan Xu, Yimeng Ma, Jingyue Huang, Yang Li, Wenye Ma, Taylor Berg-Kirkpatrick, Julian McAuley, Paul Pu Liang, Hao-Wen Dong', 'link': 'https://arxiv.org/abs/2505.18880', 'abstract': "Short videos are an effective tool for promoting contents and improving knowledge accessibility. While existing extractive video summarization methods struggle to produce a coherent narrative, existing abstractive methods cannot `quote' from the input videos, i.e., inserting short video clips in their outputs. In this work, we explore novel video editing models for generating shorts that feature a coherent narrative with embedded video insertions extracted from a long input video. We propose a novel retrieval-embedded generation framework that allows a large language model to quote multimodal resources while maintaining a coherent narrative. Our proposed REGen system first generates the output story script with quote placeholders using a finetuned large language model, and then uses a novel retrieval model to replace the quote placeholders by selecting a video clip that best supports the narrative from a pool of candidate quotable video clips. We examine the proposed method on the task of documentary teaser generation, where short interview insertions are commonly used to support the narrative of a documentary. Our objective evaluations show that the proposed method can effectively insert short video clips while maintaining a coherent narrative. In a subjective survey, we show that our proposed method outperforms existing abstractive and extractive approaches in terms of coherence, alignment, and realism in teaser generation.", 'abstract_zh': '短视频是推广内容和提高知识可访问性的有效工具。现有提取式视频摘要方法难以生成连贯的叙事，而现有的抽象式方法则无法从输入视频中“引用”，即在输出中插入短视频片段。在本文中，我们探讨了新型视频编辑模型，用于生成包含从长输入视频中提取的视频插入并具有连贯叙事的短视频。我们提出了一种新颖的检索嵌入生成框架，允许大型语言模型引用多模态资源同时保持连贯的叙事。我们提出的REGen系统首先使用微调的大语言模型生成包含引用占位符的输出故事剧本，然后使用一种新颖的检索模型，通过从候选可引用视频片段池中选择最支持叙事的视频片段来替换这些引用占位符。我们在纪录片预告片生成任务上检验了该方法，其中常见的短访谈插入支持纪录片的叙事。客观评估显示，该方法能够在保持连贯叙事的同时有效插入短视频片段。在主观调查中，我们证明了与现有抽象和提取方法相比，我们的方法在预告片生成的连贯性、对齐和真实性方面表现更优。', 'title_zh': 'REGen: 多模态检索嵌入生成的长视频到短视频编辑'}
{'arxiv_id': 'arXiv:2505.18878', 'title': 'CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions', 'authors': 'Kung-Hsiang Huang, Akshara Prabhakar, Onkar Thorat, Divyansh Agarwal, Prafulla Kumar Choubey, Yixin Mao, Silvio Savarese, Caiming Xiong, Chien-Sheng Wu', 'link': 'https://arxiv.org/abs/2505.18878', 'abstract': "While AI agents hold transformative potential in business, effective performance benchmarking is hindered by the scarcity of public, realistic business data on widely used platforms. Existing benchmarks often lack fidelity in their environments, data, and agent-user interactions, with limited coverage of diverse business scenarios and industries. To address these gaps, we introduce CRMArena-Pro, a novel benchmark for holistic, realistic assessment of LLM agents in diverse professional settings. CRMArena-Pro expands on CRMArena with nineteen expert-validated tasks across sales, service, and 'configure, price, and quote' processes, for both Business-to-Business and Business-to-Customer scenarios. It distinctively incorporates multi-turn interactions guided by diverse personas and robust confidentiality awareness assessments. Experiments reveal leading LLM agents achieve only around 58% single-turn success on CRMArena-Pro, with performance dropping significantly to approximately 35% in multi-turn settings. While Workflow Execution proves more tractable for top agents (over 83% single-turn success), other evaluated business skills present greater challenges. Furthermore, agents exhibit near-zero inherent confidentiality awareness; though targeted prompting can improve this, it often compromises task performance. These findings highlight a substantial gap between current LLM capabilities and enterprise demands, underscoring the need for advancements in multi-turn reasoning, confidentiality adherence, and versatile skill acquisition.", 'abstract_zh': 'CRMArena-Pro：一种针对多样化专业场景的LLM代理综合、现实评估基准', 'title_zh': 'CRMArena-Pro：跨多样商业场景和交互的整体评估大型语言模型代理'}
{'arxiv_id': 'arXiv:2505.18859', 'title': 'Writing Like the Best: Exemplar-Based Expository Text Generation', 'authors': 'Yuxiang Liu, Kevin Chen-Chuan Chang', 'link': 'https://arxiv.org/abs/2505.18859', 'abstract': 'We introduce the Exemplar-Based Expository Text Generation task, aiming to generate an expository text on a new topic using an exemplar on a similar topic. Current methods fall short due to their reliance on extensive exemplar data, difficulty in adapting topic-specific content, and issues with long-text coherence. To address these challenges, we propose the concept of Adaptive Imitation and present a novel Recurrent Plan-then-Adapt (RePA) framework. RePA leverages large language models (LLMs) for effective adaptive imitation through a fine-grained plan-then-adapt process. RePA also enables recurrent segment-by-segment imitation, supported by two memory structures that enhance input clarity and output coherence. We also develop task-specific evaluation metrics--imitativeness, adaptiveness, and adaptive-imitativeness--using LLMs as evaluators. Experimental results across our collected three diverse datasets demonstrate that RePA surpasses existing baselines in producing factual, consistent, and relevant texts for this task.', 'abstract_zh': '基于范例的 exposition 文本生成任务：一种适应性模仿的 Recurrent Plan-then-Adapt (RePA) 框架', 'title_zh': '像顶尖作者那样写作：基于范例的说明文生成'}
{'arxiv_id': 'arXiv:2505.18817', 'title': 'High-order Equivariant Flow Matching for Density Functional Theory Hamiltonian Prediction', 'authors': 'Seongsu Kim, Nayoung Kim, Dongwoo Kim, Sungsoo Ahn', 'link': 'https://arxiv.org/abs/2505.18817', 'abstract': 'Density functional theory (DFT) is a fundamental method for simulating quantum chemical properties, but it remains expensive due to the iterative self-consistent field (SCF) process required to solve the Kohn-Sham equations. Recently, deep learning methods are gaining attention as a way to bypass this step by directly predicting the Hamiltonian. However, they rely on deterministic regression and do not consider the highly structured nature of Hamiltonians. In this work, we propose QHFlow, a high-order equivariant flow matching framework that generates Hamiltonian matrices conditioned on molecular geometry. Flow matching models continuous-time trajectories between simple priors and complex targets, learning the structured distributions over Hamiltonians instead of direct regression. To further incorporate symmetry, we use a neural architecture that predicts SE(3)-equivariant vector fields, improving accuracy and generalization across diverse geometries. To further enhance physical fidelity, we additionally introduce a fine-tuning scheme to align predicted orbital energies with the target. QHFlow achieves state-of-the-art performance, reducing Hamiltonian error by 71% on MD17 and 53% on QH9. Moreover, we further show that QHFlow accelerates the DFT process without trading off the solution quality when initializing SCF iterations with the predicted Hamiltonian, significantly reducing the number of iterations and runtime.', 'abstract_zh': '基于密度泛函理论的高阶对称流匹配框架QHFlow：生成条件于分子几何的哈密顿矩阵', 'title_zh': '高阶等变流形匹配用于密度泛函理论哈密顿量预测'}
{'arxiv_id': 'arXiv:2505.18799', 'title': 'ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models', 'authors': 'Hao Chen, Haoze Li, Zhiqing Xiao, Lirong Gao, Qi Zhang, Xiaomeng Hu, Ningtao Wang, Xing Fu, Junbo Zhao', 'link': 'https://arxiv.org/abs/2505.18799', 'abstract': 'Aligning general-purpose large language models (LLMs) to downstream tasks often incurs significant costs, including constructing task-specific instruction pairs and extensive training adjustments. Prior research has explored various avenues to enhance alignment efficiency, primarily through minimal-data training or data-driven activations to identify key attention heads. However, these approaches inherently introduce data dependency, which hinders generalization and reusability. To address this issue and enhance model alignment efficiency, we propose the \\textit{\\textbf{A}ttention \\textbf{L}ocalization and \\textbf{P}runing \\textbf{S}trategy (\\textbf{ALPS})}, an efficient algorithm that localizes the most task-sensitive attention heads and prunes by restricting attention training updates to these heads, thereby reducing alignment costs. Experimental results demonstrate that our method activates only \\textbf{10\\%} of attention parameters during fine-tuning while achieving a \\textbf{2\\%} performance improvement over baselines on three tasks. Moreover, the identified task-specific heads are transferable across datasets and mitigate knowledge forgetting. Our work and findings provide a novel perspective on efficient LLM alignment.', 'abstract_zh': '一种注意力定位与修剪策略（ALPS）以提高通用大语言模型的下游任务对齐效率', 'title_zh': 'ALPS: 注意力定位与剪枝策略以提高大型语言模型对齐效率'}
{'arxiv_id': 'arXiv:2505.18787', 'title': 'Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation', 'authors': 'Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac', 'link': 'https://arxiv.org/abs/2505.18787', 'abstract': 'Deepfake (DF) detectors face significant challenges when deployed in real-world environments, particularly when encountering test samples deviated from training data through either postprocessing manipulations or distribution shifts. We demonstrate postprocessing techniques can completely obscure generation artifacts presented in DF samples, leading to performance degradation of DF detectors. To address these challenges, we propose Think Twice before Adaptation (\\texttt{T$^2$A}), a novel online test-time adaptation method that enhances the adaptability of detectors during inference without requiring access to source training data or labels. Our key idea is to enable the model to explore alternative options through an Uncertainty-aware Negative Learning objective rather than solely relying on its initial predictions as commonly seen in entropy minimization (EM)-based approaches. We also introduce an Uncertain Sample Prioritization strategy and Gradients Masking technique to improve the adaptation by focusing on important samples and model parameters. Our theoretical analysis demonstrates that the proposed negative learning objective exhibits complementary behavior to EM, facilitating better adaptation capability. Empirically, our method achieves state-of-the-art results compared to existing test-time adaptation (TTA) approaches and significantly enhances the resilience and generalization of DF detectors during inference. Code is available \\href{this https URL}{here}.', 'abstract_zh': 'Deepfake检测器在实际应用场景中面临显著挑战，特别是在处理通过后处理操作或分布偏移与训练数据不一致的测试样本时。我们展示了后处理技术可以完全隐藏Deepfake样本中的生成特征，导致Deepfake检测器性能下降。为应对这些挑战，我们提出了一种名为Think Twice before Adaptation (\\texttt{T$^2$A})的新型在线测试时自适应方法，该方法在推理过程中增强了检测器的适应性，而不需访问源训练数据或标签。我们的主要思想是通过不确定性感知的负面学习目标使模型能够探索替代选项，而不是像基于熵最小化的方法那样仅依赖其初始预测。我们还引入了一种不确定性样本优先级策略和梯度屏蔽技术，通过聚焦重要样本和模型参数来提高自适应性能。我们的理论分析表明，提出的负面学习目标与熵最小化方法表现互补，有利于更好的自适应能力。实验结果显示，与现有的测试时自适应（TTA）方法相比，该方法在推理过程中显著提高了Deepfake检测器的鲁棒性和泛化能力。源代码可在这里获取。', 'title_zh': '三思而后适应：通过在线测试时适应提高深度假信息检测的适应性'}
{'arxiv_id': 'arXiv:2505.18783', 'title': 'Soft Weighted Machine Unlearning', 'authors': 'Xinbao Qiao, Ningning Ding, Yushi Cheng, Meng Zhang', 'link': 'https://arxiv.org/abs/2505.18783', 'abstract': 'Machine unlearning, as a post-hoc processing technique, has gained widespread adoption in addressing challenges like bias mitigation and robustness enhancement, colloquially, machine unlearning for fairness and robustness. However, existing non-privacy unlearning-based solutions persist in using binary data removal framework designed for privacy-driven motivation, leading to significant information loss, a phenomenon known as over-unlearning. While over-unlearning has been largely described in many studies as primarily causing utility degradation, we investigate its fundamental causes and provide deeper insights in this work through counterfactual leave-one-out analysis. In this paper, we introduce a weighted influence function that assigns tailored weights to each sample by solving a convex quadratic programming problem analytically. Building on this, we propose a soft-weighted framework enabling fine-grained model adjustments to address the over-unlearning challenge. We demonstrate that the proposed soft-weighted scheme is versatile and can be seamlessly integrated into most existing unlearning algorithms. Extensive experiments show that in fairness- and robustness-driven tasks, the soft-weighted scheme significantly outperforms hard-weighted schemes in fairness/robustness metrics and alleviates the decline in utility metric, thereby enhancing machine unlearning algorithm as an effective correction solution.', 'abstract_zh': '机器反学习作为一种后处理技术，在应对偏见缓解和鲁棒性增强等挑战中获得了广泛应用，即公平与鲁棒性的机器反学习。然而，现有的非隐私驱动的反学习解决方案仍然采用旨在保护隐私的数据二元删除框架，导致了显著的信息丢失，这种现象被称为过度反学习。尽管过度反学习在许多研究中主要被描述为导致效用下降，我们在本文中通过反事实的“leave-one-out”分析探究其根本原因，并提供更深入的见解。本文引入了一种加权影响函数，通过求解凸二次规划问题为每个样本赋予定制权重。在此基础上，我们提出了一种软加权框架，允许细粒度的模型调整以应对过度反学习挑战。我们证明，提出的软加权方案具有普适性，可以无缝集成到大多数现有的反学习算法中。大量实验表明，在公平性和鲁棒性驱动的任务中，软加权方案在公平性/鲁棒性指标上显著优于硬加权方案，并缓解了效用指标的下降，从而增强了机器反学习算法作为有效矫正解决方案的有效性。', 'title_zh': '软加权机器卸载'}
{'arxiv_id': 'arXiv:2505.18777', 'title': 'HD-PiSSA: High-Rank Distributed Orthogonal Adaptation', 'authors': 'Yiding Wang, Fauxu meng, Xuefeng Zhang, Fan Jiang, Pingzhi Tang, Muhan Zhang', 'link': 'https://arxiv.org/abs/2505.18777', 'abstract': 'Existing parameter-efficient fine-tuning (PEFT) methods for large language models (LLMs), such as LoRA and PiSSA, constrain model updates to low-rank subspaces, limiting their expressiveness and leading to suboptimal performance on complex tasks. To address this, we introduce High-rank Distributed PiSSA (HD-PiSSA), a distributed PEFT approach that initializes orthogonal adapters across different devices and aggregates their delta updates collectively on W for fine-tuning. Unlike Data Parallel LoRA or PiSSA, which maintain identical adapters across all devices, HD-PiSSA assigns different principal components of the pre-trained weights to each GPU, significantly expanding the range of update directions. This results in over 16x higher effective updated ranks than data-parallel LoRA or PiSSA when fine-tuning on 8 GPUs with the same per-device adapter rank. Empirically, we evaluate HD-PiSSA across various challenging downstream tasks, including mathematics, code generation, and multi-task learning. In the multi-task setting, HD-PiSSA achieves average gains of 10.0 absolute points (14.63%) over LoRA and 4.98 points (6.60%) over PiSSA across 12 benchmarks, demonstrating its benefits from the extra optimization flexibility.', 'abstract_zh': '高秩分布式PiSSA（HD-PiSSA）：一种扩展更新方向的分布式参数高效微调方法', 'title_zh': 'HD-PiSSA: 高秩分布式正交适应'}
{'arxiv_id': 'arXiv:2505.18775', 'title': 'OmniGenBench: A Benchmark for Omnipotent Multimodal Generation across 50+ Tasks', 'authors': 'Jiayu Wang, Yang Jiao, Yue Yu, Tianwen Qian, Shaoxiang Chen, Jingjing Chen, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2505.18775', 'abstract': 'Recent breakthroughs in large multimodal models (LMMs), such as the impressive GPT-4o-Native, have demonstrated remarkable proficiency in following general-purpose instructions for image generation. However, current benchmarks often lack the necessary breadth and depth to fully evaluate the diverse capabilities of these models. To overcome this limitation, we introduce OmniGenBench, a novel and comprehensive benchmark meticulously designed to assess the instruction-following abilities of state-of-the-art LMMs across both perception-centric and cognition-centric dimensions. Our OmniGenBench includes 57 diverse sub-tasks grounded in real-world scenarios, systematically categorized according to the specific model capabilities they demand. For rigorous evaluation, we further employ a dual-mode protocol. This protocol utilizes off-the-shelf visual parsing tools for perception-centric tasks and a powerful LLM-based judger for cognition-centric tasks to assess the alignment between generated images and user instructions. Using OmniGenBench, we evaluate mainstream generative models, including prevalent models like GPT-4o, Gemini-2.0-Flash, and Seedream, and provide in-depth comparisons and analyses of their this http URL and data are available at this https URL.', 'abstract_zh': '近期大型多模态模型（LMMs）的突破，如令人印象深刻的GPT-4o-Native，在遵循通用指令进行图像生成方面展现了非凡的能力。然而，当前的基准测试往往缺乏足够的广度和深度，无法全面评估这些模型的多样能力。为克服这一限制，我们引入了OmniGenBench，这是一种新型且全面的基准测试，旨在从感知中心和认知中心两个维度评估最新LMMs的指令遵循能力。我们的OmniGenBench包括57个基于现实场景的多样化子任务，根据所需的具体模型能力系统分类。为确保严格的评估，我们进一步采用了一种双模式协议。该协议利用现成的视觉解析工具处理感知中心任务，并使用强大的LLM基础评判者评估认知中心任务，以衡量生成图像与用户指令的契合度。使用OmniGenBench，我们评估了主流生成模型，包括流行的GPT-4o、Gemini-2.0-Flash和Seedream等，并对其性能进行了深入比较和分析。相关数据可在以下链接获取：this https URL。', 'title_zh': 'OmniGenBench：多模态生成跨50余任务的基准测试'}
{'arxiv_id': 'arXiv:2505.18773', 'title': 'Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models', 'authors': 'Jamie Hayes, Ilia Shumailov, Christopher A. Choquette-Choo, Matthew Jagielski, George Kaissis, Katherine Lee, Milad Nasr, Sahra Ghalebikesabi, Niloofar Mireshghallah, Meenatchi Sundaram Mutu Selva Annamalai, Igor Shilov, Matthieu Meeus, Yves-Alexandre de Montjoye, Franziska Boenisch, Adam Dziedzic, A. Feder Cooper', 'link': 'https://arxiv.org/abs/2505.18773', 'abstract': "State-of-the-art membership inference attacks (MIAs) typically require training many reference models, making it difficult to scale these attacks to large pre-trained language models (LLMs). As a result, prior research has either relied on weaker attacks that avoid training reference models (e.g., fine-tuning attacks), or on stronger attacks applied to small-scale models and datasets. However, weaker attacks have been shown to be brittle - achieving close-to-arbitrary success - and insights from strong attacks in simplified settings do not translate to today's LLMs. These challenges have prompted an important question: are the limitations observed in prior work due to attack design choices, or are MIAs fundamentally ineffective on LLMs? We address this question by scaling LiRA - one of the strongest MIAs - to GPT-2 architectures ranging from 10M to 1B parameters, training reference models on over 20B tokens from the C4 dataset. Our results advance the understanding of MIAs on LLMs in three key ways: (1) strong MIAs can succeed on pre-trained LLMs; (2) their effectiveness, however, remains limited (e.g., AUC<0.7) in practical settings; and, (3) the relationship between MIA success and related privacy metrics is not as straightforward as prior work has suggested.", 'abstract_zh': '最先进的成员推断攻击（MIAs）通常需要训练许多参考模型，这使得将这些攻击扩展到大规模预训练语言模型（LLMs）变得困难。因此，前期研究要么依赖于无需训练参考模型（例如，微调攻击）的较弱攻击，要么在小型模型和数据集上应用较强的攻击。然而，较弱的攻击已被证明是脆弱的——能够实现接近任意的成功率——而在简化环境下从强攻击中获得的见解并不适用于今天的LLMs。这些挑战促使了一个重要问题：前期工作中的局限性是由于攻击设计选择，还是MIAs在LLMs上根本无效？我们通过将LiRA——一种最强的MIA之一——扩展到参数范围从10M到1B的GPT-2架构，并在C4数据集中超过20B个Token上训练参考模型，来回答这个问题。我们的结果从三个方面推进了对LLMs上MIAs的理解：（1）强大的MIAs可以在预训练的LLMs上取得成功；（2）然而，其有效性在实际应用中仍然受到限制（例如AUC<0.7）；（3）MIAs的成功与其相关隐私指标之间的关系并没有先前研究所说的那样简单。', 'title_zh': '大规模数据集和中等到大规模语言模型上的强成员推断攻击'}
{'arxiv_id': 'arXiv:2505.18766', 'title': 'StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations', 'authors': 'Yanjie Li, Wenxuan Zhang, Xinqi Lyu, Yihao Liu, Bin Xiao', 'link': 'https://arxiv.org/abs/2505.18766', 'abstract': "Recently, text-to-image diffusion models have been widely used for style mimicry and personalized customization through methods such as DreamBooth and Textual Inversion. This has raised concerns about intellectual property protection and the generation of deceptive content. Recent studies, such as Glaze and Anti-DreamBooth, have proposed using adversarial noise to protect images from these attacks. However, recent purification-based methods, such as DiffPure and Noise Upscaling, have successfully attacked these latest defenses, showing the vulnerabilities of these methods. Moreover, present methods show limited transferability across models, making them less effective against unknown text-to-image models. To address these issues, we propose a novel anti-mimicry method, StyleGuard. We propose a novel style loss that optimizes the style-related features in the latent space to make it deviate from the original image, which improves model-agnostic transferability. Additionally, to enhance the perturbation's ability to bypass diffusion-based purification, we designed a novel upscale loss that involves ensemble purifiers and upscalers during training. Extensive experiments on the WikiArt and CelebA datasets demonstrate that StyleGuard outperforms existing methods in robustness against various transformations and purifications, effectively countering style mimicry in various models. Moreover, StyleGuard is effective on different style mimicry methods, including DreamBooth and Textual Inversion.", 'abstract_zh': '一种新的防模仿方法：StyleGuard', 'title_zh': 'StyleGuard：通过风格扰动防止基于文本到图像模型的风格模仿攻击'}
{'arxiv_id': 'arXiv:2505.18762', 'title': 'Towards an automatic method for generating topical vocabulary test forms for specific reading passages', 'authors': "Michael Flor, Zuowei Wang, Paul Deane, Tenaha O'Reilly", 'link': 'https://arxiv.org/abs/2505.18762', 'abstract': "Background knowledge is typically needed for successful comprehension of topical and domain specific reading passages, such as in the STEM domain. However, there are few automated measures of student knowledge that can be readily deployed and scored in time to make predictions on whether a given student will likely be able to understand a specific content area text. In this paper, we present our effort in developing K-tool, an automated system for generating topical vocabulary tests that measure students' background knowledge related to a specific text. The system automatically detects the topic of a given text and produces topical vocabulary items based on their relationship with the topic. This information is used to automatically generate background knowledge forms that contain words that are highly related to the topic and words that share similar features but do not share high associations to the topic. Prior research indicates that performance on such tasks can help determine whether a student is likely to understand a particular text based on their knowledge state. The described system is intended for use with middle and high school student population of native speakers of English. It is designed to handle single reading passages and is not dependent on any corpus or text collection. In this paper, we describe the system architecture and present an initial evaluation of the system outputs.", 'abstract_zh': '背景知识对于成功理解主题和特定领域的阅读 passages（如STEM领域）通常是必要的。然而，目前缺乏能够在及时评估学生知识状态后预测学生是否能够理解特定内容领域文本的自动化评估措施。本文我们介绍了开发K-tool的努力，这是一种自动化系统，用于生成与特定文本相关的主题词汇测验，以测量学生的背景知识。该系统自动检测文本的主题，并基于词汇与主题的关系生成相关词汇项。这些信息用于自动生成包含高度相关主题词汇和具有相似特征但与主题关联不强的词汇的背景知识测验。先前的研究表明，此类任务的表现可以帮助确定学生是否有可能基于其知识状态理解特定文本。该系统旨在用于英语为母语的中学生和高中生群体，可处理单篇阅读文本，不依赖于任何语料库或文本集合。本文描述了系统的架构，并介绍了系统的初步评估结果。', 'title_zh': '面向特定阅读 passages 的主题词汇测试题自动生成方法'}
{'arxiv_id': 'arXiv:2505.18761', 'title': 'How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark', 'authors': 'Minglai Yang, Ethan Huang, Liang Zhang, Mihai Surdeanu, William Wang, Liangming Pan', 'link': 'https://arxiv.org/abs/2505.18761', 'abstract': "We introduce Grade School Math with Distracting Context (GSM-DC), a synthetic benchmark to evaluate Large Language Models' (LLMs) reasoning robustness against systematically controlled irrelevant context (IC). GSM-DC constructs symbolic reasoning graphs with precise distractor injections, enabling rigorous, reproducible evaluation. Our experiments demonstrate that LLMs are significantly sensitive to IC, affecting both reasoning path selection and arithmetic accuracy. Additionally, training models with strong distractors improves performance in both in-distribution and out-of-distribution scenarios. We further propose a stepwise tree search guided by a process reward model, which notably enhances robustness in out-of-distribution conditions.", 'abstract_zh': '我们介绍了一种具有干扰背景的分级学校数学合成基准（GSM-DC），用于评估大型语言模型（LLMs）在系统性控制无关背景（IC）下的推理稳健性。GSM-DC 通过精确的干扰注入构建符号推理图，使评估更加严谨和可 reproduction。我们的实验表明，LLMs 对 IC 显著敏感，影响推理路径选择和算术准确性。此外，使用强干扰进行模型训练提高了模型在分布内和分布外场景下的性能。我们还提出了一种基于过程奖励模型的逐步树搜索方法，该方法在分布外条件下显著增强了稳健性。', 'title_zh': 'LLM推理受无关背景干扰的方式：基于受控基准的分析'}
{'arxiv_id': 'arXiv:2505.18755', 'title': 'Smart Energy Guardian: A Hybrid Deep Learning Model for Detecting Fraudulent PV Generation', 'authors': 'Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang', 'link': 'https://arxiv.org/abs/2505.18755', 'abstract': 'With the proliferation of smart grids, smart cities face growing challenges due to cyber-attacks and sophisticated electricity theft behaviors, particularly in residential photovoltaic (PV) generation systems. Traditional Electricity Theft Detection (ETD) methods often struggle to capture complex temporal dependencies and integrating multi-source data, limiting their effectiveness. In this work, we propose an efficient ETD method that accurately identifies fraudulent behaviors in residential PV generation, thus ensuring the supply-demand balance in smart cities. Our hybrid deep learning model, combining multi-scale Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, excels in capturing both short-term and long-term temporal dependencies. Additionally, we introduce a data embedding technique that seamlessly integrates time-series data with discrete temperature variables, enhancing detection robustness. Extensive simulation experiments using real-world data validate the effectiveness of our approach, demonstrating significant improvements in the accuracy of detecting sophisticated energy theft activities, thereby contributing to the stability and fairness of energy systems in smart cities.', 'abstract_zh': '随着智能电网的普及，智能城市面临着日益严重的网络安全攻击和 sophisticated 电力窃取行为的挑战，特别是在住宅光伏（PV）发电系统中。传统的电力窃取检测（ETD）方法往往难以捕捉复杂的时序依赖性和多源数据的集成，限制了其有效性。在本工作中，我们提出了一种有效的ETD方法，能够准确识别住宅PV发电中的欺诈行为，从而确保智能城市的供需平衡。我们的混合深度学习模型结合了多尺度卷积神经网络（CNN）、长短期记忆网络（LSTM）和Transformer，能够在捕捉短时和长时依赖性方面表现出色。此外，我们引入了一种数据嵌入技术，无缝地将时间序列数据与离散温度变量集成，提高了检测的稳健性。通过使用真实数据进行广泛的仿真实验，验证了我们方法的有效性，展示了在检测复杂能源窃取活动方面显著的准确性提升，从而为智能城市的能源系统稳定性和公平性做出了贡献。', 'title_zh': '智能能量守护者：一种检测欺诈性光伏发电的混合深度学习模型'}
{'arxiv_id': 'arXiv:2505.18750', 'title': 'Agent-Based Decentralized Energy Management of EV Charging Station with Solar Photovoltaics via Multi-Agent Reinforcement Learning', 'authors': 'Jiarong Fan, Chenghao Huang, Hao Wang', 'link': 'https://arxiv.org/abs/2505.18750', 'abstract': 'In the pursuit of energy net zero within smart cities, transportation electrification plays a pivotal role. The adoption of Electric Vehicles (EVs) keeps increasing, making energy management of EV charging stations critically important. While previous studies have managed to reduce energy cost of EV charging while maintaining grid stability, they often overlook the robustness of EV charging management against uncertainties of various forms, such as varying charging behaviors and possible faults in faults in some chargers. To address the gap, a novel Multi-Agent Reinforcement Learning (MARL) approach is proposed treating each charger to be an agent and coordinate all the agents in the EV charging station with solar photovoltaics in a more realistic scenario, where system faults may occur. A Long Short-Term Memory (LSTM) network is incorporated in the MARL algorithm to extract temporal features from time-series. Additionally, a dense reward mechanism is designed for training the agents in the MARL algorithm to improve EV charging experience. Through validation on a real-world dataset, we show that our approach is robust against system uncertainties and faults and also effective in minimizing EV charging costs and maximizing charging service satisfaction.', 'abstract_zh': '在智能城市中追求能源净零的进程中，交通运输 electrification 起到关键作用。电动汽车（EVs）的 adoption 持续增加，使得 EV 充电站的能源管理变得至关重要。尽管以往的研究能够在保持电网稳定的同时降低 EV 充电成本，但它们往往忽视了各种不确定性（如不同的充电行为和某些充电桩可能出现的故障）对 EV 充电管理健壮性的影响。为填补这一空白，本文提出了一种新颖的多智能体强化学习（MARL）方法，将每个充电桩视为一个智能体，并在可能发生系统故障的更现实场景中，通过结合太阳能光伏与所有智能体进行协调。此外，本文在 MARL 算法中引入了长短期记忆（LSTM）网络以提取时间序列中的时序特征，并设计了密集奖励机制以提高智能体的训练效果，从而改善 EV 充电体验。通过在真实数据集上的验证，我们证明了该方法能够有效应对系统不确定性与故障，同时最大限度地减少 EV 充电成本并增加充电服务满意度。', 'title_zh': '基于代理的电动汽车充电站太阳能光伏 decentralized 能源管理方法：多代理强化学习_approach'}
{'arxiv_id': 'arXiv:2505.18747', 'title': 'Season-Independent PV Disaggregation Using Multi-Scale Net Load Temporal Feature Extraction and Weather Factor Fusion', 'authors': 'Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang', 'link': 'https://arxiv.org/abs/2505.18747', 'abstract': 'With the advancement of energy Internet and energy system integration, the increasing adoption of distributed photovoltaic (PV) systems presents new challenges on smart monitoring and measurement for utility companies, particularly in separating PV generation from net electricity load. Existing methods struggle with feature extraction from net load and capturing the relevance between weather factors. This paper proposes a PV disaggregation method that integrates Hierarchical Interpolation (HI) and multi-head self-attention mechanisms. By using HI to extract net load features and multi-head self-attention to capture the complex dependencies between weather factors, the method achieves precise PV generation predictions. Simulation experiments demonstrate the effectiveness of the proposed method in real-world data, supporting improved monitoring and management of distributed energy systems.', 'abstract_zh': '随着能源互联网和能源系统集成的发展，分布式光伏系统（PV）的广泛应用给电力公司带来了新的智能监测和计量挑战，特别是在分离光伏发电与净电量负荷方面。现有方法在从净负荷中提取特征和捕捉天气因素的相关性方面存在困难。本文提出了一种结合分层插值（HI）和多头自注意力机制的光伏解耦方法。通过使用HI提取净负荷特征和多头自注意力捕捉天气因素之间的复杂依赖关系，该方法实现了精确的光伏发电预测。仿真实验表明，所提出的方法在实际数据中的有效性，支持分布式能源系统的改进监控和管理。', 'title_zh': '独立于季节的光伏功率解耦利用多尺度净负荷时序特征提取和气象因素融合'}
{'arxiv_id': 'arXiv:2505.18741', 'title': 'MoMBS: Mixed-order minibatch sampling enhances model training from diverse-quality images', 'authors': 'Han Li, Hu Han, S. Kevin Zhou', 'link': 'https://arxiv.org/abs/2505.18741', 'abstract': 'Natural images exhibit label diversity (clean vs. noisy) in noisy-labeled image classification and prevalence diversity (abundant vs. sparse) in long-tailed image classification. Similarly, medical images in universal lesion detection (ULD) exhibit substantial variations in image quality, encompassing attributes such as clarity and label correctness. How to effectively leverage training images with diverse qualities becomes a problem in learning deep models. Conventional training mechanisms, such as self-paced curriculum learning (SCL) and online hard example mining (OHEM), relieve this problem by reweighting images with high loss values. Despite their success, these methods still confront two challenges: (i) the loss-based measure of sample hardness is imprecise, preventing optimum handling of different cases, and (ii) there exists under-utilization in SCL or over-utilization OHEM with the identified hard samples. To address these issues, this paper revisits the minibatch sampling (MBS), a technique widely used in deep network training but largely unexplored concerning the handling of diverse-quality training samples. We discover that the samples within a minibatch influence each other during training; thus, we propose a novel Mixed-order Minibatch Sampling (MoMBS) method to optimize the use of training samples with diverse qualities. MoMBS introduces a measure that takes both loss and uncertainty into account to surpass a sole reliance on loss and allows for a more refined categorization of high-loss samples by distinguishing them as either poorly labeled and under represented or well represented and overfitted. We prioritize under represented samples as the main gradient contributors in a minibatch and keep them from the negative influences of poorly labeled or overfitted samples with a mixed-order minibatch sampling design.', 'abstract_zh': '自然图像在嘈噪声标注图像分类中表现出标签多样性（干净 vs. 噪声）的特点，在长尾图像分类中表现出丰度多样性（丰富 vs. 稀少）的特点。同样，在普遍病灶检测中，医学图像在图像质量方面表现出显著差异，涵盖清晰度和标签正确性等属性。如何有效利用具有不同质量的训练图像成为学习深度模型中的一个难题。传统的训练机制，如自步曲案课程学习（SCL）和在线难例挖掘（OHEM），通过重新加权高损失值的图像来缓解这一问题。尽管取得了成功，这些方法仍面临两个挑战：（i）基于损失的样本难度衡量不够准确，阻碍了对不同情况的最优处理，（ii）SCL中存在欠利用或OHEM中存在过利用识别出的难例。为解决这些问题，本文重新审视了小批量采样（MBS）这一在深度网络训练中广泛应用但对多样质训练样本处理较少探讨的技术。我们发现小批量内的样本在训练过程中互相影响，因此提出了一种新颖的混合顺序小批量采样（MoMBS）方法以优化具有不同质量的训练样本的使用。MoMBS引入了一个同时考虑损失和不确定性的度量，超越了单纯依赖损失的做法，并通过区分低标签质量和欠表示与良好表示和过拟合的高损失样本来实现更精细的分类。在小批量中，我们优先考虑欠表示样本作为主要梯度贡献者，并通过混合顺序小批量采样设计防止其受到低标签质量和过拟合样本的负面影响。', 'title_zh': 'MoMBS: 混合阶数 minibatch 抽样增强多样质量图像的模型训练'}
{'arxiv_id': 'arXiv:2505.18728', 'title': 'Message-Passing State-Space Models: Improving Graph Learning with Modern Sequence Modeling', 'authors': 'Andrea Ceni, Alessio Gravina, Claudio Gallicchio, Davide Bacciu, Carola-Bibiane Schonlieb, Moshe Eliasof', 'link': 'https://arxiv.org/abs/2505.18728', 'abstract': 'The recent success of State-Space Models (SSMs) in sequence modeling has motivated their adaptation to graph learning, giving rise to Graph State-Space Models (GSSMs). However, existing GSSMs operate by applying SSM modules to sequences extracted from graphs, often compromising core properties such as permutation equivariance, message-passing compatibility, and computational efficiency. In this paper, we introduce a new perspective by embedding the key principles of modern SSM computation directly into the Message-Passing Neural Network framework, resulting in a unified methodology for both static and temporal graphs. Our approach, MP-SSM, enables efficient, permutation-equivariant, and long-range information propagation while preserving the architectural simplicity of message passing. Crucially, MP-SSM enables an exact sensitivity analysis, which we use to theoretically characterize information flow and evaluate issues like vanishing gradients and over-squashing in the deep regime. Furthermore, our design choices allow for a highly optimized parallel implementation akin to modern SSMs. We validate MP-SSM across a wide range of tasks, including node classification, graph property prediction, long-range benchmarks, and spatiotemporal forecasting, demonstrating both its versatility and strong empirical performance.', 'abstract_zh': '最近状态空间模型在序列建模中的成功激发了其在图学习中的应用，产生了图状态空间模型（GSSMs）。然而，现有的GSSMs往往通过将状态空间模块应用于从图中抽取的序列来进行操作，这往往会牺牲置换等变性、消息传递兼容性和计算效率等核心属性。在本文中，我们通过将现代状态空间计算的关键原则直接嵌入到消息传递神经网络框架中，提出了一种统一的方法来处理静态和动态图。我们的方法MP-SSM能够在保持消息传递架构简洁性的同时，实现高效、置换等变且长程的信息传播。 crucially, MP-SSM 允许进行精确的灵敏度分析，我们利用这一特性从理论上表征信息流动并评估深层情况下的梯度消失和过度挤压等问题。此外，我们的设计选择使得MP-SSM 具有类似现代状态空间模型的高效并行实现。我们通过一系列任务验证了MP-SSM 的性能，包括节点分类、图属性预测、长程基准测试和时空预测，展示了其灵活性和强大的实证效果。', 'title_zh': '消息传递状态空间模型：借助现代序列建模改进图学习'}
{'arxiv_id': 'arXiv:2505.18724', 'title': 'LoTA-QAF: Lossless Ternary Adaptation for Quantization-Aware Fine-Tuning', 'authors': 'Junyu Chen, Junzhuo Li, Zhen Peng, Wenjie Wang, Yuxiang Ren, Long Shi, Xuming Hu', 'link': 'https://arxiv.org/abs/2505.18724', 'abstract': 'Quantization and fine-tuning are crucial for deploying large language models (LLMs) on resource-constrained edge devices. However, fine-tuning quantized models presents significant challenges, primarily stemming from: First, the mismatch in data types between the low-precision quantized weights (e.g., 4-bit) and the high-precision adaptation weights (e.g., 16-bit). This mismatch limits the computational efficiency advantage offered by quantized weights during inference. Second, potential accuracy degradation when merging these high-precision adaptation weights into the low-precision quantized weights, as the adaptation weights often necessitate approximation or truncation. Third, as far as we know, no existing methods support the lossless merging of adaptation while adjusting all quantized weights. To address these challenges, we introduce lossless ternary adaptation for quantization-aware fine-tuning (LoTA-QAF). This is a novel fine-tuning method specifically designed for quantized LLMs, enabling the lossless merging of ternary adaptation weights into quantized weights and the adjustment of all quantized weights. LoTA-QAF operates through a combination of: i) A custom-designed ternary adaptation (TA) that aligns ternary weights with the quantization grid and uses these ternary weights to adjust quantized weights. ii) A TA-based mechanism that enables the lossless merging of adaptation weights. iii) Ternary signed gradient descent (t-SignSGD) for updating the TA weights. We apply LoTA-QAF to Llama-3.1/3.3 and Qwen-2.5 model families and validate its effectiveness on several downstream tasks. On the MMLU benchmark, our method effectively recovers performance for quantized models, surpassing 16-bit LoRA by up to 5.14\\%. For task-specific fine-tuning, 16-bit LoRA achieves superior results, but LoTA-QAF still outperforms other methods.', 'abstract_zh': '量化和微调对于在资源受限的边缘设备上部署大型语言模型（LLMs）至关重要。然而，量化模型的微调面临着重大挑战，主要源自以下几点：首先，低精度量化权重（如4位）与高精度适应权重（如16位）之间数据类型的不匹配，这限制了在推理过程中由量化权重提供的计算效率优势。其次，在将高精度适应权重合并到低精度量化权重中时可能出现的精度下降，因为适应权重常常需要近似或截断。第三，据我们所知，目前没有任何方法在调整所有量化权重的同时支持无损合并适应权重。为应对这些挑战，我们介绍了一种用于感知量化微调的无损三值适应方法（LoTA-QAF）。这是一种专为量化LLMs设计的新微调方法，能够将三值适应权重无损地合并到量化权重中，并调整所有量化权重。LoTA-QAF通过以下方式运作：i) 自定义设计的三值适应（TA），将三值权重与量化网格对齐，并使用这些三值权重调整量化权重。ii) 基于TA的机制，使得适应权重的无损合并成为可能。iii) 三值符号梯度下降（t-SignSGD）用于更新TA权重。我们将LoTA-QAF应用于Llama-3.1/3.3和Qwen-2.5模型系列，并在多个下游任务中验证了其有效性。在MMLU基准测试中，我们的方法有效地恢复了量化模型的性能，超越了16位LoRA最多5.14%。对于任务特定的微调，16位LoRA表现更优，但LoTA-QAF仍优于其他方法。', 'title_zh': '无损三元适应的量化感知微调'}
{'arxiv_id': 'arXiv:2505.18722', 'title': "Evaluating the Usefulness of Non-Diagnostic Speech Data for Developing Parkinson's Disease Classifiers", 'authors': 'Terry Yi Zhong, Esther Janse, Cristian Tejedor-Garcia, Louis ten Bosch, Martha Larson', 'link': 'https://arxiv.org/abs/2505.18722', 'abstract': "Speech-based Parkinson's disease (PD) detection has gained attention for its automated, cost-effective, and non-intrusive nature. As research studies usually rely on data from diagnostic-oriented speech tasks, this work explores the feasibility of diagnosing PD on the basis of speech data not originally intended for diagnostic purposes, using the Turn-Taking (TT) dataset. Our findings indicate that TT can be as useful as diagnostic-oriented PD datasets like PC-GITA. We also investigate which specific dataset characteristics impact PD classification performance. The results show that concatenating audio recordings and balancing participants' gender and status distributions can be beneficial. Cross-dataset evaluation reveals that models trained on PC-GITA generalize poorly to TT, whereas models trained on TT perform better on PC-GITA. Furthermore, we provide insights into the high variability across folds, which is mainly due to large differences in individual speaker performance.", 'abstract_zh': '基于语音的帕金森病（PD）检测因其实现自动化、成本效益高且非侵入性而引起了关注。本研究探讨了使用非诊断目的的转换取向（TT）数据集进行帕金森病诊断的可能性，发现TT数据集与PC-GITA等诊断导向的数据集具有相似的诊断价值。研究还分析了哪些特定的数据集特征会影响PD分类性能。结果表明，将音频记录片段串联使用并平衡参与者性别和状态分布可能有助于提高性能。跨数据集评估表明，基于PC-GITA训练的模型在TT数据集上的泛化能力较差，而基于TT数据集训练的模型在PC-GITA数据集上的表现更好。此外，研究还揭示了不同折间高变异性的主要原因在于个体说话人表现差异较大。', 'title_zh': '评估非诊断性语音数据在帕金森病分类器开发中的 usefulness'}
{'arxiv_id': 'arXiv:2505.18720', 'title': 'Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization', 'authors': 'Meng Li, Guangda Huzhang, Haibo Zhang, Xiting Wang, Anxiang Zeng', 'link': 'https://arxiv.org/abs/2505.18720', 'abstract': "Direct Preference Optimization (DPO) has emerged as a promising framework for aligning Large Language Models (LLMs) with human preferences by directly optimizing the log-likelihood difference between chosen and rejected responses. However, existing methods assign equal importance to all tokens in the response, while humans focus on more meaningful parts. This leads to suboptimal preference optimization, as irrelevant or noisy tokens disproportionately influence DPO loss. To address this limitation, we propose \\textbf{O}ptimal \\textbf{T}ransport-based token weighting scheme for enhancing direct \\textbf{P}reference \\textbf{O}ptimization (OTPO). By emphasizing semantically meaningful token pairs and de-emphasizing less relevant ones, our method introduces a context-aware token weighting scheme that yields a more contrastive reward difference estimate. This adaptive weighting enhances reward stability, improves interpretability, and ensures that preference optimization focuses on meaningful differences between responses. Extensive experiments have validated OTPO's effectiveness in improving instruction-following ability across various settings\\footnote{Code is available at this https URL.}.", 'abstract_zh': '基于最优运输的令牌加权方案以增强直接偏好优化（OTPO）', 'title_zh': '基于最优运输的token权重方案以增强偏好优化'}
{'arxiv_id': 'arXiv:2505.18719', 'title': 'VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning', 'authors': 'Guanxing Lu, Wenkai Guo, Chubin Zhang, Yuheng Zhou, Haonan Jiang, Zifeng Gao, Yansong Tang, Ziwei Wang', 'link': 'https://arxiv.org/abs/2505.18719', 'abstract': 'Recent high-capacity vision-language-action (VLA) models have demonstrated impressive performance on a range of robotic manipulation tasks by imitating human demonstrations. However, exploiting offline data with limited visited states will cause execution failure in out-of-distribution scenarios. Intuitively, an exploration-based method that improves on online collected data at test time could address this limitation. We present VLA-RL, an algorithmic and systematic framework that leverages online reinforcement learning (RL) to improve pretrained auto-regressive VLAs in downstream tasks. Within a unified perspective, we first introduce a trajectory-level RL formulation for auto-regressive VLA training, which models general robotic manipulation trajectory as multi-modal multi-turn conversation. To address the challenge of sparse rewards, we fine-tune a pretrained vision-language model as a robotic process reward model, which is trained on pseudo reward labels annotated on automatically extracted task segments. To scale up, we identify several implementation findings that improve the stability and efficiency including curriculum selection strategy, GPU-balanced vectorized environments, batch decoding, and critic warmup. VLA-RL enables OpenVLA-7B to surpass the strongest finetuned baseline by 4.5% on 40 challenging robotic manipulation tasks in LIBERO, and even matches the performance of advanced commercial models such as $\\pi_0$-FAST. Notably, we observe that VLA-RL benefits from increased test-time optimization, indicating an early spark of inference scaling laws in robotics.', 'abstract_zh': 'Recent High-Capacity Vision-Language-Action (VLA) Models Leveraging Online RL for Improved Robotic Manipulation Tasks', 'title_zh': 'VLA-RL：面向规模化强化学习的精湛且通用的机器人 manipulation'}
{'arxiv_id': 'arXiv:2505.18713', 'title': 'Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer', 'authors': 'Guodong Du, Zitao Fang, Jing Li, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai Liu, Min Zhang', 'link': 'https://arxiv.org/abs/2505.18713', 'abstract': 'Foundation models and their checkpoints have significantly advanced deep learning, boosting performance across various applications. However, fine-tuned models often struggle outside their specific domains and exhibit considerable redundancy. Recent studies suggest that combining a pruned fine-tuned model with the original pre-trained model can mitigate forgetting, reduce interference when merging model parameters across tasks, and improve compression efficiency. In this context, developing an effective pruning strategy for fine-tuned models is crucial. Leveraging the advantages of the task vector mechanism, we preprocess fine-tuned models by calculating the differences between them and the original model. Recognizing that different task vector subspaces contribute variably to model performance, we introduce a novel method called Neural Parameter Search (NPS-Pruning) for slimming down fine-tuned models. This method enhances pruning efficiency by searching through neural parameters of task vectors within low-rank subspaces. Our method has three key applications: enhancing knowledge transfer through pairwise model interpolation, facilitating effective knowledge fusion via model merging, and enabling the deployment of compressed models that retain near-original performance while significantly reducing storage costs. Extensive experiments across vision, NLP, and multi-modal benchmarks demonstrate the effectiveness and robustness of our approach, resulting in substantial performance gains. The code is publicly available at: this https URL.', 'abstract_zh': '基于预训练模型的剪枝策略：提高微调模型的效率与压缩性能', 'title_zh': '神经参数搜索以获得更瘦的微调模型和更好的迁移学习'}
{'arxiv_id': 'arXiv:2505.18710', 'title': 'GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis', 'authors': 'Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin', 'link': 'https://arxiv.org/abs/2505.18710', 'abstract': 'The Retrieval-Augmented Generation (RAG) framework introduces a retrieval module to dynamically inject retrieved information into the input context of large language models (LLMs), and has demonstrated significant success in various NLP tasks. However, the current study points out that there is a preference gap between retrievers and LLMs in the RAG framework, which limit the further improvement of system performance. Some highly relevant passages may interfere with LLM reasoning because they contain complex or contradictory information; while some indirectly related or even inaccurate content may help LLM generate more accurate answers by providing suggestive information or logical clues. To solve this, we propose GainRAG, a novel approach that aligns the retriever\'s and LLM\'s preferences by defining a new metric, "gain", which measure how well an input passage contributes to correct outputs. Specifically, we propose a method to estimate these gain signals and train a middleware that aligns the preferences of the retriever and the LLM using only limited data. In addition, we introduce a pseudo-passage strategy to mitigate degradation. The experimental results on 6 datasets verify the effectiveness of GainRAG.', 'abstract_zh': 'GainRAG：通过定义“增益”度量来对齐检索器和大型语言模型的偏好', 'title_zh': 'GainRAG：通过Gain信号合成实现检索增强生成中的偏好对齐'}
{'arxiv_id': 'arXiv:2505.18709', 'title': 'Improving Bangla Linguistics: Advanced LSTM, Bi-LSTM, and Seq2Seq Models for Translating Sylheti to Modern Bangla', 'authors': 'Sourav Kumar Das, Md. Julkar Naeen, MD. Jahidul Islam, Md. Anisul Haque Sajeeb, Narayan Ranjan Chakraborty, Mayen Uddin Mojumdar', 'link': 'https://arxiv.org/abs/2505.18709', 'abstract': "Bangla or Bengali is the national language of Bangladesh, people from different regions don't talk in proper Bangla. Every division of Bangladesh has its own local language like Sylheti, Chittagong etc. In recent years some papers were published on Bangla language like sentiment analysis, fake news detection and classifications, but a few of them were on Bangla languages. This research is for the local language and this particular paper is on Sylheti language. It presented a comprehensive system using Natural Language Processing or NLP techniques for translating Pure or Modern Bangla to locally spoken Sylheti Bangla language. Total 1200 data used for training 3 models LSTM, Bi-LSTM and Seq2Seq and LSTM scored the best in performance with 89.3% accuracy. The findings of this research may contribute to the growth of Bangla NLP researchers for future more advanced innovations.", 'abstract_zh': 'Bangla或孟加拉语是孟加拉国的官方语言，不同地区的人们并不使用标准孟加拉语。孟加拉国的每个地区都有自己的地方语言，如锡莱希语、 Chattagram语等。近年来，关于孟加拉语的研究论文有所发表，涉及情感分析、虚假新闻检测和分类等领域，但其中对地方语言的研究较少。本研究专注于地方语言，本文特别关注锡莱希语。研究使用自然语言处理或NLP技术，构建了一个综合系统，用于将纯孟加拉语或现代孟加拉语翻译成当地口语锡莱希语。共使用1200条数据训练了3个模型（LSTM、Bi-LSTM和Seq2Seq），其中LSTM在性能上表现最佳，准确率达到89.3%。本研究的发现可能有助于促进孟加拉语NLP研究人员未来更多的先进创新。', 'title_zh': '改进孟加拉语研究：从西莱蒂到现代孟加拉语的高级LSTM、双向LSTM和Seq2Seq模型翻译'}
{'arxiv_id': 'arXiv:2505.18708', 'title': 'A General Knowledge Injection Framework for ICD Coding', 'authors': 'Xu Zhang, Kun Zhang, Wenxin Ma, Rongsheng Wang, Chenxu Wu, Yingtai Li, S. Kevin Zhou', 'link': 'https://arxiv.org/abs/2505.18708', 'abstract': 'ICD Coding aims to assign a wide range of medical codes to a medical text document, which is a popular and challenging task in the healthcare domain. To alleviate the problems of long-tail distribution and the lack of annotations of code-specific evidence, many previous works have proposed incorporating code knowledge to improve coding performance. However, existing methods often focus on a single type of knowledge and design specialized modules that are complex and incompatible with each other, thereby limiting their scalability and effectiveness. To address this issue, we propose GKI-ICD, a novel, general knowledge injection framework that integrates three key types of knowledge, namely ICD Description, ICD Synonym, and ICD Hierarchy, without specialized design of additional modules. The comprehensive utilization of the above knowledge, which exhibits both differences and complementarity, can effectively enhance the ICD coding performance. Extensive experiments on existing popular ICD coding benchmarks demonstrate the effectiveness of GKI-ICD, which achieves the state-of-the-art performance on most evaluation metrics. Code is available at this https URL.', 'abstract_zh': 'ICD编码旨在为医疗文本文档分配广泛的医学代码，这是医疗领域一个流行且具有挑战性的任务。为了缓解长尾分布和代码特定证据标注不足的问题，许多先前的工作提出了结合代码知识以提高编码性能的方法。然而，现有方法通常关注单类型的知识，并设计专门的模块，这些模块复杂且彼此不兼容，从而限制了它们的可扩展性和有效性。为解决这一问题，我们提出了一种新颖的一般知识注入框架GKI-ICD，该框架整合了ICD描述、ICD同义词和ICD层级三种关键类型的知识，而不需要设计额外的专门模块。综合利用这些知识，虽然它们之间存在差异和互补性，但可以有效提高ICD编码性能。在现有广泛的ICD编码基准上的广泛实验展示了GKI-ICD的有效性，该方法在大多数评估指标上达到了最先进的性能。代码可在以下链接获得：this https URL。', 'title_zh': 'ICD编码的一般知识注入框架'}
{'arxiv_id': 'arXiv:2505.18706', 'title': 'Steering LLM Reasoning Through Bias-Only Adaptation', 'authors': 'Viacheslav Sinii, Alexey Gorbatovski, Artem Cherepanov, Boris Shaposhnikov, Nikita Balagansky, Daniil Gavrilov', 'link': 'https://arxiv.org/abs/2505.18706', 'abstract': 'Recent work on reasoning-oriented language models, exemplified by o1-like systems, suggests that reinforcement-learning (RL) finetuning does not create new capabilities but instead strengthens reasoning patterns already latent in the pretrained network. We test this claim by training steering vectors: layer-wise biases that additively amplify selected hidden features while leaving all original weights unchanged. Experiments on four base models across the GSM8K and MATH benchmarks show that steering vectors recover, and in several cases exceed, the accuracy of fully-tuned counterparts. This result supports the view that the required reasoning skills pre-exist in the base model. Further, logit-lens analysis reveals that the trained vectors consistently boost token groups linked to structured languages and logical connectors, providing an interpretable account that aligns with the demands of quantitative reasoning tasks.', 'abstract_zh': '近期关于基于推理的语言模型的研究，以o1-like系统为例，表明强化学习（RL）微调并没有创造新的能力，而是加强了预训练网络中已经存在推理模式。通过训练引导向量（层wise偏置）进行测试：这些向量在不改变原始权重的情况下，累加放大选定的隐藏特征。在GSM8K和MATH基准测试上的四项基础模型实验表明，引导向量恢复并超过了完全微调版本的准确率。这一结果支持了所需推理技能已经在基础模型中存在这一观点。进一步的logit-lens分析显示，训练后的向量始终提升与结构化语言和逻辑连接词相关的词组，这与定量推理任务的需求相一致，提供了可解释的说明。', 'title_zh': '通过偏见唯一适应引导大语言模型推理'}
{'arxiv_id': 'arXiv:2505.18700', 'title': 'GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains', 'authors': 'Chun Wang, Xiaoran Pan, Zihao Pan, Haofan Wang, Yiren Song', 'link': 'https://arxiv.org/abs/2505.18700', 'abstract': 'Recent advances in Visual Language Models (VLMs) have demonstrated exceptional performance in visual reasoning tasks. However, geo-localization presents unique challenges, requiring the extraction of multigranular visual cues from images and their integration with external world knowledge for systematic reasoning. Current approaches to geo-localization tasks often lack robust reasoning mechanisms and explainability, limiting their effectiveness. To address these limitations, we propose the Geo Reason Enhancement (GRE) Suite, a novel framework that augments VLMs with structured reasoning chains for accurate and interpretable location inference. The GRE Suite is systematically developed across three key dimensions: dataset, model, and benchmark. First, we introduce GRE30K, a high-quality geo-localization reasoning dataset designed to facilitate fine-grained visual and contextual analysis. Next, we present the GRE model, which employs a multi-stage reasoning strategy to progressively infer scene attributes, local details, and semantic features, thereby narrowing down potential geographic regions with enhanced precision. Finally, we construct the Geo Reason Evaluation Benchmark (GREval-Bench), a comprehensive evaluation framework that assesses VLMs across diverse urban, natural, and landmark scenes to measure both coarse-grained (e.g., country, continent) and fine-grained (e.g., city, street) localization performance. Experimental results demonstrate that GRE significantly outperforms existing methods across all granularities of geo-localization tasks, underscoring the efficacy of reasoning-augmented VLMs in complex geographic inference. Code and data will be released at this https URL.', 'abstract_zh': 'Recent Advances in Geo-Reason Enhancement for Visual Language Models', 'title_zh': 'GE地点套件：通过微调的视觉-语言模型和增强的推理链进行地理定位推断'}
{'arxiv_id': 'arXiv:2505.18697', 'title': 'Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study', 'authors': 'Ziyang Cheng, Zhixun Li, Yuhan Li, Yixin Song, Kangyi Zhao, Dawei Cheng, Jia Li, Jeffrey Xu Yu', 'link': 'https://arxiv.org/abs/2505.18697', 'abstract': 'Nowadays, real-world data, including graph-structure data, often arrives in a streaming manner, which means that learning systems need to continuously acquire new knowledge without forgetting previously learned information. Although substantial existing works attempt to address catastrophic forgetting in graph machine learning, they are all based on training from scratch with streaming data. With the rise of pretrained models, an increasing number of studies have leveraged their strong generalization ability for continual learning. Therefore, in this work, we attempt to answer whether large language models (LLMs) can mitigate catastrophic forgetting in Graph Continual Learning (GCL). We first point out that current experimental setups for GCL have significant flaws, as the evaluation stage may lead to task ID leakage. Then, we evaluate the performance of LLMs in more realistic scenarios and find that even minor modifications can lead to outstanding results. Finally, based on extensive experiments, we propose a simple-yet-effective method, Simple Graph Continual Learning (SimGCL), that surpasses the previous state-of-the-art GNN-based baseline by around 20% under the rehearsal-free constraint. To facilitate reproducibility, we have developed an easy-to-use benchmark LLM4GCL for training and evaluating existing GCL methods. The code is available at: this https URL.', 'abstract_zh': '现在的现实世界数据，包括图结构数据，常常以流式方式到达，这意味着学习系统需要不断获取新知识而不忘记之前学到的信息。尽管现有大量工作试图解决图机器学习中的灾难性遗忘问题，但它们都是基于从头开始使用流式数据训练。随着预训练模型的兴起，越来越多的研究利用其强大的泛化能力进行持续学习。因此，在本文中，我们试图回答大规模语言模型（LLMs）是否可以缓解图持续学习（GCL）中的灾难性遗忘。我们首先指出，当前GCL的实验设置存在显著缺陷，因为评估阶段可能会导致任务ID泄露。然后，我们在更现实的场景下评估了LLMs的表现，发现即使是细微的修改也能取得出色的结果。最后，在大量实验的基础上，我们提出了一种简单而有效的方法——简单图持续学习（SimGCL），在无回顾约束的情况下，该方法比之前的基于GNN的基线方法提高了约20%。为了便于再现，我们开发了一个易于使用且可用于训练和评估现有GCL方法的基准——LLM4GCL。代码可在以下链接获取：this https URL。', 'title_zh': '利用大语言模型缓解图连续学习中的灾难性遗忘：一项系统性研究'}
{'arxiv_id': 'arXiv:2505.18688', 'title': 'Large Language Models in the Task of Automatic Validation of Text Classifier Predictions', 'authors': 'Aleksandr Tsymbalov', 'link': 'https://arxiv.org/abs/2505.18688', 'abstract': "Machine learning models for text classification are trained to predict a class for a given text. To do this, training and validation samples must be prepared: a set of texts is collected, and each text is assigned a class. These classes are usually assigned by human annotators with different expertise levels, depending on the specific classification task. Collecting such samples from scratch is labor-intensive because it requires finding specialists and compensating them for their work; moreover, the number of available specialists is limited, and their productivity is constrained by human factors. While it may not be too resource-intensive to collect samples once, the ongoing need to retrain models (especially in incremental learning pipelines) to address data drift (also called model drift) makes the data collection process crucial and costly over the model's entire lifecycle. This paper proposes several approaches to replace human annotators with Large Language Models (LLMs) to test classifier predictions for correctness, helping ensure model quality and support high-quality incremental learning.", 'abstract_zh': '使用大型语言模型替代人工注释者进行文本分类模型的分类预测验证：确保模型质量并支持高质量增量学习', 'title_zh': '大型语言模型在文本分类器预测自动验证任务中的应用'}
{'arxiv_id': 'arXiv:2505.18687', 'title': 'An AI Capability Threshold for Rent-Funded Universal Basic Income in an AI-Automated Economy', 'authors': 'Aran Nayebi', 'link': 'https://arxiv.org/abs/2505.18687', 'abstract': "We derive the first closed-form condition under which artificial intelligence (AI) capital profits could sustainably finance a universal basic income (UBI) without additional taxes or new job creation. In a Solow-Zeira economy characterized by a continuum of automatable tasks, a constant net saving rate $s$, and task-elasticity $\\sigma < 1$, we analyze how the AI capability threshold--defined as the productivity level of AI relative to pre-AI automation--varies under different economic scenarios. At present economic parameters, we find that AI systems must achieve only approximately 5-6 times existing automation productivity to finance an 11\\%-of-GDP UBI, in the worst case situation where \\emph{no} new jobs or tasks are created.\nOur analysis also reveals some specific policy levers: raising public revenue share (e.g. profit taxation) of AI capital from the current 15\\% to about 33\\% halves the required AI capability threshold to attain UBI to 3 times existing automotion productivity, but gains diminish beyond 50\\% public revenue share, especially if regulatory costs increase. Market structure also strongly affects outcomes: monopolistic or concentrated oligopolistic markets reduce the threshold by increasing economic rents, whereas heightened competition significantly raises it.\nOverall, these results suggest a couple policy recommendations: maximizing public revenue share up to a point so that operating costs are minimized, and strategically managing market competition can ensure AI's growing capabilities translate into meaningful social benefits within realistic technological progress scenarios.", 'abstract_zh': '我们推导出了第一个闭合形式条件，即人工智能资本收益可以在无需额外税收或创造新就业的情况下持续资助普遍基本收入。在由可自动化任务连续体、恒定净储蓄率 \\(s\\) 和任务弹性 \\(\\sigma < 1\\) 特征的索洛-泽拉经济中，我们分析了人工智能能力门槛——即人工智能相对于预人工智能自动化的产品ivity水平——在不同经济情景下的变化。在当前的经济参数下，我们发现，即使在不创造任何新工作或任务的情况下，人工智能系统只需实现现有自动化生产力的约5-6倍，就能资助占GDP 11%的普遍基本收入。', 'title_zh': 'AI能力阈值下的租金资助普遍基本收入在AI自动化经济中的应用'}
{'arxiv_id': 'arXiv:2505.18675', 'title': 'Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps', 'authors': 'Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang', 'link': 'https://arxiv.org/abs/2505.18675', 'abstract': 'Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning tasks involving fine-grained visual understanding remains insufficiently evaluated. To address this gap, we introduce ReasonMap, a benchmark designed to assess the fine-grained visual understanding and spatial reasoning abilities of MLLMs. ReasonMap encompasses high-resolution transit maps from 30 cities across 13 countries and includes 1,008 question-answer pairs spanning two question types and three templates. Furthermore, we design a two-level evaluation pipeline that properly assesses answer correctness and quality. Comprehensive evaluations of 15 popular MLLMs, including both base and reasoning variants, reveal a counterintuitive pattern: among open-source models, base models outperform reasoning ones, while the opposite trend is observed in closed-source models. Additionally, performance generally degrades when visual inputs are masked, indicating that while MLLMs can leverage prior knowledge to answer some questions, fine-grained visual reasoning tasks still require genuine visual perception for strong performance. Our benchmark study offers new insights into visual reasoning and contributes to investigating the gap between open-source and closed-source models.', 'abstract_zh': '多模态大规模语言模型（MLLMs）在视觉任务中的细粒度视觉理解和空间推理能力评估', 'title_zh': 'MLLMs能引导我回家吗？关于基于公交地图的细粒度视觉推理的基准研究'}
{'arxiv_id': 'arXiv:2505.18674', 'title': 'Restoring Real-World Images with an Internal Detail Enhancement Diffusion Model', 'authors': 'Peng Xiao, Hongbo Zhao, Yijun Wang, Jianxin Lin', 'link': 'https://arxiv.org/abs/2505.18674', 'abstract': 'Restoring real-world degraded images, such as old photographs or low-resolution images, presents a significant challenge due to the complex, mixed degradations they exhibit, such as scratches, color fading, and noise. Recent data-driven approaches have struggled with two main challenges: achieving high-fidelity restoration and providing object-level control over colorization. While diffusion models have shown promise in generating high-quality images with specific controls, they often fail to fully preserve image details during restoration. In this work, we propose an internal detail-preserving diffusion model for high-fidelity restoration of real-world degraded images. Our method utilizes a pre-trained Stable Diffusion model as a generative prior, eliminating the need to train a model from scratch. Central to our approach is the Internal Image Detail Enhancement (IIDE) technique, which directs the diffusion model to preserve essential structural and textural information while mitigating degradation effects. The process starts by mapping the input image into a latent space, where we inject the diffusion denoising process with degradation operations that simulate the effects of various degradation factors. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art models in both qualitative assessments and perceptual quantitative evaluations. Additionally, our approach supports text-guided restoration, enabling object-level colorization control that mimics the expertise of professional photo editing.', 'abstract_zh': '恢复现实世界退化图像，如老照片或低分辨率图像，因其表现出的复杂混合退化现象（如刮痕、褪色和噪声）而面临重大挑战。近期的数据驱动方法在两个主要挑战中挣扎：实现高保真恢复和提供物体级别的颜色化控制。尽管扩散模型在生成具有特定控制的高质量图像方面显示出潜力，但在恢复过程中往往无法完全保留图像细节。本工作提出了一种内部细节保留扩散模型，用于高保真恢复现实世界退化图像。我们的方法利用预训练的稳定扩散模型作为生成先验，从而免去了从头训练模型的需要。我们的方法的核心是内部图像细节增强（IIDE）技术，该技术引导扩散模型保留关键的结构和纹理信息，同时减轻退化效应。过程首先将输入图像映射到潜在空间，在该空间中，我们通过模拟各种退化因素的效果注入扩散去噪过程。实验结果表明，我们的方法在定性和感知量化评估中均显著优于现有最佳模型。此外，我们的方法支持文本引导的恢复，允许实现物体级别的颜色化控制，模拟专业照片编辑的技巧。', 'title_zh': '使用内部细节增强扩散模型恢复现实世界图像'}
{'arxiv_id': 'arXiv:2505.18659', 'title': 'Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees', 'authors': 'Sangwoo Park, Matteo Zecchin, Osvaldo Simeone', 'link': 'https://arxiv.org/abs/2505.18659', 'abstract': 'Selecting artificial intelligence (AI) models, such as large language models (LLMs), from multiple candidates requires accurate performance estimation. This is ideally achieved through empirical evaluations involving abundant real-world data. However, such evaluations are costly and impractical at scale. To address this challenge, autoevaluation methods leverage synthetic data produced by automated evaluators, such as LLMs-as-judges, reducing variance but potentially introducing bias. Recent approaches have employed semi-supervised prediction-powered inference (\\texttt{PPI}) to correct for the bias of autoevaluators. However, the use of autoevaluators may lead in practice to a degradation in sample efficiency compared to conventional methods using only real-world data. In this paper, we propose \\texttt{R-AutoEval+}, a novel framework that provides finite-sample reliability guarantees on the model evaluation, while also ensuring an enhanced (or at least no worse) sample efficiency compared to conventional methods. The key innovation of \\texttt{R-AutoEval+} is an adaptive construction of the model evaluation variable, which dynamically tunes its reliance on synthetic data, reverting to conventional methods when the autoevaluator is insufficiently accurate. Experiments on the use of LLMs-as-judges for the optimization of quantization settings for the weights of an LLM, and for prompt design in LLMs confirm the reliability and efficiency of \\texttt{R-AutoEval+}.', 'abstract_zh': '从多个候选模型中选择人工智能模型，例如大型语言模型，需要准确的性能估计。理想情况下，这通过涉及丰富的真实世界数据的经验评估来实现。然而，大规模进行此类评估是昂贵且不切实际的。为应对这一挑战，自评估方法利用自动评估器生成的合成数据，如LLM-as-judge，减少方差但可能会引入偏差。最近的方法采用了半监督预测驱动的推理（\\texttt{PPI}）来纠正自动评估器的偏差。然而，在实践中，使用自动评估器可能会导致样本效率劣于仅使用真实世界数据的传统方法。在这篇论文中，我们提出了\\texttt{R-AutoEval+}这一新型框架，它在提供有限样本可靠性保证的同时，确保了相比传统方法至少样本效率不降低。\\texttt{R-AutoEval+}的关键创新在于其自适应构建模型评估变量的方法，该方法动态调整对合成数据的依赖性，在自动评估器准确性不足时返回传统方法。实验表明，\\texttt{R-AutoEval+}在使用LLM-as-judge优化大型语言模型的权重量化设置以及大型语言模型的提示设计中具有可靠性和效率。', 'title_zh': '自适应预测驱动的AutoEval及其可靠性和效率保证'}
{'arxiv_id': 'arXiv:2505.18658', 'title': 'Robustness in Large Language Models: A Survey of Mitigation Strategies and Evaluation Metrics', 'authors': 'Pankaj Kumar, Subhankar Mishra', 'link': 'https://arxiv.org/abs/2505.18658', 'abstract': 'Large Language Models (LLMs) have emerged as a promising cornerstone for the development of natural language processing (NLP) and artificial intelligence (AI). However, ensuring the robustness of LLMs remains a critical challenge. To address these challenges and advance the field, this survey provides a comprehensive overview of current studies in this area. First, we systematically examine the nature of robustness in LLMs, including its conceptual foundations, the importance of consistent performance across diverse inputs, and the implications of failure modes in real-world applications. Next, we analyze the sources of non-robustness, categorizing intrinsic model limitations, data-driven vulnerabilities, and external adversarial factors that compromise reliability. Following this, we review state-of-the-art mitigation strategies, and then we discuss widely adopted benchmarks, emerging metrics, and persistent gaps in assessing real-world reliability. Finally, we synthesize findings from existing surveys and interdisciplinary studies to highlight trends, unresolved issues, and pathways for future research.', 'abstract_zh': '大型语言模型（LLMs）已成为自然语言处理（NLP）和人工智能（AI）发展的重要基石。然而，确保LLMs的稳健性仍然是一个关键挑战。为了应对这些挑战并促进该领域的发展，本文综述了当前该领域的研究现状。首先，我们系统地探讨了LLMs稳健性的本质，包括其概念基础、在多样输入中保持一致性能的重要性以及在实际应用中故障模式的影响。接下来，我们分析了非稳健性的来源，分为内在模型限制、数据驱动的脆弱性和外部敌对因素对可靠性的损害。随后，我们回顾了最先进的缓解策略，并讨论了广泛采用的基准测试、新兴指标以及评估实际可靠性时持续存在的缺口。最后，我们综合现有综述和跨学科研究的发现，强调了研究趋势、未解决的问题以及未来研究的方向。', 'title_zh': '大型语言模型的稳健性：缓解策略与评估指标综述'}
{'arxiv_id': 'arXiv:2505.18647', 'title': 'Flow Matching for Geometric Trajectory Simulation', 'authors': 'Kiet Bennema ten Brinke, Koen Minartz, Vlado Menkovski', 'link': 'https://arxiv.org/abs/2505.18647', 'abstract': 'The simulation of N-body systems is a fundamental problem with applications in a wide range of fields, such as molecular dynamics, biochemistry, and pedestrian dynamics. Machine learning has become an invaluable tool for scaling physics-based simulators and developing models directly from experimental data. In particular, recent advances based on deep generative modeling and geometric deep learning have enabled probabilistic simulation by modeling complex distributions over trajectories while respecting the permutation symmetry that is fundamental to N-body systems. However, to generate realistic trajectories, existing methods must learn complex transformations starting from uninformed noise and do not allow for the exploitation of domain-informed priors. In this work, we propose STFlow to address this limitation. By leveraging flow matching and data-dependent couplings, STFlow facilitates physics-informed simulation of geometric trajectories without sacrificing model expressivity or scalability. Our evaluation on N-body dynamical systems, molecular dynamics, and pedestrian dynamics benchmarks shows that STFlow produces significantly lower prediction errors while enabling more efficient inference, highlighting the benefits of employing physics-informed prior distributions in probabilistic geometric trajectory modeling.', 'abstract_zh': '基于N-体系统的仿真：从实验数据中直接开发物理模型的机器学习方法及其应用', 'title_zh': '几何轨迹模拟中的流匹配'}
{'arxiv_id': 'arXiv:2505.18646', 'title': 'SEW: Self-Evolving Agentic Workflows for Automated Code Generation', 'authors': 'Siwei Liu, Jinyuan Fang, Han Zhou, Yingxu Wang, Zaiqiao Meng', 'link': 'https://arxiv.org/abs/2505.18646', 'abstract': 'Large Language Models (LLMs) have demonstrated effectiveness in code generation tasks. To enable LLMs to address more complex coding challenges, existing research has focused on crafting multi-agent systems with agentic workflows, where complex coding tasks are decomposed into sub-tasks, assigned to specialized agents. Despite their effectiveness, current approaches heavily rely on hand-crafted agentic workflows, with both agent topologies and prompts manually designed, which limits their ability to automatically adapt to different types of coding problems. To address these limitations and enable automated workflow design, we propose \\textbf{S}elf-\\textbf{E}volving \\textbf{W}orkflow (\\textbf{SEW}), a novel self-evolving framework that automatically generates and optimises multi-agent workflows. Extensive experiments on three coding benchmark datasets, including the challenging LiveCodeBench, demonstrate that our SEW can automatically design agentic workflows and optimise them through self-evolution, bringing up to 33\\% improvement on LiveCodeBench compared to using the backbone LLM only. Furthermore, by investigating different representation schemes of workflow, we provide insights into the optimal way to encode workflow information with text.', 'abstract_zh': '大规模语言模型（LLMs）在代码生成任务中展示了有效性。为了使LLMs能够应对更复杂的编码挑战，现有研究主要集中在构建具有代理型工作流的多代理系统，其中复杂的编码任务被分解为子任务并分配给专门的代理。尽管这些方法效果显著，但当前的方案仍然严重依赖手动设计的代理型工作流，包括代理拓扑结构和提示的亲手设计，这限制了它们自动适应不同类型编码问题的能力。为了解决这些局限性并实现自动化工作流设计，我们提出了一种新颖的自演进框架——自演进工作流（SEW），该框架能够自动生成和优化多代理工作流。在包括具有挑战性的LiveCodeBench在内的三个编码基准数据集上的广泛实验表明，我们的SEW可以自动设计代理型工作流并通过自演进来优化它们，在LiveCodeBench上的性能比仅使用骨干LLM提高了33%。此外，通过探讨不同的工作流表示方案，我们提供了关于如何使用文本最佳编码工作流信息的洞察。', 'title_zh': 'SEW: 自我进化代理工作流的自动化代码生成'}
{'arxiv_id': 'arXiv:2505.18643', 'title': 'Anomaly detection in radio galaxy data with trainable COSFIRE filters', 'authors': "Steven Ndung'u, Trienko Grobler, Stefan J. Wijnholds, George Azzopardi", 'link': 'https://arxiv.org/abs/2505.18643', 'abstract': 'Detecting anomalies in radio astronomy is challenging due to the vast amounts of data and the rarity of labeled anomalous examples. Addressing this challenge requires efficient methods capable of identifying unusual radio galaxy morphologies without relying on extensive supervision. This work introduces an innovative approach to anomaly detection based on morphological characteristics of the radio sources using trainable COSFIRE (Combination of Shifted Filter Responses) filters as an efficient alternative to complex deep learning methods. The framework integrates COSFIRE descriptors with an unsupervised Local Outlier Factor (LOF) algorithm to identify unusual radio galaxy morphologies. Evaluations on a radio galaxy benchmark data set demonstrate strong performance, with the COSFIRE-based approach achieving a geometric mean (G-Mean) score of 79%, surpassing the 77% achieved by a computationally intensive deep learning autoencoder. By characterizing normal patterns and detecting deviations, this semi-supervised methodology overcomes the need for anomalous examples in the training set, a major limitation of traditional supervised methods. This approach shows promise for next-generation radio telescopes, where fast processing and the ability to discover unknown phenomena are crucial.', 'abstract_zh': '基于形态特征的COSFIRE滤波器在射电天文学异常检测中的应用：一种无需大量监督的方法', 'title_zh': 'RADIO 星系数据中可训练 COSFIRE 滤波器的异常检测'}
{'arxiv_id': 'arXiv:2505.18640', 'title': 'ThanoRA: Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation', 'authors': 'Jian Liang, Wenke Huang, Xianda Guo, Guancheng Wan, Bo Du, Mang Ye', 'link': 'https://arxiv.org/abs/2505.18640', 'abstract': 'Low-Rank Adaptation (LoRA) is widely adopted for downstream fine-tuning of foundation models due to its efficiency and zero additional inference cost. Many real-world applications require foundation models to specialize in multiple tasks simultaneously, motivating the need for efficient multi-task adaptation. While recent approaches integrate LoRA with mixture-of-experts (MoE) to address this, the use of routers prevents parameter mergeability, which increases inference overhead and hinders unified multi-task adaptation, thereby limiting deployment practicality. In this work, we propose ThanoRA, a Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation framework that enables multi-task adaptation while preserving the inference efficiency of LoRA. ThanoRA jointly models task heterogeneity and mitigates subspace interference throughout training. Specifically, motivated by inherent differences in complexity and heterogeneity across tasks, ThanoRA constructs task-specific LoRA subspaces at initialization, enabling fine-grained knowledge injection aligned with task heterogeneity. Furthermore, to prevent task interference and subspace collapse during multi-task training, ThanoRA introduces a subspace-preserving regularization that maintains the independence of task-specific representations. With the synergy of both components, ThanoRA enables efficient and unified multi-task adaptation. Extensive experiments across multimodal and text-only benchmarks under varying multi-task mixtures demonstrate that ThanoRA consistently achieves robust and superior performance over strong baselines without introducing additional inference overhead. Our code is publicly available at: this https URL.', 'abstract_zh': '基于任务异质性的多任务低秩适应框架ThanoRA', 'title_zh': 'ThanoRA：任务异质性意识的多任务低秩适应'}
{'arxiv_id': 'arXiv:2505.18630', 'title': 'DDO: Dual-Decision Optimization via Multi-Agent Collaboration for LLM-Based Medical Consultation', 'authors': 'Zhihao Jia, Mingyi Jia, Junwen Duan, Jianxin Wang', 'link': 'https://arxiv.org/abs/2505.18630', 'abstract': 'Large Language Models (LLMs) demonstrate strong generalization and reasoning abilities, making them well-suited for complex decision-making tasks such as medical consultation (MC). However, existing LLM-based methods often fail to capture the dual nature of MC, which entails two distinct sub-tasks: symptom inquiry, a sequential decision-making process, and disease diagnosis, a classification problem. This mismatch often results in ineffective symptom inquiry and unreliable disease diagnosis. To address this, we propose \\textbf{DDO}, a novel LLM-based framework that performs \\textbf{D}ual-\\textbf{D}ecision \\textbf{O}ptimization by decoupling and independently optimizing the the two sub-tasks through a collaborative multi-agent workflow. Experiments on three real-world MC datasets show that DDO consistently outperforms existing LLM-based approaches and achieves competitive performance with state-of-the-art generation-based methods, demonstrating its effectiveness in the MC task.', 'abstract_zh': '大型语言模型（LLMs）展示出强大的泛化和推理能力，使其适合复杂决策任务如医学咨询（MC）。然而，现有基于LLM的方法往往无法捕捉MC的双重性质，这涉及到两个不同的子任务：症状询问，这是一个顺序决策过程，和疾病诊断，这是一个分类问题。这种不匹配常导致无效的症状询问和不可靠的疾病诊断。为了解决这一问题，我们提出了一种新颖的基于LLM的框架\\textbf{DDO}，该框架通过脱钩并独立优化这两个子任务来实现双重决策优化，采用协作多智能体工作流。实验结果表明，\\textbf{DDO}在三个真实的MC数据集上始终优于现有基于LLM的方法，并且在与最先进的生成方法的竞争中表现出了竞争力，证明了其在MC任务中的有效性。', 'title_zh': 'DDO：基于多Agent协作的双重决策优化在LLM驱动的医疗咨询中的应用'}
{'arxiv_id': 'arXiv:2505.18622', 'title': "Trust, or Don't Predict: Introducing the CWSA Family for Confidence-Aware Model Evaluation", 'authors': 'Kourosh Shahnazari, Seyed Moein Ayyoubzadeh, Mohammadali Keshtparvar, Pegah Ghaffari', 'link': 'https://arxiv.org/abs/2505.18622', 'abstract': 'In recent machine learning systems, confidence scores are being utilized more and more to manage selective prediction, whereby a model can abstain from making a prediction when it is unconfident. Yet, conventional metrics like accuracy, expected calibration error (ECE), and area under the risk-coverage curve (AURC) do not capture the actual reliability of predictions. These metrics either disregard confidence entirely, dilute valuable localized information through averaging, or neglect to suitably penalize overconfident misclassifications, which can be particularly detrimental in real-world systems. We introduce two new metrics Confidence-Weighted Selective Accuracy (CWSA) and its normalized variant CWSA+ that offer a principled and interpretable way to evaluate predictive models under confidence thresholds. Unlike existing methods, our metrics explicitly reward confident accuracy and penalize overconfident mistakes. They are threshold-local, decomposable, and usable in both evaluation and deployment settings where trust and risk must be quantified. Through exhaustive experiments on both real-world data sets (MNIST, CIFAR-10) and artificial model variants (calibrated, overconfident, underconfident, random, perfect), we show that CWSA and CWSA+ both effectively detect nuanced failure modes and outperform classical metrics in trust-sensitive tests. Our results confirm that CWSA is a sound basis for developing and assessing selective prediction systems for safety-critical domains.', 'abstract_zh': '基于置信度加权选择准确率及其规范化 variant CWSA+ 在选择性预测中的评估新方法', 'title_zh': '信任，或不预测：引入基于置信意识的模型评价CWSA家族'}
{'arxiv_id': 'arXiv:2505.18605', 'title': 'Rethinking Causal Mask Attention for Vision-Language Inference', 'authors': 'Xiaohuan Pei, Tao Huang, YanXiang Ma, Chang Xu', 'link': 'https://arxiv.org/abs/2505.18605', 'abstract': "Causal attention has become a foundational mechanism in autoregressive vision-language models (VLMs), unifying textual and visual inputs under a single generative framework. However, existing causal mask-based strategies are inherited from large language models (LLMs) where they are tailored for text-only decoding, and their adaptation to vision tokens is insufficiently addressed in the prefill stage. Strictly masking future positions for vision queries introduces overly rigid constraints, which hinder the model's ability to leverage future context that often contains essential semantic cues for accurate inference. In this work, we empirically investigate how different causal masking strategies affect vision-language inference and then propose a family of future-aware attentions tailored for this setting. We first empirically analyze the effect of previewing future tokens for vision queries and demonstrate that rigid masking undermines the model's capacity to capture useful contextual semantic representations. Based on these findings, we propose a lightweight attention family that aggregates future visual context into past representations via pooling, effectively preserving the autoregressive structure while enhancing cross-token dependencies. We evaluate a range of causal masks across diverse vision-language inference settings and show that selectively compressing future semantic context into past representations benefits the inference.", 'abstract_zh': '因果注意机制已成为自回归视觉语言模型（VLMs）的基础机制，将文本和视觉输入统一在一个生成框架下。然而，现有的因果掩码策略源自大型语言模型（LLMs），这些模型专门针对文本解码进行了调整，在视觉标记的预填阶段，这些策略的适应性不足。严格掩码未来位置会为视觉查询引入过于刚性的约束，这阻碍了模型利用通常包含准确推理所需关键语义线索的未来上下文的能力。在本文中，我们实证研究了不同的因果掩码策略对视觉语言推理的影响，然后提出了一种专门为此场景设计的未来意识注意机制。我们首先实证分析了视觉查询预览未来标记的影响，并证明了刚性掩码会削弱模型捕捉有用上下文语义表示的能力。基于这些发现，我们提出了一种轻量级的注意机制，通过聚类将未来的视觉上下文整合到过去表示中，从而有效保持自回归结构的同时增强跨标记依赖关系。我们评估了多种因果掩码在不同的视觉语言推理场景中的表现，并展示了有选择地将未来语义上下文压缩到过去表示中对推理是有益的。', 'title_zh': '重新思考因果掩码注意力在视觉-语言推理中的应用'}
{'arxiv_id': 'arXiv:2505.18602', 'title': 'LLM-Meta-SR: Learning to Evolve Selection Operators for Symbolic Regression', 'authors': 'Hengzhe Zhang, Qi Chen, Bing Xue, Mengjie Zhang', 'link': 'https://arxiv.org/abs/2505.18602', 'abstract': 'Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts. In this paper, we propose a learning-to-evolve framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms. We first identify two key limitations in existing LLM-based algorithm evolution techniques: code bloat and a lack of semantic guidance. Bloat results in unnecessarily complex components, and the absence of semantic awareness can lead to ineffective exchange of useful code components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress. To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: bloat control and a complementary, semantics-aware selection operator. Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators. Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance. This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.', 'abstract_zh': '大规模语言模型（LLMs）在算法开发中取得了革命性进展，但在符号回归中的应用仍受到限制，通常需要人工专家手动设计。本文提出了一种学习演化框架，使LLMs能够自动为演化符号回归算法设计选择算子。我们首先识别现有基于LLM的算法演化技术中的两个关键限制：代码膨胀和缺乏语义指导。代码膨胀会导致不必要的复杂性，而缺乏语义意识则可能导致有用代码组件的有效交换受阻，这两者都可能降低所设计算法的可解释性或阻碍进化学习进程。为了解决这些问题，我们通过两种关键创新增强了基于LLM的元符号回归演化框架：代码膨胀控制和互补的、具有语义意识的选择算子。此外，我们还将领域知识嵌入提示中，使LLM能够生成更有效且更具上下文相关性的选择算子。我们对符号回归基准的实验结果表明，LLMs能够设计出超越九个专家设计基准的选择算子，达到最先进的性能。这表明LLMs能够在符号回归的算法设计上超越专家水平。', 'title_zh': 'LLM-Meta-SR：学习演化符号回归中的选择算子'}
{'arxiv_id': 'arXiv:2505.18601', 'title': 'Flex-Judge: Think Once, Judge Anywhere', 'authors': 'Jongwoo Ko, Sungnyun Kim, Sungwoo Cho, Se-Young Yun', 'link': 'https://arxiv.org/abs/2505.18601', 'abstract': 'Human-generated reward signals are critical for aligning generative models with human preferences, guiding both training and inference-time evaluations. While large language models (LLMs) employed as proxy evaluators, i.e., LLM-as-a-Judge, significantly reduce the costs associated with manual annotations, they typically require extensive modality-specific training data and fail to generalize well across diverse multimodal tasks. In this paper, we propose Flex-Judge, a reasoning-guided multimodal judge model that leverages minimal textual reasoning data to robustly generalize across multiple modalities and evaluation formats. Our core intuition is that structured textual reasoning explanations inherently encode generalizable decision-making patterns, enabling an effective transfer to multimodal judgments, e.g., with images or videos. Empirical results demonstrate that Flex-Judge, despite being trained on significantly fewer text data, achieves competitive or superior performance compared to state-of-the-art commercial APIs and extensively trained multimodal evaluators. Notably, Flex-Judge presents broad impact in modalities like molecule, where comprehensive evaluation benchmarks are scarce, underscoring its practical value in resource-constrained domains. Our framework highlights reasoning-based text supervision as a powerful, cost-effective alternative to traditional annotation-intensive approaches, substantially advancing scalable multimodal model-as-a-judge.', 'abstract_zh': '人类生成的奖励信号对于对齐生成模型与人类偏好至关重要，指导训练和推理时期的评估。虽然作为代理评估器使用的大型语言模型（LLMs），即LLM-as-a-Judge，显著降低了手动注释的成本，但它们通常需要大量的模态特定训练数据，并且在多种模态任务上的泛化能力较差。本文提出了一种名为Flex-Judge的推理引导多模态评估模型，利用少量的文本推理数据，在多种模态和评估格式上实现稳健泛化。我们核心的直觉是，结构化的文本推理解释内固地编码了可泛化的决策模式，能够有效转移到多模态判断中，例如带有图片或视频的任务。实验结果表明，尽管Flex-Judge在远少于文本数据上进行训练，但在性能上与最先进的商业API和广泛训练的多模态评估器相当或更优。特别是在评价基准稀缺的分子等模态中，Flex-Judge展示了其在资源受限领域中的广泛影响，突显了其实用价值。本文框架突出了基于推理的文本监督作为传统注释密集型方法的一种强大、成本效益高的替代方案，显著推进了可扩展的多模态模型作为评估器的发展。', 'title_zh': 'Flex-Judge: 一次思考，随处判断'}
{'arxiv_id': 'arXiv:2505.18600', 'title': 'Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and Preference Alignment', 'authors': 'Bryan Sangwoo Kim, Jeongsol Kim, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2505.18600', 'abstract': 'Modern single-image super-resolution (SISR) models deliver photo-realistic results at the scale factors on which they are trained, but collapse when asked to magnify far beyond that regime. We address this scalability bottleneck with Chain-of-Zoom (CoZ), a model-agnostic framework that factorizes SISR into an autoregressive chain of intermediate scale-states with multi-scale-aware prompts. CoZ repeatedly re-uses a backbone SR model, decomposing the conditional probability into tractable sub-problems to achieve extreme resolutions without additional training. Because visual cues diminish at high magnifications, we augment each zoom step with multi-scale-aware text prompts generated by a vision-language model (VLM). The prompt extractor itself is fine-tuned using Generalized Reward Policy Optimization (GRPO) with a critic VLM, aligning text guidance towards human preference. Experiments show that a standard 4x diffusion SR model wrapped in CoZ attains beyond 256x enlargement with high perceptual quality and fidelity.', 'abstract_zh': '现代单图像超分辨率（SISR）模型在训练的尺度因子上能够生成照片级真实的恢复结果，但在要求其放大远远超出该范围时会失效。我们通过Chain-of-Zoom（CoZ）框架解决了这一可扩展性的瓶颈，CoZ是一种模型无关的框架，将SISR分解为一个自动回归的中间尺度状态链，并通过多尺度感知的提示实现极端分辨率。由于视觉线索在高放大倍数下会减弱，我们在每次放大步骤中增加由视觉语言模型生成的多尺度感知文本提示。提示提取器本身使用通用奖励策略优化（GRPO）并与评论家视觉语言模型进行微调，使其文本指导更符合人类偏好。实验表明，标准的4倍扩散SR模型嵌入CoZ框架后可以实现超过256倍的放大，同时保持高的感知质量和保真度。', 'title_zh': '链择放大：基于尺度自回归和偏好对齐的极端超分辨率'}
{'arxiv_id': 'arXiv:2505.18596', 'title': 'Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models', 'authors': 'Chen Han, Wenzhen Zheng, Xijin Tang', 'link': 'https://arxiv.org/abs/2505.18596', 'abstract': "The proliferation of misinformation in digital platforms reveals the limitations of traditional detection methods, which mostly rely on static classification and fail to capture the intricate process of real-world fact-checking. Despite advancements in Large Language Models (LLMs) that enhance automated reasoning, their application to misinformation detection remains hindered by issues of logical inconsistency and superficial verification. In response, we introduce Debate-to-Detect (D2D), a novel Multi-Agent Debate (MAD) framework that reformulates misinformation detection as a structured adversarial debate. Inspired by fact-checking workflows, D2D assigns domain-specific profiles to each agent and orchestrates a five-stage debate process, including Opening Statement, Rebuttal, Free Debate, Closing Statement, and Judgment. To transcend traditional binary classification, D2D introduces a multi-dimensional evaluation mechanism that assesses each claim across five distinct dimensions: Factuality, Source Reliability, Reasoning Quality, Clarity, and Ethics. Experiments with GPT-4o on two fakenews datasets demonstrate significant improvements over baseline methods, and the case study highlight D2D's capability to iteratively refine evidence while improving decision transparency, representing a substantial advancement towards robust and interpretable misinformation detection. The code will be open-sourced in a future release.", 'abstract_zh': '数字平台中虚假信息的泛滥揭示了传统检测方法的局限性，这些方法主要依赖静态分类并无法捕捉现实世界事实核查的复杂过程。尽管大型语言模型（LLMs）的进步提高了自动推理的能力，但其在虚假信息检测中的应用仍受到逻辑不一致和表面化验证的问题限制。为应对这一挑战，我们提出了 Debate-to-Detect（D2D），一种新颖的多智能体辩论（MAD）框架，将虚假信息检测重新定义为结构化的对抗性辩论。受到事实核查工作流程的启发，D2D 为每个智能体分配领域特定的特征，并 orchestrates 一个包括开场陈述、反驳、自由辩论、总结陈述和裁决的五阶段辩论过程。为超越传统的二元分类，D2D 引入了一种多维度评估机制，分别从事实性、源可靠性、推理质量、清晰度和伦理学五个维度评估每个断言。使用 GPT-4o 在两个假新闻数据集上的实验展示了显著的改进，案例研究突显了 D2D 的能力，可以在迭代中细化证据并提高决策透明度，代表了虚假信息检测向稳健和可解释性方向的一大进步。代码将在未来的发布中开源。', 'title_zh': '辩论驱动检测：将信息误导检测重新表述为大型语言模型参与的实际辩论'}
{'arxiv_id': 'arXiv:2505.18595', 'title': 'MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations', 'authors': 'Viet Bui, Tien Mai, Hong Thanh Nguyen', 'link': 'https://arxiv.org/abs/2505.18595', 'abstract': 'We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.', 'abstract_zh': '我们在合作多智能体环境下研究离线模仿学习（IL），其中示例具有未标记的混合质量，包含专家和次优轨迹。我们提出的方法分为两个阶段：轨迹标注和多智能体模仿学习，旨在有效学习来自异构且未标记的数据。在第一阶段，我们结合大型语言模型和基于偏好的强化学习进展，构建一个逐步的标注流水线，以区分专家级轨迹。在第二阶段，我们引入了一种名为MisoDICE的新颖多智能体IL算法，利用这些标注来学习鲁棒策略，同时解决大型联合状态动作空间的计算复杂性问题。通过将流行的单智能体DICE框架扩展到具有新值分解和混合架构的合作多智能体环境，我们的方法产生了凸策略优化目标，并确保全局和局部策略的一致性。我们使用多个标准多智能体RL基准评估MisoDICE，并展示了更好性能，尤其是在专家数据稀缺时。', 'title_zh': 'MisoDICE: 多Agentimitation 从未标记的混合质量示范中学习'}
{'arxiv_id': 'arXiv:2505.18588', 'title': 'Safety Alignment via Constrained Knowledge Unlearning', 'authors': 'Zesheng Shi, Yucheng Zhou, Jing Li', 'link': 'https://arxiv.org/abs/2505.18588', 'abstract': 'Despite significant progress in safety alignment, large language models (LLMs) remain susceptible to jailbreak attacks. Existing defense mechanisms have not fully deleted harmful knowledge in LLMs, which allows such attacks to bypass safeguards and produce harmful outputs. To address this challenge, we propose a novel safety alignment strategy, Constrained Knowledge Unlearning (CKU), which focuses on two primary objectives: knowledge localization and retention, and unlearning harmful knowledge. CKU works by scoring neurons in specific multilayer perceptron (MLP) layers to identify a subset U of neurons associated with useful knowledge. During the unlearning process, CKU prunes the gradients of neurons in U to preserve valuable knowledge while effectively mitigating harmful content. Experimental results demonstrate that CKU significantly enhances model safety without compromising overall performance, offering a superior balance between safety and utility compared to existing methods. Additionally, our analysis of neuron knowledge sensitivity across various MLP layers provides valuable insights into the mechanics of safety alignment and model knowledge editing.', 'abstract_zh': '尽管在安全性对齐方面取得了显著进展，大型语言模型（LLMs）仍然易受脱管攻击的影响。现有的防护机制未能完全删除LLMs中的有害知识，这使得此类攻击能够规避防护措施并产生有害输出。为应对这一挑战，我们提出了一种新的安全性对齐策略——约束知识遗忘（CKU），该策略主要包含两个目标：知识定位与保留，以及遗忘有害知识。CKU通过为特定多层感知器（MLP）层中的神经元评分，来识别与有用知识相关的神经元子集U。在遗忘过程中，CKU通过修剪神经元U的梯度来保留有价值的知识，同时有效降低有害内容的影响。实验结果表明，CKU显著提升了模型的安全性，而不会牺牲总体性能，提供了在安全性与实用性之间更优越的平衡。此外，我们对不同MLP层中神经元知识敏感性的分析为安全性对齐和模型知识编辑的机理提供了宝贵见解。', 'title_zh': '基于约束知识遗忘的安全对齐'}
{'arxiv_id': 'arXiv:2505.18587', 'title': 'HyperFake: Hyperspectral Reconstruction and Attention-Guided Analysis for Advanced Deepfake Detection', 'authors': 'Pavan C Shekar, Pawan Soni, Vivek Kanhangad', 'link': 'https://arxiv.org/abs/2505.18587', 'abstract': 'Deepfakes pose a significant threat to digital media security, with current detection methods struggling to generalize across different manipulation techniques and datasets. While recent approaches combine CNN-based architectures with Vision Transformers or leverage multi-modal learning, they remain limited by the inherent constraints of RGB data. We introduce HyperFake, a novel deepfake detection pipeline that reconstructs 31-channel hyperspectral data from standard RGB videos, revealing hidden manipulation traces invisible to conventional methods. Using an improved MST++ architecture, HyperFake enhances hyperspectral reconstruction, while a spectral attention mechanism selects the most critical spectral features for deepfake detection. The refined spectral data is then processed by an EfficientNet-based classifier optimized for spectral analysis, enabling more accurate and generalizable detection across different deepfake styles and datasets, all without the need for expensive hyperspectral cameras. To the best of our knowledge, this is the first approach to leverage hyperspectral imaging reconstruction for deepfake detection, opening new possibilities for detecting increasingly sophisticated manipulations.', 'abstract_zh': '基于超光谱成像重建的Deepfake检测新方法', 'title_zh': 'HyperFake: 超谱重建与注意力引导分析在高级换脸检测中的应用'}
{'arxiv_id': 'arXiv:2505.18582', 'title': 'On Denoising Walking Videos for Gait Recognition', 'authors': 'Dongyang Jin, Chao Fan, Jingzhe Ma, Jingkai Zhou, Weihua Chen, Shiqi Yu', 'link': 'https://arxiv.org/abs/2505.18582', 'abstract': 'To capture individual gait patterns, excluding identity-irrelevant cues in walking videos, such as clothing texture and color, remains a persistent challenge for vision-based gait recognition. Traditional silhouette- and pose-based methods, though theoretically effective at removing such distractions, often fall short of high accuracy due to their sparse and less informative inputs. Emerging end-to-end methods address this by directly denoising RGB videos using human priors. Building on this trend, we propose DenoisingGait, a novel gait denoising method. Inspired by the philosophy that "what I cannot create, I do not understand", we turn to generative diffusion models, uncovering how they partially filter out irrelevant factors for gait understanding. Additionally, we introduce a geometry-driven Feature Matching module, which, combined with background removal via human silhouettes, condenses the multi-channel diffusion features at each foreground pixel into a two-channel direction vector. Specifically, the proposed within- and cross-frame matching respectively capture the local vectorized structures of gait appearance and motion, producing a novel flow-like gait representation termed Gait Feature Field, which further reduces residual noise in diffusion features. Experiments on the CCPG, CASIA-B*, and SUSTech1K datasets demonstrate that DenoisingGait achieves a new SoTA performance in most cases for both within- and cross-domain evaluations. Code is available at this https URL.', 'abstract_zh': '基于去噪的步态识别方法：DenoisingGait', 'title_zh': '基于去噪的行走视频去噪处理与步态识别'}
{'arxiv_id': 'arXiv:2505.18581', 'title': 'Removal of Hallucination on Hallucination: Debate-Augmented RAG', 'authors': 'Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Qing Li', 'link': 'https://arxiv.org/abs/2505.18581', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external knowledge, yet it introduces a critical issue: erroneous or biased retrieval can mislead generation, compounding hallucinations, a phenomenon we term Hallucination on Hallucination. To address this, we propose Debate-Augmented RAG (DRAG), a training-free framework that integrates Multi-Agent Debate (MAD) mechanisms into both retrieval and generation stages. In retrieval, DRAG employs structured debates among proponents, opponents, and judges to refine retrieval quality and ensure factual reliability. In generation, DRAG introduces asymmetric information roles and adversarial debates, enhancing reasoning robustness and mitigating factual inconsistencies. Evaluations across multiple tasks demonstrate that DRAG improves retrieval reliability, reduces RAG-induced hallucinations, and significantly enhances overall factual accuracy. Our code is available at this https URL.', 'abstract_zh': '检索增强生成（RAG）通过集成外部知识提高了事实准确性，但引入了一个关键问题：错误或有偏见的检索可能导致生成产生误导，加剧幻觉现象，我们称之为幻觉叠加重现。为解决这一问题，我们提出了辩论增强RAG（DRAG）框架，这是一种无需训练的框架，将多智能体辩论（MAD）机制融入检索和生成阶段。在检索阶段，DRAG通过倡导者、反对者和法官之间的结构化辩论来优化检索质量并确保事实可靠性。在生成阶段，DRAG引入了不对称信息角色和对抗性辩论，增强了推理的鲁棒性并减轻了事实不一致问题。跨多个任务的评估表明，DRAG提高了检索可靠性、减少了RAG诱导的幻觉，并显著提高了整体事实准确性。代码托管在该地址：<https://>。', 'title_zh': '幻觉中的幻觉消除：辩论增强的RAG'}
{'arxiv_id': 'arXiv:2505.18574', 'title': 'Autocomp: LLM-Driven Code Optimization for Tensor Accelerators', 'authors': 'Charles Hong, Sahil Bhatia, Alvin Cheung, Yakun Sophia Shao', 'link': 'https://arxiv.org/abs/2505.18574', 'abstract': "Hardware accelerators, especially those designed for tensor processing, have become ubiquitous in today's computing landscape. However, even with significant efforts in building compilers, programming these tensor accelerators remains challenging, leaving much of their potential underutilized. Recently, large language models (LLMs), trained on large amounts of code, have shown significant promise in code generation and optimization tasks, but generating low-resource languages like specialized tensor accelerator code still poses a significant challenge. We tackle this challenge with Autocomp, an approach that empowers accelerator programmers to leverage domain knowledge and hardware feedback to optimize code via an automated LLM-driven search. We accomplish this by: 1) formulating each optimization pass as a structured two-phase prompt, divided into planning and code generation phases, 2) inserting domain knowledge during planning via a concise and adaptable optimization menu, and 3) integrating correctness and performance metrics from hardware as feedback at each search iteration. Across three categories of representative workloads and two different accelerators, we demonstrate that Autocomp-optimized code runs 5.6x (GEMM) and 2.7x (convolution) faster than the vendor-provided library, and outperforms expert-level hand-tuned code by 1.4x (GEMM), 1.1x (convolution), and 1.3x (fine-grained linear algebra). Additionally, we demonstrate that optimization schedules generated from Autocomp can be reused across similar tensor operations, improving speedups by up to 24% under a fixed sample budget.", 'abstract_zh': '硬件加速器，尤其是为张量处理设计的加速器，已成为当今计算领域无处不在的存在。然而，即使在构建编译器方面投入了大量努力，编程这些张量加速器仍然具有挑战性，导致其潜在性能远远未被充分利用。最近，大量代码训练的大语言模型（LLMs）在代码生成和优化任务中展现了显著的潜力，但生成低资源语言如专门的张量加速器代码仍然存在重大挑战。我们通过Autocomp的方法来应对这一挑战，该方法使加速器程序员能够利用领域知识和硬件反馈，通过自动化的LLM驱动搜索来优化代码。我们通过以下方式实现了这一点：1）将每个优化步骤形式化为结构化的两阶段提示，分为规划和代码生成阶段；2）在规划期间通过简洁且可适应的优化菜单插入领域知识；3）在每次搜索迭代中将正确性和性能指标作为反馈集成到硬件中。在三个代表性工作负载类别和两种不同的加速器上，我们展示了Autocomp优化的代码分别比供应商提供的库快5.6倍（GEMM）和2.7倍（卷积），并且在GEMM、卷积和精细粒度线性代数方面优于专家级别的手动调优代码1.4倍、1.1倍和1.3倍。此外，我们展示了从Autocomp生成的优化调度可以在类似张量操作之间重用，从而在固定样本预算下将加速性能提高多达24%。', 'title_zh': 'Autocomp: 由大规模语言模型驱动的张量加速器代码优化'}
{'arxiv_id': 'arXiv:2505.18572', 'title': 'MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework', 'authors': 'Yifan Zhu, Chao Zhang, Xin Shi, Xueqiao Zhang, Yi Yang, Yawei Luo', 'link': 'https://arxiv.org/abs/2505.18572', 'abstract': 'Large Language Models (LLMs)-based Multi-Agent Systems (MAS) exhibit remarkable problem-solving and task planning capabilities across diverse domains due to their specialized agentic roles and collaborative interactions. However, this also amplifies the severity of security risks under MAS attacks. To address this, we introduce MASTER, a novel security research framework for MAS, focusing on diverse Role configurations and Topological structures across various scenarios. MASTER offers an automated construction process for different MAS setups and an information-flow-based interaction paradigm. To tackle MAS security challenges in varied scenarios, we design a scenario-adaptive, extensible attack strategy utilizing role and topological information, which dynamically allocates targeted, domain-specific attack tasks for collaborative agent execution. Our experiments demonstrate that such an attack, leveraging role and topological information, exhibits significant destructive potential across most models. Additionally, we propose corresponding defense strategies, substantially enhancing MAS resilience across diverse scenarios. We anticipate that our framework and findings will provide valuable insights for future research into MAS security challenges.', 'abstract_zh': '基于大型语言模型的多 Agent 系统的新型安全研究框架：考虑多样化角色配置和拓扑结构', 'title_zh': 'MASTER：通过角色与拓扑结构探索实现多agent安全的综合框架'}
{'arxiv_id': 'arXiv:2505.18568', 'title': 'Learning without Isolation: Pathway Protection for Continual Learning', 'authors': 'Zhikang Chen, Abudukelimu Wuerkaixi, Sen Cui, Haoxuan Li, Ding Li, Jingfeng Zhang, Bo Han, Gang Niu, Houfang Liu, Yi Yang, Sifan Yang, Changshui Zhang, Tianling Ren', 'link': 'https://arxiv.org/abs/2505.18568', 'abstract': 'Deep networks are prone to catastrophic forgetting during sequential task learning, i.e., losing the knowledge about old tasks upon learning new tasks. To this end, continual learning(CL) has emerged, whose existing methods focus mostly on regulating or protecting the parameters associated with the previous tasks. However, parameter protection is often impractical, since the size of parameters for storing the old-task knowledge increases linearly with the number of tasks, otherwise it is hard to preserve the parameters related to the old-task knowledge. In this work, we bring a dual opinion from neuroscience and physics to CL: in the whole networks, the pathways matter more than the parameters when concerning the knowledge acquired from the old tasks. Following this opinion, we propose a novel CL framework, learning without isolation(LwI), where model fusion is formulated as graph matching and the pathways occupied by the old tasks are protected without being isolated. Thanks to the sparsity of activation channels in a deep network, LwI can adaptively allocate available pathways for a new task, realizing pathway protection and addressing catastrophic forgetting in a parameter-efficient manner. Experiments on popular benchmark datasets demonstrate the superiority of the proposed LwI.', 'abstract_zh': '深度网络在进行序列任务学习时容易发生灾难性遗忘，即在学习新任务时会丢失旧任务的知识。为此，连续学习(CL)应运而生，现有方法主要集中在调节或保护与之前任务相关的参数。然而，参数保护往往不切实际，因为用于存储旧任务知识的参数数量随任务数量线性增加，否则很难保留与旧任务知识相关的参数。在本工作中，我们从神经科学和物理学的角度出发，提出了一种新的观点应用于CL：在网络整体中，路径比参数更重要，当考虑从旧任务中学到的知识时。基于此观点，我们提出了一个新颖的连续学习框架“学习无孤立”(LwI)，其中模型融合被形式化为图匹配，旧任务所占的路径被保护而不被孤立。得益于深层网络激活通道的稀疏性，LwI 可以自适应地为新任务分配可用路径，从而实现路径保护并以参数高效的方式解决灾难性遗忘问题。实验在流行的基准数据集上证明了所提出的LwI的优越性。', 'title_zh': '无孤立学习：连续学习的路径保护'}
{'arxiv_id': 'arXiv:2505.18563', 'title': 'PacTrain: Pruning and Adaptive Sparse Gradient Compression for Efficient Collective Communication in Distributed Deep Learning', 'authors': 'Yisu Wang, Ruilong Wu, Xinjiao Li, Dirk Kutscher', 'link': 'https://arxiv.org/abs/2505.18563', 'abstract': 'Large-scale deep neural networks (DNN) exhibit excellent performance for various tasks. As DNNs and datasets grow, distributed training becomes extremely time-consuming and demands larger clusters. A main bottleneck is the resulting gradient aggregation overhead. While gradient compression and sparse collective communication techniques are commonly employed to alleviate network load, many gradient compression schemes do not achieve acceleration of the training process while also preserving accuracy. This paper introduces PacTrain, a novel framework that accelerates distributed training by combining pruning with sparse gradient compression. Active pruning of the neural network makes the model weights and gradients sparse. By ensuring the global knowledge of the gradient sparsity among all distributed training workers, we can perform lightweight compression communication without harming accuracy. We show that the PacTrain compression scheme achieves a near-optimal compression strategy while remaining compatible with the all-reduce primitive. Experimental evaluations show that PacTrain improves training throughput by 1.25 to 8.72 times compared to state-of-the-art compression-enabled systems for representative vision and language models training tasks under bandwidth-constrained conditions.', 'abstract_zh': '大规模深度神经网络（DNN）在各种任务中表现出色。随着DNN和数据集的增长，分布式训练变得极其耗时，并要求更大的计算集群。主要瓶颈是由此产生的梯度聚合开销。虽然梯度压缩和稀疏集体通信技术通常被用来缓解网络负载，但许多梯度压缩方案在加速训练过程的同时未能保持准确性。本文提出了一种名为PacTrain的新框架，通过结合剪枝与稀疏梯度压缩来加速分布式训练。通过对神经网络进行活动剪枝，使得模型权重和梯度变得稀疏。通过确保梯度稀疏性在所有分布式训练工作节点之间的全局知识，可以在不损害准确性的情况下进行轻量级压缩通信。实验评估表明，在带宽受限条件下，PacTrain压缩方案在代表性视觉和语言模型训练任务中相较于最先进的压缩启用系统，能将训练吞吐量提高1.25到8.72倍。', 'title_zh': 'PacTrain: 剪枝和自适应稀疏梯度压缩在分布式深度学习中高效集体通信'}
{'arxiv_id': 'arXiv:2505.18562', 'title': 'From Word to World: Evaluate and Mitigate Culture Bias via Word Association Test', 'authors': 'Xunlian Dai, Li Zhou, Benyou Wang, Haizhou Li', 'link': 'https://arxiv.org/abs/2505.18562', 'abstract': 'The human-centered word association test (WAT) serves as a cognitive proxy, revealing sociocultural variations through lexical-semantic patterns. We extend this test into an LLM-adaptive, free-relation task to assess the alignment of large language models (LLMs) with cross-cultural cognition. To mitigate the culture preference, we propose CultureSteer, an innovative approach that integrates a culture-aware steering mechanism to guide semantic representations toward culturally specific spaces. Experiments show that current LLMs exhibit significant bias toward Western cultural (notably in American) schemas at the word association level. In contrast, our model substantially improves cross-cultural alignment, surpassing prompt-based methods in capturing diverse semantic associations. Further validation on culture-sensitive downstream tasks confirms its efficacy in fostering cognitive alignment across cultures. This work contributes a novel methodological paradigm for enhancing cultural awareness in LLMs, advancing the development of more inclusive language technologies.', 'abstract_zh': '以人为中心的词联想法卌（WAT）作为一种认知代理，通过语言意义模式揭示社会文化差异。我们将其扩展为一种针对大规模语言模型（LLM）的自适应自由关联任务，以评估其与跨文化认知的对齐程度。为缓解文化偏好，我们提出了一种名为CultureSteer的创新方法，该方法通过融入一种文化意识的引导机制，使语义表示朝着特定文化空间发展。实验表明，当前的LLM在词联想法卌层面上表现出明显偏向西方文化（特别是美国文化）的偏见。相比之下，我们的模型在跨文化对齐方面取得了显著改善，其在捕捉多样化的语义关联方面超越了基于提示的方法。进一步在文化敏感的下游任务上的验证证实了其在促进跨文化交流认知对齐方面的有效性。本工作提供了一种新的方法论范式，以增强LLM的文化意识，推动更包容的语言技术的发展。', 'title_zh': '从词到世界：通过词联想法评估和减轻文化偏见'}
{'arxiv_id': 'arXiv:2505.18556', 'title': 'Exploring the Vulnerability of the Content Moderation Guardrail in Large Language Models via Intent Manipulation', 'authors': 'Jun Zhuang, Haibo Jin, Ye Zhang, Zhengjian Kang, Wenbin Zhang, Gaby G. Dagher, Haohan Wang', 'link': 'https://arxiv.org/abs/2505.18556', 'abstract': 'Intent detection, a core component of natural language understanding, has considerably evolved as a crucial mechanism in safeguarding large language models (LLMs). While prior work has applied intent detection to enhance LLMs\' moderation guardrails, showing a significant success against content-level jailbreaks, the robustness of these intent-aware guardrails under malicious manipulations remains under-explored. In this work, we investigate the vulnerability of intent-aware guardrails and demonstrate that LLMs exhibit implicit intent detection capabilities. We propose a two-stage intent-based prompt-refinement framework, IntentPrompt, that first transforms harmful inquiries into structured outlines and further reframes them into declarative-style narratives by iteratively optimizing prompts via feedback loops to enhance jailbreak success for red-teaming purposes. Extensive experiments across four public benchmarks and various black-box LLMs indicate that our framework consistently outperforms several cutting-edge jailbreak methods and evades even advanced Intent Analysis (IA) and Chain-of-Thought (CoT)-based defenses. Specifically, our "FSTR+SPIN" variant achieves attack success rates ranging from 88.25% to 96.54% against CoT-based defenses on the o1 model, and from 86.75% to 97.12% on the GPT-4o model under IA-based defenses. These findings highlight a critical weakness in LLMs\' safety mechanisms and suggest that intent manipulation poses a growing challenge to content moderation guardrails.', 'abstract_zh': '基于意图的防御漏洞研究：大语言模型的安全机制缺陷', 'title_zh': '通过意图操纵探索大型语言模型内容审核护栏的脆弱性'}
{'arxiv_id': 'arXiv:2505.18536', 'title': 'Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal Large Language Models', 'authors': 'Haoyuan Sun, Jiaqi Wu, Bo Xia, Yifu Luo, Yifei Zhao, Kai Qin, Xufei Lv, Tiantian Zhang, Yongzhe Chang, Xueqian Wang', 'link': 'https://arxiv.org/abs/2505.18536', 'abstract': 'Standing in 2025, at a critical juncture in the pursuit of Artificial General Intelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated significant potential in enhancing the reasoning capability of large language models (LLMs) and has led to the development of cutting-edge AI models such as OpenAI-o1 and DeepSeek-R1. Moreover, the efficient application of RFT to enhance the reasoning capability of multimodal large language models (MLLMs) has attracted widespread attention from the community. In this position paper, we argue that reinforcement fine-tuning powers the reasoning capability of multimodal large language models. To begin with, we provide a detailed introduction to the fundamental background knowledge that researchers interested in this field should be familiar with. Furthermore, we meticulously summarize the improvements of RFT in powering reasoning capability of MLLMs into five key points: diverse modalities, diverse tasks and domains, better training algorithms, abundant benchmarks and thriving engineering frameworks. Finally, we propose five promising directions for future research that the community might consider. We hope that this position paper will provide valuable insights to the community at this pivotal stage in the advancement toward AGI. Summary of works done on RFT for MLLMs is available at this https URL.', 'abstract_zh': '站在2025年，人工智能通用智能（AGI）追求的关键时刻，强化微调（RFT）已在增强大型语言模型（LLMs）的推理能力方面展示了显著潜力，并推动了如OpenAI-o1和DeepSeek-R1等前沿AI模型的发展。此外，将高效的RFT应用到多模态大型语言模型（MLLMs）以增强其推理能力引起了社区的广泛关注。在本文中，我们认为强化微调赋能了多模态大型语言模型的推理能力。首先，我们详细介绍了该领域的研究者应当熟悉的基础知识。其次，我们仔细总结了RFT在赋能MLLMs推理能力方面的五项改进：多样化的模态、多样化的任务和领域、更优的训练算法、丰富的基准数据集和繁荣的工程框架。最后，我们提出了社区在未来研究中可以考虑的五个有前景的方向。我们希望本文能够为AGI发展关键阶段的社区提供宝贵见解。有关RFT在MLLMs上的工作总结，请访问此链接：this https URL。', 'title_zh': '多模态大型语言模型的强化微调增强推理能力'}
{'arxiv_id': 'arXiv:2505.18533', 'title': 'TS-URGENet: A Three-stage Universal Robust and Generalizable Speech Enhancement Network', 'authors': 'Xiaobin Rong, Dahan Wang, Qinwen Hu, Yushi Wang, Yuxiang Hu, Jing Lu', 'link': 'https://arxiv.org/abs/2505.18533', 'abstract': 'Universal speech enhancement aims to handle input speech with different distortions and input formats. To tackle this challenge, we present TS-URGENet, a Three-Stage Universal, Robust, and Generalizable speech Enhancement Network. To address various distortions, the proposed system employs a novel three-stage architecture consisting of a filling stage, a separation stage, and a restoration stage. The filling stage mitigates packet loss by preliminarily filling lost regions under noise interference, ensuring signal continuity. The separation stage suppresses noise, reverberation, and clipping distortion to improve speech clarity. Finally, the restoration stage compensates for bandwidth limitation, codec artifacts, and residual packet loss distortion, refining the overall speech quality. Our proposed TS-URGENet achieved outstanding performance in the Interspeech 2025 URGENT Challenge, ranking 2nd in Track 1.', 'abstract_zh': '三阶段通用鲁棒可泛化语音增强网络', 'title_zh': 'TS-URGENet：三阶段通用鲁棒且泛化的语音增强网络'}
{'arxiv_id': 'arXiv:2505.18530', 'title': 'MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs', 'authors': 'Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim', 'link': 'https://arxiv.org/abs/2505.18530', 'abstract': 'Medical Large Vision-Language Models (Med-LVLMs) have been widely adopted for medical report generation. Despite Med-LVLMs producing state-of-the-art performance, they exhibit a bias toward predicting all findings as normal, leading to reports that overlook critical abnormalities. Furthermore, these models often fail to provide comprehensive descriptions of radiologically relevant regions necessary for accurate diagnosis. To address these challenges, we proposeMedical Report Generation Agents (MRGAgents), a novel multi-agent framework that fine-tunes specialized agents for different disease categories. By curating subsets of the IU X-ray and MIMIC-CXR datasets to train disease-specific agents, MRGAgents generates reports that more effectively balance normal and abnormal findings while ensuring a comprehensive description of clinically relevant regions. Our experiments demonstrate that MRGAgents outperformed the state-of-the-art, improving both report comprehensiveness and diagnostic utility.', 'abstract_zh': '医学大型视-语言模型（Med-LVLMs）在医学报告生成中得到了广泛应用。尽管Med-LVLMs能产生最先进的性能，但它们倾向于预测所有发现为正常，导致报告忽略了重要的异常。此外，这些模型往往不能提供准确诊断所需的相关放射学区域的全面描述。为了应对这些挑战，我们提出了一种新型多智能体框架——医学报告生成代理（MRGAgents），该框架针对不同疾病类别细调专门的智能体。通过定制IU X射线和MIMIC-CXR数据集中与特定疾病相关的子集进行训练，MRGAgents生成的报告更有效地平衡正常和异常发现，同时确保对临床相关区域的全面描述。我们的实验表明，MRGAgents在报告全面性和诊断效用方面均优于最先进的模型。', 'title_zh': 'MRGAgents: 一种基于医学生物语言模型的多 Agent 框架以改进医疗报告生成'}
{'arxiv_id': 'arXiv:2505.18527', 'title': 'CLaDMoP: Learning Transferrable Models from Successful Clinical Trials via LLMs', 'authors': 'Yiqing Zhang, Xiaozhong Liu, Fabricio Murai', 'link': 'https://arxiv.org/abs/2505.18527', 'abstract': 'Many existing models for clinical trial outcome prediction are optimized using task-specific loss functions on trial phase-specific data. While this scheme may boost prediction for common diseases and drugs, it can hinder learning of generalizable representations, leading to more false positives/negatives. To address this limitation, we introduce CLaDMoP, a new pre-training approach for clinical trial outcome prediction, alongside the Successful Clinical Trials dataset(SCT), specifically designed for this task. CLaDMoP leverages a Large Language Model-to encode trials\' eligibility criteria-linked to a lightweight Drug-Molecule branch through a novel multi-level fusion technique. To efficiently fuse long embeddings across levels, we incorporate a grouping block, drastically reducing computational overhead. CLaDMoP avoids reliance on task-specific objectives by pre-training on a "pair matching" proxy task. Compared to established zero-shot and few-shot baselines, our method significantly improves both PR-AUC and ROC-AUC, especially for phase I and phase II trials. We further evaluate and perform ablation on CLaDMoP after Parameter-Efficient Fine-Tuning, comparing it to state-of-the-art supervised baselines, including MEXA-CTP, on the Trial Outcome Prediction(TOP) benchmark. CLaDMoP achieves up to 10.5% improvement in PR-AUC and 3.6% in ROC-AUC, while attaining comparable F1 score to MEXA-CTP, highlighting its potential for clinical trial outcome prediction. Code and SCT dataset can be downloaded from this https URL.', 'abstract_zh': 'CLaDMoP：一种新的临床试验结果预测预训练方法及其在 Successful Clinical Trials 数据集上的应用', 'title_zh': 'CLaDMoP：通过大语言模型从成功的临床试验学习可转移模型'}
{'arxiv_id': 'arXiv:2505.18514', 'title': 'Test-Time Adaptation with Binary Feedback', 'authors': 'Taeckyung Lee, Sorn Chottananurak, Junsu Kim, Jinwoo Shin, Taesik Gong, Sung-Ju Lee', 'link': 'https://arxiv.org/abs/2505.18514', 'abstract': 'Deep learning models perform poorly when domain shifts exist between training and test data. Test-time adaptation (TTA) is a paradigm to mitigate this issue by adapting pre-trained models using only unlabeled test samples. However, existing TTA methods can fail under severe domain shifts, while recent active TTA approaches requiring full-class labels are impractical due to high labeling costs. To address this issue, we introduce a new setting of TTA with binary feedback. This setting uses a few binary feedback inputs from annotators to indicate whether model predictions are correct, thereby significantly reducing the labeling burden of annotators. Under the setting, we propose BiTTA, a novel dual-path optimization framework that leverages reinforcement learning to balance binary feedback-guided adaptation on uncertain samples with agreement-based self-adaptation on confident predictions. Experiments show BiTTA achieves 13.3%p accuracy improvements over state-of-the-art baselines, demonstrating its effectiveness in handling severe distribution shifts with minimal labeling effort. The source code is available at this https URL.', 'abstract_zh': '基于二元反馈的测试时自适应（BiTTA）方法：处理严重分布偏移的新方法', 'title_zh': '测试时自适应与二元反馈'}
{'arxiv_id': 'arXiv:2505.18512', 'title': 'AcuRank: Uncertainty-Aware Adaptive Computation for Listwise Reranking', 'authors': 'Soyoung Yoon, Gyuwan Kim, Gyu-Hwung Cho, Seung-won Hwang', 'link': 'https://arxiv.org/abs/2505.18512', 'abstract': 'Listwise reranking with large language models (LLMs) enhances top-ranked results in retrieval-based applications. Due to the limit in context size and high inference cost of long context, reranking is typically performed over a fixed size of small subsets, with the final ranking aggregated from these partial results. This fixed computation disregards query difficulty and document distribution, leading to inefficiencies. We propose AcuRank, an adaptive reranking framework that dynamically adjusts both the amount and target of computation based on uncertainty estimates over document relevance. Using a Bayesian TrueSkill model, we iteratively refine relevance estimates until reaching sufficient confidence levels, and our explicit modeling of ranking uncertainty enables principled control over reranking behavior and avoids unnecessary updates to confident predictions. Results on the TREC-DL and BEIR benchmarks show that our method consistently achieves a superior accuracy-efficiency trade-off and scales better with compute than fixed-computation baselines. These results highlight the effectiveness and generalizability of our method across diverse retrieval tasks and LLM-based reranking models.', 'abstract_zh': '使用大规模语言模型（LLMs）进行列表级别的重排可增强基于检索的应用中的顶级结果。由于上下文大小的限制和长期上下文推理成本高，重排通常在固定大小的小子集上进行，最终排名从这些部分结果聚合而来。这种固定的计算忽略了查询难度和文档分布，导致效率低下。我们提出了AcuRank，一种基于文档相关性不确定性估计动态调整计算量和目标的自适应重排框架。利用贝叶斯TrueSkill模型，我们逐步细化相关性估计，直到达到足够的信心水平，并通过明确建模排名不确定性实现了对重排行为的原则性控制，避免了对有信心预测不必要的更新。在TREC-DL和BEIR基准上的结果表明，我们的方法在准确性和效率权衡上始终表现优越，并且在计算资源上的扩展性优于固定计算量基线。这些结果突显了我们在不同检索任务和基于LLM的重排模型上的方法的有效性和泛化能力。', 'title_zh': 'AcuRank: 基于不确定性自适应计算的列表重排序'}
{'arxiv_id': 'arXiv:2505.18505', 'title': 'How Particle System Theory Enhances Hypergraph Message Passing', 'authors': 'Yixuan Ma, Kai Yi, Pietro Lio, Shi Jin, Yu Guang Wang', 'link': 'https://arxiv.org/abs/2505.18505', 'abstract': 'Hypergraphs effectively model higher-order relationships in natural phenomena, capturing complex interactions beyond pairwise connections. We introduce a novel hypergraph message passing framework inspired by interacting particle systems, where hyperedges act as fields inducing shared node dynamics. By incorporating attraction, repulsion, and Allen-Cahn forcing terms, particles of varying classes and features achieve class-dependent equilibrium, enabling separability through the particle-driven message passing. We investigate both first-order and second-order particle system equations for modeling these dynamics, which mitigate over-smoothing and heterophily thus can capture complete interactions. The more stable second-order system permits deeper message passing. Furthermore, we enhance deterministic message passing with stochastic element to account for interaction uncertainties. We prove theoretically that our approach mitigates over-smoothing by maintaining a positive lower bound on the hypergraph Dirichlet energy during propagation and thus to enable hypergraph message passing to go deep. Empirically, our models demonstrate competitive performance on diverse real-world hypergraph node classification tasks, excelling on both homophilic and heterophilic datasets.', 'abstract_zh': '基于交互粒子系统的高阶关系高效建模：高阶图消息传递框架及其应用', 'title_zh': '粒子系统理论增强超图消息传递'}
{'arxiv_id': 'arXiv:2505.18499', 'title': 'G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning', 'authors': 'Xiaojun Guo, Ang Li, Yifei Wang, Stefanie Jegelka, Yisen Wang', 'link': 'https://arxiv.org/abs/2505.18499', 'abstract': "Although Large Language Models (LLMs) have demonstrated remarkable progress, their proficiency in graph-related tasks remains notably limited, hindering the development of truly general-purpose models. Previous attempts, including pretraining graph foundation models or employing supervised fine-tuning, often face challenges such as the scarcity of large-scale, universally represented graph data. We introduce G1, a simple yet effective approach demonstrating that Reinforcement Learning (RL) on synthetic graph-theoretic tasks can significantly scale LLMs' graph reasoning abilities. To enable RL training, we curate Erdõs, the largest graph reasoning dataset to date comprising 50 diverse graph-theoretic tasks of varying difficulty levels, 100k training data and 5k test data, all drived from real-world graphs. With RL on Erdõs, G1 obtains substantial improvements in graph reasoning, where our finetuned 3B model even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models also show strong zero-shot generalization to unseen tasks, domains, and graph encoding schemes, including other graph-theoretic benchmarks as well as real-world node classification and link prediction tasks, without compromising general reasoning abilities. Our findings offer an efficient, scalable path for building strong graph reasoners by finetuning LLMs with RL on graph-theoretic tasks, which combines the strengths of pretrained LLM capabilities with abundant, automatically generated synthetic data, suggesting that LLMs possess graph understanding abilities that RL can elicit successfully.", 'abstract_zh': '虽然大规模语言模型（LLMs）取得了显著进展，但在图相关任务上的能力仍然受到明显限制，阻碍了真正通用模型的发展。以往尝试，包括预先训练图基础模型或采用监督微调，往往面临大规模、通用表示图数据稀缺的挑战。我们引入了G1，这是一种简单而有效的方法，证明了在合成图理论任务上使用强化学习（RL）可以显著提升LLMs的图推理能力。为了支持RL训练，我们制定了Erdõs数据集，这是迄今为止最大的图推理数据集，包含50个难度各异的图理论任务，100,000个训练数据和5,000个测试数据，均来自真实世界的图。通过在Erdõs上的RL训练，G1在图推理上取得了显著改进，我们的微调3B模型甚至超过了Qwen2.5-72B-Instruct（大小为其24倍）。经RL训练的模型还展示了强大的零样本泛化能力，适用于未见过的任务、领域和图编码方案，包括其他图理论基准以及真实世界的节点分类和链接预测任务，而不会削弱普遍推理能力。我们的发现提供了一条通过在图理论任务上使用RL微调LLMs来构建强大图推理者的有效、可扩展路径，结合了预训练LLM能力与丰富、自动生成的合成数据的优势，表明LLMs具有RL能够成功揭示的图理解能力。', 'title_zh': '教学大规模语言模型使用强化学习进行图推理'}
{'arxiv_id': 'arXiv:2505.18494', 'title': 'FedHL: Federated Learning for Heterogeneous Low-Rank Adaptation via Unbiased Aggregation', 'authors': 'Zihao Peng, Jiandian Zeng, Boyuan Li, Guo Li, Shengbo Chen, Tian Wang', 'link': 'https://arxiv.org/abs/2505.18494', 'abstract': 'Federated Learning (FL) facilitates the fine-tuning of Foundation Models (FMs) using distributed data sources, with Low-Rank Adaptation (LoRA) gaining popularity due to its low communication costs and strong performance. While recent work acknowledges the benefits of heterogeneous LoRA in FL and introduces flexible algorithms to support its implementation, our theoretical analysis reveals a critical gap: existing methods lack formal convergence guarantees due to parameter truncation and biased gradient updates. Specifically, adapting client-specific LoRA ranks necessitates truncating global parameters, which introduces inherent truncation errors and leads to subsequent inaccurate gradient updates that accumulate over training rounds, ultimately degrading performance. To address the above issues, we propose \\textbf{FedHL}, a simple yet effective \\textbf{Fed}erated Learning framework tailored for \\textbf{H}eterogeneous \\textbf{L}oRA. By leveraging the full-rank global model as a calibrated aggregation basis, FedHL eliminates the direct truncation bias from initial alignment with client-specific ranks. Furthermore, we derive the theoretically optimal aggregation weights by minimizing the gradient drift term in the convergence upper bound. Our analysis shows that FedHL guarantees $\\mathcal{O}(1/\\sqrt{T})$ convergence rate, and experiments on multiple real-world datasets demonstrate a 1-3\\% improvement over several state-of-the-art methods.', 'abstract_zh': 'federated学习（FL）利用分布式数据源细调基础模型（FMs），低秩适应（LoRA）由于其低通信成本和强大性能而受到欢迎。尽管近期工作承认了异构LoRA在FL中的益处并引入了灵活的算法来支持其实现，我们的理论分析揭示了一个关键缺口：现有方法缺乏正式的收敛保证，由于参数截断和有偏梯度更新。具体来说，适应客户端特定的LoRA秩需要截断全局参数，这引入了固有的截断误差，并导致随后不准确的梯度更新在训练轮次中积累，最终导致性能下降。为了解决上述问题，我们提出了\\textbf{FedHL}，这是一个简单而有效的针对\\textbf{H}eterogeneous \\textbf{L}oRA的\\textbf{F}ederated学习框架。通过利用完整的全局模型作为校准聚合基础，FedHL消除了与客户端特定秩初始对齐时的直接截断偏差。此外，我们通过最小化收敛上界中的梯度漂移项来推导出理论上最优的聚合权重。我们的分析表明，FedHL保证了$\\mathcal{O}(1/\\sqrt{T})$的收敛速率，并且在多个真实世界数据集上的实验结果显示相比于几种最先进的方法，其性能提高了1-3%。', 'title_zh': 'FedHL: 异质低秩适应的无偏聚合联邦学习'}
{'arxiv_id': 'arXiv:2505.18488', 'title': 'Synthesizing and Adapting Error Correction Data for Mobile Large Language Model Applications', 'authors': 'Yanxiang Zhang, Zheng Xu, Shanshan Wu, Yuanbo Zhang, Daniel Ramage', 'link': 'https://arxiv.org/abs/2505.18488', 'abstract': 'Error correction is an important capability when applying large language models (LLMs) to facilitate user typing on mobile devices. In this paper, we use LLMs to synthesize a high-quality dataset of error correction pairs to evaluate and improve LLMs for mobile applications. We first prompt LLMs with error correction domain knowledge to build a scalable and reliable addition to the existing data synthesis pipeline. We then adapt the synthetic data distribution to match the mobile application domain by reweighting the samples. The reweighting model is learnt by predicting (a handful of) live A/B test metrics when deploying LLMs in production, given the LLM performance on offline evaluation data and scores from a small privacy-preserving on-device language model. Finally, we present best practices for mixing our synthetic data with other data sources to improve model performance on error correction in both offline evaluation and production live A/B testing.', 'abstract_zh': '大型语言模型在移动设备上应用时辅助用户输入错误修正是一项重要能力。本文利用大型语言模型合成高质量的错误修正数据集以评估和改进适用于移动应用的大型语言模型。我们首先利用错误修正领域的知识提示大型语言模型，构建扩展现有数据合成管道的可扩展且可靠的补充内容。然后，通过重新加权样本，使合成数据分布与移动应用领域相匹配。重新加权模型通过预测部署大型语言模型时的实时A/B测试指标（给定离线评估数据上的大型语言模型性能和小型私有设备语言模型的分数）来学习。最后，我们介绍了在错误修正的离线评估和生产实时A/B测试中提高模型性能的最佳实践，包括将合成数据与其他数据源混合的方法。', 'title_zh': '合成和适应错误纠正数据以应用于移动大型语言模型'}
{'arxiv_id': 'arXiv:2505.18475', 'title': 'Using Large Language Models to Tackle Fundamental Challenges in Graph Learning: A Comprehensive Survey', 'authors': 'Mengran Li, Pengyu Zhang, Wenbin Xing, Yijia Zheng, Klim Zaporojets, Junzhou Chen, Ronghui Zhang, Yong Zhang, Siyuan Gong, Jia Hu, Xiaolei Ma, Zhiyuan Liu, Paul Groth, Marcel Worring', 'link': 'https://arxiv.org/abs/2505.18475', 'abstract': 'Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. Conventional graph learning approaches typically rely on fixed structural assumptions or fully observed data, limiting their effectiveness in more complex, noisy, or evolving settings. Consequently, real-world graph data often violates the assumptions of traditional graph learning methods, in particular, it leads to four fundamental challenges: (1) Incompleteness, real-world graphs have missing nodes, edges, or attributes; (2) Imbalance, the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity, graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability, graphs evolve over time in unpredictable ways. Recent advances in Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey provides a comprehensive review of how LLMs can be integrated with graph learning to address the aforementioned challenges. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: this https URL.', 'abstract_zh': '大型语言模型在图学习中的应用：解决非欧几里得数据挑战的研究综述', 'title_zh': '使用大规模语言模型应对图学习中的基础挑战：一项全面综述'}
{'arxiv_id': 'arXiv:2505.18471', 'title': 'Invisible Tokens, Visible Bills: The Urgent Need to Audit Hidden Operations in Opaque LLM Services', 'authors': 'Guoheng Sun, Ziyao Wang, Xuandong Zhao, Bowei Tian, Zheyu Shen, Yexiao He, Jinming Xing, Ang Li', 'link': 'https://arxiv.org/abs/2505.18471', 'abstract': 'Modern large language model (LLM) services increasingly rely on complex, often abstract operations, such as multi-step reasoning and multi-agent collaboration, to generate high-quality outputs. While users are billed based on token consumption and API usage, these internal steps are typically not visible. We refer to such systems as Commercial Opaque LLM Services (COLS). This position paper highlights emerging accountability challenges in COLS: users are billed for operations they cannot observe, verify, or contest. We formalize two key risks: \\textit{quantity inflation}, where token and call counts may be artificially inflated, and \\textit{quality downgrade}, where providers might quietly substitute lower-cost models or tools. Addressing these risks requires a diverse set of auditing strategies, including commitment-based, predictive, behavioral, and signature-based methods. We further explore the potential of complementary mechanisms such as watermarking and trusted execution environments to enhance verifiability without compromising provider confidentiality. We also propose a modular three-layer auditing framework for COLS and users that enables trustworthy verification across execution, secure logging, and user-facing auditability without exposing proprietary internals. Our aim is to encourage further research and policy development toward transparency, auditability, and accountability in commercial LLM services.', 'abstract_zh': '现代商业不透明大型语言模型服务中的新兴问责难题及其应对策略', 'title_zh': '隐形令牌，可见账单：审计不透明LLM服务中隐藏操作的迫切需求'}
{'arxiv_id': 'arXiv:2505.18464', 'title': 'From Reddit to Generative AI: Evaluating Large Language Models for Anxiety Support Fine-tuned on Social Media Data', 'authors': 'Ugur Kursuncu, Trilok Padhi, Gaurav Sinha, Abdulkadir Erol, Jaya Krishna Mandivarapu, Christopher R. Larrison', 'link': 'https://arxiv.org/abs/2505.18464', 'abstract': 'The growing demand for accessible mental health support, compounded by workforce shortages and logistical barriers, has led to increased interest in utilizing Large Language Models (LLMs) for scalable and real-time assistance. However, their use in sensitive domains such as anxiety support remains underexamined. This study presents a systematic evaluation of LLMs (GPT and Llama) for their potential utility in anxiety support by using real user-generated posts from the r/Anxiety subreddit for both prompting and fine-tuning. Our approach utilizes a mixed-method evaluation framework incorporating three main categories of criteria: (i) linguistic quality, (ii) safety and trustworthiness, and (iii) supportiveness. Results show that fine-tuning LLMs with naturalistic anxiety-related data enhanced linguistic quality but increased toxicity and bias, and diminished emotional responsiveness. While LLMs exhibited limited empathy, GPT was evaluated as more supportive overall. Our findings highlight the risks of fine-tuning LLMs on unprocessed social media content without mitigation strategies.', 'abstract_zh': '快速增长的可访问心理健康支持需求，加之人力资源短缺和物流障碍，促使人们越来越多地考虑利用大型语言模型（LLMs）提供 scalable 和实时帮助。然而，其在焦虑支持等敏感领域中的应用仍然缺乏研究。本研究通过使用来自 r/Anxiety 子reddit 的实际用户生成帖子来提示和微调，系统性评估了 GPT 和 Llama 等LLMs在焦虑支持中的潜在用途。我们的方法采用了混合方法评估框架，包含三个主要评价标准类别：(i) 语言质量，(ii) 安全性和可信度，(iii) 支持性。结果显示，使用自然语言处理过的焦虑相关数据微调 LLMs 提高了语言质量，但增加了毒性和偏见，并降低了情感响应性。虽然LLMs在移情方面表现有限，但GPT总体上被认为更具支持性。本研究结果强调了在没有缓解策略的情况下使用未处理社交媒体内容微调LLMs所带来的风险。', 'title_zh': '从Reddit到生成型AI：基于社交媒体数据 fine-tuned 的焦虑支持大型语言模型评估'}
{'arxiv_id': 'arXiv:2505.18461', 'title': 'Performance and Generalizability Impacts of Incorporating Geolocation into Deep Learning for Dynamic PM2.5 Estimation', 'authors': 'Morteza Karimzadeh, Zhongying Wang, James L. Crooks', 'link': 'https://arxiv.org/abs/2505.18461', 'abstract': 'Deep learning models have demonstrated success in geospatial applications, yet quantifying the role of geolocation information in enhancing model performance and geographic generalizability remains underexplored. A new generation of location encoders have emerged with the goal of capturing attributes present at any given location for downstream use in predictive modeling. Being a nascent area of research, their evaluation has remained largely limited to static tasks such as species distributions or average temperature mapping. In this paper, we discuss and quantify the impact of incorporating geolocation into deep learning for a real-world application domain that is characteristically dynamic (with fast temporal change) and spatially heterogeneous at high resolutions: estimating surface-level daily PM2.5 levels using remotely sensed and ground-level data. We build on a recently published deep learning-based PM2.5 estimation model that achieves state-of-the-art performance on data observed in the contiguous United States. We examine three approaches for incorporating geolocation: excluding geolocation as a baseline, using raw geographic coordinates, and leveraging pretrained location encoders. We evaluate each approach under within-region (WR) and out-of-region (OoR) evaluation scenarios. Aggregate performance metrics indicate that while naïve incorporation of raw geographic coordinates improves within-region performance by retaining the interpolative value of geographic location, it can hinder generalizability across regions. In contrast, pretrained location encoders like GeoCLIP enhance predictive performance and geographic generalizability for both WR and OoR scenarios. However, qualitative analysis reveals artifact patterns caused by high-degree basis functions and sparse upstream samples in certain areas, and ablation results indicate varying performance among location encoders...', 'abstract_zh': '深度学习模型在地理空间应用中取得了成功，但量化地理位置信息在增强模型性能和地理普适性方面的作用仍待深入探究。新兴的位置编码器旨在捕捉任何位置存在的属性，以便在下游预测建模中使用。作为研究的新兴领域，它们的评估主要局限于静态任务，如物种分布或平均温度地图。在本文中，我们探讨并量化了将地理位置纳入深度学习在具有动态特性和高分辨率空间异质性的实际应用领域中的影响：使用遥感和地面数据估算表面日均PM2.5水平。我们构建了一个基于深度学习的PM2.5估算模型，该模型在美国大陆观测数据上实现了 currentState-of-the-art 性能。我们探讨了三种地理位置纳入方法：排除地理位置作为基线、使用原始地理坐标以及利用预训练的位置编码器。我们在区域内部（WR）和区域外部（OoR）评估场景下评估了每种方法。综合性能指标表明，虽然原始地理坐标的大规模纳入在区域内部提升了性能，但可能削弱了跨区域的普适性。相比之下，预训练的位置编码器如GeoCLIP在区域内部和区域外部场景中均提升了预测性能和地理普适性。然而，定性分析揭示了由高阶基函数和上游稀疏样本引起的模式异常，并且消除实验表明不同位置编码器的性能各异……', 'title_zh': '将地理定位融入深度学习以动态估算PM2.5的影响：性能与泛化能力'}
{'arxiv_id': 'arXiv:2505.18458', 'title': 'A Survey of LLM $\\times$ DATA', 'authors': 'Xuanhe Zhou, Junxuan He, Wei Zhou, Haodong Chen, Zirui Tang, Haoyu Zhao, Xin Tong, Guoliang Li, Youmin Chen, Jun Zhou, Zhaojun Sun, Binyuan Hui, Shuo Wang, Conghui He, Zhiyuan Liu, Jingren Zhou, Fan Wu', 'link': 'https://arxiv.org/abs/2505.18458', 'abstract': 'The integration of large language model (LLM) and data management (DATA) is rapidly redefining both domains. In this survey, we comprehensively review the bidirectional relationships. On the one hand, DATA4LLM, spanning large-scale data processing, storage, and serving, feeds LLMs with high quality, diversity, and timeliness of data required for stages like pre-training, post-training, retrieval-augmented generation, and agentic workflows: (i) Data processing for LLMs includes scalable acquisition, deduplication, filtering, selection, domain mixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on efficient data and model formats, distributed and heterogeneous storage hierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data serving for LLMs tackles challenges in RAG (e.g., knowledge post-processing), LLM inference (e.g., prompt compression, data provenance), and training strategies (e.g., data packing and shuffling). On the other hand, in LLM4DATA, LLMs are emerging as general-purpose engines for data management. We review recent advances in (i) data manipulation, including automatic data cleaning, integration, discovery; (ii) data analysis, covering reasoning over structured, semi-structured, and unstructured data, and (iii) system optimization (e.g., configuration tuning, query rewriting, anomaly diagnosis), powered by LLM techniques like retrieval-augmented prompting, task-specialized fine-tuning, and multi-agent collaboration.', 'abstract_zh': '大规模语言模型（LLM）与数据管理（DATA）的整合正迅速重塑这两个领域。在本文综述中，我们全面回顾了二者之间的双向关系。一方面，DATA4LLM，覆盖大规模数据处理、存储和供给，为LLM在预训练、后训练、检索增强生成和自主工作流等阶段提供高质量、多样性和及时性的数据，包括：(i) 对LLM的数据处理包括可扩展的数据获取、去重、过滤、选择、领域混合和合成增强；(ii) LLMD数据存储关注高效的数据和模型格式、分布式和异构存储层次结构、KV缓存管理以及容错检查点；(iii) LLMD数据供给解决挑战，如RAG的知识后处理、LLM推理（如提示压缩、数据溯源）和训练策略（如数据打包和打乱）。另一方面，在LLM4DATA中，LLM正成为通用的数据管理引擎。我们回顾了数据操作（包括自动数据清洗、集成和发现）、数据分析（包括结构化、半结构化和非结构化数据的推理）以及系统优化（如配置调优、查询重写和异常诊断）的近期进展，这些进展得益于如检索增强提示、任务专用微调和多代理协作等LLM技术。', 'title_zh': 'LLM与数据综述'}
{'arxiv_id': 'arXiv:2505.18453', 'title': 'MPE-TTS: Customized Emotion Zero-Shot Text-To-Speech Using Multi-Modal Prompt', 'authors': 'Zhichao Wu, Yueteng Kang, Songjun Cao, Long Ma, Qiulin Li, Qun Yang', 'link': 'https://arxiv.org/abs/2505.18453', 'abstract': 'Most existing Zero-Shot Text-To-Speech(ZS-TTS) systems generate the unseen speech based on single prompt, such as reference speech or text descriptions, which limits their flexibility. We propose a customized emotion ZS-TTS system based on multi-modal prompt. The system disentangles speech into the content, timbre, emotion and prosody, allowing emotion prompts to be provided as text, image or speech. To extract emotion information from different prompts, we propose a multi-modal prompt emotion encoder. Additionally, we introduce an prosody predictor to fit the distribution of prosody and propose an emotion consistency loss to preserve emotion information in the predicted prosody. A diffusion-based acoustic model is employed to generate the target mel-spectrogram. Both objective and subjective experiments demonstrate that our system outperforms existing systems in terms of naturalness and similarity. The samples are available at this https URL.', 'abstract_zh': '基于多模态提示的定制情感零样本文本到语音系统', 'title_zh': 'MPE-TTS：基于多模态提示的定制化零样本文本到语音合成'}
{'arxiv_id': 'arXiv:2505.18451', 'title': '$μ$-MoE: Test-Time Pruning as Micro-Grained Mixture-of-Experts', 'authors': 'Toshiaki Koike-Akino, Jing Liu, Ye Wang', 'link': 'https://arxiv.org/abs/2505.18451', 'abstract': 'To tackle the huge computational demand of large foundation models, activation-aware compression techniques without retraining have been introduced. However, since these rely on calibration data, domain shift may arise for unknown downstream tasks. With a computationally efficient calibration, activation-aware pruning can be executed for every prompt adaptively, yet achieving reduced complexity at inference. We formulate it as a mixture of micro-experts, called $\\mu$-MoE. Several experiments demonstrate that $\\mu$-MoE can dynamically adapt to task/prompt-dependent structured sparsity on the fly.', 'abstract_zh': '激活感知压缩技术在不重新训练的情况下应对大规模基础模型的庞大计算需求，但可能因校准数据而产生领域偏移。通过计算高效校准，激活感知剪枝可以适应每个提示动态执行，从而在推理时实现降低复杂度。我们将其形式化为微专家的混合模型，称为$\\mu$-MoE。实验结果表明，$\\mu$-MoE可以在运行时动态适应任务/提示相关的结构稀疏性。', 'title_zh': '$\\mu$-MoE: 测试时裁剪作为细粒度混合专家模型'}
{'arxiv_id': 'arXiv:2505.18446', 'title': 'Mitigating Context Bias in Domain Adaptation for Object Detection using Mask Pooling', 'authors': 'Hojun Son, Asma Almutairi, Arpan Kusari', 'link': 'https://arxiv.org/abs/2505.18446', 'abstract': 'Context bias refers to the association between the foreground objects and background during the object detection training process. Various methods have been proposed to minimize the context bias when applying the trained model to an unseen domain, known as domain adaptation for object detection (DAOD). But a principled approach to understand why the context bias occurs and how to remove it has been missing.\nIn this work, we provide a causal view of the context bias, pointing towards the pooling operation in the convolution network architecture as the possible source of this bias. We present an alternative, Mask Pooling, which uses an additional input of foreground masks, to separate the pooling process in the respective foreground and background regions and show that this process leads the trained model to detect objects in a more robust manner under different domains. We also provide a benchmark designed to create an ultimate test for DAOD, using foregrounds in the presence of absolute random backgrounds, to analyze the robustness of the intended trained models. Through these experiments, we hope to provide a principled approach for minimizing context bias under domain shift.', 'abstract_zh': '上下文偏差是指目标检测训练过程中前景对象与背景之间的关联。各种方法已被提出，以在应用于未见过的领域时最小化上下文偏差，这被称为目标检测的领域适应（DAOD）。然而，尚未有一个基本的方法来理解上下文偏差为什么会发生以及如何消除它。\n在本文中，我们从因果角度探讨了上下文偏差，将其归因于卷积网络架构中的聚合操作可能是这种偏差的来源。我们提出了替代方案——掩码聚合，它使用前景掩码的附加输入，将聚合过程分别应用于前景和背景区域，证明这一过程使训练模型在不同领域中以更稳健的方式检测对象。我们还提供了一个基准测试，该测试使用前景和绝对随机背景来创建一个最终的DAOD测试，以分析目标训练模型的稳健性。通过这些实验，我们希望提供一种在领域转换中最小化上下文偏差的基本方法。', 'title_zh': '使用Mask Pooling减轻领域适应中对象检测的上下文偏差'}
{'arxiv_id': 'arXiv:2505.18442', 'title': 'Breaking Silos: Adaptive Model Fusion Unlocks Better Time Series Forecasting', 'authors': 'Zhining Liu, Ze Yang, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Yada Zhu, Hendrik Hamann, Jingrui He, Hanghang Tong', 'link': 'https://arxiv.org/abs/2505.18442', 'abstract': 'Time-series forecasting plays a critical role in many real-world applications. Although increasingly powerful models have been developed and achieved superior results on benchmark datasets, through a fine-grained sample-level inspection, we find that (i) no single model consistently outperforms others across different test samples, but instead (ii) each model excels in specific cases. These findings prompt us to explore how to adaptively leverage the distinct strengths of various forecasting models for different samples. We introduce TimeFuse, a framework for collective time-series forecasting with sample-level adaptive fusion of heterogeneous models. TimeFuse utilizes meta-features to characterize input time series and trains a learnable fusor to predict optimal model fusion weights for any given input. The fusor can leverage samples from diverse datasets for joint training, allowing it to adapt to a wide variety of temporal patterns and thus generalize to new inputs, even from unseen datasets. Extensive experiments demonstrate the effectiveness of TimeFuse in various long-/short-term forecasting tasks, achieving near-universal improvement over the state-of-the-art individual models. Code is available at this https URL.', 'abstract_zh': '时间序列预测在许多实际应用中扮演着关键角色。尽管不断发展的强大模型在基准数据集中取得了卓越的结果，但我们通过细粒度的样本级检查发现：(i) 没有一种模型能够一致地在所有测试样本上表现 superior，相反 (ii) 每种模型在特定情况下表现出色。这些发现促使我们探索如何根据不同的样本 adaptively 利用各种预测模型的独特优势。我们提出了 TimeFuse 框架，这是一种基于样本级异构模型自适应融合的时间序列集体预测框架。TimeFuse 利用元特征来表征输入时间序列，并训练一个可学习的融合器以预测任何给定输入的最佳模型融合权重。融合器可以从多样化的数据集中学习样本，从而适应各种时间模式，并能够泛化到新的输入，甚至是未见过的数据集。广泛实验证明，TimeFuse 在各种长期/短期预测任务中表现出色，实现了对先进个体模型的近似全面改进。代码可在该网址获取。', 'title_zh': '打破壁垒：自适应模型融合解锁更好的时间序列预测'}
{'arxiv_id': 'arXiv:2505.18440', 'title': 'Efficient Long CoT Reasoning in Small Language Models', 'authors': 'Zhaoyang Wang, Jinqi Jiang, Tian Qiu, Hui Liu, Xianfeng Tang, Huaxiu Yao', 'link': 'https://arxiv.org/abs/2505.18440', 'abstract': 'Recent large reasoning models such as DeepSeek-R1 exhibit strong complex problems solving abilities by generating long chain-of-thought (CoT) reasoning steps. It is challenging to directly train small language models (SLMs) to emerge long CoT. Thus, distillation becomes a practical method to enable SLMs for such reasoning ability. However, the long CoT often contains a lot of redundant contents (e.g., overthinking steps) which may make SLMs hard to learn considering their relatively poor capacity and generalization. To address this issue, we propose a simple-yet-effective method to prune unnecessary steps in long CoT, and then employ an on-policy method for the SLM itself to curate valid and useful long CoT training data. In this way, SLMs can effectively learn efficient long CoT reasoning and preserve competitive performance at the same time. Experimental results across a series of mathematical reasoning benchmarks demonstrate the effectiveness of the proposed method in distilling long CoT reasoning ability into SLMs which maintains the competitive performance but significantly reduces generating redundant reasoning steps.', 'abstract_zh': '近期的大规模推理模型如DeepSeek-R1通过生成长链条推理步骤（CoT）展现出强大的复杂问题解决能力。直接训练小型语言模型（SLMs）以生成长链条推理步骤具有挑战性。因此，蒸馏成为一种实用的方法以使SLMs具备这种推理能力。然而，长链条推理步骤通常包含许多冗余内容（例如，过度思考的步骤），这可能使得SLMs难以学习，考虑到它们相对较差的容量和泛化能力。为了解决这个问题，我们提出了一种简单有效的方法来修剪长链条推理步骤中的不必要的步骤，并利用一种在线策略方法对SLMs本身进行训练，以生成有效且有用的长链条推理训练数据。这样，SLMs可以有效地学习高效的长链条推理，并同时保持竞争力。一系列数学推理基准的实验结果证明，所提出的方法在将长链条推理能力蒸馏到SLMs中的有效性，该方法能够保持竞争力的同时显著减少生成冗余推理步骤。', 'title_zh': '小语言模型中高效长链推理'}
{'arxiv_id': 'arXiv:2505.18434', 'title': 'TNG-CLIP:Training-Time Negation Data Generation for Negation Awareness of CLIP', 'authors': 'Yuliang Cai, Jesse Thomason, Mohammad Rostami', 'link': 'https://arxiv.org/abs/2505.18434', 'abstract': "Vision-language models (VLMs), such as CLIP, have demonstrated strong performance across a range of downstream tasks. However, CLIP is still limited in negation understanding: the ability to recognize the absence or exclusion of a concept. Existing methods address the problem by using a large language model (LLM) to generate large-scale data of image captions containing negation for further fine-tuning CLIP. However, these methods are both time- and compute-intensive, and their evaluations are typically restricted to image-text matching tasks. To expand the horizon, we (1) introduce a training-time negation data generation pipeline such that negation captions are generated during the training stage, which only increases 2.5% extra training time, and (2) we propose the first benchmark, Neg-TtoI, for evaluating text-to-image generation models on prompts containing negation, assessing model's ability to produce semantically accurate images. We show that our proposed method, TNG-CLIP, achieves SOTA performance on diverse negation benchmarks of image-to-text matching, text-to-image retrieval, and image generation.", 'abstract_zh': 'Vision-language模型（VLMs），如CLIP，在多种下游任务中展现出了强大的性能。然而，CLIP在否定理解方面 still有限：即识别概念的缺失或排除的能力。现有的方法通过使用大规模语言模型（LLM）生成包含否定的图片字幕数据集，进一步fine-tune CLIP来解决这个问题。然而，这些方法既耗费时间和计算资源，其评估通常限于图像-文本匹配任务。为进一步扩大研究范围，我们（1）提出了一种在训练阶段生成否定数据的训练流水线，使得否定字幕在训练期间生成，仅增加了2.5%的额外训练时间；（2）提出了第一个基准测试Neg-TtoI，用于评估文本到图像生成模型在包含否定的提示上的表现，评估模型生成语义准确图像的能力。我们展示了我们提出的方法TNG-CLIP在图像到文本匹配、文本到图像检索和图像生成等多样化否定基准上的SOTA性能。', 'title_zh': 'TNG-CLIP：训练时否定数据生成以增强CLIP的否定意识'}
{'arxiv_id': 'arXiv:2505.18426', 'title': 'Retrieval Augmented Generation-based Large Language Models for Bridging Transportation Cybersecurity Legal Knowledge Gaps', 'authors': 'Khandakar Ashrafi Akbar, Md Nahiyan Uddin, Latifur Khan, Trayce Hockstad, Mizanur Rahman, Mashrur Chowdhury, Bhavani Thuraisingham', 'link': 'https://arxiv.org/abs/2505.18426', 'abstract': 'As connected and automated transportation systems evolve, there is a growing need for federal and state authorities to revise existing laws and develop new statutes to address emerging cybersecurity and data privacy challenges. This study introduces a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM) framework designed to support policymakers by extracting relevant legal content and generating accurate, inquiry-specific responses. The framework focuses on reducing hallucinations in LLMs by using a curated set of domain-specific questions to guide response generation. By incorporating retrieval mechanisms, the system enhances the factual grounding and specificity of its outputs. Our analysis shows that the proposed RAG-based LLM outperforms leading commercial LLMs across four evaluation metrics: AlignScore, ParaScore, BERTScore, and ROUGE, demonstrating its effectiveness in producing reliable and context-aware legal insights. This approach offers a scalable, AI-driven method for legislative analysis, supporting efforts to update legal frameworks in line with advancements in transportation technologies.', 'abstract_zh': '随着连接和自动运输系统的发展，联邦和州当局需要修订现有法律并制定新法规以应对新兴的网络安全和数据隐私挑战。本文介绍了一种基于检索增强生成（RAG）的大语言模型（LLM）框架，旨在通过提取相关法律内容并生成准确的、问题特定的回应来支持决策者。该框架通过使用特定领域的定制问题来指导响应生成，以减少LLM中的幻觉现象。通过结合检索机制，系统增强了输出的事实基础性和特定性。我们的分析表明，所提出的基于RAG的LLM在四个评估指标（AlignScore、ParaScore、BERTScore和ROUGE）上优于领先的商业LLM，证明了其在产生可靠且上下文相关的法律见解方面的有效性。该方法为立法分析提供了一种可扩展的、基于AI的方法，支持法律框架更新以适应运输技术的进步。', 'title_zh': '基于检索增强生成的大语言模型在弥补交通运输网络安全法律知识缺口中的应用'}
{'arxiv_id': 'arXiv:2505.18424', 'title': "How We Won the ISLES'24 Challenge by Preprocessing", 'authors': 'Tianyi Ren, Juampablo E. Heras Rivera, Hitender Oswal, Yutong Pan, William Henry, Jacob Ruzevick, Mehmet Kurt', 'link': 'https://arxiv.org/abs/2505.18424', 'abstract': "Stroke is among the top three causes of death worldwide, and accurate identification of stroke lesion boundaries is critical for diagnosis and treatment. Supervised deep learning methods have emerged as the leading solution for stroke lesion segmentation but require large, diverse, and annotated datasets. The ISLES'24 challenge addresses this need by providing longitudinal stroke imaging data, including CT scans taken on arrival to the hospital and follow-up MRI taken 2-9 days from initial arrival, with annotations derived from follow-up MRI. Importantly, models submitted to the ISLES'24 challenge are evaluated using only CT inputs, requiring prediction of lesion progression that may not be visible in CT scans for segmentation. Our winning solution shows that a carefully designed preprocessing pipeline including deep-learning-based skull stripping and custom intensity windowing is beneficial for accurate segmentation. Combined with a standard large residual nnU-Net architecture for segmentation, this approach achieves a mean test Dice of 28.5 with a standard deviation of 21.27.", 'abstract_zh': "中风是全球前三大死亡原因，准确识别中风病变边界对于诊断和治疗至关重要。监督深度学习方法已成为中风病变分割的主导解决方案，但需要大量、多样且标注的数据集。ISLES'24挑战通过提供纵向中风影像数据来应对这一需求，包括患者到医院时拍摄的CT扫描和初次到达后2-9天的随访MRI，并根据随访MRI进行标注。重要的是，提交到ISLES'24挑战的模型仅使用CT输入进行评估，需要预测可能在CT扫描中不可见的病变进展以进行分割。我们的获胜解决方案表明，一个精心设计的预处理管道，包括基于深度学习的颅骨去除和自定义强度窗，对于准确分割有益。结合标准的大残差nnU-Net分割架构，此方法在测试集上的平均Dice值为28.5，标准差为21.27。", 'title_zh': "我们如何在ISLES'24挑战中获胜：通过预处理方法"}
{'arxiv_id': 'arXiv:2505.18417', 'title': 'Reinforcement Learning for Ballbot Navigation in Uneven Terrain', 'authors': 'Achkan Salehi', 'link': 'https://arxiv.org/abs/2505.18417', 'abstract': 'Ballbot (i.e. Ball balancing robot) navigation usually relies on methods rooted in control theory (CT), and works that apply Reinforcement learning (RL) to the problem remain rare while generally being limited to specific subtasks (e.g. balance recovery). Unlike CT based methods, RL does not require (simplifying) assumptions about environment dynamics (e.g. the absence of slippage between the ball and the floor). In addition to this increased accuracy in modeling, RL agents can easily be conditioned on additional observations such as depth-maps without the need for explicit formulations from first principles, leading to increased adaptivity. Despite those advantages, there has been little to no investigation into the capabilities, data-efficiency and limitations of RL based methods for ballbot control and navigation. Furthermore, there is a notable absence of an open-source, RL-friendly simulator for this task. In this paper, we present an open-source ballbot simulation based on MuJoCo, and show that with appropriate conditioning on exteroceptive observations as well as reward shaping, policies learned by classical model-free RL methods are capable of effectively navigating through randomly generated uneven terrain, using a reasonable amount of data (four to five hours on a system operating at 500hz).', 'abstract_zh': '基于强化学习的球形机器人导航方法的能力、数据效率及局限性研究：MuJoCo模拟器的开发与应用', 'title_zh': '球型机器人在不平地形上的引导学习'}
{'arxiv_id': 'arXiv:2505.18413', 'title': 'LatentLLM: Attention-Aware Joint Tensor Compression', 'authors': 'Toshiaki Koike-Akino, Xiangyu Chen, Jing Liu, Ye Wang, Wang, Matthew Brand', 'link': 'https://arxiv.org/abs/2505.18413', 'abstract': 'Modern foundation models such as large language models (LLMs) and large multi-modal models (LMMs) require a massive amount of computational and memory resources. We propose a new framework to convert such LLMs/LMMs into a reduced-dimension latent structure. Our method extends a local activation-aware tensor decomposition to a global attention-aware joint tensor de-composition. Our framework can significantly improve the model accuracy over the existing model compression methods when reducing the latent dimension to realize computationally/memory-efficient LLMs/LLMs. We show the benefit on several benchmark including multi-modal reasoning tasks.', 'abstract_zh': '现代基础模型如大型语言模型（LLMs）和大型多模态模型（LMMs）需要大量的计算和内存资源。我们提出了一种新框架，将此类LLMs/LMMs转换为低维度的潜在结构。我们的方法将局部激活感知张量分解扩展为全局注意力感知联合张量分解。当降低潜在维度以实现计算/内存高效的LLMs/LMMs时，我们的框架可以在保持模型精度方面显著优于现有的模型压缩方法。我们在包括多模态推理任务在内的多个基准上展示了其优势。', 'title_zh': 'LatentLLM: 注意力引导的联合张量压缩'}
{'arxiv_id': 'arXiv:2505.18407', 'title': 'KL-regularization Itself is Differentially Private in Bandits and RLHF', 'authors': 'Yizhou Zhang, Kishan Panaganti, Laixi Shi, Juba Ziani, Adam Wierman', 'link': 'https://arxiv.org/abs/2505.18407', 'abstract': "Differential Privacy (DP) provides a rigorous framework for privacy, ensuring the outputs of data-driven algorithms remain statistically indistinguishable across datasets that differ in a single entry. While guaranteeing DP generally requires explicitly injecting noise either to the algorithm itself or to its outputs, the intrinsic randomness of existing algorithms presents an opportunity to achieve DP ``for free''. In this work, we explore the role of regularization in achieving DP across three different decision-making problems: multi-armed bandits, linear contextual bandits, and reinforcement learning from human feedback (RLHF), in offline data settings. We show that adding KL-regularization to the learning objective (a common approach in optimization algorithms) makes the action sampled from the resulting stochastic policy itself differentially private. This offers a new route to privacy guarantees without additional noise injection, while also preserving the inherent advantage of regularization in enhancing performance.", 'abstract_zh': '差分隐私（DP）提供了一种严谨的隐私框架，确保在单个条目不同的数据集中，数据驱动算法的输出在统计上无法区分。虽然通常保证差分隐私需要显式地向算法本身或其输出中注入噪声，但现有算法固有的随机性为实现“免费”的差分隐私提供了机会。在本文中，我们探讨了正则化在三个不同的决策问题中实现差分隐私的作用：多臂 bandit 问题、线性上下文 bandit 问题以及从人类反馈强化学习（RLHF），在离线数据设置中的角色。我们证明，在学习目标中添加 KL-正则化（优化算法中的一种常见方法）会使从生成的随机策略中采样的动作本身成为差分隐私的。这一发现提供了一种新的路径，无需额外注入噪声即可获得隐私保证，同时也保留了正则化在提高性能方面的固有优势。', 'title_zh': 'KL-正则化本身在 bandits 和 RLHF 中具有差分隐私性'}
{'arxiv_id': 'arXiv:2505.18404', 'title': 'Thought calibration: Efficient and confident test-time scaling', 'authors': 'Menghua Wu, Cai Zhou, Stephen Bates, Tommi Jaakkola', 'link': 'https://arxiv.org/abs/2505.18404', 'abstract': "Reasoning large language models achieve impressive test-time scaling by thinking for longer, but this performance gain comes at significant compute cost. Directly limiting test-time budget hurts overall performance, but not all problems are equally difficult. We propose thought calibration to decide dynamically when thinking can be terminated. To calibrate our decision rule, we view a language model's growing body of thoughts as a nested sequence of reasoning trees, where the goal is to identify the point at which novel reasoning plateaus. We realize this framework through lightweight probes that operate on top of the language model's hidden representations, which are informative of both the reasoning structure and overall consistency of response. Based on three reasoning language models and four datasets, thought calibration preserves model performance with up to a 60% reduction in thinking tokens on in-distribution data, and up to 20% in out-of-distribution data.", 'abstract_zh': '大规模语言模型通过延长推理时间实现显著的测试时扩展，但这种性能提升伴随着巨大的计算成本。直接限制测试时间预算会损害整体性能，但并非所有问题都同样困难。我们提出推理校准以动态决定何时终止推理。通过轻量级探针对语言模型隐藏表示的操作，我们实现这一框架，该探针能提供推理结构和响应总体一致性的信息，以识别新颖推理 plateau 出现的点。基于三种推理语言模型和四个数据集，推理校准在领域内数据上可以将推理令牌减少最多 60%，在领域外数据上可以减少最多 20%。', 'title_zh': '思维校准：高效且自信的测试时缩放'}
{'arxiv_id': 'arXiv:2505.18399', 'title': 'Taming Diffusion for Dataset Distillation with High Representativeness', 'authors': 'Lin Zhao, Yushu Wu, Xinru Jiang, Jianyang Gu, Yanzhi Wang, Xiaolin Xu, Pu Zhao, Xue Lin', 'link': 'https://arxiv.org/abs/2505.18399', 'abstract': 'Recent deep learning models demand larger datasets, driving the need for dataset distillation to create compact, cost-efficient datasets while maintaining performance. Due to the powerful image generation capability of diffusion, it has been introduced to this field for generating distilled images. In this paper, we systematically investigate issues present in current diffusion-based dataset distillation methods, including inaccurate distribution matching, distribution deviation with random noise, and separate sampling. Building on this, we propose D^3HR, a novel diffusion-based framework to generate distilled datasets with high representativeness. Specifically, we adopt DDIM inversion to map the latents of the full dataset from a low-normality latent domain to a high-normality Gaussian domain, preserving information and ensuring structural consistency to generate representative latents for the distilled dataset. Furthermore, we propose an efficient sampling scheme to better align the representative latents with the high-normality Gaussian distribution. Our comprehensive experiments demonstrate that D^3HR can achieve higher accuracy across different model architectures compared with state-of-the-art baselines in dataset distillation. Source code: this https URL.', 'abstract_zh': '近期的深度学习模型需要更大的数据集，推动了数据集蒸馏的需求，以创建紧凑且成本效益高的数据集同时保持性能。由于扩散模型强大的图像生成能力，它已被引入该领域用于生成蒸馏图像。在本文中，我们系统地研究了当前基于扩散的数据集蒸馏方法中存在的问题，包括不准确的分布匹配、随机噪声引起的功能偏差以及单独采样。在此基础上，我们提出了一种新颖的基于扩散的框架D^3HR，用于生成具有高代表性特征的数据集。具体而言，我们采用DDIM反向映射，将完整数据集的潜在变量从低常态潜在域映射到高常态高斯域，保留信息并确保结构一致性，以生成蒸馏数据集的代表性潜在变量。此外，我们提出了一种高效的采样方案以更好地将代表性潜在变量与高常态高斯分布对齐。我们的综合实验结果表明，与最新的基线方法相比，D^3HR在数据集蒸馏中能够获得更高的准确性。源代码：此链接。', 'title_zh': '控制扩散以提取高代表性数据集'}
{'arxiv_id': 'arXiv:2505.18398', 'title': 'Towards Anonymous Neural Network Inference', 'authors': 'Liao Peiyuan', 'link': 'https://arxiv.org/abs/2505.18398', 'abstract': 'We introduce funion, a system providing end-to-end sender-receiver unlinkability for neural network inference. By leveraging the Pigeonhole storage protocol and BACAP (blinding-and-capability) scheme from the Echomix anonymity system, funion inherits the provable security guarantees of modern mixnets. Users can anonymously store input tensors in pseudorandom storage locations, commission compute services to process them via the neural network, and retrieve results with no traceable connection between input and output parties. This store-compute-store paradigm masks both network traffic patterns and computational workload characteristics, while quantizing execution timing into public latency buckets. Our security analysis demonstrates that funion inherits the strong metadata privacy guarantees of Echomix under largely the same trust assumptions, while introducing acceptable overhead for production-scale workloads. Our work paves the way towards an accessible platform where users can submit fully anonymized inference queries to cloud services.', 'abstract_zh': '我们介绍了一种名为funion的系统，该系统提供了从发送者到接收者的端到端不可链接性，用于神经网络推理。通过利用Echomix匿名系统中的鸽洞存储协议和Pigeonhole存储方案以及BLINDING-AND-CAPABILITY (BACAP) 方案，funion继承了现代混洗网络的可证明安全保证。用户可以匿名地将输入张量存储在伪随机存储位置，委托计算服务通过神经网络处理这些输入张量，并获取结果时没有任何可追溯的链接关系。这一存储-计算-存储的范式遮掩了网络流量模式和计算工作负载的特征，同时将执行时间量化为公共延迟桶。我们的安全性分析表明，在很大程度上具有相同的信任假设下，funion继承了Echomix的强大的元数据隐私保障，同时为生产规模的工作负载引入了可接受的额外开销。我们的工作为用户提供了一种平台，使用户能够向云服务提交完全匿名化的推理查询。', 'title_zh': 'Towards Anonymous Neural Network Inference'}
{'arxiv_id': 'arXiv:2505.18397', 'title': 'An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems', 'authors': 'Fangqiao Tian, An Luo, Jin Du, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Jiawei Zhou, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Rui Zhang, Zirui Liu, Mingyi Hong, Jie Ding', 'link': 'https://arxiv.org/abs/2505.18397', 'abstract': 'Multi-agent AI systems (MAS) offer a promising framework for distributed intelligence, enabling collaborative reasoning, planning, and decision-making across autonomous agents. This paper provides a systematic outlook on the current opportunities and challenges of MAS, drawing insights from recent advances in large language models (LLMs), federated optimization, and human-AI interaction. We formalize key concepts including agent topology, coordination protocols, and shared objectives, and identify major risks such as dependency, misalignment, and vulnerabilities arising from training data overlap. Through a biologically inspired simulation and comprehensive theoretical framing, we highlight critical pathways for developing robust, scalable, and secure MAS in real-world settings.', 'abstract_zh': '多智能体AI系统（MAS）提供了分布式智能的有前途框架，使其能够支持自主智能体之间的协作推理、规划和决策。本文从大型语言模型（LLMs）、联邦优化和人机交互的最新进展中，系统地探讨了MAS当前的机会与挑战。我们正式化了关键概念，包括智能体拓扑结构、协调协议和共同目标，并识别出由训练数据重叠引起的主要风险，如依赖性、不一致性和脆弱性。通过生物启发的仿真和全面的理论框架，我们强调了在实际应用场景中开发稳健、可扩展和安全的MAS的关键路径。', 'title_zh': '多智能体AI系统的机会与挑战展望'}
{'arxiv_id': 'arXiv:2505.18392', 'title': 'Applications of Modular Co-Design for De Novo 3D Molecule Generation', 'authors': 'Danny Reidenbach, Filipp Nikitin, Olexandr Isayev, Saee Paliwal', 'link': 'https://arxiv.org/abs/2505.18392', 'abstract': "De novo 3D molecule generation is a pivotal task in drug discovery. However, many recent geometric generative models struggle to produce high-quality 3D structures, even if they maintain 2D validity and topological stability. To tackle this issue and enhance the learning of effective molecular generation dynamics, we present Megalodon-a family of scalable transformer models. These models are enhanced with basic equivariant layers and trained using a joint continuous and discrete denoising co-design objective. We assess Megalodon's performance on established molecule generation benchmarks and introduce new 3D structure benchmarks that evaluate a model's capability to generate realistic molecular structures, particularly focusing on energetics. We show that Megalodon achieves state-of-the-art results in 3D molecule generation, conditional structure generation, and structure energy benchmarks using diffusion and flow matching. Furthermore, doubling the number of parameters in Megalodon to 40M significantly enhances its performance, generating up to 49x more valid large molecules and achieving energy levels that are 2-10x lower than those of the best prior generative models.", 'abstract_zh': 'De novo 3D分子生成是药物发现中的关键任务。然而，许多近期的几何生成模型在生成高质量的3D结构方面存在困难，即使它们能够保持2D的有效性和拓扑稳定性。为了解决这一问题并增强有效的分子生成动力学的学习，我们提出了一种可扩展的变压器模型家族Megalodon。这些模型通过增强基本不变层并使用联合连续和离散去噪协同设计目标进行训练。我们评估了Megalodon在已建立的分子生成基准测试上的性能，并引入了新的3D结构基准测试来评价模型生成现实分子结构的能力，特别是重点在于能量方面。我们表明，Megalodon在3D分子生成、条件结构生成和结构能量基准测试中均达到了最先进的成果，使用扩散和流匹配。此外，将Megalodon的参数数量翻倍至40M显著提升了其性能，生成了高达49倍的有效大分子，并且能量水平比之前最好的生成模型低2-10倍。', 'title_zh': '基于模块化联合设计的从头三维分子生成应用'}
{'arxiv_id': 'arXiv:2505.18385', 'title': 'Human-Centered AI Communication in Co-Creativity: An Initial Framework and Insights', 'authors': 'Jeba Rezwana, Corey Ford', 'link': 'https://arxiv.org/abs/2505.18385', 'abstract': "Effective communication between AI and humans is essential for successful human-AI co-creation. However, many current co-creative AI systems lack effective communication, which limits their potential for collaboration. This paper presents the initial design of the Framework for AI Communication (FAICO) for co-creative AI, developed through a systematic review of 107 full-length papers. FAICO presents key aspects of AI communication and their impact on user experience, offering preliminary guidelines for designing human-centered AI communication. To improve the framework, we conducted a preliminary study with two focus groups involving skilled individuals in AI, HCI, and design. These sessions sought to understand participants' preferences for AI communication, gather their perceptions of the framework, collect feedback for refinement, and explore its use in co-creative domains like collaborative writing and design. Our findings reveal a preference for a human-AI feedback loop over linear communication and emphasize the importance of context in fostering mutual understanding. Based on these insights, we propose actionable strategies for applying FAICO in practice and future directions, marking the first step toward developing comprehensive guidelines for designing effective human-centered AI communication in co-creation.", 'abstract_zh': '有效的AI与人类沟通对于成功的人机共创至关重要。然而，当前许多共创型AI系统缺乏有效的沟通，这限制了它们的合作潜力。本文提出了基于系统性文献综述（分析了107篇完整论文）的人机共创AI沟通框架（FAICO）的初步设计。FAICO呈现了AI沟通的关键方面及其对用户体验的影响，并提供了以人为本的AI沟通初步设计指南。为改进框架，我们进行了初步研究，包括两个焦点小组，邀请了AI、人机交互（HCI）和设计领域的专业人士。这些会话旨在理解参与者对AI沟通的偏好，收集他们对框架的看法，收集改进的反馈，并探索其在共创领域（如协作写作和设计）的应用。研究发现显示了参与者对于人机双向反馈循环而非线性沟通的偏好，并强调了情境在促进相互理解中的重要性。基于这些见解，我们提出了在实践中应用FAICO的具体策略和未来方向，这是向开发全面的人效中心AI沟通设计指南迈出的第一步。', 'title_zh': '以人为本的AI通信在共创性中的作用：初步框架与见解'}
{'arxiv_id': 'arXiv:2505.18384', 'title': 'Dynamic Risk Assessments for Offensive Cybersecurity Agents', 'authors': 'Boyi Wei, Benedikt Stroebl, Jiacen Xu, Joie Zhang, Zhou Li, Peter Henderson', 'link': 'https://arxiv.org/abs/2505.18384', 'abstract': "Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.", 'abstract_zh': '基础模型正日益成为自主程序员，这使得它们有可能自动化危险的进攻性网络操作。当前的前沿模型审查探讨了这类代理的网络安全风险，但大多数审查未考虑到现实世界中对手所拥有的自由度。特别是，在有强大验证器和经济激励的情况下，进攻性网络安全代理可以通过潜在对手的迭代改进。我们认为评估应在网络安全的背景下考虑扩大的威胁模型，强调在固定计算预算内，对手在有状态和无状态环境中可能拥有的不同自由度。研究结果表明，即使计算预算相对较小（我们的研究中为8个H100 GPU小时），对手也能够在InterCode CTF中将代理的网络安全能力相对于基线提高超过40%，无需外部帮助。这些结果突显了需要动态评估代理的网络安全风险，以提供更具有代表性的风险图景。', 'title_zh': '动态风险评估方法研究：针对进攻性网络安全代理'}
{'arxiv_id': 'arXiv:2505.18377', 'title': 'SP2RINT: Spatially-Decoupled Physics-Inspired Progressive Inverse Optimization for Scalable, PDE-Constrained Meta-Optical Neural Network Training', 'authors': 'Pingchuan Ma, Ziang Yin, Qi Jing, Zhengqi Gao, Nicholas Gangi, Boyang Zhang, Tsung-Wei Huang, Zhaoran Huang, Duane S. Boning, Yu Yao, Jiaqi Gu', 'link': 'https://arxiv.org/abs/2505.18377', 'abstract': 'DONNs harness the physics of light propagation for efficient analog computation, with applications in AI and signal processing. Advances in nanophotonic fabrication and metasurface-based wavefront engineering have opened new pathways to realize high-capacity DONNs across various spectral regimes. Training such DONN systems to determine the metasurface structures remains challenging. Heuristic methods are fast but oversimplify metasurfaces modulation, often resulting in physically unrealizable designs and significant performance degradation. Simulation-in-the-loop training methods directly optimize a physically implementable metasurface using adjoint methods during end-to-end DONN training, but are inherently computationally prohibitive and this http URL address these limitations, we propose SP2RINT, a spatially decoupled, progressive training framework that formulates DONN training as a PDE-constrained learning problem. Metasurface responses are first relaxed into freely trainable transfer matrices with a banded structure. We then progressively enforce physical constraints by alternating between transfer matrix training and adjoint-based inverse design, avoiding per-iteration PDE solves while ensuring final physical realizability. To further reduce runtime, we introduce a physics-inspired, spatially decoupled inverse design strategy based on the natural locality of field interactions. This approach partitions the metasurface into independently solvable patches, enabling scalable and parallel inverse design with system-level calibration. Evaluated across diverse DONN training tasks, SP2RINT achieves digital-comparable accuracy while being 1825 times faster than simulation-in-the-loop approaches. By bridging the gap between abstract DONN models and implementable photonic hardware, SP2RINT enables scalable, high-performance training of physically realizable meta-optical neural systems.', 'abstract_zh': 'DONNs利用光传播的物理原理进行高效的类比计算，应用于AI和信号处理。 advancements in nanophotonic fabrication and metasurface-based wavefront engineering have opened new pathways to realize high-capacity DONNs across various spectral regimes. Training such DONN systems to determine the metasurface structures remains challenging.', 'title_zh': 'SP2RINT: 空间解耦物理启发的渐进逆优化方法及其在偏微分方程约束元光学神经网络训练中的应用'}
{'arxiv_id': 'arXiv:2505.18373', 'title': 'Next-token pretraining implies in-context learning', 'authors': 'Paul M. Riechers, Henry R. Bigelow, Eric A. Alt, Adam Shai', 'link': 'https://arxiv.org/abs/2505.18373', 'abstract': "We argue that in-context learning (ICL) predictably arises from standard self-supervised next-token pretraining, rather than being an exotic emergent property. This work establishes the foundational principles of this emergence by focusing on in-distribution ICL, demonstrating how models necessarily adapt to context when trained on token sequences, especially from non-ergodic sources. Our information-theoretic framework precisely predicts these in-distribution ICL dynamics (i.e., context-dependent loss reduction). We verify this with experiments using synthetic datasets of differing types of correlational structure, reproducing characteristic phenomena like phase transitions in training loss for induction head formation and power-law scaling of in-context loss. We further show that a model's in-context performance on any task is mathematically coupled to the ensemble of tasks seen in pretraining, offering a fundamental explanation, grounded in architecture- and modality-independent principles, for such inference-time learning.", 'abstract_zh': '我们 argue 认为基于上下文的学习（ICL）可预测地源自标准的自监督下一个词预训练，而不是一种奇特的 emergent 属性。本文通过关注同分布下的 ICL，建立了这种 emergence 的基础原理，展示了当模型在 token 序列上训练时，不可避免地会适应上下文，尤其是在从非遍历源数据训练时。我们的信息论框架精确地预测了这些同分布下的 ICL 动态（即上下文相关的损失减少）。我们使用不同类型相关结构的合成数据集进行了实验验证，重现了如归纳头形成过程中的训练损失相变现象和上下文损失的幂律缩放。进一步表明，模型在任何任务上的基于上下文的表现与预训练中看到的任务集合在数学上是有联系的，提供了从架构和模态无关的基本原理出发，对于这种推理时学习的本质解释。', 'title_zh': '下一个 tokens 预训练蕴含场内学习'}
{'arxiv_id': 'arXiv:2505.18371', 'title': 'Military AI Needs Technically-Informed Regulation to Safeguard AI Research and its Applications', 'authors': 'Riley Simmons-Edler, Jean Dong, Paul Lushenko, Kanaka Rajan, Ryan P. Badman', 'link': 'https://arxiv.org/abs/2505.18371', 'abstract': 'Military weapon systems and command-and-control infrastructure augmented by artificial intelligence (AI) have seen rapid development and deployment in recent years. However, the sociotechnical impacts of AI on combat systems, military decision-making, and the norms of warfare have been understudied. We focus on a specific subset of lethal autonomous weapon systems (LAWS) that use AI for targeting or battlefield decisions. We refer to this subset as AI-powered lethal autonomous weapon systems (AI-LAWS) and argue that they introduce novel risks -- including unanticipated escalation, poor reliability in unfamiliar environments, and erosion of human oversight -- all of which threaten both military effectiveness and the openness of AI research. These risks cannot be addressed by high-level policy alone; effective regulation must be grounded in the technical behavior of AI models. We argue that AI researchers must be involved throughout the regulatory lifecycle. Thus, we propose a clear, behavior-based definition of AI-LAWS -- systems that introduce unique risks through their use of modern AI -- as a foundation for technically grounded regulation, given that existing frameworks do not distinguish them from conventional LAWS. Using this definition, we propose several technically-informed policy directions and invite greater participation from the AI research community in military AI policy discussions.', 'abstract_zh': '基于人工智能的军事武器系统和指挥控制基础设施已在近年来迅速发展和部署。然而，人工智能对战斗系统、军事决策以及战争规范的社会技术影响尚研究不足。我们关注特定类型的致命自主武器系统（LAWS），这些系统使用人工智能进行目标识别或战场决策。我们将这一子集称为人工智能赋能的致命自主武器系统（AI-LAWS），并认为它们引入了新颖的风险，包括不可预见的升级风险、在不熟悉环境中可靠性不佳以及削弱的人类监督，这些风险既威胁军事有效性，也威胁人工智能研究的开放性。这些风险仅靠高级政策无法解决；有效的规制必须基于人工智能模型的技术行为。我们主张在整个规制生命周期中都应包括人工智能研究人员。因此，我们提出了一种明确、基于行为的AI-LAWS定义——通过使用现代人工智能技术引入独特风险的系统，作为基于技术的规制的基础，因为现有框架无法将它们与传统LAWS区分开来。利用这一定义，我们提出了一些基于技术的政策方向，并邀请AI研究社区更大程度地参与军事人工智能政策讨论。', 'title_zh': '军事AI需要基于技术的理解来制定监管以保护AI研究及其应用。'}
{'arxiv_id': 'arXiv:2505.18369', 'title': 'Small Models, Smarter Learning: The Power of Joint Task Training', 'authors': 'Csaba Both, Benjamin Hoover, Hendrik Strobelt, Dmitry Krotov, Daniel Karl I. Weidele, Mauro Martino, Nima Dehmamy', 'link': 'https://arxiv.org/abs/2505.18369', 'abstract': 'The ability of a model to learn a task depends strongly on both the task difficulty and the model size. We aim to understand how task difficulty relates to the minimum number of parameters required for learning specific tasks in small transformer models. Our study focuses on the ListOps dataset, which consists of nested mathematical operations. We gradually increase task difficulty by introducing new operations or combinations of operations into the training data. We observe that sum modulo n is the hardest to learn. Curiously, when combined with other operations such as maximum and median, the sum operation becomes easier to learn and requires fewer parameters. We show that joint training not only improves performance but also leads to qualitatively different model behavior. We show evidence that models trained only on SUM might be memorizing and fail to capture the number structure in the embeddings. In contrast, models trained on a mixture of SUM and other operations exhibit number-like representations in the embedding space, and a strong ability to distinguish parity. Furthermore, the SUM-only model relies more heavily on its feedforward layers, while the jointly trained model activates the attention mechanism more. Finally, we show that learning pure SUM can be induced in models below the learning threshold of pure SUM, by pretraining them on MAX+MED. Our findings indicate that emergent abilities in language models depend not only on model size, but also the training curriculum.', 'abstract_zh': '模型学习任务的能力强烈依赖于任务难度和模型大小。我们旨在理解任务难度与在小型变压器模型中学习特定任务所需最小参数数量之间的关系。我们研究集中在ListOps数据集中，该数据集包含嵌套的数学运算。我们通过引入新的运算或运算组合逐渐增加任务难度。我们观察到，模n求和是最难学习的。有趣的是，当与其他运算（如最大值和中值）结合时，求和运算变得更容易学习，并且所需的参数更少。我们表明，联合训练不仅改善了性能，还导致了模型行为上的质的差异。我们展示了仅在SUM上训练的模型可能在嵌入中记忆数据而未能捕捉数字结构的证据。相反，训练在SUM和其他运算混合数据上的模型在嵌入空间中表现出数字似的行为，并且在区分奇偶性方面有强大的能力。此外，仅训练在SUM上的模型更多依赖其前馈层，而联合训练的模型则更多激活了注意力机制。最后，我们展示了通过在MAX+MED数据上进行预训练，可以在低于纯SUM学习阈值的模型中诱导出纯SUM的学习能力。我们的研究结果表明，语言模型中的 emergent 能力不仅依赖于模型大小，还依赖于训练课程。', 'title_zh': '小模型，更聪明的学习：联合任务训练的威力'}
{'arxiv_id': 'arXiv:2505.18366', 'title': 'Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems', 'authors': 'Hansa Meghwani, Amit Agarwal, Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Srikant Panda', 'link': 'https://arxiv.org/abs/2505.18366', 'abstract': "Enterprise search systems often struggle to retrieve accurate, domain-specific information due to semantic mismatches and overlapping terminologies. These issues can degrade the performance of downstream applications such as knowledge management, customer support, and retrieval-augmented generation agents. To address this challenge, we propose a scalable hard-negative mining framework tailored specifically for domain-specific enterprise data. Our approach dynamically selects semantically challenging but contextually irrelevant documents to enhance deployed re-ranking models.\nOur method integrates diverse embedding models, performs dimensionality reduction, and uniquely selects hard negatives, ensuring computational efficiency and semantic precision. Evaluation on our proprietary enterprise corpus (cloud services domain) demonstrates substantial improvements of 15\\% in MRR@3 and 19\\% in MRR@10 compared to state-of-the-art baselines and other negative sampling techniques. Further validation on public domain-specific datasets (FiQA, Climate Fever, TechQA) confirms our method's generalizability and readiness for real-world applications.", 'abstract_zh': '企业搜索引擎常常由于语义不匹配和术语重叠而难以检索到准确的领域特定信息，这会降低知识管理、客户支持和检索增强生成代理等下游应用的性能。为应对这一挑战，我们提出了一种针对特定领域的企业数据进行扩展的硬负样本挖掘框架。该方法动态选择语义上具有挑战性但与当前上下文无关的文档，以增强已部署的重排序模型。该方法整合了多种嵌入模型，进行了维度减少，并独特地选择了硬负样本，确保了计算效率和语义精度。在专属的企业语料库（云服务领域）上的评估结果显示，与最先进的基线方法和其他负样本技术相比，MRR@3 提高了 15%，MRR@10 提高了 19%。进一步在公开的特定领域数据集（FiQA、Climate Fever、TechQA）上的验证确认了该方法的通用性和在实际应用中的准备好状态。', 'title_zh': '企业系统中领域特定检索的硬负样本挖掘'}
{'arxiv_id': 'arXiv:2505.18363', 'title': 'SchemaGraphSQL: Efficient Schema Linking with Pathfinding Graph Algorithms for Text-to-SQL on Large-Scale Databases', 'authors': 'AmirHossein Safdarian, Milad Mohammadi, Ehsan Jahanbakhsh, Mona Shahamat Naderi, Heshaam Faili', 'link': 'https://arxiv.org/abs/2505.18363', 'abstract': 'Text-to-SQL systems translate natural language questions into executable SQL queries, and recent progress with large language models (LLMs) has driven substantial improvements in this task. Schema linking remains a critical component in Text-to-SQL systems, reducing prompt size for models with narrow context windows and sharpening model focus even when the entire schema fits. We present a zero-shot, training-free schema linking approach that first constructs a schema graph based on foreign key relations, then uses a single prompt to Gemini 2.5 Flash to extract source and destination tables from the user query, followed by applying classical path-finding algorithms and post-processing to identify the optimal sequence of tables and columns that should be joined, enabling the LLM to generate more accurate SQL queries. Despite being simple, cost-effective, and highly scalable, our method achieves state-of-the-art results on the BIRD benchmark, outperforming previous specialized, fine-tuned, and complex multi-step LLM-based approaches. We conduct detailed ablation studies to examine the precision-recall trade-off in our framework. Additionally, we evaluate the execution accuracy of our schema filtering method compared to other approaches across various model sizes.', 'abstract_zh': 'Text-to-SQL系统将自然语言问题转换为可执行的SQL查询，并且大型语言模型（LLMs）的进展在这一任务上带来了显著的改进。模式链接仍是Text-to-SQL系统中的关键组件，可减少具有狭窄上下文窗口的模型的提示大小，并即使在整个模式都适合的情况下也能使模型聚焦。我们提出了一种无需训练的零样本模式链接方法，首先基于外键关系构建模式图，然后使用单个提示将Gemini 2.5 Flash从用户查询中提取源表和目标表，接着应用经典路径查找算法和后处理来识别应连接的最佳表和列序列，从而使LLM能够生成更准确的SQL查询。尽管方法简单、成本效益高且高度可扩展，我们的方法在BIRD基准测试中达到了最先进的性能，超过了之前的专门化、微调和复杂的多步LLM基方法。我们进行了详尽的消融研究以检查我们框架中的查准率权衡，并评估了我们的模式过滤方法与其他方法在不同模型大小下的执行准确性。', 'title_zh': 'SchemaGraphSQL：高效的路径查找图算法在大规模数据库中实现文本到SQL的模式链接'}
{'arxiv_id': 'arXiv:2505.18362', 'title': 'Hamiltonian Theory and Computation of Optimal Probability Density Control in High Dimensions', 'authors': 'Nathan Gaby, Xiaojing Ye', 'link': 'https://arxiv.org/abs/2505.18362', 'abstract': 'We develop a general theoretical framework for optimal probability density control and propose a numerical algorithm that is scalable to solve the control problem in high dimensions. Specifically, we establish the Pontryagin Maximum Principle (PMP) for optimal density control and construct the Hamilton-Jacobi-Bellman (HJB) equation of the value functional through rigorous derivations without any concept from Wasserstein theory. To solve the density control problem numerically, we propose to use reduced-order models, such as deep neural networks (DNNs), to parameterize the control vector-field and the adjoint function, which allows us to tackle problems defined on high-dimensional state spaces. We also prove several convergence properties of the proposed algorithm. Numerical results demonstrate promising performances of our algorithm on a variety of density control problems with obstacles and nonlinear interaction challenges in high dimensions.', 'abstract_zh': '我们建立了一般最优概率密度控制的理论框架，并提出了一种可扩展的数值算法以解决高维控制问题。具体来说，我们通过严谨的推导建立了最优密度控制的庞特里亚金最大原则（PMP），并通过无 Wasserstein 理论概念的推导构建了值函数的哈密尔顿-雅可比-贝尔曼（HJB）方程。为了数值求解密度控制问题，我们提出使用降阶模型，如深度神经网络（DNNs），来参数化控制向量场和伴随函数，从而能够处理定义在高维状态空间上的问题。我们还证明了所提算法的若干收敛性质。数值结果表明，我们的算法在多种含有障碍物和非线性交互挑战的高维密度控制问题上具有出色的表现。', 'title_zh': '哈密尔顿理论与高维最优概率密度控制的计算方法'}
{'arxiv_id': 'arXiv:2505.18361', 'title': 'Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain', 'authors': 'Trinity Chung, Yuchen Shen, Nathan C. L. Kong, Aran Nayebi', 'link': 'https://arxiv.org/abs/2505.18361', 'abstract': 'Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language. We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment. Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.\nFor neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.', 'abstract_zh': '触觉感知在神经科学中仍远未被充分理解，在人工系统中的应用效果也逊色于如视觉和语言等更为成熟的感知模态。我们通过引入一种新颖的编码-注意-解码（EAD）框架，系统性地探索基于定制化啮齿动物须触传感器模拟器的现实触觉输入序列训练下的任务优化时间神经网络的空间。我们发现卷积递归神经网络（ConvRNN）是触觉分类任务中优于纯前馈和状态空间架构的高级编码器。 crucial 地，基于 ConvRNN 编码器的 EAD 模型实现了与啮齿动物体感皮层相近的神经表示，饱和可解释的神经变异性，并揭示了监督分类性能与神经对齐之间明显的线性关系。此外，通过触觉特定增强训练的对比自监督 ConvRNN 编码器基于的 EADs，在监督神经拟合方面表现出色，作为生态相关且无标签的替代方案。对于神经科学，我们的发现强调了非线性递归处理对于体感皮层通用触觉表示的重要性，并提供了该系统底层归纳偏置的首次定量表征。对于具身人工智能，我们的结果强调了递归 EAD 架构在处理现实触觉输入中的重要性，同时也突显了定制化自监督学习方法对于使用与动物在非结构化环境中使用的相同传感器实现鲁棒触觉感知的重要性。', 'title_zh': '任务优化的卷积循环网络与啮齿类动物大脑中的触觉处理相一致'}
{'arxiv_id': 'arXiv:2505.18356', 'title': 'The Unreasonable Effectiveness of Model Merging for Cross-Lingual Transfer in LLMs', 'authors': 'Lucas Bandarkar, Nanyun Peng', 'link': 'https://arxiv.org/abs/2505.18356', 'abstract': 'Large language models (LLMs) still struggle across tasks outside of high-resource languages. In this work, we investigate cross-lingual transfer to lower-resource languages where task-specific post-training data is scarce. Building on prior work, we first validate that the subsets of model parameters that matter most for mathematical reasoning and multilingual capabilities are distinctly non-overlapping. To exploit this implicit separability between task and target language parameterization, we develop and analyze numerous modular frameworks to improve the composition of the two during fine-tuning. These methods generally employ freezing parameters or post hoc model merging to assign math and language improvement to different key parts of the LLM. In the absence of in-language math data, we demonstrate that the modular approaches successfully improve upon baselines across three languages, four models, and two fine-tuning paradigms (full and LoRA). Furthermore, we identify the most consistently successful modular method to be fine-tuning separate language and math experts and model merging via Layer-Swapping, somewhat surprisingly. We offer possible explanations for this result via recent works on the linearity of task vectors. We further explain this by empirically showing that reverting less useful fine-tuning updates after training often outperforms freezing them from the start.', 'abstract_zh': '大型语言模型（LLMs）在低资源语言任务上仍然表现不佳。本文研究了跨语言迁移学习在低资源语言任务中的应用，尤其是在任务特定的后训练数据稀缺的情况下。基于先前的工作，我们首先验证了对于数学推理和多语言能力最重要的模型参数子集是明显不重叠的。为了利用任务参数和目标语言参数之间的这种隐含分离性，我们开发并分析了多种模块化框架，在微调过程中改善这两个方面的组合。这些方法通常采用冻结参数或后 hoc 模型合并的方式来将数学和语言改进分配到 LLM 的不同关键部分。在缺乏本语言数学数据的情况下，我们展示了模块化方法能够跨三种语言、四种模型和两种微调范式（全量微调和LoRA）显著改进基线性能。此外，我们确定了一种最一致有效的模块化方法，即分别微调语言专家和数学专家，并通过分层置换进行模型合并，这有些出乎意料。我们通过最近有关任务向量线性性的研究工作提供了这种结果的可能解释。我们进一步通过实验证明，在训练后逆转一些不太有用的微调更新通常优于从一开始就冻结它们。', 'title_zh': '模型合并对大语言模型跨语言迁移的意外有效性'}
{'arxiv_id': 'arXiv:2505.18350', 'title': 'Task Specific Pruning with LLM-Sieve: How Many Parameters Does Your Task Really Need?', 'authors': 'Waleed Reda, Abhinav Jangda, Krishna Chintalapudi', 'link': 'https://arxiv.org/abs/2505.18350', 'abstract': 'As Large Language Models (LLMs) are increasingly being adopted for narrow tasks - such as medical question answering or sentiment analysis - and deployed in resource-constrained settings, a key question arises: how many parameters does a task actually need? In this work, we present LLM-Sieve, the first comprehensive framework for task-specific pruning of LLMs that achieves 20-75% parameter reduction with only 1-5% accuracy degradation across diverse domains. Unlike prior methods that apply uniform pruning or rely on low-rank approximations of weight matrices or inputs in isolation, LLM-Sieve (i) learns task-aware joint projections to better approximate output behavior, and (ii) employs a Genetic Algorithm to discover differentiated pruning levels for each matrix. LLM-Sieve is fully compatible with LoRA fine-tuning and quantization, and uniquely demonstrates strong generalization across datasets within the same task domain. Together, these results establish a practical and robust mechanism to generate smaller performant task-specific models.', 'abstract_zh': '大规模语言模型（LLMs）在资源受限环境中执行狭窄任务（如医疗问答或情感分析）时，一个关键问题出现了：任务究竟需要多少参数？在本文中，我们提出了LLM-Sieve，这是首个针对特定任务剪枝的大规模语言模型综合框架，实现了20%至75%的参数减少，同时准确率下降仅为1%至5%，并在多种领域中展示了广泛适用性。与以往应用均匀剪枝或孤立地依赖权重矩阵或输入的低秩逼近的方法不同，LLM-Sieve通过（i）学习任务感知的联合投影以更好地近似输出行为，以及（ii）采用遗传算法发现对每个矩阵不同的剪枝水平，来实现这一目标。LLM-Sieve完全兼容LoRA微调和量化，并且独特地展示了在同一任务领域内的不同数据集间强大的泛化能力。这些结果共同建立了生成更小且性能良好的特定任务模型的实用和 robust 机制。', 'title_zh': '基于LLM-Sieve的特定任务剪枝：你的任务究竟需要多少参数？'}
{'arxiv_id': 'arXiv:2505.18347', 'title': 'The Cell Must Go On: Agar.io for Continual Reinforcement Learning', 'authors': 'Mohamed A. Mohamed, Kateryna Nekhomiazh, Vedant Vyas, Marcos M. Jose, Andrew Patterson, Marlos C. Machado', 'link': 'https://arxiv.org/abs/2505.18347', 'abstract': 'Continual reinforcement learning (RL) concerns agents that are expected to learn continually, rather than converge to a policy that is then fixed for evaluation. Such an approach is well suited to environments the agent perceives as changing, which renders any static policy ineffective over time. The few simulators explicitly designed for empirical research in continual RL are often limited in scope or complexity, and it is now common for researchers to modify episodic RL environments by artificially incorporating abrupt task changes during interaction. In this paper, we introduce AgarCL, a research platform for continual RL that allows for a progression of increasingly sophisticated behaviour. AgarCL is based on the game this http URL, a non-episodic, high-dimensional problem featuring stochastic, ever-evolving dynamics, continuous actions, and partial observability. Additionally, we provide benchmark results reporting the performance of DQN, PPO, and SAC in both the primary, challenging continual RL problem, and across a suite of smaller tasks within AgarCL, each of which isolates aspects of the full environment and allow us to characterize the challenges posed by different aspects of the game.', 'abstract_zh': '持续强化学习（RL）关注能够持续学习而非固定政策进行评估的代理。这样的方法适用于代理感知环境变化的场景，使得任何静态策略随着时间的推移变得无效。为实证研究持续RL而专门设计的少数几个模拟器往往在范围或复杂性上有所限制，现在研究人员通常通过在交互过程中人工引入突然的任务变化来修改 episodic RL 环境。在本文中，我们介绍了 AgarCL，一个用于持续RL的研究平台，支持逐步实现日益复杂的执行行为。AgarCL 基于这个网址提供的游戏，这是一个非 episodic、高维度问题，具有随机的、不断演变的动力学、连续动作以及部分可观测性。此外，我们还提供了基准结果，报告了 DQN、PPO 和 SAC 在 AgarCL 的主要挑战性持续RL问题以及其内部一系列较小任务中的性能表现，每个任务都隔离了环境的不同方面，使我们能够对游戏不同方面的挑战进行表征。', 'title_zh': '细胞必须继续：Agar.io在连续强化学习中的应用'}
{'arxiv_id': 'arXiv:2505.18344', 'title': 'Sample Complexity of Diffusion Model Training Without Empirical Risk Minimizer Access', 'authors': 'Mudit Gaur, Prashant Trivedi, Sasidhar Kunapuli, Amrit Singh Bedi, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2505.18344', 'abstract': 'Diffusion models have demonstrated state-of-the-art performance across vision, language, and scientific domains. Despite their empirical success, prior theoretical analyses of the sample complexity suffer from poor scaling with input data dimension or rely on unrealistic assumptions such as access to exact empirical risk minimizers. In this work, we provide a principled analysis of score estimation, establishing a sample complexity bound of $\\widetilde{\\mathcal{O}}(\\epsilon^{-6})$. Our approach leverages a structured decomposition of the score estimation error into statistical, approximation, and optimization errors, enabling us to eliminate the exponential dependence on neural network parameters that arises in prior analyses. It is the first such result which achieves sample complexity bounds without assuming access to the empirical risk minimizer of score function estimation loss.', 'abstract_zh': '扩散模型在视觉、语言和科学领域中展现出了最先进的性能。尽管它们在实践中取得了成功，之前的样本复杂性理论分析要么不适用于高维输入数据，要么依赖于获取精确的经验风险最小化解这样不现实的假设。在本文中，我们提供了一种原则性的分析方法，建立了样本复杂性界 $\\widetilde{\\mathcal{O}}(\\epsilon^{-6})$。我们的方法利用了评分估计误差的结构分解，将其分为统计误差、逼近误差和优化误差，从而能够消除前人在分析中出现的对神经网络参数的指数依赖。这是首次在不假设能够访问评分函数估计损失的经验风险最小化解的情况下，获得样本复杂性界的结果。', 'title_zh': '无经验风险最小化扩散模型训练的样本复杂度研究'}
{'arxiv_id': 'arXiv:2505.18341', 'title': 'CrashAgent: Crash Scenario Generation via Multi-modal Reasoning', 'authors': 'Miao Li, Wenhao Ding, Haohong Lin, Yiqi Lyu, Yihang Yao, Yuyou Zhang, Ding Zhao', 'link': 'https://arxiv.org/abs/2505.18341', 'abstract': 'Training and evaluating autonomous driving algorithms requires a diverse range of scenarios. However, most available datasets predominantly consist of normal driving behaviors demonstrated by human drivers, resulting in a limited number of safety-critical cases. This imbalance, often referred to as a long-tail distribution, restricts the ability of driving algorithms to learn from crucial scenarios involving risk or failure, scenarios that are essential for humans to develop driving skills efficiently. To generate such scenarios, we utilize Multi-modal Large Language Models to convert crash reports of accidents into a structured scenario format, which can be directly executed within simulations. Specifically, we introduce CrashAgent, a multi-agent framework designed to interpret multi-modal real-world traffic crash reports for the generation of both road layouts and the behaviors of the ego vehicle and surrounding traffic participants. We comprehensively evaluate the generated crash scenarios from multiple perspectives, including the accuracy of layout reconstruction, collision rate, and diversity. The resulting high-quality and large-scale crash dataset will be publicly available to support the development of safe driving algorithms in handling safety-critical situations.', 'abstract_zh': '培训和评估自动驾驶算法需要多样化的场景。然而，大多数可用的数据集主要由人类驾驶者的正常驾驶行为构成，导致安全关键场景的数量有限。这种不平衡，通常称为长尾分布，限制了驾驶算法从涉及风险或失败的关键场景中学习的能力，这些场景对于人类高效地发展驾驶技能至关重要。为了生成这些场景，我们利用多模态大语言模型将事故报告转换为结构化的场景格式，可以直接在仿真中执行。具体来说，我们引入了CrashAgent多agent框架，用于解释多模态的真实世界交通事故报告，以生成道路布局和ego车辆及其周围交通参与者行为的场景。我们从多个角度全面评估生成的事故场景，包括布局重建的准确性、碰撞率和多样性。所产生的高质量和大规模事故数据集将公开提供，以支持开发能够 Handling Safety-Critical Situations 的安全驾驶算法。', 'title_zh': 'CrashAgent: 基于多模态推理的故障场景生成'}
{'arxiv_id': 'arXiv:2505.18333', 'title': 'A Critical Evaluation of Defenses against Prompt Injection Attacks', 'authors': 'Yuqi Jia, Zedian Shao, Yupei Liu, Jinyuan Jia, Dawn Song, Neil Zhenqiang Gong', 'link': 'https://arxiv.org/abs/2505.18333', 'abstract': 'Large Language Models (LLMs) are vulnerable to prompt injection attacks, and several defenses have recently been proposed, often claiming to mitigate these attacks successfully. However, we argue that existing studies lack a principled approach to evaluating these defenses. In this paper, we argue the need to assess defenses across two critical dimensions: (1) effectiveness, measured against both existing and adaptive prompt injection attacks involving diverse target and injected prompts, and (2) general-purpose utility, ensuring that the defense does not compromise the foundational capabilities of the LLM. Our critical evaluation reveals that prior studies have not followed such a comprehensive evaluation methodology. When assessed using this principled approach, we show that existing defenses are not as successful as previously reported. This work provides a foundation for evaluating future defenses and guiding their development. Our code and data are available at: this https URL.', 'abstract_zh': '大型语言模型（LLMs）易受提示注入攻击的影响，已有研究提出了多种防御措施，常称其能够成功缓解这些攻击。然而，我们认为现有研究缺乏一种原则性的评估方法。本文主张从两个关键维度评估防御措施：（1）效果，基于现有的和适应性的、涉及多种目标和注入提示的提示注入攻击进行衡量；（2）通用实用性，确保防御措施不损害LLM的基本功能。我们的批判性评估表明，先前的研究并未遵循这种全面的评估方法。运用这种方法进行评估后，我们显示现有的防御措施并不如先前所报道的那么成功。本文为评估未来的防御措施和指导其发展提供了基础。我们的代码和数据可在以下链接获取：this https URL。', 'title_zh': '对提示注入攻击防御措施的批判性评估'}
{'arxiv_id': 'arXiv:2505.18331', 'title': 'PerMedCQA: Benchmarking Large Language Models on Medical Consumer Question Answering in Persian Language', 'authors': 'Naghmeh Jamali, Milad Mohammadi, Danial Baledi, Zahra Rezvani, Hesham Faili', 'link': 'https://arxiv.org/abs/2505.18331', 'abstract': 'Medical consumer question answering (CQA) is crucial for empowering patients by providing personalized and reliable health information. Despite recent advances in large language models (LLMs) for medical QA, consumer-oriented and multilingual resources, particularly in low-resource languages like Persian, remain sparse. To bridge this gap, we present PerMedCQA, the first Persian-language benchmark for evaluating LLMs on real-world, consumer-generated medical questions. Curated from a large medical QA forum, PerMedCQA contains 68,138 question-answer pairs, refined through careful data cleaning from an initial set of 87,780 raw entries. We evaluate several state-of-the-art multilingual and instruction-tuned LLMs, utilizing MedJudge, a novel rubric-based evaluation framework driven by an LLM grader, validated against expert human annotators. Our results highlight key challenges in multilingual medical QA and provide valuable insights for developing more accurate and context-aware medical assistance systems. The data is publicly available on this https URL', 'abstract_zh': '医疗消费者问答（CQA）对于通过提供个性化和可靠的健康信息来赋能患者至关重要。尽管近年来大型语言模型（LLMs）在医疗问答方面的进展显著，面向消费者且多语言的资源，特别是低资源语言如波斯语的资源仍十分稀少。为了弥合这一差距，我们提出了PerMedCQA，这是首个用于评估LLMs处理真实世界消费者生成的医疗问题的波斯语基准数据集。从一个大型医疗问答论坛精心挑选并清理，PerMedCQA包含68,138个问题-答案对，源自最初87,780个原始条目的精心筛选。我们使用MedJudge评估了多种最先进的多语言及指令调优的LLMs，MedJudge是一种由LLM评分员驱动的新型基于评价指标的评估框架，其结果已由专家人工注释者进行验证。我们的研究结果突显了多语言医疗问答中的关键挑战，并为开发更准确和更具有情境感知能力的医疗辅助系统提供了宝贵的见解。数据可从以下网址获取：此https URL。', 'title_zh': 'PerMedCQA：评价大型语言模型在波斯语医学消费者问答任务上的表现'}
{'arxiv_id': 'arXiv:2505.18323', 'title': 'Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation', 'authors': 'Nicolas Küchler, Ivan Petrov, Conrad Grobler, Ilia Shumailov', 'link': 'https://arxiv.org/abs/2505.18323', 'abstract': 'For nearly a decade the academic community has investigated backdoors in neural networks, primarily focusing on classification tasks where adversaries manipulate the model prediction. While demonstrably malicious, the immediate real-world impact of such prediction-altering attacks has remained unclear. In this paper we introduce a novel and significantly more potent class of backdoors that builds upon recent advancements in architectural backdoors. We demonstrate how these backdoors can be specifically engineered to exploit batched inference, a common technique for hardware utilization, enabling large-scale user data manipulation and theft. By targeting the batching process, these architectural backdoors facilitate information leakage between concurrent user requests and allow attackers to fully control model responses directed at other users within the same batch. In other words, an attacker who can change the model architecture can set and steal model inputs and outputs of other users within the same batch. We show that such attacks are not only feasible but also alarmingly effective, can be readily injected into prevalent model architectures, and represent a truly malicious threat to user privacy and system integrity. Critically, to counteract this new class of vulnerabilities, we propose a deterministic mitigation strategy that provides formal guarantees against this new attack vector, unlike prior work that relied on Large Language Models to find the backdoors. Our mitigation strategy employs a novel Information Flow Control mechanism that analyzes the model graph and proves non-interference between different user inputs within the same batch. Using our mitigation strategy we perform a large scale analysis of models hosted through Hugging Face and find over 200 models that introduce (unintended) information leakage between batch entries due to the use of dynamic quantization.', 'abstract_zh': '近乎十年来，学术界一直在研究神经网络中的后门，主要关注攻击者操控模型预测的分类任务。尽管这些预测篡改攻击显然具有恶意性，但它们在现实世界中的直接影响仍然不够清晰。在本文中，我们引入了一种新型且更为有效的后门类别，该类别基于最近在架构后门方面的进展。我们展示了如何以特定的方式设计这些后门，使其能够利用批量推理，这是一种常见的硬件利用技术，从而实现大规模的用户数据操控和窃取。通过针对批量处理过程，这些架构后门使信息在并发用户请求之间泄漏成为可能，并允许攻击者完全控制同一批量内其他用户收到的模型响应。换句话说，能够改变模型架构的攻击者可以设定并窃取同一批量内其他用户的模型输入和输出。我们证明了此类攻击不仅可行，而且令人警觉地有效，可以轻松注入到普遍使用的模型架构中，并且代表了用户隐私和系统完整性的一种真正恶意威胁。关键的是，为了应对这一新类漏洞，我们提出了一个确定性的缓解策略，该策略提供了对该新攻击向量的正式保证，而不同于之前依赖大型语言模型来发现后门的方法。我们的缓解策略采用了一种新型的信息流控制机制，分析模型图，并证明同一批量内不同用户输入之间的非干涉性。使用我们的缓解策略，我们对通过Hugging Face托管的大量模型进行了分析，发现超过200个模型因使用动态量化而引入了（无意的）批量条目间的信息泄漏。', 'title_zh': '建筑设计中的批次内数据窃取和模型推理操纵后门'}
{'arxiv_id': 'arXiv:2505.18322', 'title': 'Is It Bad to Work All the Time? Cross-Cultural Evaluation of Social Norm Biases in GPT-4', 'authors': 'Zhuozhuo Joy Liu, Farhan Samir, Mehar Bhatia, Laura K. Nelson, Vered Shwartz', 'link': 'https://arxiv.org/abs/2505.18322', 'abstract': 'LLMs have been demonstrated to align with the values of Western or North American cultures. Prior work predominantly showed this effect through leveraging surveys that directly ask (originally people and now also LLMs) about their values. However, it is hard to believe that LLMs would consistently apply those values in real-world scenarios. To address that, we take a bottom-up approach, asking LLMs to reason about cultural norms in narratives from different cultures. We find that GPT-4 tends to generate norms that, while not necessarily incorrect, are significantly less culture-specific. In addition, while it avoids overtly generating stereotypes, the stereotypical representations of certain cultures are merely hidden rather than suppressed in the model, and such stereotypes can be easily recovered. Addressing these challenges is a crucial step towards developing LLMs that fairly serve their diverse user base.', 'abstract_zh': 'LLMs在不同文化叙事中的文化规范推理显示它们的文化特定性减弱，并且潜在刻板印象依旧存在：克服这些挑战是开发公平服务于多元化用户的基础。', 'title_zh': '全职工作是否弊大于利？GPT-4的社会规范偏差跨文化评估'}
{'arxiv_id': 'arXiv:2505.18315', 'title': 'COLORA: Efficient Fine-Tuning for Convolutional Models with a Study Case on Optical Coherence Tomography Image Classification', 'authors': 'Mariano Rivera, Angello Hoyos', 'link': 'https://arxiv.org/abs/2505.18315', 'abstract': 'We introduce the Convolutional Low-Rank Adaptation (CoLoRA) method, designed explicitly to overcome the inefficiencies found in current CNN fine-tuning methods. CoLoRA can be seen as a natural extension of the convolutional architectures of the Low-Rank Adaptation (LoRA) technique. We demonstrate the capabilities of our method by developing and evaluating models using the widely adopted CNN backbone pre-trained on ImageNet. We observed that this strategy results in a stable and accurate coarse-tuning procedure. Moreover, this strategy is computationally efficient and significantly reduces the number of parameters required for fine-tuning compared to traditional methods. Furthermore, our method substantially improves the speed and stability of training. Our case study focuses on classifying retinal diseases from optical coherence tomography (OCT) images, specifically using the OCTMNIST dataset. Experimental results demonstrate that a CNN backbone fine-tuned with CoLoRA surpasses nearly 1\\% in accuracy. Such a performance is comparable to the Vision Transformer, State-space discrete, and Kolmogorov-Arnold network models.', 'abstract_zh': '我们介绍了卷积低秩适应（CoLoRA）方法，该方法专门设计用于克服当前CNN微调方法中存在的低效问题。CoLoRA可以视为低秩适应（LoRA）技术中卷积架构的自然扩展。我们通过在ImageNet上预训练的广泛采用的CNN骨干网络构建和评估模型，展示了该方法的能力。我们发现这种方法能够实现稳定且准确的粗微调过程。此外，这种方法在计算上更加高效，并且相对于传统方法显著减少了微调所需的参数数量。此外，我们的方法显著提高了训练的速度和稳定性。我们的案例研究集中在使用OCTMNIST数据集从光学相干断层扫描（OCT）图像中分类视网膜疾病上。实验结果表明，使用CoLoRA进行微调的CNN骨干网络的准确率提高了近1%。该性能与Vision Transformer、State-space discrete和Kolmogorov-Arnold网络模型相当。', 'title_zh': 'COLORA：针对光学相干断层图像分类的卷积模型高效微调研究'}
{'arxiv_id': 'arXiv:2505.18287', 'title': 'Efficient Algorithms for Electing Successive Committees', 'authors': 'Pallavi Jain, Andrzej Kaczmarczyk', 'link': 'https://arxiv.org/abs/2505.18287', 'abstract': 'In a recently introduced model of successive committee elections (Bredereck et al., AAAI-20) for a given set of ordinal or approval preferences one aims to find a sequence of a given length of "best" same-size committees such that each candidate is a member of a limited number of consecutive committees. However, the practical usability of this model remains limited, as the described task turns out to be NP-hard for most selection criteria already for seeking committees of size three. Non-trivial or somewhat efficient algorithms for these cases are lacking too. Motivated by a desire to unlock the full potential of the described temporal model of committee elections, we devise (parameterized) algorithms that effectively solve the mentioned hard cases in realistic scenarios of a moderate number of candidates or of a limited time horizon.', 'abstract_zh': '近日引入的连续委员会选举模型（Bredereck et al., AAAI-20）：为给定的序贯或批准偏好集，目标是在每个候选人仅属于有限数量的连续委员会的前提下，找到一个给定长度的最佳同规模委员会序列。然而，由于大多数选择标准在寻找大小为三的委员会时该项任务被认为NP难，未能找到有效或相对高效的算法。为实现上述时间模型在委员会选举中的全部潜力，我们设计了参数化算法，在候选人数适度或时间范围有限的现实场景中有效解决上述难题。', 'title_zh': '高效算法选举继任委员会'}
{'arxiv_id': 'arXiv:2505.18286', 'title': 'Single-agent or Multi-agent Systems? Why Not Both?', 'authors': 'Mingyan Gao, Yanzi Li, Banruo Liu, Yifan Yu, Phillip Wang, Ching-Yu Lin, Fan Lai', 'link': 'https://arxiv.org/abs/2505.18286', 'abstract': 'Multi-agent systems (MAS) decompose complex tasks and delegate subtasks to different large language model (LLM) agents and tools. Prior studies have reported the superior accuracy performance of MAS across diverse domains, enabled by long-horizon context tracking and error correction through role-specific agents. However, the design and deployment of MAS incur higher complexity and runtime cost compared to single-agent systems (SAS). Meanwhile, frontier LLMs, such as OpenAI-o3 and Gemini-2.5-Pro, have rapidly advanced in long-context reasoning, memory retention, and tool usage, mitigating many limitations that originally motivated MAS designs. In this paper, we conduct an extensive empirical study comparing MAS and SAS across various popular agentic applications. We find that the benefits of MAS over SAS diminish as LLM capabilities improve, and we propose efficient mechanisms to pinpoint the error-prone agent in MAS. Furthermore, the performance discrepancy between MAS and SAS motivates our design of a hybrid agentic paradigm, request cascading between MAS and SAS, to improve both efficiency and capability. Our design improves accuracy by 1.1-12% while reducing deployment costs by up to 20% across various agentic applications.', 'abstract_zh': '多智能体系统（MAS）将复杂任务分解并委派给不同的大型语言模型（LLM）智能体和工具。前期研究显示，MAS在多个领域表现出更优异的准确性，这得益于其长时序语境追踪和通过特定角色智能体进行的错误纠正。然而，MAS的设计和部署比单智能体系统（SAS）更为复杂且运行成本更高。同时，前沿的LLM，如OpenAI-o3和Gemini-2.5-Pro，在长上下文推理、记忆保留和工具使用方面取得了快速进步，缓解了许多原本促使设计MAS的局限性。在本文中，我们对MAS和SAS在多种流行的智能体应用中进行了广泛的实证研究。我们发现，随着LLM能力的提升，MAS相对于SAS的优势逐渐减弱，并提出有效的机制以确定MAS中的易出错智能体。此外，MAS和SAS之间的性能差异促使我们设计了一种混合型智能体范式——MAS和SAS之间的请求级联，以提高效率和能力。我们的设计在多种智能体应用中提高了1.1%-12%的准确性并降低了20%的部署成本。', 'title_zh': '单智能体系统还是多智能体系统？何不兼而有之？'}
{'arxiv_id': 'arXiv:2505.18284', 'title': 'Tube Loss based Deep Networks For Improving the Probabilistic Forecasting of Wind Speed', 'authors': 'Pritam Anand, Aadesh Minz, Asish Joel', 'link': 'https://arxiv.org/abs/2505.18284', 'abstract': 'Uncertainty Quantification (UQ) in wind speed forecasting is a critical challenge in wind power production due to the inherently volatile nature of wind. By quantifying the associated risks and returns, UQ supports more effective decision-making for grid operations and participation in the electricity market. In this paper, we design a sequence of deep learning based probabilistic forecasting methods by using the Tube loss function for wind speed forecasting. The Tube loss function is a simple and model agnostic Prediction Interval (PI) estimation approach and can obtain the narrow PI with asymptotical coverage guarantees without any distribution assumption. Our deep probabilistic forecasting models effectively incorporate popular architectures such as LSTM, GRU, and TCN within the Tube loss framework. We further design a simple yet effective heuristic for tuning the $\\delta$ parameter of the Tube loss function so that our deep forecasting models obtain the narrower PI without compromising its calibration ability. We have considered three wind datasets, containing the hourly recording of the wind speed, collected from three distinct location namely Jaisalmer, Los Angeles and San Fransico. Our numerical results demonstrate that the proposed deep forecasting models produce more reliable and narrower PIs compared to recently developed probabilistic wind forecasting methods.', 'abstract_zh': '风速预测中的不确定性量化（UQ）是由于风能本身具有固有的波动性，在风力发电生产中是一个关键挑战。通过量化相关的风险和回报，不确定性量化支持了更有效的电网运营决策和电力市场的参与。在本文中，我们设计了一系列基于深度学习的概率预测方法，使用Tube损失函数进行风速预测。Tube损失函数是一种简单且模型无关的预测区间（PI）估计方法，可以在没有任何分布假设的情况下获得具有渐近覆盖保证的窄PI。我们的深度概率预测模型在Tube损失框架内有效地整合了流行的架构，如LSTM、GRU和TCN。我们还设计了一个简单而有效的启发式方法来调整Tube损失函数中的$\\delta$参数，从而使我们的深度预测模型获得更窄的预测区间同时不牺牲其校准能力。我们考虑了三个风数据集，分别来自杰亚斯梅尔、洛杉矶和旧金山，每小时记录风速。我们的数值结果表明，所提出的深度预测模型相比于最近开发的概率风速预测方法，能产生更可靠和更窄的预测区间。', 'title_zh': '基于Tube Loss的深层网络模型改进风速概率预测'}
{'arxiv_id': 'arXiv:2505.18283', 'title': 'TAGS: A Test-Time Generalist-Specialist Framework with Retrieval-Augmented Reasoning and Verification', 'authors': 'Jianghao Wu, Feilong Tang, Yulong Li, Ming Hu, Haochen Xue, Shoaib Jameel, Yutong Xie, Imran Razzak', 'link': 'https://arxiv.org/abs/2505.18283', 'abstract': 'Recent advances such as Chain-of-Thought prompting have significantly improved large language models (LLMs) in zero-shot medical reasoning. However, prompting-based methods often remain shallow and unstable, while fine-tuned medical LLMs suffer from poor generalization under distribution shifts and limited adaptability to unseen clinical scenarios. To address these limitations, we present TAGS, a test-time framework that combines a broadly capable generalist with a domain-specific specialist to offer complementary perspectives without any model fine-tuning or parameter updates. To support this generalist-specialist reasoning process, we introduce two auxiliary modules: a hierarchical retrieval mechanism that provides multi-scale exemplars by selecting examples based on both semantic and rationale-level similarity, and a reliability scorer that evaluates reasoning consistency to guide final answer aggregation. TAGS achieves strong performance across nine MedQA benchmarks, boosting GPT-4o accuracy by 13.8%, DeepSeek-R1 by 16.8%, and improving a vanilla 7B model from 14.1% to 23.9%. These results surpass several fine-tuned medical LLMs, without any parameter updates. The code will be available at this https URL.', 'abstract_zh': 'Recent Advances in Zero-Shot Medical Reasoning with TAGS: A Test-Time Framework Combining Generalist and Specialist Models', 'title_zh': 'TAGS：一种测试时通用专家检索增强推理与验证框架'}
{'arxiv_id': 'arXiv:2505.18282', 'title': 'Towards a Quantum-classical Augmented Network', 'authors': 'Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam', 'link': 'https://arxiv.org/abs/2505.18282', 'abstract': 'In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of existing networks and adopt currently feasible quantum technologies, the next step is to augment classical networks with quantum devices, properties, and phenomena. To achieve this, we propose a change in the structure of the HTTP protocol such that it can carry both quantum and classical payload. This work lays the foundation for dividing one single network packet into classical and quantum payloads depending on the privacy needs. We implement logistic regression, CNN, LSTM, and BiLSTM models to classify the privacy label for outgoing communications. This enables reduced utilization of quantum resources allowing for a more efficient secure quantum network design. Experimental results using the proposed methods are presented.', 'abstract_zh': '近十年来，已建立了一些小型量子密钥分发网络。然而，大型量子网络的部署取决于量子中继器、量子信道、量子存储和量子网络协议的发展。为了提高现有网络的安全性并采用当前可行的量子技术，下一步是在经典网络中引入量子设备、属性和现象。为此，我们提议改变HTTP协议的结构，使其能够同时承载量子和经典负载。本项工作为根据隐私需求将单个网络包分为经典和量子负载奠定了基础。我们实现了逻辑回归、CNN、LSTM和BiLSTM模型来分类出站通信的隐私标签，这使得量子资源的使用减少，从而能够更高效地设计安全的量子网络。使用所提出的方法进行了实验，展示了实验结果。', 'title_zh': '面向量子-经典增强网络'}
{'arxiv_id': 'arXiv:2505.18280', 'title': 'Feature Preserving Shrinkage on Bayesian Neural Networks via the R2D2 Prior', 'authors': 'Tsai Hor Chan, Dora Yan Zhang, Guosheng Yin, Lequan Yu', 'link': 'https://arxiv.org/abs/2505.18280', 'abstract': 'Bayesian neural networks (BNNs) treat neural network weights as random variables, which aim to provide posterior uncertainty estimates and avoid overfitting by performing inference on the posterior weights. However, the selection of appropriate prior distributions remains a challenging task, and BNNs may suffer from catastrophic inflated variance or poor predictive performance when poor choices are made for the priors. Existing BNN designs apply different priors to weights, while the behaviours of these priors make it difficult to sufficiently shrink noisy signals or they are prone to overshrinking important signals in the weights. To alleviate this problem, we propose a novel R2D2-Net, which imposes the R^2-induced Dirichlet Decomposition (R2D2) prior to the BNN weights. The R2D2-Net can effectively shrink irrelevant coefficients towards zero, while preventing key features from over-shrinkage. To approximate the posterior distribution of weights more accurately, we further propose a variational Gibbs inference algorithm that combines the Gibbs updating procedure and gradient-based optimization. This strategy enhances stability and consistency in estimation when the variational objective involving the shrinkage parameters is non-convex. We also analyze the evidence lower bound (ELBO) and the posterior concentration rates from a theoretical perspective. Experiments on both natural and medical image classification and uncertainty estimation tasks demonstrate satisfactory performance of our method.', 'abstract_zh': 'R2D2-Net：基于R²诱导狄利克雷分解先验的贝叶斯神经网络', 'title_zh': '贝叶斯神经网络中基于R2D2先验的特征保真收缩'}
{'arxiv_id': 'arXiv:2505.18279', 'title': 'Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control', 'authors': 'Alireza Rezazadeh, Zichao Li, Ange Lou, Yuying Zhao, Wei Wei, Yujia Bao', 'link': 'https://arxiv.org/abs/2505.18279', 'abstract': 'Complex tasks are increasingly delegated to ensembles of specialized LLM-based agents that reason, communicate, and coordinate actions-both among themselves and through interactions with external tools, APIs, and databases. While persistent memory has been shown to enhance single-agent performance, most approaches assume a monolithic, single-user context-overlooking the benefits and challenges of knowledge transfer across users under dynamic, asymmetric permissions. We introduce Collaborative Memory, a framework for multi-user, multi-agent environments with asymmetric, time-evolving access controls encoded as bipartite graphs linking users, agents, and resources. Our system maintains two memory tiers: (1) private memory-private fragments visible only to their originating user; and (2) shared memory-selectively shared fragments. Each fragment carries immutable provenance attributes (contributing agents, accessed resources, and timestamps) to support retrospective permission checks. Granular read policies enforce current user-agent-resource constraints and project existing memory fragments into filtered transformed views. Write policies determine fragment retention and sharing, applying context-aware transformations to update the memory. Both policies may be designed conditioned on system, agent, and user-level information. Our framework enables safe, efficient, and interpretable cross-user knowledge sharing, with provable adherence to asymmetric, time-varying policies and full auditability of memory operations.', 'abstract_zh': '基于多用户、多代理环境的协作记忆框架', 'title_zh': '协作记忆：LLM代理中的多用户记忆共享及动态访问控制'}
{'arxiv_id': 'arXiv:2505.18266', 'title': 'Uncovering a Universal Abstract Algorithm for Modular Addition in Neural Networks', 'authors': 'Gavin McCracken, Gabriela Moisescu-Pareja, Vincent Letourneau, Doina Precup, Jonathan Love', 'link': 'https://arxiv.org/abs/2505.18266', 'abstract': 'We propose a testable universality hypothesis, asserting that seemingly disparate neural network solutions observed in the simple task of modular addition are unified under a common abstract algorithm. While prior work interpreted variations in neuron-level representations as evidence for distinct algorithms, we demonstrate - through multi-level analyses spanning neurons, neuron clusters, and entire networks - that multilayer perceptrons and transformers universally implement the abstract algorithm we call the approximate Chinese Remainder Theorem. Crucially, we introduce approximate cosets and show that neurons activate exclusively on them. Furthermore, our theory works for deep neural networks (DNNs). It predicts that universally learned solutions in DNNs with trainable embeddings or more than one hidden layer require only O(log n) features, a result we empirically confirm. This work thus provides the first theory-backed interpretation of multilayer networks solving modular addition. It advances generalizable interpretability and opens a testable universality hypothesis for group multiplication beyond modular addition.', 'abstract_zh': '我们提出一个可验证的普遍性假设，认为在简单模块加法任务中观察到的看似不同的神经网络解决方案其实统一在一种共同的抽象算法之下。此前的工作通过神经元层面表示的差异解释为不同的算法，而我们通过涵盖神经元、神经元簇和整个网络的多层级分析表明，多层感知机和变换器普遍实现了我们所称的近似中国剩余定理的抽象算法。关键的是，我们引入了近似陪集的概念，并证明了神经元仅在这些陪集上激活。此外，我们的理论适用于深度神经网络。我们预测，在具有可训练嵌入或多个隐藏层的深度神经网络中，普遍学习的解决方案只需要O(log n)个特征，这一结果我们通过实证研究得到了验证。因此，本工作提供了第一个关于多层网络解决模加法的理论支持解释，推进了可泛化的可解释性，并为超越模加法的群乘操作提出一个可验证的普遍性假设。', 'title_zh': '揭示神经网络中模块化加法的通用抽象算法'}
{'arxiv_id': 'arXiv:2505.18247', 'title': 'MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning', 'authors': 'Kunal Sawarkar, Shivam R. Solanki, Abhilasha Mangal', 'link': 'https://arxiv.org/abs/2505.18247', 'abstract': "Despite the widespread exploration of Retrieval-Augmented Generation (RAG), its deployment in enterprises for domain-specific datasets remains limited due to poor answer accuracy. These corpora, often shielded behind firewalls in private enterprise knowledge bases, having complex, domain-specific terminology, rarely seen by LLMs during pre-training; exhibit significant semantic variability across domains (like networking, military, or legal, etc.), or even within a single domain like medicine, and thus result in poor context precision for RAG systems. Currently, in such situations, fine-tuning or RAG with fine-tuning is attempted, but these approaches are slow, expensive, and lack generalization for accuracy as the new domain-specific data emerges. We propose an approach for Enterprise Search that focuses on enhancing the retriever for a domain-specific corpus through hybrid query indexes and metadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata generation pipeline using key concepts, topics, and acronyms, and then creates a metadata-enriched hybrid index with boosted search queries. This approach avoids overfitting and generalizes effectively across domains. On the PubMedQA benchmark for the biomedical domain, the proposed method achieves 82% retrieval accuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results without fine-tuning and sets a new benchmark for zero-shot results while outperforming much larger models like GPT3.5. The results are even comparable to the best fine-tuned models on this dataset, and we further demonstrate the robustness and scalability of the approach by evaluating it on other Q&A datasets like SQuAD, NQ etc.", 'abstract_zh': '基于元数据增强的混合查询融合生成检索增强生成方法在企业搜索中的应用', 'title_zh': 'MetaGen 混合 RAG：无需微调的领域特定问答更高准确性'}
{'arxiv_id': 'arXiv:2505.18244', 'title': 'Multi-Scale Probabilistic Generation Theory: A Hierarchical Framework for Interpreting Large Language Models', 'authors': 'Yukin Zhang, Qi Dong', 'link': 'https://arxiv.org/abs/2505.18244', 'abstract': 'Large Transformer based language models achieve remarkable performance but remain opaque in how they plan, structure, and realize text. We introduce Multi_Scale Probabilistic Generation Theory (MSPGT), a hierarchical framework that factorizes generation into three semantic scales_global context, intermediate structure, and local word choices and aligns each scale with specific layer ranges in Transformer architectures. To identify scale boundaries, we propose two complementary metrics: attention span thresholds and inter layer mutual information peaks. Across four representative models (GPT-2, BERT, RoBERTa, and T5), these metrics yield stable local/intermediate/global partitions, corroborated by probing tasks and causal interventions. We find that decoder_only models allocate more layers to intermediate and global processing while encoder_only models emphasize local feature extraction. Through targeted interventions, we demonstrate that local scale manipulations primarily influence lexical diversity, intermediate-scale modifications affect sentence structure and length, and global_scale perturbations impact discourse coherence all with statistically significant effects. MSPGT thus offers a unified, architecture-agnostic method for interpreting, diagnosing, and controlling large language models, bridging the gap between mechanistic interpretability and emergent capabilities.', 'abstract_zh': '多尺度概率生成理论：一种区分生成文本层次结构的统一框架', 'title_zh': '多尺度概率生成理论：一种解释大型语言模型的分层框架'}
{'arxiv_id': 'arXiv:2505.18243', 'title': 'ZeroML: A Next Generation AutoML Language', 'authors': 'Monirul Islam Mahmud', 'link': 'https://arxiv.org/abs/2505.18243', 'abstract': 'ZeroML is a new generation programming language for AutoML to drive the ML pipeline in a compiled and multi-paradigm way, with a pure functional core. Meeting the shortcomings introduced by Python, R, or Julia such as slow-running time, brittle pipelines or high dependency cost ZeroML brings the Microservices-based architecture adding the modular, reusable pieces such as DataCleaner, FeatureEngineer or ModelSelector. As a native multithread and memory-aware search optimized toolkit, and with one command deployability ability, ZeroML ensures non-coders and ML professionals to create high-accuracy models super fast and in a more reproducible way. The verbosity of the language ensures that when it comes to dropping into the backend, the code we will be creating is extremely clear but the level of repetition and boilerplate required when developing on the front end is now removed.', 'abstract_zh': 'ZeroML是一种基于微服务架构的新一代编程语言，用于以编译和多范式方式驱动ML管道，具有纯粹函数核心。零编译Python、R或Julia等语言引入的运行效率低、管道脆弱或依赖成本高问题，ZeroML提供了模块化、可重用的数据清洗器（DataCleaner）、特征工程师（FeatureEngineer）或模型选择器（ModelSelector）等组件。作为一种原生多线程和内存感知的搜索优化工具包，具有单命令部署能力，ZeroML确保非编码人员和ML专业人士能够快速创建高精度模型，并以更可再现的方式进行。语言的简洁性确保了在后端创建的代码极其清晰，而在前端开发中所需的重复和样板代码现在已被去除。', 'title_zh': 'ZeroML: 下一代自动机器学习语言'}
{'arxiv_id': 'arXiv:2505.18241', 'title': 'Intent Classification on Low-Resource Languages with Query Similarity Search', 'authors': 'Arjun Bhalla, Qi Huang', 'link': 'https://arxiv.org/abs/2505.18241', 'abstract': 'Intent classification is an important component of a functional Information Retrieval ecosystem. Many current approaches to intent classification, typically framed as a classification problem, can be problematic as intents are often hard to define and thus data can be difficult and expensive to annotate. The problem is exacerbated when we need to extend the intent classification system to support multiple and in particular low-resource languages. To address this, we propose casting intent classification as a query similarity search problem - we use previous example queries to define an intent, and a query similarity method to classify an incoming query based on the labels of its most similar queries in latent space. With the proposed approach, we are able to achieve reasonable intent classification performance for queries in low-resource languages in a zero-shot setting.', 'abstract_zh': '意图分类是功能型信息检索生态系统中的一个重要组成部分。当前许多意图分类的方法通常被构架为分类问题，但这种方法可能存在问题，因为意图往往很难定义，因此标注数据具有挑战性和成本高昂。当需要将意图分类系统扩展以支持多种语言，尤其是低资源语言时，这一问题更为严重。为解决这一问题，我们建议将意图分类重新构架为查询相似性搜索问题——使用先前的示例查询来定义意图，并使用查询相似性方法根据入coming查询在潜在空间中最相似查询的标签对其进行分类。通过提出的这种方法，在零样本设置下，我们能够实现对低资源语言查询的合理意图分类性能。', 'title_zh': '低资源语言中的意图分类与查询相似性搜索'}
{'arxiv_id': 'arXiv:2505.18240', 'title': 'Taming LLMs with Negative Samples: A Reference-Free Framework to Evaluate Presentation Content with Actionable Feedback', 'authors': 'Ananth Muppidi, Tarak Das, Sambaran Bandyopadhyay, Tripti Shukla, Dharun D A', 'link': 'https://arxiv.org/abs/2505.18240', 'abstract': 'The generation of presentation slides automatically is an important problem in the era of generative AI. This paper focuses on evaluating multimodal content in presentation slides that can effectively summarize a document and convey concepts to a broad audience. We introduce a benchmark dataset, RefSlides, consisting of human-made high-quality presentations that span various topics. Next, we propose a set of metrics to characterize different intrinsic properties of the content of a presentation and present REFLEX, an evaluation approach that generates scores and actionable feedback for these metrics. We achieve this by generating negative presentation samples with different degrees of metric-specific perturbations and use them to fine-tune LLMs. This reference-free evaluation technique does not require ground truth presentations during inference. Our extensive automated and human experiments demonstrate that our evaluation approach outperforms classical heuristic-based and state-of-the-art large language model-based evaluations in generating scores and explanations.', 'abstract_zh': '生成演示文稿自动生成是生成AI时代的重要问题。本文专注于评估演示文稿中的多模态内容，这些内容能够有效总结文档并传达给广泛受众的概念。我们介绍了一个基准数据集RefSlides，包含高质量的人工制作的演示文稿，涵盖多个主题。接下来，我们提出了一套度量标准来表征演示文稿内容的不同内在属性，并介绍了REFLEX评估方法，该方法为这些度量标准生成评分和可操作的反馈。我们通过生成具有不同程度度量标准特定扰动的负演示样本，并使用它们微调LLM来实现这一目标。这种参考自由的评估技术在推理时不需真实演示文稿作为 ground truth。我们的广泛自动和人工实验表明，我们的评估方法在生成评分和解释方面优于经典启发式方法和最新的基于大型语言模型的方法。', 'title_zh': '用负样本驯服大型语言模型：一个基于可操作反馈评估展示内容的参考免费框架'}
{'arxiv_id': 'arXiv:2505.18237', 'title': 'Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens', 'authors': 'Xixian Yong, Xiao Zhou, Yingying Zhang, Jinlin Li, Yefeng Zheng, Xian Wu', 'link': 'https://arxiv.org/abs/2505.18237', 'abstract': 'The recent rise of Large Reasoning Models (LRMs) has significantly improved multi-step reasoning performance, but often at the cost of generating excessively long reasoning chains. This paper revisits the efficiency of such reasoning processes through an information-theoretic lens, revealing a fundamental trade-off between reasoning length and semantic efficiency. We propose two metrics, InfoBias and InfoGain, to quantify divergence from ideal reasoning paths and stepwise information contribution, respectively. Empirical analyses show that longer reasoning chains tend to exhibit higher information bias and diminishing information gain, especially for incorrect answers. Motivated by these findings, we introduce an entropy-based Adaptive Think strategy that dynamically halts reasoning once confidence is sufficiently high, improving efficiency while maintaining competitive accuracy. Compared to the Vanilla Think approach (default mode), our strategy yields a 1.10% improvement in average accuracy and a 50.80% reduction in token usage on QwQ-32B across six benchmark tasks spanning diverse reasoning types and difficulty levels, demonstrating superior efficiency and reasoning performance. These results underscore the promise of entropy-based methods for enhancing both accuracy and cost-effiiciency in large language model deployment.', 'abstract_zh': '大型推理模型近期的发展显著提高了多步推理性能，但往往以生成过长的推理链为代价。本文从信息论的角度重新审视了此类推理过程的本质，揭示了推理长度与语义效率之间基本的权衡关系。我们提出了两个度量标准，分别为InfoBias和InfoGain，分别用于量化偏离理想推理路径的程度和逐步信息贡献。实证分析表明，较长的推理链往往会表现出更高的信息偏差和递减的信息增益，尤其是在错误答案的情况下更为明显。基于这些发现，我们引入了一种基于熵的自适应推理策略，该策略能够动态停止推理以实现高效性，并维持竞争力的准确率。与Vanilla Think方法（默认模式）相比，我们的策略在QwQ-32B上的六项基准任务中实现了平均准确率1.10%的提升和50.80%的令牌使用量减少，显示出更高的效率和推理性能。这些结果突显了基于熵的方法在提升大型语言模型部署的准确性和成本效率方面的潜力。', 'title_zh': '思考还是不思考？通过信息论视角探索大型推理模型的思考效率'}
{'arxiv_id': 'arXiv:2505.18236', 'title': 'From Bias to Accountability: How the EU AI Act Confronts Challenges in European GeoAI Auditing', 'authors': 'Natalia Matuszczyk, Craig R. Barnes, Rohit Gupta, Bulent Ozel, Aniket Mitra', 'link': 'https://arxiv.org/abs/2505.18236', 'abstract': "Bias in geospatial artificial intelligence (GeoAI) models has been documented, yet the evidence is scattered across narrowly focused studies. We synthesize this fragmented literature to provide a concise overview of bias in GeoAI and examine how the EU's Artificial Intelligence Act (EU AI Act) shapes audit obligations. We discuss recurring bias mechanisms, including representation, algorithmic and aggregation bias, and map them to specific provisions of the EU AI Act. By applying the Act's high-risk criteria, we demonstrate that widely deployed GeoAI applications qualify as high-risk systems. We then present examples of recent audits along with an outline of practical methods for detecting bias. As far as we know, this study represents the first integration of GeoAI bias evidence into the EU AI Act context, by identifying high-risk GeoAI systems and mapping bias mechanisms to the Act's Articles. Although the analysis is exploratory, it suggests that even well-curated European datasets should employ routine bias audits before 2027, when the AI Act's high-risk provisions take full effect.", 'abstract_zh': '地理人工智能（GeoAI）模型中的偏差已有所记录，但证据散布在专门研究中。我们将这些分散的文献综合起来，提供GeoAI偏差的简洁综述，并探讨欧盟人工智能法案（EU AI Act）如何影响审计义务。我们讨论重复出现的偏差机制，包括表示偏差、算法偏差和聚合偏差，并将它们映射到EU AI Act的具体条款中。通过应用该法案的高风险标准，我们证明广泛部署的GeoAI应用符合高风险系统的要求。然后，我们提供了最近审计的例子，并概述了检测偏差的实际方法。据我们所知，本研究可能是首次将GeoAI偏差证据纳入EU AI Act的背景中，通过识别高风险GeoAI系统并将偏差机制映射到法案的各条文。尽管分析具有探索性，但它表明即使精心策划的欧洲数据集也应在2027年欧盟人工智能法案的高风险条款完全生效之前进行常规偏差审计。', 'title_zh': '从偏见到问责：欧盟AI法案在欧洲地景人工智能审计中应对挑战的方式'}
{'arxiv_id': 'arXiv:2505.18235', 'title': 'The Origins of Representation Manifolds in Large Language Models', 'authors': 'Alexander Modell, Patrick Rubin-Delanchy, Nick Whiteley', 'link': 'https://arxiv.org/abs/2505.18235', 'abstract': "There is a large ongoing scientific effort in mechanistic interpretability to map embeddings and internal representations of AI systems into human-understandable concepts. A key element of this effort is the linear representation hypothesis, which posits that neural representations are sparse linear combinations of `almost-orthogonal' direction vectors, reflecting the presence or absence of different features. This model underpins the use of sparse autoencoders to recover features from representations. Moving towards a fuller model of features, in which neural representations could encode not just the presence but also a potentially continuous and multidimensional value for a feature, has been a subject of intense recent discourse. We describe why and how a feature might be represented as a manifold, demonstrating in particular that cosine similarity in representation space may encode the intrinsic geometry of a feature through shortest, on-manifold paths, potentially answering the question of how distance in representation space and relatedness in concept space could be connected. The critical assumptions and predictions of the theory are validated on text embeddings and token activations of large language models.", 'abstract_zh': '大规模正在进行中有系统解释性的科学研究致力于将AI系统的嵌入和内部表示映射到人类可理解的概念。这一努力的关键要素是线性表示假设，该假设认为神经表示是几乎正交的方向向量的稀疏线性组合，反映出不同特征的存在与否。该模型支持使用稀疏自编码器从表示中恢复特征。朝着更具综合性的特征模型发展，该模型中神经表示不仅能编码特征的存在，还能编码特征的一个潜在的连续且多维的价值，这是近期讨论的热点。我们描述了为何以及如何将特征表示为流形，并特别说明了表示空间中的余弦相似度可能通过流形上的最短路径编码特征的内在几何结构，从而有可能解释表示空间中的距离与概念空间中的相关性之间的关系。该理论的关键假设和预测在文本嵌入和大型语言模型的标记激活中得到了验证。', 'title_zh': '大型语言模型中表示流形的起源'}
{'arxiv_id': 'arXiv:2505.18234', 'title': 'A Robust PPO-optimized Tabular Transformer Framework for Intrusion Detection in Industrial IoT Systems', 'authors': 'Yuanya She', 'link': 'https://arxiv.org/abs/2505.18234', 'abstract': 'In this paper, we propose a robust and reinforcement-learning-enhanced network intrusion detection system (NIDS) designed for class-imbalanced and few-shot attack scenarios in Industrial Internet of Things (IIoT) environments. Our model integrates a TabTransformer for effective tabular feature representation with Proximal Policy Optimization (PPO) to optimize classification decisions via policy learning. Evaluated on the TON\\textunderscore IoT benchmark, our method achieves a macro F1-score of 97.73\\% and accuracy of 98.85\\%. Remarkably, even on extremely rare classes like man-in-the-middle (MITM), our model achieves an F1-score of 88.79\\%, showcasing strong robustness and few-shot detection capabilities. Extensive ablation experiments confirm the complementary roles of TabTransformer and PPO in mitigating class imbalance and improving generalization. These results highlight the potential of combining transformer-based tabular learning with reinforcement learning for real-world NIDS applications.', 'abstract_zh': '一种增强学习增强的鲁棒网络入侵检测系统：适用于工业互联网中的类别不平衡和少样本攻击场景', 'title_zh': '一种针对工业物联网系统入侵检测的鲁棒PPO优化表结构变换器框架'}
{'arxiv_id': 'arXiv:2505.18233', 'title': 'POSTER: A Multi-Signal Model for Detecting Evasive Smishing', 'authors': 'Shaghayegh Hosseinpour, Sanchari Das', 'link': 'https://arxiv.org/abs/2505.18233', 'abstract': 'Smishing, or SMS-based phishing, poses an increasing threat to mobile users by mimicking legitimate communications through culturally adapted, concise, and deceptive messages, which can result in the loss of sensitive data or financial resources. In such, we present a multi-channel smishing detection model that combines country-specific semantic tagging, structural pattern tagging, character-level stylistic cues, and contextual phrase embeddings. We curated and relabeled over 84,000 messages across five datasets, including 24,086 smishing samples. Our unified architecture achieves 97.89% accuracy, an F1 score of 0.963, and an AUC of 99.73%, outperforming single-stream models by capturing diverse linguistic and structural cues. This work demonstrates the effectiveness of multi-signal learning in robust and region-aware phishing.', 'abstract_zh': '基于短信的诈骗（Smishing）通过模仿经过文化适应的、简洁的和有欺骗性的信息，对移动用户构成日益严重的威胁，可能导致敏感数据或财务资源的损失。为此，我们提出了一种多渠道的smishing检测模型，结合了国家特定的语义标签、结构模式标签、字符级风格暗示和上下文短语嵌入。我们整理并重新标记了来自五个数据集的超过84,000条消息，其中包括24,086条smishing样本。我们的统一架构达到了97.89%的准确率，F1分数为0.963，AUC为99.73%，比单一渠道模型更好地捕捉到了多元的语言和结构线索。本工作展示了多信号学习在鲁棒和区域意识诈骗检测中的有效性。', 'title_zh': 'Poster: 基于多信号模型的规避式 Smishing 检测方法'}
{'arxiv_id': 'arXiv:2505.18232', 'title': 'ELDeR: Getting Efficient LLMs through Data-Driven Regularized Layer-wise Pruning', 'authors': 'Mingkuan Feng, Jinyang Wu, Siyuan Liu, Shuai Zhang, Hongjian Fang, Ruihan Jin, Feihu Che, Pengpeng Shao, Zhengqi Wen, Jianhua Tao', 'link': 'https://arxiv.org/abs/2505.18232', 'abstract': "The deployment of Large language models (LLMs) in many fields is largely hindered by their high computational and memory costs. Recent studies suggest that LLMs exhibit sparsity, which can be used for pruning. Previous pruning methods typically follow a prune-then-finetune paradigm. Since the pruned parts still contain valuable information, statically removing them without updating the remaining parameters often results in irreversible performance degradation, requiring costly recovery fine-tuning (RFT) to maintain performance. To address this, we propose a novel paradigm: first apply regularization, then prune. Based on this paradigm, we propose ELDeR: Getting Efficient LLMs through Data-Driven Regularized Layer-wise Pruning. We multiply the output of each transformer layer by an initial weight, then we iteratively learn the weights of each transformer layer by using a small amount of data in a simple way. After that, we apply regularization to the difference between the output and input of the layers with smaller weights, forcing the information to be transferred to the remaining layers. Compared with direct pruning, ELDeR reduces the information loss caused by direct parameter removal, thus better preserving the model's language modeling ability. Experimental results show that ELDeR achieves superior performance compared with powerful layer-wise structured pruning methods, while greatly reducing RFT computational costs. Since ELDeR is a layer-wise pruning method, its end-to-end acceleration effect is obvious, making it a promising technique for efficient LLMs.", 'abstract_zh': '大型语言模型（LLMs）在许多领域的部署受到其高计算和内存成本的限制。近期的研究表明，LLMs表现出稀疏性，可以被用于剪枝。之前的剪枝方法通常遵循先剪枝后微调的范式。由于剪枝后的部分仍然包含有价值的信息，如果静态移除这些部分而不更新剩余参数，往往会导致不可逆的性能下降，需要昂贵的恢复微调（RFT）来维持性能。为了解决这一问题，我们提出了一种新的范式：先应用正则化，再剪枝。基于这一范式，我们提出了ELDeR：通过数据驱动的正则化逐层剪枝获得高效LLMs。我们首先对每个变压器层的输出乘以初始权重，然后通过少量数据简单地学习每个变压器层的权重。之后，我们对权重较小的层的输出和输入之间的差异应用正则化，迫使信息传递到剩余的层。与直接剪枝相比，ELDeR减少了直接移除参数所导致的信息损失，从而更好地保留了模型的语言建模能力。实验结果表明，ELDeR在性能上优于强大的逐层结构化剪枝方法，同时大大降低了RFT的计算成本。由于ELDeR是一种逐层剪枝方法，其端到端加速效果明显，因此是一种有望用于高效LLMs的技术。', 'title_zh': 'ELDeR: 通过数据驱动正则化分层剪枝实现高效LLMs'}
{'arxiv_id': 'arXiv:2505.18231', 'title': 'NSNQuant: A Double Normalization Approach for Calibration-Free Low-Bit Vector Quantization of KV Cache', 'authors': 'Donghyun Son, Euntae Choi, Sungjoo Yoo', 'link': 'https://arxiv.org/abs/2505.18231', 'abstract': 'Large Language Model (LLM) inference is typically memory-intensive, especially when processing large batch sizes and long sequences, due to the large size of key-value (KV) cache. Vector Quantization (VQ) is recently adopted to alleviate this issue, but we find that the existing approach is susceptible to distribution shift due to its reliance on calibration datasets. To address this limitation, we introduce NSNQuant, a calibration-free Vector Quantization (VQ) technique designed for low-bit compression of the KV cache. By applying a three-step transformation-1) a token-wise normalization (Normalize), 2) a channel-wise centering (Shift), and 3) a second token-wise normalization (Normalize)-with Hadamard transform, NSNQuant effectively aligns the token distribution with the standard normal distribution. This alignment enables robust, calibration-free vector quantization using a single reusable codebook. Extensive experiments show that NSNQuant consistently outperforms prior methods in both 1-bit and 2-bit settings, offering strong generalization and up to 3$\\times$ throughput gain over full-precision baselines.', 'abstract_zh': '无监督归一化量化(NSNQuant):一种无需校准的数据关键值缓存低比特压缩技术', 'title_zh': 'NSNQuant: 一种用于KV缓存无校准低比特向量量化的方法，双归一化方式'}
{'arxiv_id': 'arXiv:2505.18230', 'title': 'Follow the Energy, Find the Path: Riemannian Metrics from Energy-Based Models', 'authors': 'Louis Béthune, David Vigouroux, Yilun Du, Rufin VanRullen, Thomas Serre, Victor Boutin', 'link': 'https://arxiv.org/abs/2505.18230', 'abstract': "What is the shortest path between two data points lying in a high-dimensional space? While the answer is trivial in Euclidean geometry, it becomes significantly more complex when the data lies on a curved manifold -- requiring a Riemannian metric to describe the space's local curvature. Estimating such a metric, however, remains a major challenge in high dimensions.\nIn this work, we propose a method for deriving Riemannian metrics directly from pretrained Energy-Based Models (EBMs) -- a class of generative models that assign low energy to high-density regions. These metrics define spatially varying distances, enabling the computation of geodesics -- shortest paths that follow the data manifold's intrinsic geometry. We introduce two novel metrics derived from EBMs and show that they produce geodesics that remain closer to the data manifold and exhibit lower curvature distortion, as measured by alignment with ground-truth trajectories. We evaluate our approach on increasingly complex datasets: synthetic datasets with known data density, rotated character images with interpretable geometry, and high-resolution natural images embedded in a pretrained VAE latent space.\nOur results show that EBM-derived metrics consistently outperform established baselines, especially in high-dimensional settings. Our work is the first to derive Riemannian metrics from EBMs, enabling data-aware geodesics and unlocking scalable, geometry-driven learning for generative modeling and simulation.", 'abstract_zh': '高维空问中两个数据点之间的最短路径是什么？在欧几里得几何中，这个问题的答案无疑是直接的，但当数据位于一个弯曲流形上时，问题变得复杂得多——需要使用黎曼度量来描述空间的局部曲率。然而，在高维空间中估计这样的度量仍然是一个重大挑战。\n\n在本文中，我们提出了一种直接从预训练的能量基础模型（EBMs）中推导黎曼度量的方法——这一类生成模型将低能量分配给高密度区域。这些度量定义了空间变化的距离，使我们可以计算符合数据流形内在几何结构的测地线——即最短路径。我们引入了从EBMs推导出的两个新颖度量，并展示了它们产生的测地线更接近数据流形且曲率失真较低，通过与真实轨迹的对齐度进行测量。我们使用从简单到复杂的数据集对其方法进行了评估：已知数据密度的合成数据集、具有可解释几何结构的旋转字符图像，以及嵌入在预训练VAE潜在空间中的高分辨率自然图像。\n\n我们的结果表明，从EBMs推导出的度量在高维设置中始终优于现有的基准方法。我们的工作是首次从EBMs中推导出黎曼度量，实现了数据感知的测地线，并为生成建模和模拟开启了基于几何的学习和可扩展性。', 'title_zh': '顺着能量找路径：来自能量模型的黎曼度量'}
{'arxiv_id': 'arXiv:2505.18229', 'title': 'BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs', 'authors': 'Mingning Guo, Mengwei Wu, Jiarun He, Shaoxian Li, Haifeng Li, Chao Tao', 'link': 'https://arxiv.org/abs/2505.18229', 'abstract': 'With the rapid advancement of low-altitude remote sensing and Vision-Language Models (VLMs), Embodied Agents based on Unmanned Aerial Vehicles (UAVs) have shown significant potential in autonomous tasks. However, current evaluation methods for UAV-Embodied Agents (UAV-EAs) remain constrained by the lack of standardized benchmarks, diverse testing scenarios and open system interfaces. To address these challenges, we propose BEDI (Benchmark for Embodied Drone Intelligence), a systematic and standardized benchmark designed for evaluating UAV-EAs. Specifically, we introduce a novel Dynamic Chain-of-Embodied-Task paradigm based on the perception-decision-action loop, which decomposes complex UAV tasks into standardized, measurable subtasks. Building on this paradigm, we design a unified evaluation framework encompassing five core sub-skills: semantic perception, spatial perception, motion control, tool utilization, and task planning. Furthermore, we construct a hybrid testing platform that integrates static real-world environments with dynamic virtual scenarios, enabling comprehensive performance assessment of UAV-EAs across varied contexts. The platform also offers open and standardized interfaces, allowing researchers to customize tasks and extend scenarios, thereby enhancing flexibility and scalability in the evaluation process. Finally, through empirical evaluations of several state-of-the-art (SOTA) VLMs, we reveal their limitations in embodied UAV tasks, underscoring the critical role of the BEDI benchmark in advancing embodied intelligence research and model optimization. By filling the gap in systematic and standardized evaluation within this field, BEDI facilitates objective model comparison and lays a robust foundation for future development in this field. Our benchmark will be released at this https URL .', 'abstract_zh': '基于无人机的嵌体智能评估基准BEDI', 'title_zh': 'BEDI：评估无人机上具身代理的综合性基准'}
{'arxiv_id': 'arXiv:2505.18227', 'title': 'Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality', 'authors': 'Zhenglun Kong, Yize Li, Fanhu Zeng, Lei Xin, Shvat Messica, Xue Lin, Pu Zhao, Manolis Kellis, Hao Tang, Marinka Zitnik', 'link': 'https://arxiv.org/abs/2505.18227', 'abstract': 'In Transformer architectures, tokens\\textemdash discrete units derived from raw data\\textemdash are formed by segmenting inputs into fixed-length chunks. Each token is then mapped to an embedding, enabling parallel attention computations while preserving the input\'s essential information. Due to the quadratic computational complexity of transformer self-attention mechanisms, token reduction has primarily been used as an efficiency strategy. This is especially true in single vision and language domains, where it helps balance computational costs, memory usage, and inference latency. Despite these advances, this paper argues that token reduction should transcend its traditional efficiency-oriented role in the era of large generative models. Instead, we position it as a fundamental principle in generative modeling, critically influencing both model architecture and broader applications. Specifically, we contend that across vision, language, and multimodal systems, token reduction can: (i) facilitate deeper multimodal integration and alignment, (ii) mitigate "overthinking" and hallucinations, (iii) maintain coherence over long inputs, and (iv) enhance training stability, etc. We reframe token reduction as more than an efficiency measure. By doing so, we outline promising future directions, including algorithm design, reinforcement learning-guided token reduction, token optimization for in-context learning, and broader ML and scientific domains. We highlight its potential to drive new model architectures and learning strategies that improve robustness, increase interpretability, and better align with the objectives of generative modeling.', 'abstract_zh': '在 transformer 架构中，通过将输入分割为固定长度片段形成的令牌（离散的源自原始数据的基本单元）映射到嵌入，使得能够并行进行注意力计算并保留输入的关键信息。由于变压器自注意力机制的二次计算复杂性，令牌减少主要被用作一种效率策略，特别是在单视图和语言领域，它有助于平衡计算成本、内存使用和推理延迟。尽管取得了这些进展，本文认为在大型生成模型时代，令牌减少不应仅仅局限于传统的效率导向角色。相反，我们应该将其定位为生成建模的基本原则，对模型架构和更广泛的应用产生关键影响。具体而言，我们认为在视觉、语言和多模态系统中，令牌减少可以：（i）促进更深的多模态整合和对齐，（ii）减轻“过度思考”和幻觉现象，（iii）保持长输入的一致性，以及（iv）增强训练稳定性等。我们将重新定义令牌减少，而不仅仅是作为一种效率度量。通过这样做，我们指出了未来研究的前景，包括算法设计、基于强化学习的令牌减少、适用于上下文学习的令牌优化以及更广泛的机器学习和科学领域。我们强调了其在推动新的模型架构和学习策略方面的潜力，这些策略将提高鲁棒性、增强可解释性，并更好地与生成建模的目标相一致。', 'title_zh': 'Token Reduction 应超越效率在生成模型中的应用——从视觉、语言到多模态'}
{'arxiv_id': 'arXiv:2505.18223', 'title': 'IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis', 'authors': 'Hanyu Li, Haoyu Liu, Tingyu Zhu, Tianyu Guo, Zeyu Zheng, Xiaotie Deng, Michael I. Jordan', 'link': 'https://arxiv.org/abs/2505.18223', 'abstract': "Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with deeper insights of the dataset. To address this, we introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round interactive scenarios. Derived from complex Kaggle notebooks, tasks are presented as sequential natural language instructions by an LLM-simulated user. Agent performance is judged by comparing its final numerical output to the human-derived baseline. Initial results show that even state-of-the-art coding agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting limitations not evident in single-turn tests. This work underscores the need to improve LLMs' multi-round capabilities for building more reliable data analysis agents, highlighting the necessity of achieving a balance between instruction following and reasoning.", 'abstract_zh': '大语言模型（LLMs）作为数据分析代理展现出潜力，但现有基准测试忽略了该领域逐步深入分析数据集过程中专家决策的迭代性。为解决这一问题，我们引入了IDA-Bench，这是一个评估LLM代理在多轮交互场景中的新型基准测试。任务来源于复杂的Kaggle笔记本，并由LLM模拟用户以顺序自然语言指令的形式呈现。代理的表现通过将其最终的数值输出与人类基准进行比较来评判。初步结果显示，即使是最先进的编码代理（如Claude-3.7-thinking）也仅能在不到50%的任务上成功，突显了单轮测试中未显现的局限性。本研究强调了提升LLMs多轮能力的重要性，以构建更可靠的数据分析代理，并强调了指令跟随与推理之间需要取得平衡。', 'title_zh': 'IDA-Bench: 评估交互引导数据分析中的大规模语言模型'}
{'arxiv_id': 'arXiv:2505.18222', 'title': 'A Domain Ontology for Modeling the Book of Purification in Islam', 'authors': 'Hessa Alawwad', 'link': 'https://arxiv.org/abs/2505.18222', 'abstract': 'This paper aims to address a gap in major Islamic topics by developing an ontology for the Book of Purification in Islam. Many authoritative Islamic texts begin with the Book of Purification, as it is essential for performing prayer (the second pillar of Islam after Shahadah, the profession of faith) and other religious duties such as Umrah and Hajj.\nThe ontology development strategy followed six key steps: (1) domain identification, (2) knowledge acquisition, (3) conceptualization, (4) classification, (5) integration and implementation, and (6) ontology generation. This paper includes examples of the constructed tables and classifications.\nThe focus is on the design and analysis phases, as technical implementation is beyond the scope of this study. However, an initial implementation is provided to illustrate the steps of the proposed strategy.\nThe developed ontology ensures reusability by formally defining and encoding the key concepts, attributes, and relationships related to the Book of Purification. This structured representation is intended to support knowledge sharing and reuse.', 'abstract_zh': '本文旨在通过为《 purification 经》开发本体来填补伊斯兰主要主题中的研究空白。许多权威的伊斯兰文本都以《 purification 经》开头，因为它对于礼拜（伊斯兰的第二个支柱，其次是认主独 Almighty ）以及其他宗教职责如朝觐和小朝觐是必不可少的。\n\n本体开发策略遵循了六个关键步骤：（1）领域识别，（2）知识获取，（3）概念化，（4）分类，（5）集成与实施，以及（6）本体生成。本文包括所构建的表格和分类的示例。\n\n重点在于设计和分析阶段，因为技术实现超出了本研究的范围。然而，提供了一个初始实现来说明所提议策略的步骤。\n\n开发的本体通过正式定义和编码与《 purification 经》相关的关键概念、属性和关系确保了可重用性。这种结构化表示旨在支持知识的共享和重用。', 'title_zh': '清真寺书籍的领域本体建模'}
{'arxiv_id': 'arXiv:2505.18221', 'title': 'Evidence-Grounded Multimodal Misinformation Detection with Attention-Based GNNs', 'authors': 'Sharad Duwal, Mir Nafis Sharear Shopnil, Abhishek Tyagi, Adiba Mahbub Proma', 'link': 'https://arxiv.org/abs/2505.18221', 'abstract': 'Multimodal out-of-context (OOC) misinformation is misinformation that repurposes real images with unrelated or misleading captions. Detecting such misinformation is challenging because it requires resolving the context of the claim before checking for misinformation. Many current methods, including LLMs and LVLMs, do not perform this contextualization step. LLMs hallucinate in absence of context or parametric knowledge. In this work, we propose a graph-based method that evaluates the consistency between the image and the caption by constructing two graph representations: an evidence graph, derived from online textual evidence, and a claim graph, from the claim in the caption. Using graph neural networks (GNNs) to encode and compare these representations, our framework then evaluates the truthfulness of image-caption pairs. We create datasets for our graph-based method, evaluate and compare our baseline model against popular LLMs on the misinformation detection task. Our method scores $93.05\\%$ detection accuracy on the evaluation set and outperforms the second-best performing method (an LLM) by $2.82\\%$, making a case for smaller and task-specific methods.', 'abstract_zh': '多模态脱靶虚假信息是指将实际图片与不相关或误导性的 caption 重新利用的情况。检测这种虚假信息具有挑战性，因为它要求在验证虚假信息之前解决声明的上下文。当前许多方法，包括大语言模型（LLMs）和大型视觉语言模型（LVLMs），未执行这一上下文化步骤。大语言模型在缺乏上下文或参数知识的情况下会编造信息。在本文中，我们提出了一种基于图的方法，通过构建两种图表示：来源于在线文本证据的证据图和来源于 caption 中声明的声明图，来评估图片和 caption 之间的一致性。利用图神经网络（GNNs）对这些表示进行编码和比较，我们的框架随后评估图像- caption 对的真实性。我们为基于图的方法创建了数据集，并在虚假信息检测任务上将基线模型与流行的 LLMs 进行评估和比较。我们的方法在验证集上的检测准确率为 93.05%，比第二优方法（一种大语言模型）高出 2.82%，证明了更小且针对特定任务的方法的有效性。', 'title_zh': '基于证据的多模态虚假信息检测：注意力机制下的图神经网络'}
{'arxiv_id': 'arXiv:2505.18220', 'title': 'Navigating Pitfalls: Evaluating LLMs in Machine Learning Programming Education', 'authors': 'Smitha Kumar, Michael A. Lones, Manuel Maarek, Hind Zantout', 'link': 'https://arxiv.org/abs/2505.18220', 'abstract': 'The rapid advancement of Large Language Models (LLMs) has opened new avenues in education. This study examines the use of LLMs in supporting learning in machine learning education; in particular, it focuses on the ability of LLMs to identify common errors of practice (pitfalls) in machine learning code, and their ability to provide feedback that can guide learning. Using a portfolio of code samples, we consider four different LLMs: one closed model and three open models. Whilst the most basic pitfalls are readily identified by all models, many common pitfalls are not. They particularly struggle to identify pitfalls in the early stages of the ML pipeline, especially those which can lead to information leaks, a major source of failure within applied ML projects. They also exhibit limited success at identifying pitfalls around model selection, which is a concept that students often struggle with when first transitioning from theory to practice. This questions the use of current LLMs to support machine learning education, and also raises important questions about their use by novice practitioners. Nevertheless, when LLMs successfully identify pitfalls in code, they do provide feedback that includes advice on how to proceed, emphasising their potential role in guiding learners. We also compare the capability of closed and open LLM models, and find that the gap is relatively small given the large difference in model sizes. This presents an opportunity to deploy, and potentially customise, smaller more efficient LLM models within education, avoiding risks around cost and data sharing associated with commercial models.', 'abstract_zh': '大型语言模型在机器学习教育中的应用：识别代码中的常见错误及其反馈能力研究', 'title_zh': '导航陷阱：评估大规模语言模型在机器学习编程教育中的作用'}
{'arxiv_id': 'arXiv:2505.18218', 'title': 'CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games', 'authors': 'Shuhang Xu, Fangwei Zhong', 'link': 'https://arxiv.org/abs/2505.18218', 'abstract': "Metaphors are a crucial way for humans to express complex or subtle ideas by comparing one concept to another, often from a different domain. However, many large language models (LLMs) struggle to interpret and apply metaphors in multi-agent language games, hindering their ability to engage in covert communication and semantic evasion, which are crucial for strategic communication. To address this challenge, we introduce CoMet, a framework that enables LLM-based agents to engage in metaphor processing. CoMet combines a hypothesis-based metaphor reasoner with a metaphor generator that improves through self-reflection and knowledge integration. This enhances the agents' ability to interpret and apply metaphors, improving the strategic and nuanced quality of their interactions. We evaluate CoMet on two multi-agent language games - Undercover and Adversarial Taboo - which emphasize Covert Communication and Semantic Evasion. Experimental results demonstrate that CoMet significantly enhances the agents' ability to communicate strategically using metaphors.", 'abstract_zh': '比喻是人类表达复杂或微妙想法的重要方式，通过将一个概念与另一个概念相比较，通常来自不同的领域。然而，许多大型语言模型（LLMs）在多智能体语言游戏中难以解释和应用比喻，这阻碍了它们进行隐蔽沟通和语义规避的能力，这是战略性沟通的关键。为了解决这一挑战，我们引入了CoMet框架，使基于LLM的智能体能够参与比喻处理。CoMet结合了基于假设的比喻推理器和一个通过自我反思和知识整合而改进的比喻生成器。这增强了智能体解释和应用比喻的能力，提高了它们互动的战略性和细致程度。我们分别在两个多智能体语言游戏中评估了CoMet——Undercover和Adversarial Taboo，这两个游戏强调隐蔽沟通和语义规避。实验结果表明，CoMet显著增强了智能体使用比喻进行战略性沟通的能力。', 'title_zh': 'CoMet: 以隐喻驱动的多代理语言游戏隐蔽通信'}
{'arxiv_id': 'arXiv:2505.18217', 'title': 'ABHINAYA -- A System for Speech Emotion Recognition In Naturalistic Conditions Challenge', 'authors': 'Soumya Dutta, Smruthi Balaji, Varada R, Viveka Salinamakki, Sriram Ganapathy', 'link': 'https://arxiv.org/abs/2505.18217', 'abstract': 'Speech emotion recognition (SER) in naturalistic settings remains a challenge due to the intrinsic variability, diverse recording conditions, and class imbalance. As participants in the Interspeech Naturalistic SER Challenge which focused on these complexities, we present Abhinaya, a system integrating speech-based, text-based, and speech-text models. Our approach fine-tunes self-supervised and speech large language models (SLLM) for speech representations, leverages large language models (LLM) for textual context, and employs speech-text modeling with an SLLM to capture nuanced emotional cues. To combat class imbalance, we apply tailored loss functions and generate categorical decisions through majority voting. Despite one model not being fully trained, the Abhinaya system ranked 4th among 166 submissions. Upon completion of training, it achieved state-of-the-art performance among published results, demonstrating the effectiveness of our approach for SER in real-world conditions.', 'abstract_zh': '自然环境中语音情绪识别（SER）仍然面临挑战，由于固有的变异性、多样的录音条件以及类别不平衡。作为专注于这些复杂性的Interspeech自然环境SER挑战赛的参与者，我们呈现了Abhinaya系统，该系统结合了基于语音、基于文本和语音文本模型。我们的方法针对语音表示微调自监督和语音大型语言模型（SLLM），利用大型语言模型（LLM）获取文本上下文，并采用SLLM进行语音文本建模以捕捉细微的情绪线索。为应对类别不平衡问题，我们应用了定制的损失函数并通过多数投票生成分类决策。尽管一个模型未完全训练，Abhinaya系统在166项提交中排名第四。在完成训练后，其性能达到了已发表结果中的最先进水平，展示了我们在实际条件下进行SER的有效方法。', 'title_zh': 'ABHINAYA -- 一种在自然条件下进行语音情感识别的系统挑战'}
{'arxiv_id': 'arXiv:2505.18216', 'title': 'Data Mining-Based Techniques for Software Fault Localization', 'authors': 'Peggy Cellier, Mireille Ducassé, Sébastien Ferré, Olivier Ridoux, W. Eric Wong', 'link': 'https://arxiv.org/abs/2505.18216', 'abstract': 'This chapter illustrates the basic concepts of fault localization using a data mining technique. It utilizes the Trityp program to illustrate the general method. Formal concept analysis and association rule are two well-known methods for symbolic data mining. In their original inception, they both consider data in the form of an object-attribute table. In their original inception, they both consider data in the form of an object-attribute table. The chapter considers a debugging process in which a program is tested against different test cases. Two attributes, PASS and FAIL, represent the issue of the test case. The chapter extends the analysis of data mining for fault localization for the multiple fault situations. It addresses how data mining can be further applied to fault localization for GUI components. Unlike traditional software, GUI test cases are usually event sequences, and each individual event has a unique corresponding event handler.', 'abstract_zh': '本章使用数据挖掘技术阐述故障定位的基本概念，并通过Trityp程序示例说明一般方法。形式概念分析和关联规则是两种著名的符号数据挖掘方法，在最初的概念中，它们都考虑数据以对象-属性表的形式存在。本章考虑了一个软件测试过程，该过程在不同的测试案例下测试程序。PASS和FAIL两个属性代表测试案例的问题。本章扩展了对故障定位的数据挖掘分析，以应对多故障情况，并探讨数据挖掘如何进一步应用于GUI组件的故障定位。与传统软件不同，GUI测试案例通常是一系列事件序列，每个单独的事件都有一个独特的相应事件处理程序。', 'title_zh': '基于数据挖掘的软件故障定位技术'}
{'arxiv_id': 'arXiv:2505.18215', 'title': 'Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?', 'authors': 'Junyan Zhang, Yiming Huang, Shuliang Liu, Yubo Gao, Xuming Hu', 'link': 'https://arxiv.org/abs/2505.18215', 'abstract': 'The rapid adoption of LLMs has overshadowed the potential advantages of traditional BERT-like models in text classification. This study challenges the prevailing "LLM-centric" trend by systematically comparing three category methods, i.e., BERT-like models fine-tuning, LLM internal state utilization, and zero-shot inference across six high-difficulty datasets. Our findings reveal that BERT-like models often outperform LLMs. We further categorize datasets into three types, perform PCA and probing experiments, and identify task-specific model strengths: BERT-like models excel in pattern-driven tasks, while LLMs dominate those requiring deep semantics or world knowledge. Based on this, we propose TaMAS, a fine-grained task selection strategy, advocating for a nuanced, task-driven approach over a one-size-fits-all reliance on LLMs.', 'abstract_zh': 'LLM迅猛 adoption has overshadowed potential advantages of traditional BERT-like models in text classification: A systematic comparison across six high-difficulty datasets', 'title_zh': 'BERT-like双方向模型在大规模语言模型时代的文本分类任务中仍表现更优吗？'}
{'arxiv_id': 'arXiv:2505.18214', 'title': 'LA-RCS: LLM-Agent-Based Robot Control System', 'authors': 'TaekHyun Park, YoungJun Choi, SeungHoon Shin, Kwangil Lee', 'link': 'https://arxiv.org/abs/2505.18214', 'abstract': 'LA-RCS (LLM-agent-based robot control system) is a sophisticated robot control system designed to autonomously plan, work, and analyze the external environment based on user requirements by utilizing LLM-Agent. Utilizing a dual-agent framework, LA-RCS generates plans based on user requests, observes the external environment, executes the plans, and modifies the plans as needed to adapt to changes in the external conditions. Additionally, LA-RCS interprets natural language commands by the user and converts them into commands compatible with the robot interface so that the robot can execute tasks and meet user requests properly. During his process, the system autonomously evaluates observation results, provides feedback on the tasks, and executes commands based on real-time environmental monitoring, significantly reducing the need for user intervention in fulfilling requests. We categorized the scenarios that LA-RCS needs to perform into four distinct types and conducted a quantitative assessment of its performance in each scenario. The results showed an average success rate of 90 percent, demonstrating the system capability to fulfill user requests satisfactorily. For more extensive results, readers can visit our project page: this https URL', 'abstract_zh': '基于LLM-Agent的LA-RCS自主机器人控制系统', 'title_zh': 'LLM-Agent-Based机器人控制系统'}
{'arxiv_id': 'arXiv:2505.18213', 'title': 'AIDRIN 2.0: A Framework to Assess Data Readiness for AI', 'authors': 'Kaveen Hiniduma, Dylan Ryan, Suren Byna, Jean Luca Bez, Ravi Madduri', 'link': 'https://arxiv.org/abs/2505.18213', 'abstract': "AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.", 'abstract_zh': 'AI数据准备性检查器(AIDRIN)框架：通过用户界面改进和隐私保护联邦学习框架集成提升AI应用数据准备性', 'title_zh': 'AIDRIN 2.0: 评估数据就绪度以供AI使用的方法框架'}
{'arxiv_id': 'arXiv:2505.18212', 'title': 'Towards medical AI misalignment: a preliminary study', 'authors': 'Barbara Puccio, Federico Castagna, Allan Tucker, Pierangelo Veltri', 'link': 'https://arxiv.org/abs/2505.18212', 'abstract': "Despite their staggering capabilities as assistant tools, often exceeding human performances, Large Language Models (LLMs) are still prone to jailbreak attempts from malevolent users. Although red teaming practices have already identified and helped to address several such jailbreak techniques, one particular sturdy approach involving role-playing (which we named `Goofy Game') seems effective against most of the current LLMs safeguards. This can result in the provision of unsafe content, which, although not harmful per se, might lead to dangerous consequences if delivered in a setting such as the medical domain. In this preliminary and exploratory study, we provide an initial analysis of how, even without technical knowledge of the internal architecture and parameters of generative AI models, a malicious user could construct a role-playing prompt capable of coercing an LLM into producing incorrect (and potentially harmful) clinical suggestions. We aim to illustrate a specific vulnerability scenario, providing insights that can support future advancements in the field.", 'abstract_zh': '尽管大型语言模型（LLMs）作为辅助工具展现出惊人的能力，甚至常常超越人类表现，但它们仍然容易受到恶意用户发起的“牢笼突破”攻击。尽管红队已识别并帮助应对了多种“牢笼突破”技术，一种名为“Goofy Game”的特定角色扮演方法似乎对当前大多数LLMs的安全防护措施都有效。这可能导致提供不安全的内容，虽然本身不一定有害，但在如医疗领域这样的环境中，可能会导致危险的后果。在本初步和探索性研究中，我们提供了一个初步分析，即使没有生成式AI模型内部架构和技术参数的知识，恶意用户如何构造一个角色扮演提示，以此迫使LLM生成错误（并可能有害）的临床建议。我们的目的是阐述一个特定的安全漏洞场景，为未来该领域的研究提供见解。', 'title_zh': '向医疗AI不对齐进发：一项初步研究'}
{'arxiv_id': 'arXiv:2505.18200', 'title': 'CrossRF: A Domain-Invariant Deep Learning Approach for RF Fingerprinting', 'authors': 'Fahrettin Emin Tiras, Hayriye Serra Altinoluk', 'link': 'https://arxiv.org/abs/2505.18200', 'abstract': "Radio Frequency (RF) fingerprinting offers a promising approach for drone identification and security, although it suffers from significant performance degradation when operating on different transmission channels. This paper presents CrossRF, a domain-invariant deep learning approach that addresses the problem of cross-channel RF fingerprinting for Unmanned Aerial Vehicle (UAV) identification. Our approach aims to minimize the domain gap between different RF channels by using adversarial learning to train a more robust model that maintains consistent identification performance despite channel variations. We validate our approach using the UAVSig dataset, comprising real-world over-the-air RF signals from identical drone models operating across several frequency channels, ensuring that the findings correspond to real-world scenarios. The experimental results show CrossRF's efficiency, achieving up to 99.03% accuracy when adapting from Channel 3 to Channel 4, compared to only 26.39% using conventional methods. The model maintains robust performance in more difficult multi-channel scenarios (87.57% accuracy adapting from Channels 1,3 to 2,4) and achieves 89.45% accuracy with 0.9 precision for controller classification. These results confirm CrossRF's ability to significantly reduce performance degradation due to cross-channel variations while maintaining high identification accuracy with minimal training data requirements, making it particularly suitable for practical drone security applications.", 'abstract_zh': 'CrossRF：一种针对无人机跨频道RF指纹识别的领域不变深度学习方法', 'title_zh': 'CrossRF：一种用于RF指纹识别的领域不变深度学习方法'}
{'arxiv_id': 'arXiv:2505.18194', 'title': 'Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications', 'authors': 'Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang', 'link': 'https://arxiv.org/abs/2505.18194', 'abstract': 'Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their effectiveness in urban or non-line-of-sight scenarios. To overcome these challenges, we propose a novel large language model (LLM)-driven distributed integrated multimodal sensing and semantic communication (LLM-DiSAC) framework. Specifically, our system consists of multiple collaborative sensing devices equipped with RF and camera modules, working together with an aggregation center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC develops an RF-vision fusion network (RVFN), which employs specialized feature extractors for RF and visual data, followed by a cross-attention module for effective multimodal integration. Second, a LLM-based semantic transmission network (LSTN) is proposed to enhance communication efficiency, where the LLM-based decoder leverages known channel parameters, such as transceiver distance and signal-to-noise ratio (SNR), to mitigate semantic distortion. Third, at the aggregation center, a transformer-based aggregation model (TRAM) with an adaptive aggregation attention mechanism is developed to fuse distributed features and enhance sensing accuracy. To preserve data privacy, a two-stage distributed learning strategy is introduced, allowing local model training at the device level and centralized aggregation model training using intermediate features. Finally, evaluations on a synthetic multi-view RF-visual dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves a good performance.', 'abstract_zh': '基于大型语言模型驱动的分布式集成多模态传感与语义通信框架（LLM-DiSAC）', 'title_zh': '大型语言模型驱动的分布式集成多模态传感与语义通信'}
{'arxiv_id': 'arXiv:2505.18191', 'title': 'SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference', 'authors': 'Jonathan Dan, Amirhossein Shahbazinia, Christodoulos Kechris, David Atienza', 'link': 'https://arxiv.org/abs/2505.18191', 'abstract': 'Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigorously assess algorithm performance, we organized a challenge using a private dataset of continuous EEG recordings from 65 subjects (4,360 hours). Expert neurophysiologists annotated the data, providing ground truth for seizure events. Participants were required to detect seizure onset and duration, with evaluation based on event-based metrics, including sensitivity, precision, F1-score, and false positives per day. The SzCORE framework ensured standardized evaluation. The primary ranking criterion was the event-based F1-score, reflecting clinical relevance by balancing sensitivity and false positives. The challenge received 30 submissions from 19 teams, with 28 algorithms evaluated. Results revealed wide variability in performance, with a top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing difficulty of seizure detection. The challenge also revealed a gap between reported performance and real-world evaluation, emphasizing the importance of rigorous benchmarking. Compared to previous challenges and commercial systems, the best-performing algorithm in this contest showed improved performance. Importantly, the challenge platform now supports continuous benchmarking, enabling reproducible research, integration of new datasets, and clinical evaluation of seizure detection algorithms using a standardized framework.', 'abstract_zh': '可靠地从长时间EEG中自动检测癫痫发作仍然是一个挑战，当前的机器学习模型往往无法在不同患者或临床环境中泛化。手动EEG审查仍是临床标准，强调了需要稳健的模型和标准化评估的重要性。为了严格评估算法性能，我们使用包含65名受试者（4,360小时）连续EEG记录的私有数据集组织了一项挑战。专家神经生理学家对数据进行了标注，提供了癫痫发作事件的ground truth。参与者需检测癫痫发作起始和持续时间，评估基于事件指标，包括灵敏度、精确度、F1分数和每日误报数。SzCORE框架确保了标准化评估。首要的排名标准是事件相关的F1分数，反映了临床相关性，平衡了灵敏度和误报。本次挑战收到了19支队伍的30份提交，共评估了28个算法。结果表明，性能存在显著差异，最高F1分数为43%（灵敏度37%，精确度45%），突显了癫痫发作检测的持续难度。挑战还揭示了报告性能与实际评估之间的差距，强调了严格基准测试的重要性。与以往挑战和商用系统相比，本次比赛表现最好的算法显示出改进的性能。重要的是，挑战平台现在支持持续基准测试，促进了可重复研究，整合新数据集，并使用标准化框架评估癫痫发作检测算法的临床性能。', 'title_zh': 'SzCORE作为基准：2025年AI在癫痫和神经疾病会议上关于癫痫检测挑战的报告'}
{'arxiv_id': 'arXiv:2505.18190', 'title': 'PhySense: Sensor Placement Optimization for Accurate Physics Sensing', 'authors': 'Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long', 'link': 'https://arxiv.org/abs/2505.18190', 'abstract': 'Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. \\correct{Leveraging the reconstruction feedback, }the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. \\correct{We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees.} Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered.', 'abstract_zh': 'Physics Sensing via Synergistic Two-Stage Framework for Joint Reconstruction and Optimal Sensor Placement', 'title_zh': 'PhySense: 物理传感的传感器放置优化'}
{'arxiv_id': 'arXiv:2505.18188', 'title': 'Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization', 'authors': 'Beck LaBash, Shahriar Khushrushahi, Fabian Ruehle', 'link': 'https://arxiv.org/abs/2505.18188', 'abstract': 'We propose a two-stage deep learning framework for the inverse design of rectangular patch antennas. Our approach leverages generative modeling to learn a latent representation of antenna frequency response curves and conditions a subsequent generative model on these responses to produce feasible antenna geometries. We further demonstrate that leveraging search and optimization techniques at test-time improves the accuracy of the generated designs and enables consideration of auxiliary objectives such as manufacturability. Our approach generalizes naturally to different design criteria, and can be easily adapted to more complex geometric design spaces.', 'abstract_zh': '我们提出了一种两阶段深度学习框架用于矩形(patch)贴片天线的逆向设计。该方法利用生成模型学习天线频率响应曲线的潜在表示，并在这些响应的基础上条件化后续的生成模型以生成可行的天线几何结构。此外，我们在测试时利用搜索和优化技术可以提高生成设计的准确性，同时考虑制备性等辅助目标。该方法自然地适用于不同的设计标准，并且可以轻松适应更复杂的几何设计空间。', 'title_zh': '基于测试时优化的矩形补片天线生成逆向设计改进'}
{'arxiv_id': 'arXiv:2505.18181', 'title': '2DNMRGym: An Annotated Experimental Dataset for Atom-Level Molecular Representation Learning in 2D NMR via Surrogate Supervision', 'authors': 'Yunrui Li, Hao Xu, Pengyu Hong', 'link': 'https://arxiv.org/abs/2505.18181', 'abstract': "Two-dimensional (2D) Nuclear Magnetic Resonance (NMR) spectroscopy, particularly Heteronuclear Single Quantum Coherence (HSQC) spectroscopy, plays a critical role in elucidating molecular structures, interactions, and electronic properties. However, accurately interpreting 2D NMR data remains labor-intensive and error-prone, requiring highly trained domain experts, especially for complex molecules. Machine Learning (ML) holds significant potential in 2D NMR analysis by learning molecular representations and recognizing complex patterns from data. However, progress has been limited by the lack of large-scale and high-quality annotated datasets. In this work, we introduce 2DNMRGym, the first annotated experimental dataset designed for ML-based molecular representation learning in 2D NMR. It includes over 22,000 HSQC spectra, along with the corresponding molecular graphs and SMILES strings. Uniquely, 2DNMRGym adopts a surrogate supervision setup: models are trained using algorithm-generated annotations derived from a previously validated method and evaluated on a held-out set of human-annotated gold-standard labels. This enables rigorous assessment of a model's ability to generalize from imperfect supervision to expert-level interpretation. We provide benchmark results using a series of 2D and 3D GNN and GNN transformer models, establishing a strong foundation for future work. 2DNMRGym supports scalable model training and introduces a chemically meaningful benchmark for evaluating atom-level molecular representations in NMR-guided structural tasks. Our data and code is open-source and available on Huggingface and Github.", 'abstract_zh': '两维（2D）核磁共振（NMR）光谱，特别是异核单量子相干（HSQC）光谱，在阐明分子结构、相互作用和电子性质方面起到关键作用。然而，准确解读2D NMR数据依然劳动密集且容易出错，需要高度训练的专业专家，尤其是对复杂分子而言。机器学习（ML）在通过学习分子表示和从数据中识别复杂模式方面为2D NMR分析提供了巨大潜力。然而，进展受限于缺乏大规模和高质量的注释数据集。本文介绍2DNMRGym，这是第一个为基于机器学习的分子表示学习设计的2D NMR注释实验数据集，包含了超过22,000张HSQC谱图，以及相应的分子图和SMILES字符串。2DNMRGym采用代用监督设置：模型使用算法生成的注释进行训练，这些注释源自之前验证的方法，并在保留了人工注释权威标准标签的一组数据上进行评估。这使得可以严格评估模型从不完美的监督到专家级解释的能力。我们使用一系列2D和3D图神经网络及图神经网络变换模型提供了基准结果，为未来工作奠定了坚实基础。2DNMRGym支持可扩展的模型训练，并引入了基于NMR导向结构任务的具有化学意义的基准，用于评估原子级分子表示。我们的数据和代码是开源的，可在Huggingface和Github上获取。', 'title_zh': '2DNMRGym：一种用于二维核磁共振中原子级分子表示学习的标注实验数据集及其代理监督方法'}
{'arxiv_id': 'arXiv:2505.18179', 'title': 'GAIA: A Foundation Model for Operational Atmospheric Dynamics', 'authors': 'Ata Akbari Asanjan, Olivia Alexander, Tom Berg, Clara Zhang, Matt Yang, Jad Makki, Disha Shidham, Srija Chakraborty, William Bender, Stephen Peng, Arun Ravindran, Olivier Raiman, David Potere, David Bell', 'link': 'https://arxiv.org/abs/2505.18179', 'abstract': 'We present the GAIA (Geospatial Artificial Intelligence for Atmospheres) Foundation Model, a novel model that combines masked autoencoders (MAE) and self-DIstillation with NO labels (DINO) for analyzing global atmospheric patterns in satellite imagery. By integrating these complementary self-supervised learning approaches, our model simultaneously captures both local features and global dependencies. We address two critical challenges in satellite data analysis: reconstructing missing regions and estimating precipitation patterns as our first downstream tasks. The model demonstrates superior temporal pattern capture compared to standard MAE approaches, while maintaining robust performance in downstream tasks. Our experimental results show strong gap-filling capabilities across varying mask ratios and accurate precipitation estimation with limited training data, achieving a false alarm ratio of 0.088 and structural similarity of 0.881. This work represents an advancement in self-supervised learning for atmospheric science, providing a foundation for improved weather monitoring and climate analysis. The trained model weights and accompanying code are publicly available as open-source on Hugging Face here: this https URL.', 'abstract_zh': '我们提出了一种新颖的Geospatial Artificial Intelligence for Atmospheres (GAIA) 基础模型，该模型结合了掩码自动编码器（MAE）和未标记自蒸馏（DINO）方法，用于分析卫星图像中的全球大气模式。通过整合这些互补的自监督学习方法，我们的模型能够同时捕捉局部特征和全局依赖关系。我们解决了卫星数据分析中的两个关键挑战：重构缺失区域和估算降水模式，作为我们首先的下游任务。与标准的MAE方法相比，该模型在时间序列模式捕捉方面表现出色，同时在下游任务中保持了稳健的性能。实验结果表明，在不同掩码比率下具有较强的插补能力，并且在有限训练数据的情况下实现了准确的降水估计，假警报率为0.088，结构相似度为0.881。这项工作代表了大气科学中自监督学习的进步，为改进天气监测和气候分析提供了基础。经过训练的模型权重和配套代码在Hugging Face上公开：this https URL。', 'title_zh': 'GAIA：大气动态运行基础模型'}
{'arxiv_id': 'arXiv:2505.18178', 'title': 'Less is More: Multimodal Region Representation via Pairwise Inter-view Learning', 'authors': 'Min Namgung, Yijun Lin, JangHyeon Lee, Yao-Yi Chiang', 'link': 'https://arxiv.org/abs/2505.18178', 'abstract': 'With the increasing availability of geospatial datasets, researchers have explored region representation learning (RRL) to analyze complex region characteristics. Recent RRL methods use contrastive learning (CL) to capture shared information between two modalities but often overlook task-relevant unique information specific to each modality. Such modality-specific details can explain region characteristics that shared information alone cannot capture. Bringing information factorization to RRL can address this by factorizing multimodal data into shared and unique information. However, existing factorization approaches focus on two modalities, whereas RRL can benefit from various geospatial data. Extending factorization beyond two modalities is non-trivial because modeling high-order relationships introduces a combinatorial number of learning objectives, increasing model complexity. We introduce Cross modal Knowledge Injected Embedding, an information factorization approach for RRL that captures both shared and unique representations. CooKIE uses a pairwise inter-view learning approach that captures high-order information without modeling high-order dependency, avoiding exhaustive combinations. We evaluate CooKIE on three regression tasks and a land use classification task in New York City and Delhi, India. Results show that CooKIE outperforms existing RRL methods and a factorized RRL model, capturing multimodal information with fewer training parameters and floating-point operations per second (FLOPs). We release the code: this https URL.', 'abstract_zh': '基于跨模态知识注入嵌入的区域表示学习中的信息分解', 'title_zh': '少即是多：通过成对跨视图学习的多模态区域表示'}
{'arxiv_id': 'arXiv:2505.18177', 'title': 'FedGRec: Dynamic Spatio-Temporal Federated Graph Learning for Secure and Efficient Cross-Border Recommendations', 'authors': 'Zhizhong Tan, Jiexin Zheng, Xingxing Yang, Chi Zhang, Weiping Deng, Wenyong Wang', 'link': 'https://arxiv.org/abs/2505.18177', 'abstract': 'Due to the highly sensitive nature of certain data in cross-border sharing, collaborative cross-border recommendations and data sharing are often subject to stringent privacy protection regulations, resulting in insufficient data for model training. Consequently, achieving efficient cross-border business recommendations while ensuring privacy security poses a significant challenge. Although federated learning has demonstrated broad potential in collaborative training without exposing raw data, most existing federated learning-based GNN training methods still rely on federated averaging strategies, which perform suboptimally on highly heterogeneous graph data. To address this issue, we propose FedGRec, a privacy-preserving federated graph learning method for cross-border recommendations. FedGRec captures user preferences from distributed multi-domain data to enhance recommendation performance across all domains without privacy leakage. Specifically, FedGRec leverages collaborative signals from local subgraphs associated with users or items to enrich their representation learning. Additionally, it employs dynamic spatiotemporal modeling to integrate global and local user preferences in real time based on business recommendation states, thereby deriving the final representations of target users and candidate items. By automatically filtering relevant behaviors, FedGRec effectively mitigates noise interference from unreliable neighbors. Furthermore, through a personalized federated aggregation strategy, FedGRec adapts global preferences to heterogeneous domain data, enabling collaborative learning of user preferences across multiple domains. Extensive experiments on three datasets demonstrate that FedGRec consistently outperforms competitive single-domain and cross-domain baselines while effectively preserving data privacy in cross-border recommendations.', 'abstract_zh': '跨border推荐中的隐私保护图联邦学习方法：FedGRec', 'title_zh': 'FedGRec：基于动态时空联邦图学习的跨边境安全高效推荐'}
{'arxiv_id': 'arXiv:2505.18175', 'title': 'Evaluation in EEG Emotion Recognition: State-of-the-Art Review and Unified Framework', 'authors': 'Natia Kukhilava, Tatia Tsmindashvili, Rapael Kalandadze, Anchit Gupta, Sofio Katamadze, François Brémond, Laura M. Ferrari, Philipp Müller, Benedikt Emanuel Wirth', 'link': 'https://arxiv.org/abs/2505.18175', 'abstract': "Electroencephalography-based Emotion Recognition (EEG-ER) has become a growing research area in recent years. Analyzing 216 papers published between 2018 and 2023, we uncover that the field lacks a unified evaluation protocol, which is essential to fairly define the state of the art, compare new approaches and to track the field's progress. We report the main inconsistencies between the used evaluation protocols, which are related to ground truth definition, evaluation metric selection, data splitting types (e.g., subject-dependent or subject-independent) and the use of different datasets. Capitalizing on this state-of-the-art research, we propose a unified evaluation protocol, EEGain (this https URL), which enables an easy and efficient evaluation of new methods and datasets. EEGain is a novel open source software framework, offering the capability to compare - and thus define - state-of-the-art results. EEGain includes standardized methods for data pre-processing, data splitting, evaluation metrics, and the ability to load the six most relevant datasets (i.e., AMIGOS, DEAP, DREAMER, MAHNOB-HCI, SEED, SEED-IV) in EEG-ER with only a single line of code. In addition, we have assessed and validated EEGain using these six datasets on the four most common publicly available methods (EEGNet, DeepConvNet, ShallowConvNet, TSception). This is a significant step to make research on EEG-ER more reproducible and comparable, thereby accelerating the overall progress of the field.", 'abstract_zh': '基于脑电图的情感识别（EEG-ER）已成为近年来的研究热点。分析2018年至2023年发表的216篇论文，我们发现该领域缺乏统一的评估协议，这阻碍了对最新技术水平的公正定义、新方法的比较以及领域进展的跟踪。我们报告了使用的评估协议中主要存在的不一致性，这些不一致性涉及 ground truth 定义、评价指标选择、数据分割类型（如被试依存或被试独立）以及不同数据集的使用。在此基础上，我们提出了一种统一的评估协议——EEGain（https://github.com/EEGAI-PL/EEGain），它能够简化并提高新方法和数据集的评估效率和效果。EEGain 是一种新型开源软件框架，提供比较和定义最新技术水平的能力。该框架包括标准化的数据预处理方法、数据分割方法、评价指标方法，并且仅需一行代码即可加载 EEG-ER 中最相关的六个多模态数据集（即 AMIGOS、DEAP、DREAMER、MAHNOB-HCI、SEED、SEED-IV）。此外，我们使用这六个数据集和四种最常见的公开方法（EEGNet、DeepConvNet、ShallowConvNet、TSception）评估并验证了EEGain，这为提高 EEG-ER 研究的可重复性和可比性、加速该领域的整体进展迈出了重要一步。', 'title_zh': 'EEG情绪识别的评估：现有研究综述与统一框架'}
{'arxiv_id': 'arXiv:2505.18174', 'title': 'NMCSE: Noise-Robust Multi-Modal Coupling Signal Estimation Method via Optimal Transport for Cardiovascular Disease Detection', 'authors': 'Zhixin li, Peihong Zhang, Rui Sang, Yuxuan Liu, Shengchen Li', 'link': 'https://arxiv.org/abs/2505.18174', 'abstract': 'Electrocardiogram (ECG) and Phonocardiogram (PCG) signals are linked by a latent coupling signal representing the electrical-to-mechanical cardiac transformation. While valuable for cardiovascular disease (CVD) detection, this coupling signal is traditionally estimated using deconvolution methods that amplify noise, limiting clinical utility. In this paper, we propose Noise-Robust Multi-Modal Coupling Signal Estimation (NMCSE), which reformulates the problem as distribution matching via optimal transport theory. By jointly optimizing amplitude and temporal alignment, NMCSE mitigates noise amplification without additional preprocessing. Integrated with our Temporal-Spatial Feature Extraction network, NMCSE enables robust multi-modal CVD detection. Experiments on the PhysioNet 2016 dataset with realistic hospital noise demonstrate that NMCSE reduces estimation errors by approximately 30% in Mean Squared Error while maintaining higher Pearson Correlation Coefficients across all tested signal-to-noise ratios. Our approach achieves 97.38% accuracy and 0.98 AUC in CVD detection, outperforming state-of-the-art methods and demonstrating robust performance for real-world clinical applications.', 'abstract_zh': '心电图（ECG）和心脏音图（PCG）信号通过一个潜在耦合信号联系，该信号代表了电气到机械心脏转换。虽然这对心血管疾病（CVD）的检测有价值，但传统上通过去卷积方法估计此耦合信号会放大噪声，限制了其临床应用。本文提出了一种噪声鲁棒多模态耦合信号估计方法（NMCSE），将其重新表述为通过最优传输理论进行分布匹配。通过同时优化幅度和时间对齐，NMCSE减轻了噪声放大而不需额外预处理。结合我们的时域-空域特征提取网络，NMCSE实现了稳健的多模态CVD检测。实验结果表明，NMCSE在均方误差中将估计误差降低了约30%，同时在所有测试信噪比下保持了更高的皮尔森相关系数。我们的方法在CVD检测中的准确率为97.38%，AUC值为0.98，优于现有方法，并在实际临床应用中表现出稳健性能。', 'title_zh': 'NMCSE: 基于最优传输的抗噪声多模态耦合信号估计方法在心血管疾病检测中的应用'}
{'arxiv_id': 'arXiv:2505.18164', 'title': 'Model-Distributed Inference for Large Language Models at the Edge', 'authors': 'Davide Macario, Hulya Seferoglu, Erdem Koyuncu', 'link': 'https://arxiv.org/abs/2505.18164', 'abstract': 'We introduce Model-Distributed Inference for Large-Language Models (MDI-LLM), a novel framework designed to facilitate the deployment of state-of-the-art large-language models (LLMs) across low-power devices at the edge. This is accomplished by dividing the model into multiple partitions, which are then assigned to different devices/nodes within the network. These nodes exchange intermediate activation vectors via device-to-device links, enabling collaborative computation. To enhance the efficiency of this process, we propose the "recurrent pipeline parallelism" technique, which reduces idle time on each device and facilitates parallel inference during the generation of multiple text sequences. By leveraging the combined computational resources of multiple edge devices, MDI-LLM enables the deployment of LLMs that exceed the memory capacity of individual devices, making it possible to perform inference on low-cost hardware. Furthermore, as the number of participating devices increases, MDI-LLM boosts token generation throughput and reduces memory consumption per device.', 'abstract_zh': 'Model-Distributed Inference for Large-Language Models (MDI-LLM)', 'title_zh': '边缘设备上的大型语言模型分布式推理'}
{'arxiv_id': 'arXiv:2505.18156', 'title': 'InjectLab: A Tactical Framework for Adversarial Threat Modeling Against Large Language Models', 'authors': 'Austin Howard', 'link': 'https://arxiv.org/abs/2505.18156', 'abstract': "Large Language Models (LLMs) are changing the way people interact with technology. Tools like ChatGPT and Claude AI are now common in business, research, and everyday life. But with that growth comes new risks, especially prompt-based attacks that exploit how these models process language. InjectLab is a security framework designed to address that problem. This paper introduces InjectLab as a structured, open-source matrix that maps real-world techniques used to manipulate LLMs. The framework is inspired by MITRE ATT&CK and focuses specifically on adversarial behavior at the prompt layer. It includes over 25 techniques organized under six core tactics, covering threats like instruction override, identity swapping, and multi-agent exploitation. Each technique in InjectLab includes detection guidance, mitigation strategies, and YAML-based simulation tests. A Python tool supports easy execution of prompt-based test cases. This paper outlines the framework's structure, compares it to other AI threat taxonomies, and discusses its future direction as a practical, community-driven foundation for securing language models.", 'abstract_zh': '大型语言模型（LLMs）正在改变人们与技术互动的方式。ChatGPT和Claude AI等工具现已在商业、研究和日常生活中广泛应用。但随着这些模型的发展，新的风险也随之而来，尤其是基于提示的攻击，这些攻击利用了这些模型处理语言的方式。InjectLab是一种安全框架，旨在解决这些问题。本文介绍了InjectLab作为一个结构化的开源矩阵，用于映射用于操纵LLMs的实际技术。该框架借鉴了MITRE ATT&CK的方法，并专注于提示层的对抗行为。它涵盖了超过25种技术，并将其组织在六大核心战术之下，涵盖诸如指令重写、身份交换和多代理利用等威胁。InjectLab中的每种技术都包括检测指南、缓解策略以及基于YAML的模拟测试。一个Python工具支持基于提示的测试用例的便捷执行。本文概述了该框架的结构，将其与其他AI威胁分类进行比较，并讨论其作为实用的社区驱动基础框架的未来方向，用于保护语言模型。', 'title_zh': 'InjectLab：一个针对大型语言模型的对抗威胁建模战术框架'}
{'arxiv_id': 'arXiv:2505.17648', 'title': 'Simulating Macroeconomic Expectations using LLM Agents', 'authors': 'Jianhao Lin, Lexuan Sun, Yixin Yan', 'link': 'https://arxiv.org/abs/2505.17648', 'abstract': 'We introduce a novel framework for simulating macroeconomic expectation formation using Large Language Model-Empowered Agents (LLM Agents). By constructing thousands of LLM Agents equipped with modules for personal characteristics, prior expectations, and knowledge, we replicate a survey experiment involving households and experts on inflation and unemployment. Our results show that although the expectations and thoughts generated by LLM Agents are more homogeneous than those of human participants, they still effectively capture key heterogeneity across agents and the underlying drivers of expectation formation. Furthermore, a module-ablation exercise highlights the critical role of prior expectations in simulating such heterogeneity. This approach complements traditional survey methods and offers new insights into AI behavioral science in macroeconomic research.', 'abstract_zh': '我们介绍了一种使用大型语言模型赋能代理（LLM代理）模拟宏观经济预期形成的新框架。通过构建拥有个人特征、先期预期和知识模块的数千个LLM代理，我们重现了一项涉及家庭和专家关于通胀和失业的调查实验。我们的结果表明，尽管LLM代理生成的预期和想法比人类参与者更为一致，但它们仍然有效地捕捉了代理间的关键异质性和预期形成的基本驱动因素。此外，模块消融实验突显了先期预期在模拟这种异质性中的关键作用。该方法补充了传统的调查方法，并为宏观经济学研究中的人工智能行为科学提供了新的见解。', 'title_zh': '使用大语言模型代理模拟宏观经济预期'}
{'arxiv_id': 'arXiv:2406.17441', 'title': 'A Matrix Product State Model for Simultaneous Classification and Generation', 'authors': 'Alex Mossi, Bojan Žunkovic, Kyriakos Flouris', 'link': 'https://arxiv.org/abs/2406.17441', 'abstract': 'Quantum machine learning (QML) is a rapidly expanding field that merges the principles of quantum computing with the techniques of machine learning. One of the powerful mathematical frameworks in this domain is tensor networks. These networks are used to approximate high-order tensors by contracting tensors with lower ranks. Initially developed for simulating quantum systems, tensor networks have become integral to quantum computing and, by extension, to QML. Drawing inspiration from these quantum methods, specifically the Matrix Product States (MPS), we apply them in a classical machine learning setting. Their ability to efficiently represent and manipulate complex, high-dimensional data makes them effective in a supervised learning framework. Here, we present an MPS model, in which the MPS functions as both a classifier and a generator. The dual functionality of this novel MPS model permits a strategy that enhances the traditional training of supervised MPS models. This framework is inspired by generative adversarial networks and is geared towards generating more realistic samples by reducing outliers. In addition, our contributions offer insights into the mechanics of tensor network methods for generation tasks. Specifically, we discuss alternative embedding functions and a new sampling method from non-normalized MPSs.', 'abstract_zh': '量子机器学习（QML）是一个迅速扩张的领域，将量子计算的原则与机器学习的技术相结合。该领域中一个强大的数学框架是张量网络。这些网络用于通过合同低秩张量来近似高阶张量。最初用于模拟量子系统，张量网络已成为量子计算和由此扩展到量子机器学习的核心组成部分。受这些量子方法的启发，特别是在矩阵乘积状态（MPS）中，我们将其应用于经典的机器学习设置中。它们能够有效表示和操作复杂的高维数据，使其在监督学习框架中非常有效。在这里，我们提出了一种MPS模型，在该模型中，MPS既作为分类器又作为生成器发挥作用。这一新型MPS模型的双重功能允许一种策略，以增强传统的监督MPS模型训练。该框架借鉴了生成对抗网络的理念，旨在通过降低离群值来生成更真实的样本。此外，我们的贡献还提供了关于生成任务中张量网络方法机理的见解，特别是讨论了替代嵌入函数和非规范化MPS的新采样方法。', 'title_zh': '矩阵乘积态模型同时进行分类和生成'}
