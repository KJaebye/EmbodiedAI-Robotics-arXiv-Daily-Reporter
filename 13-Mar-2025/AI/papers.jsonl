{'arxiv_id': 'arXiv:2503.09586', 'title': 'Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot', 'authors': 'Andrew Crossman, Andrew R. Plummer, Chandra Sekharudu, Deepak Warrier, Mohammad Yekrangian', 'link': 'https://arxiv.org/abs/2503.09586', 'abstract': 'We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.', 'abstract_zh': 'Auspex - 一种基于生成型人工智能方法的威胁建模系统', 'title_zh': 'Auspex: 将威胁建模技术融入基于人工智能的副驾系统'}
{'arxiv_id': 'arXiv:2503.09567', 'title': 'Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models', 'authors': 'Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, Wangxiang Che', 'link': 'https://arxiv.org/abs/2503.09567', 'abstract': 'Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies in the application of long chain-of-thought (Long CoT) characteristics, which enhance reasoning abilities and enable the solution of intricate problems. However, despite these developments, a comprehensive survey on Long CoT is still lacking, limiting our understanding of its distinctions from traditional short chain-of-thought (Short CoT) and complicating ongoing debates on issues like "overthinking" and "test-time scaling." This survey seeks to fill this gap by offering a unified perspective on Long CoT. (1) We first distinguish Long CoT from Short CoT and introduce a novel taxonomy to categorize current reasoning paradigms. (2) Next, we explore the key characteristics of Long CoT: deep reasoning, extensive exploration, and feasible reflection, which enable models to handle more complex tasks and produce more efficient, coherent outcomes compared to the shallower Short CoT. (3) We then investigate key phenomena such as the emergence of Long CoT with these characteristics, including overthinking, and test-time scaling, offering insights into how these processes manifest in practice. (4) Finally, we identify significant research gaps and highlight promising future directions, including the integration of multi-modal reasoning, efficiency improvements, and enhanced knowledge frameworks. By providing a structured overview, this survey aims to inspire future research and further the development of logical reasoning in artificial intelligence.', 'abstract_zh': 'Recent advancements in reasoning with large language models (RLLMs)，如OpenAI-O1和DeepSeek-R1，在数学和编码等复杂领域展示了其出色的能力。其成功的关键因素之一在于长链推理（Long CoT）特征的应用，这增强了推理能力，并使解决复杂问题成为可能。然而，尽管取得这些进展，关于长链推理的全面综述仍然缺乏，限制了我们对它与传统短链推理（Short CoT）的区别理解，并使得关于“过度推理”和“测试时扩展”等问题的争论复杂化。本综述旨在通过提供统一的视角来填补这一空白。(1) 首先，我们将长链推理与短链推理区分开来，并引入一种新颖的分类法来划分当前的推理范式。(2) 然后，我们探讨长链推理的关键特征：深入推理、广泛探索和可行的反思，这些特征使模型能够处理更复杂的任务，并比表层的短链推理产生更有效和连贯的结果。(3) 接着，我们研究这些特征出现的关键现象，包括过度推理和测试时扩展等，提供这些过程在实践中表现的见解。(4) 最后，我们确定了重要的研究缺口，并强调了有希望的未来方向，包括多模态推理的整合、效率改进和知识框架的增强。通过提供结构化的概述，本综述旨在激发未来研究，并推动人工智能中逻辑推理的发展。', 'title_zh': '向推理时代迈进：长链推理综述——针对大规模语言模型的逻辑推理研究'}
{'arxiv_id': 'arXiv:2503.09545', 'title': 'The Value of Goal Commitment in Planning', 'authors': 'Alberto Pozanco, Marianela Morales, Daniel Borrajo, Manuela Veloso', 'link': 'https://arxiv.org/abs/2503.09545', 'abstract': 'In this paper, we revisit the concept of goal commitment from early planners in the presence of current forward chaining heuristic planners. We present a compilation that extends the original planning task with commit actions that enforce the persistence of specific goals once achieved, thereby committing to them in the search sub-tree. This approach imposes a specific goal achievement order in parts of the search tree, potentially introducing dead-end states. This can reduce search effort if the goal achievement order is correct. Otherwise, the search algorithm can expand nodes in the open list where goals do not persist. Experimental results demonstrate that the reformulated tasks suit state-of-the-art agile planners, enabling them to find better', 'abstract_zh': '在当前正向连接启发式规划器背景下重新审视早期规划器中的目标承诺概念：一种通过承诺动作扩展规划任务的方法', 'title_zh': '目标承诺在规划中的价值'}
{'arxiv_id': 'arXiv:2503.09521', 'title': 'PairVDN - Pair-wise Decomposed Value Functions', 'authors': 'Zak Buzzard', 'link': 'https://arxiv.org/abs/2503.09521', 'abstract': 'Extending deep Q-learning to cooperative multi-agent settings is challenging due to the exponential growth of the joint action space, the non-stationary environment, and the credit assignment problem. Value decomposition allows deep Q-learning to be applied at the joint agent level, at the cost of reduced expressivity. Building on past work in this direction, our paper proposes PairVDN, a novel method for decomposing the value function into a collection of pair-wise, rather than per-agent, functions, improving expressivity at the cost of requiring a more complex (but still efficient) dynamic programming maximisation algorithm. Our method enables the representation of value functions which cannot be expressed as a monotonic combination of per-agent functions, unlike past approaches such as VDN and QMIX. We implement a novel many-agent cooperative environment, Box Jump, and demonstrate improved performance over these baselines in this setting. We open-source our code and environment at this https URL.', 'abstract_zh': '将深度Q学习扩展到协作多智能体环境中具有挑战性，原因在于联合动作空间的指数增长、非稳定环境以及奖励归属问题。价值分解允许在联合智能体级别应用深度Q学习，但会导致表达能力降低。基于这一方向上的先前工作，我们提出了一种新颖的方法PairVDN，该方法将价值函数分解为一对一的而非单个智能体的函数集合，从而提高了表达能力，但需要使用更复杂（但仍高效）的动态规划最大化算法。我们的方法能够表示那些无法用单个智能体函数的单调组合来表达的价值函数，不同于过去的方法如VDN和QMIX。我们在盒跳跃环境中实现了一种新颖的多智能体协作环境，并在该环境中展示了相对于基准方法的性能提升。我们在GitHub上开源了我们的代码和环境：https://github.com/author/repo。', 'title_zh': 'PairVDN - 配对分解值函数'}
{'arxiv_id': 'arXiv:2503.09501', 'title': 'ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement Learning', 'authors': 'Ziyu Wan, Yunxiang Li, Yan Song, Hanjing Wang, Linyi Yang, Mark Schmidt, Jun Wang, Weinan Zhang, Shuyue Hu, Ying Wen', 'link': 'https://arxiv.org/abs/2503.09501', 'abstract': 'Recent research on Reasoning of Large Language Models (LLMs) has sought to further enhance their performance by integrating meta-thinking -- enabling models to monitor, evaluate, and control their reasoning processes for more adaptive and effective problem-solving. However, current single-agent work lacks a specialized design for acquiring meta-thinking, resulting in low efficacy. To address this challenge, we introduce Reinforced Meta-thinking Agents (ReMA), a novel framework that leverages Multi-Agent Reinforcement Learning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think about thinking. ReMA decouples the reasoning process into two hierarchical agents: a high-level meta-thinking agent responsible for generating strategic oversight and plans, and a low-level reasoning agent for detailed executions. Through iterative reinforcement learning with aligned objectives, these agents explore and learn collaboration, leading to improved generalization and robustness. Experimental results demonstrate that ReMA outperforms single-agent RL baselines on complex reasoning tasks, including competitive-level mathematical benchmarks and LLM-as-a-Judge benchmarks. Comprehensive ablation studies further illustrate the evolving dynamics of each distinct agent, providing valuable insights into how the meta-thinking reasoning process enhances the reasoning capabilities of LLMs.', 'abstract_zh': 'Recent研究大语言模型（LLMs）的推理研究旨在通过整合元思考进一步提升其性能，使模型能够监控、评估和控制其推理过程，实现更适应性和有效的解决问题。然而，当前单智能体工作的设计未能专门针对获得元思考进行优化，导致其效果较低。为应对这一挑战，我们提出了一种新型框架——强化元思考智能体（ReMA），该框架利用多智能体强化学习（MARL）来激发元思考行为，鼓励大语言模型进行反思性思考。ReMA 将推理过程分解为两个层次的智能体：高层元思考智能体负责生成战略监督和计划，而低层推理智能体负责详细的执行。通过具有对齐目标的迭代强化学习，这些智能体探索并学习协作，从而提高泛化能力和鲁棒性。实验结果表明，ReMA 在复杂推理任务（包括竞争级别的数学基准和大语言模型作为裁判的基准）中优于单智能体 RL 基准。全面的消融研究进一步阐述了每个独立智能体的演变动态，提供了宝贵的见解，说明了元思考推理过程如何增强大语言模型的推理能力。', 'title_zh': 'ReMA：利用多 agent 强化学习进行元思考的大型语言模型学习方法'}
{'arxiv_id': 'arXiv:2503.09447', 'title': 'Online Language Splatting', 'authors': 'Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan Huang, Liu Ren', 'link': 'https://arxiv.org/abs/2503.09447', 'abstract': 'To enable AI agents to interact seamlessly with both humans and 3D environments, they must not only perceive the 3D world accurately but also align human language with 3D spatial representations. While prior work has made significant progress by integrating language features into geometrically detailed 3D scene representations using 3D Gaussian Splatting (GS), these approaches rely on computationally intensive offline preprocessing of language features for each input image, limiting adaptability to new environments. In this work, we introduce Online Language Splatting, the first framework to achieve online, near real-time, open-vocabulary language mapping within a 3DGS-SLAM system without requiring pre-generated language features. The key challenge lies in efficiently fusing high-dimensional language features into 3D representations while balancing the computation speed, memory usage, rendering quality and open-vocabulary capability. To this end, we innovatively design: (1) a high-resolution CLIP embedding module capable of generating detailed language feature maps in 18ms per frame, (2) a two-stage online auto-encoder that compresses 768-dimensional CLIP features to 15 dimensions while preserving open-vocabulary capabilities, and (3) a color-language disentangled optimization approach to improve rendering quality. Experimental results show that our online method not only surpasses the state-of-the-art offline methods in accuracy but also achieves more than 40x efficiency boost, demonstrating the potential for dynamic and interactive AI applications.', 'abstract_zh': '使AI代理能够无缝交互于人类和3D环境之间，它们不仅需要准确地感知3D世界，还需要将人类语言与3D空间表示对齐。尽管先前的工作通过使用3D高斯斑点化（GS）将语言特征整合到几何细节丰富的3D场景表示中取得了显著进展，但这些方法依赖于为每个输入图像进行计算密集型的离线语言特征预处理，限制了对新环境的适应性。在本文中，我们引入了在线语言斑点化，这是第一个在3DGS-SLAM系统中实现在线、接近实时、开放词汇量语言映射的框架，无需预先生成语言特征。关键挑战在于高效地将高维语言特征融合到3D表示中，同时平衡计算速度、内存使用、渲染质量和开放词汇量能力。为此，我们创新设计了：（1）一个高分辨率CLIP嵌入模块，在每帧18毫秒内生成详细的语言特征图，（2）一个两阶段在线自编码器，将768维的CLIP特征压缩到15维的同时保留开放词汇量的能力，以及（3）一种颜色-语言解耦优化方法以提高渲染质量。实验结果表明，我们的在线方法不仅在准确性上超越了最新的离线方法，还在效率上实现了超过40倍的提升，展示了动态和交互式AI应用的潜力。', 'title_zh': '在线语言绘制'}
{'arxiv_id': 'arXiv:2503.09241', 'title': 'In-Context Defense in Computer Agents: An Empirical Study', 'authors': 'Pei Yang, Hai Ci, Mike Zheng Shou', 'link': 'https://arxiv.org/abs/2503.09241', 'abstract': "Computer agents powered by vision-language models (VLMs) have significantly advanced human-computer interaction, enabling users to perform complex tasks through natural language instructions. However, these agents are vulnerable to context deception attacks, an emerging threat where adversaries embed misleading content into the agent's operational environment, such as a pop-up window containing deceptive instructions. Existing defenses, such as instructing agents to ignore deceptive elements, have proven largely ineffective. As the first systematic study on protecting computer agents, we introduce textbf{in-context defense}, leveraging in-context learning and chain-of-thought (CoT) reasoning to counter such attacks. Our approach involves augmenting the agent's context with a small set of carefully curated exemplars containing both malicious environments and corresponding defensive responses. These exemplars guide the agent to first perform explicit defensive reasoning before action planning, reducing susceptibility to deceptive attacks. Experiments demonstrate the effectiveness of our method, reducing attack success rates by 91.2% on pop-up window attacks, 74.6% on average on environment injection attacks, while achieving 100% successful defenses against distracting advertisements. Our findings highlight that (1) defensive reasoning must precede action planning for optimal performance, and (2) a minimal number of exemplars (fewer than three) is sufficient to induce an agent's defensive behavior.", 'abstract_zh': '由视觉-语言模型驱动的计算机代理在人机交互方面取得了显著进展，使用户能够通过自然语言指令执行复杂任务。然而，这些代理容易受到上下文欺骗攻击的威胁，这是一种新兴的威胁，对手会在代理的操作环境中嵌入误导性内容，如包含欺骗指令的弹出窗口。现有的防御措施，如指示代理忽略欺骗性元素，证明效果有限。作为第一个系统性的计算机代理保护研究，我们引入了“上下文内防御”，利用上下文学习和链式思考（CoT）推理来对抗此类攻击。我们的方法包括为代理的上下文增加一组精心策划的示例，其中包含恶意环境及其相应的防御响应。这些示例引导代理首先进行显式的防御推理，然后再进行行动计划，从而减少对欺骗性攻击的易感性。实验结果表明，我们的方法在弹出窗口攻击中将攻击成功率降低了91.2%，在平均环境下注入攻击中降低了74.6%，而在对抗干扰广告时实现了100%的成功防御。我们的研究发现，（1）防御推理应在行动计划之前进行，以获得最佳性能，（2）少量的示例（少于三个）就足以诱导代理的防御行为。', 'title_zh': '计算机代理的上下文防御：一项实证研究'}
{'arxiv_id': 'arXiv:2503.09164', 'title': 'AI-Driven Decision Support in Oncology: Evaluating Data Readiness for Skin Cancer Treatment', 'authors': 'Joscha Grüger, Tobias Geyer, Tobias Brix, Michael Storck, Sonja Leson, Laura Bley, Carsten Weishaupt, Ralph Bergmann, Stephan A. Braun', 'link': 'https://arxiv.org/abs/2503.09164', 'abstract': 'This research focuses on evaluating and enhancing data readiness for the development of an Artificial Intelligence (AI)-based Clinical Decision Support System (CDSS) in the context of skin cancer treatment. The study, conducted at the Skin Tumor Center of the University Hospital Münster, delves into the essential role of data quality, availability, and extractability in implementing effective AI applications in oncology. By employing a multifaceted methodology, including literature review, data readiness assessment, and expert workshops, the study addresses the challenges of integrating AI into clinical decision-making. The research identifies crucial data points for skin cancer treatment decisions, evaluates their presence and quality in various information systems, and highlights the difficulties in extracting information from unstructured data. The findings underline the significance of high-quality, accessible data for the success of AI-driven CDSS in medical settings, particularly in the complex field of oncology.', 'abstract_zh': '本研究聚焦于评估和提升用于皮肤癌治疗的基于人工智能（AI）的临床决策支持系统（CDSS）的数据准备情况。研究在鲁尔西格医院进行，深入探讨了数据质量、可用性和提取性在肿瘤学中实施有效AI应用中的核心作用。通过采用多方面的方法，包括文献回顾、数据准备评估和专家研讨会，本研究解决了将AI整合到临床决策中的挑战。研究确定了皮肤癌治疗决策中的关键数据点，评估了这些数据点在各种信息系统中的存在和质量，并指出了从非结构化数据中提取信息的困难。研究结果强调了高质量、易于获取的数据对AI驱动的CDSS在医疗环境中的成功，特别是在复杂的肿瘤学领域中的重要性。', 'title_zh': '基于AI的肿瘤决策支持：评估皮肤癌治疗的数据成熟度'}
{'arxiv_id': 'arXiv:2503.08883', 'title': 'Imitation Learning of Correlated Policies in Stackelberg Games', 'authors': 'Kunag-Da Wang, Ping-Chun Hsieh, Wen-Chih Peng', 'link': 'https://arxiv.org/abs/2503.08883', 'abstract': "Stackelberg games, widely applied in domains like economics and security, involve asymmetric interactions where a leader's strategy drives follower responses. Accurately modeling these dynamics allows domain experts to optimize strategies in interactive scenarios, such as turn-based sports like badminton. In multi-agent systems, agent behaviors are interdependent, and traditional Multi-Agent Imitation Learning (MAIL) methods often fail to capture these complex interactions. Correlated policies, which account for opponents' strategies, are essential for accurately modeling such dynamics. However, even methods designed for learning correlated policies, like CoDAIL, struggle in Stackelberg games due to their asymmetric decision-making, where leaders and followers cannot simultaneously account for each other's actions, often leading to non-correlated policies. Furthermore, existing MAIL methods that match occupancy measures or use adversarial techniques like GAIL or Inverse RL face scalability challenges, particularly in high-dimensional environments, and suffer from unstable training. To address these challenges, we propose a correlated policy occupancy measure specifically designed for Stackelberg games and introduce the Latent Stackelberg Differential Network (LSDN) to match it. LSDN models two-agent interactions as shared latent state trajectories and uses multi-output Geometric Brownian Motion (MO-GBM) to effectively capture joint policies. By leveraging MO-GBM, LSDN disentangles environmental influences from agent-driven transitions in latent space, enabling the simultaneous learning of interdependent policies. This design eliminates the need for adversarial training and simplifies the learning process. Extensive experiments on Iterative Matrix Games and multi-agent particle environments demonstrate that LSDN can better reproduce complex interaction dynamics than existing MAIL methods.", 'abstract_zh': 'Stackelberg博弈中的相关策略建模与Latent Stackelberg差分网络(LSDN)方法', 'title_zh': 'Stackelberg博弈中相关策略的imitation学习'}
{'arxiv_id': 'arXiv:2503.08786', 'title': 'Combining Local Symmetry Exploitation and Reinforcement Learning for Optimised Probabilistic Inference -- A Work In Progress', 'authors': 'Sagad Hamid, Tanya Braun', 'link': 'https://arxiv.org/abs/2503.08786', 'abstract': "Efficient probabilistic inference by variable elimination in graphical models requires an optimal elimination order. However, finding an optimal order is a challenging combinatorial optimisation problem for models with a large number of random variables. Most recently, a reinforcement learning approach has been proposed to find efficient contraction orders in tensor networks. Due to the duality between graphical models and tensor networks, we adapt this approach to probabilistic inference in graphical models. Furthermore, we incorporate structure exploitation into the process of finding an optimal order. Currently, the agent's cost function is formulated in terms of intermediate result sizes which are exponential in the number of indices (i.e., random variables). We show that leveraging specific structures during inference allows for introducing compact encodings of intermediate results which can be significantly smaller. By considering the compact encoding sizes for the cost function instead, we enable the agent to explore more efficient contraction orders. The structure we consider in this work is the presence of local symmetries (i.e., symmetries within a model's factors).", 'abstract_zh': '基于图形模型中变量消除的高效概率推理需要最优的消除顺序。然而，对于具有大量随机变量的模型，找到最优顺序是一个具有挑战性的组合优化问题。最近，一种强化学习方法被提出用于在张量网络中寻找有效的收缩顺序。由于图形模型与张量网络之间的对偶性，我们将此方法适应于图形模型中的概率推理。此外，我们在寻找最优顺序的过程中融入了结构利用。目前，代理的成本函数是以中间结果大小的形式给出的，这些中间结果的大小与索引的数量成指数关系（即随机变量的数量）。我们展示了利用特定结构可以在推理过程中引入紧凑的中间结果编码，这些编码可以显著减小。通过以紧凑编码的大小作为成本函数，我们可以使代理探索更高效的收缩顺序。我们在这项工作中考虑的结构是局部对称性的存在（即模型因子内的对称性）。', 'title_zh': '结合局部对称性exploitation和强化学习以优化概率推理——一项工作进行中'}
{'arxiv_id': 'arXiv:2503.08762', 'title': 'Neurosymbolic Decision Trees', 'authors': 'Matthias Möller, Arvid Norlander, Pedro Zuidberg Dos Martires, Luc De Raedt', 'link': 'https://arxiv.org/abs/2503.08762', 'abstract': 'Neurosymbolic (NeSy) AI studies the integration of neural networks (NNs) and symbolic reasoning based on logic. Usually, NeSy techniques focus on learning the neural, probabilistic and/or fuzzy parameters of NeSy models. Learning the symbolic or logical structure of such models has, so far, received less attention. We introduce neurosymbolic decision trees (NDTs), as an extension of decision trees together with a novel NeSy structure learning algorithm, which we dub NeuID3. NeuID3 adapts the standard top-down induction of decision tree algorithms and combines it with a neural probabilistic logic representation, inherited from the DeepProbLog family of models. The key advantage of learning NDTs with NeuID3 is the support of both symbolic and subsymbolic data (such as images), and that they can exploit background knowledge during the induction of the tree structure, In our experimental evaluation we demonstrate the benefits of NeSys structure learning over more traditonal approaches such as purely data-driven learning with neural networks.', 'abstract_zh': '神经符号 (NeSy) AI 研究神经网络 (NNs) 和基于逻辑的符号推理的集成', 'title_zh': '神经符号决策树'}
{'arxiv_id': 'arXiv:2503.09598', 'title': 'How to Protect Yourself from 5G Radiation? Investigating LLM Responses to Implicit Misinformation', 'authors': 'Ruohao Guo, Wei Xu, Alan Ritter', 'link': 'https://arxiv.org/abs/2503.09598', 'abstract': "As Large Language Models (LLMs) are widely deployed in diverse scenarios, the extent to which they could tacitly spread misinformation emerges as a critical safety concern. Current research primarily evaluates LLMs on explicit false statements, overlooking how misinformation often manifests subtly as unchallenged premises in real-world user interactions. We curated ECHOMIST, the first comprehensive benchmark for implicit misinformation, where the misinformed assumptions are embedded in a user query to LLMs. ECHOMIST is based on rigorous selection criteria and carefully curated data from diverse sources, including real-world human-AI conversations and social media interactions. We also introduce a new evaluation metric to measure whether LLMs can recognize and counter false information rather than amplify users' misconceptions. Through an extensive empirical study on a wide range of LLMs, including GPT-4, Claude, and Llama, we find that current models perform alarmingly poorly on this task, often failing to detect false premises and generating misleading explanations. Our findings underscore the critical need for an increased focus on implicit misinformation in LLM safety research.", 'abstract_zh': '作为大规模语言模型（LLMs）在各种场景中广泛部署，它们默示传播虚假信息的程度已成为一个关键的安全 concern。当前的研究主要评估LLMs在显性错误陈述上的表现，忽视了虚假信息在实际用户交互中常以未受挑战的前提形式悄然出现。我们编纂了ECHOMIST，这是首个全面的隐性虚假信息基准数据集，其中的误导性假设被嵌入到用户针对LLMs的查询中。ECHOMIST基于严格的筛选标准，数据来源多样，包括现实世界的人机对话和社会媒体互动。我们还引入了一个新的评估指标，以衡量LLMs能否识别和反驳虚假信息，而不是放大用户的误解。通过对包括GPT-4、Claude和Llama在内的多种LLM进行广泛的实证研究，我们发现当前的模型在这项任务上的表现令人担忧，经常无法检测到虚假前提并生成误导性解释。我们的研究结果强调了在LLM安全研究中加强对隐性虚假信息的关注的紧迫性。', 'title_zh': '如何防护5G辐射？探究大语言模型对隐含虚假信息的响应'}
{'arxiv_id': 'arXiv:2503.09579', 'title': 'Cost-Optimal Grouped-Query Attention for Long-Context LLMs', 'authors': 'Yingfa Chen, Yutong Wu, Xu Han, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2503.09579', 'abstract': 'Building effective and efficient Transformer-based large language models (LLMs) has recently become a research focus, requiring maximizing model language capabilities and minimizing training and deployment costs. Existing efforts have primarily described complex relationships among model performance, parameter size, and data size, as well as searched for the optimal compute allocation to train LLMs. However, they overlook the impacts of context length and attention head configuration (the number of query and key-value heads in grouped-query attention) on training and inference. In this paper, we systematically compare models with different parameter sizes, context lengths, and attention head configurations in terms of model performance, computational cost, and memory cost. Then, we extend the existing scaling methods, which are based solely on parameter size and training compute, to guide the construction of cost-optimal LLMs during both training and inference. Our quantitative scaling studies show that, when processing sufficiently long sequences, a larger model with fewer attention heads can achieve a lower loss while incurring lower computational and memory costs. Our findings provide valuable insights for developing practical LLMs, especially in long-context processing scenarios. We will publicly release our code and data.', 'abstract_zh': '构建高效且有效的基于Transformer的大语言模型（LLMs）近期成为研究重点，需要最大化模型语言能力并最小化训练和部署成本。现有工作主要描述了模型性能、参数量和数据量之间复杂的相互关系，并寻找训练LLMs的最佳计算分配。然而，它们忽略了上下文长度和注意力头配置（分组查询注意力中的查询和键值头的数量）对训练和推理的影响。在本文中，我们系统地比较了具有不同参数量、上下文长度和注意力头配置的模型在模型性能、计算成本和内存成本方面的差异。然后，我们将现有的仅基于参数量和训练计算量的扩展方法扩展，以指导在训练和推理过程中构建成本最优的LLMs。我们的定量扩展研究表明，处理足够长的序列时，具有较少注意力头的大型模型可以在较低的计算和内存成本下实现较低的损失。我们的发现为开发实际的LLMs，尤其是在长上下文处理场景中提供了宝贵的见解。我们将公开发布我们的代码和数据。', 'title_zh': '面向长期上下文LLM的分组查询注意力成本优化技术'}
{'arxiv_id': 'arXiv:2503.09573', 'title': 'Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models', 'authors': 'Marianne Arriola, Aaron Gokaslan, Justin T Chiu, Zhihan Yang, Zhixuan Qi, Jiaqi Han, Subham Sekhar Sahoo, Volodymyr Kuleshov', 'link': 'https://arxiv.org/abs/2503.09573', 'abstract': 'Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation. In this work, we introduce a class of block diffusion language models that interpolate between discrete denoising diffusion and autoregressive models. Block diffusion overcomes key limitations of both approaches by supporting flexible-length generation and improving inference efficiency with KV caching and parallel token sampling. We propose a recipe for building effective block diffusion models that includes an efficient training algorithm, estimators of gradient variance, and data-driven noise schedules to minimize the variance. Block diffusion sets a new state-of-the-art performance among diffusion models on language modeling benchmarks and enables generation of arbitrary-length sequences. We provide the code, along with the model weights and blog post on the project page: this https URL', 'abstract_zh': '扩散语言模型因其并行生成和可控性等独特优势，在概率建模和固定长度生成方面优于自回归模型。然而，它们在概率建模方面仍有不足，并且受限于固定长度生成。本文介绍了一类块扩散语言模型，介于离散去噪扩散和自回归模型之间。块扩散通过支持灵活长度生成和通过KV缓存和并行 token 抽样提高推理效率，解决了这两种方法的关键限制。我们提出了一种构建有效块扩散模型的方案，包括高效的训练算法、梯度方差估计器以及数据驱动的噪声调度，以最小化方差。块扩散在语言建模基准测试中设定了新的性能标准，并且能够生成任意长度的序列。项目代码、模型权重和博客文章可在项目页面获取：this https URL', 'title_zh': '块扩散：自回归与扩散语言模型的插值'}
{'arxiv_id': 'arXiv:2503.09565', 'title': 'Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width Neural Networks under $μ$P Parametrization', 'authors': 'Zixiang Chen, Greg Yang, Qingyue Zhao, Quanquan Gu', 'link': 'https://arxiv.org/abs/2503.09565', 'abstract': "Despite deep neural networks' powerful representation learning capabilities, theoretical understanding of how networks can simultaneously achieve meaningful feature learning and global convergence remains elusive. Existing approaches like the neural tangent kernel (NTK) are limited because features stay close to their initialization in this parametrization, leaving open questions about feature properties during substantial evolution. In this paper, we investigate the training dynamics of infinitely wide, $L$-layer neural networks using the tensor program (TP) framework. Specifically, we show that, when trained with stochastic gradient descent (SGD) under the Maximal Update parametrization ($\\mu$P) and mild conditions on the activation function, SGD enables these networks to learn linearly independent features that substantially deviate from their initial values. This rich feature space captures relevant data information and ensures that any convergent point of the training process is a global minimum. Our analysis leverages both the interactions among features across layers and the properties of Gaussian random variables, providing new insights into deep representation learning. We further validate our theoretical findings through experiments on real-world datasets.", 'abstract_zh': '尽管深度神经网络具有强大表征学习能力，但关于网络如何能够同时实现有意义的特征学习和全局收敛的理论理解仍然不明晰。现有方法如神经 tangent 核（NTK）受限于特征在该参数化下保持接近初始化，留下关于特征属性在显著演化过程中性质的问题。在本文中，我们使用张量程序（TP）框架研究无限宽、L层神经网络的训练动态。具体而言，我们表明，在最大更新参数化（$\\mu$P）和激活函数的轻微条件下，使用随机梯度下降（SGD）训练可以使网络学习出线性独立的特征，这些特征显著偏离初始值。这种丰富的特征空间捕捉了相关数据信息，并确保训练过程中的任何收敛点均为全局最小值。我们的分析结合了跨层特征之间的相互作用和高斯随机变量的性质，为深度表示学习提供了新的见解。我们进一步通过在实际数据集上的实验验证了我们的理论发现。', 'title_zh': '$L$层无限宽神经网络在$\\mu$P参数化下的全局收敛性和丰富特征学习'}
{'arxiv_id': 'arXiv:2503.09538', 'title': 'Differentially Private Equilibrium Finding in Polymatrix Games', 'authors': 'Mingyang Liu, Gabriele Farina, Asuman Ozdaglar', 'link': 'https://arxiv.org/abs/2503.09538', 'abstract': 'We study equilibrium finding in polymatrix games under differential privacy constraints. To start, we show that high accuracy and asymptotically vanishing differential privacy budget (as the number of players goes to infinity) cannot be achieved simultaneously under either of the two settings: (i) We seek to establish equilibrium approximation guarantees in terms of Euclidean distance to the equilibrium set, and (ii) the adversary has access to all communication channels. Then, assuming the adversary has access to a constant number of communication channels, we develop a novel distributed algorithm that recovers strategies with simultaneously vanishing Nash gap (in expected utility, also referred to as exploitability and privacy budget as the number of players increases.', 'abstract_zh': '在差分隐私约束下的多矩阵博弈均衡寻找研究', 'title_zh': '差异隐私下的多项式矩阵博弈均衡查找'}
{'arxiv_id': 'arXiv:2503.09537', 'title': 'GenHPE: Generative Counterfactuals for 3D Human Pose Estimation with Radio Frequency Signals', 'authors': 'Shuokang Huang, Julie A. McCann', 'link': 'https://arxiv.org/abs/2503.09537', 'abstract': 'Human pose estimation (HPE) detects the positions of human body joints for various applications. Compared to using cameras, HPE using radio frequency (RF) signals is non-intrusive and more robust to adverse conditions, exploiting the signal variations caused by human interference. However, existing studies focus on single-domain HPE confined by domain-specific confounders, which cannot generalize to new domains and result in diminished HPE performance. Specifically, the signal variations caused by different human body parts are entangled, containing subject-specific confounders. RF signals are also intertwined with environmental noise, involving environment-specific confounders. In this paper, we propose GenHPE, a 3D HPE approach that generates counterfactual RF signals to eliminate domain-specific confounders. GenHPE trains generative models conditioned on human skeleton labels, learning how human body parts and confounders interfere with RF signals. We manipulate skeleton labels (i.e., removing body parts) as counterfactual conditions for generative models to synthesize counterfactual RF signals. The differences between counterfactual signals approximately eliminate domain-specific confounders and regularize an encoder-decoder model to learn domain-independent representations. Such representations help GenHPE generalize to new subjects/environments for cross-domain 3D HPE. We evaluate GenHPE on three public datasets from WiFi, ultra-wideband, and millimeter wave. Experimental results show that GenHPE outperforms state-of-the-art methods and reduces estimation errors by up to 52.2mm for cross-subject HPE and 10.6mm for cross-environment HPE.', 'abstract_zh': 'RF信号生成的人体姿态估计（GenHPE）：生成反事实RF信号消除领域特定混杂因素的3D姿态估计方法', 'title_zh': 'GenHPE: 基于无线电频率信号的生成对抗性-counterfactuals人体三维姿态估计'}
{'arxiv_id': 'arXiv:2503.09535', 'title': 'Evaluating Visual Explanations of Attention Maps for Transformer-based Medical Imaging', 'authors': 'Minjae Chung, Jong Bum Won, Ganghyun Kim, Yujin Kim, Utku Ozbulak', 'link': 'https://arxiv.org/abs/2503.09535', 'abstract': 'Although Vision Transformers (ViTs) have recently demonstrated superior performance in medical imaging problems, they face explainability issues similar to previous architectures such as convolutional neural networks. Recent research efforts suggest that attention maps, which are part of decision-making process of ViTs can potentially address the explainability issue by identifying regions influencing predictions, especially in models pretrained with self-supervised learning. In this work, we compare the visual explanations of attention maps to other commonly used methods for medical imaging problems. To do so, we employ four distinct medical imaging datasets that involve the identification of (1) colonic polyps, (2) breast tumors, (3) esophageal inflammation, and (4) bone fractures and hardware implants. Through large-scale experiments on the aforementioned datasets using various supervised and self-supervised pretrained ViTs, we find that although attention maps show promise under certain conditions and generally surpass GradCAM in explainability, they are outperformed by transformer-specific interpretability methods. Our findings indicate that the efficacy of attention maps as a method of interpretability is context-dependent and may be limited as they do not consistently provide the comprehensive insights required for robust medical decision-making.', 'abstract_zh': '尽管视觉transformer（ViT）在医疗影像问题上最近展示了优越的性能，它们在可解释性方面面临着与卷积神经网络等先前架构相似的问题。近期的研究表明，作为ViT决策过程一部分的注意力图有潜力通过识别影响预测的区域来解决可解释性问题，尤其是在自我监督学习预训练的模型中。在本工作中，我们比较了注意力图的视觉解释与其他常用方法在医疗影像问题中的表现。为此，我们采用了涉及（1）结肠息肉识别，（2）乳腺肿瘤识别，（3）食管炎症识别，以及（4）骨折和医疗器械植入物识别的四种不同的医疗影像数据集。通过在上述数据集上使用各种监督和自我监督预训练的ViT进行大规模实验，我们发现虽然注意力图在某些条件下具有前景，在可解释性方面通常超越了GradCAM，但在解释性方面仍被特定于transformer的可解释性方法超越。我们的研究结果表明，注意力图作为解释方法的有效性是情境依赖的，并且可能受到限制，因为它们不能一致地提供进行稳健医疗决策所需的全面洞察。', 'title_zh': '基于变换器的医学影像注意力图可视化解释评估'}
{'arxiv_id': 'arXiv:2503.09527', 'title': 'CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in 3D Action Role-Playing Games', 'authors': 'Peng Chen, Pi Bu, Yingyao Wang, Xinyi Wang, Ziming Wang, Jie Guo, Yingxiu Zhao, Qi Zhu, Jun Song, Siran Yang, Jiamang Wang, Bo Zheng', 'link': 'https://arxiv.org/abs/2503.09527', 'abstract': 'Recent advances in Vision-Language-Action models (VLAs) have expanded the capabilities of embodied intelligence. However, significant challenges remain in real-time decision-making in complex 3D environments, which demand second-level responses, high-resolution perception, and tactical reasoning under dynamic conditions. To advance the field, we introduce CombatVLA, an efficient VLA model optimized for combat tasks in 3D action role-playing games(ARPGs). Specifically, our CombatVLA is a 3B model trained on video-action pairs collected by an action tracker, where the data is formatted as action-of-thought (AoT) sequences. Thereafter, CombatVLA seamlessly integrates into an action execution framework, allowing efficient inference through our truncated AoT strategy. Experimental results demonstrate that CombatVLA not only outperforms all existing models on the combat understanding benchmark but also achieves a 50-fold acceleration in game combat. Moreover, it has a higher task success rate than human players. We will open-source all resources, including the action tracker, dataset, benchmark, model weights, training code, and the implementation of the framework at this https URL.', 'abstract_zh': '近期视觉-语言-行动模型（VLAs）的进展扩展了嵌入式智能的能力。然而，在复杂3D环境中的实时决策仍面临重大挑战，这要求二级响应、高分辨率感知和动态条件下的战术推理。为了推动这一领域的发展，我们引入了CombatVLA，这是一种针对3D动作角色扮演游戏（ARPGs）中战斗任务优化的高效VLAs模型。具体而言，我们的CombatVLA是一个3B规模的模型，通过行为追踪器收集的视频-行动对进行训练，数据格式化为行动-思考（AoT）序列。随后，CombatVLA无缝集成到行动执行框架中，通过我们的截断AoT策略实现了高效的推理。实验结果表明，CombatVLA不仅在战斗理解基准测试中优于所有现有模型，还实现了50倍的游戏战斗加速。此外，其任务成功率高于人类玩家。我们将在此<https://this.url/> 开源所有资源，包括行为追踪器、数据集、基准测试、模型权重、训练代码和框架实现。', 'title_zh': 'CombatVLA：一种用于3D动作角色扮演游戏战斗任务的高效视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2503.09516', 'title': 'Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning', 'authors': 'Bowen Jin, Hansi Zeng, Zhenrui Yue, Dong Wang, Hamed Zamani, Jiawei Han', 'link': 'https://arxiv.org/abs/2503.09516', 'abstract': 'Efficiently acquiring external knowledge and up-to-date information is essential for effective reasoning and text generation in large language models (LLMs). Retrieval augmentation and tool-use training approaches where a search engine is treated as a tool lack complex multi-turn retrieval flexibility or require large-scale supervised data. Prompting advanced LLMs with reasoning capabilities during inference to use search engines is not optimal, since the LLM does not learn how to optimally interact with the search engine. This paper introduces Search-R1, an extension of the DeepSeek-R1 model where the LLM learns -- solely through reinforcement learning (RL) -- to autonomously generate (multiple) search queries during step-by-step reasoning with real-time retrieval. Search-R1 optimizes LLM rollouts with multi-turn search interactions, leveraging retrieved token masking for stable RL training and a simple outcome-based reward function. Experiments on seven question-answering datasets show that Search-R1 improves performance by 26% (Qwen2.5-7B), 21% (Qwen2.5-3B), and 10% (LLaMA3.2-3B) over SOTA baselines. This paper further provides empirical insights into RL optimization methods, LLM choices, and response length dynamics in retrieval-augmented reasoning. The code and model checkpoints are available at this https URL.', 'abstract_zh': '高效地获取外部知识和最新的信息对于大型语言模型（LLMs）的有效推理和文本生成至关重要。将搜索引擎作为工具的检索增强和工具使用训练方法缺乏复杂的多轮检索灵活性，或者需要大量的监督数据。在推理过程中通过提示具有推理能力的高级LLM使用搜索引擎并不是最优方案，因为LLM并未学会如何与搜索引擎进行最优互动。本文介绍了Search-R1，这是DeepSeek-R1模型的一种扩展，使得LLM通过强化学习（RL）自主在逐步推理过程中实时生成多个搜索查询。Search-R1利用检索到的标记掩蔽进行稳定的学习，并采用基于简单结果的奖励函数来优化LLM的滚动部署。在七个问答数据集上的实验表明，Search-R1分别在Qwen2.5-7B、Qwen2.5-3B和LLaMA3.2-3B上比SOTA基线提高了26%、21%和10%的性能。本文还进一步提供了关于RL优化方法、LLM选择和响应长度动态的实证见解。相关代码和模型检查点可在以下链接获取。', 'title_zh': 'Search-R1: 通过强化学习训练大规模语言模型进行推理和利用搜索引擎'}
{'arxiv_id': 'arXiv:2503.09513', 'title': 'RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment', 'authors': 'Md Morshed Alam, Lokesh Chandra Das, Sandip Roy, Sachin Shetty, Weichao Wang', 'link': 'https://arxiv.org/abs/2503.09513', 'abstract': 'Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.', 'abstract_zh': '基于触发-动作能力的物联网平台允许事件条件自主触发物联网设备中的操作，形成一连串交互。攻击者利用这种交互链恶意注入虚假事件条件到物联网枢纽中，触发目标物联网设备上的未经授权操作以实施远程注入攻击。现有防护机制主要侧重于使用物理事件特征来验证事件交易，以执行安全策略以阻止不安全的事件交易。这些方法设计为提供离线防护以应对注入攻击，而最先进的在线防护机制提供实时防护，但严重依赖对物联网网络攻击影响的推断限制了这些方法的泛化能力。本文提出了一种平台独立的多代理在线防御系统RESTRAIN，用于在运行时抵御远程注入攻击。RESTRAIN允许防御代理在运行时对攻击操作进行建模，并利用强化学习优化符合物联网网络安全要求的防御策略。实验结果表明，该防御代理能有效应对复杂和动态的远程注入攻击，并在几乎不增加计算开销的情况下最大化安全收益。', 'title_zh': '基于强化学习的Trigger-Action物联网环境安全框架RESTRAIN'}
{'arxiv_id': 'arXiv:2503.09504', 'title': 'Double-Stage Feature-Level Clustering-Based Mixture of Experts Framework', 'authors': 'Bakary Badjie, José Cecílio, António Casimiro', 'link': 'https://arxiv.org/abs/2503.09504', 'abstract': 'The Mixture-of-Experts (MoE) model has succeeded in deep learning (DL). However, its complex architecture and advantages over dense models in image classification remain unclear. In previous studies, MoE performance has often been affected by noise and outliers in the input space. Some approaches incorporate input clustering for training MoE models, but most clustering algorithms lack access to labeled data, limiting their effectiveness. This paper introduces the Double-stage Feature-level Clustering and Pseudo-labeling-based Mixture of Experts (DFCP-MoE) framework, which consists of input feature extraction, feature-level clustering, and a computationally efficient pseudo-labeling strategy. This approach reduces the impact of noise and outliers while leveraging a small subset of labeled data to label a large portion of unlabeled inputs. We propose a conditional end-to-end joint training method that improves expert specialization by training the MoE model on well-labeled, clustered inputs. Unlike traditional MoE and dense models, the DFCP-MoE framework effectively captures input space diversity, leading to competitive inference results. We validate our approach on three benchmark datasets for multi-class classification tasks.', 'abstract_zh': '基于双阶段特征级聚类和伪标签专家混合的混合专家模型（DFCP-MoE）', 'title_zh': '双阶段特征级聚类基于专家混合的框架'}
{'arxiv_id': 'arXiv:2503.09499', 'title': 'MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging Questions', 'authors': 'Zhe Xu, Daoyuan Chen, Zhenqing Ling, Yaliang Li, Ying Shen', 'link': 'https://arxiv.org/abs/2503.09499', 'abstract': "Large vision-language models (VLMs) face challenges in achieving robust, transferable reasoning abilities due to reliance on labor-intensive manual instruction datasets or computationally expensive self-supervised methods. To address these issues, we introduce MindGYM, a framework that enhances VLMs through synthetic self-challenging questions, consisting of three stages: (1) Seed Single-Hop Question Synthesis, generating cognitive questions across textual (e.g., logical deduction) and multimodal contexts (e.g., diagram-based queries) spanning eight semantic areas like ethical analysis; (2) Challenging Multi-Hop Question Synthesis, combining seed questions via diverse principles like bridging, visual-textual alignment, to create multi-step problems demanding deeper reasoning; and (3) Thinking-Induced Curriculum Fine-Tuning, a structured pipeline that progressively trains the model from scaffolded reasoning to standalone inference. By leveraging the model's self-synthesis capability, MindGYM achieves high data efficiency (e.g., +16% gains on MathVision-Mini with only 400 samples), computational efficiency (reducing both training and inference costs), and robust generalization across tasks. Extensive evaluations on seven benchmarks demonstrate superior performance over strong baselines, with notable improvements (+15.77% win rates) in reasoning depth and breadth validated via GPT-based scoring. MindGYM underscores the viability of self-challenging for refining VLM capabilities while minimizing human intervention and resource demands. Code and data are released to advance multimodal reasoning research.", 'abstract_zh': 'MindGYM：通过合成自挑战问题增强的视觉语言模型框架', 'title_zh': 'MindGYM：通过合成自我挑战问题提升视觉语言模型'}
{'arxiv_id': 'arXiv:2503.09446', 'title': 'Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models', 'authors': 'Zhihua Tian, Sirun Nan, Ming Xu, Shengfang Zhai, Wenjie Qu, Jian Liu, Kui Ren, Ruoxi Jia, Jiaheng Zhang', 'link': 'https://arxiv.org/abs/2503.09446', 'abstract': "Text-to-image (T2I) diffusion models have achieved remarkable progress in generating high-quality images but also raise people's concerns about generating harmful or misleading content. While extensive approaches have been proposed to erase unwanted concepts without requiring retraining from scratch, they inadvertently degrade performance on normal generation tasks. In this work, we propose Interpret then Deactivate (ItD), a novel framework to enable precise concept removal in T2I diffusion models while preserving overall performance. ItD first employs a sparse autoencoder (SAE) to interpret each concept as a combination of multiple features. By permanently deactivating the specific features associated with target concepts, we repurpose SAE as a zero-shot classifier that identifies whether the input prompt includes target concepts, allowing selective concept erasure in diffusion models. Moreover, we demonstrate that ItD can be easily extended to erase multiple concepts without requiring further training. Comprehensive experiments across celebrity identities, artistic styles, and explicit content demonstrate ItD's effectiveness in eliminating targeted concepts without interfering with normal concept generation. Additionally, ItD is also robust against adversarial prompts designed to circumvent content filters. Code is available at: this https URL.", 'abstract_zh': '文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著进展，但也引发了人们对生成有害或误导性内容的担忧。虽然提出了大量方法在无需从头开始重新训练的情况下消除不需要的概念，但这些方法无意中降低了普通生成任务的性能。在本文中，我们提出了一种名为Interpret then Deactivate (ItD)的新框架，以在保持整体性能的同时实现精确的概念移除。ItD 首先采用稀疏自编码器（SAE）将每个概念解释为多种特征的组合。通过永久停用与目标概念相关联的特定特征，我们将SAE重新用于零-shot分类器，以识别输入提示是否包含目标概念，从而在扩散模型中实现选择性概念移除。此外，我们展示了ItD可以轻松扩展以移除多个概念，无需进一步训练。在名人身份、艺术风格和明确内容方面的全面实验表明，ItD能够有效消除目标概念而不干扰正常概念生成。此外，ItD还能够抵御旨在规避内容过滤的对抗性提示。代码可在以下链接获取：this https URL。', 'title_zh': '稀疏自编码器作为零样本分类器用于文本到图像扩散模型中的概念删除'}
{'arxiv_id': 'arXiv:2503.09445', 'title': 'Astrea: A MOE-based Visual Understanding Model with Progressive Alignment', 'authors': 'Xiaoda Yang, JunYu Lu, Hongshun Qiu, Sijing Li, Hao Li, Shengpeng Ji, Xudong Tang, Jiayang Xu, Jiaqi Duan, Ziyue Jiang, Cong Lin, Sihang Cai, Zejian Xie, Zhuoyang Song, Songxin Zhang', 'link': 'https://arxiv.org/abs/2503.09445', 'abstract': "Vision-Language Models (VLMs) based on Mixture-of-Experts (MoE) architectures have emerged as a pivotal paradigm in multimodal understanding, offering a powerful framework for integrating visual and linguistic information. However, the increasing complexity and diversity of tasks present significant challenges in coordinating load balancing across heterogeneous visual experts, where optimizing one specialist's performance often compromises others' capabilities. To address task heterogeneity and expert load imbalance, we propose Astrea, a novel multi-expert collaborative VLM architecture based on progressive pre-alignment. Astrea introduces three key innovations: 1) A heterogeneous expert coordination mechanism that integrates four specialized models (detection, segmentation, classification, captioning) into a comprehensive expert matrix covering essential visual comprehension elements; 2) A dynamic knowledge fusion strategy featuring progressive pre-alignment to harmonize experts within the VLM latent space through contrastive learning, complemented by probabilistically activated stochastic residual connections to preserve knowledge continuity; 3) An enhanced optimization framework utilizing momentum contrastive learning for long-range dependency modeling and adaptive weight allocators for real-time expert contribution calibration. Extensive evaluations across 12 benchmark tasks spanning VQA, image captioning, and cross-modal retrieval demonstrate Astrea's superiority over state-of-the-art models, achieving an average performance gain of +4.7\\%. This study provides the first empirical demonstration that progressive pre-alignment strategies enable VLMs to overcome task heterogeneity limitations, establishing new methodological foundations for developing general-purpose multimodal agents.", 'abstract_zh': '基于MoE架构的多模态理解Vision-Language模型Astrea：渐进预对齐的多专家协作范式', 'title_zh': 'Astrea：一种基于MOE的分阶对齐视觉理解模型'}
{'arxiv_id': 'arXiv:2503.09436', 'title': 'PromptMap: An Alternative Interaction Style for AI-Based Image Generation', 'authors': 'Krzysztof Adamkiewicz, Paweł W. Woźniak, Julia Dominiak, Andrzej Romanowski, Jakob Karolus, Stanislav Frolov', 'link': 'https://arxiv.org/abs/2503.09436', 'abstract': 'Recent technological advances popularized the use of image generation among the general public. Crafting effective prompts can, however, be difficult for novice users. To tackle this challenge, we developed PromptMap, a new interaction style for text-to-image AI that allows users to freely explore a vast collection of synthetic prompts through a map-like view with semantic zoom. PromptMap groups images visually by their semantic similarity, allowing users to discover relevant examples. We evaluated PromptMap in a between-subject online study ($n=60$) and a qualitative within-subject study ($n=12$). We found that PromptMap supported users in crafting prompts by providing them with examples. We also demonstrated the feasibility of using LLMs to create vast example collections. Our work contributes a new interaction style that supports users unfamiliar with prompting in achieving a satisfactory image output.', 'abstract_zh': 'Recent 技术进步普及了图像生成的应用，但新手用户可能难以制作有效的提示。为了应对这一挑战，我们开发了PromptMap，这是一种新的文本到图像AI交互样式，用户可以通过类似地图的视图以语义缩放的方式自由探索庞大的合成提示集合。PromptMap通过语义相似性对图像进行视觉分组，让用户发现相关示例。我们在一项包含60名受试者的在线研究中评估了PromptMap，并进行了一项包含12名受试者的定性单被试研究。我们发现，PromptMap通过提供示例支持用户制作提示。我们还展示了使用大语言模型创建庞大示例集合的可行性。我们的工作贡献了一种新的交互样式，支持不熟悉提示技术的用户获得满意的图像输出。', 'title_zh': 'PromptMap: 一种基于AI的图像生成的替代交互方式'}
{'arxiv_id': 'arXiv:2503.09433', 'title': 'CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection', 'authors': 'Richard A. Dubniczky, Krisztofer Zoltán Horvát, Tamás Bisztray, Mohamed Amine Ferrag, Lucas C. Cordeiro, Norbert Tihanyi', 'link': 'https://arxiv.org/abs/2503.09433', 'abstract': 'Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at this https URL.', 'abstract_zh': '识别源代码中的漏洞在关键软件组件中尤为重要。现有的方法如静态分析、动态分析、形式验证以及最近的大规模语言模型被广泛用于检测安全缺陷。本文引入了CASTLE（CWE Automated Security Testing and Low-Level Evaluation）基准框架，以评估不同方法的漏洞检测能力。我们使用一个手工制作的数据集评估了13种静态分析工具、10种大模型和2种形式验证工具，该数据集涵盖了250个微型基准程序和25种常见的CWE。我们提出了CASTLE评分，这是一种新的评估指标，以确保公平比较。结果显示：形式验证工具ESBMC能够最小化误报，但在超出模型检查范围的漏洞，如弱加密或SQL注入方面表现不佳。静态分析器因高误报率增加开发者的手动验证工作。大模型在CASTLE数据集中识别小型代码片段中的漏洞表现十分出色，但在代码规模增长时，其准确性下降且生成错误信息增多。这些结果表明，大模型可能在未来安全解决方案中扮演关键角色，特别是在代码补全框架中，它们可以提供实时指导以防止漏洞。数据集可通过此链接访问：https://。', 'title_zh': 'CASTLE：面向 CWE 检测的静态代码分析器和大语言模型基准数据集'}
{'arxiv_id': 'arXiv:2503.09427', 'title': 'Multimodal Language Modeling for High-Accuracy Single Cell Transcriptomics Analysis and Generation', 'authors': 'Yaorui Shi, Jiaqi Yang, Sihang Li, Junfeng Fang, Xiang Wang, Zhiyuan Liu, Yang Zhang', 'link': 'https://arxiv.org/abs/2503.09427', 'abstract': 'Pre-trained language models (PLMs) have revolutionized scientific research, yet their application to single-cell analysis remains limited. Text PLMs cannot process single-cell RNA sequencing data, while cell PLMs lack the ability to handle free text, restricting their use in multimodal tasks. Existing efforts to bridge these modalities often suffer from information loss or inadequate single-modal pre-training, leading to suboptimal performances. To address these challenges, we propose Single-Cell MultiModal Generative Pre-trained Transformer (scMMGPT), a unified PLM for joint cell and text modeling. scMMGPT effectively integrates the state-of-the-art cell and text PLMs, facilitating cross-modal knowledge sharing for improved performance. To bridge the text-cell modality gap, scMMGPT leverages dedicated cross-modal projectors, and undergoes extensive pre-training on 27 million cells -- the largest dataset for multimodal cell-text PLMs to date. This large-scale pre-training enables scMMGPT to excel in joint cell-text tasks, achieving an 84\\% relative improvement of textual discrepancy for cell description generation, 20.5\\% higher accuracy for cell type annotation, and 4\\% improvement in $k$-NN accuracy for text-conditioned pseudo-cell generation, outperforming baselines.', 'abstract_zh': '预训练语言模型（PLMs）已 revolutionized 科学研究，但在单细胞分析中的应用仍有限制。文本 PLMs 无法处理单细胞 RNA 测序数据，而细胞 PLMs 在处理自由文本方面能力不足，限制了其在多模态任务中的应用。现有的跨模态融合努力往往存在信息丢失或单模态预训练不足的问题，导致性能不佳。为了解决这些挑战，我们提出了单细胞多模态生成预训练变换器（scMMGPT），这是一种用于联合细胞和文本建模的统一 PLM。scMMGPT 有效整合了最先进的细胞和文本 PLMs，促进多模态知识共享以提高性能。为弥合文本-细胞模态缺口，scMMGPT 利用专门的跨模态投影器，并在包含 2700 万个细胞的大型数据集上进行了广泛的预训练，这是迄今为止用于多模态细胞-文本 PLMs 的最大数据集。大规模预训练使 scMMGPT 在联合细胞-文本任务中表现出色，细胞描述生成的文本差异相对改进了 84%，细胞类型注释的准确性提高了 20.5%，文本条件伪细胞生成的 $k$-NN 准确率提高了 4%，优于基线。', 'title_zh': '多模态语言建模用于高精度单细胞转录组分析与生成'}
{'arxiv_id': 'arXiv:2503.09409', 'title': 'AI-based Framework for Robust Model-Based Connector Mating in Robotic Wire Harness Installation', 'authors': 'Claudius Kienle, Benjamin Alt, Finn Schneider, Tobias Pertlwieser, Rainer Jäkel, Rania Rayyes', 'link': 'https://arxiv.org/abs/2503.09409', 'abstract': 'Despite the widespread adoption of industrial robots in automotive assembly, wire harness installation remains a largely manual process, as it requires precise and flexible manipulation. To address this challenge, we design a novel AI-based framework that automates cable connector mating by integrating force control with deep visuotactile learning. Our system optimizes search-and-insertion strategies using first-order optimization over a multimodal transformer architecture trained on visual, tactile, and proprioceptive data. Additionally, we design a novel automated data collection and optimization pipeline that minimizes the need for machine learning expertise. The framework optimizes robot programs that run natively on standard industrial controllers, permitting human experts to audit and certify them. Experimental validations on a center console assembly task demonstrate significant improvements in cycle times and robustness compared to conventional robot programming approaches. Videos are available under this https URL.', 'abstract_zh': '尽管工业机器人在汽车装配中得到了广泛应用，线束安装过程仍主要依赖手动操作，因为它需要精确且灵活的操作。为应对这一挑战，我们设计了一种基于AI的新框架，通过将力控制与深度跨模态学习相结合，自动实现电缆接头对接。该系统使用多模态变换器架构对视觉、触觉和本体感受数据进行训练，并通过一阶优化方法优化搜索与插入策略。此外，我们还设计了一种新的自动化数据收集和优化管道，以减少对机器学习专业知识的需求。该框架优化的机器人程序可以在标准工业控制器上本地运行，使人类专家能够审核和认证这些程序。在中央控制台装配任务上的实验验证表明，与传统的机器人编程方法相比，该框架在循环时间和鲁棒性方面取得了显著改进。更多视频请访问此链接。', 'title_zh': '基于AI的鲁棒模型导向连接器对接框架在机器人线束安装中的应用'}
{'arxiv_id': 'arXiv:2503.09403', 'title': 'Multi-Agent Image Restoration', 'authors': 'Xu Jiang, Gehui Li, Bin Chen, Jian Zhang', 'link': 'https://arxiv.org/abs/2503.09403', 'abstract': 'Image restoration (IR) is challenging due to the complexity of real-world degradations. While many specialized and all-in-one IR models have been developed, they fail to effectively handle complex, mixed degradations. Recent agentic methods RestoreAgent and AgenticIR leverage intelligent, autonomous workflows to alleviate this issue, yet they suffer from suboptimal results and inefficiency due to their resource-intensive finetunings, and ineffective searches and tool execution trials for satisfactory outputs. In this paper, we propose MAIR, a novel Multi-Agent approach for complex IR problems. We introduce a real-world degradation prior, categorizing degradations into three types: (1) scene, (2) imaging, and (3) compression, which are observed to occur sequentially in real world, and reverse them in the opposite order. Built upon this three-stage restoration framework, MAIR emulates a team of collaborative human specialists, including a "scheduler" for overall planning and multiple "experts" dedicated to specific degradations. This design minimizes search space and trial efforts, improving image quality while reducing inference costs. In addition, a registry mechanism is introduced to enable easy integration of new tools. Experiments on both synthetic and real-world datasets show that proposed MAIR achieves competitive performance and improved efficiency over the previous agentic IR system. Code and models will be made available.', 'abstract_zh': '复杂图像恢复的多智能体方法（MAIR）', 'title_zh': '多智能体图像恢复'}
{'arxiv_id': 'arXiv:2503.09399', 'title': 'ForAug: Recombining Foregrounds and Backgrounds to Improve Vision Transformer Training with Bias Mitigation', 'authors': 'Tobias Christian Nauen, Brian Moser, Federico Raue, Stanislav Frolov, Andreas Dengel', 'link': 'https://arxiv.org/abs/2503.09399', 'abstract': 'Transformers, particularly Vision Transformers (ViTs), have achieved state-of-the-art performance in large-scale image classification. However, they often require large amounts of data and can exhibit biases that limit their robustness and generalizability. This paper introduces ForAug, a novel data augmentation scheme that addresses these challenges and explicitly includes inductive biases, which commonly are part of the neural network architecture, into the training data. ForAug is constructed by using pretrained foundation models to separate and recombine foreground objects with different backgrounds, enabling fine-grained control over image composition during training. It thus increases the data diversity and effective number of training samples. We demonstrate that training on ForNet, the application of ForAug to ImageNet, significantly improves the accuracy of ViTs and other architectures by up to 4.5 percentage points (p.p.) on ImageNet and 7.3 p.p. on downstream tasks. Importantly, ForAug enables novel ways of analyzing model behavior and quantifying biases. Namely, we introduce metrics for background robustness, foreground focus, center bias, and size bias and show that training on ForNet substantially reduces these biases compared to training on ImageNet. In summary, ForAug provides a valuable tool for analyzing and mitigating biases, enabling the development of more robust and reliable computer vision models. Our code and dataset are publicly available at this https URL.', 'abstract_zh': 'ForAug: 一种新的数据增强方案及其在图像分类中的应用', 'title_zh': 'ForAug: 结合前景和背景以减轻偏差并改进视觉变换器训练'}
{'arxiv_id': 'arXiv:2503.09396', 'title': 'Close-up-GS: Enhancing Close-Up View Synthesis in 3D Gaussian Splatting with Progressive Self-Training', 'authors': 'Jiatong Xia, Lingqiao Liu', 'link': 'https://arxiv.org/abs/2503.09396', 'abstract': "3D Gaussian Splatting (3DGS) has demonstrated impressive performance in synthesizing novel views after training on a given set of viewpoints. However, its rendering quality deteriorates when the synthesized view deviates significantly from the training views. This decline occurs due to (1) the model's difficulty in generalizing to out-of-distribution scenarios and (2) challenges in interpolating fine details caused by substantial resolution changes and occlusions. A notable case of this limitation is close-up view generation--producing views that are significantly closer to the object than those in the training set. To tackle this issue, we propose a novel approach for close-up view generation based by progressively training the 3DGS model with self-generated data. Our solution is based on three key ideas. First, we leverage the See3D model, a recently introduced 3D-aware generative model, to enhance the details of rendered views. Second, we propose a strategy to progressively expand the ``trust regions'' of the 3DGS model and update a set of reference views for See3D. Finally, we introduce a fine-tuning strategy to carefully update the 3DGS model with training data generated from the above schemes. We further define metrics for close-up views evaluation to facilitate better research on this problem. By conducting evaluations on specifically selected scenarios for close-up views, our proposed approach demonstrates a clear advantage over competitive solutions.", 'abstract_zh': '基于逐级训练的3DGS近景视图生成方法', 'title_zh': 'Close-up-GS: 在渐进自训练增强下的一种用于三维高斯点云的近距离视图合成方法'}
{'arxiv_id': 'arXiv:2503.09382', 'title': 'Towards Next-Generation Recommender Systems: A Benchmark for Personalized Recommendation Assistant with LLMs', 'authors': 'Jiani Huang, Shijie Wang, Liang-bo Ning, Wenqi Fan, Shuaiqiang Wang, Dawei Yin, Qing Li', 'link': 'https://arxiv.org/abs/2503.09382', 'abstract': "Recommender systems (RecSys) are widely used across various modern digital platforms and have garnered significant attention. Traditional recommender systems usually focus only on fixed and simple recommendation scenarios, making it difficult to generalize to new and unseen recommendation tasks in an interactive paradigm. Recently, the advancement of large language models (LLMs) has revolutionized the foundational architecture of RecSys, driving their evolution into more intelligent and interactive personalized recommendation assistants. However, most existing studies rely on fixed task-specific prompt templates to generate recommendations and evaluate the performance of personalized assistants, which limits the comprehensive assessments of their capabilities. This is because commonly used datasets lack high-quality textual user queries that reflect real-world recommendation scenarios, making them unsuitable for evaluating LLM-based personalized recommendation assistants. To address this gap, we introduce RecBench+, a new dataset benchmark designed to access LLMs' ability to handle intricate user recommendation needs in the era of LLMs. RecBench+ encompasses a diverse set of queries that span both hard conditions and soft preferences, with varying difficulty levels. We evaluated commonly used LLMs on RecBench+ and uncovered below findings: 1) LLMs demonstrate preliminary abilities to act as recommendation assistants, 2) LLMs are better at handling queries with explicitly stated conditions, while facing challenges with queries that require reasoning or contain misleading information. Our dataset has been released at this https URL.", 'abstract_zh': '推荐系统（RecSys）在各种现代数字平台中广泛使用并引起了广泛关注。传统推荐系统通常仅专注于固定且简单的推荐场景，这使得它们难以在交互式范式中泛化到新的和未见过的推荐任务。近年来，大型语言模型（LLMs）的进步彻底改变了推荐系统的基本架构，推动其演变为更加智能和互动的个性化推荐助手。然而，现有的大多数研究依赖于固定的针对特定任务的提示模板来生成推荐并评估个性化助手的性能，这限制了对它们能力的全面评估。这是因为常用的数据集缺乏反映真实世界推荐场景的高质量文本用户查询，使得它们不适用于评估基于LLM的个性化推荐助手。为解决这一问题，我们引入了RecBench+，这是一个新的数据集基准，旨在评估LLMs在LLM时代处理复杂用户推荐需求的能力。RecBench+包含了涵盖硬条件和软偏好、不同难度级别的查询集。我们在RecBench+上评估了常用的大型语言模型，并发现了以下结论：1）大型语言模型初步展示了作为推荐助手的能力；2）大型语言模型在处理明确条件的查询方面表现更佳，但在需要推理或包含误导信息的查询方面面临挑战。我们的数据集已在以下链接发布：https://github.com/recbench/recbench-plus。', 'title_zh': '面向下一代推荐系统：基于大语言模型的个性化推荐助手基准'}
{'arxiv_id': 'arXiv:2503.09378', 'title': 'Pig behavior dataset and Spatial-temporal perception and enhancement networks based on the attention mechanism for pig behavior recognition', 'authors': 'Fangzheng Qi, Zhenjie Hou, En Lin, Xing Li, iuzhen Liang, Xinwen Zhou', 'link': 'https://arxiv.org/abs/2503.09378', 'abstract': "The recognition of pig behavior plays a crucial role in smart farming and welfare assurance for pigs. Currently, in the field of pig behavior recognition, the lack of publicly available behavioral datasets not only limits the development of innovative algorithms but also hampers model robustness and algorithm this http URL paper proposes a dataset containing 13 pig behaviors that significantly impact this http URL on this dataset, this paper proposes a spatial-temporal perception and enhancement networks based on the attention mechanism to model the spatiotemporal features of pig behaviors and their associated interaction areas in video data. The network is composed of a spatiotemporal perception network and a spatiotemporal feature enhancement network. The spatiotemporal perception network is responsible for establishing connections between the pigs and the key regions of their behaviors in the video data. The spatiotemporal feature enhancement network further strengthens the important spatial features of individual pigs and captures the long-term dependencies of the spatiotemporal features of individual behaviors by remodeling these connections, thereby enhancing the model's perception of spatiotemporal changes in pig behaviors. Experimental results demonstrate that on the dataset established in this paper, our proposed model achieves a MAP score of 75.92%, which is an 8.17% improvement over the best-performing traditional model. This study not only improces the accuracy and generalizability of individual pig behavior recognition but also provides new technological tools for modern smart farming. The dataset and related code will be made publicly available alongside this paper.", 'abstract_zh': '猪行为识别在智能 farming 和猪的福利保障中起着关键作用。当前，在猪行为识别领域，缺乏公开的行为数据集不仅限制了创新算法的发展，也阻碍了模型的鲁棒性和算法性能的提升。本文提出一个包含13种对猪行为影响显著的数据集。基于注意力机制，本文提出了空间-时间感知和增强网络，用于建模猪行为及其相关交互区域的空间-时间特征。该网络由空间-时间感知网络和空间-时间特征增强网络组成。空间-时间感知网络负责在视频数据中建立猪与行为关键区域之间的连接。空间-时间特征增强网络进一步增强了单个猪的重要空间特征，并通过重塑这些连接捕获个体行为的空间-时间特征的长期依赖性，从而增强了模型对猪行为空间-时间变化的感知能力。实验结果表明，与最佳传统模型相比，本文提出的模型在本文建立的数据集上的MAP得分为75.92%，提高了8.17%。本研究不仅提高了个体猪行为识别的准确性和普适性，还为现代智能 farming 提供了新的技术工具。本文还将与论文一起公开该数据集及相关代码。', 'title_zh': '基于注意力机制的猪行为识别时空注意与增强网络及猪行为数据集'}
{'arxiv_id': 'arXiv:2503.09370', 'title': 'Revisiting Medical Image Retrieval via Knowledge Consolidation', 'authors': 'Yang Nan, Huichi Zhou, Xiaodan Xing, Giorgos Papanastasiou, Lei Zhu, Zhifan Gao, Alejandro F Fangi, Guang Yang', 'link': 'https://arxiv.org/abs/2503.09370', 'abstract': 'As artificial intelligence and digital medicine increasingly permeate healthcare systems, robust governance frameworks are essential to ensure ethical, secure, and effective implementation. In this context, medical image retrieval becomes a critical component of clinical data management, playing a vital role in decision-making and safeguarding patient information. Existing methods usually learn hash functions using bottleneck features, which fail to produce representative hash codes from blended embeddings. Although contrastive hashing has shown superior performance, current approaches often treat image retrieval as a classification task, using category labels to create positive/negative pairs. Moreover, many methods fail to address the out-of-distribution (OOD) issue when models encounter external OOD queries or adversarial attacks. In this work, we propose a novel method to consolidate knowledge of hierarchical features and optimisation functions. We formulate the knowledge consolidation by introducing Depth-aware Representation Fusion (DaRF) and Structure-aware Contrastive Hashing (SCH). DaRF adaptively integrates shallow and deep representations into blended features, and SCH incorporates image fingerprints to enhance the adaptability of positive/negative pairings. These blended features further facilitate OOD detection and content-based recommendation, contributing to a secure AI-driven healthcare environment. Moreover, we present a content-guided ranking to improve the robustness and reproducibility of retrieval results. Our comprehensive assessments demonstrate that the proposed method could effectively recognise OOD samples and significantly outperform existing approaches in medical image retrieval (p<0.05). In particular, our method achieves a 5.6-38.9% improvement in mean Average Precision on the anatomical radiology dataset.', 'abstract_zh': '随着人工智能和数字医学日益渗透到 healthcare 系统中， robust 的治理框架对于确保实施的伦理、安全和有效性至关重要。在此背景下，医学图像检索成为临床数据管理中的关键组成部分，对决策过程和保护患者信息发挥着重要作用。现有方法通常使用瓶颈特征来学习哈希函数，但无法产生具有代表性的哈希码。尽管对比哈希显示出优越的性能，但当前方法往往将图像检索视为分类任务，并使用类别标签创建正负样本对。此外，许多方法在模型遇到外部 OOD 查询或对抗性攻击时未能解决 out-of-distribution (OOD) 问题。在此工作中，我们提出了一种新的方法，以整合层次特征知识和优化函数。通过引入深度感知表示融合 (DaRF) 和结构感知对比哈希 (SCH)，我们对知识进行了形式化表述。DaRF 适应性地将浅层和深层表示融合到混合特征中，而 SCH 则通过引入图像指纹增强了正负样本对的适应性。这些混合特征进一步促进了 OOD 检测和基于内容的推荐，从而促进了一个安全的人工智能驱动的医疗保健环境。此外，我们提出了一种基于内容的排序方法，以提高检索结果的鲁棒性和可重复性。全面评估表明，所提出的方法能够有效地识别 OOD 样本，并在医学图像检索中显著优于现有方法 (p<0.05)。特别是，我们的方法在解剖放射学数据集上达到了 5.6-38.9% 的平均精确率 (mAP) 改进。', 'title_zh': '基于知识 consolidation 重访医学图像检索'}
{'arxiv_id': 'arXiv:2503.09365', 'title': 'Membership Inference Attacks fueled by Few-Short Learning to detect privacy leakage tackling data integrity', 'authors': 'Daniel Jiménez-López, Nuria Rodríguez-Barroso, M. Victoria Luzón, Francisco Herrera', 'link': 'https://arxiv.org/abs/2503.09365', 'abstract': 'Deep learning models have an intrinsic privacy issue as they memorize parts of their training data, creating a privacy leakage. Membership Inference Attacks (MIA) exploit it to obtain confidential information about the data used for training, aiming to steal information. They can be repurposed as a measurement of data integrity by inferring whether it was used to train a machine learning model. While state-of-the-art attacks achieve a significant privacy leakage, their requirements are not feasible enough, hindering their role as practical tools to assess the magnitude of the privacy risk. Moreover, the most appropriate evaluation metric of MIA, the True Positive Rate at low False Positive Rate lacks interpretability. We claim that the incorporation of Few-Shot Learning techniques to the MIA field and a proper qualitative and quantitative privacy evaluation measure should deal with these issues. In this context, our proposal is twofold. We propose a Few-Shot learning based MIA, coined as the FeS-MIA model, which eases the evaluation of the privacy breach of a deep learning model by significantly reducing the number of resources required for the purpose. Furthermore, we propose an interpretable quantitative and qualitative measure of privacy, referred to as Log-MIA measure. Jointly, these proposals provide new tools to assess the privacy leakage and to ease the evaluation of the training data integrity of deep learning models, that is, to analyze the privacy breach of a deep learning model. Experiments carried out with MIA over image classification and language modeling tasks and its comparison to the state-of-the-art show that our proposals excel at reporting the privacy leakage of a deep learning model with little extra information.', 'abstract_zh': '深度学习模型固有的隐私问题在于它们会记忆训练数据的一部分，从而造成隐私泄露。成员推理攻击（MIA）利用这一问题来获取用于训练的数据的保密信息，以达到窃取信息的目的。这些攻击可以重新用于通过推断特定数据是否用于训练机器学习模型来衡量数据完整性。虽然最先进的攻击手段能够造成显著的隐私泄露，但它们的要求不够实际，阻碍了它们作为评估隐私风险规模的实用工具的角色。此外，成员推理攻击最合适的评估指标——低误报率下的真实阳性率缺乏可解释性。我们主张将少量样本学习技术引入成员推理攻击领域，并提出适当的定性和定量隐私评估指标来解决这些问题。在此背景下，我们的提案分为两部分。我们提出了一种基于少量样本学习的成员推理攻击模型，名为FeS-MIA模型，该模型通过大幅减少评估所需资源来简化深度学习模型的隐私泄露评估。此外，我们还提出了一种可解释的定量和定性隐私度量，称为Log-MIA度量。这两项提案为评估深度学习模型的隐私泄露和简化训练数据完整性评估提供了新的工具，即分析深度学习模型的隐私泄露。实验结果表明，在图像分类和语言模型任务上进行的成员推理攻击及其与最先进的技术进行比较显示，我们的提案能够在报告深度学习模型的隐私泄露时提供少量额外信息。', 'title_zh': '由Few-Shot学习驱动的会员推断攻击：检测隐私泄露以保障数据完整性'}
{'arxiv_id': 'arXiv:2503.09358', 'title': 'RetSTA: An LLM-Based Approach for Standardizing Clinical Fundus Image Reports', 'authors': 'Jiushen Cai, Weihang Zhang, Hanruo Liu, Ningli Wang, Huiqi Li', 'link': 'https://arxiv.org/abs/2503.09358', 'abstract': 'Standardization of clinical reports is crucial for improving the quality of healthcare and facilitating data integration. The lack of unified standards, including format, terminology, and style, is a great challenge in clinical fundus diagnostic reports, which increases the difficulty for large language models (LLMs) to understand the data. To address this, we construct a bilingual standard terminology, containing fundus clinical terms and commonly used descriptions in clinical diagnosis. Then, we establish two models, RetSTA-7B-Zero and RetSTA-7B. RetSTA-7B-Zero, fine-tuned on an augmented dataset simulating clinical scenarios, demonstrates powerful standardization behaviors. However, it encounters a challenge of limitation to cover a wider range of diseases. To further enhance standardization performance, we build RetSTA-7B, which integrates a substantial amount of standardized data generated by RetSTA-7B-Zero along with corresponding English data, covering diverse complex clinical scenarios and achieving report-level standardization for the first time. Experimental results demonstrate that RetSTA-7B outperforms other compared LLMs in bilingual standardization task, which validates its superior performance and generalizability. The checkpoints are available at this https URL.', 'abstract_zh': '临床报告的标准规范化对于提高医疗质量并促进数据整合至关重要。临床视网膜诊断报告缺乏统一的标准，包括格式、术语和风格，这是巨大的挑战，增加了大型语言模型理解数据的难度。为应对这一挑战，我们构建了一种双语标准术语，包含视网膜临床术语和临床诊断中常用的描述。然后，我们建立了两个模型：RetSTA-7B-Zero和RetSTA-7B。RetSTA-7B-Zero在模拟临床场景的扩充数据集上进行微调，展现了强大的标准化行为。然而，它在覆盖更广泛的疾病方面存在局限。为了进一步增强标准化性能，我们构建了RetSTA-7B，它整合了大量的由RetSTA-7B-Zero生成的标准化数据以及对应的英语文本，覆盖了多样复杂的临床场景，并首次实现了报告级别的标准化。实验结果表明，RetSTA-7B在双语标准化任务中优于其他对比的大型语言模型，验证了其优越的性能和泛化能力。模型检查点见此链接。', 'title_zh': 'RetSTA: 一种基于LLM的临床眼底图像报告标准化方法'}
{'arxiv_id': 'arXiv:2503.09357', 'title': 'Automatic Operator-level Parallelism Planning for Distributed Deep Learning -- A Mixed-Integer Programming Approach', 'authors': 'Ruifeng She, Bowen Pang, Kai Li, Zehua Liu, Tao Zhong', 'link': 'https://arxiv.org/abs/2503.09357', 'abstract': "As the artificial intelligence community advances into the era of large models with billions of parameters, distributed training and inference have become essential. While various parallelism strategies-data, model, sequence, and pipeline-have been successfully implemented for popular neural networks on main-stream hardware, optimizing the distributed deployment schedule requires extensive expertise and manual effort. Further more, while existing frameworks with most simple chain-like structures, they struggle with complex non-linear architectures. Mixture-of-experts and multi-modal models feature intricate MIMO and branch-rich topologies that require fine-grained operator-level parallelization beyond the capabilities of existing frameworks. We propose formulating parallelism planning as a scheduling optimization problem using mixed-integer programming. We propose a bi-level solution framework balancing optimality with computational efficiency, automatically generating effective distributed plans that capture both the heterogeneous structure of modern neural networks and the underlying hardware constraints. In experiments comparing against expert-designed strategies like DeepSeek's DualPipe, our framework achieves comparable or superior performance, reducing computational bubbles by half under the same memory constraints. The framework's versatility extends beyond throughput optimization to incorporate hardware utilization maximization, memory capacity constraints, and other considerations or potential strategies. Such capabilities position our solution as both a valuable research tool for exploring optimal parallelization strategies and a practical industrial solution for large-scale AI deployment.", 'abstract_zh': '随着人工智能领域进入以十亿参数为特征的大模型时代，分布式训练和推理已成为必备技术。尽管已在主流硬件上成功实现了多种并行策略（数据并行、模型并行、序列并行和管道并行），但优化分布式部署调度仍需大量专业知识和手工努力。此外，现有的大多数具有简单链式结构的框架难以处理复杂的非线性架构。混合专家模型和多模态模型具有复杂的MIMO和分支丰富的拓扑结构，要求在现有框架能力之外进行细粒度的操作级并行化。我们提出将并行性规划问题建模为混合整数规划的调度优化问题。我们提出了一种双层解决方案框架，平衡优化与计算效率，自动生成既捕捉现代神经网络的异构结构又考虑底层硬件约束的有效分布式计划。与DeepSeek的DualPipe等专家设计策略相比，在相同的内存约束下，我们的框架可实现相当或更优的性能，减少了一半的计算瓶颈。该框架的灵活性不仅限于吞吐量优化，还涵盖了硬件利用率最大化、内存容量约束以及其他考量或潜在策略。这些能力使我们的解决方案既适合作为探索最佳并行化策略的有价值的科研工具，也适用于大规模人工智能部署的实用工业解决方案。', 'title_zh': '分布式深度学习中基于整数规划的自动操作级并行规划方法'}
{'arxiv_id': 'arXiv:2503.09348', 'title': 'MOAT: Evaluating LMMs for Capability Integration and Instruction Grounding', 'authors': 'Zhoutong Ye, Mingze Sun, Huan-ang Gao, Chun Yu, Yuanchun Shi', 'link': 'https://arxiv.org/abs/2503.09348', 'abstract': "Large multimodal models (LMMs) have demonstrated significant potential as generalists in vision-language (VL) tasks. However, there remains a significant gap between state-of-the-art LMMs and human performance when it comes to complex tasks that require a combination of fundamental VL capabilities, as well as tasks involving the grounding of complex instructions. To thoroughly investigate the human-LMM gap and its underlying causes, we propose MOAT, a diverse benchmark with complex real-world VL tasks that are challenging for LMMs. Specifically, the tasks in MOAT require LMMs to engage in generalist problem solving by integrating fundamental VL capabilities such as reading text, counting, understanding spatial relations, grounding textual and visual instructions, etc. All these abilities fit into a taxonomy proposed by us that contains 10 fundamental VL capabilities, enabling MOAT to provide a fine-grained view of LMMs' strengths and weaknesses. Besides, MOAT is the first benchmark to explicitly evaluate LMMs' ability to ground complex text and visual instructions, which is essential to many real-world applications. We evaluate over 20 proprietary and open source LMMs, as well as humans, on MOAT, and found that humans achieved 82.7% accuracy while the best performing LMM (OpenAI o1) achieved only 38.8%. To guide future model development, we analyze common trends in our results and discuss the underlying causes of observed performance gaps between LMMs and humans, focusing on which VL capability forms the bottleneck in complex tasks, whether test time scaling improves performance on MOAT, and how tiling harms LMMs' capability to count. Code and data are available at this https URL.", 'abstract_zh': '大型多模态模型在视觉-语言任务中的通用潜力已得到显著展现，但当涉及需要结合基本视觉-语言能力的复杂任务，以及涉及复杂指令的 anchoring 任务时，与人类表现之间仍存在显著差距。为彻底探究人-多模态模型差距及其根本原因，我们提出 MOAT，一个包含具有挑战性的现实世界视觉-语言任务的综合性基准，旨在挑战多模态模型。具体而言，MOAT 中的任务要求模型结合阅读文本、计数、理解空间关系、锚定文本和视觉指令等基本视觉-语言能力进行通用问题解决。这些能力符合我们提出的包含 10 个基本视觉-语言能力的分类体系，使得 MOAT 能够提供对多模态模型优势和弱点的精细视角。此外，MOAT 是首个明确评估多模态模型锚定复杂文本和视觉指令能力的基准，这对许多实际应用至关重要。我们对 20 个自研和开源的多模态模型以及人类在 MOAT 上进行了评估，发现人类的准确率为 82.7%，而表现最佳的模型 (OpenAI o1) 的准确率为仅 38.8%。为了指导未来模型开发，我们分析了结果中的常见趋势，并讨论了多模态模型与人类表现差距背后的根本原因，重点关注哪些视觉-语言能力在复杂任务中成为瓶颈，测试时间的扩展是否在 MOAT 上提高性能，以及切片如何损害模型的计数能力。代码和数据可在以下链接获取。', 'title_zh': 'MOAT: 评估LMMs在能力集成和指令关联方面的表现'}
{'arxiv_id': 'arXiv:2503.09347', 'title': 'Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts', 'authors': 'Hongyu Chen, Seraphina Goldfarb-Tarrant', 'link': 'https://arxiv.org/abs/2503.09347', 'abstract': 'Large Language Models (LLMs) are increasingly employed as automated evaluators to assess the safety of generated content, yet their reliability in this role remains uncertain. This study evaluates a diverse set of 11 LLM judge models across critical safety domains, examining three key aspects: self-consistency in repeated judging tasks, alignment with human judgments, and susceptibility to input artifacts such as apologetic or verbose phrasing. Our findings reveal that biases in LLM judges can significantly distort the final verdict on which content source is safer, undermining the validity of comparative evaluations. Notably, apologetic language artifacts alone can skew evaluator preferences by up to 98\\%. Contrary to expectations, larger models do not consistently exhibit greater robustness, while smaller models sometimes show higher resistance to specific artifacts. To mitigate LLM evaluator robustness issues, we investigate jury-based evaluations aggregating decisions from multiple models. Although this approach both improves robustness and enhances alignment to human judgements, artifact sensitivity persists even with the best jury configurations. These results highlight the urgent need for diversified, artifact-resistant methodologies to ensure reliable safety assessments.', 'abstract_zh': '大型语言模型（LLMs）越来越多地被用作自动化评估器来评估生成内容的安全性，但其在这一角色中的可靠性仍有待确定。本研究评估了11种不同类型的LLM裁判模型在关键安全领域中的表现，考察了三个关键方面：重复评判任务中的自我一致性、与人类评判的一致性以及对输入艺术（如道歉或冗长措辞）的敏感性。研究发现，LLM裁判中存在偏向性，这可能导致对哪种内容来源更安全的最终判决产生重大扭曲，从而削弱了比较评估的有效性。值得注意的是，仅道歉语言艺术即可将评判者偏好偏斜高达98%。与预期相反，较大的模型并不总是更具有鲁棒性，而较小的模型有时对特定艺术更具抵抗力。为了减轻LLM评估者的鲁棒性问题，我们研究了陪审团式评估方法，即从多个模型的决策中进行聚合。尽管这种方法既提高了鲁棒性又增强了与人类判断的一致性，但即使在最佳陪审团配置下，对艺术的敏感性仍然存在。这些结果强调了需要多样化且对艺术具有抵抗力的方法的重要性，以确保可靠的安全性评估。', 'title_zh': '更安全还是更幸运？大规模语言模型作为安全性评估器并不 robust 至artifact'}
{'arxiv_id': 'arXiv:2503.09335', 'title': 'NVP-HRI: Zero Shot Natural Voice and Posture-based Human-Robot Interaction via Large Language Model', 'authors': 'Yuzhi Lai, Shenghai Yuan, Youssef Nassar, Mingyu Fan, Thomas Weber, Matthias Rätsch', 'link': 'https://arxiv.org/abs/2503.09335', 'abstract': 'Effective Human-Robot Interaction (HRI) is crucial for future service robots in aging societies. Existing solutions are biased toward only well-trained objects, creating a gap when dealing with new objects. Currently, HRI systems using predefined gestures or language tokens for pretrained objects pose challenges for all individuals, especially elderly ones. These challenges include difficulties in recalling commands, memorizing hand gestures, and learning new names. This paper introduces NVP-HRI, an intuitive multi-modal HRI paradigm that combines voice commands and deictic posture. NVP-HRI utilizes the Segment Anything Model (SAM) to analyze visual cues and depth data, enabling precise structural object representation. Through a pre-trained SAM network, NVP-HRI allows interaction with new objects via zero-shot prediction, even without prior knowledge. NVP-HRI also integrates with a large language model (LLM) for multimodal commands, coordinating them with object selection and scene distribution in real time for collision-free trajectory solutions. We also regulate the action sequence with the essential control syntax to reduce LLM hallucination risks. The evaluation of diverse real-world tasks using a Universal Robot showcased up to 59.2\\% efficiency improvement over traditional gesture control, as illustrated in the video this https URL. Our code and design will be openly available at this https URL.', 'abstract_zh': '有效的多模态人机交互（NVP-HRI）对于老龄化社会中的服务机器人至关重要', 'title_zh': 'NVP-HRI: 通过对大型语言模型零样本学习的自然语音和姿态驱动的人机交互'}
{'arxiv_id': 'arXiv:2503.09334', 'title': 'CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data', 'authors': 'Adel ElZemity, Budi Arief, Shujun Li', 'link': 'https://arxiv.org/abs/2503.09334', 'abstract': "The integration of large language models (LLMs) into cyber security applications presents significant opportunities, such as enhancing threat analysis and malware detection, but can also introduce critical risks and safety concerns, including personal data leakage and automated generation of new malware. To address these challenges, we developed CyberLLMInstruct, a dataset of 54,928 instruction-response pairs spanning cyber security tasks such as malware analysis, phishing simulations, and zero-day vulnerabilities. The dataset was constructed through a multi-stage process. This involved sourcing data from multiple resources, filtering and structuring it into instruction-response pairs, and aligning it with real-world scenarios to enhance its applicability. Seven open-source LLMs were chosen to test the usefulness of CyberLLMInstruct: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. In our primary example, we rigorously assess the safety of fine-tuned models using the OWASP top 10 framework, finding that fine-tuning reduces safety resilience across all tested LLMs and every adversarial attack (e.g., the security score of Llama 3.1 8B against prompt injection drops from 0.95 to 0.15). In our second example, we show that these same fine-tuned models can also achieve up to 92.50 percent accuracy on the CyberMetric benchmark. These findings highlight a trade-off between performance and safety, showing the importance of adversarial testing and further research into fine-tuning methodologies that can mitigate safety risks while still improving performance across diverse datasets and domains. All scripts required to reproduce the dataset, along with examples and relevant resources for replicating our results, will be made available upon the paper's acceptance.", 'abstract_zh': '大型语言模型（LLMs）在网络安全应用中的集成既带来了显著机会，也引入了关键风险和安全顾虑，包括个人数据泄露和新型恶意软件的自动化生成。为应对这些挑战，我们开发了CyberLLMInstruct数据集，包含54,928个指令-响应对，涵盖诸如恶意软件分析、鱼叉 phishing 模拟和零日漏洞等网络安全任务。该数据集通过多阶段过程构建，涉及从多个资源采集数据、筛选和结构化为指令-响应对，并与现实场景对齐以增强其实用性。我们选择了七个开源LLMs进行测试：Phi 3 Mini 3.8B、Mistral 7B、Qwen 2.5 7B、Llama 3 8B、Llama 3.1 8B、Gemma 2 9B 和 Llama 2 70B。在我们的主要示例中，我们使用OWASP TOP 10框架严格评估调优模型的安全性，发现调优降低了所有测试LLMs的安全韧性，并对每种对抗性攻击（例如，对Llama 3.1 8B针对提示注入的安全评分从0.95降至0.15）产生负面影响。在我们的第二个示例中，我们展示了这些相同的调优模型在CyberMetric基准测试中可达到高达92.50%的准确性。这些发现突显了性能与安全之间的权衡关系，强调了对抗性测试的重要性，并进一步研究可以减轻安全风险同时在多样数据集和领域中改进性能的调优方法的重要性。论文被接受后，将提供所有用于重现数据集的脚本，以及复制我们结果的示例和相关资源。', 'title_zh': 'CyberLLMInstruct: 一种使用网络安全数据分析细调LLM安全性的新数据集'}
{'arxiv_id': 'arXiv:2503.09332', 'title': 'SDD-4DGS: Static-Dynamic Aware Decoupling in Gaussian Splatting for 4D Scene Reconstruction', 'authors': 'Dai Sun, Huhao Guan, Kun Zhang, Xike Xie, S. Kevin Zhou', 'link': 'https://arxiv.org/abs/2503.09332', 'abstract': 'Dynamic and static components in scenes often exhibit distinct properties, yet most 4D reconstruction methods treat them indiscriminately, leading to suboptimal performance in both cases. This work introduces SDD-4DGS, the first framework for static-dynamic decoupled 4D scene reconstruction based on Gaussian Splatting. Our approach is built upon a novel probabilistic dynamic perception coefficient that is naturally integrated into the Gaussian reconstruction pipeline, enabling adaptive separation of static and dynamic components. With carefully designed implementation strategies to realize this theoretical framework, our method effectively facilitates explicit learning of motion patterns for dynamic elements while maintaining geometric stability for static structures. Extensive experiments on five benchmark datasets demonstrate that SDD-4DGS consistently outperforms state-of-the-art methods in reconstruction fidelity, with enhanced detail restoration for static structures and precise modeling of dynamic motions. The code will be released.', 'abstract_zh': '基于高斯Splating的静态-动态解耦4D场景重建框架SDD-4DGS', 'title_zh': 'SDD-4DGS：静态-动态感知的高斯点云解耦在四维场景重建中的应用'}
{'arxiv_id': 'arXiv:2503.09330', 'title': 'Group-robust Machine Unlearning', 'authors': 'Thomas De Min, Subhankar Roy, Stéphane Lathuilière, Elisa Ricci, Massimiliano Mancini', 'link': 'https://arxiv.org/abs/2503.09330', 'abstract': 'Machine unlearning is an emerging paradigm to remove the influence of specific training data (i.e., the forget set) from a model while preserving its knowledge of the rest of the data (i.e., the retain set). Previous approaches assume the forget data to be uniformly distributed from all training datapoints. However, if the data to unlearn is dominant in one group, we empirically show that performance for this group degrades, leading to fairness issues. This work tackles the overlooked problem of non-uniformly distributed forget sets, which we call group-robust machine unlearning, by presenting a simple, effective strategy that mitigates the performance loss in dominant groups via sample distribution reweighting. Moreover, we present MIU (Mutual Information-aware Machine Unlearning), the first approach for group robustness in approximate machine unlearning. MIU minimizes the mutual information between model features and group information, achieving unlearning while reducing performance degradation in the dominant group of the forget set. Additionally, MIU exploits sample distribution reweighting and mutual information calibration with the original model to preserve group robustness. We conduct experiments on three datasets and show that MIU outperforms standard methods, achieving unlearning without compromising model robustness. Source code available at this https URL.', 'abstract_zh': '基于分组稳健性的机器遗忘研究：一种通过样本分布重加权减轻性能损失的简单有效策略及MIU方法', 'title_zh': '组稳健机器遗忘'}
{'arxiv_id': 'arXiv:2503.09326', 'title': 'A Survey on Enhancing Causal Reasoning Ability of Large Language Models', 'authors': 'Xin Li, Zhuo Cai, Shoujin Wang, Kun Yu, Fang Chen', 'link': 'https://arxiv.org/abs/2503.09326', 'abstract': "Large language models (LLMs) have recently shown remarkable performance in language tasks and beyond. However, due to their limited inherent causal reasoning ability, LLMs still face challenges in handling tasks that require robust causal reasoning ability, such as health-care and economic analysis. As a result, a growing body of research has focused on enhancing the causal reasoning ability of LLMs. Despite the booming research, there lacks a survey to well review the challenges, progress and future directions in this area. To bridge this significant gap, we systematically review literature on how to strengthen LLMs' causal reasoning ability in this paper. We start from the introduction of background and motivations of this topic, followed by the summarisation of key challenges in this area. Thereafter, we propose a novel taxonomy to systematically categorise existing methods, together with detailed comparisons within and between classes of methods. Furthermore, we summarise existing benchmarks and evaluation metrics for assessing LLMs' causal reasoning ability. Finally, we outline future research directions for this emerging field, offering insights and inspiration to researchers and practitioners in the area.", 'abstract_zh': '大型语言模型（LLMs）在语言任务和相关领域中最近展现了卓越的性能。然而，由于其有限的固有因果推理能力，LLMs在处理需要 robust 因果推理能力的任务（如医疗和经济分析）时仍面临挑战。因此，越来越多的研究聚焦于增强LLMs的因果推理能力。尽管该领域研究迅速发展，但缺乏对该领域挑战、进展和未来方向的综述。为填补这一重要空白，本文系统地回顾了如何增强LLMs的因果推理能力的研究文献。我们从背景和动机介绍开始，随后总结了该领域的关键挑战。之后，我们提出了一种新的分类法，系统地对现有方法进行分类，并进行了详细的类内和类间比较。此外，我们总结了现有的基准和评估指标，用于评估LLMs的因果推理能力。最后，我们展望了该新兴领域的未来研究方向，为该领域的研究人员和实践者提供了见解和灵感。', 'title_zh': '大型语言模型因果推理能力增强进展综述'}
{'arxiv_id': 'arXiv:2503.09321', 'title': 'DAVE: Diagnostic benchmark for Audio Visual Evaluation', 'authors': 'Gorjan Radevski, Teodora Popordanoska, Matthew B. Blaschko, Tinne Tuytelaars', 'link': 'https://arxiv.org/abs/2503.09321', 'abstract': 'Audio-visual understanding is a rapidly evolving field that seeks to integrate and interpret information from both auditory and visual modalities. Despite recent advances in multi-modal learning, existing benchmarks often suffer from strong visual bias -- where answers can be inferred from visual data alone -- and provide only aggregate scores that conflate multiple sources of error. This makes it difficult to determine whether models struggle with visual understanding, audio interpretation, or audio-visual alignment. In this work, we introduce DAVE (Diagnostic Audio Visual Evaluation), a novel benchmark dataset designed to systematically evaluate audio-visual models across controlled challenges. DAVE alleviates existing limitations by (i) ensuring both modalities are necessary to answer correctly and (ii) decoupling evaluation into atomic subcategories. Our detailed analysis of state-of-the-art models reveals specific failure modes and provides targeted insights for improvement. By offering this standardized diagnostic framework, we aim to facilitate more robust development of audio-visual models. The dataset is released: this https URL', 'abstract_zh': '音视频理解是一个快速发展的领域，旨在整合和解释来自听觉和视觉两种模态的信息。尽管在多模态学习方面取得了近期进展，现有的基准测试往往存在强烈的视觉偏差——答案可以从视觉数据中单独推断出来——并且仅提供可能会混淆多种错误来源的综合评分。这使得很难判断模型是在视觉理解、音频解释还是音视频对齐方面遇到困难。在本文中，我们引入了DAVE（诊断音视频评估），这是一个新型基准数据集，旨在系统性地评估音视频模型在可控挑战中的表现。DAVE通过确保（i）两个模态都必要来正确回答问题以及（ii）将评估拆分到原子子类别中来克服现有局限性。我们对最先进的模型的详细分析揭示了特定的失败模式，并提供了改进的针对性见解。通过提供这种标准化的诊断框架，我们旨在促进音视频模型的更稳健开发。数据集已发布：[这个链接]。', 'title_zh': 'DAVE:  Audio Visual Evaluation诊断基准'}
{'arxiv_id': 'arXiv:2503.09311', 'title': 'Adaptive political surveys and GPT-4: Tackling the cold start problem with simulated user interactions', 'authors': 'Fynn Bachmann, Daan van der Weijden, Lucien Heitz, Cristina Sarasua, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2503.09311', 'abstract': 'Adaptive questionnaires dynamically select the next question for a survey participant based on their previous answers. Due to digitalisation, they have become a viable alternative to traditional surveys in application areas such as political science. One limitation, however, is their dependency on data to train the model for question selection. Often, such training data (i.e., user interactions) are unavailable a priori. To address this problem, we (i) test whether Large Language Models (LLM) can accurately generate such interaction data and (ii) explore if these synthetic data can be used to pre-train the statistical model of an adaptive political survey. To evaluate this approach, we utilise existing data from the Swiss Voting Advice Application (VAA) Smartvote in two ways: First, we compare the distribution of LLM-generated synthetic data to the real distribution to assess its similarity. Second, we compare the performance of an adaptive questionnaire that is randomly initialised with one pre-trained on synthetic data to assess their suitability for training. We benchmark these results against an "oracle" questionnaire with perfect prior knowledge. We find that an off-the-shelf LLM (GPT-4) accurately generates answers to the Smartvote questionnaire from the perspective of different Swiss parties. Furthermore, we demonstrate that initialising the statistical model with synthetic data can (i) significantly reduce the error in predicting user responses and (ii) increase the candidate recommendation accuracy of the VAA. Our work emphasises the considerable potential of LLMs to create training data to improve the data collection process in adaptive questionnaires in LLM-affine areas such as political surveys.', 'abstract_zh': '自适应问卷能够根据受访者的先前答案动态选择下一个问题。由于数字化的发展，它们已成为政治科学等领域传统调查的可行替代方案。然而，它们的一个限制在于对训练问题选择模型所需的数据的依赖。通常，这类训练数据（即用户交互数据）在先验情况下不可用。为解决这一问题，我们（i）测试大型语言模型（LLM）是否能够准确生成此类交互数据，并（ii）探讨这些合成数据是否可以用于预先训练自适应政治调查的统计模型。为了评估这一方法，我们利用瑞士投票建议应用（VAA）Smartvote的现有数据，采用两种方式：首先，我们将LLM生成的合成数据分布与实际数据的分布进行比较以评估其相似度；其次，我们将一个随机初始化的自适应问卷与一个预先训练在合成数据上的自适应问卷进行比较，评估它们的训练适用性。我们将这些结果与一个具有先验完美知识的“顾问”问卷进行了对比。我们发现，现成的LLM（GPT-4）能够从瑞士不同政党的视角准确生成Smartvote问卷的答案。此外，我们展示了使用合成数据初始化统计模型可以（i）显著减少预测用户响应的误差，并且（ii）提高VAA的候选人推荐准确性。我们的工作强调了大型语言模型在自适应问卷中创建训练数据的巨大潜力，特别是在政治调查等LLM相关领域，以改善数据收集过程。', 'title_zh': '自适应政治调查与GPT-4：通过模拟用户交互解决冷启动问题'}
{'arxiv_id': 'arXiv:2503.09309', 'title': 'Steering No-Regret Agents in MFGs under Model Uncertainty', 'authors': 'Leo Widmer, Jiawei Huang, Niao He', 'link': 'https://arxiv.org/abs/2503.09309', 'abstract': "Incentive design is a popular framework for guiding agents' learning dynamics towards desired outcomes by providing additional payments beyond intrinsic rewards. However, most existing works focus on a finite, small set of agents or assume complete knowledge of the game, limiting their applicability to real-world scenarios involving large populations and model uncertainty. To address this gap, we study the design of steering rewards in Mean-Field Games (MFGs) with density-independent transitions, where both the transition dynamics and intrinsic reward functions are unknown. This setting presents non-trivial challenges, as the mediator must incentivize the agents to explore for its model learning under uncertainty, while simultaneously steer them to converge to desired behaviors without incurring excessive incentive payments. Assuming agents exhibit no(-adaptive) regret behaviors, we contribute novel optimistic exploration algorithms. Theoretically, we establish sub-linear regret guarantees for the cumulative gaps between the agents' behaviors and the desired ones. In terms of the steering cost, we demonstrate that our total incentive payments incur only sub-linear excess, competing with a baseline steering strategy that stabilizes the target policy as an equilibrium. Our work presents an effective framework for steering agents behaviors in large-population systems under uncertainty.", 'abstract_zh': '基于密度无关转换的均场博弈引导奖励设计', 'title_zh': '在模型不确定性下的MFG中引导无遗憾代理'}
{'arxiv_id': 'arXiv:2503.09289', 'title': 'Unmask It! AI-Generated Product Review Detection in Dravidian Languages', 'authors': 'Somsubhra De, Advait Vats', 'link': 'https://arxiv.org/abs/2503.09289', 'abstract': 'The rise of Generative AI has led to a surge in AI-generated reviews, often posing a serious threat to the credibility of online platforms. Reviews serve as the primary source of information about products and services. Authentic reviews play a vital role in consumer decision-making. The presence of fabricated content misleads consumers, undermines trust and facilitates potential fraud in digital marketplaces. This study focuses on detecting AI-generated product reviews in Tamil and Malayalam, two low-resource languages where research in this domain is relatively under-explored. We worked on a range of approaches - from traditional machine learning methods to advanced transformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and MalayalamBERT. Our findings highlight the effectiveness of leveraging the state-of-the-art transformers in accurately identifying AI-generated content, demonstrating the potential in enhancing the detection of fake reviews in low-resource language settings.', 'abstract_zh': '生成式AI的兴起导致了AI生成的评论大量涌现，这对在线平台的可信度构成了严重威胁。评论是关于产品和服务的主要信息来源。真实的评论在消费者决策中起着至关重要的作用。虚假内容的存在误导消费者，损害信任，促进数字市场中的潜在欺诈行为。本研究专注于检测泰米尔语和马拉雅拉姆语中的AI生成的产品评论，这两种语言在该领域相对较缺乏相关研究。我们采用了从传统机器学习方法到先进变换器模型（如Indic-BERT、IndicSBERT、MuRIL、XLM-RoBERTa和MalayalamBERT）的多种方法。我们的研究结果强调了利用最先进的变换器模型准确识别AI生成内容的有效性，展示了在低资源语言环境中增强假评论检测的潜在可能性。', 'title_zh': '揭开面纱！印第安语系生成的产品评论检测'}
{'arxiv_id': 'arXiv:2503.09277', 'title': 'UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer', 'authors': 'Haoxuan Wang, Jinlong Peng, Qingdong He, Hao Yang, Ying Jin, Jiafu Wu, Xiaobin Hu, Yanjie Pan, Zhenye Gan, Mingmin Chi, Bo Peng, Yabiao Wang', 'link': 'https://arxiv.org/abs/2503.09277', 'abstract': 'With the rapid development of diffusion models in image generation, the demand for more powerful and flexible controllable frameworks is increasing. Although existing methods can guide generation beyond text prompts, the challenge of effectively combining multiple conditional inputs while maintaining consistency with all of them remains unsolved. To address this, we introduce UniCombine, a DiT-based multi-conditional controllable generative framework capable of handling any combination of conditions, including but not limited to text prompts, spatial maps, and subject images. Specifically, we introduce a novel Conditional MMDiT Attention mechanism and incorporate a trainable LoRA module to build both the training-free and training-based versions. Additionally, we propose a new pipeline to construct SubjectSpatial200K, the first dataset designed for multi-conditional generative tasks covering both the subject-driven and spatially-aligned conditions. Extensive experimental results on multi-conditional generation demonstrate the outstanding universality and powerful capability of our approach with state-of-the-art performance.', 'abstract_zh': '基于DiT的多条件可控生成框架UniCombine及其应用', 'title_zh': 'UniCombine: 统一多条件组合的扩散变换器方法'}
{'arxiv_id': 'arXiv:2503.09269', 'title': 'Single-Qudit Quantum Neural Networks for Multiclass Classification', 'authors': 'Leandro C. Souza, Renato Portugal', 'link': 'https://arxiv.org/abs/2503.09269', 'abstract': 'This paper proposes a single-qudit quantum neural network for multiclass classification, by using the enhanced representational capacity of high-dimensional qudit states. Our design employs an $d$-dimensional unitary operator, where $d$ corresponds to the number of classes, constructed using the Cayley transform of a skew-symmetric matrix, to efficiently encode and process class information. This architecture enables a direct mapping between class labels and quantum measurement outcomes, reducing circuit depth and computational overhead. To optimize network parameters, we introduce a hybrid training approach that combines an extended activation function -- derived from a truncated multivariable Taylor series expansion -- with support vector machine optimization for weight determination. We evaluate our model on the MNIST and EMNIST datasets, demonstrating competitive accuracy while maintaining a compact single-qudit quantum circuit. Our findings highlight the potential of qudit-based QNNs as scalable alternatives to classical deep learning models, particularly for multiclass classification. However, practical implementation remains constrained by current quantum hardware limitations. This research advances quantum machine learning by demonstrating the feasibility of higher-dimensional quantum systems for efficient learning tasks.', 'abstract_zh': '这种论文提出了一种用于多类分类的单ubits量子神经网络，通过利用高维qudit状态的增强表示能力。设计采用了$d$维酉算子，其中$d$对应于类别的数量，并使用辛矩阵的凯莱变换构建，以高效地编码和处理类别信息。该架构使得类别标签可以直接映射到量子测量结果，从而减少了电路深度和计算开销。为了优化网络参数，引入了一种混合训练方法，该方法结合了扩展激活函数——源自截断的多元泰勒级数展开——与支持向量机优化以确定权重。我们在MNIST和EMNIST数据集上评估了我们的模型，展示了其在保持紧凑的单ubits量子电路的同时保持竞争力的精度。我们的研究结果突显了基于qudit的QNNs作为可扩展的替代经典深度学习模型的潜在优势，特别是在多类分类方面。然而，实际实施仍受限于当前量子硬件的限制。这项研究通过证明高效学习任务中高维量子系统可行性，推进了量子机器学习的发展。', 'title_zh': '单量子位量子神经网络的多类分类'}
{'arxiv_id': 'arXiv:2503.09257', 'title': 'DeepInnovation AI: A Global Dataset Mapping the AI innovation and technology Transfer from Academic Research to Industrial Patents', 'authors': 'Haixing Gong, Hui Zou, Xingzhou Liang, Shiyuan Meng, Pinlong Cai, Xingcheng Xu, Jingjing Qu', 'link': 'https://arxiv.org/abs/2503.09257', 'abstract': 'In the rapidly evolving field of artificial intelligence (AI), mapping innovation patterns and understanding effective technology transfer from academic research to practical applications are essential for economic growth. This paper introduces DeepInnovationAI, the first comprehensive global dataset designed to bridge the gap between academic papers and industrial patents. However, existing data infrastructures face three major limitations: fragmentation, incomplete coverage, and insufficient evaluative capacity. Here, we present DeepInnovationAI, a comprehensive global dataset documenting AI innovation trajectories. The dataset comprises three structured files: this http URL: Contains 2,356,204 patent records with 8 field-specific attributes. this http URL: Encompasses 3,511,929 academic publications with 13 metadata fields. These two datasets employ large language models, multilingual text analysis and dual-layer BERT classifiers to accurately identify AI-related content and utilizing hypergraph analysis methods to create robust innovation metrics. In addition, this http URL: By applying semantic vector proximity analysis, this file presents approximately one hundred million calculated paper-patent similarity pairs to enhance understanding of how theoretical advancements translate into commercial technologies. This enables researchers, policymakers, and industry leaders to anticipate trends and identify emerging areas for collaboration. With its extensive temporal and geographical scope, DeepInnovationAI supports detailed analysis of technological development patterns and international competition dynamics, providing a robust foundation for modeling AI innovation dynamics and technology transfer processes.', 'abstract_zh': '在快速发展的人工智能（AI）领域，映射创新模式并理解从学术研究向实际应用的有效技术转移对于经济增长至关重要。本文介绍了DeepInnovationAI，这是首个旨在连接学术论文与工业专利的全面全球数据集。然而，现有数据基础设施面临三大局限：碎片化、覆盖不完整和评价能力不足。本文介绍了DeepInnovationAI，这是一个全面的全球数据集，记录了AI创新轨迹。该数据集包含三个结构化的文件：该文件包含2,356,204项专利记录，附有8个领域特定属性；该文件包含3,511,929篇学术出版物，附有13个元数据字段；这两个数据集利用大型语言模型、多语言文本分析和双层BERT分类器准确识别与AI相关内容，并运用超图分析方法生成稳健的创新度量。此外，该文件通过语义向量接近性分析，展示了大约一亿个计算出的文章-专利相似性对，以增强对理论进步转化为商业技术的理解。这使得研究人员、政策制定者和行业领导者能够预见趋势并识别潜在的合作领域。DeepInnovationAI的广泛时间和地理范围支持对技术发展模式和国际竞争动态的详细分析，为其建模AI创新动态和技术转移过程提供了坚实基础。', 'title_zh': 'DeepInnovation AI：一种全球数据集，映射从学术研究到工业专利的AI创新和技术转移'}
{'arxiv_id': 'arXiv:2503.09251', 'title': 'SCOPE-DTI: Semi-Inductive Dataset Construction and Framework Optimization for Practical Usability Enhancement in Deep Learning-Based Drug Target Interaction Prediction', 'authors': 'Yigang Chen, Xiang Ji, Ziyue Zhang, Yuming Zhou, Yang-Chi-Dung Lin, Hsi-Yuan Huang, Tao Zhang, Yi Lai, Ke Chen, Chang Su, Xingqiao Lin, Zihao Zhu, Yanggyi Zhang, Kangping Wei, Jiehui Fu, Yixian Huang, Shidong Cui, Shih-Chung Yen, Ariel Warshel, Hsien-Da Huang', 'link': 'https://arxiv.org/abs/2503.09251', 'abstract': 'Deep learning-based drug-target interaction (DTI) prediction methods have demonstrated strong performance; however, real-world applicability remains constrained by limited data diversity and modeling complexity. To address these challenges, we propose SCOPE-DTI, a unified framework combining a large-scale, balanced semi-inductive human DTI dataset with advanced deep learning modeling. Constructed from 13 public repositories, the SCOPE dataset expands data volume by up to 100-fold compared to common benchmarks such as the Human dataset. The SCOPE model integrates three-dimensional protein and compound representations, graph neural networks, and bilinear attention mechanisms to effectively capture cross domain interaction patterns, significantly outperforming state-of-the-art methods across various DTI prediction tasks. Additionally, SCOPE-DTI provides a user-friendly interface and database. We further validate its effectiveness by experimentally identifying anticancer targets of Ginsenoside Rh1. By offering comprehensive data, advanced modeling, and accessible tools, SCOPE-DTI accelerates drug discovery research.', 'abstract_zh': '基于深度学习的药物-目标相互作用（DTI）预测方法已经展现出了强大的性能，但实际应用受到有限的数据多样性和建模复杂性的限制。为了解决这些挑战，我们提出SCOPE-DTI，一种结合大规模平衡半归纳人类DTI数据集和高级深度学习建模的统一框架。该数据集由13个公共存储库构建而成，相较于常见的基准数据集（如Human数据集），数据量扩展了100倍。SCOPE模型结合了三维蛋白质和化合物表示、图神经网络和双线性注意力机制，有效捕获跨域相互作用模式，在各种DTI预测任务中显著优于最先进的方法。此外，SCOPE-DTI提供了一个用户友好的界面和数据库。我们通过实验进一步验证了其有效性，通过识别 Ginsenoside Rh1 的抗癌目标进行了实证验证。通过提供全面的数据、先进的建模和可访问的工具，SCOPE-DTI 加速了药物发现研究。', 'title_zh': 'SCOPE-DTI：基于半归纳数据集构建及框架优化的深度学习药物靶标相互作用预测实用性能增强方法'}
{'arxiv_id': 'arXiv:2503.09249', 'title': 'Considering Length Diversity in Retrieval-Augmented Summarization', 'authors': 'Juseon-Do, Jaesung Hwang, Jingun Kwon, Hidetaka Kamigaito, Manabu Okumura', 'link': 'https://arxiv.org/abs/2503.09249', 'abstract': 'This study investigates retrieval-augmented summarization by specifically examining the impact of exemplar summary lengths under length constraints, not covered by previous work. We propose a Diverse Length-aware Maximal Marginal Relevance (DL-MMR) algorithm to better control summary lengths. This algorithm combines the query relevance with diverse target lengths in retrieval-augmented summarization. Unlike previous methods that necessitate exhaustive exemplar exemplar relevance comparisons using MMR, DL-MMR considers the exemplar target length as well and avoids comparing exemplars to each other, thereby reducing computational cost and conserving memory during the construction of an exemplar pool. Experimental results showed the effectiveness of DL-MMR, which considers length diversity, compared to the original MMR algorithm. DL-MMR additionally showed the effectiveness in memory saving of 781,513 times and computational cost reduction of 500,092 times, while maintaining the same level of informativeness.', 'abstract_zh': '本研究通过在长度约束下特别探讨范例总结长度的影响，以考察检索增强总结的方法。我们提出了一种多样长度感知最大边际相关性（DL-MMR）算法，以更好地控制总结长度。该算法将检索增强总结中的查询相关性和多样目标长度相结合。与以往需要使用最大边际相关性（MMR）进行 exhaustive 的范例相关性比较的方法不同，DL-MMR 考虑了范例的目标长度，并避免了范例之间的比较，从而在构建范例池的过程中减少了计算成本并节省了内存。实验结果表明，与原始 MMR 算法相比，DL-MMR 在考虑长度多样性方面更为有效。DL-MMR 还在节省内存方面提高了 781,513 倍，在计算成本方面降低了 500,092 倍，同时保持了相同的信息量。', 'title_zh': '考虑检索增强总结中的长度多样性'}
{'arxiv_id': 'arXiv:2503.09223', 'title': 'LREF: A Novel LLM-based Relevance Framework for E-commerce', 'authors': 'Tian Tang, Zhixing Tian, Zhenyu Zhu, Chenyang Wang, Haiqing Hu, Guoyu Tang, Lin Liu, Sulong Xu', 'link': 'https://arxiv.org/abs/2503.09223', 'abstract': 'Query and product relevance prediction is a critical component for ensuring a smooth user experience in e-commerce search. Traditional studies mainly focus on BERT-based models to assess the semantic relevance between queries and products. However, the discriminative paradigm and limited knowledge capacity of these approaches restrict their ability to comprehend the relevance between queries and products fully. With the rapid advancement of Large Language Models (LLMs), recent research has begun to explore their application to industrial search systems, as LLMs provide extensive world knowledge and flexible optimization for reasoning processes. Nonetheless, directly leveraging LLMs for relevance prediction tasks introduces new challenges, including a high demand for data quality, the necessity for meticulous optimization of reasoning processes, and an optimistic bias that can result in over-recall. To overcome the above problems, this paper proposes a novel framework called the LLM-based RElevance Framework (LREF) aimed at enhancing e-commerce search relevance. The framework comprises three main stages: supervised fine-tuning (SFT) with Data Selection, Multiple Chain of Thought (Multi-CoT) tuning, and Direct Preference Optimization (DPO) for de-biasing. We evaluate the performance of the framework through a series of offline experiments on large-scale real-world datasets, as well as online A/B testing. The results indicate significant improvements in both offline and online metrics. Ultimately, the model was deployed in a well-known e-commerce application, yielding substantial commercial benefits.', 'abstract_zh': '基于大规模语言模型的查询与产品相关性框架（LREF）研究', 'title_zh': 'LREF：一种基于大语言模型的相关性框架在电子商务中的应用'}
{'arxiv_id': 'arXiv:2503.09217', 'title': 'Evaluating the Generalizability of LLMs in Automated Program Repair', 'authors': 'Fengjie Li, Jiajun Jiang, Jiajun Sun, Hongyu Zhang', 'link': 'https://arxiv.org/abs/2503.09217', 'abstract': "LLM-based automated program repair methods have attracted significant attention for their state-of-the-art performance. However, they were primarily evaluated on a few well known datasets like Defects4J, raising questions about their effectiveness on new datasets. In this study, we evaluate 11 top-performing LLMs on DEFECTS4J-TRANS, a new dataset derived from transforming Defects4J while maintaining the original semantics. Results from experiments on both Defects4J and DEFECTS4J-TRANS show that all studied LLMs have limited generalizability in APR tasks, with the average number of correct and plausible patches decreasing by 49.48% and 42.90%, respectively, on DEFECTS4J-TRANS. Further investigation into incorporating additional repair-relevant information in repair prompts reveals that, although this information significantly enhances the LLMs' capabilities (increasing the number of correct and plausible patches by up to 136.67% and 121.82%, respectively), performance still falls short of their original results. This indicates that prompt engineering alone is insufficient to substantially enhance LLMs' repair capabilities. Based on our study, we also offer several recommendations for future research.", 'abstract_zh': '基于LLM的自动化程序修复方法在新数据集上的有效性研究', 'title_zh': '评估大规模语言模型在自动化程序修复中的泛化能力'}
{'arxiv_id': 'arXiv:2503.09215', 'title': 'Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latant Space', 'authors': 'Jian Zhu, Zhengyu Jia, Tian Gao, Jiaxin Deng, Shidi Li, Fu Liu, Peng Jia, Xianpeng Lang, Xiaolong Sun', 'link': 'https://arxiv.org/abs/2503.09215', 'abstract': "Advanced end-to-end autonomous driving systems predict other vehicles' motions and plan ego vehicle's trajectory. The world model that can foresee the outcome of the trajectory has been used to evaluate the end-to-end autonomous driving system. However, existing world models predominantly emphasize the trajectory of the ego vehicle and leave other vehicles uncontrollable. This limitation hinders their ability to realistically simulate the interaction between the ego vehicle and the driving scenario. In addition, it remains a challenge to match multiple trajectories with each vehicle in the video to control the video generation. To address above issues, a driving \\textbf{W}orld \\textbf{M}odel named EOT-WM is proposed in this paper, unifying \\textbf{E}go-\\textbf{O}ther vehicle \\textbf{T}rajectories in videos. Specifically, we first project ego and other vehicle trajectories in the BEV space into the image coordinate to match each trajectory with its corresponding vehicle in the video. Then, trajectory videos are encoded by the Spatial-Temporal Variational Auto Encoder to align with driving video latents spatially and temporally in the unified visual space. A trajectory-injected diffusion Transformer is further designed to denoise the noisy video latents for video generation with the guidance of ego-other vehicle trajectories. In addition, we propose a metric based on control latent similarity to evaluate the controllability of trajectories. Extensive experiments are conducted on the nuScenes dataset, and the proposed model outperforms the state-of-the-art method by 30\\% in FID and 55\\% in FVD. The model can also predict unseen driving scenes with self-produced trajectories.", 'abstract_zh': '高级端到端自主驾驶系统预测其他车辆的运动并规划ego车辆的轨迹。为了评估端到端自主驾驶系统，已经使用了能够预见轨迹结果的世界模型。然而，现有的世界模型主要侧重于ego车辆的轨迹，而忽略了其他车辆的轨迹控制。这一限制阻碍了它们在统一视觉空间中真实模拟ego车辆与驾驶场景之间交互的能力。此外，将视频中多条轨迹与每辆车匹配以控制视频生成仍是一项挑战。为了解决上述问题，本文提出了一种名为EOT-WM的驾驶世界模型，统一了视频中的ego-others车辆轨迹。具体地，首先将ego和其他车辆轨迹在BEV空间中投影到图像坐标系中，以便将每条轨迹与其对应的车辆在视频中匹配。然后，通过时空变分自编码器对轨迹视频进行编码，使其在统一的视觉空间中与驾驶视频的空时特征对齐。进一步设计了一种轨迹注入的扩散变压器，以根据ego-others车辆轨迹对噪声的视频特征进行去噪，以指导视频生成。此外，我们提出了一种基于控制隐藏特征相似性的度量，以评估轨迹的可控性。在nuScenes数据集上进行了广泛的实验，所提模型在FID上优于最先进的方法30%，在FVD上优于55%。该模型还可以使用自生成的轨迹预测未见过的驾驶场景。', 'title_zh': '其他车辆轨迹同样重要：一个驾驶世界模型在视频隐空间中统一了本体车辆和其他车辆的轨迹'}
{'arxiv_id': 'arXiv:2503.09206', 'title': 'Robust Asymmetric Heterogeneous Federated Learning with Corrupted Clients', 'authors': 'Xiuwen Fang, Mang Ye, Bo Du', 'link': 'https://arxiv.org/abs/2503.09206', 'abstract': 'This paper studies a challenging robust federated learning task with model heterogeneous and data corrupted clients, where the clients have different local model structures. Data corruption is unavoidable due to factors such as random noise, compression artifacts, or environmental conditions in real-world deployment, drastically crippling the entire federated system. To address these issues, this paper introduces a novel Robust Asymmetric Heterogeneous Federated Learning (RAHFL) framework. We propose a Diversity-enhanced supervised Contrastive Learning technique to enhance the resilience and adaptability of local models on various data corruption patterns. Its basic idea is to utilize complex augmented samples obtained by the mixed-data augmentation strategy for supervised contrastive learning, thereby enhancing the ability of the model to learn robust and diverse feature representations. Furthermore, we design an Asymmetric Heterogeneous Federated Learning strategy to resist corrupt feedback from external clients. The strategy allows clients to perform selective one-way learning during collaborative learning phase, enabling clients to refrain from incorporating lower-quality information from less robust or underperforming collaborators. Extensive experimental results demonstrate the effectiveness and robustness of our approach in diverse, challenging federated learning environments. Our code and models are public available at this https URL.', 'abstract_zh': '这篇论文研究了一个具有模型异构和数据污染客户的挑战性鲁棒联邦学习任务，其中客户具有不同的本地模型结构。由于实际情况中随机噪声、压缩_artifacts_或环境条件等因素引起的_data_corruption_不可避免，严重削弱了整个联邦系统。为了解决这些问题，本文引入了一个新的鲁棒非对称异构联邦学习（RAHFL）框架。我们提出了增强监督对比学习技术来增强本地模型在各种数据污染模式下的鲁棒性和适应性。其基本思想是利用通过混合数据增强策略获得的复杂增强样本进行监督对比学习，从而增强模型学习稳健且多样特征表示的能力。此外，我们设计了一种非对称异构联邦学习策略来抵抗外部客户提供的污染反馈。该策略使得客户在协作学习阶段可以选择性地进行单向学习，从而避免整合来自较不鲁棒或表现较差合作方的低质量信息。大量实验结果表明，我们的方法在多种挑战性的联邦学习环境中具有有效性和鲁棒性。我们的代码和模型可在以下链接公开获取。', 'title_zh': '鲁棒的有损客户端异构联邦学习'}
{'arxiv_id': 'arXiv:2503.09199', 'title': 'GENEOnet: Statistical analysis supporting explainability and trustworthiness', 'authors': 'Giovanni Bocchi, Patrizio Frosini, Alessandra Micheletti, Alessandro Pedretti, Carmen Gratteri, Filippo Lunghini, Andrea Rosario Beccari, Carmine Talarico', 'link': 'https://arxiv.org/abs/2503.09199', 'abstract': "Group Equivariant Non-Expansive Operators (GENEOs) have emerged as mathematical tools for constructing networks for Machine Learning and Artificial Intelligence. Recent findings suggest that such models can be inserted within the domain of eXplainable Artificial Intelligence (XAI) due to their inherent interpretability. In this study, we aim to verify this claim with respect to GENEOnet, a GENEO network developed for an application in computational biochemistry by employing various statistical analyses and experiments. Such experiments first allow us to perform a sensitivity analysis on GENEOnet's parameters to test their significance. Subsequently, we show that GENEOnet exhibits a significantly higher proportion of equivariance compared to other methods. Lastly, we demonstrate that GENEOnet is on average robust to perturbations arising from molecular dynamics. These results collectively serve as proof of the explainability, trustworthiness, and robustness of GENEOnet and confirm the beneficial use of GENEOs in the context of Trustworthy Artificial Intelligence.", 'abstract_zh': 'Group Equivariant Non-Expansive Operators (GENEOs)在机器学习和人工智能中的应用：以GENEO网络为例的解释性、可靠性和稳健性验证', 'title_zh': 'GENEOnet: 统计分析支持可解释性和可信度'}
{'arxiv_id': 'arXiv:2503.09173', 'title': 'Long-Term Planning Around Humans in Domestic Environments with 3D Scene Graphs', 'authors': 'Ermanno Bartoli, Dennis Rotondi, Kai O. Arras, Iolanda Leite', 'link': 'https://arxiv.org/abs/2503.09173', 'abstract': 'Long-term planning for robots operating in domestic environments poses unique challenges due to the interactions between humans, objects, and spaces. Recent advancements in trajectory planning have leveraged vision-language models (VLMs) to extract contextual information for robots operating in real-world environments. While these methods achieve satisfying performance, they do not explicitly model human activities. Such activities influence surrounding objects and reshape spatial constraints. This paper presents a novel approach to trajectory planning that integrates human preferences, activities, and spatial context through an enriched 3D scene graph (3DSG) representation. By incorporating activity-based relationships, our method captures the spatial impact of human actions, leading to more context-sensitive trajectory adaptation. Preliminary results demonstrate that our approach effectively assigns costs to spaces influenced by human activities, ensuring that the robot trajectory remains contextually appropriate and sensitive to the ongoing environment. This balance between task efficiency and social appropriateness enhances context-aware human-robot interactions in domestic settings. Future work includes implementing a full planning pipeline and conducting user studies to evaluate trajectory acceptability.', 'abstract_zh': '长期规划家居环境中的机器人操作面临独特挑战，由于人类、物体和空间的交互。近期轨迹规划的进步利用了视觉-语言模型（VLMs）来提取机器人在现实世界环境中操作所需的背景信息。尽管这些方法取得了令人满意的效果，但它们并未明确建模人类活动。这些活动影响周围的物体并重塑空间约束。本文提出了一种新的轨迹规划方法，通过增强的3D场景图（3DSG）表示整合了人类偏好、活动和空间上下文。通过结合基于活动的关系，我们的方法捕捉到了人类行为的空间影响，从而实现了更具上下文敏感性的轨迹适应。初步结果表明，我们的方法有效地为受人类活动影响的空间分配了成本，确保了机器人轨迹在上下文中具有适当的适应性和对当前环境的敏感性。这种任务效率与社会适宜性的平衡增强了家居环境中的人机交互。未来工作包括实现完整的规划管道并进行用户研究以评估轨迹可接受性。', 'title_zh': '在家庭环境中基于3D场景图的人机长期规划'}
{'arxiv_id': 'arXiv:2503.09153', 'title': 'Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News Detection', 'authors': 'Chaowei Zhang, Zongling Feng, Zewei Zhang, Jipeng Qiang, Guandong Xu, Yun Li', 'link': 'https://arxiv.org/abs/2503.09153', 'abstract': "The questionable responses caused by knowledge hallucination may lead to LLMs' unstable ability in decision-making. However, it has never been investigated whether the LLMs' hallucination is possibly usable to generate negative reasoning for facilitating the detection of fake news. This study proposes a novel supervised self-reinforced reasoning rectification approach - SR$^3$ that yields both common reasonable reasoning and wrong understandings (negative reasoning) for news via LLMs reflection for semantic consistency learning. Upon that, we construct a negative reasoning-based news learning model called - \\emph{NRFE}, which leverages positive or negative news-reasoning pairs for learning the semantic consistency between them. To avoid the impact of label-implicated reasoning, we deploy a student model - \\emph{NRFE-D} that only takes news content as input to inspect the performance of our method by distilling the knowledge from \\emph{NRFE}. The experimental results verified on three popular fake news datasets demonstrate the superiority of our method compared with three kinds of baselines including prompting on LLMs, fine-tuning on pre-trained SLMs, and other representative fake news detection methods.", 'abstract_zh': '知识幻觉引起的可疑响应可能导致LLMs在决策方面的能力不稳定。然而，尚未研究LLMs的幻觉是否可能用于生成否定推理，以促进fake news的检测。本研究提出了一种新颖的监督自我增强推理校正方法——SR$^3$，该方法通过LLMs的反思生成新闻的合理推理和错误理解（否定推理），以实现语义一致性学习。在此基础上，我们构建了一种基于否定推理的新闻学习模型——NRFE，该模型利用正向或负向新闻推理配对来学习它们之间的语义一致性。为了避免标签相关推理的影响，我们部署了一种学生模型——NRFE-D，该模型仅接受新闻内容作为输入，通过从NRFE中提取知识来检验我们方法的性能。实验结果在三个流行的fake news数据集上验证了我们的方法优于三种基线，包括对LLMs的提示、在预训练SLMs上微调以及其他代表性的fake news检测方法。', 'title_zh': '基于LLM的负向推理在假新闻检测中的实用性探究'}
{'arxiv_id': 'arXiv:2503.09151', 'title': 'Reangle-A-Video: 4D Video Generation as Video-to-Video Translation', 'authors': 'Hyeonho Jeong, Suhyeon Lee, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2503.09151', 'abstract': 'We introduce Reangle-A-Video, a unified framework for generating synchronized multi-view videos from a single input video. Unlike mainstream approaches that train multi-view video diffusion models on large-scale 4D datasets, our method reframes the multi-view video generation task as video-to-videos translation, leveraging publicly available image and video diffusion priors. In essence, Reangle-A-Video operates in two stages. (1) Multi-View Motion Learning: An image-to-video diffusion transformer is synchronously fine-tuned in a self-supervised manner to distill view-invariant motion from a set of warped videos. (2) Multi-View Consistent Image-to-Images Translation: The first frame of the input video is warped and inpainted into various camera perspectives under an inference-time cross-view consistency guidance using DUSt3R, generating multi-view consistent starting images. Extensive experiments on static view transport and dynamic camera control show that Reangle-A-Video surpasses existing methods, establishing a new solution for multi-view video generation. We will publicly release our code and data. Project page: this https URL', 'abstract_zh': '我们介绍了Reangle-A-Video，这是一种生成单输入视频同步多视角视频的统一框架。与主流方法通过大规模4D数据集训练多视角视频扩散模型不同，我们的方法将多视角视频生成任务重新 framing 为视频到视频的翻译，利用公开可用的图像和视频扩散先验。本质上，Reangle-A-Video 分为两个阶段进行。 (1) 多视角运动学习：一个图像到视频的扩散变换器在自我监督的方式下同步微调，以从一组变形视频中提炼出视点不变的运动。 (2) 多视角一致的图像到图像翻译：在推理时跨视角一致性指导之下，使用DUSt3R将输入视频的首帧变形并填补到各种摄像机视角，生成多视角一致的起始图像。广泛的静态视图传输和动态摄像机控制实验表明，Reangle-A-Video 超越了现有方法，为多视角视频生成提供了新的解决方案。我们将公开发布我们的代码和数据。项目页面：这个\xa0https://链接URL。', 'title_zh': 'Reangle-A-Video: 视频到视频的4D视频生成'}
{'arxiv_id': 'arXiv:2503.09144', 'title': 'Efficient UAV Swarm-Based Multi-Task Federated Learning with Dynamic Task Knowledge Sharing', 'authors': 'Yubo Yang, Tao Yang, Xiaofeng Wu, Ziyu Guo, Bo Hu', 'link': 'https://arxiv.org/abs/2503.09144', 'abstract': 'UAV swarms are widely used in emergency communications, area monitoring, and disaster relief. Coordinated by control centers, they are ideal for federated learning (FL) frameworks. However, current UAV-assisted FL methods primarily focus on single tasks, overlooking the need for multi-task training. In disaster relief scenarios, UAVs perform tasks such as crowd detection, road feasibility analysis, and disaster assessment, which exhibit time-varying demands and potential correlations. In order to meet the time-varying requirements of tasks and complete multiple tasks efficiently under resource constraints, in this paper, we propose a UAV swarm based multi-task FL framework, where ground emergency vehicles (EVs) collaborate with UAVs to accomplish multiple tasks efficiently under constrained energy and bandwidth resources. Through theoretical analysis, we identify key factors affecting task performance and introduce a task attention mechanism to dynamically evaluate task importance, thereby achieving efficient resource allocation. Additionally, we propose a task affinity (TA) metric to capture the dynamic correlation among tasks, thereby promoting task knowledge sharing to accelerate training and improve the generalization ability of the model in different scenarios. To optimize resource allocation, we formulate a two-layer optimization problem to jointly optimize UAV transmission power, computation frequency, bandwidth allocation, and UAV-EV associations. For the inner problem, we derive closed-form solutions for transmission power, computation frequency, and bandwidth allocation and apply a block coordinate descent method for optimization. For the outer problem, a two-stage algorithm is designed to determine optimal UAV-EV associations. Furthermore, theoretical analysis reveals a trade-off between UAV energy consumption and multi-task performance.', 'abstract_zh': '基于UAV蜂群的多任务联邦学习框架：结合地面应急车辆实现资源约束下的高效任务协同', 'title_zh': '基于动态任务知识共享的高效无人机集群多任务 federated 学习'}
{'arxiv_id': 'arXiv:2503.09132', 'title': 'Investigation of Frame Differences as Motion Cues for Video Object Segmentation', 'authors': 'Sota Kawamura, Hirotada Honda, Shugo Nakamura, Takashi Sano', 'link': 'https://arxiv.org/abs/2503.09132', 'abstract': 'Automatic Video Object Segmentation (AVOS) refers to the task of autonomously segmenting target objects in video sequences without relying on human-provided annotations in the first frames. In AVOS, the use of motion information is crucial, with optical flow being a commonly employed method for capturing motion cues. However, the computation of optical flow is resource-intensive, making it unsuitable for real-time applications, especially on edge devices with limited computational resources. In this study, we propose using frame differences as an alternative to optical flow for motion cue extraction. We developed an extended U-Net-like AVOS model that takes a frame on which segmentation is performed and a frame difference as inputs, and outputs an estimated segmentation map. Our experimental results demonstrate that the proposed model achieves performance comparable to the model with optical flow as an input, particularly when applied to videos captured by stationary cameras. Our results suggest the usefulness of employing frame differences as motion cues in cases with limited computational resources.', 'abstract_zh': '自动视频对象分割（AVOS）是指在视频序列中自主分割目标对象的任务，而无需依赖人类提供的初始帧注释。在AVOS中，运动信息的使用至关重要，光学流是常用的方法之一，用于捕捉运动线索。然而，计算光学流资源密集，使其不适合实时应用，特别是在计算资源受限的边缘设备上。在本研究中，我们提出了使用帧差异作为替代方法来提取运动线索。我们开发了一种扩展的类似U-Net的AVOS模型，该模型将用于分割的帧和帧差异作为输入，并输出估计的分割图。我们的实验结果表明，所提出模型在应用到由固定摄像机拍摄的视频时，其性能与将光学流作为输入的模型相当。我们的结果表明，在计算资源有限的情况下，使用帧差异作为运动线索具有实用性。', 'title_zh': '帧差异在视频物体分割中的运动线索研究'}
{'arxiv_id': 'arXiv:2503.09120', 'title': 'On the Internal Representations of Graph Metanetworks', 'authors': 'Taesun Yeom, Jaeho Lee', 'link': 'https://arxiv.org/abs/2503.09120', 'abstract': 'Weight space learning is an emerging paradigm in the deep learning community. The primary goal of weight space learning is to extract informative features from a set of parameters using specially designed neural networks, often referred to as \\emph{metanetworks}. However, it remains unclear how these metanetworks learn solely from parameters. To address this, we take the first step toward understanding \\emph{representations} of metanetworks, specifically graph metanetworks (GMNs), which achieve state-of-the-art results in this field, using centered kernel alignment (CKA). Through various experiments, we reveal that GMNs and general neural networks (\\textit{e.g.,} multi-layer perceptrons (MLPs) and convolutional neural networks (CNNs)) differ in terms of their representation space.', 'abstract_zh': '权重空间学习是深度学习领域的一个新兴范式。权重空间学习的主要目标是使用特设的神经网络（通常称为元网络）从一组参数中提取富有信息性的特征。然而，尚不清楚这些元网络仅从参数中是如何学习的。为了解决这一问题，我们首次尝试通过中心核对齐（CKA）来理解元网络的表示，特别是达到该领域最佳效果的图元网络（GMNs）。通过各种实验，我们发现GMNs与通用神经网络（例如，多层感知机（MLPs）和卷积神经网络（CNNs））在表示空间上存在差异。', 'title_zh': '关于图超网络的内部表示'}
{'arxiv_id': 'arXiv:2503.09114', 'title': 'Sometimes Painful but Certainly Promising: Feasibility and Trade-offs of Language Model Inference at the Edge', 'authors': 'Maximilian Abstreiter, Sasu Tarkoma, Roberto Morabito', 'link': 'https://arxiv.org/abs/2503.09114', 'abstract': 'The rapid rise of Language Models (LMs) has expanded the capabilities of natural language processing, powering applications from text generation to complex decision-making. While state-of-the-art LMs often boast hundreds of billions of parameters and are primarily deployed in data centers, recent trends show a growing focus on compact models-typically under 10 billion parameters-enabled by techniques such as quantization and other model compression techniques. This shift paves the way for LMs on edge devices, offering potential benefits such as enhanced privacy, reduced latency, and improved data sovereignty. However, the inherent complexity of even these smaller models, combined with the limited computing resources of edge hardware, raises critical questions about the practical trade-offs in executing LM inference outside the cloud. To address these challenges, we present a comprehensive evaluation of generative LM inference on representative CPU-based and GPU-accelerated edge devices. Our study measures key performance indicators-including memory usage, inference speed, and energy consumption-across various device configurations. Additionally, we examine throughput-energy trade-offs, cost considerations, and usability, alongside an assessment of qualitative model performance. While quantization helps mitigate memory overhead, it does not fully eliminate resource bottlenecks, especially for larger models. Our findings quantify the memory and energy constraints that must be considered for practical real-world deployments, offering concrete insights into the trade-offs between model size, inference performance, and efficiency. The exploration of LMs at the edge is still in its early stages. We hope this study provides a foundation for future research, guiding the refinement of models, the enhancement of inference efficiency, and the advancement of edge-centric AI systems.', 'abstract_zh': '语言模型的快速崛起扩展了自然语言处理的能力，推动了从文本生成到复杂决策的应用。虽然最先进的语言模型通常拥有数十亿参数，并主要部署在数据中心，但最近的趋势显示，人们越来越注重紧凑型模型——通常参数量不到100亿，通过量化和其他模型压缩技术得以实现。这种转变为边缘设备上的语言模型铺平了道路，提供了增强隐私、减少延迟和提高数据主权的潜在益处。然而，即使这些较小模型的固有复杂性与边缘硬件的有限计算资源相结合，也引发了在云外执行语言模型推理时实际权衡的关键问题。为应对这些挑战，我们对代表性的基于CPU和GPU加速的边缘设备上生成型语言模型推理进行了全面评估。我们的研究测量了包括内存使用、推理速度和能耗在内的关键性能指标，并涵盖了各种设备配置。此外，我们还分析了吞吐量-能耗权衡、成本考虑、易用性以及模型性能的质量评估。虽然量化有助于缓解内存开销，但并不能完全消除资源瓶颈，尤其是对于较大模型而言。我们的研究量化了实际现场部署中必须考虑的内存和能源约束，提供了关于模型规模、推理性能和效率之间权衡的具体见解。边缘设备上的语言模型探索仍处于早期阶段。我们希望这项研究能为基础研究提供基础，指导模型的精炼、推理效率的提升以及边缘为中心的AI系统的发展。', 'title_zh': '有时痛苦但必定前景广阔：边缘端语言模型推理的可行性与权衡'}
{'arxiv_id': 'arXiv:2503.09113', 'title': 'Constraint-Guided Learning of Data-driven Health Indicator Models: An Application on the Pronostia Bearing Dataset', 'authors': 'Yonas Tefera, Quinten Van Baelen, Maarten Meire, Stijn Luca, Peter Karsmakers', 'link': 'https://arxiv.org/abs/2503.09113', 'abstract': 'This paper presents a constraint-guided deep learning framework for developing physically consistent health indicators in bearing prognostics and health management. Conventional data-driven methods often lack physical plausibility, while physics-based models are limited by incomplete system knowledge. To address this, we integrate domain knowledge into deep learning using constraints to enforce monotonicity, bound output values between 1 and 0 (representing healthy to failed states), and ensure consistency between signal energy trends and health indicator estimates. This eliminates the need for complex loss term balancing. We implement constraint-guided gradient descent within an autoencoder architecture, creating a constrained autoencoder. However, the framework is adaptable to other architectures. Using time-frequency representations of accelerometer signals from the Pronostia dataset, our constrained model generates smoother, more reliable degradation profiles compared to conventional methods, aligning with expected physical behavior. Performance is assessed using three metrics: trendability, robustness, and consistency. Compared to a conventional baseline, the constrained model improves all three. Another baseline, incorporating monotonicity via a soft-ranking loss function, outperforms in trendability but falls short in robustness and consistency. An ablation study confirms that the monotonicity constraint enhances trendability, the boundary constraint ensures consistency, and the energy-health consistency constraint improves robustness. These findings highlight the effectiveness of constraint-guided deep learning in producing reliable, physically meaningful health indicators, offering a promising direction for future prognostic applications.', 'abstract_zh': '基于约束引导的深度学习框架在轴承 prognostics 和健康管理中开发物理一致性健康指示器', 'title_zh': '基于约束引导的学习驱动健康指标模型：Pronostia轴承数据集的应用'}
{'arxiv_id': 'arXiv:2503.09106', 'title': 'Freeze and Cluster: A Simple Baseline for Rehearsal-Free Continual Category Discovery', 'authors': 'Chuyu Zhang, Xueyang Yu, Peiyan Gu, Xuming He', 'link': 'https://arxiv.org/abs/2503.09106', 'abstract': 'This paper addresses the problem of Rehearsal-Free Continual Category Discovery (RF-CCD), which focuses on continuously identifying novel class by leveraging knowledge from labeled data. Existing methods typically train from scratch, overlooking the potential of base models, and often resort to data storage to prevent forgetting. Moreover, because RF-CCD encompasses both continual learning and novel class discovery, previous approaches have struggled to effectively integrate advanced techniques from these fields, resulting in less convincing comparisons and failing to reveal the unique challenges posed by RF-CCD. To address these challenges, we lead the way in integrating advancements from both domains and conducting extensive experiments and analyses. Our findings demonstrate that this integration can achieve state-of-the-art results, leading to the conclusion that in the presence of pre-trained models, the representation does not improve and may even degrade with the introduction of unlabeled data. To mitigate representation degradation, we propose a straightforward yet highly effective baseline method. This method first utilizes prior knowledge of known categories to estimate the number of novel classes. It then acquires representations using a model specifically trained on the base classes, generates high-quality pseudo-labels through k-means clustering, and trains only the classifier layer. We validate our conclusions and methods by conducting extensive experiments across multiple benchmarks, including the Stanford Cars, CUB, iNat, and Tiny-ImageNet datasets. The results clearly illustrate our findings, demonstrate the effectiveness of our baseline, and pave the way for future advancements in RF-CCD.', 'abstract_zh': '无回顾持续类别发现中的表示泛化研究', 'title_zh': '冻结与聚类：一种无回顾的持续类别发现简单基线'}
{'arxiv_id': 'arXiv:2503.09101', 'title': 'The Shape of Attraction in UMAP: Exploring the Embedding Forces in Dimensionality Reduction', 'authors': 'Mohammad Tariqul Islam, Jason W. Fleischer', 'link': 'https://arxiv.org/abs/2503.09101', 'abstract': 'Uniform manifold approximation and projection (UMAP) is among the most popular neighbor embedding methods. The method relies on attractive and repulsive forces among high-dimensional data points to obtain a low-dimensional embedding. In this paper, we analyze the forces to reveal their effects on cluster formations and visualization. Repulsion emphasizes differences, controlling cluster boundaries and inter-cluster distance. Attraction is more subtle, as attractive tension between points can manifest simultaneously as attraction and repulsion in the lower-dimensional mapping. This explains the need for learning rate annealing and motivates the different treatments between attractive and repulsive terms. Moreover, by modifying attraction, we improve the consistency of cluster formation under random initialization. Overall, our analysis makes UMAP and similar embedding methods more interpretable, more robust, and more accurate.', 'abstract_zh': '均匀流形逼近与投影（UMAP）是邻域嵌入方法中最受欢迎的方法之一。本文分析了这些力的影响，揭示了它们对聚类形成和可视化的作用。排斥力强调差异，控制聚类边界和类间距离。吸引力更为微妙，在低维映射中，点之间的吸引力可以同时表现为吸引力和排斥力。这解释了学习率退火的必要性，并促进了吸引力和排斥力项的不同处理。此外，通过修改吸引力，我们提高了在随机初始化下的聚类形成一致性。总体而言，我们的分析使得UMAP及其类似嵌入方法更加可解释、更为稳健且更准确。', 'title_zh': 'UMAP中吸引力的形状：探索降维中的嵌入力'}
{'arxiv_id': 'arXiv:2503.09091', 'title': 'Multi-Modal Foundation Models for Computational Pathology: A Survey', 'authors': 'Dong Li, Guihong Wan, Xintao Wu, Xinyu Wu, Xiaohui Chen, Yi He, Christine G. Lian, Peter K. Sorger, Yevgeniy R. Semenov, Chen Zhao', 'link': 'https://arxiv.org/abs/2503.09091', 'abstract': 'Foundation models have emerged as a powerful paradigm in computational pathology (CPath), enabling scalable and generalizable analysis of histopathological images. While early developments centered on uni-modal models trained solely on visual data, recent advances have highlighted the promise of multi-modal foundation models that integrate heterogeneous data sources such as textual reports, structured domain knowledge, and molecular profiles. In this survey, we provide a comprehensive and up-to-date review of multi-modal foundation models in CPath, with a particular focus on models built upon hematoxylin and eosin (H&E) stained whole slide images (WSIs) and tile-level representations. We categorize 32 state-of-the-art multi-modal foundation models into three major paradigms: vision-language, vision-knowledge graph, and vision-gene expression. We further divide vision-language models into non-LLM-based and LLM-based approaches. Additionally, we analyze 28 available multi-modal datasets tailored for pathology, grouped into image-text pairs, instruction datasets, and image-other modality pairs. Our survey also presents a taxonomy of downstream tasks, highlights training and evaluation strategies, and identifies key challenges and future directions. We aim for this survey to serve as a valuable resource for researchers and practitioners working at the intersection of pathology and AI.', 'abstract_zh': '多模态基础模型在计算病理学中的发展：基于苏木精和伊红染色全切片图像和小块表示的综述', 'title_zh': '多模态基础模型在计算病理学中的应用：一个综述'}
{'arxiv_id': 'arXiv:2503.09089', 'title': 'LocAgent: Graph-Guided LLM Agents for Code Localization', 'authors': 'Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang', 'link': 'https://arxiv.org/abs/2503.09089', 'abstract': 'Code localization--identifying precisely where in a codebase changes need to be made--is a fundamental yet challenging task in software maintenance. Existing approaches struggle to efficiently navigate complex codebases when identifying relevant code sections. The challenge lies in bridging natural language problem descriptions with the appropriate code elements, often requiring reasoning across hierarchical structures and multiple dependencies. We introduce LocAgent, a framework that addresses code localization through graph-based representation. By parsing codebases into directed heterogeneous graphs, LocAgent creates a lightweight representation that captures code structures (files, classes, functions) and their dependencies (imports, invocations, inheritance), enabling LLM agents to effectively search and locate relevant entities through powerful multi-hop reasoning. Experimental results on real-world benchmarks demonstrate that our approach significantly enhances accuracy in code localization. Notably, our method with the fine-tuned Qwen-2.5-Coder-Instruct-32B model achieves comparable results to SOTA proprietary models at greatly reduced cost (approximately 86% reduction), reaching up to 92.7% accuracy on file-level localization while improving downstream GitHub issue resolution success rates by 12% for multiple attempts (Pass@10). Our code is available at this https URL.', 'abstract_zh': '代码定位——识别需要在代码库中进行更改的具体位置——是软件维护中一个基础而具有挑战性的任务。现有方法在识别相关代码段时难以高效地导航复杂代码库。挑战在于将自然语言问题描述与合适的代码元素连接起来，通常需要跨越层次结构和多个依赖关系进行推理。我们引入了LocAgent框架，通过图表示来解决代码定位问题。通过将代码库解析为有向异构图，LocAgent创建了一个轻量级的表示，能够捕捉代码结构（文件、类、函数）及其依赖关系（导入、调用、继承），从而使LLM代理能够通过强大的多跳推理有效地搜索和定位相关实体。在实际基准上的实验结果表明，我们的方法显著提高了代码定位的准确性。特别地，使用微调后的Qwen-2.5-Coder-Instruct-32B模型的方法在文件级别定位方面的准确率达到92.7%，并降低了成本（约86%），同时在多次尝试（Pass@10）下提高了GitHub问题解决成功率12%。我们的代码可在以下链接获取。', 'title_zh': 'LocAgent: 图引导的大语言模型码位定位代理'}
{'arxiv_id': 'arXiv:2503.09081', 'title': 'Everything Can Be Described in Words: A Simple Unified Multi-Modal Framework with Semantic and Temporal Alignment', 'authors': 'Xiaowei Bi, Zheyuan Xu', 'link': 'https://arxiv.org/abs/2503.09081', 'abstract': 'Long Video Question Answering (LVQA) is challenging due to the need for temporal reasoning and large-scale multimodal data processing. Existing methods struggle with retrieving cross-modal information from long videos, especially when relevant details are sparsely distributed. We introduce UMaT (Unified Multi-modal as Text), a retrieval-augmented generation (RAG) framework that efficiently processes extremely long videos while maintaining cross-modal coherence. UMaT converts visual and auditory data into a unified textual representation, ensuring semantic and temporal alignment. Short video clips are analyzed using a vision-language model, while automatic speech recognition (ASR) transcribes dialogue. These text-based representations are structured into temporally aligned segments, with adaptive filtering to remove redundancy and retain salient details. The processed data is embedded into a vector database, enabling precise retrieval of dispersed yet relevant content. Experiments on a benchmark LVQA dataset show that UMaT outperforms existing methods in multimodal integration, long-form video understanding, and sparse information retrieval. Its scalability and interpretability allow it to process videos over an hour long while maintaining semantic and temporal coherence. These findings underscore the importance of structured retrieval and multimodal synchronization for advancing LVQA and long-form AI systems.', 'abstract_zh': '长视频问答（LVQA）由于需要进行时序推理和大规模多模态数据处理而具有挑战性。现有方法在从长视频中检索跨模态信息时遇到困难，尤其是在相关细节稀疏分布的情况下。我们介绍了UMaT（统一多模态作为文本）检索增强生成（RAG）框架，该框架能够高效处理极长视频同时保持跨模态一致性。UMaT将视觉和音频数据转换为统一的文本表示，确保语义和时序对齐。使用视觉语言模型分析短视频片段，同时利用自动语音识别（ASR）转录对话。这些基于文本的表示被结构化为时序对齐的片段，采用自适应过滤去除冗余信息并保留重要细节。处理后的数据被嵌入向量数据库中，从而能够精确检索分散但相关的内容。在基准LVQA数据集上的实验表明，UMaT在多模态集成、长视频理解以及稀疏信息检索方面优于现有方法。其可扩展性和可解释性使其能够处理超过一小时的视频，同时保持语义和时序一致。这些发现强调了结构化检索和多模态同步对于推进LVQA和长视频AI系统的重要性。', 'title_zh': '一切都可以用语言描述：一个简单的统一多模态框架，具备语义和时间对齐功能'}
{'arxiv_id': 'arXiv:2503.09069', 'title': 'Theoretical Guarantees for High Order Trajectory Refinement in Generative Flows', 'authors': 'Chengyue Gong, Xiaoyu Li, Yingyu Liang, Jiangxuan Long, Zhenmei Shi, Zhao Song, Yu Tian', 'link': 'https://arxiv.org/abs/2503.09069', 'abstract': 'Flow matching has emerged as a powerful framework for generative modeling, offering computational advantages over diffusion models by leveraging deterministic Ordinary Differential Equations (ODEs) instead of stochastic dynamics. While prior work established the worst case optimality of standard flow matching under Wasserstein distances, the theoretical guarantees for higher-order flow matching - which incorporates acceleration terms to refine sample trajectories - remain unexplored. In this paper, we bridge this gap by proving that higher-order flow matching preserves worst case optimality as a distribution estimator. We derive upper bounds on the estimation error for second-order flow matching, demonstrating that the convergence rates depend polynomially on the smoothness of the target distribution (quantified via Besov spaces) and key parameters of the ODE dynamics. Our analysis employs neural network approximations with carefully controlled depth, width, and sparsity to bound acceleration errors across both small and large time intervals, ultimately unifying these results into a general worst case optimal bound for all time steps.', 'abstract_zh': '高阶流匹配通过引入加速项来细化样本轨迹，保留了作为分布估计器的最坏情况最优性。', 'title_zh': '生成流中高阶轨迹精化的理论保证'}
{'arxiv_id': 'arXiv:2503.09068', 'title': 'Probing Network Decisions: Capturing Uncertainties and Unveiling Vulnerabilities Without Label Information', 'authors': 'Youngju Joung, Sehyun Lee, Jaesik Choi', 'link': 'https://arxiv.org/abs/2503.09068', 'abstract': "To improve trust and transparency, it is crucial to be able to interpret the decisions of Deep Neural classifiers (DNNs). Instance-level examinations, such as attribution techniques, are commonly employed to interpret the model decisions. However, when interpreting misclassified decisions, human intervention may be required. Analyzing the attribu tions across each class within one instance can be particularly labor intensive and influenced by the bias of the human interpreter. In this paper, we present a novel framework to uncover the weakness of the classifier via counterfactual examples. A prober is introduced to learn the correctness of the classifier's decision in terms of binary code-hit or miss. It enables the creation of the counterfactual example concerning the prober's decision. We test the performance of our prober's misclassification detection and verify its effectiveness on the image classification benchmark datasets. Furthermore, by generating counterfactuals that penetrate the prober, we demonstrate that our framework effectively identifies vulnerabilities in the target classifier without relying on label information on the MNIST dataset.", 'abstract_zh': '提高信任和透明度的关键在于能够解释深度神经网络分类器（DNNs）的决策。实例级别的检查，如归因技术，常被用来解释模型决策。然而，在解释错误分类的决策时，可能需要人工干预。通过对单个实例内每个类别的归因进行分析，可能会特别耗费人力且受到人类解释者的偏见影响。在本文中，我们提出了一种新的框架，通过反事实例子来揭示分类器的弱点。引入了一种探针来学习分类器决策的正确性，以二进制代码匹配或不匹配的形式表示。这使得能够根据探针的决策生成反事实例子。我们测试了探针对错误分类检测的表现，并在MNIST数据集上验证了其有效性。此外，通过生成穿透探针的反事实例子，我们证明了该框架在无需依赖标签信息的情况下有效识别目标分类器的漏洞。', 'title_zh': '探究网络决策：在无标签信息情况下捕获不确定性与揭示脆弱性'}
{'arxiv_id': 'arXiv:2503.09066', 'title': 'Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States', 'authors': 'Xin Wei Chia, Jonathan Pan', 'link': 'https://arxiv.org/abs/2503.09066', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they remain vulnerable to adversarial manipulations such as jailbreaking via prompt injection attacks. These attacks bypass safety mechanisms to generate restricted or harmful content. In this study, we investigated the underlying latent subspaces of safe and jailbroken states by extracting hidden activations from a LLM. Inspired by attractor dynamics in neuroscience, we hypothesized that LLM activations settle into semi stable states that can be identified and perturbed to induce state transitions. Using dimensionality reduction techniques, we projected activations from safe and jailbroken responses to reveal latent subspaces in lower dimensional spaces. We then derived a perturbation vector that when applied to safe representations, shifted the model towards a jailbreak state. Our results demonstrate that this causal intervention results in statistically significant jailbreak responses in a subset of prompts. Next, we probed how these perturbations propagate through the model's layers, testing whether the induced state change remains localized or cascades throughout the network. Our findings indicate that targeted perturbations induced distinct shifts in activations and model responses. Our approach paves the way for potential proactive defenses, shifting from traditional guardrail based methods to preemptive, model agnostic techniques that neutralize adversarial states at the representation level.", 'abstract_zh': '大型语言模型在各种任务中表现出色，但仍然容易受到诸如提示注入攻击在内的恶意操控。这些攻击绕过了安全机制，生成受限或有害的内容。本研究通过从大型语言模型中提取隐藏激活，探究安全和被破解状态下的潜在隐空间。受神经科学中吸引子动力学的启发，我们假设大型语言模型的激活会稳定在半稳定的状态下，并可以通过干扰这些状态来诱导状态转换。利用降维技术，我们将安全和被破解响应的激活投影到低维空间，揭示潜在隐空间。随后，我们推导出一个扰动向量，当应用于安全表示时，可以将模型引导至破解状态。我们的结果表明，这种因果干预在一部分提示下产生了统计学上显著的破解响应。接着，我们研究了这些扰动如何通过模型的各层传播，检验诱导的状态变化是否局部化或在整个网络中传播。我们的研究发现，针对性的扰动引起了激活和模型响应的独特转变。我们的方法为潜在的主动防御铺平了道路，从传统的防护栏方法转向预先防范、模型无关的技术，以在表示级别中中和对抗状态。', 'title_zh': '探查大规模语言模型中的隐含子空间以提升AI安全：识别和操控对抗状态'}
{'arxiv_id': 'arXiv:2503.09058', 'title': 'Implicit Contrastive Representation Learning with Guided Stop-gradient', 'authors': 'Byeongchan Lee, Sehyun Lee', 'link': 'https://arxiv.org/abs/2503.09058', 'abstract': 'In self-supervised representation learning, Siamese networks are a natural architecture for learning transformation-invariance by bringing representations of positive pairs closer together. But it is prone to collapse into a degenerate solution. To address the issue, in contrastive learning, a contrastive loss is used to prevent collapse by moving representations of negative pairs away from each other. But it is known that algorithms with negative sampling are not robust to a reduction in the number of negative samples. So, on the other hand, there are algorithms that do not use negative pairs. Many positive-only algorithms adopt asymmetric network architecture consisting of source and target encoders as a key factor in coping with collapse. By exploiting the asymmetric architecture, we introduce a methodology to implicitly incorporate the idea of contrastive learning. As its implementation, we present a novel method guided stop-gradient. We apply our method to benchmark algorithms SimSiam and BYOL and show that our method stabilizes training and boosts performance. We also show that the algorithms with our method work well with small batch sizes and do not collapse even when there is no predictor. The code is available at this https URL.', 'abstract_zh': '在自监督表示学习中，Siamese网络是一种自然的架构，通过使正样本对的表示更接近来学习不变性，但易陷入退化解。为解决该问题，在对比学习中，使用对比损失将负样本对的表示彼此拉开以防止退化。然而，已知带有负样本采样的算法对负样本数量减少不够 robust。因此，还存在不使用负样本对的算法。许多仅使用正样本的算法通过采用源编码器和目标编码器构成的不对称网络结构，将对比学习的思想隐式地纳入其中。作为其实现，我们提出了一种新的指导梯度停止方法。我们将该方法应用于基准算法SimSiam和BYOL，并显示该方法稳定训练并提升性能。我们还展示了在没有预测器的情况下，带有该方法的算法在小批量情况下也能很好地工作，并且即使没有预测器也不会退化。代码可在以下链接获取。', 'title_zh': '隐式对比表示学习与引导停止梯度方法'}
{'arxiv_id': 'arXiv:2503.09051', 'title': 'TreeX: Generating Global Graphical GNN Explanations via Critical Subtree Extraction', 'authors': 'Shengyao Lu, Jiuding Yang, Baochun Li, Di Niu', 'link': 'https://arxiv.org/abs/2503.09051', 'abstract': 'The growing demand for transparency and interpretability in critical domains has driven increased interests in comprehending the explainability of Message-Passing (MP) Graph Neural Networks (GNNs). Although substantial research efforts have been made to generate explanations for individual graph instances, identifying global explaining concepts for a GNN still poses great challenges, especially when concepts are desired in a graphical form on the dataset level. While most prior works treat GNNs as black boxes, in this paper, we propose to unbox GNNs by analyzing and extracting critical subtrees incurred by the inner workings of message passing, which correspond to critical subgraphs in the datasets. By aggregating subtrees in an embedding space with an efficient algorithm, which does not require complex subgraph matching or search, we can make intuitive graphical explanations for Message-Passing GNNs on local, class and global levels. We empirically show that our proposed approach not only generates clean subgraph concepts on a dataset level in contrast to existing global explaining methods which generate non-graphical rules (e.g., language or embeddings) as explanations, but it is also capable of providing explanations for individual instances with a comparable or even superior performance as compared to leading local-level GNN explainers.', 'abstract_zh': '不断增加的透明性和可解释性需求推动了对消息传递（MP）图神经网络（GNNs）的解释性的理解。虽然在生成单个图实例的解释方面已经付出了大量的研究努力，但在数据集层面上识别全局解释概念仍然面临巨大挑战，特别是当希望这些概念以图形形式呈现时。尽管大多数先前的工作将GNNs视为黑盒，本文提出通过分析和提取消息传递内部工作引起的子树来拆箱GNNs，这些子树对应于数据集中的关键子图。通过在嵌入空间中使用高效算法聚合子树，无需复杂的子图匹配或搜索，可以在局部、类别和全局层面上为消息传递GNNs提供直观的图形解释。我们通过实验证明，与现有全局解释方法生成非图形规则（例如，语言或嵌入）相比，我们的方法能够在数据集层面上生成清晰的子图概念，并且还能够为个体实例提供解释，其性能与领先的局部GNN解释器相当甚至更优。', 'title_zh': 'TreeX：通过关键子树提取生成全局图形GNN解释'}
{'arxiv_id': 'arXiv:2503.09046', 'title': 'Discovering Influential Neuron Path in Vision Transformers', 'authors': 'Yifan Wang, Yifei Liu, Yingdong Shi, Changming Li, Anqi Pang, Sibei Yang, Jingyi Yu, Kan Ren', 'link': 'https://arxiv.org/abs/2503.09046', 'abstract': "Vision Transformer models exhibit immense power yet remain opaque to human understanding, posing challenges and risks for practical applications. While prior research has attempted to demystify these models through input attribution and neuron role analysis, there's been a notable gap in considering layer-level information and the holistic path of information flow across layers. In this paper, we investigate the significance of influential neuron paths within vision Transformers, which is a path of neurons from the model input to output that impacts the model inference most significantly. We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome. And we further provide a layer-progressive neuron locating approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model. Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows, over the existing baseline solutions. Additionally, the neuron paths have illustrated that vision Transformers exhibit some specific inner working mechanism for processing the visual information within the same image category. We further analyze the key effects of these neurons on the image classification task, showcasing that the found neuron paths have already preserved the model capability on downstream tasks, which may also shed some lights on real-world applications like model pruning. The project website including implementation code is available at this https URL.", 'abstract_zh': '视觉Transformer模型展现出巨大的能力但依旧对人类理解不透明，这为其实用应用带来了挑战和风险。尽管早期研究试图通过输入归因和神经元作用分析来揭开这些模型的面纱，但在考虑层级信息以及跨层信息流的整体路径方面仍存在明显不足。在本文中，我们探讨了视觉Transformer中具有影响力的神经元路径的重要性，这是一种从模型输入到输出的路径，对模型推断的影响最大。我们首先提出了一种联合影响度量方法来评估一组神经元对模型结果的贡献，并进一步提供了一种逐层神经元定位方法，该方法可以在每一层中高效地选择最具影响力的神经元，以发现目标模型从输入到输出的关键神经元路径。我们的实验表明，我们方法找到的信息流路径相比现有的基线解决方案具有优势。此外，神经元路径表明视觉Transformer在处理相同图像类别内的视觉信息时表现出一些特定的内部工作机制。我们进一步分析了这些神经元对抗图像分类任务的关键影响，展示了找到的神经元路径已经保留了模型在下游任务中的能力，这也有助于模型剪枝等实际应用。项目网站和实现代码可通过以下链接访问。', 'title_zh': '发现视觉transformer中的关键神经元路径'}
{'arxiv_id': 'arXiv:2503.09035', 'title': 'ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers', 'authors': 'Shawn Azdam, Pranav Doma, Aliasghar Moj Arab', 'link': 'https://arxiv.org/abs/2503.09035', 'abstract': 'The next generation of active safety features in autonomous vehicles should be capable of safely executing evasive hazard-avoidance maneuvers akin to those performed by professional stunt drivers to achieve high-agility motion at the limits of vehicle handling. This paper presents a novel framework, ManeuverGPT, for generating and executing high-dynamic stunt maneuvers in autonomous vehicles using large language model (LLM)-based agents as controllers. We target aggressive maneuvers, such as J-turns, within the CARLA simulation environment and demonstrate an iterative, prompt-based approach to refine vehicle control parameters, starting tabula rasa without retraining model weights. We propose an agentic architecture comprised of three specialized agents (1) a Query Enricher Agent for contextualizing user commands, (2) a Driver Agent for generating maneuver parameters, and (3) a Parameter Validator Agent that enforces physics-based and safety constraints. Experimental results demonstrate successful J-turn execution across multiple vehicle models through textual prompts that adapt to differing vehicle dynamics. We evaluate performance via established success criteria and discuss limitations regarding numeric precision and scenario complexity. Our findings underscore the potential of LLM-driven control for flexible, high-dynamic maneuvers, while highlighting the importance of hybrid approaches that combine language-based reasoning with algorithmic validation.', 'abstract_zh': '下一代自主车辆中的主动安全功能应具备像专业特技驾驶者那样在车辆操控极限内执行规避危险的机动操作的能力。本文提出了一种新颖的框架，ManeuverGPT，该框架使用基于大规模语言模型（LLM）的代理作为控制器，以在自主车辆中生成和执行高强度特技机动。我们在CARLA仿真环境中针对激进机动（如J形转弯）进行目标定位，并展示了一种基于提示的迭代方法来细化车辆控制参数，从头开始无需重新训练模型权重。我们提出了一种由三个专门代理组成的机构型架构（1）查询增补代理，用于固化用户命令；（2）驾驶员代理，用于生成机动参数；（3）参数验证代理，用于施加基于物理和安全的约束。实验结果表明，通过适应不同车辆动态的文本提示，可以成功执行多种车型的J形转弯。我们通过既定的成功标准评估性能，并讨论了数字精度和场景复杂性方面的限制。我们的研究结果强调了LLM驱动控制在灵活执行高强度机动方面的潜力，同时指出了将基于语言的推理与算法验证相结合的混合方法的重要性。', 'title_zh': 'ManeuverGPT赋能的安全自主特技操纵'}
{'arxiv_id': 'arXiv:2503.09033', 'title': 'RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification', 'authors': 'Rui Shi, Xiaodong Yu, Shengming Wang, Yijia Zhang, Lu Xu, Peng Pan, Chunlai Ma', 'link': 'https://arxiv.org/abs/2503.09033', 'abstract': 'In this paper, we propose RFUAV as a new benchmark dataset for radio-frequency based (RF-based) unmanned aerial vehicle (UAV) identification and address the following challenges: Firstly, many existing datasets feature a restricted variety of drone types and insufficient volumes of raw data, which fail to meet the demands of practical applications. Secondly, existing datasets often lack raw data covering a broad range of signal-to-noise ratios (SNR), or do not provide tools for transforming raw data to different SNR levels. This limitation undermines the validity of model training and evaluation. Lastly, many existing datasets do not offer open-access evaluation tools, leading to a lack of unified evaluation standards in current research within this field. RFUAV comprises approximately 1.3 TB of raw frequency data collected from 37 distinct UAVs using the Universal Software Radio Peripheral (USRP) device in real-world environments. Through in-depth analysis of the RF data in RFUAV, we define a drone feature sequence called RF drone fingerprint, which aids in distinguishing drone signals. In addition to the dataset, RFUAV provides a baseline preprocessing method and model evaluation tools. Rigorous experiments demonstrate that these preprocessing methods achieve state-of-the-art (SOTA) performance using the provided evaluation tools. The RFUAV dataset and baseline implementation are publicly available at this https URL.', 'abstract_zh': '本文提出了基于射频的无人自驾飞机（RFUAV）数据集作为射频（RF）基于的无人机识别的新基准，并解决了以下挑战：首先，许多现有数据集的无人机类型有限且原始数据量不足，无法满足实际应用需求。其次，现有数据集往往缺少涵盖广泛信噪比（SNR）范围的原始数据，或者不提供将原始数据转换为不同SNR水平的工具，这限制了模型训练和评估的有效性。最后，许多现有数据集未提供开放访问的评估工具，导致该领域当前研究缺乏统一的评估标准。RFUAV数据集包含约1.3 TB来自37种不同无人机的原始射频数据，这些数据是在实际环境中使用通用软件无线电外设（USRP）设备收集的。通过对RFUAV的射频数据进行深入分析，我们定义了一种无人机特征序列——射频无人机指纹，有助于区分无人机信号。此外，RFUAV还提供了基础预处理方法和模型评估工具。严格的实验表明，这些预处理方法使用提供的评估工具可达到目前最佳（SOTA）性能。RFUAV数据集和基础实现可在此网址访问：this https URL。', 'title_zh': 'RFUAV：无人机检测与识别基准数据集'}
{'arxiv_id': 'arXiv:2503.09032', 'title': 'Teaching LLMs How to Learn with Contextual Fine-Tuning', 'authors': 'Younwoo Choi, Muhammad Adil Asif, Ziwen Han, John Willes, Rahul G. Krishnan', 'link': 'https://arxiv.org/abs/2503.09032', 'abstract': 'Prompting Large Language Models (LLMs), or providing context on the expected model of operation, is an effective way to steer the outputs of such models to satisfy human desiderata after they have been trained. But in rapidly evolving domains, there is often need to fine-tune LLMs to improve either the kind of knowledge in their memory or their abilities to perform open ended reasoning in new domains. When human\'s learn new concepts, we often do so by linking the new material that we are studying to concepts we have already learned before. To that end, we ask, "can prompting help us teach LLMs how to learn". In this work, we study a novel generalization of instruction tuning, called contextual fine-tuning, to fine-tune LLMs. Our method leverages instructional prompts designed to mimic human cognitive strategies in learning and problem-solving to guide the learning process during training, aiming to improve the model\'s interpretation and understanding of domain-specific knowledge. We empirically demonstrate that this simple yet effective modification improves the ability of LLMs to be fine-tuned rapidly on new datasets both within the medical and financial domains.', 'abstract_zh': '提示大型语言模型：通过提供预期模型操作的背景，在快速发展的领域中微调大型语言模型以提高其在新领域内的知识类型或泛化推理能力。探究提示在教学大型语言模型中的作用：一种新的指令微调变体——上下文微调，利用模拟人类学习和解决问题的认知策略的提示，指导训练过程，以改善模型对领域特定知识的解释和理解。我们实验证明，这种简单而有效的修改能显著提高大型语言模型在医疗和金融领域内快速适应新数据集的能力。', 'title_zh': '教LLM如何通过上下文微调进行学习'}
{'arxiv_id': 'arXiv:2503.09020', 'title': 'Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning', 'authors': 'Yuan Jiang, Yujian Zhang, Liang Lu, Christoph Treude, Xiaohong Su, Shan Huang, Tiantian Wang', 'link': 'https://arxiv.org/abs/2503.09020', 'abstract': "Large Language Models (LLMs) have been widely adopted in commercial code completion engines, significantly enhancing coding efficiency and productivity. However, LLMs may generate code with quality issues that violate coding standards and best practices, such as poor code style and maintainability, even when the code is functionally correct. This necessitates additional effort from developers to improve the code, potentially negating the efficiency gains provided by LLMs. To address this problem, we propose a novel comparative prefix-tuning method for controllable high-quality code generation. Our method introduces a single, property-specific prefix that is prepended to the activations of the LLM, serving as a lightweight alternative to fine-tuning. Unlike existing methods that require training multiple prefixes, our approach trains only one prefix and leverages pairs of high-quality and low-quality code samples, introducing a sequence-level ranking loss to guide the model's training. This comparative approach enables the model to better understand the differences between high-quality and low-quality code, focusing on aspects that impact code quality. Additionally, we design a data construction pipeline to collect and annotate pairs of high-quality and low-quality code, facilitating effective training. Extensive experiments on the Code Llama 7B model demonstrate that our method improves code quality by over 100% in certain task categories, while maintaining functional correctness. We also conduct ablation studies and generalization experiments, confirming the effectiveness of our method's components and its strong generalization capability.", 'abstract_zh': '大规模语言模型（LLMs）已广泛应用于商业代码完成引擎中，显著提升了编码效率和生产力。然而，LLMs可能生成违反编码标准和最佳实践的代码，即使这些代码从功能上是正确的，也可能包含代码风格和可维护性不佳的问题。这需要开发人员付出额外的努力来改进代码，从而可能抵消LLMs带来的效率提升。为了解决这一问题，我们提出了一种新颖的可控高质量代码生成的比较前缀调优方法。该方法引入了一个特定属性的前缀，将其添加到LLM的激活之前，作为微调的轻量级替代方案。与现有需要训练多个前缀的方法不同，我们的方法仅训练一个前缀，并利用高质量和低质量代码样本的配对，引入序列级排序损失以指导模型的训练。这种比较方法使模型更好地理解高质量和低质量代码之间的差异，关注影响代码质量的因素。此外，我们设计了一个数据构建管道来收集和标注高质量和低质量代码配对，便于有效的训练。在Code Llama 7B模型上的广泛实验表明，我们的方法在某些任务类别中将代码质量提高了超过100%，同时保持功能正确性。我们还进行了消融研究和泛化实验，验证了我们方法各组成部分的有效性及其强大的泛化能力。', 'title_zh': '使用比较性前缀调优提升大型语言模型中的高质量代码生成'}
{'arxiv_id': 'arXiv:2503.09008', 'title': 'Towards Quantifying Long-Range Interactions in Graph Machine Learning: a Large Graph Dataset and a Measurement', 'authors': 'Huidong Liang, Haitz Sáez de Ocáriz Borde, Baskaran Sripathmanathan, Michael Bronstein, Xiaowen Dong', 'link': 'https://arxiv.org/abs/2503.09008', 'abstract': 'Long-range dependencies are critical for effective graph representation learning, yet most existing datasets focus on small graphs tailored to inductive tasks, offering limited insight into long-range interactions. Current evaluations primarily compare models employing global attention (e.g., graph transformers) with those using local neighborhood aggregation (e.g., message-passing neural networks) without a direct measurement of long-range dependency. In this work, we introduce City-Networks, a novel large-scale transductive learning dataset derived from real-world city roads. This dataset features graphs with over $10^5$ nodes and significantly larger diameters than those in existing benchmarks, naturally embodying long-range information. We annotate the graphs using an eccentricity-based approach, ensuring that the classification task inherently requires information from distant nodes. Furthermore, we propose a model-agnostic measurement based on the Jacobians of neighbors from distant hops, offering a principled quantification of long-range dependencies. Finally, we provide theoretical justifications for both our dataset design and the proposed measurement - particularly by focusing on over-smoothing and influence score dilution - which establishes a robust foundation for further exploration of long-range interactions in graph neural networks.', 'abstract_zh': '长范围依赖对于有效的图表示学习至关重要，然而大多数现有数据集侧重于适用于归纳任务的小型图，这限制了对长范围交互的理解。当前的评估主要比较使用全局注意力（如图变压器）的模型与使用局部邻域聚合（如消息传递神经网络）的模型，但没有直接测量长范围依赖。在本文中，我们引入了City-Networks，这是一个新的大规模归纳学习数据集，来源于实际城市的道路。该数据集包含包含超过 \\(10^5\\) 个节点的图，并且直径显著大于现有基准数据集，自然地体现了长范围信息。我们采用基于 eccentricity 的方法对图进行标注，确保分类任务需要远距离节点的信息。此外，我们提出了一种基于远处跳跃邻居雅可比矩阵的模型无关测量方法，为长范围依赖提供了一个原则性的量化方法。最后，我们为我们的数据集设计和提议的测量提供了理论依据——特别是通过关注过度平滑和影响分数稀释——这为图神经网络中长范围相互作用的进一步探索奠定了坚实的基础。', 'title_zh': '量化图机器学习中长程交互：大规模图数据集及评估方法'}
{'arxiv_id': 'arXiv:2503.09002', 'title': 'KNighter: Transforming Static Analysis with LLM-Synthesized Checkers', 'authors': 'Chenyuan Yang, Zijie Zhao, Zichen Xie, Haoyu Li, Lingming Zhang', 'link': 'https://arxiv.org/abs/2503.09002', 'abstract': 'Static analysis is a powerful technique for bug detection in critical systems like operating system kernels. However, designing and implementing static analyzers is challenging, time-consuming, and typically limited to predefined bug patterns. While large language models (LLMs) have shown promise for static analysis, directly applying them to scan large codebases remains impractical due to computational constraints and contextual limitations.\nWe present KNighter, the first approach that unlocks practical LLM-based static analysis by automatically synthesizing static analyzers from historical bug patterns. Rather than using LLMs to directly analyze massive codebases, our key insight is leveraging LLMs to generate specialized static analyzers guided by historical patch knowledge. KNighter implements this vision through a multi-stage synthesis pipeline that validates checker correctness against original patches and employs an automated refinement process to iteratively reduce false positives. Our evaluation on the Linux kernel demonstrates that KNighter generates high-precision checkers capable of detecting diverse bug patterns overlooked by existing human-written analyzers. To date, KNighter-synthesized checkers have discovered 70 new bugs/vulnerabilities in the Linux kernel, with 56 confirmed and 41 already fixed. 11 of these findings have been assigned CVE numbers. This work establishes an entirely new paradigm for scalable, reliable, and traceable LLM-based static analysis for real-world systems via checker synthesis.', 'abstract_zh': 'KNighter：通过历史漏洞模式自动生成的实用大语言模型驱动的静态分析方法', 'title_zh': 'KNighter: 通过LLM合成的检查器改造静态分析'}
{'arxiv_id': 'arXiv:2503.08994', 'title': 'DistJoin: A Decoupled Join Cardinality Estimator based on Adaptive Neural Predicate Modulation', 'authors': 'Kaixin Zhang, Hongzhi Wang, Ziqi Li, Yabin Lu, Yingze Li, Yu Yan, Yiming Guan', 'link': 'https://arxiv.org/abs/2503.08994', 'abstract': 'Research on learned cardinality estimation has achieved significant progress in recent years. However, existing methods still face distinct challenges that hinder their practical deployment in production environments. We conceptualize these challenges as the "Trilemma of Cardinality Estimation", where learned cardinality estimation methods struggle to balance generality, accuracy, and updatability. To address these challenges, we introduce DistJoin, a join cardinality estimator based on efficient distribution prediction using multi-autoregressive models. Our contributions are threefold: (1) We propose a method for estimating both equi and non-equi join cardinality by leveraging the conditional probability distributions of individual tables in a decoupled manner. (2) To meet the requirements of efficient training and inference for DistJoin, we develop Adaptive Neural Predicate Modulation (ANPM), a high-throughput conditional probability distribution estimation model. (3) We formally analyze the variance of existing similar methods and demonstrate that such approaches suffer from variance accumulation issues. To mitigate this problem, DistJoin employs a selectivity-based approach rather than a count-based approach to infer join cardinality, effectively reducing variance. In summary, DistJoin not only represents the first data-driven method to effectively support both equi and non-equi joins but also demonstrates superior accuracy while enabling fast and flexible updates. We evaluate DistJoin on JOB-light and JOB-light-ranges, extending the evaluation to non-equi join conditions. The results demonstrate that our approach achieves the highest accuracy, robustness to data updates, generality, and comparable update and inference speed relative to existing methods.', 'abstract_zh': '基于高效分布预测的DistJoin：面向等值与非等值连接的卡方估计', 'title_zh': 'DistJoin：基于自适应神经谓词调制的解耦连接基数估计器'}
{'arxiv_id': 'arXiv:2503.08990', 'title': 'JBFuzz: Jailbreaking LLMs Efficiently and Effectively Using Fuzzing', 'authors': 'Vasudev Gohil', 'link': 'https://arxiv.org/abs/2503.08990', 'abstract': 'Large language models (LLMs) have shown great promise as language understanding and decision making tools, and they have permeated various aspects of our everyday life. However, their widespread availability also comes with novel risks, such as generating harmful, unethical, or offensive content, via an attack called jailbreaking. Despite extensive efforts from LLM developers to align LLMs using human feedback, they are still susceptible to jailbreak attacks. To tackle this issue, researchers often employ red-teaming to understand and investigate jailbreak prompts. However, existing red-teaming approaches lack effectiveness, scalability, or both. To address these issues, we propose JBFuzz, a novel effective, automated, and scalable red-teaming technique for jailbreaking LLMs.\nJBFuzz is inspired by the success of fuzzing for detecting bugs/vulnerabilities in software. We overcome three challenges related to effectiveness and scalability by devising novel seed prompts, a lightweight mutation engine, and a lightweight and accurate evaluator for guiding the fuzzer. Assimilating all three solutions results in a potent fuzzer that only requires black-box access to the target LLM. We perform extensive experimental evaluation of JBFuzz using nine popular and widely-used LLMs. We find that JBFuzz successfully jailbreaks all LLMs for various harmful/unethical questions, with an average attack success rate of 99%. We also find that JBFuzz is extremely efficient as it jailbreaks a given LLM for a given question in 60 seconds on average. Our work highlights the susceptibility of the state-of-the-art LLMs to jailbreak attacks even after safety alignment, and serves as a valuable red-teaming tool for LLM developers.', 'abstract_zh': '大型语言模型（LLMs）在语言理解和决策方面展现了巨大的潜力，并渗透到了我们日常生活中的多个方面。然而，它们的广泛应用也带来了新型风险，如通过名为“ jailbreaking ”的攻击生成有害、不道德或冒犯性的内容。尽管LLM开发者付出了大量努力通过人类反馈对模型进行对齐，它们仍然容易受到“ jailbreaking ”攻击。为解决这一问题，研究人员常常采用“红队”方法理解并调查“ jailbreaking ”提示。然而，现有的“红队”方法在有效性或可扩展性方面存在不足。为此，我们提出了一种名为JBFuzz的新颖有效、自动化和可扩展的“红队”技术，用于破解LLMs。', 'title_zh': 'JBFuzz：高效有效地破解LLMs的方法'}
{'arxiv_id': 'arXiv:2503.08960', 'title': 'Are ECGs enough? Deep learning classification of cardiac anomalies using only electrocardiograms', 'authors': 'Joao D.S. Marques, Arlindo L. Oliveira', 'link': 'https://arxiv.org/abs/2503.08960', 'abstract': 'Electrocardiography (ECG) is an essential tool for diagnosing multiple cardiac anomalies: it provides valuable clinical insights, while being affordable, fast and available in many settings. However, in the current literature, the role of ECG analysis is often unclear: many approaches either rely on additional imaging modalities, such as Computed Tomography Pulmonary Angiography (CTPA), which may not always be available, or do not effectively generalize across different classification problems. Furthermore, the availability of public ECG datasets is limited and, in practice, these datasets tend to be small, making it essential to optimize learning strategies. In this study, we investigate the performance of multiple neural network architectures in order to assess the impact of various approaches. Moreover, we check whether these practices enhance model generalization when transfer learning is used to translate information learned in larger ECG datasets, such as PTB-XL and CPSC18, to a smaller, more challenging dataset for pulmonary embolism (PE) detection. By leveraging transfer learning, we analyze the extent to which we can improve learning efficiency and predictive performance on limited data. Code available at this https URL .', 'abstract_zh': '心电图（ECG）是诊断多种心脏异常的重要工具：它提供有价值的临床见解，且成本低、快速，并可在多种环境中使用。然而，当前文献中，ECG分析的作用往往不够明确：许多方法要么依赖额外的成像模态，如计算机断层扫描肺动脉造影（CTPA），而这并非总是可用的，要么在不同分类问题上的推广效果不佳。此外，公开的ECG数据集的可用性有限，实际中这些数据集往往规模较小，因此优化学习策略至关重要。在本研究中，我们调查了多种神经网络架构的性能，以评估不同方法的影响，并检查这些实践是否有助于通过迁移学习将从更大规模的ECG数据集（如PTB-XL和CPSC18）中学到的信息应用于较小、更具挑战性的肺栓塞（PE）检测数据集，以增强模型的泛化能力。通过利用迁移学习，我们分析了在有限数据下提高学习效率和预测性能的程度。相关代码见此链接：https://xxxxxx。', 'title_zh': 'ECGs足够吗？仅使用心电图的心脏异常深度学习分类'}
{'arxiv_id': 'arXiv:2503.08950', 'title': 'FP3: A 3D Foundation Policy for Robotic Manipulation', 'authors': 'Rujia Yang, Geng Chen, Chuan Wen, Yang Gao', 'link': 'https://arxiv.org/abs/2503.08950', 'abstract': 'Following its success in natural language processing and computer vision, foundation models that are pre-trained on large-scale multi-task datasets have also shown great potential in robotics. However, most existing robot foundation models rely solely on 2D image observations, ignoring 3D geometric information, which is essential for robots to perceive and reason about the 3D world. In this paper, we introduce FP3, a first large-scale 3D foundation policy model for robotic manipulation. FP3 builds on a scalable diffusion transformer architecture and is pre-trained on 60k trajectories with point cloud observations. With the model design and diverse pre-training data, FP3 can be efficiently fine-tuned for downstream tasks while exhibiting strong generalization capabilities. Experiments on real robots demonstrate that with only 80 demonstrations, FP3 is able to learn a new task with over 90% success rates in novel environments with unseen objects, significantly surpassing existing robot foundation models.', 'abstract_zh': '基于3D点云观察的大规模机器人 manipulation 基础策略模型 FP3', 'title_zh': 'FP3: 3D 基础政策用于机器人操作'}
{'arxiv_id': 'arXiv:2503.08939', 'title': 'KAN-Mixers: a new deep learning architecture for image classification', 'authors': 'Jorge Luiz dos Santos Canuto, Linnyer Beatrys Ruiz Aylon, Rodrigo Clemente Thom de Souza', 'link': 'https://arxiv.org/abs/2503.08939', 'abstract': 'Due to their effective performance, Convolutional Neural Network (CNN) and Vision Transformer (ViT) architectures have become the standard for solving computer vision tasks. Such architectures require large data sets and rely on convolution and self-attention operations. In 2021, MLP-Mixer emerged, an architecture that relies only on Multilayer Perceptron (MLP) and achieves extremely competitive results when compared to CNNs and ViTs. Despite its good performance in computer vision tasks, the MLP-Mixer architecture may not be suitable for refined feature extraction in images. Recently, the Kolmogorov-Arnold Network (KAN) was proposed as a promising alternative to MLP models. KANs promise to improve accuracy and interpretability when compared to MLPs. Therefore, the present work aims to design a new mixer-based architecture, called KAN-Mixers, using KANs as main layers and evaluate its performance, in terms of several performance metrics, in the image classification task. As main results obtained, the KAN-Mixers model was superior to the MLP, MLP-Mixer and KAN models in the Fashion-MNIST and CIFAR-10 datasets, with 0.9030 and 0.6980 of average accuracy, respectively.', 'abstract_zh': '基于KAN的混合架构在图像分类任务中的性能评估', 'title_zh': 'KAN-Mixers：一种新的图像分类深度学习架构'}
{'arxiv_id': 'arXiv:2503.08936', 'title': 'Simulator Ensembles for Trustworthy Autonomous Driving Testing', 'authors': 'Lev Sorokin, Matteo Biagiola, Andrea Stocco', 'link': 'https://arxiv.org/abs/2503.08936', 'abstract': 'Scenario-based testing with driving simulators is extensively used to identify failing conditions of automated driving assistance systems (ADAS) and reduce the amount of in-field road testing. However, existing studies have shown that repeated test execution in the same as well as in distinct simulators can yield different outcomes, which can be attributed to sources of flakiness or different implementations of the physics, among other factors. In this paper, we present MultiSim, a novel approach to multi-simulation ADAS testing based on a search-based testing approach that leverages an ensemble of simulators to identify failure-inducing, simulator-agnostic test scenarios. During the search, each scenario is evaluated jointly on multiple simulators. Scenarios that produce consistent results across simulators are prioritized for further exploration, while those that fail on only a subset of simulators are given less priority, as they may reflect simulator-specific issues rather than generalizable failures. Our case study, which involves testing a deep neural network-based ADAS on different pairs of three widely used simulators, demonstrates that MultiSim outperforms single-simulator testing by achieving on average a higher rate of simulator-agnostic failures by 51%. Compared to a state-of-the-art multi-simulator approach that combines the outcome of independent test generation campaigns obtained in different simulators, MultiSim identifies 54% more simulator-agnostic failing tests while showing a comparable validity rate. An enhancement of MultiSim that leverages surrogate models to predict simulator disagreements and bypass executions does not only increase the average number of valid failures but also improves efficiency in finding the first valid failure.', 'abstract_zh': '基于搜索的多仿真实验方法MultiSim及其在自动驾驶辅助系统测试中的应用', 'title_zh': '可信自动驾驶测试的仿真器ensemble方法'}
{'arxiv_id': 'arXiv:2503.08929', 'title': 'HessianForge: Scalable LiDAR reconstruction with Physics-Informed Neural Representation and Smoothness Energy Constraints', 'authors': 'Hrishikesh Viswanath, Md Ashiqur Rahman, Chi Lin, Damon Conover, Aniket Bera', 'link': 'https://arxiv.org/abs/2503.08929', 'abstract': 'Accurate and efficient 3D mapping of large-scale outdoor environments from LiDAR measurements is a fundamental challenge in robotics, particularly towards ensuring smooth and artifact-free surface reconstructions. Although the state-of-the-art methods focus on memory-efficient neural representations for high-fidelity surface generation, they often fail to produce artifact-free manifolds, with artifacts arising due to noisy and sparse inputs. To address this issue, we frame surface mapping as a physics-informed energy optimization problem, enforcing surface smoothness by optimizing an energy functional that penalizes sharp surface ridges. Specifically, we propose a deep learning based approach that learns the signed distance field (SDF) of the surface manifold from raw LiDAR point clouds using a physics-informed loss function that optimizes the $L_2$-Hessian energy of the surface. Our learning framework includes a hierarchical octree based input feature encoding and a multi-scale neural network to iteratively refine the signed distance field at different scales of resolution. Lastly, we introduce a test-time refinement strategy to correct topological inconsistencies and edge distortions that can arise in the generated mesh. We propose a \\texttt{CUDA}-accelerated least-squares optimization that locally adjusts vertex positions to enforce feature-preserving smoothing. We evaluate our approach on large-scale outdoor datasets and demonstrate that our approach outperforms current state-of-the-art methods in terms of improved accuracy and smoothness. Our code is available at \\href{this https URL}{this https URL}', 'abstract_zh': '大规模室外环境从LiDAR测量中实现精确且高效的三维建模是一项基本挑战，尤其是在确保无瑕疵表面重建平滑性方面。尽管最先进的方法专注于高保真表面生成的内存高效神经表征，它们往往无法产生无瑕疵的数据流形，其中的瑕疵多由噪声和稀疏的输入产生。为了解决这一问题，我们将表面建模框架化为一个受物理约束的能量优化问题，通过优化惩罚尖锐表面嵴的数据流形表面平滑性能量功能来强制表面平滑性。具体而言，我们提出了一种基于深度学习的方法，该方法使用一个受物理约束的损失函数从原始LiDAR点云中学习数据流形的符号距离场(SDF)，该损失函数优化表面的$L_2$海森能量。我们的学习框架包括基于层次八叉树的输入特征编码和多尺度神经网络，以在不同分辨率级别上逐步细化符号距离场。最后，我们引入了一种测试时间细化策略来纠正生成网格中可能出现的拓扑不一致性和边缘畸变。我们提出了一种基于CUDA加速的最小二乘优化方法，以局部调整顶点位置来实现特征保持平滑。我们在大规模室外数据集上评估了我们的方法，并证明了我们在准确性和平滑性方面优于当前最先进的方法。我们的代码可在\\url{this https URL}访问。', 'title_zh': 'HessianForge: 具有物理信息神经表示和平滑能量约束的大规模LiDAR重建'}
{'arxiv_id': 'arXiv:2503.08919', 'title': 'Backtracking for Safety', 'authors': 'Bilgehan Sel, Dingcheng Li, Phillip Wallis, Vaishakh Keshava, Ming Jin, Siddhartha Reddy Jonnalagadda', 'link': 'https://arxiv.org/abs/2503.08919', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities across various tasks, but ensuring their safety and alignment with human values remains crucial. Current safety alignment methods, such as supervised fine-tuning and reinforcement learning-based approaches, can exhibit vulnerabilities to adversarial attacks and often result in shallow safety alignment, primarily focusing on preventing harmful content in the initial tokens of the generated output. While methods like resetting can help recover from unsafe generations by discarding previous tokens and restarting the generation process, they are not well-suited for addressing nuanced safety violations like toxicity that may arise within otherwise benign and lengthy generations. In this paper, we propose a novel backtracking method designed to address these limitations. Our method allows the model to revert to a safer generation state, not necessarily at the beginning, when safety violations occur during generation. This approach enables targeted correction of problematic segments without discarding the entire generated text, thereby preserving efficiency. We demonstrate that our method dramatically reduces toxicity appearing through the generation process with minimal impact to efficiency.', 'abstract_zh': '大型语言模型（LLMs）已在多种任务中展示了卓越的能力，但确保其安全并与其人类价值观保持一致仍至关重要。当前的安全对齐方法，如监督微调和基于强化学习的方法，可能会表现出对对抗攻击的脆弱性，并且往往导致浅层次的安全对齐，主要集中在防止生成输出初始词汇中的有害内容。尽管重置等方法可以帮助通过丢弃先前的词汇并重新开始生成过程来从不安全的生成中恢复，但它们并不适合解决可能在否则看似无害和冗长的生成过程中产生的细微安全违规，如毒性。在本文中，我们提出了一种新的回溯方法，旨在解决这些局限性。该方法在生成过程中发生安全违规时允许模型回退到一个更安全的生成状态，而不仅仅是初始状态。这种方法允许对有问题的段落进行有针对性的修正，而不必丢弃整个生成的文本，从而保持效率。我们证明，我们的方法能够显著减少生成过程中出现的毒性现象，且对效率的影响 minimal。', 'title_zh': '回溯以确保安全'}
{'arxiv_id': 'arXiv:2503.08916', 'title': 'Robust Unsupervised Fault Diagnosis For High-Dimensional Nonlinear Noisy Data', 'authors': 'Dandan Zhao, Hongpeng Yin, Jintang Bian, Han Zhou', 'link': 'https://arxiv.org/abs/2503.08916', 'abstract': 'Traditional fault diagnosis methods struggle to handle fault data, with complex data characteristics such as high dimensions and large noise. Deep learning is a promising solution, which typically works well only when labeled fault data are available. To address these problems, a robust unsupervised fault diagnosis using machine learning is proposed in this paper. First, a special dimension reduction method for the high-dimensional fault data is designed. Second, the extracted features are enhanced by incorporating nonlinear information through the learning of a graph structure. Third, to alleviate the problem of reduced fault-diagnosis accuracy attributed to noise and outliers, $l_{2,1}$-norm and typicality-aware constraints are introduced from the perspective of model optimization, respectively. Finally, this paper provides comprehensive theoretical and experimental evidence supporting the effectiveness and robustness of the proposed method. The experiments on both the benchmark Tennessee-Eastman process and a real hot-steel milling process show that the proposed method exhibits better robustness compared to other methods, maintaining high diagnostic accuracy even in the presence of outliers or noise.', 'abstract_zh': '基于机器学习的鲁棒无监督故障诊断方法', 'title_zh': '鲁棒无监督故障诊断方法及其在高维非线性噪声数据中的应用'}
{'arxiv_id': 'arXiv:2503.08908', 'title': 'Interpreting the Repeated Token Phenomenon in Large Language Models', 'authors': 'Itay Yona, Ilia Shumailov, Jamie Hayes, Federico Barbero, Yossi Gandelsman', 'link': 'https://arxiv.org/abs/2503.08908', 'abstract': "Large Language Models (LLMs), despite their impressive capabilities, often fail to accurately repeat a single word when prompted to, and instead output unrelated text. This unexplained failure mode represents a vulnerability, allowing even end-users to diverge models away from their intended behavior. We aim to explain the causes for this phenomenon and link it to the concept of ``attention sinks'', an emergent LLM behavior crucial for fluency, in which the initial token receives disproportionately high attention scores. Our investigation identifies the neural circuit responsible for attention sinks and shows how long repetitions disrupt this circuit. We extend this finding to other non-repeating sequences that exhibit similar circuit disruptions. To address this, we propose a targeted patch that effectively resolves the issue without negatively impacting the model's overall performance. This study provides a mechanistic explanation for an LLM vulnerability, demonstrating how interpretability can diagnose and address issues, and offering insights that pave the way for more secure and reliable models.", 'abstract_zh': '大型语言模型（LLMs）尽管具备 impressive 的能力，但在被提示重复单个单词时，往往无法准确重复，反而生成不相关的内容。这种无法解释的失效模式代表了一种漏洞，甚至允许最终用户使模型偏离预期行为。我们旨在解释这一现象的原因，并将其与“注意力陷阱”这一对流畅性至关重要的新兴 LLM 行为联系起来，在这种行为中，初始标记获得了不成比例高的注意力分数。我们的研究确定了负责注意力陷阱的神经电路，并展示了长时间重复如何破坏这一电路。我们将这一发现扩展到其他类似电路破坏的非重复序列。为了解决这一问题，我们提出了一种针对性的补丁，该补丁能够在不负面影响模型整体性能的前提下有效解决问题。本研究提供了对 LLM 漏洞的机制性解释，展示了可解释性如何诊断和解决这些问题，并提供了使模型更安全和可靠的见解。', 'title_zh': '大规模语言模型中重复 token 现象的解读'}
{'arxiv_id': 'arXiv:2503.08906', 'title': 'Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge Preservation in Vision-Language Model Adaptation', 'authors': 'Xiwen Chen, Wenhui Zhu, Peijie Qiu, Hao Wang, Huayu Li, Haiyu Wu, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi', 'link': 'https://arxiv.org/abs/2503.08906', 'abstract': 'Vision-language models (VLMs) such as CLIP demonstrate strong performance but struggle when adapted to downstream tasks. Prompt learning has emerged as an efficient and effective strategy to adapt VLMs while preserving their pre-trained knowledge. However, existing methods still lead to overfitting and degrade zero-shot generalization. To address this challenge, we propose an optimal transport (OT)-guided prompt learning framework that mitigates forgetting by preserving the structural consistency of feature distributions between pre-trained and fine-tuned models. Unlike conventional point-wise constraints, OT naturally captures cross-instance relationships and expands the feasible parameter space for prompt tuning, allowing a better trade-off between adaptation and generalization. Our approach enforces joint constraints on both vision and text representations, ensuring a holistic feature alignment. Extensive experiments on benchmark datasets demonstrate that our simple yet effective method can outperform existing prompt learning strategies in base-to-novel generalization, cross-dataset evaluation, and domain generalization without additional augmentation or ensemble techniques. The code is available at this https URL', 'abstract_zh': '基于最优传输的提示学习框架：通过保留特征分布结构一致性来缓解遗忘，提高基态到新颖态的泛化、跨数据集评估和领域泛化性能', 'title_zh': 'Prompt-OT：视觉语言模型适应中知识保留的最优传输正则化范式'}
{'arxiv_id': 'arXiv:2503.08879', 'title': 'LLMs Know What to Drop: Self-Attention Guided KV Cache Eviction for Efficient Long-Context Inference', 'authors': 'Guangtao Wang, Shubhangi Upasani, Chen Wu, Darshan Gandhi, Jonathan Li, Changran Hu, Bo Li, Urmish Thakker', 'link': 'https://arxiv.org/abs/2503.08879', 'abstract': 'Efficient long-context inference is critical as large language models (LLMs) adopt context windows of ranging from 128K to 1M tokens. However, the growing key-value (KV) cache and the high computational complexity of attention create significant bottlenecks in memory usage and latency. In this paper, we find that attention in diverse long-context tasks exhibits sparsity, and LLMs implicitly "know" which tokens can be dropped or evicted at the head level after the pre-filling stage. Based on this insight, we propose Self-Attention Guided Eviction~(SAGE-KV), a simple and effective KV eviction cache method for long-context inference. After prefilling, our method performs a one-time top-k selection at both the token and head levels to compress the KV cache, enabling efficient inference with the reduced cache. Evaluations on LongBench and three long-context LLMs (Llama3.1-8B-Instruct-128k, Llama3-8B-Prolong-512k-Instruct, and Qwen2.5-7B-Instruct-128k) show that SAGE-KV maintains accuracy comparable to full attention while significantly improving efficiency. Specifically, SAGE-KV achieves 4x higher memory efficiency with improved accuracy over the static KV cache selection method StreamLLM, and 2x higher memory efficiency with better accuracy than the dynamic KV cache selection method Quest.', 'abstract_zh': '高效的长上下文推理对于大型语言模型（LLMs）至关重要，LLMs采用的上下文窗口范围从128K到1M个令牌。然而， growing key-value (KV) 缓存的增长和注意力机制的高计算复杂度在内存使用和延迟方面造成了显著瓶颈。在本文中，我们发现不同的长上下文任务中的注意力表现出稀疏性，并且LLMs在预填充阶段后在头部级别“知道”哪些令牌可以被丢弃或淘汰。基于这一洞察，我们提出了Self-Attention Guided Eviction (SAGE-KV)，一种简单的有效的方法，用于长上下文推理中的KV缓存淘汰。经过预填充后，我们的方法在令牌和头部级别进行一次性的top-k选择，以压缩KV缓存，从而使使用减少的缓存实现高效的推理。在LongBench以及三个长上下文LLM（Llama3.1-8B-Instruct-128k、Llama3-8B-Prolong-512k-Instruct和Qwen2.5-7B-Instruct-128k）上的评估显示，SAGE-KV在保持与全注意力相当的准确性的基础上，显著提高了效率。具体而言，与静态KV缓存选择方法StreamLLM相比，SAGE-KV在提高准确性的基础上实现了4倍的内存效率提升；与动态KV缓存选择方法Quest相比，SAGE-KV在更高的内存效率基础上实现了更好的准确率。', 'title_zh': 'LLMs了解该丢弃什么：自我注意力引导的KV缓存淘汰以实现高效长上下文推理'}
{'arxiv_id': 'arXiv:2503.08872', 'title': 'Meta-Reinforcement Learning with Discrete World Models for Adaptive Load Balancing', 'authors': 'Cameron Redovian', 'link': 'https://arxiv.org/abs/2503.08872', 'abstract': 'We integrate a meta-reinforcement learning algorithm with the DreamerV3 architecture to improve load balancing in operating systems. This approach enables rapid adaptation to dynamic workloads with minimal retraining, outperforming the Advantage Actor-Critic (A2C) algorithm in standard and adaptive trials. It demonstrates robust resilience to catastrophic forgetting, maintaining high performance under varying workload distributions and sizes. These findings have important implications for optimizing resource management and performance in modern operating systems. By addressing the challenges posed by dynamic and heterogeneous workloads, our approach advances the adaptability and efficiency of reinforcement learning in real-world system management tasks.', 'abstract_zh': '我们将元强化学习算法与DreamerV3架构相结合，以提高操作系统中的负载均衡。该方法能够在不进行大量重新训练的情况下快速适应动态工作负载，标准试验和自适应试验中均优于优势_actor_评论家（A2C）算法。该方法表现出对灾难性遗忘的稳健韧性，在不同工作负载分布和规模下保持了高性能。这些发现对于优化现代操作系统的资源管理和性能具有重要影响。通过解决动态和异构工作负载带来的挑战，我们的方法促进了强化学习在实际系统管理任务中的适应性和效率。', 'title_zh': '基于离散世界模型的元强化学习自适应负载均衡'}
{'arxiv_id': 'arXiv:2503.08867', 'title': 'Zero-Shot Action Generalization with Limited Observations', 'authors': 'Abdullah Alchihabi, Hanping Zhang, Yuhong Guo', 'link': 'https://arxiv.org/abs/2503.08867', 'abstract': 'Reinforcement Learning (RL) has demonstrated remarkable success in solving sequential decision-making problems. However, in real-world scenarios, RL agents often struggle to generalize when faced with unseen actions that were not encountered during training. Some previous works on zero-shot action generalization rely on large datasets of action observations to capture the behaviors of new actions, making them impractical for real-world applications. In this paper, we introduce a novel zero-shot framework, Action Generalization from Limited Observations (AGLO). Our framework has two main components: an action representation learning module and a policy learning module. The action representation learning module extracts discriminative embeddings of actions from limited observations, while the policy learning module leverages the learned action representations, along with augmented synthetic action representations, to learn a policy capable of handling tasks with unseen actions. The experimental results demonstrate that our framework significantly outperforms state-of-the-art methods for zero-shot action generalization across multiple benchmark tasks, showcasing its effectiveness in generalizing to new actions with minimal action observations.', 'abstract_zh': '基于有限观测的零样本动作泛化框架（Action Generalization from Limited Observations）', 'title_zh': '基于有限观察的零样本动作泛化'}
{'arxiv_id': 'arXiv:2503.08823', 'title': 'ResBench: Benchmarking LLM-Generated FPGA Designs with Resource Awareness', 'authors': 'Ce Guo, Tong Zhao', 'link': 'https://arxiv.org/abs/2503.08823', 'abstract': "Field-Programmable Gate Arrays (FPGAs) are widely used in modern hardware design, yet writing Hardware Description Language (HDL) code for FPGA implementation remains labor-intensive and complex. Large Language Models (LLMs) have emerged as a promising tool for automating HDL generation, but existing benchmarks for LLM HDL code generation primarily evaluate functional correctness while overlooking the critical aspect of hardware resource efficiency. Moreover, current benchmarks lack diversity, failing to capture the broad range of real-world FPGA applications. To address these gaps, we introduce ResBench, the first resource-oriented benchmark explicitly designed to differentiate between resource-optimized and inefficient LLM-generated HDL. ResBench consists of 56 problems across 12 categories, covering applications from finite state machines to financial computing. Our evaluation framework systematically integrates FPGA resource constraints, with a primary focus on Lookup Table (LUT) usage, enabling a realistic assessment of hardware efficiency. Experimental results reveal substantial differences in resource utilization across LLMs, demonstrating ResBench's effectiveness in distinguishing models based on their ability to generate resource-optimized FPGA designs.", 'abstract_zh': '基于资源的资源优化现场可编程门阵列硬件描述语言生成基准（ResBench）', 'title_zh': 'ResBench: 基于资源感知的LLM生成FPGA设计基准测试'}
{'arxiv_id': 'arXiv:2503.08815', 'title': 'Cross-Examiner: Evaluating Consistency of Large Language Model-Generated Explanations', 'authors': 'Danielle Villa, Maria Chang, Keerthiram Murugesan, Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy', 'link': 'https://arxiv.org/abs/2503.08815', 'abstract': "Large Language Models (LLMs) are often asked to explain their outputs to enhance accuracy and transparency. However, evidence suggests that these explanations can misrepresent the models' true reasoning processes. One effective way to identify inaccuracies or omissions in these explanations is through consistency checking, which typically involves asking follow-up questions. This paper introduces, cross-examiner, a new method for generating follow-up questions based on a model's explanation of an initial question. Our method combines symbolic information extraction with language model-driven question generation, resulting in better follow-up questions than those produced by LLMs alone. Additionally, this approach is more flexible than other methods and can generate a wider variety of follow-up questions.", 'abstract_zh': '大规模语言模型（LLMs）往往被要求解释其输出以提高准确性和透明度。然而，证据表明这些解释可能会歪曲模型的真实推理过程。一种有效的方法是通过一致性检查来识别这些解释中的不准确或遗漏，这通常涉及提出后续问题。本文介绍了交叉检视者（Cross-examiner），一种基于模型对初始问题解释生成后续问题的新方法。该方法结合了符号信息提取与基于语言模型的问题生成，产生的后续问题比单独使用LLM生成的问题质量更高。此外，该方法比其他方法更具灵活性，能够生成更多样化的后续问题。', 'title_zh': 'Cross-Examiner: 评估大型语言模型生成的解释一致性'}
{'arxiv_id': 'arXiv:2503.08796', 'title': 'Robust Multi-Objective Controlled Decoding of Large Language Models', 'authors': 'Seongho Son, William Bankes, Sangwoong Yoon, Shyam Sundhar Ramesh, Xiaohang Tang, Ilija Bogunovic', 'link': 'https://arxiv.org/abs/2503.08796', 'abstract': 'Test-time alignment of Large Language Models (LLMs) to human preferences offers a flexible way to generate responses aligned to diverse objectives without extensive retraining of LLMs. Existing methods achieve alignment to multiple objectives simultaneously (e.g., instruction-following, helpfulness, conciseness) by optimizing their corresponding reward functions. However, they often rely on predefined weights or optimize for averages, sacrificing one objective for another and leading to unbalanced outcomes. To address this, we introduce Robust Multi-Objective Decoding (RMOD), a novel inference-time algorithm that optimizes for improving worst-case rewards. RMOD formalizes the robust decoding problem as a maximin two-player game between reward weights and the sampling policy, solving for the Nash equilibrium. We show that the game reduces to a convex optimization problem to find the worst-case weights, while the best response policy can be computed analytically. We also introduce a practical RMOD variant designed for efficient decoding with contemporary LLMs, incurring minimal computational overhead compared to non-robust Multi-Objective Decoding (MOD) methods. Our experimental results showcase the effectiveness of RMOD in generating responses equitably aligned with diverse objectives, outperforming baselines up to 20%.', 'abstract_zh': '大型语言模型（LLMs）在测试时与人类偏好的对齐为生成符合多样目标的响应提供了一种灵活的方法，而无需对LLMs进行大量重新训练。现有方法通过优化相应的奖励函数同时实现对多个目标的对齐（例如，指令遵循、有用性、简洁性）。然而，它们往往依赖于预定义的权重或优化平均值，导致在不同的目标之间牺牲某一个目标，从而产生不平衡的结果。为解决这一问题，我们引入了鲁棒多目标解码（RMOD），这是一种新型的推理时算法，旨在优化最坏情况奖励的改进。RMOD将鲁棒解码问题形式化为奖励权重和采样策略之间的最大化最小化二人博弈，并求解纳什均衡。我们证明该博弈可减少为一个凸优化问题以找出最坏情况的权重，而最优反应策略可以解析计算。我们还引入了一种实用的RMOD变体，该变体适用于当代LLMs的高效解码，并且相对于非鲁棒多目标解码（MOD）方法的计算开销最小。我们的实验证明了RMOD在生成公平地符合多样目标的响应方面的有效性，相对于基线方法可提高20%以上。', 'title_zh': '鲁棒多目标控制解码大型语言模型'}
{'arxiv_id': 'arXiv:2503.08764', 'title': 'Towards Interpretable Protein Structure Prediction with Sparse Autoencoders', 'authors': 'Nithin Parsan, David J. Yang, John J. Yang', 'link': 'https://arxiv.org/abs/2503.08764', 'abstract': 'Protein language models have revolutionized structure prediction, but their nonlinear nature obscures how sequence representations inform structure prediction. While sparse autoencoders (SAEs) offer a path to interpretability here by learning linear representations in high-dimensional space, their application has been limited to smaller protein language models unable to perform structure prediction. In this work, we make two key advances: (1) we scale SAEs to ESM2-3B, the base model for ESMFold, enabling mechanistic interpretability of protein structure prediction for the first time, and (2) we adapt Matryoshka SAEs for protein language models, which learn hierarchically organized features by forcing nested groups of latents to reconstruct inputs independently. We demonstrate that our Matryoshka SAEs achieve comparable or better performance than standard architectures. Through comprehensive evaluations, we show that SAEs trained on ESM2-3B significantly outperform those trained on smaller models for both biological concept discovery and contact map prediction. Finally, we present an initial case study demonstrating how our approach enables targeted steering of ESMFold predictions, increasing structure solvent accessibility while fixing the input sequence. To facilitate further investigation by the broader community, we open-source our code, dataset, pretrained models this https URL , and visualizer this https URL .', 'abstract_zh': '蛋白质语言模型已经重塑了结构预测，但其非线性性质使人们难以理解序列表示如何影响结构预测。虽然稀疏自编码器（SAEs）可以通过在高维空间中学习线性表示来提供可解释性的途径，但其应用仅限于较小的蛋白质语言模型，无法进行结构预测。在本文中，我们做出了两大关键进展：（1）我们将SAEs扩展到ESM2-3B，这是ESMFold的基本模型，首次实现了蛋白质结构预测的机制可解释性；（2）我们将Matryoshka SAEs应用于蛋白质语言模型，使其能够通过强制嵌套的潜在特征独立重建输入来学习分层组织的特征。我们证明，我们的Matryoshka SAEs在性能上可与标准架构媲美或更优。通过综合评估，我们展示了在ESM2-3B上训练的SAEs在生物概念发现和接触图预测方面显著优于在较小模型上训练的SAEs。最后，我们呈现了一个初步的案例研究，展示了我们的方法如何使ESMFold预测具有目标控制性，同时提高结构的溶剂可及性并固定输入序列。为了促进更广泛的社区进一步研究，我们开放了我们的代码、数据集、预训练模型和可视化工具（此链接：this https URL 和此链接：this https URL）。', 'title_zh': '基于稀疏自编码器的可解释蛋白质结构预测'}
{'arxiv_id': 'arXiv:2503.08760', 'title': 'Heterogeneous Graph Structure Learning through the Lens of Data-generating Processes', 'authors': 'Keyue Jiang, Bohan Tang, Xiaowen Dong, Laura Toni', 'link': 'https://arxiv.org/abs/2503.08760', 'abstract': 'Inferring the graph structure from observed data is a key task in graph machine learning to capture the intrinsic relationship between data entities. While significant advancements have been made in learning the structure of homogeneous graphs, many real-world graphs exhibit heterogeneous patterns where nodes and edges have multiple types. This paper fills this gap by introducing the first approach for heterogeneous graph structure learning (HGSL). To this end, we first propose a novel statistical model for the data-generating process (DGP) of heterogeneous graph data, namely hidden Markov networks for heterogeneous graphs (H2MN). Then we formalize HGSL as a maximum a-posterior estimation problem parameterized by such DGP and derive an alternating optimization method to obtain a solution together with a theoretical justification of the optimization conditions. Finally, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate that our proposed method excels in learning structure on heterogeneous graphs in terms of edge type identification and edge weight recovery.', 'abstract_zh': '从观测数据推断异构图结构是图机器学习中捕捉数据实体之间内在关系的关键任务。尽管在学习同构图结构方面取得了显著进展，但许多实际中的图表现出异构模式，其中节点和边具有多种类型。本文通过引入第一个异构图结构学习（HGSL）的方法来填补这一空白。为此，我们首先提出了一种新的统计模型来描述异构图数据的数据生成过程（DGP），即异构图中的隐藏马尔可夫网络（H2MN）。然后我们将HGSL形式化为一个基于此类DGP的最大后验估计问题，并推导出一种交替优化方法来获得解，并提供优化条件的理论证明。最后，我们在合成数据集和真实世界数据集上进行了广泛的实验，证明了我们提出的方法在边类型识别和边权重恢复方面在异构图结构学习中的优异性能。', 'title_zh': '数据生成过程视角下的异质图结构学习'}
{'arxiv_id': 'arXiv:2503.08750', 'title': 'Exposing Product Bias in LLM Investment Recommendation', 'authors': 'Yuhan Zhi, Xiaoyu Zhang, Longtian Wang, Shumin Jiang, Shiqing Ma, Xiaohong Guan, Chao Shen', 'link': 'https://arxiv.org/abs/2503.08750', 'abstract': "Large language models (LLMs), as a new generation of recommendation engines, possess powerful summarization and data analysis capabilities, surpassing traditional recommendation systems in both scope and performance. One promising application is investment recommendation. In this paper, we reveal a novel product bias in LLM investment recommendation, where LLMs exhibit systematic preferences for specific products. Such preferences can subtly influence user investment decisions, potentially leading to inflated valuations of products and financial bubbles, posing risks to both individual investors and market stability. To comprehensively study the product bias, we develop an automated pipeline to create a dataset of 567,000 samples across five asset classes (stocks, mutual funds, cryptocurrencies, savings, and portfolios). With this dataset, we present the bf first study on product bias in LLM investment recommendations. Our findings reveal that LLMs exhibit clear product preferences, such as certain stocks (e.g., `AAPL' from Apple and `MSFT' from Microsoft). Notably, this bias persists even after applying debiasing techniques. We urge AI researchers to take heed of the product bias in LLM investment recommendations and its implications, ensuring fairness and security in the digital space and market.", 'abstract_zh': "大型语言模型（LLMs）作为新一代推荐系统，具备强大的总结和数据分析能力，超越了传统推荐系统的范围和性能。在投资推荐领域的应用前景广阔。本文揭示了LLMs投资推荐中的一种新型产品偏差，即LLMs对特定产品表现出系统的偏好。这些偏好可能微妙地影响用户的投资决策，导致产品被过度估值，可能引发金融泡沫，对个人投资者和市场稳定构成风险。为全面研究产品偏差，我们开发了一种自动化管道，创建了一个包含567,000个样本的五类资产（股票、共同基金、加密货币、储蓄和投资组合）数据集。基于此数据集，我们进行了首个关于LLMs投资推荐中产品偏差的研究。研究发现，LLMs表现出明 显的产品偏好，例如某些股票（如来自苹果的`AAPL'和来自微软的`MSFT'）。值得注意的是，即使应用去偏技术，这种偏差依然存在。我们敦促AI研究人员关注LLMs投资推荐中的产品偏差及其影响，确保数字空间和市场的公平与安全。", 'title_zh': '暴露LLM在投资推荐中的产品偏见'}
{'arxiv_id': 'arXiv:2503.08749', 'title': 'Source-free domain adaptation based on label reliability for cross-domain bearing fault diagnosis', 'authors': 'Wenyi Wu, Hao Zhang, Zhisen Wei, Xiao-Yuan Jing, Qinghua Zhang, Songsong Wu', 'link': 'https://arxiv.org/abs/2503.08749', 'abstract': 'Source-free domain adaptation (SFDA) has been exploited for cross-domain bearing fault diagnosis without access to source data. Current methods select partial target samples with reliable pseudo-labels for model adaptation, which is sub-optimal due to the ignored target samples. We argue that every target sample can contribute to model adaptation, and accordingly propose in this paper a novel SFDA-based approach for bearing fault diagnosis that exploits both reliable and unreliable pseudo-labels. We develop a data-augmentation-based label voting strategy to divide the target samples into reliable and unreliable ones. We propose to explore the underlying relation between feature space and label space by using the reliable pseudo-labels as ground-truth labels, meanwhile, alleviating negative transfer by maximizing the entropy of the unreliable pseudo-labels. The proposed method achieves well-balance between discriminability and diversity by taking advantage of reliable and unreliable pseudo-labels. Extensive experiments are conducted on two bearing fault benchmarks, demonstrating that our approach achieves significant performance improvements against existing SFDA-based bearing fault diagnosis methods. Our code is available at this https URL.', 'abstract_zh': '无源域适应（SFDA）在无需源数据的情况下进行了跨域轴承故障诊断的研究。当前方法选择具有可靠伪标签的部分目标样本进行模型适应，这由于忽略了目标样本而欠佳。我们argue每个多目标样本都可以为模型适应做出贡献，并在此基础上提出了一种新的基于SFDA的轴承故障诊断方法，该方法利用可靠和不可靠的伪标签。我们开发了一种基于数据增强的标签投票策略，将目标样本分为可靠和不可靠两类。我们提出利用可靠伪标签作为真实标签探索特征空间和标签空间之间的潜在关系，同时通过最大化不可靠伪标签的熵来缓解负迁移。通过利用可靠和不可靠的伪标签，提出的算法实现了可判别性和多样性的良好平衡。在两个轴承故障基准上的大量实验表明，与现有的基于SFDA的轴承故障诊断方法相比，我们的方法实现了显著的性能提升。我们的代码可在以下链接获取。', 'title_zh': '基于标签可靠性的无源域适应轴承故障跨域诊断'}
{'arxiv_id': 'arXiv:2503.08748', 'title': 'Mirror Descent and Novel Exponentiated Gradient Algorithms Using Trace-Form Entropies and Deformed Logarithms', 'authors': 'Andrzej Cichocki, Toshihisa Tanaka, Sergio Cruces', 'link': 'https://arxiv.org/abs/2503.08748', 'abstract': 'In this paper we propose and investigate a wide class of Mirror Descent updates (MD) and associated novel Generalized Exponentiated Gradient (GEG) algorithms by exploiting various trace-form entropies and associated deformed logarithms and their inverses - deformed (generalized) exponential functions. The proposed algorithms can be considered as extension of entropic MD and generalization of multiplicative updates. In the literature, there exist nowadays over fifty mathematically well defined generalized entropies, so impossible to exploit all of them in one research paper. So we focus on a few selected most popular entropies and associated logarithms like the Tsallis, Kaniadakis and Sharma-Taneja-Mittal and some of their extension like Tempesta or Kaniadakis-Scarfone entropies. The shape and properties of the deformed logarithms and their inverses are tuned by one or more hyperparameters. By learning these hyperparameters, we can adapt to distribution of training data, which can be designed to the specific geometry of the optimization problem, leading to potentially faster convergence and better performance. The using generalized entropies and associated deformed logarithms in the Bregman divergence, used as a regularization term, provides some new insight into exponentiated gradient descent updates.', 'abstract_zh': '本文提出并研究了一类广泛的镜像下降更新（MD）及其相关的新型广义指数梯度（GEG）算法，通过利用各种迹形式熵及其相关的变形对数和它们的逆——变形（广义）指数函数。所提出的算法可以被视为广义熵镜像下降算法的扩展和乘法更新的一般化。目前文献中已有五十多种数学上严格定义的广义熵，不可能在一个研究论文中全部利用。因此，我们集中在几类最流行的广义熵及其相关的对数，如Tsallis、Kaniadakis和Sharma-Taneja-Mittal熵及其扩展，如Tempesta或Kaniadakis-Scarfone熵。这些变形对数及其逆的形状和性质通过一个或多个超参数进行调整。通过学习这些超参数，我们可以根据训练数据的分布进行适应，并且可以针对优化问题的具体几何结构进行设计，从而可能导致更快的收敛和更好的性能。利用广义熵及其相关的变形对数在Bregman散度中作为正则化项，为指数梯度下降更新提供了新的见解。', 'title_zh': '镜像下降与新型迹形式熵及变形对数函数的指数梯度算法'}
{'arxiv_id': 'arXiv:2503.08745', 'title': 'Neural Network for Blind Unmixing: a novel MatrixConv Unmixing (MCU) Approach', 'authors': 'Chao Zhou, Wei Pu, Miguel Rodrigues', 'link': 'https://arxiv.org/abs/2503.08745', 'abstract': 'Hyperspectral image (HSI) unmixing is a challenging research problem that tries to identify the constituent components, known as endmembers, and their corresponding proportions, known as abundances, in the scene by analysing images captured by hyperspectral cameras. Recently, many deep learning based unmixing approaches have been proposed with the surge of machine learning techniques, especially convolutional neural networks (CNN). However, these methods face two notable challenges: 1. They frequently yield results lacking physical significance, such as signatures corresponding to unknown or non-existent materials. 2. CNNs, as general-purpose network structures, are not explicitly tailored for unmixing tasks. In response to these concerns, our work draws inspiration from double deep image prior (DIP) techniques and algorithm unrolling, presenting a novel network structure that effectively addresses both issues. Specifically, we first propose a MatrixConv Unmixing (MCU) approach for endmember and abundance estimation, respectively, which can be solved via certain iterative solvers. We then unroll these solvers to build two sub-networks, endmember estimation DIP (UEDIP) and abundance estimation DIP (UADIP), to generate the estimation of endmember and abundance, respectively. The overall network is constructed by assembling these two sub-networks. In order to generate meaningful unmixing results, we also propose a composite loss function. To further improve the unmixing quality, we also add explicitly a regularizer for endmember and abundance estimation, respectively. The proposed methods are tested for effectiveness on both synthetic and real datasets.', 'abstract_zh': '高光谱图像(HSI)解混是挑战性的研究问题，旨在通过分析高光谱相机捕获的图像来识别构成组件（称为端元）及其相应的比例（称为丰度）。近年来，随着机器学习技术特别是卷积神经网络(CNN)的兴起，提出了许多基于深度学习的解混方法。然而，这些方法面临两个显著挑战：1. 经常产生缺乏物理意义的结果，例如与未知或不存在的材料对应的签名。2. 卷积神经网络作为通用的网络结构，并未专门为解混任务进行明确设计。为应对这些问题，我们的工作借鉴了双层深度图像先验(DIP)技术和算法展开技术，提出了一种新的网络结构，有效解决了上述两个问题。具体地，我们首先提出了矩阵卷积解混(MCU)方法，分别用于端元和丰度估计，这两种方法可以通过某些迭代求解器解决。然后，我们将这些求解器展开以构建两个子网络：端元估计DIP(UEDIP)和丰度估计DIP(UADIP)，以分别生成端元和丰度的估计值。整个网络通过组装这两个子网络来构建。为了生成有意义的解混结果，我们还提出了复合损失函数。为了进一步提高解混质量，我们还分别对端元和丰度估计添加了正则化项。我们对合成数据集和真实数据集的有效性进行了测试。', 'title_zh': '基于神经网络的盲解混：一种新型MatrixConv解混（MCU）方法'}
{'arxiv_id': 'arXiv:2503.08741', 'title': 'Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis', 'authors': 'Letian Zhang, Quan Cui, Bingchen Zhao, Cheng Yang', 'link': 'https://arxiv.org/abs/2503.08741', 'abstract': 'The success of multi-modal large language models (MLLMs) has been largely attributed to the large-scale training data. However, the training data of many MLLMs is unavailable due to privacy concerns. The expensive and labor-intensive process of collecting multi-modal data further exacerbates the problem. Is it possible to synthesize multi-modal training data automatically without compromising diversity and quality? In this paper, we propose a new method, Oasis, to synthesize high-quality multi-modal data with only images. Oasis breaks through traditional methods by prompting only images to the MLLMs, thus extending the data diversity by a large margin. Our method features a delicate quality control method which ensures the data quality. We collected over 500k data and conducted incremental experiments on LLaVA-NeXT. Extensive experiments demonstrate that our method can significantly improve the performance of MLLMs. The image-based synthesis also allows us to focus on the specific-domain ability of MLLMs. Code and data will be publicly available.', 'abstract_zh': '多模态大型语言模型(MLLLMs)的成功主要归因于大规模训练数据。然而，由于隐私问题，许多MLLLMs的训练数据不可用。收集多模态数据的过程既昂贵又劳动密集，进一步加剧了这一问题。是否可以在不牺牲多样性和质量的前提下自动合成多模态训练数据？在本文中，我们提出了一种名为Oasis的新方法，仅使用图像即可合成高质量的多模态数据。Oasis突破了传统方法，仅通过将图像提示给MLLMs来扩展数据多样性。该方法具有精细的质量控制机制，确保数据质量。我们收集了超过50万条数据，并在LLaVA-NeXT上进行了逐步实验。广泛的实验结果表明，该方法可以显著提高MLLMs的性能。基于图像的合成还使我们能够专注于MLLMs的特定领域能力。代码和数据将公开发布。', 'title_zh': 'Oasis: 一张图片足以实现多模态指令数据合成'}
{'arxiv_id': 'arXiv:2503.08739', 'title': 'HeGMN: Heterogeneous Graph Matching Network for Learning Graph Similarity', 'authors': 'Shilong Sang, Ke-Jia Chen, Zheng liu', 'link': 'https://arxiv.org/abs/2503.08739', 'abstract': 'Graph similarity learning (GSL), also referred to as graph matching in many scenarios, is a fundamental problem in computer vision, pattern recognition, and graph learning. However, previous GSL methods assume that graphs are homogeneous and struggle to maintain their performance on heterogeneous graphs. To address this problem, this paper proposes a Heterogeneous Graph Matching Network (HeGMN), which is an end-to-end graph similarity learning framework composed of a two-tier matching mechanism. Firstly, a heterogeneous graph isomorphism network is proposed as the encoder, which reinvents graph isomorphism network for heterogeneous graphs by perceiving different semantic relationships during aggregation. Secondly, a graph-level and node-level matching modules are designed, both employing type-aligned matching principles. The former conducts graph-level matching by node type alignment, and the latter computes the interactions between the cross-graph nodes with the same type thus reducing noise interference and computational overhead. Finally, the graph-level and node-level matching features are combined and fed into fully connected layers for predicting graph similarity scores. In experiments, we propose a heterogeneous graph resampling method to construct heterogeneous graph pairs and define the corresponding heterogeneous graph edit distance, filling the gap in missing datasets. Extensive experiments demonstrate that HeGMN consistently achieves advanced performance on graph similarity prediction across all datasets.', 'abstract_zh': '异构图匹配网络（HeGMN）：一种端到端的图相似性学习框架', 'title_zh': 'HeGMN：异质图匹配网络用于学习图相似性'}
{'arxiv_id': 'arXiv:2503.08737', 'title': 'Representing 3D Shapes With 64 Latent Vectors for 3D Diffusion Models', 'authors': 'In Cho, Youngbeom Yoo, Subin Jeon, Seon Joo Kim', 'link': 'https://arxiv.org/abs/2503.08737', 'abstract': 'Constructing a compressed latent space through a variational autoencoder (VAE) is the key for efficient 3D diffusion models. This paper introduces COD-VAE, a VAE that encodes 3D shapes into a COmpact set of 1D latent vectors without sacrificing quality. COD-VAE introduces a two-stage autoencoder scheme to improve compression and decoding efficiency. First, our encoder block progressively compresses point clouds into compact latent vectors via intermediate point patches. Second, our triplane-based decoder reconstructs dense triplanes from latent vectors instead of directly decoding neural fields, significantly reducing computational overhead of neural fields decoding. Finally, we propose uncertainty-guided token pruning, which allocates resources adaptively by skipping computations in simpler regions and improves the decoder efficiency. Experimental results demonstrate that COD-VAE achieves 16x compression compared to the baseline while maintaining quality. This enables 20.8x speedup in generation, highlighting that a large number of latent vectors is not a prerequisite for high-quality reconstruction and generation.', 'abstract_zh': '通过变分自编码器（VAE）构建压缩隐空间是高效3D扩散模型的关键。本文介绍了一种名为COD-VAE的VAE，它将3D形状编码为紧凑的1D隐区间集合，而不牺牲质量。COD-VAE引入了两阶段自编码方案以提高压缩和解码效率。首先，我们的编码块逐步通过中间点片将点云压缩为紧凑的隐向量。其次，我们的基于三平面的解码器从隐向量重构密集的三平面，而不是直接解码神经场，从而显著减少了神经场解码的计算开销。最后，我们提出了基于不确定性指导的标记剪枝方法，通过在简单区域跳过计算来适应性地分配资源，从而提高解码效率。实验结果表明，与 baseline 相比，COD-VAE 实现了16倍的压缩比，同时保持了质量。这使得生成速度提高了20.8倍，展示了高质量重建和生成并不一定需要大量的隐向量。', 'title_zh': '用64个潜在向量表示3D形状：适用于3D扩散模型'}
{'arxiv_id': 'arXiv:2503.08734', 'title': 'Zero-to-One IDV: A Conceptual Model for AI-Powered Identity Verification', 'authors': 'Aniket Vaidya, Anurag Awasthi', 'link': 'https://arxiv.org/abs/2503.08734', 'abstract': "In today's increasingly digital interactions, robust Identity Verification (IDV) is crucial for security and trust. Artificial Intelligence (AI) is transforming IDV, enhancing accuracy and fraud detection. This paper introduces ``Zero to One,'' a holistic conceptual framework for developing AI-powered IDV products. This paper outlines the foundational problem and research objectives that necessitate a new framework for IDV in the age of AI. It details the evolution of identity verification and the current regulatory landscape to contextualize the need for a robust conceptual model. The core of the paper is the presentation of the ``Zero to One'' framework itself, dissecting its four essential components: Document Verification, Biometric Verification, Risk Assessment, and Orchestration. The paper concludes by discussing the implications of this conceptual model and suggesting future research directions focused on the framework's further development and application. The framework addresses security, privacy, UX, and regulatory compliance, offering a structured approach to building effective IDV solutions. Successful IDV platforms require a balanced conceptual understanding of verification methods, risk management, and operational scalability, with AI as a key enabler. This paper presents the ``Zero to One'' framework as a refined conceptual model, detailing verification layers, and AI's transformative role in shaping next-generation IDV products.", 'abstract_zh': '在日益数字化的交互中，强大的身份验证（IDV）对于安全和信任至关重要。人工智能（AI）正在转型身份验证，提高准确性和欺诈检测。本文介绍“从零到一”这一整体概念框架，用于开发AI赋能的身份验证产品。本文概述了在人工智能时代 necessitate 新框架的基础问题和研究目标，详细介绍了身份验证的发展历程和当前监管环境，以阐述构建稳健概念模型的必要性。论文的核心在于“从零到一”框架本身，拆解其四个核心组件：文档验证、生物验证、风险评估和编排。论文最后讨论该概念模型的含义，并建议未来的研究方向集中在框架的进一步开发和应用上。该框架涵盖了安全、隐私、用户体验和合规性，提供了一个构建有效身份验证解决方案的结构化方法。成功的身份验证平台需要平衡验证方法、风险管理以及运营规模化的理解，AI是关键使能器。本文展示了“从零到一”框架作为一个细化的概念模型，详细描述了验证层次以及AI在塑造下一代身份验证产品中的变革性作用。', 'title_zh': '从零到一的个人识别：一种基于人工智能的身份验证概念模型'}
{'arxiv_id': 'arXiv:2503.08732', 'title': 'Quantifying Circadian Desynchrony in ICU Patients and Its Association with Delirium', 'authors': 'Yuanfang Ren, Andrea E. Davidson, Jiaqing Zhang, Miguel Contreras, Ayush K. Patel, Michelle Gumz, Tezcan Ozrazgat-Baslanti, Parisa Rashidi, Azra Bihorac', 'link': 'https://arxiv.org/abs/2503.08732', 'abstract': "Background: Circadian desynchrony characterized by the misalignment between an individual's internal biological rhythms and external environmental cues, significantly affects various physiological processes and health outcomes. Quantifying circadian desynchrony often requires prolonged and frequent monitoring, and currently, an easy tool for this purpose is missing. Additionally, its association with the incidence of delirium has not been clearly explored. Methods: A prospective observational study was carried out in intensive care units (ICU) of a tertiary hospital. Circadian transcriptomics of blood monocytes from 86 individuals were collected on two consecutive days, although a second sample could not be obtained from all participants. Using two public datasets comprised of healthy volunteers, we replicated a model for determining internal circadian time. We developed an approach to quantify circadian desynchrony by comparing internal circadian time and external blood collection time. We applied the model and quantified circadian desynchrony index among ICU patients, and investigated its association with the incidence of delirium. Results: The replicated model for determining internal circadian time achieved comparable high accuracy. The quantified circadian desynchrony index was significantly higher among critically ill ICU patients compared to healthy subjects, with values of 10.03 hours vs 2.50-2.95 hours (p < 0.001). Most ICU patients had a circadian desynchrony index greater than 9 hours. Additionally, the index was lower in patients whose blood samples were drawn after 3pm, with values of 5.00 hours compared to 10.01-10.90 hours in other groups (p < 0.001)...", 'abstract_zh': '背景：由个体内部生物节律与外部环境线索的错位所定义的昼夜节律失同步，严重影响了各种生理过程和健康结果。测量昼夜节律失同步通常需要长时间和频繁的监测，目前缺乏一种简便的工具。此外，其与谵妄发病的相关性尚未得到明确探讨。方法：在三级医院的重症监护室（ICU）中进行前瞻性观察研究。收集了86名个体连续两天的外周血单个核细胞的昼夜转录组学数据，尽管并非所有参与者都提供了第二个样本。使用包含健康志愿者的两个公共数据集，我们复制了一个确定内在昼夜时间的模型。我们开发了一种方法，通过比较内在昼夜时间和外在采血时间来量化昼夜节律失同步。我们应用该模型量化了ICU患者昼夜节律失同步指数，并研究了其与谵妄发病率之间的关联。结果：复制的确定内在昼夜时间的模型达到了相似的高准确性。量化得到的昼夜节律失同步指数在重症ICU患者中显著高于健康对照，分别为10.03小时 vs 2.50-2.95小时（p < 0.001）。大多数ICU患者昼夜节律失同步指数超过9小时。此外，下午3点后采集样本的患者指数较低，值为5.00小时，而在其他组则为10.01-10.90小时（p < 0.001）...', 'title_zh': '重症监护病房患者昼夜节律不同步的程度及其与谵妄的相关性'}
{'arxiv_id': 'arXiv:2503.08729', 'title': 'Preserving Product Fidelity in Large Scale Image Recontextualization with Diffusion Models', 'authors': 'Ishaan Malhi, Praneet Dutta, Ellie Talius, Sally Ma, Brendan Driscoll, Krista Holden, Garima Pruthi, Arunachalam Narayanaswamy', 'link': 'https://arxiv.org/abs/2503.08729', 'abstract': "We present a framework for high-fidelity product image recontextualization using text-to-image diffusion models and a novel data augmentation pipeline. This pipeline leverages image-to-video diffusion, in/outpainting & negatives to create synthetic training data, addressing limitations of real-world data collection for this task. Our method improves the quality and diversity of generated images by disentangling product representations and enhancing the model's understanding of product characteristics. Evaluation on the ABO dataset and a private product dataset, using automated metrics and human assessment, demonstrates the effectiveness of our framework in generating realistic and compelling product visualizations, with implications for applications such as e-commerce and virtual product showcasing.", 'abstract_zh': '基于文本到图像扩散模型和新型数据增强管道的高保真产品图重新语境化框架', 'title_zh': '在大规模图像重新情境化中保持产品 fidelity 的扩散模型方法'}
{'arxiv_id': 'arXiv:2503.08728', 'title': 'Enhancing Traffic Signal Control through Model-based Reinforcement Learning and Policy Reuse', 'authors': 'Yihong Li, Chengwei Zhang, Furui Zhan, Wanting Liu, Kailing Zhou, Longji Zheng', 'link': 'https://arxiv.org/abs/2503.08728', 'abstract': 'Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and road network conditions used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies and environment models using predefined source-domain traffic scenarios. The environment model predicts the state transitions, which facilitates the comparison of environmental features. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.', 'abstract_zh': '基于PLight和PRLight的多Agent强化学习在交通信号控制中的应用研究', 'title_zh': '基于模型的强化学习和策略重用提升交通信号控制'}
{'arxiv_id': 'arXiv:2503.08727', 'title': 'Training Plug-n-Play Knowledge Modules with Deep Context Distillation', 'authors': 'Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni', 'link': 'https://arxiv.org/abs/2503.08727', 'abstract': 'Dynamically integrating new or rapidly evolving information after (Large) Language Model pre-training remains challenging, particularly in low-data scenarios or when dealing with private and specialized documents. In-context learning and retrieval-augmented generation (RAG) face limitations, including their high inference costs and their inability to capture global document information. In this paper, we propose a way of modularizing knowledge by training document-level Knowledge Modules (KMs). KMs are lightweight components implemented as parameter-efficient LoRA modules, which are trained to store information about new documents and can be easily plugged into models on demand. We show that next-token prediction performs poorly as the training objective for KMs. We instead propose Deep Context Distillation: we learn KMs parameters such as to simulate hidden states and logits of a teacher that takes the document in context. Our method outperforms standard next-token prediction and pre-instruction training techniques, across two datasets. Finally, we highlight synergies between KMs and retrieval-augmented generation.', 'abstract_zh': '在大型语言模型预训练后动态集成新信息或快速演变的信息仍具挑战性，特别是在低数据场景或处理私有和专业化文档时。基于上下文的学习和检索增强生成（RAG）面临高推理成本和难以捕捉全局文档信息的局限。本文提出了一种通过训练文档级知识模块（KMs）对知识进行模块化的方法。KMs是轻量级的参数高效LoRA模块，用于存储新文档的信息，并可根据需要随时插入模型中。我们展示了下一标记预测不适合作为KMs的训练目标。相反，我们提出了深度上下文蒸馏：通过学习KMs参数，使其模拟教师模型在上下文中处理文档时的隐藏状态和logits。我们的方法在两个数据集上均优于标准的下一标记预测和预指令训练技术。最后，我们强调了KMs与检索增强生成之间的协同作用。', 'title_zh': '基于深度语境蒸馏的即插即用知识模块训练'}
{'arxiv_id': 'arXiv:2503.08726', 'title': 'SIMAC: A Semantic-Driven Integrated Multimodal Sensing And Communication Framework', 'authors': 'Yubo Peng, Luping Xiang, Kun Yang, Feibo Jiang, Kezhi Wang, Dapeng Oliver Wu', 'link': 'https://arxiv.org/abs/2503.08726', 'abstract': "Traditional single-modality sensing faces limitations in accuracy and capability, and its decoupled implementation with communication systems increases latency in bandwidth-constrained environments. Additionally, single-task-oriented sensing systems fail to address users' diverse demands. To overcome these challenges, we propose a semantic-driven integrated multimodal sensing and communication (SIMAC) framework. This framework leverages a joint source-channel coding architecture to achieve simultaneous sensing decoding and transmission of sensing results. Specifically, SIMAC first introduces a multimodal semantic fusion (MSF) network, which employs two extractors to extract semantic information from radar signals and images, respectively. MSF then applies cross-attention mechanisms to fuse these unimodal features and generate multimodal semantic representations. Secondly, we present a large language model (LLM)-based semantic encoder (LSE), where relevant communication parameters and multimodal semantics are mapped into a unified latent space and input to the LLM, enabling channel-adaptive semantic encoding. Thirdly, a task-oriented sensing semantic decoder (SSD) is proposed, in which different decoded heads are designed according to the specific needs of tasks. Simultaneously, a multi-task learning strategy is introduced to train the SIMAC framework, achieving diverse sensing services. Finally, experimental simulations demonstrate that the proposed framework achieves diverse sensing services and higher accuracy.", 'abstract_zh': '基于语义驱动的集成多模态传感与通信（SIMAC）框架', 'title_zh': 'SIMAC：一种语义驱动的多模态传感与通信集成框架'}
{'arxiv_id': 'arXiv:2503.08725', 'title': 'The Algorithmic State Architecture (ASA): An Integrated Framework for AI-Enabled Government', 'authors': 'Zeynep Engin, Jon Crowcroft, David Hand, Philip Treleaven', 'link': 'https://arxiv.org/abs/2503.08725', 'abstract': 'As artificial intelligence transforms public sector operations, governments struggle to integrate technological innovations into coherent systems for effective service delivery. This paper introduces the Algorithmic State Architecture (ASA), a novel four-layer framework conceptualising how Digital Public Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and GovTech interact as an integrated system in AI-enabled states. Unlike approaches that treat these as parallel developments, ASA positions them as interdependent layers with specific enabling relationships and feedback mechanisms. Through comparative analysis of implementations in Estonia, Singapore, India, and the UK, we demonstrate how foundational digital infrastructure enables systematic data collection, which powers algorithmic decision-making processes, ultimately manifesting in user-facing services. Our analysis reveals that successful implementations require balanced development across all layers, with particular attention to integration mechanisms between them. The framework contributes to both theory and practice by bridging previously disconnected domains of digital government research, identifying critical dependencies that influence implementation success, and providing a structured approach for analysing the maturity and development pathways of AI-enabled government systems.', 'abstract_zh': '随着人工智能改造公共部门运营，政府努力将技术革新整合到一致的系统中以实现有效的公共服务交付。本文介绍了一种新的四层框架——算法国家架构（ASA），该框架设想了在人工智能驱动的国家中数字公共基础设施、数据为政策服务、算法政府/治理和GovTech如何作为一种集成系统相互作用。ASA将它们定位为相互依赖的层次，具有特定的使能关系和反馈机制，不同于将它们视为平行发展的方法。通过比较爱沙尼亚、新加坡、印度和英国的实施情况，我们展示了基础数字基础设施如何促进系统性数据收集，从而为算法决策过程提供动力，最终体现在面向用户的服务中。我们的分析表明，成功的实施需要在所有层次上平衡发展，并特别注意它们之间的整合机制。该框架通过将数字政府研究中之前分离的领域连接起来，识别影响实施成功的关键依赖性，并提供了一种分析人工智能驱动政府系统成熟度和发展路径的结构化方法，从而为理论和实践做出了贡献。', 'title_zh': 'AI赋能政府的综合架构：算法状态架构（ASA）'}
{'arxiv_id': 'arXiv:2503.08722', 'title': 'A Recipe for Improving Remote Sensing VLM Zero Shot Generalization', 'authors': 'Aviad Barzilai, Yotam Gigi, Vered Silverman, Yehonathan Refael, Bolous Jaber, Amr Helmy, Tomer Shekel, George Leifman, Genady Beryozkin', 'link': 'https://arxiv.org/abs/2503.08722', 'abstract': "Foundation models have had a significant impact across various AI applications, enabling use cases that were previously impossible. Contrastive Visual Language Models (VLMs), in particular, have outperformed other techniques in many tasks. However, their prevalence in remote sensing (RS) is still limited, due to the scarcity of diverse remote-sensing visual-language datasets. In this work we introduce two novel image-caption datasets for training of remote sensing foundation models. The first dataset pairs aerial and satellite imagery with captions generated by Gemini using landmarks extracted from Google Maps. The second dataset utilizes public web images and their corresponding alt-text, filtered for the remote sensing domain, resulting in a diverse dataset with greater breadth in image styles and subject matter. These datasets are used to pre-train the MaMMUT~\\citep{kuo2023mammutsimplearchitecturejoint} VLM architecture, resulting in state-of-the-art generalization performance in zero-shot cross-modal retrieval on well-known public benchmarks. Finally, we present our ongoing research to distill image-level knowledge gained in the VLM contrastive training procedure to enhance the model's localization ability. Specifically, we iteratively generate pseudo-labels for image regions based on the model's attention maps and use these labels for further training. To mitigate noisy attention maps and create robust segmentation masks, we introduce a novel attention-pooling mechanism called the Smooth-Attention-Operation.", 'abstract_zh': '基于模型在各类AI应用中产生了重要影响，使得许多之前不可能实现的应用成为可能。特别是在遥感（RS）领域，对比视觉语言模型（VLMs）已经在许多任务中表现出色，但由于缺乏多样性的遥感视觉语言数据集，其应用依然受限。本文引入了两个新的图像配 caption 数据集，用于训练遥感基础模型。第一个数据集将空中和卫星图像与由 Gemini 生成的、使用 Google 地图中的地标信息生成的 captions 进行配对。第二个数据集则利用公共网页图像及其相应的 alt-text，并针对遥感领域进行了筛选，从而形成一个更具多样性的数据集，涵盖了更广泛的照片风格和主题。这些数据集用于预训练 MaMMUT 模型架构，在著名的公开基准上的零样本跨模态检索表现出了最先进的泛化性能。最后，本文介绍了我们正在进行的研究，旨在通过 VLM 对比训练过程中获得的图像级知识来增强模型的空间定位能力。具体来说，我们基于模型的注意力图迭代生成图像区域的伪标签，并利用这些标签进行进一步的训练。为了减少注意力图中的噪声并创建鲁棒的分割掩码，我们引入了一种新的注意力池化机制，称为平滑注意力操作。', 'title_zh': '提高遥感VLM零样本泛化能力的配方'}
{'arxiv_id': 'arXiv:2503.08720', 'title': 'AI for Just Work: Constructing Diverse Imaginations of AI beyond "Replacing Humans"', 'authors': 'Weina Jin, Nicholas Vincent, Ghassan Hamarneh', 'link': 'https://arxiv.org/abs/2503.08720', 'abstract': 'The AI community usually focuses on "how" to develop AI techniques, but lacks thorough open discussions on "why" we develop AI. Lacking critical reflections on the general visions and purposes of AI may make the community vulnerable to manipulation. In this position paper, we explore the "why" question of AI. We denote answers to the "why" question the imaginations of AI, which depict our general visions, frames, and mindsets for the prospects of AI. We identify that the prevailing vision in the AI community is largely a monoculture that emphasizes objectives such as replacing humans and improving productivity. Our critical examination of this mainstream imagination highlights its underpinning and potentially unjust assumptions. We then call to diversify our collective imaginations of AI, embedding ethical assumptions from the outset in the imaginations of AI. To facilitate the community\'s pursuit of diverse imaginations, we demonstrate one process for constructing a new imagination of "AI for just work," and showcase its application in the medical image synthesis task to make it more ethical. We hope this work will help the AI community to open dialogues with civil society on the visions and purposes of AI, and inspire more technical works and advocacy in pursuit of diverse and ethical imaginations to restore the value of AI for the public good.', 'abstract_zh': '人工智能社区通常关注“如何”发展人工智能技术，但在“为何”发展人工智能的全面开放讨论方面存在不足。缺乏对人工智能总体愿景和目的的批判性反思可能使社区容易受到操纵。在本文中，我们探讨人工智能的“为何”问题。我们将对“为何”问题的回答称为人工智能的想象，描绘了我们对人工智能前景的一般愿景、框架和心态。我们指出，人工智能社区中占主导地位的愿景在很大程度上是一种单一文化，强调如取代人类和提高生产力等目标。我们对这一主流想象的批判性审查揭示了其潜在的不合理假设。然后，我们呼吁多样化我们对人工智能的集体想象，在一开始就将伦理假设嵌入人工智能的想象中。为了促进社区在追求多样性和伦理想象方面的努力，我们展示了一个构建“为公平工作而的人工智能”新想象的过程，并在医学图像合成任务中展示了其如何使其更加符合伦理。我们希望这项工作能帮助人工智能社区与社会公众开启关于人工智能愿景和目的的对话，促进更多的技术工作和倡导以追求多样而伦理的想象，以恢复人工智能为公共利益服务的价值。', 'title_zh': 'AI 促进公正工作：构建超越“取代人类”的多元想象'}
{'arxiv_id': 'arXiv:2503.08717', 'title': 'A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain', 'authors': 'Xiaoping Sun, Sirui Zhuge, Hai Zhuge', 'link': 'https://arxiv.org/abs/2503.08717', 'abstract': 'The ability of tracing states of logistic transportations requires an efficient storage and retrieval of the state of logistic transportations and locations of logistic objects. However, the restriction of sharing states and locations of logistic objects across organizations from different countries makes it hard to deploy a centralized database for implementing the traceability in a cross-border logistic system. This paper proposes a semantic data model on Blockchain to represent a logistic process based on the Semantic Link Network model where each semantic link represents a logistic transportation of a logistic object between two parties. A state representation model is designed to represent the states of a logistic transportation with semantic links. It enables the locations of logistic objects to be derived from the link states. A mapping from the semantic links to the blockchain transactions is designed to enable schema of semantic links and states of semantic links to be published in blockchain transactions. To improve the efficiency of tracing a path of semantic links on blockchain platform, an algorithm is designed to build shortcuts along the path of semantic links to enable a query on the path of a logistic object to reach the target in logarithmic steps on the blockchain platform. A reward-penalty policy is designed to allow participants to confirm the state of links on blockchain. Analysis and simulation demonstrate the flexibility, effectiveness and the efficiency of Semantic Link Network on immutable blockchain for implementing logistic traceability.', 'abstract_zh': '基于Semantic Link Network模型的区块链语义数据模型在跨境物流追溯中的应用', 'title_zh': '区块链支持物流可追溯的语义链接网络模型'}
{'arxiv_id': 'arXiv:2503.08716', 'title': 'AuthorMist: Evading AI Text Detectors with Reinforcement Learning', 'authors': 'Isaac David, Arthur Gervais', 'link': 'https://arxiv.org/abs/2503.08716', 'abstract': 'In the age of powerful AI-generated text, automatic detectors have emerged to identify machine-written content. This poses a threat to author privacy and freedom, as text authored with AI assistance may be unfairly flagged. We propose AuthorMist, a novel reinforcement learning-based system to transform AI-generated text into human-like writing. AuthorMist leverages a 3-billion-parameter language model as a backbone, fine-tuned with Group Relative Policy Optimization (GPRO) to paraphrase text in a way that evades AI detectors.\nOur framework establishes a generic approach where external detector APIs (GPTZero, WinstonAI, this http URL, etc.) serve as reward functions within the reinforcement learning loop, enabling the model to systematically learn outputs that these detectors are less likely to classify as AI-generated. This API-as-reward methodology can be applied broadly to optimize text against any detector with an accessible interface. Experiments on multiple datasets and detectors demonstrate that AuthorMist effectively reduces the detectability of AI-generated text while preserving the original meaning. Our evaluation shows attack success rates ranging from 78.6% to 96.2% against individual detectors, significantly outperforming baseline paraphrasing methods. AuthorMist maintains high semantic similarity (above 0.94) with the original text while successfully evading detection. These results highlight limitations in current AI text detection technologies and raise questions about the sustainability of the detection-evasion arms race.', 'abstract_zh': '在强大AI生成文本的时代，自动检测器 Emerged to Identify Machine-Generated Content 并对其进行识别，这给作者隐私和自由带来了威胁，因为接受AI辅助撰写的文本可能会被不公平地标记为机器生成。我们提出了AuthorMist，这是一种基于强化学习的新颖系统，旨在将AI生成的文本转换为人类风格的写作。AuthorMist利用了一个30亿参数的语言模型作为基础，并通过组相对策略优化（GPRO）进行了微调，以以避开AI检测器的方式来重述文本。我们的框架提供了一种通用的方法，其中外部检测器API（如GPTZero、WinstonAI、等）在强化学习循环中作为奖励函数使用，使模型能够系统地学习这些检测器不太可能将其分类为AI生成的输出。这种方法可以广泛应用于优化文本以对抗任何具有访问接口的检测器。在多个数据集和检测器上的实验表明，AuthorMist有效地降低了AI生成文本的可检测性，同时保留了原始意义。我们的评估显示，AuthorMist在针对个别检测器的攻击成功率范围为78.6%至96.2%，显著优于基线重述方法。AuthorMist在保留与原始文本高语义相似度（超过0.94）的同时成功躲避检测。这些结果突显了当前AI文本检测技术的局限性，并引发了关于检测-躲避军备竞赛可持续性的讨论。', 'title_zh': 'AuthorMist: 用强化学习规避AI文本检测器'}
{'arxiv_id': 'arXiv:2503.08714', 'title': 'Versatile Multimodal Controls for Whole-Body Talking Human Animation', 'authors': 'Zheng Qin, Ruobing Zheng, Yabing Wang, Tianqi Li, Zixin Zhu, Minghui Yang, Ming Yang, Le Wang', 'link': 'https://arxiv.org/abs/2503.08714', 'abstract': 'Human animation from a single reference image shall be flexible to synthesize whole-body motion for either a headshot or whole-body portrait, where the motions are readily controlled by audio signal and text prompts. This is hard for most existing methods as they only support producing pre-specified head or half-body motion aligned with audio inputs. In this paper, we propose a versatile human animation method, i.e., VersaAnimator, which generates whole-body talking human from arbitrary portrait images, not only driven by audio signal but also flexibly controlled by text prompts. Specifically, we design a text-controlled, audio-driven motion generator that produces whole-body motion representations in 3D synchronized with audio inputs while following textual motion descriptions. To promote natural smooth motion, we propose a code-pose translation module to link VAE codebooks with 2D DWposes extracted from template videos. Moreover, we introduce a multi-modal video diffusion that generates photorealistic human animation from a reference image according to both audio inputs and whole-body motion representations. Extensive experiments show that VersaAnimator outperforms existing methods in visual quality, identity preservation, and audio-lip synchronization.', 'abstract_zh': '单张参考图像的人体动画生成应该能够灵活合成头部特写或全身肖像的全身运动，且这些运动可以通过音频信号和文本提示方便地控制。大多数现有方法难以实现这一点，因为它们仅支持生成与音频输入对齐的预定义头部或半身运动。本文提出了一种通用的人体动画方法，即VersaAnimator，能够从任意肖像图像生成全身讲话的人体动画，不仅受音频信号驱动，还可通过文本提示灵活控制。具体而言，我们设计了一种受文本控制、由音频驱动的运动生成器，该生成器能够生成与音频输入同步的全身运动表示，并遵循文本运动描述以实现自然流畅的运动。为了促进自然平滑的运动，我们提出了一种代码-姿态转换模块，将VAE代码书与从模板视频中提取的2D DWposes链接起来。此外，我们引入了一种多模态视频扩散方法，可以根据参考图像、音频输入以及全身运动表示生成逼真人像动画。大量实验表明，VersaAnimator在视觉质量、身份保留和音频唇部同步方面优于现有方法。', 'title_zh': '全身对话人类动画的多功能多模态控制'}
{'arxiv_id': 'arXiv:2503.08712', 'title': 'SHAP-Integrated Convolutional Diagnostic Networks for Feature-Selective Medical Analysis', 'authors': 'Yan Hu, Ahmad Chaddad', 'link': 'https://arxiv.org/abs/2503.08712', 'abstract': 'This study introduces the SHAP-integrated convolutional diagnostic network (SICDN), an interpretable feature selection method designed for limited datasets, to address the challenge posed by data privacy regulations that restrict access to medical datasets. The SICDN model was tested on classification tasks using pneumonia and breast cancer datasets, demonstrating over 97% accuracy and surpassing four popular CNN models. We also integrated a historical weighted moving average technique to enhance feature selection. The SICDN shows potential in medical image prediction, with the code available on this https URL.', 'abstract_zh': 'SHAP-集成卷积诊断网络（SICDN）：一种适用于有限数据集的可解释特征选择方法及其在医疗数据隐私限制下的应用', 'title_zh': 'SHAP-集成卷积诊断网络的特征选择性医疗分析'}
{'arxiv_id': 'arXiv:2503.08711', 'title': 'A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem', 'authors': 'Yajie Wen, Defu Zhang', 'link': 'https://arxiv.org/abs/2503.08711', 'abstract': 'This paper introduces BSPA, a parallel algorithm that leverages beam search to address the two-dimensional strip packing problem. The study begins with a comprehensive review of existing approaches and methodologies, followed by a detailed presentation of the BSPA algorithm. Experimental results demonstrate the effectiveness of the proposed method. To facilitate further research, both the code and datasets are publicly available.', 'abstract_zh': '本文介绍了BSPA，这是一种利用束搜索方法解决二维条形 packing 问题的并行算法。研究从现有方法和方法论的全面回顾开始，随后详细介绍了BSPA算法。实验结果证明了所提出方法的有效性。为了促进进一步的研究，相关代码和数据集均已公开。', 'title_zh': '基于束搜索的二维条形 packing 问题并行算法'}
{'arxiv_id': 'arXiv:2503.08709', 'title': 'Simulating Influence Dynamics with LLM Agents', 'authors': 'Mehwish Nasim, Syed Muslim Gilani, Amin Qasmi, Usman Naseem', 'link': 'https://arxiv.org/abs/2503.08709', 'abstract': 'This paper introduces a simulator designed for opinion dynamics researchers to model competing influences within social networks in the presence of LLM-based agents. By integrating established opinion dynamics principles with state-of-the-art LLMs, this tool enables the study of influence propagation and counter-misinformation strategies. The simulator is particularly valuable for researchers in social science, psychology, and operations research, allowing them to analyse societal phenomena without requiring extensive coding expertise. Additionally, the simulator will be openly available on GitHub, ensuring accessibility and adaptability for those who wish to extend its capabilities for their own research.', 'abstract_zh': '本文介绍了一种模拟器，该模拟器旨在帮助意见动力学研究人员在基于LLM的代理存在的情况下，建模社交网络中相互竞争的影响。通过将成熟的意见动力学原理与最先进的LLM相结合，该工具能够研究影响传播和反误信息策略。该模拟器特别适合社会科学研究、心理学和运筹学领域的研究人员，允许他们在无需大量编程专业知识的情况下分析社会现象。此外，该模拟器将在GitHub上开放获取，确保其对希望扩展其功能以满足自己研究需求的人们具有可访问性和适应性。', 'title_zh': '使用LLM代理模拟影响动力学'}
{'arxiv_id': 'arXiv:2503.08708', 'title': 'TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors', 'authors': 'Jingyi Zheng, Junfeng Wang, Zhen Sun, Wenhan Dong, Yule Liu, Xinlei He', 'link': 'https://arxiv.org/abs/2503.08708', 'abstract': 'As Large Language Models (LLMs) advance, Machine-Generated Texts (MGTs) have become increasingly fluent, high-quality, and informative. Existing wide-range MGT detectors are designed to identify MGTs to prevent the spread of plagiarism and misinformation. However, adversaries attempt to humanize MGTs to evade detection (named evading attacks), which requires only minor modifications to bypass MGT detectors. Unfortunately, existing attacks generally lack a unified and comprehensive evaluation framework, as they are assessed using different experimental settings, model architectures, and datasets. To fill this gap, we introduce the Text-Humanization Benchmark (TH-Bench), the first comprehensive benchmark to evaluate evading attacks against MGT detectors. TH-Bench evaluates attacks across three key dimensions: evading effectiveness, text quality, and computational overhead. Our extensive experiments evaluate 6 state-of-the-art attacks against 13 MGT detectors across 6 datasets, spanning 19 domains and generated by 11 widely used LLMs. Our findings reveal that no single evading attack excels across all three dimensions. Through in-depth analysis, we highlight the strengths and limitations of different attacks. More importantly, we identify a trade-off among three dimensions and propose two optimization insights. Through preliminary experiments, we validate their correctness and effectiveness, offering potential directions for future research.', 'abstract_zh': '随着大型语言模型（LLMs）的发展，机器生成文本（MGTs）变得越来越流畅、高质量且信息丰富。现有的广泛范围的MGT检测器设计用于识别MGTs以防止剽窃和错误信息的传播。然而，攻击者试图通过对MGT进行人性化修改来规避检测（称为规避攻击），只需要进行少量修改即可绕过MGT检测器。不幸的是，现有的攻击缺乏一个统一且全面的评估框架，因为它们通常使用不同的实验设置、模型架构和数据集进行评估。为了填补这一空白，我们引入了文本人性化基准（TH-Bench），这是第一个用于评估MGT检测器规避攻击的全面基准。TH-Bench从三个关键维度评估攻击：规避效果、文本质量和计算开销。我们的广泛实验在六个数据集上评估了六种最先进的攻击，这些数据集涵盖了19个领域，由11个广泛使用的LLMs生成。我们的发现表明，没有单一的规避攻击在所有三个维度中表现优异。通过深入分析，我们强调了不同攻击的优点和局限。更重要的是，我们识别出了三个维度之间的权衡，并提出了两种优化见解。通过初步实验，我们验证了它们的正确性和有效性，为未来的相关研究提供了潜在方向。', 'title_zh': 'TH-Bench: 通过人性化AI文本评估机器生成文本检测器的规避攻击'}
{'arxiv_id': 'arXiv:2503.08705', 'title': 'A Block-Based Heuristic Algorithm for the Three-Dimensional Nuclear Waste Packing Problem', 'authors': 'Yajie Wen, Defu Zhang', 'link': 'https://arxiv.org/abs/2503.08705', 'abstract': "In this study, we present a block-based heuristic search algorithm to address the nuclear waste container packing problem in the context of real-world nuclear power plants. Additionally, we provide a dataset comprising 1600 problem instances for future researchers to use. Experimental results on this dataset demonstrate that the proposed algorithm effectively enhances the disposal pool's space utilization while minimizing the radiation dose within the pool. The code and data employed in this study are publicly available to facilitate reproducibility and further investigation.", 'abstract_zh': '本研究提出了一种块基启发式搜索算法以解决实际核电厂中的核废料容器打包问题，并提供了包含1600个问题实例的数据集供未来研究使用。实验结果表明，所提出算法有效提高了处置池的空间利用率，同时最大限度地减少了池内的辐射剂量。本研究中使用的代码和数据均已公开，以促进再现性和进一步的研究。', 'title_zh': '基于块的启发式算法解决三维核廢物包装问题'}
{'arxiv_id': 'arXiv:2503.08704', 'title': 'Life-Cycle Routing Vulnerabilities of LLM Router', 'authors': 'Qiqi Lin, Xiaoyang Ji, Shengfang Zhai, Qingni Shen, Zhi Zhang, Yuejian Fang, Yansong Gao', 'link': 'https://arxiv.org/abs/2503.08704', 'abstract': 'Large language models (LLMs) have achieved remarkable success in natural language processing, yet their performance and computational costs vary significantly. LLM routers play a crucial role in dynamically balancing these trade-offs. While previous studies have primarily focused on routing efficiency, security vulnerabilities throughout the entire LLM router life cycle, from training to inference, remain largely unexplored. In this paper, we present a comprehensive investigation into the life-cycle routing vulnerabilities of LLM routers. We evaluate both white-box and black-box adversarial robustness, as well as backdoor robustness, across several representative routing models under extensive experimental settings. Our experiments uncover several key findings: 1) Mainstream DNN-based routers tend to exhibit the weakest adversarial and backdoor robustness, largely due to their strong feature extraction capabilities that amplify vulnerabilities during both training and inference; 2) Training-free routers demonstrate the strongest robustness across different attack types, benefiting from the absence of learnable parameters that can be manipulated. These findings highlight critical security risks spanning the entire life cycle of LLM routers and provide insights for developing more robust models.', 'abstract_zh': '大型语言模型（LLMs）在自然语言处理领域取得了显著成功，但其性能和计算成本差异明显。LLM路由器在动态平衡这些权衡方面发挥着关键作用。尽管以往研究主要关注路由效率，但整个LLM路由器生命周期（从训练到推断）中的安全漏洞依然鲜有探索。本文对LLM路由器的生命周期路由漏洞进行了全面调查，评估了多种代表性路由模型在广泛实验条件下的白盒和黑盒对抗鲁棒性以及后门鲁棒性。实验揭示了几项关键发现：1）基于主流深度神经网络（DNN）的路由器展现出最弱的对抗和后门鲁棒性，主要是由于其强大的特征提取能力在训练和推断过程中放大了漏洞；2）无需训练的路由器在不同攻击类型下表现出最强的鲁棒性，得益于没有可被操纵的学习参数。这些发现突显了整个LLM路由器生命周期中的关键安全风险，并为开发更鲁棒的模型提供了见解。', 'title_zh': 'LLM Router 生命周期路由漏洞'}
{'arxiv_id': 'arXiv:2503.08700', 'title': 'Real-Time Semantic Segmentation of Aerial Images Using an Embedded U-Net: A Comparison of CPU, GPU, and FPGA Workflows', 'authors': 'Julien Posso, Hugo Kieffer, Nicolas Menga, Omar Hlimi, Sébastien Tarris, Hubert Guerard, Guy Bois, Matthieu Couderc, Eric Jenn', 'link': 'https://arxiv.org/abs/2503.08700', 'abstract': "This study introduces a lightweight U-Net model optimized for real-time semantic segmentation of aerial images, targeting the efficient utilization of Commercial Off-The-Shelf (COTS) embedded computing platforms. We maintain the accuracy of the U-Net on a real-world dataset while significantly reducing the model's parameters and Multiply-Accumulate (MAC) operations by a factor of 16. Our comprehensive analysis covers three hardware platforms (CPU, GPU, and FPGA) and five different toolchains (TVM, FINN, Vitis AI, TensorFlow GPU, and cuDNN), assessing each on metrics such as latency, power consumption, memory footprint, energy efficiency, and FPGA resource usage. The results highlight the trade-offs between these platforms and toolchains, with a particular focus on the practical deployment challenges in real-world applications. Our findings demonstrate that while the FPGA with Vitis AI emerges as the superior choice due to its performance, energy efficiency, and maturity, it requires specialized hardware knowledge, emphasizing the need for a balanced approach in selecting embedded computing solutions for semantic segmentation tasks", 'abstract_zh': '本研究介绍了一种针对机载图像实时语义分割优化的轻量化U-Net模型，旨在高效利用商用现货（COTS）嵌入式计算平台。我们在保持U-Net在真实数据集上准确性的基础上，显著减少了模型的参数和乘积累加（MAC）操作，降低了16倍。我们的综合分析涵盖了三种硬件平台（CPU、GPU和FPGA）和五种不同的工具链（TVM、FINN、Vitis AI、TensorFlow GPU和cuDNN），评估指标包括延迟、功耗、内存占用、能量效率和FPGA资源使用情况。研究结果强调了这些平台和工具链之间的权衡，特别关注实际应用场景中的部署挑战。我们的发现表明，尽管使用Vitis AI的FPGA因其性能、能源效率和成熟度而成为更优选择，但其需要专门的硬件知识，强调了在语义分割任务中选择嵌入式计算解决方案时需要平衡这一点。', 'title_zh': '使用嵌入式U-Net进行实时机载图像语义分割：CPU、GPU和FPGA工作流的比较'}
{'arxiv_id': 'arXiv:2503.08699', 'title': 'Blockchain As a Platform For Artificial Intelligence (AI) Transparency', 'authors': 'Afroja Akther, Ayesha Arobee, Abdullah Al Adnan, Omum Auyon, ASM Johirul Islam, Farhad Akter', 'link': 'https://arxiv.org/abs/2503.08699', 'abstract': 'As artificial intelligence (AI) systems become increasingly complex and autonomous, concerns over transparency and accountability have intensified. The "black box" problem in AI decision-making limits stakeholders\' ability to understand, trust, and verify outcomes, particularly in high-stakes sectors such as healthcare, finance, and autonomous systems. Blockchain technology, with its decentralized, immutable, and transparent characteristics, presents a potential solution to enhance AI transparency and auditability. This paper explores the integration of blockchain with AI to improve decision traceability, data provenance, and model accountability. By leveraging blockchain as an immutable record-keeping system, AI decision-making can become more interpretable, fostering trust among users and regulatory compliance. However, challenges such as scalability, integration complexity, and computational overhead must be addressed to fully realize this synergy. This study discusses existing research, proposes a framework for blockchain-enhanced AI transparency, and highlights practical applications, benefits, and limitations. The findings suggest that blockchain could be a foundational technology for ensuring AI systems remain accountable, ethical, and aligned with regulatory standards.', 'abstract_zh': '随着人工智能（AI）系统变得日益复杂和自主，透明度和问责制方面的担忧加剧。AI决策中的“黑箱”问题限制了利益相关者理解、信任和验证结果的能力，特别是在医疗保健、金融和自主系统等高风险领域。由于区块链技术具有去中心化、不可变和透明的特性，它为提高AI透明度和可审计性提供了潜在解决方案。本文探讨了将区块链与AI集成以改进决策追踪性、数据溯源性和模型问责制的方法。通过利用区块链作为不可变的记账系统，AI决策可以变得更加可解释，从而在用户和监管合规方面培养信任。然而，必须应对诸如可扩展性、集成复杂性和计算成本等挑战，以充分利用这种协同效应。本文讨论了现有研究，提出了增强AI透明性的区块链框架，并指出了实际应用、优点和局限性。研究结果表明，区块链可能是确保AI系统保持问责、道德和符合监管标准的基础技术。', 'title_zh': '区块链作为人工智能透明性的平台'}
{'arxiv_id': 'arXiv:2503.04824', 'title': 'ProReflow: Progressive Reflow with Decomposed Velocity', 'authors': 'Lei Ke, Haohang Xu, Xuefei Ning, Yu Li, Jiajun Li, Haoling Li, Yuxuan Lin, Dongsheng Jiang, Yujiu Yang, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2503.04824', 'abstract': 'Diffusion models have achieved significant progress in both image and video generation while still suffering from huge computation costs. As an effective solution, flow matching aims to reflow the diffusion process of diffusion models into a straight line for a few-step and even one-step generation. However, in this paper, we suggest that the original training pipeline of flow matching is not optimal and introduce two techniques to improve it. Firstly, we introduce progressive reflow, which progressively reflows the diffusion models in local timesteps until the whole diffusion progresses, reducing the difficulty of flow matching. Second, we introduce aligned v-prediction, which highlights the importance of direction matching in flow matching over magnitude matching. Experimental results on SDv1.5 and SDXL demonstrate the effectiveness of our method, for example, conducting on SDv1.5 achieves an FID of 10.70 on MSCOCO2014 validation set with only 4 sampling steps, close to our teacher model (32 DDIM steps, FID = 10.05).', 'abstract_zh': '流匹配技术在改进扩散模型图像和视频生成中的应用及其优化方法', 'title_zh': '渐进式分解速度再镕: ProReflow'}
{'arxiv_id': 'arXiv:2411.01297', 'title': 'Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems', 'authors': 'Josue N. Rivera, Dengfeng Sun', 'link': 'https://arxiv.org/abs/2411.01297', 'abstract': "This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers, a novel class of neural network-based controllers for dynamical systems and explicit non-linear model predictive control. Hion controllers estimate future states and compute optimal control inputs using Pontryagin's Maximum Principle. The proposed framework allows for customization of transient behavior, addressing limitations of existing methods. The Taylored Multi-Faceted Approach for Neural ODE and Optimal Control (T-mano) architecture facilitates training and ensures accurate state estimation. Optimal control strategies are demonstrated for both linear and non-linear dynamical systems.", 'abstract_zh': 'This paper formalizes Hamiltonian-Informed Optimal Neural (HION) Controllers: A Novel Class of Neural Network-Based Controllers for Dynamical Systems and Explicit Non-Linear Model Predictive Control', 'title_zh': '退化的Hamiltonian启发式最优神经控制与状态估计用于闭环动力学系统'}
