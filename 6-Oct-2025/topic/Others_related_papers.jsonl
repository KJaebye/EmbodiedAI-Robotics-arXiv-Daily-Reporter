{'arxiv_id': 'arXiv:2510.02464', 'title': 'ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in Extended Reality', 'authors': 'Isaac Ngui, Courtney McBeth, André Santos, Grace He, Katherine J. Mimnaugh, James D. Motes, Luciano Soares, Marco Morales, Nancy M. Amato', 'link': 'https://arxiv.org/abs/2510.02464', 'abstract': 'We propose the Extended Reality Universal Planning Toolkit (ERUPT), an extended reality (XR) system for interactive motion planning. Our system allows users to create and dy- namically reconfigure environments while they plan robot paths. In immersive three-dimensional XR environments, users gain a greater spatial understanding. XR also unlocks a broader range of natural interaction capabilities, allowing users to grab and adjust objects in the environment similarly to the real world, rather than using a mouse and keyboard with the scene projected onto a two-dimensional computer screen. Our system integrates with MoveIt, a manipulation planning framework, allowing users to send motion planning requests and visualize the resulting robot paths in virtual or augmented reality. We provide a broad range of interaction modalities, allowing users to modify objects in the environment and interact with a virtual robot. Our system allows operators to visualize robot motions, ensuring desired behavior as it moves throughout the environment, without risk of collisions within a virtual space, and to then deploy planned paths on physical robots in the real world.', 'abstract_zh': '扩展现实通用规划工具包（ERUPT）：一种交互运动规划的扩展现实系统', 'title_zh': 'ERUPT：扩展现实环境中与机器人运动规划器接口的开源工具包'}
{'arxiv_id': 'arXiv:2510.02791', 'title': 'VERNIER: an open-source software pushing marker pose estimation down to the micrometer and nanometer scales', 'authors': 'Patrick Sandoz, Antoine N. André, Guillaume J. Laurent', 'link': 'https://arxiv.org/abs/2510.02791', 'abstract': 'Pose estimation is still a challenge at the small scales. Few solutions exist to capture the 6 degrees of freedom of an object with nanometric and microradians resolutions over relatively large ranges. Over the years, we have proposed several fiducial marker and pattern designs to achieve reliable performance for various microscopy applications. Centimeter ranges are possible using pattern encoding methods, while nanometer resolutions can be achieved using phase processing of the periodic frames. This paper presents VERNIER, an open source phase processing software designed to provide fast and reliable pose measurement based on pseudo-periodic patterns. Thanks to a phase-based local thresholding algorithm, the software has proven to be particularly robust to noise, defocus and occlusion. The successive steps of the phase processing are presented, as well as the different types of patterns that address different application needs. The implementation procedure is illustrated with synthetic and experimental images. Finally, guidelines are given for selecting the appropriate pattern design and microscope magnification lenses as a function of the desired performance.', 'abstract_zh': '小尺度下姿态估计仍是一项挑战。很少有解决方案能以纳米级和微弧度分辨率，在相对大范围内捕获对象的6自由度。多年来，我们提出了几种标记和模式设计，以实现各种显微镜应用的可靠性能。利用模式编码方法可实现厘米范围，而利用周期性帧的相位处理可实现纳米级分辨率。本文介绍了VERNIER，一款基于伪周期性模式设计的开源相位处理软件，提供基于相位的快速可靠姿态测量。得益于基于相位的局部阈值算法，该软件对噪声、焦距偏移和遮挡具有特别的鲁棒性。相位处理的各个步骤以及适应不同应用需求的不同类型模式被呈现，同时用合成和实验图像说明了其实现过程。最后，给出了根据期望的性能选择合适的模式设计和显微镜放大镜的指南。', 'title_zh': 'VERNIER：一款将标记物姿态估计精度推向微米和纳米尺度的开源软件'}
{'arxiv_id': 'arXiv:2510.02769', 'title': 'Periodic Event-Triggered Prescribed Time Control of Euler-Lagrange Systems under State and Input Constraints', 'authors': 'Chidre Shravista Kashyap, Karnan A, Pushpak Jagtap, Jishnu Keshavan', 'link': 'https://arxiv.org/abs/2510.02769', 'abstract': 'This article proposes a periodic event-triggered adaptive barrier control policy for the trajectory tracking problem of perturbed Euler-Lagrangian systems with state, input, and temporal (SIT) constraints. In particular, an approximation-free adaptive-barrier control architecture is designed to ensure prescribed-time convergence of the tracking error to a prescribed bound while rejecting exogenous disturbances. In contrast to existing approaches that necessitate continuous real-time control action, the proposed controller generates event-based updates through periodic evaluation of the triggering condition. Additionally, we derive an upper bound on the monitoring period by analysing the performance degradation of the filtered tracking error to facilitate periodic evaluation of the event-triggered strategy. To this end, a time-varying threshold function is considered in the triggering mechanism to reduce the number of triggers during the transient phase of system behaviour. Notably, the proposed design avoids Zeno behaviour and precludes the need for continuous monitoring of the triggering condition. A simulation and experimental study is undertaken to demonstrate the efficacy of the proposed control scheme.', 'abstract_zh': '本文提出了一种周期事件触发自适应障碍控制器策略，用于受状态、输入和时间（SIT）约束的受扰欧拉-拉格朗日系统轨迹跟踪问题。特别地，设计了一种无近似自适应障碍控制器架构，以确保跟踪误差在预定时间内收敛到预定界，并拒绝外部干扰。与现有需要连续实时控制作用的方法不同，所提出的控制器通过周期性评估触发条件来生成事件驱动的更新。此外，通过分析过滤后的跟踪误差性能退化来推导出触发策略的监测周期的上界，以促进事件驱动策略的周期性评估。在此过程中，在触发机制中考虑了一个时间变阈值函数，以减少系统行为瞬态阶段的触发次数。值得注意的是，所提设计避开了Zeno行为，并消除了对触发条件连续监控的需要。进行了仿真和实验研究以证明所提出控制方案的有效性。', 'title_zh': '基于状态和输入约束的欧拉-拉格朗日系统在预定时间内的周期事件触发控制'}
{'arxiv_id': 'arXiv:2510.03127', 'title': "A Study of Rule Omission in Raven's Progressive Matrices", 'authors': 'Binze Li', 'link': 'https://arxiv.org/abs/2510.03127', 'abstract': "Analogical reasoning lies at the core of human cognition and remains a fundamental challenge for artificial intelligence. Raven's Progressive Matrices (RPM) serve as a widely used benchmark to assess abstract reasoning by requiring the inference of underlying structural rules. While many vision-based and language-based models have achieved success on RPM tasks, it remains unclear whether their performance reflects genuine reasoning ability or reliance on statistical shortcuts. This study investigates the generalization capacity of modern AI systems under conditions of incomplete training by deliberately omitting several structural rules during training. Both sequence-to-sequence transformer models and vision-based architectures such as CoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN (I-RAVEN) dataset. Experiments reveal that although transformers demonstrate strong performance on familiar rules, their accuracy declines sharply when faced with novel or omitted rules. Moreover, the gap between token-level accuracy and complete answer accuracy highlights fundamental limitations in current approaches. These findings provide new insights into the reasoning mechanisms underlying deep learning models and underscore the need for architectures that move beyond pattern recognition toward robust abstract reasoning.", 'abstract_zh': '类比推理是人类认知的核心，也是人工智能的基本挑战。雷文 progressives 图阵（RPM）常被用作评估抽象推理能力的标准，要求推断出潜在的结构规则。虽然许多基于视觉和语言的模型在RPM任务中取得了成功，但尚不清楚其性能是否反映了真实的推理能力，还是依赖于统计捷径。本研究在训练数据不完整的情况下考察现代AI系统的泛化能力，故意在训练过程中省略了几条结构规则。序列到序列的变换器模型和基于视觉的架构，如CoPINet和双对比网络，在Impartial-RAVEN（I-RAVEN）数据集上进行评估。实验表明，尽管变换器在熟悉规则上表现出强劲的性能，但在面对新颖或被省略的规则时，准确性会急剧下降。此外，token级准确率与完整答案准确率之间的差距进一步突显了当前方法的基本局限性。这些发现为深入学习模型的推理机制提供了新的见解，并强调了需要超越模式识别向着稳健的抽象推理迈进的架构的需求。', 'title_zh': '关于 Ravens 进步矩阵中规则省略的研究'}
{'arxiv_id': 'arXiv:2510.03078', 'title': 'From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments', 'authors': 'Anna Trapp, Mersedeh Sadeghi, Andreas Vogelsang', 'link': 'https://arxiv.org/abs/2510.03078', 'abstract': 'Explainability is increasingly seen as an essential feature of rule-based smart environments. While counterfactual explanations, which describe what could have been done differently to achieve a desired outcome, are a powerful tool in eXplainable AI (XAI), no established methods exist for generating them in these rule-based domains. In this paper, we present the first formalization and implementation of counterfactual explanations tailored to this domain. It is implemented as a plugin that extends an existing explanation engine for smart environments. We conducted a user study (N=17) to evaluate our generated counterfactuals against traditional causal explanations. The results show that user preference is highly contextual: causal explanations are favored for their linguistic simplicity and in time-pressured situations, while counterfactuals are preferred for their actionable content, particularly when a user wants to resolve a problem. Our work contributes a practical framework for a new type of explanation in smart environments and provides empirical evidence to guide the choice of when each explanation type is most effective.', 'abstract_zh': '基于规则的智能环境中可解释性的增强：counterfactual解释的正式化与实现', 'title_zh': '从事实到反事实：设计与评估智能环境中的反事实解释'}
{'arxiv_id': 'arXiv:2510.02996', 'title': 'Onto-Epistemological Analysis of AI Explanations', 'authors': 'Martina Mattioli, Eike Petersen, Aasa Feragen, Marcello Pelillo, Siavash A. Bigdeli', 'link': 'https://arxiv.org/abs/2510.02996', 'abstract': "Artificial intelligence (AI) is being applied in almost every field. At the same time, the currently dominant deep learning methods are fundamentally black-box systems that lack explanations for their inferences, significantly limiting their trustworthiness and adoption. Explainable AI (XAI) methods aim to overcome this challenge by providing explanations of the models' decision process. Such methods are often proposed and developed by engineers and scientists with a predominantly technical background and incorporate their assumptions about the existence, validity, and explanatory utility of different conceivable explanatory mechanisms. However, the basic concept of an explanation -- what it is, whether we can know it, whether it is absolute or relative -- is far from trivial and has been the subject of deep philosophical debate for millennia. As we point out here, the assumptions incorporated into different XAI methods are not harmless and have important consequences for the validity and interpretation of AI explanations in different domains. We investigate ontological and epistemological assumptions in explainability methods when they are applied to AI systems, meaning the assumptions we make about the existence of explanations and our ability to gain knowledge about those explanations. Our analysis shows how seemingly small technical changes to an XAI method may correspond to important differences in the underlying assumptions about explanations. We furthermore highlight the risks of ignoring the underlying onto-epistemological paradigm when choosing an XAI method for a given application, and we discuss how to select and adapt appropriate XAI methods for different domains of application.", 'abstract_zh': '人工 Intelligence (AI) 已几乎应用于所有领域。与此同时，当前主导的深度学习方法本质上是黑箱系统，缺乏对其推断过程的解释，严重限制了其可信度和应用。可解释的人工智能 (XAI) 方法旨在通过提供模型决策过程的解释来克服这一挑战。这类方法通常由具有主要技术背景的工程师和科学家提出，并结合了他们关于不同可设想的解释机制的存在、有效性及其解释用途的假设。然而，解释的基本概念——它是什么、我们能否知道它、它是绝对的还是相对的——远非不言自明，并且自古以来一直是深刻的哲学辩论的主题。如我们所指出的，不同 XAI 方法中的假设并非无害，对不同领域的 AI 解释的有效性和解释具有重要影响。我们在将可解释性方法应用于 AI 系统时对其本体论和认识论假设进行了分析，这意味着我们对解释的存在以及获取这些解释知识所做的假设。我们的分析表明，对 XAI 方法进行看似微小的技术更改可能对应于解释底层假设的重要差异。此外，我们强调了在选择适用于特定应用的 XAI 方法时忽略本体论与认识论范式的风险，并讨论了如何为不同应用领域选择和适应合适的 XAI 方法。', 'title_zh': 'AI解释的本体 epistemological 分析'}
{'arxiv_id': 'arXiv:2510.02677', 'title': 'ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks', 'authors': 'Zhaorun Chen, Xun Liu, Mintong Kang, Jiawei Zhang, Minzhou Pan, Shuang Yang, Bo Li', 'link': 'https://arxiv.org/abs/2510.02677', 'abstract': 'As vision-language models (VLMs) gain prominence, their multimodal interfaces also introduce new safety vulnerabilities, making the safety evaluation challenging and critical. Existing red-teaming efforts are either restricted to a narrow set of adversarial patterns or depend heavily on manual engineering, lacking scalable exploration of emerging real-world VLM vulnerabilities. To bridge this gap, we propose ARMs, an adaptive red-teaming agent that systematically conducts comprehensive risk assessments for VLMs. Given a target harmful behavior or risk definition, ARMs automatically optimizes diverse red-teaming strategies with reasoning-enhanced multi-step orchestration, to effectively elicit harmful outputs from target VLMs. We propose 11 novel multimodal attack strategies, covering diverse adversarial patterns of VLMs (e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming algorithms into ARMs via model context protocol (MCP). To balance the diversity and effectiveness of the attack, we design a layered memory with an epsilon-greedy attack exploration algorithm. Extensive experiments on instance- and policy-based benchmarks show that ARMs achieves SOTA attack success rates, exceeding baselines by an average of 52.1% and surpassing 90% on Claude-4-Sonnet. We show that the diversity of red-teaming instances generated by ARMs is significantly higher, revealing emerging vulnerabilities in VLMs. Leveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety dataset comprising over 30K red-teaming instances spanning 51 diverse risk categories, grounded in both real-world multimodal threats and regulatory risks. Safety fine-tuning with ARMs-Bench substantially improves the robustness of VLMs while preserving their general utility, providing actionable guidance to improve multimodal safety alignment against emerging threats.', 'abstract_zh': '随着视觉语言模型（VLMs）的重要性日益增加，其多模态接口也引入了新的安全漏洞，使得安全评估变得极具挑战性和关键性。现有的红队努力要么局限于狭窄的 adversarial 模式集合，要么高度依赖手动工程，缺乏对新兴实际世界 VLM 漏洞的大规模探索。为弥补这一差距，我们提出了一种自适应红队代理 ARMs，它系统地对 VLMs 进行全面的风险评估。给定一个目标有害行为或风险定义，ARMs 自动优化多种增强推理的多层次 orchestration 红队策略，以有效地从目标 VLMs 中引发有害输出。我们提出了 11 种新颖的多模态攻击策略，涵盖了 VLMs 的多种 adversarial 模式（例如推理劫持、上下文隐形），并通过模型上下文协议（MCP）将 17 种红队算法集成到 ARMs 中。为了平衡攻击的多样性和有效性，我们设计了一层记忆以及一个epsilon-贪心攻击探索算法。在基于实例和策略的基准测试中，大量的实验证明 ARM 实现了最先进的攻击成功率，平均超过基线 52.1%，在 Claude-4-Sonnet 上超过 90%。我们展示了 ARMs 生成的红队实例多样性显著更高，揭示了 VLMs 中新兴的漏洞。利用 ARM 构建 ARMs-Bench，这是一个包含超过 30,000 个红队实例的大规模多模态安全数据集，涵盖了 51 种不同风险类别，基于现实世界的多模态威胁和监管风险。通过使用 ARMs-Bench 进行安全性微调，VLMs 的鲁棒性显著提高，同时保持其通用功能，提供对抗新兴威胁改进多模态安全对准的实际指导。', 'title_zh': 'ARMs：针对多模态模型的自适应红队代理及插件式攻击方法'}
{'arxiv_id': 'arXiv:2510.02655', 'title': 'A Concept of Possibility for Real-World Events', 'authors': 'Daniel G. Schwartz', 'link': 'https://arxiv.org/abs/2510.02655', 'abstract': 'This paper offers a new concept of {\\it possibility} as an alternative to the now-a-days standard concept originally introduced by L.A. Zadeh in 1978. This new version was inspired by the original but, formally, has nothing in common with it other than that they both adopt the Łukasiewicz multivalent interpretation of the logical connectives. Moreover, rather than seeking to provide a general notion of possibility, this focuses specifically on the possibility of a real-world event. An event is viewed as having prerequisites that enable its occurrence and constraints that may impede its occurrence, and the possibility of the event is computed as a function of the probabilities that the prerequisites hold and the constraints do not. This version of possibility might appropriately be applied to problems of planning. When there are multiple plans available for achieving a goal, this theory can be used to determine which plan is most possible, i.e., easiest or most feasible to complete. It is speculated that this model of reasoning correctly captures normal human reasoning about plans. The theory is elaborated and an illustrative example for vehicle route planning is provided. There is also a suggestion of potential future applications.', 'abstract_zh': '本文提出了一种新的可能性概念，作为替代如今标准概念的选项，该标准概念最初由L.A. Zadeh在1978年引入。这一新版本受到原概念的启发，但在形式上与之没有其他共同之处，二者均采用Łukasiewicz多值逻辑运算的解释。此外，本文并未寻求提供一个一般性的可能性概念，而是专注于具体事件的可能性。事件被视为在其发生需要满足先决条件并且可能存在阻碍条件的情境下发生的，事件的可能性是先决条件成立和阻碍条件不成立的概率函数。这一可能性概念适合作为规划问题的应用。当有多种计划可用于实现目标时，可以使用该理论来确定哪个计划最有可能，即最容易或最可行完成。推测这种推理模型正确捕捉了正常的关于计划的人类推理。本文对这一理论进行了详细阐述，并提供了车辆路线规划的示例说明。此外，还建议了潜在的未来应用。', 'title_zh': '一种关于现实事件的可能性概念'}
{'arxiv_id': 'arXiv:2510.02557', 'title': 'Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge', 'authors': 'Charlie Masters, Advaith Vellanki, Jiangbo Shangguan, Bart Kultys, Jonathan Gilmore, Alastair Moore, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2510.02557', 'abstract': 'While agentic AI has advanced in automating individual tasks, managing complex multi-agent workflows remains a challenging problem. This paper presents a research vision for autonomous agentic systems that orchestrate collaboration within dynamic human-AI teams. We propose the Autonomous Manager Agent as a core challenge: an agent that decomposes complex goals into task graphs, allocates tasks to human and AI workers, monitors progress, adapts to changing conditions, and maintains transparent stakeholder communication. We formalize workflow management as a Partially Observable Stochastic Game and identify four foundational challenges: (1) compositional reasoning for hierarchical decomposition, (2) multi-objective optimization under shifting preferences, (3) coordination and planning in ad hoc teams, and (4) governance and compliance by design. To advance this agenda, we release MA-Gym, an open-source simulation and evaluation framework for multi-agent workflow orchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we find they struggle to jointly optimize for goal completion, constraint adherence, and workflow runtime - underscoring workflow management as a difficult open problem. We conclude with organizational and ethical implications of autonomous management systems.', 'abstract_zh': '尽管代理型人工智能在自动化个体任务方面取得了进步，但管理复杂多智能体工作流仍是一项具有挑战性的问题。本文提出了自主代理系统的研究愿景，旨在 orchestrate 动态人机团队中的协作。我们提出自主管理代理作为核心挑战：该代理将复杂目标分解为任务图，分配任务给人类和智能体工作者，监测进度，适应变化条件，并保持透明的利益相关者沟通。我们将工作流管理形式化为部分可观测随机游戏，并确认四个基础挑战：（1）层次分解的组合性推理，（2）目标偏好的动态优化，（3）临时团队中的协调与规划，（4）设计中的治理与合规。为推进这一议程，我们发布了 MA-Gym，这是一个开源的多智能体工作流编排模拟与评估框架。通过对 20 个工作流的 GPT-5 基础管理代理进行评估，我们发现它们在同时优化目标完成、约束遵守和工作流运行时间方面存在困难，突显了工作流管理作为一项艰巨的开放问题。最后，我们讨论了自主管理系统在组织和伦理方面的 implications。', 'title_zh': 'orchestrating 人机团队：管理者代理作为统一的研究挑战'}
{'arxiv_id': 'arXiv:2510.03230', 'title': 'Improving GUI Grounding with Explicit Position-to-Coordinate Mapping', 'authors': 'Suyuchen Wang, Tianyu Zhang, Ahmed Masry, Christopher Pal, Spandana Gella, Bang Liu, Perouz Taslakian', 'link': 'https://arxiv.org/abs/2510.03230', 'abstract': 'GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current VLMs. The core bottleneck is reliable patch-to-pixel mapping, which breaks when extrapolating to high-resolution displays unseen during training. Current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and failures proliferate on new resolutions. We address this with two complementary innovations. First, RULER tokens serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and adjust rather than generate coordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. Experiments on ScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in grounding accuracy, with the largest improvements on high-resolution interfaces. By providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable GUI automation across diverse resolutions and platforms.', 'abstract_zh': 'GUI定位：将自然语言指令映射到像素坐标的关键任务对于自主代理至关重要，但当前的多模态模型仍然难以实现。核心瓶颈是可靠的 patch-to-pixel 映射，在处理训练期间未见过的高分辨率显示时会失效。当前的方法直接从视觉特征生成坐标，迫使模型以隐式的形式推断复杂的坐标映射；结果导致准确度下降并在新分辨率上产生更多失败。我们通过两种互补的创新来解决这一问题。首先，RULER.Token 作为显式的坐标标记，使模型能够参考类似于地图上的网格线的位置，并调整而不是从零开始生成坐标。其次，交错的 MRoPE（I-MRoPE）通过确保宽度和高度维度的同等表示，解决了标准位置方案的不对称性，从而改善了空间编码。在 ScreenSpot、ScreenSpot-V2 和 ScreenSpot-Pro 上进行的实验显示出一致的定位准确度提升，高分辨率界面的提升最为显著。通过提供显式的空间指导而不是依赖隐式学习，我们的方法能够在多种分辨率和平台上实现更可靠的 GUI 自动化。', 'title_zh': '改进GUI接地性能：通过显式位置到坐标映射'}
{'arxiv_id': 'arXiv:2510.03224', 'title': 'Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles', 'authors': 'Dong Lao, Yuxiang Zhang, Haniyeh Ehsani Oskouie, Yangchao Wu, Alex Wong, Stefano Soatto', 'link': 'https://arxiv.org/abs/2510.03224', 'abstract': 'We propose a test-time defense mechanism against adversarial attacks: imperceptible image perturbations that significantly alter the predictions of a model. Unlike existing methods that rely on feature filtering or smoothing, which can lead to information loss, we propose to "combat noise with noise" by leveraging stochastic resonance to enhance robustness while minimizing information loss. Our approach introduces small translational perturbations to the input image, aligns the transformed feature embeddings, and aggregates them before mapping back to the original reference image. This can be expressed in a closed-form formula, which can be deployed on diverse existing network architectures without introducing additional network modules or fine-tuning for specific attack types. The resulting method is entirely training-free, architecture-agnostic, and attack-agnostic. Empirical results show state-of-the-art robustness on image classification and, for the first time, establish a generic test-time defense for dense prediction tasks, including stereo matching and optical flow, highlighting the method\'s versatility and practicality. Specifically, relative to clean (unperturbed) performance, our method recovers up to 68.1% of the accuracy loss on image classification, 71.9% on stereo matching, and 29.2% on optical flow under various types of adversarial attacks.', 'abstract_zh': '我们提出了一种对抗攻击的测试时防御机制：不可感知的图像扰动，显著改变模型的预测结果。该机制通过利用随机共振来增强鲁棒性同时最小化信息损失，不同于依赖特征过滤或平滑的现有方法，可能会导致信息丢失。我们的方法在输入图像中引入小型平移扰动，对变换后的特征嵌入进行对齐，并在映射回原始参考图像之前进行聚合。该方法可以通过闭式公式表达，并能在无需引入额外网络模块或专门针对特定攻击类型进行微调的情况下部署在多种现有的网络架构上。该方法完全无监督训练、架构无关，并能应对多种攻击。实验证明，该方法在图像分类任务中达到了最先进的鲁棒性，并且首次为密集预测任务（包括立体匹配和光流）建立了通用的测试时防御机制，展示了该方法的 versatility 和实用性。具体而言，与干净（未扰动）性能相比，该方法在不同类型对抗攻击下分别恢复了图像分类68.1%、立体匹配71.9%、光流29.2%的准确率损失。', 'title_zh': '基于潜在ensemble的随机共振测试时防御对抗攻击'}
{'arxiv_id': 'arXiv:2510.03161', 'title': 'UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization', 'authors': 'Qing Huang, Zhipei Xu, Xuanyu Zhang, Jian Zhang', 'link': 'https://arxiv.org/abs/2510.03161', 'abstract': 'With the rapid advancements in image generation, synthetic images have become increasingly realistic, posing significant societal risks, such as misinformation and fraud. Forgery Image Detection and Localization (FIDL) thus emerges as essential for maintaining information integrity and societal security. Despite impressive performances by existing domain-specific detection methods, their practical applicability remains limited, primarily due to their narrow specialization, poor cross-domain generalization, and the absence of an integrated adaptive framework. To address these issues, we propose UniShield, the novel multi-agent-based unified system capable of detecting and localizing image forgeries across diverse domains, including image manipulation, document manipulation, DeepFake, and AI-generated images. UniShield innovatively integrates a perception agent with a detection agent. The perception agent intelligently analyzes image features to dynamically select suitable detection models, while the detection agent consolidates various expert detectors into a unified framework and generates interpretable reports. Extensive experiments show that UniShield achieves state-of-the-art results, surpassing both existing unified approaches and domain-specific detectors, highlighting its superior practicality, adaptiveness, and scalability.', 'abstract_zh': '基于多代理的统一伪造图像检测与定位系统（UniShield）', 'title_zh': 'UniShield：一种适应性的多代理框架，用于统一的伪造图像检测与定位'}
{'arxiv_id': 'arXiv:2510.03160', 'title': 'SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus', 'authors': 'Ming Zhao, Wenhui Dong, Yang Zhang, Xiang Zheng, Zhonghao Zhang, Zian Zhou, Yunzhi Guan, Liukun Xu, Wei Peng, Zhaoyang Gong, Zhicheng Zhang, Dachuan Li, Xiaosheng Ma, Yuli Ma, Jianing Ni, Changjiang Jiang, Lixia Tian, Qixin Chen, Kaishun Xia, Pingping Liu, Tongshun Zhang, Zhiqiang Liu, Zhongan Bi, Chenyang Si, Tiansheng Sun, Caifeng Shan', 'link': 'https://arxiv.org/abs/2510.03160', 'abstract': "Spine disorders affect 619 million people globally and are a leading cause of disability, yet AI-assisted diagnosis remains limited by the lack of level-aware, multimodal datasets. Clinical decision-making for spine disorders requires sophisticated reasoning across X-ray, CT, and MRI at specific vertebral levels. However, progress has been constrained by the absence of traceable, clinically-grounded instruction data and standardized, spine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem co-designed with practicing spine surgeons. It features SpineMed-450k, the first large-scale dataset explicitly designed for vertebral-level reasoning across imaging modalities with over 450,000 instruction instances, and SpineBench, a clinically-grounded evaluation framework. SpineMed-450k is curated from diverse sources, including textbooks, guidelines, open datasets, and ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline with a two-stage LLM generation method (draft and revision) to ensure high-quality, traceable data for question-answering, multi-turn consultations, and report generation. SpineBench evaluates models on clinically salient axes, including level identification, pathology assessment, and surgical planning. Our comprehensive evaluation of several recently advanced large vision-language models (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained, level-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k demonstrates consistent and significant improvements across all tasks. Clinician assessments confirm the diagnostic clarity and practical utility of our model's outputs.", 'abstract_zh': '脊柱疾病影响全球6.19亿人，并且是导致残疾的主要原因之一，但AI辅助诊断仍然受限于缺乏层次意识的多模态数据集。脊柱疾病的临床决策需要在特定椎体水平上对X射线、CT和MRI进行复杂的推理。然而，进展受限于缺乏可追溯的、基于临床的指令数据和标准化的脊柱特定基准。为解决这一问题，我们介绍了与实践经验丰富的脊柱外科医生共同设计的SpineMed生态系统。它包含SpineMed-450k，这是首个明确设计用于跨影像模态的椎体水平推理的大规模数据集，包含超过450,000个指令实例，以及SpineBench，一个基于临床的评估框架。SpineMed-450k从多种来源精心整理而来，包括教科书、指南、开放数据集和约1000个匿名医院病例，采用临床医师在环管道和两阶段LLM生成方法（草案和修订）来确保高质量、可追溯的数据，用于问题回答、多轮咨询和报告生成。SpineBench在临床显著轴线上评估模型，包括椎体水平识别、病理评估和手术规划。我们在SpineBench上对几种领先的大规模视觉-语言模型的全面评估表明，这些模型在细微层次和特定椎体水平推理方面存在系统性弱点。相比之下，我们基于SpineMed-450k微调的模型在所有任务中表现出一致且显著的改进。临床医师评估证实了我们模型输出的诊断清晰度和实际应用价值。', 'title_zh': 'SpineBench: 一个基于SpineMed-450k语料库、具有临床相关性和层级意识的基准测试'}
{'arxiv_id': 'arXiv:2510.03155', 'title': 'Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches', 'authors': 'Stevens Johnson, Varun Puram, Johnson Thomas, Acsah Konuparamban, Ashwin Kannan', 'link': 'https://arxiv.org/abs/2510.03155', 'abstract': 'Accurate modeling of neuronal action potential (AP) onset timing is crucial for understanding neural coding of danger signals. Traditional leaky integrate-and-fire (LIF) models, while widely used, exhibit high relative error in predicting AP onset latency, especially under strong or rapidly changing stimuli. Inspired by recent experimental findings and quantum theory, we present a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats AP onset as a probabilistic event, represented by a Gaussian wave packet in time. This approach captures the biological variability and uncertainty inherent in neuronal firing. We systematically compare the relative error of AP onset predictions between the classical LIF and QI-LIF models using synthetic data from hippocampal and sensory neurons subjected to varying stimulus amplitudes. Our results demonstrate that the QI-LIF model significantly reduces prediction error, particularly for high-intensity stimuli, aligning closely with observed biological responses. This work highlights the potential of quantum-inspired computational frameworks in advancing the accuracy of neural modeling and has implications for quantum engineering approaches to brain-inspired computing.', 'abstract_zh': '准确建模神经动作电位(AP) onset 时间对于理解神经编码危险信号至关重要。传统漏氏积分-放电(LIF)模型虽然广泛使用，但在预测AP onset 迟滞时表现出较高的相对误差，尤其是在强或快速变化的刺激下。受到最近实验发现和量子理论的启发，我们提出了一种量子启发式漏氏积分-放电(QI-LIF)模型，将AP onset 视作一个概率事件，并用时间中的高斯波包表示。该方法捕捉了神经元放电的生物变异性与不确定性。我们使用来自海马区和感觉神经元的合成数据，这些神经元在不同刺激幅度下受到刺激，系统地比较了经典LIF模型和QI-LIF模型在预测AP onset 上的相对误差。结果显示，QI-LIF模型显著降低了预测误差，特别是在高强度刺激下，与观察到的生物响应接近。这项工作突出了量子启发式计算框架在提高神经建模准确性方面的潜力，并对基于量子工程的仿脑计算具有重要意义。', 'title_zh': '基于刺激电压的Action Potential起始时间预测：经典方法 vs. 受量子启发的方法'}
{'arxiv_id': 'arXiv:2510.03129', 'title': 'Signature-Informed Transformer for Asset Allocation', 'authors': 'Yoontae Hwang, Stefan Zohren', 'link': 'https://arxiv.org/abs/2510.03129', 'abstract': "Robust asset allocation is a key challenge in quantitative finance, where deep-learning forecasters often fail due to objective mismatch and error amplification. We introduce the Signature-Informed Transformer (SIT), a novel framework that learns end-to-end allocation policies by directly optimizing a risk-aware financial objective. SIT's core innovations include path signatures for a rich geometric representation of asset dynamics and a signature-augmented attention mechanism embedding financial inductive biases, like lead-lag effects, into the model. Evaluated on daily S\\&P 100 equity data, SIT decisively outperforms traditional and deep-learning baselines, especially when compared to predict-then-optimize models. These results indicate that portfolio-aware objectives and geometry-aware inductive biases are essential for risk-aware capital allocation in machine-learning systems. The code is available at: this https URL", 'abstract_zh': '基于签名的信息 transformer 在量化金融中的稳健资产配置：一种直接优化风险意识金融目标的端到端分配策略', 'title_zh': '基于签名的Transformer资产配置'}
{'arxiv_id': 'arXiv:2510.03095', 'title': 'Distilled Protein Backbone Generation', 'authors': 'Liyang Xie, Haoran Zhang, Zhendong Wang, Wesley Tansey, Mingyuan Zhou', 'link': 'https://arxiv.org/abs/2510.03095', 'abstract': 'Diffusion- and flow-based generative models have recently demonstrated strong performance in protein backbone generation tasks, offering unprecedented capabilities for de novo protein design. However, while achieving notable performance in generation quality, these models are limited by their generating speed, often requiring hundreds of iterative steps in the reverse-diffusion process. This computational bottleneck limits their practical utility in large-scale protein discovery, where thousands to millions of candidate structures are needed. To address this challenge, we explore the techniques of score distillation, which has shown great success in reducing the number of sampling steps in the vision domain while maintaining high generation quality. However, a straightforward adaptation of these methods results in unacceptably low designability. Through extensive study, we have identified how to appropriately adapt Score identity Distillation (SiD), a state-of-the-art score distillation strategy, to train few-step protein backbone generators which significantly reduce sampling time, while maintaining comparable performance to their pretrained teacher model. In particular, multistep generation combined with inference time noise modulation is key to the success. We demonstrate that our distilled few-step generators achieve more than a 20-fold improvement in sampling speed, while achieving similar levels of designability, diversity, and novelty as the Proteina teacher model. This reduction in inference cost enables large-scale in silico protein design, thereby bringing diffusion-based models closer to real-world protein engineering applications.', 'abstract_zh': '基于扩散和流的生成模型在蛋白质主链生成任务中 recently demonstrated 强大的性能，为从头蛋白质设计提供了前所未有的能力。然而，尽管在生成质量方面取得了显著的性能，这些模型在生成速度方面受到限制，经常需要在逆向扩散过程中进行数百次迭代步骤。这一计算瓶颈限制了它们在大规模蛋白质发现中的实用性，其中需要成千上万甚至数百万的候选结构。为了解决这一挑战，我们探索了评分蒸馏的技术，该技术在视觉领域显示出显著的成功，可以减少采样步骤的数量，同时保持高质量的生成。然而，直接适应这些方法会导致不合理的低可设计性。通过广泛的研究所发现，可以通过适当适应当前最先进的评分身份蒸馏（SiD）策略来训练多步蛋白质主链生成器，从而显著减少采样时间，同时保持与预训练教师模型相当的性能。特别是，多步生成与推理时间噪声调节是成功的关键。我们证明，我们的蒸馏多步生成器在采样速度上实现了超过20倍的提升，同时在可设计性、多样性和新颖性方面与Proteina教师模型相当。这降低了推理成本，从而实现大规模的体外蛋白质设计，使基于扩散的模型更接近实际的蛋白质工程应用。', 'title_zh': '提取蛋白主链生成'}
{'arxiv_id': 'arXiv:2510.03069', 'title': 'A Study of Neural Polar Decoders for Communication', 'authors': 'Rom Hirsch, Ziv Aharoni, Henry D. Pfister, Haim H. Permuter', 'link': 'https://arxiv.org/abs/2510.03069', 'abstract': 'In this paper, we adapt and analyze Neural Polar Decoders (NPDs) for end-to-end communication systems. While prior work demonstrated the effectiveness of NPDs on synthetic channels, this study extends the NPD to real-world communication systems. The NPD was adapted to complete OFDM and single-carrier communication systems. To satisfy practical system requirements, the NPD is extended to support any code length via rate matching, higher-order modulations, and robustness across diverse channel conditions. The NPD operates directly on channels with memory, exploiting their structure to achieve higher data rates without requiring pilots and a cyclic prefix. Although NPD entails higher computational complexity than the standard 5G polar decoder, its neural network architecture enables an efficient representation of channel statistics, resulting in manageable complexity suitable for practical systems. Experimental results over 5G channels demonstrate that the NPD consistently outperforms the 5G polar decoder in terms of BER, BLER, and throughput. These improvements are particularly significant for low-rate and short-block configurations, which are prevalent in 5G control channels. Furthermore, NPDs applied to single-carrier systems offer performance comparable to OFDM with lower PAPR, enabling effective single-carrier transmission over 5G channels. These results position the NPD as a high-performance, pilotless, and robust decoding solution.', 'abstract_zh': '基于神经极化译码器的端到端通信系统研究', 'title_zh': '神经极化解码器的研究'}
{'arxiv_id': 'arXiv:2510.03060', 'title': 'Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles', 'authors': 'Rongchen Guo, Vincent Francoeur, Isar Nejadgholi, Sylvain Gagnon, Miodrag Bolic', 'link': 'https://arxiv.org/abs/2510.03060', 'abstract': "Speech Emotion Recognition (SER) is essential for improving human-computer interaction, yet its accuracy remains constrained by the complexity of emotional nuances in speech. In this study, we distinguish between descriptive semantics, which represents the contextual content of speech, and expressive semantics, which reflects the speaker's emotional state. After watching emotionally charged movie segments, we recorded audio clips of participants describing their experiences, along with the intended emotion tags for each clip, participants' self-rated emotional responses, and their valence/arousal scores. Through experiments, we show that descriptive semantics align with intended emotions, while expressive semantics correlate with evoked emotions. Our findings inform SER applications in human-AI interaction and pave the way for more context-aware AI systems.", 'abstract_zh': '语音情感识别（SER）对于改善人机交互至关重要，但其准确性受限于语音中情感细腻程度的复杂性。在本研究中，我们将描述性语义定义为表示语音背景内容的含义，并将表现性语义定义为反映说话者情感状态的含义。参与者观看了情感化的电影片段后，我们记录了他们描述体验时的语音片段，每个片段的预期情感标签，参与者的自评情感反应，以及他们的愉悦度/唤醒度评分。通过实验我们表明，描述性语义与预期情感一致，而表现性语义与引发的情感相关。我们的发现为人类-AI交互中的SER应用提供了指导，并为更具情境意识的AI系统的发展铺平了道路。', 'title_zh': '语音情感识别中的语义分化：描述性与表达性语音角色的启示'}
{'arxiv_id': 'arXiv:2510.03051', 'title': 'ZeroShotOpt: Towards Zero-Shot Pretrained Models for Efficient Black-Box Optimization', 'authors': 'Jamison Meindl, Yunsheng Tian, Tony Cui, Veronika Thost, Zhang-Wei Hong, Johannes Dürholt, Jie Chen, Wojciech Matusik, Mina Konaković Luković', 'link': 'https://arxiv.org/abs/2510.03051', 'abstract': 'Global optimization of expensive, derivative-free black-box functions requires extreme sample efficiency. While Bayesian optimization (BO) is the current state-of-the-art, its performance hinges on surrogate and acquisition function hyper-parameters that are often hand-tuned and fail to generalize across problem landscapes. We present ZeroShotOpt, a general-purpose, pretrained model for continuous black-box optimization tasks ranging from 2D to 20D. Our approach leverages offline reinforcement learning on large-scale optimization trajectories collected from 12 BO variants. To scale pretraining, we generate millions of synthetic Gaussian process-based functions with diverse landscapes, enabling the model to learn transferable optimization policies. As a result, ZeroShotOpt achieves robust zero-shot generalization on a wide array of unseen benchmarks, matching or surpassing the sample efficiency of leading global optimizers, including BO, while also offering a reusable foundation for future extensions and improvements. Our open-source code, dataset, and model are available at: this https URL', 'abstract_zh': '全球昂贵且无导数黑盒函数的优化需要极高的样本效率。尽管贝叶斯优化（BO）是当前最先进的方法，但其性能依赖于往往需要手动调优且难以跨问题景观泛化的先验和获取函数超参数。我们提出ZeroShotOpt，这是一种用于从2D到20D连续黑盒优化任务的一般用途、预训练模型。该方法通过在12种BO变体的大规模优化轨迹上进行离线强化学习来提升预训练效率。为扩展预训练，我们生成了数百万个基于高斯过程的合成函数，具有多样化的景观，使模型能够学习通用的优化策略。因此，ZeroShotOpt在一系列未见过的基准测试上实现了稳健的零样本泛化，其样本效率与包括BO在内的领先全局优化器相当或更优，同时为未来扩展和改进提供了一个可重用的基础。我们的开源代码、数据集和模型可在以下链接获取：this https URL。', 'title_zh': '零-shot预训练：高效黑盒优化的零-shot预训练模型研究'}
{'arxiv_id': 'arXiv:2510.03038', 'title': 'CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration', 'authors': 'Tianqi Liu, Kairui Fu, Shengyu Zhang, Wenyan Fan, Zhaocheng Du, Jieming Zhu, Fan Wu, Fei Wu', 'link': 'https://arxiv.org/abs/2510.03038', 'abstract': 'With the advancement of mobile device capabilities, deploying reranking models directly on devices has become feasible, enabling real-time contextual recommendations. When migrating models from cloud to devices, resource heterogeneity inevitably necessitates model compression. Recent quantization methods show promise for efficient deployment, yet they overlook device-specific user interests, resulting in compromised recommendation accuracy. While on-device finetuning captures personalized user preference, it imposes additional computational burden through local retraining. To address these challenges, we propose a framework for \\underline{\\textbf{C}}ustomizing \\underline{\\textbf{H}}ybrid-precision \\underline{\\textbf{O}}n-device model for sequential \\underline{\\textbf{R}}ecommendation with \\underline{\\textbf{D}}evice-cloud collaboration (\\textbf{CHORD}), leveraging channel-wise mixed-precision quantization to simultaneously achieve personalization and resource-adaptive deployment. CHORD distributes randomly initialized models across heterogeneous devices and identifies user-specific critical parameters through auxiliary hypernetwork modules on the cloud. Our parameter sensitivity analysis operates across multiple granularities (layer, filter, and element levels), enabling precise mapping from user profiles to quantization strategy. Through on-device mixed-precision quantization, CHORD delivers dynamic model adaptation and accelerated inference without backpropagation, eliminating costly retraining cycles. We minimize communication overhead by encoding quantization strategies using only 2 bits per channel instead of 32-bit weights. Experiments on three real-world datasets with two popular backbones (SASRec and Caser) demonstrate the accuracy, efficiency, and adaptivity of CHORD.', 'abstract_zh': '基于设备-云协作的自适应混合精度离线推荐框架（CHORD）', 'title_zh': 'CHORD: 基于设备-云协作的混合精度定制序列推荐模型'}
{'arxiv_id': 'arXiv:2510.03016', 'title': 'Learning Robust Diffusion Models from Imprecise Supervision', 'authors': 'Dong-Dong Wu, Jiacheng Cui, Wei Wang, Zhiqiang She, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2510.03016', 'abstract': 'Conditional diffusion models have achieved remarkable success in various generative tasks recently, but their training typically relies on large-scale datasets that inevitably contain imprecise information in conditional inputs. Such supervision, often stemming from noisy, ambiguous, or incomplete labels, will cause condition mismatch and degrade generation quality. To address this challenge, we propose DMIS, a unified framework for training robust Diffusion Models from Imprecise Supervision, which is the first systematic study within diffusion models. Our framework is derived from likelihood maximization and decomposes the objective into generative and classification components: the generative component models imprecise-label distributions, while the classification component leverages a diffusion classifier to infer class-posterior probabilities, with its efficiency further improved by an optimized timestep sampling strategy. Extensive experiments on diverse forms of imprecise supervision, covering tasks of image generation, weakly supervised learning, and noisy dataset condensation demonstrate that DMIS consistently produces high-quality and class-discriminative samples.', 'abstract_zh': '基于不精确监督训练稳健扩散模型的统一框架', 'title_zh': '从模糊监督中学习 robust 分布模型'}
{'arxiv_id': 'arXiv:2510.03004', 'title': 'BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia', 'authors': 'Tianzheng Hu, Qiang Li, Shu Liu, Vince D. Calhoun, Guido van Wingen, Shujian Yu', 'link': 'https://arxiv.org/abs/2510.03004', 'abstract': "The development of diagnostic models is gaining traction in the field of psychiatric disorders. Recently, machine learning classifiers based on resting-state functional magnetic resonance imaging (rs-fMRI) have been developed to identify brain biomarkers that differentiate psychiatric disorders from healthy controls. However, conventional machine learning-based diagnostic models often depend on extensive feature engineering, which introduces bias through manual intervention. While deep learning models are expected to operate without manual involvement, their lack of interpretability poses significant challenges in obtaining explainable and reliable brain biomarkers to support diagnostic decisions, ultimately limiting their clinical applicability. In this study, we introduce an end-to-end innovative graph neural network framework named BrainIB++, which applies the information bottleneck (IB) principle to identify the most informative data-driven brain regions as subgraphs during model training for interpretation. We evaluate the performance of our model against nine established brain network classification methods across three multi-cohort schizophrenia datasets. It consistently demonstrates superior diagnostic accuracy and exhibits generalizability to unseen data. Furthermore, the subgraphs identified by our model also correspond with established clinical biomarkers in schizophrenia, particularly emphasizing abnormalities in the visual, sensorimotor, and higher cognition brain functional network. This alignment enhances the model's interpretability and underscores its relevance for real-world diagnostic applications.", 'abstract_zh': '基于静息态功能磁共振成像的产前诊断模型的发展：BrainIB++图神经网络框架在精神疾病诊断中的应用', 'title_zh': 'BrainIB++: 结合图神经网络和信息瓶颈方法识别精神分裂症的功能脑生物标志物'}
{'arxiv_id': 'arXiv:2510.03003', 'title': 'From high-frequency sensors to noon reports: Using transfer learning for shaft power prediction in maritime', 'authors': 'Akriti Sharma, Dogan Altan, Dusica Marijan, Arnbjørn Maressa', 'link': 'https://arxiv.org/abs/2510.03003', 'abstract': 'With the growth of global maritime transportation, energy optimization has become crucial for reducing costs and ensuring operational efficiency. Shaft power is the mechanical power transmitted from the engine to the shaft and directly impacts fuel consumption, making its accurate prediction a paramount step in optimizing vessel performance. Power consumption is highly correlated with ship parameters such as speed and shaft rotation per minute, as well as weather and sea conditions. Frequent access to this operational data can improve prediction accuracy. However, obtaining high-quality sensor data is often infeasible and costly, making alternative sources such as noon reports a viable option. In this paper, we propose a transfer learning-based approach for predicting vessels shaft power, where a model is initially trained on high-frequency data from a vessel and then fine-tuned with low-frequency daily noon reports from other vessels. We tested our approach on sister vessels (identical dimensions and configurations), a similar vessel (slightly larger with a different engine), and a different vessel (distinct dimensions and configurations). The experiments showed that the mean absolute percentage error decreased by 10.6 percent for sister vessels, 3.6 percent for a similar vessel, and 5.3 percent for a different vessel, compared to the model trained solely on noon report data.', 'abstract_zh': '随着全球海洋运输的发展，能源优化已成为降低运营成本和确保操作效率的关键。轴功率是发动机传递给轴的机械功率，直接影响燃料消耗，因此其准确预测是优化船舶性能的首要步骤。功率消耗与船速、轴每分钟转数以及天气和海况等因素高度相关。频繁获取这类操作数据可以提高预测准确性。然而，获得高质量的传感器数据往往既不可能又昂贵，因此可以考虑使用中午报告作为替代数据源。本文提出了一种基于迁移学习的方法，先在船舶高频数据上训练模型，然后使用其他船舶的低频每日中午报告进行微调。我们分别在姊妹船（相同尺寸和配置）、类似船舶（稍大且发动机不同）和不同船舶（不同尺寸和配置）上测试了该方法。实验结果显示，与仅使用中午报告数据训练的模型相比，姊妹船的平均绝对百分比误差降低了10.6%，类似船舶降低了3.6%，不同船舶降低了5.3%。', 'title_zh': '从高频率传感器数据到午间报告：基于迁移学习的船舶轴功率预测'}
{'arxiv_id': 'arXiv:2510.02978', 'title': "AI Generated Child Sexual Abuse Material - What's the Harm?", 'authors': 'Caoilte Ó Ciardha, John Buckley, Rebecca S. Portnoff', 'link': 'https://arxiv.org/abs/2510.02978', 'abstract': 'The development of generative artificial intelligence (AI) tools capable of producing wholly or partially synthetic child sexual abuse material (AI CSAM) presents profound challenges for child protection, law enforcement, and societal responses to child exploitation. While some argue that the harmfulness of AI CSAM differs fundamentally from other CSAM due to a perceived absence of direct victimization, this perspective fails to account for the range of risks associated with its production and consumption. AI has been implicated in the creation of synthetic CSAM of children who have not previously been abused, the revictimization of known survivors of abuse, the facilitation of grooming, coercion and sexual extortion, and the normalization of child sexual exploitation. Additionally, AI CSAM may serve as a new or enhanced pathway into offending by lowering barriers to engagement, desensitizing users to progressively extreme content, and undermining protective factors for individuals with a sexual interest in children. This paper provides a primer on some key technologies, critically examines the harms associated with AI CSAM, and cautions against claims that it may function as a harm reduction tool, emphasizing how some appeals to harmlessness obscure its real risks and may contribute to inertia in ecosystem responses.', 'abstract_zh': '生成式人工智能工具生成合成儿童性剥削材料的发展给儿童保护、执法和社会应对儿童 exploitation 带来了深刻挑战。', 'title_zh': '由AI生成的儿童性虐待材料：有何危害？'}
{'arxiv_id': 'arXiv:2510.02973', 'title': 'Corrosion Risk Estimation for Heritage Preservation: An Internet of Things and Machine Learning Approach Using Temperature and Humidity', 'authors': 'Reginald Juan M. Mercado, Muhammad Kabeer, Haider Al-Obaidy, Rosdiadee Nordin', 'link': 'https://arxiv.org/abs/2510.02973', 'abstract': 'Proactive preservation of steel structures at culturally significant heritage sites like the San Sebastian Basilica in the Philippines requires accurate corrosion forecasting. This study developed an Internet of Things hardware system connected with LoRa wireless communications to monitor heritage buildings with steel structures. From a three year dataset generated by the IoT system, we built a machine learning framework for predicting atmospheric corrosion rates using only temperature and relative humidity data. Deployed via a Streamlit dashboard with ngrok tunneling for public access, the framework provides real-time corrosion monitoring and actionable preservation recommendations. This minimal-data approach is scalable and cost effective for heritage sites with limited monitoring resources, showing that advanced regression can extract accurate corrosion predictions from basic meteorological data enabling proactive preservation of culturally significant structures worldwide without requiring extensive sensor networks', 'abstract_zh': '菲律宾圣塞巴斯蒂安大教堂等历史文化遗址中钢铁结构的主动保护需要准确的腐蚀预测。本研究开发了一个物联网硬件系统，结合LoRa无线通讯监测具有钢铁结构的文化遗产建筑。基于物联网系统生成的三年数据集，我们构建了一个仅使用温度和相对湿度数据的机器学习框架来预测大气腐蚀速率。该框架通过Streamlit仪表板和ngrok隧道供公众访问，提供实时腐蚀监测和可行的保护建议。这种数据最小化方法对于监测资源有限的历史文化遗址具有可扩展性和成本效益，表明先进的回归分析可以从基本的气象数据中提取出准确的腐蚀预测，从而在全球范围内对具有文化意义的建筑结构进行主动保护，而无需庞大的传感器网络。', 'title_zh': '遗产保护中的腐蚀风险估计：基于温度和湿度的物联网与机器学习方法'}
{'arxiv_id': 'arXiv:2510.02945', 'title': 'Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning', 'authors': 'Juan Sebastian Rojas, Chi-Guhn Lee', 'link': 'https://arxiv.org/abs/2510.02945', 'abstract': 'Continual reinforcement learning (continual RL) seeks to formalize the notions of lifelong learning and endless adaptation in RL. In particular, the aim of continual RL is to develop RL agents that can maintain a careful balance between retaining useful information and adapting to new situations. To date, continual RL has been explored almost exclusively through the lens of risk-neutral decision-making, in which the agent aims to optimize the expected (or mean) long-run performance. In this work, we present the first formal theoretical treatment of continual RL through the lens of risk-aware decision-making, in which the agent aims to optimize a reward-based measure of long-run performance beyond the mean. In particular, we show that the classical theory of risk measures, widely used as a theoretical foundation in non-continual risk-aware RL, is, in its current form, incompatible with the continual setting. Then, building on this insight, we extend risk measure theory into the continual setting by introducing a new class of ergodic risk measures that are compatible with continual learning. Finally, we provide a case study of risk-aware continual learning, along with empirical results, which show the intuitive appeal and theoretical soundness of ergodic risk measures.', 'abstract_zh': '持续强化学习（持续RL）旨在形式化终身学习和无尽适应的概念。特别是在持续RL中，目标是开发能够在保留有用信息和适应新情况之间保持谨慎平衡的RL代理。到目前为止，持续RL几乎完全通过风险中性决策制定的视角进行探索，其中代理的目标是最大化长期性能的期望值（或平均值）。在本工作中，我们通过风险感知决策制定的视角首次为持续RL提供了形式化的理论处理，其中代理旨在优化超出平均值的基于奖励的长期性能度量。特别是在此工作中，我们表明了广泛用于非持续风险感知RL理论基础的经典风险测度理论，在当前形式下无法适用于持续学习的环境。基于此认识，我们通过引入与持续学习兼容的新一类遍历风险测度，将风险测度理论扩展到了持续学习的环境。最后，我们提供了风险感知持续学习的案例研究，并给出了实验证据，证明了遍历风险测度的直观吸引力和理论严谨性。', 'title_zh': '遍历风险测度：迈向持续强化学习的风险意识基础'}
{'arxiv_id': 'arXiv:2510.02915', 'title': 'WavInWav: Time-domain Speech Hiding via Invertible Neural Network', 'authors': 'Wei Fan, Kejiang Chen, Xiangkun Wang, Weiming Zhang, Nenghai Yu', 'link': 'https://arxiv.org/abs/2510.02915', 'abstract': 'Data hiding is essential for secure communication across digital media, and recent advances in Deep Neural Networks (DNNs) provide enhanced methods for embedding secret information effectively. However, previous audio hiding methods often result in unsatisfactory quality when recovering secret audio, due to their inherent limitations in the modeling of time-frequency relationships. In this paper, we explore these limitations and introduce a new DNN-based approach. We use a flow-based invertible neural network to establish a direct link between stego audio, cover audio, and secret audio, enhancing the reversibility of embedding and extracting messages. To address common issues from time-frequency transformations that degrade secret audio quality during recovery, we implement a time-frequency loss on the time-domain signal. This approach not only retains the benefits of time-frequency constraints but also enhances the reversibility of message recovery, which is vital for practical applications. We also add an encryption technique to protect the hidden data from unauthorized access. Experimental results on the VCTK and LibriSpeech datasets demonstrate that our method outperforms previous approaches in terms of subjective and objective metrics and exhibits robustness to various types of noise, suggesting its utility in targeted secure communication scenarios.', 'abstract_zh': '基于深度神经网络的音频隐写 advances in deep neural networks (dnn) for secure communication through enhanced audio embedding', 'title_zh': 'WavInWav：通过可逆神经网络的时域语音隐藏'}
{'arxiv_id': 'arXiv:2510.02914', 'title': 'FeDABoost: Fairness Aware Federated Learning with Adaptive Boosting', 'authors': 'Tharuka Kasthuri Arachchige, Veselka Boeva, Shahrooz Abghari', 'link': 'https://arxiv.org/abs/2510.02914', 'abstract': 'This work focuses on improving the performance and fairness of Federated Learning (FL) in non IID settings by enhancing model aggregation and boosting the training of underperforming clients. We propose FeDABoost, a novel FL framework that integrates a dynamic boosting mechanism and an adaptive gradient aggregation strategy. Inspired by the weighting mechanism of the Multiclass AdaBoost (SAMME) algorithm, our aggregation method assigns higher weights to clients with lower local error rates, thereby promoting more reliable contributions to the global model. In parallel, FeDABoost dynamically boosts underperforming clients by adjusting the focal loss focusing parameter, emphasizing hard to classify examples during local training. We have evaluated FeDABoost on three benchmark datasets MNIST, FEMNIST, and CIFAR10, and compared its performance with those of FedAvg and Ditto. The results show that FeDABoost achieves improved fairness and competitive performance.', 'abstract_zh': '本研究旨在通过增强模型聚合和提升表现不佳的客户端训练，在非IID设置中改善联邦学习（FL）的性能和公平性。我们提出了一种新的FL框架FeDABoost，该框架结合了动态增强机制和自适应梯度聚合策略。受Multiclass AdaBoost（SAMME）算法加权机制的启发，我们的聚合方法将较高权重赋予本地错误率较低的客户端，从而促进其对全局模型的更可靠贡献。同时，FeDABoost通过调整局部训练中的焦点损失聚焦参数，动态提升表现不佳的客户端，强调难以分类的样本。我们在三个基准数据集MNIST、FEMNIST和CIFAR10上评估了FeDABoost，并将其性能与FedAvg和Ditto进行了比较。结果表明，FeDABoost在公平性和性能方面得到了改善。', 'title_zh': '基于公平性意识的自适应提升联邦学习'}
{'arxiv_id': 'arXiv:2510.02906', 'title': 'FinReflectKG - MultiHop: Financial QA Benchmark for Reasoning with Knowledge Graph Evidence', 'authors': 'Abhinav Arun, Reetu Raj Harsh, Bhaskarjit Sarmah, Stefano Pasquali', 'link': 'https://arxiv.org/abs/2510.02906', 'abstract': 'Multi-hop reasoning over financial disclosures is often a retrieval problem before it becomes a reasoning or generation problem: relevant facts are dispersed across sections, filings, companies, and years, and LLMs often expend excessive tokens navigating noisy context. Without precise Knowledge Graph (KG)-guided selection of relevant context, even strong reasoning models either fail to answer or consume excessive tokens, whereas KG-linked evidence enables models to focus their reasoning on composing already retrieved facts. We present FinReflectKG - MultiHop, a benchmark built on FinReflectKG, a temporally indexed financial KG that links audited triples to source chunks from S&P 100 filings (2022-2024). Mining frequent 2-3 hop subgraph patterns across sectors (via GICS taxonomy), we generate financial analyst style questions with exact supporting evidence from the KG. A two-phase pipeline first creates QA pairs via pattern-specific prompts, followed by a multi-criteria quality control evaluation to ensure QA validity. We then evaluate three controlled retrieval scenarios: (S1) precise KG-linked paths; (S2) text-only page windows centered on relevant text spans; and (S3) relevant page windows with randomizations and distractors. Across both reasoning and non-reasoning models, KG-guided precise retrieval yields substantial gains on the FinReflectKG - MultiHop QA benchmark dataset, boosting correctness scores by approximately 24 percent while reducing token utilization by approximately 84.5 percent compared to the page window setting, which reflects the traditional vector retrieval paradigm. Spanning intra-document, inter-year, and cross-company scopes, our work underscores the pivotal role of knowledge graphs in efficiently connecting evidence for multi-hop financial QA. We also release a curated subset of the benchmark (555 QA Pairs) to catalyze further research.', 'abstract_zh': '多跳推理金融披露数据往往是检索问题：相关事实分布在不同节、文件、公司和年份之间，大型语言模型在处理噪声上下文时常常消耗过多的tokens。缺乏精准的知识图谱(KG)指导选择相关上下文，即使是强大的推理模型也可能无法作答或消耗过多tokens，而KG链接的证据可使模型专注于组合已检索的事实。我们提出了FinReflectKG-MultiHop基准，基于FinReflectKG，这是一个时间索引的金融KG，将审计 triples 连接到 S&P 100 的文件（2022-2024）。通过GICS分类学跨行业挖掘频繁的2-3跳子图模式，从KG中生成符合金融分析师风格的问题，并提供精确的支持证据。该基准采用两阶段管道生成问题-答案对，并进行多标准质量控制评估以确保有效。我们随后评估了三种受控检索场景：(S1) 精确的KG链接路径；(S2) 中心化于相关文本段落的纯文本页面窗口；以及(S3) 带有随机化和干扰项的相关页面窗口。在推理模型和非推理模型中，KG指导的精确检索在FinReflectKG-MultiHop问题-答案基准数据集上取得了显著优势，正确率提高了约24%，token利用率降低了约84.5%，相较于纯文本页面窗口设置，这反映了传统的向量检索范式。我们的研究跨内部文档、跨年和跨公司范围，强调了知识图谱在高效连接多跳金融问题-答案证据方面的作用。我们还发布了一个精编的基准子集（555个问题-答案对），以促进进一步研究。', 'title_zh': 'FinReflectKG - 多跳：金融问答知识图谱推理基准'}
{'arxiv_id': 'arXiv:2510.02896', 'title': 'Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with multiplicative noise', 'authors': 'Gabriel Diaz, Lucky Li, Wenhao Zhang', 'link': 'https://arxiv.org/abs/2510.02896', 'abstract': 'Reinforcement Learning (RL) has emerged as a powerful framework for sequential decision-making in dynamic environments, particularly when system parameters are unknown. This paper investigates RL-based control for entropy-regularized Linear Quadratic control (LQC) problems with multiplicative noises over an infinite time horizon. First, we adapt the Regularized Policy Gradient (RPG) algorithm to stochastic optimal control settings, proving that despite the non-convexity of the problem, RPG converges globally under conditions of gradient domination and near-smoothness. Second, based on zero-order optimization approach, we introduce a novel model free RL algorithm: Sample-Based Regularized Policy Gradient (SB-RPG). SB-RPG operates without knowledge of system parameters yet still retains strong theoretical guarantees of global convergence. Our model leverages entropy regularization to accelerate convergence and address the exploration versus exploitation trade-off inherent in RL. Numerical simulations validate the theoretical results and demonstrate the efficacy of SB-RPG in unknown-parameters environments.', 'abstract_zh': '基于强化学习的熵正则化线性二次控制问题在无限时间 horizont 上的研究', 'title_zh': '熵正则化线性二次控制在乘性噪声情况下的策略梯度全局收敛性'}
{'arxiv_id': 'arXiv:2510.02855', 'title': 'Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation', 'authors': 'Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Kamrujjaman, Eftakhar Ahmed Arnob, Ahsan Habib Tareq', 'link': 'https://arxiv.org/abs/2510.02855', 'abstract': "Wordle presents an algorithmically rich testbed for constraint satisfaction problem (CSP) solving. While existing solvers rely on information-theoretic entropy maximization or frequency-based heuristics without formal constraint treatment, we present the first comprehensive CSP formulation of Wordle with novel constraint-aware solving strategies. We introduce CSP-Aware Entropy, computing information gain after constraint propagation rather than on raw candidate sets, and a Probabilistic CSP framework integrating Bayesian word-frequency priors with logical constraints. Through evaluation on 2,315 English words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9% success rate, a statistically significant 1.7% improvement over Forward Checking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms versus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3 percentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic CSP achieves 100% success across all noise levels (0-20%) through constraint recovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates 88% success with zero language-specific tuning, validating that core CSP principles transfer across languages despite an 11.2 percentage point gap from linguistic differences (p<0.001, Fisher's exact test). Our open-source implementation with 34 unit tests achieving 91% code coverage provides reproducible infrastructure for CSP research. The combination of formal CSP treatment, constraint-aware heuristics, probabilistic-logical integration, robustness analysis, and cross-lexicon validation establishes new performance benchmarks demonstrating that principled constraint satisfaction techniques outperform classical information-theoretic and learning-based approaches for structured puzzle-solving domains.", 'abstract_zh': "Wordle 提供了一个算法丰富的约束满足问题 (CSP) 解决测试平台。尽管现有的求解器依赖于信息论熵最大化或基于频率的启发式方法而缺乏形式化的约束处理，我们提出了第一个全面的 Wordle CSP 形式化，并引入了新颖的约束感知求解策略。我们引入了 CSP 意识熵，通过约束传播后计算信息增益，而不是在原始候选集上计算，并结合贝叶斯词频先验和逻辑约束提出了概率 CSP 框架。通过在 2,315 个英文字词上的评估，CSP 意识熵实现了平均每词 3.54 次猜测和 99.9% 的成功率达到，相对于前向检查显示出统计显著性的 1.7% 的改进（t=-4.82, p<0.001, Cohen's d=0.07），同时运行时间快 46%（平均每词 12.9 毫秒对 23.7 毫秒）。在 10% 的噪声下，CSP 意识方法保持了 5.3 个百分点的优势（29.0% 对 23.7%，p=0.041），而概率 CSP 通过约束恢复机制在所有噪声水平（0-20%）下实现了 100% 的成功。跨语言验证在 500 个西班牙语词上的结果显示了 88% 的成功率，无需特定语言调整，验证了尽管存在 11.2 个百分点的语言差异，核心 CSP 原理在不同语言中依然有效（p<0.001，Fisher 精确检验）。我们的开源实现包含 34 个单元测试，覆盖率 91%，为 CSP 研究提供了可重复的基础设施。结合形式化的 CSP 处理、约束意识启发式方法、概率-逻辑集成、稳健性分析和跨语言验证，建立了新的性能基准，表明基于原则的约束满足技术在结构化谜题求解领域优于经典的信息论和学习导向方法。", 'title_zh': '基于约束满足方法的Wordle求解：新颖启发式方法与跨词库验证'}
{'arxiv_id': 'arXiv:2510.02848', 'title': 'Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech', 'authors': 'Hieu-Nghia Huynh-Nguyen, Huynh Nguyen Dang, Ngoc-Son Nguyen, Van Nguyen', 'link': 'https://arxiv.org/abs/2510.02848', 'abstract': 'Zero-shot Text-to-Speech (TTS) has recently advanced significantly, enabling models to synthesize speech from text using short, limited-context prompts. These prompts serve as voice exemplars, allowing the model to mimic speaker identity, prosody, and other traits without extensive speaker-specific data. Although recent approaches incorporating language models, diffusion, and flow matching have proven their effectiveness in zero-shot TTS, they still encounter challenges such as unreliable synthesis caused by token repetition or unexpected content transfer, along with slow inference and substantial computational overhead. Moreover, temporal diversity-crucial for enhancing the naturalness of synthesized speech-remains largely underexplored. To address these challenges, we propose Flamed-TTS, a novel zero-shot TTS framework that emphasizes low computational cost, low latency, and high speech fidelity alongside rich temporal diversity. To achieve this, we reformulate the flow matching training paradigm and incorporate both discrete and continuous representations corresponding to different attributes of speech. Experimental results demonstrate that Flamed-TTS surpasses state-of-the-art models in terms of intelligibility, naturalness, speaker similarity, acoustic characteristics preservation, and dynamic pace. Notably, Flamed-TTS achieves the best WER of 4% compared to the leading zero-shot TTS baselines, while maintaining low latency in inference and high fidelity in generated speech. Code and audio samples are available at our demo page this https URL.', 'abstract_zh': '零样本文本到语音（TTS）最近取得了显著进展，使模型能够使用短的、背景有限的提示从文本合成立音。这些提示作为声音示例，使模型能够在无需大量特定说话人数据的情况下模仿说话人身份、语调和其他特征。尽管最近结合了语言模型、扩散和流匹配的方法在零样本TTS方面证明了其有效性，但仍面临合成不可靠等问题，如由标记重复引起的问题或意外内容转移，此外，还有推理速度慢和大量计算开销的问题。此外，时间多样性对于提高合成语音的自然度至关重要，但仍然很少被探索。为了解决这些问题，我们提出了Flamed-TTS，这是首个强调低计算成本、低延迟、高语音保真度以及丰富时间多样性相结合的零样本TTS框架。通过重新定义流匹配训练范式并结合与语音不同属性相对应的离散和连续表示，我们实现了这一目标。实验结果表明，Flamed-TTS 在可理解性、自然度、说话人相似性、声学特征保持以及动态节奏方面超越了现有最先进的模型。值得注意的是，Flamed-TTS 达到了 4% 的最佳词误差率（WER），同时在推理延迟低且生成语音保真度高。详细代码和音频样本可在我们的演示页面获取：https://demo.com。', 'title_zh': 'Flamed-TTS: 流匹配注意力自由模型实现高效的生成和动态节奏文本-to-语音'}
{'arxiv_id': 'arXiv:2510.02839', 'title': 'Knowledge-Aware Modeling with Frequency Adaptive Learning for Battery Health Prognostics', 'authors': 'Vijay Babu Pamshetti, Wei Zhang, Sumei Sun, Jie Zhang, Yonggang Wen, Qingyu Yan', 'link': 'https://arxiv.org/abs/2510.02839', 'abstract': "Battery health prognostics are critical for ensuring safety, efficiency, and sustainability in modern energy systems. However, it has been challenging to achieve accurate and robust prognostics due to complex battery degradation behaviors with nonlinearity, noise, capacity regeneration, etc. Existing data-driven models capture temporal degradation features but often lack knowledge guidance, which leads to unreliable long-term health prognostics. To overcome these limitations, we propose Karma, a knowledge-aware model with frequency-adaptive learning for battery capacity estimation and remaining useful life prediction. The model first performs signal decomposition to derive battery signals in different frequency bands. A dual-stream deep learning architecture is developed, where one stream captures long-term low-frequency degradation trends and the other models high-frequency short-term dynamics. Karma regulates the prognostics with knowledge, where battery degradation is modeled as a double exponential function based on empirical studies. Our dual-stream model is used to optimize the parameters of the knowledge with particle filters to ensure physically consistent and reliable prognostics and uncertainty quantification. Experimental study demonstrates Karma's superior performance, achieving average error reductions of 50.6% and 32.6% over state-of-the-art algorithms for battery health prediction on two mainstream datasets, respectively. These results highlight Karma's robustness, generalizability, and potential for safer and more reliable battery management across diverse applications.", 'abstract_zh': '电池健康预测对于确保现代能源系统中的安全、效率和可持续性至关重要。然而，由于电池退化行为的非线性、噪声、容量再生等因素，准确且 robust 的预测一直具有挑战性。现有的数据驱动模型虽然可以捕捉到时间退化特征，但往往缺乏知识引导，导致长期健康预测不可靠。为克服这些限制，我们提出了一种名为 Karma 的知识感知模型，该模型具有频率自适应学习能力，用于电池容量估计和剩余使用寿命预测。该模型首先进行信号分解，以在不同频率带中提取电池信号。开发了一种双流深度学习架构，其中一条流捕捉长期低频退化趋势，另一条流建模高频短期动态。Karma 通过知识调节预测，其中电池退化基于经验研究被建模为双指数函数。我们的双流模型通过粒子滤波优化知识的参数，以确保物理上一致且可靠的预测和不确定性量化。实验研究表明，Karma 在两个主流数据集上的电池健康预测性能明显优于现有先进算法，平均误差分别降低了 50.6% 和 32.6%。这些结果突显了 Karma 在不同应用中实现更安全且更可靠电池管理的稳健性、泛化能力和潜力。', 'title_zh': '基于频率自适应学习的知识aware建模方法及其在电池健康预测中的应用'}
{'arxiv_id': 'arXiv:2510.02811', 'title': 'A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media', 'authors': 'Matej Gjurković', 'link': 'https://arxiv.org/abs/2510.02811', 'abstract': "Personality refers to individual differences in behavior, thinking, and feeling. With the growing availability of digital footprints, especially from social media, automated methods for personality assessment have become increasingly important. Natural language processing (NLP) enables the analysis of unstructured text data to identify personality indicators. However, two main challenges remain central to this thesis: the scarcity of large, personality-labeled datasets and the disconnect between personality psychology and NLP, which restricts model validity and interpretability. To address these challenges, this thesis presents two datasets -- MBTI9k and PANDORA -- collected from Reddit, a platform known for user anonymity and diverse discussions. The PANDORA dataset contains 17 million comments from over 10,000 users and integrates the MBTI and Big Five personality models with demographic information, overcoming limitations in data size, quality, and label coverage. Experiments on these datasets show that demographic variables influence model validity. In response, the SIMPA (Statement-to-Item Matching Personality Assessment) framework was developed - a computational framework for interpretable personality assessment that matches user-generated statements with validated questionnaire items. By using machine learning and semantic similarity, SIMPA delivers personality assessments comparable to human evaluations while maintaining high interpretability and efficiency. Although focused on personality assessment, SIMPA's versatility extends beyond this domain. Its model-agnostic design, layered cue detection, and scalability make it suitable for various research and practical applications involving complex label taxonomies and variable cue associations with target concepts.", 'abstract_zh': '个性指的是行为、思维和情感方面的个体差异。随着数字足迹，尤其是来自社交媒体的数据日益增多，自动化的人格评估方法变得愈加重要。自然语言处理（NLP）使对非结构化文本数据进行分析以识别人格指标成为可能。然而，这一论文的核心挑战仍然是大数据集的稀缺性和人格心理学与NLP之间的脱节，这限制了模型的有效性和可解释性。为应对这些挑战，本论文提出了两个数据集——MBTI9k和PANDORA，并从以匿名性和多样化讨论著称的Reddit平台收集数据。PANDORA数据集包含了超过10,000名用户的1700万条评论，并将MBTI和大五人格模型与人口统计信息相结合，克服了数据量、质量和标签覆盖率的限制。在这些数据集上的实验表明，人口统计变量影响模型的有效性。针对此，开发了SIMPA（陈述到项目匹配人格评估）框架——一种计算框架，用于解释性人格评估，通过将用户生成的陈述与验证的问卷项目匹配。SIMPA使用机器学习和语义相似性，提供的人格评估结果与人类评估相当，同时保持了高可解释性和高效性。尽管主要集中于人格评估，SIMPA的多功能性超越了这一领域。其模型无偏的设计、多层提示检测和可扩展性使其适用于涉及复杂标签分类和多种提示与目标概念关联的各种研究和实际应用。', 'title_zh': '一种基于社交媒体的可解释文本型人格评估的计算框架'}
{'arxiv_id': 'arXiv:2510.02809', 'title': 'Relevance-Aware Thresholding in Online Conformal Prediction for Time Series', 'authors': 'Théo Dupuy, Binbin Xu, Stéphane Perrey, Jacky Montmain, Abdelhak Imoussaten', 'link': 'https://arxiv.org/abs/2510.02809', 'abstract': 'Uncertainty quantification has received considerable interest in recent works in Machine Learning. In particular, Conformal Prediction (CP) gains ground in this field. For the case of time series, Online Conformal Prediction (OCP) becomes an option to address the problem of data distribution shift over time. Indeed, the idea of OCP is to update a threshold of some quantity (whether the miscoverage level or the quantile) based on the distribution observation. To evaluate the performance of OCP methods, two key aspects are typically considered: the coverage validity and the prediction interval width minimization. Recently, new OCP methods have emerged, offering long-run coverage guarantees and producing more informative intervals. However, during the threshold update step, most of these methods focus solely on the validity of the prediction intervals~--~that is, whether the ground truth falls inside or outside the interval~--~without accounting for their relevance. In this paper, we aim to leverage this overlooked aspect. Specifically, we propose enhancing the threshold update step by replacing the binary evaluation (inside/outside) with a broader class of functions that quantify the relevance of the prediction interval using the ground truth. This approach helps prevent abrupt threshold changes, potentially resulting in narrower prediction intervals. Indeed, experimental results on real-world datasets suggest that these functions can produce tighter intervals compared to existing OCP methods while maintaining coverage validity.', 'abstract_zh': '不确定性量化在机器学习Recent Works中受到了广泛关注，特别是在 conformal预测领域。对于时间序列情况，在线 conformal预测(OCP)成为处理随时间变化的数据分布偏移问题的一种选择。实际上，OCP的核心思想是根据分布观察更新某一量的阈值（无论是覆盖率还是分位数）。为了评估OCP方法的性能，通常考虑两个关键方面：预测区间覆盖的有效性和预测区间宽度的最小化。最近，新兴的OCP方法提供了长期覆盖保证，并生成更具信息量的区间。然而，在阈值更新步骤中，大多数方法仅关注预测区间的有效性——即真实值是否落入或未落入区间——而不考虑其相关性。本文旨在利用这一被忽视的方面。具体来说，我们建议通过将二元评估（包含/不包含）替换为量化预测区间相关性的函数族，来增强阈值更新步骤。这种方法有助于防止阈值突然变化，从而可能产生更窄的预测区间。事实上，实世界数据集上的实验结果表明，与现有OCP方法相比，这些函数可以在保持覆盖有效性的前提下，生成更紧的区间。', 'title_zh': '基于时序的在线同变预测中的相关性意识阈值化'}
{'arxiv_id': 'arXiv:2510.02798', 'title': 'OptunaHub: A Platform for Black-Box Optimization', 'authors': 'Yoshihiko Ozaki, Shuhei Watanabe, Toshihiko Yanase', 'link': 'https://arxiv.org/abs/2510.02798', 'abstract': 'Black-box optimization (BBO) drives advances in domains such as AutoML and Materials Informatics, yet research efforts often remain fragmented across domains. We introduce OptunaHub (this https URL), a community platform that centralizes BBO methods and benchmarks. OptunaHub provides unified Python APIs, a contributor package registry, and a web interface to promote searchability and cross-domain research. OptunaHub aims to foster a virtuous cycle of contributions and applications. The source code is publicly available in the optunahub, optunahub-registry, and optunahub-web repositories under the Optuna organization on GitHub (this https URL).', 'abstract_zh': '黑箱优化（BBO）推动了诸如自动化机器学习（AutoML）和材料信息学等领域的发展，但研究努力在不同领域间往往保持分散状态。我们介绍了OptunaHub（https://optuna.org/hub），这是一个社区平台，旨在集中黑箱优化方法和基准测试。OptunaHub提供统一的Python API、贡献者包注册表以及网页界面，以促进可搜索性和跨领域研究。OptunaHub旨在促进贡献和应用的良性循环。源代码在GitHub（https://github.com/optuna）的optunahub、optunahub-registry和optunahub-web存储库中公开可用。', 'title_zh': 'OptunaHub: 一个黑盒优化平台'}
{'arxiv_id': 'arXiv:2510.02763', 'title': 'Fusing Multi- and Hyperspectral Satellite Data for Harmful Algal Bloom Monitoring with Self-Supervised and Hierarchical Deep Learning', 'authors': 'Nicholas LaHaye, Kelly M. Luis, Michelle M. Gierach', 'link': 'https://arxiv.org/abs/2510.02763', 'abstract': 'We present a self-supervised machine learning framework for detecting and mapping harmful algal bloom (HAB) severity and speciation using multi-sensor satellite data. By fusing reflectance data from operational instruments (VIIRS, MODIS, Sentinel-3, PACE) with TROPOMI solar-induced fluorescence (SIF), our framework, called SIT-FUSE, generates HAB severity and speciation products without requiring per-instrument labeled datasets. The framework employs self-supervised representation learning, hierarchical deep clustering to segment phytoplankton concentrations and speciations into interpretable classes, validated against in-situ data from the Gulf of Mexico and Southern California (2018-2025). Results show strong agreement with total phytoplankton, Karenia brevis, Alexandrium spp., and Pseudo-nitzschia spp. measurements. This work advances scalable HAB monitoring in label-scarce environments while enabling exploratory analysis via hierarchical embeddings: a critical step toward operationalizing self-supervised learning for global aquatic biogeochemistry.', 'abstract_zh': '我们提出了一种自监督机器学习框架，通过多传感器卫星数据检测和映射有害藻华（HAB）的严重程度和种类。该框架名为SIT-FUSE，通过融合来自操作仪器（VIIRS、MODIS、Sentinel-3、PACE）的反射数据与TROPOMI太阳诱导荧光（SIF）数据，生成HAB的严重程度和种类产品，无需依赖单个仪器的标注数据集。该框架采用自监督表示学习和分层深度聚类方法，对佛罗里达湾和南加州（2018-2025年）的实地数据进行验证，结果显示与微型浮游植物、Karenia brevis、Alexandrium spp. 和 Pseudo-nitzschia spp. 的测量值高度一致。这项工作在标签稀少的环境中推进了可扩展的HAB监测，并通过层次嵌入支持探索性分析：这是实现自监督学习在地球水文生物地球化学中的操作化的一个关键步骤。', 'title_zh': '多光谱与高光谱卫星数据融合用于有害藻华监测的自我监督和分层深度学习方法'}
{'arxiv_id': 'arXiv:2510.02760', 'title': 'Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology', 'authors': 'Matthias Perkonigg, Patrick Rockenschaub, Georg Göbel, Adelheid Wöhrer', 'link': 'https://arxiv.org/abs/2510.02760', 'abstract': 'Accurate brain tumor classification is critical for intra-operative decision making in neuro-oncological surgery. However, existing approaches are restricted to a fixed set of predefined classes and are therefore unable to capture patterns of tumor types not available during training. Unsupervised learning can extract general-purpose features, but it lacks the ability to incorporate prior knowledge from labelled data, and semi-supervised methods often assume that all potential classes are represented in the labelled data. Generalized Category Discovery (GCD) aims to bridge this gap by categorizing both known and unknown classes within unlabelled data. To reflect the hierarchical structure of brain tumor taxonomies, in this work, we introduce Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT), a novel approach that integrates hierarchical clustering with contrastive learning. Our method extends contrastive learning based GCD by incorporating a novel semi-supervised hierarchical clustering loss. We evaluate HGCD-BT on OpenSRH, a dataset of stimulated Raman histology brain tumor images, achieving a +28% improvement in accuracy over state-of-the-art GCD methods for patch-level classification, particularly in identifying previously unseen tumor categories. Furthermore, we demonstrate the generalizability of HGCD-BT on slide-level classification of hematoxylin and eosin stained whole-slide images from the Digital Brain Tumor Atlas, confirming its utility across imaging modalities.', 'abstract_zh': '准确的脑肿瘤分类对于神经肿瘤手术中的 intra-operative 决策至关重要。然而，现有方法仅限于固定的预定义分类集，因此无法捕捉训练期间不可用的肿瘤类型模式。无监督学习可以提取通用特征，但缺乏将标记数据中的先验知识纳入的能力，而半监督方法通常假设所有潜在类别都在标记数据中得到代表。泛化类别发现（GCD）旨在通过将已知和未知类别归类到无标记数据中来弥合这一差距。为了反映脑肿瘤分类体系结构的层次结构，本文介绍了一种名为 Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT) 的新颖方法，该方法结合了层次聚类和对比学习。我们的方法通过引入一种新颖的半监督层次聚类损失，扩展了基于对比学习的 GCD。我们在 OpenSRH 数据集上评估了 HGCD-BT，该数据集包含刺激拉曼组化脑肿瘤图像，实现了与最先进的 GCD 方法相比在 patch 级分类上的 +28% 准确率提升，尤其是在识别以前未见过的肿瘤类别方面。此外，我们展示了 HGCD-BT 在 Digital Brain Tumor Atlas 中的压片级别分类中的通用性，使用苏木精和伊红染色的全切片图像，证明了其在不同成像模态中的实用性。', 'title_zh': '数字病理学中脑肿瘤分类的分层广义类别发现'}
{'arxiv_id': 'arXiv:2510.02717', 'title': 'CST-AFNet: A dual attention-based deep learning framework for intrusion detection in IoT networks', 'authors': 'Waqas Ishtiaq, Ashrafun Zannat, A.H.M. Shahariar Parvez, Md. Alamgir Hossain, Muntasir Hasan Kanchan, Muhammad Masud Tarek', 'link': 'https://arxiv.org/abs/2510.02717', 'abstract': 'The rapid expansion of the Internet of Things (IoT) has revolutionized modern industries by enabling smart automation and real time connectivity. However, this evolution has also introduced complex cybersecurity challenges due to the heterogeneous, resource constrained, and distributed nature of these environments. To address these challenges, this research presents CST AFNet, a novel dual attention based deep learning framework specifically designed for robust intrusion detection in IoT networks. The model integrates multi scale Convolutional Neural Networks (CNNs) for spatial feature extraction, Bidirectional Gated Recurrent Units (BiGRUs) for capturing temporal dependencies, and a dual attention mechanism, channel and temporal attention, to enhance focus on critical patterns in the data. The proposed method was trained and evaluated on the Edge IIoTset dataset, a comprehensive and realistic benchmark containing more than 2.2 million labeled instances spanning 15 attack types and benign traffic, collected from a seven layer industrial testbed. Our proposed model achieves outstanding accuracy for both 15 attack types and benign traffic. CST AFNet achieves 99.97 percent accuracy. Moreover, this model demonstrates exceptional performance with macro averaged precision, recall, and F1 score all above 99.3 percent. Experimental results show that CST AFNet achieves superior detection accuracy, significantly outperforming traditional deep learning models. The findings confirm that CST AFNet is a powerful and scalable solution for real time cyber threat detection in complex IoT and IIoT environments, paving the way for more secure, intelligent, and adaptive cyber physical systems.', 'abstract_zh': '物联网(IoT)的快速扩展通过实现智能自动化和实时连接颠覆了现代工业，但这一演变也带来了复杂的网络安全挑战，尤其是由于这些环境的异构性、资源限制性和分布式特性。为应对这些挑战，本研究提出了一种名为CST AFNet的新型双注意机制深度学习框架，专门设计用于物联网网络中的稳健入侵检测。该模型结合了多尺度卷积神经网络(CNNs)进行空间特征提取、双向门控循环单元(BiGRUs)捕获时间依赖性，并引入了通道注意和时间注意双注意机制，以增强对数据中关键模式的关注。所提出的方法在Edge IIoTset数据集上进行了训练和评估，该数据集是一个全面且逼真的基准，包含超过220万标注实例，涵盖15种攻击类型和良性流量，来自一个七层工业测试床。我们的提出的模型在15种攻击类型和良性流量上均实现了卓越的准确性。CST AFNet的准确率达到99.97%。此外，该模型在宏观平均精确度、召回率和F1分数上均超过99.3%。实验结果表明，CST AFNet在检测准确性上表现出色，显著优于传统的深度学习模型。研究发现确认了CST AFNet在复杂物联网和工业物联网环境中实时网络威胁检测的强大和可扩展性解决方案，为更安全、智能且适应性强的网络物理系统铺平了道路。', 'title_zh': 'CST-AFNet：物联网网络入侵检测的基于双注意力机制的深度学习框架'}
{'arxiv_id': 'arXiv:2510.02715', 'title': 'Fully automated inverse co-optimization of templates and block copolymer blending recipes for DSA lithography', 'authors': 'Yuhao Zhou, Huangyan Shen, Qingliang Song, Qingshu Dong, Jianfeng Li, Weihua Li', 'link': 'https://arxiv.org/abs/2510.02715', 'abstract': 'The directed self-assembly (DSA) of block copolymers (BCPs) offers a highly promising approach for the fabrication of contact holes or vertical interconnect access at sub-7nm technology nodes. To fabricate circular holes with precisely controlled size and positions, the self-assembly of block copolymers requires guidance from a properly designed template. Effectively parameterizing the template shape to enable efficient optimization remains a critical yet challenging problem. Moreover, the optimized template must possess excellent manufacturability for practical applications. In this work, we propose a Gaussian descriptor for characterizing the template shape with only two parameters. We further propose to use AB/AB binary blends instead of pure diblock copolymer to improve the adaptability of the block copolymer system to the template shape. The Bayesian optimization (BO) is applied to co-optimize the binary blend and the template shape. Our results demonstrate that BO based on the Gaussian descriptor can efficiently yield the optimal templates for diverse multi-hole patterns, all leading to highly matched self-assembled morphologies. Moreover, by imposing constraints on the variation of curvature of the template during optimization, superior manufacturability is ensured for each optimized template. It is noteworthy that each key parameter of the blend exhibits a relatively wide tunable window under the requirement of rather high precision. Our work provides valuable insights for advancing DSA technology, and thus potentially propels its practical applications forward.', 'abstract_zh': '基于高斯描述符的模板形状参数化及Bayesian优化在直接自组装中的应用', 'title_zh': '全自动化逆共优化模板和_block共聚物混合配方用于DSA光刻'}
{'arxiv_id': 'arXiv:2510.02711', 'title': 'A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks', 'authors': 'Tarun Kumar Biswas, Ashrafun Zannat, Waqas Ishtiaq, Md. Alamgir Hossain', 'link': 'https://arxiv.org/abs/2510.02711', 'abstract': 'The growing integration of drones across commercial, industrial, and civilian domains has introduced significant cybersecurity challenges, particularly due to the susceptibility of drone networks to a wide range of cyberattacks. Existing intrusion detection mechanisms often lack the adaptability, efficiency, and generalizability required for the dynamic and resource constrained environments in which drones operate. This paper proposes TSLT-Net, a novel lightweight and unified Temporal Spatial Transformer based intrusion detection system tailored specifically for drone networks. By leveraging self attention mechanisms, TSLT-Net effectively models both temporal patterns and spatial dependencies in network traffic, enabling accurate detection of diverse intrusion types. The framework includes a streamlined preprocessing pipeline and supports both multiclass attack classification and binary anomaly detection within a single architecture. Extensive experiments conducted on the ISOT Drone Anomaly Detection Dataset, consisting of more than 2.3 million labeled records, demonstrate the superior performance of TSLT-Net with 99.99 percent accuracy in multiclass detection and 100 percent in binary anomaly detection, while maintaining a minimal memory footprint of only 0.04 MB and 9722 trainable parameters. These results establish TSLT-Net as an effective and scalable solution for real time drone cybersecurity, particularly suitable for deployment on edge devices in mission critical UAV systems.', 'abstract_zh': '无人机网络的时空转换器基于新型轻量级统一入侵检测系统', 'title_zh': '一种用于无人机网络入侵检测的新型统一轻量时空变换器方法'}
{'arxiv_id': 'arXiv:2510.02683', 'title': 'Can Data-Driven Dynamics Reveal Hidden Physics? There Is A Need for Interpretable Neural Operators', 'authors': 'Wenhan Gao, Jian Luo, Fang Wan, Ruichen Xu, Xiang Liu, Haipeng Xing, Yi Liu', 'link': 'https://arxiv.org/abs/2510.02683', 'abstract': 'Recently, neural operators have emerged as powerful tools for learning mappings between function spaces, enabling data-driven simulations of complex dynamics. Despite their successes, a deeper understanding of their learning mechanisms remains underexplored. In this work, we classify neural operators into two types: (1) Spatial domain models that learn on grids and (2) Functional domain models that learn with function bases. We present several viewpoints based on this classification and focus on learning data-driven dynamics adhering to physical principles. Specifically, we provide a way to explain the prediction-making process of neural operators and show that neural operator can learn hidden physical patterns from data. However, this explanation method is limited to specific situations, highlighting the urgent need for generalizable explanation methods. Next, we show that a simple dual-space multi-scale model can achieve SOTA performance and we believe that dual-space multi-spatio-scale models hold significant potential to learn complex physics and require further investigation. Lastly, we discuss the critical need for principled frameworks to incorporate known physics into neural operators, enabling better generalization and uncovering more hidden physical phenomena.', 'abstract_zh': '最近，神经算子作为学习函数空间之间映射的强有力工具而 emergence，使得复杂动态的数据驱动模拟成为可能。尽管它们取得了成功，但对其学习机制的理解仍需进一步探究。在本文中，我们将神经算子分为两类：（1）基于网格的空间域模型和（2）基于函数基的函数域模型。基于这种分类，我们提出了几种观点，并专注于遵循物理原理的数据驱动动力学学习。具体而言，我们提供了一种解释神经算子预测过程的方法，并展示了神经算子可以从数据中学习到隐藏的物理模式。然而，这种方法局限于特定情况，突显了通用解释方法的迫切需求。接下来，我们展示了简单的双空间多层次模型可以达到SOTA性能，并认为双空间多层次模型具有学习复杂物理的巨大潜力，需要进一步研究。最后，我们讨论了将已知物理原理融入神经算子的原理性框架的迫切需求，以提高泛化能力并揭示更多隐藏的物理现象。', 'title_zh': '数据驱动的动力学能否揭示隐藏的物理规律？需要可解释的神经算子。'}
{'arxiv_id': 'arXiv:2510.02668', 'title': 'AgenticRAG: Tool-Augmented Foundation Models for Zero-Shot Explainable Recommender Systems', 'authors': 'Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Liu', 'link': 'https://arxiv.org/abs/2510.02668', 'abstract': 'Foundation models have revolutionized artificial intelligence, yet their application in recommender systems remains limited by reasoning opacity and knowledge constraints. This paper introduces AgenticRAG, a novel framework that combines tool-augmented foundation models with retrieval-augmented generation for zero-shot explainable recommendations. Our approach integrates external tool invocation, knowledge retrieval, and chain-of-thought reasoning to create autonomous recommendation agents capable of transparent decision-making without task-specific training. Experimental results on three real-world datasets demonstrate that AgenticRAG achieves consistent improvements over state-of-the-art baselines, with NDCG@10 improvements of 0.4\\% on Amazon Electronics, 0.8\\% on MovieLens-1M, and 1.6\\% on Yelp datasets. The framework exhibits superior explainability while maintaining computational efficiency comparable to traditional methods.', 'abstract_zh': '基于因子模型在推荐系统中的应用受限于推理不透明性和知识约束，本文提出了AgenticRAG框架，该框架结合了工具增强的基础模型和检索增强的生成技术，以实现零样本可解释推荐。实验结果表明，AgenticRAG在Amazon Electronics、MovieLens-1M和Yelp数据集上的NDCG@10分别提高了0.4%、0.8%和1.6%，并在保持计算效率的同时表现出更强的可解释性。', 'title_zh': 'AgenticRAG: 工具增强的基础模型在零样本可解释推荐系统中的应用'}
{'arxiv_id': 'arXiv:2510.02610', 'title': 'MINERVA: Mutual Information Neural Estimation for Supervised Feature Selection', 'authors': 'Taurai Muvunzaa, Egor Kraev, Pere Planell-Morell, Alexander Y. Shestopaloff', 'link': 'https://arxiv.org/abs/2510.02610', 'abstract': 'Existing feature filters rely on statistical pair-wise dependence metrics to model feature-target relationships, but this approach may fail when the target depends on higher-order feature interactions rather than individual contributions. We introduce Mutual Information Neural Estimation Regularized Vetting Algorithm (MINERVA), a novel approach to supervised feature selection based on neural estimation of mutual information between features and targets. We paramaterize the approximation of mutual information with neural networks and perform feature selection using a carefully designed loss function augmented with sparsity-inducing regularizers. Our method is implemented in a two-stage process to decouple representation learning from feature selection, ensuring better generalization and a more accurate expression of feature importance. We present examples of ubiquitous dependency structures that are rarely captured in literature and show that our proposed method effectively captures these complex feature-target relationships by evaluating feature subsets as an ensemble. Experimental results on synthetic and real-life fraud datasets demonstrate the efficacy of our method and its ability to perform exact solutions.', 'abstract_zh': '基于神经估计互信息正则化筛选算法（MINERVA）的监督特征选择', 'title_zh': 'MINERVA: 监督特征选择中的互信息神经估计'}
{'arxiv_id': 'arXiv:2510.02535', 'title': 'PHORECAST: Enabling AI Understanding of Public Health Outreach Across Populations', 'authors': 'Rifaa Qadri, Anh Nhat Nhu, Swati Ramnath, Laura Yu Zheng, Raj Bhansali, Sylvette La Touche-Howard, Tracy Marie Zeeger, Tom Goldstein, Ming Lin', 'link': 'https://arxiv.org/abs/2510.02535', 'abstract': 'Understanding how diverse individuals and communities respond to persuasive messaging holds significant potential for advancing personalized and socially aware machine learning. While Large Vision and Language Models (VLMs) offer promise, their ability to emulate nuanced, heterogeneous human responses, particularly in high stakes domains like public health, remains underexplored due in part to the lack of comprehensive, multimodal dataset. We introduce PHORECAST (Public Health Outreach REceptivity and CAmpaign Signal Tracking), a multimodal dataset curated to enable fine-grained prediction of both individuallevel behavioral responses and community-wide engagement patterns to health messaging. This dataset supports tasks in multimodal understanding, response prediction, personalization, and social forecasting, allowing rigorous evaluation of how well modern AI systems can emulate, interpret, and anticipate heterogeneous public sentiment and behavior. By providing a new dataset to enable AI advances for public health, PHORECAST aims to catalyze the development of models that are not only more socially aware but also aligned with the goals of adaptive and inclusive health communication', 'abstract_zh': '理解多样化个体和社区对说服性信息的响应机制具有推动个性化和社会意识机器学习的重要潜力。虽然大规模视觉和语言模型（VLMs）充满希望，但在公共卫生等高风险领域，它们模仿细腻且异质的人类响应能力仍较少被探讨，部分原因是缺乏全面的多模态数据集。我们介绍了一个名为PHORECAST（Public Health Outreach REceptivity and CAmpaign Signal Tracking）的多模态数据集，旨在促进对健康信息个体层面行为响应和社区层面参与模式的精细预测。该数据集支持多模态理解、响应预测、个性化和社交预测任务，允许对现代AI系统模仿、解释和预判异质公共情绪和行为的能力进行严格的评估。通过提供一个新数据集以促进公共健康领域的AI进步，PHORECAST旨在推动开发更加社会意识强且与适应性和包容性健康沟通目标一致的模型。', 'title_zh': 'PHORECAST: 跨群体促进公共健康宣传的AI理解能力'}
{'arxiv_id': 'arXiv:2510.02484', 'title': 'From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning', 'authors': 'Rafael Rodriguez-Sanchez, Cameron Allen, George Konidaris', 'link': 'https://arxiv.org/abs/2510.02484', 'abstract': "Algorithms that exploit factored Markov decision processes are far more sample-efficient than factor-agnostic methods, yet they assume a factored representation is known a priori -- a requirement that breaks down when the agent sees only high-dimensional observations. Conversely, deep reinforcement learning handles such inputs but cannot benefit from factored structure. We address this representation problem with Action-Controllable Factorization (ACF), a contrastive learning approach that uncovers independently controllable latent variables -- state components each action can influence separately. ACF leverages sparsity: actions typically affect only a subset of variables, while the rest evolve under the environment's dynamics, yielding informative data for contrastive training. ACF recovers the ground truth controllable factors directly from pixel observations on three benchmarks with known factored structure -- Taxi, FourRooms, and MiniGrid-DoorKey -- consistently outperforming baseline disentanglement algorithms.", 'abstract_zh': '利用行动可控因子化的算法在样本效率方面远超无因子aware的方法，但这些算法假设因子化表示已知先验——这一要求在智能体仅看到高维观察时会失效。相反，深度强化学习可以处理此类输入，但无法利用因子结构的优势。我们通过行动可控因子化（ACF）解决这一表示问题，ACF 是一种对比学习方法，能够发现各自可独立控制的潜在变量——每个动作可以单独影响的状态成分。ACF 利用稀疏性：动作通常仅影响一部分变量，而其余变量则在环境动力学的驱动下变化，从而为对比训练提供有用的数据。ACF 直接从三个已知因子结构基准（Taxi、FourRooms 和 MiniGrid-DoorKey）的像素观察中恢复真正的可控制因子，并且在基准测试中一致性地优于基线解耦算法。', 'title_zh': '从像素到因素：学习可独立控制的状态变量以进行强化学习'}
{'arxiv_id': 'arXiv:2510.02456', 'title': 'Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility', 'authors': 'Ashish Jha, Valentin Leplat, AH Phan', 'link': 'https://arxiv.org/abs/2510.02456', 'abstract': 'Selecting a small yet useful subset of training data is hard because signals of example utility (uncertainty, rarity, diversity, etc.) are heterogeneous and typically combined with ad hoc weights. We propose a market-based selector that prices each example via a cost-function prediction market (LMSR), signals act as traders, a single liquidity parameter controls concentration, and topic-wise normalization stabilizes calibration. Token budgets are handled explicitly by a price-per-token rule $\\rho=p/\\ell^{\\gamma}$, with $\\gamma$ exposing an interpretable length bias; a lightweight diversity head improves coverage. We quantify coverage via topic cluster coverage and effective sample size. On the theory side, we show that LMSR implements a maximum-entropy aggregation with exponential weighting and a convex objective, yielding transparent knobs for aggregation strength. Empirically, on GSM8K (60k-token budget) the market with diversity achieves parity with strong single-signal baselines while reducing seed variance and incurring $<\\!0.1$ GPU-hr selection overhead; on AGNews at kept=5-25\\% the market (with light balancing) delivers competitive accuracy with improved balance and stability. The framework unifies multi-signal data curation under fixed compute for prompt-level reasoning and classification.', 'abstract_zh': '基于市场选择的小而有用训练数据子集的选择：一种成本函数预测市场的方法', 'title_zh': '基于市场的数据子集选择——多准则例证效用的原理性聚合'}
{'arxiv_id': 'arXiv:2510.02417', 'title': 'NEURODNAAI: Neural pipeline approaches for the advancing dna-based information storage as a sustainable digital medium using deep learning framework', 'authors': 'Rakesh Thakur, Lavanya Singh, Yashika, Manomay Bundawala, Aruna Kumar', 'link': 'https://arxiv.org/abs/2510.02417', 'abstract': 'DNA is a promising medium for digital information storage for its exceptional density and durability. While prior studies advanced coding theory, workflow design, and simulation tools, challenges such as synthesis costs, sequencing errors, and biological constraints (GC-content imbalance, homopolymers) limit practical deployment. To address this, our framework draws from quantum parallelism concepts to enhance encoding diversity and resilience, integrating biologically informed constraints with deep learning to enhance error mitigation in DNA storage. NeuroDNAAI encodes binary data streams into symbolic DNA sequences, transmits them through a noisy channel with substitutions, insertions, and deletions, and reconstructs them with high fidelity. Our results show that traditional prompting or rule-based schemes fail to adapt effectively to realistic noise, whereas NeuroDNAAI achieves superior accuracy. Experiments on benchmark datasets demonstrate low bit error rates for both text and images. By unifying theory, workflow, and simulation into one pipeline, NeuroDNAAI enables scalable, biologically valid archival DNA storage', 'abstract_zh': 'DNA是一种具有卓越密度和耐久性的数字信息存储媒介。虽然先前的研究推进了编码理论、工作流程设计和模拟工具的发展，但合成成本、测序错误和生物学限制（如GC含量不平衡、同聚物）等挑战限制了其实用部署。为应对这些挑战，我们的框架借鉴了量子并行性的概念，增强编码多样性和韧性，并结合深度学习与生物学启发的约束，以提高DNA存储中的错误抑制能力。NeuroDNAAI将二进制数据流编码为符号DNA序列，通过含有替换、插入和删除的信道进行传输，并以高保真度重建。实验结果表明，传统提示或基于规则的方案难以有效适应现实中的噪声，而NeuroDNAAI则取得了更优的准确性。在基准数据集上的实验显示，无论是文本还是图像，其位错误率均较低。通过将理论、工作流程和模拟统一到一个管道中，NeuroDNAAI使规模化、生物学有效的归档DNA存储成为可能。', 'title_zh': 'NEURODNAAI：基于深度学习框架的神经管道方法，推动DNA基信息存储技术的发展，作为可持续的数字介质'}
{'arxiv_id': 'arXiv:2510.02416', 'title': 'Cross-Platform DNA Methylation Classifier for the Eight Molecular Subtypes of Group 3 & 4 Medulloblastoma', 'authors': 'Omer Abid, Gholamreza Rafiee', 'link': 'https://arxiv.org/abs/2510.02416', 'abstract': 'Medulloblastoma is a malignant pediatric brain cancer, and the discovery of molecular subgroups is enabling personalized treatment strategies. In 2019, a consensus identified eight novel subtypes within Groups 3 and 4, each displaying heterogeneous characteristics. Classifiers are essential for translating these findings into clinical practice by supporting clinical trials, personalized therapy development and application, and patient monitoring. This study presents a DNA methylation-based, cross-platform machine learning classifier capable of distinguishing these subtypes on both HM450 and EPIC methylation array samples. Across two independent test sets, the model achieved weighted F1 = 0.95 and balanced accuracy = 0.957, consistent across platforms. As the first cross-platform solution, it provides backward compatibility while extending applicability to a newer platform, also enhancing accessibility. It also has the potential to become the first publicly available classifier for these subtypes once deployed through a web application, as planned in the future. This work overall takes steps in the direction of advancing precision medicine and improving clinical outcomes for patients within the majority prevalence medulloblastoma subgroups, groups 3 and 4.', 'abstract_zh': '髓母细胞瘤是一种恶性儿童脑癌，分子亚群的发现正推动个性化治疗策略的发展。2019年，一项共识将3组和4组细分为八种新型亚型，每种亚型均显示出异质性特征。分类器对于将这些发现转化为临床实践至关重要，能够支持临床试验、个性化治疗方法的开发和应用，以及患者的监控。本研究提出了一种基于DNA甲基化的跨平台机器学习分类器，该分类器能够区分HM450和EPIC甲基化阵列样本中的这些亚型。在两个独立的测试集中，该模型的加权F1值为0.95，平衡准确率为0.957，且在不同平台上保持一致。作为首个跨平台解决方案，该分类器提供向后兼容性，同时将适用范围扩展到较新的平台，从而提高可访问性。一旦通过网络应用部署，它还有潜力成为首个公开可用的此类亚型分类器。本研究的整体目标是推进精准医疗，改善髓母细胞瘤3组和4组亚型患者临床结局。', 'title_zh': '跨平台DNA甲基化分类器：Group 3 & 4 Medulloblastoma的八种分子亚型'}
{'arxiv_id': 'arXiv:2510.02414', 'title': 'RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling', 'authors': 'Lin Chen, Jun Chen, Minghui Qiu, Shuxin Zhong, Binghong Chen, Kaishun Wu', 'link': 'https://arxiv.org/abs/2510.02414', 'abstract': 'Reconstructing high-resolution rainfall fields is essential for flood forecasting, hydrological modeling, and climate analysis. However, existing spatial interpolation methods-whether based on automatic weather station (AWS) measurements or enhanced with satellite/radar observations often over-smooth critical structures, failing to capture sharp transitions and localized extremes. We introduce RainSeer, a structure-aware reconstruction framework that reinterprets radar reflectivity as a physically grounded structural prior-capturing when, where, and how rain develops. This shift, however, introduces two fundamental challenges: (i) translating high-resolution volumetric radar fields into sparse point-wise rainfall observations, and (ii) bridging the physical disconnect between aloft hydro-meteors and ground-level precipitation. RainSeer addresses these through a physics-informed two-stage architecture: a Structure-to-Point Mapper performs spatial alignment by projecting mesoscale radar structures into localized ground-level rainfall, through a bidirectional mapping, and a Geo-Aware Rain Decoder captures the semantic transformation of hydro-meteors through descent, melting, and evaporation via a causal spatiotemporal attention mechanism. We evaluate RainSeer on two public datasets-RAIN-F (Korea, 2017-2019) and MeteoNet (France, 2016-2018)-and observe consistent improvements over state-of-the-art baselines, reducing MAE by over 13.31% and significantly enhancing structural fidelity in reconstructed rainfall fields.', 'abstract_zh': '基于结构意识的高分辨率降水场重建对于洪水预报、水文模拟和气候分析至关重要。现有的空间插值方法，无论是基于自动气象站测量还是增强卫星/雷达观测，往往过度平滑关键结构，无法捕捉到锋利的转折和局部极端值。我们提出了RainSeer，一种结构意识的重建框架，重新解释雷达反射率作为物理上可验证的结构先验，捕捉降水何时、何地、如何发展。然而，这种转变带来了两大基本挑战：(i) 将高分辨率体视雷达场转换为稀疏点状降水观测；(ii)弥合高空水汽和地面降水之间的物理差距。RainSeer 通过一种基于物理的两阶段架构来解决这些问题：结构到点的映射器通过双向映射将中尺度雷达结构投影到局部地面降水，地理意识的降水解码器通过因果时空注意机制捕捉水汽在下降、融化和蒸发过程中的语义转换。我们在两个公开数据集RAIN-F（韩国，2017-2019年）和MeteoNet（法国，2016-2018年）上评估了RainSeer，并观察到相对于最先进的基线方法的一致改进，MAE降低了超过13.31%，显著提高了重建降水场的结构保真度。', 'title_zh': 'RainSeer: 基于物理指导建模的细粒度降雨重构'}
{'arxiv_id': 'arXiv:2510.02407', 'title': 'Extreme value forecasting using relevance-based data augmentation with deep learning models', 'authors': 'Junru Hua, Rahul Ahluwalia, Rohitash Chandra', 'link': 'https://arxiv.org/abs/2510.02407', 'abstract': 'Data augmentation with generative adversarial networks (GANs) has been popular for class imbalance problems, mainly for pattern classification and computer vision-related applications. Extreme value forecasting is a challenging field that has various applications from finance to climate change problems. In this study, we present a data augmentation framework for extreme value forecasting. In this framework, our focus is on forecasting extreme values using deep learning models in combination with data augmentation models such as GANs and synthetic minority oversampling technique (SMOTE). We use deep learning models such as convolutional long short-term memory (Conv-LSTM) and bidirectional long short-term memory (BD-LSTM) networks for multistep ahead prediction featuring extremes. We investigate which data augmentation models are the most suitable, taking into account the prediction accuracy overall and at extreme regions, along with computational efficiency. We also present novel strategies for incorporating data augmentation, considering extreme values based on a relevance function. Our results indicate that the SMOTE-based strategy consistently demonstrated superior adaptability, leading to improved performance across both short- and long-horizon forecasts. Conv-LSTM and BD-LSTM exhibit complementary strengths: the former excels in periodic, stable datasets, while the latter performs better in chaotic or non-stationary sequences.', 'abstract_zh': '基于生成对抗网络的数据增强方法在极端值预报中的应用', 'title_zh': '基于相关性数据增强的深度学习模型极端值预测'}
{'arxiv_id': 'arXiv:2510.02401', 'title': 'Linear RNNs for autoregressive generation of long music samples', 'authors': 'Konrad Szewczyk, Daniel Gallo Fernández, James Townsend', 'link': 'https://arxiv.org/abs/2510.02401', 'abstract': 'Directly learning to generate audio waveforms in an autoregressive manner is a challenging task, due to the length of the raw sequences and the existence of important structure on many different timescales. Traditional approaches based on recurrent neural networks, as well as causal convolutions and self-attention, have only had limited success on this task. However, recent work has shown that deep state space models, also referred to as linear RNNs, can be highly efficient in this context. In this work, we push the boundaries of linear RNNs applied to raw audio modeling, investigating the effects of different architectural choices and using context-parallelism to enable training on sequences up to one minute (1M tokens) in length. We present a model, HarmonicRNN, which attains state of the art log-likelihoods and perceptual metrics on small-scale datasets.', 'abstract_zh': '直接学习以自回归方式生成音频波形是一项具有挑战性的任务，由于原始序列的长度和在许多不同时间尺度上存在的重要结构。传统的基于循环神经网络的方法，以及因果卷积和自我注意力机制，在此任务上仅取得了有限的成功。然而，近期研究表明，在这个任务背景下，深度状态空间模型（也称为线性RNN）可以非常高效。在本工作中，我们推动了线性RNN在原始音频建模中的边界，探讨了不同架构选择的影响，并利用上下文并行性使得训练能够在长达一分钟（1M令牌）的序列上进行。我们提出了一种模型，HarmonicRNN，该模型在小型数据集上的对数似然性和感知度量上达到了最先进的水平。', 'title_zh': '用于自回归生成长音乐样本的线性RNN'}
{'arxiv_id': 'arXiv:2510.02386', 'title': 'On The Fragility of Benchmark Contamination Detection in Reasoning Models', 'authors': 'Han Wang, Haoyu Li, Brian Ko, Huan Zhang', 'link': 'https://arxiv.org/abs/2510.02386', 'abstract': 'Leaderboards for LRMs have turned evaluation into a competition, incentivizing developers to optimize directly on benchmark suites. A shortcut to achieving higher rankings is to incorporate evaluation benchmarks into the training data, thereby yielding inflated performance, known as benchmark contamination. Surprisingly, our studies find that evading contamination detections for LRMs is alarmingly easy. We focus on the two scenarios where contamination may occur in practice: (I) when the base model evolves into LRM via SFT and RL, we find that contamination during SFT can be originally identified by contamination detection methods. Yet, even a brief GRPO training can markedly conceal contamination signals that most detection methods rely on. Further empirical experiments and theoretical analysis indicate that PPO style importance sampling and clipping objectives are the root cause of this detection concealment, indicating that a broad class of RL methods may inherently exhibit similar concealment capability; (II) when SFT contamination with CoT is applied to advanced LRMs as the final stage, most contamination detection methods perform near random guesses. Without exposure to non-members, contaminated LRMs would still have more confidence when responding to those unseen samples that share similar distributions to the training set, and thus, evade existing memorization-based detection methods. Together, our findings reveal the unique vulnerability of LRMs evaluations: Model developers could easily contaminate LRMs to achieve inflated leaderboards performance while leaving minimal traces of contamination, thereby strongly undermining the fairness of evaluation and threatening the integrity of public leaderboards. This underscores the urgent need for advanced contamination detection methods and trustworthy evaluation protocols tailored to LRMs.', 'abstract_zh': 'LRMs评估中的基准污染：一种难以检测的欺骗方法', 'title_zh': '基于推理模型的基准污染检测脆弱性研究'}
{'arxiv_id': 'arXiv:2510.02376', 'title': 'Scaling Homomorphic Applications in Deployment', 'authors': 'Ryan Marinelli, Angelica Chowdhury', 'link': 'https://arxiv.org/abs/2510.02376', 'abstract': 'In this endeavor, a proof-of-concept homomorphic application is developed to determine the production readiness of encryption ecosystems. A movie recommendation app is implemented for this purpose and productionized through containerization and orchestration. By tuning deployment configurations, the computational limitations of Fully Homomorphic Encryption (FHE) are mitigated through additional infrastructure optimizations\nIndex Terms: Reinforcement Learning, Orchestration, Homomorphic Encryption', 'abstract_zh': '在这个研究中，开发了一个概念验证同态应用，以确定加密生态系统的产品就绪情况。为此实现了 movie 推荐应用，并通过容器化和编排进行生产化。通过调整部署配置，对完全同态加密（FHE）的计算限制进行了缓解，通过额外的基础设施优化。关键词：强化学习、编排、同态加密', 'title_zh': '部署中可同态应用的缩放scaling homomorphic applications in deployment'}
{'arxiv_id': 'arXiv:2510.02374', 'title': 'A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection', 'authors': 'Ayda Aghaei Nia', 'link': 'https://arxiv.org/abs/2510.02374', 'abstract': "Completely Automated Public Turing tests to tell Computers and Humans Apart (CAPTCHAs) are a foundational component of web security, yet traditional implementations suffer from a trade-off between usability and resilience against AI-powered bots. This paper introduces a novel hybrid CAPTCHA system that synergizes the cognitive challenges posed by Large Language Models (LLMs) with the behavioral biometric analysis of keystroke dynamics. Our approach generates dynamic, unpredictable questions that are trivial for humans but non-trivial for automated agents, while simultaneously analyzing the user's typing rhythm to distinguish human patterns from robotic input. We present the system's architecture, formalize the feature extraction methodology for keystroke analysis, and report on an experimental evaluation. The results indicate that our dual-layered approach achieves a high degree of accuracy in bot detection, successfully thwarting both paste-based and script-based simulation attacks, while maintaining a high usability score among human participants. This work demonstrates the potential of combining cognitive and behavioral tests to create a new generation of more secure and user-friendly CAPTCHAs.", 'abstract_zh': '完全自动化的公共图灵测试以区分计算机和人类：一种新型认知挑战与行为生物特征分析相结合的CAPTCHA系统', 'title_zh': '基于生成式AI与键入动态的混合验证码以增强机器人检测'}
{'arxiv_id': 'arXiv:2510.02371', 'title': 'Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids', 'authors': 'Bochra Al Agha, Razane Tajeddine', 'link': 'https://arxiv.org/abs/2510.02371', 'abstract': 'Smart grids are exposed to passive eavesdropping, where attackers listen silently to communication links. Although no data is actively altered, such reconnaissance can reveal grid topology, consumption patterns, and operational behavior, creating a gateway to more severe targeted attacks. Detecting this threat is difficult because the signals it produces are faint, short-lived, and often disappear when traffic is examined by a single node or along a single timeline. This paper introduces a graph-centric, multimodal detector that fuses physical-layer and behavioral indicators over ego-centric star subgraphs and short temporal windows to detect passive attacks. To capture stealthy perturbations, a two-stage encoder is introduced: graph convolution aggregates spatial context across ego-centric star subgraphs, while a bidirectional GRU models short-term temporal dependencies. The encoder transforms heterogeneous features into a unified spatio-temporal representation suitable for classification. Training occurs in a federated learning setup under FedProx, improving robustness to heterogeneous local raw data and contributing to the trustworthiness of decentralized training; raw measurements remain on client devices. A synthetic, standards-informed dataset is generated to emulate heterogeneous HAN/NAN/WAN communications with wireless-only passive perturbations, event co-occurrence, and leak-safe splits. The model achieves a testing accuracy of 98.32% per-timestep (F1_{attack}=0.972) and 93.35% per-sequence at 0.15% FPR using a simple decision rule with run-length m=2 and threshold $\\tau=0.55$. The results demonstrate that combining spatial and temporal context enables reliable detection of stealthy reconnaissance while maintaining low false-positive rates, making the approach suitable for non-IID federated smart-grid deployments.', 'abstract_zh': '基于图的多模态检测器：融合ego为中心的星形子图和短时间窗口的物理层和行为指标以检测被动攻击', 'title_zh': '基于智能电网中被动攻击检测的联邦时空图学习'}
{'arxiv_id': 'arXiv:2510.02357', 'title': 'Privacy in the Age of AI: A Taxonomy of Data Risks', 'authors': 'Grace Billiris, Asif Gill, Madhushi Bandara', 'link': 'https://arxiv.org/abs/2510.02357', 'abstract': 'Artificial Intelligence (AI) systems introduce unprecedented privacy challenges as they process increasingly sensitive data. Traditional privacy frameworks prove inadequate for AI technologies due to unique characteristics such as autonomous learning and black-box decision-making. This paper presents a taxonomy classifying AI privacy risks, synthesised from 45 studies identified through systematic review. We identify 19 key risks grouped under four categories: Dataset-Level, Model-Level, Infrastructure-Level, and Insider Threat Risks. Findings reveal a balanced distribution across these dimensions, with human error (9.45%) emerging as the most significant factor. This taxonomy challenges conventional security approaches that typically prioritise technical controls over human factors, highlighting gaps in holistic understanding. By bridging technical and behavioural dimensions of AI privacy, this paper contributes to advancing trustworthy AI development and provides a foundation for future research.', 'abstract_zh': '人工智能系统在处理日益敏感的数据时引入了前所未有的隐私挑战。传统的隐私框架因具备自主学习和黑盒决策等独特特性而显得不够充分。本文通过系统综述识别出45项研究，并提出了一种分类AI隐私风险的分类法。我们识别出19个关键风险，分为四个类别：数据集级、模型级、基础设施级和内部威胁风险。研究结果显示，这些维度分布均衡，人为错误（9.45%）成为最主要的因素。本文的分类法挑战了传统的安全方法，这些方法通常优先考虑技术控制而非人为因素，突显了整体理解上的缺口。通过弥合AI隐私的技术和行为维度，本文为可信AI的发展贡献了力量，并为未来研究提供了基础。', 'title_zh': '人工智能时代的隐私保护：数据风险分类'}
{'arxiv_id': 'arXiv:2510.02349', 'title': 'An Investigation into the Performance of Non-Contrastive Self-Supervised Learning Methods for Network Intrusion Detection', 'authors': 'Hamed Fard, Tobias Schalau, Gerhard Wunder', 'link': 'https://arxiv.org/abs/2510.02349', 'abstract': 'Network intrusion detection, a well-explored cybersecurity field, has predominantly relied on supervised learning algorithms in the past two decades. However, their limitations in detecting only known anomalies prompt the exploration of alternative approaches. Motivated by the success of self-supervised learning in computer vision, there is a rising interest in adapting this paradigm for network intrusion detection. While prior research mainly delved into contrastive self-supervised methods, the efficacy of non-contrastive methods, in conjunction with encoder architectures serving as the representation learning backbone and augmentation strategies that determine what is learned, remains unclear for effective attack detection. This paper compares the performance of five non-contrastive self-supervised learning methods using three encoder architectures and six augmentation strategies. Ninety experiments are systematically conducted on two network intrusion detection datasets, UNSW-NB15 and 5G-NIDD. For each self-supervised model, the combination of encoder architecture and augmentation method yielding the highest average precision, recall, F1-score, and AUCROC is reported. Furthermore, by comparing the best-performing models to two unsupervised baselines, DeepSVDD, and an Autoencoder, we showcase the competitiveness of the non-contrastive methods for attack detection. Code at: this https URL', 'abstract_zh': '网络入侵检测中的无监督学习方法比较：基于三种编码器架构和六种增强策略的性能分析', 'title_zh': '非对比自监督学习方法在网络入侵检测中的性能研究'}
{'arxiv_id': 'arXiv:2510.02348', 'title': 'mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations', 'authors': 'Guy Dar', 'link': 'https://arxiv.org/abs/2510.02348', 'abstract': "We build upon vec2vec, a procedure designed to align text embedding spaces without parallel data. vec2vec finds a near-perfect alignment, but it is expensive and unstable. We present mini-vec2vec, a simple and efficient alternative that requires substantially lower computational cost and is highly robust. Moreover, the learned mapping is a linear transformation. Our method consists of three main stages: a tentative matching of pseudo-parallel embedding vectors, transformation fitting, and iterative refinement. Our linear alternative exceeds the original instantiation of vec2vec by orders of magnitude in efficiency, while matching or exceeding their results. The method's stability and interpretable algorithmic steps facilitate scaling and unlock new opportunities for adoption in new domains and fields.", 'abstract_zh': '基于mini-vec2vec：一种简单高效的文本嵌入空间对齐方法及其应用', 'title_zh': 'mini-vec2vec: 通过线性变换扩展通用几何对齐規模'}
{'arxiv_id': 'arXiv:2510.02337', 'title': 'CRACQ: A Multi-Dimensional Approach To Automated Document Assessment', 'authors': 'Ishak Soltani, Francisco Belo, Bernardo Tavares', 'link': 'https://arxiv.org/abs/2510.02337', 'abstract': 'This paper presents CRACQ, a multi-dimensional evaluation framework tailored to evaluate documents across f i v e specific traits: Coherence, Rigor, Appropriateness, Completeness, and Quality. Building on insights from traitbased Automated Essay Scoring (AES), CRACQ expands its fo-cus beyond essays to encompass diverse forms of machine-generated text, providing a rubricdriven and interpretable methodology for automated evaluation. Unlike singlescore approaches, CRACQ integrates linguistic, semantic, and structural signals into a cumulative assessment, enabling both holistic and trait-level analysis. Trained on 500 synthetic grant pro-posals, CRACQ was benchmarked against an LLM-as-a-judge and further tested on both strong and weak real applications. Preliminary results in-dicate that CRACQ produces more stable and interpretable trait-level judgments than direct LLM evaluation, though challenges in reliability and domain scope remain', 'abstract_zh': 'This paper presents CRACQ，一种针对五种特定特质（连贯性、严谨性、适宜性、完整性、质量）评价文档的多维度评估框架。基于基于特质的机器作文评分（AES）的见解，CRACQ 的关注点不仅限于作文，还涵盖了各种形式的机器生成文本，提供了一种基于评分标准且具有可解释性的自动化评估方法。不同于单一评分方法，CRACQ 将语言、语义和结构信号整合到综合评估中，既能够进行整体分析又能进行特质层面的分析。CRACQ 基于500份合成的资助提案进行训练，并与基于LLM的评判进行了基准测试，进一步在强应用和弱应用上进行了测试。初步结果显示，CRACQ 在特质层面生成的判断比直接的LLM评估更加稳定且具有解释性，尽管在可靠性和领域范围方面仍存在挑战。', 'title_zh': 'CRACQ: 多维度的自动文档评估方法'}
{'arxiv_id': 'arXiv:2510.02336', 'title': 'KurdSTS: The Kurdish Semantic Textual Similarity', 'authors': 'Abdulhady Abas Abdullah, Hadi Veisi, Hussein M. Al', 'link': 'https://arxiv.org/abs/2510.02336', 'abstract': 'Semantic Textual Similarity (STS) measures the degree of meaning overlap between two texts and underpins many NLP tasks. While extensive resources exist for high-resource languages, low-resource languages such as Kurdish remain underserved. We present, to our knowledge, the first Kurdish STS dataset: 10,000 sentence pairs spanning formal and informal registers, each annotated for similarity. We benchmark Sentence-BERT, multilingual BERT, and other strong baselines, obtaining competitive results while highlighting challenges arising from Kurdish morphology, orthographic variation, and code-mixing. The dataset and baselines establish a reproducible evaluation suite and provide a strong starting point for future research on Kurdish semantics and low-resource NLP.', 'abstract_zh': '低资源语言库尔德语语义文本相似性数据集及其benchmark分析：面向库尔德语语义研究和低资源NLP的起点', 'title_zh': 'KurdSTS：库尔德语语义文本相似度'}
{'arxiv_id': 'arXiv:2510.02333', 'title': 'Human Mobility Datasets Enriched With Contextual and Social Dimensions', 'authors': 'Chiara Pugliese, Francesco Lettich, Guido Rocchietti, Chiara Renso, Fabio Pinelli', 'link': 'https://arxiv.org/abs/2510.02333', 'abstract': 'In this resource paper, we present two publicly available datasets of semantically enriched human trajectories, together with the pipeline to build them. The trajectories are publicly available GPS traces retrieved from OpenStreetMap. Each dataset includes contextual layers such as stops, moves, points of interest (POIs), inferred transportation modes, and weather data. A novel semantic feature is the inclusion of synthetic, realistic social media posts generated by Large Language Models (LLMs), enabling multimodal and semantic mobility analysis. The datasets are available in both tabular and Resource Description Framework (RDF) formats, supporting semantic reasoning and FAIR data practices. They cover two structurally distinct, large cities: Paris and New York. Our open source reproducible pipeline allows for dataset customization, while the datasets support research tasks such as behavior modeling, mobility prediction, knowledge graph construction, and LLM-based applications. To our knowledge, our resource is the first to combine real-world movement, structured semantic enrichment, LLM-generated text, and semantic web compatibility in a reusable framework.', 'abstract_zh': '本资源论文中，我们介绍了两个富含语义的个人轨迹公开数据集及其构建管道。这些轨迹来源于OpenStreetMap的公开GPS轨迹。每个数据集包含上下文层，如停留点、移动轨迹、兴趣点（POIs）、推断的交通模式以及天气数据。一种新颖的语义特征是通过大型语言模型（LLMs）生成的合成、真实的社交媒体帖子，支持多模态和语义移动性分析。数据集以表格形式和资源描述框架（RDF）格式提供，支持语义推理和FAIR数据实践。它们涵盖了两个结构上不同的大型城市：巴黎和纽约。我们开源的可再现管道允许数据集的定制，而数据集支持行为建模、移动性预测、知识图谱构建以及基于LLM的应用。据我们所知，这是第一个将真实世界移动性、结构化语义增强、LLM生成文本以及语义网兼容性整合在一个可重用框架中的资源。', 'title_zh': '富含上下文和社会维度的人类移动数据集'}
{'arxiv_id': 'arXiv:2510.02331', 'title': 'Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)', 'authors': 'Moonkyung Ryu, Chih-Wei Hsu, Yinlam Chow, Mohammad Ghavamzadeh, Craig Boutilier', 'link': 'https://arxiv.org/abs/2510.02331', 'abstract': "While language models (LMs) offer great potential for conversational recommender systems (CRSs), the paucity of public CRS data makes fine-tuning LMs for CRSs challenging. In response, LMs as user simulators qua data generators can be used to train LM-based CRSs, but often lack behavioral consistency, generating utterance sequences inconsistent with those of any real user. To address this, we develop a methodology for generating natural dialogues that are consistent with a user's underlying state using behavior simulators together with LM-prompting. We illustrate our approach by generating a large, open-source CRS data set with both preference elicitation and example critiquing. Rater evaluation on some of these dialogues shows them to exhibit considerable consistency, factuality and naturalness.", 'abstract_zh': '语言模型（LMs）为对话式推荐系统（CRSs）提供了巨大潜力，但由于缺乏公开的CRS数据，使LMs针对CRSs的微调具有挑战性。为应对这一挑战，可以将LMs作为数据生成器用于训练基于LM的CRSs，但它们往往缺乏行为一致性，生成的对话序列与任何真实用户的行为不符。为解决这一问题，我们开发了一种方法，利用行为模拟器与LM提示生成与用户潜在状态一致的自然对话。我们通过生成包含偏好 elicitation 和示例批评的大规模开源CRS数据集来说明我们的方法。对部分对话的评估显示，它们表现出相当高的一致性和自然性。', 'title_zh': '合成对话生成用于交互式会话引发与推荐（ICER）'}
{'arxiv_id': 'arXiv:2509.21923', 'title': 'Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects', 'authors': 'Fumin Wang', 'link': 'https://arxiv.org/abs/2509.21923', 'abstract': 'Interpretability is one of the considerations when applying machine learning to high-stakes fields such as healthcare that involve matters of life safety. Generalized Additive Models (GAMs) enhance interpretability by visualizing shape functions. Nevertheless, to preserve interpretability, GAMs omit higher-order interaction effects (beyond pairwise interactions), which imposes significant constraints on their predictive performance. We observe that Curve Ergodic Set Regression (CESR), a multiplicative model, naturally enables the visualization of its shape functions and simultaneously incorporates both interactions among all features and individual feature effects. Nevertheless, CESR fails to demonstrate superior performance compared to GAMs. We introduce Multiplicative-Additive Constrained Models (MACMs), which augment CESR with an additive part to disentangle the intertwined coefficients of its interactive and independent terms, thus effectively broadening the hypothesis space. The model is composed of a multiplicative part and an additive part, whose shape functions can both be naturally visualized, thereby assisting users in interpreting how features participate in the decision-making process. Consequently, MACMs constitute an improvement over both CESR and GAMs. The experimental results indicate that neural network-based MACMs significantly outperform both CESR and the current state-of-the-art GAMs in terms of predictive performance.', 'abstract_zh': '在涉及生命安全的高风险领域如医疗健康中应用机器学习时，可解释性是重要的考虑因素。广义加性模型（GAMs）通过可视化形函数来增强可解释性。然而，为保持可解释性，GAMs会忽略高于二阶的交互效应，这对预测性能造成了显著限制。我们观察到，曲线遍历集回归（CESR），作为一种乘法模型，自然能够可视化其形函数，并同时结合所有特征间的交互效应及单个特征效应。然而，CESR在性能上未能优于GAMs。我们提出了乘性-加性约束模型（MACMs），其在CESR的基础上增加了一个加性部分，以解开交互项和独立项纠缠的系数，从而有效扩展假设空间。该模型由乘性部分和加性部分组成，其形函数均可自然可视化，有助于用户理解特征在决策过程中的作用。因此，MACMs在CESR和GAMs之上构成改进。实验结果表明，基于神经网络的MACMs在预测性能方面显著优于CESR和当前最先进的GAMs。', 'title_zh': '乘法-加法约束模型：面向交互效应和独立效应联合可视化'}
