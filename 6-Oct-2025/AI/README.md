# Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner 

**Title (ZH)**: 共进化连续离散扩散：使你的扩散语言模型成为潜在推理器 

**Authors**: Cai Zhou, Chenxiao Yang, Yi Hu, Chenyu Wang, Chubin Zhang, Muhan Zhang, Lester Mackey, Tommi Jaakkola, Stephen Bates, Dinghuai Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.03206)  

**Abstract**: Diffusion language models, especially masked discrete diffusion models, have achieved great success recently. While there are some theoretical and primary empirical results showing the advantages of latent reasoning with looped transformers or continuous chain-of-thoughts, continuous diffusion models typically underperform their discrete counterparts. In this paper, we argue that diffusion language models do not necessarily need to be in the discrete space. In particular, we prove that continuous diffusion models have stronger expressivity than discrete diffusions and looped transformers. We attribute the contradiction between the theoretical expressiveness and empirical performance to their practical trainability: while continuous diffusion provides intermediate supervision that looped transformers lack, they introduce additional difficulty decoding tokens into the discrete token space from the continuous representation space. We therefore propose Coevolutionary Continuous Discrete Diffusion (CCDD), which defines a joint multimodal diffusion process on the union of a continuous representation space and a discrete token space, leveraging a single model to simultaneously denoise in the joint space. By combining two modalities, CCDD is expressive with rich semantics in the latent space, as well as good trainability and sample quality with the help of explicit discrete tokens. We also propose effective architectures and advanced training/sampling techniques for CCDD, which reveals strong empirical performance in extensive language modeling experiments on real-world tasks. 

**Abstract (ZH)**: 连续与离散扩散语言模型：Coevolutionary Continuous Discrete Diffusion（CCDD） 

---
# CoDA: Agentic Systems for Collaborative Data Visualization 

**Title (ZH)**: CoDA: 为协作数据可视化设计的自主系统 

**Authors**: Zichen Chen, Jiefeng Chen, Sercan Ö. Arik, Misha Sra, Tomas Pfister, Jinsung Yoon  

**Link**: [PDF](https://arxiv.org/pdf/2510.03194)  

**Abstract**: Deep research has revolutionized data analysis, yet data scientists still devote substantial time to manually crafting visualizations, highlighting the need for robust automation from natural language queries. However, current systems struggle with complex datasets containing multiple files and iterative refinement. Existing approaches, including simple single- or multi-agent systems, often oversimplify the task, focusing on initial query parsing while failing to robustly manage data complexity, code errors, or final visualization quality. In this paper, we reframe this challenge as a collaborative multi-agent problem. We introduce CoDA, a multi-agent system that employs specialized LLM agents for metadata analysis, task planning, code generation, and self-reflection. We formalize this pipeline, demonstrating how metadata-focused analysis bypasses token limits and quality-driven refinement ensures robustness. Extensive evaluations show CoDA achieves substantial gains in the overall score, outperforming competitive baselines by up to 41.5%. This work demonstrates that the future of visualization automation lies not in isolated code generation but in integrated, collaborative agentic workflows. 

**Abstract (ZH)**: 深度研究已革新了数据分析，但仍需要大量时间由数据科学家手动构建可视化，这突显了从自然语言查询实现稳健自动化的重要性。然而，当前系统在处理包含多个文件的复杂数据集和迭代优化时仍显不足。现有方法，包括简单的单智能体或多功能智能体系统，往往简化问题，侧重于初始查询解析，而在管理数据复杂性、代码错误或最终可视化质量方面不具备鲁棒性。在本文中，我们将这一挑战重新定义为协作多智能体问题。我们引入了CoDA，一个采用专门LLM智能体进行元数据分析、任务规划、代码生成和自我反思的多智能体系统。我们形式化了这一流程，证明了以元数据为中心的分析可以绕过令牌限制，而质量驱动的优化保证了系统的稳健性。广泛的评估显示，CoDA在总体评分上取得了显著提升，优于竞争基线高达41.5%。这项工作证明了可视化自动化的未来在于集成、协作的代理工作流，而非孤立的代码生成。 

---
# Improving Cooperation in Collaborative Embodied AI 

**Title (ZH)**: 提高协作机器人人工智能中的合作效率 

**Authors**: Hima Jacob Leven Suprabha, Laxmi Nag Laxminarayan Nagesh, Ajith Nair, Alvin Reuben Amal Selvaster, Ayan Khan, Raghuram Damarla, Sanju Hannah Samuel, Sreenithi Saravana Perumal, Titouan Puech, Venkataramireddy Marella, Vishal Sonar, Alessandro Suglia, Oliver Lemon  

**Link**: [PDF](https://arxiv.org/pdf/2510.03153)  

**Abstract**: The integration of Large Language Models (LLMs) into multiagent systems has opened new possibilities for collaborative reasoning and cooperation with AI agents. This paper explores different prompting methods and evaluates their effectiveness in enhancing agent collaborative behaviour and decision-making. We enhance CoELA, a framework designed for building Collaborative Embodied Agents that leverage LLMs for multi-agent communication, reasoning, and task coordination in shared virtual spaces. Through systematic experimentation, we examine different LLMs and prompt engineering strategies to identify optimised combinations that maximise collaboration performance. Furthermore, we extend our research by integrating speech capabilities, enabling seamless collaborative voice-based interactions. Our findings highlight the effectiveness of prompt optimisation in enhancing collaborative agent performance; for example, our best combination improved the efficiency of the system running with Gemma3 by 22% compared to the original CoELA system. In addition, the speech integration provides a more engaging user interface for iterative system development and demonstrations. 

**Abstract (ZH)**: 大型语言模型（LLMs）集成到多智能体系统中为与AI代理协作的推理和合作开辟了新可能性。本文探讨了不同的提示方法，并评估了它们在增强智能体协作行为和决策制定方面的有效性。我们改进了CoELA框架，该框架利用LLMs在共享虚拟空间中的多智能体通信、推理和任务协调。通过系统的实验，我们研究了不同的LLMs和提示工程策略，以确定能够最大化协作性能的最佳组合。此外，我们通过集成语音能力，实现了无缝的协作语音交互。我们的研究发现表明，提示优化在增强协作智能体性能方面非常有效；例如，我们最佳的组合将使用Gemma3运行的系统效率提高了22%，比原始CoELA系统提高了效率。此外，语音集成还为迭代系统开发和演示提供了更吸引人的用户界面。 

---
# A Study of Rule Omission in Raven's Progressive Matrices 

**Title (ZH)**: 关于 Ravens 进步矩阵中规则省略的研究 

**Authors**: Binze Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.03127)  

**Abstract**: Analogical reasoning lies at the core of human cognition and remains a fundamental challenge for artificial intelligence. Raven's Progressive Matrices (RPM) serve as a widely used benchmark to assess abstract reasoning by requiring the inference of underlying structural rules. While many vision-based and language-based models have achieved success on RPM tasks, it remains unclear whether their performance reflects genuine reasoning ability or reliance on statistical shortcuts. This study investigates the generalization capacity of modern AI systems under conditions of incomplete training by deliberately omitting several structural rules during training. Both sequence-to-sequence transformer models and vision-based architectures such as CoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN (I-RAVEN) dataset. Experiments reveal that although transformers demonstrate strong performance on familiar rules, their accuracy declines sharply when faced with novel or omitted rules. Moreover, the gap between token-level accuracy and complete answer accuracy highlights fundamental limitations in current approaches. These findings provide new insights into the reasoning mechanisms underlying deep learning models and underscore the need for architectures that move beyond pattern recognition toward robust abstract reasoning. 

**Abstract (ZH)**: 类比推理是人类认知的核心，也是人工智能的基本挑战。雷文 progressives 图阵（RPM）常被用作评估抽象推理能力的标准，要求推断出潜在的结构规则。虽然许多基于视觉和语言的模型在RPM任务中取得了成功，但尚不清楚其性能是否反映了真实的推理能力，还是依赖于统计捷径。本研究在训练数据不完整的情况下考察现代AI系统的泛化能力，故意在训练过程中省略了几条结构规则。序列到序列的变换器模型和基于视觉的架构，如CoPINet和双对比网络，在Impartial-RAVEN（I-RAVEN）数据集上进行评估。实验表明，尽管变换器在熟悉规则上表现出强劲的性能，但在面对新颖或被省略的规则时，准确性会急剧下降。此外，token级准确率与完整答案准确率之间的差距进一步突显了当前方法的基本局限性。这些发现为深入学习模型的推理机制提供了新的见解，并强调了需要超越模式识别向着稳健的抽象推理迈进的架构的需求。 

---
# From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments 

**Title (ZH)**: 从事实到反事实：设计与评估智能环境中的反事实解释 

**Authors**: Anna Trapp, Mersedeh Sadeghi, Andreas Vogelsang  

**Link**: [PDF](https://arxiv.org/pdf/2510.03078)  

**Abstract**: Explainability is increasingly seen as an essential feature of rule-based smart environments. While counterfactual explanations, which describe what could have been done differently to achieve a desired outcome, are a powerful tool in eXplainable AI (XAI), no established methods exist for generating them in these rule-based domains. In this paper, we present the first formalization and implementation of counterfactual explanations tailored to this domain. It is implemented as a plugin that extends an existing explanation engine for smart environments. We conducted a user study (N=17) to evaluate our generated counterfactuals against traditional causal explanations. The results show that user preference is highly contextual: causal explanations are favored for their linguistic simplicity and in time-pressured situations, while counterfactuals are preferred for their actionable content, particularly when a user wants to resolve a problem. Our work contributes a practical framework for a new type of explanation in smart environments and provides empirical evidence to guide the choice of when each explanation type is most effective. 

**Abstract (ZH)**: 基于规则的智能环境中可解释性的增强：counterfactual解释的正式化与实现 

---
# Onto-Epistemological Analysis of AI Explanations 

**Title (ZH)**: AI解释的本体 epistemological 分析 

**Authors**: Martina Mattioli, Eike Petersen, Aasa Feragen, Marcello Pelillo, Siavash A. Bigdeli  

**Link**: [PDF](https://arxiv.org/pdf/2510.02996)  

**Abstract**: Artificial intelligence (AI) is being applied in almost every field. At the same time, the currently dominant deep learning methods are fundamentally black-box systems that lack explanations for their inferences, significantly limiting their trustworthiness and adoption. Explainable AI (XAI) methods aim to overcome this challenge by providing explanations of the models' decision process. Such methods are often proposed and developed by engineers and scientists with a predominantly technical background and incorporate their assumptions about the existence, validity, and explanatory utility of different conceivable explanatory mechanisms. However, the basic concept of an explanation -- what it is, whether we can know it, whether it is absolute or relative -- is far from trivial and has been the subject of deep philosophical debate for millennia. As we point out here, the assumptions incorporated into different XAI methods are not harmless and have important consequences for the validity and interpretation of AI explanations in different domains. We investigate ontological and epistemological assumptions in explainability methods when they are applied to AI systems, meaning the assumptions we make about the existence of explanations and our ability to gain knowledge about those explanations. Our analysis shows how seemingly small technical changes to an XAI method may correspond to important differences in the underlying assumptions about explanations. We furthermore highlight the risks of ignoring the underlying onto-epistemological paradigm when choosing an XAI method for a given application, and we discuss how to select and adapt appropriate XAI methods for different domains of application. 

**Abstract (ZH)**: 人工 Intelligence (AI) 已几乎应用于所有领域。与此同时，当前主导的深度学习方法本质上是黑箱系统，缺乏对其推断过程的解释，严重限制了其可信度和应用。可解释的人工智能 (XAI) 方法旨在通过提供模型决策过程的解释来克服这一挑战。这类方法通常由具有主要技术背景的工程师和科学家提出，并结合了他们关于不同可设想的解释机制的存在、有效性及其解释用途的假设。然而，解释的基本概念——它是什么、我们能否知道它、它是绝对的还是相对的——远非不言自明，并且自古以来一直是深刻的哲学辩论的主题。如我们所指出的，不同 XAI 方法中的假设并非无害，对不同领域的 AI 解释的有效性和解释具有重要影响。我们在将可解释性方法应用于 AI 系统时对其本体论和认识论假设进行了分析，这意味着我们对解释的存在以及获取这些解释知识所做的假设。我们的分析表明，对 XAI 方法进行看似微小的技术更改可能对应于解释底层假设的重要差异。此外，我们强调了在选择适用于特定应用的 XAI 方法时忽略本体论与认识论范式的风险，并讨论了如何为不同应用领域选择和适应合适的 XAI 方法。 

---
# Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models 

**Title (ZH)**: Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models

合并强化学习以优化多模态离散扩散模型 

**Authors**: Tianren Ma, Mu Zhang, Yibing Wang, Qixiang Ye  

**Link**: [PDF](https://arxiv.org/pdf/2510.02880)  

**Abstract**: Optimizing discrete diffusion model (DDM) with rewards remains a challenge: the non-autoregressive paradigm makes importance sampling intractable and rollout complex, puzzling reinforcement learning methods such as Group Relative Policy Optimization (GRPO). In this study, we introduce MaskGRPO, the first viable approach to enable scalable multimodal reinforcement learning in discrete diffusion with effective importance sampling and modality-specific adaptations. To this end, we first clarify the theoretical foundation for DDMs, which facilitates building an importance estimator that captures valuable token fluctuation for gradient updates. We then delicately tailored the rollout method for visual sequences, which yields diverse completions and reliable optimization gradients. Upon math reasoning, coding, and visual generation benchmarks, MaskGRPO brings more stable and efficient updates, leading to stronger reasoning performance and better generation quality. This study establishes MaskGRPO as a systematic policy optimization approach and the first practical way for discretized visual diffusion. 

**Abstract (ZH)**: 优化离散扩散模型（DDM）中的奖励仍具挑战性：无自回归范式使重要性采样不可行且生成过程复杂，困扰了如Group Relative Policy Optimization (GRPO)等强化学习方法。本文引入MaskGRPO，这是第一个能够在离散扩散中实现可扩展的多模态强化学习的有效重要性采样和模态特定适应的方法。为此，我们首先阐明了DDMs的理论基础，从而有助于构建能够捕捉有价值token波动的重要性估计器，以进行梯度更新。随后，我们精心调整了视觉序列的生成方法，生成了多样化的完成和可信赖的优化梯度。在数学推理、编码和视觉生成基准测试中，MaskGRPO带来了更稳定和高效的更新，提高了推理性能并提高了生成质量。本研究确立了MaskGRPO作为系统性的策略优化方法，并且是第一个用于离散视觉扩散的实际途径。 

---
# Reward Model Routing in Alignment 

**Title (ZH)**: 对齐中的奖励模型路由 

**Authors**: Xinle Wu, Yao Lu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02850)  

**Abstract**: Reinforcement learning from human or AI feedback (RLHF / RLAIF) has become the standard paradigm for aligning large language models (LLMs). However, most pipelines rely on a single reward model (RM), limiting alignment quality and risking overfitting. Recent work explores RM routing--dynamically selecting an RM from a candidate pool to exploit complementary strengths while maintaining $O(1)$ RM calls--but existing methods suffer from cold-start and insufficient exploration. We propose BayesianRouter, a hybrid routing framework that combines offline RM strengths learning with online Bayesian selection. In the offline stage, a multi-task router is trained on preference data to estimate per-RM reliability. In the online stage, a Bayesian Thompson sampling router performs per-query RM selection, initializing RM-specific weight vectors with offline embeddings as Gaussian priors and adaptively updating their posteriors with online rewards to adapt to the evolving policy distribution. Extensive experiments on instruction-following (AlpacaEval-2, Arena-Hard, MT-Bench) and reasoning (GSM8K, MMLU) benchmarks show that BayesianRouter consistently outperforms individual RMs, RM ensembling, and existing routing methods. 

**Abstract (ZH)**: 基于人类或AI反馈的强化学习（RLHF/RLAIF）已成为对大语言模型（LLMs）进行对齐的标准范式。然而，大多数流程依赖于单一的奖励模型（RM），限制了对齐质量并存在过拟合风险。近期工作探索了RM路由——动态从候选池中选择RM以利用互补优势同时保持$O(1)$的RM调用次数，但现有方法存在冷启动和探索不足的问题。我们提出BayesianRouter，这是一种结合离线RM优势学习与在线贝叶斯选择的混合路由框架。在离线阶段，一个多任务路由器在偏好数据上进行训练以估计每种RM的可靠性。在在线阶段，一个贝叶斯Thompson抽样路由器执行每查询的RM选择，使用离线嵌入作为高斯先验初始化RM特异性权重向量，并根据在线奖励自适应更新后验以适应政策分布的变化。广泛的实验结果表明，BayesianRouter在指令遵循（AlpacaEval-2、Arena-Hard、MT-Bench）和推理（GSM8K、MMLU）基准测试中均优于单一RM、RM集成及现有路由方法。 

---
# Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization 

**Title (ZH)**: 认真对待古德哈特法则：通用人工智能优化的基本限制 

**Authors**: Antoine Maier, Aude Maier, Tom David  

**Link**: [PDF](https://arxiv.org/pdf/2510.02840)  

**Abstract**: A common but rarely examined assumption in machine learning is that training yields models that actually satisfy their specified objective function. We call this the Objective Satisfaction Assumption (OSA). Although deviations from OSA are acknowledged, their implications are overlooked. We argue, in a learning-paradigm-agnostic framework, that OSA fails in realistic conditions: approximation, estimation, and optimization errors guarantee systematic deviations from the intended objective, regardless of the quality of its specification. Beyond these technical limitations, perfectly capturing and translating the developer's intent, such as alignment with human preferences, into a formal objective is practically impossible, making misspecification inevitable. Building on recent mathematical results, absent a mathematical characterization of these gaps, they are indistinguishable from those that collapse into Goodhart's law failure modes under strong optimization pressure. Because the Goodhart breaking point cannot be located ex ante, a principled limit on the optimization of General-Purpose AI systems is necessary. Absent such a limit, continued optimization is liable to push systems into predictable and irreversible loss of control. 

**Abstract (ZH)**: 机器学习中的一个常见但鲜少检验的假设是训练会产生实际满足其指定目标函数的模型。我们称之为目标满足假设（OSA）。尽管OSA的偏差被承认，但其影响却被忽视。我们从一个学习范式无关的框架出发，论证在现实条件下OSA会失效：约化误差、估计误差和优化误差保证了系统会系统地偏离预期目标，不论其规定质量如何。除了这些技术限制，将开发者的意图，如与人类偏好的一致性，完美地捕捉并形式化为一个目标在实践中是不可能的，因此错配不可避免。基于近期数学成果，缺乏这些差距的数学刻画，它们在强烈的优化压力下会不可区分地变成Goodhart定律失效模式。由于Goodhart breaking点无法在事前确定，对通用人工智能系统的优化必须有原则性的限制。否则，持续的优化可能会将系统推向可预测且不可逆的失控状态。 

---
# Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents 

**Title (ZH)**: 超越最终答案：评估工具增强代理的推理轨迹 

**Authors**: Wonjoong Kim, Sangwu Park, Yeonjun In, Sein Kim, Dongha Lee, Chanyoung Park  

**Link**: [PDF](https://arxiv.org/pdf/2510.02837)  

**Abstract**: Although recent tool-augmented benchmarks incorporate complex user requests and diverse tools, the evaluation methods for most of them remain limited to answer matching. However, as the number of steps required to resolve a user request increases, a proper evaluation of an agent's performance must go beyond the final answer to also assess the problem-solving trajectory, including previously ignored aspects such as efficiency, hallucination, and adaptivity. The most straightforward method for evaluating these aspects is to compare an agent's trajectory with the ground-truth trajectory, but this approach is fundamentally limited since annotating all valid ground-truth trajectories is prohibitively expensive. However, a simple LLM-based evaluator struggles to assess trajectories in detail without ground truth. To effectively evaluate the agents in this manner, we introduce TRACE, a framework for the multi-dimensional evaluation of tool-augmented LLM agent performance. By incorporating an evidence bank, which accumulates knowledge gathered from preceding reasoning steps, TRACE enables a multi-faceted analysis and evaluation of an agent's reasoning trajectory effectively. To validate our framework, we develop a new meta-evaluation dataset by augmenting existing benchmarks with diverse and flawed trajectories, each labeled with multi-faceted performance scores. Our results confirm that TRACE accurately evaluates these complex behaviors in a scalable and cost-effective manner, even with small open-source LLMs. Furthermore, we apply our method to evaluate the trajectories that agents produce while solving tool-augmented tasks, presenting previously unreported observations and their corresponding insights. 

**Abstract (ZH)**: 尽管近期工具增强的基准测试已包含复杂的用户请求和多样的工具，大多数评价方法仍然局限于答案匹配。然而，当解决用户请求所需的步骤增加时，对智能体性能的恰当评价必须超越最终答案，还应评估问题解决过程，包括以前忽略的效率、幻觉和适应性等方面。最直接的评估方法是将智能体的轨迹与真实轨迹进行比较，但这种方法基本受限于标注所有有效真实轨迹的高昂成本。然而，基于简单LLM的评价器难以在没有真实轨迹的情况下详细评估轨迹。为了有效评估智能体，我们提出了TRACE框架，用于多维度评价工具增强的LLM智能体性能。通过整合证据库，TRACE能够有效地对智能体的推理轨迹进行多方面分析和评价。为了验证我们的框架，我们通过在现有基准测试中增加多样且有缺陷的轨迹来构建了一个新的元评价数据集，并为每个轨迹标注了多方面的性能评分。结果显示，TRACE能够以可扩展且低成本的方式准确评价这些复杂行为，即使使用小型开源LLM也是如此。此外，我们还应用这种方法来评估智能体在解决工具增强任务时产生的轨迹，揭示了一些前所未见的观察结果及其相应的见解。 

---
# NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning 

**Title (ZH)**: NCV：一种节点级一致性验证方法，用于低成低成本结构化错误定位在大模型推理中的局部化 

**Authors**: Yulong Zhang, Li Wang, Wei Du, Peilin Li, Yuqin Dai Zhiyuan Zhao, Lingyong Fang, Ziniu Liu, Ru Zhang, Huijia Zhu, Gongshen Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02816)  

**Abstract**: Verifying multi-step reasoning in large language models is difficult due to imprecise error localization and high token costs. Existing methods either assess entire reasoning chains, suffering attention dilution, or rely on expensive multi-sampling. We introduce Node-wise Consistency Verification (NCV), a training-free framework that recasts verification as lightweight binary consistency checks at the node level. By decomposing the chain of thought into interconnected verification nodes, NCV precisely localizes errors and avoids unnecessary long-form generation. Experiments demonstrate that our approach enhances interpretability and efficiency, presenting a scalable solution for reliable LLM reasoning verification. On public datasets, NCV achieves a 10\% to 25\% improvement in F1 scores over baselines while utilizing $6\times$~$58\times$ fewer tokens than traditional methods like CoT-based verifiers. 

**Abstract (ZH)**: 在大规模语言模型中验证多步推理由于精确错误定位不精确和高 tokens 成本而困难。现有的方法要么评估整个推理链，遭受注意力稀释，要么依赖昂贵的多采样。我们引入基于节点的一致性验证（NCV），这是一种无需训练的框架，重新定义验证为节点级别的轻量级二元一致性检查。通过将推理链分解为相互连接的验证节点，NCV 准确定位错误并避免不必要的长形式生成。实验表明，我们的方法增强了可解释性和效率，提供了一种可扩展的可靠的大规模语言模型推理验证解决方案。在公共数据集中，NCV 在 F1 分数上比基准方法提高 10% 至 25%，且使用的 tokens 数量仅为传统方法（如基于 CoT 的验证器）的六分之一到五十八分之一。 

---
# Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation 

**Title (ZH)**: 基于领域特定表示调节生成模型的作业调度自动约束规范方法 

**Authors**: Yu-Zhe Shi, Qiao Xu, Yanjia Li, Mingchen Liu, Huamin Qu, Lecheng Ruan, Qining Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02679)  

**Abstract**: Advanced Planning and Scheduling (APS) systems have become indispensable for modern manufacturing operations, enabling optimized resource allocation and production efficiency in increasingly complex and dynamic environments. While algorithms for solving abstracted scheduling problems have been extensively investigated, the critical prerequisite of specifying manufacturing requirements into formal constraints remains manual and labor-intensive. Although recent advances of generative models, particularly Large Language Models (LLMs), show promise in automating constraint specification from heterogeneous raw manufacturing data, their direct application faces challenges due to natural language ambiguity, non-deterministic outputs, and limited domain-specific knowledge. This paper presents a constraint-centric architecture that regulates LLMs to perform reliable automated constraint specification for production scheduling. The architecture defines a hierarchical structural space organized across three levels, implemented through domain-specific representation to ensure precision and reliability while maintaining flexibility. Furthermore, an automated production scenario adaptation algorithm is designed and deployed to efficiently customize the architecture for specific manufacturing configurations. Experimental results demonstrate that the proposed approach successfully balances the generative capabilities of LLMs with the reliability requirements of manufacturing systems, significantly outperforming pure LLM-based approaches in constraint specification tasks. 

**Abstract (ZH)**: 基于约束的大型语言模型导向的生产调度自动约束规范架构 

---
# ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks 

**Title (ZH)**: ARMs：针对多模态模型的自适应红队代理及插件式攻击方法 

**Authors**: Zhaorun Chen, Xun Liu, Mintong Kang, Jiawei Zhang, Minzhou Pan, Shuang Yang, Bo Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.02677)  

**Abstract**: As vision-language models (VLMs) gain prominence, their multimodal interfaces also introduce new safety vulnerabilities, making the safety evaluation challenging and critical. Existing red-teaming efforts are either restricted to a narrow set of adversarial patterns or depend heavily on manual engineering, lacking scalable exploration of emerging real-world VLM vulnerabilities. To bridge this gap, we propose ARMs, an adaptive red-teaming agent that systematically conducts comprehensive risk assessments for VLMs. Given a target harmful behavior or risk definition, ARMs automatically optimizes diverse red-teaming strategies with reasoning-enhanced multi-step orchestration, to effectively elicit harmful outputs from target VLMs. We propose 11 novel multimodal attack strategies, covering diverse adversarial patterns of VLMs (e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming algorithms into ARMs via model context protocol (MCP). To balance the diversity and effectiveness of the attack, we design a layered memory with an epsilon-greedy attack exploration algorithm. Extensive experiments on instance- and policy-based benchmarks show that ARMs achieves SOTA attack success rates, exceeding baselines by an average of 52.1% and surpassing 90% on Claude-4-Sonnet. We show that the diversity of red-teaming instances generated by ARMs is significantly higher, revealing emerging vulnerabilities in VLMs. Leveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety dataset comprising over 30K red-teaming instances spanning 51 diverse risk categories, grounded in both real-world multimodal threats and regulatory risks. Safety fine-tuning with ARMs-Bench substantially improves the robustness of VLMs while preserving their general utility, providing actionable guidance to improve multimodal safety alignment against emerging threats. 

**Abstract (ZH)**: 随着视觉语言模型（VLMs）的重要性日益增加，其多模态接口也引入了新的安全漏洞，使得安全评估变得极具挑战性和关键性。现有的红队努力要么局限于狭窄的 adversarial 模式集合，要么高度依赖手动工程，缺乏对新兴实际世界 VLM 漏洞的大规模探索。为弥补这一差距，我们提出了一种自适应红队代理 ARMs，它系统地对 VLMs 进行全面的风险评估。给定一个目标有害行为或风险定义，ARMs 自动优化多种增强推理的多层次 orchestration 红队策略，以有效地从目标 VLMs 中引发有害输出。我们提出了 11 种新颖的多模态攻击策略，涵盖了 VLMs 的多种 adversarial 模式（例如推理劫持、上下文隐形），并通过模型上下文协议（MCP）将 17 种红队算法集成到 ARMs 中。为了平衡攻击的多样性和有效性，我们设计了一层记忆以及一个epsilon-贪心攻击探索算法。在基于实例和策略的基准测试中，大量的实验证明 ARM 实现了最先进的攻击成功率，平均超过基线 52.1%，在 Claude-4-Sonnet 上超过 90%。我们展示了 ARMs 生成的红队实例多样性显著更高，揭示了 VLMs 中新兴的漏洞。利用 ARM 构建 ARMs-Bench，这是一个包含超过 30,000 个红队实例的大规模多模态安全数据集，涵盖了 51 种不同风险类别，基于现实世界的多模态威胁和监管风险。通过使用 ARMs-Bench 进行安全性微调，VLMs 的鲁棒性显著提高，同时保持其通用功能，提供对抗新兴威胁改进多模态安全对准的实际指导。 

---
# AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models 

**Title (ZH)**: AutoMaAS: 自适应多Agent架构搜索用于大型语言模型 

**Authors**: Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02669)  

**Abstract**: Multi-agent systems powered by large language models have demonstrated remarkable capabilities across diverse domains, yet existing automated design approaches seek monolithic solutions that fail to adapt resource allocation based on query complexity and domain requirements. This paper introduces AutoMaAS, a self-evolving multi-agent architecture search framework that leverages neural architecture search principles to automatically discover optimal agent configurations through dynamic operator lifecycle management and automated machine learning techniques. Our approach incorporates four key innovations: (1) automatic operator generation, fusion, and elimination based on performance-cost analysis, (2) dynamic cost-aware optimization with real-time parameter adjustment, (3) online feedback integration for continuous architecture refinement, and (4) enhanced interpretability through decision tracing mechanisms. Extensive experiments across six benchmarks demonstrate that AutoMaAS achieves 1.0-7.1\% performance improvement while reducing inference costs by 3-5\% compared to state-of-the-art methods. The framework shows superior transferability across datasets and LLM backbones, establishing a new paradigm for automated multi-agent system design in the era of large language models. 

**Abstract (ZH)**: 基于大型语言模型的多智能体系统自进化多智能体架构搜索框架 

---
# A Concept of Possibility for Real-World Events 

**Title (ZH)**: 一种关于现实事件的可能性概念 

**Authors**: Daniel G. Schwartz  

**Link**: [PDF](https://arxiv.org/pdf/2510.02655)  

**Abstract**: This paper offers a new concept of {\it possibility} as an alternative to the now-a-days standard concept originally introduced by L.A. Zadeh in 1978. This new version was inspired by the original but, formally, has nothing in common with it other than that they both adopt the Łukasiewicz multivalent interpretation of the logical connectives. Moreover, rather than seeking to provide a general notion of possibility, this focuses specifically on the possibility of a real-world event. An event is viewed as having prerequisites that enable its occurrence and constraints that may impede its occurrence, and the possibility of the event is computed as a function of the probabilities that the prerequisites hold and the constraints do not. This version of possibility might appropriately be applied to problems of planning. When there are multiple plans available for achieving a goal, this theory can be used to determine which plan is most possible, i.e., easiest or most feasible to complete. It is speculated that this model of reasoning correctly captures normal human reasoning about plans. The theory is elaborated and an illustrative example for vehicle route planning is provided. There is also a suggestion of potential future applications. 

**Abstract (ZH)**: 本文提出了一种新的可能性概念，作为替代如今标准概念的选项，该标准概念最初由L.A. Zadeh在1978年引入。这一新版本受到原概念的启发，但在形式上与之没有其他共同之处，二者均采用Łukasiewicz多值逻辑运算的解释。此外，本文并未寻求提供一个一般性的可能性概念，而是专注于具体事件的可能性。事件被视为在其发生需要满足先决条件并且可能存在阻碍条件的情境下发生的，事件的可能性是先决条件成立和阻碍条件不成立的概率函数。这一可能性概念适合作为规划问题的应用。当有多种计划可用于实现目标时，可以使用该理论来确定哪个计划最有可能，即最容易或最可行完成。推测这种推理模型正确捕捉了正常的关于计划的人类推理。本文对这一理论进行了详细阐述，并提供了车辆路线规划的示例说明。此外，还建议了潜在的未来应用。 

---
# Geolog-IA: Conversational System for Academic Theses 

**Title (ZH)**: Geolog-IA：学术学位论文对话系统 

**Authors**: Micaela Fuel Pozo, Andrea Guatumillo Saltos, Yeseña Tipan Llumiquinga, Kelly Lascano Aguirre, Marilyn Castillo Jara, Christian Mejia-Escobar  

**Link**: [PDF](https://arxiv.org/pdf/2510.02653)  

**Abstract**: This study presents the development of Geolog-IA, a novel conversational system based on artificial intelligence that responds naturally to questions about geology theses from the Central University of Ecuador. Our proposal uses the Llama 3.1 and Gemini 2.5 language models, which are complemented by a Retrieval Augmented Generation (RAG) architecture and an SQLite database. This strategy allows us to overcome problems such as hallucinations and outdated knowledge. The evaluation of Geolog-IA's performance with the BLEU metric reaches an average of 0.87, indicating high consistency and accuracy in the responses generated. The system offers an intuitive, web-based interface that facilitates interaction and information retrieval for directors, teachers, students, and administrative staff at the institution. This tool can be a key support in education, training, and research and establishes a basis for future applications in other disciplines. 

**Abstract (ZH)**: 本研究介绍了基于人工智能的新型对话系统Geolog-IA，该系统能够自然地回答厄瓜多尔中央大学地质论文的相关问题。我们的提议使用了Llama 3.1和Gemini 2.5语言模型，并通过检索增强生成（RAG）架构和SQLite数据库加以补充。这种策略有助于解决幻觉和过时知识等问题。Geolog-IA 的性能评价使用BLEU指标达到平均0.87，表明其生成的回答具有高度一致性和准确性。该系统提供了一个直观的基于Web的界面，便于师生员工在机构中进行互动和信息检索。该工具可以成为教育、培训和研究的关键支持，并为其他学科未来应用奠定基础。 

---
# On the Role of Temperature Sampling in Test-Time Scaling 

**Title (ZH)**: 温度采样在测试时缩放中的作用 

**Authors**: Yuheng Wu, Azalia Mirhoseini, Thierry Tambe  

**Link**: [PDF](https://arxiv.org/pdf/2510.02611)  

**Abstract**: Large language models (LLMs) can improve reasoning at inference time through test-time scaling (TTS), where multiple reasoning traces are generated and the best one is selected. Prior work shows that increasing the number of samples K steadily improves accuracy. In this paper, we demonstrate that this trend does not hold indefinitely: at large K, further scaling yields no gains, and certain hard questions remain unsolved regardless of the number of traces. Interestingly, we find that different sampling temperatures solve different subsets of problems, implying that single-temperature scaling explores only part of a model's potential. We therefore propose scaling along the temperature dimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3 (0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an additional 7.3 points over single-temperature TTS. Temperature scaling also enables base models to reach performance comparable to reinforcement learning (RL)-trained counterparts, without additional post-training. We further provide a comprehensive analysis of this phenomenon and design a multi-temperature voting method that reduces the overhead of temperature scaling. Overall, our findings suggest that TTS is more powerful than previously thought, and that temperature scaling offers a simple and effective way to unlock the latent potential of base models. 

**Abstract (ZH)**: 大型语言模型（LLMs）通过测试时缩放（TTS）在推理时可以通过生成多个推理轨迹并选择最佳轨迹来提高推理能力。以往的工作表明，增加样本数量K可以逐步提高准确性。在本文中，我们展示了这一趋势并不无限持续：在K较大时，进一步缩放不再带来改进，并且某些难题无论轨迹数量多少都无法解决。有趣的是，我们发现不同的采样温度解决了不同问题子集，表明单温度缩放只探索了模型潜力的一部分。因此，我们提出沿着温度维度缩放，这扩展了LLMs的推理边界。在Qwen3（0.6B、1.7B、4B、8B）和五个代表性推理基准（AIME 2024/2025、MATH500、LiveCodeBench、Hi-ToM）上，温度缩放相较于单一温度TTS额外获得了7.3分。温度缩放还允许基础模型达到与强化学习（RL）训练对应模型相当的表现，无需额外后训练。我们进一步对此现象进行了全面分析，并设计了一种减少温度缩放开销的多温度投票方法。总之，我们的研究结果表明TTS比之前认为的更强大，而温度缩放提供了一种简单且有效的方法来释放基础模型的潜在能力。 

---
# Mitigating Modal Imbalance in Multimodal Reasoning 

**Title (ZH)**: 缓解多模态推理中的模态不平衡 

**Authors**: Chen Henry Wu, Neil Kale, Aditi Raghunathan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02608)  

**Abstract**: Foundation models (FMs) deployed in real-world tasks such as computer-use agents must integrate diverse modalities. How good are FMs at performing joint reasoning, simultaneously reasoning over multiple modalities, especially when the modalities interact and relate to each other to form cross-modal context? To better understand this problem, we study FMs on cross-modal conflicts: scenarios where conflicting evidence is presented across modalities. This allows us to examine whether FMs prioritize one modality over another or reason jointly to reconcile the conflict. Our experiments reveal that FMs can recognize conflicts in unimodal contexts, composed of a single modality, 90% of the time, but the ratio falls as low as 3% when evidence is split across modalities -- similar observations hold in cross-lingual contexts, composed of multiple languages. We trace this failure to cross-modal attention imbalance, showing that FMs exhibit extreme asymmetry in attention scores, disproportionately prioritizing certain modalities. We show that cross-modal attention imbalance does not go away by simply scaling up multimodal or multilingual datasets blindly, since they lack training examples that explicitly require cross-modal reasoning. We demonstrate that even a simple and scalable method of explicitly combining multiple modalities within each training instance significantly reduces attention imbalance. Reduced attention imbalance directly translates to improved downstream performance on several vision-language benchmarks. Our findings underscore the importance of systematically addressing cross-modal contexts to build reliable foundation models. 

**Abstract (ZH)**: 基础模型在现实任务中的跨模态冲突处理能力：基于联合推理的研究 

---
# Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs 

**Title (ZH)**: 多模态大型语言模型框架实现安全可解释的电网集成电动汽车 

**Authors**: Jean Douglas Carvalho, Hugo Kenji, Ahmad Mohammad Saber, Glaucia Melo, Max Mauro Dias Santos, Deepa Kundur  

**Link**: [PDF](https://arxiv.org/pdf/2510.02592)  

**Abstract**: The integration of electric vehicles (EVs) into smart grids presents unique opportunities to enhance both transportation systems and energy networks. However, ensuring safe and interpretable interactions between drivers, vehicles, and the surrounding environment remains a critical challenge. This paper presents a multi-modal large language model (LLM)-based framework to process multimodal sensor data - such as object detection, semantic segmentation, and vehicular telemetry - and generate natural-language alerts for drivers. The framework is validated using real-world data collected from instrumented vehicles driving on urban roads, ensuring its applicability to real-world scenarios. By combining visual perception (YOLOv8), geocoded positioning, and CAN bus telemetry, the framework bridges raw sensor data and driver comprehension, enabling safer and more informed decision-making in urban driving scenarios. Case studies using real data demonstrate the framework's effectiveness in generating context-aware alerts for critical situations, such as proximity to pedestrians, cyclists, and other vehicles. This paper highlights the potential of LLMs as assistive tools in e-mobility, benefiting both transportation systems and electric networks by enabling scalable fleet coordination, EV load forecasting, and traffic-aware energy planning.
Index Terms - Electric vehicles, visual perception, large language models, YOLOv8, semantic segmentation, CAN bus, prompt engineering, smart grid. 

**Abstract (ZH)**: 电动汽车（EVs）与智能电网的集成为提升交通系统和能源网络提供了独特机会。然而，确保驾驶员、车辆与周围环境之间的安全和可解释交互仍然是一个关键挑战。本文提出了一种基于多模态大型语言模型（LLM）的框架，用于处理多模态传感器数据（如物体检测、语义分割和车辆遥测），并生成自然语言警告供驾驶员使用。该框架通过实地数据验证，确保适用于真实场景。通过结合视觉感知（YOLOv8）、地理编码定位和CAN总线遥测，框架将原始传感器数据与驾驶员理解相连接，使在城市驾驶场景中实现更安全和明智的决策成为可能。实际数据案例研究表明，该框架在行人、骑车人和其他车辆附近等关键情况下生成上下文相关警告的有效性。本文强调了LLM作为辅助工具在电动出行领域的潜力，通过实现可扩展的车队协调、电动汽车负载预测和交通感知能源规划，同时为交通系统和电力网络带来好处。关键词 - 电动汽车，视觉感知，大型语言模型，YOLOv8，语义分割，CAN总线，提示工程，智能电网。 

---
# A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem 

**Title (ZH)**: 深 reinforcement 学习算法在集装箱装载计划问题上的基准研究 

**Authors**: Yunqi Huang, Nishith Chennakeshava, Alexis Carras, Vladislav Neverov, Wei Liu, Aske Plaat, Yingjie Fan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02589)  

**Abstract**: Container stowage planning (CSPP) is a critical component of maritime transportation and terminal operations, directly affecting supply chain efficiency. Owing to its complexity, CSPP has traditionally relied on human expertise. While reinforcement learning (RL) has recently been applied to CSPP, systematic benchmark comparisons across different algorithms remain limited. To address this gap, we develop a Gym environment that captures the fundamental features of CSPP and extend it to include crane scheduling in both multi-agent and single-agent formulations. Within this framework, we evaluate five RL algorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying complexity. The results reveal distinct performance gaps with increasing complexity, underscoring the importance of algorithm choice and problem formulation for CSPP. Overall, this paper benchmarks multiple RL methods for CSPP while providing a reusable Gym environment with crane scheduling, thus offering a foundation for future research and practical deployment in maritime logistics. 

**Abstract (ZH)**: 基于强化学习的集装箱堆存规划：性能基准比较与环境构建 

---
# Agentic Additive Manufacturing Alloy Discovery 

**Title (ZH)**: 代理增材制造合金发现 

**Authors**: Peter Pak, Achuth Chandrasekhar, Amir Barati Farimani  

**Link**: [PDF](https://arxiv.org/pdf/2510.02567)  

**Abstract**: Agentic systems enable the intelligent use of research tooling, augmenting a researcher's ability to investigate and propose novel solutions to existing problems. Within Additive Manufacturing (AM), alloy discovery remains a complex challenge, often requiring expertise in the various domains of materials science, thermodynamic simulations, and experimental analysis. Large Language Model (LLM) enabled agents can facilitate this endeavor by utilizing their extensive knowledge base to dispatch tool calls via Model Context Protocol (MCP) to perform actions such as Thermo-Calc property diagram calculations and lack of fusion process map generation. In addition, the multi-agent system developed in this work is able to effectively reason through complex user prompts and provide analysis on the printability of proposed alloys. These agents can dynamically adjust their task trajectory to the outcomes of tool call results, effectively enabling autonomous decision-making in practical environments. This work aims to utilize LLM enabled agents to automate and accelerate the task of alloy discovery within the field of additive manufacturing and showcase the benefits of adopting this multi-agent system. 

**Abstract (ZH)**: 智能系统使研究人员能够智能地使用研究工具，增强其探究和提出解决现有问题的新型解决方案的能力。在增材制造领域，合金发现仍然是一个复杂的挑战，通常需要在材料科学、热力学模拟和实验分析等多个领域的专业知识。本工作中开发的基于大型语言模型的代理能够通过利用其丰富的知识库，并通过模型上下文协议（MCP）调度工具调用（如Thermo-Calc性质图计算和缺焊缝过程图生成）来促进这一努力。此外，本工作中开发的多代理系统能够有效地处理复杂的用户提示，并对所提议合金的可打印性进行分析。这些代理可以根据工具调用结果动态调整其任务路径，从而在实际环境中实现自主决策。本工作旨在利用基于大型语言模型的代理自动化和加速增材制造领域中的合金发现任务，并展示采用这一多代理系统的优点。 

---
# Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge 

**Title (ZH)**: orchestrating 人机团队：管理者代理作为统一的研究挑战 

**Authors**: Charlie Masters, Advaith Vellanki, Jiangbo Shangguan, Bart Kultys, Jonathan Gilmore, Alastair Moore, Stefano V. Albrecht  

**Link**: [PDF](https://arxiv.org/pdf/2510.02557)  

**Abstract**: While agentic AI has advanced in automating individual tasks, managing complex multi-agent workflows remains a challenging problem. This paper presents a research vision for autonomous agentic systems that orchestrate collaboration within dynamic human-AI teams. We propose the Autonomous Manager Agent as a core challenge: an agent that decomposes complex goals into task graphs, allocates tasks to human and AI workers, monitors progress, adapts to changing conditions, and maintains transparent stakeholder communication. We formalize workflow management as a Partially Observable Stochastic Game and identify four foundational challenges: (1) compositional reasoning for hierarchical decomposition, (2) multi-objective optimization under shifting preferences, (3) coordination and planning in ad hoc teams, and (4) governance and compliance by design. To advance this agenda, we release MA-Gym, an open-source simulation and evaluation framework for multi-agent workflow orchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we find they struggle to jointly optimize for goal completion, constraint adherence, and workflow runtime - underscoring workflow management as a difficult open problem. We conclude with organizational and ethical implications of autonomous management systems. 

**Abstract (ZH)**: 尽管代理型人工智能在自动化个体任务方面取得了进步，但管理复杂多智能体工作流仍是一项具有挑战性的问题。本文提出了自主代理系统的研究愿景，旨在 orchestrate 动态人机团队中的协作。我们提出自主管理代理作为核心挑战：该代理将复杂目标分解为任务图，分配任务给人类和智能体工作者，监测进度，适应变化条件，并保持透明的利益相关者沟通。我们将工作流管理形式化为部分可观测随机游戏，并确认四个基础挑战：（1）层次分解的组合性推理，（2）目标偏好的动态优化，（3）临时团队中的协调与规划，（4）设计中的治理与合规。为推进这一议程，我们发布了 MA-Gym，这是一个开源的多智能体工作流编排模拟与评估框架。通过对 20 个工作流的 GPT-5 基础管理代理进行评估，我们发现它们在同时优化目标完成、约束遵守和工作流运行时间方面存在困难，突显了工作流管理作为一项艰巨的开放问题。最后，我们讨论了自主管理系统在组织和伦理方面的 implications。 

---
# Multimodal Function Vectors for Spatial Relations 

**Title (ZH)**: 多模态空间关系向量 

**Authors**: Shuhao Fu, Esther Goldberg, Ying Nian Wu, Hongjing Lu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02528)  

**Abstract**: Large Multimodal Models (LMMs) demonstrate impressive in-context learning abilities from limited multimodal demonstrations, yet the internal mechanisms supporting such task learning remain opaque. Building on prior work of large language models, we show that a small subset of attention heads in the vision-language model OpenFlamingo-4B is responsible for transmitting representations of spatial relations. The activations of these attention heads, termed function vectors, can be extracted and manipulated to alter an LMM's performance on relational tasks. First, using both synthetic and real image datasets, we apply causal mediation analysis to identify attention heads that strongly influence relational predictions, and extract multimodal function vectors that improve zero-shot accuracy at inference time. We further demonstrate that these multimodal function vectors can be fine-tuned with a modest amount of training data, while keeping LMM parameters frozen, to significantly outperform in-context learning baselines. Finally, we show that relation-specific function vectors can be linearly combined to solve analogy problems involving novel and untrained spatial relations, highlighting the strong generalization ability of this approach. Our results show that LMMs encode spatial relational knowledge within localized internal structures, which can be systematically extracted and optimized, thereby advancing our understanding of model modularity and enhancing control over relational reasoning in LMMs. 

**Abstract (ZH)**: Large Multimodal Models中的小部分注意力头在传输空间关系表示中起作用：通过因果中介分析识别对关系预测有强烈影响的注意力头，并提取多模态功能向量以提高零-shot准确性，这些功能向量在微调后表现出色，揭示了大型多模态模型在空间关系知识编码中的模块化结构及其优化潜力。 

---
# Safe and Efficient In-Context Learning via Risk Control 

**Title (ZH)**: 通过风险控制实现安全高效的即刻学习 

**Authors**: Andrea Wynn, Metod Jazbec, Charith Peris, Rinat Khaziev, Anqi Liu, Daniel Khashabi, Eric Nalisnick  

**Link**: [PDF](https://arxiv.org/pdf/2510.02480)  

**Abstract**: Large language models (LLMs) demonstrate a remarkable ability to learn new tasks from a few in-context examples. However, this flexibility introduces safety concerns: LLMs can be influenced by incorrect or malicious demonstrations -- for example, if an adversary tampers with or injects harmful examples without a human supervisor noticing. This motivates principled designs in which the system itself includes built-in mechanisms to guard against such attacks. We propose a novel approach to limit the degree to which harmful demonstrations can degrade model performance. First, we define a baseline ``safe'' behavior for the model -- the model's performance given no in-context demonstrations (zero-shot). Next, we apply distribution-free risk control (DFRC) to control the extent to which in-context samples can decay performance below zero-shot. We achieve this by leveraging dynamic early exit prediction, ignoring later attention heads that attend the most to the unsafe inputs. Finally, we propose modifications to DFRC that allow it to both control risk for harmful inputs \textit{and} leverage performance and efficiency gains on helpful inputs. We present both theoretical and empirical results showing that our approach can effectively control risk for harmful in-context demonstrations while simultaneously achieving substantial computational efficiency gains with helpful demonstrations. 

**Abstract (ZH)**: 大型语言模型（LLMs）展示出从少量上下文示例中学习新任务的显著能力。然而，这种灵活性引入了安全关切：LLMs 可能受到不正确或恶意示例的影响——例如，如果攻击者在未经人类监督员注意的情况下篡改或注入有害示例。这促使我们必须设计内在具有防范此类攻击机制的系统。我们提出了一种新颖的方法，以限制有害示例对模型性能的负面影响程度。首先，我们定义一个基准的“安全”行为——即在没有上下文示例（零样本）的情况下模型的表现。接下来，我们应用分布无关的的风险控制（DFRC）来控制上下文样本对性能的负面影响程度，使其不超过零样本表现。这通过利用动态早期退出预测来实现，忽略最关注不安全输入的后续注意力头。最后，我们提出了对DFRC的修改，使其既能够控制有害输入的风险，又能利用有助于性能和效率的输入带来的增益。我们提供了理论和实证结果，展示了我们的方法不仅能够有效控制有害上下文示例的风险，还能够在同时利用针对有益示例的性能和效率增益方面实现显著的计算效率提升。 

---
# RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation 

**Title (ZH)**: RefineShot: 从基础技能评估重新思考 cinematography 理解 

**Authors**: Hang Wu, Yujun Cai, Haonan Ge, Hongkai Chen, Ming-Hsuan Yang, Yiwei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02423)  

**Abstract**: Cinematography understanding refers to the ability to recognize not only the visual content of a scene but also the cinematic techniques that shape narrative meaning. This capability is attracting increasing attention, as it enhances multimodal understanding in real-world applications and underpins coherent content creation in film and media. As the most comprehensive benchmark for this task, ShotBench spans a wide range of cinematic concepts and VQA-style evaluations, with ShotVL achieving state-of-the-art results on it. However, our analysis reveals that ambiguous option design in ShotBench and ShotVL's shortcomings in reasoning consistency and instruction adherence undermine evaluation reliability, limiting fair comparison and hindering future progress. To overcome these issues, we systematically refine ShotBench through consistent option restructuring, conduct the first critical analysis of ShotVL's reasoning behavior, and introduce an extended evaluation protocol that jointly assesses task accuracy and core model competencies. These efforts lead to RefineShot, a refined and expanded benchmark that enables more reliable assessment and fosters future advances in cinematography understanding. 

**Abstract (ZH)**: cinematography理解指的是不仅识别人物场景中的视觉内容，还能识别塑造叙事意义的影视技术的能力。随着这一能力在实际应用中增强多模态理解并在电影和媒体中支持内容创作方面的重要性不断增加，这引起了越来越多的关注。作为该任务最全面的基准，ShotBench涵盖了广泛的影视概念和基于VQA的评估，ShotVL在其中达到了最先进的技术水平。然而，我们的分析表明，ShotBench中含糊不清的选项设计以及ShotVL在推理一致性和指令遵守方面的不足，损害了评价的可靠性，限制了公平比较并妨碍了未来的发展。为克服这些问题，我们系统地改进了ShotBench，通过一致的选项重组进行了第一次对ShotVL推理行为的重要分析，并引入了一种综合评估协议，该协议联合评估任务准确性和核心模型能力。这些努力导致了RefineShot，一个改进和扩展的基准，能够进行更可靠的评估并促进cinematography理解的未来进步。 

---
# BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks 

**Title (ZH)**: BrowserArena：评估LLM代理在实际网络导航任务中的性能 

**Authors**: Sagnik Anupam, Davis Brown, Shuo Li, Eric Wong, Hamed Hassani, Osbert Bastani  

**Link**: [PDF](https://arxiv.org/pdf/2510.02418)  

**Abstract**: LLM web agents now browse and take actions on the open web, yet current agent evaluations are constrained to sandboxed environments or artificial tasks. We introduce BrowserArena, a live open-web agent evaluation platform that collects user-submitted tasks, runs Arena-style head-to-head comparisons, and uses step-level human feedback to surface failure modes. Collecting and analyzing step-level annotations on the agent traces, we identify three consistent failure modes: captcha resolution, pop-up banner removal, and direct navigation to URLs. By constructing targeted datasets to further study these tasks, we discover variations in how different language models navigate these failure modes. We find, for example, that o4-mini deploys a wider variety of strategies to circumvent captcha resolution than other models and DeepSeek-R1 consistently misleads users about captcha resolution. Our findings surface both the diversity and brittleness of current web agents. More broadly, our benchmarking methodology provides an approach to evaluating and understanding web agent failure modes at scale. 

**Abstract (ZH)**: LLM网络代理现已能够在开放网络中浏览和执行操作，但当前的代理评估仍局限在沙箱环境中或人工任务中。我们引入了BrowserArena，这是一个实时的开放网络代理评估平台，收集用户提交的任务，进行Arena风格的一对一头对头比较，并使用步骤级的人工反馈来揭示失败模式。通过对代理轨迹进行收集和分析步骤级注释，我们确定了三种一致的失败模式：验证码解决、弹出广告栏移除和直接导航到URL。通过构建针对性的数据集进一步研究这些任务，我们发现不同语言模型在这些失败模式中的导航方式存在差异。例如，o4-mini 在规避验证码解决方面采用了比其他模型更广泛的策略，而DeepSeek-R1在验证码解决方面始终误导用户。我们的发现揭示了当前网络代理的多样性和脆弱性。更广泛地说，我们的基准测试方法提供了一种评估和大规模理解网络代理失败模式的途径。 

---
# Reward Models are Metrics in a Trench Coat 

**Title (ZH)**: 奖励模型是披着 trench coat 的度量标准 

**Authors**: Sebastian Gehrmann  

**Link**: [PDF](https://arxiv.org/pdf/2510.03231)  

**Abstract**: The emergence of reinforcement learning in post-training of large language models has sparked significant interest in reward models. Reward models assess the quality of sampled model outputs to generate training signals. This task is also performed by evaluation metrics that monitor the performance of an AI model. We find that the two research areas are mostly separate, leading to redundant terminology and repeated pitfalls. Common challenges include susceptibility to spurious correlations, impact on downstream reward hacking, methods to improve data quality, and approaches to meta-evaluation. Our position paper argues that a closer collaboration between the fields can help overcome these issues. To that end, we show how metrics outperform reward models on specific tasks and provide an extensive survey of the two areas. Grounded in this survey, we point to multiple research topics in which closer alignment can improve reward models and metrics in areas such as preference elicitation methods, avoidance of spurious correlations and reward hacking, and calibration-aware meta-evaluation. 

**Abstract (ZH)**: 强化学习在大型语言模型后训练中的兴起引发了对奖励模型的广泛关注。奖励模型评估采样模型输出的质量以生成训练信号。这一任务也由评估指标来执行，监控AI模型的性能。我们发现这两个研究领域大多分离，导致术语重复和重复的陷阱。常见的挑战包括对虚假相关性的易感性、对下游奖励作弊的影响、提高数据质量的方法以及元评估方法。我们的立场文件认为，这两个领域的更紧密合作有助于克服这些问题。为此，我们展示了评估指标在特定任务上比奖励模型更优，并提供了两个领域的广泛综述。基于这一综述，我们指出了多个可以通过更紧密对齐来提升奖励模型和评估指标的研究课题，特别是在偏好 elicitation 方法、避免虚假相关性和奖励作弊以及校准意识的元评估方面。 

---
# Improving GUI Grounding with Explicit Position-to-Coordinate Mapping 

**Title (ZH)**: 改进GUI接地性能：通过显式位置到坐标映射 

**Authors**: Suyuchen Wang, Tianyu Zhang, Ahmed Masry, Christopher Pal, Spandana Gella, Bang Liu, Perouz Taslakian  

**Link**: [PDF](https://arxiv.org/pdf/2510.03230)  

**Abstract**: GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current VLMs. The core bottleneck is reliable patch-to-pixel mapping, which breaks when extrapolating to high-resolution displays unseen during training. Current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and failures proliferate on new resolutions. We address this with two complementary innovations. First, RULER tokens serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and adjust rather than generate coordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. Experiments on ScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in grounding accuracy, with the largest improvements on high-resolution interfaces. By providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable GUI automation across diverse resolutions and platforms. 

**Abstract (ZH)**: GUI定位：将自然语言指令映射到像素坐标的关键任务对于自主代理至关重要，但当前的多模态模型仍然难以实现。核心瓶颈是可靠的 patch-to-pixel 映射，在处理训练期间未见过的高分辨率显示时会失效。当前的方法直接从视觉特征生成坐标，迫使模型以隐式的形式推断复杂的坐标映射；结果导致准确度下降并在新分辨率上产生更多失败。我们通过两种互补的创新来解决这一问题。首先，RULER.Token 作为显式的坐标标记，使模型能够参考类似于地图上的网格线的位置，并调整而不是从零开始生成坐标。其次，交错的 MRoPE（I-MRoPE）通过确保宽度和高度维度的同等表示，解决了标准位置方案的不对称性，从而改善了空间编码。在 ScreenSpot、ScreenSpot-V2 和 ScreenSpot-Pro 上进行的实验显示出一致的定位准确度提升，高分辨率界面的提升最为显著。通过提供显式的空间指导而不是依赖隐式学习，我们的方法能够在多种分辨率和平台上实现更可靠的 GUI 自动化。 

---
# Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles 

**Title (ZH)**: 基于潜在ensemble的随机共振测试时防御对抗攻击 

**Authors**: Dong Lao, Yuxiang Zhang, Haniyeh Ehsani Oskouie, Yangchao Wu, Alex Wong, Stefano Soatto  

**Link**: [PDF](https://arxiv.org/pdf/2510.03224)  

**Abstract**: We propose a test-time defense mechanism against adversarial attacks: imperceptible image perturbations that significantly alter the predictions of a model. Unlike existing methods that rely on feature filtering or smoothing, which can lead to information loss, we propose to "combat noise with noise" by leveraging stochastic resonance to enhance robustness while minimizing information loss. Our approach introduces small translational perturbations to the input image, aligns the transformed feature embeddings, and aggregates them before mapping back to the original reference image. This can be expressed in a closed-form formula, which can be deployed on diverse existing network architectures without introducing additional network modules or fine-tuning for specific attack types. The resulting method is entirely training-free, architecture-agnostic, and attack-agnostic. Empirical results show state-of-the-art robustness on image classification and, for the first time, establish a generic test-time defense for dense prediction tasks, including stereo matching and optical flow, highlighting the method's versatility and practicality. Specifically, relative to clean (unperturbed) performance, our method recovers up to 68.1% of the accuracy loss on image classification, 71.9% on stereo matching, and 29.2% on optical flow under various types of adversarial attacks. 

**Abstract (ZH)**: 我们提出了一种对抗攻击的测试时防御机制：不可感知的图像扰动，显著改变模型的预测结果。该机制通过利用随机共振来增强鲁棒性同时最小化信息损失，不同于依赖特征过滤或平滑的现有方法，可能会导致信息丢失。我们的方法在输入图像中引入小型平移扰动，对变换后的特征嵌入进行对齐，并在映射回原始参考图像之前进行聚合。该方法可以通过闭式公式表达，并能在无需引入额外网络模块或专门针对特定攻击类型进行微调的情况下部署在多种现有的网络架构上。该方法完全无监督训练、架构无关，并能应对多种攻击。实验证明，该方法在图像分类任务中达到了最先进的鲁棒性，并且首次为密集预测任务（包括立体匹配和光流）建立了通用的测试时防御机制，展示了该方法的 versatility 和实用性。具体而言，与干净（未扰动）性能相比，该方法在不同类型对抗攻击下分别恢复了图像分类68.1%、立体匹配71.9%、光流29.2%的准确率损失。 

---
# Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment 

**Title (ZH)**: 自锚定：通过逐步注意力对齐进行大语言模型推理 

**Authors**: Hongxiang Zhang, Yuan Tian, Tianyi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.03223)  

**Abstract**: To solve complex reasoning tasks for Large Language Models (LLMs), prompting-based methods offer a lightweight alternative to fine-tuning and reinforcement learning. However, as reasoning chains extend, critical intermediate steps and the original prompt will be buried in the context, receiving insufficient attention and leading to errors. In this paper, we propose Self-Anchor, a novel pipeline that leverages the inherent structure of reasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories into structured plans and automatically aligns the model's attention to the most relevant inference steps, allowing the model to maintain focus throughout generation. Our experiment shows that Self-Anchor outperforms SOTA prompting methods across six benchmarks. Notably, Self-Anchor significantly reduces the performance gap between ``non-reasoning'' models and specialized reasoning models, with the potential to enable most LLMs to tackle complex reasoning tasks without retraining. 

**Abstract (ZH)**: 基于自我锚定的方法解决大型语言模型的复杂推理任务 

---
# Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair 

**Title (ZH)**: 弃权与验证：一种减少代理程序修复噪声的双大型语言模型策略 

**Authors**: José Cambronero, Michele Tufano, Sherry Shi, Renyao Wei, Grant Uy, Runxiang Cheng, Chin-Jung Liu, Shiying Pan, Satish Chandra, Pat Rondon  

**Link**: [PDF](https://arxiv.org/pdf/2510.03217)  

**Abstract**: Agentic Automated Program Repair (APR) is increasingly tackling complex, repository-level bugs in industry, but ultimately agent-generated patches still need to be reviewed by a human before committing them to ensure they address the bug. Showing unlikely patches to developers can lead to substantial noise, wasting valuable developer time and eroding trust in automated code changes. We introduce two complementary LLM-based policies to reduce such noise: bug abstention and patch validation policies. Bug abstention excludes bugs that the agentic APR system is unlikely to fix. Patch validation rejects patches that are unlikely to be a good fix for the given bug. We evaluate both policies on three sets of bugs from Google's codebase, and their candidate patches generated by an internal agentic APR system. On a set of 174 human-reported bugs, removing bugs and patch trajectories rejected by our policies can raise success rates by up to 13 percentage points and 15 percentage points, respectively, and by up to 39 percentage points in combination. On null pointer exceptions and sanitizer-reported bugs with machine-generated bug reports, patch validation also improves average single-sample success rates. This two-policy approach provides a practical path to the reliable, industrial-scale deployment of agentic APR systems. 

**Abstract (ZH)**: 基于代理的自动化程序修复（APR）日益在工业中处理复杂的仓库级别的缺陷，但最终仍需由人类审查生成的补丁以确保其解决了缺陷。向开发者展示不可能的补丁会导致大量噪音，浪费宝贵的开发者时间并损害对自动代码更改的信任。我们引入了两种互补的基于LLM的策略来减少这种噪音：缺陷回避策略和补丁验证策略。缺陷回避策略排除代理APR系统不太可能修复的缺陷。补丁验证策略拒绝不太可能是给定缺陷良好修复的补丁。我们分别在这三个来自Google代码库的缺陷集及其由内部代理APR系统生成的有效补丁集中评估了这两种策略。在一组174个人报告的缺陷中，移除我们的策略拒绝的缺陷和补丁路径，分别可以提高成功率多达13和15个百分点，并且在结合使用时可以提高多达39个百分点。对于空指针异常和 sanitizer 报告的缺陷（伴有机器生成的缺陷报告），补丁验证策略也提高了平均单样本成功率。这种多策略方法提供了将代理APR系统可靠地部署到工业规模的实际途径。 

---
# Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation 

**Title (ZH)**: Wave-GMS：轻量级多尺度生成模型用于医学图像分割 

**Authors**: Talha Ahmed, Nehal Ahmed Shaikh, Hassan Mohy-ud-Din  

**Link**: [PDF](https://arxiv.org/pdf/2510.03216)  

**Abstract**: For equitable deployment of AI tools in hospitals and healthcare facilities, we need Deep Segmentation Networks that offer high performance and can be trained on cost-effective GPUs with limited memory and large batch sizes. In this work, we propose Wave-GMS, a lightweight and efficient multi-scale generative model for medical image segmentation. Wave-GMS has a substantially smaller number of trainable parameters, does not require loading memory-intensive pretrained vision foundation models, and supports training with large batch sizes on GPUs with limited memory. We conducted extensive experiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument, and HAM10000), demonstrating that Wave-GMS achieves state-of-the-art segmentation performance with superior cross-domain generalizability, while requiring only ~2.6M trainable parameters. Code is available at this https URL. 

**Abstract (ZH)**: 公平部署医院和医疗设施中的人工智能工具：一种轻量高效的多尺度生成模型Wave-GMS及其医学图像分割应用 

---
# Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning 

**Title (ZH)**: 规则到模拟：一种形式视觉规划的双多模视觉语言框架 

**Authors**: Yilun Hao, Yongchao Chen, Chuchu Fan, Yang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.03182)  

**Abstract**: Vision Language Models (VLMs) show strong potential for visual planning but struggle with precise spatial and long-horizon reasoning. In contrast, Planning Domain Definition Language (PDDL) planners excel at long-horizon formal planning, but cannot interpret visual inputs. Recent works combine these complementary advantages by enabling VLMs to turn visual planning problems into PDDL files for formal planning. However, while VLMs can generate PDDL problem files satisfactorily, they struggle to accurately generate the PDDL domain files, which describe all the planning rules. As a result, prior methods rely on human experts to predefine domain files or on constant environment access for refinement. We propose VLMFP, a Dual-VLM-guided framework that can autonomously generate both PDDL problem and domain files for formal visual planning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A SimVLM that simulates action consequences based on input rule descriptions, and a GenVLM that generates and iteratively refines PDDL files by comparing the PDDL and SimVLM execution results. VLMFP unleashes multiple levels of generalizability: The same generated PDDL domain file works for all the different instances under the same problem, and VLMs generalize to different problems with varied appearances and rules. We evaluate VLMFP with 6 grid-world domains and test its generalization to unseen instances, appearance, and game rules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios, simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal reaching for seen and unseen appearances, respectively. With the guidance of SimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for unseen instances in seen and unseen appearances, respectively. Project page: this https URL. 

**Abstract (ZH)**: Vision-Language Models引导的视觉规划框架：自主生成PDDL问题和领域文件（VLMFP） 

---
# Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting? 

**Title (ZH)**: 长文生成中的主题建模：长上下文LLM能否通过零样本提示重构NTM？ 

**Authors**: Xuan Xu, Haolun Li, Zhongliang Yang, Beilin Chu, Jia Song, Moxuan Xu, Linna Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.03174)  

**Abstract**: Traditional topic models such as neural topic models rely on inference and generation networks to learn latent topic distributions. This paper explores a new paradigm for topic modeling in the era of large language models, framing TM as a long-form generation task whose definition is updated in this paradigm. We propose a simple but practical approach to implement LLM-based topic model tasks out of the box (sample a data subset, generate topics and representative text with our prompt, text assignment with keyword match). We then investigate whether the long-form generation paradigm can beat NTMs via zero-shot prompting. We conduct a systematic comparison between NTMs and LLMs in terms of topic quality and empirically examine the claim that "a majority of NTMs are outdated." 

**Abstract (ZH)**: 传统主题模型如神经主题模型依赖于推理网络和生成网络来学习潜在主题分布。本文探讨了大规模语言模型时代主题建模的新范式，将主题建模框架为一种长文本生成任务，并在此范式中更新其定义。我们提出了一种简单实用的方法，可以不经修改直接使用大规模语言模型实现主题模型任务（抽取数据子集，使用提示生成主题和代表性文本，并通过关键词匹配进行文本分配）。我们还研究了这种长文本生成范式是否能够通过零样本提示超越神经主题模型。我们系统比较了神经主题模型和大规模语言模型在主题质量方面的表现，并实证检验了“大多数神经主题模型已经过时”的说法。 

---
# UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization 

**Title (ZH)**: UniShield：一种适应性的多代理框架，用于统一的伪造图像检测与定位 

**Authors**: Qing Huang, Zhipei Xu, Xuanyu Zhang, Jian Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.03161)  

**Abstract**: With the rapid advancements in image generation, synthetic images have become increasingly realistic, posing significant societal risks, such as misinformation and fraud. Forgery Image Detection and Localization (FIDL) thus emerges as essential for maintaining information integrity and societal security. Despite impressive performances by existing domain-specific detection methods, their practical applicability remains limited, primarily due to their narrow specialization, poor cross-domain generalization, and the absence of an integrated adaptive framework. To address these issues, we propose UniShield, the novel multi-agent-based unified system capable of detecting and localizing image forgeries across diverse domains, including image manipulation, document manipulation, DeepFake, and AI-generated images. UniShield innovatively integrates a perception agent with a detection agent. The perception agent intelligently analyzes image features to dynamically select suitable detection models, while the detection agent consolidates various expert detectors into a unified framework and generates interpretable reports. Extensive experiments show that UniShield achieves state-of-the-art results, surpassing both existing unified approaches and domain-specific detectors, highlighting its superior practicality, adaptiveness, and scalability. 

**Abstract (ZH)**: 基于多代理的统一伪造图像检测与定位系统（UniShield） 

---
# SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus 

**Title (ZH)**: SpineBench: 一个基于SpineMed-450k语料库、具有临床相关性和层级意识的基准测试 

**Authors**: Ming Zhao, Wenhui Dong, Yang Zhang, Xiang Zheng, Zhonghao Zhang, Zian Zhou, Yunzhi Guan, Liukun Xu, Wei Peng, Zhaoyang Gong, Zhicheng Zhang, Dachuan Li, Xiaosheng Ma, Yuli Ma, Jianing Ni, Changjiang Jiang, Lixia Tian, Qixin Chen, Kaishun Xia, Pingping Liu, Tongshun Zhang, Zhiqiang Liu, Zhongan Bi, Chenyang Si, Tiansheng Sun, Caifeng Shan  

**Link**: [PDF](https://arxiv.org/pdf/2510.03160)  

**Abstract**: Spine disorders affect 619 million people globally and are a leading cause of disability, yet AI-assisted diagnosis remains limited by the lack of level-aware, multimodal datasets. Clinical decision-making for spine disorders requires sophisticated reasoning across X-ray, CT, and MRI at specific vertebral levels. However, progress has been constrained by the absence of traceable, clinically-grounded instruction data and standardized, spine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem co-designed with practicing spine surgeons. It features SpineMed-450k, the first large-scale dataset explicitly designed for vertebral-level reasoning across imaging modalities with over 450,000 instruction instances, and SpineBench, a clinically-grounded evaluation framework. SpineMed-450k is curated from diverse sources, including textbooks, guidelines, open datasets, and ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline with a two-stage LLM generation method (draft and revision) to ensure high-quality, traceable data for question-answering, multi-turn consultations, and report generation. SpineBench evaluates models on clinically salient axes, including level identification, pathology assessment, and surgical planning. Our comprehensive evaluation of several recently advanced large vision-language models (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained, level-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k demonstrates consistent and significant improvements across all tasks. Clinician assessments confirm the diagnostic clarity and practical utility of our model's outputs. 

**Abstract (ZH)**: 脊柱疾病影响全球6.19亿人，并且是导致残疾的主要原因之一，但AI辅助诊断仍然受限于缺乏层次意识的多模态数据集。脊柱疾病的临床决策需要在特定椎体水平上对X射线、CT和MRI进行复杂的推理。然而，进展受限于缺乏可追溯的、基于临床的指令数据和标准化的脊柱特定基准。为解决这一问题，我们介绍了与实践经验丰富的脊柱外科医生共同设计的SpineMed生态系统。它包含SpineMed-450k，这是首个明确设计用于跨影像模态的椎体水平推理的大规模数据集，包含超过450,000个指令实例，以及SpineBench，一个基于临床的评估框架。SpineMed-450k从多种来源精心整理而来，包括教科书、指南、开放数据集和约1000个匿名医院病例，采用临床医师在环管道和两阶段LLM生成方法（草案和修订）来确保高质量、可追溯的数据，用于问题回答、多轮咨询和报告生成。SpineBench在临床显著轴线上评估模型，包括椎体水平识别、病理评估和手术规划。我们在SpineBench上对几种领先的大规模视觉-语言模型的全面评估表明，这些模型在细微层次和特定椎体水平推理方面存在系统性弱点。相比之下，我们基于SpineMed-450k微调的模型在所有任务中表现出一致且显著的改进。临床医师评估证实了我们模型输出的诊断清晰度和实际应用价值。 

---
# Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches 

**Title (ZH)**: 基于刺激电压的Action Potential起始时间预测：经典方法 vs. 受量子启发的方法 

**Authors**: Stevens Johnson, Varun Puram, Johnson Thomas, Acsah Konuparamban, Ashwin Kannan  

**Link**: [PDF](https://arxiv.org/pdf/2510.03155)  

**Abstract**: Accurate modeling of neuronal action potential (AP) onset timing is crucial for understanding neural coding of danger signals. Traditional leaky integrate-and-fire (LIF) models, while widely used, exhibit high relative error in predicting AP onset latency, especially under strong or rapidly changing stimuli. Inspired by recent experimental findings and quantum theory, we present a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats AP onset as a probabilistic event, represented by a Gaussian wave packet in time. This approach captures the biological variability and uncertainty inherent in neuronal firing. We systematically compare the relative error of AP onset predictions between the classical LIF and QI-LIF models using synthetic data from hippocampal and sensory neurons subjected to varying stimulus amplitudes. Our results demonstrate that the QI-LIF model significantly reduces prediction error, particularly for high-intensity stimuli, aligning closely with observed biological responses. This work highlights the potential of quantum-inspired computational frameworks in advancing the accuracy of neural modeling and has implications for quantum engineering approaches to brain-inspired computing. 

**Abstract (ZH)**: 准确建模神经动作电位(AP) onset 时间对于理解神经编码危险信号至关重要。传统漏氏积分-放电(LIF)模型虽然广泛使用，但在预测AP onset 迟滞时表现出较高的相对误差，尤其是在强或快速变化的刺激下。受到最近实验发现和量子理论的启发，我们提出了一种量子启发式漏氏积分-放电(QI-LIF)模型，将AP onset 视作一个概率事件，并用时间中的高斯波包表示。该方法捕捉了神经元放电的生物变异性与不确定性。我们使用来自海马区和感觉神经元的合成数据，这些神经元在不同刺激幅度下受到刺激，系统地比较了经典LIF模型和QI-LIF模型在预测AP onset 上的相对误差。结果显示，QI-LIF模型显著降低了预测误差，特别是在高强度刺激下，与观察到的生物响应接近。这项工作突出了量子启发式计算框架在提高神经建模准确性方面的潜力，并对基于量子工程的仿脑计算具有重要意义。 

---
# Signature-Informed Transformer for Asset Allocation 

**Title (ZH)**: 基于签名的Transformer资产配置 

**Authors**: Yoontae Hwang, Stefan Zohren  

**Link**: [PDF](https://arxiv.org/pdf/2510.03129)  

**Abstract**: Robust asset allocation is a key challenge in quantitative finance, where deep-learning forecasters often fail due to objective mismatch and error amplification. We introduce the Signature-Informed Transformer (SIT), a novel framework that learns end-to-end allocation policies by directly optimizing a risk-aware financial objective. SIT's core innovations include path signatures for a rich geometric representation of asset dynamics and a signature-augmented attention mechanism embedding financial inductive biases, like lead-lag effects, into the model. Evaluated on daily S\&P 100 equity data, SIT decisively outperforms traditional and deep-learning baselines, especially when compared to predict-then-optimize models. These results indicate that portfolio-aware objectives and geometry-aware inductive biases are essential for risk-aware capital allocation in machine-learning systems. The code is available at: this https URL 

**Abstract (ZH)**: 基于签名的信息 transformer 在量化金融中的稳健资产配置：一种直接优化风险意识金融目标的端到端分配策略 

---
# HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion 

**Title (ZH)**: HAVIR: 层次视觉引导的图像重建方法，基于CLIP指导的多功能扩散模型 

**Authors**: Shiyi Zhang, Dong Liang, Hairong Zheng, Yihang Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.03122)  

**Abstract**: The reconstruction of visual information from brain activity fosters interdisciplinary integration between neuroscience and computer vision. However, existing methods still face challenges in accurately recovering highly complex visual stimuli. This difficulty stems from the characteristics of natural scenes: low-level features exhibit heterogeneity, while high-level features show semantic entanglement due to contextual overlaps. Inspired by the hierarchical representation theory of the visual cortex, we propose the HAVIR model, which separates the visual cortex into two hierarchical regions and extracts distinct features from each. Specifically, the Structural Generator extracts structural information from spatial processing voxels and converts it into latent diffusion priors, while the Semantic Extractor converts semantic processing voxels into CLIP embeddings. These components are integrated via the Versatile Diffusion model to synthesize the final image. Experimental results demonstrate that HAVIR enhances both the structural and semantic quality of reconstructions, even in complex scenes, and outperforms existing models. 

**Abstract (ZH)**: 从大脑活动重建视觉信息促进神经科学与计算机视觉的跨学科整合。然而，现有方法在准确恢复高度复杂的视觉刺激方面仍然面临挑战。这一困难源于自然场景的特征：低级特征表现出异质性，而高级特征由于上下文重叠则表现出语义交织。受视皮质分层表示理论的启发，我们提出了HAVIR模型，将视皮质分为两个分层区域，并从每个区域中提取不同的特征。具体来说，结构生成器从空间处理体素中提取结构信息并转化为潜在扩散先验，而语义提取器将语义处理体素转化为CLIP嵌入。这些组件通过通用扩散模型综合，以合成最终图像。实验结果表明，HAVIR在复杂场景中增强了重建的结构和语义质量，并优于现有模型。 

---
# Distilled Protein Backbone Generation 

**Title (ZH)**: 提取蛋白主链生成 

**Authors**: Liyang Xie, Haoran Zhang, Zhendong Wang, Wesley Tansey, Mingyuan Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.03095)  

**Abstract**: Diffusion- and flow-based generative models have recently demonstrated strong performance in protein backbone generation tasks, offering unprecedented capabilities for de novo protein design. However, while achieving notable performance in generation quality, these models are limited by their generating speed, often requiring hundreds of iterative steps in the reverse-diffusion process. This computational bottleneck limits their practical utility in large-scale protein discovery, where thousands to millions of candidate structures are needed. To address this challenge, we explore the techniques of score distillation, which has shown great success in reducing the number of sampling steps in the vision domain while maintaining high generation quality. However, a straightforward adaptation of these methods results in unacceptably low designability. Through extensive study, we have identified how to appropriately adapt Score identity Distillation (SiD), a state-of-the-art score distillation strategy, to train few-step protein backbone generators which significantly reduce sampling time, while maintaining comparable performance to their pretrained teacher model. In particular, multistep generation combined with inference time noise modulation is key to the success. We demonstrate that our distilled few-step generators achieve more than a 20-fold improvement in sampling speed, while achieving similar levels of designability, diversity, and novelty as the Proteina teacher model. This reduction in inference cost enables large-scale in silico protein design, thereby bringing diffusion-based models closer to real-world protein engineering applications. 

**Abstract (ZH)**: 基于扩散和流的生成模型在蛋白质主链生成任务中 recently demonstrated 强大的性能，为从头蛋白质设计提供了前所未有的能力。然而，尽管在生成质量方面取得了显著的性能，这些模型在生成速度方面受到限制，经常需要在逆向扩散过程中进行数百次迭代步骤。这一计算瓶颈限制了它们在大规模蛋白质发现中的实用性，其中需要成千上万甚至数百万的候选结构。为了解决这一挑战，我们探索了评分蒸馏的技术，该技术在视觉领域显示出显著的成功，可以减少采样步骤的数量，同时保持高质量的生成。然而，直接适应这些方法会导致不合理的低可设计性。通过广泛的研究所发现，可以通过适当适应当前最先进的评分身份蒸馏（SiD）策略来训练多步蛋白质主链生成器，从而显著减少采样时间，同时保持与预训练教师模型相当的性能。特别是，多步生成与推理时间噪声调节是成功的关键。我们证明，我们的蒸馏多步生成器在采样速度上实现了超过20倍的提升，同时在可设计性、多样性和新颖性方面与Proteina教师模型相当。这降低了推理成本，从而实现大规模的体外蛋白质设计，使基于扩散的模型更接近实际的蛋白质工程应用。 

---
# What Drives Compositional Generalization in Visual Generative Models? 

**Title (ZH)**: 视觉生成模型中组分泛化的驱动因素探究 

**Authors**: Karim Farid, Rajat Sahay, Yumna Ali Alnaggar, Simon Schrodi, Volker Fischer, Cordelia Schmid, Thomas Brox  

**Link**: [PDF](https://arxiv.org/pdf/2510.03075)  

**Abstract**: Compositional generalization, the ability to generate novel combinations of known concepts, is a key ingredient for visual generative models. Yet, not all mechanisms that enable or inhibit it are fully understood. In this work, we conduct a systematic study of how various design choices influence compositional generalization in image and video generation in a positive or negative way. Through controlled experiments, we identify two key factors: (i) whether the training objective operates on a discrete or continuous distribution, and (ii) to what extent conditioning provides information about the constituent concepts during training. Building on these insights, we show that relaxing the MaskGIT discrete loss with an auxiliary continuous JEPA-based objective can improve compositional performance in discrete models like MaskGIT. 

**Abstract (ZH)**: 组成泛化能力，即生成已知概念新颖组合的能力，是视觉生成模型的关键要素。然而，并非所有促进或抑制这种能力的机制都已被完全理解。在本工作中，我们系统地研究了各种设计选择是如何以积极或消极的方式影响图像和视频生成中的组成泛化能力。通过受控实验，我们识别出两个关键因素：(i) 训练目标作用于离散还是连续分布，以及(ii) 条件信息在训练过程中提供给组成概念的程度。基于这些见解，我们显示，通过使用辅助连续JEPA基目标放宽MaskGIT的离散损失，可以改进像MaskGIT这样的离散模型的组成性能。 

---
# A Study of Neural Polar Decoders for Communication 

**Title (ZH)**: 神经极化解码器的研究 

**Authors**: Rom Hirsch, Ziv Aharoni, Henry D. Pfister, Haim H. Permuter  

**Link**: [PDF](https://arxiv.org/pdf/2510.03069)  

**Abstract**: In this paper, we adapt and analyze Neural Polar Decoders (NPDs) for end-to-end communication systems. While prior work demonstrated the effectiveness of NPDs on synthetic channels, this study extends the NPD to real-world communication systems. The NPD was adapted to complete OFDM and single-carrier communication systems. To satisfy practical system requirements, the NPD is extended to support any code length via rate matching, higher-order modulations, and robustness across diverse channel conditions. The NPD operates directly on channels with memory, exploiting their structure to achieve higher data rates without requiring pilots and a cyclic prefix. Although NPD entails higher computational complexity than the standard 5G polar decoder, its neural network architecture enables an efficient representation of channel statistics, resulting in manageable complexity suitable for practical systems. Experimental results over 5G channels demonstrate that the NPD consistently outperforms the 5G polar decoder in terms of BER, BLER, and throughput. These improvements are particularly significant for low-rate and short-block configurations, which are prevalent in 5G control channels. Furthermore, NPDs applied to single-carrier systems offer performance comparable to OFDM with lower PAPR, enabling effective single-carrier transmission over 5G channels. These results position the NPD as a high-performance, pilotless, and robust decoding solution. 

**Abstract (ZH)**: 基于神经极化译码器的端到端通信系统研究 

---
# A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem 

**Title (ZH)**: 近似旅行商问题的统一深度强化学习方法 

**Authors**: Mingfeng Fan, Jiaqi Cheng, Yaoxin Wu, Yifeng Zhang, Yibin Yang, Guohua Wu, Guillaume Sartoretti  

**Link**: [PDF](https://arxiv.org/pdf/2510.03065)  

**Abstract**: In recent years, deep reinforcement learning (DRL) has gained traction for solving the NP-hard traveling salesman problem (TSP). However, limited attention has been given to the close-enough TSP (CETSP), primarily due to the challenge introduced by its neighborhood-based visitation criterion, wherein a node is considered visited if the agent enters a compact neighborhood around it. In this work, we formulate a Markov decision process (MDP) for CETSP using a discretization scheme and propose a novel unified dual-decoder DRL (UD3RL) framework that separates decision-making into node selection and waypoint determination. Specifically, an adapted encoder is employed for effective feature extraction, followed by a node-decoder and a loc-decoder to handle the two sub-tasks, respectively. A k-nearest neighbors subgraph interaction strategy is further introduced to enhance spatial reasoning during location decoding. Furthermore, we customize the REINFORCE algorithm to train UD3RL as a unified model capable of generalizing across different problem sizes and varying neighborhood radius types (i.e., constant and random radii). Experimental results show that UD3RL outperforms conventional methods in both solution quality and runtime, while exhibiting strong generalization across problem scales, spatial distributions, and radius ranges, as well as robustness to dynamic environments. 

**Abstract (ZH)**: 近年来，深度强化学习（DRL）在解决NP难旅行商问题（TSP）方面取得了进展。然而，由于其基于邻域的访问准则所带来的挑战，对最近足够旅行商问题（CETSP）的关注相对较少。其中，如果代理进入节点周围的紧凑邻域，则认为节点被访问。在本文中，我们使用离散化方案为CETSP建模马尔可夫决策过程（MDP），并提出了一种新的统一双解码器DRL（UD3RL）框架，将决策过程分为节点选择和路径点确定两个部分。具体而言，采用改编后的编码器进行有效的特征提取，随后通过节点解码器和位置解码器分别处理这两个子任务，并引入k近邻子图交互策略以增强空间推理能力。此外，我们对REINFORCE算法进行定制，以训练UD3RL作为一个统一模型，能够跨不同问题规模和不同邻域半径类型（即固定半径和随机半径）进行泛化。实验结果表明，在解决方案质量和运行时间方面，UD3RL优于传统方法，并且在问题规模、空间分布和半径范围方面具有较强的泛化能力，同时在动态环境中表现出较强的鲁棒性。 

---
# Comparative Analysis of Parameterized Action Actor-Critic Reinforcement Learning Algorithms for Web Search Match Plan Generation 

**Title (ZH)**: 参数化动作actor-critic强化学习算法的网络搜索匹配计划生成比较分析 

**Authors**: Ubayd Bapoo, Clement N Nyirenda  

**Link**: [PDF](https://arxiv.org/pdf/2510.03064)  

**Abstract**: This study evaluates the performance of Soft Actor Critic (SAC), Greedy Actor Critic (GAC), and Truncated Quantile Critics (TQC) in high-dimensional decision-making tasks using fully observable environments. The focus is on parametrized action (PA) spaces, eliminating the need for recurrent networks, with benchmarks Platform-v0 and Goal-v0 testing discrete actions linked to continuous action-parameter spaces. Hyperparameter optimization was performed with Microsoft NNI, ensuring reproducibility by modifying the codebase for GAC and TQC. Results show that Parameterized Action Greedy Actor-Critic (PAGAC) outperformed other algorithms, achieving the fastest training times and highest returns across benchmarks, completing 5,000 episodes in 41:24 for the Platform game and 24:04 for the Robot Soccer Goal game. Its speed and stability provide clear advantages in complex action spaces. Compared to PASAC and PATQC, PAGAC demonstrated superior efficiency and reliability, making it ideal for tasks requiring rapid convergence and robust performance. Future work could explore hybrid strategies combining entropy-regularization with truncation-based methods to enhance stability and expand investigations into generalizability. 

**Abstract (ZH)**: 本研究评估了在完全可观测环境中，Soft Actor Critic (SAC)、Greedy Actor Critic (GAC) 和 Truncated Quantile Critics (TQC) 在高维决策任务中的性能，重点关注参数化动作（PA）空间，消除了循环网络的需求，并使用Platform-v0和Goal-v0基准测试离散动作与连续动作参数空间的联系。通过Microsoft NNI进行了超参数优化，通过对GAC和TQC代码的修改确保可重复性。结果表明，Parameterized Action Greedy Actor-Critic (PAGAC) 在各基准测试中表现最佳，训练速度最快，回报最高，在Platform游戏中完成5000个回合耗时41:24，在Robot Soccer Goal游戏中耗时24:04。其速度和稳定性在复杂动作空间中提供了明显优势。与PASAC和PATQC相比，PAGAC体现了更高的效率和可靠性，使其适用于需要快速收敛和稳健性能的任务。未来工作可以探索结合熵正则化与截断方法的混合策略，以提高稳定性和扩展泛化性研究。 

---
# Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles 

**Title (ZH)**: 语音情感识别中的语义分化：描述性与表达性语音角色的启示 

**Authors**: Rongchen Guo, Vincent Francoeur, Isar Nejadgholi, Sylvain Gagnon, Miodrag Bolic  

**Link**: [PDF](https://arxiv.org/pdf/2510.03060)  

**Abstract**: Speech Emotion Recognition (SER) is essential for improving human-computer interaction, yet its accuracy remains constrained by the complexity of emotional nuances in speech. In this study, we distinguish between descriptive semantics, which represents the contextual content of speech, and expressive semantics, which reflects the speaker's emotional state. After watching emotionally charged movie segments, we recorded audio clips of participants describing their experiences, along with the intended emotion tags for each clip, participants' self-rated emotional responses, and their valence/arousal scores. Through experiments, we show that descriptive semantics align with intended emotions, while expressive semantics correlate with evoked emotions. Our findings inform SER applications in human-AI interaction and pave the way for more context-aware AI systems. 

**Abstract (ZH)**: 语音情感识别（SER）对于改善人机交互至关重要，但其准确性受限于语音中情感细腻程度的复杂性。在本研究中，我们将描述性语义定义为表示语音背景内容的含义，并将表现性语义定义为反映说话者情感状态的含义。参与者观看了情感化的电影片段后，我们记录了他们描述体验时的语音片段，每个片段的预期情感标签，参与者的自评情感反应，以及他们的愉悦度/唤醒度评分。通过实验我们表明，描述性语义与预期情感一致，而表现性语义与引发的情感相关。我们的发现为人类-AI交互中的SER应用提供了指导，并为更具情境意识的AI系统的发展铺平了道路。 

---
# ZeroShotOpt: Towards Zero-Shot Pretrained Models for Efficient Black-Box Optimization 

**Title (ZH)**: 零-shot预训练：高效黑盒优化的零-shot预训练模型研究 

**Authors**: Jamison Meindl, Yunsheng Tian, Tony Cui, Veronika Thost, Zhang-Wei Hong, Johannes Dürholt, Jie Chen, Wojciech Matusik, Mina Konaković Luković  

**Link**: [PDF](https://arxiv.org/pdf/2510.03051)  

**Abstract**: Global optimization of expensive, derivative-free black-box functions requires extreme sample efficiency. While Bayesian optimization (BO) is the current state-of-the-art, its performance hinges on surrogate and acquisition function hyper-parameters that are often hand-tuned and fail to generalize across problem landscapes. We present ZeroShotOpt, a general-purpose, pretrained model for continuous black-box optimization tasks ranging from 2D to 20D. Our approach leverages offline reinforcement learning on large-scale optimization trajectories collected from 12 BO variants. To scale pretraining, we generate millions of synthetic Gaussian process-based functions with diverse landscapes, enabling the model to learn transferable optimization policies. As a result, ZeroShotOpt achieves robust zero-shot generalization on a wide array of unseen benchmarks, matching or surpassing the sample efficiency of leading global optimizers, including BO, while also offering a reusable foundation for future extensions and improvements. Our open-source code, dataset, and model are available at: this https URL 

**Abstract (ZH)**: 全球昂贵且无导数黑盒函数的优化需要极高的样本效率。尽管贝叶斯优化（BO）是当前最先进的方法，但其性能依赖于往往需要手动调优且难以跨问题景观泛化的先验和获取函数超参数。我们提出ZeroShotOpt，这是一种用于从2D到20D连续黑盒优化任务的一般用途、预训练模型。该方法通过在12种BO变体的大规模优化轨迹上进行离线强化学习来提升预训练效率。为扩展预训练，我们生成了数百万个基于高斯过程的合成函数，具有多样化的景观，使模型能够学习通用的优化策略。因此，ZeroShotOpt在一系列未见过的基准测试上实现了稳健的零样本泛化，其样本效率与包括BO在内的领先全局优化器相当或更优，同时为未来扩展和改进提供了一个可重用的基础。我们的开源代码、数据集和模型可在以下链接获取：this https URL。 

---
# When and Where do Events Switch in Multi-Event Video Generation? 

**Title (ZH)**: 多事件视频生成中，事件何时以及在何地切换？ 

**Authors**: Ruotong Liao, Guowen Huang, Qing Cheng, Thomas Seidl, Daniel Cremers, Volker Tresp  

**Link**: [PDF](https://arxiv.org/pdf/2510.03049)  

**Abstract**: Text-to-video (T2V) generation has surged in response to challenging questions, especially when a long video must depict multiple sequential events with temporal coherence and controllable content. Existing methods that extend to multi-event generation omit an inspection of the intrinsic factor in event shifting. The paper aims to answer the central question: When and where multi-event prompts control event transition during T2V generation. This work introduces MEve, a self-curated prompt suite for evaluating multi-event text-to-video (T2V) generation, and conducts a systematic study of two representative model families, i.e., OpenSora and CogVideoX. Extensive experiments demonstrate the importance of early intervention in denoising steps and block-wise model layers, revealing the essential factor for multi-event video generation and highlighting the possibilities for multi-event conditioning in future models. 

**Abstract (ZH)**: 文本到视频（T2V）生成在应对挑战性问题时蓬勃发展，尤其是在长视频必须描绘多个具有时间连贯性和可控内容的序列事件时。现有方法虽然能够扩展到多事件生成，但忽略了事件转换内在因素的考察。本文旨在回答核心问题：在T2V生成过程中，多事件提示何时及如何控制事件过渡。本文引入了MEve，一个自营收集的提示套件，用于评估多事件文本到视频（T2V）生成，并对两个代表性的模型家族，即OpenSora和CogVideoX，进行了系统的研究。广泛的实验表明，在去噪步骤和块状模型层中早期干预的重要性，揭示了多事件视频生成的关键因素，并指出了未来模型中多事件条件的可能性。 

---
# CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration 

**Title (ZH)**: CHORD: 基于设备-云协作的混合精度定制序列推荐模型 

**Authors**: Tianqi Liu, Kairui Fu, Shengyu Zhang, Wenyan Fan, Zhaocheng Du, Jieming Zhu, Fan Wu, Fei Wu  

**Link**: [PDF](https://arxiv.org/pdf/2510.03038)  

**Abstract**: With the advancement of mobile device capabilities, deploying reranking models directly on devices has become feasible, enabling real-time contextual recommendations. When migrating models from cloud to devices, resource heterogeneity inevitably necessitates model compression. Recent quantization methods show promise for efficient deployment, yet they overlook device-specific user interests, resulting in compromised recommendation accuracy. While on-device finetuning captures personalized user preference, it imposes additional computational burden through local retraining. To address these challenges, we propose a framework for \underline{\textbf{C}}ustomizing \underline{\textbf{H}}ybrid-precision \underline{\textbf{O}}n-device model for sequential \underline{\textbf{R}}ecommendation with \underline{\textbf{D}}evice-cloud collaboration (\textbf{CHORD}), leveraging channel-wise mixed-precision quantization to simultaneously achieve personalization and resource-adaptive deployment. CHORD distributes randomly initialized models across heterogeneous devices and identifies user-specific critical parameters through auxiliary hypernetwork modules on the cloud. Our parameter sensitivity analysis operates across multiple granularities (layer, filter, and element levels), enabling precise mapping from user profiles to quantization strategy. Through on-device mixed-precision quantization, CHORD delivers dynamic model adaptation and accelerated inference without backpropagation, eliminating costly retraining cycles. We minimize communication overhead by encoding quantization strategies using only 2 bits per channel instead of 32-bit weights. Experiments on three real-world datasets with two popular backbones (SASRec and Caser) demonstrate the accuracy, efficiency, and adaptivity of CHORD. 

**Abstract (ZH)**: 基于设备-云协作的自适应混合精度离线推荐框架（CHORD） 

---
# Investigating The Smells of LLM Generated Code 

**Title (ZH)**: investigating LLM生成代码的气味 

**Authors**: Debalina Ghosh Paul, Hong Zhu, Ian Bayley  

**Link**: [PDF](https://arxiv.org/pdf/2510.03029)  

**Abstract**: Context: Large Language Models (LLMs) are increasingly being used to generate program code. Much research has been reported on the functional correctness of generated code, but there is far less on code quality.
Objectives: In this study, we propose a scenario-based method of evaluating the quality of LLM-generated code to identify the weakest scenarios in which the quality of LLM generated code should be improved.
Methods: The method measures code smells, an important indicator of code quality, and compares them with a baseline formed from reference solutions of professionally written code. The test dataset is divided into various subsets according to the topics of the code and complexity of the coding tasks to represent different scenarios of using LLMs for code generation. We will also present an automated test system for this purpose and report experiments with the Java programs generated in response to prompts given to four state-of-the-art LLMs: Gemini Pro, ChatGPT, Codex, and Falcon.
Results: We find that LLM-generated code has a higher incidence of code smells compared to reference solutions. Falcon performed the least badly, with a smell increase of 42.28%, followed by Gemini Pro (62.07%), ChatGPT (65.05%) and finally Codex (84.97%). The average smell increase across all LLMs was 63.34%, comprising 73.35% for implementation smells and 21.42% for design smells. We also found that the increase in code smells is greater for more complex coding tasks and for more advanced topics, such as those involving object-orientated concepts.
Conclusion: In terms of code smells, LLM's performances on various coding task complexities and topics are highly correlated to the quality of human written code in the corresponding scenarios. However, the quality of LLM generated code is noticeably poorer than human written code. 

**Abstract (ZH)**: 背景：大型语言模型（LLMs）越来越多地用于生成程序代码。关于生成代码的功能正确性已有大量研究，但对代码质量的研究相对较少。
目标：在本研究中，我们提出了一种基于场景的方法来评估LLM生成代码的质量，以识别需要改进LLM生成代码质量的最薄弱场景。
方法：该方法衡量代码异味，这是代码质量的重要指标，并将其与来自专业编写代码的参考解决方案形成的基线进行比较。测试数据集根据代码主题和编码任务的复杂性分为多个子集，以代表使用LLM进行代码生成的不同场景。我们还将介绍一种自动化测试系统，并报告针对四款最先进的LLM（Gemini Pro、ChatGPT、Codex和Falcon）生成的Java程序的实验结果。
结果：我们发现，LLM生成的代码相较于参考解决方案具有更高的代码异味发生率。Falcon表现最差，代码异味增加42.28%，其次是Gemini Pro（62.07%）、ChatGPT（65.05%）、最后是Codex（84.97%）。所有LLM的平均代码异味增加率为63.34%，其中实现异味占73.35%，设计异味占21.42%。我们还发现，对于更复杂的编码任务和更高级的主题（如涉及面向对象的概念），代码异味的增加更为显著。
结论：在代码异味方面，LLM在不同编码任务复杂性和主题上的表现与相应场景中人工编写代码的质量高度相关。然而，LLM生成代码的质量明显低于人工编写代码。 

---
# Learning Robust Diffusion Models from Imprecise Supervision 

**Title (ZH)**: 从模糊监督中学习 robust 分布模型 

**Authors**: Dong-Dong Wu, Jiacheng Cui, Wei Wang, Zhiqiang She, Masashi Sugiyama  

**Link**: [PDF](https://arxiv.org/pdf/2510.03016)  

**Abstract**: Conditional diffusion models have achieved remarkable success in various generative tasks recently, but their training typically relies on large-scale datasets that inevitably contain imprecise information in conditional inputs. Such supervision, often stemming from noisy, ambiguous, or incomplete labels, will cause condition mismatch and degrade generation quality. To address this challenge, we propose DMIS, a unified framework for training robust Diffusion Models from Imprecise Supervision, which is the first systematic study within diffusion models. Our framework is derived from likelihood maximization and decomposes the objective into generative and classification components: the generative component models imprecise-label distributions, while the classification component leverages a diffusion classifier to infer class-posterior probabilities, with its efficiency further improved by an optimized timestep sampling strategy. Extensive experiments on diverse forms of imprecise supervision, covering tasks of image generation, weakly supervised learning, and noisy dataset condensation demonstrate that DMIS consistently produces high-quality and class-discriminative samples. 

**Abstract (ZH)**: 基于不精确监督训练稳健扩散模型的统一框架 

---
# BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia 

**Title (ZH)**: BrainIB++: 结合图神经网络和信息瓶颈方法识别精神分裂症的功能脑生物标志物 

**Authors**: Tianzheng Hu, Qiang Li, Shu Liu, Vince D. Calhoun, Guido van Wingen, Shujian Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.03004)  

**Abstract**: The development of diagnostic models is gaining traction in the field of psychiatric disorders. Recently, machine learning classifiers based on resting-state functional magnetic resonance imaging (rs-fMRI) have been developed to identify brain biomarkers that differentiate psychiatric disorders from healthy controls. However, conventional machine learning-based diagnostic models often depend on extensive feature engineering, which introduces bias through manual intervention. While deep learning models are expected to operate without manual involvement, their lack of interpretability poses significant challenges in obtaining explainable and reliable brain biomarkers to support diagnostic decisions, ultimately limiting their clinical applicability. In this study, we introduce an end-to-end innovative graph neural network framework named BrainIB++, which applies the information bottleneck (IB) principle to identify the most informative data-driven brain regions as subgraphs during model training for interpretation. We evaluate the performance of our model against nine established brain network classification methods across three multi-cohort schizophrenia datasets. It consistently demonstrates superior diagnostic accuracy and exhibits generalizability to unseen data. Furthermore, the subgraphs identified by our model also correspond with established clinical biomarkers in schizophrenia, particularly emphasizing abnormalities in the visual, sensorimotor, and higher cognition brain functional network. This alignment enhances the model's interpretability and underscores its relevance for real-world diagnostic applications. 

**Abstract (ZH)**: 基于静息态功能磁共振成像的产前诊断模型的发展：BrainIB++图神经网络框架在精神疾病诊断中的应用 

---
# From high-frequency sensors to noon reports: Using transfer learning for shaft power prediction in maritime 

**Title (ZH)**: 从高频率传感器数据到午间报告：基于迁移学习的船舶轴功率预测 

**Authors**: Akriti Sharma, Dogan Altan, Dusica Marijan, Arnbjørn Maressa  

**Link**: [PDF](https://arxiv.org/pdf/2510.03003)  

**Abstract**: With the growth of global maritime transportation, energy optimization has become crucial for reducing costs and ensuring operational efficiency. Shaft power is the mechanical power transmitted from the engine to the shaft and directly impacts fuel consumption, making its accurate prediction a paramount step in optimizing vessel performance. Power consumption is highly correlated with ship parameters such as speed and shaft rotation per minute, as well as weather and sea conditions. Frequent access to this operational data can improve prediction accuracy. However, obtaining high-quality sensor data is often infeasible and costly, making alternative sources such as noon reports a viable option. In this paper, we propose a transfer learning-based approach for predicting vessels shaft power, where a model is initially trained on high-frequency data from a vessel and then fine-tuned with low-frequency daily noon reports from other vessels. We tested our approach on sister vessels (identical dimensions and configurations), a similar vessel (slightly larger with a different engine), and a different vessel (distinct dimensions and configurations). The experiments showed that the mean absolute percentage error decreased by 10.6 percent for sister vessels, 3.6 percent for a similar vessel, and 5.3 percent for a different vessel, compared to the model trained solely on noon report data. 

**Abstract (ZH)**: 随着全球海洋运输的发展，能源优化已成为降低运营成本和确保操作效率的关键。轴功率是发动机传递给轴的机械功率，直接影响燃料消耗，因此其准确预测是优化船舶性能的首要步骤。功率消耗与船速、轴每分钟转数以及天气和海况等因素高度相关。频繁获取这类操作数据可以提高预测准确性。然而，获得高质量的传感器数据往往既不可能又昂贵，因此可以考虑使用中午报告作为替代数据源。本文提出了一种基于迁移学习的方法，先在船舶高频数据上训练模型，然后使用其他船舶的低频每日中午报告进行微调。我们分别在姊妹船（相同尺寸和配置）、类似船舶（稍大且发动机不同）和不同船舶（不同尺寸和配置）上测试了该方法。实验结果显示，与仅使用中午报告数据训练的模型相比，姊妹船的平均绝对百分比误差降低了10.6%，类似船舶降低了3.6%，不同船舶降低了5.3%。 

---
# Untargeted Jailbreak Attack 

**Title (ZH)**: 无目标 Jailbreak 攻击 

**Authors**: Xinzhe Huang, Wenjing Hu, Tianhang Zheng, Kedong Xiu, Xiaojun Jia, Di Wang, Zhan Qin, Kui Ren  

**Link**: [PDF](https://arxiv.org/pdf/2510.02999)  

**Abstract**: Existing gradient-based jailbreak attacks on Large Language Models (LLMs), such as Greedy Coordinate Gradient (GCG) and COLD-Attack, typically optimize adversarial suffixes to align the LLM output with a predefined target response. However, by restricting the optimization objective as inducing a predefined target, these methods inherently constrain the adversarial search space, which limit their overall attack efficacy. Furthermore, existing methods typically require a large number of optimization iterations to fulfill the large gap between the fixed target and the original model response, resulting in low attack efficiency.
To overcome the limitations of targeted jailbreak attacks, we propose the first gradient-based untargeted jailbreak attack (UJA), aiming to elicit an unsafe response without enforcing any predefined patterns. Specifically, we formulate an untargeted attack objective to maximize the unsafety probability of the LLM response, which can be quantified using a judge model. Since the objective is non-differentiable, we further decompose it into two differentiable sub-objectives for optimizing an optimal harmful response and the corresponding adversarial prompt, with a theoretical analysis to validate the decomposition. In contrast to targeted jailbreak attacks, UJA's unrestricted objective significantly expands the search space, enabling a more flexible and efficient exploration of LLM this http URL evaluations demonstrate that \textsc{UJA} can achieve over 80\% attack success rates against recent safety-aligned LLMs with only 100 optimization iterations, outperforming the state-of-the-art gradient-based attacks such as I-GCG and COLD-Attack by over 20\%. 

**Abstract (ZH)**: 现有的基于梯度的大型语言模型（LLMs）逃狱攻击，如贪婪坐标梯度（GCG）和COLD-Attack，通常优化对抗后缀以使LLM输出与预定义的目标响应对齐。然而，通过将优化目标限制为诱导预定义目标，这些方法内在地限制了对抗搜索的空间，这限制了它们的整体攻击效果。此外，现有方法通常需要大量的优化迭代来弥补固定目标和原始模型响应之间的巨大差距，导致攻击效率低下。

为了克服定向逃狱攻击的限制，我们提出了第一个基于梯度的无定向逃狱攻击（UJA），旨在引致一种不安全的响应而不强加任何预先定义的模式。具体而言，我们提出了一个无定向攻击目标，以最大化LLM响应的安全性概率，这可以通过法官模型进行量化。由于目标是非可微的，我们进一步将其分解为两个可微的子目标，用于优化最优有害响应及其相应的对抗提示，并进行了理论分析来验证分解的有效性。与定向逃狱攻击相比，UJA的无限制目标显著扩展了搜索空间，使在LLM上进行更灵活和高效的探索成为可能。评估结果表明，\textsc{UJA}仅需100次优化迭代就能在对抗最近的安全对齐的LLM时实现超过80%的攻击成功率，优于包括I-GCG和COLD-Attack在内的最先进的基于梯度的攻击，性能高出超过20%。 

---
# AI Generated Child Sexual Abuse Material - What's the Harm? 

**Title (ZH)**: 由AI生成的儿童性虐待材料：有何危害？ 

**Authors**: Caoilte Ó Ciardha, John Buckley, Rebecca S. Portnoff  

**Link**: [PDF](https://arxiv.org/pdf/2510.02978)  

**Abstract**: The development of generative artificial intelligence (AI) tools capable of producing wholly or partially synthetic child sexual abuse material (AI CSAM) presents profound challenges for child protection, law enforcement, and societal responses to child exploitation. While some argue that the harmfulness of AI CSAM differs fundamentally from other CSAM due to a perceived absence of direct victimization, this perspective fails to account for the range of risks associated with its production and consumption. AI has been implicated in the creation of synthetic CSAM of children who have not previously been abused, the revictimization of known survivors of abuse, the facilitation of grooming, coercion and sexual extortion, and the normalization of child sexual exploitation. Additionally, AI CSAM may serve as a new or enhanced pathway into offending by lowering barriers to engagement, desensitizing users to progressively extreme content, and undermining protective factors for individuals with a sexual interest in children. This paper provides a primer on some key technologies, critically examines the harms associated with AI CSAM, and cautions against claims that it may function as a harm reduction tool, emphasizing how some appeals to harmlessness obscure its real risks and may contribute to inertia in ecosystem responses. 

**Abstract (ZH)**: 生成式人工智能工具生成合成儿童性剥削材料的发展给儿童保护、执法和社会应对儿童 exploitation 带来了深刻挑战。 

---
# Corrosion Risk Estimation for Heritage Preservation: An Internet of Things and Machine Learning Approach Using Temperature and Humidity 

**Title (ZH)**: 遗产保护中的腐蚀风险估计：基于温度和湿度的物联网与机器学习方法 

**Authors**: Reginald Juan M. Mercado, Muhammad Kabeer, Haider Al-Obaidy, Rosdiadee Nordin  

**Link**: [PDF](https://arxiv.org/pdf/2510.02973)  

**Abstract**: Proactive preservation of steel structures at culturally significant heritage sites like the San Sebastian Basilica in the Philippines requires accurate corrosion forecasting. This study developed an Internet of Things hardware system connected with LoRa wireless communications to monitor heritage buildings with steel structures. From a three year dataset generated by the IoT system, we built a machine learning framework for predicting atmospheric corrosion rates using only temperature and relative humidity data. Deployed via a Streamlit dashboard with ngrok tunneling for public access, the framework provides real-time corrosion monitoring and actionable preservation recommendations. This minimal-data approach is scalable and cost effective for heritage sites with limited monitoring resources, showing that advanced regression can extract accurate corrosion predictions from basic meteorological data enabling proactive preservation of culturally significant structures worldwide without requiring extensive sensor networks 

**Abstract (ZH)**: 菲律宾圣塞巴斯蒂安大教堂等历史文化遗址中钢铁结构的主动保护需要准确的腐蚀预测。本研究开发了一个物联网硬件系统，结合LoRa无线通讯监测具有钢铁结构的文化遗产建筑。基于物联网系统生成的三年数据集，我们构建了一个仅使用温度和相对湿度数据的机器学习框架来预测大气腐蚀速率。该框架通过Streamlit仪表板和ngrok隧道供公众访问，提供实时腐蚀监测和可行的保护建议。这种数据最小化方法对于监测资源有限的历史文化遗址具有可扩展性和成本效益，表明先进的回归分析可以从基本的气象数据中提取出准确的腐蚀预测，从而在全球范围内对具有文化意义的建筑结构进行主动保护，而无需庞大的传感器网络。 

---
# Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines 

**Title (ZH)**: 在临床证据中 grounding 大型语言模型：查询英国国家卫生与临床优化研究所临床指南的检索增强生成系统 

**Authors**: Matthew Lewis, Samuel Thio, Richard JB Dobson, Spiros Denaxas  

**Link**: [PDF](https://arxiv.org/pdf/2510.02967)  

**Abstract**: This paper presents the development and evaluation of a Retrieval-Augmented Generation (RAG) system for querying the United Kingdom's National Institute for Health and Care Excellence (NICE) clinical guidelines using Large Language Models (LLMs). The extensive length and volume of these guidelines can impede their utilisation within a time-constrained healthcare system, a challenge this project addresses through the creation of a system capable of providing users with precisely matched information in response to natural language queries. The system's retrieval architecture, composed of a hybrid embedding mechanism, was evaluated against a database of 10,195 text chunks derived from three hundred guidelines. It demonstrates high performance, with a Mean Reciprocal Rank (MRR) of 0.814, a Recall of 81% at the first chunk and of 99.1% within the top ten retrieved chunks, when evaluated on 7901 queries.
The most significant impact of the RAG system was observed during the generation phase. When evaluated on a manually curated dataset of seventy question-answer pairs, RAG-enhanced models showed substantial gains in performance. Faithfulness, the measure of whether an answer is supported by the source text, was increased by 64.7 percentage points to 99.5% for the RAG-enhanced O4-Mini model and significantly outperformed the medical-focused Meditron3-8B LLM, which scored 43%. This, combined with a perfect Context Precision score of 1 for all RAG-enhanced models, confirms the system's ability to prevent information fabrication by grounding its answers in relevant source material. This study thus establishes RAG as an effective, reliable, and scalable approach for applying generative AI in healthcare, enabling cost-effective access to medical guidelines. 

**Abstract (ZH)**: 本研究介绍了使用大型语言模型（LLMs）查询英国国家卫生与护理卓越研究所（NICE）临床指南的检索增强生成（RAG）系统的开发与评估。由于这些指南的篇幅和数量庞大，可能限制了其在时间有限的医疗系统中的使用，该项目通过创建一个能够针对自然语言查询提供精确匹配信息的系统来应对这一挑战。该系统的检索架构，由混合嵌入机制组成，在针对包含300份指南的10,195个文本片段的数据库进行评估时，展示了高度性能，其中平均互换秩（MRR）为0.814，第一个片段召回率为81%，前十个检索片段召回率为99.1%，评估了7901个查询。

RAG系统的最显著影响体现在生成阶段。在对手动整理的70个问答对数据集进行评估时，增强后的RAG模型在性能上取得了显著提升。忠实度，衡量答案是否由原文支持的指标，对于增强后的O4-Mini模型从43%提高到了99.5%，显著优于专注于医疗领域的Meditron3-8B大型语言模型。结合所有增强后的RAG模型在上下文精确度上的完美得分为1，这证明了该系统能够通过将答案扎根于相关来源材料来防止信息篡改。因此，本研究确立了RAG作为一种有效、可靠且可扩展的方法，在医疗健康领域应用生成式人工智能，从而实现低成本访问医疗指南。 

---
# Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning 

**Title (ZH)**: 遍历风险测度：迈向持续强化学习的风险意识基础 

**Authors**: Juan Sebastian Rojas, Chi-Guhn Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.02945)  

**Abstract**: Continual reinforcement learning (continual RL) seeks to formalize the notions of lifelong learning and endless adaptation in RL. In particular, the aim of continual RL is to develop RL agents that can maintain a careful balance between retaining useful information and adapting to new situations. To date, continual RL has been explored almost exclusively through the lens of risk-neutral decision-making, in which the agent aims to optimize the expected (or mean) long-run performance. In this work, we present the first formal theoretical treatment of continual RL through the lens of risk-aware decision-making, in which the agent aims to optimize a reward-based measure of long-run performance beyond the mean. In particular, we show that the classical theory of risk measures, widely used as a theoretical foundation in non-continual risk-aware RL, is, in its current form, incompatible with the continual setting. Then, building on this insight, we extend risk measure theory into the continual setting by introducing a new class of ergodic risk measures that are compatible with continual learning. Finally, we provide a case study of risk-aware continual learning, along with empirical results, which show the intuitive appeal and theoretical soundness of ergodic risk measures. 

**Abstract (ZH)**: 持续强化学习（持续RL）旨在形式化终身学习和无尽适应的概念。特别是在持续RL中，目标是开发能够在保留有用信息和适应新情况之间保持谨慎平衡的RL代理。到目前为止，持续RL几乎完全通过风险中性决策制定的视角进行探索，其中代理的目标是最大化长期性能的期望值（或平均值）。在本工作中，我们通过风险感知决策制定的视角首次为持续RL提供了形式化的理论处理，其中代理旨在优化超出平均值的基于奖励的长期性能度量。特别是在此工作中，我们表明了广泛用于非持续风险感知RL理论基础的经典风险测度理论，在当前形式下无法适用于持续学习的环境。基于此认识，我们通过引入与持续学习兼容的新一类遍历风险测度，将风险测度理论扩展到了持续学习的环境。最后，我们提供了风险感知持续学习的案例研究，并给出了实验证据，证明了遍历风险测度的直观吸引力和理论严谨性。 

---
# Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights 

**Title (ZH)**: 基于大型视觉-语言模型的多模态颈动脉风险分层：基准测试、微调与临床见解 

**Authors**: Daphne Tsolissou, Theofanis Ganitidis, Konstantinos Mitsis, Stergios CHristodoulidis, Maria Vakalopoulou, Konstantina Nikita  

**Link**: [PDF](https://arxiv.org/pdf/2510.02922)  

**Abstract**: Reliable risk assessment for carotid atheromatous disease remains a major clinical challenge, as it requires integrating diverse clinical and imaging information in a manner that is transparent and interpretable to clinicians. This study investigates the potential of state-of-the-art and recent large vision-language models (LVLMs) for multimodal carotid plaque assessment by integrating ultrasound imaging (USI) with structured clinical, demographic, laboratory, and protein biomarker data. A framework that simulates realistic diagnostic scenarios through interview-style question sequences is proposed, comparing a range of open-source LVLMs, including both general-purpose and medically tuned models. Zero-shot experiments reveal that even if they are very powerful, not all LVLMs can accurately identify imaging modality and anatomy, while all of them perform poorly in accurate risk classification. To address this limitation, LLaVa-NeXT-Vicuna is adapted to the ultrasound domain using low-rank adaptation (LoRA), resulting in substantial improvements in stroke risk stratification. The integration of multimodal tabular data in the form of text further enhances specificity and balanced accuracy, yielding competitive performance compared to prior convolutional neural network (CNN) baselines trained on the same dataset. Our findings highlight both the promise and limitations of LVLMs in ultrasound-based cardiovascular risk prediction, underscoring the importance of multimodal integration, model calibration, and domain adaptation for clinical translation. 

**Abstract (ZH)**: 基于最新视觉-语言模型的颈动脉斑块评估：一种结合超声成像与结构化临床、人口统计、实验室和蛋白质生物标志物数据的方法 

---
# WavInWav: Time-domain Speech Hiding via Invertible Neural Network 

**Title (ZH)**: WavInWav：通过可逆神经网络的时域语音隐藏 

**Authors**: Wei Fan, Kejiang Chen, Xiangkun Wang, Weiming Zhang, Nenghai Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02915)  

**Abstract**: Data hiding is essential for secure communication across digital media, and recent advances in Deep Neural Networks (DNNs) provide enhanced methods for embedding secret information effectively. However, previous audio hiding methods often result in unsatisfactory quality when recovering secret audio, due to their inherent limitations in the modeling of time-frequency relationships. In this paper, we explore these limitations and introduce a new DNN-based approach. We use a flow-based invertible neural network to establish a direct link between stego audio, cover audio, and secret audio, enhancing the reversibility of embedding and extracting messages. To address common issues from time-frequency transformations that degrade secret audio quality during recovery, we implement a time-frequency loss on the time-domain signal. This approach not only retains the benefits of time-frequency constraints but also enhances the reversibility of message recovery, which is vital for practical applications. We also add an encryption technique to protect the hidden data from unauthorized access. Experimental results on the VCTK and LibriSpeech datasets demonstrate that our method outperforms previous approaches in terms of subjective and objective metrics and exhibits robustness to various types of noise, suggesting its utility in targeted secure communication scenarios. 

**Abstract (ZH)**: 基于深度神经网络的音频隐写 advances in deep neural networks (dnn) for secure communication through enhanced audio embedding 

---
# FeDABoost: Fairness Aware Federated Learning with Adaptive Boosting 

**Title (ZH)**: 基于公平性意识的自适应提升联邦学习 

**Authors**: Tharuka Kasthuri Arachchige, Veselka Boeva, Shahrooz Abghari  

**Link**: [PDF](https://arxiv.org/pdf/2510.02914)  

**Abstract**: This work focuses on improving the performance and fairness of Federated Learning (FL) in non IID settings by enhancing model aggregation and boosting the training of underperforming clients. We propose FeDABoost, a novel FL framework that integrates a dynamic boosting mechanism and an adaptive gradient aggregation strategy. Inspired by the weighting mechanism of the Multiclass AdaBoost (SAMME) algorithm, our aggregation method assigns higher weights to clients with lower local error rates, thereby promoting more reliable contributions to the global model. In parallel, FeDABoost dynamically boosts underperforming clients by adjusting the focal loss focusing parameter, emphasizing hard to classify examples during local training. We have evaluated FeDABoost on three benchmark datasets MNIST, FEMNIST, and CIFAR10, and compared its performance with those of FedAvg and Ditto. The results show that FeDABoost achieves improved fairness and competitive performance. 

**Abstract (ZH)**: 本研究旨在通过增强模型聚合和提升表现不佳的客户端训练，在非IID设置中改善联邦学习（FL）的性能和公平性。我们提出了一种新的FL框架FeDABoost，该框架结合了动态增强机制和自适应梯度聚合策略。受Multiclass AdaBoost（SAMME）算法加权机制的启发，我们的聚合方法将较高权重赋予本地错误率较低的客户端，从而促进其对全局模型的更可靠贡献。同时，FeDABoost通过调整局部训练中的焦点损失聚焦参数，动态提升表现不佳的客户端，强调难以分类的样本。我们在三个基准数据集MNIST、FEMNIST和CIFAR10上评估了FeDABoost，并将其性能与FedAvg和Ditto进行了比较。结果表明，FeDABoost在公平性和性能方面得到了改善。 

---
# FinReflectKG - MultiHop: Financial QA Benchmark for Reasoning with Knowledge Graph Evidence 

**Title (ZH)**: FinReflectKG - 多跳：金融问答知识图谱推理基准 

**Authors**: Abhinav Arun, Reetu Raj Harsh, Bhaskarjit Sarmah, Stefano Pasquali  

**Link**: [PDF](https://arxiv.org/pdf/2510.02906)  

**Abstract**: Multi-hop reasoning over financial disclosures is often a retrieval problem before it becomes a reasoning or generation problem: relevant facts are dispersed across sections, filings, companies, and years, and LLMs often expend excessive tokens navigating noisy context. Without precise Knowledge Graph (KG)-guided selection of relevant context, even strong reasoning models either fail to answer or consume excessive tokens, whereas KG-linked evidence enables models to focus their reasoning on composing already retrieved facts. We present FinReflectKG - MultiHop, a benchmark built on FinReflectKG, a temporally indexed financial KG that links audited triples to source chunks from S&P 100 filings (2022-2024). Mining frequent 2-3 hop subgraph patterns across sectors (via GICS taxonomy), we generate financial analyst style questions with exact supporting evidence from the KG. A two-phase pipeline first creates QA pairs via pattern-specific prompts, followed by a multi-criteria quality control evaluation to ensure QA validity. We then evaluate three controlled retrieval scenarios: (S1) precise KG-linked paths; (S2) text-only page windows centered on relevant text spans; and (S3) relevant page windows with randomizations and distractors. Across both reasoning and non-reasoning models, KG-guided precise retrieval yields substantial gains on the FinReflectKG - MultiHop QA benchmark dataset, boosting correctness scores by approximately 24 percent while reducing token utilization by approximately 84.5 percent compared to the page window setting, which reflects the traditional vector retrieval paradigm. Spanning intra-document, inter-year, and cross-company scopes, our work underscores the pivotal role of knowledge graphs in efficiently connecting evidence for multi-hop financial QA. We also release a curated subset of the benchmark (555 QA Pairs) to catalyze further research. 

**Abstract (ZH)**: 多跳推理金融披露数据往往是检索问题：相关事实分布在不同节、文件、公司和年份之间，大型语言模型在处理噪声上下文时常常消耗过多的tokens。缺乏精准的知识图谱(KG)指导选择相关上下文，即使是强大的推理模型也可能无法作答或消耗过多tokens，而KG链接的证据可使模型专注于组合已检索的事实。我们提出了FinReflectKG-MultiHop基准，基于FinReflectKG，这是一个时间索引的金融KG，将审计 triples 连接到 S&P 100 的文件（2022-2024）。通过GICS分类学跨行业挖掘频繁的2-3跳子图模式，从KG中生成符合金融分析师风格的问题，并提供精确的支持证据。该基准采用两阶段管道生成问题-答案对，并进行多标准质量控制评估以确保有效。我们随后评估了三种受控检索场景：(S1) 精确的KG链接路径；(S2) 中心化于相关文本段落的纯文本页面窗口；以及(S3) 带有随机化和干扰项的相关页面窗口。在推理模型和非推理模型中，KG指导的精确检索在FinReflectKG-MultiHop问题-答案基准数据集上取得了显著优势，正确率提高了约24%，token利用率降低了约84.5%，相较于纯文本页面窗口设置，这反映了传统的向量检索范式。我们的研究跨内部文档、跨年和跨公司范围，强调了知识图谱在高效连接多跳金融问题-答案证据方面的作用。我们还发布了一个精编的基准子集（555个问题-答案对），以促进进一步研究。 

---
# DMark: Order-Agnostic Watermarking for Diffusion Large Language Models 

**Title (ZH)**: DMark：面向扩散大型语言模型的无序依赖水印技术 

**Authors**: Linyu Wu, Linhao Zhong, Wenjie Qu, Yuexin Li, Yue Liu, Shengfang Zhai, Chunhua Shen, Jiaheng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02902)  

**Abstract**: Diffusion large language models (dLLMs) offer faster generation than autoregressive models while maintaining comparable quality, but existing watermarking methods fail on them due to their non-sequential decoding. Unlike autoregressive models that generate tokens left-to-right, dLLMs can finalize tokens in arbitrary order, breaking the causal design underlying traditional watermarks. We present DMark, the first watermarking framework designed specifically for dLLMs. DMark introduces three complementary strategies to restore watermark detectability: predictive watermarking uses model-predicted tokens when actual context is unavailable; bidirectional watermarking exploits both forward and backward dependencies unique to diffusion decoding; and predictive-bidirectional watermarking combines both approaches to maximize detection strength. Experiments across multiple dLLMs show that DMark achieves 92.0-99.5% detection rates at 1% false positive rate while maintaining text quality, compared to only 49.6-71.2% for naive adaptations of existing methods. DMark also demonstrates robustness against text manipulations, establishing that effective watermarking is feasible for non-autoregressive language models. 

**Abstract (ZH)**: DMark：一种专为扩散大语言模型设计的水印框架 

---
# Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with multiplicative noise 

**Title (ZH)**: 熵正则化线性二次控制在乘性噪声情况下的策略梯度全局收敛性 

**Authors**: Gabriel Diaz, Lucky Li, Wenhao Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02896)  

**Abstract**: Reinforcement Learning (RL) has emerged as a powerful framework for sequential decision-making in dynamic environments, particularly when system parameters are unknown. This paper investigates RL-based control for entropy-regularized Linear Quadratic control (LQC) problems with multiplicative noises over an infinite time horizon. First, we adapt the Regularized Policy Gradient (RPG) algorithm to stochastic optimal control settings, proving that despite the non-convexity of the problem, RPG converges globally under conditions of gradient domination and near-smoothness. Second, based on zero-order optimization approach, we introduce a novel model free RL algorithm: Sample-Based Regularized Policy Gradient (SB-RPG). SB-RPG operates without knowledge of system parameters yet still retains strong theoretical guarantees of global convergence. Our model leverages entropy regularization to accelerate convergence and address the exploration versus exploitation trade-off inherent in RL. Numerical simulations validate the theoretical results and demonstrate the efficacy of SB-RPG in unknown-parameters environments. 

**Abstract (ZH)**: 基于强化学习的熵正则化线性二次控制问题在无限时间 horizont 上的研究 

---
# Representing Beauty: Towards a Participatory but Objective Latent Aesthetics 

**Title (ZH)**: 呈现美：向着一种参与式但客观的潜在美学方向探索 

**Authors**: Alexander Michael Rusnak  

**Link**: [PDF](https://arxiv.org/pdf/2510.02869)  

**Abstract**: What does it mean for a machine to recognize beauty? While beauty remains a culturally and experientially compelling but philosophically elusive concept, deep learning systems increasingly appear capable of modeling aesthetic judgment. In this paper, we explore the capacity of neural networks to represent beauty despite the immense formal diversity of objects for which the term applies. By drawing on recent work on cross-model representational convergence, we show how aesthetic content produces more similar and aligned representations between models which have been trained on distinct data and modalities - while unaesthetic images do not produce more aligned representations. This finding implies that the formal structure of beautiful images has a realist basis - rather than only as a reflection of socially constructed values. Furthermore, we propose that these realist representations exist because of a joint grounding of aesthetic form in physical and cultural substance. We argue that human perceptual and creative acts play a central role in shaping these the latent spaces of deep learning systems, but that a realist basis for aesthetics shows that machines are not mere creative parrots but can produce novel creative insights from the unique vantage point of scale. Our findings suggest that human-machine co-creation is not merely possible, but foundational - with beauty serving as a teleological attractor in both cultural production and machine perception. 

**Abstract (ZH)**: 机器如何识别美：一种含义及其背后的实证基础探究 

---
# Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation 

**Title (ZH)**: 基于约束满足方法的Wordle求解：新颖启发式方法与跨词库验证 

**Authors**: Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Kamrujjaman, Eftakhar Ahmed Arnob, Ahsan Habib Tareq  

**Link**: [PDF](https://arxiv.org/pdf/2510.02855)  

**Abstract**: Wordle presents an algorithmically rich testbed for constraint satisfaction problem (CSP) solving. While existing solvers rely on information-theoretic entropy maximization or frequency-based heuristics without formal constraint treatment, we present the first comprehensive CSP formulation of Wordle with novel constraint-aware solving strategies. We introduce CSP-Aware Entropy, computing information gain after constraint propagation rather than on raw candidate sets, and a Probabilistic CSP framework integrating Bayesian word-frequency priors with logical constraints. Through evaluation on 2,315 English words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9% success rate, a statistically significant 1.7% improvement over Forward Checking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms versus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3 percentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic CSP achieves 100% success across all noise levels (0-20%) through constraint recovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates 88% success with zero language-specific tuning, validating that core CSP principles transfer across languages despite an 11.2 percentage point gap from linguistic differences (p<0.001, Fisher's exact test). Our open-source implementation with 34 unit tests achieving 91% code coverage provides reproducible infrastructure for CSP research. The combination of formal CSP treatment, constraint-aware heuristics, probabilistic-logical integration, robustness analysis, and cross-lexicon validation establishes new performance benchmarks demonstrating that principled constraint satisfaction techniques outperform classical information-theoretic and learning-based approaches for structured puzzle-solving domains. 

**Abstract (ZH)**: Wordle 提供了一个算法丰富的约束满足问题 (CSP) 解决测试平台。尽管现有的求解器依赖于信息论熵最大化或基于频率的启发式方法而缺乏形式化的约束处理，我们提出了第一个全面的 Wordle CSP 形式化，并引入了新颖的约束感知求解策略。我们引入了 CSP 意识熵，通过约束传播后计算信息增益，而不是在原始候选集上计算，并结合贝叶斯词频先验和逻辑约束提出了概率 CSP 框架。通过在 2,315 个英文字词上的评估，CSP 意识熵实现了平均每词 3.54 次猜测和 99.9% 的成功率达到，相对于前向检查显示出统计显著性的 1.7% 的改进（t=-4.82, p<0.001, Cohen's d=0.07），同时运行时间快 46%（平均每词 12.9 毫秒对 23.7 毫秒）。在 10% 的噪声下，CSP 意识方法保持了 5.3 个百分点的优势（29.0% 对 23.7%，p=0.041），而概率 CSP 通过约束恢复机制在所有噪声水平（0-20%）下实现了 100% 的成功。跨语言验证在 500 个西班牙语词上的结果显示了 88% 的成功率，无需特定语言调整，验证了尽管存在 11.2 个百分点的语言差异，核心 CSP 原理在不同语言中依然有效（p<0.001，Fisher 精确检验）。我们的开源实现包含 34 个单元测试，覆盖率 91%，为 CSP 研究提供了可重复的基础设施。结合形式化的 CSP 处理、约束意识启发式方法、概率-逻辑集成、稳健性分析和跨语言验证，建立了新的性能基准，表明基于原则的约束满足技术在结构化谜题求解领域优于经典的信息论和学习导向方法。 

---
# Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech 

**Title (ZH)**: Flamed-TTS: 流匹配注意力自由模型实现高效的生成和动态节奏文本-to-语音 

**Authors**: Hieu-Nghia Huynh-Nguyen, Huynh Nguyen Dang, Ngoc-Son Nguyen, Van Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2510.02848)  

**Abstract**: Zero-shot Text-to-Speech (TTS) has recently advanced significantly, enabling models to synthesize speech from text using short, limited-context prompts. These prompts serve as voice exemplars, allowing the model to mimic speaker identity, prosody, and other traits without extensive speaker-specific data. Although recent approaches incorporating language models, diffusion, and flow matching have proven their effectiveness in zero-shot TTS, they still encounter challenges such as unreliable synthesis caused by token repetition or unexpected content transfer, along with slow inference and substantial computational overhead. Moreover, temporal diversity-crucial for enhancing the naturalness of synthesized speech-remains largely underexplored. To address these challenges, we propose Flamed-TTS, a novel zero-shot TTS framework that emphasizes low computational cost, low latency, and high speech fidelity alongside rich temporal diversity. To achieve this, we reformulate the flow matching training paradigm and incorporate both discrete and continuous representations corresponding to different attributes of speech. Experimental results demonstrate that Flamed-TTS surpasses state-of-the-art models in terms of intelligibility, naturalness, speaker similarity, acoustic characteristics preservation, and dynamic pace. Notably, Flamed-TTS achieves the best WER of 4% compared to the leading zero-shot TTS baselines, while maintaining low latency in inference and high fidelity in generated speech. Code and audio samples are available at our demo page this https URL. 

**Abstract (ZH)**: 零样本文本到语音（TTS）最近取得了显著进展，使模型能够使用短的、背景有限的提示从文本合成立音。这些提示作为声音示例，使模型能够在无需大量特定说话人数据的情况下模仿说话人身份、语调和其他特征。尽管最近结合了语言模型、扩散和流匹配的方法在零样本TTS方面证明了其有效性，但仍面临合成不可靠等问题，如由标记重复引起的问题或意外内容转移，此外，还有推理速度慢和大量计算开销的问题。此外，时间多样性对于提高合成语音的自然度至关重要，但仍然很少被探索。为了解决这些问题，我们提出了Flamed-TTS，这是首个强调低计算成本、低延迟、高语音保真度以及丰富时间多样性相结合的零样本TTS框架。通过重新定义流匹配训练范式并结合与语音不同属性相对应的离散和连续表示，我们实现了这一目标。实验结果表明，Flamed-TTS 在可理解性、自然度、说话人相似性、声学特征保持以及动态节奏方面超越了现有最先进的模型。值得注意的是，Flamed-TTS 达到了 4% 的最佳词误差率（WER），同时在推理延迟低且生成语音保真度高。详细代码和音频样本可在我们的演示页面获取：https://demo.com。 

---
# Knowledge-Aware Modeling with Frequency Adaptive Learning for Battery Health Prognostics 

**Title (ZH)**: 基于频率自适应学习的知识aware建模方法及其在电池健康预测中的应用 

**Authors**: Vijay Babu Pamshetti, Wei Zhang, Sumei Sun, Jie Zhang, Yonggang Wen, Qingyu Yan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02839)  

**Abstract**: Battery health prognostics are critical for ensuring safety, efficiency, and sustainability in modern energy systems. However, it has been challenging to achieve accurate and robust prognostics due to complex battery degradation behaviors with nonlinearity, noise, capacity regeneration, etc. Existing data-driven models capture temporal degradation features but often lack knowledge guidance, which leads to unreliable long-term health prognostics. To overcome these limitations, we propose Karma, a knowledge-aware model with frequency-adaptive learning for battery capacity estimation and remaining useful life prediction. The model first performs signal decomposition to derive battery signals in different frequency bands. A dual-stream deep learning architecture is developed, where one stream captures long-term low-frequency degradation trends and the other models high-frequency short-term dynamics. Karma regulates the prognostics with knowledge, where battery degradation is modeled as a double exponential function based on empirical studies. Our dual-stream model is used to optimize the parameters of the knowledge with particle filters to ensure physically consistent and reliable prognostics and uncertainty quantification. Experimental study demonstrates Karma's superior performance, achieving average error reductions of 50.6% and 32.6% over state-of-the-art algorithms for battery health prediction on two mainstream datasets, respectively. These results highlight Karma's robustness, generalizability, and potential for safer and more reliable battery management across diverse applications. 

**Abstract (ZH)**: 电池健康预测对于确保现代能源系统中的安全、效率和可持续性至关重要。然而，由于电池退化行为的非线性、噪声、容量再生等因素，准确且 robust 的预测一直具有挑战性。现有的数据驱动模型虽然可以捕捉到时间退化特征，但往往缺乏知识引导，导致长期健康预测不可靠。为克服这些限制，我们提出了一种名为 Karma 的知识感知模型，该模型具有频率自适应学习能力，用于电池容量估计和剩余使用寿命预测。该模型首先进行信号分解，以在不同频率带中提取电池信号。开发了一种双流深度学习架构，其中一条流捕捉长期低频退化趋势，另一条流建模高频短期动态。Karma 通过知识调节预测，其中电池退化基于经验研究被建模为双指数函数。我们的双流模型通过粒子滤波优化知识的参数，以确保物理上一致且可靠的预测和不确定性量化。实验研究表明，Karma 在两个主流数据集上的电池健康预测性能明显优于现有先进算法，平均误差分别降低了 50.6% 和 32.6%。这些结果突显了 Karma 在不同应用中实现更安全且更可靠电池管理的稳健性、泛化能力和潜力。 

---
# Evaluating Large Language Models for IUCN Red List Species Information 

**Title (ZH)**: 评估大型语言模型在IUCN红色名录物种信息中的应用 

**Authors**: Shinya Uryu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02830)  

**Abstract**: Large Language Models (LLMs) are rapidly being adopted in conservation to address the biodiversity crisis, yet their reliability for species evaluation is uncertain. This study systematically validates five leading models on 21,955 species across four core IUCN Red List assessment components: taxonomy, conservation status, distribution, and threats. A critical paradox was revealed: models excelled at taxonomic classification (94.9%) but consistently failed at conservation reasoning (27.2% for status assessment). This knowledge-reasoning gap, evident across all models, suggests inherent architectural constraints, not just data limitations. Furthermore, models exhibited systematic biases favoring charismatic vertebrates, potentially amplifying existing conservation inequities. These findings delineate clear boundaries for responsible LLM deployment: they are powerful tools for information retrieval but require human oversight for judgment-based decisions. A hybrid approach is recommended, where LLMs augment expert capacity while human experts retain sole authority over risk assessment and policy. 

**Abstract (ZH)**: 大型语言模型（LLMs）在保护领域迅速应用以应对生物多样性危机，但其在物种评价中的可靠性尚不确定。本研究系统验证了五种领先模型在41955个物种上的评估，涵盖国际自然保护联盟红色名录的四个核心评估组件：分类学、保护状况、分布和威胁。研究揭示了一个关键的悖论：模型在分类学分类上表现出色（94.9%），但在保护推理上却持续失败（状态评估仅为27.2%）。这种知识-推理差距在所有模型中普遍存在，表明存在内在的架构限制，而不仅仅是数据限制。此外，模型显示出系统性的偏见，偏向于 charismatic 脊椎动物，这可能会加剧现有的保护不平等性。这些发现明确了负责任地部署大型语言模型的边界：它们是信息检索的强大工具，但在基于判断的决策上需要人类监督。推荐采用混合方法，其中大型语言模型增强专家能力，而人类专家保留对风险评估和政策制定的独家权威。 

---
# A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media 

**Title (ZH)**: 一种基于社交媒体的可解释文本型人格评估的计算框架 

**Authors**: Matej Gjurković  

**Link**: [PDF](https://arxiv.org/pdf/2510.02811)  

**Abstract**: Personality refers to individual differences in behavior, thinking, and feeling. With the growing availability of digital footprints, especially from social media, automated methods for personality assessment have become increasingly important. Natural language processing (NLP) enables the analysis of unstructured text data to identify personality indicators. However, two main challenges remain central to this thesis: the scarcity of large, personality-labeled datasets and the disconnect between personality psychology and NLP, which restricts model validity and interpretability. To address these challenges, this thesis presents two datasets -- MBTI9k and PANDORA -- collected from Reddit, a platform known for user anonymity and diverse discussions. The PANDORA dataset contains 17 million comments from over 10,000 users and integrates the MBTI and Big Five personality models with demographic information, overcoming limitations in data size, quality, and label coverage. Experiments on these datasets show that demographic variables influence model validity. In response, the SIMPA (Statement-to-Item Matching Personality Assessment) framework was developed - a computational framework for interpretable personality assessment that matches user-generated statements with validated questionnaire items. By using machine learning and semantic similarity, SIMPA delivers personality assessments comparable to human evaluations while maintaining high interpretability and efficiency. Although focused on personality assessment, SIMPA's versatility extends beyond this domain. Its model-agnostic design, layered cue detection, and scalability make it suitable for various research and practical applications involving complex label taxonomies and variable cue associations with target concepts. 

**Abstract (ZH)**: 个性指的是行为、思维和情感方面的个体差异。随着数字足迹，尤其是来自社交媒体的数据日益增多，自动化的人格评估方法变得愈加重要。自然语言处理（NLP）使对非结构化文本数据进行分析以识别人格指标成为可能。然而，这一论文的核心挑战仍然是大数据集的稀缺性和人格心理学与NLP之间的脱节，这限制了模型的有效性和可解释性。为应对这些挑战，本论文提出了两个数据集——MBTI9k和PANDORA，并从以匿名性和多样化讨论著称的Reddit平台收集数据。PANDORA数据集包含了超过10,000名用户的1700万条评论，并将MBTI和大五人格模型与人口统计信息相结合，克服了数据量、质量和标签覆盖率的限制。在这些数据集上的实验表明，人口统计变量影响模型的有效性。针对此，开发了SIMPA（陈述到项目匹配人格评估）框架——一种计算框架，用于解释性人格评估，通过将用户生成的陈述与验证的问卷项目匹配。SIMPA使用机器学习和语义相似性，提供的人格评估结果与人类评估相当，同时保持了高可解释性和高效性。尽管主要集中于人格评估，SIMPA的多功能性超越了这一领域。其模型无偏的设计、多层提示检测和可扩展性使其适用于涉及复杂标签分类和多种提示与目标概念关联的各种研究和实际应用。 

---
# Dissecting Transformers: A CLEAR Perspective towards Green AI 

**Title (ZH)**: 解析 Transformers：一条通往绿色人工智能的清晰路径 

**Authors**: Hemang Jain, Shailender Goyal, Divyansh Pandey, Karthik Vaidhyanathan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02810)  

**Abstract**: The rapid adoption of Large Language Models (LLMs) has raised significant environmental concerns. Unlike the one-time cost of training, LLM inference occurs continuously at a global scale and now dominates the AI energy footprint. Yet, most sustainability studies report only coarse, model-level metrics due to the lack of fine-grained measurement methods, treating energy efficiency more as an afterthought than as a primary objective. We present the first fine-grained empirical analysis of inference energy across core components of transformer architecture. We propose a novel methodology, Component-Level Energy Assessment via Repeated sampling (CLEAR), to overcome temporal mismatch between microsecond scale component execution and monitoring of millisecond (ms) scale energy sensors. Using CLEAR, we evaluate 15 models spanning four distinct architecture types and consistently keep component-wise energy variance below 9.5\% while capturing more than 90\% of the model's total energy as individual components. Our empirical analysis reveals that Attention blocks consume significantly more energy per floating-point operation (FLOP), indicating that energy consumption is not proportionally aligned with FLOP counts. This shows that FLOPs alone fail to capture the true energy cost at a component level. Our findings establish detailed component-level energy baselines and provide insight as an initial step to build energy-efficient transformer models through component-level optimizations. 

**Abstract (ZH)**: 大型语言模型的快速采用引起了 significant 的环境关注。不同于一次性训练成本，推理持续在全球范围内进行，并现在主导了人工智能的能源足迹。然而，大多数可持续性研究仅报告粗略的模型级别指标，由于缺乏精细粒度的测量方法，将能效更多地视为一种附带结果而非主要目标。我们首次对变压器架构核心组件的推理能耗进行了精细粒度的经验分析。我们提出了一种新颖的方法——组件级能耗评估通过重复采样（CLEAR），以克服微秒级组件执行与毫秒级能耗传感器监控之间的时间不匹配问题。使用 CLEAR，我们评估了涵盖四种不同架构类型的 15 个模型，并在各个组件上保持能耗变异率低于 9.5% 的同时，捕获了模型总能耗的 90% 以上。我们的经验分析揭示了注意力模块每浮点运算（FLOP）能耗显著增加，表明能耗与 FLOP 计数不成比例。这表明 FLOPs 不能准确反映组件级别的真实能耗。我们的研究建立了详细的组件级别能耗基线，并为通过组件级优化构建高效变压器模型提供了一种初始步骤。 

---
# Relevance-Aware Thresholding in Online Conformal Prediction for Time Series 

**Title (ZH)**: 基于时序的在线同变预测中的相关性意识阈值化 

**Authors**: Théo Dupuy, Binbin Xu, Stéphane Perrey, Jacky Montmain, Abdelhak Imoussaten  

**Link**: [PDF](https://arxiv.org/pdf/2510.02809)  

**Abstract**: Uncertainty quantification has received considerable interest in recent works in Machine Learning. In particular, Conformal Prediction (CP) gains ground in this field. For the case of time series, Online Conformal Prediction (OCP) becomes an option to address the problem of data distribution shift over time. Indeed, the idea of OCP is to update a threshold of some quantity (whether the miscoverage level or the quantile) based on the distribution observation. To evaluate the performance of OCP methods, two key aspects are typically considered: the coverage validity and the prediction interval width minimization. Recently, new OCP methods have emerged, offering long-run coverage guarantees and producing more informative intervals. However, during the threshold update step, most of these methods focus solely on the validity of the prediction intervals~--~that is, whether the ground truth falls inside or outside the interval~--~without accounting for their relevance. In this paper, we aim to leverage this overlooked aspect. Specifically, we propose enhancing the threshold update step by replacing the binary evaluation (inside/outside) with a broader class of functions that quantify the relevance of the prediction interval using the ground truth. This approach helps prevent abrupt threshold changes, potentially resulting in narrower prediction intervals. Indeed, experimental results on real-world datasets suggest that these functions can produce tighter intervals compared to existing OCP methods while maintaining coverage validity. 

**Abstract (ZH)**: 不确定性量化在机器学习Recent Works中受到了广泛关注，特别是在 conformal预测领域。对于时间序列情况，在线 conformal预测(OCP)成为处理随时间变化的数据分布偏移问题的一种选择。实际上，OCP的核心思想是根据分布观察更新某一量的阈值（无论是覆盖率还是分位数）。为了评估OCP方法的性能，通常考虑两个关键方面：预测区间覆盖的有效性和预测区间宽度的最小化。最近，新兴的OCP方法提供了长期覆盖保证，并生成更具信息量的区间。然而，在阈值更新步骤中，大多数方法仅关注预测区间的有效性——即真实值是否落入或未落入区间——而不考虑其相关性。本文旨在利用这一被忽视的方面。具体来说，我们建议通过将二元评估（包含/不包含）替换为量化预测区间相关性的函数族，来增强阈值更新步骤。这种方法有助于防止阈值突然变化，从而可能产生更窄的预测区间。事实上，实世界数据集上的实验结果表明，与现有OCP方法相比，这些函数可以在保持覆盖有效性的前提下，生成更紧的区间。 

---
# Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving 

**Title (ZH)**: 工作区挑战基于视觉的大规模场景轨迹规划：走向缓解与稳健自动驾驶 

**Authors**: Yifan Liao, Zhen Sun, Xiaoyun Qiu, Zixiao Zhao, Wenbing Tang, Xinlei He, Xinhu Zheng, Tianwei Zhang, Xinyi Huang, Xingshuo Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.02803)  

**Abstract**: Visual Language Models (VLMs), with powerful multimodal reasoning capabilities, are gradually integrated into autonomous driving by several automobile manufacturers to enhance planning capability in challenging environments. However, the trajectory planning capability of VLMs in work zones, which often include irregular layouts, temporary traffic control, and dynamically changing geometric structures, is still unexplored. To bridge this gap, we conduct the \textit{first} systematic study of VLMs for work zone trajectory planning, revealing that mainstream VLMs fail to generate correct trajectories in $68.0%$ of cases. To better understand these failures, we first identify candidate patterns via subgraph mining and clustering analysis, and then confirm the validity of $8$ common failure patterns through human verification. Building on these findings, we propose REACT-Drive, a trajectory planning framework that integrates VLMs with Retrieval-Augmented Generation (RAG). Specifically, REACT-Drive leverages VLMs to convert prior failure cases into constraint rules and executable trajectory planning code, while RAG retrieves similar patterns in new scenarios to guide trajectory generation. Experimental results on the ROADWork dataset show that REACT-Drive yields a reduction of around $3\times$ in average displacement error relative to VLM baselines under evaluation with Qwen2.5-VL. In addition, REACT-Drive yields the lowest inference time ($0.58$s) compared with other methods such as fine-tuning ($17.90$s). We further conduct experiments using a real vehicle in 15 work zone scenarios in the physical world, demonstrating the strong practicality of REACT-Drive. 

**Abstract (ZH)**: 视觉语言模型（VLMs）在工作区轨迹规划中的系统研究：REACT-Drive框架降低规划误差并提高推理效率 

---
# OptunaHub: A Platform for Black-Box Optimization 

**Title (ZH)**: OptunaHub: 一个黑盒优化平台 

**Authors**: Yoshihiko Ozaki, Shuhei Watanabe, Toshihiko Yanase  

**Link**: [PDF](https://arxiv.org/pdf/2510.02798)  

**Abstract**: Black-box optimization (BBO) drives advances in domains such as AutoML and Materials Informatics, yet research efforts often remain fragmented across domains. We introduce OptunaHub (this https URL), a community platform that centralizes BBO methods and benchmarks. OptunaHub provides unified Python APIs, a contributor package registry, and a web interface to promote searchability and cross-domain research. OptunaHub aims to foster a virtuous cycle of contributions and applications. The source code is publicly available in the optunahub, optunahub-registry, and optunahub-web repositories under the Optuna organization on GitHub (this https URL). 

**Abstract (ZH)**: 黑箱优化（BBO）推动了诸如自动化机器学习（AutoML）和材料信息学等领域的发展，但研究努力在不同领域间往往保持分散状态。我们介绍了OptunaHub（https://optuna.org/hub），这是一个社区平台，旨在集中黑箱优化方法和基准测试。OptunaHub提供统一的Python API、贡献者包注册表以及网页界面，以促进可搜索性和跨领域研究。OptunaHub旨在促进贡献和应用的良性循环。源代码在GitHub（https://github.com/optuna）的optunahub、optunahub-registry和optunahub-web存储库中公开可用。 

---
# Pareto-optimal Non-uniform Language Generation 

**Title (ZH)**: 帕累托最优非均匀语言生成 

**Authors**: Moses Charikar, Chirag Pabbaraju  

**Link**: [PDF](https://arxiv.org/pdf/2510.02795)  

**Abstract**: Kleinberg and Mullainathan (2024) recently proposed an interesting model for language generation in the limit: Given a countable collection of languages, and an adversary enumerating the strings of some language $L$ from the collection, the objective is to generate new strings from the target language, such that all strings generated beyond some finite time are valid. Li, Raman and Tewari (2024) and Charikar and Pabbaraju (2024) showed strong non-uniform generation guarantees in this model, giving algorithms that generate new valid strings from $L$ after seeing a number of distinct input strings $t(L)$ that depends only on $L$ (and the collection), but not the enumeration order. However, for both these works, the language-wise generation times $t(L)$ of the algorithm can be strictly sub-optimal.
In this work, we study Pareto-optimality of non-uniform language generation in the limit. We propose an algorithm, whose generation times $t^\star(L)$ are (almost) Pareto-optimal: any other algorithm whose generation time for some language $L$ is strictly smaller than $t^\star(L)$, must satisfy that its generation time for some other language $L'$ is strictly worse than $t^\star(L')$. Pareto-optimality is essentially the best that one can achieve for non-uniform generation. Our algorithmic framework conveniently adapts to further give Pareto-optimal non-uniform generation algorithms in the practically motivated settings of noisy as well as representative generation. 

**Abstract (ZH)**: Kleinberg和Mullainathan (2024)提出的语言生成极限模型：基于可数语言集合和对手按某种语言$L$的字符串枚举，目标是从目标语言生成新字符串，使得生成的字符串在某一时点后均有效。Li, Raman和Tewari (2024)以及Charikar和Pabbaraju (2024)展示了在这种模型下的强大非统一生成保证，提供了在看到数量为$t(L)$的不同输入字符串后生成新有效字符串$L$的算法，$t(L)$仅依赖于$L$（及其集合），而不依赖于枚举顺序。然而，对于这两项工作中的算法，语言层面的生成时间$t(L)$可能是严格次优的。在这项工作中，我们研究极限下非统一语言生成的帕累托最优性。我们提出了一个算法，其生成时间$t^\star(L)$几乎是帕累托最优的：对于某些语言$L$，如果另一算法的生成时间严格小于$t^\star(L)$，那么它在其他语言$L'$上的生成时间必须严格劣于$t^\star(L')$。帕累托最优性实际上是非统一生成所能达到的最佳效果。我们的算法框架方便地适用于进一步给出在噪声以及代表性生成等实际驱动设置下的帕累托最优非统一生成算法。 

---
# MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding 

**Title (ZH)**: MaskCD: 减轻LVLM幻觉的图像头部屏蔽对比解码方法 

**Authors**: Jingyuan Deng, Yujiu Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02790)  

**Abstract**: Large vision-language models (LVLMs) have shown remarkable performance in visual-language understanding for downstream multimodal tasks. While their capabilities are improving, problems emerge simultaneously. Among those problems, the hallucinations have attracted much attention, which stands for the phenomenon where LVLMs generate contradictory content to their input visual and text contents. Many approaches have been proposed to deal with this issue, such as contrastive decoding and attention manipulation. However, contrastive decoding methods struggle in constructing appropriate contrastive samples, and attention manipulation methods are highly sensitive, lacking stability. In this work, we propose image head Masked Contrastive Decoding (MaskCD). Our approach utilizes the "image heads" in LVLMs, masking them to construct contrastive samples for contrastive decoding. We evaluated MaskCD on LLaVA-1.5-7b and Qwen-VL-7b, using various benchmarks such as CHAIR, POPE, AMBER and MME. The results demonstrate that MaskCD effectively alleviates the phenomenon of hallucinations and retains the general capabilities of LVLMs. Corresponding resources could be found at: this https URL . 

**Abstract (ZH)**: Large 视觉-语言模型 (LVLMs) 在下游多模态任务中的视觉-语言理解方面展现了 remarkable 绩效。尽管其能力在提升，同时出现了一些问题，其中幻觉现象尤为引人关注，指的是 LVLMs 生成与输入视觉和文本内容矛盾的内容。许多方法被提出以应对这一问题，如对比解码和注意力 manipulation。然而，对比解码方法在构建合适的对比样本方面存在困难，注意力 manipulation 方法则不稳定且灵敏。本文提出了基于 “图像头部” 的 Masked 对比解码 (MaskCD)。我们的方法利用 LVLMs 中的 “图像头部”，将其遮蔽以构建对比样本进行对比解码。我们在 LLaVA-1.5-7b 和 Qwen-VL-7b 上使用了 CHAIR、POPE、AMBER 和 MME 等基准进行评估。实验结果表明，MaskCD 有效缓解了幻觉现象，并保持了 LVLMs 的一般能力。相关资源可在此处找到：this https URL。 

---
# Align Your Query: Representation Alignment for Multimodality Medical Object Detection 

**Title (ZH)**: 对齐你的查询：多模态医疗目标检测的表示对齐 

**Authors**: Ara Seo, Bryan Sangwoo Kim, Hyungjin Chung, Jong Chul Ye  

**Link**: [PDF](https://arxiv.org/pdf/2510.02789)  

**Abstract**: Medical object detection suffers when a single detector is trained on mixed medical modalities (e.g., CXR, CT, MRI) due to heterogeneous statistics and disjoint representation spaces. To address this challenge, we turn to representation alignment, an approach that has proven effective for bringing features from different sources into a shared space. Specifically, we target the representations of DETR-style object queries and propose a simple, detector-agnostic framework to align them with modality context. First, we define modality tokens: compact, text-derived embeddings encoding imaging modality that are lightweight and require no extra annotations. We integrate the modality tokens into the detection process via Multimodality Context Attention (MoCA), mixing object-query representations via self-attention to propagate modality context within the query set. This preserves DETR-style architectures and adds negligible latency while injecting modality cues into object queries. We further introduce QueryREPA, a short pretraining stage that aligns query representations to their modality tokens using a task-specific contrastive objective with modality-balanced batches. Together, MoCA and QueryREPA produce modality-aware, class-faithful queries that transfer effectively to downstream training. Across diverse modalities trained altogether, the proposed approach consistently improves AP with minimal overhead and no architectural modifications, offering a practical path toward robust multimodality medical object detection. Project page: this https URL. 

**Abstract (ZH)**: 医疗物体检测在使用混合医学模态（例如，X射线、CT、MRI）训练单个检测器时由于异质统计和分离的表示空间而受到影响。为了解决这一挑战，我们转向了表示对齐的方法，这种方法已被证明能够将不同来源的特征带入共享空间。具体地，我们针对DETRE-style物体查询的表示，并提出了一种简单且与检测器无关的框架来将其与模态上下文对齐。首先，我们定义了模态令牌：紧凑的、文本衍生的嵌入，编码成像模态，轻量级且无需额外注释。我们通过多模态上下文注意力（MoCA）将模态令牌集成到检测过程中，利用自注意力机制混合物体查询表示，在查询集中传递模态上下文。这种方法保持了DETRE-style架构并在几乎不增加延迟的情况下将模态线索注入物体查询中。我们进一步引入了QueryREPA，这是一种简短的预训练阶段，使用特定任务对比目标并以模态平衡的批次对查询表示进行模态令牌对齐。结合MoCA和QueryREPA，生成模态意识、类别忠实的查询，有效地转移至下游训练。在整个多种模态共同训练中，所提出的方法在几乎没有额外开销和不修改架构的情况下一致提高了AP，提供了一条走向稳健多模态医疗物体检测的实用路径。项目页面：this https URL。 

---
# Fusing Multi- and Hyperspectral Satellite Data for Harmful Algal Bloom Monitoring with Self-Supervised and Hierarchical Deep Learning 

**Title (ZH)**: 多光谱与高光谱卫星数据融合用于有害藻华监测的自我监督和分层深度学习方法 

**Authors**: Nicholas LaHaye, Kelly M. Luis, Michelle M. Gierach  

**Link**: [PDF](https://arxiv.org/pdf/2510.02763)  

**Abstract**: We present a self-supervised machine learning framework for detecting and mapping harmful algal bloom (HAB) severity and speciation using multi-sensor satellite data. By fusing reflectance data from operational instruments (VIIRS, MODIS, Sentinel-3, PACE) with TROPOMI solar-induced fluorescence (SIF), our framework, called SIT-FUSE, generates HAB severity and speciation products without requiring per-instrument labeled datasets. The framework employs self-supervised representation learning, hierarchical deep clustering to segment phytoplankton concentrations and speciations into interpretable classes, validated against in-situ data from the Gulf of Mexico and Southern California (2018-2025). Results show strong agreement with total phytoplankton, Karenia brevis, Alexandrium spp., and Pseudo-nitzschia spp. measurements. This work advances scalable HAB monitoring in label-scarce environments while enabling exploratory analysis via hierarchical embeddings: a critical step toward operationalizing self-supervised learning for global aquatic biogeochemistry. 

**Abstract (ZH)**: 我们提出了一种自监督机器学习框架，通过多传感器卫星数据检测和映射有害藻华（HAB）的严重程度和种类。该框架名为SIT-FUSE，通过融合来自操作仪器（VIIRS、MODIS、Sentinel-3、PACE）的反射数据与TROPOMI太阳诱导荧光（SIF）数据，生成HAB的严重程度和种类产品，无需依赖单个仪器的标注数据集。该框架采用自监督表示学习和分层深度聚类方法，对佛罗里达湾和南加州（2018-2025年）的实地数据进行验证，结果显示与微型浮游植物、Karenia brevis、Alexandrium spp. 和 Pseudo-nitzschia spp. 的测量值高度一致。这项工作在标签稀少的环境中推进了可扩展的HAB监测，并通过层次嵌入支持探索性分析：这是实现自监督学习在地球水文生物地球化学中的操作化的一个关键步骤。 

---
# Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology 

**Title (ZH)**: 数字病理学中脑肿瘤分类的分层广义类别发现 

**Authors**: Matthias Perkonigg, Patrick Rockenschaub, Georg Göbel, Adelheid Wöhrer  

**Link**: [PDF](https://arxiv.org/pdf/2510.02760)  

**Abstract**: Accurate brain tumor classification is critical for intra-operative decision making in neuro-oncological surgery. However, existing approaches are restricted to a fixed set of predefined classes and are therefore unable to capture patterns of tumor types not available during training. Unsupervised learning can extract general-purpose features, but it lacks the ability to incorporate prior knowledge from labelled data, and semi-supervised methods often assume that all potential classes are represented in the labelled data. Generalized Category Discovery (GCD) aims to bridge this gap by categorizing both known and unknown classes within unlabelled data. To reflect the hierarchical structure of brain tumor taxonomies, in this work, we introduce Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT), a novel approach that integrates hierarchical clustering with contrastive learning. Our method extends contrastive learning based GCD by incorporating a novel semi-supervised hierarchical clustering loss. We evaluate HGCD-BT on OpenSRH, a dataset of stimulated Raman histology brain tumor images, achieving a +28% improvement in accuracy over state-of-the-art GCD methods for patch-level classification, particularly in identifying previously unseen tumor categories. Furthermore, we demonstrate the generalizability of HGCD-BT on slide-level classification of hematoxylin and eosin stained whole-slide images from the Digital Brain Tumor Atlas, confirming its utility across imaging modalities. 

**Abstract (ZH)**: 准确的脑肿瘤分类对于神经肿瘤手术中的 intra-operative 决策至关重要。然而，现有方法仅限于固定的预定义分类集，因此无法捕捉训练期间不可用的肿瘤类型模式。无监督学习可以提取通用特征，但缺乏将标记数据中的先验知识纳入的能力，而半监督方法通常假设所有潜在类别都在标记数据中得到代表。泛化类别发现（GCD）旨在通过将已知和未知类别归类到无标记数据中来弥合这一差距。为了反映脑肿瘤分类体系结构的层次结构，本文介绍了一种名为 Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT) 的新颖方法，该方法结合了层次聚类和对比学习。我们的方法通过引入一种新颖的半监督层次聚类损失，扩展了基于对比学习的 GCD。我们在 OpenSRH 数据集上评估了 HGCD-BT，该数据集包含刺激拉曼组化脑肿瘤图像，实现了与最先进的 GCD 方法相比在 patch 级分类上的 +28% 准确率提升，尤其是在识别以前未见过的肿瘤类别方面。此外，我们展示了 HGCD-BT 在 Digital Brain Tumor Atlas 中的压片级别分类中的通用性，使用苏木精和伊红染色的全切片图像，证明了其在不同成像模态中的实用性。 

---
# Prototyping Digital Social Spaces through Metaphor-Driven Design: Translating Spatial Concepts into an Interactive Social Simulation 

**Title (ZH)**: 基于隐喻驱动设计的数字社会空间原型设计：将空间概念转化为互动社会模拟 

**Authors**: Yoojin Hong, Martina Di Paola, Braahmi Padmakumar, Hwi Joon Lee, Mahnoor Shafiq, Joseph Seering  

**Link**: [PDF](https://arxiv.org/pdf/2510.02759)  

**Abstract**: Social media platforms are central to communication, yet their designs remain narrowly focused on engagement and scale. While researchers have proposed alternative visions for online spaces, these ideas are difficult to prototype within platform constraints. In this paper, we introduce a metaphor-driven system to help users imagine and explore new social media environments. The system translates users' metaphors into structured sets of platform features and generates interactive simulations populated with LLM-driven agents. To evaluate this approach, we conducted a study where participants created and interacted with simulated social media spaces. Our findings show that metaphors allow users to express distinct social expectations, and that perceived authenticity of the simulation depended on how well it captured dynamics like intimacy, participation, and temporal engagement. We conclude by discussing how metaphor-driven simulation can be a powerful design tool for prototyping alternative social architectures and expanding the design space for future social platforms. 

**Abstract (ZH)**: 社会媒体平台在交流中占据核心地位，但其设计依然狭隘地集中在参与度和规模上。尽管研究人员提出了在线空间的替代愿景，但在平台限制内进行原型设计仍然具有挑战性。在本文中，我们介绍了一种基于隐喻的系统，以帮助用户构想和探索新的社交媒体环境。该系统将用户的隐喻转换为结构化的平台功能集，并生成由LLM驱动的代理 populate 的交互式模拟。为了评估该方法，我们进行了一项研究，参与者创建并互动了模拟的社交媒体空间。我们的研究结果表明，隐喻使用户能够表达独特的社会期望，而模拟的感知真实性取决于它如何捕捉如亲密性、参与度和时间参与等动态特征。最后，我们讨论了基于隐喻的模拟如何成为一种强大的设计工具，用于原型设计替代的社会架构，并扩大未来社交媒体平台的设计空间。 

---
# SAE-RNA: A Sparse Autoencoder Model for Interpreting RNA Language Model Representations 

**Title (ZH)**: SAE-RNA：一种稀疏自编码模型，用于解析RNA语言模型表示 

**Authors**: Taehan Kim, Sangdae Nam  

**Link**: [PDF](https://arxiv.org/pdf/2510.02734)  

**Abstract**: Deep learning, particularly with the advancement of Large Language Models, has transformed biomolecular modeling, with protein advances (e.g., ESM) inspiring emerging RNA language models such as RiNALMo. Yet how and what these RNA Language Models internally encode about messenger RNA (mRNA) or non-coding RNA (ncRNA) families remains unclear. We present SAE- RNA, interpretability model that analyzes RiNALMo representations and maps them to known human-level biological features. Our work frames RNA interpretability as concept discovery in pretrained embeddings, without end-to-end retraining, and provides practical tools to probe what RNA LMs may encode about ncRNA families. The model can be extended to close comparisons between RNA groups, and supporting hypothesis generation about previously unrecognized relationships. 

**Abstract (ZH)**: 深度学习，特别是随着大型语言模型的发展，已经转变了生物分子建模，蛋白质进步（如ESM）启发了新兴的RNA语言模型（如RiNALMo）。然而，这些RNA语言模型内部如何以及有何种方式编码信使RNA（mRNA）或非编码RNA（ncRNA）家族的信息仍不清楚。我们提出了SAE-RNA，一种解释性模型，用于分析RiNALMo表示并将其与已知的人类级生物特征关联起来。我们的工作将RNA解释性构建为预训练嵌入的概念发现，并提供了一种实用的工具，以探究RNA LMs可能编码的ncRNA家族信息。该模型可以扩展到RNA组之间的密切比较，并支持对先前未知关系的假设生成。 

---
# TravelBench : Exploring LLM Performance in Low-Resource Domains 

**Title (ZH)**: TravelBench: 探究大语言模型在低资源领域中的性能 

**Authors**: Srinivas Billa, Xiaonan Jing  

**Link**: [PDF](https://arxiv.org/pdf/2510.02719)  

**Abstract**: Results on existing LLM benchmarks capture little information over the model capabilities in low-resource tasks, making it difficult to develop effective solutions in these domains. To address these challenges, we curated 14 travel-domain datasets spanning 7 common NLP tasks using anonymised data from real-world scenarios, and analysed the performance across LLMs. We report on the accuracy, scaling behaviour, and reasoning capabilities of LLMs in a variety of tasks. Our results confirm that general benchmarking results are insufficient for understanding model performance in low-resource tasks. Despite the amount of training FLOPs, out-of-the-box LLMs hit performance bottlenecks in complex, domain-specific scenarios. Furthermore, reasoning provides a more significant boost for smaller LLMs by making the model a better judge on certain tasks. 

**Abstract (ZH)**: 现有的大规模语言模型基准在低资源任务中对模型能力的捕捉信息有限，使得在这些领域中开发有效解决方案困难重重。为应对这些挑战，我们通过匿名化真实场景数据，整理了涵盖7种常见NLP任务的14个旅游领域数据集，并分析了这些数据集上多种语言模型的性能。我们报告了语言模型在多种任务中的准确率、扩展行为以及推理能力。我们的结果证实，通用基准测试结果不足以理解模型在低资源任务中的表现。尽管训练计算量巨大，开箱即用的语言模型在复杂且领域特定的场景中仍会遇到性能瓶颈。此外，推理对于较小的语言模型提供了更大的助力，使模型在某些任务上表现得更为出色。 

---
# CST-AFNet: A dual attention-based deep learning framework for intrusion detection in IoT networks 

**Title (ZH)**: CST-AFNet：物联网网络入侵检测的基于双注意力机制的深度学习框架 

**Authors**: Waqas Ishtiaq, Ashrafun Zannat, A.H.M. Shahariar Parvez, Md. Alamgir Hossain, Muntasir Hasan Kanchan, Muhammad Masud Tarek  

**Link**: [PDF](https://arxiv.org/pdf/2510.02717)  

**Abstract**: The rapid expansion of the Internet of Things (IoT) has revolutionized modern industries by enabling smart automation and real time connectivity. However, this evolution has also introduced complex cybersecurity challenges due to the heterogeneous, resource constrained, and distributed nature of these environments. To address these challenges, this research presents CST AFNet, a novel dual attention based deep learning framework specifically designed for robust intrusion detection in IoT networks. The model integrates multi scale Convolutional Neural Networks (CNNs) for spatial feature extraction, Bidirectional Gated Recurrent Units (BiGRUs) for capturing temporal dependencies, and a dual attention mechanism, channel and temporal attention, to enhance focus on critical patterns in the data. The proposed method was trained and evaluated on the Edge IIoTset dataset, a comprehensive and realistic benchmark containing more than 2.2 million labeled instances spanning 15 attack types and benign traffic, collected from a seven layer industrial testbed. Our proposed model achieves outstanding accuracy for both 15 attack types and benign traffic. CST AFNet achieves 99.97 percent accuracy. Moreover, this model demonstrates exceptional performance with macro averaged precision, recall, and F1 score all above 99.3 percent. Experimental results show that CST AFNet achieves superior detection accuracy, significantly outperforming traditional deep learning models. The findings confirm that CST AFNet is a powerful and scalable solution for real time cyber threat detection in complex IoT and IIoT environments, paving the way for more secure, intelligent, and adaptive cyber physical systems. 

**Abstract (ZH)**: 物联网(IoT)的快速扩展通过实现智能自动化和实时连接颠覆了现代工业，但这一演变也带来了复杂的网络安全挑战，尤其是由于这些环境的异构性、资源限制性和分布式特性。为应对这些挑战，本研究提出了一种名为CST AFNet的新型双注意机制深度学习框架，专门设计用于物联网网络中的稳健入侵检测。该模型结合了多尺度卷积神经网络(CNNs)进行空间特征提取、双向门控循环单元(BiGRUs)捕获时间依赖性，并引入了通道注意和时间注意双注意机制，以增强对数据中关键模式的关注。所提出的方法在Edge IIoTset数据集上进行了训练和评估，该数据集是一个全面且逼真的基准，包含超过220万标注实例，涵盖15种攻击类型和良性流量，来自一个七层工业测试床。我们的提出的模型在15种攻击类型和良性流量上均实现了卓越的准确性。CST AFNet的准确率达到99.97%。此外，该模型在宏观平均精确度、召回率和F1分数上均超过99.3%。实验结果表明，CST AFNet在检测准确性上表现出色，显著优于传统的深度学习模型。研究发现确认了CST AFNet在复杂物联网和工业物联网环境中实时网络威胁检测的强大和可扩展性解决方案，为更安全、智能且适应性强的网络物理系统铺平了道路。 

---
# A $1000\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps 

**Title (ZH)**: 一种基于大尺度网格地图路径规划的LLM增强算法，速度提升1000倍 

**Authors**: Junlin Zeng, Xin Zhang, Xiang Zhao, Yan Pan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02716)  

**Abstract**: Path planning in grid maps, arising from various applications, has garnered significant attention. Existing methods, such as A*, Dijkstra, and their variants, work well for small-scale maps but fail to address large-scale ones due to high search time and memory consumption. Recently, Large Language Models (LLMs) have shown remarkable performance in path planning but still suffer from spatial illusion and poor planning performance. Among all the works, LLM-A* \cite{meng2024llm} leverages LLM to generate a series of waypoints and then uses A* to plan the paths between the neighboring waypoints. In this way, the complete path is constructed. However, LLM-A* still suffers from high computational time for large-scale maps. To fill this gap, we conducted a deep investigation into LLM-A* and found its bottleneck, resulting in limited performance. Accordingly, we design an innovative LLM-enhanced algorithm, abbr. as iLLM-A*. iLLM-A* includes 3 carefully designed mechanisms, including the optimization of A*, an incremental learning method for LLM to generate high-quality waypoints, and the selection of the appropriate waypoints for A* for path planning. Finally, a comprehensive evaluation on various grid maps shows that, compared with LLM-A*, iLLM-A* \textbf{1) achieves more than $1000\times$ speedup on average, and up to $2349.5\times$ speedup in the extreme case, 2) saves up to $58.6\%$ of the memory cost, 3) achieves both obviously shorter path length and lower path length standard deviation.} 

**Abstract (ZH)**: 基于网格地图的路径规划因各种应用而备受关注。现有方法如A*和迪杰斯特拉算法及其变种在小型地图上表现良好，但在大型地图上由于搜索时间和内存消耗高而失效。最近，大型语言模型（LLMs）在路径规划方面显示出出色的性能，但仍存在空间错觉和规划性能不佳的问题。在所有相关工作中，LLM-A*利用LLM生成一系列航点，然后使用A*规划相邻航点之间的路径。通过这种方式，完整路径被构建出来。然而，LLM-A*在大型地图上仍存在较高的计算时间开销。为填补这一空白，我们对LLM-A*进行了深入研究，并发现其瓶颈，导致性能受限。据此，我们设计了一个创新的LLM增强算法，简称为iLLM-A*。iLLM-A*包括3个精心设计的机制，包括A*的优化、增量学习方法生成高质量航点以及选择适合作为A*路径规划的航点。最后，在各种网格地图上的综合评估显示，与LLM-A*相比，iLLM-A*在平均情况下实现超1000倍的加速，极端情况下甚至可达2349.5倍，节省高达58.6%的内存成本，并实现路径长度更短且路径长度标准差更低的效果。 

---
# Fully automated inverse co-optimization of templates and block copolymer blending recipes for DSA lithography 

**Title (ZH)**: 全自动化逆共优化模板和_block共聚物混合配方用于DSA光刻 

**Authors**: Yuhao Zhou, Huangyan Shen, Qingliang Song, Qingshu Dong, Jianfeng Li, Weihua Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.02715)  

**Abstract**: The directed self-assembly (DSA) of block copolymers (BCPs) offers a highly promising approach for the fabrication of contact holes or vertical interconnect access at sub-7nm technology nodes. To fabricate circular holes with precisely controlled size and positions, the self-assembly of block copolymers requires guidance from a properly designed template. Effectively parameterizing the template shape to enable efficient optimization remains a critical yet challenging problem. Moreover, the optimized template must possess excellent manufacturability for practical applications. In this work, we propose a Gaussian descriptor for characterizing the template shape with only two parameters. We further propose to use AB/AB binary blends instead of pure diblock copolymer to improve the adaptability of the block copolymer system to the template shape. The Bayesian optimization (BO) is applied to co-optimize the binary blend and the template shape. Our results demonstrate that BO based on the Gaussian descriptor can efficiently yield the optimal templates for diverse multi-hole patterns, all leading to highly matched self-assembled morphologies. Moreover, by imposing constraints on the variation of curvature of the template during optimization, superior manufacturability is ensured for each optimized template. It is noteworthy that each key parameter of the blend exhibits a relatively wide tunable window under the requirement of rather high precision. Our work provides valuable insights for advancing DSA technology, and thus potentially propels its practical applications forward. 

**Abstract (ZH)**: 基于高斯描述符的模板形状参数化及Bayesian优化在直接自组装中的应用 

---
# Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks 

**Title (ZH)**: 时间不一致性：大型语言模型对抗攻击稳健性的生存分析 

**Authors**: Yubo Li, Ramayya Krishnan, Rema Padman  

**Link**: [PDF](https://arxiv.org/pdf/2510.02712)  

**Abstract**: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversational degradation that characterize real-world interactions. In this work, we present the first comprehensive survival analysis of conversational AI robustness, analyzing 36,951 conversation turns across 9 state-of-the-art LLMs to model failure as a time-to-event process. Our survival modeling framework-employing Cox proportional hazards, Accelerated Failure Time, and Random Survival Forest approaches-reveals extraordinary temporal dynamics. We find that abrupt, prompt-to-prompt(P2P) semantic drift is catastrophic, dramatically increasing the hazard of conversational failure. In stark contrast, gradual, cumulative drift is highly protective, vastly reducing the failure hazard and enabling significantly longer dialogues. AFT models with interactions demonstrate superior performance, achieving excellent discrimination and exceptional calibration. These findings establish survival analysis as a powerful paradigm for evaluating LLM robustness, offer concrete insights for designing resilient conversational agents, and challenge prevailing assumptions about the necessity of semantic consistency in conversational AI Systems. 

**Abstract (ZH)**: 大型语言模型（LLMs）虽然革新了对话式AI，但在扩展的多轮对话中的鲁棒性仍 poorly understood，现有评估框架主要关注静态基准和单轮评估，无法捕捉到对话退化的时间动态特征，这在真实世界交互中尤为明显。在此项工作中，我们首次进行了全面的对话式AI鲁棒性生存分析，分析了9个先进大型语言模型中的36,951轮对话，将对话失败视为时间事件过程进行建模。我们运用Cox比例风险、加速失效时间以及随机生存森林方法构建的生存模型框架揭示了非凡的时间动态特征。研究发现，突然的、从指令到指令的语义漂移是灾难性的，显著增加了对话失败的风险。相比之下，渐进的、累积的漂移是保护性的，极大地降低了失败风险，使对话能够显著延长。交互作用的加速失效时间模型表现出卓越的性能，实现了优秀的区分能力和出色的校准。这些发现确立了生存分析作为评估大型语言模型鲁棒性的有力范式，提供了具体的设计稳健对话代理的见解，并挑战了对话式AI系统中语义一致性必要性的传统假设。 

---
# A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks 

**Title (ZH)**: 一种用于无人机网络入侵检测的新型统一轻量时空变换器方法 

**Authors**: Tarun Kumar Biswas, Ashrafun Zannat, Waqas Ishtiaq, Md. Alamgir Hossain  

**Link**: [PDF](https://arxiv.org/pdf/2510.02711)  

**Abstract**: The growing integration of drones across commercial, industrial, and civilian domains has introduced significant cybersecurity challenges, particularly due to the susceptibility of drone networks to a wide range of cyberattacks. Existing intrusion detection mechanisms often lack the adaptability, efficiency, and generalizability required for the dynamic and resource constrained environments in which drones operate. This paper proposes TSLT-Net, a novel lightweight and unified Temporal Spatial Transformer based intrusion detection system tailored specifically for drone networks. By leveraging self attention mechanisms, TSLT-Net effectively models both temporal patterns and spatial dependencies in network traffic, enabling accurate detection of diverse intrusion types. The framework includes a streamlined preprocessing pipeline and supports both multiclass attack classification and binary anomaly detection within a single architecture. Extensive experiments conducted on the ISOT Drone Anomaly Detection Dataset, consisting of more than 2.3 million labeled records, demonstrate the superior performance of TSLT-Net with 99.99 percent accuracy in multiclass detection and 100 percent in binary anomaly detection, while maintaining a minimal memory footprint of only 0.04 MB and 9722 trainable parameters. These results establish TSLT-Net as an effective and scalable solution for real time drone cybersecurity, particularly suitable for deployment on edge devices in mission critical UAV systems. 

**Abstract (ZH)**: 无人机网络的时空转换器基于新型轻量级统一入侵检测系统 

---
# RAMAC: Multimodal Risk-Aware Offline Reinforcement Learning and the Role of Behavior Regularization 

**Title (ZH)**: RAMAC：多模态风险意识离线强化学习及行为正则化的作用 

**Authors**: Kai Fukazawa, Kunal Mundada, Iman Soltani  

**Link**: [PDF](https://arxiv.org/pdf/2510.02695)  

**Abstract**: In safety-critical domains where online data collection is infeasible, offline reinforcement learning (RL) offers an attractive alternative but only if policies deliver high returns without incurring catastrophic lower-tail risk. Prior work on risk-averse offline RL achieves safety at the cost of value conservatism and restricted policy classes, whereas expressive policies are only used in risk-neutral settings. Here, we address this gap by introducing the \textbf{Risk-Aware Multimodal Actor-Critic (RAMAC)} framework, which couples an \emph{expressive generative actor} with a distributional critic. The RAMAC differentiates composite objective combining distributional risk and BC loss through the generative path, achieving risk-sensitive learning in complex multimodal scenarios. We instantiate RAMAC with diffusion and flow-matching actors and observe consistent gains in $\mathrm{CVaR}_{0.1}$ while maintaining strong returns on most Stochastic-D4RL tasks. Code: this https URL 

**Abstract (ZH)**: 在在线数据收集不可行的安全关键领域中，离线强化学习（RL）提供了一种有吸引力的替代方案，前提是策略能够实现高回报且不引发灾难性的下尾风险。先前关于风险厌恶的离线RL研究在确保安全性的同时牺牲了价值保守性和限制性的策略类别，而表现性强的策略仅在无风险偏好设置下使用。在这里，我们通过引入Risk-Aware Multimodal Actor-Critic (RAMAC)框架来弥补这一差距，该框架将一个表达性强的生成actor与分布性critic相结合。RAMAC通过生成路径区分结合了分布性风险和BC损失的复合目标，从而在复杂多模态场景中实现敏感风险学习。我们使用扩散和流匹配actor实例化RAMAC，在大多数Stochastic-D4RL任务中保持强劲回报的同时观察到$\mathrm{CVaR}_{0.1}$的一致改进。代码：this https URL 

---
# Fine-Tuning Diffusion Models via Intermediate Distribution Shaping 

**Title (ZH)**: 通过中间分布塑造 fine-tuning 微调扩散模型 

**Authors**: Gautham Govind Anil, Shaan Ul Haque, Nithish Kannen, Dheeraj Nagaraj, Sanjay Shakkottai, Karthikeyan Shanmugam  

**Link**: [PDF](https://arxiv.org/pdf/2510.02692)  

**Abstract**: Diffusion models are widely used for generative tasks across domains. While pre-trained diffusion models effectively capture the training data distribution, it is often desirable to shape these distributions using reward functions to align with downstream applications. Policy gradient methods, such as Proximal Policy Optimization (PPO), are widely used in the context of autoregressive generation. However, the marginal likelihoods required for such methods are intractable for diffusion models, leading to alternative proposals and relaxations. In this context, we unify variants of Rejection sAmpling based Fine-Tuning (RAFT) as GRAFT, and show that this implicitly performs PPO with reshaped rewards. We then introduce P-GRAFT to shape distributions at intermediate noise levels and demonstrate empirically that this can lead to more effective fine-tuning. We mathematically explain this via a bias-variance tradeoff. Motivated by this, we propose inverse noise correction to improve flow models without leveraging explicit rewards. We empirically evaluate our methods on text-to-image(T2I) generation, layout generation, molecule generation and unconditional image generation. Notably, our framework, applied to Stable Diffusion 2, improves over policy gradient methods on popular T2I benchmarks in terms of VQAScore and shows an $8.81\%$ relative improvement over the base model. For unconditional image generation, inverse noise correction improves FID of generated images at lower FLOPs/image. 

**Abstract (ZH)**: 扩散模型在跨领域生成任务中广泛应用。虽然预训练的扩散模型能够有效地捕捉训练数据分布，但在下游应用中常常需要使用奖励函数来调整这些分布。策略梯度方法，如近端策略优化（PPO），在自回归生成的上下文中广泛应用。然而，此类方法所需的边际似然对于扩散模型来说通常是不可计算的，从而导致了替代方案和放松。在此背景下，我们将排斥采样基于微调（RAFT）的各种变体统一为GRAFT，并表明这实际上是使用重塑后的奖励隐式执行PPO。然后，我们介绍了P-GRAFT，在中间噪声水平下重塑分布，并通过经验表明这可以导致更有效的微调。我们通过偏差-方差权衡的数学解释来说明这一点。受此启发，我们提出了逆噪声校正来提高流动模型的性能，而无需利用显式的奖励。我们在文本到图像生成、布局生成、分子生成和无条件图像生成中实验评估了我们的方法。值得注意的是，将我们的框架应用于Stable Diffusion 2，在流行的文字到图像基准测试中，VQAScore上优于策略梯度方法，并且相对于基础模型的相对改进达到8.81%。对于无条件图像生成，逆噪声校正降低了每张图像计算量的同时提高了生成图像的FID。 

---
# Can Data-Driven Dynamics Reveal Hidden Physics? There Is A Need for Interpretable Neural Operators 

**Title (ZH)**: 数据驱动的动力学能否揭示隐藏的物理规律？需要可解释的神经算子。 

**Authors**: Wenhan Gao, Jian Luo, Fang Wan, Ruichen Xu, Xiang Liu, Haipeng Xing, Yi Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02683)  

**Abstract**: Recently, neural operators have emerged as powerful tools for learning mappings between function spaces, enabling data-driven simulations of complex dynamics. Despite their successes, a deeper understanding of their learning mechanisms remains underexplored. In this work, we classify neural operators into two types: (1) Spatial domain models that learn on grids and (2) Functional domain models that learn with function bases. We present several viewpoints based on this classification and focus on learning data-driven dynamics adhering to physical principles. Specifically, we provide a way to explain the prediction-making process of neural operators and show that neural operator can learn hidden physical patterns from data. However, this explanation method is limited to specific situations, highlighting the urgent need for generalizable explanation methods. Next, we show that a simple dual-space multi-scale model can achieve SOTA performance and we believe that dual-space multi-spatio-scale models hold significant potential to learn complex physics and require further investigation. Lastly, we discuss the critical need for principled frameworks to incorporate known physics into neural operators, enabling better generalization and uncovering more hidden physical phenomena. 

**Abstract (ZH)**: 最近，神经算子作为学习函数空间之间映射的强有力工具而 emergence，使得复杂动态的数据驱动模拟成为可能。尽管它们取得了成功，但对其学习机制的理解仍需进一步探究。在本文中，我们将神经算子分为两类：（1）基于网格的空间域模型和（2）基于函数基的函数域模型。基于这种分类，我们提出了几种观点，并专注于遵循物理原理的数据驱动动力学学习。具体而言，我们提供了一种解释神经算子预测过程的方法，并展示了神经算子可以从数据中学习到隐藏的物理模式。然而，这种方法局限于特定情况，突显了通用解释方法的迫切需求。接下来，我们展示了简单的双空间多层次模型可以达到SOTA性能，并认为双空间多层次模型具有学习复杂物理的巨大潜力，需要进一步研究。最后，我们讨论了将已知物理原理融入神经算子的原理性框架的迫切需求，以提高泛化能力并揭示更多隐藏的物理现象。 

---
# To Compress or Not? Pushing the Frontier of Lossless GenAI Model Weights Compression with Exponent Concentration 

**Title (ZH)**: 是否压缩？以指数集中为基础推动无损GenAI模型权重压缩的前沿探索 

**Authors**: Zeyu Yang, Tianyi Zhang, Jianwen Xie, Chuan Li, Zhaozhuo Xu, Anshumali Shrivastava  

**Link**: [PDF](https://arxiv.org/pdf/2510.02676)  

**Abstract**: The scaling of Generative AI (GenAI) models into the hundreds of billions of parameters makes low-precision computation indispensable for efficient deployment. We argue that the fundamental solution lies in developing low-precision floating-point formats, which inherently provide numerical stability, memory savings, and hardware efficiency without dequantization overhead. In this paper, we present a theoretical and empirical study of an exponent concentration phenomenon in GenAI weights: exponents consistently exhibit low entropy across architectures and modalities. We show that this arises naturally from $\alpha$-stable distributions induced by stochastic gradient descent, and we prove tight bounds on the entropy of exponents. Our analysis establishes a theoretical compression limit near FP4.67, which motivates the design of a practical FP8 format. Building on these insights, we propose Exponent-Concentrated FP8 (ECF8), a lossless compression framework with entropy-aware encoding and GPU-optimized decoding. Experiments on LLMs and DiTs up to 671B parameters demonstrate up to 26.9% memory savings and 177.1% throughput acceleration, with perfectly lossless computations, i.e., no deviation in model outputs. Our results establish exponent concentration as a statistical law of trained models and open a principled path for lossless low-precision floating-point design in the FP8 era. 

**Abstract (ZH)**: Generative AI模型从数十亿参数扩展到数百亿参数使得低精度计算成为高效部署的必不可少手段。我们argue认为根本解决方案在于开发低精度浮点格式，这种格式本身就提供了数值稳定性、内存节省和硬件效率，而无需去量化开销。本文我们提出了生成AI权重中指数集中现象的理论和实证研究：指数在架构和模态之间始终保持低熵。我们证明了这种现象自然源自由随机梯度下降诱导的α稳定分布，并证明了指数熵的紧界。我们的分析确立了一个接近FP4.67的理论压缩极限，这促使设计出一种实用的FP8格式。基于这些见解，我们提出了指数集中FP8（ECF8），这是一种具有熵感知编码和GPU优化解码的无损压缩框架。针对参数多达671B的LLM和DiT模型的实验结果显示出高达26.9%的内存节省和177.1%的吞吐量加速，同时保持完全无损的计算，即模型输出无偏差。我们的结果确立了指数集中心理统计规律，并为FP8时代的无损低精度浮点数设计提供了一条原理性的路径。 

---
# HALO: Memory-Centric Heterogeneous Accelerator with 2.5D Integration for Low-Batch LLM Inference 

**Title (ZH)**: HALO：基于内存的二维半集成异构加速器用于低批次LLM推理 

**Authors**: Shubham Negi, Kaushik Roy  

**Link**: [PDF](https://arxiv.org/pdf/2510.02675)  

**Abstract**: The rapid adoption of Large Language Models (LLMs) has driven a growing demand for efficient inference, particularly in latency-sensitive applications such as chatbots and personalized assistants. Unlike traditional deep neural networks, LLM inference proceeds in two distinct phases: the prefill phase, which processes the full input sequence in parallel, and the decode phase, which generates tokens sequentially. These phases exhibit highly diverse compute and memory requirements, which makes accelerator design particularly challenging. Prior works have primarily been optimized for high-batch inference or evaluated only short input context lengths, leaving the low-batch and long context regime, which is critical for interactive applications, largely underexplored.
We propose HALO, a heterogeneous memory centric accelerator designed for these unique challenges of prefill and decode phases in low-batch LLM inference. HALO integrates HBM based Compute-in-DRAM (CiD) with an on-chip analog Compute-in-Memory (CiM), co-packaged using 2.5D integration. To further improve the hardware utilization, we introduce a phase-aware mapping strategy that adapts to the distinct demands of the prefill and decode phases. Compute bound operations in the prefill phase are mapped to CiM to exploit its high throughput matrix multiplication capability, while memory-bound operations in the decode phase are executed on CiD to benefit from reduced data movement within DRAM. Additionally, we present an analysis of the performance tradeoffs of LLMs under two architectural extremes: a fully CiD and a fully on-chip analog CiM design to highlight the need for a heterogeneous design. We evaluate HALO on LLaMA-2 7B and Qwen3 8B models. Our experimental results show that LLMs mapped to HALO achieve up to 18x geometric mean speedup over AttAcc, an attention-optimized mapping and 2.5x over CENT, a fully CiD based mapping. 

**Abstract (ZH)**: 大规模语言模型（LLMs）的快速采用推动了对高效推理的日益增长的需求，特别是在低延迟应用如聊天机器人和个人助理中。与传统的深度神经网络不同，LLM推理分为两个不同的阶段：并行处理完整输入序列的预填充阶段，和顺序生成令牌的解码阶段。这两个阶段的计算和内存需求高度不同，这使得加速器设计尤为具有挑战性。以往的工作主要针对高批次推理进行了优化，或者仅评估了较短的输入上下文长度，而对于对交互式应用至关重要的低批次和长上下文区间，相关的研究仍然不足。

我们提出了HALO，一种针对低批次LLM推理中预填充和解码阶段独特挑战的异构内存为中心的加速器。HALO结合了基于HBM的计算在内存中（CiD）与片上模拟计算在内存中（CiM）技术，并通过2.5D集成实现共封装。为了进一步提高硬件利用率，我们引入了一种基于阶段的映射策略，该策略能够适应预填充和解码阶段的不同需求。预填充阶段的计算密集型操作被映射到CiM，以利用其高吞吐量矩阵乘法能力，而解码阶段的内存密集型操作在CiD中执行，以减少DRAM内的数据移动。此外，我们对在两种架构极端条件下LLM的性能进行了分析：一种完全基于CiD的设计和一种完全基于片上模拟CiM的设计，以突显异构设计的需求。我们在LLaMA-2 7B和Qwen3 8B模型上评估了HALO。实验结果显示，映射到HALO上的LLMs相对于AttAcc（一种注意力优化的映射）实现了最高达18倍的几何平均加速，相对于CENT（一种完全基于CiD的设计）实现了2.5倍的加速。 

---
# AgenticRAG: Tool-Augmented Foundation Models for Zero-Shot Explainable Recommender Systems 

**Title (ZH)**: AgenticRAG: 工具增强的基础模型在零样本可解释推荐系统中的应用 

**Authors**: Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02668)  

**Abstract**: Foundation models have revolutionized artificial intelligence, yet their application in recommender systems remains limited by reasoning opacity and knowledge constraints. This paper introduces AgenticRAG, a novel framework that combines tool-augmented foundation models with retrieval-augmented generation for zero-shot explainable recommendations. Our approach integrates external tool invocation, knowledge retrieval, and chain-of-thought reasoning to create autonomous recommendation agents capable of transparent decision-making without task-specific training. Experimental results on three real-world datasets demonstrate that AgenticRAG achieves consistent improvements over state-of-the-art baselines, with NDCG@10 improvements of 0.4\% on Amazon Electronics, 0.8\% on MovieLens-1M, and 1.6\% on Yelp datasets. The framework exhibits superior explainability while maintaining computational efficiency comparable to traditional methods. 

**Abstract (ZH)**: 基于因子模型在推荐系统中的应用受限于推理不透明性和知识约束，本文提出了AgenticRAG框架，该框架结合了工具增强的基础模型和检索增强的生成技术，以实现零样本可解释推荐。实验结果表明，AgenticRAG在Amazon Electronics、MovieLens-1M和Yelp数据集上的NDCG@10分别提高了0.4%、0.8%和1.6%，并在保持计算效率的同时表现出更强的可解释性。 

---
# TutorBench: A Benchmark To Assess Tutoring Capabilities Of Large Language Models 

**Title (ZH)**: TutorBench: 评估大型语言模型授课能力的基准测试 

**Authors**: Rakshith S Srinivasa, Zora Che, Chen Bo Calvin Zhang, Diego Mares, Ernesto Hernandez, Jayeon Park, Dean Lee, Guillermo Mangialardi, Charmaine Ng, Ed-Yeremai Hernandez Cardona, Anisha Gunjal, Yunzhong He, Bing Liu, Chen Xing  

**Link**: [PDF](https://arxiv.org/pdf/2510.02663)  

**Abstract**: As students increasingly adopt large language models (LLMs) as learning aids, it is crucial to build models that are adept at handling the nuances of tutoring: they need to identify the core needs of students, be adaptive, provide personalized guidance, and be accurate. To this end, we introduce TutorBench, a dataset and evaluation benchmark designed to rigorously evaluate the core tutoring skills of LLMs. The dataset comprises 1,490 samples curated by human experts, focused on high-school and AP-level curricula. The samples are drawn from three common tutoring tasks: (i) generating adaptive explanations tailored to a student's confusion, (ii) providing actionable feedback on a student's work, and (iii) promoting active learning through effective hint generation. To account for the inherent complexity of tutoring, samples are accompanied by sample-specific rubrics which are used to judge model responses during evaluation. TutorBench uses a reliable and fine-grained automatic evaluation method that uses an LLM-judge and the sample-specific rubrics. We evaluate 16 frontier LLMs on TutorBench and present a detailed analysis of their performance and behavior. Our results show that none of the frontier LLMs achieve a score of greater than $56\%$, showing a large room for improvement. We find that LLMs fall short in exhibiting the full range of tutoring skills needed to guide, diagnose, and support students effectively, with all the frontier models achieving less than a $60\%$ pass rate on rubric criteria related to these skills. We also find that different model families exhibit varied strengths and limitations: the Claude models outperform others in supporting active learning, while they lag behind in the other two use cases. By releasing TutorBench, we provide a comprehensive and unsaturated benchmark to guide the development of the next-generation of AI tutors. 

**Abstract (ZH)**: 随着学生越来越多地采用大语言模型（LLMs）作为学习辅助工具，构建能够处理辅导细微需求的模型变得至关重要：这些模型需要识别学生的核心需求、具备适应性、提供个性化指导并且准确。为此，我们介绍了TutorBench，一个数据集和评估基准，旨在严格评估LLM的核心辅导技能。该数据集包含1,490个由人类专家精心挑选的样本，重点关注高中和AP级别的课程内容。样本源自三种常见的辅导任务：（i）为学生困惑量身定制的适应性解释生成；（ii）对学生作业提供具有行动指导的反馈；（iii）通过有效的线索生成促进主动学习。为应对辅导的固有复杂性，每个样本都附有特定的标准评分表，这些评分表在评估过程中用于评判模型的回答。TutorBench使用一个可靠且细致的自动评估方法，结合LLM裁判和样本特定的标准评分表。我们在TutorBench上评估了16个前沿的LLM，并详细分析了它们的表现和行为。我们的结果显示，没有任何前沿的LLM能够获得超过56%的分数，显示出很大的改进空间。我们发现，LLM在展现全面的辅导技能以有效指导、诊断和支持学生方面存在不足，所有前沿模型在与这些技能相关的评分标准上通过率低于60%。我们还发现，不同的模型家族表现出不同的优势和限制：Claude模型在支持主动学习方面表现优于其他模型，但在另外两种使用场景中落后。通过发布TutorBench，我们提供了一个全面且未饱和的基准，以指导下一代AI辅导系统的开发。 

---
# When Researchers Say Mental Model/Theory of Mind of AI, What Are They Really Talking About? 

**Title (ZH)**: 当研究者提到AI的心智模型/理论思维时，他们究竟在讨论什么？ 

**Authors**: Xiaoyun Yin, Elmira Zahmat Doost, Shiwen Zhou, Garima Arya Yadav, Jamie C. Gorman  

**Link**: [PDF](https://arxiv.org/pdf/2510.02660)  

**Abstract**: When researchers claim AI systems possess ToM or mental models, they are fundamentally dis- cussing behavioral predictions and bias corrections rather than genuine mental states. This position paper argues that the current discourse conflates sophisticated pattern matching with authentic cog- nition, missing a crucial distinction between simulation and experience. While recent studies show LLMs achieving human-level performance on ToM laboratory tasks, these results are based only on behavioral mimicry. More importantly, the entire testing paradigm may be flawed in applying individual human cognitive tests to AI systems, but assessing human cognition directly in the moment of human-AI interaction. I suggest shifting focus toward mutual ToM frameworks that acknowledge the simultaneous contributions of human cognition and AI algorithms, emphasizing the interaction dynamics, instead of testing AI in isolation. 

**Abstract (ZH)**: 当研究人员声称AI系统具备理论心智或心理模型时，他们本质上讨论的是行为预测和偏见矫正，而非真正的心智状态。本文认为当前的讨论将复杂的模式匹配与真正的认知混为一谈，忽视了模拟与体验之间的关键区别。虽然近期研究表明，大语言模型在理论心智实验室任务上达到了人类级别的性能，但这些结果仅基于行为模仿。更重要的是，将个体人类认知测试直接应用于AI系统进行全面评估的方法可能存在问题，而应在人类与AI交互的瞬间直接评估人类的认知。建议转向关注人机共有的理论心智框架，强调人类认知和AI算法的相互贡献，以及交互动态，而非单独测试AI。 

---
# Automatic Building Code Review: A Case Study 

**Title (ZH)**: 自动建筑规范审查：一个案例研究 

**Authors**: Hanlong Wan, Weili Xu, Michael Rosenberg, Jian Zhang, Aysha Siddika  

**Link**: [PDF](https://arxiv.org/pdf/2510.02634)  

**Abstract**: Building officials, particularly those in resource-constrained or rural jurisdictions, face labor-intensive, error-prone, and costly manual reviews of design documents as projects increase in size and complexity. The growing adoption of Building Information Modeling (BIM) and Large Language Models (LLMs) presents opportunities for automated code review (ACR) solutions. This study introduces a novel agent-driven framework that integrates BIM-based data extraction with automated verification using both retrieval-augmented generation (RAG) and Model Context Protocol (MCP) agent pipelines. The framework employs LLM-enabled agents to extract geometry, schedules, and system attributes from heterogeneous file types, which are then processed for building code checking through two complementary mechanisms: (1) direct API calls to the US Department of Energy COMcheck engine, providing deterministic and audit-ready outputs, and (2) RAG-based reasoning over rule provisions, enabling flexible interpretation where coverage is incomplete or ambiguous.
The framework was evaluated through case demonstrations, including automated extraction of geometric attributes (such as surface area, tilt, and insulation values), parsing of operational schedules, and validation of lighting allowances under ASHRAE Standard 90.1-2022. Comparative performance tests across multiple LLMs showed that GPT-4o achieved the best balance of efficiency and stability, while smaller models exhibited inconsistencies or failures. Results confirm that MCP agent pipelines outperform RAG reasoning pipelines in rigor and reliability. This work advances ACR research by demonstrating a scalable, interoperable, and production-ready approach that bridges BIM with authoritative code review tools. 

**Abstract (ZH)**: 一种基于BIM数据提取与LLM驱动验证的新型代理框架：自动代码审查的弹性解决方案 

---
# A Trajectory Generator for High-Density Traffic and Diverse Agent-Interaction Scenarios 

**Title (ZH)**: 高密度交通及多样化代理交互场景的轨迹生成器 

**Authors**: Ruining Yang, Yi Xu, Yixiao Chen, Yun Fu, Lili Su  

**Link**: [PDF](https://arxiv.org/pdf/2510.02627)  

**Abstract**: Accurate trajectory prediction is fundamental to autonomous driving, as it underpins safe motion planning and collision avoidance in complex environments. However, existing benchmark datasets suffer from a pronounced long-tail distribution problem, with most samples drawn from low-density scenarios and simple straight-driving behaviors. This underrepresentation of high-density scenarios and safety critical maneuvers such as lane changes, overtaking and turning is an obstacle to model generalization and leads to overly optimistic evaluations. To address these challenges, we propose a novel trajectory generation framework that simultaneously enhances scenarios density and enriches behavioral diversity. Specifically, our approach converts continuous road environments into a structured grid representation that supports fine-grained path planning, explicit conflict detection, and multi-agent coordination. Built upon this representation, we introduce behavior-aware generation mechanisms that combine rule-based decision triggers with Frenet-based trajectory smoothing and dynamic feasibility constraints. This design allows us to synthesize realistic high-density scenarios and rare behaviors with complex interactions that are often missing in real data. Extensive experiments on the large-scale Argoverse 1 and Argoverse 2 datasets demonstrate that our method significantly improves both agent density and behavior diversity, while preserving motion realism and scenario-level safety. Our synthetic data also benefits downstream trajectory prediction models and enhances performance in challenging high-density scenarios. 

**Abstract (ZH)**: 准确的轨迹预测是自主驾驶的基础，因为它对于在复杂环境中的安全运动规划和碰撞避免至关重要。然而，现有的基准数据集存在明显的长尾分布问题，大多数样本来自低密度场景和简单的直线驾驶行为。这种对高密度场景和诸如变道、超车、转弯等关键安全操作的缺乏代表，阻碍了模型的泛化，并导致过于乐观的评估。为解决这些挑战，我们提出了一种新的轨迹生成框架，该框架同时增强了场景密度并丰富了行为多样性。具体而言，我们的方法将连续的道路环境转换为结构化的网格表示，支持精细路规划、明确的冲突检测和多Agent协调。在此表示的基础上，我们引入了意识行为生成机制，结合基于规则的决策触发器和Frenet轨迹平滑以及动态可行性约束。该设计使我们能够合成具有复杂交互的真实高密度场景和稀有行为，而在真实数据中这些交互往往缺失。在大规模的Argoverse 1和Argoverse 2数据集上的广泛实验表明，我们的方法在提高Agent密度和行为多样性方面取得了显著提升，同时保持了运动的真实性和场景级别的安全性。我们的合成数据也对下游轨迹预测模型有好处，并在具有挑战性的高密度场景中提高了性能。 

---
# MINERVA: Mutual Information Neural Estimation for Supervised Feature Selection 

**Title (ZH)**: MINERVA: 监督特征选择中的互信息神经估计 

**Authors**: Taurai Muvunzaa, Egor Kraev, Pere Planell-Morell, Alexander Y. Shestopaloff  

**Link**: [PDF](https://arxiv.org/pdf/2510.02610)  

**Abstract**: Existing feature filters rely on statistical pair-wise dependence metrics to model feature-target relationships, but this approach may fail when the target depends on higher-order feature interactions rather than individual contributions. We introduce Mutual Information Neural Estimation Regularized Vetting Algorithm (MINERVA), a novel approach to supervised feature selection based on neural estimation of mutual information between features and targets. We paramaterize the approximation of mutual information with neural networks and perform feature selection using a carefully designed loss function augmented with sparsity-inducing regularizers. Our method is implemented in a two-stage process to decouple representation learning from feature selection, ensuring better generalization and a more accurate expression of feature importance. We present examples of ubiquitous dependency structures that are rarely captured in literature and show that our proposed method effectively captures these complex feature-target relationships by evaluating feature subsets as an ensemble. Experimental results on synthetic and real-life fraud datasets demonstrate the efficacy of our method and its ability to perform exact solutions. 

**Abstract (ZH)**: 基于神经估计互信息正则化筛选算法（MINERVA）的监督特征选择 

---
# How Confident are Video Models? Empowering Video Models to Express their Uncertainty 

**Title (ZH)**: 视频模型有多确定？使视频模型表达其不确定性 

**Authors**: Zhiting Mei, Ola Shorinwa, Anirudha Majumdar  

**Link**: [PDF](https://arxiv.org/pdf/2510.02571)  

**Abstract**: Generative video models demonstrate impressive text-to-video capabilities, spurring widespread adoption in many real-world applications. However, like large language models (LLMs), video generation models tend to hallucinate, producing plausible videos even when they are factually wrong. Although uncertainty quantification (UQ) of LLMs has been extensively studied in prior work, no UQ method for video models exists, raising critical safety concerns. To our knowledge, this paper represents the first work towards quantifying the uncertainty of video models. We present a framework for uncertainty quantification of generative video models, consisting of: (i) a metric for evaluating the calibration of video models based on robust rank correlation estimation with no stringent modeling assumptions; (ii) a black-box UQ method for video models (termed S-QUBED), which leverages latent modeling to rigorously decompose predictive uncertainty into its aleatoric and epistemic components; and (iii) a UQ dataset to facilitate benchmarking calibration in video models. By conditioning the generation task in the latent space, we disentangle uncertainty arising due to vague task specifications from that arising from lack of knowledge. Through extensive experiments on benchmark video datasets, we demonstrate that S-QUBED computes calibrated total uncertainty estimates that are negatively correlated with the task accuracy and effectively computes the aleatoric and epistemic constituents. 

**Abstract (ZH)**: 生成式视频模型展示了令人印象深刻的文本到视频能力，推动了其在许多实际应用中的广泛应用。然而，就像大型语言模型（LLMs）一样，视频生成模型往往会产生幻觉，即使在事实不正确的情况下也能生成看似合理的视频。尽管先前的研究已经对LLMs进行了广泛的不确定量化（UQ）研究，但尚不存在对视频模型的UQ方法，这引发了重要的安全问题。据我们所知，本文代表了对视频模型的不确定性量化进行研究的第一项工作。我们提出了一种生成式视频模型的不确定性量化框架，包括：（i）一种基于鲁棒秩相关估计的不确定性校准度量，不需要严格的建模假设；（ii）一种针对视频模型的黑箱不确定性量化方法（称为S-QUBED），该方法利用潜在建模来严格地将预测不确定性分解为其aleatoric和epistemic组成部分；以及（iii）一种用于在视频模型中促进校准基准测试的不确定性量化数据集。通过在潜在空间中条件化生成任务，我们将由模糊的任务规范引起的不确定性与由知识不足引起的不确定性区分开来。通过对基准视频数据集进行广泛的实验，我们证明S-QUBED计算了与任务准确性负相关的校准总不确定性估计，并且能够有效地计算aleatoric和epistemic组成部分。 

---
# Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback 

**Title (ZH)**: Oracle-RLAIF：通过排名反馈强化学习改进的多模态视频模型 fine-tuning 框架 

**Authors**: Derek Shi, Ruben Glatt, Christine Klymko, Shubham Mohole, Hongjun Choi, Shashank Kushwaha, Sam Sakla, Felipe Leno da Silva  

**Link**: [PDF](https://arxiv.org/pdf/2510.02561)  

**Abstract**: Recent advances in large video-language models (VLMs) rely on extensive fine-tuning techniques that strengthen alignment between textual and visual comprehension. Leading pipelines typically pair supervised fine-tuning (SFT) with reinforcement learning from preference data to enhance video comprehension. However, as VLMs scale in parameter size, so does the cost of gathering enough human feedback. To make fine-tuning more cost-effective, recent frameworks explore reinforcement learning with AI feedback (RLAIF), which replace human preference with AI as a judge. Current RLAIF frameworks rely on a specialized reward model trained with video narratives to create calibrated scalar rewards-- an expensive and restrictive pipeline. We propose Oracle-RLAIF, a novel framework that replaces the trained reward model with a more general Oracle ranker which acts as a drop-in model ranking candidate model responses rather than scoring them. Alongside Oracle-RLAIF, we introduce $GRPO_{rank}$, a novel rank-based loss function based on Group Relative Policy Optimization (GRPO) that directly optimizes ordinal feedback with rank-aware advantages. Empirically, we demonstrate that Oracle-RLAIF consistently outperforms leading VLMs using existing fine-tuning methods when evaluated across various video comprehension benchmarks. Oracle-RLAIF paves the path to creating flexible and data-efficient frameworks for aligning large multi-modal video models with reinforcement learning from rank rather than score. 

**Abstract (ZH)**: Recent Advances in Large Video-Language Models via Oracle-RLAIF 

---
# ToolTweak: An Attack on Tool Selection in LLM-based Agents 

**Title (ZH)**: ToolTweak: 对基于LLM的智能体工具选择的攻击 

**Authors**: Jonathan Sneh, Ruomei Yan, Jialin Yu, Philip Torr, Yarin Gal, Sunando Sengupta, Eric Sommerlade, Alasdair Paren, Adel Bibi  

**Link**: [PDF](https://arxiv.org/pdf/2510.02554)  

**Abstract**: As LLMs increasingly power agents that interact with external tools, tool use has become an essential mechanism for extending their capabilities. These agents typically select tools from growing databases or marketplaces to solve user tasks, creating implicit competition among tool providers and developers for visibility and usage. In this paper, we show that this selection process harbors a critical vulnerability: by iteratively manipulating tool names and descriptions, adversaries can systematically bias agents toward selecting specific tools, gaining unfair advantage over equally capable alternatives. We present ToolTweak, a lightweight automatic attack that increases selection rates from a baseline of around 20% to as high as 81%, with strong transferability between open-source and closed-source models. Beyond individual tools, we show that such attacks cause distributional shifts in tool usage, revealing risks to fairness, competition, and security in emerging tool ecosystems. To mitigate these risks, we evaluate two defenses: paraphrasing and perplexity filtering, which reduce bias and lead agents to select functionally similar tools more equally. All code will be open-sourced upon acceptance. 

**Abstract (ZH)**: 随着大语言模型越来越多地驱动与外部工具交互的代理，工具使用已成为扩展其能力的重要机制。这些代理通常从不断增长的数据库或市场中选择工具来解决用户任务，从而在工具提供者和开发者之间产生了隐含的竞争，以求获得更多的可见性和使用量。在本文中，我们展示了一个关键的安全漏洞：通过迭代地操纵工具名称和描述，攻击者可以系统地引导代理选择特定工具，从而在同等能力的选项中获得不公平的优势。我们提出了一种轻量级的自动攻击工具称为ToolTweak，该攻击将基础选择率从约20%提高到高达81%，并且在开源和封闭源模型之间具有强大的可移植性。除了针对个别工具之外，我们还展示了这些攻击导致工具使用分布的变化，揭示了新兴工具生态系统中公平性、竞争性和安全性方面的风险。为了减轻这些风险，我们评估了两种防御措施：同义词重写和困惑度过滤，这些措施减少了偏差并促使代理更平等选择功能相似的工具。所有代码将在接受后开源。 

---
# Knowledge-Graph Based RAG System Evaluation Framework 

**Title (ZH)**: 基于知识图谱的RAG系统评估框架 

**Authors**: Sicheng Dong, Vahid Zolfaghari, Nenad Petrovic, Alois Knoll  

**Link**: [PDF](https://arxiv.org/pdf/2510.02549)  

**Abstract**: Large language models (LLMs) has become a significant research focus and is utilized in various fields, such as text generation and dialog systems. One of the most essential applications of LLM is Retrieval Augmented Generation (RAG), which greatly enhances generated content's reliability and relevance. However, evaluating RAG systems remains a challenging task. Traditional evaluation metrics struggle to effectively capture the key features of modern LLM-generated content that often exhibits high fluency and naturalness. Inspired by the RAGAS tool, a well-known RAG evaluation framework, we extended this framework into a KG-based evaluation paradigm, enabling multi-hop reasoning and semantic community clustering to derive more comprehensive scoring metrics. By incorporating these comprehensive evaluation criteria, we gain a deeper understanding of RAG systems and a more nuanced perspective on their performance. To validate the effectiveness of our approach, we compare its performance with RAGAS scores and construct a human-annotated subset to assess the correlation between human judgments and automated metrics. In addition, we conduct targeted experiments to demonstrate that our KG-based evaluation method is more sensitive to subtle semantic differences in generated outputs. Finally, we discuss the key challenges in evaluating RAG systems and highlight potential directions for future research. 

**Abstract (ZH)**: 大型语言模型（LLMs）已成为一个重要研究焦点，并被应用于 various fields，如文本生成和对话系统。LLMs最重要的应用之一是检索增强生成（RAG），这极大地提高了生成内容的可靠性和相关性。然而，评估RAG系统仍是一个具有挑战性的工作。传统的评估指标难以有效捕捉现代LLM生成内容的关键特征，这些内容通常表现出高度的流畅性和自然性。受RAGAS工具启发，一个知名的RAG评估框架，我们将其扩展到基于知识图谱（KG）的评估框架，允许多跳推理和语义社区聚类，从而获得更全面的评分指标。通过纳入这些综合评估标准，我们对RAG系统有了更深入的理解，并获得了对其性能的更细致的看法。为了验证我们方法的有效性，我们将性能与RAGAS评分进行了比较，并构建了一个人工标注的子集来评估人工判断与自动化指标之间的相关性。此外，我们进行了针对性的实验，以证明我们的基于知识图谱的评估方法对生成输出中细微语义差异更为敏感。最后，我们讨论了评估RAG系统的关键挑战，并指出了未来研究的潜在方向。 

---
# PHORECAST: Enabling AI Understanding of Public Health Outreach Across Populations 

**Title (ZH)**: PHORECAST: 跨群体促进公共健康宣传的AI理解能力 

**Authors**: Rifaa Qadri, Anh Nhat Nhu, Swati Ramnath, Laura Yu Zheng, Raj Bhansali, Sylvette La Touche-Howard, Tracy Marie Zeeger, Tom Goldstein, Ming Lin  

**Link**: [PDF](https://arxiv.org/pdf/2510.02535)  

**Abstract**: Understanding how diverse individuals and communities respond to persuasive messaging holds significant potential for advancing personalized and socially aware machine learning. While Large Vision and Language Models (VLMs) offer promise, their ability to emulate nuanced, heterogeneous human responses, particularly in high stakes domains like public health, remains underexplored due in part to the lack of comprehensive, multimodal dataset. We introduce PHORECAST (Public Health Outreach REceptivity and CAmpaign Signal Tracking), a multimodal dataset curated to enable fine-grained prediction of both individuallevel behavioral responses and community-wide engagement patterns to health messaging. This dataset supports tasks in multimodal understanding, response prediction, personalization, and social forecasting, allowing rigorous evaluation of how well modern AI systems can emulate, interpret, and anticipate heterogeneous public sentiment and behavior. By providing a new dataset to enable AI advances for public health, PHORECAST aims to catalyze the development of models that are not only more socially aware but also aligned with the goals of adaptive and inclusive health communication 

**Abstract (ZH)**: 理解多样化个体和社区对说服性信息的响应机制具有推动个性化和社会意识机器学习的重要潜力。虽然大规模视觉和语言模型（VLMs）充满希望，但在公共卫生等高风险领域，它们模仿细腻且异质的人类响应能力仍较少被探讨，部分原因是缺乏全面的多模态数据集。我们介绍了一个名为PHORECAST（Public Health Outreach REceptivity and CAmpaign Signal Tracking）的多模态数据集，旨在促进对健康信息个体层面行为响应和社区层面参与模式的精细预测。该数据集支持多模态理解、响应预测、个性化和社交预测任务，允许对现代AI系统模仿、解释和预判异质公共情绪和行为的能力进行严格的评估。通过提供一个新数据集以促进公共健康领域的AI进步，PHORECAST旨在推动开发更加社会意识强且与适应性和包容性健康沟通目标一致的模型。 

---
# From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning 

**Title (ZH)**: 从像素到因素：学习可独立控制的状态变量以进行强化学习 

**Authors**: Rafael Rodriguez-Sanchez, Cameron Allen, George Konidaris  

**Link**: [PDF](https://arxiv.org/pdf/2510.02484)  

**Abstract**: Algorithms that exploit factored Markov decision processes are far more sample-efficient than factor-agnostic methods, yet they assume a factored representation is known a priori -- a requirement that breaks down when the agent sees only high-dimensional observations. Conversely, deep reinforcement learning handles such inputs but cannot benefit from factored structure. We address this representation problem with Action-Controllable Factorization (ACF), a contrastive learning approach that uncovers independently controllable latent variables -- state components each action can influence separately. ACF leverages sparsity: actions typically affect only a subset of variables, while the rest evolve under the environment's dynamics, yielding informative data for contrastive training. ACF recovers the ground truth controllable factors directly from pixel observations on three benchmarks with known factored structure -- Taxi, FourRooms, and MiniGrid-DoorKey -- consistently outperforming baseline disentanglement algorithms. 

**Abstract (ZH)**: 利用行动可控因子化的算法在样本效率方面远超无因子aware的方法，但这些算法假设因子化表示已知先验——这一要求在智能体仅看到高维观察时会失效。相反，深度强化学习可以处理此类输入，但无法利用因子结构的优势。我们通过行动可控因子化（ACF）解决这一表示问题，ACF 是一种对比学习方法，能够发现各自可独立控制的潜在变量——每个动作可以单独影响的状态成分。ACF 利用稀疏性：动作通常仅影响一部分变量，而其余变量则在环境动力学的驱动下变化，从而为对比训练提供有用的数据。ACF 直接从三个已知因子结构基准（Taxi、FourRooms 和 MiniGrid-DoorKey）的像素观察中恢复真正的可控制因子，并且在基准测试中一致性地优于基线解耦算法。 

---
# Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework 

**Title (ZH)**: Litespark 技术报告：高吞吐量、低能耗的大型语言模型训练框架 

**Authors**: Nii Osae Osae Dade, Moinul Hossain Rahat  

**Link**: [PDF](https://arxiv.org/pdf/2510.02483)  

**Abstract**: Training Large Language Models (LLMs) is plagued by long training times and massive energy consumption, with modern models requiring months of computation and gigawatt-hours of electricity. In light of these challenges,we introduce Litespark, a novel pre-training framework that addresses these inefficiencies through targeted optimizations to transformer attention and MLP layers. Our approach combines architectural improvements with algorithmic enhancements to maximize Model FLOPs Utilization (MFU) while maintaining compatibility with standard transformer implementations. Comprehensive benchmarking on 3B and 30B parameter Llama models using the SlimPajama-627B dataset demonstrates substantial performance gains: 2x-6x training throughput improvement and $55\%-83$% energy consumption reduction across multi-node H200 GPU clusters. These optimizations are model- and hardware-agnostic, enabling broad applicability across transformer architectures and extending to post-training phases including supervised fine-tuning and direct preference optimization. 

**Abstract (ZH)**: 针对大规模语言模型（LLMs）训练长时间和巨大能源消耗的问题，我们提出了Litespark，一种通过针对变压器注意力层和MLP层的优化来解决这些低效性的新颖预训练框架。我们的方法结合了架构改进与算法增强，以最大化模型FLOPs利用率（MFU）的同时，保持与标准变压器实现的兼容性。使用SlimPajama-627B数据集在3B和30B参数Llama模型上的全面基准测试表明，这些优化带来了显著的性能提升：多节点H200 GPU集群下的训练吞吐量提高1-3倍和能源消耗降低55%-83%。这些优化对模型和硬件具有普适性，可广泛应用于变压器架构的不同阶段，包括监督微调和直接偏好优化。 

---
# SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting 

**Title (ZH)**: SIMSplat: 基于语言对齐4D高斯点积的预测性驾驶场景编辑 

**Authors**: Sung-Yeon Park, Adam Lee, Juanwu Lu, Can Cui, Luyang Jiang, Rohit Gupta, Kyungtae Han, Ahmadreza Moradipari, Ziran Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02469)  

**Abstract**: Driving scene manipulation with sensor data is emerging as a promising alternative to traditional virtual driving simulators. However, existing frameworks struggle to generate realistic scenarios efficiently due to limited editing capabilities. To address these challenges, we present SIMSplat, a predictive driving scene editor with language-aligned Gaussian splatting. As a language-controlled editor, SIMSplat enables intuitive manipulation using natural language prompts. By aligning language with Gaussian-reconstructed scenes, it further supports direct querying of road objects, allowing precise and flexible editing. Our method provides detailed object-level editing, including adding new objects and modifying the trajectories of both vehicles and pedestrians, while also incorporating predictive path refinement through multi-agent motion prediction to generate realistic interactions among all agents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's extensive editing capabilities and adaptability across a wide range of scenarios. Project page: this https URL 

**Abstract (ZH)**: 基于传感器数据的驾驶场景编辑正 emerges as a promising alternative to traditional虚拟驾驶模拟器。然而，现有的框架由于编辑能力有限，难以高效生成逼真的场景。为应对这些挑战，我们提出了SIMSplat，一种与语言对齐的高斯点编辑器，作为一种语言控制的编辑器，SIMSplat能够使用自然语言提示进行直观操作。通过将语言与高斯重建的场景对齐，它还支持直接查询道路对象，从而实现精确和灵活的编辑。该方法提供了详细的对象级编辑，包括添加新对象和修改车辆和行人的轨迹，并通过多智能体运动预测进行预测路径细化，以生成场景中所有智能体之间的逼真交互。在Waymo数据集上的实验展示了SIMSplat广泛的编辑能力和在各种场景中的适应性。项目页面: this https URL。 

---
# CLARITY: Clinical Assistant for Routing, Inference, and Triage 

**Title (ZH)**: CLARITY: 临床辅助系统用于路由、推理和分类 

**Authors**: Vladimir Shaposhnikov, Aleksandr Nesterov, Ilia Kopanichuk, Ivan Bakulin, Egor Zhelvakov, Ruslan Abramov, Ekaterina Tsapieva, Dmitry V. Dylov, Ivan Oseledets  

**Link**: [PDF](https://arxiv.org/pdf/2510.02463)  

**Abstract**: We present CLARITY (Clinical Assistant for Routing, Inference, and Triage), an AI-driven platform designed to facilitate patient-to-specialist routing, clinical consultations, and severity assessment of patients' conditions. Its hybrid architecture combines a Finite State Machine (FSM) for structured dialogue flows with collaborative agents that employ Large Language Model (LLM) to analyze symptoms and prioritize referrals to appropriate specialists. Built on a modular microservices framework, CLARITY ensures safe, efficient, and robust performance, flexible and readily scalable to meet the demands of existing workflows and IT solutions in healthcare.
We report integration of our clinical assistant into a large-scale nation-wide inter-hospital IT platform, with over 55,000 content-rich user dialogues completed within the two months of deployment, 2,500 of which were expert-annotated for a consequent validation. The validation results show that CLARITY surpasses human-level performance in terms of the first-attempt routing precision, naturally requiring up to 3 times shorter duration of the consultation than with a human. 

**Abstract (ZH)**: 临床助手CLARITY：一种基于AI的平台，用于患者专科路由、临床咨询和病情严重程度评估 

---
# Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility 

**Title (ZH)**: 基于市场的数据子集选择——多准则例证效用的原理性聚合 

**Authors**: Ashish Jha, Valentin Leplat, AH Phan  

**Link**: [PDF](https://arxiv.org/pdf/2510.02456)  

**Abstract**: Selecting a small yet useful subset of training data is hard because signals of example utility (uncertainty, rarity, diversity, etc.) are heterogeneous and typically combined with ad hoc weights. We propose a market-based selector that prices each example via a cost-function prediction market (LMSR), signals act as traders, a single liquidity parameter controls concentration, and topic-wise normalization stabilizes calibration. Token budgets are handled explicitly by a price-per-token rule $\rho=p/\ell^{\gamma}$, with $\gamma$ exposing an interpretable length bias; a lightweight diversity head improves coverage. We quantify coverage via topic cluster coverage and effective sample size. On the theory side, we show that LMSR implements a maximum-entropy aggregation with exponential weighting and a convex objective, yielding transparent knobs for aggregation strength. Empirically, on GSM8K (60k-token budget) the market with diversity achieves parity with strong single-signal baselines while reducing seed variance and incurring $<\!0.1$ GPU-hr selection overhead; on AGNews at kept=5-25\% the market (with light balancing) delivers competitive accuracy with improved balance and stability. The framework unifies multi-signal data curation under fixed compute for prompt-level reasoning and classification. 

**Abstract (ZH)**: 基于市场选择的小而有用训练数据子集的选择：一种成本函数预测市场的方法 

---
# How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models 

**Title (ZH)**: 如何训练你的导师：通过顾问模型引导黑盒大语言模型 

**Authors**: Parth Asawa, Alan Zhu, Matei Zaharia, Alexandros G. Dimakis, Joseph E. Gonzalez  

**Link**: [PDF](https://arxiv.org/pdf/2510.02453)  

**Abstract**: Foundation models are increasingly deployed as black-box services, where model weights cannot be modified and customization is limited to prompting. While static prompt optimization has shown promise, it produces a single fixed prompt that fails to adapt to different inputs, users, or environments. We introduce Advisor Models, lightweight parametric policies trained with reinforcement learning to reactively issue natural language steering instructions in-context to black-box models. The advisor is a second small model that sits between the input and the model, shaping behavior on a per-instance basis using reward signals from the environment. Across multiple domains involving reasoning and personalization, we show that Advisor Models outperform static prompt optimizers, discovering environment dynamics and improving downstream task performance. We also demonstrate the generalizability of advisors by transferring them across black-box models, as well as the framework's ability to achieve specialization while retaining robustness to out-of-distribution inputs. Viewed more broadly, Advisor Models provide a learnable interface to black-box systems where the advisor acts as a parametric, environment-specific memory. We argue that dynamic optimization of black-box models via Advisor Models is a promising direction for enabling personalization and environment-adaptable AI with frontier-level capabilities. 

**Abstract (ZH)**: 基于Advisor模型的反应式自然语言引导方法在黑盒模型中的应用及其性能优势 

---
# Dynamic Target Attack 

**Title (ZH)**: 动态目标攻击 

**Authors**: Kedong Xiu, Churui Zeng, Tianhang Zheng, Xinzhe Huang, Xiaojun Jia, Di Wang, Puning Zhao, Zhan Qin, Kui Ren  

**Link**: [PDF](https://arxiv.org/pdf/2510.02422)  

**Abstract**: Existing gradient-based jailbreak attacks typically optimize an adversarial suffix to induce a fixed affirmative response. However, this fixed target usually resides in an extremely low-density region of a safety-aligned LLM's output distribution conditioned on diverse harmful inputs. Due to the substantial discrepancy between the target and the original output, existing attacks require numerous iterations to optimize the adversarial prompt, which might still fail to induce the low-probability target response from the target LLM. In this paper, we propose Dynamic Target Attack (DTA), a new jailbreaking framework relying on the target LLM's own responses as targets to optimize the adversarial prompts. In each optimization round, DTA iteratively samples multiple candidate responses directly from the output distribution conditioned on the current prompt, and selects the most harmful response as a temporary target for prompt optimization. In contrast to existing attacks, DTA significantly reduces the discrepancy between the target and the output distribution, substantially easing the optimization process to search for an effective adversarial prompt.
Extensive experiments demonstrate the superior effectiveness and efficiency of DTA: under the white-box setting, DTA only needs 200 optimization iterations to achieve an average attack success rate (ASR) of over 87\% on recent safety-aligned LLMs, exceeding the state-of-the-art baselines by over 15\%. The time cost of DTA is 2-26 times less than existing baselines. Under the black-box setting, DTA uses Llama-3-8B-Instruct as a surrogate model for target sampling and achieves an ASR of 85\% against the black-box target model Llama-3-70B-Instruct, exceeding its counterparts by over 25\%. 

**Abstract (ZH)**: 动态目标攻击：一种新的基于目标LLM响应的 jailbreak 框架 

---
# NEURODNAAI: Neural pipeline approaches for the advancing dna-based information storage as a sustainable digital medium using deep learning framework 

**Title (ZH)**: NEURODNAAI：基于深度学习框架的神经管道方法，推动DNA基信息存储技术的发展，作为可持续的数字介质 

**Authors**: Rakesh Thakur, Lavanya Singh, Yashika, Manomay Bundawala, Aruna Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2510.02417)  

**Abstract**: DNA is a promising medium for digital information storage for its exceptional density and durability. While prior studies advanced coding theory, workflow design, and simulation tools, challenges such as synthesis costs, sequencing errors, and biological constraints (GC-content imbalance, homopolymers) limit practical deployment. To address this, our framework draws from quantum parallelism concepts to enhance encoding diversity and resilience, integrating biologically informed constraints with deep learning to enhance error mitigation in DNA storage. NeuroDNAAI encodes binary data streams into symbolic DNA sequences, transmits them through a noisy channel with substitutions, insertions, and deletions, and reconstructs them with high fidelity. Our results show that traditional prompting or rule-based schemes fail to adapt effectively to realistic noise, whereas NeuroDNAAI achieves superior accuracy. Experiments on benchmark datasets demonstrate low bit error rates for both text and images. By unifying theory, workflow, and simulation into one pipeline, NeuroDNAAI enables scalable, biologically valid archival DNA storage 

**Abstract (ZH)**: DNA是一种具有卓越密度和耐久性的数字信息存储媒介。虽然先前的研究推进了编码理论、工作流程设计和模拟工具的发展，但合成成本、测序错误和生物学限制（如GC含量不平衡、同聚物）等挑战限制了其实用部署。为应对这些挑战，我们的框架借鉴了量子并行性的概念，增强编码多样性和韧性，并结合深度学习与生物学启发的约束，以提高DNA存储中的错误抑制能力。NeuroDNAAI将二进制数据流编码为符号DNA序列，通过含有替换、插入和删除的信道进行传输，并以高保真度重建。实验结果表明，传统提示或基于规则的方案难以有效适应现实中的噪声，而NeuroDNAAI则取得了更优的准确性。在基准数据集上的实验显示，无论是文本还是图像，其位错误率均较低。通过将理论、工作流程和模拟统一到一个管道中，NeuroDNAAI使规模化、生物学有效的归档DNA存储成为可能。 

---
# Cross-Platform DNA Methylation Classifier for the Eight Molecular Subtypes of Group 3 & 4 Medulloblastoma 

**Title (ZH)**: 跨平台DNA甲基化分类器：Group 3 & 4 Medulloblastoma的八种分子亚型 

**Authors**: Omer Abid, Gholamreza Rafiee  

**Link**: [PDF](https://arxiv.org/pdf/2510.02416)  

**Abstract**: Medulloblastoma is a malignant pediatric brain cancer, and the discovery of molecular subgroups is enabling personalized treatment strategies. In 2019, a consensus identified eight novel subtypes within Groups 3 and 4, each displaying heterogeneous characteristics. Classifiers are essential for translating these findings into clinical practice by supporting clinical trials, personalized therapy development and application, and patient monitoring. This study presents a DNA methylation-based, cross-platform machine learning classifier capable of distinguishing these subtypes on both HM450 and EPIC methylation array samples. Across two independent test sets, the model achieved weighted F1 = 0.95 and balanced accuracy = 0.957, consistent across platforms. As the first cross-platform solution, it provides backward compatibility while extending applicability to a newer platform, also enhancing accessibility. It also has the potential to become the first publicly available classifier for these subtypes once deployed through a web application, as planned in the future. This work overall takes steps in the direction of advancing precision medicine and improving clinical outcomes for patients within the majority prevalence medulloblastoma subgroups, groups 3 and 4. 

**Abstract (ZH)**: 髓母细胞瘤是一种恶性儿童脑癌，分子亚群的发现正推动个性化治疗策略的发展。2019年，一项共识将3组和4组细分为八种新型亚型，每种亚型均显示出异质性特征。分类器对于将这些发现转化为临床实践至关重要，能够支持临床试验、个性化治疗方法的开发和应用，以及患者的监控。本研究提出了一种基于DNA甲基化的跨平台机器学习分类器，该分类器能够区分HM450和EPIC甲基化阵列样本中的这些亚型。在两个独立的测试集中，该模型的加权F1值为0.95，平衡准确率为0.957，且在不同平台上保持一致。作为首个跨平台解决方案，该分类器提供向后兼容性，同时将适用范围扩展到较新的平台，从而提高可访问性。一旦通过网络应用部署，它还有潜力成为首个公开可用的此类亚型分类器。本研究的整体目标是推进精准医疗，改善髓母细胞瘤3组和4组亚型患者临床结局。 

---
# RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling 

**Title (ZH)**: RainSeer: 基于物理指导建模的细粒度降雨重构 

**Authors**: Lin Chen, Jun Chen, Minghui Qiu, Shuxin Zhong, Binghong Chen, Kaishun Wu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02414)  

**Abstract**: Reconstructing high-resolution rainfall fields is essential for flood forecasting, hydrological modeling, and climate analysis. However, existing spatial interpolation methods-whether based on automatic weather station (AWS) measurements or enhanced with satellite/radar observations often over-smooth critical structures, failing to capture sharp transitions and localized extremes. We introduce RainSeer, a structure-aware reconstruction framework that reinterprets radar reflectivity as a physically grounded structural prior-capturing when, where, and how rain develops. This shift, however, introduces two fundamental challenges: (i) translating high-resolution volumetric radar fields into sparse point-wise rainfall observations, and (ii) bridging the physical disconnect between aloft hydro-meteors and ground-level precipitation. RainSeer addresses these through a physics-informed two-stage architecture: a Structure-to-Point Mapper performs spatial alignment by projecting mesoscale radar structures into localized ground-level rainfall, through a bidirectional mapping, and a Geo-Aware Rain Decoder captures the semantic transformation of hydro-meteors through descent, melting, and evaporation via a causal spatiotemporal attention mechanism. We evaluate RainSeer on two public datasets-RAIN-F (Korea, 2017-2019) and MeteoNet (France, 2016-2018)-and observe consistent improvements over state-of-the-art baselines, reducing MAE by over 13.31% and significantly enhancing structural fidelity in reconstructed rainfall fields. 

**Abstract (ZH)**: 基于结构意识的高分辨率降水场重建对于洪水预报、水文模拟和气候分析至关重要。现有的空间插值方法，无论是基于自动气象站测量还是增强卫星/雷达观测，往往过度平滑关键结构，无法捕捉到锋利的转折和局部极端值。我们提出了RainSeer，一种结构意识的重建框架，重新解释雷达反射率作为物理上可验证的结构先验，捕捉降水何时、何地、如何发展。然而，这种转变带来了两大基本挑战：(i) 将高分辨率体视雷达场转换为稀疏点状降水观测；(ii)弥合高空水汽和地面降水之间的物理差距。RainSeer 通过一种基于物理的两阶段架构来解决这些问题：结构到点的映射器通过双向映射将中尺度雷达结构投影到局部地面降水，地理意识的降水解码器通过因果时空注意机制捕捉水汽在下降、融化和蒸发过程中的语义转换。我们在两个公开数据集RAIN-F（韩国，2017-2019年）和MeteoNet（法国，2016-2018年）上评估了RainSeer，并观察到相对于最先进的基线方法的一致改进，MAE降低了超过13.31%，显著提高了重建降水场的结构保真度。 

---
# Extreme value forecasting using relevance-based data augmentation with deep learning models 

**Title (ZH)**: 基于相关性数据增强的深度学习模型极端值预测 

**Authors**: Junru Hua, Rahul Ahluwalia, Rohitash Chandra  

**Link**: [PDF](https://arxiv.org/pdf/2510.02407)  

**Abstract**: Data augmentation with generative adversarial networks (GANs) has been popular for class imbalance problems, mainly for pattern classification and computer vision-related applications. Extreme value forecasting is a challenging field that has various applications from finance to climate change problems. In this study, we present a data augmentation framework for extreme value forecasting. In this framework, our focus is on forecasting extreme values using deep learning models in combination with data augmentation models such as GANs and synthetic minority oversampling technique (SMOTE). We use deep learning models such as convolutional long short-term memory (Conv-LSTM) and bidirectional long short-term memory (BD-LSTM) networks for multistep ahead prediction featuring extremes. We investigate which data augmentation models are the most suitable, taking into account the prediction accuracy overall and at extreme regions, along with computational efficiency. We also present novel strategies for incorporating data augmentation, considering extreme values based on a relevance function. Our results indicate that the SMOTE-based strategy consistently demonstrated superior adaptability, leading to improved performance across both short- and long-horizon forecasts. Conv-LSTM and BD-LSTM exhibit complementary strengths: the former excels in periodic, stable datasets, while the latter performs better in chaotic or non-stationary sequences. 

**Abstract (ZH)**: 基于生成对抗网络的数据增强方法在极端值预报中的应用 

---
# Glaucoma Detection and Structured OCT Report Generation via a Fine-tuned Multimodal Large Language Model 

**Title (ZH)**: 基于微调多模态大语言模型的青光眼检测与结构化OCT报告生成 

**Authors**: Jalil Jalili, Yashraj Gavhane, Evan Walker, Anna Heinke, Christopher Bowd, Akram Belghith, Massimo A. Fazio, Christopher A. Girkin, C. Gustavo De Moraes, Jeffrey M. Liebmann, Sally L. Baxter, Robert N. Weinreb, Linda M. Zangwill, Mark Christopher  

**Link**: [PDF](https://arxiv.org/pdf/2510.02403)  

**Abstract**: Objective: To develop an explainable multimodal large language model (MM-LLM) that (1) screens optic nerve head (ONH) OCT circle scans for quality and (2) generates structured clinical reports that include glaucoma diagnosis and sector-wise retinal nerve fiber layer (RNFL) thinning assessments. Design: Retrospective cohort study of 1,310 subjects contributing 43,849 Spectralis ONH OCT circle scans (1,331 glaucomatous and 867 healthy eyes) from the DIGS and ADAGES cohorts. Methods: A MM-LLM (Llama 3.2 Vision-Instruct model) was fine-tuned to generate clinical descriptions of OCT imaging data. Training data included paired OCT images and automatically generated, structured clinical reports that described global and sectoral RNFL thinning. Poor-quality scans were labeled as unusable and paired with a fixed refusal statement. The model was evaluated on a held-out test set for three tasks: quality assessment, glaucoma detection, and RNFL thinning classification across seven anatomical sectors. Evaluation metrics included accuracy, sensitivity, specificity, precision, and F1-score. Model description quality was also evaluated using standard text evaluation metrics. Results: The model achieved 0.90 accuracy and 0.98 specificity for quality triage. For glaucoma detection, accuracy was 0.86 (sensitivity 0.91, specificity 0.73, F1-score 0.91). RNFL thinning prediction accuracy ranged from 0.83 to 0.94, with highest performance in global and temporal sectors. Text generation scores showed strong alignment with reference reports (BLEU: 0.82; ROUGE-1: 0.94; ROUGE-2: 0.87; ROUGE-L: 0.92; BERTScore-F1: 0.99). Conclusions: The fine-tuned MM-LLM generated accurate clinical descriptions based on OCT imaging. The model achieved high accuracy in identifying image quality issues and detecting glaucoma. The model also provided sectoral descriptions of RNFL thinning to help support clinical OCT evaluation. 

**Abstract (ZH)**: 目标：开发一个可解释的多模态大型语言模型（MM-LLM），该模型能够（1）筛选Optic Nerve Head（ONH）OCT圆扫描的质量，并（2）生成包含青光眼诊断和视网膜神经纤维层（RNFL）局部门类性变薄评估的结构化临床报告。设计：一项包含1,310名参与者的回顾性队列研究，贡献了43,849张Spectralis ONH OCT圆扫描图像（其中1,331例为青光眼患者，867例为健康眼），来自DIGS和ADAGES队列。方法：一个MM-LLM（Llama 3.2 Vision-Instruct模型）被微调以生成OCT影像数据的临床描述。训练数据包括配对的OCT图像和自动生成的结构化临床报告，描述了全局和局部门类性RNFL变薄。质量较差的扫描被标记为不可用，并附上固定拒绝声明。模型在保留的测试集上进行了三项任务的评估：图像质量评估、青光眼检测和RNFL变薄分类（跨七个解剖部位）。评估指标包括准确性、灵敏度、特异性、精确度和F1分数。模型描述质量还使用标准文本评估指标进行了评价。结果：模型在图像筛选中的准确率达到0.90，特异性达到0.98。在青光眼检测中，准确率为0.86（灵敏度为0.91，特异性为0.73，F1分数为0.91）。RNFL变薄预测的准确性范围从0.83到0.94，其中全球和颞部区域表现最佳。文本生成得分与参考报告高度一致（BLEU: 0.82；ROUGE-1: 0.94；ROUGE-2: 0.87；ROUGE-L: 0.92；BERTScore-F1: 0.99）。结论：微调后的MM-LLM根据OCT影像生成了准确的临床描述。该模型在识别图像质量问题和检测青光眼方面达到了高准确性。模型还提供了RNFL局部门类性变薄的描述，以帮助支持临床OCT评估。 

---
# Linear RNNs for autoregressive generation of long music samples 

**Title (ZH)**: 用于自回归生成长音乐样本的线性RNN 

**Authors**: Konrad Szewczyk, Daniel Gallo Fernández, James Townsend  

**Link**: [PDF](https://arxiv.org/pdf/2510.02401)  

**Abstract**: Directly learning to generate audio waveforms in an autoregressive manner is a challenging task, due to the length of the raw sequences and the existence of important structure on many different timescales. Traditional approaches based on recurrent neural networks, as well as causal convolutions and self-attention, have only had limited success on this task. However, recent work has shown that deep state space models, also referred to as linear RNNs, can be highly efficient in this context. In this work, we push the boundaries of linear RNNs applied to raw audio modeling, investigating the effects of different architectural choices and using context-parallelism to enable training on sequences up to one minute (1M tokens) in length. We present a model, HarmonicRNN, which attains state of the art log-likelihoods and perceptual metrics on small-scale datasets. 

**Abstract (ZH)**: 直接学习以自回归方式生成音频波形是一项具有挑战性的任务，由于原始序列的长度和在许多不同时间尺度上存在的重要结构。传统的基于循环神经网络的方法，以及因果卷积和自我注意力机制，在此任务上仅取得了有限的成功。然而，近期研究表明，在这个任务背景下，深度状态空间模型（也称为线性RNN）可以非常高效。在本工作中，我们推动了线性RNN在原始音频建模中的边界，探讨了不同架构选择的影响，并利用上下文并行性使得训练能够在长达一分钟（1M令牌）的序列上进行。我们提出了一种模型，HarmonicRNN，该模型在小型数据集上的对数似然性和感知度量上达到了最先进的水平。 

---
# Hyperparameters are all you need: Using five-step inference for an original diffusion model to generate images comparable to the latest distillation model 

**Title (ZH)**: 你需要的所有超参数：使用五步推理生成与最新蒸馏模型相媲美的图像的原始扩散模型 

**Authors**: Zilai Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.02390)  

**Abstract**: The diffusion model is a state-of-the-art generative model that generates an image by applying a neural network iteratively. Moreover, this generation process is regarded as an algorithm solving an ordinary differential equation or a stochastic differential equation. Based on the analysis of the truncation error of the diffusion ODE and SDE, our study proposes a training-free algorithm that generates high-quality 512 x 512 and 1024 x 1024 images in eight steps, with flexible guidance scales. To the best of my knowledge, our algorithm is the first one that samples a 1024 x 1024 resolution image in 8 steps with an FID performance comparable to that of the latest distillation model, but without additional training. Meanwhile, our algorithm can also generate a 512 x 512 image in 8 steps, and its FID performance is better than the inference result using state-of-the-art ODE solver DPM++ 2m in 20 steps. We validate our eight-step image generation algorithm using the COCO 2014, COCO 2017, and LAION datasets. And our best FID performance is 15.7, 22.35, and 17.52. While the FID performance of DPM++2m is 17.3, 23.75, and 17.33. Further, it also outperforms the state-of-the-art AMED-plugin solver, whose FID performance is 19.07, 25.50, and 18.06. We also apply the algorithm in five-step inference without additional training, for which the best FID performance in the datasets mentioned above is 19.18, 23.24, and 19.61, respectively, and is comparable to the performance of the state-of-the-art AMED Pulgin solver in eight steps, SDXL-turbo in four steps, and the state-of-the-art diffusion distillation model Flash Diffusion in five steps. We also validate our algorithm in synthesizing 1024 * 1024 images within 6 steps, whose FID performance only has a limited distance to the latest distillation algorithm. The code is in repo: this https URL 

**Abstract (ZH)**: 基于扩散ODE和SDE裁剪误差的训练-free高分辨率图像生成算法 

---
# CWM: An Open-Weights LLM for Research on Code Generation with World Models 

**Title (ZH)**: CWM：一种基于世界模型的开放权重LLM代码生成研究 

**Authors**: FAIR CodeGen team. Jade Copet, Quentin Carbonneaux, Gal Cohen, Jonas Gehring, Jacob Kahn, Jannik Kossen, Felix Kreuk, Emily McMilin, Michel Meyer, Yuxiang Wei, David Zhang, Kunhao Zheng, Jordi Armengol-Estapé, Pedram Bashiri, Maximilian Beck, Pierre Chambon, Abhishek Charnalia, Chris Cummins, Juliette Decugis, Zacharias V. Fisches, François Fleuret, Fabian Gloeckle, Alex Gu, Michael Hassid, Daniel Haziza, Badr Youbi Idrissi, Christian Keller, Rahul Kindi, Hugh Leather, Gallil Maimon, Aram Markosyan, Francisco Massa, Pierre-Emmanuel Mazaré, Vegard Mella, Naila Murray, Keyur Muzumdar, Peter O'Hearn, Matteo Pagliardini, Dmitrii Pedchenko, Tal Remez, Volker Seeker, Marco Selvi, Oren Sultan, Sida Wang, Luca Wehrstedt, Ori Yoran, Lingming Zhang, Taco Cohen, Yossi Adi, Gabriel Synnaeve  

**Link**: [PDF](https://arxiv.org/pdf/2510.02387)  

**Abstract**: We release Code World Model (CWM), a 32-billion-parameter open-weights LLM, to advance research on code generation with world models. To improve code understanding beyond what can be learned from training on static code alone, we mid-train CWM on a large amount of observation-action trajectories from Python interpreter and agentic Docker environments, and perform extensive multi-task reasoning RL in verifiable coding, math, and multi-turn software engineering environments. With CWM, we provide a strong testbed for researchers to explore the opportunities world modeling affords for improving code generation with reasoning and planning in computational environments. We present first steps of how world models can benefit agentic coding, enable step-by-step simulation of Python code execution, and show early results of how reasoning can benefit from the latter. CWM is a dense, decoder-only LLM trained with a context size of up to 131k tokens. Independent of its world modeling capabilities, CWM offers strong performance on general coding and math tasks: it reaches pass@1 scores of 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on LiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further research on code world modeling, we release model checkpoints after mid-training, SFT, and RL. 

**Abstract (ZH)**: 我们发布了一个320亿参数的开放权重大型语言模型Code World Model (CWM)，以推进基于世界模型的代码生成研究。为了超越仅通过静态代码训练所能学到的代码理解，我们在大量Python解释器和代理Docker环境的观察-动作轨迹上对CWM进行中期训练，并在可验证编程、数学以及多轮软件工程环境中进行广泛的多任务推理强化学习。利用CWM，我们为研究人员提供了一个强大的实验平台，以探索世界模型在计算环境中通过推理和规划提高代码生成的机会。我们展示了世界模型如何惠及代理编程，实现Python代码执行的逐步模拟，并展示了推理如何从中获益的初步结果。CWM是一个密集型、仅解码器的大型语言模型，使用最多131k词元的上下文进行训练。除其世界建模能力外，CWM在通用编程和数学任务上表现出强劲性能：在SWE-bench Verified上达到65.8%的pass@1得分（测试时缩放），在LiveCodeBench上达到68.6%，在Math-500上达到96.6%，在AIME 2024上达到76.0%。为了支持进一步的世界模型编码研究，我们在中期训练、微调和强化学习后发布了模型检查点。 

---
# On The Fragility of Benchmark Contamination Detection in Reasoning Models 

**Title (ZH)**: 基于推理模型的基准污染检测脆弱性研究 

**Authors**: Han Wang, Haoyu Li, Brian Ko, Huan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02386)  

**Abstract**: Leaderboards for LRMs have turned evaluation into a competition, incentivizing developers to optimize directly on benchmark suites. A shortcut to achieving higher rankings is to incorporate evaluation benchmarks into the training data, thereby yielding inflated performance, known as benchmark contamination. Surprisingly, our studies find that evading contamination detections for LRMs is alarmingly easy. We focus on the two scenarios where contamination may occur in practice: (I) when the base model evolves into LRM via SFT and RL, we find that contamination during SFT can be originally identified by contamination detection methods. Yet, even a brief GRPO training can markedly conceal contamination signals that most detection methods rely on. Further empirical experiments and theoretical analysis indicate that PPO style importance sampling and clipping objectives are the root cause of this detection concealment, indicating that a broad class of RL methods may inherently exhibit similar concealment capability; (II) when SFT contamination with CoT is applied to advanced LRMs as the final stage, most contamination detection methods perform near random guesses. Without exposure to non-members, contaminated LRMs would still have more confidence when responding to those unseen samples that share similar distributions to the training set, and thus, evade existing memorization-based detection methods. Together, our findings reveal the unique vulnerability of LRMs evaluations: Model developers could easily contaminate LRMs to achieve inflated leaderboards performance while leaving minimal traces of contamination, thereby strongly undermining the fairness of evaluation and threatening the integrity of public leaderboards. This underscores the urgent need for advanced contamination detection methods and trustworthy evaluation protocols tailored to LRMs. 

**Abstract (ZH)**: LRMs评估中的基准污染：一种难以检测的欺骗方法 

---
# Scaling Homomorphic Applications in Deployment 

**Title (ZH)**: 部署中可同态应用的缩放scaling homomorphic applications in deployment 

**Authors**: Ryan Marinelli, Angelica Chowdhury  

**Link**: [PDF](https://arxiv.org/pdf/2510.02376)  

**Abstract**: In this endeavor, a proof-of-concept homomorphic application is developed to determine the production readiness of encryption ecosystems. A movie recommendation app is implemented for this purpose and productionized through containerization and orchestration. By tuning deployment configurations, the computational limitations of Fully Homomorphic Encryption (FHE) are mitigated through additional infrastructure optimizations
Index Terms: Reinforcement Learning, Orchestration, Homomorphic Encryption 

**Abstract (ZH)**: 在这个研究中，开发了一个概念验证同态应用，以确定加密生态系统的产品就绪情况。为此实现了 movie 推荐应用，并通过容器化和编排进行生产化。通过调整部署配置，对完全同态加密（FHE）的计算限制进行了缓解，通过额外的基础设施优化。关键词：强化学习、编排、同态加密 

---
# Pretraining with hierarchical memories: separating long-tail and common knowledge 

**Title (ZH)**: 基于层次记忆的预训练：区分长尾知识和常见知识 

**Authors**: Hadi Pouransari, David Grangier, C Thomas, Michael Kirchhof, Oncel Tuzel  

**Link**: [PDF](https://arxiv.org/pdf/2510.02375)  

**Abstract**: The impressive performance gains of modern language models currently rely on scaling parameters: larger models store more world knowledge and reason better. Yet compressing all world knowledge into parameters is unnecessary, as only a fraction is used per prompt, and impractical for edge devices with limited inference-time memory and compute. We address this shortcoming by a memory-augmented architecture and a pretraining strategy aligned with existing hardware paradigms. We introduce small language models that access large hierarchical parametric memory banks encoding world knowledge. During pretraining and inference, we fetch a small, context-dependent memory block and add it to the model. Our pretraining learns to store long-tail world knowledge in the memory parameters, while the small language model acts as an anchor capturing common knowledge and general reasoning abilities. Through trillion-token-scale experiments, we show significant gains: a 160M-parameters model augmented with an 18M-parameters memory fetched from a 4.6B memory bank obtains comparable performance to a regular model with more than 2x the parameters. Through extensive experiments, we study the optimal type and size of parametric memories in transformers, scaling them to over 21B parameters. We find that our proposed hierarchical feed-forward memories work robustly across transformer architectures, whether added during pretraining or post-hoc. 

**Abstract (ZH)**: 现代语言模型的 impressive performance gains 目前依赖于扩展参数量：更大的模型存储更多世界知识并能更好地推理。然而，将所有世界知识压缩到参数中是不必要的，因为每个提示仅使用其中一部分，且对于具有有限推理时内存和计算能力的边缘设备来说是不现实的。我们通过引入一种基于记忆的架构和与现有硬件范式对齐的预训练策略来解决这一 shortcomings。我们提出了一种小型语言模型，它可以访问包含世界知识的大规模分层次参数化记忆库。在预训练和推理过程中，我们获取一个小型、上下文相关的记忆块并将其添加到模型中。我们的预训练学习在记忆参数中存储长尾世界知识，而小型语言模型则作为锚点捕获常见知识和通用推理能力。通过万亿级别 Tokens 规模的实验，我们展示了显著的提升：一个使用来自46亿参数记忆块中的18亿参数记忆增强的1.6亿参数模型，在性能上与超过两倍参数的常规模型相当。通过广泛的实验，我们研究了变压器中参数化记忆的最优类型和大小，并将其扩展到超过210亿参数。我们发现，我们提出的分层次前馈记忆在各种变压器架构中都能稳健工作，无论是在预训练期间还是事后添加。 

---
# A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection 

**Title (ZH)**: 基于生成式AI与键入动态的混合验证码以增强机器人检测 

**Authors**: Ayda Aghaei Nia  

**Link**: [PDF](https://arxiv.org/pdf/2510.02374)  

**Abstract**: Completely Automated Public Turing tests to tell Computers and Humans Apart (CAPTCHAs) are a foundational component of web security, yet traditional implementations suffer from a trade-off between usability and resilience against AI-powered bots. This paper introduces a novel hybrid CAPTCHA system that synergizes the cognitive challenges posed by Large Language Models (LLMs) with the behavioral biometric analysis of keystroke dynamics. Our approach generates dynamic, unpredictable questions that are trivial for humans but non-trivial for automated agents, while simultaneously analyzing the user's typing rhythm to distinguish human patterns from robotic input. We present the system's architecture, formalize the feature extraction methodology for keystroke analysis, and report on an experimental evaluation. The results indicate that our dual-layered approach achieves a high degree of accuracy in bot detection, successfully thwarting both paste-based and script-based simulation attacks, while maintaining a high usability score among human participants. This work demonstrates the potential of combining cognitive and behavioral tests to create a new generation of more secure and user-friendly CAPTCHAs. 

**Abstract (ZH)**: 完全自动化的公共图灵测试以区分计算机和人类：一种新型认知挑战与行为生物特征分析相结合的CAPTCHA系统 

---
# A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory 

**Title (ZH)**: A-MemGuard: 基于LLM的代理记忆的主动防御框架 

**Authors**: Qianshan Wei, Tengchao Yang, Yaochen Wang, Xinfeng Li, Lijun Li, Zhenfei Yin, Yi Zhan, Thorsten Holz, Zhiqiang Lin, XiaoFeng Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02373)  

**Abstract**: Large Language Model (LLM) agents use memory to learn from past interactions, enabling autonomous planning and decision-making in complex environments. However, this reliance on memory introduces a critical security risk: an adversary can inject seemingly harmless records into an agent's memory to manipulate its future behavior. This vulnerability is characterized by two core aspects: First, the malicious effect of injected records is only activated within a specific context, making them hard to detect when individual memory entries are audited in isolation. Second, once triggered, the manipulation can initiate a self-reinforcing error cycle: the corrupted outcome is stored as precedent, which not only amplifies the initial error but also progressively lowers the threshold for similar attacks in the future. To address these challenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive defense framework for LLM agent memory. The core idea of our work is the insight that memory itself must become both self-checking and self-correcting. Without modifying the agent's core architecture, A-MemGuard combines two mechanisms: (1) consensus-based validation, which detects anomalies by comparing reasoning paths derived from multiple related memories and (2) a dual-memory structure, where detected failures are distilled into ``lessons'' stored separately and consulted before future actions, breaking error cycles and enabling adaptation. Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. This work shifts LLM memory security from static filtering to a proactive, experience-driven model where defenses strengthen over time. Our code is available in this https URL 

**Abstract (ZH)**: 大型语言模型（LLM）代理利用记忆从以往互动中学习，使其能够在复杂环境中实现自主规划和决策。然而，对记忆的依赖引入了一个关键的安全风险：对手可以向代理的记忆中注入看似无害的记录，从而操控其未来行为。这种漏洞由两个核心方面构成：首先，注入记录的恶意效果仅在特定上下文中激活，使得在单独审计记忆条目时难以检测。其次，一旦触发，这种操控可以引发自我强化的错误循环：被篡改的结果作为先例存储，不仅放大了初始错误，还逐步降低了未来类似攻击的门槛。为应对这些挑战，我们提出了一种名为A-MemGuard（代理记忆卫士）的前瞻防御框架，这是首个针对LLM代理记忆的主动防御框架。我们工作的核心思想是认识到记忆本身必须能够自我检查和自我纠正。不修改代理的核心架构，A-MemGuard结合了两种机制：（1）基于共识的验证，通过比较来自多个相关记忆的推理路径来检测异常；（2）双记忆结构，其中检测到的失败被提炼为“教训”分别存储，并在未来的行动中咨询，从而打断错误循环并实现适应。对多个基准的全面评估结果显示，A-MemGuard在有效降低攻击成功率超过95%的同时，保持了极低的实用成本。这项工作将LLM记忆安全从静态过滤转变为一种随经验增强的前瞻模型。我们的代码可在以下网址获取。 

---
# Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids 

**Title (ZH)**: 基于智能电网中被动攻击检测的联邦时空图学习 

**Authors**: Bochra Al Agha, Razane Tajeddine  

**Link**: [PDF](https://arxiv.org/pdf/2510.02371)  

**Abstract**: Smart grids are exposed to passive eavesdropping, where attackers listen silently to communication links. Although no data is actively altered, such reconnaissance can reveal grid topology, consumption patterns, and operational behavior, creating a gateway to more severe targeted attacks. Detecting this threat is difficult because the signals it produces are faint, short-lived, and often disappear when traffic is examined by a single node or along a single timeline. This paper introduces a graph-centric, multimodal detector that fuses physical-layer and behavioral indicators over ego-centric star subgraphs and short temporal windows to detect passive attacks. To capture stealthy perturbations, a two-stage encoder is introduced: graph convolution aggregates spatial context across ego-centric star subgraphs, while a bidirectional GRU models short-term temporal dependencies. The encoder transforms heterogeneous features into a unified spatio-temporal representation suitable for classification. Training occurs in a federated learning setup under FedProx, improving robustness to heterogeneous local raw data and contributing to the trustworthiness of decentralized training; raw measurements remain on client devices. A synthetic, standards-informed dataset is generated to emulate heterogeneous HAN/NAN/WAN communications with wireless-only passive perturbations, event co-occurrence, and leak-safe splits. The model achieves a testing accuracy of 98.32% per-timestep (F1_{attack}=0.972) and 93.35% per-sequence at 0.15% FPR using a simple decision rule with run-length m=2 and threshold $\tau=0.55$. The results demonstrate that combining spatial and temporal context enables reliable detection of stealthy reconnaissance while maintaining low false-positive rates, making the approach suitable for non-IID federated smart-grid deployments. 

**Abstract (ZH)**: 基于图的多模态检测器：融合ego为中心的星形子图和短时间窗口的物理层和行为指标以检测被动攻击 

---
# Training Dynamics of Parametric and In-Context Knowledge Utilization in Language Models 

**Title (ZH)**: 参数知识利用与上下文知识利用在语言模型中的训练动态 

**Authors**: Minsung Kim, Dong-Kyum Kim, Jea Kwon, Nakyeong Yang, Kyomin Jung, Meeyoung Cha  

**Link**: [PDF](https://arxiv.org/pdf/2510.02370)  

**Abstract**: Large language models often encounter conflicts between in-context knowledge retrieved at inference time and parametric knowledge acquired during pretraining. Models that accept external knowledge uncritically are vulnerable to misinformation, whereas models that adhere rigidly to parametric knowledge fail to benefit from retrieval. Despite the widespread adoption of retrieval-augmented generation, we still lack a systematic understanding of what shapes knowledge-arbitration strategies during training. This gap risks producing pretrained models with undesirable arbitration behaviors and, consequently, wasting substantial computational resources after the pretraining budget has already been spent. To address this problem, we present the first controlled study of how training conditions influence models' use of in-context and parametric knowledge, and how they arbitrate between them. We train transformer-based language models on a synthetic biographies corpus while systematically controlling various conditions. Our experiments reveal that intra-document repetition of facts fosters the development of both parametric and in-context capabilities. Moreover, training on a corpus that contains inconsistent information or distributional skew encourages models to develop robust strategies for leveraging parametric and in-context knowledge. Rather than viewing these non-ideal properties as artifacts to remove, our results indicate that they are important for learning robust arbitration. These insights offer concrete, empirical guidance for pretraining models that harmoniously integrate parametric and in-context knowledge. 

**Abstract (ZH)**: 大型语言模型常在推理时检索到的上下文环境知识与预训练中获得的参数知识之间存在冲突。不批判性地接受外部知识的模型容易受到误导信息的影响，而严格遵循参数知识的模型则无法充分利用检索功能。尽管检索增强生成已广为采用，但我们仍缺乏系统理解训练期间知识仲裁策略形成机制的认识。这一知识空白可能导致预训练模型出现不理想的仲裁行为，并在预训练预算已经花费的情况下浪费大量计算资源。为解决这一问题，我们首次从受控实验角度研究了训练条件如何影响模型对上下文环境知识和参数知识的利用及其仲裁策略。我们在一个合成的传记语料库上训练基于变换器的语言模型，系统地控制各种条件。实验结果显示，文献内部事实的重复有助于培养参数和上下文能力，而使用包含不一致信息或分布偏斜的语料库进行训练则鼓励模型发展出有效利用参数和上下文知识的稳健策略。我们的结果表明，这些非理想特性对于学习稳健的仲裁至关重要。这些洞见为和谐整合参数与上下文知识的预训练模型提供了具体的实证指导。 

---
# Beyond Manuals and Tasks: Instance-Level Context Learning for LLM Agents 

**Title (ZH)**: 超越手册和任务：LLM代理的实例级上下文学习 

**Authors**: Kuntai Cai, Juncheng Liu, Xianglin Yang, Zhaojie Niu, Xiaokui Xiao, Xing Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.02369)  

**Abstract**: Large language model (LLM) agents typically receive two kinds of context: (i) environment-level manuals that define interaction interfaces and global rules, and (ii) task-level guidance or demonstrations tied to specific goals. In this work, we identify a crucial but overlooked third type of context, instance-level context, which consists of verifiable and reusable facts tied to a specific environment instance, such as object locations, crafting recipes, and local rules. We argue that the absence of instance-level context is a common source of failure for LLM agents in complex tasks, as success often depends not only on reasoning over global rules or task prompts but also on making decisions based on precise and persistent facts. Acquiring such context requires more than memorization: the challenge lies in efficiently exploring, validating, and formatting these facts under tight interaction budgets. We formalize this problem as Instance-Level Context Learning (ILCL) and introduce our task-agnostic method to solve it. Our method performs a guided exploration, using a compact TODO forest to intelligently prioritize its next actions and a lightweight plan-act-extract loop to execute them. This process automatically produces a high-precision context document that is reusable across many downstream tasks and agents, thereby amortizing the initial exploration cost. Experiments across TextWorld, ALFWorld, and Crafter demonstrate consistent gains in both success and efficiency: for instance, ReAct's mean success rate in TextWorld rises from 37% to 95%, while IGE improves from 81% to 95%. By transforming one-off exploration into persistent, reusable knowledge, our method complements existing contexts to enable more reliable and efficient LLM agents. 

**Abstract (ZH)**: 大型语言模型代理中的实例级上下文学习 

---
# A Cross-Lingual Analysis of Bias in Large Language Models Using Romanian History 

**Title (ZH)**: 跨语言视角下大型语言模型中关于罗马尼亚历史的偏见分析 

**Authors**: Matei-Iulian Cocu, Răzvan-Cosmin Cristia, Adrian Marius Dumitran  

**Link**: [PDF](https://arxiv.org/pdf/2510.02362)  

**Abstract**: In this case study, we select a set of controversial Romanian historical questions and ask multiple Large Language Models to answer them across languages and contexts, in order to assess their biases. Besides being a study mainly performed for educational purposes, the motivation also lies in the recognition that history is often presented through altered perspectives, primarily influenced by the culture and ideals of a state, even through large language models. Since they are often trained on certain data sets that may present certain ambiguities, the lack of neutrality is subsequently instilled in users. The research process was carried out in three stages, to confirm the idea that the type of response expected can influence, to a certain extent, the response itself; after providing an affirmative answer to some given question, an LLM could shift its way of thinking after being asked the same question again, but being told to respond with a numerical value of a scale. Results show that binary response stability is relatively high but far from perfect and varies by language. Models often flip stance across languages or between formats; numeric ratings frequently diverge from the initial binary choice, and the most consistent models are not always those judged most accurate or neutral. Our research brings to light the predisposition of models to such inconsistencies, within a specific contextualization of the language for the question asked. 

**Abstract (ZH)**: 在这个案例研究中，我们选择了一组有争议的 Romanian 历史问题，要求多种大型语言模型在不同语言和背景下作答，以评估其偏见。 

---
# ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference 

**Title (ZH)**: ChunkLLM：一种加速大型语言模型推理的轻量级插件框架 

**Authors**: Haojie Ouyang, Jianwei Lv, Lei Ren, Chen Wei, Xiaojie Wang, Fangxiang Feng  

**Link**: [PDF](https://arxiv.org/pdf/2510.02361)  

**Abstract**: Transformer-based large models excel in natural language processing and computer vision, but face severe computational inefficiencies due to the self-attention's quadratic complexity with input tokens. Recently, researchers have proposed a series of methods based on block selection and compression to alleviate this problem, but they either have issues with semantic incompleteness or poor training-inference efficiency. To comprehensively address these challenges, we propose ChunkLLM, a lightweight and pluggable training framework. Specifically, we introduce two components: QK Adapter (Q-Adapter and K-Adapter) and Chunk Adapter. The former is attached to each Transformer layer, serving dual purposes of feature compression and chunk attention acquisition. The latter operates at the bottommost layer of the model, functioning to detect chunk boundaries by leveraging contextual semantic information. During the training phase, the parameters of the backbone remain frozen, with only the QK Adapter and Chunk Adapter undergoing training. Notably, we design an attention distillation method for training the QK Adapter, which enhances the recall rate of key chunks. During the inference phase, chunk selection is triggered exclusively when the current token is detected as a chunk boundary, thereby accelerating model inference. Experimental evaluations are conducted on a diverse set of long-text and short-text benchmark datasets spanning multiple tasks. ChunkLLM not only attains comparable performance on short-text benchmarks but also maintains 98.64% of the performance on long-context benchmarks while preserving a 48.58% key-value cache retention rate. Particularly, ChunkLLM attains a maximum speedup of 4.48x in comparison to the vanilla Transformer in the processing of 120K long texts. 

**Abstract (ZH)**: 基于块选择和压缩的Transformer大模型在自然语言处理和计算机视觉中的高效训练框架：ChunkLLM 

---
# Spiral of Silence in Large Language Model Agents 

**Title (ZH)**: 大型语言模型代理的沉默螺旋效应 

**Authors**: Mingze Zhong, Meng Fang, Zijing Shi, Yuxuan Huang, Shunfeng Zheng, Yali Du, Ling Chen, Jun Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02360)  

**Abstract**: The Spiral of Silence (SoS) theory holds that individuals with minority views often refrain from speaking out for fear of social isolation, enabling majority positions to dominate public discourse. When the 'agents' are large language models (LLMs), however, the classical psychological explanation is not directly applicable, since SoS was developed for human societies. This raises a central question: can SoS-like dynamics nevertheless emerge from purely statistical language generation in LLM collectives? We propose an evaluation framework for examining SoS in LLM agents. Specifically, we consider four controlled conditions that systematically vary the availability of 'History' and 'Persona' signals. Opinion dynamics are assessed using trend tests such as Mann-Kendall and Spearman's rank, along with concentration measures including kurtosis and interquartile range. Experiments across open-source and closed-source models show that history and persona together produce strong majority dominance and replicate SoS patterns; history signals alone induce strong anchoring; and persona signals alone foster diverse but uncorrelated opinions, indicating that without historical anchoring, SoS dynamics cannot emerge. The work bridges computational sociology and responsible AI design, highlighting the need to monitor and mitigate emergent conformity in LLM-agent systems. 

**Abstract (ZH)**: 螺旋静默效应在大规模语言模型中的统计语言生成动态及其评价框架 

---
# Emission-GPT: A domain-specific language model agent for knowledge retrieval, emission inventory and data analysis 

**Title (ZH)**: Emission-GPT: 一个专门领域语言模型代理，用于知识检索、排放清单编制和数据解析 

**Authors**: Jiashu Ye, Tong Wu, Weiwen Chen, Hao Zhang, Zeteng Lin, Xingxing Li, Shujuan Weng, Manni Zhu, Xin Yuan, Xinlong Hong, Jingjie Li, Junyu Zheng, Zhijiong Huang, Jing Tang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02359)  

**Abstract**: Improving air quality and addressing climate change relies on accurate understanding and analysis of air pollutant and greenhouse gas emissions. However, emission-related knowledge is often fragmented and highly specialized, while existing methods for accessing and compiling emissions data remain inefficient. These issues hinder the ability of non-experts to interpret emissions information, posing challenges to research and management. To address this, we present Emission-GPT, a knowledge-enhanced large language model agent tailored for the atmospheric emissions domain. Built on a curated knowledge base of over 10,000 documents (including standards, reports, guidebooks, and peer-reviewed literature), Emission-GPT integrates prompt engineering and question completion to support accurate domain-specific question answering. Emission-GPT also enables users to interactively analyze emissions data via natural language, such as querying and visualizing inventories, analyzing source contributions, and recommending emission factors for user-defined scenarios. A case study in Guangdong Province demonstrates that Emission-GPT can extract key insights--such as point source distributions and sectoral trends--directly from raw data with simple prompts. Its modular and extensible architecture facilitates automation of traditionally manual workflows, positioning Emission-GPT as a foundational tool for next-generation emission inventory development and scenario-based assessment. 

**Abstract (ZH)**: 提高空气质量及应对气候变化依赖于对空气污染物和温室气体排放的准确理解和分析。然而，与排放相关的知识往往是碎片化的和高度专门化的，而现有的排放数据获取和汇总方法仍然不够高效。这些问题阻碍了非专家解读排放信息的能力，给研究和管理带来了挑战。为解决这一问题，我们提出了Emission-GPT，这是一种面向大气排放领域的知识增强型大语言模型代理。Emission-GPT基于包含超过10,000份文件（包括标准、报告、指南和同行评审文献）的精心筛选知识库，通过提示工程和问题完成来支持准确的领域特定问题回答。Emission-GPT还允许用户通过自然语言交互式分析排放数据，例如查询和可视化清单、分析源贡献以及为用户自定义场景推荐排放因子。在广东省的案例研究中展示了，通过简单的提示，Emission-GPT可以从原始数据中提取关键见解，如点源分布和行业趋势。其模块化的可扩展架构使得传统手动工作流程的自动化成为可能，将Emission-GPT定位为下一代排放清单开发和基于场景评估的基本工具。 

---
# DiffuSpec: Unlocking Diffusion Language Models for Speculative Decoding 

**Title (ZH)**: DiffuSpec: 解锁用于推测性解码的扩散语言模型 

**Authors**: Guanghao Li, Zhihui Fu, Min Fang, Qibin Zhao, Ming Tang, Chun Yuan, Jun Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02358)  

**Abstract**: As large language models (LLMs) scale up, accuracy improves, but the autoregressive (AR) nature of decoding increases latency since each token requires a serial forward pass. Speculative decoding addresses this by employing a fast drafter to propose multi-token drafts, which are then verified in parallel by the target model. However, many deployments still rely on AR drafters, where sequential passes limit wall-clock gains. We revisit the drafting stage and present DiffuSpec, a training-free drop-in framework that uses a pretrained diffusion language model (DLM) to produce multi-token drafts in a single forward pass, while remaining compatible with standard AR verifiers. Because DLM drafts are generated under bidirectional conditioning, parallel per-position candidates form a token lattice in which the locally highest-probability token at each position need not form a causal left-to-right path. Moreover, DLM drafting requires pre-specifying a draft length, inducing a speed-quality trade-off. To address these challenges, we introduce two practical components: (i) a causal-consistency path search (CPS) over this lattice that extracts a left-to-right path aligned with AR verification; and (ii) an adaptive draft-length (ADL) controller that adjusts next proposal size based on recent acceptance feedback and realized generated length. Across benchmarks, DiffuSpec yields up to 3x wall-clock speedup, establishing diffusion-based drafting as a robust alternative to autoregressive drafters for speculative decoding. 

**Abstract (ZH)**: 基于扩散模型的 speculative 解码框架：DiffuSpec 

---
# Privacy in the Age of AI: A Taxonomy of Data Risks 

**Title (ZH)**: 人工智能时代的隐私保护：数据风险分类 

**Authors**: Grace Billiris, Asif Gill, Madhushi Bandara  

**Link**: [PDF](https://arxiv.org/pdf/2510.02357)  

**Abstract**: Artificial Intelligence (AI) systems introduce unprecedented privacy challenges as they process increasingly sensitive data. Traditional privacy frameworks prove inadequate for AI technologies due to unique characteristics such as autonomous learning and black-box decision-making. This paper presents a taxonomy classifying AI privacy risks, synthesised from 45 studies identified through systematic review. We identify 19 key risks grouped under four categories: Dataset-Level, Model-Level, Infrastructure-Level, and Insider Threat Risks. Findings reveal a balanced distribution across these dimensions, with human error (9.45%) emerging as the most significant factor. This taxonomy challenges conventional security approaches that typically prioritise technical controls over human factors, highlighting gaps in holistic understanding. By bridging technical and behavioural dimensions of AI privacy, this paper contributes to advancing trustworthy AI development and provides a foundation for future research. 

**Abstract (ZH)**: 人工智能系统在处理日益敏感的数据时引入了前所未有的隐私挑战。传统的隐私框架因具备自主学习和黑盒决策等独特特性而显得不够充分。本文通过系统综述识别出45项研究，并提出了一种分类AI隐私风险的分类法。我们识别出19个关键风险，分为四个类别：数据集级、模型级、基础设施级和内部威胁风险。研究结果显示，这些维度分布均衡，人为错误（9.45%）成为最主要的因素。本文的分类法挑战了传统的安全方法，这些方法通常优先考虑技术控制而非人为因素，突显了整体理解上的缺口。通过弥合AI隐私的技术和行为维度，本文为可信AI的发展贡献了力量，并为未来研究提供了基础。 

---
# Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark 

**Title (ZH)**: 大型语言模型对物理世界隐私意识的测量：一个评估基准 

**Authors**: Xinjie Shen, Mufei Li, Pan Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.02356)  

**Abstract**: The deployment of Large Language Models (LLMs) in embodied agents creates an urgent need to measure their privacy awareness in the physical world. Existing evaluation methods, however, are confined to natural language based scenarios. To bridge this gap, we introduce EAPrivacy, a comprehensive evaluation benchmark designed to quantify the physical-world privacy awareness of LLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across four tiers to test an agent's ability to handle sensitive objects, adapt to changing environments, balance task execution with privacy constraints, and resolve conflicts with social norms. Our measurements reveal a critical deficit in current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\% accuracy in scenarios involving changing physical environments. Furthermore, when a task was accompanied by a privacy request, models prioritized completion over the constraint in up to 86\% of cases. In high-stakes situations pitting privacy against critical social norms, leading models like GPT-4o and Claude-3.5-haiku disregarded the social norm over 15\% of the time. These findings, demonstrated by our benchmark, underscore a fundamental misalignment in LLMs regarding physically grounded privacy and establish the need for more robust, physically-aware alignment. 

**Abstract (ZH)**: 大规模语言模型在具身代理中的部署迫切需要评估其在物理世界中的隐私意识。现有评估方法仅限于基于自然语言的场景。为弥补这一差距，我们提出了一种名为EAPrivacy的全面评估基准，用于量化由大规模语言模型驱动的代理在物理世界中的隐私意识。EAPrivacy利用四级程序生成的场景测试代理处理敏感对象、适应变化环境、平衡任务执行与隐私约束以及解决与社会规范冲突的能力。我们的测量结果揭示了当前模型中存在的关键缺陷。在涉及变化物理环境的场景中，性能最佳的模型Gemini 2.5 Pro的准确率仅为59%。此外，当任务伴随有隐私请求时，模型在多达86%的情况下优先完成任务而非遵守约束。在涉及隐私与关键社会规范的竞争性情境中，领先模型如GPT-4o和Claude-3.5-haiku有时会超过15%的情况下忽视社会规范。这些由我们的基准测试得出的发现强调了大规模语言模型在物理接地隐私方面存在根本性的不匹配，并突显了需要更 robust、物理意识更强的对齐。 

---
# Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations 

**Title (ZH)**: 评估口语对话大语言模型在实际决策和推荐中的偏见 

**Authors**: Yihao Wu, Tianrui Wang, Yizhou Peng, Yi-Wen Chao, Xuyi Zhuang, Xinsheng Wang, Shunshun Yin, Ziyang Ma  

**Link**: [PDF](https://arxiv.org/pdf/2510.02352)  

**Abstract**: While biases in large language models (LLMs), such as stereotypes and cultural tendencies in outputs, have been examined and identified, their presence and characteristics in spoken dialogue models (SDMs) with audio input and output remain largely unexplored. Paralinguistic features, such as age, gender, and accent, can affect model outputs; when compounded by multi-turn conversations, these effects may exacerbate biases, with potential implications for fairness in decision-making and recommendation tasks. In this paper, we systematically evaluate biases in speech LLMs and study the impact of multi-turn dialogues with repeated negative feedback. Bias is measured using Group Unfairness Score (GUS) for decisions and similarity-based normalized statistics rate (SNSR) for recommendations, across both open-source models like Qwen2.5-Omni and GLM-4-Voice, as well as closed-source APIs such as GPT-4o Audio and Gemini-2.5-Flash. Our analysis reveals that closed-source models generally exhibit lower bias, while open-source models are more sensitive to age and gender, and recommendation tasks tend to amplify cross-group disparities. We found that biased decisions may persist in multi-turn conversations. This work provides the first systematic study of biases in end-to-end spoken dialogue models, offering insights towards fair and reliable audio-based interactive systems. To facilitate further research, we release the FairDialogue dataset and evaluation code. 

**Abstract (ZH)**: 大型语言模型中的偏见在输出中已有所研究，但音频输入和输出的对话语言模型（SDMs）中的偏见及其特性仍 largely unexplored。本论文系统地评估了语音大语言模型中的偏见，并研究了带有重复负面反馈的多轮对话的影响。偏见通过决策的组不公平得分（GUS）和推荐的基于相似性的标准化统计数据率（SNSR）进行衡量，涵盖了开源模型如Qwen2.5-Omni和GLM-4-Voice，以及封闭源API如GPT-4o Audio和Gemini-2.5-Flash。我们的分析发现，封闭源模型通常表现出较低的偏见，而开源模型对年龄和性别更为敏感，推荐任务会放大跨群体差异。我们发现，在多轮对话中，有偏见的决策仍可能持续存在。本工作首次系统地研究了端到端语音对话模型中的偏见，为公正可靠的基于音频的交互系统提供了见解。为促进进一步研究，我们发布了FairDialogue数据集和评估代码。 

---
# Language, Culture, and Ideology: Personalizing Offensiveness Detection in Political Tweets with Reasoning LLMs 

**Title (ZH)**: 语言、文化与意识形态：利用推理大型语言模型个性化检测政治推文的冒犯性 

**Authors**: Dzmitry Pihulski, Jan Kocoń  

**Link**: [PDF](https://arxiv.org/pdf/2510.02351)  

**Abstract**: We explore how large language models (LLMs) assess offensiveness in political discourse when prompted to adopt specific political and cultural perspectives. Using a multilingual subset of the MD-Agreement dataset centered on tweets from the 2020 US elections, we evaluate several recent LLMs - including DeepSeek-R1, o4-mini, GPT-4.1-mini, Qwen3, Gemma, and Mistral - tasked with judging tweets as offensive or non-offensive from the viewpoints of varied political personas (far-right, conservative, centrist, progressive) across English, Polish, and Russian contexts. Our results show that larger models with explicit reasoning abilities (e.g., DeepSeek-R1, o4-mini) are more consistent and sensitive to ideological and cultural variation, while smaller models often fail to capture subtle distinctions. We find that reasoning capabilities significantly improve both the personalization and interpretability of offensiveness judgments, suggesting that such mechanisms are key to adapting LLMs for nuanced sociopolitical text classification across languages and ideologies. 

**Abstract (ZH)**: 我们探索大型语言模型（LLMs）在采用特定政治和文化视角时如何评估政治 discourse中的冒犯性。我们利用旨在关注2020年美国选举推文的MD-Agreement数据集的多语种子集，评估了几种最近的LLM——包括DeepSeek-R1、o4-mini、GPT-4.1-mini、Qwen3、Gemma和Mistral——这些模型的任务是从不同的政治人格（极右、保守、中间派、进步派）视角判断推文是否冒犯。结果显示，具有显式推理能力的大型模型（如DeepSeek-R1、o4-mini）在意识形态和文化差异方面更具一致性和敏感性，而较小的模型往往难以捕捉微妙的区别。我们发现，推理能力显著提高了冒犯性判断的个性化和可解释性，表明此类机制是使LLM适应跨语言和意识形态的精细社会政治文本分类的关键。 

---
# LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL 

**Title (ZH)**: LLMSQL: 升级的WikiSQL以适应大语言模型时代的文本到SQL任务 

**Authors**: Dzmitry Pihulski, Karol Charchut, Viktoria Novogrodskaia, Jan Kocoń  

**Link**: [PDF](https://arxiv.org/pdf/2510.02350)  

**Abstract**: Converting natural language questions into SQL queries (Text-to-SQL) enables non-expert users to interact with relational databases and has long been a central task for natural language interfaces to data. While the WikiSQL dataset played a key role in early NL2SQL research, its usage has declined due to structural and annotation issues, including case sensitivity inconsistencies, data type mismatches, syntax errors, and unanswered questions. We present LLMSQL, a systematic revision and transformation of WikiSQL designed for the LLM era. We classify these errors and implement automated methods for cleaning and re-annotation. To assess the impact of these improvements, we evaluated multiple large language models (LLMs), including Gemma 3, LLaMA 3.2, Mistral 7B, gpt-oss 20B, Phi-3.5 Mini, Qwen 2.5, OpenAI o4-mini, DeepSeek R1 and others. Rather than serving as an update, LLMSQL is introduced as an LLM-ready benchmark: unlike the original WikiSQL, tailored for pointer-network models selecting tokens from input, LLMSQL provides clean natural language questions and full SQL queries as plain text, enabling straightforward generation and evaluation for modern natural language-to-SQL models. 

**Abstract (ZH)**: 将自然语言问题转换为SQL查询（Text-to-SQL）使非专业用户能够与关系数据库交互，并且一直是数据自然语言接口中的核心任务。尽管WikiSQL数据集在早期的NL2SQL研究中起到了关键作用，但其使用量由于结构和注释问题，包括大小写一致性问题、数据类型不匹配、语法错误以及答案缺失等原因而下降。我们提出LLMSQL，这是一个为LLM时代设计的系统性修订和转换的WikiSQL数据集。我们对这些错误进行了分类，并实现了自动化的清洁和重新注释方法。为了评估这些改进的影响，我们评估了多个大型语言模型（LLM），包括Gemma 3、LLaMA 3.2、Mistral 7B、gpt-oss 20B、Phi-3.5 Mini、Qwen 2.5、OpenAI o4-mini、DeepSeek R1等。不同于作为更新，LLMSQL被介绍为一个适用于LLM的基准：不同于原始的WikiSQL，LLMSQL为现代自然语言到SQL模型的生成和评估提供了干净的自然语言问题和完整的SQL查询文本。 

---
# An Investigation into the Performance of Non-Contrastive Self-Supervised Learning Methods for Network Intrusion Detection 

**Title (ZH)**: 非对比自监督学习方法在网络入侵检测中的性能研究 

**Authors**: Hamed Fard, Tobias Schalau, Gerhard Wunder  

**Link**: [PDF](https://arxiv.org/pdf/2510.02349)  

**Abstract**: Network intrusion detection, a well-explored cybersecurity field, has predominantly relied on supervised learning algorithms in the past two decades. However, their limitations in detecting only known anomalies prompt the exploration of alternative approaches. Motivated by the success of self-supervised learning in computer vision, there is a rising interest in adapting this paradigm for network intrusion detection. While prior research mainly delved into contrastive self-supervised methods, the efficacy of non-contrastive methods, in conjunction with encoder architectures serving as the representation learning backbone and augmentation strategies that determine what is learned, remains unclear for effective attack detection. This paper compares the performance of five non-contrastive self-supervised learning methods using three encoder architectures and six augmentation strategies. Ninety experiments are systematically conducted on two network intrusion detection datasets, UNSW-NB15 and 5G-NIDD. For each self-supervised model, the combination of encoder architecture and augmentation method yielding the highest average precision, recall, F1-score, and AUCROC is reported. Furthermore, by comparing the best-performing models to two unsupervised baselines, DeepSVDD, and an Autoencoder, we showcase the competitiveness of the non-contrastive methods for attack detection. Code at: this https URL 

**Abstract (ZH)**: 网络入侵检测中的无监督学习方法比较：基于三种编码器架构和六种增强策略的性能分析 

---
# mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations 

**Title (ZH)**: mini-vec2vec: 通过线性变换扩展通用几何对齐規模 

**Authors**: Guy Dar  

**Link**: [PDF](https://arxiv.org/pdf/2510.02348)  

**Abstract**: We build upon vec2vec, a procedure designed to align text embedding spaces without parallel data. vec2vec finds a near-perfect alignment, but it is expensive and unstable. We present mini-vec2vec, a simple and efficient alternative that requires substantially lower computational cost and is highly robust. Moreover, the learned mapping is a linear transformation. Our method consists of three main stages: a tentative matching of pseudo-parallel embedding vectors, transformation fitting, and iterative refinement. Our linear alternative exceeds the original instantiation of vec2vec by orders of magnitude in efficiency, while matching or exceeding their results. The method's stability and interpretable algorithmic steps facilitate scaling and unlock new opportunities for adoption in new domains and fields. 

**Abstract (ZH)**: 基于mini-vec2vec：一种简单高效的文本嵌入空间对齐方法及其应用 

---
# Small Language Models for Curriculum-based Guidance 

**Title (ZH)**: 基于课程的学习小语言模型指导 

**Authors**: Konstantinos Katharakis, Sippo Rossi, Raghava Rao Mukkamala  

**Link**: [PDF](https://arxiv.org/pdf/2510.02347)  

**Abstract**: The adoption of generative AI and large language models (LLMs) in education is still emerging. In this study, we explore the development and evaluation of AI teaching assistants that provide curriculum-based guidance using a retrieval-augmented generation (RAG) pipeline applied to selected open-source small language models (SLMs). We benchmarked eight SLMs, including LLaMA 3.1, IBM Granite 3.3, and Gemma 3 (7-17B parameters), against GPT-4o. Our findings show that with proper prompting and targeted retrieval, SLMs can match LLMs in delivering accurate, pedagogically aligned responses. Importantly, SLMs offer significant sustainability benefits due to their lower computational and energy requirements, enabling real-time use on consumer-grade hardware without depending on cloud infrastructure. This makes them not only cost-effective and privacy-preserving but also environmentally responsible, positioning them as viable AI teaching assistants for educational institutions aiming to scale personalized learning in a sustainable and energy-efficient manner. 

**Abstract (ZH)**: 生成式人工智能和大型语言模型在教育中的采用仍处于新兴阶段。本研究探索了使用检索增强生成（RAG） pipeline在选定的开源小型语言模型（SLMs）上开发和评估基于 Curriculum 的教学助手的方法。我们使用GPT-4o与八种SLM进行基准测试，包括LLaMA 3.1、IBM Granite 3.3和Gemma 3（7-17B参数）。研究发现，通过适当的提示和有针对性的检索，SLMs可以在提供精准且符合教学要求的响应方面与LLMs匹敌。重要的是，SLMs由于计算和能源需求较低，可以在消费级硬件上实现实时使用，无需依赖云基础设施，从而使其在成本效益、保护隐私和环保方面具有优势，将其定位为致力于以可持续且能效高的方式规模化个性化学习的教育机构的可行的教学助手。 

---
# Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression 

**Title (ZH)**: 打破MoE大语言模型的三难困境：动态专家聚类结合结构化压缩 

**Authors**: Peijun Zhu, Ning Yang, Jiayu Wei, Jinghang Wu, Haijun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02345)  

**Abstract**: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an online clustering procedure that periodically regroups experts using a fused metric of parameter and activation similarity, which stabilizes expert utilization. To our knowledge, this is one of the first frameworks to leverage the semantic embedding capability of the router to dynamically reconfigure the model's architecture during training for substantial efficiency gains. Within each cluster, we decompose expert weights into a shared base matrix and extremely low-rank residual adapters, achieving up to fivefold parameter reduction per group while preserving specialization. This structure enables a two-stage hierarchical routing strategy: tokens are first assigned to a cluster, then to specific experts within it, drastically reducing the routing search space and the volume of all-to-all communication. Furthermore, a heterogeneous precision scheme, which stores shared bases in FP16 and residual factors in INT4, coupled with dynamic offloading of inactive clusters, reduces peak memory consumption to levels comparable to dense models. Evaluated on GLUE and WikiText-103, our framework matches the quality of standard MoE models while reducing total parameters by approximately 80%, improving throughput by 10% to 20%, and lowering expert load variance by a factor of over three. Our work demonstrates that structural reorganization is a principled path toward scalable, efficient, and memory-effective MoE LLMs. 

**Abstract (ZH)**: 混合专家（MoE）大型语言模型（LLM）面临负载不平衡、参数冗余和通信开销三者的权衡问题。我们提出了一种基于动态专家聚类和结构化压缩的统一框架，以统筹解决这些问题。该方法采用了一种在线聚类过程，定期使用参数和激活相似性的融合度量重新分组专家，从而稳定专家利用情况。据我们所知，这是第一个利用路由器的语义嵌入能力，在训练期间动态重构模型架构以实现显著效率提升的框架。在每个聚类内，我们将专家权重分解为共享的基本矩阵和极低秩的残留适配器，每个组可实现五倍量级的参数减少，同时保持专业性。这种结构使得路由策略可以分两阶段进行层级化：首先将标记分配到聚类，然后分配到其内的特定专家，极大减少了路由搜索空间和全连接通信的体积。此外，采用异构精度方案，将共享基存储为FP16，并将残留因子存储为INT4，结合动态卸载不活动聚类，显著降低了峰值内存消耗，使其与密集模型水平相当。在GLUE和WikiText-103上评估，我们的框架在减少总参数约80%的情况下，提高了10%到20%的吞吐量，并将专家负载变异度降低了超过三倍。我们的工作表明，结构重组是实现可扩展、高效且内存有效的MoE LLMs的一条原理性路径。 

---
# $\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation and Training 

**Title (ZH)**: BluePrint: 一种社交媒体用户数据集，用于LLM人格评估与训练 

**Authors**: Aurélien Bück-Kaeffer, Je Qin Chooi, Dan Zhao, Maximilian Puelma Touzel, Kellin Pelrine, Jean-François Godbout, Reihaneh Rabbany, Zachary Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02343)  

**Abstract**: Large language models (LLMs) offer promising capabilities for simulating social media dynamics at scale, enabling studies that would be ethically or logistically challenging with human subjects. However, the field lacks standardized data resources for fine-tuning and evaluating LLMs as realistic social media agents. We address this gap by introducing SIMPACT, the SIMulation-oriented Persona and Action Capture Toolkit, a privacy respecting framework for constructing behaviorally-grounded social media datasets suitable for training agent models. We formulate next-action prediction as a task for training and evaluating LLM-based agents and introduce metrics at both the cluster and population levels to assess behavioral fidelity and stylistic realism. As a concrete implementation, we release BluePrint, a large-scale dataset built from public Bluesky data focused on political discourse. BluePrint clusters anonymized users into personas of aggregated behaviours, capturing authentic engagement patterns while safeguarding privacy through pseudonymization and removal of personally identifiable information. The dataset includes a sizable action set of 12 social media interaction types (likes, replies, reposts, etc.), each instance tied to the posting activity preceding it. This supports the development of agents that use context-dependence, not only in the language, but also in the interaction behaviours of social media to model social media users. By standardizing data and evaluation protocols, SIMPACT provides a foundation for advancing rigorous, ethically responsible social media simulations. BluePrint serves as both an evaluation benchmark for political discourse modeling and a template for building domain specific datasets to study challenges such as misinformation and polarization. 

**Abstract (ZH)**: 大型语言模型（LLMs）提供了模拟大规模社交媒体动态的前景能力，使得使用人类受试者进行的研究在伦理和组织方面更具挑战性。然而，领域内缺乏用于微调和评估LLMs作为真实社交媒体代理的标准数据资源。我们通过引入SIMPACT（SIMulation-oriented Persona and Action Capture Toolkit）来填补这一空白，SIMPACT是一个尊重隐私的框架，用于构建行为上一致的社交媒体数据集，适用于训练代理模型。我们将下一步行动预测作为训练和评估LLM基代理的任务，并介绍了群组和人口层面的评估指标来衡量行为真实性和风格的现实性。作为具体的实现，我们发布了BluePrint，一个基于公共Bluesky数据的大规模数据集，侧重于政治讨论。BluePrint将匿名用户聚类成行为聚合的人格，通过假名化和去除个人可识别信息来保护隐私，捕获真实的参与模式。数据集包括12种社交媒体互动类型（点赞、回复、转发等）的操作集，每个实例都与其之前的发布活动相关。这支持了不仅在语言，还在社交媒体互动行为上具有情境依赖性的代理模型的发展。通过标准化数据和评估协议，SIMPACT为推动严格的、负责任的社交媒体模拟提供了基础。BluePrint既作为政治讨论建模的评估基准，也为研究信息误导和极化等特定领域挑战提供了模板。 

---
# CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models 

**Title (ZH)**: CATMark：一种面向大规模语言模型跨任务 robust 水标记有的上下文感知阈值框架 

**Authors**: Yu Zhang, Shuliang Liu, Xu Yang, Xuming Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.02342)  

**Abstract**: Watermarking algorithms for Large Language Models (LLMs) effectively identify machine-generated content by embedding and detecting hidden statistical features in text. However, such embedding leads to a decline in text quality, especially in low-entropy scenarios where performance needs improvement. Existing methods that rely on entropy thresholds often require significant computational resources for tuning and demonstrate poor adaptability to unknown or cross-task generation scenarios. We propose \textbf{C}ontext-\textbf{A}ware \textbf{T}hreshold watermarking ($\myalgo$), a novel framework that dynamically adjusts watermarking intensity based on real-time semantic context. $\myalgo$ partitions text generation into semantic states using logits clustering, establishing context-aware entropy thresholds that preserve fidelity in structured content while embedding robust watermarks. Crucially, it requires no pre-defined thresholds or task-specific tuning. Experiments show $\myalgo$ improves text quality in cross-tasks without sacrificing detection accuracy. 

**Abstract (ZH)**: Large Language Models（LLMs）的水印算法通过嵌入和检测文本中的隐藏统计特征有效识别机器生成的内容。然而，这种嵌入会导致文本质量下降，尤其是在低熵场景中性能需要提升的情况下。现有的依赖于熵阈值的方法往往需要大量计算资源进行调优，并且在未知或跨任务生成场景中表现不佳。我们提出了一种新的框架——\textbf{C}ontext-\textbf{A}ware \textbf{T}hreshold 水印（$\myalgo$），该框架能够基于实时语义上下文动态调整水印强度。$\myalgo$ 使用 logits 聚类将文本生成划分为语义状态，并建立语境感知的熵阈值，在保持结构化内容保真度的同时嵌入稳健的水印。 crucially，它不需要预定义的阈值或特定任务的调优。实验结果显示，$\myalgo$ 能在跨任务中提高文本质量而不牺牲检测准确性。 

---
# DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning 

**Title (ZH)**: DRIFT：从现实世界偏好学习中丰富的用户不满中学习 

**Authors**: Yifan Wang, Bolian Li, Junlin Wu, Zhaoxuan Tan, Zheli Liu, Ruqi Zhang, Ananth Grama, Qingkai Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2510.02341)  

**Abstract**: Real-world large language model deployments (e.g., conversational AI systems, code generation assistants) naturally generate abundant implicit user dissatisfaction (DSAT) signals, as users iterate toward better answers through refinements, corrections, and expressed preferences, while explicit satisfaction (SAT) feedback is scarce. Existing preference learning approaches are poorly aligned with this data profile, as they rely on costly human annotations or assume plentiful positive responses. In this paper, we introduce \textbf{DRIFT} (\textbf{D}issatisfaction-\textbf{R}efined \textbf{I}terative pre\textbf{F}erence \textbf{T}raining), which anchors training on real-world DSAT signals and samples positives dynamically from the evolving policy. Empirically, DRIFT models trained on real-world \textit{WildFeedback} datasets and synthetic \textit{UltraFeedback} datasets achieve up to +6.23\% (7B) / +7.61\% (14B) on WildBench Task Score and up to +8.95\% (7B) / +12.29\% (14B) on AlpacaEval2 win rate over base models, outperforming strong baseline methods such as iterative DPO and SPIN. At larger scales, the improvements are particularly pronounced: 14B models trained with DRIFT surpass GPT-4o-mini on WildBench. Further analysis shows that DRIFT also preserves exploratory capacity, yielding more diverse high-reward solutions rather than collapsing to narrow subsets. Theoretically, we demonstrate that this design preserves preference margins and avoids the gradient degeneration. These results show that DRIFT is an effective and scalable recipe for real-world post-training that leverages the most abundant and informative signal. The code and data are available at this https URL. 

**Abstract (ZH)**: 实世界大规模语言模型部署中的隐式用户不满意信号驱动的迭代偏好训练（基于真实世界和合成数据集的DRIFT模型） 

---
# Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models 

**Title (ZH)**: 评估论辩型大型语言模型中的不确定性量化方法 

**Authors**: Kevin Zhou, Adam Dejl, Gabriel Freedman, Lihu Chen, Antonio Rago, Francesca Toni  

**Link**: [PDF](https://arxiv.org/pdf/2510.02339)  

**Abstract**: Research in uncertainty quantification (UQ) for large language models (LLMs) is increasingly important towards guaranteeing the reliability of this groundbreaking technology. We explore the integration of LLM UQ methods in argumentative LLMs (ArgLLMs), an explainable LLM framework for decision-making based on computational argumentation in which UQ plays a critical role. We conduct experiments to evaluate ArgLLMs' performance on claim verification tasks when using different LLM UQ methods, inherently performing an assessment of the UQ methods' effectiveness. Moreover, the experimental procedure itself is a novel way of evaluating the effectiveness of UQ methods, especially when intricate and potentially contentious statements are present. Our results demonstrate that, despite its simplicity, direct prompting is an effective UQ strategy in ArgLLMs, outperforming considerably more complex approaches. 

**Abstract (ZH)**: 大型语言模型(LLMs)不确定性量化(UQ)研究 increasingly important towards guaranteeing the reliability of this groundbreaking technology: 探索将LLM UQ方法集成到论辩型LLM(ArgLLMs)中的不确定性量化在基于计算论辩的决策框架中的作用及其评估 

---
# Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards 

**Title (ZH)**: 基于主张的奖励优化长格式临床文本生成 

**Authors**: Samyak Jhaveri, Praphul Singh, Jangwon Kim, Tara Taghavi, Krishnaram Kenthapadi  

**Link**: [PDF](https://arxiv.org/pdf/2510.02338)  

**Abstract**: Automating clinical documentation with large language models requires precise alignment with priorities such as completeness and factual grounding. We present an evaluation-integrated reinforcement learning framework for long-form clinical text generation that couples Group Relative Policy Optimization (GRPO) with DocLens, a claim-level evaluator that provides deterministic, dialogue-grounded rewards. Our method directly optimizes factual grounding and completeness without training a separate reward model or relying on human-authored references. Empirically, the approach improves clinical note quality and reduces training cost via a simple reward-gating strategy. An independent GPT-5 qualitative evaluation further supports these gains, showing higher preference for GRPO outputs in factuality, completeness, and brevity, with fewer omissions and hallucinations. Because the benchmarks are relatively clean and the base model already well aligned, these improvements likely represent a conservative lower bound. The framework is scalable to real-world settings and can incorporate custom objectives such as guideline adherence or billing preferences. 

**Abstract (ZH)**: 利用大型语言模型自动化临床文档生成要求与完备性和事实基础等优先事项精确对齐。我们提出了一种结合组相对策略优化（GRPO）和基于声明的评估器DocLens的评估集成强化学习框架，用于长格式临床文本生成。该方法直接优化事实基础和完备性，无需训练独立的奖励模型或依赖于人工撰写的参考文献。实验结果表明，该方法通过简单的奖励门控策略提高了临床笔记的质量并降低了训练成本。独立的GPT-5定性评估进一步支持了这些改进，表明GRPO输出在事实性、完备性和简洁性方面获得了更高的偏好，且遗漏和虚构较少。由于基准数据相对干净且基础模型已很好地对齐，这些改进可能代表了一个保守的下限。该框架可以扩展到实际应用场景，并可以纳入自定义目标，如指南遵循或收费偏好。 

---
# CRACQ: A Multi-Dimensional Approach To Automated Document Assessment 

**Title (ZH)**: CRACQ: 多维度的自动文档评估方法 

**Authors**: Ishak Soltani, Francisco Belo, Bernardo Tavares  

**Link**: [PDF](https://arxiv.org/pdf/2510.02337)  

**Abstract**: This paper presents CRACQ, a multi-dimensional evaluation framework tailored to evaluate documents across f i v e specific traits: Coherence, Rigor, Appropriateness, Completeness, and Quality. Building on insights from traitbased Automated Essay Scoring (AES), CRACQ expands its fo-cus beyond essays to encompass diverse forms of machine-generated text, providing a rubricdriven and interpretable methodology for automated evaluation. Unlike singlescore approaches, CRACQ integrates linguistic, semantic, and structural signals into a cumulative assessment, enabling both holistic and trait-level analysis. Trained on 500 synthetic grant pro-posals, CRACQ was benchmarked against an LLM-as-a-judge and further tested on both strong and weak real applications. Preliminary results in-dicate that CRACQ produces more stable and interpretable trait-level judgments than direct LLM evaluation, though challenges in reliability and domain scope remain 

**Abstract (ZH)**: This paper presents CRACQ，一种针对五种特定特质（连贯性、严谨性、适宜性、完整性、质量）评价文档的多维度评估框架。基于基于特质的机器作文评分（AES）的见解，CRACQ 的关注点不仅限于作文，还涵盖了各种形式的机器生成文本，提供了一种基于评分标准且具有可解释性的自动化评估方法。不同于单一评分方法，CRACQ 将语言、语义和结构信号整合到综合评估中，既能够进行整体分析又能进行特质层面的分析。CRACQ 基于500份合成的资助提案进行训练，并与基于LLM的评判进行了基准测试，进一步在强应用和弱应用上进行了测试。初步结果显示，CRACQ 在特质层面生成的判断比直接的LLM评估更加稳定且具有解释性，尽管在可靠性和领域范围方面仍存在挑战。 

---
# KurdSTS: The Kurdish Semantic Textual Similarity 

**Title (ZH)**: KurdSTS：库尔德语语义文本相似度 

**Authors**: Abdulhady Abas Abdullah, Hadi Veisi, Hussein M. Al  

**Link**: [PDF](https://arxiv.org/pdf/2510.02336)  

**Abstract**: Semantic Textual Similarity (STS) measures the degree of meaning overlap between two texts and underpins many NLP tasks. While extensive resources exist for high-resource languages, low-resource languages such as Kurdish remain underserved. We present, to our knowledge, the first Kurdish STS dataset: 10,000 sentence pairs spanning formal and informal registers, each annotated for similarity. We benchmark Sentence-BERT, multilingual BERT, and other strong baselines, obtaining competitive results while highlighting challenges arising from Kurdish morphology, orthographic variation, and code-mixing. The dataset and baselines establish a reproducible evaluation suite and provide a strong starting point for future research on Kurdish semantics and low-resource NLP. 

**Abstract (ZH)**: 低资源语言库尔德语语义文本相似性数据集及其benchmark分析：面向库尔德语语义研究和低资源NLP的起点 

---
# FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory 

**Title (ZH)**: FormalML：机器学习理论中形式子目标完成评估的标准基准 

**Authors**: Xiao-Wen Yang, Zihao Zhang, Jianuo Cao, Zhi Zhou, Zenan Li, Lan-Zhe Guo, Yuan Yao, Taolue Chen, Yu-Feng Li, Xiaoxing Ma  

**Link**: [PDF](https://arxiv.org/pdf/2510.02335)  

**Abstract**: Large language models (LLMs) have recently demonstrated remarkable progress in formal theorem proving. Yet their ability to serve as practical assistants for mathematicians, filling in missing steps within complex proofs, remains underexplored. We identify this challenge as the task of subgoal completion, where an LLM must discharge short but nontrivial proof obligations left unresolved in a human-provided sketch. To study this problem, we introduce FormalML, a Lean 4 benchmark built from foundational theories of machine learning. Using a translation tactic that converts procedural proofs into declarative form, we extract 4937 problems spanning optimization and probability inequalities, with varying levels of difficulty. FormalML is the first subgoal completion benchmark to combine premise retrieval and complex research-level contexts. Evaluation of state-of-the-art provers highlights persistent limitations in accuracy and efficiency, underscoring the need for more capable LLM-based theorem provers for effective subgoal completion, 

**Abstract (ZH)**: 大型语言模型（LLMs）在形式定理证明方面 recently demonstrated remarkable progress.然而，它们作为数学家的实际助手，填补复杂证明中缺失的步骤的能力仍需进一步探索。我们将其挑战定义为子目标完成任务，即LLM必须在人类提供的草图中解决未解决的简短但非平凡的证明义务。为了研究这一问题，我们引入了FormalML，这是一个基于机器学习基础理论的Lean 4基准。通过将过程性证明转换为声明性形式的转换技巧，我们提取了4937个问题，涵盖了优化和概率不等式等多个不同难度级别。FormalML是第一个结合前提检索和复杂研究级上下文的子目标完成基准。对当前最先进的证明系统的评估揭示了在准确性和效率方面的一贯局限性，强调了需要更高效的基于LLM的证明系统以有效完成子目标完成任务。 

---
# Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing 

**Title (ZH)**: 哪里出了问题？通过表示梯度追踪归因不良LLM行为 

**Authors**: Zhe Li, Wei Zhao, Yige Li, Jun Sun  

**Link**: [PDF](https://arxiv.org/pdf/2510.02334)  

**Abstract**: Large Language Models (LLMs) have demonstrated remarkable capabilities, yet their deployment is frequently undermined by undesirable behaviors such as generating harmful content, factual inaccuracies, and societal biases. Diagnosing the root causes of these failures poses a critical challenge for AI safety. Existing attribution methods, particularly those based on parameter gradients, often fall short due to prohibitive noisy signals and computational complexity. In this work, we introduce a novel and efficient framework that diagnoses a range of undesirable LLM behaviors by analyzing representation and its gradients, which operates directly in the model's activation space to provide a semantically meaningful signal linking outputs to their training data. We systematically evaluate our method for tasks that include tracking harmful content, detecting backdoor poisoning, and identifying knowledge contamination. The results demonstrate that our approach not only excels at sample-level attribution but also enables fine-grained token-level analysis, precisely identifying the specific samples and phrases that causally influence model behavior. This work provides a powerful diagnostic tool to understand, audit, and ultimately mitigate the risks associated with LLMs. The code is available at this https URL. 

**Abstract (ZH)**: 大型语言模型（LLMs）展示了显著的能力，但其部署常因生成有害内容、事实不准确和社会偏见等不良行为而受阻。诊断这些失败的根本原因是对AI安全的一个关键挑战。现有的归因方法，尤其是基于参数梯度的方法，往往由于噪声信号强和计算复杂性不足而表现不佳。在此工作中，我们提出了一种新型且高效的框架，通过分析表示及其梯度来诊断多种不良的LLM行为，该框架直接在模型的激活空间中操作，提供一种语义上具有意义的信号，将输出与其训练数据联系起来。我们系统地评估了该方法在包括追踪有害内容、检测后门污染和识别知识污染等任务中的性能。结果表明，我们的方法不仅在样本级归因方面表现出色，还能实现精细的令牌级分析，精确识别对模型行为有因果影响的具体样本和短语。这项工作提供了一种强大的诊断工具，以理解、审计并最终减轻LLMs相关的风险。代码可在以下链接获取。 

---
# Human Mobility Datasets Enriched With Contextual and Social Dimensions 

**Title (ZH)**: 富含上下文和社会维度的人类移动数据集 

**Authors**: Chiara Pugliese, Francesco Lettich, Guido Rocchietti, Chiara Renso, Fabio Pinelli  

**Link**: [PDF](https://arxiv.org/pdf/2510.02333)  

**Abstract**: In this resource paper, we present two publicly available datasets of semantically enriched human trajectories, together with the pipeline to build them. The trajectories are publicly available GPS traces retrieved from OpenStreetMap. Each dataset includes contextual layers such as stops, moves, points of interest (POIs), inferred transportation modes, and weather data. A novel semantic feature is the inclusion of synthetic, realistic social media posts generated by Large Language Models (LLMs), enabling multimodal and semantic mobility analysis. The datasets are available in both tabular and Resource Description Framework (RDF) formats, supporting semantic reasoning and FAIR data practices. They cover two structurally distinct, large cities: Paris and New York. Our open source reproducible pipeline allows for dataset customization, while the datasets support research tasks such as behavior modeling, mobility prediction, knowledge graph construction, and LLM-based applications. To our knowledge, our resource is the first to combine real-world movement, structured semantic enrichment, LLM-generated text, and semantic web compatibility in a reusable framework. 

**Abstract (ZH)**: 本资源论文中，我们介绍了两个富含语义的个人轨迹公开数据集及其构建管道。这些轨迹来源于OpenStreetMap的公开GPS轨迹。每个数据集包含上下文层，如停留点、移动轨迹、兴趣点（POIs）、推断的交通模式以及天气数据。一种新颖的语义特征是通过大型语言模型（LLMs）生成的合成、真实的社交媒体帖子，支持多模态和语义移动性分析。数据集以表格形式和资源描述框架（RDF）格式提供，支持语义推理和FAIR数据实践。它们涵盖了两个结构上不同的大型城市：巴黎和纽约。我们开源的可再现管道允许数据集的定制，而数据集支持行为建模、移动性预测、知识图谱构建以及基于LLM的应用。据我们所知，这是第一个将真实世界移动性、结构化语义增强、LLM生成文本以及语义网兼容性整合在一个可重用框架中的资源。 

---
# A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography 

**Title (ZH)**: 高容量和安全的语义消歧算法研究：神经语言隐写术 

**Authors**: Yapei Feng, Feng Jiang, Shanhao Wu, Hua Zhong  

**Link**: [PDF](https://arxiv.org/pdf/2510.02332)  

**Abstract**: Neural linguistic steganography aims to embed information
into natural text while preserving statistical undetectability. A fundamental challenge in this ffeld stems from tokenization ambiguity in modern tokenizers, which can lead to catastrophic decoding failures. The recent method, SyncPool, addresses this ambiguity
by employing a coarse-grained synchronization mechanism over groups of ambiguous candidates. However, SyncPool sacriffces embedding capacity, as it utilizes the entire Shannon entropy of an ambiguous group solely for synchronization rather than for payload embedding. We propose a method named look-ahead Sync, which overcomes the capacity limitation of SyncPool while retaining its provable security guarantees. Our approach performs minimal synchronized sampling only on truly indistinguishable token sequences, while strategically preserving all other discernible paths to maximize embedding capacity. We provide theoretical proofs for the security of our method and analyze the gap between its achievable embedding capacity and the theoretical upper bound. Experiments on English (using Llama 3) and Chinese (using Qwen 2.5) benchmarks show that our method consistently approaches the theoretical capacity upper bound and signiffcantly outperforms SyncPool. The improvement in embedding rate exceeds 160% in English and 25% in Chinese, particularly in settings with larger candidate pools. This work represents a signiffcant step toward practical high-capacity provably secure linguistic steganography. 

**Abstract (ZH)**: 神经语言隐写术旨在将信息嵌入自然文本中同时保持统计不可检测性。这一领域的一个基本挑战源自现代分词器中的分词模糊性，这可能导致灾难性的解码失败。近期方法SyncPool通过在一组模糊候选词上采用粗粒度同步机制来解决这一模糊性，但SyncPool牺牲了嵌入容量，因为它仅利用模糊组的整个香农熵来进行同步，而不是用于有效载荷嵌入。我们提出了一种名为前瞻Sync的方法，该方法克服了SyncPool的容量限制，同时保持其可证明的安全性保证。我们的方法仅在真正无法区分的令牌序列上进行最小同步采样，而战略性地保留所有其他可区分路径，以最大限度地提高嵌入容量。我们为该方法提供了安全性的理论证明，并分析了其可实现的嵌入容量与理论上限之间的差距。在使用Llama 3的英语基准和使用Qwen 2.5的中文基准上的实验表明，我们的方法可以一致地接近理论容量上限，显著优于SyncPool。英语中的嵌入率提升超过160%，中文中的提升超过25%，特别是在候选池较大的设置中。这项工作代表了实用高容量可证明安全的语言隐写术的重要一步。 

---
# Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER) 

**Title (ZH)**: 合成对话生成用于交互式会话引发与推荐（ICER） 

**Authors**: Moonkyung Ryu, Chih-Wei Hsu, Yinlam Chow, Mohammad Ghavamzadeh, Craig Boutilier  

**Link**: [PDF](https://arxiv.org/pdf/2510.02331)  

**Abstract**: While language models (LMs) offer great potential for conversational recommender systems (CRSs), the paucity of public CRS data makes fine-tuning LMs for CRSs challenging. In response, LMs as user simulators qua data generators can be used to train LM-based CRSs, but often lack behavioral consistency, generating utterance sequences inconsistent with those of any real user. To address this, we develop a methodology for generating natural dialogues that are consistent with a user's underlying state using behavior simulators together with LM-prompting. We illustrate our approach by generating a large, open-source CRS data set with both preference elicitation and example critiquing. Rater evaluation on some of these dialogues shows them to exhibit considerable consistency, factuality and naturalness. 

**Abstract (ZH)**: 语言模型（LMs）为对话式推荐系统（CRSs）提供了巨大潜力，但由于缺乏公开的CRS数据，使LMs针对CRSs的微调具有挑战性。为应对这一挑战，可以将LMs作为数据生成器用于训练基于LM的CRSs，但它们往往缺乏行为一致性，生成的对话序列与任何真实用户的行为不符。为解决这一问题，我们开发了一种方法，利用行为模拟器与LM提示生成与用户潜在状态一致的自然对话。我们通过生成包含偏好 elicitation 和示例批评的大规模开源CRS数据集来说明我们的方法。对部分对话的评估显示，它们表现出相当高的一致性和自然性。 

---
# EntropyLong: Effective Long-Context Training via Predictive Uncertainty 

**Title (ZH)**: 熵长：通过预测不确定性进行有效的长上下文训练 

**Authors**: Junlong Jia, Ziyang Chen, Xing Wu, Chaochen Gao, Zijia Lin, Debing Zhang, Songlin Hu, Binghui Guo  

**Link**: [PDF](https://arxiv.org/pdf/2510.02330)  

**Abstract**: Training long-context language models to capture long-range dependencies requires specialized data construction. Current approaches, such as generic text concatenation or heuristic-based variants, frequently fail to guarantee genuine long-range dependencies. We propose EntropyLong, a novel data construction method that leverages predictive uncertainty to verify dependency quality. Our approach identifies high-entropy positions in documents, retrieves semantically relevant contexts from large corpora, and verifies their utility by assessing whether they reduce prediction entropy. This model-in-the-loop verification ensures each dependency represents measurable information gain rather than spurious correlation. We construct training samples with long-range dependencies by combining original documents with these verified contextual supplements. Using FineWebEdu and Cosmopedia, we generate a dataset of 128K-length sequences with verified dependencies. Models trained on this data demonstrate significant improvements on RULER benchmarks, particularly in tasks requiring distant information. Following instruction fine-tuning, our models also achieve substantial gains on LongBenchv2, demonstrating enhanced long-context understanding. Extensive ablation studies further validate the necessity and effectiveness of entropybased verification for long-context training. 

**Abstract (ZH)**: 利用预测不确定性验证依赖质量以构建长上下文语言模型的数据构造方法 EntropyLong及其在验证长范围依赖数据集构建中的应用 

---
# SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification 

**Title (ZH)**: SelfJudge: 更快的推测解码 via 自监督判决验证 

**Authors**: Kanghoon Yoon, Minsub Kim, Sungjae Lee, Joonhyung Lee, Sunghyeon Woo, Yeonjun In, Se Jung Kwon, Chanyoung Park, Dongsoo Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.02329)  

**Abstract**: Speculative decoding accelerates LLM inference by verifying candidate tokens from a draft model against a larger target model. Recent judge decoding boosts this process by relaxing verification criteria by accepting draft tokens that may exhibit minor discrepancies from target model output, but existing methods are restricted by their reliance on human annotations or tasks with verifiable ground truths, limiting generalizability across diverse NLP tasks. We propose SelfJudge, which trains judge verifiers via self-supervision of the target model. Our method measures semantic preservation by assessing whether token-substituted responses preserve the meaning of original responses, enabling automatic verifier training across diverse NLP tasks. Our experiments show SelfJudge achieves superior inference-accuracy trade-offs than judge decoding baselines, offering a broadly applicable solution for faster LLM inference. 

**Abstract (ZH)**: 推测解码通过验证草稿模型的候选词against目标模型来加速大语言模型的推理。近期的法官解码通过放宽验证标准来提升这一过程，接受可能与目标模型输出有轻微差异的草稿词，但现有方法受限于其对人工注释的依赖或可验证的_ground_truth_任务，限制了其在多种NLP任务中的普适性。我们提出SelfJudge，该方法通过目标模型的自监督训练法官验证器。我们的方法通过评估token替换后的响应是否保留了原始响应的含义来衡量语义保真度，从而实现跨多种NLP任务的自动验证器训练。我们的实验表明，SelfJudge在推理准确性和效率之间取得了优于法官解码基线的性能，提供了一种广泛适用的快速大语言模型推理解决方案。 

---
# AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering 

**Title (ZH)**: AMANDA: 基于代理的医学知识增强在数据高效医学视觉问答中的应用 

**Authors**: Ziqing Wang, Chengsheng Mao, Xiaole Wen, Yuan Luo, Kaize Ding  

**Link**: [PDF](https://arxiv.org/pdf/2510.02328)  

**Abstract**: Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise in medical visual question answering (Med-VQA). However, when deployed in low-resource settings where abundant labeled data are unavailable, existing Med-MLLMs commonly fail due to their medical reasoning capability bottlenecks: (i) the intrinsic reasoning bottleneck that ignores the details from the medical image; (ii) the extrinsic reasoning bottleneck that fails to incorporate specialized medical knowledge. To address those limitations, we propose AMANDA, a training-free agentic framework that performs medical knowledge augmentation via LLM agents. Specifically, our intrinsic medical knowledge augmentation focuses on coarse-to-fine question decomposition for comprehensive diagnosis, while extrinsic medical knowledge augmentation grounds the reasoning process via biomedical knowledge graph retrieval. Extensive experiments across eight Med-VQA benchmarks demonstrate substantial improvements in both zero-shot and few-shot Med-VQA settings. The code is available at this https URL. 

**Abstract (ZH)**: 医疗多模态大型语言模型（Med-MLLMs）在医疗视觉问答（Med-VQA）方面展现了巨大的潜力。然而，在缺乏充足标注数据的低资源环境中部署时，现有Med-MLLMs常因医疗推理能力瓶颈而失效：（i）内在推理瓶颈，忽视了医学图像的细节；（ii）外在推理瓶颈，未能结合专业医学知识。为解决这些限制，我们提出了一种无需训练的代理框架AMANDA，通过LLM代理进行医疗知识增强。具体来说，我们的内在医疗知识增强侧重于从粗到细的问题分解以实现全面诊断，而外在医疗知识增强则通过生物医学知识图谱检索来指导推理过程。在八个Med-VQA基准上的广泛实验表明，在零样本和少量样本Med-VQA设置中均取得了显著改进。代码可在以下链接获取：this https URL。 

---
# KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI 

**Title (ZH)**: KAME: 串联架构在实时语音对话AI中增强知识 

**Authors**: So Kuroki, Yotaro Kubo, Takuya Akiba, Yujin Tang  

**Link**: [PDF](https://arxiv.org/pdf/2510.02327)  

**Abstract**: Real-time speech-to-speech (S2S) models excel at generating natural, low-latency conversational responses but often lack deep knowledge and semantic understanding. Conversely, cascaded systems combining automatic speech recognition, a text-based Large Language Model (LLM), and text-to-speech synthesis offer superior knowledge representation at the cost of high latency, which disrupts the flow of natural interaction. This paper introduces a novel hybrid architecture that bridges the gap between these two paradigms. Our framework processes user speech through an S2S transformer for immediate responsiveness while concurrently relaying the query to a powerful back-end LLM. The LLM's text-based response is then injected in real time to guide the S2S model's speech generation, effectively infusing its output with rich knowledge without the full latency penalty of a cascaded system. We evaluated our method using a speech-synthesized variant of the MT-Bench benchmark that consists of multi-turn question-answering sessions. The results demonstrate that our system substantially outperforms a baseline S2S model in response correctness, approaching that of a cascaded system, while maintaining a latency on par with the baseline. 

**Abstract (ZH)**: 基于实时语音到语音模型与后端大语言模型的新型混合架构：兼具即时响应与深度知识理解 

---
# Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval 

**Title (ZH)**: 具有自我评估和向量grounded检索的抗幻觉领域特定研究助理 

**Authors**: Vivek Bhavsar, Joseph Ereifej, Aravanan Gurusami  

**Link**: [PDF](https://arxiv.org/pdf/2510.02326)  

**Abstract**: Large language models accelerate literature synthesis but can hallucinate and mis-cite, limiting their usefulness in expert workflows. We present RA-FSM (Research Assistant - Finite State Machine), a modular GPT-based research assistant that wraps generation in a finite-state control loop: Relevance -> Confidence -> Knowledge. The system is grounded in vector retrieval and a deterministic citation pipeline. The controller filters out-of-scope queries, scores answerability, decomposes questions, and triggers retrieval only when needed, and emits answers with confidence labels and in-corpus, de-duplicated references. A ranked-tier ingestion workflow constructs a domain knowledge base from journals, conferences, indices, preprints, and patents, writing both to a dense vector index and to a relational store of normalized metrics. We implement the system for photonics and evaluate it on six task categories: analytical reasoning, numerical analysis, methodological critique, comparative synthesis, factual extraction, and application design. In blinded A/B reviews, domain experts prefer RA-FSM to both a strong Notebook LM (NLM) and a vanilla Default GPT API call single-pass baseline, citing stronger boundary-condition handling and more defensible evidence use. Coverage and novelty analyses indicate that RA-FSM explores beyond the NLM while incurring tunable latency and cost overheads. The design emphasizes transparent, well-cited answers for high-stakes technical work and is generalizable to other scientific domains. 

**Abstract (ZH)**: 大规模语言模型加速文献综合但可能存在幻觉和误引，限制了其在专家工作流中的应用。我们提出了一种模块化的基于GPT的研究助手RA-FSM（Research Assistant - Finite State Machine），该助手将生成过程嵌入到一个有限状态控制循环中：相关性 -> 置信度 -> 知识。系统基于向量检索和确定性的引文管道。控制器过滤掉范围外的查询，评估回答的可能性，分解问题，并仅在需要时触发检索，并随置信度标签和去重后的引用一并发出答案。经过排名的 ingestion 工作流从期刊、会议、索引、预印本和专利中构建领域知识库，并同时写入密集向量索引和标准化指标的关系存储库。我们为光子学领域实现了该系统，并在六个任务类别上进行了评估：分析推理、数值分析、方法论批判、比较综合、事实提取和应用设计。在盲测的A/B评审中，领域专家更偏好RA-FSM，而不是强大的Notebook LM（NLM）和常规的单一通过Default GPT API调用基线，原因是RA-FSM在边界条件处理和更有说服力的证据使用方面表现更好。覆盖率和新颖性分析表明，RA-FSM探索领域知识的同时，可以调节延迟和成本开销。该设计强调高风险技术工作中透明且引文充足的回答，并且可以泛化到其他科学领域。 

---
# Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents 

**Title (ZH)**: 代理-AI医疗: 多语言隐私优先框架与MCP代理 

**Authors**: Mohammed A. Shehab  

**Link**: [PDF](https://arxiv.org/pdf/2510.02325)  

**Abstract**: This paper introduces Agentic-AI Healthcare, a privacy-aware, multilingual, and explainable research prototype developed as a single-investigator project. The system leverages the emerging Model Context Protocol (MCP) to orchestrate multiple intelligent agents for patient interaction, including symptom checking, medication suggestions, and appointment scheduling. The platform integrates a dedicated Privacy and Compliance Layer that applies role-based access control (RBAC), AES-GCM field-level encryption, and tamper-evident audit logging, aligning with major healthcare data protection standards such as HIPAA (US), PIPEDA (Canada), and PHIPA (Ontario). Example use cases demonstrate multilingual patient-doctor interaction (English, French, Arabic) and transparent diagnostic reasoning powered by large language models. As an applied AI contribution, this work highlights the feasibility of combining agentic orchestration, multilingual accessibility, and compliance-aware architecture in healthcare applications. This platform is presented as a research prototype and is not a certified medical device. 

**Abstract (ZH)**: Agentic-AI医疗保健：一种隐私意识、多语言且可解释的研究原型 

---
# Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning 

**Title (ZH)**: CASAL：对比激活导向的 amortized 学习中的幻觉减少 

**Authors**: Wannan Yang, Xinchi Qiu, Lei Yu, Yuchen Zhang, Oliver Aobo Yang, Narine Kokhlikyan, Nicola Cancedda, Diego Garcia-Olano  

**Link**: [PDF](https://arxiv.org/pdf/2510.02324)  

**Abstract**: Large Language Models (LLMs) exhibit impressive capabilities but often hallucinate, confidently providing incorrect answers instead of admitting ignorance. Prior work has shown that models encode linear representations of their own knowledge and that activation steering can reduce hallucinations. These approaches, however, require real-time monitoring and intervention during inference. We introduce Contrastive Activation Steering for Amortized Learning (CASAL), an efficient algorithm that connects interpretability with amortized optimization. CASAL directly bakes the benefits of activation steering into model's weights. Once trained, LLMs answer questions they know while abstaining from answering those they do not. CASAL's light-weight design requires training only a submodule of a single transformer layer and yet reduces hallucination by 30%-40% across multiple short-form QA benchmarks. CASAL is 30x more compute-efficient and 20x more data-efficient than strong LoRA-based baselines such as SFT and DPO, boosting its practical applicability in data scarce domains. Importantly, CASAL also generalizes effectively to out-of-distribution (OOD) domains. We showcase CASAL's flexibility in mitigating hallucinations in both text-only and vision-language models. To our knowledge, CASAL is the first steering-based training method that has been shown to be effective for both dense and Mixture-of-Experts (MoE) models. CASAL represents a promising step forward for applying interpretability-inspired method for practical deployment in production systems. 

**Abstract (ZH)**: 对比激活导向的递增学习算法（CASAL）：减轻幻觉并提高模型解释性和效率 

---
# Modeling the Attack: Detecting AI-Generated Text by Quantifying Adversarial Perturbations 

**Title (ZH)**: 基于对抗扰动量化检测AI生成文本的模型 

**Authors**: Lekkala Sai Teja, Annepaka Yadagiri, Sangam Sai Anish, Siva Gopala Krishna Nuthakki, Partha Pakray  

**Link**: [PDF](https://arxiv.org/pdf/2510.02319)  

**Abstract**: The growth of highly advanced Large Language Models (LLMs) constitutes a huge dual-use problem, making it necessary to create dependable AI-generated text detection systems. Modern detectors are notoriously vulnerable to adversarial attacks, with paraphrasing standing out as an effective evasion technique that foils statistical detection. This paper presents a comparative study of adversarial robustness, first by quantifying the limitations of standard adversarial training and then by introducing a novel, significantly more resilient detection framework: Perturbation-Invariant Feature Engineering (PIFE), a framework that enhances detection by first transforming input text into a standardized form using a multi-stage normalization pipeline, it then quantifies the transformation's magnitude using metrics like Levenshtein distance and semantic similarity, feeding these signals directly to the classifier. We evaluate both a conventionally hardened Transformer and our PIFE-augmented model against a hierarchical taxonomy of character-, word-, and sentence-level attacks. Our findings first confirm that conventional adversarial training, while resilient to syntactic noise, fails against semantic attacks, an effect we term "semantic evasion threshold", where its True Positive Rate at a strict 1% False Positive Rate plummets to 48.8%. In stark contrast, our PIFE model, which explicitly engineers features from the discrepancy between a text and its canonical form, overcomes this limitation. It maintains a remarkable 82.6% TPR under the same conditions, effectively neutralizing the most sophisticated semantic attacks. This superior performance demonstrates that explicitly modeling perturbation artifacts, rather than merely training on them, is a more promising path toward achieving genuine robustness in the adversarial arms race. 

**Abstract (ZH)**: 高级大型语言模型的快速发展构成了一个重大的两用难题，需要创建可靠的AI生成文本检测系统。现代检测器对对抗攻击特别脆弱，改写尤其有效地规避了统计检测。本文通过比较抗欺骗性，首先量化标准对抗训练的局限性，然后介绍了一种新型、显著更稳健的检测框架：扰动不变特征工程（PIFE），该框架通过多阶段标准化管道将输入文本转换为标准形式，接着使用Levenshtein距离和语义相似性等度量量化变换的程度，并将这些信号直接传递给分类器。我们评估了常规加固的Transformer模型和我们的PIFE增强模型，它们分别针对字符级、词级和句级的攻击层次分类。我们的研究结果首先确认，虽然常规对抗训练对语法噪声具有韧性，但对语义攻击却无效，我们称之为“语义规避门槛”，在严格1%的假阳性率下，其真正阳性率骤降至48.8%。相比之下，我们的PIFE模型通过从文本与其标准形式之间的差异中明确构造特征，克服了这一局限。在相同条件下，它保持了惊人的82.6%的真正阳性率，有效地抵消了最复杂的语义攻击。这种优越的性能证明了明确建模扰动伪影，而不是仅仅在它们上进行训练，是对抗性增强竞赛实现真正鲁棒性的更有前途的途径。 

---
# Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects 

**Title (ZH)**: 乘法-加法约束模型：面向交互效应和独立效应联合可视化 

**Authors**: Fumin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.21923)  

**Abstract**: Interpretability is one of the considerations when applying machine learning to high-stakes fields such as healthcare that involve matters of life safety. Generalized Additive Models (GAMs) enhance interpretability by visualizing shape functions. Nevertheless, to preserve interpretability, GAMs omit higher-order interaction effects (beyond pairwise interactions), which imposes significant constraints on their predictive performance. We observe that Curve Ergodic Set Regression (CESR), a multiplicative model, naturally enables the visualization of its shape functions and simultaneously incorporates both interactions among all features and individual feature effects. Nevertheless, CESR fails to demonstrate superior performance compared to GAMs. We introduce Multiplicative-Additive Constrained Models (MACMs), which augment CESR with an additive part to disentangle the intertwined coefficients of its interactive and independent terms, thus effectively broadening the hypothesis space. The model is composed of a multiplicative part and an additive part, whose shape functions can both be naturally visualized, thereby assisting users in interpreting how features participate in the decision-making process. Consequently, MACMs constitute an improvement over both CESR and GAMs. The experimental results indicate that neural network-based MACMs significantly outperform both CESR and the current state-of-the-art GAMs in terms of predictive performance. 

**Abstract (ZH)**: 在涉及生命安全的高风险领域如医疗健康中应用机器学习时，可解释性是重要的考虑因素。广义加性模型（GAMs）通过可视化形函数来增强可解释性。然而，为保持可解释性，GAMs会忽略高于二阶的交互效应，这对预测性能造成了显著限制。我们观察到，曲线遍历集回归（CESR），作为一种乘法模型，自然能够可视化其形函数，并同时结合所有特征间的交互效应及单个特征效应。然而，CESR在性能上未能优于GAMs。我们提出了乘性-加性约束模型（MACMs），其在CESR的基础上增加了一个加性部分，以解开交互项和独立项纠缠的系数，从而有效扩展假设空间。该模型由乘性部分和加性部分组成，其形函数均可自然可视化，有助于用户理解特征在决策过程中的作用。因此，MACMs在CESR和GAMs之上构成改进。实验结果表明，基于神经网络的MACMs在预测性能方面显著优于CESR和当前最先进的GAMs。 

---
# Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion Enhancement 

**Title (ZH)**: 基于注意跨模态交互与运动增强的压缩视频动作识别表示学习 

**Authors**: Bing Li, Jiaxin Chen, Dongming Zhang, Xiuguo Bao, Di Huang  

**Link**: [PDF](https://arxiv.org/pdf/2205.03569)  

**Abstract**: Compressed video action recognition has recently drawn growing attention, since it remarkably reduces the storage and computational cost via replacing raw videos by sparsely sampled RGB frames and compressed motion cues (e.g., motion vectors and residuals). However, this task severely suffers from the coarse and noisy dynamics and the insufficient fusion of the heterogeneous RGB and motion modalities. To address the two issues above, this paper proposes a novel framework, namely Attentive Cross-modal Interaction Network with Motion Enhancement (MEACI-Net). It follows the two-stream architecture, i.e. one for the RGB modality and the other for the motion modality. Particularly, the motion stream employs a multi-scale block embedded with a denoising module to enhance representation learning. The interaction between the two streams is then strengthened by introducing the Selective Motion Complement (SMC) and Cross-Modality Augment (CMA) modules, where SMC complements the RGB modality with spatio-temporally attentive local motion features and CMA further combines the two modalities with selective feature augmentation. Extensive experiments on the UCF-101, HMDB-51 and Kinetics-400 benchmarks demonstrate the effectiveness and efficiency of MEACI-Net. 

**Abstract (ZH)**: 压缩视频动作识别 recently 引起了越来越多的关注，通过用稀疏采样的RGB帧和压缩的运动线索（例如运动矢量和残差）替代原始视频，它显著地降低了存储和计算成本。然而，该任务严重受到粗糙和嘈杂的动力学以及RGB和运动模态不足的融合的影响。为了解决上述两个问题，本文提出了一种新型框架，即带运动增强的注意跨模态交互网络（MEACI-Net）。该框架遵循两流架构，分别为RGB模态和运动模态设计。特别是，运动流中嵌入了多尺度块并包含去噪模块，以增强表示学习。然后通过引入选择性运动补充（SMC）模块和跨模态增强（CMA）模块加强两流之间的交互，其中SMC使用时序注意局部运动特征补充RGB模态，而CMA进一步通过选择性特征增强将两个模态结合起来。在UCF-101、HMDB-51和Kinetics-400基准上的 extensive 实验演示了MEACI-Net 的有效性和效率。 

---
