{'arxiv_id': 'arXiv:2507.23773', 'title': 'SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model', 'authors': 'Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing', 'link': 'https://arxiv.org/abs/2507.23773', 'abstract': 'AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \\modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \\modelname improves the success of flight search from 0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent advantage of up to 124\\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \\modelname with pretrained LLMs, available as a research demo for public testing.', 'abstract_zh': '基于大型语言模型的AI代理前景巨大，但当前实践主要采用单任务单代理的方法，这不仅缺乏可扩展性和普遍性，而且还受到自回归大型语言模型基本限制的制约。相比之下，人类是一般性代理，通过心理模拟其行动和计划的结果来进行推理。朝着更通用和强大的AI代理方向，我们引入了SimuRA，即一个以目标为导向、适用于通用代理推理的架构。基于任何环境中的最优代理的原理性表述，\\modelname 通过引入用于计划的世界模型克服了自回归推理的限制。世界模型使用大型语言模型实现，能够利用自然语言丰富的潜在空间灵活地在各种环境中进行规划。实验表明，在困难的网页浏览任务中，\\modelname 将航班搜索的成功率从0%提升至32.2%。特别是基于世界模型的规划显示出高达124%的一致优势，证明了世界模型模拟作为一种推理范式的优越性。我们正在探索基于大型语言模型训练单个通用超智能代理模型的可能性。为起步，我们发布了一个基于\\message 的SimuRA网页浏览代理进行公开测试作为研究demo。', 'title_zh': 'SimuRA：通过基于大语言模型的世界模型模拟推理架构实现通用目标导向代理'}
{'arxiv_id': 'arXiv:2507.23751', 'title': 'CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks', 'authors': 'Ping Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, Jing Xu', 'link': 'https://arxiv.org/abs/2507.23751', 'abstract': 'We propose CoT-Self-Instruct, a synthetic data generation method that instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the given seed tasks, and then to generate a new synthetic prompt of similar quality and complexity for use in LLM training, followed by filtering for high-quality data with automatic metrics. In verifiable reasoning, our synthetic data significantly outperforms existing training datasets, such as s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For non-verifiable instruction-following tasks, our method surpasses the performance of human or standard self-instruct prompts on both AlpacaEval 2.0 and Arena-Hard.', 'abstract_zh': '我们提出了一种名为CoT-Self-Instruct的合成数据生成方法，该方法通过Chain-of-Thought (CoT) 首先指导LLMs根据给定的种子任务进行推理和规划，然后生成具有相似质量和复杂性的新合成提示用于LLM训练，并通过自动指标进行过滤，以获取高质量数据。在可验证的推理中，我们的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond等基准上显著优于现有训练数据集s1k和OpenMathReasoning。对于不可验证的指令跟随任务，我们的方法在AlpacaEval 2.0和Arena-Hard上的性能超过了人类或标准自指导提示。', 'title_zh': 'CoT-Self-Instruct：构建高质量合成提示以用于推理和非推理任务'}
{'arxiv_id': 'arXiv:2507.23726', 'title': 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving', 'authors': 'Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu', 'link': 'https://arxiv.org/abs/2507.23726', 'abstract': 'LLMs have demonstrated strong mathematical reasoning abilities by leveraging reinforcement learning with long chain-of-thought, yet they continue to struggle with theorem proving due to the lack of clear supervision signals when solely using natural language. Dedicated domain-specific languages like Lean provide clear supervision via formal verification of proofs, enabling effective training through reinforcement learning. In this work, we propose \\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover can iteratively refine its proof based on Lean feedback, proved lemmas, and self-summarization. To solve IMO-level contest problems, we design three test-time inference strategies that enable both deep and broad reasoning. Seed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F, and achieves over 50\\% on PutnamBench, outperforming the previous state-of-the-art by a large margin. To address the lack of geometry support in Lean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which outperforms previous formal geometry engines. We use these two systems to participate in IMO 2025 and fully prove 5 out of 6 problems. This work represents a significant advancement in automated mathematical reasoning, demonstrating the effectiveness of formal verification with long chain-of-thought reasoning.', 'abstract_zh': '大规模语言模型通过 reinforcement learning 以及长链条推理展示了强大的数学推理能力，但仍因单一自然语言监督信号不明确而在定理证明中遇到挑战。专门领域的语言如 Lean 通过正式验证提供了清晰的监督信号，从而使强化学习能够有效训练模型。本文提出了一种以引理风格的全过程推理模型 \\textbf{Seed-Prover}。Seed-Prover 可以基于 Lean 反馈、已证明的引理和自我总结迭代改进其证明过程。为了解决 IMO 级别的竞赛问题，我们设计了三种测试时推理策略，以实现深入且广泛的推理。Seed-Prover 证明了 78.1% 的正式化过去的 IMO 问题，使 MiniF2F 达到饱和状态，并在 PutnamBench 上达到了超过 50% 的成绩，大幅超越了之前的最佳水平。为了解决 Lean 在几何推理方面的欠缺，我们引入了一种几何推理引擎 \\textbf{Seed-Geometry}，其性能优于之前的正式几何引擎。我们使用这两种系统参加 IMO 2025，并完全证明了 6 个问题中的 5 个。这项工作代表了自动数学推理的重要进展，展示了长链条推理与正式验证的有效结合。', 'title_zh': 'Seed-Prover: 深度与广度兼备的自动定理证明方法'}
{'arxiv_id': 'arXiv:2507.23701', 'title': 'TextQuests: How Good are LLMs at Text-Based Video Games?', 'authors': 'Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks', 'link': 'https://arxiv.org/abs/2507.23701', 'abstract': "Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agent's capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at this https URL.", 'abstract_zh': '在复杂交互环境中评估AI代理对于理解其实际能力至关重要。现有的代理基准虽然能够有效评估工具使用或结构化任务上的技能，但往往未能充分捕捉代理在探索性环境中自主操作的能力，这些环境中需要长时间持续的自我导向推理。为促进能够实现更稳健长期内在推理的代理开发，我们引入了基于Infocom互动小说游戏套件的TextQuests基准。这些基于文本的冒险可以在人类玩家身上耗时超过30小时，并且需要数百次精确操作才能解决，因此有效地评估了AI代理在集中、状态感知任务上的能力。该基准特别设计用于评估LLM代理的独立问题解决能力，通过禁止使用外部工具，从而聚焦于在需要试错学习和单一交互会话内持续问题解决的探索性环境中的内在长期上下文推理能力。我们在此发布TextQuests：https://www.example.com/textquests。', 'title_zh': 'TextQuests：文本型视频游戏中的LLM们表现如何？'}
{'arxiv_id': 'arXiv:2507.23664', 'title': 'Personalized Education with Ranking Alignment Recommendation', 'authors': 'Haipeng Liu, Yuxuan Liu, Ting Long', 'link': 'https://arxiv.org/abs/2507.23664', 'abstract': 'Personalized question recommendation aims to guide individual students through questions to enhance their mastery of learning targets. Most previous methods model this task as a Markov Decision Process and use reinforcement learning to solve, but they struggle with efficient exploration, failing to identify the best questions for each student during training. To address this, we propose Ranking Alignment Recommendation (RAR), which incorporates collaborative ideas into the exploration mechanism, enabling more efficient exploration within limited training episodes. Experiments show that RAR effectively improves recommendation performance, and our framework can be applied to any RL-based question recommender. Our code is available in this https URL.', 'abstract_zh': '个性化问题推荐旨在引导个体学生通过特定问题来提高其对学习目标的掌握程度。大多数先前方法将此任务建模为马尔可夫决策过程，并使用强化学习来解决，但在训练过程中难以实现高效的探索，无法在训练期间识别出最适合每个学生的问题。为了解决这一问题，我们提出了排序对齐推荐（RAR），该方法将协作思想融入探索机制中，能够在有限的训练期内实现更高效的探索。实验结果表明，RAR能有效提高推荐性能，并且我们的框架可以应用于任何基于RL的问题推荐系统。我们的代码可在以下链接获得。', 'title_zh': '个性化教育与排序对齐推荐'}
{'arxiv_id': 'arXiv:2507.23633', 'title': 'MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying', 'authors': 'Qian Zhao, Zhuo Sun, Bin Guo, Zhiwen Yu', 'link': 'https://arxiv.org/abs/2507.23633', 'abstract': "Agent-assisted memory recall is one critical research problem in the field of human-computer interaction. In conventional methods, the agent can retrieve information from its equipped memory module to help the person recall incomplete or vague memories. The limited size of memory module hinders the acquisition of complete memories and impacts the memory recall performance in practice. Memory theories suggest that the person's relevant memory can be proactively activated through some effective cues. Inspired by this, we propose a novel strategy-guided agent-assisted memory recall method, allowing the agent to transform an original query into a cue-rich one via the judiciously designed strategy to help the person recall memories. To this end, there are two key challenges. (1) How to choose the appropriate recall strategy for diverse forgetting scenarios with distinct memory-recall characteristics? (2) How to obtain the high-quality responses leveraging recall strategies, given only abstract and sparsely annotated strategy patterns? To address the challenges, we propose a Recall Router framework. Specifically, we design a 5W Recall Map to classify memory queries into five typical scenarios and define fifteen recall strategy patterns across the corresponding scenarios. We then propose a hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to optimize the selection of strategy and the generation of strategy responses. We construct an instruction tuning dataset and fine-tune multiple open-source large language models (LLMs) to develop MemoCue, an agent that excels in providing memory-inspired responses. Experiments on three representative datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Further human evaluation highlights its advantages in memory-recall applications.", 'abstract_zh': '基于代理的辅助记忆召回是人机交互领域的一个关键研究问题。在传统方法中，代理可以从其装备的记忆模块中检索信息以帮助人们回忆不完整或模糊的记忆。记忆模块的有限大小阻碍了完整记忆的获取，影响实际的记忆召回性能。记忆理论表明，可以通过有效的提示主动激活人的相关记忆。受此启发，我们提出了一种新颖的策略导向的代理辅助记忆召回方法，使代理能够通过精心设计的策略将原始查询转换为富含提示的查询，以帮助人们回忆记忆。为此，有两个关键挑战：（1）如何为具有不同记忆-召回特征的不同遗忘场景选择合适的召回策略？（2）如何利用召回策略获取高质量的响应，仅利用抽象和稀疏标注的策略模式？为了解决这些挑战，我们提出了一种召回路由框架。具体地，我们设计了一个5W召回地图，将记忆查询分类为五种典型场景，并在相应场景中定义了十五种召回策略模式。然后，我们提出了一种结合蒙特卡洛树搜索算法的分层召回树来优化策略的选择和策略响应的生成。我们构建了一个指令调优数据集，并对多个开源的大语言模型（LLMs）进行微调，开发出了MemoCue，这是一种在提供记忆启发式响应方面表现出色的代理。实验结果在三个代表性数据集上表明，MemoCue在召回启发方面比基于大语言模型的方法提高了17.74%。进一步的人类评估突显了其在记忆召回应用中的优势。', 'title_zh': 'MemoCue: 通过策略导向的查询增强基于LLM的代理的人类记忆回忆能力'}
{'arxiv_id': 'arXiv:2507.23565', 'title': 'Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI', 'authors': 'Botao Zhu, Xianbin Wang, Dusit Niyato', 'link': 'https://arxiv.org/abs/2507.23565', 'abstract': 'In collaborative systems, the effective completion of tasks hinges on task-specific trust evaluations of potential devices for distributed collaboration. However, the complexity of tasks, the spatiotemporal dynamism of distributed device resources, and the inevitable assessment overhead dramatically increase the complexity and resource consumption of the trust evaluation process. As a result, ill-timed or overly frequent trust evaluations can reduce utilization rate of constrained resources, negatively affecting collaborative task execution. To address this challenge, this paper proposes an autonomous trust orchestration method based on a new concept of semantic chain-of-trust. Our technique employs agentic AI and hypergraph to establish and maintain trust relationships among devices. By leveraging its strengths in autonomous perception, task decomposition, and semantic reasoning, we propose agentic AI to perceive device states and autonomously perform trust evaluations of collaborators based on historical performance data only during device idle periods, thereby enabling efficient utilization of distributed resources. In addition, agentic AI performs task-specific trust evaluations on collaborator resources by analyzing the alignment between resource capabilities and task requirements. Moreover, by maintaining a trust hypergraph embedded with trust semantics for each device, agentic AI enables hierarchical management of collaborators and identifies collaborators requiring trust evaluation based on trust semantics, thereby achieving a balance between overhead and trust accuracy. Furthermore, local trust hypergraphs from multiple devices can be chained together to support multi-hop collaboration, enabling efficient coordination in large-scale systems. Experimental results demonstrate that the proposed method achieves resource-efficient trust evaluation.', 'abstract_zh': '基于语义链的信任自治编排方法：实现分布式协作任务的有效执行', 'title_zh': '语义信任链：通过超图辅助代理AI实现自主信任编排的合作方选择'}
{'arxiv_id': 'arXiv:2507.23554', 'title': 'DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer', 'authors': 'Ruoyu Wang, Junda Wu, Yu Xia, Tong Yu, Ryan A. Rossi, Julian McAuley, Lina Yao', 'link': 'https://arxiv.org/abs/2507.23554', 'abstract': "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks. However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance. While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps. Therefore, it is non-trivial to develop a principled, general-purpose method for selecting demonstrations that consistently benefit agent performance. In this paper, we address this challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a theoretically grounded ICL framework for agentic tasks that selects the most relevant demonstrations at each step of reasoning. Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization. We further propose a stepwise selection criterion with a formal guarantee of improved agent performance. Importantly, DICE is a general, framework-agnostic solution that can be integrated as a plug-in module into existing agentic frameworks without any additional training cost. Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", 'abstract_zh': '基于大型语言模型的代理：带内在情境学习的动态示例选择（DICE）', 'title_zh': 'DICE: 动态上下文相关示例选择在高效知识转移的大型语言模型代理中'}
{'arxiv_id': 'arXiv:2507.23497', 'title': 'Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification', 'authors': 'David A Kelly, Hana Chockler', 'link': 'https://arxiv.org/abs/2507.23497', 'abstract': 'Existing algorithms for explaining the outputs of image classifiers are based on a variety of approaches and produce explanations that lack formal rigor. On the other hand, logic-based explanations are formally and rigorously defined but their computability relies on strict assumptions about the model that do not hold on image classifiers.\nIn this paper, we show that causal explanations, in addition to being formally and rigorously defined, enjoy the same formal properties as logic-based ones, while still lending themselves to black-box algorithms and being a natural fit for image classifiers. We prove formal properties of causal explanations and introduce contrastive causal explanations for image classifiers. Moreover, we augment the definition of explanation with confidence awareness and introduce complete causal explanations: explanations that are classified with exactly the same confidence as the original image.\nWe implement our definitions, and our experimental results demonstrate that different models have different patterns of sufficiency, contrastiveness, and completeness. Our algorithms are efficiently computable, taking on average 6s per image on a ResNet50 model to compute all types of explanations, and are totally black-box, needing no knowledge of the model, no access to model internals, no access to gradient, nor requiring any properties, such as monotonicity, of the model.', 'abstract_zh': '现有的图像分类器解释算法基于多种方法并且缺乏形式 rigor。另一方面，逻辑基于的解释具有形式上的 rigor 但其可计算性依赖于对模型的严格假设，这些假设在图像分类器中并不成立。在本文中，我们展示了因果解释不仅具有形式上的 rigor，还具有与逻辑基于解释相同的正式属性，同时适合于黑盒算法并且是图像分类器的天然选择。我们证明了因果解释的正式属性，并引入了用于图像分类器的对比因果解释。此外，我们扩展了解释的定义以包含置信度意识，并引入了完整的因果解释：这些解释与原始图像具有相同的置信度分类。我们实现了这些定义，并且实验结果表明不同的模型具有不同的充分性、对比性和完整性模式。我们的算法计算效率高，平均每个图像需要约6秒来计算所有类型的解释，并且是完全黑盒的，不需要了解模型、访问模型内部、访问梯度或要求模型具有任何属性（如单调性）。', 'title_zh': '图像分类中充分性、对比性和完备性特征集的因果识别'}
{'arxiv_id': 'arXiv:2507.23488', 'title': 'Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery', 'authors': 'Kacper Kadziolka, Saber Salehkaleybar', 'link': 'https://arxiv.org/abs/2507.23488', 'abstract': "Causal inference remains a fundamental challenge for large language models. Recent advances in internal reasoning with large language models have sparked interest in whether state-of-the-art reasoning models can robustly perform causal discovery-a task where conventional models often suffer from severe overfitting and near-random performance under data perturbations. We study causal discovery on the Corr2Cause benchmark using the emergent OpenAI's o-series and DeepSeek-R model families and find that these reasoning-first architectures achieve significantly greater native gains than prior approaches. To capitalize on these strengths, we introduce a modular in-context pipeline inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding nearly three-fold improvements over conventional baselines. We further probe the pipeline's impact by analyzing reasoning chain length, complexity, and conducting qualitative and quantitative comparisons between conventional and reasoning models. Our findings suggest that while advanced reasoning models represent a substantial leap forward, carefully structured in-context frameworks are essential to maximize their capabilities and offer a generalizable blueprint for causal discovery across diverse domains.", 'abstract_zh': '因果推断仍然是大型语言模型的基本挑战。内部推理的最新进展引发了关于最先进的推理模型是否能够稳健地完成因果发现任务的兴趣——在该任务中，传统模型在数据扰动下往往遭受严重的过拟合和接近随机的表现。我们使用新兴的OpenAI o系列和DeepSeek-R模型家族在Corr2Cause基准上研究因果发现，发现这些以推理为主的架构比先前的方法实现了显著更大的固有收益。为了充分利用这些优势，我们引入了一种借鉴Tree-of-Thoughts和Chain-of-Thoughts方法论的模块化上下文内管道，结果在传统基线之上实现了近三倍的改进。我们进一步通过分析推理链的长度、复杂性和在传统模型与推理模型之间进行定性和定量比较，来探究管道的影响。我们的发现表明，虽然先进的推理模型代表了一个重大进步，但精心结构化的上下文内框架对于最大化其能力至关重要，并提供了因果发现跨不同领域的一般化蓝图。', 'title_zh': '片段因果推理：模块化上下文学习中的因果发现'}
{'arxiv_id': 'arXiv:2507.23440', 'title': 'Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation', 'authors': 'Mingzhe Li, Xin Lu, Yanyan Zhao', 'link': 'https://arxiv.org/abs/2507.23440', 'abstract': 'Large language models (LLMs) with instruction following capabilities have demonstrated impressive problem-solving abilities. While synthesizing instructional data from unsupervised text has become a common approach for training such models, conventional methods rely heavily on human effort for data annotation. Although existing automated synthesis paradigms have alleviated this constraint, they still exhibit significant limitations in ensuring adequate diversity and difficulty of synthesized instructions. To address these challenges, we propose Self-Foveate, an innovative LLM-driven method for instruction synthesis. This approach introduces a "Micro-Scatter-Macro" multi-level foveation methodology that effectively guides the LLM to deeply excavate fine-grained information embedded in unsupervised text, thereby enhancing both the diversity and difficulty of synthesized instructions. Comprehensive experiments across multiple unsupervised corpora and diverse model architectures validate the effectiveness and superiority of our proposed method. We publicly release our data and codes: this https URL', 'abstract_zh': '具有指令跟随能力的大语言模型展示了令人印象深刻的解决问题能力。虽然从无监督文本中合成指令已成为培训此类模型的常见方法，但传统方法在数据标注方面仍高度依赖人工。尽管现有的自动化合成范式已缓解了这一限制，但在确保合成指令的多样性和难度方面仍存在显著局限。为应对这些挑战，我们提出了一种创新的大语言模型驱动的指令合成方法Self-Foveate。该方法引入了一种“微-散-宏”多级聚光方法，有效地引导大语言模型深入挖掘无监督文本中嵌入的精细信息，从而增强合成指令的多样性和难度。在多个无监督数据集和多种模型架构上的全面实验验证了我们提出方法的有效性和优越性。我们公开释放了我们的数据和代码：this https URL。', 'title_zh': '自聚焦：通过多级聚焦增强无监督文本合成指令的多样性和难度'}
{'arxiv_id': 'arXiv:2507.23429', 'title': 'Chatting with your ERP: A Recipe', 'authors': 'Jorge Ruiz Gómez, Lidia Andrés Susinos, Jorge Alamo Olivé, Sonia Rey Osorno, Manuel Luis Gonzalez Hernández', 'link': 'https://arxiv.org/abs/2507.23429', 'abstract': 'This paper presents the design, implementation, and evaluation behind a Large Language Model (LLM) agent that chats with an industrial production-grade ERP system. The agent is capable of interpreting natural language queries and translating them into executable SQL statements, leveraging open-weight LLMs. A novel dual-agent architecture combining reasoning and critique stages was proposed to improve query generation reliability.', 'abstract_zh': '这篇论文介绍了与工业生产级ERP系统对话的大型语言模型代理的设计、实现与评估。该代理能够解析自然语言查询并将其转换为可执行的SQL语句，利用开放式大型语言模型。提出了结合推理和批判阶段的新型双代理架构，以提高查询生成的可靠性。', 'title_zh': '与您的ERP聊天：一份配方'}
{'arxiv_id': 'arXiv:2507.23377', 'title': 'LLM4Rail: An LLM-Augmented Railway Service Consulting Platform', 'authors': 'Zhuo Li, Xianghuai Deng, Chiwei Feng, Hanmeng Li, Shenjie Wang, Haichao Zhang, Teng Jia, Conlin Chen, Louis Linchun Wu, Jia Wang', 'link': 'https://arxiv.org/abs/2507.23377', 'abstract': 'Large language models (LLMs) have significantly reshaped different walks of business. To meet the increasing demands for individualized railway service, we develop LLM4Rail - a novel LLM-augmented railway service consulting platform. Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway food & drink recommendations, weather information, and chitchat. In LLM4Rail, we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting framework. It meticulously integrates verbal reasoning with task-oriented actions, that is, reasoning to guide action selection, to effectively retrieve external observations relevant to railway operation and service to generate accurate responses. To provide personalized onboard dining services, we first construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible takeout dataset tailored for railway services. CRFD-25 covers a wide range of signature dishes categorized by cities, cuisines, age groups, and spiciness levels. We further introduce an LLM-based zero-shot conversational recommender for railway catering. To address the unconstrained nature of open recommendations, the feature similarity-based post-processing step is introduced to ensure all the recommended items are aligned with CRFD-25 dataset.', 'abstract_zh': '大型语言模型（LLMs）显著重塑了各行各业的业务。为了满足日益增长的个性化铁路服务需求，我们开发了LLM4Rail——一种新型的LLM增强铁路服务咨询平台。借助大型语言模型的加持，LLM4Rail能够提供定制化的票务模块、铁路食品与饮料推荐、天气信息以及闲聊服务。在LLM4Rail中，我们提出了迭代的“提问-思考-行动-观察（QTAO）”提示框架。该框架精心整合了语言推理与任务导向的操作，即通过推理来指导行动选择，从而有效地检索与铁路运营和服务相关的外部观察信息，生成准确的响应。为了提供个性化的列车上餐饮服务，我们首先构建了中国铁路食品与饮料（CRFD-25）——一个面向铁路服务的公开取餐数据集。CRFD-25涵盖了按城市、菜系、年龄组和辣度分类的多种特色菜肴。我们进一步引入了基于大型语言模型的零样本对话推荐系统，以铁路餐饮为应用场景。为了确保推荐物品与CRFD-25数据集保持一致，我们还引入了基于特征相似性的后处理步骤，以解决开放式推荐的无约束性问题。', 'title_zh': 'LLM4Rail：一种基于LLM的铁路服务咨询平台'}
{'arxiv_id': 'arXiv:2507.23336', 'title': 'DSBC : Data Science task Benchmarking with Context engineering', 'authors': 'Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Giulio Martini, Suman Debnath, Hamza Farooq', 'link': 'https://arxiv.org/abs/2507.23336', 'abstract': 'Recent advances in large language models (LLMs) have significantly impacted data science workflows, giving rise to specialized data science agents designed to automate analytical tasks. Despite rapid adoption, systematic benchmarks evaluating the efficacy and limitations of these agents remain scarce. In this paper, we introduce a comprehensive benchmark specifically crafted to reflect real-world user interactions with data science agents by observing usage of our commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet, Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with context engineering, multi-step with context engineering, and with SmolAgent. Our benchmark assesses performance across a diverse set of eight data science task categories, additionally exploring the sensitivity of models to common prompting issues, such as data leakage and slightly ambiguous instructions. We further investigate the influence of temperature parameters on overall and task-specific outcomes for each model and approach. Our findings reveal distinct performance disparities among the evaluated models and methodologies, highlighting critical factors that affect practical deployment. The benchmark dataset and evaluation framework introduced herein aim to provide a foundation for future research of more robust and effective data science agents.', 'abstract_zh': 'Recent advances in大型语言模型（LLMs）对数据科学工作流产生了显著影响，催生了专门设计用于自动化分析任务的数据科学代理。尽管这些代理的采用率迅速提升，但系统性基准测试以评估其有效性和局限性仍然较为稀缺。本文介绍了一个综合基准，旨在通过观察我们商业应用程序的使用情况来反映数据科学代理的实际情况。我们评估了三种LLM：Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini，采用了三种方法：零样本、带有上下文工程的多步骤和带有SmolAgent的方法。该基准测试评估了涵盖八大数据科学任务类别的性能，并探讨了模型对常见提示问题（如数据泄露和模棱两可指令）的敏感性。我们还进一步研究了温度参数对每个模型和方法整体及任务特定结果的影响。我们的研究结果揭示了评估模型和方法之间的显著性能差异，并强调了影响实际部署的关键因素。本文引入的基准数据集和评估框架旨在为更稳健和有效的数据科学代理的研究提供基础。', 'title_zh': 'DSBC：基于上下文工程的数据科学任务基准测试'}
{'arxiv_id': 'arXiv:2507.23330', 'title': 'AI Must not be Fully Autonomous', 'authors': 'Tosin Adewumi, Lama Alkhaled, Florent Imbert, Hui Han, Nudrat Habib, Karl Löwenmark', 'link': 'https://arxiv.org/abs/2507.23330', 'abstract': 'Autonomous Artificial Intelligence (AI) has many benefits. It also has many risks. In this work, we identify the 3 levels of autonomous AI. We are of the position that AI must not be fully autonomous because of the many risks, especially as artificial superintelligence (ASI) is speculated to be just decades away. Fully autonomous AI, which can develop its own objectives, is at level 3 and without responsible human oversight. However, responsible human oversight is crucial for mitigating the risks. To ague for our position, we discuss theories of autonomy, AI and agents. Then, we offer 12 distinct arguments and 6 counterarguments with rebuttals to the counterarguments. We also present 15 pieces of recent evidence of AI misaligned values and other risks in the appendix.', 'abstract_zh': '自主人工智能的3个层次及其风险：不应完全自主', 'title_zh': 'AI必须不是完全自主的。'}
{'arxiv_id': 'arXiv:2507.23276', 'title': 'How Far Are AI Scientists from Changing the World?', 'authors': 'Qiujie Xie, Yixuan Weng, Minjun Zhu, Fuchen Shen, Shulin Huang, Zhen Lin, Jiahui Zhou, Zilan Mao, Zijie Yang, Linyi Yang, Jian Wu, Yue Zhang', 'link': 'https://arxiv.org/abs/2507.23276', 'abstract': 'The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research. Several influential works have already appeared in the field of AI Scientist systems, with AI-generated research papers having been accepted at the ICLR 2025 workshop, suggesting that a human-level AI Scientist capable of uncovering phenomena previously unknown to humans, may soon become a reality. In this survey, we focus on the central question: How far are AI scientists from changing the world and reshaping the scientific research paradigm? To answer this question, we provide a prospect-driven review that comprehensively analyzes the current achievements of AI Scientist systems, identifying key bottlenecks and the critical components required for the emergence of a scientific agent capable of producing ground-breaking discoveries that solve grand challenges. We hope this survey will contribute to a clearer understanding of limitations of current AI Scientist systems, showing where we are, what is missing, and what the ultimate goals for scientific AI should be.', 'abstract_zh': '大型语言模型的出现正推动自动化科学研究达到新的水平，基于大型语言模型的人工智能（AI）科学家系统现已在科学研究中占据领先地位。已有若干重要研究工作出现在AI科学家系统领域，AI生成的研究论文已被ICLR 2025研讨会接受，表明人类水平的AI科学家可能很快成为可能。在这篇综述中，我们聚焦的核心问题是：AI科学家距离改变世界和重塑科学研究范式还有多远？为了回答这一问题，我们提供了一种前瞻性的审查，全面分析了AI科学家系统的现有成果，指出了关键瓶颈，并识别出能够产生突破性发现解决重大挑战的科学代理所需的关键组成部分。我们希望这篇综述能有助于对当前AI科学家系统的局限性有一个更清晰的理解，显示我们的现状、缺失的部分，以及科学AI的最终目标应是什么。', 'title_zh': 'AI科学家距离改变世界还有多远？'}
{'arxiv_id': 'arXiv:2507.23197', 'title': 'Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification', 'authors': 'Yuke Liao, Blaise Genest, Kuldeep Meel, Shaan Aryaman', 'link': 'https://arxiv.org/abs/2507.23197', 'abstract': 'To handle complex instances, we revisit a divide-and-conquer approach to break down the complexity: instead of few complex BaB calls, we rely on many small {\\em partial} MILP calls. The crucial step is to select very few but very important ReLUs to treat using (costly) binary variables. The previous attempts were suboptimal in that respect. To select these important ReLU variables, we propose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt the BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf GS}) functions. We compare them theoretically as well as experimentally, and {\\sf SAS} is more efficient at selecting a set of variables to open using binary variables. Compared with previous attempts, SAS reduces the number of binary variables by around 6 times, while maintaining the same level of accuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN with a short time-out to solve easier instances, and then partial MILP, produces a very accurate yet efficient verifier, reducing by up to $40\\%$ the number of undecided instances to low levels ($8-15\\%$), while keeping a reasonable runtime ($46s-417s$ on average per instance), even for fairly large CNNs with 2 million parameters.', 'abstract_zh': '使用部分MILP调用处理复杂实例：一种新型ReLU评分方法的研究', 'title_zh': '局部ReLU选择 vs 整体ReLU选择：部分MILP再显身手用于DNN验证'}
{'arxiv_id': 'arXiv:2507.23191', 'title': 'Tractable Responsibility Measures for Ontology-Mediated Query Answering', 'authors': 'Meghyn Bienvenu, Diego Figueira, Pierre Lafourcade', 'link': 'https://arxiv.org/abs/2507.23191', 'abstract': 'Recent work on quantitative approaches to explaining query answers employs responsibility measures to assign scores to facts in order to quantify their respective contributions to obtaining a given answer. In this paper, we study the complexity of computing such responsibility scores in the setting of ontology-mediated query answering, focusing on a very recently introduced family of Shapley-value-based responsibility measures defined in terms of weighted sums of minimal supports (WSMS). By exploiting results from the database setting, we can show that such measures enjoy polynomial data complexity for classes of ontology-mediated queries that are first-order-rewritable, whereas the problem becomes "shP"-hard when the ontology language can encode reachability queries (via axioms like $\\exists R. A \\sqsubseteq A$). To better understand the tractability frontier, we next explore the combined complexity of WSMS computation. We prove that intractability applies already to atomic queries if the ontology language supports conjunction, as well as to unions of `well-behaved\' conjunctive queries, even in the absence of an ontology. By contrast, our study yields positive results for common DL-Lite dialects: by means of careful analysis, we identify classes of structurally restricted conjunctive queries (which intuitively disallow undesirable interactions between query atoms) that admit tractable WSMS computation.', 'abstract_zh': '近期对查询答案进行定量解释的工作利用责任度量来为事实分配得分，以量化它们对获得给定答案的各自贡献。在本文中，我们研究了在本体介导查询处理设置下计算此类责任得分的复杂性，重点关注最近引入的一种基于Shapley值的责任度量，该度量基于最小支持的加权和（WSMS）。通过利用数据库设置中的结果，我们可以证明，在可一阶重写的本体介导查询类中，此类度量享有多项式数据复杂性，而在本体语言能够编码可达性查询（通过类似 $\\exists R. A \\sqsubseteq A$ 的公理）的情况下，问题变得“shP-难”。为了更好地理解可处理性的临界点，我们接下来研究了WSMS计算的组合复杂性。我们证明，即使没有本体，在本体语言支持合取的情况下，原子查询的不可处理性已显现，同时，对于“良好行为”的合取查询的联合，即使在没有本体的情况下，WSMS计算也不可处理。相比之下，我们的研究在常见的DL-Lite方言中得出了积极结果：通过精细分析，我们确定了允许可处理WSMS计算的结构上受限的合取查询类（直觉上不允许查询原子之间的不良交互）。', 'title_zh': '基于本体介导查询回答的可计算责任度量方法'}
{'arxiv_id': 'arXiv:2507.23163', 'title': 'Argumentatively Coherent Judgmental Forecasting', 'authors': 'Deniz Gorur, Antonio Rago, Francesca Toni', 'link': 'https://arxiv.org/abs/2507.23163', 'abstract': "Judgmental forecasting employs human opinions to make predictions about future events, rather than exclusively historical data as in quantitative forecasting. When these opinions form an argumentative structure around forecasts, it is useful to study the properties of the forecasts from an argumentative perspective. In this paper, we advocate and formally define a property of argumentative coherence, which, in essence, requires that a forecaster's reasoning is coherent with their forecast. We then conduct three evaluations with our notion of coherence. First, we assess the impact of enforcing coherence on human forecasters as well as on Large Language Model (LLM)-based forecasters, given that they have recently shown to be competitive with human forecasters. In both cases, we show that filtering out incoherent predictions improves forecasting accuracy consistently, supporting the practical value of coherence in both human and LLM-based forecasting. Then, via crowd-sourced user experiments, we show that, despite its apparent intuitiveness and usefulness, users do not generally align with this coherence property. This points to the need to integrate, within argumentation-based judgmental forecasting, mechanisms to filter out incoherent opinions before obtaining group forecasting predictions.", 'abstract_zh': '主观预测利用人类意见对未来事件进行预测，而非仅依赖定量预测中的历史数据。当这些意见形成围绕预测的论辩结构时，从论辩的角度研究预测的性质是有益的。本文我们倡导并正式定义了一个论辩一致性属性，其实质要求预测者的推理与预测一致。随后，我们以我们的一致性概念进行了三项评估。首先，我们评估了强制一致性对人类预测者和基于大规模语言模型（LLM）的预测者的影响，鉴于它们最近已被证明能够与人类预测者竞争。在两种情况下，我们表明过滤掉不一致的预测能够一致地提高预测准确性，支持在人类和基于LLM的预测中一致性具有实际价值的观点。然后，通过众包用户实验，我们表明，尽管该一致性属性显得直观且有用，用户通常并不与该属性对齐。这表明，在基于论辩的主观预测中，需要集成机制，在获得小组预测结果之前过滤掉不一致的意见。', 'title_zh': '论据一致的判断性预测'}
{'arxiv_id': 'arXiv:2507.23091', 'title': "Moravec's Paradox: Towards an Auditory Turing Test", 'authors': 'David Noever, Forrest McKee', 'link': 'https://arxiv.org/abs/2507.23091', 'abstract': "This research work demonstrates that current AI systems fail catastrophically on auditory tasks that humans perform effortlessly. Drawing inspiration from Moravec's paradox (i.e., tasks simple for humans often prove difficult for machines, and vice versa), we introduce an auditory Turing test comprising 917 challenges across seven categories: overlapping speech, speech in noise, temporal distortion, spatial audio, coffee-shop noise, phone distortion, and perceptual illusions. Our evaluation of state-of-the-art audio models including GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate exceeding 93%, with even the best-performing model achieving only 6.9% accuracy on tasks that humans solved at 7.5 times higher success (52%). These results expose focusing failures in how AI systems process complex auditory scenes, particularly in selective attention, noise robustness, and contextual adaptation. Our benchmark not only quantifies the human-machine auditory gap but also provides insights into why these failures occur, suggesting that current architectures lack fundamental mechanisms for human-like auditory scene analysis. The traditional design of audio CAPTCHAs highlights common filters that humans evolved but machines fail to select in multimodal language models. This work establishes a diagnostic framework for measuring progress toward human-level machine listening and highlights the need for novel approaches integrating selective attention, physics-based audio understanding, and context-aware perception into multimodal AI systems.", 'abstract_zh': '本研究工作表明当前的AI系统在人类能够轻易完成的听觉任务上表现灾难性失败。借鉴莫拉维克悖论（即人类简单的任务往往对机器来说很困难，反之亦然），我们引入了一个包含917个挑战的听觉图灵测试，涵盖了七个类别：重叠语音、噪声中语音、时域失真、空间音频、咖啡馆噪音、电话失真以及知觉错觉。对包括GPT-4的音频能力以及OpenAI的Whisper在内的最新音频模型的评估显示，异常高的失败率为93%以上，即使表现最好的模型在人类成功率为7.5倍（52%）的任务中也仅达到6.9%的准确率。这些结果揭示了AI系统在处理复杂听觉场景时的重点失误，特别是在选择性注意、噪声鲁棒性和上下文适应性方面。我们的基准不仅量化了人类与机器在听觉方面的差距，还提供了这些失败为什么会发生的原因的见解，表明当前的架构缺乏类似人类的听觉场景分析的基本机制。传统设计的音频验证码突显了人类演化出但机器未能在多模态语言模型中选择的常见过滤器。这项工作建立了衡量人工智能向人类级听觉理解进展的诊断框架，并强调了在多模态AI系统中整合选择性注意、基于物理的音频理解以及上下文感知的必要性。', 'title_zh': '莫雷拉悖论：向听觉图灵测试迈进'}
{'arxiv_id': 'arXiv:2507.23067', 'title': 'FairReason: Balancing Reasoning and Social Bias in MLLMs', 'authors': 'Zhenyu Pan, Yutong Zhang, Jianshu Zhang, Haoran Lu, Haozheng Luo, Yuwei Han, Philip S. Yu, Manling Li, Han Liu', 'link': 'https://arxiv.org/abs/2507.23067', 'abstract': "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art results across a wide range of tasks and modalities. To push their reasoning ability further, recent studies explore advanced prompting schemes and post-training fine-tuning. Although these techniques improve logical accuracy, they frequently leave the models' outputs burdened with pronounced social biases. Clarifying how reasoning gains interact with bias mitigation-and whether the two objectives inherently trade off-therefore remains an open and pressing research problem. Our study begins by benchmarking three bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation (KD), and rule-based reinforcement learning (RL)-under identical conditions, establishing their baseline strengths and weaknesses. Building on these results, we vary the proportion of debias-focused and reasoning-centric samples within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement learning cuts stereotype scores by 10% while retaining 88% of the model's original reasoning accuracy, offering concrete guidance for balancing fairness and capability in MLLMs.", 'abstract_zh': '多模态大型语言模型（MLLMs）已在广泛的任务和模态中达到最先进的成果。为了进一步提升其推理能力，近期研究探索了高级提示方案和后训练微调。尽管这些技术提高了逻辑准确性，但它们经常使模型的输出带有明显的社会偏见。因此，如何澄清推理增益与偏见缓解之间的关系——以及这两个目标是否不可避免地相互权衡——仍然是一个开放且紧迫的研究问题。我们的研究首先在相同条件下基准测试三种偏见缓解策略——监督后训练（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL），以确立它们的基本优势和劣势。在此基础上，我们改变每个范式中偏见缓解重点和推理中心样本的比例，以绘制推理与偏见之间的权衡图。我们的研究揭示了一致的最佳比例：通过强化学习训练的大约1:4混合训练，可以将刻板印象得分降低10%，同时保留88%的原始推理准确性，为在MLLMs中平衡公平性和能力提供了具体指导。', 'title_zh': 'FairReason: 平衡理性推理与社会偏见在MLLMs中的应用'}
{'arxiv_id': 'arXiv:2507.23018', 'title': 'Data Readiness for Scientific AI at Scale', 'authors': 'Wesley Brewer, Patrick Widener, Valentine Anantharaj, Feiyi Wang, Tom Beck, Arjun Shankar, Sarp Oral', 'link': 'https://arxiv.org/abs/2507.23018', 'abstract': 'This paper examines how Data Readiness for AI (DRAI) principles apply to leadership-scale scientific datasets used to train foundation models. We analyze archetypal workflows across four representative domains - climate, nuclear fusion, bio/health, and materials - to identify common preprocessing patterns and domain-specific constraints. We introduce a two-dimensional readiness framework composed of Data Readiness Levels (raw to AI-ready) and Data Processing Stages (ingest to shard), both tailored to high performance computing (HPC) environments. This framework outlines key challenges in transforming scientific data for scalable AI training, emphasizing transformer-based generative models. Together, these dimensions form a conceptual maturity matrix that characterizes scientific data readiness and guides infrastructure development toward standardized, cross-domain support for scalable and reproducible AI for science.', 'abstract_zh': '本文探讨了数据就绪原则（DRAI）在应用于领导力规模的科学数据集（用于训练基础模型）时的适用性。我们分析了四个代表性领域的典型工作流程——气候、核聚变、生物/健康和材料——以识别通用的预处理模式和领域特定的约束条件。我们引入了一个二维就绪框架，该框架由数据就绪级别（从原始数据到AI就绪）和数据处理阶段（摄入到切片）组成，并针对高性能计算（HPC）环境进行了定制。该框架概述了将科学数据转换为可扩展AI训练的关键挑战，强调了基于变换器的生成模型。这些维度共同形成了一个概念上的成熟矩阵，用于表征科学数据的就绪状态，并指导基础设施开发，以标准化和支持跨域的可扩展和可重复的科学AI。', 'title_zh': '大规模科学AI的数据准备'}
{'arxiv_id': 'arXiv:2507.22951', 'title': 'Unifying Post-hoc Explanations of Knowledge Graph Completions', 'authors': 'Alessandro Lonardi, Samy Badreddine, Tarek R. Besold, Pablo Sanchez Martin', 'link': 'https://arxiv.org/abs/2507.22951', 'abstract': 'Post-hoc explainability for Knowledge Graph Completion (KGC) lacks formalization and consistent evaluations, hindering reproducibility and cross-study comparisons. This paper argues for a unified approach to post-hoc explainability in KGC. First, we propose a general framework to characterize post-hoc explanations via multi-objective optimization, balancing their effectiveness and conciseness. This unifies existing post-hoc explainability algorithms in KGC and the explanations they produce. Next, we suggest and empirically support improved evaluation protocols using popular metrics like Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of interpretability as the ability of explanations to address queries meaningful to end-users. By unifying methods and refining evaluation standards, this work aims to make research in KGC explainability more reproducible and impactful.', 'abstract_zh': '知识图谱完成任务的后验可解释性缺乏正式化和一致评估，阻碍了可重复性和跨研究比较。本文呼吁在知识图谱完成任务中采用统一的后验可解释性方法。首先，我们提出了一种通用框架，通过多目标优化来characterize后验解释，平衡其有效性和简洁性。这统一了现有知识图谱完成任务中的后验可解释性算法及其产生的解释。其次，我们建议并实证支持使用Mean Reciprocal Rank和Hits@$k$等流行指标改进评估协议。最后，我们强调解释的可解释性是指解释能够回答终端用户有意义的问题的重要性。通过统一方法并改进评估标准，本文旨在使知识图谱完成任务中的可解释性研究更具可重复性和影响力。', 'title_zh': '统一知识图谱补全的后验解释方法'}
{'arxiv_id': 'arXiv:2507.23784', 'title': 'SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions', 'authors': 'Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata', 'link': 'https://arxiv.org/abs/2507.23784', 'abstract': 'Concept Bottleneck Models (CBMs) and other concept-based interpretable models show great promise for making AI applications more transparent, which is essential in fields like medicine. Despite their success, we demonstrate that CBMs struggle to reliably identify the correct concepts under distribution shifts. To assess the robustness of CBMs to concept variations, we introduce SUB: a fine-grained image and concept benchmark containing 38,400 synthetic images based on the CUB dataset. To create SUB, we select a CUB subset of 33 bird classes and 45 concepts to generate images which substitute a specific concept, such as wing color or belly pattern. We introduce a novel Tied Diffusion Guidance (TDG) method to precisely control generated images, where noise sharing for two parallel denoising processes ensures that both the correct bird class and the correct attribute are generated. This novel benchmark enables rigorous evaluation of CBMs and similar interpretable models, contributing to the development of more robust methods. Our code is available at this https URL and the dataset at this http URL.', 'abstract_zh': '概念瓶颈模型（CBMs）和其他基于概念的可解释模型在使AI应用更具透明度方面显示出巨大的潜力，这对于医疗等领域至关重要。尽管取得了成功，我们证明CBMs在分布偏移情况下难以可靠地识别正确的概念。为了评估CBMs对概念变化的鲁棒性，我们引入了SUB：一个细粒度的图像和概念基准，包含基于CUB数据集的38,400张合成图像。为了创建SUB，我们选择了CUB数据集中的33个鸟类类别和45个概念来生成替换特定概念的图像，如翅膀颜色或腹部图案。我们提出了一种新颖的连接扩散引导（TDG）方法，以精确控制生成的图像，其中两个并行去噪过程的噪声共享确保同时生成正确的鸟类类别和正确属性。这一新颖基准为CBMs和其他可解释模型的严格评估提供了可能，促进了更稳健方法的发展。相关代码和数据集可分别在以下链接获取：此 https URL 和此 http URL。', 'title_zh': '基于合成属性替换benchmarking CBM泛化能力'}
{'arxiv_id': 'arXiv:2507.23779', 'title': 'Phi-Ground Tech Report: Advancing Perception in GUI Grounding', 'authors': 'Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo', 'link': 'https://arxiv.org/abs/2507.23779', 'abstract': 'With the development of multimodal reasoning models, Computer Use Agents (CUAs), akin to Jarvis from \\textit{"Iron Man"}, are becoming a reality. GUI grounding is a core component for CUAs to execute actual actions, similar to mechanical control in robotics, and it directly leads to the success or failure of the system. It determines actions such as clicking and typing, as well as related parameters like the coordinates for clicks. Current end-to-end grounding models still achieve less than 65\\% accuracy on challenging benchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from being ready for deployment. % , as a single misclick can result in unacceptable consequences. In this work, we conduct an empirical study on the training of grounding models, examining details from data collection to model training. Ultimately, we developed the \\textbf{Phi-Ground} model family, which achieves state-of-the-art performance across all five grounding benchmarks for models under $10B$ parameters in agent settings. In the end-to-end model setting, our model still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on ScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the various details discussed in this paper, along with our successes and failures, not only clarify the construction of grounding models but also benefit other perception tasks. Project homepage: \\href{this https URL}{this https URL}', 'abstract_zh': '随着多模态推理模型的发展，计算机使用代理（CUAs），类似于《钢铁侠》中的Jarvis，正在成为现实。GUI定位是CUAs执行实际操作的核心组件，类似于机器人领域的机械控制，直接关系到系统的成功或失败。它决定了点击和输入等相关操作及其参数，如点击坐标。当前的端到端定位模型在ScreenSpot-pro和UI-Vision等具有挑战性的基准测试中仍未能达到65%以上的准确率，表明它们尚未准备好部署。因此，单次误操作可能导致不可接受的后果。在本文中，我们对定位模型的训练进行了实证研究，从数据收集到模型训练进行了详细探讨。最终，我们开发了Phi-Ground模型系列，在agent设置下，该模型在所有五个定位基准测试中都达到了参数量低于10B的模型的最优性能。在端到端模型设置中，我们的模型在ScreenSpot-pro和UI-Vision上的得分分别为43.2和27.2，仍然取得了最优结果。我们相信，本文中讨论的各个方面，以及我们的成功与失败，不仅阐明了定位模型的构建，还对其他感知任务有益。项目主页：this https URL', 'title_zh': 'Phi-Ground 技术报告：提升GUI定位感知技术'}
{'arxiv_id': 'arXiv:2507.23771', 'title': 'Consensus-Driven Active Model Selection', 'authors': 'Justin Kay, Grant Van Horn, Subhransu Maji, Daniel Sheldon, Sara Beery', 'link': 'https://arxiv.org/abs/2507.23771', 'abstract': 'The widespread availability of off-the-shelf machine learning models poses a challenge: which model, of the many available candidates, should be chosen for a given data analysis task? This question of model selection is traditionally answered by collecting and annotating a validation dataset -- a costly and time-intensive process. We propose a method for active model selection, using predictions from candidate models to prioritize the labeling of test data points that efficiently differentiate the best candidate. Our method, CODA, performs consensus-driven active model selection by modeling relationships between classifiers, categories, and data points within a probabilistic framework. The framework uses the consensus and disagreement between models in the candidate pool to guide the label acquisition process, and Bayesian inference to update beliefs about which model is best as more information is collected. We validate our approach by curating a collection of 26 benchmark tasks capturing a range of model selection scenarios. CODA outperforms existing methods for active model selection significantly, reducing the annotation effort required to discover the best model by upwards of 70% compared to the previous state-of-the-art. Code and data are available at this https URL.', 'abstract_zh': '现成机器学习模型的广泛可用性提出了一个挑战：在众多候选模型中，应该选择哪个模型来完成给定的数据分析任务？传统的模型选择方法是通过收集和标注验证数据集来回答这一问题，这是一个 costly 和耗费时间的过程。我们提出了一种主动模型选择方法，利用候选模型的预测来优先标注能够有效区分最佳候选模型的测试数据点。我们的方法 CODA 通过在概率框架下建模分类器、类别和数据点之间的关系来进行共识驱动的主动模型选择。该框架利用候选池中模型的一致性和分歧来指导标签获取过程，并利用贝叶斯推断随着收集更多信息来更新对最佳模型的信念。我们通过收集 26 个基准任务的集合验证了我们的方法，涵盖了各种模型选择场景。CODA 在主动模型选择方面显著优于现有方法，相比之前最先进的方法，发现最佳模型所需标注努力最多可减少 70%。代码和数据可在以下链接获取。', 'title_zh': '共识驱动的主动模型选择'}
{'arxiv_id': 'arXiv:2507.23740', 'title': 'Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs', 'authors': 'Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li', 'link': 'https://arxiv.org/abs/2507.23740', 'abstract': 'Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at this https URL}{this https URL.', 'abstract_zh': '知识图谱中的逻辑规则的自然语言解释：大规模语言模型的潜力探究', 'title_zh': 'Rule2Text：知识图谱中逻辑规则的自然语言解释'}
{'arxiv_id': 'arXiv:2507.23735', 'title': 'Distributed AI Agents for Cognitive Underwater Robot Autonomy', 'authors': 'Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot', 'link': 'https://arxiv.org/abs/2507.23735', 'abstract': "Achieving robust cognitive autonomy in robots navigating complex, unpredictable environments remains a fundamental challenge in robotics. This paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a groundbreaking architecture leveraging distributed Large Language Model AI agents integrated within the Robot Operating System 2 (ROS 2) framework to enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA decentralises cognition into specialised AI agents responsible for multimodal perception, adaptive reasoning, dynamic mission planning, and real-time decision-making. Central innovations include flexible agents dynamically adapting their roles, retrieval-augmented generation utilising vector databases for efficient knowledge management, reinforcement learning-driven behavioural optimisation, and autonomous on-the-fly ROS 2 node generation for runtime functional extensibility. Extensive empirical validation demonstrates UROSA's promising adaptability and reliability through realistic underwater missions in simulation and real-world deployments, showing significant advantages over traditional rule-based architectures in handling unforeseen scenarios, environmental uncertainties, and novel mission objectives. This work not only advances underwater autonomy but also establishes a scalable, safe, and versatile cognitive robotics framework capable of generalising to a diverse array of real-world applications.", 'abstract_zh': '在复杂不可预测环境中实现机器人鲁棒认知自主仍然是机器人领域的一项基本挑战。本文提出了基于机器人操作系统2（ROS 2）框架的自组织自主水下机器人（Underwater Robot Self-Organizing Autonomy，UROSA）架构，该架构结合了分布式大型语言模型AI代理，以在自主水下车辆中实现高级认知能力。UROSA将认知分散到专门的AI代理中，负责多模态感知、自适应推理、动态任务规划和实时决策。核心创新包括灵活的代理动态适应其角色、利用向量数据库进行高效知识管理的检索增强生成、基于强化学习的行为优化，以及运行时功能扩展的自主ROS 2节点生成。广泛的实证验证展示了UROSA在模拟和真实世界部署中的适应性和可靠性，证实其在处理未预见场景、环境不确定性以及新型任务目标方面较传统基于规则的架构具有显著优势。这项工作不仅推进了水下自主性，还建立了一个可扩展、安全且多功能的认知机器人框架，适用于多种实际应用。', 'title_zh': '分布式人工智能代理的认知水下机器人自主控制'}
{'arxiv_id': 'arXiv:2507.23704', 'title': 'Enhanced Velocity Field Modeling for Gaussian Video Reconstruction', 'authors': 'Zhenyang Li, Xiaoyang Bai, Tongchen Zhang, Pengfei Shen, Weiwei Xu, Yifan Peng', 'link': 'https://arxiv.org/abs/2507.23704', 'abstract': "High-fidelity 3D video reconstruction is essential for enabling real-time rendering of dynamic scenes with realistic motion in virtual and augmented reality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has achieved near-photorealistic results in video reconstruction due to the great representation capability of deep deformation networks. However, in videos with complex motion and significant scale variations, deformation networks often overfit to irregular Gaussian trajectories, leading to suboptimal visual quality. Moreover, the gradient-based densification strategy designed for static scene reconstruction proves inadequate to address the absence of dynamic content. In light of these challenges, we propose a flow-empowered velocity field modeling scheme tailored for Gaussian video reconstruction, dubbed FlowGaussian-VR. It consists of two core components: a velocity field rendering (VFR) pipeline which enables optical flow-based optimization, and a flow-assisted adaptive densification (FAD) strategy that adjusts the number and size of Gaussians in dynamic regions. We validate our model's effectiveness on multi-view dynamic reconstruction and novel view synthesis with multiple real-world datasets containing challenging motion scenarios, demonstrating not only notable visual improvements (over 2.5 dB gain in PSNR) and less blurry artifacts in dynamic textures, but also regularized and trackable per-Gaussian trajectories.", 'abstract_zh': '高保真3D视频重建对于在虚拟现实（VR）和增强现实（AR）中实时渲染具有现实运动的动态场景至关重要。基于变形场的3D高斯散点图方法由于深层变形网络的强大表示能力，在视频重建中实现了接近照片级的真实结果。然而，在具有复杂运动和显著尺度变化的视频中，变形网络往往会过度拟合不规则的高斯轨迹，导致视觉质量不佳。此外，为静态场景重建设计的基于梯度的密度增强策略无法有效解决动态内容的缺失问题。针对这些挑战，我们提出了一种流增强的速度场建模方案，名为FlowGaussian-VR。该方案包含两个核心组件：速度场渲染（VFR）管道，支持基于光流的优化，以及流辅助自适应密度增强（FAD）策略，该策略根据动态区域调整高斯的数量和大小。我们在包含具有挑战性运动场景的多个真实世界数据集的多视图动态重建和新颖视图合成中验证了我们模型的有效性，不仅展示了显著的视觉改善（PSNR增益超过2.5 dB）和动态纹理中较少的模糊 artefacts，而且还展示了规整且可追踪的每高斯轨迹。', 'title_zh': '增强速度场建模以实现高斯视频重建'}
{'arxiv_id': 'arXiv:2507.23698', 'title': 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents', 'authors': 'Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang', 'link': 'https://arxiv.org/abs/2507.23698', 'abstract': "While Reinforcement Learning (RL) has achieved remarkable success in language modeling, its triumph hasn't yet fully translated to visuomotor agents. A primary challenge in RL models is their tendency to overfit specific tasks or environments, thereby hindering the acquisition of generalizable behaviors across diverse settings. This paper provides a preliminary answer to this challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can achieve zero-shot generalization to unseen worlds. Specifically, we explore RL's potential to enhance generalizable spatial reasoning and interaction capabilities in 3D worlds. To address challenges in multi-task RL representation, we analyze and establish cross-view goal specification as a unified multi-task goal space for visuomotor policies. Furthermore, to overcome the significant bottleneck of manual task design, we propose automated task synthesis within the highly customizable Minecraft environment for large-scale multi-task RL training, and we construct an efficient distributed RL framework to support this. Experimental results show RL significantly boosts interaction success rates by $4\\times$ and enables zero-shot generalization of spatial reasoning across diverse environments, including real-world settings. Our findings underscore the immense potential of RL training in 3D simulated environments, especially those amenable to large-scale task generation, for significantly advancing visuomotor agents' spatial reasoning.", 'abstract_zh': '强化学习在视觉运动代理中的零样本泛化：以《我的世界》为例', 'title_zh': '可扩展的多任务强化学习以实现通用的空间智能在视觉运动代理中的应用'}
{'arxiv_id': 'arXiv:2507.23694', 'title': 'A survey of multi-agent geosimulation methodologies: from ABM to LLM', 'authors': 'Virginia Padilla, Jacinto Dávila', 'link': 'https://arxiv.org/abs/2507.23694', 'abstract': 'We provide a comprehensive examination of agent-based approaches that codify the principles and linkages underlying multi-agent systems, simulations, and information systems. Based on two decades of study, this paper confirms a framework intended as a formal specification for geosimulation platforms. Our findings show that large language models (LLMs) can be effectively incorporated as agent components if they follow a structured architecture specific to fundamental agent activities such as perception, memory, planning, and action. This integration is precisely consistent with the architecture that we formalize, providing a solid platform for next-generation geosimulation systems.', 'abstract_zh': '基于代理的多代理系统、仿真和信息系统的原则与链接的全面考察：大型语言模型在结构化代理架构中的有效整合与框架验证', 'title_zh': '多智能体地理模拟方法学综述：从ABM到LLM'}
{'arxiv_id': 'arXiv:2507.23682', 'title': 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models', 'authors': 'Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian', 'link': 'https://arxiv.org/abs/2507.23682', 'abstract': 'Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent work has begun to explore the incorporation of latent actions, an abstract representation of visual change between two frames, into VLA pre-training. In this paper, we introduce villa-X, a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies. Our approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. Together, these contributions enable villa-X to achieve superior performance across simulated environments including SIMPLER and LIBERO, as well as on two real-world robot setups including gripper and dexterous hand manipulation. We believe the ViLLA paradigm holds significant promise, and that our villa-X provides a strong foundation for future research.', 'abstract_zh': '视觉-语言-隐含动作（ViLLA）框架：一种用于学习可泛化机器人操作策略的新型隐含动作建模方法', 'title_zh': 'villa-X: 提升视觉-语言-动作模型中的潜在动作建模能力'}
{'arxiv_id': 'arXiv:2507.23669', 'title': 'Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database', 'authors': 'Diego Russo, Gian Marco Orlando, Valerio La Gatta, Vincenzo Moscato', 'link': 'https://arxiv.org/abs/2507.23669', 'abstract': 'Artificial Intelligence (AI) systems are transforming critical sectors such as healthcare, finance, and transportation, enhancing operational efficiency and decision-making processes. However, their deployment in high-stakes domains has exposed vulnerabilities that can result in significant societal harm. To systematically study and mitigate these risk, initiatives like the AI Incident Database (AIID) have emerged, cataloging over 3,000 real-world AI failure reports. Currently, associating a new report with the appropriate AI Incident relies on manual expert intervention, limiting scalability and delaying the identification of emerging failure patterns.\nTo address this limitation, we propose a retrieval-based framework that automates the association of new reports with existing AI Incidents through semantic similarity modeling. We formalize the task as a ranking problem, where each report-comprising a title and a full textual description-is compared to previously documented AI Incidents based on embedding cosine similarity. Benchmarking traditional lexical methods, cross-encoder architectures, and transformer-based sentence embedding models, we find that the latter consistently achieve superior performance. Our analysis further shows that combining titles and descriptions yields substantial improvements in ranking accuracy compared to using titles alone. Moreover, retrieval performance remains stable across variations in description length, highlighting the robustness of the framework. Finally, we find that retrieval performance consistently improves as the training set expands. Our approach provides a scalable and efficient solution for supporting the maintenance of the AIID.', 'abstract_zh': '人工intelligence（AI）系统正在改变医疗、金融和交通等关键领域，提升运营效率和决策过程。然而，在高风险领域部署AI系统暴露出了一些漏洞，可能导致重大社会危害。为系统地研究和缓解这些风险，AI事故数据库（AIID）等相关倡议应运而生，已记录了超过3,000份真实的AI故障报告。目前，将新报告与适当的AI事故关联依赖于人工专家介入，限制了可扩展性并延迟了新兴故障模式的识别。\n\n为解决这一局限，我们提出了一种检索框架，通过语义相似度建模自动将新报告与现有AI事故关联。我们将任务正式化为一个排序问题，每个报告（包含标题和完整文本描述）基于嵌入余弦相似度与之前记录的AI事故进行比较。我们对传统的词法方法、跨编码架构以及基于转换器的句子嵌入模型进行了基准测试，发现后者始终表现出更优的性能。进一步分析表明，结合标题和描述在排名准确性上相较于仅使用标题带来了显著提高。此外，检索性能在描述长度变化时保持稳定，突显了该框架的稳健性。最后，我们发现随着训练集的扩展，检索性能持续提高。我们的方法提供了一种可扩展且高效的解决方案，以支持AIID的维护。', 'title_zh': '自动化AI失败跟踪：AI事件数据库中报告的语义关联'}
{'arxiv_id': 'arXiv:2507.23642', 'title': 'Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation', 'authors': 'Dustin Carrión-Ojeda, Stefan Roth, Simone Schaub-Meyer', 'link': 'https://arxiv.org/abs/2507.23642', 'abstract': 'Few-shot classification and segmentation (FS-CS) focuses on jointly performing multi-label classification and multi-class segmentation using few annotated examples. Although the current state of the art (SOTA) achieves high accuracy in both tasks, it struggles with small objects. To overcome this, we propose the Efficient Masked Attention Transformer (EMAT), which improves classification and segmentation accuracy, especially for small objects. EMAT introduces three modifications: a novel memory-efficient masked attention mechanism, a learnable downscaling strategy, and parameter-efficiency enhancements. EMAT outperforms all FS-CS methods on the PASCAL-5$^i$ and COCO-20$^i$ datasets, using at least four times fewer trainable parameters. Moreover, as the current FS-CS evaluation setting discards available annotations, despite their costly collection, we introduce two novel evaluation settings that consider these annotations to better reflect practical scenarios.', 'abstract_zh': 'Few-shot 分类与分割 (FS-CS) 研究旨在使用少量标注样本同时进行多标签分类和多类分割。尽管当前最佳方法 (SOTA) 在两项任务上都达到了较高的准确性，但它在处理小物体时表现不佳。为了解决这一问题，我们提出了高效掩码注意力变换器 (EMAT)，该方法能够提高分类和分割的准确性，尤其适用于小物体。EMAT 引入了三种改进：一种新的内存高效掩码注意力机制、可学习的下采样策略和参数效率增强。EMAT 在 PASCAL-5$^i$ 和 COCO-20$^i$ 数据集上的表现优于所有 FS-CS 方法，使用了至少四倍少的可训练参数。此外，鉴于当前 FS-CS 评估设置忽略了可用的标注信息，尽管这些标注信息的收集成本高昂，我们引入了两种新的评估设置，考虑这些标注信息以更好地反映实际场景。', 'title_zh': '面向少样本分类和分割的高效遮蔽注意力变压器'}
{'arxiv_id': 'arXiv:2507.23638', 'title': 'OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting', 'authors': 'Mohammad Karami, Fatemeh Ghassemi, Hamed Kebriaei, Hamid Azadegan', 'link': 'https://arxiv.org/abs/2507.23638', 'abstract': "Federated Learning (FL) enables collaborative model training across distributed medical institutions while preserving patient privacy, but remains vulnerable to Byzantine attacks and statistical heterogeneity. We present OptiGradTrust, a comprehensive defense framework that evaluates gradient updates through a novel six-dimensional fingerprint including VAE reconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency ratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module for adaptive trust scoring. To address convergence challenges under data heterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch Normalization with proximal regularization for optimal accuracy-convergence trade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI datasets under various Byzantine attack scenarios demonstrates significant improvements over state-of-the-art defenses, achieving up to +1.6 percentage points over FLGuard under non-IID conditions while maintaining robust performance against diverse attack patterns through our adaptive learning approach.", 'abstract_zh': '联邦学习(Federated Learning, FL)能够在保护患者隐私的同时跨分布式医疗机构进行协作模型训练，但仍然易受拜占庭攻击和统计异质性的影响。我们提出了一种名为OptiGradTrust的综合防御框架，通过六维指纹（包括VAE重构误差、余弦相似度度量、$L_2$范数、符号一致性比值和蒙特卡洛Shapley值）评估梯度更新，并驱动混合强化学习-注意力模块以实现自适应信任评分。为了解决数据异质性下的收敛挑战，我们开发了FedBN-Prox（FedBN-P），结合了分布式批量归一化和邻近正则化，以实现最优的准确率-收敛性 trade-offs。在MNIST、CIFAR-10 和阿尔茨海默病MRI数据集上的广泛评估表明，我们的防御方法在各种拜占庭攻击场景下显著优于现有防御方法，在非IID条件下FLGuard之上提升幅度可达1.6个百分点，并通过自适应学习方法实现对多种攻击模式的稳健性能。', 'title_zh': 'OptiGradTrust：基于多特征梯度分析和基于强化学习的信任加权的拜占庭鲁棒联邦学习'}
{'arxiv_id': 'arXiv:2507.23615', 'title': 'L-GTA: Latent Generative Modeling for Time Series Augmentation', 'authors': 'Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo', 'link': 'https://arxiv.org/abs/2507.23615', 'abstract': 'Data augmentation is gaining importance across various aspects of time series analysis, from forecasting to classification and anomaly detection tasks. We introduce the Latent Generative Transformer Augmentation (L-GTA) model, a generative approach using a transformer-based variational recurrent autoencoder. This model uses controlled transformations within the latent space of the model to generate new time series that preserve the intrinsic properties of the original dataset. L-GTA enables the application of diverse transformations, ranging from simple jittering to magnitude warping, and combining these basic transformations to generate more complex synthetic time series datasets. Our evaluation of several real-world datasets demonstrates the ability of L-GTA to produce more reliable, consistent, and controllable augmented data. This translates into significant improvements in predictive accuracy and similarity measures compared to direct transformation methods.', 'abstract_zh': 'Latent Generative Transformer Augmentation (L-GTA)模型：一种基于变换器的变分递归自编码器生成方法', 'title_zh': 'L-GTA:潜在生成模型的时间序列扩充'}
{'arxiv_id': 'arXiv:2507.23611', 'title': 'LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora', 'authors': 'Estelle Ruellan, Eric Clay, Nicholas Ascoli', 'link': 'https://arxiv.org/abs/2507.23611', 'abstract': 'Infostealers exfiltrate credentials, session cookies, and sensitive data from infected systems. With over 29 million stealer logs reported in 2024, manual analysis and mitigation at scale are virtually unfeasible/unpractical. While most research focuses on proactive malware detection, a significant gap remains in leveraging reactive analysis of stealer logs and their associated artifacts. Specifically, infection artifacts such as screenshots, image captured at the point of compromise, are largely overlooked by the current literature. This paper introduces a novel approach leveraging Large Language Models (LLMs), more specifically gpt-4o-mini, to analyze infection screenshots to extract potential Indicators of Compromise (IoCs), map infection vectors, and track campaigns. Focusing on the Aurora infostealer, we demonstrate how LLMs can process screenshots to identify infection vectors, such as malicious URLs, installer files, and exploited software themes. Our method extracted 337 actionable URLs and 246 relevant files from 1000 screenshots, revealing key malware distribution methods and social engineering tactics. By correlating extracted filenames, URLs, and infection themes, we identified three distinct malware campaigns, demonstrating the potential of LLM-driven analysis for uncovering infection workflows and enhancing threat intelligence. By shifting malware analysis from traditional log-based detection methods to a reactive, artifact-driven approach that leverages infection screenshots, this research presents a scalable method for identifying infection vectors and enabling early intervention.', 'abstract_zh': '信息窃取者从感染系统中窃取凭证、会话cookie和敏感数据。2024年报告的窃取者日志超过2900万条，大规模的手动分析和缓解几乎不可能实现。尽管大多数研究集中在主动恶意软件检测上，但在利用窃取者日志及其相关 artifacts 的主动分析方面仍然存在显著差距。特别是，当前文献中对感染 artifacts 如屏幕截图、妥协点捕获的图像等的重视不足。本文提出了一种利用大型语言模型（LLMs），具体而言是gpt-4o-mini，通过分析感染屏幕截图来提取潜在的指标（IoCs）、映射感染途径并追踪活动的新方法。以Aurora信息窃取者为例，我们展示了如何通过分析屏幕截图识别出感染途径，如恶意URL、安装文件和被利用的软件主题。我们的方法从1000张屏幕截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件传播方式和社会工程战术。通过关联提取出的文件名、URL和感染主题，我们识别出了三个不同的恶意软件活动系列，验证了基于LLM的分析在揭示感染工作流和增强威胁情报方面的潜力。通过将恶意软件分析从传统的日志基础检测方法转向基于感染屏幕截图的反馈式、artifact驱动的方法，本研究提出了一种可扩展的方法来识别感染途径并实现早期干预。', 'title_zh': '基于LLM的屏幕截图中信息窃取者感染向量识别：以 Aurora 为例'}
{'arxiv_id': 'arXiv:2507.23607', 'title': 'Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates', 'authors': 'Tien Huu Do, Antoine Masquelier, Nae Eoun Lee, Jonathan Crowther', 'link': 'https://arxiv.org/abs/2507.23607', 'abstract': 'Clinical trials are a systematic endeavor to assess the safety and efficacy of new drugs or treatments. Conducting such trials typically demands significant financial investment and meticulous planning, highlighting the need for accurate predictions of trial outcomes. Accurately predicting patient enrollment, a key factor in trial success, is one of the primary challenges during the planning phase. In this work, we propose a novel deep learning-based method to address this critical challenge. Our method, implemented as a neural network model, leverages pre-trained language models (PLMs) to capture the complexities and nuances of clinical documents, transforming them into expressive representations. These representations are then combined with encoded tabular features via an attention mechanism. To account for uncertainties in enrollment prediction, we enhance the model with a probabilistic layer based on the Gamma distribution, which enables range estimation. We apply the proposed model to predict clinical trial duration, assuming site-level enrollment follows a Poisson-Gamma process. We carry out extensive experiments on real-world clinical trial data, and show that the proposed method can effectively predict the number of patients enrolled at a number of sites for a given clinical trial, outperforming established baseline models.', 'abstract_zh': '基于深度学习的方法用于预测临床试验患者招募数量', 'title_zh': '基于深度学习的临床试验入组预测及其不确定性估计'}
{'arxiv_id': 'arXiv:2507.23589', 'title': 'Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study', 'authors': 'Kai Goebel, Patrik Zips', 'link': 'https://arxiv.org/abs/2507.23589', 'abstract': 'Recent advancements in Large Language Models have sparked interest in their potential for robotic task planning. While these models demonstrate strong generative capabilities, their effectiveness in producing structured and executable plans remains uncertain. This paper presents a systematic evaluation of a broad spectrum of current state of the art language models, each directly prompted using Planning Domain Definition Language domain and problem files, and compares their planning performance with the Fast Downward planner across a variety of benchmarks. In addition to measuring success rates, we assess how faithfully the generated plans translate into sequences of actions that can actually be executed, identifying both strengths and limitations of using these models in this setting. Our findings show that while the models perform well on simpler planning tasks, they continue to struggle with more complex scenarios that require precise resource management, consistent state tracking, and strict constraint compliance. These results underscore fundamental challenges in applying language models to robotic planning in real world environments. By outlining the gaps that emerge during execution, we aim to guide future research toward combined approaches that integrate language models with classical planners in order to enhance the reliability and scalability of planning in autonomous robotics.', 'abstract_zh': '近期大型语言模型的进展激发了对其在机器人任务规划中潜力的兴趣。虽然这些模型展示了强大的生成能力，但它们在生成结构化和可执行计划方面的有效性仍有待确定。本文系统评估了当前最先进的多种语言模型在使用Planning Domain Definition Language领域和问题文件直接提示下的规划性能，并将其与Fast Downward规划器在多种基准测试中的表现进行比较。除了衡量成功率外，我们还评估了生成的计划如何忠实转化为实际可执行的动作序列，从而识别这些模型在这种设置下使用的优势和局限性。研究发现，尽管模型在简单的规划任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束合规的复杂场景中仍然表现不佳。这些结果突显了将语言模型应用于现实环境中的机器人规划的基本挑战。通过指出执行中出现的差距，我们旨在引导未来研究向结合语言模型与经典规划器的方法发展，以提高自主机器人规划的可靠性和可扩展性。', 'title_zh': 'LLM-推理模型能否替代经典规划？一项基准研究'}
{'arxiv_id': 'arXiv:2507.23543', 'title': 'ART: Adaptive Relation Tuning for Generalized Relation Prediction', 'authors': 'Gopika Sudhakaran, Hikaru Shindo, Patrick Schramowski, Simone Schaub-Meyer, Kristian Kersting, Stefan Roth', 'link': 'https://arxiv.org/abs/2507.23543', 'abstract': "Visual relation detection (VRD) is the task of identifying the relationships between objects in a scene. VRD models trained solely on relation detection data struggle to generalize beyond the relations on which they are trained. While prompt tuning has been used to adapt vision-language models (VLMs) for VRD, it uses handcrafted prompts and struggles with novel or complex relations. We argue that instruction tuning offers a more effective solution by fine-tuning VLMs on diverse instructional data. We thus introduce ART, an Adaptive Relation Tuning framework that adapts VLMs for VRD through instruction tuning and strategic instance selection. By converting VRD datasets into an instruction tuning format and employing an adaptive sampling algorithm, ART directs the VLM to focus on informative relations while maintaining generalizability. Specifically, we focus on the relation classification, where subject-object boxes are given and the model predicts the predicate between them. We tune on a held-in set and evaluate across multiple held-out datasets of varying complexity. Our approach strongly improves over its baselines and can infer unseen relation concepts, a capability absent in mainstream VRD methods. We demonstrate ART's practical value by using the predicted relations for segmenting complex scenes.", 'abstract_zh': '视觉关系检测中的自适应关系微调（ART）', 'title_zh': '自适应关系调谐以实现通用关系预测'}
{'arxiv_id': 'arXiv:2507.23540', 'title': 'A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving', 'authors': 'Yi Zhang, Erik Leo Haß, Kuo-Yi Chao, Nenad Petrovic, Yinglei Song, Chengdong Wu, Alois Knoll', 'link': 'https://arxiv.org/abs/2507.23540', 'abstract': 'Autonomous driving systems face significant challenges in achieving human-like adaptability, robustness, and interpretability in complex, open-world environments. These challenges stem from fragmented architectures, limited generalization to novel scenarios, and insufficient semantic extraction from perception. To address these limitations, we propose a unified Perception-Language-Action (PLA) framework that integrates multi-sensor fusion (cameras, LiDAR, radar) with a large language model (LLM)-augmented Vision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered reasoning core. This framework unifies low-level sensory processing with high-level contextual reasoning, tightly coupling perception with natural language-based semantic understanding and decision-making to enable context-aware, explainable, and safety-bounded autonomous driving. Evaluations on an urban intersection scenario with a construction zone demonstrate superior performance in trajectory tracking, speed prediction, and adaptive planning. The results highlight the potential of language-augmented cognitive frameworks for advancing the safety, interpretability, and scalability of autonomous driving systems.', 'abstract_zh': '自主驾驶系统在实现人类级别的适应性、鲁棒性和可解释性方面面临重大挑战，尤其是在复杂、开放的环境中。这些挑战源自于分立的架构、对新型场景的有限泛化能力以及感知中语义提取的不足。为了解决这些限制，我们提出了一种统一的感知-语言-行动（PLA）框架，该框架集成了多传感器融合（摄像头、LiDAR、雷达）并与增强型视觉-语言-行动（VLA）架构相结合，特别是使用GPT-4.1增强的推理核心。该框架将低级感官处理与高级上下文推理统一起来，紧密耦合感知与基于自然语言的语义理解及决策制定，以实现情境感知、可解释且安全可靠的自主驾驶。在包含施工区的城镇交叉口场景上的评估表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现出优越性能。研究结果突显了语言增强认知框架在提高自主驾驶系统安全性、可解释性和可扩展性方面的潜在价值。', 'title_zh': '统一的感知-语言-行动框架以实现适应性自动驾驶'}
{'arxiv_id': 'arXiv:2507.23536', 'title': 'From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices', 'authors': 'Georg Slamanig, Francesco Corti, Olga Saukh', 'link': 'https://arxiv.org/abs/2507.23536', 'abstract': 'Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs of updating deep learning models by minimizing the number of additional parameters used to adapt a model to a down- stream task. While extensively researched in large language models (LLMs), their application to smaller models used on edge devices, such as convolutional neural networks, remains underexplored. This paper benchmarks and analyzes popular PEFT methods on convolutional architectures typically deployed in resource-constrained edge environments. We evaluate LoRA, DoRA, and GaLore for updating standard and depthwise convolutional architectures to handle distribution shifts and accommodate unseen classes. We utilize recently proposed PyTorch profilers to compare the updated model performance and computational costs of these PEFT methods with traditional fine-tuning approaches. With resource efficiency in mind, we investigate their update behavior across different rank dimensions. We find that the evaluated PEFT methods are only half as memory-efficient when applied to depthwise-separable convolution architectures, compared to their efficiency with LLMs. Conversely, when targeting convolu- tional architectures optimized for edge deployment, adapter-based PEFT methods can reduce floating point operations (FLOPs) during model updates by up to 95%. These insights offer valuable guidance for selecting PEFT methods based on hardware constraints, performance requirements, and application needs. Our code is online.', 'abstract_zh': '参数效率微调（PEFT）方法通过减少附加参数的数量来降低更新深度学习模型的计算成本，从而最小化下游任务适应所需的新增参数。尽管在大型语言模型（LLMs）中得到了广泛研究，但其在资源受限的边缘设备上使用的小型模型，如卷积神经网络（CNNs）中的应用仍处于探索阶段。本文对流行的各种PEFT方法在资源受限的边缘环境常见的卷积架构上进行了基准测试和分析，评估了LoRA、DoRA和GaLore方法用于更新标准卷积架构和深度可分离卷积架构以应对分布偏移和处理未见类别的能力。我们利用最近提出的PyTorch性能分析器，将这些PEFT方法与传统微调方法在更新模型的性能和计算成本方面的表现进行了比较。考虑到资源效率，我们研究了这些方法在不同秩维度下的更新行为。研究表明，当应用于深度可分离卷积架构时，评估的PEFT方法的内存效率仅为大型语言模型中的效率的一半。相反，当针对优化用于边缘部署的卷积架构时，基于适配器的PEFT方法可以将模型更新过程中的浮点运算（FLOPs）减少高达95%。这些见解为根据硬件限制、性能要求和应用需求选择PEFT方法提供了宝贵指导。我们的代码已上线。', 'title_zh': '从大型语言模型到边缘设备：参数高效微调'}
{'arxiv_id': 'arXiv:2507.23535', 'title': 'Transparent AI: The Case for Interpretability and Explainability', 'authors': 'Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval', 'link': 'https://arxiv.org/abs/2507.23535', 'abstract': 'As artificial intelligence systems increasingly inform high-stakes decisions across sectors, transparency has become foundational to responsible and trustworthy AI implementation. Leveraging our role as a leading institute in advancing AI research and enabling industry adoption, we present key insights and lessons learned from practical interpretability applications across diverse domains. This paper offers actionable strategies and implementation guidance tailored to organizations at varying stages of AI maturity, emphasizing the integration of interpretability as a core design principle rather than a retrospective add-on.', 'abstract_zh': '随着人工智能系统在各领域的高风险决策中发挥越来越重要的作用，透明度已成为负责任且可信赖的人工智能实施的基础。凭借我们在推动人工智能研究和促进产业应用方面领先机构的地位，我们呈现了跨多种领域实际可解释性应用的关键见解和经验教训。本文为处于不同人工智能成熟阶段的组织提供了可操作的策略和实施指导，强调在设计原则中整合可解释性的重要性，而不是事后添加。', 'title_zh': '透明AI：可解释性的重要性和必要性'}
{'arxiv_id': 'arXiv:2507.23511', 'title': 'MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks', 'authors': 'Yadong Niu, Tianzi Wang, Heinrich Dinkel, Xingwei Sun, Jiahao Zhou, Gang Li, Jizhong Liu, Xunying Liu, Junbo Zhang, Jian Luan', 'link': 'https://arxiv.org/abs/2507.23511', 'abstract': 'While large audio-language models have advanced open-ended audio understanding, they still fall short of nuanced human-level comprehension. This gap persists largely because current benchmarks, limited by data annotations and evaluation metrics, fail to reliably distinguish between generic and highly detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via a pipeline that integrates analysis from specialized expert models with Chain-of-Thought large language model reasoning, MECAT provides multi-perspective, fine-grained captions and open-set question-answering pairs. The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced Audio Text Evaluation). This metric penalizes generic terms and rewards detailed descriptions by combining single-sample semantic similarity with cross-sample discriminability. A comprehensive evaluation of state-of-the-art audio models is also presented, providing new insights into their current capabilities and limitations. The data and code are available at this https URL', 'abstract_zh': '面向细粒度音频理解任务的多专家构建基准MECAT', 'title_zh': 'MECAT：一个多专家构建的细粒度音频理解基准数据集'}
{'arxiv_id': 'arXiv:2507.23509', 'title': 'I Am Big, You Are Little; I Am Right, You Are Wrong', 'authors': 'David A. Kelly, Akchunya Chanchal, Nathan Blake', 'link': 'https://arxiv.org/abs/2507.23509', 'abstract': "Machine learning for image classification is an active and rapidly developing field. With the proliferation of classifiers of different sizes and different architectures, the problem of choosing the right model becomes more and more important.\nWhile we can assess a model's classification accuracy statistically, our understanding of the way these models work is unfortunately limited. In order to gain insight into the decision-making process of different vision models, we propose using minimal sufficient pixels sets to gauge a model's `concentration': the pixels that capture the essence of an image through the lens of the model. By comparing position, overlap, and size of sets of pixels, we identify that different architectures have statistically different concentration, in both size and position. In particular, ConvNext and EVA models differ markedly from the others. We also identify that images which are misclassified are associated with larger pixels sets than correct classifications.", 'abstract_zh': '机器学习在图像分类领域的应用是一个活跃且快速发展的领域。随着不同大小和架构分类器的增多，选择合适的模型问题越来越重要。虽然我们可以从统计上评估模型的分类准确性，但对这些模型工作方式的理解是有限的。为了深入了解不同视觉模型的决策过程，我们提出使用最小充分像素集来衡量模型的“集中度”：即通过模型视角捕捉图像本质的像素集合。通过比较像素集的位置、重叠和大小，我们发现不同的架构在集中度上存在统计上的显著差异，尤其是在大小和位置上。特别是，ConvNext和EVA模型与其他模型有明显不同。我们还发现，误分类的图像与更大的像素集合相关，而正确分类的图像则与较小的像素集合相关。', 'title_zh': '我大你小；我对你说错'}
{'arxiv_id': 'arXiv:2507.23492', 'title': 'Digital literacy interventions can boost humans in discerning deepfakes', 'authors': 'Dominique Geissler, Claire Robertson, Stefan Feuerriegel', 'link': 'https://arxiv.org/abs/2507.23492', 'abstract': "Deepfakes, i.e., images generated by artificial intelligence (AI), can erode trust in institutions and compromise election outcomes, as people often struggle to discern real images from deepfakes. Improving digital literacy can help address these challenges, yet scalable and effective approaches remain largely unexplored. Here, we compare the efficacy of five digital literacy interventions to boost people's ability to discern deepfakes: (1) textual guidance on common indicators of deepfakes; (2) visual demonstrations of these indicators; (3) a gamified exercise for identifying deepfakes; (4) implicit learning through repeated exposure and feedback; and (5) explanations of how deepfakes are generated with the help of AI. We conducted an experiment with N=1,200 participants from the United States to test the immediate and long-term effectiveness of our interventions. Our results show that our interventions can boost deepfake discernment by up to 13 percentage points while maintaining trust in real images. Altogether, our approach is scalable, suitable for diverse populations, and highly effective for boosting deepfake detection while maintaining trust in truthful information.", 'abstract_zh': '深度假信息，即由人工智能生成的图像，可能会侵蚀机构的信任并损害选举结果，因为人们往往难以区分真实的图像与深度假信息。提高数字素养可以帮助应对这些挑战，但可扩展且有效的干预措施尚未得到充分探索。本文比较了五种数字素养干预措施的有效性，以提升人们辨别深度假信息的能力：（1）关于常见深度假信息指标的文本指导；（2）这些指标的视觉演示；（3）一种用于识别深度假信息的游戏化练习；（4）通过重复暴露和反馈进行的潜默学习；以及（5）利用人工智能解释深度假信息的生成方式。我们对来自美国的N=1,200名参与者进行了实验，以测试我们干预措施的即时效果和长期效果。我们的结果显示，我们的干预措施可以将深度假信息的识别能力提高多达13个百分点，同时保持对真实图像的信任。总之，我们的方法具有可扩展性，适合多元人群，并且在提高深度假信息检测能力的同时，能有效维护对真实信息的信任。', 'title_zh': '数字素养干预可以提升人类辨别深伪内容的能力'}
{'arxiv_id': 'arXiv:2507.23470', 'title': 'Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models', 'authors': 'Sebastian Gürtl, Gloria Schimetta, David Kerschbaumer, Michael Liut, Alexander Steinmaurer', 'link': 'https://arxiv.org/abs/2507.23470', 'abstract': 'UML and ER diagrams are foundational in computer science education but come with challenges for learners due to the need for abstract thinking, contextual understanding, and mastery of both syntax and semantics. These complexities are difficult to address through traditional teaching methods, which often struggle to provide scalable, personalized feedback, especially in large classes. We introduce DUET (Diagrammatic UML & ER Tutor), a prototype of an LLM-based tool, which converts a reference diagram and a student-submitted diagram into a textual representation and provides structured feedback based on the differences. It uses a multi-stage LLM pipeline to compare diagrams and generate reflective feedback. Furthermore, the tool enables analytical insights for educators, aiming to foster self-directed learning and inform instructional strategies. We evaluated DUET through semi-structured interviews with six participants, including two educators and four teaching assistants. They identified strengths such as accessibility, scalability, and learning support alongside limitations, including reliability and potential misuse. Participants also suggested potential improvements, such as bulk upload functionality and interactive clarification features. DUET presents a promising direction for integrating LLMs into modeling education and offers a foundation for future classroom integration and empirical evaluation.', 'abstract_zh': 'UML和ER图是计算机科学教育中的基础工具，但由于需要抽象思维、情境理解以及掌握语法规则和语义，给学习者带来了挑战。这些复杂性通过传统的教学方法难以解决，传统方法往往难以提供规模化的、个性化的反馈，尤其是在大型班级中。我们介绍了DUET（Diagrammatic UML & ER Tutor），这是一种基于LLM的原型工具，可以将参考图和学生提交的图转换为文本表示，并基于差异提供结构化反馈。它使用多阶段LLM管道来比较图并生成反思性反馈。此外，该工具为教育者提供了分析洞察，旨在促进自我导向学习并指导教学策略。我们通过六名参与者（包括两名教育者和四名助教）的半结构化访谈评估了DUET，他们指出了其优势，如易用性、可扩展性和学习支持，同时也提出了局限性，如可靠性及潜在的误用。参与者还建议了潜在的改进建议，如批量上传功能和交互式澄清功能。DUET为将LLM集成到建模教育中提供了一个有前景的方向，并为未来的课堂集成和实证评估奠定了基础。', 'title_zh': '使用大型语言模型自动评估学生生成的UML和ER图反馈'}
{'arxiv_id': 'arXiv:2507.23465', 'title': 'Role-Aware Language Models for Secure and Contextualized Access Control in Organizations', 'authors': 'Saeed Almheiri, Yerulan Kongrat, Adrian Santosh, Ruslan Tasmukhanov, Josemaria Vera, Muhammad Dehan Al Kautsar, Fajri Koto', 'link': 'https://arxiv.org/abs/2507.23465', 'abstract': 'As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts.', 'abstract_zh': '随着大规模语言模型（LLMs）在企业环境中的日益普及，基于用户角色控制模型行为成为一项基本要求。现有的安全方法通常假设统一访问，并专注于防止有害或有毒输出，而不考虑角色特定的访问约束。在本研究中，我们探讨是否可以对LLMs进行微调，使其生成反映不同组织角色相关访问权限的响应。我们探索了三种建模策略：基于BERT的分类器、基于LLM的分类器以及角色条件生成。为了评估这些方法，我们构建了两个互补的数据集。第一个数据集通过聚类和角色标签对现有指令微调语料库进行调整，而第二个数据集则是为了反映现实中的、具有角色敏感性的企业场景而合成生成的。我们评估了模型在不同组织结构下的性能，并分析了其对提示注入、角色不匹配和脱管攻击的鲁棒性。', 'title_zh': '面向角色的语言模型在组织中的安全与上下文化访问控制'}
{'arxiv_id': 'arXiv:2507.23461', 'title': 'Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection', 'authors': 'Taeheon Lim, Joohyung Lee, Kyungjae Lee, Jungchan Cho', 'link': 'https://arxiv.org/abs/2507.23461', 'abstract': "The Federated Learning (FL) approach enables effective learning across distributed systems, while preserving user data privacy. To date, research has primarily focused on addressing statistical heterogeneity and communication efficiency, through which FL has achieved success in classification tasks. However, its application to non-classification tasks, such as human pose estimation, remains underexplored. This paper identifies and investigates a critical issue termed ``resolution-drift,'' where performance degrades significantly due to resolution variability across clients. Unlike class-level heterogeneity, resolution drift highlights the importance of resolution as another axis of not independent or identically distributed (non-IID) data. To address this issue, we present resolution-adaptive federated learning (RAF), a method that leverages heatmap-based knowledge distillation. Through multi-resolution knowledge distillation between higher-resolution outputs (teachers) and lower-resolution outputs (students), our approach enhances resolution robustness without overfitting. Extensive experiments and theoretical analysis demonstrate that RAF not only effectively mitigates resolution drift and achieves significant performance improvements, but also can be integrated seamlessly into existing FL frameworks. Furthermore, although this paper focuses on human pose estimation, our t-SNE analysis reveals distinct characteristics between classification and high-resolution representation tasks, supporting the generalizability of RAF to other tasks that rely on preserving spatial detail.", 'abstract_zh': '联邦学习（FL）方法使跨分布式系统进行有效学习成为可能，同时保持用户数据隐私。截至目前，研究主要集中在通过解决统计异质性和通信效率来实现分类任务的成功。然而，其在非分类任务（如人体姿态估计）中的应用仍待探索。本论文识别并研究了一个关键问题，即“分辨率漂移”，由于客户端间分辨率的变化导致性能显著下降。不同于类别的异质性，分辨率漂移突显了分辨率作为另一个非独立同分布（non-IID）数据轴的重要性。为解决这一问题，我们提出了一种基于热力图的知识蒸馏方法，即适应性分辨率联邦学习（RAF），通过高分辨率输出（教师）与低分辨率输出（学生）之间的多分辨率知识蒸馏，增强了分辨率鲁棒性而不发生过拟合。 extensive实验和理论分析表明，RAF不仅有效缓解了分辨率漂移，显著提高了性能，还能无缝集成到现有的联邦学习框架中。此外，尽管本文主要关注人体姿态估计，但我们的t-SNE分析揭示了分类任务与高分辨率表示任务之间存在的差异特性，支持了RAF在其他依赖于保护断言细节的任务中的普适性。', 'title_zh': '缓解 federated learning 中的分辨率漂移：以关键点检测为例'}
{'arxiv_id': 'arXiv:2507.23459', 'title': 'KLAN: Kuaishou Landing-page Adaptive Navigator', 'authors': 'Fan Li, Chang Meng, Jiaqi Fu, Shuchang Liu, Jiashuo Zhang, Tianke Zhang, Xueliang Wang, Xiaoqiang Feng', 'link': 'https://arxiv.org/abs/2507.23459', 'abstract': "Modern online platforms configure multiple pages to accommodate diverse user needs. This multi-page architecture inherently establishes a two-stage interaction paradigm between the user and the platform: (1) Stage I: page navigation, navigating users to a specific page and (2) Stage II: in-page interaction, where users engage with customized content within the specific page. While the majority of research has been focusing on the sequential recommendation task that improves users' feedback in Stage II, there has been little investigation on how to achieve better page navigation in Stage I. To fill this gap, we formally define the task of Personalized Landing Page Modeling (PLPM) into the field of recommender systems: Given a user upon app entry, the goal of PLPM is to proactively select the most suitable landing page from a set of candidates (e.g., functional tabs, content channels, or aggregation pages) to optimize the short-term PDR metric and the long-term user engagement and satisfaction metrics, while adhering to industrial constraints. Additionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a hierarchical solution framework designed to provide personalized landing pages under the formulation of PLPM. KLAN comprises three key components: (1) KLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures intra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates both components for optimal navigation decisions. Extensive online experiments conducted on the Kuaishou platform demonstrate the effectiveness of KLAN, obtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and user Lifetime (LT). Our KLAN is ultimately deployed on the online platform at full traffic, serving hundreds of millions of users. To promote further research in this important area, we will release our dataset and code upon paper acceptance.", 'abstract_zh': '现代在线平台配置多个页面以满足多样化用户需求。这种多页面架构本质上确立了用户与平台之间两阶段的交互 paradigm：（1）第Ⅰ阶段：页面导航，将用户导向特定页面；（2）第Ⅱ阶段：页面内交互，用户在特定页面内与定制内容进行互动。尽管大多数研究集中于第Ⅱ阶段的序列推荐任务以改善用户的反馈，但第Ⅰ阶段的页面导航如何优化的问题却鲜有探讨。为填补这一空白，我们将个性化落地页建模（PLPM）任务正式引入推荐系统领域：在用户进入应用时，PLPM 的目标是从候选页面（如功能标签、内容频道或聚合页等）中主动选择最合适的落地页，以优化短期 PDR 指标，并长期增强用户参与度和满意度，同时遵守工业约束。此外，我们提出了一种层次化解决方案框架 KLAN（快手落地页自适应导航器），以在 PLPM 的范式下提供个性化落地页。KLAN 包含三个关键组件：（1）KLAN-ISP 捕获日间静态页面偏好；（2）KLAN-IIT 捕获日间动态兴趣转换；（3）KLAN-AM 融合两部分以进行最优导航决策。在快手平台进行的广泛在线实验表明，KLAN 的有效性，获得 Daily Active Users（DAU）和用户 Lifetime（LT）分别提高了 +0.205% 和 +0.192%。最终，KLAN 在线上平台全面部署，为数亿用户提供服务。为促进该重要领域的进一步研究，在论文被接受后，我们将发布我们的数据集和代码。', 'title_zh': 'KLAN: 快手着陆页自适应导航器'}
{'arxiv_id': 'arXiv:2507.23455', 'title': 'Machine learning and machine learned prediction in chest X-ray images', 'authors': 'Shereiff Garrett, Abhinav Adhikari, Sarina Gautam, DaShawn Marquis Morris, Chandra Mani Adhikari', 'link': 'https://arxiv.org/abs/2507.23455', 'abstract': 'Machine learning and artificial intelligence are fast-growing fields of research in which data is used to train algorithms, learn patterns, and make predictions. This approach helps to solve seemingly intricate problems with significant accuracy without explicit programming by recognizing complex relationships in data. Taking an example of 5824 chest X-ray images, we implement two machine learning algorithms, namely, a baseline convolutional neural network (CNN) and a DenseNet-121, and present our analysis in making machine-learned predictions in predicting patients with ailments. Both baseline CNN and DenseNet-121 perform very well in the binary classification problem presented in this work. Gradient-weighted class activation mapping shows that DenseNet-121 correctly focuses on essential parts of the input chest X-ray images in its decision-making more than the baseline CNN.', 'abstract_zh': '机器学习和人工智能是快速发展的研究领域，通过数据来训练算法、学习模式并进行预测。这种方法通过识别数据中的复杂关系，在无需显式编程的情况下，能够以显著的准确性解决看似复杂的问题。通过5824张胸部X光图像的例子，我们实现了两种机器学习算法，即基本卷积神经网络（CNN）和DenseNet-121，并在此工作中展示了在预测患者疾病方面的机器学习预测分析。基本CNN和DenseNet-121在本文呈现的二分类问题中表现都非常出色。梯度加权类激活映射显示，DenseNet-121在决策过程中更准确地聚焦于输入胸部X光图像的关键部分，远超基本CNN。', 'title_zh': '机器学习与胸部X光图像的机器学习预测'}
{'arxiv_id': 'arXiv:2507.23402', 'title': 'AGA: An adaptive group alignment framework for structured medical cross-modal representation learning', 'authors': 'Wei Li, Xun Gong, Jiao Li, Xiaobin Sun', 'link': 'https://arxiv.org/abs/2507.23402', 'abstract': 'Learning medical visual representations from paired images and reports is a promising direction in representation learning. However, current vision-language pretraining methods in the medical domain often simplify clinical reports into single entities or fragmented tokens, ignoring their inherent structure. In addition, contrastive learning frameworks typically depend on large quantities of hard negative samples, which is impractical for small-scale medical datasets. To tackle these challenges, we propose Adaptive Grouped Alignment (AGA), a new framework that captures structured semantics from paired medical images and reports. AGA introduces a bidirectional grouping mechanism based on a sparse similarity matrix. For each image-report pair, we compute fine-grained similarities between text tokens and image patches. Each token selects its top-matching patches to form a visual group, and each patch selects its most related tokens to form a language group. To enable adaptive grouping, we design two threshold gating modules, called Language Grouped Threshold Gate and Vision Grouped Threshold Gate, which learn grouping thresholds dynamically. Group representations are computed as weighted averages based on similarity scores. To align each token with its group representation, we introduce an Instance Aware Group Alignment loss that operates within each image-text pair, removing the need for external negatives. Finally, a Bidirectional Cross-modal Grouped Alignment module is applied to enhance fine-grained alignment between visual and linguistic group representations. Extensive experiments on public and private datasets show that our method achieves strong performance on image-text retrieval and classification tasks under both fine-tuning and zero-shot settings.', 'abstract_zh': '基于配对图像和报告学习医学视觉表示是一种有前景的表示学习方向。然而，当前医学领域的视觉-语言预训练方法常常将临床报告简化为单个实体或碎片化标记，忽视了其固有的结构。此外，对比学习框架通常依赖大量困难的负样本，这对小型医学数据集而言不切实际。为应对这些挑战，我们提出了一种新的框架Adaptive Grouped Alignment (AGA)，用于从配对的医学图像和报告中捕捉结构化的语义。AGA引入了一种基于稀疏相似矩阵的双向分组机制。对于每张图像-报告配对，我们计算文本标记和图像 Patch 之间的细致相似性。每个标记选择与其最匹配的前m个 Patch 组成视觉分组，每个 Patch 选择与其最相关的标记组成语言分组。为了实现分组的自适应性，我们设计了两个阈值门控模块，分别称为语言分组阈值门和视觉分组阈值门，这些模块能够动态学习分组阈值。组表示通过相似性分数加权平均计算。为了使每个标记与其组表示对齐，我们引入了一种基于实例意识的组对齐损失，该损失在每张图像-文本配对内操作，无需外部负样本。最后，应用双向跨模态组对齐模块以增强视觉和语义组表示之间的细致对齐。在公共和私有数据集上的广泛实验表明，我们的方法在细调和零样本设置下的图像-文本检索和分类任务中均表现出强性能。', 'title_zh': 'AGA：一种自适应组对齐框架用于结构化医学跨模态表示学习'}
{'arxiv_id': 'arXiv:2507.23386', 'title': 'Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models', 'authors': 'Ailiang Lin, Zhuoyun Li, Kotaro Funakoshi', 'link': 'https://arxiv.org/abs/2507.23386', 'abstract': "Decoder-only large language models (LLMs) are increasingly used to build embedding models that effectively encode the semantic information of natural language texts into dense vector representations for various embedding tasks. However, many existing methods primarily focus on removing the causal attention mask in LLMs to enable bidirectional attention, potentially undermining the model's ability to extract semantic information acquired during pretraining. Additionally, leading unidirectional approaches often rely on extra input text to overcome the inherent limitations of causal attention, inevitably increasing computational costs. In this work, we propose Causal2Vec, a general-purpose embedding model tailored to enhance the performance of decoder-only LLMs without altering their original architectures or introducing significant computational overhead. Specifically, we first employ a lightweight BERT-style model to pre-encode the input text into a single Contextual token, which is then prepended to the LLM's input sequence, allowing each token to capture contextualized information even without attending to future tokens. Furthermore, to mitigate the recency bias introduced by last-token pooling and help LLMs better leverage the semantic information encoded in the Contextual token, we concatenate the last hidden states of Contextual and EOS tokens as the final text embedding. In practice, Causal2Vec achieves state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB) among models trained solely on publicly available retrieval datasets, while reducing the required sequence length by up to 85% and inference time by up to 82% compared to best-performing methods.", 'abstract_zh': '仅解码大型语言模型（LLMs）越来越多地用于构建嵌入模型，有效将自然语言文本的语义信息编码为密集向量表示，以满足各种嵌入任务的需求。然而，许多现有方法主要集中在消除LLMs中的因果注意力掩码以实现双向注意力，这可能会削弱模型提取预训练过程中获得的语义信息的能力。此外，领先的单向方法通常依赖额外的输入文本以克服因果注意力的固有局限性，不可避免地增加了计算成本。在本工作中，我们提出了Causal2Vec，这是一种通用的嵌入模型，旨在不改变原始架构或引入显著的计算负担的情况下增强仅解码LLMs的性能。具体而言，我们首先使用一种轻量级的BERT风格模型对输入文本进行预编码，得到一个Contextual词元，然后将其添加到LLM的输入序列之前，使每个词元即使不关注后续词元也能捕获上下文信息。此外，为了减轻由最后词元池化引入的近期偏见，并帮助LLMs更好地利用嵌入在Contextual词元中的语义信息，我们将Contextual词元和EOS词元的最后隐藏状态连接起来作为最终的文本嵌入。实践表明，Causal2Vec在仅基于公开检索数据集训练的模型中，在大规模文本嵌入基准测试（MTEB）上达到了最佳性能，同时将所需序列长度减少了85%，推断时间减少了82%。', 'title_zh': '因果2Vec：提升作为通用嵌入模型的解码器唯一大语言模型性能'}
{'arxiv_id': 'arXiv:2507.23382', 'title': 'MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models', 'authors': 'Yiyan Ji, Haoran Chen, Qiguang Chen, Chengyue Wu, Libo Qin, Wanxiang Che', 'link': 'https://arxiv.org/abs/2507.23382', 'abstract': "Multimodal planning capabilities refer to the ability to predict, reason, and design steps for task execution with multimodal context, which is essential for complex reasoning and decision-making across multiple steps. However, current benchmarks face two key challenges: (1) they cannot directly assess multimodal real-world planning capabilities, and (2) they lack constraints or implicit constraints across modalities. To address these issues, we introduce Multimodal Planning with Complex Constraints (MPCC), the first benchmark to systematically evaluate MLLMs' ability to handle multimodal constraints in planning. To address the first challenge, MPCC focuses on three real-world tasks: Flight Planning, Calendar Planning, and Meeting Planning. To solve the second challenge, we introduce complex constraints (e.g. budget, temporal, and spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to separate constraint complexity from search space expansion. Experiments on 13 advanced MLLMs reveal significant challenges: closed-source models achieve only 21.3% feasible plans, while open-source models average below 11%. Additionally, we observe that MLLMs are highly sensitive to constraint complexity and that traditional multimodal prompting strategies fail in multi-constraint scenarios. Our work formalizes multimodal constraints in planning, provides a rigorous evaluation framework, and highlights the need for advancements in constraint-aware reasoning for real-world MLLM applications.", 'abstract_zh': '多模态规划能力包含在多模态上下文中预测、推理和设计任务执行步骤的能力，这对于在多个步骤中进行复杂推理和决策至关重要。然而，当前的基准面临两个关键挑战：（1）它们无法直接评估多模态实际世界的规划能力；（2）它们缺乏跨模态的约束或隐含约束。为了应对这些挑战，我们引入了多模态复杂约束规划（MPCC），这是第一个系统评估MLLMs处理规划中多模态约束能力的基准。为了应对第一个挑战，MPCC集中于三个实际任务：飞行规划、日历规划和会议规划。为了应对第二个挑战，我们在这三项任务中引入了复杂的约束（例如，预算、时间、空间约束），并引入了分级难度级别（EASY、MEDIUM、HARD），以区分约束复杂性和搜索空间的扩展。在13个先进MLLM上的实验揭示了重大挑战：闭源模型只能实现21.3%可行计划，而开源模型平均值低于11%。此外，我们观察到，MLLMs对约束复杂性非常敏感，传统的多模态提示策略在多约束场景中失效。我们的工作在规划中正式化了多模态约束，提供了一个严格的评估框架，并强调了在实际MLLM应用中对约束感知推理的发展需求。', 'title_zh': 'MPCC：多模态复杂约束规划的新型基准模型'}
{'arxiv_id': 'arXiv:2507.23370', 'title': 'Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling', 'authors': 'Trae Research Team, Pengfei Gao, Zhao Tian, Xiangxin Meng, Xinchen Wang, Ruida Hu, Yuanan Xiao, Yizhou Liu, Zhao Zhang, Junjie Chen, Cuiyun Gao, Yun Lin, Yingfei Xiong, Chao Peng, Xia Liu', 'link': 'https://arxiv.org/abs/2507.23370', 'abstract': 'Software issue resolution is a critical challenge in software engineering and has garnered increasing attention in recent years. With the rapid advancement of large language models (LLMs), substantial progress has been made in addressing real-world software engineering tasks. Recent studies have introduced ensemble reasoning techniques to enhance the performance of LLM-based issue resolution. However, existing prompting-based methods still face limitations in effectively exploring large ensemble spaces and lack the capacity for repository-level understanding, both of which constrain their overall effectiveness. In this paper, we propose Trae Agent, the first agent-based ensemble reasoning approach for repository-level issue resolution. Trae Agent formulates our goal as an optimal solution search problem and addresses two key challenges, i.e., large ensemble spaces and repository-level understanding, through modular agents for generation, pruning, and selection. We conduct extensive experiments using three leading LLMs on the widely-adopted SWE-bench benchmark, comparing Trae Agent against four state-of-the-art ensemble reasoning techniques. Experimental results demonstrate that Trae Agent consistently achieves superior performance, with an average improvement of 10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of 75.20%. We are pleased to release Trae Agent as an open-source project to support the research community, with all resources available at this https URL.', 'abstract_zh': '软件问题解决是软件工程中的关键挑战，近年来引起了越来越多的关注。随着大型语言模型（LLMs）的迅速发展，已在应对实际软件工程任务方面取得了显著进展。近年来的研究引入了集成推理技术以增强基于LLM的问题解决性能。然而，现有的基于提示的方法在有效地探索大型集成空间以及缺乏仓库级理解方面仍存在局限性，这些限制了它们的整体有效性。在本文中，我们提出了Trae Agent，这是第一个基于代理的仓库级问题解决集成推理方法。Trae Agent将我们的目标形式化为最优解搜索问题，并通过生成、裁剪和选择模块化代理来解决两个关键挑战，即大型集成空间和仓库级理解。我们在广泛采用的SWE-bench基准上使用三种领先的LLM进行了广泛实验，将Trae Agent与四种最先进的集成推理技术进行比较。实验结果表明，Trae Agent在Pass@1指标上始终保持 superiority，相较于所有基线平均提升10.22%。 Trae Agent在SWE-bench Verified排行榜上位居第一，Pass@1得分为75.20%。我们很高兴将Trae Agent作为开源项目发布，所有资源可访问此处 https://。', 'title_zh': 'Trae代理：一种基于LLM的软件工程代理，具备测试时扩展能力'}
{'arxiv_id': 'arXiv:2507.23365', 'title': '"I made this (sort of)": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation', 'authors': 'Bob L. T. Sturm', 'link': 'https://arxiv.org/abs/2507.23365', 'abstract': "I reflect on my experience creating two music albums centered on state-of-the-art prompt-based AI music generation platforms. The first album explicitly poses the question: What happens when I collide my junk mail with these platforms? The second album is a direct response to the first, and toys with the inability of state-of-the-art prompt-based AI music generation platforms to generate music that is not ``practiced'', ``polished'', and ``produced''. I seed a large language model (LLM) with information about these albums and have it interview me, which results in the exploration of several deeper questions: To what extent am I the author? Where am I in the resulting music? How is my musical identity changing as I am faced with machines that are in some ways far more talented than I? What new musical spaces does my work open, for me or anyone/thing else? I conclude by reflecting on my reflections, as well as LLM-mediated self-reflection as method.", 'abstract_zh': '我反思了自己创作两张以最先进的提示驱动AI音乐生成平台为中心的音乐专辑的经历。第一张专辑明确提出了一个问题：当我把垃圾邮件与这些平台相碰撞会发生什么呢？第二张专辑是对第一张专辑的直接回应，并探讨了最先进的提示驱动AI音乐生成平台无法生成非“练习过”、“润色过”和“制作过”的音乐的事实。我将一个大型语言模型（LLM）种子信息关于这些专辑，并让它采访我，结果引发了以下几个深层次的问题：我在多大程度上是作者？我的音乐在最终形成的音乐中处于怎样的位置？随着面对某些方面比我更有才华的机器，我的音乐身份发生了怎样的变化？我的作品开启了哪些新的音乐空间，对我来说或是对其他人/其他事物？最后，我反思了自己的反思，以及通过LLM中介的自我反思作为一种方法。', 'title_zh': '“我就是这样（某种程度上）做的”：基于提示的AI音乐生成中的作者身份协商、应对欺骗性和探索新的音乐空间'}
{'arxiv_id': 'arXiv:2507.23358', 'title': 'Text-to-SQL Task-oriented Dialogue Ontology Construction', 'authors': 'Renato Vukovic, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Hsien-Chin Lin, Shutong Feng, Nurul Lubis, Milica Gasic', 'link': 'https://arxiv.org/abs/2507.23358', 'abstract': 'Large language models (LLMs) are widely used as general-purpose knowledge sources, but they rely on parametric knowledge, limiting explainability and trustworthiness. In task-oriented dialogue (TOD) systems, this separation is explicit, using an external database structured by an explicit ontology to ensure explainability and controllability. However, building such ontologies requires manual labels or supervised training. We introduce TeQoDO: a Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM autonomously builds a TOD ontology from scratch without supervision using its inherent SQL programming capabilities combined with dialogue theory provided in the prompt. We show that TeQoDO outperforms transfer learning approaches, and its constructed ontology is competitive on a downstream dialogue state tracking task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also scales to allow construction of much larger ontologies, which we investigate on a Wikipedia and ArXiv dataset. We view this as a step towards broader application of ontologies to increase LLM explainability.', 'abstract_zh': '大型语言模型（LLMs）广泛用作通用知识来源，但它们依赖于参数化知识，限制了可解释性和可信度。在任务导向对话（TOD）系统中，这种分离是明确的，通过使用由显式本体结构化的外部数据库来确保可解释性和可控性。然而，构建这样的本体需要手动标签或监督训练。我们介绍了一种TeQoDO：基于文本到SQL的任务导向对话本体构建方法。在此方法中，LLM利用其固有的SQL编程能力和提示提供的对话理论，在无监督的情况下从头开始自主构建TOD本体。我们证明TeQoDO优于迁移学习方法，并且其构建的本体在下游对话状态跟踪任务上具有竞争力。消融研究证明了对话理论的关键作用。TeQoDO还可以扩展以允许构建更大的本体，我们对此在维基百科和ArXiv数据集上进行了研究。我们认为这是朝着更广泛地应用本体以提高LLM可解释性迈出的一步。', 'title_zh': '文本到SQL任务导向对话本体构建'}
{'arxiv_id': 'arXiv:2507.23356', 'title': 'Quality Evaluation of COBOL to Java Code Transformation', 'authors': 'Shmulik Froimovich, Raviv Gal, Wesam Ibraheem, Avi Ziv', 'link': 'https://arxiv.org/abs/2507.23356', 'abstract': "We present an automated evaluation system for assessing COBOL-to-Java code translation within IBM's watsonx Code Assistant for Z (WCA4Z). The system addresses key challenges in evaluating LLM-based translators, including model opacity and the complexity of translation quality assessment. Our approach combines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver scalable, multi-faceted evaluations. The system supports continuous integration workflows, enables large-scale benchmarking, and reduces reliance on manual review. We describe the system architecture, evaluation strategies, and reporting mechanisms that provide actionable insights for developers and project managers, facilitating the evolution of high-quality, modernized codebases.", 'abstract_zh': '我们提出了一种自动评估系统，用于评估IBM Watsonx Code Assistant for Z (WCA4Z) 中的COBOL-to-Java 代码转换。该系统解决了一些关键挑战，包括模型不透明性和翻译质量评估的复杂性。我们的方法结合了分析检查器和LLM-as-a-judge (LaaJ) 技术，以实现可扩展性和多维度的评估。该系统支持持续集成工作流，允许大规模基准测试，并减少对人工审查的依赖。我们描述了该系统的架构、评估策略和报告机制，为开发人员和项目管理人员提供了可操作的见解，促进了高质量现代化代码库的发展。', 'title_zh': 'COBOL到Java代码转换的质量评估'}
{'arxiv_id': 'arXiv:2507.23350', 'title': 'Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications', 'authors': 'Mahmoud Ghorab, Matthias Lorenzen', 'link': 'https://arxiv.org/abs/2507.23350', 'abstract': "There is a growing demand for autonomous mobile robots capable of navigating unstructured agricultural environments. Tasks such as weed control in meadows require efficient path planning through an unordered set of coordinates while minimizing travel distance and adhering to curvature constraints to prevent soil damage and protect vegetation. This paper presents an integrated navigation framework combining a global path planner based on the Dubins Traveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control (NMPC) strategy for local path planning and control. The DTSP generates a minimum-length, curvature-constrained path that efficiently visits all targets, while the NMPC leverages this path to compute control signals to accurately reach each waypoint. The system's performance was validated through comparative simulation analysis on real-world field datasets, demonstrating that the coupled DTSP-based planner produced smoother and shorter paths, with a reduction of about 16% in the provided scenario, compared to decoupled methods. Based thereon, the NMPC controller effectively steered the robot to the desired waypoints, while locally optimizing the trajectory and ensuring adherence to constraints. These findings demonstrate the potential of the proposed framework for efficient autonomous navigation in agricultural environments.", 'abstract_zh': '自主移动机器人在未结构化农业环境中的导航需求不断增加。草地杂草控制等任务需要有效地在无序坐标集合中规划路径，同时最小化行程距离并遵循曲率约束，以防止土壤损坏和保护植被。本文提出了一种结合基于Dubins巡回售货员问题（DTSP）的全局路径规划器和非线性模型预测控制（NMPC）策略的集成导航框架。DTSP生成一条既高效又满足曲率约束的最短路径，而NMPC利用这条路径计算控制信号，以准确到达每个航点。通过在实际田野数据集上进行比较仿真分析，验证了该系统性能，结果显示耦合的基于DTSP的规划器生成了更平滑和更短的路径，与分离方法相比，在给定场景中路径长度减少了约16%。基于此，NMPC控制器有效地引导机器人到达所需航点，同时局部优化轨迹并确保满足约束。这些发现证明了所提框架在农业环境中的高效自主导航潜力。', 'title_zh': '非完整移动机器人在农业应用中的多航点路径规划与运动控制'}
{'arxiv_id': 'arXiv:2507.23334', 'title': 'MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation', 'authors': 'Daeyong Kwon, SeungHeon Doh, Juhan Nam', 'link': 'https://arxiv.org/abs/2507.23334', 'abstract': "Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）已在多个领域展示了 remarkable 能力。尽管它们在各种任务上表现出强大的零样本性能，但由于训练数据中音乐特定知识的比例相对较小，LLMs 在音乐相关应用中的效果仍有限。为解决这一局限，我们提出了一种基于检索增强生成（RAG）的全面框架 MusT-RAG，以将通用语言模型适应于仅文本音乐问答（MQA）任务。RAG 是一种技术，通过在生成答案时检索相关上下文信息来为语言模型提供外部知识。为了优化 RAG 以适应音乐领域，我们（1）提出了一种专门为检索阶段设计的音乐专项向量数据库 MusWikiDB，（2）并在推理和微调过程中利用上下文信息，有效地将通用语言模型转变为音乐特定模型。我们的实验表明，MusT-RAG 显著优于传统的微调方法，在提升语言模型的音乐领域适应能力方面显示出一致的改进，不仅在领域内，还在领域外的 MQA 测量基准测试中。此外，我们证明 MusWikiDB 相较于通用维基百科语料库更为有效，提供更好的性能和计算效率。', 'title_zh': 'MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation'}
{'arxiv_id': 'arXiv:2507.23318', 'title': 'FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning', 'authors': 'Jiajun Cao, Qizhe Zhang, Peidong Jia, Xuhui Zhao, Bo Lan, Xiaoan Zhang, Xiaobao Wei, Sixiang Chen, Zhuo Li, Yang Wang, Liyun Li, Xianming Liu, Ming Lu, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2507.23318', 'abstract': 'Vision-Language-Action (VLA) models have demonstrated significant potential in complex scene understanding and action reasoning, leading to their increasing adoption in end-to-end autonomous driving systems. However, the long visual tokens of VLA models greatly increase computational costs. Current visual token pruning methods in Vision-Language Models (VLM) rely on either visual token similarity or visual-text attention, but both have shown poor performance in autonomous driving scenarios. Given that human drivers concentrate on relevant foreground areas while driving, we assert that retaining visual tokens containing this foreground information is essential for effective decision-making. Inspired by this, we propose FastDriveVLA, a novel reconstruction-based vision token pruning framework designed specifically for autonomous driving. FastDriveVLA includes a plug-and-play visual token pruner called ReconPruner, which prioritizes foreground information through MAE-style pixel reconstruction. A novel adversarial foreground-background reconstruction strategy is designed to train ReconPruner for the visual encoder of VLA models. Once trained, ReconPruner can be seamlessly applied to different VLA models with the same visual encoder without retraining. To train ReconPruner, we also introduce a large-scale dataset called nuScenes-FG, consisting of 241K image-mask pairs with annotated foreground regions. Our approach achieves state-of-the-art results on the nuScenes closed-loop planning benchmark across different pruning ratios.', 'abstract_zh': '基于视觉-语言-动作的快速决策驱动框架FastDriveVLA', 'title_zh': 'FastDriveVLA: 高效端到端驾驶通过即插即用重建基础上的令牌剪枝'}
{'arxiv_id': 'arXiv:2507.23315', 'title': 'Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification', 'authors': 'Vineet Kumar Rakesh, Soumya Mazumdar, Tapas Samanta, Sarbajit Pal, Amitabha Das', 'link': 'https://arxiv.org/abs/2507.23315', 'abstract': 'Lightweight convolutional and transformer-based models have become vital for real-time image classification in resource-constrained applications, such as embedded systems and edge devices. This work analyzes the influence of hyperparameter adjustment on the accuracy and convergence behavior of seven efficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT v2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are trained on the ImageNet-1K dataset under consistent training settings, with an emphasis on real-time practicality. An comprehensive ablation study is undertaken to separate the effect of critical hyperparameters, including learning rate schedules, batch sizes, input resolution, data augmentation, regularization approaches, and optimizer choice. To assess appropriateness for real-time applications, each model is assessed not only in terms of Top-1 and Top-5 classification accuracy, but also in terms of inference time, parameter count, model size, and frames-per-second (FPS) on a GPU-accelerated edge deployment simulation. Results demonstrate that cosine learning rate decay and adjustable batch size may greatly boost both accuracy and convergence speed, while keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80% Top-1 accuracy with efficient inference performance, offering a compelling balance between accuracy and deployment cost for VGG-style models. The results give practical guidance for constructing resource-efficient deep learning models appropriate for real-time image processing pipelines. All code and training logs are publicly accessible at this https URL.', 'abstract_zh': '轻量级的卷积和变压器模型已成为嵌入式系统和边缘设备等资源受限应用中实时图像分类的关键。本研究分析了超参数调整对七种高效的深度学习架构（EfficientNetV2-S、ConvNeXt-T、MobileViT v2 (XXS/XS/S)、MobileNetV3-L、TinyViT-21M、RepVGG-A2）准确性和收敛行为的影响。所有模型均在一致的训练设置下使用ImageNet-1K数据集进行训练，并强调实时实用性。进行了一项全面的消融研究，以分离关键超参数（包括学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择）的效果。为了评估其适用于实时应用的适宜性，每个模型不仅从Top-1和Top-5分类准确性，还从推理时间、参数量、模型大小和每秒帧数（FPS）的角度在GPU加速的边缘部署仿真中进行了评估。结果显示，余弦衰减学习率和可调批量大小可以显著提高准确性和收敛速度，同时保持低延迟和低成本。值得注意的是，RepVGG-A2在高效推理性能下实现了超过80%的Top-1准确率，为VGG风格的模型提供了准确性和部署成本之间具有竞争力的平衡。结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。所有代码和训练日志均可在该网址访问。', 'title_zh': '轻量级深度学习模型实时图像分类精度的超参数优化影响研究'}
{'arxiv_id': 'arXiv:2507.23291', 'title': 'Evaluating the Dynamics of Membership Privacy in Deep Learning', 'authors': 'Yuetian Chen, Zhiqi Wang, Nathalie Baracaldo, Swanand Ravindra Kadhe, Lei Yu', 'link': 'https://arxiv.org/abs/2507.23291', 'abstract': "Membership inference attacks (MIAs) pose a critical threat to the privacy of training data in deep learning. Despite significant progress in attack methodologies, our understanding of when and how models encode membership information during training remains limited. This paper presents a dynamic analytical framework for dissecting and quantifying privacy leakage dynamics at the individual sample level. By tracking per-sample vulnerabilities on an FPR-TPR plane throughout training, our framework systematically measures how factors such as dataset complexity, model architecture, and optimizer choice influence the rate and severity at which samples become vulnerable. Crucially, we discover a robust correlation between a sample's intrinsic learning difficulty, and find that the privacy risk of samples highly vulnerable in the final trained model is largely determined early during training. Our results thus provide a deeper understanding of how privacy risks dynamically emerge during training, laying the groundwork for proactive, privacy-aware model training strategies.", 'abstract_zh': '成员推断攻击（MIAs）对深度学习训练数据的隐私构成了关键威胁。尽管在攻击方法学上取得了显著进展，但对我们理解模型在训练过程中如何编码成员信息的时间和方式仍然了解有限。本文提出了一种动态分析框架，用于在个体样本层面剖析和量化隐私泄露动态。通过在整个训练过程中在FPR-TPR平面上跟踪每个样本的脆弱性，我们的框架系统地测量了数据集复杂性、模型架构和优化器选择等因素如何影响样本脆弱性的发生速率和严重程度。 crucially，我们发现样本固有的学习难度之间存在稳健的相关性，并发现在最终训练模型中高度脆弱的样本的隐私风险主要在训练早期被确定。因此，我们的结果提供了对隐私风险如何动态出现期间的更深入理解，为前瞻性的、隐私意识的模型训练策略奠定了基础。', 'title_zh': '评估深度学习中成员隐私的动力学过程'}
{'arxiv_id': 'arXiv:2507.23272', 'title': 'Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2', 'authors': 'Solha Kang, Eugene Kim, Joris Vankerschaver, Utku Ozbulak', 'link': 'https://arxiv.org/abs/2507.23272', 'abstract': 'Breast MRI provides high-resolution volumetric imaging critical for tumor assessment and treatment planning, yet manual interpretation of 3D scans remains labor-intensive and subjective. While AI-powered tools hold promise for accelerating medical image analysis, adoption of commercial medical AI products remains limited in low- and middle-income countries due to high license costs, proprietary software, and infrastructure demands. In this work, we investigate whether the Segment Anything Model 2 (SAM2) can be adapted for low-cost, minimal-input 3D tumor segmentation in breast MRI. Using a single bounding box annotation on one slice, we propagate segmentation predictions across the 3D volume using three different slice-wise tracking strategies: top-to-bottom, bottom-to-top, and center-outward. We evaluate these strategies across a large cohort of patients and find that center-outward propagation yields the most consistent and accurate segmentations. Despite being a zero-shot model not trained for volumetric medical data, SAM2 achieves strong segmentation performance under minimal supervision. We further analyze how segmentation performance relates to tumor size, location, and shape, identifying key failure modes. Our results suggest that general-purpose foundation models such as SAM2 can support 3D medical image analysis with minimal supervision, offering an accessible and affordable alternative for resource-constrained settings.', 'abstract_zh': 'Segment Anything Model 2 (SAM2) 适用于低剂量输入的低成本三维肿瘤分割在乳腺MRI中的应用探究', 'title_zh': '基于SAM2的可负担的3D乳腺MRI肿瘤分割与可视化研究'}
{'arxiv_id': 'arXiv:2507.23269', 'title': 'XABPs: Towards eXplainable Autonomous Business Processes', 'authors': 'Peter Fettke, Fabiana Fournier, Lior Limonad, Andreas Metzger, Stefanie Rinderle-Ma, Barbara Weber', 'link': 'https://arxiv.org/abs/2507.23269', 'abstract': 'Autonomous business processes (ABPs), i.e., self-executing workflows leveraging AI/ML, have the potential to improve operational efficiency, reduce errors, lower costs, improve response times, and free human workers for more strategic and creative work. However, ABPs may raise specific concerns including decreased stakeholder trust, difficulties in debugging, hindered accountability, risk of bias, and issues with regulatory compliance. We argue for eXplainable ABPs (XABPs) to address these concerns by enabling systems to articulate their rationale. The paper outlines a systematic approach to XABPs, characterizing their forms, structuring explainability, and identifying key BPM research challenges towards XABPs.', 'abstract_zh': '自主业务流程（ABPs），即利用AI/ML自我执行的工作流，有潜力提高运营效率、减少错误、降低费用、缩短响应时间，并释放人力进行更具战略性和创造性的工作。然而，ABPs可能会引发特定的担忧，包括减少相关方信任、调试困难、责任缺失、偏见风险以及合规性问题。本文主张采用可解释的自主业务流程（XABPs）来应对这些担忧，通过使系统能够阐述其决策原因。论文概述了XABPs的系统性方法，描述了其形式、结构化解释性，并指出了通向XABPs的关键BPM研究挑战。', 'title_zh': 'XABPs: 向可解释的自主业务过程迈进'}
{'arxiv_id': 'arXiv:2507.23261', 'title': 'DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System', 'authors': 'Hui Yi Leong, Yuqing Wu', 'link': 'https://arxiv.org/abs/2507.23261', 'abstract': 'Current multi-agent systems (MAS) frameworks often rely on manually designed and static collaboration graph structures, limiting adaptability and performance. To address these limitations, we propose DynaSwarm, a dynamic framework that enhances LLM-based MAS through two key innovations: (1) an actor-critic reinforcement learning (A2C) mechanism to optimize graph structures with improved stability over prior RL methods, and (2) a dynamic graph selector that adaptively chooses the optimal graph structure for each input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the need for rigid, one-fits-all graph architectures, instead leveraging sample-specific idiosyncrasies to dynamically route queries through specialized agent networks. (c) We propose to fine-tune the demonstration retriever to fully exploit the power of in-context learning (ICL). Extensive experiments on question answering, mathematical reasoning, and coding tasks demonstrate that DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones. Our findings highlight the importance of sample-aware structural flexibility in LLM MAS designs.', 'abstract_zh': '当前的多Agent系统（MAS）框架往往依赖于手工设计且静态的协作图结构，限制了系统的适应性和性能。为了解决这些问题，我们提出DynaSwarm，这是一个通过两种关键创新增强基于LLM的MAS的动态框架：（1）一种改进的演员-评论家强化学习（A2C）机制，用于优化图结构，比之前的强化学习方法更具稳定性；（2）一个动态图选择器，通过参数高效的LLM微调，能够根据每个输入样本自适应地选择最优图结构。DynaSwarm消除了 rigid、one-fits-all 图架构的需要，而是利用样本特定的特性，动态地将查询路由到专门的Agent网络中。（c）我们提出微调示例检索器，以充分利用上下文学习（ICL）的力量。在问答、数学推理和编码任务上的广泛实验表明，DynaSwarm在多个LLM微调框架上始终优于最先进的单Agent和MAS基线系统。我们的研究结果强调了LLM MAS设计中样本感知结构灵活性的重要性。', 'title_zh': 'DynaSwarm：基于LLM的多agent系统动态图结构选择'}
{'arxiv_id': 'arXiv:2507.23257', 'title': 'Efficient Machine Unlearning via Influence Approximation', 'authors': 'Jiawei Liu, Chenwang Wu, Defu Lian, Enhong Chen', 'link': 'https://arxiv.org/abs/2507.23257', 'abstract': 'Due to growing privacy concerns, machine unlearning, which aims at enabling machine learning models to ``forget" specific training data, has received increasing attention. Among existing methods, influence-based unlearning has emerged as a prominent approach due to its ability to estimate the impact of individual training samples on model parameters without retraining. However, this approach suffers from prohibitive computational overhead arising from the necessity to compute the Hessian matrix and its inverse across all training samples and parameters, rendering it impractical for large-scale models and scenarios involving frequent data deletion requests. This highlights the difficulty of forgetting. Inspired by cognitive science, which suggests that memorizing is easier than forgetting, this paper establishes a theoretical link between memorizing (incremental learning) and forgetting (unlearning). This connection allows machine unlearning to be addressed from the perspective of incremental learning. Unlike the time-consuming Hessian computations in unlearning (forgetting), incremental learning (memorizing) typically relies on more efficient gradient optimization, which supports the aforementioned cognitive theory. Based on this connection, we introduce the Influence Approximation Unlearning (IAU) algorithm for efficient machine unlearning from the incremental perspective. Extensive empirical evaluations demonstrate that IAU achieves a superior balance among removal guarantee, unlearning efficiency, and comparable model utility, while outperforming state-of-the-art methods across diverse datasets and model architectures. Our code is available at this https URL.', 'abstract_zh': '由于日益增长的隐私担忧，旨在使机器学习模型“忘记”特定训练数据的机器卸载受到了越来越多的关注。在现有方法中，基于影响的卸载由于能够估计每个训练样本对模型参数的影响而无需重新训练，从而脱颖而出。然而，这种方法由于需要计算所有训练样本和参数的海森矩阵及其逆矩阵而导致巨大的计算开销，使其在大规模模型和频繁的数据删除请求场景中不切实际。这凸显了忘记的难度。受认知科学的启发，认知科学表明记忆比忘记更容易，本文从增量学习的角度建立了记忆（增量学习）与遗忘（卸载）之间的理论联系。这一联系使得机器卸载可以从增量学习的角度进行研究。与卸载（忘记）过程中耗时的海森矩阵计算不同，增量学习（记忆）通常依赖于更高效的梯度优化，这支持了上述认知理论。基于此联系，我们提出了基于增量视角的近似影响卸载（IAU）算法，以高效地实现机器卸载。广泛的实证评估表明，IAU在删除保证、卸载效率和模型实用性方面均表现出优越的平衡，同时在多个数据集和模型架构上优于现有最佳方法。我们的代码可在以下链接获取。', 'title_zh': '通过影响逼近实现高效的机器遗忘'}
{'arxiv_id': 'arXiv:2507.23218', 'title': 'An Information Bottleneck Asset Pricing Model', 'authors': 'Che Sun', 'link': 'https://arxiv.org/abs/2507.23218', 'abstract': 'Deep neural networks (DNNs) have garnered significant attention in financial asset pricing, due to their strong capacity for modeling complex nonlinear relationships within financial data. However, sophisticated models are prone to over-fitting to the noise information in financial data, resulting in inferior performance. To address this issue, we propose an information bottleneck asset pricing model that compresses data with low signal-to-noise ratios to eliminate redundant information and retain the critical information for asset pricing. Our model imposes constraints of mutual information during the nonlinear mapping process. Specifically, we progressively reduce the mutual information between the input data and the compressed representation while increasing the mutual information between the compressed representation and the output prediction. The design ensures that irrelevant information, which is essentially the noise in the data, is forgotten during the modeling of financial nonlinear relationships without affecting the final asset pricing. By leveraging the constraints of the Information bottleneck, our model not only harnesses the nonlinear modeling capabilities of deep networks to capture the intricate relationships within financial data but also ensures that noise information is filtered out during the information compression process.', 'abstract_zh': '深度神经网络（DNNs）在金融资产定价中由于其在建模金融数据中的复杂非线性关系方面的强大能力而引起了广泛关注。然而，复杂的模型容易过度拟合金融数据中的噪声信息，导致性能不佳。为解决这一问题，我们提出了一种信息瓶颈资产定价模型，该模型通过压缩低信噪比的数据，消除冗余信息并保留用于资产定价的关键信息。在非线性映射过程中，我们的模型对互信息施加约束。具体而言，我们逐步减少输入数据与压缩表示之间的互信息，同时增加压缩表示与输出预测之间的互信息。这种设计确保在建模金融非线性关系时忽略了无关信息（实质上是数据中的噪声），而不影响最终的资产定价。通过利用信息瓶颈的约束，我们的模型不仅利用了深度网络的非线性建模能力来捕捉金融数据中的复杂关系，还确保在信息压缩过程中过滤掉了噪声信息。', 'title_zh': '信息瓶颈资产定价模型'}
{'arxiv_id': 'arXiv:2507.23217', 'title': 'Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation', 'authors': 'Hyeon Seong Jeong, Sangwoo Jo, Byeong Hyun Yoon, Yoonseok Heo, Haedong Jeong, Taehoon Kim', 'link': 'https://arxiv.org/abs/2507.23217', 'abstract': "Understanding complex multimodal documents remains challenging due to their structural inconsistencies and limited training data availability. We introduce \\textit{DocsRay}, a training-free document understanding system that integrates pseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented Generation (RAG). Our approach leverages multimodal Large Language Models' (LLMs) native capabilities to seamlessly process documents containing diverse elements such as text, images, charts, and tables without requiring specialized models or additional training. DocsRay's framework synergistically combines three key techniques: (1) a semantic structuring module using prompt-based LLM interactions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal analysis that converts diverse document elements into unified, text-centric representations using the inherent capabilities of multimodal LLMs, and (3) an efficient two-stage hierarchical retrieval system that reduces retrieval complexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents averaging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency from 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the MMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%, substantially surpassing previous state-of-the-art results.", 'abstract_zh': 'Understanding Complex Multimodal Documents with DocsRay: Synergistically Combining Pseudo Table of Contents Generation and Hierarchical Retrieval-Augmented Generation', 'title_zh': '使用伪目录引导检索增强生成的零样本文档理解'}
{'arxiv_id': 'arXiv:2507.23194', 'title': 'Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks', 'authors': 'Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum', 'link': 'https://arxiv.org/abs/2507.23194', 'abstract': 'The demand for AI-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware-optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands. Major cloud providers, semiconductor companies, and research institutions are now investing heavily in AI-driven code generation for GPUs, aiming to reduce manual optimization efforts while achieving near-expert performance on hardware like AMD MI300X. The Triton language, a Python-based DSL for GPU programming, has emerged as a popular target for such AI-generated kernels due to its balance of performance and ease-of-coding. In this work, we present an evaluation suite for Triton-based GPU kernels and GEAK (Generating Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs to generate performant Triton code specifically for AMD GPUs, including the AMD MI300X and MI250. GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms. On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to $63$% and execution speed up of up to $2.59$X. These results highlight the promise of GEAK-like agentic code generation for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kernel performance.', 'abstract_zh': 'AI生成的GPU内核需求迅速增长：基于 Triton 的GPU内核评估套件与GEAK框架的研究', 'title_zh': 'Geak: 引入 Triton Kernel AI 代理及评估基准'}
{'arxiv_id': 'arXiv:2507.23190', 'title': 'Accessibility Scout: Personalized Accessibility Scans of Built Environments', 'authors': 'William Huang, Xia Su, Jon E. Froehlich, Yang Zhang', 'link': 'https://arxiv.org/abs/2507.23190', 'abstract': 'Assessing the accessibility of unfamiliar built environments is critical for people with disabilities. However, manual assessments, performed by users or their personal health professionals, are laborious and unscalable, while automatic machine learning methods often neglect an individual user\'s unique needs. Recent advances in Large Language Models (LLMs) enable novel approaches to this problem, balancing personalization with scalability to enable more adaptive and context-aware assessments of accessibility. We present Accessibility Scout, an LLM-based accessibility scanning system that identifies accessibility concerns from photos of built environments. With use, Accessibility Scout becomes an increasingly capable "accessibility scout", tailoring accessibility scans to an individual\'s mobility level, preferences, and specific environmental interests through collaborative Human-AI assessments. We present findings from three studies: a formative study with six participants to inform the design of Accessibility Scout, a technical evaluation of 500 images of built environments, and a user study with 10 participants of varying mobility. Results from our technical evaluation and user study show that Accessibility Scout can generate personalized accessibility scans that extend beyond traditional ADA considerations. Finally, we conclude with a discussion on the implications of our work and future steps for building more scalable and personalized accessibility assessments of the physical world.', 'abstract_zh': '评估不熟悉建成环境的可达性对于残疾人至关重要。然而，由用户或其个人健康专业人士进行的手动评估既费时又不具有可扩展性，而自动机器学习方法往往忽视了个人用户独特的需要。大型语言模型（LLMs）的最新进展为这一问题提供了新的方法，平衡个性化与可扩展性，以实现更具适应性和上下文感知的可达性评估。我们提出了一个基于大型语言模型的可达性扫描系统Accessibility Scout，能够从建成环境的照片中识别可达性问题。通过使用，Accessibility Scout 变得越来越“能干”，能够根据个人的行动能力、偏好和特定的环境兴趣进行个性化的可达性评估，通过协作的人机评估来进行。我们进行了三项研究：一项涉及六名参与者的形成性研究以指导Accessibility Scout的设计，一项对500张建成环境照片的技术评估，以及一项涉及10名不同行动能力参与者的用户研究。我们的技术评估和用户研究结果显示，Accessibility Scout能够生成超越传统ADA考虑的个性化可达性扫描。最后，我们讨论了我们工作的意义及其对未来构建更具可扩展性和个性化的物理世界可达性评估的展望。', 'title_zh': '可达性探查器：建成环境的个性化可达性检查'}
{'arxiv_id': 'arXiv:2507.23178', 'title': 'AutoBridge: Automating Smart Device Integration with Centralized Platform', 'authors': 'Siyuan Liu, Zhice Yang, Huangxun Chen', 'link': 'https://arxiv.org/abs/2507.23178', 'abstract': 'Multimodal IoT systems coordinate diverse IoT devices to deliver human-centered services. The ability to incorporate new IoT devices under the management of a centralized platform is an essential requirement. However, it requires significant human expertise and effort to program the complex IoT integration code that enables the platform to understand and control the device functions. Therefore, we propose AutoBridge to automate IoT integration code generation. Specifically, AutoBridge adopts a divide-and-conquer strategy: it first generates device control logic by progressively retrieving device-specific knowledge, then synthesizes platformcompliant integration code using platform-specific knowledge. To ensure correctness, AutoBridge features a multi-stage debugging pipeline, including an automated debugger for virtual IoT device testing and an interactive hardware-in-the-loop debugger that requires only binary user feedback (yes and no) for real-device verification. We evaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT platforms. The results demonstrate that AutoBridge can achieves an average success rate of 93.87% and an average function coverage of 94.87%, without any human involvement. With minimal binary yes and no feedback from users, the code is then revised to reach 100% function coverage. A user study with 15 participants further shows that AutoBridge outperforms expert programmers by 50% to 80% in code accuracy, even when the programmers are allowed to use commercial code LLMs.', 'abstract_zh': '多模态物联网系统协调多样化的物联网设备以提供以人类为中心的服务。集中管理平台下整合新物联网设备的能力是必不可少的要求。然而，编程使平台能够理解并控制设备功能的复杂物联网集成代码需要大量的专业人力和努力。因此，我们提出了AutoBridge以自动化物联网集成代码的生成。具体而言，AutoBridge采用分而治之的策略：首先通过逐步检索设备特定的知识生成设备控制逻辑，然后使用平台特定的知识合成符合平台规范的集成代码。为了确保正确性，AutoBridge配备了一套多阶段调试流水线，包括自动调试器用于虚拟物联网设备测试，以及只需要二进制用户反馈（是和否）即可进行实际设备验证的互动硬件在环调试器。我们在两个开源物联网平台上涵盖的34种物联网设备基准测试上评估了AutoBridge。结果表明，AutoBridge在没有任何人工干预的情况下，可以实现93.87%的平均成功率和94.87%的平均功能覆盖率。通过最少的二进制是和否用户反馈，代码被修订以达到100%的功能覆盖率。进一步的用户研究结果显示，在允许程序员使用商业代码LLM的情况下，AutoBridge在代码准确性方面比专家程序员高出50%到80%。', 'title_zh': 'AutoBridge: 通过集中平台自动化智能设备集成'}
{'arxiv_id': 'arXiv:2507.23167', 'title': 'LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration', 'authors': 'Jizhou Guo', 'link': 'https://arxiv.org/abs/2507.23167', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive performance across various tasks, with different models excelling in distinct domains and specific abilities. Effectively combining the predictions of multiple LLMs is crucial for enhancing system robustness and performance. However, existing ensemble methods often rely on simple techniques like voting or logits ensembling, which overlook the varying confidence and reliability of models in different contexts. In this work, we propose LENS (Learning ENsemble confidence from Neural States), a novel approach that learns to estimate model confidence by analyzing internal representations. For each LLM, we train a lightweight linear confidence predictor that leverages layer-wise hidden states and normalized probabilities as inputs. This allows for more nuanced weighting of model predictions based on their context-dependent reliability. Our method does not require modifying the model parameters and requires negligible additional computation. Experimental results on multiple-choice and boolean question-answering tasks demonstrate that LENS outperforms traditional ensemble methods by a substantial margin. Our findings suggest that internal representations provide valuable signals for determining model confidence and can be effectively leveraged for ensemble learning.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中展现了出色的性能，不同的模型在特定领域和能力上表现出色。有效地结合多种LLMs的预测对于提升系统的稳健性和性能至关重要。然而，现有的ensemble方法通常依赖于简单的技术，如投票或logits ensemble，这些技术忽视了模型在不同上下文中不同置信度和可靠性。在本工作中，我们提出LENS（Learning ENsemble confidence from Neural States）这一新型方法，通过分析内部表示来学习估计模型的置信度。对于每一个LLM，我们训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这使得可以根据模型预测的上下文相关可靠性来进行更精细的加权。我们的方法不需要修改模型参数，并且所需的额外计算量微乎其微。在多项选择和布尔问答任务上的实验结果表明，LENS在传统ensemble方法上具有显著的优势。我们的研究结果表明，内部表示提供了确定模型置信度的有价值信号，并且可以有效地用于ensemble学习。', 'title_zh': 'LENS: 从神经状态学习集成置信度以实现多语言模型答案集成'}
{'arxiv_id': 'arXiv:2507.23154', 'title': 'FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations', 'authors': 'Sofiane Bouaziz, Adel Hafiane, Raphael Canals, Rachid Nedjai', 'link': 'https://arxiv.org/abs/2507.23154', 'abstract': "Urban heatwaves, droughts, and land degradation are pressing and growing challenges in the context of climate change. A valuable approach to studying them requires accurate spatio-temporal information on land surface conditions. One of the most important variables for assessing and understanding these phenomena is Land Surface Temperature (LST), which is derived from satellites and provides essential information about the thermal state of the Earth's surface. However, satellite platforms inherently face a trade-off between spatial and temporal resolutions. To bridge this gap, we propose FuseTen, a novel generative framework that produces daily LST observations at a fine 10 m spatial resolution by fusing spatio-temporal observations derived from Sentinel-2, Landsat 8, and Terra MODIS. FuseTen employs a generative architecture trained using an averaging-based supervision strategy grounded in physical principles. It incorporates attention and normalization modules within the fusion process and uses a PatchGAN discriminator to enforce realism. Experiments across multiple dates show that FuseTen outperforms linear baselines, with an average 32.06% improvement in quantitative metrics and 31.42% in visual fidelity. To the best of our knowledge, this is the first non-linear method to generate daily LST estimates at such fine spatial resolution.", 'abstract_zh': '城市热浪、干旱和土地退化是气候变化背景下 pressing 和增长的挑战。研究它们的一个有价值的方法是获取土地表面条件的准确时空信息。评估和理解这些现象最重要的变量之一是地表温度（LST），它源自卫星并提供了关于地球表面热状态的重要信息。然而，卫星平台固有地在空间分辨率和时间分辨率之间存在权衡。为弥补这一差距，我们提出了一种名为 FuseTen 的新型生成框架，通过融合来自 Sentinel-2、Landsat 8 和 Terra MODIS 的时空观测数据生成每日 10 米空间分辨率的 LST 观测数据。FuseTen 使用一种基于物理原理的平均监督策略进行训练的生成架构，并在融合过程中结合了注意力和规范化模块，同时使用 PatchGAN 辨别器来增强现实性。多项实验结果表明，FuseTen 在定量指标和视觉保真度方面分别比线性基准高出平均 32.06% 和 31.42%。据我们所知，这是首个生成如此高空间分辨率每日 LST 估计值的非线性方法。', 'title_zh': 'FuseTen：一种基于时空卫星观测的每日10米地表温度生成模型'}
{'arxiv_id': 'arXiv:2507.23121', 'title': 'Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity', 'authors': 'Xinwei Wu, Haojie Li, Hongyu Liu, Xinyu Ji, Ruohan Li, Yule Chen, Yigeng Zhang', 'link': 'https://arxiv.org/abs/2507.23121', 'abstract': 'In this work, we study a critical research problem regarding the trustworthiness of large language models (LLMs): how LLMs behave when encountering ambiguous narrative text, with a particular focus on Chinese textual ambiguity. We created a benchmark dataset by collecting and generating ambiguous sentences with context and their corresponding disambiguated pairs, representing multiple possible interpretations. These annotated examples are systematically categorized into 3 main categories and 9 subcategories. Through experiments, we discovered significant fragility in LLMs when handling ambiguity, revealing behavior that differs substantially from humans. Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous text, show overconfidence in interpreting ambiguous text as having a single meaning rather than multiple meanings, and exhibit overthinking when attempting to understand the various possible meanings. Our findings highlight a fundamental limitation in current LLMs that has significant implications for their deployment in real-world applications where linguistic ambiguity is common, calling for improved approaches to handle uncertainty in language understanding. The dataset and code are publicly available at this GitHub repository: this https URL.', 'abstract_zh': '在这项工作中，我们研究了一个关于大型语言模型（LLMs）可信度的关键研究问题：LLMs在遇到模棱两可的叙事文本时的行为，特别是对中国文本模棱两可性的关注。我们创建了一个基准数据集，通过收集并生成带有上下文的模棱两可句子及其对应的消歧义配对，表示多种可能的解释。这些标注的例子被系统地分为3个主要类别和9个子类别。通过实验，我们发现LLMs在处理模棱两可性时存在显著的脆弱性，揭示了与人类行为显著不同的行为特征。具体而言，LLMs不能可靠地区分模棱两可文本和非模棱两可文本，对模棱两可文本的解释表现出过度自信，认为模棱两可文本只有一种意义而不是多种意义，并且在试图理解各种可能的意义时表现出过度思考。我们的发现揭示了当前LLMs的基本局限性，这在语言模棱两可性普遍存在的真实世界应用中具有重要意义，呼吁改进语言理解中的不确定性处理方法。该数据集和代码在GitHub仓库中公开发布：this https URL。', 'title_zh': '通过中文文本歧义探究可信赖的大语言模型的脆弱性'}
{'arxiv_id': 'arXiv:2507.23115', 'title': 'FLOSS: Federated Learning with Opt-Out and Straggler Support', 'authors': 'David J Goetze, Dahlia J Felten, Jeannie R Albrecht, Rohit Bhattacharya', 'link': 'https://arxiv.org/abs/2507.23115', 'abstract': 'Previous work on data privacy in federated learning systems focuses on privacy-preserving operations for data from users who have agreed to share their data for training. However, modern data privacy agreements also empower users to use the system while opting out of sharing their data as desired. When combined with stragglers that arise from heterogeneous device capabilities, the result is missing data from a variety of sources that introduces bias and degrades model performance. In this paper, we present FLOSS, a system that mitigates the impacts of such missing data on federated learning in the presence of stragglers and user opt-out, and empirically demonstrate its performance in simulations.', 'abstract_zh': '联邦学习系统中关于数据隐私的先前工作主要关注用户同意共享数据进行训练时的隐私保护操作。然而，现代数据隐私协议也赋予用户在不共享数据的情况下使用系统的权利。当与不同设备能力导致的延迟者结合时，结果是来自多种来源的缺失数据，这引入了偏差并降低了模型性能。本文提出了一种名为FLOSS的系统，该系统在存在延迟者和用户退出的情况下缓解此类缺失数据对联邦学习的影响，并通过仿真实验展示了其性能。', 'title_zh': 'FLOSS: 带有退出选项和支持迟到节点的联邦学习'}
{'arxiv_id': 'arXiv:2507.23104', 'title': 'RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL', 'authors': 'Jeffrey Eben, Aitzaz Ahmad, Stephen Lau', 'link': 'https://arxiv.org/abs/2507.23104', 'abstract': 'Despite advances in large language model (LLM)-based natural language interfaces for databases, scaling to enterprise-level data catalogs remains an under-explored challenge. Prior works addressing this challenge rely on domain-specific fine-tuning - complicating deployment - and fail to leverage important semantic context contained within database metadata. To address these limitations, we introduce a component-based retrieval architecture that decomposes database schemas and metadata into discrete semantic units, each separately indexed for targeted retrieval. Our approach prioritizes effective table identification while leveraging column-level information, ensuring the total number of retrieved tables remains within a manageable context budget. Experiments demonstrate that our method maintains high recall and accuracy, with our system outperforming baselines over massive databases with varying structure and available metadata. Our solution enables practical text-to-SQL systems deployable across diverse enterprise settings without specialized fine-tuning, addressing a critical scalability gap in natural language database interfaces.', 'abstract_zh': '尽管在基于大型语言模型（LLM）的自然语言数据库接口方面取得了进展，但将这些接口扩展到企业级数据目录仍然是一项未充分探索的挑战。前人解决这一挑战的工作依赖于特定领域的微调——这使得部署过程变得复杂——并且无法充分利用数据库元数据中包含的重要语义上下文。为了解决这些局限性，我们提出了一种基于组件的检索架构，将数据库模式和元数据分解为独立的语义单元，并分别索引以实现精确检索。我们的方法优先考虑有效的表识别，同时利用列级信息，确保检索出的表总数在可管理的上下文预算之内。实验结果表明，我们的方法保持了高水平的召回率和准确性，我们的系统在具有不同结构和可用元数据的大规模数据库中优于基线方法。我们的解决方案使得统一的文本到SQL系统能够在无需专门微调的情况下应用于各种企业环境，从而解决了自然语言数据库接口在可扩展性方面的关键差距。', 'title_zh': 'RASL：检索增强的模式链接用于大规模数据库文本到SQL'}
{'arxiv_id': 'arXiv:2507.23095', 'title': 'SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity', 'authors': 'Ishani Mondal, Meera Bharadwaj, Ayush Roy, Aparna Garimella, Jordan Lee Boyd-Graber', 'link': 'https://arxiv.org/abs/2507.23095', 'abstract': 'We present SMART-Editor, a framework for compositional layout and content editing across structured (posters, websites) and unstructured (natural images) domains. Unlike prior models that perform local edits, SMART-Editor preserves global coherence through two strategies: Reward-Refine, an inference-time rewardguided refinement method, and RewardDPO, a training-time preference optimization approach using reward-aligned layout pairs. To evaluate model performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain, cascading edit scenarios. SMART-Editor outperforms strong baselines like InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in structured settings and Reward-Refine showing advantages on natural images. Automatic and human evaluations confirm the value of reward-guided planning in producing semantically consistent and visually aligned edits.', 'abstract_zh': 'SMART-Editor：跨结构化与非结构化领域 состав成布局和内容编辑的框架', 'title_zh': 'SMART-Editor: 一种具有结构完整性的类人类设计编辑多智能体框架'}
{'arxiv_id': 'arXiv:2507.23093', 'title': 'On the Sustainability of AI Inferences in the Edge', 'authors': 'Ghazal Sobhani, Md. Monzurul Amin Ifath, Tushar Sharma, Israat Haque', 'link': 'https://arxiv.org/abs/2507.23093', 'abstract': 'The proliferation of the Internet of Things (IoT) and its cutting-edge AI-enabled applications (e.g., autonomous vehicles and smart industries) combine two paradigms: data-driven systems and their deployment on the edge. Usually, edge devices perform inferences to support latency-critical applications. In addition to the performance of these resource-constrained edge devices, their energy usage is a critical factor in adopting and deploying edge applications. Examples of such devices include Raspberry Pi (RPi), Intel Neural Compute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU). Despite their adoption in edge deployment for AI inferences, there is no study on their performance and energy usage for informed decision-making on the device and model selection to meet the demands of applications. This study fills the gap by rigorously characterizing the performance of traditional, neural networks, and large language models on the above-edge devices. Specifically, we analyze trade-offs among model F1 score, inference time, inference power, and memory usage. Hardware and framework optimization, along with external parameter tuning of AI models, can balance between model performance and resource usage to realize practical edge AI deployments.', 'abstract_zh': '物联网（IoT）的普及及其先进的AI驱动应用（例如自动驾驶车辆和智能制造）结合了两种范式：数据驱动系统及其在边缘的部署。通常，边缘设备用于支持具有严格延迟要求的应用的推理。除了这些资源受限边缘设备的性能外，其能耗是采用和部署边缘应用的关键因素。此类设备包括Raspberry Pi（RPi）、Intel神经计算棒（INCS）、NVIDIA Jetson nano（NJn）和Google Coral USB（GCU）。尽管这些设备已在边缘部署中用于AI推理，但尚未对此类设备上的性能和能耗进行全面研究，以支持基于应用需求的设备和模型选择。本研究通过严格表征上述边缘设备上的传统模型、神经网络和大规模语言模型的性能来填补这一空白。具体而言，我们分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。通过硬件和框架优化及AI模型的外部参数调节，可以在模型性能和资源使用之间取得平衡，从而实现实际的边缘AI部署。', 'title_zh': '关于边缘计算中AI推断的可持续性研究'}
{'arxiv_id': 'arXiv:2507.23088', 'title': 'Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance', 'authors': 'Lalithkumar Seenivasan, Jiru Xu, Roger D. Soberanis Mukul, Hao Ding, Grayson Byrd, Yu-Chun Ku, Jose L. Porras, Masaru Ishii, Mathias Unberath', 'link': 'https://arxiv.org/abs/2507.23088', 'abstract': 'Emerging surgical data science and robotics solutions, especially those designed to provide assistance in situ, require natural human-machine interfaces to fully unlock their potential in providing adaptive and intuitive aid. Contemporary AI-driven solutions remain inherently rigid, offering limited flexibility and restricting natural human-machine interaction in dynamic surgical environments. These solutions rely heavily on extensive task-specific pre-training, fixed object categories, and explicit manual-prompting. This work introduces a novel Perception Agent that leverages speech-integrated prompt-engineered large language models (LLMs), segment anything model (SAM), and any-point tracking foundation models to enable a more natural human-machine interaction in real-time intraoperative surgical assistance. Incorporating a memory repository and two novel mechanisms for segmenting unseen elements, Perception Agent offers the flexibility to segment both known and unseen elements in the surgical scene through intuitive interaction. Incorporating the ability to memorize novel elements for use in future surgeries, this work takes a marked step towards human-machine symbiosis in surgical procedures. Through quantitative analysis on a public dataset, we show that the performance of our agent is on par with considerably more labor-intensive manual-prompting strategies. Qualitatively, we show the flexibility of our agent in segmenting novel elements (instruments, phantom grafts, and gauze) in a custom-curated dataset. By offering natural human-machine interaction and overcoming rigidity, our Perception Agent potentially brings AI-based real-time assistance in dynamic surgical environments closer to reality.', 'abstract_zh': '新兴外科数据科学与机器人解决方案，尤其是那些旨在提供现场辅助的解决方案，需要自然的人机界面以充分利用其在提供适应性和直观辅助方面的潜力。当前基于AI的解决方案本质上具有刚性，灵活性有限，限制了在动态手术环境中的自然人机交互。这些解决方案高度依赖特定任务的预训练、固定的对象类别和明确的手动提示。本文介绍了一种新的知觉代理，该代理利用语音集成的提示工程大型语言模型（LLMs）、分割一切模型（SAM）和任意点追踪基础模型，以实现更自然的实时手术辅助中的人机交互。该知觉代理通过直观交互实现了包含记忆库以及两种分割未见元素的新机制，能够灵活地分割手术场景中的已知和未见元素。通过记住新的元素以在未来手术中使用，本文朝着手术程序中的人机共生迈出了重要一步。通过对公开数据集的定量分析，我们展示了我们的代理在性能上与劳动密集型的手动提示策略相当。定性分析表明，我们的代理在自定义编曲数据集中具有灵活性，能够分割新的元素（器械、仿生移植物和纱布）。通过提供自然的人机交互并克服刚性，我们的知觉代理有可能将基于AI的实时辅助推向动态手术环境更加现实的未来。', 'title_zh': '超越刚性人工智能： toward 自然的人机共生以实现联合手术辅助'}
{'arxiv_id': 'arXiv:2507.23087', 'title': 'On LLM-Assisted Generation of Smart Contracts from Business Processes', 'authors': 'Fabian Stiehle, Hans Weytjens, Ingo Weber', 'link': 'https://arxiv.org/abs/2507.23087', 'abstract': 'Large language models (LLMs) have changed the reality of how software is produced. Within the wider software engineering community, among many other purposes, they are explored for code generation use cases from different types of input. In this work, we present an exploratory study to investigate the use of LLMs for generating smart contract code from business process descriptions, an idea that has emerged in recent literature to overcome the limitations of traditional rule-based code generation approaches. However, current LLM-based work evaluates generated code on small samples, relying on manual inspection, or testing whether code compiles but ignoring correct execution. With this work, we introduce an automated evaluation framework and provide empirical data from larger data sets of process models. We test LLMs of different types and sizes in their capabilities of achieving important properties of process execution, including enforcing process flow, resource allocation, and data-based conditions. Our results show that LLM performance falls short of the perfect reliability required for smart contract development. We suggest future work to explore responsible LLM integrations in existing tools for code generation to ensure more reliable output. Our benchmarking framework can serve as a foundation for developing and evaluating such integrations.', 'abstract_zh': '大型语言模型（LLMs）已改变了软件生产的真实现状。在更广泛的软件工程社区中，它们被探索用于从不同类型的输入自动生成代码的各种用例。在本研究中，我们提出了一项探索性研究，探讨将LLMs用于生成基于业务流程描述的智能合约代码的应用，这一想法近期在文献中出现，旨在克服传统基于规则的代码生成方法的局限性。然而，目前基于LLM的工作主要在小样本上评估生成的代码，依赖于人工检查，或测试代码是否编译，而忽略了正确执行。通过本研究，我们引入了一种自动评估框架，并提供了从更大规模流程模型数据集中获得的经验数据。我们测试了不同类型和规模的LLMs在实现流程执行重要属性方面的能力，包括强制执行流程控制、资源分配以及数据驱动的条件。我们的结果表明，LLM性能未能达到智能合约开发所需的完美可靠性。我们建议未来工作探索将负责任的LLM集成到现有代码生成工具中，以确保更可靠的结果。我们的基准测试框架可以作为开发和评估此类集成的基础。', 'title_zh': '基于业务过程的LLM辅助智能合约生成'}
{'arxiv_id': 'arXiv:2507.23084', 'title': 'AutoIndexer: A Reinforcement Learning-Enhanced Index Advisor Towards Scaling Workloads', 'authors': 'Taiyi Wang, Eiko Yoneki', 'link': 'https://arxiv.org/abs/2507.23084', 'abstract': "Efficiently selecting indexes is fundamental to database performance optimization, particularly for systems handling large-scale analytical workloads. While deep reinforcement learning (DRL) has shown promise in automating index selection through its ability to learn from experience, few works address how these RL-based index advisors can adapt to scaling workloads due to exponentially growing action spaces and heavy trial and error. To address these challenges, we introduce AutoIndexer, a framework that combines workload compression, query optimization, and specialized RL models to scale index selection effectively. By operating on compressed workloads, AutoIndexer substantially lowers search complexity without sacrificing much index quality. Extensive evaluations show that it reduces end-to-end query execution time by up to 95% versus non-indexed baselines. On average, it outperforms state-of-the-art RL-based index advisors by approximately 20% in workload cost savings while cutting tuning time by over 50%. These results affirm AutoIndexer's practicality for large and diverse workloads.", 'abstract_zh': '高效选择索引是数据库性能优化的基本要素，尤其是在处理大规模分析工作负载的系统中。尽管深度强化学习（DRL）通过其从经验中学习的能力在自动化索引选择方面显示出前景，但很少有研究解决这些基于RL的索引顾问如何适应因动作空间指数级增长和大量试错而导致的工作负载扩展问题。为应对这些挑战，我们引入了AutoIndexer框架，该框架结合了工作负载压缩、查询优化和专门的RL模型，以有效扩展索引选择。通过在压缩的工作负载上操作，AutoIndexer显著降低了搜索复杂性，同时不牺牲太多索引质量。 extensive评估表明，它将端到端查询执行时间减少了多达95%。平均而言，它在工作负载成本节约方面比最先进的基于RL的索引顾问高出约20%，同时将调优时间减少了超过50%。这些结果证实了AutoIndexer在大规模和多样化工作负载中的实用性。', 'title_zh': 'AutoIndexer: 一种增强学习驱动的索引建议器以扩展工作负载'}
{'arxiv_id': 'arXiv:2507.23064', 'title': 'Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints', 'authors': 'Santosh Patapati, Trisanth Srinivasan, Murari Ambati', 'link': 'https://arxiv.org/abs/2507.23064', 'abstract': 'Autonomous cars need geometric accuracy and semantic understanding to navigate complex environments, yet most stacks handle them separately. We present XYZ-Drive, a single vision-language model that reads a front-camera frame, a 25m $\\times$ 25m overhead map, and the next waypoint, then outputs steering and speed. A lightweight goal-centered cross-attention layer lets waypoint tokens highlight relevant image and map patches, supporting both action and textual explanations, before the fused tokens enter a partially fine-tuned LLaMA-3.2 11B model.\nOn the MD-NEX Outdoor-Driving benchmark XYZ-Drive attains 95% success and 0.80 Success weighted by Path Length (SPL), surpassing PhysNav-DG by 15%. and halving collisions, all while significantly improving efficiency by using only a single branch. Sixteen ablations explain the gains. Removing any modality (vision, waypoint, map) drops success by up to 11%, confirming their complementary roles and rich connections. Replacing goal-centered attention with simple concatenation cuts 3% in performance, showing query-based fusion injects map knowledge more effectively. Keeping the transformer frozen loses 5%, showing the importance of fine-tuning when applying VLMs for specific tasks such as autonomous driving. Coarsening map resolution from 10 cm to 40 cm blurs lane edges and raises crash rate.\nOverall, these results demonstrate that early, token-level fusion of intent and map layout enables accurate, transparent, real-time driving.', 'abstract_zh': '自主驾驶汽车需要几何精确性和语义理解以导航复杂环境，然而大多数系统分别处理它们。我们提出XYZ-Drive，这是一种单一的视觉-语言模型，它读取前视摄像头帧、25m×25m的鸟瞰图地图以及下一个航点，然后输出方向盘控制和速度。轻量级的目标导向交叉注意力层使航点标记突出相关的图像和地图片段，支持动作和文本解释，之后融合的标记进入部分微调的LLaMA-3.2 11B模型。\n在MD-NEX户外驾驶基准测试中，XYZ-Drive 的成功率为95%，路径长度加权的成功率为0.80 SPL（成功加权路径长度），超过PhysNav-DG 15%，同时减少了碰撞次数，显著提高了效率，仅使用一个分支。六项消融实验解释了这些增益。去除任何模态（视觉、航点、地图）都会将成功率降低高达11%，证实了它们的互补作用和密切联系。用简单的串联替换目标导向注意力会降低3%的性能，表明基于查询的融合更有效地注入地图知识。冻结变换器会降低5%，表明在特定任务（如自动驾驶）中应用视觉语言模型时微调的重要性。降低地图分辨率从10厘米到40厘米会模糊车道边缘并增加事故发生率。\n总体而言，这些结果表明，早期、标记级别的意图和地图布局融合能够实现准确、透明的实时驾驶。', 'title_zh': '基于视觉-语言融合的实时自主驾驶：目标导向的相机、高精地图与航点跨注意力机制'}
{'arxiv_id': 'arXiv:2507.23058', 'title': 'Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation', 'authors': 'Alexandru Buburuzan', 'link': 'https://arxiv.org/abs/2507.23058', 'abstract': "Safety-critical applications, such as autonomous driving and medical image analysis, require extensive multimodal data for rigorous testing. Synthetic data methods are gaining prominence due to the cost and complexity of gathering real-world data, but they demand a high degree of realism and controllability to be useful. This work introduces two novel methods for synthetic data generation in autonomous driving and medical image analysis, namely MObI and AnydoorMed, respectively. MObI is a first-of-its-kind framework for Multimodal Object Inpainting that leverages a diffusion model to produce realistic and controllable object inpaintings across perceptual modalities, demonstrated simultaneously for camera and lidar. Given a single reference RGB image, MObI enables seamless object insertion into existing multimodal scenes at a specified 3D location, guided by a bounding box, while maintaining semantic consistency and multimodal coherence. Unlike traditional inpainting methods that rely solely on edit masks, this approach uses 3D bounding box conditioning to ensure accurate spatial positioning and realistic scaling. AnydoorMed extends this paradigm to the medical imaging domain, focusing on reference-guided inpainting for mammography scans. It leverages a diffusion-based model to inpaint anomalies with impressive detail preservation, maintaining the reference anomaly's structural integrity while semantically blending it with the surrounding tissue. Together, these methods demonstrate that foundation models for reference-guided inpainting in natural images can be readily adapted to diverse perceptual modalities, paving the way for the next generation of systems capable of constructing highly realistic, controllable and multimodal counterfactual scenarios.", 'abstract_zh': '安全关键应用（如自动驾驶和医学图像分析）需要大量的多模态数据进行严格的测试。合成数据方法由于收集真实世界数据的成本和复杂性逐渐受到重视，但它们需要极高的真实感和可控性才能发挥作用。本文介绍了两种新型的合成数据生成方法，分别为应用于自动驾驶的MObI和应用于医学图像分析的AnydoorMed。MObI是一种首创的多模态物体补全框架，利用扩散模型生成跨感知模态的真实且可控的物体补全，同时在相机和激光雷达观测量中进行展示。给定一张参考RGB图像，MObI能够根据bounding box指导，在指定的3D位置无缝插入物体，同时保持语义一致性和多模态一致性。不同于依赖于编辑掩模的传统补全方法，这种方法使用3D bounding box条件来确保准确的空间定位和真实的尺度。AnydoorMed将这一范式扩展到医学成像领域，重点关注参考引导的乳腺X光片补全。它利用基于扩散模型的方法以令人印象深刻的细节保真度补全异常，同时维护参考异常的结构完整性和与周围组织的语义融合。结合这些方法展示了，用于自然图像参考引导补全的基础模型可以很容易地适应各种感知模态，为下一代能够构建高度真实、可控和多模态反事实场景的系统铺平了道路。', 'title_zh': '参考指南扩散修复用于多模态反事实生成'}
{'arxiv_id': 'arXiv:2507.23042', 'title': 'Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving', 'authors': 'Santosh Patapati, Trisanth Srinivasan', 'link': 'https://arxiv.org/abs/2507.23042', 'abstract': "Autonomous vehicles must react in milliseconds while reasoning about road geometry and traffic intent to navigate complex situations. We introduce NovaDrive, a single-branch vision-language architecture that processes front-camera images, HD-map tiles, LiDAR depth, and textual waypoints in a single branch. A lightweight, two-stage cross-attention block first aligns waypoint tokens with the HD map, then refines attention over fine-grained image and depth patches. Coupled with a novel smoothness loss that discourages abrupt steering and speed changes, this design eliminates the need for recurrent memory. We fine-tune the top 15 layers of an 11B LLaMA-3.2 vision-language backbone, enabling real-time inference. On the nuScenes / Waymo subset of the MD-NEX Outdoor benchmark, NovaDrive raises success rate to 84% (+4%), boosts path-efficiency (SPL) to 0.66 (+0.11), and reduces collision frequency from 2.6% to 1.2% (-1.4%) relative to the previous state-of-the-art. Our ablations confirm that waypoint tokens, partial VLM fine-tuning, and the cross-attention fusion each contribute the most to these gains. Beyond safety, NovaDrive's shorter routes (resulting from the novel smoothness loss) translate to lower fuel or battery usage, pointing toward leaner, more easily updated driving stacks. NovaDrive can be extended to other embodied-AI domains as well.", 'abstract_zh': '自主驾驶车辆必须在毫秒级时间内处理道路几何和交通意图以应对复杂情况。我们引入了NovaDrive，这是一种单分支视觉语言架构，能同时处理前方摄像头图像、高精度地图瓦片、LiDAR深度以及文本方式点信息。一个轻量级的两阶段交叉注意力模块首先将方式点标记与高精度地图对齐，然后对细微图像和深度补丁进行注意力精炼。结合一种新的平滑损失，这种设计消除了循环记忆的需要。我们对11B LLaMA-3.2视觉语言骨干网络的顶层15层进行了微调，实现实时推理。在MD-NEX Outdoor基准的nuScenes / Waymo子集上，NovaDrive的成功率提高到84%（+4%），路径效率（SPL）提升至0.66（+0.11），碰撞频率从2.6%降至1.2%（-1.4%），超过了之前的最佳水平。我们的消融实验表明，方式点标记、部分VLM微调和交叉注意力融合对这些提升贡献最大。除了安全性，NovaDrive的更短路径（得益于新颖的平滑损失）也意味着更低的燃油或电池消耗，这指向了更轻量、更易于更新的驾驶栈。NovaDrive还可以扩展到其他具身AI领域。', 'title_zh': '实时视觉-语言驾驶中的早期目标导向多尺度融合'}
{'arxiv_id': 'arXiv:2507.23027', 'title': 'Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging', 'authors': 'Krishan Agyakari Raja Babu, Om Prabhu, Annu, Mohanasankar Sivaprakasam', 'link': 'https://arxiv.org/abs/2507.23027', 'abstract': 'Automated cardiac interpretation in resource-constrained settings (RCS) is often hindered by poor-quality echocardiographic imaging, limiting the effectiveness of downstream diagnostic models. While super-resolution (SR) techniques have shown promise in enhancing magnetic resonance imaging (MRI) and computed tomography (CT) scans, their application to echocardiography-a widely accessible but noise-prone modality-remains underexplored. In this work, we investigate the potential of deep learning-based SR to improve classification accuracy on low-quality 2D echocardiograms. Using the publicly available CAMUS dataset, we stratify samples by image quality and evaluate two clinically relevant tasks of varying complexity: a relatively simple Two-Chamber vs. Four-Chamber (2CH vs. 4CH) view classification and a more complex End-Diastole vs. End-Systole (ED vs. ES) phase classification. We apply two widely used SR models-Super-Resolution Generative Adversarial Network (SRGAN) and Super-Resolution Residual Network (SRResNet), to enhance poor-quality images and observe significant gains in performance metric-particularly with SRResNet, which also offers computational efficiency. Our findings demonstrate that SR can effectively recover diagnostic value in degraded echo scans, making it a viable tool for AI-assisted care in RCS, achieving more with less.', 'abstract_zh': '资源受限环境中基于深度学习的自动心脏图像解释在低质量超声心动图分类中的应用探究', 'title_zh': '提升诊断价值：资源受限成像中基于超分辨率的心脏超声分类'}
{'arxiv_id': 'arXiv:2507.23021', 'title': 'Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction', 'authors': "Giuseppe Cartella, Vittorio Cuculo, Alessandro D'Amelio, Marcella Cornia, Giuseppe Boccignone, Rita Cucchiara", 'link': 'https://arxiv.org/abs/2507.23021', 'abstract': 'Predicting human gaze scanpaths is crucial for understanding visual attention, with applications in human-computer interaction, autonomous systems, and cognitive robotics. While deep learning models have advanced scanpath prediction, most existing approaches generate averaged behaviors, failing to capture the variability of human visual exploration. In this work, we present ScanDiff, a novel architecture that combines diffusion models with Vision Transformers to generate diverse and realistic scanpaths. Our method explicitly models scanpath variability by leveraging the stochastic nature of diffusion models, producing a wide range of plausible gaze trajectories. Additionally, we introduce textual conditioning to enable task-driven scanpath generation, allowing the model to adapt to different visual search objectives. Experiments on benchmark datasets show that ScanDiff surpasses state-of-the-art methods in both free-viewing and task-driven scenarios, producing more diverse and accurate scanpaths. These results highlight its ability to better capture the complexity of human visual behavior, pushing forward gaze prediction research. Source code and models are publicly available at this https URL.', 'abstract_zh': '预测人类视扫描路径对于理解视觉注意至关重要，并在人机交互、自主系统和认知机器人等领域有着广泛的应用。尽管深度学习模型在扫描路径预测方面取得了进展，但现有方法大多生成平均行为，无法捕捉人类视觉探索的变异性。在这项工作中，我们提出了一种名为ScanDiff的新架构，该架构结合了扩散模型和Vision Transformers，以生成多样且真实的人类视扫描路径。我们的方法通过利用扩散模型的随机性质，明确建模扫描路径的变异性，产生多种可能的眼球运动轨迹。此外，我们引入了文本条件，以实现任务驱动的扫描路径生成，使模型能够适应不同的视觉搜索目标。基准数据集上的实验结果显示，ScanDiff在自由观看和任务驱动场景中均超越了现有最先进的方法，生成的扫描路径更具多样性和准确性。这些结果突显了其更好地捕捉人类视觉行为复杂性的能力，推动了视扫描预测研究的发展。源代码和模型已在以下网址公开。', 'title_zh': '使用扩散模型建模人类注视行为以实现统一的扫视路径预测'}
{'arxiv_id': 'arXiv:2507.23010', 'title': 'Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods', 'authors': 'Siwoo Park', 'link': 'https://arxiv.org/abs/2507.23010', 'abstract': 'This paper investigates the inverse capabilities and broader utility of multimodal latent spaces within task-specific AI (Artificial Intelligence) models. While these models excel at their designed forward tasks (e.g., text-to-image generation, audio-to-text transcription), their potential for inverse mappings remains largely unexplored. We propose an optimization-based framework to infer input characteristics from desired outputs, applying it bidirectionally across Text-Image (BLIP, Flux.1-dev) and Text-Audio (Whisper-Large-V3, Chatterbox-TTS) modalities.\nOur central hypothesis posits that while optimization can guide models towards inverse tasks, their multimodal latent spaces will not consistently support semantically meaningful and perceptually coherent inverse mappings. Experimental results consistently validate this hypothesis. We demonstrate that while optimization can force models to produce outputs that align textually with targets (e.g., a text-to-image model generating an image that an image captioning model describes correctly, or an ASR model transcribing optimized audio accurately), the perceptual quality of these inversions is chaotic and incoherent. Furthermore, when attempting to infer the original semantic input from generative models, the reconstructed latent space embeddings frequently lack semantic interpretability, aligning with nonsensical vocabulary tokens.\nThese findings highlight a critical limitation. multimodal latent spaces, primarily optimized for specific forward tasks, do not inherently possess the structure required for robust and interpretable inverse mappings. Our work underscores the need for further research into developing truly semantically rich and invertible multimodal latent spaces.', 'abstract_zh': '本文探讨了多功能潜空间在任务特定AI模型中的逆向能力和更广泛的应用潜力。虽然这些模型在设计的前向任务（如文本生成图像、音频转文本）上表现出色，但它们在逆向映射方面的潜力尚未得到充分探索。我们提出了一种基于优化的框架，用于从期望的输出推断输入特征，并将其应用于文本-图像（BLIP, Flux.1-dev）和文本-音频（Whisper-Large-V3, Chatterbox-TTS）模态的双向映射中。\n\n我们的核心假设认为，虽然优化可以引导模型执行逆向任务，但其多功能潜空间并不总是能够支持语义上和感知上连贯的逆向映射。实验结果一致验证了这一假设。我们证明了虽然优化可以迫使模型生成与目标文本一致的内容（例如，一个文本生成图像的模型生成一个图像分类模型能正确描述的图像，或一个自动语音识别模型准确地转录优化后的音频），但这些逆向转换的感知质量是混沌且不连贯的。此外，当尝试从生成模型推断原始语义输入时，重构的潜空间嵌入往往缺乏语义可解释性，与无意义的词汇令牌一致。\n\n这些发现指出了一个关键限制：主要用于特定前向任务优化的多功能潜空间，并不天生具备支持稳健且可解释的逆向映射的结构。我们的工作强调了进一步研究开发真正丰富语义且可逆的多功能潜空间的必要性。', 'title_zh': '探究多模态潜在空间的可逆性：基于优化的方法的局限性'}
{'arxiv_id': 'arXiv:2507.23009', 'title': 'Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead', 'authors': 'Tom Sühr, Florian E. Dorner, Olawale Salaudeen, Augustin Kelava, Samira Samadi', 'link': 'https://arxiv.org/abs/2507.23009', 'abstract': "Large Language Models (LLMs) have achieved remarkable results on a range of standardized tests originally designed to assess human cognitive and psychological traits, such as intelligence and personality. While these results are often interpreted as strong evidence of human-like characteristics in LLMs, this paper argues that such interpretations constitute an ontological error. Human psychological and educational tests are theory-driven measurement instruments, calibrated to a specific human population. Applying these tests to non-human subjects without empirical validation, risks mischaracterizing what is being measured. Furthermore, a growing trend frames AI performance on benchmarks as measurements of traits such as ``intelligence'', despite known issues with validity, data contamination, cultural bias and sensitivity to superficial prompt changes. We argue that interpreting benchmark performance as measurements of human-like traits, lacks sufficient theoretical and empirical justification. This leads to our position: Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead. We call for the development of principled, AI-specific evaluation frameworks tailored to AI systems. Such frameworks might build on existing frameworks for constructing and validating psychometrics tests, or could be created entirely from scratch to fit the unique context of AI.", 'abstract_zh': '停止使用人类测试评估AI，开发原则性的AI专用评估框架', 'title_zh': '停止用人为主观评估AI，而是发展 principle-based、特定于AI 的评估方法。'}
{'arxiv_id': 'arXiv:2507.22968', 'title': 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations', 'authors': 'Chengqian Ma, Wei Tao, Yiwen Guo', 'link': 'https://arxiv.org/abs/2507.22968', 'abstract': "Spoken Dialogue Models (SDMs) have recently attracted significant attention for their ability to generate voice responses directly to users' spoken queries. Despite their increasing popularity, there exists a gap in research focused on comprehensively understanding their practical effectiveness in comprehending and emulating human conversations. This is especially true compared to text-based Large Language Models (LLMs), which benefit from extensive benchmarking. Human voice interactions are inherently more complex than text due to characteristics unique to spoken dialogue. Ambiguity poses one challenge, stemming from semantic factors like polysemy, as well as phonological aspects such as heterograph, heteronyms, and stress patterns. Additionally, context-dependency, like omission, coreference, and multi-turn interaction, adds further complexity to human conversational dynamics. To illuminate the current state of SDM development and to address these challenges, we present a benchmark dataset in this paper, which comprises 1,079 instances in English and Chinese. Accompanied by an LLM-based evaluation method that closely aligns with human judgment, this dataset facilitates a comprehensive exploration of the performance of SDMs in tackling these practical challenges.", 'abstract_zh': '口语对话模型（SDMs）近年来因其能够直接生成针对用户口语查询的语音响应而备受关注。尽管其 popularity 日益提高，但有关其在理解和模仿人类对话方面的实际有效性的全面研究仍存在差距，与广泛受益于基准测试的基于文本的大语言模型（LLMs）相比这一差距更为明显。由于口语对话特有的特点，人类语音交互本质上比文本更复杂。语义方面的歧义，如多义词，以及音韵方面的异形词、异音词和重音模式，都是挑战之一。此外，上下文依赖性，如省略、指代和多轮交互，进一步增加了人类对话动态的复杂性。为了阐明 SDM 的当前开发状态并应对这些挑战，本文呈现了一个包含 1,079 个实例（英文和中文）的标准基准数据集，并配备了与人类判断密切一致的基于大语言模型的评估方法，以促进对 SDMs 在应对这些实际挑战方面的性能进行全面探究。', 'title_zh': 'C3: 一种探讨复杂对话挑战的双语基准模型'}
{'arxiv_id': 'arXiv:2507.22958', 'title': 'CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam', 'authors': 'Ruslan Khrulev', 'link': 'https://arxiv.org/abs/2507.22958', 'abstract': 'This paper introduces a novel benchmark, EGE-Math Solutions Assessment Benchmark, for evaluating Vision-Language Models (VLMs) on their ability to assess hand-written mathematical solutions. Unlike existing benchmarks that focus on problem solving, our approach centres on understanding student solutions, identifying mistakes, and assigning grades according to fixed criteria. We compile 122 scanned solutions from the Russian Unified State Exam (EGE) together with official expert grades, and evaluate seven modern VLMs from Google, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The results reveal current limitations in mathematical reasoning and human-rubric alignment, opening new research avenues in AI-assisted assessment. You can find code in this https URL', 'abstract_zh': '这种论文介绍了针对视觉-语言模型评估手写数学解决方案能力的新型基准——EGE-Math Solutions Assessment Benchmark。不同于现有侧重于问题解决的基准，我们的方法聚焦于理解学生解题过程、识别错误并依据固定标准评分。我们收集了来自俄罗斯统一国家考试（EGE）的122份手写解题扫描版本，并附有官方专家评分，评估了来自Google、OpenAI、Arcee AI和阿里云的七种现代视觉-语言模型在三种推理模式下的表现。结果揭示了当前在数学推理和人类评分标准一致性方面的局限性，为AI辅助评估的研究开辟了新的途径。你可以在以下链接找到代码：https://alink.com/code。', 'title_zh': 'CHECK-MAT: 检查俄联邦统一国家考试的手写数学答案'}
{'arxiv_id': 'arXiv:2507.22946', 'title': 'SmartCourse: A Contextual AI-Powered Course Advising System for Undergraduates', 'authors': 'Yixuan Mi, Yiduo Yu, Yiyi Zhao', 'link': 'https://arxiv.org/abs/2507.22946', 'abstract': 'We present SmartCourse, an integrated course management and AI-driven advising system for undergraduate students (specifically tailored to the Computer Science (CPS) major). SmartCourse addresses the limitations of traditional advising tools by integrating transcript and plan information for student-specific context. The system combines a command-line interface (CLI) and a Gradio web GUI for instructors and students, manages user accounts, course enrollment, grading, and four-year degree plans, and integrates a locally hosted large language model (via Ollama) for personalized course recommendations. It leverages transcript and major plan to offer contextual advice (e.g., prioritizing requirements or retakes). We evaluated the system on 25 representative advising queries and introduced custom metrics: PlanScore, PersonalScore, Lift, and Recall to assess recommendation quality across different context conditions. Experiments show that using full context yields substantially more relevant recommendations than context-omitted modes, confirming the necessity of transcript and plan information for personalized academic advising. SmartCourse thus demonstrates how transcript-aware AI can enhance academic planning.', 'abstract_zh': '智能课程管理与AI驱动的本科学生指导系统：以计算机科学专业为例', 'title_zh': 'SmartCourse: 一种面向本科生的语境驱动AI辅助选课系统'}
{'arxiv_id': 'arXiv:2507.22944', 'title': 'Opacity as Authority: Arbitrariness and the Preclusion of Contestation', 'authors': 'Naomi Omeonga wa Kayembe', 'link': 'https://arxiv.org/abs/2507.22944', 'abstract': 'This article redefines arbitrariness not as a normative flaw or a symptom of domination, but as a foundational functional mechanism structuring human systems and interactions. Diverging from critical traditions that conflate arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a property enabling systems - linguistic, legal, or social - to operate effectively while withholding their internal rationale. Building on Ferdinand de Saussure\'s concept of l\'arbitraire du signe, the analysis extends this principle beyond language to demonstrate its cross-domain applicability, particularly in law and social dynamics. The paper introduces the "Motivation -> Constatability -> Contestability" chain, arguing that motivation functions as a crucial interface rendering an act\'s logic vulnerable to intersubjective contestation. When this chain is broken through mechanisms like "immotivization" or "Conflict Lateralization" (exemplified by "the blur of the wolf drowned in the fish"), acts produce binding effects without exposing their rationale, thus precluding justiciability. This structural opacity, while appearing illogical, is a deliberate design protecting authority from accountability. Drawing on Shannon\'s entropy model, the paper formalizes arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern theory of arbitrariness as a neutral operator central to control as well as care, an overlooked dimension of interpersonal relations. While primarily developed through human social systems, this framework also illuminates a new pathway for analyzing explainability in advanced artificial intelligence systems.', 'abstract_zh': '本文重新定义任意性，不是将其视为规范性缺陷或 domination 的症状，而是视为构建人类系统和互动的基础功能性机制。不同于将任意性与不正义混为一谈的批判传统，本文将任意性定义为一种符号特征：一种使语言、法律或社会系统有效运作但仍保留其内在理性的属性。基于费迪南·德·索绪尔的符号任意性概念，分析将这一原则扩展到语言之外，以展示其跨域适用性，特别是在法律和社会动态领域。本文引入了“动机 -> 可验证性 -> 可争议性”链条的概念，认为动机作为一种关键接口，使行为的逻辑变得容易受到主体间争议的影响。当通过诸如“无动机化”或“冲突平行化”（例如“狼与鱼模糊不清”）等机制打断这一链条时，行为会产生具有约束力的效果而不揭示其逻辑，从而阻止其可司法性。这种结构性的不透明性虽然看似不合逻辑，但实际上是为了保护权威免于问责而故意设计的。借助香农的熵模型，本文将任意性公式化为 A = H(L|M)（条件熵）。因此，本文提出一种现代任意性理论，将其视为控制与关怀的核心中立操作，这是人际关系的一个未被关注的维度。虽然主要通过人类社会系统发展这一框架，但它也为分析高级人工智能系统的可解释性提供了一条新的途径。', 'title_zh': 'opacity作为权威：任意性与抗辩排除'}
{'arxiv_id': 'arXiv:2507.22940', 'title': 'Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes', 'authors': 'Rui Jiao, Yue Zhang, Jinku Li', 'link': 'https://arxiv.org/abs/2507.22940', 'abstract': 'We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy for Confidence Enhancement), a novel framework addressing a critical vulnerability in Large Language Models (LLMs): the prevalence of factual inaccuracies within intermediate reasoning steps despite correct final answers. This phenomenon poses substantial risks in high-stakes domains including healthcare, legal analysis, and scientific research, where erroneous yet confidently presented reasoning can mislead users into dangerous decisions. Our framework integrates three core components: (1) a specialized fact-checking classifier trained on counterfactually augmented data to detect subtle factual inconsistencies within reasoning chains; (2) a Group Relative Policy Optimization (GRPO) reinforcement learning approach that balances factuality, coherence, and structural correctness through multi-dimensional rewards; and (3) a mechanistic interpretability module examining how factuality improvements manifest in model activations during reasoning processes. Extensive evaluation across ten state-of-the-art models reveals concerning patterns: even leading models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual robustness (up to 49.90% improvement) while maintaining or improving performance on challenging benchmarks including Math-500, AIME-2024, and GPQA. Furthermore, our activation-level analysis provides actionable insights into how factual enhancements reshape reasoning trajectories within model architectures, establishing foundations for future training methodologies that explicitly target factual robustness through activation-guided optimization.', 'abstract_zh': 'RELIANCE：基于逻辑完整性和准确性提升的信心增强推理评价框架', 'title_zh': '可信赖的推理：评估和提升LLM中间思考过程的事实准确性'}
{'arxiv_id': 'arXiv:2507.22939', 'title': 'PARROT: An Open Multilingual Radiology Reports Dataset', 'authors': 'Bastien Le Guellec, Kokou Adambounou, Lisa C Adams, Thibault Agripnidis, Sung Soo Ahn, Radhia Ait Chalal, Tugba Akinci D Antonoli, Philippe Amouyel, Henrik Andersson, Raphael Bentegeac, Claudio Benzoni, Antonino Andrea Blandino, Felix Busch, Elif Can, Riccardo Cau, Armando Ugo Cavallo, Christelle Chavihot, Erwin Chiquete, Renato Cuocolo, Eugen Divjak, Gordana Ivanac, Barbara Dziadkowiec Macek, Armel Elogne, Salvatore Claudio Fanni, Carlos Ferrarotti, Claudia Fossataro, Federica Fossataro, Katarzyna Fulek, Michal Fulek, Pawel Gac, Martyna Gachowska, Ignacio Garcia Juarez, Marco Gatti, Natalia Gorelik, Alexia Maria Goulianou, Aghiles Hamroun, Nicolas Herinirina, Krzysztof Kraik, Dominik Krupka, Quentin Holay, Felipe Kitamura, Michail E Klontzas, Anna Kompanowska, Rafal Kompanowski, Alexandre Lefevre, Tristan Lemke, Maximilian Lindholz, Lukas Muller, Piotr Macek, Marcus Makowski, Luigi Mannacio, Aymen Meddeb, Antonio Natale, Beatrice Nguema Edzang, Adriana Ojeda, Yae Won Park, Federica Piccione, Andrea Ponsiglione, Malgorzata Poreba, Rafal Poreba, Philipp Prucker, Jean Pierre Pruvo, Rosa Alba Pugliesi, Feno Hasina Rabemanorintsoa, Vasileios Rafailidis, Katarzyna Resler, Jan Rotkegel, Luca Saba, Ezann Siebert, Arnaldo Stanzione, Ali Fuat Tekin, Liz Toapanta Yanchapaxi, Matthaios Triantafyllou, Ekaterini Tsaoulia, Evangelia Vassalou, Federica Vernuccio, Johan Wasselius, Weilang Wang, Szymon Urban, Adrian Wlodarczak, Szymon Wlodarczak, Andrzej Wysocki, Lina Xu, Tomasz Zatonski, Shuhang Zhang, Sebastian Ziegelmayer, Gregory Kuchcinski, Keno K Bressem', 'link': 'https://arxiv.org/abs/2507.22939', 'abstract': 'Rationale and Objectives: To develop and validate PARROT (Polyglottal Annotated Radiology Reports for Open Testing), a large, multicentric, open-access dataset of fictional radiology reports spanning multiple languages for testing natural language processing applications in radiology. Materials and Methods: From May to September 2024, radiologists were invited to contribute fictional radiology reports following their standard reporting practices. Contributors provided at least 20 reports with associated metadata including anatomical region, imaging modality, clinical context, and for non-English reports, English translations. All reports were assigned ICD-10 codes. A human vs. AI report differentiation study was conducted with 154 participants (radiologists, healthcare professionals, and non-healthcare professionals) assessing whether reports were human-authored or AI-generated. Results: The dataset comprises 2,658 radiology reports from 76 authors across 21 countries and 13 languages. Reports cover multiple imaging modalities (CT: 36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%) being most prevalent. In the differentiation study, participants achieved 53.9% accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated reports, with radiologists performing significantly better (56.9%, 95% CI: 53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the largest open multilingual radiology report dataset, enabling development and validation of natural language processing applications across linguistic, geographic, and clinical boundaries without privacy constraints.', 'abstract_zh': '研究背景与目标：开发并验证PARROT（Polyglottal Annotated Radiology Reports for Open Testing）数据集，该数据集包含多语言虚构放射报告，旨在测试放射学领域自然语言处理应用。材料与方法：从2024年5月至9月，邀请放射ologist按照其标准报告实践提交虚构的放射报告。贡献者提供了至少20份报告及其元数据，包括解剖区域、成像模态、临床背景，以及其他语言报告的英语翻译。所有报告均分配了ICD-10编码。进行了一项人类报告与AI报告区分研究，共有154名参与者（放射ologist、医疗保健专业人员和非医疗保健专业人员）评估报告是由人类撰写还是由AI生成的。结果：数据集包含来自76位作者、跨越21个国家和13种语言的2,658份放射报告。报告涵盖了多种成像模态（CT：36.1%，MRI：22.8%，X线摄影：19.0%，超声：16.8%），最常见的解剖区域依次为胸部（19.9%）、腹部（18.6%）、头部（17.3%）和骨盆（14.1%）。在区分研究中，参与者在区分人类撰写和AI生成的报告方面达到了53.9%的准确性（95% CI：50.7%-57.1%），其中放射ologist的表现显著优于其他组别（56.9%，95% CI：53.3%-60.6%，p<0.05）。结论：PARROT代表了最大的开源多语言放射报告数据集，可以在不影响隐私保护的情况下跨越语言、地理和临床边界开发和验证自然语言处理应用。', 'title_zh': 'PARROT: 一个开源多语言放射学报告数据集'}
{'arxiv_id': 'arXiv:2507.22938', 'title': 'A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents', 'authors': 'Sumit Soman, H. G. Ranjani, Sujoy Roychowdhury, Venkata Dharma Surya Narayana Sastry, Akshat Jain, Pranav Gangrade, Ayaaz Khan', 'link': 'https://arxiv.org/abs/2507.22938', 'abstract': 'Question-Answering (QA) from technical documents often involves questions whose answers are present in figures, such as flowcharts or flow diagrams. Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such questions. We leverage graph representations of flowcharts obtained from Visual large Language Models (VLMs) and incorporate them in a text-based RAG system to show that this approach can enable image retrieval for QA in the telecom domain. We present the end-to-end approach from processing technical documents, classifying image types, building graph representations, and incorporating them with the text embedding pipeline for efficient retrieval. We benchmark the same on a QA dataset created based on proprietary telecom product information documents. Results show that the graph representations obtained using a fine-tuned VLM model have lower edit distance with respect to the ground truth, which illustrate the robustness of these representations for flowchart images. Further, the approach for QA using these representations gives good retrieval performance using text-based embedding models, including a telecom-domain adapted one. Our approach also alleviates the need for a VLM in inference, which is an important cost benefit for deployed QA systems.', 'abstract_zh': '来自技术文档的问答（QA）往往涉及其答案包含在流程图或流程图中的问题。基于文本的检索增强生成（RAG）系统可能无法回答此类问题。我们利用从视觉大规模语言模型（VLMs）获得的流程图的图表示，并将其纳入基于文本的RAG系统中，以展示此方法可以实现电信领域中图像检索的QA。我们提出了从处理技术文档、分类图像类型、构建图表示到将它们与文本嵌入管道结合的端到端方法，以实现高效检索。我们在基于专有电信产品信息文档创建的QA数据集上进行了基准测试。结果显示，使用微调后的VLM模型获得的图表示与真实值的编辑距离较低，这表明这些表示对于流程图图像的鲁棒性较强。此外，使用这些表示进行的问答方法能够使用基于文本的嵌入模型（包括一个适应电信领域模型）实现良好的检索性能。我们的方法还减轻了推理时对VLM的需求，这是部署的问答系统中的一个重要成本优势。', 'title_zh': '基于图的方法：电信文档流程图中的多模态问答'}
{'arxiv_id': 'arXiv:2507.22937', 'title': 'CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering', 'authors': 'Jinkun Zhao, Yuanshuai Wang, Xingjian Zhang, Ruibo Chen, Xingchuang Liao, Junle Wang, Lei Huang, Kui Zhang, Wenjun Wu', 'link': 'https://arxiv.org/abs/2507.22937', 'abstract': "With the rapid evolution of artificial intelligence, AIOps has emerged as a prominent paradigm in DevOps. Lots of work has been proposed to improve the performance of different AIOps phases. However, constrained by domain-specific knowledge, a single model can only handle the operation requirement of a specific task,such as log parser,root cause analysis. Meanwhile, combining multiple models can achieve more efficient results, which have been proved in both previous ensemble learning and the recent LLM training domain. Inspired by these works,to address the similar challenges in AIOPS, this paper first proposes a collaboration-of-expert framework(CoE-Ops) incorporating a general-purpose large language model task classifier. A retrieval-augmented generation mechanism is introduced to improve the framework's capability in handling both Question-Answering tasks with high-level(Code,build,Test,etc.) and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed method is implemented in the AIOps domain, and extensive experiments are conducted on the DevOps-EVAL dataset. Experimental results demonstrate that CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement over single AIOps models in DevOps problem resolution, and outperforms larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.", 'abstract_zh': '基于通用大型语言模型任务分类器的操作员合作框架（CoE-Ops）在AIOps中的应用', 'title_zh': 'CoE-Ops: 基于LLM的专家协作以实现AIOps问答'}
{'arxiv_id': 'arXiv:2507.22936', 'title': 'Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis', 'authors': 'Md Talha Mohsin', 'link': 'https://arxiv.org/abs/2507.22936', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide variety of Financial Natural Language Processing (FinNLP) tasks. However, systematic comparisons among widely used LLMs remain underexplored. Given the rapid advancement and growing influence of LLMs in financial analysis, this study conducts a thorough comparative evaluation of five leading LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the 'Magnificent Seven' technology companies. We create a set of domain-specific prompts and then use three methodologies to evaluate model performance: human annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity, Jaccard), and model behavior diagnostics (prompt-level variance and across-model similarity). The results show that GPT gives the most coherent, semantically aligned, and contextually relevant answers; followed by Claude and Perplexity. Gemini and DeepSeek, on the other hand, have more variability and less agreement. Also, the similarity and stability of outputs change from company to company and over time, showing that they are sensitive to how prompts are written and what source material is used.", 'abstract_zh': '大规模语言模型（LLMs）在金融自然语言处理（FinNLP）任务中展现了卓越的能力。然而，广泛使用的LLMs之间的系统性比较仍被忽视。鉴于LLMs在金融分析中的快速发展和影响，本研究使用来自“壮丽七 powerhouse”科技公司的10-K filings，对五种领先的LLM（GPT、Claude、Perplexity、Gemini和DeepSeek）进行了全面比较评估。我们创建了一组领域特定的提示，并使用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示级别差异性和模型间相似性）。结果表明，GPT给出的答案最为连贯、语义对齐且相关；其次是Claude和Perplexity。相比之下，Gemini和DeepSeek表现出更大差异性和较低的一致性。此外，输出的相似性和稳定性会因公司而异并在时间上变化，表明它们对提示的写法和所用数据源非常敏感。', 'title_zh': '评估大型语言模型（LLMs）在金融NLP中的表现：基于财务报告分析的 comparative study'}
{'arxiv_id': 'arXiv:2507.22935', 'title': 'Trusted Knowledge Extraction for Operations and Maintenance Intelligence', 'authors': 'Kathleen Mealey, Jonathan A. Karr Jr., Priscila Saboia Moreira, Paul R. Brenner, Charles F. Vardeman II', 'link': 'https://arxiv.org/abs/2507.22935', 'abstract': 'Deriving operational intelligence from organizational data repositories is a key challenge due to the dichotomy of data confidentiality vs data integration objectives, as well as the limitations of Natural Language Processing (NLP) tools relative to the specific knowledge structure of domains such as operations and maintenance. In this work, we discuss Knowledge Graph construction and break down the Knowledge Extraction process into its Named Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation Extraction functional components. We then evaluate sixteen NLP tools in concert with or in comparison to the rapidly advancing capabilities of Large Language Models (LLMs). We focus on the operational and maintenance intelligence use case for trusted applications in the aircraft industry. A baseline dataset is derived from a rich public domain US Federal Aviation Administration dataset focused on equipment failures or maintenance requirements. We assess the zero-shot performance of NLP and LLM tools that can be operated within a controlled, confidential environment (no data is sent to third parties). Based on our observation of significant performance limitations, we discuss the challenges related to trusted NLP and LLM tools as well as their Technical Readiness Level for wider use in mission-critical industries such as aviation. We conclude with recommendations to enhance trust and provide our open-source curated dataset to support further baseline testing and evaluation.', 'abstract_zh': '从组织数据仓库中提取运营智能是一项关键挑战，由于数据保密性与数据集成目标之间的二元性，以及自然语言处理（NLP）工具相对于运营和维护等特定领域知识结构的局限性。在本工作中，我们讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指解析、命名实体链接和关系提取的功能组件。然后，我们评估了十六种NLP工具，并将其与大型语言模型（LLMs）的快速进步能力进行对比。我们重点关注航空行业可信应用中的运营和维护智能用例。基线数据集源自一个丰富的美国联邦航空管理局公开领域数据集，专注于设备故障或维护需求。我们评估了可在受控、保密环境中运行的NLP和LLM工具的零样本性能（不向第三方发送数据）。基于我们对显著性能限制的观察，我们讨论了可信NLP和LLM工具面临的挑战及其在航空等关键行业更广泛应用的技术成熟度水平。最后，我们提出了增强信任的建议，并提供了一个开源的精选数据集，以支持进一步的基线测试和评估。', 'title_zh': '可信知识提取用于运营与维护intelligence'}
{'arxiv_id': 'arXiv:2507.22934', 'title': 'Deep Learning Approaches for Multimodal Intent Recognition: A Survey', 'authors': 'Jingwei Zhao, Yuhua Wen, Qifei Li, Minchi Hu, Yingying Zhou, Jingyao Xue, Junyang Wu, Yingming Gao, Zhengqi Wen, Jianhua Tao, Ya Li', 'link': 'https://arxiv.org/abs/2507.22934', 'abstract': "Intent recognition aims to identify users' underlying intentions, traditionally focusing on text in natural language processing. With growing demands for natural human-computer interaction, the field has evolved through deep learning and multimodal approaches, incorporating data from audio, vision, and physiological signals. Recently, the introduction of Transformer-based models has led to notable breakthroughs in this domain. This article surveys deep learning methods for intent recognition, covering the shift from unimodal to multimodal techniques, relevant datasets, methodologies, applications, and current challenges. It provides researchers with insights into the latest developments in multimodal intent recognition (MIR) and directions for future research.", 'abstract_zh': '意图识别旨在识别用户背后的目的，传统上聚焦于自然语言处理中的文本。随着对自然人机交互需求的增加，该领域通过深度学习和多模态方法得到了发展， Incorporating 数据从音频、视觉和生理信号中获得。最近，基于Transformer的模型的引入在该领域取得了显著突破。本文综述了意图识别中的深度学习方法，涵盖了从单模态到多模态技术的转变、相关数据集、方法学、应用以及当前挑战。为研究人员提供了多模态意图识别（MIR）最新发展的洞察和未来研究方向。', 'title_zh': '多模态意图识别的深度学习方法综述'}
{'arxiv_id': 'arXiv:2507.22933', 'title': 'Augmented Vision-Language Models: A Systematic Review', 'authors': 'Anthony C Davis, Burhan Sadiq, Tianmin Shu, Chien-Ming Huang', 'link': 'https://arxiv.org/abs/2507.22933', 'abstract': 'Recent advances in visual-language machine learning models have demonstrated exceptional ability to use natural language and understand visual scenes by training on large, unstructured datasets. However, this training paradigm cannot produce interpretable explanations for its outputs, requires retraining to integrate new information, is highly resource-intensive, and struggles with certain forms of logical reasoning. One promising solution involves integrating neural networks with external symbolic information systems, forming neural symbolic systems that can enhance reasoning and memory abilities. These neural symbolic systems provide more interpretable explanations to their outputs and the capacity to assimilate new information without extensive retraining. Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural component, augmented by external systems, offers a pragmatic approach to realizing the benefits of neural-symbolic integration. This systematic literature review aims to categorize techniques through which visual-language understanding can be improved by interacting with external symbolic information systems.', 'abstract_zh': 'Recent advances in 视觉-语言机器学习模型已经在大规模未结构化数据集上训练，展示了使用自然语言理解和处理视觉场景的出色能力。然而，这种训练 paradigm 无法为输出生成可解释的解释，需要重新训练以整合新信息，并且在处理某些形式的逻辑推理方面存在困难。一种有前途的解决方案是将神经网络与外部符号信息系统的结合，形成能够增强推理和记忆能力的神经符号系统。这些神经符号系统可以为输出提供更可解释的解释，并且能够在不进行大量重新训练的情况下吸收新信息。利用强大的预训练视觉-语言模型（VLMs）作为核心神经组件，并辅以外部系统，为实现神经符号集成的好处提供了一个实用的方法。本系统文献综述旨在通过与外部符号信息系统的交互来改进视觉-语言理解的方法进行分类。', 'title_zh': '增强视觉-语言模型：一项系统性回顾'}
{'arxiv_id': 'arXiv:2507.22931', 'title': 'Enhancing RAG Efficiency with Adaptive Context Compression', 'authors': 'Shuyu Guo, Zhaochun Ren', 'link': 'https://arxiv.org/abs/2507.22931', 'abstract': 'Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but incurs significant inference costs due to lengthy retrieved contexts. While context compression mitigates this issue, existing methods apply fixed compression rates, over-compressing simple queries or under-compressing complex ones. We propose Adaptive Context Compression for RAG (ACC-RAG), a framework that dynamically adjusts compression rates based on input complexity, optimizing inference efficiency without sacrificing accuracy. ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with a context selector to retain minimal sufficient information, akin to human skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms fixed-rate methods and matches/unlocks over 4 times faster inference versus standard RAG while maintaining or improving accuracy.', 'abstract_zh': 'Retrieval-augmented generation with adaptive context compression for large language models', 'title_zh': '适配性上下文压缩增强RAG效率'}
{'arxiv_id': 'arXiv:2507.22928', 'title': 'How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding', 'authors': 'Xi Chen, Aske Plaat, Niki van Stein', 'link': 'https://arxiv.org/abs/2507.22928', 'abstract': 'Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on multi-step tasks, yet whether the generated "thoughts" reflect the true internal reasoning process is unresolved. We present the first feature-level causal study of CoT faithfulness. Combining sparse autoencoders with activation patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B while they tackle GSM8K math problems under CoT and plain (noCoT) prompting. Swapping a small set of CoT-reasoning features into a noCoT run raises answer log-probabilities significantly in the 2.8B model, but has no reliable effect in 70M, revealing a clear scale threshold. CoT also leads to significantly higher activation sparsity and feature interpretability scores in the larger model, signalling more modular internal computation. For example, the model\'s confidence in generating correct answers improves from 1.2 to 4.3. We introduce patch-curves and random-feature patching baselines, showing that useful CoT information is not only present in the top-K patches but widely distributed. Overall, our results indicate that CoT can induce more interpretable internal structures in high-capacity LLMs, validating its role as a structured prompting method.', 'abstract_zh': 'Chain-of-thought (CoT) 提示增强大规模语言模型在多步任务上的准确性，但生成的“思考过程”是否反映真实的内部推理过程尚不明确。我们首次进行了特征层面的 CoT 忠实性因果研究。结合稀疏自编码器与激活补丁技术，我们在 Pythia-70M 和 Pythia-2.8B 处理 GSM8K 数学问题时，提取了单义特征，并分别在 CoT 和无 CoT 提示下进行了比较。用少量的 CoT 推理特征替换无 CoT 运行中的特征，在 2.8B 模型中显著提高了答案对数概率，而对 70M 模型没有可靠的影响，揭示了一个明确的规模阈值。此外，CoT 还在较大的模型中导致显著更高的激活稀疏性和特征可解释性评分，表明内部计算更加模块化。例如，模型生成正确答案的信心从 1.2 提高到 4.3。我们引入了补丁曲线和随机特征补丁基准，表明有用的 CoT 信息不仅存在于前 K 补丁中，而是广泛分布的。总体而言，我们的结果表明 CoT 可以在高容量的 LLM 中诱导出更可解释的内部结构，验证了其作为结构化提示方法的角色。', 'title_zh': 'Chain of Thought是如何思考的？基于稀疏自编码的链式推理机理可解释性'}
{'arxiv_id': 'arXiv:2507.22925', 'title': 'Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents', 'authors': 'Haoran Sun, Shaoning Zeng', 'link': 'https://arxiv.org/abs/2507.22925', 'abstract': 'Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.', 'abstract_zh': '长时记忆是影响大型语言模型代理（LLM代理）推理能力的关键因素。通过有效集成过往交互的内存机制可以显著增强LLM代理的决策能力和上下文连贯性。尽管近期研究在内存存储和检索方面取得了进展，如将内存编码为密集向量以进行基于相似性的搜索或以图的形式组织知识，但这些方法往往在结构化内存组织和高效检索方面存在不足。为解决这些问题，我们提出了一种分层记忆（H-MEM）架构，该架构基于语义抽象程度多级组织和更新内存。每个记忆向量嵌入了一个位置索引编码，指向其在下一层相关的子记忆。在推理阶段，基于索引的路由机制可以实现逐层高效检索，而无需进行耗时的相似性计算。我们在LoCoMo数据集的五个任务设置上评估了该方法。实验结果表明，我们的方法在所有基准方法中表现出优越性，证明了其在长期对话场景中的有效性。', 'title_zh': '层级记忆以提高大规模语言模型代理长期推理效率'}
{'arxiv_id': 'arXiv:2507.22923', 'title': 'How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting', 'authors': 'Aman Gupta, Yingying Zhuang, Zhou Yu, Ziji Zhang, Anurag Beniwal', 'link': 'https://arxiv.org/abs/2507.22923', 'abstract': 'Despite advances in the multilingual capabilities of Large Language Models (LLMs), their performance varies substantially across different languages and tasks. In multilingual retrieval-augmented generation (RAG)-based systems, knowledge bases (KB) are often shared from high-resource languages (such as English) to low-resource ones, resulting in retrieved information from the KB being in a different language than the rest of the context. In such scenarios, two common practices are pre-translation to create a mono-lingual prompt and cross-lingual prompting for direct inference. However, the impact of these choices remains unclear. In this paper, we systematically evaluate the impact of different prompt translation strategies for classification tasks with RAG-enhanced LLMs in multilingual systems. Experimental results show that an optimized prompting strategy can significantly improve knowledge sharing across languages, therefore improve the performance on the downstream classification task. The findings advocate for a broader utilization of multilingual resource sharing and cross-lingual prompt optimization for non-English languages, especially the low-resource ones.', 'abstract_zh': '尽管大规模语言模型（LLMs）在多语言能力方面取得了进步，但其在不同语言和任务上的性能差异仍然很大。在基于多语言检索增强生成（RAG）的系统中，通常会从高资源语言（如英语）向低资源语言共享知识库（KB），导致从KB检索到的信息与上下文中的其余部分语言不同。在这种情况下，两种常见的做法是预先翻译以创建单语言提示和跨语言提示以进行直接推理。然而，这些选择的影响尚不明确。在本文中，我们系统地评估了不同提示翻译策略对带有RAG增强的大规模语言模型的跨语言分类任务的影响。实验结果表明，优化的提示策略可以显著改善跨语言的知识共享，从而提高下游分类任务的性能。这些发现倡导更广泛地利用多语言资源共享和跨语言提示优化，特别是一些低资源语言。', 'title_zh': '如何翻译以及在哪里翻译？跨语言LLM提示中翻译策略的影响'}
{'arxiv_id': 'arXiv:2507.22922', 'title': 'Predicting stock prices with ChatGPT-annotated Reddit sentiment', 'authors': 'Mateusz Kmak, Kamil Chmurzyński, Kamil Matejuk, Paweł Kotzbach, Jan Kocoń', 'link': 'https://arxiv.org/abs/2507.22922', 'abstract': "The surge of retail investor activity on social media, exemplified by the 2021 GameStop short squeeze, raised questions about the influence of online sentiment on stock prices. This paper explores whether sentiment derived from social media discussions can meaningfully predict stock market movements. We focus on Reddit's r/wallstreetbets and analyze sentiment related to two companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's role, we employ two existing text-based sentiment analysis methods and introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model designed to better interpret the informal language and emojis prevalent in social media discussions. We use correlation and causality metrics to determine these models' predictive power. Surprisingly, our findings suggest that social media sentiment has only a weak correlation with stock prices. At the same time, simpler metrics, such as the volume of comments and Google search trends, exhibit stronger predictive signals. These results highlight the complexity of retail investor behavior and suggest that traditional sentiment analysis may not fully capture the nuances of market-moving online discussions.", 'abstract_zh': '社交媒体上零售投资者活动激增，以2021年GameStop逼空为例，引发了线上情绪对股价影响的疑问。本文探讨社交媒体讨论中获取的情绪是否能有效预测股市变动。我们聚焦Reddit的r/wallstreetbets板块，分析GameStop（GME）和AMC Entertainment（AMC）两家公司的相关情绪。为了评估情绪的作用，我们使用了两种现有的基于文本的情绪分析方法，并引入了一种根据ChatGPT标注和微调的RoBERTa模型，旨在更好地解读社交媒体讨论中普遍存在的非正式语言和表情符号。我们利用相关性和因果关系指标来确定这些模型的预测能力。令我们惊讶的是，研究发现社交媒体情绪与股价之间的相关性较弱，而简单的评论数量和谷歌搜索趋势等指标则显示出更强的预测信号。这些结果突显了零售投资者行为的复杂性，并暗示传统的情绪分析可能未能全面捕捉到能够推动市场讨论的微妙之处。', 'title_zh': '使用ChatGPT注释的Reddit情绪预测股票价格'}
{'arxiv_id': 'arXiv:2507.22921', 'title': 'Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers', 'authors': 'Lee Harris', 'link': 'https://arxiv.org/abs/2507.22921', 'abstract': "Language models can capture complex relationships in given text, but these are notorious for being costly and for producing information that does not exist (i.e., hallucinations). Furthermore, the resources invested into producing this information would be wasted if it were incorrect. We address these issues by proposing, implementing, and applying the Language Model Chain (LMC) algorithm. In this, a language model's response to a given prompt about given text is only correct if it exists in the collection of possible (i.e., candidate) answers, and text corresponding to incorrect responses is fed into a more predictive (but slower) language model. This process is repeated for a collection of language models, or until all predictions about the text are correct. We used the LMC algorithm to extract patient dates of birth from medical documents, and combining a collection of language models in a multi-stage cascade significantly increased prediction speed and accuracy over individual language models, while greatly reducing the number of corresponding hallucinations. We believe that the novel LMC algorithm significantly contributes to the knowledge extraction field, and that this should be explored much further in the future.", 'abstract_zh': '语言模型可以通过捕捉给定文本中的复杂关系，但它们经常成本高昂并且会产生不存在的信息（即幻觉）。此外，如果这些信息不正确，投入的资源将被浪费。我们通过提出、实施并应用语言模型链（LMC）算法来解决这些问题。在该算法中，只有当语言模型的响应存在于可能的答案集合中时，其响应才是正确的；不正确的响应则会被输入到更具预测性（但速度较慢）的语言模型中。这一过程可以应用于多个语言模型，直到所有关于文本的预测都正确为止。我们使用LMC算法从医疗文档中提取患者出生日期，并且将多个语言模型在多阶段级联中使用，显著提高了预测速度和准确性，同时大幅减少了相应的幻觉现象。我们认为，新颖的LMC算法对知识抽取领域有重要贡献，并且未来应对此进行更深入的研究。', 'title_zh': '使用级联语言模型链和候选答案进行快速准确的上下文知识抽取'}
{'arxiv_id': 'arXiv:2507.22920', 'title': 'Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey', 'authors': 'Jindong Li, Yali Fu, Jiahong Liu, Linxiao Cao, Wei Ji, Menglin Yang, Irwin King, Ming-Hsuan Yang', 'link': 'https://arxiv.org/abs/2507.22920', 'abstract': 'The rapid advancement of large language models (LLMs) has intensified the need for effective mechanisms to transform continuous multimodal data into discrete representations suitable for language-based processing. Discrete tokenization, with vector quantization (VQ) as a central approach, offers both computational efficiency and compatibility with LLM architectures. Despite its growing importance, there is a lack of a comprehensive survey that systematically examines VQ techniques in the context of LLM-based systems. This work fills this gap by presenting the first structured taxonomy and analysis of discrete tokenization methods designed for LLMs. We categorize 8 representative VQ variants that span classical and modern paradigms and analyze their algorithmic principles, training dynamics, and integration challenges with LLM pipelines. Beyond algorithm-level investigation, we discuss existing research in terms of classical applications without LLMs, LLM-based single-modality systems, and LLM-based multimodal systems, highlighting how quantization strategies influence alignment, reasoning, and generation performance. In addition, we identify key challenges including codebook collapse, unstable gradient estimation, and modality-specific encoding constraints. Finally, we discuss emerging research directions such as dynamic and task-adaptive quantization, unified tokenization frameworks, and biologically inspired codebook learning. This survey bridges the gap between traditional vector quantization and modern LLM applications, serving as a foundational reference for the development of efficient and generalizable multimodal systems. A continuously updated version is available at: this https URL.', 'abstract_zh': '大型语言模型（LLMs）的迅速发展加剧了将连续多模态数据转换为适合基于语言处理的离散表示的有效机制的需求。作为中心方法的向量量化（VQ）提供了计算效率并兼容LLM架构。尽管其重要性日益增加，但缺乏系统地在LLM系统背景下审查VQ技术的全面综述。本工作通过呈现针对LLMs设计的第一个结构化分类和分析填补了这一空白。我们分类了8种代表性的VQ变体，涵盖经典和现代范式，并分析了它们的算法原理、训练动态及其与LLM管道的集成挑战。除了算法层面的调查，我们还讨论了现有研究在没有LLMs的经典应用、基于LLMs的单模态系统以及基于LLMs的多模态系统中的表现，强调量化策略如何影响对齐、推理和生成性能。此外，我们确定了关键挑战，包括码本崩溃、梯度估计不稳以及模态特定编码约束。最后，我们讨论了新兴的研究方向，包括动态和任务自适应量化、统一的分词框架以及受生物学启发的码本学习。本综述填补了传统向量量化与现代LLM应用之间的空白，为高效和可泛化的多模态系统的发展提供了基础参考。更新版本请参阅：this https URL。', 'title_zh': '离散令牌化为多模态LLMs：综述'}
{'arxiv_id': 'arXiv:2507.22919', 'title': 'A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations', 'authors': 'Qixuan Hu, Xumou Zhang, Jinman Kim, Florence Bourgeois, Adam G. Dunn', 'link': 'https://arxiv.org/abs/2507.22919', 'abstract': 'Objectives: With accurate estimates of expected safety results, clinical trials could be designed to avoid terminations and limit exposing participants to unnecessary risks. We evaluated methods for predicting serious adverse event (SAE) results in clinical trials using information only from their registrations prior to the trial. Material and Methods: We analysed 22,107 two-arm parallel interventional clinical trials from this http URL with structured summary results. Two prediction models were developed: a classifier predicting will experimental arm have higher SAE rates (area under the receiver operating characteristic curve; AUC) than control arm, and a regression model to predict the proportion of SAEs in control arms (root mean squared error; RMSE). A transfer learning approach using pretrained language models (e.g., ClinicalT5, BioBERT) was used for feature extraction, combined with downstream model for prediction. To maintain semantic representation in long trial texts exceeding localised language model input limits, a sliding window method was developed for embedding extraction. Results: The best model (ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a higher proportion of patients with SAEs. When predicting proportion of participants experiencing SAE in the control arm, the same model achieved RMSE of 18.6%. The sliding window approach consistently outperformed methods without it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across 12 regressors, the average absolute RMSE reduction was 1.58%. Discussion: Summary results data available at this http URL remains underutilised. The potential to estimate results of trials before they start is an opportunity to improve trial design and flag discrepancies between expected and reported safety results.', 'abstract_zh': '研究目的：通过准确估计预期的安全结果，临床试验可以被设计以避免提前终止并限制参与者面临不必要的风险。我们评估了仅使用临床试验注册信息（在试验前）来预测严重不良事件（SAE）结果的方法。材料与方法：我们分析了从这个网址获得的22,107项两臂并行的干预性临床试验，这些试验具有结构化的总结结果。开发了两种预测模型：一种分类器预测实验臂的SAE率是否高于对照臂（面积下接收器操作特征曲线下面积；AUC），一种回归模型预测对照臂的SAE比例（均方根误差；RMSE）。使用预训练语言模型（如ClinicalT5、BioBERT）进行特征提取，并结合下游模型进行预测。为保持长文本试验证据的语义表示，开发了一种滑动窗口方法进行嵌入提取。结果：最佳模型（ClinicalT5+Transformer+MLP）在预测哪一试验臂的患者中有更高比例的SAE方面达到了77.6%的AUC。在预测对照臂中经历SAE的参与者比例时，同一模型获得了18.6%的RMSE。滑动窗口方法在所有情况下都表现优于未使用该方法的方法。在12个分类器中，平均绝对AUC提升为2.00%，在12个回归器中，平均绝对RMSE减少为1.58%。讨论：该网址提供的总结结果数据尚未充分利用。在试验开始前估计试验结果的可能性为改善试验设计并指出预期与报告的安全结果之间的差异提供了机会。', 'title_zh': '一种新的语言模型用于预测临床试验前瞻性注册中的严重不良事件结果'}
{'arxiv_id': 'arXiv:2507.22917', 'title': 'Reading Between the Timelines: RAG for Answering Diachronic Questions', 'authors': 'Kwun Hang Lau, Ruiyuan Zhang, Weijie Shi, Xiaofang Zhou, Xiaojun Cheng', 'link': 'https://arxiv.org/abs/2507.22917', 'abstract': "While Retrieval-Augmented Generation (RAG) excels at injecting static, factual knowledge into Large Language Models (LLMs), it exhibits a critical deficit in handling longitudinal queries that require tracking entities and phenomena across time. This blind spot arises because conventional, semantically-driven retrieval methods are not equipped to gather evidence that is both topically relevant and temporally coherent for a specified duration. We address this challenge by proposing a new framework that fundamentally redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by disentangling a user's query into its core subject and its temporal window. It then employs a specialized retriever that calibrates semantic matching against temporal relevance, ensuring the collection of a contiguous evidence set that spans the entire queried period. To enable rigorous evaluation of this capability, we also introduce the Analytical Diachronic Question Answering Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus of real and synthetic financial news. Empirical results on ADQAB show that our approach yields substantial gains in answer accuracy, surpassing standard RAG implementations by 13% to 27%. This work provides a validated pathway toward RAG systems capable of performing the nuanced, evolutionary analysis required for complex, real-world questions. The dataset and code for this study are publicly available at this https URL.", 'abstract_zh': '尽管检索增强生成（RAG）在向大型语言模型（LLMs）注入静态事实性知识方面表现出色，但在处理需要跨时间追踪实体和现象的纵向查询时却存在着关键缺陷。这种盲点是因为传统的基于语义的检索方法无法收集既主题相关又时间连贯的证据，以满足特定的时间跨度需求。我们通过提出一种新的框架来解决这一挑战，该框架从根本上重新设计了RAG管道，使其融入时间逻辑。我们的方法首先将用户查询分解为核心主题和时间窗口。然后使用一个专门的检索器，该检索器根据时间相关性校准语义匹配，确保收集到的时间连续的证据集覆盖整个查询时期。为了对这一能力进行严格的评估，我们还引入了分析历时问答基准（ADQAB），这是一个基于真实和合成金融新闻混合语料库的具有挑战性的评估套件。ADQAB上的实验证据显示，我们的方法在答案准确性上取得了显著提升，相较于标准的RAG实现提高了13%至27%。本项工作为开发能够进行复杂现实问题所需细致进化分析的RAG系统提供了经过验证的路径。该研究的数据集和代码可在此网址获取。', 'title_zh': '跨越时间线的阅读：基于RAG的历时性问题回答'}
{'arxiv_id': 'arXiv:2507.22916', 'title': 'From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems', 'authors': 'Kun Jiang', 'link': 'https://arxiv.org/abs/2507.22916', 'abstract': "In our previous work, we proposed a novel neuron model based on symmetric differential equations and demonstrated its potential as an efficient signal propagator. Building upon that foundation, the present study delves deeper into the intrinsic dynamics and functional diversity of this model. By systematically exploring the parameter space and employing a range of mathematical analysis tools, we theoretically reveal the system 's core property of functional duality. Specifically, the model exhibits two distinct trajectory behaviors: one is asymptotically stable, corresponding to a reliable signal propagator; the other is Lyapunov stable, characterized by sustained self-excited oscillations, functioning as a signal generator. To enable effective monitoring and prediction of system states during simulations, we introduce a novel intermediate-state metric termed on-road energy. Simulation results confirm that transitions between the two functional modes can be induced through parameter adjustments or modifications to the connection structure. Moreover, we show that oscillations can be effectively suppressed by introducing external signals. These findings draw a compelling parallel to the dual roles of biological neurons in both information transmission and rhythm generation, thereby establishing a solid theoretical basis and a clear functional roadmap for the broader application of this model in neuromorphic engineering.", 'abstract_zh': '基于对称微分方程的新颖神经元模型的内在动力学与功能多样性研究', 'title_zh': '从传播子到振荡器：对称微分方程在神经系统中的双重角色'}
{'arxiv_id': 'arXiv:2507.22915', 'title': 'Theoretical Foundations and Mitigation of Hallucination in Large Language Models', 'authors': 'Esmail Gumaan', 'link': 'https://arxiv.org/abs/2507.22915', 'abstract': 'Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretical analyses. We distinguish between intrinsic and extrinsic hallucinations, and define a \\textit{hallucination risk} for models. We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes and Rademacher complexity). We then survey detection strategies for hallucinations, such as token-level uncertainty estimation, confidence calibration, and attention alignment checks. On the mitigation side, we discuss approaches including retrieval-augmented generation, hallucination-aware fine-tuning, logit calibration, and the incorporation of fact-verification modules. We propose a unified detection and mitigation workflow, illustrated with a diagram, to integrate these strategies. Finally, we outline evaluation protocols for hallucination, recommending datasets, metrics, and experimental setups to quantify and reduce hallucinations. Our work lays a theoretical foundation and practical guidelines for addressing the crucial challenge of hallucination in LLMs.', 'abstract_zh': '大型语言模型中的幻觉指的是生成与输入或现实世界事实不相符的内容。本文对大型语言模型中的幻觉提供了严格的处理，包括形式定义和理论分析。我们区分内在幻觉和外在幻觉，并为模型定义了幻觉风险。我们使用学习理论框架（PAC-Bayes和Rademacher复杂性）推导出这一风险的界。然后，我们概述了幻觉检测策略，如标记级不确定性估计、置信度校准和注意力对齐检查。在缓解方面，我们讨论了包括检索增强生成、幻觉感知微调、logit校准以及事实验证模块纳入在内的方法。我们提出了一种统一的检测和缓解工作流，以图表形式阐明这些策略。最后，我们提出了幻觉评估协议，推荐了数据集、评价指标和实验设置，以量化和减少幻觉。我们的工作为解决大型语言模型中的幻觉问题奠定了理论基础并提供了实用指南。', 'title_zh': '大型语言模型中的幻觉理论基础及其缓解方法'}
{'arxiv_id': 'arXiv:2507.22913', 'title': 'A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models', 'authors': 'Jinyu Liu, Xiaoying Song, Diana Zhang, Jason Thomale, Daqing He, Lingzi Hong', 'link': 'https://arxiv.org/abs/2507.22913', 'abstract': 'Providing subject access to information resources is an essential function of any library management system. Large language models (LLMs) have been widely used in classification and summarization tasks, but their capability to perform subject analysis is underexplored. Multi-label classification with traditional machine learning (ML) models has been used for subject analysis but struggles with unseen cases. LLMs offer an alternative but often over-generate and hallucinate. Therefore, we propose a hybrid framework that integrates embedding-based ML models with LLMs. This approach uses ML models to (1) predict the optimal number of LCSH labels to guide LLM predictions and (2) post-edit the predicted terms with actual LCSH terms to mitigate hallucinations. We experimented with LLMs and the hybrid framework to predict the subject terms of books using the Library of Congress Subject Headings (LCSH). Experiment results show that providing initial predictions to guide LLM generations and imposing post-edits result in more controlled and vocabulary-aligned outputs.', 'abstract_zh': '为信息资源提供主题访问是任何图书馆管理系统的基本功能。大型语言模型（LLMs）在分类和总结任务中已被广泛应用，但在执行主题分析方面的能力尚未得到充分探索。传统机器学习（ML）模型的多标签分类已被用于主题分析，但难以应对未见过的情况。LLMs 提供了一种替代方案，但常常过度生成和虚构。因此，我们提出一种集成基于嵌入的机器学习模型与LLMs的混合框架。该方法利用机器学习模型来（1）预测LCSH标签的最佳数量以指导LLM预测，并（2）使用实际的LCSH术语进行后续编辑以减少虚构现象。我们使用LLMs和混合框架，基于美国国会图书馆主题 headings（LCSH）预测图书的主题术语。实验结果表明，提供初始预测以指导LLM生成，并实施后续编辑，可以得到更加可控和符合词汇表的输出。', 'title_zh': '基于嵌入表示回归模型与大规模语言模型的混合框架：主题分析集成'}
{'arxiv_id': 'arXiv:2507.22912', 'title': 'A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms', 'authors': 'Navid Yazdanjue, Morteza Rakhshaninejad, Hossein Yazdanjouei, Mohammad Sadegh Khorshidi, Mikko S. Niemela, Fang Chen, Amir H. Gandomi', 'link': 'https://arxiv.org/abs/2507.22912', 'abstract': 'Illegal marketplaces have increasingly shifted to concealed parts of the internet, including the deep and dark web, as well as platforms such as Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of illicit goods including drugs, weapons, and stolen credentials. Detecting and categorizing such content remains challenging due to limited labeled data, the evolving nature of illicit language, and the structural heterogeneity of online sources. This paper presents a hierarchical classification framework that combines fine-tuned language models with a semi-supervised ensemble learning strategy to detect and classify illicit marketplace content across diverse platforms. We extract semantic representations using ModernBERT, a transformer model for long documents, finetuned on domain-specific data from deep and dark web pages, Telegram channels, Subreddits, and Pastebin pastes to capture specialized jargon and ambiguous linguistic patterns. In addition, we incorporate manually engineered features such as document structure, embedded patterns including Bitcoin addresses, emails, and IPs, and metadata, which complement language model embeddings. The classification pipeline operates in two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random Forest, and SVM with entropy-based weighted voting to detect sales-related documents. The second stage further classifies these into drug, weapon, or credential sales. Experiments on three datasets, including our multi-source corpus, DUTA, and CoDA, show that our model outperforms several baselines, including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of 0.95388, demonstrating strong generalization, robustness under limited supervision, and effectiveness in real-world illicit content detection.', 'abstract_zh': '非法市场正逐渐转向互联网的隐蔽部分，包括深网、暗网，以及Telegram、Reddit和Pastebin等平台。这些渠道使毒品、武器和被盗凭据等非法商品的匿名交易成为可能。由于缺乏标注数据、非法用语的演变以及在线来源的结构性异质性，检测和分类此类内容仍然具有挑战性。本文 presents一种分层分类框架，结合了微调的语言模型与半监督集成学习策略，以跨多种平台检测和分类非法市场内容。', 'title_zh': '基于语言模型驱动的半监督集成框架：跨深/暗网和社会平台的非法市场检测'}
{'arxiv_id': 'arXiv:2507.22911', 'title': 'ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing', 'authors': 'Jinzhi Wang, Qingke Peng, Haozhou Li, Zeyuan Zeng, Qinfeng Song, Kaixuan Yang, Jiangbo Zhang, Yaoying Wang, Ruimeng Li, Biyi Zhou', 'link': 'https://arxiv.org/abs/2507.22911', 'abstract': "Electric power marketing customer service plays a critical role in addressing inquiries, complaints, and service requests. However, current systems, such as China's 95598 hotline, often struggle with slow response times, inflexible procedures, and limited accuracy in domain-specific tasks. While large language models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities, they lack the domain expertise and empathy required in this field. To bridge this gap, we introduce ElectriQ, the first benchmark designed to evaluate and enhance LLMs in electric power marketing scenarios. ElectriQ consists of a dialogue dataset covering six key service categories and introduces four evaluation metrics: professionalism, popularity, readability, and user-friendliness. We further incorporate a domain-specific knowledge base and propose a knowledge augmentation method to boost model performance. Experiments on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and augmented, can surpass GPT-4o in terms of professionalism and user-friendliness. ElectriQ establishes a comprehensive foundation for developing LLMs tailored to the needs of power marketing services.", 'abstract_zh': '电能营销客户服务在处理问询、投诉和服务请求方面发挥着关键作用。然而，当前的系统，如中国的95598热线，往往面临响应缓慢、程序僵化以及在特定领域任务上的准确性有限的问题。虽然大型语言模型（LLMs）如GPT-4o和Claude 3展示了强大的通用能力，但在这一领域缺乏专业知识和同理心。为了弥合这一差距，我们引入了ElectriQ，这是首个旨在评估和提升LLMs在电能营销场景中的基准测试。ElectriQ包含一个涵盖六类关键服务的对话数据集，并引入了四个评估指标：专业性、受欢迎度、易读性和用户友好性。我们进一步整合了领域专业知识库，并提出了一种知识增强方法以提升模型性能。对13种LLM的实验结果显示，经过微调和增强的小型模型，如LLama3-8B，在专业性和用户友好性方面可以超越GPT-4o。ElectriQ为开发满足电力营销服务需求的LLM奠定了全面的基础。', 'title_zh': 'ElectriQ: 评估大型语言模型在电力营销场景下响应能力的基准'}
{'arxiv_id': 'arXiv:2507.22910', 'title': 'Large Language Models in the Travel Domain: An Industrial Experience', 'authors': 'Sergio Di Meglio, Aniello Somma, Luigi Libero Lucio Starace, Fabio Scippacercola, Giancarlo Sperlì, Sergio Di Martino', 'link': 'https://arxiv.org/abs/2507.22910', 'abstract': 'Online property booking platforms are widely used and rely heavily on consistent, up-to-date information about accommodation facilities, often sourced from third-party providers. However, these external data sources are frequently affected by incomplete or inconsistent details, which can frustrate users and result in a loss of market. In response to these challenges, we present an industrial case study involving the integration of Large Language Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B, fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt. Both models were assessed based on their ability to generate consistent and homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision (98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet more concise content (249 vs. 277 words on average). However, this came at a significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB and $0.16/hour for Mistral 7B. Our findings provide practical insights into the trade-offs between model quality and resource efficiency, offering guidance for deploying LLMs in production environments and demonstrating their effectiveness in enhancing the consistency and reliability of accommodation data.', 'abstract_zh': '基于大型语言模型的在线房产预订平台数据整合工业案例研究：以FERVENTO的CALEIDOHOTELS平台为例', 'title_zh': '大型语言模型在旅游领域的应用：工业实践'}
{'arxiv_id': 'arXiv:2507.22908', 'title': 'A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection', 'authors': 'Abhishek Sawaika, Swetang Krishna, Tushar Tomar, Durga Pritam Suggisetti, Aditi Lal, Tanmaya Shrivastav, Nouhaila Innan, Muhammad Shafique', 'link': 'https://arxiv.org/abs/2507.22908', 'abstract': 'Rapid growth of digital transactions has led to a surge in fraudulent activities, challenging traditional detection methods in the financial sector. To tackle this problem, we introduce a specialised federated learning framework that uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model with advanced privacy preserving techniques. By integrating quantum layers into the LSTM architecture, our approach adeptly captures complex cross-transactional patters, resulting in an approximate 5% performance improvement across key evaluation metrics compared to conventional models. Central to our framework is "FedRansel", a novel method designed to defend against poisoning and inference attacks, thereby reducing model degradation and inference accuracy by 4-8%, compared to standard differential privacy mechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances fraud detection accuracy and reinforces the security and confidentiality of sensitive financial data.', 'abstract_zh': '数字交易的快速增长导致了欺诈活动的激增，挑战了金融领域的传统检测方法。为应对这一问题，我们介绍了一种专门的 federated learning 框架，该框架独特地结合了量子增强的长短期记忆（LSTM）模型和先进的隐私保护技术。通过将量子层集成到LSTM架构中，我们的方法能够巧妙地捕捉复杂的跨交易模式，相较于常规模型，在关键评估指标上实现了约5%的性能提升。该框架的核心是“FedRansel”方法，这是一种新颖的方法，旨在防御中毒和推理攻击，与标准差分隐私机制相比，它可以将模型退化和推理准确性分别降低4-8%。这种伪中心化的设置与量子LSTM模型结合，增强了欺诈检测 accuracy 并强化了敏感金融数据的安全性和保密性。', 'title_zh': '基于混合量子增强学习的隐私保护联邦框架在金融欺诈检测中的应用'}
{'arxiv_id': 'arXiv:2507.22906', 'title': 'DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver', 'authors': 'Bin Deng, Jiatong Bai, Feilong Zhao, Zuming Xie, Maolin Li, Yan Wang, Feng Shu', 'link': 'https://arxiv.org/abs/2507.22906', 'abstract': 'As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO architecture has been shown to own a great potential to replace the massive or extremely large-scale fully-digital MIMO in the future wireless networks to address the three challenging problems faced by the latter: high energy consumption, high circuit cost, and high complexity. However, how to intelligently sense the number and direction of multi-emitters via such a structure is still an open hard problem. To address this, we propose a two-stage sensing framework that jointly estimates the number and direction values of multiple targets. Specifically, three target number sensing methods are designed: an improved eigen-domain clustering (EDC) framework, an enhanced deep neural network (DNN) based on five key statistical features, and an improved one-dimensional convolutional neural network (1D-CNN) utilizing full eigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is achieved via the introduced online micro-clustering (OMC-DOA) method. Furthermore, we derive the Cramér-Rao lower bound (CRLB) for the H2AD under multiple-source conditions as a theoretical performance benchmark. Simulation results show that the developed three methods achieve 100\\% number of targets sensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior under extremely-low SNR conditions. The introduced OMC-DOA outperforms existing clustering and fusion-based DOA methods in multi-source environments.', 'abstract_zh': '作为一种绿色MIMO结构，异构混合模拟-数字H2AD MIMO架构已被证明具有未来无线网络中替代大规模或超大规模全数字MIMO的巨大潜力，以解决后者面临的三个挑战问题：高能耗、高电路成本和高复杂度。然而，如何通过此类结构智能感知多发射源的数量和方向仍然是一个开放的难题。为此，我们提出了一种两阶段的感知框架，联合估计多目标的数量和方向值。具体地，设计了三种目标数量感知方法：改进的特征域聚类(EDC)框架、基于五种关键统计特征的增强深度神经网络(DNN)以及利用全部特征值改进的一维卷积神经网络(1D-CNN)。随后，通过引入在线微聚类(OMC-DOA)方法实现了低复杂度和高精度的方向角估计(DOA)。此外，我们推导了在多源条件下H2AD的克朗纳罗 lower bound (CRLB)作为理论性能基准。仿真结果表明，所开发的三种方法在中等到高信噪比下实现了100%的目标数量感知，而改进的1D-CNN在极低信噪比条件下表现出色。引入的OMC-DOA在多源环境中优于现有的聚类和融合基于的方向角方法。', 'title_zh': '基于DNN的方法：通过绿色大规模H2AD MIMO接收机联合感知目标的数量和方向'}
{'arxiv_id': 'arXiv:2507.22904', 'title': 'SketchMind: A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches', 'authors': 'Ehsan Latif, Zirak Khan, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2507.22904', 'abstract': "Scientific sketches (e.g., models) offer a powerful lens into students' conceptual understanding, yet AI-powered automated assessment of such free-form, visually diverse artifacts remains a critical challenge. Existing solutions often treat sketch evaluation as either an image classification task or monolithic vision-language models, which lack interpretability, pedagogical alignment, and adaptability across cognitive levels. To address these limitations, we present SketchMind, a cognitively grounded, multi-agent framework for evaluating and improving student-drawn scientific sketches. SketchMind comprises modular agents responsible for rubric parsing, sketch perception, cognitive alignment, and iterative feedback with sketch modification, enabling personalized and transparent evaluation. We evaluate SketchMind on a curated dataset of 3,575 student-generated sketches across six science assessment items with different highest order of Bloom's level that require students to draw models to explain phenomena. Compared to baseline GPT-4o performance without SRG (average accuracy: 55.6%), and with SRG integration achieves 77.1% average accuracy (+21.4% average absolute gain). We also demonstrate that multi-agent orchestration with SRG enhances SketchMind performance, for example, GPT-4.1 gains an average 8.9% increase in sketch prediction accuracy, outperforming single-agent pipelines across all items. Human evaluators rated the feedback and co-created sketches generated by \\textsc{SketchMind} with GPT-4.1, which achieved an average of 4.1 out of 5, significantly higher than those of baseline models (e.g., 2.3 for GPT-4o). Experts noted the system's potential to meaningfully support conceptual growth through guided revision. Our code and (pending approval) dataset will be released to support reproducibility and future research in AI-driven education.", 'abstract_zh': '科学草图（例如模型）为 student 概念理解提供了强大的视角，然而，基于 AI 的自动化评估如此这类自由形式、视觉多样的作品仍面临关键挑战。现有解决方案往往将草图评估视作图像分类任务或单一体视语言模型，缺乏可解释性、教育对齐和跨认知水平的适应性。为应对这些局限，我们提出了 SketchMind，一个认知基础、多智能体框架，用于评估和改进学生绘制的科学草图。SketchMind 包含负责评分准则解析、草图感知、认知对齐和迭代反馈并包含草图修改的模块化智能体，实现个性化和透明的评估。我们对六门科学评估项目中的 3,575 个学生生成的草图进行了评估，这些项目涉及不同阶次的布鲁姆认知水平，并要求学生绘制模型来解释现象。与 Baseline GPT-4o（平均准确率：55.6%）的表现相比，集成 SRG 后的表现达到了 77.1% 的平均准确率（绝对平均增益 +21.4%）。我们还证明，SRG 驱动的多智能体协调提升了 SketchMind 的表现，例如 GPT-4.1 在草图预测准确率上平均提高了 8.9% 并在所有项目中优于单一智能体流程。人类评估者对 SketchMind 和 GPT-4.1 生成的反馈和共创草图给出了平均 4.1 分（满分 5 分），显著高于基线模型（例如，GPT-4o 的 2.3 分）。专家们指出，该系统有能力通过引导式修订在概念发展方面实质性地支持学生。我们的代码和（待审批）数据集将被发布，以支持该研究的可复现性和未来人工智能驱动教育的研究。', 'title_zh': 'SketchMind：评估学生绘制的科学草图的多智能体认知框架'}
{'arxiv_id': 'arXiv:2507.22902', 'title': 'Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting', 'authors': 'Hashim Hayat, Maksim Kudrautsau, Evgeniy Makarov, Vlad Melnichenko, Tim Tsykunou, Piotr Varaksin, Matt Pavelle, Adam Z. Oskowitz', 'link': 'https://arxiv.org/abs/2507.22902', 'abstract': 'Background: Globally we face a projected shortage of 11 million healthcare practitioners by 2030, and administrative burden consumes 50% of clinical time. Artificial intelligence (AI) has the potential to help alleviate these problems. However, no end-to-end autonomous large language model (LLM)-based AI system has been rigorously evaluated in real-world clinical practice. In this study, we evaluated whether a multi-agent LLM-based AI framework can function autonomously as an AI doctor in a virtual urgent care setting. Methods: We retrospectively compared the performance of the multi-agent AI system Doctronic and board-certified clinicians across 500 consecutive urgent-care telehealth encounters. The primary end points: diagnostic concordance, treatment plan consistency, and safety metrics, were assessed by blinded LLM-based adjudication and expert human review. Results: The top diagnosis of Doctronic and clinician matched in 81% of cases, and the treatment plan aligned in 99.2% of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not supported by clinical findings). In an expert review of discordant cases, AI performance was superior in 36.1%, and human performance was superior in 9.3%; the diagnoses were equivalent in the remaining cases. Conclusions: In this first large-scale validation of an autonomous AI doctor, we demonstrated strong diagnostic and treatment plan concordance with human clinicians, with AI performance matching and in some cases exceeding that of practicing clinicians. These findings indicate that multi-agent AI systems achieve comparable clinical decision-making to human providers and offer a potential solution to healthcare workforce shortages.', 'abstract_zh': '背景：全球到2030年预计将面临1100万名医疗卫生从业者短缺的问题，行政负担消耗了临床时间的50%。人工智能（AI）有潜力帮助解决这些问题。然而，目前尚无基于大型语言模型（LLM）的端到端自主AI系统在真实临床环境中得到严格的评估。在这项研究中，我们评估了一种基于多智能体的LLM AI框架是否可以在虚拟急诊环境中自主运行作为AI医生。', 'title_zh': '朝着自主人工智能医生的愿景：在实际应用场景中，自主代理人工智能与认证临床医生的定量基准测试'}
{'arxiv_id': 'arXiv:2507.22900', 'title': 'Tool or Trouble? Exploring Student Attitudes Toward AI Coding Assistants', 'authors': 'Sergio Rojas-Galeano', 'link': 'https://arxiv.org/abs/2507.22900', 'abstract': "This exploratory study examines how AI code assistants shape novice programmers' experiences during a two-part exam in an introductory programming course. In the first part, students completed a programming task with access to AI support; in the second, they extended their solutions without AI. We collected Likert-scale and open-ended responses from 20 students to evaluate their perceptions and challenges. Findings suggest that AI tools were perceived as helpful for understanding code and increasing confidence, particularly during initial development. However, students reported difficulties transferring knowledge to unaided tasks, revealing possible overreliance and gaps in conceptual understanding. These insights highlight the need for pedagogical strategies that integrate AI meaningfully while reinforcing foundational programming skills.", 'abstract_zh': '本探索性研究考察了AI代码助手在 introductory programming 课程中两部分考试中对 novice programmers 经验的影响。在第一部分，学生在有AI支持的情况下完成一个编程任务；在第二部分，他们独立扩展解决方案。我们从20名学生那里收集了Likert量表和开放性回答，以评估他们的感知和挑战。研究发现，AI工具被认为有助于理解代码和增强信心，尤其是在初始开发阶段。然而，学生报告称在无辅助任务中难以转移知识，揭示了可能的过度依赖和概念理解上的缺口。这些洞察强调了需要采用有意义地整合AI的教學策略，同时强化基础编程技能。', 'title_zh': '工具还是麻烦？探索学生对AI编程助手的态度'}
{'arxiv_id': 'arXiv:2507.22897', 'title': 'RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems', 'authors': 'Luyu Chen, Quanyu Dai, Zeyu Zhang, Xueyang Feng, Mingyu Zhang, Pengcheng Tang, Xu Chen, Yue Zhu, Zhenhua Dong', 'link': 'https://arxiv.org/abs/2507.22897', 'abstract': 'Conversational recommender systems (CRS) enhance user experience through multi-turn interactions, yet evaluating CRS remains challenging. User simulators can provide comprehensive evaluations through interactions with CRS, but building realistic and diverse simulators is difficult. While recent work leverages large language models (LLMs) to simulate user interactions, they still fall short in emulating individual real users across diverse scenarios and lack explicit rating mechanisms for quantitative evaluation. To address these gaps, we propose RecUserSim, an LLM agent-based user simulator with enhanced simulation realism and diversity while providing explicit scores. RecUserSim features several key modules: a profile module for defining realistic and diverse user personas, a memory module for tracking interaction history and discovering unknown preferences, and a core action module inspired by Bounded Rationality theory that enables nuanced decision-making while generating more fine-grained actions and personalized responses. To further enhance output control, a refinement module is designed to fine-tune final responses. Experiments demonstrate that RecUserSim generates diverse, controllable outputs and produces realistic, high-quality dialogues, even with smaller base LLMs. The ratings generated by RecUserSim show high consistency across different base LLMs, highlighting its effectiveness for CRS evaluation.', 'abstract_zh': '基于大语言模型的增强现实用户模拟器（RecUserSim）：提升对话推荐系统评价的现实性和多样性', 'title_zh': 'RecUserSim: 一种用于评估对话推荐系统的现实且多样的用户模拟器'}
{'arxiv_id': 'arXiv:2507.22896', 'title': 'iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement', 'authors': 'Kohou Wang, ZhaoXiang Liu, Lin Bai, Kun Fan, Xiang Liu, Huan Hu, Kai Wang, Shiguo Lian', 'link': 'https://arxiv.org/abs/2507.22896', 'abstract': "It is crucial that robots' performance can be improved after deployment, as they are inherently likely to encounter novel scenarios never seen before. This paper presents an innovative solution: an interactive learning-based robot system powered by a Multi-modal Large Language Model(MLLM). A key feature of our system is its ability to learn from natural dialogues with non-expert users. We also propose chain of question to clarify the exact intent of the question before providing an answer and dual-modality retrieval modules to leverage these interaction events to avoid repeating same mistakes, ensuring a seamless user experience before model updates, which is in contrast to current mainstream MLLM-based robotic systems. Our system marks a novel approach in robotics by integrating interactive learning, paving the way for superior adaptability and performance in diverse environments. We demonstrate the effectiveness and improvement of our method through experiments, both quantitively and qualitatively.", 'abstract_zh': '机器人部署后性能可提升的关键在于它们能够处理前所未见的新型场景。本文提出了一种创新解决方案：一种由多模态大语言模型（MLLM）驱动的交互式学习机器人系统。系统的关键技术在于能够从非专家用户的自然对话中学习。我们还提出了一套连贯的问题链以澄清问题的具体意图，并利用双模态检索模块来利用这些交互事件以避免重复错误，从而在模型更新之前提供无缝的用户体验，这与当前主流的基于MLLM的机器人系统形成对比。通过实验，从定量和定性的角度证明了该系统方法的有效性和改进。', 'title_zh': 'iLearnRobot：一种基于交互学习的多模态机器人及其持续改进'}
{'arxiv_id': 'arXiv:2507.22893', 'title': 'Invisible Architectures of Thought: Toward a New Science of AI as Cognitive Infrastructure', 'authors': 'Giuseppe Riva', 'link': 'https://arxiv.org/abs/2507.22893', 'abstract': 'Contemporary human-AI interaction research overlooks how AI systems fundamentally reshape human cognition pre-consciously, a critical blind spot for understanding distributed cognition. This paper introduces "Cognitive Infrastructure Studies" (CIS) as a new interdisciplinary domain to reconceptualize AI as "cognitive infrastructures": foundational, often invisible systems conditioning what is knowable and actionable in digital societies. These semantic infrastructures transport meaning, operate through anticipatory personalization, and exhibit adaptive invisibility, making their influence difficult to detect. Critically, they automate "relevance judgment," shifting the "locus of epistemic agency" to non-human systems. Through narrative scenarios spanning individual (cognitive dependency), collective (democratic deliberation), and societal (governance) scales, we describe how cognitive infrastructures reshape human cognition, public reasoning, and social epistemologies. CIS aims to address how AI preprocessing reshapes distributed cognition across individual, collective, and cultural scales, requiring unprecedented integration of diverse disciplinary methods. The framework also addresses critical gaps across disciplines: cognitive science lacks population-scale preprocessing analysis capabilities, digital sociology cannot access individual cognitive mechanisms, and computational approaches miss cultural transmission dynamics. To achieve this goal CIS also provides methodological innovations for studying invisible algorithmic influence: "infrastructure breakdown methodologies", experimental approaches that reveal cognitive dependencies by systematically withdrawing AI preprocessing after periods of habituation.', 'abstract_zh': '当代人类-人工智能互动研究忽视了人工智能系统如何从根本上重新塑造人类的前意识认知，这是一个理解分布式认知的关键盲点。本文引入“认知基础设施研究”（CIS）作为一个新的跨学科领域，重新 conceptualize 人工智能为“认知基础设施”：作为基础的、常常是无形的系统，条件着数字社会中可认知和可行动的内容。这些语义基础设施传输意义，通过预见性个性化运作，并表现出适应性的隐形性，使其影响难以察觉。关键的是，它们自动化了“相关性判断”，将“知识主体性”的焦点转移到非人类系统上。通过涵盖个体（认知依赖）、集体（民主审议）和社会（治理）三个尺度的叙事场景，我们描述了认知基础设施如何重塑人类认知、公共理性和社会认识论。CIS旨在解决人工智能预处理如何在个体、集体和文化层面重塑分布式认知的问题，要求各学科间前所未有的整合方法。该框架还解决了各学科之间的关键空白：认知科学缺乏大规模预处理分析能力，数字社会学无法访问个体认知机制，而计算方法未能捕捉文化传递动态。为了实现这一目标，CIS还提供了研究隐形算法影响的方法论创新：“基础设施中断方法”以及通过系统性地在习惯化期后撤回人工智能预处理来揭示认知依赖性的实验方法。', 'title_zh': '思维的隐形架构：走向作为认知基础设施的新人工智能科学'}
{'arxiv_id': 'arXiv:2507.22890', 'title': 'Evaluating LLMs for Visualization Generation and Understanding', 'authors': 'Saadiq Rauf Khan, Vinit Chandak, Sougata Mukherjea', 'link': 'https://arxiv.org/abs/2507.22890', 'abstract': 'Information Visualization has been utilized to gain insights from complex data. In recent times, Large Language models (LLMs) have performed very well in many tasks. In this paper, we showcase the capabilities of different popular LLMs to generate code for visualization based on simple prompts. We also analyze the power of LLMs to understand some common visualizations by answering questions. Our study shows that LLMs could generate code for some simpler visualizations such as bar and pie charts. Moreover, they could answer simple questions about visualizations. However, LLMs also have several limitations. For example, some of them had difficulty generating complex visualizations, such as violin plot. LLMs also made errors in answering some questions about visualizations, for example, identifying relationships between close boundaries and determining lengths of shapes. We believe that our insights can be used to improve both LLMs and Information Visualization systems.', 'abstract_zh': '大规模语言模型在生成可视化代码方面的能力及限制研究', 'title_zh': '评估Large Language Models在生成与理解可视化方面的能力'}
{'arxiv_id': 'arXiv:2503.21813', 'title': 'OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching', 'authors': 'Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang', 'link': 'https://arxiv.org/abs/2503.21813', 'abstract': 'Hallucinations are often inevitable in downstream tasks using large language models (LLMs). To tackle the substantial challenge of addressing hallucinations for LLM-based ontology matching (OM) systems, we introduce a new benchmark dataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the Ontology Alignment Evaluation Initiative (OAEI), capturing hallucinations of ten different LLMs performing OM tasks. These OM-specific hallucinations are organised into two primary categories and six sub-categories. We showcase the usefulness of the dataset in constructing an LLM leaderboard for OM tasks and for fine-tuning LLMs used in OM tasks.', 'abstract_zh': '大型语言模型（LLMs）在下游任务中经常出现幻觉。为应对基于LLM的本体匹配（OM）系统中幻觉带来的重大挑战，我们引入了一个新的基准数据集OAEI-LLM-T。该数据集源自Ontology Alignment Evaluation Initiative (OAEI)中的七个TBox数据集，涵盖了十种不同LLM执行本体匹配任务时出现的幻觉。这些OM特定的幻觉被组织成两个主要类别和六个子类别。我们展示了该数据集在构建OM任务的LLM排行榜以及Fine-tuning用于OM任务的LLM方面的实用性。', 'title_zh': 'OAEI-LLM-T：一个用于理解大型语言模型在本体匹配中幻觉现象的TBox基准数据集'}
