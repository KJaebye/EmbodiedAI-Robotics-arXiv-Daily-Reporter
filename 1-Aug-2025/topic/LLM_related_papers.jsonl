{'arxiv_id': 'arXiv:2507.23088', 'title': 'Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance', 'authors': 'Lalithkumar Seenivasan, Jiru Xu, Roger D. Soberanis Mukul, Hao Ding, Grayson Byrd, Yu-Chun Ku, Jose L. Porras, Masaru Ishii, Mathias Unberath', 'link': 'https://arxiv.org/abs/2507.23088', 'abstract': 'Emerging surgical data science and robotics solutions, especially those designed to provide assistance in situ, require natural human-machine interfaces to fully unlock their potential in providing adaptive and intuitive aid. Contemporary AI-driven solutions remain inherently rigid, offering limited flexibility and restricting natural human-machine interaction in dynamic surgical environments. These solutions rely heavily on extensive task-specific pre-training, fixed object categories, and explicit manual-prompting. This work introduces a novel Perception Agent that leverages speech-integrated prompt-engineered large language models (LLMs), segment anything model (SAM), and any-point tracking foundation models to enable a more natural human-machine interaction in real-time intraoperative surgical assistance. Incorporating a memory repository and two novel mechanisms for segmenting unseen elements, Perception Agent offers the flexibility to segment both known and unseen elements in the surgical scene through intuitive interaction. Incorporating the ability to memorize novel elements for use in future surgeries, this work takes a marked step towards human-machine symbiosis in surgical procedures. Through quantitative analysis on a public dataset, we show that the performance of our agent is on par with considerably more labor-intensive manual-prompting strategies. Qualitatively, we show the flexibility of our agent in segmenting novel elements (instruments, phantom grafts, and gauze) in a custom-curated dataset. By offering natural human-machine interaction and overcoming rigidity, our Perception Agent potentially brings AI-based real-time assistance in dynamic surgical environments closer to reality.', 'abstract_zh': '新兴外科数据科学与机器人解决方案，尤其是那些旨在提供现场辅助的解决方案，需要自然的人机界面以充分利用其在提供适应性和直观辅助方面的潜力。当前基于AI的解决方案本质上具有刚性，灵活性有限，限制了在动态手术环境中的自然人机交互。这些解决方案高度依赖特定任务的预训练、固定的对象类别和明确的手动提示。本文介绍了一种新的知觉代理，该代理利用语音集成的提示工程大型语言模型（LLMs）、分割一切模型（SAM）和任意点追踪基础模型，以实现更自然的实时手术辅助中的人机交互。该知觉代理通过直观交互实现了包含记忆库以及两种分割未见元素的新机制，能够灵活地分割手术场景中的已知和未见元素。通过记住新的元素以在未来手术中使用，本文朝着手术程序中的人机共生迈出了重要一步。通过对公开数据集的定量分析，我们展示了我们的代理在性能上与劳动密集型的手动提示策略相当。定性分析表明，我们的代理在自定义编曲数据集中具有灵活性，能够分割新的元素（器械、仿生移植物和纱布）。通过提供自然的人机交互并克服刚性，我们的知觉代理有可能将基于AI的实时辅助推向动态手术环境更加现实的未来。', 'title_zh': '超越刚性人工智能： toward 自然的人机共生以实现联合手术辅助'}
{'arxiv_id': 'arXiv:2507.23773', 'title': 'SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model', 'authors': 'Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing', 'link': 'https://arxiv.org/abs/2507.23773', 'abstract': 'AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \\modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \\modelname improves the success of flight search from 0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent advantage of up to 124\\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \\modelname with pretrained LLMs, available as a research demo for public testing.', 'abstract_zh': '基于大型语言模型的AI代理前景巨大，但当前实践主要采用单任务单代理的方法，这不仅缺乏可扩展性和普遍性，而且还受到自回归大型语言模型基本限制的制约。相比之下，人类是一般性代理，通过心理模拟其行动和计划的结果来进行推理。朝着更通用和强大的AI代理方向，我们引入了SimuRA，即一个以目标为导向、适用于通用代理推理的架构。基于任何环境中的最优代理的原理性表述，\\modelname 通过引入用于计划的世界模型克服了自回归推理的限制。世界模型使用大型语言模型实现，能够利用自然语言丰富的潜在空间灵活地在各种环境中进行规划。实验表明，在困难的网页浏览任务中，\\modelname 将航班搜索的成功率从0%提升至32.2%。特别是基于世界模型的规划显示出高达124%的一致优势，证明了世界模型模拟作为一种推理范式的优越性。我们正在探索基于大型语言模型训练单个通用超智能代理模型的可能性。为起步，我们发布了一个基于\\message 的SimuRA网页浏览代理进行公开测试作为研究demo。', 'title_zh': 'SimuRA：通过基于大语言模型的世界模型模拟推理架构实现通用目标导向代理'}
{'arxiv_id': 'arXiv:2507.23751', 'title': 'CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks', 'authors': 'Ping Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, Jing Xu', 'link': 'https://arxiv.org/abs/2507.23751', 'abstract': 'We propose CoT-Self-Instruct, a synthetic data generation method that instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the given seed tasks, and then to generate a new synthetic prompt of similar quality and complexity for use in LLM training, followed by filtering for high-quality data with automatic metrics. In verifiable reasoning, our synthetic data significantly outperforms existing training datasets, such as s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For non-verifiable instruction-following tasks, our method surpasses the performance of human or standard self-instruct prompts on both AlpacaEval 2.0 and Arena-Hard.', 'abstract_zh': '我们提出了一种名为CoT-Self-Instruct的合成数据生成方法，该方法通过Chain-of-Thought (CoT) 首先指导LLMs根据给定的种子任务进行推理和规划，然后生成具有相似质量和复杂性的新合成提示用于LLM训练，并通过自动指标进行过滤，以获取高质量数据。在可验证的推理中，我们的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond等基准上显著优于现有训练数据集s1k和OpenMathReasoning。对于不可验证的指令跟随任务，我们的方法在AlpacaEval 2.0和Arena-Hard上的性能超过了人类或标准自指导提示。', 'title_zh': 'CoT-Self-Instruct：构建高质量合成提示以用于推理和非推理任务'}
{'arxiv_id': 'arXiv:2507.23701', 'title': 'TextQuests: How Good are LLMs at Text-Based Video Games?', 'authors': 'Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks', 'link': 'https://arxiv.org/abs/2507.23701', 'abstract': "Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agent's capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at this https URL.", 'abstract_zh': '在复杂交互环境中评估AI代理对于理解其实际能力至关重要。现有的代理基准虽然能够有效评估工具使用或结构化任务上的技能，但往往未能充分捕捉代理在探索性环境中自主操作的能力，这些环境中需要长时间持续的自我导向推理。为促进能够实现更稳健长期内在推理的代理开发，我们引入了基于Infocom互动小说游戏套件的TextQuests基准。这些基于文本的冒险可以在人类玩家身上耗时超过30小时，并且需要数百次精确操作才能解决，因此有效地评估了AI代理在集中、状态感知任务上的能力。该基准特别设计用于评估LLM代理的独立问题解决能力，通过禁止使用外部工具，从而聚焦于在需要试错学习和单一交互会话内持续问题解决的探索性环境中的内在长期上下文推理能力。我们在此发布TextQuests：https://www.example.com/textquests。', 'title_zh': 'TextQuests：文本型视频游戏中的LLM们表现如何？'}
{'arxiv_id': 'arXiv:2507.23633', 'title': 'MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying', 'authors': 'Qian Zhao, Zhuo Sun, Bin Guo, Zhiwen Yu', 'link': 'https://arxiv.org/abs/2507.23633', 'abstract': "Agent-assisted memory recall is one critical research problem in the field of human-computer interaction. In conventional methods, the agent can retrieve information from its equipped memory module to help the person recall incomplete or vague memories. The limited size of memory module hinders the acquisition of complete memories and impacts the memory recall performance in practice. Memory theories suggest that the person's relevant memory can be proactively activated through some effective cues. Inspired by this, we propose a novel strategy-guided agent-assisted memory recall method, allowing the agent to transform an original query into a cue-rich one via the judiciously designed strategy to help the person recall memories. To this end, there are two key challenges. (1) How to choose the appropriate recall strategy for diverse forgetting scenarios with distinct memory-recall characteristics? (2) How to obtain the high-quality responses leveraging recall strategies, given only abstract and sparsely annotated strategy patterns? To address the challenges, we propose a Recall Router framework. Specifically, we design a 5W Recall Map to classify memory queries into five typical scenarios and define fifteen recall strategy patterns across the corresponding scenarios. We then propose a hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to optimize the selection of strategy and the generation of strategy responses. We construct an instruction tuning dataset and fine-tune multiple open-source large language models (LLMs) to develop MemoCue, an agent that excels in providing memory-inspired responses. Experiments on three representative datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Further human evaluation highlights its advantages in memory-recall applications.", 'abstract_zh': '基于代理的辅助记忆召回是人机交互领域的一个关键研究问题。在传统方法中，代理可以从其装备的记忆模块中检索信息以帮助人们回忆不完整或模糊的记忆。记忆模块的有限大小阻碍了完整记忆的获取，影响实际的记忆召回性能。记忆理论表明，可以通过有效的提示主动激活人的相关记忆。受此启发，我们提出了一种新颖的策略导向的代理辅助记忆召回方法，使代理能够通过精心设计的策略将原始查询转换为富含提示的查询，以帮助人们回忆记忆。为此，有两个关键挑战：（1）如何为具有不同记忆-召回特征的不同遗忘场景选择合适的召回策略？（2）如何利用召回策略获取高质量的响应，仅利用抽象和稀疏标注的策略模式？为了解决这些挑战，我们提出了一种召回路由框架。具体地，我们设计了一个5W召回地图，将记忆查询分类为五种典型场景，并在相应场景中定义了十五种召回策略模式。然后，我们提出了一种结合蒙特卡洛树搜索算法的分层召回树来优化策略的选择和策略响应的生成。我们构建了一个指令调优数据集，并对多个开源的大语言模型（LLMs）进行微调，开发出了MemoCue，这是一种在提供记忆启发式响应方面表现出色的代理。实验结果在三个代表性数据集上表明，MemoCue在召回启发方面比基于大语言模型的方法提高了17.74%。进一步的人类评估突显了其在记忆召回应用中的优势。', 'title_zh': 'MemoCue: 通过策略导向的查询增强基于LLM的代理的人类记忆回忆能力'}
{'arxiv_id': 'arXiv:2507.23554', 'title': 'DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer', 'authors': 'Ruoyu Wang, Junda Wu, Yu Xia, Tong Yu, Ryan A. Rossi, Julian McAuley, Lina Yao', 'link': 'https://arxiv.org/abs/2507.23554', 'abstract': "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks. However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance. While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps. Therefore, it is non-trivial to develop a principled, general-purpose method for selecting demonstrations that consistently benefit agent performance. In this paper, we address this challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a theoretically grounded ICL framework for agentic tasks that selects the most relevant demonstrations at each step of reasoning. Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization. We further propose a stepwise selection criterion with a formal guarantee of improved agent performance. Importantly, DICE is a general, framework-agnostic solution that can be integrated as a plug-in module into existing agentic frameworks without any additional training cost. Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", 'abstract_zh': '基于大型语言模型的代理：带内在情境学习的动态示例选择（DICE）', 'title_zh': 'DICE: 动态上下文相关示例选择在高效知识转移的大型语言模型代理中'}
{'arxiv_id': 'arXiv:2507.23440', 'title': 'Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation', 'authors': 'Mingzhe Li, Xin Lu, Yanyan Zhao', 'link': 'https://arxiv.org/abs/2507.23440', 'abstract': 'Large language models (LLMs) with instruction following capabilities have demonstrated impressive problem-solving abilities. While synthesizing instructional data from unsupervised text has become a common approach for training such models, conventional methods rely heavily on human effort for data annotation. Although existing automated synthesis paradigms have alleviated this constraint, they still exhibit significant limitations in ensuring adequate diversity and difficulty of synthesized instructions. To address these challenges, we propose Self-Foveate, an innovative LLM-driven method for instruction synthesis. This approach introduces a "Micro-Scatter-Macro" multi-level foveation methodology that effectively guides the LLM to deeply excavate fine-grained information embedded in unsupervised text, thereby enhancing both the diversity and difficulty of synthesized instructions. Comprehensive experiments across multiple unsupervised corpora and diverse model architectures validate the effectiveness and superiority of our proposed method. We publicly release our data and codes: this https URL', 'abstract_zh': '具有指令跟随能力的大语言模型展示了令人印象深刻的解决问题能力。虽然从无监督文本中合成指令已成为培训此类模型的常见方法，但传统方法在数据标注方面仍高度依赖人工。尽管现有的自动化合成范式已缓解了这一限制，但在确保合成指令的多样性和难度方面仍存在显著局限。为应对这些挑战，我们提出了一种创新的大语言模型驱动的指令合成方法Self-Foveate。该方法引入了一种“微-散-宏”多级聚光方法，有效地引导大语言模型深入挖掘无监督文本中嵌入的精细信息，从而增强合成指令的多样性和难度。在多个无监督数据集和多种模型架构上的全面实验验证了我们提出方法的有效性和优越性。我们公开释放了我们的数据和代码：this https URL。', 'title_zh': '自聚焦：通过多级聚焦增强无监督文本合成指令的多样性和难度'}
{'arxiv_id': 'arXiv:2507.23429', 'title': 'Chatting with your ERP: A Recipe', 'authors': 'Jorge Ruiz Gómez, Lidia Andrés Susinos, Jorge Alamo Olivé, Sonia Rey Osorno, Manuel Luis Gonzalez Hernández', 'link': 'https://arxiv.org/abs/2507.23429', 'abstract': 'This paper presents the design, implementation, and evaluation behind a Large Language Model (LLM) agent that chats with an industrial production-grade ERP system. The agent is capable of interpreting natural language queries and translating them into executable SQL statements, leveraging open-weight LLMs. A novel dual-agent architecture combining reasoning and critique stages was proposed to improve query generation reliability.', 'abstract_zh': '这篇论文介绍了与工业生产级ERP系统对话的大型语言模型代理的设计、实现与评估。该代理能够解析自然语言查询并将其转换为可执行的SQL语句，利用开放式大型语言模型。提出了结合推理和批判阶段的新型双代理架构，以提高查询生成的可靠性。', 'title_zh': '与您的ERP聊天：一份配方'}
{'arxiv_id': 'arXiv:2507.23377', 'title': 'LLM4Rail: An LLM-Augmented Railway Service Consulting Platform', 'authors': 'Zhuo Li, Xianghuai Deng, Chiwei Feng, Hanmeng Li, Shenjie Wang, Haichao Zhang, Teng Jia, Conlin Chen, Louis Linchun Wu, Jia Wang', 'link': 'https://arxiv.org/abs/2507.23377', 'abstract': 'Large language models (LLMs) have significantly reshaped different walks of business. To meet the increasing demands for individualized railway service, we develop LLM4Rail - a novel LLM-augmented railway service consulting platform. Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway food & drink recommendations, weather information, and chitchat. In LLM4Rail, we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting framework. It meticulously integrates verbal reasoning with task-oriented actions, that is, reasoning to guide action selection, to effectively retrieve external observations relevant to railway operation and service to generate accurate responses. To provide personalized onboard dining services, we first construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible takeout dataset tailored for railway services. CRFD-25 covers a wide range of signature dishes categorized by cities, cuisines, age groups, and spiciness levels. We further introduce an LLM-based zero-shot conversational recommender for railway catering. To address the unconstrained nature of open recommendations, the feature similarity-based post-processing step is introduced to ensure all the recommended items are aligned with CRFD-25 dataset.', 'abstract_zh': '大型语言模型（LLMs）显著重塑了各行各业的业务。为了满足日益增长的个性化铁路服务需求，我们开发了LLM4Rail——一种新型的LLM增强铁路服务咨询平台。借助大型语言模型的加持，LLM4Rail能够提供定制化的票务模块、铁路食品与饮料推荐、天气信息以及闲聊服务。在LLM4Rail中，我们提出了迭代的“提问-思考-行动-观察（QTAO）”提示框架。该框架精心整合了语言推理与任务导向的操作，即通过推理来指导行动选择，从而有效地检索与铁路运营和服务相关的外部观察信息，生成准确的响应。为了提供个性化的列车上餐饮服务，我们首先构建了中国铁路食品与饮料（CRFD-25）——一个面向铁路服务的公开取餐数据集。CRFD-25涵盖了按城市、菜系、年龄组和辣度分类的多种特色菜肴。我们进一步引入了基于大型语言模型的零样本对话推荐系统，以铁路餐饮为应用场景。为了确保推荐物品与CRFD-25数据集保持一致，我们还引入了基于特征相似性的后处理步骤，以解决开放式推荐的无约束性问题。', 'title_zh': 'LLM4Rail：一种基于LLM的铁路服务咨询平台'}
{'arxiv_id': 'arXiv:2507.23336', 'title': 'DSBC : Data Science task Benchmarking with Context engineering', 'authors': 'Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Giulio Martini, Suman Debnath, Hamza Farooq', 'link': 'https://arxiv.org/abs/2507.23336', 'abstract': 'Recent advances in large language models (LLMs) have significantly impacted data science workflows, giving rise to specialized data science agents designed to automate analytical tasks. Despite rapid adoption, systematic benchmarks evaluating the efficacy and limitations of these agents remain scarce. In this paper, we introduce a comprehensive benchmark specifically crafted to reflect real-world user interactions with data science agents by observing usage of our commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet, Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with context engineering, multi-step with context engineering, and with SmolAgent. Our benchmark assesses performance across a diverse set of eight data science task categories, additionally exploring the sensitivity of models to common prompting issues, such as data leakage and slightly ambiguous instructions. We further investigate the influence of temperature parameters on overall and task-specific outcomes for each model and approach. Our findings reveal distinct performance disparities among the evaluated models and methodologies, highlighting critical factors that affect practical deployment. The benchmark dataset and evaluation framework introduced herein aim to provide a foundation for future research of more robust and effective data science agents.', 'abstract_zh': 'Recent advances in大型语言模型（LLMs）对数据科学工作流产生了显著影响，催生了专门设计用于自动化分析任务的数据科学代理。尽管这些代理的采用率迅速提升，但系统性基准测试以评估其有效性和局限性仍然较为稀缺。本文介绍了一个综合基准，旨在通过观察我们商业应用程序的使用情况来反映数据科学代理的实际情况。我们评估了三种LLM：Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini，采用了三种方法：零样本、带有上下文工程的多步骤和带有SmolAgent的方法。该基准测试评估了涵盖八大数据科学任务类别的性能，并探讨了模型对常见提示问题（如数据泄露和模棱两可指令）的敏感性。我们还进一步研究了温度参数对每个模型和方法整体及任务特定结果的影响。我们的研究结果揭示了评估模型和方法之间的显著性能差异，并强调了影响实际部署的关键因素。本文引入的基准数据集和评估框架旨在为更稳健和有效的数据科学代理的研究提供基础。', 'title_zh': 'DSBC：基于上下文工程的数据科学任务基准测试'}
{'arxiv_id': 'arXiv:2507.23276', 'title': 'How Far Are AI Scientists from Changing the World?', 'authors': 'Qiujie Xie, Yixuan Weng, Minjun Zhu, Fuchen Shen, Shulin Huang, Zhen Lin, Jiahui Zhou, Zilan Mao, Zijie Yang, Linyi Yang, Jian Wu, Yue Zhang', 'link': 'https://arxiv.org/abs/2507.23276', 'abstract': 'The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research. Several influential works have already appeared in the field of AI Scientist systems, with AI-generated research papers having been accepted at the ICLR 2025 workshop, suggesting that a human-level AI Scientist capable of uncovering phenomena previously unknown to humans, may soon become a reality. In this survey, we focus on the central question: How far are AI scientists from changing the world and reshaping the scientific research paradigm? To answer this question, we provide a prospect-driven review that comprehensively analyzes the current achievements of AI Scientist systems, identifying key bottlenecks and the critical components required for the emergence of a scientific agent capable of producing ground-breaking discoveries that solve grand challenges. We hope this survey will contribute to a clearer understanding of limitations of current AI Scientist systems, showing where we are, what is missing, and what the ultimate goals for scientific AI should be.', 'abstract_zh': '大型语言模型的出现正推动自动化科学研究达到新的水平，基于大型语言模型的人工智能（AI）科学家系统现已在科学研究中占据领先地位。已有若干重要研究工作出现在AI科学家系统领域，AI生成的研究论文已被ICLR 2025研讨会接受，表明人类水平的AI科学家可能很快成为可能。在这篇综述中，我们聚焦的核心问题是：AI科学家距离改变世界和重塑科学研究范式还有多远？为了回答这一问题，我们提供了一种前瞻性的审查，全面分析了AI科学家系统的现有成果，指出了关键瓶颈，并识别出能够产生突破性发现解决重大挑战的科学代理所需的关键组成部分。我们希望这篇综述能有助于对当前AI科学家系统的局限性有一个更清晰的理解，显示我们的现状、缺失的部分，以及科学AI的最终目标应是什么。', 'title_zh': 'AI科学家距离改变世界还有多远？'}
{'arxiv_id': 'arXiv:2507.23163', 'title': 'Argumentatively Coherent Judgmental Forecasting', 'authors': 'Deniz Gorur, Antonio Rago, Francesca Toni', 'link': 'https://arxiv.org/abs/2507.23163', 'abstract': "Judgmental forecasting employs human opinions to make predictions about future events, rather than exclusively historical data as in quantitative forecasting. When these opinions form an argumentative structure around forecasts, it is useful to study the properties of the forecasts from an argumentative perspective. In this paper, we advocate and formally define a property of argumentative coherence, which, in essence, requires that a forecaster's reasoning is coherent with their forecast. We then conduct three evaluations with our notion of coherence. First, we assess the impact of enforcing coherence on human forecasters as well as on Large Language Model (LLM)-based forecasters, given that they have recently shown to be competitive with human forecasters. In both cases, we show that filtering out incoherent predictions improves forecasting accuracy consistently, supporting the practical value of coherence in both human and LLM-based forecasting. Then, via crowd-sourced user experiments, we show that, despite its apparent intuitiveness and usefulness, users do not generally align with this coherence property. This points to the need to integrate, within argumentation-based judgmental forecasting, mechanisms to filter out incoherent opinions before obtaining group forecasting predictions.", 'abstract_zh': '主观预测利用人类意见对未来事件进行预测，而非仅依赖定量预测中的历史数据。当这些意见形成围绕预测的论辩结构时，从论辩的角度研究预测的性质是有益的。本文我们倡导并正式定义了一个论辩一致性属性，其实质要求预测者的推理与预测一致。随后，我们以我们的一致性概念进行了三项评估。首先，我们评估了强制一致性对人类预测者和基于大规模语言模型（LLM）的预测者的影响，鉴于它们最近已被证明能够与人类预测者竞争。在两种情况下，我们表明过滤掉不一致的预测能够一致地提高预测准确性，支持在人类和基于LLM的预测中一致性具有实际价值的观点。然后，通过众包用户实验，我们表明，尽管该一致性属性显得直观且有用，用户通常并不与该属性对齐。这表明，在基于论辩的主观预测中，需要集成机制，在获得小组预测结果之前过滤掉不一致的意见。', 'title_zh': '论据一致的判断性预测'}
{'arxiv_id': 'arXiv:2507.23067', 'title': 'FairReason: Balancing Reasoning and Social Bias in MLLMs', 'authors': 'Zhenyu Pan, Yutong Zhang, Jianshu Zhang, Haoran Lu, Haozheng Luo, Yuwei Han, Philip S. Yu, Manling Li, Han Liu', 'link': 'https://arxiv.org/abs/2507.23067', 'abstract': "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art results across a wide range of tasks and modalities. To push their reasoning ability further, recent studies explore advanced prompting schemes and post-training fine-tuning. Although these techniques improve logical accuracy, they frequently leave the models' outputs burdened with pronounced social biases. Clarifying how reasoning gains interact with bias mitigation-and whether the two objectives inherently trade off-therefore remains an open and pressing research problem. Our study begins by benchmarking three bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation (KD), and rule-based reinforcement learning (RL)-under identical conditions, establishing their baseline strengths and weaknesses. Building on these results, we vary the proportion of debias-focused and reasoning-centric samples within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement learning cuts stereotype scores by 10% while retaining 88% of the model's original reasoning accuracy, offering concrete guidance for balancing fairness and capability in MLLMs.", 'abstract_zh': '多模态大型语言模型（MLLMs）已在广泛的任务和模态中达到最先进的成果。为了进一步提升其推理能力，近期研究探索了高级提示方案和后训练微调。尽管这些技术提高了逻辑准确性，但它们经常使模型的输出带有明显的社会偏见。因此，如何澄清推理增益与偏见缓解之间的关系——以及这两个目标是否不可避免地相互权衡——仍然是一个开放且紧迫的研究问题。我们的研究首先在相同条件下基准测试三种偏见缓解策略——监督后训练（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL），以确立它们的基本优势和劣势。在此基础上，我们改变每个范式中偏见缓解重点和推理中心样本的比例，以绘制推理与偏见之间的权衡图。我们的研究揭示了一致的最佳比例：通过强化学习训练的大约1:4混合训练，可以将刻板印象得分降低10%，同时保留88%的原始推理准确性，为在MLLMs中平衡公平性和能力提供了具体指导。', 'title_zh': 'FairReason: 平衡理性推理与社会偏见在MLLMs中的应用'}
{'arxiv_id': 'arXiv:2507.23740', 'title': 'Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs', 'authors': 'Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li', 'link': 'https://arxiv.org/abs/2507.23740', 'abstract': 'Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at this https URL}{this https URL.', 'abstract_zh': '知识图谱中的逻辑规则的自然语言解释：大规模语言模型的潜力探究', 'title_zh': 'Rule2Text：知识图谱中逻辑规则的自然语言解释'}
{'arxiv_id': 'arXiv:2507.23694', 'title': 'A survey of multi-agent geosimulation methodologies: from ABM to LLM', 'authors': 'Virginia Padilla, Jacinto Dávila', 'link': 'https://arxiv.org/abs/2507.23694', 'abstract': 'We provide a comprehensive examination of agent-based approaches that codify the principles and linkages underlying multi-agent systems, simulations, and information systems. Based on two decades of study, this paper confirms a framework intended as a formal specification for geosimulation platforms. Our findings show that large language models (LLMs) can be effectively incorporated as agent components if they follow a structured architecture specific to fundamental agent activities such as perception, memory, planning, and action. This integration is precisely consistent with the architecture that we formalize, providing a solid platform for next-generation geosimulation systems.', 'abstract_zh': '基于代理的多代理系统、仿真和信息系统的原则与链接的全面考察：大型语言模型在结构化代理架构中的有效整合与框架验证', 'title_zh': '多智能体地理模拟方法学综述：从ABM到LLM'}
{'arxiv_id': 'arXiv:2507.23611', 'title': 'LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora', 'authors': 'Estelle Ruellan, Eric Clay, Nicholas Ascoli', 'link': 'https://arxiv.org/abs/2507.23611', 'abstract': 'Infostealers exfiltrate credentials, session cookies, and sensitive data from infected systems. With over 29 million stealer logs reported in 2024, manual analysis and mitigation at scale are virtually unfeasible/unpractical. While most research focuses on proactive malware detection, a significant gap remains in leveraging reactive analysis of stealer logs and their associated artifacts. Specifically, infection artifacts such as screenshots, image captured at the point of compromise, are largely overlooked by the current literature. This paper introduces a novel approach leveraging Large Language Models (LLMs), more specifically gpt-4o-mini, to analyze infection screenshots to extract potential Indicators of Compromise (IoCs), map infection vectors, and track campaigns. Focusing on the Aurora infostealer, we demonstrate how LLMs can process screenshots to identify infection vectors, such as malicious URLs, installer files, and exploited software themes. Our method extracted 337 actionable URLs and 246 relevant files from 1000 screenshots, revealing key malware distribution methods and social engineering tactics. By correlating extracted filenames, URLs, and infection themes, we identified three distinct malware campaigns, demonstrating the potential of LLM-driven analysis for uncovering infection workflows and enhancing threat intelligence. By shifting malware analysis from traditional log-based detection methods to a reactive, artifact-driven approach that leverages infection screenshots, this research presents a scalable method for identifying infection vectors and enabling early intervention.', 'abstract_zh': '信息窃取者从感染系统中窃取凭证、会话cookie和敏感数据。2024年报告的窃取者日志超过2900万条，大规模的手动分析和缓解几乎不可能实现。尽管大多数研究集中在主动恶意软件检测上，但在利用窃取者日志及其相关 artifacts 的主动分析方面仍然存在显著差距。特别是，当前文献中对感染 artifacts 如屏幕截图、妥协点捕获的图像等的重视不足。本文提出了一种利用大型语言模型（LLMs），具体而言是gpt-4o-mini，通过分析感染屏幕截图来提取潜在的指标（IoCs）、映射感染途径并追踪活动的新方法。以Aurora信息窃取者为例，我们展示了如何通过分析屏幕截图识别出感染途径，如恶意URL、安装文件和被利用的软件主题。我们的方法从1000张屏幕截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件传播方式和社会工程战术。通过关联提取出的文件名、URL和感染主题，我们识别出了三个不同的恶意软件活动系列，验证了基于LLM的分析在揭示感染工作流和增强威胁情报方面的潜力。通过将恶意软件分析从传统的日志基础检测方法转向基于感染屏幕截图的反馈式、artifact驱动的方法，本研究提出了一种可扩展的方法来识别感染途径并实现早期干预。', 'title_zh': '基于LLM的屏幕截图中信息窃取者感染向量识别：以 Aurora 为例'}
{'arxiv_id': 'arXiv:2507.23589', 'title': 'Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study', 'authors': 'Kai Goebel, Patrik Zips', 'link': 'https://arxiv.org/abs/2507.23589', 'abstract': 'Recent advancements in Large Language Models have sparked interest in their potential for robotic task planning. While these models demonstrate strong generative capabilities, their effectiveness in producing structured and executable plans remains uncertain. This paper presents a systematic evaluation of a broad spectrum of current state of the art language models, each directly prompted using Planning Domain Definition Language domain and problem files, and compares their planning performance with the Fast Downward planner across a variety of benchmarks. In addition to measuring success rates, we assess how faithfully the generated plans translate into sequences of actions that can actually be executed, identifying both strengths and limitations of using these models in this setting. Our findings show that while the models perform well on simpler planning tasks, they continue to struggle with more complex scenarios that require precise resource management, consistent state tracking, and strict constraint compliance. These results underscore fundamental challenges in applying language models to robotic planning in real world environments. By outlining the gaps that emerge during execution, we aim to guide future research toward combined approaches that integrate language models with classical planners in order to enhance the reliability and scalability of planning in autonomous robotics.', 'abstract_zh': '近期大型语言模型的进展激发了对其在机器人任务规划中潜力的兴趣。虽然这些模型展示了强大的生成能力，但它们在生成结构化和可执行计划方面的有效性仍有待确定。本文系统评估了当前最先进的多种语言模型在使用Planning Domain Definition Language领域和问题文件直接提示下的规划性能，并将其与Fast Downward规划器在多种基准测试中的表现进行比较。除了衡量成功率外，我们还评估了生成的计划如何忠实转化为实际可执行的动作序列，从而识别这些模型在这种设置下使用的优势和局限性。研究发现，尽管模型在简单的规划任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束合规的复杂场景中仍然表现不佳。这些结果突显了将语言模型应用于现实环境中的机器人规划的基本挑战。通过指出执行中出现的差距，我们旨在引导未来研究向结合语言模型与经典规划器的方法发展，以提高自主机器人规划的可靠性和可扩展性。', 'title_zh': 'LLM-推理模型能否替代经典规划？一项基准研究'}
{'arxiv_id': 'arXiv:2507.23536', 'title': 'From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices', 'authors': 'Georg Slamanig, Francesco Corti, Olga Saukh', 'link': 'https://arxiv.org/abs/2507.23536', 'abstract': 'Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs of updating deep learning models by minimizing the number of additional parameters used to adapt a model to a down- stream task. While extensively researched in large language models (LLMs), their application to smaller models used on edge devices, such as convolutional neural networks, remains underexplored. This paper benchmarks and analyzes popular PEFT methods on convolutional architectures typically deployed in resource-constrained edge environments. We evaluate LoRA, DoRA, and GaLore for updating standard and depthwise convolutional architectures to handle distribution shifts and accommodate unseen classes. We utilize recently proposed PyTorch profilers to compare the updated model performance and computational costs of these PEFT methods with traditional fine-tuning approaches. With resource efficiency in mind, we investigate their update behavior across different rank dimensions. We find that the evaluated PEFT methods are only half as memory-efficient when applied to depthwise-separable convolution architectures, compared to their efficiency with LLMs. Conversely, when targeting convolu- tional architectures optimized for edge deployment, adapter-based PEFT methods can reduce floating point operations (FLOPs) during model updates by up to 95%. These insights offer valuable guidance for selecting PEFT methods based on hardware constraints, performance requirements, and application needs. Our code is online.', 'abstract_zh': '参数效率微调（PEFT）方法通过减少附加参数的数量来降低更新深度学习模型的计算成本，从而最小化下游任务适应所需的新增参数。尽管在大型语言模型（LLMs）中得到了广泛研究，但其在资源受限的边缘设备上使用的小型模型，如卷积神经网络（CNNs）中的应用仍处于探索阶段。本文对流行的各种PEFT方法在资源受限的边缘环境常见的卷积架构上进行了基准测试和分析，评估了LoRA、DoRA和GaLore方法用于更新标准卷积架构和深度可分离卷积架构以应对分布偏移和处理未见类别的能力。我们利用最近提出的PyTorch性能分析器，将这些PEFT方法与传统微调方法在更新模型的性能和计算成本方面的表现进行了比较。考虑到资源效率，我们研究了这些方法在不同秩维度下的更新行为。研究表明，当应用于深度可分离卷积架构时，评估的PEFT方法的内存效率仅为大型语言模型中的效率的一半。相反，当针对优化用于边缘部署的卷积架构时，基于适配器的PEFT方法可以将模型更新过程中的浮点运算（FLOPs）减少高达95%。这些见解为根据硬件限制、性能要求和应用需求选择PEFT方法提供了宝贵指导。我们的代码已上线。', 'title_zh': '从大型语言模型到边缘设备：参数高效微调'}
{'arxiv_id': 'arXiv:2507.23470', 'title': 'Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models', 'authors': 'Sebastian Gürtl, Gloria Schimetta, David Kerschbaumer, Michael Liut, Alexander Steinmaurer', 'link': 'https://arxiv.org/abs/2507.23470', 'abstract': 'UML and ER diagrams are foundational in computer science education but come with challenges for learners due to the need for abstract thinking, contextual understanding, and mastery of both syntax and semantics. These complexities are difficult to address through traditional teaching methods, which often struggle to provide scalable, personalized feedback, especially in large classes. We introduce DUET (Diagrammatic UML & ER Tutor), a prototype of an LLM-based tool, which converts a reference diagram and a student-submitted diagram into a textual representation and provides structured feedback based on the differences. It uses a multi-stage LLM pipeline to compare diagrams and generate reflective feedback. Furthermore, the tool enables analytical insights for educators, aiming to foster self-directed learning and inform instructional strategies. We evaluated DUET through semi-structured interviews with six participants, including two educators and four teaching assistants. They identified strengths such as accessibility, scalability, and learning support alongside limitations, including reliability and potential misuse. Participants also suggested potential improvements, such as bulk upload functionality and interactive clarification features. DUET presents a promising direction for integrating LLMs into modeling education and offers a foundation for future classroom integration and empirical evaluation.', 'abstract_zh': 'UML和ER图是计算机科学教育中的基础工具，但由于需要抽象思维、情境理解以及掌握语法规则和语义，给学习者带来了挑战。这些复杂性通过传统的教学方法难以解决，传统方法往往难以提供规模化的、个性化的反馈，尤其是在大型班级中。我们介绍了DUET（Diagrammatic UML & ER Tutor），这是一种基于LLM的原型工具，可以将参考图和学生提交的图转换为文本表示，并基于差异提供结构化反馈。它使用多阶段LLM管道来比较图并生成反思性反馈。此外，该工具为教育者提供了分析洞察，旨在促进自我导向学习并指导教学策略。我们通过六名参与者（包括两名教育者和四名助教）的半结构化访谈评估了DUET，他们指出了其优势，如易用性、可扩展性和学习支持，同时也提出了局限性，如可靠性及潜在的误用。参与者还建议了潜在的改进建议，如批量上传功能和交互式澄清功能。DUET为将LLM集成到建模教育中提供了一个有前景的方向，并为未来的课堂集成和实证评估奠定了基础。', 'title_zh': '使用大型语言模型自动评估学生生成的UML和ER图反馈'}
{'arxiv_id': 'arXiv:2507.23465', 'title': 'Role-Aware Language Models for Secure and Contextualized Access Control in Organizations', 'authors': 'Saeed Almheiri, Yerulan Kongrat, Adrian Santosh, Ruslan Tasmukhanov, Josemaria Vera, Muhammad Dehan Al Kautsar, Fajri Koto', 'link': 'https://arxiv.org/abs/2507.23465', 'abstract': 'As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts.', 'abstract_zh': '随着大规模语言模型（LLMs）在企业环境中的日益普及，基于用户角色控制模型行为成为一项基本要求。现有的安全方法通常假设统一访问，并专注于防止有害或有毒输出，而不考虑角色特定的访问约束。在本研究中，我们探讨是否可以对LLMs进行微调，使其生成反映不同组织角色相关访问权限的响应。我们探索了三种建模策略：基于BERT的分类器、基于LLM的分类器以及角色条件生成。为了评估这些方法，我们构建了两个互补的数据集。第一个数据集通过聚类和角色标签对现有指令微调语料库进行调整，而第二个数据集则是为了反映现实中的、具有角色敏感性的企业场景而合成生成的。我们评估了模型在不同组织结构下的性能，并分析了其对提示注入、角色不匹配和脱管攻击的鲁棒性。', 'title_zh': '面向角色的语言模型在组织中的安全与上下文化访问控制'}
{'arxiv_id': 'arXiv:2507.23386', 'title': 'Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models', 'authors': 'Ailiang Lin, Zhuoyun Li, Kotaro Funakoshi', 'link': 'https://arxiv.org/abs/2507.23386', 'abstract': "Decoder-only large language models (LLMs) are increasingly used to build embedding models that effectively encode the semantic information of natural language texts into dense vector representations for various embedding tasks. However, many existing methods primarily focus on removing the causal attention mask in LLMs to enable bidirectional attention, potentially undermining the model's ability to extract semantic information acquired during pretraining. Additionally, leading unidirectional approaches often rely on extra input text to overcome the inherent limitations of causal attention, inevitably increasing computational costs. In this work, we propose Causal2Vec, a general-purpose embedding model tailored to enhance the performance of decoder-only LLMs without altering their original architectures or introducing significant computational overhead. Specifically, we first employ a lightweight BERT-style model to pre-encode the input text into a single Contextual token, which is then prepended to the LLM's input sequence, allowing each token to capture contextualized information even without attending to future tokens. Furthermore, to mitigate the recency bias introduced by last-token pooling and help LLMs better leverage the semantic information encoded in the Contextual token, we concatenate the last hidden states of Contextual and EOS tokens as the final text embedding. In practice, Causal2Vec achieves state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB) among models trained solely on publicly available retrieval datasets, while reducing the required sequence length by up to 85% and inference time by up to 82% compared to best-performing methods.", 'abstract_zh': '仅解码大型语言模型（LLMs）越来越多地用于构建嵌入模型，有效将自然语言文本的语义信息编码为密集向量表示，以满足各种嵌入任务的需求。然而，许多现有方法主要集中在消除LLMs中的因果注意力掩码以实现双向注意力，这可能会削弱模型提取预训练过程中获得的语义信息的能力。此外，领先的单向方法通常依赖额外的输入文本以克服因果注意力的固有局限性，不可避免地增加了计算成本。在本工作中，我们提出了Causal2Vec，这是一种通用的嵌入模型，旨在不改变原始架构或引入显著的计算负担的情况下增强仅解码LLMs的性能。具体而言，我们首先使用一种轻量级的BERT风格模型对输入文本进行预编码，得到一个Contextual词元，然后将其添加到LLM的输入序列之前，使每个词元即使不关注后续词元也能捕获上下文信息。此外，为了减轻由最后词元池化引入的近期偏见，并帮助LLMs更好地利用嵌入在Contextual词元中的语义信息，我们将Contextual词元和EOS词元的最后隐藏状态连接起来作为最终的文本嵌入。实践表明，Causal2Vec在仅基于公开检索数据集训练的模型中，在大规模文本嵌入基准测试（MTEB）上达到了最佳性能，同时将所需序列长度减少了85%，推断时间减少了82%。', 'title_zh': '因果2Vec：提升作为通用嵌入模型的解码器唯一大语言模型性能'}
{'arxiv_id': 'arXiv:2507.23382', 'title': 'MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models', 'authors': 'Yiyan Ji, Haoran Chen, Qiguang Chen, Chengyue Wu, Libo Qin, Wanxiang Che', 'link': 'https://arxiv.org/abs/2507.23382', 'abstract': "Multimodal planning capabilities refer to the ability to predict, reason, and design steps for task execution with multimodal context, which is essential for complex reasoning and decision-making across multiple steps. However, current benchmarks face two key challenges: (1) they cannot directly assess multimodal real-world planning capabilities, and (2) they lack constraints or implicit constraints across modalities. To address these issues, we introduce Multimodal Planning with Complex Constraints (MPCC), the first benchmark to systematically evaluate MLLMs' ability to handle multimodal constraints in planning. To address the first challenge, MPCC focuses on three real-world tasks: Flight Planning, Calendar Planning, and Meeting Planning. To solve the second challenge, we introduce complex constraints (e.g. budget, temporal, and spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to separate constraint complexity from search space expansion. Experiments on 13 advanced MLLMs reveal significant challenges: closed-source models achieve only 21.3% feasible plans, while open-source models average below 11%. Additionally, we observe that MLLMs are highly sensitive to constraint complexity and that traditional multimodal prompting strategies fail in multi-constraint scenarios. Our work formalizes multimodal constraints in planning, provides a rigorous evaluation framework, and highlights the need for advancements in constraint-aware reasoning for real-world MLLM applications.", 'abstract_zh': '多模态规划能力包含在多模态上下文中预测、推理和设计任务执行步骤的能力，这对于在多个步骤中进行复杂推理和决策至关重要。然而，当前的基准面临两个关键挑战：（1）它们无法直接评估多模态实际世界的规划能力；（2）它们缺乏跨模态的约束或隐含约束。为了应对这些挑战，我们引入了多模态复杂约束规划（MPCC），这是第一个系统评估MLLMs处理规划中多模态约束能力的基准。为了应对第一个挑战，MPCC集中于三个实际任务：飞行规划、日历规划和会议规划。为了应对第二个挑战，我们在这三项任务中引入了复杂的约束（例如，预算、时间、空间约束），并引入了分级难度级别（EASY、MEDIUM、HARD），以区分约束复杂性和搜索空间的扩展。在13个先进MLLM上的实验揭示了重大挑战：闭源模型只能实现21.3%可行计划，而开源模型平均值低于11%。此外，我们观察到，MLLMs对约束复杂性非常敏感，传统的多模态提示策略在多约束场景中失效。我们的工作在规划中正式化了多模态约束，提供了一个严格的评估框架，并强调了在实际MLLM应用中对约束感知推理的发展需求。', 'title_zh': 'MPCC：多模态复杂约束规划的新型基准模型'}
{'arxiv_id': 'arXiv:2507.23370', 'title': 'Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling', 'authors': 'Trae Research Team, Pengfei Gao, Zhao Tian, Xiangxin Meng, Xinchen Wang, Ruida Hu, Yuanan Xiao, Yizhou Liu, Zhao Zhang, Junjie Chen, Cuiyun Gao, Yun Lin, Yingfei Xiong, Chao Peng, Xia Liu', 'link': 'https://arxiv.org/abs/2507.23370', 'abstract': 'Software issue resolution is a critical challenge in software engineering and has garnered increasing attention in recent years. With the rapid advancement of large language models (LLMs), substantial progress has been made in addressing real-world software engineering tasks. Recent studies have introduced ensemble reasoning techniques to enhance the performance of LLM-based issue resolution. However, existing prompting-based methods still face limitations in effectively exploring large ensemble spaces and lack the capacity for repository-level understanding, both of which constrain their overall effectiveness. In this paper, we propose Trae Agent, the first agent-based ensemble reasoning approach for repository-level issue resolution. Trae Agent formulates our goal as an optimal solution search problem and addresses two key challenges, i.e., large ensemble spaces and repository-level understanding, through modular agents for generation, pruning, and selection. We conduct extensive experiments using three leading LLMs on the widely-adopted SWE-bench benchmark, comparing Trae Agent against four state-of-the-art ensemble reasoning techniques. Experimental results demonstrate that Trae Agent consistently achieves superior performance, with an average improvement of 10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of 75.20%. We are pleased to release Trae Agent as an open-source project to support the research community, with all resources available at this https URL.', 'abstract_zh': '软件问题解决是软件工程中的关键挑战，近年来引起了越来越多的关注。随着大型语言模型（LLMs）的迅速发展，已在应对实际软件工程任务方面取得了显著进展。近年来的研究引入了集成推理技术以增强基于LLM的问题解决性能。然而，现有的基于提示的方法在有效地探索大型集成空间以及缺乏仓库级理解方面仍存在局限性，这些限制了它们的整体有效性。在本文中，我们提出了Trae Agent，这是第一个基于代理的仓库级问题解决集成推理方法。Trae Agent将我们的目标形式化为最优解搜索问题，并通过生成、裁剪和选择模块化代理来解决两个关键挑战，即大型集成空间和仓库级理解。我们在广泛采用的SWE-bench基准上使用三种领先的LLM进行了广泛实验，将Trae Agent与四种最先进的集成推理技术进行比较。实验结果表明，Trae Agent在Pass@1指标上始终保持 superiority，相较于所有基线平均提升10.22%。 Trae Agent在SWE-bench Verified排行榜上位居第一，Pass@1得分为75.20%。我们很高兴将Trae Agent作为开源项目发布，所有资源可访问此处 https://。', 'title_zh': 'Trae代理：一种基于LLM的软件工程代理，具备测试时扩展能力'}
{'arxiv_id': 'arXiv:2507.23365', 'title': '"I made this (sort of)": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation', 'authors': 'Bob L. T. Sturm', 'link': 'https://arxiv.org/abs/2507.23365', 'abstract': "I reflect on my experience creating two music albums centered on state-of-the-art prompt-based AI music generation platforms. The first album explicitly poses the question: What happens when I collide my junk mail with these platforms? The second album is a direct response to the first, and toys with the inability of state-of-the-art prompt-based AI music generation platforms to generate music that is not ``practiced'', ``polished'', and ``produced''. I seed a large language model (LLM) with information about these albums and have it interview me, which results in the exploration of several deeper questions: To what extent am I the author? Where am I in the resulting music? How is my musical identity changing as I am faced with machines that are in some ways far more talented than I? What new musical spaces does my work open, for me or anyone/thing else? I conclude by reflecting on my reflections, as well as LLM-mediated self-reflection as method.", 'abstract_zh': '我反思了自己创作两张以最先进的提示驱动AI音乐生成平台为中心的音乐专辑的经历。第一张专辑明确提出了一个问题：当我把垃圾邮件与这些平台相碰撞会发生什么呢？第二张专辑是对第一张专辑的直接回应，并探讨了最先进的提示驱动AI音乐生成平台无法生成非“练习过”、“润色过”和“制作过”的音乐的事实。我将一个大型语言模型（LLM）种子信息关于这些专辑，并让它采访我，结果引发了以下几个深层次的问题：我在多大程度上是作者？我的音乐在最终形成的音乐中处于怎样的位置？随着面对某些方面比我更有才华的机器，我的音乐身份发生了怎样的变化？我的作品开启了哪些新的音乐空间，对我来说或是对其他人/其他事物？最后，我反思了自己的反思，以及通过LLM中介的自我反思作为一种方法。', 'title_zh': '“我就是这样（某种程度上）做的”：基于提示的AI音乐生成中的作者身份协商、应对欺骗性和探索新的音乐空间'}
{'arxiv_id': 'arXiv:2507.23334', 'title': 'MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation', 'authors': 'Daeyong Kwon, SeungHeon Doh, Juhan Nam', 'link': 'https://arxiv.org/abs/2507.23334', 'abstract': "Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）已在多个领域展示了 remarkable 能力。尽管它们在各种任务上表现出强大的零样本性能，但由于训练数据中音乐特定知识的比例相对较小，LLMs 在音乐相关应用中的效果仍有限。为解决这一局限，我们提出了一种基于检索增强生成（RAG）的全面框架 MusT-RAG，以将通用语言模型适应于仅文本音乐问答（MQA）任务。RAG 是一种技术，通过在生成答案时检索相关上下文信息来为语言模型提供外部知识。为了优化 RAG 以适应音乐领域，我们（1）提出了一种专门为检索阶段设计的音乐专项向量数据库 MusWikiDB，（2）并在推理和微调过程中利用上下文信息，有效地将通用语言模型转变为音乐特定模型。我们的实验表明，MusT-RAG 显著优于传统的微调方法，在提升语言模型的音乐领域适应能力方面显示出一致的改进，不仅在领域内，还在领域外的 MQA 测量基准测试中。此外，我们证明 MusWikiDB 相较于通用维基百科语料库更为有效，提供更好的性能和计算效率。', 'title_zh': 'MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation'}
{'arxiv_id': 'arXiv:2507.23261', 'title': 'DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System', 'authors': 'Hui Yi Leong, Yuqing Wu', 'link': 'https://arxiv.org/abs/2507.23261', 'abstract': 'Current multi-agent systems (MAS) frameworks often rely on manually designed and static collaboration graph structures, limiting adaptability and performance. To address these limitations, we propose DynaSwarm, a dynamic framework that enhances LLM-based MAS through two key innovations: (1) an actor-critic reinforcement learning (A2C) mechanism to optimize graph structures with improved stability over prior RL methods, and (2) a dynamic graph selector that adaptively chooses the optimal graph structure for each input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the need for rigid, one-fits-all graph architectures, instead leveraging sample-specific idiosyncrasies to dynamically route queries through specialized agent networks. (c) We propose to fine-tune the demonstration retriever to fully exploit the power of in-context learning (ICL). Extensive experiments on question answering, mathematical reasoning, and coding tasks demonstrate that DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones. Our findings highlight the importance of sample-aware structural flexibility in LLM MAS designs.', 'abstract_zh': '当前的多Agent系统（MAS）框架往往依赖于手工设计且静态的协作图结构，限制了系统的适应性和性能。为了解决这些问题，我们提出DynaSwarm，这是一个通过两种关键创新增强基于LLM的MAS的动态框架：（1）一种改进的演员-评论家强化学习（A2C）机制，用于优化图结构，比之前的强化学习方法更具稳定性；（2）一个动态图选择器，通过参数高效的LLM微调，能够根据每个输入样本自适应地选择最优图结构。DynaSwarm消除了 rigid、one-fits-all 图架构的需要，而是利用样本特定的特性，动态地将查询路由到专门的Agent网络中。（c）我们提出微调示例检索器，以充分利用上下文学习（ICL）的力量。在问答、数学推理和编码任务上的广泛实验表明，DynaSwarm在多个LLM微调框架上始终优于最先进的单Agent和MAS基线系统。我们的研究结果强调了LLM MAS设计中样本感知结构灵活性的重要性。', 'title_zh': 'DynaSwarm：基于LLM的多agent系统动态图结构选择'}
{'arxiv_id': 'arXiv:2507.23194', 'title': 'Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks', 'authors': 'Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum', 'link': 'https://arxiv.org/abs/2507.23194', 'abstract': 'The demand for AI-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware-optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands. Major cloud providers, semiconductor companies, and research institutions are now investing heavily in AI-driven code generation for GPUs, aiming to reduce manual optimization efforts while achieving near-expert performance on hardware like AMD MI300X. The Triton language, a Python-based DSL for GPU programming, has emerged as a popular target for such AI-generated kernels due to its balance of performance and ease-of-coding. In this work, we present an evaluation suite for Triton-based GPU kernels and GEAK (Generating Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs to generate performant Triton code specifically for AMD GPUs, including the AMD MI300X and MI250. GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms. On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to $63$% and execution speed up of up to $2.59$X. These results highlight the promise of GEAK-like agentic code generation for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kernel performance.', 'abstract_zh': 'AI生成的GPU内核需求迅速增长：基于 Triton 的GPU内核评估套件与GEAK框架的研究', 'title_zh': 'Geak: 引入 Triton Kernel AI 代理及评估基准'}
{'arxiv_id': 'arXiv:2507.23190', 'title': 'Accessibility Scout: Personalized Accessibility Scans of Built Environments', 'authors': 'William Huang, Xia Su, Jon E. Froehlich, Yang Zhang', 'link': 'https://arxiv.org/abs/2507.23190', 'abstract': 'Assessing the accessibility of unfamiliar built environments is critical for people with disabilities. However, manual assessments, performed by users or their personal health professionals, are laborious and unscalable, while automatic machine learning methods often neglect an individual user\'s unique needs. Recent advances in Large Language Models (LLMs) enable novel approaches to this problem, balancing personalization with scalability to enable more adaptive and context-aware assessments of accessibility. We present Accessibility Scout, an LLM-based accessibility scanning system that identifies accessibility concerns from photos of built environments. With use, Accessibility Scout becomes an increasingly capable "accessibility scout", tailoring accessibility scans to an individual\'s mobility level, preferences, and specific environmental interests through collaborative Human-AI assessments. We present findings from three studies: a formative study with six participants to inform the design of Accessibility Scout, a technical evaluation of 500 images of built environments, and a user study with 10 participants of varying mobility. Results from our technical evaluation and user study show that Accessibility Scout can generate personalized accessibility scans that extend beyond traditional ADA considerations. Finally, we conclude with a discussion on the implications of our work and future steps for building more scalable and personalized accessibility assessments of the physical world.', 'abstract_zh': '评估不熟悉建成环境的可达性对于残疾人至关重要。然而，由用户或其个人健康专业人士进行的手动评估既费时又不具有可扩展性，而自动机器学习方法往往忽视了个人用户独特的需要。大型语言模型（LLMs）的最新进展为这一问题提供了新的方法，平衡个性化与可扩展性，以实现更具适应性和上下文感知的可达性评估。我们提出了一个基于大型语言模型的可达性扫描系统Accessibility Scout，能够从建成环境的照片中识别可达性问题。通过使用，Accessibility Scout 变得越来越“能干”，能够根据个人的行动能力、偏好和特定的环境兴趣进行个性化的可达性评估，通过协作的人机评估来进行。我们进行了三项研究：一项涉及六名参与者的形成性研究以指导Accessibility Scout的设计，一项对500张建成环境照片的技术评估，以及一项涉及10名不同行动能力参与者的用户研究。我们的技术评估和用户研究结果显示，Accessibility Scout能够生成超越传统ADA考虑的个性化可达性扫描。最后，我们讨论了我们工作的意义及其对未来构建更具可扩展性和个性化的物理世界可达性评估的展望。', 'title_zh': '可达性探查器：建成环境的个性化可达性检查'}
{'arxiv_id': 'arXiv:2507.23167', 'title': 'LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration', 'authors': 'Jizhou Guo', 'link': 'https://arxiv.org/abs/2507.23167', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive performance across various tasks, with different models excelling in distinct domains and specific abilities. Effectively combining the predictions of multiple LLMs is crucial for enhancing system robustness and performance. However, existing ensemble methods often rely on simple techniques like voting or logits ensembling, which overlook the varying confidence and reliability of models in different contexts. In this work, we propose LENS (Learning ENsemble confidence from Neural States), a novel approach that learns to estimate model confidence by analyzing internal representations. For each LLM, we train a lightweight linear confidence predictor that leverages layer-wise hidden states and normalized probabilities as inputs. This allows for more nuanced weighting of model predictions based on their context-dependent reliability. Our method does not require modifying the model parameters and requires negligible additional computation. Experimental results on multiple-choice and boolean question-answering tasks demonstrate that LENS outperforms traditional ensemble methods by a substantial margin. Our findings suggest that internal representations provide valuable signals for determining model confidence and can be effectively leveraged for ensemble learning.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中展现了出色的性能，不同的模型在特定领域和能力上表现出色。有效地结合多种LLMs的预测对于提升系统的稳健性和性能至关重要。然而，现有的ensemble方法通常依赖于简单的技术，如投票或logits ensemble，这些技术忽视了模型在不同上下文中不同置信度和可靠性。在本工作中，我们提出LENS（Learning ENsemble confidence from Neural States）这一新型方法，通过分析内部表示来学习估计模型的置信度。对于每一个LLM，我们训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这使得可以根据模型预测的上下文相关可靠性来进行更精细的加权。我们的方法不需要修改模型参数，并且所需的额外计算量微乎其微。在多项选择和布尔问答任务上的实验结果表明，LENS在传统ensemble方法上具有显著的优势。我们的研究结果表明，内部表示提供了确定模型置信度的有价值信号，并且可以有效地用于ensemble学习。', 'title_zh': 'LENS: 从神经状态学习集成置信度以实现多语言模型答案集成'}
{'arxiv_id': 'arXiv:2507.23121', 'title': 'Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity', 'authors': 'Xinwei Wu, Haojie Li, Hongyu Liu, Xinyu Ji, Ruohan Li, Yule Chen, Yigeng Zhang', 'link': 'https://arxiv.org/abs/2507.23121', 'abstract': 'In this work, we study a critical research problem regarding the trustworthiness of large language models (LLMs): how LLMs behave when encountering ambiguous narrative text, with a particular focus on Chinese textual ambiguity. We created a benchmark dataset by collecting and generating ambiguous sentences with context and their corresponding disambiguated pairs, representing multiple possible interpretations. These annotated examples are systematically categorized into 3 main categories and 9 subcategories. Through experiments, we discovered significant fragility in LLMs when handling ambiguity, revealing behavior that differs substantially from humans. Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous text, show overconfidence in interpreting ambiguous text as having a single meaning rather than multiple meanings, and exhibit overthinking when attempting to understand the various possible meanings. Our findings highlight a fundamental limitation in current LLMs that has significant implications for their deployment in real-world applications where linguistic ambiguity is common, calling for improved approaches to handle uncertainty in language understanding. The dataset and code are publicly available at this GitHub repository: this https URL.', 'abstract_zh': '在这项工作中，我们研究了一个关于大型语言模型（LLMs）可信度的关键研究问题：LLMs在遇到模棱两可的叙事文本时的行为，特别是对中国文本模棱两可性的关注。我们创建了一个基准数据集，通过收集并生成带有上下文的模棱两可句子及其对应的消歧义配对，表示多种可能的解释。这些标注的例子被系统地分为3个主要类别和9个子类别。通过实验，我们发现LLMs在处理模棱两可性时存在显著的脆弱性，揭示了与人类行为显著不同的行为特征。具体而言，LLMs不能可靠地区分模棱两可文本和非模棱两可文本，对模棱两可文本的解释表现出过度自信，认为模棱两可文本只有一种意义而不是多种意义，并且在试图理解各种可能的意义时表现出过度思考。我们的发现揭示了当前LLMs的基本局限性，这在语言模棱两可性普遍存在的真实世界应用中具有重要意义，呼吁改进语言理解中的不确定性处理方法。该数据集和代码在GitHub仓库中公开发布：this https URL。', 'title_zh': '通过中文文本歧义探究可信赖的大语言模型的脆弱性'}
{'arxiv_id': 'arXiv:2507.23087', 'title': 'On LLM-Assisted Generation of Smart Contracts from Business Processes', 'authors': 'Fabian Stiehle, Hans Weytjens, Ingo Weber', 'link': 'https://arxiv.org/abs/2507.23087', 'abstract': 'Large language models (LLMs) have changed the reality of how software is produced. Within the wider software engineering community, among many other purposes, they are explored for code generation use cases from different types of input. In this work, we present an exploratory study to investigate the use of LLMs for generating smart contract code from business process descriptions, an idea that has emerged in recent literature to overcome the limitations of traditional rule-based code generation approaches. However, current LLM-based work evaluates generated code on small samples, relying on manual inspection, or testing whether code compiles but ignoring correct execution. With this work, we introduce an automated evaluation framework and provide empirical data from larger data sets of process models. We test LLMs of different types and sizes in their capabilities of achieving important properties of process execution, including enforcing process flow, resource allocation, and data-based conditions. Our results show that LLM performance falls short of the perfect reliability required for smart contract development. We suggest future work to explore responsible LLM integrations in existing tools for code generation to ensure more reliable output. Our benchmarking framework can serve as a foundation for developing and evaluating such integrations.', 'abstract_zh': '大型语言模型（LLMs）已改变了软件生产的真实现状。在更广泛的软件工程社区中，它们被探索用于从不同类型的输入自动生成代码的各种用例。在本研究中，我们提出了一项探索性研究，探讨将LLMs用于生成基于业务流程描述的智能合约代码的应用，这一想法近期在文献中出现，旨在克服传统基于规则的代码生成方法的局限性。然而，目前基于LLM的工作主要在小样本上评估生成的代码，依赖于人工检查，或测试代码是否编译，而忽略了正确执行。通过本研究，我们引入了一种自动评估框架，并提供了从更大规模流程模型数据集中获得的经验数据。我们测试了不同类型和规模的LLMs在实现流程执行重要属性方面的能力，包括强制执行流程控制、资源分配以及数据驱动的条件。我们的结果表明，LLM性能未能达到智能合约开发所需的完美可靠性。我们建议未来工作探索将负责任的LLM集成到现有代码生成工具中，以确保更可靠的结果。我们的基准测试框架可以作为开发和评估此类集成的基础。', 'title_zh': '基于业务过程的LLM辅助智能合约生成'}
{'arxiv_id': 'arXiv:2507.23009', 'title': 'Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead', 'authors': 'Tom Sühr, Florian E. Dorner, Olawale Salaudeen, Augustin Kelava, Samira Samadi', 'link': 'https://arxiv.org/abs/2507.23009', 'abstract': "Large Language Models (LLMs) have achieved remarkable results on a range of standardized tests originally designed to assess human cognitive and psychological traits, such as intelligence and personality. While these results are often interpreted as strong evidence of human-like characteristics in LLMs, this paper argues that such interpretations constitute an ontological error. Human psychological and educational tests are theory-driven measurement instruments, calibrated to a specific human population. Applying these tests to non-human subjects without empirical validation, risks mischaracterizing what is being measured. Furthermore, a growing trend frames AI performance on benchmarks as measurements of traits such as ``intelligence'', despite known issues with validity, data contamination, cultural bias and sensitivity to superficial prompt changes. We argue that interpreting benchmark performance as measurements of human-like traits, lacks sufficient theoretical and empirical justification. This leads to our position: Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead. We call for the development of principled, AI-specific evaluation frameworks tailored to AI systems. Such frameworks might build on existing frameworks for constructing and validating psychometrics tests, or could be created entirely from scratch to fit the unique context of AI.", 'abstract_zh': '停止使用人类测试评估AI，开发原则性的AI专用评估框架', 'title_zh': '停止用人为主观评估AI，而是发展 principle-based、特定于AI 的评估方法。'}
{'arxiv_id': 'arXiv:2507.22940', 'title': 'Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes', 'authors': 'Rui Jiao, Yue Zhang, Jinku Li', 'link': 'https://arxiv.org/abs/2507.22940', 'abstract': 'We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy for Confidence Enhancement), a novel framework addressing a critical vulnerability in Large Language Models (LLMs): the prevalence of factual inaccuracies within intermediate reasoning steps despite correct final answers. This phenomenon poses substantial risks in high-stakes domains including healthcare, legal analysis, and scientific research, where erroneous yet confidently presented reasoning can mislead users into dangerous decisions. Our framework integrates three core components: (1) a specialized fact-checking classifier trained on counterfactually augmented data to detect subtle factual inconsistencies within reasoning chains; (2) a Group Relative Policy Optimization (GRPO) reinforcement learning approach that balances factuality, coherence, and structural correctness through multi-dimensional rewards; and (3) a mechanistic interpretability module examining how factuality improvements manifest in model activations during reasoning processes. Extensive evaluation across ten state-of-the-art models reveals concerning patterns: even leading models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual robustness (up to 49.90% improvement) while maintaining or improving performance on challenging benchmarks including Math-500, AIME-2024, and GPQA. Furthermore, our activation-level analysis provides actionable insights into how factual enhancements reshape reasoning trajectories within model architectures, establishing foundations for future training methodologies that explicitly target factual robustness through activation-guided optimization.', 'abstract_zh': 'RELIANCE：基于逻辑完整性和准确性提升的信心增强推理评价框架', 'title_zh': '可信赖的推理：评估和提升LLM中间思考过程的事实准确性'}
{'arxiv_id': 'arXiv:2507.22937', 'title': 'CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering', 'authors': 'Jinkun Zhao, Yuanshuai Wang, Xingjian Zhang, Ruibo Chen, Xingchuang Liao, Junle Wang, Lei Huang, Kui Zhang, Wenjun Wu', 'link': 'https://arxiv.org/abs/2507.22937', 'abstract': "With the rapid evolution of artificial intelligence, AIOps has emerged as a prominent paradigm in DevOps. Lots of work has been proposed to improve the performance of different AIOps phases. However, constrained by domain-specific knowledge, a single model can only handle the operation requirement of a specific task,such as log parser,root cause analysis. Meanwhile, combining multiple models can achieve more efficient results, which have been proved in both previous ensemble learning and the recent LLM training domain. Inspired by these works,to address the similar challenges in AIOPS, this paper first proposes a collaboration-of-expert framework(CoE-Ops) incorporating a general-purpose large language model task classifier. A retrieval-augmented generation mechanism is introduced to improve the framework's capability in handling both Question-Answering tasks with high-level(Code,build,Test,etc.) and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed method is implemented in the AIOps domain, and extensive experiments are conducted on the DevOps-EVAL dataset. Experimental results demonstrate that CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement over single AIOps models in DevOps problem resolution, and outperforms larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.", 'abstract_zh': '基于通用大型语言模型任务分类器的操作员合作框架（CoE-Ops）在AIOps中的应用', 'title_zh': 'CoE-Ops: 基于LLM的专家协作以实现AIOps问答'}
{'arxiv_id': 'arXiv:2507.22936', 'title': 'Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis', 'authors': 'Md Talha Mohsin', 'link': 'https://arxiv.org/abs/2507.22936', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide variety of Financial Natural Language Processing (FinNLP) tasks. However, systematic comparisons among widely used LLMs remain underexplored. Given the rapid advancement and growing influence of LLMs in financial analysis, this study conducts a thorough comparative evaluation of five leading LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the 'Magnificent Seven' technology companies. We create a set of domain-specific prompts and then use three methodologies to evaluate model performance: human annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity, Jaccard), and model behavior diagnostics (prompt-level variance and across-model similarity). The results show that GPT gives the most coherent, semantically aligned, and contextually relevant answers; followed by Claude and Perplexity. Gemini and DeepSeek, on the other hand, have more variability and less agreement. Also, the similarity and stability of outputs change from company to company and over time, showing that they are sensitive to how prompts are written and what source material is used.", 'abstract_zh': '大规模语言模型（LLMs）在金融自然语言处理（FinNLP）任务中展现了卓越的能力。然而，广泛使用的LLMs之间的系统性比较仍被忽视。鉴于LLMs在金融分析中的快速发展和影响，本研究使用来自“壮丽七 powerhouse”科技公司的10-K filings，对五种领先的LLM（GPT、Claude、Perplexity、Gemini和DeepSeek）进行了全面比较评估。我们创建了一组领域特定的提示，并使用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示级别差异性和模型间相似性）。结果表明，GPT给出的答案最为连贯、语义对齐且相关；其次是Claude和Perplexity。相比之下，Gemini和DeepSeek表现出更大差异性和较低的一致性。此外，输出的相似性和稳定性会因公司而异并在时间上变化，表明它们对提示的写法和所用数据源非常敏感。', 'title_zh': '评估大型语言模型（LLMs）在金融NLP中的表现：基于财务报告分析的 comparative study'}
{'arxiv_id': 'arXiv:2507.22935', 'title': 'Trusted Knowledge Extraction for Operations and Maintenance Intelligence', 'authors': 'Kathleen Mealey, Jonathan A. Karr Jr., Priscila Saboia Moreira, Paul R. Brenner, Charles F. Vardeman II', 'link': 'https://arxiv.org/abs/2507.22935', 'abstract': 'Deriving operational intelligence from organizational data repositories is a key challenge due to the dichotomy of data confidentiality vs data integration objectives, as well as the limitations of Natural Language Processing (NLP) tools relative to the specific knowledge structure of domains such as operations and maintenance. In this work, we discuss Knowledge Graph construction and break down the Knowledge Extraction process into its Named Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation Extraction functional components. We then evaluate sixteen NLP tools in concert with or in comparison to the rapidly advancing capabilities of Large Language Models (LLMs). We focus on the operational and maintenance intelligence use case for trusted applications in the aircraft industry. A baseline dataset is derived from a rich public domain US Federal Aviation Administration dataset focused on equipment failures or maintenance requirements. We assess the zero-shot performance of NLP and LLM tools that can be operated within a controlled, confidential environment (no data is sent to third parties). Based on our observation of significant performance limitations, we discuss the challenges related to trusted NLP and LLM tools as well as their Technical Readiness Level for wider use in mission-critical industries such as aviation. We conclude with recommendations to enhance trust and provide our open-source curated dataset to support further baseline testing and evaluation.', 'abstract_zh': '从组织数据仓库中提取运营智能是一项关键挑战，由于数据保密性与数据集成目标之间的二元性，以及自然语言处理（NLP）工具相对于运营和维护等特定领域知识结构的局限性。在本工作中，我们讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指解析、命名实体链接和关系提取的功能组件。然后，我们评估了十六种NLP工具，并将其与大型语言模型（LLMs）的快速进步能力进行对比。我们重点关注航空行业可信应用中的运营和维护智能用例。基线数据集源自一个丰富的美国联邦航空管理局公开领域数据集，专注于设备故障或维护需求。我们评估了可在受控、保密环境中运行的NLP和LLM工具的零样本性能（不向第三方发送数据）。基于我们对显著性能限制的观察，我们讨论了可信NLP和LLM工具面临的挑战及其在航空等关键行业更广泛应用的技术成熟度水平。最后，我们提出了增强信任的建议，并提供了一个开源的精选数据集，以支持进一步的基线测试和评估。', 'title_zh': '可信知识提取用于运营与维护intelligence'}
{'arxiv_id': 'arXiv:2507.22931', 'title': 'Enhancing RAG Efficiency with Adaptive Context Compression', 'authors': 'Shuyu Guo, Zhaochun Ren', 'link': 'https://arxiv.org/abs/2507.22931', 'abstract': 'Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but incurs significant inference costs due to lengthy retrieved contexts. While context compression mitigates this issue, existing methods apply fixed compression rates, over-compressing simple queries or under-compressing complex ones. We propose Adaptive Context Compression for RAG (ACC-RAG), a framework that dynamically adjusts compression rates based on input complexity, optimizing inference efficiency without sacrificing accuracy. ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with a context selector to retain minimal sufficient information, akin to human skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms fixed-rate methods and matches/unlocks over 4 times faster inference versus standard RAG while maintaining or improving accuracy.', 'abstract_zh': 'Retrieval-augmented generation with adaptive context compression for large language models', 'title_zh': '适配性上下文压缩增强RAG效率'}
{'arxiv_id': 'arXiv:2507.22928', 'title': 'How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding', 'authors': 'Xi Chen, Aske Plaat, Niki van Stein', 'link': 'https://arxiv.org/abs/2507.22928', 'abstract': 'Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on multi-step tasks, yet whether the generated "thoughts" reflect the true internal reasoning process is unresolved. We present the first feature-level causal study of CoT faithfulness. Combining sparse autoencoders with activation patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B while they tackle GSM8K math problems under CoT and plain (noCoT) prompting. Swapping a small set of CoT-reasoning features into a noCoT run raises answer log-probabilities significantly in the 2.8B model, but has no reliable effect in 70M, revealing a clear scale threshold. CoT also leads to significantly higher activation sparsity and feature interpretability scores in the larger model, signalling more modular internal computation. For example, the model\'s confidence in generating correct answers improves from 1.2 to 4.3. We introduce patch-curves and random-feature patching baselines, showing that useful CoT information is not only present in the top-K patches but widely distributed. Overall, our results indicate that CoT can induce more interpretable internal structures in high-capacity LLMs, validating its role as a structured prompting method.', 'abstract_zh': 'Chain-of-thought (CoT) 提示增强大规模语言模型在多步任务上的准确性，但生成的“思考过程”是否反映真实的内部推理过程尚不明确。我们首次进行了特征层面的 CoT 忠实性因果研究。结合稀疏自编码器与激活补丁技术，我们在 Pythia-70M 和 Pythia-2.8B 处理 GSM8K 数学问题时，提取了单义特征，并分别在 CoT 和无 CoT 提示下进行了比较。用少量的 CoT 推理特征替换无 CoT 运行中的特征，在 2.8B 模型中显著提高了答案对数概率，而对 70M 模型没有可靠的影响，揭示了一个明确的规模阈值。此外，CoT 还在较大的模型中导致显著更高的激活稀疏性和特征可解释性评分，表明内部计算更加模块化。例如，模型生成正确答案的信心从 1.2 提高到 4.3。我们引入了补丁曲线和随机特征补丁基准，表明有用的 CoT 信息不仅存在于前 K 补丁中，而是广泛分布的。总体而言，我们的结果表明 CoT 可以在高容量的 LLM 中诱导出更可解释的内部结构，验证了其作为结构化提示方法的角色。', 'title_zh': 'Chain of Thought是如何思考的？基于稀疏自编码的链式推理机理可解释性'}
{'arxiv_id': 'arXiv:2507.22925', 'title': 'Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents', 'authors': 'Haoran Sun, Shaoning Zeng', 'link': 'https://arxiv.org/abs/2507.22925', 'abstract': 'Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.', 'abstract_zh': '长时记忆是影响大型语言模型代理（LLM代理）推理能力的关键因素。通过有效集成过往交互的内存机制可以显著增强LLM代理的决策能力和上下文连贯性。尽管近期研究在内存存储和检索方面取得了进展，如将内存编码为密集向量以进行基于相似性的搜索或以图的形式组织知识，但这些方法往往在结构化内存组织和高效检索方面存在不足。为解决这些问题，我们提出了一种分层记忆（H-MEM）架构，该架构基于语义抽象程度多级组织和更新内存。每个记忆向量嵌入了一个位置索引编码，指向其在下一层相关的子记忆。在推理阶段，基于索引的路由机制可以实现逐层高效检索，而无需进行耗时的相似性计算。我们在LoCoMo数据集的五个任务设置上评估了该方法。实验结果表明，我们的方法在所有基准方法中表现出优越性，证明了其在长期对话场景中的有效性。', 'title_zh': '层级记忆以提高大规模语言模型代理长期推理效率'}
{'arxiv_id': 'arXiv:2507.22923', 'title': 'How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting', 'authors': 'Aman Gupta, Yingying Zhuang, Zhou Yu, Ziji Zhang, Anurag Beniwal', 'link': 'https://arxiv.org/abs/2507.22923', 'abstract': 'Despite advances in the multilingual capabilities of Large Language Models (LLMs), their performance varies substantially across different languages and tasks. In multilingual retrieval-augmented generation (RAG)-based systems, knowledge bases (KB) are often shared from high-resource languages (such as English) to low-resource ones, resulting in retrieved information from the KB being in a different language than the rest of the context. In such scenarios, two common practices are pre-translation to create a mono-lingual prompt and cross-lingual prompting for direct inference. However, the impact of these choices remains unclear. In this paper, we systematically evaluate the impact of different prompt translation strategies for classification tasks with RAG-enhanced LLMs in multilingual systems. Experimental results show that an optimized prompting strategy can significantly improve knowledge sharing across languages, therefore improve the performance on the downstream classification task. The findings advocate for a broader utilization of multilingual resource sharing and cross-lingual prompt optimization for non-English languages, especially the low-resource ones.', 'abstract_zh': '尽管大规模语言模型（LLMs）在多语言能力方面取得了进步，但其在不同语言和任务上的性能差异仍然很大。在基于多语言检索增强生成（RAG）的系统中，通常会从高资源语言（如英语）向低资源语言共享知识库（KB），导致从KB检索到的信息与上下文中的其余部分语言不同。在这种情况下，两种常见的做法是预先翻译以创建单语言提示和跨语言提示以进行直接推理。然而，这些选择的影响尚不明确。在本文中，我们系统地评估了不同提示翻译策略对带有RAG增强的大规模语言模型的跨语言分类任务的影响。实验结果表明，优化的提示策略可以显著改善跨语言的知识共享，从而提高下游分类任务的性能。这些发现倡导更广泛地利用多语言资源共享和跨语言提示优化，特别是一些低资源语言。', 'title_zh': '如何翻译以及在哪里翻译？跨语言LLM提示中翻译策略的影响'}
{'arxiv_id': 'arXiv:2507.22921', 'title': 'Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers', 'authors': 'Lee Harris', 'link': 'https://arxiv.org/abs/2507.22921', 'abstract': "Language models can capture complex relationships in given text, but these are notorious for being costly and for producing information that does not exist (i.e., hallucinations). Furthermore, the resources invested into producing this information would be wasted if it were incorrect. We address these issues by proposing, implementing, and applying the Language Model Chain (LMC) algorithm. In this, a language model's response to a given prompt about given text is only correct if it exists in the collection of possible (i.e., candidate) answers, and text corresponding to incorrect responses is fed into a more predictive (but slower) language model. This process is repeated for a collection of language models, or until all predictions about the text are correct. We used the LMC algorithm to extract patient dates of birth from medical documents, and combining a collection of language models in a multi-stage cascade significantly increased prediction speed and accuracy over individual language models, while greatly reducing the number of corresponding hallucinations. We believe that the novel LMC algorithm significantly contributes to the knowledge extraction field, and that this should be explored much further in the future.", 'abstract_zh': '语言模型可以通过捕捉给定文本中的复杂关系，但它们经常成本高昂并且会产生不存在的信息（即幻觉）。此外，如果这些信息不正确，投入的资源将被浪费。我们通过提出、实施并应用语言模型链（LMC）算法来解决这些问题。在该算法中，只有当语言模型的响应存在于可能的答案集合中时，其响应才是正确的；不正确的响应则会被输入到更具预测性（但速度较慢）的语言模型中。这一过程可以应用于多个语言模型，直到所有关于文本的预测都正确为止。我们使用LMC算法从医疗文档中提取患者出生日期，并且将多个语言模型在多阶段级联中使用，显著提高了预测速度和准确性，同时大幅减少了相应的幻觉现象。我们认为，新颖的LMC算法对知识抽取领域有重要贡献，并且未来应对此进行更深入的研究。', 'title_zh': '使用级联语言模型链和候选答案进行快速准确的上下文知识抽取'}
{'arxiv_id': 'arXiv:2507.22920', 'title': 'Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey', 'authors': 'Jindong Li, Yali Fu, Jiahong Liu, Linxiao Cao, Wei Ji, Menglin Yang, Irwin King, Ming-Hsuan Yang', 'link': 'https://arxiv.org/abs/2507.22920', 'abstract': 'The rapid advancement of large language models (LLMs) has intensified the need for effective mechanisms to transform continuous multimodal data into discrete representations suitable for language-based processing. Discrete tokenization, with vector quantization (VQ) as a central approach, offers both computational efficiency and compatibility with LLM architectures. Despite its growing importance, there is a lack of a comprehensive survey that systematically examines VQ techniques in the context of LLM-based systems. This work fills this gap by presenting the first structured taxonomy and analysis of discrete tokenization methods designed for LLMs. We categorize 8 representative VQ variants that span classical and modern paradigms and analyze their algorithmic principles, training dynamics, and integration challenges with LLM pipelines. Beyond algorithm-level investigation, we discuss existing research in terms of classical applications without LLMs, LLM-based single-modality systems, and LLM-based multimodal systems, highlighting how quantization strategies influence alignment, reasoning, and generation performance. In addition, we identify key challenges including codebook collapse, unstable gradient estimation, and modality-specific encoding constraints. Finally, we discuss emerging research directions such as dynamic and task-adaptive quantization, unified tokenization frameworks, and biologically inspired codebook learning. This survey bridges the gap between traditional vector quantization and modern LLM applications, serving as a foundational reference for the development of efficient and generalizable multimodal systems. A continuously updated version is available at: this https URL.', 'abstract_zh': '大型语言模型（LLMs）的迅速发展加剧了将连续多模态数据转换为适合基于语言处理的离散表示的有效机制的需求。作为中心方法的向量量化（VQ）提供了计算效率并兼容LLM架构。尽管其重要性日益增加，但缺乏系统地在LLM系统背景下审查VQ技术的全面综述。本工作通过呈现针对LLMs设计的第一个结构化分类和分析填补了这一空白。我们分类了8种代表性的VQ变体，涵盖经典和现代范式，并分析了它们的算法原理、训练动态及其与LLM管道的集成挑战。除了算法层面的调查，我们还讨论了现有研究在没有LLMs的经典应用、基于LLMs的单模态系统以及基于LLMs的多模态系统中的表现，强调量化策略如何影响对齐、推理和生成性能。此外，我们确定了关键挑战，包括码本崩溃、梯度估计不稳以及模态特定编码约束。最后，我们讨论了新兴的研究方向，包括动态和任务自适应量化、统一的分词框架以及受生物学启发的码本学习。本综述填补了传统向量量化与现代LLM应用之间的空白，为高效和可泛化的多模态系统的发展提供了基础参考。更新版本请参阅：this https URL。', 'title_zh': '离散令牌化为多模态LLMs：综述'}
{'arxiv_id': 'arXiv:2507.22919', 'title': 'A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations', 'authors': 'Qixuan Hu, Xumou Zhang, Jinman Kim, Florence Bourgeois, Adam G. Dunn', 'link': 'https://arxiv.org/abs/2507.22919', 'abstract': 'Objectives: With accurate estimates of expected safety results, clinical trials could be designed to avoid terminations and limit exposing participants to unnecessary risks. We evaluated methods for predicting serious adverse event (SAE) results in clinical trials using information only from their registrations prior to the trial. Material and Methods: We analysed 22,107 two-arm parallel interventional clinical trials from this http URL with structured summary results. Two prediction models were developed: a classifier predicting will experimental arm have higher SAE rates (area under the receiver operating characteristic curve; AUC) than control arm, and a regression model to predict the proportion of SAEs in control arms (root mean squared error; RMSE). A transfer learning approach using pretrained language models (e.g., ClinicalT5, BioBERT) was used for feature extraction, combined with downstream model for prediction. To maintain semantic representation in long trial texts exceeding localised language model input limits, a sliding window method was developed for embedding extraction. Results: The best model (ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a higher proportion of patients with SAEs. When predicting proportion of participants experiencing SAE in the control arm, the same model achieved RMSE of 18.6%. The sliding window approach consistently outperformed methods without it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across 12 regressors, the average absolute RMSE reduction was 1.58%. Discussion: Summary results data available at this http URL remains underutilised. The potential to estimate results of trials before they start is an opportunity to improve trial design and flag discrepancies between expected and reported safety results.', 'abstract_zh': '研究目的：通过准确估计预期的安全结果，临床试验可以被设计以避免提前终止并限制参与者面临不必要的风险。我们评估了仅使用临床试验注册信息（在试验前）来预测严重不良事件（SAE）结果的方法。材料与方法：我们分析了从这个网址获得的22,107项两臂并行的干预性临床试验，这些试验具有结构化的总结结果。开发了两种预测模型：一种分类器预测实验臂的SAE率是否高于对照臂（面积下接收器操作特征曲线下面积；AUC），一种回归模型预测对照臂的SAE比例（均方根误差；RMSE）。使用预训练语言模型（如ClinicalT5、BioBERT）进行特征提取，并结合下游模型进行预测。为保持长文本试验证据的语义表示，开发了一种滑动窗口方法进行嵌入提取。结果：最佳模型（ClinicalT5+Transformer+MLP）在预测哪一试验臂的患者中有更高比例的SAE方面达到了77.6%的AUC。在预测对照臂中经历SAE的参与者比例时，同一模型获得了18.6%的RMSE。滑动窗口方法在所有情况下都表现优于未使用该方法的方法。在12个分类器中，平均绝对AUC提升为2.00%，在12个回归器中，平均绝对RMSE减少为1.58%。讨论：该网址提供的总结结果数据尚未充分利用。在试验开始前估计试验结果的可能性为改善试验设计并指出预期与报告的安全结果之间的差异提供了机会。', 'title_zh': '一种新的语言模型用于预测临床试验前瞻性注册中的严重不良事件结果'}
{'arxiv_id': 'arXiv:2507.22917', 'title': 'Reading Between the Timelines: RAG for Answering Diachronic Questions', 'authors': 'Kwun Hang Lau, Ruiyuan Zhang, Weijie Shi, Xiaofang Zhou, Xiaojun Cheng', 'link': 'https://arxiv.org/abs/2507.22917', 'abstract': "While Retrieval-Augmented Generation (RAG) excels at injecting static, factual knowledge into Large Language Models (LLMs), it exhibits a critical deficit in handling longitudinal queries that require tracking entities and phenomena across time. This blind spot arises because conventional, semantically-driven retrieval methods are not equipped to gather evidence that is both topically relevant and temporally coherent for a specified duration. We address this challenge by proposing a new framework that fundamentally redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by disentangling a user's query into its core subject and its temporal window. It then employs a specialized retriever that calibrates semantic matching against temporal relevance, ensuring the collection of a contiguous evidence set that spans the entire queried period. To enable rigorous evaluation of this capability, we also introduce the Analytical Diachronic Question Answering Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus of real and synthetic financial news. Empirical results on ADQAB show that our approach yields substantial gains in answer accuracy, surpassing standard RAG implementations by 13% to 27%. This work provides a validated pathway toward RAG systems capable of performing the nuanced, evolutionary analysis required for complex, real-world questions. The dataset and code for this study are publicly available at this https URL.", 'abstract_zh': '尽管检索增强生成（RAG）在向大型语言模型（LLMs）注入静态事实性知识方面表现出色，但在处理需要跨时间追踪实体和现象的纵向查询时却存在着关键缺陷。这种盲点是因为传统的基于语义的检索方法无法收集既主题相关又时间连贯的证据，以满足特定的时间跨度需求。我们通过提出一种新的框架来解决这一挑战，该框架从根本上重新设计了RAG管道，使其融入时间逻辑。我们的方法首先将用户查询分解为核心主题和时间窗口。然后使用一个专门的检索器，该检索器根据时间相关性校准语义匹配，确保收集到的时间连续的证据集覆盖整个查询时期。为了对这一能力进行严格的评估，我们还引入了分析历时问答基准（ADQAB），这是一个基于真实和合成金融新闻混合语料库的具有挑战性的评估套件。ADQAB上的实验证据显示，我们的方法在答案准确性上取得了显著提升，相较于标准的RAG实现提高了13%至27%。本项工作为开发能够进行复杂现实问题所需细致进化分析的RAG系统提供了经过验证的路径。该研究的数据集和代码可在此网址获取。', 'title_zh': '跨越时间线的阅读：基于RAG的历时性问题回答'}
{'arxiv_id': 'arXiv:2507.22915', 'title': 'Theoretical Foundations and Mitigation of Hallucination in Large Language Models', 'authors': 'Esmail Gumaan', 'link': 'https://arxiv.org/abs/2507.22915', 'abstract': 'Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretical analyses. We distinguish between intrinsic and extrinsic hallucinations, and define a \\textit{hallucination risk} for models. We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes and Rademacher complexity). We then survey detection strategies for hallucinations, such as token-level uncertainty estimation, confidence calibration, and attention alignment checks. On the mitigation side, we discuss approaches including retrieval-augmented generation, hallucination-aware fine-tuning, logit calibration, and the incorporation of fact-verification modules. We propose a unified detection and mitigation workflow, illustrated with a diagram, to integrate these strategies. Finally, we outline evaluation protocols for hallucination, recommending datasets, metrics, and experimental setups to quantify and reduce hallucinations. Our work lays a theoretical foundation and practical guidelines for addressing the crucial challenge of hallucination in LLMs.', 'abstract_zh': '大型语言模型中的幻觉指的是生成与输入或现实世界事实不相符的内容。本文对大型语言模型中的幻觉提供了严格的处理，包括形式定义和理论分析。我们区分内在幻觉和外在幻觉，并为模型定义了幻觉风险。我们使用学习理论框架（PAC-Bayes和Rademacher复杂性）推导出这一风险的界。然后，我们概述了幻觉检测策略，如标记级不确定性估计、置信度校准和注意力对齐检查。在缓解方面，我们讨论了包括检索增强生成、幻觉感知微调、logit校准以及事实验证模块纳入在内的方法。我们提出了一种统一的检测和缓解工作流，以图表形式阐明这些策略。最后，我们提出了幻觉评估协议，推荐了数据集、评价指标和实验设置，以量化和减少幻觉。我们的工作为解决大型语言模型中的幻觉问题奠定了理论基础并提供了实用指南。', 'title_zh': '大型语言模型中的幻觉理论基础及其缓解方法'}
{'arxiv_id': 'arXiv:2507.22913', 'title': 'A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models', 'authors': 'Jinyu Liu, Xiaoying Song, Diana Zhang, Jason Thomale, Daqing He, Lingzi Hong', 'link': 'https://arxiv.org/abs/2507.22913', 'abstract': 'Providing subject access to information resources is an essential function of any library management system. Large language models (LLMs) have been widely used in classification and summarization tasks, but their capability to perform subject analysis is underexplored. Multi-label classification with traditional machine learning (ML) models has been used for subject analysis but struggles with unseen cases. LLMs offer an alternative but often over-generate and hallucinate. Therefore, we propose a hybrid framework that integrates embedding-based ML models with LLMs. This approach uses ML models to (1) predict the optimal number of LCSH labels to guide LLM predictions and (2) post-edit the predicted terms with actual LCSH terms to mitigate hallucinations. We experimented with LLMs and the hybrid framework to predict the subject terms of books using the Library of Congress Subject Headings (LCSH). Experiment results show that providing initial predictions to guide LLM generations and imposing post-edits result in more controlled and vocabulary-aligned outputs.', 'abstract_zh': '为信息资源提供主题访问是任何图书馆管理系统的基本功能。大型语言模型（LLMs）在分类和总结任务中已被广泛应用，但在执行主题分析方面的能力尚未得到充分探索。传统机器学习（ML）模型的多标签分类已被用于主题分析，但难以应对未见过的情况。LLMs 提供了一种替代方案，但常常过度生成和虚构。因此，我们提出一种集成基于嵌入的机器学习模型与LLMs的混合框架。该方法利用机器学习模型来（1）预测LCSH标签的最佳数量以指导LLM预测，并（2）使用实际的LCSH术语进行后续编辑以减少虚构现象。我们使用LLMs和混合框架，基于美国国会图书馆主题 headings（LCSH）预测图书的主题术语。实验结果表明，提供初始预测以指导LLM生成，并实施后续编辑，可以得到更加可控和符合词汇表的输出。', 'title_zh': '基于嵌入表示回归模型与大规模语言模型的混合框架：主题分析集成'}
{'arxiv_id': 'arXiv:2507.22912', 'title': 'A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms', 'authors': 'Navid Yazdanjue, Morteza Rakhshaninejad, Hossein Yazdanjouei, Mohammad Sadegh Khorshidi, Mikko S. Niemela, Fang Chen, Amir H. Gandomi', 'link': 'https://arxiv.org/abs/2507.22912', 'abstract': 'Illegal marketplaces have increasingly shifted to concealed parts of the internet, including the deep and dark web, as well as platforms such as Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of illicit goods including drugs, weapons, and stolen credentials. Detecting and categorizing such content remains challenging due to limited labeled data, the evolving nature of illicit language, and the structural heterogeneity of online sources. This paper presents a hierarchical classification framework that combines fine-tuned language models with a semi-supervised ensemble learning strategy to detect and classify illicit marketplace content across diverse platforms. We extract semantic representations using ModernBERT, a transformer model for long documents, finetuned on domain-specific data from deep and dark web pages, Telegram channels, Subreddits, and Pastebin pastes to capture specialized jargon and ambiguous linguistic patterns. In addition, we incorporate manually engineered features such as document structure, embedded patterns including Bitcoin addresses, emails, and IPs, and metadata, which complement language model embeddings. The classification pipeline operates in two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random Forest, and SVM with entropy-based weighted voting to detect sales-related documents. The second stage further classifies these into drug, weapon, or credential sales. Experiments on three datasets, including our multi-source corpus, DUTA, and CoDA, show that our model outperforms several baselines, including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of 0.95388, demonstrating strong generalization, robustness under limited supervision, and effectiveness in real-world illicit content detection.', 'abstract_zh': '非法市场正逐渐转向互联网的隐蔽部分，包括深网、暗网，以及Telegram、Reddit和Pastebin等平台。这些渠道使毒品、武器和被盗凭据等非法商品的匿名交易成为可能。由于缺乏标注数据、非法用语的演变以及在线来源的结构性异质性，检测和分类此类内容仍然具有挑战性。本文 presents一种分层分类框架，结合了微调的语言模型与半监督集成学习策略，以跨多种平台检测和分类非法市场内容。', 'title_zh': '基于语言模型驱动的半监督集成框架：跨深/暗网和社会平台的非法市场检测'}
{'arxiv_id': 'arXiv:2507.22911', 'title': 'ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing', 'authors': 'Jinzhi Wang, Qingke Peng, Haozhou Li, Zeyuan Zeng, Qinfeng Song, Kaixuan Yang, Jiangbo Zhang, Yaoying Wang, Ruimeng Li, Biyi Zhou', 'link': 'https://arxiv.org/abs/2507.22911', 'abstract': "Electric power marketing customer service plays a critical role in addressing inquiries, complaints, and service requests. However, current systems, such as China's 95598 hotline, often struggle with slow response times, inflexible procedures, and limited accuracy in domain-specific tasks. While large language models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities, they lack the domain expertise and empathy required in this field. To bridge this gap, we introduce ElectriQ, the first benchmark designed to evaluate and enhance LLMs in electric power marketing scenarios. ElectriQ consists of a dialogue dataset covering six key service categories and introduces four evaluation metrics: professionalism, popularity, readability, and user-friendliness. We further incorporate a domain-specific knowledge base and propose a knowledge augmentation method to boost model performance. Experiments on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and augmented, can surpass GPT-4o in terms of professionalism and user-friendliness. ElectriQ establishes a comprehensive foundation for developing LLMs tailored to the needs of power marketing services.", 'abstract_zh': '电能营销客户服务在处理问询、投诉和服务请求方面发挥着关键作用。然而，当前的系统，如中国的95598热线，往往面临响应缓慢、程序僵化以及在特定领域任务上的准确性有限的问题。虽然大型语言模型（LLMs）如GPT-4o和Claude 3展示了强大的通用能力，但在这一领域缺乏专业知识和同理心。为了弥合这一差距，我们引入了ElectriQ，这是首个旨在评估和提升LLMs在电能营销场景中的基准测试。ElectriQ包含一个涵盖六类关键服务的对话数据集，并引入了四个评估指标：专业性、受欢迎度、易读性和用户友好性。我们进一步整合了领域专业知识库，并提出了一种知识增强方法以提升模型性能。对13种LLM的实验结果显示，经过微调和增强的小型模型，如LLama3-8B，在专业性和用户友好性方面可以超越GPT-4o。ElectriQ为开发满足电力营销服务需求的LLM奠定了全面的基础。', 'title_zh': 'ElectriQ: 评估大型语言模型在电力营销场景下响应能力的基准'}
{'arxiv_id': 'arXiv:2507.22910', 'title': 'Large Language Models in the Travel Domain: An Industrial Experience', 'authors': 'Sergio Di Meglio, Aniello Somma, Luigi Libero Lucio Starace, Fabio Scippacercola, Giancarlo Sperlì, Sergio Di Martino', 'link': 'https://arxiv.org/abs/2507.22910', 'abstract': 'Online property booking platforms are widely used and rely heavily on consistent, up-to-date information about accommodation facilities, often sourced from third-party providers. However, these external data sources are frequently affected by incomplete or inconsistent details, which can frustrate users and result in a loss of market. In response to these challenges, we present an industrial case study involving the integration of Large Language Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B, fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt. Both models were assessed based on their ability to generate consistent and homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision (98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet more concise content (249 vs. 277 words on average). However, this came at a significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB and $0.16/hour for Mistral 7B. Our findings provide practical insights into the trade-offs between model quality and resource efficiency, offering guidance for deploying LLMs in production environments and demonstrating their effectiveness in enhancing the consistency and reliability of accommodation data.', 'abstract_zh': '基于大型语言模型的在线房产预订平台数据整合工业案例研究：以FERVENTO的CALEIDOHOTELS平台为例', 'title_zh': '大型语言模型在旅游领域的应用：工业实践'}
{'arxiv_id': 'arXiv:2507.22902', 'title': 'Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting', 'authors': 'Hashim Hayat, Maksim Kudrautsau, Evgeniy Makarov, Vlad Melnichenko, Tim Tsykunou, Piotr Varaksin, Matt Pavelle, Adam Z. Oskowitz', 'link': 'https://arxiv.org/abs/2507.22902', 'abstract': 'Background: Globally we face a projected shortage of 11 million healthcare practitioners by 2030, and administrative burden consumes 50% of clinical time. Artificial intelligence (AI) has the potential to help alleviate these problems. However, no end-to-end autonomous large language model (LLM)-based AI system has been rigorously evaluated in real-world clinical practice. In this study, we evaluated whether a multi-agent LLM-based AI framework can function autonomously as an AI doctor in a virtual urgent care setting. Methods: We retrospectively compared the performance of the multi-agent AI system Doctronic and board-certified clinicians across 500 consecutive urgent-care telehealth encounters. The primary end points: diagnostic concordance, treatment plan consistency, and safety metrics, were assessed by blinded LLM-based adjudication and expert human review. Results: The top diagnosis of Doctronic and clinician matched in 81% of cases, and the treatment plan aligned in 99.2% of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not supported by clinical findings). In an expert review of discordant cases, AI performance was superior in 36.1%, and human performance was superior in 9.3%; the diagnoses were equivalent in the remaining cases. Conclusions: In this first large-scale validation of an autonomous AI doctor, we demonstrated strong diagnostic and treatment plan concordance with human clinicians, with AI performance matching and in some cases exceeding that of practicing clinicians. These findings indicate that multi-agent AI systems achieve comparable clinical decision-making to human providers and offer a potential solution to healthcare workforce shortages.', 'abstract_zh': '背景：全球到2030年预计将面临1100万名医疗卫生从业者短缺的问题，行政负担消耗了临床时间的50%。人工智能（AI）有潜力帮助解决这些问题。然而，目前尚无基于大型语言模型（LLM）的端到端自主AI系统在真实临床环境中得到严格的评估。在这项研究中，我们评估了一种基于多智能体的LLM AI框架是否可以在虚拟急诊环境中自主运行作为AI医生。', 'title_zh': '朝着自主人工智能医生的愿景：在实际应用场景中，自主代理人工智能与认证临床医生的定量基准测试'}
{'arxiv_id': 'arXiv:2507.22897', 'title': 'RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems', 'authors': 'Luyu Chen, Quanyu Dai, Zeyu Zhang, Xueyang Feng, Mingyu Zhang, Pengcheng Tang, Xu Chen, Yue Zhu, Zhenhua Dong', 'link': 'https://arxiv.org/abs/2507.22897', 'abstract': 'Conversational recommender systems (CRS) enhance user experience through multi-turn interactions, yet evaluating CRS remains challenging. User simulators can provide comprehensive evaluations through interactions with CRS, but building realistic and diverse simulators is difficult. While recent work leverages large language models (LLMs) to simulate user interactions, they still fall short in emulating individual real users across diverse scenarios and lack explicit rating mechanisms for quantitative evaluation. To address these gaps, we propose RecUserSim, an LLM agent-based user simulator with enhanced simulation realism and diversity while providing explicit scores. RecUserSim features several key modules: a profile module for defining realistic and diverse user personas, a memory module for tracking interaction history and discovering unknown preferences, and a core action module inspired by Bounded Rationality theory that enables nuanced decision-making while generating more fine-grained actions and personalized responses. To further enhance output control, a refinement module is designed to fine-tune final responses. Experiments demonstrate that RecUserSim generates diverse, controllable outputs and produces realistic, high-quality dialogues, even with smaller base LLMs. The ratings generated by RecUserSim show high consistency across different base LLMs, highlighting its effectiveness for CRS evaluation.', 'abstract_zh': '基于大语言模型的增强现实用户模拟器（RecUserSim）：提升对话推荐系统评价的现实性和多样性', 'title_zh': 'RecUserSim: 一种用于评估对话推荐系统的现实且多样的用户模拟器'}
{'arxiv_id': 'arXiv:2507.22890', 'title': 'Evaluating LLMs for Visualization Generation and Understanding', 'authors': 'Saadiq Rauf Khan, Vinit Chandak, Sougata Mukherjea', 'link': 'https://arxiv.org/abs/2507.22890', 'abstract': 'Information Visualization has been utilized to gain insights from complex data. In recent times, Large Language models (LLMs) have performed very well in many tasks. In this paper, we showcase the capabilities of different popular LLMs to generate code for visualization based on simple prompts. We also analyze the power of LLMs to understand some common visualizations by answering questions. Our study shows that LLMs could generate code for some simpler visualizations such as bar and pie charts. Moreover, they could answer simple questions about visualizations. However, LLMs also have several limitations. For example, some of them had difficulty generating complex visualizations, such as violin plot. LLMs also made errors in answering some questions about visualizations, for example, identifying relationships between close boundaries and determining lengths of shapes. We believe that our insights can be used to improve both LLMs and Information Visualization systems.', 'abstract_zh': '大规模语言模型在生成可视化代码方面的能力及限制研究', 'title_zh': '评估Large Language Models在生成与理解可视化方面的能力'}
{'arxiv_id': 'arXiv:2503.21813', 'title': 'OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching', 'authors': 'Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang', 'link': 'https://arxiv.org/abs/2503.21813', 'abstract': 'Hallucinations are often inevitable in downstream tasks using large language models (LLMs). To tackle the substantial challenge of addressing hallucinations for LLM-based ontology matching (OM) systems, we introduce a new benchmark dataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the Ontology Alignment Evaluation Initiative (OAEI), capturing hallucinations of ten different LLMs performing OM tasks. These OM-specific hallucinations are organised into two primary categories and six sub-categories. We showcase the usefulness of the dataset in constructing an LLM leaderboard for OM tasks and for fine-tuning LLMs used in OM tasks.', 'abstract_zh': '大型语言模型（LLMs）在下游任务中经常出现幻觉。为应对基于LLM的本体匹配（OM）系统中幻觉带来的重大挑战，我们引入了一个新的基准数据集OAEI-LLM-T。该数据集源自Ontology Alignment Evaluation Initiative (OAEI)中的七个TBox数据集，涵盖了十种不同LLM执行本体匹配任务时出现的幻觉。这些OM特定的幻觉被组织成两个主要类别和六个子类别。我们展示了该数据集在构建OM任务的LLM排行榜以及Fine-tuning用于OM任务的LLM方面的实用性。', 'title_zh': 'OAEI-LLM-T：一个用于理解大型语言模型在本体匹配中幻觉现象的TBox基准数据集'}
