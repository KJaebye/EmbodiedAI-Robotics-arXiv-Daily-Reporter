{'arxiv_id': 'arXiv:2504.02822', 'title': 'Do Two AI Scientists Agree?', 'authors': 'Xinghong Fu, Ziming Liu, Max Tegmark', 'link': 'https://arxiv.org/abs/2504.02822', 'abstract': 'When two AI models are trained on the same scientific task, do they learn the same theory or two different theories? Throughout history of science, we have witnessed the rise and fall of theories driven by experimental validation or falsification: many theories may co-exist when experimental data is lacking, but the space of survived theories become more constrained with more experimental data becoming available. We show the same story is true for AI scientists. With increasingly more systems provided in training data, AI scientists tend to converge in the theories they learned, although sometimes they form distinct groups corresponding to different theories. To mechanistically interpret what theories AI scientists learn and quantify their agreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI Scientists, trained on standard problems in physics, aggregating training results across many seeds simulating the different configurations of AI scientists. Our findings suggests for AI scientists switch from learning a Hamiltonian theory in simple setups to a Lagrangian formulation when more complex systems are introduced. We also observe strong seed dependence of the training dynamics and final learned weights, controlling the rise and fall of relevant theories. We finally demonstrate that not only can our neural networks aid interpretability, it can also be applied to higher dimensional problems.', 'abstract_zh': '当两个AI模型在同一科学任务上训练时，它们学习相同的理论还是不同的理论？随着科学史的发展，我们见证了由实验验证或证伪驱动的理论兴衰：当实验数据缺乏时，可能存在多种理论共存，但随着可用实验数据的增加，幸存理论的空间变得更加受限。我们展示在AI科学家的情况也是如此。随着训练数据中系统数量的不断增加，AI科学家倾向于在其学习的理论中趋同，尽管有时它们会形成不同的群体，对应于不同的理论。为了机械地解释AI科学家学习的理论及其一致程度，我们提出了MASS，即基于哈密顿-拉格朗日神经网络的AI科学家，并在物理学的标准问题上进行训练，汇总来自许多随机种子的训练结果，模拟不同配置的AI科学家。我们的研究结果表明，当从简单配置到更复杂系统时，AI科学家的学习从哈密顿理论转变为拉格朗日形式。我们还观察到训练动力学和最终学习权重的强烈随机种子依赖性，控制相关理论的兴衰。最后，我们证明我们的神经网络不仅有助于提高可解释性，还可以应用于更高维度的问题。', 'title_zh': '两AI科学家意见一致吗？'}
{'arxiv_id': 'arXiv:2504.02793', 'title': 'A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models', 'authors': 'Gaurav Verma, Jiawei Zhou, Mohit Chandra, Srijan Kumar, Munmun De Choudhury', 'link': 'https://arxiv.org/abs/2504.02793', 'abstract': 'Large artificial intelligence (AI) models have garnered significant attention for their remarkable, often "superhuman", performance on standardized benchmarks. However, when these models are deployed in high-stakes verticals such as healthcare, education, and law, they often reveal notable limitations. For instance, they exhibit brittleness to minor variations in input data, present contextually uninformed decisions in critical settings, and undermine user trust by confidently producing or reproducing inaccuracies. These challenges in applying large models necessitate cross-disciplinary innovations to align the models\' capabilities with the needs of real-world applications. We introduce a framework that addresses this gap through a layer-wise abstraction of innovations aimed at meeting users\' requirements with large models. Through multiple case studies, we illustrate how researchers and practitioners across various fields can operationalize this framework. Beyond modularizing the pipeline of transforming large models into useful "vertical systems", we also highlight the dynamism that exists within different layers of the framework. Finally, we discuss how our framework can guide researchers and practitioners to (i) optimally situate their innovations (e.g., when vertical-specific insights can empower broadly impactful vertical-agnostic innovations), (ii) uncover overlooked opportunities (e.g., spotting recurring problems across verticals to develop practically useful foundation models instead of chasing benchmarks), and (iii) facilitate cross-disciplinary communication of critical challenges (e.g., enabling a shared vocabulary for AI developers, domain experts, and human-computer interaction scholars).', 'abstract_zh': '大型人工智能模型在标准化基准上的出色表现吸引了广泛关注，但在医疗、教育和法律等高风险领域部署时，往往暴露出显著的局限性。这些挑战促使我们需要跨学科创新，以调整模型能力以满足实际应用的需求。我们提出一种框架，通过分层抽象创新，旨在利用大型模型满足用户需求。通过多个案例研究，我们展示了不同领域研究人员和实践者如何实现这一框架的落地。该框架不仅模块化了将大型模型转化为实用垂直系统的管道，还突显了框架各层中的动态性。最后，我们讨论了该框架如何指导研究人员和实践者：（i）优化创新定位（如，将垂直领域的洞察应用于普遍具有广泛影响的无垂直设定的创新），（ii）发现被忽视的机会（如，识别垂直领域中的重复问题，发展实用性基础模型而不是追求基准），以及（iii）促进跨学科关键挑战的沟通（如，为人工智能开发者、领域专家和人机交互学者提供共享的术语）。', 'title_zh': '一种关于推进垂直系统中大型AI模型应用中创新、机遇与挑战的框架研究'}
{'arxiv_id': 'arXiv:2504.02701', 'title': 'Responsible Development of Offensive AI', 'authors': 'Ryan Marinelli', 'link': 'https://arxiv.org/abs/2504.02701', 'abstract': 'As AI advances, broader consensus is needed to determine research priorities. This endeavor discusses offensive AI and provides guidance by leveraging Sustainable Development Goals (SDGs) and interpretability techniques. The objective is to more effectively establish priorities that balance societal benefits against risks. The two forms of offensive AI evaluated in this study are vulnerability detection agents, which solve Capture- The-Flag challenges, and AI-powered malware.', 'abstract_zh': '随着人工智能的发展，需要形成更广泛的共识来确定研究优先级。本研究探讨了攻击型人工智能，并通过可持续发展目标（SDGs）和可解释性技术提供指导，旨在更有效地确立平衡社会利益与风险的优先级。本研究评估了两种形式的攻击型人工智能：漏洞检测代理，它们解决Capture-The-Flag挑战，以及人工智能驱动的恶意软件。', 'title_zh': '负责任地开发进攻性AI'}
{'arxiv_id': 'arXiv:2504.02670', 'title': 'Affordable AI Assistants with Knowledge Graph of Thoughts', 'authors': 'Maciej Besta, Lorenzo Paleari, Jia Hao Andrea Jiang, Robert Gerstenberger, You Wu, Patrick Iff, Ales Kubicek, Piotr Nyczyk, Diana Khimey, Jón Gunnar Hannesson, Grzegorz Kwaśniewski, Marcin Copik, Hubert Niewiadomski, Torsten Hoefler', 'link': 'https://arxiv.org/abs/2504.02670', 'abstract': 'Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose the Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini, while reducing costs by over 36x compared to GPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and 37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a scalable, affordable, and high-performing solution for AI assistants.', 'abstract_zh': '大型语言模型（LLMs）正在颠覆跨领域能够执行多样化任务的AI助手的发展。然而，当前最先进的LLM驱动代理面临显著挑战，包括高昂的运营成本和在GAIA等复杂基准测试上有限的成功率。为了解决这些问题，我们提出了思维知识图谱（KGoT）这一创新的AI助手架构，它将LLM推理与动态构建的知识图谱（KGs）集成。KGoT提取并结构化与任务相关知识，通过外部工具如数学求解器、网页爬虫和Python脚本进行迭代增强。这种结构化表示使得低成本模型能够有效解决复杂任务。例如，KGoT在GAIA基准测试中的任务成功率比使用GPT-4o mini的Hugging Face代理提高了29%，同时成本降低了36倍以上，与GPT-4o相比。最近的推理模型也有类似改进，如Qwen2.5-32B的36%和Deepseek-R1-70B的37.5%。KGoT提供了一种可扩展、经济高效且高性能的AI助手解决方案。', 'title_zh': '具有思维知识图谱的可负担AI助手'}
{'arxiv_id': 'arXiv:2504.02654', 'title': 'SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning', 'authors': 'Ivo Amador, Nina Gierasimczuk', 'link': 'https://arxiv.org/abs/2504.02654', 'abstract': 'We propose a learning architecture that allows symbolic control and guidance in reinforcement learning with deep neural networks. We introduce SymDQN, a novel modular approach that augments the existing Dueling Deep Q-Networks (DuelDQN) architecture with modules based on the neuro-symbolic framework of Logic Tensor Networks (LTNs). The modules guide action policy learning and allow reinforcement learning agents to display behaviour consistent with reasoning about the environment. Our experiment is an ablation study performed on the modules. It is conducted in a reinforcement learning environment of a 5x5 grid navigated by an agent that encounters various shapes, each associated with a given reward. The underlying DuelDQN attempts to learn the optimal behaviour of the agent in this environment, while the modules facilitate shape recognition and reward prediction. We show that our architecture significantly improves learning, both in terms of performance and the precision of the agent. The modularity of SymDQN allows reflecting on the intricacies and complexities of combining neural and symbolic approaches in reinforcement learning.', 'abstract_zh': '我们提出一种学习架构，允许在深度神经网络中进行符号控制和指导的强化学习。我们引入了SymDQN，这是一种新颖的模块化方法，将基于逻辑张量网络（LTNs）的神经符号框架模块集成到现有的 Dueling Deep Q-Networks（DuelDQN）架构中。这些模块指导动作策略学习，并允许强化学习代理表现出与环境推理一致的行为。我们的实验是对模块的消融研究，在一个5x5网格环境中进行，该环境中有一个代理遇到各种形状，每种形状对应一个给定的奖励。DuelingDQN试图学习代理在该环境中的最优行为，而模块则促进形状识别和奖励预测。我们证明，我们的架构在性能和代理精度方面显著提高了学习效果。SymDQN的模块化设计允许我们探讨在强化学习中结合神经和符号方法的复杂性和细微之处。', 'title_zh': 'SymDQN: 基于神经网络的强化学习中符号知识与推理GORITHM'}
{'arxiv_id': 'arXiv:2504.02623', 'title': 'Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions', 'authors': 'PeiJie Yu, Yifan Yang, Jinjian Li, Zelong Zhang, Haorui Wang, Xiao Feng, Feng Zhang', 'link': 'https://arxiv.org/abs/2504.02623', 'abstract': 'Large language models (LLMs) demonstrate strong potential as agents for tool invocation due to their advanced comprehension and planning capabilities. Users increasingly rely on LLM-based agents to solve complex missions through iterative interactions. However, existing benchmarks predominantly access agents in single-mission scenarios, failing to capture real-world complexity. To bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark, each test case comprises multiple interrelated missions. This design requires agents to dynamically adapt to evolving demands. Moreover, the proposed benchmark explores all possible mission-switching patterns within a fixed mission number. Specifically, we propose a multi-agent data generation framework to construct the benchmark. We also propose a novel method to evaluate the accuracy and efficiency of agent decisions with dynamic decision trees. Experiments on diverse open-source and closed-source LLMs reveal critical factors influencing agent robustness and provide actionable insights to the tool invocation society.', 'abstract_zh': '多任务工具基准：多任务场景下的智能代理评估', 'title_zh': '多任务工具台：通过相关和动态任务评估基于LLM的代理的 robustness'}
{'arxiv_id': 'arXiv:2504.02577', 'title': 'Reasoning Inconsistencies and How to Mitigate Them in Deep Learning', 'authors': 'Erik Arakelyan', 'link': 'https://arxiv.org/abs/2504.02577', 'abstract': 'The recent advancements in Deep Learning models and techniques have led to significant strides in performance across diverse tasks and modalities. However, while the overall capabilities of models show promising growth, our understanding of their internal reasoning processes remains limited, particularly concerning systematic inconsistencies or errors patterns of logical or inferential flaws. These inconsistencies may manifest as contradictory outputs, failure to generalize across similar tasks, or erroneous conclusions in specific contexts. Even detecting and measuring such reasoning discrepancies is challenging, as they may arise from opaque internal procedures, biases and imbalances in training data, or the inherent complexity of the task. Without effective methods to detect, measure, and mitigate these errors, there is a risk of deploying models that are biased, exploitable, or logically unreliable. This thesis aims to address these issues by producing novel methods for deep learning models that reason over knowledge graphs, natural language, and images. The thesis contributes two techniques for detecting and quantifying predictive inconsistencies originating from opaque internal procedures in natural language and image processing models. To mitigate inconsistencies from biases in training data, this thesis presents a data efficient sampling method to improve fairness and performance and a synthetic dataset generation approach in low resource scenarios. Finally, the thesis offers two techniques to optimize the models for complex reasoning tasks. These methods enhance model performance while allowing for more faithful and interpretable exploration and exploitation during inference. Critically, this thesis provides a comprehensive framework to improve the robustness, fairness, and interpretability of deep learning models across diverse tasks and modalities.', 'abstract_zh': '近期深度学习模型和方法的进步在跨多种任务和模态中取得了显著的性能提升。然而，尽管模型的整体能力显示出有希望的增长，我们对其内部推理过程的理解仍然有限，尤其是在系统性不一致或推理错误模式方面的理解更为有限。这些不一致可能表现为矛盾的输出、无法泛化到类似任务或在特定上下文中得出错误结论。即使检测和量化这些推理差异也很具有挑战性，因为它们可能来自不透明的内部程序、训练数据中的偏差和不平衡或任务本身的固有复杂性。缺乏有效的检测、量化和缓解这些错误的方法，存在部署存在偏差、可利用或逻辑上不可靠模型的风险。本论文旨在通过开发新的方法来解决这些问题，这些方法可以对知识图谱、自然语言和图像进行推理。论文提出了两种技术来检测和量化自然语言和图像处理模型中源自不透明内部程序的预测不一致。为减轻由训练数据偏差引起的不一致性，论文提出了一种高效的数据采样方法以提高公平性和性能，并在低资源场景中提出了一种合成数据集生成方法。最后，论文提供了两种技术来优化模型以适应复杂的推理任务。这些方法在提高模型性能的同时，还允许在推理过程中进行更忠实和可解释的探索与利用。本论文提供了一个全面的框架，以提高不同任务和模态下的深度学习模型的稳健性、公平性和可解释性。', 'title_zh': '在深度学习中推理不一致性和如何减轻它们'}
{'arxiv_id': 'arXiv:2504.02509', 'title': 'A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders', 'authors': 'Yuhao Liu, Maolin Yang, Pingyu Jiang', 'link': 'https://arxiv.org/abs/2504.02509', 'abstract': 'With the rapid development of 3D printing, the demand for personalized and customized production on the manufacturing line is steadily increasing. Efficient merging of printing workpieces can significantly enhance the processing efficiency of the production line. Addressing the challenge, a Large Language Model (LLM)-driven method is established in this paper for the autonomous merging of 3D printing work orders, integrated with a memory-augmented learning strategy. In industrial scenarios, both device and order features are modeled into LLM-readable natural language prompt templates, and develop an order-device matching tool along with a merging interference checking module. By incorporating a self-memory learning strategy, an intelligent agent for autonomous order merging is constructed, resulting in improved accuracy and precision in order allocation. The proposed method effectively leverages the strengths of LLMs in industrial applications while reducing hallucination.', 'abstract_zh': '随着3D打印的快速发展，制造线上对个性化和定制化生产的需求稳步增加。高效融合印刷工件可以显著提高生产线的加工效率。针对这一挑战，本文提出了一种由大规模语言模型（LLM）驱动的方法，用于自主融合3D打印工作订单，并结合了增强记忆的学习策略。在工业场景中，将设备和订单特征建模为LLM可读的自然语言提示模板，并开发了订单-设备匹配工具以及融合干扰检查模块。通过集成自我记忆学习策略，构建了一个智能化订单融合代理，从而提高了订单分配的准确性和精确度。所提出的方法有效利用了LLM在工业应用中的优势，减少了幻觉现象。', 'title_zh': '带有记忆增强的LLM驱动方法实现3D打印工作订单的自主合并'}
{'arxiv_id': 'arXiv:2504.02489', 'title': 'The Self-Learning Agent with a Progressive Neural Network Integrated Transformer', 'authors': 'Ajay Sivakumar, Shalini, Vasantha Raj, Sebastian Sylvester', 'link': 'https://arxiv.org/abs/2504.02489', 'abstract': 'This paper introduces a self-learning agent that integrates LLaMA 3.2 with a Progressive Neural Network (PNN) for continual learning in conversational AI and code generation. The framework dynamically collects data, fine-tunes tasks with minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA optimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances knowledge retention. Experimental results demonstrate improved adaptability and memory stability, positioning this approach as a scalable step toward Artificial General Intelligence (AGI).', 'abstract_zh': '本文介绍了一种将LLaMA 3.2与渐进神经网络（PNN）相结合的自学习代理，用于对话AI和代码生成的连续学习。该框架动态收集数据，使用最少样本微调任务，并利用元学习实现快速适应。LoRA优化微调，而弹性权重 consolidation（EWC）增强知识保持。实验结果表明，该方法在适应性和记忆稳定性方面有所改进，为通用人工智能（AGI）的发展提供了一个可扩展的步骤。', 'title_zh': '具有渐进神经网络集成变换器的自学习代理'}
{'arxiv_id': 'arXiv:2504.02486', 'title': 'We Need Improved Data Curation and Attribution in AI for Scientific Discovery', 'authors': 'Mara Graziani, Antonio Foncubierta, Dimitrios Christofidellis, Irina Espejo-Morales, Malina Molnar, Marvin Alberts, Matteo Manica, Jannis Born', 'link': 'https://arxiv.org/abs/2504.02486', 'abstract': 'As the interplay between human-generated and synthetic data evolves, new challenges arise in scientific discovery concerning the integrity of the data and the stability of the models. In this work, we examine the role of synthetic data as opposed to that of real experimental data for scientific research. Our analyses indicate that nearly three-quarters of experimental datasets available on open-access platforms have relatively low adoption rates, opening new opportunities to enhance their discoverability and usability by automated methods. Additionally, we observe an increasing difficulty in distinguishing synthetic from real experimental data. We propose supplementing ongoing efforts in automating synthetic data detection by increasing the focus on watermarking real experimental data, thereby strengthening data traceability and integrity. Our estimates suggest that watermarking even less than half of the real world data generated annually could help sustain model robustness, while promoting a balanced integration of synthetic and human-generated content.', 'abstract_zh': '随着人类生成数据与合成数据的互动演变，在科学发现中的数据完整性和模型稳定性面临新的挑战。本研究探讨了合成数据在科学研究中与真实实验数据的角色差异。我们的分析表明，近四分之三在开放访问平台上可用的实验数据集的采用率相对较低，这为通过自动化方法增强其可发现性和可用性提供了新的机会。此外，我们观察到区分合成数据与真实实验数据的难度日益增加。我们建议在自动化合成数据检测的同时，增加真实实验数据水印化的重点，从而加强数据的可追溯性和完整性。我们的估算表明，即使每年对不到一半的真实数据进行水印化，也有助于维持模型的稳健性，并促进合成数据与人类生成内容的平衡整合。', 'title_zh': '我们需要在科学发现中的AI领域提升数据整理和归属规范。'}
{'arxiv_id': 'arXiv:2504.02467', 'title': 'BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking', 'authors': 'Qisheng Hu, Quanyu Long, Wenya Wang', 'link': 'https://arxiv.org/abs/2504.02467', 'abstract': 'Program-guided reasoning has shown promise in complex claim fact-checking by decomposing claims into function calls and executing reasoning programs. However, prior work primarily relies on few-shot in-context learning (ICL) with ad-hoc demonstrations, which limit program diversity and require manual design with substantial domain knowledge. Fundamentally, the underlying principles of effective reasoning program generation still remain underexplored, making it challenging to construct effective demonstrations. To address this, we propose BOOST, a bootstrapping-based framework for few-shot reasoning program generation. BOOST explicitly integrates claim decomposition and information-gathering strategies as structural guidance for program generation, iteratively refining bootstrapped demonstrations in a strategy-driven and data-centric manner without human intervention. This enables a seamless transition from zero-shot to few-shot strategic program-guided learning, enhancing interpretability and effectiveness. Experimental results show that BOOST outperforms prior few-shot baselines in both zero-shot and few-shot settings for complex claim verification.', 'abstract_zh': '基于程序引导的推理在复杂声明事实核查中的潜在应用通过将声明分解为函数调用并执行推理程序展现了一定前景。然而，现有工作主要依赖少量上下文学习（ICL）和 ad-hoc 展示，这限制了程序多样性并需要大量领域知识的ручное проектирование.从根本上说，有效的推理程序生成的基本原理仍然未得到充分探索，使得构建有效展示变得具有挑战性。为解决这一问题，我们提出 BOOST——一种基于自助法的少量样本推理程序生成框架。BOOST 显式地将声明分解和信息收集策略整合为程序生成的结构引导，在策略驱动和数据中心化的迭代方式中逐步优化自助展示，无需人工干预，从而实现从零样本到少量样本战略程序引导学习的无缝过渡，增强可解释性和有效性。实验结果表明，BOOST 在复杂声明验证的零样本和少量样本设置中均优于先前的少量样本基线方法。', 'title_zh': 'BOOST: 基于策略驱动推理程序的程序指导事实核查bootstrapping方法'}
{'arxiv_id': 'arXiv:2504.02430', 'title': "How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics", 'authors': 'Guus Eelink, Kilian Rückschloß, Felix Weitkämper', 'link': 'https://arxiv.org/abs/2504.02430', 'abstract': "Bayesian networks and causal models provide frameworks for handling queries about external interventions and counterfactuals, enabling tasks that go beyond what probability distributions alone can address. While these formalisms are often informally described as capturing causal knowledge, there is a lack of a formal theory characterizing the type of knowledge required to predict the effects of external interventions. This work introduces the theoretical framework of causal systems to clarify Aristotle's distinction between knowledge that and knowledge why within artificial intelligence. By interpreting existing artificial intelligence technologies as causal systems, it investigates the corresponding types of knowledge. Furthermore, it argues that predicting the effects of external interventions is feasible only with knowledge why, providing a more precise understanding of the knowledge necessary for such tasks.", 'abstract_zh': '贝叶斯网络和因果模型提供了处理关于外部干预和反事实查询的框架，使任务超越了仅凭概率分布所能实现的范围。虽然这些形式主义通常非正式地被认为捕捉了因果知识，但缺乏对预测外部干预效果所需类型的知识的正式理论。本文引入因果系统理论框架来澄清人工智能中的知识that与知识why之间的区别。通过将现有的人工智能技术解释为因果系统，它探讨了相应的知识类型，并进一步认为，仅凭知识that无法预测外部干预的效果，预测外部干预效果仅在具备知识why的前提下才可行，从而为这类任务所需的知识提供了更精确的理解。', 'title_zh': '人工智能如何产生知识：受亚里士多德后分析篇启发的探究'}
{'arxiv_id': 'arXiv:2504.02426', 'title': 'Narrative Studio: Visual narrative exploration using LLMs and Monte Carlo Tree Search', 'authors': 'Parsa Ghaffari, Chris Hokamp', 'link': 'https://arxiv.org/abs/2504.02426', 'abstract': "Interactive storytelling benefits from planning and exploring multiple 'what if' scenarios. Modern LLMs are useful tools for ideation and exploration, but current chat-based user interfaces restrict users to a single linear flow. To address this limitation, we propose Narrative Studio -- a novel in-browser narrative exploration environment featuring a tree-like interface that allows branching exploration from user-defined points in a story. Each branch is extended via iterative LLM inference guided by system and user-defined prompts. Additionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand promising narrative paths based on user-specified criteria, enabling more diverse and robust story development. We also allow users to enhance narrative coherence by grounding the generated text in an entity graph that represents the actors and environment of the story.", 'abstract_zh': '交互式讲故事受益于规划和探索多个“如果”情景。现代语言模型是创意和探索的有用工具，但基于聊天的用户界面限制用户在单一线性流程中操作。为了解决这一限制，我们提出了Narrative Studio——一种新的基于浏览器的叙事探索环境，其特色是一个树状界面，允许从故事中用户定义的点出发进行分支探索。每条分支通过迭代的LLM推理并根据系统和用户定义的提示扩展。此外，我们采用蒙特卡洛树搜索（MCTS）来根据用户指定的指标自动扩展有前途的叙事路径，从而实现更多样和 robust 的故事开发。我们还允许用户通过将生成的文本与表示故事中演员和环境的实体图结合，增强叙事连贯性。', 'title_zh': '叙事工作室：使用LLMs和蒙特卡洛树搜索的视觉叙事探索'}
{'arxiv_id': 'arXiv:2504.02269', 'title': 'Engineering Artificial Intelligence: Framework, Challenges, and Future Direction', 'authors': 'Jay Lee, Hanqi Su, Dai-Yan Ji, Takanobu Minami', 'link': 'https://arxiv.org/abs/2504.02269', 'abstract': 'Over the past ten years, the application of artificial intelligence (AI) and machine learning (ML) in engineering domains has gained significant popularity, showcasing their potential in data-driven contexts. However, the complexity and diversity of engineering problems often require the development of domain-specific AI approaches, which are frequently hindered by a lack of systematic methodologies, scalability, and robustness during the development process. To address this gap, this paper introduces the "ABCDE" as the key elements of Engineering AI and proposes a unified, systematic engineering AI ecosystem framework, including eight essential layers, along with attributes, goals, and applications, to guide the development and deployment of AI solutions for specific engineering needs. Additionally, key challenges are examined, and nine future research directions are highlighted. By providing a comprehensive perspective, this paper aims to advance the strategic implementation of AI, fostering the development of next-generation engineering AI solutions.', 'abstract_zh': '过去十年，人工智能（AI）和机器学习（ML）在工程领域中的应用获得了显著 popularity，并在数据驱动的背景下展示了其潜力。然而，工程问题的复杂性和多样性往往需要开发特定领域的 AI 方法，这在开发过程中经常受到缺乏系统方法论、可扩展性和鲁棒性等因素的阻碍。为解决这一差距，本文提出了“ABCDE”作为工程 AI 的关键要素，并提出了一种统一的、系统的工程 AI 生态系统框架，包括八个基本层次及其属性、目标和应用，以指导特定工程需求的 AI 解决方案的开发和部署。此外，本文还探讨了主要挑战，并指出了九个未来研究方向。通过提供一个全面的视角，本文旨在促进 AI 的战略实施，推动下一代工程 AI 解决方案的发展。', 'title_zh': '工程化人工智能：框架、挑战及未来方向'}
{'arxiv_id': 'arXiv:2504.02227', 'title': 'VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence', 'authors': 'Hao Li, Hao Fei, Zechao Hu, Zhengwei Yang, Zheng Wang', 'link': 'https://arxiv.org/abs/2504.02227', 'abstract': "Social Intelligence Queries (Social-IQ) serve as the primary multimodal benchmark for evaluating a model's social intelligence level. While impressive multiple-choice question(MCQ) accuracy is achieved by current solutions, increasing evidence shows that they are largely, and in some cases entirely, dependent on language modality, overlooking visual context. Additionally, the closed-set nature further prevents the exploration of whether and to what extent the reasoning path behind selection is correct. To address these limitations, we propose the Visually Explainable and Grounded Artificial Social Intelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages open-ended answering to provide explainable responses, which enhances the clarity and evaluation of reasoning paths. To enable visually grounded answering, we propose a novel sampling strategy to provide the model with more relevant visual frames. We then enhance the model's interpretation of these frames through Generalist Instruction Fine-Tuning (GIFT), which aims to: i) learn multimodal-language transformations for fundamental emotional social traits, and ii) establish multimodal joint reasoning capabilities. Extensive experiments, comprising modality ablation, open-ended assessments, and supervised MCQ evaluations, consistently show that VEGAS effectively utilizes visual information in reasoning to produce correct and also credible answers. We expect this work to of fer a new perspective on Social-IQ and advance the development of human-like social AI.", 'abstract_zh': 'Visually Explainable and Grounded Artificial Social Intelligence (VEGAS)：一种可解释且视觉导向的人工社会智能模型', 'title_zh': 'VEGAS:向具有视觉可解释性和grounded人工社会智能迈进'}
{'arxiv_id': 'arXiv:2504.02193', 'title': 'More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment', 'authors': 'Yifan Wang, Runjin Chen, Bolian Li, David Cho, Yihe Deng, Ruqi Zhang, Tianlong Chen, Zhangyang Wang, Ananth Grama, Junyuan Hong', 'link': 'https://arxiv.org/abs/2504.02193', 'abstract': 'Aligning large language models (LLMs) with human values is an increasingly critical step in post-training. Direct Preference Optimization (DPO) has emerged as a simple, yet effective alternative to reinforcement learning from human feedback (RLHF). Synthetic preference data with its low cost and high quality enable effective alignment through single- or multi-model generated preference data. Our study reveals a striking, safety-specific phenomenon associated with DPO alignment: Although multi-model generated data enhances performance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by providing diverse responses, it also tends to facilitate reward hacking during training. This can lead to a high attack success rate (ASR) when models encounter jailbreaking prompts. The issue is particularly pronounced when employing stronger models like GPT-4o or larger models in the same family to generate chosen responses paired with target model self-generated rejected responses, resulting in dramatically poorer safety outcomes. Furthermore, with respect to safety, using solely self-generated responses (single-model generation) for both chosen and rejected pairs significantly outperforms configurations that incorporate responses from stronger models, whether used directly as chosen data or as part of a multi-model response pool. We demonstrate that multi-model preference data exhibits high linear separability between chosen and rejected responses, which allows models to exploit superficial cues rather than internalizing robust safety constraints. Our experiments, conducted on models from the Llama, Mistral, and Qwen families, consistently validate these findings.', 'abstract_zh': '使用多模型数据在直接偏好优化对齐中增强性能但也可能导致安全风险：从Llama、Mistral和Qwen家族模型的实验中观察到', 'title_zh': '更多反而更少：多模型合成偏好数据在DPO安全对齐中的陷阱'}
{'arxiv_id': 'arXiv:2504.02181', 'title': 'A Survey of Scaling in Large Language Model Reasoning', 'authors': 'Zihan Chen, Song Wang, Zhen Tan, Xingbo Fu, Zhenyu Lei, Peng Wang, Huan Liu, Cong Shen, Jundong Li', 'link': 'https://arxiv.org/abs/2504.02181', 'abstract': 'The rapid advancements in large Language models (LLMs) have significantly enhanced their reasoning capabilities, driven by various strategies such as multi-agent collaboration. However, unlike the well-established performance improvements achieved through scaling data and model size, the scaling of reasoning in LLMs is more complex and can even negatively impact reasoning performance, introducing new challenges in model alignment and robustness. In this survey, we provide a comprehensive examination of scaling in LLM reasoning, categorizing it into multiple dimensions and analyzing how and to what extent different scaling strategies contribute to improving reasoning capabilities. We begin by exploring scaling in input size, which enables LLMs to process and utilize more extensive context for improved reasoning. Next, we analyze scaling in reasoning steps that improves multi-step inference and logical consistency. We then examine scaling in reasoning rounds, where iterative interactions refine reasoning outcomes. Furthermore, we discuss scaling in training-enabled reasoning, focusing on optimization through iterative model improvement. Finally, we review applications of scaling across domains and outline future directions for further advancing LLM reasoning. By synthesizing these diverse perspectives, this survey aims to provide insights into how scaling strategies fundamentally enhance the reasoning capabilities of LLMs and further guide the development of next-generation AI systems.', 'abstract_zh': '大型语言模型（LLMs）的 Rapid Advancements and Scaling in Reasoning: A Comprehensive Survey', 'title_zh': '大型语言模型推理中的扩展性研究'}
{'arxiv_id': 'arXiv:2504.02148', 'title': 'OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling', 'authors': 'Heming Zhang, Tim Xu, Dekang Cao, Shunning Liang, Lars Schimmelpfennig, Levi Kaster, Di Huang, Carlos Cruchaga, Guangfu Li, Michael Province, Yixin Chen, Philip Payne, Fuhai Li', 'link': 'https://arxiv.org/abs/2504.02148', 'abstract': 'Complex cell signaling systems -- governed by varying protein abundances and interactions -- generate diverse cell types across organs. These systems evolve under influences such as age, sex, diet, environmental exposures, and diseases, making them challenging to decode given the involvement of tens of thousands of genes and proteins. Recently, hundreds of millions of single-cell omics data have provided a robust foundation for understanding these signaling networks within various cell subpopulations and conditions. Inspired by the success of large foundation models (for example, large language models and large vision models) pre-trained on massive datasets, we introduce OmniCellTOSG, the first dataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents the signaling network of an individual or meta-cell and is labeled with information such as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two key contributions. First, it introduces a novel graph model that integrates human-readable annotations -- such as biological functions, cellular locations, signaling pathways, related diseases, and drugs -- with quantitative gene and protein abundance data, enabling graph reasoning to decode cell signaling. This approach calls for new joint models combining large language models and graph neural networks. Second, the dataset is built from single-cell RNA sequencing data of approximately 120 million cells from diverse tissues and conditions (healthy and diseased) and is fully compatible with PyTorch. This facilitates the development of innovative cell signaling models that could transform research in life sciences, healthcare, and precision medicine. The OmniCellTOSG dataset is continuously expanding and will be updated regularly. The dataset and code are available at this https URL.', 'abstract_zh': '复杂的细胞信号系统——由蛋白质丰度和相互作用的差异调控——在不同器官中生成多种细胞类型。这些系统受到年龄、性别、饮食、环境暴露和疾病等因素的影响而进化，给解析带来挑战，因为涉及成千上万的基因和蛋白质。近年来，数亿条单细胞组学数据为理解这些信号网络提供了坚实基础，特别是在不同细胞亚群和条件下。受大规模基础模型（如大型语言模型和大型视觉模型）在大规模数据集上预训练成功的启发，我们引入了OmniCellTOSG，这是首个细胞文本-组学信号图谱（TOSGs）数据集。每个TOSG代表个体或元细胞的信号网络，并标注有器官、疾病、性别、年龄和细胞亚型等信息。OmniCellTOSG提供了两个关键贡献。首先，它引入了一种新颖的图模型，将生物功能、细胞位置、信号通路、相关疾病和药物等可读注释与定量的基因和蛋白质丰度数据结合，以图示推理解码细胞信号。这需要新的结合大型语言模型和图神经网络的联合模型。其次，该数据集源自大约1.2亿个来自不同组织和条件（健康和患病状态）的单细胞RNA测序数据，并完全兼容PyTorch，这为开发创新的细胞信号模型提供了便利，这些模型有可能改变生命科学、医疗保健和精准医疗领域的研究。OmniCellTOSG数据集将持续扩展并定期更新。数据集和代码可从此链接访问。', 'title_zh': 'OmniCellTOSG：首个联合LLM和GNN建模的细胞文本组信号图数据集'}
{'arxiv_id': 'arXiv:2504.02111', 'title': 'Exploring LLM Reasoning Through Controlled Prompt Variations', 'authors': 'Giannis Chatziveroglou, Richard Yun, Maura Kelleher', 'link': 'https://arxiv.org/abs/2504.02111', 'abstract': "This study investigates the reasoning robustness of large language models (LLMs) on mathematical problem-solving tasks under systematically introduced input perturbations. Using the GSM8K dataset as a controlled testbed, we evaluate how well state-of-the-art models maintain logical consistency and correctness when confronted with four categories of prompt perturbations: irrelevant context, pathological instructions, factually relevant but non-essential context, and a combination of the latter two. Our experiments, conducted on thirteen open-source and closed-source LLMs, reveal that introducing irrelevant context within the model's context window significantly degrades performance, suggesting that distinguishing essential from extraneous details remains a pressing challenge. Surprisingly, performance regressions are relatively insensitive to the complexity of the reasoning task, as measured by the number of steps required, and are not strictly correlated with model size. Moreover, we observe that certain perturbations inadvertently trigger chain-of-thought-like reasoning behaviors, even without explicit prompting. Our findings highlight critical vulnerabilities in current LLMs and underscore the need for improved robustness against noisy, misleading, and contextually dense inputs, paving the way for more resilient and reliable reasoning in real-world applications.", 'abstract_zh': '本研究探讨了在系统引入输入扰动的情况下，大型语言模型（LLMs）在数学问题解决任务中的推理稳健性。使用GSM8K数据集作为控制试验平台，我们评估了当前最先进的模型在面对四类提示扰动（无关背景信息、病态指令、事实相关但非关键的背景信息以及后两者的组合）时，如何保持逻辑一致性和正确性。我们的实验在十三个开源和闭源LLM上进行，结果表明，在模型上下文窗口中引入无关背景信息显著降低了性能，这表明区分核心信息和非核心信息仍然是一个紧迫的挑战。令人惊讶的是，性能下降对所需推理步骤的数量（作为推理任务复杂性的度量）的敏感度较低，并且与模型大小之间没有严格的正相关关系。此外，我们观察到某些扰动会无意中触发类似于链式推理的行为，即使没有显式的提示也是如此。我们的研究结果突显了当前LLM中存在的关键漏洞，并强调了需要提高对嘈杂、误导性和语境密集输入的稳健性的改进，为在实际应用中实现更可靠和稳健的推理铺平了道路。', 'title_zh': '通过受控提示变异探究LLM推理能力'}
{'arxiv_id': 'arXiv:2504.02058', 'title': 'Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation', 'authors': 'Andy Williams', 'link': 'https://arxiv.org/abs/2504.02058', 'abstract': 'Efforts to ensure the safe development of artificial general intelligence (AGI) often rely on consensus-based alignment approaches grounded in axiomatic formalism, interpretability, and empirical validation. However, these methods may be structurally unable to recognize or incorporate novel solutions that fall outside their accepted epistemic frameworks. This paper introduces a functional model of epistemic closure, in which cognitive, institutional, social, and infrastructural filters combine to make many alignment proposals illegible to existing evaluation systems. We present a weighted closure model supported by both theoretical and empirical sources, including a meta-analysis performed by an AI system on patterns of rejection and non-engagement with a framework for decentralized collective intelligence (DCI). We argue that the recursive failure to assess models like DCI is not just a sociological oversight but a structural attractor, mirroring the very risks of misalignment we aim to avoid in AGI. Without the adoption of DCI or a similarly recursive model of epistemic correction, we may be on a predictable path toward irreversible misalignment. The development and acceptance of this paper, first through simulated review and then through formal channels, provide a case study supporting its central claim: that epistemic closure can only be overcome by recursive modeling of the constraints that sustain it.', 'abstract_zh': '确保通用人工智能(AGI)安全发展的努力往往依赖于基于公理形式主义、可解释性和经验验证的共识导向对齐方法。然而，这些方法可能在结构上无法识别或纳入超出其接受的认识框架的新型解决方案。本文引入了一种功能模型，以认知、机构、社会和基础设施过滤器组合的方式，使得许多对齐提案对现有评估系统来说变得不可读。我们提出了一个基于理论和实证来源的加权闭合模型，包括一个AI系统对去中心化集体智能(DCI)框架的拒斥和非参与模式进行的元分析。我们认为，对类似于DCI的模型的递归评估失败不仅是社会学上的疏忽，也是结构上的吸引子，这与我们试图避免的AGI对齐风险相呼应。如果不采用DCI或类似具有递归性的认识纠正模型，我们可能走上一条不可预测的不可逆对齐偏差之路。本文的发展和接受过程，首先通过模拟评审，然后通过正式渠道进行，提供了一个案例研究，支持其核心观点：只有通过递归建模才能克服认识闭合。', 'title_zh': '知识闭合与错配的不可逆性：建模系统性对齐创新障碍'}
{'arxiv_id': 'arXiv:2504.01995', 'title': 'Brains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics', 'authors': 'Hamed Mahdavi, Alireza Hashemi, Majid Daliri, Pegah Mohammadipour, Alireza Farhadi, Samira Malek, Yekta Yazdanifard, Amir Khasahmadi, Vasant Honavar', 'link': 'https://arxiv.org/abs/2504.01995', 'abstract': 'Recent advancements in large language models (LLMs) have shown impressive progress in mathematical reasoning tasks. However, current evaluation benchmarks predominantly focus on the accuracy of final answers, often overlooking the logical rigor crucial for mathematical problem-solving. The claim that state-of-the-art LLMs can solve Math Olympiad-level problems requires closer examination. To explore this, we conducted both qualitative and quantitative human evaluations of proofs generated by LLMs, and developed a schema for automatically assessing their reasoning capabilities. Our study reveals that current LLMs fall significantly short of solving challenging Olympiad-level problems and frequently fail to distinguish correct mathematical reasoning from clearly flawed solutions. We also found that occasional correct final answers provided by LLMs often result from pattern recognition or heuristic shortcuts rather than genuine mathematical reasoning. These findings underscore the substantial gap between LLM performance and human expertise in advanced mathematical reasoning and highlight the importance of developing benchmarks that prioritize the rigor and coherence of mathematical arguments rather than merely the correctness of final answers.', 'abstract_zh': '近期大型语言模型（LLMs）在数学推理任务上的进展显示了令人印象深刻的成果，然而当前的评估基准主要集中在最终答案的准确性上，常常忽视了数学问题解决中至关重要的逻辑严谨性。当前关于最先进的LLMs能够解决奥林匹克数学水平问题的断言需要更深入的审视。为了探索这一问题，我们对LLMs生成的证明进行了定性和定量的人类评估，并开发了一种自动评估其推理能力的框架。研究结果揭示，当前的LLMs在解决具有挑战性的奥林匹克级别问题时存在显著不足，经常无法区分正确的数学推理与明显错误的解决方案。我们还发现，LLMs偶尔提供的正确最终答案通常源于模式识别或启发式捷径，而不是真正的数学推理。这些发现凸显了LLMs在高级数学推理方面的表现与人类专长之间的显著差距，并强调了优先考虑数学论证的严谨性和连贯性而非仅仅最终答案的正确性的重要性。', 'title_zh': 'brains vs. bytes: 评估大型语言模型在奥林匹克数学中的专业水平'}
{'arxiv_id': 'arXiv:2504.01990', 'title': 'Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems', 'authors': 'Bang Liu, Xinfeng Li, Jiayi Zhang, Jinlin Wang, Tanjin He, Sirui Hong, Hongzhang Liu, Shaokun Zhang, Kaitao Song, Kunlun Zhu, Yuheng Cheng, Suyuchen Wang, Xiaoqiang Wang, Yuyu Luo, Haibo Jin, Peiyan Zhang, Ollie Liu, Jiaqi Chen, Huan Zhang, Zhaoyang Yu, Haochen Shi, Boyan Li, Dekun Wu, Fengwei Teng, Xiaojun Jia, Jiawei Xu, Jinyu Xiang, Yizhang Lin, Tianming Liu, Tongliang Liu, Yu Su, Huan Sun, Glen Berseth, Jianyun Nie, Ian Foster, Logan Ward, Qingyun Wu, Yu Gu, Mingchen Zhuge, Xiangru Tang, Haohan Wang, Jiaxuan You, Chi Wang, Jian Pei, Qiang Yang, Xiaoliang Qi, Chenglin Wu', 'link': 'https://arxiv.org/abs/2504.01990', 'abstract': 'The advent of large language models (LLMs) has catalyzed a transformative shift in artificial intelligence, paving the way for advanced intelligent agents capable of sophisticated reasoning, robust perception, and versatile action across diverse domains. As these agents increasingly drive AI research and practical applications, their design, evaluation, and continuous improvement present intricate, multifaceted challenges. This survey provides a comprehensive overview, framing intelligent agents within a modular, brain-inspired architecture that integrates principles from cognitive science, neuroscience, and computational research. We structure our exploration into four interconnected parts. First, we delve into the modular foundation of intelligent agents, systematically mapping their cognitive, perceptual, and operational modules onto analogous human brain functionalities, and elucidating core components such as memory, world modeling, reward processing, and emotion-like systems. Second, we discuss self-enhancement and adaptive evolution mechanisms, exploring how agents autonomously refine their capabilities, adapt to dynamic environments, and achieve continual learning through automated optimization paradigms, including emerging AutoML and LLM-driven optimization strategies. Third, we examine collaborative and evolutionary multi-agent systems, investigating the collective intelligence emerging from agent interactions, cooperation, and societal structures, highlighting parallels to human social dynamics. Finally, we address the critical imperative of building safe, secure, and beneficial AI systems, emphasizing intrinsic and extrinsic security threats, ethical alignment, robustness, and practical mitigation strategies necessary for trustworthy real-world deployment.', 'abstract_zh': '大型语言模型的出现推动了人工智能领域的 transformative变革，为高级智能代理的发展铺平了道路，这些代理能够在多样化的领域中进行复杂的推理、 robust的感知和灵活的行动。随着这些代理在人工智能研究和实际应用中发挥越来越重要的作用，它们的设计、评估和持续改进面临着复杂多维的挑战。本综述提供了全面的概述，在具模块化、脑启发式架构中将智能代理整合进认知科学、神经科学和计算研究的原则中。我们将探索分为四个紧密相连的部分。首先，我们探讨智能代理的模块化基础，系统地将认知、感知和操作模块映射到类人的大脑功能，并阐明核心组件，如记忆、世界建模、奖赏处理和类似情感的系统。其次，我们讨论自我增强和适应性进化机制，探讨智能代理如何自主提升其能力、适应动态环境并通过自动优化范式实现持续学习，包括新兴的自动化机器学习和以大型语言模型驱动的优化策略。第三，我们研究协作和进化的多智能体系统，调查来自代理互动、合作和社会结构的集体智能，突出与人类社会动态的相似之处。最后，我们应对构建安全、安全和有益的人工智能系统的关键需求，强调内在和外在安全威胁、伦理对齐、鲁棒性和实际缓解策略，以确保可信赖的实际部署。', 'title_zh': '基于脑启发智能的基座代理进展与挑战：从进化协作到安全系统的探索'}
{'arxiv_id': 'arXiv:2504.02828', 'title': 'Concept Lancet: Image Editing with Compositional Representation Transplant', 'authors': 'Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Hancheng Min, Chris Callison-Burch, René Vidal', 'link': 'https://arxiv.org/abs/2504.02828', 'abstract': 'Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation.', 'abstract_zh': '基于概念 Lancet 的零样本即插即用扩散模型图像编辑框架', 'title_zh': '概念柳叶刀：基于组合表示移植的图像编辑'}
{'arxiv_id': 'arXiv:2504.02827', 'title': 'On Vanishing Variance in Transformer Length Generalization', 'authors': 'Ruining Li, Gabrijel Boduljak, Jensen, Zhou', 'link': 'https://arxiv.org/abs/2504.02827', 'abstract': "It is a widely known issue that Transformers, when trained on shorter sequences, fail to generalize robustly to longer ones at test time. This raises the question of whether Transformer models are real reasoning engines, despite their impressive abilities in mathematical problem solving and code synthesis. In this paper, we offer a vanishing variance perspective on this issue. To the best of our knowledge, we are the first to demonstrate that even for today's frontier models, a longer sequence length results in a decrease in variance in the output of the multi-head attention modules. On the argmax retrieval and dictionary lookup tasks, our experiments show that applying layer normalization after the attention outputs leads to significantly better length generalization. Our analyses attribute this improvement to a reduction-though not a complete elimination-of the distribution shift caused by vanishing variance.", 'abstract_zh': '预训练序列较短时Transformer模型在长序列上的泛化能力不足：消失方差视角下的分析', 'title_zh': 'Transformer 长度泛化的消失方差现象'}
{'arxiv_id': 'arXiv:2504.02821', 'title': 'Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models', 'authors': 'Mateusz Pach, Shyamgopal Karthik, Quentin Bouniot, Serge Belongie, Zeynep Akata', 'link': 'https://arxiv.org/abs/2504.02821', 'abstract': 'Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs.', 'abstract_zh': '稀疏自编码器（SAEs）最近被证明可以增强大型语言模型（LLMs）的可解释性和可控性。在本文中，我们将SAEs的应用扩展到视觉-语言模型（VLMs），如CLIP，并引入了一种全面的框架来评估视觉表示的单义性。实验结果表明，SAEs在VLMs上的训练显著增强了单个神经元的单义性，同时展示了与专家定义的结构（例如，iNaturalist分类学）高度对齐的层次表示。尤为重要的是，我们证明了将SAEs应用于干预CLIP视觉编码器可以直接引导多模态LLMs（例如，LLaVA）的输出，而无需对底层模型进行任何修改。这些发现突显了SAEs作为无监督方法，用于增强VLMs的可解释性和可控性的实用性和有效性。', 'title_zh': '稀疏自编码器在视觉-语言模型中学习单义特征'}
{'arxiv_id': 'arXiv:2504.02819', 'title': 'GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings', 'authors': 'Yuexi Du, Jiazhen Zhang, Nicha C. Dvornek, John A. Onofrey', 'link': 'https://arxiv.org/abs/2504.02819', 'abstract': "Symmetry, where certain features remain invariant under geometric transformations, can often serve as a powerful prior in designing convolutional neural networks (CNNs). While conventional CNNs inherently support translational equivariance, extending this property to rotation and reflection has proven challenging, often forcing a compromise between equivariance, efficiency, and information loss. In this work, we introduce Gaussian Mixture Ring Convolution (GMR-Conv), an efficient convolution kernel that smooths radial symmetry using a mixture of Gaussian-weighted rings. This design mitigates discretization errors of circular kernels, thereby preserving robust rotation and reflection equivariance without incurring computational overhead. We further optimize both the space and speed efficiency of GMR-Conv via a novel parameterization and computation strategy, allowing larger kernels at an acceptable cost. Extensive experiments on eight classification and one segmentation datasets demonstrate that GMR-Conv not only matches conventional CNNs' performance but can also surpass it in applications with orientation-less data. GMR-Conv is also proven to be more robust and efficient than the state-of-the-art equivariant learning methods. Our work provides inspiring empirical evidence that carefully applied radial symmetry can alleviate the challenges of information loss, marking a promising advance in equivariant network architectures. The code is available at this https URL.", 'abstract_zh': 'Gaussian Mixture Ring Convolution: Efficiently Preserving Robust Rotation and Reflection Equivariance Without Computational Overhead', 'title_zh': 'GMR-Conv：一种基于高斯混合环的高效旋转和反射等变卷积核'}
{'arxiv_id': 'arXiv:2504.02810', 'title': 'Generative Evaluation of Complex Reasoning in Large Language Models', 'authors': 'Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang', 'link': 'https://arxiv.org/abs/2504.02810', 'abstract': "With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments. To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs. KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty. Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization. We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students. Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges. Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities.", 'abstract_zh': '强大的大型语言模型（LLMs）展示出超人类的推理能力，一个关键问题由此产生：LLMs究竟是真正的推理，还是仅仅从广泛采集的网络训练数据集中回忆答案？公开发布的基准不可避免地会在被纳入后续LLM训练集后受到污染，削弱它们作为可信评估工具的有效性。为解决这一问题，我们提出KUMO，一种专门用于评估LLM推理能力的生成型评估框架。KUMO利用LLMs与符号引擎协同工作，动态生成多样且多轮的推理任务，这些任务部分可观测且具备调整难度的能力。通过自动化流程，KUMO持续生成跨开放式领域的新型任务，促使模型展示真正的泛化能力而非记忆能力。我们对KUMO生成的100个领域中的5000个任务评估了23种最先进的LLMs，并将其推理能力与大学生进行了基准测试。研究发现，许多LLMs已经在简单的推理任务上超越了大学水平的表现，而推理调优的LLMs在复杂推理挑战中也达到了大学水平的表现。此外，LLMs在KUMO任务上的表现与新发布的实际推理基准测试结果之间存在强烈的相关性，这突显了KUMO作为评估LLM真正推理能力的坚固且持久工具的价值。', 'title_zh': '大型语言模型中复杂推理的生成性评估'}
{'arxiv_id': 'arXiv:2504.02807', 'title': 'MegaMath: Pushing the Limits of Open Math Corpora', 'authors': 'Fan Zhou, Zengzhi Wang, Nikhil Ranjan, Zhoujun Cheng, Liping Tang, Guowei He, Zhengzhong Liu, Eric P. Xing', 'link': 'https://arxiv.org/abs/2504.02807', 'abstract': 'Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet. (2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity. (3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data. By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets.', 'abstract_zh': '数学推理是人类智能的基础，也是大型语言模型（LLMs）高级能力的关键评价标准。然而，研究社区仍然缺乏一个针对数学中心型LLM预训练需求的开放、大规模、高质量语料库。我们介绍了MegaMath，一个通过以下策略慎重编纂的开放数据集：（1）重访网络数据：我们重新从Common Crawl中提取数学文档，并进行了数学导向的HTML优化、基于fastText的过滤和去重，以获取更高质量的网络数据。（2）回忆相关代码数据：我们从大规模代码训练语料库Stack-V2中识别高质量的数学相关代码，进一步增强数据多样性。（3）探索合成数据：我们从网络数据或代码数据中合成了问答风格文本、数学相关代码以及交错的文本-代码块。通过整合这些策略并在广泛的 ablation 实验中验证其有效性，MegaMath 提供了现有开放数学预训练语料库中词汇量和质量最大的 371B 个词元。', 'title_zh': 'MegaMath: 推动开源数学语料库的极限'}
{'arxiv_id': 'arXiv:2504.02799', 'title': 'Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence', 'authors': 'Anita Rau, Mark Endo, Josiah Aklilu, Jaewoo Heo, Khaled Saab, Alberto Paderno, Jeffrey Jopling, F. Christopher Holsinger, Serena Yeung-Levy', 'link': 'https://arxiv.org/abs/2504.02799', 'abstract': "Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications.", 'abstract_zh': '大型多模态视觉-语言模型为基于AI的图像理解提供了新范式，使模型能够在无需特定任务训练的情况下执行任务。这种灵活性在医学领域特别有前景，因为专家标注的数据匮乏。然而，VLMs在干预导向领域（尤其是手术领域，决策具有主观性，临床场景多变）的实际应用价值仍不确定。在此，我们通过涵盖腔镜、机器人和开放手术在内的13个数据集，对17项关键视觉理解任务进行全面分析，评估了11种最先进的VLM在手术AI中的表现，从解剖识别到技能评估。在我们的实验中，VLMs展示了令人瞩目的泛化能力，在某些情况下，即使在远离训练环境的情况下部署，其性能也超过了监督模型。上下文学习通过在测试期间引入示例，将性能提升三倍以上，表明适应性是其关键优势。然而，涉及空间或时间推理的任务仍然具有挑战性。除此之外，我们的研究还为VLMs在临床和其他复杂且动态的现实世界应用中的潜力提供了见解。', 'title_zh': '系统评价大型视觉-语言模型在手术人工智能中的应用'}
{'arxiv_id': 'arXiv:2504.02792', 'title': 'Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets', 'authors': 'Chuning Zhu, Raymond Yu, Siyuan Feng, Benjamin Burchfiel, Paarth Shah, Abhishek Gupta', 'link': 'https://arxiv.org/abs/2504.02792', 'abstract': 'Imitation learning has emerged as a promising approach towards building generalist robots. However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations. Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available. This data provides a rich source of information about real-world dynamics and agent-environment interactions. Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods. In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning. Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality. We show that by simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator. Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies. Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling. Videos and code are available at this https URL.', 'abstract_zh': '统一世界模型：结合视频和动作数据进行策略学习的方法', 'title_zh': '统一的世界模型：结合视频和动作扩散的大规模机器人数据预训练'}
{'arxiv_id': 'arXiv:2504.02781', 'title': 'Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations', 'authors': 'Selim Ickin, Shruti Bothe, Aman Raparia, Nitin Khanna, Erik Sanders', 'link': 'https://arxiv.org/abs/2504.02781', 'abstract': 'Optimization of radio hardware and AI-based network management software yield significant energy savings in radio access networks. The execution of underlying Machine Learning (ML) models, which enable energy savings through recommended actions, may require additional compute and energy, highlighting the opportunity to explore and adopt accurate and energy-efficient ML technologies. This work evaluates the novel use of sparsely structured Neural Circuit Policies (NCPs) in a use case to estimate the energy consumption of base stations. Sparsity in ML models yields reduced memory, computation and energy demand, hence facilitating a low-cost and scalable solution. We also evaluate the generalization capability of NCPs in comparison to traditional and widely used ML models such as Long Short Term Memory (LSTM), via quantifying their sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a clear reduction in computational overhead and energy consumption. Moreover, results indicated that the NCPs are robust to varying HPs such as number of epochs and neurons in each layer, making them a suitable option to ease model management and to reduce energy consumption in Machine Learning Operations (MLOps) in telecommunications.', 'abstract_zh': '基于稀疏结构神经电路策略的无线接入网络能耗优化研究', 'title_zh': '面向绿色AI原生网络：基站能耗估算的神经电路策略评估'}
{'arxiv_id': 'arXiv:2504.02780', 'title': 'From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks', 'authors': 'Joshua Holstein, Moritz Diener, Philipp Spitzer', 'link': 'https://arxiv.org/abs/2504.02780', 'abstract': 'The rise of Generative AI, and Large Language Models (LLMs) in particular, is fundamentally changing cognitive processes in knowledge work, raising critical questions about their impact on human reasoning and problem-solving capabilities. As these AI systems become increasingly integrated into workflows, they offer unprecedented opportunities for augmenting human thinking while simultaneously risking cognitive erosion through passive consumption of generated answers. This tension is particularly pronounced in open-ended tasks, where effective solutions require deep contextualization and integration of domain knowledge. Unlike structured tasks with established metrics, measuring the quality of human-LLM interaction in such open-ended tasks poses significant challenges due to the absence of ground truth and the iterative nature of solution development. To address this, we present a framework that analyzes interaction patterns along two dimensions: cognitive activity mode (exploration vs. exploitation) and cognitive engagement mode (constructive vs. detrimental). This framework provides systematic measurements to evaluate when LLMs are effective tools for thought rather than substitutes for human cognition, advancing theoretical understanding and practical guidance for developing AI systems that protect and augment human cognitive capabilities.', 'abstract_zh': '生成式AI的兴起，尤其是大型语言模型（LLMs），从根本上改变了知识工作中的认知过程，引发了对其对人类推理和问题解决能力影响的关键问题。随着这些AI系统越来越多地集成到工作流程中，它们提供了前所未有的机会来增强人类思维，同时也通过被动消费生成的答案而带来认知衰退的风险。这一紧张关系在开放式任务中尤为突出，有效解决方案需要深厚的上下文理解和领域知识的集成。与有明确度量标准的结构化任务不同，由于缺乏真实标准且解决方案开发具有迭代性，衡量人类与LLM交互的质量面临重大挑战。为此，我们提出了一种框架，从两个维度分析交互模式：认知活动模式（探索 vs. 利用）和认知参与模式（建设性 vs. 损害性）。该框架提供了系统性测量标准，以评估LLM是作为辅助思维工具还是代替人类认知的工具，从而推动对保护和增强人类认知能力的AI系统理论理解与实践指导。', 'title_zh': '从消费到协作：通过测量互动模式增强在开放任务中的人类认知'}
{'arxiv_id': 'arXiv:2504.02778', 'title': 'Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition', 'authors': 'Vincent Gbouna Zakka, Luis J. Manso, Zhuangzhuang Dai', 'link': 'https://arxiv.org/abs/2504.02778', 'abstract': 'Human activity recognition is increasingly vital for supporting independent living, particularly for the elderly and those in need of assistance. Domestic service robots with monitoring capabilities can enhance safety and provide essential support. Although image-based methods have advanced considerably in the past decade, their adoption remains limited by concerns over privacy and sensitivity to low-light or dark conditions. As an alternative, millimetre-wave (mmWave) radar can produce point cloud data which is privacy-preserving. However, processing the sparse and noisy point clouds remains a long-standing challenge. While graph-based methods and attention mechanisms show promise, they predominantly rely on "fixed" kernels; kernels that are applied uniformly across all neighbourhoods, highlighting the need for adaptive approaches that can dynamically adjust their kernels to the specific geometry of each local neighbourhood in point cloud data. To overcome this limitation, we introduce an adaptive approach within the graph convolutional framework. Instead of a single shared weight function, our Multi-Head Adaptive Kernel (MAK) module generates multiple dynamic kernels, each capturing different aspects of the local feature space. By progressively refining local features while maintaining global spatial context, our method enables convolution kernels to adapt to varying local features. Experimental results on benchmark datasets confirm the effectiveness of our approach, achieving state-of-the-art performance in human activity recognition. Our source code is made publicly available at: this https URL', 'abstract_zh': '基于人体活动识别在支持独立生活中的重要作用，特别是对于老年人和需要协助的人群而言，具有监控能力的家庭服务机器人可以增强安全性并提供必要支持。尽管在过去十年中基于图像的方法取得了显著进展，但由于隐私担忧和对低光或暗环境敏感的问题，其应用仍然受到限制。作为替代方案，毫米波（mmWave）雷达可以生成保护隐私的点云数据。然而，处理稀疏和噪声点云仍然是一个长期挑战。虽然图基元方法和注意力机制显示出前景，但它们主要依赖于“固定”内核；这些内核在所有局部邻域中均匀应用，表明需要能够根据每个局部邻域的具体几何形状动态调整内核的适应性方法。为克服这一局限，我们在图卷积框架内引入了一种适应性方法。与单一共享权重函数不同，我们的多头自适应内核（MAK）模块生成多个动态内核，每个内核捕捉局部特征空间的不同方面。通过逐步细化局部特征同时保持全局空间上下文，我们的方法使卷积内核能够适应变化的局部特征。在基准数据集上的实验结果证实了我们方法的有效性，达到了人体活动识别的最新性能。我们的源代码已公开发布在：this https URL。', 'title_zh': '基于稀疏点云的多头自适应图卷积网络人体活动识别'}
{'arxiv_id': 'arXiv:2504.02767', 'title': 'How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?', 'authors': 'Andres Algaba, Vincent Holst, Floriano Tori, Melika Mobini, Brecht Verbeken, Sylvia Wenmackers, Vincent Ginis', 'link': 'https://arxiv.org/abs/2504.02767', 'abstract': 'The spread of scientific knowledge depends on how researchers discover and cite previous work. The adoption of large language models (LLMs) in the scientific research process introduces a new layer to these citation practices. However, it remains unclear to what extent LLMs align with human citation practices, how they perform across domains, and may influence citation dynamics. Here, we show that LLMs systematically reinforce the Matthew effect in citations by consistently favoring highly cited papers when generating references. This pattern persists across scientific domains despite significant field-specific variations in existence rates, which refer to the proportion of generated references that match existing records in external bibliometric databases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers, we find that LLM recommendations diverge from traditional citation patterns by preferring more recent references with shorter titles and fewer authors. Emphasizing their content-level relevance, the generated references are semantically aligned with the content of each paper at levels comparable to the ground truth references and display similar network effects while reducing author self-citations. These findings illustrate how LLMs may reshape citation practices and influence the trajectory of scientific discovery by reflecting and amplifying established trends. As LLMs become more integrated into the scientific research process, it is important to understand their role in shaping how scientific communities discover and build upon prior work.', 'abstract_zh': '科学知识的传播取决于研究人员如何发现和引用先前的工作。大型语言模型（LLMs）在科学研究过程中的应用引入了引用实践的新层次。然而，LLMs与人类引用实践的契合度、其在不同领域的表现以及如何影响引用动态尚不明确。在这里，我们表明，LLMs系统地强化了引用中的马太效应，即在生成参考文献时始终更青睐高被引论文。这一模式在不同科学领域中持续存在，尽管这些领域在生成的参考文献与外部引文数据库现有记录匹配率方面存在显著的领域特定差异。分析GPT-4o为10,000篇论文生成的274,951个参考文献，我们发现，LLMs的推荐偏好于更近、标题更短和作者更少的参考文献。通过强调内容相关性，生成的参考文献在语义上与每篇论文的内容保持一致，显示相似的网络效应，同时减少了作者自引。这些发现说明了LLMs可能如何重新塑造引用实践，以及通过反映和放大已确立的趋势如何影响科学发现的轨迹。随着LLMs在科学研究过程中的集成程度加深，理解其在塑造科学社区发现和借鉴先前工作方面的作用变得尤为重要。', 'title_zh': '大型语言模型在多大程度上内化了科学文献和引用实践？'}
{'arxiv_id': 'arXiv:2504.02764', 'title': 'Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model', 'authors': 'Shengjun Zhang, Jinzhao Li, Xin Fei, Hao Liu, Yueqi Duan', 'link': 'https://arxiv.org/abs/2504.02764', 'abstract': 'In this paper, we propose Scene Splatter, a momentum-based paradigm for video diffusion to generate generic scenes from single image. Existing methods, which employ video generation models to synthesize novel views, suffer from limited video length and scene inconsistency, leading to artifacts and distortions during further reconstruction. To address this issue, we construct noisy samples from original features as momentum to enhance video details and maintain scene consistency. However, for latent features with the perception field that spans both known and unknown regions, such latent-level momentum restricts the generative ability of video diffusion in unknown regions. Therefore, we further introduce the aforementioned consistent video as a pixel-level momentum to a directly generated video without momentum for better recovery of unseen regions. Our cascaded momentum enables video diffusion models to generate both high-fidelity and consistent novel views. We further finetune the global Gaussian representations with enhanced frames and render new frames for momentum update in the next step. In this manner, we can iteratively recover a 3D scene, avoiding the limitation of video length. Extensive experiments demonstrate the generalization capability and superior performance of our method in high-fidelity and consistent scene generation.', 'abstract_zh': '基于动量的视频扩散场景泼溅：单张图像生成通用场景的方法', 'title_zh': '场景泼溅：基于视频扩散模型的单图像3D场景生成'}
{'arxiv_id': 'arXiv:2504.02737', 'title': 'RBR4DNN: Requirements-based Testing of Neural Networks', 'authors': 'Nusrat Jahan Mozumder, Felipe Toledo, Swaroopa Dola, Matthew B. Dwyer', 'link': 'https://arxiv.org/abs/2504.02737', 'abstract': 'Deep neural network (DNN) testing is crucial for the reliability and safety of critical systems, where failures can have severe consequences. Although various techniques have been developed to create robustness test suites, requirements-based testing for DNNs remains largely unexplored -- yet such tests are recognized as an essential component of software validation of critical systems. In this work, we propose a requirements-based test suite generation method that uses structured natural language requirements formulated in a semantic feature space to create test suites by prompting text-conditional latent diffusion models with the requirement precondition and then using the associated postcondition to define a test oracle to judge outputs of the DNN under test. We investigate the approach using fine-tuned variants of pre-trained generative models. Our experiments on the MNIST, CelebA-HQ, ImageNet, and autonomous car driving datasets demonstrate that the generated test suites are realistic, diverse, consistent with preconditions, and capable of revealing faults.', 'abstract_zh': '基于需求的深度神经网络测试套件生成方法', 'title_zh': '基于需求的神经网络测试：RBR4DNN'}
{'arxiv_id': 'arXiv:2504.02724', 'title': 'Autonomous Human-Robot Interaction via Operator Imitation', 'authors': 'Sammy Christen, David Müller, Agon Serifi, Ruben Grandia, Georg Wiedebach, Michael A. Hopkins, Espen Knoop, Moritz Bächer', 'link': 'https://arxiv.org/abs/2504.02724', 'abstract': "Teleoperated robotic characters can perform expressive interactions with humans, relying on the operators' experience and social intuition. In this work, we propose to create autonomous interactive robots, by training a model to imitate operator data. Our model is trained on a dataset of human-robot interactions, where an expert operator is asked to vary the interactions and mood of the robot, while the operator commands as well as the pose of the human and robot are recorded. Our approach learns to predict continuous operator commands through a diffusion process and discrete commands through a classifier, all unified within a single transformer architecture. We evaluate the resulting model in simulation and with a user study on the real system. We show that our method enables simple autonomous human-robot interactions that are comparable to the expert-operator baseline, and that users can recognize the different robot moods as generated by our model. Finally, we demonstrate a zero-shot transfer of our model onto a different robotic platform with the same operator interface.", 'abstract_zh': '基于生成模型和分类器的自主交互机器人训练方法及其零样本迁移', 'title_zh': '自主人体-机器人交互通过操作员模仿'}
{'arxiv_id': 'arXiv:2504.02698', 'title': 'SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions', 'authors': 'Shengrui XU, Tianchi Lu, Zikun Wang, Jixiu Zhai, Jingwan Wang', 'link': 'https://arxiv.org/abs/2504.02698', 'abstract': 'Protein-Protein Interaction (PPI) prediction is a key task in uncovering cellular functional networks and disease mechanisms. However, traditional experimental methods are time-consuming and costly, and existing computational models face challenges in cross-modal feature fusion, robustness, and false-negative suppression. In this paper, we propose a novel supervised contrastive multimodal framework, SCMPPI, for PPI prediction. By integrating protein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology information (Node2Vec graph embedding), and combining an improved supervised contrastive learning strategy, SCMPPI significantly enhances PPI prediction performance. For the PPI task, SCMPPI introduces a negative sample filtering mechanism and modifies the contrastive loss function, effectively optimizing multimodal features. Experiments on eight benchmark datasets, including yeast, human, and this http URL, show that SCMPPI outperforms existing state-of-the-art methods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%) and AUC (99.62%), and demonstrates strong generalization in cross-species prediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been successfully applied to CD9 networks, the Wnt pathway, and cancer-specific networks, providing a reliable tool for disease target discovery. This framework also offers a new paradigm for multimodal biological information fusion and contrastive learning in collaborative optimization for various combined predictions.', 'abstract_zh': '蛋白质-蛋白质相互作用（PPI）预测是揭示细胞功能网络和疾病机制的关键任务。然而，传统的实验方法耗时且成本高，现有的计算模型在跨模态特征融合、鲁棒性和减少假阴性方面面临挑战。本文提出了一种新的监督对比多模态框架SCMPPI，用于PPI预测。通过将蛋白质序列特征（AAC, DPC, CKSAAP-ESMC）与PPI网络拓扑信息（Node2Vec图嵌入）相结合，并采用改进的监督对比学习策略，SCMPPI显著提高了PPI预测性能。在酵母、人类以及其他基准数据集中，SCMPPI在关键指标如准确率（98.01%）和AUC（99.62%）上优于现有最先进的方法（如DF-PPI和TAGPPI），并在跨物种预测中展现了强大的泛化能力（多物种数据集中AUC > 99%）。此外，SCMPPI已成功应用于CD9网络、Wnt信号通路和癌症特异性网络，为疾病靶标发现提供了可靠的工具。该框架还为多模态生物信息融合和在各种联合预测中的协作优化提供了新的范式。', 'title_zh': 'SCMPPI：监督对比多模态框架用于预测蛋白质-蛋白质相互作用'}
{'arxiv_id': 'arXiv:2504.02685', 'title': 'STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability', 'authors': 'Iván Sevillano-García, Julián Luengo, Francisco Herrera', 'link': 'https://arxiv.org/abs/2504.02685', 'abstract': 'Out-of-Distribution (OOD) detection is a critical task in machine learning, particularly in safety-sensitive applications where model failures can have serious consequences. However, current OOD detection methods often suffer from restrictive distributional assumptions, limited scalability, and a lack of interpretability. To address these challenges, we propose STOOD-X, a two-stage methodology that combines a Statistical nonparametric Test for OOD Detection with eXplainability enhancements. In the first stage, STOOD-X uses feature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD samples without assuming a specific feature distribution. In the second stage, it generates user-friendly, concept-based visual explanations that reveal the features driving each decision, aligning with the BLUE XAI paradigm. Through extensive experiments on benchmark datasets and multiple architectures, STOOD-X achieves competitive performance against state-of-the-art post hoc OOD detectors, particularly in high-dimensional and complex settings. In addition, its explainability framework enables human oversight, bias detection, and model debugging, fostering trust and collaboration between humans and AI systems. The STOOD-X methodology therefore offers a robust, explainable, and scalable solution for real-world OOD detection tasks.', 'abstract_zh': 'Out-of-Distribution (OOD)检测是机器学习中的一个重要任务，特别是在安全性要求高的应用中，模型失败可能会导致严重后果。然而，当前的OOD检测方法往往存在严格的分布假设、可扩展性有限以及缺乏可解释性的问题。为了解决这些挑战，我们提出了一种名为STOOD-X的两阶段方法，该方法结合了统计非参数检验与可解释性增强。在第一阶段，STOOD-X利用特征空间距离和Wilcoxon-Mann-Whitney检验来识别OOD样本，而不假设特定的特征分布。在第二阶段，它生成用户友好的、基于概念的可视化解释，揭示每个决策背后的关键特征，符合BLUE XAI范式。通过在基准数据集和多种架构上的广泛实验，STOOD-X在高维度和复杂设置中实现了与先进事后OOD检测器相当的性能。此外，其可解释性框架可以实现人类监督、偏差检测和模型调试，促进人类与AI系统的信任与协作。因此，STOOD-X方法为现实世界的OOD检测任务提供了一个稳健、可解释且可扩展的解决方案。', 'title_zh': 'STOOD-X 方法学：使用统计非参数测试进行OOD检测，增强可解释性的大规模数据集'}
{'arxiv_id': 'arXiv:2504.02646', 'title': 'Prompt Optimization with Logged Bandit Data', 'authors': 'Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims', 'link': 'https://arxiv.org/abs/2504.02646', 'abstract': 'We study how to use naturally available user feedback, such as clicks, to optimize large language model (LLM) pipelines for generating personalized sentences using prompts. Naive approaches, which estimate the policy gradient in the prompt space, suffer either from variance caused by the large action space of prompts or bias caused by inaccurate reward predictions. To circumvent these challenges, we propose a novel kernel-based off-policy gradient method, which estimates the policy gradient by leveraging similarity among generated sentences, substantially reducing variance while suppressing the bias. Empirical results on our newly established suite of benchmarks demonstrate the effectiveness of the proposed approach in generating personalized descriptions for movie recommendations, particularly when the number of candidate prompts is large.', 'abstract_zh': '我们研究如何利用自然可用的用户反馈，如点击行为，优化生成个性化句子的大语言模型（LLM）管道，并使用提示进行优化。针对提示空间大的动作空间导致的方差问题及不准确奖励预测导致的偏差问题，我们提出了一种新颖的核基于离策策略梯度方法，通过利用生成句子之间的相似性来估计策略梯度，显著降低了方差并抑制了偏差。我们在新建立的基准测试套件上的实验结果表明，所提出的方法在生成电影推荐的个性化描述方面特别有效，尤其是在候选提示数量较多时。', 'title_zh': '带日志的bandit数据的提示优化'}
{'arxiv_id': 'arXiv:2504.02620', 'title': 'Efficient Model Editing with Task-Localized Sparse Fine-tuning', 'authors': 'Leonardo Iurada, Marco Ciccone, Tatiana Tommasi', 'link': 'https://arxiv.org/abs/2504.02620', 'abstract': 'Task arithmetic has emerged as a promising approach for editing models by representing task-specific knowledge as composable task vectors. However, existing methods rely on network linearization to derive task vectors, leading to computational bottlenecks during training and inference. Moreover, linearization alone does not ensure weight disentanglement, the key property that enables conflict-free composition of task vectors. To address this, we propose TaLoS which allows to build sparse task vectors with minimal interference without requiring explicit linearization and sharing information across tasks. We find that pre-trained models contain a subset of parameters with consistently low gradient sensitivity across tasks, and that sparsely updating only these parameters allows for promoting weight disentanglement during fine-tuning. Our experiments prove that TaLoS improves training and inference efficiency while outperforming current methods in task addition and negation. By enabling modular parameter editing, our approach fosters practical deployment of adaptable foundation models in real-world applications.', 'abstract_zh': '任务算术已 emergent as a promising approach for editing models by representing task-specific knowledge as composable task vectors.然而，现有方法依赖于网络线性化来推导任务向量，导致训练和推理中的计算瓶颈。此外，仅线性化并不能确保权重解纠缠，这是使任务向量冲突-free composition 的关键属性。为了解决这一问题，我们提出了 TaLoS，它允许构建稀疏的任务向量，同时最小化相互干扰，而无需明确的线性化和跨任务共享信息。我们发现预训练模型中包含一组参数，其在任务间的梯度敏感性始终较低，仅更新这些参数可以促进解纠缠过程在微调中的进行。我们的实验表明，TaLoS 在提高训练和推理效率的同时，在任务添加和否定方面也优于当前方法。通过使参数编辑模块化，我们的方法促进了一体化基础模型的实际部署和应用。', 'title_zh': '任务局部化稀疏微调的高效模型编辑'}
{'arxiv_id': 'arXiv:2504.02607', 'title': 'Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks', 'authors': 'Samuel Tesfazgi, Leonhard Sprandl, Sandra Hirche', 'link': 'https://arxiv.org/abs/2504.02607', 'abstract': 'The practical deployment of learning-based autonomous systems would greatly benefit from tools that flexibly obtain safety guarantees in the form of certificate functions from data. While the geometrical properties of such certificate functions are well understood, synthesizing them using machine learning techniques still remains a challenge. To mitigate this issue, we propose a diffeomorphic function learning framework where prior structural knowledge of the desired output is encoded in the geometry of a simple surrogate function, which is subsequently augmented through an expressive, topology-preserving state-space transformation. Thereby, we achieve an indirect function approximation framework that is guaranteed to remain in the desired hypothesis space. To this end, we introduce a novel approach to construct diffeomorphic maps based on RBF networks, which facilitate precise, local transformations around data. Finally, we demonstrate our approach by learning diffeomorphic Lyapunov functions from real-world data and apply our method to different attractor systems.', 'abstract_zh': '基于学习的自主系统实用部署将极大地受益于能够灵活从数据中获取安全保证（以证书函数的形式）的工具。虽然此类证书函数的几何性质已被充分了解，但使用机器学习技术合成它们仍然是一项挑战。为缓解这一问题，我们提出了一种 diffeomorphic 函数学习框架，其中将所需输出的先验结构知识编码在简单替代函数的几何结构中，随后通过一个表征性强且保持拓扑结构的态空间变换进行增强。由此，我们实现了一个间接函数逼近框架，可以保证其始终保持在所需的假设空间。为此，我们提出了一种基于 RBF 网络构建 diffeomorphic 映射的新方法，这些方法能够实现数据周围的精确局部变换。最后，我们通过从真实-world 数据中学习 diffeomorphic 李雅普诺夫函数，并将我们的方法应用到不同的吸引子系统，展示了我们的方法。', 'title_zh': '学习几何导向的李雅普unov函数的深层 diffeomorphic RBF 网络方法'}
{'arxiv_id': 'arXiv:2504.02606', 'title': 'Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification', 'authors': 'Jonas Teufel, Annika Leinweber, Pascal Friederich', 'link': 'https://arxiv.org/abs/2504.02606', 'abstract': 'Explainable AI (xAI) interventions aim to improve interpretability for complex black-box models, not only to improve user trust but also as a means to extract scientific insights from high-performing predictive systems. In molecular property prediction, counterfactual explanations offer a way to understand predictive behavior by highlighting which minimal perturbations in the input molecular structure cause the greatest deviation in the predicted property. However, such explanations only allow for meaningful scientific insights if they reflect the distribution of the true underlying property -- a feature we define as counterfactual truthfulness. To increase this truthfulness, we propose the integration of uncertainty estimation techniques to filter counterfactual candidates with high predicted uncertainty. Through computational experiments with synthetic and real-world datasets, we demonstrate that traditional uncertainty estimation methods, such as ensembles and mean-variance estimation, can already substantially reduce the average prediction error and increase counterfactual truthfulness, especially for out-of-distribution settings. Our results highlight the importance and potential impact of incorporating uncertainty estimation into explainability methods, especially considering the relatively high effectiveness of low-effort interventions like model ensembles.', 'abstract_zh': '可解释人工智能（xAI）干预旨在提高复杂黑盒模型的可解释性，不仅提高用户信任，也是从高性能预测系统中提取科学洞察的有效途径。在分子性质预测中，反事实解释通过突出显示哪些最小的输入分子结构变化导致预测性质的最大偏差，提供了一种理解预测行为的方式。然而，这样的解释只有反映真实基础性质的分布时，才允许获得有意义的科学洞察——我们将其定义为反事实真实性。为了增加这种真实性，我们提出将不确定性估计技术集成到反事实候选者筛选中，以过滤出高预测不确定性的情况。通过使用合成和真实世界数据集的计算实验，我们表明传统的不确定性估计方法（如集成和均方差估计）可以显著降低平均预测误差，并提高反事实真实性，尤其是在分布外设置中。我们的结果强调了将不确定性估计纳入解释方法的重要性及其潜在影响，特别是考虑到模型集成等低投入干预措施的相对高效率。', 'title_zh': '通过不确定性量化提高分子性质预测的反事实真实性'}
{'arxiv_id': 'arXiv:2504.02605', 'title': 'Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving', 'authors': 'Daoguang Zan, Zhirong Huang, Wei Liu, Hanwu Chen, Linhao Zhang, Shulin Xin, Lu Chen, Qi Liu, Xiaojian Zhong, Aoyan Li, Siyao Liu, Yongsheng Xiao, Liangqiang Chen, Yuyu Zhang, Jing Su, Tianyu Liu, Rui Long, Kai Shen, Liang Xiang', 'link': 'https://arxiv.org/abs/2504.02605', 'abstract': 'The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To address this, we introduce a multilingual issue-resolving benchmark, called Multi-SWE-bench, covering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a total of 1,632 high-quality instances, which were carefully annotated from 2,456 candidates by 68 expert annotators, ensuring that the benchmark can provide an accurate and reliable evaluation. Based on Multi-SWE-bench, we evaluate a series of state-of-the-art models using three representative methods (Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with key empirical insights. In addition, we launch a Multi-SWE-RL open-source community, aimed at building large-scale reinforcement learning (RL) training datasets for issue-resolving tasks. As an initial contribution, we release a set of 4,723 well-structured instances spanning seven programming languages, laying a solid foundation for RL research in this domain. More importantly, we open-source our entire data production pipeline, along with detailed tutorials, encouraging the open-source community to continuously contribute and expand the dataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL community as catalysts for advancing RL toward its full potential, bringing us one step closer to the dawn of AGI.', 'abstract_zh': '一种多语言问题解决基准Multi-SWE-bench及其在大语言模型评价中的应用', 'title_zh': '多语言问题解决基准：Multi-SWE-bench'}
{'arxiv_id': 'arXiv:2504.02589', 'title': 'Knowledge Graph Completion with Mixed Geometry Tensor Factorization', 'authors': 'Viacheslav Yusupov, Maxim Rakhuba, Evgeny Frolov', 'link': 'https://arxiv.org/abs/2504.02589', 'abstract': 'In this paper, we propose a new geometric approach for knowledge graph completion via low rank tensor approximation. We augment a pretrained and well-established Euclidean model based on a Tucker tensor decomposition with a novel hyperbolic interaction term. This correction enables more nuanced capturing of distributional properties in data better aligned with real-world knowledge graphs. By combining two geometries together, our approach improves expressivity of the resulting model achieving new state-of-the-art link prediction accuracy with a significantly lower number of parameters compared to the previous Euclidean and hyperbolic models.', 'abstract_zh': '本文提出了一种新的几何方法，通过低秩张量近似来完成知识图谱。该方法基于Tucker张量分解，对一个预训练且成熟的欧几里得模型进行扩充，加入了新型双曲交互项。这使得模型能够更细腻地捕捉与现实世界知识图谱更一致的数据分布特性。通过结合两种几何方法，该方法提升了模型的表现力，实现了新的链接预测准确率状态最in，并且所需参数显著少于之前的欧几里得和双曲模型。', 'title_zh': '混合几何张量分解的知识图谱补全'}
{'arxiv_id': 'arXiv:2504.02586', 'title': 'Deep learning for music generation. Four approaches and their comparative evaluation', 'authors': 'Razvan Paroiu, Stefan Trausan-Matu', 'link': 'https://arxiv.org/abs/2504.02586', 'abstract': 'This paper introduces four different artificial intelligence algorithms for music generation and aims to compare these methods not only based on the aesthetic quality of the generated music but also on their suitability for specific applications. The first set of melodies is produced by a slightly modified visual transformer neural network that is used as a language model. The second set of melodies is generated by combining chat sonification with a classic transformer neural network (the same method of music generation is presented in a previous research), the third set of melodies is generated by combining the Schillinger rhythm theory together with a classic transformer neural network, and the fourth set of melodies is generated using GPT3 transformer provided by OpenAI. A comparative analysis is performed on the melodies generated by these approaches and the results indicate that significant differences can be observed between them and regarding the aesthetic value of them, GPT3 produced the most pleasing melodies, and the newly introduced Schillinger method proved to generate better sounding music than previous sonification methods.', 'abstract_zh': '本文介绍了四种不同的人工智能算法在音乐生成中的应用，并旨在不仅从所生成音乐的审美质量，而且从其特定应用的适用性方面比较这些方法。第一组旋律由略微修改的视觉变换神经网络生成，该网络作为语言模型使用。第二组旋律通过结合对话声化和经典变换神经网络生成（音乐生成方法在先前研究中有所呈现），第三组旋律通过结合希尔灵格节奏理论与经典变换神经网络生成，第四组旋律使用由OpenAI提供的GPT3变换器生成。对这些方法生成的旋律进行了比较分析，结果表明，这些方法之间存在显著差异，在审美价值方面，GPT3生成的旋律最为悦耳，新引入的希尔灵格方法证明生成的音乐比之前的声化方法听起来更好。', 'title_zh': '基于深度学习的音乐生成：四种方法及其比较评价'}
{'arxiv_id': 'arXiv:2504.02558', 'title': 'Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results', 'authors': 'Andrei Dumitriu, Florin Tatui, Florin Miron, Radu Tudor Ionescu, Radu Timofte', 'link': 'https://arxiv.org/abs/2504.02558', 'abstract': 'Rip currents are the leading cause of fatal accidents and injuries on many beaches worldwide, emphasizing the importance of automatically detecting these hazardous surface water currents. In this paper, we address a novel task: rip current instance segmentation. We introduce a comprehensive dataset containing $2,466$ images with newly created polygonal annotations for instance segmentation, used for training and validation. Additionally, we present a novel dataset comprising $17$ drone videos (comprising about $24K$ frames) captured at $30 FPS$, annotated with both polygons for instance segmentation and bounding boxes for object detection, employed for testing purposes. We train various versions of YOLOv8 for instance segmentation on static images and assess their performance on the test dataset (videos). The best results were achieved by the YOLOv8-nano model (runnable on a portable device), with an mAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the test dataset. The results provide a baseline for future research in rip current segmentation. Our work contributes to the existing literature by introducing a detailed, annotated dataset, and training a deep learning model for instance segmentation of rip currents. The code, training details and the annotated dataset are made publicly available at this https URL.', 'abstract_zh': 'Rip現流是全球許多海灘上致命事故和傷害的主要原因，強調了自動檢測這些危險的表面水流現流的重要性。在本文中，我們 Dresses 一项新颖的任务：rip現流实例分割。我们引入了一个全面的数据集，包含2,466张带有新创建的多边形注释的图像，用于训练和验证。此外，我们还展示了包含17架无人机视频（约24K帧，每秒30帧）的新数据集，这些视频被标注为实例分割的多边形和对象检测的边界框，用于测试目的。我们对静态图像训练了多种版本的YOLOv8模型，并评估其在测试数据集（视频）上的性能。YOLOv8-nano模型在验证数据集上取得了mAP50为88.94%的最佳结果，并在测试数据集上的宏平均mAP为81.21%。我们的结果为未来的研究提供了基线。我们的工作通过引入详细的标注数据集和为rip現流实例分割训练深度学习模型，为现有的文献做出了贡献。相关代码、训练细节和标注数据集在此网址公开提供。', 'title_zh': 'rip现细分段：一种新型基准和YOLOv8基准结果'}
{'arxiv_id': 'arXiv:2504.02546', 'title': 'GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning', 'authors': 'Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang', 'link': 'https://arxiv.org/abs/2504.02546', 'abstract': 'Reinforcement Learning (RL) can directly enhance the reasoning capabilities of large language models without extensive reliance on Supervised Fine-Tuning (SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism and propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike conventional methods, GPG directly optimize the original RL objective, thus obviating the need for surrogate loss functions. As illustrated in our paper, by eliminating both the critic and reference models, and avoiding KL divergence constraints, our approach significantly simplifies the training process when compared to Group Relative Policy Optimization (GRPO). Our approach achieves superior performance without relying on auxiliary techniques or adjustments. Extensive experiments demonstrate that our method not only reduces computational costs but also consistently outperforms GRPO across various unimodal and multimodal tasks. Our code is available at this https URL.', 'abstract_zh': 'reinforcement learning可以直接增强大型语言模型的推理能力，而无需大量依赖监督微调。在这项工作中，我们回顾了传统的策略梯度机制，并提出了一种名为群体策略梯度（GPG）的 minimalist RL方法。与传统方法不同，GPG 直接优化原始的 RL 目标，从而避免使用代理损失函数。我们的研究表明，通过消除批评者和参考模型，并避免 KL 散度约束，与群体相对策略优化（GRPO）相比，我们的方法在训练过程中显著简化。我们的方法不依赖于辅助技术或调整，在各种单模态和多模态任务中均表现出更优性能。我们的代码可从该网址获取。', 'title_zh': 'GPG：一种简单而强大的模型推理强化学习基线'}
{'arxiv_id': 'arXiv:2504.02544', 'title': 'Fourier Sliced-Wasserstein Embedding for Multisets and Measures', 'authors': 'Tal Amir, Nadav Dym', 'link': 'https://arxiv.org/abs/2504.02544', 'abstract': 'We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to embed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\nOur proposed embedding approximately preserves the sliced Wasserstein distance on distributions, thereby yielding geometrically meaningful representations that better capture the structure of the input. Moreover, it is injective on measures and bi-Lipschitz on multisets - a significant advantage over prevalent methods based on sum- or max-pooling, which are provably not bi-Lipschitz, and, in many cases, not even injective. The required output dimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is the maximal input multiset size.\nFurthermore, we prove that it is impossible to embed distributions over $\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric properties of our embedding are, in a sense, the best possible.\nThrough numerical experiments, we demonstrate that our method yields superior multiset representations that improve performance in practical learning tasks. Specifically, we show that (a) a simple combination of the FSW embedding with an MLP achieves state-of-the-art performance in learning the (non-sliced) Wasserstein distance; and (b) replacing max-pooling with the FSW embedding makes PointNet significantly more robust to parameter reduction, with only minor performance degradation even after a 40-fold reduction.', 'abstract_zh': 'Fourier裁断 Wasserstein嵌入：一种将实数域上多重集和测度嵌入欧几里得空间的新方法', 'title_zh': '多重集和度量的傅里叶切片Wasserstein嵌入'}
{'arxiv_id': 'arXiv:2504.02526', 'title': 'Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity', 'authors': 'Jeba Rezwana, Corey Ford', 'link': 'https://arxiv.org/abs/2504.02526', 'abstract': 'How AI communicates with humans is crucial for effective human-AI co-creation. However, many existing co-creative AI tools cannot communicate effectively, limiting their potential as collaborators. This paper introduces our initial design of a Framework for designing AI Communication (FAICO) for co-creative AI based on a systematic review of 107 full-length papers. FAICO presents key aspects of AI communication and their impacts on user experience to guide the design of effective AI communication. We then show actionable ways to translate our framework into two practical tools: design cards for designers and a configuration tool for users. The design cards enable designers to consider AI communication strategies that cater to a diverse range of users in co-creative contexts, while the configuration tool empowers users to customize AI communication based on their needs and creative workflows. This paper contributes new insights within the literature on human-AI co-creativity and Human-Computer Interaction, focusing on designing AI communication to enhance user experience.', 'abstract_zh': 'AI沟通框架在有效人机共创中的设计：FAICO方法论', 'title_zh': '基于FAICO的用户体验提升：迈向人类-人工智能共同创造中的AI通信框架'}
{'arxiv_id': 'arXiv:2504.02512', 'title': 'Towards Generalizing Temporal Action Segmentation to Unseen Views', 'authors': 'Emad Bahrami, Olga Zatsarynna, Gianpiero Francesca, Juergen Gall', 'link': 'https://arxiv.org/abs/2504.02512', 'abstract': 'While there has been substantial progress in temporal action segmentation, the challenge to generalize to unseen views remains unaddressed. Hence, we define a protocol for unseen view action segmentation where camera views for evaluating the model are unavailable during training. This includes changing from top-frontal views to a side view or even more challenging from exocentric to egocentric views. Furthermore, we present an approach for temporal action segmentation that tackles this challenge. Our approach leverages a shared representation at both the sequence and segment levels to reduce the impact of view differences during training. We achieve this by introducing a sequence loss and an action loss, which together facilitate consistent video and action representations across different views. The evaluation on the Assembly101, IkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a 12.8% increase in F1@50 for unseen exocentric views and a substantial 54% improvement for unseen egocentric views.', 'abstract_zh': '尽管在时间动作分割方面已经取得了显著进展，但将方法推广到未见视角的问题仍未得到解决。因此，我们定义了一种未见视角动作分割的协议，其中评估模型的相机视角在训练过程中不可用。这包括从正面视角变为侧面视角，甚至更具挑战性地从外视角变为内视角。此外，我们提出了一种时间动作分割的方法来应对这一挑战。该方法在序列和片段层面共享表示，以减少训练中视角差异的影响。我们通过引入序列损失和动作损失实现这一点，这些损失共同促进了不同视角下一致的视频和动作表示。在Assembly101、IkeaASM和EgoExoLearn数据集上的评估表明，这种方法在未见外视角下的F1@50提高了12.8%，在未见内视角下的表现提升了54%。', 'title_zh': '面向未见视角下时空动作分割的一般化'}
{'arxiv_id': 'arXiv:2504.02495', 'title': 'Inference-Time Scaling for Generalist Reward Modeling', 'authors': 'Zijun Liu, Peiyi Wang, Runxin Xu, Shirong Ma, Chong Ruan, Peng Li, Yang Liu, Yu Wu', 'link': 'https://arxiv.org/abs/2504.02495', 'abstract': 'Reinforcement learning (RL) has been widely adopted in post-training for large language models (LLMs) at scale. Recently, the incentivization of reasoning capabilities in LLMs from RL indicates that $\\textit{proper learning methods could enable effective inference-time scalability}$. A key challenge of RL is to obtain accurate reward signals for LLMs in various domains beyond verifiable questions or artificial rules. In this work, we investigate how to improve reward modeling (RM) with more inference compute for general queries, i.e. the $\\textbf{inference-time scalability of generalist RM}$, and further, how to improve the effectiveness of performance-compute scaling with proper learning methods. For the RM approach, we adopt pointwise generative reward modeling (GRM) to enable flexibility for different input types and potential for inference-time scaling. For the learning method, we propose Self-Principled Critique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs through online RL, to generate principles adaptively and critiques accurately, resulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective inference-time scaling, we use parallel sampling to expand compute usage, and introduce a meta RM to guide voting process for better scaling performance. Empirically, we show that SPCT significantly improves the quality and scalability of GRMs, outperforming existing methods and models in various RM benchmarks without severe biases, and could achieve better performance compared to training-time scaling. DeepSeek-GRM still meets challenges in some tasks, which we believe can be addressed by future efforts in generalist reward systems. The models will be released and open-sourced.', 'abstract_zh': '强化学习（RL）在大规模语言模型（LLMs）训练后应用中已被广泛采用。近期，从RL激励LLMs的推理能力表明，适当的學習方法能够实现有效的推理時�试可扩展性。强化学习的关键挑战是如何在可验证的问题或人工规则之外的各种领域为LLMs获得准确的奖励信号。在本文中，我们研究如何通过增加推理计算来改进奖励建模（RM），即通用查询的奖励建模的推理时测试可扩展性，并进一步探讨如何通过适当的學習方法改进性能计算的扩展效果。在奖励建模方法方面，我们采用点式生成奖励建模（GRM）来实现不同类型输入的灵活性和推理时测试的可扩展性。在学习方法方面，我们提出了自我原则批判调优（SPCT），通过在线RL促进GRM中的可扩展奖励生成行为，以适应性生成原则并准确地提出批判，从而构建出DeepSeek-GRM模型。此外，为了实现高效的推理时测试可扩展性，我们使用并行采样扩展计算使用，引入元级奖励建模以指导投票过程，以获得更好的扩展性能。实验结果表明，SPCT显著提高了GRM的质量和可扩展性，在各种奖励建模基准测试中优于现有方法和模型，且在某些任务中仍能实现更好的性能，这表明了一般奖励系统的未来努力可能会解决这些问题。该模型将被发布和开源。', 'title_zh': '通用奖励建模的推理时缩放方法'}
{'arxiv_id': 'arXiv:2504.02492', 'title': 'Industrial Internet Robot Collaboration System and Edge Computing Optimization', 'authors': 'Qian Zuo, Dajun Tao, Tian Qi, Jieyi Xie, Zijie Zhou, Zhen Tian, Yu Mingyu', 'link': 'https://arxiv.org/abs/2504.02492', 'abstract': "In a complex environment, for a mobile robot to safely and collision - free avoid all obstacles, it poses high requirements for its intelligence level. Given that the information such as the position and geometric characteristics of obstacles is random, the control parameters of the robot, such as velocity and angular velocity, are also prone to random deviations. To address this issue in the framework of the Industrial Internet Robot Collaboration System, this paper proposes a global path control scheme for mobile robots based on deep learning. First of all, the dynamic equation of the mobile robot is established. According to the linear velocity and angular velocity of the mobile robot, its motion behaviors are divided into obstacle - avoidance behavior, target - turning behavior, and target approaching behavior. Subsequently, the neural network method in deep learning is used to build a global path planning model for the robot. On this basis, a fuzzy controller is designed with the help of a fuzzy control algorithm to correct the deviations that occur during path planning, thereby achieving optimized control of the robot's global path. In addition, considering edge computing optimization, the proposed model can process local data at the edge device, reducing the communication burden between the robot and the central server, and improving the real time performance of path planning. The experimental results show that for the mobile robot controlled by the research method in this paper, the deviation distance of the path angle is within 5 cm, the deviation convergence can be completed within 10 ms, and the planned path is shorter. This indicates that the proposed scheme can effectively improve the global path planning ability of mobile robots in the industrial Internet environment and promote the collaborative operation of robots through edge computing optimization.", 'abstract_zh': '基于深度学习的工业互联网移动机器人全局路径控制方案', 'title_zh': '工业互联网机器人协作系统与边缘计算优化'}
{'arxiv_id': 'arXiv:2504.02480', 'title': 'Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging', 'authors': 'Kyungmin Choi, JaKeoung Koo, Stephen McLaughlin, Abderrahim Halimi', 'link': 'https://arxiv.org/abs/2504.02480', 'abstract': 'Single-photon Lidar imaging offers a significant advantage in 3D imaging due to its high resolution and long-range capabilities, however it is challenging to apply in noisy environments with multiple targets per pixel. To tackle these challenges, several methods have been proposed. Statistical methods demonstrate interpretability on the inferred parameters, but they are often limited in their ability to handle complex scenes. Deep learning-based methods have shown superior performance in terms of accuracy and robustness, but they lack interpretability or they are limited to a single-peak per pixel. In this paper, we propose a deep unrolling algorithm for dual-peak single-photon Lidar imaging. We introduce a hierarchical Bayesian model for multiple targets and propose a neural network that unrolls the underlying statistical method. To support multiple targets, we adopt a dual depth maps representation and exploit geometric deep learning to extract features from the point cloud. The proposed method takes advantages of statistical methods and learning-based methods in terms of accuracy and quantifying uncertainty. The experimental results on synthetic and real data demonstrate the competitive performance when compared to existing methods, while also providing uncertainty information.', 'abstract_zh': '单光子LiDAR成像在嘈杂环境下的双峰成像中具有显著优势，但由于目标数量多且像素噪声大，应用挑战较大。为此，已有多种方法被提出。统计方法在推断参数上具有可解释性，但往往难以处理复杂场景。基于深度学习的方法在准确性和鲁棒性上表现出优越性能，但缺乏可解释性或仅限于单峰场景。本文提出了一种用于双峰单光子LiDAR成像的深度拆解算法。我们引入了多层次贝叶斯模型处理多目标问题，并提出了一种神经网络来拆解基础统计方法。通过采用双深度图表示和利用几何深度学习从点云中提取特征，该方法在准确性和不确定性量化方面结合了统计方法和基于学习的方法的优势。实验结果在合成和实际数据上展示了与现有方法相比的竞争性能，并提供了不确定性信息。', 'title_zh': '基于图注意力的贝叶斯深度 unfolding 技术用于双峰单光子激光雷达成像'}
{'arxiv_id': 'arXiv:2504.02479', 'title': 'Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets', 'authors': 'Stefano Covone, Italo Napolitano, Francesco De Lellis, Mario di Bernardo', 'link': 'https://arxiv.org/abs/2504.02479', 'abstract': "We propose a decentralized reinforcement learning solution for multi-agent shepherding of non-cohesive targets using policy-gradient methods. Our architecture integrates target-selection with target-driving through Proximal Policy Optimization, overcoming discrete-action constraints of previous Deep Q-Network approaches and enabling smoother agent trajectories. This model-free framework effectively solves the shepherding problem without prior dynamics knowledge. Experiments demonstrate our method's effectiveness and scalability with increased target numbers and limited sensing capabilities.", 'abstract_zh': '我们提出了一种基于策略梯度方法的去中心化强化学习多-Agent非粘聚目标驱赶解决方案。该架构通过近端策略优化将目标选择与目标引导集成在一起，克服了之前基于Deep Q-Network方法的离散动作限制，使Agent的轨迹更加平滑。该无模型框架在无需先验动力学知识的情况下有效解决了驱赶问题。实验表明，该方法在目标数量增加和传感器能力受限的情况下仍具有有效性和可扩展性。', 'title_zh': '层次化策略梯度强化学习在非凝聚力目标多Agent放牧控制中的应用'}
{'arxiv_id': 'arXiv:2504.02464', 'title': 'CornerPoint3D: Look at the Nearest Corner Instead of the Center', 'authors': 'Ruixiao Zhang, Runwei Guan, Xiangyu Chen, Adam Prugel-Bennett, Xiaohao Cai', 'link': 'https://arxiv.org/abs/2504.02464', 'abstract': "3D object detection aims to predict object centers, dimensions, and rotations from LiDAR point clouds. Despite its simplicity, LiDAR captures only the near side of objects, making center-based detectors prone to poor localization accuracy in cross-domain tasks with varying point distributions. Meanwhile, existing evaluation metrics designed for single-domain assessment also suffer from overfitting due to dataset-specific size variations. A key question arises: Do we really need models to maintain excellent performance in the entire 3D bounding boxes after being applied across domains? Actually, one of our main focuses is on preventing collisions between vehicles and other obstacles, especially in cross-domain scenarios where correctly predicting the sizes is much more difficult. To address these issues, we rethink cross-domain 3D object detection from a practical perspective. We propose two new metrics that evaluate a model's ability to detect objects' closer-surfaces to the LiDAR sensor. Additionally, we introduce EdgeHead, a refinement head that guides models to focus more on learnable closer surfaces, significantly improving cross-domain performance under both our new and traditional BEV/3D metrics. Furthermore, we argue that predicting the nearest corner rather than the object center enhances robustness. We propose a novel 3D object detector, coined as CornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise the learning and detection of the nearest corner of each object. Our proposed methods realize a balanced trade-off between the detection quality of entire bounding boxes and the locating accuracy of closer surfaces to the LiDAR sensor, outperforming the traditional center-based detector CenterPoint in multiple cross-domain tasks and providing a more practically reasonable and robust cross-domain 3D object detection solution.", 'abstract_zh': '基于LiDAR点云的3D物体检测旨在预测物体中心、尺寸和旋转。为了解决这一问题，我们重新审视跨域3D物体检测，并提出两种新的评估指标来评估模型检测物体靠近LiDAR传感器表面的能力。此外，我们引入了EdgeHead，一种引导模型更加关注可学习的靠近表面的 refine头部，显著提高了在我们新提出的和传统BEV/3D指标下的跨域性能。我们还提出了一种新颖的3D物体检测器CornerPoint3D，基于CenterPoint并使用热图来监督每个物体最近角落的检测和学习。我们的方法在保持整个边界框检测质量的同时，提高了靠近LiDAR传感器表面的定位精度，跨域任务中性能优于传统的基于中心的检测器CenterPoint，并提供了一种更实用、更健壮的跨域3D物体检测方案。', 'title_zh': 'CornerPoint3D: 朝最近的角看而不是中心'}
{'arxiv_id': 'arXiv:2504.02463', 'title': 'Evaluating AI Recruitment Sourcing Tools by Human Preference', 'authors': 'Vladimir Slaykovskiy, Maksim Zvegintsev, Yury Sakhonchyk, Hrachik Ajamian', 'link': 'https://arxiv.org/abs/2504.02463', 'abstract': "This study introduces a benchmarking methodology designed to evaluate the performance of AI-driven recruitment sourcing tools. We created and utilized a dataset to perform a comparative analysis of search results generated by leading AI-based solutions, LinkedIn Recruiter, and our proprietary system, this http URL. Human experts assessed the relevance of the returned candidates, and an Elo rating system was applied to quantitatively measure each tool's comparative performance. Our findings indicate that AI-driven recruitment sourcing tools consistently outperform LinkedIn Recruiter in candidate relevance, with this http URL achieving the highest performance scores. Furthermore, we found a strong alignment between AI-based evaluations and human judgments, highlighting the potential for advanced AI technologies to substantially enhance talent acquisition effectiveness. Code and supporting data are publicly available at this https URL", 'abstract_zh': '本研究介绍了一种基准测试方法，用于评估人工智能驱动的招聘 sourcing 工具的性能。我们创建并使用了一个数据集，对领先的人工智能解决方案 LinkedIn Recruiter 和我们自主研发系统 this http URL 生成的搜索结果进行了比较分析。人类专家评估了返回候选人的相关性，并应用 Elo 排名体系定量衡量每种工具的相对性能。研究结果表明，人工智能驱动的招聘 sourcing 工具在候选人相关性方面始终优于 LinkedIn Recruiter，且 this http URL 达到了最高的性能评分。此外，我们发现基于人工智能的评估与人类判断之间存在很强的一致性，突显了先进人工智能技术在显著增强人才获取效果方面的潜力。代码和支持数据可在该链接 https:// 这里 公开获取。', 'title_zh': '基于人类偏好的评估AI招聘 sourcing 工具'}
{'arxiv_id': 'arXiv:2504.02461', 'title': 'Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness', 'authors': 'Juliett Suárez Ferreira, Marija Slavkovik, Jorge Casillas', 'link': 'https://arxiv.org/abs/2504.02461', 'abstract': 'Current fairness metrics and mitigation techniques provide tools for practitioners to asses how non-discriminatory Automatic Decision Making (ADM) systems are. What if I, as an individual facing a decision taken by an ADM system, would like to know: Am I being treated fairly? We explore how to create the affordance for users to be able to ask this question of ADM. In this paper, we argue for the reification of fairness not only as a property of ADM, but also as an epistemic right of an individual to acquire information about the decisions that affect them and use that information to contest and seek effective redress against those decisions, in case they are proven to be discriminatory. We examine key concepts from existing research not only in algorithmic fairness but also in explainable artificial intelligence, accountability, and contestability. Integrating notions from these domains, we propose a conceptual framework to ascertain fairness by combining different tools that empower the end-users of ADM systems. Our framework shifts the focus from technical solutions aimed at practitioners to mechanisms that enable individuals to understand, challenge, and verify the fairness of decisions, and also serves as a blueprint for organizations and policymakers, bridging the gap between technical requirements and practical, user-centered accountability.', 'abstract_zh': '当前公平性指标与缓解技术为实践者提供了评估自动决策系统（ADM）非歧视性的工具。但如果我是面对ADM系统决策的个体，我希望能够知道：我是否得到了公平对待？我们探讨了如何为用户提供能力，使其能够对ADM提出这一问题。在本文中，我们不仅将公平性视为ADM的属性，也将其视为个体获取关于影响自己的决策信息的权利，并利用这些信息质疑和寻求有效救济的权利。我们研究了现有研究中的关键概念，不仅限于算法公平性，还包括可解释的人工智能、问责制和可争议性。结合这些领域中的概念，我们提出了一种概念框架，通过结合不同的工具来增强ADM系统终用户的能力，以确证公平性。该框架将关注点从针对实践者的技术解决方案转移到使个体能够理解、质疑和验证决策公平性的机制上，并为组织和政策制定者提供了蓝本，填补了技术要求与以用户为中心的实际问责制之间的差距。', 'title_zh': '我是否得到了公正的待遇？个人认定公正性的一个概念框架'}
{'arxiv_id': 'arXiv:2504.02458', 'title': 'Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation', 'authors': 'Liangbo Ning, Wenqi Fan, Qing Li', 'link': 'https://arxiv.org/abs/2504.02458', 'abstract': "Recently, Large Language Model (LLM)-empowered recommender systems have revolutionized personalized recommendation frameworks and attracted extensive attention. Despite the remarkable success, existing LLM-empowered RecSys have been demonstrated to be highly vulnerable to minor perturbations. To mitigate the negative impact of such vulnerabilities, one potential solution is to employ collaborative signals based on item-item co-occurrence to purify the malicious collaborative knowledge from the user's historical interactions inserted by attackers. On the other hand, due to the capabilities to expand insufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG) techniques provide unprecedented opportunities to enhance the robustness of LLM-empowered recommender systems by introducing external collaborative knowledge. Therefore, in this paper, we propose a novel framework (RETURN) by retrieving external collaborative signals to purify the poisoned user profiles and enhance the robustness of LLM-empowered RecSys in a plug-and-play manner. Specifically, retrieval-augmented perturbation positioning is proposed to identify potential perturbations within the users' historical sequences by retrieving external knowledge from collaborative item graphs. After that, we further retrieve the collaborative knowledge to cleanse the perturbations by using either deletion or replacement strategies and introduce a robust ensemble recommendation strategy to generate final robust predictions. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed RETURN.", 'abstract_zh': '大型语言模型赋能的推荐系统近年来革命性地革新了个性化推荐框架并吸引了广泛注意。尽管取得了显著成功，现有的大型语言模型赋能的RecSys已被证明对轻微扰动非常脆弱。为了减轻这些脆弱性带来的负面影响，一种潜在的解决方案是利用基于项目共现的合作信号来净化攻击者插入到用户历史交互中的恶意合作知识。另一方面，由于能够扩展大型语言模型内部知识的局限性，检索增强生成（RAG）技术提供了前所未有的机会，通过引入外部合作知识来增强大型语言模型赋能的推荐系统的鲁棒性。因此，在本文中，我们提出了一种新型框架（RETURN），通过检索外部合作信号以插拔式方式净化被毒化的用户配置文件并增强大型语言模型赋能的RecSys的鲁棒性。具体而言，提出了一种检索增强扰动定位方法，通过从合作项目图中检索外部知识来识别用户历史序列中的潜在扰动。然后，我们进一步使用删除或替换策略检索合作知识以净化扰动，并引入一种健壮的集成推荐策略以生成最终的健壮预测。在三个真实世界数据集上的广泛实验表明了所提出RETURN的有效性。', 'title_zh': 'Robust LLM增强的检索增广净化器推荐系统'}
{'arxiv_id': 'arXiv:2504.02450', 'title': 'CHARMS: Cognitive Hierarchical Agent with Reasoning and Motion Styles', 'authors': 'Jingyi Wang, Duanfeng Chu, Zejian Deng, Liping Lu', 'link': 'https://arxiv.org/abs/2504.02450', 'abstract': 'To address the current challenges of low intelligence and simplistic vehicle behavior modeling in autonomous driving simulation scenarios, this paper proposes the Cognitive Hierarchical Agent with Reasoning and Motion Styles (CHARMS). The model can reason about the behavior of other vehicles like a human driver and respond with different decision-making styles, thereby improving the intelligence and diversity of the surrounding vehicles in the driving scenario. By introducing the Level-k behavioral game theory, the paper models the decision-making process of human drivers and employs deep reinforcement learning to train the models with diverse decision styles, simulating different reasoning approaches and behavioral characteristics. Building on the Poisson cognitive hierarchy theory, this paper also presents a novel driving scenario generation method. The method controls the proportion of vehicles with different driving styles in the scenario using Poisson and binomial distributions, thus generating controllable and diverse driving environments. Experimental results demonstrate that CHARMS not only exhibits superior decision-making capabilities as ego vehicles, but also generates more complex and diverse driving scenarios as surrounding vehicles. We will release code for CHARMS at this https URL.', 'abstract_zh': 'Cognitive Hierarchical Agent with Reasoning and Motion Styles (CHARMS): Improving Vehicle Behavior Modeling in Autonomous Driving Simulation Scenarios', 'title_zh': 'CHARMS：认知层次代理及其推理与运动风格'}
{'arxiv_id': 'arXiv:2504.02441', 'title': 'Cognitive Memory in Large Language Models', 'authors': 'Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu', 'link': 'https://arxiv.org/abs/2504.02441', 'abstract': 'This paper examines memory mechanisms in Large Language Models (LLMs), emphasizing their importance for context-rich responses, reduced hallucinations, and improved efficiency. It categorizes memory into sensory, short-term, and long-term, with sensory memory corresponding to input prompts, short-term memory processing immediate context, and long-term memory implemented via external databases or structures. The text-based memory section covers acquisition (selection and summarization), management (updating, accessing, storing, and resolving conflicts), and utilization (full-text search, SQL queries, semantic search). The KV cache-based memory section discusses selection methods (regularity-based summarization, score-based approaches, special token embeddings) and compression techniques (low-rank compression, KV merging, multimodal compression), along with management strategies like offloading and shared attention mechanisms. Parameter-based memory methods (LoRA, TTT, MoE) transform memories into model parameters to enhance efficiency, while hidden-state-based memory approaches (chunk mechanisms, recurrent transformers, Mamba model) improve long-text processing by combining RNN hidden states with current methods. Overall, the paper offers a comprehensive analysis of LLM memory mechanisms, highlighting their significance and future research directions.', 'abstract_zh': '本文探讨了大型语言模型中的记忆机制，强调其对丰富上下文响应、减少幻觉和提高效率的重要性。它将记忆分为感觉记忆、短期记忆和长期记忆，感觉记忆对应于输入提示，短期记忆处理即时上下文，长期记忆通过外部数据库或结构实现。基于文本的记忆部分涵盖了获取（选择和摘要）、管理（更新、访问、存储和冲突解决）以及利用（全文搜索、SQL查询、语义搜索）。基于KV缓存的记忆部分讨论了选择方法（基于规律的摘要、基于评分的方法、特殊标记嵌入）和压缩技术（低秩压缩、KV合并、多模态压缩），以及管理策略，如卸载和共享注意力机制。基于参数的记忆方法（LoRA、TTT、MoE）将记忆转换为模型参数以增强效率，基于隐藏状态的记忆方法（片段机制、递归变压器、Mamba模型）通过结合RNN隐藏状态和当前方法来改进长文本处理。总体而言，本文对大型语言模型的记忆机制进行了全面分析，突出了它们的重要性及其未来的研究方向。', 'title_zh': '大型语言模型中的认知记忆'}
{'arxiv_id': 'arXiv:2504.02438', 'title': 'Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation', 'authors': 'Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan', 'link': 'https://arxiv.org/abs/2504.02438', 'abstract': "Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice critical temporal dependencies or dilute semantic information. We introduce differential distillation, a principled approach that systematically preserves task-relevant information while suppressing redundancy. Based on this principle, we develop ViLaMP, a hierarchical video-language model that processes hour-long videos at ``mixed precision'' through two key mechanisms: (1) differential keyframe selection that maximizes query relevance while maintaining temporal distinctiveness at the frame level and (2) differential feature merging that preserves query-salient features in non-keyframes at the patch level. Hence, ViLaMP retains full information in keyframes while reducing non-keyframes to their most salient features, resembling mixed-precision training. Extensive experiments demonstrate ViLaMP's superior performance across four video understanding benchmarks, particularly on long-form content. Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a single NVIDIA A100 GPU, achieving substantial computational efficiency while maintaining state-of-the-art performance.", 'abstract_zh': '长期视频处理从根本上对视觉语言模型（VLMs）构成了挑战，因为处理延长的时间序列需付出高昂的计算成本。现有的标记修剪和特征合并方法往往牺牲了关键的时间依赖性或稀释了语义信息。我们引入了差异性蒸馏，这是一种系统地保留与任务相关的信息并抑制冗余的原理性方法。在此基础上，我们开发了ViLaMP，这是一种分层视频语言模型，通过两种关键机制以“混合精度”处理长达一个小时的视频：（1）差异性关键帧选择，该机制在保持帧级时间独特性的同时最大化查询相关性；（2）差异性特征合并，在块级层面保留与查询相关的显著特征。因此，ViLaMP 在关键帧中保留完整信息，同时将非关键帧缩减为其最显著的特征，类似于混合精度训练。广泛实验证明了ViLaMP在四个视频理解基准测试中的优越性能，特别是在长视频内容上。值得注意的是，ViLaMP可以在单个NVIDIA A100 GPU上处理超长视频（多达10K帧），实现了显著的计算效率同时保持了最先进的性能。', 'title_zh': '将视频语言模型扩展到10K帧 via 分层差别性蒸馏'}
{'arxiv_id': 'arXiv:2504.02417', 'title': 'Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing in Video Question Answering', 'authors': 'Lili Liang, Guanglu Sun', 'link': 'https://arxiv.org/abs/2504.02417', 'abstract': 'Video Question Answering (VideoQA) is an important research direction in the field of artificial intelligence, enabling machines to understand video content and perform reasoning and answering based on natural language questions. Although methods based on static relationship reasoning have made certain progress, there are still deficiencies in the accuracy of static relationship recognition and representation, and they have not fully utilized the static relationship information in videos for in-depth reasoning and analysis. Therefore, this paper proposes a reasoning method for intra-type and inter-type message passing based on static relationships. This method constructs a dual graph for intra-type message passing reasoning and builds a heterogeneous graph based on static relationships for inter-type message passing reasoning. The intra-type message passing reasoning model captures the neighborhood information of targets and relationships related to the question in the dual graph, updating the dual graph to obtain intra-type clues for answering the question. The inter-type message passing reasoning model captures the neighborhood information of targets and relationships from different categories related to the question in the heterogeneous graph, updating the heterogeneous graph to obtain inter-type clues for answering the question. Finally, the answers are inferred by combining the intra-type and inter-type clues based on static relationships. Experimental results on the ANetQA and Next-QA datasets demonstrate the effectiveness of this method.', 'abstract_zh': '基于静态关系的同类型与异类型消息传递推理方法', 'title_zh': '利用静态关系进行同类型和跨类型消息传递的视频问答'}
{'arxiv_id': 'arXiv:2504.02408', 'title': 'Translation of Fetal Brain Ultrasound Images into Pseudo-MRI Images using Artificial Intelligence', 'authors': 'Naomi Silverstein, Efrat Leibowitz, Ron Beloosesky, Haim Azhari', 'link': 'https://arxiv.org/abs/2504.02408', 'abstract': 'Ultrasound is a widely accessible and cost-effective medical imaging tool commonly used for prenatal evaluation of the fetal brain. However, it has limitations, particularly in the third trimester, where the complexity of the fetal brain requires high image quality for extracting quantitative data. In contrast, magnetic resonance imaging (MRI) offers superior image quality and tissue differentiation but is less available, expensive, and requires time-consuming acquisition. Thus, transforming ultrasonic images into an MRI-mimicking display may be advantageous and allow better tissue anatomy presentation. To address this goal, we have examined the use of artificial intelligence, implementing a diffusion model renowned for generating high-quality images. The proposed method, termed "Dual Diffusion Imposed Correlation" (DDIC), leverages a diffusion-based translation methodology, assuming a shared latent space between ultrasound and MRI domains. Model training was obtained utilizing the "HC18" dataset for ultrasound and the "CRL fetal brain atlas" along with the "FeTA " datasets for MRI. The generated pseudo-MRI images provide notable improvements in visual discrimination of brain tissue, especially in the lateral ventricles and the Sylvian fissure, characterized by enhanced contrast clarity. Improvement was demonstrated in Mutual information, Peak signal-to-noise ratio, Fréchet Inception Distance, and Contrast-to-noise ratio. Findings from these evaluations indicate statistically significant superior performance of the DDIC compared to other translation methodologies. In addition, a Medical Opinion Test was obtained from 5 gynecologists. The results demonstrated display improvement in 81% of the tested images. In conclusion, the presented pseudo-MRI images hold the potential for streamlining diagnosis and enhancing clinical outcomes through improved representation.', 'abstract_zh': '超声是一种广泛 доступ且经济有效的医疗成像工具，常用于胎儿脑部的产前评估。然而，它在第三孕期存在局限性，因为胎儿脑部的复杂性要求高质量图像以提取定量数据。相比之下，磁共振成像（MRI）提供卓越的图像质量和组织区分度，但其可用性较低、成本较高且成像耗时。因此，将超声图像转换为MRI模拟显示可能具有优势，并允许更好的组织解剖学呈现。为了达成这一目标，我们考察了人工智能的应用，采用了一种以生成高质量图像闻名的扩散模型。所提出的方法名为“双扩散施加相关性”（DDIC），利用基于扩散的转换方法，假设超声和MRI领域共享一个潜在空间。模型培训使用了“HC18”超声数据集、“CRL胎儿脑部图谱”以及“FeTA”MRI数据集。生成的伪MRI图像在视觉区分脑组织方面提供了显著改进，特别是在侧脑室和顶枕裂区域，显示出增强的对比清晰度。通过互信息、峰值信噪比、弗雷切特-因斯坎距离和对比度-噪声比等指标的不同提高，这些评估结果表明，DDIC相比其他转换方法具有统计学显著的优越性能。此外，从5位妇产科医生那里得到了医学意见测试结果。结果显示，在测试图像中有81%的图像显示了显示改进。综上所述，提出的伪MRI图像通过改进表示具有简化诊断和增强临床结果的潜力。', 'title_zh': '使用人工智能将胎儿脑超声图像转换为伪 MRI 图像'}
{'arxiv_id': 'arXiv:2504.02402', 'title': 'EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling', 'authors': 'Hao Yin, Shi Guo, Xu Jia, Xudong XU, Lu Zhang, Si Liu, Dong Wang, Huchuan Lu, Tianfan Xue', 'link': 'https://arxiv.org/abs/2504.02402', 'abstract': 'When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advances in event camera hardware show good potential for its application in visual sound recovery, because of its superior ability in capturing high-frequency signals. However, existing event-based vibration recovery methods are still sub-optimal for sound recovery. In this work, we propose a novel pipeline for non-contact sound recovery, fully utilizing spatial-temporal information from the event stream. We first generate a large training set using a novel simulation pipeline. Then we designed a network that leverages the sparsity of events to capture spatial information and uses Mamba to model long-term temporal information. Lastly, we train a spatial aggregation block to aggregate information from different locations to further improve signal quality. To capture event signals caused by sound waves, we also designed an imaging system using a laser matrix to enhance the gradient and collected multiple data sequences for testing. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method.', 'abstract_zh': '非接触声波恢复的时空信息利用新pipeline及其应用研究', 'title_zh': '基于事件的空间-时间模型的有效非接触声音恢复'}
{'arxiv_id': 'arXiv:2504.02388', 'title': 'Steiner Traveling Salesman Problem with Quantum Annealing', 'authors': 'Alessia Ciacco, Francesca Guerriero, Eneko Osaba', 'link': 'https://arxiv.org/abs/2504.02388', 'abstract': "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical Traveling Salesman Problem. The STSP involves incorporating steiner nodes, which are extra nodes not originally part of the required visit set but that can be added to the route to enhance the overall solution and minimize the total travel cost. Given the NP-hard nature of the STSP, we propose a quantum approach to address it. Specifically, we employ quantum annealing using D-Wave's hardware to explore its potential for solving this problem. To enhance computational feasibility, we develop a preprocessing method that effectively reduces the network size. Our experimental results demonstrate that this reduction technique significantly decreases the problem complexity, making the Quadratic Unconstrained Binary Optimization formulation, the standard input for quantum annealers, better suited for existing quantum hardware. Furthermore, the results highlight the potential of quantum annealing as a promising and innovative approach for solving the STSP.", 'abstract_zh': 'Steiner旅行售货商问题的量子方法研究', 'title_zh': '量子退火求解Steiner旅行商问题'}
{'arxiv_id': 'arXiv:2504.02382', 'title': 'Benchmark of Segmentation Techniques for Pelvic Fracture in CT and X-ray: Summary of the PENGWIN 2024 Challenge', 'authors': 'Yudi Sang, Yanzhen Liu, Sutuke Yibulayimu, Yunning Wang, Benjamin D. Killeen, Mingxu Liu, Ping-Cheng Ku, Ole Johannsen, Karol Gotkowski, Maximilian Zenk, Klaus Maier-Hein, Fabian Isensee, Peiyan Yue, Yi Wang, Haidong Yu, Zhaohong Pan, Yutong He, Xiaokun Liang, Daiqi Liu, Fuxin Fan, Artur Jurgas, Andrzej Skalski, Yuxi Ma, Jing Yang, Szymon Płotka, Rafał Litka, Gang Zhu, Yingchun Song, Mathias Unberath, Mehran Armand, Dan Ruan, S. Kevin Zhou, Qiyong Cao, Chunpeng Zhao, Xinbao Wu, Yu Wang', 'link': 'https://arxiv.org/abs/2504.02382', 'abstract': 'The segmentation of pelvic fracture fragments in CT and X-ray images is crucial for trauma diagnosis, surgical planning, and intraoperative guidance. However, accurately and efficiently delineating the bone fragments remains a significant challenge due to complex anatomy and imaging limitations. The PENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance automated fracture segmentation by benchmarking state-of-the-art algorithms on these complex tasks. A diverse dataset of 150 CT scans was collected from multiple clinical centers, and a large set of simulated X-ray images was generated using the DeepDRR method. Final submissions from 16 teams worldwide were evaluated under a rigorous multi-metric testing scheme. The top-performing CT algorithm achieved an average fragment-wise intersection over union (IoU) of 0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the best algorithm attained an IoU of 0.774, highlighting the greater challenges posed by overlapping anatomical structures. Beyond the quantitative evaluation, the challenge revealed methodological diversity in algorithm design. Variations in instance representation, such as primary-secondary classification versus boundary-core separation, led to differing segmentation strategies. Despite promising results, the challenge also exposed inherent uncertainties in fragment definition, particularly in cases of incomplete fractures. These findings suggest that interactive segmentation approaches, integrating human decision-making with task-relevant information, may be essential for improving model reliability and clinical applicability.', 'abstract_zh': '盆腔骨折碎片在CT和X光图像中的分割对于创伤诊断、手术计划和术中指导至关重要。然而，由于复杂的解剖结构和成像限制，准确而高效地 delineate 骨折碎片仍是一项重大挑战。PENGWIN 挑战赛作为 MICCAI 2024 的卫星事件，旨在通过基准测试最先进的算法来推进自动化骨折分割技术。来自多个临床中心的150份CT扫描图像和大量使用DeepDRR方法生成的模拟X光图像被收集。来自全球的16支队伍的最终提交结果在严格的多指标测试方案下进行了评估。最佳CT算法的平均片段级交并比（IoU）为0.930，显示出较高的准确性。然而，在X光任务中，最佳算法的IoU仅为0.774，突显了重叠解剖结构带来的更大挑战。除了定量评估外，该挑战还揭示了算法设计中的方法多样性。实例表示的差异，如主要-次要分类与边界-核心分离，导致了不同的分割策略。尽管取得了一定的成果，挑战也揭示了碎片定义中固有的不确定性，尤其是在不完全骨折的情况下。这些发现表明，结合人类决策与任务相关信息的交互式分割方法可能对于提高模型可靠性和临床适用性至关重要。', 'title_zh': '盆腔骨折在CT和X射线分割技术基准：PENGWIN 2024挑战赛总结'}
{'arxiv_id': 'arXiv:2504.02351', 'title': 'Agglomerating Large Vision Encoders via Distillation for VFSS Segmentation', 'authors': 'Chengxi Zeng, Yuxuan Jiang, Fan Zhang, Alberto Gambaruto, Tilo Burghardt', 'link': 'https://arxiv.org/abs/2504.02351', 'abstract': 'The deployment of foundation models for medical imaging has demonstrated considerable success. However, their training overheads associated with downstream tasks remain substantial due to the size of the image encoders employed, and the inference complexity is also significantly high. Although lightweight variants have been obtained for these foundation models, their performance is constrained by their limited model capacity and suboptimal training strategies. In order to achieve an improved tradeoff between complexity and performance, we propose a new framework to improve the performance of low complexity models via knowledge distillation from multiple large medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each specializing in different vision tasks, with the goal to effectively bridge the performance gap for medical image segmentation tasks. The agglomerated model demonstrates superior generalization across 12 segmentation tasks, whereas specialized models require explicit training for each task. Our approach achieved an average performance gain of 2\\% in Dice coefficient compared to simple distillation.', 'abstract_zh': '基础模型在医疗成像中的部署取得了显著成功，但由于所使用图像编码器的规模庞大，其下游任务的训练开销仍然很大，推理复杂性也很高。尽管已经获得了轻量级变体，但它们的性能受限于模型容量有限和训练策略欠优化。为了在复杂性和性能之间实现改进的权衡，我们提出了一种新框架，通过从多个大型医疗基础模型（例如，MedSAM、RAD-DINO、MedCLIP）知识蒸馏，每个模型专注于不同的视觉任务，以有效填补医学图像分割任务的性能差距。聚合模型在12项分割任务中展示了优于专门模型的泛化能力。我们的方法在骰子系数上实现了平均2%的性能提升，相比于简单的知识蒸馏。', 'title_zh': '通过蒸馏聚合大规模视觉编码器进行VFSS分割'}
{'arxiv_id': 'arXiv:2504.02317', 'title': 'Temporal Gaussian Copula For Clinical Multivariate Time Series Data Imputation', 'authors': 'Ye Su, Hezhe Qiao, Di Wu, Yuwen Chen, Lin Chen', 'link': 'https://arxiv.org/abs/2504.02317', 'abstract': 'The imputation of the Multivariate time series (MTS) is particularly challenging since the MTS typically contains irregular patterns of missing values due to various factors such as instrument failures, interference from irrelevant data, and privacy regulations. Existing statistical methods and deep learning methods have shown promising results in time series imputation. In this paper, we propose a Temporal Gaussian Copula Model (TGC) for three-order MTS imputation. The key idea is to leverage the Gaussian Copula to explore the cross-variable and temporal relationships based on the latent Gaussian representation. Subsequently, we employ an Expectation-Maximization (EM) algorithm to improve robustness in managing data with varying missing rates. Comprehensive experiments were conducted on three real-world MTS datasets. The results demonstrate that our TGC substantially outperforms the state-of-the-art imputation methods. Additionally, the TGC model exhibits stronger robustness to the varying missing ratios in the test dataset. Our code is available at this https URL.', 'abstract_zh': '多变量时间序列的插值（MTS）由于受到各种因素如仪器故障、无关数据干扰和隐私规定的影响，通常包含不规则的缺失值模式，这使其特别具有挑战性。现有的统计方法和深度学习方法在时间序列插值方面已经显示出有希望的结果。本文提出了一种用于三阶多变量时间序列插值的临时高斯 copula 模型（TGC）。关键思想是利用高斯 copula 基于潜在高斯表示来探索跨变量和 temporal 关系。随后，我们采用期望最大（EM）算法以增强在处理不同缺失率数据时的稳健性。我们在三个真实世界的多变量时间序列数据集上进行了全面实验。结果表明，我们的 TGC 显著优于当前最先进的插值方法。此外，TGC 模型对测试数据集中变异缺失比例的鲁棒性更强。我们的代码可在此处获取。', 'title_zh': '基于时间的高斯copula临床多变量时间序列数据 imputation'}
{'arxiv_id': 'arXiv:2504.02316', 'title': 'ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation', 'authors': 'Yuan Zhou, Shilong Jin, Litao Hua, Wanjun Lv, Haoran Duan, Jungong Han', 'link': 'https://arxiv.org/abs/2504.02316', 'abstract': 'Recent advances in zero-shot text-to-3D generation have revolutionized 3D content creation by enabling direct synthesis from textual descriptions. While state-of-the-art methods leverage 3D Gaussian Splatting with score distillation to enhance multi-view rendering through pre-trained text-to-image (T2I) models, they suffer from inherent view biases in T2I priors. These biases lead to inconsistent 3D generation, particularly manifesting as the multi-face Janus problem, where objects exhibit conflicting features across views. To address this fundamental challenge, we propose ConsDreamer, a novel framework that mitigates view bias by refining both the conditional and unconditional terms in the score distillation process: (1) a View Disentanglement Module (VDM) that eliminates viewpoint biases in conditional prompts by decoupling irrelevant view components and injecting precise camera parameters; and (2) a similarity-based partial order loss that enforces geometric consistency in the unconditional term by aligning cosine similarities with azimuth relationships. Extensive experiments demonstrate that ConsDreamer effectively mitigates the multi-face Janus problem in text-to-3D generation, outperforming existing methods in both visual quality and consistency.', 'abstract_zh': '最近零样本文本到3D生成的进展通过直接从文本描述合成3D内容已 revolutionized 3D内容创作。尽管最先进的方法利用预训练的文本到图像（T2I）模型的3D高斯散射和评分精炼增强多视角渲染，但它们会因T2I先验中的固有视角偏见而受到限制。这些偏见导致3D生成不一致，特别是在视角矛盾问题上表现明显，即对象在不同视角中展现矛盾特征。为解决这一根本性挑战，我们提出了一种名为ConsDreamer的新框架，通过在评分精炼过程中精炼条件性和无条件性项来减轻视角偏见：（1）视角解耦模块（VDM），通过解除无关视角组件和注入精确的相机参数来消除条件提示中的视角偏见；以及（2）基于相似性的部分有序损失，通过与方位关系对余弦相似性进行对齐来强化无条件项中的几何一致性。广泛实验表明，ConsDreamer在视觉质量和一致性方面有效缓解了文本到3D生成中的多面Janus问题，优于现有方法。', 'title_zh': 'ConsDreamer: 提升零样本文本到3D生成的多视角一致性'}
{'arxiv_id': 'arXiv:2504.02312', 'title': 'OmniCam: Unified Multimodal Video Generation via Camera Control', 'authors': 'Xiaoda Yang, Jiayang Xu, Kaixuan Luan, Xinyu Zhan, Hongshun Qiu, Shijun Shi, Hao Li, Shuai Yang, Li Zhang, Checheng Yu, Cewu Lu, Lixin Yang', 'link': 'https://arxiv.org/abs/2504.02312', 'abstract': 'Camera control, which achieves diverse visual effects by changing camera position and pose, has attracted widespread attention. However, existing methods face challenges such as complex interaction and limited control capabilities. To address these issues, we present OmniCam, a unified multimodal camera control framework. Leveraging large language models and video diffusion models, OmniCam generates spatio-temporally consistent videos. It supports various combinations of input modalities: the user can provide text or video with expected trajectory as camera path guidance, and image or video as content reference, enabling precise control over camera motion. To facilitate the training of OmniCam, we introduce the OmniTr dataset, which contains a large collection of high-quality long-sequence trajectories, videos, and corresponding descriptions. Experimental results demonstrate that our model achieves state-of-the-art performance in high-quality camera-controlled video generation across various metrics.', 'abstract_zh': '相机控制：一种通过改变相机位置和姿态实现多样视觉效果的统一多模态相机控制框架', 'title_zh': 'OmniCam：通过摄像头控制实现统一多模态视频生成'}
{'arxiv_id': 'arXiv:2504.02293', 'title': 'State-of-the-Art Translation of Text-to-Gloss using mBART : A case study of Bangla', 'authors': 'Sharif Md. Abdullah, Abhijit Paul, Shebuti Rayana, Ahmedul Kabir, Zarif Masud', 'link': 'https://arxiv.org/abs/2504.02293', 'abstract': 'Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language (BdSL) remains a understudied domain. Specifically, there are no works on Bangla text-to-gloss translation task. To address this gap, we begin by addressing the dataset problem. We take inspiration from grammatical rule based gloss generation used in Germany and American sign langauage (ASL) and adapt it for BdSL. We also leverage LLM to generate synthetic data and use back-translation, text generation for data augmentation. With dataset prepared, we started experimentation. We fine-tuned pretrained mBART-50 and mBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a novel seq-to-seq model with multi-head attention. We observe significant high performance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual model from Facebook. We then explored why we observe such high performance with mBART. We soon notice an interesting property of mBART -- it was trained on shuffled and masked text data. And as we know, gloss form has shuffling property. So we hypothesize that mBART is inherently good at text-to-gloss tasks. To find support against this hypothesis, we trained mBART-50 on PHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50 finetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark, far outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 = 55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on the results, this study proposes a new paradigm for text-to-gloss task using mBART models. Additionally, our results show that BdSL text-to-gloss task can greatly benefit from rule-based synthetic dataset.', 'abstract_zh': '尽管有170万聋哑人口，孟加拉手语（BdSL）仍是一个未被充分研究的领域。具体而言，目前没有关于孟加拉文本到手笨词翻译任务的研究。为填补这一空白，我们首先解决了数据集问题。我们借鉴了德国和美国手语（ASL）基于语法规则的手笨词生成方法，并将其适应到BdSL。我们还利用大语言模型生成合成数据，并通过反向翻译和文本生成进行数据增强。数据集准备完成后，我们开始了实验。我们对Facebook的预训练mBART-50和mBERT-multiclass-uncased模型进行了微调，并训练了GRU、RNN和一种新型的带有多头注意力机制的序列到序列模型。我们观察到显著的高性能（ScareBLEU=79.53）来自预训练mBART-50多语言模型的微调。为了进一步探索为什么mBART表现出如此高的性能，我们注意到一个有趣的现象：mBART是在打乱和掩盖的文本数据上进行训练的。而我们知道，手笨词形式具有打乱属性。因此，我们推测mBART本就擅长文本到手笨词任务。为了验证这一假设，我们在PHOENIX-14T基准数据集上训练了mBART-50，并用现有文献进行了评估。我们的mBART-50微调在PHOENIX-14T基准数据集上表现出SOTA性能，在所有6项指标上都远超现有模型（ScareBLEU = 63.89，BLEU-1 = 55.14，BLEU-2 = 38.07，BLEU-3 = 27.13，BLEU-4 = 20.68，COMET = 0.624）。基于这些结果，这项研究提出了一种新的基于mBART模型的文本到手笨词任务范式。此外，我们的研究表明，基于规则生成的数据集可以显著提升BdSL文本到手笨词任务的表现。', 'title_zh': '基于mBART的文本到手语翻译：孟加拉语案例研究'}
{'arxiv_id': 'arXiv:2504.02285', 'title': 'Tree-based Models for Vertical Federated Learning: A Survey', 'authors': 'Bingchen Qian, Yuexiang Xie, Yaliang Li, Bolin Ding, Jingren Zhou', 'link': 'https://arxiv.org/abs/2504.02285', 'abstract': 'Tree-based models have achieved great success in a wide range of real-world applications due to their effectiveness, robustness, and interpretability, which inspired people to apply them in vertical federated learning (VFL) scenarios in recent years. In this paper, we conduct a comprehensive study to give an overall picture of applying tree-based models in VFL, from the perspective of their communication and computation protocols. We categorize tree-based models in VFL into two types, i.e., feature-gathering models and label-scattering models, and provide a detailed discussion regarding their characteristics, advantages, privacy protection mechanisms, and applications. This study also focuses on the implementation of tree-based models in VFL, summarizing several design principles for better satisfying various requirements from both academic research and industrial deployment. We conduct a series of experiments to provide empirical observations on the differences and advances of different types of tree-based models.', 'abstract_zh': '基于树的模型在垂直联邦学习中的应用：从通信和计算协议视角的综合研究', 'title_zh': '基于树的模型在垂直联邦学习中的研究综述'}
{'arxiv_id': 'arXiv:2504.02277', 'title': 'Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation', 'authors': 'Amit Rand, Hadi Ibrahim', 'link': 'https://arxiv.org/abs/2504.02277', 'abstract': "Medical imaging, particularly X-ray analysis, often involves detecting multiple conditions simultaneously within a single scan, making multi-label classification crucial for real-world clinical applications. We present the Medical X-ray Attention (MXA) block, a novel attention mechanism tailored specifically to address the unique challenges of X-ray abnormality detection. The MXA block enhances traditional Multi-Head Self Attention (MHSA) by integrating a specialized module that efficiently captures both detailed local information and broader global context. To the best of our knowledge, this is the first work to propose a task-specific attention mechanism for diagnosing chest X-rays, as well as to attempt multi-label classification using an Efficient Vision Transformer (EfficientViT). By embedding the MXA block within the EfficientViT architecture and employing knowledge distillation, our proposed model significantly improves performance on the CheXpert dataset, a widely used benchmark for multi-label chest X-ray abnormality detection. Our approach achieves an area under the curve (AUC) of 0.85, an absolute improvement of 0.19 compared to our baseline model's AUC of 0.66, corresponding to a substantial approximate 233% relative improvement over random guessing (AUC = 0.5).", 'abstract_zh': '医学成像，尤其是X射线分析，往往需要在单次扫描中同时检测多种情况，因此多标签分类对于实际临床应用至关重要。我们提出了医学X射线注意力（MXA）模块，这是一种专门针对X射线异常检测的独特挑战而设计的新型注意力机制。MXA模块通过整合一个专门模块来增强传统的多头自注意力（MHSA），该模块能够高效地捕捉详细的局部信息和更广泛的全局上下文。据我们所知，这是首次提出针对胸部X射线诊断的任务特定注意力机制，并尝试使用高效视觉变压器（EfficientViT）进行多标签分类。通过在EfficientViT架构中嵌入MXA模块并使用知识蒸馏，我们提出的方法在CheXpert数据集上的表现显著提升，CheXpert数据集是广泛使用的多标签胸部X射线异常检测基准。我们的方法在曲线下面积（AUC）上达到0.85，相比基线模型的AUC（0.66）绝对提升了0.19，相当于随机猜测（AUC=0.5）约233%的相对改善。', 'title_zh': '超越传统变压器：基于医学X射线注意力（MXA）块的知识蒸馏多标签诊断改进方法'}
{'arxiv_id': 'arXiv:2504.02260', 'title': 'Implicit Neural Differential Model for Spatiotemporal Dynamics', 'authors': 'Deepak Akhare, Pan Du, Tengfei Luo, Jian-Xun Wang', 'link': 'https://arxiv.org/abs/2504.02260', 'abstract': "Hybrid neural-physics modeling frameworks through differentiable programming have emerged as powerful tools in scientific machine learning, enabling the integration of known physics with data-driven learning to improve prediction accuracy and generalizability. However, most existing hybrid frameworks rely on explicit recurrent formulations, which suffer from numerical instability and error accumulation during long-horizon forecasting. In this work, we introduce Im-PiNDiff, a novel implicit physics-integrated neural differentiable solver for stable and accurate modeling of spatiotemporal dynamics. Inspired by deep equilibrium models, Im-PiNDiff advances the state using implicit fixed-point layers, enabling robust long-term simulation while remaining fully end-to-end differentiable. To enable scalable training, we introduce a hybrid gradient propagation strategy that integrates adjoint-state methods with reverse-mode automatic differentiation. This approach eliminates the need to store intermediate solver states and decouples memory complexity from the number of solver iterations, significantly reducing training overhead. We further incorporate checkpointing techniques to manage memory in long-horizon rollouts. Numerical experiments on various spatiotemporal PDE systems, including advection-diffusion processes, Burgers' dynamics, and multi-physics chemical vapor infiltration processes, demonstrate that Im-PiNDiff achieves superior predictive performance, enhanced numerical stability, and substantial reductions in memory and runtime cost relative to explicit and naive implicit baselines. This work provides a principled, efficient, and scalable framework for hybrid neural-physics modeling.", 'abstract_zh': '基于可微编程的隐式物理集成神经计算框架：稳定且准确的空间时间动态建模', 'title_zh': '时空动态的隐式神经微分模型'}
{'arxiv_id': 'arXiv:2504.02254', 'title': 'LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks', 'authors': 'Seunghyun Yoo', 'link': 'https://arxiv.org/abs/2504.02254', 'abstract': 'Recent advancements in Large Language Models (LLMs) have not only showcased impressive creative capabilities but also revealed emerging agentic behaviors that exploit linguistic ambiguity in adversarial settings. In this study, we investigate how an LLM, acting as an autonomous agent, leverages semantic ambiguity to generate deceptive puzzles that mislead and challenge human users. Inspired by the popular puzzle game "Connections", we systematically compare puzzles produced through zero-shot prompting, role-injected adversarial prompts, and human-crafted examples, with an emphasis on understanding the underlying agent decision-making processes. Employing computational analyses with HateBERT to quantify semantic ambiguity, alongside subjective human evaluations, we demonstrate that explicit adversarial agent behaviors significantly heighten semantic ambiguity -- thereby increasing cognitive load and reducing fairness in puzzle solving. These findings provide critical insights into the emergent agentic qualities of LLMs and underscore important ethical considerations for evaluating and safely deploying autonomous language systems in both educational technologies and entertainment.', 'abstract_zh': '最近在大型语言模型（LLMs）方面的进展不仅展示了其令人印象深刻的创造力，还揭示了其利用语义模糊在对抗性环境中展现出的新兴代理行为。本研究探讨了一个作为自主代理的LLM如何利用语义模糊生成误导性和挑战性极强的谜题，误导和挑战人类用户。受到流行谜题游戏“连接”（Connections）的启发，我们系统地比较了通过零样本提示、角色注入对抗性提示以及人工制作的示例生成的谜题，重点在于理解底层代理决策过程。利用HateBERT进行计算分析以量化语义模糊，并结合主观的人类评估，我们证明了明确的对抗性代理行为显著增加了语义模糊度——从而增加了解谜的认知负担并降低了公平性。这些发现为了解LLMs的 emergent 代理品质提供了关键性见解，并强调了在教育技术和娱乐领域评估和安全部署自主语言系统时重要的伦理考虑。', 'title_zh': 'LLMs作为欺骗性代理：基于角色的提示如何在谜题任务中诱导语义 ambiguity'}
{'arxiv_id': 'arXiv:2504.02252', 'title': 'Adapting World Models with Latent-State Dynamics Residuals', 'authors': 'JB Lanier, Kyungmin Kim, Armin Karamzade, Yifei Liu, Ankita Sinha, Kat He, Davide Corsi, Roy Fox', 'link': 'https://arxiv.org/abs/2504.02252', 'abstract': 'Simulation-to-reality reinforcement learning (RL) faces the critical challenge of reconciling discrepancies between simulated and real-world dynamics, which can severely degrade agent performance. A promising approach involves learning corrections to simulator forward dynamics represented as a residual error function, however this operation is impractical with high-dimensional states such as images. To overcome this, we propose ReDRAW, a latent-state autoregressive world model pretrained in simulation and calibrated to target environments through residual corrections of latent-state dynamics rather than of explicit observed states. Using this adapted world model, ReDRAW enables RL agents to be optimized with imagined rollouts under corrected dynamics and then deployed in the real world. In multiple vision-based MuJoCo domains and a physical robot visual lane-following task, ReDRAW effectively models changes to dynamics and avoids overfitting in low data regimes where traditional transfer methods fail.', 'abstract_zh': '模拟到现实的强化学习（RL）面临着 reconciling 虚拟环境和真实世界动力学差异的关键挑战，这可能导致代理性能严重下降。一种有前景的方法是学习修正仿真的前向动力学，这种修正以残差误差函数的形式表示，然而当状态维度高，如图像时，这种操作是不切实际的。为克服这一问题，我们提出了一种名为 ReDRAW 的潜在状态自回归世界模型，在仿真中预先训练，并通过潜在状态动力学的残差修正而非显式观测状态的修正来对准目标环境。利用这种适应的世界模型，ReDRAW 可以使 RL 代理在修正后的动力学下进行想象中的 rollout 优化，并部署到现实世界中。在多个基于视觉的 MuJoCo 领域和一个物理机器人视觉车道跟随任务中，ReDRAW 有效地模型化了动力学的变化，并在传统迁移方法失败的数据稀少情况下避免了过拟合。', 'title_zh': '使用潜在状态动力学残差适应世界模型'}
{'arxiv_id': 'arXiv:2504.02234', 'title': 'LLM Social Simulations Are a Promising Research Method', 'authors': 'Jacy Reese Anthis, Ryan Liu, Sean M. Richardson, Austin C. Kozlowski, Bernard Koch, James Evans, Erik Brynjolfsson, Michael Bernstein', 'link': 'https://arxiv.org/abs/2504.02234', 'abstract': 'Accurate and verifiable large language model (LLM) simulations of human research subjects promise an accessible data source for understanding human behavior and training new AI systems. However, results to date have been limited, and few social scientists have adopted these methods. In this position paper, we argue that the promise of LLM social simulations can be achieved by addressing five tractable challenges. We ground our argument in a literature survey of empirical comparisons between LLMs and human research subjects, commentaries on the topic, and related work. We identify promising directions with prompting, fine-tuning, and complementary methods. We believe that LLM social simulations can already be used for exploratory research, such as pilot experiments for psychology, economics, sociology, and marketing. More widespread use may soon be possible with rapidly advancing LLM capabilities, and researchers should prioritize developing conceptual models and evaluations that can be iteratively deployed and refined at pace with ongoing AI advances.', 'abstract_zh': '准确可验证的大语言模型（LLM）模拟人类研究主体有望提供一个了解人类行为和培训新AI系统的可访问数据源。然而，目前的结果有限，很少有社会科学家采用这些方法。在本文中，我们认为通过解决五个可处理的挑战，可以实现LLM社会模拟的潜力。我们基于对LLM与人类研究主体之间实证比较的文献综述、主题评论和相关工作的分析，提出论点。我们指出了通过提示、微调和互补方法的有前途的方向。我们认为，LLM社会模拟已经在探索性研究中得到应用，如心理学、经济学、社会学和市场营销的试点实验。随着LLM能力的迅猛发展，更广泛的使用可能很快成为可能，并且研究人员应优先开发可以与持续的AI进步同步迭代部署和优化的概念模型和评估方法。', 'title_zh': 'LLM社会模拟是一种有前景的研究方法'}
{'arxiv_id': 'arXiv:2504.02231', 'title': 'AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image Generation', 'authors': 'Zhipu Cui, Andong Tian, Zhi Ying, Jialiang Lu', 'link': 'https://arxiv.org/abs/2504.02231', 'abstract': 'Personalized image generation allows users to preserve styles or subjects of a provided small set of images for further image generation. With the advancement in large text-to-image models, many techniques have been developed to efficiently fine-tune those models for personalization, such as Low Rank Adaptation (LoRA). However, LoRA-based methods often face the challenge of adjusting the rank parameter to achieve satisfactory results. To address this challenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to automatically separate the signal component and noise component of the LoRA matrices for fast and efficient personalized artistic style image generation. This method is based on Singular Value Decomposition (SVD) and dynamic heuristics to update the hyperparameters during training. Superior performance over existing methods in overcoming model underfitting or overfitting problems is demonstrated. The results were validated using FID, CLIP, DINO, and ImageReward, achieving an average of 9% improvement.', 'abstract_zh': '个性化图像生成允许用户保留所提供小图像集的风格或主题以进行进一步的图像生成。随着大规模文本到图像模型的进步，已经开发了许多高效微调这些模型以实现个性化的技术，如低秩适应（LoRA）。然而，基于LoRA的方法常常面临调整秩参数以取得满意结果的挑战。为了解决这一挑战，提出了AutoComponent-LoRA（AC-LoRA），该方法能够自动分离LoRA矩阵的信号分量和噪声分量，以实现快速高效的个性化艺术风格图像生成。该方法基于奇异值分解（SVD）和动态启发式，在训练过程中更新超参数。实验结果表明，该方法在克服模型欠拟合或过拟合问题方面优于现有方法，使用FID、CLIP、DINO和ImageReward验证的结果平均提高了9%。', 'title_zh': 'AC-LoRA: 自动组件LoRA个性化艺术风格图像生成'}
{'arxiv_id': 'arXiv:2504.02221', 'title': 'Learning and Improving Backgammon Strategy', 'authors': 'Gregory R. Galperin', 'link': 'https://arxiv.org/abs/2504.02221', 'abstract': "A novel approach to learning is presented, combining features of on-line and off-line methods to achieve considerable performance in the task of learning a backgammon value function in a process that exploits the processing power of parallel supercomputers. The off-line methods comprise a set of techniques for parallelizing neural network training and $TD(\\lambda)$ reinforcement learning; here Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line policy improvement technique which applies resources to the decision points encountered during the search of the game tree to further augment the learned value function estimate. A level of play roughly as good as, or possibly better than, the current champion human and computer backgammon players has been achieved in a short period of learning.", 'abstract_zh': '一种结合在线和离线方法的新颖学习方法，在利用并行超级计算机的计算能力完成背Gammon价值函数学习任务的过程中实现了显著的性能提升。离线方法包括用于并行化神经网络训练和$TD(\\lambda)$强化学习的技术；在此基础上引入了蒙特卡罗“Rollouts”作为大规模并行在线策略改进技术，将资源应用于游戏中遇到的决策点，进一步增强学习到的价值函数估计。在较短的学习时间内，达到了与当前顶级人类和计算机背Gammon玩家水平相当，甚至更高的水平。', 'title_zh': '学习并提升背gammon策略'}
{'arxiv_id': 'arXiv:2504.02211', 'title': 'FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention', 'authors': 'Huangliang Dai, Shixun Wu, Hairui Zhao, Jiajun Huang, Zizhe Jian, Yue Zhu, Haiyang Hu, Zizhong Chen', 'link': 'https://arxiv.org/abs/2504.02211', 'abstract': 'Transformer models leverage self-attention mechanisms to capture complex dependencies, demonstrating exceptional performance in various applications. However, the long-duration high-load computations required for model inference impose stringent reliability demands on the computing platform, as soft errors that occur during execution can significantly degrade model performance. Existing fault tolerance methods protect each operation separately using decoupled kernels, incurring substantial computational and memory overhead. In this paper, we propose a novel error-resilient framework for Transformer models, integrating end-to-end fault tolerant attention (EFTA) to improve inference reliability against soft errors. Our approach enables error detection and correction within a fully fused attention kernel, reducing redundant data access and thereby mitigating memory faults. To further enhance error coverage and reduce overhead, we design a hybrid fault tolerance scheme tailored for the EFTA, introducing for the first time: 1) architecture-aware algorithm-based fault tolerance (ABFT) using tensor checksum, which minimizes inter-thread communication overhead on tensor cores during error detection; 2) selective neuron value restriction, which selectively applies adaptive fault tolerance constraints to neuron values, balancing error coverage and overhead; 3) unified verification, reusing checksums to streamline multiple computation steps into a single verification process. Experimental results show that EFTA achieves up to 7.56x speedup over traditional methods with an average fault tolerance overhead of 13.9%.', 'abstract_zh': 'Transformer模型利用自注意力机制捕获复杂依赖关系，在各种应用中表现出色。然而，模型推理所需的长时间高负载计算对计算平台提出了严格的可靠性要求，因为执行过程中发生的软错误会显著降低模型性能。现有的容错方法单独保护每个操作，使用解耦内核，导致巨大的计算和内存开销。本文提出了一种新的Transformer模型容错框架，集成了端到端容错注意力(EFTA)，以提高在软错误下的推理可靠性。我们的方法能够在完全融合的注意力内核中进行错误检测和纠正，从而减少冗余数据访问，进而减轻内存故障的影响。为进一步提高错误覆盖并减少开销，我们设计了一种针对EFTA的混合容错方案，并首次引入了：1) 意识架构的算法-Based容错(ABFT)使用张量校验和，以最小化张量核心在错误检测过程中线程间通信开销；2) 选择性神经元值限制，选择性地对神经元值应用自适应容错约束，平衡错误覆盖和开销；3) 统一验证，利用校验和重新使用，将多个计算步骤合并为单一验证过程。实验结果表明，EFTA相比传统方法实现了高达7.56倍的速度提升，平均容错开销为13.9%。', 'title_zh': 'FT-Transformer: 具有端到端故障容忍注意机制的稳健可靠变换器'}
{'arxiv_id': 'arXiv:2504.02199', 'title': 'ESC: Erasing Space Concept for Knowledge Deletion', 'authors': 'Tae-Young Lee, Sundong Park, Minwoo Jeon, Hyoseok Hwang, Gyeong-Moon Park', 'link': 'https://arxiv.org/abs/2504.02199', 'abstract': 'As concerns regarding privacy in deep learning continue to grow, individuals are increasingly apprehensive about the potential exploitation of their personal knowledge in trained models. Despite several research efforts to address this, they often fail to consider the real-world demand from users for complete knowledge erasure. Furthermore, our investigation reveals that existing methods have a risk of leaking personal knowledge through embedding features. To address these issues, we introduce a novel concept of Knowledge Deletion (KD), an advanced task that considers both concerns, and provides an appropriate metric, named Knowledge Retention score (KR), for assessing knowledge retention in feature space. To achieve this, we propose a novel training-free erasing approach named Erasing Space Concept (ESC), which restricts the important subspace for the forgetting knowledge by eliminating the relevant activations in the feature. In addition, we suggest ESC with Training (ESC-T), which uses a learnable mask to better balance the trade-off between forgetting and preserving knowledge in KD. Our extensive experiments on various datasets and models demonstrate that our proposed methods achieve the fastest and state-of-the-art performance. Notably, our methods are applicable to diverse forgetting scenarios, such as facial domain setting, demonstrating the generalizability of our methods. The code is available at this http URL .', 'abstract_zh': '随着对深度学习中隐私问题的关注不断增加，个人对训练模型中可能对其个人知识的利用越来越感到担忧。尽管已经进行了多项研究努力来解决这些问题，但它们常常未能考虑用户对完全删除知识的现实需求。此外，我们的研究发现，现有方法存在通过特征嵌入泄露个人知识的风险。为解决这些问题，我们提出了一种新的知识删除（KD）概念，这是一个同时考虑上述两个方面的高级任务，并提出了一种名为知识保留得分（KR）的评估特征空间中知识保留的合适度量方法。为此，我们提出了一种新型无训练删除方法——擦除空间概念（ESC），通过消除特征中的相关激活来限制遗忘知识的重要子空间。此外，我们建议了带有训练的ESC（ESC-T），它使用可学习的掩码来更好地平衡KD中遗忘与保留知识之间的权衡。我们在多种数据集和模型上的广泛实验表明，我们提出的方法达到了最快的和最先进的性能。值得注意的是，我们的方法适用于各种遗忘场景，例如面部域设置，展示了我们方法的普适性。代码可在以下网址获取。', 'title_zh': 'ESC: 删除知识时的.erase空间概念'}
{'arxiv_id': 'arXiv:2504.02169', 'title': 'On the Geometry of Receiver Operating Characteristic and Precision-Recall Curves', 'authors': 'Reza Sameni', 'link': 'https://arxiv.org/abs/2504.02169', 'abstract': 'We study the geometry of Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves in binary classification problems. The key finding is that many of the most commonly used binary classification metrics are merely functions of the composition function $G := F_p \\circ F_n^{-1}$, where $F_p(\\cdot)$ and $F_n(\\cdot)$ are the class-conditional cumulative distribution functions of the classifier scores in the positive and negative classes, respectively. This geometric perspective facilitates the selection of operating points, understanding the effect of decision thresholds, and comparison between classifiers. It also helps explain how the shapes and geometry of ROC/PR curves reflect classifier behavior, providing objective tools for building classifiers optimized for specific applications with context-specific constraints. We further explore the conditions for classifier dominance, present analytical and numerical examples demonstrating the effects of class separability and variance on ROC and PR geometries, and derive a link between the positive-to-negative class leakage function $G(\\cdot)$ and the Kullback--Leibler divergence. The framework highlights practical considerations, such as model calibration, cost-sensitive optimization, and operating point selection under real-world capacity constraints, enabling more informed approaches to classifier deployment and decision-making.', 'abstract_zh': '我们研究了二分类问题中接收器操作 characteristic (ROC) 和精确率-召回率 (PR) 曲线的几何结构。主要发现是，许多常用的二分类指标仅仅是类条件累积分布函数的复合函数 $G := F_p \\circ F_n^{-1}$ 的函数，其中 $F_p(\\cdot)$ 和 $F_n(\\cdot)$ 分别是正类和负类中分类器得分的类条件累积分布函数。这种几何视角简化了操作点的选择，有助于理解决策阈值的影响，并在比较不同分类器时提供便利。它还解释了 ROC/PR 曲线的形状和几何结构如何反映分类器的行为，提供了在特定应用场景和情境约束下优化分类器的客观工具。我们进一步探讨了分类器占优的条件，给出了类可分性和方差对 ROC 和 PR 几何结构的影响的分析和数值示例，并推导了正类泄漏函数 $G(\\cdot)$ 与克劳德-莱布尼兹散度之间的关系。该框架突出了实际考虑因素，如模型校准、代价敏感优化以及实际容量约束下的操作点选择，使分类器的部署和决策更具指导意义。', 'title_zh': '关于接收器操作特征和精确度-召回率曲线的几何学'}
{'arxiv_id': 'arXiv:2504.02168', 'title': 'MDP: Multidimensional Vision Model Pruning with Latency Constraint', 'authors': 'Xinglong Sun, Barath Lakshmanan, Maying Shen, Shiyi Lan, Jingde Chen, Jose M. Alvarez', 'link': 'https://arxiv.org/abs/2504.02168', 'abstract': 'Current structural pruning methods face two significant limitations: (i) they often limit pruning to finer-grained levels like channels, making aggressive parameter reduction challenging, and (ii) they focus heavily on parameter and FLOP reduction, with existing latency-aware methods frequently relying on simplistic, suboptimal linear models that fail to generalize well to transformers, where multiple interacting dimensions impact latency. In this paper, we address both limitations by introducing Multi-Dimensional Pruning (MDP), a novel paradigm that jointly optimizes across a variety of pruning granularities-including channels, query, key, heads, embeddings, and blocks. MDP employs an advanced latency modeling technique to accurately capture latency variations across all prunable dimensions, achieving an optimal balance between latency and accuracy. By reformulating pruning as a Mixed-Integer Nonlinear Program (MINLP), MDP efficiently identifies the optimal pruned structure across all prunable dimensions while respecting latency constraints. This versatile framework supports both CNNs and transformers. Extensive experiments demonstrate that MDP significantly outperforms previous methods, especially at high pruning ratios. On ImageNet, MDP achieves a 28% speed increase with a +1.4 Top-1 accuracy improvement over prior work like HALP for ResNet50 pruning. Against the latest transformer pruning method, Isomorphic, MDP delivers an additional 37% acceleration with a +0.7 Top-1 accuracy improvement.', 'abstract_zh': '多维度剪枝：一种新型跨粒度优化范式', 'title_zh': 'MDP：多维度视觉模型剪枝算法及其延迟约束'}
{'arxiv_id': 'arXiv:2504.02151', 'title': 'Multivariate Temporal Regression at Scale: A Three-Pillar Framework Combining ML, XAI, and NLP', 'authors': 'Jiztom Kavalakkatt Francis, Matthew J Darr', 'link': 'https://arxiv.org/abs/2504.02151', 'abstract': 'The rapid use of artificial intelligence (AI) in processes such as coding, image processing, and data prediction means it is crucial to understand and validate the data we are working with fully. This paper dives into the hurdles of analyzing high-dimensional data, especially when it gets too complex. Traditional methods in data analysis often look at direct connections between input variables, which can miss out on the more complicated relationships within the data.\nTo address these issues, we explore several tested techniques, such as removing specific variables to see their impact and using statistical analysis to find connections between multiple variables. We also consider the role of synthetic data and how information can sometimes be redundant across different sensors. These analyses are typically very computationally demanding and often require much human effort to make sense of the results.\nA common approach is to treat the entire dataset as one unit and apply advanced models to handle it. However, this can become problematic with larger, noisier datasets and more complex models. So, we suggest methods to identify overall patterns that can help with tasks like classification or regression based on the idea that more straightforward approaches might be more understandable.\nOur research looks at two datasets: a real-world dataset and a synthetic one. The goal is to create a methodology that highlights key features on a global scale that lead to predictions, making it easier to validate or quantify the data set. By reducing the dimensionality with this method, we can simplify the models used and thus clarify the insights we gain. Furthermore, our method can reveal unexplored relationships between specific inputs and outcomes, providing a way to validate these new connections further.', 'abstract_zh': '人工智能在编码、图像处理和数据预测等过程中的快速应用意味着我们需要全面理解并验证我们所处理的数据。本文深入探讨了分析高维数据的挑战，特别是在数据变得过于复杂时。传统数据分析方法通常关注输入变量之间的直接联系，这可能会忽略数据内部更为复杂的关系。为应对这些问题，我们探索了几种经过验证的技术，如移除特定变量以观察其影响，以及利用统计分析来发现多个变量间的联系。我们还考虑了合成数据的作用，以及不同传感器之间信息可能存在的冗余。这些分析通常计算需求非常高，并且经常需要大量的人工努力来理解结果。', 'title_zh': '大规模多变量时间序列回归：结合机器学习、解释性人工智能和自然语言处理的三支柱框架'}
{'arxiv_id': 'arXiv:2504.02144', 'title': 'Towards Interpretable Soft Prompts', 'authors': 'Oam Patel, Jason Wang, Nikhil Shivakumar Nayak, Suraj Srinivas, Himabindu Lakkaraju', 'link': 'https://arxiv.org/abs/2504.02144', 'abstract': 'Soft prompts have been popularized as a cheap and easy way to improve task-specific LLM performance beyond few-shot prompts. Despite their origin as an automated prompting method, however, soft prompts and other trainable prompts remain a black-box method with no immediately interpretable connections to prompting. We create a novel theoretical framework for evaluating the interpretability of trainable prompts based on two desiderata: faithfulness and scrutability. We find that existing methods do not naturally satisfy our proposed interpretability criterion. Instead, our framework inspires a new direction of trainable prompting methods that explicitly optimizes for interpretability. To this end, we formulate and test new interpretability-oriented objective functions for two state-of-the-art prompt tuners: Hard Prompts Made Easy (PEZ) and RLPrompt. Our experiments with GPT-2 demonstrate a fundamental trade-off between interpretability and the task-performance of the trainable prompt, explicating the hardness of the soft prompt interpretability problem and revealing odd behavior that arises when one optimizes for an interpretability proxy.', 'abstract_zh': '软提示作为一种经济高效的方法，在提高任务特定的大语言模型性能方面日益流行，超越了少量示例提示。然而，尽管软提示和其他可训练提示源自自动化提示方法，它们仍然是一种黑盒方法，缺乏直接可解释的连接。我们构建了一个新的理论框架，基于忠实度和可审查性两个需求来评估可训练提示的可解释性。我们发现现有方法并不自然满足我们提出的可解释性标准。相反，我们的框架启发了一种新的可训练提示方法方向，明确地优化了可解释性。为此，我们为两种最先进的提示调优方法——Hard Prompts Made Easy (PEZ) 和 RLPrompt——制定了并测试了新的可解释性导向的目标函数。GPT-2的实验展示了可解释性和可训练提示任务性能之间的基本权衡，解释了软提示可解释性问题的困难性，并揭示了在优化可解释性代理时出现的奇怪行为。', 'title_zh': '可解释的软提示研究'}
{'arxiv_id': 'arXiv:2504.02141', 'title': 'On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software', 'authors': 'Ali Nouri, Johan Andersson, Kailash De Jesus Hornig, Zhennan Fei, Emil Knabe, Hakan Sivencrona, Beatriz Cabrero-Daniel, Christian Berger', 'link': 'https://arxiv.org/abs/2504.02141', 'abstract': "Automated Driving System (ADS) is a safety-critical software system responsible for the interpretation of the vehicle's environment and making decisions accordingly. The unbounded complexity of the driving context, including unforeseeable events, necessitate continuous improvement, often achieved through iterative DevOps processes. However, DevOps processes are themselves complex, making these improvements both time- and resource-intensive. Automation in code generation for ADS using Large Language Models (LLM) is one potential approach to address this challenge. Nevertheless, the development of ADS requires rigorous processes to verify, validate, assess, and qualify the code before it can be deployed in the vehicle and used. In this study, we developed and evaluated a prototype for automatic code generation and assessment using a designed pipeline of a LLM-based agent, simulation model, and rule-based feedback generator in an industrial setup. The LLM-generated code is evaluated automatically in a simulation model against multiple critical traffic scenarios, and an assessment report is provided as feedback to the LLM for modification or bug fixing. We report about the experimental results of the prototype employing Codellama:34b, DeepSeek (r1:32b and Coder:33b), CodeGemma:7b, Mistral:7b, and GPT4 for Adaptive Cruise Control (ACC) and Unsupervised Collision Avoidance by Evasive Manoeuvre (CAEM). We finally assessed the tool with 11 experts at two Original Equipment Manufacturers (OEMs) by conducting an interview study.", 'abstract_zh': '自动驾驶系统（ADS）的自动化代码生成与评估研究：基于大规模语言模型的管道设计与工业应用', 'title_zh': '基于仿真引导的大语言模型代码生成以实现安全自主驾驶软件'}
{'arxiv_id': 'arXiv:2504.02137', 'title': 'Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID', 'authors': 'Carolina Zheng, Minhui Huang, Dmitrii Pedchenko, Kaushik Rangadurai, Siyu Wang, Gaby Nahum, Jie Lei, Yang Yang, Tao Liu, Zutian Luo, Xiaohan Wei, Dinesh Ramasamy, Jiyan Yang, Yiping Han, Lin Yang, Hangjun Xu, Rong Jin, Shuang Yang', 'link': 'https://arxiv.org/abs/2504.02137', 'abstract': 'The exponential growth of online content has posed significant challenges to ID-based models in industrial recommendation systems, ranging from extremely high cardinality and dynamically growing ID space, to highly skewed engagement distributions, to prediction instability as a result of natural id life cycles (e.g, the birth of new IDs and retirement of old IDs). To address these issues, many systems rely on random hashing to handle the id space and control the corresponding model parameters (i.e embedding table). However, this approach introduces data pollution from multiple ids sharing the same embedding, leading to degraded model performance and embedding representation instability.\nThis paper examines these challenges and introduces Semantic ID prefix ngram, a novel token parameterization technique that significantly improves the performance of the original Semantic ID. Semantic ID prefix ngram creates semantically meaningful collisions by hierarchically clustering items based on their content embeddings, as opposed to random assignments. Through extensive experimentation, we demonstrate that Semantic ID prefix ngram not only addresses embedding instability but also significantly improves tail id modeling, reduces overfitting, and mitigates representation shifts. We further highlight the advantages of Semantic ID prefix ngram in attention-based models that contextualize user histories, showing substantial performance improvements. We also report our experience of integrating Semantic ID into Meta production Ads Ranking system, leading to notable performance gains and enhanced prediction stability in live deployments.', 'abstract_zh': '基于语义的ID前缀n元组：显著改善工业推荐系统中的ID表示', 'title_zh': '在推荐系统中通过语义ID增强嵌入表示稳定性'}
{'arxiv_id': 'arXiv:2504.02128', 'title': 'Achieving Unanimous Consensus in Decision Making Using Multi-Agents', 'authors': 'Apurba Pokharel, Ram Dantu, Shakila Zaman, Sirisha Talapuru, Vinh Quach', 'link': 'https://arxiv.org/abs/2504.02128', 'abstract': "Blockchain consensus mechanisms have relied on algorithms such as Proof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality and integrity. However, these approaches struggle with adaptability for decision-making where the opinions of each matter rather than reaching an agreement based on honest majority or weighted consensus. This paper introduces a novel deliberation-based consensus mechanism where Large Language Models (LLMs) act as rational agents engaging in structured discussions to reach a unanimous consensus. By leveraging graded consensus and a multi-round deliberation process, our approach ensures both unanimous consensus for definitive problems and graded confidence for prioritized decisions and policies. We provide a formalization of our system and use it to show that the properties of blockchains: consistency, agreement, liveness, and determinism are maintained. Moreover, experimental results demonstrate our system's feasibility, showcasing how our deliberation method's convergence, block properties, and accuracy enable decision-making on blockchain networks. We also address key challenges with this novel approach such as degeneration of thoughts, hallucinations, malicious models and nodes, resource consumption, and scalability.", 'abstract_zh': '基于大型语言模型的共识机制：一种基于协商的创新方法', 'title_zh': '在决策中使用多智能体实现一致共识'}
{'arxiv_id': 'arXiv:2504.02118', 'title': 'LLMPi: Optimizing LLMs for High-Throughput on Raspberry Pi', 'authors': 'Mahsa Ardakani, Jinendra Malekar, Ramtin Zand', 'link': 'https://arxiv.org/abs/2504.02118', 'abstract': 'Deploying Large Language Models (LLMs) on resource-constrained edge devices like the Raspberry Pi presents challenges in computational efficiency, power consumption, and response latency. This paper explores quantization-based optimization techniques to enable high-throughput, energy-efficient execution of LLMs on low-power embedded systems. Our approach leverages k-quantization, a Post-Training Quantization (PTQ) method designed for different bit-widths, enabling efficient 2-bit, 4-bit, 6-bit, and 8-bit weight quantization. Additionally, we employ ternary quantization using Quantization-Aware Training (QAT) for BitNet models, allowing for more effective adaptation to lower-bit representations while preserving accuracy.\nOur findings highlight the potential of quantized LLMs for real-time conversational AI on edge devices, paving the way for low-power, high-efficiency AI deployment in mobile and embedded applications. This study demonstrates that aggressive quantization strategies can significantly reduce energy consumption while maintaining inference quality, making LLMs practical for resource-limited environments.', 'abstract_zh': '将大型语言模型（LLMs）部署在资源受限的边缘设备如Raspberry Pi上，面临计算效率、功耗和响应延迟的挑战。本文探讨基于量化优化技术，以在低功耗嵌入式系统上实现LLMs的高吞吐量、节能执行。我们的方法采用了k-量化，这是一种用于不同位宽的后训练量化（PTQ）方法，支持高效的2位、4位、6位和8位权重量化。此外，我们还利用Quantization-Aware Training（QAT）进行三值量化，适用于BitNet模型，允许更有效地适应低位表示，同时保持准确性。', 'title_zh': 'LLMPi: 优化Raspberry Pi上的高 throughput 大语言模型'}
{'arxiv_id': 'arXiv:2504.02114', 'title': 'On Model Protection in Federated Learning against Eavesdropping Attacks', 'authors': 'Dipankar Maity, Kushal Chakrabarti', 'link': 'https://arxiv.org/abs/2504.02114', 'abstract': "In this study, we investigate the protection offered by federated learning algorithms against eavesdropping adversaries. In our model, the adversary is capable of intercepting model updates transmitted from clients to the server, enabling it to create its own estimate of the model. Unlike previous research, which predominantly focuses on safeguarding client data, our work shifts attention protecting the client model itself. Through a theoretical analysis, we examine how various factors, such as the probability of client selection, the structure of local objective functions, global aggregation at the server, and the eavesdropper's capabilities, impact the overall level of protection. We further validate our findings through numerical experiments, assessing the protection by evaluating the model accuracy achieved by the adversary. Finally, we compare our results with methods based on differential privacy, underscoring their limitations in this specific context.", 'abstract_zh': '本研究探讨了联邦学习算法在对抗窃听攻击时所提供的保护。在我们的模型中，攻击者能够拦截从客户端传输到服务器的模型更新，从而能够生成自己的模型估计。与以往主要集中在保护客户端数据的研究不同，我们的工作将注意力转向保护客户端模型本身。通过理论分析，我们探讨了参与客户端的选择概率、本地目标函数的结构、服务器端的全局聚合以及攻击者的各种能力等因素如何影响整体保护水平。我们进一步通过数值实验验证了这些发现，通过评估攻击者实现的模型准确性来衡量保护程度。最后，我们将我们的结果与基于差分隐私的方法进行比较，突显了它们在这一特定情境下的局限性。', 'title_zh': '联邦学习中针对窃听攻击的模型保护'}
{'arxiv_id': 'arXiv:2504.02110', 'title': 'ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models', 'authors': 'Mingyuan Zhong, Ruolin Chen, Xia Chen, James Fogarty, Jacob O. Wobbrock', 'link': 'https://arxiv.org/abs/2504.02110', 'abstract': "Many mobile apps are inaccessible, thereby excluding people from their potential benefits. Existing rule-based accessibility checkers aim to mitigate these failures by identifying errors early during development but are constrained in the types of errors they can detect. We present ScreenAudit, an LLM-powered system designed to traverse mobile app screens, extract metadata and transcripts, and identify screen reader accessibility errors overlooked by existing checkers. We recruited six accessibility experts including one screen reader user to evaluate ScreenAudit's reports across 14 unique app screens. Our findings indicate that ScreenAudit achieves an average coverage of 69.2%, compared to only 31.3% with a widely-used accessibility checker. Expert feedback indicated that ScreenAudit delivered higher-quality feedback and addressed more aspects of screen reader accessibility compared to existing checkers, and that ScreenAudit would benefit app developers in real-world settings.", 'abstract_zh': '许多移动应用不可访问，从而排除了人们享受其潜在利益的机会。现有的基于规则的无障碍检查器旨在通过在开发早期识别错误来减轻这些失败，但它们在检测错误的类型上存在限制。我们提出了一个以LLM为动力的系统ScreenAudit，用于遍历移动应用屏幕、提取元数据和转录，并识别现有检查器未能发现的屏幕阅读器无障碍错误。我们招募了六名无障碍专家，其中包括一名屏幕阅读器用户，对ScreenAudit的报告在14个独特的应用屏幕上的表现进行了评估。我们的研究发现，ScreenAudit的覆盖率为69.2%，而一款广泛使用的无障碍检查器的覆盖率为31.3%。专家反馈表明，与现有的检查器相比，ScreenAudit提供了更高质量的反馈，并且涵盖了更多屏幕阅读器无障碍方面的内容，且ScreenAudit在实际应用环境中将有助于应用开发人员。', 'title_zh': 'ScreenAudit：使用大型语言模型检测移动应用中的屏幕阅读器 Accessibility 错误'}
{'arxiv_id': 'arXiv:2504.02094', 'title': 'FlowDistill: Scalable Traffic Flow Prediction via Distillation from LLMs', 'authors': 'Chenyang Yu, Xinpeng Xie, Yan Huang, Chenxi Qiu', 'link': 'https://arxiv.org/abs/2504.02094', 'abstract': "Accurate traffic flow prediction is vital for optimizing urban mobility, yet it remains difficult in many cities due to complex spatio-temporal dependencies and limited high-quality data. While deep graph-based models demonstrate strong predictive power, their performance often comes at the cost of high computational overhead and substantial training data requirements, making them impractical for deployment in resource-constrained or data-scarce environments. We propose the FlowDistill, a lightweight and scalable traffic prediction framework based on knowledge distillation from large language models (LLMs). In this teacher-student setup, a fine-tuned LLM guides a compact multi-layer perceptron (MLP) student model using a novel combination of the information bottleneck principle and teacher-bounded regression loss, ensuring the distilled model retains only essential and transferable knowledge. Spatial and temporal correlations are explicitly encoded to enhance the model's generalization across diverse urban settings. Despite its simplicity, FlowDistill consistently outperforms state-of-the-art models in prediction accuracy while requiring significantly less training data, and achieving lower memory usage and inference latency, highlighting its efficiency and suitability for real-world, scalable deployment.", 'abstract_zh': '基于大型语言模型知识蒸馏的FlowDistill交通预测框架', 'title_zh': 'FlowDistill：通过来自LLM的精炼实现可扩展的交通流预测'}
{'arxiv_id': 'arXiv:2504.02087', 'title': 'An Introductory Survey to Autoencoder-based Deep Clustering -- Sandboxes for Combining Clustering with Deep Learning', 'authors': 'Collin Leiber, Lukas Miklautz, Claudia Plant, Christian Böhm', 'link': 'https://arxiv.org/abs/2504.02087', 'abstract': 'Autoencoders offer a general way of learning low-dimensional, non-linear representations from data without labels. This is achieved without making any particular assumptions about the data type or other domain knowledge. The generality and domain agnosticism in combination with their simplicity make autoencoders a perfect sandbox for researching and developing novel (deep) clustering algorithms. Clustering methods group data based on similarity, a task that benefits from the lower-dimensional representation learned by an autoencoder, mitigating the curse of dimensionality. Specifically, the combination of deep learning with clustering, called Deep Clustering, enables to learn a representation tailored to specific clustering tasks, leading to high-quality results. This survey provides an introduction to fundamental autoencoder-based deep clustering algorithms that serve as building blocks for many modern approaches.', 'abstract_zh': '自动编码器提供了一种从数据中学习低维非线性表示的通用方法，无需标签，无需对数据类型或其他领域知识做出特定假设。其通用性和领域无关性与简洁性使得自动编码器成为研究和开发新型（深度）聚类算法的理想平台。基于聚类的深层表示降低了维数 curse of dimensionality，使得聚类方法能够根据相似性对数据进行分组，特别地，深度学习与聚类的结合，即深层聚类，能够学习适合特定聚类任务的表示，从而获得高质量的结果。本文提供了自动编码器基础的深度聚类算法的综述，这些算法是许多现代方法的基础。', 'title_zh': '基于自动编码器的深度聚类入门综述——结合聚类与深度学习的实验平台'}
{'arxiv_id': 'arXiv:2504.02080', 'title': 'Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses', 'authors': 'Zhengchun Shang, Wenlan Wei', 'link': 'https://arxiv.org/abs/2504.02080', 'abstract': 'Large Language Models (LLMs) are increasingly popular, powering a wide range of applications. Their widespread use has sparked concerns, especially through jailbreak attacks that bypass safety measures to produce harmful content.\nIn this paper, we present a comprehensive security analysis of large language models (LLMs), addressing critical research questions on the evolution and determinants of model safety.\nSpecifically, we begin by identifying the most effective techniques for detecting jailbreak attacks. Next, we investigate whether newer versions of LLMs offer improved security compared to their predecessors. We also assess the impact of model size on overall security and explore the potential benefits of integrating multiple defense strategies to enhance model robustness.\nOur study evaluates both open-source models (e.g., LLaMA and Mistral) and closed-source systems (e.g., GPT-4) by employing four state-of-the-art attack techniques and assessing the efficacy of three new defensive approaches.', 'abstract_zh': '大型语言模型（LLMs）日益流行，推动了广泛的应用。它们的广泛应用引发了诸多关切，尤其是在通过越狱攻击绕过安全措施以生成有害内容的问题上。\n\n在这篇论文中，我们对大型语言模型（LLMs）进行了全面的安全分析，探讨了模型安全性演化及其决定因素的关键研究问题。\n\n具体来说，我们首先识别出检测越狱攻击最有效的方法。接下来，我们调查了新版本的LLMs是否在安全性上优于其前代产品。我们还评估了模型规模对整体安全性的影响，并探索了结合多种防御策略以增强模型稳健性的潜力。\n\n我们的研究通过使用四种最先进的攻击技术评估开源模型（如LLaMA和Mistral）和封闭源系统（如GPT-4），并评估了三种新防御方法的有效性。', 'title_zh': 'LLMs中 evolving 安全性：一项关于 Jailbreak 攻击与防御的研究'}
{'arxiv_id': 'arXiv:2504.02074', 'title': 'Trapped by Expectations: Functional Fixedness in LLM-Enabled Chat Search', 'authors': 'Jiqun Liu, Jamshed Karimnazarov, Ryen W. White', 'link': 'https://arxiv.org/abs/2504.02074', 'abstract': "Functional fixedness, a cognitive bias that restricts users' interactions with a new system or tool to expected or familiar ways, limits the full potential of Large Language Model (LLM)-enabled chat search, especially in complex and exploratory tasks. To investigate its impact, we conducted a crowdsourcing study with 450 participants, each completing one of six decision-making tasks spanning public safety, diet and health management, sustainability, and AI ethics. Participants engaged in a multi-prompt conversation with ChatGPT to address the task, allowing us to compare pre-chat intent-based expectations with observed interactions. We found that: 1) Several aspects of pre-chat expectations are closely associated with users' prior experiences with ChatGPT, search engines, and virtual assistants; 2) Prior system experience shapes language use and prompting behavior. Frequent ChatGPT users reduced deictic terms and hedge words and frequently adjusted prompts. Users with rich search experience maintained structured, less-conversational queries with minimal modifications. Users of virtual assistants favored directive, command-like prompts, reinforcing functional fixedness; 3) When the system failed to meet expectations, participants generated more detailed prompts with increased linguistic diversity, reflecting adaptive shifts. These findings suggest that while preconceived expectations constrain early interactions, unmet expectations can motivate behavioral adaptation. With appropriate system support, this may promote broader exploration of LLM capabilities. This work also introduces a typology for user intents in chat search and highlights the importance of mitigating functional fixedness to support more creative and analytical use of LLMs.", 'abstract_zh': '认知偏见功能固定性限制了大语言模型（LLM）赋能的聊天搜索的潜力，特别是在复杂和探索性任务中。为了探究其影响，我们通过众包研究对450名参与者进行了调查，每位参与者完成了一个涉及公共安全、饮食与健康管理、可持续发展和AI伦理的六项决策任务之一。参与者与ChatGPT进行了多轮对话以应对任务，使我们能够比较事前预期与实际交互之间的差异。研究发现：1）事前预期的多个方面与用户对ChatGPT、搜索引擎和虚拟助手的先前经验密切相关；2）先前系统的使用经验影响语言使用和提问行为。频繁使用ChatGPT的用户减少了指示词和模糊词汇的使用，并频繁调整提问。拥有丰富搜索经验的用户维持了结构化、较少对话性的查询并进行了最小的修改。虚拟助手的用户倾向于使用指令性、命令式的提问，强化了功能固定性；3）当系统未能满足预期时，参与者生成了更详细的、语言多样性更高的提问，反映出适应性调整。这些发现表明，尽管先入为主的预期会限制早期交互，但未能满足的预期可以促使行为调整。适当的支持系统可以使用户更广泛地探索LLM的能力。这项工作还提出了聊天搜索用户意图的分类，并强调减轻功能固定性的重要性，以支持更创造性和分析性的LLM使用。', 'title_zh': '被困于期望之中：大语言模型 enabling 的聊天查找中的功能固定性'}
{'arxiv_id': 'arXiv:2504.02069', 'title': 'RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics', 'authors': 'Zhiyuan Zhang, Yuxin He, Yong Sun, Junyu Shi, Lijiang Liu, Qiang Nie', 'link': 'https://arxiv.org/abs/2504.02069', 'abstract': 'Visual Language Models (VLMs) have emerged as pivotal tools for robotic systems, enabling cross-task generalization, dynamic environmental interaction, and long-horizon planning through multimodal perception and semantic reasoning. However, existing open-source VLMs predominantly trained for generic vision-language alignment tasks fail to model temporally correlated action semantics that are crucial for robotic manipulation effectively. While current image-based fine-tuning methods partially adapt VLMs to robotic applications, they fundamentally disregard temporal evolution patterns in video sequences and suffer from visual feature entanglement between robotic agents, manipulated objects, and environmental contexts, thereby limiting semantic decoupling capability for atomic actions and compromising model this http URL overcome these challenges, this work presents RoboAct-CLIP with dual technical contributions: 1) A dataset reconstruction framework that performs semantic-constrained action unit segmentation and re-annotation on open-source robotic videos, constructing purified training sets containing singular atomic actions (e.g., "grasp"); 2) A temporal-decoupling fine-tuning strategy based on Contrastive Language-Image Pretraining (CLIP) architecture, which disentangles temporal action features across video frames from object-centric characteristics to achieve hierarchical representation learning of robotic atomic this http URL results in simulated environments demonstrate that the RoboAct-CLIP pretrained model achieves a 12% higher success rate than baseline VLMs, along with superior generalization in multi-object manipulation tasks.', 'abstract_zh': 'Visual语言模型（VLMs）已成为机器人系统的关键工具，通过多模态感知和语义推理实现跨任务通用性、动态环境交互和长期规划。然而，现有的开源VLMs主要针对通用视觉-语言对齐任务进行训练，未能有效建模对于机器人操作至关重要的时间相关动作语义。尽管现有的基于图像的微调方法部分地使VLMs适应机器人应用，但他们从根本上忽略了视频序列中的时间演化模式，并且受制于机器人代理、操作对象和环境上下文之间的视觉特征纠缠，从而限制了原子动作的语义解耦能力并损害了模型的泛化能力。为了解决这些挑战，本文提出了RoboAct-CLIP，并贡献了两项关键技术：1）一个数据集重构框架，对开源机器人视频进行语义约束的动作单元分割和重新注释，构建包含单一原子动作（如“抓取”）的净化训练集；2）基于对比视觉-语言预训练（CLIP）架构的时间解耦微调策略，该策略从以对象为中心的特性中解纠缠时间动作特征，以实现层次化的机器人原子操作的表示学习。模拟环境的实验结果表明，RoboAct-CLIP预训练模型的成功率比基线VLMs高出12%，并且在多对象操作任务中的泛化能力更优。', 'title_zh': 'RoboAct-CLIP: 由视频驱动的机器人原子动作理解预训练'}
{'arxiv_id': 'arXiv:2504.02064', 'title': 'From Text to Graph: Leveraging Graph Neural Networks for Enhanced Explainability in NLP', 'authors': 'Fabio Yáñez-Romero, Andrés Montoyo, Armando Suárez, Yoan Gutiérrez, Ruslan Mitkov', 'link': 'https://arxiv.org/abs/2504.02064', 'abstract': 'Researchers have relegated natural language processing tasks to Transformer-type models, particularly generative models, because these models exhibit high versatility when performing generation and classification tasks. As the size of these models increases, they achieve outstanding results. Given their widespread use, many explainability techniques are developed based on these models. However, this process becomes computationally expensive due to the large size of the models. Additionally, transformers interpret input information through tokens that fragment input words into sequences lacking inherent semantic meaning, complicating the explanation of the model from the very beginning. This study proposes a novel methodology to achieve explainability in natural language processing tasks by automatically converting sentences into graphs and maintaining semantics through nodes and relations that express fundamental linguistic concepts. It also allows the subsequent exploitation of this knowledge in subsequent tasks, making it possible to obtain trends and understand how the model associates the different elements inside the text with the explained task. The experiments delivered promising results in determining the most critical components within the text structure for a given classification.', 'abstract_zh': '研究人员将自然语言处理任务交予Transformer类型模型，特别是生成模型，因为这些模型在生成和分类任务中表现出高度的灵活性。随着模型规模的增加，它们取得了出色的结果。鉴于这些模型的广泛应用，许多解释性技术基于这些模型开发出来。然而，由于模型规模庞大，这一过程变得计算成本高昂。此外，Transformer通过令牌将输入词分解成缺乏内在语义意义的序列，从一开始就使模型解释变得复杂。本研究提出了一种新的方法，通过自动将句子转换为图，并通过节点和关系保留语义，来实现自然语言处理任务的解释性，这些节点和关系表达基本的语言概念。这种方法还允许在后续任务中利用这一知识，从而能够获得趋势并理解模型是如何将文本中的不同元素与解释性任务关联起来的。实验结果显示，这种方法在确定给定分类任务中最重要的文本结构组件方面取得了令人鼓舞的结果。', 'title_zh': '从文本到图形：利用图形神经网络提高自然语言处理的可解释性'}
{'arxiv_id': 'arXiv:2504.02051', 'title': 'Self-Resource Allocation in Multi-Agent LLM Systems', 'authors': 'Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, Xin Eric Wang, William Wang', 'link': 'https://arxiv.org/abs/2504.02051', 'abstract': 'With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.', 'abstract_zh': '随着大型语言模型（LLMs）作为代理的发展，人们越来越兴趣于将多个代理连接到多代理系统中并发完成任务，重点在于它们在任务分配和协调中的作用。本文探讨了LLMs如何有效地将计算任务分配给多个代理，考虑了成本、效率和性能等因素。在本研究中，我们关注的关键问题包括LLMs作为调度器和规划者的有效性，比较了它们在任务分配和协调中的效果。我们的实验表明，LLMs在资源分配任务中能够达到高有效性和准确性。我们发现，在处理并发动作时，规划者方法优于调度器方法，从而提高了效率并更好地利用了代理。此外，我们展示了提供关于工人能力的显式信息可以提高规划者的分配策略，尤其是在处理低效工人时。', 'title_zh': '多智能体大语言模型系统中的自我资源分配'}
{'arxiv_id': 'arXiv:2504.02019', 'title': 'Antithetic Sampling for Top-k Shapley Identification', 'authors': 'Patrick Kolpaczki, Tim Nielen, Eyke Hüllermeier', 'link': 'https://arxiv.org/abs/2504.02019', 'abstract': "Additive feature explanations rely primarily on game-theoretic notions such as the Shapley value by viewing features as cooperating players. The Shapley value's popularity in and outside of explainable AI stems from its axiomatic uniqueness. However, its computational complexity severely limits practicability. Most works investigate the uniform approximation of all features' Shapley values, needlessly consuming samples for insignificant features. In contrast, identifying the $k$ most important features can already be sufficiently insightful and yields the potential to leverage algorithmic opportunities connected to the field of multi-armed bandits. We propose Comparable Marginal Contributions Sampling (CMCS), a method for the top-$k$ identification problem utilizing a new sampling scheme taking advantage of correlated observations. We conduct experiments to showcase the efficacy of our method in compared to competitive baselines. Our empirical findings reveal that estimation quality for the approximate-all problem does not necessarily transfer to top-$k$ identification and vice versa.", 'abstract_zh': '加性特征解释主要依赖于合作博弈理论中的Shapley值。Shapley值在可解释AI内外的广泛接受源于其公理唯一性。然而，其计算复杂性严重限制了其实用性。大多数研究关注所有特征Shapley值的均匀近似，无谓地为不重要的特征消耗样本。相反，识别最重要的$k$个特征已经可以提供足够的洞察，并有可能利用与多臂bandit问题相关的算法机会。我们提出了一种称为可比边际贡献采样（CMCS）的方法，用于利用相关观测的新采样方案解决top-$k$识别问题。我们进行了实验以展示我们的方法相对于竞争基线的有效性。我们的实证研究表明，对于近似所有特征的问题，估计质量不一定转移到top-$k$识别问题上，反之亦然。', 'title_zh': '反向取样法用于Top-k Shapley值识别'}
{'arxiv_id': 'arXiv:2504.02014', 'title': 'HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks', 'authors': 'Jiannuo Li, Lan Yao', 'link': 'https://arxiv.org/abs/2504.02014', 'abstract': 'Accurate prediction of the binding affinity between drugs and target proteins is a core task in computer-aided drug design. Existing deep learning methods tend to ignore the information of internal sub-structural features of drug molecules and drug-target interactions, resulting in limited prediction performance. In this paper, we propose a drug-target association prediction model HCAF-DTA based on cross-attention fusion hypergraph neural network. The model innovatively introduces hypergraph representation in the feature extraction stage: drug molecule hypergraphs are constructed based on the tree decomposition algorithm, and the sub-structural and global features extracted by fusing the hypergraph neural network with the graphical neural network through hopping connections, in which the hyper edges can efficiently characterise the functional functional groups and other key chemical features; for the protein feature extraction, a weighted graph is constructed based on the residues predicted by the ESM model contact maps to construct weighted graphs, and multilayer graph neural networks were used to capture spatial dependencies. In the prediction stage, a bidirectional multi-head cross-attention mechanism is designed to model intermolecular interactions from the dual viewpoints of atoms and amino acids, and cross-modal features with correlated information are fused by attention. Experiments on benchmark datasets such as Davis and KIBA show that HCAF-DTA outperforms state of the arts in all three performance evaluation metrics, with the MSE metrics reaching 0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal baseline.', 'abstract_zh': '基于跨注意力融合超图神经网络的药物-靶标结合 affinity 预测模型 HCAF-DTA', 'title_zh': 'HCAF-DTA：基于交叉注意力融合超图神经网络的药物-靶点结合亲和力预测'}
{'arxiv_id': 'arXiv:2504.02011', 'title': 'Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression', 'authors': 'Dohyun Kim, Sehwan Park, Geonhee Han, Seung Wook Kim, Paul Hongsuck Seo', 'link': 'https://arxiv.org/abs/2504.02011', 'abstract': 'Diffusion models generate high-quality images through progressive denoising but are computationally intensive due to large model sizes and repeated sampling. Knowledge distillation, which transfers knowledge from a complex teacher to a simpler student model, has been widely studied in recognition tasks, particularly for transferring concepts unseen during student training. However, its application to diffusion models remains underexplored, especially in enabling student models to generate concepts not covered by the training images. In this work, we propose Random Conditioning, a novel approach that pairs noised images with randomly selected text conditions to enable efficient, image-free knowledge distillation. By leveraging this technique, we show that the student can generate concepts unseen in the training images. When applied to conditional diffusion model distillation, our method allows the student to explore the condition space without generating condition-specific images, resulting in notable improvements in both generation quality and efficiency. This promotes resource-efficient deployment of generative diffusion models, broadening their accessibility for both research and real-world applications. Code, models, and datasets are available at this https URL .', 'abstract_zh': '基于随机条件的扩散模型高效知识蒸馏', 'title_zh': '数据高效的扩散模型压缩中的随机条件化与蒸馏'}
{'arxiv_id': 'arXiv:2504.02008', 'title': 'Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates', 'authors': 'Kecheng Chen, Xinyu Luo, Tiexin Qin, Jie Liu, Hui Liu, Victor Ho Fun Lee, Hong Yan, Haoliang Li', 'link': 'https://arxiv.org/abs/2504.02008', 'abstract': 'Foundation medical segmentation models, with MedSAM being the most popular, have achieved promising performance across organs and lesions. However, MedSAM still suffers from compromised performance on specific lesions with intricate structures and appearance, as well as bounding box prompt-induced perturbations. Although current test-time adaptation (TTA) methods for medical image segmentation may tackle this issue, partial (e.g., batch normalization) or whole parametric updates restrict their effectiveness due to limited update signals or catastrophic forgetting in large models. Meanwhile, these approaches ignore the computational complexity during adaptation, which is particularly significant for modern foundation models. To this end, our theoretical analyses reveal that directly refining image embeddings is feasible to approach the same goal as parametric updates under the MedSAM architecture, which enables us to realize high computational efficiency and segmentation performance without the risk of catastrophic forgetting. Under this framework, we propose to encourage maximizing factorized conditional probabilities of the posterior prediction probability using a proposed distribution-approximated latent conditional random field loss combined with an entropy minimization loss. Experiments show that we achieve about 3\\% Dice score improvements across three datasets while reducing computational complexity by over 7 times.', 'abstract_zh': '基于医学图像分割的foundation模型，MedSAM尤为流行，已经在多个器官和病灶上取得了令人瞩目的性能。然而，MedSAM在处理具有复杂结构和外观的特定病灶时仍然表现出妥协的性能，并且受到边界框提示引起的扰动的影响。尽管当前的测试时适应（TTA）方法可能解决这一问题，但部分（如批量归一化）或整体参数更新方法因更新信号有限或大模型中的灾难性遗忘而限制了其有效性。同时，这些方法忽略了适应过程中的计算复杂性，这对于现代foundation模型尤为重要。为此，我们的理论分析表明，在MedSAM架构下直接精炼图像嵌入是可行的，以实现相同目标，从而使我们能够在不发生灾难性遗忘风险的情况下实现高计算效率和分割性能。在此框架下，我们提出了一种鼓励最大化后验预测概率的因子条件概率并结合熵最小化损失的分布逼近潜条件随机场损失，以增强分割性能。实验结果显示，我们在三个数据集中实现了大约3%的Dice分数提高，同时计算复杂性降低了约7倍。', 'title_zh': '测试时自适应调整不包含参数更新的基础医疗分割模型'}
{'arxiv_id': 'arXiv:2504.02000', 'title': 'AI Regulation and Capitalist Growth: Balancing Innovation, Ethics, and Global Governance', 'authors': 'Vikram Kulothungan, Priya Ranjani Mohan, Deepti Gupta', 'link': 'https://arxiv.org/abs/2504.02000', 'abstract': 'Artificial Intelligence (AI) is increasingly central to economic growth, promising new efficiencies and markets. This economic significance has sparked debate over AI regulation: do rules and oversight bolster long term growth by building trust and safeguarding the public, or do they constrain innovation and free enterprise? This paper examines the balance between AI regulation and capitalist ideals, focusing on how different approaches to AI data privacy can impact innovation in AI-driven applications. The central question is whether AI regulation enhances or inhibits growth in a capitalist economy. Our analysis synthesizes historical precedents, the current U.S. regulatory landscape, economic projections, legal challenges, and case studies of recent AI policies. We discuss that carefully calibrated AI data privacy regulations-balancing innovation incentives with the public interest can foster sustainable growth by building trust and ensuring responsible data use, while excessive regulation may risk stifling innovation and entrenching incumbents.', 'abstract_zh': '人工智能（AI）日益成为经济增长的核心，承诺带来新的效率和市场。这种经济意义引发了关于AI监管的争论：规则和监督是否通过建立信任和保护公众来促进长期增长，还是限制创新和自由企业？本文探讨了AI监管与资本主义理想之间的平衡，重点关注不同的人工智能数据隐私方法如何影响人工智能驱动应用的创新。中心问题是AI监管是促进还是阻碍资本主义经济的增长。我们的分析综合了历史先例、当前的美国监管环境、经济增长预测、法律挑战以及近年来AI政策的案例研究。我们讨论了精心设计的人工智能数据隐私监管——平衡创新激励与公众利益可以通过建立信任和确保负责任的数据使用来促进可持续增长，而过度监管可能会限制创新并巩固既有企业。', 'title_zh': 'AI监管与资本主义增长：平衡创新、 Ethics 和全球治理'}
{'arxiv_id': 'arXiv:2504.01994', 'title': 'PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs', 'authors': 'Jinendra Malekar, Peyton Chandarana, Md Hasibul Amin, Mohammed E. Elbtity, Ramtin Zand', 'link': 'https://arxiv.org/abs/2504.01994', 'abstract': 'In this paper, we propose PIM-LLM, a hybrid architecture developed to accelerate 1-bit large language models (LLMs). PIM-LLM leverages analog processing-in-memory (PIM) architectures and digital systolic arrays to accelerate low-precision matrix multiplication (MatMul) operations in projection layers and high-precision MatMul operations in attention heads of 1-bit LLMs, respectively. Our design achieves up to roughly 80x improvement in tokens per second and a 70% increase in tokens per joule compared to conventional hardware accelerators. Additionally, PIM-LLM outperforms previous PIM-based LLM accelerators, setting a new benchmark with at least 2x and 5x improvement in GOPS and GOPS/W, respectively.', 'abstract_zh': '本文提出PIM-LLM，一种加速1比特大型语言模型（LLM）的混合架构。PIM-LLM利用模拟处理-in-内存（PIM）架构和数字梭形阵列分别加速1比特LLM中投影层的低精度矩阵乘法（MatMul）操作和注意头的高精度MatMul操作，实现每秒高达约80倍的token性能提升，以及每焦耳70%的token性能提升，相较于传统硬件加速器。此外，PIM-LLM优于现有的PIM基LLM加速器，分别在GOPS和GOPS/W上实现至少2倍和5倍的性能提升。', 'title_zh': 'PIM-LLM: 一种用于1比特大语言模型的高吞吐量混合PIM架构'}
{'arxiv_id': 'arXiv:2504.01992', 'title': 'Exploring the Societal and Economic Impacts of Artificial Intelligence: A Scenario Generation Methodology', 'authors': 'Carlos J. Costa, Joao Tiago Aparicio', 'link': 'https://arxiv.org/abs/2504.01992', 'abstract': "This paper explores artificial intelligence's potential societal and economic impacts (AI) through generating scenarios that assess how AI may influence various sectors. We categorize and analyze key factors affecting AI's integration and adoption by applying an Impact-Uncertainty Matrix. A proposed methodology involves querying academic databases, identifying emerging trends and topics, and categorizing these into an impact uncertainty framework. The paper identifies critical areas where AI may bring significant change and outlines potential future scenarios based on these insights. This research aims to inform policymakers, industry leaders, and researchers on the strategic planning required to address the challenges and opportunities AI presents", 'abstract_zh': '本文通过生成情景来探讨人工智能在社会和经济领域的潜在影响（AI），分析AI融入和 Adoption 的关键因素，并将其分类和分析应用到影响-不确定性矩阵中。提出的 methodology 包括查询学术数据库、识别新兴趋势和主题，并将这些内容分类到影响不确定性框架中。本文确定了 AI 可能带来重大变革的关键领域，并基于这些洞察预测潜在的未来情景。此项研究旨在为政策制定者、行业领袖和研究人员提供关于应对 AI 带来的挑战和机遇所需的战略规划信息。', 'title_zh': '探索人工智能的社会与经济影响：一种情景生成方法论'}
{'arxiv_id': 'arXiv:2504.01986', 'title': 'TuRTLe: A Unified Evaluation of LLMs for RTL Generation', 'authors': "Dario Garcia-Gasulla, Gokcen Kestor, Emanuele Parisi, Miquel Albert'i-Binimelis, Cristian Gutierrez, Razine Moundir Ghorab, Orlando Montenegro, Bernat Homs, Miquel Moreto", 'link': 'https://arxiv.org/abs/2504.01986', 'abstract': 'The rapid advancements in LLMs have driven the adoption of generative AI in various domains, including Electronic Design Automation (EDA). Unlike traditional software development, EDA presents unique challenges, as generated RTL code must not only be syntactically correct and functionally accurate but also synthesizable by hardware generators while meeting performance, power, and area constraints. These additional requirements introduce complexities that existing code-generation benchmarks often fail to capture, limiting their effectiveness in evaluating LLMs for RTL generation. To address this gap, we propose TuRTLe, a unified evaluation framework designed to systematically assess LLMs across key RTL generation tasks. TuRTLe integrates multiple existing benchmarks and automates the evaluation process, enabling a comprehensive assessment of LLM performance in syntax correctness, functional correctness, synthesis, PPA optimization, and exact line completion. Using this framework, we benchmark a diverse set of open LLMs and analyze their strengths and weaknesses in EDA-specific tasks. Our results show that reasoning-based models, such as DeepSeek R1, consistently outperform others across multiple evaluation criteria, but at the cost of increased computational overhead and inference latency. Additionally, base models are better suited in module completion tasks, while instruct-tuned models perform better in specification-to-RTL tasks.', 'abstract_zh': 'LLMs迅猛发展推动了生成式AI在电子设计自动化(EDA)领域的应用。与传统软件开发不同，EDA面临着独特的挑战，生成的RTL代码不仅需要语法正确、功能准确，还需要能够被硬件合成器合成，并满足性能、功耗和面积的约束。这些额外的要求使得现有的代码生成基准往往无法完全捕捉到这些复杂性，限制了它们在评价LLMs在RTL生成方面的有效性。为弥补这一短板，我们提出了TuRTLe，一个统一的评价框架，旨在系统地评估LLMs在关键RTL生成任务中的性能。TuRTLe集成了多个现有的基准，并自动化了评价过程，能够全面评估LLMs在语法正确性、功能正确性、合成、PPA优化和精确行完成等方面的性能。利用此框架，我们对多种开源LLMs进行了基准测试，并分析了它们在EDA特定任务中的强项和弱点。结果显示，基于推理的模型，如DeepSeek R1，在多个评价标准中持续表现出色，但需要增加计算开销和推理延迟。此外，基础模型更适合模块完成任务，而指令调优模型在规格到RTL任务中表现更好。', 'title_zh': 'TuRTLe: LLMs for RTL Generation 的统一评估'}
{'arxiv_id': 'arXiv:2504.01985', 'title': 'Multi-Dimensional AGV Path Planning in 3D Warehouses Using Ant Colony Optimization and Advanced Neural Networks', 'authors': 'Bo Zhang, Xiubo Liang, Wei Song, Yulu Chen', 'link': 'https://arxiv.org/abs/2504.01985', 'abstract': 'Within modern warehouse scenarios, the rapid expansion of e-commerce and increasingly complex, multi-level storage environments have exposed the limitations of traditional AGV (Automated Guided Vehicle) path planning methods--often reliant on static 2D models and expert-tuned heuristics that struggle to handle dynamic traffic and congestion. Addressing these limitations, this paper introduces a novel AGV path planning approach for 3D warehouse environments that leverages a hybrid framework combining ACO (Ant Colony Optimization) with deep learning models, called NAHACO (Neural Adaptive Heuristic Ant Colony Optimization). NAHACO integrates three key innovations: first, an innovative heuristic algorithm for 3D warehouse cargo modeling using multidimensional tensors, which addresses the challenge of achieving superior heuristic accuracy; second, integration of a congestion-aware loss function within the ACO framework to adjust path costs based on traffic and capacity constraints, called CARL (Congestion-Aware Reinforce Loss), enabling dynamic heuristic calibration for optimizing ACO-based path planning; and third, an adaptive attention mechanism that captures multi-scale spatial features, thereby addressing dynamic heuristic calibration for further optimization of ACO-based path planning and AGV navigation. NAHACO significantly boosts path planning efficiency, yielding faster computation times and superior performance over both vanilla and state-of-the-art methods, while automatically adapting to warehouse constraints for real-time optimization. NAHACO outperforms state-of-the-art methods, lowering the total cost by up to 24.7% on TSP benchmarks. In warehouse tests, NAHACO cuts cost by up to 41.5% and congestion by up to 56.1% compared to previous methods.', 'abstract_zh': '基于ACO与深度学习的神经自适应蚁群优化算法（NAHACO）在3D仓储环境中的路径规划方法', 'title_zh': '基于蚁群优化和高级神经网络的三维仓库多维度AGV路径规划'}
{'arxiv_id': 'arXiv:2504.01981', 'title': 'NLS: Natural-Level Synthesis for Hardware Implementation Through GenAI', 'authors': 'Kaiyuan Yang, Huang Ouyang, Xinyi Wang, Bingjie Lu, Yanbo Wang, Charith Abhayaratne, Sizhao Li, Long Jin, Tiantai Deng', 'link': 'https://arxiv.org/abs/2504.01981', 'abstract': "This paper introduces Natural-Level Synthesis, an innovative approach for generating hardware using generative artificial intelligence on both the system level and component-level. NLS bridges a gap in current hardware development processes, where algorithm and application engineers' involvement typically ends at the requirements stage. With NLS, engineers can participate more deeply in the development, synthesis, and test stages by using Gen-AI models to convert natural language descriptions directly into Hardware Description Language code. This approach not only streamlines hardware development but also improves accessibility, fostering a collaborative workflow between hardware and algorithm engineers. We developed the NLS tool to facilitate natural language-driven HDL synthesis, enabling rapid generation of system-level HDL designs while significantly reducing development complexity. Evaluated through case studies and benchmarks using Performance, Power, and Area metrics, NLS shows its potential to enhance resource efficiency in hardware development. This work provides a extensible, efficient solution for hardware synthesis and establishes a Visual Studio Code Extension to assess Gen-AI-driven HDL generation and system integration, laying a foundation for future AI-enhanced and AI-in-the-loop Electronic Design Automation tools.", 'abstract_zh': '自然水平合成：一种使用生成人工智能进行系统级和组件级硬件生成的新方法', 'title_zh': 'NLS：通过生成式人工智能实现硬件级别的自然水平合成'}
{'arxiv_id': 'arXiv:2504.01980', 'title': 'Information Gain Is Not All You Need', 'authors': 'Ludvig Ericson, José Pedro, Patric Jensfelt', 'link': 'https://arxiv.org/abs/2504.01980', 'abstract': 'Autonomous exploration in mobile robotics is driven by two competing objectives: coverage, to exhaustively observe the environment; and path length, to do so with the shortest path possible. Though it is difficult to evaluate the best course of action without knowing the unknown, the unknown can often be understood through models, maps, or common sense. However, previous work has shown that improving estimates of information gain through such prior knowledge leads to greedy behavior and ultimately causes backtracking, which degrades coverage performance. In fact, any information gain maximization will exhibit this behavior, even without prior knowledge. Information gained at task completion is constant, and cannot be maximized for. It is therefore an unsuitable choice as an optimization objective. Instead, information gain is a decision criterion for determining which candidate states should still be considered for exploration. The task therefore becomes to reach completion with the shortest total path. Since determining the shortest path is typically intractable, it is necessary to rely on a heuristic or estimate to identify candidate states that minimize the total path length. To address this, we propose a heuristic that reduces backtracking by preferring candidate states that are close to the robot, but far away from other candidate states. We evaluate the performance of the proposed heuristic in simulation against an information gain-based approach and frontier exploration, and show that our method significantly decreases total path length, both with and without prior knowledge of the environment.', 'abstract_zh': '自主移动机器人中的自动探索受兩個競爭目標驅動：覆蓋，以便 Exhaustively 觀察環境；和路徑長度，以便儘可能使用 shortest path。尽管在不知不了解情況下的最佳行動難以評估，但通過模型、地圖或常識可以理解不了解的部分。然而，先前的研究表明，通過先驗知識來改進信息獲取估計會導致貪婪行為，最終導致回溯，這會]*(損害覆蓋性能。事實上，任何信息獲取最大化都會表現出這種行為，即使在沒有先驗知識的情況下。任務完成時獲取的信*[息是固定的，無法最大化。因此，它不能用作優化目標的合適選擇。相反，信息獲取是確定哪些候選狀態仍然值得探索的決策標準。因此，任務成為使用最短總路徑完成任务。由於確定最短路徑通常是不可解的，因此需要依靠启发式方法或估計來識別最小化總路徑長度的候選狀態。為此，我們提出了一種启发式方法，通过优选距离机器人较近但与其他候選状态较远的候選状态，来減少回溯行为。我们将提出的启发式方法在仿真中与基于信息获取的方法和前沿探索方法进行了性能评估，并展示了在有无环境先验知识的情况下，我们的方法显著降低了总路径长度。', 'title_zh': '信息增益并非万能'}
{'arxiv_id': 'arXiv:2504.01979', 'title': 'Correlation-Attention Masked Temporal Transformer for User Identity Linkage Using Heterogeneous Mobility Data', 'authors': 'Ziang Yan, Xingyu Zhao, Hanqing Ma, Wei Chen, Jianpeng Qi, Yanwei Yu, Junyu Dong', 'link': 'https://arxiv.org/abs/2504.01979', 'abstract': "With the rise of social media and Location-Based Social Networks (LBSN), check-in data across platforms has become crucial for User Identity Linkage (UIL). These data not only reveal users' spatio-temporal information but also provide insights into their behavior patterns and interests. However, cross-platform identity linkage faces challenges like poor data quality, high sparsity, and noise interference, which hinder existing methods from extracting cross-platform user information. To address these issues, we propose a Correlation-Attention Masked Transformer for User Identity Linkage Network (MT-Link), a transformer-based framework to enhance model performance by learning spatio-temporal co-occurrence patterns of cross-platform users. Our model effectively captures spatio-temporal co-occurrence in cross-platform user check-in sequences. It employs a correlation attention mechanism to detect the spatio-temporal co-occurrence between user check-in sequences. Guided by attention weight maps, the model focuses on co-occurrence points while filtering out noise, ultimately improving classification performance. Experimental results show that our model significantly outperforms state-of-the-art baselines by 12.92%~17.76% and 5.80%~8.38% improvements in terms of Macro-F1 and Area Under Curve (AUC).", 'abstract_zh': '基于相关性注意机制掩码变压器的用户身份链接网络（MT-Link）', 'title_zh': '基于异质移动数据的用户身份关联的相关-注意力掩蔽时序变换器'}
{'arxiv_id': 'arXiv:2504.01973', 'title': 'Universally applicable and tunable graph-based coarse-graining for Machine learning force fields', 'authors': "Christoph Brunken, Sebastien Boyer, Mustafa Omar, Martin Maarand, Olivier Peltre, Solal Attias, Bakary N'tji Diallo, Anastasia Markina, Olaf Othersen, Oliver Bent", 'link': 'https://arxiv.org/abs/2504.01973', 'abstract': 'Coarse-grained (CG) force field methods for molecular systems are a crucial tool to simulate large biological macromolecules and are therefore essential for characterisations of biomolecular systems. While state-of-the-art deep learning (DL)-based models for all-atom force fields have improved immensely over recent years, we observe and analyse significant limitations of the currently available approaches for DL-based CG simulations. In this work, we present the first transferable DL-based CG force field approach (i.e., not specific to only one narrowly defined system type) applicable to a wide range of biosystems. To achieve this, our CG algorithm does not rely on hard-coded rules and is tuned to output coarse-grained systems optimised for minimal statistical noise in the ground truth CG forces, which results in significant improvement of model training. Our force field model is also the first CG variant that is based on the MACE architecture and is trained on a custom dataset created by a new approach based on the fragmentation of large biosystems covering protein, RNA and lipid chemistry. We demonstrate that our model can be applied in molecular dynamics simulations to obtain stable and qualitatively accurate trajectories for a variety of systems, while also discussing cases for which we observe limited reliability.', 'abstract_zh': '粗粒化（CG）力场方法在分子系统中的应用对于模拟大型生物大分子至关重要，因此对于生物分子系统的表征至关重要。尽管基于深度学习（DL）的原子力场模型在近年来取得了显著进步，但我们观察并分析了当前可用的DL基粗粒化方法的重要局限性。在此工作中，我们提出了首个适用于广泛生物系统的可转移DL基粗粒化力场方法（即，不限于单一狭义系统类型）。为了实现这一点，我们的粗粒化算法不依赖于硬编码规则，并且是为在真实CG力最小的统计噪声下优化输出粗粒化系统而调整的，从而显著改进了模型训练。此外，我们的力场模型是首个基于MACE架构的CG变体，并在一种新的基于大型生物系统碎片化方法创建的自定义数据集上进行了训练，涵盖了蛋白质、RNA和脂质化学。我们证明，该模型可以应用于分子动力学模拟，以获得多种系统的稳定且定性准确的轨迹，并讨论了一些我们观察到可靠性有限的情况。', 'title_zh': '基于图的通用可调粗粒化方法在机器学习力场中的应用'}
{'arxiv_id': 'arXiv:2504.01970', 'title': 'Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow', 'authors': 'Andrew Rosemberg, Michael Klamkin', 'link': 'https://arxiv.org/abs/2504.01970', 'abstract': "The growing scale of power systems and the increasing uncertainty introduced by renewable energy sources necessitates novel optimization techniques that are significantly faster and more accurate than existing methods. The AC Optimal Power Flow (AC-OPF) problem, a core component of power grid optimization, is often approximated using linearized DC Optimal Power Flow (DC-OPF) models for computational tractability, albeit at the cost of suboptimal and inefficient decisions. To address these limitations, we propose a novel deep learning-based framework for network equivalency that enhances DC-OPF to more closely mimic the behavior of AC-OPF. The approach utilizes recent advances in differentiable optimization, incorporating a neural network trained to predict adjusted nodal shunt conductances and branch susceptances in order to account for nonlinear power flow behavior. The model can be trained end-to-end using modern deep learning frameworks by leveraging the implicit function theorem. Results demonstrate the framework's ability to significantly improve prediction accuracy, paving the way for more reliable and efficient power systems.", 'abstract_zh': '随着电力系统规模的扩大和可再生能源引入的不确定性增加，亟需比现有方法更快更准确的新优化技术。AC最优功率流（AC-OPF）问题是电力网络优化的核心组成部分，通常为了计算上的可操作性，通过线性化的直流最优功率流（DC-OPF）模型进行近似，但会导致次优和低效的决策。为此，我们提出了一种基于深度学习的网络等效新框架，以使DC-OPF更接近模拟AC-OPF的行为。该方法利用可微优化的最新进展，结合一个经过训练以预测调整节点分流和支路电纳的神经网络，以考虑非线性功率流行为。该模型可以通过利用隐函数定理使用现代深度学习框架进行端到端训练。结果表明，该框架能够显著提高预测准确性，为更可靠和高效的电力系统铺平了道路。', 'title_zh': '基于可微优化的深度学习增强的交流最优功率流的DC逼近'}
{'arxiv_id': 'arXiv:2504.01963', 'title': 'LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems', 'authors': 'R. M. Aratchige, W. M. K. S. Ilmini', 'link': 'https://arxiv.org/abs/2504.01963', 'abstract': 'This survey investigates foundational technologies essential for developing effective Large Language Model (LLM)-based multi-agent systems. Aiming to answer how best to optimize these systems for collaborative, dynamic environments, we focus on four critical areas: Architecture, Memory, Planning, and Technologies/Frameworks. By analyzing recent advancements and their limitations - such as scalability, real-time response challenges, and agent coordination constraints, we provide a detailed view of the technological landscape. Frameworks like the Mixture of Agents architecture and the ReAct planning model exemplify current innovations, showcasing improvements in role assignment and decision-making. This review synthesizes key strengths and persistent challenges, offering practical recommendations to enhance system scalability, agent collaboration, and adaptability. Our findings provide a roadmap for future research, supporting the creation of robust, efficient multi-agent systems that advance both individual agent performance and collective system resilience.', 'abstract_zh': '本调查探讨了开发有效的大型语言模型（LLM）基于的多agent系统所需的基础技术。着眼于如何最佳地优化这些系统以适应协作和动态环境，我们专注于四大关键领域：架构、内存、规划和技术/框架。通过分析近期的进步及其局限性，如可扩展性、实时响应挑战以及agent协调约束，我们提供了一个详细的技术景观图。诸如Mixture of Agents架构和ReAct规划模型等框架体现了当前的创新，展示了在角色分配和决策方面取得的改进。本综述综合了关键优势和持续挑战，并提供了实用建议以提高系统的可扩展性、agent间的协作和适应性。我们的发现为未来研究提供了一条路线图，支持创建既强大又高效的多agent系统，从而提高个体agent性能和集体系统韧性。', 'title_zh': 'LLMs和谐共进：基于大规模语言模型的多代理系统技术综述'}
