{'arxiv_id': 'arXiv:2508.14706', 'title': 'ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine', 'authors': 'Junying Chen, Zhenyang Cai, Zhiheng Liu, Yunjin Yang, Rongsheng Wang, Qingying Xiao, Xiangyi Feng, Zhan Su, Jing Guo, Xiang Wan, Guangjun Yu, Haizhou Li, Benyou Wang', 'link': 'https://arxiv.org/abs/2508.14706', 'abstract': 'Despite the success of large language models (LLMs) in various domains, their potential in Traditional Chinese Medicine (TCM) remains largely underexplored due to two critical barriers: (1) the scarcity of high-quality TCM data and (2) the inherently multimodal nature of TCM diagnostics, which involve looking, listening, smelling, and pulse-taking. These sensory-rich modalities are beyond the scope of conventional LLMs. To address these challenges, we present ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and physiological signals. ShizhenGPT is pretrained and instruction-tuned to achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect recent national TCM qualification exams and build a visual benchmark for Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that ShizhenGPT outperforms comparable-scale LLMs and competes with larger proprietary models. Moreover, it leads in TCM visual understanding among existing multimodal LLMs and demonstrates unified perception across modalities like sound, pulse, smell, and vision, paving the way toward holistic multimodal perception and diagnosis in TCM. Datasets, models, and code are publicly available. We hope this work will inspire further exploration in this field.', 'abstract_zh': '尽管大型语言模型（LLMs）在各个领域取得了成功，但在传统中医（TCM）领域的潜力仍因两大关键障碍而未得到充分探索：（1）高质量TCM数据稀缺；（2）TCM诊断的固有多模态性质，涉及到看、听、闻和切脉。这些富含感官信息的模态超出了传统LLMs的功能范围。为应对这些挑战，我们提出了ShizhenGPT，这是首个专门为TCM设计的多模态LLM。为克服数据稀缺问题，我们编纂了迄今为止最大规模的TCM数据集，包含超过100GB的文本和超过200GB的多模态数据，其中包括120万张图像、200小时的音频和生理信号。ShizhenGPT进行预训练和指令调整，以实现深厚的TCM知识和多模态推理。为评估效果，我们收集了最新的国家级TCM资格考试，并建立了一个视觉基准用于药用识别和视觉诊断。实验表明，ShizhenGPT优于同等规模的LLMs，并能与更大的专属模型竞争。此外，ShizhenGPT在现有多模态LLMs中领先于TCM视觉理解，并展示了横跨听觉、脉搏、嗅觉和视觉等模态的统一感知能力，为TCM的全貌多模态感知和诊断铺平了道路。数据集、模型和代码已公开。我们希望这项工作能激发更多对该领域的探索。', 'title_zh': '.shizhenGPT:向量跨模态中医药大型语言模型'}
{'arxiv_id': 'arXiv:2508.14395', 'title': 'NoteIt: A System Converting Instructional Videos to Interactable Notes Through Multimodal Video Understanding', 'authors': 'Running Zhao, Zhihan Jiang, Xinchen Zhang, Chirui Chang, Handi Chen, Weipeng Deng, Luyao Jin, Xiaojuan Qi, Xun Qian, Edith C.H. Ngai', 'link': 'https://arxiv.org/abs/2508.14395', 'abstract': "Users often take notes for instructional videos to access key knowledge later without revisiting long videos. Automated note generation tools enable users to obtain informative notes efficiently. However, notes generated by existing research or off-the-shelf tools fail to preserve the information conveyed in the original videos comprehensively, nor can they satisfy users' expectations for diverse presentation formats and interactive features when using notes digitally. In this work, we present NoteIt, a system, which automatically converts instructional videos to interactable notes using a novel pipeline that faithfully extracts hierarchical structure and multimodal key information from videos. With NoteIt's interface, users can interact with the system to further customize the content and presentation formats of the notes according to their preferences. We conducted both a technical evaluation and a comparison user study (N=36). The solid performance in objective metrics and the positive user feedback demonstrated the effectiveness of the pipeline and the overall usability of NoteIt. Project website: this https URL", 'abstract_zh': '用户常常为 instructional videos 做笔记以在后续访问关键知识时不再观看长视频。自动笔记生成工具使用户能够高效地获取有信息量的笔记。然而，现有研究或即用型工具生成的笔记未能全面保留原始视频中的信息，也无法满足用户在数字环境下对多样化呈现格式和交互功能的需求。在本工作中，我们提出了 NoteIt 系统，该系统使用一种新颖的工作流程，自动将 instructional videos 转换为可交互的笔记，并忠实提取视频中的层次结构和多元模态关键信息。通过 NoteIt 的界面，用户可以根据自己的偏好进一步自定义笔记的内容和呈现格式。我们进行了技术评估和比较用户研究（N=36）。客观指标的良好表现和积极的用户反馈证明了该工作流程的有效性和 NoteIt 的整体易用性。项目网址：this https URL。', 'title_zh': 'NoteIt: 一种通过多模态视频理解将 instructional videos 转换为可交互笔记的系统'}
