# FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy 

**Title (ZH)**: FBI：学习动态视触捷径策略的在手灵巧操作 

**Authors**: Yijin Chen, Wenqiang Xu, Zhenjun Yu, Tutian Tang, Yutong Li, Siqiong Yao, Cewu Lu  

**Link**: [PDF](https://arxiv.org/pdf/2508.14441)  

**Abstract**: Dexterous in-hand manipulation is a long-standing challenge in robotics due to complex contact dynamics and partial observability. While humans synergize vision and touch for such tasks, robotic approaches often prioritize one modality, therefore limiting adaptability. This paper introduces Flow Before Imitation (FBI), a visuotactile imitation learning framework that dynamically fuses tactile interactions with visual observations through motion dynamics. Unlike prior static fusion methods, FBI establishes a causal link between tactile signals and object motion via a dynamics-aware latent model. FBI employs a transformer-based interaction module to fuse flow-derived tactile features with visual inputs, training a one-step diffusion policy for real-time execution. Extensive experiments demonstrate that the proposed method outperforms the baseline methods in both simulation and the real world on two customized in-hand manipulation tasks and three standard dexterous manipulation tasks. Code, models, and more results are available in the website this https URL. 

**Abstract (ZH)**: 手部灵巧 manipulation 是由于复杂接触动力学和部分可观测性而在机器人领域长期存在的挑战。虽然人类通过视觉和触觉协同完成这些任务，但机器人方法往往优先考虑一种模态，从而限制了适应性。本文介绍了一种名为 Flow Before Imitation (FBI) 的联合触觉模仿学习框架，该框架通过运动动力学动态融合触觉交互和视觉观测。与之前静态融合方法不同，FBI 通过动力学感知的潜在模型建立了触觉信号与物体运动之间的因果关系。FBI 使用基于变换器的交互模块将基于流动的触觉特征与视觉输入融合，并训练了一步扩散策略以实现实时执行。广泛的实验结果表明，在两个定制的手部灵巧 manipulation 任务和三个标准灵巧 manipulation 任务上，所提出的方法在仿真和现实世界中均优于基线方法。更多代码、模型和实验结果可在以下网址获取 this https URL。 

---
# Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations 

**Title (ZH)**: 基于任意演示的离线模仿学习通过先训练动力学表示 

**Authors**: Haitong Ma, Bo Dai, Zhaolin Ren, Yebin Wang, Na Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.14383)  

**Abstract**: Limited data has become a major bottleneck in scaling up offline imitation learning (IL). In this paper, we propose enhancing IL performance under limited expert data by introducing a pre-training stage that learns dynamics representations, derived from factorizations of the transition dynamics. We first theoretically justify that the optimal decision variable of offline IL lies in the representation space, significantly reducing the parameters to learn in the downstream IL. Moreover, the dynamics representations can be learned from arbitrary data collected with the same dynamics, allowing the reuse of massive non-expert data and mitigating the limited data issues. We present a tractable loss function inspired by noise contrastive estimation to learn the dynamics representations at the pre-training stage. Experiments on MuJoCo demonstrate that our proposed algorithm can mimic expert policies with as few as a single trajectory. Experiments on real quadrupeds show that we can leverage pre-trained dynamics representations from simulator data to learn to walk from a few real-world demonstrations. 

**Abstract (ZH)**: 在有限专家数据下通过预训练增强离线 imitation learning 性能的研究 

---
# Action-Constrained Imitation Learning 

**Title (ZH)**: 动作约束 imitation 学习 

**Authors**: Chia-Han Yeh, Tse-Sheng Nan, Risto Vuorio, Wei Hung, Hung-Yen Wu, Shao-Hua Sun, Ping-Chun Hsieh  

**Link**: [PDF](https://arxiv.org/pdf/2508.14379)  

**Abstract**: Policy learning under action constraints plays a central role in ensuring safe behaviors in various robot control and resource allocation applications. In this paper, we study a new problem setting termed Action-Constrained Imitation Learning (ACIL), where an action-constrained imitator aims to learn from a demonstrative expert with larger action space. The fundamental challenge of ACIL lies in the unavoidable mismatch of occupancy measure between the expert and the imitator caused by the action constraints. We tackle this mismatch through \textit{trajectory alignment} and propose DTWIL, which replaces the original expert demonstrations with a surrogate dataset that follows similar state trajectories while adhering to the action constraints. Specifically, we recast trajectory alignment as a planning problem and solve it via Model Predictive Control, which aligns the surrogate trajectories with the expert trajectories based on the Dynamic Time Warping (DTW) distance. Through extensive experiments, we demonstrate that learning from the dataset generated by DTWIL significantly enhances performance across multiple robot control tasks and outperforms various benchmark imitation learning algorithms in terms of sample efficiency. Our code is publicly available at this https URL. 

**Abstract (ZH)**: 带动作约束的模仿学习在确保各类机器人控制和资源分配应用中的安全行为中起着关键作用。在本文中，我们研究了一种新的问题设定，称为带动作约束的模仿学习（ACIL），其中带动作约束的模仿者旨在从具有更大动作空间的示范专家那里学习。ACIL的基本挑战在于由动作约束引起的专家和模仿者之间的不可避免的态势分布不匹配。我们通过轨迹对齐来应对这种不匹配，并提出DTWIL，它用一个遵循相似状态轨迹同时遵守动作约束的替代数据集来替换原始专家示范。具体而言，我们将轨迹对齐重新定义为一个规划问题，并通过模型预测控制来解决，基于动态时间规整（DTW）距离对替代轨迹进行对齐。通过广泛的实验，我们证明了通过DTWIL生成的数据集在多种机器人控制任务中显著提升了性能，并在样本效率方面优于各种基准模仿学习算法。我们的代码可在如下链接公开获取：this https URL。 

---
# SimGenHOI: Physically Realistic Whole-Body Humanoid-Object Interaction via Generative Modeling and Reinforcement Learning 

**Title (ZH)**: SimGenHOI: 通过生成建模和强化学习实现的物理真实人体形态人偶与物体交互 

**Authors**: Yuhang Lin, Yijia Xie, Jiahong Xie, Yuehao Huang, Ruoyu Wang, Jiajun Lv, Yukai Ma, Xingxing Zuo  

**Link**: [PDF](https://arxiv.org/pdf/2508.14120)  

**Abstract**: Generating physically realistic humanoid-object interactions (HOI) is a fundamental challenge in robotics. Existing HOI generation approaches, such as diffusion-based models, often suffer from artifacts such as implausible contacts, penetrations, and unrealistic whole-body actions, which hinder successful execution in physical environments. To address these challenges, we introduce SimGenHOI, a unified framework that combines the strengths of generative modeling and reinforcement learning to produce controllable and physically plausible HOI. Our HOI generative model, based on Diffusion Transformers (DiT), predicts a set of key actions conditioned on text prompts, object geometry, sparse object waypoints, and the initial humanoid pose. These key actions capture essential interaction dynamics and are interpolated into smooth motion trajectories, naturally supporting long-horizon generation. To ensure physical realism, we design a contact-aware whole-body control policy trained with reinforcement learning, which tracks the generated motions while correcting artifacts such as penetration and foot sliding. Furthermore, we introduce a mutual fine-tuning strategy, where the generative model and the control policy iteratively refine each other, improving both motion realism and tracking robustness. Extensive experiments demonstrate that SimGenHOI generates realistic, diverse, and physically plausible humanoid-object interactions, achieving significantly higher tracking success rates in simulation and enabling long-horizon manipulation tasks. Code will be released upon acceptance on our project page: this https URL. 

**Abstract (ZH)**: 生成物理上真实的类人物体交互（HOI）是机器人学中的一个基础挑战。现有的HOI生成方法，如基于扩散的模型，常常受到不合理接触、穿透和不现实的整体动作等瑕疵的影响，这阻碍了在物理环境中成功的执行。为解决这些挑战，我们引入了SimGenHOI，这是一种结合生成建模和强化学习优势的统一框架，用于生成可控且物理上合理的HOI。我们的HOI生成模型基于扩散变换器（DiT），在文本提示、物体几何、稀疏物体航点以及初始类人姿态的条件下预测一系列关键动作。这些关键动作捕捉了关键的交互动态，并被插值为平滑的运动轨迹，自然支持长时间段的生成。为确保物理真实性，我们设计了一种基于接触感知的全身控制策略，该策略通过强化学习训练，跟踪生成的运动并修正诸如穿透和脚滑等瑕疵。此外，我们提出了一个互训策略，生成模型和控制策略在生成和跟踪中迭代地相互提高，增强运动的真实性和跟踪鲁棒性。广泛的实验表明，SimGenHOI能够生成逼真、多样且物理上合理的类人物体交互，在模拟中显著提高跟踪成功率，并能够执行长时间段的操作任务。代码将在接受后在我们的项目页面发布：this https URL。 

---
# Efficient Environment Design for Multi-Robot Navigation via Continuous Control 

**Title (ZH)**: 多机器人导航的连续控制高效环境设计 

**Authors**: Jahid Chowdhury Choton, John Woods, William Hsu  

**Link**: [PDF](https://arxiv.org/pdf/2508.14105)  

**Abstract**: Multi-robot navigation and path planning in continuous state and action spaces with uncertain environments remains an open challenge. Deep Reinforcement Learning (RL) is one of the most popular paradigms for solving this task, but its real-world application has been limited due to sample inefficiency and long training periods. Moreover, the existing works using RL for multi-robot navigation lack formal guarantees while designing the environment. In this paper, we introduce an efficient and highly customizable environment for continuous-control multi-robot navigation, where the robots must visit a set of regions of interest (ROIs) by following the shortest paths. The task is formally modeled as a Markov Decision Process (MDP). We describe the multi-robot navigation task as an optimization problem and relate it to finding an optimal policy for the MDP. We crafted several variations of the environment and measured the performance using both gradient and non-gradient based RL methods: A2C, PPO, TRPO, TQC, CrossQ and ARS. To show real-world applicability, we deployed our environment to a 3-D agricultural field with uncertainties using the CoppeliaSim robot simulator and measured the robustness by running inference on the learned models. We believe our work will guide the researchers on how to develop MDP-based environments that are applicable to real-world systems and solve them using the existing state-of-the-art RL methods with limited resources and within reasonable time periods. 

**Abstract (ZH)**: 连续状态和动作空间以及不确定环境中多机器人导航和路径规划的研究仍然是一个开放的挑战。基于深度强化学习的连续控制多机器人导航高效自定义环境及其应用 

---
# Domain Translation of a Soft Robotic Arm using Conditional Cycle Generative Adversarial Network 

**Title (ZH)**: 基于条件周期生成对抗网络的软质机械臂域翻译 

**Authors**: Nilay Kushawaha, Carlo Alessi, Lorenzo Fruzzetti, Egidio Falotico  

**Link**: [PDF](https://arxiv.org/pdf/2508.14100)  

**Abstract**: Deep learning provides a powerful method for modeling the dynamics of soft robots, offering advantages over traditional analytical approaches that require precise knowledge of the robot's structure, material properties, and other physical characteristics. Given the inherent complexity and non-linearity of these systems, extracting such details can be challenging. The mappings learned in one domain cannot be directly transferred to another domain with different physical properties. This challenge is particularly relevant for soft robots, as their materials gradually degrade over time. In this paper, we introduce a domain translation framework based on a conditional cycle generative adversarial network (CCGAN) to enable knowledge transfer from a source domain to a target domain. Specifically, we employ a dynamic learning approach to adapt a pose controller trained in a standard simulation environment to a domain with tenfold increased viscosity. Our model learns from input pressure signals conditioned on corresponding end-effector positions and orientations in both domains. We evaluate our approach through trajectory-tracking experiments across five distinct shapes and further assess its robustness under noise perturbations and periodicity tests. The results demonstrate that CCGAN-GP effectively facilitates cross-domain skill transfer, paving the way for more adaptable and generalizable soft robotic controllers. 

**Abstract (ZH)**: 基于条件周期生成对抗网络的领域转移框架：软体机器人跨域技能迁移 

---
# Task and Motion Planning for Humanoid Loco-manipulation 

**Title (ZH)**: humanoid 任务与运动规划 

**Authors**: Michal Ciebielski, Victor Dhédin, Majid Khadiv  

**Link**: [PDF](https://arxiv.org/pdf/2508.14099)  

**Abstract**: This work presents an optimization-based task and motion planning (TAMP) framework that unifies planning for locomotion and manipulation through a shared representation of contact modes. We define symbolic actions as contact mode changes, grounding high-level planning in low-level motion. This enables a unified search that spans task, contact, and motion planning while incorporating whole-body dynamics, as well as all constraints between the robot, the manipulated object, and the environment. Results on a humanoid platform show that our method can generate a broad range of physically consistent loco-manipulation behaviors over long action sequences requiring complex reasoning. To the best of our knowledge, this is the first work that enables the resolution of an integrated TAMP formulation with fully acyclic planning and whole body dynamics with actuation constraints for the humanoid loco-manipulation problem. 

**Abstract (ZH)**: 基于优化的任务与运动规划框架：通过共享的接触模式表示实现 locomotion 和 manipulation 的统一规划 

---
# No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets 

**Title (ZH)**: 不再僵硬行进：学习面向短距离SE(2)目标的人形机器人运动学 

**Authors**: Pranay Dugar, Mohitvishnu S. Gadde, Jonah Siekmann, Yesh Godse, Aayam Shrestha, Alan Fern  

**Link**: [PDF](https://arxiv.org/pdf/2508.14098)  

**Abstract**: Humanoids operating in real-world workspaces must frequently execute task-driven, short-range movements to SE(2) target poses. To be practical, these transitions must be fast, robust, and energy efficient. While learning-based locomotion has made significant progress, most existing methods optimize for velocity-tracking rather than direct pose reaching, resulting in inefficient, marching-style behavior when applied to short-range tasks. In this work, we develop a reinforcement learning approach that directly optimizes humanoid locomotion for SE(2) targets. Central to this approach is a new constellation-based reward function that encourages natural and efficient target-oriented movement. To evaluate performance, we introduce a benchmarking framework that measures energy consumption, time-to-target, and footstep count on a distribution of SE(2) goals. Our results show that the proposed approach consistently outperforms standard methods and enables successful transfer from simulation to hardware, highlighting the importance of targeted reward design for practical short-range humanoid locomotion. 

**Abstract (ZH)**: 真实世界工作空间中的人形机器人必须频繁执行任务驱动的短距离SE(2)目标位姿移动。为了实用，这些转换必须快速、稳健且能效高。尽管基于学习的移动已取得显著进展，但现有大多数方法优化的是速度跟踪而非直接位姿达到，导致应用于短距离任务时行为效率低下且步伐僵硬。在这项工作中，我们开发了一种强化学习方法，直接优化人形机器人移动以达到SE(2)目标。该方法的核心是一种新的星座基奖励函数，鼓励自然且高效的目标导向移动。为了评估性能，我们引入了一种基准框架，该框架在一系列SE(2)目标上衡量能耗、达到目标时间和步数。实验结果表明，所提出的方法始终优于标准方法，并成功实现了从模拟到硬件的迁移，突显了针对实际短距离人形移动的奖励设计的重要性。 

---
# Virtual Community: An Open World for Humans, Robots, and Society 

**Title (ZH)**: 虚拟社区：人类、机器人与社会的开放世界 

**Authors**: Qinhong Zhou, Hongxin Zhang, Xiangye Lin, Zheyuan Zhang, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen, Lixing Fang, Qiushi Lyu, Xinyu Sun, Jincheng Yang, Zeyuan Wang, Bao Chi Dang, Zhehuan Chen, Daksha Ladia, Jiageng Liu, Chuang Gan  

**Link**: [PDF](https://arxiv.org/pdf/2508.14893)  

**Abstract**: The rapid progress in AI and Robotics may lead to a profound societal transformation, as humans and robots begin to coexist within shared communities, introducing both opportunities and challenges. To explore this future, we present Virtual Community-an open-world platform for humans, robots, and society-built on a universal physics engine and grounded in real-world 3D scenes. With Virtual Community, we aim to study embodied social intelligence at scale: 1) How robots can intelligently cooperate or compete; 2) How humans develop social relations and build community; 3) More importantly, how intelligent robots and humans can co-exist in an open world. To support these, Virtual Community features: 1) An open-source multi-agent physics simulator that supports robots, humans, and their interactions within a society; 2) A large-scale, real-world aligned community generation pipeline, including vast outdoor space, diverse indoor scenes, and a community of grounded agents with rich characters and appearances. Leveraging Virtual Community, we propose two novel challenges. The Community Planning Challenge evaluates multi-agent reasoning and planning ability in open-world settings, such as cooperating to help agents with daily activities and efficiently connecting other agents. The Community Robot Challenge requires multiple heterogeneous robots to collaborate in solving complex open-world tasks. We evaluate various baselines on these tasks and demonstrate the challenges in both high-level open-world task planning and low-level cooperation controls. We hope that Virtual Community will unlock further study of human-robot coexistence within open-world environments. 

**Abstract (ZH)**: AI和机器人技术的迅速发展可能导致社会深刻的转型，人类和机器人开始在共享社区中共存，带来机遇和挑战。为探索这一未来，我们提出虚拟社区——一个基于通用物理引擎且与现实世界3D场景相匹配的开放世界平台，供人类、机器人和社会使用。借助虚拟社区，我们旨在大规模研究具身社交智能：1）机器人如何智能地合作或竞争；2）人类如何发展社交关系并构建社区；3）更重要的是，智能机器人和人类如何在开放世界中共存。为此，虚拟社区具备以下功能：1）开源多智能体物理模拟器，支持机器人、人类及其在社会中的互动；2）大规模、与真实世界对齐的社区生成流水线，包括广阔的户外空间、多样的室内场景以及一个包含丰富人物和外观的真实代理群体。利用虚拟社区，我们提出了两项新颖挑战。社区规划挑战评估多智能体在开放世界中的推理和规划能力，如协作帮助代理完成日常活动和有效连接其他代理。社区机器人挑战要求多个异构机器人协作解决复杂的开放世界任务。我们在这些任务上评估了各种baseline，并展示了高层开放世界任务规划和低层协作控制的挑战。我们希望虚拟社区能够促进对开放世界环境中的人机共存研究。 

---
# Towards Unified Probabilistic Verification and Validation of Vision-Based Autonomy 

**Title (ZH)**: 基于视觉的自主性统一概率验证与验证方法研究 

**Authors**: Jordan Peper, Yan Miao, Sayan Mitra, Ivan Ruchkin  

**Link**: [PDF](https://arxiv.org/pdf/2508.14181)  

**Abstract**: Precise and comprehensive situational awareness is a critical capability of modern autonomous systems. Deep neural networks that perceive task-critical details from rich sensory signals have become ubiquitous; however, their black-box behavior and sensitivity to environmental uncertainty and distribution shifts make them challenging to verify formally. Abstraction-based verification techniques for vision-based autonomy produce safety guarantees contingent on rigid assumptions, such as bounded errors or known unique distributions. Such overly restrictive and inflexible assumptions limit the validity of the guarantees, especially in diverse and uncertain test-time environments. We propose a methodology that unifies the verification models of perception with their offline validation. Our methodology leverages interval MDPs and provides a flexible end-to-end guarantee that adapts directly to the out-of-distribution test-time conditions. We evaluate our methodology on a synthetic perception Markov chain with well-defined state estimation distributions and a mountain car benchmark. Our findings reveal that we can guarantee tight yet rigorous bounds on overall system safety. 

**Abstract (ZH)**: 现代自主系统中精确而全面的情境意识是一项关键能力。基于深度神经网络的感知技术能够从丰富的感官信号中识别出任务关键细节，但其黑箱行为及对环境不确定性和分布偏移的敏感性使其难以进行正式验证。基于抽象的视觉自主性验证技术依赖于严格的假设，如有限的误差或已知的独特分布，这些过度限制且不灵活的假设限制了保证的有效性，尤其是在多样性和不确定性的测试环境。我们提出了一种统一感知验证模型与其离线验证的方法论。该方法论利用区间MDP，并提供了灵活的端到端保证，能够直接适应超出分布的测试条件。我们通过一个定义明确状态估计分布的合成感知马尔可夫链和一个山车基准进行了评估。我们的研究发现，我们能够确保整个系统的安全性的紧致而严格的界限。 

---
# RynnEC: Bringing MLLMs into Embodied World 

**Title (ZH)**: RynnEC: 将MLLMs带入实体世界 

**Authors**: Ronghao Dang, Yuqian Yuan, Yunxuan Mao, Kehan Li, Jiangpin Liu, Zhikai Wang, Xin Li, Fan Wang, Deli Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2508.14160)  

**Abstract**: We introduce RynnEC, a video multimodal large language model designed for embodied cognition. Built upon a general-purpose vision-language foundation model, RynnEC incorporates a region encoder and a mask decoder, enabling flexible region-level video interaction. Despite its compact architecture, RynnEC achieves state-of-the-art performance in object property understanding, object segmentation, and spatial reasoning. Conceptually, it offers a region-centric video paradigm for the brain of embodied agents, providing fine-grained perception of the physical world and enabling more precise interactions. To mitigate the scarcity of annotated 3D datasets, we propose an egocentric video based pipeline for generating embodied cognition data. Furthermore, we introduce RynnEC-Bench, a region-centered benchmark for evaluating embodied cognitive capabilities. We anticipate that RynnEC will advance the development of general-purpose cognitive cores for embodied agents and facilitate generalization across diverse embodied tasks. The code, model checkpoints, and benchmark are available at: this https URL 

**Abstract (ZH)**: 我们引入了RynnEC，一个为 embodiled 认知设计的视频多模态大语言模型。基于通用的视觉-语言基础模型，RynnEC 结合了区域编码器和掩码解码器，实现了灵活的区域级视频交互。尽管具有紧凑的架构，RynnEC 在对象属性理解、对象分割和空间推理方面均取得了最先进的性能。从概念上讲，它为 embodied 代理的大脑提供了一种以区域为中心的视频范式，提供了对物理世界的精细感知并促进了更精确的交互。为缓解注释的 3D 数据集稀缺性，我们提出了一种以第一人称视频为基础的数据生成流水线，用于生成 embodiled 认知数据。此外，我们介绍了 RynnEC-Bench，一种以区域为中心的基准，用于评估 embodiled 认知能力。我们预计 RynnEC 将推动通用认知核心的发展，并促进跨多种 embodied 任务的泛化。源代码、模型检查点和基准均可在以下网址获得：this https URL。 

---
# Beyond Fixed Morphologies: Learning Graph Policies with Trust Region Compensation in Variable Action Spaces 

**Title (ZH)**: 超越固定形态：在可变动作空间中通过信任区域补偿学习图策略 

**Authors**: Thomas Gallien  

**Link**: [PDF](https://arxiv.org/pdf/2508.14102)  

**Abstract**: Trust region-based optimization methods have become foundational reinforcement learning algorithms that offer stability and strong empirical performance in continuous control tasks. Growing interest in scalable and reusable control policies translate also in a demand for morphological generalization, the ability of control policies to cope with different kinematic structures. Graph-based policy architectures provide a natural and effective mechanism to encode such structural differences. However, while these architectures accommodate variable morphologies, the behavior of trust region methods under varying action space dimensionality remains poorly understood. To this end, we conduct a theoretical analysis of trust region-based policy optimization methods, focusing on both Trust Region Policy Optimization (TRPO) and its widely used first-order approximation, Proximal Policy Optimization (PPO). The goal is to demonstrate how varying action space dimensionality influence the optimization landscape, particularly under the constraints imposed by KL-divergence or policy clipping penalties. Complementing the theoretical insights, an empirical evaluation under morphological variation is carried out using the Gymnasium Swimmer environment. This benchmark offers a systematically controlled setting for varying the kinematic structure without altering the underlying task, making it particularly well-suited to study morphological generalization. 

**Abstract (ZH)**: 基于信任域的优化方法已成为连续控制任务中提供稳定性和强大实证性能的强化学习基础算法。随着对可扩展且可重用控制策略兴趣的增长，对形态通用性的需求也随之增加，即控制策略能够应对不同的运动学结构的能力。基于图的策略架构自然且有效地编码了这些结构差异。然而，尽管这些架构能够适应变化的形态，但信任域方法在变化的动作空间维度下的行为仍知之甚少。为此，我们对基于信任域的策略优化方法进行了理论分析，重点关注信任域策略优化（TRPO）及其广泛使用的近似方法近端策略优化（PPO）。我们的目标是展示变化的动作空间维度如何影响优化景观，特别是在由KL散度或策略剪切惩罚所施加的约束下。通过Gymnasium Swimmer环境进行的经验评估补充了这些理论洞察。该基准提供了一种系统控制的变化运动学结构设置，而不改变底层任务，使其特别适用于研究形态通用性。 

---
# The Agent Behavior: Model, Governance and Challenges in the AI Digital Age 

**Title (ZH)**: 智能时代的代理行为：模型、治理与挑战 

**Authors**: Qiang Zhang, Pei Yan, Yijia Xu, Chuanpo Fu, Yong Fang, Yang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.14415)  

**Abstract**: Advancements in AI have led to agents in networked environments increasingly mirroring human behavior, thereby blurring the boundary between artificial and human actors in specific contexts. This shift brings about significant challenges in trust, responsibility, ethics, security and etc. The difficulty in supervising of agent behaviors may lead to issues such as data contamination and unclear accountability. To address these challenges, this paper proposes the "Network Behavior Lifecycle" model, which divides network behavior into 6 stages and systematically analyzes the behavioral differences between humans and agents at each stage. Based on these insights, the paper further introduces the "Agent for Agent (A4A)" paradigm and the "Human-Agent Behavioral Disparity (HABD)" model, which examine the fundamental distinctions between human and agent behaviors across 5 dimensions: decision mechanism, execution efficiency, intention-behavior consistency, behavioral inertia, and irrational patterns. The effectiveness of the model is verified through real-world cases such as red team penetration and blue team defense. Finally, the paper discusses future research directions in dynamic cognitive governance architecture, behavioral disparity quantification, and meta-governance protocol stacks, aiming to provide a theoretical foundation and technical roadmap for secure and trustworthy human-agent collaboration. 

**Abstract (ZH)**: 人工智能的进步使得网络环境中的人工智能代理越来越接近人类行为，从而在特定情境下模糊了人工与人类行为之间的界限。这一转变带来了信任、责任、伦理和安全等方面的重大挑战。由于监管代理行为的难度，可能会导致数据污染和责任不清等问题。为应对这些挑战，本文提出了“网络行为生命周期”模型，将网络行为分为六个阶段，并系统分析每个阶段人类和代理的行为差异。基于这些见解，本文进一步介绍了“代理对代理（A4A）”范式和“人类-代理行为差异（HABD）”模型，该模型从五个维度（决策机制、执行效率、意图与行为一致性、行为惯性和非理性模式）考察人类和代理行为的差异。该模型通过实际案例（如红队渗透和蓝队防御）的有效性得到了验证。最后，本文探讨了动态认知治理架构、行为差异量化和元治理协议栈等未来研究方向，旨在为安全可信的人机协作提供理论基础和技术路线图。 

---
# Cross-Modality Controlled Molecule Generation with Diffusion Language Model 

**Title (ZH)**: 跨模态控制的分子生成差分语言模型 

**Authors**: Yunzhe Zhang, Yifei Wang, Khanh Vinh Nguyen, Pengyu Hong  

**Link**: [PDF](https://arxiv.org/pdf/2508.14748)  

**Abstract**: Current SMILES-based diffusion models for molecule generation typically support only unimodal constraint. They inject conditioning signals at the start of the training process and require retraining a new model from scratch whenever the constraint changes. However, real-world applications often involve multiple constraints across different modalities, and additional constraints may emerge over the course of a study. This raises a challenge: how to extend a pre-trained diffusion model not only to support cross-modality constraints but also to incorporate new ones without retraining. To tackle this problem, we propose the Cross-Modality Controlled Molecule Generation with Diffusion Language Model (CMCM-DLM), demonstrated by two distinct cross modalities: molecular structure and chemical properties. Our approach builds upon a pre-trained diffusion model, incorporating two trainable modules, the Structure Control Module (SCM) and the Property Control Module (PCM), and operates in two distinct phases during the generation process. In Phase I, we employs the SCM to inject structural constraints during the early diffusion steps, effectively anchoring the molecular backbone. Phase II builds on this by further introducing PCM to guide the later stages of inference to refine the generated molecules, ensuring their chemical properties match the specified targets. Experimental results on multiple datasets demonstrate the efficiency and adaptability of our approach, highlighting CMCM-DLM's significant advancement in molecular generation for drug discovery applications. 

**Abstract (ZH)**: 跨模态控制分子生成的扩散语言模型（CMCM-DLM） 

---
# PB-IAD: Utilizing multimodal foundation models for semantic industrial anomaly detection in dynamic manufacturing environments 

**Title (ZH)**: PB-IAD：利用多模态基础模型在动态制造环境中进行语义工业异常检测 

**Authors**: Bernd Hofmann, Albert Scheck, Joerg Franke, Patrick Bruendl  

**Link**: [PDF](https://arxiv.org/pdf/2508.14504)  

**Abstract**: The detection of anomalies in manufacturing processes is crucial to ensure product quality and identify process deviations. Statistical and data-driven approaches remain the standard in industrial anomaly detection, yet their adaptability and usability are constrained by the dependence on extensive annotated datasets and limited flexibility under dynamic production conditions. Recent advances in the perception capabilities of foundation models provide promising opportunities for their adaptation to this downstream task. This paper presents PB-IAD (Prompt-based Industrial Anomaly Detection), a novel framework that leverages the multimodal and reasoning capabilities of foundation models for industrial anomaly detection. Specifically, PB-IAD addresses three key requirements of dynamic production environments: data sparsity, agile adaptability, and domain user centricity. In addition to the anomaly detection, the framework includes a prompt template that is specifically designed for iteratively implementing domain-specific process knowledge, as well as a pre-processing module that translates domain user inputs into effective system prompts. This user-centric design allows domain experts to customise the system flexibly without requiring data science expertise. The proposed framework is evaluated by utilizing GPT-4.1 across three distinct manufacturing scenarios, two data modalities, and an ablation study to systematically assess the contribution of semantic instructions. Furthermore, PB-IAD is benchmarked to state-of-the-art methods for anomaly detection such as PatchCore. The results demonstrate superior performance, particularly in data-sparse scenarios and low-shot settings, achieved solely through semantic instructions. 

**Abstract (ZH)**: 基于提示的工业异常检测（Prompt-based Industrial Anomaly Detection） 

---
# A Comparative Evaluation of Teacher-Guided Reinforcement Learning Techniques for Autonomous Cyber Operations 

**Title (ZH)**: 教师引导的强化学习技术在自主网络运营中的比较评估 

**Authors**: Konur Tholl, Mariam El Mezouar, Ranwa Al Mallah  

**Link**: [PDF](https://arxiv.org/pdf/2508.14340)  

**Abstract**: Autonomous Cyber Operations (ACO) rely on Reinforcement Learning (RL) to train agents to make effective decisions in the cybersecurity domain. However, existing ACO applications require agents to learn from scratch, leading to slow convergence and poor early-stage performance. While teacher-guided techniques have demonstrated promise in other domains, they have not yet been applied to ACO. In this study, we implement four distinct teacher-guided techniques in the simulated CybORG environment and conduct a comparative evaluation. Our results demonstrate that teacher integration can significantly improve training efficiency in terms of early policy performance and convergence speed, highlighting its potential benefits for autonomous cybersecurity. 

**Abstract (ZH)**: 自主网络操作（ACO）依赖强化学习（RL）训练代理在网络安全领域做出有效的决策。然而，现有的ACO应用需要代理从头学习，导致收敛速度慢且早期性能差。尽管教师引导技术在其他领域显示出潜力，但尚未应用于ACO。在本研究中，我们在模拟的CybORG环境中实施了四种不同的教师引导技术，并进行了比较评估。我们的结果表明，教师集成可以显著提高早期策略性能和收敛速度的训练效率，突显了其在自主网络安全方面的潜在益处。 

---
# AI Agents for Photonic Integrated Circuit Design Automation 

**Title (ZH)**: AI代理在光子集成电路设计自动化中的应用 

**Authors**: Ankita Sharma, YuQi Fu, Vahid Ansari, Rishabh Iyer, Fiona Kuang, Kashish Mistry, Raisa Islam Aishy, Sara Ahmad, Joaquin Matres, Dirk R. Englund, Joyce K.S. Poon  

**Link**: [PDF](https://arxiv.org/pdf/2508.14123)  

**Abstract**: We present Photonics Intelligent Design and Optimization (PhIDO), a multi-agent framework that converts natural-language photonic integrated circuit (PIC) design requests into layout mask files. We compare 7 reasoning large language models for PhIDO using a testbench of 102 design descriptions that ranged from single devices to 112-component PICs. The success rate for single-device designs was up to 91%. For design queries with less than or equal to 15 components, o1, Gemini-2.5-pro, and Claude Opus 4 achieved the highest end-to-end pass@5 success rates of approximately 57%, with Gemini-2.5-pro requiring the fewest output tokens and lowest cost. The next steps toward autonomous PIC development include standardized knowledge representations, expanded datasets, extended verification, and robotic automation. 

**Abstract (ZH)**: 光电智能设计与优化(PhIDO)：一种多代理框架，将自然语言的光子集成电路(PIC)设计请求转换为布局掩膜文件 

---
