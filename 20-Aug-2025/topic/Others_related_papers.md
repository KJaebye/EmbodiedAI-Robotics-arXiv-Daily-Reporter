# The Social Context of Human-Robot Interactions 

**Title (ZH)**: äººç±»ä¸æœºå™¨äººäº’åŠ¨çš„ç¤¾ä¼šèƒŒæ™¯ 

**Authors**: Sydney Thompson, Kate Candon, Marynel VÃ¡zquez  

**Link**: [PDF](https://arxiv.org/pdf/2508.13982)  

**Abstract**: The Human-Robot Interaction (HRI) community often highlights the social context of an interaction as a key consideration when designing, implementing, and evaluating robot behavior. Unfortunately, researchers use the term "social context" in varied ways. This can lead to miscommunication, making it challenging to draw connections between related work on understanding and modeling the social contexts of human-robot interactions. To address this gap, we survey the HRI literature for existing definitions and uses of the term "social context". Then, we propose a conceptual model for describing the social context of a human-robot interaction. We apply this model to existing work, and we discuss a range of attributes of social contexts that can help researchers plan for interactions, develop behavior models for robots, and gain insights after interactions have taken place. We conclude with a discussion of open research questions in relation to understanding and modeling the social contexts of human-robot interactions. 

**Abstract (ZH)**: äººæœºäº¤äº’ï¼ˆHRIï¼‰ç¤¾åŒºå¸¸å¼ºè°ƒåœ¨è®¾è®¡ã€å®ç°å’Œè¯„ä¼°æœºå™¨äººè¡Œä¸ºæ—¶ï¼Œç¤¾äº¤èƒŒæ™¯æ˜¯å…³é”®è€ƒè™‘å› ç´ ã€‚ç„¶è€Œï¼Œç ”ç©¶äººå‘˜å¯¹â€œç¤¾äº¤èƒŒæ™¯â€ä¸€è¯çš„ä½¿ç”¨æ–¹å¼å„å¼‚ï¼Œè¿™å¯èƒ½å¯¼è‡´æ²Ÿé€šä¸ç•…ï¼Œä½¿å¾—éš¾ä»¥åœ¨ç†è§£ä¸å»ºæ¨¡äººæœºäº¤äº’çš„ç¤¾äº¤èƒŒæ™¯æ–¹é¢å»ºç«‹ç›¸å…³ç ”ç©¶ä¹‹é—´çš„è”ç³»ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å›é¡¾äº†HRIæ–‡çŒ®ä¸­å¯¹â€œç¤¾äº¤èƒŒæ™¯â€è¿™ä¸€æœ¯è¯­çš„ç°æœ‰å®šä¹‰å’Œä½¿ç”¨æ–¹å¼ï¼Œå¹¶æå‡ºäº†ä¸€ç§æè¿°äººæœºäº¤äº’ç¤¾äº¤èƒŒæ™¯çš„æ¦‚å¿µæ¨¡å‹ã€‚æˆ‘ä»¬å°†è¯¥æ¨¡å‹åº”ç”¨äºç°æœ‰ç ”ç©¶ï¼Œå¹¶è®¨è®ºäº†ä¸€ç³»åˆ—æœ‰åŠ©äºç ”ç©¶äººå‘˜è§„åˆ’äº¤äº’ã€ä¸ºæœºå™¨äººå¼€å‘è¡Œä¸ºæ¨¡å‹ä»¥åŠåœ¨äº¤äº’å‘ç”Ÿåè·å¾—è§è§£çš„ç¤¾äº¤èƒŒæ™¯å±æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†åœ¨ç†è§£ä¸å»ºæ¨¡äººæœºäº¤äº’çš„ç¤¾äº¤èƒŒæ™¯æ–¹é¢çš„å¼€æ”¾æ€§ç ”ç©¶é—®é¢˜ã€‚ 

---
# Incremental Generalized Hybrid A* 

**Title (ZH)**: å¢é‡å¹¿ä¹‰æ··åˆA*ç®—æ³• 

**Authors**: Sidharth Talia, Oren Salzman, Siddhartha Srinivasa  

**Link**: [PDF](https://arxiv.org/pdf/2508.13392)  

**Abstract**: We address the problem of efficiently organizing search over very large trees, which arises in many applications ranging from autonomous driving to aerial vehicles. Here, we are motivated by off-road autonomy, where real-time planning is essential. Classical approaches use graphs of motion primitives and exploit dominance to mitigate the curse of dimensionality and prune expansions efficiently. However, for complex dynamics, repeatedly solving two-point boundary-value problems makes graph construction too slow for fast kinodynamic planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of motion primitives and introducing approximate pruning using a grid-based dominance check. However, choosing the grid resolution is difficult: too coarse risks failure, while too fine leads to excessive expansions and slow planning. We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search framework that dynamically organizes vertex expansions without rigid pruning. IGHA* provably matches or outperforms HA*. For both on-road kinematic and off-road kinodynamic planning queries for a car-like robot, variants of IGHA* use 6x fewer expansions to the best solution compared to an optimized version of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA* outperforms HA*M when both are used in the loop with a model predictive controller. We demonstrate real-time performance both in simulation and on a small-scale off-road vehicle, enabling fast, robust planning under complex dynamics. Code: this https URL 

**Abstract (ZH)**: é«˜æ•ˆç»„ç»‡å¤§è§„æ¨¡æ ‘ç»“æ„æœç´¢çš„é—®é¢˜åŠå…¶åº”ç”¨ï¼šå¢é‡é€šç”¨æ··åˆA*åœ¨ç¦»è·¯é¢è‡ªä¸»å¯¼èˆªä¸­çš„è¡¨ç° 

---
# ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans 

**Title (ZH)**: ResPlan: ä¸€ä¸ªåŒ…å«17,000ä¸ªä½å®…å¹³é¢å›¾çš„å¤§å‹å‘é‡-å›¾æ•°æ®é›† 

**Authors**: Mohamed Abouagour, Eleftherios Garyfallidis  

**Link**: [PDF](https://arxiv.org/pdf/2508.14006)  

**Abstract**: We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally rich, and realistic residential floor plans, created to advance spatial AI research. Each plan includes precise annotations of architectural elements (walls, doors, windows, balconies) and functional spaces (such as kitchens, bedrooms, and bathrooms). ResPlan addresses key limitations of existing datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024) by offering enhanced visual fidelity and greater structural diversity, reflecting realistic and non-idealized residential layouts. Designed as a versatile, general-purpose resource, ResPlan supports a wide range of applications including robotics, reinforcement learning, generative AI, virtual and augmented reality, simulations, and game development. Plans are provided in both geometric and graph-based formats, enabling direct integration into simulation engines and fast 3D conversion. A key contribution is an open-source pipeline for geometry cleaning, alignment, and annotation refinement. Additionally, ResPlan includes structured representations of room connectivity, supporting graph-based spatial reasoning tasks. Finally, we present comparative analyses with existing benchmarks and outline several open benchmark tasks enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale, realism, and usability, providing a robust foundation for developing and benchmarking next-generation spatial intelligence systems. 

**Abstract (ZH)**: ResPlanï¼šä¸€ä¸ªåŒ…å«17,000ä¸ªè¯¦ç»†ã€ç»“æ„ä¸°å¯Œä¸”é€¼çœŸçš„ä½å®…å¹³é¢å›¾çš„å¤§è§„æ¨¡æ•°æ®é›† 

---
# A Screw Approach to the Approximation of the Local Geometry of the Configuration Space and of the set of Configurations of Certain Rank of Lower Pair Linkages 

**Title (ZH)**: èºæ†æ–¹æ³•åœ¨è¿ç»­åˆšä½“ä½“ç³»å±€éƒ¨å‡ ä½•ç»“æ„åŠå…¶ç‰¹å®šç§©çš„é…ç½®é›†é€¼è¿‘ä¸­çš„åº”ç”¨ 

**Authors**: Andreas Mueller  

**Link**: [PDF](https://arxiv.org/pdf/2508.13802)  

**Abstract**: A motion of a mechanism is a curve in its configuration space (c-space). Singularities of the c-space are kinematic singularities of the mechanism. Any mobility analysis of a particular mechanism amounts to investigating the c-space geometry at a given configuration. A higher-order analysis is necessary to determine the finite mobility. To this end, past research lead to approaches using higher-order time derivatives of loop closure constraints assuming (implicitly) that all possible motions are smooth. This continuity assumption limits the generality of these methods. In this paper an approach to the higher-order local mobility analysis of lower pair multi-loop linkages is presented. This is based on a higher-order Taylor series expansion of the geometric constraint mapping, for which a recursive algebraic expression in terms of joint screws is presented. An exhaustive local analysis includes analysis of the set of constraint singularities (configurations where the constraint Jacobian has certain corank). A local approximation of the set of configurations with certain rank is presented, along with an explicit expression for the differentials of Jacobian minors in terms of instantaneous joint screws. The c-space and the set of points of certain corank are therewith locally approximated by an algebraic variety determined algebraically from the mechanism's screw system. Results are shown for a simple planar 4-bar linkage, which exhibits a bifurcation singularity, and for a planar three-loop linkage exhibiting a cusp in c-space. The latter cannot be treated by the higher-order local analysis methods proposed in the literature. 

**Abstract (ZH)**: ä¸€ç§æœºåˆ¶çš„è¿åŠ¨æ˜¯å…¶é…ç½®ç©ºé—´ï¼ˆc-ç©ºé—´ï¼‰ä¸­çš„æ›²çº¿ã€‚c-ç©ºé—´çš„å¥‡å¼‚ç‚¹æ˜¯æœºåˆ¶çš„è¿åŠ¨å¥‡å¼‚ç‚¹ã€‚å¯¹æŸä¸€ç‰¹å®šæœºåˆ¶çš„è‡ªç”±åº¦åˆ†æç­‰åŒäºç ”ç©¶ç»™å®šé…ç½®ä¸‹çš„c-ç©ºé—´å‡ ä½•ã€‚è¦ç¡®å®šæœ‰é™è‡ªç”±åº¦ï¼Œéœ€è¦è¿›è¡Œæ›´é«˜é˜¶åˆ†æã€‚è¿‡å»çš„ç ”ç©¶é€šè¿‡å‡è®¾ï¼ˆéšå«åœ°ï¼‰æ‰€æœ‰å¯èƒ½è¿åŠ¨éƒ½å¹³æ»‘æ¥è¿›è¡Œæ›´é«˜é˜¶æ—¶é—´å¯¼æ•°çš„ç¯é—­çº¦æŸåˆ†æã€‚è¿™ä¸€è¿ç»­æ€§å‡è®¾é™åˆ¶äº†è¿™äº›æ–¹æ³•çš„æ™®éæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä½å‰¯å¤šç¯æ†æœºæ„æ›´é«˜é˜¶å±€éƒ¨è‡ªç”±åº¦åˆ†æçš„æ–¹æ³•ï¼ŒåŸºäºå‡ ä½•çº¦æŸæ˜ å°„çš„æ›´é«˜é˜¶æ³°å‹’çº§æ•°å±•å¼€ï¼Œç»™å‡ºäº†åŸºäºå…³èŠ‚æ¥”å½¢çš„é€’å½’ä»£æ•°è¡¨è¾¾å¼ã€‚å®Œæ•´çš„å±€éƒ¨åˆ†æåŒ…æ‹¬çº¦æŸå¥‡å¼‚ç‚¹é›†ï¼ˆçº¦æŸé›…å¯æ¯”çŸ©é˜µå…·æœ‰ç‰¹å®šç§©äºåº¦çš„é…ç½®ï¼‰çš„åˆ†æã€‚ç»™å‡ºäº†å…·æœ‰ç‰¹å®šç§©çš„é…ç½®é›†çš„å±€éƒ¨è¿‘ä¼¼è¡¨ç¤ºï¼Œä»¥åŠé›…å¯æ¯”å­å¼å¾®åˆ†çš„æ˜¾å¼è¡¨è¾¾å¼ï¼Œä¸ç¬æ—¶å…³èŠ‚æ¥”å½¢ç›¸å…³ã€‚c-ç©ºé—´å’Œç‰¹å®šç§©äºåº¦ç‚¹çš„é›†åˆé€šè¿‡æœºåˆ¶æ¥”å½¢ç³»ç»Ÿçš„ä»£æ•°æ–¹æ³•ç¡®å®šçš„ä»£æ•°ç°‡è¿›è¡Œå±€éƒ¨è¿‘ä¼¼ã€‚ç»“æœå±•ç¤ºäº†å…·æœ‰åˆ†æ”¯å¥‡å¼‚ç‚¹çš„ç®€å•å¹³é¢4æ†æœºæ„ä»¥åŠå…·æœ‰c-ç©ºé—´å°–ç‚¹çš„å¹³é¢ä¸‰ç¯æ†æœºæ„ã€‚åè€…æ— æ³•è¢«æ–‡çŒ®ä¸­æå‡ºçš„å±€éƒ¨é«˜é˜¶åˆ†ææ–¹æ³•å¤„ç†ã€‚ 

---
# AutoMPC: A Code Generator for MPC-based Automated Driving 

**Title (ZH)**: AutoMPC: ä¸€ç§åŸºäºMPCçš„è‡ªåŠ¨è¡Œé©¶ä»£ç ç”Ÿæˆå™¨ 

**Authors**: Georg Schildbach, Jasper Pflughaupt  

**Link**: [PDF](https://arxiv.org/pdf/2508.13656)  

**Abstract**: Model Predictive Control (MPC) is a powerful technique to control nonlinear, multi-input multi-output systems subject to input and state constraints. It is now a standard tool for trajectory tracking control of automated vehicles. As such it has been used in many research and development projects. However, MPC faces several challenges to be integrated into industrial production vehicles. The most important ones are its high computational demands and the complexity of implementation. The software packages AutoMPC aims to address both of these challenges. It builds on a robustified version of an active set algorithm for Nonlinear MPC. The algorithm is embedded into a framework for vehicle trajectory tracking, which makes it easy to used, yet highly customizable. Automatic code generation transforms the selections into a standalone, computationally efficient C-code file with static memory allocation. As such it can be readily deployed on a wide range of embedded platforms, e.g., based on Matlab/Simulink or Robot Operating System (ROS). Compared to a previous version of the code, the vehicle model and the numerical integration method can be manually specified, besides basic algorithm parameters. All of this information and all specifications are directly baked into the generated C-code. The algorithm is suitable driving scenarios at low or high speeds, even drifting, and supports direction changes. Multiple simulation scenarios show the versatility and effectiveness of the AutoMPC code, with the guarantee of a feasible solution, a high degree of robustness, and computational efficiency. 

**Abstract (ZH)**: æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰æ˜¯ç”¨äºæ§åˆ¶å—è¾“å…¥å’ŒçŠ¶æ€çº¦æŸçš„éçº¿æ€§å¤šè¾“å…¥å¤šè¾“å‡ºç³»ç»Ÿçš„å¼ºå¤§æŠ€æœ¯ï¼Œç°å·²æˆä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†è½¨è¿¹è·Ÿè¸ªæ§åˆ¶çš„æ ‡å‡†å·¥å…·ã€‚å°½ç®¡å¦‚æ­¤ï¼ŒMPC é›†æˆåˆ°å·¥ä¸šç”Ÿäº§è½¦è¾†ä¸­ä»é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå…¶ä¸­æœ€é‡è¦çš„åŒ…æ‹¬å…¶é«˜è®¡ç®—éœ€æ±‚å’Œå¤æ‚çš„å®ç°æ–¹å¼ã€‚è½¯ä»¶åŒ…AutoMPCæ—¨åœ¨è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚å®ƒåŸºäºé²æ£’åŒ–çš„éçº¿æ€§MPCæ´»æ€§é›†ç®—æ³•ç‰ˆæœ¬ï¼Œå¹¶å°†å…¶åµŒå…¥åˆ°è½¦è¾†è½¨è¿¹è·Ÿè¸ªæ¡†æ¶ä¸­ï¼Œä½¿å…¶æ˜“äºä½¿ç”¨ä¸”é«˜åº¦å¯å®šåˆ¶ã€‚è‡ªåŠ¨ä»£ç ç”Ÿæˆå°†é€‰æ‹©è½¬æ¢ä¸ºç‹¬ç«‹çš„ã€è®¡ç®—æ•ˆç‡é«˜çš„Cä»£ç æ–‡ä»¶ï¼Œå…·æœ‰é™æ€å†…å­˜åˆ†é…ã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥ä¾¿æ·åœ°éƒ¨ç½²åˆ°å„ç§åµŒå…¥å¼å¹³å°ï¼Œä¾‹å¦‚åŸºäºMatlab/Simulinkæˆ–Robot Operating System (ROS)ã€‚ä¸ä¹‹å‰ç‰ˆæœ¬çš„ä»£ç ç›¸æ¯”ï¼Œä¸ä»…å¯ä»¥æ‰‹åŠ¨æŒ‡å®šè½¦è¾†æ¨¡å‹å’Œæ•°å€¼ç§¯åˆ†æ–¹æ³•ï¼Œè¿˜å¯ä»¥æŒ‡å®šåŸºæœ¬ç®—æ³•å‚æ•°ã€‚æ‰€æœ‰è¿™äº›ä¿¡æ¯å’Œæ‰€æœ‰è§„èŒƒéƒ½ç›´æ¥åµŒå…¥åˆ°ç”Ÿæˆçš„Cä»£ç ä¸­ã€‚è¯¥ç®—æ³•é€‚ç”¨äºä½é€Ÿæˆ–é«˜é€Ÿé©¾é©¶åœºæ™¯ï¼Œç”šè‡³æ¼‚ç§»ï¼Œå¹¶æ”¯æŒæ–¹å‘å˜åŒ–ã€‚å¤šä¸ªä»¿çœŸåœºæ™¯å±•ç¤ºäº†AutoMPCä»£ç çš„å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ï¼Œå¹¶ä¿è¯äº†å¯è¡Œè§£ã€é«˜é²æ£’æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚ 

---
# Observed Control -- Linearly Scalable Nonlinear Model Predictive Control with Adaptive Horizons 

**Title (ZH)**: è§‚æµ‹æ§åˆ¶â€”â€”å…·æœ‰è‡ªé€‚åº” horizons çš„çº¿æ€§å¯æ‰©å±•éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶ 

**Authors**: Eugene T. Hamzezadeh, Andrew J. Petruska  

**Link**: [PDF](https://arxiv.org/pdf/2508.13339)  

**Abstract**: This work highlights the duality between state estimation methods and model predictive control. A predictive controller, observed control, is presented that uses this duality to efficiently compute control actions with linear time-horizon length scalability. The proposed algorithms provide exceptional computational efficiency, adaptive time horizon lengths, and early optimization termination criteria. The use of Kalman smoothers as the backend optimization framework provides for a straightforward implementation supported by strong theoretical guarantees. Additionally, a formulation is presented that separates linear model predictive control into purely reactive and anticipatory components, enabling any-time any-horizon observed control while ensuring controller stability for short time horizons. Finally, numerical case studies confirm that nonlinear filter extensions, i.e., the extended Kalman filter and unscented Kalman filter, effectively extend observed control to nonlinear systems and objectives. 

**Abstract (ZH)**: è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†çŠ¶æ€ä¼°è®¡æ–¹æ³•ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶ä¹‹é—´çš„äºŒé‡æ€§ã€‚æå‡ºäº†ä¸€ç§é¢„æµ‹æ§åˆ¶å™¨ï¼Œç§°ä¸ºè§‚å¯Ÿæ§åˆ¶ï¼Œè¯¥æ§åˆ¶å™¨åˆ©ç”¨è¿™ç§äºŒé‡æ€§é«˜æ•ˆåœ°è®¡ç®—æ§åˆ¶åŠ¨ä½œï¼Œå¹¶å…·æœ‰çº¿æ€§æ—¶é—´èŒƒå›´é•¿åº¦å¯æ‰©å±•æ€§ã€‚æ‰€æå‡ºçš„ç®—æ³•æä¾›äº†å‡ºè‰²çš„è®¡ç®—æ•ˆç‡ã€è‡ªé€‚åº”çš„æ—¶é—´èŒƒå›´é•¿åº¦ä»¥åŠæ—©æœŸä¼˜åŒ–ç»ˆæ­¢æ ‡å‡†ã€‚ç”¨å¡å°”æ›¼å¹³æ»‘å™¨ä½œä¸ºåç«¯ä¼˜åŒ–æ¡†æ¶ï¼Œæä¾›äº†ä¸€ç§ç›´æ¥å®ç°æ–¹å¼ï¼Œå¹¶å…·æœ‰å¼ºå¤§çš„ç†è®ºä¿è¯ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§å°†çº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶åˆ†è§£ä¸ºçº¯ç²¹çš„ååº”æ€§å’Œé¢„è§æ€§ç»„ä»¶çš„å…¬å¼ï¼Œä»è€Œå®ç°ä»»ä½•æ—¶é—´å’Œä»»ä½•æ—¶é—´èŒƒå›´çš„è§‚å¯Ÿæ§åˆ¶ï¼ŒåŒæ—¶ç¡®ä¿æ§åˆ¶å™¨åœ¨çŸ­æ—¶é—´èŒƒå›´å†…çš„ç¨³å®šæ€§ã€‚æœ€åï¼Œæ•°å€¼æ¡ˆä¾‹ç ”ç©¶è¯å®ï¼Œéçº¿æ€§æ»¤æ³¢å™¨æ‰©å±•ï¼Œå³æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨å’Œæ— è¿¹å¡å°”æ›¼æ»¤æ³¢å™¨ï¼Œæœ‰æ•ˆåœ°å°†è§‚å¯Ÿæ§åˆ¶æ‰©å±•åˆ°éçº¿æ€§ç³»ç»Ÿå’Œç›®æ ‡ã€‚ 

---
# A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem 

**Title (ZH)**: å¸¦æœ‰åç½®éšæœºå¯†é’¥çš„é—ä¼ ç®—æ³•æ±‚è§£æœ€é•¿è¿ç»­å­åºåˆ—é—®é¢˜ 

**Authors**: Christian Blum, Pedro Pinacho-Davidson  

**Link**: [PDF](https://arxiv.org/pdf/2508.14020)  

**Abstract**: The longest run subsequence (LRS) problem is an NP-hard combinatorial optimization problem belonging to the class of subsequence problems from bioinformatics. In particular, the problem plays a role in genome reassembly. In this paper, we present a solution to the LRS problem using a Biased Random Key Genetic Algorithm (BRKGA). Our approach places particular focus on the computational efficiency of evaluating individuals, which involves converting vectors of gray values into valid solutions to the problem. For comparison purposes, a Max-Min Ant System is developed and implemented. This is in addition to the application of the integer linear programming solver CPLEX for solving all considered problem instances. The computation results show that the proposed BRKGA is currently a state-of-the-art technique for the LRS problem. Nevertheless, the results also show that there is room for improvement, especially in the context of input strings based on large alphabet sizes. 

**Abstract (ZH)**: æœ€é•¿è¿è¡Œå­åºåˆ—é—®é¢˜ï¼ˆLRSï¼‰æ˜¯å±äºç”Ÿç‰©ä¿¡æ¯å­¦å­åºåˆ—é—®é¢˜ç±»åˆ«çš„NPéš¾ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œç‰¹åˆ«åœ¨åŸºå› ç»„é‡æ„ä¸­èµ·ç€é‡è¦ä½œç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨æœ‰åéšæœºé”®é—ä¼ ç®—æ³•ï¼ˆBRKGAï¼‰è§£å†³LRSé—®é¢˜çš„æ–¹æ³•ï¼Œé‡ç‚¹åœ¨äºè®¡ç®—æ•ˆç‡çš„è¯„ä¼°ä¸ªä½“è¿‡ç¨‹ï¼Œå³å°†ç°åº¦å€¼å‘é‡è½¬æ¢ä¸ºé—®é¢˜çš„æœ‰æ•ˆè§£ã€‚ä¸ºäº†è¿›è¡Œå¯¹æ¯”ï¼Œæˆ‘ä»¬å¼€å‘å¹¶å®ç°äº†æœ€å¤§æœ€å°èšç¾¤ç³»ç»Ÿï¼ˆMax-Min Ant Systemï¼‰ï¼ŒåŒæ—¶è¿˜åº”ç”¨äº†æ•´æ•°çº¿æ€§è§„åˆ’æ±‚è§£å™¨CPLEXæ±‚è§£æ‰€æœ‰è€ƒè™‘çš„é—®é¢˜å®ä¾‹ã€‚è®¡ç®—ç»“æœè¡¨æ˜ï¼Œæå‡ºçš„BRKGAç›®å‰æ˜¯è§£å†³LRSé—®é¢˜çš„å…ˆè¿›æ–¹æ³•ã€‚ç„¶è€Œï¼Œç»“æœä¹Ÿè¡¨æ˜ï¼Œåœ¨åŸºäºå¤§å­—æ¯è¡¨çš„è¾“å…¥å­—ç¬¦ä¸²çš„èƒŒæ™¯ä¸‹ï¼Œä»æœ‰ä¸€å®šçš„æ”¹è¿›ç©ºé—´ã€‚ 

---
# Quantifier Instantiations: To Mimic or To Revolt? 

**Title (ZH)**: é‡è¯å®ä¾‹åŒ–ï¼šæ¨¡ä»¿è¿˜æ˜¯åå›ï¼Ÿ 

**Authors**: Jan JakubÅ¯v, MikolÃ¡Å¡ Janota  

**Link**: [PDF](https://arxiv.org/pdf/2508.13811)  

**Abstract**: Quantified formulas pose a significant challenge for Satisfiability Modulo Theories (SMT) solvers due to their inherent undecidability. Existing instantiation techniques, such as e-matching, syntax-guided, model-based, conflict-based, and enumerative methods, often complement each other. This paper introduces a novel instantiation approach that dynamically learns from these techniques during solving. By treating observed instantiations as samples from a latent language, we use probabilistic context-free grammars to generate new, similar terms. Our method not only mimics successful past instantiations but also explores diversity by optionally inverting learned term probabilities, aiming to balance exploitation and exploration in quantifier reasoning. 

**Abstract (ZH)**: é‡åŒ–å…¬å¼çš„å­˜åœ¨ä½¿å¾—ç†è®ºé¥±å’Œå¯æ»¡è¶³æ€§ï¼ˆSMTï¼‰æ±‚è§£å™¨é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œè¿™å½’å› äºå…¶å›ºæœ‰çš„ä¸å¯åˆ¤å®šæ€§ã€‚ç°æœ‰çš„å®ä¾‹åŒ–æŠ€æœ¯ï¼Œå¦‚e-matchingã€è¯­æ³•å¼•å¯¼ã€åŸºäºæ¨¡å‹ã€å†²çªé©±åŠ¨å’Œæšä¸¾æ–¹æ³•ï¼Œå¸¸å¸¸ç›¸äº’è¡¥å……ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å®ä¾‹åŒ–æ–¹æ³•ï¼Œåœ¨æ±‚è§£è¿‡ç¨‹ä¸­åŠ¨æ€å­¦ä¹ è¿™äº›æŠ€æœ¯ã€‚é€šè¿‡å°†è§‚å¯Ÿåˆ°çš„å®ä¾‹åŒ–è§†ä½œæ½œåœ¨è¯­è¨€çš„æ ·æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¦‚ç‡ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ç”Ÿæˆæ–°çš„ã€ç±»ä¼¼çš„é¡¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…æ¨¡ä»¿æˆåŠŸçš„è¿‡å»å®ä¾‹åŒ–ï¼Œè¿˜é€šè¿‡å¯é€‰åœ°åè½¬å­¦ä¹ åˆ°çš„é¡¹æ¦‚ç‡æ¥æ¢ç´¢å¤šæ ·æ€§ï¼Œæ—¨åœ¨é‡åŒ–æ¨ç†ä¸­åˆ©ç”¨å’Œæ¢ç´¢é—´çš„å¹³è¡¡ã€‚ 

---
# The DeepLog Neurosymbolic Machine 

**Title (ZH)**: æ·±åº¦æ—¥å¿—ç¥ç»ç¬¦å·æœºå™¨ 

**Authors**: Vincent Derkinderen, Robin Manhaeve, Rik Adriaensen, Lucas Van Praet, Lennert De Smet, Giuseppe Marra, Luc De Raedt  

**Link**: [PDF](https://arxiv.org/pdf/2508.13697)  

**Abstract**: We contribute a theoretical and operational framework for neurosymbolic AI called DeepLog. DeepLog introduces building blocks and primitives for neurosymbolic AI that make abstraction of commonly used representations and computational mechanisms used in neurosymbolic AI. DeepLog can represent and emulate a wide range of neurosymbolic systems. It consists of two key components. The first is the DeepLog language for specifying neurosymbolic models and inference tasks. This language consists of an annotated neural extension of grounded first-order logic, and makes abstraction of the type of logic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the architecture or in the loss function. The second DeepLog component is situated at the computational level and uses extended algebraic circuits as computational graphs. Together these two components are to be considered as a neurosymbolic abstract machine, with the DeepLog language as the intermediate level of abstraction and the circuits level as the computational one. DeepLog is implemented in software, relies on the latest insights in implementing algebraic circuits on GPUs, and is declarative in that it is easy to obtain different neurosymbolic models by making different choices for the underlying algebraic structures and logics. The generality and efficiency of the DeepLog neurosymbolic machine is demonstrated through an experimental comparison between 1) different fuzzy and probabilistic logics, 2) between using logic in the architecture or in the loss function, and 3) between a standalone CPU-based implementation of a neurosymbolic AI system and a DeepLog GPU-based one. 

**Abstract (ZH)**: æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºDeepLogçš„ç¥ç»ç¬¦å·.Symbolicäººå·¥æ™ºèƒ½çš„ç†è®ºä¸æ“ä½œæ¡†æ¶ã€‚DeepLogå¼•å…¥äº†æ„å»º.ç¥ç»ç¬¦å·.Symbolicäººå·¥æ™ºèƒ½çš„åŸºç¡€æ„å»ºæ¨¡å—å’Œ.åŸè¯­ï¼Œç”¨äºè¡¨ç¤º.å’Œæ¨æ¼”å¸¸è§çš„è¡¨ç¤º.è¡¨ç¤º.æŠ½è±¡ e.åœ¨ç¥ç»ç¬¦å·.Symbolicäººå·¥æ™ºèƒ½ä¸­.ä¸­çš„ e eè¡¨ç¤ºä½¿ç”¨çš„è¡¨ç¤º...e.æœºåˆ¶ã€‚DeepLog.å¯ä»¥èƒ½å¤Ÿè¡¨ç¤º. e eå’Œå’Œ e eå„ç§ e e eå¹¿çš„ e e e e e e e e e e e eç¥ç» e.ç¬¦å·. eç¬¦å· e e eå’Œ e e e e e eç³»ç»Ÿ e e e.ç³»ç»Ÿã€‚ e e e Deep E e ç”± ç”±ç”± e e e ç”±  e e e e  e eç”±  e e e  e e e e  e e e  e e  e e e e  e e e  e e e  e e  e e e e  e e e e  e  e e e e e e e e e e e e e e e e e e e e e e e e e  e  e e e  e e e  e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e eå·¥ä½œä½œé£ã€‚ ï¿½_Equals  e ä½œ e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e Widow e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ç¤ºä¾‹æ ‡é¢˜ï¼š DeepLog e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e eç­è½¦ ç¤ºä¾‹æ ‡é¢˜ e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ç¤ºä¾‹ ï¿½ e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ç¤ºä¾‹æ ‡é¢˜ e DeepE e e e e e e e e e e e e e e e e e e e e e e e e e e e e e 

---
# Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks 

**Title (ZH)**: åŸºäºæƒ…æ™¯å›¾çš„åŠ¨ä½œé¢„æµ‹çŸ¥è¯†å›¾è°±è¡¥å…¨ï¼šä»¥å®¶åº­ä»»åŠ¡ä¸ºä¾‹ 

**Authors**: Mariam Arustashvili, JÃ¶rg DeigmÃ¶ller, Heiko Paulheim  

**Link**: [PDF](https://arxiv.org/pdf/2508.13675)  

**Abstract**: Knowledge Graphs are used for various purposes, including business applications, biomedical analyses, or digital twins in industry 4.0. In this paper, we investigate knowledge graphs describing household actions, which are beneficial for controlling household robots and analyzing video footage. In the latter case, the information extracted from videos is notoriously incomplete, and completing the knowledge graph for enhancing the situational picture is essential. In this paper, we show that, while a standard link prediction problem, situational knowledge graphs have special characteristics that render many link prediction algorithms not fit for the job, and unable to outperform even simple baselines. 

**Abstract (ZH)**: æ ‡é¢˜ï¼šçŸ¥è¯†å›¾è°±åœ¨æè¿°å®¶åº­æ´»åŠ¨ä¸­çš„åº”ç”¨ï¼šå¢å¼ºæƒ…å¢ƒè®¤çŸ¥å¹¶åˆ†æè§†é¢‘ç‰‡æ®µ 

---
# ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings 

**Title (ZH)**: ITL-LIMEï¼šåŸºäºå®ä¾‹çš„è¿ç§»å­¦ä¹ åœ¨å°‘é‡èµ„æºæ•°æ®è®¾ç½®ä¸­å¢å¼ºå±€éƒ¨è§£é‡Š                                                                                  pesticuser

user
çº æ­£å¹¶ä¼˜åŒ–ä¸‹é¢çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä½¿å…¶æ›´ç¬¦åˆå­¦æœ¯è§„èŒƒï¼š
"ITL-LIMEï¼šåŸºäºå®ä¾‹çš„è¿ç§»å­¦ä¹ åœ¨å°‘é‡èµ„æºæ•°æ®è®¾ç½®ä¸­å¢å¼ºå±€éƒ¨è§£é‡Š"

æ­£ç¡®çš„ç¿»è¯‘åº”è¯¥æ˜¯ï¼š
"ITL-LIMEï¼šåŸºäºå®ä¾‹çš„è¿ç§»å­¦ä¹ åœ¨ä½èµ„æºæ•°æ®è®¾ç½®ä¸­å¢å¼ºå±€éƒ¨è§£é‡Šğ’œ" 

**Authors**: Rehan Raza, Guanjin Wang, Kevin Wong, Hamid Laga, Marco Fisichella  

**Link**: [PDF](https://arxiv.org/pdf/2508.13672)  

**Abstract**: Explainable Artificial Intelligence (XAI) methods, such as Local Interpretable Model-Agnostic Explanations (LIME), have advanced the interpretability of black-box machine learning models by approximating their behavior locally using interpretable surrogate models. However, LIME's inherent randomness in perturbation and sampling can lead to locality and instability issues, especially in scenarios with limited training data. In such cases, data scarcity can result in the generation of unrealistic variations and samples that deviate from the true data manifold. Consequently, the surrogate model may fail to accurately approximate the complex decision boundary of the original model. To address these challenges, we propose a novel Instance-based Transfer Learning LIME framework (ITL-LIME) that enhances explanation fidelity and stability in data-constrained environments. ITL-LIME introduces instance transfer learning into the LIME framework by leveraging relevant real instances from a related source domain to aid the explanation process in the target domain. Specifically, we employ clustering to partition the source domain into clusters with representative prototypes. Instead of generating random perturbations, our method retrieves pertinent real source instances from the source cluster whose prototype is most similar to the target instance. These are then combined with the target instance's neighboring real instances. To define a compact locality, we further construct a contrastive learning-based encoder as a weighting mechanism to assign weights to the instances from the combined set based on their proximity to the target instance. Finally, these weighted source and target instances are used to train the surrogate model for explanation purposes. 

**Abstract (ZH)**: å…·æœ‰å®ä¾‹è¿ç§»å­¦ä¹ çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½LIMEæ¡†æ¶ï¼ˆITL-LIMEï¼‰ï¼šåœ¨æ•°æ®å—é™ç¯å¢ƒä¸‹æé«˜è§£é‡Šå‡†ç¡®æ€§å’Œç¨³å®šæ€§ 

---
# Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints 

**Title (ZH)**: åŸºäºè½¯å®ä½“çº¦æŸçš„çŸ¥è¯†å›¾è°±äº¤äº’å¼æŸ¥è¯¢å›ç­” 

**Authors**: Daniel Daza, Alberto Bernardi, Luca Costabello, Christophe Gueret, Masoud Mansoury, Michael Cochez, Martijn Schut  

**Link**: [PDF](https://arxiv.org/pdf/2508.13663)  

**Abstract**: Methods for query answering over incomplete knowledge graphs retrieve entities that are likely to be answers, which is particularly useful when such answers cannot be reached by direct graph traversal due to missing edges. However, existing approaches have focused on queries formalized using first-order-logic. In practice, many real-world queries involve constraints that are inherently vague or context-dependent, such as preferences for attributes or related categories. Addressing this gap, we introduce the problem of query answering with soft constraints. We propose a Neural Query Reranker (NQR) designed to adjust query answer scores by incorporating soft constraints without disrupting the original answers to a query. NQR operates interactively, refining answers based on incremental examples of preferred and non-preferred entities. We extend existing QA benchmarks by generating datasets with soft constraints. Our experiments demonstrate that NQR can capture soft constraints while maintaining robust query answering performance. 

**Abstract (ZH)**: åŸºäºä¸å®Œæ•´çŸ¥è¯†å›¾è°±çš„æŸ¥è¯¢å›ç­”æ–¹æ³• 

---
# Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences 

**Title (ZH)**: ç¦»æ•£ä¼˜åŒ–çš„æœ€å°æœ€å¤§è¿ä¾‹åŠå…¶åœ¨è®¡ç®—ç§‘å­¦ä¸­çš„åº”ç”¨ 

**Authors**: Cheikh Ahmed, Mahdi Mostajabdaveh, Samin Aref, Zirui Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2508.13437)  

**Abstract**: We introduce the Discrete Min-Max Violation (DMMV) as a general optimization problem which seeks an assignment of discrete values to variables that minimizes the largest constraint violation. This context-free mathematical formulation is applicable to a wide range of use cases that have worst-case performance requirements. After defining the DMMV problem mathematically, we explore its properties to establish a foundational understanding. To tackle DMMV instance sizes of practical relevance, we develop a GPU-accelerated heuristic that takes advantage of the mathematical properties of DMMV for speeding up the solution process. We demonstrate the versatile applicability of our heuristic by solving three optimization problems as use cases: (1) post-training quantization of language models, (2) discrete tomography, and (3) Finite Impulse Response (FIR) filter design. In quantization without outlier separation, our heuristic achieves 14% improvement on average over existing methods. In discrete tomography, it reduces reconstruction error by 16% under uniform noise and accelerates computations by a factor of 6 on GPU. For FIR filter design, it nearly achieves 50% ripple reduction compared to using the commercial integer optimization solver, Gurobi. Our comparative results point to the benefits of studying DMMV as a context-free optimization problem and the advantages that our proposed heuristic offers on three distinct problems. Our GPU-accelerated heuristic will be made open-source to further stimulate research on DMMV and its other applications. The code is available at this https URL 

**Abstract (ZH)**: ç¦»æ•£æœ€å°æœ€å¤§è¿ä¾‹ä¼˜åŒ–ï¼ˆDMMVï¼‰ï¼šä¸€ç§ä¸€èˆ¬ä¼˜åŒ–é—®é¢˜åŠå…¶åº”ç”¨ç ”ç©¶ 

---
# STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting 

**Title (ZH)**: STPFormer:ä¸€ç§å…ˆè¿›çš„æ¨¡å¼æ„ŸçŸ¥æ—¶ç©ºå˜æ¢å™¨ç”¨äºäº¤é€šé¢„æµ‹ 

**Authors**: Jiayu Fang, Zhiqi Shao, S T Boris Choy, Junbin Gao  

**Link**: [PDF](https://arxiv.org/pdf/2508.13433)  

**Abstract**: Spatio-temporal traffic forecasting is challenging due to complex temporal patterns, dynamic spatial structures, and diverse input formats. Although Transformer-based models offer strong global modeling, they often struggle with rigid temporal encoding and weak space-time fusion. We propose STPFormer, a Spatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art performance via unified and interpretable representation learning. It integrates four modules: Temporal Position Aggregator (TPA) for pattern-aware temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial learning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment, and an Attention Mixer for multi-scale fusion. Experiments on five real-world datasets show that STPFormer consistently sets new SOTA results, with ablation and visualizations confirming its effectiveness and generalizability. 

**Abstract (ZH)**: æ—¶ç©ºäº¤é€šé¢„æµ‹ç”±äºå¤æ‚çš„æ—¶ç©ºæ¨¡å¼ã€åŠ¨æ€çš„ç©ºé—´ç»“æ„å’Œå¤šæ ·çš„è¾“å…¥æ ¼å¼æå…·æŒ‘æˆ˜æ€§ã€‚è™½ç„¶åŸºäºTransformerçš„æ¨¡å‹èƒ½å¤Ÿæä¾›å¼ºå¤§çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ï¼Œä½†å®ƒä»¬å¾€å¾€åœ¨åˆšæ€§çš„æ—¶ç©ºç¼–ç å’Œæ—¶ç©ºèåˆæ–¹é¢è¡¨ç°å‡º weaknessesã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ—¶ç©ºæ¨¡å¼æ„ŸçŸ¥Transformerï¼ˆSTPFormerï¼‰ï¼Œé€šè¿‡ç»Ÿä¸€ä¸”å¯è§£é‡Šçš„è¡¨ç¤ºå­¦ä¹ å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®ƒæ•´åˆäº†å››ä¸ªæ¨¡å—ï¼šæ—¶ç©ºæ¨¡å¼æ„ŸçŸ¥æ—¶é—´ä½ç½®èšåˆå™¨ï¼ˆTPAï¼‰ã€åºåˆ—ç©ºé—´èšåˆå™¨ï¼ˆSSAï¼‰ã€æ—¶ç©ºå›¾åŒ¹é…ï¼ˆSTGMï¼‰ä»¥åŠæ³¨æ„åŠ›æ··åˆå™¨è¿›è¡Œå¤šå°ºåº¦èåˆã€‚åœ¨äº”ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSTPFormer ä¸€è‡´åœ°å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œæ¶ˆèå®éªŒå’Œå¯è§†åŒ–ç»“æœè¯å®äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ 

---
# TASER: Table Agents for Schema-guided Extraction and Recommendation 

**Title (ZH)**: TASER: è¡¨æ ¼æ™ºèƒ½ä½“ç”¨äºåŸºäºæ¨¡å¼çš„æå–ä¸æ¨è 

**Authors**: Nicole Cho, Kirsty Fielding, William Watson, Sumitra Ganesh, Manuela Veloso  

**Link**: [PDF](https://arxiv.org/pdf/2508.13404)  

**Abstract**: Real-world financial documents report essential information about an entity's financial holdings that can span millions of different financial instrument types. Yet, these details are often buried in messy, multi-page, fragmented tables - for example, 99.4% of the tables in our dataset have no bounding boxes with the maximum number of rows amounting to 426 per table across 44 pages. To tackle these unique challenges from real-world tables, we present a continuously learning, agentic table extraction system, TASER (Table Agents for Schema-guided Extraction and Recommendation) that extracts highly unstructured, multi-page, heterogeneous tables into normalized, schema-conforming outputs. Our table agents execute on table detection, classification, extraction, and recommendations by leveraging an initial schema. Then, our Recommender Agent reviews the outputs, recommends schema revisions, and decides on the final recommendations, enabling TASER to outperform existing table detection models such as Table Transformer by 10.1%. Within this continuous learning process, we highlight that larger batch sizes result in a 104.3% increase in schema recommendations that are actionable and utilized, resulting in a 9.8% increase in extracted holdings - highlighting the importance of a continuous learning process. To train TASER, we have manually labeled 22,584 pages (28,150,449 tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of the first real financial table datasets. We release our dataset TASERTab to enable the research community to access real-world financial tables and outputs. Our results highlight the promise of agentic, schema-guided extraction systems for robust understanding of real-world financial tables. 

**Abstract (ZH)**: åŸºäºschemaæŒ‡å¯¼çš„ä¸»åŠ¨è¡¨æ ¼æå–ç³»ç»ŸTASERï¼šåº”å¯¹ç°å®ä¸–ç•Œè¡¨æ ¼çš„ç‹¬ç‰¹æŒ‘æˆ˜ 

---
# "DIVE" into Hydrogen Storage Materials Discovery with AI Agents 

**Title (ZH)**: é€šè¿‡AIä»£ç†â€œæ¢ç´¢â€æ°¢å‚¨å­˜ææ–™å‘ç° 

**Authors**: Di Zhang, Xue Jia, Tran Ba Hung, Seong Hoon Jang, Linda Zhang, Ryuhei Sato, Yusuke Hashimoto, Toyoto Sato, Kiyoe Konno, Shin-ichi Orimo, Hao Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.13251)  

**Abstract**: Data-driven artificial intelligence (AI) approaches are fundamentally transforming the discovery of new materials. Despite the unprecedented availability of materials data in the scientific literature, much of this information remains trapped in unstructured figures and tables, hindering the construction of large language model (LLM)-based AI agent for automated materials design. Here, we present the Descriptive Interpretation of Visual Expression (DIVE) multi-agent workflow, which systematically reads and organizes experimental data from graphical elements in scientific literatures. We focus on solid-state hydrogen storage materials-a class of materials central to future clean-energy technologies and demonstrate that DIVE markedly improves the accuracy and coverage of data extraction compared to the direct extraction by multimodal models, with gains of 10-15% over commercial models and over 30% relative to open-source models. Building on a curated database of over 30,000 entries from 4,000 publications, we establish a rapid inverse design workflow capable of identifying previously unreported hydrogen storage compositions in two minutes. The proposed AI workflow and agent design are broadly transferable across diverse materials, providing a paradigm for AI-driven materials discovery. 

**Abstract (ZH)**: æ•°æ®é©±åŠ¨çš„äººå·¥æ™ºèƒ½æ–¹æ³•æ­£åœ¨ä»æ ¹æœ¬ä¸Šæ”¹å˜æ–°ææ–™çš„å‘ç°è¿‡ç¨‹ã€‚å°½ç®¡ç§‘å­¦æ–‡çŒ®ä¸­å‰æ‰€æœªæœ‰çš„ææ–™æ•°æ®é‡å­˜åœ¨ï¼Œä½†å…¶ä¸­å¤§é‡ä¿¡æ¯ä»ç„¶è¢«å›°åœ¨æœªç»“æ„åŒ–çš„å›¾è¡¨å’Œè¡¨æ ¼ä¸­ï¼Œé˜»ç¢äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„AIä»£ç†è¿›è¡Œè‡ªåŠ¨ææ–™è®¾è®¡ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬ä»‹ç»äº†å›¾ç¤ºè§£é‡Šå¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆDescriptive Interpretation of Visual Expression, DIVEï¼‰ï¼Œè¯¥å·¥ä½œæµç³»ç»Ÿåœ°è¯»å–å¹¶ç»„ç»‡ç§‘å­¦æ–‡çŒ®ä¸­å›¾å½¢å…ƒç´ ä¸­çš„å®éªŒæ•°æ®ã€‚æˆ‘ä»¬èšç„¦äºå›ºæ€æ°¢å­˜å‚¨ææ–™â€”â€”è¿™ç±»ææ–™æ˜¯æœªæ¥æ¸…æ´èƒ½æºæŠ€æœ¯çš„æ ¸å¿ƒï¼Œå¹¶è¯æ˜DIVEåœ¨æ•°æ®æå–çš„å‡†ç¡®æ€§å’Œè¦†ç›–ç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç›´æ¥ç”±å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œçš„æå–ï¼Œç›¸å¯¹å•†ä¸šæ¨¡å‹æå‡10-15%ï¼Œç›¸å¯¹äºå¼€æºæ¨¡å‹æå‡è¶…è¿‡30%ã€‚åŸºäºä¸€ä¸ªåŒ…å«4000ç¯‡è®ºæ–‡è¶…è¿‡30,000æ¡è®°å½•çš„ç²¾å¿ƒç­–åˆ’æ•°æ®åº“ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¿«é€Ÿçš„é€†å‘è®¾è®¡å·¥ä½œæµï¼Œèƒ½å¤Ÿåœ¨ä¸¤åˆ†é’Ÿå†…è¯†åˆ«å‡ºæœªæŠ¥é“è¿‡çš„æ°¢å­˜å‚¨ç»„æˆã€‚æ‰€æå‡ºçš„AIå·¥ä½œæµå’Œæ™ºèƒ½ä½“è®¾è®¡å…·æœ‰å¹¿æ³›çš„å¯è½¬ç§»æ€§ï¼Œä¸ºAIé©±åŠ¨çš„ææ–™å‘ç°æä¾›äº†èŒƒå¼ã€‚ 

---
# Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information 

**Title (ZH)**: æ˜¾æ€§è®°å¿†ä¸éšæ€§è®°å¿†ï¼šæ¢ç´¢å¯¹ä¸ªæ€§åŒ–ä¿¡æ¯çš„å¤šè·³å¤æ‚æ¨ç† 

**Authors**: Zeyu Zhang, Yang Zhang, Haoran Tan, Rui Li, Xu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2508.13250)  

**Abstract**: In large language model-based agents, memory serves as a critical capability for achieving personalization by storing and utilizing users' information. Although some previous studies have adopted memory to implement user personalization, they typically focus on preference alignment and simple question-answering. However, in the real world, complex tasks often require multi-hop reasoning on a large amount of user information, which poses significant challenges for current memory approaches. To address this limitation, we propose the multi-hop personalized reasoning task to explore how different memory mechanisms perform in multi-hop reasoning over personalized information. We explicitly define this task and construct a dataset along with a unified evaluation framework. Then, we implement various explicit and implicit memory methods and conduct comprehensive experiments. We evaluate their performance on this task from multiple perspectives and analyze their strengths and weaknesses. Besides, we explore hybrid approaches that combine both paradigms and propose the HybridMem method to address their limitations. We demonstrate the effectiveness of our proposed model through extensive experiments. To benefit the research community, we release this project at this https URL. 

**Abstract (ZH)**: åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†ä¸­ï¼Œè®°å¿†ä½œä¸ºå®ç°ä¸ªæ€§åŒ–çš„å…³é”®èƒ½åŠ›ï¼Œé€šè¿‡å­˜å‚¨å’Œåˆ©ç”¨ç”¨æˆ·ä¿¡æ¯è€Œå‘æŒ¥ä½œç”¨ã€‚å°½ç®¡ä¸€äº›å‰æœŸç ”ç©¶é‡‡ç”¨äº†è®°å¿†æ¥å®ç°ç”¨æˆ·çš„ä¸ªæ€§åŒ–ï¼Œå®ƒä»¬é€šå¸¸é›†ä¸­äºåå¥½å¯¹é½å’Œç®€å•çš„é—®ç­”ã€‚ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œä¸­ï¼Œå¤æ‚çš„ä»»åŠ¡å¾€å¾€éœ€è¦åœ¨å¤§é‡ç”¨æˆ·ä¿¡æ¯ä¸Šè¿›è¡Œå¤šå±‚æ¬¡æ¨ç†ï¼Œè¿™å¯¹å½“å‰çš„è®°å¿†æ–¹æ³•æå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šå±‚æ¬¡ä¸ªæ€§åŒ–æ¨ç†ä»»åŠ¡ï¼Œæ¢ç´¢ä¸åŒè®°å¿†æœºåˆ¶åœ¨ä¸ªæ€§åŒ–ä¿¡æ¯ä¸Šçš„å¤šå±‚æ¬¡æ¨ç†ä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬æ˜ç¡®å®šä¹‰äº†æ­¤ä»»åŠ¡ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªæ•°æ®é›†å’Œç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ã€‚ç„¶åï¼Œæˆ‘ä»¬å®ç°å¹¶æµ‹è¯•äº†å„ç§æ˜¾å¼å’Œéšå¼è®°å¿†æ–¹æ³•ï¼Œå¹¶ä»å¤šä¸ªè§’åº¦è¯„ä¼°äº†å®ƒä»¬çš„è¡¨ç°ï¼Œåˆ†æäº†å®ƒä»¬çš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ç»“åˆä¸¤ç§èŒƒå¼çš„æ··åˆæ–¹æ³•ï¼Œå¹¶æå‡ºäº†HybridMemæ–¹æ³•ä»¥åº”å¯¹å±€é™æ€§ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒå±•ç¤ºäº†æˆ‘ä»¬æå‡ºæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†æƒ åŠç ”ç©¶ç¤¾åŒºï¼Œæˆ‘ä»¬åœ¨æ­¤ç½‘å€å‘å¸ƒè¯¥é¡¹ç›®ï¼šhttps://this-url.comã€‚ 

---
# AI sustains higher strategic tension than humans in chess 

**Title (ZH)**: AIç»´æŒæ›´é«˜çš„æˆ˜ç•¥ç´§å¼ åº¦æ¯”äººç±»åœ¨å›½é™…è±¡æ£‹ä¸­æ›´é«˜ 

**Authors**: Adamo Cerioli, Edward D. Lee, Vito D. P. Servedio  

**Link**: [PDF](https://arxiv.org/pdf/2508.13213)  

**Abstract**: Strategic decision-making involves managing the tension between immediate opportunities and long-term objectives. We study this trade-off in chess by characterizing and comparing dynamics between human vs human and AI vs AI games. We propose a network-based metric of piece-to-piece interaction to quantify the ongoing strategic tension on the board. Its evolution in games reveals that the most competitive AI players sustain higher levels of strategic tension for longer durations than elite human players. Cumulative tension varies with algorithmic complexity for AI and correspondingly in human-played games increases abruptly with expertise at about 1600 Elo and again at 2300 Elo. The profiles reveal different approaches. Highly competitive AI tolerates interconnected positions balanced between offensive and defensive tactics over long periods. Human play, in contrast, limits tension and game complexity, which may reflect cognitive limitations and adaptive strategies. The difference may have implications for AI usage in complex, strategic environments. 

**Abstract (ZH)**: æˆ˜ç•¥æ€§å†³ç­–æ¶‰åŠåœ¨å³æ—¶æœºä¼šä¸é•¿æœŸç›®æ ‡ä¹‹é—´è¿›è¡Œç®¡ç†ã€‚æˆ‘ä»¬é€šè¿‡æè¿°å’Œæ¯”è¾ƒäººæœºå¯¹å¼ˆå’ŒAIå¯¹å¼ˆä¹‹é—´çš„åŠ¨æ€å˜åŒ–æ¥ç ”ç©¶è¿™ç§æƒè¡¡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç½‘ç»œçš„æ£‹å­é—´ç›¸äº’ä½œç”¨åº¦é‡æ–¹æ³•ï¼Œä»¥é‡åŒ–æ£‹ç›˜ä¸Šçš„æŒç»­æˆ˜ç•¥å¼ åŠ›ã€‚åœ¨æ•´ä¸ªæ¯”èµ›ä¸­ï¼Œè¿™ç§å¼ åŠ›çš„æ¼”å˜è¡¨æ˜ï¼Œæœ€å…·æœ‰ç«äº‰åŠ›çš„AIç©å®¶åœ¨è¾ƒé•¿æ—¶é—´å†…ç»´æŒæ›´é«˜çš„æˆ˜ç•¥å¼ åŠ›æ°´å¹³ï¼Œè€Œé¡¶çº§äººç±»ç©å®¶åˆ™ä¸ç„¶ã€‚AIçš„ç´¯ç§¯å¼ åŠ›éšç®—æ³•å¤æ‚æ€§çš„å¢åŠ è€Œå˜åŒ–ï¼Œç›¸åº”åœ°ï¼Œåœ¨äººç±»å¯¹å¼ˆä¸­ï¼Œå¼ åŠ›åœ¨å¤§çº¦1600 Eloå’Œ2300 Eloæ—¶å‡ºç°æ€¥å‰§å¢åŠ ã€‚è¿™äº›ç‰¹å¾æ­ç¤ºäº†ä¸åŒçš„ç­–ç•¥ã€‚é«˜åº¦ç«äº‰çš„AIèƒ½å¤Ÿåœ¨é•¿æ—¶é—´å†…å®¹å¿ç›¸äº’è”ç³»çš„ã€å…¼å…·è¿›æ”»æ€§å’Œé˜²å¾¡æ€§çš„æ£‹å±€å¸ƒå±€ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäººç±»çš„ç©æ³•é™åˆ¶äº†å¼ åŠ›å’Œæ¯”èµ›çš„å¤æ‚æ€§ï¼Œè¿™å¯èƒ½åæ˜ äº†è®¤çŸ¥é™åˆ¶å’Œé€‚åº”æ€§ç­–ç•¥ã€‚è¿™ç§å·®å¼‚å¯èƒ½å¯¹åœ¨å¤æ‚æˆ˜ç•¥æ€§ç¯å¢ƒä¸­ä½¿ç”¨AIå…·æœ‰é‡è¦æ„ä¹‰ã€‚ 

---
# QuickMerge++: Fast Token Merging with Autoregressive Prior 

**Title (ZH)**: QuickMerge++ï¼šå¸¦æœ‰è‡ªå›å½’å…ˆéªŒçš„å¿«é€Ÿæ ‡è®°åˆå¹¶ 

**Authors**: Dong Liu, Yanxuan Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13204)  

**Abstract**: As generative models scale to larger inputs across language, vision, and video domains, the cost of token-level computation has become a key bottleneck. While prior work suggests that only a subset of tokens significantly influence downstream predictions, most token selection methods are static, modality-specific, or incompatible with autoregressive generation. In this paper, we propose QuickMerge, a lightweight token merging framework designed for efficient next-token prediction.
QuickMerge dynamically selects a reduced number of tokens based on attention norm magnitude, guided by an entropy-based budget estimator. To preserve autoregressive compatibility, we introduce a lightweight transformer prior trained over the merged token sequence. By combining semantic salience estimation, flexible token budgets, and AR alignment, QuickMerge enables accurate generation with fewer tokens.
We evaluate QuickMerge across multi-modality domains, demonstrating consistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge reduces token counts sustantially while matching as well as exceeding the performance of learned tokenizers and fixed-patch baselines. 

**Abstract (ZH)**: éšç€ç”Ÿæˆæ¨¡å‹åœ¨è¯­è¨€ã€è§†è§‰å’Œè§†é¢‘é¢†åŸŸå¤„ç†æ›´å¤§è¾“å…¥è§„æ¨¡ï¼Œtokençº§è®¡ç®—æˆæœ¬å·²æˆä¸ºå…³é”®ç“¶é¢ˆã€‚å°½ç®¡å…ˆå‰çš„å·¥ä½œè¡¨æ˜åªæœ‰éƒ¨åˆ†tokenå¯¹ä¸‹æ¸¸é¢„æµ‹æœ‰æ˜¾è‘—å½±å“ï¼Œä½†å¤§å¤šæ•°tokené€‰æ‹©æ–¹æ³•éƒ½æ˜¯é™æ€çš„ã€æ¨¡æ€ç‰¹å®šçš„æˆ–ä¸å…¼å®¹è‡ªå›å½’ç”Ÿæˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†QuickMergeï¼Œä¸€ç§è½»é‡çº§çš„tokenåˆå¹¶æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆé¢„æµ‹ä¸‹ä¸€ä¸ªtokenã€‚

QuickMergeæ ¹æ®æ³¨æ„åŠ›èŒƒæ•°å¤§å°åŠ¨æ€é€‰æ‹©å‡å°‘æ•°é‡çš„tokenï¼Œå¹¶ç”±åŸºäºç†µçš„é¢„ç®—ä¼°è®¡å™¨æŒ‡å¯¼ã€‚ä¸ºä¿æŒè‡ªå›å½’å…¼å®¹æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„åœ¨åˆå¹¶tokenåºåˆ—ä¸Šè®­ç»ƒçš„transformerå…ˆéªŒã€‚é€šè¿‡ç»“åˆè¯­ä¹‰æ˜¾è‘—æ€§ä¼°è®¡ã€çµæ´»çš„tokené¢„ç®—å’ŒARå¯¹é½ï¼ŒQuickMergeèƒ½å¤Ÿåœ¨è¾ƒå°‘çš„tokenä¸‹å®ç°å‡†ç¡®çš„ç”Ÿæˆã€‚

æˆ‘ä»¬åœ¨å¤šæ¨¡æ€é¢†åŸŸè¯„ä¼°äº†QuickMergeï¼Œå±•ç¤ºäº†åœ¨è®¡ç®—-å‡†ç¡®ç‡æƒè¡¡ä¸­çš„æŒç»­æ”¹è¿›ã€‚å…·ä½“è€Œè¨€ï¼ŒQuickMergeå¤§å¹…å‡å°‘äº†tokenæ•°é‡ï¼ŒåŒæ—¶åŒ¹é…å¹¶è¶…è¿‡å­¦ä¹ tokenizerå’Œå›ºå®šè¡¥ä¸åŸºçº¿çš„æ€§èƒ½ã€‚ 

---
# The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task 

**Title (ZH)**: æ¨¡å‹çš„å¯è§£é‡Šæ€§åˆ†æå¯ä»¥æ”¹å–„æ–‡æœ¬åˆ°SQLä»»åŠ¡ã€‚ 

**Authors**: Cong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2508.13178)  

**Abstract**: To elevate the foundational capabilities and generalization prowess of the text-to-SQL model in real-world applications, we integrate model interpretability analysis with execution-guided strategy for semantic parsing of WHERE clauses in SQL queries. Furthermore, we augment this approach with filtering adjustments, logical correlation refinements, and model fusion, culminating in the design of the CESQL model that facilitates conditional enhancement. Our model excels on the WikiSQL dataset, which is emblematic of single-table database query tasks, markedly boosting the accuracy of prediction outcomes. When predicting conditional values in WHERE clauses, we have not only minimized our dependence on data within the condition columns of tables but also circumvented the impact of manually labeled training data. Our hope is that this endeavor to enhance accuracy in processing basic database queries will offer fresh perspectives for research into handling complex queries and scenarios featuring irregular data in real-world database environments. 

**Abstract (ZH)**: ä¸ºäº†æå‡æ–‡æœ¬åˆ°SQLæ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„åŸºç¡€èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæˆ‘ä»¬ç»“åˆæ¨¡å‹å¯è§£é‡Šæ€§åˆ†æä¸æ‰§è¡ŒæŒ‡å¯¼ç­–ç•¥ï¼Œä¼˜åŒ–SQLæŸ¥è¯¢ä¸­WHEREå­å¥çš„è¯­ä¹‰è§£æï¼Œå¹¶é€šè¿‡è¿‡æ»¤è°ƒæ•´ã€é€»è¾‘å…³è” refinement å’Œæ¨¡å‹èåˆï¼Œè®¾è®¡å‡ºCESQLæ¨¡å‹ä»¥å®ç°æ¡ä»¶å¢å¼ºã€‚è¯¥æ¨¡å‹åœ¨ä»£è¡¨å•è¡¨æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡çš„WikiSQLæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†é¢„æµ‹ç»“æœçš„å‡†ç¡®æ€§ã€‚åœ¨é¢„æµ‹WHEREå­å¥ä¸­çš„æ¡ä»¶å€¼æ—¶ï¼Œæˆ‘ä»¬ä¸ä»…å‡å°‘äº†å¯¹è¡¨å†…æ¡ä»¶åˆ—æ•°æ®çš„ä¾èµ–ï¼Œè¿˜è§„é¿äº†æ‰‹åŠ¨æ ‡æ³¨è®­ç»ƒæ•°æ®çš„å½±å“ã€‚æˆ‘ä»¬æœŸæœ›è¿™ä¸€æé«˜åŸºæœ¬æ•°æ®åº“æŸ¥è¯¢å¤„ç†å‡†ç¡®æ€§çš„åŠªåŠ›èƒ½ä¸ºå¤„ç†å¤æ‚æŸ¥è¯¢å’ŒåŒ…å«ä¸è§„åˆ™æ•°æ®çš„ç°å®æ•°æ®åº“ç¯å¢ƒä¸­çš„é—®é¢˜æä¾›æ–°çš„ç ”ç©¶è§†è§’ã€‚ 

---
# Fitting Ontologies and Constraints to Relational Structures 

**Title (ZH)**: å°†æœ¬ä½“å’Œçº¦æŸé€‚é…åˆ°å…³ç³»ç»“æ„ 

**Authors**: Simon Hosemann, Jean Christoph Jung, Carsten Lutz, Sebastian Rudolph  

**Link**: [PDF](https://arxiv.org/pdf/2508.13176)  

**Abstract**: We study the problem of fitting ontologies and constraints to positive and negative examples that take the form of a finite relational structure. As ontology and constraint languages, we consider the description logics $\mathcal{E\mkern-2mu L}$ and $\mathcal{E\mkern-2mu LI}$ as well as several classes of tuple-generating dependencies (TGDs): full, guarded, frontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion dependencies. We pinpoint the exact computational complexity, design algorithms, and analyze the size of fitting ontologies and TGDs. We also investigate the related problem of constructing a finite basis of concept inclusions / TGDs for a given set of finite structures. While finite bases exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs, and inclusion dependencies, they in general do not exist for full, frontier-guarded and frontier-one TGDs. 

**Abstract (ZH)**: æˆ‘ä»¬ç ”ç©¶å°†æè¿°é€»è¾‘$\mathcal{E\mkern-2mu L}$å’Œ$\mathcal{E\mkern-2mu LI}$ä»¥åŠå¤šç§å…ƒç»„ç”Ÿæˆä¾èµ–ï¼ˆTGDsï¼‰ï¼šå…¨ä¾èµ–ã€ä¿æŠ¤ä¾èµ–ã€è¾¹ç•Œä¿æŠ¤ä¾èµ–ã€è¾¹ç•Œå•ä¸€ä¾èµ–å’Œæ— é™åˆ¶ä¾èµ–ï¼Œä»¥åŠåŒ…å«ä¾èµ–åº”ç”¨äºæ­£è´Ÿä¾‹å­ï¼ˆå½¢å¼ä¸ºæœ‰é™å…³ç³»ç»“æ„ï¼‰çš„é—®é¢˜ã€‚æˆ‘ä»¬ç¡®å®šäº†æ‹Ÿåˆæœ¬ä½“å’ŒTGDsçš„ç¡®åˆ‡è®¡ç®—å¤æ‚æ€§ï¼Œè®¾è®¡äº†ç®—æ³•ï¼Œå¹¶åˆ†æäº†æ‹Ÿåˆæœ¬ä½“å’ŒTGDsçš„å¤§å°ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†ä¸ºç»™å®šçš„ä¸€ç»„æœ‰é™ç»“æ„æ„é€ æ¦‚å¿µåŒ…å«/TGDsæœ‰é™åŸºçš„ç›¸å…³é—®é¢˜ã€‚è™½ç„¶$\mathcal{E\mkern-2mu L}$ã€$\mathcal{E\mkern-2mu LI}$ã€ä¿æŠ¤TGDså’ŒåŒ…å«ä¾èµ–å­˜åœ¨æœ‰é™åŸºï¼Œä½†å…¨TGDsã€è¾¹ç•Œä¿æŠ¤TGDså’Œè¾¹ç•Œå•ä¸€TGDsé€šå¸¸ä¸å­˜åœ¨æœ‰é™åŸºã€‚ 

---
# AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining 

**Title (ZH)**: AlphaEval: å…¬å¼AlphaæŒ–æ˜çš„å…¨é¢é«˜æ•ˆè¯„ä¼°æ¡†æ¶ 

**Authors**: Hongjun Ding, Binqi Chen, Jinsheng Huang, Taian Guo, Zhengyang Mao, Guoyi Shao, Lutong Zou, Luchen Liu, Ming Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2508.13174)  

**Abstract**: Formula alpha mining, which generates predictive signals from financial data, is critical for quantitative investment. Although various algorithmic approaches-such as genetic programming, reinforcement learning, and large language models-have significantly expanded the capacity for alpha discovery, systematic evaluation remains a key challenge. Existing evaluation metrics predominantly include backtesting and correlation-based measures. Backtesting is computationally intensive, inherently sequential, and sensitive to specific strategy parameters. Correlation-based metrics, though efficient, assess only predictive ability and overlook other crucial properties such as temporal stability, robustness, diversity, and interpretability. Additionally, the closed-source nature of most existing alpha mining models hinders reproducibility and slows progress in this field. To address these issues, we propose AlphaEval, a unified, parallelizable, and backtest-free evaluation framework for automated alpha mining models. AlphaEval assesses the overall quality of generated alphas along five complementary dimensions: predictive power, stability, robustness to market perturbations, financial logic, and diversity. Extensive experiments across representative alpha mining algorithms demonstrate that AlphaEval achieves evaluation consistency comparable to comprehensive backtesting, while providing more comprehensive insights and higher efficiency. Furthermore, AlphaEval effectively identifies superior alphas compared to traditional single-metric screening approaches. All implementations and evaluation tools are open-sourced to promote reproducibility and community engagement. 

**Abstract (ZH)**: å…¬å¼Î±æŒ–æ˜çš„ç»¼åˆè¯„ä»·ï¼šä¸€ç§æ— å›æµ‹çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ 

---
# Efficient Knowledge Graph Unlearning with Zeroth-order Information 

**Title (ZH)**: åŸºäºé›¶é˜¶ä¿¡æ¯çš„é«˜æ•ˆçŸ¥è¯†å›¾è°±é—å¿˜æŠ€æœ¯ 

**Authors**: Yang Xiao, Ruimeng Ye, Bohan Liu, Xiaolong Ma, Bo Hui  

**Link**: [PDF](https://arxiv.org/pdf/2508.14013)  

**Abstract**: Due to regulations like the Right to be Forgotten, there is growing demand for removing training data and its influence from models. Since full retraining is costly, various machine unlearning methods have been proposed. In this paper, we firstly present an efficient knowledge graph (KG) unlearning algorithm. We remark that KG unlearning is nontrivial due to the distinctive structure of KG and the semantic relations between entities. Also, unlearning by estimating the influence of removed components incurs significant computational overhead when applied to large-scale knowledge graphs. To this end, we define an influence function for KG unlearning and propose to approximate the model's sensitivity without expensive computation of first-order and second-order derivatives for parameter updates. Specifically, we use Taylor expansion to estimate the parameter changes caused by data removal. Given that the first-order gradients and second-order derivatives dominate the computational load, we use the Fisher matrices and zeroth-order optimization to approximate the inverse-Hessian vector product without constructing the computational graphs. Our experimental results demonstrate that the proposed method outperforms other state-of-the-art graph unlearning baselines significantly in terms of unlearning efficiency and unlearning quality. Our code is released at this https URL. 

**Abstract (ZH)**: ç”±äºåƒâ€œè¢«é—å¿˜æƒâ€è¿™æ ·çš„è§„å®šï¼Œä»æ¨¡å‹ä¸­ç§»é™¤è®­ç»ƒæ•°æ®åŠå…¶å½±å“çš„éœ€æ±‚æ—¥ç›Šå¢é•¿ã€‚ç”±äºå…¨é¢é‡æ–°è®­ç»ƒæˆæœ¬è¾ƒé«˜ï¼Œå·²ç»æå‡ºäº†å¤šç§æœºå™¨é—å¿˜æ–¹æ³•ã€‚æœ¬æ–‡é¦–å…ˆæå‡ºä¸€ä¸ªé«˜æ•ˆçš„çŸ¥è¯†å›¾è°±(KG)é—å¿˜ç®—æ³•ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œç”±äºçŸ¥è¯†å›¾è°±çš„ç‹¬ç‰¹ç»“æ„åŠå…¶å®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ŒçŸ¥è¯†å›¾è°±é—å¿˜å¹¶éæ˜“äº‹ã€‚æ­¤å¤–ï¼Œåœ¨å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±ä¸Šé€šè¿‡ä¼°ç®—ç§»é™¤ç»„ä»¶çš„å½±å“æ¥å®ç°é—å¿˜ä¼šå¸¦æ¥æ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªçŸ¥è¯†å›¾è°±é—å¿˜çš„å½±å“å‡½æ•°ï¼Œå¹¶æå‡ºäº†ä¸€ç§åœ¨ä¸è¿›è¡Œæ˜‚è´µçš„ä¸€é˜¶å’ŒäºŒé˜¶å¯¼æ•°è®¡ç®—çš„æƒ…å†µä¸‹è¿‘ä¼¼æ¨¡å‹æ•æ„Ÿæ€§çš„æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨æ³°å‹’å±•å¼€æ¥ä¼°è®¡ç”±äºæ•°æ®ç§»é™¤å¼•èµ·å‚æ•°çš„å˜åŒ–ã€‚é‰´äºä¸€é˜¶æ¢¯åº¦å’ŒäºŒé˜¶å¯¼æ•°ä¸»å¯¼è®¡ç®—è´Ÿè½½ï¼Œæˆ‘ä»¬ä½¿ç”¨è´¹èˆå°”çŸ©é˜µå’Œé›¶é˜¶ä¼˜åŒ–æ¥è¿‘ä¼¼é€†æµ·æ£®çŸ©é˜µå‘é‡ç§¯ï¼Œè€Œæ— éœ€æ„å»ºè®¡ç®—å›¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨é—å¿˜æ•ˆç‡å’Œé—å¿˜è´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æœ€æ–°çš„å›¾é—å¿˜åŸºçº¿æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å‘å¸ƒåœ¨è¯¥ç½‘å€ï¼šhttps://xxxxxxã€‚ 

---
# Evaluating Identity Leakage in Speaker De-Identification Systems 

**Title (ZH)**: è¯„ä¼°è®²è€…å»æ ‡è¯†åŒ–ç³»ç»Ÿä¸­çš„èº«ä»½æ³„éœ² 

**Authors**: Seungmin Seo, Oleg Aulov, Afzal Godil, Kevin Mangold  

**Link**: [PDF](https://arxiv.org/pdf/2508.14012)  

**Abstract**: Speaker de-identification aims to conceal a speaker's identity while preserving intelligibility of the underlying speech. We introduce a benchmark that quantifies residual identity leakage with three complementary error rates: equal error rate, cumulative match characteristic hit rate, and embedding-space similarity measured via canonical correlation analysis and Procrustes analysis. Evaluation results reveal that all state-of-the-art speaker de-identification systems leak identity information. The highest performing system in our evaluation performs only slightly better than random guessing, while the lowest performing system achieves a 45% hit rate within the top 50 candidates based on CMC. These findings highlight persistent privacy risks in current speaker de-identification technologies. 

**Abstract (ZH)**: æ¼”è®²è€…å»æ ‡è¯†åŒ–æ—¨åœ¨ä¿æŠ¤æ¼”è®²è€…èº«ä»½çš„åŒæ—¶ä¿ç•™å…¶è¯­éŸ³å†…å®¹çš„å¯ç†è§£æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºå‡†ï¼Œé€šè¿‡ä¸‰ç§äº’è¡¥çš„é”™è¯¯ç‡æ¥é‡åŒ–å‰©ä½™çš„èº«ä»½æ³„éœ²ï¼šç­‰é”™è¯¯ç‡ã€ç´¯ç§¯åŒ¹é…ç‰¹å¾å‘½ä¸­ç‡ï¼Œä»¥åŠé€šè¿‡å…¸å‹ç›¸å…³åˆ†æå’ŒProcrustesåˆ†ææµ‹é‡çš„åµŒå…¥ç©ºé—´ç›¸ä¼¼æ€§ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æœ€æ–°çš„æ¼”è®²è€…å»æ ‡è¯†åŒ–ç³»ç»Ÿéƒ½ä¼šæ³„éœ²èº«ä»½ä¿¡æ¯ã€‚æˆ‘ä»¬åœ¨è¯„ä¼°ä¸­è¡¨ç°æœ€å¥½çš„ç³»ç»Ÿä»…æ¯”éšæœºçŒœæµ‹ç•¥å¥½ï¼Œè€Œè¡¨ç°æœ€å·®çš„ç³»ç»Ÿåœ¨åŸºäºCMCçš„å‰50ä¸ªå€™é€‰é¡¹ä¸­è¾¾åˆ°äº†45%çš„å‘½ä¸­ç‡ã€‚è¿™äº›å‘ç°çªæ˜¾äº†å½“å‰æ¼”è®²è€…å»æ ‡è¯†åŒ–æŠ€æœ¯ä¸­å­˜åœ¨çš„æŒç»­éšç§é£é™©ã€‚ 

---
# ASDFormer: A Transformer with Mixtures of Pooling-Classifier Experts for Robust Autism Diagnosis and Biomarker Discovery 

**Title (ZH)**: ASDFormer: ç»“åˆæ± åŒ–åˆ†ç±»ä¸“å®¶æ··åˆçš„å˜å‹å™¨æ¨¡å‹ï¼Œç”¨äºç¨³å¥çš„è‡ªé—­ç—‡è¯Šæ–­å’Œç”Ÿç‰©æ ‡å¿—ç‰©å‘ç° 

**Authors**: Mohammad Izadi, Mehran Safayani  

**Link**: [PDF](https://arxiv.org/pdf/2508.14005)  

**Abstract**: Autism Spectrum Disorder (ASD) is a complex neurodevelopmental condition marked by disruptions in brain connectivity. Functional MRI (fMRI) offers a non-invasive window into large-scale neural dynamics by measuring blood-oxygen-level-dependent (BOLD) signals across the brain. These signals can be modeled as interactions among Regions of Interest (ROIs), which are grouped into functional communities based on their underlying roles in brain function. Emerging evidence suggests that connectivity patterns within and between these communities are particularly sensitive to ASD-related alterations. Effectively capturing these patterns and identifying interactions that deviate from typical development is essential for improving ASD diagnosis and enabling biomarker discovery. In this work, we introduce ASDFormer, a Transformer-based architecture that incorporates a Mixture of Pooling-Classifier Experts (MoE) to capture neural signatures associated with ASD. By integrating multiple specialized expert branches with attention mechanisms, ASDFormer adaptively emphasizes different brain regions and connectivity patterns relevant to autism. This enables both improved classification performance and more interpretable identification of disorder-related biomarkers. Applied to the ABIDE dataset, ASDFormer achieves state-of-the-art diagnostic accuracy and reveals robust insights into functional connectivity disruptions linked to ASD, highlighting its potential as a tool for biomarker discovery. 

**Abstract (ZH)**: è‡ªé—­ç—‡è°±ç³»éšœç¢ï¼ˆASDï¼‰æ˜¯ä¸€ç§å¤æ‚çš„ç¥ç»å‘è‚²æ¡ä»¶ï¼Œç‰¹å¾ä¸ºè„‘è¿æ¥æ€§ä¸­æ–­ã€‚åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰é€šè¿‡æµ‹é‡æ•´ä¸ªå¤§è„‘çš„è¡€æ°§æ°´å¹³ä¾èµ–ï¼ˆBOLDï¼‰ä¿¡å·æä¾›äº†ä¸€ç§æ— åˆ›çš„å¤§è§„æ¨¡ç¥ç»åŠ¨åŠ›å­¦çª—å£ã€‚è¿™äº›ä¿¡å·å¯å»ºæ¨¡ä¸ºæ„Ÿå…´è¶£åŒºï¼ˆROIsï¼‰ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæ ¹æ®ä¸åŒè„‘åŠŸèƒ½çš„æ½œåœ¨ä½œç”¨ï¼Œå°†è¿™äº›åŒºåˆ†ä¸ºåŠŸèƒ½æ€§ç¤¾åŒºã€‚æ–°å…´çš„è¯æ®è¡¨æ˜ï¼Œè¿™äº›ç¤¾åŒºå†…éƒ¨åŠä¹‹é—´çš„è¿æ¥æ¨¡å¼ç‰¹åˆ«å®¹æ˜“å—åˆ°ä¸ASDç›¸å…³çš„æ”¹å˜å½±å“ã€‚æœ‰æ•ˆæ•æ‰è¿™äº›æ¨¡å¼å¹¶è¯†åˆ«åç¦»æ­£å¸¸å‘è‚²çš„ç›¸äº’ä½œç”¨å¯¹äºæé«˜ASDè¯Šæ–­èƒ½åŠ›å’Œä¿ƒè¿›ç”Ÿç‰©æ ‡å¿—ç‰©å‘ç°è‡³å…³é‡è¦ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ASDFormerï¼Œè¿™æ˜¯ä¸€ç§åŸºäºTransformerçš„æ¶æ„ï¼Œç»“åˆäº†æ··åˆæ± åŒ–åˆ†ç±»ä¸“å®¶ï¼ˆMoEï¼‰ä»¥æ•æ‰ä¸ASDç›¸å…³çš„ç¥ç»ç‰¹å¾ã€‚é€šè¿‡é›†æˆå¤šç§ä¸“é—¨çš„ä¸“å®¶åˆ†æ”¯å’Œæ³¨æ„æœºåˆ¶ï¼ŒASDFormerèƒ½å¤Ÿè‡ªé€‚åº”åœ°å¼ºè°ƒä¸è‡ªé—­ç—‡ç›¸å…³çš„ä¸åŒè„‘åŒºå’Œè¿æ¥æ¨¡å¼ï¼Œä»è€Œæé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œå¹¶æ›´æ˜“äºè¯†åˆ«ä¸ç–¾ç—…ç›¸å…³çš„ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚åœ¨ABIDEæ•°æ®é›†ä¸Šçš„åº”ç”¨è¯æ˜ï¼ŒASDFormerå®ç°äº†æœ€å…ˆè¿›çš„è¯Šæ–­å‡†ç¡®æ€§ï¼Œå¹¶æ­ç¤ºäº†ä¸ASDç›¸å…³çš„åŠŸèƒ½æ€§è¿æ¥ä¸­æ–­çš„ç¨³å¥è§è§£ï¼Œçªæ˜¾äº†å…¶ä½œä¸ºç”Ÿç‰©æ ‡å¿—ç‰©å‘ç°å·¥å…·çš„æ½œåŠ›ã€‚ 

---
# A Mechanism for Mutual Fairness in Cooperative Games with Replicable Resources -- Extended Version 

**Title (ZH)**: å…·æœ‰å¯å¤åˆ¶èµ„æºçš„åˆä½œåšå¼ˆä¸­çš„ç›¸äº’å…¬å¹³æœºåˆ¶â€”â€”æ‰©å±•ç‰ˆæœ¬ 

**Authors**: BjÃ¶rn Filter, Ralf MÃ¶ller, Ã–zgÃ¼r LÃ¼tfÃ¼ Ã–zÃ§ep  

**Link**: [PDF](https://arxiv.org/pdf/2508.13960)  

**Abstract**: The latest developments in AI focus on agentic systems where artificial and human agents cooperate to realize global goals. An example is collaborative learning, which aims to train a global model based on data from individual agents. A major challenge in designing such systems is to guarantee safety and alignment with human values, particularly a fair distribution of rewards upon achieving the global goal. Cooperative game theory offers useful abstractions of cooperating agents via value functions, which assign value to each coalition, and via reward functions. With these, the idea of fair allocation can be formalized by specifying fairness axioms and designing concrete mechanisms. Classical cooperative game theory, exemplified by the Shapley value, does not fully capture scenarios like collaborative learning, as it assumes nonreplicable resources, whereas data and models can be replicated. Infinite replicability requires a generalized notion of fairness, formalized through new axioms and mechanisms. These must address imbalances in reciprocal benefits among participants, which can lead to strategic exploitation and unfair allocations. The main contribution of this paper is a mechanism and a proof that it fulfills the property of mutual fairness, formalized by the Balanced Reciprocity Axiom. It ensures that, for every pair of players, each benefits equally from the participation of the other. 

**Abstract (ZH)**: æœ€è¿‘äººå·¥æ™ºèƒ½çš„å‘å±•é›†ä¸­åœ¨ä»£ç†ç³»ç»Ÿé¢†åŸŸï¼Œå…¶ä¸­äººå·¥ä»£ç†å’Œäººç±»ä»£ç†åä½œä»¥å®ç°å…¨çƒç›®æ ‡ã€‚ä¾‹å¦‚ï¼Œåä½œå­¦ä¹ æ—¨åœ¨åŸºäºä¸ªä½“ä»£ç†çš„æ•°æ®è®­ç»ƒå…¨çƒæ¨¡å‹ã€‚è®¾è®¡æ­¤ç±»ç³»ç»Ÿçš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ç¡®ä¿å®‰å…¨å¹¶ä¸å…¶äººç±»ä»·å€¼è§‚ä¿æŒä¸€è‡´ï¼Œç‰¹åˆ«æ˜¯å…¨çƒç›®æ ‡è¾¾æˆåçš„å¥–åŠ±å…¬å¹³åˆ†é…ã€‚åˆä½œåšå¼ˆè®ºé€šè¿‡ä»·å€¼å‡½æ•°å’Œå¥–åŠ±å‡½æ•°æä¾›äº†åˆä½œä»£ç†çš„æœ‰æ•ˆæŠ½è±¡ï¼Œè¿™äº›å¯ä»¥æ­£å¼åŒ–å…¬å¹³åˆ†é…çš„æ¦‚å¿µï¼Œé€šè¿‡æŒ‡å®šå…¬å¹³å…¬ç†å¹¶è®¾è®¡å…·ä½“çš„æœºåˆ¶ã€‚ç»å…¸çš„åˆä½œåšå¼ˆè®ºå¦‚å¤æ™®åˆ©å€¼æœªèƒ½å……åˆ†æ•æ‰åˆ°å¦‚åä½œå­¦ä¹ è¿™æ ·çš„åœºæ™¯ï¼Œå› ä¸ºå®ƒå‡è®¾èµ„æºä¸å¯å¤åˆ¶ï¼Œè€Œæ•°æ®å’Œæ¨¡å‹æ˜¯å¯ä»¥å¤åˆ¶çš„ã€‚æ— é™å¯å¤åˆ¶æ€§éœ€è¦é€šè¿‡æ–°çš„å…¬ç†å’Œæœºåˆ¶æ¥å½¢å¼åŒ–çš„å¹¿ä¹‰å…¬å¹³æ¦‚å¿µã€‚è¿™äº›æœºåˆ¶å¿…é¡»è§£å†³å‚ä¸è€…ä¹‹é—´ç›¸äº’åˆ©ç›Šä¸å¹³è¡¡çš„é—®é¢˜ï¼Œè¿™å¯èƒ½å¯¼è‡´æˆ˜ç•¥ä¸Šçš„å‰¥å‰Šå’Œä¸å…¬å¹³çš„åˆ†é…ã€‚æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä¸€ç§æœºåˆ¶åŠå…¶è¯æ˜ï¼Œè¯¥æœºåˆ¶æ»¡è¶³å¹³è¡¡äº’æƒ å…¬ç†æ‰€å½¢å¼åŒ–çš„äº’æƒ å…¬å¹³æ€§å±æ€§ï¼Œç¡®ä¿å¯¹æ¯ä¸€å¯¹ç©å®¶è€Œè¨€ï¼Œä»–ä»¬éƒ½ä»å½¼æ­¤çš„å‚ä¸ä¸­è·å¾—å¹³ç­‰çš„æ”¶ç›Šã€‚ 

---
# Fisher-Orthogonal Projection Methods for Natural Gradient Descent with Large Batches 

**Title (ZH)**: Fisher-æ­£äº¤æŠ•å½±æ–¹æ³•åœ¨å¤§æ•°æ®æ‰¹é‡ä¸‹çš„è‡ªç„¶æ¢¯åº¦ä¸‹é™ 

**Authors**: Yishun Lu, Wesley Armour  

**Link**: [PDF](https://arxiv.org/pdf/2508.13898)  

**Abstract**: Modern GPUs are equipped with large amounts of high-bandwidth memory, enabling them to support mini-batch sizes of up to tens of thousands of training samples. However, most existing optimizers struggle to perform effectively at such a large batch size. As batch size increases, gradient noise decreases due to averaging over many samples, limiting the ability of first-order methods to escape sharp or suboptimal minima and reach the global minimum. Meanwhile, second-order methods like the natural gradient with Kronecker-Factored Approximate Curvature (KFAC) often require excessively high damping to remain stable at large batch sizes. This high damping effectively washes out the curvature information that gives these methods their advantage, reducing their performance to that of simple gradient descent. In this paper, we introduce Fisher-Orthogonal Projection (FOP), a novel technique that restores the effectiveness of the second-order method at very large batch sizes, enabling scalable training with improved generalization and faster convergence. FOP constructs a variance-aware update direction by leveraging gradients from two sub-batches, enhancing the average gradient with a component of the gradient difference that is orthogonal to the average under the Fisher-metric. 

**Abstract (ZH)**: ç°ä»£GPUé…å¤‡äº†å¤§å®¹é‡é«˜å¸¦å®½å†…å­˜ï¼Œä½¿å…¶èƒ½å¤Ÿæ”¯æŒæ•°ä¸‡çº§çš„è®­ç»ƒæ ·æœ¬æ‰¹é‡å¤§å°ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§å¤šæ•°ä¼˜åŒ–å™¨åœ¨å¦‚æ­¤å¤§çš„æ‰¹é‡å¤§å°ä¸‹éš¾ä»¥æœ‰æ•ˆå·¥ä½œã€‚éšç€æ‰¹é‡å¤§å°çš„å¢åŠ ï¼Œç”±äºå¯¹ä¼—å¤šæ ·æœ¬è¿›è¡Œå¹³å‡ï¼Œæ¢¯åº¦å™ªå£°ä¼šå‡å°‘ï¼Œé™åˆ¶äº†åŸºäºä¸€é˜¶æ–¹æ³•ä»å°–é”æˆ–æ¬¡ä¼˜æå°å€¼ä¸­é€ƒé€¸å¹¶è¾¾åˆ°å…¨å±€æå°å€¼çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå¦‚Kronecker-Factored Approximate Curvature (KFAC) è‡ªç„¶æ¢¯åº¦ç­‰äºŒé˜¶æ–¹æ³•åœ¨å¤§æ‰¹é‡å¤§å°ä¸‹é€šå¸¸éœ€è¦æå¤§çš„é˜»å°¼ä»¥ä¿æŒç¨³å®šï¼Œè¿™ç§é«˜é˜»å°¼æœ‰æ•ˆæ¶ˆé™¤äº†è¿™äº›æ–¹æ³•å…·æœ‰çš„æ›²ç‡ä¿¡æ¯ä¼˜åŠ¿ï¼Œä½¿å…¶æ€§èƒ½é™ä½åˆ°ç®€å•çš„æ¢¯åº¦ä¸‹é™çš„æ°´å¹³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†Fisher-æ­£äº¤æŠ•å½±ï¼ˆFOPï¼‰è¿™ä¸€æ–°é¢–çš„æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å¯ä»¥åœ¨éå¸¸å¤§çš„æ‰¹é‡å¤§å°ä¸‹æ¢å¤äºŒé˜¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œå®ç°å¯æ‰©å±•çš„è®­ç»ƒå¹¶æé«˜æ³›åŒ–èƒ½åŠ›å’ŒåŠ é€Ÿæ”¶æ•›ã€‚FOPé€šè¿‡åˆ©ç”¨ä¸¤ä¸ªå­æ‰¹é‡çš„æ¢¯åº¦æ„é€ å‡ºä¸€ä¸ªæ–¹å·®æ„ŸçŸ¥çš„æ›´æ–°æ–¹å‘ï¼Œåœ¨Fisheråº¦é‡ä¸‹ï¼Œé€šè¿‡å¢åŠ æ¢¯åº¦å·®å¼‚çš„æ­£äº¤åˆ†é‡æ¥å¢å¼ºå¹³å‡æ¢¯åº¦ã€‚ 

---
# One Shot vs. Iterative: Rethinking Pruning Strategies for Model Compression 

**Title (ZH)**: ä¸€æ¬¡è£å‰ª vs. è¿­ä»£è£å‰ªï¼šé‡æ–°æ€è€ƒæ¨¡å‹å‹ç¼©çš„è£å‰ªç­–ç•¥ 

**Authors**: MikoÅ‚aj Janusz, Tomasz Wojnar, Yawei Li, Luca Benini, Kamil Adamczewski  

**Link**: [PDF](https://arxiv.org/pdf/2508.13836)  

**Abstract**: Pruning is a core technique for compressing neural networks to improve computational efficiency. This process is typically approached in two ways: one-shot pruning, which involves a single pass of training and pruning, and iterative pruning, where pruning is performed over multiple cycles for potentially finer network refinement. Although iterative pruning has historically seen broader adoption, this preference is often assumed rather than rigorously tested. Our study presents one of the first systematic and comprehensive comparisons of these methods, providing rigorous definitions, benchmarking both across structured and unstructured settings, and applying different pruning criteria and modalities. We find that each method has specific advantages: one-shot pruning proves more effective at lower pruning ratios, while iterative pruning performs better at higher ratios. Building on these findings, we advocate for patience-based pruning and introduce a hybrid approach that can outperform traditional methods in certain scenarios, providing valuable insights for practitioners selecting a pruning strategy tailored to their goals and constraints. Source code is available at this https URL. 

**Abstract (ZH)**: å‰ªææ˜¯å‹ç¼©ç¥ç»ç½‘ç»œä»¥æé«˜è®¡ç®—æ•ˆç‡çš„æ ¸å¿ƒæŠ€æœ¯ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸æœ‰ä¸¤ç§æ–¹å¼ï¼šå•æ¬¡å‰ªæï¼Œå³é€šè¿‡ä¸€æ¬¡è®­ç»ƒå’Œå‰ªæå®Œæˆï¼›è¿­ä»£å‰ªæï¼Œåˆ™é€šè¿‡å¤šæ¬¡å¾ªç¯å‰ªæä»¥å®ç°æ›´ç²¾ç»†çš„ç½‘ç»œä¼˜åŒ–ã€‚å°½ç®¡è¿­ä»£å‰ªæåœ¨è¿‡å»æ›´ä¸ºå¸¸ç”¨ï¼Œä½†è¿™ç§åå¥½é€šå¸¸è¢«è®¤ä¸ºæ˜¯ç†æ‰€å½“ç„¶çš„ï¼Œè€Œéç»è¿‡ä¸¥æ ¼çš„æµ‹è¯•ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†é¦–æ¬¡ç³»ç»Ÿä¸”å…¨é¢åœ°æ¯”è¾ƒè¿™ä¸¤ç§æ–¹æ³•çš„å°è¯•ï¼Œæå‡ºäº†ä¸¥æ ¼çš„å®šä¹‰ï¼Œè·¨ç»“æ„åŒ–å’Œéç»“æ„åŒ–è®¾ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå¹¶åº”ç”¨ä¸åŒçš„å‰ªææ ‡å‡†å’Œæ¨¡å¼ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ¯ç§æ–¹æ³•å„æœ‰ä¼˜åŠ¿ï¼šå•æ¬¡å‰ªæåœ¨è¾ƒä½å‰ªææ¯”ä¾‹ä¸‹æ›´æœ‰æ•ˆï¼Œè€Œè¿­ä»£å‰ªæåœ¨è¾ƒé«˜æ¯”ä¾‹ä¸‹è¡¨ç°æ›´å¥½ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå€¡åŸºäºè€å¿ƒçš„å‰ªæï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ï¼Œä¸ºä»ä¸šè€…é€‰æ‹©äº†ç¬¦åˆå…¶ç›®æ ‡å’Œçº¦æŸæ¡ä»¶çš„å‰ªæç­–ç•¥æä¾›äº†å®è´µçš„è§è§£ã€‚ç›¸å…³æºä»£ç å¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ã€‚ 

---
# Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling 

**Title (ZH)**: ä»å»ºç­‘æŠ€æœ¯è§„èŒƒä¸­æå–ç»“æ„åŒ–éœ€æ±‚ä»¥æ”¯æŒå»ºç­‘ä¿¡æ¯å»ºæ¨¡ 

**Authors**: Insaf Nahri, Romain PinquiÃ©, Philippe VÃ©ron, Nicolas Bus, Mathieu Thorel  

**Link**: [PDF](https://arxiv.org/pdf/2508.13833)  

**Abstract**: This study explores the integration of Building Information Modeling (BIM) with Natural Language Processing (NLP) to automate the extraction of requirements from unstructured French Building Technical Specification (BTS) documents within the construction industry. Employing Named Entity Recognition (NER) and Relation Extraction (RE) techniques, the study leverages the transformer-based model CamemBERT and applies transfer learning with the French language model Fr\_core\_news\_lg, both pre-trained on a large French corpus in the general domain. To benchmark these models, additional approaches ranging from rule-based to deep learning-based methods are developed. For RE, four different supervised models, including Random Forest, are implemented using a custom feature vector. A hand-crafted annotated dataset is used to compare the effectiveness of NER approaches and RE models. Results indicate that CamemBERT and Fr\_core\_news\_lg exhibited superior performance in NER, achieving F1-scores over 90\%, while Random Forest proved most effective in RE, with an F1 score above 80\%. The outcomes are intended to be represented as a knowledge graph in future work to further enhance automatic verification systems. 

**Abstract (ZH)**: æœ¬ç ”ç©¶æ¢ç´¢å°†å»ºç­‘ä¿¡æ¯å»ºæ¨¡ï¼ˆBIMï¼‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é›†æˆï¼Œä»¥è‡ªåŠ¨åŒ–æå– construction è¡Œä¸šæœªç»“æ„åŒ–æ³•å›½å»ºç­‘æŠ€æœ¯è§„èŒƒï¼ˆBTSï¼‰æ–‡æ¡£ä¸­çš„è¦æ±‚ã€‚åˆ©ç”¨å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰å’Œå…³ç³»æå–ï¼ˆREï¼‰æŠ€æœ¯ï¼Œç ”ç©¶åˆ©ç”¨åŸºäºå˜æ¢å™¨çš„æ¨¡å‹ CamemBERTï¼Œå¹¶é‡‡ç”¨ä¸é€šç”¨é¢†åŸŸå¤§è§„æ¨¡æ³•è¯­æ–‡æœ¬é¢„è®­ç»ƒçš„ French è¯­è¨€æ¨¡å‹ Fr\_core\_news\_lg ç»“åˆçš„è¿ç§»å­¦ä¹ æ–¹æ³•ã€‚ä¸ºäº†è¯„ä¼°è¿™äº›æ¨¡å‹ï¼Œè¿˜å¼€å‘äº†ä»è§„åˆ™åŸºäºåˆ°æ·±åº¦å­¦ä¹ åŸºäºçš„å„ç§æ–¹æ³•ã€‚å¯¹äº REï¼Œå®ç°å››ç§ç›‘ç£æ¨¡å‹ï¼ŒåŒ…æ‹¬éšæœºæ£®æ—ï¼Œä½¿ç”¨å®šåˆ¶ç‰¹å¾å‘é‡ã€‚ä½¿ç”¨æ‰‹å·¥æ ‡æ³¨æ•°æ®é›†æ¥æ¯”è¾ƒ NER æ–¹æ³•å’Œ RE æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ç»“æœæ˜¾ç¤ºï¼ŒCamemBERT å’Œ Fr\_core\_news\_lg åœ¨ NER ä¸­è¡¨ç°å‡ºè‰²ï¼ŒF1 åˆ†æ•°è¶…è¿‡ 90%ï¼Œè€Œéšæœºæ£®æ—åœ¨ RE ä¸­è¡¨ç°æœ€ä½³ï¼ŒF1 åˆ†æ•°è¶…è¿‡ 80%ã€‚ç ”ç©¶ç»“æœæ—¨åœ¨æœªæ¥å·¥ä½œé€šè¿‡çŸ¥è¯†å›¾è°±å½¢å¼è¿›ä¸€æ­¥å¢å¼ºè‡ªåŠ¨åŒ–éªŒè¯ç³»ç»Ÿã€‚ 

---
# The illusion of a perfect metric: Why evaluating AI's words is harder than it looks 

**Title (ZH)**: å®Œç¾åº¦é‡çš„å¹»è±¡ï¼šä¸ºä½•è¯„ä¼°AIçš„è¯è¯­æ¯”çœ‹èµ·æ¥çš„è¦å›°éš¾å¾—å¤š 

**Authors**: Maria Paz Oliva, Adriana Correia, Ivan Vankov, Viktor Botev  

**Link**: [PDF](https://arxiv.org/pdf/2508.13816)  

**Abstract**: Evaluating Natural Language Generation (NLG) is crucial for the practical adoption of AI, but has been a longstanding research challenge. While human evaluation is considered the de-facto standard, it is expensive and lacks scalability. Practical applications have driven the development of various automatic evaluation metrics (AEM), designed to compare the model output with human-written references, generating a score which approximates human judgment. Over time, AEMs have evolved from simple lexical comparisons, to semantic similarity models and, more recently, to LLM-based evaluators. However, it seems that no single metric has emerged as a definitive solution, resulting in studies using different ones without fully considering the implications. This paper aims to show this by conducting a thorough examination of the methodologies of existing metrics, their documented strengths and limitations, validation methods, and correlations with human judgment. We identify several key challenges: metrics often capture only specific aspects of text quality, their effectiveness varies by task and dataset, validation practices remain unstructured, and correlations with human judgment are inconsistent. Importantly, we find that these challenges persist in the most recent type of metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented Generation (RAG), an increasingly relevant task in academia and industry. Our findings challenge the quest for the 'perfect metric'. We propose selecting metrics based on task-specific needs and leveraging complementary evaluations and advocate that new metrics should focus on enhanced validation methodologies. 

**Abstract (ZH)**: è¯„ä¼°è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰å¯¹äºäººå·¥æ™ºèƒ½çš„å®é™…åº”ç”¨è‡³å…³é‡è¦ï¼Œä½†ä¸€ç›´æ˜¯ä¸€ä¸ªé•¿æœŸçš„ç ”ç©¶æŒ‘æˆ˜ã€‚å°½ç®¡äººç±»è¯„ä¼°è¢«è®¤ä¸ºæ˜¯æ ‡å‡†æ–¹æ³•ï¼Œä½†å®ƒæˆæœ¬é«˜ä¸”ç¼ºä¹å¯æ‰©å±•æ€§ã€‚å®é™…åº”ç”¨æ¨åŠ¨äº†å„ç§è‡ªåŠ¨è¯„ä»·æŒ‡æ ‡ï¼ˆAEMï¼‰çš„å‘å±•ï¼Œæ—¨åœ¨å°†æ¨¡å‹è¾“å‡ºä¸äººç±»æ’°å†™çš„å‚è€ƒæ ‡å‡†è¿›è¡Œæ¯”è¾ƒï¼Œç”Ÿæˆä¸€ä¸ªæ¥è¿‘äººç±»åˆ¤æ–­çš„è¯„åˆ†ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼ŒAEMä»ç®€å•çš„è¯å…¸æ¯”è¾ƒå‘å±•åˆ°è¯­ä¹‰ç›¸ä¼¼æ€§æ¨¡å‹ï¼Œå†åˆ°åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¯„ä»·è€…ã€‚ç„¶è€Œï¼Œä¼¼ä¹æ²¡æœ‰å•ä¸€çš„åº¦é‡æ ‡å‡†èƒ½å¤Ÿæˆä¸ºæœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œå¯¼è‡´ç ”ç©¶ä¸­ä½¿ç”¨ä¸åŒçš„åº¦é‡æ ‡å‡†è€Œæœªå……åˆ†è€ƒè™‘å…¶å½±å“ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡è¯¦ç»†ç ”ç©¶ç°æœ‰åº¦é‡æ ‡å‡†çš„æ–¹æ³•ã€å…¶è®°å½•çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€éªŒè¯æ–¹æ³•ä»¥åŠä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ¥å±•ç¤ºè¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬è¯†åˆ«äº†å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼šåº¦é‡æ ‡å‡†é€šå¸¸ä»…æ•æ‰æ–‡æœ¬è´¨é‡çš„ç‰¹å®šæ–¹é¢ï¼Œå…¶æœ‰æ•ˆæ€§éšä»»åŠ¡å’Œæ•°æ®é›†è€Œå˜åŒ–ï¼ŒéªŒè¯å®è·µä»ç¼ºä¹ç»“æ„ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§ä¸ä¸€è‡´ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°è¿™äº›æŒ‘æˆ˜ä¸ä»…å­˜åœ¨äºæœ€æ–°ç±»å‹çš„åº¦é‡æ ‡å‡†â€”â€”å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä»·è€…â€”â€”ä¸­ï¼Œè€Œä¸”è¿˜å­˜åœ¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„è¯„ä¼°ä¸­ï¼Œè¿™ä¸€ä»»åŠ¡åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œæ—¥ç›Šç›¸å…³ã€‚æˆ‘ä»¬çš„å‘ç°æŒ‘æˆ˜äº†å¯»æ‰¾â€œå®Œç¾åº¦é‡æ ‡å‡†â€çš„è¿½æ±‚ã€‚æˆ‘ä»¬å»ºè®®æ ¹æ®ä»»åŠ¡ç‰¹å®šéœ€æ±‚é€‰æ‹©åº¦é‡æ ‡å‡†ï¼Œå¹¶åˆ©ç”¨è¡¥å……æ€§è¯„ä¼°æ–¹æ³•ï¼Œå¹¶ä¸”æå€¡æ–°åº¦é‡æ ‡å‡†åº”å…³æ³¨å¢å¼ºçš„éªŒè¯æ–¹æ³•ã€‚ 

---
# Assessing Trustworthiness of AI Training Dataset using Subjective Logic -- A Use Case on Bias 

**Title (ZH)**: åŸºäºä¸»è§‚é€»è¾‘è¯„ä¼°AIè®­ç»ƒæ•°æ®é›†çš„å¯ä¿¡åº¦â€”â€”ä»¥åè§ä¸ºä¾‹çš„ç ”ç©¶ 

**Authors**: Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Frank Kargl  

**Link**: [PDF](https://arxiv.org/pdf/2508.13813)  

**Abstract**: As AI systems increasingly rely on training data, assessing dataset trustworthiness has become critical, particularly for properties like fairness or bias that emerge at the dataset level. Prior work has used Subjective Logic to assess trustworthiness of individual data, but not to evaluate trustworthiness properties that emerge only at the level of the dataset as a whole. This paper introduces the first formal framework for assessing the trustworthiness of AI training datasets, enabling uncertainty-aware evaluations of global properties such as bias. Built on Subjective Logic, our approach supports trust propositions and quantifies uncertainty in scenarios where evidence is incomplete, distributed, and/or conflicting. We instantiate this framework on the trustworthiness property of bias, and we experimentally evaluate it based on a traffic sign recognition dataset. The results demonstrate that our method captures class imbalance and remains interpretable and robust in both centralized and federated contexts. 

**Abstract (ZH)**: éšç€AIç³»ç»Ÿè¶Šæ¥è¶Šä¾èµ–è®­ç»ƒæ•°æ®ï¼Œè¯„ä¼°æ•°æ®é›†å¯ä¿¡åº¦å·²æˆä¸ºå…³é”®ï¼Œç‰¹åˆ«æ˜¯åœ¨å…¬å¹³æ€§æˆ–åå·®ç­‰æ•°æ®é›†å±‚é¢æ¶Œç°çš„å±æ€§æ–¹é¢ã€‚å…ˆå‰çš„å·¥ä½œä½¿ç”¨ä¸»è§‚é€»è¾‘è¯„ä¼°å•ä¸ªæ•°æ®çš„å¯ä¿¡åº¦ï¼Œä½†å°šæœªç”¨äºè¯„ä¼°ä»…åœ¨æ•°æ®é›†æ•´ä½“å±‚é¢æ¶Œç°çš„å¯ä¿¡åº¦å±æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†é¦–ä¸ªæ­£å¼æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°AIè®­ç»ƒæ•°æ®é›†çš„å¯ä¿¡åº¦ï¼Œèƒ½å¤Ÿè¿›è¡Œå…¨å±€å±æ€§ï¼ˆå¦‚åå·®ï¼‰çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„ä¼°ã€‚è¯¥æ–¹æ³•åŸºäºä¸»è§‚é€»è¾‘ï¼Œæ”¯æŒä¿¡ä»»å‘½é¢˜å¹¶åœ¨è¯æ®ä¸å®Œæ•´ã€åˆ†æ•£æˆ–å­˜åœ¨å†²çªçš„æƒ…å†µä¸‹é‡åŒ–ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬åœ¨åå·®è¿™ä¸€å¯ä¿¡åº¦å±æ€§ä¸Šå®ä¾‹åŒ–äº†è¿™ä¸€æ¡†æ¶ï¼Œå¹¶åŸºäºäº¤é€šæ ‡å¿—è¯†åˆ«æ•°æ®é›†è¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ•æ‰ç±»åˆ«ä¸å¹³è¡¡ï¼Œå¹¶åœ¨é›†ä¸­å¼å’Œè”é‚¦å¼ç¯å¢ƒä¸­ä¿æŒå¯è§£é‡Šæ€§å’Œç¨³å¥æ€§ã€‚ 

---
# BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web 

**Title (ZH)**: BetaWeb: å‘ä¸€ä¸ªåŒºå—é“¾é©±åŠ¨çš„å€¼å¾—ä¿¡èµ–çš„ä»£ç†Webè¿ˆè¿› 

**Authors**: Zihan Guo, Yuanjian Zhou, Chenyi Wang, Linlin You, Minjie Bian, Weinan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2508.13787)  

**Abstract**: The rapid development of large language models (LLMs) has significantly propelled the development of artificial intelligence (AI) agents, which are increasingly evolving into diverse autonomous entities, advancing the LLM-based multi-agent systems (LaMAS). However, current agentic ecosystems remain fragmented and closed. Establishing an interconnected and scalable paradigm for Agentic AI has become a critical prerequisite. Although Agentic Web proposes an open architecture to break the ecosystem barriers, its implementation still faces core challenges such as privacy protection, data management, and value measurement. Existing centralized or semi-centralized paradigms suffer from inherent limitations, making them inadequate for supporting large-scale, heterogeneous, and cross-domain autonomous interactions. To address these challenges, this paper introduces the blockchain-enabled trustworthy Agentic Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not only offers a trustworthy and scalable infrastructure for LaMAS but also has the potential to advance the Web paradigm from Web3 (centered on data ownership) towards Web3.5, which emphasizes ownership of agent capabilities and the monetization of intelligence. Beyond a systematic examination of the BetaWeb framework, this paper presents a five-stage evolutionary roadmap, outlining the path of LaMAS from passive execution to advanced collaboration and autonomous governance. We also conduct a comparative analysis of existing products and discuss key challenges of BetaWeb from multiple perspectives. Ultimately, we argue that deep integration between blockchain and LaMAS can lay the foundation for a resilient, trustworthy, and sustainably incentivized digital ecosystem. A summary of the enabling technologies for each stage is available at this https URL. 

**Abstract (ZH)**: åŒºå—é“¾èµ‹èƒ½å¯ä¿¡ä»£ç†Webï¼ˆBetaWebï¼‰ 

---
# DegDiT: Controllable Audio Generation with Dynamic Event Graph Guided Diffusion Transformer 

**Title (ZH)**: DegDiTï¼šå—åŠ¨æ€äº‹ä»¶å›¾å¼•å¯¼çš„å¯æ§éŸ³é¢‘ç”Ÿæˆå˜æ¢å™¨ 

**Authors**: Yisu Liu, Chenxing Li, Wanqian Zhang, Wenfu Wang, Meng Yu, Ruibo Fu, Zheng Lin, Weiping Wang, Dong Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13786)  

**Abstract**: Controllable text-to-audio generation aims to synthesize audio from textual descriptions while satisfying user-specified constraints, including event types, temporal sequences, and onset and offset timestamps. This enables precise control over both the content and temporal structure of the generated audio. Despite recent progress, existing methods still face inherent trade-offs among accurate temporal localization, open-vocabulary scalability, and practical efficiency. To address these challenges, we propose DegDiT, a novel dynamic event graph-guided diffusion transformer framework for open-vocabulary controllable audio generation. DegDiT encodes the events in the description as structured dynamic graphs. The nodes in each graph are designed to represent three aspects: semantic features, temporal attributes, and inter-event connections. A graph transformer is employed to integrate these nodes and produce contextualized event embeddings that serve as guidance for the diffusion model. To ensure high-quality and diverse training data, we introduce a quality-balanced data selection pipeline that combines hierarchical event annotation with multi-criteria quality scoring, resulting in a curated dataset with semantic diversity. Furthermore, we present consensus preference optimization, facilitating audio generation through consensus among multiple reward signals. Extensive experiments on AudioCondition, DESED, and AudioTime datasets demonstrate that DegDiT achieves state-of-the-art performances across a variety of objective and subjective evaluation metrics. 

**Abstract (ZH)**: å¯æ§æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆæ—¨åœ¨ä»æ–‡æœ¬æè¿°ä¸­åˆæˆéŸ³é¢‘ï¼ŒåŒæ—¶æ»¡è¶³ç”¨æˆ·æŒ‡å®šçš„çº¦æŸï¼ŒåŒ…æ‹¬äº‹ä»¶ç±»å‹ã€æ—¶é—´åºåˆ—ä»¥åŠèµ·å§‹å’Œç»“æŸæ—¶é—´æˆ³ã€‚è¿™ä½¿å¾—å¯¹ç”ŸæˆéŸ³é¢‘çš„å†…å®¹å’Œæ—¶é—´ç»“æ„è¿›è¡Œç²¾ç¡®æ§åˆ¶æˆä¸ºå¯èƒ½ã€‚å°½ç®¡å–å¾—äº†è¿‘æœŸè¿›å±•ï¼Œç°æœ‰æ–¹æ³•ä»ç„¶åœ¨å‡†ç¡®çš„æ—¶é—´å®šä½ã€å¼€æ”¾å¼è¯æ±‡è¡¨çš„å¯æ‰©å±•æ€§å’Œå®ç”¨æ•ˆç‡ä¹‹é—´å­˜åœ¨å›ºæœ‰çš„æƒè¡¡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨æ€äº‹ä»¶å›¾å¼•å¯¼çš„æ‰©æ•£å˜æ¢å™¨æ¡†æ¶DegDiTï¼Œç”¨äºå¼€æ”¾å¼è¯æ±‡è¡¨çš„å¯æ§éŸ³é¢‘ç”Ÿæˆã€‚DegDiT å°†æè¿°ä¸­çš„äº‹ä»¶ç¼–ç ä¸ºç»“æ„åŒ–çš„åŠ¨æ€å›¾ã€‚æ¯ä¸ªå›¾ä¸­çš„èŠ‚ç‚¹è®¾è®¡ç”¨äºè¡¨ç¤ºä¸‰ä¸ªæ–¹é¢ï¼šè¯­ä¹‰ç‰¹å¾ã€æ—¶é—´å±æ€§å’Œäº‹ä»¶é—´çš„è¿æ¥ã€‚é‡‡ç”¨å›¾å˜æ¢å™¨å°†è¿™äº›èŠ‚ç‚¹è¿›è¡Œæ•´åˆï¼Œç”Ÿæˆå…·æœ‰å¼•å¯¼ä½œç”¨çš„äº‹ä»¶ä¸Šä¸‹æ–‡åµŒå…¥ï¼Œä½œä¸ºæ‰©æ•£æ¨¡å‹çš„æŒ‡å¯¼ã€‚ä¸ºç¡®ä¿é«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºå±‚æ¬¡äº‹ä»¶æ³¨é‡Šä¸å¤šæŒ‡æ ‡è´¨é‡è¯„åˆ†çš„è´¨é‡å¹³è¡¡æ•°æ®é€‰æ‹©ç®¡é“ï¼Œä»è€Œç”Ÿæˆè¯­ä¹‰å¤šæ ·çš„æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†å…±è¯†åå¥½ä¼˜åŒ–ï¼Œé€šè¿‡å¤šä¸ªå¥–åŠ±ä¿¡å·çš„ä¸€è‡´æ€§ä¿ƒè¿›éŸ³é¢‘ç”Ÿæˆã€‚åœ¨AudioConditionã€DESEDå’ŒAudioTimeæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDegDiT åœ¨å¤šç§å®¢è§‚å’Œä¸»è§‚è¯„ä¼°æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ 

---
# PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting 

**Title (ZH)**: PENGUINï¼šå¢å¼ºTransformerçš„å‘¨æœŸåµŒå¥—ç»„æ³¨æ„åŠ›æœºåˆ¶ä»¥è¿›è¡Œé•¿æœŸæ—¶é—´åºåˆ—é¢„æµ‹ 

**Authors**: Tian Sun, Yuqi Chen, Weiwei Sun  

**Link**: [PDF](https://arxiv.org/pdf/2508.13773)  

**Abstract**: Long-term time series forecasting (LTSF) is a fundamental task with wide-ranging applications. Although Transformer-based models have made significant breakthroughs in forecasting, their effectiveness for time series forecasting remains debatable. In this paper, we revisit the significance of self-attention and propose a simple yet effective mechanism, Periodic-Nested Group Attention, namely PENGUIN. Our approach highlights the importance of explicitly modeling periodic patterns and incorporating relative attention bias for effective time series modeling. To this end, we introduce a periodic-nested relative attention bias that captures periodic structures directly. To handle multiple coexisting periodicities (e.g., daily and weekly cycles), we design a grouped attention mechanism, where each group targets a specific periodicity using a multi-query attention mechanism. Extensive experiments across diverse benchmarks demonstrate that PENGUIN consistently outperforms both MLP-based and Transformer-based models. 

**Abstract (ZH)**: é•¿å‘¨æœŸæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆLTSFï¼‰æ˜¯ä¸€é¡¹å…·æœ‰å¹¿æ³›åº”ç”¨çš„åŸºæœ¬ä»»åŠ¡ã€‚å°½ç®¡åŸºäºTransformerçš„æ¨¡å‹åœ¨é¢„æµ‹æ–¹é¢å–å¾—äº†æ˜¾è‘—çªç ´ï¼Œä½†å®ƒä»¬åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§ä»å­˜äº‰è®®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡æ–°å®¡è§†äº†è‡ªæ³¨æ„åŠ›çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æœºåˆ¶ï¼Œå³å‘¨æœŸåµŒå¥—ç»„æ³¨æ„æœºåˆ¶ï¼ˆPENGUINï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼ºè°ƒäº†æ˜ç¡®å»ºæ¨¡å‘¨æœŸæ€§æ¨¡å¼å’Œå¼•å…¥ç›¸å¯¹æ³¨æ„åè§å¯¹äºæœ‰æ•ˆæ—¶é—´åºåˆ—å»ºæ¨¡çš„é‡è¦æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å‘¨æœŸåµŒå¥—çš„ç›¸å¯¹æ³¨æ„åè§ï¼Œå¯ä»¥ç›´æ¥æ•æ‰å‘¨æœŸç»“æ„ã€‚ä¸ºäº†å¤„ç†å¤šé‡å…±å­˜çš„å‘¨æœŸæ€§ï¼ˆä¾‹å¦‚ï¼Œæ—¥å‘¨æœŸå’Œå‘¨å‘¨æœŸï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åˆ†ç»„æ³¨æ„æœºåˆ¶ï¼Œå…¶ä¸­æ¯ä¸ªç»„ä½¿ç”¨å¤šæŸ¥è¯¢æ³¨æ„æœºåˆ¶é’ˆå¯¹ç‰¹å®šçš„å‘¨æœŸæ€§ã€‚åœ¨å¤šç§åŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒPENGUINä¸€è´¯ä¼˜äºåŸºäºMLPå’ŒåŸºäºTransformerçš„æ¨¡å‹ã€‚ 

---
# On the Security and Privacy of Federated Learning: A Survey with Attacks, Defenses, Frameworks, Applications, and Future Directions 

**Title (ZH)**: è”é‚¦å­¦ä¹ ä¸­çš„å®‰å…¨ä¸éšç§ï¼šæ”»å‡»ã€é˜²å¾¡ã€æ¡†æ¶ã€åº”ç”¨åŠæœªæ¥æ–¹å‘ç»¼è¿° 

**Authors**: Daniel M. Jimenez-Gutierrez, Yelizaveta Falkouskaya, Jose L. Hernandez-Ramos, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti  

**Link**: [PDF](https://arxiv.org/pdf/2508.13730)  

**Abstract**: Federated Learning (FL) is an emerging distributed machine learning paradigm enabling multiple clients to train a global model collaboratively without sharing their raw data. While FL enhances data privacy by design, it remains vulnerable to various security and privacy threats. This survey provides a comprehensive overview of more than 200 papers regarding the state-of-the-art attacks and defense mechanisms developed to address these challenges, categorizing them into security-enhancing and privacy-preserving techniques. Security-enhancing methods aim to improve FL robustness against malicious behaviors such as byzantine attacks, poisoning, and Sybil attacks. At the same time, privacy-preserving techniques focus on protecting sensitive data through cryptographic approaches, differential privacy, and secure aggregation. We critically analyze the strengths and limitations of existing methods, highlight the trade-offs between privacy, security, and model performance, and discuss the implications of non-IID data distributions on the effectiveness of these defenses. Furthermore, we identify open research challenges and future directions, including the need for scalable, adaptive, and energy-efficient solutions operating in dynamic and heterogeneous FL environments. Our survey aims to guide researchers and practitioners in developing robust and privacy-preserving FL systems, fostering advancements safeguarding collaborative learning frameworks' integrity and confidentiality. 

**Abstract (ZH)**: è”é‚¦å­¦ä¹ (Federated Learning)æ˜¯ä¸€ç§æ–°å…´çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ èŒƒå¼ï¼Œä½¿å¤šä¸ªå®¢æˆ·ç«¯èƒ½å¤Ÿåä½œè®­ç»ƒå…¨çƒæ¨¡å‹è€Œæ— éœ€å…±äº«å…¶åŸå§‹æ•°æ®ã€‚å°½ç®¡è”é‚¦å­¦ä¹ é€šè¿‡è®¾è®¡å¢å¼ºäº†æ•°æ®éšç§æ€§ï¼Œä½†å®ƒä»æ˜“å—åˆ°å„ç§å®‰å…¨å’Œéšç§å¨èƒã€‚æœ¬æ–‡ç»¼è¿°äº†è¶…è¿‡200ç¯‡å…³äºæœ€æ–°æ”»å‡»å’Œé˜²å¾¡æœºåˆ¶çš„ç ”ç©¶è®ºæ–‡ï¼Œå°†è¿™äº›ç ”ç©¶è®ºæ–‡åˆ†ç±»ä¸ºå®‰å…¨å¢å¼ºæŠ€æœ¯å’Œéšç§ä¿æŠ¤æŠ€æœ¯ã€‚å®‰å…¨å¢å¼ºæŠ€æœ¯æ—¨åœ¨é€šè¿‡å¯¹æŠ—æ‹œå åº­æ”»å‡»ã€æŠ•æ¯’æ”»å‡»å’ŒSybilæ”»å‡»ç­‰æ¶æ„è¡Œä¸ºæé«˜è”é‚¦å­¦ä¹ çš„é²æ£’æ€§ã€‚åŒæ—¶ï¼Œéšç§ä¿æŠ¤æŠ€æœ¯ä¾§é‡äºé€šè¿‡åŠ å¯†æ–¹æ³•ã€å·®åˆ†éšç§å’Œå®‰å…¨èšåˆç­‰æ–¹å¼ä¿æŠ¤æ•æ„Ÿæ•°æ®ã€‚æœ¬æ–‡æ‰¹åˆ¤æ€§åœ°åˆ†æç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¼ºè°ƒéšç§ã€å®‰å…¨æ€§å’Œæ¨¡å‹æ€§èƒ½ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶è®¨è®ºéåŒæ€åˆ†å¸ƒæ•°æ®å¯¹è¿™äº›é˜²å¾¡æªæ–½æœ‰æ•ˆæ€§çš„å½±å“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æŒ‡å‡ºäº†å¼€æ”¾çš„ç ”ç©¶æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ï¼ŒåŒ…æ‹¬åœ¨åŠ¨æ€å’Œå¼‚æ„è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­å¼€å‘å¯æ‰©å±•ã€è‡ªé€‚åº”å’Œèƒ½æ•ˆæ€§çš„è§£å†³æ–¹æ¡ˆçš„éœ€æ±‚ã€‚æœ¬æ–‡æ—¨åœ¨æŒ‡å¯¼ç ”ç©¶äººå‘˜å’Œå®è·µè€…å¼€å‘ robust å’Œéšç§ä¿æŠ¤çš„è”é‚¦å­¦ä¹ ç³»ç»Ÿï¼Œä¿ƒè¿›ä¿æŠ¤åä½œå­¦ä¹ æ¡†æ¶å®Œæ•´æ€§å’Œä¿å¯†æ€§çš„è¿›æ­¥ã€‚ 

---
# The AI Risk Spectrum: From Dangerous Capabilities to Existential Threats 

**Title (ZH)**: äººå·¥æ™ºèƒ½é£é™©è°±ï¼šä»å±é™©èƒ½åŠ›åˆ°å­˜åœ¨æ€§å¨èƒ 

**Authors**: Markov Grey, Charbel-RaphaÃ«l Segerie  

**Link**: [PDF](https://arxiv.org/pdf/2508.13700)  

**Abstract**: As AI systems become more capable, integrated, and widespread, understanding the associated risks becomes increasingly important. This paper maps the full spectrum of AI risks, from current harms affecting individual users to existential threats that could endanger humanity's survival. We organize these risks into three main causal categories. Misuse risks, which occur when people deliberately use AI for harmful purposes - creating bioweapons, launching cyberattacks, adversarial AI attacks or deploying lethal autonomous weapons. Misalignment risks happen when AI systems pursue outcomes that conflict with human values, irrespective of developer intentions. This includes risks arising through specification gaming (reward hacking), scheming and power-seeking tendencies in pursuit of long-term strategic goals. Systemic risks, which arise when AI integrates into complex social systems in ways that gradually undermine human agency - concentrating power, accelerating political and economic disempowerment, creating overdependence that leads to human enfeeblement, or irreversibly locking in current values curtailing future moral progress. Beyond these core categories, we identify risk amplifiers - competitive pressures, accidents, corporate indifference, and coordination failures - that make all risks more likely and severe. Throughout, we connect today's existing risks and empirically observable AI behaviors to plausible future outcomes, demonstrating how existing trends could escalate to catastrophic outcomes. Our goal is to help readers understand the complete landscape of AI risks. Good futures are possible, but they don't happen by default. Navigating these challenges will require unprecedented coordination, but an extraordinary future awaits if we do. 

**Abstract (ZH)**: éšç€AIç³»ç»Ÿå˜å¾—æ›´åŠ å“è¶Šã€é›†æˆåŒ–å’Œæ™®åŠåŒ–ï¼Œç†è§£ç›¸å…³é£é™©å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚æœ¬æ–‡æ˜ å°„äº†AIé£é™©çš„å®Œæ•´è°±ç³»ï¼Œä»ç›®å‰å½±å“ä¸ªåˆ«ç”¨æˆ·çš„ä¼¤å®³åˆ°å¯èƒ½å±åŠäººç±»ç”Ÿå­˜çš„ç»ˆç»“æ€§å¨èƒã€‚æˆ‘ä»¬å°†è¿™äº›é£é™©å½’ç±»ä¸ºä¸‰å¤§ä¸»è¦å› æœç±»åˆ«ã€‚æ»¥ç”¨é£é™©ï¼Œå‘ç”Ÿåœ¨äººä»¬æ•…æ„å°†AIç”¨äºæœ‰å®³ç›®çš„æ—¶â€”â€”ä¾‹å¦‚åˆ¶é€ ç”Ÿç‰©æ­¦å™¨ã€å‘åŠ¨ç½‘ç»œæ”»å‡»ã€å¯¹æŠ—æ€§AIæ”»å‡»æˆ–éƒ¨ç½²è‡´å‘½è‡ªä¸»æ­¦å™¨ã€‚å¯¹é½é£é™©å‘ç”Ÿåœ¨AIç³»ç»Ÿè¿½æ±‚ä¸äººç±»ä»·å€¼è§‚ç›¸å†²çªçš„ç»“æœæ—¶ï¼Œæ— è®ºå¼€å‘è€…çš„æ„å›¾å¦‚ä½•ã€‚è¿™åŒ…æ‹¬å› è§„èŒƒæ¸¸æˆï¼ˆå¥–åŠ±åŠ«æŒï¼‰ã€ä¸ºé•¿æœŸæˆ˜ç•¥ç›®æ ‡è¿½æ±‚æƒè°‹å’ŒæƒåŠ›è¿½æ±‚è€Œäº§ç”Ÿçš„é£é™©ã€‚ç³»ç»Ÿæ€§é£é™©ï¼Œå‘ç”Ÿåœ¨AIä»¥é€æ¸å‰Šå¼±äººç±»è‡ªä¸»æƒçš„æ–¹å¼æ•´åˆåˆ°å¤æ‚çš„ç¤¾ä¼šç³»ç»Ÿä¸­æ—¶â€”â€”æƒåŠ›é›†ä¸­ã€åŠ é€Ÿæ”¿æ²»å’Œç»æµå»è‡ªä¸»åŒ–ã€ä¾èµ–æ€§è¿‡å¼ºå¯¼è‡´äººç±»è™šå¼±ï¼Œæˆ–ä¸å¯é€†åœ°é”å®šå½“å‰ä»·å€¼è§‚ï¼Œé™åˆ¶æœªæ¥é“å¾·è¿›æ­¥ã€‚é™¤äº†è¿™äº›æ ¸å¿ƒç±»åˆ«ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜è¯†åˆ«å‡ºé£é™©æ”¾å¤§å™¨â€”â€”ç«äº‰å‹åŠ›ã€äº‹æ•…ã€ä¼ä¸šæ¼ è§†å’Œåè°ƒå¤±è´¥â€”â€”å®ƒä»¬ä½¿æ‰€æœ‰é£é™©æ›´æœ‰å¯èƒ½å‘ç”Ÿä¸”æ›´åŠ ä¸¥é‡ã€‚åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å½“ä»Šå·²æœ‰çš„é£é™©å’Œå¯è§‚å¯Ÿåˆ°çš„AIè¡Œä¸ºä¸åˆç†çš„æœªæ¥ç»“æœè”ç³»èµ·æ¥ï¼Œæ¼”ç¤ºç°æœ‰è¶‹åŠ¿å¦‚ä½•å‡çº§ä¸ºç¾éš¾æ€§ç»“æœã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¸®åŠ©è¯»è€…äº†è§£AIé£é™©çš„å®Œæ•´æ™¯è§‚ã€‚å…‰æ˜çš„æœªæ¥æ˜¯å¯èƒ½çš„ï¼Œä½†ä¸ä¼šè‡ªåŠ¨å®ç°ã€‚åº”å¯¹è¿™äº›æŒ‘æˆ˜éœ€è¦å‰æ‰€æœªæœ‰çš„åè°ƒï¼Œä½†å¦‚æœèƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œä¸€ä¸ªéå‡¡çš„æœªæ¥å°†ç­‰å¾…ç€æˆ‘ä»¬ã€‚ 

---
# Multi-Plasticity Synergy with Adaptive Mechanism Assignment for Training Spiking Neural Networks 

**Title (ZH)**: å…·æœ‰è‡ªé€‚åº”æœºåˆ¶åˆ†é…çš„å¤šå¡‘æ€§ååŒè®­ç»ƒè„‰å†²ç¥ç»ç½‘ç»œ 

**Authors**: Yuzhe Liu, Xin Deng, Qiang Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13673)  

**Abstract**: Spiking Neural Networks (SNNs) are promising brain-inspired models known for low power consumption and superior potential for temporal processing, but identifying suitable learning mechanisms remains a challenge. Despite the presence of multiple coexisting learning strategies in the brain, current SNN training methods typically rely on a single form of synaptic plasticity, which limits their adaptability and representational capability. In this paper, we propose a biologically inspired training framework that incorporates multiple synergistic plasticity mechanisms for more effective SNN training. Our method enables diverse learning algorithms to cooperatively modulate the accumulation of information, while allowing each mechanism to preserve its own relatively independent update dynamics. We evaluated our approach on both static image and dynamic neuromorphic datasets to demonstrate that our framework significantly improves performance and robustness compared to conventional learning mechanism models. This work provides a general and extensible foundation for developing more powerful SNNs guided by multi-strategy brain-inspired learning. 

**Abstract (ZH)**: åŸºäºå¤šç§ååŒå¯å¡‘æ€§æœºåˆ¶çš„ç”Ÿç‰©å¯å‘å¼Spikingç¥ç»ç½‘ç»œè®­ç»ƒæ¡†æ¶ 

---
# In-Context Decision Making for Optimizing Complex AutoML Pipelines 

**Title (ZH)**: ä¸Šä¸‹æ–‡å†³ç­–ä¼˜åŒ–å¤æ‚è‡ªåŠ¨æœºå™¨å­¦ä¹ ç®¡é“ 

**Authors**: Amir Rezaei Balef, Katharina Eggensperger  

**Link**: [PDF](https://arxiv.org/pdf/2508.13657)  

**Abstract**: Combined Algorithm Selection and Hyperparameter Optimization (CASH) has been fundamental to traditional AutoML systems. However, with the advancements of pre-trained models, modern ML workflows go beyond hyperparameter optimization and often require fine-tuning, ensembling, and other adaptation techniques. While the core challenge of identifying the best-performing model for a downstream task remains, the increasing heterogeneity of ML pipelines demands novel AutoML approaches. This work extends the CASH framework to select and adapt modern ML pipelines. We propose PS-PFN to efficiently explore and exploit adapting ML pipelines by extending Posterior Sampling (PS) to the max k-armed bandit problem setup. PS-PFN leverages prior-data fitted networks (PFNs) to efficiently estimate the posterior distribution of the maximal value via in-context learning. We show how to extend this method to consider varying costs of pulling arms and to use different PFNs to model reward distributions individually per arm. Experimental results on one novel and two existing standard benchmark tasks demonstrate the superior performance of PS-PFN compared to other bandit and AutoML strategies. We make our code and data available at this https URL. 

**Abstract (ZH)**: Combined ç®—æ³•é€‰æ‹©ä¸è¶…å‚æ•°ä¼˜åŒ– (CASH) æ˜¯ä¼ ç»Ÿè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„æ ¸å¿ƒã€‚ç„¶è€Œï¼Œéšç€é¢„è®­ç»ƒæ¨¡å‹çš„å‘å±•ï¼Œç°ä»£æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹è¶…è¶Šäº†è¶…å‚æ•°ä¼˜åŒ–ï¼Œ often è€Œå¸¸éœ€è¦å¾®è°ƒã€é›†æˆå’Œå…¶ä»–é€‚åº”æŠ€æœ¯ã€‚å°½ç®¡ç¡®å®šä¸‹æ¸¸ä»»åŠ¡æœ€ä½³æ¨¡å‹çš„æ ¸å¿ƒæŒ‘æˆ˜ä»ç„¶å­˜åœ¨ï¼Œä½†æ—¥ç›Šå¼‚è´¨çš„æœºå™¨å­¦ä¹ ç®¡é“å¯¹æ–°å‹è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æ–¹æ³•æå‡ºäº†éœ€æ±‚ã€‚è¿™é¡¹å·¥ä½œå°† CASH æ¡†æ¶æ‰©å±•åˆ°é€‰æ‹©å’Œé€‚åº”ç°ä»£æœºå™¨å­¦ä¹ ç®¡é“ã€‚æˆ‘ä»¬æå‡º PS-PFN é€šè¿‡å°†åéªŒé‡‡æ · (PS) æ‰©å±•åˆ°æœ€å¤§ k- èµŒå¾’è‡‚é—®é¢˜è®¾ç½®ä¸­ï¼Œä»¥é«˜æ•ˆåœ°æ¢ç´¢å’Œåˆ©ç”¨é€‚åº”æ€§æœºå™¨å­¦ä¹ ç®¡é“ã€‚PS-PFN åˆ©ç”¨å…ˆéªŒ-æ•°æ®æ‹Ÿåˆç½‘ç»œ (PFNs) é€šè¿‡æƒ…å¢ƒå­¦ä¹ é«˜æ•ˆä¼°è®¡æœ€å¤§å€¼çš„åéªŒåˆ†å¸ƒã€‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•æ‰©å±•æ­¤æ–¹æ³•è€ƒè™‘æ‹‰åŠ¨ä¸åŒè‡‚çš„æˆæœ¬å˜åŒ–ï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„ PFNs åˆ†åˆ«å¯¹æ¯ä¸ªè‡‚çš„å¥–åŠ±åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚åœ¨ä¸€é¡¹æ–°é¢–çš„å’Œä¸¤é¡¹ç°æœ‰æ ‡å‡†åŸºå‡†ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒPS-PFN åœ¨ä¸å…¶å®ƒå¤šè‡‚å’Œè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ç­–ç•¥ç›¸æ¯”æ—¶è¡¨ç°æ›´ä¼˜ã€‚æˆ‘ä»¬å·²å°†ä»£ç å’Œæ•°æ®å…¬å¼€äºæ­¤ <https> URLã€‚ 

---
# GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling 

**Title (ZH)**: GRAFTï¼š gradient-æ„ŸçŸ¥å¿«é€ŸMaxVolåŠ¨æ€æ•°æ®é‡‡æ ·æ–¹æ³• 

**Authors**: Ashish Jha, Anh huy Phan, Razan Dibo, Valentin Leplat  

**Link**: [PDF](https://arxiv.org/pdf/2508.13653)  

**Abstract**: Training modern neural networks on large datasets is computationally and environmentally costly. We introduce GRAFT, a scalable in-training subset selection method that (i) extracts a low-rank feature representation for each batch, (ii) applies a Fast MaxVol sampler to select a small, diverse subset that spans the batch's dominant subspace, and (iii) dynamically adjusts the subset size using a gradient-approximation criterion. By operating in low-rank subspaces and training on carefully chosen examples instead of full batches, GRAFT preserves the training trajectory while reducing wall-clock time, energy consumption, and $\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFT matches or exceeds recent selection baselines in both accuracy and efficiency, providing a favorable trade-off between accuracy, efficiency, and emissions. 

**Abstract (ZH)**: åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒç°ä»£ç¥ç»ç½‘ç»œæ—¢è€—è´¹è®¡ç®—èµ„æºåˆç¯ä¿ä»£ä»·é«˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­é›†é€‰æ‹©æ–¹æ³•GRAFTï¼Œè¯¥æ–¹æ³•é€šè¿‡(i) ä¸ºæ¯ä¸ªæ‰¹æ¬¡æå–ä½ç§©ç‰¹å¾è¡¨ç¤ºï¼Œ(ii) ä½¿ç”¨å¿«é€ŸMaxVolé‡‡æ ·å™¨é€‰æ‹©ä¸€ä¸ªå°è€Œå¤šæ ·çš„å­é›†ä»¥è¦†ç›–æ‰¹æ¬¡çš„ä¸»è¦å­ç©ºé—´ï¼Œä»¥åŠ(iii) ä½¿ç”¨æ¢¯åº¦é€¼è¿‘å‡†åˆ™åŠ¨æ€è°ƒæ•´å­é›†å¤§å°ï¼Œä»è€Œåœ¨ä½ç§©å­ç©ºé—´ä¸­è¿›è¡Œè®­ç»ƒå¹¶åœ¨ç²¾å¿ƒé€‰æ‹©çš„æ ·ä¾‹ä¸Šè®­ç»ƒï¼Œæ¥ä¿ç•™è®­ç»ƒè½¨è¿¹åŒæ—¶å‡å°‘å¢™é’Ÿæ—¶é—´ã€èƒ½é‡æ¶ˆè€—å’Œ$\mathrm{CO}_2$æ’æ”¾ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒGRAFTåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢ä¸æœ€è¿‘çš„é€‰æ ·åŸºçº¿ç›¸å½“æˆ–è¶…è¶Šï¼Œæä¾›äº†ä¸€ä¸ªåœ¨å‡†ç¡®ç‡ã€æ•ˆç‡å’Œæ’æ”¾ä¹‹é—´æœ‰åˆ©çš„æƒè¡¡ã€‚ 

---
# Bounding Causal Effects and Counterfactuals 

**Title (ZH)**: å› æœæ•ˆåº”å’Œåäº‹å®æ¨ç†çš„ç•Œé™ 

**Authors**: Tobias Maringgele  

**Link**: [PDF](https://arxiv.org/pdf/2508.13607)  

**Abstract**: Causal inference often hinges on strong assumptions - such as no unmeasured confounding or perfect compliance - that are rarely satisfied in practice. Partial identification offers a principled alternative: instead of relying on unverifiable assumptions to estimate causal effects precisely, it derives bounds that reflect the uncertainty inherent in the data. Despite its theoretical appeal, partial identification remains underutilized in applied work, in part due to the fragmented nature of existing methods and the lack of practical guidance. This thesis addresses these challenges by systematically comparing a diverse set of bounding algorithms across multiple causal scenarios. We implement, extend, and unify state-of-the-art methods - including symbolic, optimization-based, and information-theoretic approaches - within a common evaluation framework. In particular, we propose an extension of a recently introduced entropy-bounded method, making it applicable to counterfactual queries such as the Probability of Necessity and Sufficiency (PNS). Our empirical study spans thousands of randomized simulations involving both discrete and continuous data-generating processes. We assess each method in terms of bound tightness, computational efficiency, and robustness to assumption violations. To support practitioners, we distill our findings into a practical decision tree for algorithm selection and train a machine learning model to predict the best-performing method based on observable data characteristics.
All implementations are released as part of an open-source Python package, CausalBoundingEngine, which enables users to apply and compare bounding methods through a unified interface. 

**Abstract (ZH)**: å› æœæ¨ç†å¾€å¾€ä¾èµ–äºä¸€äº›å‡è®¾ï¼Œæœªæµ‹é‡æ··æ‚æˆ–å®Œå…¨éµå®ˆä¸Šï¼Œåœ¨å®è·µä¸­é€šå¸¸æ— æ³•æ»¡è¶³ã€‚éƒ¨åˆ†è¯†åˆ«æä¾›äº†ä¸€ç§åŸåˆ™æ€§çš„æ›¿ä»£æ–¹æ¡ˆï¼šè€Œä¸æ˜¯ä¾èµ–äºæ— æ³•éªŒè¯çš„å‡è®¾æ¥ç²¾ç¡®ä¼°è®¡å› æœæ•ˆåº”ï¼Œï¼Œè€Œç»™å‡ºåæ˜ æ•°æ®å†…åœ¨ä¸ç¡®å®šæ€§çš„è¾¹ç•Œä¼°è®¡ã€‚å°½ç®¡å¦‚æ­¤ï¼Œç†è®ºä¸Šçš„çš„è¯†åˆ«ä»ç„¶åœ¨å®è·µä¸­è¢«å¹¿æ³›å¿½è§†ï¼ŒåŸå› ä¹‹ä¸€åœ¨äºç°æœ‰çš„æ–‡çŒ®ç¢ç‰‡åŒ–ä¸”ç¼ºä¹å®ç”¨æŒ‡å¯¼ä¸Šã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡ç³»ç»Ÿåœ°åœ°æ¯”è¾ƒå¤šç§è¾¹ç•Œç®—æ³•åœ¨å¤šç§å› æœæƒ…æ™¯ä¸Šçš„è¡¨ç°æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬å®ç°äº†å¯¹åŸºäºç¬¦å·çš„ä¼˜åŒ–æ–¹æ³•å’Œæ¦‚ç‡è®ºçš„æ–¹æ³•çš„ç»Ÿä¸€ï¼Œå¹¶åœ¨ç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ä¸Šä¸Šæå‡ºäº†ä¸€ä¸ªæ”¹è¿›çš„åŸºäºç†µçš„ç•Œé™æ–¹æ³•ï¼Œä½¿å…¶é€‚ç”¨äºè¯¸å¦‚éœ€è¦- å’Œå……åˆ†æ¡ä»¶ -æ¦‚ç‡æŸ¥è¯¢ï¼ˆPNSï¼‰è¿™ç±»çš„åäº‹å®æŸ¥è¯¢ã€‚æˆ‘ä»¬çš„å®è¯ç ”ç©¶è¦†ç›–äº†æˆåƒä¸ªéšæœºåŒ–è®¾å®šï¼Œæ¶‰åŠç¦»æ•£å’Œéƒ¨åˆ†è§‚æµ‹æ•°æ®è·å–ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬ä»å„æ–¹æ³•çš„è§’åº¦å‡ºå‘è¯„ä¼°äº†è¾¹ç•Œä¼°è®¡çš„ç´§è‡´æ€§ã€è®¡ç®—æ•ˆç‡ä»¥åŠå‡è®¾ä¸æˆç«‹æ—¶çš„é²æ£’æ€§æ€§ã€‚ä¸ºäº†æŒ‡å¯¼ä»ä¸šè€…ä½œå‡ºé€‰æ‹©ï¼Œæˆ‘ä»¬æ€»ç»“äº†å‘ç°æˆæœäº†å¯ä½œå†³ç­–æ ‘å¹¶å¼€å‘äº†ä¸€ä¸ªæœºå™¨å­¦ä¹ å®è·µæ¥é¢„æµ‹åœ¨ç‰¹å®šæŸ¥è¯¢ç‰¹å¾åŸºç¡€ä¸Šçš„æœ€ä½³è¡¨ç°ã€‚ 

---
# Physics-Informed Neural Networks for Programmable Origami Metamaterials with Controlled Deployment 

**Title (ZH)**: åŸºäºç‰©ç†ä¿¡æ¯çš„ç¥ç»ç½‘ç»œåœ¨å¯æ§å±•å¼€çš„å¯ç¼–ç¨‹ Origami è¶…ææ–™ä¸­çš„åº”ç”¨ 

**Authors**: Sukheon Kang, Youngkwon Kim, Jinkyu Yang, Seunghwa Ryu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13559)  

**Abstract**: Origami-inspired structures provide unprecedented opportunities for creating lightweight, deployable systems with programmable mechanical responses. However, their design remains challenging due to complex nonlinear mechanics, multistability, and the need for precise control of deployment forces. Here, we present a physics-informed neural network (PINN) framework for both forward prediction and inverse design of conical Kresling origami (CKO) without requiring pre-collected training data. By embedding mechanical equilibrium equations directly into the learning process, the model predicts complete energy landscapes with high accuracy while minimizing non-physical artifacts. The inverse design routine specifies both target stable-state heights and separating energy barriers, enabling freeform programming of the entire energy curve. This capability is extended to hierarchical CKO assemblies, where sequential layer-by-layer deployment is achieved through programmed barrier magnitudes. Finite element simulations and experiments on physical prototypes validate the designed deployment sequences and barrier ratios, confirming the robustness of the approach. This work establishes a versatile, data-free route for programming complex mechanical energy landscapes in origami-inspired metamaterials, offering broad potential for deployable aerospace systems, morphing structures, and soft robotic actuators. 

**Abstract (ZH)**: Origami-Inspired ç»“æ„æä¾›çš„é”¥å½¢å…‹é›·å°”æŠ˜çº¸ (CKO) çš„æ­£å‘é¢„æµ‹å’Œé€†å‘è®¾è®¡çš„ç‰©ç†çŸ¥æƒ…ç¥ç»ç½‘ç»œæ¡†æ¶æ— éœ€é¢„å…ˆæ”¶é›†è®­ç»ƒæ•°æ®æä¾›äº†å‰æ‰€æœªæœ‰çš„æœºä¼šï¼Œä»¥åˆ›å»ºå…·æœ‰å¯ç¼–ç¨‹æœºæ¢°å“åº”çš„è½»é‡åŒ–ã€å¯å±•å¼€ç³»ç»Ÿã€‚ç„¶è€Œï¼Œç”±äºå¤æ‚çš„éçº¿æ€§åŠ›å­¦ã€å¤šç¨³å®šæ€§å’Œéƒ¨ç½²åŠ›çš„ç²¾ç¡®æ§åˆ¶éœ€æ±‚ï¼Œå…¶è®¾è®¡ä»å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‰©ç†çŸ¥æƒ…ç¥ç»ç½‘ç»œ (PINN) æ¡†æ¶ï¼Œç”¨äºé”¥å½¢å…‹é›·å°”æŠ˜çº¸ (CKO) çš„æ­£å‘é¢„æµ‹å’Œé€†å‘è®¾è®¡ï¼Œæ— éœ€é¢„å…ˆæ”¶é›†è®­ç»ƒæ•°æ®ã€‚é€šè¿‡ç›´æ¥å°†æœºæ¢°å¹³è¡¡æ–¹ç¨‹åµŒå…¥å­¦ä¹ è¿‡ç¨‹ï¼Œè¯¥æ¨¡å‹ä»¥é«˜åº¦å‡†ç¡®çš„æ–¹å¼é¢„æµ‹å®Œæ•´èƒ½é‡æ™¯è§‚ï¼ŒåŒæ—¶æœ€å°åŒ–éç‰©ç†ä¼ªå½±ã€‚é€†å‘è®¾è®¡æµç¨‹æ—¢è§„å®šç›®æ ‡ç¨³å®šçŠ¶æ€é«˜åº¦åˆè§„å®šåˆ†éš”èƒ½é‡éšœç¢ï¼Œä»è€Œå®ç°æ•´ä¸ªèƒ½é‡æ›²çº¿çš„è‡ªç”±ç¼–ç¨‹ã€‚è¿™ä¸€èƒ½åŠ›æ‰©å±•åˆ°äº†åˆ†å±‚ CKO ç»„è£…ä¸­ï¼Œé€šè¿‡ç¨‹åºåŒ–éšœç¢å¹…åº¦å®ç°äº†é€å±‚å±•å¼€ã€‚æœ‰é™å…ƒä»¿çœŸå’Œç‰©ç†åŸå‹ä¸Šçš„å®éªŒéªŒè¯äº†è®¾è®¡çš„å±•å¼€åºåˆ—å’Œéšœç¢æ¯”å€¼ï¼Œè¯å®äº†è¯¥æ–¹æ³•çš„ç¨³å¥æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºç¼–ç¨‹ origami å¯å‘å¼ metamaterial ä¸­å¤æ‚çš„æœºæ¢°èƒ½é‡æ™¯è§‚æä¾›äº†ä¸€ç§é€šç”¨ä¸”æ— éœ€æ•°æ®çš„è·¯å¾„ï¼Œä¸ºå¯å±•å¼€èˆªç©ºèˆªå¤©ç³»ç»Ÿã€å½¢æ€å¯å˜ç»“æ„å’Œè½¯ä½“æœºå™¨äººæ‰§è¡Œå™¨æä¾›äº†å¹¿æ³›æ½œåŠ›ã€‚ 

---
# Collapsing ROC approach for risk prediction research on both common and rare variants 

**Title (ZH)**: å…±åŒå˜å¼‚ä¸ç½•è§å˜å¼‚çš„è”åˆé£é™©é¢„æµ‹ROCåç¼©æ–¹æ³• 

**Authors**: Changshuai Wei, Qing Lu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13552)  

**Abstract**: Risk prediction that capitalizes on emerging genetic findings holds great promise for improving public health and clinical care. However, recent risk prediction research has shown that predictive tests formed on existing common genetic loci, including those from genome-wide association studies, have lacked sufficient accuracy for clinical use. Because most rare variants on the genome have not yet been studied for their role in risk prediction, future disease prediction discoveries should shift toward a more comprehensive risk prediction strategy that takes into account both common and rare variants. We are proposing a collapsing receiver operating characteristic CROC approach for risk prediction research on both common and rare variants. The new approach is an extension of a previously developed forward ROC FROC approach, with additional procedures for handling rare variants. The approach was evaluated through the use of 533 single-nucleotide polymorphisms SNPs in 37 candidate genes from the Genetic Analysis Workshop 17 mini-exome data set. We found that a prediction model built on all SNPs gained more accuracy AUC = 0.605 than one built on common variants alone AUC = 0.585. We further evaluated the performance of two approaches by gradually reducing the number of common variants in the analysis. We found that the CROC method attained more accuracy than the FROC method when the number of common variants in the data decreased. In an extreme scenario, when there are only rare variants in the data, the CROC reached an AUC value of 0.603, whereas the FROC had an AUC value of 0.524. 

**Abstract (ZH)**: æ ‡é¢˜ï¼šåŸºäºæ–°å…´é—ä¼ å‘ç°çš„é£é™©é¢„æµ‹ï¼šä¸€ç§ç»¼åˆç½•è§å˜å¼‚çš„åç¼©å—è¯•è€…æ“ä½œç‰¹å¾ï¼ˆCROCï¼‰æ–¹æ³• 

---
# FLAIR: Frequency- and Locality-Aware Implicit Neural Representations 

**Title (ZH)**: FLAIR: é¢‘ç‡å’Œå±€éƒ¨æ€§æ„è¯†çš„éšå¼ç¥ç»è¡¨ç¤º 

**Authors**: Sukhun Ko, Dahyeon Kye, Kyle Min, Chanho Eom, Jihyong Oh  

**Link**: [PDF](https://arxiv.org/pdf/2508.13544)  

**Abstract**: Implicit Neural Representations (INRs) leverage neural networks to map coordinates to corresponding signals, enabling continuous and compact representations. This paradigm has driven significant advances in various vision tasks. However, existing INRs lack frequency selectivity, spatial localization, and sparse representations, leading to an over-reliance on redundant signal components. Consequently, they exhibit spectral bias, tending to learn low-frequency components early while struggling to capture fine high-frequency details. To address these issues, we propose FLAIR (Frequency- and Locality-Aware Implicit Neural Representations), which incorporates two key innovations. The first is RC-GAUSS, a novel activation designed for explicit frequency selection and spatial localization under the constraints of the time-frequency uncertainty principle (TFUP). The second is Wavelet-Energy-Guided Encoding (WEGE), which leverages the discrete wavelet transform (DWT) to compute energy scores and explicitly guide frequency information to the network. Our method consistently outperforms existing INRs in 2D image representation and restoration, as well as 3D reconstruction. 

**Abstract (ZH)**: é¢‘ç‡å’Œå±€éƒ¨æ€§awareéšå¼ç¥ç»è¡¨ç¤ºï¼ˆFLAIRï¼‰ï¼šé¢‘ç‡é€‰æ‹©å’Œç©ºé—´å±€éƒ¨åŒ–çš„æ–°å‹æ¿€æ´»ä¸å°æ³¢èƒ½é‡å¼•å¯¼ç¼–ç  

---
# DDoS Attacks in Cloud Computing: Detection and Prevention 

**Title (ZH)**: äº‘ computing ä¸­çš„ DDoS æ”»å‡»ï¼šæ£€æµ‹ä¸é˜²èŒƒ 

**Authors**: Zain Ahmad, Musab Ahmad, Bilal Ahmad  

**Link**: [PDF](https://arxiv.org/pdf/2508.13522)  

**Abstract**: DDoS attacks are one of the most prevalent and harmful cybersecurity threats faced by organizations and individuals today. In recent years, the complexity and frequency of DDoS attacks have increased significantly, making it challenging to detect and mitigate them effectively. The study analyzes various types of DDoS attacks, including volumetric, protocol, and application layer attacks, and discusses the characteristics, impact, and potential targets of each type. It also examines the existing techniques used for DDoS attack detection, such as packet filtering, intrusion detection systems, and machine learning-based approaches, and their strengths and limitations. Moreover, the study explores the prevention techniques employed to mitigate DDoS attacks, such as firewalls, rate limiting , CPP and ELD mechanism. It evaluates the effectiveness of each approach and its suitability for different types of attacks and environments. In conclusion, this study provides a comprehensive overview of the different types of DDoS attacks, their detection, and prevention techniques. It aims to provide insights and guidelines for organizations and individuals to enhance their cybersecurity posture and protect against DDoS attacks. 

**Abstract (ZH)**: DDoSæ”»å‡»æ˜¯ç»„ç»‡å’Œä¸ªäººå½“å‰é¢ä¸´çš„æœ€å¸¸è§å’Œæœ€å…·å±å®³æ€§çš„ç½‘ç»œå®‰å…¨å¨èƒä¹‹ä¸€ã€‚è¿‘å¹´æ¥ï¼ŒDDoSæ”»å‡»çš„å¤æ‚æ€§å’Œé¢‘ç‡æ˜¾è‘—å¢åŠ ï¼Œç»™æœ‰æ•ˆæ£€æµ‹å’Œç¼“è§£å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶åˆ†æäº†å„ç§ç±»å‹çš„DDoSæ”»å‡»ï¼ŒåŒ…æ‹¬ volumetricã€åè®®å’Œåº”ç”¨å±‚æ”»å‡»ï¼Œå¹¶è®¨è®ºäº†æ¯ç§ç±»å‹çš„ç‰¹ç‚¹ã€å½±å“å’Œæ½œåœ¨ç›®æ ‡ã€‚ç ”ç©¶è¿˜è€ƒå¯Ÿäº†ç°æœ‰çš„DDoSæ”»å‡»æ£€æµ‹æŠ€æœ¯ï¼Œå¦‚åŒ…è¿‡æ»¤ã€å…¥ä¾µæ£€æµ‹ç³»ç»Ÿå’ŒåŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼ŒåŠå…¶ä¼˜ç¼ºç‚¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ¢è®¨äº†ç”¨äºç¼“è§£DDoSæ”»å‡»çš„é¢„é˜²æŠ€æœ¯ï¼Œå¦‚é˜²ç«å¢™ã€é€Ÿç‡é™åˆ¶ã€CPPå’ŒELDæœºåˆ¶ï¼Œå¹¶è¯„ä¼°äº†æ¯ç§æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚æœ€åï¼Œæœ¬ç ”ç©¶æä¾›äº†ä¸€ç§å…¨é¢çš„DDoSæ”»å‡»ç±»å‹ã€æ£€æµ‹å’Œé¢„é˜²æŠ€æœ¯æ¦‚è¿°ï¼Œæ—¨åœ¨ä¸ºç»„ç»‡å’Œä¸ªäººæä¾›å¢å¼ºç½‘ç»œå®‰å…¨æ€åŠ¿å’ŒæŠµå¾¡DDoSæ”»å‡»çš„è§è§£å’ŒæŒ‡å¯¼ã€‚ 

---
# Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency 

**Title (ZH)**: åŸºäºè·¨åŸŸå‡ ä½•ä¸€è‡´æ€§æ ¡å‡†ç”±VFMè¡ç”Ÿçš„åç½®åˆ†å¸ƒçš„æ½œç©ºé—´ 

**Authors**: Yanbiao Ma, Wei Dai, Bowei Liu, Jiayi Chen, Wenke Huang, Guancheng Wan, Zhiwu Lu, Junchi Yan  

**Link**: [PDF](https://arxiv.org/pdf/2508.13518)  

**Abstract**: Despite the fast progress of deep learning, one standing challenge is the gap of the observed training samples and the underlying true distribution. There are multiple reasons for the causing of this gap e.g. sampling bias, noise etc. In the era of foundation models, we show that when leveraging the off-the-shelf (vision) foundation models (e.g., CLIP, DINOv2) for feature extraction, the geometric shapes of the resulting feature distributions exhibit remarkable transferability across domains and datasets. To verify its practical usefulness, we embody our geometric knowledge-guided distribution calibration framework in two popular and challenging settings: federated learning and long-tailed recognition. In the federated setting, we devise a technique of acquiring the global geometric shape under privacy constraints, then leverage this knowledge to generate new samples for clients, in the aim of bridging the gap between local and global observations. In long-tailed learning, it utilizes the geometric knowledge transferred from sample-rich categories to recover the true distribution for sample-scarce tail classes. Comprehensive experiments show that our proposed geometric knowledge-guided distribution calibration effectively overcomes information deficits caused by data heterogeneity and sample imbalance, with boosted performance across benchmarks. 

**Abstract (ZH)**: å°½ç®¡æ·±åº¦å­¦ä¹ å–å¾—äº†å¿«é€Ÿå‘å±•ï¼Œä½†å­˜åœ¨çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯è§‚å¯Ÿåˆ°çš„è®­ç»ƒæ ·æœ¬ä¸åº•å±‚çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®è·ã€‚è¿™ç§å·®è·çš„åŸå› å¤šç§å¤šæ ·ï¼Œä¾‹å¦‚é‡‡æ ·åå·®å’Œå™ªå£°ç­‰ã€‚åœ¨åŸºç¡€æ¨¡å‹æ—¶ä»£ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åˆ©ç”¨ç°æˆï¼ˆè§†è§‰ï¼‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚CLIPã€DINOv2ï¼‰è¿›è¡Œç‰¹å¾æå–æ—¶ï¼Œç»“æœç‰¹å¾åˆ†å¸ƒçš„å‡ ä½•å½¢çŠ¶åœ¨ä¸åŒé¢†åŸŸå’Œæ•°æ®é›†ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„å¯ç§»æ¤æ€§ã€‚ä¸ºäº†éªŒè¯å…¶å®ç”¨æ€§ï¼Œæˆ‘ä»¬å°†å‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ¡†æ¶åº”ç”¨äºä¸¤ä¸ªæµè¡Œçš„å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ï¼šè”é‚¦å­¦ä¹ å’Œé•¿å°¾è¯†åˆ«ã€‚åœ¨è”é‚¦å­¦ä¹ åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨éšç§çº¦æŸä¸‹è·å–å…¨å±€å‡ ä½•å½¢çŠ¶çš„æŠ€æœ¯ï¼Œç„¶ååˆ©ç”¨è¿™äº›çŸ¥è¯†ç”Ÿæˆæ–°çš„æ ·æœ¬ï¼Œä»¥å¼¥åˆå±€éƒ¨å’Œå…¨å±€è§‚å¯Ÿä¹‹é—´çš„å·®è·ã€‚åœ¨é•¿å°¾å­¦ä¹ ä¸­ï¼Œå®ƒåˆ©ç”¨ä»æ ·æœ¬ä¸°å¯Œçš„ç±»åˆ«è½¬ç§»åˆ°æ ·æœ¬ç¨€ç¼ºçš„å°¾éƒ¨ç±»åˆ«çš„å‡ ä½•çŸ¥è¯†æ¥æ¢å¤çœŸå®åˆ†å¸ƒã€‚å…¨é¢çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æœ‰æ•ˆå…‹æœäº†ç”±äºæ•°æ®å¼‚æ„æ€§å’Œæ ·æœ¬ä¸å¹³è¡¡å¼•èµ·çš„ä¿¡æ¯ä¸è¶³ï¼Œæå‡äº†å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ã€‚ 

---
# Heterogeneous Influence Maximization in User Recommendation 

**Title (ZH)**: å¼‚è´¨ç”¨æˆ·å½±å“æœ€å¤§åŒ–æ¨è 

**Authors**: Hongru Hou, Jiachen Sun, Wenqing Lin, Wendong Bi, Xiangrong Wang, Deqing Yang  

**Link**: [PDF](https://arxiv.org/pdf/2508.13517)  

**Abstract**: User recommendation systems enhance user engagement by encouraging users to act as inviters to interact with other users (invitees), potentially fostering information propagation. Conventional recommendation methods typically focus on modeling interaction willingness. Influence-Maximization (IM) methods focus on identifying a set of users to maximize the information propagation. However, existing methods face two significant challenges. First, recommendation methods fail to unleash the candidates' spread capability. Second, IM methods fail to account for the willingness to interact. To solve these issues, we propose two models named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to unleash the dissemination potential of user recommendation systems. HeteroIM fills the gap between the IM method and the recommendation task, improving interaction willingness and maximizing spread coverage. The HeteroIR introduces a two-stage framework to estimate the spread profits. The HeteroIM incrementally selects the most influential invitee to recommend and rerank based on the number of reverse reachable (RR) sets containing inviters and invitees. RR set denotes a set of nodes that can reach a target via propagation. Extensive experiments show that HeteroIR and HeteroIM significantly outperform the state-of-the-art baselines with the p-value < 0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online gaming platforms and gained an 8.5\% and 10\% improvement in the online A/B test, respectively. Implementation codes are available at this https URL. 

**Abstract (ZH)**: ç”¨æˆ·æ¨èç³»ç»Ÿé€šè¿‡é¼“åŠ±ç”¨æˆ·ä½œä¸ºæ¨èè€…ä¸å…¶ä»–äººï¼ˆè¢«æ¨èè€…ï¼‰äº’åŠ¨ï¼Œå¢å¼ºç”¨æˆ·å‚ä¸åº¦ï¼Œ potentially ä¿ƒè¿›ä¿¡æ¯ä¼ æ’­ã€‚ä¼ ç»Ÿçš„æ¨èæ–¹æ³•é€šå¸¸ä¸“æ³¨äºå»ºæ¨¡äº’åŠ¨æ„æ„¿ã€‚å½±å“æœ€å¤§åŒ–ï¼ˆIMï¼‰æ–¹æ³•ä¸“æ³¨äºè¯†åˆ«ä¸€ç»„ç”¨æˆ·ä»¥æœ€å¤§åŒ–ä¿¡æ¯ä¼ æ’­ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•é¢ä¸´ç€ä¸¤ä¸ªæ˜¾è‘—çš„æŒ‘æˆ˜ï¼šé¦–å…ˆï¼Œæ¨èæ–¹æ³•æœªèƒ½é‡Šæ”¾å€™é€‰è€…çš„ä¼ æ’­èƒ½åŠ›ï¼›å…¶æ¬¡ï¼ŒIMæ–¹æ³•æœªèƒ½è€ƒè™‘äº’åŠ¨æ„æ„¿ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªæ¨¡å‹ï¼Œåˆ†åˆ«åä¸ºHeteroIRå’ŒHeteroIMã€‚HeteroIRæä¾›äº†ä¸€ç§ç›´è§‚çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥é‡Šæ”¾ç”¨æˆ·æ¨èç³»ç»Ÿçš„ä¼ æ’­æ½œåŠ›ã€‚HeteroIMåœ¨IMæ–¹æ³•ä¸æ¨èä»»åŠ¡ä¹‹é—´å¡«è¡¥äº†ç©ºç™½ï¼Œæé«˜äº†äº’åŠ¨æ„æ„¿å¹¶æœ€å¤§åŒ–ä¼ æ’­è¦†ç›–èŒƒå›´ã€‚HeteroIRå¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶æ¥ä¼°è®¡ä¼ æ’­æ”¶ç›Šã€‚HeteroIMåŸºäºåŒ…å«æ¨èè€…å’Œè¢«æ¨èè€…çš„é€†å¯è¾¾é›†ï¼ˆRRï¼‰çš„æ•°é‡ï¼Œé€æ­¥é€‰æ‹©æœ€å…·å½±å“åŠ›çš„è¢«æ¨èè€…è¿›è¡Œæ¨èå¹¶é‡æ–°æ’åºã€‚é€†å¯è¾¾é›†æŒ‡çš„æ˜¯å¯ä»¥é€šè¿‡ä¼ æ’­åˆ°è¾¾ç›®æ ‡çš„èŠ‚ç‚¹é›†ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒHeteroIRå’ŒHeteroIMçš„è¡¨ç°æ˜¾è‘—ä¼˜è¶Šï¼Œpå€¼<0.05ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨è…¾è®¯çš„åœ¨çº¿æ¸¸æˆå¹³å°ä¸Šéƒ¨ç½²äº†HeteroIRå’ŒHeteroIMï¼Œå¹¶åˆ†åˆ«åœ¨åœ¨çº¿A/Bæµ‹è¯•ä¸­è·å¾—äº†8.5%å’Œ10%çš„æå‡ã€‚ç›¸å…³å®æ–½ä»£ç å¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ã€‚ 

---
# Consumer Autonomy or Illusion? Rethinking Consumer Agency in the Age of Algorithms 

**Title (ZH)**: æ¶ˆè´¹è€…è‡ªä¸»è¿˜æ˜¯å¹»è±¡ï¼Ÿåœ¨ç®—æ³•æ—¶ä»£é‡æ€æ¶ˆè´¹è€…èƒ½åŠ¨æ€§ 

**Authors**: Pegah Nokhiz, Aravinda Kanchana Ruwanpathirana  

**Link**: [PDF](https://arxiv.org/pdf/2508.13440)  

**Abstract**: Consumer agency in the digital age is increasingly constrained by systemic barriers and algorithmic manipulation, raising concerns about the authenticity of consumption choices. Nowadays, financial decisions are shaped by external pressures like obligatory consumption, algorithmic persuasion, and unstable work schedules that erode financial autonomy. Obligatory consumption (like hidden fees) is intensified by digital ecosystems. Algorithmic tactics like personalized recommendations lead to impulsive purchases. Unstable work schedules also undermine financial planning. Thus, it is important to study how these factors impact consumption agency. To do so, we examine formal models grounded in discounted consumption with constraints that bound agency. We construct analytical scenarios in which consumers face obligatory payments, algorithm-influenced impulsive expenses, or unpredictable income due to temporal instability. Using this framework, we demonstrate that even rational, utility-maximizing agents can experience early financial ruin when agency is limited across structural, behavioral, or temporal dimensions and how diminished autonomy impacts long-term financial well-being. Our central argument is that consumer agency must be treated as a value (not a given) requiring active cultivation, especially in digital ecosystems. The connection between our formal modeling and this argument allows us to indicate that limitations on agency (whether structural, behavioral, or temporal) can be rigorously linked to measurable risks like financial instability. This connection is also a basis for normative claims about consumption as a value, by anchoring them in a formally grounded analysis of consumer behavior. As solutions, we study systemic interventions and consumer education to support value deliberation and informed choices. We formally demonstrate how these measures strengthen agency. 

**Abstract (ZH)**: æ•°å­—æ—¶ä»£æ¶ˆè´¹è€…çš„è‡ªä¸»æƒå—åˆ°ç³»ç»Ÿéšœç¢å’ŒæŠ€æœ¯æ“æ§çš„é™åˆ¶ï¼Œæ¶ˆè´¹é€‰æ‹©çš„çœŸå®æ€§å—åˆ°å…³æ³¨ã€‚å½“å‰çš„è´¢åŠ¡å†³ç­–å—åˆ°å¼ºåˆ¶æ¶ˆè´¹ã€ç®—æ³•åŠè¯´å’Œä¸ç¨³å®šå·¥ä½œæ—¶é—´ç­‰å¤–éƒ¨å‹åŠ›çš„å½±å“ï¼ŒæŸå®³äº†è´¢åŠ¡è‡ªä¸»æƒã€‚å¼ºåˆ¶æ¶ˆè´¹ï¼ˆå¦‚éšå½¢è´¹ç”¨ï¼‰åœ¨æ•°å­—ç”Ÿæ€ç³»ç»Ÿä¸­è¢«æ”¾å¤§ã€‚ä¸ªæ€§åŒ–çš„æ¨èç®—æ³•å¯¼è‡´å†²åŠ¨è´­ä¹°ã€‚ä¸ç¨³å®šçš„å·¥ä½œæ—¶é—´ä¹Ÿå‰Šå¼±äº†è´¢åŠ¡è§„åˆ’ã€‚å› æ­¤ï¼Œç ”ç©¶è¿™äº›å› ç´ å¦‚ä½•å½±å“æ¶ˆè´¹è‡ªä¸»æƒè‡³å…³é‡è¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åŸºäºå—é™æŠ˜ç°æ¶ˆè´¹çš„æ­£å¼æ¨¡å‹è¿›è¡Œç ”ç©¶ï¼Œæ„å»ºäº†æ¶ˆè´¹è€…é¢å¯¹å¼ºåˆ¶ä»˜æ¬¾ã€ç®—æ³•å½±å“ä¸‹çš„å†²åŠ¨å¼€æ”¯æˆ–å› æ—¶é—´ä¸ç¨³å®šæ€§è€Œå¸¦æ¥çš„ä¸å¯é¢„æµ‹æ”¶å…¥çš„åˆ†æåœºæ™¯ã€‚å€ŸåŠ©è¿™ä¸€æ¡†æ¶ï¼Œæˆ‘ä»¬è¯æ˜äº†å³ä½¿æ˜¯æœ€ç†æ€§çš„æ•ˆç”¨æœ€å¤§åŒ–ä»£ç†ï¼Œå½“è‡ªä¸»æƒåœ¨ç»“æ„ã€è¡Œä¸ºæˆ–æ—¶é—´ç»´åº¦ä¸Šå—åˆ°é™åˆ¶æ—¶ï¼Œä¹Ÿå¯èƒ½åœ¨æ—©æœŸé­é‡è´¢åŠ¡ç ´äº§ï¼Œå¹¶é˜æ˜äº†å‡å¼±çš„è‡ªä¸»æƒå¦‚ä½•å½±å“é•¿æœŸçš„è´¢åŠ¡ç¦ç¥‰ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼Œæ¶ˆè´¹è€…çš„è‡ªä¸»æƒåº”è¢«è§†ä¸ºä¸€ç§ä»·å€¼ï¼ˆè€Œéæ—¢å®šäº‹å®ï¼‰ï¼Œéœ€è¦ä¸»åŠ¨åŸ¹å…»ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­—ç”Ÿæ€ç³»ç»Ÿä¸­ã€‚æˆ‘ä»¬æ­£å¼å»ºæ¨¡ä¸è¿™ä¸€è®ºç‚¹çš„è”ç³»ï¼Œè¡¨æ˜è‡ªä¸»æƒçš„é™åˆ¶ï¼ˆæ— è®ºæ˜¯ç»“æ„æ€§çš„ã€è¡Œä¸ºä¸Šçš„è¿˜æ˜¯æ—¶é—´ä¸Šçš„ï¼‰å¯ä»¥ä¸¥æ ¼å…³è”åˆ°å¯è¡¡é‡çš„é£é™©ï¼Œå¦‚è´¢åŠ¡ä¸ç¨³å®šæ€§ã€‚è¿™ä¸€è”ç³»ä¹Ÿä¸ºå…³äºæ¶ˆè´¹ä½œä¸ºä»·å€¼çš„è§„èŒƒæ€§ä¸»å¼ æä¾›äº†ä¾æ®ï¼Œé€šè¿‡æ­£å¼çš„åœ°åˆ†ææ¶ˆè´¹è€…è¡Œä¸ºæ¥é”šå®šè¿™äº›ä¸»å¼ ã€‚ä½œä¸ºè§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬ç ”ç©¶ç³»ç»Ÿå¹²é¢„æªæ–½å’Œæ¶ˆè´¹è€…æ•™è‚²ï¼Œä»¥æ”¯æŒä»·å€¼æƒè¡¡ä¸çŸ¥æƒ…é€‰æ‹©ï¼Œå¹¶æ­£å¼è¯æ˜äº†è¿™äº›æªæ–½æ˜¯å¦‚ä½•å¢å¼ºè‡ªä¸»æƒçš„ã€‚ 

---
# Dynamic Design of Machine Learning Pipelines via Metalearning 

**Title (ZH)**: åŸºäºå…ƒå­¦ä¹ çš„æœºå™¨å­¦ä¹ ç®¡é“åŠ¨æ€è®¾è®¡ 

**Authors**: Edesio AlcobaÃ§a, AndrÃ© C. P. L. F. de Carvalho  

**Link**: [PDF](https://arxiv.org/pdf/2508.13436)  

**Abstract**: Automated machine learning (AutoML) has democratized the design of machine learning based systems, by automating model selection, hyperparameter tuning and feature engineering. However, the high computational cost associated with traditional search and optimization strategies, such as Random Search, Particle Swarm Optimization and Bayesian Optimization, remains a significant challenge. Moreover, AutoML systems typically explore a large search space, which can lead to overfitting. This paper introduces a metalearning method for dynamically designing search spaces for AutoML system. The proposed method uses historical metaknowledge to select promising regions of the search space, accelerating the optimization process. According to experiments conducted for this study, the proposed method can reduce runtime by 89\% in Random Search and search space by (1.8/13 preprocessor and 4.3/16 classifier), without compromising significant predictive performance. Moreover, the proposed method showed competitive performance when adapted to Auto-Sklearn, reducing its search space. Furthermore, this study encompasses insights into meta-feature selection, meta-model explainability, and the trade-offs inherent in search space reduction strategies. 

**Abstract (ZH)**: è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰é€šè¿‡è‡ªåŠ¨åŒ–æ¨¡å‹é€‰æ‹©ã€è¶…å‚æ•°è°ƒä¼˜å’Œç‰¹å¾å·¥ç¨‹ï¼Œæ°‘ä¸»åŒ–äº†åŸºäºæœºå™¨å­¦ä¹ çš„ç³»ç»Ÿè®¾è®¡ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæœç´¢å’Œä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚éšæœºæœç´¢ã€ç²’å­ç¾¤ä¼˜åŒ–å’Œè´å¶æ–¯ä¼˜åŒ–ï¼‰ç›¸å…³çš„äººæœºæˆæœ¬ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼ŒAutoMLç³»ç»Ÿé€šå¸¸æ¢ç´¢ä¸€ä¸ªå·¨å¤§çš„æœç´¢ç©ºé—´ï¼Œè¿™å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å…ƒå­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€è®¾è®¡AutoMLç³»ç»Ÿçš„æœç´¢ç©ºé—´ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å†å²å…ƒçŸ¥è¯†é€‰æ‹©æœç´¢ç©ºé—´ä¸­å…·æœ‰æ½œåŠ›çš„åŒºåŸŸï¼Œä»è€ŒåŠ é€Ÿä¼˜åŒ–è¿‡ç¨‹ã€‚æ ¹æ®æœ¬ç ”ç©¶ä¸­çš„å®éªŒï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥å°†éšæœºæœç´¢çš„è¿è¡Œæ—¶é—´å‡å°‘89%ï¼Œå¹¶å°†æœç´¢ç©ºé—´åˆ†åˆ«å‡å°‘åˆ°1.8/13é¢„å¤„ç†å™¨å’Œ4.3/16åˆ†ç±»å™¨ï¼Œè€Œä¸ä¼šæ˜¾è‘—ç‰ºç‰²é¢„æµ‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå½“å°†è¯¥æ–¹æ³•è°ƒæ•´åº”ç”¨äºAuto-Sklearnæ—¶ï¼Œå±•ç¤ºäº†å…¶ç«äº‰æ€§èƒ½å¹¶å‡å°‘äº†å…¶æœç´¢ç©ºé—´ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜åŒ…æ‹¬äº†å…³äºå…ƒç‰¹å¾é€‰æ‹©ã€å…ƒæ¨¡å‹å¯è§£é‡Šæ€§å’Œæœç´¢ç©ºé—´ç¼©å‡ç­–ç•¥å›ºæœ‰æŠ˜è¡·çš„è§è§£ã€‚ 

---
# SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer 

**Title (ZH)**: SVDformer: åŸºäºSVDå’ŒTransformerçš„æ–¹å‘æ„ŸçŸ¥é¢‘è°±å›¾åµŒå…¥å­¦ä¹  

**Authors**: Jiayu Fang, Zhiqi Shao, S T Boris Choy, Junbin Gao  

**Link**: [PDF](https://arxiv.org/pdf/2508.13435)  

**Abstract**: Directed graphs are widely used to model asymmetric relationships in real-world systems. However, existing directed graph neural networks often struggle to jointly capture directional semantics and global structural patterns due to their isotropic aggregation mechanisms and localized filtering mechanisms. To address this limitation, this paper proposes SVDformer, a novel framework that synergizes SVD and Transformer architecture for direction-aware graph representation learning. SVDformer first refines singular value embeddings through multi-head self-attention, adaptively enhancing critical spectral components while suppressing high-frequency noise. This enables learnable low-pass/high-pass graph filtering without requiring spectral kernels. Furthermore, by treating singular vectors as directional projection bases and singular values as scaling factors, SVDformer uses the Transformer to model multi-scale interactions between incoming/outgoing edge patterns through attention weights, thereby explicitly preserving edge directionality during feature propagation. Extensive experiments on six directed graph benchmarks demonstrate that SVDformer consistently outperforms state-of-the-art GNNs and direction-aware baselines on node classification tasks, establishing a new paradigm for learning representations on directed graphs. 

**Abstract (ZH)**: SVDFormerï¼šä¸€ç§ååŒSVDå’ŒTransformeræ¶æ„çš„æ–¹å‘æ„ŸçŸ¥å›¾è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ 

---
# EventTSF: Event-Aware Non-Stationary Time Series Forecasting 

**Title (ZH)**: åŸºäºäº‹ä»¶çš„éå¹³ç¨³æ—¶é—´åºåˆ—é¢„æµ‹ï¼šEventTSF 

**Authors**: Yunfeng Ge, Ming Jin, Yiji Zhao, Hongyan Li, Bo Du, Chang Xu, Shirui Pan  

**Link**: [PDF](https://arxiv.org/pdf/2508.13434)  

**Abstract**: Time series forecasting plays a vital role in critical domains like energy and transportation, where non-stationary dynamics are deeply intertwined with events in other modalities such as texts. However, incorporating natural language-based external events to improve non-stationary forecasting remains largely unexplored, as most approaches still rely on a single modality, resulting in limited contextual knowledge and model underperformance. Enabling fine-grained multimodal interactions between temporal and textual data is challenged by three fundamental issues: (1) the difficulty of fine-grained synchronization between time-varying discrete textual events and continuous time series; (2) the inherent temporal uncertainty introduced by textual semantics; and (3) the misalignment between textual event embeddings and multi-resolution temporal patterns. In this work, we address these challenges by introducing event-aware non-stationary time series forecasting (EventTSF), an autoregressive generation framework that integrates historical time series with textual events to make subsequent forecasts. Specifically, EventTSF uses autoregressive diffusion with flow matching at each step to capture nuanced temporal-event interactions. To handle event-induced uncertainty, flow matching timesteps are adaptively controlled according to event semantic signals. The underlying denoiser employs a multimodal U-shaped diffusion transformer that efficiently fuses temporal and textual modalities across different resolutions. Extensive experiments on 8 synthetic and real-world datasets show that EventTSF outperforms 12 baselines across diverse event-aware non-stationary time series forecasting scenarios, achieving substantial improvements of 10.7% higher forecasting accuracy and $1.13\times$ faster training efficiency. 

**Abstract (ZH)**: äº‹ä»¶æ„è¯†éå¹³ç¨³æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆEventTSFï¼‰ï¼šä¸€ç§é›†æˆå†å²æ—¶é—´åºåˆ—å’Œæ–‡æœ¬äº‹ä»¶çš„è‡ªå›å½’ç”Ÿæˆæ¡†æ¶ 

---
# AlphaX: An AI-Based Value Investing Strategy for the Brazilian Stock Market 

**Title (ZH)**: AlphaXï¼šåŸºäºäººå·¥æ™ºèƒ½çš„ä»·å€¼æŠ•èµ„ç­–ç•¥â€”â€”ä»¥å·´è¥¿è‚¡å¸‚ä¸ºä¾‹ 

**Authors**: Paulo AndrÃ© Lima de Castro  

**Link**: [PDF](https://arxiv.org/pdf/2508.13429)  

**Abstract**: Autonomous trading strategies have been a subject of research within the field of artificial intelligence (AI) for aconsiderable period. Various AI techniques have been explored to develop autonomous agents capable of trading financial assets. These approaches encompass traditional methods such as neural networks, fuzzy logic, and reinforcement learning, as well as more recent advancements, including deep neural networks and deep reinforcement learning. Many developers report success in creating strategies that exhibit strong performance during simulations using historical price data, a process commonly referred to as backtesting. However, when these strategies are deployed in real markets, their performance often deteriorates, particularly in terms of risk-adjusted returns. In this study, we propose an AI-based strategy inspired by a classical investment paradigm: Value Investing. Financial AI models are highly susceptible to lookahead bias and other forms of bias that can significantly inflate performance in backtesting compared to live trading conditions. To address this issue, we conducted a series of computational simulations while controlling for these biases, thereby reducing the risk of overfitting. Our results indicate that the proposed approach outperforms major Brazilian market benchmarks. Moreover, the strategy, named AlphaX, demonstrated superior performance relative to widely used technical indicators such as the Relative Strength Index (RSI) and Money Flow Index (MFI), with statistically significant results. Finally, we discuss several open challenges and highlight emerging technologies in qualitative analysis that may contribute to the development of a comprehensive AI-based Value Investing framework in the future 

**Abstract (ZH)**: åŸºäºäººå·¥æ™ºèƒ½çš„ä»·å€¼æŠ•èµ„è‡ªä¸»äº¤æ˜“ç­–ç•¥ï¼šå…‹æœå›æµ‹åå·®ä¸å®ç›˜è¡¨ç°å·®å¼‚çš„ç ”ç©¶ 

---
# Mitigating Easy Option Bias in Multiple-Choice Question Answering 

**Title (ZH)**: ç¼“è§£å¤šé¡¹é€‰æ‹©é¢˜å›ç­”ä¸­çš„æ˜“é€‰é¡¹åè§ 

**Authors**: Hao Zhang, Chen Li, Basura Fernando  

**Link**: [PDF](https://arxiv.org/pdf/2508.13428)  

**Abstract**: In this early study, we observe an Easy-Options Bias (EOB) issue in some multiple-choice Visual Question Answering (VQA) benchmarks such as MMStar, RealWorldQA, SEED-Bench, Next-QA, STAR benchmark and Video-MME. This bias allows vision-language models (VLMs) to select the correct answer using only the vision (V) and options (O) as inputs, without the need for the question (Q). Through grounding experiments, we attribute the bias to an imbalance in visual relevance: the correct answer typically aligns more closely with the visual contents than the negative options in feature space, creating a shortcut for VLMs to infer the answer via simply vision-option similarity matching. To fix this, we introduce GroundAttack, a toolkit that automatically generates hard negative options as visually plausible as the correct answer. We apply it to the NExT-QA and MMStar datasets, creating new EOB-free annotations. On these EOB-free annotations, current VLMs approach to random accuracies under (V+O) settings, and drop to non-saturated accuracies under (V+Q+O) settings, providing a more realistic evaluation of VLMs' QA ability. Codes and new annotations will be released soon. 

**Abstract (ZH)**: åœ¨æ—©æœŸç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å‘ç°åœ¨MMStarã€RealWorldQAã€SEED-Benchã€Next-QAã€STARåŸºå‡†å’ŒVideo-MMEç­‰ä¸€äº›å¤šé¡¹é€‰æ‹©è§†è§‰é—®ç­”ï¼ˆVQAï¼‰åŸºå‡†ä¸­å­˜åœ¨æ˜“é€‰é¡¹åå·®ï¼ˆEOBï¼‰é—®é¢˜ã€‚é€šè¿‡æ¥åœ°å®éªŒï¼Œæˆ‘ä»¬å½’å› äºè§†è§‰ç›¸å…³æ€§çš„ä¸å¹³è¡¡ï¼šæ­£ç¡®ç­”æ¡ˆåœ¨ç‰¹å¾ç©ºé—´ä¸­é€šå¸¸ä¸è§†è§‰å†…å®¹æ›´å¯†åˆ‡å¯¹é½ï¼Œè€Œè´Ÿé€‰é¡¹åˆ™ä¸ç„¶ï¼Œè¿™ä¸ºVLMsæä¾›äº†ç›´æ¥é€šè¿‡è§†è§‰-é€‰é¡¹ç›¸ä¼¼æ€§åŒ¹é…æ¥æ¨æ–­ç­”æ¡ˆçš„æ·å¾„ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†GroundAttackå·¥å…·åŒ…ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨ç”Ÿæˆä¸æ­£ç¡®ç­”æ¡ˆè§†è§‰ä¸ŠåŒæ ·å¯ä¿¡çš„å›°éš¾è´Ÿé€‰é¡¹ã€‚æˆ‘ä»¬å°†å…¶åº”ç”¨äºNExT-QAå’ŒMMStaræ•°æ®é›†ï¼Œåˆ›å»ºäº†æ–°çš„æ— EOBæ³¨é‡Šã€‚åœ¨è¿™äº›æ— EOBæ³¨é‡Šä¸‹ï¼Œå½“å‰çš„VLMsåœ¨ä»…ä½¿ç”¨ï¼ˆV+Oï¼‰è®¾ç½®æ—¶è¡¨ç°ä¸ºéšæœºå‡†ç¡®æ€§ï¼Œå¹¶åœ¨ï¼ˆV+Q+Oï¼‰è®¾ç½®ä¸‹å‡†ç¡®æ€§æ— æ³•é¥±å’Œï¼Œè¿™ä¸ºæ›´çœŸå®åœ°è¯„ä¼°VLMsçš„é—®ç­”èƒ½åŠ›æä¾›äº†ä¾æ®ã€‚ä»£ç å’Œæ–°æ³¨é‡Šå°†äºè¿‘æœŸå‘å¸ƒã€‚ 

---
# AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System 

**Title (ZH)**: AdaptJobRec: æå‡ç”± LLM é©±åŠ¨çš„ä»£ç†å‹èŠå¤©èŒä¸šæ¨èç³»ç»Ÿæ¥½ã—ï¿½Ã¡ndose
user
Adaptive Transformer Compression for Efficient Recommender Systems in Edge Computing Environments 

**Authors**: Qixin Wang, Dawei Wang, Kun Chen, Yaowei Hu, Puneet Girdhar, Ruoteng Wang, Aadesh Gupta, Chaitanya Devella, Wenlai Guo, Shangwen Huang, Bachir Aoun, Greg Hayworth, Han Li, Xintao Wu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13423)  

**Abstract**: In recent years, recommendation systems have evolved from providing a single list of recommendations to offering a comprehensive suite of topic focused services. To better accomplish this task, conversational recommendation systems (CRS) have progressed from basic retrieval augmented LLM generation to agentic systems with advanced reasoning and self correction capabilities. However, agentic systems come with notable response latency, a longstanding challenge for conversational recommendation systems. To balance the trade off between handling complex queries and minimizing latency, we propose AdaptJobRec, the first conversational job recommendation system that leverages autonomous agent to integrate personalized recommendation algorithm tools. The system employs a user query complexity identification mechanism to minimize response latency. For straightforward queries, the agent directly selects the appropriate tool for rapid responses. For complex queries, the agent uses the memory processing module to filter chat history for relevant content, then passes the results to the intelligent task decomposition planner, and finally executes the tasks using personalized recommendation tools. Evaluation on Walmart's real world career recommendation scenarios demonstrates that AdaptJobRec reduces average response latency by up to 53.3% compared to competitive baselines, while significantly improving recommendation accuracy. 

**Abstract (ZH)**: è¿‘å¹´æ¥ï¼Œæ¨èç³»ç»Ÿä»æä¾›å•ä¸€æ¨èåˆ—è¡¨æ¼”è¿›åˆ°æä¾›å…¨é¢çš„ä¸»é¢˜èšç„¦æœåŠ¡ã€‚ä¸ºäº†æ›´å¥½åœ°å®Œæˆè¿™ä¸€ä»»åŠ¡ï¼Œå¯¹è¯æ¨èç³»ç»Ÿï¼ˆCRSï¼‰ä»åŸºæœ¬çš„æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ç”Ÿæˆå‘å±•åˆ°å…·æœ‰é«˜çº§æ¨ç†å’Œè‡ªæˆ‘ä¿®æ­£èƒ½åŠ›çš„ä»£ç†ç³»ç»Ÿã€‚ç„¶è€Œï¼Œä»£ç†ç³»ç»Ÿä¼´éšç€æ˜¾è‘—çš„å“åº”å»¶è¿Ÿï¼Œè¿™æ˜¯å¯¹è¯æ¨èç³»ç»Ÿçš„ä¸€ä¸ªé•¿æœŸæŒ‘æˆ˜ã€‚ä¸ºäº†åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢å’Œæœ€å°åŒ–å»¶è¿Ÿä¹‹é—´å–å¾—å¹³è¡¡ï¼Œæˆ‘ä»¬æå‡ºäº†AdaptJobRecï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåˆ©ç”¨è‡ªä¸»ä»£ç†æ•´åˆä¸ªæ€§åŒ–æ¨èç®—æ³•å·¥å…·çš„å¯¹è¯èŒä¸šæ¨èç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ç”¨æˆ·æŸ¥è¯¢å¤æ‚æ€§è¯†åˆ«æœºåˆ¶ä»¥å‡å°‘å“åº”å»¶è¿Ÿã€‚å¯¹äºç®€å•çš„æŸ¥è¯¢ï¼Œä»£ç†ç›´æ¥é€‰æ‹©åˆé€‚çš„å·¥å…·ä»¥å¿«é€Ÿå“åº”ã€‚å¯¹äºå¤æ‚çš„æŸ¥è¯¢ï¼Œä»£ç†ä½¿ç”¨è®°å¿†å¤„ç†æ¨¡å—è¿‡æ»¤èŠå¤©å†å²ä»¥æå–ç›¸å…³ä¿¡æ¯ï¼Œéšåå°†ç»“æœä¼ é€’ç»™æ™ºèƒ½ä»»åŠ¡åˆ†è§£è§„åˆ’å™¨ï¼Œå¹¶æœ€ç»ˆä½¿ç”¨ä¸ªæ€§åŒ–æ¨èå·¥å…·æ‰§è¡Œä»»åŠ¡ã€‚åœ¨æ²ƒå°”ç›å®é™…èŒä¸šç”Ÿæ¶¯æ¨èåœºæ™¯ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸ç«äº‰baselineç›¸æ¯”ï¼ŒAdaptJobRecå°†å¹³å‡å“åº”å»¶è¿Ÿæœ€å¤šé™ä½äº†53.3%ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜æ¨èå‡†ç¡®æ€§ã€‚ 

---
# Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp 

**Title (ZH)**: åŸºäºç™«ç—«ç›¸å…³å•éŸ³è°ƒçš„åŠç›‘ç£å¼‚å¸¸æ£€æµ‹ç®¡é“ç”¨äºSOZå®šä½ 

**Authors**: Nooshin Bahador, Milad Lankarany  

**Link**: [PDF](https://arxiv.org/pdf/2508.13406)  

**Abstract**: This study presents a quantitative framework for evaluating the spatial concordance between clinically defined seizure onset zones (SOZs) and statistically anomalous channels identified through time-frequency analysis of chirp events. The proposed pipeline employs a two-step methodology: (1) Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with adaptive neighborhood selection identifies anomalous channels based on spectro-temporal features of chirp (Onset frequency, offset frequency, and temporal duration); and (2) Spatial Correlation Analysis, which computes both exact co-occurrence metrics and weighted index similarity, incorporating hemispheric congruence and electrode proximity. Key findings demonstrate that the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects outliers, with index matching (weighted by channel proximity) outperforming exact matching in SOZ localization. Performance metrics (precision, recall, F1) were highest for seizure-free patients (Index Precision mean: 0.903) and those with successful surgical outcomes (Index Precision mean: 0.865), whereas failure cases exhibited lower concordance (Index Precision mean: 0.460). The key takeaway is that chirp-based outlier detection, combined with weighted spatial metrics, provides a complementary method for SOZ localization, particularly in patients with successful surgical outcomes. 

**Abstract (ZH)**: åŸºäºé¢¤åŠ¨äº‹ä»¶æ—¶é¢‘åˆ†æè¯†åˆ«çš„ç»Ÿè®¡å¼‚å¸¸é€šé“ä¸ä¸´åºŠå®šä¹‰çš„ç™«ç—«å‘ä½œèµ·å§‹åŒºçš„ç©ºé—´ä¸€è‡´æ€§çš„é‡åŒ–è¯„ä¼°æ¡†æ¶ 

---
# Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts 

**Title (ZH)**: é»˜å£°ä¹‹æ¯ï¼šæç‚¼é•¿è¯­éŸ³è½¬å½•ä¸­çš„è¯­æ³•ä¸è¯­ä¹‰ 

**Authors**: Duygu Altinok  

**Link**: [PDF](https://arxiv.org/pdf/2508.13376)  

**Abstract**: ASR systems often struggle with maintaining syntactic and semantic accuracy in long audio transcripts, impacting tasks like Named Entity Recognition (NER), capitalization, and punctuation. We propose a novel approach that enhances ASR by distilling contextual knowledge from LLaMA models into Whisper. Our method uses two strategies: (1) token level distillation with optimal transport to align dimensions and sequence lengths, and (2) representation loss minimization between sentence embeddings of Whisper and LLaMA, blending syntax and semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long audios and rich entities demonstrate significant improvements in Word Error Rate (WER), NER, capitalization, and punctuation success. By introducing novel NER metrics and exploring semantics aware ASR, our work highlights the value of integrating linguistic context into transcription, setting a foundation for robust, context-aware ASR in longform speech. 

**Abstract (ZH)**: ASRç³»ç»Ÿåœ¨ç»´æŠ¤é•¿éŸ³é¢‘è½¬å½•çš„å¥æ³•å’Œè¯­ä¹‰å‡†ç¡®æ€§æ–¹é¢å¾€å¾€é¢ä¸´æŒ‘æˆ˜ï¼Œå½±å“å‘½åå®ä½“è¯†åˆ«(NER)ã€æ ‡ç‚¹ç¬¦å·å’Œå¤§å°å†™ç­‰ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡å°†LLaMAæ¨¡å‹çš„ä¸Šä¸‹æ–‡çŸ¥è¯†æç‚¼åˆ°Whisperä¸­æ¥å¢å¼ºASRæ€§èƒ½ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤ç§ç­–ç•¥ï¼š(1) åŸºäºæœ€ä¼˜ä¼ è¾“çš„å­ä»¤ç‰Œçº§åˆ«æç‚¼ï¼Œå¯¹é½ç»´åº¦å’Œåºåˆ—é•¿åº¦ï¼›(2) é€šè¿‡æœ€å°åŒ–Whisperå’ŒLLaMAå¥å­åµŒå…¥ä¹‹é—´çš„è¡¨ç¤ºæŸå¤±ï¼Œèåˆå¥æ³•å’Œè¯­ä¹‰ã€‚åœ¨åŒ…å«é•¿éŸ³é¢‘å’Œä¸°å¯Œå®ä½“çš„Spoken Wikipediaæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å•è¯é”™è¯¯ç‡(WER)ã€NERã€å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·å‡†ç¡®ç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ã€‚é€šè¿‡å¼•å…¥æ–°çš„NERæŒ‡æ ‡å¹¶æ¢ç´¢è¯­ä¹‰æ„ŸçŸ¥çš„ASRï¼Œæˆ‘ä»¬çš„å·¥ä½œçªæ˜¾äº†å°†è¯­è¨€ä¸Šä¸‹æ–‡æ•´åˆåˆ°è½¬å½•ä¸­çš„ä»·å€¼ï¼Œä¸ºé•¿ç¯‡è¯­éŸ³çš„å¥å£®ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ASRå¥ å®šäº†åŸºç¡€ã€‚ 

---
# Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT 

**Title (ZH)**: å…‹æœè®¾å¤‡ç«¯è¯­éŸ³ç¿»è¯‘çš„å»¶è¿Ÿç“¶é¢ˆï¼šåŸºäºå¯¹é½çš„çº§è”æµå¼MTæ–¹æ³• 

**Authors**: Zeeshan Ahmed, Frank Seide, Niko Moritz, Ju Lin, Ruiming Xie, Simone Merello, Zhe Liu, Christian Fuegen  

**Link**: [PDF](https://arxiv.org/pdf/2508.13358)  

**Abstract**: This paper tackles several challenges that arise when integrating Automatic Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device streaming speech translation. Although state-of-the-art ASR systems based on Recurrent Neural Network Transducers (RNN-T) can perform real-time transcription, achieving streaming translation in real-time remains a significant challenge. To address this issue, we propose a simultaneous translation approach that effectively balances translation quality and latency. We also investigate efficient integration of ASR and MT, leveraging linguistic cues generated by the ASR system to manage context and utilizing efficient beam-search pruning techniques such as time-out and forced finalization to maintain system's real-time factor. We apply our approach to an on-device bilingual conversational speech translation and demonstrate that our techniques outperform baselines in terms of latency and quality. Notably, our technique narrows the quality gap with non-streaming translation systems, paving the way for more accurate and efficient real-time speech translation. 

**Abstract (ZH)**: æœ¬æ–‡è§£å†³äº†å°†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œæœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰é›†æˆç”¨äºå®æ—¶è®¾å¤‡ç«¯æµå¼è¯­éŸ³ç¿»è¯‘æ—¶å‡ºç°çš„å¤šä¸ªæŒ‘æˆ˜ã€‚è™½ç„¶åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œè¯‘ç å™¨ï¼ˆRNN-Tï¼‰çš„å…ˆè¿›ASRç³»ç»Ÿå¯ä»¥è¿›è¡Œå®æ—¶è½¬å†™ï¼Œä½†åœ¨å®æ—¶å®ç°æµå¼ç¿»è¯‘ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒæ—¶ç¿»è¯‘æ–¹æ³•ï¼Œæœ‰æ•ˆå¹³è¡¡äº†ç¿»è¯‘è´¨é‡å’Œå»¶è¿Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ASRå’ŒMTçš„é«˜æ•ˆé›†æˆï¼Œåˆ©ç”¨ASRç³»ç»Ÿç”Ÿæˆçš„è¯­è¨€çº¿ç´¢ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œå¹¶é‡‡ç”¨æ—¶é—´è¶…æ—¶å’Œå¼ºåˆ¶æœ€ç»ˆåŒ–ç­‰é«˜æ•ˆçš„æŸæœç´¢å‰ªææŠ€æœ¯æ¥ä¿æŒç³»ç»Ÿçš„å®æ—¶æ€§ã€‚æˆ‘ä»¬å°†è¯¥æ–¹æ³•åº”ç”¨äºè®¾å¤‡ç«¯åŒè¯­å¯¹è¯è¯­éŸ³ç¿»è¯‘ï¼Œå¹¶è¯æ˜äº†æˆ‘ä»¬çš„æŠ€æœ¯åœ¨å»¶è¿Ÿå’Œè´¨é‡ä¸Šè¶…è¿‡äº†åŸºçº¿ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯ç¼©å°äº†ä¸éæµå¼ç¿»è¯‘ç³»ç»Ÿä¹‹é—´çš„è´¨é‡å·®è·ï¼Œä¸ºæ›´å‡†ç¡®å’Œé«˜æ•ˆçš„å®æ—¶è¯­éŸ³ç¿»è¯‘é“ºå¹³äº†é“è·¯ã€‚ 

---
# Counterfactual Probabilistic Diffusion with Expert Models 

**Title (ZH)**: ä¸“å®¶æ¨¡å‹å¼•å¯¼çš„åäº‹å®æ¦‚ç‡æ‰©æ•£ 

**Authors**: Wenhao Mu, Zhi Cao, Mehmed Uludag, Alexander RodrÃ­guez  

**Link**: [PDF](https://arxiv.org/pdf/2508.13355)  

**Abstract**: Predicting counterfactual distributions in complex dynamical systems is essential for scientific modeling and decision-making in domains such as public health and medicine. However, existing methods often rely on point estimates or purely data-driven models, which tend to falter under data scarcity. We propose a time series diffusion-based framework that incorporates guidance from imperfect expert models by extracting high-level signals to serve as structured priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and data-driven approaches, enabling more reliable and interpretable causal inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations, synthetic pharmacological dynamics, and real-world case studies, demonstrating that it consistently outperforms strong baselines in both point prediction and distributional accuracy. 

**Abstract (ZH)**: åœ¨å¤æ‚åŠ¨åŠ›ç³»ç»Ÿä¸­é¢„æµ‹åäº‹å®åˆ†å¸ƒå¯¹äºç§‘å­¦å»ºæ¨¡å’Œå†³ç­–åœ¨å…¬å…±å«ç”Ÿå’Œè¯ç‰©é¢†åŸŸä¸­æ˜¯å¿…ä¸å¯å°‘çš„ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºçº¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºæ—¶å¾€å¾€ä¼šå¤±æ•ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ¡†æ¶ï¼Œé€šè¿‡æå–é«˜é¢‘ä¿¡å·ä½œä¸ºç»“æ„å…ˆéªŒç”¨äºç”Ÿæˆå»ºæ¨¡ï¼Œä»è€Œæ•´åˆäº†æœºæ¢°ä¸»ä¹‰å’Œæ•°æ®é©±åŠ¨çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨ODE-Diffä¸Šå®ç°äº†åœ¨åŠåˆæˆçš„COVID-1-1æ„ŸæŸ“æ¨¡æ‹Ÿã€åˆæˆçš„è¯ç‰©åŠ¨åŠ›å­¦å’ŒçœŸå®ä¸–ç•Œçš„å…¬å…±å«ç”Ÿæ•°æ®ä¸Šçš„è¯„ä¼°ï¼Œåœ¨è¿™äº›è¯„ä¼°ä¸­ï¼ŒODE-Diff ä¸€è‡´åœ°ä¼˜äºå¼ºå¤§çš„åŸºçº¿æ–¹æ³•ï¼Œåœ¨åœ¨åäº‹å®é¢„æµ‹å’Œåˆ†å¸ƒå‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚ 

---
# A Dual-Attention Graph Network for fMRI Data Classification 

**Title (ZH)**: åŒæ³¨æ„åŠ›å›¾å½¢ç½‘ç»œåœ¨fMRIæ•°æ®åˆ†ç±»ä¸­çš„åº”ç”¨ 

**Authors**: Amirali Arbab, Zeinab Davarani, Mehran Safayani  

**Link**: [PDF](https://arxiv.org/pdf/2508.13328)  

**Abstract**: Understanding the complex neural activity dynamics is crucial for the development of the field of neuroscience. Although current functional MRI classification approaches tend to be based on static functional connectivity or cannot capture spatio-temporal relationships comprehensively, we present a new framework that leverages dynamic graph creation and spatiotemporal attention mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in this research dynamically infers functional brain connectivity in each time interval using transformer-based attention mechanisms, enabling the model to selectively focus on crucial brain regions and time segments. By constructing time-varying graphs that are then processed with Graph Convolutional Networks (GCNs) and transformers, our method successfully captures both localized interactions and global temporal dependencies. Evaluated on the subset of ABIDE dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint modeling of dynamic connectivity and spatio-temporal context for fMRI classification. The core novelty arises from (1) attention-driven dynamic graph creation that learns temporal brain region interactions and (2) hierarchical spatio-temporal feature fusion through GCNtransformer fusion. 

**Abstract (ZH)**: åŸºäºåŠ¨æ€å›¾åˆ›å»ºå’Œæ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶çš„è‡ªé—­ç—‡è°±ç³»éšœç¢è¯Šæ–­ç ”ç©¶ï¼šæ•è·æ—¶ç©ºä¾èµ–å…³ç³»çš„æ–°æ¡†æ¶ 

---
# Hierarchical Conformal Classification 

**Title (ZH)**: åˆ†å±‚ç¬¦åˆåˆ†ç±» 

**Authors**: Floris den Hengst, InÃ¨s Blin, Majid Mohammadi, Syed Ihtesham Hussain Shah, Taraneh Younesian  

**Link**: [PDF](https://arxiv.org/pdf/2508.13288)  

**Abstract**: Conformal prediction (CP) is a powerful framework for quantifying uncertainty in machine learning models, offering reliable predictions with finite-sample coverage guarantees. When applied to classification, CP produces a prediction set of possible labels that is guaranteed to contain the true label with high probability, regardless of the underlying classifier. However, standard CP treats classes as flat and unstructured, ignoring domain knowledge such as semantic relationships or hierarchical structure among class labels. This paper presents hierarchical conformal classification (HCC), an extension of CP that incorporates class hierarchies into both the structure and semantics of prediction sets. We formulate HCC as a constrained optimization problem whose solutions yield prediction sets composed of nodes at different levels of the hierarchy, while maintaining coverage guarantees. To address the combinatorial nature of the problem, we formally show that a much smaller, well-structured subset of candidate solutions suffices to ensure coverage while upholding optimality. An empirical evaluation on three new benchmarks consisting of audio, image, and text data highlights the advantages of our approach, and a user study shows that annotators significantly prefer hierarchical over flat prediction sets. 

**Abstract (ZH)**: å±‚æ¬¡åŒ– conformal åˆ†ç±»ï¼ˆHCCï¼‰ï¼š incorporate ç±»åˆ«å±‚æ¬¡ç»“æ„åˆ° prediction sets çš„ç»“æ„å’Œè¯­ä¹‰ä¸­ 

---
# Goal-Directedness is in the Eye of the Beholder 

**Title (ZH)**: ç›®æ ‡å¯¼å‘æ€§åœ¨äºè§‚å¯Ÿè€…çš„è§†è§’ã€‚ 

**Authors**: Nina Rajcic, Anders SÃ¸gaard  

**Link**: [PDF](https://arxiv.org/pdf/2508.13247)  

**Abstract**: Our ability to predict the behavior of complex agents turns on the attribution of goals. Probing for goal-directed behavior comes in two flavors: Behavioral and mechanistic. The former proposes that goal-directedness can be estimated through behavioral observation, whereas the latter attempts to probe for goals in internal model states. We work through the assumptions behind both approaches, identifying technical and conceptual problems that arise from formalizing goals in agent systems. We arrive at the perhaps surprising position that goal-directedness cannot be measured objectively. We outline new directions for modeling goal-directedness as an emergent property of dynamic, multi-agent systems. 

**Abstract (ZH)**: æˆ‘ä»¬é¢„æµ‹å¤æ‚ä»£ç†è¡Œä¸ºçš„èƒ½åŠ›å–å†³äºç›®æ ‡çš„å½’å› ã€‚æ¢æ±‚ç›®æ ‡å¯¼å‘è¡Œä¸ºæœ‰ä¸¤ç§æ–¹å¼ï¼šè¡Œä¸ºæ–¹å¼å’Œæœºåˆ¶æ–¹å¼ã€‚å‰è€…è®¤ä¸ºå¯ä»¥é€šè¿‡è¡Œä¸ºè§‚å¯Ÿä¼°ç®—ç›®æ ‡å¯¼å‘æ€§ï¼Œåè€…åˆ™å°è¯•åœ¨å†…éƒ¨æ¨¡å‹çŠ¶æ€ä¸­æ¢æ±‚ç›®æ ‡ã€‚æˆ‘ä»¬æ¢è®¨äº†è¿™ä¸¤ç§æ–¹æ³•èƒŒåçš„å‡è®¾ï¼ŒæŒ‡å‡ºäº†åœ¨ä»£ç†ç³»ç»Ÿä¸­æ­£å¼åŒ–ç›®æ ‡æ—¶å‡ºç°çš„æŠ€æœ¯å’Œæ¦‚å¿µé—®é¢˜ã€‚æˆ‘ä»¬å¾—å‡ºä¸€ä¸ªæˆ–è®¸ä»¤äººæƒŠè®¶çš„ç»“è®ºï¼šç›®æ ‡å¯¼å‘æ€§æ— æ³•å®¢è§‚æµ‹é‡ã€‚æˆ‘ä»¬æ¦‚è¿°äº†å°†ç›®æ ‡å¯¼å‘æ€§å»ºæ¨¡ä¸ºåŠ¨æ€å¤šä»£ç†ç³»ç»Ÿ emergent å±æ€§çš„æ–°æ–¹å‘ã€‚ 

---
# Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray 

**Title (ZH)**: é¢å‘èƒ¸ç‰‡ä¸­è‚ºç»“èŠ‚æ£€æµ‹çš„ä¸ç¡®å®šæ€§awareå­¦ä¹ ç­–ç•¥ 

**Authors**: Hyeonjin Choi, Jinse Kim, Dong-yeon Yoo, Ju-sung Sun, Jung-won Lee  

**Link**: [PDF](https://arxiv.org/pdf/2508.13236)  

**Abstract**: Early detection and rapid intervention of lung cancer are crucial. Nonetheless, ensuring an accurate diagnosis is challenging, as physicians' ability to interpret chest X-rays varies significantly depending on their experience and degree of fatigue. Although medical AI has been rapidly advancing to assist in diagnosis, physicians' trust in such systems remains limited, preventing widespread clinical adoption. This skepticism fundamentally stems from concerns about its diagnostic uncertainty. In clinical diagnosis, physicians utilize extensive background knowledge and clinical experience. In contrast, medical AI primarily relies on repetitive learning of the target lesion to generate diagnoses based solely on that data. In other words, medical AI does not possess sufficient knowledge to render a diagnosis, leading to diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning Policy that can address the issue of knowledge deficiency by learning the physicians' background knowledge alongside the Chest X-ray lesion information. We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a 10% enhancement in sensitivity compared to the baseline model while also decreasing entropy as a measure of uncertainty by 0.2. 

**Abstract (ZH)**: æ—©æœŸæ£€æµ‹ä¸è¿…é€Ÿå¹²é¢„è‚ºç™Œè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç¡®ä¿å‡†ç¡®è¯Šæ–­æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåŒ»ç”Ÿè§£è¯»èƒ¸éƒ¨Xå…‰çš„èƒ½åŠ›å› ç»éªŒç¨‹åº¦å’Œç–²åŠ³ç¨‹åº¦è€Œå¼‚ã€‚å°½ç®¡åŒ»å­¦AIå·²è¿…é€Ÿå‘å±•ä»¥è¾…åŠ©è¯Šæ–­ï¼Œä½†åŒ»ç”Ÿå¯¹å…¶ç³»ç»Ÿçš„ä¿¡ä»»ç¨‹åº¦æœ‰é™ï¼Œé˜»ç¢äº†å…¶åœ¨ä¸´åºŠä¸­çš„å¹¿æ³›åº”ç”¨ã€‚è¿™ç§æ€€ç–‘ä»æ ¹æœ¬ä¸Šæºäºå¯¹è¯Šæ–­ä¸ç¡®å®šæ€§çš„æ‹…å¿§ã€‚åœ¨ä¸´åºŠè¯Šæ–­ä¸­ï¼ŒåŒ»ç”Ÿåˆ©ç”¨å¹¿æ³›çš„èƒŒæ™¯çŸ¥è¯†å’Œä¸´åºŠç»éªŒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŒ»å­¦AIä¸»è¦ä¾é é‡å¤å­¦ä¹ ç›®æ ‡ç—…ç¶æ¥ç”Ÿæˆè¯Šæ–­ï¼Œä»…åŸºäºé‚£ç»„æ•°æ®ã€‚æ¢å¥è¯è¯´ï¼ŒåŒ»å­¦AIç¼ºä¹è¶³å¤Ÿçš„çŸ¥è¯†è¿›è¡Œè¯Šæ–­ï¼Œå¯¼è‡´è¯Šæ–­ä¸ç¡®å®šæ€§ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶æå‡ºä¸€ç§awareness of uncertaintyå­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é€šè¿‡åŒæ—¶å­¦ä¹ åŒ»ç”Ÿçš„èƒŒæ™¯çŸ¥è¯†å’Œèƒ¸éƒ¨Xå…‰ç—…ç¶ä¿¡æ¯ï¼Œä»¥è§£å†³çŸ¥è¯†ä¸è¶³çš„é—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨äº†2,517å¼ æ— ç—…ç¶å›¾åƒå’Œ656å¼ ç»“èŠ‚å›¾åƒï¼Œæ‰€æœ‰æ•°æ®å‡æ¥è‡ª Ajouå¤§å­¦åŒ»é™¢ã€‚æ‰€æå‡ºçš„æ¨¡å‹åœ¨IoUä¸º0.2å’ŒFPPIä¸º2çš„æƒ…å†µä¸‹è¾¾åˆ°äº†92%çš„æ£€æµ‹ç‡ï¼Œä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œçµæ•åº¦æé«˜äº†10%ï¼ŒåŒæ—¶é€šè¿‡å‡å°‘ä¸ç¡®å®šæ€§åº¦é‡ï¼ˆç†µï¼‰0.2æ¥é™ä½ä¸ç¡®å®šæ€§ã€‚ 

---
# The Role of AI in Facilitating Interdisciplinary Collaboration: Evidence from AlphaFold 

**Title (ZH)**: AIåœ¨ä¿ƒè¿›è·¨å­¦ç§‘åˆä½œä¸­çš„ä½œç”¨ï¼šæ¥è‡ªAlphaFoldçš„è¯æ® 

**Authors**: Naixuan Zhao, Chunli Wei, Xinyan Zhang, Jiang Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.13234)  

**Abstract**: The acceleration of artificial intelligence (AI) in science is recognized and many scholars have begun to explore its role in interdisciplinary collaboration. However, the mechanisms and extent of this impact are still unclear. This study, using AlphaFold's impact on structural biologists, examines how AI technologies influence interdisciplinary collaborative patterns. By analyzing 1,247 AlphaFold-related papers and 7,700 authors from Scopus, we employ bibliometric analysis and causal inference to compare interdisciplinary collaboration between AlphaFold adopters and non-adopters. Contrary to the widespread belief that AI facilitates interdisciplinary collaboration, our findings show that AlphaFold increased structural biology-computer science collaborations by just 0.48%, with no measurable effect on other disciplines. Specifically, AI creates interdisciplinary collaboration demands with specific disciplines due to its technical characteristics, but this demand is weakened by technological democratization and other factors. These findings demonstrate that artificial intelligence (AI) alone has limited efficacy in bridging disciplinary divides or fostering meaningful interdisciplinary collaboration. 

**Abstract (ZH)**: äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨ç§‘å­¦ä¸­çš„åŠ é€Ÿåº”ç”¨åŠå…¶å¯¹è·¨å­¦ç§‘åˆä½œçš„å½±å“ï¼šä»¥AlphaFoldä¸ºä¾‹çš„ç ”ç©¶ 

---
# Deep Graph Neural Point Process For Learning Temporal Interactive Networks 

**Title (ZH)**: æ·±åº¦å›¾ç¥ç»ç‚¹è¿‡ç¨‹å­¦ä¹ æ—¶åºäº¤äº’ç½‘ç»œ 

**Authors**: Su Chen, Xiaohua Qi, Xixun Lin, Yanmin Shang, Xiaolin Xu, Yangxi Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.13219)  

**Abstract**: Learning temporal interaction networks(TIN) is previously regarded as a coarse-grained multi-sequence prediction problem, ignoring the network topology structure influence. This paper addresses this limitation and a Deep Graph Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node Aggregation Layer captures topological structures to generate static representation for users and items, while the Self Attentive Layer dynamically updates embeddings over time. By incorporating both dynamic and static embeddings into the event intensity function and optimizing the model via maximum likelihood estimation, DGNPP predicts events and occurrence time effectively. Experimental evaluations on three public datasets demonstrate that DGNPP achieves superior performance in event prediction and time prediction tasks with high efficiency, significantly outperforming baseline models and effectively mitigating the limitations of prior approaches. 

**Abstract (ZH)**: å­¦ä¹ æ—¶åºäº¤äº’ç½‘ç»œï¼ˆTINï¼‰ previouslyè¢«è§†ä¸ºç²—ç²’åº¦çš„å¤šåºåˆ—é¢„æµ‹é—®é¢˜ï¼Œå¿½ç•¥äº†ç½‘ç»œæ‹“æ‰‘ç»“æ„çš„å½±å“ã€‚æœ¬æ–‡è§£å†³äº†è¿™ä¸€å±€é™ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ·±åº¦å›¾ç¥ç»ç‚¹è¿‡ç¨‹ï¼ˆDGNPPï¼‰æ¨¡å‹ç”¨äºTINã€‚DGNPPç”±ä¸¤ä¸ªå…³é”®æ¨¡å—ç»„æˆï¼šèŠ‚ç‚¹èšåˆå±‚å’Œè‡ªæˆ‘æ³¨æ„å±‚ã€‚èŠ‚ç‚¹èšåˆå±‚æ•è·æ‹“æ‰‘ç»“æ„ä»¥ç”Ÿæˆç”¨æˆ·å’Œé¡¹ç›®çš„é™æ€è¡¨ç¤ºï¼Œè€Œè‡ªæˆ‘æ³¨æ„å±‚åˆ™åŠ¨æ€æ›´æ–°æ—¶é—´ä¸Šçš„åµŒå…¥è¡¨ç¤ºã€‚é€šè¿‡å°†åŠ¨æ€å’Œé™æ€åµŒå…¥æ•´åˆåˆ°äº‹ä»¶å¼ºåº¦å‡½æ•°ä¸­ï¼Œå¹¶é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¼˜åŒ–æ¨¡å‹ï¼ŒDGNPPèƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹äº‹ä»¶åŠå…¶å‘ç”Ÿæ—¶é—´ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒDGNPPåœ¨äº‹ä»¶é¢„æµ‹å’Œæ—¶é—´é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ä¸”æ•ˆç‡é«˜ï¼Œæ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œå¹¶æœ‰æ•ˆç¼“è§£äº†å…ˆå‰æ–¹æ³•çš„å±€é™æ€§ã€‚ 

---
# Research on Conversational Recommender System Considering Consumer Types 

**Title (ZH)**: è€ƒè™‘æ¶ˆè´¹è€…ç±»å‹çš„å¯¹è¯æ¨èç³»ç»Ÿç ”ç©¶ 

**Authors**: Yaying Luo, Hui Fang, Zhu Sun  

**Link**: [PDF](https://arxiv.org/pdf/2508.13209)  

**Abstract**: Conversational Recommender Systems (CRS) provide personalized services through multi-turn interactions, yet most existing methods overlook users' heterogeneous decision-making styles and knowledge levels, which constrains both accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer Type-Enhanced Conversational Recommender System), a framework that integrates consumer type modeling into dialogue recommendation. Based on consumer type theory, we define four user categories--dependent, efficient, cautious, and expert--derived from two dimensions: decision-making style (maximizers vs. satisficers) and knowledge level (high vs. low). CT-CRS employs interaction histories and fine-tunes the large language model to automatically infer user types in real time, avoiding reliance on static questionnaires. We incorporate user types into state representation and design a type-adaptive policy that dynamically adjusts recommendation granularity, diversity, and attribute query complexity. To further optimize the dialogue policy, we adopt Inverse Reinforcement Learning (IRL), enabling the agent to approximate expert-like strategies conditioned on consumer type. Experiments on LastFM, Amazon-Book, and Yelp show that CTCRS improves recommendation success rate and reduces interaction turns compared to strong baselines. Ablation studies confirm that both consumer type modeling and IRL contribute significantly to performance gains. These results demonstrate that CT-CRS offers a scalable and interpretable solution for enhancing CRS personalization through the integration of psychological modeling and advanced policy optimization. 

**Abstract (ZH)**: é¢å‘æ¶ˆè´¹è€…ç±»å‹çš„å¯¹è¯æ¨èç³»ç»Ÿï¼ˆCT-CRSï¼‰ï¼šç»“åˆå¿ƒç†å»ºæ¨¡çš„ä¸ªæ€§åŒ–ä¼˜åŒ– 

---
# Utilizing the RAIN method and Graph SAGE Model to Identify Effective Drug Combinations for Gastric Neoplasm Treatment 

**Title (ZH)**: åˆ©ç”¨RAINæ–¹æ³•å’ŒGraph SAGEæ¨¡å‹è¯†åˆ«èƒƒç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤çš„æœ‰æ•ˆè¯ç‰©ç»„åˆ 

**Authors**: S. Z. Pirasteh, Ali A. Kiaei, Mahnaz Bush, Sabra Moghadam, Raha Aghaei, Behnaz Sadeghigol  

**Link**: [PDF](https://arxiv.org/pdf/2508.13207)  

**Abstract**: Background: Gastric neoplasm, primarily adenocarcinoma, is an aggressive cancer with high mortality, often diagnosed late, leading to complications like metastasis. Effective drug combinations are vital to address disease heterogeneity, enhance efficacy, reduce resistance, and improve patient outcomes. Methods: The RAIN method integrated Graph SAGE to propose drug combinations, using a graph model with p-value-weighted edges connecting drugs, genes, and proteins. NLP and systematic literature review (PubMed, Scopus, etc.) validated proposed drugs, followed by network meta-analysis to assess efficacy, implemented in Python. Results: Oxaliplatin, fluorouracil, and trastuzumab were identified as effective, supported by 61 studies. Fluorouracil alone had a p-value of 0.0229, improving to 0.0099 with trastuzumab, and 0.0069 for the triple combination, indicating superior efficacy. Conclusion: The RAIN method, combining AI and network meta-analysis, effectively identifies optimal drug combinations for gastric neoplasm, offering a promising strategy to enhance treatment outcomes and guide health policy. 

**Abstract (ZH)**: èƒŒæ™¯ï¼šèƒƒæ¶æ€§è‚¿ç˜¤ä¸»è¦æ˜¯è…ºç™Œï¼Œæ˜¯ä¸€ç§å…·æœ‰é«˜æ­»äº¡ç‡çš„ä¾µè¢­æ€§ç™Œç—‡ï¼Œå¸¸å¸¸åœ¨æ™šæœŸè¯Šæ–­ï¼Œå¯¼è‡´è½¬ç§»ç­‰å¹¶å‘ç—‡ã€‚æœ‰æ•ˆçš„è¯ç‰©ç»„åˆå¯¹äºåº”å¯¹ç–¾ç—…å¼‚è´¨æ€§ã€å¢å¼ºç–—æ•ˆã€å‡å°‘æŠ—è¯æ€§å¹¶æ”¹å–„æ‚£è€…é¢„åè‡³å…³é‡è¦ã€‚æ–¹æ³•ï¼šRAINæ–¹æ³•ç»“åˆGraph SAGEæå‡ºè¯ç‰©ç»„åˆï¼Œä½¿ç”¨ä¸€ä¸ªè¿æ¥è¯ç‰©ã€åŸºå› å’Œè›‹ç™½è´¨çš„å›¾æ¨¡å‹ï¼Œå¹¶é€šè¿‡på€¼åŠ æƒçš„è¾¹è¿›è¡Œè¿æ¥ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œç³»ç»Ÿæ–‡çŒ®å›é¡¾ï¼ˆPubMedã€Scopusç­‰ï¼‰éªŒè¯æå‡ºçš„è¯ç‰©ï¼Œéšåé€šè¿‡ç½‘ç»œmetaåˆ†æè¯„ä¼°ç–—æ•ˆï¼Œå…¨éƒ¨åœ¨Pythonä¸­å®æ–½ã€‚ç»“æœï¼šå¥¥æ²™åˆ©é“‚ã€æ°Ÿå°¿å˜§å•¶å’Œæ›²å¦¥ç å•æŠ—è¢«è¯†åˆ«ä¸ºæœ‰æ•ˆçš„è¯ç‰©ç»„åˆï¼Œæœ‰61é¡¹ç ”ç©¶æ”¯æŒã€‚å•ç‹¬ä½¿ç”¨æ°Ÿå°¿å˜§å•¶çš„på€¼ä¸º0.0229ï¼ŒåŠ å…¥æ›²å¦¥ç å•æŠ—åé™è‡³0.0099ï¼Œè€Œä¸‰è”ç»„åˆçš„på€¼ä¸º0.0069ï¼Œè¡¨æ˜å…¶æœ‰æ•ˆæ€§æ›´ä¼˜ã€‚ç»“è®ºï¼šRAINæ–¹æ³•ç»“åˆAIå’Œç½‘ç»œmetaåˆ†æï¼Œæœ‰æ•ˆåœ°è¯†åˆ«å‡ºèƒƒæ¶æ€§è‚¿ç˜¤çš„æœ€ä½³è¯ç‰©ç»„åˆï¼Œä¸ºæé«˜æ²»ç–—æ•ˆæœå’ŒæŒ‡å¯¼å«ç”Ÿæ”¿ç­–æä¾›äº†æœ‰å‰æ™¯çš„ç­–ç•¥ã€‚ 

---
# The Rise of Generative AI for Metal-Organic Framework Design and Synthesis 

**Title (ZH)**: é‡‘å±æœ‰æœºæ¡†æ¶è®¾è®¡ä¸åˆæˆä¸­ç”Ÿæˆå¼AIçš„å´›èµ· 

**Authors**: Chenru Duan, Aditya Nandy, Shyam Chand Pal, Xin Yang, Wenhao Gao, Yuanqi Du, Hendrik KraÃŸ, Yeonghun Kang, Varinia Bernales, Zuyang Ye, Tristan Pyle, Ray Yang, Zeqi Gu, Philippe Schwaller, Shengqian Ma, Shijing Sun, AlÃ¡n Aspuru-Guzik, Seyed Mohamad Moosavi, Robert Wexler, Zhiling Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2508.13197)  

**Abstract**: Advances in generative artificial intelligence are transforming how metal-organic frameworks (MOFs) are designed and discovered. This Perspective introduces the shift from laborious enumeration of MOF candidates to generative approaches that can autonomously propose and synthesize in the laboratory new porous reticular structures on demand. We outline the progress of employing deep learning models, such as variational autoencoders, diffusion models, and large language model-based agents, that are fueled by the growing amount of available data from the MOF community and suggest novel crystalline materials designs. These generative tools can be combined with high-throughput computational screening and even automated experiments to form accelerated, closed-loop discovery pipelines. The result is a new paradigm for reticular chemistry in which AI algorithms more efficiently direct the search for high-performance MOF materials for clean air and energy applications. Finally, we highlight remaining challenges such as synthetic feasibility, dataset diversity, and the need for further integration of domain knowledge. 

**Abstract (ZH)**: ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è¿›æ­¥æ­£åœ¨å˜é©é‡‘å±æœ‰æœºæ¡†æ¶ï¼ˆMOFsï¼‰çš„è®¾è®¡ä¸å‘ç°æ–¹å¼ã€‚æœ¬æ–‡æ¦‚è§ˆäº†ä»è€—æ—¶çš„MOFå€™é€‰ç‰©æšä¸¾æ–¹æ³•å‘èƒ½å¤Ÿè‡ªä¸»æå‡ºå¹¶åœ¨å®éªŒå®¤åˆæˆæ–°å¤šå­”éª¨æ¶ç»“æ„çš„æ–¹æ³•çš„è½¬å˜ã€‚æˆ‘ä»¬æ¦‚è¿°äº†åˆ©ç”¨å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿›å±•ï¼Œè¿™äº›æ¨¡å‹å¾—ç›Šäºè¶Šæ¥è¶Šå¤šçš„æ¥è‡ªMOFç¤¾åŒºçš„æ•°æ®ï¼Œå¹¶æå‡ºæ–°å‹æ™¶ä½“ææ–™è®¾è®¡ã€‚è¿™äº›ç”Ÿæˆå·¥å…·å¯ä»¥ä¸é«˜é€šé‡è®¡ç®—ç­›é€‰å’Œè‡ªåŠ¨åŒ–å®éªŒç›¸ç»“åˆï¼Œå½¢æˆåŠ é€Ÿçš„é—­ç¯å‘ç°æµç¨‹ã€‚ç»“æœï¼Œè¿™ä¸ºæ™¶æ€åŒ–å­¦æä¾›äº†ä¸€ä¸ªæ–°çš„èŒƒå¼ï¼Œåœ¨æ­¤èŒƒå¼ä¸­ï¼ŒAIç®—æ³•æ›´æœ‰æ•ˆåœ°æŒ‡å¯¼é«˜æ€§èƒ½MOFææ–™åœ¨æ¸…æ´ç©ºæ°”å’Œèƒ½æºåº”ç”¨ä¸­çš„æœç´¢ã€‚æœ€åï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å‰©ä½™çš„æŒ‘æˆ˜ï¼Œå¦‚åˆæˆå¯è¡Œæ€§ã€æ•°æ®é›†å¤šæ ·æ€§ä»¥åŠéœ€è¦è¿›ä¸€æ­¥æ•´åˆä¸“ä¸šçŸ¥è¯†ã€‚ 

---
# Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis 

**Title (ZH)**: åŸºäºä¸Šä¸‹æ–‡æ³¨æ„åŠ›çš„LLMå’ŒCNNå¤šæ¨¡æ€èåˆæƒ…æ„Ÿåˆ†æ 

**Authors**: Meriem Zerkouk, Miloud Mihoubi, Belkacem Chikhaoui  

**Link**: [PDF](https://arxiv.org/pdf/2508.13196)  

**Abstract**: This paper introduces a novel approach for multimodal sentiment analysis on social media, particularly in the context of natural disasters, where understanding public sentiment is crucial for effective crisis management. Unlike conventional methods that process text and image modalities separately, our approach seamlessly integrates Convolutional Neural Network (CNN) based image analysis with Large Language Model (LLM) based text processing, leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to extract sentiment relevant features from the CrisisMMD dataset. To effectively model intermodal relationships, we introduce a contextual attention mechanism within the fusion process. Leveraging contextual-attention layers, this mechanism effectively captures intermodality interactions, enhancing the model's comprehension of complex relationships between textual and visual data. The deep neural network architecture of our model learns from these fused features, leading to improved accuracy compared to existing baselines. Experimental results demonstrate significant advancements in classifying social media data into informative and noninformative categories across various natural disasters. Our model achieves a notable 2.43% increase in accuracy and 5.18% in F1-score, highlighting its efficacy in processing complex multimodal data. Beyond quantitative metrics, our approach provides deeper insight into the sentiments expressed during crises. The practical implications extend to real time disaster management, where enhanced sentiment analysis can optimize the accuracy of emergency interventions. By bridging the gap between multimodal analysis, LLM powered text understanding, and disaster response, our work presents a promising direction for Artificial Intelligence (AI) driven crisis management solutions. Keywords: 

**Abstract (ZH)**: ä¸€ç§é’ˆå¯¹è‡ªç„¶ç¾å®³æƒ…å¢ƒä¸‹çš„ç¤¾äº¤åª’ä½“å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„æ–°å‹æ–¹æ³•ï¼šåŸºäºä¸Šä¸‹æ–‡æ³¨æ„åŠ›æœºåˆ¶çš„å›¾åƒåˆ†æä¸è¯­è¨€æ¨¡å‹æ–‡æœ¬å¤„ç†èåˆ 

---
# Preference Models assume Proportional Hazards of Utilities 

**Title (ZH)**: åå¥½æ¨¡å‹å‡è®¾æ•ˆç”¨çš„æ¯”ä¾‹å±å®³ã€‚ 

**Authors**: Chirag Nagpal  

**Link**: [PDF](https://arxiv.org/pdf/2508.13189)  

**Abstract**: Approaches for estimating preferences from human annotated data typically involves inducing a distribution over a ranked list of choices such as the Plackett-Luce model. Indeed, modern AI alignment tools such as Reward Modelling and Direct Preference Optimization are based on the statistical assumptions posed by the Plackett-Luce model. In this paper, I will connect the Plackett-Luce model to another classical and well known statistical model, the Cox Proportional Hazards model and attempt to shed some light on the implications of the connection therein. 

**Abstract (ZH)**: åŸºäºäººç±»æ ‡æ³¨æ•°æ®ä¼°è®¡åå¥½æ–¹æ³•é€šå¸¸æ¶‰åŠè¯±å¯¼ä¸€ä¸ªæ’åºé€‰æ‹©åˆ—è¡¨ä¸Šçš„åˆ†å¸ƒï¼Œå¦‚Plackett-Luceæ¨¡å‹ã€‚äº‹å®ä¸Šï¼Œç°ä»£AIå¯¹é½å·¥å…·ï¼Œå¦‚å¥–åŠ±å»ºæ¨¡å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ­£æ˜¯åŸºäºPlackett-Luceæ¨¡å‹çš„ç»Ÿè®¡å‡è®¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†è¿æ¥Plackett-Luceæ¨¡å‹ä¸å¦ä¸€ä¸ªç»å…¸ä¸”å¹¿ä¸ºäººçŸ¥çš„ç»Ÿè®¡æ¨¡å‹â€”â€”Coxæ¯”ä¾‹é£é™©æ¨¡å‹ï¼Œå¹¶å°è¯•æ¢è®¨å…¶ä¸­è¿æ¥çš„å«ä¹‰ã€‚ 

---
# Toward an African Agenda for AI Safety 

**Title (ZH)**: é¢å‘éæ´²çš„AIå®‰å…¨è®®ç¨‹ 

**Authors**: Samuel T. Segun, Rachel Adams, Ana Florido, Scott Timcke, Jonathan Shock, Leah Junck, Fola Adeleke, Nicolas Grossman, Ayantola Alayande, Jerry John Kponyo, Matthew Smith, Dickson Marfo Fosu, Prince Dawson Tetteh, Juliet Arthur, Stephanie Kasaon, Odilile Ayodele, Laetitia Badolo, Paul Plantinga, Michael Gastrow, Sumaya Nur Adan, Joanna Wiaterek, Cecil Abungu, Kojo Apeagyei, Luise Eder, Tegawende Bissyande  

**Link**: [PDF](https://arxiv.org/pdf/2508.13179)  

**Abstract**: This paper maps Africa's distinctive AI risk profile, from deepfake fuelled electoral interference and data colonial dependency to compute scarcity, labour disruption and disproportionate exposure to climate driven environmental costs. While major benefits are promised to accrue, the availability, development and adoption of AI also mean that African people and countries face particular AI safety risks, from large scale labour market disruptions to the nefarious use of AI to manipulate public opinion. To date, African perspectives have not been meaningfully integrated into global debates and processes regarding AI safety, leaving African stakeholders with limited influence over the emerging global AI safety governance agenda. While there are Computer Incident Response Teams on the continent, none hosts a dedicated AI Safety Institute or office. We propose a five-point action plan centred on (i) a policy approach that foregrounds the protection of the human rights of those most vulnerable to experiencing the harmful socio-economic effects of AI; (ii) the establishment of an African AI Safety Institute; (iii) promote public AI literacy and awareness; (iv) development of early warning system with inclusive benchmark suites for 25+ African languages; and (v) an annual AU-level AI Safety & Security Forum. 

**Abstract (ZH)**: è¿™ç¯‡è®ºæ–‡æ˜ å°„äº†éæ´²ç‹¬ç‰¹çš„AIé£é™©ç”»åƒï¼Œä»æ·±åº¦é€ å‡é€‰ä¸¾å¹²é¢„å’Œæ•°æ®æ®–æ°‘ä¾èµ–ï¼Œåˆ°è®¡ç®—èµ„æºç¨€ç¼ºã€åŠ³åŠ¨åŠ›å¸‚åœºæ‰°ä¹±ä»¥åŠå¯¹ç”±æ°”å€™é©±åŠ¨çš„ç¯å¢ƒæˆæœ¬çš„ä¸æˆæ¯”ä¾‹æš´éœ²ã€‚è™½ç„¶AIå¸¦æ¥çš„å¥½å¤„å—åˆ°æœŸå¾…ï¼Œä½†AIçš„å¯ç”¨æ€§ã€å¼€å‘å’Œé‡‡ç”¨ä¹Ÿæ„å‘³ç€éæ´²äººæ°‘å’Œå›½å®¶é¢ä¸´ç‰¹å®šçš„AIå®‰å…¨é£é™©ï¼Œä»å¤§è§„æ¨¡åŠ³åŠ¨åŠ›å¸‚åœºæ‰°ä¹±åˆ°åˆ©ç”¨AI manipulateå…¬å…±æ„è§çš„æ¶æ„è¡Œä¸ºã€‚è¿„ä»Šä¸ºæ­¢ï¼Œéæ´²è§†è§’å°šæœªè¢«æœ‰æ„ä¹‰åœ°çº³å…¥å…³äºAIå®‰å…¨çš„å…¨çƒè¾©è®ºå’Œè¿›ç¨‹ä¸­ï¼Œå¯¼è‡´éæ´²åˆ©ç›Šç›¸å…³è€…åœ¨æ­£åœ¨å½¢æˆçš„å…¨çƒAIå®‰å…¨æ²»ç†è®®ç¨‹ä¸­å½±å“åŠ›æœ‰é™ã€‚è™½ç„¶éæ´²å¤§é™†ä¸Šæœ‰è®¡ç®—æœºåº”æ€¥å“åº”å›¢é˜Ÿï¼Œä½†æ²¡æœ‰ä¸“é—¨çš„AIå®‰å…¨ç ”ç©¶æ‰€æˆ–åŠå…¬å®¤ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªäº”ç‚¹è¡ŒåŠ¨è®¡åˆ’ï¼Œé‡ç‚¹åœ¨äºï¼ˆiï¼‰ä¸€ç§ä»¥ä¿æŠ¤æœ€æ˜“é­å—AIæœ‰å®³ç¤¾ä¼šç»æµå½±å“çš„äººç±»æƒåˆ©ä¸ºä¸­å¿ƒçš„æ”¿ç­–æ–¹æ³•ï¼›ï¼ˆiiï¼‰å»ºç«‹éæ´²AIå®‰å…¨ç ”ç©¶æ‰€ï¼›ï¼ˆiiiï¼‰ä¿ƒè¿›å…¬ä¼—AIç´ å…»å’Œæ„è¯†ï¼›ï¼ˆivï¼‰å¼€å‘é€‚ç”¨äº25ç§ä»¥ä¸Šéæ´²è¯­è¨€çš„æ—©æœŸé¢„è­¦ç³»ç»Ÿå’ŒåŒ…å®¹æ€§åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼›ä»¥åŠï¼ˆvï¼‰æ¯å¹´ä¸¾åŠä¸€æ¬¡éæ´²è”ç›Ÿå±‚é¢çš„AIå®‰å…¨ä¸å®‰å…¨è®ºå›ã€‚ 

---
# Sustainable AI Training via Hardware-Software Co-Design on NVIDIA, AMD, and Emerging GPU Architectures 

**Title (ZH)**: åŸºäº NVIDIAã€AMD åŠæ–°å…´ GPU æ¶æ„çš„ç¡¬ä»¶-è½¯ä»¶ååŒè®¾è®¡å¯æŒç»­ AI è®­ç»ƒ 

**Authors**: Yashasvi Makin, Rahul Maliakkal  

**Link**: [PDF](https://arxiv.org/pdf/2508.13163)  

**Abstract**: In particular, large-scale deep learning and artificial intelligence model training uses a lot of computational power and energy, so it poses serious sustainability issues. The fast rise in model complexity has resulted in exponential increases in energy consumption, increasing the demand for techniques maximizing computational efficiency and lowering environmental impact. This work explores environmentally driven performance optimization methods especially intended for advanced GPU architectures from NVIDIA, AMD, and other emerging GPU architectures. Our main focus is on investigating hardware-software co-design techniques meant to significantly increase memory-level and kernel-level operations, so improving performance-per-watt measures. Our thorough research encompasses evaluations of specialized tensor and matrix cores, advanced memory optimization methods, and creative integration approaches that taken together result in notable energy efficiency increases. We also discuss important software-level optimizations that augment hardware capability including mixed-precision arithmetic, advanced energy-aware scheduling algorithms, and compiler-driven kernel enhancements. Moreover, we methodically point out important research gaps and suggest future directions necessary to create really sustainable artificial intelligence systems. This paper emphasizes how major increases in training efficiency can be obtained by co-design of hardware and software, so lowering the environmental impact of artificial intelligence without compromising performance. To back up our analysis, we use real-world case studies from top companies like Meta, Google, Amazon, and others that show how these sustainable AI training methods are used in the real world. 

**Abstract (ZH)**: å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ å’Œäººå·¥æ™ºèƒ½æ¨¡å‹è®­ç»ƒæ¶ˆè€—å¤§é‡è®¡ç®—èµ„æºå’Œèƒ½æºï¼Œå¯¼è‡´ä¸¥é‡çš„å¯æŒç»­æ€§é—®é¢˜ã€‚æ¨¡å‹å¤æ‚åº¦çš„å¿«é€Ÿæé«˜å¯¼è‡´èƒ½æºæ¶ˆè€—å‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œå¢åŠ äº†æé«˜è®¡ç®—æ•ˆç‡å’Œé™ä½ç¯å¢ƒå½±å“çš„æŠ€æœ¯éœ€æ±‚ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†ç‰¹åˆ«é’ˆå¯¹NVIDIAã€AMDåŠå…¶ä»–æ–°å…´GPUæ¶æ„çš„ç¯å¢ƒé©±åŠ¨å‹æ€§èƒ½ä¼˜åŒ–æ–¹æ³•ï¼Œé‡ç‚¹å…³æ³¨ç¡¬ä»¶-è½¯ä»¶ååŒè®¾è®¡æŠ€æœ¯ä»¥æ˜¾è‘—æé«˜å†…å­˜çº§å’Œå†…æ ¸çº§æ“ä½œï¼Œä»è€Œæå‡å•ä½ç“¦ç‰¹æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ·±å…¥ç ”ç©¶æ¶µç›–äº†ä¸“ç”¨å¼ é‡å’ŒçŸ©é˜µæ ¸çš„è¯„ä¼°ã€é«˜çº§å†…å­˜ä¼˜åŒ–æ–¹æ³•ä»¥åŠåˆ›æ–°çš„é›†æˆæ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ç»“åˆèµ·æ¥èƒ½å¤Ÿæ˜¾è‘—æé«˜èƒ½æ•ˆã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†åœ¨ç¡¬ä»¶èƒ½åŠ›åŸºç¡€ä¸Šçš„è½¯ä»¶çº§ä¼˜åŒ–æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ··åˆç²¾åº¦ç®—æœ¯ã€é«˜çº§èƒ½æ•ˆè°ƒåº¦ç®—æ³•å’Œç¼–è¯‘å™¨é©±åŠ¨çš„å†…æ ¸å¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°æŒ‡å‡ºç°æœ‰ç ”ç©¶ä¸­çš„é‡è¦ç©ºç™½ï¼Œå¹¶å»ºè®®æœªæ¥å‘å±•æ–¹å‘ï¼Œä»¥åˆ›å»ºçœŸæ­£å¯æŒç»­çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚æœ¬æ–‡å¼ºè°ƒäº†é€šè¿‡ç¡¬ä»¶å’Œè½¯ä»¶ååŒè®¾è®¡ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹é™ä½äººå·¥æ™ºèƒ½çš„ç¯å¢ƒå½±å“ï¼Œä»è€Œè·å¾—å¤§å¹…æé«˜è®­ç»ƒæ•ˆç‡çš„æ–¹å¼ã€‚ä¸ºäº†æ”¯æŒæˆ‘ä»¬çš„åˆ†æï¼Œæˆ‘ä»¬ä½¿ç”¨æ¥è‡ªMetaã€Googleã€Amazonç­‰é¡¶çº§å…¬å¸çš„å®é™…æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†è¿™äº›å¯æŒç»­çš„AIè®­ç»ƒæ–¹æ³•åœ¨å®é™…ä¸­çš„åº”ç”¨ã€‚ 

---
# Piano: A Multi-Constraint Pin Assignment-Aware Floorplanner 

**Title (ZH)**: é’¢ç´ï¼šä¸€ç§å¤šçº¦æŸé’ˆè„šåˆ†é…æ„ŸçŸ¥çš„å¸ƒå±€è§„åˆ’å™¨ 

**Authors**: Zhexuan Xu, Kexin Zhou, Jie Wang, Zijie Geng, Siyuan Xu, Shixiong Kai, Mingxuan Yuan, Feng Wu  

**Link**: [PDF](https://arxiv.org/pdf/2508.13161)  

**Abstract**: Floorplanning is a critical step in VLSI physical design, increasingly complicated by modern constraints such as fixed-outline requirements, whitespace removal, and the presence of pre-placed modules. In addition, the assignment of pins on module boundaries significantly impacts the performance of subsequent stages, including detailed placement and routing. However, traditional floorplanners often overlook pin assignment with modern constraints during the floorplanning stage. In this work, we introduce Piano, a floorplanning framework that simultaneously optimizes module placement and pin assignment under multiple constraints. Specifically, we construct a graph based on the geometric relationships among modules and their netlist connections, then iteratively search for shortest paths to determine pin assignments. This graph-based method also enables accurate evaluation of feedthrough and unplaced pins, thereby guiding overall layout quality. To further improve the design, we adopt a whitespace removal strategy and employ three local optimizers to enhance layout metrics under multi-constraint scenarios. Experimental results on widely used benchmark circuits demonstrate that Piano achieves an average 6.81% reduction in HPWL, a 13.39% decrease in feedthrough wirelength, a 16.36% reduction in the number of feedthrough modules, and a 21.21% drop in unplaced pins, while maintaining zero whitespace. 

**Abstract (ZH)**: åŸºäºå¤šçº¦æŸæ¡ä»¶ä¸‹çš„æ¨¡å—æ”¾ç½®ä¸å¼•è„šåˆ†é…ä¼˜åŒ–æ¡†æ¶Piano 

---
# Image2Net: Datasets, Benchmark and Hybrid Framework to Convert Analog Circuit Diagrams into Netlists 

**Title (ZH)**: Image2Net: æ•°æ®é›†ã€åŸºå‡†å’Œæ··åˆæ¡†æ¶ï¼Œç”¨äºå°†æ¨¡æ‹Ÿç”µè·¯å›¾è½¬æ¢ä¸ºç½‘è¡¨ 

**Authors**: Haohang Xu, Chengjie Liu, Qihang Wang, Wenhao Huang, Yongjian Xu, Weiyu Chen, Anlan Peng, Zhijun Li, Bo Li, Lei Qi, Jun Yang, Yuan Du, Li Du  

**Link**: [PDF](https://arxiv.org/pdf/2508.13157)  

**Abstract**: Large Language Model (LLM) exhibits great potential in designing of analog integrated circuits (IC) because of its excellence in abstraction and generalization for knowledge. However, further development of LLM-based analog ICs heavily relies on textual description of analog ICs, while existing analog ICs are mostly illustrated in image-based circuit diagrams rather than text-based netlists. Converting circuit diagrams to netlists help LLMs to enrich the knowledge of analog IC. Nevertheless, previously proposed conversion frameworks face challenges in further application because of limited support of image styles and circuit elements. Up to now, it still remains a challenging task to effectively convert complex circuit diagrams into netlists. To this end, this paper constructs and opensources a new dataset with rich styles of circuit diagrams as well as balanced distribution of simple and complex analog ICs. And a hybrid framework, named Image2Net, is proposed for practical conversion from circuit diagrams to netlists. The netlist edit distance (NED) is also introduced to precisely assess the difference between the converted netlists and ground truth. Based on our benchmark, Image2Net achieves 80.77\% successful rate, which is 34.62\%-45.19\% higher than previous works. Specifically, the proposed work shows 0.116 averaged NED, which is 62.1\%-69.6\% lower than state-of-the-arts. 

**Abstract (ZH)**: åŸºäºå›¾åƒåˆ°ç½‘è¡¨è½¬æ¢çš„æ–°æ•°æ®é›†åŠImage2Netæ··åˆæ¡†æ¶ï¼šå¤æ‚ç”µè·¯å›¾åˆ°ç½‘è¡¨çš„æœ‰æ•ˆè½¬æ¢ 

---
# Preliminary suggestions for rigorous GPAI model evaluations 

**Title (ZH)**: åˆæ­¥å»ºè®®ï¼šä¸¥æ ¼çš„GPAIæ¨¡å‹è¯„ä¼° 

**Authors**: Patricia Paskov, Michael J. Byun, Kevin Wei, Toby Webster  

**Link**: [PDF](https://arxiv.org/pdf/2508.00875)  

**Abstract**: This document presents a preliminary compilation of general-purpose AI (GPAI) evaluation practices that may promote internal validity, external validity and reproducibility. It includes suggestions for human uplift studies and benchmark evaluations, as well as cross-cutting suggestions that may apply to many different evaluation types. Suggestions are organised across four stages in the evaluation life cycle: design, implementation, execution and documentation. Drawing from established practices in machine learning, statistics, psychology, economics, biology and other fields recognised to have important lessons for AI evaluation, these suggestions seek to contribute to the conversation on the nascent and evolving field of the science of GPAI evaluations. The intended audience of this document includes providers of GPAI models presenting systemic risk (GPAISR), for whom the EU AI Act lays out specific evaluation requirements; third-party evaluators; policymakers assessing the rigour of evaluations; and academic researchers developing or conducting GPAI evaluations. 

**Abstract (ZH)**: æœ¬æ–‡æ¡£æå‡ºäº†ä¿ƒè¿›ä¸€èˆ¬ç”¨é€”äººå·¥æ™ºèƒ½ï¼ˆGPAIï¼‰å†…éƒ¨æœ‰æ•ˆæ€§ã€å¤–éƒ¨æœ‰æ•ˆæ€§å’Œå¯å†ç°æ€§çš„åˆæ­¥ç»¼åˆè¯„ä»·å®è·µã€‚å®ƒåŒ…æ‹¬äººç±»æå‡ç ”ç©¶å’ŒåŸºå‡†è¯„ä¼°çš„å»ºè®®ï¼Œä»¥åŠå¯åº”ç”¨äºå¤šç§è¯„ä»·ç±»å‹çš„è·¨å­¦ç§‘å»ºè®®ã€‚è¿™äº›å»ºè®®æŒ‰ç…§è¯„ä»·ç”Ÿå‘½å‘¨æœŸçš„å››ä¸ªé˜¶æ®µï¼ˆè®¾è®¡ã€å®æ–½ã€æ‰§è¡Œå’Œæ–‡æ¡£ï¼‰è¿›è¡Œç»„ç»‡ã€‚æœ¬æ–‡æ¡£å€Ÿé‰´äº†æœºå™¨å­¦ä¹ ã€ç»Ÿè®¡å­¦ã€å¿ƒç†å­¦ã€ç»æµå­¦ã€ç”Ÿç‰©å­¦åŠå…¶ä»–é¢†åŸŸå…¬è®¤å…·æœ‰é‡è¦è¯„ä»·æ•™è®­çš„å®è·µï¼Œæ—¨åœ¨ä¸ºæ–°å…´ä¸”ä¸æ–­å‘å±•ä¸­çš„GPAIè¯„ä»·ç§‘å­¦é¢†åŸŸçš„è®¨è®ºåšå‡ºè´¡çŒ®ã€‚æœ¬æ–‡æ¡£çš„é¢„æœŸè¯»è€…åŒ…æ‹¬æä¾›å¯èƒ½äº§ç”Ÿç³»ç»Ÿæ€§é£é™©çš„ä¸€èˆ¬ç”¨é€”äººå·¥æ™ºèƒ½ï¼ˆGPAIï¼‰æ¨¡å‹çš„ä¾›åº”å•†ï¼ˆæ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆä¸ºæ­¤ç±»ä¾›åº”å•†åˆ—å‡ºäº†å…·ä½“è¯„ä»·è¦æ±‚ï¼‰ã€ç¬¬ä¸‰æ–¹è¯„ä»·è€…ã€è¯„ä¼°è¯„ä»·ä¸¥è°¨æ€§çš„æ”¿ç­–åˆ¶å®šè€…ä»¥åŠè¿›è¡Œæˆ–å¼€å‘GPAIè¯„ä»·çš„å­¦æœ¯ç ”ç©¶äººå‘˜ã€‚ 

---
