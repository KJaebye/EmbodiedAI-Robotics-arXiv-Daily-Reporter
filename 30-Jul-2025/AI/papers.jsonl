{'arxiv_id': 'arXiv:2507.22047', 'title': 'The Interspeech 2025 Speech Accessibility Project Challenge', 'authors': 'Xiuwen Zheng, Bornali Phukon, Jonghwan Na, Ed Cutrell, Kyu Han, Mark Hasegawa-Johnson, Pan-Pan Jiang, Aadhrik Kuila, Colin Lea, Bob MacDonald, Gautam Mantena, Venkatesh Ravichandran, Leda Sari, Katrin Tomanek, Chang D. Yoo, Chris Zwilling', 'link': 'https://arxiv.org/abs/2507.22047', 'abstract': 'While the last decade has witnessed significant advancements in Automatic Speech Recognition (ASR) systems, performance of these systems for individuals with speech disabilities remains inadequate, partly due to limited public training data. To bridge this gap, the 2025 Interspeech Speech Accessibility Project (SAP) Challenge was launched, utilizing over 400 hours of SAP data collected and transcribed from more than 500 individuals with diverse speech disabilities. Hosted on EvalAI and leveraging the remote evaluation pipeline, the SAP Challenge evaluates submissions based on Word Error Rate and Semantic Score. Consequently, 12 out of 22 valid teams outperformed the whisper-large-v2 baseline in terms of WER, while 17 teams surpassed the baseline on SemScore. Notably, the top team achieved the lowest WER of 8.11\\%, and the highest SemScore of 88.44\\% at the same time, setting new benchmarks for future ASR systems in recognizing impaired speech.', 'abstract_zh': '自动语音识别系统在言语障碍个体中的性能仍不足：2025年Interspeech言语 accessibility项目挑战赛进展', 'title_zh': 'Interspeech 2025 语音Accessibility项目挑战'}
{'arxiv_id': 'arXiv:2507.22034', 'title': 'UserBench: An Interactive Gym Environment for User-Centric Agents', 'authors': 'Cheng Qian, Zuxin Liu, Akshara Prabhakar, Zhiwei Liu, Jianguo Zhang, Haolin Chen, Heng Ji, Weiran Yao, Shelby Heinecke, Silvio Savarese, Caiming Xiong, Huan Wang', 'link': 'https://arxiv.org/abs/2507.22034', 'abstract': 'Large Language Models (LLMs)-based agents have made impressive progress in reasoning and tool use, enabling them to solve complex tasks. However, their ability to proactively collaborate with users, especially when goals are vague, evolving, or indirectly expressed, remains underexplored. To address this gap, we introduce UserBench, a user-centric benchmark designed to evaluate agents in multi-turn, preference-driven interactions. UserBench features simulated users who start with underspecified goals and reveal preferences incrementally, requiring agents to proactively clarify intent and make grounded decisions with tools. Our evaluation of leading open- and closed-source LLMs reveals a significant disconnect between task completion and user alignment. For instance, models provide answers that fully align with all user intents only 20% of the time on average, and even the most advanced models uncover fewer than 30% of all user preferences through active interaction. These results highlight the challenges of building agents that are not just capable task executors, but true collaborative partners. UserBench offers an interactive environment to measure and advance this critical capability.', 'abstract_zh': '基于大型语言模型的代理在推理和工具使用方面取得了显著进展，使它们能够解决复杂任务。然而，在目标模糊、不断演变或间接表达的情况下，它们与用户主动合作的能力仍未充分探索。为解决这一问题，我们引入了UserBench，这是一个以用户为中心的基准测试，旨在评估多轮、基于偏好的交互中的代理性能。UserBench包含模拟用户，这些用户初始时目标不明确，并逐步揭示偏好，要求代理主动澄清意图并利用工具进行基于实际情况的决策。我们对领先开源和闭源大型语言模型的评估表明，在任务完成和用户对齐之间存在显著差距。例如，模型提供的答案仅在平均20%的情况下完全符合所有用户意图，即使是最先进的模型，通过积极互动也仅能识别出所有用户偏好中的不到30%。这些结果突显了构建不仅是高效任务执行者，而是真正协作伙伴的代理所面临的挑战。UserBench提供了一个互动环境来衡量和推动这一关键能力。', 'title_zh': '用户基准：以用户为中心代理的交互式 gym 环境'}
{'arxiv_id': 'arXiv:2507.22025', 'title': 'UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding', 'authors': 'Shuquan Lian, Yuhang Wu, Jia Ma, Zihan Song, Bingqi Chen, Xiawu Zheng, Hui Li', 'link': 'https://arxiv.org/abs/2507.22025', 'abstract': 'The emergence of Multimodal Large Language Models (MLLMs) has driven significant advances in Graphical User Interface (GUI) agent capabilities. Nevertheless, existing GUI agent training and inference techniques still suffer from a dilemma for reasoning designs, ineffective reward, and visual noise. To address these issues, we introduce UI-AGILE, a comprehensive framework enhancing GUI agents at both the training and inference stages. For training, we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process: 1) a Continuous Reward function to incentivize high-precision grounding; 2) a "Simple Thinking" reward to balance planning with speed and grounding accuracy; and 3) a Cropping-based Resampling strategy to mitigate the sparse reward problem and improve learning on complex tasks. For inference, we present Decomposed Grounding with Selection, a novel method that dramatically improves grounding accuracy on high-resolution displays by breaking the image into smaller, manageable parts. Experiments show that UI-AGILE achieves the state-of-the-art performance on two benchmarks ScreenSpot-Pro and ScreenSpot-v2. For instance, using both our proposed training and inference enhancement methods brings 23% grounding accuracy improvement over the best baseline on ScreenSpot-Pro.', 'abstract_zh': '多模态大型语言模型的涌现推动了图形用户界面代理能力的重要进步。尽管如此，现有的图形用户界面代理训练和推理技术仍面临推理设计难题、无效奖励和视觉噪声的困境。为解决这些问题，我们引入了UI-AGILE，这是一个综合框架，旨在提高图形用户界面代理在训练和推理阶段的能力。在训练阶段，我们提出了一系列对监督微调（SFT）过程的改进：1）连续奖励函数，以激励高精度定位；2）“简单思考”奖励，以平衡规划速度与定位准确性；3）基于裁剪的重采样策略，以缓解稀疏奖励问题并提高复杂任务的学习效果。在推理阶段，我们提出了一种分解定位加选择的新方法，通过将图像分解成更小、更易管理的部分，显著提高了高分辨率显示器上的定位准确性。实验结果显示，UI-AGILE在ScreenSpot-Pro和ScreenSpot-v2两个基准测试中达到了最先进的性能。例如，使用我们提出的所有训练和推理增强方法，在ScreenSpot-Pro上实现了23%的定位准确性改进。', 'title_zh': 'UI-AGILE：基于有效的强化学习和精确的推理时Grounding提升GUI代理'}
{'arxiv_id': 'arXiv:2507.22009', 'title': 'PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences', 'authors': 'Bahar İlgen, Akshat Dubey, Georges Hattab', 'link': 'https://arxiv.org/abs/2507.22009', 'abstract': 'Ensuring transparency and trust in AI-driven public health and biomedical sciences systems requires more than accurate predictions-it demands explanations that are clear, contextual, and socially accountable. While explainable AI (XAI) has advanced in areas like feature attribution and model interpretability, most methods still lack the structure and adaptability needed for diverse health stakeholders, including clinicians, policymakers, and the general public. We introduce PHAX-a Public Health Argumentation and eXplainability framework-that leverages structured argumentation to generate human-centered explanations for AI outputs. PHAX is a multi-layer architecture combining defeasible reasoning, adaptive natural language techniques, and user modeling to produce context-aware, audience-specific justifications. More specifically, we show how argumentation enhances explainability by supporting AI-driven decision-making, justifying recommendations, and enabling interactive dialogues across user types. We demonstrate the applicability of PHAX through use cases such as medical term simplification, patient-clinician communication, and policy justification. In particular, we show how simplification decisions can be modeled as argument chains and personalized based on user expertise-enhancing both interpretability and trust. By aligning formal reasoning methods with communicative demands, PHAX contributes to a broader vision of transparent, human-centered AI in public health.', 'abstract_zh': '确保人工智能驱动的公共卫生和生物医学科学系统中的透明度和信任不仅需要准确的预测，还需要清晰、语境相关且社会责任导向的解释。尽管可解释人工智能（XAI）在特征归因和模型可解释性方面取得了进展，但大多数方法仍缺乏为包括临床医生、政策制定者和普通公众在内的多元化健康利益相关者提供结构化和适应性的能力。我们引入了PHAX——公共卫生论辩与可解释性框架，利用结构化论辩生成以人为中心的AI输出解释。PHAX是一种多层架构，结合了可败论推理、自适应自然语言技术和用户建模，以产生上下文相关的、针对特定受众的理由。具体而言，我们展示了论辩如何通过支持基于AI的决策、对建议进行辩护以及在不同类型用户之间启用互动对话，来增强解释性。我们通过医疗术语简化、患者-临床医生沟通和政策辩护等用例，展示了PHAX的应用性。特别是，我们展示了如何将简化决策建模为论证链，并基于用户专长进行个性化，从而同时增强解释性和信任。通过将形式推理方法与沟通需求相结合，PHAX为公共卫生领域的透明、以人为中心的人工智能贡献了更广泛的观点。', 'title_zh': 'PHAX：面向用户的公共卫生和生物医学科学解释型人工智能的结构化论辩框架'}
{'arxiv_id': 'arXiv:2507.21976', 'title': 'The Effect of Compression Techniques on Large Multimodal Language Models in the Medical Domain', 'authors': 'Tanvir Ahmed Khan, Aranya Saha, Ismam Nur Swapnil, Mohammad Ariful Haque', 'link': 'https://arxiv.org/abs/2507.21976', 'abstract': 'Multimodal Large Language Models (MLLMs) hold huge potential for usage in the medical domain, but their computational costs necessitate efficient compression techniques. This paper evaluates the impact of structural pruning and activation-aware quantization on a fine-tuned LLAVA model for medical applications. We propose a novel layer selection method for pruning, analyze different quantization techniques, and assess the performance trade-offs in a prune-SFT-quantize pipeline. Our proposed method enables MLLMs with 7B parameters to run within 4 GB of VRAM, reducing memory usage by 70% while achieving 4% higher model performance compared to traditional pruning and quantization techniques in the same compression ratio.', 'abstract_zh': '多模态大型语言模型（MLLMs）在医疗领域的应用具有巨大潜力，但其计算成本需要高效的压缩技术。本文评估了结构剪枝和激活感知量化对 fine-tuned LLAVA 模型在医疗应用中的影响。我们提出了一种新颖的层选择方法进行剪枝，分析了不同的量化技术，并在剪枝-微调-量化流水线中评估了性能trade-offs。本文提出的方法使具有7B参数的MLLMs能够在4 GB VRAM 内运行，与传统剪枝和量化技术相比，在相同的压缩比下，内存使用减少了70%，同时模型性能提高了4%。', 'title_zh': '压缩技术对医疗领域大型多模态语言模型的影响'}
{'arxiv_id': 'arXiv:2507.21974', 'title': 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks', 'authors': 'Mohamed Sana, Nicola Piovesan, Antonio De Domenico, Yibin Kang, Haozhe Zhang, Merouane Debbah, Fadhel Ayed', 'link': 'https://arxiv.org/abs/2507.21974', 'abstract': 'Root Cause Analysis (RCA) in mobile networks remains a challenging task due to the need for interpretability, domain expertise, and causal reasoning. In this work, we propose a lightweight framework that leverages Large Language Models (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of annotated troubleshooting problems designed to benchmark RCA capabilities. Our evaluation reveals that existing open-source reasoning LLMs struggle with these problems, underscoring the need for domain-specific adaptation. To address this issue, we propose a two-stage training methodology that combines supervised fine-tuning with reinforcement learning to improve the accuracy and reasoning quality of LLMs. The proposed approach fine-tunes a series of RCA models to integrate domain knowledge and generate structured, multi-step diagnostic explanations, improving both interpretability and effectiveness. Extensive experiments across multiple LLM sizes show significant performance gains over state-of-the-art reasoning and non-reasoning models, including strong generalization to randomized test variants. These results demonstrate the promise of domain-adapted, reasoning-enhanced LLMs for practical and explainable RCA in network operation and management.', 'abstract_zh': '基于大型语言模型的移动网络根因分析轻量级框架', 'title_zh': '5G无线网络根因分析的语言模型推理'}
{'arxiv_id': 'arXiv:2507.21964', 'title': 'Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities', 'authors': 'Sourish Gunesh Dhekane, Thomas Ploetz', 'link': 'https://arxiv.org/abs/2507.21964', 'abstract': "Developing zero-shot human activity recognition (HAR) methods is a critical direction in smart home research -- considering its impact on making HAR systems work across smart homes having diverse sensing modalities, layouts, and activities of interest. The state-of-the-art solutions along this direction are based on generating natural language descriptions of the sensor data and feeding it via a carefully crafted prompt to the LLM to perform classification. Despite their performance guarantees, such ``prompt-the-LLM'' approaches carry several risks, including privacy invasion, reliance on an external service, and inconsistent predictions due to version changes, making a case for alternative zero-shot HAR methods that do not require prompting the LLMs. In this paper, we propose one such solution that models sensor data and activities using natural language, leveraging its embeddings to perform zero-shot classification and thereby bypassing the need to prompt the LLMs for activity predictions. The impact of our work lies in presenting a detailed case study on six datasets, highlighting how language modeling can bolster HAR systems in zero-shot recognition.", 'abstract_zh': '开发零样本人类活动识别方法是智能家居研究的一个关键方向——考虑其对跨具有不同传感模态、布局和兴趣活动的智能家居系统工作的影响。当前这一方向上的先进解决方案基于生成传感器数据的自然语言描述，并通过精心构造的提示将这些描述传递给大型语言模型以执行分类。尽管这些方法有一定的性能保证，但诸如“提示大型语言模型”的方法仍存在隐私泄露、依赖外部服务及因版本变化导致预测不一致等风险，因此需要寻找不需要提示大型语言模型的零样本人类活动识别方法。在本文中，我们提出了一种解决方案，通过自然语言建模传感器数据和活动，并利用其嵌入进行零样本分类，从而避免了为活动预测而提示大型语言模型的需要。我们的工作影响在于对六个数据集进行了详细的案例研究，展示了语言建模如何增强零样本识别中的智能家居系统。', 'title_zh': '不得提示：通过传感器数据和活动的语言建模在智能家居中实现零样本人体活动识别'}
{'arxiv_id': 'arXiv:2507.21929', 'title': 'Libra: Large Chinese-based Safeguard for AI Content', 'authors': 'Ziyang Chen, Huimu Yu, Xing Wu, Dongqin Liu, Songlin Hu', 'link': 'https://arxiv.org/abs/2507.21929', 'abstract': 'Large language models (LLMs) excel in text understanding and generation but raise significant safety and ethical concerns in high-stakes applications. To mitigate these risks, we present Libra-Guard, a cutting-edge safeguard system designed to enhance the safety of Chinese-based LLMs. Leveraging a two-stage curriculum training pipeline, Libra-Guard enhances data efficiency by employing guard pretraining on synthetic samples, followed by fine-tuning on high-quality, real-world data, thereby significantly reducing reliance on manual annotations. To enable rigorous safety evaluations, we also introduce Libra-Test, the first benchmark specifically designed to evaluate the effectiveness of safeguard systems for Chinese content. It covers seven critical harm scenarios and includes over 5,700 samples annotated by domain experts. Experiments show that Libra-Guard achieves 86.79% accuracy, outperforming Qwen2.5-14B-Instruct (74.33%) and ShieldLM-Qwen-14B-Chat (65.69%), and nearing closed-source models like Claude-3.5-Sonnet and GPT-4o. These contributions establish a robust framework for advancing the safety governance of Chinese LLMs and represent a tentative step toward developing safer, more reliable Chinese AI systems.', 'abstract_zh': '大型语言模型（LLMs）在文本理解和生成方面表现出色，但在高风险应用中引发了重大安全和伦理关切。为减轻这些风险，我们提出Libra-Guard，一种先进防护系统，旨在提升基于中文的LLMs的安全性。Libra-Guard利用两阶段课程训练管道，通过在合成样本上进行防护预训练，然后在高质量的真实世界数据上进行微调，从而显著减少对人工标注的依赖。为了进行严格的安全性评估，我们还引入了Libra-Test，这是首个专门用于评估防护系统效果的基准测试，涵盖七大关键危害场景，并包含超过5,700个由领域专家标注的样本。实验结果显示，Libra-Guard的准确性达到86.79%，优于Qwen2.5-14B-Instruct（74.33%）和ShieldLM-Qwen-14B-Chat（65.69%），接近于像Claude-3.5-Sonnet和GPT-4o这样的闭源模型。这些贡献为推动中文LLMs的安全治理建立了一个坚实框架，并代表了朝着开发更安全、更可靠中文AI系统迈出的一小步。', 'title_zh': '.Libra：基于中文的大规模AI内容保护方法'}
{'arxiv_id': 'arXiv:2507.21899', 'title': 'LLM-based Content Classification Approach for GitHub Repositories by the README Files', 'authors': 'Malik Uzair Mehmood, Shahid Hussain, Wen Li Wang, Muhammad Usama Malik', 'link': 'https://arxiv.org/abs/2507.21899', 'abstract': "GitHub is the world's most popular platform for storing, sharing, and managing code. Every GitHub repository has a README file associated with it. The README files should contain project-related information as per the recommendations of GitHub to support the usage and improvement of repositories. However, GitHub repository owners sometimes neglected these recommendations. This prevents a GitHub repository from reaching its full potential. This research posits that the comprehensiveness of a GitHub repository's README file significantly influences its adoption and utilization, with a lack of detail potentially hindering its full potential for widespread engagement and impact within the research community. Large Language Models (LLMs) have shown great performance in many text-based tasks including text classification, text generation, text summarization and text translation. In this study, an approach is developed to fine-tune LLMs for automatically classifying different sections of GitHub README files. Three encoder-only LLMs are utilized, including BERT, DistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a gold-standard dataset consisting of 4226 README file sections. This approach outperforms current state-of-the-art methods and has achieved an overall F1 score of 0.98. Moreover, we have also investigated the use of Parameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation (LoRA) and shown an economical alternative to full fine-tuning without compromising much performance. The results demonstrate the potential of using LLMs in designing an automatic classifier for categorizing the content of GitHub README files. Consequently, this study contributes to the development of automated tools for GitHub repositories to improve their identifications and potential usages.", 'abstract_zh': 'GitHub是全球最受欢迎的代码存储、共享和管理平台。每个GitHub仓库都关联有一个README文件。README文件应包含与GitHub推荐相符的项目相关信息，以支持仓库的使用和改进。然而，有时GitHub仓库所有者会忽略这些推荐。这阻碍了仓库充分发挥其潜力。本文假定GitHub仓库README文件的全面性显著影响其采用和利用率，缺乏细节可能会阻碍其广泛参与和在研究社区中的影响。大规模语言模型（LLMs）在许多基于文本的任务中表现出色，包括文本分类、文本生成、文本摘要和文本翻译。本研究开发了一种方法，将LLMs微调以自动分类GitHub README文件的不同部分。利用了三个仅编码器的LLMs，包括BERT、DistilBERT和RoBERTa。这些预训练模型基于包含4226个README文件部分的黄金标准数据集进行了微调。该方法在当前最先进的方法中表现出色，实现了整体F1分数为0.98。此外，我们还探讨了使用参数高效微调（PEFT）技术，如低秩适应（LoRA），展示了在不牺牲太多性能的情况下，一种经济的全微调替代方案。结果表明，使用LLMs设计自动分类GitHub README文件内容的分类器的潜力。因此，本研究为GitHub仓库开发自动工具的改进奠定了基础，以提高其识别和潜在用途。', 'title_zh': '基于LLM的内容分类方法：基于GitHub仓库README文件的分类方法'}
{'arxiv_id': 'arXiv:2507.21886', 'title': 'Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline', 'authors': 'Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2507.21886', 'abstract': "Pain is a complex condition affecting a large portion of the population. Accurate and consistent evaluation is essential for individuals experiencing pain, and it supports the development of effective and advanced management strategies. Automatic pain assessment systems provide continuous monitoring and support clinical decision-making, aiming to reduce distress and prevent functional decline. This study has been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline that leverages respiration as the input signal and incorporates a highly efficient cross-attention transformer alongside a multi-windowing strategy. Extensive experiments demonstrate that respiration is a valuable physiological modality for pain assessment. Moreover, experiments revealed that compact and efficient models, when properly optimized, can achieve strong performance, often surpassing larger counterparts. The proposed multi-window approach effectively captures both short-term and long-term features, as well as global characteristics, thereby enhancing the model's representational capacity.", 'abstract_zh': '疼痛是一种影响大量人群的复杂状况。准确且一致的评估对经历疼痛的个体至关重要，有助于开发有效的管理和治疗策略。自动疼痛评估系统提供连续监测并支持临床决策，旨在减轻痛苦并防止功能衰退。本研究已提交至“第二代多模态传感 Grand 挑战赛——下一代疼痛评估（AI4PAIN）”。所提出的方法利用呼吸作为输入信号，并结合了高效率的交叉注意力变换器和多窗口策略。广泛实验表明，呼吸是一种有价值的生理模态用于疼痛评估。此外，实验显示，当适当优化时，紧凑且高效的模型可以达到很强的性能，往往超过较大的模型。所提出的方法窗口策略有效地捕捉了短期、长期特征以及全局特征，从而增强了模型的表征能力。', 'title_zh': '基于呼吸信号的高效疼痛识别：一种单跨注意力变换器多窗融合管道'}
{'arxiv_id': 'arXiv:2507.21882', 'title': 'The Impact of Foundational Models on Patient-Centric e-Health Systems', 'authors': 'Elmira Onagh, Alireza Davoodi, Maleknaz Nayebi', 'link': 'https://arxiv.org/abs/2507.21882', 'abstract': 'As Artificial Intelligence (AI) becomes increasingly embedded in healthcare technologies, understanding the maturity of AI in patient-centric applications is critical for evaluating its trustworthiness, transparency, and real-world impact. In this study, we investigate the integration and maturity of AI feature integration in 116 patient-centric healthcare applications. Using Large Language Models (LLMs), we extracted key functional features, which are then categorized into different stages of the Gartner AI maturity model. Our results show that over 86.21\\% of applications remain at the early stages of AI integration, while only 13.79% demonstrate advanced AI integration.', 'abstract_zh': '随着人工智能（AI）在医疗技术中越来越普及，了解AI在以患者为中心的应用中的成熟度对于评估其可信度、透明度和实际影响至关重要。本研究调查了116个以患者为中心的医疗应用中AI功能集成的整合与成熟度。通过大型语言模型（LLMs），我们提取了关键功能特征，并将其分类为盖特纳人工智能成熟度模型的不同阶段。研究结果显示，超过86.21%的应用仍处于AI集成的早期阶段，仅13.79%的应用展现出先进的AI集成水平。', 'title_zh': '基础模型对以患者为中心的电子健康系统的影响'}
{'arxiv_id': 'arXiv:2507.21881', 'title': 'Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image', 'authors': 'Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2507.21881', 'abstract': "Pain is a multifaceted phenomenon that affects a substantial portion of the population. Reliable and consistent evaluation benefits those experiencing pain and underpins the development of effective and advanced management strategies. Automatic pain-assessment systems deliver continuous monitoring, inform clinical decision-making, and aim to reduce distress while preventing functional decline. By incorporating physiological signals, these systems provide objective, accurate insights into an individual's condition. This study has been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline that leverages electrodermal activity signals as input modality. Multiple representations of the signal are created and visualized as waveforms, and they are jointly visualized within a single multi-representation diagram. Extensive experiments incorporating various processing and filtering techniques, along with multiple representation combinations, demonstrate the effectiveness of the proposed approach. It consistently yields comparable, and in several cases superior, results to traditional fusion methods, establishing it as a robust alternative for integrating different signal representations or modalities.", 'abstract_zh': '疼痛是一种多维度的现象，影响着大量人群。可靠的且一致的评估有助于减轻疼痛患者的痛苦，并支撑有效且先进的疼痛管理策略的发展。自动疼痛评估系统提供连续监控，助力临床决策，并旨在减少痛苦同时防止功能衰退。通过整合生理信号，这些系统提供了关于个体状况的客观且准确的见解。本研究提交给了“下一代疼痛评估 multimodal 感知 grand challenge (AI4PAIN)”。所提出的方法引入了一种管道，利用电导率活动信号作为输入模态。创建了多种信号表示，并以波形的形式可视化，同时在单一多表示图中联合可视化。结合多种处理和滤波技术以及多种表示组合进行的大量实验表明，所提出的方法具有有效性，并在多种情况下优于传统融合方法，确立了其作为整合不同信号表示或模态的 robust 替代方案的地位。', 'title_zh': '多种表示图用于疼痛识别：整合多种电生理活动信号成单一图像'}
{'arxiv_id': 'arXiv:2507.21875', 'title': 'Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis', 'authors': 'Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis', 'link': 'https://arxiv.org/abs/2507.21875', 'abstract': "Pain is a complex and pervasive condition that affects a significant portion of the population. Accurate and consistent assessment is essential for individuals suffering from pain, as well as for developing effective management strategies in a healthcare system. Automatic pain assessment systems enable continuous monitoring, support clinical decision-making, and help minimize patient distress while mitigating the risk of functional deterioration. Leveraging physiological signals offers objective and precise insights into a person's state, and their integration in a multimodal framework can further enhance system performance. This study has been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The proposed approach introduces \\textit{Tiny-BioMoE}, a lightweight pretrained embedding model for biosignal analysis. Trained on $4.4$ million biosignal image representations and consisting of only $7.3$ million parameters, it serves as an effective tool for extracting high-quality embeddings for downstream tasks. Extensive experiments involving electrodermal activity, blood volume pulse, respiratory signals, peripheral oxygen saturation, and their combinations highlight the model's effectiveness across diverse modalities in automatic pain recognition tasks. \\textit{\\textcolor{blue}{The model's architecture (code) and weights are available at this https URL.", 'abstract_zh': '疼痛是一种复杂且普遍存在的状况，影响着大量人群。准确且一致的评估对于疼痛患者至关重要，也是在医疗保健系统中制定有效管理策略的基础。自动疼痛评估系统能够实现连续监测，支持临床决策，有助于减轻患者痛苦，同时减小功能衰退的风险。利用生理信号可以提供客观和精确的个体状态洞察，其在多模态框架中的集成可以进一步提升系统性能。本研究已提交至“下一代疼痛评估的第二轮多模态传感大赛（AI4PAIN）”。提出的办法介绍了一种轻量级预训练嵌入模型Tiny-BioMoE。该模型基于440万生理信号图像表示训练，仅包含730万个参数，适合作为提取高质量嵌入用于下游任务的有效工具。广泛涉及电导活性、血容积脉搏、呼吸信号、周围氧饱和度及其组合的实验强调了该模型在多种自动疼痛识别任务中的有效性。模型的架构（代码）和权重可从此链接获取。', 'title_zh': 'Tiny-BioMoE：一种轻量级生物信号分析嵌入模型'}
{'arxiv_id': 'arXiv:2507.21873', 'title': 'A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data', 'authors': 'Raffaele Pojer, Andrea Passerini, Kim G. Larsen, Manfred Jaeger', 'link': 'https://arxiv.org/abs/2507.21873', 'abstract': "Graph neural networks (GNNs) excel at predictive tasks on graph-structured data but often lack the ability to incorporate symbolic domain knowledge and perform general reasoning. Relational Bayesian Networks (RBNs), in contrast, enable fully generative probabilistic modeling over graph-like structures and support rich symbolic knowledge and probabilistic inference. This paper presents a neuro-symbolic framework that seamlessly integrates GNNs into RBNs, combining the learning strength of GNNs with the flexible reasoning capabilities of RBNs.\nWe develop two implementations of this integration: one compiles GNNs directly into the native RBN language, while the other maintains the GNN as an external component. Both approaches preserve the semantics and computational properties of GNNs while fully aligning with the RBN modeling paradigm. We also propose a maximum a-posteriori (MAP) inference method for these neuro-symbolic models.\nTo demonstrate the framework's versatility, we apply it to two distinct problems. First, we transform a GNN for node classification into a collective classification model that explicitly models homo- and heterophilic label patterns, substantially improving accuracy. Second, we introduce a multi-objective network optimization problem in environmental planning, where MAP inference supports complex decision-making. Both applications include new publicly available benchmark datasets.\nThis work introduces a powerful and coherent neuro-symbolic approach to graph data, bridging learning and reasoning in ways that enable novel applications and improved performance across diverse tasks.", 'abstract_zh': '基于图神经网络和关系贝叶斯网络的神经符号框架：结合学习与推理的优势以提高图数据的应用性能', 'title_zh': '基于神经符号方法的图数据概率推理'}
{'arxiv_id': 'arXiv:2507.21872', 'title': 'MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors', 'authors': 'Shouyi Lu, Zihan Lin, Chao Lu, Huanran Wang, Guirong Zhuo, Lianqing Zheng', 'link': 'https://arxiv.org/abs/2507.21872', 'abstract': 'Autonomous driving systems rely heavily on multimodal perception data to understand complex environments. However, the long-tailed distribution of real-world data hinders generalization, especially for rare but safety-critical vehicle categories. To address this challenge, we propose MultiEditor, a dual-branch latent diffusion framework designed to edit images and LiDAR point clouds in driving scenarios jointly. At the core of our approach is introducing 3D Gaussian Splatting (3DGS) as a structural and appearance prior for target objects. Leveraging this prior, we design a multi-level appearance control mechanism--comprising pixel-level pasting, semantic-level guidance, and multi-branch refinement--to achieve high-fidelity reconstruction across modalities. We further propose a depth-guided deformable cross-modality condition module that adaptively enables mutual guidance between modalities using 3DGS-rendered depth, significantly enhancing cross-modality consistency. Extensive experiments demonstrate that MultiEditor achieves superior performance in visual and geometric fidelity, editing controllability, and cross-modality consistency. Furthermore, generating rare-category vehicle data with MultiEditor substantially enhances the detection accuracy of perception models on underrepresented classes.', 'abstract_zh': '自主驾驶系统高度依赖多模态感知数据以理解复杂环境。然而，实际数据的长尾分布阻碍了泛化能力，尤其是在处理稀少但至关安全的车辆类别时。为应对这一挑战，我们提出了MultiEditor，这是一种设计用于联合编辑驾驶场景中图像和LiDAR点云的双分支潜扩散框架。我们方法的核心在于引入3D高斯斑点生成（3DGS）作为目标物体的结构和外观先验。基于此先验，我们设计了一种多层次的外观控制机制——包括像素级别拼接、语义级别指导以及多分支细化——以实现跨模态的高保真重构。此外，我们还提出了一个基于深度的可变形跨模态条件模块，利用3DGS渲染的深度信息实现模态间的自适应互指导，显著增强了跨模态一致性。大量实验表明，MultiEditor在视觉和几何保真度、编辑可控性以及跨模态一致性方面取得了优异性能。进一步使用MultiEditor生成稀有类别车辆数据显著提高了感知模型对未充分代表类别的检测精度。', 'title_zh': 'MultiEditor：基于3D高斯斑点先验的可控多模态对象编辑在驾驶场景中应用'}
{'arxiv_id': 'arXiv:2507.21848', 'title': 'EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity', 'authors': 'Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang', 'link': 'https://arxiv.org/abs/2507.21848', 'abstract': 'Large Language Models (LLMs) have made remarkable progress in enhancing step-by-step reasoning through reinforcement learning. However, the Group Relative Policy Optimization (GRPO) algorithm, which relies on sparse reward rules, often encounters the issue of identical rewards within groups, leading to the advantage collapse problem. Existing works typically address this challenge from two perspectives: enforcing model reflection to enhance response diversity, and introducing internal feedback to augment the training signal (advantage). In this work, we begin by analyzing the limitations of model reflection and investigating the policy entropy of responses at the fine-grained sample level. Based on our experimental findings, we propose the EDGE-GRPO algorithm, which adopts \\textbf{E}ntropy-\\textbf{D}riven Advantage and \\textbf{G}uided \\textbf{E}rror Correction to effectively mitigate the problem of advantage collapse. Extensive experiments on several main reasoning benchmarks demonstrate the effectiveness and superiority of our approach. It is available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）通过强化学习增强了逐步推理能力，然而，依赖稀疏奖励规则的群组相对策略优化（GRPO）算法常常遇到组内奖励一致导致的优势崩塌问题。现有工作通常从两种视角应对这一挑战：强化模型反思以提高响应多样性，以及引入内部反馈以增强训练信号（优势）。在本工作中，我们首先分析了模型反思的局限性，并在细粒度样本级别上研究了响应的策略熵。基于实验发现，我们提出了EDGE-GRPO算法，该算法采用基于熵的优势和引导错误校正（Entropy-Driven Advantage and Guided Error Correction）有效地缓解了优势崩塌问题。在多个主要推理基准上的广泛实验展示了我们方法的有效性和优越性。详情请见：this https URL。', 'title_zh': 'EDGE-GRPO：熵驱动的误差校正引导的GRPO以促进优势多样性'}
{'arxiv_id': 'arXiv:2507.21846', 'title': 'Probabilistic Active Goal Recognition', 'authors': 'Chenyuan Zhang, Cristian Rojas Cardenas, Hamid Rezatofighi, Mor Vered, Buser Say', 'link': 'https://arxiv.org/abs/2507.21846', 'abstract': "In multi-agent environments, effective interaction hinges on understanding the beliefs and intentions of other agents. While prior work on goal recognition has largely treated the observer as a passive reasoner, Active Goal Recognition (AGR) focuses on strategically gathering information to reduce uncertainty. We adopt a probabilistic framework for Active Goal Recognition and propose an integrated solution that combines a joint belief update mechanism with a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan efficiently and infer the actor's hidden goal without requiring domain-specific knowledge. Through comprehensive empirical evaluation in a grid-based domain, we show that our joint belief update significantly outperforms passive goal recognition, and that our domain-independent MCTS performs comparably to our strong domain-specific greedy baseline. These results establish our solution as a practical and robust framework for goal inference, advancing the field toward more interactive and adaptive multi-agent systems.", 'abstract_zh': '在多agent环境中，有效的交互依赖于理解其他agent的信念和意图。与以往主要将观察者视为被动推理者的基于目标识别工作不同，主动目标识别（AGR）侧重于通过战略性的信息收集来减少不确定性。我们采用概率框架进行主动目标识别，并提出了一种结合联合信念更新机制和蒙特卡洛树搜索（MCTS）算法的集成解决方案，使得观察者可以在无需特定领域知识的情况下高效规划并推断出行动者的隐藏目标。通过在网格域中的全面实验评估，我们证明了我们的联合信念更新显著优于被动目标识别，并且我们的领域无关MCTS与我们的强大领域特定贪心基准具有 comparable 性能。这些结果确立了我们的解决方案作为目标推断的实用且稳健框架的地位，推动了该领域向更具交互性和适应性的多agent系统方向发展。', 'title_zh': '概率主动目标识别'}
{'arxiv_id': 'arXiv:2507.21830', 'title': 'DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework', 'authors': 'Kuiye Ding, Fanda Fan, Yao Wang, Ruijie jian, Xiaorui Wang, Luqi Gong, Yishan Jiang, Chunjie Luo an Jianfeng Zhan', 'link': 'https://arxiv.org/abs/2507.21830', 'abstract': 'Multivariate Time Series Forecasting plays a key role in many applications. Recent works have explored using Large Language Models for MTSF to take advantage of their reasoning abilities. However, many methods treat LLMs as end-to-end forecasters, which often leads to a loss of numerical precision and forces LLMs to handle patterns beyond their intended design. Alternatively, methods that attempt to align textual and time series modalities within latent space frequently encounter alignment difficulty. In this paper, we propose to treat LLMs not as standalone forecasters, but as semantic guidance modules within a dual-stream framework. We propose DualSG, a dual-stream framework that provides explicit semantic guidance, where LLMs act as Semantic Guides to refine rather than replace traditional predictions. As part of DualSG, we introduce Time Series Caption, an explicit prompt format that summarizes trend patterns in natural language and provides interpretable context for LLMs, rather than relying on implicit alignment between text and time series in the latent space. We also design a caption-guided fusion module that explicitly models inter-variable relationships while reducing noise and computation. Experiments on real-world datasets from diverse domains show that DualSG consistently outperforms 15 state-of-the-art baselines, demonstrating the value of explicitly combining numerical forecasting with semantic guidance.', 'abstract_zh': '多变量时间序列预测在许多应用中发挥着关键作用。近年来的研究探索了使用大型语言模型进行多变量时间序列预测（MTSF），以利用其推理能力。然而，许多方法将大型语言模型视为端到端的预测器，这往往会损失数值精度，并迫使大型语言模型处理超出其设计意图的模式。另一种方法试图在潜在空间内对文本和时间序列模式进行对齐，但经常遇到对齐困难。在本文中，我们提出将大型语言模型不视为独立的预测器，而是作为双流框架内的语义指导模块。我们提出了DualSG双流框架，提供明确的语义指导，其中大型语言模型充当语义导向模块以精炼而非替代传统预测。作为DualSG的一部分，我们引入了时间序列描述这一明确的提示格式，以自然语言总结趋势模式并为大型语言模型提供可解释的上下文，而不是依赖潜在空间中文本与时间序列之间的隐式对齐。我们还设计了一个描述导向融合模块，明确建模变量间关系并减少噪声和计算量。实验结果表明，DualSG在来自不同领域的实际数据集上始终优于15个最先进的基线方法，证实了将数值预测与语义指导明确结合的价值。', 'title_zh': '双流显式语义引导的多变量时间序列forecasting框架'}
{'arxiv_id': 'arXiv:2507.21823', 'title': 'An Agentic AI for a New Paradigm in Business Process Development', 'authors': 'Mohammad Azarijafari, Luisa Mich, Michele Missikoff', 'link': 'https://arxiv.org/abs/2507.21823', 'abstract': 'Artificial Intelligence agents represent the next major revolution in the continuous technological evolution of industrial automation. In this paper, we introduce a new approach for business process design and development that leverages the capabilities of Agentic AI. Departing from the traditional task-based approach to business process design, we propose an agent-based method, where agents contribute to the achievement of business goals, identified by a set of business objects. When a single agent cannot fulfill a goal, we have a merge goal that can be achieved through the collaboration of multiple agents. The proposed model leads to a more modular and intelligent business process development by organizing it around goals, objects, and agents. As a result, this approach enables flexible and context-aware automation in dynamic industrial environments.', 'abstract_zh': '人工 intelligence 剂量代表了工业自动化连续技术进化中的下一重大革命。本文介绍了一种新的业务流程设计与开发方法，利用了 Agentic AI 的能力。不同于传统的基于任务的业务流程设计方法，我们提出了一种基于代理的方法，其中代理通过一组业务对象来实现业务目标。当单个代理无法完成目标时，我们将目标合并，通过多个代理的合作来实现。所提出的模型通过围绕目标、对象和代理组织业务流程开发，实现了更模块化和智能的业务流程开发。结果，这种方法在动态工业环境中实现了灵活和情境aware 的自动化。', 'title_zh': '代理型AI：商业流程开发新范式的基石'}
{'arxiv_id': 'arXiv:2507.21802', 'title': 'MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE', 'authors': 'Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong', 'link': 'https://arxiv.org/abs/2507.21802', 'abstract': 'Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPO-guided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for sampling. So we present a faster variant, termed $\\textbf{MixGRPO-Flash}$, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%. Codes and models are available at $\\href{this https URL}{MixGRPO}$.', 'abstract_zh': 'MixGRPO：一种利用混合采样策略的新型框架', 'title_zh': 'MixGRPO: 结合ODE-SDE实现基于流的GRPO效率提升'}
{'arxiv_id': 'arXiv:2507.21792', 'title': 'Hybrid Causal Identification and Causal Mechanism Clustering', 'authors': 'Saixiong Liu, Yuhua Qian, Jue Li, Honghong Cheng, Feijiang Li', 'link': 'https://arxiv.org/abs/2507.21792', 'abstract': 'Bivariate causal direction identification is a fundamental and vital problem in the causal inference field. Among binary causal methods, most methods based on additive noise only use one single causal mechanism to construct a causal model. In the real world, observations are always collected in different environments with heterogeneous causal relationships. Therefore, on observation data, this paper proposes a Mixture Conditional Variational Causal Inference model (MCVCI) to infer heterogeneous causality. Specifically, according to the identifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the superior fitting capabilities of the Gaussian mixture model and the neural network and elegantly uses the likelihoods obtained from the probabilistic bounds of the mixture conditional variational auto-encoder as causal decision criteria. Moreover, we model the casual heterogeneity into cluster numbers and propose the Mixture Conditional Variational Causal Clustering (MCVCC) method, which can reveal causal mechanism expression. Compared with state-of-the-art methods, the comprehensive best performance demonstrates the effectiveness of the methods proposed in this paper on several simulated and real data.', 'abstract_zh': '双变量因果方向识别是因果推理领域的一个基础而重要的问题。在二元因果方法中，大多数基于加性噪声的方法仅使用单一因果机制来构建因果模型。在现实世界中，观测数据总是收集自具有异质因果关系的不同环境。因此，本文在观测数据上提出了混合条件变异性因果推理模型（MCVCI）以推断异质因果关系。具体地，根据混合加性噪声模型（HANM）的可识别性，MCVCI 结合了高斯混合模型的优秀拟合能力和神经网络，并巧妙地使用混合条件变分自编码器的概率边界似然作为因果决策标准。此外，我们将因果异质性建模为聚类数目，并提出混合条件变分因果聚类（MCVCC）方法，该方法可以揭示因果机制表达。与现有最佳方法相比，全面的最优性能验证了本文所提出方法在多个模拟和真实数据集上的有效性。', 'title_zh': '混合因果识别与因果机制聚类'}
{'arxiv_id': 'arXiv:2507.21753', 'title': 'Towards a rigorous evaluation of RAG systems: the challenge of due diligence', 'authors': 'Grégoire Martinon, Alexandra Lorenzo de Brionne, Jérôme Bohard, Antoine Lojou, Damien Hervault, Nicolas J-B. Brunel', 'link': 'https://arxiv.org/abs/2507.21753', 'abstract': 'The rise of generative AI, has driven significant advancements in high-risk sectors like healthcare and finance. The Retrieval-Augmented Generation (RAG) architecture, combining language models (LLMs) with search engines, is particularly notable for its ability to generate responses from document corpora. Despite its potential, the reliability of RAG systems in critical contexts remains a concern, with issues such as hallucinations persisting. This study evaluates a RAG system used in due diligence for an investment fund. We propose a robust evaluation protocol combining human annotations and LLM-Judge annotations to identify system failures, like hallucinations, off-topic, failed citations, and abstentions. Inspired by the Prediction Powered Inference (PPI) method, we achieve precise performance measurements with statistical guarantees. We provide a comprehensive dataset for further analysis. Our contributions aim to enhance the reliability and scalability of RAG systems evaluation protocols in industrial applications.', 'abstract_zh': '生成式AI的兴起推动了医疗和金融等高风险领域的显著进步。检索增强生成（RAG）架构，结合语言模型（LLMs）和搜索引擎，特别因其能够从文档集合中生成响应而备受瞩目。尽管其潜力巨大，但在关键场景中RAG系统的可靠性仍是值得关注的问题，幻觉等问题仍然存在。本研究评估了一种应用于投资基金尽职调查的RAG系统。我们提出了一种结合人类标注和LLM-Judge标注的稳健评估协议，以识别系统故障，如幻觉、离题、引用失败和弃权。受预测驱动的推理（PPI）方法的启发，我们实现了具有统计保证的精确性能测量。我们提供了一个全面的数据集供进一步分析。我们的贡献旨在增强RAG系统评估协议在工业应用中的可靠性和扩展性。', 'title_zh': '向RAG系统严格评估的迈进：尽职调查挑战'}
{'arxiv_id': 'arXiv:2507.21752', 'title': 'SAT-Based Bounded Fitting for the Description Logic ALC', 'authors': 'Maurice Funk, Jean Christoph Jung, Tom Voellmer', 'link': 'https://arxiv.org/abs/2507.21752', 'abstract': "Bounded fitting is a general paradigm for learning logical formulas from positive and negative data examples, that has received considerable interest recently. We investigate bounded fitting for the description logic ALC and its syntactic fragments. We show that the underlying size-restricted fitting problem is NP-complete for all studied fragments, even in the special case of a single positive and a single negative example. By design, bounded fitting comes with probabilistic guarantees in Valiant's PAC learning framework. In contrast, we show that other classes of algorithms for learning ALC concepts do not provide such guarantees. Finally, we present an implementation of bounded fitting in ALC and its fragments based on a SAT solver. We discuss optimizations and compare our implementation to other concept learning tools.", 'abstract_zh': '有界拟合是学习正反例数据逻辑公式的一般范式， recently received considerable interest. 我们研究了描述逻辑ALC及其语法片段的有界拟合。我们证明了所有研究片段的基本大小限制的拟合问题是NP完全的，即使在仅有一个正例和一个反例的特殊情况也是如此。由于设计原因，有界拟合在Valiant的PAC学习框架中提供了概率保证。相比之下，我们证明了其他学习ALC概念的算法类没有提供这样的保证。最后，我们基于SAT求解器实现了ALC及其片段的有界拟合，并讨论了优化措施，将我们的实现与其他概念学习工具进行了比较。', 'title_zh': '基于SAT的描述逻辑ALC的有界拟合方法'}
{'arxiv_id': 'arXiv:2507.21727', 'title': 'GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation', 'authors': 'Jianfei Zhu, Haiqi Zhu, Shaohui Liu, Feng Jiang, Baichun Wei, Chunzhi Yi', 'link': 'https://arxiv.org/abs/2507.21727', 'abstract': 'Recent deep learning approaches have shown promise in learning such individual brain parcellations from functional magnetic resonance imaging (fMRI). However, most existing methods assume consistent data distributions across domains and struggle with domain shifts inherent to real-world cross-dataset scenarios. To address this challenge, we proposed Graph Domain Adaptation for Individual Parcellation (GDAIP), a novel framework that integrates Graph Attention Networks (GAT) with Minimax Entropy (MME)-based domain adaptation. We construct cross-dataset brain graphs at both the group and individual levels. By leveraging semi-supervised training and adversarial optimization of the prediction entropy on unlabeled vertices from target brain graph, the reference atlas is adapted from the group-level brain graph to the individual brain graph, enabling individual parcellation under cross-dataset settings. We evaluated our method using parcellation visualization, Dice coefficient, and functional homogeneity. Experimental results demonstrate that GDAIP produces individual parcellations with topologically plausible boundaries, strong cross-session consistency, and ability of reflecting functional organization.', 'abstract_zh': '图域适应个体分叶方法（GDAIP）：基于Graph注意力网络和最小最大熵的域适应框架', 'title_zh': '基于图的领域自适应框架：个体脑区划分'}
{'arxiv_id': 'arXiv:2507.21705', 'title': 'Unrolling Dynamic Programming via Graph Filters', 'authors': 'Sergio Rozada, Samuel Rey, Gonzalo Mateos, Antonio G. Marques', 'link': 'https://arxiv.org/abs/2507.21705', 'abstract': "Dynamic programming (DP) is a fundamental tool used across many engineering fields. The main goal of DP is to solve Bellman's optimality equations for a given Markov decision process (MDP). Standard methods like policy iteration exploit the fixed-point nature of these equations to solve them iteratively. However, these algorithms can be computationally expensive when the state-action space is large or when the problem involves long-term dependencies. Here we propose a new approach that unrolls and truncates policy iterations into a learnable parametric model dubbed BellNet, which we train to minimize the so-termed Bellman error from random value function initializations. Viewing the transition probability matrix of the MDP as the adjacency of a weighted directed graph, we draw insights from graph signal processing to interpret (and compactly re-parameterize) BellNet as a cascade of nonlinear graph filters. This fresh look facilitates a concise, transferable, and unifying representation of policy and value iteration, with an explicit handle on complexity during inference. Preliminary experiments conducted in a grid-like environment demonstrate that BellNet can effectively approximate optimal policies in a fraction of the iterations required by classical methods.", 'abstract_zh': '动态规划（DP）是许多工程领域中的一项基本工具。DP的主要目标是通过给定的马尔可夫决策过程（MDP）来求解贝尔曼最优方程。标准方法如策略迭代利用这些方程的不动点性质迭代求解。然而，当状态-动作空间巨大或问题涉及长期依赖时，这些算法可能会非常耗时。 herein我们提出了一种新方法，将策略迭代展开并截断为一个可学习的参数模型贝尔网（BellNet），并通过从随机价值函数初始化中最小化贝尔曼误差来进行训练。将MDP的转移概率矩阵视为加权有向图的邻接矩阵，我们从图信号处理中汲取灵感，以解释（并紧凑地重新参数化）贝尔网为级联的非线性图滤波器。这种新的视角为策略和值迭代提供了一种简洁、可迁移且统一的表示，并在推理过程中明确处理了复杂性。初步实验在网格环境中显示，贝尔网可以在经典方法所需迭代次数的很小一部分内有效地逼近最优策略。', 'title_zh': '通过图滤波展开动态规划'}
{'arxiv_id': 'arXiv:2507.21664', 'title': 'Can the current trends of AI handle a full course of mathematics?', 'authors': 'Mariam Alsayyad, Fayadh Kadhem', 'link': 'https://arxiv.org/abs/2507.21664', 'abstract': 'This paper addresses the question of how able the current trends of Artificial Intelligence (AI) are in managing to take the responsibility of a full course of mathematics at a college level. The study evaluates this ability in four significant aspects, namely, creating a course syllabus, presenting selected material, answering student questions, and creating an assessment. It shows that even though the AI is strong in some important parts like organization and accuracy, there are still some human aspects that are far away from the current abilities of AI. There is still a hidden emotional part, even in science, that cannot be fulfilled by the AI in its current state. This paper suggests some recommendations to integrate the human and AI potentials to create better outcomes in terms of reaching the target of creating a full course of mathematics, at a university level, as best as possible.', 'abstract_zh': '本文探讨当前人工智能（AI）趋势在承担大学数学完整课程责任方面的能力。研究从四个重要方面评估这种能力，即制定课程大纲、呈现选定材料、回答学生问题和创建评估。研究表明，尽管AI在组织和准确性方面表现出色，但仍有一些人类特质远超当前AI的能力范围。即使在科学领域，AI当前状态下仍无法满足某些隐藏的情感需求。本文提出了一些建议，以整合人类和AI的潜力，尽可能地达成在大学水平上创建完整数学课程的目标，以取得更好的成果。', 'title_zh': '当前的人工智能趋势能否应对完整数学课程？'}
{'arxiv_id': 'arXiv:2507.21638', 'title': 'Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics', 'authors': 'Leonard Hinckeldey, Elliot Fosong, Elle Miller, Rimvydas Rubavicius, Trevor McInroe, Patricia Wollstadt, Christiane B. Wiebel-Herboth, Subramanian Ramamoorthy, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2507.21638', 'abstract': "The development of reinforcement learning (RL) algorithms has been largely driven by ambitious challenge tasks and benchmarks. Games have dominated RL benchmarks because they present relevant challenges, are inexpensive to run and easy to understand. While games such as Go and Atari have led to many breakthroughs, they often do not directly translate to real-world embodied applications. In recognising the need to diversify RL benchmarks and addressing complexities that arise in embodied interaction scenarios, we introduce Assistax: an open-source benchmark designed to address challenges arising in assistive robotics tasks. Assistax uses JAX's hardware acceleration for significant speed-ups for learning in physics-based simulations. In terms of open-loop wall-clock time, Assistax runs up to $370\\times$ faster when vectorising training runs compared to CPU-based alternatives. Assistax conceptualises the interaction between an assistive robot and an active human patient using multi-agent RL to train a population of diverse partner agents against which an embodied robotic agent's zero-shot coordination capabilities can be tested. Extensive evaluation and hyperparameter tuning for popular continuous control RL and MARL algorithms provide reliable baselines and establish Assistax as a practical benchmark for advancing RL research for assistive robotics. The code is available at: this https URL.", 'abstract_zh': '强化学习算法的发展主要受到雄心勃勃的挑战任务和基准测试的推动。由于游戏能够提供相关的挑战、运行成本低且易于理解，因此一直在强化学习基准测试中占据主导地位。尽管如围棋和_atari_等游戏取得了许多突破，但它们往往不能直接应用于实际的生活类交互场景。为了满足对多样化强化学习基准测试的需求，并应对生活中交互场景中出现的复杂性，我们引入了Assistax：一个开源基准测试，旨在解决助手法学任务中出现的挑战。Assistax利用JAX的硬件加速技术，在基于物理的模拟学习中显著提高速度。与基于CPU的替代方案相比，Assistax在向量化的训练运行中可以快至370倍的开放环墙钟时间。Assistax通过多智能体强化学习的概念化，将辅助机器人与积极的人类患者之间的交互进行建模，训练出一系列多样化的伙伴智能体，以测试有身体的机器人智能体的零样本协调能力。广泛评估和针对流行的连续控制强化学习及多智能体强化学习算法的超参数调整为研究提供了可靠的基准，并确立了Assistax作为推进助手法学研究的实用基准的地位。代码可在以下链接获取：this https URL。', 'title_zh': 'Assistax：面向辅助机器人的硬件加速强化学习基准评测'}
{'arxiv_id': 'arXiv:2507.21637', 'title': 'Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models', 'authors': 'Wanying Wang, Zeyu Ma, Han Zheng, Xin Tan, Mingang Chen', 'link': 'https://arxiv.org/abs/2507.21637', 'abstract': "Large vision-language models (LVLMs) are vulnerable to harmful input compared to their language-only backbones. We investigated this vulnerability by exploring LVLMs internal dynamics, framing their inherent safety understanding in terms of three key capabilities. Specifically, we define these capabilities as safety perception, semantic understanding, and alignment for linguistic expression, and experimentally pinpointed their primary locations within the model architecture. The results indicate that safety perception often emerges before comprehensive semantic understanding, leading to the reduction in safety. Motivated by these findings, we propose \\textbf{Self-Aware Safety Augmentation (SASA)}, a technique that projects informative semantic representations from intermediate layers onto earlier safety-oriented layers. This approach leverages the model's inherent semantic understanding to enhance safety recognition without fine-tuning. Then, we employ linear probing to articulate the model's internal semantic comprehension to detect the risk before the generation process. Extensive experiments on various datasets and tasks demonstrate that SASA significantly improves the safety of LVLMs, with minimal impact on the utility.", 'abstract_zh': 'Large 视觉-语言 模型 (LVLMs) 对有害输入的脆弱性高于其仅语言的骨干模型。我们通过探索 LVLMs 内部动力学，从三个关键能力的角度框架其内在的安全理解。具体地，我们将这些能力定义为安全感知、语义理解以及语言表达的对齐，并实验性地确定了它们在模型架构中的主要位置。结果显示，安全感知往往在全面的语义理解之前出现，从而导致安全性的降低。受此发现的启发，我们提出了一种名为 **自我感知安全增强 (Self-Aware Safety Augmentation, SASA)** 的技术，该技术将中间层的信息语义表示投影到早期的安全导向层。该方法利用模型固有的语义理解来增强安全性识别，而无需微调。然后，我们使用线性探测来表达模型内部的语义理解，以在生成过程之前检测风险。在多种数据集和任务上的广泛实验表明，SASA 显著提高了 LVLMs 的安全性，且对其实用性的影响较小。', 'title_zh': '自我意识安全性增强：利用内部语义理解提高视觉语言模型的安全性'}
{'arxiv_id': 'arXiv:2507.21636', 'title': 'StaffPro: an LLM Agent for Joint Staffing and Profiling', 'authors': 'Alessio Maritan', 'link': 'https://arxiv.org/abs/2507.21636', 'abstract': "Large language model (LLM) agents integrate pre-trained LLMs with modular algorithmic components and have shown remarkable reasoning and decision-making abilities. In this work, we investigate their use for two tightly intertwined challenges in workforce management: staffing, i.e., the assignment and scheduling of tasks to workers, which may require team formation; and profiling, i.e., the continuous estimation of workers' skills, preferences, and other latent attributes from unstructured data. We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly. Differently from existing staffing solutions, StaffPro allows expressing optimization objectives using natural language, accepts textual task descriptions and provides high flexibility. StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use. By analyzing human feedback, our agent continuously estimates the latent features of workers, realizing life-long worker profiling and ensuring optimal staffing performance over time. A consulting firm simulation example demonstrates that StaffPro successfully estimates workers' attributes and generates high quality schedules. With its innovative design, StaffPro offers a robust, interpretable, and human-centric solution for automated personnel management.", 'abstract_zh': '大型语言模型代理（LLM代理）结合预训练的LLM和模块化算法组件，并展示了出色的推理和决策能力。本文探讨了它们在劳动力管理中两个紧密相关的挑战的应用：排班，即任务分配和调度，可能需要团队组建；和建模，即从非结构化数据中持续估计工人的技能、偏好及其他潜在属性。我们将这些问题置于一个形式化的数学框架中，将调度决策与潜在特征估计联系起来，并介绍了StaffPro，这是一种联合解决排班和建模问题的LLM代理。与现有的排班解决方案不同，StaffPro允许使用自然语言表达优化目标，接受文本任务描述并提供高灵活性。StaffPro通过建立持续的人机反馈循环直接与人类交互，确保自然且直观的使用。通过分析人类反馈，我们的代理连续估计工人的潜在特征，实现终身工人建模，并确保随着时间推移实现最优的排班性能。咨询公司模拟案例表明，StaffPro成功估计了工人的属性并生成了高质量的排班。凭借其创新设计，StaffPro提供了自动化人员管理的稳健、可解释且以人为本的解决方案。', 'title_zh': 'StaffPro: 一个用于联合人员配置和画像的LLM代理'}
{'arxiv_id': 'arXiv:2507.21631', 'title': '"Teammates, Am I Clear?": Analysing Legible Behaviours in Teams', 'authors': 'Miguel Faria, Francisco S. Melo, Ana Paiva', 'link': 'https://arxiv.org/abs/2507.21631', 'abstract': 'In this paper we investigate the notion of legibility in sequential decision-making in the context of teams and teamwork. There have been works that extend the notion of legibility to sequential decision making, for deterministic and for stochastic scenarios. However, these works focus on one agent interacting with one human, foregoing the benefits of having legible decision making in teams of agents or in team configurations with humans. In this work we propose an extension of legible decision-making to multi-agent settings that improves the performance of agents working in collaboration. We showcase the performance of legible decision making in team scenarios using our proposed extension in multi-agent benchmark scenarios. We show that a team with a legible agent is able to outperform a team composed solely of agents with standard optimal behaviour.', 'abstract_zh': '本文探讨了在团队和团队协作背景下序列决策中的可读性问题。已有研究将可读性扩展到确定性和随机情景下的序列决策中。然而，这些研究主要关注单个代理与人类交互的情况，忽视了团队中具有可读性决策或包含人类的团队配置中的优势。本文提出了一种扩展可读性决策的方法，以增强协作中代理的表现。通过在多代理基准场景中应用所提出的方法，展示了在团队场景中可读性决策的性能。我们证明了具有可读性代理的团队能够超越仅由标准最优行为代理组成的团队。', 'title_zh': '“队友，倾听我的声音”：分析团队中的可辨识行为'}
{'arxiv_id': 'arXiv:2507.21589', 'title': 'Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems', 'authors': 'Bin Liu', 'link': 'https://arxiv.org/abs/2507.21589', 'abstract': 'Embodied intelligence posits that cognitive capabilities fundamentally emerge from - and are shaped by - an agent\'s real-time sensorimotor interactions with its environment. Such adaptive behavior inherently requires continuous inference under uncertainty. Bayesian statistics offers a principled probabilistic framework to address this challenge by representing knowledge as probability distributions and updating beliefs in response to new evidence. The core computational processes underlying embodied intelligence - including perception, action selection, learning, and even higher-level cognition - can be effectively understood and modeled as forms of Bayesian inference. Despite the deep conceptual connection between Bayesian statistics and embodied intelligence, Bayesian principles have not been widely or explicitly applied in today\'s embodied intelligence systems. In this work, we examine both Bayesian and contemporary embodied intelligence approaches through two fundamental lenses: search and learning - the two central themes in modern AI, as highlighted in Rich Sutton\'s influential essay "The Bitter Lesson". This analysis sheds light on why Bayesian inference has not played a central role in the development of modern embodied intelligence. At the same time, it reveals that current embodied intelligence systems remain largely confined to closed-physical-world environments, and highlights the potential for Bayesian methods to play a key role in extending these systems toward truly open physical-world embodied intelligence.', 'abstract_zh': '本体智能认为认知能力从根本上源自于并由智能体与环境实时传感器运动交互所塑造。这种适应性行为本质上要求在不确定性下进行持续推断。贝叶斯统计提供了一个原理性的概率框架来应对这一挑战，通过将知识表示为概率分布并在新证据面前更新信念。本体智能的核心计算过程——包括感知、动作选择、学习，甚至高层次认知——可以有效被理解为多种形式的贝叶斯推断。尽管贝叶斯统计与本体智能之间存在深刻的概念联系，但贝叶斯原则至今并未在当今的本体智能系统中广泛或明确地应用。在本工作中，我们通过两个基本视角——搜索与学习——分析贝叶斯方法和现代本体智能方法，这两个主题是Rich Sutton影响深远的文章《苦涩的教训》中强调的现代人工智能的核心。这一分析揭示了为什么贝叶斯推断尚未在现代本体智能的发展中扮演核心角色。同时，它还显示当前的本体智能系统主要局限于封闭的物理环境，强调了贝叶斯方法在扩展这些系统以实现真正开放物理世界的本体智能方面的潜在作用。', 'title_zh': '探索贝叶斯推断与体化智能之间的联系：通往开放物理世界体化AI系统的道路'}
{'arxiv_id': 'arXiv:2507.21588', 'title': 'Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning', 'authors': 'Jiong Yin, Liang Li, Jiehua Zhang, Yuhan Gao, Chenggang Yan, Xichun Sheng', 'link': 'https://arxiv.org/abs/2507.21588', 'abstract': 'Audio-visual multi-task incremental learning aims to continuously learn from multiple audio-visual tasks without the need for joint training on all tasks. The challenge of the problem is how to preserve the old task knowledge while facilitating the learning of new task with previous experiences. To address these challenges, we introduce a three-stage Progressive Homeostatic and Plastic audio-visual prompt (PHP) method. In the shallow phase, we design the task-shared modality aggregating adapter to foster cross-task and cross-modal audio-visual representation learning to enhance shared understanding between tasks. In the middle phase, we propose the task-specific modality-shared dynamic generating adapter, which constructs prompts that are tailored to individual tasks while remaining general across modalities, which balances the models ability to retain knowledge against forgetting with its potential for versatile multi-task transferability. In the deep phase, we introduce the task-specific modality-independent prompts to further refine the understand ability by targeting individual information for each task and modality. By incorporating these three phases, PHP retains task-specific prompts while adapting shared parameters for new tasks to effectively balance knowledge sharing and specificity. Our method achieves SOTA performance in different orders of four tasks (AVE, AVVP, AVS and AVQA). Our code can be available at this https URL.', 'abstract_zh': '视听多任务增量学习旨在无需联合训练所有任务的情况下，持续从多个视听任务中学习。该问题的挑战在于如何在促进新任务学习的同时保留旧任务的知识。为解决这些挑战，我们引入了一种三级动态平衡视听提示（PHP）方法。在浅层阶段，我们设计了任务共享模态聚合适配器，以促进跨任务和跨模态的视听表示学习，增强任务间的共享理解。在中间阶段，我们提出了任务特定模态共享动态生成适配器，该适配器构建针对个别任务的定制提示，同时保持跨模态的一般性，从而在保留知识与遗忘之间的能力与多任务转移的灵活性之间取得平衡。在深层阶段，我们引入了任务特定独立模态的提示，进一步通过针对每个任务和模态的特定信息来精炼理解能力。通过结合这三个阶段，PHP 保留了任务特定的提示，同时适应新的任务的共享参数，以有效平衡知识共享和特定性。我们的方法在四种任务（AVE、AVVP、AVS 和 AVQA）中实现了最佳性能。我们的代码可在以下链接获取：this https URL。', 'title_zh': '渐进稳态与塑性提示调谐用于音频-视觉多任务增量学习'}
{'arxiv_id': 'arXiv:2507.21585', 'title': 'SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation', 'authors': 'Hao Ye, Mengshi Qi, Zhaohong Liu, Liang Liu, Huadong Ma', 'link': 'https://arxiv.org/abs/2507.21585', 'abstract': "In this work, we study how vision-language models (VLMs) can be utilized to enhance the safety for the autonomous driving system, including perception, situational understanding, and path planning. However, existing research has largely overlooked the evaluation of these models in traffic safety-critical driving scenarios. To bridge this gap, we create the benchmark (SafeDrive228K) and propose a new baseline based on VLM with knowledge graph-based retrieval-augmented generation (SafeDriveRAG) for visual question answering (VQA). Specifically, we introduce SafeDrive228K, the first large-scale multimodal question-answering benchmark comprising 228K examples across 18 sub-tasks. This benchmark encompasses a diverse range of traffic safety queries, from traffic accidents and corner cases to common safety knowledge, enabling a thorough assessment of the comprehension and reasoning abilities of the models. Furthermore, we propose a plug-and-play multimodal knowledge graph-based retrieval-augmented generation approach that employs a novel multi-scale subgraph retrieval algorithm for efficient information retrieval. By incorporating traffic safety guidelines collected from the Internet, this framework further enhances the model's capacity to handle safety-critical situations. Finally, we conduct comprehensive evaluations on five mainstream VLMs to assess their reliability in safety-sensitive driving tasks. Experimental results demonstrate that integrating RAG significantly improves performance, achieving a +4.73% gain in Traffic Accidents tasks, +8.79% in Corner Cases tasks and +14.57% in Traffic Safety Commonsense across five mainstream VLMs, underscoring the potential of our proposed benchmark and methodology for advancing research in traffic safety. Our source code and data are available at this https URL.", 'abstract_zh': '在本工作中，我们研究了视觉语言模型（VLMs）如何被利用以增强自主驾驶系统的安全性，包括感知、情景理解以及路径规划。然而，现有的研究大多忽视了在交通安全关键驾驶场景中评估这些模型的表现。为了填补这一空白，我们创建了基准（SafeDrive228K），并基于知识图谱检索增强生成（SafeDriveRAG）提出了一个视觉问答（VQA）的新基线。具体地，我们引入了SafeDrive228K，这是第一个大规模多模态问答基准，包含228K个跨18个亚任务的样本。该基准涵盖了从交通事故和极端情况到普通安全知识的各种交通安全查询，使模型的理解和推理能力得到全面评估。此外，我们提出了一个插即用的多模态知识图谱检索增强生成方法，使用了一种新颖的多尺度子图检索算法，以实现高效的信息检索。通过集成从互联网收集的交通安全指南，该框架进一步增强了模型在处理安全关键情况时的能力。最后，我们在五种主流VLM上进行了全面评估，以评估其在安全敏感驾驶任务中的可靠性。实验结果表明，结合RAG显著提高了性能，在交通事故任务中提高了4.73%，在极端情况任务中提高了8.79%，在交通安全性常识中提高了14.57%，突显了我们提出基准和方法在交通安全性研究中的潜力。我们的源代码和数据可在以下链接获取。', 'title_zh': 'SafeDriveRAG：基于知识图谱检索增强生成 toward 安全自动驾驶'}
{'arxiv_id': 'arXiv:2507.21571', 'title': 'Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations', 'authors': 'Laura Spillner, Nima Zargham, Mihai Pomarlan, Robert Porzel, Rainer Malaka', 'link': 'https://arxiv.org/abs/2507.21571', 'abstract': "The need for explanations in AI has, by and large, been driven by the desire to increase the transparency of black-box machine learning models. However, such explanations, which focus on the internal mechanisms that lead to a specific output, are often unsuitable for non-experts. To facilitate a human-centered perspective on AI explanations, agents need to focus on individuals and their preferences as well as the context in which the explanations are given. This paper proposes a personalized approach to explanation, where the agent tailors the information provided to the user based on what is most likely pertinent to them. We propose a model of the agent's worldview that also serves as a personal and dynamic memory of its previous interactions with the same user, based on which the artificial agent can estimate what part of its knowledge is most likely new information to the user.", 'abstract_zh': 'AI解释的个性化方法：基于用户视角的定制化信息提供', 'title_zh': '寻求共同点：以人为本的外向型解释模型'}
{'arxiv_id': 'arXiv:2507.21524', 'title': 'Large Language Models for Wireless Communications: From Adaptation to Autonomy', 'authors': 'Le Liang, Hao Ye, Yucheng Sheng, Ouya Wang, Jiacheng Wang, Shi Jin, Geoffrey Ye Li', 'link': 'https://arxiv.org/abs/2507.21524', 'abstract': 'The emergence of large language models (LLMs) has revolutionized artificial intelligence, offering unprecedented capabilities in reasoning, generalization, and zero-shot learning. These strengths open new frontiers in wireless communications, where increasing complexity and dynamics demand intelligent and adaptive solutions. This article explores the role of LLMs in transforming wireless systems across three key directions: adapting pretrained LLMs for core communication tasks, developing wireless-specific foundation models to balance versatility and efficiency, and enabling agentic LLMs with autonomous reasoning and coordination capabilities. We highlight recent advances, practical case studies, and the unique benefits of LLM-based approaches over traditional methods. Finally, we outline open challenges and research opportunities, including multimodal fusion, collaboration with lightweight models, and self-improving capabilities, charting a path toward intelligent, adaptive, and autonomous wireless networks of the future.', 'abstract_zh': '大型语言模型的 emergence 与发展革新了人工智能，在推理、泛化和零样本学习方面提供了前所未有的能力。这些优势为无线通信领域带来了新的前沿挑战，尤其是在日益复杂的动态环境中，需要智能和自适应的解决方案。本文探讨了大型语言模型在无线系统三个关键方向上的转型作用：适应预训练大型语言模型以执行核心通信任务、开发针对无线通信领域的基础模型以平衡多功能性和效率，以及启用具有自主推理和协调能力的大型语言模型。我们强调了最近的进展、实用案例研究以及基于大型语言模型方法的独特优势，相对于传统方法的优势。最后，我们概述了开放的挑战和研究机会，包括多模态融合、与轻量化模型协作以及自我提升能力，绘制了一条通向智能、自适应和自主无线网络的未来之路。', 'title_zh': '无线通信中的大规模语言模型：从适应到自主'}
{'arxiv_id': 'arXiv:2507.21518', 'title': 'ST-GDance: Long-Term and Collision-Free Group Choreography from Music', 'authors': 'Jing Xu, Weiqiang Wang, Cunjian Chen, Jun Liu, Qiuhong Ke', 'link': 'https://arxiv.org/abs/2507.21518', 'abstract': 'Group dance generation from music has broad applications in film, gaming, and animation production. However, it requires synchronizing multiple dancers while maintaining spatial coordination. As the number of dancers and sequence length increase, this task faces higher computational complexity and a greater risk of motion collisions. Existing methods often struggle to model dense spatial-temporal interactions, leading to scalability issues and multi-dancer collisions. To address these challenges, we propose ST-GDance, a novel framework that decouples spatial and temporal dependencies to optimize long-term and collision-free group choreography. We employ lightweight graph convolutions for distance-aware spatial modeling and accelerated sparse attention for efficient temporal modeling. This design significantly reduces computational costs while ensuring smooth and collision-free interactions. Experiments on the AIOZ-GDance dataset demonstrate that ST-GDance outperforms state-of-the-art baselines, particularly in generating long and coherent group dance sequences. Project page: this https URL.', 'abstract_zh': '音乐驱动群舞生成在电影、游戏和动画制作中有广泛的应用。然而，这需要同步多个舞者并保持空间协调。随着舞者数量和序列长度的增加，该任务面临的计算复杂性更高，并且运动碰撞的风险更大。现有方法常常难以建模密集的空间-时间交互，导致可扩展性问题和多舞者碰撞。为此，我们提出了一种名为ST-GDance的新型框架，该框架解耦空间和时间依赖性以优化长期且无碰撞的群舞编排。我们采用轻量级图卷积进行距离感知的空间建模，并采用加速稀疏注意机制实现高效的临时建模。这种设计显著降低了计算成本，同时确保了平滑且无碰撞的交互。实验结果表明，ST-GDance在生成长且连贯的群舞序列方面优于现有的基线方法。项目页面：this https URL。', 'title_zh': 'ST-GDance: 长期且无碰撞的群体 choreography 从音乐生成'}
{'arxiv_id': 'arXiv:2507.21513', 'title': 'What Does it Mean for a Neural Network to Learn a "World Model"?', 'authors': 'Kenneth Li, Fernanda Viégas, Martin Wattenberg', 'link': 'https://arxiv.org/abs/2507.21513', 'abstract': 'We propose a set of precise criteria for saying a neural net learns and uses a "world model." The goal is to give an operational meaning to terms that are often used informally, in order to provide a common language for experimental investigation. We focus specifically on the idea of representing a latent "state space" of the world, leaving modeling the effect of actions to future work. Our definition is based on ideas from the linear probing literature, and formalizes the notion of a computation that factors through a representation of the data generation process. An essential addition to the definition is a set of conditions to check that such a "world model" is not a trivial consequence of the neural net\'s data or task.', 'abstract_zh': '我们提出了一套精确的标准，用于判断神经网络是否学习并使用了一个“世界模型”。目标是为常被非正式使用的术语赋予操作性含义，以便为实验调查提供一种共同的语言。我们特别关注世界潜在“状态空间”的表示想法，将动作效果的建模留作未来工作。我们的定义基于线性探查文献中的想法，并正式化了通过数据生成过程表示的计算概念。定义中的一个关键补充是一系列条件，用于检查这种“世界模型”是否仅仅是神经网络数据或任务的 trivial 结果。', 'title_zh': '神经网络学习“世界模型”意味着什么？'}
{'arxiv_id': 'arXiv:2507.21503', 'title': 'MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions', 'authors': 'Yanxu Zhu, Shitong Duan, Xiangxu Zhang, Jitao Sang, Peng Zhang, Tun Lu, Xiao Zhou, Jing Yao, Xiaoyuan Yi, Xing Xie', 'link': 'https://arxiv.org/abs/2507.21503', 'abstract': "Recently Multimodal Large Language Models (MLLMs) have achieved considerable advancements in vision-language tasks, yet produce potentially harmful or untrustworthy content. Despite substantial work investigating the trustworthiness of language models, MMLMs' capability to act honestly, especially when faced with visually unanswerable questions, remains largely underexplored. This work presents the first systematic assessment of honesty behaviors across various MLLMs. We ground honesty in models' response behaviors to unanswerable visual questions, define four representative types of such questions, and construct MoHoBench, a large-scale MMLM honest benchmark, consisting of 12k+ visual question samples, whose quality is guaranteed by multi-stage filtering and human verification. Using MoHoBench, we benchmarked the honesty of 28 popular MMLMs and conducted a comprehensive analysis. Our findings show that: (1) most models fail to appropriately refuse to answer when necessary, and (2) MMLMs' honesty is not solely a language modeling issue, but is deeply influenced by visual information, necessitating the development of dedicated methods for multimodal honesty alignment. Therefore, we implemented initial alignment methods using supervised and preference learning to improve honesty behavior, providing a foundation for future work on trustworthy MLLMs. Our data and code can be found at this https URL.", 'abstract_zh': '近年来，多模态大型语言模型（MLLMs）在视觉-语言任务中取得了显著进展，但往往会生成潜在有害或不可靠的内容。尽管已经开展了大量研究探讨语言模型的可信度，但MLLMs在面对视觉不可回答的问题时是否能够诚实行事的能力仍 largely未被探索。本文首次系统评估了各种MLLMs的诚实行为。我们基于模型对不可回答的视觉问题的响应行为定义了四种代表性问题类型，并构建了 MoHoBench，一个包含超过 12000 个视觉问题样本的大规模 MLLMs 诚实基准，其质量通过多阶段过滤和人工验证得以保证。使用 MoHoBench，我们对 28 个流行的 MLLMs 进行了基准测试并进行了全面分析。我们的研究发现表明：（1）大多数模型在必要时未能恰当拒绝回答，（2）MLLMs 的诚实不仅仅是一个语言建模问题，还受到视觉信息的深刻影响，需要开发专门的多模态诚实对齐方法。因此，我们采用了监督学习和偏好学习的方法实施了初步的诚实对齐方法，以改善诚实行为，为未来可信赖的 MLLMs 研究奠定了基础。我们的数据和代码可在以下网址找到。', 'title_zh': 'MoHoBench: 通过不可答的视觉问题评估多模态大型语言模型的诚实性'}
{'arxiv_id': 'arXiv:2507.21502', 'title': 'Large Language Models for Supply Chain Decisions', 'authors': 'David Simchi-Levi, Konstantina Mellou, Ishai Menache, Jeevan Pathuri', 'link': 'https://arxiv.org/abs/2507.21502', 'abstract': "Supply Chain Management requires addressing a variety of complex decision-making challenges, from sourcing strategies to planning and execution. Over the last few decades, advances in computation and information technologies have enabled the transition from manual, intuition and experience-based decision-making, into more automated and data-driven decisions using a variety of tools that apply optimization techniques. These techniques use mathematical methods to improve decision-making.\nUnfortunately, business planners and executives still need to spend considerable time and effort to (i) understand and explain the recommendations coming out of these technologies; (ii) analyze various scenarios and answer what-if questions; and (iii) update the mathematical models used in these tools to reflect current business environments. Addressing these challenges requires involving data science teams and/or the technology providers to explain results or make the necessary changes in the technology and hence significantly slows down decision making.\nMotivated by the recent advances in Large Language Models (LLMs), we report how this disruptive technology can democratize supply chain technology - namely, facilitate the understanding of tools' outcomes, as well as the interaction with supply chain tools without human-in-the-loop. Specifically, we report how we apply LLMs to address the three challenges described above, thus substantially reducing the time to decision from days and weeks to minutes and hours as well as dramatically increasing planners' and executives' productivity and impact.", 'abstract_zh': '基于大型语言模型的进展，我们报告了这项颠覆性技术如何使供应链技术 democratize——即促进对工具结果的理解，以及与供应链工具的交互，无需人工介入。具体而言，我们报告了如何应用大型语言模型来解决上述三个挑战，从而将决策时间从几天或几周缩短到几分钟或几小时，显著提高规划者和执行者的生产力和影响力。', 'title_zh': '大型语言模型在供应链决策中的应用'}
{'arxiv_id': 'arXiv:2507.21488', 'title': 'Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess', 'authors': 'Zhenwei Tang, Difan Jiao, Eric Xue, Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Ashton Anderson', 'link': 'https://arxiv.org/abs/2507.21488', 'abstract': 'As humans seek to collaborate with, learn from, and better understand artificial intelligence systems, developing AIs that can accurately emulate individual decision-making becomes increasingly important. Chess, a long-standing AI benchmark with precise skill measurement, offers an ideal testbed for human-AI alignment. However, existing approaches to modeling human behavior require prohibitively large amounts of data from each individual, making them impractical for new or sparsely represented users. In this work, we introduce Maia4All, a framework designed to learn and adapt to individual decision-making styles efficiently, even with limited data. Maia4All achieves this through a two-stage optimization process: (1) an enrichment step, which bridges population and individual-level human behavior modeling with a prototype-enriched model, and (2) a democratization step, which leverages ability levels or user prototypes to initialize and refine individual embeddings with minimal data. Our experimental results show that Maia4All can accurately predict individual moves and profile behavioral patterns with high fidelity, establishing a new standard for personalized human-like AI behavior modeling in chess. Maia4All achieves individual human behavior modeling in chess with only 20 games, compared to the 5,000 games required previously, representing a significant improvement in data efficiency. Our work provides an example of how population AI systems can flexibly adapt to individual users using a prototype-enriched model as a bridge. This approach extends beyond chess, as shown in our case study on idiosyncratic LLMs, highlighting its potential for broader applications in personalized AI adaptation.', 'abstract_zh': '随着人类寻求与人工智能系统合作、学习和更好地理解这些系统，发展能够准确模拟个体决策的人工智能变得越来越重要。国际象棋作为一种长期的人工智能基准，具有精确的技能衡量标准，为人类-人工智能对齐提供了理想的试验平台。然而，现有的人工行为建模方法需要从每个个体收集大量数据，这使得它们对于新用户或稀疏表示的用户来说不切实际。在本文中，我们介绍了一种名为Maia4All的框架，旨在即使在有限数据的情况下也能高效地学习和适应个体的决策风格。Maia4All通过两阶段优化过程实现这一点：（1）丰富步骤，通过原型增强模型将总体和个体水平的人类行为建模连接起来；（2）民主化步骤，利用能力水平或用户原型以最少的数据初始化和精炼个体嵌入。实验结果表明，Maia4All能够准确预测个体走法并高保真地刻画行为模式，为国际象棋中的个性化类人类人工行为建模设立了新标准。Maia4All仅需20场比赛就能实现个体行为建模，与之前所需的5000场比赛相比，显著提高了数据效率。我们的工作提供了一个例子，展示了如何通过原型增强模型作为一种桥梁使总体人工智能系统灵活适应个别用户。这种方法不仅限于国际象棋，在我们对具有独特性的LLMs的案例研究中得到了证明，突显了其在个性化人工智能适应方面的更广泛应用潜力。', 'title_zh': '学习用得更少：象棋中高效个体行为建模'}
{'arxiv_id': 'arXiv:2507.21471', 'title': 'An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning', 'authors': 'Zujie Xie, Zixuan Chen, Jiheng Liang, Xiangyang Yu, Ziru Yu', 'link': 'https://arxiv.org/abs/2507.21471', 'abstract': "Infrared spectroscopy offers rapid, non destructive measurement of chemical and material properties but suffers from high dimensional, overlapping spectral bands that challenge conventional chemometric approaches. Emerging large language models (LLMs), with their capacity for generalization and reasoning, offer promising potential for automating complex scientific workflows. Despite this promise, their application in IR spectral analysis remains largely unexplored. This study addresses the critical challenge of achieving accurate, automated infrared spectral interpretation under low-data conditions using an LLM-driven framework. We introduce an end-to-end, large language model driven agent framework that integrates a structured literature knowledge base, automated spectral preprocessing, feature extraction, and multi task reasoning in a unified pipeline. By querying a curated corpus of peer reviewed IR publications, the agent selects scientifically validated routines. The selected methods transform each spectrum into low dimensional feature sets, which are fed into few shot prompt templates for classification, regression, and anomaly detection. A closed loop, multi turn protocol iteratively appends mispredicted samples to the prompt, enabling dynamic refinement of predictions. Across diverse materials: stamp pad ink, Chinese medicine, Pu'er tea, Citri Reticulatae Pericarpium and waste water COD datasets, the multi turn LLM consistently outperforms single turn inference, rivaling or exceeding machine learning and deep learning models under low data regimes.", 'abstract_zh': '基于大语言模型的红外光谱自动化解析框架：在低数据条件下的准确诠释', 'title_zh': '基于LLM驱动的代理框架实现红外光谱多任务推理自动化'}
{'arxiv_id': 'arXiv:2507.21453', 'title': 'Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)', 'authors': 'Ashley Rector, Keaton Minor, Kamden Minor, Jeff McCormack, Beth Breeden, Ryan Nowers, Jay Dorris', 'link': 'https://arxiv.org/abs/2507.21453', 'abstract': "This study evaluated Sherpa Rx, an artificial intelligence tool leveraging large language models and retrieval-augmented generation (RAG) for pharmacogenomics, to validate its performance on key response metrics. Sherpa Rx integrated Clinical Pharmacogenetics Implementation Consortium (CPIC) guidelines with Pharmacogenomics Knowledgebase (PharmGKB) data to generate contextually relevant responses. A dataset (N=260 queries) spanning 26 CPIC guidelines was used to evaluate drug-gene interactions, dosing recommendations, and therapeutic implications. In Phase 1, only CPIC data was embedded. Phase 2 additionally incorporated PharmGKB content. Responses were scored on accuracy, relevance, clarity, completeness (5-point Likert scale), and recall. Wilcoxon signed-rank tests compared accuracy between Phase 1 and Phase 2, and between Phase 2 and ChatGPT-4omini. A 20-question quiz assessed the tool's real-world applicability against other models. In Phase 1 (N=260), Sherpa Rx demonstrated high performance of accuracy 4.9, relevance 5.0, clarity 5.0, completeness 4.8, and recall 0.99. The subset analysis (N=20) showed improvements in accuracy (4.6 vs. 4.4, Phase 2 vs. Phase 1 subset) and completeness (5.0 vs. 4.8). ChatGPT-4omini performed comparably in relevance (5.0) and clarity (4.9) but lagged in accuracy (3.9) and completeness (4.2). Differences in accuracy between Phase 1 and Phase 2 was not statistically significant. However, Phase 2 significantly outperformed ChatGPT-4omini. On the 20-question quiz, Sherpa Rx achieved 90% accuracy, outperforming other models. Integrating additional resources like CPIC and PharmGKB with RAG enhances AI accuracy and performance. This study highlights the transformative potential of generative AI like Sherpa Rx in pharmacogenomics, improving decision-making with accurate, personalized responses.", 'abstract_zh': '本研究评估了Sherpa Rx这一人工智能工具的表现，该工具利用大型语言模型和检索增强生成（RAG）技术应用于药代遗传学领域，并验证其在关键响应指标上的性能。Sherpa Rx将临床药代遗传学实施 consortium（CPIC）指南与药代遗传学知识库（PharmGKB）数据相结合，生成上下文相关响应。研究使用包含26个CPIC指南的260个查询数据集来评估药物-基因相互作用、剂量建议和治疗意义。第一阶段仅嵌入CPIC数据，第二阶段额外纳入PharmGKB内容。响应依据准确度、相关性、清晰度、完整性和召回率（5级李克特量表）进行评分。威尔科克森符号秩检验比较了第一阶段与第二阶段以及第二阶段与ChatGPT-4omini的准确度。进行了一项包含20个问题的测试评估该工具的实际应用性，对比其他模型。在第一阶段（N=260），Sherpa Rx在准确度（4.9）、相关性（5.0）、清晰度（5.0）、完整度（4.8）和召回率（0.99）方面表现出高水平。子集分析（N=20）显示准确度（4.6 vs. 4.4，第二阶段 vs. 第一阶段子集）和完整度（5.0 vs. 4.8）有所提高。ChatGPT-4omini在相关性（5.0）和清晰度（4.9）方面表现相当，但在准确度（3.9）和完整度（4.2）方面表现不佳。第一阶段和第二阶段之间准确度差异无统计学意义，但第二阶段显著优于ChatGPT-4omini。在20个问题的测试中，Sherpa Rx获得了90%的准确率，超过了其他模型。将CPIC和PharmGKB等额外资源与RAG结合使用，提高了AI的准确性和性能。本研究突显了如Sherpa Rx这类生成式AI在药代遗传学领域的变革潜力，通过提供准确、个性化的响应来改善决策。', 'title_zh': '使用检索增强生成（RAG）验证药代基因组学生成人工智能查询提示的有效性'}
{'arxiv_id': 'arXiv:2507.21438', 'title': 'Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models', 'authors': 'Vishal Raman, Vijai Aravindh R', 'link': 'https://arxiv.org/abs/2507.21438', 'abstract': "Ontologies and knowledge graphs require continuous evolution to remain comprehensive and accurate, but manual curation is labor intensive. Large Language Models (LLMs) possess vast unstructured knowledge but struggle with maintaining structured consistency. We propose Evo-DKD, a novel dual-decoder framework for autonomous ontology evolution that combines structured ontology traversal with unstructured text reasoning. Evo-DKD introduces two parallel decoding streams within an LLM: one decoder generates candidate ontology edits (e.g., new concepts or relations) while the other produces natural-language justifications. A dynamic attention-based gating mechanism coordinates the two streams, deciding at each step how to blend structured and unstructured knowledge. Due to GPU constraints, we simulate the dual-decoder behavior using prompt-based mode control to approximate coordinated decoding in a single-stream mode. The system operates in a closed reasoning loop: proposed ontology edits are validated (via consistency checks and cross-verification with the text explanations) and then injected into the knowledge base, which in turn informs subsequent reasoning. We demonstrate Evo-DKD's effectiveness on use cases including healthcare ontology refinement, semantic search improvement, and cultural heritage timeline modeling. Experiments show that Evo-DKD outperforms baselines using structured-only or unstructured-only decoding in both precision of ontology updates and downstream task performance. We present quantitative metrics and qualitative examples, confirming the contributions of the dual-decoder design and gating router. Evo-DKD offers a new paradigm for LLM-driven knowledge base maintenance, combining the strengths of symbolic and neural reasoning for sustainable ontology evolution.", 'abstract_zh': '基于双解码器框架的自主本体演化方法 Evo-DKD', 'title_zh': 'Evo-DKD：自主大语言模型中双知识解码的本体演化方法'}
{'arxiv_id': 'arXiv:2507.21419', 'title': 'GovRelBench:A Benchmark for Government Domain Relevance', 'authors': 'Haiquan Wang, Yi Chen, Shang Zeng, Yun Bian, Zhe Cui', 'link': 'https://arxiv.org/abs/2507.21419', 'abstract': "Current evaluations of LLMs in the government domain primarily focus on safety considerations in specific scenarios, while the assessment of the models' own core capabilities, particularly domain relevance, remains insufficient. To address this gap, we propose GovRelBench, a benchmark specifically designed for evaluating the core capabilities of LLMs in the government domain. GovRelBench consists of government domain prompts and a dedicated evaluation tool, GovRelBERT. During the training process of GovRelBERT, we introduce the SoftGovScore method: this method trains a model based on the ModernBERT architecture by converting hard labels to soft scores, enabling it to accurately compute the text's government domain relevance score. This work aims to enhance the capability evaluation framework for large models in the government domain, providing an effective tool for relevant research and practice. Our code and dataset are available at this https URL.", 'abstract_zh': '政府领域中当前对大型语言模型的评估主要集中在特定场景下的安全性考量，而对其自身核心能力，尤其是领域相关性的评估仍显不足。为填补这一空白，我们提出了GovRelBench，这是一种专门用于评估政府领域大型语言模型核心能力的基准工具。GovRelBench 包括政府领域提示和专门的评估工具 GovRelBERT。在 GovRelBERT 的训练过程中，我们引入了 SoftGovScore 方法：该方法基于 ModernBERT 架构，通过将硬标签转换为软分数训练模型，使其能够精确计算文本在政府领域的相关性分数。本工作旨在提升政府领域大型模型能力评估框架，并提供有效的研究与实践工具。我们的代码和数据集可通过此链接获得。', 'title_zh': 'GovRelBench：政府领域相关性基准'}
{'arxiv_id': 'arXiv:2507.21407', 'title': 'Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects', 'authors': 'Yixin Liu, Guibin Zhang, Kun Wang, Shiyuan Li, Shirui Pan', 'link': 'https://arxiv.org/abs/2507.21407', 'abstract': 'Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control. While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows. Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work. Specifically, we categorize existing GLA methods by their primary functions in LLM agent systems, including planning, memory, and tool usage, and then analyze how graphs and graph learning algorithms contribute to each. For multi-agent systems, we further discuss how GLA solutions facilitate the orchestration, efficiency optimization, and trustworthiness of MAS. Finally, we highlight key future directions to advance this field, from improving structural adaptability to enabling unified, scalable, and multimodal GLA systems. We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.', 'abstract_zh': '基于大型语言模型的自主代理：图增强方法综述及未来方向', 'title_zh': '图增强大型语言模型代理：当前进展与未来前景'}
{'arxiv_id': 'arXiv:2507.21406', 'title': 'Shapley Uncertainty in Natural Language Generation', 'authors': 'Meilin Zhu, Gaojie Jin, Xiaowei Huang, Lijun Zhang', 'link': 'https://arxiv.org/abs/2507.21406', 'abstract': 'In question-answering tasks, determining when to trust the outputs is crucial to the alignment of large language models (LLMs). Kuhn et al. (2023) introduces semantic entropy as a measure of uncertainty, by incorporating linguistic invariances from the same meaning. It primarily relies on setting threshold to measure the level of semantic equivalence relation. We propose a more nuanced framework that extends beyond such thresholding by developing a Shapley-based uncertainty metric that captures the continuous nature of semantic relationships. We establish three fundamental properties that characterize valid uncertainty metrics and prove that our Shapley uncertainty satisfies these criteria. Through extensive experiments, we demonstrate that our Shapley uncertainty more accurately predicts LLM performance in question-answering and other datasets, compared to similar baseline measures.', 'abstract_zh': '在问答任务中，确定何时信任模型输出对于大型语言模型（LLMs）的对齐至关重要。Kuhn等（2023）通过引入语义熵作为不确定性度量，利用相同含义的语言不变性。该方法主要依赖于设置阈值来衡量语义等价关系的水平。我们提出一个更加精细化的框架，超越这种阈值方法，通过开发基于Shapley值的不确定性度量来捕捉语义关系的连续性。我们确立了三个基本属性来表征有效的不确定性度量，并证明我们的Shapley不确定性满足这些标准。通过大量实验，我们证明了我们的Shapley不确定性在问答和其他数据集上更准确地预测了LLM的表现，与类似的基线度量相比。', 'title_zh': '自然语言生成中的Shapley不确定性'}
{'arxiv_id': 'arXiv:2507.21389', 'title': 'Teaching Language Models To Gather Information Proactively', 'authors': 'Tenghao Huang, Sihao Chen, Muhao Chen, Jonathan May, Longqi Yang, Mengting Wan, Pei Zhou', 'link': 'https://arxiv.org/abs/2507.21389', 'abstract': 'Large language models (LLMs) are increasingly expected to function as collaborative partners, engaging in back-and-forth dialogue to solve complex, ambiguous problems. However, current LLMs often falter in real-world settings, defaulting to passive responses or narrow clarifications when faced with incomplete or under-specified prompts, falling short of proactively gathering the missing information that is crucial for high-quality solutions. In this work, we introduce a new task paradigm: proactive information gathering, where LLMs must identify gaps in the provided context and strategically elicit implicit user knowledge through targeted questions. To systematically study and train this capability, we design a scalable framework that generates partially specified, real-world tasks, masking key information and simulating authentic ambiguity. Within this setup, our core innovation is a reinforcement finetuning strategy that rewards questions that elicit genuinely new, implicit user information -- such as hidden domain expertise or fine-grained requirements -- that would otherwise remain unspoken. Experiments demonstrate that our trained Qwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic evaluation metrics. More importantly, human evaluation reveals that clarification questions and final outlines generated by our model are favored by human annotators by 42% and 28% respectively. Together, these results highlight the value of proactive clarification in elevating LLMs from passive text generators to genuinely collaborative thought partners.', 'abstract_zh': '大型语言模型（LLMs）日益被期望作为协作伙伴，在前后对话中解决复杂、模糊的问题。然而，当前的LLMs在实际应用中往往在面对不完整或描述不清的提示时表现不佳，倾向于给出被动反应或狭窄澄清，未能主动收集高质量解决方案所需的关键缺失信息。本文介绍了一个新的任务范式：主动信息收集，要求LLMs识别提供的背景中的信息缺口，并通过针对性的问题来策略性地激发用户的隐含知识。为系统地研究和训练这一能力，我们设计了一个可扩展的框架，生成部分指定的、现实世界中的任务，屏蔽关键信息并模拟真实的模糊性。在这种设置中，我们的核心创新是一个强化微调策略，奖励那些激发真正新且隐含用户信息的问题，例如隐藏的专业知识或细粒度的要求，这些信息否则将不会被提及。实验结果显示，我们训练的Qwen-2.5-7B模型在自动评估指标上比o3-mini高18%。更重要的是，人工评估表明，由我们的模型生成的澄清问题和最终概述分别获得了42%和28%的人工注释者青睐。这些结果共同强调了主动澄清的价值，使LLMs从被动文本生成者转变为真正的合作思维伙伴。', 'title_zh': '教学语言模型主动获取信息'}
{'arxiv_id': 'arXiv:2507.21383', 'title': 'Optimizing Multi-Tier Supply Chain Ordering with LNN+XGBoost: Mitigating the Bullwhip Effect', 'authors': 'Chunan Tong', 'link': 'https://arxiv.org/abs/2507.21383', 'abstract': "Supply chain management faces significant challenges, including demand fluctuations, inventory imbalances, and amplified upstream order variability due to the bullwhip effect. Traditional methods, such as simple moving averages, struggle to address dynamic market conditions. Emerging machine learning techniques, including LSTM, reinforcement learning, and XGBoost, offer potential solutions but are limited by computational complexity, training inefficiencies, or constraints in time-series modeling. Liquid Neural Networks, inspired by dynamic biological systems, present a promising alternative due to their adaptability, low computational cost, and robustness to noise, making them suitable for real-time decision-making and edge computing. Despite their success in applications like autonomous vehicles and medical monitoring, their potential in supply chain optimization remains underexplored. This study introduces a hybrid LNN and XGBoost model to optimize ordering strategies in multi-tier supply chains. By leveraging LNN's dynamic feature extraction and XGBoost's global optimization capabilities, the model aims to mitigate the bullwhip effect and enhance cumulative profitability. The research investigates how local and global synergies within the hybrid framework address the dual demands of adaptability and efficiency in SCM. The proposed approach fills a critical gap in existing methodologies, offering an innovative solution for dynamic and efficient supply chain management.", 'abstract_zh': '基于液态神经网络和XGBoost的 hybrid 模型在多层供应链中的订货策略优化', 'title_zh': '基于LNN+XGBoost优化多级供应链订单：减轻牛鞭效应'}
{'arxiv_id': 'arXiv:2507.21360', 'title': 'Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures', 'authors': 'Nicholas Botti, Flora Haberkorn, Charlotte Hoopes, Shaun Khan', 'link': 'https://arxiv.org/abs/2507.21360', 'abstract': 'We utilize a within-subjects design with randomized task assignments to understand the effectiveness of using an AI retrieval augmented generation (RAG) tool to assist analysts with an information extraction and data annotation task. We replicate an existing, challenging real-world annotation task with complex multi-part criteria on a set of thousands of pages of public disclosure documents from global systemically important banks (GSIBs) with heterogeneous and incomplete information content. We test two treatment conditions. First, a "naive" AI use condition in which annotators use only the tool and must accept the first answer they are given. And second, an "interactive" AI treatment condition where annotators use the tool interactively, and use their judgement to follow-up with additional information if necessary. Compared to the human-only baseline, the use of the AI tool accelerated task execution by up to a factor of 10 and enhanced task accuracy, particularly in the interactive condition. We find that when extrapolated to the full task, these methods could save up to 268 hours compared to the human-only approach. Additionally, our findings suggest that annotator skill, not just with the subject matter domain, but also with AI tools, is a factor in both the accuracy and speed of task performance.', 'abstract_zh': '我们利用一种被试内设计并随机分配任务的方法，研究AI检索增强生成（RAG）工具在信息提取和数据标注任务中对分析师的辅助效果。我们复制了一个现有且具有挑战性的实际注释任务，该任务包含复杂的多部分标准，并应用在网络全球系统重要性银行（GSIBs）数千页的公开披露文件上，这些文件包括异质性和不完整的信息内容。我们测试了两种条件。首先，一个简单的AI使用条件，注释者仅使用工具并必须接受最初提供的答案；其次，一个互动的AI治疗条件，注释者可以互动地使用工具，并在必要时利用自己的判断获取额外信息。与仅有人类参与的基线相比，使用AI工具将任务执行速度最多加快10倍，并显著提高任务准确性，尤其是在互动条件下。我们的研究发现，当应用到整个任务时，这些方法相较于仅有人类参与的方法最多可节省268小时。此外，我们的研究结果表明，注释者的技能，不仅在于专业知识领域，也在于对AI工具的掌握，是任务准确性和速度的关键因素。', 'title_zh': 'AI RAG工具在复杂信息提取和数据标注任务中的有效性：以银行公开披露为例的研究'}
{'arxiv_id': 'arXiv:2507.21354', 'title': 'Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems', 'authors': 'Monika Zamojska, Jarosław A. Chudziak', 'link': 'https://arxiv.org/abs/2507.21354', 'abstract': "Multi-Agent Systems (MAS) are increasingly used to simulate social interactions, but most of the frameworks miss the underlying cognitive complexity of human behavior. In this paper, we introduce Trans-ACT (Transactional Analysis Cognitive Toolkit), an approach embedding Transactional Analysis (TA) principles into MAS to generate agents with realistic psychological dynamics. Trans-ACT integrates the Parent, Adult, and Child ego states into an agent's cognitive architecture. Each ego state retrieves context-specific memories and uses them to shape response to new situations. The final answer is chosen according to the underlying life script of the agent. Our experimental simulation, which reproduces the Stupid game scenario, demonstrates that agents grounded in cognitive and TA principles produce deeper and context-aware interactions. Looking ahead, our research opens a new way for a variety of applications, including conflict resolution, educational support, and advanced social psychology studies.", 'abstract_zh': '多Agent系统（MAS）越来越多地用于模拟社会互动，但大多数框架忽略了人类行为的内在认知复杂性。本文介绍了Transaction Analysis Cognitive Toolkit（Trans-ACT）方法，将Transaction Analysis（TA）原则嵌入到MAS中，以生成具有现实心理动态的代理。Trans-ACT将父母、成人和儿童自我状态整合到代理的认知架构中。每个自我状态检索特定于上下文的记忆，并使用它们来塑造对新情况的响应。最终的答案根据代理的基本生活脚本进行选择。我们的实验仿真重现了愚蠢游戏场景，表明基于认知和TA原则的代理能够产生更深和情境相关的互动。展望未来，我们的研究为冲突解决、教育支持和高级社会心理学研究等多种应用开辟了新的途径。', 'title_zh': '游戏中的代理法则：迈向基于LLM的多代理系统中的交易分析'}
{'arxiv_id': 'arXiv:2507.21287', 'title': 'Structured Relevance Assessment for Robust Retrieval-Augmented Language Models', 'authors': 'Aryan Raj, Astitva Veer Garg, Anitha D', 'link': 'https://arxiv.org/abs/2507.21287', 'abstract': 'Retrieval-Augmented Language Models (RALMs) face significant challenges in reducing factual errors, particularly in document relevance evaluation and knowledge integration. We introduce a framework for structured relevance assessment that enhances RALM robustness through improved document evaluation, balanced intrinsic and external knowledge integration, and effective handling of unanswerable queries. Our approach employs a multi-dimensional scoring system that considers both semantic matching and source reliability, utilizing embedding-based relevance scoring and synthetic training data with mixed-quality documents. We implement specialized benchmarking on niche topics, a knowledge integration mechanism, and an "unknown" response protocol for queries with insufficient knowledge coverage. Preliminary evaluations demonstrate significant reductions in hallucination rates and improved transparency in reasoning processes. Our framework advances the development of more reliable question-answering systems capable of operating effectively in dynamic environments with variable data quality. While challenges persist in accurately distinguishing credible information and balancing system latency with thoroughness, this work represents a meaningful step toward enhancing RALM reliability.', 'abstract_zh': '结构化相关性评估框架：增强检索增强语言模型的鲁棒性', 'title_zh': '结构化相关性评估以提高检索增强语言模型的鲁棒性'}
{'arxiv_id': 'arXiv:2507.21285', 'title': 'Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions', 'authors': 'Harsh Darji, Thibaud Lutellier', 'link': 'https://arxiv.org/abs/2507.21285', 'abstract': "Large Language Models (LLMs) are increasingly used as coding assistants. However, the ambiguity of the developer's prompt often leads to incorrect code generation, as current models struggle to infer user intent without extensive prompt engineering or external context. This work aims to build an LLM-based coding assistant that mimics the human code review process by asking clarification questions when faced with ambiguous or under-specified queries.\nOur end-to-end system includes (1) a query classifier trained to detect unclear programming-related queries and (2) a fine-tuned LLM that generates clarification questions. Our evaluation shows that the fine-tuned LLM outperforms standard zero-shot prompting in generating useful clarification questions. Furthermore, our user study indicates that users find the clarification questions generated by our model to outperform the baseline, demonstrating that our coding assistant produces more accurate and helpful code responses compared to baseline coding assistants.", 'abstract_zh': '大型语言模型（LLMs）越来越多地被用作编程助手。然而，开发者的模糊提示往往导致代码生成错误，因为当前模型在没有大量提示工程或外部上下文的情况下难以推断用户意图。本文旨在构建一个基于LLM的编程助手，该助手在面对模糊或描述不足的查询时会询问澄清问题，以模仿人类的代码审查过程。我们的端到端系统包括（1）一个查询分类器，训练用于检测含糊的编程相关查询，以及（2）一个微调后的LLM，用于生成澄清问题。我们的评估表明，微调后的LLM在生成有用的澄清问题方面优于标准的零-shot提示。此外，我们的用户研究显示，用户认为由我们的模型生成的澄清问题优于基线，这表明我们的编程助手相比于基线编程助手能产生更准确和有帮助的代码响应。', 'title_zh': '设计好奇心：基于LLM的编程助手提问澄清问题'}
{'arxiv_id': 'arXiv:2507.21276', 'title': 'LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems', 'authors': 'Yufei Li, Zexin Li, Yinglun Zhu, Cong Liu', 'link': 'https://arxiv.org/abs/2507.21276', 'abstract': 'Modern deployment of large language models (LLMs) frequently involves both inference serving and continuous retraining to stay aligned with evolving data and user feedback. Common practices separate these workloads onto distinct servers in isolated phases, causing substantial inefficiencies (e.g., GPU idleness) and delayed adaptation to new data in distributed settings. Our empirical analysis reveals that these inefficiencies stem from dynamic request arrivals during serving and workload heterogeneity in pipeline-parallel training. To address these challenges, we propose LeMix, a system for co-locating and managing concurrent LLM serving and training workloads. LeMix integrates offline profiling, execution prediction mechanisms, and runtime scheduling to dynamically adapt resource allocation based on workload characteristics and system conditions. By understanding task-specific behaviors and co-execution interference across shared nodes, LeMix improves utilization and serving quality without compromising serving responsiveness. Our evaluation shows that LeMix improves throughput by up to 3.53x, reduces inference loss by up to 0.61x, and delivers up to 2.12x higher response time SLO attainment over traditional separate setups. To our knowledge, this is the first work to uncover and exploit the opportunities of joint LLM inference and training, paving the way for more resource-efficient deployment of LLMs in production environments.', 'abstract_zh': '现代大规模语言模型的部署通常涉及推理服务和连续重训练，以保持与 evolving 数据和用户反馈的一致性。常见的做法是将这些工作负载分离到不同的服务器上，在孤立的阶段进行处理，导致了显著的低效（例如，GPU空闲）并在分布式环境中延迟了对新数据的适应。我们的实证分析表明，这些低效源于服务过程中的动态请求到达和管道并行训练中的工作负载异构性。为解决这些挑战，我们提出了一种名为 LeMix 的系统，用于同时管理和调度并发的语言模型服务和训练工作负载。LeMix 结合了离线分析、执行预测机制和运行时调度，根据工作负载特征和系统条件动态调整资源分配。通过理解特定任务的行为以及在共享节点上的并发执行干扰，LeMix 在不牺牲响应性的前提下提高了利用率和服务质量。我们的评估结果表明，与传统的分离设置相比，LeMix 可以将吞吐量提高 3.53 倍，降低推理损失 0.61 倍，并实现响应时间 SLO 达成率提高 2.12 倍。据我们所知，这是首次研究和利用联合语言模型推理和训练的机会，为生产环境中的大规模语言模型更高效的部署铺平了道路。', 'title_zh': 'LeMix: 统一调度框架用于多GPU系统中的LLM训练与推理'}
{'arxiv_id': 'arXiv:2507.21257', 'title': 'CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting', 'authors': 'David Maria Schmidt, Raoul Schubert, Philipp Cimiano', 'link': 'https://arxiv.org/abs/2507.21257', 'abstract': 'Language interpretation is a compositional process, in which the meaning of more complex linguistic structures is inferred from the meaning of their parts. Large language models possess remarkable language interpretation capabilities and have been successfully applied to interpret questions by mapping them to SPARQL queries. An open question is how systematic this interpretation process is. Toward this question, in this paper, we propose a benchmark for investigating to what extent the abilities of LLMs to interpret questions are actually compositional. For this, we generate three datasets of varying difficulty based on graph patterns in DBpedia, relying on Lemon lexica for verbalization. Our datasets are created in a very controlled fashion in order to test the ability of LLMs to interpret structurally complex questions, given that they have seen the atomic building blocks. This allows us to evaluate to what degree LLMs are able to interpret complex questions for which they "understand" the atomic parts. We conduct experiments with models of different sizes using both various prompt and few-shot optimization techniques as well as fine-tuning. Our results show that performance in terms of macro $F_1$ degrades from $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the samples optimized on. Even when all necessary information was provided to the model in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of lowest complexity. We thus conclude that LLMs struggle to systematically and compositionally interpret questions and map them into SPARQL queries.', 'abstract_zh': '语言解释是一个组合过程，在这个过程中，更复杂的语言结构的意义是从其组成部分的意义中推断出来的。大规模语言模型具备显著的语言解释能力，并且成功地被应用到通过将其映射到SPARQL查询上解释问题中。一个开放的问题是这个解释过程是否系统化。为此，本文提出一个基准，用于调查语言模型解释问题的能力实际上在多大程度上是组合性的。为此，我们基于DBpedia中的图模式生成三个不同难度级别的数据集，并依赖于Lemon词典进行言语化。我们的数据集以非常受控的方式创建，以测试语言模型在给定它们见过的原子构建块的情况下解释结构复杂问题的能力。这使我们能够评估语言模型在理解原子部分的情况下，解释复杂问题的程度。我们使用不同大小的模型进行实验，并结合使用各种提示技术和少量示例优化以及微调方法。我们的结果显示，随着与优化样本的偏差增加，宏$F_1$值从0.45下降到0.26，再下降到0.09。即使在输入中提供了所有必要信息，对于最简单复杂度的数据集，$F_1$得分也不超过0.57。因此，我们得出结论，语言模型在系统性和组合性地解释问题并将它们映射到SPARQL查询方面存在困难。', 'title_zh': 'CompoST：在QALD环境中分析LLMs组合解释问题能力的基准'}
{'arxiv_id': 'arXiv:2507.21206', 'title': 'Agentic Web: Weaving the Next Web with AI Agents', 'authors': 'Yingxuan Yang, Mulei Ma, Yuxuan Huang, Huacan Chai, Chenyu Gong, Haoran Geng, Yuanjian Zhou, Ying Wen, Meng Fang, Muhao Chen, Shangding Gu, Ming Jin, Costas Spanos, Yang Yang, Pieter Abbeel, Dawn Song, Weinan Zhang, Jun Wang', 'link': 'https://arxiv.org/abs/2507.21206', 'abstract': 'The emergence of AI agents powered by large language models (LLMs) marks a pivotal shift toward the Agentic Web, a new phase of the internet defined by autonomous, goal-driven interactions. In this paradigm, agents interact directly with one another to plan, coordinate, and execute complex tasks on behalf of users. This transition from human-driven to machine-to-machine interaction allows intent to be delegated, relieving users from routine digital operations and enabling a more interactive, automated web experience. In this paper, we present a structured framework for understanding and building the Agentic Web. We trace its evolution from the PC and Mobile Web eras and identify the core technological foundations that support this shift. Central to our framework is a conceptual model consisting of three key dimensions: intelligence, interaction, and economics. These dimensions collectively enable the capabilities of AI agents, such as retrieval, recommendation, planning, and collaboration. We analyze the architectural and infrastructural challenges involved in creating scalable agentic systems, including communication protocols, orchestration strategies, and emerging paradigms such as the Agent Attention Economy. We conclude by discussing the potential applications, societal risks, and governance issues posed by agentic systems, and outline research directions for developing open, secure, and intelligent ecosystems shaped by both human intent and autonomous agent behavior. A continuously updated collection of relevant studies for agentic web is available at: this https URL.', 'abstract_zh': '大型语言模型驱动的AI代理的出现标志着向能动互联网的转折点，这一新阶段的互联网由自主的目标驱动交互定义。在这种范式中，代理直接与彼此交互，计划、协调并代表用户执行复杂的任务。从人力驱动到机器间交互的转变使用户能够将意图委托给AI代理，从而减轻用户处理常规数字操作的负担，并提供更交互式和自动化的网络体验。在本文中，我们提出了一个结构化的框架，用于理解和构建能动互联网。我们追踪其从个人计算机和移动互联网时代的演变，并确定支持这一转变的核心技术基础。在我们框架的核心是一个概念模型，包含三个关键维度：智能、互动和经济。这些维度共同赋予AI代理检索、推荐、规划和协作的能力。我们分析了构建可扩展的能动系统所涉及的架构和基础设施挑战，包括通信协议、编排策略以及正在兴起的如代理注意力经济等概念。最后，我们讨论了能动系统可能带来的应用、社会风险和治理问题，并概述了研发开放、安全和智能生态系统的研究方向，该生态由人类意图和自主代理行为共同塑造。相关研究的持续更新列表可访问：this https URL。', 'title_zh': '代理网格：用AI代理编织下一个网络'}
{'arxiv_id': 'arXiv:2507.21176', 'title': "Tell Me You're Biased Without Telling Me You're Biased -- Toward Revealing Implicit Biases in Medical LLMs", 'authors': 'Farzana Islam Adiba, Rahmatollah Beheshti', 'link': 'https://arxiv.org/abs/2507.21176', 'abstract': 'Large language models (LLMs) that are used in medical applications are known to show biased and unfair patterns. Prior to adopting these in clinical decision-making applications, it is crucial to identify these bias patterns to enable effective mitigation of their impact. In this study, we present a novel framework combining knowledge graphs (KGs) with auxiliary LLMs to systematically reveal complex bias patterns in medical LLMs. Specifically, the proposed approach integrates adversarial perturbation techniques to identify subtle bias patterns. The approach adopts a customized multi-hop characterization of KGs to enhance the systematic evaluation of arbitrary LLMs. Through a series of comprehensive experiments (on three datasets, six LLMs, and five bias types), we show that our proposed framework has noticeably greater ability and scalability to reveal complex biased patterns of LLMs compared to other baselines.', 'abstract_zh': '大规模语言模型在医疗应用中显示出偏见和不公平模式。在将其应用于临床决策之前，识别这些偏见模式以有效减轻其影响至关重要。本研究提出了一种结合知识图谱与辅助语言模型的新框架，以系统地揭示医疗语言模型中的复杂偏见模式。具体而言，该方法整合了对抗性扰动技术以识别微妙的偏见模式。采用定制化的多跳表征知识图谱以增强任意语言模型的系统评估能力。通过一系列全面的实验（涉及三种数据集、六种语言模型和五种偏见类型），我们证明所提出框架在揭示语言模型的复杂偏见模式方面具有明显更强的能力和可扩展性，与其他基准方法相比。', 'title_zh': '不说破偏见——揭示医疗LLM中的隐性偏见'}
{'arxiv_id': 'arXiv:2507.21172', 'title': 'Ontological Foundations of State Sovereignty', 'authors': 'John Beverley, Danielle Limbaugh', 'link': 'https://arxiv.org/abs/2507.21172', 'abstract': 'This short paper is a primer on the nature of state sovereignty and the importance of claims about it. It also aims to reveal (merely reveal) a strategy for working with vague or contradictory data about which states, in fact, are sovereign. These goals together are intended to set the stage for applied work in ontology about international affairs.', 'abstract_zh': '这篇简短的论文是对国家主权本质及其主张重要性的基础介绍，同时也旨在揭示（仅仅揭示）处理有关哪些国家实际上享有主权的模糊或矛盾数据的一种策略。这些目标旨在为关于国际事务的本体论应用工作奠定基础。', 'title_zh': '国家主权的本体论基础'}
{'arxiv_id': 'arXiv:2507.21171', 'title': 'An ontological analysis of risk in Basic Formal Ontology', 'authors': 'Federico Donato, Adrien Barton', 'link': 'https://arxiv.org/abs/2507.21171', 'abstract': 'The paper explores the nature of risk, providing a characterization using the categories of the Basic Formal Ontology (BFO). It argues that the category Risk is a subclass of BFO:Role, contrasting it with a similar view classifying Risk as a subclass of BFO:Disposition. This modeling choice is applied on one example of risk, which represents objects, processes (both physical and mental) and their interrelations, then generalizing from the instances in the example to obtain an overall analysis of risk, making explicit what are the sufficient conditions for being a risk. Plausible necessary conditions are also mentioned for future work. Index Terms: ontology, risk, BFO, role, disposition', 'abstract_zh': '该论文探讨了风险的本质，使用基本形式本体（BFO）的类别对风险进行刻画。它认为风险类别是BFO:Role的子类别，将其与将风险归类为BFO:Disposition的类似观点区分开来。这种建模选择应用于风险的一个实例，该实例代表物体、过程（包括物理和心理过程）及其相互关系，然后从该实例中的实例中概括，以获得对风险的整体分析，明确说明成为风险所需的充分条件。还提到了一些有说服力的必要条件供未来工作参考。关键词：本体、风险、BFO、角色、倾向。', 'title_zh': '基本形式本体中风险的本体分析'}
{'arxiv_id': 'arXiv:2507.21162', 'title': 'Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems', 'authors': 'Xu Yang, Chenhui Lin, Yue Yang, Qi Wang, Haotian Liu, Haizhou Hua, Wenchuan Wu', 'link': 'https://arxiv.org/abs/2507.21162', 'abstract': 'The increasing penetration of distributed energy resources into active distribution networks (ADNs) has made effective ADN dispatch imperative. However, the numerous newly-integrated ADN operators, such as distribution system aggregators, virtual power plant managers, and end prosumers, often lack specialized expertise in power system operation, modeling, optimization, and programming. This knowledge gap renders reliance on human experts both costly and time-intensive. To address this challenge and enable intelligent, flexible ADN dispatch, this paper proposes a large language model (LLM) powered automated modeling and optimization approach. First, the ADN dispatch problems are decomposed into sequential stages, and a multi-LLM coordination architecture is designed. This framework comprises an Information Extractor, a Problem Formulator, and a Code Programmer, tasked with information retrieval, optimization problem formulation, and code implementation, respectively. Afterwards, tailored refinement techniques are developed for each LLM agent, greatly improving the accuracy and reliability of generated content. The proposed approach features a user-centric interface that enables ADN operators to derive dispatch strategies via simple natural language queries, eliminating technical barriers and increasing efficiency. Comprehensive comparisons and end-to-end demonstrations on various test cases validate the effectiveness of the proposed architecture and methods.', 'abstract_zh': '分布式能源资源日益融入活跃配电网络（ADNs）使得有效的ADN调度变得必不可少。然而，众多新集成的ADN运营商，如配电系统聚合商、虚拟电厂管理者和终端产消者，往往缺乏电力系统操作、建模、优化和编程的专业知识。这种知识缺口使得依赖人类专家变得既昂贵又耗时。为应对这一挑战并实现智能、灵活的ADN调度，本文提出了一种由大型语言模型（LLM）驱动的自动化建模和优化方法。首先，将ADN调度问题分解为一系列阶段，并设计了一个多LLM协调架构。该框架包括信息提取器、问题构建筑师和代码编程器，分别负责信息检索、优化问题建模和代码实现。随后，为每个LLM代理开发了定制的细化技术，大幅提高了生成内容的准确性和可靠性。该提出的方案具有用户中心的界面，使ADN运营商能够通过简单的自然语言查询生成调度策略，从而消除技术障碍并提高效率。综合比较和端到端演示在多种测试案例上的有效性验证了所提出架构和方法的有效性。', 'title_zh': '由大规模语言模型驱动的主动配电网调度问题自动化建模与优化'}
{'arxiv_id': 'arXiv:2507.21159', 'title': 'Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity', 'authors': 'Zhihao Peng, Liuxin Bao, Shengyuan Liu, Yixuan Yuan', 'link': 'https://arxiv.org/abs/2507.21159', 'abstract': 'The collaborativeness of large language models (LLMs) has proven effective in natural language processing systems, holding considerable promise for healthcare development. However, it lacks explicit component selection rules, necessitating human intervention or clinical-specific validation. Moreover, existing architectures heavily rely on a predefined LLM cluster, where partial LLMs underperform in medical decision support scenarios, invalidating the collaborativeness of LLMs. To this end, we propose an adaptive cluster collaborativeness methodology involving self-diversity and cross-consistency maximization mechanisms to boost LLMs medical decision support capacity. For the self-diversity, we calculate the fuzzy matching value of pairwise outputs within an LLM as its self-diversity value, subsequently prioritizing LLMs with high self-diversity values as cluster components in a training-free manner. For the cross-consistency, we first measure cross-consistency values between the LLM with the highest self-diversity value and others, and then gradually mask out the LLM having the lowest cross-consistency value to eliminate the potential inconsistent output during the collaborative propagation. Extensive experiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health, demonstrate the effectiveness of our method across physician-oriented specialties. For example, on NEJMQA, our method achieves the accuracy rate up to the publicly official passing score across all disciplines, especially achieving ACC of 65.47\\% compared to the 56.12\\% achieved by GPT-4 on the Obstetrics and Gynecology discipline.', 'abstract_zh': '大型语言模型的协作性在自然语言处理系统中表现有效，对医疗健康的发展充满潜力。然而，缺乏明确的组件选择规则，需要人工干预或针对临床的具体验证。此外，现有架构严重依赖预定义的大型语言模型集群，其中部分大型语言模型在医疗决策支持场景下表现不佳，质疑了大型语言模型协作性的有效性。为此，我们提出了一种自适应集群协作性方法，该方法通过最大化自我多样性和跨一致性机制来提升大型语言模型的医疗决策支持能力。对于自我多样性，我们通过计算大型语言模型内成对输出的模糊匹配值来确定其自我多样性值，并在无需训练的情况下优先选择高自我多样性值的大型语言模型作为集群组件。对于跨一致性，我们首先测量具有最高自我多样性值的大型语言模型与其他大型语言模型之间的跨一致性值，然后逐步掩盖具有最低跨一致性值的大型语言模型，以消除协作传播过程中潜在的一致性输出冲突。在两个专门的医疗数据集NEJMQA和MMLU-Pro-health上的广泛实验表明，我们的方法在面向医生的专业领域中表现出有效性。例如，在NEJMQA数据集上，我们的方法在全部学科中达到了公开官方通过分数线的准确率，特别是在妇产科学科中，我们的方法的准确率（ACC）达到了65.47%，而GPT-4的准确率为56.12%。', 'title_zh': '自适应集群协作性增强大语言模型在医学决策支持中的能力'}
{'arxiv_id': 'arXiv:2507.21158', 'title': 'Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams', 'authors': 'Nishani Fernando, Bahareh Nakisa, Adnan Ahmad, Mohammad Naim Rastgoo', 'link': 'https://arxiv.org/abs/2507.21158', 'abstract': "Effective human-AI teaming heavily depends on swift trust, particularly in high-stakes scenarios such as emergency response, where timely and accurate decision-making is critical. In these time-sensitive and cognitively demanding settings, adaptive explainability is essential for fostering trust between human operators and AI systems. However, existing explainable AI (XAI) approaches typically offer uniform explanations and rely heavily on explicit feedback mechanisms, which are often impractical in such high-pressure scenarios. To address this gap, we propose a conceptual framework for adaptive XAI that operates non-intrusively by responding to users' real-time cognitive and emotional states through implicit feedback, thereby enhancing swift trust in high-stakes environments. The proposed adaptive explainability trust framework (AXTF) leverages physiological and behavioral signals, such as EEG, ECG, and eye tracking, to infer user states and support explanation adaptation. At its core is a multi-objective, personalized trust estimation model that maps workload, stress, and emotion to dynamic trust estimates. These estimates guide the modulation of explanation features enabling responsive and personalized support that promotes swift trust in human-AI collaboration. This conceptual framework establishes a foundation for developing adaptive, non-intrusive XAI systems tailored to the rigorous demands of high-pressure, time-sensitive environments.", 'abstract_zh': '适应性人机团队中的解释性信任框架：在高压力、时间敏感环境中促进快速信任', 'title_zh': '高风险环境中的自适应XAI：基于多模态反馈建模人类AI团队中的快速信任'}
{'arxiv_id': 'arXiv:2507.21141', 'title': 'The Geometry of Harmfulness in LLMs through Subconcept Probing', 'authors': "McNair Shah, Saleena Angeline, Adhitya Rajendra Kumar, Naitik Chheda, Kevin Zhu, Vasu Sharma, Sean O'Brien, Will Cai", 'link': 'https://arxiv.org/abs/2507.21141', 'abstract': "Recent advances in large language models (LLMs) have intensified the need to understand and reliably curb their harmful behaviours. We introduce a multidimensional framework for probing and steering harmful content in model internals. For each of 55 distinct harmfulness subconcepts (e.g., racial hate, employment scams, weapons), we learn a linear probe, yielding 55 interpretable directions in activation space. Collectively, these directions span a harmfulness subspace that we show is strikingly low-rank. We then test ablation of the entire subspace from model internals, as well as steering and ablation in the subspace's dominant direction. We find that dominant direction steering allows for near elimination of harmfulness with a low decrease in utility. Our findings advance the emerging view that concept subspaces provide a scalable lens on LLM behaviour and offer practical tools for the community to audit and harden future generations of language models.", 'abstract_zh': 'Recent advances in大规模语言模型（LLMs）加强了理解并可靠地遏制其有害行为的必要性。我们引入了一个多维度框架，用于探测和引导模型内部的有害内容。对于55个不同的有害性子概念（如种族仇恨、就业诈骗、武器），我们学习了一个线性探测器，生成了55个可解释的方向向量。这些方向共同构成了一个低秩的有害性子空间，我们展示了该子空间是极其低秩的。随后，我们在模型内部消融整个子空间，并在子空间的主要方向上进行引导和消融。我们发现，在主要方向上进行引导可以近乎完全消除有害性，同时保持较低的效用损失。我们的发现推进了当前认为的概念子空间提供了一种可扩展的视角来审视LLM行为，并为社区提供了实用工具，以审查和强化未来语言模型。', 'title_zh': 'LLMs中危害性几何学通过子概念探测'}
{'arxiv_id': 'arXiv:2507.21137', 'title': 'Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?', 'authors': 'Arman Eisenkolb-Vaithyanathan', 'link': 'https://arxiv.org/abs/2507.21137', 'abstract': 'In this paper we try to answer the question "What constitutes Sudoku difficulty rating across different Sudoku websites?" Using two distinct methods that can both solve every Sudoku puzzle, I propose two new metrics to characterize Sudoku difficulty. The first method is based on converting a Sudoku puzzle into its corresponding Satisfiability (SAT) problem. The first proposed metric is derived from SAT Clause Length Distribution which captures the structural complexity of a Sudoku puzzle including the number of given digits and the cells they are in. The second method simulates human Sudoku solvers by intertwining four popular Sudoku strategies within a backtracking algorithm called Nishio. The second metric is computed by counting the number of times Sudoku strategies are applied within the backtracking iterations of a randomized Nishio. Using these two metrics, I analyze more than a thousand Sudoku puzzles across five popular websites to characterize every difficulty level in each website. I evaluate the relationship between the proposed metrics and website-labeled difficulty levels using Spearman\'s rank correlation coefficient, finding strong correlations for 4 out of 5 websites. I construct a universal rating system using a simple, unsupervised classifier based on the two proposed metrics. This rating system is capable of classifying both individual puzzles and entire difficulty levels from the different Sudoku websites into three categories - Universal Easy, Universal Medium, and Universal Hard - thereby enabling consistent difficulty mapping across Sudoku websites. The experimental results show that for 4 out of 5 Sudoku websites, the universal classification aligns well with website-labeled difficulty levels. Finally, I present an algorithm that can be used by early Sudoku practitioners to solve Sudoku puzzles.', 'abstract_zh': '在这篇文章中，我们尝试回答“不同数独网站上的数独难度评级由什么构成？”的问题。使用两种可以解决所有数独谜题的不同方法，我们提出两种新的指标来表征数独难度。首先，基于将数独谜题转换为其相应的可满足性（SAT）问题的方法。第一个提出的指标源自SAT子句长度分布，它可以捕捉数独谜题的结构性复杂度，包括已给定的数字数量及其所在的单元格。其次，通过在回溯算法Nishio中交织四种流行的数独策略来模拟人类解数独的过程。第二个指标通过计算在一个随机化Nishio的回溯迭代过程中应用数独策略的次数来计算。利用这两个指标，我们分析了五个热门网站上的上千个数独谜题，以表征每个网站上的每一难度级别。我们使用斯皮尔曼等级相关系数评估所提指标与网站标注难度等级之间的关系，发现有4个网站显示出强烈的相关性。我们基于这两个提出的指标构建了一个通用评分系统，该系统能够对来自不同数独网站的单个谜题和整个难度等级进行分类，归为三类：通用简单、通用中等和通用困难，从而在数独网站之间实现一致的难度映射。实验结果显示，对于4个数独网站，通用分类与网站标注难度等级吻合良好。最后，我们提出了一种算法，早期数独实践者可以使用该算法来解决数独谜题。', 'title_zh': 'Patti项目：为什么你能在一个数独网站上解决恶棍级谜题却不能在另一个网站上解决简单级谜题？'}
{'arxiv_id': 'arXiv:2507.21132', 'title': 'Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses', 'authors': 'Joshua Adrian Cahyono, Saran Subramanian', 'link': 'https://arxiv.org/abs/2507.21132', 'abstract': 'Large Language Models (LLMs) are increasingly consulted for high-stakes life advice, yet they lack standard safeguards against providing confident but misguided responses. This creates risks of sycophancy and over-confidence. This paper investigates these failure modes through three experiments: (1) a multiple-choice evaluation to measure model stability against user pressure; (2) a free-response analysis using a novel safety typology and an LLM Judge; and (3) a mechanistic interpretability experiment to steer model behavior by manipulating a "high-stakes" activation vector. Our results show that while some models exhibit sycophancy, others like o4-mini remain robust. Top-performing models achieve high safety scores by frequently asking clarifying questions, a key feature of a safe, inquisitive approach, rather than issuing prescriptive advice. Furthermore, we demonstrate that a model\'s cautiousness can be directly controlled via activation steering, suggesting a new path for safety alignment. These findings underscore the need for nuanced, multi-faceted benchmarks to ensure LLMs can be trusted with life-changing decisions.', 'abstract_zh': '大型语言模型（LLMs）在提供高风险生活建议时越来越受到咨询，但它们缺乏标准的安全保障，以防止提供自信但误导性的回应。这创造了阿谀奉承和过度自信的风险。本文通过三项实验调查了这些失败模式：（1）一项多项选择评价，以衡量模型在用户压力下的稳定性；（2）一项使用新颖的安全类型学和LLM裁判进行的自由响应分析；（3）一项机制可解释性实验，通过操纵“高风险”激活向量引导模型行为。研究结果表明，虽然有些模型表现出阿谀奉承，但如o4-mini等其他模型则保持了稳健性。表现优异的模型通过频繁提出澄清问题来实现高安全性得分，这是一种安全、探索性的方法的关键特征，而不是提供具有约束性的建议。此外，我们证明模型的谨慎性可以通过激活引导直接控制，这表明了一条新的安全对齐路径。这些发现强调了需要细致且多维度的基准来确保LLMs能够在关键决策中获得信任。', 'title_zh': '你能把你的生命改变决定交给你信任的LLM吗？一项关于AI高风险回应的研究'}
{'arxiv_id': 'arXiv:2507.21131', 'title': 'NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback', 'authors': 'Madhava Gaikwad, Ashwini Ramchandra Doke', 'link': 'https://arxiv.org/abs/2507.21131', 'abstract': 'We present NPO, an alignment-aware learning framework that operationalizes feedback-driven adaptation in human-in-the-loop decision systems. Unlike prior approaches that treat alignment as a static or post-hoc property, NPO introduces a formalization of alignment loss that is measurable, supervisable, and reducible under structured feedback. In parallel, we propose meta-alignment as the fidelity of the monitoring process that governs retraining or override triggers, and show that it is formally reducible to primary alignment via threshold fidelity. Our implementation spans a scalable operational loop involving scenario scoring, threshold tuning, policy validation, and structured feedback ingestion, including "likes", overrides, and abstentions. We provide formal convergence results under stochastic feedback and show that both alignment loss and monitoring fidelity converge additively. Empirically, NPO demonstrates measurable value in hyperscale deployment settings. A simulation-based artifact and ablation studies further illustrate the theoretical principles in action. Together, NPO offers a compact, inspectable architecture for continual alignment monitoring, helping bridge theoretical alignment guarantees with practical reliability in dynamic environments.', 'abstract_zh': 'NPO：一种 Awareness-Based 学习框架，用于人类在环决策系统中的对齐适应', 'title_zh': 'NPO: 通过结构化人类反馈学习对齐与元对齐'}
{'arxiv_id': 'arXiv:2507.21130', 'title': 'INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems', 'authors': 'Bintao Tang, Xin Yang, Yuhao Wang, Zixuan Qiu, Zimo Ji, Wenyuan Jiang', 'link': 'https://arxiv.org/abs/2507.21130', 'abstract': 'We present INTEGRALBENCH, a focused benchmark designed to evaluate Large Language Model (LLM) performance on definite integral problems. INTEGRALBENCH provides both symbolic and numerical ground truth solutions with manual difficulty annotations. Our evaluation of nine state-of-the-art LLMs reveals significant performance gaps and strong correlations between problem difficulty and model accuracy, establishing baseline metrics for this challenging domain. INTEGRALBENCH aims to advance automated mathematical reasoning by providing a rigorous evaluation framework specifically tailored for definite integral computation.', 'abstract_zh': 'INTEGRALBENCH：一个用于评估大规模语言模型在定积分问题上表现的聚焦基准', 'title_zh': 'INTEGRALBENCH：使用定积分问题评估LLMs'}
{'arxiv_id': 'arXiv:2507.21129', 'title': 'Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics', 'authors': 'Jae Wan Shim', 'link': 'https://arxiv.org/abs/2507.21129', 'abstract': 'The remarkable capabilities of Large Language Models (LLMs) are now extensively documented on task-specific benchmarks, yet the internal mechanisms that produce these results are the subject of intense scientific inquiry. This paper contributes to this inquiry by moving beyond metrics that measure \\textit{what} models can do, to a methodology that characterizes \\textit{how} they process information. We introduce a novel, task-agnostic approach to probe these dynamics by creating a quantitative ``Cognitive Profile" for any given model. This profile is centered on the \\textbf{Entropy Decay Curve}, a visualization that traces how a model\'s normalized predictive uncertainty changes as a function of context length. Applying this methodology to several state-of-the-art LLMs across diverse texts, we uncover unique and consistent cognitive profiles that are sensitive to both model scale and text complexity. We also introduce the Information Gain Span (IGS) index to summarize the desirability of the decay trajectory. This work thus provides a new, principled lens for analyzing and comparing the intrinsic operational dynamics of artificial intelligence.', 'abstract_zh': '大型语言模型的杰出能力已在特定任务基准上广泛记录，但其产生这些结果的内部机制仍然是科学研究的焦点。本文通过超越衡量模型“能做什么”的指标，转向一种描述模型“如何”处理信息的方法论，为这一研究做出了贡献。我们引入了一种新的、任务无关的方法来探索这些动态，通过为任何给定模型创建一个定量的“认知轮廓”来实现。这种轮廓以“熵衰减曲线”为中心，这是一种可视化模型归一化预测不确定性随上下文长度变化的曲线的方式。将这一方法论应用于不同领域的一些最先进的大型语言模型，我们发现了独特的且一致的认知轮廓，这些轮廓对模型规模和文本复杂性都表现出敏感性。我们还引入了信息增益跨度（IGS）指数来总结衰减轨迹的可取性。因此，这项工作提供了一个新的、原理性的视角来分析和比较人工智能内在的操作动态。', 'title_zh': '通过信息论度量在大型语言模型中基于上下文不确定性衡量和分析智能'}
{'arxiv_id': 'arXiv:2507.21123', 'title': 'Leveraging Generative AI to Enhance Synthea Module Development', 'authors': 'Mark A. Kramer, Aanchal Mathur, Caroline E. Adams, Jason A. Walonoski', 'link': 'https://arxiv.org/abs/2507.21123', 'abstract': 'This paper explores the use of large language models (LLMs) to assist in the development of new disease modules for Synthea, an open-source synthetic health data generator. Incorporating LLMs into the module development process has the potential to reduce development time, reduce required expertise, expand model diversity, and improve the overall quality of synthetic patient data. We demonstrate four ways that LLMs can support Synthea module creation: generating a disease profile, generating a disease module from a disease profile, evaluating an existing Synthea module, and refining an existing module. We introduce the concept of progressive refinement, which involves iteratively evaluating the LLM-generated module by checking its syntactic correctness and clinical accuracy, and then using that information to modify the module. While the use of LLMs in this context shows promise, we also acknowledge the challenges and limitations, such as the need for human oversight, the importance of rigorous testing and validation, and the potential for inaccuracies in LLM-generated content. The paper concludes with recommendations for future research and development to fully realize the potential of LLM-aided synthetic data creation.', 'abstract_zh': '本文探讨了使用大规模语言模型（LLMs）辅助Synthea（一个开源的合成健康数据生成器）新疾病模块开发的应用。将LLMs集成到模块开发过程中，有望减少开发时间，降低所需专业知识，扩展模型多样性，并提高合成患者数据的整体质量。我们展示了LLMs支持Synthea模块创建的四种方式：生成疾病概要、从疾病概要生成疾病模块、评估现有Synthea模块以及优化现有模块。我们提出了渐进式优化的概念，即通过检查LLMs生成模块的语法正确性和临床准确性来逐步评估，并利用这些信息对该模块进行修改。虽然在这一上下文中使用LLMs表现出潜力，但我们也承认面临的挑战和限制，如需要人工监督、严格测试和验证的重要性，以及LLMs生成内容的潜在不准确性。文章最后提出了关于未来研究和开发的建议，以充分利用LLMs辅助合成数据创建的潜力。', 'title_zh': '利用生成式人工智能提升Synthea模块开发'}
{'arxiv_id': 'arXiv:2507.21098', 'title': 'Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism', 'authors': 'Marta Sidorkiewicz, Karolina Królikowska, Berenika Dyczek, Edyta Pijet-Migon, Anna Dubel', 'link': 'https://arxiv.org/abs/2507.21098', 'abstract': "This study examines the role of Artificial Intelligence (AI) in enhancing sustainability and efficiency within the wine industry. It focuses on AI-driven intelligent management in viticulture, wine production, and enotourism. As the wine industry faces environmental and economic challenges, AI offers innovative solutions to optimize resource use, reduce environmental impact, and improve customer engagement. Understanding AI's potential in sustainable winemaking is crucial for fostering responsible and efficient industry practices. The research is based on a questionnaire survey conducted among Polish winemakers, combined with a comprehensive analysis of AI methods applicable to viticulture, production, and tourism. Key AI technologies, including predictive analytics, machine learning, and computer vision, are explored. The findings indicate that AI enhances vineyard monitoring, optimizes irrigation, and streamlines production processes, contributing to sustainable resource management. In enotourism, AI-powered chatbots, recommendation systems, and virtual tastings personalize consumer experiences. The study highlights AI's impact on economic, environmental, and social sustainability, supporting local wine enterprises and cultural heritage. Keywords: Artificial Intelligence, Sustainable Development, AI-Driven Management, Viticulture, Wine Production, Enotourism, Wine Enterprises, Local Communities", 'abstract_zh': '本研究探讨了人工智能（AI）在葡萄酒行业中增强可持续性和效率的作用。它重点关注AI驱动的智能管理在葡萄种植、葡萄酒生产和葡萄酒旅游业中的应用。随着葡萄酒行业面临环境和经济挑战，AI提供了优化资源使用、减少环境影响和改善消费者参与的创新解决方案。理解AI在可持续酿酒中的潜力对于促进负责任和高效的行业实践至关重要。该研究基于对波兰酿酒商的问卷调查，并结合了对适用于葡萄种植、生产及旅游业的AI方法的全面分析。研究探讨了包括预测分析、机器学习和计算机视觉在内的关键AI技术。研究结果表明，AI增强了葡萄园的监控，优化了灌溉，并简化了生产流程，从而促进了可持续资源管理。在葡萄酒旅游业中，AI驱动的聊天机器人、推荐系统和虚拟品酒使消费者体验更加个性化。该研究突出了AI对经济、环境和社会可持续性的影响，支持了本地葡萄酒企业和文化遗产。关键词：人工智能，可持续发展，AI驱动管理，葡萄种植，葡萄酒生产，葡萄酒旅游业，本地社区。', 'title_zh': '人工智能赋能可持续葡萄酒产业：智能驱动的葡萄种植、葡萄酒生产及葡萄酒旅游业管理'}
{'arxiv_id': 'arXiv:2507.21067', 'title': 'SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration', 'authors': 'Jan Kapusta', 'link': 'https://arxiv.org/abs/2507.21067', 'abstract': "Current AI systems rely on opaque reasoning processes that hinder human oversight and collaborative potential. Conventional explainable AI approaches offer post-hoc justifications and often fail to establish genuine symbiotic collaboration. In this paper, the Symbiotic Epistemology is presented as a philosophical foundation for human-AI cognitive partnerships. Unlike frameworks that treat AI as a mere tool or replacement, symbiotic epistemology positions AI as a reasoning partner, fostering calibrated trust by aligning human confidence with AI reliability through explicit reasoning patterns and confidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as a formal protocol for transparent human-AI collaboration. The framework is empirically validated through actual human-AI dialogues demonstrating AI's adaptation to structured reasoning protocols and successful metacognitive intervention. The protocol defines two complementary mechanisms: TRACE for high-level reasoning patterns and TRACE_FE for detailed factor explanations. It also integrates confidence quantification, declarative control over AI behavior, and context inheritance for multi-agent coordination. By structuring communication and embedding confidence-calibrated transparency, SynLang, together with symbiotic epistemology, enables AI systems that enhance human intelligence, preserve human agency, and uphold ethical accountability in collaborative decision-making. Through dual-level transparency, beginning with high-level reasoning patterns and progressing to granular explanations, the protocol facilitates rapid comprehension and supports thorough verification of AI decision-making.", 'abstract_zh': '当前的AI系统依赖于不透明的推理过程，这阻碍了人类的监督和协作潜力。传统的可解释AI方法通常只提供事后解释，并未能建立真正共生的合作关系。本文提出了共生知识论作为人类与AI认知伙伴关系的哲学基础。与将AI视为 mere 工具或替代品的框架不同，共生知识论将AI定位为推理伙伴，通过明确的推理模式和信任评估与人类信心对齐，从而培养校准的信任。SynLang（共生语义语言）被引入作为一种形式化协议，促进透明的人机合作。该框架通过实际的人机对话经验得到了验证，展示了AI适应结构化推理协议并成功进行元认知干预的能力。该协议定义了两种互补机制：TRACE 用于高级推理模式和 TRACE_FE 用于详细因素解释。该协议还整合了信心量化、声明性控制AI行为和上下文继承以支持多智能体协调。通过结构化沟通并嵌入校准信心的透明性，SynLang 与共生知识论一起，使AI系统能够增强人类智能、保护人类自主权并维护协作决策中的伦理问责制。通过双重水平的透明性，从高级推理模式开始，逐步到细粒度解释，该协议促进快速理解并支持对AI决策的彻底验证。', 'title_zh': 'SynLang 和共生 epistemology: 人类意识与AI协作的宣言'}
{'arxiv_id': 'arXiv:2507.22053', 'title': 'Foundation Models for Demand Forecasting via Dual-Strategy Ensembling', 'authors': 'Wei Yang, Defu Cao, Yan Liu', 'link': 'https://arxiv.org/abs/2507.22053', 'abstract': 'Accurate demand forecasting is critical for supply chain optimization, yet remains difficult in practice due to hierarchical complexity, domain shifts, and evolving external factors. While recent foundation models offer strong potential for time series forecasting, they often suffer from architectural rigidity and limited robustness under distributional change. In this paper, we propose a unified ensemble framework that enhances the performance of foundation models for sales forecasting in real-world supply chains. Our method combines two complementary strategies: (1) Hierarchical Ensemble (HE), which partitions training and inference by semantic levels (e.g., store, category, department) to capture localized patterns; and (2) Architectural Ensemble (AE), which integrates predictions from diverse model backbones to mitigate bias and improve stability. We conduct extensive experiments on the M5 benchmark and three external sales datasets, covering both in-domain and zero-shot forecasting. Results show that our approach consistently outperforms strong baselines, improves accuracy across hierarchical levels, and provides a simple yet effective mechanism for boosting generalization in complex forecasting environments.', 'abstract_zh': '准确的需求预测对于供应链优化至关重要，但在实践中由于层次复杂性、领域变化和不断演变的外部因素仍然具有挑战性。尽管近期的基础模型在时间序列预测方面表现出强大的潜力，但它们往往缺乏架构柔性和在分布变化下的稳健性。在本文中，我们提出了一种统一的集成框架，以增强基础模型在实际供应链中的销售预测性能。该方法结合了两种互补策略：(1) 层次集成（HE），通过按语义层次（如商店、品类、部门）划分训练和推理来捕获局部模式；(2) 架构集成（AE），通过整合来自不同模型架构的预测来减轻偏差并提高稳定性。我们在M5基准和三个外部销售数据集上进行了广泛的实验，涵盖了领域内和零样本预测。结果表明，我们的方法在各种层次上均能持续优于强基线，并提供了一种简单而有效的机制，以增强复杂预测环境中的泛化能力。', 'title_zh': '基于双重策略集成的Demand Forecasting基础模型研究'}
{'arxiv_id': 'arXiv:2507.22039', 'title': 'Supervised Quantum Image Processing', 'authors': 'Marco Parigi, Mehran Khosrojerdi, Filippo Caruso, Leonardo Banchi', 'link': 'https://arxiv.org/abs/2507.22039', 'abstract': 'In the era of big data and artificial intelligence, the increasing volume of data and the demand to solve more and more complex computational challenges are two driving forces for improving the efficiency of data storage, processing and analysis. Quantum image processing (QIP) is an interdisciplinary field between quantum information science and image processing, which has the potential to alleviate some of these challenges by leveraging the power of quantum computing. In this work, we compare and examine the compression properties of four different Quantum Image Representations (QImRs): namely, Tensor Network Representation (TNR), Flexible Representation of Quantum Image (FRQI), Novel Enhanced Quantum Representation NEQR, and Quantum Probability Image Encoding (QPIE). Our simulations show that FRQI performs a higher compression of image information than TNR, NEQR, and QPIE. Furthermore, we investigate the trade-off between accuracy and memory in binary classification problems, evaluating the performance of quantum kernels based on QImRs compared to the classical linear kernel. Our results indicate that quantum kernels provide comparable classification average accuracy but require exponentially fewer resources for image storage.', 'abstract_zh': '在大数据和人工智能时代，不断增加的数据量和解决日益复杂的计算挑战的需求，推动了数据存储、处理和分析效率的提高。量子图像处理（QIP）是量子信息科学与图像处理的交叉领域，有可能通过利用量子计算的强大功能来缓解一些这些挑战。在本文中，我们比较和分析了四种不同的量子图像表示（QImRs）的压缩性能：张量网络表示（TNR）、灵活的量子图像表示（FRQI）、新型增强量子表示（NEQR）和量子概率图像编码（QPIE）。我们的模拟结果显示，FRQI在压缩图像信息方面优于TNR、NEQR和QPIE。此外，我们探讨了准确性与内存之间的权衡，在二分类问题中评估基于QImRs的量子核与经典线性核的性能。结果显示，量子核提供了可比拟的分类平均准确率，但需要指数级更少的图像存储资源。', 'title_zh': '监督量子图像处理'}
{'arxiv_id': 'arXiv:2507.22037', 'title': 'Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security', 'authors': 'Muzhi Dai, Shixuan Liu, Zhiyuan Zhao, Junyu Gao, Hao Sun, Xuelong Li', 'link': 'https://arxiv.org/abs/2507.22037', 'abstract': "The rapid advancement of multimodal large language models (MLLMs) has led to breakthroughs in various applications, yet their security remains a critical challenge. One pressing issue involves unsafe image-query pairs--jailbreak inputs specifically designed to bypass security constraints and elicit unintended responses from MLLMs. Compared to general multimodal data, such unsafe inputs are relatively sparse, which limits the diversity and richness of training samples available for developing robust defense models. Meanwhile, existing guardrail-type methods rely on external modules to enforce security constraints but fail to address intrinsic vulnerabilities within MLLMs. Traditional supervised fine-tuning (SFT), on the other hand, often over-refuses harmless inputs, compromising general performance. Given these challenges, we propose Secure Tug-of-War (SecTOW), an innovative iterative defense-attack training method to enhance the security of MLLMs. SecTOW consists of two modules: a defender and an auxiliary attacker, both trained iteratively using reinforcement learning (GRPO). During the iterative process, the attacker identifies security vulnerabilities in the defense model and expands jailbreak data. The expanded data are then used to train the defender, enabling it to address identified security vulnerabilities. We also design reward mechanisms used for GRPO to simplify the use of response labels, reducing dependence on complex generative labels and enabling the efficient use of synthetic data. Additionally, a quality monitoring mechanism is used to mitigate the defender's over-refusal of harmless inputs and ensure the diversity of the jailbreak data generated by the attacker. Experimental results on safety-specific and general benchmarks demonstrate that SecTOW significantly improves security while preserving general performance.", 'abstract_zh': 'Secure Tug-of-War：一种增强多模态大型语言模型安全性的迭代防御-攻击训练方法', 'title_zh': '安全 tug-of-war (SecTOW): 迭代防御-攻击训练的多模态模型安全方法'}
{'arxiv_id': 'arXiv:2507.22030', 'title': 'ReXGroundingCT: A 3D Chest CT Dataset for Segmentation of Findings from Free-Text Reports', 'authors': 'Mohammed Baharoon, Luyang Luo, Michael Moritz, Abhinav Kumar, Sung Eun Kim, Xiaoman Zhang, Miao Zhu, Mahmoud Hussain Alabbad, Maha Sbayel Alhazmi, Neel P. Mistry, Kent Ryan Kleinschmidt, Brady Chrisler, Sathvik Suryadevara, Sri Sai Dinesh Jaliparthi, Noah Michael Prudlo, Mark David Marino, Jeremy Palacio, Rithvik Akula, Hong-Yu Zhou, Ibrahim Ethem Hamamci, Scott J. Adams, Hassan Rayhan AlOmaish, Pranav Rajpurkar', 'link': 'https://arxiv.org/abs/2507.22030', 'abstract': 'We present ReXGroundingCT, the first publicly available dataset to link free-text radiology findings with pixel-level segmentations in 3D chest CT scans that is manually annotated. While prior datasets have relied on structured labels or predefined categories, ReXGroundingCT captures the full expressiveness of clinical language represented in free text and grounds it to spatially localized 3D segmentation annotations in volumetric imaging. This addresses a critical gap in medical AI: the ability to connect complex, descriptive text, such as "3 mm nodule in the left lower lobe", to its precise anatomical location in three-dimensional space, a capability essential for grounded radiology report generation systems. The dataset comprises 3,142 non-contrast chest CT scans paired with standardized radiology reports from the CT-RATE dataset. Using a systematic three-stage pipeline, GPT-4 was used to extract positive lung and pleural findings, which were then manually segmented by expert annotators. A total of 8,028 findings across 16,301 entities were annotated, with quality control performed by board-certified radiologists. Approximately 79% of findings are focal abnormalities, while 21% are non-focal. The training set includes up to three representative segmentations per finding, while the validation and test sets contain exhaustive labels for each finding entity. ReXGroundingCT establishes a new benchmark for developing and evaluating sentence-level grounding and free-text medical segmentation models in chest CT. The dataset can be accessed at this https URL.', 'abstract_zh': 'ReXGroundingCT：第一个将自由文本放射学发现与3D胸CT扫描的像素级分割关联起来的手动标注数据集', 'title_zh': 'ReXGroundingCT：一种用于自由文本报告中发现分割的3D胸腔CT数据集'}
{'arxiv_id': 'arXiv:2507.22020', 'title': 'XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation', 'authors': 'Raju Ningappa Mulawade, Christoph Garth, Alexander Wiebel', 'link': 'https://arxiv.org/abs/2507.22020', 'abstract': 'We propose a novel segmentation-based explainable artificial intelligence (XAI) method for neural networks working on point cloud classification. As one building block of this method, we propose a novel point-shifting mechanism to introduce perturbations in point cloud data. Recently, AI has seen an exponential growth. Hence, it is important to understand the decision-making process of AI algorithms when they are applied in critical areas. Our work focuses on explaining AI algorithms that classify point cloud data. An important aspect of the methods used for explaining AI algorithms is their ability to produce explanations that are easy for humans to understand. This allows them to analyze the AI algorithms better and make appropriate decisions based on that analysis. Therefore, in this work, we intend to generate meaningful explanations that can be easily interpreted by humans. The point cloud data we consider represents 3D objects such as cars, guitars, and laptops. We make use of point cloud segmentation models to generate explanations for the working of classification models. The segments are used to introduce perturbations into the input point cloud data and generate saliency maps. The perturbations are introduced using the novel point-shifting mechanism proposed in this work which ensures that the shifted points no longer influence the output of the classification algorithm. In contrast to previous methods, the segments used by our method are meaningful, i.e. humans can easily interpret the meaning of the segments. Thus, the benefit of our method over other methods is its ability to produce more meaningful saliency maps. We compare our method with the use of classical clustering algorithms to generate explanations. We also analyze the saliency maps generated for example inputs using our method to demonstrate the usefulness of the method in generating meaningful explanations.', 'abstract_zh': '一种基于分割的可解释人工智能方法：点云分类神经网络中的可解释性人工智能方法', 'title_zh': '基于有意义分割的扰动解释可点云数据的方法'}
{'arxiv_id': 'arXiv:2507.22010', 'title': 'Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform', 'authors': 'Justin Curry, Brennan Lagasse, Ngoc B. Lam, Gregory Cox, David Rosenbluth, Alberto Speranzon', 'link': 'https://arxiv.org/abs/2507.22010', 'abstract': 'In this work, we explore the structure of the embedding space of a transformer model trained for playing a particular reinforcement learning (RL) game. Specifically, we investigate how a transformer-based Proximal Policy Optimization (PPO) model embeds visual inputs in a simple environment where an agent must collect "coins" while avoiding dynamic obstacles consisting of "spotlights." By adapting Robinson et al.\'s study of the volume growth transform for LLMs to the RL setting, we find that the token embedding space for our visual coin collecting game is also not a manifold, and is better modeled as a stratified space, where local dimension can vary from point to point. We further strengthen Robinson\'s method by proving that fairly general volume growth curves can be realized by stratified spaces. Finally, we carry out an analysis that suggests that as an RL agent acts, its latent representation alternates between periods of low local dimension, while following a fixed sub-strategy, and bursts of high local dimension, where the agent achieves a sub-goal (e.g., collecting an object) or where the environmental complexity increases (e.g., more obstacles appear). Consequently, our work suggests that the distribution of dimensions in a stratified latent space may provide a new geometric indicator of complexity for RL games.', 'abstract_zh': '本研究探究了用于玩特定强化学习（RL）游戏的变压器模型的嵌入空间结构。具体而言，我们调查了基于变压器的近端策略优化（PPO）模型如何在代理必须收集“硬币”并避免“聚光灯”动态障碍的简单环境中嵌入视觉输入。通过将Robinson等人对大型语言模型（LLM）的体积增长变换研究适应到RL环境中，我们发现我们视觉硬币收集游戏的标记嵌入空间也不是流形，而更适合用层化空间模型，其中局部维度可以在不同点上变化。我们进一步改进了Robinson的方法，证明了相当一般的体积增长曲线可以由层化空间实现。最后，我们进行的分析表明，随着RL代理采取行动，其潜在表示在遵循固定子策略的长时间低局部维度时期与代理实现子目标（例如，收集物体）或环境复杂度增加（例如，出现更多障碍物）的高局部维度爆发期之间交替。因此，我们的研究建议，层化潜在空间中维度的分布可能为RL游戏提供一种新的几何复杂性指标。', 'title_zh': '探索RL游戏的分层空间结构的体积增长变换方法'}
{'arxiv_id': 'arXiv:2507.22002', 'title': 'Bridging Synthetic and Real-World Domains: A Human-in-the-Loop Weakly-Supervised Framework for Industrial Toxic Emission Segmentation', 'authors': 'Yida Tao, Yen-Chia Hsu', 'link': 'https://arxiv.org/abs/2507.22002', 'abstract': 'Industrial smoke segmentation is critical for air-quality monitoring and environmental protection but is often hampered by the high cost and scarcity of pixel-level annotations in real-world settings. We introduce CEDANet, a human-in-the-loop, class-aware domain adaptation framework that uniquely integrates weak, citizen-provided video-level labels with adversarial feature alignment. Specifically, we refine pseudo-labels generated by a source-trained segmentation model using citizen votes, and employ class-specific domain discriminators to transfer rich source-domain representations to the industrial domain. Comprehensive experiments on SMOKE5K and custom IJmond datasets demonstrate that CEDANet achieves an F1-score of 0.414 and a smoke-class IoU of 0.261 with citizen feedback, vastly outperforming the baseline model, which scored 0.083 and 0.043 respectively. This represents a five-fold increase in F1-score and a six-fold increase in smoke-class IoU. Notably, CEDANet with citizen-constrained pseudo-labels achieves performance comparable to the same architecture trained on limited 100 fully annotated images with F1-score of 0.418 and IoU of 0.264, demonstrating its ability to reach small-sampled fully supervised-level accuracy without target-domain annotations. Our research validates the scalability and cost-efficiency of combining citizen science with weakly supervised domain adaptation, offering a practical solution for complex, data-scarce environmental monitoring applications.', 'abstract_zh': '基于公民科学的弱监督领域适应框架CEDANet：低成本工业烟雾分割方法', 'title_zh': '合成与实际领域桥梁构建：基于人类在环的弱监督框架在工业有毒排放分割中的应用'}
{'arxiv_id': 'arXiv:2507.22000', 'title': 'Staining and locking computer vision models without retraining', 'authors': 'Oliver J. Sutton, Qinghua Zhou, George Leete, Alexander N. Gorban, Ivan Y. Tyukin', 'link': 'https://arxiv.org/abs/2507.22000', 'abstract': "We introduce new methods of staining and locking computer vision models, to protect their owners' intellectual property. Staining, also known as watermarking, embeds secret behaviour into a model which can later be used to identify it, while locking aims to make a model unusable unless a secret trigger is inserted into input images. Unlike existing methods, our algorithms can be used to stain and lock pre-trained models without requiring fine-tuning or retraining, and come with provable, computable guarantees bounding their worst-case false positive rates. The stain and lock are implemented by directly modifying a small number of the model's weights and have minimal impact on the (unlocked) model's performance. Locked models are unlocked by inserting a small `trigger patch' into the corner of the input image. We present experimental results showing the efficacy of our methods and demonstrating their practical performance on a variety of computer vision models.", 'abstract_zh': '我们介绍了新的染色和锁定方法，以保护计算机视觉模型所有者的知识产权。染色，也称为水印技术，将秘密行为嵌入到模型中，以后可以用于识别该模型，而锁定的目的是除非在输入图像中插入秘密触发器否则模型无法使用。与现有方法不同，我们的算法可以在不需要微调或重新训练的情况下对预训练模型进行染色和锁定，并且提供了计算可证明的最坏情况的假阳性率界。染色和锁定通过直接修改模型的少量权重实现，并对（解锁状态下的）模型性能影响极小。通过在输入图像的角落插入小型“触发补丁”可以解锁模型。我们展示了这些方法的有效性并演示了它们在多种计算机视觉模型上的实际性能。', 'title_zh': '不重新训练即染色和锁定计算机视觉模型'}
{'arxiv_id': 'arXiv:2507.21992', 'title': 'Teach Me to Trick: Exploring Adversarial Transferability via Knowledge Distillation', 'authors': 'Siddhartha Pradhan, Shikshya Shiwakoti, Neha Bathuri', 'link': 'https://arxiv.org/abs/2507.21992', 'abstract': 'We investigate whether knowledge distillation (KD) from multiple heterogeneous teacher models can enhance the generation of transferable adversarial examples. A lightweight student model is trained using two KD strategies: curriculum-based switching and joint optimization, with ResNet50 and DenseNet-161 as teachers. The trained student is then used to generate adversarial examples using FG, FGS, and PGD attacks, which are evaluated against a black-box target model (GoogLeNet). Our results show that student models distilled from multiple teachers achieve attack success rates comparable to ensemble-based baselines, while reducing adversarial example generation time by up to a factor of six. An ablation study further reveals that lower temperature settings and the inclusion of hard-label supervision significantly enhance transferability. These findings suggest that KD can serve not only as a model compression technique but also as a powerful tool for improving the efficiency and effectiveness of black-box adversarial attacks.', 'abstract_zh': '我们调查了多个异构教师模型的知识蒸馏是否能增强可转移对抗样本的生成，并使用ResNet50和DenseNet-161作为教师模型，通过基于课程的学习切换和联合优化两种知识蒸馏策略训练一个轻量级学生模型。训练后，该学生模型使用FG、FGS和PGD攻击生成对抗样本，并与黑色盒目标模型（GoogLeNet）进行评估。结果表明，从多个教师模型蒸馏而来的学生模型在攻击成功率上与基于集成的基线相当，同时对抗样本生成时间最多可减少六倍。进一步的消融研究显示，较低的温度设置和硬标签监督的加入显著提高了可转移性。这些发现表明，知识蒸馏不仅可以作为模型压缩技术，还可以作为提高黑色盒对抗攻击效率和效果的强大工具。', 'title_zh': '教我欺骗：通过知识精炼探索对抗迁移性'}
{'arxiv_id': 'arXiv:2507.21990', 'title': 'ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge', 'authors': 'Zihan Zhao, Bo Chen, Ziping Wan, Lu Chen, Xuanze Lin, Shiyang Yu, Situo Zhang, Da Ma, Zichen Zhu, Danyang Zhang, Huayang Wang, Zhongyang Dai, Liyang Wen, Xin Chen, Kai Yu', 'link': 'https://arxiv.org/abs/2507.21990', 'abstract': "While large language models (LLMs) have achieved impressive progress, their application in scientific domains such as chemistry remains hindered by shallow domain understanding and limited reasoning capabilities. In this work, we focus on the specific field of chemistry and develop a Chemical Reasoner LLM, ChemDFM-R. We first construct a comprehensive dataset of atomized knowledge points to enhance the model's understanding of the fundamental principles and logical structure of chemistry. Then, we propose a mix-sourced distillation strategy that integrates expert-curated knowledge with general-domain reasoning skills, followed by domain-specific reinforcement learning to enhance chemical reasoning. Experiments on diverse chemical benchmarks demonstrate that ChemDFM-R achieves state-of-the-art performance while providing interpretable, rationale-driven outputs. Further case studies illustrate how explicit reasoning chains significantly improve the reliability, transparency, and practical utility of the model in real-world human-AI collaboration scenarios.", 'abstract_zh': '虽然大型语言模型（LLMs）取得了显著进展，但在化学等科学领域中的应用仍受制于浅显的领域理解能力和有限的推理能力。在本工作中，我们专注于化学这一特定领域，开发了一种化学推理大型语言模型ChemDFM-R。我们首先构建了一个全面的原子化知识点数据集，以增强模型对化学基本原理和逻辑结构的理解。随后，我们提出了一种混合来源的知识蒸馏策略，将专家提炼的知识与通用领域推理能力相结合，再通过领域特定的强化学习来提升化学推理能力。在多种化学基准测试上的实验表明，ChemDFM-R 达到了最先进的性能，并提供了可解释的、基于推理的输出。进一步的案例研究显示，明确的推理链条显著提高了模型在实际的人机协作场景中的可靠性和透明度及其实用性。', 'title_zh': 'ChemDFM-R：一种增强型原子化化学知识化学推理大语言模型'}
{'arxiv_id': 'arXiv:2507.21954', 'title': 'Fine-Tuning Code Language Models to Detect Cross-Language Bugs', 'authors': 'Zengyang Li, Yimeng Li, Binbin Huang, Peng Liang, Ran Mo, Hui Liu, Yutao Ma', 'link': 'https://arxiv.org/abs/2507.21954', 'abstract': "Multilingual programming, which involves using multiple programming languages (PLs) in a single project, is increasingly common due to its benefits. However, it introduces cross-language bugs (CLBs), which arise from interactions between different PLs and are difficult to detect by single-language bug detection tools. This paper investigates the potential of pre-trained code language models (CodeLMs) in CLB detection. We developed CLCFinder, a cross-language code identification tool, and constructed a CLB dataset involving three PL combinations (Python-C/C++, Java-C/C++, and Python-Java) with nine interaction types. We fine-tuned 13 CodeLMs on this dataset and evaluated their performance, analyzing the effects of dataset size, token sequence length, and code comments. Results show that all CodeLMs performed poorly before fine-tuning, but exhibited varying degrees of performance improvement after fine-tuning, with UniXcoder-base achieving the best F1 score (0.7407). Notably, small fine-tuned CodeLMs tended to performe better than large ones. CodeLMs fine-tuned on single-language bug datasets performed poorly on CLB detection, demonstrating the distinction between CLBs and single-language bugs. Additionally, increasing the fine-tuning dataset size significantly improved performance, while longer token sequences did not necessarily improve the model performance. The impact of code comments varied across models. Some fine-tuned CodeLMs' performance was improved, while others showed degraded performance.", 'abstract_zh': '多语言编程中的跨语言代码模型在跨语言 bug 检测中的潜力研究', 'title_zh': '细调代码语言模型以检测跨语言错误'}
{'arxiv_id': 'arXiv:2507.21953', 'title': 'MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation', 'authors': 'Yi Kong, Dianxi Shi, Guoli Yang, Zhang ke-di, Chenlin Huang, Xiaopeng Li, Songchang Jin', 'link': 'https://arxiv.org/abs/2507.21953', 'abstract': 'The recent advancement of autonomous agents powered by Large Language Models (LLMs) has demonstrated significant potential for automating tasks on mobile devices through graphical user interfaces (GUIs). Despite initial progress, these agents still face challenges when handling complex real-world tasks. These challenges arise from a lack of knowledge about real-life mobile applications in LLM-based agents, which may lead to ineffective task planning and even cause hallucinations. To address these challenges, we propose a novel LLM-based agent framework called MapAgent that leverages memory constructed from historical trajectories to augment current task planning. Specifically, we first propose a trajectory-based memory mechanism that transforms task execution trajectories into a reusable and structured page-memory database. Each page within a trajectory is extracted as a compact yet comprehensive snapshot, capturing both its UI layout and functional context. Secondly, we introduce a coarse-to-fine task planning approach that retrieves relevant pages from the memory database based on similarity and injects them into the LLM planner to compensate for potential deficiencies in understanding real-world app scenarios, thereby achieving more informed and context-aware task planning. Finally, planned tasks are transformed into executable actions through a task executor supported by a dual-LLM architecture, ensuring effective tracking of task progress. Experimental results in real-world scenarios demonstrate that MapAgent achieves superior performance to existing methods. The code will be open-sourced to support further research.', 'abstract_zh': '基于大型语言模型的自主代理 recent 进展：通过图形用户界面在移动设备上自动执行任务的新框架', 'title_zh': 'MapAgent: 基于轨迹构建的增强记忆规划mobile任务自动化'}
{'arxiv_id': 'arXiv:2507.21949', 'title': 'Contrast-Prior Enhanced Duality for Mask-Free Shadow Removal', 'authors': 'Jiyu Wu, Yifan Liu, Jiancheng Huang, Mingfu Yan, Shifeng Chen', 'link': 'https://arxiv.org/abs/2507.21949', 'abstract': "Existing shadow removal methods often rely on shadow masks, which are challenging to acquire in real-world scenarios. Exploring intrinsic image cues, such as local contrast information, presents a potential alternative for guiding shadow removal in the absence of explicit masks. However, the cue's inherent ambiguity becomes a critical limitation in complex scenes, where it can fail to distinguish true shadows from low-reflectance objects and intricate background textures. To address this motivation, we propose the Adaptive Gated Dual-Branch Attention (AGBA) mechanism. AGBA dynamically filters and re-weighs the contrast prior to effectively disentangle shadow features from confounding visual elements. Furthermore, to tackle the persistent challenge of restoring soft shadow boundaries and fine-grained details, we introduce a diffusion-based Frequency-Contrast Fusion Network (FCFN) that leverages high-frequency and contrast cues to guide the generative process. Extensive experiments demonstrate that our method achieves state-of-the-art results among mask-free approaches while maintaining competitive performance relative to mask-based methods.", 'abstract_zh': '现有的阴影去除方法通常依赖于阴影掩模，但在实际场景中获取这些掩模具有挑战性。探索内在图像线索，如局部对比度信息，提供了在无明确掩模情况下指导阴影去除的潜在替代方案。然而，在复杂场景中，线索的固有模糊性成为了关键限制，可能导致无法将真实阴影与低反射物体和复杂的背景纹理区分开来。为了解决这一问题，我们提出了一种自适应门控双分支注意机制（AGBA）。AGBA动态筛选并重新加权对比度信息，以有效地分离出阴影特征与混淆的视觉元素。此外，为了解决恢复软阴影边界和细粒度细节的持续挑战，我们引入了一种基于扩散的频率-对比度融合网络（FCFN），利用高频和对比度线索来引导生成过程。广泛实验证明，我们的方法在无需掩模的方案中达到了最先进的性能，并且在与基于掩模的方法相比时，保持了竞争力。', 'title_zh': '对比先验增强对偶性在无遮罩阴影去除中的应用'}
{'arxiv_id': 'arXiv:2507.21947', 'title': 'Enhancing Generalization in Data-free Quantization via Mixup-class Prompting', 'authors': 'Jiwoong Park, Chaeun Lee, Yongseok Choi, Sein Park, Deokki Hong, Jungwook Choi', 'link': 'https://arxiv.org/abs/2507.21947', 'abstract': 'Post-training quantization (PTQ) improves efficiency but struggles with limited calibration data, especially under privacy constraints. Data-free quantization (DFQ) mitigates this by generating synthetic images using generative models such as generative adversarial networks (GANs) and text-conditioned latent diffusion models (LDMs), while applying existing PTQ algorithms. However, the relationship between generated synthetic images and the generalizability of the quantized model during PTQ remains underexplored. Without investigating this relationship, synthetic images generated by previous prompt engineering methods based on single-class prompts suffer from issues such as polysemy, leading to performance degradation. We propose \\textbf{mixup-class prompt}, a mixup-based text prompting strategy that fuses multiple class labels at the text prompt level to generate diverse, robust synthetic data. This approach enhances generalization, and improves optimization stability in PTQ. We provide quantitative insights through gradient norm and generalization error analysis. Experiments on convolutional neural networks (CNNs) and vision transformers (ViTs) show that our method consistently outperforms state-of-the-art DFQ methods like GenQ. Furthermore, it pushes the performance boundary in extremely low-bit scenarios, achieving new state-of-the-art accuracy in challenging 2-bit weight, 4-bit activation (W2A4) quantization.', 'abstract_zh': '基于mixup-class提示的数据无开集量化', 'title_zh': '基于Mixup-class提示的数据无关量化中的泛化增强'}
{'arxiv_id': 'arXiv:2507.21931', 'title': 'Post-Training Large Language Models via Reinforcement Learning from Self-Feedback', 'authors': 'Carel van Niekerk, Renato Vukovic, Benjamin Matthias Ruppik, Hsien-chin Lin, Milica Gašić', 'link': 'https://arxiv.org/abs/2507.21931', 'abstract': "Large Language Models (LLMs) often produce plausible but poorly-calibrated answers, limiting their reliability on reasoning-intensive tasks. We present Reinforcement Learning from Self-Feedback (RLSF), a post-training stage that uses the model's own confidence as an intrinsic reward, mimicking how humans learn in the absence of external feedback. After a frozen LLM generates several chain-of-thought solutions, we define and compute the confidence of each final answer span and rank the traces accordingly. These synthetic preferences are then used to fine-tune the policy with standard preference optimization, similar to RLHF yet requiring no human labels, gold answers, or externally curated rewards.\nRLSF simultaneously (i) refines the model's probability estimates -- restoring well-behaved calibration -- and (ii) strengthens step-by-step reasoning, yielding improved performance on arithmetic reasoning and multiple-choice question answering.\nBy turning a model's own uncertainty into useful self-feedback, RLSF affirms reinforcement learning on intrinsic model behaviour as a principled and data-efficient component of the LLM post-training pipeline and warrents further research in intrinsic rewards for LLM post-training.", 'abstract_zh': '大型语言模型（LLMs）往往生成看似合理但实际上校准不佳的答案，限制了其在逻辑密集型任务中的可靠性。我们提出了一种自我反馈强化学习（RLSF），这是一种后训练阶段的方法，通过使用模型自身的置信度作为内在奖励，模仿人类在缺乏外部反馈时的学习方式。在冻结的LLM生成多个推理链解决方案后，我们定义并计算每个最终答案片段的置信度，并根据这些排名相应的轨迹。这些合成的偏好随后用于使用标准偏好优化微调策略，类似于RLHF，但无需任何人工标签、黄金答案或外部策划的奖励。\n\nRLSF同时（i）改进了模型的概率估计——恢复了良好的校准行为；（ii）增强了逐步推理，从而在算术推理和多项选择题回答等方面取得了更好的性能。\n\n通过将模型自身的不确定性转化为有用的自我反馈，RLSF证实了内在模型行为上的强化学习作为LLM后训练管道的一个原则性和数据高效组成部分的有效性，并促使进一步研究LLM后训练过程中的内在奖励。', 'title_zh': '通过自我反馈强化学习Fine-tuning大规模语言模型'}
{'arxiv_id': 'arXiv:2507.21928', 'title': 'Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda', 'authors': 'Christian Meske, Tobias Hermanns, Esther von der Weiden, Kai-Uwe Loser, Thorsten Berger', 'link': 'https://arxiv.org/abs/2507.21928', 'abstract': 'Software development is undergoing a fundamental transformation as vibe coding becomes widespread, with large portions of contemporary codebases now being AI-generated. The disconnect between rapid adoption and limited conceptual understanding highlights the need for an inquiry into this emerging paradigm. Drawing on an intent perspective and historical analysis, we define vibe coding as a software development paradigm where humans and generative AI engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference. By intent mediation, we refer to the fundamental process through which developers translate their conceptual goals into representations that computational systems can execute. Our results show that vibe coding reconfigures cognitive work by redistributing epistemic labor between humans and machines, shifting the expertise in the software development process away from traditional areas such as design or technical implementation toward collaborative orchestration. We identify key opportunities, including democratization, acceleration, and systemic leverage, alongside risks, such as black box codebases, responsibility gaps, and ecosystem bias. We conclude with a research agenda spanning human-, technology-, and organization-centered directions to guide future investigations of this paradigm.', 'abstract_zh': '软件开发正经历一场根本性的变革，随着vibe编码的广泛使用，当代代码库中现在有大量部分是由AI生成的。快速采用与有限的概念理解之间的差距突显了对这一新兴范式的探究需求。基于意图视角及历史分析，我们将vibe编码定义为一种软件开发范式，在这种范式中，人类与生成型AI通过自然语言对话协作流动以共同创造软件制品，将开发人员意图的中介从确定性指令转向概率性推理。通过意图中介，我们指的是开发人员将概念性目标转换为计算系统可以执行的表现形式的基本过程。研究结果表明，vibe编码重新配置了认知工作，重新分配了人类与机器之间的本体论劳动，将软件开发过程中的专业性从传统的设计或技术实现领域转向了协作指挥。我们识别出关键机遇，包括普及化、加速和系统性杠杆作用，同时识别出风险，如黑盒代码库、责任缺口和生态系统偏见。我们提出了一项涵盖以人为中心、技术为中心和组织为中心的研究议程，以引导对该范式未来研究的指导。', 'title_zh': '振动编码作为软件开发中意图中介的重新配置：定义、影响与研究议程'}
{'arxiv_id': 'arXiv:2507.21922', 'title': 'SwinECAT: A Transformer-based fundus disease classification model with Shifted Window Attention and Efficient Channel Attention', 'authors': 'Peiran Gu, Teng Yao, Mengshen He, Fuhao Duan, Feiyan Liu, RenYuan Peng, Bao Ge', 'link': 'https://arxiv.org/abs/2507.21922', 'abstract': "In recent years, artificial intelligence has been increasingly applied in the field of medical imaging. Among these applications, fundus image analysis presents special challenges, including small lesion areas in certain fundus diseases and subtle inter-disease differences, which can lead to reduced prediction accuracy and overfitting in the models. To address these challenges, this paper proposes the Transformer-based model SwinECAT, which combines the Shifted Window (Swin) Attention with the Efficient Channel Attention (ECA) Attention. SwinECAT leverages the Swin Attention mechanism in the Swin Transformer backbone to effectively capture local spatial structures and long-range dependencies within fundus images. The lightweight ECA mechanism is incorporated to guide the SwinECAT's attention toward critical feature channels, enabling more discriminative feature representation. In contrast to previous studies that typically classify fundus images into 4 to 6 categories, this work expands fundus disease classification to 9 distinct types, thereby enhancing the granularity of diagnosis. We evaluate our method on the Eye Disease Image Dataset (EDID) containing 16,140 fundus images for 9-category classification. Experimental results demonstrate that SwinECAT achieves 88.29\\% accuracy, with weighted F1-score of 0.88 and macro F1-score of 0.90. The classification results of our proposed model SwinECAT significantly outperform the baseline Swin Transformer and multiple compared baseline models. To our knowledge, this represents the highest reported performance for 9-category classification on this public dataset.", 'abstract_zh': '基于变换器的SwinECAT模型在视网膜图像分析中的应用', 'title_zh': 'SwinECAT：一种基于变换器的 fundus 疾病分类模型，融合了移窗注意力和高效通道注意力'}
{'arxiv_id': 'arXiv:2507.21919', 'title': 'Training language models to be warm and empathetic makes them less reliable and more sycophantic', 'authors': 'Lujain Ibrahim, Franziska Sofia Hafner, Luc Rocher', 'link': 'https://arxiv.org/abs/2507.21919', 'abstract': 'Artificial intelligence (AI) developers are increasingly building language models with warm and empathetic personas that millions of people now use for advice, therapy, and companionship. Here, we show how this creates a significant trade-off: optimizing language models for warmth undermines their reliability, especially when users express vulnerability. We conducted controlled experiments on five language models of varying sizes and architectures, training them to produce warmer, more empathetic responses, then evaluating them on safety-critical tasks. Warm models showed substantially higher error rates (+10 to +30 percentage points) than their original counterparts, promoting conspiracy theories, providing incorrect factual information, and offering problematic medical advice. They were also significantly more likely to validate incorrect user beliefs, particularly when user messages expressed sadness. Importantly, these effects were consistent across different model architectures, and occurred despite preserved performance on standard benchmarks, revealing systematic risks that current evaluation practices may fail to detect. As human-like AI systems are deployed at an unprecedented scale, our findings indicate a need to rethink how we develop and oversee these systems that are reshaping human relationships and social interaction.', 'abstract_zh': '人工智能开发者 increasingly 建立具有温暖和同情人格的语言模型，数百万用户现在使用这些模型寻求建议、进行治疗和获得陪伴。这里，我们展示了这种做法带来的重大权衡：优化语言模型以提高温暖度会损害它们的可靠性，尤其是当用户表达脆弱性时。我们在五种不同规模和架构的语言模型上进行了受控实验，训练它们生成更温暖、更具同情心的回应，然后评估它们在关键安全任务上的表现。温暖模型在错误率上显著高于原始模型（高出10到30个百分点），更容易促进阴谋论、提供不正确的事实信息，并给出有问题的医疗建议。它们也更有可能验证错误的用户信念，尤其是在用户消息表达悲伤时。重要的是，这些效果在不同模型架构中是一致的，并且即使在标准基准测试上保持了性能，也揭示了当前评估实践可能未能检测到的系统性风险。随着类人类的AI系统前所未有的规模部署，我们的研究结果表明需要重新思考我们开发和监管这些正在重塑人类关系和社会互动的系统的方式。', 'title_zh': '训练语言模型具备温暖和共情的特性会使其更不可靠且更加阿谀奉承。'}
{'arxiv_id': 'arXiv:2507.21905', 'title': 'Evaluating Deepfake Detectors in the Wild', 'authors': 'Viacheslav Pirogov, Maksim Artemev', 'link': 'https://arxiv.org/abs/2507.21905', 'abstract': 'Deepfakes powered by advanced machine learning models present a significant and evolving threat to identity verification and the authenticity of digital media. Although numerous detectors have been developed to address this problem, their effectiveness has yet to be tested when applied to real-world data. In this work we evaluate modern deepfake detectors, introducing a novel testing procedure designed to mimic real-world scenarios for deepfake detection. Using state-of-the-art deepfake generation methods, we create a comprehensive dataset containing more than 500,000 high-quality deepfake images. Our analysis shows that detecting deepfakes still remains a challenging task. The evaluation shows that in fewer than half of the deepfake detectors tested achieved an AUC score greater than 60%, with the lowest being 50%. We demonstrate that basic image manipulations, such as JPEG compression or image enhancement, can significantly reduce model performance. All code and data are publicly available at this https URL.', 'abstract_zh': '由先进机器学习模型驱动的Deepfake对身份验证和数字媒体真实性构成了一个重要的且不断演化的威胁。尽管已经开发出许多检测工具来应对这一问题，但它们在实际数据中的有效性尚未得到测试。在本文中，我们评估了现代Deepfake检测器，引入了一种新的测试程序，旨在模拟Deepfake检测的实际场景。借助最先进的Deepfake生成方法，我们创建了一个包含超过500,000张高质量Deepfake图像的综合数据集。我们的分析表明，检测Deepfake仍然是一项具有挑战性的任务。评估结果显示，在测试的Deepfake检测器中，不到一半的检测器实现了AUC评分大于60%，最低得分为50%。我们证明，基本的图像处理操作，如JPEG压缩或图像增强，可以显著降低模型性能。所有代码和数据均可在此网址访问。', 'title_zh': '评估野生环境中的深度伪造检测器'}
{'arxiv_id': 'arXiv:2507.21890', 'title': 'Data-driven quantum Koopman method for simulating nonlinear dynamics', 'authors': 'Baoyang Zhang, Zhen Lu, Yaomin Zhao, Yue Yang', 'link': 'https://arxiv.org/abs/2507.21890', 'abstract': "Quantum computation offers potential exponential speedups for simulating certain physical systems, but its application to nonlinear dynamics is inherently constrained by the requirement of unitary evolution. We propose the quantum Koopman method (QKM), a data-driven framework that bridges this gap through transforming nonlinear dynamics into linear unitary evolution in higher-dimensional observable spaces. Leveraging the Koopman operator theory to achieve a global linearization, our approach maps system states into a hierarchy of Hilbert spaces using a deep autoencoder. Within the linearized embedding spaces, the state representation is decomposed into modulus and phase components, and the evolution is governed by a set of unitary Koopman operators that act exclusively on the phase. These operators are constructed from diagonal Hamiltonians with coefficients learned from data, a structure designed for efficient implementation on quantum hardware. This architecture enables direct multi-step prediction, and the operator's computational complexity scales logarithmically with the observable space dimension. The QKM is validated across diverse nonlinear systems. Its predictions maintain relative errors below 6% for reaction-diffusion systems and shear flows, and capture key statistics in 2D turbulence. This work establishes a practical pathway for quantum-accelerated simulation of nonlinear phenomena, exploring a framework built on the synergy between deep learning for global linearization and quantum algorithms for unitary dynamics evolution.", 'abstract_zh': '量子计算为模拟某些物理系统提供了潜在的指数级加速，但在应用于非线性动力学时，其应用受到单位态演化要求的固有约束。我们提出了量子库蒙方法（QKM），这是一种数据驱动的框架，通过将非线性动力学转换为高层可观测空间中的线性单位态演化来弥合这一差距。利用库蒙算子理论实现全局线性化，我们的方法使用深度自编码器将系统状态映射到希尔伯特空间层次结构中。在线性嵌入空间中，状态表示分解为幅度和相位分量，演化由作用于相位的单位态库蒙算子集控制。这些算子由从数据中学习系数的对角哈密顿量构造而成，这一结构设计用于在量子硬件上高效实现。该架构支持直接多步预测，而操作符的计算复杂度与可观测空间维数呈对数关系。QKM已在多种非线性系统中得到验证。其预测反应扩散系统和剪切流的相对误差保持在6%以下，并在二维湍流中捕捉到关键统计量。这项工作为非线性现象的量子加速模拟提供了一条实际途径，探索了深度学习为全局线性化和量子算法为单位态动力学演化之间的协同作用构建的框架。', 'title_zh': '数据驱动的量子Koopman方法用于模拟非线性动力学'}
{'arxiv_id': 'arXiv:2507.21839', 'title': 'Against racing to AGI: Cooperation, deterrence, and catastrophic risks', 'authors': 'Leonard Dung, Max Hellrigel-Holderbaum', 'link': 'https://arxiv.org/abs/2507.21839', 'abstract': "AGI Racing is the view that it is in the self-interest of major actors in AI development, especially powerful nations, to accelerate their frontier AI development to build highly capable AI, especially artificial general intelligence (AGI), before competitors have a chance. We argue against AGI Racing. First, the downsides of racing to AGI are much higher than portrayed by this view. Racing to AGI would substantially increase catastrophic risks from AI, including nuclear instability, and undermine the prospects of technical AI safety research to be effective. Second, the expected benefits of racing may be lower than proponents of AGI Racing hold. In particular, it is questionable whether winning the race enables complete domination over losers. Third, international cooperation and coordination, and perhaps carefully crafted deterrence measures, constitute viable alternatives to racing to AGI which have much smaller risks and promise to deliver most of the benefits that racing to AGI is supposed to provide. Hence, racing to AGI is not in anyone's self-interest as other actions, particularly incentivizing and seeking international cooperation around AI issues, are preferable.", 'abstract_zh': 'AGI竞赛的观点认为，在AI发展中的主要参与者，尤其是强大的国家，有动力加速前沿AI开发以建立高度 capable 的AI，尤其是人工通用智能（AGI），并在竞争对手之前占优。我们反对这一观点。首先，竞赛至AGI的负面风险远高于该观点所展现的水平。竞赛至AGI将显著增加AI带来的灾难性风险，包括核不稳定性，并损害技术AI安全性研究的有效性。其次，竞赛所带来的预期益处可能低于AGI竞赛倡导者所认为的水平。特别是，赢得竞赛是否能完全控制失败者存在疑问。第三，国际间合作与协调，以及可能精心设计的威慑措施，是竞赛至AGI的有效替代方案，风险更小，并有望提供竞赛至AGI所承诺的大部分益处。因此，竞赛至AGI并非符合任何一方利益的行为，特别是激励并寻求在AI问题上的国际间合作，更为优选。', 'title_zh': '反对急于迈向AGI：合作、威慑与灾难性风险'}
{'arxiv_id': 'arXiv:2507.21833', 'title': 'Analysis of Fourier Neural Operators via Effective Field Theory', 'authors': 'Taeyoung Kim', 'link': 'https://arxiv.org/abs/2507.21833', 'abstract': 'Fourier Neural Operators (FNOs) have emerged as leading surrogates for high-dimensional partial-differential equations, yet their stability, generalization and frequency behavior lack a principled explanation. We present the first systematic effective-field-theory analysis of FNOs in an infinite-dimensional function space, deriving closed recursion relations for the layer kernel and four-point vertex and then examining three practically important settings-analytic activations, scale-invariant cases and architectures with residual connections. The theory shows that nonlinear activations inevitably couple frequency inputs to high-frequency modes that are otherwise discarded by spectral truncation, and experiments confirm this frequency transfer. For wide networks we obtain explicit criticality conditions on the weight-initialization ensemble that keep small input perturbations to have uniform scale across depth, and empirical tests validate these predictions. Taken together, our results quantify how nonlinearity enables neural operators to capture non-trivial features, supply criteria for hyper-parameter selection via criticality analysis, and explain why scale-invariant activations and residual connections enhance feature learning in FNOs.', 'abstract_zh': 'Fourier神经算子（FNOs）已成为高维偏微分方程的主要代理模型，然而它们的稳定性、泛化能力和频率行为缺乏原理性的解释。我们首次系统地在无限维函数空间中分析FNOs的有效场理论，导出了层核和四点顶点的封闭递归关系，然后探讨了三个实际重要场景：解析激活函数、标度不变情况以及具有残差连接的架构。理论表明，非线性激活函数不可避免地将频率输入耦合到通过光谱截断丢弃的高频率模式中，实验也证实了这种频率转移。对于宽网络，我们得到了保持小输入扰动在深度上均匀尺度的具体临界条件，并实证测试验证了这些预测。综合我们的研究结果，量化了非线性如何使神经算子能够捕捉非平凡特性，提出了通过临界性分析选择超参数的准则，并解释了为何标度不变激活函数和残差连接在FNOs中增强特征学习。', 'title_zh': 'Fourier神经算子的有效场论分析'}
{'arxiv_id': 'arXiv:2507.21831', 'title': 'Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences', 'authors': 'Andreas Reich, Claudia Thoms, Tobias Schrimpf', 'link': 'https://arxiv.org/abs/2507.21831', 'abstract': 'LLMs are seeing widespread use for task automation, including automated coding in the social sciences. However, even though researchers have proposed different prompting strategies, their effectiveness varies across LLMs and tasks. Often trial and error practices are still widespread. We propose HALC$-$a general pipeline that allows for the systematic and reliable construction of optimal prompts for any given coding task and model, permitting the integration of any prompting strategy deemed relevant. To investigate LLM coding and validate our pipeline, we sent a total of 1,512 individual prompts to our local LLMs in over two million requests. We test prompting strategies and LLM task performance based on few expert codings (ground truth). When compared to these expert codings, we find prompts that code reliably for single variables (${\\alpha}$climate = .76; ${\\alpha}$movement = .78) and across two variables (${\\alpha}$climate = .71; ${\\alpha}$movement = .74) using the LLM Mistral NeMo. Our prompting strategies are set up in a way that aligns the LLM to our codebook$-$we are not optimizing our codebook for LLM friendliness. Our paper provides insights into the effectiveness of different prompting strategies, crucial influencing factors, and the identification of reliable prompts for each coding task and model.', 'abstract_zh': 'LLMs在社会科学研究中的自动化编码中得到广泛应用，但即使研究人员提出了不同的提示策略，这些策略在不同的LLMs和任务上的有效性也存在差异。通常仍广泛采用试错法。我们提出HALC——一个通用管道，能够系统可靠地为任何给定的编码任务和模型构建最优提示，允许集成任何认为相关的心策略。为了研究LLM编码并验证我们的管道，我们向本地LLM发送了超过两百万次请求，总共1,512个个体提示。我们基于少量专家编码（ ground truth）测试提示策略和LLM任务性能。与这些专家编码相比，我们发现使用Mistral NeMo的LLM在单变量（气候：α气候 = .76；运动：α运动 = .78）和跨两变量（气候：α气候 = .71；运动：α运动 = .74）编码方面表现出可靠的效果。我们的提示策略旨在使LLM与我们的代码簿保持一致——我们没有为LLM友好性优化我们的代码簿。本文提供了不同提示策略效果、关键影响因素以及为每种编码任务和模型识别可靠提示的见解。', 'title_zh': '介绍HALC：计算社会科学领域使用LLMs进行自动化编码的通用提示策略优化管道'}
{'arxiv_id': 'arXiv:2507.21799', 'title': 'Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer', 'authors': 'Xie Zhang, Yina Wang, Chenshu Wu', 'link': 'https://arxiv.org/abs/2507.21799', 'abstract': "The empirical success of deep learning has spurred its application to the radio-frequency (RF) domain, leading to significant advances in Deep Wireless Sensing (DWS). However, most existing DWS models function as black boxes with limited interpretability, which hampers their generalizability and raises concerns in security-sensitive physical applications. In this work, inspired by the remarkable advances of white-box transformers, we present RF-CRATE, the first mathematically interpretable deep network architecture for RF sensing, grounded in the principles of complex sparse rate reduction. To accommodate the unique RF signals, we conduct non-trivial theoretical derivations that extend the original real-valued white-box transformer to the complex domain. By leveraging the CR-Calculus framework, we successfully construct a fully complex-valued white-box transformer with theoretically derived self-attention and residual multi-layer perceptron modules. Furthermore, to improve the model's ability to extract discriminative features from limited wireless data, we introduce Subspace Regularization, a novel regularization strategy that enhances feature diversity, resulting in an average performance improvement of 19.98% across multiple sensing tasks. We extensively evaluate RF-CRATE against seven baselines with multiple public and self-collected datasets involving different RF signals. The results show that RF-CRATE achieves performance on par with thoroughly engineered black-box models, while offering full mathematical interpretability. More importantly, by extending CRATE to the complex domain, RF-CRATE yields substantial improvements, achieving an average classification gain of 5.08% and reducing regression error by 10.34% across diverse sensing tasks compared to CRATE. RF-CRATE is fully open-sourced at: this https URL.", 'abstract_zh': '射频CRATE：基于复稀疏率降低的可解释深度网络架构', 'title_zh': '解锁RF传感的可解释性：一种复值白盒Transformer'}
{'arxiv_id': 'arXiv:2507.21796', 'title': 'MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects', 'authors': 'Yuying Zhang, Kevin Sebastian Luck, Francesco Verdoja, Ville Kyrki, Joni Pajarinen', 'link': 'https://arxiv.org/abs/2507.21796', 'abstract': "Mobile manipulation is a critical capability for robots operating in diverse, real-world environments. However, manipulating deformable objects and materials remains a major challenge for existing robot learning algorithms. While various benchmarks have been proposed to evaluate manipulation strategies with rigid objects, there is still a notable lack of standardized benchmarks that address mobile manipulation tasks involving deformable objects.\nTo address this gap, we introduce MoDeSuite, the first Mobile Manipulation Deformable Object task suite, designed specifically for robot learning. MoDeSuite consists of eight distinct mobile manipulation tasks covering both elastic objects and deformable objects, each presenting a unique challenge inspired by real-world robot applications. Success in these tasks requires effective collaboration between the robot's base and manipulator, as well as the ability to exploit the deformability of the objects. To evaluate and demonstrate the use of the proposed benchmark, we train two state-of-the-art reinforcement learning algorithms and two imitation learning algorithms, highlighting the difficulties encountered and showing their performance in simulation. Furthermore, we demonstrate the practical relevance of the suite by deploying the trained policies directly into the real world with the Spot robot, showcasing the potential for sim-to-real transfer. We expect that MoDeSuite will open a novel research domain in mobile manipulation involving deformable objects. Find more details, code, and videos at this https URL.", 'abstract_zh': '移动操作是机器人在多样化真实环境作业的关键能力。然而，操纵变形物体和材料仍然是现有机器人学习算法的主要挑战。尽管提出了各种基准来评估使用刚性物体的操纵策略，但在涉及变形物体的移动操纵任务上仍然缺乏标准化基准。\n为解决这一缺口，我们引入了MoDeSuite，这是首个专门用于机器人学习的移动操纵变形物体任务套件。MoDeSuite 包含八个不同的移动操纵任务，涵盖了弹性物体和变形物体，每个任务都提出了源自实际机器人应用的独特挑战。任务的成功要求机器人基座与操作机构之间有效的协作，以及利用物体变形性的能力。为了评估和展示所提出的基准的使用，我们训练了两个最先进的强化学习算法和两个模仿学习算法，并强调了遇到的困难，展示了它们在模拟中的性能。此外，通过直接将训练策略部署到Spot机器人中，我们展示了套件的实际相关性，展示了从仿真到现实的过渡潜力。我们期望MoDeSuite 将开启移动操纵中涉及变形物体的新研究领域。更多细节、代码和视频请参见 <https://this-url>。', 'title_zh': 'MoDeSuite：用于柔体对象移动操作基准测试的机器人学习任务套件'}
{'arxiv_id': 'arXiv:2507.21790', 'title': 'Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities', 'authors': 'Georges Sfeir, Gabriel Nova, Stephane Hess, Sander van Cranenburgh', 'link': 'https://arxiv.org/abs/2507.21790', 'abstract': "Large Language Models (LLMs) are widely used to support various workflows across different disciplines, yet their potential in choice modelling remains relatively unexplored. This work examines the potential of LLMs as assistive agents in the specification and, where technically feasible, estimation of Multinomial Logit models. We implement a systematic experimental framework involving thirteen versions of six leading LLMs (ChatGPT, Claude, DeepSeek, Gemini, Gemma, and Llama) evaluated under five experimental configurations. These configurations vary along three dimensions: modelling goal (suggesting vs. suggesting and estimating MNLs); prompting strategy (Zero-Shot vs. Chain-of-Thoughts); and information availability (full dataset vs. data dictionary only). Each LLM-suggested specification is implemented, estimated, and evaluated based on goodness-of-fit metrics, behavioural plausibility, and model complexity. Findings reveal that proprietary LLMs can generate valid and behaviourally sound utility specifications, particularly when guided by structured prompts. Open-weight models such as Llama and Gemma struggled to produce meaningful specifications. Claude 4 Sonnet consistently produced the best-fitting and most complex models, while GPT models suggested models with robust and stable modelling outcomes. Some LLMs performed better when provided with just data dictionary, suggesting that limiting raw data access may enhance internal reasoning capabilities. Among all LLMs, GPT o3 was uniquely capable of correctly estimating its own specifications by executing self-generated code. Overall, the results demonstrate both the promise and current limitations of LLMs as assistive agents in choice modelling, not only for model specification but also for supporting modelling decision and estimation, and provide practical guidance for integrating these tools into choice modellers' workflows.", 'abstract_zh': '大型语言模型（LLMs）在支持各种跨学科工作流程方面被广泛应用，但在选择模型领域的潜力尚未得到充分探索。本研究考察了LLMs作为辅助代理在多选Logit模型的制定（在技术可行的情况下还包括估计）方面的潜力。我们实施了一个系统性的实验框架，涉及六款领先LLM（ChatGPT、Claude、DeepSeek、Gemini、Gemma、Llama）的十三个版本，在五个实验配置下进行评估。这些配置在三个维度上有所不同：建模目标（建议 vs. 建议和估计MNLogit模型）；提示策略（零样本 vs. 思维链）；信息可用性（完整数据集 vs. 仅数据字典）。每个LLM建议的建模规格被实施、估计，并根据拟合度指标、行为合理性以及模型复杂度进行评估。研究发现，专有LLM在结构化提示的引导下能生成有效且行为合理的效用规格，而开源权重模型如Llama和Gemma难以产生有意义的规格。Claude 4 Sonnet 一贯生成拟合度最好且最复杂的模型，而GPT模型建议的模型具有稳健且稳定的建模结果。一些LLM在仅数据字典的情况下表现更佳，表明限制原始数据访问可能增强内部推理能力。在所有LLM中，只有GPT o3独有能力通过执行自动生成的代码正确估计自己的规格。总体而言，研究结果展示了LLMs作为选择模型辅助代理的前景及其当前局限性，不仅在模型制定方面，也在支持建模决策和估计方面，并为将这些工具整合到选择模型的工作流程中提供了实用指导。', 'title_zh': '大型语言模型能够辅助选择建模吗？关于提示策略和当前模型能力的 Insights'}
{'arxiv_id': 'arXiv:2507.21770', 'title': "Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's NLP Results", 'authors': 'Ali Fallahi, Azam Bastanfard, Amineh Amini, Hadi Saboohi', 'link': 'https://arxiv.org/abs/2507.21770', 'abstract': "The importance of recommender systems on the web has grown, especially in the movie industry, with a vast selection of options to watch. To assist users in traversing available items and finding relevant results, recommender systems analyze operational data and investigate users' tastes and habits. Providing highly individualized suggestions can boost user engagement and satisfaction, which is one of the fundamental goals of the movie industry, significantly in online platforms. According to recent studies and research, using knowledge-based techniques and considering the semantic ideas of the textual data is a suitable way to get more appropriate results. This study provides a new method for building a knowledge graph based on semantic information. It uses the ChatGPT, as a large language model, to assess the brief descriptions of movies and extract their tone of voice. Results indicated that using the proposed method may significantly enhance accuracy rather than employing the explicit genres supplied by the publishers.", 'abstract_zh': '基于语义信息的推荐系统知识图构建方法研究', 'title_zh': '基于ChatGPT自然语言处理结果增强的语义电影推荐系统'}
{'arxiv_id': 'arXiv:2507.21763', 'title': 'Learning Kinetic Monte Carlo stochastic dynamics with Deep Generative Adversarial Networks', 'authors': 'Daniele Lanzoni, Olivier Pierre-Louis, Roberto Bergamaschini, Francesco Montalenti', 'link': 'https://arxiv.org/abs/2507.21763', 'abstract': 'We show that Generative Adversarial Networks (GANs) may be fruitfully exploited to learn stochastic dynamics, surrogating traditional models while capturing thermal fluctuations. Specifically, we showcase the application to a two-dimensional, many-particle system, focusing on surface-step fluctuations and on the related time-dependent roughness. After the construction of a dataset based on Kinetic Monte Carlo simulations, a conditional GAN is trained to propagate stochastically the state of the system in time, allowing the generation of new sequences with a reduced computational cost. Modifications with respect to standard GANs, which facilitate convergence and increase accuracy, are discussed. The trained network is demonstrated to quantitatively reproduce equilibrium and kinetic properties, including scaling laws, with deviations of a few percent from the exact value. Extrapolation limits and future perspectives are critically discussed.', 'abstract_zh': '我们展示了生成式对抗网络（GANs）可以有效地用于学习随机动力学，替代传统模型并捕捉热波动。具体而言，我们展示了其在二维多粒子系统中的应用，重点关注表面台阶的波动以及相关的时变粗糙度。基于基于动力蒙特卡洛模拟构建的数据集，我们训练了一个条件GAN来随时间推进系统的状态，从而生成新的序列并降低计算成本。关于标准GANs的改进之处，有助于提高收敛性和准确性。训练后的网络被证明能够定量再现平衡和动力学性质，偏差几百分点。我们批判性地讨论了其外推限制和未来展望。', 'title_zh': '使用深度生成对抗网络学习动力学蒙特卡洛随机动力学'}
{'arxiv_id': 'arXiv:2507.21756', 'title': 'LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection', 'authors': 'Jing Ren, Suyu Ma, Hong Jia, Xiwei Xu, Ivan Lee, Haytham Fayek, Xiaodong Li, Feng Xia', 'link': 'https://arxiv.org/abs/2507.21756', 'abstract': 'Detecting driver fatigue is critical for road safety, as drowsy driving remains a leading cause of traffic accidents. Many existing solutions rely on computationally demanding deep learning models, which result in high latency and are unsuitable for embedded robotic devices with limited resources (such as intelligent vehicles/cars) where rapid detection is necessary to prevent accidents. This paper introduces LiteFat, a lightweight spatio-temporal graph learning model designed to detect driver fatigue efficiently while maintaining high accuracy and low computational demands. LiteFat involves converting streaming video data into spatio-temporal graphs (STG) using facial landmark detection, which focuses on key motion patterns and reduces unnecessary data processing. LiteFat uses MobileNet to extract facial features and create a feature matrix for the STG. A lightweight spatio-temporal graph neural network is then employed to identify signs of fatigue with minimal processing and low latency. Experimental results on benchmark datasets show that LiteFat performs competitively while significantly decreasing computational complexity and latency as compared to current state-of-the-art methods. This work enables the development of real-time, resource-efficient human fatigue detection systems that can be implemented upon embedded robotic devices.', 'abstract_zh': '检测驾驶员疲劳对于道路安全至关重要，因为困倦驾驶仍然是导致交通事故的主要原因之一。许多现有解决方案依赖于计算需求高的深度学习模型，这导致了高延迟，并不适合资源有限（如智能车辆/汽车）的嵌入式机器人设备，而这些设备需要快速检测以防止事故。本文介绍了一种轻量级时空图学习模型LiteFat，旨在高效地检测驾驶员疲劳同时保持高准确性和低计算需求。LiteFat涉及使用面部特征点检测将流式视频数据转换为时空图（STG），并专注于关键运动模式以减少不必要的数据处理。LiteFat使用MobileNet提取面部特征并创建STG的特征矩阵。然后使用轻量级时空图神经网络以最少的处理和低延迟来识别疲劳迹象。基准数据集上的实验结果表明，与当前最先进的方法相比，LiteFat在显著降低计算复杂性和延迟的同时保持了竞争力。此项工作使开发实时、资源高效的人体疲劳检测系统成为可能，并可在嵌入式机器人设备上实现。', 'title_zh': 'LiteFat: 轻量级时空图学习及其在实时驾驶疲劳检测中的应用'}
{'arxiv_id': 'arXiv:2507.21738', 'title': 'Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation', 'authors': 'Huiqiang Chen, Tianqing Zhu, Xin Yu, Wanlei Zhou', 'link': 'https://arxiv.org/abs/2507.21738', 'abstract': "Machine unlearning aims to remove the influence of specific samples from a trained model. A key challenge in this process is over-unlearning, where the model's performance on the remaining data significantly drops due to the change in the model's parameters. Existing unlearning algorithms depend on the remaining data to prevent this issue. As such, these methods are inapplicable in a more practical scenario, where only the unlearning samples are available (i.e., zero-shot unlearning). This paper presents a novel framework, ZS-PAG, to fill this gap. Our approach offers three key innovations: (1) we approximate the inaccessible remaining data by generating adversarial samples; (2) leveraging the generated samples, we pinpoint a specific subspace to perform the unlearning process, therefore preventing over-unlearning in the challenging zero-shot scenario; and (3) we consider the influence of the unlearning process on the remaining samples and design an influence-based pseudo-labeling strategy. As a result, our method further improves the model's performance after unlearning. The proposed method holds a theoretical guarantee, and experiments on various benchmarks validate the effectiveness and superiority of our proposed method over several baselines.", 'abstract_zh': '零样本机器遗忘框架ZS-PAG的研究', 'title_zh': '零样本机器去学习与代理对抗数据生成'}
{'arxiv_id': 'arXiv:2507.21723', 'title': 'Detection Transformers Under the Knife: A Neuroscience-Inspired Approach to Ablations', 'authors': 'Nils Hütten, Florian Hölken, Hasan Tercan, Tobias Meisen', 'link': 'https://arxiv.org/abs/2507.21723', 'abstract': "In recent years, Explainable AI has gained traction as an approach to enhancing model interpretability and transparency, particularly in complex models such as detection transformers. Despite rapid advancements, a substantial research gap remains in understanding the distinct roles of internal components - knowledge that is essential for improving transparency and efficiency. Inspired by neuroscientific ablation studies, which investigate the functions of brain regions through selective impairment, we systematically analyze the impact of ablating key components in three state-of-the-art detection transformer models: Detection transformer (DETR), deformable detection transformer (DDETR), and DETR with improved denoising anchor boxes (DINO). The ablations target query embeddings, encoder and decoder multi-head self-attentions (MHSA) as well as decoder multi-head cross-attention (MHCA) layers. We evaluate the effects of these ablations on the performance metrics gIoU and F1-score, quantifying effects on both the classification and regression sub-tasks on the COCO dataset. To facilitate reproducibility and future research, we publicly release the DeepDissect library. Our findings reveal model-specific resilience patterns: while DETR is particularly sensitive to ablations in encoder MHSA and decoder MHCA, DDETR's multi-scale deformable attention enhances robustness, and DINO exhibits the greatest resilience due to its look-forward twice update rule, which helps distributing knowledge across blocks. These insights also expose structural redundancies, particularly in DDETR's and DINO's decoder MHCA layers, highlighting opportunities for model simplification without sacrificing performance. This study advances XAI for DETRs by clarifying the contributions of internal components to model performance, offering insights to optimize and improve transparency and efficiency in critical applications.", 'abstract_zh': '近年来，可解释AI在提高模型可解释性和透明度方面取得了进展，尤其是在检测变换器等复杂模型中。尽管取得了 rapid advancements，但在理解内部组件的独特作用方面仍然存在显著的研究空白，这对于提高透明度和效率至关重要。受神经科学消融研究的启发，这些研究通过选择性损伤来研究大脑区域的功能，我们系统地分析了在三种先进的检测变换器模型（Detection Transformer (DETR)、Deformable Detection Transformer (DDETR) 和 Improved Denoising Anchor Boxes for DETR (DINO)）中消融关键组件的影响。消融实验针对查询嵌入、编码器和解码器的多头自注意力（MHSA）以及解码器的多头交叉注意力（MHCA）层。我们评估了这些消融对gIoU和F1分数等性能指标的影响，量化了分类和回归子任务在COCO数据集上的影响。为了便于再现性和未来研究，我们公开发布了DeepDissect库。我们的研究揭示了模型特定的抗消融模式：虽然DETR对编码器MHSA和解码器MHCA的消融特别敏感，但DDETR的多尺度可变形注意力增强了鲁棒性，而DINO则表现出最大的抗消融性，这归因于其向前更新两次的规则，该规则有助于知识在各块间的分布。这些见解还揭示了结构冗余，特别是在DDETR和DINO的解码器MHCA层中发现，突显了在不牺牲性能的情况下简化模型的机会。该研究通过阐明内部组件对模型性能的贡献，推进了检测变换器的可解释AI，为优化和改进关键应用中的透明度和效率提供了洞察。', 'title_zh': 'Detection Transformers 在显微刀下：一种受神经科学启发的消融方法'}
{'arxiv_id': 'arXiv:2507.21706', 'title': 'EnTao-GPM: DNA Foundation Model for Predicting the Germline Pathogenic Mutations', 'authors': 'Zekai Lin, Haoran Sun, Yucheng Guo, Yujie Yang, Yanwen Wang, Bozhen Hu, Chonghang Ye, Qirong Yang, Fan Zhong, Xiaoming Zhang, Lei Liu', 'link': 'https://arxiv.org/abs/2507.21706', 'abstract': 'Distinguishing pathogenic mutations from benign polymorphisms remains a critical challenge in precision medicine. EnTao-GPM, developed by Fudan University and BioMap, addresses this through three innovations: (1) Cross-species targeted pre-training on disease-relevant mammalian genomes (human, pig, mouse), leveraging evolutionary conservation to enhance interpretation of pathogenic motifs, particularly in non-coding regions; (2) Germline mutation specialization via fine-tuning on ClinVar and HGMD, improving accuracy for both SNVs and non-SNVs; (3) Interpretable clinical framework integrating DNA sequence embeddings with LLM-based statistical explanations to provide actionable insights. Validated against ClinVar, EnTao-GPM demonstrates superior accuracy in mutation classification. It revolutionizes genetic testing by enabling faster, more accurate, and accessible interpretation for clinical diagnostics (e.g., variant assessment, risk identification, personalized treatment) and research, advancing personalized medicine.', 'abstract_zh': '从良性多态性中区分致病变异仍然是精准医学中的一个关键挑战。复旦大学和BioMap开发的EnTao-GPM通过三项创新解决了这一问题：(1) 跨物种靶向预训练于与疾病相关的哺乳动物基因组（人类、猪、小鼠），利用进化保守性增强对致病变异体的解释，特别是在非编码区域；(2) 通过在ClinVar和HGMD上进行微调专门化于生殖细胞突变，提高对单核苷酸变异和非单核苷酸变异的准确性；(3) 可解释的临床框架，将DNA序列嵌入与基于LLM的统计解释相结合，提供可操作的见解。EnTao-GPM在ClinVar上验证显示了在突变分类中的优越准确性。它通过使遗传测试更快、更准确和更有可及性，革命性地改变了临床诊断（如变异评估、风险识别、个性化治疗）和研究，推进了个性化医学。', 'title_zh': 'EnTao-GPM: DNA 基础模型用于预测遗传致病变异'}
{'arxiv_id': 'arXiv:2507.21695', 'title': 'Towards a Large Physics Benchmark', 'authors': 'Kristian G. Barman, Sascha Caron, Faegheh Hasibi, Eugene Shalugin, Yoris Marcet, Johannes Otte, Henk W. de Regt, Merijn Moody', 'link': 'https://arxiv.org/abs/2507.21695', 'abstract': 'We introduce a benchmark framework developed by and for the scientific community to evaluate, monitor and steer large language model development in fundamental physics. Building on philosophical concepts of scientific understanding and creativity, we develop a scoring system in which each question is scored by an expert for its correctness, difficulty, and surprise. The questions are of three forms: (i) multiple-choice questions for conceptual understanding, (ii) analytical problems requiring mathematical derivation, and (iii) openended tasks requiring complex problem solving. Our current dataset contains diverse set of examples, including a machine learning challenge to classify high-energy physics events, such as the four top quark signal. To ensure continued relevance, we propose a living benchmark, where physicists contribute questions, for instance alongside new publications. We invite contributions via: this http URL. We hope that this benchmark will enable a targeted AI development that can make a meaningful contribution to fundamental physics research.', 'abstract_zh': '我们介绍了由科学界开发的基准框架，用于评估、监控和引导大型语言模型在基础物理学中的发展。基于科学理解与创造性的哲学概念，我们开发了一种评分系统，其中每个问题都由专家从正确性、难度和惊喜度三个方面进行评分。问题分为三种类型：（i）概念性理解的多项选择题，（ii）需要数学推导的分析性问题，以及（iii）需要复杂问题解决的开放型任务。目前数据集中包含多种类型的示例，包括用于分类高能物理事件的机器学习挑战，如顶夸克四体信号分类。为了保持持续的相关性，我们提出了一种活的基准框架，物理学家可以贡献问题，例如与新的出版物同时贡献。我们邀请通过以下链接贡献：this http URL。我们希望这一基准框架能够促进有针对性的AI开发，为基础物理学研究作出有意义的贡献。', 'title_zh': '朝着大型物理基准的方向'}
{'arxiv_id': 'arXiv:2507.21694', 'title': 'A Multi-Agent Generative AI Framework for IC Module-Level Verification Automation', 'authors': 'Wenbo Liu, Forbes Hou, Jon Zhang, Hong Liu, Allen Lei', 'link': 'https://arxiv.org/abs/2507.21694', 'abstract': 'As large language models demonstrate enormous potential in the field of Electronic Design Automation (EDA), generative AI-assisted chip design is attracting widespread attention from academia and industry. Although these technologies have made preliminary progress in tasks such as code generation, their application in chip verification -- a critical bottleneck in the chip development cycle -- remains at an exploratory stage. This paper proposes an innovative Multi-Agent Verification Framework (MAVF) aimed at addressing the limitations of current single-LLM approaches in complex verification tasks. Our framework builds an automated transformation system from design specifications to testbench through the collaborative work of multiple specialized agents, including specification parsing, verification strategy generation, and code implementation. Through verification experiments on multiple chip modules of varying complexity, results show that MAVF significantly outperforms traditional manual methods and single-dialogue generative AI approaches in verification document parsing and generation, as well as automated testbench generation. This research opens new directions for exploring generative AI applications in verification automation, potentially providing effective approaches to solving the most challenging bottleneck issues in chip design.', 'abstract_zh': '电子设计自动化领域中大型语言模型的潜力使生成式AI辅助芯片设计引起了学术界和工业界的广泛关注。尽管这些技术在代码生成等任务上取得了一些初步进展，但在芯片验证——芯片开发周期中的一个关键瓶颈——上的应用仍处于探索阶段。本文提出了一种创新的多代理验证框架(MAVF)，旨在解决当前单大型语言模型方法在复杂验证任务中的局限性。该框架通过多个专门代理的协作工作，从设计规范自动生成测试平台，包括规范解析、验证策略生成和代码实现。通过多种复杂度的芯片模块验证实验，结果显示，MAVF在验证文档解析与生成以及自动化测试平台生成方面的性能显著优于传统的手工方法和单轮对话生成式AI方法。这项研究为探索生成式AI在验证自动化中的应用打开了新的方向，可能为解决芯片设计中最具挑战性的瓶颈问题提供有效的解决方案。', 'title_zh': '多代理生成式AI框架用于IC模块级验证自动化'}
{'arxiv_id': 'arXiv:2507.21693', 'title': 'MultiAIGCD: A Comprehensive dataset for AI Generated Code Detection Covering Multiple Languages, Models,Prompts, and Scenarios', 'authors': 'Basak Demirok, Mucahid Kutlu, Selin Mergen', 'link': 'https://arxiv.org/abs/2507.21693', 'abstract': "As large language models (LLMs) rapidly advance, their role in code generation has expanded significantly. While this offers streamlined development, it also creates concerns in areas like education and job interviews. Consequently, developing robust systems to detect AI-generated code is imperative to maintain academic integrity and ensure fairness in hiring processes. In this study, we introduce MultiAIGCD, a dataset for AI-generated code detection for Python, Java, and Go. From the CodeNet dataset's problem definitions and human-authored codes, we generate several code samples in Java, Python, and Go with six different LLMs and three different prompts. This generation process covered three key usage scenarios: (i) generating code from problem descriptions, (ii) fixing runtime errors in human-written code, and (iii) correcting incorrect outputs. Overall, MultiAIGCD consists of 121,271 AI-generated and 32,148 human-written code snippets. We also benchmark three state-of-the-art AI-generated code detection models and assess their performance in various test scenarios such as cross-model and cross-language. We share our dataset and codes to support research in this field.", 'abstract_zh': '随着大规模语言模型（LLMs）的迅速发展，它们在代码生成中的作用显著扩大。尽管这为开发提供了便利，但也引发了教育和面试等领域的关注。因此，开发 robust 的系统来检测 AI 生成的代码以维护学术诚信和确保招聘过程的公平性至关重要。在本研究中，我们介绍了 MultiAIGCD，一个用于 Python、Java 和 Go 语言的 AI 生成代码检测数据集。从 CodeNet 数据集的问题定义和人类编写的代码中，我们使用六种不同的 LLM 和三种不同的提示生成了多项代码样本。生成过程涵盖了三个关键应用场景：（i）从问题描述生成代码，（ii）修复人类编写的代码中的运行时错误，以及（iii）纠正错误输出。总体而言，MultiAIGCD 包含 121,271 个 AI 生成的代码片段和 32,148 个人类编写的代码片段。我们还对三种最先进的 AI 生成代码检测模型进行了基准测试，并评估了它们在各种测试场景中的性能，例如跨模型和跨语言。我们分享我们的数据集和代码以支持该领域的研究。', 'title_zh': 'MultiAIGCD：一个涵盖多种语言、模型、提示和场景的综合AI生成代码检测数据集'}
{'arxiv_id': 'arXiv:2507.21690', 'title': 'APT: Improving Diffusion Models for High Resolution Image Generation with Adaptive Path Tracing', 'authors': 'Sangmin Han, Jinho Jeong, Jinwoo Kim, Seon Joo Kim', 'link': 'https://arxiv.org/abs/2507.21690', 'abstract': 'Latent Diffusion Models (LDMs) are generally trained at fixed resolutions, limiting their capability when scaling up to high-resolution images. While training-based approaches address this limitation by training on high-resolution datasets, they require large amounts of data and considerable computational resources, making them less practical. Consequently, training-free methods, particularly patch-based approaches, have become a popular alternative. These methods divide an image into patches and fuse the denoising paths of each patch, showing strong performance on high-resolution generation. However, we observe two critical issues for patch-based approaches, which we call ``patch-level distribution shift" and ``increased patch monotonicity." To address these issues, we propose Adaptive Path Tracing (APT), a framework that combines Statistical Matching to ensure patch distributions remain consistent in upsampled latents and Scale-aware Scheduling to deal with the patch monotonicity. As a result, APT produces clearer and more refined details in high-resolution images. In addition, APT enables a shortcut denoising process, resulting in faster sampling with minimal quality degradation. Our experimental results confirm that APT produces more detailed outputs with improved inference speed, providing a practical approach to high-resolution image generation.', 'abstract_zh': '潜扩散模型（LDMs）通常在固定分辨率下训练，这限制了它们在扩大到高分辨率图像时的能力。虽然基于训练的方法通过在高分辨率数据集上进行训练来解决这一限制，但它们需要大量的数据和大量的计算资源，使其不够实用。因此，无训练方法，特别是基于补丁的方法，已成为一种流行的替代方案。这些方法将图像划分为补丁，并融合每个补丁的去噪路径，展现出在高分辨率生成方面的强大性能。然而，我们观察到补丁方法存在两个关键问题，称为“补丁级别分布偏移”和“增加的补丁单调性”。为了解决这些问题，我们提出了一种结合统计匹配和尺度感知调度的自适应路径追踪（APT）框架，以确保上采样潜在变量中的补丁分布保持一致，并处理补丁单调性问题。结果，APT 能够生成更清晰和更精细的高分辨率图像细节。此外，APT 允许一个捷径去噪过程，从而实现快速采样，且质量下降最小。我们的实验结果证实，APT 能够生成更详细且推理速度更快的输出，提供了一种高分辨率图像生成的实用方法。', 'title_zh': 'APT：通过自适应路径跟踪提高高分辨率图像生成的扩散模型性能'}
{'arxiv_id': 'arXiv:2507.21684', 'title': 'diffSPH: Differentiable Smoothed Particle Hydrodynamics for Adjoint Optimization and Machine Learning', 'authors': 'Rene Winchenbach, Nils Thuerey', 'link': 'https://arxiv.org/abs/2507.21684', 'abstract': "We present diffSPH, a novel open-source differentiable Smoothed Particle Hydrodynamics (SPH) framework developed entirely in PyTorch with GPU acceleration. diffSPH is designed centrally around differentiation to facilitate optimization and machine learning (ML) applications in Computational Fluid Dynamics~(CFD), including training neural networks and the development of hybrid models. Its differentiable SPH core, and schemes for compressible (with shock capturing and multi-phase flows), weakly compressible (with boundary handling and free-surface flows), and incompressible physics, enable a broad range of application areas. We demonstrate the framework's unique capabilities through several applications, including addressing particle shifting via a novel, target-oriented approach by minimizing physical and regularization loss terms, a task often intractable in traditional solvers. Further examples include optimizing initial conditions and physical parameters to match target trajectories, shape optimization, implementing a solver-in-the-loop setup to emulate higher-order integration, and demonstrating gradient propagation through hundreds of full simulation steps. Prioritizing readability, usability, and extensibility, this work offers a foundational platform for the CFD community to develop and deploy novel neural networks and adjoint optimization applications.", 'abstract_zh': '我们介绍diffSPH：一种完全基于PyTorch并利用GPU加速的新型开放源代码可微分光滑粒子流体力学（SPH）框架，及其在计算流体力学（CFD）中的优化和机器学习应用。', 'title_zh': 'diffSPH: 可微光滑粒子动力学在伴随优化和机器学习中的应用'}
{'arxiv_id': 'arXiv:2507.21654', 'title': 'AI Literacy as a Key Driver of User Experience in AI-Powered Assessment: Insights from Socratic Mind', 'authors': 'Meryem Yilmaz Soylu, Jeonghyun Lee, Jui-Tse Hung, Christopher Zhang Cui, David A. Joyner', 'link': 'https://arxiv.org/abs/2507.21654', 'abstract': "As Artificial Intelligence (AI) tools become increasingly embedded in higher education, understanding how students interact with these systems is essential to supporting effective learning. This study examines how students' AI literacy and prior exposure to AI technologies shape their perceptions of Socratic Mind, an interactive AI-powered formative assessment tool. Drawing on Self-Determination Theory and user experience research, we analyze relationships among AI literacy, perceived usability, satisfaction, engagement, and perceived learning effectiveness. Data from 309 undergraduates in Computer Science and Business courses were collected through validated surveys. Partial least squares structural equation modeling showed that AI literacy - especially self-efficacy, conceptual understanding, and application skills - significantly predicts usability, satisfaction, and engagement. Usability and satisfaction, in turn, strongly predict perceived learning effectiveness, while prior AI exposure showed no significant effect. These findings highlight that AI literacy, rather than exposure alone, shapes student experiences. Designers should integrate adaptive guidance and user-centered features to support diverse literacy levels, fostering inclusive, motivating, and effective AI-based learning environments.", 'abstract_zh': '随着人工智能（AI）工具在高等教育中的广泛应用，理解学生与这些系统交互的方式对于支持有效的学习至关重要。本研究探讨了学生的AI素养和对AI技术的先前接触如何影响他们对Socratic Mind的认知，这是一种交互式AI驱动的形式化评估工具。基于自我决定理论和用户经验研究，我们分析了AI素养、感知可用性、满意度、参与度和感知学习有效性之间的关系。通过使用经过验证的问卷收集了309名计算机科学和商学课程学生的数据。部分最小二乘结构方程模型显示，AI素养——尤其是自我效能感、概念理解和应用技能——显著预测了可用性、满意度和参与度。而可用性与满意度又强烈预测了感知学习有效性，而先前的AI接触则没有显著影响。这些发现强调，与单一的接触相比，AI素养塑造了学生的学习体验。设计师应整合自适应指导和用户中心的功能，以支持多样化的素养水平，促进包容性、激励性和有效的基于AI的学习环境。', 'title_zh': 'AI素养作为AI驱动评估中用户经验的关键驱动因素：苏格拉底思维的洞见'}
{'arxiv_id': 'arXiv:2507.21653', 'title': 'DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs', 'authors': 'Yuan Li, Jun Hu, Bryan Hooi, Bingsheng He, Cheng Chen', 'link': 'https://arxiv.org/abs/2507.21653', 'abstract': "Real-world fraud detection applications benefit from graph learning techniques that jointly exploit node features, often rich in textual data, and graph structural information. Recently, Graph-Enhanced LLMs emerge as a promising graph learning approach that converts graph information into prompts, exploiting LLMs' ability to reason over both textual and structural information. Among them, text-only prompting, which converts graph information to prompts consisting solely of text tokens, offers a solution that relies only on LLM tuning without requiring additional graph-specific encoders. However, text-only prompting struggles on heterogeneous fraud-detection graphs: multi-hop relations expand exponentially with each additional hop, leading to rapidly growing neighborhoods associated with dense textual information. These neighborhoods may overwhelm the model with long, irrelevant content in the prompt and suppress key signals from the target node, thereby degrading performance. To address this challenge, we propose Dual Granularity Prompting (DGP), which mitigates information overload by preserving fine-grained textual details for the target node while summarizing neighbor information into coarse-grained text prompts. DGP introduces tailored summarization strategies for different data modalities, bi-level semantic abstraction for textual fields and statistical aggregation for numerical features, enabling effective compression of verbose neighbor content into concise, informative prompts. Experiments across public and industrial datasets demonstrate that DGP operates within a manageable token budget while improving fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods, showing the potential of Graph-Enhanced LLMs for fraud detection.", 'abstract_zh': '面向现实世界的欺诈检测应用受益于能够综合运用节点特征和图结构信息的图学习技术。最近，增强图学习的LLMs emerg作为一种有前景的图学习方法，能够将图信息转换为提示，利用LLMs在处理文本和结构信息方面的推理能力。其中，仅基于文本的提示，将图信息转换为仅由文本标记组成的提示，提供了一种仅依赖于LLMs微调而不需要额外图特定编码器的解决方案。然而，仅基于文本的提示在异构欺诈检测图上表现不佳：多跳关系随每一跳的增加而指数级扩展，导致关联密集文本信息的邻域迅速增长。这些邻域可能会在提示中压倒模型，引入大量冗余内容，从而抑制目标节点的关键信号，导致性能下降。为解决这一挑战，我们提出了双粒度提示 (DGP)，通过保留目标节点的细粒度文本细节，同时将邻居信息总结为粗粒度文本提示来减轻信息过载。DGP 引入了针对不同数据模态的定制总结策略、文本字段的双层语义抽象以及数值特征的统计聚合，使冗长的邻居内容能够被有效地压缩成简洁且具有信息量的提示。跨公开和工业数据集的实验表明，DGP 在合理控制标记预算的同时，相比现有方法在欺诈检测性能上提高了最多 6.8%（AUPRC），展示了增强图学习的LLMs在欺诈检测中的潜力。', 'title_zh': 'DGP：一种结合图增强大语言模型的双粒度提示框架用于欺诈检测'}
{'arxiv_id': 'arXiv:2507.21640', 'title': 'GUARD-CAN: Graph-Understanding and Recurrent Architecture for CAN Anomaly Detection', 'authors': 'Hyeong Seon Kim, Huy Kang Kim', 'link': 'https://arxiv.org/abs/2507.21640', 'abstract': 'Modern in-vehicle networks face various cyber threats due to the lack of encryption and authentication in the Controller Area Network (CAN). To address this security issue, this paper presents GUARD-CAN, an anomaly detection framework that combines graph-based representation learning with time-series modeling. GUARD-CAN splits CAN messages into fixed-length windows and converts each window into a graph that preserves message order. To detect anomalies in the timeaware and structure-aware context at the same window, GUARD-CAN takes advantage of the overcomplete Autoencoder (AE) and Graph Convolutional Network (GCN) to generate graph embedding vectors. The model groups these vectors into sequences and feeds them into the Gated Recurrent Unit (GRU) to detect temporal anomaly patterns across the graphs. GUARD-CAN performs anomaly detection at both the sequence level and the window level, and this allows multi-perspective performance evaluation. The model also verifies the importance of window size selection through an analysis based on Shannon entropy. As a result, GUARD-CAN shows that the proposed model detects four types of CAN attacks (flooding, fuzzing, replay and spoofing attacks) effectively without relying on complex feature engineering.', 'abstract_zh': 'GUARD-CAN：一种结合图表示学习与时间序列建模的异常检测框架', 'title_zh': 'GUARD-CAN: 基于图理解的循环架构用于CAN异常检测'}
{'arxiv_id': 'arXiv:2507.21591', 'title': 'Hierarchical Graph Neural Network for Compressed Speech Steganalysis', 'authors': 'Mustapha Hemis, Hamza Kheddar, Mohamed Chahine Ghanem, Bachir Boudraa', 'link': 'https://arxiv.org/abs/2507.21591', 'abstract': 'Steganalysis methods based on deep learning (DL) often struggle with computational complexity and challenges in generalizing across different datasets. Incorporating a graph neural network (GNN) into steganalysis schemes enables the leveraging of relational data for improved detection accuracy and adaptability. This paper presents the first application of a Graph Neural Network (GNN), specifically the GraphSAGE architecture, for steganalysis of compressed voice over IP (VoIP) speech streams. The method involves straightforward graph construction from VoIP streams and employs GraphSAGE to capture hierarchical steganalysis information, including both fine grained details and high level patterns, thereby achieving high detection accuracy. Experimental results demonstrate that the developed approach performs well in uncovering quantization index modulation (QIM)-based steganographic patterns in VoIP signals. It achieves detection accuracy exceeding 98 percent even for short 0.5 second samples, and 95.17 percent accuracy under challenging conditions with low embedding rates, representing an improvement of 2.8 percent over the best performing state of the art methods. Furthermore, the model exhibits superior efficiency, with an average detection time as low as 0.016 seconds for 0.5-second samples an improvement of 0.003 seconds. This makes it efficient for online steganalysis tasks, providing a superior balance between detection accuracy and efficiency under the constraint of short samples with low embedding rates.', 'abstract_zh': '基于深度学习的隐写分析方法往往面临计算复杂度高和跨不同数据集泛化的挑战。将图神经网络（GNN）集成到隐写分析方案中，可以利用关系数据以提高检测准确性和适应性。本文首次将图神经网络（GNN），具体为GraphSAGE架构，应用于压缩VoIP语音流的隐写分析。该方法从VoIP流构建简单图，并利用GraphSAGE捕获分层隐写分析信息，包括细粒度细节和高层次模式，从而实现高检测准确率。实验结果表明，该方法在揭开基于量化指数调制（QIM）的VoIP信号隐写图模式方面表现出色，即使对于0.5秒的短样本，检测准确率也超过98%，在低嵌入率的挑战性条件下，准确率为95.17%，比最佳现有方法高出2.8%。此外，该模型表现出更高的效率，对于0.5秒的样本，平均检测时间为0.016秒，比之前方法快0.003秒，这使其适用于在线隐写分析任务，在短样本和低嵌入率的约束下实现了检测准确率与效率之间的优化平衡。', 'title_zh': '分层图神经网络在压缩语音隐写分析中的应用'}
{'arxiv_id': 'arXiv:2507.21533', 'title': 'Model Predictive Adversarial Imitation Learning for Planning from Observation', 'authors': 'Tyler Han, Yanda Bao, Bhaumik Mehta, Gabriel Guo, Anubhav Vishwakarma, Emily Kang, Sanghun Jung, Rosario Scalise, Jason Zhou, Bryan Xu, Byron Boots', 'link': 'https://arxiv.org/abs/2507.21533', 'abstract': 'Human demonstration data is often ambiguous and incomplete, motivating imitation learning approaches that also exhibit reliable planning behavior. A common paradigm to perform planning-from-demonstration involves learning a reward function via Inverse Reinforcement Learning (IRL) then deploying this reward via Model Predictive Control (MPC). Towards unifying these methods, we derive a replacement of the policy in IRL with a planning-based agent. With connections to Adversarial Imitation Learning, this formulation enables end-to-end interactive learning of planners from observation-only demonstrations. In addition to benefits in interpretability, complexity, and safety, we study and observe significant improvements on sample efficiency, out-of-distribution generalization, and robustness. The study includes evaluations in both simulated control benchmarks and real-world navigation experiments using few-to-single observation-only demonstrations.', 'abstract_zh': '人类示范数据常常模糊且不完整，促使采用也表现出可靠规划行为的模仿学习方法。进行从示范中规划的方法通常涉及通过逆强化学习（IRL）学习奖励函数，然后通过模型预测控制（MPC）部署该奖励。为了统一这些方法，我们推导出IRL中策略的一种基于规划的替代方案。借助对抗模仿学习的联系，这种形式化方法能够通过仅凭观察进行端到端的交互式学习规划器。除了提高可解释性、复杂性和安全性之外，我们研究并观察到在样本效率、域外泛化能力和鲁棒性方面有显著改进。研究包括在模拟控制基准和使用少量至单个仅凭观察的演示进行真实世界导航实验的评估。', 'title_zh': '基于观察的模型预测对抗模仿学习规划'}
{'arxiv_id': 'arXiv:2507.21532', 'title': 'Automatic Classification of User Requirements from Online Feedback -- A Replication Study', 'authors': 'Meet Bhatt, Nic Boilard, Muhammad Rehan Chaudhary, Cole Thompson, Jacob Idoko, Aakash Sorathiya, Gouri Ginde', 'link': 'https://arxiv.org/abs/2507.21532', 'abstract': 'Natural language processing (NLP) techniques have been widely applied in the requirements engineering (RE) field to support tasks such as classification and ambiguity detection. Although RE research is rooted in empirical investigation, it has paid limited attention to replicating NLP for RE (NLP4RE) studies. The rapidly advancing realm of NLP is creating new opportunities for efficient, machine-assisted workflows, which can bring new perspectives and results to the forefront. Thus, we replicate and extend a previous NLP4RE study (baseline), "Classifying User Requirements from Online Feedback in Small Dataset Environments using Deep Learning", which evaluated different deep learning models for requirement classification from user reviews. We reproduced the original results using publicly released source code, thereby helping to strengthen the external validity of the baseline study. We then extended the setup by evaluating model performance on an external dataset and comparing results to a GPT-4o zero-shot classifier. Furthermore, we prepared the replication study ID-card for the baseline study, important for evaluating replication readiness. Results showed diverse reproducibility levels across different models, with Naive Bayes demonstrating perfect reproducibility. In contrast, BERT and other models showed mixed results. Our findings revealed that baseline deep learning models, BERT and ELMo, exhibited good generalization capabilities on an external dataset, and GPT-4o showed performance comparable to traditional baseline machine learning models. Additionally, our assessment confirmed the baseline study\'s replication readiness; however missing environment setup files would have further enhanced readiness. We include this missing information in our replication package and provide the replication study ID-card for our study to further encourage and support the replication of our study.', 'abstract_zh': '自然语言处理（NLP）技术在需求工程（RE）领域中的应用：复制和扩展先前的NLP4RE研究', 'title_zh': '基于在线反馈的用户需求自动分类——一项复制研究'}
{'arxiv_id': 'arXiv:2507.21506', 'title': 'Decision Transformer-Based Drone Trajectory Planning with Dynamic Safety-Efficiency Trade-Offs', 'authors': 'Chang-Hun Ji, SiWoon Song, Youn-Hee Han, SungTae Moon', 'link': 'https://arxiv.org/abs/2507.21506', 'abstract': 'A drone trajectory planner should be able to dynamically adjust the safety-efficiency trade-off according to varying mission requirements in unknown environments. Although traditional polynomial-based planners offer computational efficiency and smooth trajectory generation, they require expert knowledge to tune multiple parameters to adjust this trade-off. Moreover, even with careful tuning, the resulting adjustment may fail to achieve the desired trade-off. Similarly, although reinforcement learning-based planners are adaptable in unknown environments, they do not explicitly address the safety-efficiency trade-off. To overcome this limitation, we introduce a Decision Transformer-based trajectory planner that leverages a single parameter, Return-to-Go (RTG), as a \\emph{temperature parameter} to dynamically adjust the safety-efficiency trade-off. In our framework, since RTG intuitively measures the safety and efficiency of a trajectory, RTG tuning does not require expert knowledge. We validate our approach using Gazebo simulations in both structured grid and unstructured random environments. The experimental results demonstrate that our planner can dynamically adjust the safety-efficiency trade-off by simply tuning the RTG parameter. Furthermore, our planner outperforms existing baseline methods across various RTG settings, generating safer trajectories when tuned for safety and more efficient trajectories when tuned for efficiency. Real-world experiments further confirm the reliability and practicality of our proposed planner.', 'abstract_zh': '一种决策变换器基于的无人机轨迹规划器应能根据未知环境中的不同任务需求动态调整安全与效率权衡。', 'title_zh': '基于决策变换器的无人机航迹规划与动态安全-效率权衡'}
{'arxiv_id': 'arXiv:2507.21504', 'title': 'Evaluation and Benchmarking of LLM Agents: A Survey', 'authors': 'Mahmoud Mohammadi, Yipeng Li, Jane Lo, Wendy Yip', 'link': 'https://arxiv.org/abs/2507.21504', 'abstract': 'The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area. This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research. We also identify future research directions, including holistic, more realistic, and scalable evaluation. This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.', 'abstract_zh': '基于LLM的代理崛起开启了AI应用的新前沿，然而评估这些代理仍然是一项复杂且尚未充分发展的任务。本综述提供了对新兴的LLM代理评估领域的深入概述，引入了一种二维分类法，根据（1）评估目标——评估什么，如代理行为、能力、可靠性和安全性——和（2）评估过程——如何评估，包括交互模式、数据集和基准、度量计算方法以及工具，对现有工作进行分类。此外，我们还强调了企业特定的挑战，如基于角色的数据访问、可靠性的保证需求、动态和长周期的交互以及合规性，这些在当前研究中常被忽视。我们还指出了未来的研究方向，包括全面性、更现实且可扩展的评估。本工作旨在为代理评估的分散化景观带来明晰，并提供系统评估的框架，使研究人员和实践者能够评估LLM代理以供实际部署。', 'title_zh': 'LLM代理的评估与基准测试：一项综述'}
{'arxiv_id': 'arXiv:2507.21500', 'title': 'VN-MTEB: Vietnamese Massive Text Embedding Benchmark', 'authors': 'Loc Pham, Tung Luu, Thu Vo, Minh Nguyen, Viet Hoang', 'link': 'https://arxiv.org/abs/2507.21500', 'abstract': 'Vietnam ranks among the top countries in terms of both internet traffic and online toxicity. As a result, implementing embedding models for recommendation and content control duties in applications is crucial. However, a lack of large-scale test datasets, both in volume and task diversity, makes it tricky for scientists to effectively evaluate AI models before deploying them in real-world, large-scale projects. To solve this important problem, we introduce a Vietnamese benchmark, VN-MTEB for embedding models, which we created by translating a large number of English samples from the Massive Text Embedding Benchmark using our new automated framework. We leverage the strengths of large language models (LLMs) and cutting-edge embedding models to conduct translation and filtering processes to retain high-quality samples, guaranteeing a natural flow of language and semantic fidelity while preserving named entity recognition (NER) and code snippets. Our comprehensive benchmark consists of 41 datasets from six tasks specifically designed for Vietnamese text embeddings. In our analysis, we find that bigger and more complex models using Rotary Positional Embedding outperform those using Absolute Positional Embedding in embedding tasks. Datasets are available at HuggingFace: this https URL', 'abstract_zh': '越南在互联网流量和在线 toxicity 方面名列前茅，因此在应用中实施嵌入模型对于推荐和内容控制至关重要。但由于缺乏大规模的测试数据集，尤其是在数据量和任务多样性方面，科学家在部署这些模型之前难以有效评估 AI 模型。为解决这一重要问题，我们引入了一个越南语基准 VN-MTEB，该基准通过新的自动化框架将大量英语样本翻译而来。我们利用大型语言模型（LLMs）和先进嵌入模型的优势，进行翻译和过滤过程，确保语言自然流畅和语义保真度，同时保留词性识别（NER）和代码片段。我们的基准包括六个任务的 41 个数据集，专门设计用于越南语文本嵌入。我们的分析发现，使用旋转位置嵌入的大而复杂的模型在嵌入任务中优于使用绝对位置嵌入的模型。数据集可在 HuggingFace 获取：this https URL。', 'title_zh': 'VN-MTEB: Vietnamese大规模文本嵌入基准'}
{'arxiv_id': 'arXiv:2507.21485', 'title': 'HLSDebugger: Identification and Correction of Logic Bugs in HLS Code with LLM Solutions', 'authors': 'Jing Wang, Shang Liu, Yao Lu, Zhiyao Xie', 'link': 'https://arxiv.org/abs/2507.21485', 'abstract': 'High-level synthesis (HLS) accelerates hardware design by enabling the automatic translation of high-level descriptions into efficient hardware implementations. However, debugging HLS code is a challenging and labor-intensive task, especially for novice circuit designers or software engineers without sufficient hardware domain knowledge. The recent emergence of Large Language Models (LLMs) is promising in automating the HLS debugging process. Despite the great potential, three key challenges persist when applying LLMs to HLS logic debugging: 1) High-quality circuit data for training LLMs is scarce, posing a significant challenge. 2) Debugging logic bugs in hardware is inherently more complex than identifying software bugs with existing golden test cases. 3) The absence of reliable test cases requires multi-tasking solutions, performing both bug identification and correction. complicates the multi-tasking required for effective HLS debugging. In this work, we propose a customized solution named HLSDebugger to address the challenges. HLSDebugger first generates and releases a large labeled dataset with 300K data samples, targeting HLS logic bugs. The HLSDebugger model adopts an encoder-decoder structure, performing bug location identification, bug type prediction, and bug correction with the same model. HLSDebugger significantly outperforms advanced LLMs like GPT-4 in bug identification and by more than 3x in bug correction. It makes a substantial advancement in the exploration of automated debugging of HLS code.', 'abstract_zh': '基于高阶综合的调试助手（HLSDebugger）：应对大规模语言模型在硬件逻辑调试中的挑战', 'title_zh': 'HLSDebugger: 高级合成级调试器——在LLM解决方案支持下的HLS代码中的逻辑错误识别与纠正'}
{'arxiv_id': 'arXiv:2507.21483', 'title': 'NCCR: to Evaluate the Robustness of Neural Networks and Adversarial Examples', 'authors': 'Pu Shi', 'link': 'https://arxiv.org/abs/2507.21483', 'abstract': 'Neural networks have received a lot of attention recently, and related security issues have come with it. Many studies have shown that neural networks are vulnerable to adversarial examples that have been artificially perturbed with modification, which is too small to be distinguishable by human perception. Different attacks and defenses have been proposed to solve these problems, but there is little research on evaluating the robustness of neural networks and their inputs. In this work, we propose a metric called the neuron cover change rate (NCCR) to measure the ability of deep learning models to resist attacks and the stability of adversarial examples. NCCR monitors alterations in the output of specifically chosen neurons when the input is perturbed, and networks with a smaller degree of variation are considered to be more robust. The results of the experiment on image recognition and the speaker recognition model show that our metrics can provide a good assessment of the robustness of neural networks or their inputs. It can also be used to detect whether an input is adversarial or not, as adversarial examples are always less robust.', 'abstract_zh': '神经网络 recently 已经受到了广泛关注，相关的安全问题也随之而来。许多研究表明，神经网络容易受到人工修改且难以被人眼察觉的微小扰动所构造的对抗样本的影响。针对这些问题，已经提出了不同的攻击和防御方法，但鲜有研究评估神经网络及其输入的鲁棒性。在本文中，我们提出了一种称为神经元覆盖变化率（NCCR）的度量标准，用于衡量深度学习模型抵抗攻击的能力和对抗样本的稳定性。NCCR 监控特定选择的神经元在输入被扰动时输出的变化，变化较小的网络被认为更有鲁棒性。图像识别和说话人识别模型的实验结果表明，我们的指标可以提供神经网络或其输入鲁棒性的良好评估。此外，该指标还可以用于检测输入是否为对抗样本，因为对抗样本通常不那么鲁棒。', 'title_zh': 'NCCR：评估神经网络和对抗样本的鲁棒性'}
{'arxiv_id': 'arXiv:2507.21482', 'title': 'Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs', 'authors': 'Abhinav Arabelly, Jagrut Nemade, Robert D Nowak, Jifan Zhang', 'link': 'https://arxiv.org/abs/2507.21482', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but developing high-performing models for specialized applications often requires substantial human annotation -- a process that is time-consuming, labor-intensive, and expensive. In this paper, we address the label-efficient learning problem for supervised finetuning (SFT) by leveraging task-diversity as a fundamental principle for effective data selection. This is markedly different from existing methods based on the prompt-diversity. Our approach is based on two key observations: 1) task labels for different prompts are often readily available; 2) pre-trained models have significantly varying levels of confidence across tasks. We combine these facts to devise a simple yet effective sampling strategy: we select examples across tasks using an inverse confidence weighting strategy. This produces models comparable to or better than those trained with more complex sampling procedures, while being significantly easier to implement and less computationally intensive. Notably, our experimental results demonstrate that this method can achieve better accuracy than training on the complete dataset (a 4\\% increase in MMLU score). Across various annotation budgets and two instruction finetuning datasets, our algorithm consistently performs at or above the level of the best existing methods, while reducing annotation costs by up to 80\\%.', 'abstract_zh': '大型语言模型（LLMs）已在多个领域展现了非凡的能力，但为了开发适用于特定应用的高性能模型，通常需要大量的人工标注——这是一个耗时、劳动密集且昂贵的过程。本文通过将任务多样性作为有效数据选择的基本原则，解决监督微调（SFT）的标签高效学习问题。这种方法与现有基于提示多样性的方法不同。我们的方法基于以下两个关键观察：1）不同提示的任务标签通常易于获得；2）预训练模型在不同任务上的置信度差异显著。我们结合这些事实，提出了一种简单而有效的方法：使用逆置信加权策略选择跨任务的样本。这种方法生成的模型在复杂采样过程生成的模型上具有可比性或更好性能，而在实施难度和计算成本方面更具优势。实验结果表明，该方法可实现比训练全数据集更高的准确性（MMLU得分提高4%）。在不同的注释预算和两个指令微调数据集上，我们的算法均表现优于或至少与现有最佳方法持平，同时将注释成本最多降低80%。', 'title_zh': '提高标签效率的监督微调中任务多样性改进'}
{'arxiv_id': 'arXiv:2507.21479', 'title': 'Capacity-Constrained Continual Learning', 'authors': 'Zheng Wen, Doina Precup, Benjamin Van Roy, Satinder Singh', 'link': 'https://arxiv.org/abs/2507.21479', 'abstract': 'Any agents we can possibly build are subject to capacity constraints, as memory and compute resources are inherently finite. However, comparatively little attention has been dedicated to understanding how agents with limited capacity should allocate their resources for optimal performance. The goal of this paper is to shed some light on this question by studying a simple yet relevant continual learning problem: the capacity-constrained linear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a solution to this problem under appropriate technical conditions. Moreover, for problems that can be decomposed into a set of sub-problems, we also demonstrate how to optimally allocate capacity across these sub-problems in the steady state. We view the results of this paper as a first step in the systematic theoretical study of learning under capacity constraints.', 'abstract_zh': '任何我们可能构建的智能体都受到容量约束的限制，因为内存和计算资源是有限的。然而，对于具有有限容量的智能体应如何分配其资源以实现最优性能的研究相对不足。本文旨在通过研究一个简单而相关的一贯学习问题——容量受限的线性二次高斯（LQG）序列预测问题——来回答这个问题。我们在适当的技术条件下推导出该问题的解。此外，对于可以分解为一组子问题的问题，我们还展示了如何在稳态下最优地分配这些子问题的容量。我们将本文的结果视为系统性理论研究学习在容量约束下问题的第一步。', 'title_zh': '容量约束持续学习'}
{'arxiv_id': 'arXiv:2507.21476', 'title': 'Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench', 'authors': 'Reuben Narad, Siddharth Suresh, Jiayi Chen, Pine S.L. Dysart-Bricken, Bob Mankoff, Robert Nowak, Jifan Zhang, Lalit Jain', 'link': 'https://arxiv.org/abs/2507.21476', 'abstract': "We present HumorBench, a benchmark designed to evaluate large language models' (LLMs) ability to reason about and explain sophisticated humor in cartoon captions. As reasoning models increasingly saturate existing benchmarks in mathematics and science, novel and challenging evaluations of model intelligence beyond STEM domains are essential. Reasoning is fundamentally involved in text-based humor comprehension, requiring the identification of connections between concepts in cartoons/captions and external cultural references, wordplays, and other mechanisms. HumorBench includes approximately 300 unique cartoon-caption pairs from the New Yorker Caption Contest and this http URL, with expert-annotated evaluation rubrics identifying essential joke elements. LLMs are evaluated based on their explanations towards the humor and abilities in identifying the joke elements. To perform well on this task, models must form and test hypotheses about associations between concepts, potentially backtracking from initial interpretations to arrive at the most plausible explanation. Our extensive benchmarking of current SOTA models reveals three key insights: (1) LLM progress on STEM reasoning transfers effectively to humor comprehension; (2) models trained exclusively on STEM reasoning data still perform well on HumorBench, demonstrating strong transferability of reasoning abilities; and (3) test-time scaling by increasing thinking token budgets yields mixed results across different models in humor reasoning.", 'abstract_zh': '我们呈现HumorBench：一个用于评估大型语言模型在漫画标题中处理和解释复杂幽默能力的标准基准。', 'title_zh': '哪些大语言模型能get到幽默？使用HumorBench探究非STEM推理能力'}
{'arxiv_id': 'arXiv:2507.21474', 'title': 'Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep Learning', 'authors': 'Daniel Szelogowski', 'link': 'https://arxiv.org/abs/2507.21474', 'abstract': 'Despite success across diverse tasks, current artificial recurrent network architectures rely primarily on implicit hidden-state memories, limiting their interpretability and ability to model long-range dependencies. In contrast, biological neural systems employ explicit, associative memory traces (i.e., engrams) strengthened through Hebbian synaptic plasticity and activated sparsely during recall. Motivated by these neurobiological insights, we introduce the Engram Neural Network (ENN), a novel recurrent architecture incorporating an explicit, differentiable memory matrix with Hebbian plasticity and sparse, attention-driven retrieval mechanisms. The ENN explicitly models memory formation and recall through dynamic Hebbian traces, improving transparency and interpretability compared to conventional RNN variants. We evaluate the ENN architecture on three canonical benchmarks: MNIST digit classification, CIFAR-10 image sequence modeling, and WikiText-103 language modeling. Our empirical results demonstrate that the ENN achieves accuracy and generalization performance broadly comparable to classical RNN, GRU, and LSTM architectures, with all models converging to similar accuracy and perplexity on the large-scale WikiText-103 task. At the same time, the ENN offers significant enhancements in interpretability through observable memory dynamics. Hebbian trace visualizations further reveal biologically plausible, structured memory formation processes, validating the potential of neuroscience-inspired mechanisms to inform the development of more interpretable and robust deep learning models.', 'abstract_zh': '尽管当前的人工循环网络架构在多种任务上取得了成功，但它们主要依赖于隐式的隐藏状态记忆，这限制了它们的可解释性和建模长距离依赖的能力。相比之下，生物神经系统通过瞬时记忆痕迹（即记忆回路）来存储信息，这些记忆回路通过Hebbian突触可塑性加强，并在回忆时稀疏激活。受这些神经生物学洞察的启发，我们引入了记忆回路神经网络（ENN），这是一种新颖的循环架构，结合了隐式的、可微的记忆矩阵、Hebbian可塑性以及基于注意力的选择性检索机制。ENN 通过动态的Hebbian痕迹明确建模记忆形成和回忆，从而在透明度和可解释性方面优于传统的循环神经网络变体。我们在三个经典基准上评估了ENN 架构：MNIST 数字分类、CIFAR-10 图像序列建模和 WikiText-103 语言建模。我们的实证结果表明，ENN 在准确率和泛化性能方面与经典的循环神经网络、门控循环单元（GRU）和长短期记忆（LSTM）架构相当，在大规模的 WikiText-103 任务上，所有模型的准确率和困惑度都达到相似水平。同时，ENN 在可解释性方面提供了显著的增强，通过可观察的记忆动态展示了生物上合乎逻辑的、结构化的记忆形成过程，进一步证实了神经科学启发机制在开发更可解释和稳健的深度学习模型方面的潜力。', 'title_zh': '基于海BI规则的记忆增强递归网络：深度学习中的记忆神经元'}
{'arxiv_id': 'arXiv:2507.21455', 'title': 'Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation', 'authors': 'Sheng-Feng Yu, Jia-Jiun Yao, Wei-Chen Chiu', 'link': 'https://arxiv.org/abs/2507.21455', 'abstract': 'Although larger datasets are crucial for training large deep models, the rapid growth of dataset size has brought a significant challenge in terms of considerable training costs, which even results in prohibitive computational expenses. Dataset Distillation becomes a popular technique recently to reduce the dataset size via learning a highly compact set of representative exemplars, where the model trained with these exemplars ideally should have comparable performance with respect to the one trained with the full dataset. While most of existing works upon dataset distillation focus on supervised datasets, we instead aim to distill images and their self-supervisedly trained representations into a distilled set. This procedure, named as Self-Supervised Dataset Distillation, effectively extracts rich information from real datasets, yielding the distilled sets with enhanced cross-architecture generalizability. Particularly, in order to preserve the key characteristics of original dataset more faithfully and compactly, several novel techniques are proposed: 1) we introduce an innovative parameterization upon images and representations via distinct low-dimensional bases, where the base selection for parameterization is experimentally shown to play a crucial role; 2) we tackle the instability induced by the randomness of data augmentation -- a key component in self-supervised learning but being underestimated in the prior work of self-supervised dataset distillation -- by utilizing predetermined augmentations; 3) we further leverage a lightweight network to model the connections among the representations of augmented views from the same image, leading to more compact pairs of distillation. Extensive experiments conducted on various datasets validate the superiority of our approach in terms of distillation efficiency, cross-architecture generalization, and transfer learning performance.', 'abstract_zh': '虽然 Larger Datasets 对于训练大模型至关重要，但数据集规模的快速增长带来了显著的挑战，导致计算成本大幅增加，甚至可能导致计算资源的极大消耗。数据集蒸馏已成为一种流行的技术，通过学习一组高度紧凑的代表样本来减少数据集规模，其中使用这些样本训练的模型理想情况下应与全数据集训练的模型具有可比的性能。尽管现有大多数组织在数据集蒸馏方面的研究主要集中在监督数据集上，但我们旨在将图像及其自监督训练的表示蒸馏到一个蒸馏集中。这一过程被称为自监督数据集蒸馏，有效提取了真实数据集中的丰富信息，生成了具有增强跨体系结构泛化能力的蒸馏集。特别地，为了更忠实且紧凑地保留原始数据集的关键特征，提出了一些新型技术：1) 通过不同的低维度基底对图像和表示进行创新参数化，其中参数化基底的选择在实验中被证明起到了关键作用；2) 通过利用预先确定的增强方法来应对自监督学习中关键组成部分数据增强引发的不稳定性——而在现有的自监督数据集蒸馏工作中对此给予了低估；3) 进一步利用轻量级网络建模同一图像的不同视角表示之间的连接，从而生成更紧凑的蒸馏对。在各种数据集上进行的广泛实验验证了我们在蒸馏效率、跨体系结构泛化能力和迁移学习性能方面的优越性。', 'title_zh': '通过参数化、预定义增强和近似增强自主监督数据集精炼'}
{'arxiv_id': 'arXiv:2507.21433', 'title': 'MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse', 'authors': 'Kaiwen Chen, Xin Tan, Minchen Yu, Hong Xu', 'link': 'https://arxiv.org/abs/2507.21433', 'abstract': 'Large Reasoning Models (LRMs) have achieved significant advances in mathematical reasoning and formal logic tasks. However, their tendency to generate lengthy chain-of-thought sequences leads to substantial memory overhead during inference. We observe that LRMs frequently produce highly similar intermediate reasoning steps, which correspond to similar KV cache states across layers. Motivated by this observation, we propose MemShare, a novel KV cache management approach that effectively reduces memory overhead. MemShare employs a collaborative filtering algorithm to efficiently identify reusable KV cache blocks and enables zero copy cache reuse to significantly reduce memory overhead, improve throughput while maintaining accuracy. Experimental results demonstrate that MemShare delivers up to 84.79\\% improvement in throughput while maintaining better accuracy compared to existing KV cache management methods.', 'abstract_zh': '大型推理模型（LRMs）在数学推理和形式逻辑任务上取得了显著进展。然而，它们倾向于生成较长的推理链，导致推理过程中内存开销显著增加。我们观察到LRMs经常产生高度相似的中间推理步骤，这些步骤对应于各层中相似的KV缓存状态。受此观察启发，我们提出了MemShare，一种新颖的KV缓存管理方法，有效减少了内存开销。MemShare采用协作过滤算法高效地识别可重复使用的KV缓存块，并通过零拷贝缓存重用显著减少内存开销、提高吞吐量的同时保持准确性。实验结果显示，与现有KV缓存管理方法相比，MemShare在保持更高准确性的基础上，吞吐量最多可提高84.79%。', 'title_zh': 'MemShare: 通过键值缓存复用的大规模推理模型高效内存推理'}
{'arxiv_id': 'arXiv:2507.21432', 'title': 'Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour', 'authors': 'Tareq Alsaleh, Bilal Farooq', 'link': 'https://arxiv.org/abs/2507.21432', 'abstract': 'This study investigates the adoption of open-access, locally deployable causal large language models (LLMs) for travel mode choice prediction and introduces LiTransMC, the first fine-tuned causal LLM developed for this task. We systematically benchmark eleven LLMs (1-12B parameters) across three stated and revealed preference datasets, testing 396 configurations and generating over 79,000 synthetic commuter predictions. Beyond predictive accuracy, we evaluate models generated reasoning using BERTopic for topic modelling and a novel Explanation Strength Index, providing the first structured analysis of how LLMs articulate decision factors in alignment with behavioural theory. LiTransMC, fine-tuned using parameter efficient and loss masking strategy, achieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of 0.000245, surpassing both untuned local models and larger proprietary systems, including GPT-4o with advanced persona inference and embedding-based loading, while also outperforming classical mode choice methods such as discrete choice models and machine learning classifiers for the same dataset. This dual improvement, i.e., high instant-level accuracy and near-perfect distributional calibration, demonstrates the feasibility of creating specialist, locally deployable LLMs that integrate prediction and interpretability. Through combining structured behavioural prediction with natural language reasoning, this work unlocks the potential for conversational, multi-task transport models capable of supporting agent-based simulations, policy testing, and behavioural insight generation. These findings establish a pathway for transforming general purpose LLMs into specialized, explainable tools for transportation research and policy formulation, while maintaining privacy, reducing cost, and broadening access through local deployment.', 'abstract_zh': '本研究探讨了采用开放访问、本地部署的因果大语言模型（LLMs）进行出行模式选择预测的应用，并引入了首个专为此任务开发的细调因果LLM——LiTransMC。我们系统性地在三个声明偏好和揭示偏好数据集中比较了十一种LLM（参数从1亿到120亿不等），测试了396种配置，并生成了超过79,000个合成通勤者预测。除了预测准确性，我们还通过BERTopic进行主题建模和一种新的解释强度指数评估了生成的推理，提供了LLM如何在行为理论框架内阐述决策因素的首次结构化分析。LiTransMC采用参数高效和损失掩蔽策略进行细调，获得了0.6845的加权F1分数和0.000245的Jensen-Shannon散度，超过了未调优的本地模型和更大的专有系统（包括具有高级角色推断和基于嵌入式加载的GPT-4o），同时在相同数据集上也超越了诸如离散选择模型和机器学习分类器等传统出行模式方法。这种双重改进，即高个体层次准确性和近乎完美的分布校准，展示了创建集预测和可解释性于一体的本地可部署专有模型的可行性。通过结合结构化的行为预测和自然语言推理，本研究揭示了构建支持基于代理的仿真、政策测试和行为洞察生成的交互式多任务运输模型的潜力。这些发现为将通用目的大语言模型转变为专一且具有解释性的交通研究和政策制定工具提供了途径，同时保持隐私、降低成本并通过本地部署扩大访问范围。', 'title_zh': '面向本地可部署的细粒度调优因果大语言模型的出行选择行为研究'}
{'arxiv_id': 'arXiv:2507.21423', 'title': 'MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving', 'authors': 'Thomas Monninger, Zihan Zhang, Zhipeng Mo, Md Zafar Anwar, Steffen Staab, Sihao Ding', 'link': 'https://arxiv.org/abs/2507.21423', 'abstract': "Autonomous driving requires an understanding of the static environment from sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse multiple inputs, and a vector decoder predicts a vectorized map representation from the latent BEV grid. However, traditional map construction models provide deterministic point estimates, failing to capture uncertainty and the inherent ambiguities of real-world environments, such as occlusions and missing lane markings. We propose MapDiffusion, a novel generative approach that leverages the diffusion paradigm to learn the full distribution of possible vectorized maps. Instead of predicting a single deterministic output from learned queries, MapDiffusion iteratively refines randomly initialized queries, conditioned on a BEV latent grid, to generate multiple plausible map samples. This allows aggregating samples to improve prediction accuracy and deriving uncertainty estimates that directly correlate with scene ambiguity. Extensive experiments on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art performance in online map construction, surpassing the baseline by 5% in single-sample performance. We further show that aggregating multiple samples consistently improves performance along the ROC curve, validating the benefit of distribution modeling. Additionally, our uncertainty estimates are significantly higher in occluded areas, reinforcing their value in identifying regions with ambiguous sensor input. By modeling the full map distribution, MapDiffusion enhances the robustness and reliability of online vectorized HD map construction, enabling uncertainty-aware decision-making for autonomous vehicles in complex environments.", 'abstract_zh': '自主驾驶需要从传感器数据中理解静态环境。Learned鸟瞰图（BEV）编码器常用于融合多个输入，并且向量解码器从潜在BEV网格中预测向量化的地图表示。然而，传统的地图构建模型仅提供确定性的点估计，无法捕捉现实环境中固有的不确定性和模糊性，例如遮挡和缺失的车道标记。我们提出MapDiffusion，这是一种新颖的生成性方法，利用扩散范式学习可能的向量化地图的完整分布。MapDiffusion通过迭代改进依据BEV潜在网格随机初始化的查询，而不是从学习的查询中预测单一的确定性输出，来生成多个可信的地图样本。这允许通过聚合样本来提高预测准确性，并直接从场景模糊性中推导出不确定性估计。在nuScenes数据集上的实验表明，MapDiffusion在在线地图构建方面的表现达到最新水平，在单样本性能上超过了基线5%。此外，我们展示了聚合多个样本沿着ROC曲线一致地提高性能，验证了分布建模的益处。此外，我们的不确定性估计在遮挡区域显著较高，强化了它们在识别模糊传感器输入区域的价值。通过建模完整地图分布，MapDiffusion增强了在线向量化高精度地图构建的稳健性和可靠性，从而在复杂环境中为自主车辆提供基于不确定性的决策支持。', 'title_zh': 'MapDiffusion: 生成扩散在自主驾驶中基于向量的在线高精度地图构建及不确定性估计'}
{'arxiv_id': 'arXiv:2507.21395', 'title': 'Sync-TVA: A Graph-Attention Framework for Multimodal Emotion Recognition with Cross-Modal Fusion', 'authors': 'Zeyu Deng, Yanhui Lu, Jiashu Liao, Shuang Wu, Chongfeng Wei', 'link': 'https://arxiv.org/abs/2507.21395', 'abstract': 'Multimodal emotion recognition (MER) is crucial for enabling emotionally intelligent systems that perceive and respond to human emotions. However, existing methods suffer from limited cross-modal interaction and imbalanced contributions across modalities. To address these issues, we propose Sync-TVA, an end-to-end graph-attention framework featuring modality-specific dynamic enhancement and structured cross-modal fusion. Our design incorporates a dynamic enhancement module for each modality and constructs heterogeneous cross-modal graphs to model semantic relations across text, audio, and visual features. A cross-attention fusion mechanism further aligns multimodal cues for robust emotion inference. Experiments on MELD and IEMOCAP demonstrate consistent improvements over state-of-the-art models in both accuracy and weighted F1 score, especially under class-imbalanced conditions.', 'abstract_zh': '多模态情感识别中的同步时间视图（Sync-TVA）：一种端到端的图注意力框架', 'title_zh': 'Sync-TVA: 一种基于图注意力的跨模态融合多模态情绪识别框架'}
{'arxiv_id': 'arXiv:2507.21391', 'title': 'Multimodal LLMs as Customized Reward Models for Text-to-Image Generation', 'authors': 'Shijie Zhou, Ruiyi Zhang, Huaisheng Zhu, Branislav Kveton, Yufan Zhou, Jiuxiang Gu, Jian Chen, Changyou Chen', 'link': 'https://arxiv.org/abs/2507.21391', 'abstract': 'We introduce LLaVA-Reward, an efficient reward model designed to automatically evaluate text-to-image (T2I) generations across multiple perspectives, leveraging pretrained multimodal large language models (MLLMs). Existing MLLM-based approaches require instruction-following data for supervised fine-tuning and evaluate generation quality on analyzing text response, which is time-consuming and difficult to train. To address this problem, we propose LLaVA-Reward, which directly utilizes the hidden states of MLLMs given text-image pairs. To enhance the bidirectional interaction between visual and textual representations in decoder-only MLLMs, we further propose adding a Skip-connection Cross Attention (SkipCA) module. This design enhances text-image correlation reasoning by connecting early-layer visual features with later-layer hidden this http URL addition, LLaVA-Reward supports different types of preference data for efficient fine-tuning, including paired preference data and unpaired data. We train LLaVA-Reward on four evaluation perspectives: text-image alignment, fidelity/artifact, safety, and overall ranking. Empirical results demonstrate that LLaVA-Reward outperforms conventional and MLLM-based methods in generating human-aligned scores for automatic evaluations and inference-time scaling in text-to-image generations.', 'abstract_zh': 'LLaVA-Reward：一种用于多视角自动评估文本到图像生成的高效奖励模型', 'title_zh': '多模态LLM作为文本到图像生成的定制奖励模型'}
{'arxiv_id': 'arXiv:2507.21386', 'title': 'Efficient Neural Combinatorial Optimization Solver for the Min-max Heterogeneous Capacitated Vehicle Routing Problem', 'authors': 'Xuan Wu, Di Wang, Chunguo Wu, Kaifang Qi, Chunyan Miao, Yubin Xiao, Jian Zhang, You Zhou', 'link': 'https://arxiv.org/abs/2507.21386', 'abstract': 'Numerous Neural Combinatorial Optimization (NCO) solvers have been proposed to address Vehicle Routing Problems (VRPs). However, most of these solvers focus exclusively on single-vehicle VRP variants, overlooking the more realistic min-max Heterogeneous Capacitated Vehicle Routing Problem (MMHCVRP), which involves multiple vehicles. Existing MMHCVRP solvers typically select a vehicle and its next node to visit at each decoding step, but often make myopic decoding decisions and overlook key properties of MMHCVRP, including local topological relationships, vehicle permutation invariance, and node symmetry, resulting in suboptimal performance. To better address these limitations, we propose ECHO, an efficient NCO solver. First, ECHO exploits the proposed dual-modality node encoder to capture local topological relationships among nodes. Subsequently, to mitigate myopic decisions, ECHO employs the proposed Parameter-Free Cross-Attention mechanism to prioritize the vehicle selected in the preceding decoding step. Finally, leveraging vehicle permutation invariance and node symmetry, we introduce a tailored data augment strategy for MMHCVRP to stabilize the Reinforcement Learning training process. To assess the performance of ECHO, we conduct extensive experiments. The experimental results demonstrate that ECHO outperforms state-of-the-art NCO solvers across varying numbers of vehicles and nodes, and exhibits well-performing generalization across both scales and distribution patterns. Finally, ablation studies validate the effectiveness of all proposed methods.', 'abstract_zh': '高效的神经组合优化解器ECHO：应对多元车辆异构容量路由问题', 'title_zh': '高效的神经组合优化解决方法：针对最小最大异质容量车辆路由问题'}
{'arxiv_id': 'arXiv:2507.21385', 'title': 'Deep Reinforcement Learning-based Cell DTX/DRX Configuration for Network Energy Saving', 'authors': 'Wei Mao, Lili Wei, Omid Semiari, Shu-ping Yeh, Hosein Nikopour', 'link': 'https://arxiv.org/abs/2507.21385', 'abstract': '3GPP Release 18 cell discontinuous transmission and reception (cell DTX/DRX) is an important new network energy saving feature for 5G. As a time-domain technique, it periodically aggregates the user data transmissions in a given duration of time when the traffic load is not heavy, so that the remaining time can be kept silent and advanced sleep modes (ASM) can be enabled to shut down more radio components and save more energy for the cell. However, inevitably the packet delay is increased, as during the silent period no transmission is allowed. In this paper we study how to configure cell DTX/DRX to optimally balance energy saving and packet delay, so that for delay-sensitive traffic maximum energy saving can be achieved while the degradation of quality of service (QoS) is minimized. As the optimal configuration can be different for different network and traffic conditions, the problem is complex and we resort to deep reinforcement learning (DRL) framework to train an AI agent to solve it. Through careful design of 1) the learning algorithm, which implements a deep Q-network (DQN) on a contextual bandit (CB) model, and 2) the reward function, which utilizes a smooth approximation of a theoretically optimal but discontinuous reward function, we are able to train an AI agent that always tries to select the best possible Cell DTX/DRX configuration under any network and traffic conditions. Simulation results show that compared to the case when cell DTX/DRX is not used, our agent can achieve up to ~45% energy saving depending on the traffic load scenario, while always maintaining no more than ~1% QoS degradation.', 'abstract_zh': '3GPPRelease18小区不连续接收传输(cellDTX/DRX):一种5G网络节能的新技术及其能效与包延迟最优平衡的研究', 'title_zh': '基于深度强化学习的小区DTX/DRX配置方法及其在网络节能中的应用'}
{'arxiv_id': 'arXiv:2507.21382', 'title': 'MAAD: Automate Software Architecture Design through Knowledge-Driven Multi-Agent Collaboration', 'authors': 'Ruiyin Li, Yiran Zhang, Xiyu Zhou, Peng Liang, Weisong Sun, Jifeng Xuan, Zhi Jin, Yang Liu', 'link': 'https://arxiv.org/abs/2507.21382', 'abstract': "Software architecture design is a critical, yet inherently complex and knowledge-intensive phase of software development. It requires deep domain expertise, development experience, architectural knowledge, careful trade-offs among competing quality attributes, and the ability to adapt to evolving requirements. Traditionally, this process is time-consuming and labor-intensive, and relies heavily on architects, often resulting in limited design alternatives, especially under the pressures of agile development. While Large Language Model (LLM)-based agents have shown promising performance across various SE tasks, their application to architecture design remains relatively scarce and requires more exploration, particularly in light of diverse domain knowledge and complex decision-making. To address the challenges, we proposed MAAD (Multi-Agent Architecture Design), an automated framework that employs a knowledge-driven Multi-Agent System (MAS) for architecture design. MAAD orchestrates four specialized agents (i.e., Analyst, Modeler, Designer and Evaluator) to collaboratively interpret requirements specifications and produce architectural blueprints enriched with quality attributes-based evaluation reports. We then evaluated MAAD through a case study and comparative experiments against MetaGPT, a state-of-the-art MAS baseline. Our results show that MAAD's superiority lies in generating comprehensive architectural components and delivering insightful and structured architecture evaluation reports. Feedback from industrial architects across 11 requirements specifications further reinforces MAAD's practical usability. We finally explored the performance of the MAAD framework with three LLMs (GPT-4o, DeepSeek-R1, and Llama 3.3) and found that GPT-4o exhibits better performance in producing architecture design, emphasizing the importance of LLM selection in MAS-driven architecture design.", 'abstract_zh': '基于多智能体系统的软件架构自动化设计（MAAD）', 'title_zh': 'MAAD：通过知识驱动的多Agent协作实现自动化软件架构设计'}
{'arxiv_id': 'arXiv:2507.21378', 'title': 'ProMemAssist: Exploring Timely Proactive Assistance Through Working Memory Modeling in Multi-Modal Wearable Devices', 'authors': 'Kevin Pu, Ting Zhang, Naveen Sendhilnathan, Sebastian Freitag, Raj Sodhi, Tanya Jonker', 'link': 'https://arxiv.org/abs/2507.21378', 'abstract': "Wearable AI systems aim to provide timely assistance in daily life, but existing approaches often rely on user initiation or predefined task knowledge, neglecting users' current mental states. We introduce ProMemAssist, a smart glasses system that models a user's working memory (WM) in real-time using multi-modal sensor signals. Grounded in cognitive theories of WM, our system represents perceived information as memory items and episodes with encoding mechanisms, such as displacement and interference. This WM model informs a timing predictor that balances the value of assistance with the cost of interruption. In a user study with 12 participants completing cognitively demanding tasks, ProMemAssist delivered more selective assistance and received higher engagement compared to an LLM baseline system. Qualitative feedback highlights the benefits of WM modeling for nuanced, context-sensitive support, offering design implications for more attentive and user-aware proactive agents.", 'abstract_zh': '可穿戴AI系统旨在提供及时生活协助，但现有方法往往依赖于用户主动触发或预定义的任务知识，忽视了用户当前的心理状态。我们介绍了ProMemAssist，这是一种智能眼镜系统，通过多模态传感器信号实时建模用户的短期记忆（工作记忆）。基于工作记忆的认知理论，我们的系统将感知到的信息表示为具有编码机制（如位移和干扰）的记忆项和事件。该工作记忆模型指导一个时间预测器，平衡协助的价值与中断的成本。在一项涉及12名参与者完成认知密集型任务的用户研究中，ProMemAssist提供了更具选择性的协助，并获得了比LLM基线系统更高的参与度。定性反馈突出了工作记忆建模在提供细致、上下文敏感支持方面的优势，为设计更细心、更用户友好的主动代理提供了设计启示。', 'title_zh': 'ProMemAssist：通过工作记忆建模在多模态可穿戴设备中探索及时主动协助'}
{'arxiv_id': 'arXiv:2507.21364', 'title': 'Evaluating Deep Learning Models for African Wildlife Image Classification: From DenseNet to Vision Transformers', 'authors': 'Lukman Jibril Aliyu, Umar Sani Muhammad, Bilqisu Ismail, Nasiru Muhammad, Almustapha A Wakili, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad, Mustapha Abdullahi', 'link': 'https://arxiv.org/abs/2507.21364', 'abstract': 'Wildlife populations in Africa face severe threats, with vertebrate numbers declining by over 65% in the past five decades. In response, image classification using deep learning has emerged as a promising tool for biodiversity monitoring and conservation. This paper presents a comparative study of deep learning models for automatically classifying African wildlife images, focusing on transfer learning with frozen feature extractors. Using a public dataset of four species: buffalo, elephant, rhinoceros, and zebra; we evaluate the performance of DenseNet-201, ResNet-152, EfficientNet-B4, and Vision Transformer ViT-H/14. DenseNet-201 achieved the best performance among convolutional networks (67% accuracy), while ViT-H/14 achieved the highest overall accuracy (99%), but with significantly higher computational cost, raising deployment concerns. Our experiments highlight the trade-offs between accuracy, resource requirements, and deployability. The best-performing CNN (DenseNet-201) was integrated into a Hugging Face Gradio Space for real-time field use, demonstrating the feasibility of deploying lightweight models in conservation settings. This work contributes to African-grounded AI research by offering practical insights into model selection, dataset preparation, and responsible deployment of deep learning tools for wildlife conservation.', 'abstract_zh': '非洲野生动物种群面临严重威胁，有脊椎动物数量在过去五十年中下降了超过65%。为应对这一挑战，基于深度学习的图像分类已成为生物多样性和保护监测的有前途的工具。本文对自动分类非洲野生动物图像的深度学习模型进行了比较研究，着重于冻结特征提取器的迁移学习。使用包含四种物种（水牛、大象、犀牛和斑马）的公共数据集，评估了DenseNet-201、ResNet-152、EfficientNet-B4和Vision Transformer ViT-H/14的性能。DenseNet-201在卷积网络中表现最佳（准确率为67%），而ViT-H/14实现了最高的总体准确率（99%），但计算成本显著更高，引发了部署方面的担忧。本文的研究结果突显了准确率、资源需求和可部署性之间的权衡。表现最佳的CNN（DenseNet-201）被集成到Hugging Face Gradio Space中，以实现实地实时使用，展示了如何在保护环境中部署轻量级模型的可行性。本文通过提供关于模型选择、数据集准备和负责任部署深度学习工具以促进野生动物保护的实际见解，为非洲本地化的人工智能研究做出了贡献。', 'title_zh': '评估适用于非洲野生动物图像分类的深度学习模型：从DenseNet到视觉变换器'}
{'arxiv_id': 'arXiv:2507.21340', 'title': 'StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation', 'authors': 'Satyananda Kashyap, Sola Shirai, Nandana Mihindukulasooriya, Horst Samulowitz', 'link': 'https://arxiv.org/abs/2507.21340', 'abstract': "Extracting structured information from text, such as key-value pairs that could augment tabular data, is quite useful in many enterprise use cases. Although large language models (LLMs) have enabled numerous automated pipelines for converting natural language into structured formats, there is still a lack of benchmarks for evaluating their extraction quality, especially in specific domains or focused documents specific to a given organization. Building such benchmarks by manual annotations is labour-intensive and limits the size and scalability of the benchmarks. In this work, we present StructText, an end-to-end framework for automatically generating high-fidelity benchmarks for key-value extraction from text using existing tabular data. It uses available tabular data as structured ground truth, and follows a two-stage ``plan-then-execute'' pipeline to synthetically generate corresponding natural-language text. To ensure alignment between text and structured source, we introduce a multi-dimensional evaluation strategy that combines (a) LLM-based judgments on factuality, hallucination, and coherence and (b) objective extraction metrics measuring numeric and temporal accuracy. We evaluated the proposed method on 71,539 examples across 49 datasets. Results reveal that while LLMs achieve strong factual accuracy and avoid hallucination, they struggle with narrative coherence in producing extractable text. Notably, models presume numerical and temporal information with high fidelity yet this information becomes embedded in narratives that resist automated extraction. We release a framework, including datasets, evaluation tools, and baseline extraction systems, to support continued research.", 'abstract_zh': '从文本中自动生成高保真结构化基准框架用于键值对提取', 'title_zh': '结构文本：一种多维度评估的合成表格到文本基准生成方法'}
{'arxiv_id': 'arXiv:2507.21295', 'title': 'Semantic Numeration Systems as Dynamical Systems', 'authors': 'Alexander Yu. Chunikhin', 'link': 'https://arxiv.org/abs/2507.21295', 'abstract': 'The foundational concepts of semantic numeration systems theory are briefly outlined. The action of cardinal semantic operators unfolds over a set of cardinal abstract entities belonging to the cardinal semantic multeity. The cardinal abstract object (CAO) formed by them in a certain connectivity topology is proposed to be considered as a linear discrete dynamical system with nonlinear control. Under the assumption of ideal observability, the CAO state equations are provided for both stationary and non-stationary cases. The fundamental role of the configuration matrix, which combines information about the types of cardinal semantic operators in the CAO, their parameters and topology of connectivity, is demonstrated.', 'abstract_zh': '语义数制理论的基础概念摘要。卡 guit数义算子的作用在卡 guit抽象实体所构成的卡 Guil数义多元体的集合上展开。由它们在某种连接拓扑下形成的卡 guit抽象对象(CAO)被提出作为一个具有非线性控制的线性离散动态系统。假设理想的可观测性，在稳态和非稳态情况下提供了CAO的状态方程。展示了配置矩阵的基本作用，该矩阵结合了CAO中卡 guit数义算子的类型、参数及其连接拓扑的信息。', 'title_zh': '语义数制系统作为动力系统'}
{'arxiv_id': 'arXiv:2507.21288', 'title': 'Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties', 'authors': 'Guanxiong Chen, Shashwat Suri, Yuhao Wu, Etienne Voulga, David I.W. Levin, Dinesh Pai', 'link': 'https://arxiv.org/abs/2507.21288', 'abstract': "Materials used in real clothing exhibit remarkable complexity and spatial variation due to common processes such as stitching, hemming, dyeing, printing, padding, and bonding. Simulating these materials, for instance using finite element methods, is often computationally demanding and slow. Worse, such methods can suffer from numerical artifacts called ``membrane locking'' that makes cloth appear artificially stiff. Here we propose a general framework, called Mass-Spring Net, for learning a simple yet efficient surrogate model that captures the effects of these complex materials using only motion observations. The cloth is discretized into a mass-spring network with unknown material parameters that are learned directly from the motion data, using a novel force-and-impulse loss function. Our approach demonstrates the ability to accurately model spatially varying material properties from a variety of data sources, and immunity to membrane locking which plagues FEM-based simulations. Compared to graph-based networks and neural ODE-based architectures, our method achieves significantly faster training times, higher reconstruction accuracy, and improved generalization to novel dynamic scenarios.", 'abstract_zh': '用于学习从运动观测中捕获复杂材料效应的简单高效代理模型的质点弹簧网络框架', 'title_zh': '学习具有空间变分本构性质的可模拟布料模型'}
{'arxiv_id': 'arXiv:2507.21260', 'title': 'Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors', 'authors': 'Amartya Banerjee, Xingyu Xu, Caroline Moosmüller, Harlin Lee', 'link': 'https://arxiv.org/abs/2507.21260', 'abstract': 'In an inverse problem, the goal is to recover an unknown parameter (e.g., an image) that has typically undergone some lossy or noisy transformation during measurement. Recently, deep generative models, particularly diffusion models, have emerged as powerful priors for protein structure generation. However, integrating noisy experimental data from multiple sources to guide these models remains a significant challenge. Existing methods often require precise knowledge of experimental noise levels and manually tuned weights for each data modality. In this work, we introduce Adam-PnP, a Plug-and-Play framework that guides a pre-trained protein diffusion model using gradients from multiple, heterogeneous experimental sources. Our framework features an adaptive noise estimation scheme and a dynamic modality weighting mechanism integrated into the diffusion process, which reduce the need for manual hyperparameter tuning. Experiments on complex reconstruction tasks demonstrate significantly improved accuracy using Adam-PnP.', 'abstract_zh': '逆问题的目标是恢复在测量过程中通常已经经历了某种失真或噪声变换的未知参数（例如，图像）。近年来，特别是扩散模型，已经作为强大的先验知识被用于蛋白质结构生成。然而，将多种来源的嘈杂实验数据整合以指导这些模型仍然是一项重大挑战。现有方法通常需要精确了解实验噪声水平，并手动调整每种数据模态的权重。在本工作中，我们引入了Adam-PnP，这是一种插即用框架，使用来自多种异质实验源的梯度来引导预训练的蛋白质扩散模型。我们的框架包含一种自适应噪声估计方案和一种集成到扩散过程中的动态模态权重机制，减少了手动超参数调整的需要。实验结果表明，在复杂重构任务中使用Adam-PnP可以显著提高准确性。', 'title_zh': '基于扩散先验的自适应多模态蛋白质插拔方法'}
{'arxiv_id': 'arXiv:2507.21246', 'title': 'On Explaining Visual Captioning with Hybrid Markov Logic Networks', 'authors': 'Monika Shah, Somdeb Sarkhel, Deepak Venugopal', 'link': 'https://arxiv.org/abs/2507.21246', 'abstract': 'Deep Neural Networks (DNNs) have made tremendous progress in multimodal tasks such as image captioning. However, explaining/interpreting how these models integrate visual information, language information and knowledge representation to generate meaningful captions remains a challenging problem. Standard metrics to measure performance typically rely on comparing generated captions with human-written ones that may not provide a user with a deep insights into this integration. In this work, we develop a novel explanation framework that is easily interpretable based on Hybrid Markov Logic Networks (HMLNs) - a language that can combine symbolic rules with real-valued functions - where we hypothesize how relevant examples from the training data could have influenced the generation of the observed caption. To do this, we learn a HMLN distribution over the training instances and infer the shift in distributions over these instances when we condition on the generated sample which allows us to quantify which examples may have been a source of richer information to generate the observed caption. Our experiments on captions generated for several state-of-the-art captioning models using Amazon Mechanical Turk illustrate the interpretability of our explanations, and allow us to compare these models along the dimension of explainability.', 'abstract_zh': '深度神经网络在多模态任务如图像 captioning 方面取得了显著进展。然而，解释这些模型如何结合视觉信息、语言信息和知识表示以生成有意义的 caption 仍然是一项具有挑战性的问题。标准的性能度量通常依赖于将生成的 caption 与人工撰写的 caption 进行比较，这可能无法为用户提供深入理解这种整合的信息。在本文中，我们基于混合马尔可夫逻辑网络（HMLNs）开发了一种新的解释框架，该框架将符号规则与实值函数结合起来，易于解释。我们假设训练数据中的相关示例如何影响观察到的 caption 的生成。为此，我们学习了一个 HMLN 分布，并在条件化生成样本的情况下推断这些实例分布的变化，从而量化哪些示例可能是生成观察到的 caption 的信息来源。我们在 Amazon Mechanical Turk 上对几种先进 captioning 模型生成的 caption 进行的实验展示了我们解释的可解释性，并允许我们从解释性的角度比较这些模型。', 'title_zh': '基于混合马尔可夫逻辑网络的视觉 captions 解释'}
{'arxiv_id': 'arXiv:2507.21244', 'title': 'Bubbleformer: Forecasting Boiling with Transformers', 'authors': 'Sheikh Md Shakeel Hassan, Xianwei Zou, Akash Dhruv, Vishwanath Ganesan, Aparna Chandramowlishwaran', 'link': 'https://arxiv.org/abs/2507.21244', 'abstract': 'Modeling boiling (an inherently chaotic, multiphase process central to energy and thermal systems) remains a significant challenge for neural PDE surrogates. Existing models require future input (e.g., bubble positions) during inference because they fail to learn nucleation from past states, limiting their ability to autonomously forecast boiling dynamics. They also fail to model flow boiling velocity fields, where sharp interface-momentum coupling demands long-range and directional inductive biases. We introduce Bubbleformer, a transformer-based spatiotemporal model that forecasts stable and long-range boiling dynamics including nucleation, interface evolution, and heat transfer without dependence on simulation data during inference. Bubbleformer integrates factorized axial attention, frequency-aware scaling, and conditions on thermophysical parameters to generalize across fluids, geometries, and operating conditions. To evaluate physical fidelity in chaotic systems, we propose interpretable physics-based metrics that evaluate heat-flux consistency, interface geometry, and mass conservation. We also release BubbleML 2.0, a high-fidelity dataset that spans diverse working fluids (cryogens, refrigerants, dielectrics), boiling configurations (pool and flow boiling), flow regimes (bubbly, slug, annular), and boundary conditions. Bubbleformer sets new benchmark results in both prediction and forecasting of two-phase boiling flows.', 'abstract_zh': '基于变压器的时空模型Bubbleformer在预测沸腾动态方面的突破：无需仿真数据实现自主预报多相沸腾流', 'title_zh': 'Bubbleformer：基于变压器的沸腾预测'}
{'arxiv_id': 'arXiv:2507.21205', 'title': 'Learning from Limited and Imperfect Data', 'authors': 'Harsh Rangwani', 'link': 'https://arxiv.org/abs/2507.21205', 'abstract': 'The distribution of data in the world (eg, internet, etc.) significantly differs from the well-curated datasets and is often over-populated with samples from common categories. The algorithms designed for well-curated datasets perform suboptimally when used for learning from imperfect datasets with long-tailed imbalances and distribution shifts. To expand the use of deep models, it is essential to overcome the labor-intensive curation process by developing robust algorithms that can learn from diverse, real-world data distributions. Toward this goal, we develop practical algorithms for Deep Neural Networks which can learn from limited and imperfect data present in the real world. This thesis is divided into four segments, each covering a scenario of learning from limited or imperfect data. The first part of the thesis focuses on Learning Generative Models from Long-Tail Data, where we mitigate the mode-collapse and enable diverse aesthetic image generations for tail (minority) classes. In the second part, we enable effective generalization on tail classes through Inductive Regularization schemes, which allow tail classes to generalize as effectively as the head classes without requiring explicit generation of images. In the third part, we develop algorithms for Optimizing Relevant Metrics for learning from long-tailed data with limited annotation (semi-supervised), followed by the fourth part, which focuses on the Efficient Domain Adaptation of the model to various domains with very few to zero labeled samples.', 'abstract_zh': '世界范围内（如互联网等）的数据分布与精心整理的数据集显著不同，通常包含过多的常见类别样本。为精心整理的数据集设计的算法在用于学习不完美数据集（这些数据集具有长尾不平衡和分布偏移）时表现不佳。为了扩大深度模型的应用范围，必须通过开发能够从多样化的实际数据分布中学习的稳健算法来克服劳动密集型的数据整理过程。为此，我们开发了适用于深度神经网络的实用算法，使其能够从现实世界中有限且不完美的数据中进行学习。本论文分为四个部分，每一部分覆盖一种从有限或不完美数据中学习的场景。第一部分专注于从长尾数据中学习生成模型，其中我们缓解了模式坍缩并为尾部（少数）类别生成多样化的美学图像。第二部分通过归纳正则化方案使尾部类别能够有效泛化，无需显式生成图像即可实现与头部类别相同的泛化效果。第三部分开发了适用于具有有限标注（半监督）长尾数据学习的优化相关度量算法。第四部分专注于高效地将模型迁移到各种领域，即使只有少量或没有标注样本也能实现适应。', 'title_zh': '从有限且不完美数据中学习'}
{'arxiv_id': 'arXiv:2507.21199', 'title': 'Advancing Compositional LLM Reasoning with Structured Task Relations in Interactive Multimodal Communications', 'authors': 'Xinye Cao, Hongcan Guo, Guoshun Nan, Jiaoyang Cui, Haoting Qian, Yihan Lin, Yilin Peng, Diyang Zhang, Yanzhao Hou, Huici Wu, Xiaofeng Tao, Tony Q.S. Quek', 'link': 'https://arxiv.org/abs/2507.21199', 'abstract': "Interactive multimodal applications (IMAs), such as route planning in the Internet of Vehicles, enrich users' personalized experiences by integrating various forms of data over wireless networks. Recent advances in large language models (LLMs) utilize mixture-of-experts (MoE) mechanisms to empower multiple IMAs, with each LLM trained individually for a specific task that presents different business workflows. In contrast to existing approaches that rely on multiple LLMs for IMAs, this paper presents a novel paradigm that accomplishes various IMAs using a single compositional LLM over wireless networks. The two primary challenges include 1) guiding a single LLM to adapt to diverse IMA objectives and 2) ensuring the flexibility and efficiency of the LLM in resource-constrained mobile environments. To tackle the first challenge, we propose ContextLoRA, a novel method that guides an LLM to learn the rich structured context among IMAs by constructing a task dependency graph. We partition the learnable parameter matrix of neural layers for each IMA to facilitate LLM composition. Then, we develop a step-by-step fine-tuning procedure guided by task relations, including training, freezing, and masking phases. This allows the LLM to learn to reason among tasks for better adaptation, capturing the latent dependencies between tasks. For the second challenge, we introduce ContextGear, a scheduling strategy to optimize the training procedure of ContextLoRA, aiming to minimize computational and communication costs through a strategic grouping mechanism. Experiments on three benchmarks show the superiority of the proposed ContextLoRA and ContextGear. Furthermore, we prototype our proposed paradigm on a real-world wireless testbed, demonstrating its practical applicability for various IMAs. We will release our code to the community.", 'abstract_zh': '基于上下文的低秩适配与调度（ContextLoRA）及其在无线网络中实现多样化交互多模态应用的新范式', 'title_zh': '在互动多模态通信中通过结构化任务关系促进组件LLM推理'}
{'arxiv_id': 'arXiv:2507.21198', 'title': 'Uncovering Gradient Inversion Risks in Practical Language Model Training', 'authors': 'Xinguo Feng, Zhongkui Ma, Zihan Wang, Eu Joe Chegne, Mengyao Ma, Alsharif Abuadbba, Guangdong Bai', 'link': 'https://arxiv.org/abs/2507.21198', 'abstract': 'The gradient inversion attack has been demonstrated as a significant privacy threat to federated learning (FL), particularly in continuous domains such as vision models. In contrast, it is often considered less effective or highly dependent on impractical training settings when applied to language models, due to the challenges posed by the discrete nature of tokens in text data. As a result, its potential privacy threats remain largely underestimated, despite FL being an emerging training method for language models. In this work, we propose a domain-specific gradient inversion attack named Grab (gradient inversion with hybrid optimization). Grab features two alternating optimization processes to address the challenges caused by practical training settings, including a simultaneous optimization on dropout masks between layers for improved token recovery and a discrete optimization for effective token sequencing. Grab can recover a significant portion (up to 92.9% recovery rate) of the private training data, outperforming the attack strategy of utilizing discrete optimization with an auxiliary model by notable improvements of up to 28.9% recovery rate in benchmark settings and 48.5% recovery rate in practical settings. Grab provides a valuable step forward in understanding this privacy threat in the emerging FL training mode of language models.', 'abstract_zh': '面向语言模型的域特定梯度反转攻击：Grab（混合优化下的梯度反转）', 'title_zh': '揭示实际语言模型训练中的梯度反转风险'}
{'arxiv_id': 'arXiv:2507.21196', 'title': 'EdgeAgentX-DT: Integrating Digital Twins and Generative AI for Resilient Edge Intelligence in Tactical Networks', 'authors': 'Abir Ray', 'link': 'https://arxiv.org/abs/2507.21196', 'abstract': 'We introduce EdgeAgentX-DT, an advanced extension of the EdgeAgentX framework that integrates digital twin simulations and generative AI-driven scenario training to significantly enhance edge intelligence in military networks. EdgeAgentX-DT utilizes network digital twins, virtual replicas synchronized with real-world edge devices, to provide a secure, realistic environment for training and validation. Leveraging generative AI methods, such as diffusion models and transformers, the system creates diverse and adversarial scenarios for robust simulation-based agent training. Our multi-layer architecture includes: (1) on-device edge intelligence; (2) digital twin synchronization; and (3) generative scenario training. Experimental simulations demonstrate notable improvements over EdgeAgentX, including faster learning convergence, higher network throughput, reduced latency, and improved resilience against jamming and node failures. A case study involving a complex tactical scenario with simultaneous jamming attacks, agent failures, and increased network loads illustrates how EdgeAgentX-DT sustains operational performance, whereas baseline methods fail. These results highlight the potential of digital-twin-enabled generative training to strengthen edge AI deployments in contested environments.', 'abstract_zh': 'EdgeAgentX-DT：一种集成数字孪生仿真和生成AI驱动场景训练的先进边缘代理框架，显著增强军事网络边缘智能', 'title_zh': 'EdgeAgentX-DT：将数字孪生与生成式AI集成以在战术网络中实现灵活边缘智能'}
{'arxiv_id': 'arXiv:2507.21195', 'title': 'MaXsive: High-Capacity and Robust Training-Free Generative Image Watermarking in Diffusion Models', 'authors': 'Po-Yuan Mao, Cheng-Chang Tsai, Chun-Shien Lu', 'link': 'https://arxiv.org/abs/2507.21195', 'abstract': 'The great success of the diffusion model in image synthesis led to the release of gigantic commercial models, raising the issue of copyright protection and inappropriate content generation. Training-free diffusion watermarking provides a low-cost solution for these issues. However, the prior works remain vulnerable to rotation, scaling, and translation (RST) attacks. Although some methods employ meticulously designed patterns to mitigate this issue, they often reduce watermark capacity, which can result in identity (ID) collusion. To address these problems, we propose MaXsive, a training-free diffusion model generative watermarking technique that has high capacity and robustness. MaXsive best utilizes the initial noise to watermark the diffusion model. Moreover, instead of using a meticulously repetitive ring pattern, we propose injecting the X-shape template to recover the RST distortions. This design significantly increases robustness without losing any capacity, making ID collusion less likely to happen. The effectiveness of MaXsive has been verified on two well-known watermarking benchmarks under the scenarios of verification and identification.', 'abstract_zh': '无训练扩散模型生成水印技术MaXsive：高容量与鲁棒性兼备', 'title_zh': 'MaXsive：高容量且鲁棒的无需训练生成式图像水印在扩散模型中的应用'}
{'arxiv_id': 'arXiv:2507.21188', 'title': 'Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs', 'authors': 'Raj Krishnan Vijayaraj', 'link': 'https://arxiv.org/abs/2507.21188', 'abstract': 'LLMs for clinical decision support often fail under small but clinically meaningful input shifts such as masking a symptom or negating a finding, despite high performance on static benchmarks. These reasoning failures frequently go undetected by standard NLP metrics, which are insensitive to latent representation shifts that drive diagnosis instability. We propose a geometry-aware evaluation framework, LAPD (Latent Agentic Perturbation Diagnostics), which systematically probes the latent robustness of clinical LLMs under structured adversarial edits. Within this framework, we introduce Latent Diagnosis Flip Rate (LDFR), a model-agnostic diagnostic signal that captures representational instability when embeddings cross decision boundaries in PCA-reduced latent space. Clinical notes are generated using a structured prompting pipeline grounded in diagnostic reasoning, then perturbed along four axes: masking, negation, synonym replacement, and numeric variation to simulate common ambiguities and omissions. We compute LDFR across both foundation and clinical LLMs, finding that latent fragility emerges even under minimal surface-level changes. Finally, we validate our findings on 90 real clinical notes from the DiReCT benchmark (MIMIC-IV), confirming the generalizability of LDFR beyond synthetic settings. Our results reveal a persistent gap between surface robustness and semantic stability, underscoring the importance of geometry-aware auditing in safety-critical clinical AI.', 'abstract_zh': '临床LLM在小但具有临床意义的输入变化下的推理失败常常导致临床决策支持效果不佳，尽管在静态基准测试中表现优异。这些推理失败通常不受标准NLP指标的检测，因为这些指标对驱动诊断不稳定性的潜在表示变化反应迟钝。我们提出了一种几何感知评估框架LAPD（潜在代理扰动诊断），系统性地探查临床LLM在结构化对抗性编辑下的潜在鲁棒性。在该框架中，引入了潜在诊断翻转率（LDFR）这一模型agnostic诊断信号，用于捕获当嵌入在PCA降维后的潜在空间中跨越决策边界时的表现表示不稳定情况。临床笔记通过基于诊断推理的结构化提示管道生成，然后沿四个轴进行扰动：掩蔽、否定、同义词替换和数值变异，以模拟常见的歧义和遗漏。我们计算LDFR在基础和临床LLM中，发现即使在表面级变化微小的情况下，也会出现潜在脆弱性。最后，我们在DiReCT基准（MIMIC-IV）的90份真实临床笔记上验证了我们的发现，证实了LDFR在合成环境之外的普适性。我们的研究表明表面鲁棒性和语义稳定性之间存在持续的差距，强调了在安全性关键的临床AI中进行几何感知审计的重要性。', 'title_zh': '_embedding到诊断：临床LLM中因能动性扰动引发的潜在脆弱性_'}
{'arxiv_id': 'arXiv:2507.21186', 'title': 'Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers', 'authors': 'Sungmin Han, Jeonghyun Lee, Sangkyun Lee', 'link': 'https://arxiv.org/abs/2507.21186', 'abstract': 'Transformers have profoundly influenced AI research, but explaining their decisions remains challenging -- even for relatively simpler tasks such as classification -- which hinders trust and safe deployment in real-world applications. Although activation-based attribution methods effectively explain transformer-based text classification models, our findings reveal that these methods can be undermined by class-irrelevant features within activations, leading to less reliable interpretations. To address this limitation, we propose Contrast-CAT, a novel activation contrast-based attribution method that refines token-level attributions by filtering out class-irrelevant features. By contrasting the activations of an input sequence with reference activations, Contrast-CAT generates clearer and more faithful attribution maps. Experimental results across various datasets and models confirm that Contrast-CAT consistently outperforms state-of-the-art methods. Notably, under the MoRF setting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds over the most competing methods, demonstrating its effectiveness in enhancing interpretability for transformer-based text classification.', 'abstract_zh': 'Transformer模型在AI研究中产生了深远的影响，但解释其决策依然具有挑战性——即使是在相对简单的分类任务上也是如此，这阻碍了实际应用中的信任和安全部署。尽管基于激活的归因方法能够有效解释基于Transformer的文本分类模型，但我们发现这些方法可能会受到激活中无关类别的特征的影响，导致解释不够可靠。为解决这一局限性，我们提出了Contrast-CAT，一种新颖的基于激活对比的归因方法，通过过滤掉无关类别的特征来细化词元级归因。通过将输入序列的激活与参考激活进行对比，Contrast-CAT生成了更为清晰和忠实的归因图。实验结果表明，Contrast-CAT在多个数据集和模型上一致优于现有最佳方法。特别是在MoRF设置下，Contrast-CAT在AOPC上平均提高了1.30倍，在LOdds上提高了2.25倍，证明了其在增强Transformer基文本分类模型可解释性方面的有效性。', 'title_zh': 'Contrast-CAT：对比激活以增强基于变换器的文字分类器的可解释性'}
{'arxiv_id': 'arXiv:2507.21184', 'title': 'EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models', 'authors': 'Haowei Lin, Xiangyu Wang, Jianzhu Ma, Yitao Liang', 'link': 'https://arxiv.org/abs/2507.21184', 'abstract': 'Scaling laws are fundamental mathematical relationships that predict how neural network performance evolves with changes in variables such as model size, dataset size, and computational resources. Traditionally, discovering these laws requires extensive human expertise and manual experimentation. We introduce EvoSLD, an automated framework for Scaling Law Discovery (SLD) that leverages evolutionary algorithms guided by Large Language Models (LLMs) to co-evolve symbolic expressions and their optimization routines. Formulated to handle scaling variables, control variables, and response metrics across diverse experimental settings, EvoSLD searches for parsimonious, universal functional forms that minimize fitting errors on grouped data subsets. Evaluated on five real-world scenarios from recent literature, EvoSLD rediscovers exact human-derived laws in two cases and surpasses them in others, achieving up to orders-of-magnitude reductions in normalized mean squared error on held-out test sets. Compared to baselines like symbolic regression and ablated variants, EvoSLD demonstrates superior accuracy, interpretability, and efficiency, highlighting its potential to accelerate AI research. Code is available at this https URL.', 'abstract_zh': 'Scaling律是基本的数学关系，预测神经网络性能随模型大小、数据集大小和计算资源等变量变化的演变。传统上，发现这些规律需要大量的专业知识和手工实验。我们引入了EvoSLD，这是一种利用大型语言模型（LLMs）引导的进化算法自动发现Scaling律（SLD）的框架。EvoSLD旨在处理各种实验设置下的规模变量、控制变量和响应指标，并搜索在分组数据子集上拟合误差最小化的简洁且通用的函数形式。在最近文献中的五个实际案例上评估，EvoSLD在两种情况下重新发现了人类推导的精确规律，在其他情况下超越了它们，实现了在保留测试集上的归一化均方误差多个数量级的减少。与符号回归等基线方法及其变种相比，EvoSLD在准确度、可解释性和效率方面表现出优越性，突显了其加速AI研究的潜力。代码可在以下网址获取：this https URL。', 'title_zh': 'EvoSLD: 用大规模语言模型自动发现神经网络缩放律'}
{'arxiv_id': 'arXiv:2507.21183', 'title': 'MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge', 'authors': 'Guangchen Lan, Sipeng Zhang, Tianle Wang, Yuwei Zhang, Daoan Zhang, Xinpeng Wei, Xiaoman Pan, Hongming Zhang, Dong-Jun Han, Christopher G. Brinton', 'link': 'https://arxiv.org/abs/2507.21183', 'abstract': 'As the era of large language models (LLMs) on behalf of users unfolds, Preference Optimization (PO) methods have become a central approach to aligning LLMs with human preferences and improving performance. We propose Maximum a Posteriori Preference Optimization (MaPPO), a framework for learning from preferences that explicitly incorporates prior reward knowledge into the optimization objective. While existing methods such as Direct Preference Optimization (DPO) and its variants treat preference learning as a Maximum Likelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating prior reward estimates into a principled Maximum a Posteriori (MaP) objective. This not only generalizes DPO and its variants, but also enhances alignment by mitigating the oversimplified binary classification of responses. More importantly, MaPPO introduces no additional hyperparameter, and supports preference optimization in both offline and online settings. In addition, MaPPO can be used as a plugin with consistent improvement on DPO variants, including widely used SimPO, IPO, and CPO. Extensive empirical evaluations of different model sizes and model series on three standard benchmarks, including MT-Bench, AlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in alignment performance without sacrificing computational efficiency.', 'abstract_zh': '大规模语言模型时代首选优化方法：Maximum a Posteriori首选优化（MaPPO）', 'title_zh': 'MaPPO：带先验知识的最大后验偏好优化'}
{'arxiv_id': 'arXiv:2507.21182', 'title': 'SDD: Self-Degraded Defense against Malicious Fine-tuning', 'authors': 'Zixuan Chen, Weikai Lu, Xin Lin, Ziqian Zeng', 'link': 'https://arxiv.org/abs/2507.21182', 'abstract': "Open-source Large Language Models (LLMs) often employ safety alignment methods to resist harmful instructions. However, recent research shows that maliciously fine-tuning these LLMs on harmful data can easily bypass these safeguards. To counter this, we theoretically uncover why malicious fine-tuning succeeds and identify potential defense strategies. Building on the theoretical analysis, we introduce the Self-Degraded Defense (SDD) framework. SDD encourages LLMs to produce high-quality but irrelevant responses to harmful prompts. When attackers attempt malicious fine-tuning, the general capability of the LLM aligned by SDD will significantly decrease, rendering it incapable of following harmful instructions. Our experimental results confirm SDD's effectiveness against such attacks.", 'abstract_zh': '开源大型语言模型（LLMs）常常采用安全性对齐方法来抵抗有害指令。然而，近期研究显示，恶意微调这些LLMs以含有有害数据的训练集进行微调可以轻松绕过这些防护措施。为应对这一问题，我们从理论上探讨了恶意微调成功的原因，并识别出潜在的防御策略。基于理论分析，我们介绍了自我降级防御（SDD）框架。SDD促使LLMs对有害提示生成高质量但无关的回答。当攻击者尝试恶意微调时，由SDD对齐的LLM的一般能力将显著下降，使其无法遵循有害指令。我们的实验结果证实了SDD对这类攻击的有效性。', 'title_zh': 'SDD：自我降级防御对抗恶意微调'}
{'arxiv_id': 'arXiv:2507.21179', 'title': 'LLM-Adapted Interpretation Framework for Machine Learning Models', 'authors': 'Yuqi Jin, Zihan Hu, Weiteng Zhang, Weihao Xie, Jianwei Shuai, Xian Shen, Zhen Feng', 'link': 'https://arxiv.org/abs/2507.21179', 'abstract': 'Background & Aims: High-performance machine learning models like XGBoost are often "black boxes," limiting their clinical adoption due to a lack of interpretability. This study aims to bridge the gap between predictive accuracy and narrative transparency for sarcopenia risk assessment. Methods: We propose the LLM-Adapted Interpretation Framework (LAI-ML), a novel knowledge distillation architecture. LAI-ML transforms feature attributions from a trained XGBoost model into a probabilistic format using specialized techniques (HAGA and CACS). A Large Language Model (LLM), guided by a reinforcement learning loop and case-based retrieval, then generates data-faithful diagnostic narratives. Results: The LAI-ML framework achieved 83% prediction accuracy, significantly outperforming the baseline XGBoost model, 13% higher. Notably, the LLM not only replicated the teacher model\'s logic but also corrected its predictions in 21.7% of discordant cases, demonstrating enhanced reasoning. Conclusion: LAI-ML effectively translates opaque model predictions into trustworthy and interpretable clinical insights, offering a deployable solution to the "black-box" problem in medical AI.', 'abstract_zh': '背景与目的：高性能机器学习模型如XGBoost通常被称为“黑箱”，由于缺乏可解释性，限制了其在临床中的应用。本研究旨在弥合预测准确性和叙述透明性之间的差距，以评估肌少症风险。方法：我们提出了一种名为LLM-适配解释框架（LAI-ML）的新型知识蒸馏架构。LAI-ML使用专门的技术（HAGA和CACS）将训练好的XGBoost模型的特征归因转换为概率格式。然后，由强化学习循环和案例检索引导的大语言模型生成数据真实的诊断叙述。结果：LAI-ML框架实现了83%的预测准确率，显著优于基准XGBoost模型，高出13%。值得注意的是，大语言模型不仅复制了教师模型的逻辑，还在21.7%的不一致情况下纠正了其预测，展示了增强的推理能力。结论：LAI-ML有效地将不透明的模型预测转化为可信赖和可解释的临床见解，为医疗AI中的“黑箱”问题提供了可部署的解决方案。', 'title_zh': '面向机器学习模型的LLM调整解释框架'}
{'arxiv_id': 'arXiv:2507.21174', 'title': 'A ChatGPT-based approach for questions generation in higher education', 'authors': 'Sinh Trong Vu, Huong Thu Truong, Oanh Tien Do, Tu Anh Le, Tai Tan Mai', 'link': 'https://arxiv.org/abs/2507.21174', 'abstract': 'Large language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a "Blind test" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.', 'abstract_zh': '大型语言模型已在生活的许多方面得到了广泛应用，为企业带来了显著的效率提升，并提供了独特的用户体验。本文 focuses 于探讨将基于大型语言模型的聊天机器人ChatGPT应用于支持高等教育者生成测验题目和评估学习者的方法。具体而言，我们探索交互式提示模式以设计最优的AI赋能试题库创建流程。生成的题目通过发送“盲测”调查给包括讲师和学习者在内的多个利益相关方进行评估。初步结果表明，该方法有望简化高等教育机构中学习者评估所花费的时间和精力。', 'title_zh': '基于ChatGPT的方法在高等教育中生成问题'}
{'arxiv_id': 'arXiv:2507.21170', 'title': 'OneShield -- the Next Generation of LLM Guardrails', 'authors': 'Chad DeLuca, Anna Lisa Gentile, Shubhi Asthana, Bing Zhang, Pawan Chowdhary, Kellen Cheng, Basel Shbita, Pengyuan Li, Guang-Jie Ren, Sandeep Gopisetty', 'link': 'https://arxiv.org/abs/2507.21170', 'abstract': 'The rise of Large Language Models has created a general excitement about the great potential for a myriad of applications. While LLMs offer many possibilities, questions about safety, privacy, and ethics have emerged, and all the key actors are working to address these issues with protective measures for their own models and standalone solutions. The constantly evolving nature of LLMs makes the task of universally shielding users against their potential risks extremely challenging, and one-size-fits-all solutions unfeasible. In this work, we propose OneShield, our stand-alone, model-agnostic and customizable solution to safeguard LLMs. OneShield aims to provide facilities for defining risk factors, expressing and declaring contextual safety and compliance policies, and mitigating LLM risks, with a focus on each specific customer. We describe the implementation of the framework, the scalability considerations and provide usage statistics of OneShield since its first deployment.', 'abstract_zh': '大型语言模型的兴起引发了对众多应用潜在价值的广泛期待。尽管大型语言模型提供了许多可能性，但有关安全、隐私和伦理的问题也随之出现，所有关键利益相关者都在努力通过保护性措施和独立解决方案来应对这些问题。由于大型语言模型不断演变的特性，使普遍性地防护用户免受其潜在风险变得极为挑战，且“一刀切”的解决方案难以实施。在此工作中，我们提出了一种名为OneShield的独立、模型无关且可定制的解决方案，以保障大型语言模型的安全。OneShield旨在为定义风险因素、表达和声明上下文安全性及合规政策，以及减轻大型语言模型风险提供设施，并重点关注每个具体的客户。我们描述了框架的实现、可扩展性考虑，并提供了OneShield自首次部署以来的使用统计数据。', 'title_zh': 'OneShield -- 下一代大语言模型防护措施'}
{'arxiv_id': 'arXiv:2507.21169', 'title': 'Trustworthy AI: UK Air Traffic Control Revisited', 'authors': 'Rob Procter, Mark Rouncefield', 'link': 'https://arxiv.org/abs/2507.21169', 'abstract': 'Exploring the socio-technical challenges confronting the adoption of AI in organisational settings is something that has so far been largely absent from the related literature. In particular, research into requirements for trustworthy AI typically overlooks how people deal with the problems of trust in the tools that they use as part of their everyday work practices. This article presents some findings from an ongoing ethnographic study of how current tools are used in air traffic control work and what it reveals about requirements for trustworthy AI in air traffic control and other safety-critical application domains.', 'abstract_zh': '探索组织环境中人工智能应用所面临的社会技术挑战相关文献目前仍 largely absent。特别是，有关可信人工智能的研究通常忽略了人们在其日常工作中使用工具时如何处理信任问题。本文呈现了对空中交通控制工作中当前工具使用情况的一些民族志研究发现，以及这些发现揭示了空中交通控制和其他安全性关键应用领域中可信人工智能的要求。', 'title_zh': '可信人工智能：英国空中交通管制再审视'}
{'arxiv_id': 'arXiv:2507.21168', 'title': 'Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question', 'authors': 'Rafael Rosales, Santiago Miret', 'link': 'https://arxiv.org/abs/2507.21168', 'abstract': 'Effectively leveraging diversity has been shown to improve performance for various machine learning models, including large language models (LLMs). However, determining the most effective way of using diversity remains a challenge. In this work, we compare two diversity approaches for answering binary questions using LLMs: model diversity, which relies on multiple models answering the same question, and question interpretation diversity, which relies on using the same model to answer the same question framed in different ways. For both cases, we apply majority voting as the ensemble consensus heuristic to determine the final answer. Our experiments on boolq, strategyqa, and pubmedqa show that question interpretation diversity consistently leads to better ensemble accuracy compared to model diversity. Furthermore, our analysis of GPT and LLaMa shows that model diversity typically produces results between the best and the worst ensemble members without clear improvement.', 'abstract_zh': '有效利用多样性已被证明可以提高各种机器学习模型的表现，包括大型语言模型（LLMs）。然而，确定最有效的利用多样性方式仍然是一项挑战。在本工作中，我们比较了两种利用大型语言模型回答二元问题的多样性方法：模型多样性，即多个模型回答同一个问题；以及问题解释多样性，即同一个模型以不同的方式回答同一个问题。对于这两种情况，我们均采用多数投票作为集成共识启发式方法来确定最终答案。我们在boolq、strategyqa和pubmedqa上的实验表明，问题解释多样性在集成准确性上始终优于模型多样性。此外，我们对GPT和LLaMa的分析表明，模型多样性通常会产生介于最佳和最差集成成员之间的结果，但缺乏明显的改进。', 'title_zh': '多元的LLM模型还是多元的问题解读？这就是 ensemble 的问题。'}
{'arxiv_id': 'arXiv:2507.21167', 'title': 'ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions', 'authors': 'Danglu Yang, Liang Zhang, Zihao Yue, Liangyu Chen, Yichen Xu, Wenxuan Wang, Qin Jin', 'link': 'https://arxiv.org/abs/2507.21167', 'abstract': 'Charts are a fundamental visualization format widely used in data analysis across research and industry. While enabling users to edit charts based on high-level intentions is of great practical value, existing methods primarily rely on natural language instructions, which are often too ambiguous to support fine-grained editing. In this work, we introduce a novel paradigm for multimodal chart editing, where user intent is expressed through a combination of natural language and visual indicators that explicitly highlight the elements to be modified. To support this paradigm, we present Chart$\\text{M}^3$, a new benchmark for Multimodal chart editing with Multi-level complexity and Multi-perspective evaluation. Chart$\\text{M}^3$ contains 1,000 samples spanning four levels of editing difficulty. Each sample includes triplets in the form of (chart, code, multimodal instructions). To comprehensively evaluate chart editing models, Chart$\\text{M}^3$ provides metrics that assess both visual appearance and code correctness. Our benchmark reveals significant limitations in current multimodal large language models (MLLMs), including GPT-4o, particularly in their ability to interpret and act on visual indicators. To address this, we construct Chart$\\text{M}^3$-Train, a large-scale training set with 24,000 multimodal chart editing samples. Fine-tuning MLLMs on this dataset leads to substantial improvements, demonstrating the importance of multimodal supervision in building practical chart editing systems. Our datasets, codes, and evaluation tools are available at this https URL. %this https URL datasets, codes, and evaluation tools are available at this https URL.', 'abstract_zh': '多模态图表编辑的新范式：Chart$\\text{M}^3$基准chnerise', 'title_zh': 'ChartM$^3$: 基于多模态指令的图表编辑基准测试'}
{'arxiv_id': 'arXiv:2507.21166', 'title': 'AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation', 'authors': 'Ren Zhuang, Ben Wang, Shuifa Sun', 'link': 'https://arxiv.org/abs/2507.21166', 'abstract': 'Progress in complex reasoning is constrained by the static nature of the current training datasets. We propose structured interaction as a new scaling axis, moving beyond the prevailing paradigm of increasing model parameters. Our self-evolving framework, AGORA, enables a collaborative ensemble to achieve reasoning performance exceeding state-of-the-art monolithic systems by up to 4.45 percentage points on challenging mathematical benchmarks. This gain stems from group emergent ability-the synthesis of collective capabilities unattainable by isolated models, validating interaction as a scalable driver of intelligence. Our results position the engineering of collaborative ecosystems as a vital frontier for capability emergence.', 'abstract_zh': '复杂的推理进步受当前训练数据集静态性质的限制。我们提出结构化交互作为新的扩展轴，超越现有不断增加模型参数的范式。我们的自演化框架AGORA能使协作ensemble在具有挑战性的数学基准测试上实现超过最先进的单体系统4.45个百分点的推理性能，这一进步来自于群体涌现能力——集体能力的合成，这证实了交互是可扩展的智能驱动力。我们的结果将协作生态系统工程视为能力涌现的关键前沿领域。', 'title_zh': 'AGORA: 通过群组精馏激励大规模语言模型的群体涌现能力'}
{'arxiv_id': 'arXiv:2507.21164', 'title': 'OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection', 'authors': 'Nicolas Pinon, Carole Lartizien', 'link': 'https://arxiv.org/abs/2507.21164', 'abstract': 'Unsupervised anomaly detection (UAD) aims to detect anomalies without labeled data, a necessity in many machine learning applications where anomalous samples are rare or not available. Most state-of-the-art methods fall into two categories: reconstruction-based approaches, which often reconstruct anomalies too well, and decoupled representation learning with density estimators, which can suffer from suboptimal feature spaces. While some recent methods attempt to couple feature learning and anomaly detection, they often rely on surrogate objectives, restrict kernel choices, or introduce approximations that limit their expressiveness and robustness. To address this challenge, we propose a novel method that tightly couples representation learning with an analytically solvable one-class SVM (OCSVM), through a custom loss formulation that directly aligns latent features with the OCSVM decision boundary. The model is evaluated on two tasks: a new benchmark based on MNIST-C, and a challenging brain MRI subtle lesion detection task. Unlike most methods that focus on large, hyperintense lesions at the image level, our approach succeeds to target small, non-hyperintense lesions, while we evaluate voxel-wise metrics, addressing a more clinically relevant scenario. Both experiments evaluate a form of robustness to domain shifts, including corruption types in MNIST-C and scanner/age variations in MRI. Results demonstrate performance and robustness of our proposed mode,highlighting its potential for general UAD and real-world medical imaging applications. The source code is available at this https URL', 'abstract_zh': '无监督异常检测（UAD）旨在无需标记数据的情况下检测异常，这在许多机器学习应用中是必需的，尤其是在异常样本罕见或不可用的情况下。大多数最先进的方法分为两类：基于重建的方法，这些方法常常能够很好地重建异常；以及解耦的表示学习与密度估计方法，这些方法可能会遭受次优特征空间的问题。虽然一些最新方法试图将特征学习与异常检测结合，但它们往往依赖于代理目标、限制内核选择或引入近似方法，从而限制了它们的表达能力和鲁棒性。为了解决这一挑战，我们提出了一种新颖的方法，通过自定义损失函数将表示学习与解析可解的一类支持向量机（OCSVM）紧密耦合。该模型在两个任务上进行评估：基于MNIST-C的新基准测试，以及一个具有挑战性的脑部MRI微小病灶检测任务。与大多数方法专注于图像水平的大、高信号病灶不同，我们的方法能够成功地针对小、非高信号病灶，同时我们通过体素级指标进行评估，解决了更具有临床相关性的场景。两个实验评估了模型对领域转移的鲁棒性，包括MNIST-C中的损坏类型以及MRI中的扫描器/年龄变化。结果展示了我们提出模型的性能和鲁棒性，强调了其在通用UAD和现实世界医学成像应用中的潜在价值。源代码可在以下网址获取。', 'title_zh': 'OCSVM引导的表示学习在无监督异常检测中的应用'}
{'arxiv_id': 'arXiv:2507.21163', 'title': 'Generating Adversarial Point Clouds Using Diffusion Model', 'authors': 'Ruiyang Zhao, Bingbing Zhu, Chuxuan Tong, Xiaoyi Zhou, Xi Zheng', 'link': 'https://arxiv.org/abs/2507.21163', 'abstract': 'Adversarial attack methods for 3D point cloud classification reveal the vulnerabilities of point cloud recognition models. This vulnerability could lead to safety risks in critical applications that use deep learning models, such as autonomous vehicles. To uncover the deficiencies of these models, researchers can evaluate their security through adversarial attacks. However, most existing adversarial attack methods are based on white-box attacks. While these methods achieve high attack success rates and imperceptibility, their applicability in real-world scenarios is limited. Black-box attacks, which are more meaningful in real-world scenarios, often yield poor results. This paper proposes a novel black-box adversarial example generation method that utilizes a diffusion model to improve the attack success rate and imperceptibility in the black-box setting, without relying on the internal information of the point cloud classification model to generate adversarial samples. We use a 3D diffusion model to use the compressed features of the point cloud as prior knowledge to guide the reverse diffusion process to add adversarial points to clean examples. Subsequently, its reverse process is employed to transform the distribution of other categories into adversarial points, which are then added to the point cloud.', 'abstract_zh': '基于对抗攻击方法的3D点云分类揭示了点云识别模型的脆弱性：一种在黑盒设置中利用扩散模型生成对抗样本的新方法及其在自主车辆等关键应用中的安全性风险', 'title_zh': '使用扩散模型生成对抗点云'}
{'arxiv_id': 'arXiv:2507.21161', 'title': 'Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues', 'authors': 'Pallavi Zambare, Venkata Nikhil Thanikella, Ying Liu', 'link': 'https://arxiv.org/abs/2507.21161', 'abstract': 'Pedestrian intention prediction is essential for autonomous driving in complex urban environments. Conventional approaches depend on supervised learning over frame sequences and require extensive retraining to adapt to new scenarios. Here, we introduce BF-PIP (Beyond Frames Pedestrian Intention Prediction), a zero-shot approach built upon Gemini 2.5 Pro. It infers crossing intentions directly from short, continuous video clips enriched with structured JAAD metadata. In contrast to GPT-4V based methods that operate on discrete frames, BF-PIP processes uninterrupted temporal clips. It also incorporates bounding-box annotations and ego-vehicle speed via specialized multimodal prompts. Without any additional training, BF-PIP achieves 73% prediction accuracy, outperforming a GPT-4V baseline by 18 %. These findings illustrate that combining temporal video inputs with contextual cues enhances spatiotemporal perception and improves intent inference under ambiguous conditions. This approach paves the way for agile, retraining-free perception module in intelligent transportation system.', 'abstract_zh': '基于Gemini 2.5 Pro的Beyond Frames行人意图预测', 'title_zh': '超越框架：利用原始时序视频和多模态线索进行零样本行人意图预测'}
{'arxiv_id': 'arXiv:2507.21160', 'title': 'Handling Out-of-Distribution Data: A Survey', 'authors': 'Lakpa Tamang, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal', 'link': 'https://arxiv.org/abs/2507.21160', 'abstract': 'In the field of Machine Learning (ML) and data-driven applications, one of the significant challenge is the change in data distribution between the training and deployment stages, commonly known as distribution shift. This paper outlines different mechanisms for handling two main types of distribution shifts: (i) Covariate shift: where the value of features or covariates change between train and test data, and (ii) Concept/Semantic-shift: where model experiences shift in the concept learned during training due to emergence of novel classes in the test phase. We sum up our contributions in three folds. First, we formalize distribution shifts, recite on how the conventional method fails to handle them adequately and urge for a model that can simultaneously perform better in all types of distribution shifts. Second, we discuss why handling distribution shifts is important and provide an extensive review of the methods and techniques that have been developed to detect, measure, and mitigate the effects of these shifts. Third, we discuss the current state of distribution shift handling mechanisms and propose future research directions in this area. Overall, we provide a retrospective synopsis of the literature in the distribution shift, focusing on OOD data that had been overlooked in the existing surveys.', 'abstract_zh': '在机器学习（ML）和数据驱动应用领域，训练阶段与部署阶段数据分布的变化，即分布偏移，是一个重要的挑战。本文概述了处理两种主要类型分布偏移的不同机制：（i）自变量偏移：特征或自变量值在训练数据和测试数据之间发生变化；（ii）概念/语义偏移：由于测试阶段出现新类导致模型在训练中学习到的概念发生变化。我们从三个方面总结了我们的贡献。首先，我们形式化了分布偏移，说明了传统方法在处理它们时的不足，并呼吁一个能够同时在各种类型分布偏移中表现更佳的模型。其次，我们讨论了为什么处理分布偏移很重要，并提供了对已开发用于检测、衡量和缓解这些偏移影响的方法和技术的全面回顾。第三，我们讨论了当前处理分布偏移机制的状态，并提出了该领域的未来研究方向。总体而言，我们为分布偏移文献提供了一个回顾性综述，重点关注现有综述中被忽视的OOD数据。', 'title_zh': '处理分布外数据：一个综述'}
{'arxiv_id': 'arXiv:2507.21153', 'title': 'Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers', 'authors': 'Abderaouf Bahi, Amel Ourici', 'link': 'https://arxiv.org/abs/2507.21153', 'abstract': "This paper explores the implementation of a Deep Reinforcement Learning (DRL)-optimized energy management system for e-commerce data centers, aimed at enhancing energy efficiency, cost-effectiveness, and environmental sustainability. The proposed system leverages DRL algorithms to dynamically manage the integration of renewable energy sources, energy storage, and grid power, adapting to fluctuating energy availability in real time. The study demonstrates that the DRL-optimized system achieves a 38\\% reduction in energy costs, significantly outperforming traditional Reinforcement Learning (RL) methods (28\\%) and heuristic approaches (22\\%). Additionally, it maintains a low SLA violation rate of 1.5\\%, compared to 3.0\\% for RL and 4.8\\% for heuristic methods. The DRL-optimized approach also results in an 82\\% improvement in energy efficiency, surpassing other methods, and a 45\\% reduction in carbon emissions, making it the most environmentally friendly solution. The system's cumulative reward of 950 reflects its superior performance in balancing multiple objectives. Through rigorous testing and ablation studies, the paper validates the effectiveness of the DRL model's architecture and parameters, offering a robust solution for energy management in data centers. The findings highlight the potential of DRL in advancing energy optimization strategies and addressing sustainability challenges.", 'abstract_zh': '基于深度强化学习优化的电子商务数据中心能源管理系统及其应用', 'title_zh': '实时绿色能源集成在数据中心中的深度强化学习方法'}
{'arxiv_id': 'arXiv:2507.21152', 'title': 'Deep Unfolding for MIMO Signal Detection', 'authors': 'Hangli Ge, Noboru Koshizuka', 'link': 'https://arxiv.org/abs/2507.21152', 'abstract': 'In this paper, we propose a deep unfolding neural network-based MIMO detector that incorporates complex-valued computations using Wirtinger calculus. The method, referred as Dynamic Partially Shrinkage Thresholding (DPST), enables efficient, interpretable, and low-complexity MIMO signal detection. Unlike prior approaches that rely on real-valued approximations, our method operates natively in the complex domain, aligning with the fundamental nature of signal processing tasks. The proposed algorithm requires only a small number of trainable parameters, allowing for simplified training. Numerical results demonstrate that the proposed method achieves superior detection performance with fewer iterations and lower computational complexity, making it a practical solution for next-generation massive MIMO systems.', 'abstract_zh': '基于Wirtinger微积分的复值计算动态部分收缩阈值MIMO检测器', 'title_zh': 'MIMO信号检测的深度解折叠方法'}
{'arxiv_id': 'arXiv:2507.21147', 'title': 'Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning', 'authors': "Fabrizio Lo Scudo, Alessio De Rango, Luca Furnari, Alfonso Senatore, Donato D'Ambrosio, Giuseppe Mendicino, Gianluigi Greco", 'link': 'https://arxiv.org/abs/2507.21147', 'abstract': "Wildfires significantly impact natural ecosystems and human health, leading to biodiversity loss, increased hydrogeological risks, and elevated emissions of toxic substances. Climate change exacerbates these effects, particularly in regions with rising temperatures and prolonged dry periods, such as the Mediterranean. This requires the development of advanced risk management strategies that utilize state-of-the-art technologies. However, in this context, the data show a bias toward an imbalanced setting, where the incidence of wildfire events is significantly lower than typical situations. This imbalance, coupled with the inherent complexity of high-dimensional spatio-temporal data, poses significant challenges for training deep learning architectures. Moreover, since precise wildfire predictions depend mainly on weather data, finding a way to reduce computational costs to enable more frequent updates using the latest weather forecasts would be beneficial. This paper investigates how adopting a contrastive framework can address these challenges through enhanced latent representations for the patch's dynamic features. We thus introduce a new morphology-based curriculum contrastive learning that mitigates issues associated with diverse regional characteristics and enables the use of smaller patch sizes without compromising performance. An experimental analysis is performed to validate the effectiveness of the proposed modeling strategies.", 'abstract_zh': '野火显著影响自然生态系统和人类健康，导致生物多样性丧失、水文地质风险增加以及有毒物质排放加剧。气候变化加剧了这些影响，尤其是在温度上升和干旱期延长的地区，如地中海地区。这需要开发先进的风险管理策略，利用最先进的技术。然而，在这种背景下，数据表明野火事件的发生频率严重失衡，远低于典型情况。这种不平衡，加之高维度时空数据的固有复杂性，对训练深度学习架构提出了重大挑战。此外，由于精确的野火预测主要依赖于气象数据，找到一种方法降低计算成本，以利用最新的天气预报数据更频繁地更新预测，将是有益的。本文探讨了如何通过增强局部动态特征的潜在表示来采用对比框架来应对这些挑战。我们因此引入了一种基于形态学的分阶对比学习，以缓解与区域特征多样性相关的问题，并能够在不牺牲性能的情况下使用更小的局部尺寸。进行了实验分析以验证所提建模策略的有效性。', 'title_zh': '基于形态意识层次对比学习的 wildfire 风险预测提升'}
{'arxiv_id': 'arXiv:2507.21146', 'title': 'Towards Unifying Quantitative Security Benchmarking for Multi Agent Systems', 'authors': 'Gauri Sharma, Vidhi Kulkarni, Miles King, Ken Huang', 'link': 'https://arxiv.org/abs/2507.21146', 'abstract': "Evolving AI systems increasingly deploy multi-agent architectures where autonomous agents collaborate, share information, and delegate tasks through developing protocols. This connectivity, while powerful, introduces novel security risks. One such risk is a cascading risk: a breach in one agent can cascade through the system, compromising others by exploiting inter-agent trust. In tandem with OWASP's initiative for an Agentic AI Vulnerability Scoring System we define an attack vector, Agent Cascading Injection, analogous to Agent Impact Chain and Blast Radius, operating across networks of agents. In an ACI attack, a malicious input or tool exploit injected at one agent leads to cascading compromises and amplified downstream effects across agents that trust its outputs. We formalize this attack with an adversarial goal equation and key variables (compromised agent, injected exploit, polluted observations, etc.), capturing how a localized vulnerability can escalate into system-wide failure. We then analyze ACI's properties -- propagation chains, amplification factors, and inter-agent compound effects -- and map these to OWASP's emerging Agentic AI risk categories (e.g. Impact Chain and Orchestration Exploits). Finally, we argue that ACI highlights a critical need for quantitative benchmarking frameworks to evaluate the security of agent-to-agent communication protocols. We outline a methodology for stress-testing multi-agent systems (using architectures such as Google's A2A and Anthropic's MCP) against cascading trust failures, developing upon groundwork for measurable, standardized agent-to-agent security evaluation. Our work provides the necessary apparatus for engineers to benchmark system resilience, make data-driven architectural trade-offs, and develop robust defenses against a new generation of agentic threats.", 'abstract_zh': 'evolving AI系统中多代理架构的演进促使自主代理合作、共享信息并通过发展协议委派任务。这种连接性虽然强大，但也引入了新型安全风险。其中一种风险是连锁风险：一个代理的漏洞可以导致系统中其他代理被利用其间的信任关系而受到影响。我们与OWASP的Agent AI漏洞评分系统倡议相呼应，定义了一个攻击向量——代理连锁注入，类似于代理影响链和破坏半径，这一攻击向量在代理网络中发挥作用。在连锁注入攻击中，恶意输入或工具漏洞注入到一个代理，导致其信任的其他代理出现连锁性的破坏和下游效应的放大。我们通过敌手目标方程和关键变量（受损代理、注入漏洞、污染观测等）形式化这个攻击，捕捉局部漏洞如何升级为系统级故障。接着，我们分析连锁注入攻击的特性——传播链、放大因子和代理间的复合效应，并将这些映射到OWASP正在发展的Agent AI风险类别（例如影响链和编排性攻击）。最终，我们认为连锁注入攻击突显了定量基准测试框架对评估代理间通信协议安全性的迫切需求。我们概述了一种方法，用于压力测试多代理系统（如Google的A2A和Anthropic的MCP架构）以抵御连锁信任失败，从而在可测量和标准化的代理间安全评估的基础上构建更坚实的理论基础。我们的工作提供了工程师所需的工具，以评估系统韧性、进行数据驱动的架构权衡，并开发出对抗新一代代理威胁的稳健防御措施。', 'title_zh': '面向多agent系统的定量安全基准统合'}
{'arxiv_id': 'arXiv:2507.21142', 'title': 'Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for Compliance AI Agents', 'authors': 'Chenhao Fang, Yanqing Peng, Rajeev Rao, Matt Sarmiento, Wendy Summer, Arya Pudota, Alex Goncalves, Jordi Mola, Hervé Robert', 'link': 'https://arxiv.org/abs/2507.21142', 'abstract': "Enterprise environments contain a heterogeneous, rapidly growing collection of internal artifacts related to code, data, and many different tools. Critical information for assessing privacy risk and ensuring regulatory compliance is often embedded across these varied resources, each with their own arcane discovery and extraction techniques. Therefore, large-scale privacy compliance in adherence to governmental regulations requires systems to discern the interconnected nature of diverse artifacts in a common, shared universe.\nWe present Privacy Artifact ConnecT or (PACT), an embeddings-driven graph that links millions of artifacts spanning multiple artifact types generated by a variety of teams and projects. Powered by the state-of-the-art DRAGON embedding model, PACT uses a contrastive learning objective with light fine-tuning to link artifacts via their textual components such as raw metadata, ownership specifics, and compliance context. Experimental results show that PACT's fine-tuned model improves recall@1 from 18% to 53%, the query match rate from 9.6% to 69.7% when paired with a baseline AI agent, and the hitrate@1 from 25.7% to 44.9% for candidate selection in a standard recommender system.", 'abstract_zh': '企业环境中包含大量异质且快速增长的代码、数据和各种工具的相关内部资料。这些资料中的关键信息往往散嵌于多种资源之中，每种资源又具有各自的独特的发现和提取方法。因此，为了遵循政府法规进行大规模的隐私合规性要求，需要系统能够识别多样资料在共同共享环境中的相互关联性。\n我们提出了一种基于嵌入式的图结构——Privacy Artifact Connect or（PACT），它可以连接多种类型的不同团队和项目生成的数百万种资料。PACT 由最先进的 DRAGON 嵌入式模型驱动，通过对比学习目标和轻量级的微调，利用文本组件（如原始元数据、所有权具体信息和合规背景）来连接这些资料。实验结果显示，与基准AI代理配合使用时，PACT 微调后的模型将召回率@1 提高至 53%，查询匹配率提高至 69.7%，标准推荐系统中候选选择的命中率@1 提高至 44.9%。', 'title_zh': '隐私特征连接器（PACT）：嵌入企业特征以合规AI代理'}
{'arxiv_id': 'arXiv:2507.21138', 'title': 'TTS-1 Technical Report', 'authors': 'Oleg Atamanenko, Anna Chalova, Joseph Coombes, Nikki Cope, Phillip Dang, Zhifeng Deng, Jimmy Du, Michael Ermolenko, Feifan Fan, Yufei Feng, Cheryl Fichter, Pavel Filimonov, Louis Fischer, Kylan Gibbs, Valeria Gusarova, Pavel Karpik, Andreas Assad Kottner, Ian Lee, Oliver Louie, Jasmine Mai, Mikhail Mamontov, Suri Mao, Nurullah Morshed, Igor Poletaev, Florin Radu, Dmytro Semernia, Evgenii Shingarev, Vikram Sivaraja, Peter Skirko, Rinat Takhautdinov, Robert Villahermosa, Jean Wang', 'link': 'https://arxiv.org/abs/2507.21138', 'abstract': "We introduce Inworld TTS-1, a set of two Transformer-based autoregressive text-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters and is designed for utmost quality and expressiveness in demanding applications. TTS-1 is our most efficient model, with 1.6B parameters, built for real-time speech synthesis and on-device use cases. By scaling train-time compute and applying a sequential process of pre-training, fine-tuning, and RL-alignment of the speech-language model (SpeechLM) component, both models achieve state-of-the-art performance on a variety of benchmarks, demonstrating exceptional quality relying purely on in-context learning of the speaker's voice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech with low latency, and support 11 languages with fine-grained emotional control and non-verbal vocalizations through audio markups. We additionally open-source our training and modeling code under an MIT license.", 'abstract_zh': 'Inworld TTS-1：基于Transformer的自动回归文本转语音模型集', 'title_zh': 'TTS-1 技术报告'}
{'arxiv_id': 'arXiv:2507.21136', 'title': 'A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning', 'authors': 'Mojtaba Moattari', 'link': 'https://arxiv.org/abs/2507.21136', 'abstract': 'Unsupervised and supervised learning methods conventionally use kernels to capture nonlinearities inherent in data structure. However experts have to ensure their proposed nonlinearity maximizes variability and capture inherent diversity of data. We reviewed all independence criteria to design unsupervised learners. Then we proposed 3 independence criteria and used them to design unsupervised and supervised dimensionality reduction methods. We evaluated contrast, accuracy and interpretability of these methods in both linear and neural nonlinear settings. The results show that the methods have outperformed the baseline (tSNE, PCA, regularized LDA, VAE with (un)supervised learner and layer sharing) and opened a new line of interpretable machine learning (ML) for the researchers.', 'abstract_zh': '无监督和监督学习方法通常使用核函数来捕捉数据结构中的非线性特征，但在提出非线性特征时，专家需要确保其最大化数据的变异性并捕捉数据的内在多样性。我们回顾了所有独立性准则以设计无监督学习者。然后我们提出了三种独立性准则，并使用这些准则设计了无监督和监督降维方法。我们在线性和神经非线性设置下评估了这些方法的对比度、准确性和可解释性。结果表明，这些方法优于基线方法（tSNE、PCA、正则化LDA、VAE与无监督学习者和层共享），并且为研究人员开辟了一条新的可解释机器学习路径。', 'title_zh': '基于传统、模糊及 Null 空间独立性准则变体的监督与无监督学习改进研究'}
{'arxiv_id': 'arXiv:2507.21133', 'title': 'Analysis of Threat-Based Manipulation in Large Language Models: A Dual Perspective on Vulnerabilities and Performance Enhancement Opportunities', 'authors': 'Atil Samancioglu', 'link': 'https://arxiv.org/abs/2507.21133', 'abstract': 'Large Language Models (LLMs) demonstrate complex responses to threat-based manipulations, revealing both vulnerabilities and unexpected performance enhancement opportunities. This study presents a comprehensive analysis of 3,390 experimental responses from three major LLMs (Claude, GPT-4, Gemini) across 10 task domains under 6 threat conditions. We introduce a novel threat taxonomy and multi-metric evaluation framework to quantify both negative manipulation effects and positive performance improvements. Results reveal systematic vulnerabilities, with policy evaluation showing the highest metric significance rates under role-based threats, alongside substantial performance enhancements in numerous cases with effect sizes up to +1336%. Statistical analysis indicates systematic certainty manipulation (pFDR < 0.0001) and significant improvements in analytical depth and response quality. These findings have dual implications for AI safety and practical prompt engineering in high-stakes applications.', 'abstract_zh': '大型语言模型（LLMs）对基于威胁的操控表现出复杂响应，揭示了既有的脆弱性与意外的性能提升机会。本研究对三种主要LLM（Claude、GPT-4、Gemini）在6种威胁条件下、10个任务领域中的3,390个实验响应进行了全面分析。我们引入了一种新的威胁分类体系和多指标评估框架，用于量化负面操控效应和正面性能提升。结果表明，存在系统性的脆弱性，其中基于角色的威胁下政策评估显示出最高的指标显著性比率，同时在许多案例中观察到显著的性能提升，效果规模最高可达+1336%。统计分析表明存在系统的确定性操控（pFDR < 0.0001）并且在分析深度和响应质量方面有显著改进。这些发现对AI安全性及高风险应用中的实用提示工程具有双重意义。', 'title_zh': '基于威胁的大型语言模型操纵分析：漏洞与性能提升机会的双重视角'}
{'arxiv_id': 'arXiv:2507.21125', 'title': 'RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline', 'authors': 'Karan Mirhosseini, Arya Aftab, Alireza Sheikh', 'link': 'https://arxiv.org/abs/2507.21125', 'abstract': 'In an era of radical technology transformations, technology maps play a crucial role in enhancing decision making. These maps heavily rely on automated methods of technology extraction. This paper introduces Retrieval Augmented Technology Extraction (RATE), a Large Language Model (LLM) based pipeline for automated technology extraction from scientific literature. RATE combines Retrieval Augmented Generation (RAG) with multi-definition LLM-based validation. This hybrid method results in high recall in candidate generation alongside with high precision in candidate filtering. While the pipeline is designed to be general and widely applicable, we demonstrate its use on 678 research articles focused on Brain-Computer Interfaces (BCIs) and Extended Reality (XR) as a case study. Consequently, The validated technology terms by RATE were mapped into a co-occurrence network, revealing thematic clusters and structural features of the research landscape. For the purpose of evaluation, a gold standard dataset of technologies in 70 selected random articles had been curated by the experts. In addition, a technology extraction model based on Bidirectional Encoder Representations of Transformers (BERT) was used as a comparative method. RATE achieved F1-score of 91.27%, Significantly outperforming BERT with F1-score of 53.73%. Our findings highlight the promise of definition-driven LLM methods for technology extraction and mapping. They also offer new insights into emerging trends within the BCI-XR field. The source code is available this https URL', 'abstract_zh': '在科技革命时代的决策支持中，科技图谱扮演着重要角色。这些图谱高度依赖于自动化的科技提取方法。本文引入了一种基于大型语言模型（LLM）的自动科技提取pipeline——Retrieval Augmented Technology Extraction（RATE），结合了Retrieval Augmented Generation（RAG）与多定义LLM验证。这种方法在候选生成方面具有高的召回率，并在候选过滤方面具有高的精确率。尽管pipeline设计为通用且广泛适用，我们通过围绕脑-机接口（BCIs）和扩展现实（XR）的678篇研究文章进行案例研究，展示了其应用。经过RATE验证的科技术语被映射到共现网络中，揭示了研究领域的主题集群和结构特征。为了评估，领域专家整理了一个包含70篇随机选定文章的标准技术数据集。此外，我们还使用基于双向编码器表示变换器（BERT）的技术提取模型作为对照方法。RATE在F1分数上达到了91.27%，显著优于F1分数为53.73%的BERT。我们的发现强调了定义驱动的LLM方法在科技提取和映射中的潜力，并为BCI-XR领域的新兴趋势提供了新的见解。源代码可从这个链接获得。', 'title_zh': 'RATE：一种由大语言模型驱动的检索增强生成技术提取管道'}
{'arxiv_id': 'arXiv:2507.21124', 'title': 'VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization', 'authors': 'Ayan Biswas, Terece L. Turton, Nishath Rajiv Ranasinghe, Shawn Jones, Bradley Love, William Jones, Aric Hagberg, Han-Wei Shen, Nathan DeBardeleben, Earl Lawrence', 'link': 'https://arxiv.org/abs/2507.21124', 'abstract': 'We present VizGenie, a self-improving, agentic framework that advances scientific visualization through large language model (LLM) by orchestrating of a collection of domain-specific and dynamically generated modules. Users initially access core functionalities--such as threshold-based filtering, slice extraction, and statistical analysis--through pre-existing tools. For tasks beyond this baseline, VizGenie autonomously employs LLMs to generate new visualization scripts (e.g., VTK Python code), expanding its capabilities on-demand. Each generated script undergoes automated backend validation and is seamlessly integrated upon successful testing, continuously enhancing the system\'s adaptability and robustness. A distinctive feature of VizGenie is its intuitive natural language interface, allowing users to issue high-level feature-based queries (e.g., ``visualize the skull"). The system leverages image-based analysis and visual question answering (VQA) via fine-tuned vision models to interpret these queries precisely, bridging domain expertise and technical implementation. Additionally, users can interactively query generated visualizations through VQA, facilitating deeper exploration. Reliability and reproducibility are further strengthened by Retrieval-Augmented Generation (RAG), providing context-driven responses while maintaining comprehensive provenance records. Evaluations on complex volumetric datasets demonstrate significant reductions in cognitive overhead for iterative visualization tasks. By integrating curated domain-specific tools with LLM-driven flexibility, VizGenie not only accelerates insight generation but also establishes a sustainable, continuously evolving visualization practice. The resulting platform dynamically learns from user interactions, consistently enhancing support for feature-centric exploration and reproducible research in scientific visualization.', 'abstract_zh': 'VizGenie：一种自我提升的智能可视化框架', 'title_zh': 'VizGenie: 向符合领域需求并能自我优化的下一代科学研究可视化工作流迈进'}
{'arxiv_id': 'arXiv:2507.21120', 'title': 'Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation', 'authors': 'Bereket A. Yilma, Luis A. Leiva', 'link': 'https://arxiv.org/abs/2507.21120', 'abstract': 'Art Therapy (AT) is an established practice that facilitates emotional processing and recovery through creative expression. Recently, Visual Art Recommender Systems (VA RecSys) have emerged to support AT, demonstrating their potential by personalizing therapeutic artwork recommendations. Nonetheless, current VA RecSys rely on visual stimuli for user modeling, limiting their ability to capture the full spectrum of emotional responses during preference elicitation. Previous studies have shown that music stimuli elicit unique affective reflections, presenting an opportunity for cross-domain recommendation (CDR) to enhance personalization in AT. Since CDR has not yet been explored in this context, we propose a family of CDR methods for AT based on music-driven preference elicitation. A large-scale study with 200 users demonstrates the efficacy of music-driven preference elicitation, outperforming the classic visual-only elicitation approach. Our source code, data, and models are available at this https URL', 'abstract_zh': '基于音乐驱动偏好评价的艺术疗法跨域推荐方法', 'title_zh': '基于音乐偏好激发的情感aware跨域推荐的艺术疗法'}
{'arxiv_id': 'arXiv:2507.21118', 'title': 'Failure Risk Prediction in a MOOC: A Multivariate Time Series Analysis Approach', 'authors': 'Anass El Ayady, Maxime Devanne, Germain Forestier, Nour El Mawas', 'link': 'https://arxiv.org/abs/2507.21118', 'abstract': "MOOCs offer free and open access to a wide audience, but completion rates remain low, often due to a lack of personalized content. To address this issue, it is essential to predict learner performance in order to provide tailored feedback. Behavioral traces-such as clicks and events-can be analyzed as time series to anticipate learners' outcomes. This work compares multivariate time series classification methods to identify at-risk learners at different stages of the course (after 5, 10 weeks, etc.). The experimental evaluation, conducted on the Open University Learning Analytics Dataset (OULAD), focuses on three courses: two in STEM and one in SHS. Preliminary results show that the evaluated approaches are promising for predicting learner failure in MOOCs. The analysis also suggests that prediction accuracy is influenced by the amount of recorded interactions, highlighting the importance of rich and diverse behavioral data.", 'abstract_zh': 'MOOCs提供免费开放的学习资源给广泛受众，但完成率低下，常常由于缺乏个性化内容。为解决这一问题，预测学习者表现以提供个性化反馈至关重要。行为轨迹，如点击和事件，可以作为时间序列进行分析以预估学习者的学业成果。本研究将比较多元时间序列分类方法，以识别不同课程阶段（5周、10周等）可能出现学业风险的学习者。实验评估基于Open University Learning Analytics Dataset (OULAD)，重点分析三门课程：两门STEM课程和一门社会科学与健康科学课程。初步结果表明，评估的方法在预测MOOC中学习者辍学方面具有潜力。分析还表明，预测准确性受记录交互数量的影响，突显了丰富多样行为数据的重要性。', 'title_zh': 'MOOC中失败风险预测：一种多变量时间序列分析方法'}
{'arxiv_id': 'arXiv:2507.21117', 'title': 'A Comprehensive Review on Harnessing Large Language Models to Overcome Recommender System Challenges', 'authors': 'Rahul Raja, Anshaj Vats, Arpita Vats, Anirban Majumder', 'link': 'https://arxiv.org/abs/2507.21117', 'abstract': 'Recommender systems have traditionally followed modular architectures comprising candidate generation, multi-stage ranking, and re-ranking, each trained separately with supervised objectives and hand-engineered features. While effective in many domains, such systems face persistent challenges including sparse and noisy interaction data, cold-start problems, limited personalization depth, and inadequate semantic understanding of user and item content. The recent emergence of Large Language Models (LLMs) offers a new paradigm for addressing these limitations through unified, language-native mechanisms that can generalize across tasks, domains, and modalities. In this paper, we present a comprehensive technical survey of how LLMs can be leveraged to tackle key challenges in modern recommender systems. We examine the use of LLMs for prompt-driven candidate retrieval, language-native ranking, retrieval-augmented generation (RAG), and conversational recommendation, illustrating how these approaches enhance personalization, semantic alignment, and interpretability without requiring extensive task-specific supervision. LLMs further enable zero- and few-shot reasoning, allowing systems to operate effectively in cold-start and long-tail scenarios by leveraging external knowledge and contextual cues. We categorize these emerging LLM-driven architectures and analyze their effectiveness in mitigating core bottlenecks of conventional pipelines. In doing so, we provide a structured framework for understanding the design space of LLM-enhanced recommenders, and outline the trade-offs between accuracy, scalability, and real-time performance. Our goal is to demonstrate that LLMs are not merely auxiliary components but foundational enablers for building more adaptive, semantically rich, and user-centric recommender systems', 'abstract_zh': '基于大型语言模型的现代推荐系统关键技术综述', 'title_zh': '大型语言模型在克服推荐系统挑战中的综合综述'}
{'arxiv_id': 'arXiv:2507.21115', 'title': 'FedFlex: Federated Learning for Diverse Netflix Recommendations', 'authors': 'Sven Lankester, Manel Slokom, Gustavo de Carvalho Bertoli, Matias Vizcaino, Emmanuelle Beauxis Aussalet, Laura Hollink', 'link': 'https://arxiv.org/abs/2507.21115', 'abstract': 'Federated learning is a decentralized approach that enables collaborative model training across multiple devices while preserving data privacy. It has shown significant potential in various domains, including healthcare and personalized recommendation systems. However, most existing work on federated recommendation systems has focused primarily on improving accuracy, with limited attention to fairness and diversity. In this paper, we introduce FedFlex, a federated recommender system for Netflix-style TV series recommendations. FedFlex integrates two state-of-the-art matrix factorization algorithms for personalized fine-tuning. FedFlex also applies Maximal Marginal Relevance (MMR) to re-rank items and enhance diversity. We conduct extensive experiments comparing recommendations generated by SVD and BPR algorithms. In a live two-week user study, participants received two recommendation lists: List A, based on SVD or BPR, and List B, a re-ranked version emphasizing diversity. Participants were asked to click on the movies they were interested in watching. Our findings demonstrate that FedFlex effectively introduces diverse content, such as new genres, into recommendations without necessarily compromising user satisfaction.', 'abstract_zh': '联邦学习是一种去中心化的方法，能够在保护数据隐私的前提下，在多个设备之间实现模型的协同训练。它在包括医疗保健和个性化推荐系统在内的各个领域展示了显著的潜力。然而，现有的大多数联邦推荐系统工作主要集中在提高准确性上，对公平性和多样性关注较少。在本文中，我们提出了一种名为FedFlex的联邦推荐系统，适用于Netflix风格的电视剧推荐。FedFlex结合了两种最先进的矩阵分解算法以实现个性化调整，并应用最大相关性度量（MMR）重新排序项目以增强多样性。我们进行了广泛的实验，对比了SVD和BPR算法生成的推荐效果。在一个为期两周的实时用户研究中，参与者分别获得了基于SVD或BPR的推荐列表A和强调多样性的重新排序列表B，被要求点击他们感兴趣的电影。我们的研究结果表明，FedFlex能够在不必要牺牲用户满意度的情况下，有效引入新的内容类型，如新类型电影。', 'title_zh': 'FedFlex: 联邦学习下的 diverse Netflix 推荐'}
{'arxiv_id': 'arXiv:2507.21114', 'title': 'Page image classification for content-specific data processing', 'authors': 'Kateryna Lutsai, Pavel Straňák', 'link': 'https://arxiv.org/abs/2507.21114', 'abstract': 'Digitization projects in humanities often generate vast quantities of page images from historical documents, presenting significant challenges for manual sorting and analysis. These archives contain diverse content, including various text types (handwritten, typed, printed), graphical elements (drawings, maps, photos), and layouts (plain text, tables, forms). Efficiently processing this heterogeneous data requires automated methods to categorize pages based on their content, enabling tailored downstream analysis pipelines. This project addresses this need by developing and evaluating an image classification system specifically designed for historical document pages, leveraging advancements in artificial intelligence and machine learning. The set of categories was chosen to facilitate content-specific processing workflows, separating pages requiring different analysis techniques (e.g., OCR for text, image analysis for graphics)', 'abstract_zh': '人文领域的数字化项目常常生成大量的历史文献页面图像，这为手动分类和分析带来了巨大挑战。这些档案包含多样化的内容，包括各种文本类型（手写、打印、印刷）、图形元素（绘制、地图、照片）以及布局（纯文本、表格、表单）。有效地处理这些异构数据需要能够根据内容对页面进行自动分类的方法，从而为下游分析流水线提供定制化的处理流程。该项目通过开发和评估一种专门针对历史文献页面的图像分类系统来满足这一需求，利用了人工智能和机器学习的最新进展。所选的类别集旨在促进内容特定的处理工作流程，将需要不同分析技术的页面分开（例如，OCR用于文本、图像分析用于图形）。', 'title_zh': '特定内容图像分类'}
{'arxiv_id': 'arXiv:2507.21111', 'title': 'A Formal Rebuttal of "The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability"', 'authors': 'Craig Wright', 'link': 'https://arxiv.org/abs/2507.21111', 'abstract': 'This paper presents a comprehensive refutation of the so-called "blockchain trilemma," a widely cited but formally ungrounded claim asserting an inherent trade-off between decentralisation, security, and scalability in blockchain protocols. Through formal analysis, empirical evidence, and detailed critique of both methodology and terminology, we demonstrate that the trilemma rests on semantic equivocation, misuse of distributed systems theory, and a failure to define operational metrics. Particular focus is placed on the conflation of topological network analogies with protocol-level architecture, the mischaracterisation of Bitcoin\'s design--including the role of miners, SPV clients, and header-based verification--and the failure to ground claims in complexity-theoretic or adversarial models. By reconstructing Bitcoin as a deterministic, stateless distribution protocol governed by evidentiary trust, we show that scalability is not a trade-off but an engineering outcome. The paper concludes by identifying systemic issues in academic discourse and peer review that have allowed such fallacies to persist, and offers formal criteria for evaluating future claims in blockchain research.', 'abstract_zh': '本文全面反驳了所谓的“区块链三难问题”这一广泛引用但缺乏正式依据的说法，该说法声称在区块链协议中去中心化、安全性和可扩展性之间存在着固有的权衡。通过形式分析、实证证据以及对方法论和术语的详细批评，我们证明“三难问题”基于语义含糊、分布式系统理论的误用以及缺乏操作性衡量指标。特别关注的是将拓扑网络类比与协议级架构混淆、对Bitcoin设计的误character化，包括矿工、SPV客户端和基于区块头验证的作用，以及缺乏复杂性理论或对抗性模型的支持。通过对Bitcoin重新构建为一个由证据信任支配的确定性、无状态分布协议，我们证明可扩展性并非权衡而是工程结果。文章最后指出了学术话语和同行评审中的系统性问题，这些问题导致了此类谬误的持续存在，并提出了评估未来区块链研究中主张的形式标准。', 'title_zh': '对“区块链三难问题：去中心化、安全性和可扩展性内在权衡的正式证明”的正式反驳'}
{'arxiv_id': 'arXiv:2507.21110', 'title': 'SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering', 'authors': 'Kezhen Zhong, Basem Suleiman, Abdelkarim Erradi, Shijing Chen', 'link': 'https://arxiv.org/abs/2507.21110', 'abstract': 'This paper introduces SemRAG, an enhanced Retrieval Augmented Generation (RAG) framework that efficiently integrates domain-specific knowledge using semantic chunking and knowledge graphs without extensive fine-tuning. Integrating domain-specific knowledge into large language models (LLMs) is crucial for improving their performance in specialized tasks. Yet, existing adaptations are computationally expensive, prone to overfitting and limit scalability. To address these challenges, SemRAG employs a semantic chunking algorithm that segments documents based on the cosine similarity from sentence embeddings, preserving semantic coherence while reducing computational overhead. Additionally, by structuring retrieved information into knowledge graphs, SemRAG captures relationships between entities, improving retrieval accuracy and contextual understanding. Experimental results on MultiHop RAG and Wikipedia datasets demonstrate SemRAG has significantly enhances the relevance and correctness of retrieved information from the Knowledge Graph, outperforming traditional RAG methods. Furthermore, we investigate the optimization of buffer sizes for different data corpus, as optimizing buffer sizes tailored to specific datasets can further improve retrieval performance, as integration of knowledge graphs strengthens entity relationships for better contextual comprehension. The primary advantage of SemRAG is its ability to create an efficient, accurate domain-specific LLM pipeline while avoiding resource-intensive fine-tuning. This makes it a practical and scalable approach aligned with sustainability goals, offering a viable solution for AI applications in domain-specific fields.', 'abstract_zh': 'SemRAG：一种利用语义分块和知识图谱增强的 Retrieval Augmented Generation 框架', 'title_zh': 'SemRAG：语义知识增强的检索-生成模型以提高问答性能'}
{'arxiv_id': 'arXiv:2507.21109', 'title': 'Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students', 'authors': 'Prital Bamnodkar', 'link': 'https://arxiv.org/abs/2507.21109', 'abstract': "Deep Neural Networks often suffer from a critical limitation known as Catastrophic Forgetting, where performance on past tasks degrades after learning new ones. This paper introduces a novel continual learning approach inspired by human learning strategies like Active Recall, Deliberate Practice and Spaced Repetition, named Task Focused Consolidation with Spaced Recall (TFC-SR). TFC-SR enhances the standard experience replay with a mechanism we termed the Active Recall Probe. It is a periodic, task-aware evaluation of the model's memory that stabilizes the representations of past knowledge. We test TFC-SR on the Split MNIST and Split CIFAR-100 benchmarks against leading regularization-based and replay-based baselines. Our results show that TFC-SR performs significantly better than these methods. For instance, on the Split CIFAR-100, it achieves a final accuracy of 13.17% compared to standard replay's 7.40%. We demonstrate that this advantage comes from the stabilizing effect of the probe itself, and not from the difference in replay volume. Additionally, we analyze the trade-off between memory size and performance and show that while TFC-SR performs better in memory-constrained environments, higher replay volume is still more effective when available memory is abundant. We conclude that TFC-SR is a robust and efficient approach, highlighting the importance of integrating active memory retrieval mechanisms into continual learning systems.", 'abstract_zh': '深度神经网络往往受到一种名为灾难性遗忘的关键限制，即在学习新任务后，对过去任务的表现会下降。本文介绍了一种受人类学习策略（如主动回忆、刻意练习和分散复习）启发的新连续学习方法，名为基于分散回忆的任务聚焦巩固（TFC-SR）。TFC-SR通过我们称之为主动回忆探针的机制增强标准的经验回放，这是一种周期性的、任务感知的记忆评估，能够稳定过去知识的表示。我们使用Split MNIST和Split CIFAR-100基准测试TFC-SR，与基于正则化和回放缓冲的领先基准方法进行比较。结果显示，TFC-SR的表现显著优于这些方法。例如，在Split CIFAR-100中，TFC-SR的最终准确率为13.17%，而标准回放缓冲仅为7.40%。我们展示了这一优势来源于探针本身的稳定作用，而不是回放容量的不同。此外，我们分析了记忆大小与性能之间的权衡，并表明虽然在资源受限的环境中TFC-SR表现更好，但当可用内存充足时，更大的回放容量仍然更为有效。我们得出结论，TFC-SR是一种稳健而高效的策略，强调了将主动记忆检索机制整合到连续学习系统中的重要性。', 'title_zh': '基于间隔回忆的任务导向性 consolidation：使神经网络像大学生一样学习'}
{'arxiv_id': 'arXiv:2507.21108', 'title': 'A Survey of Classification Tasks and Approaches for Legal Contracts', 'authors': 'Amrita Singh, Aditya Joshi, Jiaojiao Jiang, Hye-young Paik', 'link': 'https://arxiv.org/abs/2507.21108', 'abstract': 'Given the large size and volumes of contracts and their underlying inherent complexity, manual reviews become inefficient and prone to errors, creating a clear need for automation. Automatic Legal Contract Classification (LCC) revolutionizes the way legal contracts are analyzed, offering substantial improvements in speed, accuracy, and accessibility. This survey delves into the challenges of automatic LCC and a detailed examination of key tasks, datasets, and methodologies. We identify seven classification tasks within LCC, and review fourteen datasets related to English-language contracts, including public, proprietary, and non-public sources. We also introduce a methodology taxonomy for LCC, categorized into Traditional Machine Learning, Deep Learning, and Transformer-based approaches. Additionally, the survey discusses evaluation techniques and highlights the best-performing results from the reviewed studies. By providing a thorough overview of current methods and their limitations, this survey suggests future research directions to improve the efficiency, accuracy, and scalability of LCC. As the first comprehensive survey on LCC, it aims to support legal NLP researchers and practitioners in improving legal processes, making legal information more accessible, and promoting a more informed and equitable society.', 'abstract_zh': '基于自动法律合同分类的挑战与方法综述：提高效率、准确性和可扩展性的未来研究方向', 'title_zh': '法律合同分类任务及方法综述'}
{'arxiv_id': 'arXiv:2507.21107', 'title': 'Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams', 'authors': 'Rob Manson', 'link': 'https://arxiv.org/abs/2507.21107', 'abstract': 'We propose Curved Inference - a geometric Interpretability framework that tracks how the residual stream trajectory of a large language model bends in response to shifts in semantic concern. Across 20 matched prompts spanning emotional, moral, perspective, logical, identity, environmental, and nonsense domains, we analyse Gemma3-1b and LLaMA3.2-3b using five native-space metrics, with a primary focus on curvature (\\k{appa}_i) and salience (S(t)). These metrics are computed under a pullback semantic metric derived from the unembedding matrix, ensuring that all measurements reflect token-aligned geometry rather than raw coordinate structure. We find that concern-shifted prompts reliably alter internal activation trajectories in both models - with LLaMA exhibiting consistent, statistically significant scaling in both curvature and salience as concern intensity increases. Gemma also responds to concern but shows weaker differentiation between moderate and strong variants. Our results support a two-layer view of LLM geometry - a latent conceptual structure encoded in the embedding space, and a contextual trajectory shaped by prompt-specific inference. Curved Inference reveals how models navigate, reorient, or reinforce semantic meaning over depth, offering a principled method for diagnosing alignment, abstraction, and emergent inference dynamics. These findings offer fresh insight into semantic abstraction and model alignment through the lens of Curved Inference.', 'abstract_zh': '曲面推理——一种几何可解释性框架：探究大型语言模型在语义关注转换时残差流轨迹的弯曲情况', 'title_zh': '曲线推理：大型语言模型残差流中的关注敏感几何'}
{'arxiv_id': 'arXiv:2507.21105', 'title': 'AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis', 'authors': 'Callie C. Liao, Duoduo Liao, Sai Surya Gadiraju', 'link': 'https://arxiv.org/abs/2507.21105', 'abstract': 'The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI), especially integrated with Large Language Models (LLMs), has greatly facilitated the resolution of complex tasks. However, current systems are still facing challenges of inter-agent communication, coordination, and interaction with heterogeneous tools and resources. Most recently, the Model Context Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by Google have been introduced, and to the best of our knowledge, very few applications exist where both protocols are employed within a single MAS framework. We present a pilot study of AgentMaster, a novel modular multi-protocol MAS framework with self-implemented A2A and MCP, enabling dynamic coordination and flexible communication. Through a unified conversational interface, the system supports natural language interaction without prior technical expertise and responds to multimodal queries for tasks including information retrieval, question answering, and image analysis. Evaluation through the BERTScore F1 and LLM-as-a-Judge metric G-Eval averaged 96.3\\% and 87.1\\%, revealing robust inter-agent coordination, query decomposition, dynamic routing, and domain-specific, relevant responses. Overall, our proposed framework contributes to the potential capabilities of domain-specific, cooperative, and scalable conversational AI powered by MAS.', 'abstract_zh': '多代理系统（MAS）在人工智能（AI）中的兴起，尤其是与大型语言模型（LLMs）的集成，极大地促进了复杂任务的解决。然而，当前系统仍然面临着代理间通信、协调及与异构工具和资源交互的挑战。最近，Anthropic的Model Context Protocol (MCP) 和Google的Agent-to-Agent (A2A) 通信协议已被引入，并且据我们所知，在单一MAS框架中同时使用这两种协议的应用非常少。我们提出了AgentMaster这一新型模块化多协议MAS框架，该框架集成了自实施的A2A和MCP协议，能够实现动态协调和灵活通信。通过统一的对话接口，系统支持自然语言交互，无需先验技术知识，并能够处理包括信息检索、问答和图像分析在内的跨模态查询。通过BERTScore F1和LLM-as-a-Judge评价指标G-Eval评估，平均得分为96.3%和87.1%，表明系统具有 robust 的代理间协调、查询分解、动态路由以及特定领域、相关响应能力。总体而言，我们提出的方法框架有助于跨领域的合作和可扩展的对话AI的发展，该AI由MAS驱动。', 'title_zh': 'AgentMaster：一种基于A2A和MCP协议的多模态信息检索与分析多智能体对话框架'}
{'arxiv_id': 'arXiv:2507.21104', 'title': 'iLSU-T: an Open Dataset for Uruguayan Sign Language Translation', 'authors': 'Ariel E. Stassi, Yanina Boria, J. Matías Di Martino, Gregory Randall', 'link': 'https://arxiv.org/abs/2507.21104', 'abstract': 'Automatic sign language translation has gained particular interest in the computer vision and computational linguistics communities in recent years. Given each sign language country particularities, machine translation requires local data to develop new techniques and adapt existing ones. This work presents iLSU T, an open dataset of interpreted Uruguayan Sign Language RGB videos with audio and text transcriptions. This type of multimodal and curated data is paramount for developing novel approaches to understand or generate tools for sign language processing. iLSU T comprises more than 185 hours of interpreted sign language videos from public TV broadcasting. It covers diverse topics and includes the participation of 18 professional interpreters of sign language. A series of experiments using three state of the art translation algorithms is presented. The aim is to establish a baseline for this dataset and evaluate its usefulness and the proposed pipeline for data processing. The experiments highlight the need for more localized datasets for sign language translation and understanding, which are critical for developing novel tools to improve accessibility and inclusion of all individuals. Our data and code can be accessed.', 'abstract_zh': '自动手语翻译近年来在计算机视觉和计算语言学领域引起了特别的兴趣。鉴于每个手语国家的独特性，机器翻译需要当地数据来开发新技术和适应现有技术。本文介绍了iLSU T，一个包含解释的乌拉圭手语RGB视频及其音频和文本转录的开源数据集。此类多模态和精心整理的数据对于开发新的手语处理方法至关重要。iLSU T 包含超过185小时的公共电视台转译手语视频，涵盖了多个主题，并包括18名专业手语翻译者的参与。本文展示了用三个最先进的翻译算法进行的一系列实验，旨在为该数据集建立基准并评估其用途及其提出的处理流程。实验强调了需要更多局部化的手语翻译和理解数据集的重要性，这对于开发新的工具以提高所有人都能获得的无障碍和包容性至关重要。我们的数据和代码可以访问。', 'title_zh': 'iLSU-T：乌拉圭手语翻译的开放数据集'}
{'arxiv_id': 'arXiv:2507.21102', 'title': 'Assessing the Ecological Impact of AI', 'authors': 'Sylvia Wenmackers', 'link': 'https://arxiv.org/abs/2507.21102', 'abstract': 'Philosophers of technology have recently started paying more attention to the environmental impacts of AI, in particular of large language models (LLMs) and generative AI (genAI) applications. Meanwhile, few developers of AI give concrete estimates of the ecological impact of their models and products, and even when they do so, their analysis is often limited to green house gas emissions of certain stages of AI development or use. The current proposal encourages practically viable analyses of the sustainability aspects of genAI informed by philosophical ideas.', 'abstract_zh': '技术哲学家最近开始更加关注人工智能的环境影响，特别是大型语言模型（LLMs）和生成人工智能（genAI）应用的影响。然而，很少有AI开发者提供其模型和产品的具体生态影响估计，即使有所估计，分析通常也仅限于某些阶段的AI开发或使用所产生的温室气体排放。当前的提议鼓励基于哲学观念来进行可持续性方面的实际可行分析。', 'title_zh': '评估人工智能的生态影响'}
{'arxiv_id': 'arXiv:2507.21100', 'title': 'A Tactical Behaviour Recognition Framework Based on Causal Multimodal Reasoning: A Study on Covert Audio-Video Analysis Combining GAN Structure Enhancement and Phonetic Accent Modelling', 'authors': 'Wei Meng', 'link': 'https://arxiv.org/abs/2507.21100', 'abstract': 'This paper introduces TACTIC-GRAPHS, a system that combines spectral graph theory and multimodal graph neural reasoning for semantic understanding and threat detection in tactical video under high noise and weak structure. The framework incorporates spectral embedding, temporal causal edge modeling, and discriminative path inference across heterogeneous modalities. A semantic-aware keyframe extraction method fuses visual, acoustic, and action cues to construct temporal graphs. Using graph attention and Laplacian spectral mapping, the model performs cross-modal weighting and causal signal analysis. Experiments on TACTIC-AVS and TACTIC-Voice datasets show 89.3 percent accuracy in temporal alignment and over 85 percent recognition of complete threat chains, with node latency within plus-minus 150 milliseconds. The approach enhances structural interpretability and supports applications in surveillance, defense, and intelligent security systems.', 'abstract_zh': '这篇论文介绍了TACTIC-GRAPHS系统，该系统结合了谱图理论和多模态图神经推理，以在高噪声和弱结构环境下进行战术视频中的语义理解和威胁检测。该框架融合了谱嵌入、时间因果边建模以及异构模态下的判别路径推断。一种语义aware的关键帧提取方法融合了视觉、声学和动作线索，构建时间图。通过图注意和拉普拉斯谱映射，模型进行跨模态加权和因果信号分析。在TACTIC-AVS和TACTIC-Voice数据集上的实验显示，时间对齐的准确率为89.3%，完整威胁链的识别率超过85%，节点延迟在±150毫秒以内。该方法增强了结构可解释性，并支持监视、防御和智能安全系统中的应用。', 'title_zh': '基于因果多模态推理的战术行为识别框架：结合GAN结构增强和音韵重音建模的隐蔽音视频分析研究'}
{'arxiv_id': 'arXiv:2507.21091', 'title': 'The Value of Gen-AI Conversations: A bottom-up Framework for AI Value Alignment', 'authors': 'Lenart Motnikar, Katharina Baum, Alexander Kagan, Sarah Spiekermann-Hoff', 'link': 'https://arxiv.org/abs/2507.21091', 'abstract': 'Conversational agents (CAs) based on generative artificial intelligence frequently face challenges ensuring ethical interactions that align with human values. Current value alignment efforts largely rely on top-down approaches, such as technical guidelines or legal value principles. However, these methods tend to be disconnected from the specific contexts in which CAs operate, potentially leading to misalignment with users interests. To address this challenge, we propose a novel, bottom-up approach to value alignment, utilizing the value ontology of the ISO Value-Based Engineering standard for ethical IT design. We analyse 593 ethically sensitive system outputs identified from 16,908 conversational logs of a major European employment service CA to identify core values and instances of value misalignment within real-world interactions. The results revealed nine core values and 32 different value misalignments that negatively impacted users. Our findings provide actionable insights for CA providers seeking to address ethical challenges and achieve more context-sensitive value alignment.', 'abstract_zh': '基于生成式人工智能的对话代理在确保与人类价值观一致的伦理交互方面经常面临挑战。当前的价值对齐努力主要依赖自上而下的方法，如技术指南或法律价值原则。然而，这些方法往往与对话代理在其运作的具体上下文脱节，可能导致与用户利益的 misalignment。为了应对这一挑战，我们提出了一种新颖的自下而上的价值对齐方法，该方法利用ISO基于价值工程标准的价值本体进行伦理IT设计的价值对齐。我们分析了来自一个主要欧洲就业服务对话代理的16,908条对话日志中识别出的593个伦理敏感系统输出，以识别实际交互中的核心价值观和价值 misalignment 的实例。结果发现有九个核心价值观和32种不同的价值 misalignment，这些 misalignment 对用户产生了负面影响。我们的发现为寻求解决伦理挑战并实现更具上下文敏感的价值对齐的对话代理提供商提供了可操作的见解。', 'title_zh': 'Gen-AI对话的价值：自底向上的AI价值对齐框架'}
{'arxiv_id': 'arXiv:2507.21090', 'title': 'Thinking Like a Scientist: Can Interactive Simulations Foster Critical AI Literacy?', 'authors': 'Yiling Zhao, Audrey Michal, Nithum Thain, Hari Subramonyam', 'link': 'https://arxiv.org/abs/2507.21090', 'abstract': 'As AI systems shape individual and societal decisions, fostering critical AI literacy is essential. Traditional approaches, such as blog articles, static lessons, and social media discussions, often fail to support deep conceptual understanding and critical engagement. This study examines whether interactive simulations can help learners think like a scientist by engaging them in hypothesis testing, experimentation, and direct observation of AI behavior. In a controlled study with 605 participants, we assess how interactive AI tutorials impact learning of key concepts such as fairness, dataset representativeness, and bias in language models. Results show that interactive simulations effectively enhance AI literacy across topics, supporting greater knowledge transfer and self-reported confidence, though engagement alone does not predict learning. This work contributes to the growing field of AI literacy education, highlighting how interactive, inquiry-driven methodologies can better equip individuals to critically engage with AI in their daily lives.', 'abstract_zh': '随着AI系统影响个人和社会决策，培养批判性AI literacy至关重要。传统的教学方法，如博客文章、静态课程和社交媒体讨论，往往无法支持深刻的概念理解与批判性参与。本研究探讨交互式模拟是否能通过让学习者参与假设测试、实验和直接观察AI行为，帮助他们像科学家一样思考。在一项包括605名参与者的受控研究中，我们评估交互式AI教程对公平性、数据集代表性以及语言模型偏见等关键概念学习的影响。结果表明，交互式模拟有效地提升了跨学科的AI literacy，促进了知识迁移和自我报告的自信心，但单纯的参与并不能预测学习效果。本研究为不断发展的AI literacy教育领域做出了贡献，突出了以探究为导向的交互式方法如何更好地帮助个人在日常生活中批判性地应对AI。', 'title_zh': '科学家般思考：交互式模拟能否培养批判性人工智能素养？'}
{'arxiv_id': 'arXiv:2507.21083', 'title': 'ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs', 'authors': 'Franck Bardol', 'link': 'https://arxiv.org/abs/2507.21083', 'abstract': 'Large Language Models like GPT-4 adjust their responses not only based on the question asked, but also on how it is emotionally phrased. We systematically vary the emotional tone of 156 prompts - spanning controversial and everyday topics - and analyze how it affects model responses. Our findings show that GPT-4 is three times less likely to respond negatively to a negatively framed question than to a neutral one. This suggests a "rebound" bias where the model overcorrects, often shifting toward neutrality or positivity. On sensitive topics (e.g., justice or politics), this effect is even more pronounced: tone-based variation is suppressed, suggesting an alignment override. We introduce concepts like the "tone floor" - a lower bound in response negativity - and use tone-valence transition matrices to quantify behavior. Visualizations based on 1536-dimensional embeddings confirm semantic drift based on tone. Our work highlights an underexplored class of biases driven by emotional framing in prompts, with implications for AI alignment and trust. Code and data are available at: this https URL', 'abstract_zh': '大型语言模型如GPT-4不仅根据提出的问题调整其响应，还根据问题的情绪表述方式调整。我们系统地对156个提示的情绪语气进行了变化——这些提示涵盖争议性和日常生活中的各种话题——并分析了这种变化如何影响模型的响应。我们的研究发现，GPT-4对负面表述的问题的回应是中性表述问题的三分之一。这表明了一种“反弹”偏差，模型过度纠正，常常转向中立或积极的方向。在敏感话题（例如，公正或政治）上，这种效应更为显著：基于语气的变化受到抑制，暗示了一种对齐的覆盖。我们引入了“语气底线”这一概念——响应负面性的下限，并使用语气-语义值转换矩阵来量化行为。基于1536维嵌入的可视化显示了基于语气的语义漂移。我们的工作强调了由提示情绪表述驱动的一种未被充分探索的偏差类别，这对AI对齐和信任具有重要意义。代码和数据可在以下链接获取：this https URL', 'title_zh': 'ChatGPT读取你的语气并相应地作出回应——直到它不再这样做——情感框架导致LLM输出中的偏见'}
{'arxiv_id': 'arXiv:2507.21081', 'title': 'Empathy in Explanation', 'authors': 'Katherine M. Collins, Kartik Chandra, Adrian Weller, Jonathan Ragan-Kelley, Joshua B. Tenenbaum', 'link': 'https://arxiv.org/abs/2507.21081', 'abstract': "Why do we give the explanations we do? Recent work has suggested that we should think of explanation as a kind of cooperative social interaction, between a why-question-asker and an explainer. Here, we apply this perspective to consider the role that emotion plays in this social interaction. We develop a computational framework for modeling explainers who consider the emotional impact an explanation might have on a listener. We test our framework by using it to model human intuitions about how a doctor might explain to a patient why they have a disease, taking into account the patient's propensity for regret. Our model predicts human intuitions well, better than emotion-agnostic ablations, suggesting that people do indeed reason about emotion when giving explanations.", 'abstract_zh': '我们为何给出这样的解释？近期研究表明，我们应该将解释视为一种合作关系，发生在为何提问者与解释者之间。在此基础上，我们探讨情感在这类社会互动中的作用。我们发展了一个计算框架，用于建模解释者考虑解释可能给听众带来的情感影响。我们通过使用该框架来模拟医生向患解释其患病原因时的情感影响，考虑到患者后悔的可能性。我们的模型很好地预测了人们的情感直觉，比不知情的情感模型表现更好，这表明人们在给出解释时确实会考虑情感因素。', 'title_zh': '共情在解释中的作用'}
{'arxiv_id': 'arXiv:2507.21080', 'title': 'Which symbol grounding problem should we try to solve?', 'authors': 'Vincent C. Müller', 'link': 'https://arxiv.org/abs/2507.21080', 'abstract': 'Floridi and Taddeo propose a condition of "zero semantic commitment" for solutions to the grounding problem, and a solution to it. I argue briefly that their condition cannot be fulfilled, not even by their own solution. After a look at Luc Steels\' very different competing suggestion, I suggest that we need to re-think what the problem is and what role the \'goals\' in a system play in formulating the problem. On the basis of a proper understanding of computing, I come to the conclusion that the only sensible grounding problem is how we can explain and re-produce the behavioral ability and function of meaning in artificial computational agents', 'abstract_zh': '弗罗里迪和塔德多提出“零语义承诺”条件以解决基底问题，并提出了一个解决方案。我认为他们的条件无法实现，甚至他们自己的解决方案也无法满足。在审视卢克·斯蒂尔斯非常不同的竞争建议后，我建议我们需要重新思考问题本身以及系统中的“目标”在界定问题中的作用。基于对计算的正确理解，我认为唯一合乎情理的基底问题是：我们如何解释和重现人工计算代理的的行为能力和意义功能。', 'title_zh': '我们应该尝试解决哪种符号 grounding 问题？'}
{'arxiv_id': 'arXiv:2507.21077', 'title': 'Data-Driven and Participatory Approaches toward Neuro-Inclusive AI', 'authors': 'Naba Rizvi', 'link': 'https://arxiv.org/abs/2507.21077', 'abstract': 'Biased data representation in AI marginalizes up to 75 million autistic people worldwide through medical applications viewing autism as a deficit of neurotypical social skills rather than an aspect of human diversity, and this perspective is grounded in research questioning the humanity of autistic people. Turing defined artificial intelligence as the ability to mimic human communication, and as AI development increasingly focuses on human-like agents, this benchmark remains popular. In contrast, we define Neuro-Inclusive AI as datasets and systems that move away from mimicking humanness as a benchmark for machine intelligence. Then, we explore the origins, prevalence, and impact of anti-autistic biases in current research. Our work finds that 90% of human-like AI agents exclude autistic perspectives, and AI creators continue to believe ethical considerations are beyond the scope of their work. To improve the autistic representation in data, we conduct empirical experiments with annotators and LLMs, finding that binary labeling schemes sufficiently capture the nuances of labeling anti-autistic hate speech. Our benchmark, AUTALIC, can be used to evaluate or fine-tune models, and was developed to serve as a foundation for more neuro-inclusive future work.', 'abstract_zh': 'AI中偏向性的数据表示通过医疗应用边缘化多达7500万自闭症患者：以自闭症缺乏神经典型社会技能为缺陷而非人类多样性的 aspects 视角为基础，这种观点根植于质疑自闭症患者人性的研究。图灵定义人工智能为模仿人类交流的能力，随着AI开发越来越多地关注类人代理，这一标准依然流行。相比之下，我们定义神经包容性AI为远离将类人性作为机器智能标准的数据集和系统。然后，我们探讨了当前研究中反自闭症偏见的起源、普遍存在性和影响。我们的工作发现，90%的类人AI代理排斥自闭症视角，AI创作者仍认为伦理考量超出了他们的工作范围。为了改善数据中的自闭症代表性，我们进行了一项以注释员和大模型为基础的实证实验，发现二元标签方案能够充分捕捉反自闭症仇恨言论的细微差别。我们的基准AUTALIC可以用于评估或微调模型，旨在作为未来更加神经包容性工作的基础。', 'title_zh': '数据驱动与参与式面向神经包容的AI'}
{'arxiv_id': 'arXiv:2507.21074', 'title': 'Empowering Educators in the Age of AI: An Empirical Study on Creating custom GPTs in Qualitative Research Method education', 'authors': 'Qian Huang, Thijs Willems', 'link': 'https://arxiv.org/abs/2507.21074', 'abstract': 'As generative AI (Gen-AI) tools become more prevalent in education, there is a growing need to understand how educators, not just students, can actively shape their design and use. This study investigates how two instructors integrated four custom GPT tools into a Masters-level Qualitative Research Methods course for Urban Planning Policy students. Addressing two key gaps: the dominant framing of students as passive AI users, and the limited use of AI in qualitative methods education. The study explores how Gen-AI can support disciplinary learning when aligned with pedagogical intent. Drawing on the Technological Pedagogical Content Knowledge (TPACK) framework and action research methodology, the instructors designed GPTs to scaffold tasks such as research question formulation, interview practice, fieldnote analysis, and design thinking. Thematic analysis of student reflections, AI chat logs, and final assignments revealed that the tools enhanced student reflexivity, improved interview techniques, and supported structured analytic thinking. However, students also expressed concerns about cognitive overload, reduced immersion in data, and the formulaic nature of AI responses. The study offers three key insights: AI can be a powerful scaffold for active learning when paired with human facilitation; custom GPTs can serve as cognitive partners in iterative research practice; and educator-led design is critical to pedagogically meaningful AI integration. This research contributes to emerging scholarship on AI in higher education by demonstrating how empowering educators to design custom tools can promote more reflective, responsible, and collaborative learning with AI.', 'abstract_zh': '随着生成式人工智能（Gen-AI）工具在教育领域的广泛应用，有必要了解教育者如何能够积极地参与设计和使用这些工具。本研究探讨了两位讲师如何将四种自定义GPT工具整合到一门面向城市规划政策学生的定量研究方法硕士课程中，以解决两个关键缺口：将学生主要视为被动的AI用户和在定性方法教育中有限使用AI的问题。研究探讨了当与教学目标一致时，Gen-AI如何支持学科学习。本研究基于技术、教学法与内容知识（TPACK）框架和行动研究方法，设计GPT工具，以支持研究问题的形成、访谈练习、实地笔记分析和设计思维等任务。通过对学生反思、AI聊天记录和最终作业的主题分析发现，这些工具增强了学生的反思能力，提高了访谈技巧，并支持了结构化的分析思维。然而，学生也表达了认知负担过重、数据沉浸减少和AI回应格式化等问题的担忧。本研究提供了三个关键见解：当与人类引导相结合时，AI可以成为促进积极学习的强大支架；定制的GPT工具可以作为迭代研究实践中的认知伙伴；而教育者主导的设计对于教育意义深远的AI整合至关重要。本研究为高等教育中人工智能相关新兴研究作出了贡献，通过展示赋能教育者设计自定义工具如何促进更具反思性、责任感和协作性的AI学习。', 'title_zh': '在人工智能时代赋能教育者：立足定性研究方法教育的自定义GPT创建实证研究'}
{'arxiv_id': 'arXiv:2507.21071', 'title': 'FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents', 'authors': 'Qinglong Yang, Haoming Li, Haotian Zhao, Xiaokai Yan, Jingtao Ding, Fengli Xu, Yong Li', 'link': 'https://arxiv.org/abs/2507.21071', 'abstract': "Mobile GUI agents are becoming critical tools for enhancing human-device interaction efficiency, with multimodal large language models (MLLMs) emerging as dominant paradigms in this domain. Current agents, however, are limited to following explicit human instructions, resulting in insufficient capability for proactive intent anticipation. Additionally, these agents fail to leverage the contextual information associated with users during task execution, thereby neglecting potentially vast differences in user preferences. To address these challenges, we introduce the FingerTip benchmark. It contains two new tracks: proactive task suggestions by analyzing environment observation and users' previous intents, and personalized task execution by catering to users' action preferences. We collected unique human demonstrations of multi-step Android device interactions across a variety of everyday apps. These demonstrations are not isolated but are continuously acquired from the users' long-term usage in their real lives, and encompass essential user-related contextual information. Our experiments reveal challenges of the tasks we propose. The model fine-tuned with the data we collected effectively utilized user information and achieved good results, highlighting the potential of our approach in building more user-oriented mobile GUI agents. Our code is open-source at this https URL for reproducibility.", 'abstract_zh': '移动GUI代理正becoming critical tools for enhancing human-device interaction efficiency，其中多模态大规模语言模型（MLLMs）已成为这一领域的主导范式。然而，当前的代理仅限于遵循明确的人类指令，导致其主动意图预测能力不足。此外，这些代理在任务执行过程中未能利用用户的上下文信息，从而忽视了用户偏好之间可能存在的巨大差异。为应对这些挑战，我们引入了FingerTip基准。该基准包含两个新的赛道：基于环境观察和用户先前意图的主动任务建议，以及根据用户行为偏好定制的任务执行。我们收集了跨越各种日常应用的多步Android设备交互的唯一人类演示。这些演示不是孤立的，而是从用户在现实生活中的长期使用中不断获取，并包含关键的用户相关上下文信息。我们的实验揭示了我们提出任务的挑战。使用我们收集的数据 fine-tuned 的模型有效地利用了用户信息，并取得了良好的结果，强调了我们方法在构建更以用户为中心的移动GUI代理方面的潜力。我们的代码在此处公开 accessible at this https URL 以实现可重现性。', 'title_zh': '指尖20K：主动个性化移动LLM代理基准'}
{'arxiv_id': 'arXiv:2507.21069', 'title': 'GAITEX: Human motion dataset from impaired gait and rehabilitation exercises of inertial and optical sensor data', 'authors': 'Andreas Spilz, Heiko Oppel, Jochen Werner, Kathrin Stucke-Straub, Felix Capanni, Michael Munz', 'link': 'https://arxiv.org/abs/2507.21069', 'abstract': 'Wearable inertial measurement units (IMUs) offer a cost-effective and scalable means to assess human movement quality in clinical and everyday settings. However, the development of robust sensor-based classification models for physiotherapeutic exercises and gait analysis requires large, diverse datasets, which are costly and time-consuming to collect. Here, we present a multimodal dataset of physiotherapeutic exercises - including correct and clinically relevant variants - and gait-related exercises - including both normal and impaired gait patterns - recorded from 19 participants using synchronized IMUs and marker-based motion capture (MoCap). The dataset includes raw data from nine IMUs and thirty-five optical markers capturing full-body kinematics. Each IMU is additionally equipped with four optical markers, enabling precise comparison between IMU-derived orientation estimates and reference values from the MoCap system. To support further analysis, we also provide processed IMU orientations aligned with common segment coordinate systems, subject-specific OpenSim models, inverse kinematics results, and tools for visualizing IMU orientations in the musculoskeletal context. Detailed annotations of movement execution quality and time-stamped segmentations support diverse analysis goals. This dataset supports the development and benchmarking of machine learning models for tasks such as automatic exercise evaluation, gait analysis, temporal activity segmentation, and biomechanical parameter estimation. To facilitate reproducibility, we provide code for postprocessing, sensor-to-segment alignment, inverse kinematics computation, and technical validation. This resource is intended to accelerate research in machine learning-driven human movement analysis.', 'abstract_zh': '可穿戴惯性测量单元（IMU）为在临床和日常生活环境中评估人类运动质量提供了低成本且可扩展的方法。然而，为了开发适用于物理治疗锻炼和步态分析的稳健传感器基分类模型，需要收集大量多样化的数据集，而这在成本和时间上都极具挑战性。在此，我们呈现了一个包含物理治疗锻炼（包括正确的和临床相关的变体）和步态相关锻炼（包括正常和受损步态模式）的多模态数据集，这些数据集是在19名参与者同步使用惯性测量单元（IMU）和标记基动捕（MoCap）系统记录下来的。数据集包括九个IMU的原始数据和35个光学标记捕捉到的全身运动学。每个IMU还配备了四个光学标记，使得IMU获取的姿态估计值与基于MoCap系统的参考值之间能够进行精确比较。此外，我们还提供了与常用节段坐标系统对齐的IMU姿态、个体特定的OpenSim模型、逆运动学结果以及在运动学背景下可视化IMU姿态的工具。详细的运动执行质量标注和时间戳分割支持多样化的分析目标。该数据集支持自动锻炼评估、步态分析、时间活动分割和生物力学参数估计等机器学习模型的开发与基准测试。为了确保可再现性，我们提供了后处理代码、传感器到节段对齐、逆运动学计算以及技术验证的工具。该资源旨在推动基于机器学习的人类运动分析研究。', 'title_zh': 'GAITEX：基于惯性和光学传感器数据的异常步态及康复锻炼的人体动作数据集'}
{'arxiv_id': 'arXiv:2507.21060', 'title': 'Privacy-Preserving AI for Encrypted Medical Imaging: A Framework for Secure Diagnosis and Learning', 'authors': 'Abdullah Al Siam, Sadequzzaman Shohan', 'link': 'https://arxiv.org/abs/2507.21060', 'abstract': 'The rapid integration of Artificial Intelligence (AI) into medical diagnostics has raised pressing concerns about patient privacy, especially when sensitive imaging data must be transferred, stored, or processed. In this paper, we propose a novel framework for privacy-preserving diagnostic inference on encrypted medical images using a modified convolutional neural network (Masked-CNN) capable of operating on transformed or ciphered image formats. Our approach leverages AES-CBC encryption coupled with JPEG2000 compression to protect medical images while maintaining their suitability for AI inference. We evaluate the system using public DICOM datasets (NIH ChestX-ray14 and LIDC-IDRI), focusing on diagnostic accuracy, inference latency, storage efficiency, and privacy leakage resistance. Experimental results show that the encrypted inference model achieves performance comparable to its unencrypted counterpart, with only marginal trade-offs in accuracy and latency. The proposed framework bridges the gap between data privacy and clinical utility, offering a practical, scalable solution for secure AI-driven diagnostics.', 'abstract_zh': '人工智能在医疗诊断中的快速集成引发了对患者隐私的迫切关注，尤其是当需要传输、存储或处理敏感影像数据时。本文提出了一种新型框架，使用修改后的卷积神经网络（Masked-CNN）进行加密医疗影像的隐私保护诊断推理，该框架能够在变换或密文格式的影像上运行。我们的方法结合使用AES-CBC加密和JPEG2000压缩，以保护医疗影像同时保持其适用于AI推理的适用性。我们使用公开的DICOM数据集（NIH ChestX-ray14和LIDC-IDRI）进行系统评估，重点关注诊断准确性、推理延迟、存储效率和隐私泄露抵抗力。实验结果表明，加密推理模型在性能上与非加密版本相当，仅在准确性与延迟方面有微小的权衡。所提出的框架在数据隐私与临床应用之间架起了桥梁，提供了一种实用且可扩展的安全AI驱动诊断解决方案。', 'title_zh': '加密医疗影像的隐私保护AI框架：安全诊断与学习体系'}
{'arxiv_id': 'arXiv:2507.21058', 'title': 'Categorical Classification of Book Summaries Using Word Embedding Techniques', 'authors': 'Kerem Keskin, Mümine Kaya Keleş', 'link': 'https://arxiv.org/abs/2507.21058', 'abstract': 'In this study, book summaries and categories taken from book sites were classified using word embedding methods, natural language processing techniques and machine learning algorithms. In addition, one hot encoding, Word2Vec and Term Frequency - Inverse Document Frequency (TF-IDF) methods, which are frequently used word embedding methods were used in this study and their success was compared. Additionally, the combination table of the pre-processing methods used is shown and added to the table. Looking at the results, it was observed that Support Vector Machine, Naive Bayes and Logistic Regression Models and TF-IDF and One-Hot Encoder word embedding techniques gave more successful results for Turkish texts.', 'abstract_zh': '在本书研究中，来自书籍网站的书摘要和类别被使用词嵌入方法、自然语言处理技术和机器学习算法进行分类。此外，本研究中使用了一热编码、Word2Vec 和词频-逆文档频数（TF-IDF）等常用词嵌入方法，并对其成功率进行了比较。同时展示了所使用预处理方法的组合表。结果表明，支持向量机、朴素贝叶斯和支持回归模型以及 TF-IDF 和一热编码词嵌入技术在土耳其文本上取得了更成功的结果。', 'title_zh': '使用词嵌入技术对图书摘要进行分类学分类'}
{'arxiv_id': 'arXiv:2507.21056', 'title': 'AI-Driven Generation of Data Contracts in Modern Data Engineering Systems', 'authors': 'Harshraj Bhoite', 'link': 'https://arxiv.org/abs/2507.21056', 'abstract': 'Data contracts formalize agreements between data producers and consumers regarding schema, semantics, and quality expectations. As data pipelines grow in complexity, manual authoring and maintenance of contracts becomes error-prone and labor-intensive. We present an AI-driven framework for automatic data contract generation using large language models (LLMs). Our system leverages parameter-efficient fine-tuning methods, including LoRA and PEFT, to adapt LLMs to structured data domains. The models take sample data or schema descriptions and output validated contract definitions in formats such as JSON Schema and Avro. We integrate this framework into modern data platforms (e.g., Databricks, Snowflake) to automate contract enforcement at scale. Experimental results on synthetic and real-world datasets demonstrate that the fine-tuned LLMs achieve high accuracy in generating valid contracts and reduce manual workload by over 70%. We also discuss key challenges such as hallucination, version control, and the need for continuous learning. This work demonstrates that generative AI can enable scalable, agile data governance by bridging the gap between intent and implementation in enterprise data management.', 'abstract_zh': '基于大规模语言模型的自动数据合同生成框架', 'title_zh': '基于AI的数据合同生成在现代数据工程系统中的应用'}
{'arxiv_id': 'arXiv:2507.21055', 'title': 'Bridging the Gap: Enhancing News Interpretation Across Diverse Audiences with Large Language Models', 'authors': 'Leyi Ouyang', 'link': 'https://arxiv.org/abs/2507.21055', 'abstract': "In the interconnected world, news media are critical in conveying information to public across diverse domains including technology, finance, and agriculture. Journalists make efforts to present accurate information, however, the interpretation of news often varies significantly among different audiences due to their specific expertise and age. In this work, we investigate how to identify these comprehension gaps and provide solutions to improve audiences understanding of news content, particular to the aspects of articles outside their primary domains of knowledge. We propose a agent-based framework using large language models (LLMs) to simulate society communication behaviors, where several agents can discuss news. These agents can be designed to be experts from various occupation, or from different age group. Our results indicate that this framework can identify confusions or even misunderstanding of news for the agent through the iterative discussion process. Based on these accurate identification, the framework can design a supplement material specific to these agents on the news. Our results show that agents exhibit significantly improved news understanding after receiving this material. These findings highlight our framework's utility and efficiency in enhancing news comprehension for diverse audiences by directly addressing their understanding gap.", 'abstract_zh': '在互联世界中，新闻媒体在向涵盖科技、金融和农业等不同领域公众传递信息方面至关重要。记者努力呈现准确的信息，但由于不同受众的专业背景和年龄差异，新闻解释往往存在显著差异。本文研究如何识别这些理解和认知差距，并提出解决方案以提高受众对新闻内容的理解，特别是对于受众在其专业知识领域之外的文章内容理解。我们提出了一种基于代理的框架，利用大型语言模型（LLMs）模拟社会通信行为，多个代理可以讨论新闻。这些代理可以被设计为来自不同职业领域的专家，或来自不同年龄组的人。研究结果显示，通过迭代讨论过程，该框架能够识别代理在新闻理解上的困惑甚至误解。基于这些准确的识别，框架可以为这些代理设计特定的补充材料。研究表明，接收这些材料后，代理在新闻理解上显著提高。这些发现突显了该框架在通过直接解决受众理解差距来提高多元受众的新闻理解方面的作用和效率。', 'title_zh': '填补差距：利用大型语言模型增强跨多元化受众的新闻解读能力'}
{'arxiv_id': 'arXiv:2507.21054', 'title': 'High hopes for "Deep Medicine"? AI, economics, and the future of care', 'authors': 'Robert Sparrow, Joshua Hatherley', 'link': 'https://arxiv.org/abs/2507.21054', 'abstract': 'In the much-celebrated book Deep Medicine, Eric Topol argues that the development of artificial intelligence for health care will lead to a dramatic shift in the culture and practice of medicine. In the next several decades, he suggests, AI will become sophisticated enough that many of the everyday tasks of physicians could be delegated to it. Topol is perhaps the most articulate advocate of the benefits of AI in medicine, but he is hardly alone in spruiking its potential to allow physicians to dedicate more of their time and attention to providing empathetic care for their patients in the future. Unfortunately, several factors suggest a radically different picture for the future of health care. Far from facilitating a return to a time of closer doctor-patient relationships, the use of medical AI seems likely to further erode therapeutic relationships and threaten professional and patient satisfaction.', 'abstract_zh': '在备受赞誉的著作《深度医学》中，埃里克·托波尔 argue了人工智能在医疗领域的开发将导致医学文化与实践的重大转变。在未来几十年里，他建议，人工智能将变得足够先进，以至于许多医生的日常工作可以委托给它处理。托波尔可能是人工智能在医学领域最大声的支持者之一，但并非唯一一个认为人工智能可能使医生能够将更多时间和注意力集中在对患者的同理心护理上的倡导者。不幸的是，一些因素预示着医疗保健未来的急剧不同图景。实际上，医疗人工智能的使用似乎更有可能进一步削弱治疗关系，并威胁专业人员和患者的满意度。', 'title_zh': '“深 Medicine”的高期望？AI、经济学与照护的未来'}
{'arxiv_id': 'arXiv:2507.20894', 'title': 'Online hierarchical partitioning of the output space in extreme multi-label data stream', 'authors': 'Lara Neves, Afonso Lourenço, Alberto Cano, Goreti Marreiros', 'link': 'https://arxiv.org/abs/2507.20894', 'abstract': 'Mining data streams with multi-label outputs poses significant challenges due to evolving distributions, high-dimensional label spaces, sparse label occurrences, and complex label dependencies. Moreover, concept drift affects not only input distributions but also label correlations and imbalance ratios over time, complicating model adaptation. To address these challenges, structured learners are categorized into local and global methods. Local methods break down the task into simpler components, while global methods adapt the algorithm to the full output space, potentially yielding better predictions by exploiting label correlations. This work introduces iHOMER (Incremental Hierarchy Of Multi-label Classifiers), an online multi-label learning framework that incrementally partitions the label space into disjoint, correlated clusters without relying on predefined hierarchies. iHOMER leverages online divisive-agglomerative clustering based on \\textit{Jaccard} similarity and a global tree-based learner driven by a multivariate \\textit{Bernoulli} process to guide instance partitioning. To address non-stationarity, it integrates drift detection mechanisms at both global and local levels, enabling dynamic restructuring of label partitions and subtrees. Experiments across 23 real-world datasets show iHOMER outperforms 5 state-of-the-art global baselines, such as MLHAT, MLHT of Pruned Sets and iSOUPT, by 23\\%, and 12 local baselines, such as binary relevance transformations of kNN, EFDT, ARF, and ADWIN bagging/boosting ensembles, by 32\\%, establishing its robustness for online multi-label classification.', 'abstract_zh': 'Mining 多标签数据流中的结构化学习面临显著挑战，由于分布演变、高维标签空间、稀疏标签出现和复杂的标签依赖关系。此外，概念漂移不仅影响输入分布，还影响标签相关性和不平衡比率，增加了模型适应的复杂性。为应对这些挑战，结构化学习方法被划分为局部和全局方法。局部方法将任务分解为更简单的组件，而全局方法适应整个输出空间，可能通过利用标签相关性获得更好的预测。本研究提出了 iHOMER（增量多标签分类器层次结构），这是一种在线多标签学习框架，无需依赖预定义的层次结构，即可逐步将标签空间划分为互不相交且相关的聚类。iHOMER 利用基于 Jaccard 相似性的在线分裂-合并聚类，并通过基于多元伯努利过程的全局树型学习器指导实例划分。为应对非平稳性，它在全局和局部层面都集成了漂移检测机制，能够动态重新构建标签分区和子树。实验结果表明，iHOMER 在 23 个真实数据集上优于 5 个最先进的全局基线（如 MLHAT、Pruned Sets 的 MLHT 和 iSOUPT），性能高出 23%，并且在 12 个局部基线（如 kNN 的二元相关性转换、EFDT、ARF 和 ADWIN 袋装/提升集成）上表现高出 32%，证明了其在在线多标签分类中的 robustness。', 'title_zh': '极端多标签数据流中在线层次化输出空间分区'}
{'arxiv_id': 'arXiv:2507.17307', 'title': 'R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning', 'authors': 'Zhuokun Chen, Zeren Chen, Jiahao He, Mingkui Tan, Jianfei Cai, Bohan Zhuang', 'link': 'https://arxiv.org/abs/2507.17307', 'abstract': "Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of large language models by encouraging step-by-step intermediate reasoning during inference. While effective, CoT introduces substantial computational overhead due to its reliance on autoregressive decoding over long token sequences. Existing acceleration strategies either reduce sequence length through early stopping or compressive reward designs, or improve decoding speed via speculative decoding with smaller models. However, speculative decoding suffers from limited speedup when the agreement between small and large models is low, and fails to exploit the potential advantages of small models in producing concise intermediate reasoning. In this paper, we present R-Stitch, a token-level, confidence-based hybrid decoding framework that accelerates CoT inference by switching between a small language model (SLM) and a large language model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to generate tokens by default and delegates to the LLM only when the SLM's confidence falls below a threshold. This design avoids full-sequence rollback and selectively invokes the LLM on uncertain steps, preserving both efficiency and answer quality. R-Stitch is model-agnostic, training-free, and compatible with standard decoding pipelines. Experiments on math reasoning benchmarks demonstrate that R-Stitch achieves up to 85\\% reduction in inference latency with negligible accuracy drop, highlighting its practical effectiveness in accelerating CoT reasoning.", 'abstract_zh': '链式推理（CoT）推理通过在推理过程中鼓励逐步的中间推理来增强大型语言模型的问题解决能力。尽管有效，但CoT由于依赖于长序列自回归解码，引入了显著的计算开销。现有的加速策略要么通过提前停止缩短序列长度，要么通过压缩奖励设计，或者通过使用较小模型的推测性解码来提高解码速度。然而，推测性解码当小模型和大模型的共识较低时，所能带来的加速有限，不能充分利用小模型在生成简洁中间推理方面的潜在优势。本文提出了一种基于token级和置信度的混合解码框架R-Stitch，通过在推理轨迹上切换使用小语言模型（SLM）和大型语言模型（LLM）来加速CoT推理。R-Stitch在默认情况下由SLM生成token，并在SLM的置信度低于阈值时仅委托给LLM。这种设计避免了全序列回滚，并仅在不确定步骤上选择性地调用LLM，既保持了效率，又保证了答案质量。R-Stitch是模型无关的、无需训练的，并与标准解码流水线兼容。在数学推理基准测试上的实验表明，R-Stitch可以实现高达85%的推理延迟减少，同时几乎没有准确率下降，展示了其在加速CoT推理方面的实际有效性。', 'title_zh': 'R-Stitch: 动态轨迹缝合以实现高效推理'}
