{'arxiv_id': 'arXiv:2507.22042', 'title': 'A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics', 'authors': 'Ruturaj Sambhus, Kapi Ketan Mehta, Ali MirMohammad Sadeghi, Basit Muhammad Imran, Jeeseop Kim, Taizoon Chunawala, Vittorio Pastore, Sujith Vijayan, Kaveh Akbari Hamed', 'link': 'https://arxiv.org/abs/2507.22042', 'abstract': 'Model predictive control (MPC) combined with reduced-order template models has emerged as a powerful tool for trajectory optimization in dynamic legged locomotion. However, loco-manipulation tasks performed by legged robots introduce additional complexity, necessitating computationally efficient MPC algorithms capable of handling high-degree-of-freedom (DoF) models. This letter presents a computationally efficient nonlinear MPC (NMPC) framework tailored for loco-manipulation tasks of quadrupedal robots equipped with robotic manipulators whose dynamics are non-negligible relative to those of the quadruped. The proposed framework adopts a decomposition strategy that couples locomotion template models -- such as the single rigid body (SRB) model -- with a full-order dynamic model of the robotic manipulator for torque-level control. This decomposition enables efficient real-time solution of the NMPC problem in a receding horizon fashion at 60 Hz. The optimal state and input trajectories generated by the NMPC for locomotion are tracked by a low-level nonlinear whole-body controller (WBC) running at 500 Hz, while the optimal torque commands for the manipulator are directly applied. The layered control architecture is validated through extensive numerical simulations and hardware experiments on a 15-kg Unitree Go2 quadrupedal robot augmented with a 4.4-kg 4-DoF Kinova arm. Given that the Kinova arm dynamics are non-negligible relative to the Go2 base, the proposed NMPC framework demonstrates robust stability in performing diverse loco-manipulation tasks, effectively handling external disturbances, payload variations, and uneven terrain.', 'abstract_zh': '基于减少阶次模板模型的非线性模型预测控制框架在四足机器人携带操作任务中的应用', 'title_zh': '一种考虑非轻量 manipulator 动力学的四足机器人操作调控的非线性 MPC 框架'}
{'arxiv_id': 'arXiv:2507.21981', 'title': 'DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments', 'authors': 'Yufei Jia, Guangyu Wang, Yuhang Dong, Junzhe Wu, Yupei Zeng, Haonan Lin, Zifan Wang, Haizhou Ge, Weibin Gu, Kairui Ding, Zike Yan, Yunjie Cheng, Yue Li, Ziming Wang, Chuxuan Li, Wei Sui, Lu Shi, Guanzhong Tian, Ruqi Huang, Guyue Zhou', 'link': 'https://arxiv.org/abs/2507.21981', 'abstract': 'We present the first unified, modular, open-source 3DGS-based simulation framework for Real2Sim2Real robot learning. It features a holistic Real2Sim pipeline that synthesizes hyper-realistic geometry and appearance of complex real-world scenarios, paving the way for analyzing and bridging the Sim2Real gap. Powered by Gaussian Splatting and MuJoCo, Discoverse enables massively parallel simulation of multiple sensor modalities and accurate physics, with inclusive supports for existing 3D assets, robot models, and ROS plugins, empowering large-scale robot learning and complex robotic benchmarks. Through extensive experiments on imitation learning, Discoverse demonstrates state-of-the-art zero-shot Sim2Real transfer performance compared to existing simulators. For code and demos: this https URL.', 'abstract_zh': '我们提出了首个基于3DGS的一体化、模块化和开源的从真实到模拟再到真实的机器人学习仿真框架。该框架具备统合的从真实到模拟管道，合成复杂真实场景的超逼真几何和外观，为分析和弥合模拟到真实差距铺平了道路。得益于高斯点云计算和MuJoCo的支持，Discoverse能够大规模并行模拟多种传感器模态和精确的物理过程，并兼容现有的3D资产、机器人模型和ROS插件，助力大规模机器人学习和复杂机器人基准测试。通过在模仿学习上的广泛实验，Discoverse展示了与现有仿真器相比最先进的零样本模拟到真实转移性能。更多代码和演示，请访问：这个链接。', 'title_zh': 'DISCOVERSE: 在复杂高度保真环境中的高效机器人模拟'}
{'arxiv_id': 'arXiv:2507.21545', 'title': 'Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning', 'authors': 'Haoming Ye, Yunxiao Xiao, Cewu Lu, Panpan Cai', 'link': 'https://arxiv.org/abs/2507.21545', 'abstract': 'Robotic task planning in real-world environments requires reasoning over implicit constraints from language and vision. While LLMs and VLMs offer strong priors, they struggle with long-horizon structure and symbolic grounding. Existing methods that combine LLMs with symbolic planning often rely on handcrafted or narrow domains, limiting generalization. We propose UniDomain, a framework that pre-trains a PDDL domain from robot manipulation demonstrations and applies it for online robotic task planning. It extracts atomic domains from 12,393 manipulation videos to form a unified domain with 3137 operators, 2875 predicates, and 16481 causal edges. Given a target class of tasks, it retrieves relevant atomics from the unified domain and systematically fuses them into high-quality meta-domains to support compositional generalization in planning. Experiments on diverse real-world tasks show that UniDomain solves complex, unseen tasks in a zero-shot manner, achieving up to 58% higher task success and 160% improvement in plan optimality over state-of-the-art LLM and LLM-PDDL baselines.', 'abstract_zh': '在现实环境中的机器人任务规划需要对语言和视觉中的隐式约束进行推理。尽管大语言模型和视觉语言模型提供了强大的先验知识，但它们在长时间结构和符号接地方面存在困难。现有将大语言模型与符号规划结合的方法往往依赖于手工制作或窄域，限制了泛化能力。我们提出了UniDomain框架，该框架通过机器人 manipulation 示范预先训练一个PDDL领域，并将其应用于在线机器人任务规划。它从12,393个manipulation视频中提取出原子领域，形成一个统一领域，包含3137个操作符、2875个谓词和16481条因果边。给定一个目标任务类别，它从统一领域中检索相关的原子，并系统地将它们融合成高质量的元领域，以支持规划中的组合泛化。在多种实时任务实验中，UniDomain以零样本方式解决了复杂且未见过的任务，与最先进的大语言模型和大语言模型结合PDDL基线相比，任务成功率提高了58%，计划优化性提高了160%。', 'title_zh': '基于真实世界示范的统一PDDL领域预训练以实现可泛化机器人任务规划'}
{'arxiv_id': 'arXiv:2507.21517', 'title': 'LITE: A Learning-Integrated Topological Explorer for Multi-Floor Indoor Environments', 'authors': 'Junhao Chen, Zhen Zhang, Chengrui Zhu, Xiaojun Hou, Tianyang Hu, Huifeng Wu, Yong Liu', 'link': 'https://arxiv.org/abs/2507.21517', 'abstract': 'This work focuses on multi-floor indoor exploration, which remains an open area of research. Compared to traditional methods, recent learning-based explorers have demonstrated significant potential due to their robust environmental learning and modeling capabilities, but most are restricted to 2D environments. In this paper, we proposed a learning-integrated topological explorer, LITE, for multi-floor indoor environments. LITE decomposes the environment into a floor-stair topology, enabling seamless integration of learning or non-learning-based 2D exploration methods for 3D exploration. As we incrementally build floor-stair topology in exploration using YOLO11-based instance segmentation model, the agent can transition between floors through a finite state machine. Additionally, we implement an attention-based 2D exploration policy that utilizes an attention mechanism to capture spatial dependencies between different regions, thereby determining the next global goal for more efficient exploration. Extensive comparison and ablation studies conducted on the HM3D and MP3D datasets demonstrate that our proposed 2D exploration policy significantly outperforms all baseline explorers in terms of exploration efficiency. Furthermore, experiments in several 3D multi-floor environments indicate that our framework is compatible with various 2D exploration methods, facilitating effective multi-floor indoor exploration. Finally, we validate our method in the real world with a quadruped robot, highlighting its strong generalization capabilities.', 'abstract_zh': '本工作聚焦于多楼层室内探索，这是研究中的一个重要领域。与传统方法相比，近期的学习导向探索器由于其环境学习和建模能力的稳健性显示出巨大的发展潜力，但大多数仍局限于2D环境。在本文中，我们提出了一种集成学习的拓扑探索器LITE，用于多楼层室内环境。LITE将环境分解为楼层-楼梯拓扑结构，使得可以无缝集成基于学习或非学习的2D探索方法进行3D探索。在探索过程中，使用YOLO11基于实例分割模型增量构建楼层-楼梯拓扑结构，智能体可以通过有限状态机在楼层之间过渡。此外，我们实现了一种基于注意力机制的2D探索策略，利用注意力机制捕捉不同区域之间的空间依赖性，从而更有效地确定下一步的全局目标。在HM3D和MP3D数据集上的广泛比较和消融研究显示，我们提出的2D探索策略在探索效率上显著优于所有基线探索器。进一步的实验表明，我们的框架兼容各种2D探索方法，有利于有效进行多楼层室内探索。最后，我们在四足机器人上验证了该方法，突显了其强大的泛化能力。', 'title_zh': 'LITE: 一种集成学习的拓扑探索者，用于多层室内环境'}
{'arxiv_id': 'arXiv:2507.21496', 'title': 'Multifunctional physical reservoir computing in soft tensegrity robots', 'authors': 'Ryo Terajima, Katsuma Inoue, Kohei Nakajima, Yasuo Kuniyoshi', 'link': 'https://arxiv.org/abs/2507.21496', 'abstract': 'Recent studies have demonstrated that the dynamics of physical systems can be utilized for the desired information processing under the framework of physical reservoir computing (PRC). Robots with soft bodies are examples of such physical systems, and their nonlinear body-environment dynamics can be used to compute and generate the motor signals necessary for the control of their own behavior. In this simulation study, we extend this approach to control and embed not only one but also multiple behaviors into a type of soft robot called a tensegrity robot. The resulting system, consisting of the robot and the environment, is a multistable dynamical system that converges to different attractors from varying initial conditions. Furthermore, attractor analysis reveals that there exist "untrained attractors" in the state space of the system outside the training data. These untrained attractors reflect the intrinsic properties and structures of the tensegrity robot and its interactions with the environment. The impacts of these recent findings in PRC remain unexplored in embodied AI research. We here illustrate their potential to understand various features of embodied cognition that have not been fully addressed to date.', 'abstract_zh': '最近的研究表明，物理系统动态可以在物理蓄水库计算（PRC）框架下用于所需的信息处理。具有软体的机器人是这类物理系统的一个例子，它们的非线性身体-环境动力学可以用于计算和生成控制自身行为所需的运动信号。在本模拟研究中，我们将这种方法扩展到不仅控制，而且还嵌入多种行为到一类称为 tensegrity 机器人的软体机器人中。由此形成的系统，包括机器人和环境，在不同初始条件下的状态下会收敛到不同的吸引子。进一步的吸引子分析揭示，在系统的状态空间中存在“未训练的吸引子”，这些未训练的吸引子反映了 tensegrity 机器人的内在特性和其与环境的交互特性。这些近期发现对嵌入式AI研究的影响尚未被探索。在这里，我们展示了它们在理解到目前为止未充分解决的各种体现认知特性方面的潜在价值。', 'title_zh': '软 tensegrity 机器人中的多功能物理储桶计算'}
{'arxiv_id': 'arXiv:2507.21431', 'title': 'Sound Source Localization for Human-Robot Interaction in Outdoor Environments', 'authors': 'Victor Liu, Timothy Du, Jordy Sehn, Jack Collier, François Grondin', 'link': 'https://arxiv.org/abs/2507.21431', 'abstract': 'This paper presents a sound source localization strategy that relies on a microphone array embedded in an unmanned ground vehicle and an asynchronous close-talking microphone near the operator. A signal coarse alignment strategy is combined with a time-domain acoustic echo cancellation algorithm to estimate a time-frequency ideal ratio mask to isolate the target speech from interferences and environmental noise. This allows selective sound source localization, and provides the robot with the direction of arrival of sound from the active operator, which enables rich interaction in noisy scenarios. Results demonstrate an average angle error of 4 degrees and an accuracy within 5 degrees of 95\\% at a signal-to-noise ratio of 1dB, which is significantly superior to the state-of-the-art localization methods.', 'abstract_zh': '基于无人地面车辆内置麦克风阵列和操作员附近异步近讲麦克风的声源定位策略', 'title_zh': '户外环境中的声源定位与人类-机器人交互'}
{'arxiv_id': 'arXiv:2507.21384', 'title': 'Projecting the New Body: How Body Image Evolves During Learning to Walk with a Wearable Robot', 'authors': 'I-Chieh Lee, He Huang', 'link': 'https://arxiv.org/abs/2507.21384', 'abstract': 'Advances in wearable robotics challenge the traditional definition of human motor systems, as wearable robots redefine body structure, movement capability, and perception of their own bodies. We measured gait performance and perceived body images via Selected Coefficient of Perceived Motion, SCoMo, after each training session. Based on human motor learning theory extended to wearer-robot systems, we hypothesized that learning the perceived body image when walking with a robotic leg co-evolves with the actual gait improvement and becomes more certain and more accurate to the actual motion. Our result confirmed that motor learning improved both physical and perceived gait pattern towards normal, indicating that via practice the wearers incorporated the robotic leg into their sensorimotor systems to enable wearer-robot movement coordination. However, a persistent discrepancy between perceived and actual motion remained, likely due to the absence of direct sensation and control of the prosthesis from wearers. Additionally, the perceptual overestimation at the later training sessions might limit further motor improvement. These findings suggest that enhancing the human sense of wearable robots and frequent calibrating perception of body image are essential for effective training with lower limb wearable robots and for developing more embodied assistive technologies.', 'abstract_zh': '穿戴式机器人技术的进步挑战了传统的人体运动系统定义，穿戴式机器人重新定义了身体结构、运动能力和对自身身体的感知。我们在每次训练结束后通过选矿感知运动系数（SCoMo）测量了步态表现和感知的身体形象。基于扩展到穿戴者-机器人系统的运动学习理论，我们假设在使用假腿行走时感知身体形象的学习与实际步态改善同步进行，并且这种感知变得更加确定和准确。我们的结果显示，运动学习不仅改善了实际的步态模式，也向正常步态靠拢，表明穿戴者通过练习将假腿整合到其感觉运动系统中，以实现穿戴者-机器人运动协调。然而，感知与实际运动之间仍然存在持续的差异，这可能是由于穿戴者无法直接感受和控制假肢造成的。此外，后期训练中的感知过度估计可能限制进一步的运动改善。这些发现表明，增强对人体穿戴式机器人的感觉，并频繁校准对身体形象的感知，对于有效训练下肢穿戴式机器人和开发更多具身辅助技术至关重要。', 'title_zh': '投影新身体：穿戴式机器人学习行走过程中身体形象的变化'}
{'arxiv_id': 'arXiv:2507.21338', 'title': 'Autonomous Exploration with Terrestrial-Aerial Bimodal Vehicles', 'authors': 'Yuman Gao, Ruibin Zhang, Tiancheng Lai, Yanjun Cao, Chao Xu, Fei Gao', 'link': 'https://arxiv.org/abs/2507.21338', 'abstract': 'Terrestrial-aerial bimodal vehicles, which integrate the high mobility of aerial robots with the long endurance of ground robots, offer significant potential for autonomous exploration. Given the inherent energy and time constraints in practical exploration tasks, we present a hierarchical framework for the bimodal vehicle to utilize its flexible locomotion modalities for exploration. Beginning with extracting environmental information to identify informative regions, we generate a set of potential bimodal viewpoints. To adaptively manage energy and time constraints, we introduce an extended Monte Carlo Tree Search approach that strategically optimizes both modality selection and viewpoint sequencing. Combined with an improved bimodal vehicle motion planner, we present a complete bimodal energy- and time-aware exploration system. Extensive simulations and deployment on a customized real-world platform demonstrate the effectiveness of our system.', 'abstract_zh': '集成空中和地面模态的双模移动平台通过结合空中机器人的高移动性和地面机器人的长续航能力，为自主探索提供了巨大的潜力。鉴于实际探索任务中固有的能量和时间限制，我们提出了一种层次框架，以利用双模平台的灵活移动模态进行探索。该框架始于提取环境信息以识别信息丰富的区域，并生成一组潜在的双模视点。为适应性管理能量和时间约束，我们引入了一种扩展的蒙特卡洛树搜索方法，战略性地优化模态选择和视点序列。结合改进的双模平台运动规划器，我们提出了一种完整的双模能量和时间感知探索系统。广泛的仿真实验和在定制的实际平台上的部署证明了该系统的有效性。', 'title_zh': '地面-航空双模车辆自主探索'}
{'arxiv_id': 'arXiv:2507.22028', 'title': 'From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning', 'authors': 'Honglin He, Yukai Ma, Wayne Wu, Bolei Zhou', 'link': 'https://arxiv.org/abs/2507.22028', 'abstract': "Navigation foundation models trained on massive webscale data enable agents to generalize across diverse environments and embodiments. However, these models trained solely on offline data, often lack the capacity to reason about the consequences of their actions or adapt through counterfactual understanding. They thus face significant limitations in the real-world urban navigation where interactive and safe behaviors, such as avoiding obstacles and moving pedestrians, are critical. To tackle these challenges, we introduce the Seeing-to-Experiencing framework to scale the capability of navigation foundation models with reinforcement learning. S2E combines the strengths of pre-training on videos and post-training through RL. It maintains the generalizability acquired from large-scale real-world videos while enhancing its interactivity through RL in simulation environments. Specifically, we introduce two innovations: an Anchor-Guided Distribution Matching strategy, which stabilizes learning and models diverse motion patterns through anchor-based supervision; and a Residual-Attention Module, which obtains reactive behaviors from simulation environments without erasing the model's pretrained knowledge. Moreover, we establish a comprehensive end-to-end evaluation benchmark, NavBench-GS, built on photorealistic 3DGS reconstructions of real-world scenes that incorporate physical interactions. It can systematically assess the generalizability and safety of navigation foundation models. Extensive experiments show that S2E mitigates the diminishing returns often seen when scaling with offline data alone. We perform a thorough analysis of the benefits of Reinforcement Learning compared to Supervised Fine-Tuning in the context of post-training for robot learning. Our findings emphasize the crucial role of integrating interactive online experiences to effectively scale foundation models in Robotics.", 'abstract_zh': '大规模网络数据训练的导航基础模型能够使代理在多种环境和体态中泛化。然而，这些仅基于离线数据训练的模型往往缺乏推理其行为后果或通过反事实理解进行适应的能力。因此，在需要交互性和安全性的实际城市导航场景中，它们面临着重大限制。为应对这些挑战，我们引入了Seeing-to-Experiencing (S2E)框架，利用强化学习扩大导航基础模型的能力。S2E结合了视频预训练和通过模拟环境中的强化学习后训练的优点，维持了从大规模真实世界视频中获得的泛化能力，同时通过强化学习增强了其交互性。特别是，我们提出了两种创新：基于锚点的分布匹配策略，通过基于锚点的监督稳定学习并建模多样化的运动模式；以及残差注意力模块，从模拟环境中获取反应性行为而不抹去模型的预训练知识。此外，我们建立了一个全面的端到端评估基准NavBench-GS，基于真实场景的物理交互的逼真3D重建。它可以系统地评估导航基础模型的泛化能力和安全性。大量实验表明，S2E克服了仅通过离线数据扩展时通常出现的收益递减现象。我们详细分析了在机器人学习后训练情境下，强化学习相较于监督微调的优势。研究发现强调了在机器人学中整合交互式在线体验对有效扩展基础模型的至关重要性。', 'title_zh': '从观察到体验：通过强化学习扩展导航基础模型'}
{'arxiv_id': 'arXiv:2507.21638', 'title': 'Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics', 'authors': 'Leonard Hinckeldey, Elliot Fosong, Elle Miller, Rimvydas Rubavicius, Trevor McInroe, Patricia Wollstadt, Christiane B. Wiebel-Herboth, Subramanian Ramamoorthy, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2507.21638', 'abstract': "The development of reinforcement learning (RL) algorithms has been largely driven by ambitious challenge tasks and benchmarks. Games have dominated RL benchmarks because they present relevant challenges, are inexpensive to run and easy to understand. While games such as Go and Atari have led to many breakthroughs, they often do not directly translate to real-world embodied applications. In recognising the need to diversify RL benchmarks and addressing complexities that arise in embodied interaction scenarios, we introduce Assistax: an open-source benchmark designed to address challenges arising in assistive robotics tasks. Assistax uses JAX's hardware acceleration for significant speed-ups for learning in physics-based simulations. In terms of open-loop wall-clock time, Assistax runs up to $370\\times$ faster when vectorising training runs compared to CPU-based alternatives. Assistax conceptualises the interaction between an assistive robot and an active human patient using multi-agent RL to train a population of diverse partner agents against which an embodied robotic agent's zero-shot coordination capabilities can be tested. Extensive evaluation and hyperparameter tuning for popular continuous control RL and MARL algorithms provide reliable baselines and establish Assistax as a practical benchmark for advancing RL research for assistive robotics. The code is available at: this https URL.", 'abstract_zh': '强化学习算法的发展主要受到雄心勃勃的挑战任务和基准测试的推动。由于游戏能够提供相关的挑战、运行成本低且易于理解，因此一直在强化学习基准测试中占据主导地位。尽管如围棋和_atari_等游戏取得了许多突破，但它们往往不能直接应用于实际的生活类交互场景。为了满足对多样化强化学习基准测试的需求，并应对生活中交互场景中出现的复杂性，我们引入了Assistax：一个开源基准测试，旨在解决助手法学任务中出现的挑战。Assistax利用JAX的硬件加速技术，在基于物理的模拟学习中显著提高速度。与基于CPU的替代方案相比，Assistax在向量化的训练运行中可以快至370倍的开放环墙钟时间。Assistax通过多智能体强化学习的概念化，将辅助机器人与积极的人类患者之间的交互进行建模，训练出一系列多样化的伙伴智能体，以测试有身体的机器人智能体的零样本协调能力。广泛评估和针对流行的连续控制强化学习及多智能体强化学习算法的超参数调整为研究提供了可靠的基准，并确立了Assistax作为推进助手法学研究的实用基准的地位。代码可在以下链接获取：this https URL。', 'title_zh': 'Assistax：面向辅助机器人的硬件加速强化学习基准评测'}
{'arxiv_id': 'arXiv:2507.21450', 'title': 'Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation', 'authors': 'Bolei Chen, Jiaxu Kang, Yifei Wang, Ping Zhong, Qi Wu, Jianxin Wang', 'link': 'https://arxiv.org/abs/2507.21450', 'abstract': 'Vision Language Navigation (VLN) typically requires agents to navigate to specified objects or remote regions in unknown scenes by obeying linguistic commands. Such tasks require organizing historical visual observations for linguistic grounding, which is critical for long-sequence navigational decisions. However, current agents suffer from overly detailed scene representation and ambiguous vision-language alignment, which weaken their comprehension of navigation-friendly high-level scene priors and easily lead to behaviors that violate linguistic commands. To tackle these issues, we propose a navigation policy by recursively summarizing along-the-way visual perceptions, which are adaptively aligned with commands to enhance linguistic grounding. In particular, by structurally modeling historical trajectories as compact neural grids, several Recursive Visual Imagination (RVI) techniques are proposed to motivate agents to focus on the regularity of visual transitions and semantic scene layouts, instead of dealing with misleading geometric details. Then, an Adaptive Linguistic Grounding (ALG) technique is proposed to align the learned situational memories with different linguistic components purposefully. Such fine-grained semantic matching facilitates the accurate anticipation of navigation actions and progress. Our navigation policy outperforms the state-of-the-art methods on the challenging VLN-CE and ObjectNav tasks, showing the superiority of our RVI and ALG techniques for VLN.', 'abstract_zh': '视觉语言导航（VLN）通常要求代理遵循语言指令，在未知场景中导航至指定物体或远程区域。此类任务需要组织历史视觉观察以实现语言接地，这对于长序列导航决策至关重要。然而，当前代理存在场景表示过于详细和视觉-语言对齐含糊的问题，这削弱了它们对导航友好的高级场景先验的理解，并容易导致违反语言指令的行为。为解决这些问题，我们提出了一种通过递归总结沿途视觉感知的导航策略，这些感知会自适应地与指令对齐以增强语言接地。特别地，通过结构化建模历史轨迹为紧凑的神经网格，我们提出了几种递归视觉想象（RVI）技术，促使代理关注视觉过渡的规律性和语义场景布局，而非处理误导性的几何细节。然后，我们提出了一种自适应语言接地（ALG）技术，旨在有目的地将学习到的场景记忆与不同的语言组件对齐。这种精细的语义匹配促进了对导航动作和进展的准确预测。我们的导航策略在具有挑战性的VLN-CE和ObjectNav任务中优于现有方法，展示了我们RVI和ALG技术在VLN中的优越性。', 'title_zh': '递归视觉想象与自适应语言接地在视觉语言导航中的应用'}
{'arxiv_id': 'arXiv:2507.21964', 'title': 'Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities', 'authors': 'Sourish Gunesh Dhekane, Thomas Ploetz', 'link': 'https://arxiv.org/abs/2507.21964', 'abstract': "Developing zero-shot human activity recognition (HAR) methods is a critical direction in smart home research -- considering its impact on making HAR systems work across smart homes having diverse sensing modalities, layouts, and activities of interest. The state-of-the-art solutions along this direction are based on generating natural language descriptions of the sensor data and feeding it via a carefully crafted prompt to the LLM to perform classification. Despite their performance guarantees, such ``prompt-the-LLM'' approaches carry several risks, including privacy invasion, reliance on an external service, and inconsistent predictions due to version changes, making a case for alternative zero-shot HAR methods that do not require prompting the LLMs. In this paper, we propose one such solution that models sensor data and activities using natural language, leveraging its embeddings to perform zero-shot classification and thereby bypassing the need to prompt the LLMs for activity predictions. The impact of our work lies in presenting a detailed case study on six datasets, highlighting how language modeling can bolster HAR systems in zero-shot recognition.", 'abstract_zh': '开发零样本人类活动识别方法是智能家居研究的一个关键方向——考虑其对跨具有不同传感模态、布局和兴趣活动的智能家居系统工作的影响。当前这一方向上的先进解决方案基于生成传感器数据的自然语言描述，并通过精心构造的提示将这些描述传递给大型语言模型以执行分类。尽管这些方法有一定的性能保证，但诸如“提示大型语言模型”的方法仍存在隐私泄露、依赖外部服务及因版本变化导致预测不一致等风险，因此需要寻找不需要提示大型语言模型的零样本人类活动识别方法。在本文中，我们提出了一种解决方案，通过自然语言建模传感器数据和活动，并利用其嵌入进行零样本分类，从而避免了为活动预测而提示大型语言模型的需要。我们的工作影响在于对六个数据集进行了详细的案例研究，展示了语言建模如何增强零样本识别中的智能家居系统。', 'title_zh': '不得提示：通过传感器数据和活动的语言建模在智能家居中实现零样本人体活动识别'}
{'arxiv_id': 'arXiv:2507.21823', 'title': 'An Agentic AI for a New Paradigm in Business Process Development', 'authors': 'Mohammad Azarijafari, Luisa Mich, Michele Missikoff', 'link': 'https://arxiv.org/abs/2507.21823', 'abstract': 'Artificial Intelligence agents represent the next major revolution in the continuous technological evolution of industrial automation. In this paper, we introduce a new approach for business process design and development that leverages the capabilities of Agentic AI. Departing from the traditional task-based approach to business process design, we propose an agent-based method, where agents contribute to the achievement of business goals, identified by a set of business objects. When a single agent cannot fulfill a goal, we have a merge goal that can be achieved through the collaboration of multiple agents. The proposed model leads to a more modular and intelligent business process development by organizing it around goals, objects, and agents. As a result, this approach enables flexible and context-aware automation in dynamic industrial environments.', 'abstract_zh': '人工 intelligence 剂量代表了工业自动化连续技术进化中的下一重大革命。本文介绍了一种新的业务流程设计与开发方法，利用了 Agentic AI 的能力。不同于传统的基于任务的业务流程设计方法，我们提出了一种基于代理的方法，其中代理通过一组业务对象来实现业务目标。当单个代理无法完成目标时，我们将目标合并，通过多个代理的合作来实现。所提出的模型通过围绕目标、对象和代理组织业务流程开发，实现了更模块化和智能的业务流程开发。结果，这种方法在动态工业环境中实现了灵活和情境aware 的自动化。', 'title_zh': '代理型AI：商业流程开发新范式的基石'}
{'arxiv_id': 'arXiv:2507.21637', 'title': 'Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models', 'authors': 'Wanying Wang, Zeyu Ma, Han Zheng, Xin Tan, Mingang Chen', 'link': 'https://arxiv.org/abs/2507.21637', 'abstract': "Large vision-language models (LVLMs) are vulnerable to harmful input compared to their language-only backbones. We investigated this vulnerability by exploring LVLMs internal dynamics, framing their inherent safety understanding in terms of three key capabilities. Specifically, we define these capabilities as safety perception, semantic understanding, and alignment for linguistic expression, and experimentally pinpointed their primary locations within the model architecture. The results indicate that safety perception often emerges before comprehensive semantic understanding, leading to the reduction in safety. Motivated by these findings, we propose \\textbf{Self-Aware Safety Augmentation (SASA)}, a technique that projects informative semantic representations from intermediate layers onto earlier safety-oriented layers. This approach leverages the model's inherent semantic understanding to enhance safety recognition without fine-tuning. Then, we employ linear probing to articulate the model's internal semantic comprehension to detect the risk before the generation process. Extensive experiments on various datasets and tasks demonstrate that SASA significantly improves the safety of LVLMs, with minimal impact on the utility.", 'abstract_zh': 'Large 视觉-语言 模型 (LVLMs) 对有害输入的脆弱性高于其仅语言的骨干模型。我们通过探索 LVLMs 内部动力学，从三个关键能力的角度框架其内在的安全理解。具体地，我们将这些能力定义为安全感知、语义理解以及语言表达的对齐，并实验性地确定了它们在模型架构中的主要位置。结果显示，安全感知往往在全面的语义理解之前出现，从而导致安全性的降低。受此发现的启发，我们提出了一种名为 **自我感知安全增强 (Self-Aware Safety Augmentation, SASA)** 的技术，该技术将中间层的信息语义表示投影到早期的安全导向层。该方法利用模型固有的语义理解来增强安全性识别，而无需微调。然后，我们使用线性探测来表达模型内部的语义理解，以在生成过程之前检测风险。在多种数据集和任务上的广泛实验表明，SASA 显著提高了 LVLMs 的安全性，且对其实用性的影响较小。', 'title_zh': '自我意识安全性增强：利用内部语义理解提高视觉语言模型的安全性'}
{'arxiv_id': 'arXiv:2507.21589', 'title': 'Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems', 'authors': 'Bin Liu', 'link': 'https://arxiv.org/abs/2507.21589', 'abstract': 'Embodied intelligence posits that cognitive capabilities fundamentally emerge from - and are shaped by - an agent\'s real-time sensorimotor interactions with its environment. Such adaptive behavior inherently requires continuous inference under uncertainty. Bayesian statistics offers a principled probabilistic framework to address this challenge by representing knowledge as probability distributions and updating beliefs in response to new evidence. The core computational processes underlying embodied intelligence - including perception, action selection, learning, and even higher-level cognition - can be effectively understood and modeled as forms of Bayesian inference. Despite the deep conceptual connection between Bayesian statistics and embodied intelligence, Bayesian principles have not been widely or explicitly applied in today\'s embodied intelligence systems. In this work, we examine both Bayesian and contemporary embodied intelligence approaches through two fundamental lenses: search and learning - the two central themes in modern AI, as highlighted in Rich Sutton\'s influential essay "The Bitter Lesson". This analysis sheds light on why Bayesian inference has not played a central role in the development of modern embodied intelligence. At the same time, it reveals that current embodied intelligence systems remain largely confined to closed-physical-world environments, and highlights the potential for Bayesian methods to play a key role in extending these systems toward truly open physical-world embodied intelligence.', 'abstract_zh': '本体智能认为认知能力从根本上源自于并由智能体与环境实时传感器运动交互所塑造。这种适应性行为本质上要求在不确定性下进行持续推断。贝叶斯统计提供了一个原理性的概率框架来应对这一挑战，通过将知识表示为概率分布并在新证据面前更新信念。本体智能的核心计算过程——包括感知、动作选择、学习，甚至高层次认知——可以有效被理解为多种形式的贝叶斯推断。尽管贝叶斯统计与本体智能之间存在深刻的概念联系，但贝叶斯原则至今并未在当今的本体智能系统中广泛或明确地应用。在本工作中，我们通过两个基本视角——搜索与学习——分析贝叶斯方法和现代本体智能方法，这两个主题是Rich Sutton影响深远的文章《苦涩的教训》中强调的现代人工智能的核心。这一分析揭示了为什么贝叶斯推断尚未在现代本体智能的发展中扮演核心角色。同时，它还显示当前的本体智能系统主要局限于封闭的物理环境，强调了贝叶斯方法在扩展这些系统以实现真正开放物理世界的本体智能方面的潜在作用。', 'title_zh': '探索贝叶斯推断与体化智能之间的联系：通往开放物理世界体化AI系统的道路'}
{'arxiv_id': 'arXiv:2507.21513', 'title': 'What Does it Mean for a Neural Network to Learn a "World Model"?', 'authors': 'Kenneth Li, Fernanda Viégas, Martin Wattenberg', 'link': 'https://arxiv.org/abs/2507.21513', 'abstract': 'We propose a set of precise criteria for saying a neural net learns and uses a "world model." The goal is to give an operational meaning to terms that are often used informally, in order to provide a common language for experimental investigation. We focus specifically on the idea of representing a latent "state space" of the world, leaving modeling the effect of actions to future work. Our definition is based on ideas from the linear probing literature, and formalizes the notion of a computation that factors through a representation of the data generation process. An essential addition to the definition is a set of conditions to check that such a "world model" is not a trivial consequence of the neural net\'s data or task.', 'abstract_zh': '我们提出了一套精确的标准，用于判断神经网络是否学习并使用了一个“世界模型”。目标是为常被非正式使用的术语赋予操作性含义，以便为实验调查提供一种共同的语言。我们特别关注世界潜在“状态空间”的表示想法，将动作效果的建模留作未来工作。我们的定义基于线性探查文献中的想法，并正式化了通过数据生成过程表示的计算概念。定义中的一个关键补充是一系列条件，用于检查这种“世界模型”是否仅仅是神经网络数据或任务的 trivial 结果。', 'title_zh': '神经网络学习“世界模型”意味着什么？'}
{'arxiv_id': 'arXiv:2507.21206', 'title': 'Agentic Web: Weaving the Next Web with AI Agents', 'authors': 'Yingxuan Yang, Mulei Ma, Yuxuan Huang, Huacan Chai, Chenyu Gong, Haoran Geng, Yuanjian Zhou, Ying Wen, Meng Fang, Muhao Chen, Shangding Gu, Ming Jin, Costas Spanos, Yang Yang, Pieter Abbeel, Dawn Song, Weinan Zhang, Jun Wang', 'link': 'https://arxiv.org/abs/2507.21206', 'abstract': 'The emergence of AI agents powered by large language models (LLMs) marks a pivotal shift toward the Agentic Web, a new phase of the internet defined by autonomous, goal-driven interactions. In this paradigm, agents interact directly with one another to plan, coordinate, and execute complex tasks on behalf of users. This transition from human-driven to machine-to-machine interaction allows intent to be delegated, relieving users from routine digital operations and enabling a more interactive, automated web experience. In this paper, we present a structured framework for understanding and building the Agentic Web. We trace its evolution from the PC and Mobile Web eras and identify the core technological foundations that support this shift. Central to our framework is a conceptual model consisting of three key dimensions: intelligence, interaction, and economics. These dimensions collectively enable the capabilities of AI agents, such as retrieval, recommendation, planning, and collaboration. We analyze the architectural and infrastructural challenges involved in creating scalable agentic systems, including communication protocols, orchestration strategies, and emerging paradigms such as the Agent Attention Economy. We conclude by discussing the potential applications, societal risks, and governance issues posed by agentic systems, and outline research directions for developing open, secure, and intelligent ecosystems shaped by both human intent and autonomous agent behavior. A continuously updated collection of relevant studies for agentic web is available at: this https URL.', 'abstract_zh': '大型语言模型驱动的AI代理的出现标志着向能动互联网的转折点，这一新阶段的互联网由自主的目标驱动交互定义。在这种范式中，代理直接与彼此交互，计划、协调并代表用户执行复杂的任务。从人力驱动到机器间交互的转变使用户能够将意图委托给AI代理，从而减轻用户处理常规数字操作的负担，并提供更交互式和自动化的网络体验。在本文中，我们提出了一个结构化的框架，用于理解和构建能动互联网。我们追踪其从个人计算机和移动互联网时代的演变，并确定支持这一转变的核心技术基础。在我们框架的核心是一个概念模型，包含三个关键维度：智能、互动和经济。这些维度共同赋予AI代理检索、推荐、规划和协作的能力。我们分析了构建可扩展的能动系统所涉及的架构和基础设施挑战，包括通信协议、编排策略以及正在兴起的如代理注意力经济等概念。最后，我们讨论了能动系统可能带来的应用、社会风险和治理问题，并概述了研发开放、安全和智能生态系统的研究方向，该生态由人类意图和自主代理行为共同塑造。相关研究的持续更新列表可访问：this https URL。', 'title_zh': '代理网格：用AI代理编织下一个网络'}
{'arxiv_id': 'arXiv:2507.22020', 'title': 'XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation', 'authors': 'Raju Ningappa Mulawade, Christoph Garth, Alexander Wiebel', 'link': 'https://arxiv.org/abs/2507.22020', 'abstract': 'We propose a novel segmentation-based explainable artificial intelligence (XAI) method for neural networks working on point cloud classification. As one building block of this method, we propose a novel point-shifting mechanism to introduce perturbations in point cloud data. Recently, AI has seen an exponential growth. Hence, it is important to understand the decision-making process of AI algorithms when they are applied in critical areas. Our work focuses on explaining AI algorithms that classify point cloud data. An important aspect of the methods used for explaining AI algorithms is their ability to produce explanations that are easy for humans to understand. This allows them to analyze the AI algorithms better and make appropriate decisions based on that analysis. Therefore, in this work, we intend to generate meaningful explanations that can be easily interpreted by humans. The point cloud data we consider represents 3D objects such as cars, guitars, and laptops. We make use of point cloud segmentation models to generate explanations for the working of classification models. The segments are used to introduce perturbations into the input point cloud data and generate saliency maps. The perturbations are introduced using the novel point-shifting mechanism proposed in this work which ensures that the shifted points no longer influence the output of the classification algorithm. In contrast to previous methods, the segments used by our method are meaningful, i.e. humans can easily interpret the meaning of the segments. Thus, the benefit of our method over other methods is its ability to produce more meaningful saliency maps. We compare our method with the use of classical clustering algorithms to generate explanations. We also analyze the saliency maps generated for example inputs using our method to demonstrate the usefulness of the method in generating meaningful explanations.', 'abstract_zh': '一种基于分割的可解释人工智能方法：点云分类神经网络中的可解释性人工智能方法', 'title_zh': '基于有意义分割的扰动解释可点云数据的方法'}
{'arxiv_id': 'arXiv:2507.22010', 'title': 'Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform', 'authors': 'Justin Curry, Brennan Lagasse, Ngoc B. Lam, Gregory Cox, David Rosenbluth, Alberto Speranzon', 'link': 'https://arxiv.org/abs/2507.22010', 'abstract': 'In this work, we explore the structure of the embedding space of a transformer model trained for playing a particular reinforcement learning (RL) game. Specifically, we investigate how a transformer-based Proximal Policy Optimization (PPO) model embeds visual inputs in a simple environment where an agent must collect "coins" while avoiding dynamic obstacles consisting of "spotlights." By adapting Robinson et al.\'s study of the volume growth transform for LLMs to the RL setting, we find that the token embedding space for our visual coin collecting game is also not a manifold, and is better modeled as a stratified space, where local dimension can vary from point to point. We further strengthen Robinson\'s method by proving that fairly general volume growth curves can be realized by stratified spaces. Finally, we carry out an analysis that suggests that as an RL agent acts, its latent representation alternates between periods of low local dimension, while following a fixed sub-strategy, and bursts of high local dimension, where the agent achieves a sub-goal (e.g., collecting an object) or where the environmental complexity increases (e.g., more obstacles appear). Consequently, our work suggests that the distribution of dimensions in a stratified latent space may provide a new geometric indicator of complexity for RL games.', 'abstract_zh': '本研究探究了用于玩特定强化学习（RL）游戏的变压器模型的嵌入空间结构。具体而言，我们调查了基于变压器的近端策略优化（PPO）模型如何在代理必须收集“硬币”并避免“聚光灯”动态障碍的简单环境中嵌入视觉输入。通过将Robinson等人对大型语言模型（LLM）的体积增长变换研究适应到RL环境中，我们发现我们视觉硬币收集游戏的标记嵌入空间也不是流形，而更适合用层化空间模型，其中局部维度可以在不同点上变化。我们进一步改进了Robinson的方法，证明了相当一般的体积增长曲线可以由层化空间实现。最后，我们进行的分析表明，随着RL代理采取行动，其潜在表示在遵循固定子策略的长时间低局部维度时期与代理实现子目标（例如，收集物体）或环境复杂度增加（例如，出现更多障碍物）的高局部维度爆发期之间交替。因此，我们的研究建议，层化潜在空间中维度的分布可能为RL游戏提供一种新的几何复杂性指标。', 'title_zh': '探索RL游戏的分层空间结构的体积增长变换方法'}
{'arxiv_id': 'arXiv:2507.21953', 'title': 'MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation', 'authors': 'Yi Kong, Dianxi Shi, Guoli Yang, Zhang ke-di, Chenlin Huang, Xiaopeng Li, Songchang Jin', 'link': 'https://arxiv.org/abs/2507.21953', 'abstract': 'The recent advancement of autonomous agents powered by Large Language Models (LLMs) has demonstrated significant potential for automating tasks on mobile devices through graphical user interfaces (GUIs). Despite initial progress, these agents still face challenges when handling complex real-world tasks. These challenges arise from a lack of knowledge about real-life mobile applications in LLM-based agents, which may lead to ineffective task planning and even cause hallucinations. To address these challenges, we propose a novel LLM-based agent framework called MapAgent that leverages memory constructed from historical trajectories to augment current task planning. Specifically, we first propose a trajectory-based memory mechanism that transforms task execution trajectories into a reusable and structured page-memory database. Each page within a trajectory is extracted as a compact yet comprehensive snapshot, capturing both its UI layout and functional context. Secondly, we introduce a coarse-to-fine task planning approach that retrieves relevant pages from the memory database based on similarity and injects them into the LLM planner to compensate for potential deficiencies in understanding real-world app scenarios, thereby achieving more informed and context-aware task planning. Finally, planned tasks are transformed into executable actions through a task executor supported by a dual-LLM architecture, ensuring effective tracking of task progress. Experimental results in real-world scenarios demonstrate that MapAgent achieves superior performance to existing methods. The code will be open-sourced to support further research.', 'abstract_zh': '基于大型语言模型的自主代理 recent 进展：通过图形用户界面在移动设备上自动执行任务的新框架', 'title_zh': 'MapAgent: 基于轨迹构建的增强记忆规划mobile任务自动化'}
{'arxiv_id': 'arXiv:2507.21796', 'title': 'MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects', 'authors': 'Yuying Zhang, Kevin Sebastian Luck, Francesco Verdoja, Ville Kyrki, Joni Pajarinen', 'link': 'https://arxiv.org/abs/2507.21796', 'abstract': "Mobile manipulation is a critical capability for robots operating in diverse, real-world environments. However, manipulating deformable objects and materials remains a major challenge for existing robot learning algorithms. While various benchmarks have been proposed to evaluate manipulation strategies with rigid objects, there is still a notable lack of standardized benchmarks that address mobile manipulation tasks involving deformable objects.\nTo address this gap, we introduce MoDeSuite, the first Mobile Manipulation Deformable Object task suite, designed specifically for robot learning. MoDeSuite consists of eight distinct mobile manipulation tasks covering both elastic objects and deformable objects, each presenting a unique challenge inspired by real-world robot applications. Success in these tasks requires effective collaboration between the robot's base and manipulator, as well as the ability to exploit the deformability of the objects. To evaluate and demonstrate the use of the proposed benchmark, we train two state-of-the-art reinforcement learning algorithms and two imitation learning algorithms, highlighting the difficulties encountered and showing their performance in simulation. Furthermore, we demonstrate the practical relevance of the suite by deploying the trained policies directly into the real world with the Spot robot, showcasing the potential for sim-to-real transfer. We expect that MoDeSuite will open a novel research domain in mobile manipulation involving deformable objects. Find more details, code, and videos at this https URL.", 'abstract_zh': '移动操作是机器人在多样化真实环境作业的关键能力。然而，操纵变形物体和材料仍然是现有机器人学习算法的主要挑战。尽管提出了各种基准来评估使用刚性物体的操纵策略，但在涉及变形物体的移动操纵任务上仍然缺乏标准化基准。\n为解决这一缺口，我们引入了MoDeSuite，这是首个专门用于机器人学习的移动操纵变形物体任务套件。MoDeSuite 包含八个不同的移动操纵任务，涵盖了弹性物体和变形物体，每个任务都提出了源自实际机器人应用的独特挑战。任务的成功要求机器人基座与操作机构之间有效的协作，以及利用物体变形性的能力。为了评估和展示所提出的基准的使用，我们训练了两个最先进的强化学习算法和两个模仿学习算法，并强调了遇到的困难，展示了它们在模拟中的性能。此外，通过直接将训练策略部署到Spot机器人中，我们展示了套件的实际相关性，展示了从仿真到现实的过渡潜力。我们期望MoDeSuite 将开启移动操纵中涉及变形物体的新研究领域。更多细节、代码和视频请参见 <https://this-url>。', 'title_zh': 'MoDeSuite：用于柔体对象移动操作基准测试的机器人学习任务套件'}
