{'arxiv_id': 'arXiv:2503.03707', 'title': 'Curating Demonstrations using Online Experience', 'authors': 'Annie S. Chen, Alec M. Lessing, Yuejiang Liu, Chelsea Finn', 'link': 'https://arxiv.org/abs/2503.03707', 'abstract': 'Many robot demonstration datasets contain heterogeneous demonstrations of varying quality. This heterogeneity may benefit policy pre-training, but can hinder robot performance when used with a final imitation learning objective. In particular, some strategies in the data may be less reliable than others or may be underrepresented in the data, leading to poor performance when such strategies are sampled at test time. Moreover, such unreliable or underrepresented strategies can be difficult even for people to discern, and sifting through demonstration datasets is time-consuming and costly. On the other hand, policy performance when trained on such demonstrations can reflect the reliability of different strategies. We thus propose for robots to self-curate based on online robot experience (Demo-SCORE). More specifically, we train and cross-validate a classifier to discern successful policy roll-outs from unsuccessful ones and use the classifier to filter heterogeneous demonstration datasets. Our experiments in simulation and the real world show that Demo-SCORE can effectively identify suboptimal demonstrations without manual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute success rate in the resulting policy compared to the base policy trained with all original demonstrations.', 'abstract_zh': '基于在线机器人体验的演示自筛选（Demo-SCORE）', 'title_zh': '基于在线体验策展演示'}
{'arxiv_id': 'arXiv:2503.03230', 'title': 'OpenGV 2.0: Motion prior-assisted calibration and SLAM with vehicle-mounted surround-view systems', 'authors': "Kun Huang, Yifu Wang, Si'ao Zhang, Zhirui Wang, Zhanpeng Ouyang, Zhenghua Yu, Laurent Kneip", 'link': 'https://arxiv.org/abs/2503.03230', 'abstract': 'The present paper proposes optimization-based solutions to visual SLAM with a vehicle-mounted surround-view camera system. Owing to their original use-case, such systems often only contain a single camera facing into either direction and very limited overlap between fields of view. Our novelty consist of three optimization modules targeting at practical online calibration of exterior orientations from simple two-view geometry, reliable front-end initialization of relative displacements, and accurate back-end optimization using a continuous-time trajectory model. The commonality between the proposed modules is given by the fact that all three of them exploit motion priors that are related to the inherent non-holonomic characteristics of passenger vehicle motion. In contrast to prior related art, the proposed modules furthermore excel in terms of bypassing partial unobservabilities in the transformation variables that commonly occur for Ackermann-motion. As a further contribution, the modules are built into a novel surround-view camera SLAM system that specifically targets deployment on Ackermann vehicles operating in urban environments. All modules are studied in the context of in-depth ablation studies, and the practical validity of the entire framework is supported by a successful application to challenging, large-scale publicly available online datasets. Note that upon acceptance, the entire framework is scheduled for open-source release as part of an extension of the OpenGV library.', 'abstract_zh': '基于优化的视觉SLAM方法研究：面向车载环视相机系统的实践在线标定与轨迹优化', 'title_zh': 'OpenGV 2.0：车辆搭载全景视图系统中的运动先验辅助标定与SLAM'}
{'arxiv_id': 'arXiv:2503.03192', 'title': 'Distributed Certifiably Correct Range-Aided SLAM', 'authors': 'Alexander Thoms, Alan Papalia, Jared Velasquez, David M. Rosen, Sriram Narasimhan', 'link': 'https://arxiv.org/abs/2503.03192', 'abstract': "Reliable simultaneous localization and mapping (SLAM) algorithms are necessary for safety-critical autonomous navigation. In the communication-constrained multi-agent setting, navigation systems increasingly use point-to-point range sensors as they afford measurements with low bandwidth requirements and known data association. The state estimation problem for these systems takes the form of range-aided (RA) SLAM. However, distributed algorithms for solving the RA-SLAM problem lack formal guarantees on the quality of the returned estimate. To this end, we present the first distributed algorithm for RA-SLAM that can efficiently recover certifiably globally optimal solutions. Our algorithm, distributed certifiably correct RA-SLAM (DCORA), achieves this via the Riemannian Staircase method, where computational procedures developed for distributed certifiably correct pose graph optimization are generalized to the RA-SLAM problem. We demonstrate DCORA's efficacy on real-world multi-agent datasets by achieving absolute trajectory errors comparable to those of a state-of-the-art centralized certifiably correct RA-SLAM algorithm. Additionally, we perform a parametric study on the structure of the RA-SLAM problem using synthetic data, revealing how common parameters affect DCORA's performance.", 'abstract_zh': '可靠的协同定位与建图（SLAM）算法对于安全关键的自主导航至关重要。在通信受限的多agent环境中，导航系统越来越多地使用点到点的距离传感器，因其具有低带宽要求和已知的数据关联性。这些系统的状态估计问题表现为辅助距离（RA）SLAM问题。然而，解决RA-SLAM问题的分布式算法缺乏关于返回估计质量的形式化保证。为此，我们提出了一种全新的分布式算法，即分布式可证实正确的RA-SLAM（DCORA），该算法能够高效地恢复全局最优解，并通过里斯曼楼梯方法实现，其中针对分布式可证实正确位图图优化开发的计算过程被推广应用于RA-SLAM问题。通过在真实的多agent数据集上展示DCORA的有效性，我们达到了与最先进的集中式可证实正确RA-SLAM算法相当的绝对轨迹误差。此外，我们使用合成数据对RA-SLAM问题的结构进行了参数研究，揭示了常见参数如何影响DCORA的性能。', 'title_zh': '分布式认证正确区间辅助SLAM'}
{'arxiv_id': 'arXiv:2503.02992', 'title': 'RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding Across Different Environments and Tasks', 'authors': 'Yimin Tang, Xiao Xiong, Jingyi Xi, Jiaoyang Li, Erdem Bıyık, Sven Koenig', 'link': 'https://arxiv.org/abs/2503.02992', 'abstract': "Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset.", 'abstract_zh': 'RAILGUN：基于地图的多Agent路径规划的首个集中式学习策略', 'title_zh': 'RAILGUN：跨不同环境和任务的统一卷积策略多-Agent路径规划'}
{'arxiv_id': 'arXiv:2503.02954', 'title': 'Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders', 'authors': 'Yue Meng, Nathalie Majcherczyk, Wenliang Liu, Scott Kiesel, Chuchu Fan, Federico Pecora', 'link': 'https://arxiv.org/abs/2503.02954', 'abstract': 'Multi-agent coordination is crucial for reliable multi-robot navigation in shared spaces such as automated warehouses. In regions of dense robot traffic, local coordination methods may fail to find a deadlock-free solution. In these scenarios, it is appropriate to let a central unit generate a global schedule that decides the passing order of robots. However, the runtime of such centralized coordination methods increases significantly with the problem scale. In this paper, we propose to leverage Graph Neural Network Variational Autoencoders (GNN-VAE) to solve the multi-agent coordination problem at scale faster than through centralized optimization. We formulate the coordination problem as a graph problem and collect ground truth data using a Mixed-Integer Linear Program (MILP) solver. During training, our learning framework encodes good quality solutions of the graph problem into a latent space. At inference time, solution samples are decoded from the sampled latent variables, and the lowest-cost sample is selected for coordination. Finally, the feasible proposal with the highest performance index is selected for the deployment. By construction, our GNN-VAE framework returns solutions that always respect the constraints of the considered coordination problem. Numerical results show that our approach trained on small-scale problems can achieve high-quality solutions even for large-scale problems with 250 robots, being much faster than other baselines. Project page: this https URL', 'abstract_zh': '多Agent协调对于自动化仓库等共享空间中可靠多机器人导航至关重要。在密集机器人流量区域，局部协调方法可能无法找到无死锁的解决方案。在这种情况下，适当的做法是由中心单位生成一个全局调度，决定机器人的通行顺序。然而，随着问题规模的增大，集中式协调方法的运行时间会显著增加。本文提出利用Graph Neural Network Variational Autoencoders (GNN-VAE) 来更快地解决大规模多Agent协调问题，而不是通过集中式优化。我们将协调问题形式化为图问题，并使用混合整数线性规划（MILP）求解器收集真实数据。在训练过程中，我们的学习框架将高质量的图问题解决方案编码到潜在空间中。在推理阶段，从采样的潜在变量中解码解决方案样本，并选择成本最低的样本进行协调。最后，选择具有最高性能指标的可行建议进行部署。通过设计，我们的GNN-VAE框架返回的解决方案总是遵守所考虑的协调问题的约束。数值结果表明，即使在包含250个机器人的大规模问题上，我们的方法在小规模问题上训练后也能达到高质量的解决方案，比其他基准方法快得多。项目页面：this https URL。', 'title_zh': '基于图神经网络变分自编码器的可靠高效多智能体协调'}
{'arxiv_id': 'arXiv:2503.02924', 'title': 'Diverse Controllable Diffusion Policy with Signal Temporal Logic', 'authors': 'Yue Meng, Chuchu fan', 'link': 'https://arxiv.org/abs/2503.02924', 'abstract': 'Generating realistic simulations is critical for autonomous system applications such as self-driving and human-robot interactions. However, driving simulators nowadays still have difficulty in generating controllable, diverse, and rule-compliant behaviors for road participants: Rule-based models cannot produce diverse behaviors and require careful tuning, whereas learning-based methods imitate the policy from data but are not designed to follow the rules explicitly. Besides, the real-world datasets are by nature "single-outcome", making the learning method hard to generate diverse behaviors. In this paper, we leverage Signal Temporal Logic (STL) and Diffusion Models to learn controllable, diverse, and rule-aware policy. We first calibrate the STL on the real-world data, then generate diverse synthetic data using trajectory optimization, and finally learn the rectified diffusion policy on the augmented dataset. We test on the NuScenes dataset and our approach can achieve the most diverse rule-compliant trajectories compared to other baselines, with a runtime 1/17X to the second-best approach. In the closed-loop testing, our approach reaches the highest diversity, rule satisfaction rate, and the least collision rate. Our method can generate varied characteristics conditional on different STL parameters in testing. A case study on human-robot encounter scenarios shows our approach can generate diverse and closed-to-oracle trajectories. The annotation tool, augmented dataset, and code are available at this https URL.', 'abstract_zh': '基于STL和扩散模型的可控、多样和守规行为学习方法', 'title_zh': '多种可控扩散策略与信号时序逻辑'}
{'arxiv_id': 'arXiv:2503.03717', 'title': 'Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements', 'authors': 'Carlo Dindorf, Fabian Horst, Djordje Slijepčević, Bernhard Dumphart, Jonas Dully, Matthias Zeppelzauer, Brian Horsak, Michael Fröhlich', 'link': 'https://arxiv.org/abs/2503.03717', 'abstract': 'This chapter provides an overview of recent and promising Machine Learning applications, i.e. pose estimation, feature estimation, event detection, data exploration & clustering, and automated classification, in gait (walking and running) and sports biomechanics. It explores the potential of Machine Learning methods to address challenges in biomechanical workflows, highlights central limitations, i.e. data and annotation availability and explainability, that need to be addressed, and emphasises the importance of interdisciplinary approaches for fully harnessing the potential of Machine Learning in gait and sports biomechanics.', 'abstract_zh': '本章提供了近期和有前景的机器学习在步态（行走和跑步）及运动生物力学中应用的综述，包括姿态估计、特征估计、事件检测、数据探索与聚类以及自动化分类。探讨了机器学习方法在生物力学工作流程中应对挑战的潜力，强调了数据和注释可用性及可解释性等核心限制需要解决，并强调了跨学科方法对于充分利用机器学习在步态和运动生物力学中的潜力的重要性。', 'title_zh': '生物力学中的机器学习：步行、跑步和运动中关键应用与局限性'}
{'arxiv_id': 'arXiv:2503.03693', 'title': 'ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX', 'authors': 'Ungsik Kim', 'link': 'https://arxiv.org/abs/2503.03693', 'abstract': 'In the field of Explainable Artificial Intelligence (XAI), argumentative XAI approaches have been proposed to represent the internal reasoning process of deep neural networks in a more transparent way by interpreting hidden nodes as arguements. However, as the number of layers increases, existing compression methods simplify all layers at once, which lead to high accumulative information loss. To compensate for this, we propose an iterative layer-by-layer compression technique in which each layer is compressed separately and the reduction error in the next layer is immediately compensated for, thereby improving the overall input-output and structural fidelity of the model. Experiments on the Breast Cancer Diagnosis dataset show that, compared to traditional compression, the method reduces input-output and structural unfaithfulness, and maintains a more consistent attack-support relationship in the Argumentative Explanation scheme. This is significant because it provides a new way to make complex MLP models more compact while still conveying their internal inference logic without distortion.', 'abstract_zh': '在可解释人工智能（XAI）领域，提出了以论辩方式表达深度神经网络内部推理过程的解释性XAI方法，通过将隐藏节点解释为论点来提高透明度。然而，随着层的数量增加，现有的压缩方法会一次性简化所有层，导致累积信息丢失。为解决这一问题，我们提出了一种迭代的逐层压缩技术，每层分别进行压缩，并在下一层立即补偿上一层的压缩误差，从而提高模型的整体输入输出 fidelity 和结构一致性。在乳腺癌诊断数据集上的实验表明，与传统压缩方法相比，该方法减少了输入输出和结构不忠实性，并在论辩解释方案中维持了更一致的攻击支持关系。这一成果意义重大，因为它提供了一种在不扭曲内部推理逻辑的情况下使复杂MLP模型更加紧凑的新方法。', 'title_zh': 'ILLC: 迭代逐层压缩以增强SpArX的结构忠实性'}
{'arxiv_id': 'arXiv:2503.03361', 'title': 'From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks', 'authors': 'Shify Treger, Shimon Ullman', 'link': 'https://arxiv.org/abs/2503.03361', 'abstract': 'Early in development, infants learn a range of useful concepts, which can be challenging from a computational standpoint. This early learning comes together with an initial understanding of aspects of the meaning of concepts, e.g., their implications, causality, and using them to predict likely future events. All this is accomplished in many cases with little or no supervision, and from relatively few examples, compared with current network models. In learning about objects and human-object interactions, early acquired and possibly innate concepts are often used in the process of learning additional, more complex concepts. In the current work, we model how early-acquired concepts are used in the learning of subsequent concepts, and compare the results with standard deep network modeling. We focused in particular on the use of the concepts of animacy and goal attribution in learning to predict future events. We show that the use of early concepts in the learning of new concepts leads to better learning (higher accuracy) and more efficient learning (requiring less data). We further show that this integration of early and new concepts shapes the representation of the concepts acquired by the model. The results show that when the concepts were learned in a human-like manner, the emerging representation was more useful, as measured in terms of generalization to novel data and tasks. On a more general level, the results suggest that there are likely to be basic differences in the conceptual structures acquired by current network models compared to human learning.', 'abstract_zh': '早期发展过程中，婴儿学习一系列有用的概念，这在计算上颇具挑战性。这些早期的学习伴随着对概念意义方面初步理解的形成，例如其推论、因果关系，以及利用这些概念预测可能的未来事件。很多情况下，这种学习几乎不需要或只需要很少的监督，并且仅需少量示例，与当前的网络模型相比。在学习物体及人与物体的交互时，早期获得的概念（可能还包括先天的概念）通常被用来学习更复杂的概念。在当前的研究中，我们建模了早期获得的概念在学习后续概念过程中的应用，并将结果与标准的深度网络建模进行了比较。我们特别关注了使用生命性和目标归因概念来预测未来事件的学习过程。结果显示，利用早期概念来学习新概念不仅能够提高学习效果（更高的准确性），而且能够更高效地学习（需要较少的数据）。此外，我们还发现这种早期和新概念的整合会影响模型所获得概念的表征方式。研究结果表明，当概念以类似人类的方式学习时，形成的表示方式在泛化到新数据和任务方面的表现更好。在更广泛的意义上，这些结果表明，当前网络模型获得的概念结构与人类学习的概念结构之间可能存在基本差异。', 'title_zh': '从婴儿到AI：在模型中融入类似婴儿的学习方式可以提升社交预测任务的学习效率和泛化能力'}
{'arxiv_id': 'arXiv:2503.03137', 'title': 'L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver', 'authors': 'Changliang Zhou, Xi Lin, Zhenkun Wang, Qingfu Zhang', 'link': 'https://arxiv.org/abs/2503.03137', 'abstract': 'Constructive neural combinatorial optimization (NCO) has attracted growing research attention due to its ability to solve complex routing problems without relying on handcrafted rules. However, existing NCO methods face significant challenges in generalizing to large-scale problems due to high computational complexity and inefficient capture of structural patterns. To address this issue, we propose a novel learning-based search space reduction method that adaptively selects a small set of promising candidate nodes at each step of the constructive NCO process. Unlike traditional methods that rely on fixed heuristics, our selection model dynamically prioritizes nodes based on learned patterns, significantly reducing the search space while maintaining solution quality. Experimental results demonstrate that our method, trained solely on 100-node instances from uniform distribution, generalizes remarkably well to large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) instances with up to 1 million nodes from the uniform distribution and over 80K nodes from other distributions.', 'abstract_zh': '基于学习的Constructive神经组合优化搜索空间缩减方法', 'title_zh': 'L2R: 学习减小搜索空间以实现更具泛化能力的神经路由求解器'}
{'arxiv_id': 'arXiv:2503.02950', 'title': 'LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications', 'authors': 'Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao', 'link': 'https://arxiv.org/abs/2503.02950', 'abstract': "We introduce LiteWebAgent, an open-source suite for VLM-based web agent applications. Our framework addresses a critical gap in the web agent ecosystem with a production-ready solution that combines minimal serverless backend configuration, intuitive user and browser interfaces, and extensible research capabilities in agent planning, memory, and tree search. For the core LiteWebAgent agent framework, we implemented a simple yet effective baseline using recursive function calling, providing with decoupled action generation and action grounding. In addition, we integrate advanced research components such as agent planning, agent workflow memory, and tree search in a modular and extensible manner. We then integrate the LiteWebAgent agent framework with frontend and backend as deployed systems in two formats: (1) a production Vercel-based web application, which provides users with an agent-controlled remote browser, (2) a Chrome extension leveraging LiteWebAgent's API to control an existing Chrome browser via CDP (Chrome DevTools Protocol). The LiteWebAgent framework is available at this https URL, with deployed frontend at this https URL.", 'abstract_zh': '我们介绍LiteWebAgent——一个基于VLM的web代理应用程序的开源套件。该框架通过结合最少的无服务器后端配置、直观的用户和浏览器界面以及在代理规划、记忆和树搜索方面的可扩展研究能力，解决了web代理生态系统中的关键问题。对于核心的LiteWebAgent代理框架，我们实现了一个简单有效的 baseline，使用递归函数调用，提供了动作生成与动作 grounding 的解耦。此外，我们以模块化和可扩展的方式整合了高级研究组件，如代理规划、代理工作流记忆和树搜索。然后，我们将LiteWebAgent代理框架以两种格式与前端和后端部署系统集成：(1) 基于Vercel的生产级web应用程序，为用户提供代理控制的远程浏览器；(2) 利用LiteWebAgent的API并通过CDP（Chrome DevTools协议）控制现有Chrome浏览器的Chrome扩展。LiteWebAgent框架可在以下链接获取，部署的前端可在此链接访问。', 'title_zh': 'LiteWebAgent: 基于VLM的网络代理应用开源套件'}
{'arxiv_id': 'arXiv:2503.03733', 'title': 'Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need', 'authors': 'Amal Shaheena, Nairouz Mrabahb, Riadh Ksantinia, Abdulla Alqaddoumia', 'link': 'https://arxiv.org/abs/2503.03733', 'abstract': 'The recent advances in deep clustering have been made possible by significant progress in self-supervised and pseudo-supervised learning. However, the trade-off between self-supervision and pseudo-supervision can give rise to three primary issues. The joint training causes Feature Randomness and Feature Drift, whereas the independent training causes Feature Randomness and Feature Twist. In essence, using pseudo-labels generates random and unreliable features. The combination of pseudo-supervision and self-supervision drifts the reliable clustering-oriented features. Moreover, moving from self-supervision to pseudo-supervision can twist the curved latent manifolds. This paper addresses the limitations of existing deep clustering paradigms concerning Feature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm with a new strategy that replaces pseudo-supervision with a second round of self-supervision training. The new strategy makes the transition between instance-level self-supervision and neighborhood-level self-supervision smoother and less abrupt. Moreover, it prevents the drifting effect that is caused by the strong competition between instance-level self-supervision and clustering-level pseudo-supervision. Moreover, the absence of the pseudo-supervision prevents the risk of generating random features. With this novel approach, our paper introduces a Rethinking of the Deep Clustering Paradigms, denoted by R-DC. Our model is specifically designed to address three primary challenges encountered in Deep Clustering: Feature Randomness, Feature Drift, and Feature Twist. Experimental results conducted on six datasets have shown that the two-level self-supervision training yields substantial improvements.', 'abstract_zh': '最近深聚类的进展得益于自我监督和伪监督学习的显著进步。然而，自我监督与伪监督之间的权衡可能导致三个主要问题。联合训练导致特征随机性和特征漂移，而独立训练导致特征随机性和特征扭曲。本质上，使用伪标签会生成随机且不可靠的特征。自我监督与伪监督的结合会使可靠的聚类导向特征发生漂移。此外，从自我监督转向伪监督会使曲面潜在流形发生扭曲。本文针对现有深聚类范式的特征随机性、特征漂移和特征扭曲的局限性进行了探讨。我们提出了一种新的范式和策略，用第二轮自我监督训练替代伪监督。这种新策略使得实例级自我监督与邻域级自我监督之间的过渡更加平滑和不那么突兀。此外，它还防止了实例级自我监督与聚类级伪监督之间强烈竞争导致的漂移效应。此外，缺乏伪监督可以防止生成随机特征的风险。通过这一新颖的方法，本文为深聚类范式提出了重新思考的方法，命名为R-DC。我们的模型专门设计用于解决深聚类中遇到的三个主要挑战：特征随机性、特征漂移和特征扭曲。在六个数据集上的实验结果表明，两层次自我监督训练带来了显著的改进。', 'title_zh': '重新思考深度聚类范式：自我监督即所有所需'}
{'arxiv_id': 'arXiv:2503.03724', 'title': 'Deep Causal Behavioral Policy Learning: Applications to Healthcare', 'authors': 'Jonas Knecht, Anna Zink, Jonathan Kolstad, Maya Petersen', 'link': 'https://arxiv.org/abs/2503.03724', 'abstract': "We present a deep learning-based approach to studying dynamic clinical behavioral regimes in diverse non-randomized healthcare settings. Our proposed methodology - deep causal behavioral policy learning (DC-BPL) - uses deep learning algorithms to learn the distribution of high-dimensional clinical action paths, and identifies the causal link between these action paths and patient outcomes. Specifically, our approach: (1) identifies the causal effects of provider assignment on clinical outcomes; (2) learns the distribution of clinical actions a given provider would take given evolving patient information; (3) and combines these steps to identify the optimal provider for a given patient type and emulate that provider's care decisions. Underlying this strategy, we train a large clinical behavioral model (LCBM) on electronic health records data using a transformer architecture, and demonstrate its ability to estimate clinical behavioral policies. We propose a novel interpretation of a behavioral policy learned using the LCBM: that it is an efficient encoding of complex, often implicit, knowledge used to treat a patient. This allows us to learn a space of policies that are critical to a wide range of healthcare applications, in which the vast majority of clinical knowledge is acquired tacitly through years of practice and only a tiny fraction of information relevant to patient care is written down (e.g. in textbooks, studies or standardized guidelines).", 'abstract_zh': '基于深度学习的动态临床行为规制研究：非随机化医疗保健环境中的深度因果行为策略学习', 'title_zh': '深度因果行为策略学习：在医疗保健领域的应用'}
{'arxiv_id': 'arXiv:2503.03606', 'title': 'Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs', 'authors': 'Anas Buhayh, Elizabeth McKinnie, Robin Burke', 'link': 'https://arxiv.org/abs/2503.03606', 'abstract': 'Recommender ecosystems are an emerging subject of research. Such research examines how the characteristics of algorithms, recommendation consumers, and item providers influence system dynamics and long-term outcomes. One architectural possibility that has not yet been widely explored in this line of research is the consequences of a configuration in which recommendation algorithms are decoupled from the platforms they serve. This is sometimes called "the friendly neighborhood algorithm store" or "middleware" model. We are particularly interested in how such architectures might offer a range of different distributions of utility across consumers, providers, and recommendation platforms. In this paper, we create a model of a recommendation ecosystem that incorporates algorithm choice and examine the outcomes of such a design.', 'abstract_zh': '推荐生态系统是一种新兴的研究主题。此类研究探讨算法特性、推荐消费者和项目提供者的特点如何影响系统动力学和长期结果。在这条研究线路上，尚未广泛探讨的一种架构可能性是推荐算法与服务的平台脱钩的后果。有时这种架构被称为“友好邻里的算法存储”或“中间件”模型。我们特别感兴趣的是这种架构如何为消费者、提供者和推荐平台提供不同类型的利益分配。在本文中，我们构建了一个包含算法选择的推荐生态系统模型，并探讨了此类设计的结果。', 'title_zh': '解耦推荐系统：探索替代的推荐生态系统设计'}
{'arxiv_id': 'arXiv:2503.03595', 'title': 'Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias', 'authors': 'Rui Lu, Runzhe Wang, Kaifeng Lyu, Xitai Jiang, Gao Huang, Mengdi Wang', 'link': 'https://arxiv.org/abs/2503.03595', 'abstract': "Score-based diffusion models have achieved incredible performance in generating realistic images, audio, and video data. While these models produce high-quality samples with impressive details, they often introduce unrealistic artifacts, such as distorted fingers or hallucinated texts with no meaning. This paper focuses on textual hallucinations, where diffusion models correctly generate individual symbols but assemble them in a nonsensical manner. Through experimental probing, we consistently observe that such phenomenon is attributed it to the network's local generation bias. Denoising networks tend to produce outputs that rely heavily on highly correlated local regions, particularly when different dimensions of the data distribution are nearly pairwise independent. This behavior leads to a generation process that decomposes the global distribution into separate, independent distributions for each symbol, ultimately failing to capture the global structure, including underlying grammar. Intriguingly, this bias persists across various denoising network architectures including MLP and transformers which have the structure to model global dependency. These findings also provide insights into understanding other types of hallucinations, extending beyond text, as a result of implicit biases in the denoising models. Additionally, we theoretically analyze the training dynamics for a specific case involving a two-layer MLP learning parity points on a hypercube, offering an explanation of its underlying mechanism.", 'abstract_zh': '评分based扩散模型在生成逼真图像、音频和视频数据方面取得了惊人的性能。尽管这些模型能够生成高质量、细节逼真的样本，但往往会引入一些不现实的伪影，如扭曲的手指或无意义的文本。本文关注文本幻觉现象，扩散模型可以生成正确的符号，但它们以一种无意义的方式组合。通过实验探究，我们一致观察到这种现象是由网络的局部生成偏见引起的。去噪网络倾向于产生高度依赖于局部高度相关区域的输出，尤其是在数据分布的不同维度几乎呈 pairwise 独立时。这种行为导致生成过程将全局分布分解为各个符号的独立分布，最终未能捕捉到全局结构，包括潜在的语法规则。有趣的是，这种偏见在包括MLP和变压器在内的各种去噪网络架构中普遍存在，尽管它们具有建模全局依赖性的结构。这些发现还为理解其他类型的幻觉提供了见解，这些幻觉超越了文本，源于去噪模型中的隐式偏见。此外，我们对一个两层MLP在超立方体上学习奇偶校验点的具体情况进行理论分析，提供了其内在机制的解释。', 'title_zh': '面向理解扩散模型的文本幻想现象通过局部生成偏差'}
{'arxiv_id': 'arXiv:2503.03563', 'title': 'A Conceptual Model for Attributions in Event-Centric Knowledge Graphs', 'authors': 'Florian Plötzky, Katarina Britz, Wolf-Tilo Balke', 'link': 'https://arxiv.org/abs/2503.03563', 'abstract': "The use of narratives as a means of fusing information from knowledge graphs (KGs) into a coherent line of argumentation has been the subject of recent investigation. Narratives are especially useful in event-centric knowledge graphs in that they provide a means to connect different real-world events and categorize them by well-known narrations. However, specifically for controversial events, a problem in information fusion arises, namely, multiple viewpoints regarding the validity of certain event aspects, e.g., regarding the role a participant takes in an event, may exist. Expressing those viewpoints in KGs is challenging because disputed information provided by different viewpoints may introduce inconsistencies. Hence, most KGs only feature a single view on the contained information, hampering the effectiveness of narrative information access. This paper is an extension of our original work and introduces attributions, i.e., parameterized predicates that allow for the representation of facts that are only valid in a specific viewpoint. For this, we develop a conceptual model that allows for the representation of viewpoint-dependent information. As an extension, we enhance the model by a conception of viewpoint-compatibility. Based on this, we deepen our original deliberations on the model's effects on information fusion and provide additional grounding in the literature.", 'abstract_zh': '利用叙事将知识图谱信息融合到连贯的论据链中的研究：引入视点归因以处理争议性事件中的个人观点冲突', 'title_zh': '事件中心知识图谱中归因的概念模型'}
{'arxiv_id': 'arXiv:2503.03532', 'title': "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking", 'authors': 'Mashrur Rashik, Shilpa Sweth, Nishtha Agrawal, Saiyyam Kochar, Kara M Smith, Fateme Rajabiyazdi, Vidya Setlur, Narges Mahyar, Ali Sarvghad', 'link': 'https://arxiv.org/abs/2503.03532', 'abstract': "Journaling plays a crucial role in managing chronic conditions by allowing patients to document symptoms and medication intake, providing essential data for long-term care. While valuable, traditional journaling methods often rely on static, self-directed entries, lacking interactive feedback and real-time guidance. This gap can result in incomplete or imprecise information, limiting its usefulness for effective treatment. To address this gap, we introduce PATRIKA, an AI-enabled prototype designed specifically for people with Parkinson's disease (PwPD). The system incorporates cooperative conversation principles, clinical interview simulations, and personalization to create a more effective and user-friendly journaling experience. Through two user studies with PwPD and iterative refinement of PATRIKA, we demonstrate conversational journaling's significant potential in patient engagement and collecting clinically valuable information. Our results showed that generating probing questions PATRIKA turned journaling into a bi-directional interaction. Additionally, we offer insights for designing journaling systems for healthcare and future directions for promoting sustained journaling.", 'abstract_zh': '延还认证在管理慢性疾病中发挥关键作用，通过允许患者记录症状和药物摄入，提供长期护理所需的重要数据。尽管传统日志记录方法有价值，但往往依赖于静态、自我驱动的条目，缺乏互动反馈和实时指导。为填补这一空白，我们介绍了PATRIKA，一种针对帕金森病患者（PwPD）的AI辅助原型系统。该系统整合了合作对话原则、临床访谈模拟和个人化设计，以创建更有效和用户友好的日志记录体验。通过与PwPD患者的两组用户研究和对PATRIKA的迭代优化，我们展示了对话式日志记录在患者参与和收集临床有价值信息方面的巨大潜力。研究结果显示，生成探询性问题使PATRIKA将日志记录转变为此消彼长的互动过程。此外，我们还提供了为医疗保健设计日志记录系统的设计见解，并提出了促进持续日志记录的未来方向。', 'title_zh': 'AI驱动的对话式日记记录方法在帕金森病症状跟踪中的应用'}
{'arxiv_id': 'arXiv:2503.03506', 'title': 'Rethinking Synthetic Data definitions: A privacy driven approach', 'authors': 'Vibeke Binz Vallevik, Serena Elizabeth Marshall, Aleksandar Babic, Jan Franz Nygaard', 'link': 'https://arxiv.org/abs/2503.03506', 'abstract': 'Synthetic data is gaining traction as a cost-effective solution for the increasing data demands of AI development and can be generated either from existing knowledge or derived data captured from real-world events. The source of the synthetic data generation and the technique used significantly impacts its residual privacy risk and therefore its opportunity for sharing. Traditional classification of synthetic data types no longer fit the newer generation techniques and there is a need to better align the classification with practical needs. We suggest a new way of grouping synthetic data types that better supports privacy evaluations to aid regulatory policymaking. Our novel classification provides flexibility to new advancements like deep generative methods and offers a more practical framework for future applications.', 'abstract_zh': '合成数据作为AI开发中日益增长的数据需求的一种成本-effective解决方案正在受到青睐，并可以通过现有知识或源于实际事件的衍生数据生成。合成数据生成的来源和所使用的技术对其剩余隐私风险以及因此对其共享机会产生了重大影响。传统意义上的合成数据类型分类已不再适用于新的生成技术，因此有必要将分类更好地与实际需求对齐。我们建议一种新的合成数据类型分组方式，以更好地支持隐私评估，从而辅助监管政策制定。我们的新分类提供了对未来进步如深度生成方法的灵活性，并为未来应用提供了一个更加实际的框架。', 'title_zh': '重塑合成数据的定义：以隐私为导向的方法'}
{'arxiv_id': 'arXiv:2503.03443', 'title': 'Conceptualizing Uncertainty', 'authors': 'Isaac Roberts, Alexander Schulz, Sarah Schroeder, Fabian Hinder, Barbara Hammer', 'link': 'https://arxiv.org/abs/2503.03443', 'abstract': "Uncertainty in machine learning refers to the degree of confidence or lack thereof in a model's predictions. While uncertainty quantification methods exist, explanations of uncertainty, especially in high-dimensional settings, remain an open challenge. Existing work focuses on feature attribution approaches which are restricted to local explanations. Understanding uncertainty, its origins, and characteristics on a global scale is crucial for enhancing interpretability and trust in a model's predictions. In this work, we propose to explain the uncertainty in high-dimensional data classification settings by means of concept activation vectors which give rise to local and global explanations of uncertainty. We demonstrate the utility of the generated explanations by leveraging them to refine and improve our model.", 'abstract_zh': '机器学习中的不确定性指的是模型预测的信心程度或缺乏程度。虽然存在不确定性量化方法，但在高维设置下解释不确定性仍然是一个开放性挑战。现有工作集中在特征归因方法，这些方法局限于局部解释。理解不确定性及其起源和特征在全局尺度上对于增强模型预测的可解释性和可信度至关重要。在这项工作中，我们提出通过概念激活向量来解释高维数据分类设置中的不确定性，从而提供局部和全局的不确定性解释。我们通过利用生成的解释来改进和完善我们的模型，展示了这些解释的实用性。', 'title_zh': '构建不确定性概念'}
{'arxiv_id': 'arXiv:2503.03428', 'title': 'Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs', 'authors': 'Karthik Barma, Seshu Babu Barma', 'link': 'https://arxiv.org/abs/2503.03428', 'abstract': 'In a world where data is the new currency, wearable health devices offer unprecedented insights into daily life, continuously monitoring vital signs and metrics. However, this convenience raises privacy concerns, as these devices collect sensitive data that can be misused or breached. Traditional measures often fail due to real-time data processing needs and limited device power. Users also lack awareness and control over data sharing and usage. We propose a Privacy-Enhancing Technology (PET) framework for wearable devices, integrating federated learning, lightweight cryptographic methods, and selectively deployed blockchain technology. The blockchain acts as a secure ledger triggered only upon data transfer requests, granting users real-time notifications and control. By dismantling data monopolies, this approach returns data sovereignty to individuals. Through real-world applications like secure medical data sharing, privacy-preserving fitness tracking, and continuous health monitoring, our framework reduces privacy risks by up to 70 percent while preserving data utility and performance. This innovation sets a new benchmark for wearable privacy and can scale to broader IoT ecosystems, including smart homes and industry. As data continues to shape our digital landscape, our research underscores the critical need to maintain privacy and user control at the forefront of technological progress.', 'abstract_zh': '在数据成为新货币的世界中，可穿戴健康设备提供了对日常生活前所未有的洞察， continuously monitoring vital signs and metrics. However, this convenience raises privacy concerns, as these devices collect sensitive data that can be misused or breached. 传统措施往往因实时数据处理需求和有限的设备功率而失效。用户也缺乏对数据共享和使用情况的意识和控制。我们提出了一种增强隐私的技术（PET）框架，整合了联邦学习、轻量级密码方法和选择性部署的区块链技术。区块链作为一种安全账本，在数据传输请求时触发，为用户提供实时通知和控制。通过打破数据垄断，该方法将数据主权返回给个人。通过安全医疗数据共享、隐私保护的健身追踪和持续健康监测等实际应用，我们的框架将隐私风险降低高达70%，同时保持数据实用性和性能。这一创新为可穿戴设备隐私设立了新标准，并可扩展到更广泛的物联网生态系统，包括智能家居和工业。随着数据继续塑造我们的数字景观，我们的研究强调了在技术进步中维持隐私和用户控制的迫切需求。', 'title_zh': '隐私至上：借助先进PET技术 revolutionize 可穿戴健康数据管理'}
{'arxiv_id': 'arXiv:2503.03418', 'title': 'Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem', 'authors': 'Oleg Kachan, Andrey Savchenko, Gleb Gusev', 'link': 'https://arxiv.org/abs/2503.03418', 'abstract': 'SMOTE (Synthetic Minority Oversampling Technique) is the established geometric approach to random oversampling to balance classes in the imbalanced learning problem, followed by many extensions. Its idea is to introduce synthetic data points of the minor class, with each new point being the convex combination of an existing data point and one of its k-nearest neighbors. In this paper, by viewing SMOTE as sampling from the edges of a geometric neighborhood graph and borrowing tools from the topological data analysis, we propose a novel technique, Simplicial SMOTE, that samples from the simplices of a geometric neighborhood simplicial complex. A new synthetic point is defined by the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number of data points being sufficiently close rather than a pair. Such a replacement of the geometric data model results in better coverage of the underlying data distribution compared to existing geometric sampling methods and allows the generation of synthetic points of the minority class closer to the majority class on the decision boundary. We experimentally demonstrate that our Simplicial SMOTE outperforms several popular geometric sampling methods, including the original SMOTE. Moreover, we show that simplicial sampling can be easily integrated into existing SMOTE extensions. We generalize and evaluate simplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and ADASYN algorithms, all of which outperform their graph-based counterparts.', 'abstract_zh': 'Simplicial SMOTE：基于单纯复形的几何邻域采样方法', 'title_zh': 'simplicial SMOTE：欠衡学习问题的过采样解决方案'}
{'arxiv_id': 'arXiv:2503.03417', 'title': 'When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits', 'authors': 'Jabez Magomere, Emanuele La Malfa, Manuel Tonneau, Ashkan Kazemi, Scott Hale', 'link': 'https://arxiv.org/abs/2503.03417', 'abstract': 'Online misinformation remains a critical challenge, and fact-checkers increasingly rely on embedding-based methods to retrieve relevant fact-checks. Yet, when debunked claims reappear in edited forms, the performance of these methods is unclear. In this work, we introduce a taxonomy of six common real-world misinformation edits and propose a perturbation framework that generates valid, natural claim variations. Our multi-stage retrieval evaluation reveals that standard embedding models struggle with user-introduced edits, while LLM-distilled embeddings offer improved robustness at a higher computational cost. Although a strong reranker helps mitigate some issues, it cannot fully compensate for first-stage retrieval gaps. Addressing these retrieval gaps, our train- and inference-time mitigation approaches enhance in-domain robustness by up to 17 percentage points and boost out-of-domain generalization by 10 percentage points over baseline models. Overall, our findings provide practical improvements to claim-matching systems, enabling more reliable fact-checking of evolving misinformation.', 'abstract_zh': '在线错误信息仍然是一个关键挑战，事实核查人员越来越依赖基于嵌入的方法来检索相关的事实核查内容。然而，当被驳斥的断言以编辑形式重新出现时，这些方法的性能尚不清楚。在本研究中，我们引入了六种常见现实世界错误信息编辑的分类，并提出了一种生成有效且自然断言变体的扰动框架。多阶段检索评估揭示出，标准嵌入模型在用户引入的编辑面前表现不佳，而通过LLM提炼的嵌入提供了较高计算成本下的增强鲁棒性。尽管强重排序器能部分缓解一些问题，但它无法完全弥补第一阶段检索的缺口。通过解决这些检索缺口，我们在训练时间和推理时间上的缓解方法能够将领域内鲁棒性提高多达17个百分点，并将领域外泛化能力提高10个百分点，相较于基线模型。总体而言，我们的研究结果为断言匹配系统提供了实用的改进，使事实核查能够更可靠地应对不断演变的错误信息。', 'title_zh': '当声明演变：评估和提升嵌入模型对抗误导性编辑的稳健性'}
{'arxiv_id': 'arXiv:2503.03410', 'title': 'Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells', 'authors': 'Martina Russo, Giulia Bertolini, Vera Cappelletti, Cinzia De Marco, Serena Di Cosimo, Petra Paiè, Nadia Brancati', 'link': 'https://arxiv.org/abs/2503.03410', 'abstract': "Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy, offering a noninvasive tool for cancer patient management. However, their identification remains particularly challenging due to their limited number and heterogeneity. Labeling samples for contrast limits the generalization of fluorescence-based methods across different hospital datasets. Analyzing single-cell images enables detailed assessment of cell morphology, subcellular structures, and phenotypic variations, often hidden in clustered images. Developing a method based on bright-field single-cell analysis could overcome these limitations. CTCs can be isolated using an unbiased workflow combining Parsortix technology, which selects cells based on size and deformability, with DEPArray technology, enabling precise visualization and selection of single cells. Traditionally, DEPArray-acquired digital images are manually analyzed, making the process time-consuming and prone to variability. In this study, we present a Deep Learning-based classification pipeline designed to distinguish CTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and optimize clinical workflows. Our approach employs images from the bright-field channel acquired through DEPArray technology leveraging a ResNet-based CNN. To improve model generalization, we applied three types of data augmentation techniques and incorporated fluorescence (DAPI) channel images into the training phase, allowing the network to learn additional CTC-specific features. Notably, only bright-field images have been used for testing, ensuring the model's ability to identify CTCs without relying on fluorescence markers. The proposed model achieved an F1-score of 0.798, demonstrating its capability to distinguish CTCs from leukocytes. These findings highlight the potential of DL in refining CTC analysis and advancing liquid biopsy applications.", 'abstract_zh': '循环肿瘤细胞（CTCs）是液体活检中的关键生物标志物，提供了非侵入性工具以管理癌症患者。然而，由于其数量有限和异质性，它们的识别仍然颇具挑战。通过标记样品以提供对比度限制了基于荧光的方法在不同医院数据集中的普适性。分析单细胞图像可实现对细胞形态、亚细胞结构和表型变异的详细评估，这些信息在聚类图像中往往被隐藏。开发基于明场单细胞分析的方法可以克服这些限制。CTCs可以通过结合使用基于大小和变形性的Parsortix技术和DEPArray技术来分离，从而实现单细胞的精确可视化和选择。传统上，通过DEPArray获取的数字图像需要人工分析，使过程耗时且易变。在本研究中，我们提出了一种基于深度学习的分类管道，旨在增强诊断准确性和优化临床工作流程，以区分血液样本中的CTCs和中性粒细胞。我们的方法采用通过DEPArray技术获取的明场通道图像，并利用基于ResNet的CNN。为了提高模型的普适性，我们应用了三种数据增强技术，并将荧光（DAPI）通道图像纳入训练阶段，使网络能够学习更多的CTC特异性特征。值得注意的是，仅使用明场图像进行测试，确保模型能够不依赖荧光标记识别CTCs。所提出模型的F1分数为0.798，展示了其区分CTCs和中性粒细胞的能力。这些发现强调了深度学习在细化CTC分析和推进液体活检应用方面的能力。', 'title_zh': '基于增强的深度学习循环肿瘤细胞识别'}
{'arxiv_id': 'arXiv:2503.03391', 'title': 'Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks', 'authors': 'Muhammet Hevesli, Abegaz Mohammed Seid, Aiman Erbad, Mohamed Abdallah', 'link': 'https://arxiv.org/abs/2503.03391', 'abstract': 'Mobile edge computing (MEC)-enabled air-ground networks are a key component of 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles (UAVs) and high-altitude platform stations (HAPS) to provide dynamic services to ground IoT devices (IoTDs). These IoTDs support real-time applications (e.g., multimedia and Metaverse services) that demand high computational resources and strict quality of service (QoS) guarantees in terms of latency and task queue management. Given their limited energy and processing capabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed processing, forming a multi-tier MEC system. This paper tackles the overall energy minimization problem in MEC-enabled air-ground integrated networks (MAGIN) by jointly optimizing UAV trajectories, computing resource allocation, and queue-aware task offloading decisions. The optimization is challenging due to the nonconvex, nonlinear nature of this hierarchical system, which renders traditional methods ineffective. We reformulate the problem as a multi-agent Markov decision process (MDP) with continuous action spaces and heterogeneous agents, and propose a novel variant of multi-agent proximal policy optimization with a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show that MAPPO-BD outperforms baseline schemes, achieving superior energy savings and efficient resource management in MAGIN while meeting queue delay and edge computing constraints.', 'abstract_zh': '基于MEC的空地网络在6G中的关键作用：联合优化UAV轨迹、计算资源分配和感知任务卸载的多代理马克夫决策过程方法', 'title_zh': '基于分层MEC使能空地网络的多代理DRL任务卸载算法研究'}
{'arxiv_id': 'arXiv:2503.03360', 'title': 'Transformers for molecular property prediction: Domain adaptation efficiently improves performance', 'authors': 'Afnan Sultan, Max Rausch-Dupont, Shahrukh Khan, Olga Kalinina, Andrea Volkamer, Dietrich Klakow', 'link': 'https://arxiv.org/abs/2503.03360', 'abstract': 'Most of the current transformer-based chemical language models are pre-trained on millions to billions of molecules. However, the improvement from such scaling in dataset size is not confidently linked to improved molecular property prediction. The aim of this study is to investigate and overcome some of the limitations of transformer models in predicting molecular properties. Specifically, we examine the impact of pre-training dataset size and diversity on the performance of transformer models and investigate the use of domain adaptation as a technique for improving model performance. First, our findings indicate that increasing pretraining dataset size beyond 400K molecules from the GuacaMol dataset does not result in a significant improvement on four ADME endpoints, namely, solubility, permeability, microsomal stability, and plasma protein binding. Second, our results demonstrate that using domain adaptation by further training the transformer model on a small set of domain-relevant molecules, i.e., a few hundred to a few thousand, using multi-task regression of physicochemical properties was sufficient to significantly improve performance for three out of the four investigated ADME endpoints (P-value < 0.001). Finally, we observe that a model pre-trained on 400K molecules and domain adopted on a few hundred/thousand molecules performs similarly (P-value > 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M molecules) and MolFormer (pre-trained on 100M molecules). A comparison to a random forest model trained on basic physicochemical properties showed similar performance to the examined transformer models. We believe that current transformer models can be improved through further systematic analysis of pre-training and downstream data, pre-training objectives, and scaling laws, ultimately leading to better and more helpful models.', 'abstract_zh': '基于变压器的化学语言模型大多预先在百万到数亿个分子上进行训练。然而，这样的数据集规模扩大在分子性质预测上的改进并不肯定地与之关联。本研究旨在 Investigate and Overcome Some Limitations of Transformer Models in Predicting Molecular Properties。具体而言，我们探讨了预训练数据集的规模和多样性对变压器模型性能的影响，并研究了使用领域适应技术以提高模型性能的方法。首先，我们的发现表明，将预训练数据集规模从 GuacaMol 数据集的 400K 分子进一步增加并不会在四个 ADMET 端点（溶解度、渗透性、微粒体稳定性、血浆蛋白结合）上带来显著的性能提升。其次，我们的结果表明，通过在几百到几千个相关领域分子上进一步训练变压器模型，并利用多任务回归的物理化学性质，可以显著提高三个 ADMET 端点的性能（P 值 < 0.001）。最后，我们观察到，预训练在 400K 分子上并通过领域适应在几百到几千个分子上训练的模型与更复杂的变压器模型（如预训练在 1.3M 分子上的 MolBERT 和预训练在 100M 分子上的 MolFormer）具有相似的性能（P 值 > 0.05）。与在基本物理化学性质上训练的随机森林模型相比，其性能与检查的变压器模型相似。我们认为，通过进一步系统地分析预训练和下游数据、预训练目标和规模律，现有的变压器模型可以得到改进，最终导致更优秀和更实用的模型。', 'title_zh': '基于变压器的分子性质预测：域适应高效提升性能'}
{'arxiv_id': 'arXiv:2503.03274', 'title': 'Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems', 'authors': 'Alfreds Lapkovskis, Boris Sedlak, Sindri Magnússon, Schahram Dustdar, Praveen Kumar Donta', 'link': 'https://arxiv.org/abs/2503.03274', 'abstract': "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such as Distributed Computing Continuum Systems (DCCS), is challenging due to their heterogeneous nature and varying service requirements across different devices and applications. Additionally, unpredictable workloads and resource limitations lead to fluctuating performance and violated SLOs. To improve SLO compliance in DCCS, one possibility is to apply machine learning; however, the design choices are often left to the developer. To that extent, we provide a benchmark of Active Inference -- an emerging method from neuroscience -- against three established reinforcement learning algorithms (Deep Q-Network, Advantage Actor-Critic, and Proximal Policy Optimization). We consider a realistic DCCS use case: an edge device running a video conferencing application alongside a WebSocket server streaming videos. Using one of the respective algorithms, we continuously monitor key performance metrics, such as latency and bandwidth usage, to dynamically adjust parameters -- including the number of streams, frame rate, and resolution -- to optimize service quality and user experience. To test algorithms' adaptability to constant system changes, we simulate dynamically changing SLOs and both instant and gradual data-shift scenarios, such as network bandwidth limitations and fluctuating device thermal states. Although the evaluated algorithms all showed advantages and limitations, our findings demonstrate that Active Inference is a promising approach for ensuring SLO compliance in DCCS, offering lower memory usage, stable CPU utilization, and fast convergence.", 'abstract_zh': '在分布式计算连续系统中确保服务级别目标的挑战及其实验研究：基于主动推断的方法', 'title_zh': '分布式计算 continuum 系统中动态SLO合规性的基准测试'}
{'arxiv_id': 'arXiv:2503.03269', 'title': 'Conformal Transformations for Symmetric Power Transformers', 'authors': 'Saurabh Kumar, Jacob Buckman, Carles Gelada, Sean Zhang', 'link': 'https://arxiv.org/abs/2503.03269', 'abstract': 'Transformers with linear attention offer significant computational advantages over softmax-based transformers but often suffer from degraded performance. The symmetric power (sympow) transformer, a particular type of linear transformer, addresses some of this performance gap by leveraging symmetric tensor embeddings, achieving comparable performance to softmax transformers. However, the finite capacity of the recurrent state in sympow transformers limits their ability to retain information, leading to performance degradation when scaling the training or evaluation context length. To address this issue, we propose the conformal-sympow transformer, which dynamically frees up capacity using data-dependent multiplicative gating and adaptively stores information using data-dependent rotary embeddings. Preliminary experiments on the LongCrawl64 dataset demonstrate that conformal-sympow overcomes the limitations of sympow transformers, achieving robust performance across scaled training and evaluation contexts.', 'abstract_zh': '线性注意力变换器与基于softmax的变换器相比提供了显著的计算优势，但常常性能较差。对称幂（sympow）变换器作为一种特殊的线性变换器，通过利用对称张量嵌入，弥补部分性能差距，实现与基于softmax变换器相当的性能。然而，sympow变换器循环状态的有限容量限制了其信息保留能力，导致在扩展训练或评估上下文长度时性能下降。为解决这一问题，我们提出了一种符合性-sympow变换器，该变换器通过数据依赖的乘法门控动态释放容量，并使用数据依赖的旋转嵌入适当地存储信息。初步实验表明，符合性-sympow克服了sympow变换器的局限性，在扩展的训练和评估上下文中实现了稳健的性能。', 'title_zh': '对称电力变压器的共形变换'}
{'arxiv_id': 'arXiv:2503.03211', 'title': 'NodeReg: Mitigating the Imbalance and Distribution Shift Effects in Semi-Supervised Node Classification via Norm Consistency', 'authors': 'Shenzhi Yang, Jun Xia, Jingbo Zhou, Xingkai Yao, Xiaofang Zhang', 'link': 'https://arxiv.org/abs/2503.03211', 'abstract': "Aggregating information from neighboring nodes benefits graph neural networks (GNNs) in semi-supervised node classification tasks. Nevertheless, this mechanism also renders nodes susceptible to the influence of their neighbors. For instance, this will occur when the neighboring nodes are imbalanced or the neighboring nodes contain noise, which can even affect the GNN's ability to generalize out of distribution. We find that ensuring the consistency of the norm for node representations can significantly reduce the impact of these two issues on GNNs. To this end, we propose a regularized optimization method called NodeReg that enforces the consistency of node representation norms. This method is simple but effective and satisfies Lipschitz continuity, thus facilitating stable optimization and significantly improving semi-supervised node classification performance under the above two scenarios. To illustrate, in the imbalance scenario, when training a GCN with an imbalance ratio of 0.1, NodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score across five public datasets. Similarly, in the distribution shift scenario, NodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.", 'abstract_zh': '从邻居节点聚合信息有助于图神经网络（GNNs）在半监督节点分类任务中的表现。然而，这种机制也会使节点容易受到邻居节点的影响。例如，这将发生在邻居节点不平衡或邻居节点包含噪声的情况下，甚至可能影响GNN的分布外泛化能力。我们发现确保节点表示范数的一致性可以显著减少这两种问题对GNN的影响。为此，我们提出了一种名为NodeReg的正则化优化方法，该方法强制节点表示范数的一致性。该方法简单而有效，并且满足利普希茨连续性，从而便于稳定优化，并在上述两种情况下大幅提高半监督节点分类性能。以不平衡场景为例，当训练不平衡比为0.1的GCN时，NodeReg在五个公共数据集上的F1分数上比最具竞争力的基线高出1.4%-25.9%。同样，在分布偏移场景中，NodeReg的准确率比最具竞争力的基线高出1.4%-3.1%。', 'title_zh': 'NodeReg: 通过范数一致性缓解半监督节点分类中的类别不平衡和分布偏移效应'}
{'arxiv_id': 'arXiv:2503.03205', 'title': 'MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving', 'authors': 'Ruida Wang, Rui Pan, Yuxin Li, Jipeng Zhang, Yizhen Jia, Shizhe Diao, Renjie Pi, Junjie Hu, Tong Zhang', 'link': 'https://arxiv.org/abs/2503.03205', 'abstract': 'Solving mathematical problems using computer-verifiable languages like Lean has significantly impacted mathematical and computer science communities. State-of-the-art methods utilize single Large Language Models (LLMs) as agents or provers to either generate complete proof or perform tree searches. However, single-agent methods inherently lack a structured way to combine high-level reasoning in Natural Language (NL) with Formal Language (FL) verification feedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought framework, (to the best of our knowledge), the first multi-agent framework for Lean4 theorem proving that balance high-level NL reasoning and FL verification in Long CoT. Using this structured interaction, our approach enables deeper insights and long-term coherence in proof generation, with which past methods struggle. We do this by leveraging emergent formal reasoning ability in Long CoT using our novel LoT-Transfer Learning training-inference pipeline. Extensive experiments show that our framework achieves 54.51% accuracy rate on the Lean4 version of MiniF2F-Test dataset, largely outperforming GPT-4 (22.95%), single-agent tree search (InternLM-Step-Prover, 50.70%), and whole-proof generation (DeepSeek-Prover-v1.5, 48.36%) baselines. Furthermore, our findings highlight the potential of combining Long CoT with formal verification for a more insightful generation in a broader perspective.', 'abstract_zh': '使用类似Lean的计算机验证语言求解数学问题显著影响了数学和计算机科学社区。现有的高级方法利用单个大型语言模型（LLMs）作为代理或证明者来生成完整的证明或执行树搜索。然而，单代理方法本质上缺乏将高级自然语言（NL）推理与形式语言（FL）验证反馈有机结合的结构化方式。为解决这些问题，我们提出MA-LoT：基于Lean的多代理长链推理框架，据我们所知，这是第一个在Lean4定理证明中平衡高级NL推理和长链推理FL验证的多代理框架。通过这种结构化的互动，我们的方法能够在证明生成中提供更深刻的见解和长期连贯性，这是以往方法难以实现的。我们通过利用我们在长链推理中新兴的形式推理能力，使用我们新颖的LoT迁移学习训练-推理管道来实现这一点。广泛的实验结果显示，我们的框架在Lean4版本的MiniF2F-Test数据集上的准确率为54.51%，大幅优于GPT-4（22.95%）、单代理树搜索（InternLM-Step-Prover，50.70%）和完整证明生成（DeepSeek-Prover-v1.5，48.36%）基准。此外，我们的研究结果强调了将长链推理与形式验证结合以从更广泛的角度实现更深入生成的潜力。', 'title_zh': 'MA-LoT：基于多智能体学习的长推理链增强形式定理证明'}
{'arxiv_id': 'arXiv:2503.03201', 'title': 'Towards Robust Universal Information Extraction: Benchmark, Evaluation, and Solution', 'authors': 'Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2503.03201', 'abstract': "In this paper, we aim to enhance the robustness of Universal Information Extraction (UIE) by introducing a new benchmark dataset, a comprehensive evaluation, and a feasible solution. Existing robust benchmark datasets have two key limitations: 1) They generate only a limited range of perturbations for a single Information Extraction (IE) task, which fails to evaluate the robustness of UIE models effectively; 2) They rely on small models or handcrafted rules to generate perturbations, often resulting in unnatural adversarial examples. Considering the powerful generation capabilities of Large Language Models (LLMs), we introduce a new benchmark dataset for Robust UIE, called RUIE-Bench, which utilizes LLMs to generate more diverse and realistic perturbations across different IE tasks. Based on this dataset, we comprehensively evaluate existing UIE models and reveal that both LLM-based models and other models suffer from significant performance drops. To improve robustness and reduce training costs, we propose a data-augmentation solution that dynamically selects hard samples for iterative training based on the model's inference loss. Experimental results show that training with only \\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative performance improvement across three IE tasks.", 'abstract_zh': '本文aiming to提升Universal Information Extraction (UIE)的 robustness，通过引入一个新的基准数据集、全面的评估和可行的解决方案。考虑到大型语言模型的强大生成能力，我们提出一个新的robust UIE基准数据集RUIE-Bench，利用大型语言模型生成更多样化和真实的扰动，适用于不同信息提取任务。基于此数据集，我们全面评估了现有UIE模型，并发现基于大型语言模型的模型和其他模型均遭受显著性能下降。为了提高robustness并减少训练成本，我们提出了一种数据增强解决方案，该方案根据模型的推理损失动态选择困难样本进行迭代训练。实验结果表明，仅使用数据的\\textbf{15\\%}进行训练，在三个信息提取任务上的相对性能平均提高\\textbf{7.5\\%}。', 'title_zh': '面向鲁棒通用信息提取：基准、评估与解决方案'}
{'arxiv_id': 'arXiv:2503.03197', 'title': 'Directly Follows Graphs Go Predictive Process Monitoring With Graph Neural Networks', 'authors': 'Attila Lischka, Simon Rauch, Oliver Stritzel', 'link': 'https://arxiv.org/abs/2503.03197', 'abstract': 'In the past years, predictive process monitoring (PPM) techniques based on artificial neural networks have evolved as a method to monitor the future behavior of business processes. Existing approaches mostly focus on interpreting the processes as sequences, so-called traces, and feeding them to neural architectures designed to operate on sequential data such as recurrent neural networks (RNNs) or transformers. In this study, we investigate an alternative way to perform PPM: by transforming each process in its directly-follows-graph (DFG) representation we are able to apply graph neural networks (GNNs) for the prediction tasks. By this, we aim to develop models that are more suitable for complex processes that are long and contain an abundance of loops. In particular, we present different ways to create DFG representations depending on the particular GNN we use. The tested GNNs range from classical node-based to novel edge-based architectures. Further, we investigate the possibility of using multi-graphs. By these steps, we aim to design graph representations that minimize the information loss when transforming traces into graphs.', 'abstract_zh': '近年来，基于人工神经网络的预测过程监控（PPM）技术演化成为监测业务过程未来行为的一种方法。现有方法主要侧重于将过程视为序列，即所谓的轨迹，并将它们输入到适用于序列数据的操作架构，如循环神经网络（RNNs）或变压器中。在本研究中，我们探索了一种替代的PPM方式：通过将每个过程转化为直接跟随图（DFG）表示，我们能够应用图神经网络（GNNs）进行预测任务。通过这种方式，我们旨在开发更适合复杂、长且包含大量循环的过程的模型。特别是，我们根据不同所使用的GNN提出了不同的DFG表示方法。测试的GNN包括经典的节点基架构和新颖的边基架构。另外，我们还探讨了使用多图的可能性。通过上述步骤，我们旨在设计图表示方法，以最大限度地减少将轨迹转换为图时的信息损失。', 'title_zh': '直接跟随图实现基于图神经网络的预测性过程监控'}
{'arxiv_id': 'arXiv:2503.03172', 'title': 'Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for Stance Detection', 'authors': 'Gibson Nkhata, Susan Gauch', 'link': 'https://arxiv.org/abs/2503.03172', 'abstract': 'Stance Detection (SD) on social media has emerged as a prominent area of interest with implications for social business and political applications thereby garnering escalating research attention within NLP. The inherent subtlety and complexity of texts procured from online platforms pose challenges for SD algorithms in accurately discerning the authors stance. Mostly the inclusion of sarcastic and figurative language drastically impacts the performance of SD models. This paper addresses this by employing sarcasm detection intermediate-task transfer learning tailored for SD. The proposed methodology involves the finetuning of BERT and RoBERTa and the concatenation of convolutional BiLSTM and dense layers. Rigorous experiments are conducted on publicly available datasets to evaluate our transfer-learning framework. The performance of the approach is assessed against various State-Of-The-Art baselines for SD providing empirical evidence of its effectiveness. Notably our model outperforms the best SOTA models even prior to sarcasm-detection pretraining. The integration of sarcasm knowledge into the model proves instrumental in mitigating misclassifications of sarcastic textual elements in SD. Our model accurately predicts 85% of texts that were previously misclassified by the model without sarcasm-detection pretraining thereby amplifying the average F1-score of the model. Our experiments also revealed that the success of the transfer-learning framework is contingent upon the correlation of lexical attributes between the intermediate task and the target task. This study represents the first exploration of sarcasm detection as an intermediate transfer-learning task in the context of SD and simultaneously uses the concatenation of BERT or RoBERTa with other deep-learning techniques establishing the proposed approach as a foundational baseline for future research endeavors in this domain.', 'abstract_zh': '社交媒体中的立场检测（SD）已成为一个重要的研究领域，对社交商业和政治应用具有重要影响，因此在自然语言处理（NLP）领域吸引了越来越多的研究关注。来源于在线平台的文本隐含的细微性和复杂性给SD算法准确识别作者立场带来了挑战。特别是 sarcastic 和比喻语言的加入严重影响了SD模型的表现。本文通过针对SD的应用进行讽刺检测的中间任务迁移学习来应对这一挑战。提出的这种方法涉及对BERT和RoBERTa的微调，以及卷积双向LSTM和密集层的连接。在公开可用的数据集上进行了严格实验以评估我们的迁移学习框架。将该方法与各种最新的SD基线进行比较，提供了其有效性的实证证据。值得注意的是，在讽刺检测预训练之前，我们的模型的性能就已经优于最先进的模型。将讽刺知识整合到模型中，对于缓解SD中讽刺文本元素的误分类起到了重要作用。我们的模型准确预测了85%之前由未进行讽 刺检测预训练的模型误分类的文本，从而提高了模型的平均F1分数。实验还表明，迁移学习框架的成功取决于中间任务和目标任务的词形特征的相关性。本研究是首次在SD背景下将讽刺检测作为中间迁移学习任务进行探索，并结合BERT或RoBERTa与其他深度学习技术的连接，使提出的方法成为未来该领域研究的基础。', 'title_zh': '中介任务迁移学习：利用讽刺检测促进立场检测'}
{'arxiv_id': 'arXiv:2503.03156', 'title': 'DiRe-JAX: A JAX based Dimensionality Reduction Algorithm for Large-scale Data', 'authors': 'Alexander Kolpakov, Igor Rivin', 'link': 'https://arxiv.org/abs/2503.03156', 'abstract': 'DiRe-JAX is a new dimensionality reduction toolkit designed to address some of the challenges faced by traditional methods like UMAP and tSNE such as loss of global structure and computational efficiency. Built on the JAX framework, DiRe leverages modern hardware acceleration to provide an efficient, scalable, and interpretable solution for visualizing complex data structures, and for quantitative analysis of lower-dimensional embeddings. The toolkit shows considerable promise in preserving both local and global structures within the data as compare to state-of-the-art UMAP and tSNE implementations. This makes it suitable for a wide range of applications in machine learning, bioinformatics, and data science.', 'abstract_zh': 'DiRe-JAX 是一个新颖的降维工具包，旨在解决传统方法如 UMAP 和 tSNE 面临的全球结构丢失和计算效率低下的挑战。基于 JAX 框架，DiRe 利用现代硬件加速提供了一个高效、可扩展且可解释的方案，用于可视化复杂的数据结构，并对低维嵌入进行定量分析。该工具包在保留数据的局部和全局结构方面表现出色，优于最先进的UMAP和tSNE实现，使其在机器学习、生物信息学和数据科学等领域具有广泛的应用前景。', 'title_zh': 'DiRe-JAX：一种基于JAX的大规模数据降维算法'}
{'arxiv_id': 'arXiv:2503.03150', 'title': 'Position: Model Collapse Does Not Mean What You Think', 'authors': 'Rylan Schaeffer, Joshua Kazdan, Alvan Caleb Arulandu, Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2503.03150', 'abstract': "The proliferation of AI-generated content online has fueled concerns over \\emph{model collapse}, a degradation in future generative models' performance when trained on synthetic data generated by earlier models. Industry leaders, premier research journals and popular science publications alike have prophesied catastrophic societal consequences stemming from model collapse. In this position piece, we contend this widespread narrative fundamentally misunderstands the scientific evidence. We highlight that research on model collapse actually encompasses eight distinct and at times conflicting definitions of model collapse, and argue that inconsistent terminology within and between papers has hindered building a comprehensive understanding of model collapse. To assess how significantly different interpretations of model collapse threaten future generative models, we posit what we believe are realistic conditions for studying model collapse and then conduct a rigorous assessment of the literature's methodologies through this lens. While we leave room for reasonable disagreement, our analysis of research studies, weighted by how faithfully each study matches real-world conditions, leads us to conclude that certain predicted claims of model collapse rely on assumptions and conditions that poorly match real-world conditions, and in fact several prominent collapse scenarios are readily avoidable. Altogether, this position paper argues that model collapse has been warped from a nuanced multifaceted consideration into an oversimplified threat, and that the evidence suggests specific harms more likely under society's current trajectory have received disproportionately less attention.", 'abstract_zh': 'AI生成内容的泛滥加剧了对未来生成模型性能下降的担忧：模型崩溃的认知偏差及其评估', 'title_zh': '位置：模型坍塌并不如你所想'}
{'arxiv_id': 'arXiv:2503.03140', 'title': 'Knowledge Augmentation in Federation: Rethinking What Collaborative Learning Can Bring Back to Decentralized Data', 'authors': 'Wentai Wu, Yingliang Wu', 'link': 'https://arxiv.org/abs/2503.03140', 'abstract': "Data, as an observable form of knowledge, has become one of the most important factors of production for the development of Artificial Intelligence (AI). Meanwhile, increasing legislation and regulations on private and proprietary information results in scattered data sources also known as the ``data islands''. Although some collaborative learning paradigms such as Federated Learning (FL) can enable privacy-preserving training over decentralized data, they have inherent deficiencies in fairness, costs and reproducibility because of being learning-centric, which greatly limits the way how participants cooperate with each other. In light of this, we present a knowledge-centric paradigm termed \\emph{Knowledge Augmentation in Federation} (KAF), with focus on how to enhance local knowledge through collaborative effort. We provide the suggested system architecture, formulate the prototypical optimization objective, and review emerging studies that employ methodologies suitable for KAF. On our roadmap, with a three-way categorization we describe the methods for knowledge expansion, knowledge filtering, and label and feature space correction in the federation. Further, we highlight several challenges and open questions that deserve more attention from the community. With our investigation, we intend to offer new insights for what collaborative learning can bring back to decentralized data.", 'abstract_zh': '基于知识为中心的知识增强联合会知识增益与联邦学习', 'title_zh': '联邦学习中的知识增强：重塑协作学习对去中心化数据的贡献'}
{'arxiv_id': 'arXiv:2503.03139', 'title': 'Convergence Analysis of Federated Learning Methods Using Backward Error Analysis', 'authors': 'Jinwoo Lim, Suhyun Kim, Soo-Mook Moon', 'link': 'https://arxiv.org/abs/2503.03139', 'abstract': 'Backward error analysis allows finding a modified loss function, which the parameter updates really follow under the influence of an optimization method. The additional loss terms included in this modified function is called implicit regularizer. In this paper, we attempt to find the implicit regularizer for various federated learning algorithms on non-IID data distribution, and explain why each method shows different convergence behavior. We first show that the implicit regularizer of FedAvg disperses the gradient of each client from the average gradient, thus increasing the gradient variance. We also empirically show that the implicit regularizer hampers its convergence. Similarly, we compute the implicit regularizers of FedSAM and SCAFFOLD, and explain why they converge better. While existing convergence analyses focus on pointing out the advantages of FedSAM and SCAFFOLD, our approach can explain their limitations in complex non-convex settings. In specific, we demonstrate that FedSAM can partially remove the bias in the first-order term of the implicit regularizer in FedAvg, whereas SCAFFOLD can fully eliminate the bias in the first-order term, but not in the second-order term. Consequently, the implicit regularizer can provide a useful insight on the convergence behavior of federated learning from a different theoretical perspective.', 'abstract_zh': 'backward误差分析允许找到一个修改后的损失函数，参数更新在优化方法影响下确实遵循该函数。此修改函数中包含的额外损失项称为隐式正则化器。本文尝试在非IID数据分布下为各种联邦学习算法找到隐式正则化器，并解释为什么每种方法表现出不同的收敛行为。我们首先表明，FedAvg的隐式正则化器使每个客户端的梯度分散到平均梯度之外，从而增加了梯度方差。我们还通过实验表明，隐式正则化器阻碍了其收敛。类似地，我们计算了FedSAM和SCAFFOLD的隐式正则化器，并解释了它们为什么能够更好地收敛。现有收敛性分析主要强调了FedSAM和SCAFFOLD的优点，而我们的方法可以解释它们在复杂非凸设置下的局限性。具体来说，我们证明了FedSAM可以部分消除FedAvg隐式正则化器中的一阶项偏差，而SCAFFOLD可以完全消除一阶项偏差，但不能消除二阶项偏差。因此，隐式正则化器可以从不同的理论角度提供有关联邦学习收敛行为的有用洞察。', 'title_zh': '联邦学习方法的回向误差分析收敛性分析'}
{'arxiv_id': 'arXiv:2503.03129', 'title': 'Exploring Neural Ordinary Differential Equations as Interpretable Healthcare classifiers', 'authors': 'Shi Li', 'link': 'https://arxiv.org/abs/2503.03129', 'abstract': 'Deep Learning has emerged as one of the most significant innovations in machine learning. However, a notable limitation of this field lies in the ``black box" decision-making processes, which have led to skepticism within groups like healthcare and scientific communities regarding its applicability. In response, this study introduces a interpretable approach using Neural Ordinary Differential Equations (NODEs), a category of neural network models that exploit the dynamics of differential equations for representation learning. Leveraging their foundation in differential equations, we illustrate the capability of these models to continuously process textual data, marking the first such model of its kind, and thereby proposing a promising direction for future research in this domain. The primary objective of this research is to propose a novel architecture for groups like healthcare that require the predictive capabilities of deep learning while emphasizing the importance of model transparency demonstrated in NODEs.', 'abstract_zh': '深度学习已成为机器学习中最重要的创新之一。然而，这一领域的显著局限在于其“黑箱”决策过程，这导致了像医疗和科学界这样的群体对其适用性的疑虑。为应对这一问题，本研究引入了一种基于神经常微分方程（NODEs）的可解释方法，这是一种利用微分方程动态进行表示学习的神经网络模型类别。借助微分方程的基础，我们展示了这些模型连续处理文本数据的能力，这是此类模型中的首创，从而为该领域的未来研究提出了一个有前景的方向。本研究的主要目标是为需要深度学习预测能力且强调模型透明度的医疗等群体提出一种新的架构。', 'title_zh': '探索神经常微分方程作为可解释的医疗分类器'}
{'arxiv_id': 'arXiv:2503.03122', 'title': 'The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models', 'authors': 'Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun', 'link': 'https://arxiv.org/abs/2503.03122', 'abstract': 'Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language Models (LLMs) with human preferences, particularly as LLMs increasingly interact with multimodal data. However, we find that MM-RMs trained on existing datasets often struggle to generalize to out-of-distribution data due to their reliance on unimodal spurious correlations, primarily text-only shortcuts within the training distribution, which prevents them from leveraging true multimodal reward functions. To address this, we introduce a Shortcut-aware MM-RM learning algorithm that mitigates this issue by dynamically reweighting training samples, shifting the distribution toward better multimodal understanding, and reducing dependence on unimodal spurious correlations. Our experiments demonstrate significant improvements in generalization, downstream task performance, and scalability, establishing a more robust framework for multimodal reward modeling.', 'abstract_zh': '多模态奖励模型（MM-RMs）对于将大型语言模型（LLMs）与人类偏好对齐至关重要，尤其是在LLMs越来越多地与多模态数据互动时。然而，我们发现，现有数据集训练的MM-RMs往往难以泛化到分布外数据，这是因为它们依赖于单模态假相关，主要是训练分布中的文本-only捷径，这阻碍了它们利用真正的多模态奖励函数。为此，我们提出了一种意识捷径的MM-RM学习算法，通过动态重新加权训练样本、调整分布以提高多模态理解能力，并减少对单模态假相关的依赖，来解决这一问题。我们的实验展示了泛化能力、下游任务性能和可扩展性方面的显著提高，从而建立了一个更 robust的多模态奖励建模框架。', 'title_zh': '细节决定一切：应对单模态虚假相关性以构建可泛化的多模态奖励模型'}
{'arxiv_id': 'arXiv:2503.03112', 'title': 'A Multimodal Framework for Topic Propagation Classification in Social Networks', 'authors': 'Yuchuan Jiang, Chaolong Jia, Yunyi Qin, Wei Cai, Yongsen Qian', 'link': 'https://arxiv.org/abs/2503.03112', 'abstract': 'The rapid proliferation of the Internet and the widespread adoption of social networks have significantly accelerated information dissemination. However, this transformation has introduced complexities in information capture and processing, posing substantial challenges for researchers and practitioners. Predicting the dissemination of topic-related information within social networks has thus become a critical research focus. This paper proposes a predictive model for topic dissemination in social networks by integrating multidimensional features derived from key dissemination characteristics. Specifically, we introduce two novel indicators, user relationship breadth and user authority, into the PageRank algorithm to quantify user influence more effectively. Additionally, we employ a Text-CNN model for sentiment classification, extracting sentiment features from textual content. Temporal embeddings of nodes are encoded using a Bi-LSTM model to capture temporal dynamics. Furthermore, we refine the measurement of user interaction traces with topics, replacing traditional topic view metrics with a more precise communication characteristics measure. Finally, we integrate the extracted multidimensional features using a Transformer model, significantly enhancing predictive performance. Experimental results demonstrate that our proposed model outperforms traditional machine learning and unimodal deep learning models in terms of FI-Score, AUC, and Recall, validating its effectiveness in predicting topic propagation within social networks.', 'abstract_zh': '互联网的迅速普及和社会网络的广泛应用极大地加速了信息传播。然而，这一转变增加了信息捕获和处理的复杂性，给研究人员和实践者带来了重大挑战。因此，预测社会网络中主题相关信息的传播成为了一个关键的研究focus。本文通过整合来自关键传播特征的多维度特征，提出了一种预测社会网络中主题传播的模型。具体而言，我们引入了两种新的指标——用户关系广度和用户权威性，以更有效地量化用户影响。此外，我们使用Text-CNN模型进行情感分类，从文本内容中提取情感特征。节点的时间嵌入使用Bi-LSTM模型进行编码，以捕获时间动态。同时，我们改进了用户与主题互动轨迹的度量，用更精确的通信特性度量替代了传统的主题视图指标。最后，我们使用Transformer模型整合提取的多维度特征，显著提高了预测性能。实验结果表明，我们提出的模型在FI-Score、AUC和Recall方面优于传统的机器学习和单模态深度学习模型，证实了其在预测社会网络传播方面的效果。', 'title_zh': '多模态框架在社交媒体中的主题传播分类'}
{'arxiv_id': 'arXiv:2503.03084', 'title': 'Hopfield Networks Meet Big Data: A Brain-Inspired Deep Learning Framework for Semantic Data Linking', 'authors': 'Ashwin Viswanathan Kannan, Johnson P Thomas, Abhimanyu Mukerji', 'link': 'https://arxiv.org/abs/2503.03084', 'abstract': 'The exponential rise in data generation has led to vast, heterogeneous datasets crucial for predictive analytics and decision-making. Ensuring data quality and semantic integrity remains a challenge. This paper presents a brain-inspired distributed cognitive framework that integrates deep learning with Hopfield networks to identify and link semantically related attributes across datasets. Modeled on the dual-hemisphere functionality of the human brain, the right hemisphere assimilates new information while the left retrieves learned representations for association. Our architecture, implemented on MapReduce with Hadoop Distributed File System (HDFS), leverages deep Hopfield networks as an associative memory mechanism to enhance recall of frequently co-occurring attributes and dynamically adjust relationships based on evolving data patterns. Experiments show that associative imprints in Hopfield memory are reinforced over time, ensuring linked datasets remain contextually meaningful and improving data disambiguation and integration accuracy. Our results indicate that combining deep Hopfield networks with distributed cognitive processing offers a scalable, biologically inspired approach to managing complex data relationships in large-scale environments.', 'abstract_zh': '数据生成的指数级增长导致了预测分析和决策制定中至关重要的大量异质性数据集。确保数据质量和语义完整性仍是一项挑战。本文提出了一种受脑启发的分布式认知框架，将深度学习与霍普菲尔德网络结合，以跨数据集识别和链接语义相关属性。该框架借鉴了人脑双半球的功能，在右侧半球吸收新信息的同时，左侧半球检索已学习的表示进行关联。我们的架构基于MapReduce在Hadoop分布式文件系统（HDFS）上实现，利用深度霍普菲尔德网络作为联想记忆机制，增强频繁共现属性的回忆能力，并根据不断变化的数据模式动态调整关系。实验表明，霍普菲尔德记忆中的联想印记随时间增强，确保链接数据集保持上下文相关性，提高数据去混淆和集成准确性。我们的结果表明，将深度霍普菲尔德网络与分布式认知处理结合，提供了一种在大规模环境中管理复杂数据关系的可扩展、生物启发式方法。', 'title_zh': 'Hopfield网络遇见大数据：一种受脑启发的深度学习框架用于语义数据链接'}
{'arxiv_id': 'arXiv:2503.03062', 'title': 'Semi-Supervised In-Context Learning: A Baseline Study', 'authors': 'Zhengyao Gu, Henry Peng Zou, Yankai Chen, Aiwei Liu, Weizhi Zhang, Philip S. Yu', 'link': 'https://arxiv.org/abs/2503.03062', 'abstract': 'Most existing work in data selection for In-Context Learning (ICL) has focused on constructing demonstrations from ground truth annotations, with limited attention given to selecting reliable self-generated annotations. In this work, we propose a three-step semi-supervised ICL framework: annotation generation, demonstration selection, and semi-supervised inference. Our baseline, Naive-SemiICL, which prompts select high-confidence self-generated demonstrations for ICL prompting, outperforms a 16-shot baseline by an average of 9.94% across 16 datasets. We further introduce IterPSD, an annotation approach that refines pseudo-demonstrations iteratively, achieving up to 6.8% additional gains in classification tasks. Lastly, we reveal a scaling law for semi-supervised ICL, where models achieve optimal performance with over 1,000 demonstrations.', 'abstract_zh': '现有的大多数数据选择工作主要集中在从ground truth注释中构建示例，对选择可靠的自动生成注释关注不足。本文提出了一种三步半监督In-Context Learning (ICL)框架：注释生成、示例选择和半监督推理。我们的基线Naive-SemiICL通过提示选择高置信度的自动生成示例用于ICL提示，相比16-shot基线，在16个数据集上平均提升了9.94%。我们进一步引入了IterPSD迭代伪示例精炼方法，在分类任务中实现了高达6.8%的额外增益。最后，我们揭示了半监督ICL的扩展规律，即模型在超过1,000个示例时达到最优性能。', 'title_zh': '半监督上下文学习： baseline 研究'}
{'arxiv_id': 'arXiv:2503.02951', 'title': 'KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding', 'authors': 'Zhangchen Xu, Yang Liu, Yueqin Yin, Mingyuan Zhou, Radha Poovendran', 'link': 'https://arxiv.org/abs/2503.02951', 'abstract': 'We introduce KodCode, a synthetic dataset that addresses the persistent challenge of acquiring high-quality, verifiable training data across diverse difficulties and domains for training Large Language Models for coding. Existing code-focused resources typically fail to ensure either the breadth of coverage (e.g., spanning simple coding tasks to advanced algorithmic problems) or verifiable correctness (e.g., unit tests). In contrast, KodCode comprises question-solution-test triplets that are systematically validated via a self-verification procedure. Our pipeline begins by synthesizing a broad range of coding questions, then generates solutions and test cases with additional attempts allocated to challenging problems. Finally, post-training data synthesis is done by rewriting questions into diverse formats and generating responses under a test-based reject sampling procedure from a reasoning model (DeepSeek R1). This pipeline yields a large-scale, robust and diverse coding dataset. KodCode is suitable for supervised fine-tuning and the paired unit tests also provide great potential for RL tuning. Fine-tuning experiments on coding benchmarks (HumanEval(+), MBPP(+), BigCodeBench, and LiveCodeBench) demonstrate that KodCode-tuned models achieve state-of-the-art performance, surpassing models like Qwen2.5-Coder-32B-Instruct and DeepSeek-R1-Distill-Llama-70B.', 'abstract_zh': 'KodCode：一种针对编码大型语言模型训练的合成数据集', 'title_zh': 'KodCode: 一个多样、具有挑战性且可验证的合成编码数据集'}
{'arxiv_id': 'arXiv:2503.02918', 'title': 'Straight-Line Diffusion Model for Efficient 3D Molecular Generation', 'authors': 'Yuyan Ni, Shikun Feng, Haohan Chi, Bowen Zheng, Huan-ang Gao, Wei-Ying Ma, Zhi-Ming Ma, Yanyan Lan', 'link': 'https://arxiv.org/abs/2503.02918', 'abstract': 'Diffusion-based models have shown great promise in molecular generation but often require a large number of sampling steps to generate valid samples. In this paper, we introduce a novel Straight-Line Diffusion Model (SLDM) to tackle this problem, by formulating the diffusion process to follow a linear trajectory. The proposed process aligns well with the noise sensitivity characteristic of molecular structures and uniformly distributes reconstruction effort across the generative process, thus enhancing learning efficiency and efficacy. Consequently, SLDM achieves state-of-the-art performance on 3D molecule generation benchmarks, delivering a 100-fold improvement in sampling efficiency. Furthermore, experiments on toy data and image generation tasks validate the generality and robustness of SLDM, showcasing its potential across diverse generative modeling domains.', 'abstract_zh': '基于扩散的模型在分子生成中展现出了巨大的潜力，但通常需要大量的采样步骤来生成有效的样本。本文提出了一种新型的直线扩散模型（SLDM），通过将扩散过程设计为线性轨迹来解决这一问题。提出的进程与分子结构的噪声敏感特性相契合，并在生成过程中均匀分布重建努力，从而提高学习效率和效果。因此，SLDM 在3D分子生成基准测试中实现了最新的技术水平，采样效率提高了100倍。此外，对玩具数据和图像生成任务的实验验证了SLDM 的普遍性和鲁棒性，展示了其在多种生成建模领域的潜力。', 'title_zh': '直线扩散模型用于高效的3D分子生成'}
{'arxiv_id': 'arXiv:2503.02905', 'title': 'Machine Learning Applications to Diffuse Reflectance Spectroscopy in Optical Diagnosis; A Systematic Review', 'authors': "Nicola Rossberg, Celina L. Li, Simone Innocente, Stefan Andersson-Engels, Katarzyna Komolibus, Barry O'Sullivan, Andrea Visentin", 'link': 'https://arxiv.org/abs/2503.02905', 'abstract': 'Diffuse Reflectance Spectroscopy has demonstrated a strong aptitude for identifying and differentiating biological tissues. However, the broadband and smooth nature of these signals require algorithmic processing, as they are often difficult for the human eye to distinguish. The implementation of machine learning models for this task has demonstrated high levels of diagnostic accuracies and led to a wide range of proposed methodologies for applications in various illnesses and conditions. In this systematic review, we summarise the state of the art of these applications, highlight current gaps in research and identify future directions. This review was conducted in accordance with the PRISMA guidelines. 77 studies were retrieved and in-depth analysis was conducted. It is concluded that diffuse reflectance spectroscopy and machine learning have strong potential for tissue differentiation in clinical applications, but more rigorous sample stratification in tandem with in-vivo validation and explainable algorithm development is required going forward.', 'abstract_zh': '弥散反射光谱技术在生物组织识别与分类中的应用已经展现了强大的能力，但由于这些信号具有宽带和平滑的特点，通常难以直接由人眼区分，因此需要算法处理。机器学习模型在此任务中的应用已经显示出高水平的诊断准确性，并提出了一系列应用于各种疾病和状况的方法。在本系统评价中，我们总结了这些应用的最新进展，指出了当前研究中的空白，并确定了未来的研究方向。该评价遵循PRISMA指南，共检索到77项研究，并进行了深入分析。研究结论认为，弥散反射光谱技术和机器学习在临床应用中具有强大的组织分类潜力，但未来需要更严格的样本分层、体内验证以及可解释算法的开发。', 'title_zh': '机器学习在光学诊断中偏振反射光谱学中的应用：一项系统性回顾'}
{'arxiv_id': 'arXiv:2503.02895', 'title': 'Adaptive Entanglement Routing with Deep Q-Networks in Quantum Networks', 'authors': 'Lamarana Jallow, Majid Iqbal Khan', 'link': 'https://arxiv.org/abs/2503.02895', 'abstract': 'The quantum internet holds transformative potential for global communication by harnessing the principles of quantum information processing. Despite significant advancements in quantum communication technologies, the efficient distribution of critical resources, such as qubits, remains a persistent and unresolved challenge. Conventional approaches often fall short of achieving optimal resource allocation, underscoring the necessity for more effective solutions. This study proposes a novel reinforcement learning-based adaptive entanglement routing framework designed to enable resource allocation tailored to the specific demands of quantum applications. The introduced QuDQN model utilizes reinforcement learning to optimize the management of quantum networks, allocate resources efficiently, and enhance entanglement routing. The model integrates key considerations, including fidelity requirements, network topology, qubit capacity, and request demands.', 'abstract_zh': '量子互联网通过利用量子信息处理原理，在全球通信方面展现出变革性的潜力。尽管在量子通信技术方面取得了显著进展，但有效分发关键资源（如量子比特）仍然是一个持久而未解决的挑战。传统方法往往无法实现最优资源分配，凸显了更有效解决方案的必要性。本研究提出了一种新型的基于强化学习的自适应纠缠路由框架，旨在实现针对量子应用特定需求的资源分配。引入的QuDQN模型利用强化学习优化量子网络的管理、高效分配资源并增强纠缠路由。该模型整合了信度要求、网络拓扑、量子比特容量和请求需求等关键考虑因素。', 'title_zh': '基于深度Q网络的量子网络自适应纠缠路由'}
{'arxiv_id': 'arXiv:2503.02890', 'title': 'Predicting Cascade Failures in Interdependent Urban Infrastructure Networks', 'authors': 'Yinzhou Tang, Jinghua Piao, Huandong Wang, Shaw Rajib, Yong Li', 'link': 'https://arxiv.org/abs/2503.02890', 'abstract': 'Cascading failures (CF) entail component breakdowns spreading through infrastructure networks, causing system-wide collapse. Predicting CFs is of great importance for infrastructure stability and urban function. Despite extensive research on CFs in single networks such as electricity and road networks, interdependencies among diverse infrastructures remain overlooked, and capturing intra-infrastructure CF dynamics amid complex evolutions poses challenges. To address these gaps, we introduce the \\textbf{I}ntegrated \\textbf{I}nterdependent \\textbf{I}nfrastructure CF model ($I^3$), designed to capture CF dynamics both within and across infrastructures. $I^3$ employs a dual GAE with global pooling for intra-infrastructure dynamics and a heterogeneous graph for inter-infrastructure interactions. An initial node enhancement pre-training strategy mitigates GCN-induced over-smoothing. Experiments demonstrate $I^3$ achieves a 31.94\\% in terms of AUC, 18.03\\% in terms of Precision, 29.17\\% in terms of Recall, 22.73\\% in terms of F1-score boost in predicting infrastructure failures, and a 28.52\\% reduction in terms of RMSE for cascade volume forecasts compared to leading models. It accurately pinpoints phase transitions in interconnected and singular networks, rectifying biases in models tailored for singular networks. Access the code at this https URL.', 'abstract_zh': '集成相互依赖基础设施 cascading 失败模型（$I^3$）：捕捉基础设施内及之间的 cascading 失败动态', 'title_zh': '预测互依城市基础设施网络中的级联故障'}
{'arxiv_id': 'arXiv:2503.02889', 'title': 'Function-Coherent Gambles with Non-Additive Sequential Dynamics', 'authors': 'Gregory Wheeler', 'link': 'https://arxiv.org/abs/2503.02889', 'abstract': 'The desirable gambles framework provides a rigorous foundation for imprecise probability theory but relies heavily on linear utility via its coherence axioms. In our related work, we introduced function-coherent gambles to accommodate non-linear utility. However, when repeated gambles are played over time -- especially in intertemporal choice where rewards compound multiplicatively -- the standard additive combination axiom fails to capture the appropriate long-run evaluation. In this paper we extend the framework by relaxing the additive combination axiom and introducing a nonlinear combination operator that effectively aggregates repeated gambles in the log-domain. This operator preserves the time-average (geometric) growth rate and addresses the ergodicity problem. We prove the key algebraic properties of the operator, discuss its impact on coherence, risk assessment, and representation, and provide a series of illustrative examples. Our approach bridges the gap between expectation values and time averages and unifies normative theory with empirically observed non-stationary reward dynamics.', 'abstract_zh': '可Desirable Gamble框架提供了不精确概率理论的严谨基础，但依赖于通过共融公理体现的线性效用。在我们相关工作中，我们引入了函数共融赌注以容纳非线性效用。然而，在随着时间重复进行赌注，尤其是在跨时间选择中奖励呈乘性复合时，标准的加性组合公理无法捕捉到适当的长期评价。在本文中，我们通过放宽加性组合公理并引入一个在对数域中有效聚合重复赌注的非线性组合算子来扩展该框架。该算子保留了时间平均（几何）增长速率并解决了遍历性问题。我们证明了该算子的关键代数性质，讨论了其对共融、风险评估和表示的影响，并提供了系列说明性例子。我们的方法在期望值和时间平均之间架起桥梁，并将规范理论与实际观测到的非稳定奖励动态统一起来。', 'title_zh': '功能共轭赌度与非增量序列动力学'}
{'arxiv_id': 'arXiv:2503.02068', 'title': 'Interactive Debugging and Steering of Multi-Agent AI Systems', 'authors': 'Will Epperson, Gagan Bansal, Victor Dibia, Adam Fourney, Jack Gerrits, Erkang Zhu, Saleema Amershi', 'link': 'https://arxiv.org/abs/2503.02068', 'abstract': 'Fully autonomous teams of LLM-powered AI agents are emerging that collaborate to perform complex tasks for users. What challenges do developers face when trying to build and debug these AI agent teams? In formative interviews with five AI agent developers, we identify core challenges: difficulty reviewing long agent conversations to localize errors, lack of support in current tools for interactive debugging, and the need for tool support to iterate on agent configuration. Based on these needs, we developed an interactive multi-agent debugging tool, AGDebugger, with a UI for browsing and sending messages, the ability to edit and reset prior agent messages, and an overview visualization for navigating complex message histories. In a two-part user study with 14 participants, we identify common user strategies for steering agents and highlight the importance of interactive message resets for debugging. Our studies deepen understanding of interfaces for debugging increasingly important agentic workflows.', 'abstract_zh': '基于大语言模型的AI代理自主团队正在涌现，它们协作以完成复杂的用户任务。开发者在构建和调试这些AI代理团队时面临哪些挑战？通过对五位AI代理开发者进行形成性访谈，我们确定了核心挑战：难以审查长代理对话以定位错误、当前工具在交互式调试方面的支持不足，以及需要工具支持以迭代代理配置。基于这些需求，我们开发了一个交互式多代理调试工具AGDebugger，具有浏览和发送消息的UI、编辑和重置先前代理消息的能力，以及用于导航复杂消息历史的概览可视化视图。在两部分用户研究中，我们确定了用户的常见策略以引导代理，并强调了交互式消息重置对于调试的重要性。我们的研究深化了对调试日益重要的代理工作流界面的理解。', 'title_zh': '多人工智能系统交互式调试与引导'}
{'arxiv_id': 'arXiv:2405.14241', 'title': 'NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation', 'authors': 'Chaokang Jiang, Dalong Du, Jiuming Liu, Siting Zhu, Zhenqiang Liu, Zhuang Ma, Zhujin Liang, Jie Zhou', 'link': 'https://arxiv.org/abs/2405.14241', 'abstract': 'Point Cloud Interpolation confronts challenges from point sparsity, complex spatiotemporal dynamics, and the difficulty of deriving complete 3D point clouds from sparse temporal information. This paper presents NeuroGauss4D-PCI, which excels at modeling complex non-rigid deformations across varied dynamic scenes. The method begins with an iterative Gaussian cloud soft clustering module, offering structured temporal point cloud representations. The proposed temporal radial basis function Gaussian residual utilizes Gaussian parameter interpolation over time, enabling smooth parameter transitions and capturing temporal residuals of Gaussian distributions. Additionally, a 4D Gaussian deformation field tracks the evolution of these parameters, creating continuous spatiotemporal deformation fields. A 4D neural field transforms low-dimensional spatiotemporal coordinates ($x,y,z,t$) into a high-dimensional latent space. Finally, we adaptively and efficiently fuse the latent features from neural fields and the geometric features from Gaussian deformation fields. NeuroGauss4D-PCI outperforms existing methods in point cloud frame interpolation, delivering leading performance on both object-level (DHB) and large-scale autonomous driving datasets (NL-Drive), with scalability to auto-labeling and point cloud densification tasks. The source code is released at this https URL.', 'abstract_zh': '点云插值面临点稀疏性、复杂时空动态以及从稀疏时间信息推导完整3D点云的困难。本文提出NeuroGauss4D-PCI，该方法擅长建模各种动态场景下的复杂非刚性变形。该方法从迭代的高斯云软聚类模块开始，提供结构化的时空点云表示。所提出的时空径向基函数高斯残差使用时间上的高斯参数插值，实现平滑参数过渡并捕捉高斯分布的时空残差。此外，4D高斯变形场追踪这些参数的演变，生成连续的时空变形场。4D神经场将低维时空坐标（x, y, z, t）转换为高维潜在空间。最后，我们自适应且高效地融合来自神经场的潜在特征和来自高斯变形场的几何特征。NeuroGauss4D-PCI在点云帧插值任务中优于现有方法，在对象级别（DHB）和大规模自动驾驶数据集（NL-Drive）上表现出领先性能，并具有自动标注和点云稠密化任务的扩展性。源代码发布于此链接。', 'title_zh': 'NeuroGauss4D-PCI: 4D神经场和高斯变形场的点云插值'}
