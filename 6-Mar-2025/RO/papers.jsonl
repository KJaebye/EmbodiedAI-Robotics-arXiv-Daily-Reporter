{'arxiv_id': 'arXiv:2503.03734', 'title': 'OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction', 'authors': 'Huang Huang, Fangchen Liu, Letian Fu, Tingfan Wu, Mustafa Mukadam, Jitendra Malik, Ken Goldberg, Pieter Abbeel', 'link': 'https://arxiv.org/abs/2503.03734', 'abstract': 'Vision-Language-Action (VLA) models aim to predict robotic actions based on visual observations and language instructions. Existing approaches require fine-tuning pre-trained visionlanguage models (VLMs) as visual and language features are independently fed into downstream policies, degrading the pre-trained semantic alignments. We propose OTTER, a novel VLA architecture that leverages these existing alignments through explicit, text-aware visual feature extraction. Instead of processing all visual features, OTTER selectively extracts and passes only task-relevant visual features that are semantically aligned with the language instruction to the policy transformer. This allows OTTER to keep the pre-trained vision-language encoders frozen. Thereby, OTTER preserves and utilizes the rich semantic understanding learned from large-scale pre-training, enabling strong zero-shot generalization capabilities. In simulation and real-world experiments, OTTER significantly outperforms existing VLA models, demonstrating strong zeroshot generalization to novel objects and environments. Video, code, checkpoints, and dataset: this https URL.', 'abstract_zh': 'Vision-Language-Action (VLA)模型旨在基于视觉观察和语言指令预测机器人行动。我们提出了OTTER，一种新颖的VLA架构，通过显式的、文本意识的视觉特征提取利用这些现有的语义对齐。OTTER仅选择性地提取并与语言指令语义上对齐的任务相关视觉特征，并将其传递给策略变压器，从而使预训练的视觉-语言编码器保持冻结状态。因此，OTTER保留并利用了大规模预训练中学习到的丰富语义理解，实现了强大的零样本泛化能力。在仿真和现实世界实验中，OTTER显著优于现有VLA模型，展示出强大的零样本泛化能力以应对新的对象和环境。视频、代码、检查点和数据集：this https URL。', 'title_zh': 'OTTER：一种具有文本意识视觉特征提取的多模态动作模型'}
{'arxiv_id': 'arXiv:2503.03707', 'title': 'Curating Demonstrations using Online Experience', 'authors': 'Annie S. Chen, Alec M. Lessing, Yuejiang Liu, Chelsea Finn', 'link': 'https://arxiv.org/abs/2503.03707', 'abstract': 'Many robot demonstration datasets contain heterogeneous demonstrations of varying quality. This heterogeneity may benefit policy pre-training, but can hinder robot performance when used with a final imitation learning objective. In particular, some strategies in the data may be less reliable than others or may be underrepresented in the data, leading to poor performance when such strategies are sampled at test time. Moreover, such unreliable or underrepresented strategies can be difficult even for people to discern, and sifting through demonstration datasets is time-consuming and costly. On the other hand, policy performance when trained on such demonstrations can reflect the reliability of different strategies. We thus propose for robots to self-curate based on online robot experience (Demo-SCORE). More specifically, we train and cross-validate a classifier to discern successful policy roll-outs from unsuccessful ones and use the classifier to filter heterogeneous demonstration datasets. Our experiments in simulation and the real world show that Demo-SCORE can effectively identify suboptimal demonstrations without manual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute success rate in the resulting policy compared to the base policy trained with all original demonstrations.', 'abstract_zh': '基于在线机器人经验的自选择框架（Demo-SCORE）筛选异质示范数据集', 'title_zh': '在线经验驱动的演示文稿策展'}
{'arxiv_id': 'arXiv:2503.03662', 'title': 'Adaptive Negative Damping Control for User-Dependent Multi-Terrain Walking Assistance with a Hip Exoskeleton', 'authors': 'Giulia Ramella, Auke Ijspeert, Mohamed Bouri', 'link': 'https://arxiv.org/abs/2503.03662', 'abstract': "Hip exoskeletons are known for their versatility in assisting users across varied scenarios. However, current assistive strategies often lack the flexibility to accommodate for individual walking patterns and adapt to diverse locomotion environments. In this work, we present a novel control strategy that adapts the mechanical impedance of the human-exoskeleton system. We design the hip assistive torques as an adaptive virtual negative damping, which is able to inject energy into the system while allowing the users to remain in control and contribute voluntarily to the movements. Experiments with five healthy subjects demonstrate that our controller reduces the metabolic cost of walking compared to free walking (average reduction of 7.2%), and it preserves the lower-limbs kinematics. Additionally, our method achieves minimal power losses from the exoskeleton across the entire gait cycle (less than 2% negative mechanical power out of the total power), ensuring synchronized action with the users' movements. Moreover, we use Bayesian Optimization to adapt the assistance strength and allow for seamless adaptation and transitions across multi-terrain environments. Our strategy achieves efficient power transmission under all conditions. Our approach demonstrates an individualized, adaptable, and straightforward controller for hip exoskeletons, advancing the development of viable, adaptive, and user-dependent control laws.", 'abstract_zh': '髋部外骨骼在多种场景下提供助力具有灵活性的优势，但当前的助力策略往往缺乏适应个体步行模式和不同运动环境的灵活性。本工作中，我们提出了一种新的控制策略，以适应人类-外骨骼系统中的机械阻抗。我们设计了髋部助力扭力作为适应性的虚拟负阻尼，能够在注入能量的同时允许用户保持控制并自愿贡献于动作。五名健康受试者的实验结果表明，与自由行走相比，我们的控制器降低了行走的代谢成本（平均降低7.2%），同时保持了下肢运动学。此外，我们的方法在整步行周期内实现了最小的外骨骼功率损失（总功率的不到2%负机械功率），确保与用户的动作同步。我们使用贝叶斯优化来适应助力强度，并实现跨多地形环境的无缝适应和过渡。该策略在所有条件下均实现高效的功率传输。我们的方法证明了个性化、适应性和简易性髋部外骨骼控制器的有效性，促进了可行、适应性和用户自依赖控制律的发展。', 'title_zh': '用户依赖的多地形行走辅助髋部外骨骼自适应负阻尼控制'}
{'arxiv_id': 'arXiv:2503.03633', 'title': 'Motion Planning and Control with Unknown Nonlinear Dynamics through Predicted Reachability', 'authors': 'Zhiquan Zhang, Gokul Puthumanaillam, Manav Vora, Melkior Ornik', 'link': 'https://arxiv.org/abs/2503.03633', 'abstract': 'Autonomous motion planning under unknown nonlinear dynamics presents significant challenges. An agent needs to continuously explore the system dynamics to acquire its properties, such as reachability, in order to guide system navigation adaptively. In this paper, we propose a hybrid planning-control framework designed to compute a feasible trajectory toward a target. Our approach involves partitioning the state space and approximating the system by a piecewise affine (PWA) system with constrained control inputs. By abstracting the PWA system into a directed weighted graph, we incrementally update the existence of its edges via affine system identification and reach control theory, introducing a predictive reachability condition by exploiting prior information of the unknown dynamics. Heuristic weights are assigned to edges based on whether their existence is certain or remains indeterminate. Consequently, we propose a framework that adaptively collects and analyzes data during mission execution, continually updates the predictive graph, and synthesizes a controller online based on the graph search outcomes. We demonstrate the efficacy of our approach through simulation scenarios involving a mobile robot operating in unknown terrains, with its unknown dynamics abstracted as a single integrator model.', 'abstract_zh': '在未知非线性动态下的自主运动规划面临重大挑战。本文提出了一种混合规划-控制框架，用于计算目标方向的可行轨迹。该方法通过将状态空间分区，并采用具有受限控制输入的分段线性-affine (PWA) 系统近似系统，逐步通过仿射系统识别和可达控制理论更新PWA系统的边的存在性，引入基于未知动力学先验信息的预测可达性条件。根据边的存在性是确定的还是不确定的，给边分配启发式权重。因此，本文提出了一种框架，在任务执行过程中适应性地收集和分析数据，持续更新预测图，并根据图搜索结果在线综合控制器。通过涉及未知地形中移动机器人操作的仿真场景，将未知动态抽象为单积分器模型，证明了该方法的有效性。', 'title_zh': '基于预测可达性的未知非线性动力学的运动规划与控制'}
{'arxiv_id': 'arXiv:2503.03629', 'title': 'TeraSim: Uncovering Unknown Unsafe Events for Autonomous Vehicles through Generative Simulation', 'authors': 'Haowei Sun, Xintao Yan, Zhijie Qiao, Haojie Zhu, Yihao Sun, Jiawei Wang, Shengyin Shen, Darian Hogue, Rajanikant Ananta, Derek Johnson, Greg Stevens, Greg McGuire, Yifan Wei, Wei Zheng, Yong Sun, Yasuo Fukai, Henry X. Liu', 'link': 'https://arxiv.org/abs/2503.03629', 'abstract': "Traffic simulation is essential for autonomous vehicle (AV) development, enabling comprehensive safety evaluation across diverse driving conditions. However, traditional rule-based simulators struggle to capture complex human interactions, while data-driven approaches often fail to maintain long-term behavioral realism or generate diverse safety-critical events. To address these challenges, we propose TeraSim, an open-source, high-fidelity traffic simulation platform designed to uncover unknown unsafe events and efficiently estimate AV statistical performance metrics, such as crash rates. TeraSim is designed for seamless integration with third-party physics simulators and standalone AV stacks, to construct a complete AV simulation system. Experimental results demonstrate its effectiveness in generating diverse safety-critical events involving both static and dynamic agents, identifying hidden deficiencies in AV systems, and enabling statistical performance evaluation. These findings highlight TeraSim's potential as a practical tool for AV safety assessment, benefiting researchers, developers, and policymakers. The code is available at this https URL.", 'abstract_zh': '交通仿真对于自动驾驶汽车（AV）的发展至关重要，能够全面评估在各种驾驶条件下的一致安全性。然而，传统的基于规则的仿真器难以捕捉复杂的人类交互，而基于数据的方法往往无法保持长期的行为现实性或生成多样的安全关键事件。为了解决这些挑战，我们提出TeraSim，这是一个开源的高保真交通仿真平台，旨在揭示未知的安全事件并高效估计AV的统计性能指标，如碰撞率。TeraSim设计用于与第三方物理仿真器和独立的AV堆栈无缝集成，以构建完整的AV仿真系统。实验结果表明，TeraSim在生成涉及静态和动态代理的安全关键事件方面具有多样性，能够识别AV系统中的隐藏缺陷，并提供统计性能评估。这些发现突显了TeraSim作为AV安全性评估实用工具的潜力，有利于研究人员、开发者和政策制定者。代码可在以下链接获得：this https URL。', 'title_zh': 'TeraSim: 通过生成性模拟发现自主车辆中的未知不安全事件'}
{'arxiv_id': 'arXiv:2503.03579', 'title': 'A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery', 'authors': 'Hanxin Zhang, Abdulqader Dhafer, Zhou Daniel Hao, Hongbiao Dong', 'link': 'https://arxiv.org/abs/2503.03579', 'abstract': "We propose a novel system for robot-to-human object handover that emulates human coworker interactions. Unlike most existing studies that focus primarily on grasping strategies and motion planning, our system focus on 1. inferring human handover intents, 2. imagining spatial handover configuration. The first one integrates multimodal perception-combining visual and verbal cues-to infer human intent. The second one using a diffusion-based model to generate the handover configuration, involving the spacial relationship among robot's gripper, the object, and the human hand, thereby mimicking the cognitive process of motor imagery. Experimental results demonstrate that our approach effectively interprets human cues and achieves fluent, human-like handovers, offering a promising solution for collaborative robotics. Code, videos, and data are available at: this https URL.", 'abstract_zh': '我们提出了一种新型的机器人向人类对象交接系统，模拟人类同事间的互动。与大多数现有研究主要集中在抓取策略和运动规划上不同，我们的系统侧重于1. 推断人类交接意图，2. 想象空间交接配置。前者结合多模态感知（结合视觉和语言提示）推断人类意图。后者使用基于扩散的模型生成交接配置，涉及机器人夹爪、物体和人类手之间的空间关系，从而模仿运动意象的认知过程。实验结果表明，我们的方法有效解读人类提示，实现流畅、类人的交接，为协作机器人提供了有前景的解决方案。代码、视频和数据可在以下链接获取：this https URL。', 'title_zh': '基于从意图推理到空间配置想象的机器人到人的物品传递生成系统'}
{'arxiv_id': 'arXiv:2503.03574', 'title': 'Olympus: A Jumping Quadruped for Planetary Exploration Utilizing Reinforcement Learning for In-Flight Attitude Control', 'authors': 'Jørgen Anker Olsen, Grzegorz Malczyk, Kostas Alexis', 'link': 'https://arxiv.org/abs/2503.03574', 'abstract': 'Exploring planetary bodies with lower gravity, such as the moon and Mars, allows legged robots to utilize jumping as an efficient form of locomotion thus giving them a valuable advantage over traditional rovers for exploration. Motivated by this fact, this paper presents the design, simulation, and learning-based "in-flight" attitude control of Olympus, a jumping legged robot tailored to the gravity of Mars. First, the design requirements are outlined followed by detailing how simulation enabled optimizing the robot\'s design - from its legs to the overall configuration - towards high vertical jumping, forward jumping distance, and in-flight attitude reorientation. Subsequently, the reinforcement learning policy used to track desired in-flight attitude maneuvers is presented. Successfully crossing the sim2real gap, extensive experimental studies of attitude reorientation tests are demonstrated.', 'abstract_zh': '探索低重力行星体，如月球和火星，使腿足机器人能够利用跳跃作为高效的移动方式，从而在探索方面给传统漫游车带来显著优势。基于这一事实，本文介绍了为适应火星重力定制的跳跃腿足机器人奥林匹斯（Olympus）的设计、仿真及基于学习的“飞行中”姿态控制。首先概述了设计要求，随后详细说明了通过仿真优化机器人从腿部到整体配置的设计，以实现高效的垂直跳跃、前向跳跃距离和空中姿态重定向。接着介绍了用于跟踪期望空中姿态机动的强化学习策略。成功跨越了仿真到现实的鸿沟，本文展示了大量的姿态重定向测试实验研究。', 'title_zh': '奥林帕斯：利用强化学习进行飞行姿态控制的行星探测四足跳跃机器人'}
{'arxiv_id': 'arXiv:2503.03511', 'title': 'NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection', 'authors': 'Qingyu Fan, Yinghao Cai, Chao Li, Wenzhe He, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang', 'link': 'https://arxiv.org/abs/2503.03511', 'abstract': 'Robotic grasping in scenes with transparent and specular objects presents great challenges for methods relying on accurate depth information. In this paper, we introduce NeuGrasp, a neural surface reconstruction method that leverages background priors for material-agnostic grasp detection. NeuGrasp integrates transformers and global prior volumes to aggregate multi-view features with spatial encoding, enabling robust surface reconstruction in narrow and sparse viewing conditions. By focusing on foreground objects through residual feature enhancement and refining spatial perception with an occupancy-prior volume, NeuGrasp excels in handling objects with transparent and specular surfaces. Extensive experiments in both simulated and real-world scenarios show that NeuGrasp outperforms state-of-the-art methods in grasping while maintaining comparable reconstruction quality. More details are available at this https URL.', 'abstract_zh': '透明和镜面物体场景下的机器人抓取对依赖准确深度信息的方法提出了巨大挑战。本文介绍了NeuGrasp，一种利用背景先验的神经表面重建方法，用于材料无关的抓取检测。NeuGrasp 结合变换器和全局先验体素，通过空间编码聚合多视图特征，能够在狭窄和稀疏的观察条件下实现稳健的表面重建。通过残差特征增强聚焦前景对象，并通过占用先验体素精化空间感知，NeuGrasp 在处理透明和镜面物体方面表现出色。在仿真和实际场景中的大量实验表明，NeuGrasp 在抓取性能上优于现有最先进的方法，同时保持相似的重建质量。更多信息请参见此链接：此 https URL。', 'title_zh': 'NeuGrasp: 基于背景先验的通用神经表面重建及其在材料无关物体抓取检测中的应用'}
{'arxiv_id': 'arXiv:2503.03509', 'title': 'A Benchmark for Optimal Multi-Modal Multi-Robot Multi-Goal Path Planning with Given Robot Assignment', 'authors': 'Valentin N. Hartmann, Tirza Heinle, Stelian Coros', 'link': 'https://arxiv.org/abs/2503.03509', 'abstract': 'In many industrial robotics applications, multiple robots are working in a shared workspace to complete a set of tasks as quickly as possible. Such settings can be treated as multi-modal multi-robot multi-goal path planning problems, where each robot has to reach an ordered sequence of goals. Existing approaches to this type of problem solve this using prioritization or assume synchronous completion of tasks, and are thus neither optimal nor complete. We formalize this problem as a single path planning problem and introduce a benchmark encompassing a diverse range of problem instances including scenarios with various robots, planning horizons, and collaborative tasks such as handovers. Along with the benchmark, we adapt an RRT* and a PRM* planner to serve as a baseline for the planning problems. Both planners work in the composite space of all robots and introduce the required changes to work in our setting. Unlike existing approaches, our planner and formulation is not restricted to discretized 2D workspaces, supports a changing environment, and works for heterogeneous robot teams over multiple modes with different constraints, and multiple goals. Videos and code for the benchmark and the planners is available at this https URL.', 'abstract_zh': '在许多工业机器人应用中，多个机器人在共享工作空间中协作，以尽可能快地完成一组任务。这种设置可以视为多模态多机器人多目标路径规划问题，其中每个机器人必须按顺序到达一系列目标。现有方法解决此类问题时使用优先级或假设任务的同时完成，因此既不是最优解也不是完备解。我们将该问题形式化为单一路径规划问题，并引入一个基准测试，该基准测试包括各种机器人、规划时域和协作任务（如交接）等多种场景。除了基准测试外，我们还调整了RRT*和PRM*规划器作为路径规划问题的基线。这两种规划器在所有机器人的复合空间中工作，并引入了相应的变化以适应我们的设置。与现有方法不同，我们的规划器和建模不限于离散的二维工作空间，支持变化环境，并适用于具有不同约束条件和多个目标的异构机器人团队在多种模式下的路径规划。基准测试和规划器的相关视频和代码可在以下链接获取：this https URL。', 'title_zh': 'Optimal 多模态多机器人多目标路径规划基准（给定机器人分配）'}
{'arxiv_id': 'arXiv:2503.03481', 'title': 'Coordinated Trajectories for Non-stop Flying Carriers Holding a Cable-Suspended Load', 'authors': 'Chiara Gabellieri, Antonio Franchi', 'link': 'https://arxiv.org/abs/2503.03481', 'abstract': 'Multirotor UAVs have been typically considered for aerial manipulation, but their scarce endurance prevents long-lasting manipulation tasks. This work demonstrates that the non-stop flights of three or more carriers are compatible with holding a constant pose of a cable-suspended load, thus potentially enabling aerial manipulation with energy-efficient non-stop carriers. It also presents an algorithm for generating the coordinated non-stop trajectories. The proposed method builds upon two pillars: (1)~the choice of $n$ special linearly independent directions of internal forces within the $3n-6$-dimensional nullspace of the grasp matrix of the load, chosen as the edges of a Hamiltonian cycle on the graph that connects the cable attachment points on the load. Adjacent pairs of directions are used to generate $n$ forces evolving on distinct 2D affine subspaces, despite the attachment points being generically in 3D; (2)~the construction of elliptical trajectories within these subspaces by mapping, through appropriate graph coloring, each edge of the Hamiltonian cycle to a periodic coordinate while ensuring that no adjacent coordinates exhibit simultaneous zero derivatives. Combined with conditions for load statics and attachment point positions, these choices ensure that each of the $n$ force trajectories projects onto the corresponding cable constraint sphere with non-zero tangential velocity, enabling perpetual motion of the carriers while the load is still. The theoretical findings are validated through simulations and laboratory experiments with non-stopping multirotor UAVs.', 'abstract_zh': '基于连续飞行的多旋翼无人机实现高效空中操作的研究', 'title_zh': '协调航迹规划以实现连续飞行的缆索悬挂载荷运载器'}
{'arxiv_id': 'arXiv:2503.03480', 'title': 'SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning', 'authors': 'Borong Zhang, Yuhao Zhang, Jiaming Ji, Yingshan Lei, Josef Dai, Yuanpei Chen, Yaodong Yang', 'link': 'https://arxiv.org/abs/2503.03480', 'abstract': 'Vision-language-action models (VLAs) have shown great potential as generalist robot policies. However, these models pose urgent safety challenges during deployment, including the risk of physical harm to the environment, the robot itself, and humans. How can safety be explicitly incorporated into VLAs? In this work, we propose SafeVLA, a novel algorithm designed to integrate safety into VLAs, ensuring the protection of the environment, robot hardware and humans in real-world settings. SafeVLA effectively balances safety and task performance by employing large-scale constrained learning within simulated environments. We demonstrate that SafeVLA outperforms the current state-of-the-art method in both safety and task performance, achieving average improvements of 83.58% and 3.85%, respectively, in simulation. By prioritizing safety, our approach eliminates high-risk behaviors and reduces the upper bound of unsafe behaviors to 1/35 of that in the current state-of-the-art, thereby significantly mitigating long-tail risks. Furthermore, the learned safety constraints generalize to diverse, unseen scenarios, including multiple out-of-distribution perturbations and tasks. Our data, models and newly proposed benchmark environment are available at this https URL.', 'abstract_zh': '视知觉行动模型（VLAs）作为通用机器人策略显示出巨大的潜在价值。然而，在部署过程中，这些模型带来了急迫的安全挑战，包括对环境、机器人本身和人类的物理风险。如何在VLAs中明确地纳入安全性？在本文中，我们提出SafeVLA，这是一种新型算法，旨在将安全性整合进VLAs中，确保在真实世界场景中保护环境、机器人硬件和人类的安全。SafeVLA通过在模拟环境中采用大规模约束学习来有效地在安全性与任务性能之间取得平衡。我们证明SafeVLA在安全性和任务性能方面均优于当前最先进的方法，在仿真中分别实现了83.58%和3.85%的平均提升。通过优先考虑安全性，我们的方法消除了高风险行为，并将不安全行为的上限降低到当前最先进的方法的1/35，从而显著减轻了长尾风险。此外，学习到的安全限制可以泛化到各种未见过的场景，包括多个离分布扰动和任务。我们的数据、模型和新提出的标准环境可通过此链接获得。', 'title_zh': 'SafeVLA：通过安全强化学习实现视觉-语言-动作模型的安全对齐'}
{'arxiv_id': 'arXiv:2503.03476', 'title': 'Continuous Control of Diverse Skills in Quadruped Robots Without Complete Expert Datasets', 'authors': 'Jiaxin Tu, Xiaoyi Wei, Yueqi Zhang, Taixian Hou, Xiaofei Gao, Zhiyan Dong, Peng Zhai, Lihua Zhang', 'link': 'https://arxiv.org/abs/2503.03476', 'abstract': 'Learning diverse skills for quadruped robots presents significant challenges, such as mastering complex transitions between different skills and handling tasks of varying difficulty. Existing imitation learning methods, while successful, rely on expensive datasets to reproduce expert behaviors. Inspired by introspective learning, we propose Progressive Adversarial Self-Imitation Skill Transition (PASIST), a novel method that eliminates the need for complete expert datasets. PASIST autonomously explores and selects high-quality trajectories based on predefined target poses instead of demonstrations, leveraging the Generative Adversarial Self-Imitation Learning (GASIL) framework. To further enhance learning, We develop a skill selection module to mitigate mode collapse by balancing the weights of skills with varying levels of difficulty. Through these methods, PASIST is able to reproduce skills corresponding to the target pose while achieving smooth and natural transitions between them. Evaluations on both simulation platforms and the Solo 8 robot confirm the effectiveness of PASIST, offering an efficient alternative to expert-driven learning.', 'abstract_zh': '渐进对抗自我模仿技能过渡（PASIST）：面向四足机器人的高效技能学习', 'title_zh': '四足机器人无需完整专家数据集的多样技能连续控制'}
{'arxiv_id': 'arXiv:2503.03464', 'title': 'Generative Artificial Intelligence in Robotic Manipulation: A Survey', 'authors': 'Kun Zhang, Peng Yun, Jun Cen, Junhao Cai, Didi Zhu, Hangjie Yuan, Chao Zhao, Tao Feng, Michael Yu Wang, Qifeng Chen, Jia Pan, Bo Yang, Hua Chen', 'link': 'https://arxiv.org/abs/2503.03464', 'abstract': 'This survey provides a comprehensive review on recent advancements of generative learning models in robotic manipulation, addressing key challenges in the field. Robotic manipulation faces critical bottlenecks, including significant challenges in insufficient data and inefficient data acquisition, long-horizon and complex task planning, and the multi-modality reasoning ability for robust policy learning performance across diverse environments. To tackle these challenges, this survey introduces several generative model paradigms, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), diffusion models, probabilistic flow models, and autoregressive models, highlighting their strengths and limitations. The applications of these models are categorized into three hierarchical layers: the Foundation Layer, focusing on data generation and reward generation; the Intermediate Layer, covering language, code, visual, and state generation; and the Policy Layer, emphasizing grasp generation and trajectory generation. Each layer is explored in detail, along with notable works that have advanced the state of the art. Finally, the survey outlines future research directions and challenges, emphasizing the need for improved efficiency in data utilization, better handling of long-horizon tasks, and enhanced generalization across diverse robotic scenarios. All the related resources, including research papers, open-source data, and projects, are collected for the community in this https URL', 'abstract_zh': '本调研提供了对机器人操作中生成学习模型近期进展的全面回顾，针对该领域的关键挑战进行了探讨。机器人操作面临的关键瓶颈包括数据不足和数据采集效率低、长时序和复杂任务规划，以及适用于多样化环境的鲁棒性策略学习所需的多模态推理能力。为应对这些挑战，本调研介绍了几种生成模型范式，包括生成对抗网络（GANs）、变分自编码器（VAEs）、扩散模型、概率流模型和自回归模型，并对它们的优缺点进行了阐述。这些模型的应用被分类为三个层次：基础层，侧重于数据生成和奖励生成；中间层，涵盖语言、代码、视觉和状态生成；策略层，强调抓取生成和轨迹生成。每个层次都进行了详细探讨，并介绍了推动该领域前沿的重要工作。最后，本调研指出了未来的研究方向和挑战，强调了提高数据利用效率、更好地处理长时序任务以及增强跨多样化机器人场景的应用前景的需要。相关资源，包括研究论文、开源数据和项目，均收集于此：https://xxxxxx', 'title_zh': '生成式人工智能在机器人操作中的应用：综述'}
{'arxiv_id': 'arXiv:2503.03449', 'title': 'Tiny Lidars for Manipulator Self-Awareness: Sensor Characterization and Initial Localization Experiments', 'authors': 'Giammarco Caroleo, Alessandro Albini, Daniele De Martini, Timothy D. Barfoot, Perla Maiolino', 'link': 'https://arxiv.org/abs/2503.03449', 'abstract': "For several tasks, ranging from manipulation to inspection, it is beneficial for robots to localize a target object in their surroundings. In this paper, we propose an approach that utilizes coarse point clouds obtained from miniaturized VL53L5CX Time-of-Flight (ToF) sensors (tiny lidars) to localize a target object in the robot's workspace. We first conduct an experimental campaign to calibrate the dependency of sensor readings on relative range and orientation to targets. We then propose a probabilistic sensor model that is validated in an object pose estimation task using a Particle Filter (PF). The results show that the proposed sensor model improves the performance of the localization of the target object with respect to two baselines: one that assumes measurements are free from uncertainty and one in which the confidence is provided by the sensor datasheet.", 'abstract_zh': '本文提出了一种利用微型VL53L5CX飞行时间（ToF）传感器（小型激光雷达）获取的粗略点云来在机器人工作空间中定位目标物体的方法。我们首先进行实验以校准传感器读数对目标相对距离和方向的依赖性。然后，我们提出了一种概率传感器模型，并通过粒子滤波器（PF）在物体姿态估计任务中进行了验证。结果表明，提出的传感器模型相比于两种基线方法提高了目标物体定位性能：一种假设测量值无不确定性，另一种则通过传感器数据表提供置信度。', 'title_zh': '小尺寸激光雷达用于 manipulator 自我意识：传感器特性化和初步定位实验'}
{'arxiv_id': 'arXiv:2503.03412', 'title': 'REACT: Real-time Efficient Attribute Clustering and Transfer for Updatable 3D Scene Graph', 'authors': 'Phuoc Nguyen, Francesco Verdoja, Ville Kyrki', 'link': 'https://arxiv.org/abs/2503.03412', 'abstract': "Modern-day autonomous robots need high-level map representations to perform sophisticated tasks. Recently, 3D scene graphs (3DSGs) have emerged as a promising alternative to traditional grid maps, blending efficient memory use and rich feature representation. However, most efforts to apply them have been limited to static worlds. This work introduces REACT, a framework that efficiently performs real-time attribute clustering and transfer to relocalize object nodes in a 3DSG. REACT employs a novel method for comparing object instances using an embedding model trained on triplet loss, facilitating instance clustering and matching. Experimental results demonstrate that REACT is able to relocalize objects while maintaining computational efficiency. The REACT framework's source code will be available as an open-source project, promoting further advancements in reusable and updatable 3DSGs.", 'abstract_zh': '现代自主机器人需要高阶地图表示以执行复杂的任务。最近，3D场景图（3DSG）作为一种有潜力的替代传统格网地图的选择出现，结合了高效的内存使用和丰富的特征表示。然而，大多数相关努力主要限定在静态世界中。本文介绍了REACT框架，该框架能够高效地进行实时属性聚类和转移，以重新定位3DSG中的对象节点。REACT采用了一种基于三元组损失训练的嵌入模型来比较对象实例的新方法，促进实例聚类和匹配。实验结果表明，REACT能够在保持计算效率的同时重新定位对象。REACT框架的源代码将作为开源项目提供，促进在可重用和可更新的3DSG方面的进一步研究进展。', 'title_zh': 'REACT: 实时高效属性聚类与传输以支持可更新的3D场景图'}
{'arxiv_id': 'arXiv:2503.03373', 'title': 'Direct Sparse Odometry with Continuous 3D Gaussian Maps for Indoor Environments', 'authors': 'Jie Deng, Fengtian Lang, Zikang Yuan, Xin Yang', 'link': 'https://arxiv.org/abs/2503.03373', 'abstract': 'Accurate localization is essential for robotics and augmented reality applications such as autonomous navigation. Vision-based methods combining prior maps aim to integrate LiDAR-level accuracy with camera cost efficiency for robust pose estimation. Existing approaches, however, often depend on unreliable interpolation procedures when associating discrete point cloud maps with dense image pixels, which inevitably introduces depth errors and degrades pose estimation accuracy. We propose a monocular visual odometry framework utilizing a continuous 3D Gaussian map, which directly assigns geometrically consistent depth values to all extracted high-gradient points without interpolation. Evaluations on two public datasets demonstrate superior tracking accuracy compared to existing methods. We have released the source code of this work for the development of the community.', 'abstract_zh': '基于视觉的单目特征跟踪框架：利用连续3D高斯图进行几何一致的深度赋值', 'title_zh': '直接稀疏 odometry 与室内环境中的连续 3D 高斯地图'}
{'arxiv_id': 'arXiv:2503.03338', 'title': 'Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles', 'authors': 'Alexandre Benoit, Pedram Asef', 'link': 'https://arxiv.org/abs/2503.03338', 'abstract': "We offer a new in-depth investigation of global path planning (GPP) for unmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP is essential for ROMIE's optimal performance, which is translated into solving the traveling salesman problem, a complex graph theory challenge that is crucial for determining the most effective route to cover all sampling locations in a mining field. This problem is central to enhancing ROMIE's operational efficiency and competitiveness against human labor by optimizing cost and time. The primary aim of this research is to advance GPP by developing, evaluating, and improving a cost-efficient software and web application. We delve into an extensive comparison and analysis of Google operations research (OR)-Tools optimization algorithms. Our study is driven by the goal of applying and testing the limits of OR-Tools capabilities by integrating Reinforcement Learning techniques for the first time. This enables us to compare these methods with OR-Tools, assessing their computational effectiveness and real-world application efficiency. Our analysis seeks to provide insights into the effectiveness and practical application of each technique. Our findings indicate that Q-Learning stands out as the optimal strategy, demonstrating superior efficiency by deviating only 1.2% on average from the optimal solutions across our datasets.", 'abstract_zh': '我们对自主采矿采样机器人ROMIE的全球路径规划（GPP）进行了新的深入研究。该研究强调了GPP对于ROMIE最优性能的重要性，将其转化为解决旅行商问题，这是一个复杂的图论挑战，对于确定在采矿场覆盖所有采样点的最有效路线至关重要。这一问题的核心在于通过优化成本和时间提高ROMIE的操作效率并增强其与人力劳动的竞争优势。本研究的主要目标是通过开发、评估和改进低成本的软件和Web应用程序来推进GPP。我们深入比较和分析了Google优化算法OR-Tools。本研究的目的是首次将强化学习技术与OR-Tools结合，以探索和完善其能力，并评估这些方法的计算有效性及其在实际应用中的效率。我们的分析旨在提供每种技术有效性和实际应用的相关洞察。研究结果表明，Q-学习脱颖而出，以其在所有数据集上平均偏离最优解仅1.2%的效率展示了最优策略的优势。', 'title_zh': '智能导航：Google OR-Tools和机器学习在自主车辆全球路径规划中的综述'}
{'arxiv_id': 'arXiv:2503.03282', 'title': 'Supervised Visual Docking Network for Unmanned Surface Vehicles Using Auto-labeling in Real-world Water Environments', 'authors': 'Yijie Chu, Ziniu Wu, Yong Yue, Eng Gee Lim, Paolo Paoletti, Xiaohui Zhu', 'link': 'https://arxiv.org/abs/2503.03282', 'abstract': 'Unmanned Surface Vehicles (USVs) are increasingly applied to water operations such as environmental monitoring and river-map modeling. It faces a significant challenge in achieving precise autonomous docking at ports or stations, still relying on remote human control or external positioning systems for accuracy and safety which limits the full potential of human-out-of-loop deployment for this http URL paper introduces a novel supervised learning pipeline with the auto-labeling technique for USVs autonomous visual docking. Firstly, we designed an auto-labeling data collection pipeline that appends relative pose and image pair to the dataset. This step does not require conventional manual labeling for supervised learning. Secondly, the Neural Dock Pose Estimator (NDPE) is proposed to achieve relative dock pose prediction without the need for hand-crafted feature engineering, camera calibration, and peripheral markers. Moreover, The NDPE can accurately predict the relative dock pose in real-world water environments, facilitating the implementation of Position-Based Visual Servo (PBVS) and low-level motion controllers for efficient and autonomous this http URL show that the NDPE is robust to the disturbance of the distance and the USV velocity. The effectiveness of our proposed solution is tested and validated in real-world water environments, reflecting its capability to handle real-world autonomous docking tasks.', 'abstract_zh': '无人驾驶水面车辆（USVs）在水体操作如环境监测和河流地图建模中应用日益广泛。它在实现精确自主靠泊方面面临重大挑战，仍依赖远程人工控制或外部定位系统以确保准确性和安全性，这限制了无人监管部署的潜力。本文介绍了一种新的监督学习管道，结合自标注技术实现USVs自主视觉靠泊。首先，我们设计了一种自标注数据采集管道，附加相对位姿和图像对到数据集中。这一步骤无需传统的手动标注即可进行监督学习。其次，我们提出了神经靠泊位姿估计器（NDPE），以实现无需手工特征工程、相机校准和辅助标记的靠泊位姿预测。此外，NDPE可以在真实水体环境中准确预测相对靠泊位姿，促进基于位置的视觉伺服（PBVS）和低级运动控制器的实现，以实现高效和自主的靠泊操作。实验表明，NDPE对距离和USV速度的干扰具有鲁棒性。我们的提出的解决方案在真实水体环境中进行测试和验证，展示了其处理真实世界自主靠泊任务的能力。', 'title_zh': '基于自动标注的监督视觉对接网络在实际水环境中的应用研究'}
{'arxiv_id': 'arXiv:2503.03262', 'title': 'Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions', 'authors': 'Nadya Abdel Madjid, Abdulrahman Ahmad, Murad Mebrahtu, Yousef Babaa, Abdelmoamen Nasser, Sumbal Malik, Bilal Hassan, Naoufel Werghi, Jorge Dias, Majid Khonji', 'link': 'https://arxiv.org/abs/2503.03262', 'abstract': 'As the potential for autonomous vehicles to be integrated on a large scale into modern traffic systems continues to grow, ensuring safe navigation in dynamic environments is crucial for smooth integration. To guarantee safety and prevent collisions, autonomous vehicles must be capable of accurately predicting the trajectories of surrounding traffic agents. Over the past decade, significant efforts from both academia and industry have been dedicated to designing solutions for precise trajectory forecasting. These efforts have produced a diverse range of approaches, raising questions about the differences between these methods and whether trajectory prediction challenges have been fully addressed. This paper reviews a substantial portion of recent trajectory prediction methods and devises a taxonomy to classify existing solutions. A general overview of the prediction pipeline is also provided, covering input and output modalities, modeling features, and prediction paradigms discussed in the literature. In addition, the paper discusses active research areas within trajectory prediction, addresses the posed research questions, and highlights the remaining research gaps and challenges.', 'abstract_zh': '随着自主车辆大规模整合到现代交通系统中的潜力不断增加，确保在动态环境中安全导航对于顺利整合至关重要。为了保证安全并防止碰撞，自主车辆必须能够准确预测周围交通代理的轨迹。在过去十年里，学术界和工业界都致力于设计精确轨迹预测的解决方案，产生了多种方法，但仍有疑问认为这些方法能否全面解决轨迹预测挑战。本文回顾了近期大量的轨迹预测方法，制定了分类学以分类现有解决方案，并提供了预测管道的总体概述，涵盖文献中讨论的输入和输出模式、建模特征和预测范式。此外，本文还讨论了轨迹预测领域内的活跃研究方向，回答了提出的研究问题，并指出了剩余的研究空白和挑战。', 'title_zh': '自动驾驶中轨迹预测：进展、局限性和未来方向'}
{'arxiv_id': 'arXiv:2503.03254', 'title': 'SCORE: Saturated Consensus Relocalization in Semantic Line Maps', 'authors': 'Haodong Jiang, Xiang Zheng, Yanglin Zhang, Qingcheng Zeng, Yiqian Li, Ziyang Hong, Junfeng Wu', 'link': 'https://arxiv.org/abs/2503.03254', 'abstract': 'This is the arxiv version for our paper submitted to IEEE/RSJ IROS 2025. We propose a scene-agnostic and light-weight visual relocalization framework that leverages semantically labeled 3D lines as a compact map representation. In our framework, the robot localizes itself by capturing a single image, extracting 2D lines, associating them with semantically similar 3D lines in the map, and solving a robust perspective-n-line problem. To address the extremely high outlier ratios~(exceeding 99.5\\%) caused by one-to-many ambiguities in semantic matching, we introduce the Saturated Consensus Maximization~(Sat-CM) formulation, which enables accurate pose estimation when the classic Consensus Maximization framework fails. We further propose a fast global solver to the formulated Sat-CM problems, leveraging rigorous interval analysis results to ensure both accuracy and computational efficiency. Additionally, we develop a pipeline for constructing semantic 3D line maps using posed depth images. To validate the effectiveness of our framework, which integrates our innovations in robust estimation and practical engineering insights, we conduct extensive experiments on the ScanNet++ dataset.', 'abstract_zh': '这是我们提交给IEEE/RSJ IROS 2025的论文的arxiv版本。我们提出了一种场景无关且轻量级的视觉重定位框架，该框架利用语义标注的3D直线作为紧凑的地图表示。在该框架中，机器人通过拍摄单张图像，提取2D直线，将它们与地图中语义相似的3D直线关联，并求解鲁棒的透视-n-直线问题来进行自身定位。为了解决由于语义匹配中一对多ambiguous性导致的极高离群值比率（超过99.5%），我们引入了饱和共识最大化（Sat-CM）公式，当经典的共识最大化框架失效时，能够实现精确的姿态估计。我们还提出了一种针对形式化的Sat-CM问题的快速全局求解器，利用严格的区间分析结果来确保准确性和计算效率。此外，我们开发了一种基于姿态深度图像构建语义3D直线地图的管道。为了验证我们框架的有效性，该框架结合了我们在稳健估计和实用工程见解方面的创新，我们在ScanNet++数据集上进行了大量实验。', 'title_zh': 'SCORE: 满量饱和共识语义线地图重定位'}
{'arxiv_id': 'arXiv:2503.03252', 'title': 'STORM: Spatial-Temporal Iterative Optimization for Reliable Multicopter Trajectory Generation', 'authors': 'Jinhao Zhang, Zhexuan Zhou, Wenlong Xia, Youmin Gong, Jie Mei', 'link': 'https://arxiv.org/abs/2503.03252', 'abstract': 'Efficient and safe trajectory planning plays a critical role in the application of quadrotor unmanned aerial vehicles. Currently, the inherent trade-off between constraint compliance and computational efficiency enhancement in UAV trajectory optimization problems has not been sufficiently addressed. To enhance the performance of UAV trajectory optimization, we propose a spatial-temporal iterative optimization framework. Firstly, B-splines are utilized to represent UAV trajectories, with rigorous safety assurance achieved through strict enforcement of constraints on control points. Subsequently, a set of QP-LP subproblems via spatial-temporal decoupling and constraint linearization is derived. Finally, an iterative optimization strategy incorporating guidance gradients is employed to obtain high-performance UAV trajectories in different scenarios. Both simulation and real-world experimental results validate the efficiency and high-performance of the proposed optimization framework in generating safe and fast trajectories. Our source codes will be released for community reference at this https URL', 'abstract_zh': '高效的时空迭代优化框架在四旋翼无人机轨迹规划中的应用：缓解约束遵守与计算效率之间的固有trade-off', 'title_zh': 'STORM：空间-时间迭代优化方法在可靠多旋翼飞行轨迹生成中的应用'}
{'arxiv_id': 'arXiv:2503.03234', 'title': 'Social Gesture Recognition in spHRI: Leveraging Fabric-Based Tactile Sensing on Humanoid Robots', 'authors': 'Dakarai Crowder, Kojo Vandyck, Xiping Sun, James McCann, Wenzhen Yuan', 'link': 'https://arxiv.org/abs/2503.03234', 'abstract': 'Humans are able to convey different messages using only touch. Equipping robots with the ability to understand social touch adds another modality in which humans and robots can communicate. In this paper, we present a social gesture recognition system using a fabric-based, large-scale tactile sensor integrated onto the arms of a humanoid robot. We built a social gesture dataset using multiple participants and extracted temporal features for classification. By collecting real-world data on a humanoid robot, our system provides valuable insights into human-robot social touch, further advancing the development of spHRI systems for more natural and effective communication.', 'abstract_zh': '基于纺织材料的大规模触觉传感器的人形机器人社会手势识别系统', 'title_zh': '基于 humanoid 机器人的基于织物基触觉感知的社会手势识别'}
{'arxiv_id': 'arXiv:2503.03230', 'title': 'OpenGV 2.0: Motion prior-assisted calibration and SLAM with vehicle-mounted surround-view systems', 'authors': "Kun Huang, Yifu Wang, Si'ao Zhang, Zhirui Wang, Zhanpeng Ouyang, Zhenghua Yu, Laurent Kneip", 'link': 'https://arxiv.org/abs/2503.03230', 'abstract': 'The present paper proposes optimization-based solutions to visual SLAM with a vehicle-mounted surround-view camera system. Owing to their original use-case, such systems often only contain a single camera facing into either direction and very limited overlap between fields of view. Our novelty consist of three optimization modules targeting at practical online calibration of exterior orientations from simple two-view geometry, reliable front-end initialization of relative displacements, and accurate back-end optimization using a continuous-time trajectory model. The commonality between the proposed modules is given by the fact that all three of them exploit motion priors that are related to the inherent non-holonomic characteristics of passenger vehicle motion. In contrast to prior related art, the proposed modules furthermore excel in terms of bypassing partial unobservabilities in the transformation variables that commonly occur for Ackermann-motion. As a further contribution, the modules are built into a novel surround-view camera SLAM system that specifically targets deployment on Ackermann vehicles operating in urban environments. All modules are studied in the context of in-depth ablation studies, and the practical validity of the entire framework is supported by a successful application to challenging, large-scale publicly available online datasets. Note that upon acceptance, the entire framework is scheduled for open-source release as part of an extension of the OpenGV library.', 'abstract_zh': '基于优化的视觉SLAM方法研究：面向车载环视相机系统的实践在线标定与轨迹优化', 'title_zh': 'OpenGV 2.0：车辆搭载全景视图系统中的运动先验辅助标定与SLAM'}
{'arxiv_id': 'arXiv:2503.03208', 'title': 'Embodied Escaping: End-to-End Reinforcement Learning for Robot Navigation in Narrow Environment', 'authors': 'Han Zheng, Jiale Zhang, Mingyang Jiang, Peiyuan Liu, Danni Liu, Tong Qin, Ming Yang', 'link': 'https://arxiv.org/abs/2503.03208', 'abstract': 'Autonomous navigation is a fundamental task for robot vacuum cleaners in indoor environments. Since their core function is to clean entire areas, robots inevitably encounter dead zones in cluttered and narrow scenarios. Existing planning methods often fail to escape due to complex environmental constraints, high-dimensional search spaces, and high difficulty maneuvers. To address these challenges, this paper proposes an embodied escaping model that leverages reinforcement learning-based policy with an efficient action mask for dead zone escaping. To alleviate the issue of the sparse reward in training, we introduce a hybrid training policy that improves learning efficiency. In handling redundant and ineffective action options, we design a novel action representation to reshape the discrete action space with a uniform turning radius. Furthermore, we develop an action mask strategy to select valid action quickly, balancing precision and efficiency. In real-world experiments, our robot is equipped with a Lidar, IMU, and two-wheel encoders. Extensive quantitative and qualitative experiments across varying difficulty levels demonstrate that our robot can consistently escape from challenging dead zones. Moreover, our approach significantly outperforms compared path planning and reinforcement learning methods in terms of success rate and collision avoidance.', 'abstract_zh': '自主导航是室内清扫机器人的一项基本任务。由于核心功能是全面清洁区域，机器人在杂乱和狭窄的场景中不可避免地会遇到死角。现有规划方法往往由于复杂的环境约束、高维搜索空间以及高难度的操作而难以逃脱。为了解决这些问题，本文提出了一种基于强化学习的体态逃脱模型，该模型利用高效的行动掩码来解决死角逃脱问题。为了解决训练中稀疏奖励的问题，我们引入了一种混合训练策略，以提高学习效率。在处理冗余和无效的动作选项时，我们设计了一种新型的动作表示，以均匀转向半径重塑离散的动作空间。此外，我们开发了一种行动掩码策略，以快速选择有效动作，平衡精度和效率。在实际实验中，我们的机器人配备了激光雷达、IMU和双轮编码器。在不同难度级别的广泛定量和定性实验中，证明我们的机器人能够一致地从挑战性的死角中逃脱。此外，与路径规划和强化学习方法相比，我们的方法在成功率和碰撞避免方面表现显著优异。', 'title_zh': '具身逃脱：狭窄环境中的机器人导航端到端强化学习'}
{'arxiv_id': 'arXiv:2503.03192', 'title': 'Distributed Certifiably Correct Range-Aided SLAM', 'authors': 'Alexander Thoms, Alan Papalia, Jared Velasquez, David M. Rosen, Sriram Narasimhan', 'link': 'https://arxiv.org/abs/2503.03192', 'abstract': "Reliable simultaneous localization and mapping (SLAM) algorithms are necessary for safety-critical autonomous navigation. In the communication-constrained multi-agent setting, navigation systems increasingly use point-to-point range sensors as they afford measurements with low bandwidth requirements and known data association. The state estimation problem for these systems takes the form of range-aided (RA) SLAM. However, distributed algorithms for solving the RA-SLAM problem lack formal guarantees on the quality of the returned estimate. To this end, we present the first distributed algorithm for RA-SLAM that can efficiently recover certifiably globally optimal solutions. Our algorithm, distributed certifiably correct RA-SLAM (DCORA), achieves this via the Riemannian Staircase method, where computational procedures developed for distributed certifiably correct pose graph optimization are generalized to the RA-SLAM problem. We demonstrate DCORA's efficacy on real-world multi-agent datasets by achieving absolute trajectory errors comparable to those of a state-of-the-art centralized certifiably correct RA-SLAM algorithm. Additionally, we perform a parametric study on the structure of the RA-SLAM problem using synthetic data, revealing how common parameters affect DCORA's performance.", 'abstract_zh': '可靠的协同定位与建图（SLAM）算法对于安全关键的自主导航至关重要。在通信受限的多agent环境中，导航系统越来越多地使用点到点的距离传感器，因其具有低带宽要求和已知的数据关联性。这些系统的状态估计问题表现为辅助距离（RA）SLAM问题。然而，解决RA-SLAM问题的分布式算法缺乏关于返回估计质量的形式化保证。为此，我们提出了一种全新的分布式算法，即分布式可证实正确的RA-SLAM（DCORA），该算法能够高效地恢复全局最优解，并通过里斯曼楼梯方法实现，其中针对分布式可证实正确位图图优化开发的计算过程被推广应用于RA-SLAM问题。通过在真实的多agent数据集上展示DCORA的有效性，我们达到了与最先进的集中式可证实正确RA-SLAM算法相当的绝对轨迹误差。此外，我们使用合成数据对RA-SLAM问题的结构进行了参数研究，揭示了常见参数如何影响DCORA的性能。', 'title_zh': '分布式认证正确区间辅助SLAM'}
{'arxiv_id': 'arXiv:2503.03145', 'title': 'Causality-Based Reinforcement Learning Method for Multi-Stage Robotic Tasks', 'authors': 'Jiechao Deng, Ning Tan', 'link': 'https://arxiv.org/abs/2503.03145', 'abstract': 'Deep reinforcement learning has made significant strides in various robotic tasks. However, employing deep reinforcement learning methods to tackle multi-stage tasks still a challenge. Reinforcement learning algorithms often encounter issues such as redundant exploration, getting stuck in dead ends, and progress reversal in multi-stage tasks. To address this, we propose a method that integrates causal relationships with reinforcement learning for multi-stage tasks. Our approach enables robots to automatically discover the causal relationships between their actions and the rewards of the tasks and constructs the action space using only causal actions, thereby reducing redundant exploration and progress reversal. By integrating correct causal relationships using the causal policy gradient method into the learning process, our approach can enhance the performance of reinforcement learning algorithms in multi-stage robotic tasks.', 'abstract_zh': '深度强化学习在各类机器人任务中取得了显著进展，但在应对多阶段任务时仍面临挑战。为了应对这一挑战，我们提出了一种结合因果关系与强化学习的方法，以适用于多阶段任务。该方法使机器人能够自动发现其动作与任务奖励之间的因果关系，并仅使用因果动作构建动作空间，从而减少冗余探索和进展逆转。通过使用因果策略梯度方法将正确的因果关系融入学习过程，该方法能够提升强化学习算法在多阶段机器人任务中的性能。', 'title_zh': '基于因果性的强化学习方法用于多阶段机器人任务'}
{'arxiv_id': 'arXiv:2503.03125', 'title': "Don't Shake the Wheel: Momentum-Aware Planning in End-to-End Autonomous Driving", 'authors': 'Ziying Song, Caiyan Jia, Lin Liu, Hongyu Pan, Yongchang Zhang, Junming Wang, Xingyu Zhang, Shaoqing Xu, Lei Yang, Yadan Luo', 'link': 'https://arxiv.org/abs/2503.03125', 'abstract': 'End-to-end autonomous driving frameworks enable seamless integration of perception and planning but often rely on one-shot trajectory prediction, which may lead to unstable control and vulnerability to occlusions in single-frame perception. To address this, we propose the Momentum-Aware Driving (MomAD) framework, which introduces trajectory momentum and perception momentum to stabilize and refine trajectory predictions. MomAD comprises two core components: (1) Topological Trajectory Matching (TTM) employs Hausdorff Distance to select the optimal planning query that aligns with prior paths to ensure coherence;(2) Momentum Planning Interactor (MPI) cross-attends the selected planning query with historical queries to expand static and dynamic perception files. This enriched query, in turn, helps regenerate long-horizon trajectory and reduce collision risks. To mitigate noise arising from dynamic environments and detection errors, we introduce robust instance denoising during training, enabling the planning model to focus on critical signals and improve its robustness. We also propose a novel Trajectory Prediction Consistency (TPC) metric to quantitatively assess planning stability. Experiments on the nuScenes dataset demonstrate that MomAD achieves superior long-term consistency (>=3s) compared to SOTA methods. Moreover, evaluations on the curated Turning-nuScenes shows that MomAD reduces the collision rate by 26% and improves TPC by 0.97m (33.45%) over a 6s prediction horizon, while closedloop on Bench2Drive demonstrates an up to 16.3% improvement in success rate.', 'abstract_zh': '基于动量的自动驾驶框架（Momentum-Aware Driving, MomAD）：稳定化轨迹预测与规划', 'title_zh': '不要摇晃方向盘：端到端自动驾驶中的动量感知规划'}
{'arxiv_id': 'arXiv:2503.03100', 'title': 'Car-STAGE: Automated framework for large-scale high-dimensional simulated time-series data generation based on user-defined criteria', 'authors': 'Asma A. Almutairi, David J. LeBlanc, Arpan Kusari', 'link': 'https://arxiv.org/abs/2503.03100', 'abstract': 'Generating large-scale sensing datasets through photo-realistic simulation is an important aspect of many robotics applications such as autonomous driving. In this paper, we consider the problem of synchronous data collection from the open-source CARLA simulator using multiple sensors attached to vehicle based on user-defined criteria. We propose a novel, one-step framework that we refer to as Car-STAGE, based on CARLA simulator, to generate data using a graphical user interface (GUI) defining configuration parameters to data collection without any user intervention. This framework can utilize the user-defined configuration parameters such as choice of maps, number and configurations of sensors, environmental and lighting conditions etc. to run the simulation in the background, collecting high-dimensional sensor data from diverse sensors such as RGB Camera, LiDAR, Radar, Depth Camera, IMU Sensor, GNSS Sensor, Semantic Segmentation Camera, Instance Segmentation Camera, and Optical Flow Camera along with the ground-truths of the individual actors and storing the sensor data as well as ground-truth labels in a local or cloud-based database. The framework uses multiple threads where a main thread runs the server, a worker thread deals with queue and frame number and the rest of the threads processes the sensor data. The other way we derive speed up over the native implementation is by memory mapping the raw binary data into the disk and then converting the data into known formats at the end of data collection. We show that using these techniques, we gain a significant speed up over frames, under an increasing set of sensors and over the number of spawned objects.', 'abstract_zh': '基于CARLA模拟器的用户定义参数驱动的一键式数据采集框架：Car-STAGE', 'title_zh': '基于用户定义标准的大型高维模拟时间序列数据生成自动化框架：Car-STAGE'}
{'arxiv_id': 'arXiv:2503.03081', 'title': 'AirExo-2: Scaling up Generalizable Robotic Imitation Learning with Low-Cost Exoskeletons', 'authors': 'Hongjie Fang, Chenxi Wang, Yiming Wang, Jingjing Chen, Shangning Xia, Jun Lv, Zihao He, Xiyan Yi, Yunhan Guo, Xinyu Zhan, Lixin Yang, Weiming Wang, Cewu Lu, Hao-Shu Fang', 'link': 'https://arxiv.org/abs/2503.03081', 'abstract': 'Scaling up imitation learning for real-world applications requires efficient and cost-effective demonstration collection methods. Current teleoperation approaches, though effective, are expensive and inefficient due to the dependency on physical robot platforms. Alternative data sources like in-the-wild demonstrations can eliminate the need for physical robots and offer more scalable solutions. However, existing in-the-wild data collection devices have limitations: handheld devices offer restricted in-hand camera observation, while whole-body devices often require fine-tuning with robot data due to action inaccuracies. In this paper, we propose AirExo-2, a low-cost exoskeleton system for large-scale in-the-wild demonstration collection. By introducing the demonstration adaptor to transform the collected in-the-wild demonstrations into pseudo-robot demonstrations, our system addresses key challenges in utilizing in-the-wild demonstrations for downstream imitation learning in real-world environments. Additionally, we present RISE-2, a generalizable policy that integrates 2D and 3D perceptions, outperforming previous imitation learning policies in both in-domain and out-of-domain tasks, even with limited demonstrations. By leveraging in-the-wild demonstrations collected and transformed by the AirExo-2 system, without the need for additional robot demonstrations, RISE-2 achieves comparable or superior performance to policies trained with teleoperated data, highlighting the potential of AirExo-2 for scalable and generalizable imitation learning. Project page: this https URL', 'abstract_zh': '大范围在野演示收集的低成本exo骨架系统AirExo-2及其应用于可扩展和普适性模仿学习的RISE-2策略', 'title_zh': 'AirExo-2：低成本外骨骼助力可泛化机器人imitation learning规模化应用'}
{'arxiv_id': 'arXiv:2503.03077', 'title': 'MochiSwarm: A testbed for robotic blimps in realistic environments', 'authors': "Jiawei Xu, Thong Vu, Diego S. D'Antonio, David Saldaña", 'link': 'https://arxiv.org/abs/2503.03077', 'abstract': 'Testing aerial robots in tasks such as pickup-and-delivery and surveillance significantly benefits from high energy efficiency and scalability of the deployed robotic system. This paper presents MochiSwarm, an open-source testbed of light-weight robotic blimps, ready for multi-robot operation without external localization. We introduce the system design in hardware, software, and perception, which capitalizes on modularity, low cost, and light weight. The hardware allows for rapid modification, which enables the integration of additional sensors to enhance autonomy for different scenarios. The software framework supports different actuation models and communication between the base station and multiple blimps. The detachable perception module allows independent blimps to perform tasks that involve detection and autonomous actuation. We showcase a differential-drive module as an example, of which the autonomy is enabled by visual servoing using the perception module. A case study of pickup-and-delivery tasks with up to 12 blimps highlights the autonomy of the MochiSwarm without external infrastructures.', 'abstract_zh': '测试诸如收发物品和 surveillance 等任务的空中机器人显著受益于部署机器人系统的高度能效和可扩展性。本文介绍了 MochiSwarm，一个开源的轻量级空中无人机测试平台，无需外部定位即可进行多机器人操作。我们在硬件、软件和感知方面介绍了系统设计，注重模块化、低成本和轻量化。硬件允许快速修改，便于集成额外传感器以增强不同场景下的自主性。软件框架支持不同的驱动模型，并在基站与多个无人机之间实现通信。可拆卸的感知模块使独立无人机能够执行涉及检测和自主操作的任务。我们以一个差分驱动模块为例，该模块的自主性通过使用感知模块实现的视觉伺服技术启用。长达12个无人机的收发物品任务案例研究表明，MochiSwarm 在没有外部基础设施的情况下具备自主性。', 'title_zh': 'MochiSwarm: 一种用于现实环境中的机器人气球的实验平台'}
{'arxiv_id': 'arXiv:2503.03074', 'title': 'BEVDriver: Leveraging BEV Maps in LLMs for Robust Closed-Loop Driving', 'authors': 'Katharina Winter, Mark Azer, Fabian B. Flohr', 'link': 'https://arxiv.org/abs/2503.03074', 'abstract': 'Autonomous driving has the potential to set the stage for more efficient future mobility, requiring the research domain to establish trust through safe, reliable and transparent driving. Large Language Models (LLMs) possess reasoning capabilities and natural language understanding, presenting the potential to serve as generalized decision-makers for ego-motion planning that can interact with humans and navigate environments designed for human drivers. While this research avenue is promising, current autonomous driving approaches are challenged by combining 3D spatial grounding and the reasoning and language capabilities of LLMs. We introduce BEVDriver, an LLM-based model for end-to-end closed-loop driving in CARLA that utilizes latent BEV features as perception input. BEVDriver includes a BEV encoder to efficiently process multi-view images and 3D LiDAR point clouds. Within a common latent space, the BEV features are propagated through a Q-Former to align with natural language instructions and passed to the LLM that predicts and plans precise future trajectories while considering navigation instructions and critical scenarios. On the LangAuto benchmark, our model reaches up to 18.9% higher performance on the Driving Score compared to SoTA methods.', 'abstract_zh': '基于自主驾驶的贝维驱动：一种利用大语言模型实现端到端闭环驾驶的方法', 'title_zh': 'BEVDriver：利用BEV图在LLMs中实现稳健的闭环驾驶'}
{'arxiv_id': 'arXiv:2503.03071', 'title': 'Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion via Trajectory Optimization and Symbolic Repair', 'authors': 'Ziyi Zhou, Qian Meng, Hadas Kress-Gazit, Ye Zhao', 'link': 'https://arxiv.org/abs/2503.03071', 'abstract': "We propose an integrated planning framework for quadrupedal locomotion over dynamically changing, unforeseen terrains. Existing approaches either rely on heuristics for instantaneous foothold selection--compromising safety and versatility--or solve expensive trajectory optimization problems with complex terrain features and long time horizons. In contrast, our framework leverages reactive synthesis to generate correct-by-construction controllers at the symbolic level, and mixed-integer convex programming (MICP) for dynamic and physically feasible footstep planning for each symbolic transition. We use a high-level manager to reduce the large state space in synthesis by incorporating local environment information, improving synthesis scalability. To handle specifications that cannot be met due to dynamic infeasibility, and to minimize costly MICP solves, we leverage a symbolic repair process to generate only necessary symbolic transitions. During online execution, re-running the MICP with real-world terrain data, along with runtime symbolic repair, bridges the gap between offline synthesis and online execution. We demonstrate, in simulation, our framework's capabilities to discover missing locomotion skills and react promptly in safety-critical environments, such as scattered stepping stones and rebars.", 'abstract_zh': '一种基于反应合成的四足机器人动态环境适应性规划框架', 'title_zh': '基于轨迹优化和符号修复的地貌自适应 locomotion 的物理可行反应合成'}
{'arxiv_id': 'arXiv:2503.03045', 'title': 'ArticuBot: Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation', 'authors': 'Yufei Wang, Ziyu Wang, Mino Nakura, Pratik Bhowal, Chia-Liang Kuo, Yi-Ting Chen, Zackory Erickson, David Held', 'link': 'https://arxiv.org/abs/2503.03045', 'abstract': 'This paper presents ArticuBot, in which a single learned policy enables a robotics system to open diverse categories of unseen articulated objects in the real world. This task has long been challenging for robotics due to the large variations in the geometry, size, and articulation types of such objects. Our system, Articubot, consists of three parts: generating a large number of demonstrations in physics-based simulation, distilling all generated demonstrations into a point cloud-based neural policy via imitation learning, and performing zero-shot sim2real transfer to real robotics systems. Utilizing sampling-based grasping and motion planning, our demonstration generalization pipeline is fast and effective, generating a total of 42.3k demonstrations over 322 training articulated objects. For policy learning, we propose a novel hierarchical policy representation, in which the high-level policy learns the sub-goal for the end-effector, and the low-level policy learns how to move the end-effector conditioned on the predicted goal. We demonstrate that this hierarchical approach achieves much better object-level generalization compared to the non-hierarchical version. We further propose a novel weighted displacement model for the high-level policy that grounds the prediction into the existing 3D structure of the scene, outperforming alternative policy representations. We show that our learned policy can zero-shot transfer to three different real robot settings: a fixed table-top Franka arm across two different labs, and an X-Arm on a mobile base, opening multiple unseen articulated objects across two labs, real lounges, and kitchens. Videos and code can be found on our project website: this https URL.', 'abstract_zh': '本文介绍了ArticuBot，该系统通过单个学习策略使机器人系统能够在现实世界中打开各类未见过的关节式物体。由于此类物体在几何形状、大小和关节类型上存在巨大变化，这一任务长期以來对机器人技术构成了挑战。我们的系统Articubot 包括三个部分：在基于物理的模拟中生成大量演示，通过模仿学习将所有生成的演示总结为基于点云的神经策略，以及在真实机器人系统中进行零样本仿真实验到现实的转移。利用基于采样的抓取和运动规划，我们的演示泛化管道既快速又高效，在322个训练关节物体上总共生成了42300个演示。在策略学习中，我们提出了一种新颖的层次化策略表示，在该表示中，高层策略学习末端执行器的子目标，而低层策略学习在预测目标的基础上如何移动末端执行器。我们证明这种层次化方法在物体级别泛化方面优于非层次化版本。我们还提出了一种新颖的加权位移模型，作为高层策略的基础，将预测嵌入到现有场景的3D结构中，优于其他策略表示方法。我们展示了我们的学习策略可以零样本转移到三种不同的真实机器人设置中：两个不同实验室中的固定桌面Franka手臂，以及移动基座上的X-Arm，打开了多个未见过的关节式物体，跨越两个实验室、真实休息室和厨房。更多视频和代码请参阅我们的项目网站：this https URL。', 'title_zh': 'ArticuBot：大规模仿真学习通用articulated物体操作策略'}
{'arxiv_id': 'arXiv:2503.02992', 'title': 'RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding Across Different Environments and Tasks', 'authors': 'Yimin Tang, Xiao Xiong, Jingyi Xi, Jiaoyang Li, Erdem Bıyık, Sven Koenig', 'link': 'https://arxiv.org/abs/2503.02992', 'abstract': "Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset.", 'abstract_zh': '基于地图的Multi-Agent Path Finding（基于地图的MAPF）：RAILGUN——一种集中式的学习策略', 'title_zh': 'RAILGUN：跨不同环境和任务的统一卷积策略多智能体路径规划'}
{'arxiv_id': 'arXiv:2503.02955', 'title': 'Monocular visual simultaneous localization and mapping: (r)evolution from geometry to deep learning-based pipelines', 'authors': 'Olaya Alvarez-Tunon, Yury Brodskiy, Erdal Kayacan', 'link': 'https://arxiv.org/abs/2503.02955', 'abstract': "With the rise of deep learning, there is a fundamental change in visual SLAM algorithms toward developing different modules trained as end-to-end pipelines. However, regardless of the implementation domain, visual SLAM's performance is subject to diverse environmental challenges, such as dynamic elements in outdoor environments, harsh imaging conditions in underwater environments, or blurriness in high-speed setups. These environmental challenges need to be identified to study the real-world viability of SLAM implementations. Motivated by the aforementioned challenges, this paper surveys the current state of visual SLAM algorithms according to the two main frameworks: geometry-based and learning-based SLAM. First, we introduce a general formulation of the SLAM pipeline that includes most of the implementations in the literature. Second, those implementations are classified and surveyed for geometry and learning-based SLAM. After that, environment-specific challenges are formulated to enable experimental evaluation of the resilience of different visual SLAM classes to varying imaging conditions. We address two significant issues in surveying visual SLAM, providing (1) a consistent classification of visual SLAM pipelines and (2) a robust evaluation of their performance under different deployment conditions. Finally, we give our take on future opportunities for visual SLAM implementations.", 'abstract_zh': '基于几何与学习的视觉SLAM算法现状综述：环境特定挑战与性能评估', 'title_zh': '单目视觉同时定位与建图：从几何方法到基于深度学习的管道的演变'}
{'arxiv_id': 'arXiv:2503.02954', 'title': 'Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders', 'authors': 'Yue Meng, Nathalie Majcherczyk, Wenliang Liu, Scott Kiesel, Chuchu Fan, Federico Pecora', 'link': 'https://arxiv.org/abs/2503.02954', 'abstract': 'Multi-agent coordination is crucial for reliable multi-robot navigation in shared spaces such as automated warehouses. In regions of dense robot traffic, local coordination methods may fail to find a deadlock-free solution. In these scenarios, it is appropriate to let a central unit generate a global schedule that decides the passing order of robots. However, the runtime of such centralized coordination methods increases significantly with the problem scale. In this paper, we propose to leverage Graph Neural Network Variational Autoencoders (GNN-VAE) to solve the multi-agent coordination problem at scale faster than through centralized optimization. We formulate the coordination problem as a graph problem and collect ground truth data using a Mixed-Integer Linear Program (MILP) solver. During training, our learning framework encodes good quality solutions of the graph problem into a latent space. At inference time, solution samples are decoded from the sampled latent variables, and the lowest-cost sample is selected for coordination. Finally, the feasible proposal with the highest performance index is selected for the deployment. By construction, our GNN-VAE framework returns solutions that always respect the constraints of the considered coordination problem. Numerical results show that our approach trained on small-scale problems can achieve high-quality solutions even for large-scale problems with 250 robots, being much faster than other baselines. Project page: this https URL', 'abstract_zh': '多代理协调对于自动仓库等共享空间中的可靠多机器人导航至关重要。在密集的机器人traffic区域，局部协调方法可能无法找到无死锁的解决方案。在这种情况下，适宜让中央单元生成全球调度，决定机器人的通行顺序。然而，随着问题规模的增加，集中协调方法的运行时间显著增加。本文提出利用图神经网络变分自编码器（GNN-VAE）以比集中优化更快的速度解决大规模多代理协调问题。我们将协调问题形式化为图问题，并使用混合整数线性规划（MILP）求解器收集ground truth数据。在训练过程中，我们的学习框架将图问题的良好质量解编码到潜在空间中。在推理阶段，从采样的潜在变量解码解样本，并选择最低成本的解进行协调。最后，选择具有最高性能指标的可行提案进行部署。通过构造，我们的GNN-VAE框架返回的解始终遵守所考虑的协调问题的约束。数值结果表明，我们的方法在小规模问题上训练后，即使在拥有250个机器人的大规模问题上也能实现高质量的解，并且比其他基线方法更快。项目页面：this https URL', 'title_zh': '基于图神经网络变分自编码器的可靠高效多智能体协调'}
{'arxiv_id': 'arXiv:2503.02924', 'title': 'Diverse Controllable Diffusion Policy with Signal Temporal Logic', 'authors': 'Yue Meng, Chuchu fan', 'link': 'https://arxiv.org/abs/2503.02924', 'abstract': 'Generating realistic simulations is critical for autonomous system applications such as self-driving and human-robot interactions. However, driving simulators nowadays still have difficulty in generating controllable, diverse, and rule-compliant behaviors for road participants: Rule-based models cannot produce diverse behaviors and require careful tuning, whereas learning-based methods imitate the policy from data but are not designed to follow the rules explicitly. Besides, the real-world datasets are by nature "single-outcome", making the learning method hard to generate diverse behaviors. In this paper, we leverage Signal Temporal Logic (STL) and Diffusion Models to learn controllable, diverse, and rule-aware policy. We first calibrate the STL on the real-world data, then generate diverse synthetic data using trajectory optimization, and finally learn the rectified diffusion policy on the augmented dataset. We test on the NuScenes dataset and our approach can achieve the most diverse rule-compliant trajectories compared to other baselines, with a runtime 1/17X to the second-best approach. In the closed-loop testing, our approach reaches the highest diversity, rule satisfaction rate, and the least collision rate. Our method can generate varied characteristics conditional on different STL parameters in testing. A case study on human-robot encounter scenarios shows our approach can generate diverse and closed-to-oracle trajectories. The annotation tool, augmented dataset, and code are available at this https URL.', 'abstract_zh': '利用Signal Temporal Logic和扩散模型生成可控、多样且守规则的仿真行为', 'title_zh': '可控制的多样化扩散策略与信号时序逻辑'}
{'arxiv_id': 'arXiv:2503.03726', 'title': 'Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames', 'authors': 'Jun Yang, Wenjie Xue, Sahar Ghavidel, Steven L. Waslander', 'link': 'https://arxiv.org/abs/2503.03726', 'abstract': 'Estimating the 6D pose of textureless objects from RBG images is an important problem in robotics. Due to appearance ambiguities, rotational symmetries, and severe occlusions, single-view based 6D pose estimators are still unable to handle a wide range of objects, motivating research towards multi-view pose estimation and next-best-view prediction that addresses these limitations. In this work, we propose a comprehensive active perception framework for estimating the 6D poses of textureless objects using only RGB images. Our approach is built upon a key idea: decoupling the 6D pose estimation into a sequential two-step process can greatly improve both accuracy and efficiency. First, we estimate the 3D translation of each object, resolving scale and depth ambiguities inherent to RGB images. These estimates are then used to simplify the subsequent task of determining the 3D orientation, which we achieve through canonical scale template matching. Building on this formulation, we then introduce an active perception strategy that predicts the next best camera viewpoint to capture an RGB image, effectively reducing object pose uncertainty and enhancing pose accuracy. We evaluate our method on the public ROBI dataset as well as on a transparent object dataset that we created. When evaluated using the same camera viewpoints, our multi-view pose estimation significantly outperforms state-of-the-art approaches. Furthermore, by leveraging our next-best-view strategy, our method achieves high object pose accuracy with substantially fewer viewpoints than heuristic-based policies.', 'abstract_zh': '从RGB图像估计无纹理对象的6D姿态是一个重要的机器人问题。由于外观歧义、旋转对称性和严重遮挡，基于单视图的6D姿态估计器仍然无法处理广泛的对象，推动了多视图姿态估计和下一步最佳视图预测的研究，以解决这些限制。在本文中，我们提出了一种综合主动感知框架，仅使用RGB图像估计无纹理对象的6D姿态。我们的方法基于一个关键理念：将6D姿态估计分解为顺序两步过程，可以大幅提高准确性和效率。首先，我们估计每个对象的3D平移，解决RGB图像固有的尺度和深度歧义。然后用这些估计来简化后续的三维方向确定任务，我们通过标准尺度模板匹配来实现这一目标。在这一框架的基础上，我们引入了一种主动感知策略，预测最佳相机视角以采集RGB图像，有效降低了对象姿态不确定性并提高了姿态准确性。我们在公共ROBI数据集以及我们创建的透明对象数据集上评估了我们的方法。当使用相同的相机视角进行评估时，我们的多视图姿态估计显著优于现有技术。此外，通过利用我们的下一步最佳视图策略，我们的方法在比基于启发式策略的方法使用明显较少视角的情况下，实现了高对象姿态准确性。', 'title_zh': '基于多视图RGB帧的无纹理物体6D姿态估计'}
{'arxiv_id': 'arXiv:2503.03599', 'title': 'REGRACE: A Robust and Efficient Graph-based Re-localization Algorithm using Consistency Evaluation', 'authors': 'Débora N.P. Oliveira, Joshua Knights, Sebastián Barbas Laina, Simon Boche, Wolfram Burgard, Stefan Leutenegger', 'link': 'https://arxiv.org/abs/2503.03599', 'abstract': 'Loop closures are essential for correcting odometry drift and creating consistent maps, especially in the context of large-scale navigation. Current methods using dense point clouds for accurate place recognition do not scale well due to computationally expensive scan-to-scan comparisons. Alternative object-centric approaches are more efficient but often struggle with sensitivity to viewpoint variation. In this work, we introduce REGRACE, a novel approach that addresses these challenges of scalability and perspective difference in re-localization by using LiDAR-based submaps. We introduce rotation-invariant features for each labeled object and enhance them with neighborhood context through a graph neural network. To identify potential revisits, we employ a scalable bag-of-words approach, pooling one learned global feature per submap. Additionally, we define a revisit with geometrical consistency cues rather than embedding distance, allowing us to recognize far-away loop closures. Our evaluations demonstrate that REGRACE achieves similar results compared to state-of-the-art place recognition and registration baselines while being twice as fast.', 'abstract_zh': '基于LiDAR子地图的旋转不变特征及其应用以应对大规模导航中的重定位挑战', 'title_zh': 'REGRACE: 一种基于图的鲁棒且高效的重新定位算法，采用一致性评估'}
{'arxiv_id': 'arXiv:2503.03556', 'title': 'Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented Manipulation', 'authors': 'Xiaomeng Zhu, Yuyang Li, Leiyao Cui, Pengfei Li, Huan-ang Gao, Yixin Zhu, Hao Zhao', 'link': 'https://arxiv.org/abs/2503.03556', 'abstract': "Object affordance reasoning, the ability to infer object functionalities based on physical properties, is fundamental for task-oriented planning and activities in both humans and Artificial Intelligence (AI). This capability, required for planning and executing daily activities in a task-oriented manner, relies on commonsense knowledge of object physics and functionalities, extending beyond simple object recognition. Current computational models for affordance reasoning from perception lack generalizability, limiting their applicability in novel scenarios. Meanwhile, comprehensive Large Language Models (LLMs) with emerging reasoning capabilities are challenging to deploy on local devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a large-scale dataset comprising 1,496 tasks and 119k images, designed to enhance the generalizability of affordance reasoning from perception. Utilizing this dataset, we develop Afford-X, an end-to-end trainable affordance reasoning model that incorporates Verb Attention and Bi-Fusion modules to improve multi-modal understanding. This model achieves up to a 12.1% performance improvement over the best-reported results from non-LLM methods, while also demonstrating a 1.2% enhancement compared to our previous conference paper. Additionally, it maintains a compact 187M parameter size and infers nearly 50 times faster than the GPT-4V API. Our work demonstrates the potential for efficient, generalizable affordance reasoning models that can be deployed on local devices for task-oriented manipulations. We showcase Afford-X's effectiveness in enabling task-oriented manipulations for robots across various tasks and environments, underscoring its efficiency and broad implications for advancing robotics and AI systems in real-world applications.", 'abstract_zh': '基于感知的 affordance 推理：一种用于任务导向操作的大规模数据集和模型', 'title_zh': 'Afford-X: 通用且精简的执行导向抓持功能推理'}
{'arxiv_id': 'arXiv:2503.03535', 'title': 'Unified Human Localization and Trajectory Prediction with Monocular Vision', 'authors': 'Po-Chien Luan, Yang Gao, Celine Demonsant, Alexandre Alahi', 'link': 'https://arxiv.org/abs/2503.03535', 'abstract': "Conventional human trajectory prediction models rely on clean curated data, requiring specialized equipment or manual labeling, which is often impractical for robotic applications. The existing predictors tend to overfit to clean observation affecting their robustness when used with noisy inputs. In this work, we propose MonoTransmotion (MT), a Transformer-based framework that uses only a monocular camera to jointly solve localization and prediction tasks. Our framework has two main modules: Bird's Eye View (BEV) localization and trajectory prediction. The BEV localization module estimates the position of a person using 2D human poses, enhanced by a novel directional loss for smoother sequential localizations. The trajectory prediction module predicts future motion from these estimates. We show that by jointly training both tasks with our unified framework, our method is more robust in real-world scenarios made of noisy inputs. We validate our MT network on both curated and non-curated datasets. On the curated dataset, MT achieves around 12% improvement over baseline models on BEV localization and trajectory prediction. On real-world non-curated dataset, experimental results indicate that MT maintains similar performance levels, highlighting its robustness and generalization capability. The code is available at this https URL.", 'abstract_zh': '基于单目相机的Transformer框架：MonoTransmotion及其在鲁棒轨迹预测中的应用', 'title_zh': '统一的人体定位与轨迹预测方法：单目视觉 approaches'}
{'arxiv_id': 'arXiv:2503.03200', 'title': 'Transformer-Based Spatio-Temporal Association of Apple Fruitlets', 'authors': 'Harry Freeman, George Kantor', 'link': 'https://arxiv.org/abs/2503.03200', 'abstract': 'In this paper, we present a transformer-based method to spatio-temporally associate apple fruitlets in stereo-images collected on different days and from different camera poses. State-of-the-art association methods in agriculture are dedicated towards matching larger crops using either high-resolution point clouds or temporally stable features, which are both difficult to obtain for smaller fruit in the field. To address these challenges, we propose a transformer-based architecture that encodes the shape and position of each fruitlet, and propagates and refines these features through a series of transformer encoder layers with alternating self and cross-attention. We demonstrate that our method is able to achieve an F1-score of 92.4% on data collected in a commercial apple orchard and outperforms all baselines and ablations.', 'abstract_zh': '基于变压器的方法实现立体图像中不同天采集且不同相机姿态下苹果幼果的时空关联', 'title_zh': '基于变压器的空间-时间苹果幼果关联研究'}
{'arxiv_id': 'arXiv:2503.03196', 'title': 'SpiritSight Agent: Advanced GUI Agent with One Look', 'authors': 'Zhiyuan Huang, Ziming Cheng, Junting Pan, Zhaohui Hou, Mingjie Zhan', 'link': 'https://arxiv.org/abs/2503.03196', 'abstract': "Graphical User Interface (GUI) agents show amazing abilities in assisting human-computer interaction, automating human user's navigation on digital devices. An ideal GUI agent is expected to achieve high accuracy, low latency, and compatibility for different GUI platforms. Recent vision-based approaches have shown promise by leveraging advanced Vision Language Models (VLMs). While they generally meet the requirements of compatibility and low latency, these vision-based GUI agents tend to have low accuracy due to their limitations in element grounding. To address this issue, we propose $\\textbf{SpiritSight}$, a vision-based, end-to-end GUI agent that excels in GUI navigation tasks across various GUI platforms. First, we create a multi-level, large-scale, high-quality GUI dataset called $\\textbf{GUI-Lasagne}$ using scalable methods, empowering SpiritSight with robust GUI understanding and grounding capabilities. Second, we introduce the $\\textbf{Universal Block Parsing (UBP)}$ method to resolve the ambiguity problem in dynamic high-resolution of visual inputs, further enhancing SpiritSight's ability to ground GUI objects. Through these efforts, SpiritSight agent outperforms other advanced methods on diverse GUI benchmarks, demonstrating its superior capability and compatibility in GUI navigation tasks. Models are available at $\\href{this https URL}{this\\ URL}$.", 'abstract_zh': '基于视觉的图形用户界面代理：SpiritSight在跨平台GUI导航任务中的卓越表现', 'title_zh': 'SpiritSight 代理: 具有一瞥功能的高级GUI代理'}
{'arxiv_id': 'arXiv:2503.03002', 'title': 'Multi-Step Deep Koopman Network (MDK-Net) for Vehicle Control in Frenet Frame', 'authors': 'Mohammad Abtahi, Mahdis Rabbani, Armin Abdolmohammadi, Shima Nazari', 'link': 'https://arxiv.org/abs/2503.03002', 'abstract': 'The highly nonlinear dynamics of vehicles present a major challenge for the practical implementation of optimal and Model Predictive Control (MPC) approaches in path planning and following. Koopman operator theory offers a global linear representation of nonlinear dynamical systems, making it a promising framework for optimization-based vehicle control. This paper introduces a novel deep learning-based Koopman modeling approach that employs deep neural networks to capture the full vehicle dynamics-from pedal and steering inputs to chassis states-within a curvilinear Frenet frame. The superior accuracy of the Koopman model compared to identified linear models is shown for a double lane change maneuver. Furthermore, it is shown that an MPC controller deploying the Koopman model provides significantly improved performance while maintaining computational efficiency comparable to a linear MPC.', 'abstract_zh': '基于深度学习的Koopman模型在路径规划与跟踪中的应用：车辆非线性动力学的优化控制方法', 'title_zh': '基于傅里叶框架的多步深Koopman网络（MDK-Net）在车辆控制中的应用'}
{'arxiv_id': 'arXiv:2503.02916', 'title': 'Monocular Person Localization under Camera Ego-motion', 'authors': 'Yu Zhan, Hanjing Ye, Hong Zhang', 'link': 'https://arxiv.org/abs/2503.02916', 'abstract': "Localizing a person from a moving monocular camera is critical for Human-Robot Interaction (HRI). To estimate the 3D human position from a 2D image, existing methods either depend on the geometric assumption of a fixed camera or use a position regression model trained on datasets containing little camera ego-motion. These methods are vulnerable to fierce camera ego-motion, resulting in inaccurate person localization. We consider person localization as a part of a pose estimation problem. By representing a human with a four-point model, our method jointly estimates the 2D camera attitude and the person's 3D location through optimization. Evaluations on both public datasets and real robot experiments demonstrate our method outperforms baselines in person localization accuracy. Our method is further implemented into a person-following system and deployed on an agile quadruped robot.", 'abstract_zh': '基于移动单目相机的人类定位对于人机交互（HRI）至关重要。通过优化联合估计二维相机姿态和人的三维位置，我们的方法不仅在公开数据集上，还在实际机器人实验中展示了对人类定位的优越性能，并进一步集成到一个人跟随系统中部署在敏捷四足机器人上。', 'title_zh': '基于摄像机 ego-运动的单目人体定位'}
{'arxiv_id': 'arXiv:2503.02913', 'title': 'Towards Robust Multi-UAV Collaboration: MARL with Noise-Resilient Communication and Attention Mechanisms', 'authors': 'Zilin Zhao, Chishui Chen, Haotian Shi, Jiale Chen, Xuanlin Yue, Zhejian Yang, Yang Liu', 'link': 'https://arxiv.org/abs/2503.02913', 'abstract': 'Efficient path planning for unmanned aerial vehicles (UAVs) is crucial in remote sensing and information collection. As task scales expand, the cooperative deployment of multiple UAVs significantly improves information collection efficiency. However, collaborative communication and decision-making for multiple UAVs remain major challenges in path planning, especially in noisy environments. To efficiently accomplish complex information collection tasks in 3D space and address robust communication issues, we propose a multi-agent reinforcement learning (MARL) framework for UAV path planning based on the Counterfactual Multi-Agent Policy Gradients (COMA) algorithm. The framework incorporates attention mechanism-based UAV communication protocol and training-deployment system, significantly improving communication robustness and individual decision-making capabilities in noisy conditions. Experiments conducted on both synthetic and real-world datasets demonstrate that our method outperforms existing algorithms in terms of path planning efficiency and robustness, especially in noisy environments, achieving a 78\\% improvement in entropy reduction.', 'abstract_zh': '多无人机路径规划中的高效策略博弈：基于Counterfactual Multi-Agent Policy Gradients的多智能体强化学习框架', 'title_zh': '基于抗噪通信和注意力机制的鲁棒多无人机协作：多智能体强化学习'}
