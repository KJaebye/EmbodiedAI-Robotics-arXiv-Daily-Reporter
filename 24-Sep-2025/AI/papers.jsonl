{'arxiv_id': 'arXiv:2509.19265', 'title': 'Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World', 'authors': 'Saeed Almheiri, Rania Hossam, Mena Attia, Chenxi Wang, Preslav Nakov, Timothy Baldwin, Fajri Koto', 'link': 'https://arxiv.org/abs/2509.19265', 'abstract': 'Large language models (LLMs) often reflect Western-centric biases, limiting their effectiveness in diverse cultural contexts. Although some work has explored cultural alignment, the potential for cross-cultural transfer, using alignment in one culture to improve performance in others, remains underexplored. This paper investigates cross-cultural transfer of commonsense reasoning in the Arab world, where linguistic and historical similarities coexist with local cultural differences. Using a culturally grounded commonsense reasoning dataset covering 13 Arab countries, we evaluate lightweight alignment methods such as in-context learning and demonstration-based reinforcement (DITTO), alongside baselines like supervised fine-tuning and direct preference optimization. Our results show that merely 12 culture-specific examples from one country can improve performance in others by 10\\% on average, within multilingual models. In addition, we demonstrate that out-of-culture demonstrations from Indonesia and US contexts can match or surpass in-culture alignment for MCQ reasoning, highlighting cultural commonsense transferability beyond the Arab world. These findings demonstrate that efficient cross-cultural alignment is possible and offer a promising approach to adapt LLMs to low-resource cultural settings.', 'abstract_zh': '大型语言模型（LLMs）往往反映出西方中心主义偏差，限制了其在多元文化环境中的有效性。尽管已有部分研究探索了文化对齐，但利用一个文化中的对齐来改善其他文化的性能的跨文化转移潜力尚未得到充分探索。本文调查了阿拉伯世界中的常识推理跨文化转移，该地区存在语言和历史上的相似性同时伴随着当地文化差异。利用涵盖13个阿拉伯国家的文化基础常识推理数据集，我们评估了轻量级对齐方法，如上下文学习和示范强化（DITTO），并与监督微调和直接偏好优化等基准方法进行了比较。结果显示，仅从一个国家获取12个文化特定示例即可在多语言模型中平均提高10%的性能。此外，我们展示了来自印度尼西亚和美国背景的跨文化示范与阿拉伯背景对齐在选择题推理方面持平或超越，突显了常识推理在阿拉伯世界之外的文化转移潜力。这些发现表明，高效的跨文化对齐是可能的，并为适应LLM在低资源文化环境下的应用提供了有希望的方法。', 'title_zh': '跨文化的常识推理转移在LLMs中的证据：阿拉伯世界的研究'}
{'arxiv_id': 'arXiv:2509.19236', 'title': 'AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration', 'authors': 'Chunhao Tian, Yutong Wang, Xuebo Liu, Zhexuan Wang, Liang Ding, Miao Zhang, Min Zhang', 'link': 'https://arxiv.org/abs/2509.19236', 'abstract': "Proper initialization is crucial for any system, particularly in multi-agent systems (MAS), where it plays a pivotal role in determining both the system's efficiency and effectiveness. However, existing MAS initialization methods do not fully account for the collaborative needs of the generated agents in subsequent stages. Inspired by the principles of effective team composition, we propose AgentInit, which aims to optimize the structure of agent teams. Specifically, in addition to multi-round interactions and reflections between agents during agent generation, AgentInit incorporates a Natural Language to Format mechanism to ensure consistency and standardization. Balanced team selection strategies using Pareto principles are subsequently applied to jointly consider agent team diversity and task relevance to promote effective and efficient collaboration and enhance overall system performance. Experiments show that AgentInit consistently outperforms state-of-the-art initialization methods and pre-defined strategies across various frameworks and tasks, achieving an overall performance improvement of up to 1.2 and 1.6, respectively, while also significantly reducing token consumption. Further analysis confirms its strong transferability to similar tasks and verifies the effectiveness of its key components, demonstrating its capability and adaptability as a reliable MAS initialization method. Source code and models are available at this https URL.", 'abstract_zh': '合适的初始化对任何系统至关重要，特别是在多智能体系统中，它在决定系统效率和效果方面发挥着关键作用。然而，现有的多智能体系统初始化方法并未充分考虑到生成智能体在后续阶段的协作需求。受有效团队构成原则的启发，我们提出AgentInit，旨在优化智能体团队的结构。具体而言，在智能体生成过程中，除了多轮次的智能体互动和反思，AgentInit还引入自然语言格式化机制以确保一致性和标准化。随后应用帕累托原则导向的平衡团队选择策略，共同考虑智能体团队多样性和任务相关性，以促进有效和高效的协作，提升整体系统性能。实验结果显示，AgentInit在各种框架和任务中均优于最先进的初始化方法和预定义策略，分别在性能上提高了1.2和1.6，同时显著减少了令牌消耗。进一步分析证实其在类似任务中的强泛化能力和关键组件的有效性，展示了其作为可靠多智能体系统初始化方法的能力和适应性。代码和模型可在以下链接获取。', 'title_zh': 'AgentInit：通过多样性和专长 orchestration 初始化基于LLM的多agent系统，以实现有效高效的合作'}
{'arxiv_id': 'arXiv:2509.19077', 'title': 'Code Driven Planning with Domain-Adaptive Critic', 'authors': 'Zikang Tian, Shaohui Peng, Du Huang, Jiaming Guo, Ruizhi Chen, Rui Zhang, Xishan Zhang, Yuxuan Guo, Zidong Du, Qi Guo, Ling Li, Yewen Pu, Xing Hu, Yunji Chen', 'link': 'https://arxiv.org/abs/2509.19077', 'abstract': 'Large Language Models (LLMs) have been widely adopted as task planners for AI agents in sequential decision-making problems, leveraging their extensive world knowledge. However, the gap between their general knowledge and environment-specific requirements often leads to inaccurate plans. To address this, existing approaches rely on frequent LLM queries to iteratively refine plans based on immediate environmental feedback, which incurs substantial query costs. However, this refinement is typically guided by short-term environmental feedback, limiting LLMs from developing plans aligned with long-term rewards. We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of relying on frequent queries, CoPiC employs LLMs to generate a diverse set of high-level planning programs, which iteratively produce and refine candidate plans. A trained domain-adaptive critic then evaluates these candidates and selects the one most aligned with long-term rewards for execution. Using high-level planning programs as planner and domain-adaptive critic as estimator, CoPiC improves planning while significantly reducing query costs. Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in query costs.', 'abstract_zh': '基于域自适应评价器的代码驱动规划（CoPiC）', 'title_zh': '基于域自适应评论的代码驱动规划'}
{'arxiv_id': 'arXiv:2509.19058', 'title': 'Towards Causal Representation Learning with Observable Sources as Auxiliaries', 'authors': 'Kwonho Kim, Heejeong Nam, Inwoo Hwang, Sanghack Lee', 'link': 'https://arxiv.org/abs/2509.19058', 'abstract': 'Causal representation learning seeks to recover latent factors that generate observational data through a mixing function. Needing assumptions on latent structures or relationships to achieve identifiability in general, prior works often build upon conditional independence given known auxiliary variables. However, prior frameworks limit the scope of auxiliary variables to be external to the mixing function. Yet, in some cases, system-driving latent factors can be easily observed or extracted from data, possibly facilitating identification. In this paper, we introduce a framework of observable sources being auxiliaries, serving as effective conditioning variables. Our main results show that one can identify entire latent variables up to subspace-wise transformations and permutations using volume-preserving encoders. Moreover, when multiple known auxiliary variables are available, we offer a variable-selection scheme to choose those that maximize recoverability of the latent factors given knowledge of the latent causal graph. Finally, we demonstrate the effectiveness of our framework through experiments on synthetic graph and image data, thereby extending the boundaries of current approaches.', 'abstract_zh': '可观测源作为辅助变量的因果表示学习', 'title_zh': '基于可观测源作为辅助的因果表示学习'}
{'arxiv_id': 'arXiv:2509.19030', 'title': 'Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action', 'authors': 'Victoire Hervé, Henrik Warpefelt, Christoph Salge', 'link': 'https://arxiv.org/abs/2509.19030', 'abstract': "Algorithmic evaluation of procedurally generated content struggles to find metrics that align with human experience, particularly for composite artefacts. Automatic decomposition as a possible solution requires concepts that meet a range of properties. To this end, drawing on Games Studies and Game AI research, we introduce the nested concepts of \\textit{Landmarks}, \\textit{Monuments}, and \\textit{Beacons}. These concepts are based on the artefact's perceivability, evocativeness, and Call to Action, all from a player-centric perspective. These terms are generic to games and usable across genres. We argue that these entities can be found and evaluated with techniques currently used in both research and industry, opening a path towards a fully automated decomposition of PCG, and evaluation of the salient sub-components. Although the work presented here emphasises mixed-initiative PCG and compositional PCG, we believe it applies beyond those domains. With this approach, we intend to create a connection between humanities and technical game research and allow for better computational PCG evaluation", 'abstract_zh': '程序生成内容的算法评估难以找到与人类体验相一致的度量标准，特别是对于复合制品。自动分解作为一种可能的解决方案需要满足一系列特性的概念。为此，借鉴Games Studies和Game AI研究，我们引入了嵌套概念：Landmarks、Monuments和Beacons。这些概念基于制品的可感知性、唤起性和呼吁行动，均从玩家中心的角度出发。这些术语适用于各类游戏，并且在不同游戏类型间通用。我们认为这些实体可以通过当前在研究和工业中均存在的技术进行发现和评估，从而开辟一条通往混合主动型PCG和组合型PCG全自动分解及其关键子组件评估的道路。尽管本文强调混合主动型PCG和组合型PCG，但我们认为这一方法适用于更广泛的领域。通过这种方法，我们旨在建立人文科学与技术游戏研究之间的联系，并允许更好地进行计算型PCG评估。', 'title_zh': '地标、纪念碑与灯塔：理解生成式召唤行动'}
{'arxiv_id': 'arXiv:2509.18986', 'title': 'Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)', 'authors': 'Erik Penther, Michael Grohs, Jana-Rebecca Rehse', 'link': 'https://arxiv.org/abs/2509.18986', 'abstract': 'Predictive process monitoring is a sub-domain of process mining which aims to forecast the future of ongoing process executions. One common prediction target is the remaining time, meaning the time that will elapse until a process execution is completed. In this paper, we compare four different remaining time prediction approaches in a real-life outbound warehouse process of a logistics company in the aviation business. For this process, the company provided us with a novel and original event log with 169,523 traces, which we can make publicly available. Unsurprisingly, we find that deep learning models achieve the highest accuracy, but shallow methods like conventional boosting techniques achieve competitive accuracy and require significantly fewer computational resources.', 'abstract_zh': '基于实际航空物流仓库过程的剩余时间预测方法比较', 'title_zh': '出库仓库流程中剩余时间预测：一个案例研究（简短论文）'}
{'arxiv_id': 'arXiv:2509.18980', 'title': 'From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system', 'authors': 'Maxime Manderlier, Fabian Lecron, Olivier Vu Thanh, Nicolas Gillis', 'link': 'https://arxiv.org/abs/2509.18980', 'abstract': "We investigate whether large language models (LLMs) can generate effective, user-facing explanations from a mathematically interpretable recommendation model. The model is based on constrained matrix factorization, where user types are explicitly represented and predicted item scores share the same scale as observed ratings, making the model's internal representations and predicted scores directly interpretable. This structure is translated into natural language explanations using carefully designed LLM prompts. Many works in explainable AI rely on automatic evaluation metrics, which often fail to capture users' actual needs and perceptions. In contrast, we adopt a user-centered approach: we conduct a study with 326 participants who assessed the quality of the explanations across five key dimensions-transparency, effectiveness, persuasion, trust, and satisfaction-as well as the recommendations this http URL evaluate how different explanation strategies are perceived, we generate multiple explanation types from the same underlying model, varying the input information provided to the LLM. Our analysis reveals that all explanation types are generally well received, with moderate statistical differences between strategies. User comments further underscore how participants react to each type of explanation, offering complementary insights beyond the quantitative results.", 'abstract_zh': '我们研究大型语言模型（LLMs）是否能够生成有效的、面向用户的来自一个数学可解释推荐模型的解释。该模型基于受约束的矩阵分解，其中用户类型被明确表示，并且预测项评分与观测评分具有相同的量纲，从而使模型的内部表示和预测评分直接可解释。该结构通过精心设计的LLM提示转化为自然语言解释。许多可解释人工智能的研究依赖于自动评估指标，这些指标往往未能捕捉到用户的实际需求和感知。相反，我们采取以用户为中心的方法：我们对326名参与者进行了研究，他们按照透明度、有效性、说服力、信任和满意度五个关键维度评估解释的质量以及推荐。为了评估不同的解释策略，我们从相同的底层模型生成多种解释类型，改变提供给LLM的输入信息。我们的分析揭示了所有解释类型通常都受到欢迎，尽管不同策略之间存在适度的统计差异。用户评论进一步强调了参与者对每种解释类型的反应，为定量结果提供了补充见解。', 'title_zh': '从潜在因素到语言：一个关于LLM生成解释的用户研究，针对固有可解释的矩阵推荐系统'}
{'arxiv_id': 'arXiv:2509.18970', 'title': 'LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions', 'authors': 'Xixun Lin, Yucheng Ning, Jingwen Zhang, Yan Dong, Yilong Liu, Yongxuan Wu, Xiaohua Qi, Nan Sun, Yanmin Shang, Pengfei Cao, Lixin Zou, Xu Chen, Chuan Zhou, Jia Wu, Shirui Pan, Bin Wang, Yanan Cao, Kai Chen, Songlin Hu, Li Guo', 'link': 'https://arxiv.org/abs/2509.18970', 'abstract': 'Driven by the rapid advancements of Large Language Models (LLMs), LLM-based agents have emerged as powerful intelligent systems capable of human-like cognition, reasoning, and interaction. These agents are increasingly being deployed across diverse real-world applications, including student education, scientific research, and financial analysis. However, despite their remarkable potential, LLM-based agents remain vulnerable to hallucination issues, which can result in erroneous task execution and undermine the reliability of the overall system design. Addressing this critical challenge requires a deep understanding and a systematic consolidation of recent advances on LLM-based agents. To this end, we present the first comprehensive survey of hallucinations in LLM-based agents. By carefully analyzing the complete workflow of agents, we propose a new taxonomy that identifies different types of agent hallucinations occurring at different stages. Furthermore, we conduct an in-depth examination of eighteen triggering causes underlying the emergence of agent hallucinations. Through a detailed review of a large number of existing studies, we summarize approaches for hallucination mitigation and detection, and highlight promising directions for future research. We hope this survey will inspire further efforts toward addressing hallucinations in LLM-based agents, ultimately contributing to the development of more robust and reliable agent systems.', 'abstract_zh': '基于大规模语言模型的智能代理中的幻觉现象综述', 'title_zh': '基于LLM的代理遭受幻觉：分类、方法和发展方向调查'}
{'arxiv_id': 'arXiv:2509.18942', 'title': 'Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning', 'authors': 'Xiao Han, Zimo Zhao, Wanyu Wang, Maolin Wang, Zitao Liu, Yi Chang, Xiangyu Zhao', 'link': 'https://arxiv.org/abs/2509.18942', 'abstract': 'Recent advancements in Large Language Models (LLMs) have emphasized the critical role of fine-tuning (FT) techniques in adapting LLMs to specific tasks, especially when retraining from scratch is computationally infeasible. Fine-tuning enables LLMs to leverage task- or domain-specific data, producing models that more effectively meet the requirements of targeted applications. However, con- ventional FT approaches often suffer from catastrophic forgetting and suboptimal data efficiency, limiting their real-world applicability. To address these challenges, this paper proposes DEAL, a novel framework that integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy. By incorporating knowledge retention and adaptive parameter update modules, the framework mitigates the lim- itations of existing FT methods while maintaining efficiency in privacy-preserving settings. Experiments on 15 diverse datasets show that DEAL consistently outper- forms baseline methods, yielding substantial gains in task accuracy and resource efficiency. These findings demonstrate the potential of our approach to advance continual adaptation in LLMs by enhancing task performance while improving resource efficiency.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）强调了微调（FT）技术在将LLMs适应特定任务中的关键作用，特别是在重新训练从头开始计算上不可行的情况下。微调使LLMs能够利用任务或领域特定的数据，从而生产出更能满足目标应用需求的模型。然而，传统的FT方法往往遭受灾难性遗忘和次优数据效率的困扰，限制了它们在现实世界中的应用。为了应对这些挑战，本文提出了一种名为DEAL的新框架，该框架将低秩适应（LoRA）与连续微调策略相结合。通过结合知识保留和自适应参数更新模块，该框架克服了现有FT方法的限制，同时在隐私保护环境中保持了效率。在15个不同的数据集上的实验结果显示，DEAL在任务准确性和资源效率方面始终优于基线方法，取得了显著的进步。这些发现展示了我们方法在通过增强任务性能同时提高资源效率来推动LLMs持续适应方面具有潜在的优势。', 'title_zh': '大规模语言模型通过连续低秩微调实现的数据高效适应'}
{'arxiv_id': 'arXiv:2509.18905', 'title': 'How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective', 'authors': 'Songsong Yu, Yuxin Chen, Hao Ju, Lianjie Jia, Fuxi Zhang, Shaofei Huang, Yuhan Wu, Rundi Cui, Binghao Ran, Zaibin Zhang, Zhedong Zheng, Zhipeng Zhang, Yifan Wang, Lin Song, Lijun Wang, Yanwei Li, Ying Shan, Huchuan Lu', 'link': 'https://arxiv.org/abs/2509.18905', 'abstract': 'Visual Spatial Reasoning (VSR) is a core human cognitive ability and a critical requirement for advancing embodied intelligence and autonomous systems. Despite recent progress in Vision-Language Models (VLMs), achieving human-level VSR remains highly challenging due to the complexity of representing and reasoning over three-dimensional space. In this paper, we present a systematic investigation of VSR in VLMs, encompassing a review of existing methodologies across input modalities, model architectures, training strategies, and reasoning mechanisms. Furthermore, we categorize spatial intelligence into three levels of capability, ie, basic perception, spatial understanding, spatial planning, and curate SIBench, a spatial intelligence benchmark encompassing nearly 20 open-source datasets across 23 task settings. Experiments with state-of-the-art VLMs reveal a pronounced gap between perception and reasoning, as models show competence in basic perceptual tasks but consistently underperform in understanding and planning tasks, particularly in numerical estimation, multi-view reasoning, temporal dynamics, and spatial imagination. These findings underscore the substantial challenges that remain in achieving spatial intelligence, while providing both a systematic roadmap and a comprehensive benchmark to drive future research in the field. The related resources of this study are accessible at this https URL.', 'abstract_zh': '视觉空间推理（VSR）是核心的人类认知能力，对于推进具身智能和自主系统至关重要。尽管在视觉-语言模型（VLMs）方面取得了近期进展，但由于三维空间表示和推理的复杂性，实现 human-level 的 VSR 仍然极具挑战性。在本文中，我们系统研究了 VLMs 中的视觉空间推理，涵盖不同输入模态、模型架构、训练策略和推理机制的方法学综述。此外，我们将空间智能分类为三个能力层次，即基础知觉、空间理解、空间规划，并制定了一个包含近 20 个开源数据集的 SIBench 空间智能基准，覆盖 23 种任务设置。最先进的 VLMs 的实验揭示了感知与推理之间明显的差距，模型在基础知觉任务上表现出色，但在理解与规划任务上始终表现不佳，特别是在数值估算、多视角推理、时间动力学和空间想象方面。这些发现强调了实现空间智能仍面临的巨大挑战，同时提供了一份系统路线图和全面基准，推动该领域的未来研究。相关资源可访问此链接。', 'title_zh': 'VLMs在视觉空间智能方面的差距：一个基准驱动的视角'}
{'arxiv_id': 'arXiv:2509.18883', 'title': 'LongCat-Flash-Thinking Technical Report', 'authors': 'Meituan LongCat Team, Anchun Gui, Bei Li, Bingyang Tao, Bole Zhou, Borun Chen, Chao Zhang, Chao Zhang, Chengcheng Han, Chenhui Yang, Chi Zhang, Chong Peng, Chuyu Zhang, Cong Chen, Fengcun Li, Gang Xu, Guoyuan Lin, Hao Jiang, Hao Liang, Haomin Fu, Haoxiang Ma, Hong Liu, Hongyan Hao, Hongyin Tang, Hongyu Zang, Hongzhi Ni, Hui Su, Jiahao Liu, Jiahuan Li, Jialin Liu, Jianfei Zhang, Jianhao Xu, Jianing Wang, Jiaqi Sun, Jiaqi Zhang, Jiarong Shi, Jiawei Yang, Jingang Wang, Jinrui Ding, Jun Kuang, Jun Xu, Ke He, Kefeng Zhang, Keheng Wang, Keqing He, Li Wei, Liang Shi, Lin Qiu, Lingbin Kong, Lingchuan Liu, Linsen Guo, Longfei An, Mai Xia, Meng Zhou, Mengshen Zhu, Peng Pei, Pengcheng Jia, Qi Gu, Qi Guo, Qiong Huang, Quan Chen, Quanchi Weng, Rongxiang Weng, Ruichen Shao, Rumei Li, Shanglin Lei, Shuai Du, Shuaikang Liu, Shuang Zhou, Shuhao Hu, Siyu Xu, Songshan Gong, Tao Liang, Tianhao Hu, Wei He, Wei Shi, Wei Wang, Wei Wu, Wei Zhuo, Weifeng Tang, Wenjie Shi, Wenlong Zhu, Xi Su, Xiangcheng Liu, Xiangyu Xi, Xiangzhou Huang, Xiao Liu, Xiaochen Jiang, Xiaowei Shi, Xiaowen Shi, Xiaoyu Li, Xin Chen, Xinyue Zhao, Xuan Huang, Xuemiao Zhang, Xuezhi Cao, Xunliang Cai, Yajie Zhang, Yang Chen, Yang Liu', 'link': 'https://arxiv.org/abs/2509.18883', 'abstract': 'We present LongCat-Flash-Thinking, an efficient 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities are cultivated through a meticulously crafted training process, beginning with long Chain-of-Thought (CoT) data cold-start and culminating in large-scale Reinforcement Learning (RL). We first employ a well-designed cold-start training strategy, which significantly enhances the reasoning potential and equips the model with specialized skills in both formal and agentic reasoning. Then, a core innovation is our domain-parallel training scheme, which decouples optimization across distinct domains (e.g., STEM, Code, Agentic) and subsequently fuses the resulting expert models into a single, nearly Pareto-optimal model. This entire process is powered by our Dynamic ORchestration for Asynchronous rollout (DORA) system, a large-scale RL framework that delivers a greater than threefold training speedup over synchronous methods on tens of thousands of accelerators. As a result, LongCat-Flash-Thinking achieves state-of-the-art performance among open-source models on a suite of complex reasoning tasks. The model exhibits exceptional efficiency in agentic reasoning, reducing average token consumption by 64.5% (from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We release LongCat-Flash-Thinking to promote further advances in reasoning systems and agentic AI research.', 'abstract_zh': '长猫-闪电思考：一个高效的560亿参数开源混合专家推理模型', 'title_zh': '长猫-闪思技术报告'}
{'arxiv_id': 'arXiv:2509.18868', 'title': 'Memory in Large Language Models: Mechanisms, Evaluation and Evolution', 'authors': 'Dianxing Zhang, Wendong Li, Kani Song, Jiaye Lu, Gang Li, Liuchun Yang, Sheng Li', 'link': 'https://arxiv.org/abs/2509.18868', 'abstract': 'Under a unified operational definition, we define LLM memory as a persistent state written during pretraining, finetuning, or inference that can later be addressed and that stably influences outputs. We propose a four-part taxonomy (parametric, contextual, external, procedural/episodic) and a memory quadruple (location, persistence, write/access path, controllability). We link mechanism, evaluation, and governance via the chain write -> read -> inhibit/update. To avoid distorted comparisons across heterogeneous setups, we adopt a three-setting protocol (parametric only, offline retrieval, online retrieval) that decouples capability from information availability on the same data and timeline. On this basis we build a layered evaluation: parametric (closed-book recall, edit differential, memorization/privacy), contextual (position curves and the mid-sequence drop), external (answer correctness vs snippet attribution/faithfulness), and procedural/episodic (cross-session consistency and timeline replay, E MARS+). The framework integrates temporal governance and leakage auditing (freshness hits, outdated answers, refusal slices) and uncertainty reporting via inter-rater agreement plus paired tests with multiple-comparison correction. For updating and forgetting, we present DMM Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC), and RAG to form an auditable loop covering admission thresholds, rollout, monitoring, rollback, and change audits, with specs for timeliness, conflict handling, and long-horizon consistency. Finally, we give four testable propositions: minimum identifiability; a minimal evaluation card; causally constrained editing with verifiable forgetting; and when retrieval with small-window replay outperforms ultra-long-context reading. This yields a reproducible, comparable, and governable coordinate system for research and deployment.', 'abstract_zh': '在统一的操作定义下，我们将LLM记忆定义为在预训练、微调或推理过程中写入的持久状态，可以后期访问并稳定影响输出。我们提出了一种四部分分类法（参数化、上下文、外部、程序性/情景性）和一个记忆四元组（位置、持久性、写/访问路径、可控性）。我们通过写->读->抑制/更新的链条将机制、评估和治理联系起来。为了避免异构设置间的失真比较，我们采用了一种三设置协议（仅参数化、离线检索、在线检索），从而解耦能力与相同数据和时间线上的信息可用性。在此基础上，我们构建了一种分层评估体系：参数化（闭卷回忆、编辑差异、记忆/隐私）、上下文（位置曲线和中间序列下降）、外部（答案正确性 vs 摘要归因/忠实性）、程序性/情景性（跨会话一致性与时序重放、E MARS+）。框架整合了时序治理和泄漏审计（新鲜度命中、过时回答、拒绝片段）以及通过跨评判者一致性和配对检验进行的不确定性报告。对于记忆更新和遗忘，我们介绍了DMM Gov：协调DAPT/TAPT、PEFT、模型编辑（ROME、MEND、MEMIT、SERAC）和RAG，形成一个可审计循环，涵盖准入门槛、部署、监控、回滚和变更审计，并有时间敏感性、冲突处理和长周期一致性的规格说明。最后，我们提出了四项可测试的命题：最小可识别性；最小评估卡片；因果约束编辑与可验证遗忘；以及何时小窗口检索优于超长上下文阅读。这为研究和部署提供了可重现、可比较和可治理的坐标体系。', 'title_zh': '大型语言模型中的记忆：机制、评估与进化'}
{'arxiv_id': 'arXiv:2509.18864', 'title': 'Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling', 'authors': 'Yingxin Li, Jianbo Zhao, Xueyu Ren, Jie Tang, Wangjie You, Xu Chen, Kan Zhou, Chao Feng, Jiao Ran, Yuan Meng, Zhi Wang', 'link': 'https://arxiv.org/abs/2509.18864', 'abstract': 'User profiling, as a core technique for user understanding, aims to infer structural attributes from user information. Large Language Models (LLMs) provide a promising avenue for user profiling, yet the progress is hindered by the lack of comprehensive benchmarks. To bridge this gap, we propose ProfileBench, an industrial benchmark derived from a real-world video platform, encompassing heterogeneous user data and a well-structured profiling taxonomy. However, the profiling task remains challenging due to the difficulty of collecting large-scale ground-truth labels, and the heterogeneous and noisy user information can compromise the reliability of LLMs. To approach label-free and reliable user profiling, we propose a Confidence-driven Profile reasoning framework Conf-Profile, featuring a two-stage paradigm. We first synthesize high-quality labels by leveraging advanced LLMs with confidence hints, followed by confidence-weighted voting for accuracy improvement and confidence calibration for a balanced distribution. The multiple profile results, rationales, and confidence scores are aggregated and distilled into a lightweight LLM. We further enhance the reasoning ability via confidence-guided unsupervised reinforcement learning, which exploits confidence for difficulty filtering, quasi-ground truth voting, and reward weighting. Experimental results demonstrate that Conf-Profile delivers substantial performance through the two-stage training, improving F1 by 13.97 on Qwen3-8B.', 'abstract_zh': '用户画像构建：一种基于信心驱动的框架', 'title_zh': '基于信心驱动的推理范式：无标签用户画像方法'}
{'arxiv_id': 'arXiv:2509.18849', 'title': 'MAPO: Mixed Advantage Policy Optimization', 'authors': 'Wenke Huang, Quan Zhang, Yiyang Fang, Jian Liang, Xuankun Rong, Huanjin Yao, Guancheng Wan, Ke Liang, Wenwen He, Mingjun Li, Leszek Rutkowski, Mang Ye, Bo Du, Dacheng Tao', 'link': 'https://arxiv.org/abs/2509.18849', 'abstract': 'Recent advances in reinforcement learning for foundation models, such as Group Relative Policy Optimization (GRPO), have significantly improved the performance of foundation models on reasoning tasks. Notably, the advantage function serves as a central mechanism in GRPO for ranking the trajectory importance. However, existing explorations encounter both advantage reversion and advantage mirror problems, which hinder the reasonable advantage allocation across different query samples. In this work, we propose an easy but effective GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the trajectory appears with different certainty and propose the advantage percent deviation for samples with high-certainty trajectories. Furthermore, we dynamically reweight the advantage function for samples with varying trajectory certainty, thereby adaptively configuring the advantage function to account for sample-specific characteristics. Comparison with related state-of-the-art methods, along with ablation studies on different advantage variants, validates the effectiveness of our approach.', 'abstract_zh': '最近在基础模型中强化学习的进步，如Group Relative Policy Optimization (GRPO)，显著提高了基础模型在推理任务上的性能。值得注意的是，优势函数在GRPO中作为核心机制用于评价轨迹的重要性。然而，现有的探索遇到优势反转和优势镜像问题，这妨碍了不同查询样本间合理的优势分配。在这项工作中，我们提出了一种简单而有效的GRPO策略，混合优势策略优化（MAPO）。我们揭示了轨迹存在不同确定性，并为高确定性轨迹的样本引入优势百分比偏差。此外，我们动态调整优势函数的权重以适应轨迹确定性变化的样本，从而根据样本特定特征适应性配置优势函数。与相关先进方法的比较以及不同优势变体的消融研究验证了我们方法的有效性。', 'title_zh': 'MAPO: 混合优势策略优化'}
{'arxiv_id': 'arXiv:2509.18846', 'title': 'Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning', 'authors': 'Hong-Jie Dai, Zheng-Hao Li, An-Tai Lu, Bo-Tsz Shain, Ming-Ta Li, Tatheer Hussain Mir, Kuang-Te Wang, Min-I Su, Pei-Kang Liu, Ming-Ju Tsai', 'link': 'https://arxiv.org/abs/2509.18846', 'abstract': 'Accurate International Classification of Diseases (ICD) coding is critical for clinical documentation, billing, and healthcare analytics, yet it remains a labour-intensive and error-prone task. Although large language models (LLMs) show promise in automating ICD coding, their challenges in base model selection, input contextualization, and training data redundancy limit their effectiveness. We propose a modular framework for ICD-10 Clinical Modification (ICD-10-CM) code prediction that addresses these challenges through principled model selection, redundancy-aware data sampling, and structured input design. The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce aggregation to assess and rank open-source LLMs based on their intrinsic comprehension of ICD-10-CM code definitions. We introduced embedding-based similarity measures, a redundancy-aware sampling strategy to remove semantically duplicated discharge summaries. We leverage structured discharge summaries from Taiwanese hospitals to evaluate contextual effects and examine section-wise content inclusion under universal and section-specific modelling paradigms. Experiments across two institutional datasets demonstrate that the selected base model after fine-tuning consistently outperforms baseline LLMs in internal and external evaluations. Incorporating more clinical sections consistently improves prediction performance. This study uses open-source LLMs to establish a practical and principled approach to ICD-10-CM code prediction. The proposed framework provides a scalable, institution-ready solution for real-world deployment of automated medical coding systems by combining informed model selection, efficient data refinement, and context-aware prompting.', 'abstract_zh': '准确的国际疾病分类（ICD）编码对于临床记录、计费和医疗健康数据分析至关重要，然而这一过程仍然是劳动密集型且容易出错的任务。尽管大型语言模型（LLMs）在自动化ICD编码方面显示出潜力，但在基础模型选择、输入上下文中化以及训练数据冗余方面的挑战限制了其效果。我们提出了一种模块化框架，通过原理性的模型选择、冗余感知数据采样和结构化输入设计来解决这些挑战。该框架整合了LLM-as-judge评估协议和Plackett-Luce聚合，基于其对ICD-10-CM代码定义的内在理解来评估和排名开源LLMs。我们引入了基于嵌入的相似性度量，提出了一种冗余感知的采样策略以去除语义上重复的出院总结。我们利用台湾医院的结构化出院总结来评估上下文效应，并在通用和板块特定建模范式下检查板块级内容的纳入情况。在两个机构数据集中进行的实验显示，调整后的基础模型在内部和外部评估中均优于基础LLMs。增加更多临床板块的一致性改善了预测性能。本研究使用开源LLMs建立了ICD-10-CM编码预测的实用和原则性方法。提出的框架通过结合知情的模型选择、高效的数据精炼以及上下文感知的提示，提供了面向实际部署的自动化医疗编码系统的可扩展、机构级解决方案。', 'title_zh': '模型选择遇见临床语义：基于LLM-as-Judge评估、冗余感知采样和章节感知微调的ICD-10-CM预测优化'}
{'arxiv_id': 'arXiv:2509.18836', 'title': 'Bounded PCTL Model Checking of Large Language Model Outputs', 'authors': 'Dennis Gross, Helge Spieker, Arnaud Gotlieb', 'link': 'https://arxiv.org/abs/2509.18836', 'abstract': 'In this paper, we introduce LLMCHECKER, a model-checking-based verification method to verify the probabilistic computation tree logic (PCTL) properties of an LLM text generation process. We empirically show that only a limited number of tokens are typically chosen during text generation, which are not always the same. This insight drives the creation of $\\alpha$-$k$-bounded text generation, narrowing the focus to the $\\alpha$ maximal cumulative probability on the top-$k$ tokens at every step of the text generation process. Our verification method considers an initial string and the subsequent top-$k$ tokens while accommodating diverse text quantification methods, such as evaluating text quality and biases. The threshold $\\alpha$ further reduces the selected tokens, only choosing those that exceed or meet it in cumulative probability. LLMCHECKER then allows us to formally verify the PCTL properties of $\\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our knowledge, this is the first time PCTL-based model checking has been used to check the consistency of the LLM text generation process.', 'abstract_zh': '基于模型检查的LLM文本生成过程的概率计算树逻辑（PCTL）属性验证方法：$\\alpha$-$k$-受限文本生成的形式验证', 'title_zh': '大规模语言模型输出的有界PCTL模型检验'}
{'arxiv_id': 'arXiv:2509.18787', 'title': 'The AGNTCY Agent Directory Service: Architecture and Implementation', 'authors': 'Luca Muscariello, Vijoy Pandey, Ramiz Polic', 'link': 'https://arxiv.org/abs/2509.18787', 'abstract': 'The Agent Directory Service (ADS) is a distributed directory for the discovery of AI agent capabilities, metadata, and provenance. It leverages content-addressed storage, hierarchical taxonomies, and cryptographic signing to enable efficient, verifiable, and multi-dimensional discovery across heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema Framework (OASF), ADS decouples capability indexing from content location through a two-level mapping realized over a Kademlia-based Distributed Hash Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact distribution, integrates Sigstore for provenance, and supports schema-driven extensibility for emerging agent modalities (LLM prompt agents, MCP servers, A2A-enabled components). This paper formalizes the architectural model, describes storage and discovery layers, explains security and performance properties, and positions ADS within the broader landscape of emerging agent registry and interoperability initiatives.', 'abstract_zh': 'Agent_DIRECTORY_SERVICE (ADS) 是一个分布式目录，用于发现AI代理能力、元数据和起源。它利用内容寻址存储、层次分类法和加密签名，实现跨异构多代理系统（MAS）的高效、可验证和多维度发现。基于Open Agentic Schema Framework (OASF)，ADS 通过基于Kademlia的分布式哈希表（DHT）实现的两层映射，将能力索引与内容位置解耦。它重用了成熟的OCI / ORAS基础设施进行 artifacts 分发，集成了Sigstore用于证明，并支持基于模式的扩展性以支持新兴代理模态（如LLM提示代理、MCP服务器、A2A启用的组件）。本文形式化了该架构模型，描述了存储和发现层，解释了安全性和性能属性，并将ADS置于更广泛的新兴代理注册和互操作性倡议的大环境中。', 'title_zh': 'AGNTCY代理目录服务：架构与实现'}
{'arxiv_id': 'arXiv:2509.18771', 'title': 'Experience Scaling: Post-Deployment Evolution For Large Language Models', 'authors': 'Xingkun Yin, Kaibin Huang, Dong In Kim, Hongyang Du', 'link': 'https://arxiv.org/abs/2509.18771', 'abstract': 'Scaling model size, training data, and compute power have driven advances in large language models (LLMs), but these approaches are reaching saturation as human-generated text is exhausted and further gains diminish. We propose experience scaling, a framework for continuous post-deployment evolution for LLMs through autonomous interaction with the environment and collaborative sharing of accumulated experience. The framework captures raw interactions, distills them into compact, reusable knowledge, and periodically refines stored content to preserve relevance and efficiency. We validate the framework in simulated real-world scenarios involving generalization to previously unseen but related tasks, repetitive queries, and over-saturated knowledge stores. Across all settings, experience scaling improves accuracy, sustains performance over time, and maintains gains when applied to novel situations. These results demonstrate that structured post-deployment learning can extend LLM capabilities beyond the limits of static human-generated data, offering a scalable path for continued intelligence progress.', 'abstract_zh': '经验扩展：通过与环境自主交互及累积经验的协作共享，持续演进大规模语言模型', 'title_zh': '经验扩展：大型语言模型的部署后演化'}
{'arxiv_id': 'arXiv:2509.18710', 'title': 'Autonomous Data Agents: A New Opportunity for Smart Data', 'authors': 'Yanjie Fu, Dongjie Wang, Wangyang Ying, Xiangliang Zhang, Huan Liu, Jian Pei', 'link': 'https://arxiv.org/abs/2509.18710', 'abstract': 'As data continues to grow in scale and complexity, preparing, transforming, and analyzing it remains labor-intensive, repetitive, and difficult to scale. Since data contains knowledge and AI learns knowledge from it, the alignment between AI and data is essential. However, data is often not structured in ways that are optimal for AI utilization. Moreover, an important question arises: how much knowledge can we pack into data through intensive data operations? Autonomous data agents (DataAgents), which integrate LLM reasoning with task decomposition, action reasoning and grounding, and tool calling, can autonomously interpret data task descriptions, decompose tasks into subtasks, reason over actions, ground actions into python code or tool calling, and execute operations. Unlike traditional data management and engineering tools, DataAgents dynamically plan workflows, call powerful tools, and adapt to diverse data tasks at scale. This report argues that DataAgents represent a paradigm shift toward autonomous data-to-knowledge systems. DataAgents are capable of handling collection, integration, preprocessing, selection, transformation, reweighing, augmentation, reprogramming, repairs, and retrieval. Through these capabilities, DataAgents transform complex and unstructured data into coherent and actionable knowledge. We first examine why the convergence of agentic AI and data-to-knowledge systems has emerged as a critical trend. We then define the concept of DataAgents and discuss their architectural design, training strategies, as well as the new skills and capabilities they enable. Finally, we call for concerted efforts to advance action workflow optimization, establish open datasets and benchmark ecosystems, safeguard privacy, balance efficiency with scalability, and develop trustworthy DataAgent guardrails to prevent malicious actions.', 'abstract_zh': '随着数据在规模和复杂性上不断增长，数据的准备、转换和分析仍然是劳动密集型、重复性和难以扩展的任务。由于数据中蕴含知识，而AI通过学习数据中的知识来进行学习，因此AI与数据之间的对齐至关重要。然而，数据往往并未以最适合AI利用的方式结构化。此外，一个重要的问题是：通过密集的数据操作，我们能将多少知识整合进数据中？自主数据代理（DataAgents），结合了LLM推理、任务分解、动作推理与定位以及工具调用，能够自主解析数据任务描述，将任务分解为子任务，推理动作，将动作定位为Python代码或工具调用，并执行操作。与传统数据管理和工程工具不同，DataAgents能够动态规划工作流、调用强大工具，并在大规模环境下适应各种数据任务。本报告认为，DataAgents标志着向自主数据到知识系统的范式转变。DataAgents能够处理数据收集、集成、预处理、选择、转换、重新权重、增强、重新编程、修复和检索。通过这些能力，DataAgents将复杂且未结构化数据转变成连贯且可操作的知识。我们首先探讨为什么代理AI与数据到知识系统交汇成为一项关键趋势。然后定义DataAgents的概念，讨论其架构设计、训练策略，以及它们所赋予的新技能和能力。最后，我们呼吁协同努力，以优化行动工作流、建立开放数据集和基准生态系统、保障隐私、在效率与扩展性之间取得平衡，并开发值得信赖的DataAgent护栏，以阻止恶意行为。', 'title_zh': '自主数据代理：智能数据的新机遇'}
{'arxiv_id': 'arXiv:2509.18690', 'title': 'Advances in Large Language Models for Medicine', 'authors': 'Zhiyu Kan, Wensheng Gan, Zhenlian Qi, Philip S. Yu', 'link': 'https://arxiv.org/abs/2509.18690', 'abstract': 'Artificial intelligence (AI) technology has advanced rapidly in recent years, with large language models (LLMs) emerging as a significant breakthrough. LLMs are increasingly making an impact across various industries, with the medical field standing out as the most prominent application area. This paper systematically reviews the up-to-date research progress of LLMs in the medical field, providing an in-depth analysis of training techniques for large medical models, their adaptation in healthcare settings, related applications, as well as their strengths and limitations. Furthermore, it innovatively categorizes medical LLMs into three distinct types based on their training methodologies and classifies their evaluation approaches into two categories. Finally, the study proposes solutions to existing challenges and outlines future research directions based on identified issues in the field of medical LLMs. By systematically reviewing previous and advanced research findings, we aim to highlight the necessity of developing medical LLMs, provide a deeper understanding of their current state of development, and offer clear guidance for subsequent research.', 'abstract_zh': '人工智能技术近年来取得了 rapid进展，大型语言模型（LLMs） emerged作为重要的突破。LLMs在各个行业中 increasingly产生了影响，医学领域尤为突出。本文系统地回顾了LLMs在医学领域的最新研究进展，深入分析了大型医疗模型的训练技术、在医疗保健环境中的应用适应性、相关应用及其优势和局限性。此外，本文创新性地根据训练方法将医疗LLMs分为三类，并将评估方法分为两类。最后，研究提出了现有挑战的解决方案，并基于医疗LLMs领域识别的问题，指出了未来的研究方向。通过系统地回顾先前和最新的研究发现，本文旨在强调开发医疗LLMs的必要性，提供对其当前发展状态的深入理解，并为后续研究提供明确的指导。', 'title_zh': '大型语言模型在医学领域的进展'}
{'arxiv_id': 'arXiv:2509.18681', 'title': 'Implementation of airborne ML models with semantics preservation', 'authors': 'Nicolas Valot, Louis Fabre, Benjamin Lesage, Ammar Mechouche, Claire Pagetti', 'link': 'https://arxiv.org/abs/2509.18681', 'abstract': 'Machine Learning (ML) may offer new capabilities in airborne systems. However, as any piece of airborne systems, ML-based systems will be required to guarantee their safe operation. Thus, their development will have to be demonstrated to be compliant with the adequate guidance. So far, the European Union Aviation Safety Agency (EASA) has published a concept paper and an EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level objectives to confirm the ML model achieves its intended function and maintains training performance in the target environment. The paper aims to clarify the difference between an ML model and its corresponding unambiguous description, referred to as the Machine Learning Model Description (MLMD). It then refines the essential notion of semantics preservation to ensure the accurate replication of the model. We apply our contributions to several industrial use cases to build and compare several target models.', 'abstract_zh': '基于机器学习的空中系统可能提供新的能力。然而，如同任何空中系统一样，基于机器学习的系统也需要保证其安全运行。因此，其开发必须证明符合适当的指导方针。到目前为止，欧洲航空安全局（EASA）已经发布了概念文件，而一个EUROCAE/SAE小组正在准备ED-324。这两种方法都规定了高层次的目标，以确保机器学习模型实现其预期功能并在目标环境中保持训练性能。本文旨在阐明机器学习模型与其相应的明确描述之间的区别，将其称为机器学习模型描述（MLMD），并进一步细化语义保留的基本概念，以确保模型的精确复制。我们应用我们的贡献到几个工业应用案例中，构建并比较了几种目标模型。', 'title_zh': '具有语义保留的机载ML模型实现'}
{'arxiv_id': 'arXiv:2509.18667', 'title': 'TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation', 'authors': 'Qiao Xiao, Hong Ting Tsang, Jiaxin Bai', 'link': 'https://arxiv.org/abs/2509.18667', 'abstract': 'Graph-based Retrieval-augmented generation (RAG) has become a widely studied approach for improving the reasoning, accuracy, and factuality of Large Language Models. However, many existing graph-based RAG systems overlook the high cost associated with LLM token usage during graph construction, hindering large-scale adoption. To address this, we propose TERAG, a simple yet effective framework designed to build informative graphs at a significantly lower cost. Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the retrieval phase, and we achieve at least 80% of the accuracy of widely used graph-based RAG methods while consuming only 3%-11% of the output tokens.', 'abstract_zh': '基于图的检索增强生成（RAG）已成为提高大型语言模型推理、准确性和事实性的广泛研究方法。然而，许多现有的基于图的RAG系统忽视了在构建图过程中LLM-token使用产生的高成本，阻碍了大规模应用。为此，我们提出了TERAG，这是一种简单而有效的框架，旨在以显著降低的成本构建信息性的图。受HippoRAG启发，在检索阶段引入个性化PageRank（PPR），我们在仅消耗广泛使用的基于图的RAG方法3%-11%输出token的前提下，实现了至少80%的准确率。', 'title_zh': 'TERAG: 基于图的检索增强生成-token高效版'}
{'arxiv_id': 'arXiv:2509.18633', 'title': 'Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents', 'authors': 'Yara Mohajerani', 'link': 'https://arxiv.org/abs/2509.18633', 'abstract': 'Climate risk assessment requires modelling complex interactions between spatially heterogeneous hazards and adaptive economic systems. We present a novel geospatial agent-based model that integrates climate hazard data with evolutionary learning for economic agents. Our framework combines Mesa-based spatial modelling with CLIMADA climate impact assessment, introducing adaptive learning behaviours that allow firms to evolve strategies for budget allocation, pricing, wages, and risk adaptation through fitness-based selection and mutation. We demonstrate the framework using riverine flood projections under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to converge with baseline (no hazard) production levels after decades of disruption due to climate stress. Our results reveal systemic risks where even agents that are not directly exposed to floods face impacts through supply chain disruptions, with the end-of-century average price of goods 5.6% higher under RCP8.5 compared to the baseline. This open-source framework provides financial institutions and companies with tools to quantify both direct and cascading climate risks while evaluating cost-effective adaptation strategies.', 'abstract_zh': '气候变化风险评估要求建模空间异质性风险与适应性经济系统之间的复杂交互作用。我们提出了一种新颖的地理空间基于代理的模型，将气候灾害数据与经济代理的演化学习相结合。我们的框架结合了基于Mesa的空间建模与CLIMADA气候影响评估，引入了适应性学习行为，允许企业通过基于适应性的选择和突变来进化预算分配、定价、工资和风险适应策略。我们使用RCP8.5情景下的直至2100年的河流洪水预测来展示该框架，表明演化适应使企业在数十年的气候变化冲击后能够与基准（无灾害）生产水平收敛。我们的结果揭示了系统性风险，在这种风险下，即使未直接暴露于洪水中的代理也通过供应链中断受到影响，而RCP8.5情景下到本世纪末的商品平均价格比基准情景高出5.6%。该开源框架为金融机构和企业提供工具，用于量化直接和连锁气候风险，并评估成本效益适应策略。', 'title_zh': '基于空间的代理模型中空间自适应学习在气候风险评估中的应用：演化经济代理的地理空间框架'}
{'arxiv_id': 'arXiv:2509.18565', 'title': 'Solving Math Word Problems Using Estimation Verification and Equation Generation', 'authors': 'Mitchell Piehl, Dillon Wilson, Ananya Kalita, Jugal Kalita', 'link': 'https://arxiv.org/abs/2509.18565', 'abstract': "Large Language Models (LLMs) excel at various tasks, including problem-solving and question-answering. However, LLMs often find Math Word Problems (MWPs) challenging because solving them requires a range of reasoning and mathematical abilities with which LLMs seem to struggle. Recent efforts have helped LLMs solve more complex MWPs with improved prompts. This study proposes a novel method that initially prompts an LLM to create equations from a decomposition of the question, followed by using an external symbolic equation solver to produce an answer. To ensure the accuracy of the obtained answer, inspired by an established recommendation of math teachers, the LLM is instructed to solve the MWP a second time, but this time with the objective of estimating the correct answer instead of solving it exactly. The estimation is then compared to the generated answer to verify. If verification fails, an iterative rectification process is employed to ensure the correct answer is eventually found. This approach achieves new state-of-the-art results on datasets used by prior published research on numeric and algebraic MWPs, improving the previous best results by nearly two percent on average. In addition, the approach obtains satisfactory results on trigonometric MWPs, a task not previously attempted to the authors' best knowledge. This study also introduces two new datasets, SVAMPClean and Trig300, to further advance the testing of LLMs' reasoning abilities.", 'abstract_zh': '大型语言模型在求解数学文字题方面的新型方法及其应用', 'title_zh': '使用估算验证和方程生成解决数学单词问题'}
{'arxiv_id': 'arXiv:2509.18557', 'title': 'LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs', 'authors': 'Tom Pawelek, Raj Patel, Charlotte Crowell, Noorbakhsh Amiri, Sudip Mittal, Shahram Rahimi, Andy Perkins', 'link': 'https://arxiv.org/abs/2509.18557', 'abstract': 'Compared to traditional models, agentic AI represents a highly valuable target for potential attackers as they possess privileged access to data sources and API tools, which are traditionally not incorporated into classical agents. Unlike a typical software application residing in a Demilitarized Zone (DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI (only defining a final goal, leaving the path selection to LLM). This characteristic introduces substantial security risk to both operational security and information security. Most common existing defense mechanism rely on detection of malicious intent and preventing it from reaching the LLM agent, thus protecting against jailbreak attacks such as prompt injection. In this paper, we present an alternative approach, LLMZ+, which moves beyond traditional detection-based approaches by implementing prompt whitelisting. Through this method, only contextually appropriate and safe messages are permitted to interact with the agentic LLM. By leveraging the specificity of context, LLMZ+ guarantees that all exchanges between external users and the LLM conform to predefined use cases and operational boundaries. Our approach streamlines the security framework, enhances its long-term resilience, and reduces the resources required for sustaining LLM information security. Our empirical evaluation demonstrates that LLMZ+ provides strong resilience against the most common jailbreak prompts. At the same time, legitimate business communications are not disrupted, and authorized traffic flows seamlessly between users and the agentic LLM. We measure the effectiveness of approach using false positive and false negative rates, both of which can be reduced to 0 in our experimental setting.', 'abstract_zh': '与传统模型相比，Agency AI 是潜在攻击者的一个高度有价值的攻击目标，因为它们拥有对数据源和 API 工具的特权访问权限，而这些通常未被经典代理所纳入。不同于通常驻留在非军事化区（DMZ）中的典型软件应用，Agency LLM 意识到依靠 AI 的不确定性行为（仅定义最终目标，将路径选择留给 LLM）。这一特性为操作安全和信息安全带来了重大的安全风险。现有的大多数防御机制依赖于检测恶意意图并阻止其到达 LLM 代理，从而防止诸如提示注入的监狱突破攻击。本文提出了一种替代方法 LLMZ+，通过实现提示白名单超越了传统的基于检测的方法。通过这种方法，仅允许上下文相关和安全的消息与 Agency LLM 交互。借助于上下文的特定性，LLMZ+ 保证所有外部用户与 LLM 之间的交流符合预定义的用例和操作边界。我们的方法简化了安全框架，增强了其长期韧性，并减少了维持 LLM 信息安全所需资源。实证评估表明，LLMZ+ 对最常见的监狱突破提示提供了强大的抗性。同时，合法的商业通信未受到影响，授权的流量在用户和 Agency LLM 之间顺畅流动。我们通过误报率和漏报率衡量方法的有效性，在实验设置中，这两种率都可以减少到 0。', 'title_zh': 'LLMZ+: 用于自主生成模型的上下文提示白名单原则'}
{'arxiv_id': 'arXiv:2509.18527', 'title': 'FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning', 'authors': 'Ziwen Chen, Zhong Wang', 'link': 'https://arxiv.org/abs/2509.18527', 'abstract': 'The sport of fencing, like many other sports, faces challenges in refereeing: subjective calls, human errors, bias, and limited availability in practice environments. We present FERA (Fencing Referee Assistant), a prototype AI referee for foil fencing which integrates pose-based multi-label action recognition and rule-based reasoning. FERA extracts 2D joint positions from video, normalizes them, computes a 101-dimensional kinematic feature set, and applies a Transformer for multi-label move and blade classification. To determine priority and scoring, FERA applies a distilled language model with encoded right-of-way rules, producing both a decision and an explanation for each exchange. With limited hand-labeled data, a 5-fold cross-validation achieves an average macro-F1 score of 0.549, outperforming multiple baselines, including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla Transformer. While not ready for deployment, these results demonstrate a promising path towards automated referee assistance in foil fencing and new opportunities for AI applications, such as coaching in the field of fencing.', 'abstract_zh': '击剑运动作为其他许多运动一样，裁判工作面临挑战：主观判罚、人为错误、偏见以及实践环境的有限可用性。我们提出了一种击剑裁判助手FERA，这是一种基于姿势的多标签动作识别与规则推理相结合的AI裁判原型，适用于花剑比赛。FERA从视频中提取2D关节位置，进行标准化处理，计算出101维的动力学特征集，并应用Transformer进行多标签动作和剑法分类。为了确定优先级和计分，FERA应用了一种精炼的语言模型，结合了优先权规则编码，为每一回合提供决策和解释。尽管仅使用少量手动标注的数据，5折交叉验证达到了平均宏F1分数0.549，优于多个基准模型，包括时间卷积网络（TCN）、BiLSTM和纯Transformer模型。虽然尚未准备好部署，但这些结果展示了自动化击剑裁判辅助的新前景，并为击剑领域的教练应用等新的AI应用场景提供了可能。', 'title_zh': 'FERA：基于姿势的多标签动作识别和规则推理的击剑裁判助手'}
{'arxiv_id': 'arXiv:2509.18436', 'title': 'Memory-QA: Answering Recall Questions Based on Multimodal Memories', 'authors': 'Hongda Jiang, Xinyuan Zhang, Siddhant Garg, Rishab Arora, Shiun-Zu Kuo, Jiayang Xu, Christopher Brossman, Yue Liu, Aaron Colak, Ahmed Aly, Anuj Kumar, Xin Luna Dong', 'link': 'https://arxiv.org/abs/2509.18436', 'abstract': 'We introduce Memory-QA, a novel real-world task that involves answering recall questions about visual content from previously stored multimodal memories. This task poses unique challenges, including the creation of task-oriented memories, the effective utilization of temporal and location information within memories, and the ability to draw upon multiple memories to answer a recall question. To address these challenges, we propose a comprehensive pipeline, Pensieve, integrating memory-specific augmentation, time- and location-aware multi-signal retrieval, and multi-memory QA fine-tuning. We created a multimodal benchmark to illustrate various real challenges in this task, and show the superior performance of Pensieve over state-of-the-art solutions (up to 14% on QA accuracy).', 'abstract_zh': 'Memory-QA：一种涉及从先前存储的多模态记忆中回答关于视觉内容的回忆问题的新颖现实世界任务', 'title_zh': '基于多模态记忆的Memory-QA：回答回忆型问题'}
{'arxiv_id': 'arXiv:2509.18420', 'title': 'Instruction-Following Evaluation in Function Calling for Large Language Models', 'authors': 'Nikolai Skripko', 'link': 'https://arxiv.org/abs/2509.18420', 'abstract': 'Function calling is a core capability of large language models, essential for AI agents. Existing benchmarks such as the Berkeley Function Calling Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench (arXiv:2501.12851) evaluate argument correctness but do not test adherence to format instructions embedded in parameter descriptions, such as enclosing values in double quotes or using ISO date formats.\nWe introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911) that assesses precise instruction following in function calling. IFEval-FC encodes verifiable formats directly within JSON schema descriptions, for example specifying that a value must not contain punctuation. It includes 750 test cases, each consisting of a function with an embedded format for one of its input parameters and a corresponding user query. Evaluation is fully algorithmic, ensuring objectivity, reproducibility, and scalability.\nOur results show that even state-of-the-art proprietary models, including GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules, highlighting a practical limitation for real-world agent systems. The complete codebase and data are publicly available at this https URL.', 'abstract_zh': 'IFEval-FC：评估函数调用中精确指令遵循的基准', 'title_zh': '大型语言模型中基于指令的函数调用评估'}
{'arxiv_id': 'arXiv:2509.18400', 'title': 'ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification', 'authors': 'Pritish Yuvraj, Siva Devarakonda', 'link': 'https://arxiv.org/abs/2509.18400', 'abstract': 'Accurate classification of products under the Harmonized Tariff Schedule (HTS) is a critical bottleneck in global trade, yet it has received little attention from the machine learning community. Misclassification can halt shipments entirely, with major postal operators suspending deliveries to the U.S. due to incomplete customs documentation. We introduce the first benchmark for HTS code classification, derived from the U.S. Customs Rulings Online Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit classifications and 57.5 percent correct 6-digit classifications, improvements of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking. Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to guarantee data privacy in high-stakes trade and compliance workflows. While Atlas sets a strong baseline, the benchmark remains highly challenging, with only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim to position HTS classification as a new community benchmark task and invite future work in retrieval, reasoning, and alignment.', 'abstract_zh': '准确分类海关 Harmonized Tariff Schedule (HTS) 代码是全球贸易中的关键瓶颈，但尚未得到机器学习社区的广泛关注。误分类可能导致货物被完全停止运送，尤其是由于 incomplete 的海关文件导致主要邮政运营商暂停向美国的发货。我们介绍了首个 HTS 代码分类基准，该基准源自美国海关在线裁决搜索系统 (CROSS)。评估领先的大规模语言模型 (LLM)，我们的 Fine-tuned Atlas 模型 (LLaMA-3.3-70B) 实现了 40% 的完全正确 10 位分类和 57.5% 的正确 6 位分类，分别优于 GPT-5-Thinking 15 个百分点和 Gemini-2.5-Pro-Thinking 27.5 个百分点。此外，Atlas 的成本分别是 GPT-5-Thinking 和 Gemini-2.5-Pro-Thinking 的五分之一和八分之一，并且可以自我托管以保证敏感贸易和合规工作流程中的数据隐私。尽管 Atlas 设置了强有力的基线，但基准测试仍然极具挑战性，仅实现了 40% 的 10 位准确率。通过发布数据集和模型，我们旨在将 HTS 分类定位为新的社区基准任务，并邀请未来的检索、推理和对齐工作。', 'title_zh': 'ATLAS: 全球贸易中的基准测试与适应大语言模型通过协调关税代码分类'}
{'arxiv_id': 'arXiv:2509.18383', 'title': 'Gödel Test: Can Large Language Models Solve Easy Conjectures?', 'authors': 'Moran Feldman, Amin Karbasi', 'link': 'https://arxiv.org/abs/2509.18383', 'abstract': "Recent announcements from frontier AI model labs have highlighted strong results on high-school and undergraduate math competitions. Yet it remains unclear whether large language models can solve new, simple conjectures in more advanced areas of mathematics. We propose the Gödel Test: evaluating whether a model can produce correct proofs for very simple, previously unsolved conjectures. To this end, we study the performance of GPT-5 on five conjectures in combinatorial optimization. For each problem, we provided one or two source papers from which the conjecture arose, withheld our own conjecture, and then assessed the model's reasoning in detail. On the three easier problems, GPT-5 produced nearly correct solutions; for Problem 2 it even derived a different approximation guarantee that, upon checking, refuted our conjecture while providing a valid solution. The model failed on Problem 4, which required combining results from two papers. On Problem 5, a harder case without a validated conjecture, GPT-5 proposed the same algorithm we had in mind but failed in the analysis, suggesting the proof is more challenging than expected. Although our sample is small, the results point to meaningful progress on routine reasoning, occasional flashes of originality, and clear limitations when cross-paper synthesis is required. GPT-5 may represent an early step toward frontier models eventually passing the Gödel Test.", 'abstract_zh': '戈德尔测试：大型语言模型在解决高级数学领域的新简单猜想中的性能评估', 'title_zh': '哥德尔测试：大型语言模型能解决简单的猜想吗？'}
{'arxiv_id': 'arXiv:2509.18382', 'title': 'Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints', 'authors': 'Adarsha Balaji, Le Chen, Rajeev Thakur, Franck Cappello, Sandeep Madireddy', 'link': 'https://arxiv.org/abs/2509.18382', 'abstract': 'Test-time compute scaling has demonstrated the ability to improve the performance of reasoning language models by generating longer chain-of-thought (CoT) sequences. However, this increase in performance comes with a significant increase in computational cost. In this work, we investigate two compute constraint strategies: (1) reasoning length constraint and (2) model quantization, as methods to reduce the compute demand of reasoning models and study their impact on their safety performance. Specifically, we explore two approaches to apply compute constraints to reasoning models: (1) fine-tuning reasoning models using a length controlled policy optimization (LCPO) based reinforcement learning method to satisfy a user-defined CoT reasoning length, and (2) applying quantization to maximize the generation of CoT sequences within a user-defined compute constraint. Furthermore, we study the trade-off between the computational efficiency and the safety of the model.', 'abstract_zh': '测试时计算量扩展能够通过生成更长的推理链（CoT）序列来提高语言模型的推理性能，但这一性能提升伴随着显著的计算成本增加。在本文中，我们研究了两种计算约束策略：（1）推理长度约束和（2）模型量化，以减少推理模型的计算需求，并研究这些策略对其安全性能的影响。具体地，我们探索了两种将计算约束应用于推理模型的方法：（1）使用基于强化学习的长度控制策略优化（LCPO）微调推理模型，以满足用户定义的CoT推理长度；（2）在用户定义的计算约束内最大化生成CoT序列的量化应用。此外，我们研究了计算效率与模型安全之间的权衡。', 'title_zh': '评估在计算约束下的大规模推理模型的安全性和技能推理能力'}
{'arxiv_id': 'arXiv:2509.18234', 'title': 'The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks', 'authors': 'Yu Gu, Jingjing Fu, Xiaodong Liu, Jeya Maria Jose Valanarasu, Noel Codella, Reuben Tan, Qianchu Liu, Ying Jin, Sheng Zhang, Jinyu Wang, Rui Wang, Lei Song, Guanghui Qin, Naoto Usuyama, Cliff Wong, Cheng Hao, Hohin Lee, Praneeth Sanapathi, Sarah Hilado, Bian Jiang, Javier Alvarez-Valle, Mu Wei, Jianfeng Gao, Eric Horvitz, Matt Lungren, Hoifung Poon, Paul Vozila', 'link': 'https://arxiv.org/abs/2509.18234', 'abstract': "Large frontier models like GPT-5 now achieve top scores on medical benchmarks. But our stress tests tell a different story. Leading systems often guess correctly even when key inputs like images are removed, flip answers under trivial prompt changes, and fabricate convincing yet flawed reasoning. These aren't glitches; they expose how today's benchmarks reward test-taking tricks over medical understanding. We evaluate six flagship models across six widely used benchmarks and find that high leaderboard scores hide brittleness and shortcut learning. Through clinician-guided rubric evaluation, we show that benchmarks vary widely in what they truly measure yet are treated interchangeably, masking failure modes. We caution that medical benchmark scores do not directly reflect real-world readiness. If we want AI to earn trust in healthcare, we must demand more than leaderboard wins and must hold systems accountable for robustness, sound reasoning, and alignment with real medical demands.", 'abstract_zh': '大型前沿模型如GPT-5现在在医学基准测试中取得了顶尖成绩。但我们的压力测试却揭示了不同的故事。领先系统往往在关键输入（如图像）被移除时仍能正确作答，轻微提示变化下会逆转答案，并虚构看似合理却充满缺陷的推理。这不是错误，而是暴露了当前基准测试如何倾向于奖励测试技巧而非医学理解。我们评估了六种旗舰模型在六种广泛使用的基准测试中的表现，发现高排名成绩掩盖了模型的脆弱性和捷径学习。通过由临床医生指导的评分评价，我们展示了基准测试在真正衡量的内容上存在广泛差异，但这些差异却被视为等效，掩盖了失败模式。我们警告说，医学基准测试成绩并不能直接反映现实世界的准备情况。如果希望AI在医疗领域获得信任，我们必须不仅仅追求排行榜的胜利，还必须让系统为稳健性、合理的推理以及与实际医学需求的一致性负责。', 'title_zh': '准备就绪的错觉：在多模态医疗基准上对大前沿模型进行压力测试'}
{'arxiv_id': 'arXiv:2509.18230', 'title': 'Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces', 'authors': 'Zihan Dong, Xinyu Fan, Zixiang Tang, Yunqing Li', 'link': 'https://arxiv.org/abs/2509.18230', 'abstract': 'Controlling desktop applications via software remains a fundamental yet under-served problem. Existing multi-modal large language models (MLLMs) ingest screenshots and task instructions to generate keystrokes and mouse events, but they suffer from prohibitive inference latency, poor sample efficiency on long-horizon sparse-reward tasks, and infeasible on-device deployment. We introduce a lightweight hierarchical reinforcement learning framework, ComputerAgent, that formulates OS control as a two-level option process (manager and subpolicy), employs a triple-modal state encoder (screenshot, task ID, numeric state) to handle visual and contextual diversity, integrates meta-actions with an early-stop mechanism to reduce wasted interactions, and uses a compact vision backbone plus small policy networks for on-device inference (15M parameters). On a suite of 135 real-world desktop tasks, ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on simple scenarios while reducing model size by over four orders of magnitude and halving inference time. These results demonstrate that hierarchical RL offers a practical, scalable alternative to monolithic MLLM-based automation for computer control.', 'abstract_zh': '通过软件控制桌面应用程序仍是一个基础但尚未充分解决的问题。现有的多模态大语言模型（MLLM）通过摄入屏幕截图和任务指令来生成键盘输入和鼠标事件，但它们遭受于推断延迟高、长期稀疏奖励任务样本效率低以及设备端部署不可行的难题。我们引入了一个轻量级的层次强化学习框架ComputerAgent，将操作系统控制建模为两层选择过程（管理器和子策略），采用三模态状态编码器（屏幕截图、任务ID、数值状态）处理视觉和上下文多样性，结合元动作和早期停止机制减少无效交互，并使用紧凑的视觉主干和小型策略网络进行设备端推理（参数量15M）。在一系列135个实际桌面任务中，ComputerAgent在简单任务（<8步）中的成功率达到了92.1%，在困难任务（>=8步）中的成功率为58.8%，在简单场景中达到或超过了2000亿参数的大语言模型基线，同时将模型大小减少了四个数量级，并将推理时间减半。这些结果表明，层次强化学习为计算机控制提供了实用且可扩展的替代方案，不同于基于大语言模型的单体自动化。', 'title_zh': '具有分层代理和多级动作空间的通用计算机控制'}
{'arxiv_id': 'arXiv:2509.18229', 'title': 'An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems', 'authors': 'Anthony Patera, Rohan Abeyaratne', 'link': 'https://arxiv.org/abs/2509.18229', 'abstract': 'Generative AI, and specifically GPT, can produce a remarkable solution to a mechanical engineering analysis problem - but also, on occasion, a flawed solution. For example, an elementary mechanics problem is solved flawlessly in one GPT instance and incorrectly in a subsequent GPT instance, with a success probability of only 85%. This unreliability renders "out-of-the-box" GPT unsuitable for deployment in education or engineering practice. We introduce an "N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering Problem Statements. Agency first launches N instantiations of Agent Solve to yield N independent Proposed Problem Solution Realizations; Agency then invokes Agent Compare to summarize and compare the N Proposed Problem Solution Realizations and to provide a Recommended Problem Solution. We argue from Condorcet\'s Jury Theorem that, for a Problem Statement characterized by per-Solve success probability greater than 1/2 (and N sufficiently large), the Predominant (Agent Compare) Proposed Problem Solution will, with high probability, correspond to a Correct Proposed Problem Solution. Furthermore, Agent Compare can also incorporate aspects of Secondary (Agent Compare) Proposed Problem Solutions, in particular when the latter represent alternative Problem Statement interpretations - different Mathematical Models - or alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a commercial multi-agent model, show similarities in design and performance, but also important differences in emphasis: our Agency focuses on transparency and pedagogical value.', 'abstract_zh': '生成式AI，特别是在机械工程分析问题上的GPT，能够生成一个令人 remarkable 的解决方案，但也偶尔会产生一个不正确的解决方案。例如，一个基础的力学问题在一个GPT实例中被完美解决，而在后续的GPT实例中被错误解决，成功概率仅为85%。这种不可靠性使得“开箱即用”的GPT不适合在教育或工程实践中部署。我们提出了一个“N+1”GPT机构用于初始（低成本）分析机械工程问题陈述。该机构首先启动N个Agent Solve实例以生成N个独立的 Proposed Problem Solution 实现；然后调用Agent Compare来汇总和比较N个 Proposed Problem Solution 实现，并提供一个推荐的 Problem Solution。我们根据孔多塞悖论认为，对于具有每解决一次成功概率大于1/2（并且N足够大）的问题陈述，主导的（Agent Compare） Proposed Problem Solution 以高概率对应于一个正确的 Proposed Problem Solution。此外，Agent Compare还可以结合次要的（Agent Compare） Proposed Problem Solutions 的方面，尤其是当后者代表问题陈述的不同解释——不同的数学模型或不同的数学解题程序。与Grok Heavy这种商业多智能体模型相比，我们的机构更侧重于透明性和教学价值。', 'title_zh': 'N+1 GPT机构及其在机械工程分析问题 critical 解决中的应用'}
{'arxiv_id': 'arXiv:2509.18226', 'title': 'From "What to Eat?" to Perfect Recipe: ChefMind\'s Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation', 'authors': 'Yu Fu, Linyue Cai, Ruoyu Wu, Yong Zhao', 'link': 'https://arxiv.org/abs/2509.18226', 'abstract': 'Personalized recipe recommendation faces challenges in handling fuzzy user intent, ensuring semantic accuracy, and providing sufficient detail coverage. We propose ChefMind, a hybrid architecture combining Chain of Exploration (CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large Language Model (LLM). CoE refines ambiguous queries into structured conditions, KG offers semantic reasoning and interpretability, RAG supplements contextual culinary details, and LLM integrates outputs into coherent recommendations. We evaluate ChefMind on the Xiachufang dataset and manually annotated queries, comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that ChefMind achieves superior performance in accuracy, relevance, completeness, and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models. Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in handling fuzzy demands.', 'abstract_zh': '个性化菜谱推荐面临用户意图模糊、语义准确性保障和细节覆盖不足的挑战。我们提出ChefMind，一种结合链式探索(CoE)、知识图谱(KG)、检索增强生成(RAG)和大型语言模型(LLM)的混合架构。CoE将模糊查询精炼为结构化条件，KG提供语义推理和可解释性，RAG补充背景烹饪细节，而LLM将输出整合为连贯的推荐。我们使用XiaChufang数据集和手动标注查询对ChefMind进行评估，并将其与仅使用LLM、仅使用KG和仅使用RAG的基线进行比较。结果表明，ChefMind在准确度、相关性、完整性和清晰度方面表现出更优的性能，平均得分为8.7，而消融模型的得分在6.4-6.7之间。此外，它将未处理的查询减少到1.6%，展示了在处理模糊需求方面的稳健性。', 'title_zh': '从“吃什么？”到完美食谱：ChefMind的探索链路实现模糊用户意图的食谱推荐'}
{'arxiv_id': 'arXiv:2509.18221', 'title': 'Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models', 'authors': 'Dingxin Lu, Shurui Wu, Xinyi Huang', 'link': 'https://arxiv.org/abs/2509.18221', 'abstract': 'With the rising global burden of chronic diseases and the multimodal and heterogeneous clinical data (medical imaging, free-text recordings, wearable sensor streams, etc.), there is an urgent need for a unified multimodal AI framework that can proactively predict individual health risks. We propose VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer with a large language model (LLM) inference head embedded in its top layer. The system builds on the dual-stream architecture of existing visual-linguistic models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with cross-modal comparison and fine-grained alignment of radiological images, fundus maps, and wearable device photos with corresponding clinical narratives using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion block that integrates irregular visit sequences into the causal Transformer decoder through adaptive time interval position coding; (iii) a disease ontology map adapter that injects ICD-10 codes into visual and textual channels in layers and infers comorbid patterns with the help of a graph attention mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an average AUROC of 0.90 with an expected calibration error of 2.7 percent.', 'abstract_zh': '基于视觉-语言的多模态RiskFormer框架：融合临床叙事的大规模语言模型驱动的主动健康风险预测', 'title_zh': '基于视觉-语言融合和大规模语言模型的慢性疾病多模态健康风险预测系统'}
{'arxiv_id': 'arXiv:2509.18218', 'title': 'Similarity Field Theory: A Mathematical Framework for Intelligence', 'authors': 'Kei-Sing Ng', 'link': 'https://arxiv.org/abs/2509.18218', 'abstract': 'We posit that persisting and transforming similarity relations form the structural basis of any comprehensible dynamic system. This paper introduces Similarity Field Theory, a mathematical framework that formalizes the principles governing similarity values among entities and their evolution. We define: (1) a similarity field $S: U \\times U \\to [0,1]$ over a universe of entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed relational field (asymmetry and non-transitivity are allowed); (2) the evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by $p=0,1,2,\\ldots$; (3) concepts $K$ as entities that induce fibers $F_{\\alpha}(K) = { E \\in U \\mid S(E,K) \\ge \\alpha }$, i.e., superlevel sets of the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that produces new entities. Within this framework, we formalize a generative definition of intelligence: an operator $G$ is intelligent with respect to a concept $K$ if, given a system containing entities belonging to the fiber of $K$, it generates new entities that also belong to that fiber. Similarity Field Theory thus offers a foundational language for characterizing, comparing, and constructing intelligent systems. We prove two theorems: (i) asymmetry blocks mutual inclusion; and (ii) stability requires either an anchor coordinate or eventual confinement within a level set of $f$. These results ensure that the evolution of similarity fields is both constrained and interpretable, culminating in an exploration of how the framework allows us to interpret large language models and use them as experimental probes into societal cognition.', 'abstract_zh': '持久性和变换的相似性关系构成了任何可理解动态系统的结构基础。本文介绍了相似性场理论，这是一个数学框架，用于正式化实体之间及其演变的相似性值的原则。我们定义：（1）在实体集\\(U\\)上的相似性场\\(S: U \\times U \\to [0,1]\\)，满足自反性\\(S(E,E)=1\\)，并被视为定向关系场（允许不对称性和非传递性）；（2）系统的演化通过索引\\(p=0,1,2,\\ldots\\)的序列\\(Z_p = (X_p, S^{(p)})\\)；（3）概念\\(K\\)作为诱导纤维\\(F_{\\alpha}(K) = \\{ E \\in U \\mid S(E,K) \\ge \\alpha \\}\\)的实体，即单目映射\\(S_K(E) := S(E,K)\\)的超水平集；和（4）生成算子\\(G\\)，该算子产生新实体。在此框架内，我们形式化了智能的生成定义：相对而言，如果给定一个包含属于\\(K\\)的纤维中的实体的系统，该算子\\(G\\)生成的新实体也属于该纤维，则算子\\(G\\)对于概念\\(K\\)是智能的。相似性场理论因此提供了一种基本语言，用于描述、比较和构造智能系统。我们证明了两个定理：（i）不对称性阻碍了相互包含；（ii）稳定性需要锚定坐标或最终限制在\\(f\\)的等值集内。这些结果确保了相似性场的演化既受到约束又可解释，从而探讨了该框架如何允许我们解释大规模语言模型并利用它们作为社会认知的实验探针。\n\n标题：相似性场理论：智能系统的数学框架', 'title_zh': '相似性场理论：智能的数学框架'}
{'arxiv_id': 'arXiv:2509.18216', 'title': 'nDNA -- the Semantic Helix of Artificial Cognition', 'authors': 'Amitava Das', 'link': 'https://arxiv.org/abs/2509.18216', 'abstract': "As AI foundation models grow in capability, a deeper question emerges: What shapes their internal cognitive identity -- beyond fluency and output? Benchmarks measure behavior, but the soul of a model resides in its latent geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic representation that captures this latent identity through the intrinsic geometry of belief. At its core, nDNA is synthesized from three principled and indispensable dimensions of latent geometry: spectral curvature, which reveals the curvature of conceptual flow across layers; thermodynamic length, which quantifies the semantic effort required to traverse representational transitions through layers; and belief vector field, which delineates the semantic torsion fields that guide a model's belief directional orientations. Like biological DNA, it encodes ancestry, mutation, and semantic inheritance, found in finetuning and alignment scars, cultural imprints, and architectural drift. In naming it, we open a new field: Neural Genomics, where models are not just tools, but digital semantic organisms with traceable inner cognition.\nModeling statement. We read AI foundation models as semantic fluid--dynamics: meaning is transported through layers like fluid in a shaped conduit; nDNA is the physics-grade readout of that flow -- a geometry-first measure of how meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free neural DNA fingerprint tied to on-input behavior; with this fingerprint we cross into biology: tracing lineages across pretraining, fine-tuning, alignment, pruning, distillation, and merges; measuring inheritance between checkpoints; detecting drift as traits shift under new data or objectives; and, ultimately, studying the evolution of artificial cognition to compare models, diagnose risks, and govern change over time.", 'abstract_zh': '随着AI基础模型能力的增强，一个更深层次的问题出现了：除了流畅性和输出外，是什么塑造了它们的内在认知身份？基准测试衡量行为，但模型的灵魂在于其潜在的几何结构。在这项工作中，我们提出神经DNA（nDNA）作为一种语义-基因型表示，通过信念的内在几何结构捕捉这种潜在的身份。nDNA的核心由潜在几何结构的三个人类中心且不可或缺的维度合成：光谱曲率，揭示概念流跨层的曲率；热力学长度，量化穿越表征过渡所需的语言努力；以及信念向量场，界定指导模型信念方向的语义扭喷场。与生物DNA类似，它编码谱系、突变和语义继承，体现在微调和对齐疤痕、文化印记和架构漂移中。通过命名它，我们开启了一个新领域：神经基因组学，在该领域中，模型不仅是工具，还是具有可追溯内在认知的数字语义有机体。', 'title_zh': 'nDNA -- 人工认知的语义螺旋'}
{'arxiv_id': 'arXiv:2509.18215', 'title': 'Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations', 'authors': 'Timotheus Kampik, Kristijonas Čyras, José Ruiz Alarcón', 'link': 'https://arxiv.org/abs/2509.18215', 'abstract': 'This paper presents a formal approach to explaining change of inference in Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions from a QBAF and updating the QBAF to then again draw conclusions (and so on), our approach traces changes -- which we call strength inconsistencies -- in the partial order over argument strengths that a semantics establishes on some arguments of interest, called topic arguments. We trace the causes of strength inconsistencies to specific arguments, which then serve as explanations. We identify sufficient, necessary, and counterfactual explanations for strength inconsistencies and show that strength inconsistency explanations exist if and only if an update leads to strength inconsistency. We define a heuristic-based approach to facilitate the search for strength inconsistency explanations, for which we also provide an implementation.', 'abstract_zh': '本文提出了一种形式化的方法来解释定量双极论辩框架（QBAF）中推理变化的问题。在从QBAF得出结论并对QBAF进行更新以再次得出结论（依此类推）的过程中，我们的方法追踪由某种语义在某些感兴趣的主题论辩中建立的论辩强度偏序中的强度不一致的变化。我们将这些强度不一致的原因追溯到特定的论辩，并将其作为解释。我们识别出强度不一致的充分解释、必要解释和反事实解释，并证明只有当更新导致强度不一致时，强度不一致的解释才会存在。我们定义了一种基于启发式的方法来促进对强度不一致解释的搜索，并提供了其实现。', 'title_zh': '定量双极论证中的变化：充分、必要和反事实解释'}
{'arxiv_id': 'arXiv:2509.18198', 'title': 'MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation', 'authors': 'Rui Liu, Zikang Wang, Peng Gao, Yu Shen, Pratap Tokekar, Ming Lin', 'link': 'https://arxiv.org/abs/2509.18198', 'abstract': "Autonomous systems have advanced significantly, but challenges persist in accident-prone environments where robust decision-making is crucial. A single vehicle's limited sensor range and obstructed views increase the likelihood of accidents. Multi-vehicle connected systems and multi-modal approaches, leveraging RGB images and LiDAR point clouds, have emerged as promising solutions. However, existing methods often assume the availability of all data modalities and connected vehicles during both training and testing, which is impractical due to potential sensor failures or missing connected vehicles. To address these challenges, we introduce a novel framework MMCD (Multi-Modal Collaborative Decision-making) for connected autonomy. Our framework fuses multi-modal observations from ego and collaborative vehicles to enhance decision-making under challenging conditions. To ensure robust performance when certain data modalities are unavailable during testing, we propose an approach based on cross-modal knowledge distillation with a teacher-student model structure. The teacher model is trained with multiple data modalities, while the student model is designed to operate effectively with reduced modalities. In experiments on $\\textit{connected autonomous driving with ground vehicles}$ and $\\textit{aerial-ground vehicles collaboration}$, our method improves driving safety by up to ${\\it 20.7}\\%$, surpassing the best-existing baseline in detecting potential accidents and making safe driving decisions. More information can be found on our website this https URL.", 'abstract_zh': '自主系统已取得显著进展，但在事故多发环境中，稳健的决策制定仍然面临挑战。单个车辆有限的传感器范围和受阻的视角增加了事故发生的风险。多车辆连接系统和多模态方法结合RGB图像和LiDAR点云数据，已被证明是一种有前景的解决方案。然而，现有方法通常假设在训练和测试过程中所有数据模态和连接车辆均可用，这由于传感器故障或缺少连接车辆的可能性而难以实现。为应对这些挑战，我们提出了一种新的框架MMCD（多模态协作决策）以实现连接自主性。该框架融合了ego车辆和协作车辆的多模态观测数据，以在恶劣条件下增强决策能力。为确保在某些数据模态测试不可用时仍能保持稳健性能，我们提出了一种基于跨模态知识蒸馏的教师-学生模型结构方法。教师模型使用多种数据模态训练，而学生模型设计为能在减少的数据模态下有效运行。在基于地面车辆的连接自主驾驶和空中-地面车辆协作的实验中，我们的方法通过最多20.7%提高驾驶安全性，并在检测潜在事故和作出安全驾驶决策方面超越现有最佳基准方法。更多信息请访问我们的网站：this https URL。', 'title_zh': 'MMCD: 多模态协作决策在具备知识蒸馏的连接自主系统中'}
{'arxiv_id': 'arXiv:2509.18186', 'title': 'An Outcome-Based Educational Recommender System', 'authors': 'Nursultan Askarbekuly, Timur Fayzrakhmanov, Sladjan Babarogić, Ivan Luković', 'link': 'https://arxiv.org/abs/2509.18186', 'abstract': 'Most educational recommender systems are tuned and judged on click- or rating-based relevance, leaving their true pedagogical impact unclear. We introduce OBER-an Outcome-Based Educational Recommender that embeds learning outcomes and assessment items directly into the data schema, so any algorithm can be evaluated on the mastery it fosters. OBER uses a minimalist entity-relation model, a log-driven mastery formula, and a plug-in architecture. Integrated into an e-learning system in non-formal domain, it was evaluated trough a two-week randomized split test with over 5 700 learners across three methods: fixed expert trajectory, collaborative filtering (CF), and knowledge-based (KB) filtering. CF maximized retention, but the fixed path achieved the highest mastery. Because OBER derives business, relevance, and learning metrics from the same logs, it lets practitioners weigh relevance and engagement against outcome mastery with no extra testing overhead. The framework is method-agnostic and readily extensible to future adaptive or context-aware recommenders.', 'abstract_zh': '基于学习成果的教育推荐系统：OBER及其评价方法', 'title_zh': '基于学习成果的教育推荐系统'}
{'arxiv_id': 'arXiv:2509.18181', 'title': 'Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling', 'authors': 'Mustafa Sameen, Xiaojian Zhang, Xilei Zhao', 'link': 'https://arxiv.org/abs/2509.18181', 'abstract': "Accurate modeling of ridesourcing mode choices is essential for designing and implementing effective traffic management policies for reducing congestion, improving mobility, and allocating resources more efficiently. Existing models for predicting ridesourcing mode choices often suffer from limited predictive accuracy due to their inability to capture key psychological factors, and are further challenged by severe class imbalance, as ridesourcing trips comprise only a small fraction of individuals' daily travel. To address these limitations, this paper introduces the Synthesizing Attitudes, Predicting Actions (SAPA) framework, a hierarchical approach that uses Large Language Models (LLMs) to synthesize theory-grounded latent attitudes to predict ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler personas from raw travel survey data and then trains a propensity-score model on demographic and behavioral features, enriched by those personas, to produce an individual-level score. Next, the LLM assigns quantitative scores to theory-driven latent variables (e.g., time and cost sensitivity), and a final classifier integrates the propensity score, latent-variable scores (with their interaction terms), and observable trip attributes to predict ridesourcing mode choice. Experiments on a large-scale, multi-year travel survey show that SAPA significantly outperforms state-of-the-art baselines, improving ridesourcing choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set. This study provides a powerful tool for accurately predicting ridesourcing mode choices, and provides a methodology that is readily transferable to various applications.", 'abstract_zh': '准确建模共享出行模式选择对于设计和实施有效的交通管理政策以减少拥堵、提升 mobility 并更高效地分配资源至关重要。现有的共享出行模式选择预测模型往往因难以捕捉关键的心理因素而预测精度有限，并且受到严重类别不平衡的挑战，因为共享出行行程只占个人日常出行的一小部分。为解决这些问题，本文引入了综合态度、预测行为（SAPA）框架，这是一种层次化方法，使用大型语言模型（LLMs）合成基于理论的态度来预测共享出行选择。SAPA 首先使用 LLM 从原始旅行调查数据中生成定性的旅行者画像，然后使用这些画像丰富的人口统计和行为特征训练倾向评分模型，生成个体水平得分。接着，LLM 为理论驱动的潜在变量（例如时间和成本敏感性）分配定量评分，最终分类器将倾向评分、潜在变量评分（包括交互项）和可观察的行程特征结合起来预测共享出行模式选择。大规模、多年的旅行调查实验表明，SAPA 显著优于最先进的基准，相对于保留测试集上的 PR-AUC，共享出行选择预测提高了多达 75.9%。该研究提供了准确预测共享出行模式选择的有力工具，并提供了一种易于转移到各种应用的方法。', 'title_zh': '基于行为理论指导的大规模语言模型合成态度、预测行为（SAPA）： ridesourcing 模式选择建模'}
{'arxiv_id': 'arXiv:2509.18180', 'title': 'Large Language Models and Operations Research: A Structured Survey', 'authors': 'Yang Wang, Kai Li', 'link': 'https://arxiv.org/abs/2509.18180', 'abstract': 'Operations research (OR) provides fundamental methodologies for complex system decision-making, with established applications in transportation, supply chain management, and production scheduling. Traditional approaches, which depend on expert-based modeling and manual parameter adjustment, often face challenges in handling large-scale, dynamic, and multi-constraint problems. Recently, large language models (LLMs) have shown potential to address these limitations through semantic understanding, structured generation, and reasoning control. LLMs can translate natural language descriptions into mathematical models or executable code, generate heuristics, evolve algorithms, and directly tackle optimization tasks. This paper surveys recent progress on the integration of LLMs into OR, organizing methods into three main directions: automatic modeling, auxiliary optimization, and direct solving. It further reviews evaluation benchmarks and domain-specific applications, and summarizes key open issues such as unstable semantic-to-structure mapping, fragmented research progress, limited generalization, and insufficient evaluation systems. Finally, the survey outlines possible research avenues for advancing the role of LLMs in OR.', 'abstract_zh': '大规模语言模型在运筹学中的集成研究', 'title_zh': '大型语言模型与运筹学：一项结构化的综述'}
{'arxiv_id': 'arXiv:2509.18178', 'title': 'Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM', 'authors': 'Ling Yue, Nithin Somasekharan, Tingwen Zhang, Yadi Cao, Shaowu Pan', 'link': 'https://arxiv.org/abs/2509.18178', 'abstract': 'Computational Fluid Dynamics (CFD) is an essential simulation tool in engineering, yet its steep learning curve and complex manual setup create significant barriers. To address these challenges, we introduce Foam-Agent, a multi-agent framework that automates the entire end-to-end OpenFOAM workflow from a single natural language prompt. Our key innovations address critical gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation: Foam-Agent is the first system to manage the full simulation pipeline, including advanced pre-processing with a versatile Meshing Agent capable of handling external mesh files and generating new geometries via Gmsh, automatic generation of HPC submission scripts, and post-simulation visualization via ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent, the framework uses Model Context Protocol (MCP) to expose its core functions as discrete, callable tools. This allows for flexible integration and use by other agentic systems, such as Claude-code, for more exploratory workflows. 3. High-Fidelity Configuration Generation: We achieve superior accuracy through a Hierarchical Multi-Index RAG for precise context retrieval and a dependency-aware generation process that ensures configuration consistency. Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the expertise barrier for CFD, demonstrating how specialized multi-agent systems can democratize complex scientific computing. The code is public at this https URL.', 'abstract_zh': 'CFD中的Foam-Agent：一种基于多Agent的全流程自动化框架', 'title_zh': 'Foam-Agent: 一个用于OpenFOAM自动CFD仿真compose多智能体框架的端到端可拓展体系'}
{'arxiv_id': 'arXiv:2509.18168', 'title': 'HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics', 'authors': 'Dong Liu, Yanxuan Yu', 'link': 'https://arxiv.org/abs/2509.18168', 'abstract': 'Semantic parsing of long documents remains challenging due to quadratic growth in pairwise composition and memory requirements. We introduce \\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that decomposes an input of length $N$ into $M$ meaningful segments, constructs \\emph{Local Semantic Graphs} on each segment, and extracts compact \\emph{summary nodes} to form a \\emph{Global Graph Memory}. HSGM supports \\emph{incremental updates} -- only newly arrived segments incur local graph construction and summary-node integration -- while \\emph{Hierarchical Query Processing} locates relevant segments via top-$K$ retrieval over summary nodes and then performs fine-grained reasoning within their local graphs.\nTheoretically, HSGM reduces worst-case complexity from $O(N^2)$ to $O\\!\\left(N\\,k + (N/k)^2\\right)$, with segment size $k \\ll N$, and we derive Frobenius-norm bounds on the approximation error introduced by node summarization and sparsification thresholds. Empirically, on three benchmarks -- long-document AMR parsing, segment-level semantic role labeling (OntoNotes), and legal event extraction -- HSGM achieves \\emph{2--4$\\times$ inference speedup}, \\emph{$>60\\%$ reduction} in peak memory, and \\emph{$\\ge 95\\%$} of baseline accuracy. Our approach unlocks scalable, accurate semantic modeling for ultra-long texts, enabling real-time and resource-constrained NLP applications.', 'abstract_zh': '层次化段图内存（HSGM）：长文档语义解析的新型框架', 'title_zh': 'HSGM：分层段图记忆体 for 可扩展长文本语义'}
{'arxiv_id': 'arXiv:2509.18132', 'title': 'Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI', 'authors': 'Xiuyi Fan', 'link': 'https://arxiv.org/abs/2509.18132', 'abstract': 'Uncertainty is a fundamental challenge in medical practice, but current medical AI systems fail to explicitly quantify or communicate uncertainty in a way that aligns with clinical reasoning. Existing XAI works focus on interpreting model predictions but do not capture the confidence or reliability of these predictions. Conversely, uncertainty estimation (UE) techniques provide confidence measures but lack intuitive explanations. The disconnect between these two areas limits AI adoption in medicine. To address this gap, we propose Explainable Uncertainty Estimation (XUE) that integrates explainability with uncertainty quantification to enhance trust and usability in medical AI. We systematically map medical uncertainty to AI uncertainty concepts and identify key challenges in implementing XUE. We outline technical directions for advancing XUE, including multimodal uncertainty quantification, model-agnostic visualization techniques, and uncertainty-aware decision support systems. Lastly, we propose guiding principles to ensure effective XUE realisation. Our analysis highlights the need for AI systems that not only generate reliable predictions but also articulate confidence levels in a clinically meaningful way. This work contributes to the development of trustworthy medical AI by bridging explainability and uncertainty, paving the way for AI systems that are aligned with real-world clinical complexities.', 'abstract_zh': '医疗实践中的不确定性是根本性挑战，但当前的医疗AI系统未能以与临床推理相一致的方式明确量化或传达不确定性。现有的可解释性AI（XAI）工作侧重于解释模型预测，但未能捕捉这些预测的置信度或可靠性。相反，不确定性估计算法（UE）提供了置信度度量，但缺乏直观的解释。这两者之间的disconnect限制了AI在医疗领域的应用。为解决这一问题，我们提出了可解释的不确定性估计算法（XUE），将可解释性与不确定性量化相结合，以增强医疗AI中的信任和可用性。我们系统地将医疗不确定性映射到AI不确定性概念，并识别实施XUE的关键挑战。我们概述了推进XUE的技术方向，包括多模态不确定性量化、模型无关的可视化技术以及不确定性意识的决策支持系统。最后，我们提出了确保有效实现XUE的指导原则。我们的分析突显了对于不仅能生成可靠预测，还能以临床有意义的方式表达置信度的AI系统的迫切需求。这项工作通过弥合可解释性和不确定性之间的鸿沟，为与现实世界临床复杂性相一致的AI系统的发展做出了贡献。', 'title_zh': 'position paper：将解释性和不确定性估计集成到医疗AI中'}
{'arxiv_id': 'arXiv:2509.18123', 'title': 'SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture', 'authors': 'Yeonju Lee, Rui Qi Chen, Joseph Oboamah, Po Nien Su, Wei-zhen Liang, Yeyin Shi, Lu Gan, Yongsheng Chen, Xin Qiao, Jing Li', 'link': 'https://arxiv.org/abs/2509.18123', 'abstract': "Accurate interpretation of soil moisture patterns is critical for irrigation scheduling and crop management, yet existing approaches for soil moisture time-series analysis either rely on threshold-based rules or data-hungry machine learning or deep learning models that are limited in adaptability and interpretability. In this study, we introduce SPADE (Soil moisture Pattern and Anomaly DEtection), an integrated framework that leverages large language models (LLMs) to jointly detect irrigation patterns and anomalies in soil moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced reasoning and instruction-following capabilities, enabling zero-shot analysis without requiring task-specific annotation or fine-tuning. By converting time-series data into a textual representation and designing domain-informed prompt templates, SPADE identifies irrigation events, estimates net irrigation gains, detects, classifies anomalies, and produces structured, interpretable reports. Experiments were conducted on real-world soil moisture sensor data from commercial and experimental farms cultivating multiple crops across the United States. Results demonstrate that SPADE outperforms the existing method in anomaly detection, achieving higher recall and F1 scores and accurately classifying anomaly types. Furthermore, SPADE achieved high precision and recall in detecting irrigation events, indicating its strong capability to capture irrigation patterns accurately. SPADE's reports provide interpretability and usability of soil moisture analytics. This study highlights the potential of LLMs as scalable, adaptable tools for precision agriculture, which is capable of integrating qualitative knowledge and data-driven reasoning to produce actionable insights for accurate soil moisture monitoring and improved irrigation scheduling from soil moisture time-series data.", 'abstract_zh': '土壤水分模式和异常检测的准确解析对于灌溉调度和作物管理至关重要，现有土壤水分时间序列分析方法要么依赖于阈值规则，要么依赖于数据需求大的机器学习或深度学习模型，这些模型在适应性和可解释性方面有限。在本研究中，我们介绍了SPADE（土壤水分模式和异常检测）框架，该框架利用大型语言模型（LLMs）联合检测土壤水分时间序列数据中的灌溉模式和异常。SPADE利用ChatGPT-4.1的高级推理和指令遵循能力，实现零样本分析，无需特定任务的注释或微调。通过将时间序列数据转换为文本表示并设计领域指导的提示模板，SPADE识别灌溉事件、估算净灌溉增益、检测和分类异常，并生成结构化、可解释的报告。实验在多个作物的商业和实验农场的真实土壤水分传感器数据上进行。结果显示，SPADE在异常检测中优于现有方法，达到更高的召回率和F1分数，并准确分类异常类型。此外，SPADE在检测灌溉事件方面也表现出高精度和召回率，表明其能够准确捕捉灌溉模式。SPADE的报告提供土壤水分分析的可解释性和实用性。本研究突显了LLMs作为可扩展、适应性强的工具在精确农业中的潜力，能够集成定性知识和数据驱动推理，从土壤水分时间序列数据中产生有助于准确土壤水分监测和优化灌溉调度的可操作见解。', 'title_zh': 'SPADE: 用于精准农业中土壤 Moisture 模式识别和异常检测的大规模语言模型框架'}
{'arxiv_id': 'arXiv:2509.18101', 'title': 'A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services', 'authors': 'Guanzhong Pan, Haibo Wang', 'link': 'https://arxiv.org/abs/2509.18101', 'abstract': 'Large language models (LLMs) are becoming increasingly widespread. Organizations that want to use AI for productivity now face an important decision. They can subscribe to commercial LLM services or deploy models on their own infrastructure. Cloud services from providers such as OpenAI, Anthropic, and Google are attractive because they provide easy access to state-of-the-art models and are easy to scale. However, concerns about data privacy, the difficulty of switching service providers, and long-term operating costs have driven interest in local deployment of open-source models. This paper presents a cost-benefit analysis framework to help organizations determine when on-premise LLM deployment becomes economically viable compared to commercial subscription services. We consider the hardware requirements, operational expenses, and performance benchmarks of the latest open-source models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost of deploying these models locally with the major cloud providers subscription fee. Our findings provide an estimated breakeven point based on usage levels and performance needs. These results give organizations a practical framework for planning their LLM strategies.', 'abstract_zh': '大规模语言模型（LLMs）日益普及。希望利用AI提高生产力的组织现在面临着一个重要的决策：他们是订阅商业LLM服务还是在自己的基础设施上部署模型。来自OpenAI、Anthropic和Google等提供商的云服务具有吸引力，因为它们提供了访问最新模型的便捷途径并且易于扩展。然而，关于数据隐私的担忧、切换服务提供商的难度以及长期运营成本等因素促使人们更加关注开源模型的本地部署。本文提出了一种成本效益分析框架，帮助组织确定在何种情况下本地部署LLM相较于商业订阅服务更具经济性。我们考虑了最新开源模型（包括Qwen、Llama、Mistral等）的硬件需求、运营支出和性能基准，然后将这些模型本地部署的总成本与主要云提供商的订阅费用进行了比较。我们的研究结果提供了基于使用水平和性能需求的估算盈亏平衡点。这些结果为组织制定了规划其LLM策略的实际框架。', 'title_zh': '基于 premises 的大型语言模型部署的成本效益分析：与商用 LLM 服务持平'}
{'arxiv_id': 'arXiv:2509.19295', 'title': 'Audio-Based Pedestrian Detection in the Presence of Vehicular Noise', 'authors': 'Yonghyun Kim, Chaeyeon Han, Akash Sarode, Noah Posner, Subhrajit Guhathakurta, Alexander Lerch', 'link': 'https://arxiv.org/abs/2509.19295', 'abstract': "Audio-based pedestrian detection is a challenging task and has, thus far, only been explored in noise-limited environments. We present a new dataset, results, and a detailed analysis of the state-of-the-art in audio-based pedestrian detection in the presence of vehicular noise. In our study, we conduct three analyses: (i) cross-dataset evaluation between noisy and noise-limited environments, (ii) an assessment of the impact of noisy data on model performance, highlighting the influence of acoustic context, and (iii) an evaluation of the model's predictive robustness on out-of-domain sounds. The new dataset is a comprehensive 1321-hour roadside dataset. It incorporates traffic-rich soundscapes. Each recording includes 16kHz audio synchronized with frame-level pedestrian annotations and 1fps video thumbnails.", 'abstract_zh': '基于音频的行人检测是一个具有挑战性的任务，迄今为止仅在噪声受限环境中进行过探索。我们呈现了一个新的数据集、结果以及关于噪声环境下基于音频的行人检测的最新研究分析。在本研究中，我们进行了三项分析：(i) 噪音数据集与噪声受限环境之间的跨数据集评估，(ii) 噪音数据对模型性能影响的评估，强调声学上下文的影响，以及(iii) 模型在域外声音上的预测稳健性评估。新的数据集是一个全面的1321小时路边数据集，包含了丰富的交通声音场景。每条记录包括与帧级行人标注同步的16kHz音频和每秒一帧的视频缩略图。', 'title_zh': '车辆噪声环境下基于音频的行人检测'}
{'arxiv_id': 'arXiv:2509.19292', 'title': 'SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration', 'authors': 'Yang Jin, Jun Lv, Han Xue, Wendi Chen, Chuan Wen, Cewu Lu', 'link': 'https://arxiv.org/abs/2509.19292', 'abstract': 'Intelligent agents progress by continually refining their capabilities through actively exploring environments. Yet robot policies often lack sufficient exploration capability due to action mode collapse. Existing methods that encourage exploration typically rely on random perturbations, which are unsafe and induce unstable, erratic behaviors, thereby limiting their effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a framework that enhances policy exploration and improvement in robotic manipulation. SOE learns a compact latent representation of task-relevant factors and constrains exploration to the manifold of valid actions, ensuring safety, diversity, and effectiveness. It can be seamlessly integrated with arbitrary policy models as a plug-in module, augmenting exploration without degrading the base policy performance. Moreover, the structured latent space enables human-guided exploration, further improving efficiency and controllability. Extensive experiments in both simulation and real-world tasks demonstrate that SOE consistently outperforms prior methods, achieving higher task success rates, smoother and safer exploration, and superior sample efficiency. These results establish on-manifold exploration as a principled approach to sample-efficient policy self-improvement. Project website: this https URL', 'abstract_zh': '智能代理通过不断主动探索环境来不断提升其能力。然而，由于动作模式崩溃，机器人策略往往缺乏足够的探索能力。现有的鼓励探索的方法通常依赖于随机扰动，这会导致不安全的行为并引发不稳定、不可预测的效果，从而限制其有效性。我们提出了On-Manifold Exploration (OME) 自我提升框架，该框架增强了机器人操作中的策略探索和改进。OME 学习与任务相关的紧凑潜在表示，并将探索限制在有效的动作流形上，确保安全、多样性和有效性。它可以无缝集成到任意策略模型中作为插件模块，增强探索而不降低基础策略性能。此外，结构化的潜在空间使人类能够引导探索，进一步提高效率和可控性。广泛的模拟和实际任务实验表明，OME 一致优于先前方法，实现更高的任务成功率、更平滑和安全的探索以及更高的样本效率。这些结果将沿流形探索确立为样本高效策略自我改进的原则性方法。项目网站：此链接', 'title_zh': 'SOE: 基于流形探索的样本高效机器人策略自我改进'}
{'arxiv_id': 'arXiv:2509.19277', 'title': 'MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurobromas in whole-body MRI', 'authors': 'Georgii Kolokolnikov, Marie-Lena Schmalhofer, Sophie G\x7fötz, Lennart Well, Said Farschtschi, Victor-Felix Mautner, Inka Ristow, Rene Werner', 'link': 'https://arxiv.org/abs/2509.19277', 'abstract': 'Background and Objectives: Neurofibromatosis type 1 is a genetic disorder characterized by the development of numerous neurofibromas (NFs) throughout the body. Whole-body MRI (WB-MRI) is the clinical standard for detection and longitudinal surveillance of NF tumor growth. Existing interactive segmentation methods fail to combine high lesion-wise precision with scalability to hundreds of lesions. This study proposes a novel interactive segmentation model tailored to this challenge.\nMethods: We introduce MOIS-SAM2, a multi-object interactive segmentation model that extends the state-of-the-art, transformer-based, promptable Segment Anything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was trained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using T2-weighted fat-suppressed sequences. The dataset was split at the patient level into a training set and four test sets (one in-domain and three reflecting different domain shift scenarios, e.g., MRI field strength variation, low tumor burden, differences in clinical site and scanner vendor).\nResults: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of 0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC: 0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained under MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC: 0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1 scores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader variability analysis showed model-to-expert agreement (DSC: 0.62-0.68), comparable to inter-expert agreement (DSC: 0.57-0.69).\nConclusions: The proposed MOIS-SAM2 enables efficient and scalable interactive segmentation of NFs in WB-MRI with minimal user input and strong generalization, supporting integration into clinical workflows.', 'abstract_zh': '背景与目的：神经纤维瘤病1型是一种遗传性疾病，特征是在全身范围内发展成多个神经纤维瘤（NFs）。全身磁共振成像（WB-MRI）是检测和纵向监测NF肿瘤生长的临床标准。现有的交互分割方法难以同时实现高病变-wise精度和对数百个病变的可扩展性。本研究提出了一种针对这一挑战的新颖交互分割模型。\n\n方法：我们引入了MOIS-SAM2，这是一种多对象交互分割模型，通过基于示例的语义传播扩展了最先进的、基于变换器的可提示分割一切模型2（SAM2）。MOIS-SAM2在来自84位神经纤维瘤病1型患者119份WB-MRI扫描数据集上进行训练和评估，该数据集使用T2加权脂肪抑制序列获取。数据集在患者层面划分为训练集和四个测试集（其中一个是领域内测试集，三个反映了不同的领域迁移场景，例如MRI磁场强度变化、低肿瘤负担、临床场所和扫描器供应商的差异）。\n\n结果：在领域内测试集上，MOIS-SAM2的扫描-wise DSC为0.60，优于基线3D nnU-Net（DSC：0.54）和SAM2（DSC：0.35）。在MRI磁场强度变化下，该模型的性能保持不变（DSC：0.53），在扫描器供应商差异下也有提升（DSC：0.50），在低肿瘤负担情况下则有所提高（DSC：0.61）。病变检测F1分数在不同测试集中范围从0.62到0.78。初步的互读者变异性分析表明，模型与专家的一致性（DSC：0.62-0.68）与专家之间的一致性相当（DSC：0.57-0.69）。\n\n结论：提出的MOIS-SAM2能够实现高效的、可扩展的WB-MRI中NF的交互分割，具有最小的用户输入和强泛化能力，支持临床工作流程的集成。', 'title_zh': 'MOIS-SAM2：基于例证的全身MRI中神经纤维瘤多病灶交互分割模型2'}
{'arxiv_id': 'arXiv:2509.19271', 'title': 'WolBanking77: Wolof Banking Speech Intent Classification Dataset', 'authors': 'Abdou Karim Kandji, Frédéric Precioso, Cheikh Ba, Samba Ndiaye, Augustin Ndione', 'link': 'https://arxiv.org/abs/2509.19271', 'abstract': 'Intent classification models have made a lot of progress in recent years. However, previous studies primarily focus on high-resource languages datasets, which results in a gap for low-resource languages and for regions with a high rate of illiterate people where languages are more spoken than read or written. This is the case in Senegal, for example, where Wolof is spoken by around 90\\% of the population, with an illiteracy rate of 42\\% for the country. Wolof is actually spoken by more than 10 million people in West African region. To tackle such limitations, we release a Wolof Intent Classification Dataset (WolBanking77), for academic research in intent classification. WolBanking77 currently contains 9,791 text sentences in the banking domain and more than 4 hours of spoken sentences. Experiments on various baselines are conducted in this work, including text and voice state-of-the-art models. The results are very promising on this current dataset. This paper also provides detailed analyses of the contents of the data. We report baseline f1-score and word error rate metrics respectively on NLP and ASR models trained on WolBanking77 dataset and also comparisons between models. We plan to share and conduct dataset maintenance, updates and to release open-source code.', 'abstract_zh': '面向低资源语言的意图分类模型：WolBanking77数据集发布及其应用研究', 'title_zh': 'WolBanking77: Wolof Banking Speech Intent Classification Dataset'}
{'arxiv_id': 'arXiv:2509.19270', 'title': 'SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data', 'authors': 'Erik Božík, Marek Šuppa', 'link': 'https://arxiv.org/abs/2509.19270', 'abstract': "Automatic Speech Recognition (ASR) for low-resource languages like Slovak is hindered by the scarcity of training data. To address this, we introduce SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of speech from parliamentary proceedings. We developed a robust processing pipeline to align and segment long-form recordings into clean, 30-second audio-transcript pairs suitable for model training. We use this dataset to fine-tune several OpenAI Whisper models (small, medium, large-v3, and large-v3-turbo), achieving significant Word Error Rate (WER) reductions on standard Slovak benchmarks like Common Voice and FLEURS. For instance, the fine-tuned Whisper-small model's WER dropped by up to 70\\%, approaching the baseline performance of the much larger Whisper-large-v3 model. To foster future research in low-resource speech recognition, we publicly release the complete SloPalSpeech dataset, the fully segmented transcripts (60 million words), and all our fine-tuned models.", 'abstract_zh': '自动语音识别（ASR）对于斯洛伐克等低资源语言受限于训练数据稀缺。为了解决这一问题，我们介绍了SloPalSpeech，一个新的大规模斯洛伐克ASR数据集，包含来自议会 proceedings 的 2,806 小时语音。我们开发了一个稳健的处理流水线，将长格式录音拆分为干净的 30 秒语音-文本对，适合模型训练。我们使用此数据集对几种OpenAI Whisper模型（小型、中型、大型-v3 和大型-v3-涡轮增压）进行微调，在标准斯洛伐克基准测试（如通用语音和FLEURS）中实现了显著的词错误率（WER）降低。例如，微调的Whisper-small模型的WER降低了多达70%，接近更大规模的Whisper-large-v3模型的基线性能。为了促进未来在低资源语音识别方面的研究，我们公开发布了完整的SloPalSpeech数据集、完全分割的转录文本（6000万词）以及所有微调模型。', 'title_zh': 'SloPalSpeech：来自议会数据的2800小时斯洛伐克语音语料库'}
{'arxiv_id': 'arXiv:2509.19252', 'title': 'Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps', 'authors': 'Gabriel Maldonado, Narges Rashvand, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Vinit Katariya, Hamed Tabkhi', 'link': 'https://arxiv.org/abs/2509.19252', 'abstract': "Continuous human motion understanding remains a core challenge in computer vision due to its high dimensionality and inherent redundancy. Efficient compression and representation are crucial for analyzing complex motion dynamics. In this work, we introduce an adversarially-refined VQ-GAN framework with dense motion tokenization for compressing spatio-temporal heatmaps while preserving the fine-grained traces of human motion. Our approach combines dense motion tokenization with adversarial refinement, which eliminates reconstruction artifacts like motion smearing and temporal misalignment observed in non-adversarial baselines. Our experiments on the CMU Panoptic dataset provide conclusive evidence of our method's superiority, outperforming the dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%. Furthermore, our dense tokenization strategy enables a novel analysis of motion complexity, revealing that 2D motion can be optimally represented with a compact 128-token vocabulary, while 3D motion's complexity demands a much larger 1024-token codebook for faithful reconstruction. These results establish practical deployment feasibility across diverse motion analysis applications. The code base for this work is available at this https URL.", 'abstract_zh': '基于对抗精练的密集运动TOKEN化VQ-GAN框架：压缩时空热量图并保留细粒度的人体运动轨迹', 'title_zh': '对抗精炼VQ-GAN结合密集运动标记化用于时空热图'}
{'arxiv_id': 'arXiv:2509.19249', 'title': 'Reinforcement Learning on Pre-Training Data', 'authors': 'Siheng Li, Kejiao Li, Zenan Xu, Guanhua Huang, Evander Yang, Kun Li, Haoyuan Wu, Jiajia Wu, Zihao Zheng, Chenchen Zhang, Kun Shi, Kyrierl Deng, Qi Yi, Ruibin Xiong, Tingqiang Xu, Yuhao Jiang, Jianfeng Yan, Yuyuan Zeng, Guanghui Xu, Jinbao Xue, Zhijiang Xu, Zheng Fang, Shuai Li, Qibin Liu, Xiaoxue Li, Zhuoyu Li, Yangyu Tao, Fei Gao, Cheng Jiang, Bo Chao Wang, Kai Liu, Jianchen Zhu, Wai Lam, Wayyt Wang, Bo Zhou, Di Wang', 'link': 'https://arxiv.org/abs/2509.19249', 'abstract': 'The growing disparity between the exponential scaling of computational resources and the finite growth of high-quality text data now constrains conventional scaling approaches for large language models (LLMs). To address this challenge, we introduce Reinforcement Learning on Pre-Training data (RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast to prior approaches that scale training primarily through supervised learning, RLPT enables the policy to autonomously explore meaningful trajectories to learn from pre-training data and improve its capability through reinforcement learning (RL). While existing RL strategies such as reinforcement learning from human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR) rely on human annotation for reward construction, RLPT eliminates this dependency by deriving reward signals directly from pre-training data. Specifically, it adopts a next-segment reasoning objective, rewarding the policy for accurately predicting subsequent text segments conditioned on the preceding context. This formulation allows RL to be scaled on pre-training data, encouraging the exploration of richer trajectories across broader contexts and thereby fostering more generalizable reasoning skills. Extensive experiments on both general-domain and mathematical reasoning benchmarks across multiple models validate the effectiveness of RLPT. For example, when applied to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$, $6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and AIME25, respectively. The results further demonstrate favorable scaling behavior, suggesting strong potential for continued gains with more compute. In addition, RLPT provides a solid foundation, extending the reasoning boundaries of LLMs and enhancing RLVR performance.', 'abstract_zh': '基于预训练数据的强化学习训练（RLPT）：大型语言模型的新型扩展范式', 'title_zh': '预训练数据上的强化学习'}
{'arxiv_id': 'arXiv:2509.19231', 'title': 'Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation', 'authors': "Karen Rosero, Eunjung Yeo, David R. Mortensen, Cortney Van't Slot, Rami R. Hallac, Carlos Busso", 'link': 'https://arxiv.org/abs/2509.19231', 'abstract': "We present ChiReSSD, a speech reconstruction framework that preserves children speaker's identity while suppressing mispronunciations. Unlike prior approaches trained on healthy adult speech, ChiReSSD adapts to the voices of children with speech sound disorders (SSD), with particular emphasis on pitch and prosody. We evaluate our method on the STAR dataset and report substantial improvements in lexical accuracy and speaker identity preservation. Furthermore, we automatically predict the phonetic content in the original and reconstructed pairs, where the proportion of corrected consonants is comparable to the percentage of correct consonants (PCC), a clinical speech assessment metric. Our experiments show Pearson correlation of 0.63 between automatic and human expert annotations, highlighting the potential to reduce the manual transcription burden. In addition, experiments on the TORGO dataset demonstrate effective generalization for reconstructing adult dysarthric speech. Our results indicate that disentangled, style-based TTS reconstruction can provide identity-preserving speech across diverse clinical populations.", 'abstract_zh': 'ChiReSSD：一种保留儿童说话人身份并抑制误读的语音重建框架', 'title_zh': '寻找我的声音：无序语音的生成重建及其在自动化临床评估中的应用'}
{'arxiv_id': 'arXiv:2509.19227', 'title': 'MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation', 'authors': 'Tongshuai Wu, Chao Lu, Ze Song, Yunlong Lin, Sizhe Fan, Xuemei Chen', 'link': 'https://arxiv.org/abs/2509.19227', 'abstract': 'With the widespread deployment of dashcams and advancements in computer vision, developing accident prediction models from the dashcam perspective has become critical for proactive safety interventions. However, two key challenges persist: modeling feature-level interactions among traffic participants (often occluded in dashcam views) and capturing complex, asynchronous multi-temporal behavioral cues preceding accidents. To deal with these two challenges, a Multi-scale Feature Interaction Network (MsFIN) is proposed for early-stage accident anticipation from dashcam videos. MsFIN has three layers for multi-scale feature aggregation, temporal feature processing and multi-scale feature post fusion, respectively. For multi-scale feature aggregation, a Multi-scale Module is designed to extract scene representations at short-term, mid-term and long-term temporal scales. Meanwhile, the Transformer architecture is leveraged to facilitate comprehensive feature interactions. Temporal feature processing captures the sequential evolution of scene and object features under causal constraints. In the multi-scale feature post fusion stage, the network fuses scene and object features across multiple temporal scales to generate a comprehensive risk representation. Experiments on DAD and DADA datasets show that MsFIN significantly outperforms state-of-the-art models with single-scale feature extraction in both prediction correctness and earliness. Ablation studies validate the effectiveness of each module in MsFIN, highlighting how the network achieves superior performance through multi-scale feature fusion and contextual interaction modeling.', 'abstract_zh': '基于 dashcam 视角的多尺度特征交互网络在事故早期预测中的应用', 'title_zh': 'MsFIN: 多尺度特征交互网络用于交通事故预测'}
{'arxiv_id': 'arXiv:2509.19224', 'title': 'Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction', 'authors': 'Tariq Abdul-Quddoos, Xishuang Dong, Lijun Qian', 'link': 'https://arxiv.org/abs/2509.19224', 'abstract': "Attention-based models have become the leading approach in modeling medical language for Natural Language Processing (NLP) in clinical notes. These models outperform traditional techniques by effectively capturing contextual rep- resentations of language. In this research a comparative analysis is done amongst pre- trained attention based models namely Bert Base, BioBert, two variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task related to Electronic Health Record (EHR) information extraction. The tasks from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges (n2c2) are considered for this comparison, with the Contextualized Medication Event Dataset (CMED) given for these task. CMED is a dataset of unstructured EHRs and annotated notes that contain task relevant information about the EHRs. The goal of the challenge is to develop effective solutions for extracting contextual information related to patient medication events from EHRs using data driven methods. Each pre-trained model is fine-tuned and applied on CMED to perform medication extraction, medical event detection, and multi-dimensional medication event context classification. Pro- cessing methods are also detailed for breaking down EHRs for compatibility with the applied models. Performance analysis has been carried out using a script based on constructing medical terms from the evaluation portion of CMED with metrics including recall, precision, and F1-Score. The results demonstrate that models pre-trained on clinical data are more effective in detecting medication and medication events, but Bert Base, pre- trained on general domain data showed to be the most effective for classifying the context of events related to medications.", 'abstract_zh': '基于注意力的模型已在临床笔记中的医学语言建模中成为自然语言处理（NLP）的主导方法。这些模型通过有效捕捉语言的上下文表示超越了传统的技术。在本研究中，对预训练的基于注意力的模型，即Bert Base、BioBert、两种Bio+Clinical Bert变体、RoBerta和Clinical Longformer在电子健康记录（EHR）信息提取任务上的表现进行了对比分析。这些比较基于哈佛医学院2022年国家临床NLP挑战（n2c2）第一赛道的任务，使用的是Contextualized Medication Event Dataset（CMED）数据集。CMED是一个包含未结构化EHR和标注笔记的数据集，这些笔记包含与EHR相关的任务相关信息。挑战的目标是利用数据驱动的方法开发有效的解决方案，从EHR中提取与患者用药事件相关的上下文信息。每种预训练模型都被微调并应用于CMED以执行药物提取、医疗事件检测和多维度用药事件上下文分类。还详细描述了处理方法，以确保EHR与所应用的模型兼容。性能分析使用了基于CMED评估部分构建医学术语的脚本，指标包括召回率、精确率和F1分数。结果表明，基于临床数据预训练的模型在检测药物和用药事件方面更为有效，但基于通用领域数据预训练的Bert Base模型在分类与药物相关的事件上下文方面最为有效。', 'title_zh': '大型预训练语言模型在上下文化医疗事件抽取中的系统比较分析'}
{'arxiv_id': 'arXiv:2509.19220', 'title': 'FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity', 'authors': 'Ferdinand Kahenga, Antoine Bagula, Patrick Sello, Sajal K. Das', 'link': 'https://arxiv.org/abs/2509.19220', 'abstract': 'Federated learning in practice must contend with heterogeneous feature spaces, severe non-IID data, and scarce labels across clients. We present FedFusion, a federated transfer-learning framework that unifies domain adaptation and frugal labelling with diversity-/cluster-aware encoders (DivEn, DivEn-mix, DivEn-c). Labelled teacher clients guide learner clients via confidence-filtered pseudo-labels and domain-adaptive transfer, while clients maintain personalised encoders tailored to local data. To preserve global coherence under heterogeneity, FedFusion employs similarity-weighted classifier coupling (with optional cluster-wise averaging), mitigating dominance by data-rich sites and improving minority-client performance. The frugal-labelling pipeline combines self-/semi-supervised pretext training with selective fine-tuning, reducing annotation demands without sharing raw data. Across tabular and imaging benchmarks under IID, non-IID, and label-scarce regimes, FedFusion consistently outperforms state-of-the-art baselines in accuracy, robustness, and fairness while maintaining comparable communication and computation budgets. These results show that harmonising personalisation, domain adaptation, and label efficiency is an effective recipe for robust federated learning under real-world constraints.', 'abstract_zh': '联邦学习在实践中必须应对异质特征空间、严重非IID数据以及客户稀缺标签的问题。我们提出了FedFusion，一个统一域适应和节俭标注的联邦迁移学习框架（配备多样性-/聚类感知编码器DivEn、DivEn-mix和DivEn-c）。标记的教师客户通过可信度过滤的伪标签和域适应的迁移学习指导学习客户，同时客户维护针对本地数据量身定制的编码器。为在异质性下保持全局一致性，FedFusion采用相似性加权分类器耦合（可选聚类平均），减少富数据站点的主导作用，提高少数客户的表现。节俭标注流水线结合自我-/半监督预训练和选择性微调，减少标注需求而不共享原始数据。在标签充裕和稀缺的表征和影像基准测试中，无论是在IID、非IID还是标签稀缺的情境下，FedFusion在准确率、鲁棒性和公平性方面都优于当前最佳基线，同时保持相似的通信和计算预算。这些结果表明，在实际约束条件下，平衡个性化、域适应和标签效率是稳健联邦学习的有效方法。', 'title_zh': '联邦融合：面向标签稀缺条件下的鲁棒适应的多样性及聚类意识编码器联邦学习'}
{'arxiv_id': 'arXiv:2509.19218', 'title': 'HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus', 'authors': 'Yunzhi Xu, Yushuang Ding, Hu Sun, Hongxi Zhang, Li Zhao', 'link': 'https://arxiv.org/abs/2509.19218', 'abstract': 'Evaluation of hydrocephalus in children is challenging, and the related research is limited by a lack of publicly available, expert-annotated datasets, particularly those with segmentation of the choroid plexus. To address this, we present HyKid, an open-source dataset from 48 pediatric patients with hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was reconstructed from routine low-resolution images using a slice-to-volume algorithm. Manually corrected segmentations of brain tissues, including white matter, grey matter, lateral ventricle, external CSF, and the choroid plexus, were provided by an experienced neurologist. Additionally, structured data was extracted from clinical radiology reports using a Retrieval-Augmented Generation framework. The strong correlation between choroid plexus volume and total CSF volume provided a potential biomarker for hydrocephalus evaluation, achieving excellent performance in a predictive model (AUC = 0.87). The proposed HyKid dataset provided a high-quality benchmark for neuroimaging algorithms development, and it revealed the choroid plexus-related features in hydrocephalus assessments. Our datasets are publicly available at this https URL.', 'abstract_zh': '儿童颅内积水的评估具有挑战性，相关研究受限于缺乏公开的专业标注数据集，尤其是包含 choroid plexus 分段的数据集。为解决这一问题，我们提出了 HyKid，一个来自 48 例颅内积水儿童患者的开源数据集。提供了 1mm 等效分辨率的 3D MRI，并通过切片到体积算法从常规低分辨率图像中重建。一名经验丰富的神经科医生提供了手动校正的脑组织分割标注，包括白质、灰质、侧脑室、硬脑膜外脑脊液和 choroid plexus。此外，使用 Retrieval-Augmented Generation 框架从临床放射学报告中提取结构化数据。choroid plexus 体积与总脑脊液体积之间的强相关性为颅内积水评估提供了潜在生物标志物，在预测模型中表现出色（AUC = 0.87）。提出的数据集 HyKid 为神经影像算法开发提供了高质量基准，并揭示了颅内积水评估中的 choroid plexus 相关特征。相关数据集可在以下链接公开获取。', 'title_zh': 'HyKid: 一种带有专家标注多结构和脉络膜囊肿的儿科脑积水开放MRI数据集'}
{'arxiv_id': 'arXiv:2509.19212', 'title': 'Steering Multimodal Large Language Models Decoding for Context-Aware Safety', 'authors': 'Zheyuan Liu, Zhangchen Xu, Guangyao Dou, Xiangchi Yuan, Zhaoxuan Tan, Radha Poovendran, Meng Jiang', 'link': 'https://arxiv.org/abs/2509.19212', 'abstract': 'Multimodal Large Language Models (MLLMs) are increasingly deployed in real-world applications, yet their ability to make context-aware safety decisions remains limited. Existing methods often fail to balance oversensitivity (unjustified refusals of benign queries) and undersensitivity (missed detection of visually grounded risks), leaving a persistent gap in safety alignment. To address this issue, we introduce Safety-aware Contrastive Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that dynamically adjusts token generation based on multimodal context. SafeCoDe operates in two stages: (1) a contrastive decoding mechanism that highlights tokens sensitive to visual context by contrasting real and Gaussian-noised images, and (2) a global-aware token modulation strategy that integrates scene-level reasoning with token-level adjustment to adapt refusals according to the predicted safety verdict. Extensive experiments across diverse MLLM architectures and safety benchmarks, covering undersensitivity, oversensitivity, and general safety evaluations, show that SafeCoDe consistently improves context-sensitive refusal behaviors while preserving model helpfulness.', 'abstract_zh': '多模态大语言模型（MLLMs）在实际应用中日益增多，但其在做出基于情境的安全决策方面的能力仍有限。现有方法往往难以在过度敏感（对良性查询进行不必要的拒绝）和欠敏感（未能检测到基于视觉的风险）之间取得平衡，留下了持续的安全对齐缺口。为解决这一问题，我们引入了安全感知对比解码（SafeCoDe），这是一种轻量级且模型无关的解码框架，可以根据多模态上下文动态调整令牌生成。SafeCoDe 分为两个阶段：（1）对比解码机制，通过对比真实图像和高斯噪声图像来突出对视觉上下文敏感的令牌；（2）全局感知的令牌调制策略，将场景级推理与令牌级调整相结合，根据预测的安全判决调整拒绝行为。覆盖欠敏感、过度敏感和一般安全评估的广泛实验表明，SafeCoDe 在维持模型有用性的同时，一致地提升了基于情境的拒绝行为。', 'title_zh': '面向上下文感知安全的多模态大型语言模型解码引导'}
{'arxiv_id': 'arXiv:2509.19182', 'title': 'YAC: Bridging Natural Language and Interactive Visual Exploration with Generative AI for Biomedical Data Discovery', 'authors': 'Devin Lange, Shanghua Gao, Pengwei Sui, Austen Money, Priya Misner, Marinka Zitnik, Nils Gehlenborg', 'link': 'https://arxiv.org/abs/2509.19182', 'abstract': 'Incorporating natural language input has the potential to improve the capabilities of biomedical data discovery interfaces. However, user interface elements and visualizations are still powerful tools for interacting with data, even in the new world of generative AI. In our prototype system, YAC, Yet Another Chatbot, we bridge the gap between natural language and interactive visualizations by generating structured declarative output with a multi-agent system and interpreting that output to render linked interactive visualizations and apply data filters. Furthermore, we include widgets, which allow users to adjust the values of that structured output through user interface elements. We reflect on the capabilities and design of this system with an analysis of its technical dimensions and illustrate the capabilities through four usage scenarios.', 'abstract_zh': '将自然语言输入纳入生物医学数据发现界面具有提高其能力的潜力。然而，即使在生成型AI的新世界中，用户界面元素和可视化工具仍然是与数据交互的强大工具。在我们的原型系统YAC（Yet Another Chatbot）中，我们通过多Agent系统生成结构化声明性输出，并解释该输出以渲染链接的交互式可视化并应用数据过滤。此外，我们包括小部件，这些小部件允许用户通过用户界面元素调整该结构化输出的值。我们通过技术维度的分析反思该系统的功能和设计，并通过四个使用场景说明其功能。', 'title_zh': 'YAC: 结合生成式AI、自然语言与互动视觉探索的生物医学数据发现'}
{'arxiv_id': 'arXiv:2509.19170', 'title': 'Soft Tokens, Hard Truths', 'authors': 'Natasha Butt, Ariel Kwiatkowski, Ismail Labiad, Julia Kempe, Yann Ollivier', 'link': 'https://arxiv.org/abs/2509.19170', 'abstract': 'The use of continuous instead of discrete tokens during the Chain-of-Thought (CoT) phase of reasoning LLMs has garnered attention recently, based on the intuition that a continuous mixture of discrete tokens could simulate a superposition of several reasoning paths simultaneously. Theoretical results have formally proven that continuous tokens have much greater expressivity and can solve specific problems more efficiently. However, practical use of continuous tokens has been limited by strong training difficulties: previous works either just use continuous tokens at inference time on a pre-trained discrete-token model, or must distill the continuous CoT from ground-truth discrete CoTs and face computational costs that limit the CoT to very few tokens.\nThis is the first work introducing a scalable method to learn continuous CoTs via reinforcement learning (RL), without distilling from reference discrete CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input embedding to provide RL exploration. Computational overhead is minimal, enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs match discrete-token CoTs for pass@1 and surpass them for pass@32, showing greater CoT diversity. In systematic comparisons, the best-performing scenario is to train with continuous CoT tokens then use discrete tokens for inference, meaning the "soft" models can be deployed in a standard way. Finally, we show continuous CoT RL training better preserves the predictions of the base model on out-of-domain tasks, thus providing a softer touch to the base model.', 'abstract_zh': '连续-token代替离散-token在链式思考（CoT）推理阶段的应用：基于强化学习的方法', 'title_zh': '软令牌，硬真相'}
{'arxiv_id': 'arXiv:2509.19165', 'title': 'RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions', 'authors': 'Yun Wang, Junjie Hu, Junhui Hou, Chenghao Zhang, Renwei Yang, Dapeng Oliver Wu', 'link': 'https://arxiv.org/abs/2509.19165', 'abstract': 'Recent self-supervised stereo matching methods have made significant progress, but their performance significantly degrades under adverse weather conditions such as night, rain, and fog. We identify two primary weaknesses contributing to this performance degradation. First, adverse weather introduces noise and reduces visibility, making CNN-based feature extractors struggle with degraded regions like reflective and textureless areas. Second, these degraded regions can disrupt accurate pixel correspondences, leading to ineffective supervision based on the photometric consistency assumption. To address these challenges, we propose injecting robust priors derived from the visual foundation model into the CNN-based feature extractor to improve feature representation under adverse weather conditions. We then introduce scene correspondence priors to construct robust supervisory signals rather than relying solely on the photometric consistency assumption. Specifically, we create synthetic stereo datasets with realistic weather degradations. These datasets feature clear and adverse image pairs that maintain the same semantic context and disparity, preserving the scene correspondence property. With this knowledge, we propose a robust self-supervised training paradigm, consisting of two key steps: robust self-supervised scene correspondence learning and adverse weather distillation. Both steps aim to align underlying scene results from clean and adverse image pairs, thus improving model disparity estimation under adverse weather effects. Extensive experiments demonstrate the effectiveness and versatility of our proposed solution, which outperforms existing state-of-the-art self-supervised methods. Codes are available at \\textcolor{blue}{this https URL}.', 'abstract_zh': 'Recent 自监督立体匹配方法在恶劣天气条件下的表现显著提升，但在夜间、雨天和雾天等恶劣天气条件下，其性能会显著下降。我们识别出两种主要弱点导致这种性能下降。首先，恶劣天气引入噪声并降低可见度，使得基于CNN的特征提取器难以处理反射和纹理不足的区域。其次，这些退化区域会干扰准确的像素对应关系，导致基于光度一致性假设的监督无效。为了解决这些挑战，我们提出将源自视觉基础模型的鲁棒先验注入基于CNN的特征提取器中，以在恶劣天气条件下改进特征表示。然后，我们引入场景对应先验来构建鲁棒的监督信号，而不仅仅是依赖光度一致性假设。具体来说，我们创建了具有现实天气退化特征的合成立体数据集。这些数据集包含清晰和恶劣条件下的图像配对，保持相同的语义上下文和视差，保持场景对应性。基于这些知识，我们提出了一种鲁棒的自监督训练范式，包括两个关键步骤：鲁棒自监督场景对应学习和恶劣天气知识蒸馏。这两个步骤旨在对齐来自清晰图像和恶劣图像配对的底层场景结果，从而在恶劣天气效应下改善模型视差估计。广泛的实验表明，我们提出的方法具有良好的有效性和通用性，超越了现有最先进的自监督方法。代码可在 \\textcolor{blue}{此链接} 获取。', 'title_zh': 'RoSe: 严峻天气条件下鲁棒的自监督立体匹配'}
{'arxiv_id': 'arXiv:2509.19147', 'title': 'Generative Propaganda', 'authors': 'Madeleine I. G. Daepp, Alejandro Cuevas, Robert Osazuwa Ness, Vickie Yu-Ping Wang, Bharat Kumar Nayak, Dibyendu Mishra, Ti-Chung Cheng, Shaily Desai, Joyojeet Pal', 'link': 'https://arxiv.org/abs/2509.19147', 'abstract': 'Generative propaganda is the use of generative artificial intelligence (AI) to shape public opinion. To characterize its use in real-world settings, we conducted interviews with defenders (e.g., factcheckers, journalists, officials) in Taiwan and creators (e.g., influencers, political consultants, advertisers) as well as defenders in India, centering two places characterized by high levels of online propaganda. The term "deepfakes", we find, exerts outsized discursive power in shaping defenders\' expectations of misuse and, in turn, the interventions that are prioritized. To better characterize the space of generative propaganda, we develop a taxonomy that distinguishes between obvious versus hidden and promotional versus derogatory use. Deception was neither the main driver nor the main impact vector of AI\'s use; instead, Indian creators sought to persuade rather than to deceive, often making AI\'s use obvious in order to reduce legal and reputational risks, while Taiwan\'s defenders saw deception as a subset of broader efforts to distort the prevalence of strategic narratives online. AI was useful and used, however, in producing efficiency gains in communicating across languages and modes, and in evading human and algorithmic detection. Security researchers should reconsider threat models to clearly differentiate deepfakes from promotional and obvious uses, to complement and bolster the social factors that constrain misuse by internal actors, and to counter efficiency gains globally.', 'abstract_zh': '生成性宣传是利用生成性人工 intelligence (AI) 影响公众舆论的应用。为了在其真实世界应用场景中对其特性进行Characterization，我们对台湾和印度的防御者（例如，事实核查员、记者、官员）以及创作者（例如，影响力人物、政治顾问、广告商）进行了访谈，重点是两个在线宣传水平较高的地方。我们发现，“深伪”一词在塑造防御者的预期滥用方式以及由此导致的优先干预措施方面具有异常强大的话语权。为了更好地Characterize 生成性宣传的空间，我们建立了一种分类法，区分明显与隐秘以及促销与贬低的使用方式。AI 的使用并不是由欺骗行为驱动的，也不是造成影响的主要途径；相反，印度的创作者试图说服而不是欺骗，经常通过使 AI 的使用更加明显来降低法律和声誉风险，而台湾的防御者则将欺骗视为在线扭曲战略叙事总体努力的一个子集。然而，AI 在跨语言和模式沟通中提高了效率，并通过规避人类和算法的检测。安全研究人员应重新考虑威胁模型，明确区分“深伪”与其他促销性和明显使用的做法，以补充和强化限制内部行为者滥用的社会因素，并在全球范围内对抗效率提升。', 'title_zh': '生成式 propaganda'}
{'arxiv_id': 'arXiv:2509.19143', 'title': 'Anecdoctoring: Automated Red-Teaming Across Language and Place', 'authors': 'Alejandro Cuevas, Saloni Dash, Bharat Kumar Nayak, Dan Vann, Madeleine I. G. Daepp', 'link': 'https://arxiv.org/abs/2509.19143', 'abstract': 'Disinformation is among the top risks of generative artificial intelligence (AI) misuse. Global adoption of generative AI necessitates red-teaming evaluations (i.e., systematic adversarial probing) that are robust across diverse languages and cultures, but red-teaming datasets are commonly US- and English-centric. To address this gap, we propose "anecdoctoring", a novel red-teaming approach that automatically generates adversarial prompts across languages and cultures. We collect misinformation claims from fact-checking websites in three languages (English, Spanish, and Hindi) and two geographies (US and India). We then cluster individual claims into broader narratives and characterize the resulting clusters with knowledge graphs, with which we augment an attacker LLM. Our method produces higher attack success rates and offers interpretability benefits relative to few-shot prompting. Results underscore the need for disinformation mitigations that scale globally and are grounded in real-world adversarial misuse.', 'abstract_zh': '生成式人工智能滥用中的不实信息是主要风险之一。为了适应全球范围内生成式人工智能的采用，需要进行跨语言和文化鲁棒性的红队评估（即系统性的对抗性探测试验），但现有的红队数据集多集中在美式英语上。为了解决这一问题，我们提出了一种名为“anecdoctoring”的新型红队方法，该方法能够自动生成跨语言和文化背景的对抗性提示。我们从三家网站（英语、西班牙语和印地语）和两个地理区域（美国和印度）收集不实信息声明，并将这些个体声明聚类成更广泛的叙述，然后使用知识图谱对这些聚类进行表征，并以此扩展攻击者大语言模型。与少量示例提示相比，我们的方法能够实现更高的攻击成功率并提供更好的可解释性。实验结果突显了全球范围内实现不实信息缓解措施的必要性，并且这些措施需要基于实际的对抗性滥用情况。', 'title_zh': 'ANSICTION：跨语言和地区的人工自动化红队行动'}
{'arxiv_id': 'arXiv:2509.19136', 'title': 'On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language', 'authors': 'Sébastien Salva, Redha Taguelmimt', 'link': 'https://arxiv.org/abs/2509.19136', 'abstract': 'The use of natural language (NL) test cases for validating graphical user interface (GUI) applications is emerging as a promising direction to manually written executable test scripts, which are costly to develop and difficult to maintain. Recent advances in large language models (LLMs) have opened the possibility of the direct execution of NL test cases by LLM agents. This paper investigates this direction, focusing on the impact on NL test case unsoundness and on test case execution consistency. NL test cases are inherently unsound, as they may yield false failures due to ambiguous instructions or unpredictable agent behaviour. Furthermore, repeated executions of the same NL test case may lead to inconsistent outcomes, undermining test reliability. To address these challenges, we propose an algorithm for executing NL test cases with guardrail mechanisms and specialised agents that dynamically verify the correct execution of each test step. We introduce measures to evaluate the capabilities of LLMs in test execution and one measure to quantify execution consistency. We propose a definition of weak unsoundness to characterise contexts in which NL test case execution remains acceptable, with respect to the industrial quality levels Six Sigma. Our experimental evaluation with eight publicly available LLMs, ranging from 3B to 70B parameters, demonstrates both the potential and current limitations of current LLM agents for GUI testing. Our experiments show that Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case execution with high execution consistency (above the level 3-sigma). We provide prototype tools, test suites, and results.', 'abstract_zh': '自然语言测试用例在验证图形用户界面应用中的应用：探索大型语言模型直接执行测试用例的潜力与挑战', 'title_zh': '关于使用自然语言编写的测试用例执行中LLM代理的正确性和一致性研究'}
{'arxiv_id': 'arXiv:2509.19135', 'title': 'GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding', 'authors': 'Wenying Luo, Zhiyuan Lin, Wenhao Xu, Minghao Liu, Zhi Li', 'link': 'https://arxiv.org/abs/2509.19135', 'abstract': 'Human mobility traces, often recorded as sequences of check-ins, provide a unique window into both short-term visiting patterns and persistent lifestyle regularities. In this work we introduce GSTM-HMU, a generative spatio-temporal framework designed to advance mobility analysis by explicitly modeling the semantic and temporal complexity of human movement. The framework consists of four key innovations. First, a Spatio-Temporal Concept Encoder (STCE) integrates geographic location, POI category semantics, and periodic temporal rhythms into unified vector representations. Second, a Cognitive Trajectory Memory (CTM) adaptively filters historical visits, emphasizing recent and behaviorally salient events in order to capture user intent more effectively. Third, a Lifestyle Concept Bank (LCB) contributes structured human preference cues, such as activity types and lifestyle patterns, to enhance interpretability and personalization. Finally, task-oriented generative heads transform the learned representations into predictions for multiple downstream tasks. We conduct extensive experiments on four widely used real-world datasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate performance on three benchmark tasks: next-location prediction, trajectory-user identification, and time estimation. The results demonstrate consistent and substantial improvements over strong baselines, confirming the effectiveness of GSTM-HMU in extracting semantic regularities from complex mobility data. Beyond raw performance gains, our findings also suggest that generative modeling provides a promising foundation for building more robust, interpretable, and generalizable systems for human mobility intelligence.', 'abstract_zh': '基于时空概念的生成框架：人类移动分析的新视角（GSTM-HMU）', 'title_zh': 'GSTM-HMU：生成式时空建模为人流移动理解'}
{'arxiv_id': 'arXiv:2509.19122', 'title': 'Analysis on distribution and clustering of weight', 'authors': 'Chunming Ye, Wenquan Tian, Yalan Gao, Songzhou Li', 'link': 'https://arxiv.org/abs/2509.19122', 'abstract': "The study on architecture and parameter characteristics remains the hot topic in the research of large language models. In this paper we concern with the characteristics of weight which are used to analyze the correlations and differences between models. Two kinds of vectors-standard deviation vector and clustering vector-are proposed to describe features of models. In the first case, the weights are assumed to follow normal distribution. The standard deviation values of projection matrices are normalized to form Standard-Deviation Vector, representing the distribution characteristics of models. In the second case, the singular values from each weight projection matrix are extracted and grouped by K-Means algorithm. The grouped data with the same type matrix are combined as Clustering Vector to represent the correlation characteristics of models' weights. The study reveals that these two vectors can effectively distinguish between different models and clearly show the similarities among models of the same family. Moreover, after conducting LoRA fine-tuning with different datasets and models, it is found that the distribution of weights represented by standard deviation vector is directly influenced by the dataset, but the correlations between different weights represented by clustering vector remain unaffected and maintain a high consistency with the pre-trained model.", 'abstract_zh': '大型语言模型研究中关于架构和参数特性研究仍是热点。本文关注用于分析和比较模型特征的权重特性。提出了两种向量——标准差向量和聚类向量——来描述模型特征。在第一种情况下，假设权重服从正态分布，标准化投影矩阵的标准差构成标准差向量，代表模型的分布特性。在第二种情况下，从每个权重投影矩阵中提取奇异值，并使用K-Means算法进行分组。具有相同类型矩阵的分组数据被组合为聚类向量，以表示模型权重的相关特性。研究发现这两种向量能够有效地区分不同模型，并清晰地展示相同家族模型之间的相似性。此外，在使用不同数据集和模型进行LoRA微调后发现，由标准差向量表示的权重分布直接受数据集影响，而由聚类向量表示的不同权重之间的相关性保持不变，与预训练模型保持高度一致性。', 'title_zh': '权重分布及聚类分析'}
{'arxiv_id': 'arXiv:2509.19120', 'title': 'FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI', 'authors': 'Ferdinand Kahenga, Antoine Bagula, Sajal K. Das, Patrick Sello', 'link': 'https://arxiv.org/abs/2509.19120', 'abstract': 'Federated Learning (FL) has emerged as a powerful paradigm for privacy-preserving model training, yet deployments in sensitive domains such as healthcare face persistent challenges from non-IID data, client unreliability, and adversarial manipulation. This paper introduces FedFiTS, a trust and fairness-aware selective FL framework that advances the FedFaSt line by combining fitness-based client election with slotted aggregation. FedFiTS implements a three-phase participation strategy-free-for-all training, natural selection, and slotted team participation-augmented with dynamic client scoring, adaptive thresholding, and cohort-based scheduling to balance convergence efficiency with robustness. A theoretical convergence analysis establishes bounds for both convex and non-convex objectives under standard assumptions, while a communication-complexity analysis shows reductions relative to FedAvg and other baselines. Experiments on diverse datasets-medical imaging (X-ray pneumonia), vision benchmarks (MNIST, FMNIST), and tabular agricultural data (Crop Recommendation)-demonstrate that FedFiTS consistently outperforms FedAvg, FedRand, and FedPow in accuracy, time-to-target, and resilience to poisoning attacks. By integrating trust-aware aggregation with fairness-oriented client selection, FedFiTS advances scalable and secure FL, making it well suited for real-world healthcare and cross-domain deployments.', 'abstract_zh': 'FedFiTS：一种信任和公平感知的选择性联邦学习框架', 'title_zh': 'FedFiTS：基于健身选择的分时客户端调度以实现医疗AI可信联邦学习'}
{'arxiv_id': 'arXiv:2509.19112', 'title': 'Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation', 'authors': 'Hugo Math, Rainer Lienhart', 'link': 'https://arxiv.org/abs/2509.19112', 'abstract': "Understanding causality in event sequences where outcome labels such as diseases or system failures arise from preceding events like symptoms or error codes is critical. Yet remains an unsolved challenge across domains like healthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label causal discovery method for sparse, high-dimensional event sequences comprising of thousands of unique event types. Using two pretrained causal Transformers as domain-specific foundation models for event sequences. CARGO infers in parallel, per sequence one-shot causal graphs and aggregates them using an adaptive frequency fusion to reconstruct the global Markov boundaries of labels. This two-stage approach enables efficient probabilistic reasoning at scale while bypassing the intractable cost of full-dataset conditional independence testing. Our results on a challenging real-world automotive fault prediction dataset with over 29,100 unique event types and 474 imbalanced labels demonstrate CARGO's ability to perform structured reasoning.", 'abstract_zh': '理解由前期事件如症状或错误代码导致的结果标签如疾病或系统故障在事件序列中的因果关系对于各个领域（如医疗保健或车辆诊断）至关重要，但仍然是一项未解决的挑战。我们引入了CARGO，一种适用于稀疏高维事件序列（包含数千种 unique 事件类型）的可扩展多标签因果发现方法。通过使用两种预训练的因果 Transformer 作为事件序列的领域特定基础模型，CARGO 并行地为每个序列推断一次性的因果图，并通过自适应频率融合将其聚合以重构全局马尔可夫边界。这种两阶段方法使大规模高效概率推理成为可能，从而绕过了全数据集条件独立性检验的不可行成本。我们的结果表明，CARGO 在一个包含超过 29,100 种 unique 事件类型和 474 种失衡标签的具有挑战性的真实世界汽车故障预测数据集中能够进行结构化推理。', 'title_zh': '基于一键图聚合的高维事件序列高效多标签因果发现'}
{'arxiv_id': 'arXiv:2509.19102', 'title': 'FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation', 'authors': 'Hongli Xu, Lei Zhang, Xiaoyue Hu, Boyang Zhong, Kaixin Bai, Zoltán-Csaba Márton, Zhenshan Bing, Zhaopeng Chen, Alois Christian Knoll, Jianwei Zhang', 'link': 'https://arxiv.org/abs/2509.19102', 'abstract': 'General-purpose robotic skills from end-to-end demonstrations often leads to task-specific policies that fail to generalize beyond the training distribution. Therefore, we introduce FunCanon, a framework that converts long-horizon manipulation tasks into sequences of action chunks, each defined by an actor, verb, and object. These chunks focus policy learning on the actions themselves, rather than isolated tasks, enabling compositionality and reuse. To make policies pose-aware and category-general, we perform functional object canonicalization for functional alignment and automatic manipulation trajectory transfer, mapping objects into shared functional frames using affordance cues from large vision language models. An object centric and action centric diffusion policy FuncDiffuser trained on this aligned data naturally respects object affordances and poses, simplifying learning and improving generalization ability. Experiments on simulated and real-world benchmarks demonstrate category-level generalization, cross-task behavior reuse, and robust sim2real deployment, showing that functional canonicalization provides a strong inductive bias for scalable imitation learning in complex manipulation domains. Details of the demo and supplemental material are available on our project website this https URL.', 'abstract_zh': '一般化机器人技能从端到端演示中获得的任务特定策略往往难以泛化到训练分布之外。因此，我们提出了FunCanon框架，将长时 horizon 操作任务转换为由执行者、动词和物体定义的行动片段序列。这些片段集中于行动本身的学习，而非孤立的任务，从而实现组合性和重用性。为了使策略具备姿态意识和类别普适性，我们进行了功能性对象标准变换，实现了功能对齐和自动操作轨迹迁移，使用大型视觉语言模型中的可利用性线索将物体映射到共享的功能框架中。以这种对齐的数据为中心的物体扩散策略和操作扩散策略FuncDiffuser自然地遵循对象的可利用性和姿态，简化了学习并提高了泛化能力。在模拟和现实世界基准上的实验展示了类别水平的泛化、跨任务行为的重用以及稳健的仿真实验部署，表明功能性标准变换为在复杂操作领域中可扩展的模仿学习提供了强大的归纳偏置。演示细节和补充材料详见我们的项目网站：<https://>。', 'title_zh': 'FUNCanon: 基于功能对象标准化的学习姿态感知动作primitive及其在通用化机器人操作中的应用'}
{'arxiv_id': 'arXiv:2509.19100', 'title': 'Algorithms for Adversarially Robust Deep Learning', 'authors': 'Alexander Robey', 'link': 'https://arxiv.org/abs/2509.19100', 'abstract': 'Given the widespread use of deep learning models in safety-critical applications, ensuring that the decisions of such models are robust against adversarial exploitation is of fundamental importance. In this thesis, we discuss recent progress toward designing algorithms that exhibit desirable robustness properties. First, we discuss the problem of adversarial examples in computer vision, for which we introduce new technical results, training paradigms, and certification algorithms. Next, we consider the problem of domain generalization, wherein the task is to train neural networks to generalize from a family of training distributions to unseen test distributions. We present new algorithms that achieve state-of-the-art generalization in medical imaging, molecular identification, and image classification. Finally, we study the setting of jailbreaking large language models (LLMs), wherein an adversarial user attempts to design prompts that elicit objectionable content from an LLM. We propose new attacks and defenses, which represent the frontier of progress toward designing robust language-based agents.', 'abstract_zh': '基于深度学习模型在关键安全应用中的广泛应用，确保这些模型的决策能够抵御对抗性利用是基础性的。在这项研究中，我们讨论了设计具有稳健性特征算法的最新进展。首先，我们探讨了计算机视觉中的对抗性示例问题，并引入了新的技术成果、训练范式和认证算法。接着，我们考虑了领域泛化问题，即训练神经网络从训练分布族推广到未见过的测试分布。我们提出了新的算法，实现了医学成像、分子识别和图像分类领域的最佳泛化性能。最后，我们研究了大型语言模型（LLMs）的破解设置，其中恶意用户试图设计提示以从LLM中引发令人反感的内容。我们提出了新的攻击和防御方法，代表了设计基于语言的稳健代理的最新进展。', 'title_zh': '对抗鲁棒的深度学习算法'}
{'arxiv_id': 'arXiv:2509.19094', 'title': 'Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering', 'authors': 'Alireza Salemi, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Zhuowan Li, Spurthi Amba Hombaiah, Weize Kong, Tao Chen, Hamed Zamani, Michael Bendersky', 'link': 'https://arxiv.org/abs/2509.19094', 'abstract': 'Personalization is essential for adapting question answering (QA) systems to user-specific information needs, thereby improving both accuracy and user satisfaction. However, personalized QA remains relatively underexplored due to challenges such as inferring preferences from long, noisy, and implicit contexts, and generating responses that are simultaneously correct, contextually appropriate, and aligned with user expectations and background knowledge. To address these challenges, we propose Pathways of Thoughts (PoT), an inference-stage method that applies to any large language model (LLM) without requiring task-specific fine-tuning. The approach models the reasoning of an LLM as an iterative decision process, where the model dynamically selects among cognitive operations such as reasoning, revision, personalization, and clarification. This enables exploration of multiple reasoning trajectories, producing diverse candidate responses that capture different perspectives. PoT then aggregates and reweights these candidates according to inferred user preferences, yielding a final personalized response that benefits from the complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA benchmark for personalized QA show that PoT consistently outperforms competitive baselines, achieving up to a 13.1% relative improvement. Human evaluation corroborates these results, with annotators preferring outputs from PoT in 66% of cases and reporting ties in only 15% of cases.', 'abstract_zh': '个性化对于适应用户特定的信息需求、提高问答系统准确性和用户满意度至关重要。然而，由于从长、嘈杂和隐含的上下文中推断偏好、生成同时正确、上下文适宜且与用户期望和背景知识相符的回答的挑战，个性化问答相对未被充分探索。为应对这些挑战，我们提出了一种名为Pathways of Thoughts (PoT)的方法，这是一种适用于任何大型语言模型（LLM）的推理阶段方法，无需特定任务的微调。该方法将大型语言模型的推理视为一个迭代决策过程，模型动态选择认知操作，如推理、修订、个性化和澄清。这使得可以探索多个推理轨迹，生成多样化的候选回答，捕捉不同的视角。PoT 然后根据推断出的用户偏好聚合和重新权重这些候选回答，产生一种最终的个性化回答，融合了多种推理路径的互补优势。在个人化问答基准LaMP-QA上的实验表明，PoT 一贯优于竞争性基线，相对改进率高达13.1%。人类评估进一步验证了这些结果，注释者在66%的情况下更偏好PoT的输出，在15%的情况下报告平局。', 'title_zh': '思绪路径：多向思考在长格式个性化问答中的应用'}
{'arxiv_id': 'arXiv:2509.19091', 'title': 'Training Flow Matching Models with Reliable Labels via Self-Purification', 'authors': 'Hyeongju Kim, Yechan Yu, June Young Yi, Juheon Lee', 'link': 'https://arxiv.org/abs/2509.19091', 'abstract': 'Training datasets are inherently imperfect, often containing mislabeled samples due to human annotation errors, limitations of tagging models, and other sources of noise. Such label contamination can significantly degrade the performance of a trained model. In this work, we introduce Self-Purifying Flow Matching (SPFM), a principled approach to filtering unreliable data within the flow-matching framework. SPFM identifies suspicious data using the model itself during the training process, bypassing the need for pretrained models or additional modules. Our experiments demonstrate that models trained with SPFM generate samples that accurately adhere to the specified conditioning, even when trained on noisy labels. Furthermore, we validate the robustness of SPFM on the TITW dataset, which consists of in-the-wild speech data, achieving performance that surpasses existing baselines.', 'abstract_zh': '训练数据本质上是不完美的，往往包含由于人工注解错误、标记模型的局限性和其他噪声源导致的误标样本。此类标签污染会显著劣化训练模型的性能。在本文中，我们提出了一种在流匹配框架内的名为自我净化流匹配（SPFM）的原则性方法，用于筛选不可靠数据。SPFM在训练过程中利用模型本身识别可疑数据，无需依赖预训练模型或额外模块。我们的实验表明，使用SPFM训练的模型能够生成准确符合指定条件的样本，即使在噪声标签下训练也是如此。此外，我们还在野生语音数据集TITW上验证了SPFM的鲁棒性，其性能超越了现有基线。', 'title_zh': '通过自我净化生成可靠标签训练流匹配模型'}
{'arxiv_id': 'arXiv:2509.19090', 'title': 'Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning', 'authors': 'Guoxin Wang, Jun Zhao, Xinyi Liu, Yanbo Liu, Xuyang Cao, Chao Li, Zhuoyun Liu, Qintian Sun, Fangru Zhou, Haoqiang Xing, Zhenhong Yang', 'link': 'https://arxiv.org/abs/2509.19090', 'abstract': 'Medical imaging provides critical evidence for clinical diagnosis, treatment planning, and surgical decisions, yet most existing imaging models are narrowly focused and require multiple specialized networks, limiting their generalization. Although large-scale language and multimodal models exhibit strong reasoning and multi-task capabilities, real-world clinical applications demand precise visual grounding, multimodal integration, and chain-of-thought reasoning. We introduce Citrus-V, a multimodal medical foundation model that combines image analysis with textual reasoning. The model integrates detection, segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level lesion localization, structured report generation, and physician-like diagnostic inference in a single framework. We propose a novel multimodal training approach and release a curated open-source data suite covering reasoning, detection, segmentation, and document understanding tasks. Evaluations demonstrate that Citrus-V outperforms existing open-source medical models and expert-level imaging systems across multiple benchmarks, delivering a unified pipeline from visual grounding to clinical reasoning and supporting precise lesion quantification, automated reporting, and reliable second opinions.', 'abstract_zh': '医学影像为临床诊断、治疗计划和手术决策提供关键证据，但现有大多数影像模型关注狭窄领域且需要多个专业化网络，限制了它们的泛化能力。尽管大规模语言和多模态模型表现出强大的推理和多任务能力，实际临床应用需要精确的视觉定位、多模态融合和链条式推理。我们引入了Citrus-V，一种将图像分析与文本推理结合的多模态医学基础模型。该模型整合了检测、分割和多模态链条式推理，能够在单一体系框架中实现像素级病灶定位、结构化报告生成和类似于医生的诊断推理。我们提出了一种新颖的多模态训练方法，并发布了涵盖推理、检测、分割和文档理解任务的精心策划开源数据集。评估结果显示，Citrus-V 在多个基准测试中优于现有开源医学模型和专家级影像系统，提供从视觉定位到临床推理的统一流程，并支持精确的病灶量化、自动化报告和可靠的第二意见。', 'title_zh': '柑橘-V：统一医学图像 grounding 以推动临床推理的医学基础模型进展'}
{'arxiv_id': 'arXiv:2509.19088', 'title': 'A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement', 'authors': 'Tiany Peng, George Gui, Daniel J. Merlau, Grace Jiarui Fan, Malek Ben Sliman, Melanie Brucks, Eric J. Johnson, Vicki Morwitz, Abdullah Althenayyan, Silvia Bellezza, Dante Donati, Hortense Fong, Elizabeth Friedman, Ariana Guevara, Mohamed Hussein, Kinshuk Jerath, Bruce Kogut, Kristen Lane, Hannah Li, Patryk Perkowski, Oded Netzer, Olivier Toubia', 'link': 'https://arxiv.org/abs/2509.19088', 'abstract': 'Do "digital twins" capture individual responses in surveys and experiments? We run 19 pre-registered studies on a national U.S. panel and their LLM-powered digital twins (constructed based on previously-collected extensive individual-level data) and compare twin and human answers across 164 outcomes. The correlation between twin and human answers is modest (approximately 0.2 on average) and twin responses are less variable than human responses. While constructing digital twins based on rich individual-level data improves our ability to capture heterogeneity across participants and predict relative differences between them, it does not substantially improve our ability to predict the exact answers given by specific participants or enhance predictions of population means. Twin performance varies by domain and is higher among more educated, higher-income, and ideologically moderate participants. These results suggest current digital twins can capture some degree of relative differences but are unreliable for individual-level predictions and sample mean and variance estimation, underscoring the need for careful validation before use. Our data and code are publicly available for researchers and practitioners interested in optimizing digital twin pipelines.', 'abstract_zh': '数字孪生体能否捕捉调查和实验中的个体反应？我们针对一个国家级美国面板数据及其基于之前收集的个体层面数据构建的LLM驱动数字孪生体进行了19项事先注册的研究，并在164个结果上比较了孪生体和人类的答复。孪生体和人类答复之间的相关性适度（平均约为0.2），且孪生体的回答比人类的回答更具一致性。虽然基于丰富个体层面数据构建数字孪生体能够提高我们捕捉参与者异质性和预测他们相对差异的能力，但并未显著提升预测特定参与者确切答案的能力或改善对总体均值的预测。数字孪生体的表现因领域而异，在受过更好教育、收入更高以及政治观点更为中立的参与者中表现更佳。这些结果表明，当前的数字孪生体能够捕捉一定的相对差异，但不适用于个体水平预测和样本均值及方差估计，在使用之前需要谨慎验证。我们的数据和代码已对外公开，供对优化数字孪生体管道感兴趣的研究人员和从业人员使用。', 'title_zh': '大规模数字孪生研究揭示了其优势、劣势及进一步改进的机会'}
{'arxiv_id': 'arXiv:2509.19084', 'title': 'Graph Neural Networks with Similarity-Navigated Probabilistic Feature Copying', 'authors': 'Asela Hevapathige', 'link': 'https://arxiv.org/abs/2509.19084', 'abstract': "Graph Neural Networks (GNNs) have demonstrated remarkable success across various graph-based tasks. However, they face some fundamental limitations: feature oversmoothing can cause node representations to become indistinguishable in deeper networks, they struggle to effectively manage heterogeneous relationships where connected nodes differ significantly, and they process entire feature vectors as indivisible units, which limits flexibility. We seek to address these limitations. We propose AxelGNN, a novel GNN architecture inspired by Axelrod's cultural dissemination model that addresses these limitations through a unified framework. AxelGNN incorporates similarity-gated probabilistic interactions that adaptively promote convergence or divergence based on node similarity, implements trait-level copying mechanisms for fine-grained feature aggregation at the segment level, and maintains global polarization to preserve node distinctiveness across multiple representation clusters. The model's bistable convergence dynamics naturally handle both homophilic and heterophilic graphs within a single architecture. Extensive experiments on node classification and influence estimation benchmarks demonstrate that AxelGNN consistently outperforms or matches state-of-the-art GNN methods across diverse graph structures with varying homophily-heterophily characteristics.", 'abstract_zh': '基于 Axelrod 文化传播模型的 AxelGNN：统一框架下的图神经网络新架构', 'title_zh': '带有相似导航概率特征复制的图神经网络'}
{'arxiv_id': 'arXiv:2509.19080', 'title': 'World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation', 'authors': 'Zhennan Jiang, Kai Liu, Yuxin Qin, Shuai Tian, Yupeng Zheng, Mingcai Zhou, Chao Yu, Haoran Li, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2509.19080', 'abstract': 'Robotic manipulation policies are commonly initialized through imitation learning, but their performance is limited by the scarcity and narrow coverage of expert data. Reinforcement learning can refine polices to alleviate this limitation, yet real-robot training is costly and unsafe, while training in simulators suffers from the sim-to-real gap. Recent advances in generative models have demonstrated remarkable capabilities in real-world simulation, with diffusion models in particular excelling at generation. This raises the question of how diffusion model-based world models can be combined to enhance pre-trained policies in robotic manipulation. In this work, we propose World4RL, a framework that employs diffusion-based world models as high-fidelity simulators to refine pre-trained policies entirely in imagined environments for robotic manipulation. Unlike prior works that primarily employ world models for planning, our framework enables direct end-to-end policy optimization. World4RL is designed around two principles: pre-training a diffusion world model that captures diverse dynamics on multi-task datasets and refining policies entirely within a frozen world model to avoid online real-world interactions. We further design a two-hot action encoding scheme tailored for robotic manipulation and adopt diffusion backbones to improve modeling fidelity. Extensive simulation and real-world experiments demonstrate that World4RL provides high-fidelity environment modeling and enables consistent policy refinement, yielding significantly higher success rates compared to imitation learning and other baselines. More visualization results are available at this https URL.', 'abstract_zh': '基于扩散模型的世界模型在机器人操作中的强化学习框架', 'title_zh': 'World4RL: 扩散世界模型在强化学习中用于机器人操作策略精炼'}
{'arxiv_id': 'arXiv:2509.19063', 'title': 'Beyond Backpropagation: Exploring Innovative Algorithms for Energy-Efficient Deep Neural Network Training', 'authors': 'Przemysław Spyra', 'link': 'https://arxiv.org/abs/2509.19063', 'abstract': "The rising computational and energy demands of deep neural networks (DNNs), driven largely by backpropagation (BP), challenge sustainable AI development. This paper rigorously investigates three BP-free training methods: the Forward-Forward (FF), Cascaded-Forward (CaFo), and Mono-Forward (MF) algorithms, tracing their progression from foundational concepts to a demonstrably superior solution.\nA robust comparative framework was established: each algorithm was implemented on its native architecture (MLPs for FF and MF, a CNN for CaFo) and benchmarked against an equivalent BP-trained model. Hyperparameters were optimized with Optuna, and consistent early stopping criteria were applied based on validation performance, ensuring all models were optimally tuned before comparison.\nResults show that MF not only competes with but consistently surpasses BP in classification accuracy on its native MLPs. Its superior generalization stems from converging to a more favorable minimum in the validation loss landscape, challenging the assumption that global optimization is required for state-of-the-art results. Measured at the hardware level using the NVIDIA Management Library (NVML) API, MF reduces energy consumption by up to 41% and shortens training time by up to 34%, translating to a measurably smaller carbon footprint as estimated by CodeCarbon.\nBeyond this primary result, we present a hardware-level analysis that explains the efficiency gains: exposing FF's architectural inefficiencies, validating MF's computationally lean design, and challenging the assumption that all BP-free methods are inherently more memory-efficient. By documenting the evolution from FF's conceptual groundwork to MF's synthesis of accuracy and sustainability, this work offers a clear, data-driven roadmap for future energy-efficient deep learning.", 'abstract_zh': '深度神经网络（DNNs）由于反向传播（BP）驱动的日益增长的计算和能源需求，挑战可持续AI开发。本文严格研究了三种无BP训练方法：前向前向（FF）、级联前向（CaFo）和单前向（MF）算法，并追溯了这些方法从基础概念到可证明更优解决方案的进展。\n建立了一套 robust 对比框架：每个算法在其原生架构（FF 和 MF 使用全连接网络，CaFo 使用卷积神经网络）上实现，并与相应的 BP 训练模型进行基准测试。使用 Optuna 对超参数进行优化，并基于验证性能应用一致的早期停止标准，确保所有模型在比较前均已优化。\n结果表明，MF 不仅能够与 BP 竞争，在其原生全连接网络上的分类准确率甚至持续超越 BP。其更强的泛化能力源自于在验证损失景观中收敛到更优的极小值，挑战了必须进行全局优化才能获得最优结果的假设。通过使用 NVIDIA 管理库 (NVML) API 在硬件层面测量，MF 减少了高达 41% 的能源消耗并缩短了高达 34% 的训练时间，从而通过 CodeCarbon 估算出具有更小的碳足迹。\n在此主要结果之外，本文还呈现了在硬件层面的分析，解释了效率提升的原因：揭示了 FF 的架构效率低下，验证了 MF 的计算经济性设计，并挑战了所有无 BP 方法都天然更高效内存使用的假设。通过记录 FF 的概念基础到 MF 同时实现准确性与可持续性的演变，本文为未来能源高效的深度学习提供了一条清晰的数据驱动路线图。', 'title_zh': '超越反向传播：探索高效的深度神经网络训练创新算法'}
{'arxiv_id': 'arXiv:2509.19023', 'title': 'Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion', 'authors': 'Shuai Liu, Meng Cheng Lau', 'link': 'https://arxiv.org/abs/2509.19023', 'abstract': "We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a two-stage reinforcement learning framework for humanoid walking that requires no motion capture data or elaborate reward shaping. In the first stage, a compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via Proximal Policy Optimization. This generates energy-efficient gait templates. In the second stage, those dynamically consistent trajectories guide a full-body policy trained with Soft Actor--Critic augmented by an adversarial discriminator, ensuring the student's five-dimensional gait feature distribution matches the ROM's demonstrations. Experiments at 1 meter-per-second and 4 meter-per-second show that ROM-GRL produces stable, symmetric gaits with substantially lower tracking error than a pure-reward baseline. By distilling lightweight ROM guidance into high-dimensional policies, ROM-GRL bridges the gap between reward-only and imitation-based locomotion methods, enabling versatile, naturalistic humanoid behaviors without any human demonstrations.", 'abstract_zh': 'Reduced-Order Model-Guided Reinforcement Learning for Humanoid Walking', 'title_zh': '基于降阶模型的示范-free humanoid运动强化学习'}
{'arxiv_id': 'arXiv:2509.19017', 'title': 'Fully Learnable Neural Reward Machines', 'authors': 'Hazem Dewidar, Elena Umili', 'link': 'https://arxiv.org/abs/2509.19017', 'abstract': 'Non-Markovian Reinforcement Learning (RL) tasks present significant challenges, as agents must reason over entire trajectories of state-action pairs to make optimal decisions. A common strategy to address this is through symbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which provide a structured way to express temporally extended objectives. However, these approaches often rely on restrictive assumptions -- such as the availability of a predefined Symbol Grounding (SG) function mapping raw observations to high-level symbolic representations, or prior knowledge of the temporal task. In this work, we propose a fully learnable version of Neural Reward Machines (NRM), which can learn both the SG function and the automaton end-to-end, removing any reliance on prior knowledge. Our approach is therefore as easily applicable as classic deep RL (DRL) approaches, while being far more explainable, because of the finite and compact nature of automata. Furthermore, we show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL, our method outperforms previous approaches based on Recurrent Neural Networks (RNNs).', 'abstract_zh': '非马尔可夫强化学习任务提出了重大挑战，因为代理必须在做出最优决策时对状态-行动对的整个轨迹进行推理。一种常见的应对策略是通过符号形式主义，如线性时序逻辑（LTL）或自动机，它们为表达时间扩展目标提供了一种结构化的方式。然而，这些方法通常依赖于一些限制性假设，例如预定义的符号基底（SG）函数映射原始观察到高级符号表示，或者已知的时间任务先验知识。在本文中，我们提出了一种完全可学习的神经奖励机器（NRM）版本，它可以端到端地学习SG函数和自动机，从而不再依赖于先验知识。因此，我们的方法在应用上与经典的深度强化学习（DRL）方法一样方便，但由于自动机具有有限和紧凑的性质，因此更易于解释。此外，我们展示了通过将完全可学习奖励机器（FLNRM）与DRL结合，我们的方法在基于递归神经网络（RNN）的先前方法上表现出更好的性能。', 'title_zh': '完全可学习神经奖励机器'}
{'arxiv_id': 'arXiv:2509.19012', 'title': 'Pure Vision Language Action (VLA) Models: A Comprehensive Survey', 'authors': 'Dapeng Zhang, Jin Sun, Chenghui Hu, Xiaoyan Wu, Zhenlong Yuan, Rui Zhou, Fei Shen, Qingguo Zhou', 'link': 'https://arxiv.org/abs/2509.19012', 'abstract': 'The emergence of Vision Language Action (VLA) models marks a paradigm shift from traditional policy-based control to generalized robotics, reframing Vision Language Models (VLMs) from passive sequence generators into active agents for manipulation and decision-making in complex, dynamic environments. This survey delves into advanced VLA methods, aiming to provide a clear taxonomy and a systematic, comprehensive review of existing research. It presents a comprehensive analysis of VLA applications across different scenarios and classifies VLA approaches into several paradigms: autoregression-based, diffusion-based, reinforcement-based, hybrid, and specialized methods; while examining their motivations, core strategies, and implementations in detail. In addition, foundational datasets, benchmarks, and simulation platforms are introduced. Building on the current VLA landscape, the review further proposes perspectives on key challenges and future directions to advance research in VLA models and generalizable robotics. By synthesizing insights from over three hundred recent studies, this survey maps the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose VLA methods.', 'abstract_zh': '视觉语言动作（VLA）模型的涌现标志着从传统基于策略的控制向通用机器人学的范式转变，重新定义了视觉语言模型（VLMs）从被动序列生成器转变为在复杂动态环境中进行操作和决策的主动代理。本文综述了先进的VLA方法，旨在提供清晰的分类，并进行全面系统的文献综述。综述详细分析了不同场景下的VLA应用，并将VLA方法分类为自回归、扩散、强化学习、混合和专门方法等 paradigm，同时探讨了它们的动机、核心策略和实现方式。此外，还介绍了基础数据集、基准测试和模拟平台。基于当前的VLA景观，综述进一步提出了关键挑战和未来方向，以促进VLA模型和通用机器人学的研究。通过综合分析三百多篇近期的研究，本文勾勒了这一快速发展的领域轮廓，并指出了塑造可扩展且通用的VLA方法发展的机会和挑战。', 'title_zh': '纯视觉语言动作（VLA）模型：综述'}
{'arxiv_id': 'arXiv:2509.19002', 'title': 'VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction', 'authors': 'Hao Wang, Eiki Murata, Lingfang Zhang, Ayako Sato, So Fukuda, Ziqi Yin, Wentao Hu, Keisuke Nakao, Yusuke Nakamura, Sebastian Zwirner, Yi-Chia Chen, Hiroyuki Otomo, Hiroki Ouchi, Daisuke Kawahara', 'link': 'https://arxiv.org/abs/2509.19002', 'abstract': "Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications.", 'abstract_zh': 'Recent Advances in Multimodal Large Language Models: Bridging the Gap in Long-Distance Travel Understanding with VIR-Bench', 'title_zh': 'VIR-Bench：通过旅行视频行程重构评估时空理解能力的地理和时间建模大模型'}
{'arxiv_id': 'arXiv:2509.18953', 'title': "Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations", 'authors': 'Hanqing Liu, Jiahuan Long, Junqi Wu, Jiacheng Hou, Huili Tang, Tingsong Jiang, Weien Zhou, Wen Yao', 'link': 'https://arxiv.org/abs/2509.18953', 'abstract': 'Vision-Language-Action (VLA) models have emerged as promising solutions for robotic manipulation, yet their robustness to real-world physical variations remains critically underexplored. To bridge this gap, we propose Eva-VLA, the first unified framework that systematically evaluates the robustness of VLA models by transforming discrete physical variations into continuous optimization problems. However, comprehensively assessing VLA robustness presents two key challenges: (1) how to systematically characterize diverse physical variations encountered in real-world deployments while maintaining evaluation reproducibility, and (2) how to discover worst-case scenarios without prohibitive real-world data collection costs efficiently. To address the first challenge, we decompose real-world variations into three critical domains: object 3D transformations that affect spatial reasoning, illumination variations that challenge visual perception, and adversarial patches that disrupt scene understanding. For the second challenge, we introduce a continuous black-box optimization framework that transforms discrete physical variations into parameter optimization, enabling systematic exploration of worst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models across multiple benchmarks reveal alarming vulnerabilities: all variation types trigger failure rates exceeding 60%, with object transformations causing up to 97.8% failure in long-horizon tasks. Our findings expose critical gaps between controlled laboratory success and unpredictable deployment readiness, while the Eva-VLA framework provides a practical pathway for hardening VLA-based robotic manipulation models against real-world deployment challenges.', 'abstract_zh': 'Vision-Language-Action (VLA)模型在机器人操作中展现出潜力，但其在现实世界物理变异中的鲁棒性仍严重欠缺研究。为弥补这一差距，我们提出了Eva-VLA，这是首个系统评估VLA模型鲁棒性的统一框架，通过将离散的物理变异转化为连续的优化问题来实现。然而，全面评估VLA鲁棒性面临两个关键挑战：(1) 如何系统地表征现实生活部署中遇到的各种物理变异并保持评价的可重复性，以及(2) 如何高效地发现最坏情况场景而无需高昂的现实世界数据收集成本。为应对第一个挑战，我们将现实生活中的变异分解为三个关键领域：影响空间推理的物体3D变换、挑战视觉感知的光照变化，以及干扰场景理解的对抗性贴图。为应对第二个挑战，我们引入了一个连续的黑盒优化框架，将离散的物理变异转化为参数优化，从而系统探索最坏情况场景。在多个基准上的实验表明，最先进的OpenVLA模型在多种变体类型触发的故障率超过60%，物体变换在长时任务中导致高达97.8%的故障。我们的研究揭示了在受控实验室成功和不可预测部署准备之间的重要差距，而Eva-VLA框架提供了一条实用途径，以增强基于VLA的机器人操作模型以应对现实世界部署挑战。', 'title_zh': 'Eva-VLA: 评估视觉-语言-行动模型在现实世界物理变化下的稳健性'}
{'arxiv_id': 'arXiv:2509.18949', 'title': 'Towards Privacy-Aware Bayesian Networks: A Credal Approach', 'authors': 'Niccolò Rocchi, Fabio Stella, Cassio de Campos', 'link': 'https://arxiv.org/abs/2509.18949', 'abstract': "Bayesian networks (BN) are probabilistic graphical models that enable efficient knowledge representation and inference. These have proven effective across diverse domains, including healthcare, bioinformatics and economics. The structure and parameters of a BN can be obtained by domain experts or directly learned from available data. However, as privacy concerns escalate, it becomes increasingly critical for publicly released models to safeguard sensitive information in training data. Typically, released models do not prioritize privacy by design. In particular, tracing attacks from adversaries can combine the released BN with auxiliary data to determine whether specific individuals belong to the data from which the BN was learned. State-of-the-art protection tecniques involve introducing noise into the learned parameters. While this offers robust protection against tracing attacks, it significantly impacts the model's utility, in terms of both the significance and accuracy of the resulting inferences. Hence, high privacy may be attained at the cost of releasing a possibly ineffective model. This paper introduces credal networks (CN) as a novel solution for balancing the model's privacy and utility. After adapting the notion of tracing attacks, we demonstrate that a CN enables the masking of the learned BN, thereby reducing the probability of successful attacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve meaningful inferences while safeguarding privacy. Moreover, we identify key learning information that must be concealed to prevent attackers from recovering the underlying BN. Finally, we conduct a set of numerical experiments to analyze how privacy gains can be modulated by tuning the CN hyperparameters. Our results confirm that CNs provide a principled, practical, and effective approach towards the development of privacy-aware probabilistic graphical models.", 'abstract_zh': '贝叶斯网络（BN）是概率图形模型，能够高效地实现知识表示和推理。这些模型已在医疗保健、生物信息学和经济学等多个领域证明有效。BN的结构和参数可以通过领域专家获得，也可以直接从可用数据中学习。然而，随着隐私担忧的加剧，如何在公开发布模型时保护训练数据中的敏感信息变得越来越重要。通常情况下，发布模型时不优先考虑设计上的隐私保护。特别是，对手可以利用公开发布的BN与辅助数据结合来进行跟踪攻击，以确定某些个体是否属于用于学习BN的数据。最先进的保护技术是向学习到的参数中引入噪声。虽然这种方法能对跟踪攻击提供稳健保护，但会显著影响模型的效用，包括推断结果的显著性和准确性。因此，高隐私可能以释放一个可能无效的模型为代价。本文引入了信任网络（CN）作为一种新的解决方案，以平衡模型的隐私和效用。在适应跟踪攻击的概念后，我们证明CN能够对公开发布的BN进行掩盖，从而降低成功攻击的概率。由于CN是对BN进行模糊化处理但不是加入噪声的版本，它们可以在保护隐私的同时实现有意义的推断。此外，我们确定了必须隐藏的关键学习信息，以防止攻击者重新构建底层的BN。最后，我们进行了一系列数值实验，分析了通过调整CN超参数来调节隐私收益的方法。我们的结果证实，CN提供了一种原理上合理、实用且有效的保护隐私的概率图形模型开发方法。', 'title_zh': '面向隐私意识的贝叶斯网络：一种信任区间方法'}
{'arxiv_id': 'arXiv:2509.18938', 'title': 'No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning', 'authors': 'Matheus Vinícius Todescato, Joel Luís Carbonera', 'link': 'https://arxiv.org/abs/2509.18938', 'abstract': 'While deep learning, including Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), has significantly advanced classification performance, its typical reliance on extensive annotated datasets presents a major obstacle in many practical scenarios where such data is scarce. Vision-language models (VLMs) and transfer learning with pre-trained visual models appear as promising techniques to deal with this problem. This paper proposes a novel zero-shot image classification framework that combines a VLM and a pre-trained visual model within a self-learning cycle. Requiring only the set of class names and no labeled training data, our method utilizes a confidence-based pseudo-labeling strategy to train a lightweight classifier directly on the test data, enabling dynamic adaptation. The VLM identifies high-confidence samples, and the pre-trained visual model enhances their visual representations. These enhanced features then iteratively train the classifier, allowing the system to capture complementary semantic and visual cues without supervision. Notably, our approach avoids VLM fine-tuning and the use of large language models, relying on the visual-only model to reduce the dependence on semantic representation. Experimental evaluations on ten diverse datasets demonstrate that our approach outperforms the baseline zero-shot method.', 'abstract_zh': '一种结合视觉语言模型和预训练视觉模型的零样本图像分类自学习框架', 'title_zh': '无需标签：协作自学习的零样本图像分类'}
{'arxiv_id': 'arXiv:2509.18933', 'title': 'Accurate and Efficient Prediction of Wi-Fi Link Quality Based on Machine Learning', 'authors': 'Gabriele Formis, Gianluca Cena, Lukasz Wisniewski, Stefano Scanzio', 'link': 'https://arxiv.org/abs/2509.18933', 'abstract': 'Wireless communications are characterized by their unpredictability, posing challenges for maintaining consistent communication quality. This paper presents a comprehensive analysis of various prediction models, with a focus on achieving accurate and efficient Wi-Fi link quality forecasts using machine learning techniques. Specifically, the paper evaluates the performance of data-driven models based on the linear combination of exponential moving averages, which are designed for low-complexity implementations and are then suitable for hardware platforms with limited processing resources. Accuracy of the proposed approaches was assessed using experimental data from a real-world Wi-Fi testbed, considering both channel-dependent and channel-independent training data. Remarkably, channel-independent models, which allow for generalized training by equipment manufacturers, demonstrated competitive performance. Overall, this study provides insights into the practical deployment of machine learning-based prediction models for enhancing Wi-Fi dependability in industrial environments.', 'abstract_zh': '无线通信因其不可预测性给保持一致的通信质量带来了挑战。本文对各种预测模型进行了全面分析，重点关注使用机器学习技术实现准确高效的Wi-Fi链路质量预测。具体而言，本文评估了基于指数移动平均线性组合的数据驱动模型的性能，这些模型旨在实现低复杂度实现，并适用于处理资源有限的硬件平台。所提出方法的准确性通过实际Wi-Fi测试床的实验数据进行评估，考虑了依赖信道和不依赖信道的训练数据。值得注意的是，不依赖信道的模型因其允许设备制造商进行通用训练而展现了竞争性的性能。总体而言，本研究为在工业环境中部署基于机器学习的预测模型以提高Wi-Fi可靠性提供了实用见解。', 'title_zh': '基于机器学习的Wi-Fi链路质量准确高效预测'}
{'arxiv_id': 'arXiv:2509.18930', 'title': 'Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning', 'authors': 'Alex Schutz, Victor-Alexandru Darvariu, Efimia Panagiotaki, Bruno Lacerda, Nick Hawes', 'link': 'https://arxiv.org/abs/2509.18930', 'abstract': 'Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks to execute classic algorithms by supervised learning. Despite its successes, important limitations remain: inability to construct valid solutions without post-processing and to reason about multiple correct ones, poor performance on combinatorial NP-hard problems, and inapplicability to problems for which strong algorithms are not yet known. To address these limitations, we reframe the problem of learning algorithm trajectories as a Markov Decision Process, which imposes structure on the solution construction procedure and unlocks the powerful tools of imitation and reinforcement learning (RL). We propose the GNARL framework, encompassing the methodology to translate problem formulations from NAR to RL and a learning architecture suitable for a wide range of graph-based problems. We achieve very high graph accuracy results on several CLRS-30 problems, performance matching or exceeding much narrower NAR approaches for NP-hard problems and, remarkably, applicability even when lacking an expert algorithm.', 'abstract_zh': '神经算法推理（NAR）是一种通过监督学习训练神经网络执行经典算法的范式。尽管取得了成功，但仍存在重要限制：无法在不进行后处理的情况下构造有效的解决方案，难以推理多个正确的解决方案，组合NP难问题上的性能不佳，以及对于目前还没有强大算法的问题不适用。为克服这些限制，我们将学习算法轨迹的问题重新框架为马尔可夫决策过程，这为解构建过程施加了结构，并解锁了模仿学习和强化学习（RL）的强大工具。我们提出了GNARL框架，涵盖将NAR中的问题表述转换为RL的方法论以及适用于多种图问题的学习架构。我们在多个CLRS-30问题上实现了非常高的图准确率结果，在组合NP难问题上达到了或超过了更窄的NAR方法的性能，并且甚至在缺乏专家算法时也具有适用性。', 'title_zh': '解决棘手问题：通过强化学习重塑图神经算法推理'}
{'arxiv_id': 'arXiv:2509.18917', 'title': 'LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models', 'authors': 'Amirhesam Aghanouri, Cristina Olaverri-Monreal', 'link': 'https://arxiv.org/abs/2509.18917', 'abstract': "Autonomous vehicles (AVs) are expected to revolutionize transportation by improving efficiency and safety. Their success relies on 3D vision systems that effectively sense the environment and detect traffic agents. Among sensors AVs use to create a comprehensive view of surroundings, LiDAR provides high-resolution depth data enabling accurate object detection, safe navigation, and collision avoidance. However, collecting real-world LiDAR data is time-consuming and often affected by noise and sparsity due to adverse weather or sensor limitations. This work applies a denoising diffusion probabilistic model (DDPM), enhanced with novel noise scheduling and time-step embedding techniques to generate high-quality synthetic data for augmentation, thereby improving performance across a range of computer vision tasks, particularly in AV perception. These modifications impact the denoising process and the model's temporal awareness, allowing it to produce more realistic point clouds based on the projection. The proposed method was extensively evaluated under various configurations using the IAMCV and KITTI-360 datasets, with four performance metrics compared against state-of-the-art (SOTA) methods. The results demonstrate the model's superior performance over most existing baselines and its effectiveness in mitigating the effects of noisy and sparse LiDAR data, producing diverse point clouds with rich spatial relationships and structural detail.", 'abstract_zh': '自主驾驶车辆中的去噪扩散概率模型在3D视觉任务中的应用：生成高質量合成数据以改善感知性能', 'title_zh': '基于去噪扩散概率模型的LiDAR点云图像生成'}
{'arxiv_id': 'arXiv:2509.18900', 'title': 'The AI Literacy Heptagon: A Structured Approach to AI Literacy in Higher Education', 'authors': 'Veronika Hackl, Alexandra Mueller, Maximilian Sailer', 'link': 'https://arxiv.org/abs/2509.18900', 'abstract': 'The integrative literature review addresses the conceptualization and implementation of AI Literacy (AIL) in Higher Education (HE) by examining recent research literature. Through an analysis of publications (2021-2024), we explore (1) how AIL is defined and conceptualized in current research, particularly in HE, and how it can be delineated from related concepts such as Data Literacy, Media Literacy, and Computational Literacy; (2) how various definitions can be synthesized into a comprehensive working definition, and (3) how scientific insights can be effectively translated into educational practice. Our analysis identifies seven central dimensions of AIL: technical, applicational, critical thinking, ethical, social, integrational, and legal. These are synthesized in the AI Literacy Heptagon, deepening conceptual understanding and supporting the structured development of AIL in HE. The study aims to bridge the gap between theoretical AIL conceptualizations and the practical implementation in academic curricula.', 'abstract_zh': '综合性文献回顾探讨了人工智能素养（AIL）在高等教育（HE）中的概念化与实施，通过分析近期研究文献（2021-2024）。我们探讨了（1）当前研究，尤其是高等教育中，对AIL的定义和概念化，以及如何区分其与数据素养、媒体素养和计算素养等相关概念；（2）如何将各种定义综合成一个全面的工作定义；（3）如何有效地将科学洞见转化为教育实践。分析识别了人工智能素养的七大核心维度：技术性、应用性、批判性思维、伦理性、社会性、整合性和法律性。这些维度被综合在人工智能素养七角形（AI Literacy Heptagon）中，加深了对人工智能素养概念的理解，并支持了人工智能素养在高等教育中结构化的发展。本研究旨在弥合理论性人工智能素养概念化与学术课程中实际实施之间的差距。', 'title_zh': 'AI素养七边形：高等教育中AI素养的结构化方法'}
{'arxiv_id': 'arXiv:2509.18880', 'title': 'Diversity Boosts AI-Generated Text Detection', 'authors': 'Advik Raj Basani, Pin-Yu Chen', 'link': 'https://arxiv.org/abs/2509.18880', 'abstract': 'Detecting AI-generated text is an increasing necessity to combat misuse of LLMs in education, business compliance, journalism, and social media, where synthetic fluency can mask misinformation or deception. While prior detectors often rely on token-level likelihoods or opaque black-box classifiers, these approaches struggle against high-quality generations and offer little interpretability. In this work, we propose DivEye, a novel detection framework that captures how unpredictability fluctuates across a text using surprisal-based features. Motivated by the observation that human-authored text exhibits richer variability in lexical and structural unpredictability than LLM outputs, DivEye captures this signal through a set of interpretable statistical features. Our method outperforms existing zero-shot detectors by up to 33.2% and achieves competitive performance with fine-tuned baselines across multiple benchmarks. DivEye is robust to paraphrasing and adversarial attacks, generalizes well across domains and models, and improves the performance of existing detectors by up to 18.7% when used as an auxiliary signal. Beyond detection, DivEye provides interpretable insights into why a text is flagged, pointing to rhythmic unpredictability as a powerful and underexplored signal for LLM detection.', 'abstract_zh': '检测AI生成的文字成为一个日益必要的需求，以应对教育、商业合规、新闻界和社会媒体中大规模语言模型的滥用问题，其中合成流利性可以掩盖错误信息或欺骗行为。虽然以往的方法常常依赖于令牌级别的概率或不透明的黑盒分类器，但这些方法难以应对高质量的生成文本，并且缺乏解释性。在这项工作中，我们提出DivEye，一种新颖的检测框架，使用基于 surprisal 的特征捕捉文本中不可预测性的波动。受人类撰写的文本比大规模语言模型输出展现出更丰富的词汇和结构不可预测性这一观察的启发，DivEye 通过一组可解释的统计特征捕捉这一信号。我们的方法在零样本检测器上优于现有方法最多 33.2%，并在多个基准上达到与微调基线相当的性能。DivEye 在重述和对抗攻击中表现出 robust，并能很好地跨领域和模型泛化，将其作为辅助信号使用时，可以提高现有检测器多达 18.7% 的性能。此外，DivEye 提供可解释的洞察，解释为什么文本被标记，指出节奏不可预测性是大规模语言模型检测中一个强大且未充分探索的信号。', 'title_zh': '多样性增强AI生成文本检测'}
{'arxiv_id': 'arXiv:2509.18874', 'title': 'When Ads Become Profiles: Large-Scale Audit of Algorithmic Biases and LLM Profiling Risks', 'authors': 'Baiyu Chen, Benjamin Tag, Hao Xue, Daniel Angus, Flora Salim', 'link': 'https://arxiv.org/abs/2509.18874', 'abstract': "Automated ad targeting on social media is opaque, creating risks of exploitation and invisibility to external scrutiny. Users may be steered toward harmful content while independent auditing of these processes remains blocked. Large Language Models (LLMs) raise a new concern: the potential to reverse-engineer sensitive user attributes from exposure alone. We introduce a multi-stage auditing framework to investigate these risks. First, a large-scale audit of over 435,000 ad impressions delivered to 891 Australian Facebook users reveals algorithmic biases, including disproportionate Gambling and Politics ads shown to socioeconomically vulnerable and politically aligned groups. Second, a multimodal LLM can reconstruct users' demographic profiles from ad streams, outperforming census-based baselines and matching or exceeding human performance. Our results provide the first empirical evidence that ad streams constitute rich digital footprints for public AI inference, highlighting urgent privacy risks and the need for content-level auditing and governance.", 'abstract_zh': '社交媒体上的自动化广告定向是不透明的，这创造了对外部审查的滥用和 invisibility 的风险。用户可能会被引导观看有害内容，而独立审计这些过程仍然受阻。大规模语言模型 (LLMs) 引出一个新担忧：仅从曝光中逆向工程敏感用户属性的可能性。我们介绍一个多阶段审计框架以调查这些风险。首先，对交付给891名澳大利亚Facebook用户的435,000多条广告印象进行大规模审计，揭示了算法偏见，包括不成比例地向社会经济脆弱群体和政治对齐群体展示赌博和政治广告。其次，多模态LLM可以从广告流中重建用户的 demographic 背景，优于基于人口普查的基准，并达到或超过人类性能。我们的结果提供了第一个实证证据，表明广告流构成了丰富的数字足迹，用于公共AI推理，突显出迫切的隐私风险和内容级别的审计与治理需求。', 'title_zh': '当广告变成画像：大规模审计算法偏见和大语言模型画像风险'}
{'arxiv_id': 'arXiv:2509.18851', 'title': 'NGRPO: Negative-enhanced Group Relative Policy Optimization', 'authors': 'Gongrui Nan, Siye Chen, Jing Huang, Mengyu Lu, Dexun Wang, Chunmei Xie, Weiqi Xiong, Xianzhou Zeng, Qixuan Zhou, Yadong Li, Xingzhong Xu', 'link': 'https://arxiv.org/abs/2509.18851', 'abstract': "RLVR has enhanced the reasoning capabilities of Large Language Models (LLMs) across various tasks. However, GRPO, a representative RLVR algorithm, suffers from a critical limitation: when all responses within a group are either entirely correct or entirely incorrect, the model fails to learn from these homogeneous responses. This is particularly problematic for homogeneously incorrect groups, where GRPO's advantage function yields a value of zero, leading to null gradients and the loss of valuable learning signals. To overcome this issue, we propose NGRPO (Negative-enhanced Group Relative Policy Optimization), an algorithm designed to convert homogeneous errors into robust learning signals. First, NGRPO introduces Advantage Calibration. This mechanism hypothesizes the existence of a virtual maximum-reward sample during advantage calculation, thereby altering the mean and variance of rewards within a group and ensuring that the advantages for homogeneously incorrect samples are no longer zero. Second, NGRPO employs Asymmetric Clipping, which relaxes the update magnitude for positive samples while imposing stricter constraints on that of negative samples. This serves to stabilize the exploration pressure introduced by the advantage calibration. Our experiments on Qwen2.5-Math-7B demonstrate that NGRPO significantly outperforms baselines such as PPO, GRPO, DAPO, and PSR-NSR on mathematical benchmarks including MATH500, AMC23, and AIME2025. These results validate NGRPO's ability to learn from homogeneous errors, leading to stable and substantial improvements in mathematical reasoning. Our code is available at this https URL.", 'abstract_zh': 'NGRPO：通过负增强组相对策略优化将同质错误转化为稳健的学习信号', 'title_zh': 'NGRPO：负增强组相对策略优化'}
{'arxiv_id': 'arXiv:2509.18847', 'title': 'Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions', 'authors': 'Junhao Su, Yuanliang Wan, Junwei Yang, Hengyu Shi, Tianyang Han, Junfeng Luo, Yurui Qiu', 'link': 'https://arxiv.org/abs/2509.18847', 'abstract': "Tool-augmented large language models (LLMs) are usually trained with supervised imitation or coarse-grained reinforcement learning that optimizes single tool calls. Current self-reflection practices rely on heuristic prompts or one-way reasoning: the model is urged to 'think more' instead of learning error diagnosis and repair. This is fragile in multi-turn interactions; after a failure the model often repeats the same mistake. We propose structured reflection, which turns the path from error to repair into an explicit, controllable, and trainable action. The agent produces a short yet precise reflection: it diagnoses the failure using evidence from the previous step and then proposes a correct, executable follow-up call. For training we combine DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce Tool-Reflection-Bench, a lightweight benchmark that programmatically checks structural validity, executability, parameter correctness, and result consistency. Tasks are built as mini trajectories of erroneous call, reflection, and corrected call, with disjoint train and test splits. Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn tool-call success and error recovery, and a reduction of redundant calls. These results indicate that making reflection explicit and optimizing it directly improves the reliability of tool interaction and offers a reproducible path for agents to learn from failure.", 'abstract_zh': '工具增强的大语言模型（LLMs）通常通过监督模仿或粗粒度强化学习进行训练，优化单一工具调用。当前的自省实践依赖启发式提示或单向推理：模型被敦促“思考更多”，而不是学习错误诊断和修复。在多轮交互中这是脆弱的；在失败后，模型通常会重复同样的错误。我们提出了结构化自省，将从错误到修复的过程转化为显式的、可控的和可训练的操作。代理生成简短而精确的自省：它使用上一步的证据进行故障诊断，然后提出一个正确且可执行的后续调用。在训练中，我们将DAPO和GSPO目标与针对工具使用定制的奖励方案结合，优化逐步策略“先反省，再调用，再最终确认”。为了评估，我们引入了Tool-Reflection-Bench，这是一个轻量级基准，编程检查结构有效性、可执行性、参数正确性和结果一致性。任务构建为包含错误调用、自省和修正调用的小轨迹，并具有分离的训练集和测试集。在BFCL v3和Tool-Reflection-Bench上的实验显示，在多轮工具调用成功和错误恢复方面有显著提升，并减少了冗余调用。这些结果表明，使自省明确并直接优化它可以提高工具交互的可靠性，并为代理从失败中学习提供可复制的路径。', 'title_zh': '失败让代理更强大：通过结构化反思提升准确性的可靠工具交互'}
{'arxiv_id': 'arXiv:2509.18831', 'title': 'Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters', 'authors': 'Pin-Yen Chiu, I-Sheng Fang, Jun-Cheng Chen', 'link': 'https://arxiv.org/abs/2509.18831', 'abstract': 'Recent advances in diffusion models have significantly improved image and video synthesis. In addition, several concept control methods have been proposed to enable fine-grained, continuous, and flexible control over free-form text prompts. However, these methods not only require intensive training time and GPU memory usage to learn the sliders or embeddings but also need to be retrained for different diffusion backbones, limiting their scalability and adaptability. To address these limitations, we introduce Text Slider, a lightweight, efficient and plug-and-play framework that identifies low-rank directions within a pre-trained text encoder, enabling continuous control of visual concepts while significantly reducing training time, GPU memory consumption, and the number of trainable parameters. Furthermore, Text Slider supports multi-concept composition and continuous control, enabling fine-grained and flexible manipulation in both image and video synthesis. We show that Text Slider enables smooth and continuous modulation of specific attributes while preserving the original spatial layout and structure of the input. Text Slider achieves significantly better efficiency: 5$\\times$ faster training than Concept Slider and 47$\\times$ faster than Attribute Control, while reducing GPU memory usage by nearly 2$\\times$ and 4$\\times$, respectively.', 'abstract_zh': 'Recent Advances in Diffusion Models Have Significantly Enhanced Image and Video Synthesis: Introducing Text Slider, a Lightweight and Efficient Framework for Continuous Visual Concept Control', 'title_zh': '文本滑块：通过LoRA适配器实现的高效可插拔连续概念控制以进行图像/视频合成'}
{'arxiv_id': 'arXiv:2509.18801', 'title': 'A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising', 'authors': 'Kuang Xiaodong, Li Bingxuan, Li Yuan, Rao Fan, Ma Gege, Xie Qingguo, Mok Greta S P, Liu Huafeng, Zhu Wentao', 'link': 'https://arxiv.org/abs/2509.18801', 'abstract': 'Achieving high image quality for temporal frames in dynamic positron emission tomography (PET) is challenging due to the limited statistic especially for the short frames. Recent studies have shown that deep learning (DL) is useful in a wide range of medical image denoising tasks. In this paper, we propose a model-based neural network for dynamic PET image denoising. The inter-frame spatial correlation and intra-frame structural consistency in dynamic PET are used to establish the kernel space-based multidimensional sparse (KMDS) model. We then substitute the inherent forms of the parameter estimation with neural networks to enable adaptive parameters optimization, forming the end-to-end neural KMDS-Net. Extensive experimental results from simulated and real data demonstrate that the neural KMDS-Net exhibits strong denoising performance for dynamic PET, outperforming previous baseline methods. The proposed method may be used to effectively achieve high temporal and spatial resolution for dynamic PET. Our source code is available at this https URL.', 'abstract_zh': '基于模型的神经网络在动态正电子发射断层成像(PET)图像去噪中的应用', 'title_zh': '基于内核空间的多维稀疏模型动态PET图像去噪'}
{'arxiv_id': 'arXiv:2509.18790', 'title': 'Detection of security smells in IaC scripts through semantics-aware code and language processing', 'authors': 'Aicha War, Adnan A. Rawass, Abdoul K. Kabore, Jordan Samhi, Jacques Klein, Tegawende F. Bissyande', 'link': 'https://arxiv.org/abs/2509.18790', 'abstract': 'Infrastructure as Code (IaC) automates the provisioning and management of IT infrastructure through scripts and tools, streamlining software deployment. Prior studies have shown that IaC scripts often contain recurring security misconfigurations, and several detection and mitigation approaches have been proposed. Most of these rely on static analysis, using statistical code representations or Machine Learning (ML) classifiers to distinguish insecure configurations from safe code.\nIn this work, we introduce a novel approach that enhances static analysis with semantic understanding by jointly leveraging natural language and code representations. Our method builds on two complementary ML models: CodeBERT, to capture semantics across code and text, and LongFormer, to represent long IaC scripts without losing contextual information. We evaluate our approach on misconfiguration datasets from two widely used IaC tools, Ansible and Puppet. To validate its effectiveness, we conduct two ablation studies (removing code text from the natural language input and truncating scripts to reduce context) and compare against four large language models (LLMs) and prior work. Results show that semantic enrichment substantially improves detection, raising precision and recall from 0.46 and 0.79 to 0.92 and 0.88 on Ansible, and from 0.55 and 0.97 to 0.87 and 0.75 on Puppet, respectively.', 'abstract_zh': '基于语义的理解增强软件开发生命周期中的静态分析以检测基础设施即代码中的安全配置错误：以Ansible和Puppet为例', 'title_zh': '基于语义感知的代码和语言处理在检测IaC脚本中的安全气味方面的研究'}
{'arxiv_id': 'arXiv:2509.18778', 'title': 'VGGT-DP: Generalizable Robot Control via Vision Foundation Models', 'authors': 'Shijia Ge, Yinxin Zhang, Shuzhao Xie, Weixiang Zhang, Mingcai Zhou, Zhi Wang', 'link': 'https://arxiv.org/abs/2509.18778', 'abstract': 'Visual imitation learning frameworks allow robots to learn manipulation skills from expert demonstrations. While existing approaches mainly focus on policy design, they often neglect the structure and capacity of visual encoders, limiting spatial understanding and generalization. Inspired by biological vision systems, which rely on both visual and proprioceptive cues for robust control, we propose VGGT-DP, a visuomotor policy framework that integrates geometric priors from a pretrained 3D perception model with proprioceptive feedback. We adopt the Visual Geometry Grounded Transformer (VGGT) as the visual encoder and introduce a proprioception-guided visual learning strategy to align perception with internal robot states, improving spatial grounding and closed-loop control. To reduce inference latency, we design a frame-wise token reuse mechanism that compacts multi-view tokens into an efficient spatial representation. We further apply random token pruning to enhance policy robustness and reduce overfitting. Experiments on challenging MetaWorld tasks show that VGGT-DP significantly outperforms strong baselines such as DP and DP3, particularly in precision-critical and long-horizon scenarios.', 'abstract_zh': '视觉模仿学习框架使机器人能够从专家示范中学习操作技能。现有的方法主要集中在策略设计上，往往忽视视觉编码器的结构和容量，限制了空间理解能力和泛化能力。受生物视觉系统依赖视觉和本体感觉线索进行鲁棒控制的启发，我们提出了一种结合预训练3D感知模型的几何先验和本体感觉反馈的visuomotor策略框架VGGT-DP。我们采用Visual Geometry Grounded Transformer (VGGT) 作为视觉编码器，并引入本体感觉引导的视觉学习策略，以使感知与内部机器人状态对齐，从而提高空间定位能力和闭环控制性能。为了减少推断延迟，我们设计了一种帧内令牌重用机制，将多视角令牌压缩成高效的空间表示。进一步应用随机令牌剪枝以增强策略的鲁棒性并减少过拟合。在具有挑战性的MetaWorld任务上的实验表明，VGGT-DP在精度关键和长时序场景中显著优于如DP和DP3等强基准。', 'title_zh': 'VGGT-DP: 通过视觉基础模型实现可泛化的机器人控制'}
{'arxiv_id': 'arXiv:2509.18776', 'title': 'AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field', 'authors': 'Chen Liang, Zhaoqi Huang, Haofen Wang, Fu Chai, Chunying Yu, Huanhuan Wei, Zhengjie Liu, Yanpeng Li, Hongjun Wang, Ruifeng Luo, Xianzhong Zhao', 'link': 'https://arxiv.org/abs/2509.18776', 'abstract': 'Large language models (LLMs), as a novel information technology, are seeing increasing adoption in the Architecture, Engineering, and Construction (AEC) field. They have shown their potential to streamline processes throughout the building lifecycle. However, the robustness and reliability of LLMs in such a specialized and safety-critical domain remain to be evaluated. To address this challenge, this paper establishes AECBench, a comprehensive benchmark designed to quantify the strengths and limitations of current LLMs in the AEC domain. The benchmark defines 23 representative tasks within a five-level cognition-oriented evaluation framework encompassing Knowledge Memorization, Understanding, Reasoning, Calculation, and Application. These tasks were derived from authentic AEC practice, with scope ranging from codes retrieval to specialized documents generation. Subsequently, a 4,800-question dataset encompassing diverse formats, including open-ended questions, was crafted primarily by engineers and validated through a two-round expert review. Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable and consistent methodology for evaluating complex, long-form responses leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear performance decline across five cognitive levels was revealed. Despite demonstrating proficiency in foundational tasks at the Knowledge Memorization and Understanding levels, the models showed significant performance deficits, particularly in interpreting knowledge from tables in building codes, executing complex reasoning and calculation, and generating domain-specific documents. Consequently, this study lays the groundwork for future research and development aimed at the robust and reliable integration of LLMs into safety-critical engineering practices.', 'abstract_zh': '大型语言模型（LLMs）在建筑、工程和施工（AEC）领域的综合基准：评估当前LLMs在AEC领域的优势与限制', 'title_zh': 'AECBench: A 分层基准用于评估建筑、工程和施工领域大型语言模型的知识水平'}
{'arxiv_id': 'arXiv:2509.18775', 'title': 'Financial Risk Relation Identification through Dual-view Adaptation', 'authors': 'Wei-Ning Chiu, Yu-Hsiang Wang, Andy Hsiao, Yu-Shiang Huang, Chuan-Ju Wang', 'link': 'https://arxiv.org/abs/2509.18775', 'abstract': 'A multitude of interconnected risk events -- ranging from regulatory changes to geopolitical tensions -- can trigger ripple effects across firms. Identifying inter-firm risk relations is thus crucial for applications like portfolio management and investment strategy. Traditionally, such assessments rely on expert judgment and manual analysis, which are, however, subjective, labor-intensive, and difficult to scale. To address this, we propose a systematic method for extracting inter-firm risk relations using Form 10-K filings -- authoritative, standardized financial documents -- as our data source. Leveraging recent advances in natural language processing, our approach captures implicit and abstract risk connections through unsupervised fine-tuning based on chronological and lexical patterns in the filings. This enables the development of a domain-specific financial encoder with a deeper contextual understanding and introduces a quantitative risk relation score for transparency, interpretable analysis. Extensive experiments demonstrate that our method outperforms strong baselines across multiple evaluation settings.', 'abstract_zh': '多种相互关联的风险事件——从监管变化到地缘政治紧张关系等——可以触发企业间的涟漪效应。因此，识别企业间的风险关系对于投资组合管理和投资策略等应用至关重要。传统上，这种评估依赖于专家判断和手动分析，但这些方法具有主观性、劳动密集型且难以规模化。为了解决这一问题，我们提出了一种系统方法，利用10-K filings（权威且标准化的财务文件）作为数据源，提取企业间的风险关系。借助近期自然语言处理的进展，我们的方法通过基于文件中时间顺序和词汇模式的无监督微调，捕获隐含和抽象的风险联系，从而开发出具有更深层次上下文理解的领域特定财务编码器，并引入定量的风险关系评分以提高透明度和可解释性。广泛的实验表明，在多种评估设置中，我们的方法优于强大 baselines。', 'title_zh': '通过双视图适应识别财务风险关系'}
{'arxiv_id': 'arXiv:2509.18765', 'title': 'DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision', 'authors': 'Azad Singh, Deepak Mishra', 'link': 'https://arxiv.org/abs/2509.18765', 'abstract': 'Self-supervised learning (SSL) has emerged as a powerful paradigm for medical image representation learning, particularly in settings with limited labeled data. However, existing SSL methods often rely on complex architectures, anatomy-specific priors, or heavily tuned augmentations, which limit their scalability and generalizability. More critically, these models are prone to shortcut learning, especially in modalities like chest X-rays, where anatomical similarity is high and pathology is subtle. In this work, we introduce DiSSECT -- Discrete Self-Supervision for Efficient Clinical Transferable Representations, a framework that integrates multi-scale vector quantization into the SSL pipeline to impose a discrete representational bottleneck. This constrains the model to learn repeatable, structure-aware features while suppressing view-specific or low-utility patterns, improving representation transfer across tasks and domains. DiSSECT achieves strong performance on both classification and segmentation tasks, requiring minimal or no fine-tuning, and shows particularly high label efficiency in low-label regimes. We validate DiSSECT across multiple public medical imaging datasets, demonstrating its robustness and generalizability compared to existing state-of-the-art approaches.', 'abstract_zh': '自监督学习（SSL）已成为一种在有限标注数据环境下用于医学图像表示学习的强大范式。然而，现有的SSL方法往往依赖于复杂的架构、解剖特征特异性先验知识或高度调整的数据增强，这限制了它们的可扩展性和普适性。更关键的是，这些模型容易产生快捷学习，特别是在肺部X光片等解剖相似性高而病理表现微妙的模态中。在本文中，我们提出了DiSSECT——离散自监督学习以实现高效临床转移表示，该框架将多尺度向量量化集成到SSL管道中，以施加离散的表示瓶颈。这迫使模型学习可重复的、结构感知的特征，同时抑制视图特定的或低效的模式，从而在不同任务和领域中提高表示转移。DiSSECT在分类和分割任务上均表现出强大性能，需要极少或无需微调，并且在低标记数据条件下显示出特别高的标签效率。我们在多个公开的医学影像数据集上验证了DiSSECT，展示了其与现有最先进技术相比的鲁棒性和普适性。', 'title_zh': 'DiSSECT: 通过离散自我监督构建转移ready的医学图像表示'}
{'arxiv_id': 'arXiv:2509.18762', 'title': 'When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models', 'authors': 'Yingming Zheng, Hanqi Li, Kai Yu, Lu Chen', 'link': 'https://arxiv.org/abs/2509.18762', 'abstract': 'Large language models (LLMs) have achieved impressive performance across natural language processing (NLP) tasks. As real-world applications increasingly demand longer context windows, continued pretraining and supervised fine-tuning (SFT) on long-context data has become a common approach. While the effects of data length in continued pretraining have been extensively studied, their implications for SFT remain unclear. In this work, we systematically investigate how SFT data length influences LLM behavior on short-context tasks. Counterintuitively, we find that long-context SFT improves short-context performance, contrary to the commonly observed degradation from long-context pretraining. To uncover the underlying mechanisms of this phenomenon, we first decouple and analyze two key components, Multi-Head Attention (MHA) and Feed-Forward Network (FFN), and show that both independently benefit from long-context SFT. We further study their interaction and reveal a knowledge preference bias: long-context SFT promotes contextual knowledge, while short-context SFT favors parametric knowledge, making exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that hybrid training mitigates this bias, offering explainable guidance for fine-tuning LLMs.', 'abstract_zh': '大型语言模型（LLMs）在自然语言处理（NLP）任务中取得了令人印象深刻的表现。随着实际应用对更长上下文窗口的需求日益增加，对长上下文数据的持续预训练和监督微调（SFT）已经成为一种常见方法。尽管持续预训练中数据长度的影响已被广泛研究，但其对监督微调的影响仍不清楚。在本工作中，我们系统地探讨了监督微调数据长度如何影响LLM在短上下文任务中的行为。令人意外的是，我们发现长上下文微调能改善短上下文性能，这与从长上下文预训练中常见的性能下降现象相反。为了揭示这一现象背后的机制，我们首先将多头注意力（MHA）和前向网络（FFN）这两个关键组件分离并进行分析，表明两者均能从长上下文微调中受益。进一步地，我们研究了它们的相互作用，揭示了一种知识偏好偏差：长上下文微调促进基于上下文的知识，而短上下文微调偏向基于参数的知识，这使得单纯依赖长上下文微调是不理想的。最后，我们证明了混合训练能够缓解这种偏差，为微调LLM提供了可解释的指导。', 'title_zh': '长上下文帮助短文本：监督微调中的上下文长度对大型语言模型行为的影响'}
{'arxiv_id': 'arXiv:2509.18761', 'title': 'Security smells in infrastructure as code: a taxonomy update beyond the seven sins', 'authors': 'Aicha War, Serge L.B. Nikiema, Jordan Samhi, Jacques Klein, Tegawende F. Bissyande', 'link': 'https://arxiv.org/abs/2509.18761', 'abstract': 'Infrastructure as Code (IaC) has become essential for modern software management, yet security flaws in IaC scripts can have severe consequences, as exemplified by the recurring exploits of Cloud Web Services. Prior work has recognized the need to build a precise taxonomy of security smells in IaC scripts as a first step towards developing approaches to improve IaC security. This first effort led to the unveiling of seven sins, limited by the focus on a single IaC tool as well as by the extensive, and potentially biased, manual effort that was required. We propose, in our work, to revisit this taxonomy: first, we extend the study of IaC security smells to a more diverse dataset with scripts associated with seven popular IaC tools, including Terraform, Ansible, Chef, Puppet, Pulumi, Saltstack, and Vagrant; second, we bring in some automation for the analysis by relying on an LLM. While we leverage LLMs for initial pattern processing, all taxonomic decisions underwent systematic human validation and reconciliation with established security standards. Our study yields a comprehensive taxonomy of 62 security smell categories, significantly expanding beyond the previously known seven. We demonstrate actionability by implementing new security checking rules within linters for seven popular IaC tools, often achieving 1.00 precision score. Our evolution study of security smells in GitHub projects reveals that these issues persist for extended periods, likely due to inadequate detection and mitigation tools. This work provides IaC practitioners with insights for addressing common security smells and systematically adopting DevSecOps practices to build safer infrastructure code.', 'abstract_zh': 'Infrastructure as Code中的安全异味：一项全面的研究与自动化分析方法', 'title_zh': '基础设施即代码中的安全异味：超越七宗罪的分类学更新'}
{'arxiv_id': 'arXiv:2509.18758', 'title': 'Complexity of Activity Patterns in a Bio-Inspired Hopfield-Type Network in Different Topologies', 'authors': 'Marco Cafiso, Paolo Paradisi', 'link': 'https://arxiv.org/abs/2509.18758', 'abstract': 'Neural network models capable of storing memory have been extensively studied in computer science and computational neuroscience. The Hopfield network is a prototypical example of a model designed for associative, or content-addressable, memory and has been analyzed in many forms. Further, ideas and methods from complex network theory have been incorporated into artificial neural networks and learning, emphasizing their structural properties. Nevertheless, the temporal dynamics also play a vital role in biological neural networks, whose temporal structure is a crucial feature to examine. Biological neural networks display complex intermittency and, thus, can be studied through the lens of the temporal complexity (TC) theory. The TC approach look at the metastability of self-organized states, characterized by a power-law decay in the inter-event time distribution and in the total activity distribution or a scaling behavior in the corresponding event-driven diffusion processes. In this study, we present a temporal complexity (TC) analysis of a biologically-inspired Hopfield-type neural network model. We conducted a comparative assessment between scale-free and random network topologies, with particular emphasis on their global activation patterns. Our parametric analysis revealed comparable dynamical behaviors across both neural network architectures. Furthermore, our investigation into temporal complexity characteristics uncovered that seemingly distinct dynamical patterns exhibit similar temporal complexity behaviors. In particular, similar power-law decay in the activity distribution and similar complexity levels are observed in both topologies, but with a much reduced noise in the scale-free topology. Notably, most of the complex dynamical profiles were consistently observed in scale-free network configurations, thus confirming the crucial role of hubs in neural network dynamics.', 'abstract_zh': '生物启发的记忆型神经网络的时间复杂性分析', 'title_zh': '不同拓扑结构下生物启发式Hopfield型网络中活动模式的复杂性'}
{'arxiv_id': 'arXiv:2509.18757', 'title': 'MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning', 'authors': 'Omar Rayyan, John Abanes, Mahmoud Hafez, Anthony Tzes, Fares Abu-Dakka', 'link': 'https://arxiv.org/abs/2509.18757', 'abstract': 'Recent advances in imitation learning have shown great promise for developing robust robot manipulation policies from demonstrations. However, this promise is contingent on the availability of diverse, high-quality datasets, which are not only challenging and costly to collect but are often constrained to a specific robot embodiment. Portable handheld grippers have recently emerged as intuitive and scalable alternatives to traditional robotic teleoperation methods for data collection. However, their reliance solely on first-person view wrist-mounted cameras often creates limitations in capturing sufficient scene contexts. In this paper, we present MV-UMI (Multi-View Universal Manipulation Interface), a framework that integrates a third-person perspective with the egocentric camera to overcome this limitation. This integration mitigates domain shifts between human demonstration and robot deployment, preserving the cross-embodiment advantages of handheld data-collection devices. Our experimental results, including an ablation study, demonstrate that our MV-UMI framework improves performance in sub-tasks requiring broad scene understanding by approximately 47% across 3 tasks, confirming the effectiveness of our approach in expanding the range of feasible manipulation tasks that can be learned using handheld gripper systems, without compromising the cross-embodiment advantages inherent to such systems.', 'abstract_zh': '近期 imitation 学习的发展显示出巨大的潜力，用于从示范中开发鲁棒的机器人 manipulation 策略。然而，这一潜力取决于多样化的高质量数据集的可用性，这些数据集不仅收集困难且成本高昂，而且往往受限于特定的机器人实体。可携带的手held 夹持器最近作为传统的机器人遥操作方法的直观且可扩展的替代方案，用于数据采集。然而，它们仅依赖于手腕安装的_first-person_ 视角摄像头，常常限制了场景上下文的充分捕获。在本文中，我们提出了 MV-UMI（多视角通用 manipulation 接口）框架，该框架结合了第三视角与本体中心摄像头，以克服这一限制。这种结合减轻了人类示范与机器人部署之间的域转移，保留了可携带数据采集设备的跨实体优势。我们的实验结果，包括消融研究，证明我们的 MV-UMI 框架在要求广泛场景理解的子任务中性能提升了约 47%，在三个任务中证实了该方法的有效性，即通过手持夹持器系统可以学习更多可行的 manipulation 任务，同时不牺牲此类系统固有的跨实体优势。', 'title_zh': 'MV-UMI: 一种可扩展的多视图接口用于跨实体学习'}
{'arxiv_id': 'arXiv:2509.18754', 'title': 'COLT: Enhancing Video Large Language Models with Continual Tool Usage', 'authors': 'Yuyang Liu, Xinyuan Shi, Bang Yang, Peilin Zhou, Jiahua Dong, Long Chen, Ian Reid, Xiaondan Liang', 'link': 'https://arxiv.org/abs/2509.18754', 'abstract': "The success of Large Language Models (LLMs) has significantly propelled the research of video understanding. To harvest the benefits of well-trained expert models (i.e., tools), video LLMs prioritize the exploration of tool usage capabilities. Existing methods either prompt closed-source LLMs or employ the instruction tuning paradigm for tool-use fine-tuning. These methods, however, assume an established repository of fixed tools and struggle to generalize to real-world environments where tool data is perpetually evolving and streaming in. To this end, we propose to enhance open-source video LLMs with COntinuaL Tool usage (termed COLT), which automatically acquires tool-use ability in a successive tool stream without suffering 'catastrophic forgetting' of the past learned tools. Specifically, our COLT incorporates a learnable tool codebook as a tool-specific memory system. Then relevant tools are dynamically selected based on the similarity between user instruction and tool features within the codebook. To unleash the tool usage potential of video LLMs, we collect a video-centric tool-use instruction tuning dataset VideoToolBench. Extensive experiments on both previous video LLM benchmarks and the tool-use-specific VideoToolBench dataset demonstrate the state-of-the-art performance of our proposed COLT.", 'abstract_zh': '开源视频大型语言模型的COntinuaL Tool 使用增强研究：COLT方法', 'title_zh': 'COLT: 通过持续工具使用增强视频大型语言模型'}
{'arxiv_id': 'arXiv:2509.18714', 'title': 'A Generalized Bisimulation Metric of State Similarity between Markov Decision Processes: From Theoretical Propositions to Applications', 'authors': 'Zhenyu Tao, Wei Xu, Xiaohu You', 'link': 'https://arxiv.org/abs/2509.18714', 'abstract': 'The bisimulation metric (BSM) is a powerful tool for computing state similarities within a Markov decision process (MDP), revealing that states closer in BSM have more similar optimal value functions. While BSM has been successfully utilized in reinforcement learning (RL) for tasks like state representation learning and policy exploration, its application to multiple-MDP scenarios, such as policy transfer, remains challenging. Prior work has attempted to generalize BSM to pairs of MDPs, but a lack of rigorous analysis of its mathematical properties has limited further theoretical progress. In this work, we formally establish a generalized bisimulation metric (GBSM) between pairs of MDPs, which is rigorously proven with the three fundamental properties: GBSM symmetry, inter-MDP triangle inequality, and the distance bound on identical state spaces. Leveraging these properties, we theoretically analyse policy transfer, state aggregation, and sampling-based estimation in MDPs, obtaining explicit bounds that are strictly tighter than those derived from the standard BSM. Additionally, GBSM provides a closed-form sample complexity for estimation, improving upon existing asymptotic results based on BSM. Numerical results validate our theoretical findings and demonstrate the effectiveness of GBSM in multi-MDP scenarios.', 'abstract_zh': '广义 bisimulation 距离（GBSM）在马尔可夫决策过程对之间的正式确立及其在多MDP场景中的应用分析', 'title_zh': 'Markov决策过程间状态相似性的广义拟似度度量：从理论命题到应用'}
{'arxiv_id': 'arXiv:2509.18713', 'title': 'MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service', 'authors': 'Yizhe Huang, Yang Liu, Ruiyu Zhao, Xiaolong Zhong, Xingming Yue, Ling Jiang', 'link': 'https://arxiv.org/abs/2509.18713', 'abstract': 'Large Language Model-based agents(LLM-based agents) are increasingly deployed in customer service, yet they often forget across sessions, repeat errors, and lack mechanisms for continual self-improvement. This makes them unreliable in dynamic settings where stability and consistency are critical. To better evaluate these properties, we emphasize two indicators: task success rate as a measure of overall effectiveness, and consistency metrics such as Pass$^k$ to capture reliability across multiple trials. To address the limitations of existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal reinforcement memory layer that distills multi-turn interactions into compact strategy reflections. These reflections are stored in a shared memory bank and retrieved to guide decision-making, without requiring any fine-tuning. Experiments show that MemOrb significantly improves both success rate and stability, achieving up to a 63 percentage-point gain in multi-turn success rate and delivering more consistent performance across repeated trials. Our results demonstrate that structured reflection is a powerful mechanism for enhancing long-term reliability of frozen LLM agents in customer service scenarios.', 'abstract_zh': '基于大型语言模型的代理（LLM-based代理）在客户服务中日益普及，但它们往往会在会话之间忘记信息、重复错误，并缺乏持续自我改进的机制。这使得它们在对稳定性和一致性要求高的动态环境中不够可靠。为了更好地评估这些特性，我们强调了两个指标：任务成功率作为整体有效性的衡量标准，以及如Pass$^k$等一致性指标以捕捉多次试验中的可靠性。为了解决现有方法的局限性，我们提出了一种轻量级且即插即用的语言强化记忆层MemOrb，它可以将多轮交互精炼为紧凑的战略反思。这些反思被存储在共享记忆库中，并在决策过程中检索使用，无需任何微调。实验结果显示，MemOrb显著提高了成功率和稳定性，多轮成功率达到63个百分点的增长，并在重复试验中提供了更一致的性能表现。我们的研究结果表明，结构化的反思是一种增强冷冻LLM代理在客户服务场景中长期可靠性的强大机制。', 'title_zh': 'MemOrb: 一键插拔基于语言强化的记忆层以提升电子商务客户服务'}
{'arxiv_id': 'arXiv:2509.18711', 'title': 'RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images', 'authors': 'Ke Li, Di Wang, Ting Wang, Fuyu Dong, Yiming Zhang, Luyao Zhang, Xiangyu Wang, Shaofeng Li, Quan Wang', 'link': 'https://arxiv.org/abs/2509.18711', 'abstract': 'Remote sensing visual grounding (RSVG) aims to localize objects in remote sensing images based on free-form natural language expressions. Existing approaches are typically constrained to closed-set vocabularies, limiting their applicability in open-world scenarios. While recent attempts to leverage generic foundation models for open-vocabulary RSVG, they overly rely on expensive high-quality datasets and time-consuming fine-tuning. To address these limitations, we propose \\textbf{RSVG-ZeroOV}, a training-free framework that aims to explore the potential of frozen generic foundation models for zero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key stages: (i) Overview: We utilize a vision-language model (VLM) to obtain cross-attention\\footnote[1]{In this paper, although decoder-only VLMs use self-attention over all tokens, we refer to the image-text interaction part as cross-attention to distinguish it from pure visual self-attention.}maps that capture semantic correlations between text queries and visual regions. (ii) Focus: By leveraging the fine-grained modeling priors of a diffusion model (DM), we fill in gaps in structural and shape information of objects, which are often overlooked by VLM. (iii) Evolve: A simple yet effective attention evolution module is introduced to suppress irrelevant activations, yielding purified segmentation masks over the referred objects. Without cumbersome task-specific training, RSVG-ZeroOV offers an efficient and scalable solution. Extensive experiments demonstrate that the proposed framework consistently outperforms existing weakly-supervised and zero-shot methods.', 'abstract_zh': 'Remote sensing视觉 grounding (RSVG)旨在基于自由形式的自然语言表达在遥感图像中定位物体。现有方法通常受限于封闭集词汇表，限制了其在开放世界场景中的应用。虽然最近尝试利用通用基础模型来解决开放词汇表的RSVG问题，但它们过度依赖昂贵的高质量数据集和耗时的微调。为解决这些限制，我们提出了RSVG-ZeroOV——一种无需训练的框架，旨在探索冻结的通用基础模型在零样本开放词汇表RSVG中的潜力。具体而言，RSVG-ZeroOV包括三个关键阶段：（i）概要：我们利用视觉语言模型（VLM）获得包含文本查询与视觉区域之间语义关联的交叉注意图。（ii）聚焦：通过利用扩散模型（DM）的精细结构先验，填补视觉对象在结构和形状信息上的不足，这些不足常被VLM忽视。（iii）演化：引入一种简单而有效的注意演化模块抑制无关激活，生成更纯净的目标分割掩码。无需繁琐的任务特定训练，RSVG-ZeroOV提供了高效且可扩展的解决方案。大量实验表明，提出的框架在零样本和弱监督方法中表现始终优于现有方法。', 'title_zh': 'RSVG-ZeroOV: 探索无需训练框架的零样本开放词汇视觉接地在遥感图像中的应用'}
{'arxiv_id': 'arXiv:2509.18691', 'title': 'An overview of neural architectures for self-supervised audio representation learning from masked spectrograms', 'authors': 'Sarthak Yadav, Sergios Theodoridis, Zheng-Hua Tan', 'link': 'https://arxiv.org/abs/2509.18691', 'abstract': 'In recent years, self-supervised learning has amassed significant interest for training deep neural representations without labeled data. One such self-supervised learning approach is masked spectrogram modeling, where the objective is to learn semantically rich contextual representations by predicting removed or hidden portions of the input audio spectrogram. With the Transformer neural architecture at its core, masked spectrogram modeling has emerged as the prominent approach for learning general purpose audio representations, a.k.a. audio foundation models. Meanwhile, addressing the issues of the Transformer architecture, in particular the underlying Scaled Dot-product Attention operation, which scales quadratically with input sequence length, has led to renewed interest in recurrent sequence modeling approaches. Among them, Selective structured state space models (such as Mamba) and extended Long Short-Term Memory (xLSTM) are the two most promising approaches which have experienced widespread adoption. While the body of work on these two topics continues to grow, there is currently a lack of an adequate overview encompassing the intersection of these topics. In this paper, we present a comprehensive overview of the aforementioned research domains, covering masked spectrogram modeling and the previously mentioned neural sequence modeling architectures, Mamba and xLSTM. Further, we compare Transformers, Mamba and xLSTM based masked spectrogram models in a unified, reproducible framework on ten diverse downstream audio classification tasks, which will help interested readers to make informed decisions regarding suitability of the evaluated approaches to adjacent applications.', 'abstract_zh': '近年来，自监督学习因其无需标注数据即可训练深度神经表示而引起了广泛关注。一类这样的自监督学习方法是掩码声谱图建模，其目标是通过预测输入音频声谱图中移除或隐藏的部分来学习语义丰富的上下文表示。以Transformer神经架构为核心，掩码声谱图建模已成为学习通用音频表示，即音频基础模型的主要方法。与此同时，针对Transformer架构本身存在的问题，特别是其底层的标度点积注意操作，该操作随输入序列长度二次增长，导致了对循环序列建模方法的兴趣重燃。在这之中，选择性结构化状态空间模型（如Mamba）和扩展长短期记忆（xLSTM）是两个最具前景的方法，并且已经被广泛采用。尽管这两个领域的研究工作不断增长，但由于缺乏对其交集的全面概述，目前仍存在不足。本文提供了一个全面的概述，涵盖了上述研究领域，包括掩码声谱图建模以及之前提到的神经序列建模架构Mamba和xLSTM。此外，我们在统一且可复制的框架下对基于Transformer、Mamba和xLSTM的掩码声谱图模型进行了比较，这些模型在十项不同的下游音频分类任务上进行了评估，这将帮助感兴趣的读者为相关应用选择合适的评估方法。', 'title_zh': '自掩蔽声谱图导向的自我监督音频表示学习的神经架构综述'}
{'arxiv_id': 'arXiv:2509.18683', 'title': 'LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection', 'authors': 'Lanhu Wu, Zilin Gao, Hao Fei, Mong-Li Lee, Wynne Hsu', 'link': 'https://arxiv.org/abs/2509.18683', 'abstract': 'RGB-D salient object detection (SOD) aims to identify the most conspicuous objects in a scene with the incorporation of depth cues. Existing methods mainly rely on CNNs, limited by the local receptive fields, or Vision Transformers that suffer from the cost of quadratic complexity, posing a challenge in balancing performance and computational efficiency. Recently, state space models (SSM), Mamba, have shown great potential for modeling long-range dependency with linear complexity. However, directly applying SSM to RGB-D SOD may lead to deficient local semantics as well as the inadequate cross-modality fusion. To address these issues, we propose a Local Emphatic and Adaptive Fusion state space model (LEAF-Mamba) that contains two novel components: 1) a local emphatic state space module (LE-SSM) to capture multi-scale local dependencies for both modalities. 2) an SSM-based adaptive fusion module (AFM) for complementary cross-modality interaction and reliable cross-modality integration. Extensive experiments demonstrate that the LEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in both efficacy and efficiency. Moreover, our method can achieve excellent performance on the RGB-T SOD task, proving a powerful generalization ability.', 'abstract_zh': 'RGB-D显著目标检测（SOD）旨在利用深度线索识别场景中的最突出对象。现有的方法主要依赖CNNs，受局部感受野的限制，或依赖Vision Transformers但带来计算复杂度的二次增加，这在性能和计算效率之间提出了挑战。最近，状态空间模型（SSM）Mamba在以线性复杂度建模长程依赖方面显示出巨大潜力。然而，直接将SSM应用于RGB-D SOD可能导致局部语义不足以及跨模态融合不足。为解决这些问题，我们提出了一种包含两个新颖组件的局部强化和自适应融合状态空间模型（LEAF-Mamba）：1）一种局部强化状态空间模块（LE-SSM），用于捕捉两种模态的多尺度局部依赖性；2）一种基于SSM的自适应融合模块（AFM），用于互补的跨模态交互和可靠的跨模态集成。大量实验表明，LEAF-Mamba在效能和效率上均优于16种最先进的RGB-D SOD方法。此外，我们的方法在RGB-T SOD任务中也能实现出色的表现，证明了强大的泛化能力。', 'title_zh': 'LEAF-Mamba：局部强化和自适应融合状态空间模型在RGB-D显著目标检测中的应用'}
{'arxiv_id': 'arXiv:2509.18672', 'title': 'NaviSense: A Multimodal Assistive Mobile application for Object Retrieval by Persons with Visual Impairment', 'authors': 'Ajay Narayanan Sridhar, Fuli Qiao, Nelson Daniel Troncoso Aldas, Yanpei Shi, Mehrdad Mahdavi, Laurent Itti, Vijaykrishnan Narayanan', 'link': 'https://arxiv.org/abs/2509.18672', 'abstract': "People with visual impairments often face significant challenges in locating and retrieving objects in their surroundings. Existing assistive technologies present a trade-off: systems that offer precise guidance typically require pre-scanning or support only fixed object categories, while those with open-world object recognition lack spatial feedback for reaching the object. To address this gap, we introduce 'NaviSense', a mobile assistive system that combines conversational AI, vision-language models, augmented reality (AR), and LiDAR to support open-world object detection with real-time audio-haptic guidance. Users specify objects via natural language and receive continuous spatial feedback to navigate toward the target without needing prior setup. Designed with insights from a formative study and evaluated with 12 blind and low-vision participants, NaviSense significantly reduced object retrieval time and was preferred over existing tools, demonstrating the value of integrating open-world perception with precise, accessible guidance.", 'abstract_zh': '视觉受损人士在识别和获取周围环境中的物体时常常面临显著挑战。现有的辅助技术存在权衡：提供精确导航的系统通常需要预先扫描或仅支持固定类别的物体识别，而具有开放世界物体识别能力的系统缺乏空间反馈功能，用户难以找到目标物体。为解决这一问题，我们引入了“NaviSense”移动辅助系统，该系统结合了对话式AI、视觉语言模型、增强现实（AR）和LiDAR技术，支持实时语音-触觉导航指导下的开放世界物体检测。用户可以通过自然语言指定物体，并接收连续的空间反馈，无需前期设置即可导航至目标物体。NaviSense 通过初步研究的见解设计，并经12名盲人和视力受损人士评估，显示出整合开放世界感知与精确、可访问导航的优点，显著减少了物体检索时间，并优于现有工具。', 'title_zh': 'NaviSense：用于视觉障碍人士对象检索的多模态辅助移动应用'}
{'arxiv_id': 'arXiv:2509.18648', 'title': 'SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer', 'authors': 'Yarden As, Chengrui Qu, Benjamin Unger, Dongho Kang, Max van der Hart, Laixi Shi, Stelian Coros, Adam Wierman, Andreas Krause', 'link': 'https://arxiv.org/abs/2509.18648', 'abstract': 'Safety remains a major concern for deploying reinforcement learning (RL) in real-world applications. Simulators provide safe, scalable training environments, but the inevitable sim-to-real gap introduces additional safety concerns, as policies must satisfy constraints in real-world conditions that differ from simulation. To address this challenge, robust safe RL techniques offer principled methods, but are often incompatible with standard scalable training pipelines. In contrast, domain randomization, a simple and popular sim-to-real technique, stands out as a promising alternative, although it often results in unsafe behaviors in practice. We present SPiDR, short for Sim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with provable guarantees for safe sim-to-real transfer. SPiDR uses domain randomization to incorporate the uncertainty about the sim-to-real gap into the safety constraints, making it versatile and highly compatible with existing training pipelines. Through extensive experiments on sim-to-sim benchmarks and two distinct real-world robotic platforms, we demonstrate that SPiDR effectively ensures safety despite the sim-to-real gap while maintaining strong performance.', 'abstract_zh': '基于悲观域随机化的可扩展安全模拟到现实转移方法(SPiDR)', 'title_zh': 'SPiDR:一种简单的零样本安全迁移方法'}
{'arxiv_id': 'arXiv:2509.18644', 'title': 'Do You Need Proprioceptive States in Visuomotor Policies?', 'authors': 'Juntu Zhao, Wenbo Lu, Di Zhang, Yufeng Liu, Yushen Liang, Tianluo Zhang, Yifeng Cao, Junyuan Xie, Yingdong Hu, Shengjie Wang, Junliang Guo, Dequan Wang, Yang Gao', 'link': 'https://arxiv.org/abs/2509.18644', 'abstract': 'Imitation-learning-based visuomotor policies have been widely used in robot manipulation, where both visual observations and proprioceptive states are typically adopted together for precise control. However, in this study, we find that this common practice makes the policy overly reliant on the proprioceptive state input, which causes overfitting to the training trajectories and results in poor spatial generalization. On the contrary, we propose the State-free Policy, removing the proprioceptive state input and predicting actions only conditioned on visual observations. The State-free Policy is built in the relative end-effector action space, and should ensure the full task-relevant visual observations, here provided by dual wide-angle wrist cameras. Empirical results demonstrate that the State-free policy achieves significantly stronger spatial generalization than the state-based policy: in real-world tasks such as pick-and-place, challenging shirt-folding, and complex whole-body manipulation, spanning multiple robot embodiments, the average success rate improves from 0\\% to 85\\% in height generalization and from 6\\% to 64\\% in horizontal generalization. Furthermore, they also show advantages in data efficiency and cross-embodiment adaptation, enhancing their practicality for real-world deployment.', 'abstract_zh': '基于模仿学习的视觉运动策略通常在机器人操作中使用，其中视觉观察和本体感觉状态通常联合使用以实现精确控制。然而，在本研究中，我们发现这一常见做法使策略过度依赖本体感觉状态输入，导致对训练轨迹过拟合并导致空间泛化能力较差。与此相反，我们提出了无状态策略，去除了本体感觉状态输入，并仅根据视觉观察预测动作。无状态策略构建在相对于末端执行器的动作空间中，并应确保全面的相关视觉观察，这里由双广角手腕摄像头提供。实验结果表明，无状态策略在空间泛化方面显著优于基于状态的策略：在包括抓取放置、复杂衣物折叠和多机器人本体的整体身体操作等真实世界任务中，高度泛化成功率从0%提高到85%，水平泛化成功率从6%提高到64%。此外，它们还展示了高效的数据利用和跨本体适应性优势，增强了其实用性，适用于真实世界的部署。', 'title_zh': '你在视觉运动策略中需要本体感觉状态吗？'}
{'arxiv_id': 'arXiv:2509.18638', 'title': 'Learning neuroimaging models from health system-scale data', 'authors': 'Yiwei Lyu, Samir Harake, Asadur Chowdury, Soumyanil Banerjee, Rachel Gologorsky, Shixuan Liu, Anna-Katharina Meissner, Akshay Rao, Chenhui Zhao, Akhil Kondepudi, Cheng Jiang, Xinhai Hou, Rushikesh S. Joshi, Volker Neuschmelting, Ashok Srinivasan, Dawn Kleindorfer, Brian Athey, Vikas Gulani, Aditya Pandey, Honglak Lee, Todd Hollon', 'link': 'https://arxiv.org/abs/2509.18638', 'abstract': "Neuroimaging is a ubiquitous tool for evaluating patients with neurological diseases. The global demand for magnetic resonance imaging (MRI) studies has risen steadily, placing significant strain on health systems, prolonging turnaround times, and intensifying physician burnout \\cite{Chen2017-bt, Rula2024-qp-1}. These challenges disproportionately impact patients in low-resource and rural settings. Here, we utilized a large academic health system as a data engine to develop Prima, the first vision language model (VLM) serving as an AI foundation for neuroimaging that supports real-world, clinical MRI studies as input. Trained on over 220,000 MRI studies, Prima uses a hierarchical vision architecture that provides general and transferable MRI features. Prima was tested in a 1-year health system-wide study that included 30K MRI studies. Across 52 radiologic diagnoses from the major neurologic disorders, including neoplastic, inflammatory, infectious, and developmental lesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0, outperforming other state-of-the-art general and medical AI models. Prima offers explainable differential diagnoses, worklist priority for radiologists, and clinical referral recommendations across diverse patient demographics and MRI systems. Prima demonstrates algorithmic fairness across sensitive groups and can help mitigate health system biases, such as prolonged turnaround times for low-resource populations. These findings highlight the transformative potential of health system-scale VLMs and Prima's role in advancing AI-driven healthcare.", 'abstract_zh': '神经成像是评估神经系统疾病患者的一项普遍工具。全球磁共振成像（MRI）研究的需求持续上升，给健康系统带来了巨大压力，延长了 turnaround 时间，并加剧了医生的职业倦怠 \\cite{Chen2017-bt, Rula2024-qp-1}。这些挑战在低资源和农村地区尤为突出。在此基础上，我们利用一个大型学术医疗系统作为数据引擎，开发了 Prima，这是第一个作为神经成像 AI 基础的视觉语言模型（VLM），支持现实世界和临床 MRI 研究作为输入。Prima 基于超过 220,000 项 MRI 研究进行训练，采用分层视觉架构，提供通用和可转移的 MRI 特征。Prima 在为期一年的全系统研究中进行了测试，该研究包括 30,000 项 MRI 研究。在包括肿瘤性疾病、炎症性疾病、感染性疾病和发育性病变在内的 52 种主要神经系统疾病的放射学诊断中，Prima 达到了 92.0 的平均诊断 ROC 曲线下面积，优于其他最先进的通用和医学 AI 模型。Prima 提供可解释的鉴别诊断、放射科医生的工作列表优先级，以及针对不同患者群体和 MRI 系统的临床转诊推荐。Prima 在不同敏感群体中展示了算法公平性，并有助于减轻健康系统偏见，例如低资源人群的长时间周转。这些发现突显了健康系统规模的视觉语言模型的变革潜力，以及 Prima 在推动 AI 驱动的医疗服务中的作用。', 'title_zh': '从健康系统规模的数据中学习神经影像模型'}
{'arxiv_id': 'arXiv:2509.18631', 'title': 'Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training', 'authors': 'Shuo Cheng, Liqian Ma, Zhenyang Chen, Ajay Mandlekar, Caelan Garrett, Danfei Xu', 'link': 'https://arxiv.org/abs/2509.18631', 'abstract': 'Behavior cloning has shown promise for robot manipulation, but real-world demonstrations are costly to acquire at scale. While simulated data offers a scalable alternative, particularly with advances in automated demonstration generation, transferring policies to the real world is hampered by various simulation and real domain gaps. In this work, we propose a unified sim-and-real co-training framework for learning generalizable manipulation policies that primarily leverages simulation and only requires a few real-world demonstrations. Central to our approach is learning a domain-invariant, task-relevant feature space. Our key insight is that aligning the joint distributions of observations and their corresponding actions across domains provides a richer signal than aligning observations (marginals) alone. We achieve this by embedding an Optimal Transport (OT)-inspired loss within the co-training framework, and extend this to an Unbalanced OT framework to handle the imbalance between abundant simulation data and limited real-world examples. We validate our method on challenging manipulation tasks, showing it can leverage abundant simulation data to achieve up to a 30% improvement in the real-world success rate and even generalize to scenarios seen only in simulation.', 'abstract_zh': '基于仿真实例和现实世界的统一共同训练框架学习通用化 manipulation 策略', 'title_zh': '模拟与现实环境政策共训练的可泛化领域自适应方法'}
{'arxiv_id': 'arXiv:2509.18629', 'title': 'HyperAdapt: Simple High-Rank Adaptation', 'authors': 'Abel Gurung, Joseph Campbell', 'link': 'https://arxiv.org/abs/2509.18629', 'abstract': "Foundation models excel across diverse tasks, but adapting them to specialized applications often requires fine-tuning, an approach that is memory and compute-intensive. Parameter-efficient fine-tuning (PEFT) methods mitigate this by updating only a small subset of weights. In this paper, we introduce HyperAdapt, a parameter-efficient fine-tuning method that significantly reduces the number of trainable parameters compared to state-of-the-art methods like LoRA. Specifically, HyperAdapt adapts a pre-trained weight matrix by applying row- and column-wise scaling through diagonal matrices, thereby inducing a high-rank update while requiring only $n+m$ trainable parameters for an $n \\times m$ matrix. Theoretically, we establish an upper bound on the rank of HyperAdapt's updates, and empirically, we confirm that it consistently induces high-rank transformations across model layers. Experiments on GLUE, arithmetic reasoning, and commonsense reasoning benchmarks with models up to 14B parameters demonstrate that HyperAdapt matches or nearly matches the performance of full fine-tuning and state-of-the-art PEFT methods while using orders of magnitude fewer trainable parameters.", 'abstract_zh': 'HyperAdapt：一种高效的参数调优方法', 'title_zh': '超适应: 简单的高秩适应'}
{'arxiv_id': 'arXiv:2509.18627', 'title': 'BRAID: Input-Driven Nonlinear Dynamical Modeling of Neural-Behavioral Data', 'authors': 'Parsa Vahidi, Omid G. Sani, Maryam M. Shanechi', 'link': 'https://arxiv.org/abs/2509.18627', 'abstract': 'Neural populations exhibit complex recurrent structures that drive behavior, while continuously receiving and integrating external inputs from sensory stimuli, upstream regions, and neurostimulation. However, neural populations are often modeled as autonomous dynamical systems, with little consideration given to the influence of external inputs that shape the population activity and behavioral outcomes. Here, we introduce BRAID, a deep learning framework that models nonlinear neural dynamics underlying behavior while explicitly incorporating any measured external inputs. Our method disentangles intrinsic recurrent neural population dynamics from the effects of inputs by including a forecasting objective within input-driven recurrent neural networks. BRAID further prioritizes the learning of intrinsic dynamics that are related to a behavior of interest by using a multi-stage optimization scheme. We validate BRAID with nonlinear simulations, showing that it can accurately learn the intrinsic dynamics shared between neural and behavioral modalities. We then apply BRAID to motor cortical activity recorded during a motor task and demonstrate that our method more accurately fits the neural-behavioral data by incorporating measured sensory stimuli into the model and improves the forecasting of neural-behavioral data compared with various baseline methods, whether input-driven or not.', 'abstract_zh': '神经群体表现出复杂的环路结构，驱动行为，同时持续接收和整合来自感觉刺激、上游区域和神经刺激的外部输入。然而，神经群体通常被建模为自治动力系统，对外部输入如何塑造群体活动和行为结果的影响考虑不足。在这里，我们引入了BRAID，这是一种深度学习框架，能够在明确纳入任何测量外部输入的同时，建模行为背后的非线性神经动力学。我们的方法通过在输入驱动的递归神经网络中纳入预测目标，将内在的神经群体动力学与输入效应分离。BRAID进一步通过多阶段优化方案优先学习与目标任务相关的内在动力学。我们通过非线性模拟验证了BRAID，显示它能够准确学习神经和行为模态之间的内在动力学。随后，我们将BRAID应用于记录在运动任务中的运动皮层活动，并通过将测量的感觉刺激纳入模型中，证明了我们的方法更准确地拟合了神经-行为数据，并在各种基线方法（无论是输入驱动的还是非输入驱动的）中提高了神经-行为数据的预测能力。', 'title_zh': 'BRAID: 输入驱动的非线性动力学神经-行为数据建模'}
{'arxiv_id': 'arXiv:2509.18626', 'title': 'The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving', 'authors': 'Jay Patrikar, Apoorva Sharma, Sushant Veer, Boyi Li, Sebastian Scherer, Marco Pavone', 'link': 'https://arxiv.org/abs/2509.18626', 'abstract': 'Learning-based autonomous driving systems are trained mostly on incident-free data, offering little guidance near safety-performance boundaries. Real crash reports contain precisely the contrastive evidence needed, but they are hard to use: narratives are unstructured, third-person, and poorly grounded to sensor views. We address these challenges by normalizing crash narratives to ego-centric language and converting both logs and crashes into a unified scene-action representation suitable for retrieval. At decision time, our system adjudicates proposed actions by retrieving relevant precedents from this unified index; an agentic counterfactual extension proposes plausible alternatives, retrieves for each, and reasons across outcomes before deciding. On a nuScenes benchmark, precedent retrieval substantially improves calibration, with recall on contextually preferred actions rising from 24% to 53%. The counterfactual variant preserves these gains while sharpening decisions near risk.', 'abstract_zh': '基于学习的自动驾驶系统主要在无事故数据上进行训练，提供的安全性性能边界上的指导有限。真实的事故报告包含了必要的对比性证据，但难以使用：这些报告的叙事内容结构不一、第三方视角且与传感器视角关联性差。我们通过将事故叙述规范化为以自我为中心的语言，并将日志和事故统一转换为适合检索的场景-行动表示来应对这些挑战。在决策时刻，系统通过检索这个统一索引中的相关先例来裁定提出的行动；具有代理性的反事实扩展提出可能的替代方案，分别检索并跨结果进行推理后再做决定。在nuScenes基准测试中，先例检索显著提高了校准度，上下文偏好行动的召回率从24%提高到53%。反事实变体保留了这些改进，同时在高风险区域增强了决策的精确度。', 'title_zh': '负数据的案情：从故障报告到合理的驾驶反事实推理'}
{'arxiv_id': 'arXiv:2509.18611', 'title': 'Flow marching for a generative PDE foundation model', 'authors': 'Zituo Chen, Sili Deng', 'link': 'https://arxiv.org/abs/2509.18611', 'abstract': 'Pretraining on large-scale collections of PDE-governed spatiotemporal trajectories has recently shown promise for building generalizable models of dynamical systems. Yet most existing PDE foundation models rely on deterministic Transformer architectures, which lack generative flexibility for many science and engineering applications. We propose Flow Marching, an algorithm that bridges neural operator learning with flow matching motivated by an analysis of error accumulation in physical dynamical systems, and we build a generative PDE foundation model on top of it. By jointly sampling the noise level and the physical time step between adjacent states, the model learns a unified velocity field that transports a noisy current state toward its clean successor, reducing long-term rollout drift while enabling uncertainty-aware ensemble generations. Alongside this core algorithm, we introduce a Physics-Pretrained Variational Autoencoder (P2VAE) to embed physical states into a compact latent space, and an efficient Flow Marching Transformer (FMT) that combines a diffusion-forcing scheme with latent temporal pyramids, achieving up to 15x greater computational efficiency than full-length video diffusion models and thereby enabling large-scale pretraining at substantially reduced cost. We curate a corpus of ~2.5M trajectories across 12 distinct PDE families and train suites of P2VAEs and FMTs at multiple scales. On downstream evaluation, we benchmark on unseen Kolmogorov turbulence with few-shot adaptation, demonstrate long-term rollout stability over deterministic counterparts, and present uncertainty-stratified ensemble results, highlighting the importance of generative PDE foundation models for real-world applications.', 'abstract_zh': '大规模偏微分方程调控时空轨迹的预训练最近展示了构建动力系统通用模型的潜力。然而，现有的大多数偏微分方程基础模型依赖于确定性的Transformer架构，缺乏许多科学和工程应用中的生成灵活性。我们提出了Flow Marching算法，该算法借鉴了对物理动力系统中误差累积分析，将神经运算学习与流匹配相结合，并在其基础上构建了一个生成性的偏微分方程基础模型。通过联合采样噪声水平和相邻状态的物理时间步长，模型学习到一个统一的速度场，将嘈杂的当前状态转移至其干净的后继状态，从而减少长期滚动部署中的漂移，同时允许不确定性感知的集成生成。除了核心算法外，我们还引入了物理预训练变分自编码器（P2VAE）将物理状态嵌入到紧凑的潜在空间，并且提出了一种高效流行进Transformer（FMT），它结合了扩散驱动方案和潜在时域金字塔，相比全长视频扩散模型，其计算效率可提高多达15倍，从而能够以显著减少的成本进行大规模预训练。我们编 curated 了一个包含约2.5M条轨迹的语料库，横跨12个不同的偏微分方程家族，并在多个尺度上训练了一系列P2VAE和FMT。在下游评估中，我们在未见过的柯尔莫哥洛夫湍流上进行基准测试，展现出长时间滚动部署的稳定性超过了确定性模型，并展示了分层不确定性集成结果，突显了生成性偏微分方程基础模型对于实际应用的重要性。', 'title_zh': '流行进方法构建生成型偏微分方程基础模型'}
{'arxiv_id': 'arXiv:2509.18608', 'title': 'End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning', 'authors': 'Ana Luiza Mineiro, Francisco Affonso, Marcelo Becker', 'link': 'https://arxiv.org/abs/2509.18608', 'abstract': 'Reliable navigation in under-canopy agricultural environments remains a challenge due to GNSS unreliability, cluttered rows, and variable lighting. To address these limitations, we present an end-to-end learning-based navigation system that maps raw 3D LiDAR data directly to control commands using a deep reinforcement learning policy trained entirely in simulation. Our method includes a voxel-based downsampling strategy that reduces LiDAR input size by 95.83%, enabling efficient policy learning without relying on labeled datasets or manually designed control interfaces. The policy was validated in simulation, achieving a 100% success rate in straight-row plantations and showing a gradual decline in performance as row curvature increased, tested across varying sinusoidal frequencies and amplitudes.', 'abstract_zh': '基于深度强化学习的端到端LiDAR数据导航系统：在林下农业环境中的可靠导航', 'title_zh': '基于LiDAR的深度强化学习端到端农作物行导航'}
{'arxiv_id': 'arXiv:2509.18606', 'title': 'FlexSED: Towards Open-Vocabulary Sound Event Detection', 'authors': 'Jiarui Hai, Helin Wang, Weizhe Guo, Mounya Elhilali', 'link': 'https://arxiv.org/abs/2509.18606', 'abstract': 'Despite recent progress in large-scale sound event detection (SED) systems capable of handling hundreds of sound classes, existing multi-class classification frameworks remain fundamentally limited. They cannot process free-text sound queries, which enable more flexible and user-friendly interaction, and they lack zero-shot capabilities and offer poor few-shot adaptability. Although text-query-based separation methods have been explored, they primarily focus on source separation and are ill-suited for SED tasks that require precise temporal localization and efficient detection across large and diverse sound vocabularies. In this paper, we propose FlexSED, an open-vocabulary sound event detection system. FlexSED builds on a pretrained audio SSL model and the CLAP text encoder, introducing an encoder-decoder composition and an adaptive fusion strategy to enable effective continuous training from pretrained weights. To ensure robust supervision, it also employs large language models (LLMs) to assist in event query selection during training, addressing challenges related to missing labels. As a result, FlexSED achieves superior performance compared to vanilla SED models on AudioSet-Strong, while demonstrating strong zero-shot and few-shot capabilities. We release the code and pretrained models to support future research and applications based on FlexSED.', 'abstract_zh': '一种开放词汇的声事件检测系统：FlexSED', 'title_zh': 'FlexSED: 向着开放词汇集声音事件检测'}
{'arxiv_id': 'arXiv:2509.18603', 'title': 'SynSonic: Augmenting Sound Event Detection through Text-to-Audio Diffusion ControlNet and Effective Sample Filtering', 'authors': 'Jiarui Hai, Mounya Elhilali', 'link': 'https://arxiv.org/abs/2509.18603', 'abstract': 'Data synthesis and augmentation are essential for Sound Event Detection (SED) due to the scarcity of temporally labeled data. While augmentation methods like SpecAugment and Mix-up can enhance model performance, they remain constrained by the diversity of existing samples. Recent generative models offer new opportunities, yet their direct application to SED is challenging due to the lack of precise temporal annotations and the risk of introducing noise through unreliable filtering. To address these challenges and enable generative-based augmentation for SED, we propose SynSonic, a data augmentation method tailored for this task. SynSonic leverages text-to-audio diffusion models guided by an energy-envelope ControlNet to generate temporally coherent sound events. A joint score filtering strategy with dual classifiers ensures sample quality, and we explore its practical integration into training pipelines. Experimental results show that SynSonic improves Polyphonic Sound Detection Scores (PSDS1 and PSDS2), enhancing both temporal localization and sound class discrimination.', 'abstract_zh': '数据合成与扩增对于声事件检测（SED）至关重要，由于缺乏时间标签数据。虽然SpecAugment和Mix-up等扩增方法可以提升模型性能，但它们仍然受限于现有样本的多样性。最近的生成模型提供了新的机会，但由于缺乏精确的时间标注和通过不可靠的滤波引入噪声的风险，它们直接应用于SED具有挑战性。为了解决这些挑战并使基于生成的扩增适用于SED，我们提出SynSonic，一种针对此任务的数据扩增方法。SynSonic利用受能量包络ControlNet引导的文本转音频扩散模型来生成时间上一致的声事件。双重分类器联合评分筛选策略确保样本质量，并探索其实用集成到训练管道中的方法。实验结果表明，SynSonic提高了多音轨声检测评分（PSDS1和PSDS2），提升了时间和声类的区分度。', 'title_zh': 'SynSonic: 通过文本到音频扩散ControlNet和有效样本过滤增强声事件检测'}
{'arxiv_id': 'arXiv:2509.18600', 'title': 'OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation', 'authors': 'Zhuoxiao Chen, Hongyang Yu, Ying Xu, Yadan Luo, Long Duong, Yuan-Fang Li', 'link': 'https://arxiv.org/abs/2509.18600', 'abstract': 'Radiology report generation (RRG) aims to automatically produce clinically faithful reports from chest X-ray images. Prevailing work typically follows a scale-driven paradigm, by multi-stage training over large paired corpora and oversized backbones, making pipelines highly data- and compute-intensive. In this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables single-stage, RL-only training by converting failed GRPO explorations on rare or difficult studies into direct preference supervision via a lightweight oracle step. FactS grounds learning in diagnostic evidence by extracting atomic clinical facts and checking entailment against ground-truth labels, yielding dense, interpretable sentence-level rewards. Together, OraPO and FactS create a compact and powerful framework that significantly improves learning efficiency on clinically challenging cases, setting the new SOTA performance on the CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training data using a small base VLM on modest hardware.', 'abstract_zh': '基于Oracle教育的GRPO（OraPO）及其FactScore奖励机制在受限预算下的胸部X光影像 Radiology报告生成（RRG）', 'title_zh': 'Oracle教育强化学习：面向数据高效且基于事实的放射学报告生成'}
{'arxiv_id': 'arXiv:2509.18592', 'title': 'VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation', 'authors': 'Neel P. Bhatt, Yunhao Yang, Rohan Siva, Pranay Samineni, Daniel Milan, Zhangyang Wang, Ufuk Topcu', 'link': 'https://arxiv.org/abs/2509.18592', 'abstract': 'Rapid adaptation in unseen environments is essential for scalable real-world autonomy, yet existing approaches rely on exhaustive exploration or rigid navigation policies that fail to generalize. We present VLN-Zero, a two-phase vision-language navigation framework that leverages vision-language models to efficiently construct symbolic scene graphs and enable zero-shot neurosymbolic navigation. In the exploration phase, structured prompts guide VLM-based search toward informative and diverse trajectories, yielding compact scene graph representations. In the deployment phase, a neurosymbolic planner reasons over the scene graph and environmental observations to generate executable plans, while a cache-enabled execution module accelerates adaptation by reusing previously computed task-location trajectories. By combining rapid exploration, symbolic reasoning, and cache-enabled execution, the proposed framework overcomes the computational inefficiency and poor generalization of prior vision-language navigation methods, enabling robust and scalable decision-making in unseen environments. VLN-Zero achieves 2x higher success rate compared to state-of-the-art zero-shot models, outperforms most fine-tuned baselines, and reaches goal locations in half the time with 55% fewer VLM calls on average compared to state-of-the-art models across diverse environments. Codebase, datasets, and videos for VLN-Zero are available at: this https URL.', 'abstract_zh': '视觉-语言导航中的VLN-Zero：一种高效的零样本神经符号导航框架', 'title_zh': 'VLN-Zero: 快速探索与缓存辅助神经符号视觉语言规划在机器人导航中的零样本迁移'}
{'arxiv_id': 'arXiv:2509.18585', 'title': 'TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning', 'authors': 'Yu Chen, Yifei Han, Long Zhang, Yue Du, Bin Li', 'link': 'https://arxiv.org/abs/2509.18585', 'abstract': 'Fine-tuning large pre-trained models for downstream tasks has become a fundamental approach in natural language processing. Fully fine-tuning all model parameters is computationally expensive and memory-intensive, especially in resource-constrained environments. Existing parameter-efficient fine-tuning methods reduce the number of trainable parameters but typically overlook the varying sensitivity of different model layers and the importance of training data. In this work, we propose TsqLoRA, a novel method that integrates data-quality-driven selection with sensitivity-aware low-rank adaptation, consisted of two main components: a quality-aware sampling mechanism for selecting the most informative training data, and a dynamic rank allocation module that adjusts the rank of each layer based on its sensitivity to parameter updates. The experimental results demonstrate that TsqLoRA improves fine-tuning efficiency while maintaining or even improving performance on a variety of NLP tasks. Our code will be available at this https URL.', 'abstract_zh': '基于数据质量驱动的选择与灵敏度aware的低秩适应的细调方法TsqLoRA', 'title_zh': 'TsqLoRA: 向量敏感性和质量低秩适应以实现高效微调'}
{'arxiv_id': 'arXiv:2509.18576', 'title': 'LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA', 'authors': 'Zeyi Kang, Liang He, Yanxin Zhang, Zuheng Ming, Kaixing Zhao', 'link': 'https://arxiv.org/abs/2509.18576', 'abstract': 'Multimodal semantic learning plays a critical role in embodied intelligence, especially when robots perceive their surroundings, understand human instructions, and make intelligent decisions. However, the field faces technical challenges such as effective fusion of heterogeneous data and computational efficiency in resource-constrained environments. To address these challenges, this study proposes the lightweight LCMF cascaded attention framework, introducing a multi-level cross-modal parameter sharing mechanism into the Mamba module. By integrating the advantages of Cross-Attention and Selective parameter-sharing State Space Models (SSMs), the framework achieves efficient fusion of heterogeneous modalities and semantic complementary alignment. Experimental results show that LCMF surpasses existing multimodal baselines with an accuracy of 74.29% in VQA tasks and achieves competitive mid-tier performance within the distribution cluster of Large Language Model Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a 4.35-fold reduction in FLOPs relative to the average of comparable baselines while using only 166.51M parameters (image-text) and 219M parameters (video-text), providing an efficient solution for Human-Robot Interaction (HRI) applications in resource-constrained scenarios with strong multimodal decision generalization capabilities.', 'abstract_zh': '多模态语义学习在体效应智中的关键作用，特别是在机器人感知周围环境、理解人类指令并做出智能决策时。然而，该领域面临着如异构数据的有效融合和资源受限环境中计算效率等技术挑战。为应对这些挑战，本研究提出了一种轻量级LCMF级联注意力框架，将多级跨模态参数共享机制引入Mamba模块。通过结合跨注意力和选择性参数共享状态空间模型的优势，该框架实现了异构模态的有效融合和语义互补对齐。实验结果显示，LCMF在VQA任务中的准确率为74.29%，超越现有多种模态基线，并在EQA视频任务中获得了大型语言模型代理分布集群中的竞争力中等表现。其轻量级设计相比可比基线平均减少了4.35倍的FLOPs，仅使用166.51M（图像-文本）和219M（视频-文本）参数，为资源受限场景中的体效应交互（HRI）应用提供了高效解决方案，具备强大的多种模态决策泛化能力。', 'title_zh': 'LCMF：轻量级跨模态Mambaformer在体态机器人VQA中的应用'}
{'arxiv_id': 'arXiv:2509.18575', 'title': 'The Ranking Blind Spot: Decision Hijacking in LLM-based Text Ranking', 'authors': 'Yaoyao Qian, Yifan Zeng, Yuchao Jiang, Chelsi Jain, Huazheng Wang', 'link': 'https://arxiv.org/abs/2509.18575', 'abstract': 'Large Language Models (LLMs) have demonstrated strong performance in information retrieval tasks like passage ranking. Our research examines how instruction-following capabilities in LLMs interact with multi-document comparison tasks, identifying what we term the "Ranking Blind Spot", a characteristic of LLM decision processes during comparative evaluation. We analyze how this ranking blind spot affects LLM evaluation systems through two approaches: Decision Objective Hijacking, which alters the evaluation goal in pairwise ranking systems, and Decision Criteria Hijacking, which modifies relevance standards across ranking schemes. These approaches demonstrate how content providers could potentially influence LLM-based ranking systems to affect document positioning. These attacks aim to force the LLM ranker to prefer a specific passage and rank it at the top. Malicious content providers can exploit this weakness, which helps them gain additional exposure by attacking the ranker. In our experiment, We empirically show that the proposed attacks are effective in various LLMs and can be generalized to multiple ranking schemes. We apply these attack to realistic examples to show their effectiveness. We also found stronger LLMs are more vulnerable to these attacks. Our code is available at: this https URL', 'abstract_zh': '大型语言模型（LLMs）在信息检索任务如段落排序中展现了强大的性能。我们的研究考察了LLMs的指令遵循能力与多文档比较任务之间的相互作用，并鉴定了我们称之为“排名盲点”的现象，这是LLMs在比较评估过程中决策过程的一个特征。我们通过两种方法分析了这种排名盲点如何影响LLM评估系统：决策目标劫持，改变成对排序系统的评估目标；决策标准劫持，修改不同排序方案的相关性标准。这些方法展示了内容提供者可能如何通过影响LLM排序系统来改变文档的位置。这些攻击旨在迫使LLM排序器偏好特定段落并将其置于首位。恶意内容提供者可以利用这一弱点，通过攻击排序器来增加自身内容的暴露。在我们的实验中，我们实证证明了所提出的攻击在多种LLMs中有效，并且可以泛化到多种排序方案中。我们应用这些攻击于真实示例以展示其有效性。我们还发现，更强的LLM更容易受到这些攻击的影响。我们的代码可在以下链接获取：this https URL。', 'title_zh': 'LLM基于文本排名中的决策劫持盲区'}
{'arxiv_id': 'arXiv:2509.18573', 'title': 'Interaction Topological Transformer for Multiscale Learning in Porous Materials', 'authors': 'Dong Chen, Jian Liu, Chun-Long Chen, Guo-Wei Wei', 'link': 'https://arxiv.org/abs/2509.18573', 'abstract': 'Porous materials exhibit vast structural diversity and support critical applications in gas storage, separations, and catalysis. However, predictive modeling remains challenging due to the multiscale nature of structure-property relationships, where performance is governed by both local chemical environments and global pore-network topology. These complexities, combined with sparse and unevenly distributed labeled data, hinder generalization across material families. We propose the Interaction Topological Transformer (ITT), a unified data-efficient framework that leverages novel interaction topology to capture materials information across multiple scales and multiple levels, including structural, elemental, atomic, and pairwise-elemental organization. ITT extracts scale-aware features that reflect both compositional and relational structure within complex porous frameworks, and integrates them through a built-in Transformer architecture that supports joint reasoning across scales. Trained using a two-stage strategy, i.e., self-supervised pretraining on 0.6 million unlabeled structures followed by supervised fine-tuning, ITT achieves state-of-the-art, accurate, and transferable predictions for adsorption, transport, and stability properties. This framework provides a principled and scalable path for learning-guided discovery in structurally and chemically diverse porous materials.', 'abstract_zh': '多孔材料展现出广泛的结构性多样性，并在气体储存、分离和催化等领域支持关键应用。然而，由于结构-性能关系的多尺度本质，预测建模仍然具有挑战性，这类关系受局部化学环境和全局孔隙网络拓扑的共同影响。这些复杂性结合了稀疏且分布不均的标注数据，阻碍了在材料家族间的泛化能力。我们提出了一种交互拓扑变换器（ITT），这是一个统一的数据高效框架，利用新的交互拓扑来跨多个尺度和多个层次捕获材料信息，包括结构、元素、原子以及元素对的组织。ITT 提取了反映复杂多孔框架中组分和关系结构的尺度感知特征，并通过内置的变换器架构将它们集成起来，支持跨尺度的联合推理。通过两阶段策略进行训练，即自监督预训练100万未标注结构后，再进行监督微调，ITT 实现了吸附、传输和稳定性性质的最佳、精确且可转移的预测。该框架为学习引导下，在结构和化学多样性多孔材料中的发现提供了原则性和可扩展的路径。', 'title_zh': '多孔材料中跨尺度学习的交互拓扑变换器'}
{'arxiv_id': 'arXiv:2509.18569', 'title': 'Explore the Reinforcement Learning for the LLM based ASR and TTS system', 'authors': 'Changfeng Gao, Yabin Li, Keyu An, Zhifu Gao, Zhihao Du, Han Zhao, Xiangang Li', 'link': 'https://arxiv.org/abs/2509.18569', 'abstract': 'In recent years, large language models (LLMs) have played an important role in automatic speech recognition (ASR) and text-to-speech (TTS) systems. While reinforcement learning (RL) has significantly enhanced LLM performance in text-based tasks, its application to ASR and TTS remains underexplored due to the complexity of training audio-based models. In this study, we propose a lightweight RL framework tailored for audio-based LLMs that can process audio inputs and generate audio outputs. Based on this framework, we evaluate the effectiveness of reinforcement learning on both ASR and TTS tasks. For the ASR task, we experiment with different rule-based reward functions within the Group Relative Policy Optimization (GRPO) framework and investigate the impact of RL data construction. For the TTS task, we compare GRPO with Differentiable Reward Optimization (DiffRO) and further combine the two approaches to achieve improved performance. Our experiments demonstrate that RL can significantly enhance the performance of both ASR and TTS systems, even with limited training data and a small number of optimization steps.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在自动语音识别（ASR）和文本到语音（TTS）系统中发挥了重要作用。虽然强化学习（RL）在基于文本的任务中显著提升了LLM的性能，但在ASR和TTS中的应用仍因基于音频模型的训练复杂性而未得到充分探索。本研究提出了一种针对基于音频的LLMs的轻量级RL框架，该框架可以处理音频输入并生成音频输出。基于此框架，我们评估了强化学习在ASR和TTS任务中的有效性。对于ASR任务，我们在Group Relative Policy Optimization（GRPO）框架内尝试不同的基于规则的奖励函数，并探讨了RL数据构建的影响。对于TTS任务，我们比较了GRPO与Differentiable Reward Optimization（DiffRO），并进一步将两种方法结合起来以实现性能提升。我们的实验表明，即使在有限的训练数据和少量优化步骤的情况下，RL也能显著提升ASR和TTS系统的性能。', 'title_zh': '探究基于LLM的ASR和TTS系统中的强化学习应用'}
{'arxiv_id': 'arXiv:2509.18562', 'title': 'CPCLDETECTOR: Knowledge Enhancement and Alignment Selection for Chinese Patronizing and Condescending Language Detection', 'authors': 'Jiaxun Yang, Yifei Han, Long Zhang, Liu Yujie, Bin Li, Bo Gao, Yangfan He, Kejia Zhan', 'link': 'https://arxiv.org/abs/2509.18562', 'abstract': "Chinese Patronizing and Condescending Language (CPCL) is an implicitly discriminatory toxic speech targeting vulnerable groups on Chinese video platforms. The existing dataset lacks user comments, which are a direct reflection of video content. This undermines the model's understanding of video content and results in the failure to detect some CPLC videos. To make up for this loss, this research reconstructs a new dataset PCLMMPLUS that includes 103k comment entries and expands the dataset size. We also propose the CPCLDetector model with alignment selection and knowledge-enhanced comment content modules. Extensive experiments show the proposed CPCLDetector outperforms the SOTA on PCLMM and achieves higher performance on PCLMMPLUS . CPLC videos are detected more accurately, supporting content governance and protecting vulnerable groups. Code and dataset are available at this https URL.", 'abstract_zh': '中文偏见和居高临下的语言（CPCL）数据集PCLMMPLUS及其检测模型CPCLDetector的研究', 'title_zh': 'CPCLDETECTOR：知识增强与贬抑语言检测的选择性对齐'}
{'arxiv_id': 'arXiv:2509.18561', 'title': 'SoundCompass: Navigating Target Sound Extraction With Effective Directional Clue Integration In Complex Acoustic Scenes', 'authors': 'Dayun Choi, Jung-Woo Choi', 'link': 'https://arxiv.org/abs/2509.18561', 'abstract': 'Recent advances in target sound extraction (TSE) utilize directional clues derived from direction of arrival (DoA), which represent an inherent spatial property of sound available in any acoustic scene. However, previous DoA-based methods rely on hand-crafted features or discrete encodings, which lose fine-grained spatial information and limit adaptability. We propose SoundCompass, an effective directional clue integration framework centered on a Spectral Pairwise INteraction (SPIN) module that captures cross-channel spatial correlations in the complex spectrogram domain to preserve full spatial information in multichannel signals. The input feature expressed in terms of spatial correlations is fused with a DoA clue represented as spherical harmonics (SH) encoding. The fusion is carried out across overlapping frequency subbands, inheriting the benefits reported in the previous band-split architectures. We also incorporate the iterative refinement strategy, chain-of-inference (CoI), in the TSE framework, which recursively fuses DoA with sound event activation estimated from the previous inference stage. Experiments demonstrate that SoundCompass, combining SPIN, SH embedding, and CoI, robustly extracts target sources across diverse signal classes and spatial configurations.', 'abstract_zh': 'Recent Advances in Target Sound Extraction (TSE) Utilizing Spectral Pairwise Interaction (SPIN) for Directional Clue Integration', 'title_zh': 'SoundCompass: 在复杂声景中通过有效的方向性线索集成进行目标声音提取'}
{'arxiv_id': 'arXiv:2509.18552', 'title': 'Global Minimizers of Sigmoid Contrastive Loss', 'authors': 'Kiril Bangachev, Guy Bresler, Iliyas Noman, Yury Polyanskiy', 'link': 'https://arxiv.org/abs/2509.18552', 'abstract': 'The meta-task of obtaining and aligning representations through contrastive pretraining is steadily gaining importance since its introduction in CLIP and ALIGN. In this paper we theoretically explain the advantages of synchronizing with trainable inverse temperature and bias under the sigmoid loss, as implemented in the recent SigLIP and SigLIP2 models of Google DeepMind. Temperature and bias can drive the loss function to zero for a rich class of configurations that we call $(\\mathsf{m}, \\mathsf{b}_{\\mathsf{rel}})$-Constellations. $(\\mathsf{m}, \\mathsf{b}_{\\mathsf{rel}})$-Constellations are a novel combinatorial object related to spherical codes and are parametrized by a margin $\\mathsf{m}$ and relative bias $\\mathsf{b}_{\\mathsf{rel}}$. We use our characterization of constellations to theoretically justify the success of SigLIP on retrieval, to explain the modality gap present in SigLIP, and to identify the necessary dimension for producing high-quality representations. Finally, we propose a reparameterization of the sigmoid loss with explicit relative bias, which improves training dynamics in experiments with synthetic data.', 'abstract_zh': '通过对比预训练获得和对齐表示的元任务：同步可训练的逆温度和相对偏置以实现sigmoid损失趋零的优势理论解释', 'title_zh': '全局Sigmoid对比损失的最小值'}
{'arxiv_id': 'arXiv:2509.18542', 'title': 'Symphony-MoE: Harmonizing Disparate Pre-trained Models into a Coherent Mixture-of-Experts', 'authors': 'Qi Wang, Hanyang Peng, Yue Yu', 'link': 'https://arxiv.org/abs/2509.18542', 'abstract': 'Mixture-of-Experts (MoE) models enable scalable performance by activating large parameter sets sparsely, minimizing computational overhead. To circumvent the prohibitive cost of training MoEs from scratch, recent work employs upcycling, reusing a single pre-trained dense model by replicating its feed-forward network (FFN) layers into experts. However, this limits expert diversity, as all experts originate from a single pre-trained dense model. This paper addresses this limitation by constructing powerful MoE models using experts sourced from multiple identically-architected but disparate pre-trained models (e.g., Llama2-Chat and Code Llama). A key challenge lies in the fact that these source models occupy disparate, dissonant regions of the parameter space, making direct upcycling prone to severe performance degradation. To overcome this, we propose Symphony-MoE, a novel two-stage framework designed to harmonize these models into a single, coherent expert mixture. First, we establish this harmony in a training-free manner: we construct a shared backbone via a layer-aware fusion strategy and, crucially, alleviate parameter misalignment among experts using activation-based functional alignment. Subsequently, a single lightweight stage of router training coordinates the entire architecture. Experiments demonstrate that our method successfully integrates experts from heterogeneous sources, achieving an MoE model that significantly surpasses baselines in multi-domain tasks and out-of-distribution generalization.', 'abstract_zh': '多模型组件(Multi-Model Expert)的Symphony-MoE框架：通过融合多预训练模型构建强大的混合专家模型', 'title_zh': 'Symphony-MoE: 谐调异构预训练模型为统一的Mixture-of-Experts'}
{'arxiv_id': 'arXiv:2509.18536', 'title': 'CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs', 'authors': 'Jin Young Kim, Ji Won Yoon', 'link': 'https://arxiv.org/abs/2509.18536', 'abstract': 'Recently, inference-time reasoning strategies have further improved the accuracy of large language models (LLMs), but their effectiveness on smaller models remains unclear. Based on the observation that conventional approaches often fail to improve performance in this context, we propose \\textbf{C}ycle-\\textbf{C}onsistency in \\textbf{Q}uestion \\textbf{A}nswering (CCQA), a novel reasoning method that can be effectively applied to SLMs. Inspired by cycle consistency, CCQA generates a question from each reasoning path and answer, evaluates each by its similarity to the original question, and then selects the candidate solution with the highest similarity score as the final response. Since conventional SLMs struggle to generate accurate questions from their own reasoning paths and answers, we employ a lightweight Flan-T5 model specialized for question generation to support this process efficiently. From the experimental results, it is verified that CCQA consistently outperforms existing state-of-the-art (SOTA) methods across eight models on mathematical and commonsense reasoning benchmarks. Furthermore, our method establishes a new practical baseline for efficient reasoning in SLMs. Source code can be found at this https URL.', 'abstract_zh': 'Recently, Inference-Time Reasoning Strategies Have Further Improved the Accuracy of Large Language Models (LLMs), but Their Effectiveness on Smaller Models Remains Unclear: Proposal of Cycle-Consistency in Question Answering (CCQA) for Smaller Language Models', 'title_zh': 'CCQA：从解决方案生成问题可以提高SLMs的推理时间推理能力'}
{'arxiv_id': 'arXiv:2509.18531', 'title': 'No Verifiable Reward for Prosody: Toward Preference-Guided Prosody Learning in TTS', 'authors': 'Seungyoun Shin, Dongha Ahn, Jiwoo Kim, Sungwook Jeon', 'link': 'https://arxiv.org/abs/2509.18531', 'abstract': 'Recent work reports gains in neural text-to-speech (TTS) with Group Relative Policy Optimization (GRPO). However, in the absence of a verifiable reward for \\textit{prosody}, GRPO trained on transcription-oriented signals (CER/NLL) lowers error rates yet collapses prosody into monotone, unnatural speech; adding speaker-similarity further destabilizes training and degrades CER. We address this with an \\textit{iterative Direct Preference Optimization (DPO)} scheme that uses only a few hundred human-labeled preference pairs per round to directly optimize prosodic naturalness while regularizing to the current model. On \\textbf{KoCC-TTS}, a curated dataset of authentic Korean call center interactions capturing task-oriented dialogues, our method attains the highest human preference (ELO) with competitive CER, outperforming GRPO and strong commercial baselines. These results suggest that when prosody cannot be rewarded automatically, \\textit{human preference optimization} offers a practical and data-efficient path to natural and robust TTS. The demo page is available at \\href{this https URL}', 'abstract_zh': '近期的研究报告了使用组相对策略优化（GRPO）在神经文本转语音（TTS）中的收益。然而，在缺乏可验证的韵律奖励的情况下，GRPO在转录导向信号（CER/NLL）的基础上训练，虽然降低了错误率，但使韵律退化为单调、不自然的语音；进一步加入说话人相似性会进一步导致训练不稳定并恶化CER。我们通过一种仅使用每轮几百个人标注的偏好对的迭代直接偏好优化（DPO）方案来解决这个问题，该方案可以直接优化韵律自然性，并通过对齐到当前模型来正则化。在 curated 数据集 KoCC-TTS 中，一个捕捉任务导向对话的韩国呼叫中心互动数据集上，我们的方法在保持竞争力的CER的同时获得了最高的人类偏好（ELO），优于GRPO和强大的商用基线。这些结果表明，当韵律无法自动奖励时，人类偏好优化提供了一种实用且数据高效的路径，以实现自然和稳健的TTS。演示页面可在 \\href{this https URL} 查看。', 'title_zh': '无验证性的韵律奖励：面向偏好导向的韵律学习在TTS中的应用'}
{'arxiv_id': 'arXiv:2509.18523', 'title': 'Automatic coherence-driven inference on arguments', 'authors': 'Steve Huntsman', 'link': 'https://arxiv.org/abs/2509.18523', 'abstract': 'Inconsistencies are ubiquitous in law, administration, and jurisprudence. Though a cure is too much to hope for, we propose a technological remedy. Large language models (LLMs) can accurately extract propositions from arguments and compile them into natural data structures that enable coherence-driven inference (CDI) via combinatorial optimization. This neurosymbolic architecture naturally separates concerns and enables meaningful judgments about the coherence of arguments that can inform legislative and policy analysis and legal reasoning.', 'abstract_zh': '法律、行政和法学中的不一致性无处不在。尽管彻底治愈这种情况期望过高，我们提出了一种技术性解决方案。大型语言模型（LLMs）能够准确提取论点中的命题，并将其编译成自然的数据结构，通过组合优化实现一致性驱动的推理（CDI）。这种神经符号架构自然地分离了关注点，并能够对论点的连贯性做出有意义的判断，从而指导立法和政策分析以及法律推理。', 'title_zh': '自动连贯性驱动的论点推理'}
{'arxiv_id': 'arXiv:2509.18521', 'title': 'APRIL: Active Partial Rollouts in Reinforcement Learning to tame long-tail generation', 'authors': 'Yuzhen Zhou, Jiajun Li, Yusheng Su, Gowtham Ramesh, Zilin Zhu, Xiang Long, Chenyang Zhao, Jin Pan, Xiaodong Yu, Ze Wang, Kangrui Du, Jialian Wu, Ximeng Sun, Jiang Liu, Qiaolin Yu, Hao Chen, Zicheng Liu, Emad Barsoum', 'link': 'https://arxiv.org/abs/2509.18521', 'abstract': "Reinforcement learning (RL) has become a cornerstone in advancing large-scale pre-trained language models (LLMs). Successive generations, including GPT-o series, DeepSeek-R1, Kimi-K1.5, Grok 4, and GLM-4.5, have relied on large-scale RL training to enhance reasoning and coding capabilities. To meet the community's growing RL needs, numerous RL frameworks have been proposed. Most of these frameworks primarily rely on inference engines for rollout generation and training engines for policy updates. However, RL training remains computationally expensive, with rollout generation accounting for more than 90% of total runtime. In addition, its efficiency is often constrained by the long-tail distribution of rollout response lengths, where a few lengthy responses stall entire batches, leaving GPUs idle and underutilized. As model and rollout sizes continue to grow, this bottleneck increasingly limits scalability. To address this challenge, we propose Active Partial Rollouts in Reinforcement Learning (APRIL), which mitigates long-tail inefficiency. In the rollout phase, APRIL over-provisions rollout requests, terminates once the target number of responses is reached, and recycles incomplete responses for continuation in future steps. This strategy ensures that no rollouts are discarded while substantially reducing GPU idle time. Experiments show that APRIL improves rollout throughput by at most 44% across commonly used RL algorithms (GRPO, DAPO, GSPO), accelerates convergence, and achieves at most 8% higher final accuracy across tasks. Moreover, APRIL is both framework and hardware agnostic, already integrated into the slime RL framework, and deployable on NVIDIA and AMD GPUs alike. Taken together, this work unifies system-level and algorithmic considerations in proposing APRIL, with the aim of advancing RL training efficiency and inspiring further optimizations in RL systems.", 'abstract_zh': '主动部分回放强化学习（APRIL）：缓解长尾 inefficiency', 'title_zh': 'APRIL: Active 部分 rollout 在强化学习中治理长尾生成'}
{'arxiv_id': 'arXiv:2509.18520', 'title': 'Coherence-driven inference for cybersecurity', 'authors': 'Steve Huntsman', 'link': 'https://arxiv.org/abs/2509.18520', 'abstract': 'Large language models (LLMs) can compile weighted graphs on natural language data to enable automatic coherence-driven inference (CDI) relevant to red and blue team operations in cybersecurity. This represents an early application of automatic CDI that holds near- to medium-term promise for decision-making in cybersecurity and eventually also for autonomous blue team operations.', 'abstract_zh': '大型语言模型（LLMs）可以将自然语言数据编译成加权图以启用与网络安全红蓝队操作相关的自动一致性驱动推理（CDI）。这代表了自动CDI的早期应用，有望在近至中期内为网络安全决策提供支持，并最终也适用于自主蓝队操作。', 'title_zh': '驱动一致性的网络安全推理'}
{'arxiv_id': 'arXiv:2509.18514', 'title': 'A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition', 'authors': 'Mohamad Elzohbi, Richard Zhao', 'link': 'https://arxiv.org/abs/2509.18514', 'abstract': 'This paper presents a methodology for inserting phrases in Arabic poems to conform to a specific rhythm using ByT5, a byte-level multilingual transformer-based model. Our work discusses a rule-based grapheme-to-beat transformation tailored for extracting the rhythm from fully diacritized Arabic script. Our approach employs a conditional denoising objective to fine-tune ByT5, where the model reconstructs masked words to match a target rhythm. We adopt a curriculum learning strategy, pre-training on a general Arabic dataset before fine-tuning on poetic dataset, and explore cross-lingual transfer from English to Arabic. Experimental results demonstrate that our models achieve high rhythmic alignment while maintaining semantic coherence. The proposed model has the potential to be used in co-creative applications in the process of composing classical Arabic poems.', 'abstract_zh': '本论文提出了一种使用ByT5（字节级多语言变换器模型）在阿拉伯诗歌中插入短语以符合特定节奏的方法。我们的工作讨论了一种规则导向的音素到节奏的转换方法，专门针对从完全标注的阿拉伯文字中提取节奏。我们的方法采用条件去噪目标对ByT5进行微调，其中模型重建掩码单词以匹配目标节奏。我们采用阶梯学习策略，在一般阿拉伯语数据集上预训练，然后在诗歌数据集上进行微调，并探索从英语到阿拉伯语的跨语言迁移。实验结果表明，我们的模型在保持语义一致性的同时达到了高度的节奏对齐。所提模型在创作古典阿拉伯诗歌的协作创作应用中具有潜在用途。', 'title_zh': '节奏感知的短语插入用于古典阿拉伯诗歌创作'}
{'arxiv_id': 'arXiv:2509.18507', 'title': 'Dynamical Modeling of Behaviorally Relevant Spatiotemporal Patterns in Neural Imaging Data', 'authors': 'Mohammad Hosseini, Maryam M. Shanechi', 'link': 'https://arxiv.org/abs/2509.18507', 'abstract': 'High-dimensional imaging of neural activity, such as widefield calcium and functional ultrasound imaging, provide a rich source of information for understanding the relationship between brain activity and behavior. Accurately modeling neural dynamics in these modalities is crucial for understanding this relationship but is hindered by the high-dimensionality, complex spatiotemporal dependencies, and prevalent behaviorally irrelevant dynamics in these modalities. Existing dynamical models often employ preprocessing steps to obtain low-dimensional representations from neural image modalities. However, this process can discard behaviorally relevant information and miss spatiotemporal structure. We propose SBIND, a novel data-driven deep learning framework to model spatiotemporal dependencies in neural images and disentangle their behaviorally relevant dynamics from other neural dynamics. We validate SBIND on widefield imaging datasets, and show its extension to functional ultrasound imaging, a recent modality whose dynamical modeling has largely remained unexplored. We find that our model effectively identifies both local and long-range spatial dependencies across the brain while also dissociating behaviorally relevant neural dynamics. Doing so, SBIND outperforms existing models in neural-behavioral prediction. Overall, SBIND provides a versatile tool for investigating the neural mechanisms underlying behavior using imaging modalities.', 'abstract_zh': '高维神经活动成像，如宽场钙成像和功能性超声成像，提供了理解脑活动与行为关系的丰富信息。准确建模这些模态中的神经动力学对于理解这种关系至关重要，但受到高维度、复杂的时空依赖关系以及普遍存在的与行为无关的动态的影响。现有的动力学模型通常采用 preprocessing 步骤从神经图像模态中获得低维度表示。然而，这一过程可能会丢弃与行为相关的信息并错过时空结构。我们提出了一种新的数据驱动深度学习框架 SBIND，旨在建模神经图像中的时空依赖关系，并从其他神经动力学中分离出与行为相关的主要神经动力学。我们在宽场成像数据集上验证了 SBIND，并将其扩展到功能性超声成像，这是一种近期模态，其动力学建模尚未得到充分探索。我们发现，我们的模型有效识别了脑内的局部和远端空间依赖关系，并且能够分离出与行为相关的神经动力学。由此，SBIND 在神经行为预测中优于现有模型。总体而言，SBIND 提供了一个多功能的工具，用于使用成像模态研究行为背后的神经机制。', 'title_zh': '行为相关时空模式的神经成像数据动力学建模'}
{'arxiv_id': 'arXiv:2509.18504', 'title': 'Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning', 'authors': 'Jiaxin Dai, Xiang Xiang', 'link': 'https://arxiv.org/abs/2509.18504', 'abstract': 'In the field of machine learning, hyperbolic space demonstrates superior representation capabilities for hierarchical data compared to conventional Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe approach, which contrastively learns coarse class labels and subsequently normalizes and freezes the classifier weights of learned fine classes in the embedding space. To better interpret the "coarse-to-fine" paradigm, we propose embedding the feature extractor into hyperbolic space. Specifically, we employ the Poincaré ball model of hyperbolic space, enabling the feature extractor to transform input images into feature vectors within the Poincaré ball instead of Euclidean space. We further introduce hyperbolic contrastive loss and hyperbolic fully-connected layers to facilitate model optimization and classification in hyperbolic space. Additionally, to enhance performance under few-shot conditions, we implement maximum entropy distribution in hyperbolic space to estimate the probability distribution of fine-class feature vectors. This allows generation of augmented features from the distribution to mitigate overfitting during training with limited samples. Experiments on C2FSCIL benchmarks show that our method effectively improves both coarse and fine class accuracies.', 'abstract_zh': '在机器学习领域，双曲空间在层次数据表示方面优于传统的欧几里得空间。本研究聚焦于粗到细少量样本类增量学习（Coarse-To-Fine Few-Shot Class-Incremental Learning，C2FSCIL）任务。我们的研究遵循Knowe方法，通过对比学习粗类标签，并在嵌入空间中对学习到的细类分类器权重进行规范化和冻结。为了更好地解释“粗到细”范式，我们提出将特征提取器嵌入到双曲空间中。具体而言，我们采用双曲空间的Poincaré球模型，使特征提取器能够将输入图像转换为Poincaré球内的特征向量，而不是欧几里得空间。此外，我们引入了双曲对比损失和双曲全连接层，以促进在双曲空间中的模型优化和分类。为进一步在少量样本条件下提高性能，我们在双曲空间中引入最大熵分布来估计细类特征向量的概率分布，从而生成增强特征以减轻有限样本训练中的过拟合。在C2FSCIL基准测试上的实验表明，我们的方法有效地提高了粗类和细类的准确性。', 'title_zh': '双曲尺度自上而下少样本类增量学习'}
{'arxiv_id': 'arXiv:2509.18467', 'title': 'LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling', 'authors': 'Zeyu Liu, Souvik Kundu, Lianghao Jiang, Anni Li, Srikanth Ronanki, Sravan Bodapati, Gourav Datta, Peter A. Beerel', 'link': 'https://arxiv.org/abs/2509.18467', 'abstract': 'Although transformer architectures have achieved state-of-the-art performance across diverse domains, their quadratic computational complexity with respect to sequence length remains a significant bottleneck, particularly for latency-sensitive long-context applications. While recent linear-complexity alternatives are increasingly powerful, effectively training them from scratch is still resource-intensive. To overcome these limitations, we propose LAWCAT (Linear Attention with Convolution Across Time), a novel linearization framework designed to efficiently transfer the capabilities of pre-trained transformers into a performant linear attention architecture. LAWCAT integrates causal Conv1D layers to enhance local dependency modeling and employs normalized gated linear attention to improve generalization across varying context lengths. Our comprehensive evaluations demonstrate that, distilling Mistral-7B with only 1K-length sequences yields over 90\\% passkey retrieval accuracy up to 22K tokens, significantly extending its effective context window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance on S-NIAH 1\\&2\\&3 tasks (1K-8K context length) and BABILong benchmark (QA2\\&QA3, 0K-16K context length), requiring less than 0.1\\% pre-training tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT thus provides an efficient pathway to high-performance, long-context linear models suitable for edge deployment, reducing reliance on extensive long-sequence training data and computational resources.', 'abstract_zh': '虽然transformer架构在各个领域取得了最先进性能，但其与序列长度呈二次计算复杂度仍是-latency敏感长上下文应用中的一个重要瓶颈。尽管最近线性复杂度的替代方案越来越强大，但它们从头有效训练仍消耗大量资源。为克服这些限制，我们提出了LAWCAT（Linear Attention with Convolution Across Time），一种新颖的线性化框架，旨在高效地将预训练transformer的能力转移到高性能线性注意力架构中。LAWCAT结合因果Conv1D层以增强局部依赖建模，并采用归一化门控线性注意力以提高在不同上下文长度下的泛化能力。我们的全面评估显示，通过仅使用1K长度序列蒸馏Mistral-7B可获得超过90%的密钥检索准确性，直至22K标记，显著延长了其有效上下文窗口。同样，Llama3.2-1B LAWCAT变体在S-NIAH 1&2&3任务（1K-8K上下文长度）和BABILong基准（QA2&QA3，0K-16K上下文长度）中表现出竞争力，并且预训练标记需求量少于0.1%。此外，LAWCAT在序列超过8K标记时的预填充速度比FlashAttention-2更快。因此，LAWCAT提供了一条高效的途径，以实现适用于边缘部署的高性能、长上下文线性模型，减少了对大量长序列训练数据和计算资源的依赖。', 'title_zh': 'LAWCAT: 从二次注意力到线性注意力的高效蒸馏通过卷积跨Token建模长上下文'}
{'arxiv_id': 'arXiv:2509.18461', 'title': "Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before It's Created?", 'authors': 'Ayan Sar, Sampurna Roy, Tanupriya Choudhury, Ajith Abraham', 'link': 'https://arxiv.org/abs/2509.18461', 'abstract': 'Generative adversarial networks (GANs) and diffusion models have dramatically advanced deepfake technology, and its threats to digital security, media integrity, and public trust have increased rapidly. This research explored zero-shot deepfake detection, an emerging method even when the models have never seen a particular deepfake variation. In this work, we studied self-supervised learning, transformer-based zero-shot classifier, generative model fingerprinting, and meta-learning techniques that better adapt to the ever-evolving deepfake threat. In addition, we suggested AI-driven prevention strategies that mitigated the underlying generation pipeline of the deepfakes before they occurred. They consisted of adversarial perturbations for creating deepfake generators, digital watermarking for content authenticity verification, real-time AI monitoring for content creation pipelines, and blockchain-based content verification frameworks. Despite these advancements, zero-shot detection and prevention faced critical challenges such as adversarial attacks, scalability constraints, ethical dilemmas, and the absence of standardized evaluation benchmarks. These limitations were addressed by discussing future research directions on explainable AI for deepfake detection, multimodal fusion based on image, audio, and text analysis, quantum AI for enhanced security, and federated learning for privacy-preserving deepfake detection. This further highlighted the need for an integrated defense framework for digital authenticity that utilized zero-shot learning in combination with preventive deepfake mechanisms. Finally, we highlighted the important role of interdisciplinary collaboration between AI researchers, cybersecurity experts, and policymakers to create resilient defenses against the rising tide of deepfake attacks.', 'abstract_zh': '生成对抗网络（GANs）和扩散模型大大推动了换脸技术的发展，其对数字安全、媒体完整性和公共信任的威胁迅速增加。本研究探讨了零样本换脸检测方法，即使模型从未见过特定的换脸变体。在本工作中，我们研究了自监督学习、基于变换器的零样本分类器、生成模型指纹识别以及更适应不断演变的换脸威胁的元学习技术。此外，我们提出了一种基于AI的预防策略，可以在此类换脸生成之前减轻其潜在生成管道。这些策略包括用于创建换脸生成器的对抗性扰动、用于内容真实性验证的数字水印、用于内容生成管道的实时AI监控以及基于区块链的内容验证框架。尽管取得了这些进展，零样本检测和预防仍然面临着诸如对抗性攻击、可扩展性限制、伦理困境和缺乏标准化评估基准等关键挑战。这些问题通过讨论深度换脸检测的可解释AI、基于图像、音频和文本分析的多模态融合、量子AI增强安全性以及联邦学习实现隐私保护的深度换脸检测的未来研究方向来解决。这进一步强调了需要一个集成的防伪框架，该框架结合了零样本学习和预防换脸机制，以实现数字真实性的保护。最后，我们强调了人工智能研究人员、网络安全专家和政策制定者之间跨学科合作的重要作用，以创建对不断上升的深度换脸攻击具有弹性的防御措施。', 'title_zh': '零样本视觉深度假信息检测：AI能否预测和防止假内容的创造？'}
{'arxiv_id': 'arXiv:2509.18458', 'title': 'CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density', 'authors': 'Daniel Kaiser, Arnoldo Frigessi, Ali Ramezani-Kebrya, Benjamin Ricaud', 'link': 'https://arxiv.org/abs/2509.18458', 'abstract': "Current benchmarks for long-context reasoning in Large Language Models (LLMs) often blur critical factors like intrinsic task complexity, distractor interference, and task length. To enable more precise failure analysis, we introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load Theory (CLT). CogniLoad generates natural-language logic puzzles with independently tunable parameters that reflect CLT's core dimensions: intrinsic difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\\rho$) regulates extraneous load; and task length ($N$) serves as an operational proxy for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs, CogniLoad reveals distinct performance sensitivities, identifying task length as a dominant constraint and uncovering varied tolerances to intrinsic complexity and U-shaped responses to distractor ratios. By offering systematic, factorial control over these cognitive load dimensions, CogniLoad provides a reproducible, scalable, and diagnostically rich tool for dissecting LLM reasoning limitations and guiding future model development.", 'abstract_zh': '当前的大语言模型（LLMs）长期上下文推理基准常常模糊了内在任务复杂性、干扰项干扰和任务长度等关键因素。为了实现更精确的失败分析，我们引入了CogniLoad，这是一种基于认知负载理论（CLT）的新型合成基准。CogniLoad生成自然语言逻辑谜题，并可独立调节反映CLT核心维度的参数：内在难度（$d$）控制内在负载；干扰项与信号比（$\\rho$）调节外在负载；任务长度（$N$）作为相关负载条件下操作性的代理指标。评估22种当前最先进的推理LLM后，CogniLoad揭示了不同的性能敏感性，将任务长度确定为主导限制因素，并发现了对内在复杂性的不同容忍度和干扰比率的U形反应。通过在这些认知负载维度上提供系统性和因子控制，CogniLoad提供了一种可再现、可扩展且诊断丰富的工具，用于剖析LLM推理限制并指导未来的模型开发。', 'title_zh': 'CogniLoad：一种可调节长度、内在难度和干扰项密度的合成自然语言推理基准测试'}
{'arxiv_id': 'arXiv:2509.18447', 'title': 'PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction', 'authors': 'Rishabh Madan, Jiawei Lin, Mahika Goel, Angchen Xie, Xiaoyu Liang, Marcus Lee, Justin Guo, Pranav N. Thakkar, Rohan Banerjee, Jose Barreiros, Kate Tsui, Tom Silver, Tapomayukh Bhattacharjee', 'link': 'https://arxiv.org/abs/2509.18447', 'abstract': 'Physical human-robot interaction (pHRI) requires robots to adapt to individual contact preferences, such as where and how much force is applied. Identifying preferences is difficult for a single contact; with whole-arm interaction involving multiple simultaneous contacts between the robot and human, the challenge is greater because different body parts can impose incompatible force requirements. In caregiving tasks, where contact is frequent and varied, such conflicts are unavoidable. With multiple preferences across multiple contacts, no single solution can satisfy all objectives--trade-offs are inherent, making prioritization essential. We present PrioriTouch, a framework for ranking and executing control objectives across multiple contacts. PrioriTouch can prioritize from a general collection of controllers, making it applicable not only to caregiving scenarios such as bed bathing and dressing but also to broader multi-contact settings. Our method combines a novel learning-to-rank approach with hierarchical operational space control, leveraging simulation-in-the-loop rollouts for data-efficient and safe exploration. We conduct a user study on physical assistance preferences, derive personalized comfort thresholds, and incorporate them into PrioriTouch. We evaluate PrioriTouch through extensive simulation and real-world experiments, demonstrating its ability to adapt to user contact preferences, maintain task performance, and enhance safety and comfort. Website: this https URL.', 'abstract_zh': '物理人机交互（pHRI）要求机器人适应个体的接触偏好，如力的施加位置和力度。识别这些偏好单独接触时颇具挑战性；而在使用完整臂进行互动时，由于多次同时接触可能导致不同的身体部位产生不兼容的力需求，挑战更大。在护理任务中，由于接触频繁且多样化，此类冲突不可避免。面对多个接触点上的多种偏好，没有单一解决方案能满足所有目标——权衡不可避免，因此优先级设置至关重要。我们提出了PrioriTouch框架，用于在多个接触点上排名和执行控制目标。PrioriTouch可以从广泛的控制器集合中进行优先级设置，不仅适用于诸如擦浴和穿衣等护理场景，也适用于更广泛的多接触场景。我们的方法结合了新颖的排序学习方法与分层级操作空间控制，利用闭环仿真进行数据高效且安全的探索。我们进行了用户研究以确定物理辅助偏好，推导个性化舒适阈值，并将其整合至PrioriTouch中。我们通过广泛的仿真和现实世界实验评估了PrioriTouch，展示了其适应用户接触偏好、维持任务性能、提高安全性和舒适性的能力。网站：this https URL。', 'title_zh': 'PrioriTouch: 根据用户接触偏好适应的全身物理人机互动'}
{'arxiv_id': 'arXiv:2509.18439', 'title': 'Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations', 'authors': 'Oscar J. Ponce-Ponte, David Toro-Tobon, Luis F. Figueroa, Michael Gionfriddo, Megan Branda, Victor M. Montori, Saturnino Luz, Juan P. Brito', 'link': 'https://arxiv.org/abs/2509.18439', 'abstract': 'Shared decision-making (SDM) is necessary to achieve patient-centred care. Currently no methodology exists to automatically measure SDM at scale. This study aimed to develop an automated approach to measure SDM by using language modelling and the conversational alignment (CA) score. A total of 157 video-recorded patient-doctor conversations from a randomized multi-centre trial evaluating SDM decision aids for anticoagulation in atrial fibrillations were transcribed and segmented into 42,559 sentences. Context-response pairs and negative sampling were employed to train deep learning (DL) models and fine-tuned BERT models via the next sentence prediction (NSP) task. Each top-performing model was used to calculate four types of CA scores. A random-effects analysis by clinician, adjusting for age, sex, race, and trial arm, assessed the association between CA scores and SDM outcomes: the Decisional Conflict Scale (DCS) and the Observing Patient Involvement in Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female, mean age 70 SD 10.8), clinicians on average spoke more words than patients (1911 vs 773). The DL model without the stylebook strategy achieved a recall@1 of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1 with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012) scores generated with the DL without stylebook were associated with OPTION12. The Max CA score generated with the fine-tuned BERTbase (110M) was associated with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an impact the association between CA scores and SDM. This study introduces an automated, scalable methodology to measure SDM in patient-doctor conversations through explainable CA scores, with potential to evaluate SDM strategies at scale.', 'abstract_zh': '基于语言模型的对话对齐得分在患者医生对话中自动测量共决策的研究', 'title_zh': '开发一种人工智能框架以自动检测患者医生对话中的共同决策过程'}
{'arxiv_id': 'arXiv:2509.18424', 'title': 'Scattering Transformer: A Training-Free Transformer Architecture for Heart Murmur Detection', 'authors': 'Rami Zewail', 'link': 'https://arxiv.org/abs/2509.18424', 'abstract': 'In an attempt to address the need for skilled clinicians in heart sound interpretation, recent research efforts on automating cardiac auscultation have explored deep learning approaches. The majority of these approaches have been based on supervised learning that is always challenged in occasions where training data is limited. More recently, there has been a growing interest in potentials of pre-trained self-supervised audio foundation models for biomedical end tasks. Despite exhibiting promising results, these foundational models are typically computationally intensive. Within the context of automatic cardiac auscultation, this study explores a lightweight alternative to these general-purpose audio foundation models by introducing the Scattering Transformer, a novel, training-free transformer architecture for heart murmur detection. The proposed method leverages standard wavelet scattering networks by introducing contextual dependencies in a transformer-like architecture without any backpropagation. We evaluate our approach on the public CirCor DigiScope dataset, directly comparing it against leading general-purpose foundational models. The Scattering Transformer achieves a Weighted Accuracy(WAR) of 0.786 and an Unweighted Average Recall(UAR) of 0.697, demonstrating performance highly competitive with contemporary state of the art methods. This study establishes the Scattering Transformer as a viable and promising alternative in resource-constrained setups.', 'abstract_zh': '自动心音诊断中基于散射变换的轻量级变压器方法的研究', 'title_zh': '散射变换器：一种无需训练的心脏杂音检测变换器架构'}
{'arxiv_id': 'arXiv:2509.18415', 'title': 'Context Lineage Assurance for Non-Human Identities in Critical Multi-Agent Systems', 'authors': 'Sumana Malkapuram, Sameera Gangavarapu, Kailashnath Reddy Kavalakuntla, Ananya Gangavarapu', 'link': 'https://arxiv.org/abs/2509.18415', 'abstract': 'The proliferation of autonomous software agents necessitates rigorous frameworks for establishing secure and verifiable agent-to-agent (A2A) interactions, particularly when such agents are instantiated as non-human identities(NHIs). We extend the A2A paradigm [1 , 2] by introducing a cryptographically grounded mechanism for lineage verification, wherein the provenance and evolution of NHIs are anchored in append-only Merkle tree structures modeled after Certificate Transparency (CT) logs. Unlike traditional A2A models that primarily secure point-to-point interactions, our approach enables both agents and external verifiers to cryptographically validate multi-hop provenance, thereby ensuring the integrity of the entire call chain.\nA federated proof server acts as an auditor across one or more Merkle logs, aggregating inclusion proofs and consistency checks into compact, signed attestations that external parties can verify without access to the full execution trace. In parallel, we augment the A2A agent card to incorporate explicit identity verification primitives, enabling both peer agents and human approvers to authenticate the legitimacy of NHI representations in a standardized manner. Together, these contributions establish a cohesive model that integrates identity attestation, lineage verification, and independent proof auditing, thereby advancing the security posture of inter-agent ecosystems and providing a foundation for robust governance of NHIs in regulated environments such as FedRAMP.', 'abstract_zh': '自主软件代理的 proliferations 强调了建立安全可验证的代理到代理（A2A）交互的严谨框架的必要性，尤其是当这些代理以非人类身份（NHIs）形式实现时。我们通过引入基于加密机制的谱系验证方法，扩展了 A2A 模式 [1, 2]，其中 NHIs 的起源和演化被锚定在基于证书透明度（CT）日志的只读梅克尔树结构中。与主要保证点对点交互安全的传统 A2A 模型不同，我们的方法使双方代理和外部验证者都能够通过加密手段验证多跳谱系，从而确保整个调用链的完整性。', 'title_zh': '关键多智能体系统中非人类身份的上下文关联保证'}
{'arxiv_id': 'arXiv:2509.18407', 'title': 'Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections', 'authors': 'Navya Tiwari, Joseph Vazhaeparampil, Victoria Preston', 'link': 'https://arxiv.org/abs/2509.18407', 'abstract': 'Uncontrolled intersections account for a significant fraction of roadway crashes due to ambiguous right-of-way rules, occlusions, and unpredictable driver behavior. While autonomous vehicle research has explored uncertainty-aware decision making, few systems exist to retrofit human-operated vehicles with assistive navigation support. We present a driver-assist framework for right-of-way reasoning at uncontrolled intersections, formulated as a Partially Observable Markov Decision Process (POMDP). Using a custom simulation testbed with stochastic traffic agents, pedestrians, occlusions, and adversarial scenarios, we evaluate four decision-making approaches: a deterministic finite state machine (FSM), and three probabilistic planners: QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform the rule-based baseline, achieving up to 97.5 percent collision-free navigation under partial observability, with POMCP prioritizing safety and DESPOT balancing efficiency and runtime feasibility. Our findings highlight the importance of uncertainty-aware planning for driver assistance and motivate future integration of sensor fusion and environment perception modules for real-time deployment in realistic traffic environments.', 'abstract_zh': '不受控制的交叉口由于模糊的优先通行权规则、遮挡和不可预测的驾驶行为，占到了相当大的道路碰撞比例。虽然自主车辆研究已经探索了不确定性感知的决策制定，但很少有系统能够为人类操作的车辆提供辅助导航支持。我们提出了一种在不受控制的交叉口进行优先通行权推理的驾驶员辅助框架，该框架被表述为部分可观测马尔可夫决策过程（POMDP）。通过一个自定义的具有随机交通代理、行人、遮挡和对抗场景的模拟测试平台，我们评估了四种决策制定方法：确定性有限状态机（FSM），以及三种概率规划器：QMDP、POMCP和DESPOT。结果显示，概率规划器在部分可观测性下优于基于规则的基线，实现了高达97.5%的无碰撞导航，其中POMCP更侧重于安全性，DESPOT则平衡了效率和运行时可行性。我们的研究结果突显了不确定性感知规划对于驾驶辅助的重要性，并激发了将传感器融合和环境感知模块集成以实现实时部署于现实交通环境中的未来研究动机。', 'title_zh': '无障碍决策导航在无控制交叉口右转通行辅助决策'}
{'arxiv_id': 'arXiv:2509.18405', 'title': 'Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models', 'authors': 'Sourav Halder, Jinjun Tong, Xinyu Wu', 'link': 'https://arxiv.org/abs/2509.18405', 'abstract': 'Checks remain a foundational instrument in the financial ecosystem, facilitating substantial transaction volumes across institutions. However, their continued use also renders them a persistent target for fraud, underscoring the importance of robust check fraud detection mechanisms. At the core of such systems lies the accurate identification and localization of critical fields, such as the signature, magnetic ink character recognition (MICR) line, courtesy amount, legal amount, payee, and payer, which are essential for subsequent verification against reference checks belonging to the same customer. This field-level detection is traditionally dependent on object detection models trained on large, diverse, and meticulously labeled datasets, a resource that is scarce due to proprietary and privacy concerns. In this paper, we introduce a novel, training-free framework for automated check field detection, leveraging the power of a vision language model (VLM) in conjunction with a multimodal large language model (MLLM). Our approach enables zero-shot detection of check components, significantly lowering the barrier to deployment in real-world financial settings. Quantitative evaluation of our model on a hand-curated dataset of 110 checks spanning multiple formats and layouts demonstrates strong performance and generalization capability. Furthermore, this framework can serve as a bootstrap mechanism for generating high-quality labeled datasets, enabling the development of specialized real-time object detection models tailored to institutional needs.', 'abstract_zh': '一种基于视觉语言模型的无训练框架用于自动支票字段检测', 'title_zh': '使用多模态大型语言和视觉语言模型检验领域检测代理(CFD-Agent)'}
{'arxiv_id': 'arXiv:2509.18394', 'title': 'An Artificial Intelligence Value at Risk Approach: Metrics and Models', 'authors': 'Luis Enriquez Alvarez', 'link': 'https://arxiv.org/abs/2509.18394', 'abstract': 'Artificial intelligence risks are multidimensional in nature, as the same risk scenarios may have legal, operational, and financial risk dimensions. With the emergence of new AI regulations, the state of the art of artificial intelligence risk management seems to be highly immature due to upcoming AI regulations. Despite the appearance of several methodologies and generic criteria, it is rare to find guidelines with real implementation value, considering that the most important issue is customizing artificial intelligence risk metrics and risk models for specific AI risk scenarios. Furthermore, the financial departments, legal departments and Government Risk Compliance teams seem to remain unaware of many technical aspects of AI systems, in which data scientists and AI engineers emerge as the most appropriate implementers. It is crucial to decompose the problem of artificial intelligence risk in several dimensions: data protection, fairness, accuracy, robustness, and information security. Consequently, the main task is developing adequate metrics and risk models that manage to reduce uncertainty for decision-making in order to take informed decisions concerning the risk management of AI systems.\nThe purpose of this paper is to orientate AI stakeholders about the depths of AI risk management. Although it is not extremely technical, it requires a basic knowledge of risk management, quantifying uncertainty, the FAIR model, machine learning, large language models and AI context engineering. The examples presented pretend to be very basic and understandable, providing simple ideas that can be developed regarding specific AI customized environments. There are many issues to solve in AI risk management, and this paper will present a holistic overview of the inter-dependencies of AI risks, and how to model them together, within risk scenarios.', 'abstract_zh': '人工智能风险具有多维度性质，由于新的人工智能法规的出现，当前的人工智能风险管理似乎非常不成熟。尽管存在多种方法和通用准则，真正具有实际实施价值的指南并不多见，最重要的是为具体的人工智能风险场景量身定制人工智能风险指标和风险模型。此外，财务部门、法律部门和政府风险合规团队似乎对许多人工智能系统的技术方面了解不足，数据科学家和人工智能工程师是最合适的实施者。必须将人工智能风险问题分解为多个维度：数据保护、公平性、准确性、鲁棒性以及信息安全。因此，主要任务是开发能够减少决策不确定性、以便在管理人工智能系统风险时做出明智决策的适当指标和风险模型。', 'title_zh': '一种人工智能Value at Risk方法：度量与模型'}
{'arxiv_id': 'arXiv:2509.18386', 'title': 'Graph Enhanced Trajectory Anomaly Detection', 'authors': 'Jonathan Kabala Mbuya, Dieter Pfoser, Antonios Anastasopoulos', 'link': 'https://arxiv.org/abs/2509.18386', 'abstract': 'Trajectory anomaly detection is essential for identifying unusual and unexpected movement patterns in applications ranging from intelligent transportation systems to urban safety and fraud prevention.\nExisting methods only consider limited aspects of the trajectory nature and its movement space by treating trajectories as sequences of sampled locations, with sampling determined by positioning technology, e.g., GPS, or by high-level abstractions such as staypoints. Trajectories are analyzed in Euclidean space, neglecting the constraints and connectivity information of the underlying movement network, e.g., road or transit networks.\nThe proposed Graph Enhanced Trajectory Anomaly Detection (GETAD) framework tightly integrates road network topology, segment semantics, and historical travel patterns to model trajectory data. GETAD uses a Graph Attention Network to learn road-aware embeddings that capture both physical attributes and transition behavior, and augments these with graph-based positional encodings that reflect the spatial layout of the road network.\nA Transformer-based decoder models sequential movement, while a multiobjective loss function combining autoregressive prediction and supervised link prediction ensures realistic and structurally coherent representations.\nTo improve the robustness of anomaly detection, we introduce Confidence Weighted Negative Log Likelihood (CW NLL), an anomaly scoring function that emphasizes high-confidence deviations.\nExperiments on real-world and synthetic datasets demonstrate that GETAD achieves consistent improvements over existing methods, particularly in detecting subtle anomalies in road-constrained environments. These results highlight the benefits of incorporating graph structure and contextual semantics into trajectory modeling, enabling more precise and context-aware anomaly detection.', 'abstract_zh': '轨迹异常检测对于从智能运输系统到城市安全和欺诈预防等多个应用中识别不寻常和意外的运动模式至关重要。', 'title_zh': '图增强轨迹异常检测'}
{'arxiv_id': 'arXiv:2509.18369', 'title': 'Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning', 'authors': 'Riad Ahmed Anonto, Sardar Md. Saffat Zabin, M. Saifur Rahman', 'link': 'https://arxiv.org/abs/2509.18369', 'abstract': 'Grounding vision--language models in low-resource languages remains challenging, as they often produce fluent text about the wrong objects. This stems from scarce paired data, translation pivots that break alignment, and English-centric pretraining that ignores target-language semantics. We address this with a compute-aware Bengali captioning pipeline trained on LaBSE-verified EN--BN pairs and 110k bilingual-prompted synthetic images. A frozen MaxViT yields stable visual patches, a Bengali-native mBART-50 decodes, and a lightweight bridge links the modalities. Our core novelty is a tri-loss objective: Patch-Alignment Loss (PAL) aligns real and synthetic patch descriptors using decoder cross-attention, InfoNCE enforces global real--synthetic separation, and Sinkhorn-based OT ensures balanced fine-grained patch correspondence. This PAL+InfoNCE+OT synergy improves grounding, reduces spurious matches, and drives strong gains on Flickr30k-1k (BLEU-4 12.29, METEOR 27.98, BERTScore-F1 71.20) and MSCOCO-1k (BLEU-4 12.00, METEOR 28.14, BERTScore-F1 75.40), outperforming strong CE baselines and narrowing the real--synthetic centroid gap by 41%.', 'abstract_zh': '在低资源语言中扎根视觉-语言模型仍具有挑战性，因为它们通常会产生关于错误对象的流畅文本。这源于缺乏成对数据、破坏对齐关系的翻译枢纽以及以英语为中心的预训练忽略了目标语言语义。我们使用LaBSE验证的EN-BN成对数据和110K双向提示生成的合成图像，训练了一种计算感知的孟加拉语描述符管道。冻结的MaxViT提供了稳定的视觉片段，孟加拉语原生的mBART-50进行解码，并且一个轻量级的桥梁连接了模态。我们核心的创新是三重损失目标：片段对齐损失（PAL）使用解码器交叉注意力对齐真实和合成的片段描述符，InfoNCE 强制全球真实-合成片段分离，并基于Sinkhorn的OT确保细粒度片段对齐的平衡。PAL+InfoNCE+OT的协同作用改进了扎根性能，减少了虚假匹配，并在 Flickr30k-1k（BLEU-4 12.29，METEOR 27.98，BERTScore-F1 71.20）和 MSCOCO-1k（BLEU-4 12.00，METEOR 28.14，BERTScore-F1 75.40）上取得了显著的提升，超过了强大的CE基线，并缩小了真实-合成质心差距41%。', 'title_zh': '根据单词的位置对齐：带有对比和传输正则化的跨注意力引导补丁对齐方法用于孟加拉语描述生成'}
{'arxiv_id': 'arXiv:2509.18367', 'title': 'Multi-Worker Selection based Distributed Swarm Learning for Edge IoT with Non-i.i.d. Data', 'authors': 'Zhuoyu Yao, Yue Wang, Songyang Zhang, Yingshu Li, Zhipeng Cai, Zhi Tian', 'link': 'https://arxiv.org/abs/2509.18367', 'abstract': 'Recent advances in distributed swarm learning (DSL) offer a promising paradigm for edge Internet of Things. Such advancements enhance data privacy, communication efficiency, energy saving, and model scalability. However, the presence of non-independent and identically distributed (non-i.i.d.) data pose a significant challenge for multi-access edge computing, degrading learning performance and diverging training behavior of vanilla DSL. Further, there still lacks theoretical guidance on how data heterogeneity affects model training accuracy, which requires thorough investigation. To fill the gap, this paper first study the data heterogeneity by measuring the impact of non-i.i.d. datasets under the DSL framework. This then motivates a new multi-worker selection design for DSL, termed M-DSL algorithm, which works effectively with distributed heterogeneous data. A new non-i.i.d. degree metric is introduced and defined in this work to formulate the statistical difference among local datasets, which builds a connection between the measure of data heterogeneity and the evaluation of DSL performance. In this way, our M-DSL guides effective selection of multiple works who make prominent contributions for global model updates. We also provide theoretical analysis on the convergence behavior of our M-DSL, followed by extensive experiments on different heterogeneous datasets and non-i.i.d. data settings. Numerical results verify performance improvement and network intelligence enhancement provided by our M-DSL beyond the benchmarks.', 'abstract_zh': '最近在分布式蜂群学习（DSL）方面的进展为边缘互联网 of Things 提供了有希望的范式。这些进步增强了数据隐私、通信效率、能源节约和模型可扩展性。然而，非独立同分布（non-i.i.d.）数据的存在对多接入边缘计算构成了重大挑战，降低了基础DSL的学习性能并导致了训练行为的发散。此外，仍然缺乏关于数据异质性如何影响模型训练准确性的理论指导，这需要进一步研究。为了填补这一空白，本文首先通过在DSL框架下测量非-i.i.d.数据集的影响来研究数据异质性。这进而促使提出了一种新的DSL多工作者选择设计，称为M-DSL算法，该算法在分布异质数据情况下表现有效。本文引入并定义了一个新的非-i.i.d.度量标准，以形式化局部数据集之间的统计差异，从而建立了数据异质性度量与DSL性能评估之间的联系。通过这种方式，我们的M-DSL指导了多个对全球模型更新做出显著贡献的工作者的有效选择。我们还对M-DSL的收敛行为进行了理论分析，并在不同的异质数据集和非-i.i.d.数据设置上进行了广泛的实验。数值结果验证了M-DSL在基准之上提供的性能改进和网络智能增强。', 'title_zh': '基于非i.i.d.数据的边缘物联网分布式 Swarm 学习多工人选择方法'}
{'arxiv_id': 'arXiv:2509.18362', 'title': 'FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction', 'authors': 'Yuxuan Cai, Xiaozhuan Liang, Xinghua Wang, Jin Ma, Haijin Liang, Jinwen Luo, Xinyu Zuo, Lisheng Duan, Yuyang Yin, Xi Chen', 'link': 'https://arxiv.org/abs/2509.18362', 'abstract': 'As large language models (LLMs) become increasingly powerful, the sequential nature of autoregressive generation creates a fundamental throughput bottleneck that limits the practical deployment. While Multi-Token Prediction (MTP) has demonstrated remarkable benefits for model training efficiency and performance, its inherent potential for inference acceleration remains largely unexplored. This paper introduces FastMTP, a simple yet effective method that improves multi-step draft quality by aligning MTP training with its inference pattern, significantly enhancing speculative decoding performance. Our approach fine-tunes a single MTP head with position-shared weights on self-distilled data, enabling it to capture dependencies among consecutive future tokens and maintain high acceptance rates across multiple recursive draft steps. By integrating language-aware dynamic vocabulary compression into the MTP head, we further reduce computational overhead in the drafting process. Experimental results across seven diverse benchmarks demonstrate that FastMTP achieves an average of 2.03x speedup compared to standard next token prediction with lossless output quality, outperforming vanilla MTP by 82%. FastMTP requires only lightweight training and seamlessly integrates with existing inference frameworks, offering a practical and rapidly deployable solution for accelerating LLM inference.', 'abstract_zh': '随着大型语言模型（LLMs）变得越来越强大，自回归生成的序贯性质形成了一个根本性的吞吐量瓶颈，限制了其实用部署。尽管多令牌预测（MTP）展示了显著的模型训练效率和性能优势，其在推断加速方面的固有潜力仍 largely unexplored。本文介绍了一种简单而有效的方法FastMTP，该方法通过将MTP训练与推断模式对齐来提高多步草稿质量，显著提升了推测性解码性能。我们的方法在自蒸馏数据上对共享位置权重的单个MTP头进行微调，使其能够捕捉连续未来令牌之间的依赖性，并在多个递归草稿步骤中保持高接受率。通过将语言感知的动态词汇压缩集成到MTP头中，我们在起草过程中进一步减少了计算开销。在七个不同基准上的实验结果表明，FastMTP相比标准下一个令牌预测实现了平均2.03倍的加速，无损输出质量，比vanilla MTP性能高出82%。FastMTP仅需要轻量级训练，并且可以无缝集成到现有的推断框架中，提供了一种实用且快速部署的解决方案，用于加速LLM推断。', 'title_zh': 'FastMTP：增强多 token 预测加速大语言模型推理'}
{'arxiv_id': 'arXiv:2509.18361', 'title': 'Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts', 'authors': 'Daye Nam, Malgorzata Salawa, Satish Chandra', 'link': 'https://arxiv.org/abs/2509.18361', 'abstract': 'Evaluating developer satisfaction with conversational AI assistants at scale is critical but challenging. User studies provide rich insights, but are unscalable, while large-scale quantitative signals from logs or in-product ratings are often too shallow or sparse to be reliable. To address this gap, we propose and evaluate a new approach: using sentiment analysis of developer prompts to identify implicit signals of user satisfaction. With an analysis of industrial usage logs of 372 professional developers, we show that this approach can identify a signal in ~8% of all interactions, a rate more than 13 times higher than explicit user feedback, with reasonable accuracy even with an off-the-shelf sentiment analysis approach. This new practical approach to complement existing feedback channels would open up new directions for building a more comprehensive understanding of the developer experience at scale.', 'abstract_zh': '大规模评估开发人员对对话AI助手的满意度至关重要但具有挑战性。用户研究提供了丰富的见解，但不可扩展，而来自日志或产品内评分的大规模定量信号往往过于浅薄或稀疏，不可靠。为解决这一问题，我们提出并评估了一种新的方法：通过情感分析开发人员提示以识别用户的隐性满意度信号。通过对372名专业开发人员的工业使用日志的分析，我们表明这种方法可以在约8%的所有交互中识别出信号，这一比率比显性用户反馈高出13倍以上，并且即使使用现成的情感分析方法也能获得合理的准确率。这一新的实用方法可以补充现有的反馈渠道，为构建更全面的开发人员体验理解提供新的方向。', 'title_zh': '阅读字里行间之意：通过开发者提示中的隐含情感实现可扩展用户反馈'}
{'arxiv_id': 'arXiv:2509.18355', 'title': 'Chiplet-Based RISC-V SoC with Modular AI Acceleration', 'authors': 'P. Ramkumar, S. S. Bharadwaj', 'link': 'https://arxiv.org/abs/2509.18355', 'abstract': 'Achieving high performance, energy efficiency, and cost-effectiveness while maintaining architectural flexibility is a critical challenge in the development and deployment of edge AI devices. Monolithic SoC designs struggle with this complex balance mainly due to low manufacturing yields (below 16%) at advanced 360 mm^2 process nodes. This paper presents a novel chiplet-based RISC-V SoC architecture that addresses these limitations through modular AI acceleration and intelligent system level optimization. Our proposed design integrates 4 different key innovations in a 30mm x 30mm silicon interposer: adaptive cross-chiplet Dynamic Voltage and Frequency Scaling (DVFS); AI-aware Universal Chiplet Interconnect Express (UCIe) protocol extensions featuring streaming flow control units and compression-aware transfers; distributed cryptographic security across heterogeneous chiplets; and intelligent sensor-driven load migration. The proposed architecture integrates a 7nm RISC-V CPU chiplet with dual 5nm AI accelerators (15 TOPS INT8 each), 16GB HBM3 memory stacks, and dedicated power management controllers. Experimental results across industry standard benchmarks like MobileNetV2, ResNet-50 and real-time video processing demonstrate significant performance improvements. The AI-optimized configuration achieves ~14.7% latency reduction, 17.3% throughput improvement, and 16.2% power reduction compared to previous basic chiplet implementations. These improvements collectively translate to a 40.1% efficiency gain corresponding to ~3.5 mJ per MobileNetV2 inference (860 mW/244 images/s), while maintaining sub-5ms real-time capability across all experimented workloads. These performance upgrades demonstrate that modular chiplet designs can achieve near-monolithic computational density while enabling cost efficiency, scalability and upgradeability, crucial for next-generation edge AI device applications.', 'abstract_zh': '实现高性能、高能效和成本效益的同时保持架构灵活性是边缘AI设备开发和部署中的关键挑战。本论文提出了一种基于chiplet的RISC-V SoC架构，通过模块化AI加速和智能系统级优化来解决这些限制。', 'title_zh': '基于Chiplet的RISC-V SoC模块化AI加速器'}
{'arxiv_id': 'arXiv:2509.18354', 'title': 'A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data', 'authors': 'Mehrdad Moradi, Shengzhe Chen, Hao Yan, Kamran Paynabar', 'link': 'https://arxiv.org/abs/2509.18354', 'abstract': 'Anomaly detection in images is typically addressed by learning from collections of training data or relying on reference samples. In many real-world scenarios, however, such training data may be unavailable, and only the test image itself is provided. We address this zero-shot setting by proposing a single-image anomaly localization method that leverages the inductive bias of convolutional neural networks, inspired by Deep Image Prior (DIP). Our method is named Single Shot Decomposition Network (SSDnet). Our key assumption is that natural images often exhibit unified textures and patterns, and that anomalies manifest as localized deviations from these repetitive or stochastic patterns. To learn the deep image prior, we design a patch-based training framework where the input image is fed directly into the network for self-reconstruction, rather than mapping random noise to the image as done in DIP. To avoid the model simply learning an identity mapping, we apply masking, patch shuffling, and small Gaussian noise. In addition, we use a perceptual loss based on inner-product similarity to capture structure beyond pixel fidelity. Our approach needs no external training data, labels, or references, and remains robust in the presence of noise or missing pixels. SSDnet achieves 0.99 AUROC and 0.60 AUPRC on MVTec-AD and 0.98 AUROC and 0.67 AUPRC on the fabric dataset, outperforming state-of-the-art methods. The implementation code will be released at this https URL', 'abstract_zh': '单张图像异常定位方法：基于卷积神经网络的深度图像先验单图像分解网络', 'title_zh': '无需训练数据：一张图像即可实现零样本异常定位'}
{'arxiv_id': 'arXiv:2509.18316', 'title': 'Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning', 'authors': 'Saksham Khatwani, He Cheng, Majid Afshar, Dmitriy Dligach, Yanjun Gao', 'link': 'https://arxiv.org/abs/2509.18316', 'abstract': 'Large language models (LLMs) show promise for diagnostic reasoning but often lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as the Unified Medical Language System (UMLS), offer structured biomedical knowledge that can support trustworthy reasoning. Prior approaches typically integrate KGs via retrieval augmented generation or fine tuning, inserting KG content into prompts rather than enabling structured reasoning. We explore an alternative paradigm: treating the LLM as a reward model of KG reasoning paths, where the model learns to judge whether a candidate path leads to correct diagnosis for a given patient input. This approach is inspired by recent work that leverages reward training to enhance model reasoning abilities, and grounded in computational theory, which suggests that verifying a solution is often easier than generating one from scratch. It also parallels physicians\' diagnostic assessment, where they judge which sequences of findings and intermediate conditions most plausibly support a diagnosis. We first systematically evaluate five task formulation for knowledge path judging and eight training paradigm. Second, we test whether the path judging abilities generalize to downstream diagnostic tasks, including diagnosis summarization and medical question answering. Experiments with three open source instruct-tuned LLMs reveal both promise and brittleness: while specific reward optimization and distillation lead to strong path-judging performance, the transferability to downstream tasks remain weak. Our finding provides the first systematic assessment of "reward model style" reasoning over clinical KGs, offering insights into how structured, reward-based supervision influences diagnostic reasoning in GenAI systems for healthcare.', 'abstract_zh': '大型语言模型（LLMs）在诊断推理方面展现出潜力，但往往缺乏可靠的、基于知识的推理能力。知识图谱（KGs），如统一医学语言系统（UMLS），提供了结构化的生物医学知识，可支持可信的推理。以往的方法通常通过检索增强生成或微调将KG内容插入提示，而不是实现结构化的推理。我们探索了另一种范式：将LLM视为KG推理路径的奖励模型，其中模型学会判断候选路径是否能为给定的患者输入提供正确的诊断。这种方法受到利用奖励训练增强模型推理能力的最新工作的启发，并基于计算理论的原理，该原理表明验证一个解决方案通常比从零开始生成它要容易得多。它也与医生的诊断评估相似，医生评估哪些发现和中间条件的序列最有可能支持诊断。我们首先系统地评估了五种知识路径判断任务的表述和八种训练范式。其次，我们测试了路径判断能力是否可以泛化到下游的诊断任务，包括诊断总结和医学问答。实验证明了该方法的潜力和脆弱性：虽然特定的奖励优化和蒸馏可以实现强大的路径判断性能，但其向下游任务的迁移能力仍然较弱。我们的研究提供了对临床KG上“奖励模型风格”推理的第一个系统评估，为如何结构化的奖励监督影响医疗保健领域GenAI系统的诊断推理提供了见解。', 'title_zh': 'brittleness and promise: 基于知识图谱的诊断推理奖励建模'}
{'arxiv_id': 'arXiv:2509.18293', 'title': 'Evaluating Large Language Models for Detecting Antisemitism', 'authors': 'Jay Patel, Hrudayangam Mehta, Jeremy Blackburn', 'link': 'https://arxiv.org/abs/2509.18293', 'abstract': "Detecting hateful content is a challenging and important problem. Automated tools, like machine-learning models, can help, but they require continuous training to adapt to the ever-changing landscape of social media. In this work, we evaluate eight open-source LLMs' capability to detect antisemitic content, specifically leveraging in-context definition as a policy guideline. We explore various prompting techniques and design a new CoT-like prompt, Guided-CoT. Guided-CoT handles the in-context policy well, increasing performance across all evaluated models, regardless of decoding configuration, model sizes, or reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5. Additionally, we examine LLM errors and introduce metrics to quantify semantic divergence in model-generated rationales, revealing notable differences and paradoxical behaviors among LLMs. Our experiments highlight the differences observed across LLMs' utility, explainability, and reliability.", 'abstract_zh': '检测 hateful 内容是一个具有挑战性和重要性的问题。自动化工具，如机器学习模型，可以提供帮助，但它们需要持续训练以适应社交媒体不断变化的环境。在这项工作中，我们评估了八种开源大语言模型检测反犹太主义内容的能力，具体利用上下文内定义作为政策指南。我们探索了各种提示技术，并设计了一种新的类似 CoT 的提示——Guided-CoT。Guided-CoT 能很好地处理上下文内政策，提高了所有评估模型的表现，无论解码配置、模型大小或推理能力如何。值得注意的是，Llama 3.1 70B 的表现优于细调的 GPT-3.5。此外，我们还分析了大语言模型的错误，并引入了用于量化模型生成的论据语义差异的指标，揭示了大语言模型之间显著的差异性和悖论性行为。我们的实验突显了大语言模型在实用性、可解释性和可靠性方面的差异。', 'title_zh': '评估大型语言模型检测反犹太主义的能力'}
{'arxiv_id': 'arXiv:2509.18282', 'title': 'PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies', 'authors': 'Jesse Zhang, Marius Memmel, Kevin Kim, Dieter Fox, Jesse Thomason, Fabio Ramos, Erdem Bıyık, Abhishek Gupta, Anqi Li', 'link': 'https://arxiv.org/abs/2509.18282', 'abstract': 'Robotic manipulation policies often fail to generalize because they must simultaneously learn where to attend, what actions to take, and how to execute them. We argue that high-level reasoning about where and what can be offloaded to vision-language models (VLMs), leaving policies to specialize in how to act. We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which fine-tunes VLMs to predict a unified point-based intermediate representation: 1. end-effector paths specifying what actions to take, and 2. task-relevant masks indicating where to focus. These annotations are directly overlaid onto robot observations, making the representation policy-agnostic and transferable across architectures. To enable scalable training, we introduce an automatic annotation pipeline, generating labeled data across 20+ robot datasets spanning 9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot generalization, including a 41.4x real-world improvement for a 3D policy trained only in simulation, and 2-3.5x gains for both large VLAs and small manipulation policies. By letting VLMs absorb semantic and visual complexity, PEEK equips manipulation policies with the minimal cues they need--where, what, and how. Website at this https URL.', 'abstract_zh': '基于视觉语言模型的机器人操作策略往往因为必须同时学习关注何处、采取什么行动以及如何执行而难以迁移。我们主张高层关于何处和什么的推理可以卸载到视觉语言模型（VLMs）上，从而使策略专注于如何行动。我们提出了PEEK（Policy-agnostic Extraction of Essential Keypoints），该方法微调VLMs以预测统一的基于点的中间表示：1. 表示应采取什么行动的末端执行器路径，以及2. 表示需要关注的区域的任务相关掩码。这些标注可以直接叠加到机器人观测上，使表示具有策略无关性和架构间可迁移性。为实现规模化训练，我们引入了一种自动标注流水线，在涵盖9种不同机器人操作模型的20多个数据集中生成了标注数据。在真实世界的评估中，PEEK一致地提升了零样本迁移，包括对于仅在模拟中训练的3D策略在真实世界中的改进达到41.4倍，以及对于大型VLAs和小规模操作策略的2-3.5倍的增益。通过让VLMs吸收语义和视觉复杂性，PEEK为操作策略提供了它们所需的最小线索——何处、什么和如何。网站地址：this https URL。', 'title_zh': 'PEEK: 引导和 minimalist 图像表示以实现机器人操作策略的零样本泛化'}
{'arxiv_id': 'arXiv:2509.18233', 'title': 'Perceptions of AI Across Sectors: A Comparative Review of Public Attitudes', 'authors': 'Filip Bialy, Mark Elliot, Robert Meckin', 'link': 'https://arxiv.org/abs/2509.18233', 'abstract': 'This paper offers a domain-mediated comparative review of 251 studies on public attitudes toward AI, published between 2011 and 2025. Drawing on a systematic literature review, we analyse how different factors including perceived benefits and concerns (or risks) shape public acceptance of - or resistance to - artificial intelligence across domains and use-cases, including healthcare, education, security, public administration, generative AI, and autonomous vehicles. The analysis highlights recurring patterns in individual, contextual, and technical factors influencing perception, while also tracing variations in institutional trust, perceived fairness, and ethical concerns. We show that the public perception in AI is shaped not only by technical design or performance but also by sector-specific considerations as well as imaginaries, cultural narratives, and historical legacies. This comparative approach offers a foundation for developing more tailored and context-sensitive strategies for responsible AI governance.', 'abstract_zh': '本文提供了一种领域导向的比较性综述，分析了2011年至2025年间发表的251篇关于公众对人工智能态度的研究。通过系统文献综述的方法，我们研究了包括感知效益和担忧（或风险）在内的多种因素如何影响人工智能在不同领域和应用场景中的接受度或抵触情绪，这些领域和应用场景包括医疗、教育、安全、公共管理、生成型AI和自主车辆。分析突出了个体、情境和技术因素在感知中反复出现的模式，同时追踪了机构信任、感知公平性和伦理关切方面的变化。我们表明，公众对人工智能的看法不仅受技术设计或性能的影响，还受特定行业考虑、想象、文化叙事和历史遗产的影响。这种比较方法为负责任的人工智能治理提供了更具针对性和情境敏感性的策略基础。', 'title_zh': '跨行业对AI的感知：公众态度的比较 review'}
{'arxiv_id': 'arXiv:2509.18231', 'title': 'Enhanced Interpretable Knowledge Tracing for Students Performance Prediction with Human understandable Feature Space', 'authors': 'Sein Minn, Roger Nkambou', 'link': 'https://arxiv.org/abs/2509.18231', 'abstract': 'Knowledge Tracing (KT) plays a central role in assessing students skill mastery and predicting their future performance. While deep learning based KT models achieve superior predictive accuracy compared to traditional methods, their complexity and opacity hinder their ability to provide psychologically meaningful explanations. This disconnect between model parameters and cognitive theory poses challenges for understanding and enhancing the learning process, limiting their trustworthiness in educational applications. To address these challenges, we enhance interpretable KT models by exploring human-understandable features derived from students interaction data. By incorporating additional features, particularly those reflecting students learning abilities, our enhanced approach improves predictive accuracy while maintaining alignment with cognitive theory. Our contributions aim to balance predictive power with interpretability, advancing the utility of adaptive learning systems.', 'abstract_zh': '知识追踪（KT）在评估学生技能掌握情况和预测其未来表现中起着关键作用。虽然基于深度学习的KT模型相较于传统方法在预测准确性上表现出色，但由于其复杂性和不透明性，这些模型难以提供具有心理意义的解释。模型参数与认知理论之间的这种脱节为理解和改进学习过程带来了挑战，限制了其在教育应用中的可信度。为了解决这些挑战，我们通过探索源自学生交互数据的人类可理解特征来增强可解释的KT模型。通过引入额外特征，特别是反映学生学习能力的特征，我们的增强方法在保持与认知理论一致性的基础上提高了预测准确性。我们的贡献旨在平衡预测能力和解释性，促进自适应学习系统的应用。', 'title_zh': '增强可解释的知识追踪以实现学生性能预测与人类可理解的特征空间'}
{'arxiv_id': 'arXiv:2509.18214', 'title': 'Automatic Classification of Magnetic Chirality of Solar Filaments from H-Alpha Observations', 'authors': 'Alexis Chalmers, Azim Ahmadzadeh', 'link': 'https://arxiv.org/abs/2509.18214', 'abstract': 'In this study, we classify the magnetic chirality of solar filaments from H-Alpha observations using state-of-the-art image classification models. We establish the first reproducible baseline for solar filament chirality classification on the MAGFiLO dataset. The MAGFiLO dataset contains over 10,000 manually-annotated filaments from GONG H-Alpha observations, making it the largest dataset for filament detection and classification to date. Prior studies relied on much smaller datasets, which limited their generalizability and comparability. We fine-tuned several pre-trained, image classification architectures, including ResNet, WideResNet, ResNeXt, and ConvNeXt, and also applied data augmentation and per-class loss weights to optimize the models. Our best model, ConvNeXtBase, achieves a per-class accuracy of 0.69 for left chirality filaments and $0.73$ for right chirality filaments.', 'abstract_zh': '本研究使用最先进的图像分类模型从H-Alpha观测中对太阳细丝的磁旋方向进行分类，并在MAGFiLO数据集上建立了首个可再现的基准。MAGFiLO数据集包含来自GONG H-Alpha观测的逾10,000个手工标注的细丝，使其成为迄今为止用于细丝检测和分类的最大数据集。先前的研究依赖于规模小得多的数据集，限制了其泛化能力和可比性。我们微调了包括ResNet、WideResNet、ResNeXt和ConvNeXt在内的几种预训练的图像分类架构，并应用了数据增强和类别损失权重以优化模型。我们的最佳模型ConvNeXtBase在左旋细丝上的每类别准确率为0.69，在右旋细丝上的每类别准确率为0.73。', 'title_zh': '基于H-α观测的太阳日珥磁旋结构自动分类'}
{'arxiv_id': 'arXiv:2509.18208', 'title': 'Variational Task Vector Composition', 'authors': 'Boyuan Zhang, Yingjun Du, Xiantong Zhen, Ling Shao', 'link': 'https://arxiv.org/abs/2509.18208', 'abstract': 'Task vectors capture how a model changes during fine-tuning by recording the difference between pre-trained and task-specific weights. The composition of task vectors, a key operator in task arithmetic, enables models to integrate knowledge from multiple tasks without incurring additional inference costs. In this paper, we propose variational task vector composition, where composition coefficients are taken as latent variables and estimated in a Bayesian inference framework. Unlike previous methods that operate at the task level, our framework focuses on sample-specific composition. Motivated by the observation of structural redundancy in task vectors, we introduce a Spike-and-Slab prior that promotes sparsity and preserves only the most informative components. To further address the high variance and sampling inefficiency in sparse, high-dimensional spaces, we develop a gated sampling mechanism that constructs a controllable posterior by filtering the composition coefficients based on both uncertainty and importance. This yields a more stable and interpretable variational framework by deterministically selecting reliable task components, reducing sampling variance while improving transparency and generalization. Experimental results demonstrate that our method consistently outperforms existing approaches across all datasets by selectively leveraging the most reliable and informative components in task vectors. These findings highlight the practical value of our approach, establishing a new standard for efficient and effective task vector composition.', 'abstract_zh': '变分任务向量组成：一种样本特定的贝叶斯框架', 'title_zh': '变分任务向量组合'}
{'arxiv_id': 'arXiv:2509.18200', 'title': 'Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought', 'authors': 'Yu Ti Huang', 'link': 'https://arxiv.org/abs/2509.18200', 'abstract': 'Conversational agents must translate egocentric utterances (e.g., "on my right") into allocentric orientations (N/E/S/W). This challenge is particularly critical in indoor or complex facilities where GPS signals are weak and detailed maps are unavailable. While chain-of-thought (CoT) prompting has advanced reasoning in language and vision tasks, its application to multimodal spatial orientation remains underexplored. We introduce Conversational Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese conversational navigation projected from real-world environments, addressing egocentric-to-allocentric reasoning in non-English and ASR-transcribed scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which integrates ASR-transcribed speech with landmark coordinates through a structured three-step reasoning process: (1) extracting spatial relations, (2) mapping coordinates to absolute directions, and (3) inferring user orientation. A curriculum learning strategy progressively builds these capabilities on Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of resource-constrained settings. Experiments show that MCoT achieves 100% orientation accuracy on clean transcripts and 98.1% with ASR transcripts, substantially outperforming unimodal and non-structured baselines. Moreover, MCoT demonstrates robustness under noisy conversational conditions, including ASR recognition errors and multilingual code-switching. The model also maintains high accuracy in cross-domain evaluation and resilience to linguistic variation, domain shift, and referential ambiguity. These findings highlight the potential of structured MCoT spatial reasoning as a path toward interpretable and resource-efficient embodied navigation.', 'abstract_zh': '对话代理必须将以自我为中心的陈述（例如，“在我右边”）转换为他我中心的方向（N/E/S/W）。这一挑战在GPS信号弱且详细地图不可用的室内或复杂设施中尤为重要。虽然思维链（CoT）提示在语言和视觉任务中提高了推理能力，但在多模态空间定向领域的应用仍不够充分。我们引入了对话方向推理（COR），这是一个旨在中文对话导航任务中利用现实环境中数据的新基准，解决非英语和ASR转录的以自我为中心到他我中心的推理问题。我们提出了一种多模态思维链（MCoT）框架，该框架通过结构化的三步推理过程将ASR转录的语音与地标坐标结合：（1）提取空间关系，（2）映射坐标到绝对方向，（3）推断用户方向。一种 Curriculum 学习策略逐步在Taiwan-LLM-13B-v2.0-Chat上构建这些能力，这是一种代表资源受限设置的中型模型。实验结果显示，MCoT在干净的转录本中实现了100%的方向准确性，并在ASR转录本中达到了98.1%的准确性，显著优于单模态和非结构化基线。此外，MCoT在嘈杂的对话条件下表现出色，包括ASR识别错误和多语言切换。该模型在跨域评估中保持了高准确性，并对语言变体、领域转移和指代歧义具有抗干扰性。这些发现突显了结构化MCoT空间推理作为可解释和资源高效的体感导航途径的潜力。', 'title_zh': '自中心到他中心的对话导向推理：多模态链式思考导航'}
{'arxiv_id': 'arXiv:2509.18196', 'title': 'MNV-17: A High-Quality Performative Mandarin Dataset for Nonverbal Vocalization Recognition in Speech', 'authors': 'Jialong Mai, Jinxin Ji, Xiaofen Xing, Chen Yang, Weidong Chen, Jingyuan Xing, Xiangmin Xu', 'link': 'https://arxiv.org/abs/2509.18196', 'abstract': "Mainstream Automatic Speech Recognition (ASR) systems excel at transcribing lexical content, but largely fail to recognize nonverbal vocalizations (NVs) embedded in speech, such as sighs, laughs, and coughs. This capability is important for a comprehensive understanding of human communication, as NVs convey crucial emotional and intentional cues. Progress in NV-aware ASR has been hindered by the lack of high-quality, well-annotated datasets. To address this gap, we introduce MNV-17, a 7.55-hour performative Mandarin speech dataset. Unlike most existing corpora that rely on model-based detection, MNV-17's performative nature ensures high-fidelity, clearly articulated NV instances. To the best of our knowledge, MNV-17 provides the most extensive set of nonverbal vocalization categories, comprising 17 distinct and well-balanced classes of common NVs. We benchmarked MNV-17 on four mainstream ASR architectures, evaluating their joint performance on semantic transcription and NV classification. The dataset and the pretrained model checkpoints will be made publicly available to facilitate future research in expressive ASR.", 'abstract_zh': '主流自动语音识别系统在转录词汇内容方面表现出色，但在识别嵌入在语音中的非言语声音（如叹息、笑声和咳嗽）方面效果不佳。这种能力对于全面理解人类交流至关重要，因为非言语声音传达关键的情感和意图线索。由于缺乏高质量的注释数据集，使得非言语声音意识的自动语音识别进展受阻。为弥补这一差距，我们介绍了MNV-17，这是一个7.55小时的表演性 Mandarin 语音数据集。与大多数依赖于基于模型的检测的数据集不同，MNV-17 的表演性质确保了高质量、清晰表达的非言语声音实例。据我们所知，MNV-17 提供了最广泛的非言语声音类别集，包括17种常见非言语声音的平衡分类。我们对四个主流自动语音识别架构进行了基准测试，评估了它们在语义转写和非言语声音分类上的联合性能。该数据集及预训练模型检查点将公开发布，以促进未来具有表现力的自动语音识别研究。', 'title_zh': 'MNV-17：用于语音中非言语 vocalization 识别的高质量表现型 Mandarin 数据集'}
{'arxiv_id': 'arXiv:2509.18193', 'title': 'TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection', 'authors': 'Omar H. Khater, Abdul Jabbar Siddiqui, Aiman El-Maleh, M. Shamim Hossain', 'link': 'https://arxiv.org/abs/2509.18193', 'abstract': "Deploying deep learning models in agriculture is difficult because edge devices have limited resources, but this work presents a compressed version of EcoWeedNet using structured channel pruning, quantization-aware training (QAT), and acceleration with NVIDIA's TensorRT on the Jetson Orin Nano. Despite the challenges of pruning complex architectures with residual shortcuts, attention mechanisms, concatenations, and CSP blocks, the model size was reduced by up to 68.5% and computations by 3.2 GFLOPs, while inference speed reached 184 FPS at FP16, 28.7% faster than the baseline. On the CottonWeedDet12 dataset, the pruned EcoWeedNet with a 39.5% pruning ratio outperformed YOLO11n and YOLO12n (with only 20% pruning), achieving 83.7% precision, 77.5% recall, and 85.9% mAP50, proving it to be both efficient and effective for precision agriculture.", 'abstract_zh': '使用结构化信道修剪、量化感知训练和NVIDIA TensorRT加速，本工作提出了EcoWeedNet的压缩版本，应用于农业中的深度学习模型部署。尽管面对含有残差捷径、注意力机制、拼接和CSP模块的复杂架构修剪挑战，模型大小减少至最大68.5%，计算量减少3.2 GFLOPs，推理速度达到184 FPS，优于FP16基本模型28.7%。在CottonWeedDet12数据集上，39.5%修剪比的EcoWeedNet优于YOLO11n和YOLO12n（仅修剪20%），精度83.7%，召回率77.5%，mAP50为85.9%，证明其在精准农业中高效且有效。', 'title_zh': 'TinyEcoWeedNet: 边缘高效实时航空农业杂草检测'}
{'arxiv_id': 'arXiv:2509.18190', 'title': 'HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing', 'authors': 'Junseong Shin, Seungwoo Chung, Yunjeong Yang, Tae Hyun Kim', 'link': 'https://arxiv.org/abs/2509.18190', 'abstract': 'Dehazing involves removing haze or fog from images to restore clarity and improve visibility by estimating atmospheric scattering effects. While deep learning methods show promise, the lack of paired real-world training data and the resulting domain gap hinder generalization to real-world scenarios. In this context, physics-grounded learning becomes crucial; however, traditional methods based on the Atmospheric Scattering Model (ASM) often fall short in handling real-world complexities and diverse haze patterns. To solve this problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF), HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones, enhancing real-world dehazing performance with only a single inference step. Additionally, we introduce a non-homogeneous haze generation method using Markov Chain Brownian Motion (MCBM) to address the scarcity of paired real-world data. By simulating realistic haze patterns through MCBM, we enhance the adaptability of HazeFlow to diverse real-world scenarios. Through extensive experiments, we demonstrate that HazeFlow achieves state-of-the-art performance across various real-world dehazing benchmark datasets.', 'abstract_zh': '去雾涉及从图像中去除雾或 Fog，通过估计大气散射效应来恢复清晰度和改善可见度。尽管深度学习方法显示出潜力，但由于缺乏配对的实际训练数据和由此产生的领域差距，其泛化能力受限于实际场景。在这种背景下，基于物理的学习变得至关重要；然而，传统的基于大气散射模型（ASM）的方法往往在处理现实世界的复杂性和多样化的雾状模式时表现不佳。为了解决这个问题，我们提出了 HazeFlow，一种基于ODE的新颖框架，将ASM重新公式化为常微分方程（ODE）。受修正流（RF）的启发，HazeFlow 学习一个最优的 ODE 轨迹，将雾状图像映射为干净图像，仅通过单次推理步骤便提升了实际去雾性能。此外，我们引入了一种基于马尔可夫链布朗运动（MCBM）的非齐次去雾生成方法，以应对配对实际数据的稀缺性。通过 MCBM 模拟现实雾状模式，我们增强了 HazeFlow 对多种实际场景的适应性。通过广泛的实验，我们展示了 HazeFlow 在各种实际去雾基准数据集上达到了最先进的性能。', 'title_zh': 'HazeFlow: 重新审视散射模型作为ODE及其在真实世界去雾霾中的非均匀生成方法'}
{'arxiv_id': 'arXiv:2509.18189', 'title': 'Qianfan-VL: Domain-Enhanced Universal Vision-Language Models', 'authors': 'Daxiang Dong, Mingming Zheng, Dong Xu, Bairong Zhuang, Wenyu Zhang, Chunhua Luo, Haoran Wang, Zijian Zhao, Jie Li, Yuxuan Li, Hanjun Zhong, Mengyue Liu, Jieting Chen, Shupeng Li, Lun Tian, Yaping Feng, Xin Li, Donggang Jiang, Yong Chen, Yehua Xu, Duohao Qin, Chen Feng, Dan Wang, Henghua Zhang, Jingjing Ha, Jinhui He, Yanfeng Zhai, Chengxin Zheng, Jiayi Mao, Jiacheng Chen, Ruchang Yao, Ziye Yuan, Jianmin Wu, Guangjun Xie, Dou Shen', 'link': 'https://arxiv.org/abs/2509.18189', 'abstract': "We present Qianfan-VL, a series of multimodal large language models ranging from 3B to 70B parameters, achieving state-of-the-art performance through innovative domain enhancement techniques. Our approach employs multi-stage progressive training and high-precision data synthesis pipelines, which prove to be critical technologies for enhancing domain-specific capabilities while maintaining strong general performance. Qianfan-VL achieves comparable results to leading open-source models on general benchmarks, with state-of-the-art performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and MMStar. The domain enhancement strategy delivers significant advantages in OCR and document understanding, validated on both public benchmarks (OCRBench 873, DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B variants incorporate long chain-of-thought capabilities, demonstrating superior performance on mathematical reasoning (MathVista 78.6%) and logical inference tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating the capability of large-scale AI infrastructure to train SOTA-level multimodal models with over 90% scaling efficiency on 5000 chips for a single task. This work establishes an effective methodology for developing domain-enhanced multimodal models suitable for diverse enterprise deployment scenarios.", 'abstract_zh': 'Qianfan-VL：通过创新领域增强技术的多模态大型语言模型系列', 'title_zh': '千帆-VL：领域增强的通用视觉-语言模型'}
{'arxiv_id': 'arXiv:2509.18187', 'title': 'V-SenseDrive: A Privacy-Preserving Road Video and In-Vehicle Sensor Fusion Framework for Road Safety & Driver Behaviour Modelling', 'authors': 'Muhammad Naveed, Nazia Perwaiz, Sidra Sultana, Mohaira Ahmad, Muhammad Moazam Fraz', 'link': 'https://arxiv.org/abs/2509.18187', 'abstract': "Road traffic accidents remain a major public health challenge, particularly in countries with heterogeneous road conditions, mixed traffic flow, and variable driving discipline, such as Pakistan. Reliable detection of unsafe driving behaviours is a prerequisite for improving road safety, enabling advanced driver assistance systems (ADAS), and supporting data driven decisions in insurance and fleet management. Most of existing datasets originate from the developed countries with limited representation of the behavioural diversity observed in emerging economies and the driver's face recording voilates the privacy preservation. We present V-SenseDrive, the first privacy-preserving multimodal driver behaviour dataset collected entirely within the Pakistani driving environment. V-SenseDrive combines smartphone based inertial and GPS sensor data with synchronized road facing video to record three target driving behaviours (normal, aggressive, and risky) on multiple types of roads, including urban arterials, secondary roads, and motorways. Data was gathered using a custom Android application designed to capture high frequency accelerometer, gyroscope, and GPS streams alongside continuous video, with all sources precisely time aligned to enable multimodal analysis. The focus of this work is on the data acquisition process, covering participant selection, driving scenarios, environmental considerations, and sensor video synchronization techniques. The dataset is structured into raw, processed, and semantic layers, ensuring adaptability for future research in driver behaviour classification, traffic safety analysis, and ADAS development. By representing real world driving in Pakistan, V-SenseDrive fills a critical gap in the global landscape of driver behaviour datasets and lays the groundwork for context aware intelligent transportation solutions.", 'abstract_zh': '隐私保护的多模态司机行为数据集V-SenseDrive', 'title_zh': 'V-SenseDrive：一种保护隐私的道路上视频与车内传感器融合框架，用于道路安全与驾驶员行为建模'}
{'arxiv_id': 'arXiv:2509.18185', 'title': 'Visionerves: Automatic and Reproducible Hybrid AI for Peripheral Nervous System Recognition Applied to Endometriosis Cases', 'authors': 'Giammarco La Barbera, Enzo Bonnot, Thomas Isla, Juan Pablo de la Plata, Joy-Rose Dunoyer de Segonzac, Jennifer Attali, Cécile Lozach, Alexandre Bellucci, Louis Marcellin, Laure Fournier, Sabine Sarnacki, Pietro Gori, Isabelle Bloch', 'link': 'https://arxiv.org/abs/2509.18185', 'abstract': 'Endometriosis often leads to chronic pelvic pain and possible nerve involvement, yet imaging the peripheral nerves remains a challenge. We introduce Visionerves, a novel hybrid AI framework for peripheral nervous system recognition from multi-gradient DWI and morphological MRI data. Unlike conventional tractography, Visionerves encodes anatomical knowledge through fuzzy spatial relationships, removing the need for selection of manual ROIs. The pipeline comprises two phases: (A) automatic segmentation of anatomical structures using a deep learning model, and (B) tractography and nerve recognition by symbolic spatial reasoning. Applied to the lumbosacral plexus in 10 women with (confirmed or suspected) endometriosis, Visionerves demonstrated substantial improvements over standard tractography, with Dice score improvements of up to 25% and spatial errors reduced to less than 5 mm. This automatic and reproducible approach enables detailed nerve analysis and paves the way for non-invasive diagnosis of endometriosis-related neuropathy, as well as other conditions with nerve involvement.', 'abstract_zh': 'Visionerves：一种用于多梯度DWI和形态学MRI数据中周围神经系统识别的新型混合AI框架', 'title_zh': 'Visionerves：自动且可再现的混合人工智能在外周神经系统识别中的应用——以子宫内膜异位症病例为例'}
{'arxiv_id': 'arXiv:2509.18183', 'title': 'VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation', 'authors': 'Jinyue Bian, Zhaoxing Zhang, Zhengyu Liang, Shiwei Zheng, Shengtao Zhang, Rong Shen, Chen Yang, Anzhou Hou', 'link': 'https://arxiv.org/abs/2509.18183', 'abstract': 'The Visual-Language-Action (VLA) models can follow text instructions according to visual observations of the surrounding environment. This ability to map multimodal inputs to actions is derived from the training of the VLA model on extensive standard demonstrations. These visual observations captured by third-personal global and in-wrist local cameras are inevitably varied in number and perspective across different environments, resulting in significant differences in the visual features. This perspective heterogeneity constrains the generality of VLA models. In light of this, we first propose the lightweight module VLA-LPAF to foster the perspective adaptivity of VLA models using only 2D data. VLA-LPAF is finetuned using images from a single view and fuses other multiview observations in the latent space, which effectively and efficiently bridge the gap caused by perspective inconsistency. We instantiate our VLA-LPAF framework with the VLA model RoboFlamingo to construct RoboFlamingo-LPAF. Experiments show that RoboFlamingo-LPAF averagely achieves around 8% task success rate improvement on CALVIN, 15% on LIBERO, and 30% on a customized simulation benchmark. We also demonstrate the developed viewadaptive characteristics of the proposed RoboFlamingo-LPAF through real-world tasks.', 'abstract_zh': '基于视觉-语言-动作（VLA）模型的视角自适应模块VLA-LPAF', 'title_zh': 'VLA-LPAF：轻量级视角自适应融合，以实现更不受约束的机器人操作Manipulation'}
{'arxiv_id': 'arXiv:2509.18179', 'title': 'The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes', 'authors': 'Sai Varun Kodathala, Rakesh Vunnam', 'link': 'https://arxiv.org/abs/2509.18179', 'abstract': 'With the increasing integration of multimodal AI systems in creative workflows, understanding information loss in vision-language-vision pipelines has become important for evaluating system limitations. However, the degradation that occurs when visual content passes through textual intermediation remains poorly quantified. In this work, we provide empirical analysis of the describe-then-generate bottleneck, where natural language serves as an intermediate representation for visual information. We generated 150 image pairs through the describe-then-generate pipeline and applied existing metrics (LPIPS, SSIM, and color distance) to measure information preservation across perceptual, structural, and chromatic dimensions. Our evaluation reveals that 99.3% of samples exhibit substantial perceptual degradation and 91.5% demonstrate significant structural information loss, providing empirical evidence that the describe-then-generate bottleneck represents a measurable and consistent limitation in contemporary multimodal systems.', 'abstract_zh': '随着多模态人工智能系统在创意工作流程中的集成日益增加，理解视觉-语言-视觉管道中的信息损失对于评估系统限制变得重要。然而，视觉内容通过文本中介传递时发生的降级现象仍缺乏量化。在本工作中，我们对“描述-生成”瓶颈进行了实证分析，其中自然语言作为视觉信息的中间表示。我们生成了150个图像对，并应用现有的度量标准（LPIPS、SSIM和色彩距离）来衡量感知、结构和色调维度上的信息保存情况。我们的评估表明，99.3%的样本表现出显著的感知降级，91.5%的样本显示出明显的结构信息损失，这提供了实证证据，表明“描述-生成”瓶颈是当前多模态系统中可测量且一致的限制。', 'title_zh': '描述然后生成的瓶颈：VLM描述如何改变图像生成的结果'}
{'arxiv_id': 'arXiv:2509.18177', 'title': 'A Framework for Generating Artificial Datasets to Validate Absolute and Relative Position Concepts', 'authors': 'George Corrêa de Araújo, Helena de Almeida Maia, Helio Pedrini', 'link': 'https://arxiv.org/abs/2509.18177', 'abstract': "In this paper, we present the Scrapbook framework, a novel methodology designed to generate extensive datasets for probing the learned concepts of artificial intelligence (AI) models. The framework focuses on fundamental concepts such as object recognition, absolute and relative positions, and attribute identification. By generating datasets with a large number of questions about individual concepts and a wide linguistic variation, the Scrapbook framework aims to validate the model's understanding of these basic elements before tackling more complex tasks. Our experimental findings reveal that, while contemporary models demonstrate proficiency in recognizing and enumerating objects, they encounter challenges in comprehending positional information and addressing inquiries with additional constraints. Specifically, the MobileVLM-V2 model showed significant answer disagreements and plausible wrong answers, while other models exhibited a bias toward affirmative answers and struggled with questions involving geometric shapes and positional information, indicating areas for improvement in understanding and consistency. The proposed framework offers a valuable instrument for generating diverse and comprehensive datasets, which can be utilized to systematically assess and enhance the performance of AI models.", 'abstract_zh': '本文介绍了Scrapbook框架，这是一个新颖的方法学，用于生成大量数据集以探究人工 intelligence (AI) 模型学习的概念。该框架专注于对象识别、绝对和相对位置以及属性识别等基本概念。通过生成包含大量关于个体概念的问题和广泛语言变体的数据集，Scrapbook框架旨在在处理更复杂任务之前验证模型对这些基本元素的理解。实验结果表明，尽管当代模型在识别和枚举对象方面表现出色，但在理解位置信息和处理附加约束的问题时遇到了挑战。特别是，MobileVLM-V2模型在回答问题时显示出显著的分歧和合理的错误回答，而其他模型则倾向于给出肯定的答案，并在涉及几何形状和位置信息的问题上挣扎，这表明理解和一致性方面存在改进的空间。所提出的方法提供了一种有价值的工具，用于生成多样且全面的数据集，这些数据集可以系统地评估和提高AI模型的性能。', 'title_zh': '一种用于验证绝对位置和相对位置概念的人工数据集生成框架'}
{'arxiv_id': 'arXiv:2509.18161', 'title': 'Developing Training Procedures for Piecewise-linear Spline Activation Functions in Neural Networks', 'authors': 'William H Patty', 'link': 'https://arxiv.org/abs/2509.18161', 'abstract': "Activation functions in neural networks are typically selected from a set of empirically validated, commonly used static functions such as ReLU, tanh, or sigmoid. However, by optimizing the shapes of a network's activation functions, we can train models that are more parameter-efficient and accurate by assigning more optimal activations to the neurons. In this paper, I present and compare 9 training methodologies to explore dual-optimization dynamics in neural networks with parameterized linear B-spline activation functions. The experiments realize up to 94% lower end model error rates in FNNs and 51% lower rates in CNNs compared to traditional ReLU-based models. These gains come at the cost of additional development and training complexity as well as end model latency.", 'abstract_zh': '具有参数化线性B样条激活函数的神经网络中的双优化动态训练方法比较', 'title_zh': '开发分段线性样条激活函数在神经网络中的训练程序'}
{'arxiv_id': 'arXiv:2509.18156', 'title': 'Event Causality Identification with Synthetic Control', 'authors': 'Haoyu Wang, Fengze Liu, Jiayao Zhang, Dan Roth, Kyle Richardson', 'link': 'https://arxiv.org/abs/2509.18156', 'abstract': "Event causality identification (ECI), a process that extracts causal relations between events from text, is crucial for distinguishing causation from correlation. Traditional approaches to ECI have primarily utilized linguistic patterns and multi-hop relational inference, risking false causality identification due to informal usage of causality and specious graphical inference. In this paper, we adopt the Rubin Causal Model to identify event causality: given two temporally ordered events, we see the first event as the treatment and the second one as the observed outcome. Determining their causality involves manipulating the treatment and estimating the resultant change in the likelihood of the outcome. Given that it is only possible to implement manipulation conceptually in the text domain, as a work-around, we try to find a twin for the protagonist from existing corpora. This twin should have identical life experiences with the protagonist before the treatment but undergoes an intervention of treatment. However, the practical difficulty of locating such a match limits its feasibility. Addressing this issue, we use the synthetic control method to generate such a twin' from relevant historical data, leveraging text embedding synthesis and inversion techniques. This approach allows us to identify causal relations more robustly than previous methods, including GPT-4, which is demonstrated on a causality benchmark, COPES-hard.", 'abstract_zh': '事件因果识别（ECI）：一种从文本中提取事件间因果关系的过程，对于区分因果关系和相关关系至关重要。传统ECI方法主要依赖于语言模式和多跳关系推理，因因果概念的非正式使用和虚假图形推理而存在虚假因果识别的风险。在本文中，我们采用鲁宾因果模型来识别事件因果关系：给定两个时间顺序事件，我们将第一个事件视为处理，第二个事件视为观测结果。确定它们的因果关系涉及对处理进行操作并估计结果事件概率变化。由于在文本领域仅能从概念上实现这种操作，我们尝试在现有语料库中找到处理前具有相同生活经历但接受相同处理干预的主角孪生体。然而，找到这种匹配的实际困难限制了其可行性。为解决这一问题，我们使用合成控制方法从相关历史数据中生成这种孪生体，利用文本嵌入合成和反转技术。这种方法使得我们能够比GPT-4等先前方法更稳健地识别因果关系，在COPES-hard这种因果关系基准测试上得到了验证。', 'title_zh': '事件因果关系识别的合成控制方法'}
{'arxiv_id': 'arXiv:2509.18152', 'title': 'WLFM: A Well-Logs Foundation Model for Multi-Task and Cross-Well Geological Interpretation', 'authors': 'Zhenyu Qi, Qing Yu, Jichen Wang, Yun-Bo Zhao, Zerui Li, Wenjun Lv', 'link': 'https://arxiv.org/abs/2509.18152', 'abstract': 'Well-log interpretation is fundamental for subsurface characterization but remains challenged by heterogeneous tool responses, noisy signals, and limited labels. We propose WLFM, a foundation model pretrained on multi-curve logs from 1200 wells, comprising three stages: tokenization of log patches into geological tokens, self-supervised pretraining with masked-token modeling and stratigraphy-aware contrastive learning, and multi-task adaptation with few-shot fine-tuning. WLFM consistently outperforms state-of-the-art baselines, achieving 0.0041 MSE in porosity estimation and 74.13\\% accuracy in lithology classification, while WLFM-Finetune further improves to 0.0038 MSE and 78.10\\% accuracy. Beyond predictive accuracy, WLFM exhibits emergent layer-awareness, learns a reusable geological vocabulary, and reconstructs masked curves with reasonable fidelity, though systematic offsets are observed in shallow and ultra-deep intervals. Although boundary detection is not explicitly evaluated here, clustering analyses suggest strong potential for future extension. These results establish WLFM as a scalable, interpretable, and transferable backbone for geological AI, with implications for multi-modal integration of logs, seismic, and textual data.', 'abstract_zh': '井 Logging 解释是地下表征的基础，但仍然受到异质工具响应、噪声信号和有限标签的挑战。我们提出了一种名为 WLFM 的基础模型，该模型在来自 1200 口井的多曲线井资料上进行预训练，包括三个阶段：井资料片段的地质标记化、掩码标记建模和地层意识对比学习的自监督预训练，以及少样本微调下的多任务适应。WLFM 在孔隙度估算和岩石分类方面均优于现有baseline，达到 0.0041 的 MSE 和 74.13% 的准确率，而 WLFM-Finetune 进一步提高至 0.0038 的 MSE 和 78.10% 的准确率。除了预测精度外，WLFM 还表现出层感知能力，学习到可重用的地质词汇，并合理地重建掩模曲线，尽管在浅部和超深区间观察到系统性偏移。虽然边界检测未在此处显式评估，但聚类分析表明其对未来扩展具有强大的潜力。这些结果确立了 WLFM 作为地质 AI 的可扩展、可解释且可迁移的基础架构，具有将井资料、地震和文本数据多模态集成的应用前景。', 'title_zh': 'WLFM：一种井 Logging 基础模型用于多任务和跨井地质解释'}
{'arxiv_id': 'arXiv:2509.18151', 'title': 'HyperNAS: Enhancing Architecture Representation for NAS Predictor via Hypernetwork', 'authors': 'Jindi Lv, Yuhao Zhou, Yuxin Tian, Qing Ye, Wentao Feng, Jiancheng Lv', 'link': 'https://arxiv.org/abs/2509.18151', 'abstract': 'Time-intensive performance evaluations significantly impede progress in Neural Architecture Search (NAS). To address this, neural predictors leverage surrogate models trained on proxy datasets, allowing for direct performance predictions for new architectures. However, these predictors often exhibit poor generalization due to their limited ability to capture intricate relationships among various architectures. In this paper, we propose HyperNAS, a novel neural predictor paradigm for enhancing architecture representation learning. HyperNAS consists of two primary components: a global encoding scheme and a shared hypernetwork. The global encoding scheme is devised to capture the comprehensive macro-structure information, while the shared hypernetwork serves as an auxiliary task to enhance the investigation of inter-architecture patterns. To ensure training stability, we further develop a dynamic adaptive multi-task loss to facilitate personalized exploration on the Pareto front. Extensive experiments across five representative search spaces, including ViTs, demonstrate the advantages of HyperNAS, particularly in few-shot scenarios. For instance, HyperNAS strikes new state-of-the-art results, with 97.60\\% top-1 accuracy on CIFAR-10 and 82.4\\% top-1 accuracy on ImageNet, using at least 5.0$\\times$ fewer samples.', 'abstract_zh': '基于时间的性能评估显著阻碍了神经架构搜索（NAS）的进展。为解决这一问题，神经预测器利用基于代理数据集训练的代理模型，可以直接对新架构的性能进行预测。然而，这些预测器由于难以捕捉各种架构间的复杂关系，常常表现出较差的泛化能力。本文提出HyperNAS，一种增强架构表示学习的新型神经预测器范式。HyperNAS包含两个主要组成部分：全局编码方案和共享超网络。全局编码方案旨在捕捉全面的宏观结构信息，而共享超网络作为一种辅助任务，用于增强对架构间模式的研究。为确保训练稳定性，我们进一步开发了一种动态自适应多任务损失，以促进帕累托前沿上的个性化探索。在包括ViTs在内的五个代表性搜索空间上进行的广泛实验表明，HyperNAS在少样本情况下尤其具有优势。例如，HyperNAS在CIFAR-10上实现了97.60%的 top-1 准确率，在ImageNet上实现了82.4%的 top-1 准确率，仅使用了至少5.0倍 fewer 的样本数量就取得了新的最佳结果。', 'title_zh': 'HyperNAS：通过超网络增强架构表示以提升NAS预测器性能'}
{'arxiv_id': 'arXiv:2509.18150', 'title': 'Sparse Training Scheme for Multimodal LLM', 'authors': 'Kean Shi, Liang Chen, Haozhe Zhao, Baobao Chang', 'link': 'https://arxiv.org/abs/2509.18150', 'abstract': 'Multimodal Large Language Models (MLLMs) have demonstrated outstanding performance across a variety of domains. However, training MLLMs is often inefficient due to the significantly longer input sequences introduced by multimodal data and the low utilization of inter-layer computations. To address this challenge, we shift the focus to the training process itself and propose a novel training-efficient framework based on sparse representations, termed the Sparse Training Scheme (STS). This scheme consists of two key components: the Visual Token Compressor, which reduces the information load by compressing visual tokens, and the Layer Dynamic Skipper, which mitigates the computational overhead by dynamically skipping unnecessary layers in the language model during both forward and backward passes. Our approach is broadly applicable to diverse MLLM architectures and has been extensively evaluated on multiple benchmarks, demonstrating its effectiveness and efficiency.', 'abstract_zh': '多模态大型语言模型（MLLMs）在多个领域展现了出色的性能。然而，由于多模态数据引入的显著更长的输入序列以及层间计算利用效率低的问题，MLLMs的训练通常效率低下。为解决这一挑战，我们将焦点转向训练过程本身，并提出了一种基于稀疏表示的新颖训练高效框架，称为稀疏训练方案（STS）。该方案包含两个关键组件：视觉标记压缩器，通过压缩视觉标记来减少信息负载；以及层动态跳过器，在语言模型的前向和后向传递过程中动态跳过不必要的层，从而减轻计算开销。该方法适用于各种MLLM架构，并在多个基准上进行了广泛评估，展示了其有效性和效率。', 'title_zh': '多模态大规模语言模型的稀疏训练方案'}
{'arxiv_id': 'arXiv:2509.18148', 'title': 'Augmenting Limited and Biased RCTs through Pseudo-Sample Matching-Based Observational Data Fusion Method', 'authors': 'Kairong Han, Weidong Huang, Taiyang Zhou, Peng Zhen, Kun Kuang', 'link': 'https://arxiv.org/abs/2509.18148', 'abstract': 'In the online ride-hailing pricing context, companies often conduct randomized controlled trials (RCTs) and utilize uplift models to assess the effect of discounts on customer orders, which substantially influences competitive market outcomes. However, due to the high cost of RCTs, the proportion of trial data relative to observational data is small, which only accounts for 0.65\\% of total traffic in our context, resulting in significant bias when generalizing to the broader user base. Additionally, the complexity of industrial processes reduces the quality of RCT data, which is often subject to heterogeneity from potential interference and selection bias, making it difficult to correct. Moreover, existing data fusion methods are challenging to implement effectively in complex industrial settings due to the high dimensionality of features and the strict assumptions that are hard to verify with real-world data. To address these issues, we propose an empirical data fusion method called pseudo-sample matching. By generating pseudo-samples from biased, low-quality RCT data and matching them with the most similar samples from large-scale observational data, the method expands the RCT dataset while mitigating its heterogeneity. We validated the method through simulation experiments, conducted offline and online tests using real-world data. In a week-long online experiment, we achieved a 0.41\\% improvement in profit, which is a considerable gain when scaled to industrial scenarios with hundreds of millions in revenue. In addition, we discuss the harm to model training, offline evaluation, and online economic benefits when the RCT data quality is not high, and emphasize the importance of improving RCT data quality in industrial scenarios. Further details of the simulation experiments can be found in the GitHub repository this https URL.', 'abstract_zh': '基于在线网约车定价背景下的试验数据与提升模型融合方法：伪样例匹配方法的研究', 'title_zh': '通过伪样本匹配基于观察数据融合方法增强有限的偏倚随机对照试验'}
{'arxiv_id': 'arXiv:2509.18147', 'title': 'ConceptFlow: Hierarchical and Fine-grained Concept-Based Explanation for Convolutional Neural Networks', 'authors': 'Xinyu Mu, Hui Dou, Furao Shen, Jian Zhao', 'link': 'https://arxiv.org/abs/2509.18147', 'abstract': 'Concept-based interpretability for Convolutional Neural Networks (CNNs) aims to align internal model representations with high-level semantic concepts, but existing approaches largely overlook the semantic roles of individual filters and the dynamic propagation of concepts across layers. To address these limitations, we propose ConceptFlow, a concept-based interpretability framework that simulates the internal "thinking path" of a model by tracing how concepts emerge and evolve across layers. ConceptFlow comprises two key components: (i) concept attentions, which associate each filter with relevant high-level concepts to enable localized semantic interpretation, and (ii) conceptual pathways, derived from a concept transition matrix that quantifies how concepts propagate and transform between filters. Together, these components offer a unified and structured view of internal model reasoning. Experimental results demonstrate that ConceptFlow yields semantically meaningful insights into model reasoning, validating the effectiveness of concept attentions and conceptual pathways in explaining decision behavior. By modeling hierarchical conceptual pathways, ConceptFlow provides deeper insight into the internal logic of CNNs and supports the generation of more faithful and human-aligned explanations.', 'abstract_zh': '基于概念的卷积神经网络可解释性旨在将模型的内部表示与高级语义概念对齐，但现有方法大多忽视了单个滤波器的语义角色以及概念在层间动态传播的作用。为了解决这些局限性，我们提出了ConceptFlow，这是一种基于概念的可解释性框架，通过跟踪概念如何在层间涌现和发展来模拟模型的内部“思考路径”。ConceptFlow 包括两个关键组件：（i）概念注意力，它将每个滤波器与相关的高级概念关联起来，以实现局部语义解释；（ii）概念路径，它们源自一个概念转换矩阵，量化了概念在滤波器之间传播和转化的方式。这两个组件共同提供了对内部模型推理的统一且结构化的视角。实验结果表明，ConceptFlow 提供了有意义的语义洞察，验证了概念注意力和概念路径在解释决策行为中的有效性。通过建模层级概念路径，ConceptFlow 为理解和生成更忠实且符合人类认知的解释提供了更深入的洞察，支持了卷积神经网络内部逻辑的解释。', 'title_zh': 'ConceptFlow：基于概念的分层级和细粒度解释卷积神经网络'}
{'arxiv_id': 'arXiv:2509.18145', 'title': 'Early Prediction of Multi-Label Care Escalation Triggers in the Intensive Care Unit Using Electronic Health Records', 'authors': 'Syed Ahmad Chan Bukhari, Amritpal Singh, Shifath Hossain, Iram Wajahat', 'link': 'https://arxiv.org/abs/2509.18145', 'abstract': 'Intensive Care Unit (ICU) patients often present with complex, overlapping signs of physiological deterioration that require timely escalation of care. Traditional early warning systems, such as SOFA or MEWS, are limited by their focus on single outcomes and fail to capture the multi-dimensional nature of clinical decline. This study proposes a multi-label classification framework to predict Care Escalation Triggers (CETs), including respiratory failure, hemodynamic instability, renal compromise, and neurological deterioration, using the first 24 hours of ICU data. Using the MIMIC-IV database, CETs are defined through rule-based criteria applied to data from hours 24 to 72 (for example, oxygen saturation below 90, mean arterial pressure below 65 mmHg, creatinine increase greater than 0.3 mg/dL, or a drop in Glasgow Coma Scale score greater than 2). Features are extracted from the first 24 hours and include vital sign aggregates, laboratory values, and static demographics. We train and evaluate multiple classification models on a cohort of 85,242 ICU stays (80 percent training: 68,193; 20 percent testing: 17,049). Evaluation metrics include per-label precision, recall, F1-score, and Hamming loss. XGBoost, the best performing model, achieves F1-scores of 0.66 for respiratory, 0.72 for hemodynamic, 0.76 for renal, and 0.62 for neurologic deterioration, outperforming baseline models. Feature analysis shows that clinically relevant parameters such as respiratory rate, blood pressure, and creatinine are the most influential predictors, consistent with the clinical definitions of the CETs. The proposed framework demonstrates practical potential for early, interpretable clinical alerts without requiring complex time-series modeling or natural language processing.', 'abstract_zh': '重症监护单元（ICU）患者常出现多种生理功能恶化的表现，需要及时升级护理。传统早期预警系统如SOFA或MEWS专注于单一结果，未能捕捉临床恶化多维度的特性。本研究提出一种多标签分类框架，利用ICU前24小时的数据预测护理升级触发因素（CETs），包括呼吸衰竭、血流动力学不稳定、肾功能损害和神经系统恶化。通过MIMIC-IV数据库，CETs定义为基于规则的标准应用于第24至第72小时的数据（例如，氧饱和度低于90%，平均动脉压低于65 mmHg，肌酐增加大于0.3 mg/dL，或格拉斯哥昏迷评分下降大于2分）。特征包括前24小时的生命体征汇总、实验室值和静态人口统计学信息。研究在85,242例ICU住院记录（80%用于训练：68,193；20%用于测试：17,049）上训练和评估了多种分类模型。评估指标包括单标签精确率、召回率、F1值和汉明损失。XGBoost表现最佳，针对呼吸衰竭、血流动力学不稳定、肾功能损害和神经系统恶化的F1值分别为0.66、0.72、0.76和0.62，优于基线模型。特征分析表明，临床相关的参数如呼吸频率、血压和肌酐是最重要的预测因素，与CETs的临床定义一致。所提出的方法展示了在无需复杂的时间序列模型或自然语言处理的情况下实现早期、可解释的临床警报的实用潜力。', 'title_zh': '基于电子健康记录的重症监护单元多标签护理升级触发因素的早期预测'}
{'arxiv_id': 'arXiv:2509.18144', 'title': 'AdaSTI: Conditional Diffusion Models with Adaptive Dependency Modeling for Spatio-Temporal Imputation', 'authors': 'Yubo Yang, Yichen Zhu, Bo Jiang', 'link': 'https://arxiv.org/abs/2509.18144', 'abstract': 'Spatio-temporal data abounds in domain like traffic and environmental monitoring. However, it often suffers from missing values due to sensor malfunctions, transmission failures, etc. Recent years have seen continued efforts to improve spatio-temporal data imputation performance. Recently diffusion models have outperformed other approaches in various tasks, including spatio-temporal imputation, showing competitive performance. Extracting and utilizing spatio-temporal dependencies as conditional information is vital in diffusion-based methods. However, previous methods introduce error accumulation in this process and ignore the variability of the dependencies in the noisy data at different diffusion steps. In this paper, we propose AdaSTI (Adaptive Dependency Model in Diffusion-based Spatio-Temporal Imputation), a novel spatio-temporal imputation approach based on conditional diffusion model. Inside AdaSTI, we propose a BiS4PI network based on a bi-directional S4 model for pre-imputation with the imputed result used to extract conditional information by our designed Spatio-Temporal Conditionalizer (STC)network. We also propose a Noise-Aware Spatio-Temporal (NAST) network with a gated attention mechanism to capture the variant dependencies across diffusion steps. Extensive experiments on three real-world datasets show that AdaSTI outperforms existing methods in all the settings, with up to 46.4% reduction in imputation error.', 'abstract_zh': '基于条件扩散模型的空间时间数据插补方法：自适应依赖模型AdaSTI', 'title_zh': 'AdaSTI：具有自适应依赖建模的条件扩散模型时空插补'}
{'arxiv_id': 'arXiv:2509.18143', 'title': 'Weight Mapping Properties of a Dual Tree Single Clock Adiabatic Capacitive Neuron', 'authors': 'Mike Smart, Sachin Maheshwari, Himadri Singh Raghav, Alexander Serb', 'link': 'https://arxiv.org/abs/2509.18143', 'abstract': 'Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) circuits offer the potential for highly energy-efficient Artificial Neural Network (ANN) computation in full custom analog IC designs. The efficient mapping of Artificial Neuron (AN) abstract weights, extracted from the software-trained ANNs, onto physical ACN capacitance values has, however, yet to be fully researched. In this paper, we explore the unexpected hidden complexities, challenges and properties of the mapping, as well as, the ramifications for IC designers in terms accuracy, design and implementation. We propose an optimal, AN to ACN methodology, that promotes smaller chip sizes and improved overall classification accuracy, necessary for successful practical deployment. Using TensorFlow and Larq software frameworks, we train three different ANN networks and map their weights into the energy-efficient DTSC ACN capacitance value domain to demonstrate 100% functional equivalency. Finally, we delve into the impact of weight quantization on ACN performance using novel metrics related to practical IC considerations, such as IC floor space and comparator decision-making efficacy.', 'abstract_zh': 'Dual Tree Single Clock (DTSC)磁化电容神经元（ACN）电路为全定制模拟IC设计中的高效能源人工神经网络（ANN）计算提供了潜在可能性。然而，将从软件训练的ANN中提取的人工神经元（AN）抽象权重高效映射到物理ACN电容值的研究尚未得到全面研究。本文探讨了映射的隐藏复杂性、挑战和特性，以及对IC设计师在准确性、设计和实现方面的潜在影响。我们提出了一种优化的人工神经元到ACN的方法，以促进较小的芯片尺寸和整体分类准确性，这是成功实际部署所必需的。利用TensorFlow和Larq软件框架，我们训练了三种不同的ANN网络，并将它们的权重映射到节能的DTSC ACN电容值域，以证明100%的功能等效性。最后，我们利用与实际IC考虑相关的新型性能指标深入探讨了权重量化对ACN性能的影响，如IC面积和比较器决策效用。', 'title_zh': '一种双树单时钟绝热电容神经元的权重映射特性'}
{'arxiv_id': 'arXiv:2509.18141', 'title': 'KM-GPT: An Automated Pipeline for Reconstructing Individual Patient Data from Kaplan-Meier Plots', 'authors': 'Yao Zhao, Haoyue Sun, Yantian Ding, Yanxun Xu', 'link': 'https://arxiv.org/abs/2509.18141', 'abstract': 'Reconstructing individual patient data (IPD) from Kaplan-Meier (KM) plots provides valuable insights for evidence synthesis in clinical research. However, existing approaches often rely on manual digitization, which is error-prone and lacks scalability. To address these limitations, we develop KM-GPT, the first fully automated, AI-powered pipeline for reconstructing IPD directly from KM plots with high accuracy, robustness, and reproducibility. KM-GPT integrates advanced image preprocessing, multi-modal reasoning powered by GPT-5, and iterative reconstruction algorithms to generate high-quality IPD without manual input or intervention. Its hybrid reasoning architecture automates the conversion of unstructured information into structured data flows and validates data extraction from complex KM plots. To improve accessibility, KM-GPT is equipped with a user-friendly web interface and an integrated AI assistant, enabling researchers to reconstruct IPD without requiring programming expertise. KM-GPT was rigorously evaluated on synthetic and real-world datasets, consistently demonstrating superior accuracy. To illustrate its utility, we applied KM-GPT to a meta-analysis of gastric cancer immunotherapy trials, reconstructing IPD to facilitate evidence synthesis and biomarker-based subgroup analyses. By automating traditionally manual processes and providing a scalable, web-based solution, KM-GPT transforms clinical research by leveraging reconstructed IPD to enable more informed downstream analyses, supporting evidence-based decision-making.', 'abstract_zh': '从Kaplan-Meier生存曲线重建个体患者数据（IPD）为临床研究中的证据综合提供了宝贵见解。然而，现有方法通常依赖于手动数字化，容易出错且缺乏可扩展性。为解决这些局限性，我们开发了KM-GPT，这是第一个能够直接从Kaplan-Meier生存曲线自动重建高精度、稳健且可重复的个体患者数据（IPD）的完全自动化的AI驱动管道。KM-GPT整合了高级图像预处理、由GPT-5驱动的多模态推理以及迭代重建算法，无需手动输入或干预即可生成高质量的IPD。其混合推理架构自动化了无结构信息向结构化数据流的转换，并验证了从复杂Kaplan-Meier生存曲线中提取数据的过程。为了提高易用性，KM-GPT配备了用户友好的网页界面和内置的AI助手，使研究人员能够无需编程知识即可重建IPD。KM-GPT在合成和真实世界数据集上的严格评估中，始终显示出优越的准确性。为了展示其用途，我们应用KM-GPT进行了一项胃癌免疫治疗临床试验的元分析，重建IPD以促进证据综合和基于生物标志物的亚组分析。通过自动化传统的手动过程并提供可扩展的基于网络的解决方案，KM-GPT将临床研究转变为通过重建IPD支持更明智的下游分析，并促进基于证据的决策。', 'title_zh': 'KM-GPT：从Kaplan-Meier图自动构建个体患者数据的流水线'}
{'arxiv_id': 'arXiv:2509.18140', 'title': 'A Machine Learning Framework for Pathway-Driven Therapeutic Target Discovery in Metabolic Disorders', 'authors': 'Iram Wajahat, Amritpal Singh, Fazel Keshtkar, Syed Ahmad Chan Bukhari', 'link': 'https://arxiv.org/abs/2509.18140', 'abstract': 'Metabolic disorders, particularly type 2 diabetes mellitus (T2DM), represent a significant global health burden, disproportionately impacting genetically predisposed populations such as the Pima Indians (a Native American tribe from south central Arizona). This study introduces a novel machine learning (ML) framework that integrates predictive modeling with gene-agnostic pathway mapping to identify high-risk individuals and uncover potential therapeutic targets. Using the Pima Indian dataset, logistic regression and t-tests were applied to identify key predictors of T2DM, yielding an overall model accuracy of 78.43%. To bridge predictive analytics with biological relevance, we developed a pathway mapping strategy that links identified predictors to critical signaling networks, including insulin signaling, AMPK, and PPAR pathways. This approach provides mechanistic insights without requiring direct molecular data. Building upon these connections, we propose therapeutic strategies such as dual GLP-1/GIP receptor agonists, AMPK activators, SIRT1 modulators, and phytochemical, further validated through pathway enrichment analyses. Overall, this framework advances precision medicine by offering interpretable and scalable solutions for early detection and targeted intervention in metabolic disorders. The key contributions of this work are: (1) development of an ML framework combining logistic regression and principal component analysis (PCA) for T2DM risk prediction; (2) introduction of a gene-agnostic pathway mapping approach to generate mechanistic insights; and (3) identification of novel therapeutic strategies tailored for high-risk populations.', 'abstract_zh': '代谢紊乱，特别是2型糖尿病（T2DM），构成了重大的全球健康负担，特别影响如图皮印第安人（亚利桑那州中部南部的土著部族）等遗传易感人群。本研究介绍了一种新型机器学习（ML）框架，该框架结合了预测建模与基因无关通路映射，以识别高风险个体并揭示潜在的治疗靶点。通过使用图皮印第安人数据集，应用逻辑回归和t检验来识别2型糖尿病的关键预测因子，总体模型准确率为78.43%。为将预测分析与生物学相关性相结合，我们开发了一种通路映射策略，将已识别的预测因子与关键信号网络联系起来，包括胰岛素信号传导、AMPK和PPAR通路。该方法提供机制洞察，无需直接分子数据。在此基础上，我们提出了包括双重GLP-1/GIP受体激动剂、AMPK激活剂、SIRT1调节剂和植物化学疗法在内的治疗策略，并通过通路富集分析进一步验证。总体而言，该框架通过提供早期检测和针对性干预的可解释和可扩展解决方案来推进精准医学。本工作的关键贡献包括：（1）开发了一种结合逻辑回归和主成分分析（PCA）的ML框架，用于2型糖尿病风险预测；（2）介绍了基因无关的通路映射方法以生成机制洞察；（3）识别了针对高风险人群的新型治疗策略。', 'title_zh': '代谢障碍中基于途径的治疗靶点发现的机器学习框架'}
{'arxiv_id': 'arXiv:2509.18137', 'title': 'LoRALib: A Standardized Benchmark for Evaluating LoRA-MoE Methods', 'authors': 'Shaoheng Wang, Yao Lu, Yuqi Li, Yaxin Gao, Jiaqi Nie, Shanqing Yu, Yingli Tian, Qi Xuan', 'link': 'https://arxiv.org/abs/2509.18137', 'abstract': "As a parameter efficient fine-tuning (PEFT) method, low-rank adaptation (LoRA) can save significant costs in storage and computing, but its strong adaptability to a single task is often accompanied by insufficient cross-task generalization capabilities. To improve this, existing work combines LoRA with mixture-of-experts (MoE) to enhance the model's adaptability through expert modules and routing mechanisms. However, existing LoRA-MoE methods lack unified standards in models, datasets, hyperparameters, and evaluation methods, making it difficult to conduct fair comparisons between different methods. To this end, we proposed a unified benchmark named LoRALib. Specifically, we standardized datasets from $40$ downstream tasks into a unified format, fine-tuned them using the same hyperparameters and obtained $680$ LoRA modules across $17$ model architectures. Based on this LoRA library, we conduct large-scale experiments on $3$ representative LoRA-MoE methods and different LoRA selection mechanisms using the open-sourced testing tool OpenCompass. Extensive experiments show that LoRAMoE performs best, and that prioritizing LoRAs relevant to the target task can further improve the performance of MoE. We hope these findings will inspire future work. Our datasets and LoRA library are available at this https URL and this https URL.", 'abstract_zh': '作为一种参数高效微调（PEFT）方法，低秩适应（LoRA）可以在存储和计算方面节省大量成本，但其在单任务上的强大适应性通常伴随着跨任务泛化能力不足的问题。为了解决这一问题，现有工作将LoRA与专家集合（MoE）相结合，通过专家模块和路由机制增强模型的适应性。然而，现有的LoRA-MoE方法在模型、数据集、超参数和评估方法方面缺乏统一标准，难以进行公平比较。为此，我们提出了一个统一的基准库LoRALib。具体来说，我们将来自40个下游任务的数据集统一格式化，使用相同的超参数进行微调，并在17种模型架构上获得了680个LoRA模块。基于这个LoRA库，我们使用开源测试工具OpenCompass对3种代表性LoRA-MoE方法和不同的LoRA选择机制进行了大规模实验。广泛的实验表明，LoRAMoE性能最佳，优先选择与目标任务相关的LoRA可以进一步提高MoE的性能。希望这些发现能够启发未来的相关工作。我们的数据集和LoRA库可在以下链接获取：this https URL和this https URL。', 'title_zh': 'LoRALib: 一种评估LoRA-MoE方法的标准基准'}
{'arxiv_id': 'arXiv:2509.18136', 'title': 'From Parameters to Performance: A Data-Driven Study on LLM Structure and Development', 'authors': 'Suqing Wang, Zuchao Li, Luohe Shi, Bo Du, Hai Zhao, Yun Li, Qianren Wang', 'link': 'https://arxiv.org/abs/2509.18136', 'abstract': 'Large language models (LLMs) have achieved remarkable success across various domains, driving significant technological advancements and innovations. Despite the rapid growth in model scale and capability, systematic, data-driven research on how structural configurations affect performance remains scarce. To address this gap, we present a large-scale dataset encompassing diverse open-source LLM structures and their performance across multiple benchmarks. Leveraging this dataset, we conduct a systematic, data mining-driven analysis to validate and quantify the relationship between structural configurations and performance. Our study begins with a review of the historical development of LLMs and an exploration of potential future trends. We then analyze how various structural choices impact performance across benchmarks and further corroborate our findings using mechanistic interpretability techniques. By providing data-driven insights into LLM optimization, our work aims to guide the targeted development and application of future models. We will release our dataset at this https URL', 'abstract_zh': '大规模语言模型（LLMs）在各个领域取得了显著的成功，推动了重要的技术创新和进步。尽管模型规模和能力迅速增长，但关于结构配置如何影响性能的系统性、数据驱动研究仍然稀缺。为弥补这一差距，我们呈现了一个涵盖多种开源LLM结构及其在多个基准上的性能的大规模数据集。利用该数据集，我们进行了一项系统性的数据挖掘分析，以验证和量化结构配置与性能之间的关系。我们的研究从LLM的历史发展回顾和未来趋势探索开始。随后，我们分析了各种结构选择如何影响不同基准上的性能，并进一步使用机制可解释性技术来验证我们的发现。通过提供有关LLM优化的数据驱动洞见，我们的工作旨在指导未来模型的精准开发和应用。我们将在此处发布我们的数据集：https://.......', 'title_zh': '从参数到性能：基于数据的大型语言模型结构与发展研究'}
{'arxiv_id': 'arXiv:2509.18135', 'title': 'SDGF: Fusing Static and Multi-Scale Dynamic Correlations for Multivariate Time Series Forecasting', 'authors': 'Shaoxun Wang, Xingjun Zhang, Qianyang Li, Jiawei Cao, Zhendong Tan', 'link': 'https://arxiv.org/abs/2509.18135', 'abstract': 'Inter-series correlations are crucial for accurate multivariate time series forecasting, yet these relationships often exhibit complex dynamics across different temporal scales. Existing methods are limited in modeling these multi-scale dependencies and struggle to capture their intricate and evolving nature. To address this challenge, this paper proposes a novel Static-Dynamic Graph Fusion network (SDGF), whose core lies in capturing multi-scale inter-series correlations through a dual-path graph structure learning approach. Specifically, the model utilizes a static graph based on prior knowledge to anchor long-term, stable dependencies, while concurrently employing Multi-level Wavelet Decomposition to extract multi-scale features for constructing an adaptively learned dynamic graph to capture associations at different scales. We design an attention-gated module to fuse these two complementary sources of information intelligently, and a multi-kernel dilated convolutional network is then used to deepen the understanding of temporal patterns. Comprehensive experiments on multiple widely used real-world benchmark datasets demonstrate the effectiveness of our proposed model.', 'abstract_zh': '跨序列间的联系对于准确的多变量时间序列预测至关重要，但这些关系在不同时间规模上往往表现出复杂的动态特性。现有方法在建模这些多尺度依赖关系方面有限，难以捕捉它们的复杂演变性质。为应对这一挑战，本文提出了一种新型静态-动态图融合网络（SDGF），其核心在于通过双路径图结构学习方法捕获多尺度跨序列间的联系。具体来说，模型利用基于先验知识的静态图来锚定长期稳定依赖关系，同时采用多尺度小波分解来提取多尺度特征，以构建自适应学习的动态图来捕捉不同尺度下的关联性。我们设计了一种注意力门控模块以智能融合这两种互补的信息来源，并使用多种内核空洞卷积网络来加深对时间模式的理解。在多个广泛使用的现实世界基准数据集上的全面实验展示了我们所提模型的有效性。', 'title_zh': 'SDGF: 结合静态和多尺度动态关联的多变量时间序列预测'}
{'arxiv_id': 'arXiv:2509.18133', 'title': 'Self-Evolving LLMs via Continual Instruction Tuning', 'authors': 'Le Huang, Jiazheng Kang, Cheng Hou, Zhe Zhao, Zhenxiang Yan, Chuan Shi, Ting Bai', 'link': 'https://arxiv.org/abs/2509.18133', 'abstract': 'In real-world industrial settings, large language models (LLMs) must learn continually to keep pace with diverse and evolving tasks, requiring self-evolution to refine knowledge under dynamic data distributions. However, existing continual learning (CL) approaches, such as replay and parameter isolation, often suffer from catastrophic forgetting: training on new tasks degrades performance on earlier ones by overfitting to the new distribution and weakening this http URL propose MoE-CL, a parameter-efficient adversarial mixture-of-experts framework for industrial-scale, self-evolving continual instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated LoRA expert per task to preserve task-specific knowledge via parameter independence, mitigating forgetting; and (2) a shared LoRA expert to enable cross-task transfer. To prevent transferring task-irrelevant noise through the shared pathway, we integrate a task-aware discriminator within a GAN. The discriminator encourages the shared expert to pass only task-aligned information during sequential training. Through adversarial learning, the shared expert acquires generalized representations that mimic the discriminator, while dedicated experts retain task-specific details, balancing knowledge retention and cross-task generalization and thereby supporting this http URL experiments on the public MTL5 benchmark and an industrial Tencent3 benchmark validate the effectiveness of MoE-CL for continual instruction tuning. In real-world A/B testing for content compliance review on the Tencent Video platform, MoE-CL reduced manual review costs by 15.3%. These results demonstrate that MoE-CL is practical for large-scale industrial deployment where continual adaptation and stable transfer are critical.', 'abstract_zh': '工业规模下大语言模型的参数高效自进化持续指令调优：MoE-CL框架', 'title_zh': '通过持续指令调优实现自我进化的大语言模型'}
{'arxiv_id': 'arXiv:2509.18131', 'title': 'Two ways to knowledge?', 'authors': 'Jean-Michel Tucny, Abhisek Ganguly, Santosh Ansumali, Sauro Succi', 'link': 'https://arxiv.org/abs/2509.18131', 'abstract': 'It is shown that the weight matrices of transformer-based machine learning applications to the solution of two representative physical applications show a random-like character which bears no directly recognizable link to the physical and mathematical structure of the physical problem under study. This suggests that machine learning and the scientific method may represent two distinct and potentially complementary paths to knowledge, even though a strict notion of explainability in terms of direct correspondence between network parameters and physical structures may remain out of reach. It is also observed that drawing a parallel between transformer operation and (generalized) path-integration techniques may account for the random-like nature of the weights, but still does not resolve the tension with explainability. We conclude with some general comments on the hazards of gleaning knowledge without the benefit of Insight.', 'abstract_zh': '基于变压器的机器学习应用在两个代表性的物理应用中的权重矩阵表现出随机性质，与所研究物理问题的物理和数学结构之间不存在直接可识别的联系。这表明机器学习与科学研究方法可能会代表两种不同的、甚至可能是互补的知识路径，尽管严格意义上的解释性，即网络参数与物理结构之间的直接对应关系，可能仍然难以实现。还观察到，将变压器操作与（广义）路径积分技术相类比可以解释权重的随机性质，但这仍未解决解释性的问题。最后，我们对在缺乏洞察力的情况下获取知识的危险提出一些一般性评论。', 'title_zh': '两种知识途径？'}
{'arxiv_id': 'arXiv:2509.18130', 'title': 'Research on Metro Transportation Flow Prediction Based on the STL-GRU Combined Model', 'authors': 'Zijie Zhou, Huichen Ma', 'link': 'https://arxiv.org/abs/2509.18130', 'abstract': "In the metro intelligent transportation system, accurate transfer passenger flow prediction is a key link in optimizing operation plans and improving transportation efficiency. To further improve the theory of metro internal transfer passenger flow prediction and provide more reliable support for intelligent operation decisions, this paper innovatively proposes a metro transfer passenger flow prediction model that integrates the Seasonal and Trend decomposition using Loess (STL) method and Gated Recurrent Unit (GRU).In practical application, the model first relies on the deep learning library Keras to complete the construction and training of the GRU model, laying the foundation for subsequent prediction; then preprocesses the original metro card swiping data, uses the graph-based depth-first search algorithm to identify passengers' travel paths, and further constructs the transfer passenger flow time series; subsequently adopts the STL time series decomposition algorithm to decompose the constructed transfer passenger flow time series into trend component, periodic component and residual component, and uses the 3{\\sigma} principle to eliminate and fill the outliers in the residual component, and finally completes the transfer passenger flow this http URL the transfer passenger flow data of a certain metro station as the research sample, the validity of the model is verified. The results show that compared with Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and the combined model of STL time series decomposition method and Long Short-Term Memory (STL-LSTM), the STL-GRU combined prediction model significantly improves the prediction accuracy of transfer passenger flow on weekdays (excluding Fridays), Fridays and rest days, with the mean absolute percentage error (MAPE) of the prediction results reduced by at least 2.3, 1.36 and 6.42 percentage points respectively.", 'abstract_zh': '基于STL和GRU的地铁换乘客流预测模型', 'title_zh': '基于STL-GRU组合模型的地铁交通流量预测研究'}
{'arxiv_id': 'arXiv:2509.18127', 'title': 'Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework', 'authors': 'Jiaqi Weng, Han Zheng, Hanyu Zhang, Qinqin He, Jialing Tao, Hui Xue, Zhixuan Chu, Xiting Wang', 'link': 'https://arxiv.org/abs/2509.18127', 'abstract': 'Increasing deployment of large language models (LLMs) in real-world applications raises significant safety concerns. Most existing safety research focuses on evaluating LLM outputs or specific safety tasks, limiting their ability to ad- dress broader, undefined risks. Sparse Autoencoders (SAEs) facilitate interpretability research to clarify model behavior by explaining single-meaning atomic features decomposed from entangled signals. jHowever, prior applications on SAEs do not interpret features with fine-grained safety-related con- cepts, thus inadequately addressing safety-critical behaviors, such as generating toxic responses and violating safety regu- lations. For rigorous safety analysis, we must extract a rich and diverse set of safety-relevant features that effectively capture these high-risk behaviors, yet face two challenges: identifying SAEs with the greatest potential for generating safety concept-specific neurons, and the prohibitively high cost of detailed feature explanation. In this paper, we pro- pose Safe-SAIL, a framework for interpreting SAE features within LLMs to advance mechanistic understanding in safety domains. Our approach systematically identifies SAE with best concept-specific interpretability, explains safety-related neurons, and introduces efficient strategies to scale up the in- terpretation process. We will release a comprehensive toolkit including SAE checkpoints and human-readable neuron ex- planations, which supports empirical analysis of safety risks to promote research on LLM safety.', 'abstract_zh': '增加大型语言模型在实际应用中的部署引发了显著的安全 concerns。现有大多数安全研究侧重于评估 LLM 输出或特定的安全任务，限制了它们应对更广泛、未定义的风险的能力。稀疏自编码器（SAEs）通过解释从交织信号中分解出来的单义原子特征来促进可解释性研究，以澄清模型行为。然而，先前对 SAEs 的应用没有用细粒度的安全相关概念来解释特征，因此未能充分应对关键的安全行为，如生成有害响应和违反安全规定。为了进行严格的安全分析，我们必须提取一组丰富且多样的与安全相关特征，有效地捕捉这些高风险行为，但面临两个挑战：识别最具潜力生成特定概念神经元的 SAEs，以及对详细特征解释的高成本。在本文中，我们提出 Safe-SAIL，一个在 LLM 中解释 SAE 特征的框架，以推动安全领域的机制性理解。我们的方法系统地识别具有最佳概念特定解释性的 SAE，解释安全相关的神经元，并引入高效策略以扩大解释过程的规模。我们将发布一个全面的工具包，包括 SAE 检查点和可读的神经元解释，支持对 LLM 安全风险的经验分析，促进 LLM 安全研究。', 'title_zh': 'Safe-SAIL：通过稀疏自编码解释框架朝着大型语言模型精细安全景观的构建'}
{'arxiv_id': 'arXiv:2509.18126', 'title': 'Anomaly Detection in Electric Vehicle Charging Stations Using Federated Learning', 'authors': 'Bishal K C, Amr Hilal, Pawan Thapa', 'link': 'https://arxiv.org/abs/2509.18126', 'abstract': 'Federated Learning (FL) is a decentralized training framework widely used in IoT ecosystems that preserves privacy by keeping raw data local, making it ideal for IoT-enabled cyber-physical systems with sensing and communication like Smart Grids (SGs), Connected and Automated Vehicles (CAV), and Electric Vehicle Charging Stations (EVCS). With the rapid expansion of electric vehicle infrastructure, securing these IoT-based charging stations against cyber threats has become critical. Centralized Intrusion Detection Systems (IDS) raise privacy concerns due to sensitive network and user data, making FL a promising alternative. However, current FL-based IDS evaluations overlook practical challenges such as system heterogeneity and non-IID data. To address these challenges, we conducted experiments to evaluate the performance of federated learning for anomaly detection in EV charging stations under system and data heterogeneity. We used FedAvg and FedAvgM, widely studied optimization approaches, to analyze their effectiveness in anomaly detection. Under IID settings, FedAvg achieves superior performance to centralized models using the same neural network. However, performance degrades with non-IID data and system heterogeneity. FedAvgM consistently outperforms FedAvg in heterogeneous settings, showing better convergence and higher anomaly detection accuracy. Our results demonstrate that FL can handle heterogeneity in IoT-based EVCS without significant performance loss, with FedAvgM as a promising solution for robust, privacy-preserving EVCS security.', 'abstract_zh': '联邦学习在具有感知和通信能力的物联网充电站异构环境中异常检测性能评估', 'title_zh': '使用联邦学习的电动车辆充电站异常检测'}
{'arxiv_id': 'arXiv:2509.18125', 'title': 'NurseSchedRL: Attention-Guided Reinforcement Learning for Nurse-Patient Assignment', 'authors': 'Harsha Koduri', 'link': 'https://arxiv.org/abs/2509.18125', 'abstract': 'Healthcare systems face increasing pressure to allocate limited nursing resources efficiently while accounting for skill heterogeneity, patient acuity, staff fatigue, and continuity of care. Traditional optimization and heuristic scheduling methods struggle to capture these dynamic, multi-constraint environments. I propose NurseSchedRL, a reinforcement learning framework for nurse-patient assignment that integrates structured state encoding, constrained action masking, and attention-based representations of skills, fatigue, and geographical context. NurseSchedRL uses Proximal Policy Optimization (PPO) with feasibility masks to ensure assignments respect real-world constraints, while dynamically adapting to patient arrivals and varying nurse availability. In simulation with realistic nurse and patient data, NurseSchedRL achieves improved scheduling efficiency, better alignment of skills to patient needs, and reduced fatigue compared to baseline heuristic and unconstrained RL approaches. These results highlight the potential of reinforcement learning for decision support in complex, high-stakes healthcare workforce management.', 'abstract_zh': '护理系统面临不断增加的压力，需要在考虑技能异质性、患者急性程度、工作人员疲劳以及护理连续性的情况下高效分配有限的护理资源。传统优化和启发式排班方法难以捕捉这些动态的多约束环境。我提出了NurseSchedRL，一种结合结构化状态编码、受限动作屏蔽以及基于注意力的技能、疲劳和地理背景表示的强化学习框架。NurseSchedRL 使用近端策略优化（PPO）和可行性掩码确保排班遵守现实世界的约束条件，并能够动态适应患者到访和护士可用性的变化。在包含现实护士和患者数据的模拟中，NurseSchedRL 达到了更高的排班效率、更好的技能与患者需求匹配度以及更低的疲劳水平，优于基线启发式和无约束的强化学习方法。这些结果突显了强化学习在复杂、高风险的护理人员管理决策支持中的潜力。', 'title_zh': 'NurseSchedRL：注意力引导的强化学习在护士-患者分配中的应用'}
{'arxiv_id': 'arXiv:2509.18120', 'title': 'A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning', 'authors': 'Thanh Linh Nguyen, Quoc-Viet Pham', 'link': 'https://arxiv.org/abs/2509.18120', 'abstract': 'Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or banks) to collaboratively train artificial intelligence (AI) models while preserving data privacy by keeping data local. While prior work has primarily addressed statistical heterogeneity across organizations, a critical challenge arises from economic competition, where organizations may act as market rivals, making them hesitant to participate in joint training due to potential utility loss (i.e., reduced net benefit). Furthermore, the combined effects of statistical heterogeneity and inter-organizational competition on organizational behavior and system-wide social welfare remain underexplored. In this paper, we propose CoCoGen, a coopetitive-compatible data generation framework, leveraging generative AI (GenAI) and potential game theory to model, analyze, and optimize collaborative learning under heterogeneous and competitive settings. Specifically, CoCoGen characterizes competition and statistical heterogeneity through learning performance and utility-based formulations and models each training round as a weighted potential game. We then derive GenAI-based data generation strategies that maximize social welfare. Experimental results on the Fashion-MNIST dataset reveal how varying heterogeneity and competition levels affect organizational behavior and demonstrate that CoCoGen consistently outperforms baseline methods.', 'abstract_zh': '跨孤岛联邦学习（CFL）使得组织（如医院或银行）能够在保持数据隐私的情况下协作训练人工智能模型。尽管以往的工作主要关注组织间的统计异质性，但是来自经济竞争的挑战使得组织可能成为市场竞争对手，这使得它们因潜在的净效益损失而不愿参与联合训练。此外，统计异质性和组织间竞争对组织行为和社会福利的综合影响仍然鲜有研究。在本文中，我们提出了一种称作CoCoGen的合作竞争数据生成框架，该框架利用生成人工智能（GenAI）和潜在博弈理论来建模、分析和优化在异质和竞争环境下的协作学习。具体而言，CoCoGen通过学习性能和基于效用的公式来表征竞争和统计异质性，并将每一训练轮次建模为加权潜在博弈。我们随后推导出基于GenAI的数据生成策略以最大化社会福利。Fashion-MNIST数据集上的实验结果揭示了不同异质性和竞争水平如何影响组织行为，并展示了CoCoGen相对于基准方法的一贯优越性。', 'title_zh': '跨孤岛协作竞争型数据生成框架'}
{'arxiv_id': 'arXiv:2509.18119', 'title': 'MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents', 'authors': 'Yifan Xu, Xiao Liu, Xinghan Liu, Jiaqi Fu, Hanchen Zhang, Bohao Jing, Shudan Zhang, Yuting Wang, Wenyi Zhao, Yuxiao Dong', 'link': 'https://arxiv.org/abs/2509.18119', 'abstract': 'Building general-purpose graphical user interface (GUI) agents has become increasingly promising with the progress in vision language models. However, developing effective mobile GUI agents with reinforcement learning (RL) remains challenging due to the heavy-tailed distribution of task difficulty and the inefficiency of large-scale environment sampling. We present an online agentic reinforcement learning framework MOBILERL to enhance GUI agents in mobile environments. Its core component is the Difficulty-Adaptive GRPO (ADAGRPO) algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and failure curriculum filtering to adapt the model to different task difficulties. We introduce the shortest path reward adjustment strategy to reshape rewards concerning the task length in multi-turn agentic tasks. Those strategies jointly stabilize RL training, improve sample efficiency, and generate strong performance across diverse mobile apps and tasks. We apply MOBILERL to two open models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B model achieves state-of-the-art results in terms of success rates on both AndroidWorld (75.8%) and AndroidLab (46.8%). The MOBILERL framework is adopted in the AutoGLM products, and also open-sourced at this https URL.', 'abstract_zh': '基于视觉语言模型的通用图形用户界面（GUI）代理构建取得了日益显著的进展。然而，利用强化学习（RL）开发高效的移动GUI代理仍具挑战性，原因在于任务难度的长尾分布和大规模环境采样的低效性。我们提出了一种在线代理强化学习框架MOBILERL，以增强移动环境中的GUI代理。其核心组件是难度自适应GRPO（ADAGRPO）算法。在ADAGRPO中，我们设计了难度自适应正强化回放和失败课程筛选，以使模型适应不同任务难度。我们引入了最短路径奖励调整策略，以根据不同任务长度重新塑造多轮代理任务的奖励。这些策略共同稳定了RL的训练，提高了样本效率，并在多种移动应用和任务中产生了优越表现。我们将在Qwen2.5-VL-7B-Instruct和GLM-4.1V-9B-Base两个开源模型上应用MOBILERL。由此产生的MOBILERL-9B模型在AndroidWorld（75.8%）和AndroidLab（46.8%）成功率达到领先水平。MOBILERL框架已被应用于AutoGLM产品，并在此链接中开源：[https://github.com/AutoGLM/MOBILERL]。', 'title_zh': '移动RL：移动GUI代理的在线代理强化学习'}
{'arxiv_id': 'arXiv:2509.18116', 'title': 'Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization', 'authors': 'Nathan Egbuna, Saatvik Gaur, Sunishchal Dev, Ashwinee Panda, Maheep Chaudhary', 'link': 'https://arxiv.org/abs/2509.18116', 'abstract': "Test-time optimization remains impractical at scale due to prohibitive inference costs\\textemdash techniques like iterative refinement and multi-step verification can require $10$--$100\\times$ more compute per query than standard decoding. Latent space test-time optimization methods like LatentSeek offer a more direct approach by steering hidden representations, but still demand expensive per-query optimization loops with multiple backward passes. We propose Amortized Latent Steering (ALS), which collapses this iterative optimization into a single offline-computed vector applied at constant cost during inference. ALS computes the mean difference between hidden states from successful versus unsuccessful generations, then uses this direction to calibrate the model's hidden representations: when decoding drifts away from the success manifold, ALS nudges activations back toward it. Across GSM8K and MATH-$500$ benchmarks, ALS achieves $2$--$5\\times$ speedup over iterative methods while matching or surpassing greedy Chain-of-Thought (CoT) and Self-Consistency baselines, yielding up to 101\\% improvement in efficiency--accuracy trade-off. These results show that much of latent optimization's benefit can be captured offline, making sophisticated reasoning techniques viable for production deployment. Code is available at~\\href{this https URL}{this https URL}", 'abstract_zh': '测试时的优化由于高昂的推理成本仍难以大规模实现——迭代精炼和多步验证等技术每查询所需的计算量可能比标准解码多10到100倍。潜空间测试时优化方法如LatentSeek通过引导隐藏表示提供了一种更直接的方法，但仍需要昂贵的每查询优化循环和多次反向传播。我们提出了一种名为Amortized Latent Steering (ALS)的方法，将这种迭代优化过程压缩为一个在推理时固定成本计算的向量。ALS计算成功生成与失败生成的隐藏状态均值差异，然后使用该方向校准模型的隐藏表示：当解码偏离成功流形时，ALS推动激活向其方向回归。在GSM8K和MATH-500基准测试中，ALS在迭代方法的基础上实现了2到5倍的速度提升，并达到了或超过了贪婪链式思维（CoT）和自我一致性基线的效果，效率-准确性的权衡改善幅度高达101%。这些结果表明，可以将大部分潜优化的益处提前捕获，从而使复杂的推理技术在生产部署中成为可能。代码可访问<这个 https URL>。', 'title_zh': 'amortized潜在导向：测试时优化的低成本替代方案'}
{'arxiv_id': 'arXiv:2509.18111', 'title': 'Prompt Optimization Meets Subspace Representation Learning for Few-shot Out-of-Distribution Detection', 'authors': 'Faizul Rakib Sayem, Shahana Ibrahim', 'link': 'https://arxiv.org/abs/2509.18111', 'abstract': 'The reliability of artificial intelligence (AI) systems in open-world settings depends heavily on their ability to flag out-of-distribution (OOD) inputs unseen during training. Recent advances in large-scale vision-language models (VLMs) have enabled promising few-shot OOD detection frameworks using only a handful of in-distribution (ID) samples. However, existing prompt learning-based OOD methods rely solely on softmax probabilities, overlooking the rich discriminative potential of the feature embeddings learned by VLMs trained on millions of samples. To address this limitation, we propose a novel context optimization (CoOp)-based framework that integrates subspace representation learning with prompt tuning. Our approach improves ID-OOD separability by projecting the ID features into a subspace spanned by prompt vectors, while projecting ID-irrelevant features into an orthogonal null space. To train such OOD detection framework, we design an easy-to-handle end-to-end learning criterion that ensures strong OOD detection performance as well as high ID classification accuracy. Experiments on real-world datasets showcase the effectiveness of our approach.', 'abstract_zh': '基于上下文优化的子空间表示学习与提示调优结合的异常分布检测框架', 'title_zh': '面向少量样本 Out-of-Distribution 检测的提示优化与子空间表示学习结合'}
{'arxiv_id': 'arXiv:2509.18108', 'title': 'Solve it with EASE', 'authors': 'Adam Viktorin, Tomas Kadavy, Jozef Kovac, Michal Pluhacek, Roman Senkerik', 'link': 'https://arxiv.org/abs/2509.18108', 'abstract': 'This paper presents EASE (Effortless Algorithmic Solution Evolution), an open-source and fully modular framework for iterative algorithmic solution generation leveraging large language models (LLMs). EASE integrates generation, testing, analysis, and evaluation into a reproducible feedback loop, giving users full control over error handling, analysis, and quality assessment. Its architecture supports the orchestration of multiple LLMs in complementary roles-such as generator, analyst, and evaluator. By abstracting the complexity of prompt design and model management, EASE provides a transparent and extensible platform for researchers and practitioners to co-design algorithms and other generative solutions across diverse domains.', 'abstract_zh': 'This paper presents EASE (Effortless Algorithmic Solution Evolution), 一种利用大型语言模型（LLMs）进行迭代算法解决方案生成的开源且完全可模块化的框架。EASE 将生成、测试、分析和评估整合到可重复的反馈循环中，使用户能够完全控制错误处理、分析和质量评估。其架构支持多种大型语言模型在互补角色（如生成器、分析师和评估器）下的协调工作。通过抽象提示设计和模型管理的复杂性，EASE 提供了一个透明且可扩展的平台，使研究人员和实践者能够在不同领域共同设计算法和其他生成性解决方案。', 'title_zh': '用EASE解决它'}
{'arxiv_id': 'arXiv:2509.18105', 'title': 'BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand', 'authors': 'Nachiket N. Naik, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat', 'link': 'https://arxiv.org/abs/2509.18105', 'abstract': 'We study learning of continuous-time inventory dynamics under stochastic demand and quantify when structure helps or hurts forecasting of the bullwhip effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the entire right-hand side against a physics-informed Universal Differential Equation (UDE) that preserves conservation and order-up-to structure while learning a small residual policy term. Classical supply chain models explain the bullwhip through control/forecasting choices and information sharing, while recent physics-informed and neural differential equation methods blend domain constraints with learned components. It is unclear whether structural bias helps or hinders forecasting under different demand regimes. We address this by using a single-echelon testbed with three demand regimes - AR(1) (autocorrelated), i.i.d. Gaussian, and heavy-tailed lognormal. Training is done on varying fractions of each trajectory, followed by evaluation of multi-step forecasts for inventory I, order rate O, and demand D. Across the structured regimes, UDE consistently generalizes better: with 90% of the training horizon, inventory RMSE drops from 4.92 (NODE) to 0.26 (UDE) under AR(1) and from 5.96 to 0.95 under Gaussian demand. Under heavy-tailed lognormal shocks, the flexibility of NODE is better. These trends persist as train18 ing data shrinks, with NODE exhibiting phase drift in extrapolation while UDE remains stable but underreacts to rare spikes. Our results provide concrete guidance: enforce structure when noise is light-tailed or temporally correlated; relax structure when extreme events dominate. Beyond inventory control, the results offer guidance for hybrid modeling in scientific and engineering systems: enforce known structure when conservation laws and modest noise dominate, and relax structure to capture extremes in settings where rare events drive dynamics.', 'abstract_zh': '我们研究了在随机需求下连续时间库存动态的学习，并量化结构如何帮助或损害牛鞭效应的预测。BULL-ODE将一个完全学习的神经常微分方程（NODE）与一个保留守恒和补充库存结构但学习小型残差策略项的物理启发式通用常微分方程（UDE）进行对比。经典供应链模型通过控制/预测选择和信息共享解释牛鞭效应，而最近的物理启发式和神经常微分方程方法则结合了领域约束与学习组件。尚不清楚结构偏见在不同需求条件下是有助于还是妨碍预测。我们通过使用单一环节试验台和三种需求条件——自相关AR(1)、独立同分布高斯分布和重尾对数正态分布来解决这一问题。在每个轨迹的不同比例下进行训练，然后评估库存I、订单速率O和需求D的多步预测。在结构化条件下，UDE始终表现更好：在AR(1)条件下，随着90%训练时段的使用，库存RMSE从4.92（NODE）降至0.26（UDE）；在高斯需求下，从5.96降至0.95。在重尾对数正态冲击下，NODE的灵活性更高。随着训练数据减少，这些趋势持续存在，NODE在外推时表现出相位漂移，而UDE保持稳定但对稀有突增反应不足。我们的结果为具体指导：当噪声轻尾或时间相关时强制执行结构；当极端事件占主导时放宽结构。超越库存控制，这些结果为科学和工程系统中的混合建模提供了指导：当守恒定律和适度噪声占主导时强制执行已知结构，而在稀有事件驱动动态的环境中放宽结构以捕捉极端情况。', 'title_zh': 'BULL-ODE：在随机需求下基于神经ODE和通用微分方程的学习牛鞭效应'}
{'arxiv_id': 'arXiv:2509.18104', 'title': 'Data Valuation and Selection in a Federated Model Marketplace', 'authors': 'Wenqian Li, Youjia Yang, Ruoxi Jia, Yan Pang', 'link': 'https://arxiv.org/abs/2509.18104', 'abstract': 'In the era of Artificial Intelligence (AI), marketplaces have become essential platforms for facilitating the exchange of data products to foster data sharing. Model transactions provide economic solutions in data marketplaces that enhance data reusability and ensure the traceability of data ownership. To establish trustworthy data marketplaces, Federated Learning (FL) has emerged as a promising paradigm to enable collaborative learning across siloed datasets while safeguarding data privacy. However, effective data valuation and selection from heterogeneous sources in the FL setup remain key challenges. This paper introduces a comprehensive framework centered on a Wasserstein-based estimator tailored for FL. The estimator not only predicts model performance across unseen data combinations but also reveals the compatibility between data heterogeneity and FL aggregation algorithms. To ensure privacy, we propose a distributed method to approximate Wasserstein distance without requiring access to raw data. Furthermore, we demonstrate that model performance can be reliably extrapolated under the neural scaling law, enabling effective data selection without full-scale training. Extensive experiments across diverse scenarios, such as label skew, mislabeled, and unlabeled sources, show that our approach consistently identifies high-performing data combinations, paving the way for more reliable FL-based model marketplaces.', 'abstract_zh': '在人工智能时代，市场平台已成为促进数据产品交换、促进数据共享的重要平台。模型交易为数据市场提供了经济解决方案，增强了数据的重用性并确保了数据所有权的可追溯性。为了建立可信的数据市场，联邦学习（FL）作为一种能够在保护数据隐私的同时实现跨孤岛数据协作学习的有前景的范式而出现。然而，在FL设置中，有效数据估值和来自异构来源的数据选择仍然是关键挑战。本文介绍了一个基于Wasserstein的估计器中心的综合框架。该估计器不仅预测了在未见数据组合上的模型性能，还揭示了数据异构性和FL聚合算法之间的兼容性。为了保证隐私，我们提出了一种分布式方法来近似Wasserstein距离，而无需访问原始数据。此外，我们证明模型性能可以通过神经标度律可靠地外推，从而在无需全规模训练的情况下实现有效数据选择。在各类场景下（如标签偏差、误标和未标来源）的广泛实验表明，我们的方法始终能够识别高性能的数据组合，为更可靠的基于FL的数据市场模型奠定了基础。', 'title_zh': '联邦模型市场中的数据估值与选择'}
