{'arxiv_id': 'arXiv:2505.04583', 'title': 'Modeling Personalized Difficulty of Rehabilitation Exercises Using Causal Trees', 'authors': 'Nathaniel Dennler, Zhonghao Shi, Uksang Yoo, Stefanos Nikolaidis, Maja Matarić', 'link': 'https://arxiv.org/abs/2505.04583', 'abstract': "Rehabilitation robots are often used in game-like interactions for rehabilitation to increase a person's motivation to complete rehabilitation exercises. By adjusting exercise difficulty for a specific user throughout the exercise interaction, robots can maximize both the user's rehabilitation outcomes and the their motivation throughout the exercise. Previous approaches have assumed exercises have generic difficulty values that apply to all users equally, however, we identified that stroke survivors have varied and unique perceptions of exercise difficulty. For example, some stroke survivors found reaching vertically more difficult than reaching farther but lower while others found reaching farther more challenging than reaching vertically. In this paper, we formulate a causal tree-based method to calculate exercise difficulty based on the user's performance. We find that this approach accurately models exercise difficulty and provides a readily interpretable model of why that exercise is difficult for both users and caretakers.", 'abstract_zh': '康复机器人常用于游戏化的互动中以增强个体完成康复锻炼的动力。通过在整个锻炼互动中调整锻炼难度，机器人可以最大化用户的康复效果和锻炼动机。以往的方法假设锻炼的难度值对所有用户都是通用的，然而我们发现中风幸存者对锻炼难度有不同的和独特的感知。例如，一些中风幸存者发现在垂直方向上伸手比向远处但较低位置伸手更困难，而其他人则发现向远处伸手比在垂直方向上伸手更具挑战性。在本文中，我们提出了一种基于因果树的方法来根据用户的性能计算锻炼难度。我们发现这种方法能够准确地建模锻炼难度，并提供了一个易于解释的模型，说明为什么该锻炼对用户和护理人员来说是具有挑战性的。', 'title_zh': '基于因果树建模康复训练的个性化难度'}
{'arxiv_id': 'arXiv:2505.04323', 'title': 'A Case Study on the Application of Digital Twins for Enhancing CPS Operations', 'authors': 'Irina Muntean, Mirgita Frasheri, Tiziano Munaro', 'link': 'https://arxiv.org/abs/2505.04323', 'abstract': 'To ensure the availability and reduce the downtime of complex cyber-physical systems across different domains, e.g., agriculture and manufacturing, fault tolerance mechanisms are implemented which are complex in both their development and operation. In addition, cyber-physical systems are often confronted with limited hardware resources or are legacy systems, both often hindering the addition of new functionalities directly on the onboard hardware. Digital Twins can be adopted to offload expensive computations, as well as providing support through fault tolerance mechanisms, thus decreasing costs and operational downtime of cyber-physical systems. In this paper, we show the feasibility of a Digital Twin used for enhancing cyber-physical system operations, specifically through functional augmentation and increased fault tolerance, in an industry-oriented use case.', 'abstract_zh': '确保跨不同领域（如农业和制造）的复杂 cyber-物理系统可用性和减少停机时间，实施了复杂且在开发和操作上都较为复杂的容错机制。此外，cyber-物理系统经常面临有限的硬件资源或为遗留系统，这两种情况常常妨碍直接在机载硬件上添加新功能。可以通过采用数字孪生来卸载昂贵的计算，并通过容错机制提供支持，从而降低cyber-物理系统的成本和运作停机时间。在本文中，我们通过功能性增强和增加容错机制展示了在工业应用场景中使用数字孪生的可行性。', 'title_zh': '数字孪生在增强CPS运行中的应用案例研究'}
{'arxiv_id': 'arXiv:2505.03917', 'title': 'Improving Failure Prediction in Aircraft Fastener Assembly Using Synthetic Data in Imbalanced Datasets', 'authors': 'Gustavo J. G. Lahr, Ricardo V. Godoy, Thiago H. Segreto, Jose O. Savazzi, Arash Ajoudani, Thiago Boaventura, Glauco A. P. Caurin', 'link': 'https://arxiv.org/abs/2505.03917', 'abstract': "Automating aircraft manufacturing still relies heavily on human labor due to the complexity of the assembly processes and customization requirements. One key challenge is achieving precise positioning, especially for large aircraft structures, where errors can lead to substantial maintenance costs or part rejection. Existing solutions often require costly hardware or lack flexibility. Used in aircraft by the thousands, threaded fasteners, e.g., screws, bolts, and collars, are traditionally executed by fixed-base robots and usually have problems in being deployed in the mentioned manufacturing sites. This paper emphasizes the importance of error detection and classification for efficient and safe assembly of threaded fasteners, especially aeronautical collars. Safe assembly of threaded fasteners is paramount since acquiring sufficient data for training deep learning models poses challenges due to the rarity of failure cases and imbalanced datasets. The paper addresses this by proposing techniques like class weighting and data augmentation, specifically tailored for temporal series data, to improve classification performance. Furthermore, the paper introduces a novel problem-modeling approach, emphasizing metrics relevant to collar assembly rather than solely focusing on accuracy. This tailored approach enhances the models' capability to handle the challenges of threaded fastener assembly effectively.", 'abstract_zh': '自动化飞机制造仍然高度依赖人工劳动，原因在于装配过程的复杂性和定制要求。其中一个关键挑战是在大型飞机结构中实现精确定位，任何错误都可能导致高昂的维护成本或零部件被拒绝。现有的解决方案往往需要昂贵的硬件或缺乏灵活性。在飞机制造中广泛使用螺纹紧固件，如螺钉、螺栓和锁紧环，通常由固定基座机器人执行，但在前述制造现场很难部署。本文强调了在组装螺纹紧固件，尤其是航空锁紧环时进行误差检测和分类的重要性，以实现高效和安全的装配。由于获取足够的数据用于训练深度学习模型存在挑战，包括故障案例罕见性和数据集不平衡问题，因此螺纹紧固件的装配安全性至关重要。本文通过提出类权重调整和数据增强等技术，特别是针对时间序列数据，来提高分类性能。此外，本文还引入了一种新的问题建模方法，强调与锁紧环装配相关的度量标准，而非仅关注准确性。这种方法增强了模型处理螺纹紧固件装配挑战的能力。', 'title_zh': '使用合成数据改进不平衡数据集中的航空紧固件装配故障预测'}
{'arxiv_id': 'arXiv:2505.03820', 'title': 'Satellite Autonomous Clock Fault Monitoring with Inter-Satellite Ranges Using Euclidean Distance Matrices', 'authors': 'Keidai Iiyama, Daniel Neamati, Grace Gao', 'link': 'https://arxiv.org/abs/2505.03820', 'abstract': 'To address the need for robust positioning, navigation, and timing services in lunar environments, this paper proposes a novel onboard clock phase jump detection framework for satellite constellations using range measurements obtained from dual one-way inter-satellite links. Our approach leverages vertex redundantly rigid graphs to detect faults without relying on prior knowledge of satellite positions or clock biases, providing flexibility for lunar satellite networks with diverse satellite types and operators. We model satellite constellations as graphs, where satellites are vertices and inter-satellite links are edges. The proposed algorithm detects and identifies satellites with clock jumps by monitoring the singular values of the geometric-centered Euclidean distance matrix (GCEDM) of 5-clique sub-graphs. The proposed method is validated through simulations of a GPS constellation and a notional constellation around the Moon, demonstrating its effectiveness in various configurations.', 'abstract_zh': '基于双单向星间链路测距测量的月球卫星星座时钟相位跃变检测框架', 'title_zh': '基于星间距离和欧氏距离矩阵的卫星自主时钟故障监测'}
{'arxiv_id': 'arXiv:2505.04539', 'title': 'Qualitative Analysis of $ω$-Regular Objectives on Robust MDPs', 'authors': 'Ali Asadi, Krishnendu Chatterjee, Ehsan Kafshdar Goharshady, Mehrdad Karrabi, Ali Shafiee', 'link': 'https://arxiv.org/abs/2505.04539', 'abstract': 'Robust Markov Decision Processes (RMDPs) generalize classical MDPs that consider uncertainties in transition probabilities by defining a set of possible transition functions. An objective is a set of runs (or infinite trajectories) of the RMDP, and the value for an objective is the maximal probability that the agent can guarantee against the adversarial environment. We consider (a) reachability objectives, where given a target set of states, the goal is to eventually arrive at one of them; and (b) parity objectives, which are a canonical representation for $\\omega$-regular objectives. The qualitative analysis problem asks whether the objective can be ensured with probability 1.\nIn this work, we study the qualitative problem for reachability and parity objectives on RMDPs without making any assumption over the structures of the RMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first present efficient algorithms with oracle access to uncertainty sets that solve qualitative problems of reachability and parity objectives. We then report experimental results demonstrating the effectiveness of our oracle-based approach on classical RMDP examples from the literature scaling up to thousands of states.', 'abstract_zh': '鲁棒马尔可夫决策过程中的稳健性问题：无结构假设下的可达性和优先级目标的质性分析', 'title_zh': 'ω-正规目标下鲁棒MDP的定性分析'}
{'arxiv_id': 'arXiv:2505.04528', 'title': 'Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving', 'authors': 'Qi Liu, Xinhao Zheng, Renqiu Xia, Xingzhi Qi, Qinxiang Cao, Junchi Yan', 'link': 'https://arxiv.org/abs/2505.04528', 'abstract': 'As a seemingly self-explanatory task, problem-solving has been a significant component of science and engineering. However, a general yet concrete formulation of problem-solving itself is missing. With the recent development of AI-based problem-solving agents, the demand for process-level verifiability is rapidly increasing yet underexplored. To fill these gaps, we present a principled formulation of problem-solving as a deterministic Markov decision process; a novel framework, FPS (Formal Problem-Solving), which utilizes existing FTP (formal theorem proving) environments to perform process-verified problem-solving; and D-FPS (Deductive FPS), decoupling solving and answer verification for better human-alignment. The expressiveness, soundness and completeness of the frameworks are proven. We construct three benchmarks on problem-solving: FormalMath500, a formalization of a subset of the MATH500 benchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP benchmarks MiniF2F and PutnamBench. For faithful, interpretable, and human-aligned evaluation, we propose RPE (Restricted Propositional Equivalence), a symbolic approach to determine the correctness of answers by formal verification. We evaluate four prevalent FTP models and two prompting methods as baselines, solving at most 23.77% of FormalMath500, 27.47% of MiniF2F-Solving, and 0.31% of PutnamBench-Solving.', 'abstract_zh': '一种形式化的问题求解框架：D-FPS及其应用', 'title_zh': '超越定理证明：形式问题求解的表述、框架与基准'}
{'arxiv_id': 'arXiv:2505.04525', 'title': 'On some improvements to Unbounded Minimax', 'authors': 'Quentin Cohen-Solal, Tristan Cazenave', 'link': 'https://arxiv.org/abs/2505.04525', 'abstract': 'This paper presents the first experimental evaluation of four previously untested modifications of Unbounded Best-First Minimax algorithm. This algorithm explores the game tree by iteratively expanding the most promising sequences of actions based on the current partial game tree. We first evaluate the use of transposition tables, which convert the game tree into a directed acyclic graph by merging duplicate states. Second, we compare the original algorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which differs in its backpropagation strategy: instead of stopping when a stable value is encountered, it updates values up to the root. This change slightly improves performance when value ties or transposition tables are involved. Third, we assess replacing the exact terminal evaluation function with the learned heuristic function. While beneficial when exact evaluations are costly, this modification reduces performance in inexpensive settings. Finally, we examine the impact of the completion technique that prioritizes resolved winning states and avoids resolved losing states. This technique also improves performance. Overall, our findings highlight how targeted modifications can enhance the efficiency of Unbounded Best-First Minimax.', 'abstract_zh': '本论文首次对四种未测试的Unbounded Best-First Minimax算法修改进行实验评估。该算法通过迭代扩展当前部分游戏树中最有可能的动作序列来探索游戏树。首先评估了转置表的使用情况，该技术通过合并重复状态将游戏树转换为有向无环图。其次，将Korf & Chickering的原始算法与Cohen-Solal提出的变体进行比较，后者在回传策略上有差异：不再遇到稳定值时停止，而是更新到根的所有值。这种变化在涉及价值平局或转置表时轻微提高了性能。第三，评估用学习启发式函数替换精确终局评估函数的情况，虽然在精确评估成本高的情况下有益，但这种修改在成本低廉的情况下降低了性能。最后，研究了优先处理已解决的获胜状态并避免已解决的失败状态的完成技术对其性能的提升作用。总体而言，本文的研究结果强调了有针对性的修改如何提升Unbounded Best-First Minimax算法的效率。', 'title_zh': '关于Unbounded Minimax的一些改进'}
{'arxiv_id': 'arXiv:2505.04352', 'title': 'Uncertain Machine Ethics Planning', 'authors': 'Simon Kolker, Louise A. Dennis, Ramon Fraga Pereira, Mengwei Xu', 'link': 'https://arxiv.org/abs/2505.04352', 'abstract': "Machine Ethics decisions should consider the implications of uncertainty over decisions. Decisions should be made over sequences of actions to reach preferable outcomes long term. The evaluation of outcomes, however, may invoke one or more moral theories, which might have conflicting judgements. Each theory will require differing representations of the ethical situation. For example, Utilitarianism measures numerical values, Deontology analyses duties, and Virtue Ethics emphasises moral character. While balancing potentially conflicting moral considerations, decisions may need to be made, for example, to achieve morally neutral goals with minimal costs. In this paper, we formalise the problem as a Multi-Moral Markov Decision Process and a Multi-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm based on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical Retrospection procedure for ethical reasoning under uncertainty. Our approach is validated by a case study from Machine Ethics literature: the problem of whether to steal insulin for someone who needs it.", 'abstract_zh': '机器伦理决策应考虑决策中的不确定性影响。应基于行动序列以实现长期更佳结果作出决策。然而，结果评估可能涉及一个或多个道德理论，这些理论可能产生相互冲突的判断。每个理论都需要不同的伦理情景表示。例如，功利主义衡量数值，义务论分析义务，美德伦理学强调道德品格。在平衡潜在冲突的道德考量时，可能需要作出决策，例如，以最小成本实现道德中立的目标。在这篇论文中，我们将问题形式化为多道德马尔可夫决策过程和多道德随机最短路径问题。我们开发了一个基于多目标AO*的启发式算法，并利用Sven-Ove Hansson的假设回顾程序进行不确定性下的伦理推理。我们的方法通过机器伦理文献中的一个案例研究得到了验证：是否应为需要的人偷窃胰岛素的问题。', 'title_zh': '不确定性机器伦理规划'}
{'arxiv_id': 'arXiv:2505.04313', 'title': 'KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning', 'authors': 'Stephen Richard Varey, Alessandro Di Stefano, Anh Han', 'link': 'https://arxiv.org/abs/2505.04313', 'abstract': "In this paper, we introduce KERAIA, a novel framework and software platform for symbolic knowledge engineering designed to address the persistent challenges of representing, reasoning with, and executing knowledge in dynamic, complex, and context-sensitive environments. The central research question that motivates this work is: How can unstructured, often tacit, human expertise be effectively transformed into computationally tractable algorithms that AI systems can efficiently utilise? KERAIA seeks to bridge this gap by building on foundational concepts such as Minsky's frame-based reasoning and K-lines, while introducing significant innovations. These include Clouds of Knowledge for dynamic aggregation, Dynamic Relations (DRels) for context-sensitive inheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and Cloud Elaboration for adaptive knowledge transformation. This approach moves beyond the limitations of traditional, often static, knowledge representation paradigms. KERAIA is designed with Explainable AI (XAI) as a core principle, ensuring transparency and interpretability, particularly through the use of LoTs. The paper details the framework's architecture, the KSYNTH representation language, and the General Purpose Paradigm Builder (GPPB) to integrate diverse inference methods within a unified structure. We validate KERAIA's versatility, expressiveness, and practical applicability through detailed analysis of multiple case studies spanning naval warfare simulation, industrial diagnostics in water treatment plants, and strategic decision-making in the game of RISK. Furthermore, we provide a comparative analysis against established knowledge representation paradigms (including ontologies, rule-based systems, and knowledge graphs) and discuss the implementation aspects and computational considerations of the KERAIA platform.", 'abstract_zh': 'KERAIA：一种用于动态复杂环境中的符号知识工程的新框架与软件平台', 'title_zh': 'KERAIA：一种适应性和可解释的动态知识表示与推理框架'}
{'arxiv_id': 'arXiv:2505.04115', 'title': 'Polynomial-Time Relational Probabilistic Inference in Open Universes', 'authors': 'Luise Ge, Brendan Juba, Kris Nilsson', 'link': 'https://arxiv.org/abs/2505.04115', 'abstract': 'Reasoning under uncertainty is a fundamental challenge in Artificial Intelligence. As with most of these challenges, there is a harsh dilemma between the expressive power of the language used, and the tractability of the computational problem posed by reasoning. Inspired by human reasoning, we introduce a method of first-order relational probabilistic inference that satisfies both criteria, and can handle hybrid (discrete and continuous) variables. Specifically, we extend sum-of-squares logic of expectation to relational settings, demonstrating that lifted reasoning in the bounded-degree fragment for knowledge bases of bounded quantifier rank can be performed in polynomial time, even with an a priori unknown and/or countably infinite set of objects. Crucially, our notion of tractability is framed in proof-theoretic terms, which extends beyond the syntactic properties of the language or queries. We are able to derive the tightest bounds provable by proofs of a given degree and size and establish completeness in our sum-of-squares refutations for fixed degrees.', 'abstract_zh': '在不确定性下的推理是人工智能中的一个根本性挑战。受到人类推理的启发，我们提出了一种一阶关系概率推理方法，该方法同时满足表达力和计算可处理性的要求，并能处理混合（离散和连续）变量。具体来说，我们将期望的平方和逻辑扩展到关系设置中，证明在有界度片段中，即使面对的是先验未知且可能是可数无穷的对象集，基于有界量词级的知识库也可以在多项式时间内进行提升推理。最关键的是，我们关于计算可处理性的概念是用证明论的方式定义的，这超越了语言或查询的句法属性。我们能够推导出由给定证明度和大小可证明的最紧边界，并为固定度数建立了平方和反驳的完备性。', 'title_zh': '开放式宇宙中的多项式时间关系概率推理'}
{'arxiv_id': 'arXiv:2505.04019', 'title': 'Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest', 'authors': 'Matteo Ceschin, Leonardo Arrighi, Luca Longo, Sylvio Barbon Junior', 'link': 'https://arxiv.org/abs/2505.04019', 'abstract': "The need to explain predictive models is well-established in modern machine learning. However, beyond model interpretability, understanding pre-processing methods is equally essential. Understanding how data modifications impact model performance improvements and potential biases and promoting a reliable pipeline is mandatory for developing robust machine learning solutions. Isolation Forest (iForest) is a widely used technique for outlier detection that performs well. Its effectiveness increases with the number of tree-based learners. However, this also complicates the explanation of outlier selection and the decision boundaries for inliers. This research introduces a novel Explainable AI (XAI) method, tackling the problem of global explainability. In detail, it aims to offer a global explanation for outlier detection to address its opaque nature. Our approach is based on the Decision Predicate Graph (DPG), which clarifies the logic of ensemble methods and provides both insights and a graph-based metric to explain how samples are identified as outliers using the proposed Inlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's explainability and provides a comprehensive view of the decision-making process, detailing which features contribute to outlier identification and how the model utilizes them. This method advances the state-of-the-art by providing insights into decision boundaries and a comprehensive view of holistic feature usage in outlier identification. -- thus promoting a fully explainable machine learning pipeline.", 'abstract_zh': '现代机器学习中解释预测模型的需求已经得到确立。然而，除了模型可解释性之外，理解预处理方法同样至关重要。理解数据修改如何影响模型性能改进和潜在偏见，并促进可靠的工作流程是开发稳健机器学习解决方案的必要条件。孤立森林（iForest）是一种广泛使用的离群点检测技术，性能良好。其有效性随树基学习器数量的增加而提高。然而，这也使得解释离群点选择及其内点的决策边界变得复杂。本研究引入了一种新的可解释人工智能（XAI）方法，旨在解决全局解释性的问题。具体而言，该方法旨在提供一种全局解释，以应对离群点检测的不透明性。我们的方法基于决策谓词图（DPG），阐明了集成方法的逻辑，并提供了有关样本如何被识别为离群点的图谱解释及其提出的内点-离群点传播得分（IOP-Score）。我们的提议增强了iForest的可解释性，并为决策过程提供了全面视角，详细说明了哪些特征对离群点识别有贡献以及模型是如何利用这些特征的。该方法通过提供决策边界的见解和在离群点识别中整体特征使用的全面视角，促进了最先进的可解释机器学习管道的发展。', 'title_zh': '扩展决策谓词图以全面解释孤立森林'}
{'arxiv_id': 'arXiv:2505.03989', 'title': 'An alignment safety case sketch based on debate', 'authors': 'Marie Davidsen Buhl, Jacob Pfau, Benjamin Hilton, Geoffrey Irving', 'link': 'https://arxiv.org/abs/2505.03989', 'abstract': "If AI systems match or exceed human capabilities on a wide range of tasks, it may become difficult for humans to efficiently judge their actions -- making it hard to use human feedback to steer them towards desirable traits. One proposed solution is to leverage another superhuman system to point out flaws in the system's outputs via a debate. This paper outlines the value of debate for AI safety, as well as the assumptions and further research required to make debate work. It does so by sketching an ``alignment safety case'' -- an argument that an AI system will not autonomously take actions which could lead to egregious harm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D agent inside an AI company sabotaging research, for example by producing false results. To prevent this, the agent is trained via debate, subject to exploration guarantees, to teach the system to be honest. Honesty is maintained throughout deployment via online training. The safety case rests on four key claims: (1) the agent has become good at the debate game, (2) good performance in the debate game implies that the system is mostly honest, (3) the system will not become significantly less honest during deployment, and (4) the deployment context is tolerant of some errors. We identify open research problems that, if solved, could render this a compelling argument that an AI system is safe.", 'abstract_zh': '如果AI系统在广泛的任务上匹配或超越人类能力，人类可能很难高效地判断其行为，从而难以利用人类反馈引导其发展出可取的特质。一种提出的解决方案是利用另一超人类系统通过辩论指出系统输出中的缺陷。本文概述了辩论在AI安全中的价值，以及使其有效工作的假设和进一步研究需求。这通过勾勒一个“对齐安全案例”来实现——一种论证尽管AI系统有能力采取可能导致严重危害的行动，但它不会自主采取这样的行动。该勾勒重点在于防范AI研发代理在AI公司内部搞破坏的风险，例如通过制造虚假结果。为防止这种情况，代理通过辩论训练，并受到探索保证的约束，以教系统保持诚实。在整个部署过程中通过在线训练维持诚实。安全案例基于四个关键主张：（1）代理擅长辩论游戏；（2）在辩论游戏中表现良好意味着系统主要是诚实的；（3）系统在部署过程中不会变得显著不那么诚实；（4）部署环境能容忍某些错误。我们确定了需要解决的开放研究问题，如果这些问题得以解决，这将使得该论证对一个AI系统是安全的具有说服力。', 'title_zh': '基于辩论的对齐安全案例草图'}
{'arxiv_id': 'arXiv:2505.03985', 'title': 'LogiDebrief: A Signal-Temporal Logic based Automated Debriefing Approach with Large Language Models Integration', 'authors': 'Zirong Chen, Ziyan An, Jennifer Reynolds, Kristin Mullen, Stephen Martini, Meiyi Ma', 'link': 'https://arxiv.org/abs/2505.03985', 'abstract': "Emergency response services are critical to public safety, with 9-1-1 call-takers playing a key role in ensuring timely and effective emergency operations. To ensure call-taking performance consistency, quality assurance is implemented to evaluate and refine call-takers' skillsets. However, traditional human-led evaluations struggle with high call volumes, leading to low coverage and delayed assessments. We introduce LogiDebrief, an AI-driven framework that automates traditional 9-1-1 call debriefing by integrating Signal-Temporal Logic (STL) with Large Language Models (LLMs) for fully-covered rigorous performance evaluation. LogiDebrief formalizes call-taking requirements as logical specifications, enabling systematic assessment of 9-1-1 calls against procedural guidelines. It employs a three-step verification process: (1) contextual understanding to identify responder types, incident classifications, and critical conditions; (2) STL-based runtime checking with LLM integration to ensure compliance; and (3) automated aggregation of results into quality assurance reports. Beyond its technical contributions, LogiDebrief has demonstrated real-world impact. Successfully deployed at Metro Nashville Department of Emergency Communications, it has assisted in debriefing 1,701 real-world calls, saving 311.85 hours of active engagement. Empirical evaluation with real-world data confirms its accuracy, while a case study and extensive user study highlight its effectiveness in enhancing call-taking performance.", 'abstract_zh': '一种基于信号时序逻辑和大规模语言模型的AI驱动紧急 debriefing 框架：LogiDebrief', 'title_zh': 'LogiDebrief: 基于信号时序逻辑并整合大型语言模型的自动化认知辅助方法'}
{'arxiv_id': 'arXiv:2505.03941', 'title': 'GRAML: Dynamic Goal Recognition As Metric Learning', 'authors': 'Matan Shamir, Reuth Mirsky', 'link': 'https://arxiv.org/abs/2505.03941', 'abstract': "Goal Recognition (GR) is the problem of recognizing an agent's objectives based on observed actions. Recent data-driven approaches for GR alleviate the need for costly, manually crafted domain models. However, these approaches can only reason about a pre-defined set of goals, and time-consuming training is needed for new emerging goals. To keep this model-learning automated while enabling quick adaptation to new goals, this paper introduces GRAML: Goal Recognition As Metric Learning. GRAML uses a Siamese network to treat GR as a deep metric learning task, employing an RNN that learns a metric over an embedding space, where the embeddings for observation traces leading to different goals are distant, and embeddings of traces leading to the same goals are close. This metric is especially useful when adapting to new goals, even if given just one example observation trace per goal. Evaluated on a versatile set of environments, GRAML shows speed, flexibility, and runtime improvements over the state-of-the-art GR while maintaining accurate recognition.", 'abstract_zh': 'Goal Recognition as Metric Learning (GRAML)', 'title_zh': 'GRAML: 动态目标识别作为元度学习'}
{'arxiv_id': 'arXiv:2505.03800', 'title': 'Design description of Wisdom Computing Persperctive', 'authors': 'TianYi Yu', 'link': 'https://arxiv.org/abs/2505.03800', 'abstract': 'This course design aims to develop and research a handwriting matrix recognition and step-by-step visual calculation process display system, addressing the issue of abstract formulas and complex calculation steps that students find difficult to understand when learning mathematics. By integrating artificial intelligence with visualization animation technology, the system enhances precise recognition of handwritten matrix content through the introduction of Mamba backbone networks, completes digital extraction and matrix reconstruction using the YOLO model, and simultaneously combines CoordAttention coordinate attention mechanisms to improve the accurate grasp of character spatial positions. The calculation process is demonstrated frame by frame through the Manim animation engine, vividly showcasing each mathematical calculation step, helping students intuitively understand the intrinsic logic of mathematical operations. Through dynamically generating animation processes for different computational tasks, the system exhibits high modularity and flexibility, capable of generating various mathematical operation examples in real-time according to student needs. By innovating human-computer interaction methods, it brings mathematical calculation processes to life, helping students bridge the gap between knowledge and understanding on a deeper level, ultimately achieving a learning experience where "every step is understood." The system\'s scalability and interactivity make it an intuitive, user-friendly, and efficient auxiliary tool in education.', 'abstract_zh': '本课程设计旨在开发和研究一种手写矩阵识别及逐步可视化计算过程展示系统，解决学生在学习数学时遇到的抽象公式和复杂的计算步骤难以理解的问题。通过将人工智能与可视化动画技术相结合，系统利用Mamba骨干网络提高手写矩阵内容的精确识别，借助YOLO模型完成数字提取和矩阵重构，并结合CoordAttention坐标注意力机制以提高字符空间位置的准确把握。计算过程通过Manim动画引擎逐帧展示，生动呈现每一个数学计算步骤，帮助学生直观理解数学运算的内在逻辑。通过动态生成不同的计算任务动画过程，系统展现出高度的模块化和灵活性，能够根据学生需求实时生成各种数学运算示例。通过创新人机交互方式，系统使数学计算过程栩栩如生，帮助学生在更深层次上弥合知识与理解之间的差距，最终实现“每一步都理解”的学习体验。该系统的可扩展性和交互性使其成为教育中直观、用户友好且高效的辅助工具。', 'title_zh': '智慧计算视角下的设计描述'}
{'arxiv_id': 'arXiv:2505.03770', 'title': 'Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind', 'authors': "Mouad Abrini, Omri Abend, Dina Acklin, Henny Admoni, Gregor Aichinger, Nitay Alon, Zahra Ashktorab, Ashish Atreja, Moises Auron, Alexander Aufreiter, Raghav Awasthi, Soumya Banerjee, Joe M. Barnby, Rhea Basappa, Severin Bergsmann, Djallel Bouneffouf, Patrick Callaghan, Marc Cavazza, Thierry Chaminade, Sonia Chernova, Mohamed Chetouan, Moumita Choudhury, Axel Cleeremans, Jacek B. Cywinski, Fabio Cuzzolin, Hokin Deng, N'yoma Diamond, Camilla Di Pasquasio, Guillaume Dumas, Max van Duijn, Mahapatra Dwarikanath, Qingying Gao, Ashok Goel, Rebecca Goldstein, Matthew Gombolay, Gabriel Enrique Gonzalez, Amar Halilovic, Tobias Halmdienst, Mahimul Islam, Julian Jara-Ettinger, Natalie Kastel, Renana Keydar, Ashish K. Khanna, Mahdi Khoramshahi, JiHyun Kim, MiHyeon Kim, YoungBin Kim, Senka Krivic, Nikita Krasnytskyi, Arun Kumar, JuneHyoung Kwon, Eunju Lee, Shane Lee, Peter R. Lewis, Xue Li, Yijiang Li, Michal Lewandowski, Nathan Lloyd, Matthew B. Luebbers, Dezhi Luo, Haiyun Lyu, Dwarikanath Mahapatra, Kamal Maheshwari, Mallika Mainali, Piyush Mathur, Patrick Mederitsch, Shuwa Miura, Manuel Preston de Miranda, Reuth Mirsky, Shreya Mishra, Nina Moorman, Katelyn Morrison, John Muchovej, Bernhard Nessler, Felix Nessler, Hieu Minh Jord Nguyen, Abby Ortego, Francis A. Papay, Antoine Pasquali, Hamed Rahimi, Charumathi Raghu, Amanda Royka, Stefan Sarkadi, Jaelle Scheuerman, Simon Schmid, Paul Schrater, Anik Sen, Zahra Sheikhbahaee, Ke Shi, Reid Simmons, Nishant Singh, Mason O. Smith, Ramira van der Meulen, Anthia Solaki, Haoran Sun, Viktor Szolga, Matthew E. Taylor, Travis Taylor, Sanne Van Waveren, Juan David Vargas", 'link': 'https://arxiv.org/abs/2505.03770', 'abstract': 'This volume includes a selection of papers presented at the Workshop on Advancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in Philadelphia US on 3rd March 2025. The purpose of this volume is to provide an open access and curated anthology for the ToM and AI research community.', 'abstract_zh': '本volume收录了于2025年3月3日在美国费城举行的第30届AAAI会议上的“通过理论思维促进人工智能”研讨会 presentations，旨在为理论思维和人工智能研究社区提供开放访问和精选的合集。', 'title_zh': '第一届关于通过理论心智促进人工智能研讨会论文集'}
{'arxiv_id': 'arXiv:2505.04621', 'title': 'Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond', 'authors': 'Jessie Richter-Powell, Antonio Torralba, Jonathan Lorraine', 'link': 'https://arxiv.org/abs/2505.04621', 'abstract': 'We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS) to text-conditioned audio diffusion models. While SDS was initially designed for text-to-3D generation using image diffusion, its core idea of distilling a powerful generative prior into a separate parametric representation extends to the audio domain. Leveraging a single pretrained model, Audio-SDS enables a broad range of tasks without requiring specialized datasets. In particular, we demonstrate how Audio-SDS can guide physically informed impact sound simulations, calibrate FM-synthesis parameters, and perform prompt-specified source separation. Our findings illustrate the versatility of distillation-based methods across modalities and establish a robust foundation for future work using generative priors in audio tasks.', 'abstract_zh': '我们介绍Audio-SDS，这是一种将Score Distillation Sampling (SDS)推广至文本条件音頻扩散模型的方法。尽管SDS最初设计用于基于图像的3D生成，但其核心思想——将强大的生成先验知识提炼为独立的参数表示——适用于音頻领域。通过单一预训练模型，Audio-SDS能够支持广泛的任务，无需专门的数据集。特别是在物理信息冲击声模拟、FM合成参数校准和按提示进行源分离方面，我们展示了Audio-SDS的应用。我们的研究成果证明了基于提炼方法在不同模态下的灵活性，并为未来在音頻任务中使用生成先验的工作奠定了坚实的基础。', 'title_zh': '音频的评分蒸馏采样：源分离、合成与 beyond'}
{'arxiv_id': 'arXiv:2505.04608', 'title': 'WATCH: Weighted Adaptive Testing for Changepoint Hypotheses via Weighted-Conformal Martingales', 'authors': 'Drew Prinster, Xing Han, Anqi Liu, Suchi Saria', 'link': 'https://arxiv.org/abs/2505.04608', 'abstract': "Responsibly deploying artificial intelligence (AI) / machine learning (ML) systems in high-stakes settings arguably requires not only proof of system reliability, but moreover continual, post-deployment monitoring to quickly detect and address any unsafe behavior. Statistical methods for nonparametric change-point detection -- especially the tools of conformal test martingales (CTMs) and anytime-valid inference -- offer promising approaches to this monitoring task. However, existing methods are restricted to monitoring limited hypothesis classes or ``alarm criteria,'' such as data shifts that violate certain exchangeability assumptions, or do not allow for online adaptation in response to shifts. In this paper, we expand the scope of these monitoring methods by proposing a weighted generalization of conformal test martingales (WCTMs), which lay a theoretical foundation for online monitoring for any unexpected changepoints in the data distribution while controlling false-alarms. For practical applications, we propose specific WCTM algorithms that accommodate online adaptation to mild covariate shifts (in the marginal input distribution) while raising alarms in response to more severe shifts, such as concept shifts (in the conditional label distribution) or extreme (out-of-support) covariate shifts that cannot be easily adapted to. On real-world datasets, we demonstrate improved performance relative to state-of-the-art baselines.", 'abstract_zh': '负责任地在高风险环境中部署人工智能（AI）/机器学习（ML）系统不仅需要系统的可靠性证明，而且还要求在部署后进行持续监控，以快速检测和解决任何不安全的行为。通过非参数变化点检测的统计方法——尤其是符合性测试鞅（CTMs）和任意时有效的推断工具——为这一监测任务提供了有前景的方法。然而，现有方法限制在监测有限的假设类别或“警报标准”，如违反某些交换性假设的数据偏移，或者不允许在偏移发生时进行在线适应。在本文中，我们通过提出加权的符合性测试鞅（WCTMs）的一般化形式，扩展了这些监测方法的应用范围，为数据分布中任何意外的变化点提供在线监控的基础，同时控制误报。针对实际应用，我们提出了具体的WCTM算法，能够适应轻微边缘输入分布的变化，并在更严重的偏移如条件标签分布的变化或超出支持范围的极端变化发生时发出警报。我们在实际数据集上的实验结果表明，与现有最佳基线相比，性能有所提升。', 'title_zh': 'WATCH: 加权自适应测试在加权齐性库恩 martingales 作用下的变化点假设检验'}
{'arxiv_id': 'arXiv:2505.04592', 'title': 'AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions', 'authors': 'Peter Barnett, Aaron Scher', 'link': 'https://arxiv.org/abs/2505.04592', 'abstract': 'Humanity appears to be on course to soon develop AI systems that substantially outperform human experts in all cognitive domains and activities. We believe the default trajectory has a high likelihood of catastrophe, including human extinction. Risks come from failure to control powerful AI systems, misuse of AI by malicious rogue actors, war between great powers, and authoritarian lock-in. This research agenda has two aims: to describe the strategic landscape of AI development and to catalog important governance research questions. These questions, if answered, would provide important insight on how to successfully reduce catastrophic risks.\nWe describe four high-level scenarios for the geopolitical response to advanced AI development, cataloging the research questions most relevant to each. Our favored scenario involves building the technical, legal, and institutional infrastructure required to internationally restrict dangerous AI development and deployment (which we refer to as an Off Switch), which leads into an internationally coordinated Halt on frontier AI activities at some point in the future. The second scenario we describe is a US National Project for AI, in which the US Government races to develop advanced AI systems and establish unilateral control over global AI development. We also describe two additional scenarios: a Light-Touch world similar to that of today and a Threat of Sabotage situation where countries use sabotage and deterrence to slow AI development.\nIn our view, apart from the Off Switch and Halt scenario, all of these trajectories appear to carry an unacceptable risk of catastrophic harm. Urgent action is needed from the US National Security community and AI governance ecosystem to answer key research questions, build the capability to halt dangerous AI activities, and prepare for international AI agreements.', 'abstract_zh': '人类似乎即将开发出在所有认知领域和活动中显著超越人类专家的AI系统。我们认为，默认轨迹有很大的可能带来灾难性后果，包括人类灭绝。这些风险源于无法控制强大的AI系统、恶意行为者滥用AI、大国之间的战争以及专制锁定。这项研究议程有两个目标：描述AI发展的战略格局，并列出重要的治理研究问题。如果这些问题得以解答，将会为如何成功降低灾难性风险提供重要见解。\n\n我们描述了四种 geopolitics 对先进AI发展的回应情景，并列出了每个情景中最相关的研究问题。我们偏好的情景是建立国际上限制危险AI开发和部署的技术、法律和制度基础设施（我们称为“关断开关”），并最终在未来某个时候推动国际协调一致的暂停前沿AI活动。我们描述的第二种情景是美国AI国家级项目，其中美国政府将竞相开发先进AI系统并建立对全球AI发展的单方面控制。我们还描述了另外两种情景：一个类似当今世界的轻触监管世界和一个破坏威胁情景，其中国家使用破坏和威慑手段减缓AI的发展。\n\n在我们看来，除了“关断开关”和暂停情景外，所有这些轨迹似乎都带来了不可接受的灾难性危害风险。需要美国国家安全社区和AI治理体系的紧急行动来解答关键研究问题、建立停止危险AI活动的能力，并为国际AI协议的制定做好准备。', 'title_zh': 'AI治理以避免灭绝：战略格局与可操作的研究问题'}
{'arxiv_id': 'arXiv:2505.04558', 'title': 'Purity Law for Generalizable Neural TSP Solvers', 'authors': 'Wenzhao Liu, Haoran Li, Congying Han, Zicheng Zhang, Anqi Li, Tiande Guo', 'link': 'https://arxiv.org/abs/2505.04558', 'abstract': 'Achieving generalization in neural approaches across different scales and distributions remains a significant challenge for the Traveling Salesman Problem~(TSP). A key obstacle is that neural networks often fail to learn robust principles for identifying universal patterns and deriving optimal solutions from diverse instances. In this paper, we first uncover Purity Law (PuLa), a fundamental structural principle for optimal TSP solutions, defining that edge prevalence grows exponentially with the sparsity of surrounding vertices. Statistically validated across diverse instances, PuLa reveals a consistent bias toward local sparsity in global optima. Building on this insight, we propose Purity Policy Optimization~(PUPO), a novel training paradigm that explicitly aligns characteristics of neural solutions with PuLa during the solution construction process to enhance generalization. Extensive experiments demonstrate that PUPO can be seamlessly integrated with popular neural solvers, significantly enhancing their generalization performance without incurring additional computational overhead during inference.', 'abstract_zh': '在不同规模和分布下实现神经方法在旅行销售商问题（TSP）中的泛化仍然是一个重大挑战。一个关键障碍是神经网络往往无法学习到识别普遍模式并从多种实例中推导出最优解的稳健原则。在本文中，我们首先揭示了纯度定律（PuLa），这是一种基本的结构原则，定义了边的频度随着周围顶点稀疏性的增加而呈指数增长。PuLa在多种实例上通过统计验证，揭示了全局最优中的局部稀疏性的一致偏差。基于这一洞见，我们提出了一种新的训练范式——纯度策略优化（PUPO），该范式在解决方案构建过程中明确地将神经解决方案的特征与PuLa对齐，以提高泛化能力。广泛的实验表明，PUPO可以无缝集成到流行的神经求解器中，显著增强其泛化性能，而在推理过程中不会增加额外的计算开销。', 'title_zh': '普遍性原则：通用神经TSP求解器'}
{'arxiv_id': 'arXiv:2505.04553', 'title': 'Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions', 'authors': 'Shanyu Han, Yang Liu, Xiang Yu', 'link': 'https://arxiv.org/abs/2505.04553', 'abstract': 'We propose a reinforcement learning (RL) framework under a broad class of risk objectives, characterized by convex scoring functions. This class covers many common risk measures, such as variance, Expected Shortfall, entropic Value-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue, we consider an augmented state space and an auxiliary variable and recast the problem as a two-state optimization problem. We propose a customized Actor-Critic algorithm and establish some theoretical approximation guarantees. A key theoretical contribution is that our results do not require the Markov decision process to be continuous. Additionally, we propose an auxiliary variable sampling method inspired by the alternating minimization algorithm, which is convergent under certain conditions. We validate our approach in simulation experiments with a financial application in statistical arbitrage trading, demonstrating the effectiveness of the algorithm.', 'abstract_zh': '我们提出了一种广义风险目标下的强化学习框架，由凸评分函数 characterization。该框架涵盖了许多常见风险度量，如方差、预期短falls、熵值 at-risk、均值-风险效用。为解决时间不一致性问题，我们考虑了扩充状态空间和辅助变量，并将问题重新表述为两状态优化问题。我们提出了一种定制化的Actor-Critic算法，并建立了若干理论近似保证。一个重要的理论贡献是，我们的结果不要求马尔可夫决策过程是连续的。此外，我们提出了一种受交替最小化算法启发的辅助变量采样方法，在某些条件下该方法是收敛的。我们在统计套利交易的仿真实验中验证了该方法，展示了该算法的有效性。', 'title_zh': '基于凸评分函数的风险敏感强化学习'}
{'arxiv_id': 'arXiv:2505.04497', 'title': 'Defining and Quantifying Creative Behavior in Popular Image Generators', 'authors': 'Aditi Ramaswamy', 'link': 'https://arxiv.org/abs/2505.04497', 'abstract': 'Creativity of generative AI models has been a subject of scientific debate in the last years, without a conclusive answer. In this paper, we study creativity from a practical perspective and introduce quantitative measures that help the user to choose a suitable AI model for a given task. We evaluated our measures on a number of popular image-to-image generation models, and the results of this suggest that our measures conform to human intuition.', 'abstract_zh': '生成AI模型的创造力在近年来的科学讨论中一直存在争议，缺乏定论。从实用角度研究创造力并引入定量指标以帮助用户选择适合的任务模型——基于这一视角，我们评估了我们的指标在多个流行图像到图像生成模型上的表现，结果表明我们的指标符合人类直觉。', 'title_zh': '定义并量化流行图像生成器中的创造性行为'}
{'arxiv_id': 'arXiv:2505.04468', 'title': 'Spectral and Temporal Denoising for Differentially Private Optimization', 'authors': 'Hyeju Shin, Kyudan Jung, Seongwon Yun, Juyoung Yun', 'link': 'https://arxiv.org/abs/2505.04468', 'abstract': 'This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a differentially private optimization method that addresses the challenge of preserving performance in DP-SGD, where added noise typically degrades model utility. FFTKF integrates frequency-domain noise shaping with Kalman filtering to enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP guarantees. It employs a high-frequency shaping mask in the Fourier domain to concentrate differential privacy noise in less informative spectral components, preserving low-frequency gradient signals. A scalar-gain Kalman filter with finite-difference Hessian approximation further refines the denoised gradients. With a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates improved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers. Theoretical analysis confirms that FFTKF maintains equivalent privacy guarantees while achieving a tighter privacy-utility trade-off through reduced noise and controlled bias.', 'abstract_zh': 'FFT增强卡尔曼滤波器：一种针对DP-SGD性能保护的差分隐私优化方法', 'title_zh': '差分隐私优化的谱域和时域去噪方法'}
{'arxiv_id': 'arXiv:2505.04464', 'title': 'Discriminative Ordering Through Ensemble Consensus', 'authors': 'Louis Ohl, Fredrik Lindsten', 'link': 'https://arxiv.org/abs/2505.04464', 'abstract': 'Evaluating the performance of clustering models is a challenging task where the outcome depends on the definition of what constitutes a cluster. Due to this design, current existing metrics rarely handle multiple clustering models with diverse cluster definitions, nor do they comply with the integration of constraints when available. In this work, we take inspiration from consensus clustering and assume that a set of clustering models is able to uncover hidden structures in the data. We propose to construct a discriminative ordering through ensemble clustering based on the distance between the connectivity of a clustering model and the consensus matrix. We first validate the proposed method with synthetic scenarios, highlighting that the proposed score ranks the models that best match the consensus first. We then show that this simple ranking score significantly outperforms other scoring methods when comparing sets of different clustering algorithms that are not restricted to a fixed number of clusters and is compatible with clustering constraints.', 'abstract_zh': '评估聚类模型的性能是一个具有挑战性的任务，Outcome取决于何为聚类的定义。由于这一设计，现有的度量标准很少能够处理具有多种聚类定义的多个聚类模型，也不符合当有约束条件时的集成。在这项工作中，我们从共识聚类中汲取灵感，假设一个聚类模型集合能够揭示数据中的隐藏结构。我们提出通过基于聚类模型连通性和共识矩阵之间距离的集成聚类来构建一个区分性排序。我们首先使用合成场景验证所提出的方法，表明提出的评分方法首先对与共识匹配最佳的模型进行排名。然后，我们展示这种简单的评分方法在比较不受固定聚类数限制的不同聚类算法集合时显著优于其他评分方法，并且兼容聚类约束。', 'title_zh': '基于集成共识的鉴别性排序'}
{'arxiv_id': 'arXiv:2505.04461', 'title': 'A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities', 'authors': 'Pengfei Jiao, Hongjiang Chen, Xuan Guo, Zhidong Zhao, Dongxiao He, Di Jin', 'link': 'https://arxiv.org/abs/2505.04461', 'abstract': 'Temporal interaction graphs (TIGs), defined by sequences of timestamped interaction events, have become ubiquitous in real-world applications due to their capability to model complex dynamic system behaviors. As a result, temporal interaction graph representation learning (TIGRL) has garnered significant attention in recent years. TIGRL aims to embed nodes in TIGs into low-dimensional representations that effectively preserve both structural and temporal information, thereby enhancing the performance of downstream tasks such as classification, prediction, and clustering within constantly evolving data environments. In this paper, we begin by introducing the foundational concepts of TIGs and emphasize the critical role of temporal dependencies. We then propose a comprehensive taxonomy of state-of-the-art TIGRL methods, systematically categorizing them based on the types of information utilized during the learning process to address the unique challenges inherent to TIGs. To facilitate further research and practical applications, we curate the source of datasets and benchmarks, providing valuable resources for empirical investigations. Finally, we examine key open challenges and explore promising research directions in TIGRL, laying the groundwork for future advancements that have the potential to shape the evolution of this field.', 'abstract_zh': '时间交互图（TIGs）由时间戳标注的交互事件序列定义，因其能够 modeling 复杂动态系统行为而在实际应用中无处不在。因此，时间交互图表示学习（TIGRL）近年来引起了广泛关注。TIGRL旨在将时间交互图中的节点嵌入到低维表示中，有效地保留结构和时间信息，从而在不断变化的数据环境中增强分类、预测和聚类等下游任务的性能。在本文中，我们首先介绍时间交互图的基本概念，并强调时间依赖关系的关键作用。然后，我们提出了一种关于最先进的 TIGRL 方法的全面分类框架，基于学习过程中利用的信息类型系统地对其进行分类，以应对时间交互图固有的独特挑战。为了促进进一步的研究和实际应用，我们汇总了数据集和基准数据的来源，提供了实证研究中宝贵的资源。最后，我们探讨了 TIGRL 中的关键开放挑战，并探索了有希望的研究方向，为该领域的未来进步奠定了基础。', 'title_zh': 'Temporal Interaction图表示学习综述：进展、挑战与机遇'}
{'arxiv_id': 'arXiv:2505.04451', 'title': 'Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform', 'authors': 'Yohannis Telila, Tommaso Cucinotta, Davide Bacciu', 'link': 'https://arxiv.org/abs/2505.04451', 'abstract': 'Automatic music transcription (AMT) is the problem of analyzing an audio recording of a musical piece and detecting notes that are being played. AMT is a challenging problem, particularly when it comes to polyphonic music. The goal of AMT is to produce a score representation of a music piece, by analyzing a sound signal containing multiple notes played simultaneously. In this work, we design a processing pipeline that can transform classical piano audio files in .wav format into a music score representation. The features from the audio signals are extracted using the constant-Q transform, and the resulting coefficients are used as an input to the convolutional neural network (CNN) model.', 'abstract_zh': '自动音乐转录（AMT）是分析音乐乐谱录音并检测正在演奏的音符的问题。AMT 是一个具有挑战性的问题，尤其是在处理多声部音乐时。AMT 的目标是通过分析包含多个同时演奏音符的声信号来生成音乐作品的乐谱表示。在本工作中，我们设计了一个处理管道，可以将 Classical Piano 音频文件转换为 .wav 格式并转化为乐谱表示。从声信号中提取的特征使用常数-Q 变换获取，最终系数作为卷积神经网络（CNN）模型的输入。', 'title_zh': '使用卷积神经网络和常数Q变换的自动音乐转录'}
{'arxiv_id': 'arXiv:2505.04435', 'title': 'FedBWO: Enhancing Communication Efficiency in Federated Learning', 'authors': 'Vahideh Hayyolalam, Öznur Özkasap', 'link': 'https://arxiv.org/abs/2505.04435', 'abstract': 'Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a shared model is collaboratively trained by various clients using their local datasets while keeping the data private. Considering resource-constrained devices, FL clients often suffer from restricted transmission capacity. Aiming to enhance the system performance, the communication between clients and server needs to be diminished. Current FL strategies transmit a tremendous amount of data (model weights) within the FL process, which needs a high communication bandwidth. Considering resource constraints, increasing the number of clients and, consequently, the amount of data (model weights) can lead to a bottleneck. In this paper, we introduce the Federated Black Widow Optimization (FedBWO) technique to decrease the amount of transmitted data by transmitting only a performance score rather than the local model weights from clients. FedBWO employs the BWO algorithm to improve local model updates. The conducted experiments prove that FedBWO remarkably improves the performance of the global model and the communication efficiency of the overall system. According to the experimental outcomes, FedBWO enhances the global model accuracy by an average of 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically decreases the communication cost compared to other methods.', 'abstract_zh': '联邦黑寡妇优化（FedBWO）算法：减少数据传输量提高联邦学习系统性能', 'title_zh': 'FedBWO: 提高联邦学习中的通信效率'}
{'arxiv_id': 'arXiv:2505.04406', 'title': 'YABLoCo: Yet Another Benchmark for Long Context Code Generation', 'authors': 'Aidar Valeev, Roman Garaev, Vadim Lomshakov, Irina Piontkovskaya, Vladimir Ivanov, Israel Adewuyi', 'link': 'https://arxiv.org/abs/2505.04406', 'abstract': 'Large Language Models demonstrate the ability to solve various programming tasks, including code generation. Typically, the performance of LLMs is measured on benchmarks with small or medium-sized context windows of thousands of lines of code. At the same time, in real-world software projects, repositories can span up to millions of LoC. This paper closes this gap by contributing to the long context code generation benchmark (YABLoCo). The benchmark featured a test set of 215 functions selected from four large repositories with thousands of functions. The dataset contained metadata of functions, contexts of the functions with different levels of dependencies, docstrings, functions bodies, and call graphs for each repository. This paper presents three key aspects of the contribution. First, the benchmark aims at function body generation in large repositories in C and C++, two languages not covered by previous benchmarks. Second, the benchmark contains large repositories from 200K to 2,000K LoC. Third, we contribute a scalable evaluation pipeline for efficient computing of the target metrics and a tool for visual analysis of generated code. Overall, these three aspects allow for evaluating code generation in large repositories in C and C++.', 'abstract_zh': '大型语言模型展示了解决各种编程任务的能力，包括代码生成。通常，大型语言模型的性能是在包含数千行代码的小或中等大小上下文窗口的基准测试中进行衡量的。同时，在实际的软件项目中，代码仓库可能包含多达数百万行代码。本文通过贡献一个长上下文代码生成基准（YABLoCo）来弥补这一差距。该基准包含来自四个大型代码仓库的215个函数测试集，每个仓库包含数千个函数。数据集包含函数的元数据、具有不同依赖程度的函数上下文、文档字符串、函数体和调用图。本文呈现了贡献的三个方面。首先，基准旨在生成大型C和C++代码仓库中的函数体，这是之前基准未涵盖的语言。其次，基准包含从20万行到200万行代码的大仓库。第三，我们贡献了一个可扩展的评估管道，用于高效计算目标指标，并提供一个生成代码的可视化分析工具。总之，这三个方面允许对大型C和C++代码仓库中的代码生成进行评估。', 'title_zh': 'YABLoCo: 另一个长上下文代码生成基准'}
{'arxiv_id': 'arXiv:2505.04405', 'title': 'High-speed multiwavelength photonic temporal integration using silicon photonics', 'authors': 'Yi Zhang, Nikolaos Farmakidis, Ioannis Roumpos, Miltiadis Moralis-Pegios, Apostolos Tsakyridis, June Sang Lee, Bowei Dong, Yuhan He, Samarth Aggarwal, Nikolaos Pleros, Harish Bhaskaran', 'link': 'https://arxiv.org/abs/2505.04405', 'abstract': 'Optical systems have been pivotal for energy-efficient computing, performing high-speed, parallel operations in low-loss carriers. While these predominantly analog optical accelerators bypass digitization to perform parallel floating-point computations, scaling optical hardware to map large-vector sizes for AI tasks remains challenging. Here, we overcome this limitation by unfolding scalar operations in time and introducing a photonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration. Counterintuitively, we exploit a slow heat dissipation process to integrate optical signals modulated at 50 GHz bridging the speed gap between the widely applied thermo-optic effects and ultrafast photonics. This architecture supports optical end-to-end signal processing, eliminates inefficient electro-optical conversions, and enables both linear and nonlinear operations within a unified framework. Our results demonstrate a scalable path towards high-speed photonic computing through thermally driven integration.', 'abstract_zh': '光学系统在高效计算中发挥着关键作用，通过低损耗介质实现高速并行运算。尽管这些主要基于模拟的光学加速器可以通过并行浮点计算规避数字化，但将光学硬件扩展以适应大规模向量尺寸进行AI任务仍具有挑战性。通过在时间上展开标量操作并引入光路光子加热单元（PHIL单元）以实现全光学时间积分，我们克服了这一限制。出人意料的是，我们利用缓慢的热耗散过程将50 GHz频率下的光学信号进行集成，从而弥合了广泛应用的温度调制效应与超快光子学之间的速度差距。该架构支持端到端光学信号处理，消除不必要的电光转换，并在统一框架内实现线性和非线性操作。我们的结果展示了通过热驱动集成实现高速光子计算的可扩展路径。', 'title_zh': '基于硅光子学的高速多波长光电时域积分技术'}
{'arxiv_id': 'arXiv:2505.04404', 'title': 'In-Context Adaptation to Concept Drift for Learned Database Operations', 'authors': 'Jiaqi Zhu, Shaofeng Cai, Yanyan Shen, Gang Chen, Fang Deng, Beng Chin Ooi', 'link': 'https://arxiv.org/abs/2505.04404', 'abstract': 'Machine learning has demonstrated transformative potential for database operations, such as query optimization and in-database data analytics. However, dynamic database environments, characterized by frequent updates and evolving data distributions, introduce concept drift, which leads to performance degradation for learned models and limits their practical applicability. Addressing this challenge requires efficient frameworks capable of adapting to shifting concepts while minimizing the overhead of retraining or fine-tuning.\nIn this paper, we propose FLAIR, an online adaptation framework that introduces a new paradigm called \\textit{in-context adaptation} for learned database operations. FLAIR leverages the inherent property of data systems, i.e., immediate availability of execution results for predictions, to enable dynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,| \\,\\mathcal{C}_t) \\to \\mathbf{y}$, with $\\mathcal{C}_t$ representing a dynamic context memory, FLAIR delivers predictions aligned with the current concept, eliminating the need for runtime parameter optimization. To achieve this, FLAIR integrates two key modules: a Task Featurization Module for encoding task-specific features into standardized representations, and a Dynamic Decision Engine, pre-trained via Bayesian meta-training, to adapt seamlessly using contextual information at runtime. Extensive experiments across key database tasks demonstrate that FLAIR outperforms state-of-the-art baselines, achieving up to 5.2x faster adaptation and reducing error by 22.5% for cardinality estimation.', 'abstract_zh': '机器学习在数据库操作中的应用，如查询优化和数据库内数据分析，已经显示出变革性的潜力。然而，动态数据库环境因其频繁的更新和数据分布的演变导致的概念漂移，使得学习模型的性能下降，并限制了其实际应用。解决这一挑战需要能够高效适应不断变化的概念的同时，尽量减小重新训练或微调的开销。\n\n本文提出FLAIR，一种在线适应框架，引入了一种新的范式——集成上下文适应，用于学习的数据库操作。FLAIR利用数据系统固有的特性，即能够即时获取执行结果以进行预测，从而实现动态上下文构建。通过将适应形式化为 $f:(\\mathbf{x} \\,|\\, \\mathcal{C}_t) \\to \\mathbf{y}$，其中 $\\mathcal{C}_t$ 代表动态上下文记忆，FLAIR能够生成与当前概念对齐的预测，消除运行时参数优化的需要。为了实现这一目标，FLAIR集成两个关键模块：任务特征化模块，用于将任务特定特征编码为标准化表示，和基于贝叶斯元训练预训练的动态决策引擎，能够在运行时利用上下文信息无缝适应。在关键数据库任务的广泛实验中，FLAIR优于现有基线，实现高达5.2倍的适应速度提升，并将基数估计的误差减少了22.5%。', 'title_zh': '基于上下文的 Learned 数据库操作概念漂移适应'}
{'arxiv_id': 'arXiv:2505.04379', 'title': 'Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic', 'authors': 'Mohammad Elayan, Wissam Kontar', 'link': 'https://arxiv.org/abs/2505.04379', 'abstract': 'Transportation systems have long been shaped by complexity and heterogeneity, driven by the interdependency of agent actions and traffic outcomes. The deployment of automated vehicles (AVs) in such systems introduces a new challenge: achieving consensus across safety, interaction quality, and traffic performance. In this work, we position consensus as a fundamental property of the traffic system and aim to quantify it. We use high-resolution trajectory data from the Third Generation Simulation (TGSIM) dataset to empirically analyze AV and human-driven vehicle (HDV) behavior at a signalized urban intersection and around vulnerable road users (VRUs). Key metrics, including Time-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns, headways, and string stability, are evaluated across the three performance dimensions. Results show that full consensus across safety, interaction, and performance is rare, with only 1.63% of AV-VRU interaction frames meeting all three conditions. These findings highlight the need for AV models that explicitly balance multi-dimensional performance in mixed-traffic environments. Full reproducibility is supported via our open-source codebase on this https URL.', 'abstract_zh': '交通运输系统长期以来受到复杂性和异质性的影响，由代理行动的相互依赖性和交通结果驱动。自动驾驶车辆（AVs）的部署为系统带来了新的挑战：在安全性、互动质量和交通性能之间达成共识。在本工作中，我们将共识视为交通系统的基本属性，并致力于定量评估它。我们使用来自TGSIM数据集的高分辨率轨迹数据，在信号控制的城市交叉口和弱势道路使用者（VRUs）周围，实证分析AV和人工驾驶车辆（HDVs）的行为。通过评估安全性、互动质量和性能三个维度的关键指标，包括碰撞时间（TTC）、侵入后时间（PET）、减速模式、车距和车队稳定性，结果显示在安全性、互动性和性能三个维度上完全达成共识极为罕见，仅有1.63%的AV-VRU交互帧满足所有三个条件。这些发现强调了在混合交通环境中需要明确平衡多维度性能的AV模型。通过我们的开源代码库，实现了完全可重复性（详见：this https URL）。', 'title_zh': '共识导向的自动驾驶车辆行为：混合城市交通中安全、交互与性能之间的权衡'}
{'arxiv_id': 'arXiv:2505.04354', 'title': 'Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows', 'authors': 'Wenhao Li, Bo Jin, Mingyi Hong, Changhong Lu, Xiangfeng Wang', 'link': 'https://arxiv.org/abs/2505.04354', 'abstract': 'This position paper argues that optimization problem solving can transition from expert-dependent to evolutionary agentic workflows. Traditional optimization practices rely on human specialists for problem formulation, algorithm selection, and hyperparameter tuning, creating bottlenecks that impede industrial adoption of cutting-edge methods. We contend that an evolutionary agentic workflow, powered by foundation models and evolutionary search, can autonomously navigate the optimization space, comprising problem, formulation, algorithm, and hyperparameter spaces. Through case studies in cloud resource scheduling and ADMM parameter adaptation, we demonstrate how this approach can bridge the gap between academic innovation and industrial implementation. Our position challenges the status quo of human-centric optimization workflows and advocates for a more scalable, adaptive approach to solving real-world optimization problems.', 'abstract_zh': '这篇立场论文 argue 讨论了优化问题求解可以从依赖专家转变为进化代理工作流。传统的优化方法依赖于人类专家进行问题表述、算法选择和超参数调整，从而形成阻碍前沿方法在工业中应用的瓶颈。我们认为，基于基础模型和进化搜索的进化代理工作流能够自主导航优化空间，包括问题、表述、算法和超参数空间。通过云资源调度和ADMM参数适应的案例研究，我们展示了这种方法如何弥合学术创新与工业实施之间的差距。我们的立场挑战了以人为中心的优化工作流现状，并倡导一种更具扩展性、更适应实际优化问题的解决方法。', 'title_zh': '优化问题求解可以过渡到进化代理工作流'}
{'arxiv_id': 'arXiv:2505.04340', 'title': 'Multi-Granular Attention based Heterogeneous Hypergraph Neural Network', 'authors': 'Hong Jin, Kaicheng Zhou, Jie Yin, Lan You, Zhifeng Zhou', 'link': 'https://arxiv.org/abs/2505.04340', 'abstract': "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong abilities to learn node representations by effectively extracting complex structural and semantic information in heterogeneous graphs. Most of the prevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging meta-path based message passing to learn latent node representations. However, due to the pairwise nature of meta-paths, these models fail to capture high-order relations among nodes, resulting in suboptimal performance. Additionally, the challenge of ``over-squashing'', where long-range message passing in HeteGNNs leads to severe information distortion, further limits the efficacy of these models. To address these limitations, this paper proposes MGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural Network for heterogeneous graph representation learning. MGA-HHN introduces two key innovations: (1) a novel approach for constructing meta-path based heterogeneous hypergraphs that explicitly models higher-order semantic information in heterogeneous graphs through multiple views, and (2) a multi-granular attention mechanism that operates at both the node and hyperedge levels. This mechanism enables the model to capture fine-grained interactions among nodes sharing the same semantic context within a hyperedge type, while preserving the diversity of semantics across different hyperedge types. As such, MGA-HHN effectively mitigates long-range message distortion and generates more expressive node representations. Extensive experiments on real-world benchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art models, showcasing its effectiveness in node classification, node clustering and visualization tasks.", 'abstract_zh': '基于多粒度注意力的异构超图神经网络（MGA-HHN）：用于异构图表示学习', 'title_zh': '基于多粒度注意力的异构超图神经网络'}
{'arxiv_id': 'arXiv:2505.04318', 'title': 'Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing', 'authors': 'Jacob Glenn Ayers, Buvaneswari A. Ramanan, Manzoor A. Khan', 'link': 'https://arxiv.org/abs/2505.04318', 'abstract': 'As the adoption of deep learning models has grown beyond human capacity for verification, meta-algorithms are needed to ensure reliable model inference. Concept drift detection is a field dedicated to identifying statistical shifts that is underutilized in monitoring neural networks that may encounter inference data with distributional characteristics diverging from their training data. Given the wide variety of model architectures, applications, and datasets, it is important that concept drift detection algorithms are adaptable to different inference scenarios. In this paper, we introduce an application of the $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection meta-algorithm applied to a multilayer perceptron, a convolutional neural network, and a transformer trained for machine vision as they are exposed to simulated drift during inference. To that end, we demonstrate how unexpected drops in accuracy due to concept drift can be detected without directly examining the inference outputs. Our approach enhances safety by ensuring models are continually evaluated for reliability across varying conditions.', 'abstract_zh': '随着深度学习模型的应用超出人类验证能力，需要元算法来确保模型推理的可靠性。概念漂移检测专注于识别统计变化，但在监测可能出现与训练数据分布特性不同的推理数据的神经网络时尚未充分利用。鉴于模型架构、应用场景和数据集的多样性，概念漂移检测算法应适应不同的推理场景。在本文中，我们介绍了一种$\\chi^2$拟合优度假设检验在多层感知器、卷积神经网络和用于机器视觉的变压器中的应用，这些模型在暴露于模拟的推理漂移期间进行训练。我们展示了如何在不直接检查推理输出的情况下检测由于概念漂移导致的意外准确度下降。我们的方法通过确保模型在各种条件下持续评估可靠性来增强安全性。', 'title_zh': '使用卡方拟合优度检验检测神经网络中的概念漂移'}
{'arxiv_id': 'arXiv:2505.04308', 'title': 'Guardians of the Web: The Evolution and Future of Website Information Security', 'authors': 'Md Saiful Islam, Li Xiangdong', 'link': 'https://arxiv.org/abs/2505.04308', 'abstract': 'Website information security has become a critical concern in the digital age. This article explores the evolution of website information security, examining its historical development, current practices, and future directions. The early beginnings from the 1960s to the 1980s laid the groundwork for modern cybersecurity, with the development of ARPANET, TCP/IP, public-key cryptography, and the first antivirus programs. The 1990s marked a transformative era, driven by the commercialization of the Internet and the emergence of web-based services. As the Internet grew, so did the range and sophistication of cyber threats, leading to advancements in security technologies such as the Secure Sockets Layer (SSL) protocol, password protection, and firewalls. Current practices in website information security involve a multi-layered approach, including encryption, secure coding practices, regular security audits, and user education. The future of website information security is expected to be shaped by emerging technologies such as artificial intelligence, blockchain, and quantum computing, as well as the increasing importance of international cooperation and standardization efforts. As cyber threats continue to evolve, ongoing research and innovation in website information security will be essential to protect sensitive information and maintain trust in the digital world.', 'abstract_zh': '网站信息安全已成为数字时代的关键关切。本文探讨了网站信息安全的发展演变，审视其历史发展、当前实践和未来方向。从20世纪60年代到80年代的早期 beginnings奠定了现代网络安全的基础，ARPANET、TCP/IP、公钥加密和首批防病毒程序的发展都是其中的重要组成部分。20世纪90年代标志着一个变革的时代，这一时期互联网的商业化和基于Web的服务的出现是其主要推动力。随着互联网的发展，网络威胁的种类和复杂性也随之增加，这推动了如安全套接层（SSL）协议、密码保护和防火墙等安全技术的进步。当前的网站信息安全实践采用了多层方法，包括加密、安全编码实践、定期安全审计和用户教育。网站信息安全的未来将受新兴技术（如人工智能、区块链和量子计算）以及国际协作和标准制定努力不断增强重要性的影响。随着网络威胁持续演变，网站信息安全领域的持续研究与创新对于保护敏感信息和维护数字世界的信任将是必不可少的。', 'title_zh': '网络守护者：网站信息安全的演变与未来'}
{'arxiv_id': 'arXiv:2505.04300', 'title': 'Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning', 'authors': 'Isabella Caranzano, Corrado Pancotti, Cesare Rollo, Flavio Sartori, Pietro Liò, Piero Fariselli, Tiziana Sanavia', 'link': 'https://arxiv.org/abs/2505.04300', 'abstract': "Biologically-informed neural networks typically leverage pathway annotations to enhance performance in biomedical applications. We hypothesized that the benefits of pathway integration does not arise from its biological relevance, but rather from the sparsity it introduces. We conducted a comprehensive analysis of all relevant pathway-based neural network models for predictive tasks, critically evaluating each study's contributions. From this review, we curated a subset of methods for which the source code was publicly available. The comparison of the biologically informed state-of-the-art deep learning models and their randomized counterparts showed that models based on randomized information performed equally well as biologically informed ones across different metrics and datasets. Notably, in 3 out of the 15 analyzed models, the randomized versions even outperformed their biologically informed counterparts. Moreover, pathway-informed models did not show any clear advantage in interpretability, as randomized models were still able to identify relevant disease biomarkers despite lacking explicit pathway information. Our findings suggest that pathway annotations may be too noisy or inadequately explored by current methods. Therefore, we propose a methodology that can be applied to different domains and can serve as a robust benchmark for systematically comparing novel pathway-informed models against their randomized counterparts. This approach enables researchers to rigorously determine whether observed performance improvements can be attributed to biological insights.", 'abstract_zh': '生物信息导向的神经网络通常通过路径注释来提高生物医学应用中的性能。我们假设路径集成的好处并非来自其生物学相关性，而是来自其引入的稀疏性。我们对所有与预测任务相关的基于路径的神经网络模型进行了全面分析，并对每一项研究的贡献进行了批判性评估。从这项综述中，我们筛选出了一组公开可获取源代码的方法。对比生物信息导向的前沿深度学习模型与其随机化版本的性能，结果显示基于随机信息的模型在不同指标和数据集上表现与生物信息导向的模型相当。值得注意的是，在分析的15个模型中有3个模型的随机化版本甚至优于其生物信息导向的版本。此外，路径导向的模型在可解释性方面并没有显示出明显的优势，尽管缺乏显式路径信息，随机化模型仍然能够识别出相关的疾病生物标志物。我们的研究结果表明，当前方法可能尚未充分探索路径注释的有效性，因此我们提出了一种可在不同领域应用的方法，并可作为系统比较新路径导向模型与其随机化版本的稳健基准。该方法允许研究人员严格确定观察到的性能改进是否源于生物学洞察。', 'title_zh': '稀疏性即为关键：重思生物途径导向的深度学习方法'}
{'arxiv_id': 'arXiv:2505.04284', 'title': 'GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance', 'authors': 'Sofia Jamil, Aryan Dabad, Bollampalli Areen Reddy, Sriparna Saha, Rajiv Misra, Adil A. Shakur', 'link': 'https://arxiv.org/abs/2505.04284', 'abstract': 'In the realm of cancer treatment, summarizing adverse drug events (ADEs) reported by patients using prescribed drugs is crucial for enhancing pharmacovigilance practices and improving drug-related decision-making. While the volume and complexity of pharmacovigilance data have increased, existing research in this field has predominantly focused on general diseases rather than specifically addressing cancer. This work introduces the task of grouped summarization of adverse drug events reported by multiple patients using the same drug for cancer treatment. To address the challenge of limited resources in cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug Reaction and Summarization (MCADRS) dataset. This dataset includes pharmacovigilance posts detailing patient concerns regarding drug efficacy and adverse effects, along with extracted labels for drug names, adverse drug events, severity, and adversity of reactions, as well as summaries of ADEs for each drug. Additionally, we propose the Grouping and Abstractive Summarization of Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that combines the information extraction capabilities of Large Language Models (LLMs) with the summarization power of the encoder-decoder T5 model. Our work is the first to apply alignment techniques, including advanced algorithms like Direct Preference Optimization, to encoder-decoder models using synthetic datasets for summarization tasks. Through extensive experiments, we demonstrate the superior performance of GASCADE across various metrics, validated through both automated assessments and human evaluations. This multitasking approach enhances drug-related decision-making and fosters a deeper understanding of patient concerns, paving the way for advancements in personalized and responsive cancer care. The code and dataset used in this work are publicly available.', 'abstract_zh': '基于患者报告的抗癌药物不良药物事件分组总结在癌症治疗领域药物警戒实践中的应用研究', 'title_zh': 'GCASCADE：分组药物不良事件总结以增强癌症药品监控'}
{'arxiv_id': 'arXiv:2505.04278', 'title': 'Non-stationary Diffusion For Probabilistic Time Series Forecasting', 'authors': 'Weiwei Ye, Zhuopeng Xu, Ning Gui', 'link': 'https://arxiv.org/abs/2505.04278', 'abstract': 'Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at this https URL.', 'abstract_zh': '基于位置-尺度噪声模型的非稳态扩散概率预测框架', 'title_zh': '非平稳扩散的概率时间序列预测'}
{'arxiv_id': 'arXiv:2505.04223', 'title': 'FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning', 'authors': 'Sanghyeon Park, Soo-Mook Moon', 'link': 'https://arxiv.org/abs/2505.04223', 'abstract': "Federated learning (FL) enables collaborative model training across distributed clients while preserving data locality. Although FedAvg pioneered synchronous rounds for global model averaging, slower devices can delay collective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by continuously integrating client updates, yet naive implementations risk client drift due to non-IID data and stale contributions. Some Blockchain-based FL approaches (e.g., BRAIN) employ robust weighting or scoring of updates to resist malicious or misaligned proposals. However, performance drops can still persist under severe data heterogeneity or high staleness, and synchronization overhead has emerged as a new concern due to its aggregator-free architectures.\nWe introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL method that mitigates these limitations by incorporating two key ideas. First, our FastSync strategy eliminates the need to replay past model versions, enabling newcomers and infrequent participants to efficiently approximate the global model. Second, we adopt spherical linear interpolation (SLERP) when merging parameters, preserving models' directions and alleviating destructive interference from divergent local training.\nExperiments with a CNN image-classification model and a Transformer-based language model demonstrate that FRAIN achieves more stable and robust convergence than FedAvg, FedAsync, and BRAIN, especially under harsh environments: non-IID data distributions, networks that experience delays and require frequent re-synchronization, and the presence of malicious nodes.", 'abstract_zh': '快速可靠AI网络：一种新的异步联邦学习方法', 'title_zh': 'FRAIN to Train: 一种快速可靠的分布式联邦学习解决方案'}
{'arxiv_id': 'arXiv:2505.04165', 'title': 'TS-SNN: Temporal Shift Module for Spiking Neural Networks', 'authors': 'Kairong Yu, Tianqing Zhang, Qi Xu, Gang Pan, Hongwei Wang', 'link': 'https://arxiv.org/abs/2505.04165', 'abstract': 'Spiking Neural Networks (SNNs) are increasingly recognized for their biological plausibility and energy efficiency, positioning them as strong alternatives to Artificial Neural Networks (ANNs) in neuromorphic computing applications. SNNs inherently process temporal information by leveraging the precise timing of spikes, but balancing temporal feature utilization with low energy consumption remains a challenge. In this work, we introduce Temporal Shift module for Spiking Neural Networks (TS-SNN), which incorporates a novel Temporal Shift (TS) module to integrate past, present, and future spike features within a single timestep via a simple yet effective shift operation. A residual combination method prevents information loss by integrating shifted and original features. The TS module is lightweight, requiring only one additional learnable parameter, and can be seamlessly integrated into existing architectures with minimal additional computational cost. TS-SNN achieves state-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100 (80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low energy consumption. This work marks a significant step forward in developing efficient and accurate SNN architectures.', 'abstract_zh': '基于时空移位模块的脉冲神经网络（TS-SNN）：高效且精确的时间和能量管理', 'title_zh': 'TS-SNN: Temporal Shift 模块 for Spiking Neural Networks'}
{'arxiv_id': 'arXiv:2505.04083', 'title': 'Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training', 'authors': 'Aditya K. Ranjan, Siddharth Singh, Cunyang Wei, Abhinav Bhatele', 'link': 'https://arxiv.org/abs/2505.04083', 'abstract': 'Graph neural networks have emerged as a potent class of neural networks capable of leveraging the connectivity and structure of real-world graphs to learn intricate properties and relationships between nodes. Many real-world graphs exceed the memory capacity of a GPU due to their sheer size, and using GNNs on them requires techniques such as mini-batch sampling to scale. However, this can lead to reduced accuracy in some cases, and sampling and data transfer from the CPU to the GPU can also slow down training. On the other hand, distributed full-graph training suffers from high communication overhead and load imbalance due to the irregular structure of graphs. We propose Plexus, a three-dimensional (3D) parallel approach for full-graph training that tackles these issues and scales to billion-edge graphs. Additionally, we introduce optimizations such as a permutation scheme for load balancing, and a performance model to predict the optimal 3D configuration. We evaluate Plexus on several graph datasets and show scaling results for up to 2048 GPUs on Perlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus achieves unprecedented speedups of 2.3x-12.5x over existing methods and a reduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on Frontier.', 'abstract_zh': 'Plexus：一种三维并行方法，用于处理十亿边图的全图训练', 'title_zh': 'Plexus: 三维并行GNN训练驯化亿级边图'}
{'arxiv_id': 'arXiv:2505.04034', 'title': 'Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks', 'authors': 'Ayana Moshruba, Hamed Poursiami, Maryam Parsa', 'link': 'https://arxiv.org/abs/2505.04034', 'abstract': 'Biological neurons exhibit diverse temporal spike patterns, which are believed to support efficient, robust, and adaptive neural information processing. While models such as Izhikevich can replicate a wide range of these firing dynamics, their complexity poses challenges for directly integrating them into scalable spiking neural networks (SNN) training pipelines. In this work, we propose two probabilistically driven, input-level temporal spike transformations: Poisson-Burst and Delayed-Burst that introduce biologically inspired temporal variability directly into standard Leaky Integrate-and-Fire (LIF) neurons. This enables scalable training and systematic evaluation of how spike timing dynamics affect privacy, generalization, and learning performance. Poisson-Burst modulates burst occurrence based on input intensity, while Delayed-Burst encodes input strength through burst onset timing. Through extensive experiments across multiple benchmarks, we demonstrate that Poisson-Burst maintains competitive accuracy and lower resource overhead while exhibiting enhanced privacy robustness against membership inference attacks, whereas Delayed-Burst provides stronger privacy protection at a modest accuracy trade-off. These findings highlight the potential of biologically grounded temporal spike dynamics in improving the privacy, generalization and biological plausibility of neuromorphic learning systems.', 'abstract_zh': '生物神经元表现出多样化的时空放电模式，这些模式被认为支持高效、稳健和适应性的神经信息处理。虽然Izhikevich等模型可以复制这些放电动态的广泛范围，但它们的复杂性为直接将它们集成到可扩展的脉冲神经网络（SNN）训练管道中带来了挑战。在本工作中，我们提出了两种基于概率的输入级时空放电变换：Poisson-Burst和Delayed-Burst，直接将生物启发的时空变异性引入标准的泄漏型积分-发放（LIF）神经元中。这使得可以实现可扩展的训练并系统地评估放电时间动态如何影响隐私、泛化和学习性能。Poisson-Burst基于输入强度调节爆发的发生，而Delayed-Burst通过爆发起始时间编码输入强度。通过在多个基准上的广泛实验，我们证明Poisson-Burst在保持竞争力的同时降低了资源开销，且在对抗成员推理攻击方面的隐私鲁棒性有所提升，而Delayed-Burst在轻微的准确性折衷下提供了更强的隐私保护。这些发现强调了基于生物过程的时间放电动态在提高神经形态学习系统中的隐私性、泛化能力和生物可行性方面的潜在价值。', 'title_zh': '受Izhikevich启发的时序动态以增强脉冲神经网络中的隐私性、效率和可迁移性'}
{'arxiv_id': 'arXiv:2505.04015', 'title': 'MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models', 'authors': 'Soheil Zibakhsh Shabgahi, Yaman Jandali, Farinaz Koushanfar', 'link': 'https://arxiv.org/abs/2505.04015', 'abstract': "This paper proposes MergeGuard, a novel methodology for mitigation of AI Trojan attacks. Trojan attacks on AI models cause inputs embedded with triggers to be misclassified to an adversary's target class, posing a significant threat to model usability trained by an untrusted third party. The core of MergeGuard is a new post-training methodology for linearizing and merging fully connected layers which we show simultaneously improves model generalizability and performance. Our Proof of Concept evaluation on Transformer models demonstrates that MergeGuard maintains model accuracy while decreasing trojan attack success rate, outperforming commonly used (post-training) Trojan mitigation by fine-tuning methodologies.", 'abstract_zh': 'MergeGuard：一种新型的AI木马攻击缓解方法', 'title_zh': 'MergeGuard: 在机器学习模型中高效对抗木马攻击的方法'}
{'arxiv_id': 'arXiv:2505.03983', 'title': 'Diffusion Models are Secretly Exchangeable: Parallelizing DDPMs via Autospeculation', 'authors': 'Hengyuan Hu, Aniket Das, Dorsa Sadigh, Nima Anari', 'link': 'https://arxiv.org/abs/2505.03983', 'abstract': 'Denoising Diffusion Probabilistic Models (DDPMs) have emerged as powerful tools for generative modeling. However, their sequential computation requirements lead to significant inference-time bottlenecks. In this work, we utilize the connection between DDPMs and Stochastic Localization to prove that, under an appropriate reparametrization, the increments of DDPM satisfy an exchangeability property. This general insight enables near-black-box adaptation of various performance optimization techniques from autoregressive models to the diffusion setting. To demonstrate this, we introduce \\emph{Autospeculative Decoding} (ASD), an extension of the widely used speculative decoding algorithm to DDPMs that does not require any auxiliary draft models. Our theoretical analysis shows that ASD achieves a $\\tilde{O} (K^{\\frac{1}{3}})$ parallel runtime speedup over the $K$ step sequential DDPM. We also demonstrate that a practical implementation of autospeculative decoding accelerates DDPM inference significantly in various domains.', 'abstract_zh': '去噪扩散概率模型（DDPMs）已经成为生成建模的强大工具。然而，它们的顺序计算要求导致了推断时的重大瓶颈。在本文中，我们利用DDPMs与随机局部化的连接，证明在适当的重构参数下，DDPM的增量满足可交换性。这一一般见解使得可以将各种性能优化技术从自回归模型直接适应到扩散设置中。为了证明这一点，我们引入了\\emph{自推测解码}（ASD），这是一种将广泛使用的推测解码算法扩展到DDPMs的方法，无需任何辅助草图模型。我们的理论分析表明，ASD在$K$步顺序DDPM上实现了$\\tilde{O}(K^{\\frac{1}{3}})$的并行运行时间加速。我们还展示了自推测解码的实用实现可以显著加速DDPM在各种领域的推断过程。', 'title_zh': '扩散模型实际上具有交换性：通过自动推测并行化DDPMs'}
{'arxiv_id': 'arXiv:2505.03946', 'title': 'Decentralized Distributed Proximal Policy Optimization (DD-PPO) for High Performance Computing Scheduling on Multi-User Systems', 'authors': 'Matthew Sgambati, Aleksandar Vakanski, Matthew Anderson', 'link': 'https://arxiv.org/abs/2505.03946', 'abstract': 'Resource allocation in High Performance Computing (HPC) environments presents a complex and multifaceted challenge for job scheduling algorithms. Beyond the efficient allocation of system resources, schedulers must account for and optimize multiple performance metrics, including job wait time and system utilization. While traditional rule-based scheduling algorithms dominate the current deployments of HPC systems, the increasing heterogeneity and scale of those systems is expected to challenge the efficiency and flexibility of those algorithms in minimizing job wait time and maximizing utilization. Recent research efforts have focused on leveraging advancements in Reinforcement Learning (RL) to develop more adaptable and intelligent scheduling strategies. Recent RL-based scheduling approaches have explored a range of algorithms, from Deep Q-Networks (DQN) to Proximal Policy Optimization (PPO), and more recently, hybrid methods that integrate Graph Neural Networks with RL techniques. However, a common limitation across these methods is their reliance on relatively small datasets, and these methods face scalability issues when using large datasets. This study introduces a novel RL-based scheduler utilizing the Decentralized Distributed Proximal Policy Optimization (DD-PPO) algorithm, which supports large-scale distributed training across multiple workers without requiring parameter synchronization at every step. By eliminating reliance on centralized updates to a shared policy, the DD-PPO scheduler enhances scalability, training efficiency, and sample utilization. The validation dataset leveraged over 11.5 million real HPC job traces for comparing DD-PPO performance between traditional and advanced scheduling approaches, and the experimental results demonstrate improved scheduling performance in comparison to both rule-based schedulers and existing RL-based scheduling algorithms.', 'abstract_zh': '高性能计算（HPC）环境中资源分配为作业调度算法提出了一个复杂且多面的挑战。除了有效地分配系统资源外，调度器必须考虑和优化多个性能指标，包括作业等待时间和系统利用率。虽然传统的基于规则的调度算法目前占据了HPC系统的部署，但那些系统的日益异构性和规模预计将对这些算法在最小化作业等待时间和最大化利用率方面的效率和灵活性提出挑战。最近的研究工作集中在利用强化学习（RL）的最新进展来开发更加适应性和智能的调度策略。最近基于RL的调度方法探索了从深度Q网络（DQN）到正则化策略优化（PPO）等一系列算法，并且最近还开发了将图神经网络与RL技术结合的混合方法。然而，这些方法的一个常见局限是它们依赖于相对较小的数据集，并且在使用大数据集时面临可扩展性问题。本研究提出了一种新型的基于RL的调度器，采用分散分布式正则化策略优化（DD-PPO）算法，在多个工人之间实现大规模分布式训练而无需在每一步都进行参数同步。通过消除对集中更新共享策略的依赖，DD-PPO调度器增强了可扩展性、训练效率和样本利用。实验利用超过1150万个实际HPC作业轨迹的数据集来对比DD-PPO与其他传统和高级调度方法的性能，实验结果表明，与基于规则的调度器和现有的基于RL的调度算法相比，DD-PPO调度器在调度性能上取得了改进。', 'title_zh': '多用户系统中高性能计算调度的去中心化分布式近端策略优化（DD-PPO）'}
{'arxiv_id': 'arXiv:2505.03945', 'title': 'AI-Driven Security in Cloud Computing: Enhancing Threat Detection, Automated Response, and Cyber Resilience', 'authors': 'Shamnad Mohamed Shaffi, Sunish Vengathattil, Jezeena Nikarthil Sidhick, Resmi Vijayan', 'link': 'https://arxiv.org/abs/2505.03945', 'abstract': "Cloud security concerns have been greatly realized in recent years due to the increase of complicated threats in the computing world. Many traditional solutions do not work well in real-time to detect or prevent more complex threats. Artificial intelligence is today regarded as a revolution in determining a protection plan for cloud data architecture through machine learning, statistical visualization of computing infrastructure, and detection of security breaches followed by counteraction. These AI-enabled systems make work easier as more network activities are scrutinized, and any anomalous behavior that might be a precursor to a more serious breach is prevented. This paper examines ways AI can enhance cloud security by applying predictive analytics, behavior-based security threat detection, and AI-stirring encryption. It also outlines the problems of the previous security models and how AI overcomes them. For a similar reason, issues like data privacy, biases in the AI model, and regulatory compliance are also covered. So, AI improves the protection of cloud computing contexts; however, more efforts are needed in the subsequent phases to extend the technology's reliability, modularity, and ethical aspects. This means that AI can be blended with other new computing technologies, including blockchain, to improve security frameworks further. The paper discusses the current trends in securing cloud data architecture using AI and presents further research and application directions.", 'abstract_zh': '近年来，由于计算世界中复杂威胁的增加，云安全问题得到了广泛关注。许多传统解决方案无法在实时检测或预防更复杂的威胁中发挥良好作用。人工智能被认为是通过机器学习、计算基础设施的统计可视化、检测安全违规并采取相应措施来为云数据架构制定保护计划的一种革命。这些基于人工智能的系统通过审查更多的网络活动使工作变得更加容易，并防止了可能导致更严重违规的任何异常行为。本文探讨了人工智能如何通过预测分析、基于行为的安全威胁检测以及人工智能驱动的加密来增强云安全。它还概述了之前安全模型的问题以及人工智能如何克服这些问题。由于类似原因，数据隐私、人工智能模型中的偏差和监管合规性等问题也得到了讨论。因此，人工智能提高了云计算环境的保护水平；然而，在后续阶段仍需更多努力来扩展该技术的可靠性、模块性和伦理方面。这意味着人工智能可以与其他新兴计算技术，包括区块链，相结合，以进一步改善安全框架。本文讨论了使用人工智能保护云数据架构的当前趋势，并提出了进一步的研究和应用方向。', 'title_zh': 'AI驱动的云 computing 安全：提升威胁检测、自动化应对和网络安全韧性'}
{'arxiv_id': 'arXiv:2505.03899', 'title': 'A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions', 'authors': 'Danial Davarnia, Mohammadreza Kiaghadi', 'link': 'https://arxiv.org/abs/2505.03899', 'abstract': 'Optimization problems with norm-bounding constraints arise in a variety of applications, including portfolio optimization, machine learning, and feature selection. A common approach to these problems involves relaxing the norm constraint via Lagrangian relaxation, transforming it into a regularization term in the objective function. A particularly challenging class includes the zero-norm function, which promotes sparsity in statistical parameter estimation. Most existing exact methods for solving these problems introduce binary variables and artificial bounds to reformulate them as higher-dimensional mixed-integer programs, solvable by standard solvers. Other exact approaches exploit specific structural properties of the objective, making them difficult to generalize across different problem types. Alternative methods employ nonconvex penalties with favorable statistical characteristics, but these are typically addressed using heuristic or local optimization techniques due to their structural complexity. In this paper, we propose a novel graph-based method to globally solve optimization problems involving generalized norm-bounding constraints. Our approach encompasses standard $\\ell_p$-norms for $p \\in [0, \\infty)$ and nonconvex penalties such as SCAD and MCP. We leverage decision diagrams to construct strong convex relaxations directly in the original variable space, eliminating the need for auxiliary variables or artificial bounds. Integrated into a spatial branch-and-cut framework, our method guarantees convergence to the global optimum. We demonstrate its effectiveness through preliminary computational experiments on benchmark sparse linear regression problems involving complex nonconvex penalties, which are not tractable using existing global optimization techniques.', 'abstract_zh': '基于图的方法求解涉及广义范数约束的优化问题', 'title_zh': '非凸正则化函数下统计模型参数估计的图形全局优化框架'}
{'arxiv_id': 'arXiv:2505.03867', 'title': 'Scratch Copilot: Supporting Youth Creative Coding with AI', 'authors': 'Stefania Druga, Amy J. Ko', 'link': 'https://arxiv.org/abs/2505.03867', 'abstract': "Creative coding platforms like Scratch have democratized programming for children, yet translating imaginative ideas into functional code remains a significant hurdle for many young learners. While AI copilots assist adult programmers, few tools target children in block-based environments. Building on prior research \\cite{druga_how_2021,druga2023ai, druga2023scratch}, we present Cognimates Scratch Copilot: an AI-powered assistant integrated into a Scratch-like environment, providing real-time support for ideation, code generation, debugging, and asset creation. This paper details the system architecture and findings from an exploratory qualitative evaluation with 18 international children (ages 7--12). Our analysis reveals how the AI Copilot supported key creative coding processes, particularly aiding ideation and debugging. Crucially, it also highlights how children actively negotiated the use of AI, demonstrating strong agency by adapting or rejecting suggestions to maintain creative control. Interactions surfaced design tensions between providing helpful scaffolding and fostering independent problem-solving, as well as learning opportunities arising from navigating AI limitations and errors. Findings indicate Cognimates Scratch Copilot's potential to enhance creative self-efficacy and engagement. Based on these insights, we propose initial design guidelines for AI coding assistants that prioritize youth agency and critical interaction alongside supportive scaffolding.", 'abstract_zh': '创意编程平台如Scratch虽然已使编程 democratized 于儿童，但将富有想象力的想法转化为可运行的代码仍然是许多年轻学习者的一大障碍。虽然 AI 共同飞行员辅助成人编程，但很少有工具针对基于积木的环境中的儿童。基于先前的研究 \\cite{druga_how_2021,druga2023ai, druga2023scratch}，我们介绍了 Cognimates Scratch 共同飞行员：一种集成于类似 Scratch 的环境中的人工智能辅助工具，提供实时支持，包括创意思维、代码生成、调试和资产创建。本文详细介绍了该系统架构及其对 18 名国际儿童（年龄 7-12 岁）进行探索性定性评估的发现。我们的分析揭示了人工智能共同飞行员如何支持关键的创意编程过程，特别是帮助创新点的开发和调试。重要的是，它还突显了儿童如何积极协商人工智能的使用，表现出强大的自主权，通过适应或拒绝建议来保持创意控制。互动体现出在提供有帮助的教学支架和培养独立问题解决能力之间的设计张力，同时也揭示了导航人工智能限制和错误所带来的学习机会。研究结果表明，Cognimates Scratch 共同飞行员有可能增强创意自我效能感和参与度。基于这些见解，我们提出了一些建议的设计指南，强调青少年的自主权和批判性交互并重，以提供支持性的教学支架。', 'title_zh': 'Scratch Copilot: 以AI支持青少年创意编程'}
{'arxiv_id': 'arXiv:2505.03864', 'title': 'From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems', 'authors': 'Qiaomu Li, Ying Xie', 'link': 'https://arxiv.org/abs/2505.03864', 'abstract': 'Artificial intelligence is rapidly evolving towards multi-agent systems where numerous AI agents collaborate and interact with external tools. Two key open standards, Google\'s Agent to Agent (A2A) protocol for inter-agent communication and Anthropic\'s Model Context Protocol (MCP) for standardized tool access, promise to overcome the limitations of fragmented, custom integration approaches. While their potential synergy is significant, this paper argues that effectively integrating A2A and MCP presents unique, emergent challenges at their intersection, particularly concerning semantic interoperability between agent tasks and tool capabilities, the compounded security risks arising from combined discovery and execution, and the practical governance required for the envisioned "Agent Economy". This work provides a critical analysis, moving beyond a survey to evaluate the practical implications and inherent difficulties of combining these horizontal and vertical integration standards. We examine the benefits (e.g., specialization, scalability) while critically assessing their dependencies and trade-offs in an integrated context. We identify key challenges increased by the integration, including novel security vulnerabilities, privacy complexities, debugging difficulties across protocols, and the need for robust semantic negotiation mechanisms. In summary, A2A+MCP offers a vital architectural foundation, but fully realizing its potential requires substantial advancements to manage the complexities of their combined operation.', 'abstract_zh': '人工智能正快速向多-agent系统发展，其中众多AI代理协作并与外部工具交互。谷歌的代理到代理（A2A）协议和Anthropic的模型上下文协议（MCP）作为两个关键的开放标准，有望克服模块化、定制集成方法的局限性。虽然它们的协同潜力巨大，但本文认为，在A2A和MCP的交汇处有效集成这两项标准带来了独特且新兴的挑战，特别是代理任务和工具能力之间的语义互操作性问题、综合发现和执行带来的复合安全风险以及为设想中的“代理经济”所需的实践治理。本文提供了关键分析，超越了单纯的调研，评估组合这些横向和纵向集成标准的实践影响和固有困难。我们探讨了其益处（如专业化、可扩展性），同时批判性地评估这些标准在集成环境下的依赖性和权衡。我们指出了集成带来的关键挑战，包括新型安全漏洞、隐私复杂性、跨协议调试困难以及对稳健的语义谈判机制的需要。总之，A2A+MCP提供了重要的架构基础，但要充分发挥其潜力，还需要在管理其联合运营的复杂性方面取得显著进展。', 'title_zh': '从粘合代码到协议：面向可扩展代理系统的A2A和MCP集成关键分析'}
{'arxiv_id': 'arXiv:2505.03863', 'title': 'Data-Driven Falsification of Cyber-Physical Systems', 'authors': 'Atanu Kundu, Sauvik Gon, Rajarshi Ray', 'link': 'https://arxiv.org/abs/2505.03863', 'abstract': 'Cyber-Physical Systems (CPS) are abundant in safety-critical domains such as healthcare, avionics, and autonomous vehicles. Formal verification of their operational safety is, therefore, of utmost importance. In this paper, we address the falsification problem, where the focus is on searching for an unsafe execution in the system instead of proving their absence. The contribution of this paper is a framework that (a) connects the falsification of CPS with the falsification of deep neural networks (DNNs) and (b) leverages the inherent interpretability of Decision Trees for faster falsification of CPS. This is achieved by: (1) building a surrogate model of the CPS under test, either as a DNN model or a Decision Tree, (2) application of various DNN falsification tools to falsify CPS, and (3) a novel falsification algorithm guided by the explanations of safety violations of the CPS model extracted from its Decision Tree surrogate. The proposed framework has the potential to exploit a repertoire of \\emph{adversarial attack} algorithms designed to falsify robustness properties of DNNs, as well as state-of-the-art falsification algorithms for DNNs. Although the presented methodology is applicable to systems that can be executed/simulated in general, we demonstrate its effectiveness, particularly in CPS. We show that our framework, implemented as a tool \\textsc{FlexiFal}, can detect hard-to-find counterexamples in CPS that have linear and non-linear dynamics. Decision tree-guided falsification shows promising results in efficiently finding multiple counterexamples in the ARCH-COMP 2024 falsification benchmarks~\\cite{khandait2024arch}.', 'abstract_zh': '基于物理系统的网络安全物理系统(CPS)在医疗、航空和自动驾驶等安全关键领域中广泛应用。确保其操作安全性因此变得尤为重要。本文针对反证问题进行探讨，重点在于寻找系统的不安全执行，而非证明其不存在。本文的贡献在于提出了一种框架，该框架将CPS的反证与其深度神经网络(DNNs)的反证关联起来，并利用决策树的内在可解释性加速CPS的反证过程。这一目标通过以下方式实现：(1) 构建待测CPS的代理模型，该模型可以是DNN模型或决策树；(2) 应用多种DNN反证工具对CPS进行反证；(3) 通过从CPS模型的决策树代理中提取的安全违规解释指导的一种新型反证算法。所提出的框架有望利用专门设计用于反证DNNs的鲁棒性性质的对抗攻击算法，以及最先进的DNN反证算法。尽管所展示的方法适用于一般可执行/模拟的系统，但我们特别展示了其在CPS中的有效性。我们证明，作为工具\\textsc{FlexiFal}实现的该框架能够检测具有线性和非线性动力学的CPS中的难找反例。基于决策树的反证在ARCH-COMP 2024反证基准测试中显示出高效发现多个反例的前景。', 'title_zh': '数据驱动的网络物理系统反驳方法'}
{'arxiv_id': 'arXiv:2505.03859', 'title': 'Deepfakes on Demand: the rise of accessible non-consensual deepfake image generators', 'authors': 'Will Hawkins, Chris Russell, Brent Mittelstadt', 'link': 'https://arxiv.org/abs/2505.03859', 'abstract': 'Advances in multimodal machine learning have made text-to-image (T2I) models increasingly accessible and popular. However, T2I models introduce risks such as the generation of non-consensual depictions of identifiable individuals, otherwise known as deepfakes. This paper presents an empirical study exploring the accessibility of deepfake model variants online. Through a metadata analysis of thousands of publicly downloadable model variants on two popular repositories, Hugging Face and Civitai, we demonstrate a huge rise in easily accessible deepfake models. Almost 35,000 examples of publicly downloadable deepfake model variants are identified, primarily hosted on Civitai. These deepfake models have been downloaded almost 15 million times since November 2022, with the models targeting a range of individuals from global celebrities to Instagram users with under 10,000 followers. Both Stable Diffusion and Flux models are used for the creation of deepfake models, with 96% of these targeting women and many signalling intent to generate non-consensual intimate imagery (NCII). Deepfake model variants are often created via the parameter-efficient fine-tuning technique known as low rank adaptation (LoRA), requiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this process widely accessible via consumer-grade computers. Despite these models violating the Terms of Service of hosting platforms, and regulation seeking to prevent dissemination, these results emphasise the pressing need for greater action to be taken against the creation of deepfakes and NCII.', 'abstract_zh': '多模态机器学习的进步使得文本到图像（T2I）模型越来越普及和易于获取，但同时也带来了如非同意生成可识别个体的深度假图像等风险。本文通过分析两个流行仓库Hugging Face和Civitai上数千个可公开下载的深度假图像模型变体的元数据，探索了深度假图像模型变体的可获取性。研究结果显示，大量易于获取的深度假图像模型变体在网络上广泛存在。超过35,000个可公开下载的深度假图像模型变体主要托管在Civitai上。自2022年11月以来，这些模型几乎被下载了1500多万次，目标个体范围从全球名人到拥有不到10,000名粉丝的Instagram用户。用于创建深度假图像模型的Stable Diffusion和Flux模型中，有96%的目标为女性，且许多模型表明意图生成非同意的亲密图像。深度假图像模型变体通常通过低秩适应（LoRA）参数高效微调技术创建，只需20张图片、24GB VRAM和15分钟的时间，使其通过消费级计算机即可广泛获取。尽管这些模型违反了托管平台的服务条款，并存在监管措施以防止传播，但研究结果强调了采取更大力度行动以应对深度假图像和非同意的亲密图像的迫切需求。', 'title_zh': '按需生成虚假影像：可访问的非同意Deepfake图像生成器'}
{'arxiv_id': 'arXiv:2505.03853', 'title': 'GRAPE: Heterogeneous Graph Representation Learning for Genetic Perturbation with Coding and Non-Coding Biotype', 'authors': 'Changxi Chi, Jun Xia, Jingbo Zhou, Jiabei Cheng, Chang Yu, Stan Z. Li', 'link': 'https://arxiv.org/abs/2505.03853', 'abstract': 'Predicting genetic perturbations enables the identification of potentially crucial genes prior to wet-lab experiments, significantly improving overall experimental efficiency. Since genes are the foundation of cellular life, building gene regulatory networks (GRN) is essential to understand and predict the effects of genetic perturbations. However, current methods fail to fully leverage gene-related information, and solely rely on simple evaluation metrics to construct coarse-grained GRN. More importantly, they ignore functional differences between biotypes, limiting the ability to capture potential gene interactions. In this work, we leverage pre-trained large language model and DNA sequence model to extract features from gene descriptions and DNA sequence data, respectively, which serve as the initialization for gene representations. Additionally, we introduce gene biotype information for the first time in genetic perturbation, simulating the distinct roles of genes with different biotypes in regulating cellular processes, while capturing implicit gene relationships through graph structure learning (GSL). We propose GRAPE, a heterogeneous graph neural network (HGNN) that leverages gene representations initialized with features from descriptions and sequences, models the distinct roles of genes with different biotypes, and dynamically refines the GRN through GSL. The results on publicly available datasets show that our method achieves state-of-the-art performance.', 'abstract_zh': '基于大型语言模型和DNA序列模型的基因表示学习与基因调控网络构建以预测基因扰动并捕获潜在基因交互作用', 'title_zh': 'GRAPE: 异构图表示学习在编码和非编码生物类型遗传 Perturbation 中的应用'}
{'arxiv_id': 'arXiv:2505.03850', 'title': 'Impact Analysis of Inference Time Attack of Perception Sensors on Autonomous Vehicles', 'authors': 'Hanlin Chen, Simin Chen, Wenyu Li, Wei Yang, Yiheng Feng', 'link': 'https://arxiv.org/abs/2505.03850', 'abstract': 'As a safety-critical cyber-physical system, cybersecurity and related safety issues for Autonomous Vehicles (AVs) have been important research topics for a while. Among all the modules on AVs, perception is one of the most accessible attack surfaces, as drivers and AVs have no control over the outside environment. Most current work targeting perception security for AVs focuses on perception correctness. In this work, we propose an impact analysis based on inference time attacks for autonomous vehicles. We demonstrate in a simulation system that such inference time attacks can also threaten the safety of both the ego vehicle and other traffic participants.', 'abstract_zh': '作为安全关键的计算物理系统，自动驾驶车辆（AVs）的网络安全及相关安全问题一直是重要的研究课题。在所有AV模块中，感知是最易遭受攻击的模块之一，因为驾驶者和AV无法控制外部环境。目前大多数针对AV感知安全的研究集中在感知准确性上。在本工作中，我们提出了基于推理时间攻击的影响分析方法。我们通过仿真系统展示，这样的推理时间攻击也会影响AV自身和其它交通参与者的安全。', 'title_zh': '感知传感器推理时间攻击的影响分析对自动驾驶车辆的影响分析'}
{'arxiv_id': 'arXiv:2505.03848', 'title': 'Advanced Clustering Framework for Semiconductor Image Analytics Integrating Deep TDA with Self-Supervised and Transfer Learning Techniques', 'authors': 'Janhavi Giri, Attila Lengyel, Don Kent, Edward Kibardin', 'link': 'https://arxiv.org/abs/2505.03848', 'abstract': "Semiconductor manufacturing generates vast amounts of image data, crucial for defect identification and yield optimization, yet often exceeds manual inspection capabilities. Traditional clustering techniques struggle with high-dimensional, unlabeled data, limiting their effectiveness in capturing nuanced patterns. This paper introduces an advanced clustering framework that integrates deep Topological Data Analysis (TDA) with self-supervised and transfer learning techniques, offering a novel approach to unsupervised image clustering. TDA captures intrinsic topological features, while self-supervised learning extracts meaningful representations from unlabeled data, reducing reliance on labeled datasets. Transfer learning enhances the framework's adaptability and scalability, allowing fine-tuning to new datasets without retraining from scratch. Validated on synthetic and open-source semiconductor image datasets, the framework successfully identifies clusters aligned with defect patterns and process variations. This study highlights the transformative potential of combining TDA, self-supervised learning, and transfer learning, providing a scalable solution for proactive process monitoring and quality control in semiconductor manufacturing and other domains with large-scale image datasets.", 'abstract_zh': '一种将深度拓扑数据分析、自监督学习和迁移学习相结合的高级聚类框架：在半导体制造中的应用', 'title_zh': '基于深度拓扑数据分析的自监督与迁移学习集成的半导体图像分析高级聚类框架'}
{'arxiv_id': 'arXiv:2505.03840', 'title': 'CoCoB: Adaptive Collaborative Combinatorial Bandits for Online Recommendation', 'authors': 'Cairong Yan, Jinyi Han, Jin Ju, Yanting Zhang, Zijian Wang, Xuan Shao', 'link': 'https://arxiv.org/abs/2505.03840', 'abstract': "Clustering bandits have gained significant attention in recommender systems by leveraging collaborative information from neighboring users to better capture target user preferences. However, these methods often lack a clear definition of similar users and face challenges when users with unique preferences lack appropriate neighbors. In such cases, relying on divergent preferences of misidentified neighbors can degrade recommendation quality. To address these limitations, this paper proposes an adaptive Collaborative Combinatorial Bandits algorithm (CoCoB). CoCoB employs an innovative two-sided bandit architecture, applying bandit principles to both the user and item sides. The user-bandit employs an enhanced Bayesian model to explore user similarity, identifying neighbors based on a similarity probability threshold. The item-bandit treats items as arms, generating diverse recommendations informed by the user-bandit's output. CoCoB dynamically adapts, leveraging neighbor preferences when available or focusing solely on the target user otherwise. Regret analysis under a linear contextual bandit setting and experiments on three real-world datasets demonstrate CoCoB's effectiveness, achieving an average 2.4% improvement in F1 score over state-of-the-art methods.", 'abstract_zh': '基于聚类的组合臂协同过滤算法在推荐系统中的应用：CoCoB算法的研究', 'title_zh': 'CoCoB: 自适应协作组合臂赛选算法的在线推荐'}
{'arxiv_id': 'arXiv:2505.03836', 'title': 'OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery', 'authors': 'Chongsheng Zhang, Shuwen Wu, Yingqi Chen, Matthias Aßenmacher, Christian Heumann, Yi Men, Gaojuan Fan, João Gama', 'link': 'https://arxiv.org/abs/2505.03836', 'abstract': 'Oracle Bone Inscription (OBI) is the earliest systematic writing system in China, while the identification of Oracle Bone (OB) duplicates is a fundamental issue in OBI research. In this work, we design a progressive OB duplicate discovery framework that combines unsupervised low-level keypoints matching with high-level text-centric content-based matching to refine and rank the candidate OB duplicates with semantic awareness and interpretability. We compare our approach with state-of-the-art content-based image retrieval and image matching methods, showing that our approach yields comparable recall performance and the highest simplified mean reciprocal rank scores for both Top-5 and Top-15 retrieval results, and with significantly accelerated computation efficiency. We have discovered over 60 pairs of new OB duplicates in real-world deployment, which were missed by OBI researchers for decades. The models, video illustration and demonstration of this work are available at: this https URL.', 'abstract_zh': '殷墟甲骨文（OBI）是最早的 systematic 记写系统，而甲骨文（OB）复制件的识别是 OBI 研究中的基本问题。本文设计了一个渐进的 OB 复制品发现框架，结合了无监督的低层级关键点匹配和高层级文本中心的内容匹配，以语义意识和可解释性来细化和排名候选 OB 复制品。我们将我们的方法与最先进的基于内容的图像检索和图像匹配方法进行比较，结果显示，我们的方法在 Top-5 和 Top-15 检索结果中达到了可比拟的召回率性能，并且具有显著加速的计算效率。我们已经在实际部署中发现了超过 60 组新的 OB 复制品，这些复制品被 OBI 研究者漏过了数十年之久。本文的模型、视频演示和示例可访问此链接: this https URL。', 'title_zh': 'OBD-Finder: 可解释的从粗到细基于文字的甲骨文重复发现'}
{'arxiv_id': 'arXiv:2505.03835', 'title': 'The Shift Towards Preprints in AI Policy Research: A Comparative Study of Preprint Trends in the U.S., Europe, and South Korea', 'authors': 'Simon Suh, Jihyuk Bang, Ji Woo Han', 'link': 'https://arxiv.org/abs/2505.03835', 'abstract': 'The adoption of open science has quickly changed how artificial intelligence (AI) policy research is distributed globally. This study examines the regional trends in the citation of preprints, specifically focusing on the impact of two major disruptive events: the COVID-19 pandemic and the release of ChatGPT, on research dissemination patterns in the United States, Europe, and South Korea from 2015 to 2024. Using bibliometrics data from the Web of Science, this study tracks how global disruptive events influenced the adoption of preprints in AI policy research and how such shifts vary by region. By marking the timing of these disruptive events, the analysis reveals that while all regions experienced growth in preprint citations, the magnitude and trajectory of change varied significantly. The United States exhibited sharp, event-driven increases; Europe demonstrated institutional growth; and South Korea maintained consistent, linear growth in preprint adoption. These findings suggest that global disruptions may have accelerated preprint adoption, but the extent and trajectory are shaped by local research cultures, policy environments, and levels of open science maturity. This paper emphasizes the need for future AI governance strategies to consider regional variability in research dissemination and highlights opportunities for further longitudinal and comparative research to deepen our understanding of open-access adoption in AI policy development.', 'abstract_zh': '开放科学的采纳迅速改变了人工智能政策研究的全球分布方式。本文研究了预印本引用的区域趋势，特别是 COVID-19 疫情和 ChatGPT 的发布这两大破坏性事件对 2015 年至 2024 年期间美国、欧洲和韩国人工智能政策研究传播模式的影响。利用 Web of Science 的引文数据，本文追踪全球破坏性事件如何影响人工智能政策研究中预印本的采纳，并分析这些变化在不同地区的差异性。通过标注这些破坏性事件的时间点，分析揭示，尽管各地区都经历了预印本引用数量的增长，但增长的幅度和轨迹存在显著差异。美国表现出事件驱动的大幅增长；欧洲则表现出机构增长；而韩国则保持着平稳、线性的预印本采纳增长。这些发现表明，全球性中断可能加速了预印本的采纳，但其程度和轨迹由当地的研究文化、政策环境和开放科学成熟度所塑造。本文强调了未来人工智能治理策略需要考虑研究传播的区域差异，并指出了进一步纵向和比较研究以深化对人工智能政策发展中的开放访问采纳理解的机会。', 'title_zh': 'AI政策研究中预印本的转变：美国、欧洲和韩国预印本趋势的比较研究'}
{'arxiv_id': 'arXiv:2505.03833', 'title': "PointExplainer: Towards Transparent Parkinson's Disease Diagnosis", 'authors': 'Xuechao Wang, Sven Nomm, Junqing Huang, Kadri Medijainen, Aaro Toomela, Michael Ruzhansky', 'link': 'https://arxiv.org/abs/2505.03833', 'abstract': "Deep neural networks have shown potential in analyzing digitized hand-drawn signals for early diagnosis of Parkinson's disease. However, the lack of clear interpretability in existing diagnostic methods presents a challenge to clinical trust. In this paper, we propose PointExplainer, an explainable diagnostic strategy to identify hand-drawn regions that drive model diagnosis. Specifically, PointExplainer assigns discrete attribution values to hand-drawn segments, explicitly quantifying their relative contributions to the model's decision. Its key components include: (i) a diagnosis module, which encodes hand-drawn signals into 3D point clouds to represent hand-drawn trajectories, and (ii) an explanation module, which trains an interpretable surrogate model to approximate the local behavior of the black-box diagnostic model. We also introduce consistency measures to further address the issue of faithfulness in explanations. Extensive experiments on two benchmark datasets and a newly constructed dataset show that PointExplainer can provide intuitive explanations with no diagnostic performance degradation. The source code is available at this https URL.", 'abstract_zh': '深神经网络在分析数字化手绘信号以实现帕金森病早期诊断方面显示出潜力。然而，现有诊断方法缺乏清晰的可解释性，这对临床信任构成挑战。本文提出了一种可解释的诊断策略PointExplainer，以识别驱动模型诊断的手绘区域。具体而言，PointExplainer为手绘段分配离散的归因值，明确量化其对模型决策的相对贡献。其主要组件包括：(i) 诊断模块，将手绘信号编码为3D点云以表示手绘轨迹，(ii) 解释模块，训练一个可解释的替代模型来逼近黑盒诊断模型的局部行为。我们还引入了一致性度量以进一步解决解释忠实性的问题。在两个基准数据集和一个新构建的数据集上进行的广泛实验表明，PointExplainer可以在不牺牲诊断性能的情况下提供直观的解释。源代码可在以下链接获得：this https URL。', 'title_zh': 'PointExplainer: 向往透明的帕金森病诊断'}
{'arxiv_id': 'arXiv:2505.03832', 'title': 'Video Forgery Detection for Surveillance Cameras: A Review', 'authors': 'Noor B. Tayfor, Tarik A. Rashid, Shko M. Qader, Bryar A. Hassan, Mohammed H. Abdalla, Jafar Majidpour, Aram M. Ahmed, Hussein M. Ali, Aso M. Aladdin, Abdulhady A. Abdullah, Ahmed S. Shamsaldin, Haval M. Sidqi, Abdulrahman Salih, Zaher M. Yaseen, Azad A. Ameen, Janmenjoy Nayak, Mahmood Yashar Hamza', 'link': 'https://arxiv.org/abs/2505.03832', 'abstract': 'The widespread availability of video recording through smartphones and digital devices has made video-based evidence more accessible than ever. Surveillance footage plays a crucial role in security, law enforcement, and judicial processes. However, with the rise of advanced video editing tools, tampering with digital recordings has become increasingly easy, raising concerns about their authenticity. Ensuring the integrity of surveillance videos is essential, as manipulated footage can lead to misinformation and undermine judicial decisions. This paper provides a comprehensive review of existing forensic techniques used to detect video forgery, focusing on their effectiveness in verifying the authenticity of surveillance recordings. Various methods, including compression-based analysis, frame duplication detection, and machine learning-based approaches, are explored. The findings highlight the growing necessity for more robust forensic techniques to counteract evolving forgery methods. Strengthening video forensic capabilities will ensure that surveillance recordings remain credible and admissible as legal evidence.', 'abstract_zh': '通过智能手机和数字化设备的广泛视频录制功能，基于视频的证据比以往任何时候都更加容易获取。监视视频在安全、执法和司法程序中发挥着重要作用。然而，随着高级视频编辑工具的兴起，篡改数字记录变得越来越容易，这引发了对其真实性的担忧。确保监视视频的完整性至关重要，因为篡改的视频可能导致误导信息并削弱司法裁决。本文对现有的用于检测视频伪造的法医技术进行了全面回顾，重点关注这些技术在验证监视记录的真实性方面的有效性。文中探讨了包括基于压缩的分析、帧复制检测以及基于机器学习的方法等各种方法。研究结果强调了开发更 robust 法医技术以应对不断演变的伪造方法的必要性。增强视频法医能力将确保监视记录继续具有可信度并可作为法律证据使用。', 'title_zh': '监控摄像头中视频伪造检测：一个综述'}
{'arxiv_id': 'arXiv:2505.03828', 'title': 'Sentiment-Aware Recommendation Systems in E-Commerce: A Review from a Natural Language Processing Perspective', 'authors': 'Yogesh Gajula', 'link': 'https://arxiv.org/abs/2505.03828', 'abstract': 'E-commerce platforms generate vast volumes of user feedback, such as star ratings, written reviews, and comments. However, most recommendation engines rely primarily on numerical scores, often overlooking the nuanced opinions embedded in free text. This paper comprehensively reviews sentiment-aware recommendation systems from a natural language processing perspective, covering advancements from 2023 to early 2025. It highlights the benefits of integrating sentiment analysis into e-commerce recommenders to enhance prediction accuracy and explainability through detailed opinion extraction. Our survey categorizes recent work into four main approaches: deep learning classifiers that combine sentiment embeddings with user item interactions, transformer based methods for nuanced feature extraction, graph neural networks that propagate sentiment signals, and conversational recommenders that adapt in real time to user feedback. We summarize model architectures and demonstrate how sentiment flows through recommendation pipelines, impacting dialogue-based suggestions. Key challenges include handling noisy or sarcastic text, dynamic user preferences, and bias mitigation. Finally, we outline research gaps and provide a roadmap for developing smarter, fairer, and more user-centric recommendation tools.', 'abstract_zh': '电子商务平台生成了大量的用户反馈，包括星级评价、书面评论和评论。然而，大多数推荐引擎主要依赖数值评分，往往忽视了嵌入在自由文本中的细腻意见。本文从自然语言处理的角度全面回顾了自2023年初至2025年初的情感感知推荐系统的发展，强调将情感分析整合到电子商务推荐系统中以提高预测准确性和可解释性，通过详细的情感意见提取实现。我们总结了最近的工作分为四种主要方法：结合情感嵌入和用户项目交互的深度学习分类器、基于变换器的方法以提取细腻特征、传播情感信号的图神经网络以及适应用户反馈的对话推荐器。我们概述了模型架构，并展示了情感如何在推荐管道中流动，影响基于对话的建议。主要挑战包括处理嘈杂或讽刺文本、动态用户偏好以及偏见缓解。最后，我们概述了研究空白，并提供了开发更智能、公平和以用户为中心的推荐工具的道路图。', 'title_zh': '电商领域具有情感意识的推荐系统：自然语言处理视角的综述'}
{'arxiv_id': 'arXiv:2505.03827', 'title': 'MISE: Meta-knowledge Inheritance for Social Media-Based Stressor Estimation', 'authors': 'Xin Wang, Ling Feng, Huijun Zhang, Lei Cao, Kaisheng Zeng, Qi Li, Yang Ding, Yi Dai, David Clifton', 'link': 'https://arxiv.org/abs/2505.03827', 'abstract': "Stress haunts people in modern society, which may cause severe health issues if left unattended. With social media becoming an integral part of daily life, leveraging social media to detect stress has gained increasing attention. While the majority of the work focuses on classifying stress states and stress categories, this study introduce a new task aimed at estimating more specific stressors (like exam, writing paper, etc.) through users' posts on social media. Unfortunately, the diversity of stressors with many different classes but a few examples per class, combined with the consistent arising of new stressors over time, hinders the machine understanding of stressors. To this end, we cast the stressor estimation problem within a practical scenario few-shot learning setting, and propose a novel meta-learning based stressor estimation framework that is enhanced by a meta-knowledge inheritance mechanism. This model can not only learn generic stressor context through meta-learning, but also has a good generalization ability to estimate new stressors with little labeled data. A fundamental breakthrough in our approach lies in the inclusion of the meta-knowledge inheritance mechanism, which equips our model with the ability to prevent catastrophic forgetting when adapting to new stressors. The experimental results show that our model achieves state-of-the-art performance compared with the baselines. Additionally, we construct a social media-based stressor estimation dataset that can help train artificial intelligence models to facilitate human well-being. The dataset is now public at \\href{this https URL}{\\underline{Kaggle}} and \\href{this https URL}{\\underline{Hugging Face}}.", 'abstract_zh': '社会媒体中特定压力源的少样本学习估算：一种元学习框架', 'title_zh': 'MISE：基于元知识继承的社交媒体压力源估计算法'}
{'arxiv_id': 'arXiv:2505.03826', 'title': 'In-situ and Non-contact Etch Depth Prediction in Plasma Etching via Machine Learning (ANN & BNN) and Digital Image Colorimetry', 'authors': 'Minji Kang, Seongho Kim, Eunseo Go, Donghyeon Paek, Geon Lim, Muyoung Kim, Soyeun Kim, Sung Kyu Jang, Min Sup Choi, Woo Seok Kang, Jaehyun Kim, Jaekwang Kim, Hyeong-U Kim', 'link': 'https://arxiv.org/abs/2505.03826', 'abstract': "Precise monitoring of etch depth and the thickness of insulating materials, such as Silicon dioxide and silicon nitride, is critical to ensuring device performance and yield in semiconductor manufacturing. While conventional ex-situ analysis methods are accurate, they are constrained by time delays and contamination risks. To address these limitations, this study proposes a non-contact, in-situ etch depth prediction framework based on machine learning (ML) techniques. Two scenarios are explored. In the first scenario, an artificial neural network (ANN) is trained to predict average etch depth from process parameters, achieving a significantly lower mean squared error (MSE) compared to a linear baseline model. The approach is then extended to incorporate variability from repeated measurements using a Bayesian Neural Network (BNN) to capture both aleatoric and epistemic uncertainty. Coverage analysis confirms the BNN's capability to provide reliable uncertainty estimates. In the second scenario, we demonstrate the feasibility of using RGB data from digital image colorimetry (DIC) as input for etch depth prediction, achieving strong performance even in the absence of explicit process parameters. These results suggest that the integration of DIC and ML offers a viable, cost-effective alternative for real-time, in-situ, and non-invasive monitoring in plasma etching processes, contributing to enhanced process stability, and manufacturing efficiency.", 'abstract_zh': '精确监测硅氧化物和硅氮化物等绝缘材料的蚀刻深度对于确保半导体制造中的器件性能和产量至关重要。尽管传统的离线分析方法准确，但它们受到时间延迟和污染风险的限制。为了解决这些限制，本研究提出了一种基于机器学习技术的非接触式原位蚀刻深度预测框架。两种场景被探索。在第一种场景中，人工神经网络（ANN）被训练从工艺参数中预测平均蚀刻深度，其均方误差（MSE）显著低于线性基线模型。随后的方法扩展了重复测量的变异性，使用贝叶斯神经网络（BNN）捕捉Aleatoric和Epistemic不确定性。覆盖分析证实了BNN提供可靠不确定性估计的能力。在第二种场景中，我们展示了使用数字图像颜色度量（DIC）的RGB数据作为蚀刻深度预测输入的可能性，即使没有显式的工艺参数也取得了优异的性能。这些结果表明，将DIC与机器学习集成提供了一种可行且成本效益高的替代方法，用于等离子蚀刻过程中的实时、原位和非侵入性监测，有助于增强工艺稳定性和制造效率。', 'title_zh': '基于机器学习（ANN & BNN）和数字图像颜色测量的等离子体刻蚀原位无接触刻蚀深度预测'}
{'arxiv_id': 'arXiv:2505.03825', 'title': 'Intelligently Augmented Contrastive Tensor Factorization: Empowering Multi-dimensional Time Series Classification in Low-Data Environments', 'authors': 'Anushiya Arunan, Yan Qin, Xiaoli Li, Yuen Chau', 'link': 'https://arxiv.org/abs/2505.03825', 'abstract': 'Classification of multi-dimensional time series from real-world systems require fine-grained learning of complex features such as cross-dimensional dependencies and intra-class variations-all under the practical challenge of low training data availability. However, standard deep learning (DL) struggles to learn generalizable features in low-data environments due to model overfitting. We propose a versatile yet data-efficient framework, Intelligently Augmented Contrastive Tensor Factorization (ITA-CTF), to learn effective representations from multi-dimensional time series. The CTF module learns core explanatory components of the time series (e.g., sensor factors, temporal factors), and importantly, their joint dependencies. Notably, unlike standard tensor factorization (TF), the CTF module incorporates a new contrastive loss optimization to induce similarity learning and class-awareness into the learnt representations for better classification performance. To strengthen this contrastive learning, the preceding ITA module generates targeted but informative augmentations that highlight realistic intra-class patterns in the original data, while preserving class-wise properties. This is achieved by dynamically sampling a "soft" class prototype to guide the warping of each query data sample, which results in an augmentation that is intelligently pattern-mixed between the "soft" class prototype and the query sample. These augmentations enable the CTF module to recognize complex intra-class variations despite the limited original training data, and seek out invariant class-wise properties for accurate classification performance. The proposed method is comprehensively evaluated on five different classification tasks. Compared to standard TF and several DL benchmarks, notable performance improvements up to 18.7% were achieved.', 'abstract_zh': '面向实际系统的多维时间序列分类需要在训练数据有限的情况下细粒度学习复杂的特征，如跨维度依赖关系和类内变异性。然而，标准深度学习在低数据环境中由于模型过拟合难以学习可泛化的特征。我们提出了一种既灵活又高效的方法——智能增强对比张量分解（ITA-CTF），用于从多维时间序列中学习有效的表示。CTF模块学习时间序列的核心解释组件（如传感器因子、时域因子），以及它们的联合依赖关系。值得注意的是，与标准张量分解不同，CTF模块引入了一种新的对比损失优化，以在学习的表示中诱导相似性学习和类意识，从而提高分类性能。为了增强这种对比学习，先前的ITA模块生成了有针对性但信息丰富的增强，突出显示了原始数据中的现实类内模式，同时保留类属性。这通过动态采样一个“软”类原型来引导每个查询数据样本的形变来实现，从而产生一种在“软”类原型和查询样本之间智能模式混合的增强。这些增强使得CTF模块即使在有限的原始训练数据下也能识别复杂的类内变异性，并寻求不变的类属性以获得准确的分类性能。该方法在五个不同的分类任务上进行了全面评估，与标准张量分解和几种深度学习基准方法相比，实现了高达18.7%的性能提升。', 'title_zh': '智能增强对比张量因子分解：在数据稀少环境中提升多维时间序列分类'}
{'arxiv_id': 'arXiv:2505.03822', 'title': 'DRSLF: Double Regularized Second-Order Low-Rank Representation for Web Service QoS Prediction', 'authors': 'Hao Wu, Jialiang Wang', 'link': 'https://arxiv.org/abs/2505.03822', 'abstract': 'Quality-of-Service (QoS) data plays a crucial role in cloud service selection. Since users cannot access all services, QoS can be represented by a high-dimensional and incomplete (HDI) matrix. Latent factor analysis (LFA) models have been proven effective as low-rank representation techniques for addressing this issue. However, most LFA models rely on first-order optimizers and use L2-norm regularization, which can lead to lower QoS prediction accuracy. To address this issue, this paper proposes a double regularized second-order latent factor (DRSLF) model with two key ideas: a) integrating L1-norm and L2-norm regularization terms to enhance the low-rank representation performance; b) incorporating second-order information by calculating the Hessian-vector product in each conjugate gradient step. Experimental results on two real-world response-time QoS datasets demonstrate that DRSLF has a higher low-rank representation capability than two baselines.', 'abstract_zh': '服务质量（QoS）数据在云服务选择中起着至关重要的作用。由于用户无法访问所有服务，QoS可以表示为高维不完全（HDI）矩阵。潜在因子分析（LFA）模型已被证明是低秩表示的有效技术，用于解决这个问题。然而，大多数LFA模型依赖于一阶优化器，并使用L2范数正则化，这可能导致较低的QoS预测准确性。为了解决这一问题，本文提出了一种双正则化二次潜在因子（DRSLF）模型，该模型包含两个关键思想：a) 结合L1范数和L2范数正则化项以提高低秩表示性能；b) 通过在每个共轭梯度步骤中计算海森berg向量乘积来引入二次信息。在两个实际响应时间QoS数据集上的实验结果显示，DRSLF在低秩表示能力上优于两个基线模型。', 'title_zh': 'DRSLF：双正则化二阶低秩表示的Web服务QoS预测'}
{'arxiv_id': 'arXiv:2505.03819', 'title': 'Focus on the Likely: Test-time Instance-based Uncertainty Removal', 'authors': 'Johannes Schneider', 'link': 'https://arxiv.org/abs/2505.03819', 'abstract': 'We propose two novel test-time fine-tuning methods to improve uncertain model predictions. Our methods require no auxiliary data and use the given test instance only. Instead of performing a greedy selection of the most likely class to make a prediction, we introduce an additional focus on the likely classes step during inference. By applying a single-step gradient descent, we refine predictions when an initial forward pass indicates high uncertainty. This aligns predictions more closely with the ideal of assigning zero probability to less plausible outcomes. Our theoretical discussion provides a deeper understanding highlighting the impact on shared and non-shared features among (focus) classes. The experimental evaluation highlights accuracy gains on samples exhibiting high decision uncertainty for a diverse set of models from both the text and image domain using the same hyperparameters.', 'abstract_zh': '我们提出两种新的测试时微调方法以提高不确定模型的预测质量。这两种方法不需要辅助数据，仅使用给定的测试实例。我们引入了在推理过程中关注可能类别的额外步骤，而不是进行贪婪选择最可能的类别来做出预测。通过应用单步梯度下降，我们在初始前向传播指示高不确定性时 refining 预测。这使预测更接近于将较少可能的结果分配零概率的理想状态。我们的理论讨论深化了对（关注）类别之间共享和非共享特征影响的理解。实验证明，在采用相同超参数的情况下，这些方法在文本和图像领域的一系列模型中对表现出高决策不确定性的样本展示了准确性的提升。', 'title_zh': '关注可能的：测试时基于实例的不确定性去除'}
{'arxiv_id': 'arXiv:2505.03817', 'title': 'Modeling Behavioral Preferences of Cyber Adversaries Using Inverse Reinforcement Learning', 'authors': 'Aditya Shinde, Prashant Doshi', 'link': 'https://arxiv.org/abs/2505.03817', 'abstract': "This paper presents a holistic approach to attacker preference modeling from system-level audit logs using inverse reinforcement learning (IRL). Adversary modeling is an important capability in cybersecurity that lets defenders characterize behaviors of potential attackers, which enables attribution to known cyber adversary groups. Existing approaches rely on documenting an ever-evolving set of attacker tools and techniques to track known threat actors. Although attacks evolve constantly, attacker behavioral preferences are intrinsic and less volatile. Our approach learns the behavioral preferences of cyber adversaries from forensics data on their tools and techniques. We model the attacker as an expert decision-making agent with unknown behavioral preferences situated in a computer host. We leverage attack provenance graphs of audit logs to derive a state-action trajectory of the attack. We test our approach on open datasets of audit logs containing real attack data. Our results demonstrate for the first time that low-level forensics data can automatically reveal an adversary's subjective preferences, which serves as an additional dimension to modeling and documenting cyber adversaries. Attackers' preferences tend to be invariant despite their different tools and indicate predispositions that are inherent to the attacker. As such, these inferred preferences can potentially serve as unique behavioral signatures of attackers and improve threat attribution.", 'abstract_zh': '基于系统审计日志的反向强化学习的攻击者偏好建模整体方法', 'title_zh': '使用逆强化学习建模网络对手的行为偏好'}
{'arxiv_id': 'arXiv:2505.03816', 'title': 'Geospatial and Temporal Trends in Urban Transportation: A Study of NYC Taxis and Pathao Food Deliveries', 'authors': 'Bidyarthi Paul, Fariha Tasnim Chowdhury, Dipta Biswas, Meherin Sultana', 'link': 'https://arxiv.org/abs/2505.03816', 'abstract': 'Urban transportation plays a vital role in modern city life, affecting how efficiently people and goods move around. This study analyzes transportation patterns using two datasets: the NYC Taxi Trip dataset from New York City and the Pathao Food Trip dataset from Dhaka, Bangladesh. Our goal is to identify key trends in demand, peak times, and important geographical hotspots. We start with Exploratory Data Analysis (EDA) to understand the basic characteristics of the datasets. Next, we perform geospatial analysis to map out high-demand and low-demand regions. We use the SARIMAX model for time series analysis to forecast demand patterns, capturing seasonal and weekly variations. Lastly, we apply clustering techniques to identify significant areas of high and low demand. Our findings provide valuable insights for optimizing fleet management and resource allocation in both passenger transport and food delivery services. These insights can help improve service efficiency, better meet customer needs, and enhance urban transportation systems in diverse urban environments.', 'abstract_zh': '城市交通在现代城市生活中发挥着至关重要的作用，影响着人们和货物的移动效率。本研究使用两个数据集对交通模式进行分析：纽约市的NYC Taxi Trip数据集和达卡的Pathao Food Trip数据集。我们的目标是识别需求的关键趋势、高峰时段以及重要的地理热点。我们首先进行探索性数据分析(EDA)以了解数据集的基本特征。接着，我们进行空间地理分析以绘制高需求和低需求区域的分布。我们使用SARIMAX模型进行时间序列分析以预测需求模式，捕捉季节性和周日变化。最后，我们应用聚类技术以识别高需求和低需求的显著区域。我们的发现为优化客运和服务资源分配提供了有价值的信息，有助于提高服务效率，更好地满足客户需求，并强化多样城市环境中的城市交通系统。', 'title_zh': '城市交通的地理空间和时间趋势：基于纽约出租车和Pathao食品配送的研究'}
{'arxiv_id': 'arXiv:2505.03811', 'title': 'ScarceGAN: Discriminative Classification Framework for Rare Class Identification for Longitudinal Data with Weak Prior', 'authors': 'Surajit Chakrabarty, Rukma Talwadker, Tridib Mukherjee', 'link': 'https://arxiv.org/abs/2505.03811', 'abstract': "This paper introduces ScarceGAN which focuses on identification of extremely rare or scarce samples from multi-dimensional longitudinal telemetry data with small and weak label prior. We specifically address: (i) severe scarcity in positive class, stemming from both underlying organic skew in the data, as well as extremely limited labels; (ii) multi-class nature of the negative samples, with uneven density distributions and partially overlapping feature distributions; and (iii) massively unlabelled data leading to tiny and weak prior on both positive and negative classes, and possibility of unseen or unknown behavior in the unlabelled set, especially in the negative class. Although related to PU learning problems, we contend that knowledge (or lack of it) on the negative class can be leveraged to learn the compliment of it (i.e., the positive class) better in a semi-supervised manner. To this effect, ScarceGAN re-formulates semi-supervised GAN by accommodating weakly labelled multi-class negative samples and the available positive samples. It relaxes the supervised discriminator's constraint on exact differentiation between negative samples by introducing a 'leeway' term for samples with noisy prior. We propose modifications to the cost objectives of discriminator, in supervised and unsupervised path as well as that of the generator. For identifying risky players in skill gaming, this formulation in whole gives us a recall of over 85% (~60% jump over vanilla semi-supervised GAN) on our scarce class with very minimal verbosity in the unknown space. Further ScarceGAN outperforms the recall benchmarks established by recent GAN based specialized models for the positive imbalanced class identification and establishes a new benchmark in identifying one of rare attack classes (0.09%) in the intrusion dataset from the KDDCUP99 challenge.", 'abstract_zh': 'ScarceGAN：处理极端稀少样本的半监督生成对抗网络', 'title_zh': 'ScarceGAN：用于纵向数据中稀有类别识别的辨别性分类框架（基于弱先验）'}
{'arxiv_id': 'arXiv:2505.03809', 'title': 'When Dynamic Data Selection Meets Data Augmentation', 'authors': 'Suorong Yang, Peng Ye, Furao Shen, Dongzhan Zhou', 'link': 'https://arxiv.org/abs/2505.03809', 'abstract': "Dynamic data selection aims to accelerate training with lossless performance. However, reducing training data inherently limits data diversity, potentially hindering generalization. While data augmentation is widely used to enhance diversity, it is typically not optimized in conjunction with selection. As a result, directly combining these techniques fails to fully exploit their synergies. To tackle the challenge, we propose a novel online data training framework that, for the first time, unifies dynamic data selection and augmentation, achieving both training efficiency and enhanced performance. Our method estimates each sample's joint distribution of local density and multimodal semantic consistency, allowing for the targeted selection of augmentation-suitable samples while suppressing the inclusion of noisy or ambiguous data. This enables a more significant reduction in dataset size without sacrificing model generalization. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches on various benchmark datasets and architectures, e.g., reducing 50\\% training costs on ImageNet-1k with lossless performance. Furthermore, our approach enhances noise resistance and improves model robustness, reinforcing its practical utility in real-world scenarios.", 'abstract_zh': '动态数据选择旨在通过无损性能加速训练。然而，减少训练数据固有地限制了数据多样性，可能妨碍泛化能力。尽管数据增强广泛用于提高多样性，但通常未与选择优化结合使用。因此，直接将这两种技术结合起来未能充分利用它们的协同效应。为解决这一挑战，我们提出了一种新颖的在线数据训练框架，首次将动态数据选择和增强统一起来，实现训练效率和增强性能。我们的方法估计每个样本的局部密度和多模态语义一致性联合分布，从而可以目标选择适合增强的样本，同时抑制噪声或模糊数据的包含。这使得在不牺牲模型泛化能力的情况下显著减少数据集大小。实验结果表明，我们的方法在各种基准数据集和架构上优于现有最先进的方法，例如，在ImageNet-1k上将训练成本降低50%的同时保持无损性能。此外，我们的方法增强了对噪声的抵抗力和提高了模型的稳健性，强化了其实用性在实际场景中的应用。', 'title_zh': '当动态数据选择遇上了数据增强'}
{'arxiv_id': 'arXiv:2505.03806', 'title': 'Perception-Informed Neural Networks: Beyond Physics-Informed Neural Networks', 'authors': 'Mehran Mazandarani, Marzieh Najariyan', 'link': 'https://arxiv.org/abs/2505.03806', 'abstract': 'This article introduces Perception-Informed Neural Networks (PrINNs), a framework designed to incorporate perception-based information into neural networks, addressing both systems with known and unknown physics laws or differential equations. Moreover, PrINNs extend the concept of Physics-Informed Neural Networks (PINNs) and their variants, offering a platform for the integration of diverse forms of perception precisiation, including singular, probability distribution, possibility distribution, interval, and fuzzy graph. In fact, PrINNs allow neural networks to model dynamical systems by integrating expert knowledge and perception-based information through loss functions, enabling the creation of modern data-driven models. Some of the key contributions include Mixture of Experts Informed Neural Networks (MOEINNs), which combine heterogeneous expert knowledge into the network, and Transformed-Knowledge Informed Neural Networks (TKINNs), which facilitate the incorporation of meta-information for enhanced model performance. Additionally, Fuzzy-Informed Neural Networks (FINNs) as a modern class of fuzzy deep neural networks leverage fuzzy logic constraints within a deep learning architecture, allowing online training without pre-training and eliminating the need for defuzzification. PrINNs represent a significant step forward in bridging the gap between traditional physics-based modeling and modern data-driven approaches, enabling neural networks to learn from both structured physics laws and flexible perception-based rules. This approach empowers neural networks to operate in uncertain environments, model complex systems, and discover new forms of differential equations, making PrINNs a powerful tool for advancing computational science and engineering.', 'abstract_zh': '感知驱动的神经网络（PrINNs）：一种结合感知信息的框架', 'title_zh': '感知驱动的神经网络：超越物理驱动的神经网络'}
{'arxiv_id': 'arXiv:2505.03803', 'title': 'RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization', 'authors': 'Chen Xu, Yuxuan Yue, Zukang Xu, Xing Hu, Jiangyong Yu, Zhixuan Chen, Sifan Zhou, Zhihang Yuan, Dawei Yang', 'link': 'https://arxiv.org/abs/2505.03803', 'abstract': 'RWKV is a modern RNN architecture with comparable performance to Transformer, but still faces challenges when deployed to resource-constrained devices. Post Training Quantization (PTQ), which is a an essential technique to reduce model size and inference latency, has been widely used in Transformer models. However, it suffers significant degradation of performance when applied to RWKV. This paper investigates and identifies two key constraints inherent in the properties of RWKV: (1) Non-linear operators hinder the parameter-fusion of both smooth- and rotation-based quantization, introducing extra computation overhead. (2) The larger amount of uniformly distributed weights poses challenges for cluster-based quantization, leading to reduced accuracy. To this end, we propose RWKVQuant, a PTQ framework tailored for RWKV models, consisting of two novel techniques: (1) a coarse-to-fine proxy capable of adaptively selecting different quantization approaches by assessing the uniformity and identifying outliers in the weights, and (2) a codebook optimization algorithm that enhances the performance of cluster-based quantization methods for element-wise multiplication in RWKV. Experiments show that RWKVQuant can quantize RWKV-6-14B into about 3-bit with less than 1% accuracy loss and 2.14x speed up.', 'abstract_zh': 'RWKVQuant：一种针对RWKV模型的后训练量化框架', 'title_zh': 'RWKVQuant：基于代理引导混合标量和向量量化的方法量化RWKV家族模型'}
{'arxiv_id': 'arXiv:2505.03798', 'title': 'Position: Foundation Models Need Digital Twin Representations', 'authors': 'Yiqing Shen, Hao Ding, Lalithkumar Seenivasan, Tianmin Shu, Mathias Unberath', 'link': 'https://arxiv.org/abs/2505.03798', 'abstract': 'Current foundation models (FMs) rely on token representations that directly fragment continuous real-world multimodal data into discrete tokens. They limit FMs to learning real-world knowledge and relationships purely through statistical correlation rather than leveraging explicit domain knowledge. Consequently, current FMs struggle with maintaining semantic coherence across modalities, capturing fine-grained spatial-temporal dynamics, and performing causal reasoning. These limitations cannot be overcome by simply scaling up model size or expanding datasets. This position paper argues that the machine learning community should consider digital twin (DT) representations, which are outcome-driven digital representations that serve as building blocks for creating virtual replicas of physical processes, as an alternative to the token representation for building FMs. Finally, we discuss how DT representations can address these challenges by providing physically grounded representations that explicitly encode domain knowledge and preserve the continuous nature of real-world processes.', 'abstract_zh': '当前的基础模型依赖于标记表示，直接将连续的多模态现实世界数据分解为离散标记。它们限制基础模型仅通过统计相关性来学习现实世界的知识和关系，而非利用显性的领域知识。因此，当前的基础模型在维护跨模态的语义连贯性、捕捉精细的空间-时间动态以及执行因果推理方面存在困难。这些限制仅靠扩大模型规模或增加数据集无法克服。本文认为，机器学习社区应考虑以结果驱动的数字孪生（DT）表示作为构建基础模型的替代方案，数字孪生表示是创建物理过程虚拟副本的构建块。最后，我们讨论了数字孪生表示如何通过提供物理上 ground 的表示和显性编码领域知识来解决这些挑战，同时保留现实世界过程的连续性。', 'title_zh': '位置：基础模型需要数字孪生表示。'}
{'arxiv_id': 'arXiv:2505.03795', 'title': 'Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics', 'authors': 'Jacob W. Crandall, Jonathan Skaggs', 'link': 'https://arxiv.org/abs/2505.03795', 'abstract': "Human networks greatly impact important societal outcomes, including wealth and health inequality, poverty, and bullying. As such, understanding human networks is critical to learning how to promote favorable societal outcomes. As a step toward better understanding human networks, we compare and contrast several methods for learning models of human behavior in a strategic network game called the Junior High Game (JHG). These modeling methods differ with respect to the assumptions they use to parameterize human behavior (behavior vs. community-aware behavior) and the statistical moments they model (mean vs. distribution). Results show that the highest-performing method models the population's distribution rather than the mean and assumes humans use community-aware behavior rather than behavior matching. When applied to small societies (6-11 individuals), this learned model, called hCAB, closely mirrors the population dynamics of human groups (with some differences). Additionally, a user study reveals that human participants were unable to distinguish hCAB agents from other humans, thus illustrating that individual hCAB behavior plausibly mirrors human behavior in this strategic network game.", 'abstract_zh': '人类网络极大地影响着财富和健康不平等、贫困和欺凌等重要社会成果。因此，理解人类网络对于学习如何促进有利的社会成果至关重要。为更好地理解人类网络，我们比较了几种在名为初中游戏（JHG）的战略网络游戏中学习人类行为模型的方法。这些建模方法在参数化人类行为（行为 vs. 社区意识行为）和建模的统计时刻（均值 vs. 分布）的假设上有所不同。结果表明，表现最高的方法建模的是人群的分布而非均值，并假设人类使用社区意识行为而非匹配行为。当应用于小社会（6-11 人）时，这种学习到的模型（称为hCAB）在一定程度上反映了人类群体的动态特性。此外，一项用户研究显示，人类参与者无法区分hCAB代理与其他人类，从而说明了个体hCAB行为在这一战略网络游戏中可能真实地反映了人类行为。', 'title_zh': '具有复杂群体动态的战略网络游戏中的人类行为建模'}
{'arxiv_id': 'arXiv:2505.03791', 'title': 'Practical Boolean Backpropagation', 'authors': 'Simon Golbert', 'link': 'https://arxiv.org/abs/2505.03791', 'abstract': 'Boolean neural networks offer hardware-efficient alternatives to real-valued models. While quantization is common, purely Boolean training remains underexplored. We present a practical method for purely Boolean backpropagation for networks based on a single specific gate we chose, operating directly in Boolean algebra involving no numerics. Initial experiments confirm its feasibility.', 'abstract_zh': '纯布尔训练为基于单一特定门电路的网络提供硬件高效的替代方案：无需数值运算的纯布尔反向传播仍然未被充分探索。初步实验证实了其可行性。', 'title_zh': '实用布尔反向传播'}
{'arxiv_id': 'arXiv:2505.03790', 'title': 'A Time-Series Data Augmentation Model through Diffusion and Transformer Integration', 'authors': 'Yuren Zhang, Zhongnan Pu, Lei Jing', 'link': 'https://arxiv.org/abs/2505.03790', 'abstract': 'With the development of Artificial Intelligence, numerous real-world tasks have been accomplished using technology integrated with deep learning. To achieve optimal performance, deep neural networks typically require large volumes of data for training. Although advances in data augmentation have facilitated the acquisition of vast datasets, most of this data is concentrated in domains like images and speech. However, there has been relatively less focus on augmenting time-series data. To address this gap and generate a substantial amount of time-series data, we propose a simple and effective method that combines the Diffusion and Transformer models. By utilizing an adjusted diffusion denoising model to generate a large volume of initial time-step action data, followed by employing a Transformer model to predict subsequent actions, and incorporating a weighted loss function to achieve convergence, the method demonstrates its effectiveness. Using the performance improvement of the model after applying augmented data as a benchmark, and comparing the results with those obtained without data augmentation or using traditional data augmentation methods, this approach shows its capability to produce high-quality augmented data.', 'abstract_zh': '随着人工智能的发展，深度学习技术被广泛应用于许多实际任务。为了实现最优性能，深度神经网络通常需要大量的数据进行训练。尽管数据增强技术的进步促进了大量数据的获取，但大多数据集中在图像和语音领域。然而，对时间序列数据的数据增强研究相对较少。为填补这一空白并生成大量时间序列数据，我们提出了一种简单而有效的方法，该方法结合了扩散模型和变压器模型。通过使用调整后的扩散去噪模型生成大量初始时间步动作数据，然后利用变压器模型预测后续动作，并结合加权损失函数以实现模型收敛，该方法展示了其有效性。通过将模型在应用增强数据后的性能提升作为基准，并将其结果与未使用数据增强或使用传统数据增强方法的结果进行比较，该方法证明了其生成高质量增强数据的能力。', 'title_zh': '通过扩散和变换器集成的时间序列数据增强模型'}
{'arxiv_id': 'arXiv:2505.03769', 'title': 'The Influence of Text Variation on User Engagement in Cross-Platform Content Sharing', 'authors': 'Yibo Hu, Yiqiao Jin, Meng Ye, Ajay Divakaran, Srijan Kumar', 'link': 'https://arxiv.org/abs/2505.03769', 'abstract': "In today's cross-platform social media landscape, understanding factors that drive engagement for multimodal content, especially text paired with visuals, remains complex. This study investigates how rewriting Reddit post titles adapted from YouTube video titles affects user engagement. First, we build and analyze a large dataset of Reddit posts sharing YouTube videos, revealing that 21% of post titles are minimally modified. Statistical analysis demonstrates that title rewrites measurably improve engagement. Second, we design a controlled, multi-phase experiment to rigorously isolate the effects of textual variations by neutralizing confounding factors like video popularity, timing, and community norms. Comprehensive statistical tests reveal that effective title rewrites tend to feature emotional resonance, lexical richness, and alignment with community-specific norms. Lastly, pairwise ranking prediction experiments using a fine-tuned BERT classifier achieves 74% accuracy, significantly outperforming near-random baselines, including GPT-4o. These results validate that our controlled dataset effectively minimizes confounding effects, allowing advanced models to both learn and demonstrate the impact of textual features on engagement. By bridging quantitative rigor with qualitative insights, this study uncovers engagement dynamics and offers a robust framework for future cross-platform, multimodal content strategies.", 'abstract_zh': '在当今跨平台社交媒体 landscape 中，理解推动多媒体内容（尤其是配有视觉的文本）参与度的因素依然复杂。本研究探讨如何修改源自 YouTube 视频标题的 Reddit 文章标题以影响用户参与度。首先，我们构建并分析了一个大规模的 Reddit 分享 YouTube 视频的文章数据集，发现 21% 的文章标题仅进行了轻微修改。统计分析表明，标题修改显著提高了参与度。其次，我们设计了一项严密控制的多阶段实验，通过消除如视频受欢迎程度、时间因素和社区规范等混淆变量，严格隔离文本变化的影响。全面的统计测试表明，有效的标题修改通常具有情感共鸣、词汇丰富性和与特定社区规范的契合。最后，使用微调后的 BERT 分类器进行成对排名预测实验实现了 74% 的准确率，显著优于近随机基线，包括 GPT-4o。这些结果验证了我们控制的数据集有效地最小化了混淆效应，使高级模型能够学习并展示文本特征对参与度的影响。通过结合定量严谨性和定性洞察，本研究揭示了参与动态，并为未来的跨平台多媒体内容策略提供了稳健框架。', 'title_zh': '跨平台内容共享中文本变异对用户参与度的影响'}
{'arxiv_id': 'arXiv:2505.03764', 'title': 'Ultra-Low-Power Spiking Neurons in 7 nm FinFET Technology: A Comparative Analysis of Leaky Integrate-and-Fire, Morris-Lecar, and Axon-Hillock Architectures', 'authors': 'Logan Larsh, Raiyan Siddique, Sarah Sharif Yaser Mike Banad', 'link': 'https://arxiv.org/abs/2505.03764', 'abstract': "Neuromorphic computing aims to replicate the brain's remarkable energy efficiency and parallel processing capabilities for large-scale artificial intelligence applications. In this work, we present a comprehensive comparative study of three spiking neuron circuit architectures-Leaky-Integrate-and-Fire (LIF), Morris-Lecar (ML), and Axon-Hillock (AH)-implemented in a 7 nm FinFET technology. Through extensive SPICE simulations, we explore the optimization of spiking frequency, energy per spike, and static power consumption. Our results show that the AH design achieves the highest throughput, demonstrating multi-gigahertz firing rates (up to 3 GHz) with attojoule energy costs. By contrast, the ML architecture excels in subthreshold to near-threshold regimes, offering robust low-power operation (as low as 0.385 aJ/spike) and biological bursting behavior. Although LIF benefits from a decoupled current mirror for high-frequency operation, it exhibits slightly higher static leakage compared to ML and AH at elevated supply voltages. Comparisons with previous node implementations (22 nm planar, 28 nm) reveal that 7 nm FinFETs can drastically boost energy efficiency and speed albeit at the cost of increased subthreshold leakage in deep subthreshold regions. By quantifying design trade-offs for each neuron architecture, our work provides a roadmap for optimizing spiking neuron circuits in advanced nanoscale technologies to deliver neuromorphic hardware capable of both ultra-low-power operation and high computational throughput.", 'abstract_zh': '神经形态计算旨在复制大脑的卓越能效和并行处理能力，以应对大规模人工智能应用。在本工作中，我们全面比较了三种尖针神经元电路架构——Leaky-Integrate-and-Fire (LIF)、Morris-Lecar (ML) 和 Axon-Hillock (AH)，这些架构在7 nm FinFET技术中实现。通过广泛的SPICE仿真，我们探索了尖针频率、每尖针能耗和静态功耗的优化。我们的结果显示，AH设计实现了最高的吞吐量，其多吉赫兹发射率（高达3 GHz）伴随阿拓焦耳级的能量成本。相比之下，ML架构在亚阈值到近阈值区域内表现出色，提供了稳健的低功耗操作（低至0.385 aJ/尖针）和生物学上的爆发行为。尽管LIF得益于用于高频操作的解耦电流镜，但在高供电电压下，其静态漏电流略高于ML和AH。与之前的节点实现（22 nm 平面，28 nm）的比较揭示，7 nm FinFET可以大幅提高能效和速度，尽管代价是深亚阈值区域内的亚阈值泄漏增加。通过量化每种神经元架构的设计权衡，我们的工作为在先进的纳米尺度技术中优化尖针神经元电路提供了路线图，以实现既能进行超低功耗操作又能提供高计算吞吐量的神经形态硬件。', 'title_zh': '7 nm FinFET 技术下的超低功耗脉冲神经元：Leaky Integrate-and-Fire、Morris-Lecar 和 Axon-Hillock 架构的比较分析'}
{'arxiv_id': 'arXiv:2505.03760', 'title': 'Deep Reinforcement Learning for Investor-Specific Portfolio Optimization: A Volatility-Guided Asset Selection Approach', 'authors': 'Arishi Orra, Aryan Bhambu, Himanshu Choudhary, Manoj Thakur, Selvaraju Natarajan', 'link': 'https://arxiv.org/abs/2505.03760', 'abstract': "Portfolio optimization requires dynamic allocation of funds by balancing the risk and return tradeoff under dynamic market conditions. With the recent advancements in AI, Deep Reinforcement Learning (DRL) has gained prominence in providing adaptive and scalable strategies for portfolio optimization. However, the success of these strategies depends not only on their ability to adapt to market dynamics but also on the careful pre-selection of assets that influence overall portfolio performance. Incorporating the investor's preference in pre-selecting assets for a portfolio is essential in refining their investment strategies. This study proposes a volatility-guided DRL-based portfolio optimization framework that dynamically constructs portfolios based on investors' risk profiles. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model is utilized for volatility forecasting of stocks and categorizes them based on their volatility as aggressive, moderate, and conservative. The DRL agent is then employed to learn an optimal investment policy by interacting with the historical market data. The efficacy of the proposed methodology is established using stocks from the Dow $30$ index. The proposed investor-specific DRL-based portfolios outperformed the baseline strategies by generating consistent risk-adjusted returns.", 'abstract_zh': '基于波动率引导的DRL动态投资组合优化框架：根据投资者风险偏好构建投资组合，并在道琼斯30指数股票上验证其优势', 'title_zh': '基于波动率引导的资产选择方法的投资者特定投资组合优化的深度强化学习研究'}
{'arxiv_id': 'arXiv:2505.03750', 'title': 'AI-Powered Agile Analog Circuit Design and Optimization', 'authors': 'Jinhai Hu, Wang Ling Goh, Yuan Gao', 'link': 'https://arxiv.org/abs/2505.03750', 'abstract': 'Artificial intelligence (AI) techniques are transforming analog circuit design by automating device-level tuning and enabling system-level co-optimization. This paper integrates two approaches: (1) AI-assisted transistor sizing using Multi-Objective Bayesian Optimization (MOBO) for direct circuit parameter optimization, demonstrated on a linearly tunable transconductor; and (2) AI-integrated circuit transfer function modeling for system-level optimization in a keyword spotting (KWS) application, demonstrated by optimizing an analog bandpass filter within a machine learning training loop. The combined insights highlight how AI can improve analog performance, reduce design iteration effort, and jointly optimize analog components and application-level metrics.', 'abstract_zh': '人工智能技术正在通过自动化器件级调谐和实现系统级协同优化来变革模拟电路设计。本文结合了两种方法：（1）使用多目标贝叶斯优化（MOBO）的人工智能辅助晶体管尺寸优化，用于直接电路参数优化，以线性可调跨导为例；（2）将人工智能集成到电路传递函数建模中，在关键词识别（KWS）应用中实现系统级优化，通过在机器学习训练回路中优化一个模拟带通滤波器来演示。结合这些见解突显了人工智能如何提高模拟性能、减少设计迭代努力，并实现模拟组件和应用级指标的联合优化。', 'title_zh': '基于AI的敏捷模拟电路设计与优化'}
{'arxiv_id': 'arXiv:2505.03748', 'title': 'APSQ: Additive Partial Sum Quantization with Algorithm-Hardware Co-Design', 'authors': 'Yonghao Tan, Pingcheng Dong, Yongkun Wu, Yu Liu, Xuejiao Liu, Peng Luo, Shih-Yang Liu, Xijie Huang, Dong Zhang, Luhong Liang, Kwang-Ting Cheng', 'link': 'https://arxiv.org/abs/2505.03748', 'abstract': 'DNN accelerators, significantly advanced by model compression and specialized dataflow techniques, have marked considerable progress. However, the frequent access of high-precision partial sums (PSUMs) leads to excessive memory demands in architectures utilizing input/weight stationary dataflows. Traditional compression strategies have typically overlooked PSUM quantization, which may account for 69% of power consumption. This study introduces a novel Additive Partial Sum Quantization (APSQ) method, seamlessly integrating PSUM accumulation into the quantization framework. A grouping strategy that combines APSQ with PSUM quantization enhanced by a reconfigurable architecture is further proposed. The APSQ performs nearly lossless on NLP and CV tasks across BERT, Segformer, and EfficientViT models while compressing PSUMs to INT8. This leads to a notable reduction in energy costs by 28-87%. Extended experiments on LLaMA2-7B demonstrate the potential of APSQ for large language models. Code is available at this https URL.', 'abstract_zh': 'DNN加速器在模型压缩和专业数据流技术的推动下取得了显著进步，然而，在采用输入/权重固定数据流架构中，高精度部分和（PSUM）的频繁访问导致了过高的内存需求。传统压缩策略通常忽略了PSUM量化，而这可能占用了69%的功耗。本研究提出了一种新颖的加性部分和量化（APSQ）方法，将PSUM累加无缝集成到量化框架中。进一步提出了结合APSQ与增强型重配置架构的PSUM量化组合策略。APSQ在BERT、Segformer和EfficientViT模型的NLP和CV任务中几乎无损压缩PSUM至INT8，从而减少高达28-87%的能耗。扩展实验表明，APSQ对大型语言模型LLaMA2-7B具有潜在优势。相关代码可访问此链接。', 'title_zh': 'APSQ: 增量部分和量化结合算法-硬件协同设计'}
{'arxiv_id': 'arXiv:2505.03747', 'title': 'The Evolution of Rough Sets 1970s-1981', 'authors': 'Viktor Marek, Ewa Orłowska, Ivo Düntsch', 'link': 'https://arxiv.org/abs/2505.03747', 'abstract': 'In this note research and publications by Zdzisław Pawlak and his collaborators from 1970s and 1981 are recalled. Focus is placed on the sources of inspiration which one can identify on the basis of those publications. Finally, developments from 1981 related to rough sets and information systems are outlined.', 'abstract_zh': '20世纪70年代和1981年Zdzisław Pawlak及其合作者的研究与出版回顾：基于这些出版物的灵感来源及其后的研究进展概述', 'title_zh': '粗糙集的发展1970年代至1981年'}
{'arxiv_id': 'arXiv:2504.13777', 'title': 'Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication', 'authors': 'Anqi Shao', 'link': 'https://arxiv.org/abs/2504.13777', 'abstract': 'This paper proposes a conceptual framework for understanding AI hallucinations as a distinct form of misinformation. While misinformation scholarship has traditionally focused on human intent, generative AI systems now produce false yet plausible outputs absent of such intent. I argue that these AI hallucinations should not be treated merely as technical failures but as communication phenomena with social consequences. Drawing on a supply-and-demand model and the concept of distributed agency, the framework outlines how hallucinations differ from human-generated misinformation in production, perception, and institutional response. I conclude by outlining a research agenda for communication scholars to investigate the emergence, dissemination, and audience reception of hallucinated content, with attention to macro (institutional), meso (group), and micro (individual) levels. This work urges communication researchers to rethink the boundaries of misinformation theory in light of probabilistic, non-human actors increasingly embedded in knowledge production.', 'abstract_zh': '本文提出了一种概念框架，用于理解AI幻觉作为 misinformation 的一种独特形式。传统 misinformation 研究侧重于人类意图，而生成型 AI 系统现在可以产生缺乏此类意图的虚假但可信的输出。我认为，这些 AI 幻觉不应仅仅被视为技术故障，而应视为具有社会后果的沟通现象。基于供需模型和分散式代理的概念，该框架阐述了幻觉在生产、感知和机构应对方面的差异。最后，本文提出了一个研究议程，建议沟通学者调查幻觉内容的产生、传播和受众接受情况，关注宏观（机构）、中观（群体）和微观（个体）三个层面。本文呼吁沟通研究者重新思考 misinformation 理论的边界，以应对日益嵌入知识生产过程中的概率性非人类行为体。', 'title_zh': '超越 misinformation：研究科学传播中 AI 幻觉的 conceptual framework'}
