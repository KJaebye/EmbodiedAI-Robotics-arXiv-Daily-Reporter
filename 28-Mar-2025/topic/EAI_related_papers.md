# Dataset and Analysis of Long-Term Skill Acquisition in Robot-Assisted Minimally Invasive Surgery 

**Title (ZH)**: 基于机器人辅助微创手术的长期技能获取数据集与分析 

**Authors**: Yarden Sharon, Alex Geftler, Hanna Kossowsky Lev, Ilana Nisky  

**Link**: [PDF](https://arxiv.org/pdf/2503.21591)  

**Abstract**: Objective: We aim to investigate long-term robotic surgical skill acquisition among surgical residents and the effects of training intervals and fatigue on performance. Methods: For six months, surgical residents participated in three training sessions once a month, surrounding a single 26-hour hospital shift. In each shift, they participated in training sessions scheduled before, during, and after the shift. In each training session, they performed three dry-lab training tasks: Ring Tower Transfer, Knot-Tying, and Suturing. We collected a comprehensive dataset, including videos synchronized with kinematic data, activity tracking, and scans of the suturing pads. Results: We collected a dataset of 972 trials performed by 18 residents of different surgical specializations. Participants demonstrated consistent performance improvement across all tasks. In addition, we found variations in between-shift learning and forgetting across metrics and tasks, and hints for possible effects of fatigue. Conclusion: The findings from our first analysis shed light on the long-term learning processes of robotic surgical skills with extended intervals and varying levels of fatigue. Significance: This study lays the groundwork for future research aimed at optimizing training protocols and enhancing AI applications in surgery, ultimately contributing to improved patient outcomes. The dataset will be made available upon acceptance of our journal submission. 

**Abstract (ZH)**: 研究目标：我们旨在调查手术 residents 在长期机器人手术技能学习中的表现，并研究训练间隔和疲劳对表现的影响。方法：六个月内，手术 residents 每月参与三次围绕26小时住院轮班的培训，每次轮班中，他们分别在轮班前后及期间参与培训。在每次培训中，他们执行三个干实验培训任务：Ring Tower Transfer、Knot-Tying 和 Suturing。我们收集了包括与运动数据同步的视频、活动跟踪以及缝合垫扫描在内的全面数据集。结果：我们收集了18名来自不同手术专科的 residents 执行的972次试验数据。参与者在所有任务上展示了持续的表现改进。此外，我们还发现学习和遗忘在不同指标和任务上的差异，并暗示了疲劳可能的影响。结论：首次分析的发现揭示了在长周期间隔和不同疲劳水平下机器人手术技能学习的长期过程。意义：本研究为未来旨在优化培训方案和增强手术中人工智能应用的研究奠定了基础，最终有助于改善患者预后。数据集将在期刊投稿接受后提供。 

---
# STAMICS: Splat, Track And Map with Integrated Consistency and Semantics for Dense RGB-D SLAM 

**Title (ZH)**: STAMICS: 喷射、追踪和建图并与一致性及语义集成的密集RGB-D SLAM 

**Authors**: Yongxu Wang, Xu Cao, Weiyun Yi, Zhaoxin Fan  

**Link**: [PDF](https://arxiv.org/pdf/2503.21425)  

**Abstract**: Simultaneous Localization and Mapping (SLAM) is a critical task in robotics, enabling systems to autonomously navigate and understand complex environments. Current SLAM approaches predominantly rely on geometric cues for mapping and localization, but they often fail to ensure semantic consistency, particularly in dynamic or densely populated scenes. To address this limitation, we introduce STAMICS, a novel method that integrates semantic information with 3D Gaussian representations to enhance both localization and mapping accuracy. STAMICS consists of three key components: a 3D Gaussian-based scene representation for high-fidelity reconstruction, a graph-based clustering technique that enforces temporal semantic consistency, and an open-vocabulary system that allows for the classification of unseen objects. Extensive experiments show that STAMICS significantly improves camera pose estimation and map quality, outperforming state-of-the-art methods while reducing reconstruction errors. Code will be public available. 

**Abstract (ZH)**: 基于语义信息的3D高斯表示 simultaneously localization and mapping (STAMICS): 同时定位与建图 

---
# AcL: Action Learner for Fault-Tolerant Quadruped Locomotion Control 

**Title (ZH)**: 故障 tolerant 四足行走控制的行动学习者 

**Authors**: Tianyu Xu, Yaoyu Cheng, Pinxi Shen, Lin Zhao, Electrical, Computer Engineering, National University of Singapore, Singapore, Mechanical Engineering, National University of Singapore, Singapore  

**Link**: [PDF](https://arxiv.org/pdf/2503.21401)  

**Abstract**: Quadrupedal robots can learn versatile locomotion skills but remain vulnerable when one or more joints lose power. In contrast, dogs and cats can adopt limping gaits when injured, demonstrating their remarkable ability to adapt to physical conditions. Inspired by such adaptability, this paper presents Action Learner (AcL), a novel teacher-student reinforcement learning framework that enables quadrupeds to autonomously adapt their gait for stable walking under multiple joint faults. Unlike conventional teacher-student approaches that enforce strict imitation, AcL leverages teacher policies to generate style rewards, guiding the student policy without requiring precise replication. We train multiple teacher policies, each corresponding to a different fault condition, and subsequently distill them into a single student policy with an encoder-decoder architecture. While prior works primarily address single-joint faults, AcL enables quadrupeds to walk with up to four faulty joints across one or two legs, autonomously switching between different limping gaits when faults occur. We validate AcL on a real Go2 quadruped robot under single- and double-joint faults, demonstrating fault-tolerant, stable walking, smooth gait transitions between normal and lamb gaits, and robustness against external disturbances. 

**Abstract (ZH)**: 四足机器人可以通过学习获得多样的运动技能，但在某些关节失效时仍然脆弱。相比之下，狗和猫在受伤时可以采用跛行步态，显示出它们适应物理条件的出色能力。受这种适应性启发，本文提出了一种新的教师-学生强化学习框架Action Learner (AcL)，该框架使四足机器人能够在多个关节故障的情况下自主调整步态以实现稳定行走。与传统的严格 imitation 方法不同，AcL 利用教师策略生成风格奖励，引导学生策略而不需精确复制。我们训练了多个针对不同故障条件的教师策略，并通过编码器-解码器架构将它们提炼成一个学生策略。相比于以往主要解决单关节故障的研究，AcL 允许四足机器人在一条或多条腿有多个故障关节的情况下自主切换不同的跛行步态以实现稳定行走。我们在单关节和双关节故障的真实 Go2 四足机器人上验证了 AcL，展示了其在面对外部干扰时的容错性、稳定行走能力以及正常步态与羔羊步态之间的平滑过渡。 

---
# OminiAdapt: Learning Cross-Task Invariance for Robust and Environment-Aware Robotic Manipulation 

**Title (ZH)**: OminiAdapt: 学习跨任务不变性以实现稳健且环境意识强的机器人操作 

**Authors**: Yongxu Wang, Weiyun Yi, Xinhao Kong, Wanting Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.21257)  

**Abstract**: With the rapid development of embodied intelligence, leveraging large-scale human data for high-level imitation learning on humanoid robots has become a focal point of interest in both academia and industry. However, applying humanoid robots to precision operation domains remains challenging due to the complexities they face in perception and control processes, the long-standing physical differences in morphology and actuation mechanisms between humanoid robots and humans, and the lack of task-relevant features obtained from egocentric vision. To address the issue of covariate shift in imitation learning, this paper proposes an imitation learning algorithm tailored for humanoid robots. By focusing on the primary task objectives, filtering out background information, and incorporating channel feature fusion with spatial attention mechanisms, the proposed algorithm suppresses environmental disturbances and utilizes a dynamic weight update strategy to significantly improve the success rate of humanoid robots in accomplishing target tasks. Experimental results demonstrate that the proposed method exhibits robustness and scalability across various typical task scenarios, providing new ideas and approaches for autonomous learning and control in humanoid robots. The project will be open-sourced on GitHub. 

**Abstract (ZH)**: 随着嵌入式智能的快速发展，利用大规模人类数据进行类人机器人高层次模仿学习已成为学术界和工业界的热点。然而，将类人机器人应用于精密操作领域仍然具有挑战性，原因在于感知和控制过程中面临的复杂性，类人机器人与人类在形态和驱动机制上的长期差异，以及从第一人称视觉获得的相关任务特征的缺乏。为解决模仿学习中的协变量偏移问题，本文提出了一种适用于类人机器人的模仿学习算法。该算法侧重主要任务目标，过滤背景信息，并结合通道特征融合与空间注意力机制，抑制环境干扰，利用动态权重更新策略显著提高类人机器人完成目标任务的成功率。实验结果表明，所提方法在多种典型任务场景下具有稳健性和可扩展性，为类人机器人自主学习与控制提供了新的思路和方法。该项目将在GitHub上开源。 

---
# Anti Robot Speciesism 

**Title (ZH)**: 反机器人种主义 

**Authors**: Julian De Freitas, Noah Castelo, Bernd Schmitt, Miklos Sarvary  

**Link**: [PDF](https://arxiv.org/pdf/2503.20842)  

**Abstract**: Humanoid robots are a form of embodied artificial intelligence (AI) that looks and acts more and more like humans. Powered by generative AI and advances in robotics, humanoid robots can speak and interact with humans rather naturally but are still easily recognizable as robots. But how will we treat humanoids when they seem indistinguishable from humans in appearance and mind? We find a tendency (called "anti-robot" speciesism) to deny such robots humanlike capabilities, driven by motivations to accord members of the human species preferential treatment. Six experiments show that robots are denied humanlike attributes, simply because they are not biological beings and because humans want to avoid feelings of cognitive dissonance when utilizing such robots for unsavory tasks. Thus, people do not rationally attribute capabilities to perfectly humanlike robots but deny them capabilities as it suits them. 

**Abstract (ZH)**: 拟人机器人是一种体现式的人工智能（AI），在外貌和行为上越来越像人类。依靠生成式AI和机器人技术的进步，拟人机器人能够以相当自然的方式与人类交谈和互动，但仍很容易被辨认出是机器人。但在拟人机器人在外貌和心智上几乎与人类无异时，我们又将如何对待它们？我们发现了一种倾向（称为“反机器人”物种主义），即否认这些机器人类似人类的能力，这种倾向的动力是给予人类物种成员优先待遇的动机。六项实验表明，机器人被认为不具备类似人类的属性，仅仅是因为它们不是生物体，而人类在利用这些机器人完成令人不快的任务时想要避免认知失调的感觉。因此，人们并不理性地将能力赋予完全类似人类的机器人，而是出于自身利益拒绝赋予它们这些能力。 

---
# TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion 

**Title (ZH)**: TAR: 通过对比学习实现与教师对齐的表示以应用于四足行走 

**Authors**: Amr Mousa, Neil Karavis, Michele Caprio, Wei Pan, Richard Allmendinger  

**Link**: [PDF](https://arxiv.org/pdf/2503.20839)  

**Abstract**: Quadrupedal locomotion via Reinforcement Learning (RL) is commonly addressed using the teacher-student paradigm, where a privileged teacher guides a proprioceptive student policy. However, key challenges such as representation misalignment between the privileged teacher and the proprioceptive-only student, covariate shift due to behavioral cloning, and lack of deployable adaptation lead to poor generalization in real-world scenarios. We propose Teacher-Aligned Representations via Contrastive Learning (TAR), a framework that leverages privileged information with self-supervised contrastive learning to bridge this gap. By aligning representations to a privileged teacher in simulation via contrastive objectives, our student policy learns structured latent spaces and exhibits robust generalization to Out-of-Distribution (OOD) scenarios, surpassing the fully privileged "Teacher". Results showed accelerated training by 2x compared to state-of-the-art baselines to achieve peak performance. OOD scenarios showed better generalization by 40 percent on average compared to existing methods. Additionally, TAR transitions seamlessly into learning during deployment without requiring privileged states, setting a new benchmark in sample-efficient, adaptive locomotion and enabling continual fine-tuning in real-world scenarios. Open-source code and videos are available at this https URL. 

**Abstract (ZH)**: 基于对比学习的教师对齐表示（TAR）：通过强化学习实现四足运动 

---
# Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning 

**Title (ZH)**: 神经符号imitation学习：发现技能学习中的符号抽象 

**Authors**: Leon Keller, Daniel Tanneberg, Jan Peters  

**Link**: [PDF](https://arxiv.org/pdf/2503.21406)  

**Abstract**: Imitation learning is a popular method for teaching robots new behaviors. However, most existing methods focus on teaching short, isolated skills rather than long, multi-step tasks. To bridge this gap, imitation learning algorithms must not only learn individual skills but also an abstract understanding of how to sequence these skills to perform extended tasks effectively. This paper addresses this challenge by proposing a neuro-symbolic imitation learning framework. Using task demonstrations, the system first learns a symbolic representation that abstracts the low-level state-action space. The learned representation decomposes a task into easier subtasks and allows the system to leverage symbolic planning to generate abstract plans. Subsequently, the system utilizes this task decomposition to learn a set of neural skills capable of refining abstract plans into actionable robot commands. Experimental results in three simulated robotic environments demonstrate that, compared to baselines, our neuro-symbolic approach increases data efficiency, improves generalization capabilities, and facilitates interpretability. 

**Abstract (ZH)**: 模仿学习是一种popular方法，用于 teaching机器人新行为。然而，现有的大多数方法侧重于教授short、孤立的技能，而不是long、多步的任务。为解决这一问题，模仿学习算法不仅需要学习个体技能，还需要理解如何将这些技能按序排列以有效执行扩展任务。本文通过提出一种神经符号模仿学习框架来应对这一挑战。系统利用任务演示首先学习一种符号表示，该表示抽象了低层的状态-动作空间。所学的表示将任务分解为更易处理的子任务，并允许系统利用符号规划生成抽象计划。随后，系统利用这一任务分解来学习一套神经技能，以将抽象计划细化为可执行的机器人命令。在三个模拟机器人环境中的实验结果表明，与基线方法相比，我们的神经符号方法提高了数据效率、增强了泛化能力和提高了可解释性。 

---
# Robust Deep Reinforcement Learning in Robotics via Adaptive Gradient-Masked Adversarial Attacks 

**Title (ZH)**: 通过自适应梯度掩蔽对抗攻击实现机器人领域的鲁棒深度强化学习 

**Authors**: Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui, Yue Gao  

**Link**: [PDF](https://arxiv.org/pdf/2503.20844)  

**Abstract**: Deep reinforcement learning (DRL) has emerged as a promising approach for robotic control, but its realworld deployment remains challenging due to its vulnerability to environmental perturbations. Existing white-box adversarial attack methods, adapted from supervised learning, fail to effectively target DRL agents as they overlook temporal dynamics and indiscriminately perturb all state dimensions, limiting their impact on long-term rewards. To address these challenges, we propose the Adaptive Gradient-Masked Reinforcement (AGMR) Attack, a white-box attack method that combines DRL with a gradient-based soft masking mechanism to dynamically identify critical state dimensions and optimize adversarial policies. AGMR selectively allocates perturbations to the most impactful state features and incorporates a dynamic adjustment mechanism to balance exploration and exploitation during training. Extensive experiments demonstrate that AGMR outperforms state-of-the-art adversarial attack methods in degrading the performance of the victim agent and enhances the victim agent's robustness through adversarial defense mechanisms. 

**Abstract (ZH)**: 基于梯度掩蔽的自适应 gradient 调整强化学习（AGMR）攻击：一种白盒攻击方法 

---
# Cognitive Science-Inspired Evaluation of Core Capabilities for Object Understanding in AI 

**Title (ZH)**: 认知科学启发的对象理解人工智能核心能力评价 

**Authors**: Danaja Rutar, Alva Markelius, Konstantinos Voudouris, José Hernández-Orallo, Lucy Cheke  

**Link**: [PDF](https://arxiv.org/pdf/2503.21668)  

**Abstract**: One of the core components of our world models is 'intuitive physics' - an understanding of objects, space, and causality. This capability enables us to predict events, plan action and navigate environments, all of which rely on a composite sense of objecthood. Despite its importance, there is no single, unified account of objecthood, though multiple theoretical frameworks provide insights. In the first part of this paper, we present a comprehensive overview of the main theoretical frameworks in objecthood research - Gestalt psychology, enactive cognition, and developmental psychology - and identify the core capabilities each framework attributes to object understanding, as well as what functional roles they play in shaping world models in biological agents. Given the foundational role of objecthood in world modelling, understanding objecthood is also essential in AI. In the second part of the paper, we evaluate how current AI paradigms approach and test objecthood capabilities compared to those in cognitive science. We define an AI paradigm as a combination of how objecthood is conceptualised, the methods used for studying objecthood, the data utilised, and the evaluation techniques. We find that, whilst benchmarks can detect that AI systems model isolated aspects of objecthood, the benchmarks cannot detect when AI systems lack functional integration across these capabilities, not solving the objecthood challenge fully. Finally, we explore novel evaluation approaches that align with the integrated vision of objecthood outlined in this paper. These methods are promising candidates for advancing from isolated object capabilities toward general-purpose AI with genuine object understanding in real-world contexts. 

**Abstract (ZH)**: 我们世界观的核心组件之一是“直观物理”——对物体、空间和因果关系的理解。这一能力使我们能够预测事件、规划行动和导航环境，所有这些都依赖于对象本质的综合感知。尽管对象本质至关重要，但在对象本质的研究中尚未形成单一且统一的理论，尽管多个理论框架提供了重要见解。在本文的第一部分中，我们全面介绍了对象本质研究中的主要理论框架——格式塔心理学、活性认知和发展心理学，并识别出每个框架赋予对象理解的核心能力及其在塑造生物智能体世界观中的功能性作用。由于对象本质在世界观建模中的基础性作用，理解对象本质也是人工智能中不可或缺的一环。在本文的第二部分中，我们评估当前人工智能范式如何处理和测试对象本质能力，这些测试与认知科学中的情况相比如何。我们将AI范式定义为对象本质的概念化、研究方法、使用的数据以及评估技术的组合。我们发现，虽然基准测试可以检测到AI系统模型化对象本质的孤立方面，但这些基准测试无法检测到这些能力之间缺乏功能性整合的情况，无法完全解决对象本质挑战。最后，我们探索与本文概述的对象本质整合愿景相一致的新型评估方法。这些方法是朝着在真实世界环境中具备真正对象理解的大规模应用型AI方向迈进的有前途的候选方法。 

---
# Towards Fully Automated Decision-Making Systems for Greenhouse Control: Challenges and Opportunities 

**Title (ZH)**: 面向温室控制的完全自动化决策系统：挑战与机遇 

**Authors**: Yongshuai Liu, Taeyeong Choi, Xin Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.21640)  

**Abstract**: Machine learning has been successful in building control policies to drive a complex system to desired states in various applications (e.g. games, robotics, etc.). To be specific, a number of parameters of policy can be automatically optimized from the observations of environment to be able to generate a sequence of decisions leading to the best performance. In this survey paper, we particularly explore such policy-learning techniques for another unique, practical use-case scenario--farming, in which critical decisions (e.g., water supply, heating, etc.) must be made in a timely manner to minimize risks (e.g., damage to plants) while maximizing the revenue (e.g., healthy crops) in the end. We first provide a broad overview of latest studies on it to identify not only domain-specific challenges but opportunities with potential solutions, some of which are suggested as promising directions for future research. Also, we then introduce our successful approach to being ranked second among 46 teams at the ''3rd Autonomous Greenhouse Challenge'' to use this specific example to discuss the lessons learned about important considerations for design to create autonomous farm-management systems. 

**Abstract (ZH)**: 机器学习已在各种应用（例如游戏、机器人技术等）中成功构建控制策略，将复杂系统驱动到所需状态。具体而言，可以通过从环境观察中自动优化策略参数，生成一系列决策以实现最佳性能。在本文综述中，我们将特别探讨此类策略学习技术在另一个独特的实际应用场景——农业中的应用，其中必须在适当的时间作出关键决策（例如，灌溉、加热等）以尽量减少风险（例如，植物受损）并最大化最终收益（例如，健康作物）。我们首先提供最新的研究综述，以识别不仅限于领域特定的挑战，还包括具有潜在解决方案的机会，并提出其中一些领域作为未来研究的有前景方向。随后，我们将介绍我们成功的方法，即在“第三届自主温室挑战赛”中获得第2名的策略，通过具体示例讨论设计自主农场管理系统时需要考虑的重要注意事项。 

---
# Federated Intelligence: When Large AI Models Meet Federated Fine-Tuning and Collaborative Reasoning at the Network Edge 

**Title (ZH)**: 联邦智能：当大型AI模型遇到网络边缘的联邦微调与协作推理 

**Authors**: Wanli Ni, Haofeng Sun, Huiqing Ao, Hui Tian  

**Link**: [PDF](https://arxiv.org/pdf/2503.21412)  

**Abstract**: Large artificial intelligence (AI) models exhibit remarkable capabilities in various application scenarios, but deploying them at the network edge poses significant challenges due to issues such as data privacy, computational resources, and latency. In this paper, we explore federated fine-tuning and collaborative reasoning techniques to facilitate the implementation of large AI models in resource-constrained wireless networks. Firstly, promising applications of large AI models within specific domains are discussed. Subsequently, federated fine-tuning methods are proposed to adapt large AI models to specific tasks or environments at the network edge, effectively addressing the challenges associated with communication overhead and enhancing communication efficiency. These methodologies follow clustered, hierarchical, and asynchronous paradigms to effectively tackle privacy issues and eliminate data silos. Furthermore, to enhance operational efficiency and reduce latency, efficient frameworks for model collaborative reasoning are developed, which include decentralized horizontal collaboration, cloud-edge-end vertical collaboration, and multi-access collaboration. Next, simulation results demonstrate the effectiveness of our proposed methods in reducing the fine-tuning loss of large AI models across various downstream tasks. Finally, several open challenges and research opportunities are outlined. 

**Abstract (ZH)**: 大规模人工智能模型在各种应用场景中展现出显著的能力，但在无线网络边缘部署它们面临着数据隐私、计算资源和延迟等方面的重大挑战。本文探讨了联邦微调和协作推理技术，以促进大规模人工智能模型在资源受限无线网络中的实现。首先，讨论了大规模人工智能模型在特定领域的潜在应用。随后，提出了联邦微调方法，以在网络边缘将大规模人工智能模型适配到特定任务或环境中，有效解决通信开销问题，提升通信效率。这些方法遵循集群化、分层次和异步化的范式，有效应对隐私问题并消除数据孤岛。为进一步提高操作效率并降低延迟，还开发了高效模型协作推理框架，包括去中心化的水平协作、云-边缘-端的垂直协作以及多接入协作。接下来，仿真结果证明了我们所提出方法在各类下游任务中减少大规模人工智能模型微调损失的有效性。最后，概述了若干开放挑战和研究机遇。 

---
# Knowledge Graphs as World Models for Semantic Material-Aware Obstacle Handling in Autonomous Vehicles 

**Title (ZH)**: 知识图谱作为语义材料感知障碍物处理的世界模型在自动驾驶车辆中的应用 

**Authors**: Ayush Bheemaiah, Seungyong Yang  

**Link**: [PDF](https://arxiv.org/pdf/2503.21232)  

**Abstract**: The inability of autonomous vehicles (AVs) to infer the material properties of obstacles limits their decision-making capacity. While AVs rely on sensor systems such as cameras, LiDAR, and radar to detect obstacles, this study suggests combining sensors with a knowledge graph (KG)-based world model to improve AVs' comprehension of physical material qualities. Beyond sensor data, AVs can infer qualities such as malleability, density, and elasticity using a semantic KG that depicts the relationships between obstacles and their attributes. Using the CARLA autonomous driving simulator, we evaluated AV performance with and without KG integration. The findings demonstrate that the KG-based method improves obstacle management, which allows AVs to use material qualities to make better decisions about when to change lanes or apply emergency braking. For example, the KG-integrated AV changed lanes for hard impediments like traffic cones and successfully avoided collisions with flexible items such as plastic bags by passing over them. Compared to the control system, the KG framework demonstrated improved responsiveness to obstacles by resolving conflicting sensor data, causing emergency stops for 13.3% more cases. In addition, our method exhibits a 6.6% higher success rate in lane-changing maneuvers in experimental scenarios, particularly for larger, high-impact obstacles. While we focus particularly on autonomous driving, our work demonstrates the potential of KG-based world models to improve decision-making in embodied AI systems and scale to other domains, including robotics, healthcare, and environmental simulation. 

**Abstract (ZH)**: 自主车辆难以推断障碍物的材料属性限制了其决策能力。本文建议通过将传感器与基于知识图谱（KG）的世界模型相结合，提升自主车辆对物理材料属性的理解。除了传感器数据外，自主车辆可以利用描述障碍物及其属性之间关系的语义知识图谱来推断柔韧性、密度和弹性等特性。通过CARLA自主驾驶模拟器评估了集成和未集成KG的自主车辆性能。研究结果表明，基于知识图谱的方法可以改善障碍物管理，使自主车辆能够利用材料属性在变更车道或紧急制动等决策时做出更合理的判断。例如，集成知识图谱的自主车辆在面对交通锥等坚硬障碍时会变道，并成功通过塑料袋等柔性物品以避免碰撞。与对照系统相比，基于知识图谱的框架在13.3%更多的情况下实现了紧急停靠，且在实验场景中，车道变更操作的成功率提高了6.6%，特别是对于大型、高冲击力的障碍物。尽管本文重点放在自主驾驶上，但研究展示了基于知识图谱的世界模型在改进具身人工智能系统决策、并扩展到其他领域（如机器人技术、医疗和环境模拟）中的潜力。 

---
# CTRL-O: Language-Controllable Object-Centric Visual Representation Learning 

**Title (ZH)**: CTRL-O: 语言可控的以对象为中心的视觉表示学习 

**Authors**: Aniket Didolkar, Andrii Zadaianchuk, Rabiul Awal, Maximilian Seitzer, Efstratios Gavves, Aishwarya Agrawal  

**Link**: [PDF](https://arxiv.org/pdf/2503.21747)  

**Abstract**: Object-centric representation learning aims to decompose visual scenes into fixed-size vectors called "slots" or "object files", where each slot captures a distinct object. Current state-of-the-art object-centric models have shown remarkable success in object discovery in diverse domains, including complex real-world scenes. However, these models suffer from a key limitation: they lack controllability. Specifically, current object-centric models learn representations based on their preconceived understanding of objects, without allowing user input to guide which objects are represented. Introducing controllability into object-centric models could unlock a range of useful capabilities, such as the ability to extract instance-specific representations from a scene. In this work, we propose a novel approach for user-directed control over slot representations by conditioning slots on language descriptions. The proposed ConTRoLlable Object-centric representation learning approach, which we term CTRL-O, achieves targeted object-language binding in complex real-world scenes without requiring mask supervision. Next, we apply these controllable slot representations on two downstream vision language tasks: text-to-image generation and visual question answering. The proposed approach enables instance-specific text-to-image generation and also achieves strong performance on visual question answering. 

**Abstract (ZH)**: 基于物体的表示学习旨在将视觉场景分解为固定大小的向量“槽”或“物体文件”，每个槽捕获一个独立的物体。当前的基于物体的表示学习模型在多样性领域，包括复杂的真实世界场景中展现出了显著的物体发现能力。然而，这些模型存在一个关键局限：缺乏可控性。具体而言，现有的基于物体的表示学习模型基于它们预设的物体理解来学习表示，而不允许用户输入来引导哪些物体被表示。将可控性引入基于物体的表示学习模型可以解锁一系列有用的功能，例如从场景中提取实例特定的表示。在本工作中，我们提出了一种新的方法，通过将槽条件化于语言描述，实现用户导向的槽表示控制。我们提出的方法CTRL-O能在不需要掩码监督的情况下实现复杂真实世界场景中的目标物体-语言绑定。然后，我们在这两种下游视觉语言任务上应用这些可控的槽表示：文本到图像生成和视觉问答。所提出的方法实现了实例特定的文本到图像生成，并且在视觉问答任务上也取得了强劲的表现。 

---
# Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base 

**Title (ZH)**: 基于特征排名知识库的ODLLM智能物联网攻击检测设计 

**Authors**: Satvik Verma, Qun Wang, E. Wes Bethel  

**Link**: [PDF](https://arxiv.org/pdf/2503.21674)  

**Abstract**: The widespread adoption of Internet of Things (IoT) devices has introduced significant cybersecurity challenges, particularly with the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks. Traditional machine learning (ML) techniques often fall short in detecting such attacks due to the complexity of blended and evolving patterns. To address this, we propose a novel framework leveraging On-Device Large Language Models (ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for intelligent IoT network attack detection. By implementing feature ranking techniques and constructing both long and short KBs tailored to model capacities, the proposed framework ensures efficient and accurate detection of DDoS attacks while overcoming computational and privacy limitations. Simulation results demonstrate that the optimized framework achieves superior accuracy across diverse attack types, especially when using compact models in edge computing environments. This work provides a scalable and secure solution for real-time IoT security, advancing the applicability of edge intelligence in cybersecurity. 

**Abstract (ZH)**: 物联网设备的广泛采用引入了重大的网络安全挑战，尤其是分布式拒绝服务（DDoS）攻击的频率和复杂性不断增加。传统的机器学习技术往往难以检测这类攻击，因为它们难以处理混杂且不断演化的模式。为此，我们提出了一种利用设备上大型语言模型（ODLLMs）并结合微调和知识库（KB）集成的新型框架，以实现智能物联网网络攻击检测。通过实施特征排名技术并构建适合模型容量的长短期知识库，所提出的框架能够在克服计算和隐私限制的同时，实现DDoS攻击的高效和准确检测。仿真结果表明，优化的框架在不同的攻击类型中实现了更高的准确性，尤其是在边缘计算环境中使用紧凑模型时更为突出。本研究为实时物联网安全提供了可扩展且安全的解决方案，并推动了边缘智能在网络安全中的应用。 

---
# Model Assembly Learning with Heterogeneous Layer Weight Merging 

**Title (ZH)**: 异质层权重合并的模型组装学习 

**Authors**: Yi-Kai Zhang, Jin Wang, Xu-Xiang Zhong, De-Chuan Zhan, Han-Jia Ye  

**Link**: [PDF](https://arxiv.org/pdf/2503.21657)  

**Abstract**: Model merging acquires general capabilities without extra data or training by combining multiple models' parameters. Previous approaches achieve linear mode connectivity by aligning parameters into the same loss basin using permutation invariance. In this paper, we introduce Model Assembly Learning (MAL), a novel paradigm for model merging that iteratively integrates parameters from diverse models in an open-ended model zoo to enhance the base model's capabilities. Unlike previous works that require identical architectures, MAL allows the merging of heterogeneous architectures and selective parameters across layers. Specifically, the base model can incorporate parameters from different layers of multiple pre-trained models. We systematically investigate the conditions and fundamental settings of heterogeneous parameter merging, addressing all possible mismatches in layer widths between the base and target models. Furthermore, we establish key laws and provide practical guidelines for effectively implementing MAL. 

**Abstract (ZH)**: 模型组装学习：一种通过迭代集成多样化模型参数以增强基础模型能力的新范式 

---
# A 71.2-$μ$W Speech Recognition Accelerator with Recurrent Spiking Neural Network 

**Title (ZH)**: 一种基于递归脉冲神经网络的71.2-μW 语音识别加速器 

**Authors**: Chih-Chyau Yang, Tian-Sheuan Chang  

**Link**: [PDF](https://arxiv.org/pdf/2503.21337)  

**Abstract**: This paper introduces a 71.2-$\mu$W speech recognition accelerator designed for edge devices' real-time applications, emphasizing an ultra low power design. Achieved through algorithm and hardware co-optimizations, we propose a compact recurrent spiking neural network with two recurrent layers, one fully connected layer, and a low time step (1 or 2). The 2.79-MB model undergoes pruning and 4-bit fixed-point quantization, shrinking it by 96.42\% to 0.1 MB. On the hardware front, we take advantage of \textit{mixed-level pruning}, \textit{zero-skipping} and \textit{merged spike} techniques, reducing complexity by 90.49\% to 13.86 MMAC/S. The \textit{parallel time-step execution} addresses inter-time-step data dependencies and enables weight buffer power savings through weight sharing. Capitalizing on the sparse spike activity, an input broadcasting scheme eliminates zero computations, further saving power. Implemented on the TSMC 28-nm process, the design operates in real time at 100 kHz, consuming 71.2 $\mu$W, surpassing state-of-the-art designs. At 500 MHz, it has 28.41 TOPS/W and 1903.11 GOPS/mm$^2$ in energy and area efficiency, respectively. 

**Abstract (ZH)**: 一种用于边缘设备实时应用的71.2-μW语音识别加速器设计及其实现 

---
# Adversarial Wear and Tear: Exploiting Natural Damage for Generating Physical-World Adversarial Examples 

**Title (ZH)**: 对抗性磨损与撕裂：利用自然损坏生成物理世界中的 adversarial examples 

**Authors**: Samra Irshad, Seungkyu Lee, Nassir Navab, Hong Joo Lee, Seong Tae Kim  

**Link**: [PDF](https://arxiv.org/pdf/2503.21164)  

**Abstract**: The presence of adversarial examples in the physical world poses significant challenges to the deployment of Deep Neural Networks in safety-critical applications such as autonomous driving. Most existing methods for crafting physical-world adversarial examples are ad-hoc, relying on temporary modifications like shadows, laser beams, or stickers that are tailored to specific scenarios. In this paper, we introduce a new class of physical-world adversarial examples, AdvWT, which draws inspiration from the naturally occurring phenomenon of `wear and tear', an inherent property of physical objects. Unlike manually crafted perturbations, `wear and tear' emerges organically over time due to environmental degradation, as seen in the gradual deterioration of outdoor signboards. To achieve this, AdvWT follows a two-step approach. First, a GAN-based, unsupervised image-to-image translation network is employed to model these naturally occurring damages, particularly in the context of outdoor signboards. The translation network encodes the characteristics of damaged signs into a latent `damage style code'. In the second step, we introduce adversarial perturbations into the style code, strategically optimizing its transformation process. This manipulation subtly alters the damage style representation, guiding the network to generate adversarial images where the appearance of damages remains perceptually realistic, while simultaneously ensuring their effectiveness in misleading neural networks. Through comprehensive experiments on two traffic sign datasets, we show that AdvWT effectively misleads DNNs in both digital and physical domains. AdvWT achieves an effective attack success rate, greater robustness, and a more natural appearance compared to existing physical-world adversarial examples. Additionally, integrating AdvWT into training enhances a model's generalizability to real-world damaged signs. 

**Abstract (ZH)**: AdvWT：源自磨损与剥蚀现象的物理世界 adversarial examples 

---
