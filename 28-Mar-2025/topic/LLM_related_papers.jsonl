{'arxiv_id': 'arXiv:2503.21564', 'title': 'Cooking Task Planning using LLM and Verified by Graph Network', 'authors': 'Ryunosuke Takebayashi, Vitor Hideyo Isume, Takuya Kiyokawa, Weiwei Wan, Kensuke Harada', 'link': 'https://arxiv.org/abs/2503.21564', 'abstract': 'Cooking tasks remain a challenging problem for robotics due to their complexity. Videos of people cooking are a valuable source of information for such task, but introduces a lot of variability in terms of how to translate this data to a robotic environment. This research aims to streamline this process, focusing on the task plan generation step, by using a Large Language Model (LLM)-based Task and Motion Planning (TAMP) framework to autonomously generate cooking task plans from videos with subtitles, and execute them. Conventional LLM-based task planning methods are not well-suited for interpreting the cooking video data due to uncertainty in the videos, and the risk of hallucination in its output. To address both of these problems, we explore using LLMs in combination with Functional Object-Oriented Networks (FOON), to validate the plan and provide feedback in case of failure. This combination can generate task sequences with manipulation motions that are logically correct and executable by a robot. We compare the execution of the generated plans for 5 cooking recipes from our approach against the plans generated by a few-shot LLM-only approach for a dual-arm robot setup. It could successfully execute 4 of the plans generated by our approach, whereas only 1 of the plans generated by solely using the LLM could be executed.', 'abstract_zh': '基于大型语言模型的任务规划框架在从烹饪视频生成可执行任务计划中的应用', 'title_zh': '使用LLM进行烹饪任务规划并由图网络验证'}
{'arxiv_id': 'arXiv:2503.21683', 'title': 'LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku with Self-Play and Reinforcement Learning', 'authors': 'Hui Wang', 'link': 'https://arxiv.org/abs/2503.21683', 'abstract': 'In recent years, large language models (LLMs) have shown significant advancements in natural language processing (NLP), with strong capa-bilities in generation, comprehension, and rea-soning. These models have found applications in education, intelligent decision-making, and gaming. However, effectively utilizing LLMs for strategic planning and decision-making in the game of Gomoku remains a challenge. This study aims to develop a Gomoku AI system based on LLMs, simulating the human learning process of playing chess. The system is de-signed to understand and apply Gomoku strat-egies and logic to make rational decisions. The research methods include enabling the model to "read the board," "understand the rules," "select strategies," and "evaluate positions," while en-hancing its abilities through self-play and rein-forcement learning. The results demonstrate that this approach significantly improves the se-lection of move positions, resolves the issue of generating illegal positions, and reduces pro-cess time through parallel position evaluation. After extensive self-play training, the model\'s Gomoku-playing capabilities have been notably enhanced.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在自然语言处理（NLP）领域取得了显著进展，具备强大的生成、理解和推理能力。这些模型已在教育、智能决策和游戏等领域找到了应用。然而，有效利用LLMs进行五子棋的战略规划和决策仍然是一项挑战。本研究旨在基于LLMs开发一个模拟人类学习下棋过程的五子棋AI系统，设计该系统以理解和应用五子棋策略和逻辑，从而作出理性决策。研究方法包括使模型能够“读棋盘”、“理解规则”、“选择策略”和“评估位置”，并通过自我对弈和强化学习提升其能力。研究结果表明，这种 Approach 显著提高了落子位置的选择，解决了生成非法位置的问题，并通过并行位置评估缩减了处理时间。经过大量自我对弈训练后，模型的五子棋能力显著增强。', 'title_zh': '基于大语言模型的_self-play与强化学习相结合的围棋战略系统_ LLVM-Gomoku'}
{'arxiv_id': 'arXiv:2503.21620', 'title': 'UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning', 'authors': 'Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Guanjing Xiong, Hongsheng Li', 'link': 'https://arxiv.org/abs/2503.21620', 'abstract': 'The recent DeepSeek-R1 has showcased the emergence of reasoning capabilities in LLMs through reinforcement learning (RL) with rule-based rewards. Building on this idea, we are the first to explore how rule-based RL can enhance the reasoning capabilities of multimodal large language models (MLLMs) for graphic user interface (GUI) action prediction tasks. To this end, we curate a small yet high-quality dataset of 136 challenging tasks, encompassing five common action types on mobile devices. We also introduce a unified rule-based action reward, enabling model optimization via policy-based algorithms such as Group Relative Policy Optimization (GRPO). Experimental results demonstrate that our proposed data-efficient model, UI-R1-3B, achieves substantial improvements on both in-domain (ID) and out-of-domain (OOD) tasks. Specifically, on the ID benchmark AndroidControl, the action type accuracy improves by 15%, while grounding accuracy increases by 10.3%, compared with the base model (i.e. Qwen2.5-VL-3B). On the OOD GUI grounding benchmark ScreenSpot-Pro, our model surpasses the base model by 6.0% and achieves competitive performance with larger models (e.g., OS-Atlas-7B), which are trained via supervised fine-tuning (SFT) on 76K data. These results underscore the potential of rule-based reinforcement learning to advance GUI understanding and control, paving the way for future research in this domain.', 'abstract_zh': '基于规则的强化学习提升多模态大型语言模型在图形用户界面操作预测任务中的推理能力', 'title_zh': 'UI-R1: 通过强化学习增强GUI代理的动作预测'}
{'arxiv_id': 'arXiv:2503.21557', 'title': 'debug-gym: A Text-Based Environment for Interactive Debugging', 'authors': 'Xingdi Yuan, Morgane M Moss, Charbel El Feghali, Chinmay Singh, Darya Moldavskaya, Drew MacPhee, Lucas Caccia, Matheus Pereira, Minseon Kim, Alessandro Sordoni, Marc-Alexandre Côté', 'link': 'https://arxiv.org/abs/2503.21557', 'abstract': "Large Language Models (LLMs) are increasingly relied upon for coding tasks, yet in most scenarios it is assumed that all relevant information can be either accessed in context or matches their training data. We posit that LLMs can benefit from the ability to interactively explore a codebase to gather the information relevant to their task. To achieve this, we present a textual environment, namely debug-gym, for developing LLM-based agents in an interactive coding setting. Our environment is lightweight and provides a preset of useful tools, such as a Python debugger (pdb), designed to facilitate an LLM-based agent's interactive debugging. Beyond coding and debugging tasks, this approach can be generalized to other tasks that would benefit from information-seeking behavior by an LLM agent.", 'abstract_zh': '大规模语言模型（LLMs）在编码任务中的应用日益增多，然而在大多数场景中，假定所有相关的信息要么可以在上下文中访问，要么与模型的训练数据匹配。我们提出，LLMs可以从能够互动性地探索代码库以收集完成任务所需的相关信息中受益。为此，我们提出了一种文本环境，即debug-gym，用于在互动编码环境中开发基于LLM的代理。我们的环境轻量且预设了一些有用工具，例如Python调试器（pdb），旨在促进基于LLM的代理的互动性调试。除了编码和调试任务外，这种approach还可以泛化到其他可以从中受益于LLM代理的信息寻求行为的任务中。', 'title_zh': 'debug-gym: 基于文本的交互式调试环境'}
{'arxiv_id': 'arXiv:2503.21411', 'title': 'Exploring the Roles of Large Language Models in Reshaping Transportation Systems: A Survey, Framework, and Roadmap', 'authors': 'Tong Nie, Jian Sun, Wei Ma', 'link': 'https://arxiv.org/abs/2503.21411', 'abstract': 'Modern transportation systems face pressing challenges due to increasing demand, dynamic environments, and heterogeneous information integration. The rapid evolution of Large Language Models (LLMs) offers transformative potential to address these challenges. Extensive knowledge and high-level capabilities derived from pretraining evolve the default role of LLMs as text generators to become versatile, knowledge-driven task solvers for intelligent transportation systems. This survey first presents LLM4TR, a novel conceptual framework that systematically categorizes the roles of LLMs in transportation into four synergetic dimensions: information processors, knowledge encoders, component generators, and decision facilitators. Through a unified taxonomy, we systematically elucidate how LLMs bridge fragmented data pipelines, enhance predictive analytics, simulate human-like reasoning, and enable closed-loop interactions across sensing, learning, modeling, and managing tasks in transportation systems. For each role, our review spans diverse applications, from traffic prediction and autonomous driving to safety analytics and urban mobility optimization, highlighting how emergent capabilities of LLMs such as in-context learning and step-by-step reasoning can enhance the operation and management of transportation systems. We further curate practical guidance, including available resources and computational guidelines, to support real-world deployment. By identifying challenges in existing LLM-based solutions, this survey charts a roadmap for advancing LLM-driven transportation research, positioning LLMs as central actors in the next generation of cyber-physical-social mobility ecosystems. Online resources can be found in the project page: this https URL.', 'abstract_zh': '现代交通系统面临着日益增长的需求、动态环境以及异质信息集成等紧迫挑战。大型语言模型（LLMs）的迅猛发展为应对这些挑战提供了变革性的潜力。通过前期训练获得的广泛知识和高级能力，LLMs 的默认角色从文本生成者转变为适应性强、知识驱动的智能交通系统任务解决者。本文综述首先提出 LLM4TR，这是一种新颖的概念框架，系统地将 LLM 在交通中的角色划分为四大协同维度：信息处理器、知识编码器、组件生成器和决策促进者。通过统一的分类体系，本文系统地阐述了如何通过 LLM 桥接碎片化的数据管道、增强预测分析、模拟类人推理，以及在交通系统中的传感、学习、建模和管理任务中实现闭环交互。对于每种角色，我们的综述涵盖了从交通预测和自动驾驶到安全分析和城市交通优化等多样化的应用，突出了新兴的 LLM 能力，如上下文学习和逐步推理，如何增强交通系统的运行和管理。我们进一步整理了实用指导，包括可利用的资源和计算指南，以支持实际部署。通过识别现有基于LLM的解决方案中的挑战，本文为推进LLM驱动的交通研究绘制了蓝图，将LLM定位为下一代网络物理社会交通生态系统中的核心角色。有关在线资源，请参阅项目页面：this https URL。', 'title_zh': '探索大型语言模型在重塑交通运输系统中的作用：综述、框架与 roadmap'}
{'arxiv_id': 'arXiv:2503.21352', 'title': 'Using large language models to produce literature reviews: Usages and systematic biases of microphysics parametrizations in 2699 publications', 'authors': 'Tianhang Zhang, Shengnan Fu, David M. Schultz, Zhonghua Zheng', 'link': 'https://arxiv.org/abs/2503.21352', 'abstract': 'Large language models afford opportunities for using computers for intensive tasks, realizing research opportunities that have not been considered before. One such opportunity could be a systematic interrogation of the scientific literature. Here, we show how a large language model can be used to construct a literature review of 2699 publications associated with microphysics parametrizations in the Weather and Research Forecasting (WRF) model, with the goal of learning how they were used and their systematic biases, when simulating precipitation. The database was constructed of publications identified from Web of Science and Scopus searches. The large language model GPT-4 Turbo was used to extract information about model configurations and performance from the text of 2699 publications. Our results reveal the landscape of how nine of the most popular microphysics parameterizations have been used around the world: Lin, Ferrier, WRF Single-Moment, Goddard Cumulus Ensemble, Morrison, Thompson, and WRF Double-Moment. More studies used one-moment parameterizations before 2020 and two-moment parameterizations after 2020. Seven out of nine parameterizations tended to overestimate precipitation. However, systematic biases of parameterizations differed in various regions. Except simulations using the Lin, Ferrier, and Goddard parameterizations that tended to underestimate precipitation over almost all locations, the remaining six parameterizations tended to overestimate, particularly over China, southeast Asia, western United States, and central Africa. This method could be used by other researchers to help understand how the increasingly massive body of scientific literature can be harnessed through the power of artificial intelligence to solve their research problems.', 'abstract_zh': '大型语言模型为使用计算机进行密集任务提供了机会，实现了前所未有的研究机会。其中一个机会是系统地审查科学文献。在这里，我们展示了如何使用大型语言模型来构建与Weather and Research Forecasting (WRF)模型中的微物理参数化相关的2699篇出版物的文献综述，目的是学习它们在模拟降水时的应用及其系统偏差。数据库是通过对Web of Science和Scopus的搜索来识别出版物构建的。使用大型语言模型GPT-4 Turbo从2699篇出版物的文本中提取有关模型配置和性能的信息。我们的结果揭示了九种最受欢迎的微物理参数化在全球范围内的使用情况：Lin、Ferrier、WRF单 moment、Goddard积云集合、Morrison、Thompson和WRF双 moment。在2020年之前，更多的研究使用了一 moment 参数化，在2020年之后则更多地使用了两 moment 参数化。九个参数化中有七个倾向于高估降水。然而，参数化的系统偏差在不同地区有所不同。除使用Lin、Ferrier和Goddard参数化模拟在全球几乎所有地区都倾向于低估降水外，其余六个参数化则倾向于在诸如中国、东南亚、美国西部和中非等地高估降水。这种方法可以供其他研究人员使用，通过人工智能的力量帮助他们理解如何利用日益庞大的科学文献解决研究问题。', 'title_zh': '使用大型语言模型生成文献综述：2699篇出版物中微物理参数化方法的用途及系统性偏差'}
{'arxiv_id': 'arXiv:2503.21272', 'title': 'Reinforced Model Merging', 'authors': 'Jiaqi Han, Jingwen Ye, Shunyu Liu, Haofei Zhang, Jie Song, Zunlei Feng, Mingli Song', 'link': 'https://arxiv.org/abs/2503.21272', 'abstract': 'The success of large language models has garnered widespread attention for model merging techniques, especially training-free methods which combine model capabilities within the parameter space. However, two challenges remain: (1) uniform treatment of all parameters leads to performance degradation; (2) search-based algorithms are often inefficient. In this paper, we present an innovative framework termed Reinforced Model Merging (RMM), which encompasses an environment and agent tailored for merging tasks. These components interact to execute layer-wise merging actions, aiming to search the optimal merging architecture. Notably, RMM operates without any gradient computations on the original models, rendering it feasible for edge devices. Furthermore, by utilizing data subsets during the evaluation process, we addressed the bottleneck in the reward feedback phase, thereby accelerating RMM by up to 100 times. Extensive experiments demonstrate that RMM achieves state-of-the-art performance across various vision and NLP datasets and effectively overcomes the limitations of the existing baseline methods. Our code is available at this https URL.', 'abstract_zh': '大型语言模型的成功引起了对模型合并技术的广泛关注，尤其是无需训练的结合模型能力的方法。然而，仍存在两个挑战：（1）所有参数的统一处理会导致性能下降；（2）基于搜索的算法往往效率低下。本文提出了一种名为Reinforced Model Merging (RMM)的创新框架，该框架包含为合并任务量身定制的环境和智能体。这些组件交互执行逐层合并操作，以搜索最优的合并架构。值得注意的是，RMM不进行原模型的任何梯度计算，使其适用于边缘设备。此外，通过在评估过程中使用数据子集，我们解决了奖励反馈阶段的瓶颈，从而使RMM提速高达100倍。广泛实验表明，RMM在各种视觉和自然语言处理数据集上取得了最先进的性能，并有效克服了现有基线方法的局限性。我们的代码可在以下链接获取。', 'title_zh': '强化模型融合'}
{'arxiv_id': 'arXiv:2503.20950', 'title': 'DEMENTIA-PLAN: An Agent-Based Framework for Multi-Knowledge Graph Retrieval-Augmented Generation in Dementia Care', 'authors': 'Yutong Song, Chenhan Lyu, Pengfei Zhang, Sabine Brunswicker, Nikil Dutt, Amir Rahmani', 'link': 'https://arxiv.org/abs/2503.20950', 'abstract': 'Mild-stage dementia patients primarily experience two critical symptoms: severe memory loss and emotional instability. To address these challenges, we propose DEMENTIA-PLAN, an innovative retrieval-augmented generation framework that leverages large language models to enhance conversational support. Our model employs a multiple knowledge graph architecture, integrating various dimensional knowledge representations including daily routine graphs and life memory graphs. Through this multi-graph architecture, DEMENTIA-PLAN comprehensively addresses both immediate care needs and facilitates deeper emotional resonance through personal memories, helping stabilize patient mood while providing reliable memory support. Our notable innovation is the self-reflection planning agent, which systematically coordinates knowledge retrieval and semantic integration across multiple knowledge graphs, while scoring retrieved content from daily routine and life memory graphs to dynamically adjust their retrieval weights for optimized response generation. DEMENTIA-PLAN represents a significant advancement in the clinical application of large language models for dementia care, bridging the gap between AI tools and caregivers interventions.', 'abstract_zh': '轻度痴呆患者主要经历两种关键症状：严重的记忆力丧失和情绪不稳定。为应对这些挑战，我们提出DEMENTIA-PLAN，一种创新的检索增强生成框架，利用大型语言模型提高对话支持。该模型采用多知识图谱架构，整合了包括日常生活图和生活记忆图在内的多种维度的知识表示。通过这种多图架构，DEMENTIA-PLAN全面满足即时护理需求，并通过个人记忆加深情感共鸣，帮助稳定患者情绪，同时提供可靠的记忆支持。我们的重要创新是自省规划代理，该代理系统地协调跨多个知识图谱的知识检索和语义集成，并根据日常生活图和生活记忆图检索的内容为优化响应生成动态调整检索权重。DEMENTIA-PLAN代表了大型语言模型在痴呆护理临床应用中的重大进步，填补了人工智能工具与护理干预之间的差距。', 'title_zh': 'DEMENTIA-PLAN：一种用于痴呆护理中的多知识图谱检索增强生成的基于代理的框架'}
{'arxiv_id': 'arXiv:2503.21757', 'title': 'Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck', 'authors': 'Adrian Bulat, Yassine Ouali, Georgios Tzimiropoulos', 'link': 'https://arxiv.org/abs/2503.21757', 'abstract': 'In this work, we aim to compress the vision tokens of a Large Vision Language Model (LVLM) into a representation that is simultaneously suitable for (a) generative and (b) discriminative tasks, (c) is nearly lossless, and (d) is storage-efficient. We propose a novel compression approach, called Fwd2Bot, that uses the LVLM itself to compress the visual information in a task-agnostic manner. At the core of Fwd2bot there exists a "double-forward pass" training strategy, whereby, during the first forward pass, the LLM (of the LVLM) creates a bottleneck by condensing the visual information into a small number of summary tokens. Then, using the same LLM, the second forward pass processes the language instruction(s) alongside the summary tokens, used as a direct replacement for the image ones. The training signal is provided by two losses: an autoregressive one applied after the second pass that provides a direct optimization objective for compression, and a contrastive loss, applied after the first pass, that further boosts the representation strength, especially for discriminative tasks. The training is further enhanced by stage-specific adapters. We accompany the proposed method by an in-depth ablation study. Overall, Fwd2Bot results in highly-informative compressed representations suitable for both generative and discriminative tasks. For generative tasks, we offer a 2x higher compression rate without compromising the generative capabilities, setting a new state-of-the-art result. For discriminative tasks, we set a new state-of-the-art on image retrieval and compositionality.', 'abstract_zh': '本研究表明，我们旨在压缩大型视觉语言模型（LVLM）的视觉词嵌入，使其同时适用于生成和判别任务，并且几乎是无损的且存储效率高。我们提出了一种名为Fwd2Bot的新型压缩方法，该方法使用LVLM本身以任务无关的方式压缩视觉信息。Fwd2Bot的核心是“双前向传递”训练策略，在第一个前向传递中，LLM（LVLM的一部分）通过将视觉信息凝缩成少量摘要词嵌入来创建瓶颈。然后，在第二个前向传递中，使用相同的LLM处理语言指令和摘要词嵌入，后者作为图像词嵌入的直接替代。训练信号由两种损失构成：一种在第二个传递之后应用的自回归损失，提供压缩的直接优化目标，以及一种在第一个传递之后应用的对比损失，进一步增强表示强度，尤其是在判别任务方面。通过特定阶段的适配器进一步增强了训练性能。我们通过详尽的消融研究来支持所提出的方法。总体而言，Fwd2Bot产生了既适合生成任务也适合判别任务的高信息量压缩表示。对于生成任务，我们实现了2倍的压缩率而不牺牲生成能力，达到新的性能基准。对于判别任务，我们在图像检索和组合性方面达到了新的性能基准。', 'title_zh': 'Fwd2Bot: 基于双前向瓶颈的LVLM视觉词元压缩'}
{'arxiv_id': 'arXiv:2503.21735', 'title': 'GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics', 'authors': 'Arsham Gholamzadeh Khoee, Shuai Wang, Yinan Yu, Robert Feldt, Dhasarathy Parthasarathy', 'link': 'https://arxiv.org/abs/2503.21735', 'abstract': 'Ensuring the reliability and effectiveness of software release decisions is critical, particularly in safety-critical domains like automotive systems. Precise analysis of release validation data, often presented in tabular form, plays a pivotal role in this process. However, traditional methods that rely on manual analysis of extensive test datasets and validation metrics are prone to delays and high costs. Large Language Models (LLMs) offer a promising alternative but face challenges in analytical reasoning, contextual understanding, handling out-of-scope queries, and processing structured test data consistently; limitations that hinder their direct application in safety-critical scenarios. This paper introduces GateLens, an LLM-based tool for analyzing tabular data in the automotive domain. GateLens translates natural language queries into Relational Algebra (RA) expressions and then generates optimized Python code. It outperforms the baseline system on benchmarking datasets, achieving higher F1 scores and handling complex and ambiguous queries with greater robustness. Ablation studies confirm the critical role of the RA module, with performance dropping sharply when omitted. Industrial evaluations reveal that GateLens reduces analysis time by over 80% while maintaining high accuracy and reliability. As demonstrated by presented results, GateLens achieved high performance without relying on few-shot examples, showcasing strong generalization across various query types from diverse company roles. Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation. Results show that by automating test result analysis, GateLens enables faster, more informed, and dependable release decisions, and can thus advance software scalability and reliability in automotive systems.', 'abstract_zh': '确保软件发布决策的可靠性和有效性在诸如汽车系统这样的安全关键领域尤为重要。精确分析发布验证数据，通常以表格形式呈现，在这一过程中发挥着关键作用。然而，依赖手动分析大量测试数据集和验证指标的传统方法容易导致延误和高成本。大型语言模型（LLMs）提供了一种有希望的替代方案，但在分析推理、情境理解、处理范围外查询以及一致处理结构化测试数据方面面临挑战；这些限制阻碍了它们在安全关键场景中的直接应用。本文介绍了GateLens，这是一个基于LLM的汽车领域表格数据分析工具。GateLens将自然语言查询转换为关系代数（RA）表达式，并生成优化的Python代码。GateLens在基准测试数据集上的表现优于基线系统，实现更高的F1分数，并且在处理复杂和模糊查询时更具鲁棒性。消融研究证实了RA模块的至关重要性，将其省略会导致性能急剧下降。工业评估表明，GateLens将分析时间减少了80%以上，同时仍保持高度准确性和可靠性。通过对GateLens在合作伙伴汽车公司的部署结果进行展示，GateLens在各种类型查询中实现了良好的泛化能力，展示了其在不同公司角色中的强大应用潜力。通过GateLens自动化测试结果分析，工业应用表明GateLens能够更快、更准确、更可靠地做出发布决策，从而推动汽车系统软件的扩展性和可靠性。', 'title_zh': 'GateLens: 一种增强推理的汽车软件发布分析LLM代理'}
{'arxiv_id': 'arXiv:2503.21729', 'title': 'ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation', 'authors': 'Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li', 'link': 'https://arxiv.org/abs/2503.21729', 'abstract': "Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG).", 'abstract_zh': '增强事实性的推理模型：ReaRAG及其在多跳问答任务中的应用', 'title_zh': 'ReaRAG：迭代检索增强生成的知识指导推理提升大型推理模型的事实性'}
{'arxiv_id': 'arXiv:2503.21720', 'title': 'Collab: Controlled Decoding using Mixture of Agents for LLM Alignment', 'authors': 'Souradip Chakraborty, Sujay Bhatt, Udari Madhushani Sehwag, Soumya Suvra Ghosal, Jiahao Qiu, Mengdi Wang, Dinesh Manocha, Furong Huang, Alec Koppel, Sumitra Ganesh', 'link': 'https://arxiv.org/abs/2503.21720', 'abstract': 'Alignment of Large Language models (LLMs) is crucial for safe and trustworthy deployment in applications. Reinforcement learning from human feedback (RLHF) has emerged as an effective technique to align LLMs to human preferences and broader utilities, but it requires updating billions of model parameters, which is computationally expensive. Controlled Decoding, by contrast, provides a mechanism for aligning a model at inference time without retraining. However, single-agent decoding approaches often struggle to adapt to diverse tasks due to the complexity and variability inherent in these tasks. To strengthen the test-time performance w.r.t the target task, we propose a mixture of agent-based decoding strategies leveraging the existing off-the-shelf aligned LLM policies. Treating each prior policy as an agent in the spirit of mixture of agent collaboration, we develop a decoding method that allows for inference-time alignment through a token-level selection strategy among multiple agents. For each token, the most suitable LLM is dynamically chosen from a pool of models based on a long-term utility metric. This policy-switching mechanism ensures optimal model selection at each step, enabling efficient collaboration and alignment among LLMs during decoding. Theoretical analysis of our proposed algorithm establishes optimal performance with respect to the target task represented via a target reward for the given off-the-shelf models. We conduct comprehensive empirical evaluations with open-source aligned models on diverse tasks and preferences, which demonstrates the merits of this approach over single-agent decoding baselines. Notably, Collab surpasses the current SoTA decoding strategy, achieving an improvement of up to 1.56x in average reward and 71.89% in GPT-4 based win-tie rate.', 'abstract_zh': '多代理解码策略在大型语言模型对齐中的应用：增强目标任务的测试时性能', 'title_zh': 'Collab: 使用混合智能体进行控制解码以实现语言模型对齐'}
{'arxiv_id': 'arXiv:2503.21718', 'title': 'Outlier dimensions favor frequent tokens in language model', 'authors': 'Iuri Macocco, Nora Graichen, Gemma Boleda, Marco Baroni', 'link': 'https://arxiv.org/abs/2503.21718', 'abstract': 'We study last-layer outlier dimensions, this http URL that display extreme activations for the majority of inputs. We show that outlier dimensions arise in many different modern language models, and trace their function back to the heuristic of constantly predicting frequent words. We further show how a model can block this heuristic when it is not contextually appropriate, by assigning a counterbalancing weight mass to the remaining dimensions, and we investigate which model parameters boost outlier dimensions and when they arise during training. We conclude that outlier dimensions are a specialized mechanism discovered by many distinct models to implement a useful token prediction heuristic.', 'abstract_zh': '我们研究最后一层异常维度，这些维度对多数输入显示极端激活值。我们展示了异常维度在许多现代语言模型中出现，并将它们的功能追溯到频繁词预测的启发式方法。我们还展示了当该启发式方法在上下文中不适用时，模型可以通过给剩余维度分配平衡权重来阻止这种启发式方法。我们研究了哪些模型参数可以增强异常维度，并在训练过程中它们何时出现。我们得出结论，异常维度是许多不同模型发现的一种专门机制，用于实现有用的词预测启发式方法。', 'title_zh': '异常维度倾向于青睐语言模型中的常用词'}
{'arxiv_id': 'arXiv:2503.21598', 'title': 'Prompt, Divide, and Conquer: Bypassing Large Language Model Safety Filters via Segmented and Distributed Prompt Processing', 'authors': 'Johan Wahréus, Ahmed Hussain, Panos Papadimitratos', 'link': 'https://arxiv.org/abs/2503.21598', 'abstract': 'Large Language Models (LLMs) have transformed task automation and content generation across various domains while incorporating safety filters to prevent misuse. We introduce a novel jailbreaking framework that employs distributed prompt processing combined with iterative refinements to bypass these safety measures, particularly in generating malicious code. Our architecture consists of four key modules: prompt segmentation, parallel processing, response aggregation, and LLM-based jury evaluation. Tested on 500 malicious prompts across 10 cybersecurity categories, the framework achieves a 73.2% Success Rate (SR) in generating malicious code. Notably, our comparative analysis reveals that traditional single-LLM judge evaluation overestimates SRs (93.8%) compared to our LLM jury system (73.2%), with manual verification confirming that single-judge assessments often accept incomplete implementations. Moreover, we demonstrate that our distributed architecture improves SRs by 12% over the non-distributed approach in an ablation study, highlighting both the effectiveness of distributed prompt processing and the importance of robust evaluation methodologies in assessing jailbreak attempts.', 'abstract_zh': '大规模语言模型（LLMs）已在各种领域中转型任务自动化和内容生成，并包含安全过滤以防止误用。我们提出了一种新的脱束缚框架，该框架采用分布式提示处理结合迭代改进来绕过这些安全措施，特别是在生成恶意代码方面。该架构包括四个关键模块：提示分割、并行处理、响应聚合和基于LLM的陪审团评估。在10个网络安全类别下的500个恶意提示上进行测试，该框架在生成恶意代码方面实现了73.2%的成功率（SR）。值得注意的是，我们的对比分析表明，传统的单一LLM法官评估高估了成功率（93.8%），而我们的LLM陪审团系统为73.2%，人工验证确认单一法官评估经常接受不完整的实现。此外，我们展示在消融研究中，我们的分布式架构在不分布的方法上将成功率提高了12%，突显了分布式提示处理的有效性和稳健评估方法在评估脱束缚尝试中的重要性。', 'title_zh': '提示、分割与征服：通过分割和分布式提示处理规避大型语言模型安全过滤器'}
{'arxiv_id': 'arXiv:2503.21544', 'title': 'SWI: Speaking with Intent in Large Language Models', 'authors': 'Yuwei Yin, EunJeong Hwang, Giuseppe Carenini', 'link': 'https://arxiv.org/abs/2503.21544', 'abstract': "Intent, typically clearly formulated and planned, functions as a cognitive framework for reasoning and problem-solving. This paper introduces the concept of Speaking with Intent (SWI) in large language models (LLMs), where the explicitly generated intent encapsulates the model's underlying intention and provides high-level planning to guide subsequent analysis and communication. By emulating deliberate and purposeful thoughts in the human mind, SWI is hypothesized to enhance the reasoning capabilities and generation quality of LLMs. Extensive experiments on mathematical reasoning benchmarks consistently demonstrate the superiority of Speaking with Intent over Baseline (i.e., generation without explicit intent). Moreover, SWI outperforms answer-trigger prompting methods Chain-of-Thought and Plan-and-Solve and maintains competitive performance with the strong method ARR (Analyzing, Retrieving, and Reasoning). Additionally, the effectiveness and generalizability of SWI are solidified on reasoning-intensive question answering (QA) and text summarization benchmarks, where SWI brings consistent improvement to the Baseline generation. In text summarization, SWI-generated summaries exhibit greater accuracy, conciseness, and factual correctness, with fewer hallucinations. Furthermore, human evaluations verify the coherence, effectiveness, and interpretability of the intent produced by SWI. This proof-of-concept study creates a novel avenue for enhancing LLMs' reasoning abilities with cognitive notions.", 'abstract_zh': '意图，通常明确提出并计划好，作为推理和问题解决的认知框架。本文在大型语言模型（LLMs）中引入了“意图驱动说话”（Speaking with Intent，SWI）的概念，明确生成的意图体现在模型的底层意图中，并提供高层次规划以指导后续分析和沟通。通过模拟人类思维中的审慎和目的性思考，SWI 假设可以增强 LLM 的推理能力和生成质量。在数学推理基准测试中的大量实验一致表明，SWI 在推理能力方面优于基准方法（即没有明确意图的生成）。此外，SWI 在 Chain-of-Thought 和 Plan-and-Solve 回答触发提示方法中表现出优越性，并在强方法 ARR（分析、检索和推理）中保持了竞争力。在推理密集型问答（QA）和文本摘要基准测试中，SWI 也对基准生成带来了持续性的改进。在文本摘要中，SWI 生成的摘要表现出更高的精确度、简洁性和事实正确性，同时减少了幻觉现象。此外，人类评估证实了由 SWI 产生的意图的连贯性、有效性和可解释性。这一概念验证研究开辟了通过认知概念增强 LLM 推理能力的新途径。', 'title_zh': 'SWI: 用意而言在大型语言模型中'}
{'arxiv_id': 'arXiv:2503.21464', 'title': 'Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection', 'authors': 'Ryan Marinelli, Josef Pichlmeier, Tamas Bisztray', 'link': 'https://arxiv.org/abs/2503.21464', 'abstract': 'In this work, we propose a metric called Number of Thoughts (NofT) to determine the difficulty of tasks pre-prompting and support Large Language Models (LLMs) in production contexts. By setting thresholds based on the number of thoughts, this metric can discern the difficulty of prompts and support more effective prompt routing. A 2% decrease in latency is achieved when routing prompts from the MathInstruct dataset through quantized, distilled versions of Deepseek with 1.7 billion, 7 billion, and 14 billion parameters. Moreover, this metric can be used to detect adversarial prompts used in prompt injection attacks with high efficacy. The Number of Thoughts can inform a classifier that achieves 95% accuracy in adversarial prompt detection. Our experiments ad datasets used are available on our GitHub page: this https URL.', 'abstract_zh': '本研究提出了一种称为思维数量（Number of Thoughts, NoFT）的度量标准，以确定预提示任务的难度，并在大规模语言模型（LLMs）的生产环境中提供支持。通过基于思维数量设置阈值，该度量标准可以辨别提示的难度并支持更有效的提示路由。通过使用量化和精简后的Deepseek（参数分别为17亿、70亿和140亿）版本对MathInstruct数据集中的提示进行路由，实现了2%的延迟降低。此外，该度量标准可以高效地检测出用于提示注入攻击的对抗性提示。思维数量可以告知一个分类器，该分类器在对抗性提示检测中的准确率达到95%。我们的实验和所用数据集可在我们的GitHub页面上获取：this https URL。', 'title_zh': '利用链式思考元数据进行任务路由和对抗性提示检测'}
{'arxiv_id': 'arXiv:2503.21393', 'title': 'An evaluation of LLMs and Google Translate for translation of selected Indian languages via sentiment and semantic analyses', 'authors': 'Rohitash Chandra, Aryan Chaudhary, Yeshwanth Rayavarapu', 'link': 'https://arxiv.org/abs/2503.21393', 'abstract': 'Large Language models (LLMs) have been prominent for language translation, including low-resource languages. There has been limited study about the assessment of the quality of translations generated by LLMs, including Gemini, GPT and Google Translate. In this study, we address this limitation by using semantic and sentiment analysis of selected LLMs for Indian languages, including Sanskrit, Telugu and Hindi. We select prominent texts that have been well translated by experts and use LLMs to generate their translations to English, and then we provide a comparison with selected expert (human) translations. Our findings suggest that while LLMs have made significant progress in translation accuracy, challenges remain in preserving sentiment and semantic integrity, especially in figurative and philosophical contexts. The sentiment analysis revealed that GPT-4o and GPT-3.5 are better at preserving the sentiments for the Bhagavad Gita (Sanskrit-English) translations when compared to Google Translate. We observed a similar trend for the case of Tamas (Hindi-English) and Maha P (Telugu-English) translations. GPT-4o performs similarly to GPT-3.5 in the translation in terms of sentiments for the three languages. We found that LLMs are generally better at translation for capturing sentiments when compared to Google Translate.', 'abstract_zh': '大型语言模型（LLMs）在语言翻译中的应用包括低资源语言，但对其生成的翻译质量评估研究有限，包括Gemini、GPT和Google Translate。本研究通过使用对印度语种（包括梵语、泰卢固语和印地语）选定LLM的语义和情感分析，填补了这一空白。我们选择了由专家精心翻译的重要文本，并使用LLM生成其英语翻译，然后与选定的专家（人类）翻译进行比较。研究发现，尽管LLM在翻译准确性方面取得了显著进展，但在保留情感和语义完整性，尤其是在比喻和哲学语境中，仍面临挑战。情感分析显示，GPT-4o和GPT-3.5在维护《薄伽梵歌》（梵语-英语）翻译的情感方面优于Google Translate。类似的趋势也体现在泰卢固语-英语和印地语-英语的“Tamas”和“Maha P”翻译中。在三种语言的翻译情感方面，GPT-4o与GPT-3.5表现类似。我们发现，与Google Translate相比，LLM在捕捉情感方面通常表现更好。', 'title_zh': '基于情感和语义分析的LLM和Google Translate在翻译选定印度语言方面的评价'}
{'arxiv_id': 'arXiv:2503.21248', 'title': 'ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition', 'authors': 'Yujie Liu, Zonglin Yang, Tong Xie, Jinjie Ni, Ben Gao, Yuqiang Li, Shixiang Tang, Wanli Ouyang, Erik Cambria, Dongzhan Zhou', 'link': 'https://arxiv.org/abs/2503.21248', 'abstract': 'Large language models (LLMs) have demonstrated potential in assisting scientific research, yet their ability to discover high-quality research hypotheses remains unexamined due to the lack of a dedicated benchmark. To address this gap, we introduce the first large-scale benchmark for evaluating LLMs with a near-sufficient set of sub-tasks of scientific discovery: inspiration retrieval, hypothesis composition, and hypothesis ranking. We develop an automated framework that extracts critical components - research questions, background surveys, inspirations, and hypotheses - from scientific papers across 12 disciplines, with expert validation confirming its accuracy. To prevent data contamination, we focus exclusively on papers published in 2024, ensuring minimal overlap with LLM pretraining data. Our evaluation reveals that LLMs perform well in retrieving inspirations, an out-of-distribution task, suggesting their ability to surface novel knowledge associations. This positions LLMs as "research hypothesis mines", capable of facilitating automated scientific discovery by generating innovative hypotheses at scale with minimal human intervention.', 'abstract_zh': '大规模语言模型（LLMs）在辅助科学研究方面展现了潜在价值，但由于缺乏专门的基准，它们在发现高质量研究假设方面的能力尚未得到验证。为弥补这一空白，我们引入了首个大规模基准，用于评估LLMs的科学发现能力，该基准涵盖了科学研究发现的基本子任务：灵感检索、假设构建和假设排序。我们开发了一个自动化框架，从12个学科的科学论文中提取关键成分——研究问题、背景调查、灵感和假设，并通过专家验证确保其准确性。为防止数据污染，我们仅专注于2024年发表的论文，确保与LLM预训练数据的重叠最小化。评估结果显示，LLMs在检索灵感方面表现出色，这是一项分布外的任务，表明它们能够揭示新颖的知识关联。这使LLMs成为“研究假设矿”，能够在最小人类干预的情况下大规模生成创新性的假设，从而促进自动科学研究发现。', 'title_zh': 'ResearchBench: 基于灵感驱动任务分解的科学发现中大语言模型的基准测试'}
{'arxiv_id': 'arXiv:2503.21237', 'title': 'Bias-Aware Agent: Enhancing Fairness in AI-Driven Knowledge Retrieval', 'authors': 'Karanbir Singh, William Ngu', 'link': 'https://arxiv.org/abs/2503.21237', 'abstract': "Advancements in retrieving accessible information have evolved faster in the last few years compared to the decades since the internet's creation. Search engines, like Google, have been the number one way to find relevant data. They have always relied on the user's abilities to find the best information in its billions of links and sources at everybody's fingertips. The advent of large language models (LLMs) has completely transformed the field of information retrieval. The LLMs excel not only at retrieving relevant knowledge but also at summarizing it effectively, making information more accessible and consumable for users. On top of it, the rise of AI Agents has introduced another aspect to information retrieval i.e. dynamic information retrieval which enables the integration of real-time data such as weather forecasts, and financial data with the knowledge base to curate context-aware knowledge. However, despite these advancements the agents remain susceptible to issues of bias and fairness, challenges deeply rooted within the knowledge base and training of LLMs. This study introduces a novel approach to bias-aware knowledge retrieval by leveraging agentic framework and the innovative use of bias detectors as tools to identify and highlight inherent biases in the retrieved content. By empowering users with transparency and awareness, this approach aims to foster more equitable information systems and promote the development of responsible AI.", 'abstract_zh': '近年来，获取可访问信息的能力进步速度远远超过了互联网诞生以来的几十年。搜索引擎，如Google，一直是查找相关数据的主要方式。它们依赖用户的技能在 billions 个链接和来源中找到最好的信息。大型语言模型（LLMs）的出现彻底改变了信息检索领域。除了检索相关知识，LLMs 还能够有效地总结知识，使信息更加易于用户获取和消化。此外，AI代理的兴起为信息检索引入了另一个方面，即动态信息检索，这使得可以通过集成实时数据（如天气预报和金融数据）来更新知识库，从而创建上下文相关知识。然而，尽管取得了这些进展，代理仍容易受到偏见和公平性问题的影响，这些问题深深植根于知识库和LLMs的训练中。本研究通过利用代理框架和创新使用偏见检测工具来识别和突出显示检索内容中的固有偏见，提出了一个新颖的偏见意识知识检索方法。通过赋予用户透明度和意识，这种方法旨在促进更加公平的信息系统，并推动负责任的AI的发展。', 'title_zh': 'Awareness Bias Agent: 提升AI驱动知识检索中的公平性'}
{'arxiv_id': 'arXiv:2503.21098', 'title': 'Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search', 'authors': 'Yedan Shen, Kaixin Wu, Yuechen Ding, Jingyuan Wen, Hong Liu, Mingjie Zhong, Zhouhan Lin, Jia Xu, Linjian Mo', 'link': 'https://arxiv.org/abs/2503.21098', 'abstract': "Generative retrieval (GR) has revolutionized document retrieval with the advent of large language models (LLMs), and LLM-based GR is gradually being adopted by the industry. Despite its remarkable advantages and potential, LLM-based GR suffers from hallucination and generates documents that are irrelevant to the query in some instances, severely challenging its credibility in practical applications. We thereby propose an optimized GR framework designed to alleviate retrieval hallucination, which integrates knowledge distillation reasoning in model training and incorporate decision agent to further improve retrieval precision. Specifically, we employ LLMs to assess and reason GR retrieved query-document (q-d) pairs, and then distill the reasoning data as transferred knowledge to the GR model. Moreover, we utilize a decision agent as post-processing to extend the GR retrieved documents through retrieval model and select the most relevant ones from multi perspectives as the final generative retrieval result. Extensive offline experiments on real-world datasets and online A/B tests on Fund Search and Insurance Search in Alipay demonstrate our framework's superiority and effectiveness in improving search quality and conversion gains.", 'abstract_zh': '基于大规模语言模型的生成式检索优化框架：缓解检索幻觉并提高检索精度', 'title_zh': '缓解基于LLM的生成型检索幻觉以提高支付宝搜索效果'}
{'arxiv_id': 'arXiv:2503.21088', 'title': 'ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging', 'authors': 'Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang', 'link': 'https://arxiv.org/abs/2503.21088', 'abstract': "This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4: Unlearning Sensitive Content from Large Language Models. This task aims to selectively erase sensitive knowledge from large language models, avoiding both over-forgetting and under-forgetting issues. We propose an unlearning system that leverages Model Merging (specifically TIES-Merging), combining two specialized models into a more balanced unlearned model. Our system achieves competitive results, ranking second among 26 teams, with an online score of 0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we also conduct local experiments and perform a comprehensive analysis of the unlearning process, examining performance trajectories, loss dynamics, and weight perspectives, along with several supplementary experiments, to understand the effectiveness of our method. Furthermore, we analyze the shortcomings of our method and evaluation metrics, emphasizing that MIA scores and ROUGE-based metrics alone are insufficient to fully evaluate successful unlearning. Finally, we emphasize the need for more comprehensive evaluation methodologies and rethinking of unlearning objectives in future research. Code is available at this https URL.", 'abstract_zh': '本论文呈现了ZJUKLAB团队在SemEval-2025 Task 4：从大型语言模型中删除敏感内容提交的内容。本任务旨在从大型语言模型中选择性地删除敏感知识，避免遗忘过度和遗忘不足的问题。我们提出了一种利用Model Merging（具体为TIES-Merging）的未学习系统，将两个专门的模型合并为一个更加平衡的未学习模型。我们的系统取得了竞争性的结果，排名第二，26支队伍中在线得分为0.944（任务综合）和0.487（总体综合）。在本文中，我们还进行了局部实验，并对未学习过程进行了全面分析，考察了性能轨迹、损失动态和权重视角，以及几个补充实验，以了解我们方法的有效性。此外，我们分析了我们方法和评估指标的缺点，强调仅通过MIA得分和基于ROUGE的指标不足以全面评估成功的未学习。最后，我们强调了未来研究中需要更全面的评估方法和重新思考未学习目标的重要性。代码可在此链接处获取。', 'title_zh': 'ZJUKLAB在SemEval-2025任务4中的模型融合去学习'}
{'arxiv_id': 'arXiv:2503.21011', 'title': 'Can Large Language Models Predict Associations Among Human Attitudes?', 'authors': 'Ana Ma, Derek Powell', 'link': 'https://arxiv.org/abs/2503.21011', 'abstract': "Prior work has shown that large language models (LLMs) can predict human attitudes based on other attitudes, but this work has largely focused on predictions from highly similar and interrelated attitudes. In contrast, human attitudes are often strongly associated even across disparate and dissimilar topics. Using a novel dataset of human responses toward diverse attitude statements, we found that a frontier language model (GPT-4o) was able to recreate the pairwise correlations among individual attitudes and to predict individuals' attitudes from one another. Crucially, in an advance over prior work, we tested GPT-4o's ability to predict in the absence of surface-similarity between attitudes, finding that while surface similarity improves prediction accuracy, the model was still highly-capable of generating meaningful social inferences between dissimilar attitudes. Altogether, our findings indicate that LLMs capture crucial aspects of the deeper, latent structure of human belief systems.", 'abstract_zh': '前期研究显示，大规模语言模型 (LLMs) 可以根据其他态度预测人类态度，但这些研究主要集中在高度相似和相关态度的预测上。相比之下，人类态度常常在不相干和不相似的主题之间表现出强烈的相关性。利用一个关于人类对多样态度陈述的新型数据集，我们发现前沿语言模型 (GPT-4o) 能够重建各个态度之间的成对相关性，并从一个态度预测另一个态度。关键的是，与先前的工作相比，我们测试了 GPT-4o 在没有表面相似性的情况下进行预测的能力，发现尽管表面相似性提高了预测准确性，但该模型仍然能够有效地生成不相似态度之间的有意义的社会推断。整体来看，我们的研究结果表明，LLMs 捕捉到了人类信念系统深层、潜在结构的关键方面。', 'title_zh': '大规模语言模型能否预测人类态度之间的关联？'}
{'arxiv_id': 'arXiv:2503.20990', 'title': 'FinAudio: A Benchmark for Audio Large Language Models in Financial Applications', 'authors': 'Yupeng Cao, Haohang Li, Yangyang Yu, Shashidhar Reddy Javaji, Yueru He, Jimin Huang, Zining Zhu, Qianqian Xie, Xiao-yang Liu, Koduvayur Subbalakshmi, Meikang Qiu, Sophia Ananiadou, Jian-Yun Nie', 'link': 'https://arxiv.org/abs/2503.20990', 'abstract': 'Audio Large Language Models (AudioLLMs) have received widespread attention and have significantly improved performance on audio tasks such as conversation, audio understanding, and automatic speech recognition (ASR). Despite these advancements, there is an absence of a benchmark for assessing AudioLLMs in financial scenarios, where audio data, such as earnings conference calls and CEO speeches, are crucial resources for financial analysis and investment decisions. In this paper, we introduce \\textsc{FinAudio}, the first benchmark designed to evaluate the capacity of AudioLLMs in the financial domain. We first define three tasks based on the unique characteristics of the financial domain: 1) ASR for short financial audio, 2) ASR for long financial audio, and 3) summarization of long financial audio. Then, we curate two short and two long audio datasets, respectively, and develop a novel dataset for financial audio summarization, comprising the \\textsc{FinAudio} benchmark. Then, we evaluate seven prevalent AudioLLMs on \\textsc{FinAudio}. Our evaluation reveals the limitations of existing AudioLLMs in the financial domain and offers insights for improving AudioLLMs. All datasets and codes will be released.', 'abstract_zh': '音频大型语言模型（AudioLLMs）已在对话、音频理解和自动语音识别（ASR）等音频任务中受到了广泛关注并取得了显著的性能提升。然而，在金融场景中仍缺乏评估AudioLLMs的基准，而音频数据，如 earnings 会议和 CEO 演讲，对于金融分析和投资决策至关重要。本文介绍了第一个用于评估AudioLLMs在金融领域的能力的基准 \\textsc{FinAudio}。我们首先定义了三个基于金融领域特点的任务：1) 短金融音频的ASR，2) 长金融音频的ASR，3) 长金融音频的摘要。然后，我们分别收集了两个短和两个长音频数据集，并开发了一个新的金融音频摘要数据集，即 \\textsc{FinAudio} 基准。最后，我们在 \\textsc{FinAudio} 上评估了七种流行的 AudioLLMs。我们的评估揭示了现有 AudioLLMs 在金融领域中的局限性，并提供了改进 AudioLLMs 的见解。所有数据集和代码将开源。', 'title_zh': 'FinAudio: 金融应用中音频大型语言模型的标准benchmark'}
{'arxiv_id': 'arXiv:2503.20981', 'title': 'Patients Speak, AI Listens: LLM-based Analysis of Online Reviews Uncovers Key Drivers for Urgent Care Satisfaction', 'authors': 'Xiaoran Xu, Zhaoqian Xue, Chi Zhang, Jhonatan Medri, Junjie Xiong, Jiayan Zhou, Jin Jin, Yongfeng Zhang, Siyuan Ma, Lingyao Li', 'link': 'https://arxiv.org/abs/2503.20981', 'abstract': 'Investigating the public experience of urgent care facilities is essential for promoting community healthcare development. Traditional survey methods often fall short due to limited scope, time, and spatial coverage. Crowdsourcing through online reviews or social media offers a valuable approach to gaining such insights. With recent advancements in large language models (LLMs), extracting nuanced perceptions from reviews has become feasible. This study collects Google Maps reviews across the DMV and Florida areas and conducts prompt engineering with the GPT model to analyze the aspect-based sentiment of urgent care. We first analyze the geospatial patterns of various aspects, including interpersonal factors, operational efficiency, technical quality, finances, and facilities. Next, we determine Census Block Group(CBG)-level characteristics underpinning differences in public perception, including population density, median income, GINI Index, rent-to-income ratio, household below poverty rate, no insurance rate, and unemployment rate. Our results show that interpersonal factors and operational efficiency emerge as the strongest determinants of patient satisfaction in urgent care, while technical quality, finances, and facilities show no significant independent effects when adjusted for in multivariate models. Among socioeconomic and demographic factors, only population density demonstrates a significant but modest association with patient ratings, while the remaining factors exhibit no significant correlations. Overall, this study highlights the potential of crowdsourcing to uncover the key factors that matter to residents and provide valuable insights for stakeholders to improve public satisfaction with urgent care.', 'abstract_zh': '探究急診機構的公共体验对于促进社區醫療服務發展至為Important。透過Crowdsourcing線上評論或社交媒體獲取此類洞察具有重要價值。隨著大型語言模型（LLMs）的進展，從評論中提取微妙感知已成為可能。本研究收集DMV和佛羅里達地區的Google Maps評論，並使用GPT模型進行提示工程，分析急診服務的方面基 erotica情感。首先，我們分析了包括人際因素、運作效率、技術質量、財務和設施等方面的地理空間模式。隨後，我們確定不同人群感知差異的Sub Census區組（CBG）級別特性，包括人口密度、中位收入、基尼係數、租金與收入比、貧困家庭占比、無保险率和失業率。研究結果表明，在多變量模型中調整後，人際因素和運作效率是影響患者滿意度的最主要因素，而技術質量、財務和設施則未顯示出顯著的獨立影響。就社會經濟和人口統計因素而言，只有人口密度與患者評估顯示出顯著但微弱的關聯，而其他因素則無顯著相關性。總體而言，本研究突顯了Crowdsourcing的潛力，可用於發現對居民重要的關鍵因素，並為利益相關者提供寶貴的洞見，以提高公眾對急診服務的滿意度。', 'title_zh': '患者发声，AI倾听：基于LLM的在线评价分析揭示急診满意的关键驱动因素'}
{'arxiv_id': 'arXiv:2503.20914', 'title': 'D4R -- Exploring and Querying Relational Graphs Using Natural Language and Large Language Models -- the Case of Historical Documents', 'authors': 'Michel Boeglin, David Kahn, Josiane Mothe, Diego Ortiz, David Panzoli', 'link': 'https://arxiv.org/abs/2503.20914', 'abstract': "D4R is a digital platform designed to assist non-technical users, particularly historians, in exploring textual documents through advanced graphical tools for text analysis and knowledge extraction. By leveraging a large language model, D4R translates natural language questions into Cypher queries, enabling the retrieval of data from a Neo4J database. A user-friendly graphical interface allows for intuitive interaction, enabling users to navigate and analyse complex relational data extracted from unstructured textual documents. Originally designed to bridge the gap between AI technologies and historical research, D4R's capabilities extend to various other domains. A demonstration video and a live software demo are available.", 'abstract_zh': 'D4R是一个数字平台，旨在通过高级图形工具辅助非技术人员，特别是历史学家，探索文本文档中的文本分析和知识提取。利用大型语言模型，D4R将自然语言问题转换为Cypher查询，从而可以从Neo4J数据库中检索数据。一个用户友好的图形界面允许直观的交互，使用户能够导航和分析从非结构化文本文档中提取的复杂关系数据。最初设计用于弥合AI技术和历史研究之间的差距，D4R的能力扩展到其他众多领域。提供演示视频和现场软件演示。', 'title_zh': 'D4R —— 使用自然语言和大规模语言模型探索和查询关系图——以历史文件为例'}
{'arxiv_id': 'arXiv:2503.20807', 'title': 'Fundamental Safety-Capability Trade-offs in Fine-tuning Large Language Models', 'authors': 'Pin-Yu Chen, Han Shen, Payel Das, Tianyi Chen', 'link': 'https://arxiv.org/abs/2503.20807', 'abstract': 'Fine-tuning Large Language Models (LLMs) on some task-specific datasets has been a primary use of LLMs. However, it has been empirically observed that this approach to enhancing capability inevitably compromises safety, a phenomenon also known as the safety-capability trade-off in LLM fine-tuning. This paper presents a theoretical framework for understanding the interplay between safety and capability in two primary safety-aware LLM fine-tuning strategies, providing new insights into the effects of data similarity, context overlap, and alignment loss landscape. Our theoretical results characterize the fundamental limits of the safety-capability trade-off in LLM fine-tuning, which are also validated by numerical experiments.', 'abstract_zh': '大型语言模型（LLM）在某些任务特定数据集上的微调是LLM的主要用途之一。然而，经验上观察到，这种增强能力的方法不可避免地会牺牲安全性，这一现象在LLM微调中也被称为安全与能力之间的权衡。本文提出了一个理论框架，用于理解两种主要的安全意识LLM微调策略之间的相互作用，提供了关于数据相似性、上下文重叠和对齐损失景观影响的新见解。我们的理论结果界定了LLM微调中安全与能力权衡的基本限制，这些结果也得到了数值实验的验证。', 'title_zh': '大型语言模型微调中的基础安全能力权衡'}
{'arxiv_id': 'arXiv:2503.20804', 'title': 'AED: Automatic Discovery of Effective and Diverse Vulnerabilities for Autonomous Driving Policy with Large Language Models', 'authors': 'Le Qiu, Zelai Xu, Qixin Tan, Wenhao Tang, Chao Yu, Yu Wang', 'link': 'https://arxiv.org/abs/2503.20804', 'abstract': 'Assessing the safety of autonomous driving policy is of great importance, and reinforcement learning (RL) has emerged as a powerful method for discovering critical vulnerabilities in driving policies. However, existing RL-based approaches often struggle to identify vulnerabilities that are both effective-meaning the autonomous vehicle is genuinely responsible for the accidents-and diverse-meaning they span various failure types. To address these challenges, we propose AED, a framework that uses large language models (LLMs) to automatically discover effective and diverse vulnerabilities in autonomous driving policies. We first utilize an LLM to automatically design reward functions for RL training. Then we let the LLM consider a diverse set of accident types and train adversarial policies for different accident types in parallel. Finally, we use preference-based learning to filter ineffective accidents and enhance the effectiveness of each vulnerability. Experiments across multiple simulated traffic scenarios and tested policies show that AED uncovers a broader range of vulnerabilities and achieves higher attack success rates compared with expert-designed rewards, thereby reducing the need for manual reward engineering and improving the diversity and effectiveness of vulnerability discovery.', 'abstract_zh': '基于大规模语言模型的有效多样自主驾驶政策漏洞评估框架', 'title_zh': 'AED：使用大型语言模型自动发现有效的多样化自动驾驶政策漏洞'}
{'arxiv_id': 'arXiv:2503.20802', 'title': 'CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models', 'authors': 'Shuhao Zhang, Bo Cheng, Jiale Han, Yuli Chen, Zhixuan Wu, Changbao Li, Pingli Gu', 'link': 'https://arxiv.org/abs/2503.20802', 'abstract': 'Text watermarking provides an effective solution for identifying synthetic text generated by large language models. However, existing techniques often focus on satisfying specific criteria while ignoring other key aspects, lacking a unified evaluation. To fill this gap, we propose the Comprehensive Evaluation Framework for Watermark (CEFW), a unified framework that comprehensively evaluates watermarking methods across five key dimensions: ease of detection, fidelity of text quality, minimal embedding cost, robustness to adversarial attacks, and imperceptibility to prevent imitation or forgery. By assessing watermarks according to all these key criteria, CEFW offers a thorough evaluation of their practicality and effectiveness. Moreover, we introduce a simple and effective watermarking method called Balanced Watermark (BW), which guarantees robustness and imperceptibility through balancing the way watermark information is added. Extensive experiments show that BW outperforms existing methods in overall performance across all evaluation dimensions. We release our code to the community for future research. this https URL.', 'abstract_zh': '全面评估水印的框架：Text 水印为识别大型语言模型生成的合成文本提供了一种有效的解决方案。然而，现有技术往往专注于满足特定标准，而忽略了其他关键方面，缺乏统一的评估方法。为填补这一空白，我们提出了全面评估水印框架（CEFW），这是一种统一框架，可以全面从五个关键维度评估水印方法：检测的便捷性、文本质量的保真度、嵌入的最小成本、对抗攻击的鲁棒性以及不可感知性，以防止模仿或伪造。通过根据所有这些关键标准评估水印，CEFW 提供了对其实用性和效果的全面评估。此外，我们提出了一种简单有效的水印方法——平衡水印（BW），通过平衡水印信息的添加方式确保了鲁棒性和不可感知性。广泛实验表明，BW 在所有评估维度的整体性能上优于现有方法。我们向社区开源了我们的代码，供未来研究使用。', 'title_zh': 'CEFW：大规模语言模型中水印的全面评估框架'}
{'arxiv_id': 'arXiv:2503.20798', 'title': 'Payload-Aware Intrusion Detection with CMAE and Large Language Models', 'authors': 'Yongcheol Kim, Chanjae Lee, Young Yoon', 'link': 'https://arxiv.org/abs/2503.20798', 'abstract': 'Intrusion Detection Systems (IDS) are crucial for identifying malicious traffic, yet traditional signature-based methods struggle with zero-day attacks and high false positive rates. AI-driven packet-capture analysis offers a promising alternative. However, existing approaches rely heavily on flow-based or statistical features, limiting their ability to detect fine-grained attack patterns. This study proposes Xavier-CMAE, an enhanced Convolutional Multi-Head Attention Ensemble (CMAE) model that improves detection accuracy while reducing computational overhead. By replacing Word2Vec embeddings with a Hex2Int tokenizer and Xavier initialization, Xavier-CMAE eliminates pre-training, accelerates training, and achieves 99.971% accuracy with a 0.018% false positive rate, outperforming Word2Vec-based methods. Additionally, we introduce LLM-CMAE, which integrates pre-trained Large Language Model (LLM) tokenizers into CMAE. While LLMs enhance feature extraction, their computational cost hinders real-time detection. LLM-CMAE balances efficiency and performance, reaching 99.969% accuracy with a 0.019% false positive rate. This work advances AI-powered IDS by (1) introducing a payload-based detection framework, (2) enhancing efficiency with Xavier-CMAE, and (3) integrating LLM tokenizers for improved real-time detection.', 'abstract_zh': '基于AI的包捕获分析在入侵检测系统中的应用：Xavier-CMAE和LLM-CMAE模型的研究', 'title_zh': '基于CMAE和大语言模型的负载感知入侵检测'}
{'arxiv_id': 'arXiv:2503.20796', 'title': 'EXPLICATE: Enhancing Phishing Detection through Explainable AI and LLM-Powered Interpretability', 'authors': 'Bryan Lim, Roman Huerta, Alejandro Sotelo, Anthonie Quintela, Priyanka Kumar', 'link': 'https://arxiv.org/abs/2503.20796', 'abstract': 'Sophisticated phishing attacks have emerged as a major cybersecurity threat, becoming more common and difficult to prevent. Though machine learning techniques have shown promise in detecting phishing attacks, they function mainly as "black boxes" without revealing their decision-making rationale. This lack of transparency erodes the trust of users and diminishes their effective threat response. We present EXPLICATE: a framework that enhances phishing detection through a three-component architecture: an ML-based classifier using domain-specific features, a dual-explanation layer combining LIME and SHAP for complementary feature-level insights, and an LLM enhancement using DeepSeek v3 to translate technical explanations into accessible natural language. Our experiments show that EXPLICATE attains 98.4 % accuracy on all metrics, which is on par with existing deep learning techniques but has better explainability. High-quality explanations are generated by the framework with an accuracy of 94.2 % as well as a consistency of 96.8\\% between the LLM output and model prediction. We create EXPLICATE as a fully usable GUI application and a light Chrome extension, showing its applicability in many deployment situations. The research shows that high detection performance can go hand-in-hand with meaningful explainability in security applications. Most important, it addresses the critical divide between automated AI and user trust in phishing detection systems.', 'abstract_zh': '复杂的欺诈攻击已成为主要的网络安全威胁，变得越来越普遍且难以预防。尽管机器学习技术在检测欺诈攻击方面显示出潜力，但它们主要作为“黑盒”运作，不揭示其决策逻辑。这种透明度的缺乏侵蚀了用户的信任并减弱了他们有效的威胁响应。我们提出EXPLICATE：一种通过三组件架构增强欺诈检测的框架：基于领域特异性特征的机器学习分类器、结合LIME和SHAP的双解释层以提供互补的特征级洞见，以及使用DeepSeek v3增强语言模型以将技术解释转化为易懂的自然语言。我们的实验表明，EXPLICATE在所有指标上的准确率为98.4%，与现有的深度学习技术相当，但具有更好的可解释性。框架生成的高质量解释准确率为94.2%，模型预测与语言模型输出的一致性为96.8%。我们创建EXPLICATE为完整的图形用户界面应用程序和轻量级的Chrome扩展程序，显示其在多种部署情况下的适用性。该研究显示，在安全应用中，高性能检测可以与有意义的可解释性并存。最重要的是，它解决了自动AI和欺诈检测系统中用户信任之间的关键鸿沟。', 'title_zh': '增强钓鱼检测通过可解释AI和基于LLM的可解释性'}
