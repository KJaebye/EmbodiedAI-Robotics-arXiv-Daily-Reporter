{'arxiv_id': 'arXiv:2508.19236', 'title': 'MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation', 'authors': 'Hao Shi, Bin Xie, Yingfei Liu, Lin Sun, Fengrong Liu, Tiancai Wang, Erjin Zhou, Haoqiang Fan, Xiangyu Zhang, Gao Huang', 'link': 'https://arxiv.org/abs/2508.19236', 'abstract': 'Temporal context is essential for robotic manipulation because such tasks are inherently non-Markovian, yet mainstream VLA models typically overlook it and struggle with long-horizon, temporally dependent tasks. Cognitive science suggests that humans rely on working memory to buffer short-lived representations for immediate control, while the hippocampal system preserves verbatim episodic details and semantic gist of past experience for long-term memory. Inspired by these mechanisms, we propose MemoryVLA, a Cognition-Memory-Action framework for long-horizon robotic manipulation. A pretrained VLM encodes the observation into perceptual and cognitive tokens that form working memory, while a Perceptual-Cognitive Memory Bank stores low-level details and high-level semantics consolidated from it. Working memory retrieves decision-relevant entries from the bank, adaptively fuses them with current tokens, and updates the bank by merging redundancies. Using these tokens, a memory-conditioned diffusion action expert yields temporally aware action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on Bridge. On 12 real-world tasks spanning general skills and long-horizon temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon tasks showing a +26 improvement over state-of-the-art baseline. Project Page: this https URL', 'abstract_zh': '基于记忆的认知-记忆-行动框架：长期_horizon类机器manipulation方法', 'title_zh': 'MemoryVLA：视觉-语言-动作模型中的感知认知记忆及其在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2508.19199', 'title': 'Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation', 'authors': 'Alex LaGrassa, Zixuan Huang, Dmitry Berenson, Oliver Kroemer', 'link': 'https://arxiv.org/abs/2508.19199', 'abstract': 'Efficient planning in high-dimensional spaces, such as those involving deformable objects, requires computationally tractable yet sufficiently expressive dynamics models. This paper introduces a method that automatically generates task-specific, spatially adaptive dynamics models by learning which regions of the object require high-resolution modeling to achieve good task performance for a given planning query. Task performance depends on the complex interplay between the dynamics model, world dynamics, control, and task requirements. Our proposed diffusion-based model generator predicts per-region model resolutions based on start and goal pointclouds that define the planning query. To efficiently collect the data for learning this mapping, a two-stage process optimizes resolution using predictive dynamics as a prior before directly optimizing using closed-loop performance. On a tree-manipulation task, our method doubles planning speed with only a small decrease in task performance over using a full-resolution model. This approach informs a path towards using previous planning and control data to generate computationally efficient yet sufficiently expressive dynamics models for new tasks.', 'abstract_zh': '高效规划在高维空间中，特别是在涉及变形对象的空间中，需要具备在计算上可处理且足够表达力的动力学模型。本文介绍了一种方法，该方法通过学习哪些对象区域需要高分辨率建模来自动生成任务特定的空间自适应动力学模型，以实现给定规划查询的良好任务性能。任务性能取决于动力学模型、世界动力学、控制和任务需求之间的复杂相互作用。我们提出的基于扩散的模型生成器根据定义规划查询的起始和目标点云来预测每个区域模型的分辨率。为了高效地收集用于学习这种映射的数据，一个两阶段过程使用预测动力学作为先验来优化分辨率，然后再直接使用闭环性能进行优化。在树操作任务中，该方法在任务性能略有下降的情况下将规划速度提高了一倍。该方法为利用先前的规划和控制数据生成适用于新任务的计算上高效且足够表达的动力学模型指出了可能的路径。', 'title_zh': '基于规划-查询引导的模型生成方法在变形对象操作中的应用'}
{'arxiv_id': 'arXiv:2508.19172', 'title': 'From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity', 'authors': 'Luca Grillotti, Lisa Coiffard, Oscar Pang, Maxence Faldor, Antoine Cully', 'link': 'https://arxiv.org/abs/2508.19172', 'abstract': 'Autonomous skill discovery aims to enable robots to acquire diverse behaviors without explicit supervision. Learning such behaviors directly on physical hardware remains challenging due to safety and data efficiency constraints. Existing methods, including Quality-Diversity Actor-Critic (QDAC), require manually defined skill spaces and carefully tuned heuristics, limiting real-world applicability. We propose Unsupervised Real-world Skill Acquisition (URSA), an extension of QDAC that enables robots to autonomously discover and master diverse, high-performing skills directly in the real world. We demonstrate that URSA successfully discovers diverse locomotion skills on a Unitree A1 quadruped in both simulation and the real world. Our approach supports both heuristic-driven skill discovery and fully unsupervised settings. We also show that the learned skill repertoire can be reused for downstream tasks such as real-world damage adaptation, where URSA outperforms all baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios. Our results establish a new framework for real-world robot learning that enables continuous skill discovery with limited human intervention, representing a significant step toward more autonomous and adaptable robotic systems. Demonstration videos are available at this http URL .', 'abstract_zh': '自主技能发现旨在使机器人能够在没有显式监督的情况下获取多种行为。直接在物理硬件上学习这些行为由于安全性和数据效率的限制仍然具有挑战性。现有方法，包括质量-多样性的actor-critic（QDAC），需要手动定义技能空间并精细调谐启发式方法，这限制了其实用性。我们提出了无监督的现实世界技能获取（URSA），这是QDAC的一种扩展，使机器人能够自主地在真实世界中发现和掌握多种高性能技能。我们展示了URSA成功在仿真和现实世界中于Unitree A1四足机器人上发现了多样的运动技能。我们的方法支持基于启发式的技能发现和完全无监督的设置。我们还证明，学习到的技能集可以用于下游任务，如现实世界的损伤适应，在5种仿真和3种现实世界的损伤场景中，URSA在所有基线中表现最佳。我们的结果建立了一种新的框架，使机器人能够在有限的人工干预下实现持续技能发现，代表了更自主和适应性强的机器人系统的重要一步。视频演示可在以下链接查看。', 'title_zh': '从白板到 emergent 能力：通过实境无监督质量多样性发现机器人技能'}
{'arxiv_id': 'arXiv:2508.19153', 'title': 'QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning', 'authors': 'Allen Wang, Gavin Tao', 'link': 'https://arxiv.org/abs/2508.19153', 'abstract': 'We address vision-guided quadruped motion control with reinforcement learning (RL) and highlight the necessity of combining proprioception with vision for robust control. We propose QuadKAN, a spline-parameterized cross-modal policy instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates a spline encoder for proprioception and a spline fusion head for proprioception-vision inputs. This structured function class aligns the state-to-action mapping with the piecewise-smooth nature of gait, improving sample efficiency, reducing action jitter and energy consumption, and providing interpretable posture-action sensitivities. We adopt Multi-Modal Delay Randomization (MMDR) and perform end-to-end training with Proximal Policy Optimization (PPO). Evaluations across diverse terrains, including both even and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate that QuadKAN achieves consistently higher returns, greater distances, and fewer collisions than state-of-the-art (SOTA) baselines. These results show that spline-parameterized policies offer a simple, effective, and interpretable alternative for robust vision-guided locomotion. A repository will be made available upon acceptance.', 'abstract_zh': '基于视觉的 quadruped 运动控制with强化学习：结合本体感觉和视觉的重要性及 QuadKAN 方法', 'title_zh': 'QuadKAN: 通过端到端强化学习增强的四足运动控制'}
{'arxiv_id': 'arXiv:2508.19131', 'title': 'ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments', 'authors': 'Shreya Gummadi, Mateus V. Gasparino, Gianluca Capezzuto, Marcelo Becker, Girish Chowdhary', 'link': 'https://arxiv.org/abs/2508.19131', 'abstract': 'The advancement of robotics and autonomous navigation systems hinges on the ability to accurately predict terrain traversability. Traditional methods for generating datasets to train these prediction models often involve putting robots into potentially hazardous environments, posing risks to equipment and safety. To solve this problem, we present ZeST, a novel approach leveraging visual reasoning capabilities of Large Language Models (LLMs) to create a traversability map in real-time without exposing robots to danger. Our approach not only performs zero-shot traversability and mitigates the risks associated with real-world data collection but also accelerates the development of advanced navigation systems, offering a cost-effective and scalable solution. To support our findings, we present navigation results, in both controlled indoor and unstructured outdoor environments. As shown in the experiments, our method provides safer navigation when compared to other state-of-the-art methods, constantly reaching the final goal.', 'abstract_zh': '基于大型语言模型视觉推理的实时可通行性地图生成方法：提升机器人自主导航系统的安全与效率', 'title_zh': 'ZeST: 基于LLM的零样本未知环境可通行性导航'}
{'arxiv_id': 'arXiv:2508.19114', 'title': 'DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning', 'authors': 'Alkesh K. Srivastava, Jared Michael Levin, Alexander Derrico, Philip Dames', 'link': 'https://arxiv.org/abs/2508.19114', 'abstract': "We present DELIVER (Directed Execution of Language-instructed Item Via Engineered Relay), a fully integrated framework for cooperative multi-robot pickup and delivery driven by natural language commands. DELIVER unifies natural language understanding, spatial decomposition, relay planning, and motion execution to enable scalable, collision-free coordination in real-world settings. Given a spoken or written instruction, a lightweight instance of LLaMA3 interprets the command to extract pickup and delivery locations. The environment is partitioned using a Voronoi tessellation to define robot-specific operating regions. Robots then compute optimal relay points along shared boundaries and coordinate handoffs. A finite-state machine governs each robot's behavior, enabling robust execution. We implement DELIVER on the MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo simulations and real-world hardware using TurtleBot3 robots. Empirical results show that DELIVER maintains consistent mission cost across varying team sizes while reducing per-agent workload by up to 55% compared to a single-agent system. Moreover, the number of active relay agents remains low even as team size increases, demonstrating the system's scalability and efficient agent utilization. These findings underscore DELIVER's modular and extensible architecture for language-guided multi-robot coordination, advancing the frontiers of cyber-physical system integration.", 'abstract_zh': '基于工程化中继的定向执行语言指示项的框架：DELIVER多机器人拣取与配送协作系统', 'title_zh': 'DELIVER：一种基于 Voronoi 辅助接力规划的大型语言模型引导协同多机器人拣取与配送系统'}
{'arxiv_id': 'arXiv:2508.19074', 'title': 'An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees', 'authors': 'ZhenDong Chen, ZhanShang Nie, ShiXing Wan, JunYi Li, YongTian Cheng, Shuai Zhao', 'link': 'https://arxiv.org/abs/2508.19074', 'abstract': 'The Large Language Models (LLM) are increasingly being deployed in robotics to generate robot control programs for specific user tasks, enabling embodied intelligence. Existing methods primarily focus on LLM training and prompt design that utilize LLMs to generate executable programs directly from user tasks in natural language. However, due to the inconsistency of the LLMs and the high complexity of the tasks, such best-effort approaches often lead to tremendous programming errors in the generated code, which significantly undermines the effectiveness especially when the light-weight LLMs are applied. This paper introduces a natural-robotic language translation framework that (i) provides correctness verification for generated control programs and (ii) enhances the performance of LLMs in program generation via feedback-based fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is proposed to abstract away from the intricate details of the control programs, bridging the natural language tasks with the underlying robot skills. Then, the RSL compiler and debugger are constructed to verify RSL programs generated by the LLM and provide error feedback to the LLM for refining the outputs until being verified by the compiler. This provides correctness guarantees for the LLM-generated programs before being offloaded to the robots for execution, significantly enhancing the effectiveness of LLM-powered robotic applications. Experiments demonstrate NRTrans outperforms the existing method under a range of LLMs and tasks, and achieves a high success rate for light-weight LLMs.', 'abstract_zh': '大型语言模型在机器人中的自然-机器人语言翻译框架', 'title_zh': '基于LLM的具有正确性保证的自然语言到机器人语言翻译框架'}
{'arxiv_id': 'arXiv:2508.19002', 'title': 'HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots', 'authors': 'Shipeng Lyu, Fangyuan Wang, Weiwei Lin, Luhao Zhu, David Navarro-Alarcon, Guodong Guo', 'link': 'https://arxiv.org/abs/2508.19002', 'abstract': 'Achieving both behavioral similarity and appropriateness in human-like motion generation for humanoid robot remains an open challenge, further compounded by the lack of cross-embodiment adaptability. To address this problem, we propose HuBE, a bi-level closed-loop framework that integrates robot state, goal poses, and contextual situations to generate human-like behaviors, ensuring both behavioral similarity and appropriateness, and eliminating structural mismatches between motion generation and execution. To support this framework, we construct HPose, a context-enriched dataset featuring fine-grained situational annotations. Furthermore, we introduce a bone scaling-based data augmentation strategy that ensures millimeter-level compatibility across heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial platforms demonstrate that HuBE significantly improves motion similarity, behavioral appropriateness, and computational efficiency over state-of-the-art baselines, establishing a solid foundation for transferable and human-like behavior execution across diverse humanoid robots.', 'abstract_zh': '实现类人机器人动作生成中行为相似性与适宜性的兼得仍是一项开放性挑战，进一步受到跨实体适应性不足的制约。为应对这一问题，我们提出了一种两层闭环框架HuBE，该框架整合了机器人状态、目标姿态和情境信息，以生成类人行为，确保行为相似性和适宜性，并消除动作生成与执行之间的结构不匹配。为支持该框架，我们构建了HPose，这是一个富含细粒度情境注释的数据集。此外，我们引入了一种基于骨骼比例的数据增强策略，确保不同种类类人机器人在毫米级上的兼容性。在多个商业平台上的全面评估表明，HuBE在动作相似性、行为适宜性和计算效率方面显著优于最新基线方法，为跨多种类人机器人的可迁移和类人行为执行奠定了坚实基础。', 'title_zh': 'HuBE: 具有类人行为执行的人形机器人跨形态人类行为处理'}
{'arxiv_id': 'arXiv:2508.18817', 'title': 'Learning Real-World Acrobatic Flight from Human Preferences', 'authors': 'Colin Merk, Ismail Geles, Jiaxu Xing, Angel Romero, Giorgia Ramponi, Davide Scaramuzza', 'link': 'https://arxiv.org/abs/2508.18817', 'abstract': 'Preference-based reinforcement learning (PbRL) enables agents to learn control policies without requiring manually designed reward functions, making it well-suited for tasks where objectives are difficult to formalize or inherently subjective. Acrobatic flight poses a particularly challenging problem due to its complex dynamics, rapid movements, and the importance of precise execution. In this work, we explore the use of PbRL for agile drone control, focusing on the execution of dynamic maneuvers such as powerloops. Building on Preference-based Proximal Policy Optimization (Preference PPO), we propose Reward Ensemble under Confidence (REC), an extension to the reward learning objective that improves preference modeling and learning stability. Our method achieves 88.4% of the shaped reward performance, compared to 55.2% with standard Preference PPO. We train policies in simulation and successfully transfer them to real-world drones, demonstrating multiple acrobatic maneuvers where human preferences emphasize stylistic qualities of motion. Furthermore, we demonstrate the applicability of our probabilistic reward model in a representative MuJoCo environment for continuous control. Finally, we highlight the limitations of manually designed rewards, observing only 60.7% agreement with human preferences. These results underscore the effectiveness of PbRL in capturing complex, human-centered objectives across both physical and simulated domains.', 'abstract_zh': '基于偏好的强化学习在敏捷无人机控制中的应用：从动力滚转等动态机动动作探索', 'title_zh': '基于人类偏好的真实世界杂技飞行学习'}
{'arxiv_id': 'arXiv:2508.18802', 'title': 'HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation', 'authors': 'Li Sun, Jiefeng Wu, Feng Chen, Ruizhe Liu, Yanchao Yang', 'link': 'https://arxiv.org/abs/2508.18802', 'abstract': 'Effective policy learning for robotic manipulation requires scene representations that selectively capture task-relevant environmental features. Current approaches typically employ task-agnostic representation extraction, failing to emulate the dynamic perceptual adaptation observed in human cognition. We present HyperTASR, a hypernetwork-driven framework that modulates scene representations based on both task objectives and the execution phase. Our architecture dynamically generates representation transformation parameters conditioned on task specifications and progression state, enabling representations to evolve contextually throughout task execution. This approach maintains architectural compatibility with existing policy learning frameworks while fundamentally reconfiguring how visual features are processed. Unlike methods that simply concatenate or fuse task embeddings with task-agnostic representations, HyperTASR establishes computational separation between task-contextual and state-dependent processing paths, enhancing learning efficiency and representational quality. Comprehensive evaluations in both simulation and real-world environments demonstrate substantial performance improvements across different representation paradigms. Through ablation studies and attention visualization, we confirm that our approach selectively prioritizes task-relevant scene information, closely mirroring human adaptive perception during manipulation tasks. The project website is at \\href{this https URL}{this http URL\\_projectpage}.', 'abstract_zh': '基于任务和执行阶段驱动的场景表示调节框架HyperTASR：有效实现机器人操作策略学习需要选择性捕捉与任务相关环境特征的场景表示。当前方法通常采用任务无关的表示提取，无法模拟人类认知中观察到的动力血压觉适应。', 'title_zh': 'HyperTASR: 基于超网络的任务感知场景表示以实现稳健操作'}
{'arxiv_id': 'arXiv:2508.18705', 'title': 'Enhancing Video-Based Robot Failure Detection Using Task Knowledge', 'authors': 'Santosh Thoduka, Sebastian Houben, Juergen Gall, Paul G. Plöger', 'link': 'https://arxiv.org/abs/2508.18705', 'abstract': 'Robust robotic task execution hinges on the reliable detection of execution failures in order to trigger safe operation modes, recovery strategies, or task replanning. However, many failure detection methods struggle to provide meaningful performance when applied to a variety of real-world scenarios. In this paper, we propose a video-based failure detection approach that uses spatio-temporal knowledge in the form of the actions the robot performs and task-relevant objects within the field of view. Both pieces of information are available in most robotic scenarios and can thus be readily obtained. We demonstrate the effectiveness of our approach on three datasets that we amend, in part, with additional annotations of the aforementioned task-relevant knowledge. In light of the results, we also propose a data augmentation method that improves performance by applying variable frame rates to different parts of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the ARMBench dataset without additional computational expense and an additional increase to 81.4 with test-time augmentation. The results emphasize the importance of spatio-temporal information during failure detection and suggest further investigation of suitable heuristics in future implementations. Code and annotations are available.', 'abstract_zh': '基于视频的时空信息在机器人任务执行故障检测中的应用：一种稳健的机器人任务执行依赖于故障的可靠检测以触发安全操作模式、恢复策略或任务重新规划。然而，许多故障检测方法在应用于各种现实场景时难以提供有意义的性能。本文提出了一种基于视频的故障检测方法，利用机器人执行的动作和视野内的任务相关物体的时空知识。这两类信息在大多数机器人场景中均可获得，因此可以轻松获取。我们通过添加对上述任务相关知识的额外标注，在三个数据集上展示了该方法的有效性。基于实验结果，我们还提出了一种数据增强方法，通过不同的视频部分应用可变帧率以提高性能。在不增加额外计算成本的情况下，ARMBench数据集的F1分数从77.9提高到80.0，进一步通过测试时数据增强提高到81.4。这些结果强调了在故障检测过程中时空信息的重要性，并建议在未来实现中进一步研究合适的启发式方法。代码和标注已公开。', 'title_zh': '基于任务知识增强视频引导的机器人故障检测'}
{'arxiv_id': 'arXiv:2508.18691', 'title': 'Deep Sensorimotor Control by Imitating Predictive Models of Human Motion', 'authors': 'Himanshu Gaurav Singh, Pieter Abbeel, Jitendra Malik, Antonio Loquercio', 'link': 'https://arxiv.org/abs/2508.18691', 'abstract': 'As the embodiment gap between a robot and a human narrows, new opportunities arise to leverage datasets of humans interacting with their surroundings for robot learning. We propose a novel technique for training sensorimotor policies with reinforcement learning by imitating predictive models of human motions. Our key insight is that the motion of keypoints on human-inspired robot end-effectors closely mirrors the motion of corresponding human body keypoints. This enables us to use a model trained to predict future motion on human data \\emph{zero-shot} on robot data. We train sensorimotor policies to track the predictions of such a model, conditioned on a history of past robot states, while optimizing a relatively sparse task reward. This approach entirely bypasses gradient-based kinematic retargeting and adversarial losses, which limit existing methods from fully leveraging the scale and diversity of modern human-scene interaction datasets. Empirically, we find that our approach can work across robots and tasks, outperforming existing baselines by a large margin. In addition, we find that tracking a human motion model can substitute for carefully designed dense rewards and curricula in manipulation tasks. Code, data and qualitative results available at this https URL.', 'abstract_zh': '随着机器人与人类之间差距的缩小，利用人类与环境交互的数据集训练机器人学习的新机遇应运而生。我们提出了一种通过模仿人类运动预测模型来训练传感器运动策略的新技术。我们的核心洞察是，受人类启发的机器人末端执行器的关键点运动与对应的人体关键点运动高度相似，这使得我们可以在不进行微调的情况下，利用训练好的预测未来运动的人类数据模型直接应用于机器人数据中。我们训练传感器运动策略，使其在历史机器人状态的条件下追踪该模型的预测，同时优化相对稀疏的任务奖励。这种方法完全绕过了基于梯度的动力学重新定位和对抗损失，从而使得现有方法能够充分利用现代人类场景交互数据集的规模和多样性。实验结果显示，我们的方法在不同机器人和任务中表现出色，显著优于现有基线。此外，我们发现，跟踪人类运动模型可以在操纵任务中替代精心设计的密集奖励和课程设置。相关代码、数据和定性结果可在以下链接获取。', 'title_zh': '深度传感器运动控制：人类运动预测模型的模仿'}
{'arxiv_id': 'arXiv:2508.18606', 'title': 'SignLoc: Robust Localization using Navigation Signs and Public Maps', 'authors': 'Nicky Zimmerman, Joel Loo, Ayush Agrawal, David Hsu', 'link': 'https://arxiv.org/abs/2508.18606', 'abstract': 'Navigation signs and maps, such as floor plans and street maps, are widely available and serve as ubiquitous aids for way-finding in human environments. Yet, they are rarely used by robot systems. This paper presents SignLoc, a global localization method that leverages navigation signs to localize the robot on publicly available maps -- specifically floor plans and OpenStreetMap (OSM) graphs--without prior sensor-based mapping. SignLoc first extracts a navigation graph from the input map. It then employs a probabilistic observation model to match directional and locational cues from the detected signs to the graph, enabling robust topo-semantic localization within a Monte Carlo framework. We evaluated SignLoc in diverse large-scale environments: part of a university campus, a shopping mall, and a hospital complex. Experimental results show that SignLoc reliably localizes the robot after observing only one to two signs.', 'abstract_zh': '基于导航标志的全球定位方法SignLoc：在公开地图上利用导航标志进行无需先验传感器建图的机器人全局定位', 'title_zh': 'SignLoc: 基于导航标志和公共地图的鲁棒定位方法'}
{'arxiv_id': 'arXiv:2508.18460', 'title': 'Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models', 'authors': 'Tianze Liu, Md Abu Bakr Siddique, Hongyu An', 'link': 'https://arxiv.org/abs/2508.18460', 'abstract': 'Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable prowess across various cognitive tasks using extensive training data. However, the reliance on large datasets and neural networks presents challenges such as highpower consumption and limited adaptability, particularly in SWaP-constrained applications like planetary exploration. To address these issues, we propose enhancing the autonomous capabilities of intelligent robots by emulating the associative learning observed in animals. Associative learning enables animals to adapt to their environment by memorizing concurrent events. By replicating this mechanism, neuromorphic robots can navigate dynamic environments autonomously, learning from interactions to optimize performance. This paper explores the emulation of associative learning in rodents using neuromorphic robots within open-field maze environments, leveraging insights from spatial cells such as place and grid cells. By integrating these models, we aim to enable online associative learning for spatial tasks in real-time scenarios, bridging the gap between biological spatial cognition and robotics for advancements in autonomous systems.', 'abstract_zh': '基于数据驱动的人工智能方法在认知任务中表现出色，尤其是在大量训练数据的支持下。然而，对大数据集和神经网络的依赖带来了高能耗和适应性有限的问题，特别是在受SWaP约束的应用如行星探索中。为了解决这些问题，我们提出通过模拟动物观察到的关联学习机制来增强智能机器人的自主能力。关联学习使动物能够通过记忆并发事件来适应环境。通过复制这一机制，神经形态机器人可以在动态环境中自主导航，并从互动中学习以优化性能。本文探讨了在开放场迷宫环境中使用神经形态机器人模拟啮齿类动物的关联学习，借鉴了空间细胞如地点细胞和网格细胞的见解。通过整合这些模型，旨在实现实时场景中的空间任务的在线关联学习，从而在生物空间认知和机器人技术之间架起桥梁，促进自主系统的发展。', 'title_zh': '基于空间细胞模型的神经形态机器人在开放场迷宫中模仿rats的关联学习'}
{'arxiv_id': 'arXiv:2508.18397', 'title': 'Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning', 'authors': 'Antonio Guillen-Perez', 'link': 'https://arxiv.org/abs/2508.18397', 'abstract': 'Offline Reinforcement Learning (RL) presents a promising paradigm for training autonomous vehicle (AV) planning policies from large-scale, real-world driving logs. However, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe policies when using standard uniform data sampling. In this work, we address this challenge through a systematic, large-scale comparative study of data curation strategies designed to focus the learning process on information-rich samples. We investigate six distinct criticality weighting schemes which are categorized into three families: heuristic-based, uncertainty-based, and behavior-based. These are evaluated at two temporal scales, the individual timestep and the complete scenario. We train seven goal-conditioned Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based architecture and evaluate them in the high-fidelity Waymax simulator. Our results demonstrate that all data curation methods significantly outperform the baseline. Notably, data-driven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear trade-off where timestep-level weighting excels at reactive safety while scenario-level weighting improves long-horizon planning. Our work provides a comprehensive framework for data curation in Offline RL and underscores that intelligent, non-uniform sampling is a critical component for building safe and reliable autonomous agents.', 'abstract_zh': '基于离线强化学习的数据收集策略在自主车辆规划中的应用：一种有前景的方法及其实证研究', 'title_zh': '长尾效应的挖掘：自主运动规划中鲁棒离线强化学习的数据为中心的关键性指标比较研究'}
{'arxiv_id': 'arXiv:2508.18898', 'title': 'Interpretable Decision-Making for End-to-End Autonomous Driving', 'authors': 'Mona Mirzaie, Bodo Rosenhahn', 'link': 'https://arxiv.org/abs/2508.18898', 'abstract': 'Trustworthy AI is mandatory for the broad deployment of autonomous vehicles. Although end-to-end approaches derive control commands directly from raw data, interpreting these decisions remains challenging, especially in complex urban scenarios. This is mainly attributed to very deep neural networks with non-linear decision boundaries, making it challenging to grasp the logic behind AI-driven decisions. This paper presents a method to enhance interpretability while optimizing control commands in autonomous driving. To address this, we propose loss functions that promote the interpretability of our model by generating sparse and localized feature maps. The feature activations allow us to explain which image regions contribute to the predicted control command. We conduct comprehensive ablation studies on the feature extraction step and validate our method on the CARLA benchmarks. We also demonstrate that our approach improves interpretability, which correlates with reducing infractions, yielding a safer, high-performance driving model. Notably, our monocular, non-ensemble model surpasses the top-performing approaches from the CARLA Leaderboard by achieving lower infraction scores and the highest route completion rate, all while ensuring interpretability.', 'abstract_zh': '可信的人工智能对于自动驾驶车辆的广泛部署是必要的。尽管端到端方法可以直接从原始数据生成控制指令，但在复杂的城市场景中解释这些决策仍然具有挑战性。这主要是由于深度非线性决策边界，使得难以理解基于人工智能的决策逻辑。本文提出了一种方法，以优化控制指令的同时增强解释性。为此，我们提出了一种损失函数，通过生成稀疏且局部化的特征图促进模型的解释性。特征激活允许我们解释哪些图像区域对预测的控制指令做出了贡献。我们在特征提取步骤上进行了全面的消融研究，并在CARLA基准测试上验证了我们的方法。我们还证明，我们的方法提高了解释性，这与减少违规行为相关联，从而得到一个更安全且高性能的驾驶模型。值得注意的是，我们的单目非集成模型在CARLA排行榜上超越了表现最佳的方法，实现了更低的违规得分和最高的路线完成率，同时确保了解释性。', 'title_zh': '端到端自主驾驶的可解释决策-making'}
{'arxiv_id': 'arXiv:2508.19163', 'title': 'MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation', 'authors': 'Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, Katrina Mason, Mariane Melo, Tom Lawton, Yan Jia, Ibrahim Habli', 'link': 'https://arxiv.org/abs/2508.19163', 'abstract': 'Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents.\nMATRIX integrates three components: (1) a safety-aligned taxonomy of clinical scenarios, expected system behaviors and failure modes derived through structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator for detecting safety-relevant dialogue failures, validated against expert clinician annotations; and (3) PatBot, a simulated patient agent capable of producing diverse, scenario-conditioned responses, evaluated for realism and behavioral fidelity with human factors expertise, and a patient-preference study.\nAcross three experiments, we show that MATRIX enables systematic, scalable safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded assessment of 240 dialogues. We also conducted one of the first realism analyses of LLM-based patient simulation, showing that PatBot reliably simulates realistic patient behavior in quantitative and qualitative evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios and 10 clinical domains.\nMATRIX is the first framework to unify structured safety engineering with scalable, validated conversational AI evaluation, enabling regulator-aligned safety auditing. We release all evaluation tools, prompts, structured scenarios, and datasets.', 'abstract_zh': '尽管大型语言模型（LLMs）在临床对话系统中的应用日益增多，现有的评估主要集中在任务完成或流畅性上，缺乏对安全关键系统所需的行为和风险管理要求的深入洞察。本文提出了MATRIX（多代理仿真框架，用于安全交互和上下文临床对话评估），这是一个面向安全的临床对话代理评估的结构化、可扩展框架。', 'title_zh': 'MATRIX: 多智能体仿真框架以保障安全互动及上下文临床对话评估'}
{'arxiv_id': 'arXiv:2508.19005', 'title': 'Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark', 'authors': 'Yuxuan Cai, Yipeng Hao, Jie Zhou, Hang Yan, Zhikai Lei, Rui Zhen, Zhenhua Han, Yutao Yang, Junsong Li, Qianjun Pan, Tianyu Huai, Qin Chen, Xin Li, Kai Chen, Bo Zhang, Xipeng Qiu, Liang He', 'link': 'https://arxiv.org/abs/2508.19005', 'abstract': 'As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as "second nature".\nWe also introduce StuLife, a benchmark dataset for ELL that simulates a student\'s holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm shifts: From Passive to Proactive, From Context to Memory, and From Imitation to Learning. In this dynamic environment, agents must acquire and distill practical skills and maintain persistent memory to make decisions based on evolving state variables. StuLife provides a comprehensive platform for evaluating lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior. Beyond evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of context engineering in advancing AGI.', 'abstract_zh': '随着人工智能向通用智能发展，焦点正从优化静态任务的系统转向创建能够不断学习的开放性代理。本文介绍了经验驱动的终身学习（ELL）框架，该框架旨在通过实际互动构建自我进化代理以实现持续增长。该框架基于四个核心原则：（1）经验探索：代理通过持续的、自我驱动的与动态环境的互动学习，导航相互依赖的任务并生成丰富的经验轨迹。（2）长时记忆：代理保存并结构化历史知识，包括个人经验、领域专长和常识推理，并将其整合进持久记忆系统。（3）技能学习：代理通过从经验中抽象出重复模式来自主提升，并将这些技能主动改进和验证以应用于新任务。（4）知识内化：代理将显性和离散的经验内化为隐性和直观的能力，成为“第二本性”。我们还引入了StuLife基准数据集，模拟学生的全方位大学旅程，涵盖三个核心阶段和十个详细的子情境。StuLife围绕三大关键范式转变进行设计：从被动到主动、从环境到记忆、从模仿到学习。在这一动态环境中，代理必须获取并提炼实用技能，并维持持久记忆以根据不断变化的状态变量做出决策。StuLife提供了一个全面的平台，用于评估终身学习能力，包括记忆保留、技能迁移和自我驱动行为。除在StuLife基准上评估最先进的大语言模型外，我们还探讨了环境工程在推进AGI中的作用。', 'title_zh': '基于经验驱动的终生学习构建自我进化的智能体：一个框架与基准'}
{'arxiv_id': 'arXiv:2508.18812', 'title': 'STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning', 'authors': 'Chenghao Wu, Ruiyang Ren, Junjie Zhang, Ruirui Wang, Zhongrui Ma, Qi Ye, Wayne Xin Zhao', 'link': 'https://arxiv.org/abs/2508.18812', 'abstract': 'While modern recommender systems are instrumental in navigating information abundance, they remain fundamentally limited by static user modeling and reactive decision-making paradigms. Current large language model (LLM)-based agents inherit these shortcomings through their overreliance on heuristic pattern matching, yielding recommendations prone to shallow correlation bias, limited causal inference, and brittleness in sparse-data scenarios. We introduce STARec, a slow-thinking augmented agent framework that endows recommender systems with autonomous deliberative reasoning capabilities. Each user is modeled as an agent with parallel cognitions: fast response for immediate interactions and slow reasoning that performs chain-of-thought rationales. To cultivate intrinsic slow thinking, we develop anchored reinforcement training - a two-stage paradigm combining structured knowledge distillation from advanced reasoning models with preference-aligned reward shaping. This hybrid approach scaffolds agents in acquiring foundational capabilities (preference summarization, rationale generation) while enabling dynamic policy adaptation through simulated feedback loops. Experiments on MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves substantial performance gains compared with state-of-the-art baselines, despite using only 0.4% of the full training data.', 'abstract_zh': '虽然现代推荐系统在导航信息过剩方面不可或缺，但它们仍然受到静态用户建模和反应性决策范式的根本限制。基于大型语言模型（LLM）的代理继承了这些局限性，因为它们过度依赖启发式模式匹配，导致推荐易受浅层相关性偏差、有限的因果推理以及在稀疏数据场景下的脆弱性。我们引入了STARec，这是一种增强型慢思考代理框架，赋予推荐系统自主深思熟虑的推理能力。每个用户被建模为具有并行认知的代理：快速反应用于即时互动，而慢思考则执行链式推理。为了培养内在的慢思考，我们开发了基于锚定的强化训练——一种两阶段范式，结合了高级推理模型的结构化知识提炼与偏好对齐的奖励塑造。这种混合方法为代理提供了构建基础能力（偏好总结、推理生成）的机会，并通过模拟反馈循环实现动态策略适应。在MovieLens 1M和Amazon CDs基准测试上的实验表明，尽管只使用了完整训练数据的0.4%，STARec仍实现了显著的性能提升。', 'title_zh': 'STARec：一种基于自主 deliberate reasoning 的推荐系统高效代理框架'}
{'arxiv_id': 'arXiv:2508.18797', 'title': 'CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks', 'authors': 'Qi Chai, Zhang Zheng, Junlong Ren, Deheng Ye, Zichuan Lin, Hao Wang', 'link': 'https://arxiv.org/abs/2508.18797', 'abstract': 'Minecraft, as an open-world virtual interactive environment, has become a prominent platform for research on agent decision-making and execution. Existing works primarily adopt a single Large Language Model (LLM) agent to complete various in-game tasks. However, for complex tasks requiring lengthy sequences of actions, single-agent approaches often face challenges related to inefficiency and limited fault tolerance. Despite these issues, research on multi-agent collaboration remains scarce. In this paper, we propose CausalMACE, a holistic causality planning framework designed to enhance multi-agent systems, in which we incorporate causality to manage dependencies among subtasks. Technically, our proposed framework introduces two modules: an overarching task graph for global task planning and a causality-based module for dependency management, where inherent rules are adopted to perform causal intervention. Experimental results demonstrate our approach achieves state-of-the-art performance in multi-agent cooperative tasks of Minecraft.', 'abstract_zh': 'Minecraft作为开放世界虚拟交互环境，已成为研究代理决策与执行的重要平台。现有研究主要采用单一大型语言模型（LLM）代理完成各种游戏任务。然而，对于需要长时间序列动作的复杂任务，单一代理方法往往面临效率低下和有限容错率的挑战。尽管存在这些问题，关于多代理协作的研究仍然较少。在本文中，我们提出了一种整体因果规划框架CausalMACE，旨在增强多代理系统，在该框架中，我们将因果关系引入以管理子任务之间的依赖关系。技术上，我们提出的框架引入了两个模块：宏观任务图用于全局任务规划，以及基于因果关系的模块用于依赖管理，其中采用固有规则进行因果干预。实验结果表明，我们的方法在Minecraft多代理协作任务中达到了最先进的性能。', 'title_zh': '因果驱动的多智能体在 Minecraft 合作任务中'}
{'arxiv_id': 'arXiv:2508.18722', 'title': 'VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft', 'authors': 'Honghao Fu, Junlong Ren, Qi Chai, Deheng Ye, Yujun Cai, Hao Wang', 'link': 'https://arxiv.org/abs/2508.18722', 'abstract': 'Large language models (LLMs) have shown significant promise in embodied decision-making tasks within virtual open-world environments. Nonetheless, their performance is hindered by the absence of domain-specific knowledge. Methods that finetune on large-scale domain-specific data entail prohibitive development costs. This paper introduces VistaWise, a cost-effective agent framework that integrates cross-modal domain knowledge and finetunes a dedicated object detection model for visual analysis. It reduces the requirement for domain-specific training data from millions of samples to a few hundred. VistaWise integrates visual information and textual dependencies into a cross-modal knowledge graph (KG), enabling a comprehensive and accurate understanding of multimodal environments. We also equip the agent with a retrieval-based pooling strategy to extract task-related information from the KG, and a desktop-level skill library to support direct operation of the Minecraft desktop client via mouse and keyboard inputs. Experimental results demonstrate that VistaWise achieves state-of-the-art performance across various open-world tasks, highlighting its effectiveness in reducing development costs while enhancing agent performance.', 'abstract_zh': '大规模语言模型（LLMs）在虚拟开放世界环境中的 embodied 决策任务中展现了显著的潜力。然而，它们的表现受限于缺乏领域特定知识。依赖大规模领域特定数据的微调方法会导致高昂的开发成本。本文介绍了一种成本效益高的代理框架 VistaWise，该框架集成跨模态领域知识并为视觉分析微调专用的物体检测模型。VistaWise 将视觉信息和文本依赖性集成到跨模态知识图谱（KG）中，从而实现对多模态环境的全面和准确理解。此外，该代理还配备了基于检索的聚合策略以从 KG 中提取任务相关信息，并配备了桌面级技能库以通过鼠标和键盘操作 Minecraft 桌面客户端。实验结果表明，VistaWise 在各种开放世界任务中实现了最先进的性能，同时突显了其降低开发成本并提升代理性能的有效性。', 'title_zh': 'VistaWise: 构建基于跨模态知识图的经济高效代理用于Minecraft'}
{'arxiv_id': 'arXiv:2508.18689', 'title': 'AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance', 'authors': 'Yuyang Zhao, Wentao Shi, Fuli Feng, Xiangnan He', 'link': 'https://arxiv.org/abs/2508.18689', 'abstract': "Large language model (LLM)-based agents have demonstrated remarkable capabilities in addressing complex tasks, thereby enabling more advanced information retrieval and supporting deeper, more sophisticated human information-seeking behaviors. However, most existing agents operate in a purely reactive manner, responding passively to user instructions, which significantly constrains their effectiveness and efficiency as general-purpose platforms for information acquisition. To overcome this limitation, this paper proposes AppAgent-Pro, a proactive GUI agent system that actively integrates multi-domain information based on user instructions. This approach enables the system to proactively anticipate users' underlying needs and conduct in-depth multi-domain information mining, thereby facilitating the acquisition of more comprehensive and intelligent information. AppAgent-Pro has the potential to fundamentally redefine information acquisition in daily life, leading to a profound impact on human society. Our code is available at: this https URL. Our code is available at: this https URL. The demonstration video could be found at: this https URL.", 'abstract_zh': '基于大型语言模型（LLM）的代理展示了在处理复杂任务方面的能力，从而 enable 更高级的信息检索并支持更深入、更复杂的用户信息查询行为。然而，现有大多数代理以纯粹被动的方式运行，仅被动响应用户指令，这严重限制了它们作为通用信息获取平台的有效性和效率。为克服这一限制，本文提出 AppAgent-Pro，这是一种主动的图形用户界面代理系统，能够根据用户指令主动整合多领域信息。该方法使系统能够主动预见用户的潜在需求并进行深入的多领域信息挖掘，从而促进获取更为全面和智能的信息。AppAgent-Pro 有潜力从根本上重新定义日常生活中的信息获取，对人类社会产生深远影响。我们的代码可在以下链接获取：this https URL。我们的代码可在以下链接获取：this https URL。演示视频可在以下链接找到：this https URL。', 'title_zh': 'AppAgent-Pro: 一种主动式GUI代理系统，用于多域信息集成与用户辅助'}
{'arxiv_id': 'arXiv:2508.18669', 'title': 'MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use', 'authors': 'Weikang Zhao, Xili Wang, Chengdi Ma, Lingbin Kong, Zhaohua Yang, Mingxiang Tuo, Xiaowei Shi, Yitao Zhai, Xunliang Cai', 'link': 'https://arxiv.org/abs/2508.18669', 'abstract': "With the recent rapid advancement of Agentic Intelligence, agentic tool use in LLMs has become increasingly important. During multi-turn interactions between agents and users, the dynamic, uncertain, and stochastic nature of user demands poses significant challenges to the agent's tool invocation capabilities. Agents are no longer expected to simply call tools to deliver a result; rather, they must iteratively refine their understanding of user needs through communication while simultaneously invoking tools to resolve user queries. Existing reinforcement learning (RL) approaches for tool use lack the integration of genuinely dynamic users during the RL training process. To bridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use), a novel reinforcement learning framework that, for the first time in the field of agentic tool use, integrates LLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable autonomous learning of models to communicate with users efficiently and use various tools to solve practical problems in dynamic multi-turn interactions. Evaluations are done on several multi-turn tool-using benchmarks (see Figure 1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2 Airline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench Agent -- outperforming or matching the performance of larger open-source models such as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.", 'abstract_zh': '基于多轮交互的代理强化学习框架：MUA-RL（多轮用户交互代理强化学习）', 'title_zh': 'MUA-RL: 多轮用户交互智能体强化学习以实现自主工具使用'}
{'arxiv_id': 'arXiv:2508.18391', 'title': 'PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization', 'authors': 'Nitin Nagesh Kulkarni, Bryson Wilcox, Max Sawa, Jason Thom', 'link': 'https://arxiv.org/abs/2508.18391', 'abstract': 'Advancing AI systems in scientific domains like physics, materials science, and engineering calls for reasoning over complex, multi-physics phenomena while respecting governing principles. Although Large Language Models (LLMs) and existing preference optimization techniques perform well on standard benchmarks, they often struggle to differentiate between physically valid and invalid reasoning. This shortcoming becomes critical in high-stakes applications like metal joining, where seemingly plausible yet physically incorrect recommendations can lead to defects, material waste, equipment damage, and serious safety risks. To address this challenge, we introduce PKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with Direct Preference Optimization (DPO) to enforce physical validity in AI-generated outputs. PKG-DPO comprises three key components A) hierarchical physics knowledge graph that encodes cross-domain relationships, conservation laws, and thermodynamic principles. B) A physics reasoning engine that leverages structured knowledge to improve discrimination between physically consistent and inconsistent responses. C) A physics-grounded evaluation suite designed to assess compliance with domain-specific constraints. PKG-DPO achieves 17% fewer constraint violations and an 11% higher Physics Score compared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO demonstrates a 12\\% higher relevant parameter accuracy and a 7% higher quality alignment in reasoning accuracy. While our primary focus is on metal joining, the framework is broadly applicable to other multi-scale, physics-driven domains, offering a principled approach to embedding scientific constraints into preference learning.', 'abstract_zh': '提升物理学、材料科学和工程等科学领域中的AI系统要求在其推理过程中考虑复杂的多物理现象并遵守物理原理。尽管大规模语言模型（LLMs）和现有偏好优化技术在标准基准上表现良好，但它们往往难以区分物理上有效的和无效的推理。这一不足在金属连接等高风险应用中尤为重要，因为看似合理的但实际上是物理错误的建议可能导致缺陷、材料浪费、设备损坏和严重安全风险。为应对这一挑战，我们提出了一种新型框架PKG-DPO，该框架将物理知识图谱（PKGs）与直接偏好优化（DPO）相结合，以确保AI生成输出的物理有效性。PKG-DPO包含三个关键组件：A) 分层物理知识图谱，编码跨域关系、守恒定律和热力学原理；B) 物理推理引擎，利用结构化知识提高物理一致性和不一致性的区分能力；C) 以物理为基础的评估套件，用于评估遵守领域特定约束的情况。与基于知识图谱的DPO（KG-DPO）相比，PKG-DPO实现了17%的约束违规次数减少和11%的物理分数提升。此外，PKG-DPO在相关参数准确性方面提高了12%，在推理准确性方面提高了7%。虽然我们主要关注金属连接，但该框架适用于其他多尺度、物理驱动的领域，提供了一种将科学约束融入偏好学习的原理性方法。', 'title_zh': 'PKG-DPO：基于物理知识图谱和直接偏好优化的领域特定AI系统优化'}
{'arxiv_id': 'arXiv:2508.19150', 'title': 'Uncertainty-Resilient Active Intention Recognition for Robotic Assistants', 'authors': 'Juan Carlos Saborío, Marc Vinci, Oscar Lima, Sebastian Stock, Lennart Niecksch, Martin Günther, Alexander Sung, Joachim Hertzberg, Martin Atzmüller', 'link': 'https://arxiv.org/abs/2508.19150', 'abstract': 'Purposeful behavior in robotic assistants requires the integration of multiple components and technological advances. Often, the problem is reduced to recognizing explicit prompts, which limits autonomy, or is oversimplified through assumptions such as near-perfect information. We argue that a critical gap remains unaddressed -- specifically, the challenge of reasoning about the uncertain outcomes and perception errors inherent to human intention recognition. In response, we present a framework designed to be resilient to uncertainty and sensor noise, integrating real-time sensor data with a combination of planners. Centered around an intention-recognition POMDP, our approach addresses cooperative planning and acting under uncertainty. Our integrated framework has been successfully tested on a physical robot with promising results.', 'abstract_zh': '机器人助手中的目的性行为需要多个组件和科技的进步的集成。通常，该问题被简化为识别显式提示，这限制了自主性，或者通过近似完美的信息假设进行过度简化。我们argue认为一个关键的差距仍待解决——具体而言，就是关于人类意图识别固有的不确定结果和感知误差的推理挑战。为此，我们提出了一种框架，该框架设计用于应对不确定性，并结合了实时传感器数据与多种规划者的组合。围绕一个意图识别POMDP，我们的方法处理在不确定性下的协同规划和执行。我们的综合框架已在物理机器人上成功测试，并取得了令人鼓舞的结果。', 'title_zh': '面向服务机器人的具有不确定性鲁棒性的主动意图识别'}
{'arxiv_id': 'arXiv:2508.19072', 'title': 'Attackers Strike Back? Not Anymore - An Ensemble of RL Defenders Awakens for APT Detection', 'authors': 'Sidahmed Benabderrahmane, Talal Rahwan', 'link': 'https://arxiv.org/abs/2508.19072', 'abstract': "Advanced Persistent Threats (APTs) represent a growing menace to modern digital infrastructure. Unlike traditional cyberattacks, APTs are stealthy, adaptive, and long-lasting, often bypassing signature-based detection systems. This paper introduces a novel framework for APT detection that unites deep learning, reinforcement learning (RL), and active learning into a cohesive, adaptive defense system. Our system combines auto-encoders for latent behavioral encoding with a multi-agent ensemble of RL-based defenders, each trained to distinguish between benign and malicious process behaviors. We identify a critical challenge in existing detection systems: their static nature and inability to adapt to evolving attack strategies. To this end, our architecture includes multiple RL agents (Q-Learning, PPO, DQN, adversarial defenders), each analyzing latent vectors generated by an auto-encoder. When any agent is uncertain about its decision, the system triggers an active learning loop to simulate expert feedback, thus refining decision boundaries. An ensemble voting mechanism, weighted by each agent's performance, ensures robust final predictions.", 'abstract_zh': '高级持续威胁（APT）代表了对现代数字基础设施日益增长的威胁。本文介绍了一种将深度学习、强化学习（RL）和主动学习结合起来的新型框架，形成一个协调且适应性强的防御系统。系统结合了自编码器进行潜在行为编码，并采用基于RL的多方代表集合，每方专长于识别良性与恶意进程行为之间的区别。我们识别现有检测系统的关键挑战：它们的静态性质及其无法应对不断演化的攻击策略。为此，我们的架构包含了多个RL代理（Q学习、PPO、DQN，以及对抗性防御者），每个代理分析自编码器生成的潜在向量。当任何代理对其决策不确定时，系统将触发一个主动学习循环来模拟专家反馈，从而精化决策边界。采用基于每个代理性能加权的集成投票机制确保了稳健的最终预测。', 'title_zh': '攻击者反扑？不再了——强化学习防御者集结对抗APT检测'}
{'arxiv_id': 'arXiv:2508.18649', 'title': 'PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality', 'authors': 'Nanxi Li, Zhengyue Zhao, Chaowei Xiao', 'link': 'https://arxiv.org/abs/2508.18649', 'abstract': "Safeguarding vision-language models (VLMs) is a critical challenge, as existing methods often suffer from over-defense, which harms utility, or rely on shallow alignment, failing to detect complex threats that require deep reasoning. To this end, we introduce PRISM (Principled Reasoning for Integrated Safety in Multimodality), a system2-like framework that aligns VLMs by embedding a structured, safety-aware reasoning process. Our framework consists of two key components: PRISM-CoT, a dataset that teaches safety-aware chain-of-thought reasoning, and PRISM-DPO, generated via Monte Carlo Tree Search (MCTS) to further refine this reasoning through Direct Preference Optimization to help obtain a delicate safety boundary. Comprehensive evaluations demonstrate PRISM's effectiveness, achieving remarkably low attack success rates including 0.15% on JailbreakV-28K for Qwen2-VL and 90% improvement over the previous best method on VLBreak for LLaVA-1.5. PRISM also exhibits strong robustness against adaptive attacks, significantly increasing computational costs for adversaries, and generalizes effectively to out-of-distribution challenges, reducing attack success rates to just 8.70% on the challenging multi-image MIS benchmark. Remarkably, this robust defense is achieved while preserving, and in some cases enhancing, model utility. To promote reproducibility, we have made our code, data, and model weights available at this https URL.", 'abstract_zh': '保障多模态视觉-语言模型的安全是一项关键挑战，现有方法往往存在过度防护的问题，这损害了模型的实用性，或者依赖于浅层次的对齐，无法检测出需要深入推理的复杂威胁。为此，我们引入了PRISM（原理性的多模态集成安全性推理系统），这是一种以结构化、安全意识为导向的推理过程来对齐视觉-语言模型的系统框架。该框架包含两个关键组件：基于安全意识链式思维推理的教学数据集PRISM-CoT，以及通过蒙特卡洛树搜索（MCTS）生成的PRISM-DPO，后者通过直接偏好优化进一步细化这种推理过程，以帮助获得精细的安全边界。全面的评估表明，PRISM的有效性极高，在JailbreakV-28K测试集上Qwen2-VL的攻击成功率仅为0.15%，在VLBreak测试集上相对于此前的最佳方法，LLaVA-1.5的攻击成功率降低了90%。PRISM还表现出强大的对抗适应攻击鲁棒性，显著增加了对手的计算成本，并且能够有效泛化到分布外挑战，在具有挑战性的多图像MIS基准上将攻击成功率降低至8.70%。这一鲁棒性防御在保持模型实用性的同时，甚至在某些情况下提升了模型实用性。为了促进可重复性，我们已在如下链接提供了代码、数据和模型权重：[请根据实际情况填写链接]。', 'title_zh': 'PRISM: 原则性推理导向的鲁棒多模态VLM对齐以实现综合安全'}
{'arxiv_id': 'arXiv:2508.18474', 'title': 'DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection', 'authors': 'Bahareh Golchin, Banafsheh Rekabdar, Kunpeng Liu', 'link': 'https://arxiv.org/abs/2508.18474', 'abstract': 'Anomaly detection in time series data is important for applications in finance, healthcare, sensor networks, and industrial monitoring. Traditional methods usually struggle with limited labeled data, high false-positive rates, and difficulty generalizing to novel anomaly types. To overcome these challenges, we propose a reinforcement learning-based framework that integrates dynamic reward shaping, Variational Autoencoder (VAE), and active learning, called DRTA. Our method uses an adaptive reward mechanism that balances exploration and exploitation by dynamically scaling the effect of VAE-based reconstruction error and classification rewards. This approach enables the agent to detect anomalies effectively in low-label systems while maintaining high precision and recall. Our experimental results on the Yahoo A1 and Yahoo A2 benchmark datasets demonstrate that the proposed method consistently outperforms state-of-the-art unsupervised and semi-supervised approaches. These findings show that our framework is a scalable and efficient solution for real-world anomaly detection tasks.', 'abstract_zh': '时间序列数据中的异常检测对于金融、医疗、传感器网络和工业监测等领域至关重要。传统的异常检测方法通常面临标注数据有限、高误报率以及难以泛化到新的异常类型等挑战。为克服这些挑战，我们提出了一种基于强化学习的框架，该框架结合了动态奖励塑造、变分自编码器（VAE）和主动学习，称为DRTA。该方法采用自适应奖励机制，在动态调整基于VAE重构误差和分类奖励的影响下平衡探索和利用。这种方法使得代理能够在低标注系统中有效检测异常，同时保持高精确度和召回率。我们的实验结果表明，所提出的方法在Yahoo A1和Yahoo A2基准数据集上始终优于最先进的无监督和半监督方法。这些发现展示了我们的框架是一个适用于实际异常检测任务的可扩展且高效的解决方案。', 'title_zh': 'DRTA：时间序列异常检测中的动态奖励缩放方法'}
{'arxiv_id': 'arXiv:2508.18406', 'title': 'Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education', 'authors': 'Ryan Hare, Ying Tang', 'link': 'https://arxiv.org/abs/2508.18406', 'abstract': "One of the enduring challenges in education is how to empower students to take ownership of their learning by setting meaningful goals, tracking their progress, and adapting their strategies when faced with setbacks. Research has shown that this form of leaner-centered learning is best cultivated through structured, supportive environments that promote guided practice, scaffolded inquiry, and collaborative dialogue. In response, educational efforts have increasingly embraced artificial-intelligence (AI)-powered digital learning environments, ranging from educational apps and virtual labs to serious games. Recent advances in large language models (LLMs) and neuro-symbolic systems, meanwhile, offer a transformative opportunity to reimagine how support is delivered in digital learning environments. LLMs are enabling socially interactive learning experiences and scalable, cross-domain learning support that can adapt instructional strategies across varied subjects and contexts. In parallel, neuro-symbolic AI provides new avenues for designing these agents that are not only adaptive but also scalable across domains. Based on these remarks, this paper presents a multi-agent, neuro-symbolic framework designed to resolve the aforementioned challenges. The framework assigns distinct pedagogical roles to specialized agents: an RL-based 'tutor' agent provides authoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer' agent facilitates the social dimensions of learning. While prior work has explored such agents in isolation, our framework's novelty lies in unifying them through a central educational ontology. Through case studies in both college-level and middle school settings, we demonstrate the framework's adaptability across domains. We conclude by outlining key insights and future directions for advancing AI-driven learning environments.", 'abstract_zh': '一种持久的教学挑战是如何通过设定有意义的目标、跟踪学习进展并在遇到挫折时调整策略来赋予学生学习自主权。研究表明，这种以学生为中心的学习方式最好在结构化和支持性的环境中通过引导练习、支架式探究和协作对话来培养。为此，教育努力已越来越多地采用了基于人工智能（AI）的数字学习环境，包括教育应用程序、虚拟实验室和严肃游戏。与此同时，大型语言模型（LLMs）和神经符号系统的最新进展为重新构想数字学习环境中的支持方式提供了变革性机遇。大型语言模型使得能够提供社交互动的学习体验和能够在多种科目和情境下适应的教学策略的规模化支持。此外，神经符号AI为设计既适应性强又能够在多个领域中扩展的智能体提供了新途径。基于上述观点，本文提出了一种多智能体、神经符号框架，以解决上述挑战。该框架将不同的教学角色分配给专门的智能体：基于强化学习的“导师”智能体提供权威的非言语支架，而基于大型语言模型的主动性“同伴”智能体则促进学习的社会维度。尽管以往工作在孤立研究这些智能体方面取得了进展，但本文框架的独特之处在于通过核心教育本体将它们统一起来。通过大学和中学的案例研究，我们展示了该框架在多个领域中的适应性。最后，我们概述了有关人工智能驱动学习环境发展的关键见解和未来方向。', 'title_zh': '迈向通用自主智能体：一种结合社会和技术支持的神经符号AI框架在教育中的应用'}
{'arxiv_id': 'arXiv:2508.18337', 'title': 'EAI-Avatar: Emotion-Aware Interactive Talking Head Generation', 'authors': 'Haijie Yang, Zhenyu Zhang, Hao Tang, Jianjun Qian, Jian Yang', 'link': 'https://arxiv.org/abs/2508.18337', 'abstract': "Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose EAI-Avatar, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.", 'abstract_zh': '基于情绪感知的双向对话生成框架：EAI-Avatar', 'title_zh': 'EAI-Avatar: 感情意识的互动谈头生成'}
