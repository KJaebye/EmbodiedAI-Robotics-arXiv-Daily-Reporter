{'arxiv_id': 'arXiv:2503.20754', 'title': 'Flying Vines: Design, Modeling, and Control of a Soft Aerial Robotic Arm', 'authors': 'Rianna Jitosho, Crystal E. Winston, Shengan Yang, Jinxin Li, Maxwell Ahlquist, Nicholas John Woehrle, C. Karen Liu, Allison M. Okamura', 'link': 'https://arxiv.org/abs/2503.20754', 'abstract': 'Aerial robotic arms aim to enable inspection and environment interaction in otherwise hard-to-reach areas from the air. However, many aerial manipulators feature bulky or heavy robot manipulators mounted to large, high-payload aerial vehicles. Instead, we propose an aerial robotic arm with low mass and a small stowed configuration called a "flying vine". The flying vine consists of a small, maneuverable quadrotor equipped with a soft, growing, inflated beam as the arm. This soft robot arm is underactuated, and positioning of the end effector is achieved by controlling the coupled quadrotor-vine dynamics. In this work, we present the flying vine design and a modeling and control framework for tracking desired end effector trajectories. The dynamic model leverages data-driven modeling methods and introduces bilinear interpolation to account for time-varying dynamic parameters. We use trajectory optimization to plan quadrotor controls that produce desired end effector motions. Experimental results on a physical prototype demonstrate that our framework enables the flying vine to perform high-speed end effector tracking, laying a foundation for performing dynamic maneuvers with soft aerial manipulators.', 'abstract_zh': '基于飞行攀援臂的低质量空中机械臂设计及其控制框架研究', 'title_zh': '飞藤：软 aerial 机器人手臂的设计、建模与控制'}
{'arxiv_id': 'arXiv:2503.20723', 'title': 'Multi-Robot Coordination Under Physical Limitations', 'authors': 'Tohid Kargar Tasooji, Sakineh Khodadadi', 'link': 'https://arxiv.org/abs/2503.20723', 'abstract': 'Multi-robot coordination is fundamental to various applications, including autonomous exploration, search and rescue, and cooperative transportation. This paper presents an optimal consensus framework for multi-robot systems (MRSs) that ensures efficient rendezvous while minimizing energy consumption and addressing actuator constraints. A critical challenge in real-world deployments is actuator limitations, particularly wheel velocity saturation, which can significantly degrade control performance. To address this issue, we incorporate Pontryagin Minimum Principle (PMP) into the control design, facilitating constrained optimization while ensuring system stability and feasibility. The resulting optimal control policy effectively balances coordination efficiency and energy consumption, even in the presence of actuation constraints. The proposed framework is validated through extensive numerical simulations and real-world experiments conducted using a team of Robotarium mobile robots. The experimental results confirm that our control strategies achieve reliable and efficient coordinated rendezvous while addressing real-world challenges such as communication delays, sensor noise, and packet loss.', 'abstract_zh': '多机器人协调是多种应用的基础，包括自主探索、搜索与救援以及协同运输。本文提出了一种多机器人系统的最优共识框架，该框架确保高效会遇的同时最小化能量消耗并解决执行器约束问题。实际部署中的一个关键挑战是执行器限制，尤其是轮速饱和，这可能会显著降低控制性能。为解决这一问题，将庞特里亚金最小原理（PMP）纳入控制设计中，以实现约束优化并确保系统稳定性和可行性。所提出的最优控制策略即使在存在执行器约束的情况下也能有效地平衡协调效率和能量消耗。所提出框架通过使用Robotarium移动机器人的广泛数值仿真和真实世界实验进行验证。实验结果证实，我们的控制策略能够在通信延迟、传感器噪声和数据包丢失等实际问题面前实现可靠且高效的协同会遇。', 'title_zh': '物理限制下的多机器人协调'}
{'arxiv_id': 'arXiv:2503.20714', 'title': 'Beyond Visuals: Investigating Force Feedback in Extended Reality for Robot Data Collection', 'authors': 'Xueyin Li, Xinkai Jiang, Philipp Dahlinger, Gerhard Neumann, Rudolf Lioutikov', 'link': 'https://arxiv.org/abs/2503.20714', 'abstract': 'This work explores how force feedback affects various aspects of robot data collection within the Extended Reality (XR) setting. Force feedback has been proved to enhance the user experience in Extended Reality (XR) by providing contact-rich information. However, its impact on robot data collection has not received much attention in the robotics community. This paper addresses this shortcoming by conducting an extensive user study on the effects of force feedback during data collection in XR. We extended two XR-based robot control interfaces, Kinesthetic Teaching and Motion Controllers, with haptic feedback features. The user study is conducted using manipulation tasks ranging from simple pick-place to complex peg assemble, requiring precise operations. The evaluations show that force feedback enhances task performance and user experience, particularly in tasks requiring high-precision manipulation. These improvements vary depending on the robot control interface and task complexity. This paper provides new insights into how different factors influence the impact of force feedback.', 'abstract_zh': '本研究探讨了力反馈如何影响扩展现实（XR）环境中机器人数据收集的各个方面。力反馈已被证明可以通过提供丰富的接触信息来增强扩展现实（XR）中的用户体验。然而，力反馈对其它机器人数据收集的影响在机器人社区中尚未得到过多关注。本文通过在XR数据采集过程中进行广泛用户研究，来解决这一缺陷。我们扩展了两种基于XR的机器人控制接口——亲身体验教学和运动控制器——以包含触觉反馈功能。用户研究使用从简单拾放任务到复杂棋子组装任务的操作任务，这些任务要求高度精确的操作。评估结果表明，力反馈可以提高任务性能和用户体验，尤其是在需要高精度操作的任务中。这些改进因所使用的机器人控制接口和任务复杂度而异。本文提供了关于不同因素如何影响力反馈效果的新见解。', 'title_zh': '超越视觉：探究扩展现实中的力反馈在机器人数据收集中的应用'}
{'arxiv_id': 'arXiv:2503.20693', 'title': 'Toward Dynamic Control of Tendon-Driven Continuum Robots using Clarke Transform', 'authors': 'Christian Muhmann, Reinhard M. Grassmann, Max Bartholdt, Jessica Burgner-Kahrs', 'link': 'https://arxiv.org/abs/2503.20693', 'abstract': 'In this paper, we propose a dynamic model and control framework for tendon-driven continuum robots with multiple segments and an arbitrary number of tendons per segment. Our approach leverages the Clarke transform, the Euler-Lagrange formalism, and the piecewise constant curvature assumption to formulate a dynamic model on a two-dimensional manifold embedded in the joint space that inherently satisfies tendon constraints. We present linear controllers that operate directly on this manifold, along with practical methods for preventing negative tendon forces without compromising control fidelity. We validate these approaches in simulation and on a physical prototype with one segment and five tendons, demonstrating accurate dynamic behavior and robust trajectory tracking under real-time conditions.', 'abstract_zh': '本文提出了一种用于多段连续驱动机器人（每段具有任意数量肌腱）的动力学模型和控制框架。该方法采用克拉克变换、欧拉-拉格朗日形式主义和分段恒定曲率假设，在关节空间中嵌入的二维流形上构建动力学模型，该模型固有地满足肌腱约束条件。我们提出了直接在该流形上操作的线性控制器，并介绍了防止负肌腱力的方法，同时不牺牲控制精度。我们在仿真和一个段五肌腱的物理原型上验证了这些方法，在实时条件下实现了准确的动力学行为和稳健的轨迹跟踪。', 'title_zh': '基于克拉克变换的动态控制腱驱动连续机器人研究'}
{'arxiv_id': 'arXiv:2503.20631', 'title': 'Robust Flower Cluster Matching Using The Unscented Transform', 'authors': 'Andy Chu, Rashik Shrestha, Yu Gu, Jason N. Gross', 'link': 'https://arxiv.org/abs/2503.20631', 'abstract': "Monitoring flowers over time is essential for precision robotic pollination in agriculture. To accomplish this, a continuous spatial-temporal observation of plant growth can be done using stationary RGB-D cameras. However, image registration becomes a serious challenge due to changes in the visual appearance of the plant caused by the pollination process and occlusions from growth and camera angles. Plants flower in a manner that produces distinct clusters on branches. This paper presents a method for matching flower clusters using descriptors generated from RGB-D data and considers allowing for spatial uncertainty within the cluster. The proposed approach leverages the Unscented Transform to efficiently estimate plant descriptor uncertainty tolerances, enabling a robust image-registration process despite temporal changes. The Unscented Transform is used to handle the nonlinear transformations by propagating the uncertainty of flower positions to determine the variations in the descriptor domain. A Monte Carlo simulation is used to validate the Unscented Transform results, confirming our method's effectiveness for flower cluster matching. Therefore, it can facilitate improved robotics pollination in dynamic environments.", 'abstract_zh': '持续监测植物花朵对农业中的精准机器人授粉至关重要。为了实现这一目标，可以使用固定安装的RGB-D相机进行植物生长的连续时空观察。然而，由于授粉过程导致植物视觉外观变化以及生长引发的遮挡和相机角度等因素，图像配准成为了一个严重挑战。植物花朵会在枝条上形成独特的簇状结构。本文提出了一种基于RGB-D数据生成描述符匹配花朵簇的方法，并考虑了簇内部的时空不确定性。所提出的方法利用无迹变换高效估计植物描述符的不确定性容忍度，从而在时间变化的情况下实现稳健的图像配准。无迹变换通过传播花朵位置的不确定性以确定描述符域的变化来处理非线性变换。利用蒙特卡洛仿真验证了无迹变换的结果，确认了该方法在花朵簇匹配方面的有效性。因此，它能够促进动态环境中机器人授粉的改进。', 'title_zh': '使用无偏变换的鲁棒花卉簇匹配'}
{'arxiv_id': 'arXiv:2503.20544', 'title': 'Safety integrity framework for automated driving', 'authors': 'Moritz Werling, Rainer Faller, Wolfgang Betz, Daniel Straub', 'link': 'https://arxiv.org/abs/2503.20544', 'abstract': "This paper describes the comprehensive safety framework that underpinned the development, release process, and regulatory approval of BMW's first SAE Level 3 Automated Driving System. The framework combines established qualitative and quantitative methods from the fields of Systems Engineering, Engineering Risk Analysis, Bayesian Data Analysis, Design of Experiments, and Statistical Learning in a novel manner. The approach systematically minimizes the risks associated with hardware and software faults, performance limitations, and insufficient specifications to an acceptable level that achieves a Positive Risk Balance. At the core of the framework is the systematic identification and quantification of uncertainties associated with hazard scenarios and the redundantly designed system based on designed experiments, field data, and expert knowledge. The residual risk of the system is then estimated through Stochastic Simulation and evaluated by Sensitivity Analysis. By integrating these advanced analytical techniques into the V-Model, the framework fulfills, unifies, and complements existing automotive safety standards. It therefore provides a comprehensive, rigorous, and transparent safety assurance process for the development and deployment of Automated Driving Systems.", 'abstract_zh': '本文描述了支撑宝马首款SAE Level 3自动驾驶系统开发、发布过程和监管审批的综合安全框架。该框架以系统工程、工程风险管理、贝叶斯数据分析、试验设计和统计学习等领域的成熟定量和定性方法为基础，以新颖的方式加以整合。该方法系统地将与硬件和软件故障、性能限制以及功能不足相关的风险降至可接受水平，实现积极的风险平衡。该框架的核心是对潜在风险场景中的不确定性进行系统识别和量化，并基于试验设计、现场数据和专家知识构建冗余系统。通过蒙特卡洛模拟估计系统的残余风险，并通过灵敏度分析进行评估。通过将这些高级分析技术整合到V模型中，该框架实现了、统一和补充了现有的汽车安全标准，因此为自动驾驶系统的开发和部署提供了全面、严格和透明的安全保障过程。', 'title_zh': '自动-driving的安全性完整性框架'}
{'arxiv_id': 'arXiv:2503.20530', 'title': 'Combining Machine Learning and Sampling-Based Search for Multi-Goal Motion Planning with Dynamics', 'authors': 'Yuanjie Lu, Erion Plaku', 'link': 'https://arxiv.org/abs/2503.20530', 'abstract': 'This paper considers multi-goal motion planning in unstructured, obstacle-rich environments where a robot is required to reach multiple regions while avoiding collisions. The planned motions must also satisfy the differential constraints imposed by the robot dynamics. To find solutions efficiently, this paper leverages machine learning, Traveling Salesman Problem (TSP), and sampling-based motion planning. The approach expands a motion tree by adding collision-free and dynamically-feasible trajectories as branches. A TSP solver is used to compute a tour for each node to determine the order in which to reach the remaining goals by utilizing a cost matrix. An important aspect of the approach is that it leverages machine learning to construct the cost matrix by combining runtime and distance predictions to single-goal motion-planning problems. During the motion-tree expansion, priority is given to nodes associated with low-cost tours. Experiments with a vehicle model operating in obstacle-rich environments demonstrate the computational efficiency and scalability of the approach.', 'abstract_zh': '本文考虑在充满障碍的未结构化环境中开展多目标运动规划，要求机器人到达多个区域并避免碰撞。所规划的运动还需满足由机器人动力学施加的微分约束。为高效找到解，本文利用机器学习、旅行商问题（TSP）和基于采样的运动规划方法。该方法通过添加无碰撞且动力学可行的轨迹作为分支来扩展运动树。使用TSP求解器计算每个节点的成本矩阵，以确定到达剩余目标的顺序。该方法的一个重要方面在于利用机器学习结合单目标运动规划的运行时和距离预测来构造成本矩阵。在运动树扩展过程中，优先处理与低成本路线相关的节点。实验结果显示，该方法在障碍丰富的环境中表现出良好的计算效率和可扩展性。', 'title_zh': '基于采样搜索的机器学习与动力学约束多目标运动规划'}
{'arxiv_id': 'arXiv:2503.20521', 'title': 'Decremental Dynamics Planning for Robot Navigation', 'authors': 'Yuanjie Lu, Tong Xu, Linji Wang, Nick Hawes, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.20521', 'abstract': "Most, if not all, robot navigation systems employ a decomposed planning framework that includes global and local planning. To trade-off onboard computation and plan quality, current systems have to limit all robot dynamics considerations only within the local planner, while leveraging an extremely simplified robot representation (e.g., a point-mass holonomic model without dynamics) in the global level. However, such an artificial decomposition based on either full or zero consideration of robot dynamics can lead to gaps between the two levels, e.g., a global path based on a holonomic point-mass model may not be realizable by a non-holonomic robot, especially in highly constrained obstacle environments. Motivated by such a limitation, we propose a novel paradigm, Decremental Dynamics Planning that integrates dynamic constraints into the entire planning process, with a focus on high-fidelity dynamics modeling at the beginning and a gradual fidelity reduction as the planning progresses. To validate the effectiveness of this paradigm, we augment three different planners with DDP and show overall improved planning performance. We also develop a new DDP-based navigation system, which achieves first place in the simulation phase of the 2025 BARN Challenge. Both simulated and physical experiments validate DDP's hypothesized benefits.", 'abstract_zh': '递减动力学Planning：整合动力学约束的整个规划过程', 'title_zh': '机器人导航中的递减动力学规划'}
{'arxiv_id': 'arXiv:2503.20384', 'title': 'MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation', 'authors': 'Rongyu Zhang, Menghang Dong, Yuan Zhang, Liang Heng, Xiaowei Chi, Gaole Dai, Li Du, Dan Wang, Yuan Du, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2503.20384', 'abstract': "Multimodal Large Language Models (MLLMs) excel in understanding complex language and visual data, enabling generalist robotic systems to interpret instructions and perform embodied tasks. Nevertheless, their real-world deployment is hindered by substantial computational and storage demands. Recent insights into the homogeneous patterns in the LLM layer have inspired sparsification techniques to address these challenges, such as early exit and token pruning. However, these methods often neglect the critical role of the final layers that encode the semantic information most relevant to downstream robotic tasks. Aligning with the recent breakthrough of the Shallow Brain Hypothesis (SBH) in neuroscience and the mixture of experts in model sparsification, we conceptualize each LLM layer as an expert and propose a Mixture-of-Layers Vision-Language-Action model (MoLe-VLA, or simply MoLe) architecture for dynamic LLM layer activation. We introduce a Spatial-Temporal Aware Router (STAR) for MoLe to selectively activate only parts of the layers based on the robot's current state, mimicking the brain's distinct signal pathways specialized for cognition and causal reasoning. Additionally, to compensate for the cognitive ability of LLMs lost in MoLe, we devise a Cognition Self-Knowledge Distillation (CogKD) framework. CogKD enhances the understanding of task demands and improves the generation of task-relevant action sequences by leveraging cognitive features. Extensive experiments conducted in both RLBench simulation and real-world environments demonstrate the superiority of MoLe-VLA in both efficiency and performance. Specifically, MoLe-VLA achieves an 8% improvement in the mean success rate across ten tasks while reducing computational costs by up to x5.6 compared to standard LLMs.", 'abstract_zh': '多模态大规模语言模型（MLLMs）在理解和处理复杂语言与视觉数据方面表现出色，使通用机器人系统能够解释指令并执行实体任务。然而，它们的实际部署受到计算和存储需求的限制。近期对LLM层中同质模式的理解启发了通过早期退出和令牌修剪等稀疏化技术来解决这些挑战的方法。然而，这些方法往往忽略了对下游机器人任务最为相关的语义信息进行编码的最终层的关键作用。顺应神经科学中浅脑假说（SBH）的最新突破以及模型稀疏化中的专家混合，我们将每个LLM层视为专家，并提出了一种动态LLM层激活的多层视觉语言行动模型（MoLe-VLA，或MoLe）架构。我们引入了一种时空感知路由器（STAR）以根据机器人当前状态仅选择性地激活部分层，模拟大脑专门化的认知和因果推理信号路径。此外，为了补偿MoLe中LLM认知能力的损失，我们设计了一种认知自知知识蒸馏（CogKD）框架。CogKD通过利用认知特征增强了对任务需求的理解，并改善了相关行动序列的生成。在RLBench模拟和真实环境中的广泛实验表明，MoLe-VLA在效率和性能上均优于标准的大规模语言模型。具体而言，MoLe-VLA在十个任务上的平均成功率提高了8%，计算成本降低了最多5.6倍。', 'title_zh': 'MoLe-VLA：基于混合层的动态层跳过视觉语言动作模型及其在高效机器人操作中的应用'}
{'arxiv_id': 'arXiv:2503.20324', 'title': 'CTS-CBS: A New Approach for Multi-Agent Collaborative Task Sequencing and Path Finding', 'authors': 'Junkai Jiang, Ruochen Li, Yibin Yang, Yihe Chen, Yuning Wang, Shaobing Xu, Jianqiang Wang', 'link': 'https://arxiv.org/abs/2503.20324', 'abstract': "This paper addresses a generalization problem of Multi-Agent Pathfinding (MAPF), called Collaborative Task Sequencing - Multi-Agent Pathfinding (CTS-MAPF), where agents must plan collision-free paths and visit a series of intermediate task locations in a specific order before reaching their final destinations. To address this problem, we propose a new approach, Collaborative Task Sequencing - Conflict-Based Search (CTS-CBS), which conducts a two-level search. In the high level, it generates a search forest, where each tree corresponds to a joint task sequence derived from the jTSP solution. In the low level, CTS-CBS performs constrained single-agent path planning to generate paths for each agent while adhering to high-level constraints. We also provide heoretical guarantees of its completeness and optimality (or sub-optimality with a bounded parameter). To evaluate the performance of CTS-CBS, we create two datasets, CTS-MAPF and MG-MAPF, and conduct comprehensive experiments. The results show that CTS-CBS adaptations for MG-MAPF outperform baseline algorithms in terms of success rate (up to 20 times larger) and runtime (up to 100 times faster), with less than a 10% sacrifice in solution quality. Furthermore, CTS-CBS offers flexibility by allowing users to adjust the sub-optimality bound omega to balance between solution quality and efficiency. Finally, practical robot tests demonstrate the algorithm's applicability in real-world scenarios.", 'abstract_zh': 'CTS-CBS：协同任务序列化-冲突基于搜索的多智能体路径规划', 'title_zh': 'CTS-CBS：一种新的多agents协作任务序列化和路径寻找方法'}
{'arxiv_id': 'arXiv:2503.20280', 'title': 'Turning Circle-based Control Barrier Function for Efficient Collision Avoidance of Nonholonomic Vehicles', 'authors': 'Changyu Lee, Kiyong Park, Jinwhan Kim', 'link': 'https://arxiv.org/abs/2503.20280', 'abstract': "This paper presents a new control barrier function (CBF) designed to improve the efficiency of collision avoidance for nonholonomic vehicles. Traditional CBFs typically rely on the shortest Euclidean distance to obstacles, overlooking the limited heading change ability of nonholonomic vehicles. This often leads to abrupt maneuvers and excessive speed reductions, which is not desirable and reduces the efficiency of collision avoidance. Our approach addresses these limitations by incorporating the distance to the turning circle, considering the vehicle's limited maneuverability imposed by its nonholonomic constraints. The proposed CBF is integrated with model predictive control (MPC) to generate more efficient trajectories compared to existing methods that rely solely on Euclidean distance-based CBFs. The effectiveness of the proposed method is validated through numerical simulations on unicycle vehicles and experiments with underactuated surface vehicles.", 'abstract_zh': '本文提出了一种新的控制障碍函数（CBF），旨在提高非完整车辆碰撞避免的效率。传统的CBF通常依赖于最短欧几里得距离来避开障碍，忽略了非完整车辆的有限转向能力。这常常导致突发性的操作和过度的减速，这不符合期望，降低了碰撞避免的效率。我们的方法通过结合转向圈距离和考虑非完整约束对车辆的有限操控性，解决了这些问题。所提出的CBF与模型预测控制（MPC）结合，生成了比仅依赖欧几里得距离CBF的方法更高效的轨迹。通过统一车辆的数值仿真和欠驱动水面车辆的实验，验证了所提出方法的有效性。', 'title_zh': '基于转弯圆的控制障碍函数用于非holonomic车辆的高效避碰'}
{'arxiv_id': 'arXiv:2503.20241', 'title': 'LGR: LLM-Guided Ranking of Frontiers for Object Goal Navigation', 'authors': 'Mitsuaki Uno, Kanji Tanaka, Daiki Iwata, Yudai Noda, Shoya Miyazaki, Kouki Terashima', 'link': 'https://arxiv.org/abs/2503.20241', 'abstract': 'Object Goal Navigation (OGN) is a fundamental task for robots and AI, with key applications such as mobile robot image databases (MRID). In particular, mapless OGN is essential in scenarios involving unknown or dynamic environments. This study aims to enhance recent modular mapless OGN systems by leveraging the commonsense reasoning capabilities of large language models (LLMs). Specifically, we address the challenge of determining the visiting order in frontier-based exploration by framing it as a frontier ranking problem. Our approach is grounded in recent findings that, while LLMs cannot determine the absolute value of a frontier, they excel at evaluating the relative value between multiple frontiers viewed within a single image using the view image as context. We dynamically manage the frontier list by adding and removing elements, using an LLM as a ranking model. The ranking results are represented as reciprocal rank vectors, which are ideal for multi-view, multi-query information fusion. We validate the effectiveness of our method through evaluations in Habitat-Sim.', 'abstract_zh': '无地图物体目标导航（OGN）是机器人和AI领域的一项基础任务，具有移动机器人图像数据库（MRID）等关键应用。特别是，无地图OGN在涉及未知或动态环境的场景中尤为重要。本研究旨在通过利用大规模语言模型（LLM）的常识推理能力，提升最近的模块化无地图OGN系统。具体而言，我们通过将前沿探索中的访问顺序问题重新定义为前沿排名问题来应对基于前沿探索的挑战。我们的方法基于近期发现，虽然LLM无法确定前沿的绝对值，但在单张图像作为上下文的情况下，它们能够出色地评估多个前沿的相对价值。我们通过动态管理前沿列表——添加和移除元素——使用LLM作为排名模型。排名结果以互逆排名向量表示，非常适合多视角、多查询信息融合。我们通过在Habitat-Sim中的评估验证了该方法的有效性。', 'title_zh': 'LLM引导的物体目标导航前沿排名：LGR'}
{'arxiv_id': 'arXiv:2503.20237', 'title': 'A Virtual Fencing Framework for Safe and Efficient Collaborative Robotics', 'authors': 'Vineela Reddy Pippera Badguna, Aliasghar Arab, Durga Avinash Kodavalla', 'link': 'https://arxiv.org/abs/2503.20237', 'abstract': 'Collaborative robots (cobots) increasingly operate alongside humans, demanding robust real-time safeguarding. Current safety standards (e.g., ISO 10218, ANSI/RIA 15.06, ISO/TS 15066) require risk assessments but offer limited guidance for real-time responses. We propose a virtual fencing approach that detects and predicts human motion, ensuring safe cobot operation. Safety and performance tradeoffs are modeled as an optimization problem and solved via sequential quadratic programming. Experimental validation shows that our method minimizes operational pauses while maintaining safety, providing a modular solution for human-robot collaboration.', 'abstract_zh': '协作机器人（cobot）越来越多地与人类并肩工作，要求具备 robust 的实时保护能力。当前的安全标准（如 ISO 10218、ANSI/RIA 15.06、ISO/TS 15066）要求进行风险评估，但对实时响应提供的指导有限。我们提出了一种虚拟围栏方法，用于检测和预测人类运动，以确保协作机器人的安全运行。安全性和性能之间的权衡被建模为一个优化问题，并通过逐步二次规划进行求解。实验验证表明，该方法在保证安全的同时最小化了操作暂停时间，提供了一种模块化的人机协作解决方案。', 'title_zh': '虚拟围栏框架实现安全高效协作机器人系统'}
{'arxiv_id': 'arXiv:2503.20208', 'title': 'Learning Adaptive Dexterous Grasping from Single Demonstrations', 'authors': 'Liangzhi Shi, Yulin Liu, Lingqi Zeng, Bo Ai, Zhengdong Hong, Hao Su', 'link': 'https://arxiv.org/abs/2503.20208', 'abstract': 'How can robots learn dexterous grasping skills efficiently and apply them adaptively based on user instructions? This work tackles two key challenges: efficient skill acquisition from limited human demonstrations and context-driven skill selection. We introduce AdaDexGrasp, a framework that learns a library of grasping skills from a single human demonstration per skill and selects the most suitable one using a vision-language model (VLM). To improve sample efficiency, we propose a trajectory following reward that guides reinforcement learning (RL) toward states close to a human demonstration while allowing flexibility in exploration. To learn beyond the single demonstration, we employ curriculum learning, progressively increasing object pose variations to enhance robustness. At deployment, a VLM retrieves the appropriate skill based on user instructions, bridging low-level learned skills with high-level intent. We evaluate AdaDexGrasp in both simulation and real-world settings, showing that our approach significantly improves RL efficiency and enables learning human-like grasp strategies across varied object configurations. Finally, we demonstrate zero-shot transfer of our learned policies to a real-world PSYONIC Ability Hand, with a 90% success rate across objects, significantly outperforming the baseline.', 'abstract_zh': '如何高效地让机器人从少量的人类示范中学习灵巧抓握技能，并根据用户指令进行适配性应用？本研究解决了两个关键挑战：从有限的人类示范中高效学习技能以及基于上下文选择技能。我们介绍了AdaDexGrasp框架，该框架从每种技能单个人类示范中学习抓握技能库，并使用视觉语言模型进行最合适的技能选择。为提高样本效率，我们提出了轨迹跟随奖励，引导强化学习（RL）向接近人类示范的状态发展，同时允许在探索中保持灵活性。为超越单示范学习，我们采用了逐步学习策略，逐步增加物体姿态变化以增强鲁棒性。在部署时，视觉语言模型根据用户指令检索合适的技能，将底层学习的技能与高层意图连接起来。我们在仿真和现实世界环境中评估了AdaDexGrasp，结果显示我们的方法显著提高了RL效率，并能在各种物体配置中学习类似人类的抓握策略。最后，我们在现实世界的PSYONIC Ability Hand上展示了我们学习策咯的零样本转移，并在各类物体上实现了90%的成功率，显著优于基线方法。', 'title_zh': '基于单次演示学习适应性灵巧抓取'}
{'arxiv_id': 'arXiv:2503.20134', 'title': 'DRPA-MPPI: Dynamic Repulsive Potential Augmented MPPI for Reactive Navigation in Unstructured Environments', 'authors': 'Takahiro Fuke, Masafumi Endo, Kohei Honda, Genya Ishigami', 'link': 'https://arxiv.org/abs/2503.20134', 'abstract': "Reactive mobile robot navigation in unstructured environments is challenging when robots encounter unexpected obstacles that invalidate previously planned trajectories. Model predictive path integral control (MPPI) enables reactive planning, but still suffers from limited prediction horizons that lead to local minima traps near obstacles. Current solutions rely on heuristic cost design or scenario-specific pre-training, which often limits their adaptability to new environments. We introduce dynamic repulsive potential augmented MPPI (DRPA-MPPI), which dynamically detects potential entrapments on the predicted trajectories. Upon detecting local minima, DRPA-MPPI automatically switches between standard goal-oriented optimization and a modified cost function that generates repulsive forces away from local minima. Comprehensive testing in simulated obstacle-rich environments confirms DRPA-MPPI's superior navigation performance and safety compared to conventional methods with less computational burden.", 'abstract_zh': '动态排斥势增强的MPPI控制（DRPA-MPPI）及其在未结构化环境中的反应式导航', 'title_zh': 'DRPA-MPPI: 动态排斥势增强的MPPI在不规则环境中的反应 navigation'}
{'arxiv_id': 'arXiv:2503.20127', 'title': 'Bandwidth Allocation for Cloud-Augmented Autonomous Driving', 'authors': 'Peter Schafhalter, Alexander Krentsel, Joseph E. Gonzalez, Sylvia Ratnasamy, Scott Shenker, Ion Stoica', 'link': 'https://arxiv.org/abs/2503.20127', 'abstract': "Autonomous vehicle (AV) control systems increasingly rely on ML models for tasks such as perception and planning. Current practice is to run these models on the car's local hardware due to real-time latency constraints and reliability concerns, which limits model size and thus accuracy. Prior work has observed that we could augment current systems by running larger models in the cloud, relying on faster cloud runtimes to offset the cellular network latency. However, prior work does not account for an important practical constraint: limited cellular bandwidth. We show that, for typical bandwidth levels, proposed techniques for cloud-augmented AV models take too long to transfer data, thus mostly falling back to the on-car models and resulting in no accuracy improvement.\nIn this work, we show that realizing cloud-augmented AV models requires intelligent use of this scarce bandwidth, i.e. carefully allocating bandwidth across tasks and providing multiple data compression and model options. We formulate this as a resource allocation problem to maximize car utility, and present our system \\sysname which achieves an increase in average model accuracy by up to 15 percentage points on driving scenarios from the Waymo Open Dataset.", 'abstract_zh': '自主驾驶车辆（AV）控制系统越来越多地依赖于机器学习模型完成感知和规划等任务。由于实时延迟和可靠性方面的考虑，当前的做法是将这些模型运行在汽车本地硬件上，这限制了模型的大小，从而降低了准确性。前期工作观察到，可以通过在云端运行更大规模的模型来增强现有系统，利用更快的云计算运行时间来抵消蜂窝网络延迟。然而，前期工作并未考虑到一个重要的实践约束：有限的蜂窝带宽。我们发现，在典型带宽水平下，提议的增强型AV模型技术在数据传输方面耗时过长，从而主要依赖于本地模型，导致未能提高准确性。\n\n在本文中，我们展示了实现增强型AV模型需要智能利用稀缺带宽，即跨任务精细分配带宽，并提供多种数据压缩和模型选项。我们将这定义为一种资源分配问题，旨在最大化车辆利用率，并提出了我们的系统\\sysname，在Waymo开放数据集的驾驶场景中，实现了平均模型准确性最多提高15个百分点。', 'title_zh': '基于云增强的自动驾驶带宽分配'}
{'arxiv_id': 'arXiv:2503.20066', 'title': 'Learning Scene-Level Signed Directional Distance Function with Ellipsoidal Priors and Neural Residuals', 'authors': 'Zhirui Dai, Hojoon Shin, Yulun Tian, Ki Myung Brian Lee, Nikolay Atanasov', 'link': 'https://arxiv.org/abs/2503.20066', 'abstract': 'Dense geometric environment representations are critical for autonomous mobile robot navigation and exploration. Recent work shows that implicit continuous representations of occupancy, signed distance, or radiance learned using neural networks offer advantages in reconstruction fidelity, efficiency, and differentiability over explicit discrete representations based on meshes, point clouds, and voxels. In this work, we explore a directional formulation of signed distance, called signed directional distance function (SDDF). Unlike signed distance function (SDF) and similar to neural radiance fields (NeRF), SDDF has a position and viewing direction as input. Like SDF and unlike NeRF, SDDF directly provides distance to the observed surface along the direction, rather than integrating along the view ray, allowing efficient view synthesis. To learn and predict scene-level SDDF efficiently, we develop a differentiable hybrid representation that combines explicit ellipsoid priors and implicit neural residuals. This approach allows the model to effectively handle large distance discontinuities around obstacle boundaries while preserving the ability for dense high-fidelity prediction. We show that SDDF is competitive with the state-of-the-art neural implicit scene models in terms of reconstruction accuracy and rendering efficiency, while allowing differentiable view prediction for robot trajectory optimization.', 'abstract_zh': '密集的几何环境表示对于自主移动机器人导航和探索至关重要。近年来的工作表明，神经网络学习的占用度、带符号距离或辐射度的隐式连续表示在重建保真度、效率和可微性方面优于基于网格、点云和体素的显式离散表示。在本文中，我们探索了一种带方向的带符号距离的表示形式，称为带方向的带符号距离函数（SDDF）。不同于带符号距离函数（SDF）且类似于神经辐射场（NeRF），SDDF 拥有位置和视图方向作为输入。类似于 SDF 但不同于 NeRF，SDDF 可直接提供沿方向与观察表面之间的距离，而不是沿视光线积分，从而实现高效的视图合成。为了高效地学习和预测场景级别的 SDDF，我们开发了一种可微混合表示，结合显式的椭球先验和隐式的神经残差。这种方法使模型能够有效地处理障碍物边界附近的大量距离不连续性，同时保持密集高保真预测的能力。我们展示了 SDDF 在重建准确性和渲染效率方面与当前最先进的神经隐式场景模型相当，同时允许可微视图预测以用于机器人轨迹优化。', 'title_zh': '基于椭球先验和神经残差的学习场景级-signed方向距离函数'}
{'arxiv_id': 'arXiv:2503.20020', 'title': 'Gemini Robotics: Bringing AI into the Physical World', 'authors': "Gemini Robotics Team, Saminda Abeyruwan, Joshua Ainslie, Jean-Baptiste Alayrac, Montserrat Gonzalez Arenas, Travis Armstrong, Ashwin Balakrishna, Robert Baruch, Maria Bauza, Michiel Blokzijl, Steven Bohez, Konstantinos Bousmalis, Anthony Brohan, Thomas Buschmann, Arunkumar Byravan, Serkan Cabi, Ken Caluwaerts, Federico Casarini, Oscar Chang, Jose Enrique Chen, Xi Chen, Hao-Tien Lewis Chiang, Krzysztof Choromanski, David D'Ambrosio, Sudeep Dasari, Todor Davchev, Coline Devin, Norman Di Palo, Tianli Ding, Adil Dostmohamed, Danny Driess, Yilun Du, Debidatta Dwibedi, Michael Elabd, Claudio Fantacci, Cody Fong, Erik Frey, Chuyuan Fu, Marissa Giustina, Keerthana Gopalakrishnan, Laura Graesser, Leonard Hasenclever, Nicolas Heess, Brandon Hernaez, Alexander Herzog, R. Alex Hofer, Jan Humplik, Atil Iscen, Mithun George Jacob, Deepali Jain, Ryan Julian, Dmitry Kalashnikov, M. Emre Karagozler, Stefani Karp, Chase Kew, Jerad Kirkland, Sean Kirmani, Yuheng Kuang, Thomas Lampe, Antoine Laurens, Isabel Leal, Alex X. Lee, Tsang-Wei Edward Lee, Jacky Liang, Yixin Lin, Sharath Maddineni, Anirudha Majumdar, Assaf Hurwitz Michaely, Robert Moreno, Michael Neunert, Francesco Nori, Carolina Parada, Emilio Parisotto, Peter Pastor, Acorn Pooley, Kanishka Rao, Krista Reymann, Dorsa Sadigh, Stefano Saliceti, Pannag Sanketi, Pierre Sermanet, Dhruv Shah, Mohit Sharma, Kathryn Shea, Charles Shu, Vikas Sindhwani, Sumeet Singh, Radu Soricut, Jost Tobias Springenberg, Rachel Sterneck, Razvan Surdulescu, Jie Tan, Jonathan Tompson, Vincent Vanhoucke, Jake Varley, Grace Vesom, Giulia Vezzani, Oriol Vinyals, Ayzaan Wahid, Stefan Welker", 'link': 'https://arxiv.org/abs/2503.20020', 'abstract': "Recent advancements in large multimodal models have led to the emergence of remarkable generalist capabilities in digital domains, yet their translation to physical agents such as robots remains a significant challenge. This report introduces a new family of AI models purposefully designed for robotics and built upon the foundation of Gemini 2.0. We present Gemini Robotics, an advanced Vision-Language-Action (VLA) generalist model capable of directly controlling robots. Gemini Robotics executes smooth and reactive movements to tackle a wide range of complex manipulation tasks while also being robust to variations in object types and positions, handling unseen environments as well as following diverse, open vocabulary instructions. We show that with additional fine-tuning, Gemini Robotics can be specialized to new capabilities including solving long-horizon, highly dexterous tasks, learning new short-horizon tasks from as few as 100 demonstrations and adapting to completely novel robot embodiments. This is made possible because Gemini Robotics builds on top of the Gemini Robotics-ER model, the second model we introduce in this work. Gemini Robotics-ER (Embodied Reasoning) extends Gemini's multimodal reasoning capabilities into the physical world, with enhanced spatial and temporal understanding. This enables capabilities relevant to robotics including object detection, pointing, trajectory and grasp prediction, as well as multi-view correspondence and 3D bounding box predictions. We show how this novel combination can support a variety of robotics applications. We also discuss and address important safety considerations related to this new class of robotics foundation models. The Gemini Robotics family marks a substantial step towards developing general-purpose robots that realizes AI's potential in the physical world.", 'abstract_zh': 'Recent advancements in大型多模态模型已在数字领域引发了一种令人瞩目的通用能力，但将其翻译到机器人等物理代理中仍然是一个重大挑战。本报告介绍了专门为机器人设计的一系列新型AI模型，建立在Gemini 2.0的基础上。我们介绍了Gemini Robotics，这是一个先进的Vision-Language-Action（VLA）通用模型，能够直接控制机器人。Gemini Robotics执行流畅且反应灵敏的动作，能够应对一系列复杂的操纵任务，同时能够应对物体类型和位置的变化，处理未见过的环境，并遵循多种多样的开放词汇指令。我们展示了通过额外的微调，Gemini Robotics可以专门用于新能力，包括解决长期目标、高度灵巧的任务，从最少100个演示中学习新的短期任务，以及适应全新的机器人实体。这得益于Gemini Robotics建立在Gemini Robotics-ER模型之上，这是我们在此工作中介绍的第二个模型。Gemini Robotics-ER（实体推理）将Gemini的多模态推理能力扩展到物理世界，增强了空间和时间理解能力。这使得与机器人相关的功能成为可能，包括物体检测、指认、轨迹和抓取预测，以及多视图对应和三维边界框预测。我们展示了这种新颖的组合如何支持各种机器人应用。我们还讨论并解决了与这一新类别的机器人基础模型相关的重要安全问题。Gemini Robotics家族标志着朝着开发能够在物理世界实现人工智能潜力的通用机器人迈出了一大步。', 'title_zh': 'Gemini机器人：将AI带入物理世界'}
{'arxiv_id': 'arXiv:2503.19984', 'title': 'Hybrid Magnetically and Electrically Powered Metallo-Dielectric Janus Microrobots: Enhanced Motion Control and Operation Beyond Planar Limits', 'authors': 'Ido Rachbuch, Sinwook Park, Yuval Katz, Touvia Miloh, Gilad Yossifon', 'link': 'https://arxiv.org/abs/2503.19984', 'abstract': 'This study introduces the integration of hybrid magnetic and electric actuation mechanisms to achieve advanced motion capabilities for Janus particle (JP) microrobots. We demonstrate enhanced in-plane motion control through versatile control strategies and present the concepts of interplanar transitions and 2.5-dimensional (2.5D) trajectories, enabled by magnetic levitation and electrostatic trapping. These innovations expand the mobility of JPs into 3D space, allowing dynamic operation beyond the limitations of traditional surface-bound motion. Key functionalities include obstacle crossing, transitions to elevated surfaces, and discrete surface patterning enabling highly localized interventions. Using this set of tools, we also showcase the controlled out-of-plane transport of both synthetic and biological cargo. Together, these advancements lay the groundwork for novel microrobot-related applications in microfluidic systems and biomedical research.', 'abstract_zh': '本研究介绍了将混合磁性和电性驱动机制集成起来，以实现Janus粒子（JP）微机器人先进的运动能力。我们通过多样化的控制策略展示了平面内运动控制的增强，并介绍了通过磁悬浮和静电捕获实现的层间转换和2.5维轨迹的概念。这些创新将JP的移动性扩展到三维空间，使它们能够在传统表面束缚运动的限制之外实现动态操作。关键功能包括障碍物穿越、过渡到高处表面以及离散表面图案化，以实现高度局部化的干预。利用这一套工具，我们还展示了对合成和生物货物进行可控的层间运输。这些进步为微流控系统和生物医学研究中的新型微机器人相关应用奠定了基础。', 'title_zh': '磁电混合动力金属-介质阴阳微机器人：超越平面限制的运动控制与操作 Enhancement of Motion Control and Operation Beyond Planar Limits for Hybrid Magnetically and Electrically Powered Metallo-Dielectric Janus Microrobots'}
{'arxiv_id': 'arXiv:2503.19941', 'title': 'Body Discovery of Embodied AI', 'authors': 'Zhe Sun, Pengfei Tian, Xiaozhu Hu, Xiaoyu Zhao, Huiying Li, Zhenliang Zhang', 'link': 'https://arxiv.org/abs/2503.19941', 'abstract': 'In the pursuit of realizing artificial general intelligence (AGI), the importance of embodied artificial intelligence (AI) becomes increasingly apparent. Following this trend, research integrating robots with AGI has become prominent. As various kinds of embodiments have been designed, adaptability to diverse embodiments will become important to AGI. We introduce a new challenge, termed "Body Discovery of Embodied AI", focusing on tasks of recognizing embodiments and summarizing neural signal functionality. The challenge encompasses the precise definition of an AI body and the intricate task of identifying embodiments in dynamic environments, where conventional approaches often prove inadequate. To address these challenges, we apply causal inference method and evaluate it by developing a simulator tailored for testing algorithms with virtual environments. Finally, we validate the efficacy of our algorithms through empirical testing, demonstrating their robust performance in various scenarios based on virtual environments.', 'abstract_zh': '追求实现通用人工智能（AGI）的过程中，具备实体的 artificial intelligence（AI）的重要性 increasingly 明显。在此趋势下，将机器人与 AGI 结合的研究逐渐成为热点。随着各种实体形式的 设计，AGI 对不同实体形式的适应性将变得尤为重要。我们引入了一个新的挑战，称为“实体 AI 的实体发现”，专注于识别实体和总结神经信号功能的任务。该挑战涉及对 AI 实体的精确定义以及在动态环境中辨识实体的复杂任务，而传统的办法往往在这种情况下效果不佳。为了应对这些挑战，我们应用因果推断方法，并通过为测试算法开发专门针对虚拟环境的模拟器来评估其效果。最后，我们通过实证测试验证了算法的有效性，展示了其在多种基于虚拟环境的场景中的稳健表现。', 'title_zh': '具身AI的obody发现'}
{'arxiv_id': 'arXiv:2503.20646', 'title': 'Immersive and Wearable Thermal Rendering for Augmented Reality', 'authors': 'Alexandra Watkins, Ritam Ghosh, Evan Chow, Nilanjan Sarkar', 'link': 'https://arxiv.org/abs/2503.20646', 'abstract': 'In augmented reality (AR), where digital content is overlaid onto the real world, realistic thermal feedback has been shown to enhance immersion. Yet current thermal feedback devices, heavily influenced by the needs of virtual reality, often hinder physical interactions and are ineffective for immersion in AR. To bridge this gap, we have identified three design considerations relevant for AR thermal feedback: indirect feedback to maintain dexterity, thermal passthrough to preserve real-world temperature perception, and spatiotemporal rendering for dynamic sensations. We then created a unique and innovative thermal feedback device that satisfies these criteria. Human subject experiments assessing perceptual sensitivity, object temperature matching, spatial pattern recognition, and moving thermal stimuli demonstrated the impact of our design, enabling realistic temperature discrimination, virtual object perception, and enhanced immersion. These findings demonstrate that carefully designed thermal feedback systems can bridge the sensory gap between physical and virtual interactions, enhancing AR realism and usability.', 'abstract_zh': '在增强现实（AR）中，将数字内容叠加到现实世界，现实的热反馈已被证明可以增强沉浸感。然而，当前的热反馈设备受到虚拟现实需求的影响，往往妨碍物理互动，并在AR中无效。为了弥合这一差距，我们确定了三个适用于AR热反馈的设计考量：间接反馈以保持灵巧性、热传递以保持真实世界的温度感知以及时空渲染以产生动态感觉。然后，我们创造了一种独特且创新的热反馈设备，符合这些标准。人体实验评估感知敏感性、物体温度匹配、空间模式识别以及移动热刺激的效果，证明了我们设计的影响，实现了现实的温度区分、虚拟对象感知和增强的沉浸感。这些发现表明，精心设计的热反馈系统可以弥合物理互动和虚拟互动之间的感知差距，增强AR的真实性和可用性。', 'title_zh': '沉浸式可穿戴热渲染技术在增强现实中的应用'}
{'arxiv_id': 'arXiv:2503.20642', 'title': 'Representation Improvement in Latent Space for Search-Based Testing of Autonomous Robotic Systems', 'authors': 'Dmytro Humeniuk, Foutse Khomh', 'link': 'https://arxiv.org/abs/2503.20642', 'abstract': 'Testing autonomous robotic systems, such as self-driving cars and unmanned aerial vehicles, is challenging due to their interaction with highly unpredictable environments. A common practice is to first conduct simulation-based testing, which, despite reducing real-world risks, remains time-consuming and resource-intensive due to the vast space of possible test scenarios. A number of search-based approaches were proposed to generate test scenarios more efficiently. A key aspect of any search-based test generation approach is the choice of representation used during the search process. However, existing methods for improving test scenario representation remain limited. We propose RILaST (Representation Improvement in Latent Space for Search-Based Testing) approach, which enhances test representation by mapping it to the latent space of a variational autoencoder. We evaluate RILaST on two use cases, including autonomous drone and autonomous lane-keeping assist system. The obtained results show that RILaST allows finding between 3 to 4.6 times more failures than baseline approaches, achieving a high level of test diversity.', 'abstract_zh': '基于潜在空间的测试表示改进在自主系统测试中的应用', 'title_zh': '基于搜索的自主机器人系统测试中Latent空间表示改进'}
{'arxiv_id': 'arXiv:2503.20523', 'title': 'GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving', 'authors': 'Lloyd Russell, Anthony Hu, Lorenzo Bertoni, George Fedoseev, Jamie Shotton, Elahe Arani, Gianluca Corrado', 'link': 'https://arxiv.org/abs/2503.20523', 'abstract': 'Generative models offer a scalable and flexible paradigm for simulating complex environments, yet current approaches fall short in addressing the domain-specific requirements of autonomous driving - such as multi-agent interactions, fine-grained control, and multi-camera consistency. We introduce GAIA-2, Generative AI for Autonomy, a latent diffusion world model that unifies these capabilities within a single generative framework. GAIA-2 supports controllable video generation conditioned on a rich set of structured inputs: ego-vehicle dynamics, agent configurations, environmental factors, and road semantics. It generates high-resolution, spatiotemporally consistent multi-camera videos across geographically diverse driving environments (UK, US, Germany). The model integrates both structured conditioning and external latent embeddings (e.g., from a proprietary driving model) to facilitate flexible and semantically grounded scene synthesis. Through this integration, GAIA-2 enables scalable simulation of both common and rare driving scenarios, advancing the use of generative world models as a core tool in the development of autonomous systems. Videos are available at this https URL.', 'abstract_zh': '生成模型提供了一种可扩展且灵活的框架来模拟复杂环境，但当前的方法在应对自动驾驶领域的特定需求（如多Agent交互、精细控制和多摄像头一致性）方面尚存在不足。我们引入了GAIA-2，这是一种生成AI自动驾驶世界模型，将其所有这些功能统合在一个生成框架中。GAIA-2支持基于丰富结构化输入的可控视频生成，包括 ego-车辆动态、Agent配置、环境因素和道路语义。它生成了高分辨率、时空一致的多摄像头视频，适用于多种地理驾驶环境（英国、美国、德国）。该模型结合了结构化条件和外部潜在嵌入（如自有的驾驶模型），以实现灵活且语义化的场景合成。通过这种结合，GAIA-2 使我们能够大规模地模拟常见和罕见的驾驶场景，推动生成世界模型在自动驾驶系统开发中的核心应用。视频可访问此链接：this https URL。', 'title_zh': 'GAIA-2：一种可控的多视图生成世界模型在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2503.20518', 'title': 'Exploring the Effect of Robotic Embodiment and Empathetic Tone of LLMs on Empathy Elicitation', 'authors': 'Liza Darwesh, Jaspreet Singh, Marin Marian, Eduard Alexa, Koen Hindriks, Kim Baraka', 'link': 'https://arxiv.org/abs/2503.20518', 'abstract': "This study investigates the elicitation of empathy toward a third party through interaction with social agents. Participants engaged with either a physical robot or a voice-enabled chatbot, both driven by a large language model (LLM) programmed to exhibit either an empathetic tone or remain neutral. The interaction is focused on a fictional character, Katie Banks, who is in a challenging situation and in need of financial donations. The willingness to help Katie, measured by the number of hours participants were willing to volunteer, along with their perceptions of the agent, were assessed for 60 participants. Results indicate that neither robotic embodiment nor empathetic tone significantly influenced participants' willingness to volunteer. While the LLM effectively simulated human empathy, fostering genuine empathetic responses in participants proved challenging.", 'abstract_zh': '本研究探讨了通过与社会代理互动激发对第三方 empathy 的机制。参与者与物理机器人或声音聊天机器人进行了互动，这两种机器人均由大型语言模型（LLM）驱动，分别被编程为展现出 empathetic 的语气或保持中立。互动的对象是一个虚构的人物凯蒂·班克斯，她遇到了一个棘手的情况，并需要获得经济上的捐赠。通过评估参与者愿意为凯蒂志愿服务的小时数以及他们对代理人的看法，研究分析了 60 名参与者的数据。结果表明，机器人实体化形式或 empathetic 的语气并未显著影响参与者的服务意愿。虽然 LLM 成功模拟了人类的 empathy，但在参与者中引发真正的 empathy 反应却颇具挑战。', 'title_zh': '探索大型语言模型的机器人具身形式和 empathy 訵调对其 empathy 引发效果的影响'}
{'arxiv_id': 'arXiv:2503.20425', 'title': 'Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation', 'authors': 'Kevin Alcedo, Pedro U. Lima, Rachid Alami', 'link': 'https://arxiv.org/abs/2503.20425', 'abstract': "Navigating in environments alongside humans requires agents to reason under uncertainty and account for the beliefs and intentions of those around them. Under a sequential decision-making framework, egocentric navigation can naturally be represented as a Markov Decision Process (MDP). However, social navigation additionally requires reasoning about the hidden beliefs of others, inherently leading to a Partially Observable Markov Decision Process (POMDP), where agents lack direct access to others' mental states. Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge of belief tracking in partially observable environments; and (2) a perspective-shift operator for belief estimation, leveraging recent work on Influence-based Abstractions (IBA) in structured multi-agent settings.", 'abstract_zh': '在人类周围环境中导航需要代理在不确定性下进行推理并考虑到周围人的信念和意图。在序列决策框架下，以自我为中心的导航可以自然地表示为马尔可夫决策过程（MDP）。然而，社会导航还需要推理他人的隐藏信念，这不可避免地导致部分可观测马尔可夫决策过程（POMDP），其中代理无法直接访问他人的心理状态。受到心智理论和知识性规划的启发，我们提出了一种基于神经符号模型的强化学习架构，用于解决部分可观测环境中信念跟踪的挑战；并利用基于影响的抽象（IBA）在结构化多代理设置中的 Recent 工作，提出了视角转换操作符以进行信念估计。', 'title_zh': '视角偏移的神经符号世界模型：一种社会意识机器人导航框架'}
{'arxiv_id': 'arXiv:2503.20211', 'title': 'Synthetic-to-Real Self-supervised Robust Depth Estimation via Learning with Motion and Structure Priors', 'authors': 'Weilong Yan, Ming Li, Haipeng Li, Shuwei Shao, Robby T. Tan', 'link': 'https://arxiv.org/abs/2503.20211', 'abstract': 'Self-supervised depth estimation from monocular cameras in diverse outdoor conditions, such as daytime, rain, and nighttime, is challenging due to the difficulty of learning universal representations and the severe lack of labeled real-world adverse data. Previous methods either rely on synthetic inputs and pseudo-depth labels or directly apply daytime strategies to adverse conditions, resulting in suboptimal results. In this paper, we present the first synthetic-to-real robust depth estimation framework, incorporating motion and structure priors to capture real-world knowledge effectively. In the synthetic adaptation, we transfer motion-structure knowledge inside cost volumes for better robust representation, using a frozen daytime model to train a depth estimator in synthetic adverse conditions. In the innovative real adaptation, which targets to fix synthetic-real gaps, models trained earlier identify the weather-insensitive regions with a designed consistency-reweighting strategy to emphasize valid pseudo-labels. We introduce a new regularization by gathering explicit depth distributions to constrain the model when facing real-world data. Experiments show that our method outperforms the state-of-the-art across diverse conditions in multi-frame and single-frame evaluations. We achieve improvements of 7.5% and 4.3% in AbsRel and RMSE on average for nuScenes and Robotcar datasets (daytime, nighttime, rain). In zero-shot evaluation of DrivingStereo (rain, fog), our method generalizes better than the previous ones.', 'abstract_zh': '单目相机在多样室外条件下的自监督深度估计：挑战与方法', 'title_zh': '基于运动和结构先验的合成到真实自监督稳健深度估计'}
{'arxiv_id': 'arXiv:2503.20207', 'title': 'Reasoning and Learning a Perceptual Metric for Self-Training of Reflective Objects in Bin-Picking with a Low-cost Camera', 'authors': 'Peiyuan Ni, Chee Meng Chew, Marcelo H. Ang Jr., Gregory S. Chirikjian', 'link': 'https://arxiv.org/abs/2503.20207', 'abstract': 'Bin-picking of metal objects using low-cost RGB-D cameras often suffers from sparse depth information and reflective surface textures, leading to errors and the need for manual labeling. To reduce human intervention, we propose a two-stage framework consisting of a metric learning stage and a self-training stage. Specifically, to automatically process data captured by a low-cost camera (LC), we introduce a Multi-object Pose Reasoning (MoPR) algorithm that optimizes pose hypotheses under depth, collision, and boundary constraints. To further refine pose candidates, we adopt a Symmetry-aware Lie-group based Bayesian Gaussian Mixture Model (SaL-BGMM), integrated with the Expectation-Maximization (EM) algorithm, for symmetry-aware filtering. Additionally, we propose a Weighted Ranking Information Noise Contrastive Estimation (WR-InfoNCE) loss to enable the LC to learn a perceptual metric from reconstructed data, supporting self-training on untrained or even unseen objects. Experimental results show that our approach outperforms several state-of-the-art methods on both the ROBI dataset and our newly introduced Self-ROBI dataset.', 'abstract_zh': '使用低成本RGB-D相机拾取金属物体的方法通常受到稀疏深度信息和反射表面纹理的影响，导致错误和需要手动标注。为降低人工干预，我们提出了一种两阶段框架，包括度量学习阶段和自我训练阶段。具体而言，为了自动处理低成本相机（LC）捕获的数据，我们引入了一种多目标姿态推理（MoPR）算法，该算法在深度、碰撞和边界约束下优化姿态假设。为了进一步细化姿态候选人，我们采用了一种基于Lie群的贝叶斯高斯混合模型（SaL-BGMM），并结合EM算法进行对称性意识过滤。此外，我们提出了一种加权排名信息噪声对比估计（WR-InfoNCE）损失，使LC能够从重构数据中学习感知度量，支持未训练或甚至未见过的物体的自我训练。实验结果表明，我们的方法在ROBI数据集和我们新引入的Self-ROBI数据集上均优于几种最先进的方法。', 'title_zh': '基于低成本摄像头的反射物体_bin-拾取_自训练感知度量推理与学习'}
{'arxiv_id': 'arXiv:2503.20202', 'title': 'SARGes: Semantically Aligned Reliable Gesture Generation via Intent Chain', 'authors': 'Nan Gao, Yihua Bao, Dongdong Weng, Jiayi Zhao, Jia Li, Yan Zhou, Pengfei Wan, Di Zhang', 'link': 'https://arxiv.org/abs/2503.20202', 'abstract': 'Co-speech gesture generation enhances human-computer interaction realism through speech-synchronized gesture synthesis. However, generating semantically meaningful gestures remains a challenging problem. We propose SARGes, a novel framework that leverages large language models (LLMs) to parse speech content and generate reliable semantic gesture labels, which subsequently guide the synthesis of meaningful co-speech this http URL, we constructed a comprehensive co-speech gesture ethogram and developed an LLM-based intent chain reasoning mechanism that systematically parses and decomposes gesture semantics into structured inference steps following ethogram criteria, effectively guiding LLMs to generate context-aware gesture labels. Subsequently, we constructed an intent chain-annotated text-to-gesture label dataset and trained a lightweight gesture label generation model, which then guides the generation of credible and semantically coherent co-speech gestures. Experimental results demonstrate that SARGes achieves highly semantically-aligned gesture labeling (50.2% accuracy) with efficient single-pass inference (0.4 seconds). The proposed method provides an interpretable intent reasoning pathway for semantic gesture synthesis.', 'abstract_zh': '同步语音手势生成通过语音同步手势合成增强人机交互的真实感。然而，生成语义相关的手势依然是一个具有挑战性的问题。我们提出了SARGes，这是一个利用大型语言模型（LLMs）解析语音内容并生成可靠语义手势标签的新型框架，这些标签随后指导有意义同步语音手势的合成。为了实现这一目标，我们构建了一个全面的同步语音手势志数组，并开发了一种基于LLM的意图链推理机制，该机制系统地按照志数组标准解析和分解手势语义为结构化的推理步骤，有效地指导大型语言模型生成上下文感知的手势标签。随后，我们构建了一个带有意图链标注的文字到手势标签数据集，并训练了一个轻量级的手势标签生成模型，该模型随后指导生成具有可信度和语义一致性的同步语音手势。实验结果表明，SARGes实现了高度语义对齐的手势标注（准确率50.2%）和高效的单次推理（0.4秒）。所提出的方法为语义手势合成提供了可解释的意图推理路径。', 'title_zh': '基于意图链的语义对齐可靠手势生成'}
{'arxiv_id': 'arXiv:2503.20176', 'title': 'Offline Reinforcement Learning with Discrete Diffusion Skills', 'authors': 'RuiXi Qiao, Jie Cheng, Xingyuan Dai, Yonglin Tian, Yisheng Lv', 'link': 'https://arxiv.org/abs/2503.20176', 'abstract': 'Skills have been introduced to offline reinforcement learning (RL) as temporal abstractions to tackle complex, long-horizon tasks, promoting consistent behavior and enabling meaningful exploration. While skills in offline RL are predominantly modeled within a continuous latent space, the potential of discrete skill spaces remains largely underexplored. In this paper, we propose a compact discrete skill space for offline RL tasks supported by state-of-the-art transformer-based encoder and diffusion-based decoder. Coupled with a high-level policy trained via offline RL techniques, our method establishes a hierarchical RL framework where the trained diffusion decoder plays a pivotal role. Empirical evaluations show that the proposed algorithm, Discrete Diffusion Skill (DDS), is a powerful offline RL method. DDS performs competitively on Locomotion and Kitchen tasks and excels on long-horizon tasks, achieving at least a 12 percent improvement on AntMaze-v2 benchmarks compared to existing offline RL approaches. Furthermore, DDS offers improved interpretability, training stability, and online exploration compared to previous skill-based methods.', 'abstract_zh': '离线 reinforcement learning任务中基于Transformer编码器和扩散解码器的紧凑离散技能空间', 'title_zh': '离线强化学习中的离散扩散技能'}
{'arxiv_id': 'arXiv:2503.20105', 'title': 'Direct Post-Training Preference Alignment for Multi-Agent Motion Generation Models Using Implicit Feedback from Pre-training Demonstrations', 'authors': 'Ran Tian, Kratarth Goel', 'link': 'https://arxiv.org/abs/2503.20105', 'abstract': "Recent advancements in LLMs have revolutionized motion generation models in embodied applications. While LLM-type auto-regressive motion generation models benefit from training scalability, there remains a discrepancy between their token prediction objectives and human preferences. As a result, models pre-trained solely with token-prediction objectives often generate behaviors that deviate from what humans would prefer, making post-training preference alignment crucial for producing human-preferred motions. Unfortunately, post-training alignment requires extensive preference rankings of motions generated by the pre-trained model, which are costly to annotate, especially in multi-agent settings. Recently, there has been growing interest in leveraging pre-training demonstrations to scalably generate preference data for post-training alignment. However, these methods often adopt an adversarial assumption, treating all pre-trained model-generated samples as unpreferred examples. This adversarial approach overlooks the valuable signal provided by preference rankings among the model's own generations, ultimately reducing alignment effectiveness and potentially leading to misaligned behaviors. In this work, instead of treating all generated samples as equally bad, we leverage implicit preferences encoded in pre-training demonstrations to construct preference rankings among the pre-trained model's generations, offering more nuanced preference alignment guidance with zero human cost. We apply our approach to large-scale traffic simulation and demonstrate its effectiveness in improving the realism of pre-trained model's generated behaviors, making a lightweight 1M motion generation model comparable to SOTA large imitation-based models by relying solely on implicit feedback from pre-training demonstrations, without additional post-training human preference annotations or high computational costs.", 'abstract_zh': "Recent advancements in LLMs have revolutionized motion generation models in embodied applications. While LLM-type auto-regressive motion generation models benefit from training scalability, there remains a discrepancy between their token prediction objectives and human preferences. As a result, models pre-trained solely with token-prediction objectives often generate behaviors that deviate from what humans would prefer, making post-training preference alignment crucial for producing human-preferred motions. Unfortunately, post-training alignment requires extensive preference rankings of motions generated by the pre-trained model, which are costly to annotate, especially in multi-agent settings. Recently, there has been growing interest in leveraging pre-training demonstrations to scalably generate preference data for post-training alignment. However, these methods often adopt an adversarial assumption, treating all pre-trained model-generated samples as unpreferred examples. This adversarial approach overlooks the valuable signal provided by preference rankings among the model's own generations, ultimately reducing alignment effectiveness and potentially leading to misaligned behaviors. In this work, instead of treating all generated samples as equally bad, we leverage implicit preferences encoded in pre-training demonstrations to construct preference rankings among the pre-trained model's generations, offering more nuanced preference alignment guidance with zero human cost. We apply our approach to large-scale traffic simulation and demonstrate its effectiveness in improving the realism of pre-trained model's generated behaviors, making a lightweight 1M motion generation model comparable to SOTA large imitation-based models by relying solely on implicit feedback from pre-training demonstrations, without additional post-training human preference annotations or high computational costs。", 'title_zh': '直接训练后偏好对齐：使用预训练示范的隐式反馈用于多智能体运动生成模型'}
{'arxiv_id': 'arXiv:2503.20102', 'title': 'Extendable Long-Horizon Planning via Hierarchical Multiscale Diffusion', 'authors': 'Chang Chen, Hany Hamed, Doojin Baek, Taegu Kang, Yoshua Bengio, Sungjin Ahn', 'link': 'https://arxiv.org/abs/2503.20102', 'abstract': 'This paper tackles a novel problem, extendable long-horizon planning-enabling agents to plan trajectories longer than those in training data without compounding errors. To tackle this, we propose the Hierarchical Multiscale Diffuser (HM-Diffuser) and Progressive Trajectory Extension (PTE), an augmentation method that iteratively generates longer trajectories by stitching shorter ones. HM-Diffuser trains on these extended trajectories using a hierarchical structure, efficiently handling tasks across multiple temporal scales. Additionally, we introduce Adaptive Plan Pondering and the Recursive HM-Diffuser, which consolidate hierarchical layers into a single model to process temporal scales recursively. Experimental results demonstrate the effectiveness of our approach, advancing diffusion-based planners for scalable long-horizon planning.', 'abstract_zh': '本文解决了一个新颖的问题，使可扩展长时间规划的智能体能够在不累积误差的情况下规划比训练数据更长的轨迹。为此，我们提出了一种层次多尺度扩散器（HM-Diffuser）和渐进轨迹扩展（PTE）方法，该方法通过缝合较短的轨迹来迭代生成更长的轨迹。HM-Diffuser使用层次结构在这些扩展的轨迹上进行训练，高效地处理多种时空尺度的任务。此外，我们还引入了自适应计划沉思和递归层次多尺度扩散器，将层次结构中的多个层合并为一个模型以递归处理时空尺度。实验结果展示了我们方法的有效性，推动了基于扩散的规划器在可扩展长时间规划中的应用。', 'title_zh': '基于分层多尺度扩散的可扩展长时规划'}
{'arxiv_id': 'arXiv:2503.20011', 'title': 'Hyperdimensional Uncertainty Quantification for Multimodal Uncertainty Fusion in Autonomous Vehicles Perception', 'authors': 'Luke Chen, Junyao Wang, Trier Mortlock, Pramod Khargonekar, Mohammad Abdullah Al Faruque', 'link': 'https://arxiv.org/abs/2503.20011', 'abstract': 'Uncertainty Quantification (UQ) is crucial for ensuring the reliability of machine learning models deployed in real-world autonomous systems. However, existing approaches typically quantify task-level output prediction uncertainty without considering epistemic uncertainty at the multimodal feature fusion level, leading to sub-optimal outcomes. Additionally, popular uncertainty quantification methods, e.g., Bayesian approximations, remain challenging to deploy in practice due to high computational costs in training and inference. In this paper, we propose HyperDUM, a novel deterministic uncertainty method (DUM) that efficiently quantifies feature-level epistemic uncertainty by leveraging hyperdimensional computing. Our method captures the channel and spatial uncertainties through channel and patch -wise projection and bundling techniques respectively. Multimodal sensor features are then adaptively weighted to mitigate uncertainty propagation and improve feature fusion. Our evaluations show that HyperDUM on average outperforms the state-of-the-art (SOTA) algorithms by up to 2.01%/1.27% in 3D Object Detection and up to 1.29% improvement over baselines in semantic segmentation tasks under various types of uncertainties. Notably, HyperDUM requires 2.36x less Floating Point Operations and up to 38.30x less parameters than SOTA methods, providing an efficient solution for real-world autonomous systems.', 'abstract_zh': '多模态特征融合中的不确定性量化：HyperDUM方法', 'title_zh': '基于自主车辆感知中多模态不确定性融合的超维度不确定性量化'}
