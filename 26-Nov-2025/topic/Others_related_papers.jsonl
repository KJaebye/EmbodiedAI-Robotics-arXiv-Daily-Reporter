{'arxiv_id': 'arXiv:2511.20586', 'title': 'PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic', 'authors': 'Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Dennis Eisermann, Frank Kargl', 'link': 'https://arxiv.org/abs/2511.20586', 'abstract': 'Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.', 'abstract_zh': '可信度已成为在关键安全应用中部署人工智能系统的关键要求。传统的评估指标如准确率和精确率无法捕捉模型预测的不确定性或可靠性，尤其是在对抗或降级条件下。本文介绍了\\emph{并行可信度评估系统(PaTAS)}，这是一种使用主观逻辑(SL)建模和传播神经网络可信度的框架。PaTAS 通过并行于标准神经计算的\\emph{可信节点}和\\emph{可信函数}，在网络中传播输入、参数和激活的可信度。该框架定义了\\emph{参数可信度更新}机制以在训练期间细化参数可靠性，并定义了\\emph{推理路径可信度评估(IPTA)}方法以在推理期间计算实例特定的可信度。在实际数据集和对抗数据集上的实验表明，PaTAS 产生可解释、对称且收敛的可信度估计，这些估计补充了准确率并揭示了中毒、偏见或不确定数据场景中的可靠性差距。结果显示，PaTAS 有效地区分了良性输入和对抗输入，并指出了模型信心与实际可靠性不一致的情况。通过在神经架构中启用透明且可量化的可信度推理，PaTAS 为评估全生命周期中模型的可靠性提供了原则性的基础。', 'title_zh': 'PaTAS: 一种基于主观逻辑的神经网络信任传播并行系统'}
{'arxiv_id': 'arXiv:2511.20510', 'title': 'FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization', 'authors': 'Yuto Suzuki, Paul Awolade, Daniel V. LaBarbera, Farnoush Banaei-Kashani', 'link': 'https://arxiv.org/abs/2511.20510', 'abstract': 'Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a "vocabulary selection" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA\'s Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.', 'abstract_zh': '使用生成AI进行分子生成在药物发现中至关重要，然而类特定的数据集往往包含少于100个训练样本。尽管基于片段的模型在处理有限数据方面优于基于原子的方法，现有的启发式片段化方法限制了多样性和关键片段的遗漏。此外，模型调优通常需要 medicinal 化学家和AI工程师之间缓慢的间接合作。我们引入了 FRAGMENTA，这是一种用于药物先导优化的端到端框架，包括：1）一种新颖的生成模型，将片段化重新定义为“词汇选择”问题，并使用动态Q学习联合优化片段化和生成；2）一种通过领域专家的对话反馈来优化目标的自主AI系统。该系统将AI工程师从循环中移除，并逐步学习领域知识以最终实现自动化调优。在实际的癌症药物发现实验中，FRAGMENTA 的人-机配置比基线方法识别出几乎多一倍的高评分分子。此外，完全自主的机-机系统优于传统的人-人调优，证明了代理调优在捕捉专家意图方面的有效性。', 'title_zh': 'FRAGMENTA：基于片段的端到端生成模型与自主调谐在药物先导优化中的应用'}
{'arxiv_id': 'arXiv:2511.20497', 'title': 'Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic', 'authors': 'Van Tran, Shinan Liu, Tian Li, Nick Feamster', 'link': 'https://arxiv.org/abs/2511.20497', 'abstract': 'To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.', 'abstract_zh': '为应对网络流量数据稀缺性和隐私担忧，已经开发了各种生成模型以生成合成流量。然而，合成流量本身并不天然具备隐私保护特性，其泄露敏感信息的程度及如何衡量这种泄露仍然鲜有探讨。模型架构的多样性进一步加剧了这一挑战，不同的架构影响流量的表示和合成方式。我们引入了一套全面的隐私度量标准，结合了如成员推理攻击（MIA）和数据提取攻击等标准方法，同时纳入了特定于网络的标识符和属性。利用这些度量标准，我们系统地评估了不同代表性生成模型的安全性，并考察了影响攻击成功的因素。研究结果揭示了模型和数据集间在隐私风险上的显著差异。MIA的成功率范围为0%至88%，并且高达100%的网络标识符可以从生成的流量中恢复，突显出严重的隐私漏洞。我们还识别出显著影响攻击结果的关键因素，包括训练数据的多样性以及生成模型与训练数据的匹配程度。这些发现为设计和部署能减少隐私泄露的生成模型提供了实用的指导，并为更安全的合成网络流量生成奠定了基础。', 'title_zh': '量化高保真合成网络流量的隐私影响'}
{'arxiv_id': 'arXiv:2511.20321', 'title': 'Active Inference in Discrete State Spaces from First Principles', 'authors': 'Patrick Kenny', 'link': 'https://arxiv.org/abs/2511.20321', 'abstract': 'We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.', 'abstract_zh': '我们通过将主动推断与自由能原理区分开来，旨在澄清主动推断的概念。我们展示了在离散状态空间中实现主动推断所需的优化可以被形式化为约束差异最小化问题，这些问题可以通过标准的均场方法求解，而不依赖于预期自由能的概念。当我们使用它来建模感知时，我们提出的感知/行动差异准则与变分自由能重合；当我们使用它来建模行动时，它与预期自由能函数相差一个熵正则化项。', 'title_zh': '从基本原理出发的离散状态空间中的主动推断'}
{'arxiv_id': 'arXiv:2511.20312', 'title': 'Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries', 'authors': 'Alexander Beiser, Flavio Martinelli, Wulfram Gerstner, Johanni Brea', 'link': 'https://arxiv.org/abs/2511.20312', 'abstract': "Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.", 'abstract_zh': '给定足够的网络输入-输出样本，网络权重可以反向工程还原。在教师-学生设置中，这相当于收集教师映射的数据集——查询教师——并拟合学生以模仿这种映射。对教师训练数据的合理选择作为查询。但当前方法在教师参数多于训练数据时失败，因为学生过度拟合查询而非调整其参数以匹配教师。在本工作中，我们探索增强技术以最佳地采样教师网络的输入-输出映射，目标是从教师隐藏层中激发丰富的表示集。我们发现，标准增强方法如旋转、翻转和添加噪声对识别问题几乎没有改善。我们设计了新的数据增强技术，以更好地采样网络隐藏层的表示空间。借助我们的增强技术，我们扩展了可恢复的网络规模的最新技术水平。为了测试其可扩展性，我们展示了可以恢复参数数量高达训练数据点100倍的网络。', 'title_zh': '从输入-输出查询逆向工程神经网络权重的数据增强技术'}
{'arxiv_id': 'arXiv:2511.20285', 'title': 'SMoG: Schema Matching on Graph', 'authors': 'Mingyu Jeon, Jaeyoung Suh, Suwan Cho', 'link': 'https://arxiv.org/abs/2511.20285', 'abstract': 'Schema matching is a critical task in data integration, par- ticularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suf- fer from hallucination and lack of up-to-date domain knowl- edge. Knowledge Graphs (KGs) offer a solution by pro- viding structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iter- ative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question An- swering (KGQA). SMoG enhances explainability and relia- bility by generating human-verifiable query paths while sig- nificantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world med- ical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effec- tiveness and efficiency in KG-augmented schema matching.', 'abstract_zh': '基于图的模式匹配（SMoG）', 'title_zh': 'SMoG: 图结构模式匹配'}
{'arxiv_id': 'arXiv:2511.20236', 'title': 'Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints', 'authors': 'Szymon Bobek, Łukasz Bałec, Grzegorz J. Nalepa', 'link': 'https://arxiv.org/abs/2511.20236', 'abstract': 'Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.', 'abstract_zh': '基于特征依赖和因果约束的多样、可行、知识约束反事实解释方法（Diverse, Actionable, and Knowledge-Constrained Explanations, DANCE）', 'title_zh': '包含领域知识和因果约束的可操作且多样的反事实解释'}
{'arxiv_id': 'arXiv:2511.20138', 'title': 'From data to concepts via wiring diagrams', 'authors': 'Jason Lo, Mohammadnima Jafari', 'link': 'https://arxiv.org/abs/2511.20138', 'abstract': 'A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.', 'abstract_zh': '一种伪骨架 wiring 图表是标记有向图的一种类型，用于表示如时间过程这样的抽象概念。本文引入了伪骨架 wiring 图表图的概念，并证明伪骨架 wiring 图表图对应哈斯图。利用该结果，我们设计了从序列数据中提取 wiring 图表的算法。我们在分析自主代理玩计算机游戏的行为时使用了这些算法，并且算法正确地识别出了获胜策略。我们将主要算法的性能与基于标准聚类技术（DBSCAN 和凝聚层次聚类）的两种其他算法进行了比较，包括在部分数据受到扰动的情况下。总体而言，本文将范畴论、图论、聚类、强化学习和数据工程等技术结合起来。', 'title_zh': '从数据到概念 via 连接图'}
{'arxiv_id': 'arXiv:2511.19864', 'title': 'MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support', 'authors': 'Valerie Lockhart, Dan McCreary, Troy A. Peterson', 'link': 'https://arxiv.org/abs/2511.19864', 'abstract': 'Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.', 'abstract_zh': '基于人工智能的轻量级互动教育模拟：MicroSims框架及其应用', 'title_zh': 'MicroSims：一种基于通用嵌入和自适应学习支持的AI生成可扩展教育模拟框架'}
{'arxiv_id': 'arXiv:2511.19829', 'title': 'A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization', 'authors': 'Ke Chen, Yifeng Wang, Hassan Almosapeeh, Haohan Wang', 'link': 'https://arxiv.org/abs/2511.19829', 'abstract': 'Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.', 'abstract_zh': '大多数提示优化方法仅精炼单一静态模板，在复杂和动态用户场景中效果不佳。现有查询依赖方法依赖不稳定的文本反馈或黑盒奖励模型，提供的优化信号较弱且不可解释。更根本的是，提示质量本身缺乏统一、系统的定义，导致评价信号碎片化且不可靠。我们的方法首先建立了一个以性能为导向、系统且全面的提示评价框架。此外，我们开发并微调了一个无需执行的评价器，可以直接从文本预测多维度的质量评分。该评价器然后指导一个具有度量意识的优化器，诊断失败模式并以可解释且查询依赖的方式重写提示。我们的评价器在预测提示性能方面表现最佳，评价引导的优化在八个数据集和三种主干模型上始终超过静态模板和查询依赖基准。总体而言，我们提出了一种统一且基于度量的提示质量视角，并证明了评价引导的优化流水线在多种任务中提供了稳定、可解释且模型无关的改进。', 'title_zh': '统一的评估指导框架：针对查询的提示优化'}
{'arxiv_id': 'arXiv:2511.19780', 'title': 'NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents', 'authors': 'Ioannis Tzachristas, Aifen Sui', 'link': 'https://arxiv.org/abs/2511.19780', 'abstract': 'We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.', 'abstract_zh': '一种集成结构化意图本体与紧凑语言模型的神经符号框架：多意图理解在移动AI代理中的应用', 'title_zh': 'NOEM$^{3}$A：一种基于神经符号本体增强的移动代理多意图理解方法'}
{'arxiv_id': 'arXiv:2511.19669', 'title': 'HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization', 'authors': 'Souradip Poddar, Chia-Tung Ho, Ziming Wei, Weidong Cao, Haoxing Ren, David Z. Pan', 'link': 'https://arxiv.org/abs/2511.19669', 'abstract': 'Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.', 'abstract_zh': '传统的基于AI的AMS设计自动化算法仍受限于对高质量数据集的依赖以捕捉电路行为，且在架构间迁移能力差，并缺乏适应机制。本文提出HeaRT，一个基础推理引擎，旨在实现智能化、自适应的人类风格设计优化，并为此迈出了第一步。', 'title_zh': 'HeaRT：一种基于层次电路推理树的自主设计优化框架 for AMS 设计优化'}
{'arxiv_id': 'arXiv:2511.20629', 'title': 'MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models', 'authors': 'Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi, Yue Zhao, Yinan Zhao, Hui Qu, Wei-An Lin, Yiru Shen, Ajinkya Kale, Irfan Essa, Humphrey Shi', 'link': 'https://arxiv.org/abs/2511.20629', 'abstract': 'Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this, we introduce two complementary methods: MapReduce LoRA and Reward-aware Token Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in parallel and iteratively merges them to refine a shared base model; RaTE learns reward-specific token embeddings that compose at inference for flexible preference control. Experiments on Text-to-Image generation (Stable Diffusion 3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and 32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On Text-to-Video generation (HunyuanVideo), visual and motion quality improve by 48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our framework sets a new state-of-the-art multi-preference alignment recipe across modalities.', 'abstract_zh': '基于奖励模型的人工反馈强化学习（RLHF）推动了生成模型与人类审美和感知偏好的对齐。然而，联合优化多个奖励往往会导致一种偏好的改进而牺牲其他偏好。为了解决这个问题，我们介绍了两种互补的方法：MapReduce LoRA和奖励感知的标记嵌入（RaTE）。MapReduce LoRA并行训练特定偏好的LoRA专家，并迭代合并它们以精炼共享基础模型；RaTE在推理时学习特定于奖励的标记嵌入，以灵活控制偏好。在Text-to-Image生成（Stable Diffusion 3.5 Medium和FLUX.1-dev）实验中，GenEval、PickScore和OCR分别提高了36.1%、4.6%和55.7%，以及32.7%、4.3%和67.1%。在Text-to-Video生成（HunyuanVideo）中，视觉和运动质量分别提高了48.1%和90.0%。在语言任务中，有帮助的助手（使用Llama-2 7B），有帮助性和无害性分别提高了43.4%和136.7%。我们的框架在跨模态多偏好对齐方面设立了新的最先进的方法。', 'title_zh': 'MapReduce LoRA: 推动生成模型多偏好优化帕累托前沿的提升'}
{'arxiv_id': 'arXiv:2511.20601', 'title': 'The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting', 'authors': 'Heman Shakeri', 'link': 'https://arxiv.org/abs/2511.20601', 'abstract': 'Deep sequence models for blood glucose forecasting consistently fail to leverage clinically informative drivers--insulin, meals, and activity--despite well-understood physiological mechanisms. We term this Driver-Blindness and formalize it via $\\Delta_{\\text{drivers}}$, the performance gain of multivariate models over matched univariate baselines. Across the literature, $\\Delta_{\\text{drivers}}$ is typically near zero. We attribute this to three interacting factors: architectural biases favoring autocorrelation (C1), data fidelity gaps that render drivers noisy and confounded (C2), and physiological heterogeneity that undermines population-level models (C3). We synthesize strategies that partially mitigate Driver-Blindness--including physiological feature encoders, causal regularization, and personalization--and recommend that future work routinely report $\\Delta_{\\text{drivers}}$ to prevent driver-blind models from being considered state-of-the-art.', 'abstract_zh': '深度序列模型在血糖预测中一致未能利用临床相关信息驱动因素——胰岛素、餐饮和活动——尽管存在明确的生理机制。我们称其为“驱动因素失明”，并通过$\\Delta_{\\text{drivers}}$的形式化定义来表示——即多元模型相对于匹配的一元基线模型的性能提升——来表述这一现象。在文献中，$\\Delta_{\\text{drivers}}$通常接近零。我们将其归因于三个相互作用的因素：有利于自相关性的架构偏见（C1）、数据保真度差距导致驱动因素噪声和混杂（C2），以及生理异质性阻碍了群体水平模型（C3）。我们综合了部分缓解驱动因素失明的策略——包括生理学特征编码器、因果正则化和个人化——并建议未来的研究常规报告$\\Delta_{\\text{drivers}}$，以防止驱动因素失明的模型被认为是最新技术。', 'title_zh': '驾驶员盲区现象：为什么深度序列模型在血糖预测中默认采用自相关性'}
{'arxiv_id': 'arXiv:2511.20597', 'title': 'BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents', 'authors': 'Kaiyuan Zhang, Mark Tenenholtz, Kyle Polley, Jerry Ma, Denis Yarats, Ninghui Li', 'link': 'https://arxiv.org/abs/2511.20597', 'abstract': 'The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.\nIn this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes beyond prior work by emphasizing injections that can influence real-world actions rather than mere text outputs, and by presenting attack payloads with complexity and distractor frequency similar to what real-world agents encounter. We leverage this benchmark to conduct a comprehensive empirical evaluation of existing defenses, assessing their effectiveness across a suite of frontier AI models. We propose a multi-layered defense strategy comprising both architectural and model-based defenses to protect against evolving prompt injection attacks. Our work offers a blueprint for designing practical, secure web agents through a defense-in-depth approach.', 'abstract_zh': '将人工智能代理集成到网络浏览器中引入了超越传统网络应用威胁模型的安全挑战。先前的研究已经识别出提示注入作为一个新的针对网络代理的攻击向量，但其在真实环境中的影响仍然不充分地理解。\n\n在这项工作中，我们探讨了提示注入攻击的景观，并综合了一个嵌入在现实HTML载荷中的攻击基准。我们的基准超越了先前的工作，强调了那些能够影响实际操作的注入，而非仅仅影响文本输出，并且提供了与真实世界代理所遇到的复杂性及干扰频率相似的攻击载荷。我们利用这个基准进行现有防护措施的全面实证评估，测试其在一系列前沿AI模型中的有效性。我们提出了一种多层次的防御策略，包括架构性和模型基的防御措施，以对抗不断演化的提示注入攻击。我们的工作为通过多层次防御方法设计实用且安全的网络代理提供了范例。', 'title_zh': 'BrowseSafe：了解和防止AI浏览器代理中的提示注入'}
{'arxiv_id': 'arXiv:2511.20590', 'title': 'EnergyTwin: A Multi-Agent System for Simulating and Coordinating Energy Microgrids', 'authors': 'Jakub Muszyński, Ignacy Walużenicz, Patryk Zan, Zofia Wrona, Maria Ganzha, Marcin Paprzycki, Costin Bădică', 'link': 'https://arxiv.org/abs/2511.20590', 'abstract': 'Microgrids are deployed to reduce purchased grid energy, limit exposure to volatile tariffs, and ensure service continuity during disturbances. This requires coordinating heterogeneous distributed energy resources across multiple time scales and under variable conditions. Among existing tools, typically, power-system simulators capture physical behaviour but assume centralized control, while multi-agent frameworks model decentralized decision-making but represent energy with no physical grounding. In this context, the EnergyTwin is introduced, an agent-based microgrid simulation environment that couples physically grounded models with forecast-informed, rolling-horizon planning, and negotiations. Each asset is modeled as an agent, interacting with a central agent that obtains forecasts, formulates predictions, and allocates energy through contract-based interactions. EnergyTwin targets tertiary-layer decision making and is extensible for digital-twin use. Its feasibility was evaluated in a university campus microgrid scenario where multiple planning strategies were compared. Achieved results show that forecast-driven rolling-horizon planning increases local energy self-sufficiency, maintains higher battery reserves, and reduces exposure to low-resilience operating states. They demonstrate also potential of EnergyTwin as platform supporting research on resilient, negotiation-driven microgrids.', 'abstract_zh': '微型电网中的能量孪生体：融合物理基础模型与预测驱动滚动最优规划及谈判的代理代理环境', 'title_zh': 'EnergyTwin: 一种模拟和协调微电网的多Agent系统'}
{'arxiv_id': 'arXiv:2511.20551', 'title': 'Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of Cavitation Activity', 'authors': 'Tatiana Gelvez-Barrera, Barbara Nicolas, Denis Kouamé, Bruno Gilles, Adrian Basarab', 'link': 'https://arxiv.org/abs/2511.20551', 'abstract': 'Passive acoustic mapping enables the spatial mapping and temporal monitoring of cavitation activity, playing a crucial role in therapeutic ultrasound applications. Most conventional beamforming methods, whether implemented in the time or frequency domains, suffer from limited axial resolution due to the absence of a reference emission onset time. While frequency-domain methods, the most efficient of which are based on the cross-spectral matrix, require long signals for accurate estimation, time-domain methods typically achieve lower spatial resolution. To address these limitations, we propose a linear model-based beamforming framework fully formulated in the time domain. The linear forward model relates a discretized spatiotemporal distribution of cavitation activity to the temporal signals recorded by a probe, explicitly accounting for time-of-flight delays dictated by the acquisition geometry. This model is then inverted using regularization techniques that exploit prior knowledge of cavitation activity in both spatial and temporal domains. Experimental results show that the proposed framework achieves enhanced or competitive cavitation map quality while using only 20\\% of the data typically required by frequency-domain methods. This highlights the substantial gain in data efficiency and the flexibility of our spatiotemporal regularization to adapt to diverse passive cavitation scenarios, outperforming state-of-the-art techniques.', 'abstract_zh': '基于时间域的线性模型导向声学成像框架 enable 无创声学成像在空腔活动的空间映射和时间监测中的应用，对于治疗超声应用至关重要。', 'title_zh': '基于时域线性模型的被动声学空泡活动mapping框架'}
{'arxiv_id': 'arXiv:2511.20540', 'title': 'Proceedings Twentieth Conference on Theoretical Aspects of Rationality and Knowledge', 'authors': 'Adam Bjorndahl', 'link': 'https://arxiv.org/abs/2511.20540', 'abstract': 'The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a conference that aims to bring together researchers from a wide variety of fields, including computer science, artificial intelligence, game theory, decision theory, philosophy, logic, linguistics, and cognitive science. Its goal is to further our understanding of interdisciplinary issues involving reasoning about rationality and knowledge.\nPrevious conferences have been held biennially around the world since 1986, on the initiative of Joe Halpern (Cornell University). Topics of interest include, but are not limited to, semantic models for knowledge, belief, uncertainty, awareness, bounded rationality, common sense epistemic reasoning, epistemic logic, epistemic game theory, knowledge and action, applications of reasoning about knowledge and other mental states, belief revision, computational social choice, algorithmic game theory, and foundations of multi-agent systems.\nInformation about TARK is available at this http URL.\nThese proceedings contain the papers that have been accepted for presentation at the Twentieth Conference on Theoretical Aspects of Rationality and Knowledge (TARK 2025), held July 14--16, 2025, at Heinrich-Heine-Universität, Düsseldorf, Germany. The conference website can be found at this https URL.', 'abstract_zh': 'TARK会议（理性和知识的理论方面）是一个旨在汇聚来自计算机科学、人工智能、博弈论、决策理论、哲学、逻辑学、语言学和认知科学等多个领域的研究者们的会议。其目标是增进我们对涉及理性与知识的跨学科问题的理解。自1986年起，在Joe Halpern教授（康奈尔大学）的倡议下，会议每两年在全球各地举办一次。会议主题包括但不限于知识、信念、不确定性、意识、有限理性、常识性知识推理、知识逻辑、知识博弈论、知识与行动、关于知识及其他心理状态的推理的应用、信念更新、计算社会选择、算法博弈论以及多智能体系统的基础。有关TARK的信息可参见此网址。这些会议论文集包含了在2025年7月14日至16日于德国杜塞尔多夫的 Heinrich-Heine-Universität举办的第二十届理性和知识的理论方面会议（TARK 2025）上被接受的论文。会议网址可参见此网址。', 'title_zh': '第二十届理性与知识理论方面会议 proceedings'}
{'arxiv_id': 'arXiv:2511.20513', 'title': 'DesignPref: Capturing Personal Preferences in Visual Design Generation', 'authors': 'Yi-Hao Peng, Jeffrey P. Bigham, Jason Wu', 'link': 'https://arxiv.org/abs/2511.20513', 'abstract': "Generative models, such as large language models and text-to-image diffusion models, are increasingly used to create visual designs like user interfaces (UIs) and presentation slides. Finetuning and benchmarking these generative models have often relied on datasets of human-annotated design preferences. Yet, due to the subjective and highly personalized nature of visual design, preference varies widely among individuals. In this paper, we study this problem by introducing DesignPref, a dataset of 12k pairwise comparisons of UI design generation annotated by 20 professional designers with multi-level preference ratings. We found that among trained designers, substantial levels of disagreement exist (Krippendorff's alpha = 0.25 for binary preferences). Natural language rationales provided by these designers indicate that disagreements stem from differing perceptions of various design aspect importance and individual preferences. With DesignPref, we demonstrate that traditional majority-voting methods for training aggregated judge models often do not accurately reflect individual preferences. To address this challenge, we investigate multiple personalization strategies, particularly fine-tuning or incorporating designer-specific annotations into RAG pipelines. Our results show that personalized models consistently outperform aggregated baseline models in predicting individual designers' preferences, even when using 20 times fewer examples. Our work provides the first dataset to study personalized visual design evaluation and support future research into modeling individual design taste.", 'abstract_zh': '生成模型，如大型语言模型和文本到图像扩散模型，越来越多地用于创建用户界面（UI）和演示文稿等视觉设计。这些生成模型的微调和基准测试通常依赖于人类标注设计偏好的数据集。然而，由于视觉设计的高度主观性和个性化，不同个体之间的偏好差异很大。在本文中，我们通过引入由20名专业设计师进行注释的包含12k组图设计比较的DesignPref数据集来研究这一问题，并给出了多级偏好评分。我们发现，在受过训练的设计师中，存在显著的分歧（二元偏好Krippendorff’s α = 0.25）。这些设计师提供的自然语言理由表明，分歧源于对各种设计方面重要性的不同看法和个体偏好的差异。通过DesignPref，我们展示了传统的多数投票方法在训练集成评判模型时往往不能准确反映个体偏好。为了解决这一挑战，我们研究了多种个性化策略，特别是针对设计师特定注释进行微调或将其纳入RAG管道。我们的结果显示，个性化模型在预测个别设计师的偏好方面始终优于使用较少示例的集成基线模型。我们的研究提供了首个研究个性化视觉设计评估的数据集，并支持未来关于建模个人设计品味的研究。', 'title_zh': 'DesignPref: 在视觉设计生成中捕捉个人偏好'}
{'arxiv_id': 'arXiv:2511.20500', 'title': 'From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection', 'authors': 'Sidahmed Benabderrahmane, Talal Rahwan', 'link': 'https://arxiv.org/abs/2511.20500', 'abstract': 'Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to their stealth, persistence, and adaptability. Traditional machine learning detectors struggle with class imbalance, high dimensional features, and scarce real world traces. They often lack transferability-performing well in the training domain but degrading in novel attack scenarios. We propose a hybrid transfer framework that integrates Transfer Learning, Explainable AI (XAI), contrastive learning, and Siamese networks to improve cross-domain generalization. An attention-based autoencoder supports knowledge transfer across domains, while Shapley Additive exPlanations (SHAP) select stable, informative features to reduce dimensionality and computational cost. A Siamese encoder trained with a contrastive objective aligns source and target representations, increasing anomaly separability and mitigating feature drift. We evaluate on real-world traces from the DARPA Transparent Computing (TC) program and augment with synthetic attack scenarios to test robustness. Across source to target transfers, the approach delivers improved detection scores with classical and deep baselines, demonstrating a scalable, explainable, and transferable solution for APT detection.', 'abstract_zh': '高级持续威胁（APT）由于其隐蔽性、持久性和适应性，给网络安全带来了重大挑战。传统的机器学习检测器在处理类别不平衡、高维特征以及稀缺的真实世界示例时存在困难，往往在训练域中表现良好，但在新的攻击场景中会退化。我们提出了一种集成迁移学习、可解释AI（XAI）、对比学习和Siamese网络的混合迁移框架，以提高跨域泛化能力。基于注意力机制的自编码器支持跨域的知识迁移，而Shapley值加性解释（SHAP）选择稳定且富有信息量的特征以减少维度和计算成本。使用对比学习目标训练的Siamese编码器对源域和目标域的表示进行对齐，增加了异常值的可区分性和缓解了特征漂移。我们在DARPA透明计算（TC）计划的真实世界示例上进行评估，并通过添加合成攻击场景测试鲁棒性。在源域到目标域的转移中，该方法在经典和深度基线下实现了更好的检测分数，展示了可扩展、可解释且可迁移的APT检测解决方案。', 'title_zh': '从一个攻击领域到另一个领域：基于卷积对比迁移学习的高级持续威胁检测'}
{'arxiv_id': 'arXiv:2511.20490', 'title': 'MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology', 'authors': 'Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne', 'link': 'https://arxiv.org/abs/2511.20490', 'abstract': 'Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.', 'abstract_zh': '多模态大型语言模型（LLMs）在生物医学推理领域展现出前景，但现有基准未能捕捉到真实临床工作流程的复杂性。现有评估主要侧重于单模态、去情境化的问答任务，忽略了许多多智能体决策环境，如分子肿瘤板（MTBs）。MTBs集合了肿瘤学领域的多元专家，诊断和预后任务需要整合异质数据并随时间演化洞见。当前基准缺乏这一纵向和多模态的复杂性。我们引入了MTBBench，这是一个通过临床挑战性、多模态和纵向肿瘤学问题模拟MTB风格决策的代理基准。真实标注由临床专家通过共同开发的应用程序验证，确保临床相关性。我们对标记多个开源和闭源的LLM进行基准测试，并显示即使在大规模应用中，它们也缺乏可靠性——经常产生幻觉，难以处理来自时间化数据的推理，无法调和冲突证据或不同模态。为解决这些局限性，MTBBench通过提供基于基础模型的代理框架和工具，超越了单纯的基准测试，实现了多模态和纵向推理能力的提升，分别在任务层面取得了高达9.0%和11.2%的性能增益。总体而言，MTBBench提供了旨在推进多模态LLM推理、可靠性和工具使用，并重点关注精准肿瘤学MTB环境的具有挑战性和现实性的测试平台。', 'title_zh': 'MTBBench: 一种肿瘤学多模态序列临床决策基准'}
{'arxiv_id': 'arXiv:2511.20480', 'title': 'Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders', 'authors': 'Sidahmed Benabderrahmane, James Cheney, Talal Rahwan', 'link': 'https://arxiv.org/abs/2511.20480', 'abstract': 'Advanced Persistent Threats (APTs) pose a significant challenge in cybersecurity due to their stealthy and long-term nature. Modern supervised learning methods require extensive labeled data, which is often scarce in real-world cybersecurity environments. In this paper, we propose an innovative approach that leverages AutoEncoders for unsupervised anomaly detection, augmented by active learning to iteratively improve the detection of APT anomalies. By selectively querying an oracle for labels on uncertain or ambiguous samples, we minimize labeling costs while improving detection rates, enabling the model to improve its detection accuracy with minimal data while reducing the need for extensive manual labeling. We provide a detailed formulation of the proposed Attention Adversarial Dual AutoEncoder-based anomaly detection framework and show how the active learning loop iteratively enhances the model. The framework is evaluated on real-world imbalanced provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\\% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The results have shown significant improvements in detection rates during active learning and better performance compared to other existing approaches.', 'abstract_zh': '高级持久威胁（APTs）由于其隐蔽性和长期性，对网络安全构成了重大挑战。现代监督学习方法需要大量的标注数据，但在现实世界的网络安全环境中，这种数据往往稀缺。在本文中，我们提出了一种创新的方法，利用自编码器进行无监督异常检测，并通过主动学习迭代提高APT异常检测的准确性。通过选择性地查询或acles对不确定或模棱两可的样本进行标注，我们最小化了标注成本，同时提高了检测率，使模型在数据有限的情况下也能提高检测精度，减少大量手动标注的需要。我们详细阐述了所提出的基于注意力对抗双自编码器的异常检测框架，并展示了主动学习循环如何逐步增强模型。框架在由DARPA透明计算计划生成的具有严重不平衡证明跟踪数据库上进行了评估，其中APT类型的攻击数据占比仅为0.004%。数据集涵盖了包括Android、Linux、BSD和Windows在内的多个操作系统，并覆盖了两种攻击场景。结果表明，在主动学习过程中检测率有显著提升，并且性能优于其他现有方法。', 'title_zh': '基于排名增强的主动学习辅助注意力对抗双自编码器异常检测'}
{'arxiv_id': 'arXiv:2511.20470', 'title': 'Efficient and Fast Generative-Based Singing Voice Separation using a Latent Diffusion Model', 'authors': 'Genís Plaja-Roglans, Yun-Ning Hung, Xavier Serra, Igor Pereira', 'link': 'https://arxiv.org/abs/2511.20470', 'abstract': 'Extracting individual elements from music mixtures is a valuable tool for music production and practice. While neural networks optimized to mask or transform mixture spectrograms into the individual source(s) have been the leading approach, the source overlap and correlation in music signals poses an inherent challenge. Also, accessing all sources in the mixture is crucial to train these systems, while complicated. Attempts to address these challenges in a generative fashion exist, however, the separation performance and inference efficiency remain limited. In this work, we study the potential of diffusion models to advance toward bridging this gap, focusing on generative singing voice separation relying only on corresponding pairs of isolated vocals and mixtures for training. To align with creative workflows, we leverage latent diffusion: the system generates samples encoded in a compact latent space, and subsequently decodes these into audio. This enables efficient optimization and faster inference. Our system is trained using only open data. We outperform existing generative separation systems, and level the compared non-generative systems on a list of signal quality measures and on interference removal. We provide a noise robustness study on the latent encoder, providing insights on its potential for the task. We release a modular toolkit for further research on the topic.', 'abstract_zh': '基于扩散模型的生成性人声分离研究', 'title_zh': '基于隐态扩散模型的高效快速生成式歌声分离'}
{'arxiv_id': 'arXiv:2511.20406', 'title': 'Short-Range Oversquashing', 'authors': 'Yaaqov Mishayev, Yonatan Sverdlov, Tal Amir, Nadav Dym', 'link': 'https://arxiv.org/abs/2511.20406', 'abstract': 'Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.\nIn this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.\nWe further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.', 'abstract_zh': '消息传递神经网络（MPNNs）广泛用于图上的学习，但它们处理长距离信息的能力受到过压缩现象的限制。这一限制导致一些研究人员认为图变换器是更好的替代方案，而另一些人则建议可以通过在MPNN框架中使用虚拟节点或其他重连技术来加以缓解。在这项工作中，我们证明了过压缩不仅限于长距离任务，也可能出现在短距离问题中。这一观察使我们能够区分出过压缩背后两种不同的机制：（1）瓶颈现象，即使在低距离设置中也可能出现，（2）梯度消失现象，与长距离任务密切相关。我们进一步表明，现有的过压缩解释未能捕捉到短距离瓶颈效应，而添加虚拟节点并不能解决这一问题。相反，变换器在这类任务中取得了成功，将它们定位为从根本上解决过压缩问题的更优方案，相较于专门的MPNNs。', 'title_zh': '短程过度压缩'}
{'arxiv_id': 'arXiv:2511.20305', 'title': 'RIS-Assisted Downlink Pinching-Antenna Systems: GNN-Enabled Optimization Approaches', 'authors': 'Changpeng He, Yang Lu, Yanqing Xu, Chong-Yung Chi, Bo Ai, Arumugam Nallanathan', 'link': 'https://arxiv.org/abs/2511.20305', 'abstract': 'This paper investigates a reconfigurable intelligent surface (RIS)-assisted multi-waveguide pinching-antenna (PA) system (PASS) for multi-user downlink information transmission, motivated by the unknown impact of the integration of emerging PASS and RIS on wireless communications. First, we formulate sum rate (SR) and energy efficiency (EE) maximization problems in a unified framework, subject to constraints on the movable region of PAs, total power budget, and tunable phase of RIS elements. Then, by leveraging a graph-structured topology of the RIS-assisted PASS, a novel three-stage graph neural network (GNN) is proposed, which learns PA positions based on user locations, and RIS phase shifts according to composite channel conditions at the first two stages, respectively, and finally determines beamforming vectors. Specifically, the proposed GNN is achieved through unsupervised training, together with three implementation strategies for its integration with convex optimization, thus offering trade-offs between inference time and solution optimality. Extensive numerical results are provided to validate the effectiveness of the proposed GNN, and to support its unique attributes of viable generalization capability, good performance reliability, and real-time applicability. Moreover, the impact of key parameters on RIS-assisted PASS is illustrated and analyzed.', 'abstract_zh': '一种辅助多波导挤压天线的可重构智能表面系统的多用户下行信息传输研究：基于新兴PASS和RIS集成对无线通信影响的探索', 'title_zh': 'RIS辅助下行挤压天线系统：基于GNN的优化方法'}
{'arxiv_id': 'arXiv:2511.20296', 'title': 'Prompting Lipschitz-constrained network for multiple-in-one sparse-view CT reconstruction', 'authors': 'Baoshun Shi, Ke Jiang, Qiusheng Lian, Xinran Yu, Huazhu Fu', 'link': 'https://arxiv.org/abs/2511.20296', 'abstract': 'Despite significant advancements in deep learning-based sparse-view computed tomography (SVCT) reconstruction algorithms, these methods still encounter two primary limitations: (i) It is challenging to explicitly prove that the prior networks of deep unfolding algorithms satisfy Lipschitz constraints due to their empirically designed nature. (ii) The substantial storage costs of training a separate model for each setting in the case of multiple views hinder practical clinical applications. To address these issues, we elaborate an explicitly provable Lipschitz-constrained network, dubbed LipNet, and integrate an explicit prompt module to provide discriminative knowledge of different sparse sampling settings, enabling the treatment of multiple sparse view configurations within a single model. Furthermore, we develop a storage-saving deep unfolding framework for multiple-in-one SVCT reconstruction, termed PromptCT, which embeds LipNet as its prior network to ensure the convergence of its corresponding iterative algorithm. In simulated and real data experiments, PromptCT outperforms benchmark reconstruction algorithms in multiple-in-one SVCT reconstruction, achieving higher-quality reconstructions with lower storage costs. On the theoretical side, we explicitly demonstrate that LipNet satisfies boundary property, further proving its Lipschitz continuity and subsequently analyzing the convergence of the proposed iterative algorithms. The data and code are publicly available at this https URL.', 'abstract_zh': '尽管基于深度学习的稀疏视角计算机断层成像（SVCT）重建算法取得了显著进展，但这些方法仍面临两个主要限制：（i）由于它们是经验设计的性质，难以明确证明深度展开算法中先验网络满足利普希茨约束；（ii）为多个视角单独训练模型导致的存储成本高昂阻碍了临床应用的实用性。为解决这些问题，我们详细设计了一个可明确证明满足利普希茨约束的网络，并命名为LipNet，同时集成一个明确提示模块以提供不同稀疏采样设置的鉴别知识，使得在单一模型中处理多个稀疏视角配置成为可能。此外，我们开发了一种用于多视角单模型SVCT重建的存储节省型深度展开框架，命名为PromptCT，将LipNet嵌入其中作为先验网络以确保其相应迭代算法的收敛性。在模拟和真实数据实验中，PromptCT在多视角单模型SVCT重建中优于基准重建算法，实现了更高的重建质量和更低的存储成本。在理论层面，我们明确展示了LipNet满足边界性质，进一步证明其利普希茨连续性，并分析了所提出迭代算法的收敛性。相关数据和代码在以下链接公开：this https URL。', 'title_zh': '受限Lipschitz网络用于多合一稀疏视图CT重建'}
{'arxiv_id': 'arXiv:2511.20293', 'title': 'Forgetting by Pruning: Data Deletion in Join Cardinality Estimation', 'authors': 'Chaowei He, Yuanjun Liu, Qingzhi Ma, Shenyuan Ren, Xizhao Luo, Lei Zhao, An Liu', 'link': 'https://arxiv.org/abs/2511.20293', 'abstract': 'Machine unlearning in learned cardinality estimation (CE) systems presents unique challenges due to the complex distributional dependencies in multi-table relational data. Specifically, data deletion, a core component of machine unlearning, faces three critical challenges in learned CE models: attribute-level sensitivity, inter-table propagation and domain disappearance leading to severe overestimation in multi-way joins. We propose Cardinality Estimation Pruning (CEP), the first unlearning framework specifically designed for multi-table learned CE systems. CEP introduces Distribution Sensitivity Pruning, which constructs semi-join deletion results and computes sensitivity scores to guide parameter pruning, and Domain Pruning, which removes support for value domains entirely eliminated by deletion. We evaluate CEP on state-of-the-art architectures NeuroCard and FACE across IMDB and TPC-H datasets. Results demonstrate CEP consistently achieves the lowest Q-error in multi-table scenarios, particularly under high deletion ratios, often outperforming full retraining. Furthermore, CEP significantly reduces convergence iterations, incurring negligible computational overhead of 0.3%-2.5% of fine-tuning time.', 'abstract_zh': '机器学习在学习基数估算（CE）系统中的取消学习由于多表关系数据中的复杂分布依赖性而面临独特挑战。具体而言，数据删除，取消学习的核心组件，在学习的CE模型中面临三个关键挑战：属性级敏感性、跨表传播以及域消失导致多路连接中的严重过度估计。我们提出了基数估算剪枝（CEP），这是首个专门针对多表学习基数估算系统的取消学习框架。CEP 引入了分布敏感性剪枝，通过构建半连接删除结果和计算敏感性得分来指导参数剪枝，并引入了域剪枝，完全移除由删除消除的价值域的支持。我们在 NeuroCard 和 FACE 最先进的架构上，以及 IMDB 和 TPC-H 数据集上评估了 CEP。结果表明，在多表场景中，CEP 一致性地实现了最低的 Q-error，特别是在高删除比例下，通常优于完全重新训练。此外，CEP 显著减少了收敛迭代次数，计算开销仅为微不足道的 0.3%-2.5% 的微调时间。', 'title_zh': '剪枝引起的遗忘：连接基数估计中的数据删除'}
{'arxiv_id': 'arXiv:2511.20277', 'title': 'HVAdam: A Full-Dimension Adaptive Optimizer', 'authors': 'Yiheng Zhang, Shaowu Wu, Yuanzhuo Xu, Jiajun Wu, Shang Xu, Steve Drew, Xiaoguang Niu', 'link': 'https://arxiv.org/abs/2511.20277', 'abstract': "Adaptive optimizers such as Adam have achieved great success in training large-scale models like large language models and diffusion models. However, they often generalize worse than non-adaptive methods, such as SGD on classical architectures like CNNs. We identify a key cause of this performance gap: adaptivity in pre-conditioners, which limits the optimizer's ability to adapt to diverse optimization landscapes. To address this, we propose Anon (Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel optimizer with continuously tunable adaptivity\n, allowing it to interpolate between SGD-like and Adam-like behaviors and even extrapolate beyond both. To ensure convergence across the entire adaptivity spectrum, we introduce incremental delay update (IDU), a novel mechanism that is more flexible than AMSGrad's hard max-tracking strategy and enhances robustness to gradient noise. We theoretically establish convergence guarantees under both convex and non-convex settings. Empirically, Anon consistently outperforms state-of-the-art optimizers on representative image classification, diffusion, and language modeling tasks. These results demonstrate that adaptivity can serve as a valuable tunable design principle, and Anon provides the first unified and reliable framework capable of bridging the gap between classical and modern optimizers and surpassing their advantageous properties.", 'abstract_zh': '自适应优化器如Adam在训练大规模模型如大规模语言模型和扩散模型方面取得了巨大成功。然而，它们往往比非自适应方法（如CNN的经典架构上的SGD）泛化性能更差。我们识别出性能差距的关键原因：预条件器的自适应性限制了优化器适应多种优化景观的能力。为了解决这一问题，我们提出了Anon（具有新型收敛技术的不受限制自适应优化器），这是一种具有连续可调自适应性的新型优化器，使其能够在SGD-like和Adam-like行为之间进行插值，甚至超越两者。为了在整个自适应范围内确保收敛性，我们引入了增量延迟更新（IDU），这是一种比AMSGrad的硬最大追踪策略更加灵活的新机制，并增强了对梯度噪声的鲁棒性。我们在凸性和非凸性设置下理论上建立了收敛性保证。实验中，Anon在代表性图像分类、扩散和语言建模任务上始终优于最先进的优化器。这些结果表明，自适应性可以作为一种有价值的可调设计原则，而Anon提供了首个统一且可靠的框架，能够弥合经典与现代优化器之间的差距，并超越它们的优势特性。', 'title_zh': 'HVAdam: 一种全维度自适应优化器'}
{'arxiv_id': 'arXiv:2511.20273', 'title': 'Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits', 'authors': 'Areeb Ahmad, Abhinav Joshi, Ashutosh Modi', 'link': 'https://arxiv.org/abs/2511.20273', 'abstract': 'Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.', 'abstract_zh': '基于Transformer的语言模型表现出复杂的分布式行为，但其内部计算机制仍不甚明了。现有的机制化可解释方法通常将注意力头和多层感知器（MLP）（transformer架构的基本构成部分）视为不可分割的整体，忽视了它们内部可能存在的功能子结构。在本工作中，我们引入了一种更精细的视角，将这些组件分解为相互正交的奇异方向，揭示了单个头或MLP内部叠加且独立的计算。我们在广泛使用的标准任务，如间接宾语识别（IOI）、代词（GP）和大于（GT）中验证了这一视角，表明先前识别的经典功能性头，如名称移动者，编码了与不同奇异方向对齐的多重重叠子功能。计算图中的某些节点，先前被确认为电路元件，强烈激活在特定的低秩方向上，表明有意义的计算存在于紧凑的子空间中。尽管某些方向仍然难以完全解释，但我们的结果强调，transformer的计算更为分布式、结构化和组合化，超过之前的假设。这一视角为细粒度的机制解释和模型内部的深入理解开辟了新途径。', 'title_zh': '超越组件：变压器电路的奇异向量基解释可读性'}
{'arxiv_id': 'arXiv:2511.20257', 'title': 'Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling', 'authors': 'Zhiguo Zhang, Xiaoliang Ma, Daniel Schlesinger', 'link': 'https://arxiv.org/abs/2511.20257', 'abstract': "Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.", 'abstract_zh': '准确可解释的空气质量预报对于公共卫生至关重要，但大多数模型在性能与可解释性之间存在权衡。本研究提出了一种基于物理指导、设计可解释的空间时态学习框架。该模型将空气质量的空间时态行为分解为两个透明的加法模块。第一个模块是基于物理导向的传输核，权重受到风和地理条件的定向条件。第二个模块是可解释的注意力机制，学习局部响应并将未来的浓度归因于特定的历史滞后和外生驱动因素。在斯德哥尔摩地区的综合数据集上评估，我们的模型在多个预报时间 horizon 上始终优于最先进的基线模型。我们的模型结合了高预测性能和空间时态可解释性，为实际应用中的运行空气质量管理提供了更可靠的基础。', 'title_zh': '物理学引导的空间时间解耦可解释空气质量预测'}
{'arxiv_id': 'arXiv:2511.20224', 'title': 'DUO-TOK: Dual-Track Semantic Music Tokenizer for Vocal-Accompaniment Generation', 'authors': 'Rui Lin, Zhiyue Wu, Jiahe Le, Kangdi Wang, Weixiong Chen, Junyu Dai, Tao Jiang', 'link': 'https://arxiv.org/abs/2511.20224', 'abstract': 'Duo-Tok is a source-aware dual-codebook tokenizer for vocal-accompaniment music that targets the growing tension between reconstruction quality and language-model (LM) learnability in modern lyrics-to-song systems. Existing codecs either prioritize high-fidelity reconstruction with difficult-to-model acoustic tokens or compress aggressively into semantic tokens that are LM-friendly but lossy, and they rarely make the tokenizer itself aware of dual-track structure. Duo-Tok follows a four-stage, SSL-centered pipeline: we first pretrain a BEST-RQ-style encoder on large-scale audio, then stabilize and factorize the representation with Gaussian replacement noise and multi-task supervision, before freezing the encoder to learn SimVQ-based dual codebooks with hard routing for vocals and accompaniment, and finally training latent diffusion decoders on top of the discrete tokens. Duo-Tok at 0.75 kbps shifts the empirical reconstruction-generation Pareto frontier, achieving the best music-tagging AP and the lowest vocabulary-normalized LM perplexity among compared codecs while maintaining reconstruction quality comparable to state-of-the-art music tokenizers.', 'abstract_zh': 'Duo-Tok是一种基于来源意识的双码本分词器，旨在解决现代歌词到歌曲系统中重建质量与语言模型可学习性之间日益加剧的紧张关系。', 'title_zh': 'DUO-TOK：双轨语义音乐Tokenizer用于人声伴奏生成'}
{'arxiv_id': 'arXiv:2511.20179', 'title': 'Human-computer interactions predict mental health', 'authors': 'Veith Weilnhammer, Jefferson Ortega, David Whitney', 'link': 'https://arxiv.org/abs/2511.20179', 'abstract': 'Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.\nWe introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.\nOur results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.', 'abstract_zh': '面向广泛人群的可访问和平等的心理健康评估仍是一个关键障碍。本文展示了人机交互编码自我报告心理健康状态及其随时间变化的多重维度。我们引入了MAILA，一种从数字活动推断潜在心理状态的机器学习框架。我们训练MAILA从20,000个鼠标和触摸屏记录中预测9,000名在线参与者中的1,300,000份心理健康自我报告。数据集包括2,000名纵向评估的个体，1,500名被诊断为抑郁症的个体，以及500名被诊断为强迫症的个体。MAILA沿着三个正交维度跟踪动态心理状态，能够在预测群体心理健康水平时实现接近天花板的准确性。该模型从一般人群转换为临床人群，识别出患有心理健康障碍的个体，并捕捉到语言无法传达的心理功能特征。研究结果表明，日常的人机交互可以驱动被动、可靠、动态和最大规模的心理健康评估。以零边际成本解码心理状态的能力为精准医疗和公共卫生设定了新的标准，同时也引发了关于在线隐私、自主权和代理人的重要问题。', 'title_zh': '人类计算机交互与心理健康预测'}
{'arxiv_id': 'arXiv:2511.20168', 'title': 'On the Limits of Momentum in Decentralized and Federated Optimization', 'authors': 'Riccardo Zaccone, Sai Praneeth Karimireddy, Carlo Masone', 'link': 'https://arxiv.org/abs/2511.20168', 'abstract': 'Recent works have explored the use of momentum in local methods to enhance distributed SGD. This is particularly appealing in Federated Learning (FL), where momentum intuitively appears as a solution to mitigate the effects of statistical heterogeneity. Despite recent progress in this direction, it is still unclear if momentum can guarantee convergence under unbounded heterogeneity in decentralized scenarios, where only some workers participate at each round. In this work we analyze momentum under cyclic client participation, and theoretically prove that it remains inevitably affected by statistical heterogeneity. Similarly to SGD, we prove that decreasing step-sizes do not help either: in fact, any schedule decreasing faster than $\\Theta\\left(1/t\\right)$ leads to convergence to a constant value that depends on the initialization and the heterogeneity bound. Numerical results corroborate the theory, and deep learning experiments confirm its relevance for realistic settings.', 'abstract_zh': '近期的研究探索了在局部方法中使用动量以增强分布式SGD的效果。这在联邦学习（FL）中尤其吸引人，因为动量直观上被视为缓解统计异质性影响的解决方案。尽管在这方面取得了一定进展，但在去中心化场景中，只有部分工作者在每一轮参与的情况下，动量是否能保证在无界异质性下收敛仍然不清楚。在本文中，我们分析了在循环客户端参与情况下的动量，并理论上证明它不可避免地受到统计异质性的影响。类似于SGD，我们证明减小的学习率也无法帮助：实际上，任何比$\\Theta\\left(1/t\\right)$更快下降的学习率计划会导致收敛到一个依赖于初始化和异质性上界的常数值。数值结果证实了理论分析，而深度学习实验进一步确认了其在现实情境中的相关性。', 'title_zh': '去中心化和联邦优化中动量的极限'}
{'arxiv_id': 'arXiv:2511.20143', 'title': 'SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models', 'authors': 'Wen-Fang Su, Hsiao-Wei Chou, Wen-Yang Lin', 'link': 'https://arxiv.org/abs/2511.20143', 'abstract': 'Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.', 'abstract_zh': '命名实体识别（NER）是自然语言处理中的关键任务，但对于断续实体而言依然特别具有挑战性。主要困难在于文本分段，传统的分段方法经常误分或完全忽略跨句断续实体，严重影响识别精度。因此，我们旨在解决这类实体的分段和遗漏问题。近期研究表明，基于格的方法由于其灵活的标记方案和稳健的结构，在信息提取中效果显著。在此基础上，我们整合了图像数据增强技术，如裁剪、缩放和填充，以提高基于格模型识别断续实体和应对分段挑战的能力。实验结果表明，传统的分段方法往往无法捕捉跨句断续实体，导致性能下降。相比之下，我们增强的基于格的模型取得了显著改进。在CADEC、ShARe13和ShARe14数据集上的评估显示，总F1分数提高了1-2.5%，断续实体的F1分数提高了3.7-8.4%，证实了我们方法的有效性。', 'title_zh': 'SEDA：一种自适应实体中心的数据增强方法以提升基于网格的断点命名实体识别模型'}
{'arxiv_id': 'arXiv:2511.20141', 'title': 'IDAP++: Advancing Divergence-Based Pruning via Filter-Level and Layer-Level Optimization', 'authors': 'Aleksei Samarin, Artem Nazarenko, Egor Kotenko, Valentin Malykh, Alexander Savelev, Aleksei Toropov', 'link': 'https://arxiv.org/abs/2511.20141', 'abstract': 'This paper presents a novel approach to neural network compression that addresses redundancy at both the filter and architectural levels through a unified framework grounded in information flow analysis. Building on the concept of tensor flow divergence, which quantifies how information is transformed across network layers, we develop a two-stage optimization process. The first stage employs iterative divergence-aware pruning to identify and remove redundant filters while preserving critical information pathways. The second stage extends this principle to higher-level architecture optimization by analyzing layer-wise contributions to information propagation and selectively eliminating entire layers that demonstrate minimal impact on network performance. The proposed method naturally adapts to diverse architectures, including convolutional networks, transformers, and hybrid designs, providing a consistent metric for comparing the structural importance across different layer types. Experimental validation across multiple modern architectures and datasets reveals that this combined approach achieves substantial model compression while maintaining competitive accuracy. The presented approach achieves parameter reduction results that are globally comparable to those of state-of-the-art solutions and outperforms them across a wide range of modern neural network architectures, from convolutional models to transformers. The results demonstrate how flow divergence serves as an effective guiding principle for both filter-level and layer-level optimization, offering practical benefits for deployment in resource-constrained environments.', 'abstract_zh': '本文提出了一种通过信息流分析构建的统一框架来解决滤波器和架构层面冗余的新方法。基于张量流发散的概念，该框架量化了信息在网络层间的变化，开发了一种两阶段优化过程。第一阶段采用迭代的发散感知剪枝策略来识别并去除冗余滤波器，同时保持关键信息路径。第二阶段将这一原则扩展到更高层次的架构优化中，通过分析各层对信息传播的贡献，并选择性地去除那些对网络性能影响最小的整个层。所提出的方法自然适用于包括卷积网络、变换器和混合设计在内的多种架构，提供了一致的度量标准来比较不同层类型的重要性。在多种现代架构和数据集上进行的实验验证表明，该联合方法能够在大幅减小程序模型规模的同时，保持竞争力的精度。所提出的方法在参数减少结果上与最先进的解决方案具有全球可比性，并在各种现代神经网络架构中表现更优，从卷积模型到变换器。结果表明，流发散作用于滤波器级和层级优化的有效指导原则，为资源受限环境中的部署提供了实用益处。', 'title_zh': 'IDAP++: 基于散度的剪枝方法的改进及滤波级和层级优化'}
{'arxiv_id': 'arXiv:2511.20116', 'title': 'LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model for Lung Cancer Risk Prediction in LDCT Screening', 'authors': 'Johannes Brandt, Maulik Chevli, Rickmer Braren, Georgios Kaissis, Philip Müller, Daniel Rueckert', 'link': 'https://arxiv.org/abs/2511.20116', 'abstract': 'Lung cancer risk estimation is gaining increasing importance as more countries introduce population-wide screening programs using low-dose CT (LDCT). As imaging volumes grow, scalable methods that can process entire lung volumes efficiently are essential to tap into the full potential of these large screening datasets. Existing approaches either over-rely on pixel-level annotations, limiting scalability, or analyze the lung in fragments, weakening performance. We present LungEvaty, a fully transformer-based framework for predicting 1-6 year lung cancer risk from a single LDCT scan. The model operates on whole-lung inputs, learning directly from large-scale screening data to capture comprehensive anatomical and pathological cues relevant for malignancy risk. Using only imaging data and no region supervision, LungEvaty matches state-of-the-art performance, refinable by an optional Anatomically Informed Attention Guidance (AIAG) loss that encourages anatomically focused attention. In total, LungEvaty was trained on more than 90,000 CT scans, including over 28,000 for fine-tuning and 6,000 for evaluation. The framework offers a simple, data-efficient, and fully open-source solution that provides an extensible foundation for future research in longitudinal and multimodal lung cancer risk prediction.', 'abstract_zh': '基于变压器的肺部低剂量CT扫描肺癌风险预测框架', 'title_zh': 'LungEvaty：一种用于LDCT筛查肺癌风险预测的大规模开源变压器ベース的深度学习模型'}
{'arxiv_id': 'arXiv:2511.20094', 'title': 'The Making of Digital Ghosts: Designing Ethical AI Afterlives', 'authors': 'Giovanni Spitale, Federico Germani', 'link': 'https://arxiv.org/abs/2511.20094', 'abstract': 'Advances in artificial intelligence now make it possible to simulate the dead through chatbots, voice clones, and video avatars trained on a person\'s digital traces. These "digital ghosts" are moving from fiction to commercial reality, reshaping how people mourn and remember. This paper offers a conceptual and ethical analysis of AI-mediated digital afterlives. We define what counts as a digital ghost, trace their rise across personal, commercial, and institutional contexts, and identify core ethical tensions around grief and well-being, truthfulness and deception, consent and posthumous privacy, dignity and misrepresentation, and the commercialization of mourning. To analyze these challenges, we propose a nine-dimensional taxonomy of digital afterlife technologies and, building on it, outline the features of an ethically acceptable digital ghost: premortem intent, mutual consent, transparent and limited data use, clear disclosure, restricted purposes and access, family or estate stewardship, and minimal behavioral agency. We argue for targeted regulation and professional guidelines to ensure that digital ghosts can aid remembrance without slipping into forms of deception.', 'abstract_zh': '人工智能领域的进展现已使得通过聊天机器人、声音克隆和基于个人数字踪迹训练的视频头像来模拟 deceased 的行为成为可能。这些“数字幽灵”正从 fiction 走向商业现实，重塑人们的悼念和纪念方式。本文对 AI 介导的数字后生命存进行了概念和伦理分析。我们定义什么是数字幽灵，在个人、商业和机构背景下追踪其兴起，并识别围绕悲伤与福祉、真相与欺诈、同意与身后隐私、尊严与误表以及悼念的商业化的核心伦理紧张点。为了分析这些挑战，我们提出了数字后生命存技术的九维度分类，并在此基础上概述了伦理上可接受的数字幽灵的特征：事前意图、相互同意、透明且有限的数据使用、明确的披露、受限的目的与访问、家庭或遗产监护，以及最小的行为自主权。我们主张采取有针对性的监管和专业指南，以确保数字幽灵能够帮助缅怀而不滑向欺骗的形式。', 'title_zh': '数字幽灵的形成：设计伦理的AI身后事'}
{'arxiv_id': 'arXiv:2511.20006', 'title': 'BERT-APC: A Reference-free Framework for Automatic Pitch Correction via Musical Context Inference', 'authors': 'Sungjae Kim, Kihyun Na, Jinyoung Choi, Injung Kim', 'link': 'https://arxiv.org/abs/2511.20006', 'abstract': 'Automatic Pitch Correction (APC) enhances vocal recordings by aligning pitch deviations with the intended musical notes. However, existing APC systems either rely on reference pitches, which limits their practical applicability, or employ simple pitch estimation algorithms that often fail to preserve expressiveness and naturalness. We propose BERT-APC, a novel reference-free APC framework that corrects pitch errors while maintaining the natural expressiveness of vocal performances. In BERT-APC, a novel stationary pitch predictor first estimates the perceived pitch of each note from the detuned singing voice. A context-aware note pitch predictor estimates the intended pitch sequence by leveraging a music language model repurposed to incorporate musical context. Finally, a note-level correction algorithm fixes pitch errors while preserving intentional pitch deviations for emotional expression. In addition, we introduce a learnable data augmentation strategy that improves the robustness of the music language model by simulating realistic detuning patterns. Compared to two recent singing voice transcription models, BERT-APC demonstrated superior performance in note pitch prediction, outperforming the second-best model, ROSVOT, by 10.49%p on highly detuned samples in terms of the raw pitch accuracy. In the MOS test, BERT-APC achieved the highest score of $4.32 \\pm 0.15$, which is significantly higher than those of the widely-used commercial APC tools, AutoTune ($3.22 \\pm 0.18$) and Melodyne ($3.08 \\pm 0.18$), while maintaining a comparable ability to preserve expressive nuances. To the best of our knowledge, this is the first APC model that leverages a music language model to achieve reference-free pitch correction with symbolic musical context. The corrected audio samples of BERT-APC are available online.', 'abstract_zh': '无需参考的基于BERT的自动音高校正（BERT-APC）：结合符号音乐上下文的音高误差校正框架', 'title_zh': 'BERT-APC：基于音乐上下文推理的无参考自动音高矫正框架'}
{'arxiv_id': 'arXiv:2511.20004', 'title': 'Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting', 'authors': 'Peining Zhang, Hongchen Qin, Haochen Zhang, Ziqi Guo, Guiling Wang, Jinbo Bi', 'link': 'https://arxiv.org/abs/2511.20004', 'abstract': 'This work investigates the zero-shot forecasting capability of time-series foundation models for Leaf Area Index (LAI) forecasting in agricultural monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare statistical baselines, a fully supervised LSTM, and the Sundial foundation model under multiple evaluation protocols. We find that Sundial, in the zero-shot setting, can outperform a fully trained LSTM provided that the input context window is sufficiently long-specifically, when covering more than one or two full seasonal cycles. This demonstrates, for the first time, that a general-purpose foundation model can surpass specialized supervised models on remote-sensing time series prediction without any task-specific tuning. These results highlight the strong potential of pretrained time-series foundation models to serve as effective plug-and-play forecasters in agricultural and environmental applications.', 'abstract_zh': '本研究探讨了时间序列基础模型在农业监测中叶面积指数（LAI）零样本预测的能力，使用HiQ数据集（美国，2000-2022年），系统比较了统计基线、完全监督的LSTM和Sundial基础模型在多种评估协议下的性能。研究发现，在零样本设置下，当输入上下文窗口足够长，即覆盖超过一个或两个完整的季节周期时，Sundial可以选择性地超过完全训练的LSTM。这一结果首次表明，一个通用基础模型可以在不进行任何任务特定微调的情况下，在遥感时间序列预测中超越专门的监督模型。这些结果突显了预训练时间序列基础模型在农业和环境应用中作为有效即插即用预测器的强大潜力。', 'title_zh': 'Sundial 基础模型在叶面积指数预报中的零样本迁移能力'}
{'arxiv_id': 'arXiv:2511.19999', 'title': 'Popularity Bias Alignment Estimates', 'authors': 'Anton Lyubinin', 'link': 'https://arxiv.org/abs/2511.19999', 'abstract': 'We are extending Popularity Bias Memorization theorem from arXiv:archive/2404.12008 in several directions. We extend it to arbitrary degree distributions and also prove both upper and lower estimates for the alignment with top-k singular hyperspace.', 'abstract_zh': '我们扩展了来自arXiv:archive/2404.12008的Popularity Bias Memorization定理的研究范围，将其扩展到任意度分布，并且证明了与前k奇异超空间匹配的上下界估计。', 'title_zh': '流行性偏见对齐估计'}
{'arxiv_id': 'arXiv:2511.19986', 'title': 'On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices', 'authors': 'Lianming Huang, Haibo Hu, Qiao Li, Nan Guan, Chun Jason Xue', 'link': 'https://arxiv.org/abs/2511.19986', 'abstract': 'Sparsity is essential for deploying large models on resource constrained edge platforms. However, optimizing sparsity patterns for individual tasks in isolation ignores the significant I/O overhead incurred during frequent task switching. We introduce an on-demand multi-task sparsity framework specifically designed to minimize switching costs by maximizing parameter reuse. Unlike monolithic approaches, we decompose weights into reusable block-granular units and align sparse structures across tasks to maximize overlap. By dynamically loading only the small differential set of blocks required for the next task, our method effectively mitigates the cold-start latency inherent in traditional monolithic this http URL on a real-world autonomous driving platform demonstrate that our framework achieves superior switching efficiency, accelerating task switching by over 6.6X on average compared to existing sparsity methods.', 'abstract_zh': '基于需求的多任务稀疏性框架通过最大化参数复用来最小化切换成本', 'title_zh': '基于需求的多任务稀疏性：在边缘设备上高效部署大型模型'}
{'arxiv_id': 'arXiv:2511.19943', 'title': 'AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload', 'authors': 'Akash Doshi, Pinar Sen, Kirill Ivanov, Wei Yang, June Namgoong, Runxin Wang, Rachel Wang, Taesang Yoo, Jing Jiang, Tingfang Ji', 'link': 'https://arxiv.org/abs/2511.19943', 'abstract': 'Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance gains could be obtained by employing joint source channel coding, aided by deep learning-based techniques. In this paper, we learn a transformer-based encoder using a novel "free-lunch" training algorithm and propose per-codeword power shaping to exploit the source prior at the encoder whilst being robust to small changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to achieve a low negative acknowledgement (NACK) error rate to avoid radio link failures resulting from multiple NACK errors. We develop an extension of the Neyman-Pearson test to a coded bit system with multiple information bits to achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally, we apply the proposed encoder and decoder designs to a 5G New Radio (NR) compliant uplink setup under a fading channel, describing the optimal receiver design and a low complexity coherent approximation to it. Our results demonstrate 3-6 dB reduction in the average transmit power required to achieve the target error rates compared to the NR baseline, while also achieving a 2-3 dB reduction in the maximum transmit power, thus providing for significant coverage gains and power savings.', 'abstract_zh': '从2G到5G的信道编码假设物理层输入位均匀分布。然而，上传中传输的混合自动重传请求确认（HARQ-ACK）位本质上是非均匀分布的。对于此类源，在编码器中利用基于源先验的信息同时对HARQ-ACK分布的小变化具有鲁棒性的联合源信道编码中，可以显著提高性能，通过基于深度学习的技术辅助。在本文中，我们使用一种新颖的“免费午餐”训练算法学习了一个基于变压器的编码器，并提出每码字功率整形以在编码器中利用源先验信息，同时对HARQ-ACK分布的小变化具有鲁棒性。此外，任何HARQ-ACK解码器都必须实现低否定确认（NACK）错误率，以避免由多次NACK错误引起的射频链路故障。我们开发了Neyman-Pearson检验的扩展，用于具有多个信息位的编码位系统，以实现解码器中NACK位对ACK位的不等错误保护。最后，我们将提出的编码器和解码器设计应用于符合5G新无线电（NR）规范的上行链路设置下具有衰落信道的场景，描述了最优接收器设计及其低复杂度相干近似。我们的结果表明，与NR基线相比，实现目标错误率所需的平均发射功率降低3-6 dB，同时最大发射功率也降低2-3 dB，从而提供了显著的覆盖范围增益和功率节省。', 'title_zh': '基于AI/ML的联合源编码和信道编码技术用于HARQ-ACK负载'}
{'arxiv_id': 'arXiv:2511.19941', 'title': 'Optimize Flip Angle Schedules In MR Fingerprinting Using Reinforcement Learning', 'authors': 'Shenjun Zhong, Zhifeng Chen, Zhaolin Chen', 'link': 'https://arxiv.org/abs/2511.19941', 'abstract': 'Magnetic Resonance Fingerprinting (MRF) leverages transient-state signal dynamics generated by the tunable acquisition parameters, making the design of an optimal, robust sequence a complex, high-dimensional sequential decision problem, such as optimizing one of the key parameters, flip angle. Reinforcement learning (RL) offers a promising approach to automate parameter selection, to optimize pulse sequences that maximize the distinguishability of fingerprints across the parameter space. In this work, we introduce an RL framework for optimizing the flip-angle schedule in MRF and demonstrate a learned schedule exhibiting non-periodic patterns that enhances fingerprint separability. Additionally, an interesting observation is that the RL-optimized schedule may enable a reduction in the number of repetition time, potentially accelerate MRF acquisitions.', 'abstract_zh': '磁共振指纹成像(MRF)中的翻转角调度优化：基于强化学习的非周期性指纹可分辨性增强策略研究', 'title_zh': '使用强化学习优化MR指纹成像中的翻转角调度'}
{'arxiv_id': 'arXiv:2511.19902', 'title': 'Zero-Knowledge Proof Based Verifiable Inference of Models', 'authors': 'Yunxiao Wang', 'link': 'https://arxiv.org/abs/2511.19902', 'abstract': 'Recent advances in artificial intelligence (AI), particularly deep learning, have led to widespread adoption across various applications. Yet, a fundamental challenge persists: how can we verify the correctness of AI model inference when model owners cannot (or will not) reveal their parameters? These parameters represent enormous training costs and valuable intellectual property, making transparent verification difficult. In this paper, we introduce a zero-knowledge framework capable of verifying deep learning inference without exposing model internal parameters. Built on recursively composed zero-knowledge proofs and requiring no trusted setup, our framework supports both linear and nonlinear neural network layers, including matrix multiplication, normalization, softmax, and SiLU. Leveraging the Fiat-Shamir heuristic, we obtain a succinct non-interactive argument of knowledge (zkSNARK) with constant-size proofs. To demonstrate the practicality of our approach, we translate the DeepSeek model into a fully SNARK-verifiable version named ZK-DeepSeek and show experimentally that our framework delivers both efficiency and flexibility in real-world AI verification workloads.', 'abstract_zh': '近年来，人工智能（AI），尤其是深度学习，已在各种应用中得到了广泛采用。然而，一个根本性的挑战仍存在：当模型所有者不愿意或无法透露其参数时，我们如何验证AI模型推理的正确性？这些参数代表着巨大的训练成本和宝贵的知识产权，使得透明验证变得困难。本文介绍了一种零知识框架，能够在不暴露模型内部参数的情况下验证深度学习推理。该框架基于递归组合的零知识证明构建，无需信任设置，支持线性及非线性神经网络层，包括矩阵乘法、归一化、softmax 和 SiLU。利用Fiat-Shamir启发式方法，我们获得了具有恒定大小证明的精简非交互式知识论证（zkSNARK）。为了证明我们方法的实用性，我们将DeepSeek模型转换为完全SNARK可验证版本ZK-DeepSeek，并实验证明，该框架在实际AI验证工作负载中既有效率又灵活。', 'title_zh': '基于零知识证明的可验证模型推断'}
{'arxiv_id': 'arXiv:2511.19841', 'title': 'Cisco Time Series Model Technical Report', 'authors': 'Liang Gou, Archit Khare, Praneet Pabolu, Prachi Patel, Joseph Ross, Hercy Shen, Yuhan, Song, Jingze Sun, Kristal Curtis, Vedant Dharnidharka, Abhinav Mathur, Hao Yang', 'link': 'https://arxiv.org/abs/2511.19841', 'abstract': 'We introduce the Cisco Time Series Model, a univariate zero-shot forecaster. This time series foundation model is the result of a general architectural innovation to a time series model enabling it to accept multiresolution input, applied to a popular decoder-only time series model (TimesFM). The resulting multiresolution decoder-only model is trained on over 300B unique data points, with more than half coming from the observability domain. Quantitative and qualitative evaluations demonstrate that the resulting model achieves superior performance on observability datasets while retaining very similar performance on a standard general-purpose forecasting benchmark (GIFT-Eval), and suggest that the multiresolution structure enables the model to make more accurate predictions on long context input.', 'abstract_zh': 'Cisco时间序列模型：一个多分辨率的零样本时序预测器', 'title_zh': 'Cisco时间序列模型技术报告'}
{'arxiv_id': 'arXiv:2511.19837', 'title': 'GED-Consistent Disentanglement of Aligned and Unaligned Substructures for Graph Similarity Learning', 'authors': 'Zhentao Zhan, Xiaoliang Xu, Jingjing Wang, Junmei Wang', 'link': 'https://arxiv.org/abs/2511.19837', 'abstract': 'Graph Similarity Computation (GSC) is a fundamental graph related task where Graph Edit Distance (GED) serves as a prevalent metric. GED is determined by an optimal alignment between a pair of graphs that partitions each into aligned (zero-cost) and unaligned (cost-incurring) substructures. Due to NP-hard nature of exact GED computation, GED approximations based on Graph Neural Network(GNN) have emerged. Existing GNN-based GED approaches typically learn node embeddings for each graph and then aggregate pairwise node similarities to estimate the final similarity. Despite their effectiveness, we identify a mismatch between this prevalent node-centric matching paradigm and the core principles of GED. This discrepancy leads to two critical limitations: (1) a failure to capture the global structural correspondence for optimal alignment, and (2) a misattribution of edit costs driven by spurious node level signals. To address these limitations, we propose GCGSim, a GED-consistent graph similarity learning framework centering on graph-level matching and substructure-level edit costs. Specifically, we make three core technical contributions. Extensive experiments on four benchmark datasets show that GCGSim achieves state-of-the-art performance. Our comprehensive analyses further validate that the framework effectively learns disentangled and semantically meaningful substructure representations.', 'abstract_zh': '图相似性计算（GSC）是图相关的基本任务，其中图编辑距离（GED）作为一种常用指标。GED由一对图的最佳对齐决定，该对齐将每个图分解为对齐的（零成本）子结构和未对齐的（具有成本的）子结构。由于精确GED计算的NP-hard性质，基于图神经网络（GNN）的GED近似方法已 emerge。现有的基于GNN的GED方法通常为每个图学习节点嵌入，然后聚合节点对之间的相似性以估算最终的相似性。尽管这些方法非常有效，但我们将注意力中心 paradigm与GED的核心原则之间的一种不匹配识别了出来。这种偏差导致了两个关键限制：（1）无法捕捉全局结构对应以实现最优对齐，（2）编辑成本由虚假的节点级信号误导向。为了解决这些限制，我们提出了GCGSim，这是一种以图级匹配和子结构级编辑成本为中心的与GED一致的图相似性学习框架。具体地，我们做出了三项核心技术贡献。在四个基准数据集上的广泛实验证明了GCGSim达到了最先进的性能。我们的综合分析还进一步验证了该框架有效地学习到了解耦且语义上有意义的子结构表示。', 'title_zh': '对齐和未对齐子结构的一致性解耦学习用于图相似性学习'}
{'arxiv_id': 'arXiv:2511.19818', 'title': 'Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana', 'authors': 'Koena Ronny Mabokela, Tim Schlippe, Mpho Raborife, Turgay Celik', 'link': 'https://arxiv.org/abs/2511.19818', 'abstract': 'Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.', 'abstract_zh': '情感分析是自动分析人工智能领域如社会公益、教育或市场营销中各种主题的意见和情绪的一项有益任务。虽然许多情感分析系统是为英语开发的，但由于缺乏如带相应情感类标签的文本等数字语言资源，许多非洲语言被归类为低资源语言。其中一个原因是，手动标注文本数据耗费时间且成本高。因此，需要自动和快速的过程来尽可能减少手动努力，使标注过程尽可能高效。在本文中，我们提出并分析了一种基于情感表情符和词汇信息的情感自动独立标注方法。我们的实验使用来自南非情感语料库SAfriSenti、包含英语、塞佩迪语和塞茨瓦纳语的推文进行。结果显示，我们的情感标注方法能够将英语推文的标注准确性达到66%，塞佩迪语推文的标注准确性达到69%，塞茨瓦纳语推文的标注准确性达到63%，因此平均而言，只有34%的自动生成的标签需要人工修正。', 'title_zh': '基于远端监督的无语言依赖情感标注：英语、西佩迪语和塞茨瓦纳语的案例研究'}
{'arxiv_id': 'arXiv:2511.19808', 'title': 'Learning to Clean: Reinforcement Learning for Noisy Label Correction', 'authors': 'Marzi Heidari, Hanping Zhang, Yuhong Guo', 'link': 'https://arxiv.org/abs/2511.19808', 'abstract': 'The challenge of learning with noisy labels is significant in machine learning, as it can severely degrade the performance of prediction models if not addressed properly. This paper introduces a novel framework that conceptualizes noisy label correction as a reinforcement learning (RL) problem. The proposed approach, Reinforcement Learning for Noisy Label Correction (RLNLC), defines a comprehensive state space representing data and their associated labels, an action space that indicates possible label corrections, and a reward mechanism that evaluates the efficacy of label corrections. RLNLC learns a deep feature representation based policy network to perform label correction through reinforcement learning, utilizing an actor-critic method. The learned policy is subsequently deployed to iteratively correct noisy training labels and facilitate the training of the prediction model. The effectiveness of RLNLC is demonstrated through extensive experiments on multiple benchmark datasets, where it consistently outperforms existing state-of-the-art techniques for learning with noisy labels.', 'abstract_zh': 'Noisy Label Correction via Reinforcement Learning: A Novel Framework', 'title_zh': '学习清洁：噪声标签矫正的强化学习方法'}
{'arxiv_id': 'arXiv:2511.19751', 'title': 'Leveraging Foundation Models for Histological Grading in Cutaneous Squamous Cell Carcinoma using PathFMTools', 'authors': 'Abdul Rahman Diab, Emily E. Karn, Renchin Wu, Emily S. Ruiz, William Lotter', 'link': 'https://arxiv.org/abs/2511.19751', 'abstract': 'Despite the promise of computational pathology foundation models, adapting them to specific clinical tasks remains challenging due to the complexity of whole-slide image (WSI) processing, the opacity of learned features, and the wide range of potential adaptation strategies. To address these challenges, we introduce PathFMTools, a lightweight, extensible Python package that enables efficient execution, analysis, and visualization of pathology foundation models. We use this tool to interface with and evaluate two state-of-the-art vision-language foundation models, CONCH and MUSK, on the task of histological grading in cutaneous squamous cell carcinoma (cSCC), a critical criterion that informs cSCC staging and patient management. Using a cohort of 440 cSCC H&E WSIs, we benchmark multiple adaptation strategies, demonstrating trade-offs across prediction approaches and validating the potential of using foundation model embeddings to train small specialist models. These findings underscore the promise of pathology foundation models for real-world clinical applications, with PathFMTools enabling efficient analysis and validation.', 'abstract_zh': '尽管病理计算基础模型具有潜力，但将其适应特定临床任务仍然面临挑战，原因包括全滑片图像(WSI)处理的复杂性、学习特征的不透明性以及广泛的潜在适应策略。为应对这些挑战，我们介绍了PathFMTools，这是一个轻量级且可扩展的Python包，能够实现病理基础模型的有效执行、分析和可视化。我们利用该工具与两种最新的视觉-语言基础模型CONCH和MUSK接口，并在角化皮肤癌(cSCC)组织学分级任务上进行评估，这是一个影响cSCC分期和患者管理的关键指标。使用440例cSCC HE WSI队列，我们对多种适应策略进行了基准测试，展示了不同预测方法之间的权衡，并验证了使用基础模型嵌入训练小型专业模型的潜力。这些发现强调了病理基础模型在实际临床应用中的前景，而PathFMTools则有助于高效地进行分析和验证。', 'title_zh': '利用基础模型在皮肤鳞状细胞癌组织学分级中的应用——使用PathFMTools'}
{'arxiv_id': 'arXiv:2511.19726', 'title': 'An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design', 'authors': 'Roberto Garrone', 'link': 'https://arxiv.org/abs/2511.19726', 'abstract': 'Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.', 'abstract_zh': '多代理系统通常在反馈、适应性和非站定性条件下运行，然而许多模拟研究仍采用静态决策规则和固定控制参数。本文介绍了一种通用的适应性多代理学习框架，该框架整合了：（i）四种动态模式，区分静态与适应性代理以及固定与适应性系统参数；（ii）信息论诊断（熵率、统计复杂性和预测信息）以评估可预测性和结构；（iii）结构因果模型以明确干预语义；（iv）从汇总或样本数据生成代理级先验的方法；以及（v）用于识别新兴行为模式的无监督方法。该框架提供了一个中立领域架构，用于分析学习代理和适应性控制如何共同塑造系统轨迹，从而跨非平衡、振荡或多变动力学实现稳定性和性能的系统比较及可解释性。提供了数学定义、计算运算符和实验设计模板，生成了一种结构化的方法，用于开发可解释性和可争议的多代理决策过程。', 'title_zh': '一种集成数据的自适应代理基于 modeling 框架：可解释和可争议性政策设计'}
{'arxiv_id': 'arXiv:2511.19711', 'title': 'CrypTorch: PyTorch-based Auto-tuning Compiler for Machine Learning with Multi-party Computation', 'authors': 'Jinyu Liu, Gang Tan, Kiwan Maeng', 'link': 'https://arxiv.org/abs/2511.19711', 'abstract': "Machine learning (ML) involves private data and proprietary model parameters. MPC-based ML allows multiple parties to collaboratively run an ML workload without sharing their private data or model parameters using multi-party computing (MPC). Because MPC cannot natively run ML operations such as Softmax or GELU, existing frameworks use different approximations. Our study shows that, on a well-optimized framework, these approximations often become the dominating bottleneck. Popular approximations are often insufficiently accurate or unnecessarily slow, and these issues are hard to identify and fix in existing frameworks. To tackle this issue, we propose a compiler for MPC-based ML, CrypTorch. CrypTorch disentangles these approximations with the rest of the MPC runtime, allows easily adding new approximations through its programming interface, and automatically selects approximations to maximize both performance and accuracy. Built as an extension to PyTorch 2's compiler, we show that CrypTorch's auto-tuning alone provides 1.20--1.7$\\times$ immediate speedup without sacrificing accuracy, and 1.31--1.8$\\times$ speedup when some accuracy degradation is allowed, compared to our well-optimized baseline. Combined with better engineering and adoption of state-of-the-art practices, the entire framework brings 3.22--8.6$\\times$ end-to-end speedup compared to the popular framework, CrypTen.", 'abstract_zh': '基于MPC的机器学习：CrypTorch编译器', 'title_zh': 'CrypTorch: 基于PyTorch的多方计算自动调优编译器'}
{'arxiv_id': 'arXiv:2511.19703', 'title': 'The Alexander-Hirschowitz theorem for neurovarieties', 'authors': 'A. Massarenti, M. Mella', 'link': 'https://arxiv.org/abs/2511.19703', 'abstract': 'We study neurovarieties for polynomial neural networks and fully characterize when they attain the expected dimension in the single-output case. As consequences, we establish non-defectiveness and global identifiability for multi-output architectures.', 'abstract_zh': '我们研究多项式神经网络的神经簇，并在单输出情况下完全刻画其何时达到预期维度。作为结果，我们建立了多输出架构的无缺陷性和全局可识别性。', 'title_zh': '亚历山大-希施霍茨定理在神经簇中的应用'}
{'arxiv_id': 'arXiv:2511.19694', 'title': 'TiCT: A Synthetically Pre-Trained Foundation Model for Time Series Classification', 'authors': 'Chin-Chia Michael Yeh, Uday Singh Saini, Junpeng Wang, Xin Dai, Xiran Fan, Jiarui Sun, Yujie Fan, Yan Zheng', 'link': 'https://arxiv.org/abs/2511.19694', 'abstract': 'The ubiquity of time series data creates a strong demand for general-purpose foundation models, yet developing them for classification remains a significant challenge, largely due to the high cost of labeled data. Foundation models capable of in-context learning (ICL) offer a powerful solution, adapting to new tasks with minimal examples and reducing the need for extensive retraining. However, prior work on large-scale time series models has predominantly focused on forecasting, leaving a critical gap for versatile, fine-tuning-free classification. To address this, we introduce TiCT (Time-series in-Context Transformer), a transformer-based model pre-trained exclusively on synthetic data to perform in-context classification. We make two primary technical contributions: 1) a novel architecture featuring a scalable bit-based label encoding and a special output attention mechanism to handle an arbitrary number of classes; and 2) a synthetic pre-training framework that combines a Mixup-inspired process with data augmentation to foster generalization and noise invariance. Extensive evaluations on the UCR Archive show that TiCT achieves competitive performance against state-of-the-art supervised methods. Crucially, this is accomplished using only in-context examples at inference time, without updating a single model weight.', 'abstract_zh': '时间序列数据的普遍性造就了对通用基础模型的强大需求，然而在分类任务上的开发仍面临重大挑战，主要原因在于标注数据的成本高昂。能够进行上下文学习的foundation模型提供了有力的解决方案，它们可以通过少量示例适应新任务，并减少大规模重训练的需求。然而，大规模时间序列模型的先前工作大多集中于预测，留下了关键的缺口，即具有高度适应性和无需微调的分类能力。为解决这一问题，我们提出TiCT（时序上下文变压器），这是一种仅在合成数据上预训练的基于变换器的模型，用于执行上下文分类。我们的主要技术贡献包括：1) 一种新颖的架构，包含可扩展的位基标签编码和特殊输出注意力机制，以处理任意数量的类别；2) 一种合成预训练框架，结合了Mixup启发的过程与数据增强，以促进泛化和噪声不变性。在UCR档案上的广泛评估表明，TiCT 在与最先进的监督方法的竞争中取得了可竞争的性能。关键的是，这一成就仅在推理时使用上下文示例来实现，而不更新任何模型权重。', 'title_zh': 'TiCT：一种合成预训练基础模型用于时间序列分类'}
{'arxiv_id': 'arXiv:2511.19693', 'title': 'TREASURE: A Transformer-Based Foundation Model for High-Volume Transaction Understanding', 'authors': 'Chin-Chia Michael Yeh, Uday Singh Saini, Xin Dai, Xiran Fan, Shubham Jain, Yujie Fan, Jiarui Sun, Junpeng Wang, Menghai Pan, Yingtong Dou, Yuzhong Chen, Vineeth Rakesh, Liang Wang, Yan Zheng, Mahashweta Das', 'link': 'https://arxiv.org/abs/2511.19693', 'abstract': "Payment networks form the backbone of modern commerce, generating high volumes of transaction records from daily activities. Properly modeling this data can enable applications such as abnormal behavior detection and consumer-level insights for hyper-personalized experiences, ultimately improving people's lives. In this paper, we present TREASURE, TRansformer Engine As Scalable Universal transaction Representation Encoder, a multipurpose transformer-based foundation model specifically designed for transaction data. The model simultaneously captures both consumer behavior and payment network signals (such as response codes and system flags), providing comprehensive information necessary for applications like accurate recommendation systems and abnormal behavior detection. Verified with industry-grade datasets, TREASURE features three key capabilities: 1) an input module with dedicated sub-modules for static and dynamic attributes, enabling more efficient training and inference; 2) an efficient and effective training paradigm for predicting high-cardinality categorical attributes; and 3) demonstrated effectiveness as both a standalone model that increases abnormal behavior detection performance by 111% over production systems and an embedding provider that enhances recommendation models by 104%. We present key insights from extensive ablation studies, benchmarks against production models, and case studies, highlighting valuable knowledge gained from developing TREASURE.", 'abstract_zh': '基于变压器的多功能交易表示编码器 TREASURE： scalable universal transaction representation for modern commerce', 'title_zh': 'TREASURE：一种基于变换器的高容量交易理解基础模型'}
{'arxiv_id': 'arXiv:2511.19649', 'title': "Synthetic Data: AI's New Weapon Against Android Malware", 'authors': 'Angelo Gaspar Diniz Nogueira, Kayua Oleques Paim, Hendrio Bragança, Rodrigo Brandão Mansilha, Diego Kreutz', 'link': 'https://arxiv.org/abs/2511.19649', 'abstract': 'The ever-increasing number of Android devices and the accelerated evolution of malware, reaching over 35 million samples by 2024, highlight the critical importance of effective detection methods. Attackers are now using Artificial Intelligence to create sophisticated malware variations that can easily evade traditional detection techniques. Although machine learning has shown promise in malware classification, its success relies heavily on the availability of up-to-date, high-quality datasets. The scarcity and high cost of obtaining and labeling real malware samples presents significant challenges in developing robust detection models. In this paper, we propose MalSynGen, a Malware Synthetic Data Generation methodology that uses a conditional Generative Adversarial Network (cGAN) to generate synthetic tabular data. This data preserves the statistical properties of real-world data and improves the performance of Android malware classifiers. We evaluated the effectiveness of this approach using various datasets and metrics that assess the fidelity of the generated data, its utility in classification, and the computational efficiency of the process. Our experiments demonstrate that MalSynGen can generalize across different datasets, providing a viable solution to address the issues of obsolescence and low quality data in malware detection.', 'abstract_zh': 'Android设备的不断增多和恶意软件的加速演变，截至2024年超过3500万样本，强调了有效检测方法的至关重要性。攻击者现在利用人工智能创建复杂的恶意软件变种，以逃避传统的检测技术。尽管机器学习在恶意软件分类中展示了潜力，其成功高度依赖于获取更新且高质量数据集的能力。获取和标注真实恶意软件样本的稀缺性和高成本给开发稳健的检测模型带来了巨大挑战。本文提出了一种MalSynGen合成数据生成方法，该方法利用条件生成对抗网络（cGAN）生成合成表格数据。这种数据保留了真实数据的统计特性，并提高了Android恶意软件分类器的性能。我们使用各类数据集和评估生成数据保真度、分类用途以及处理过程计算效率的指标，验证了该方法的有效性。实验结果表明，MalSynGen可以在不同数据集上泛化，提供了解决恶意软件检测中过时和低质量数据问题的可行方案。', 'title_zh': '合成数据：AI对抗Android恶意软件的新武器'}
{'arxiv_id': 'arXiv:2511.19644', 'title': 'IRSDA: An Agent-Orchestrated Framework for Enterprise Intrusion Response', 'authors': 'Damodar Panigrahi, Raj Patel, Shaswata Mitra, Sudip Mittal, Shahram Rahimi', 'link': 'https://arxiv.org/abs/2511.19644', 'abstract': 'Modern enterprise systems face escalating cyber threats that are increasingly dynamic, distributed, and multi-stage in nature. Traditional intrusion detection and response systems often rely on static rules and manual workflows, which limit their ability to respond with the speed and precision required in high-stakes environments. To address these challenges, we present the Intrusion Response System Digital Assistant (IRSDA), an agent-based framework designed to deliver autonomous and policy-compliant cyber defense. IRSDA combines Self-Adaptive Autonomic Computing Systems (SA-ACS) with the Knowledge guided Monitor, Analyze, Plan, and Execute (MAPE-K) loop to support real-time, partition-aware decision-making across enterprise infrastructure.\nIRSDA incorporates a knowledge-driven architecture that integrates contextual information with AI-based reasoning to support system-guided intrusion response. The framework leverages retrieval mechanisms and structured representations to inform decision-making while maintaining alignment with operational policies. We assess the system using a representative real-world microservices application, demonstrating its ability to automate containment, enforce compliance, and provide traceable outputs for security analyst interpretation. This work outlines a modular and agent-driven approach to cyber defense that emphasizes explainability, system-state awareness, and operational control in intrusion response.', 'abstract_zh': '现代企业系统面临 escalating 的网络威胁，这些威胁日益动态、分布广泛且具有多阶段特性。传统的入侵检测与响应系统通常依赖静态规则和人工流程，这限制了它们在高风险环境中以所需的速度和精度作出响应的能力。为应对这些挑战，我们提出了入侵响应系统数字助理（IRSDA），这是一种基于代理的框架，旨在提供自主且符合策略的网络安全防护。IRSDA 将自适应自主计算系统（SA-ACS）与基于知识的监控、分析、计划和执行（MAPE-K）循环相结合，以支持企业基础设施中的实时、分区感知决策。IRSDA 结合了知识驱动的架构，将上下文信息与基于 AI 的推理相结合，以支持系统导向的入侵响应。该框架利用检索机制和结构化表示来指导决策，同时保持与操作政策的一致性。我们使用一个典型的现实世界微服务应用评估该系统，展示了其自动遏制、执行合规性和提供可追溯输出以供安全分析师解释的能力。本文概述了一种模块化且基于代理的方法，强调入侵响应中的可解释性、系统状态感知和操作控制。', 'title_zh': 'IRSDA: 一种基于代理orchestration的企业入侵响应框架'}
{'arxiv_id': 'arXiv:2511.19636', 'title': 'Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks', 'authors': 'Shihan Feng, Cheng Zhang, Michael Xi, Ethan Hsu, Lesia Semenova, Chudi Zhong', 'link': 'https://arxiv.org/abs/2511.19636', 'abstract': 'Modern neural networks rarely have a single way to be right. For many tasks, multiple models can achieve identical performance while relying on different features or reasoning patterns, a property known as the Rashomon Effect. However, uncovering this diversity in deep architectures is challenging as their continuous parameter spaces contain countless near-optimal solutions that are numerically distinct but often behaviorally similar. We introduce Rashomon Concept Bottleneck Models, a framework that learns multiple neural networks which are all accurate yet reason through distinct human-understandable concepts. By combining lightweight adapter modules with a diversity-regularized training objective, our method constructs a diverse set of deep concept-based models efficiently without retraining from scratch. The resulting networks provide fundamentally different reasoning processes for the same predictions, revealing how concept reliance and decision making vary across equally performing solutions. Our framework enables systematic exploration of data-driven reasoning diversity in deep models, offering a new mechanism for auditing, comparison, and alignment across equally accurate solutions.', 'abstract_zh': '现代神经网络很少有单一的正确方式。对于许多任务，多种模型可以达到相同的性能，但依赖不同的特征或推理模式，这一特性被称为拉沙蒙效应。然而，在深层架构中发现这种多样性极具挑战性，因为它们的连续参数空间包含了无数个数值上不同但行为上相似的近最优解。我们引入了一种框架，即拉沙蒙概念瓶颈模型，该框架学习多个均准确但通过不同的可理解概念进行推理的神经网络。通过结合轻量级适配器模块和多样性正则化训练目标，我们的方法可以高效地构建一组深层概念基于的多样化模型，而无需从头开始重新训练。由此产生的网络提供了相同预测中根本不同的推理过程，揭示了概念依赖性和决策在同样表现的解决方案之间如何变化。该框架使系统探索深层模型中的数据驱动推理多样性成为可能，提供了在相同准确度解决方案之间进行审计、比较和对齐的新机制。', 'title_zh': '多种正确方式：基于概念的神经网络的拉修门集'}
{'arxiv_id': 'arXiv:2511.19580', 'title': 'Towards Synergistic Teacher-AI Interactions with Generative Artificial Intelligence', 'authors': 'Mutlu Cukurova, Wannapon Suraworachet, Qi Zhou, Sahan Bulathwela', 'link': 'https://arxiv.org/abs/2511.19580', 'abstract': "Generative artificial intelligence (GenAI) is increasingly used in education, posing significant challenges for teachers adapting to these changes. GenAI offers unprecedented opportunities for accessibility, scalability and productivity in educational tasks. However, the automation of teaching tasks through GenAI raises concerns about reduced teacher agency, potential cognitive atrophy, and the broader deprofessionalisation of teaching. Drawing findings from prior literature on AI in Education, and refining through a recent systematic literature review, this chapter presents a conceptualisation of five levels of teacher-AI teaming: transactional, situational, operational, praxical and synergistic teaming. The framework aims to capture the nuanced dynamics of teacher-AI interactions, particularly with GenAI, that may lead to the replacement, complementarity, or augmentation of teachers' competences and professional practice. GenAI technological affordances required in supporting teaming, along with empirical studies, are discussed. Drawing on empirical observations, we outline a future vision that moves beyond individual teacher agency toward collaborative decision-making between teachers and AI, in which both agents engage in negotiation, constructive challenge, and co-reasoning that enhance each other's capabilities and enable outcomes neither could realise independently. Further discussion of socio-technical factors beyond teacher-AI teaming is also included to streamline the synergy of teachers and AI in education ethically and practically.", 'abstract_zh': '生成型人工智能日益用于教育，在教师适应这些变化的过程中提出了重大挑战。生成型人工智能为教育任务提供了前所未有的便利性、可扩展性和生产力。然而，通过生成型人工智能自动化教学任务引发了关于教师自主权减少、潜在的认知退化以及更广泛的教育去专业化问题的担忧。借前人关于人工智能在教育中应用的研究成果，并通过最近的系统文献综述进行优化，本章提出了五种教师-人工智能协作层次的概念框架：事务性协作、情境性协作、操作性协作、实践性协作和协同性协作。该框架旨在捕捉教师-人工智能交互的复杂动态，特别是在生成型人工智能中的交互，可能涉及教师能力及专业实践的替代、互补或增强。讨论了支持协作的生成型人工智能技术特性及实证研究。基于实证观察，我们提出了一种超越单一教师自主权、走向教师与人工智能之间的合作决策的未来愿景，在这种愿景中，双方共同进行协商、建设性挑战和共同推理，以提升彼此的能力，并实现单凭一方难以实现的结果。还讨论了超出教师-人工智能协作的社会技术因素，以实现教育中教师和人工智能的伦理和实际协同。', 'title_zh': '面向生成式人工智能的协同教师-人工智能交互研究'}
{'arxiv_id': 'arXiv:2511.19565', 'title': 'Deductive Systems for Logic Programs with Counting', 'authors': 'Jorge Fandinno, Vladimir Lifschitz', 'link': 'https://arxiv.org/abs/2511.19565', 'abstract': 'In answer set programming, two groups of rules are considered strongly equivalent if they have the same meaning in any context. Strong equivalence of two programs can be sometimes established by deriving rules of each program from rules of the other in an appropriate deductive system. This paper shows how to extend this method of proving strong equivalence to programs containing the counting aggregate.', 'abstract_zh': '在回答集编程中，如果两组规则在任何上下文中具有相同的意义，则认为这两组规则是强烈等价的。有时可以通过在适当的演绎系统中从一组规则推导另一组规则的规则来建立两个程序的强烈等价性。本文展示了如何将这种方法扩展到包含计数聚合的程序中。', 'title_zh': '逻辑程序=counting=的演绎系统'}
{'arxiv_id': 'arXiv:2511.19562', 'title': 'Trust-Based Social Learning for Communication (TSLEC) Protocol Evolution in Multi-Agent Reinforcement Learning', 'authors': 'Abraham Itzhak Weinberg', 'link': 'https://arxiv.org/abs/2511.19562', 'abstract': "Emergent communication in multi-agent systems typically occurs through independent learning, resulting in slow convergence and potentially suboptimal protocols. We introduce TSLEC (Trust-Based Social Learning with Emergent Communication), a framework where agents explicitly teach successful strategies to peers, with knowledge transfer modulated by learned trust relationships. Through experiments with 100 episodes across 30 random seeds, we demonstrate that trust-based social learning reduces episodes-to-convergence by 23.9% (p < 0.001, Cohen's d = 1.98) compared to independent emergence, while producing compositional protocols (C = 0.38) that remain robust under dynamic objectives (Phi > 0.867 decoding accuracy). Trust scores strongly correlate with teaching quality (r = 0.743, p < 0.001), enabling effective knowledge filtering. Our results establish that explicit social learning fundamentally accelerates emergent communication in multi-agent coordination.", 'abstract_zh': '基于信任的社会学习在多智能体系统中的新兴通信', 'title_zh': '基于信任的社会学习通信（TSLEC）协议在多 agent 强化学习中的演化'}
{'arxiv_id': 'arXiv:2511.19561', 'title': 'Merging without Forgetting: Continual Fusion of Task-Specific Models via Optimal Transport', 'authors': 'Zecheng Pan, Zhikang Chen, Ding Li, Min Zhang, Sen Cui, Hongshuo Jin, Luqi Tao, Yi Yang, Deheng Ye, Yu Zhang, Tingting Zhu, Tianling Ren', 'link': 'https://arxiv.org/abs/2511.19561', 'abstract': 'Merging models fine-tuned for different tasks into a single unified model has become an increasingly important direction for building versatile, efficient multi-task systems. Existing approaches predominantly rely on parameter interpolation in weight space, which we show introduces significant distribution shift in the feature space and undermines task-specific knowledge. In this paper, we propose OTMF (Optimal Transport-based Masked Fusion), a novel model merging framework rooted in optimal transport theory to address the distribution shift that arises from naive parameter interpolation. Instead of directly aggregating features or weights, OTMF aligns the semantic geometry of task-specific models by discovering common masks applied to task vectors through optimal transport plans. These masks selectively extract transferable and task-agnostic components while preserving the unique structural identities of each task. To ensure scalability in real-world settings, OTMF further supports a continual fusion paradigm that incrementally integrates each new task vector without revisiting previous ones, maintaining a bounded memory footprint and enabling efficient fusion across a growing number of tasks. We conduct comprehensive experiments on multiple vision and language benchmarks, and results show that OTMF achieves state-of-the-art performance in terms of both accuracy and efficiency. These findings highlight the practical and theoretical value of our approach to model merging.', 'abstract_zh': '基于最优传输的掩蔽融合（OTMF）：一种解决任务特定知识丢失的新型模型融合框架', 'title_zh': '无忘持续融合：基于最优传输的任务特定模型持续融合'}
{'arxiv_id': 'arXiv:2511.19558', 'title': 'SPQR: A Standardized Benchmark for Modern Safety Alignment Methods in Text-to-Image Diffusion Models', 'authors': 'Mohammed Talha Alam, Nada Saadi, Fahad Shamshad, Nils Lukas, Karthik Nandakumar, Fahkri Karray, Samuele Poppi', 'link': 'https://arxiv.org/abs/2511.19558', 'abstract': 'Text-to-image diffusion models can emit copyrighted, unsafe, or private content. Safety alignment aims to suppress specific concepts, yet evaluations seldom test whether safety persists under benign downstream fine-tuning routinely applied after deployment (e.g., LoRA personalization, style/domain adapters). We study the stability of current safety methods under benign fine-tuning and observe frequent breakdowns. As true safety alignment must withstand even benign post-deployment adaptations, we introduce the SPQR benchmark (Safety-Prompt adherence-Quality-Robustness). SPQR is a single-scored metric that provides a standardized and reproducible framework to evaluate how well safety-aligned diffusion models preserve safety, utility, and robustness under benign fine-tuning, by reporting a single leaderboard score to facilitate comparisons. We conduct multilingual, domain-specific, and out-of-distribution analyses, along with category-wise breakdowns, to identify when safety alignment fails after benign fine-tuning, ultimately showcasing SPQR as a concise yet comprehensive benchmark for T2I safety alignment techniques for T2I models.', 'abstract_zh': 'Text-to-image扩散模型可能生成受版权保护、不安全或私人内容。安全对齐旨在抑制特定概念，但评估往往未测试安全性在部署后常规良性微调（例如LoRA个性化、风格/领域适配器）下能否保持。我们研究了当前安全方法在良性微调下的稳定性，观察到频繁出现失效。鉴于真正有效安全对齐必须能够应对即使是良性部署后适应，我们引入了SPQR基准（Safety-Prompt一致性-Quality-稳健性）。SPQR是一个单一评分指标，提供了一种标准化和可重复的框架，用于评估安全对齐的扩散模型在良性微调下如何保留安全性、实用性和稳健性，并通过发布单一排行榜评分以促进比较。我们进行了多语言、领域特定和分布外分析，以及类别级拆解，以识别良性微调后安全对齐失败的时间，并最终展示了SPQR作为T2I安全对齐技术的简洁而全面基准的潜力，适用于T2I模型。', 'title_zh': 'SPQR: 现代文本到图像扩散模型安全对齐方法的标准化基准'}
{'arxiv_id': 'arXiv:2511.19557', 'title': 'Think First, Assign Next (ThiFAN-VQA): A Two-stage Chain-of-Thought Framework for Post-Disaster Damage Assessment', 'authors': 'Ehsan Karimi, Nhut Le, Maryam Rahnemoonfar', 'link': 'https://arxiv.org/abs/2511.19557', 'abstract': 'Timely and accurate assessment of damages following natural disasters is essential for effective emergency response and recovery. Recent AI-based frameworks have been developed to analyze large volumes of aerial imagery collected by Unmanned Aerial Vehicles, providing actionable insights rapidly. However, creating and annotating data for training these models is costly and time-consuming, resulting in datasets that are limited in size and diversity. Furthermore, most existing approaches rely on traditional classification-based frameworks with fixed answer spaces, restricting their ability to provide new information without additional data collection or model retraining. Using pre-trained generative models built on in-context learning (ICL) allows for flexible and open-ended answer spaces. However, these models often generate hallucinated outputs or produce generic responses that lack domain-specific relevance. To address these limitations, we propose ThiFAN-VQA, a two-stage reasoning-based framework for visual question answering (VQA) in disaster scenarios. ThiFAN-VQA first generates structured reasoning traces using chain-of-thought (CoT) prompting and ICL to enable interpretable reasoning under limited supervision. A subsequent answer selection module evaluates the generated responses and assigns the most coherent and contextually accurate answer, effectively improve the model performance. By integrating a custom information retrieval system, domain-specific prompting, and reasoning-guided answer selection, ThiFAN-VQA bridges the gap between zero-shot and supervised methods, combining flexibility with consistency. Experiments on FloodNet and RescueNet-VQA, UAV-based datasets from flood- and hurricane-affected regions, demonstrate that ThiFAN-VQA achieves superior accuracy, interpretability, and adaptability for real-world post-disaster damage assessment tasks.', 'abstract_zh': '及时准确地评估自然灾害后的损失对于有效的应急响应和恢复至关重要。基于Recent AI技术框架能够快速分析由无人机收集的大规模航空影像，提供了行动指南。然而，创建和标注用于训练这些模型的数据成本高且耗时，导致数据集规模有限且缺乏多样性。此外，现有大多数方法依赖于传统的基于分类的框架，固定了答案空间，限制了提供新信息的能力，除非进行额外的数据收集或模型重新训练。使用基于上下文学习（ICL）的预训练生成模型可以实现灵活和开放的答案空间。然而，这些模型通常生成虚构的输出，或产生缺乏领域相关性的通用响应。为解决这些局限性，我们提出了一种名为ThiFAN-VQA的两阶段推理框架，用于灾害场景下的视觉问答（VQA）。ThiFAN-VQA首先使用链式思考（CoT）提示和ICL生成结构化推理轨迹，以在有限监督下实现可解释的推理。随后的答案选择模块评估生成的响应，并给出最连贯且上下文相关的答案，从而提高模型性能。通过整合自定义的信息检索系统、领域特定提示以及推理引导的答案选择，ThiFAN-VQA在零样本和监督方法之间架起桥梁，结合了灵活性和一致性。在FloodNet和受洪水和飓风影响区域的UAV数据集RescueNet-VQA上的实验表明，ThiFAN-VQA在真实世界灾害后损失评估任务中实现了更高的准确率、可解释性和适应性。', 'title_zh': '先思考后分配（ThiFAN-VQA）：一种用于灾后损害评估的两阶段思维链框架'}
{'arxiv_id': 'arXiv:2511.19555', 'title': 'Online Sparse Feature Selection in Data Streams via Differential Evolution', 'authors': 'Ruiyang Xu', 'link': 'https://arxiv.org/abs/2511.19555', 'abstract': 'The processing of high-dimensional streaming data commonly utilizes online streaming feature selection (OSFS) techniques. However, practical implementations often face challenges with data incompleteness due to equipment failures and technical constraints. Online Sparse Streaming Feature Selection (OS2FS) tackles this issue through latent factor analysis-based missing data imputation. Despite this advancement, existing OS2FS approaches exhibit substantial limitations in feature evaluation, resulting in performance deterioration. To address these shortcomings, this paper introduces a novel Online Differential Evolution for Sparse Feature Selection (ODESFS) in data streams, incorporating two key innovations: (1) missing value imputation using a latent factor analysis model, and (2) feature importance evaluation through differential evolution. Comprehensive experiments conducted on six real-world datasets demonstrate that ODESFS consistently outperforms state-of-the-art OSFS and OS2FS methods by selecting optimal feature subsets and achieving superior accuracy.', 'abstract_zh': '高维流数据处理通常利用在线流式特征选择（OSFS）技术。但由于设备故障和技术限制导致的数据不完备性，实际实施中常常面临挑战。基于潜在因子分析的缺失数据插补的在线稀疏流式特征选择（OS2FS）方法解决了这一问题。尽管如此，现有的OS2FS方法在特征评估方面仍存在显著限制，导致性能下降。为解决这些问题，本文提出了一种新的在线差分演化稀疏特征选择（ODESFS）方法，结合了两个关键创新：（1）使用潜在因子分析模型进行缺失值插补，（2）通过差分演化进行特征重要性评估。在六组真实数据集上的综合实验表明，ODESFS连贯地优于最先进的OSFS和OS2FS方法，通过选择最优特征子集并实现更高的准确性。', 'title_zh': '基于差分进化的数据流中在线稀疏特征选择'}
{'arxiv_id': 'arXiv:2511.19548', 'title': 'When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics', 'authors': 'Yiven', 'link': 'https://arxiv.org/abs/2511.19548', 'abstract': 'Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, "brain-based" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies "true" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.', 'abstract_zh': '神经经济学有望将福利分析建立在关于人们如何评估结果、从经验中学习和行使自我控制的神经和计算证据之上。同时，政策和商业行动者越来越多地引用神经数据来证明 paternalistic 规则、基于大脑的干预措施和新福利指标的正当性。本文探讨了在何种条件下神经数据能够合法地为政策制定提供福利判断依据，而不仅仅是描述行为。本文发展了一个非经验性的、基于模型的框架，将三个层次联系起来：神经信号、计算决策模型和规范性福利标准。在行为-批评强化学习模型中，本文形式化了从神经活动到潜在价值和预测误差，再到福利主张的推理路径。本文表明，只有当神经-计算映射得到充分验证、决策模型识别“真正的”利益而非情境依赖的错误，并且福利标准明确指定并得到辩护时，神经证据才能限制福利判断。将该框架应用于成瘾、神经市场营销和环境政策，本文为监管机构和NeuroAI系统设计师制定了神经经济学福利推理检查表。分析将大脑和人工代理视为价值学习系统，同时指出，无论内部奖励信号是生物学的还是人工的，都是计算量度，如果没有明确的规范性模型，它们不能被视为福利度量。', 'title_zh': '当神经数据应该影响福利？一种关于神经经济学在政策应用中的批判性框架'}
{'arxiv_id': 'arXiv:2511.19500', 'title': 'CycleChemist: A Dual-Pronged Machine Learning Framework for Organic Photovoltaic Discovery', 'authors': 'Hou Hei Lam, Jiangjie Qiu, Xiuyuan Hu, Wentao Li, Fankun Zeng, Siwei Fu, Hao Zhang, Xiaonan Wang', 'link': 'https://arxiv.org/abs/2511.19500', 'abstract': 'Organic photovoltaic (OPV) materials offer a promising path toward sustainable energy generation, but their development is limited by the difficulty of identifying high performance donor and acceptor pairs with strong power conversion efficiencies (PCEs). Existing design strategies typically focus on either the donor or the acceptor alone, rather than using a unified approach capable of modeling both components. In this work, we introduce a dual machine learning framework for OPV discovery that combines predictive modeling with generative molecular design. We present the Organic Photovoltaic Donor Acceptor Dataset (OPV2D), the largest curated dataset of its kind, containing 2000 experimentally characterized donor acceptor pairs. Using this dataset, we develop the Organic Photovoltaic Classifier (OPVC) to predict whether a material exhibits OPV behavior, and a hierarchical graph neural network that incorporates multi task learning and donor acceptor interaction modeling. This framework includes the Molecular Orbital Energy Estimator (MOE2) for predicting HOMO and LUMO energy levels, and the Photovoltaic Performance Predictor (P3) for estimating PCE. In addition, we introduce the Material Generative Pretrained Transformer (MatGPT) to produce synthetically accessible organic semiconductors, guided by a reinforcement learning strategy with three objective policy optimization. By linking molecular representation learning with performance prediction, our framework advances data driven discovery of high performance OPV materials.', 'abstract_zh': '有机光伏材料的大规模机器学习框架：从分子设计到性能预测', 'title_zh': 'CycleChemist: 一种双管齐下的机器学习框架用于有机光伏材料发现'}
{'arxiv_id': 'arXiv:2511.19499', 'title': 'Beyond Binary Classification: A Semi-supervised Approach to Generalized AI-generated Image Detection', 'authors': 'Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac', 'link': 'https://arxiv.org/abs/2511.19499', 'abstract': 'The rapid advancement of generators (e.g., StyleGAN, Midjourney, DALL-E) has produced highly realistic synthetic images, posing significant challenges to digital media authenticity. These generators are typically based on a few core architectural families, primarily Generative Adversarial Networks (GANs) and Diffusion Models (DMs). A critical vulnerability in current forensics is the failure of detectors to achieve cross-generator generalization, especially when crossing architectural boundaries (e.g., from GANs to DMs). We hypothesize that this gap stems from fundamental differences in the artifacts produced by these \\textbf{distinct architectures}. In this work, we provide a theoretical analysis explaining how the distinct optimization objectives of the GAN and DM architectures lead to different manifold coverage behaviors. We demonstrate that GANs permit partial coverage, often leading to boundary artifacts, while DMs enforce complete coverage, resulting in over-smoothing patterns. Motivated by this analysis, we propose the \\textbf{Tri}archy \\textbf{Detect}or (TriDetect), a semi-supervised approach that enhances binary classification by discovering latent architectural patterns within the "fake" class. TriDetect employs balanced cluster assignment via the Sinkhorn-Knopp algorithm and a cross-view consistency mechanism, encouraging the model to learn fundamental architectural distincts. We evaluate our approach on two standard benchmarks and three in-the-wild datasets against 13 baselines to demonstrate its generalization capability to unseen generators.', 'abstract_zh': '快速发展的生成器（例如StyleGAN、Midjourney、DALL-E）产生了高度逼真的合成图像，对数字媒体的真实性构成了重大挑战。这些生成器通常基于少数几种核心架构，主要是生成对抗网络（GANs）和扩散模型（DMs）。现有取证中的一个关键漏洞是对抗不同生成器的通用性检测不足，特别是在跨越架构边界时（例如，从GANs到DMs）。我们认为这一差距源自这些不同架构产生的基本差异。在本文中，我们提供了一个理论分析，解释了GAN和DM架构不同的优化目标如何导致不同的流形覆盖行为。我们证明了GAN允许部分覆盖，经常导致边界伪影，而DMs则强制完全覆盖，导致过平滑模式。受这一分析的启发，我们提出了三元体检测器（TriDetect），这是一种半监督方法，通过在“假”类中发现潜在的架构模式来增强二元分类。TriDetect利用Sinkhorn-Knopp算法进行平衡簇分配和跨视图一致性机制，鼓励模型学习基本的架构差异。我们在两个标准基准和三个野外数据集上对13种基线进行了评估，以展示其对未见生成器的泛化能力。', 'title_zh': '超越二元分类： generalized AI生成图像检测的半监督方法'}
{'arxiv_id': 'arXiv:2511.19497', 'title': 'PeriodNet: Boosting the Potential of Attention Mechanism for Time Series Forecasting', 'authors': 'Bowen Zhao, Huanlai Xing, Zhiwen Xiao, Jincheng Peng, Li Feng, Xinhan Wang, Rong Qu, Hui Li', 'link': 'https://arxiv.org/abs/2511.19497', 'abstract': 'The attention mechanism has demonstrated remarkable potential in sequence modeling, exemplified by its successful application in natural language processing with models such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT). Despite these advancements, its utilization in time series forecasting (TSF) has yet to meet expectations. Exploring a better network structure for attention in TSF holds immense significance across various domains. In this paper, we present PeriodNet with a brand new structure to forecast univariate and multivariate time series. PeriodNet incorporates period attention and sparse period attention mechanism for analyzing adjacent periods. It enhances the mining of local characteristics, periodic patterns, and global dependencies. For efficient cross-variable modeling, we introduce an iterative grouping mechanism which can directly reduce the cross-variable redundancy. To fully leverage the extracted features on the encoder side, we redesign the entire architecture of the vanilla Transformer and propose a period diffuser for precise multi-period prediction. Through comprehensive experiments conducted on eight datasets, we demonstrate that PeriodNet outperforms six state-of-the-art models in both univariate and multivariate TSF scenarios in terms of mean square error and mean absolute error. In particular, PeriodNet achieves a relative improvement of 22% when forecasting time series with a length of 720, in comparison to other models based on the conventional encoder-decoder Transformer architecture.', 'abstract_zh': 'PeriodNet：一种新的注意力机制在网络结构中用于时间序列 forecasting 的方法', 'title_zh': 'PeriodNet：增强时间序列预测中注意力机制的潜力'}
{'arxiv_id': 'arXiv:2511.19492', 'title': 'Forecasting AI Time Horizon Under Compute Slowdowns', 'authors': 'Parker Whitfill, Ben Snodin, Joel Becker', 'link': 'https://arxiv.org/abs/2511.19492', 'abstract': "METR's time horizon metric has grown exponentially since 2019, along with compute. However, it is unclear whether compute scaling will persist at current rates through 2030, raising the question of how possible compute slowdowns might impact AI agent capability forecasts. Given a model of time horizon as a function of training compute and algorithms, along with a model of how compute investment spills into algorithmic progress (which, notably, precludes the possibility of a software-only singularity), and the empirical fact that both time horizon and compute have grown at constant rates over 2019--2025, we derive that time horizon growth must be proportional to compute growth. We provide additional, albeit limited, experimental evidence consistent with this theory. We use our model to project time horizon growth under OpenAI's compute projection, finding substantial projected delays in some cases. For example, 1-month time horizons at $80\\%$ reliability occur $7$ years later than simple trend extrapolation suggests.", 'abstract_zh': 'METR的时间框架度量自2019年以来以指数方式增长，伴随计算能力的增长。然而，当前计算能力规模化的速度能否持续到2030年尚不明确，这引发了计算能力可能放缓将如何影响AI代理能力预测的疑问。给出时间框架作为训练计算和算法函数的模型，以及计算投资如何转化为算法进步的模型（这特别排除了软件单一性的可能性），并考虑到从2019年至2025年时间框架和计算能力都以恒定速度增长的事实，我们推导出时间框架的增长必须与计算能力的增长成比例。我们还提供了额外（尽管有限）的经验实验证据支持这一理论。我们使用该模型在OpenAI的计算预测下 projection time框架的増长，发现某些情况下存在重大延迟。例如，80%可靠性的1个月时间框架在简单趋势外推的情况下预计出现的时间会晚7年。', 'title_zh': '计算减速下的AI时间 horizons 预测'}
{'arxiv_id': 'arXiv:2511.19490', 'title': 'Generative Model-Aided Continual Learning for CSI Feedback in FDD mMIMO-OFDM Systems', 'authors': 'Guijun Liu, Yuwen Cao, Tomoaki Ohtsuki, Jiguang He, Shahid Mumtaz', 'link': 'https://arxiv.org/abs/2511.19490', 'abstract': 'Deep autoencoder (DAE) frameworks have demonstrated their effectiveness in reducing channel state information (CSI) feedback overhead in massive multiple-input multiple-output (mMIMO) orthogonal frequency division multiplexing (OFDM) systems. However, existing CSI feedback models struggle to adapt to dynamic environments caused by user mobility, requiring retraining when encountering new CSI distributions. Moreover, returning to previously encountered environments often leads to performance degradation due to catastrophic forgetting. Continual learning involves enabling models to incorporate new information while maintaining performance on previously learned tasks. To address these challenges, we propose a generative adversarial network (GAN)-based learning approach for CSI feedback. By using a GAN generator as a memory unit, our method preserves knowledge from past environments and ensures consistently high performance across diverse scenarios without forgetting. Simulation results show that the proposed approach enhances the generalization capability of the DAE framework while maintaining low memory overhead. Furthermore, it can be seamlessly integrated with other advanced CSI feedback models, highlighting its robustness and adaptability.', 'abstract_zh': '基于生成对抗网络（GAN）的信道状态信息（CSI）反馈学习方法', 'title_zh': '生成模型辅助的持续学习在FDD mMIMO-OFDM系统中的CSI反馈'}
{'arxiv_id': 'arXiv:2511.19482', 'title': "Human Experts' Evaluation of Generative AI for Contextualizing STEAM Education in the Global South", 'authors': 'Matthew Nyaaba, Macharious Nabang, Patrick Kyeremeh, Ibrahim Nantomah, Collins Owusu-Fordjour, Martin Ako, Bismark Nyaaba Akanzire, Kassim Korah Nantom, Cecilia Issaka, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2511.19482', 'abstract': "This study investigates how human experts evaluate the capacity of Generative AI (GenAI) to contextualize STEAM education in the Global South, with a focus on Ghana. Using a convergent mixed-methods design, four STEAM specialists assessed GenAI-generated lesson plans created with a customized Culturally Responsive Lesson Planner (CRLP) and compared them to standardized lesson plans from the Ghana National Council for Curriculum and Assessment (NaCCA). Quantitative ratings were based on a validated 25-item Culturally Responsive Pedagogy Rubric measuring bias awareness, cultural representation, contextual relevance, linguistic responsiveness, and teacher agency. Qualitative reflections provided additional insight into how GenAI handles cultural and pedagogical appropriateness.\nFindings show that GenAI, when paired with the CRLP tool, can support contextualized STEAM instruction by linking abstract curriculum standards to learners' cultural knowledge, community practices, and everyday experiences. Experts rated GenAI-assisted lessons as more culturally grounded and pedagogically responsive than NaCCA plans, integrating Indigenous knowledge, bilingual elements, and locally relevant examples. However, GenAI struggled to represent Ghana's cultural pluralism, often offering surface-level references to language, history, and identity. These weaknesses were most evident in Mathematics and Computing, where cultural nuance was limited. The results highlight the need for continued teacher mediation, community involvement, and culturally attuned refinement of AI outputs. Future work should include classroom trials, expanded expert participation, and model fine-tuning using Indigenous language corpora to strengthen cultural fidelity in Global South contexts.", 'abstract_zh': '本研究探讨了人类专家如何评估生成式人工智能（GenAI）在 Gloal South 地区 contextualize STEAM 教育的能力，以加纳为重点。研究采用了汇合混合方法设计，四名 STEAM 专家评估了使用定制文化响应式课程规划器（CRLP）生成的教学计划，并将其与加纳国家课程与评估委员会（NaCCA）的标准教学计划进行了比较。定量评分为基于经过验证的包含 25 项条目的文化响应式教学评鉴量表，该量表衡量了偏见意识、文化表现、上下文相关性、语言响应性和教师能动性。定性反思提供了关于 GenAI 如何处理文化适宜性和教学适宜性的额外见解。研究结果显示，当与 CRLP 工具结合使用时，GenAI 可以通过将抽象的课程标准与学习者的文化知识、社区实践和日常生活经验联系起来，支持 contextulized STEAM 教学。专家们认为，GenAI 辅助的教学计划比 NaCCA 计划更具文化根基和教学响应性，融入了原住民知识、双语元素和当地的相关例子。然而，GenAI 在表现加纳的文化多元性方面存在困难，经常提供表面化的语言、历史和身份参考。这些薄弱环节在数学和计算领域尤为明显，文化细微差异有限。研究结果强调了持续教师介导、社区参与和人工智能输出的文化契合度调整的必要性。未来的研究应包括课堂试验、扩大专家参与，并使用原住民语言语料库对模型进行微调，以加强 Global South 地区的 文化忠实性。', 'title_zh': '人类专家对生成式AI在全球南方情境化STEAM教育中的评价'}
{'arxiv_id': 'arXiv:2511.19476', 'title': 'FAST: Topology-Aware Frequency-Domain Distribution Matching for Coreset Selection', 'authors': 'Jin Cui, Boran Zhao, Jiajun Xu, Jiaqi Guo, Shuo Guan, Pengju Ren', 'link': 'https://arxiv.org/abs/2511.19476', 'abstract': 'Coreset selection compresses large datasets into compact, representative subsets, reducing the energy and computational burden of training deep neural networks. Existing methods are either: (i) DNN-based, which are tied to model-specific parameters and introduce architectural bias; or (ii) DNN-free, which rely on heuristics lacking theoretical guarantees. Neither approach explicitly constrains distributional equivalence, largely because continuous distribution matching is considered inapplicable to discrete sampling. Moreover, prevalent metrics (e.g., MSE, KL, MMD, CE) cannot accurately capture higher-order moment discrepancies, leading to suboptimal coresets. In this work, we propose FAST, the first DNN-free distribution-matching coreset selection framework that formulates the coreset selection task as a graph-constrained optimization problem grounded in spectral graph theory and employs the Characteristic Function Distance (CFD) to capture full distributional information in the frequency domain. We further discover that naive CFD suffers from a "vanishing phase gradient" issue in medium and high-frequency regions; to address this, we introduce an Attenuated Phase-Decoupled CFD. Furthermore, for better convergence, we design a Progressive Discrepancy-Aware Sampling strategy that progressively schedules frequency selection from low to high, preserving global structure before refining local details and enabling accurate matching with fewer frequencies while avoiding overfitting. Extensive experiments demonstrate that FAST significantly outperforms state-of-the-art coreset selection methods across all evaluated benchmarks, achieving an average accuracy gain of 9.12%. Compared to other baseline coreset methods, it reduces power consumption by 96.57% and achieves a 2.2x average speedup, underscoring its high performance and energy efficiency.', 'abstract_zh': 'FAST：一种基于图约束优化和特征函数距离的无深度神经网络聚 Sundays coreset选择框架', 'title_zh': 'FAST：基于拓扑结构的频域分布匹配核心样本选择方法'}
{'arxiv_id': 'arXiv:2511.19472', 'title': 'PrefixGPT: Prefix Adder Optimization by a Generative Pre-trained Transformer', 'authors': 'Ruogu Ding, Xin Ning, Ulf Schlichtmann, Weikang Qian', 'link': 'https://arxiv.org/abs/2511.19472', 'abstract': "Prefix adders are widely used in compute-intensive applications for their high speed. However, designing optimized prefix adders is challenging due to strict design rules and an exponentially large design space. We introduce PrefixGPT, a generative pre-trained Transformer (GPT) that directly generates optimized prefix adders from scratch. Our approach represents an adder's topology as a two-dimensional coordinate sequence and applies a legality mask during generation, ensuring every design is valid by construction. PrefixGPT features a customized decoder-only Transformer architecture. The model is first pre-trained on a corpus of randomly synthesized valid prefix adders to learn design rules and then fine-tuned to navigate the design space for optimized design quality. Compared with existing works, PrefixGPT not only finds a new optimal design with a 7.7% improved area-delay product (ADP) but exhibits superior exploration quality, lowering the average ADP by up to 79.1%. This demonstrates the potential of GPT-style models to first master complex hardware design principles and then apply them for more efficient design optimization.", 'abstract_zh': 'PrefixGPT：直接生成优化前缀加法器的预训练生成变换器', 'title_zh': 'PrefixGPT：由生成式预训练变换器实现的前缀加法器优化'}
{'arxiv_id': 'arXiv:2511.19466', 'title': 'SG-OIF: A Stability-Guided Online Influence Framework for Reliable Vision Data', 'authors': 'Penghao Rao, Runmin Jiang, Min Xu', 'link': 'https://arxiv.org/abs/2511.19466', 'abstract': 'Approximating training-point influence on test predictions is critical for deploying deep-learning vision models, essential for locating noisy data. Though the influence function was proposed for attributing how infinitesimal up-weighting or removal of individual training examples affects model outputs, its implementation is still challenging in deep-learning vision models: inverse-curvature computations are expensive, and training non-stationarity invalidates static approximations. Prior works use iterative solvers and low-rank surrogates to reduce cost, but offline computation lags behind training dynamics, and missing confidence calibration yields fragile rankings that misidentify critical examples. To address these challenges, we introduce a Stability-Guided Online Influence Framework (SG-OIF), the first framework that treats algorithmic stability as a real-time controller, which (i) maintains lightweight anchor IHVPs via stochastic Richardson and preconditioned Neumann; (ii) proposes modular curvature backends to modulate per-example influence scores using stability-guided residual thresholds, anomaly gating, and confidence. Experimental results show that SG-OIF achieves SOTA (State-Of-The-Art) on noise-label and out-of-distribution detection tasks across multiple datasets with various corruption. Notably, our approach achieves 91.1\\% accuracy in the top 1\\% prediction samples on the CIFAR-10 (20\\% asym), and gets 99.8\\% AUPR score on MNIST, effectively demonstrating that this framework is a practical controller for online influence estimation.', 'abstract_zh': '基于稳定性引导的在线影响框架：用于检测噪声数据的关键训练点近似计算', 'title_zh': 'SG-OIF: 一种基于稳定性的在线影响框架以确保视觉数据的可靠性'}
{'arxiv_id': 'arXiv:2511.19465', 'title': 'Hidden markov model to predict tourists visited place', 'authors': 'Theo Demessance, Chongke Bi, Sonia Djebali, Guillaume Guerard', 'link': 'https://arxiv.org/abs/2511.19465', 'abstract': "Nowadays, social networks are becoming a popular way of analyzing tourist behavior, thanks to the digital traces left by travelers during their stays on these networks. The massive amount of data generated; by the propensity of tourists to share comments and photos during their trip; makes it possible to model their journeys and analyze their behavior. Predicting the next movement of tourists plays a key role in tourism marketing to understand demand and improve decision support. In this paper, we propose a method to understand and to learn tourists' movements based on social network data analysis to predict future movements. The method relies on a machine learning grammatical inference algorithm. A major contribution in this paper is to adapt the grammatical inference algorithm to the context of big data. Our method produces a hidden Markov model representing the movements of a group of tourists. The hidden Markov model is flexible and editable with new data. The capital city of France, Paris is selected to demonstrate the efficiency of the proposed methodology.", 'abstract_zh': '现今，社交媒体成为分析旅游行为的一种流行方式，得益于游客在这些网络上留下的数字足迹。大量数据的生成，由于游客在旅行期间倾向于分享评论和照片，使得能够建模他们的旅行路径并分析其行为。预测游客的下一步行动对于理解需求并在旅游营销中提供决策支持起着关键作用。本文提出了一种基于社会网络数据分析理解并学习游客行动的方法，该方法依赖于机器学习语法推断算法。本文的一个重要贡献是将语法推断算法适应大数据环境。我们的方法生成了一个隐藏马尔可夫模型，代表了一组游客的行动路径，并且该模型具有灵活性和可编辑性。为了展示所提方法的有效性，选择了法国首都巴黎作为案例研究。', 'title_zh': '隐马尔可夫模型预测游客访问地点'}
{'arxiv_id': 'arXiv:2511.19464', 'title': 'Temperature in SLMs: Impact on Incident Categorization in On-Premises Environments', 'authors': 'Marcio Pohlmann, Alex Severo, Gefté Almeida, Diego Kreutz, Tiago Heinrich, Lourenço Pereira', 'link': 'https://arxiv.org/abs/2511.19464', 'abstract': 'SOCs and CSIRTs face increasing pressure to automate incident categorization, yet the use of cloud-based LLMs introduces costs, latency, and confidentiality risks. We investigate whether locally executed SLMs can meet this challenge. We evaluated 21 models ranging from 1B to 20B parameters, varying the temperature hyperparameter and measuring execution time and precision across two distinct architectures. The results indicate that temperature has little influence on performance, whereas the number of parameters and GPU capacity are decisive factors.', 'abstract_zh': '基于本地执行的SLMs能否应对SOCs和CSIRTs的事件分类挑战：参数数量和GPU容量是决定因素', 'title_zh': 'SLMs中的温度影响：基于本地环境的事件分类'}
{'arxiv_id': 'arXiv:2511.19460', 'title': 'Systemic approach for modeling a generic smart grid', 'authors': 'Sofiane Ben Amor, Guillaume Guerard, Loup-Noé Levy', 'link': 'https://arxiv.org/abs/2511.19460', 'abstract': 'Smart grid technological advances present a recent class of complex interdisciplinary modeling and increasingly difficult simulation problems to solve using traditional computational methods. To simulate a smart grid requires a systemic approach to integrated modeling of power systems, energy markets, demand-side management, and much other resources and assets that are becoming part of the current paradigm of the power grid. This paper presents a backbone model of a smart grid to test alternative scenarios for the grid. This tool simulates disparate systems to validate assumptions before the human scale model. Thanks to a distributed optimization of subsystems, the production and consumption scheduling is achieved while maintaining flexibility and scalability.', 'abstract_zh': '智能电网的技术进步提出了一个近期的复杂跨学科建模类别，并给传统计算方法带来日益艰巨的模拟挑战。为了模拟智能电网，需要一种系统的综合建模方法，将电力系统、能源市场、需求侧管理以及其他已成为当前电力网络范式的一部分的资源和资产结合起来。本文介绍了一种智能电网的核心模型，用于测试电网的替代情景。该工具模拟不同系统以在进行人类规模的模型前验证假设。借助子系统分布式优化，实现了生产和消费调度，在保持灵活性和可扩展性的同时。', 'title_zh': '系统建模通用型智能电网的方法'}
{'arxiv_id': 'arXiv:2511.19458', 'title': 'Personalized Reward Modeling for Text-to-Image Generation', 'authors': 'Jeongeun Lee, Ryang Heo, Dongha Lee', 'link': 'https://arxiv.org/abs/2511.19458', 'abstract': 'Recent text-to-image (T2I) models generate semantically coherent images from textual prompts, yet evaluating how well they align with individual user preferences remains an open challenge. Conventional evaluation methods, general reward functions or similarity-based metrics, fail to capture the diversity and complexity of personal visual tastes. In this work, we present PIGReward, a personalized reward model that dynamically generates user-conditioned evaluation dimensions and assesses images through CoT reasoning. To address the scarcity of user data, PIGReward adopt a self-bootstrapping strategy that reasons over limited reference data to construct rich user contexts, enabling personalization without user-specific training. Beyond evaluation, PIGReward provides personalized feedback that drives user-specific prompt optimization, improving alignment between generated images and individual intent. We further introduce PIGBench, a per-user preference benchmark capturing diverse visual interpretations of shared prompts. Extensive experiments demonstrate that PIGReward surpasses existing methods in both accuracy and interpretability, establishing a scalable and reasoning-based foundation for personalized T2I evaluation and optimization. Taken together, our findings highlight PIGReward as a robust steptoward individually aligned T2I generation.', 'abstract_zh': '近期的文本到图像（T2I）模型能够从文本提示中生成语义一致的图像，然而评估这些模型如何与个体用户偏好相匹配仍然是一个开放的挑战。传统的评估方法，通用的奖励函数或基于相似性的度量，无法捕捉个人视觉喜好的多样性和复杂性。在本文中，我们提出了PIGReward，这是一种个人化奖励模型，能够动态生成用户条件化的评估维度并通过CoT推理评估图像。为了解决用户数据稀缺的问题，PIGReward采用了一种自我-bootstrap策略，通过有限的参考数据进行推理以构建丰富的用户上下文，从而实现个性化而无需用户特定的训练。超越评估，PIGReward还提供了个性化反馈，以驱动用户特定提示优化，从而提高生成图像与个体意图的一致性。我们进一步引入了PIGBench，这是一种针对每个用户偏好的基准测试，能够捕捉共享提示的多样视觉解释。大量的实验表明，PIGReward在准确性和可解释性方面超越了现有方法，为个性化T2I评估与优化提供了可扩展且基于推理的基础。综上所述，我们的研究成果突显了PIGReward作为个体对齐T2I生成的稳健步骤的重要性。', 'title_zh': '个性化奖励建模for文本生成为图像'}
{'arxiv_id': 'arXiv:2511.19457', 'title': 'SparOA: Sparse and Operator-aware Hybrid Scheduling for Edge DNN Inference', 'authors': 'Ziyang Zhang, Jie Liu, Luca Mottola', 'link': 'https://arxiv.org/abs/2511.19457', 'abstract': 'The resource demands of deep neural network (DNN) models introduce significant performance challenges, especially when deployed on resource-constrained edge devices. Existing solutions like model compression often sacrifice accuracy, while specialized hardware remains costly and inflexible. Hybrid inference methods, however, typically overlook how operator characteristics impact performance. In this work, we present SparOA, a CPU-GPU hybrid inference framework, which leverages both sparsity and computational intensity to optimize operator scheduling. SparOA embraces aforementioned challenges through three key components: (1) a threshold predictor that accurately determines optimal sparsity and computational intensity thresholds; (2) a reinforcement learning-based scheduler that dynamically optimizes resource allocation based on real-time hardware states; and (3) a hybrid inference engine that enhances efficiency through asynchronous execution and batch size this http URL results show that SparOA achieves an average speedup of 1.22-1.31x compared to all baselines, and outperforms the CPU-Only by up to 50.7x. Also, SparOA achieves optimal energy-per-inference, consuming 7\\%-16\\% less energy than the SOTA co-execution baseline.', 'abstract_zh': '基于稀疏性和计算强度的CPU-GPU混合推理框架SparOA及其性能优化研究', 'title_zh': 'SparOA: 稀疏和运算器感知的边缘DNN推理混合调度'}
{'arxiv_id': 'arXiv:2511.17645', 'title': 'BlockCert: Certified Blockwise Extraction of Transformer Mechanisms', 'authors': 'Sandro Andric', 'link': 'https://arxiv.org/abs/2511.17645', 'abstract': 'Mechanistic interpretability aspires to reverse-engineer neural networks into explicit algorithms, while model editing seeks to modify specific behaviours without retraining. Both areas are typically evaluated with informal evidence and ad-hoc experiments, with few explicit guarantees about how far an extracted or edited model can drift from the original on relevant inputs. We introduce BlockCert, a framework for certified blockwise extraction of transformer mechanisms, and outline how a lightweight extension can support certified local edits. Given a pre-trained transformer and a prompt distribution, BlockCert extracts structured surrogate implementations for residual blocks together with machine-checkable certificates that bound approximation error, record coverage metrics, and hash the underlying artifacts. We formalize a simple Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees to a global deviation bound. Empirically, we apply the framework to GPT-2 small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain high per-block coverage and small residual errors on the evaluated prompts, and in the TinyLlama setting we show that a fully stitched model matches the baseline perplexity within approximately 6e-5 on stress prompts. Our results suggest that blockwise extraction with explicit certificates is feasible for real transformer language models and offers a practical bridge between mechanistic interpretability and formal reasoning about model behaviour.', 'abstract_zh': '块级认证提取框架及其支持的认证局部编辑为真实的变换器语言模型提供了机械可解释性和形式化推理之间的实用桥梁', 'title_zh': 'BlockCert：基于块级提取的变压器机制认证'}
