{'arxiv_id': 'arXiv:2502.09170', 'title': 'LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement', 'authors': 'Daocheng Fu, Naiting Zhong, Xu Han, Pinlong Cai, Licheng Wen, Song Mao, Botian Shi, Yu Qiao', 'link': 'https://arxiv.org/abs/2502.09170', 'abstract': 'Closed-loop simulation environments play a crucial role in the validation and enhancement of autonomous driving systems (ADS). However, certain challenges warrant significant attention, including balancing simulation accuracy with duration, reconciling functionality with practicality, and establishing comprehensive evaluation mechanisms. This paper addresses these challenges by introducing the LimSim Series, a comprehensive simulation platform designed to support the rapid deployment and efficient iteration of ADS. The LimSim Series integrates multi-type information from road networks, employs human-like decision-making and planning algorithms for background vehicles, and introduces the concept of the Area of Interest (AoI) to optimize computational resources. The platform offers a variety of baseline algorithms and user-friendly interfaces, facilitating flexible validation of multiple technical pipelines. Additionally, the LimSim Series incorporates multi-dimensional evaluation metrics, delivering thorough insights into system performance, thus enabling researchers to promptly identify issues for further improvements. Experiments demonstrate that the LimSim Series is compatible with modular, end-to-end, and VLM-based knowledge-driven systems. It can assist in the iteration and updating of ADS by evaluating performance across various scenarios. The code of the LimSim Series is released at: this https URL.', 'abstract_zh': '闭-loop仿真环境在自主驾驶系统（ADS）的验证与提升中发挥着关键作用，然而，某些挑战需要引起重视，包括平衡仿真准确性和时间长度、协调功能性和实用性以及建立全面的评估机制。本文通过引入LimSim系列综合仿真平台来应对这些挑战，该平台旨在支持ADS的快速部署和高效迭代。LimSim系列整合了多种道路网络信息，采用了人类类似的决策和规划算法来模拟背景车辆，并引入了兴趣区域（Area of Interest，AoI）的概念来优化计算资源。该平台提供了多种基本算法和用户友好的界面，便于灵活验证多个技术管线。此外，LimSim系列还整合了多维度的评估指标，提供了系统性能的全面洞察，从而帮助研究人员及时发现需要改进的问题。实验表明，LimSim系列兼容模块化、端到端和基于VLM的知识驱动系统，可以辅助在各种场景下评估和更新ADS。LimSim系列的代码发布在：this https URL。', 'title_zh': 'LimSim系列：一种用于验证和增强的 Autonomous Driving Simulation Platform'}
{'arxiv_id': 'arXiv:2502.08676', 'title': 'LIR-LIVO: A Lightweight,Robust LiDAR/Vision/Inertial Odometry with Illumination-Resilient Deep Features', 'authors': 'Shujie Zhou, Zihao Wang, Xinye Dai, Weiwei Song, Shengfeng Gu', 'link': 'https://arxiv.org/abs/2502.08676', 'abstract': "In this paper, we propose LIR-LIVO, a lightweight and robust LiDAR-inertial-visual odometry system designed for challenging illumination and degraded environments. The proposed method leverages deep learning-based illumination-resilient features and LiDAR-Inertial-Visual Odometry (LIVO). By incorporating advanced techniques such as uniform depth distribution of features enabled by depth association with LiDAR point clouds and adaptive feature matching utilizing Superpoint and LightGlue, LIR-LIVO achieves state-of-the-art (SOTA) accuracy and robustness with low computational cost. Experiments are conducted on benchmark datasets, including NTU-VIRAL, Hilti'22, and R3LIVE-Dataset. The corresponding results demonstrate that our proposed method outperforms other SOTA methods on both standard and challenging datasets. Particularly, the proposed method demonstrates robust pose estimation under poor ambient lighting conditions in the Hilti'22 dataset. The code of this work is publicly accessible on GitHub to facilitate advancements in the robotics community.", 'abstract_zh': '基于LiDAR-惯性-视觉里程计的轻量级鲁棒系统LIR-LIVO：针对复杂光照和降级环境的设计与实现', 'title_zh': 'LIR-LIVO：一种抗照度变化的轻量级、稳健的LiDAR/视觉/惯性里程计'}
{'arxiv_id': 'arXiv:2502.08664', 'title': 'Motion Forecasting for Autonomous Vehicles: A Survey', 'authors': 'Jianxin Shi, Jinhao Chen, Yuandong Wang, Li Sun, Chunyang Liu, Wei Xiong, Tianyu Wo', 'link': 'https://arxiv.org/abs/2502.08664', 'abstract': 'In recent years, the field of autonomous driving has attracted increasingly significant public interest. Accurately forecasting the future behavior of various traffic participants is essential for the decision-making of Autonomous Vehicles (AVs). In this paper, we focus on both scenario-based and perception-based motion forecasting for AVs. We propose a formal problem formulation for motion forecasting and summarize the main challenges confronting this area of research. We also detail representative datasets and evaluation metrics pertinent to this field. Furthermore, this study classifies recent research into two main categories: supervised learning and self-supervised learning, reflecting the evolving paradigms in both scenario-based and perception-based motion forecasting. In the context of supervised learning, we thoroughly examine and analyze each key element of the methodology. For self-supervised learning, we summarize commonly adopted techniques. The paper concludes and discusses potential research directions, aiming to propel progress in this vital area of AV technology.', 'abstract_zh': '近年来，自主驾驶领域吸引了日益显著的公众关注。准确预测各种交通参与者的未来行为对于自主车辆（AVs）的决策至关重要。本文集中探讨基于场景和基于感知的运动预测方法。我们提出了一种形式化的问题表述方法，并总结了该领域研究面临的主要挑战。此外，本文详细介绍了该领域相关的代表性数据集和评价指标。进一步地，本研究将最近的研究成果分为两大类：监督学习和自主学习，反映了基于场景和基于感知的运动预测领域演变中的范式变化。在监督学习背景下，我们全面分析了该方法的每个关键组成部分。对于自主学习，我们总结了常用的技巧。本文总结并讨论了潜在的研究方向，旨在促进这一关键领域的发展。', 'title_zh': '自主驾驶车辆的运动预测：一个综述'}
{'arxiv_id': 'arXiv:2502.09587', 'title': 'Rolling Ahead Diffusion for Traffic Scene Simulation', 'authors': 'Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood', 'link': 'https://arxiv.org/abs/2502.09587', 'abstract': 'Realistic driving simulation requires that NPCs not only mimic natural driving behaviors but also react to the behavior of other simulated agents. Recent developments in diffusion-based scenario generation focus on creating diverse and realistic traffic scenarios by jointly modelling the motion of all the agents in the scene. However, these traffic scenarios do not react when the motion of agents deviates from their modelled trajectories. For example, the ego-agent can be controlled by a stand along motion planner. To produce reactive scenarios with joint scenario models, the model must regenerate the scenario at each timestep based on new observations in a Model Predictive Control (MPC) fashion. Although reactive, this method is time-consuming, as one complete possible future for all NPCs is generated per simulation step. Alternatively, one can utilize an autoregressive model (AR) to predict only the immediate next-step future for all NPCs. Although faster, this method lacks the capability for advanced planning. We present a rolling diffusion based traffic scene generation model which mixes the benefits of both methods by predicting the next step future and simultaneously predicting partially noised further future steps at the same time. We show that such model is efficient compared to diffusion model based AR, achieving a beneficial compromise between reactivity and computational efficiency.', 'abstract_zh': '基于滚动扩散的交通场景生成模型：混合高效预测方法', 'title_zh': 'Rolling Ahead Diffusion 交通场景模拟'}
{'arxiv_id': 'arXiv:2502.09233', 'title': 'Commonsense Reasoning-Aided Autonomous Vehicle Systems', 'authors': 'Keegan Kimbrell', 'link': 'https://arxiv.org/abs/2502.09233', 'abstract': 'Autonomous Vehicle (AV) systems have been developed with a strong reliance on machine learning techniques. While machine learning approaches, such as deep learning, are extremely effective at tasks that involve observation and classification, they struggle when it comes to performing higher level reasoning about situations on the road. This research involves incorporating commonsense reasoning models that use image data to improve AV systems. This will allow AV systems to perform more accurate reasoning while also making them more adjustable, explainable, and ethical. This paper will discuss the findings so far and motivate its direction going forward.', 'abstract_zh': '基于机器学习的自主车辆系统已得以开发。虽然深度学习等机器学习方法在涉及观察和分类的任务中极为有效，但在进行道路情况的高层次推理方面存在困难。本研究旨在通过结合使用图像数据的常识推理模型，以提高自主车辆系统的能力。这将使得自主车辆系统能够进行更准确的推理，并且更具可调性、可解释性和伦理性。本文将讨论迄今为止的研究成果，并展望未来的研究方向。', 'title_zh': '常识推理辅助的自主车辆系统'}
{'arxiv_id': 'arXiv:2502.09211', 'title': 'Visual Graph Question Answering with ASP and LLMs for Language Parsing', 'authors': 'Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch', 'link': 'https://arxiv.org/abs/2502.09211', 'abstract': 'Visual Question Answering (VQA) is a challenging problem that requires to process multimodal input. Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures. In this work, we address the problem of how to integrate ASP with modules for vision and natural language processing to solve a new and demanding VQA variant that is concerned with images of graphs (not graphs in symbolic form). Images containing graph-based structures are an ubiquitous and popular form of visualisation. Here, we deal with the particular problem of graphs inspired by transit networks, and we introduce a novel dataset that amends an existing one by adding images of graphs that resemble metro lines. Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning. This method serves as a first baseline and achieves an overall average accuracy of 73% on the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pretrained models that do not involve any further training and logic programming for reasoning, to solve complex VQA tasks.', 'abstract_zh': '视觉问答（VQA）中的图图像问题：通过模块化神经符号方法结合ASP解决基于图形的图像问答任务', 'title_zh': '基于ASP和LLMs的视觉图语言解析的视觉图问答'}
{'arxiv_id': 'arXiv:2502.09620', 'title': 'Exploring the Potential of Encoder-free Architectures in 3D LMMs', 'authors': 'Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao', 'link': 'https://arxiv.org/abs/2502.09620', 'abstract': 'Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios. In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs). These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses. And we present the Hybrid Semantic Loss to extract high-level semantics. 2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage. This incorporates inductive bias into the LLM early layers to focus on the local details of the point clouds. To the end, we present the first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the classification, captioning, and VQA tasks, respectively. Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding. The code is released at this https URL', 'abstract_zh': '无encoder架构在3D理解场景中的潜力探索：无encoder 3D大型多模态模型ENEL的研究', 'title_zh': '探索3D LMMs中无编码器架构的潜力'}
{'arxiv_id': 'arXiv:2502.09471', 'title': 'Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection', 'authors': 'Yi Yu, Xue Yang, Yansheng Li, Zhenjun Han, Feipeng Da, Junchi Yan', 'link': 'https://arxiv.org/abs/2502.09471', 'abstract': 'Accurately estimating the orientation of visual objects with compact rotated bounding boxes (RBoxes) has become a prominent demand, which challenges existing object detection paradigms that only use horizontal bounding boxes (HBoxes). To equip the detectors with orientation awareness, supervised regression/classification modules have been introduced at the high cost of rotation annotation. Meanwhile, some existing datasets with oriented objects are already annotated with horizontal boxes or even single points. It becomes attractive yet remains open for effectively utilizing weaker single point and horizontal annotations to train an oriented object detector (OOD). We develop Wholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging various labeling forms (Points, HBoxes, RBoxes, and their combination) in a unified fashion. By only using HBox for training, our Wholly-WOOD achieves performance very close to that of the RBox-trained counterpart on remote sensing and other areas, significantly reducing the tedious efforts on labor-intensive annotation for oriented objects. The source codes are available at this https URL (PyTorch-based) and this https URL (Jittor-based).', 'abstract_zh': '使用紧凑旋转边界盒（RBoxes）精确估计视觉对象姿态的需求已成为一个突出的需求，这挑战了仅使用水平边界盒（HBoxes）的对象检测范式。为了使检测器具备姿态感知能力，引入了监督回归/分类模块，但会以高昂的代价标注旋转信息。同时，一些包含姿态对象的现有数据集已经使用水平边界盒或单个点进行了标注。因此，利用较弱的单点和水平标注有效训练姿态对象检测器（OOD）变得具有吸引力但尚未解决。我们开发了Wholly-WOOD，这是一种弱监督OOD框架，能够统一利用各种标注形式（点、水平边界盒、旋转边界盒及其组合）。仅使用水平边界盒进行训练，我们的Wholly-WOOD在遥感和其他领域中达到了与使用旋转边界盒进行训练的版本非常接近的性能，显著减少了对姿态对象标注的繁琐劳动。源代码可在以下链接获取：this <https URL>（基于PyTorch）和this <https URL>（基于Jittor）。', 'title_zh': 'Wholly-WOOD：充分利用多样化质量标签的弱监督定向对象检测'}
{'arxiv_id': 'arXiv:2502.09460', 'title': 'Metamorphic Testing for Pose Estimation Systems', 'authors': 'Matias Duran, Thomas Laurent, Ellen Rushe, Anthony Ventresque', 'link': 'https://arxiv.org/abs/2502.09460', 'abstract': 'Pose estimation systems are used in a variety of fields, from sports analytics to livestock care. Given their potential impact, it is paramount to systematically test their behaviour and potential for failure. This is a complex task due to the oracle problem and the high cost of manual labelling necessary to build ground truth keypoints. This problem is exacerbated by the fact that different applications require systems to focus on different subjects (e.g., human versus animal) or landmarks (e.g., only extremities versus whole body and face), which makes labelled test data rarely reusable. To combat these problems we propose MET-POSE, a metamorphic testing framework for pose estimation systems that bypasses the need for manual annotation while assessing the performance of these systems under different circumstances. MET-POSE thus allows users of pose estimation systems to assess the systems in conditions that more closely relate to their application without having to label an ad-hoc test dataset or rely only on available datasets, which may not be adapted to their application domain. While we define MET-POSE in general terms, we also present a non-exhaustive list of metamorphic rules that represent common challenges in computer vision applications, as well as a specific way to evaluate these rules. We then experimentally show the effectiveness of MET-POSE by applying it to Mediapipe Holistic, a state of the art human pose estimation system, with the FLIC and PHOENIX datasets. With these experiments, we outline numerous ways in which the outputs of MET-POSE can uncover faults in pose estimation systems at a similar or higher rate than classic testing using hand labelled data, and show that users can tailor the rule set they use to the faults and level of accuracy relevant to their application.', 'abstract_zh': 'Pose 估计系统的元测试框架：MET-POSE', 'title_zh': '姿态估计系统的演变测试'}
{'arxiv_id': 'arXiv:2502.09256', 'title': 'DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images', 'authors': 'Zesheng Li, Minwen Liao, Haoran Chen, Yan Su, Chengchang Pan, Honggang Qi', 'link': 'https://arxiv.org/abs/2502.09256', 'abstract': 'The hemorrhagic lesion segmentation plays a critical role in ophthalmic diagnosis, directly influencing early disease detection, treatment planning, and therapeutic efficacy evaluation. However, the task faces significant challenges due to lesion morphological variability, indistinct boundaries, and low contrast with background tissues. To improve diagnostic accuracy and treatment outcomes, developing advanced segmentation techniques remains imperative. This paper proposes an adversarial learning-based dynamic architecture adjustment approach that integrates hierarchical U-shaped encoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By dynamically optimizing feature fusion, our method enhances segmentation performance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU of 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955, effectively addressing the challenges in fundus image hemorrhage segmentation.[* Corresponding author.]', 'abstract_zh': '出血病变分割在眼科诊断中起着关键作用，直接影响早期疾病检测、治疗计划和治疗效果评估。然而，由于病变形态的可变性、边界不清以及与背景组织对比度低，该任务面临着重大挑战。为了提高诊断准确性和治疗效果，开发高级分割技术仍然是必不可少的。本文提出了一种基于对抗学习的动力架构调整方法，该方法结合了层次U形单向编码-解码器、残差块、注意力机制和ASPP模块。通过动态优化特征融合，我们的方法提高了分割性能。实验结果表明，Dice系数为0.6802，IoU为0.5602，召回率为0.766，精度为0.6525，准确率为0.9955，有效地解决了视网膜图像出血分割中的挑战。[*对应作者]。', 'title_zh': 'DynSegNet: 用于分割视网膜图像中出血病变的动态架构调整对抗学习方法'}
{'arxiv_id': 'arXiv:2502.09039', 'title': 'Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting', 'authors': 'Lingting Zhu, Guying Lin, Jinnan Chen, Xinjie Zhang, Zhenchao Jin, Zhao Wang, Lequan Yu', 'link': 'https://arxiv.org/abs/2502.09039', 'abstract': 'While Implicit Neural Representations (INRs) have demonstrated significant success in image representation, they are often hindered by large training memory and slow decoding speed. Recently, Gaussian Splatting (GS) has emerged as a promising solution in 3D reconstruction due to its high-quality novel view synthesis and rapid rendering capabilities, positioning it as a valuable tool for a broad spectrum of applications. In particular, a GS-based representation, 2DGS, has shown potential for image fitting. In our work, we present \\textbf{L}arge \\textbf{I}mages are \\textbf{G}aussians (\\textbf{LIG}), which delves deeper into the application of 2DGS for image representations, addressing the challenge of fitting large images with 2DGS in the situation of numerous Gaussian points, through two distinct modifications: 1) we adopt a variant of representation and optimization strategy, facilitating the fitting of a large number of Gaussian points; 2) we propose a Level-of-Gaussian approach for reconstructing both coarse low-frequency initialization and fine high-frequency details. Consequently, we successfully represent large images as Gaussian points and achieve high-quality large image representation, demonstrating its efficacy across various types of large images. Code is available at {\\href{this https URL}{this https URL}}.', 'abstract_zh': '大型图像为高斯表示：2DGS在大图像表示中的应用（Large Images are Gaussians: 2DGS for Large Image Representations）', 'title_zh': '大图像即高斯分布：基于2D高斯点变换的高保真大图像表示'}
{'arxiv_id': 'arXiv:2502.08774', 'title': 'Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound', 'authors': 'Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale', 'link': 'https://arxiv.org/abs/2502.08774', 'abstract': 'Monitoring the growth of subcortical regions of the fetal brain in ultrasound (US) images can help identify the presence of abnormal development. Manually segmenting these regions is a challenging task, but recent work has shown that it can be automated using deep learning. However, applying pretrained models to unseen freehand US volumes often leads to a degradation of performance due to the vast differences in acquisition and alignment. In this work, we first demonstrate that test time adaptation (TTA) can be used to improve model performance in the presence of both real and simulated domain shifts. We further propose a novel TTA method by incorporating a normative atlas as a prior for anatomy. In the presence of various types of domain shifts, we benchmark the performance of different TTA methods and demonstrate the improvements brought by our proposed approach, which may further facilitate automated monitoring of fetal brain development. Our code is available at this https URL.', 'abstract_zh': '在超声图像中监测胎儿大脑皮层下区域的生长有助于识别异常发育。手动分割这些区域是一项具有挑战性的任务，但近期研究表明，可以使用深度学习技术实现自动化。然而，将预训练模型应用于未见过的手动超声体积时，往往会由于采集和对齐的巨大差异而导致性能下降。在本工作中，我们首先证明，在实态和模拟领域转移的情况下，测试时适配（TTA）可以用于提升模型性能。我们进一步提出了一种新的TTA方法，通过将解剖学先验信息融入正态图进行集成。在各种类型领域转移的情况下，我们评估了不同TTA方法的性能，并展示了我们提出方法带来的改进，这有助于进一步实现胎儿大脑发育的自动化监测。我们的代码可在以下链接获取：this https URL。', 'title_zh': '探索基于3D超声的胎儿脑部亚皮层分割的测试时自适应方法'}
{'arxiv_id': 'arXiv:2502.08769', 'title': 'Cluster and Predict Latents Patches for Improved Masked Image Modeling', 'authors': 'Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski', 'link': 'https://arxiv.org/abs/2502.08769', 'abstract': 'Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI - a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2. We release all our code and models.', 'abstract_zh': '掩码图像建模（MIM）提供了一种有前途的自我监督表示学习方法，但现有MIM模型仍然落后于当前最佳水平。本文系统分析了目标表示、损失函数和架构，引入了一种新的纯MIM框架——CAPI，该框架依赖于对潜在聚类的预测。我们的方法利用基于聚类的损失，训练稳定，具有良好的放大特性。我们的ViT-L主干和CAPI在ImageNet上达到了83.8%的准确率，在ADE20K上达到了32.1%的mIoU，使用简单的线性探针显著优于以前的MIM方法，并接近当前最佳水平DINOv2。我们发布了所有代码和模型。', 'title_zh': '基于聚类和预测潜在片段以改进掩码图像建模'}
{'arxiv_id': 'arXiv:2502.08754', 'title': 'HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification', 'authors': 'Valentina Vadori, Jean-Marie Graïc, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan', 'link': 'https://arxiv.org/abs/2502.08754', 'abstract': 'Precise segmentation and classification of cell instances are vital for analyzing the tissue microenvironment in histology images, supporting medical diagnosis, prognosis, treatment planning, and studies of brain cytoarchitecture. However, the creation of high-quality annotated datasets for training remains a major challenge. This study introduces a novel single-stage approach (HistoSmith) for generating image-label pairs to augment histology datasets. Unlike state-of-the-art methods that utilize diffusion models with separate components for label and image generation, our approach employs a latent diffusion model to learn the joint distribution of cellular layouts, classification masks, and histology images. This model enables tailored data generation by conditioning on user-defined parameters such as cell types, quantities, and tissue types. Trained on the Conic H&E histopathology dataset and the Nissl-stained CytoDArk0 dataset, the model generates realistic and diverse labeled samples. Experimental results demonstrate improvements in cell instance segmentation and classification, particularly for underrepresented cell types like neutrophils in the Conic dataset. These findings underscore the potential of our approach to address data scarcity challenges.', 'abstract_zh': '精确的细胞实例分割与分类对于组织微环境分析至关重要，支持医疗诊断、预后、治疗计划以及脑细胞架构研究。然而，创建高质量标注数据集以进行训练仍是主要挑战。本研究提出了一种新颖的一阶段方法（HistoSmith），用于生成图像-标签对以扩充组织学数据集。与利用扩散模型且包含独立标签生成和图像生成组件的现有方法不同，我们的方法采用潜在扩散模型学习细胞布局、分类掩膜和组织学图像的联合分布。此模型通过条件化用户定义的参数（如细胞类型、数量和组织类型），实现定制化数据生成。该模型在Conic H&E组织病理学数据集和Nissl染色CytoDArk0数据集上训练，生成真实且多样的标注样本。实验结果证明了在细胞实例分割与分类方面的改进，尤其是对Conic数据集中代表性不足的细胞类型（如中性粒细胞）的改进。这些发现突显了我们方法解决数据匮乏挑战的潜力。', 'title_zh': 'HistoSmith: 基于条件潜在扩散的单阶段组织学图像标注生成以增强细胞分割和分类'}
{'arxiv_id': 'arXiv:2502.08690', 'title': 'Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation', 'authors': 'Hoigi Seo, Wongi Jeong, Jae-sun Seo, Se Young Chun', 'link': 'https://arxiv.org/abs/2502.08690', 'abstract': 'Large-scale text encoders in text-to-image (T2I) diffusion models have demonstrated exceptional performance in generating high-quality images from textual prompts. Unlike denoising modules that rely on multiple iterative steps, text encoders require only a single forward pass to produce text embeddings. However, despite their minimal contribution to total inference time and floating-point operations (FLOPs), text encoders demand significantly higher memory usage, up to eight times more than denoising modules. To address this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet effective pruning strategy specifically designed for text encoders in T2I diffusion models. Skrr exploits the inherent redundancy in transformer blocks by selectively skipping or reusing certain layers in a manner tailored for T2I tasks, thereby reducing memory consumption without compromising performance. Extensive experiments demonstrate that Skrr maintains image quality comparable to the original model even under high sparsity levels, outperforming existing blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory efficiency while preserving performance across multiple evaluation metrics, including the FID, CLIP, DreamSim, and GenEval scores.', 'abstract_zh': '大规模文本编码器在文本到图像（T2I）扩散模型中的应用已经展示了从文本提示生成高品質图像的出色性能。与依赖多步迭代的去噪模块不同，文本编码器只需单步前向传播即可生成文本嵌入。然而，尽管文本编码器对总推理时间和浮点运算（FLOPs）的贡献相对较小，但它们的内存使用量却高出多达八倍，远高于去噪模块。为解决这一效率问题，我们提出了一种简单而有效的剪枝策略——Skip and Re-use layers（Skrr），专门针对T2I扩散模型中的文本编码器。Skrr通过在Transformer块中选择性地跳过或重用某些层来利用其固有的冗余性，以适应T2I任务，从而在不牺牲性能的前提下降低内存消耗。实验结果表明，即使在高稀疏性水平下，Skrr仍能保持与原始模型相当的图像质量，并且在现有块级剪枝方法中脱颖而出。此外，Skrr在多个评估指标中实现了最先进的内存效率，同时保持了性能，包括FID、CLIP、DreamSim和GenEval得分。', 'title_zh': 'Skrr: 跳过并reuse文本编码层以实现高效的记忆文字到图像生成'}
{'arxiv_id': 'arXiv:2502.08689', 'title': 'Advancing machine fault diagnosis: A detailed examination of convolutional neural networks', 'authors': 'Govind Vashishtha, Sumika Chauhan, Mert Sehri, Justyna Hebda-Sobkowicz, Radoslaw Zimroz, Patrick Dumond, Rajesh Kumar', 'link': 'https://arxiv.org/abs/2502.08689', 'abstract': 'The growing complexity of machinery and the increasing demand for operational efficiency and safety have driven the development of advanced fault diagnosis techniques. Among these, convolutional neural networks (CNNs) have emerged as a powerful tool, offering robust and accurate fault detection and classification capabilities. This comprehensive review delves into the application of CNNs in machine fault diagnosis, covering its theoretical foundation, architectural variations, and practical implementations. The strengths and limitations of CNNs are analyzed in this domain, discussing their effectiveness in handling various fault types, data complexities, and operational environments. Furthermore, we explore the evolving landscape of CNN-based fault diagnosis, examining recent advancements in data augmentation, transfer learning, and hybrid architectures. Finally, we highlight future research directions and potential challenges to further enhance the application of CNNs for reliable and proactive machine fault diagnosis.', 'abstract_zh': '机械设备日益复杂以及对操作效率和安全性的日益增长需求推动了先进故障诊断技术的发展。在这之中，卷积神经网络（CNNs）已成为一种强大的工具，提供稳健且准确的故障检测和分类能力。本文通过对CNN在机器故障诊断中的应用进行全面回顾，涵盖其理论基础、架构变体和实际应用。分析了CNN在处理各种故障类型、数据复杂性和运行环境方面的优势与局限性。此外，本文探讨了基于CNN的故障诊断领域的发展态势，研究了数据增强、迁移学习和混合架构的最新进展。最后，本文指出了未来的研究方向和潜在挑战，以进一步增强CNN在可靠且主动的机器故障诊断中的应用。', 'title_zh': '机器故障诊断的进步：卷积神经网络的详细研究'}
