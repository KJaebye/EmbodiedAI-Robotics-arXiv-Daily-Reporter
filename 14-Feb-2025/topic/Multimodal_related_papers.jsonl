{'arxiv_id': 'arXiv:2502.09242', 'title': 'From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine', 'authors': 'Lukas Buess, Matthias Keicher, Nassir Navab, Andreas Maier, Soroosh Tayebi Arasteh', 'link': 'https://arxiv.org/abs/2502.09242', 'abstract': "Generative artificial intelligence (AI) models, such as diffusion models and OpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy and automating clinical workflows. The field has advanced rapidly, evolving from text-only large language models for tasks such as clinical documentation and decision support to multimodal AI systems capable of integrating diverse data modalities, including imaging, text, and structured data, within a single model. The diverse landscape of these technologies, along with rising interest, highlights the need for a comprehensive review of their applications and potential. This scoping review explores the evolution of multimodal AI, highlighting its methods, applications, datasets, and evaluation in clinical settings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed, IEEE Xplore, and Web of Science, prioritizing recent studies published up to the end of 2024. After rigorous screening, 144 papers were included, revealing key trends and challenges in this dynamic field. Our findings underscore a shift from unimodal to multimodal approaches, driving innovations in diagnostic support, medical report generation, drug discovery, and conversational AI. However, critical challenges remain, including the integration of heterogeneous data types, improving model interpretability, addressing ethical concerns, and validating AI systems in real-world clinical settings. This review summarizes the current state of the art, identifies critical gaps, and provides insights to guide the development of scalable, trustworthy, and clinically impactful multimodal AI solutions in healthcare.", 'abstract_zh': '生成式人工智能模型，如扩散模型和OpenAI的ChatGPT，正通过提升诊断准确性并自动化临床工作流程来变革医学。该领域发展迅速，从仅处理文本的大语言模型（例如，用于临床记录和决策支持）演变为能够整合影像、文本和结构化数据等多种数据模态的多模态AI系统。这些技术多样化的景观及其日益增长的兴趣，凸显了对其应用和潜力进行全面review的需求。本综述探讨了多模态AI的发展，强调其方法、应用、数据集及其在临床环境中的评价。依据PRISMA-ScR指南，系统地查询了PubMed、IEEE Xplore和Web of Science，优先考虑截至2024年底发表的最新研究。经过严格的筛选，最终纳入144篇论文，揭示了这一动态领域中的关键趋势和挑战。研究发现表明，从单模态到多模态方法的转变推动了诊断支持、医疗报告生成、药物发现和对话AI等领域的创新。然而，仍然存在关键挑战，包括不同数据类型的集成、模型可解释性的提高、伦理问题的解决以及在实际临床环境中验证AI系统的挑战。本综述总结了当前的最新技术状态，指出了关键的缺失部分，并提供了指导以促进可扩展、可信且具有临床影响力的多模态AI解决方案发展的见解。', 'title_zh': '从大型语言模型到多模态AI：生成式AI在医疗领域潜力的综述'}
{'arxiv_id': 'arXiv:2502.08942', 'title': 'Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative', 'authors': 'Zihao Li, Xiao Lin, Zhining Liu, Jiaru Zou, Ziwei Wu, Lecheng Zheng, Dongqi Fu, Yada Zhu, Hendrik Hamann, Hanghang Tong, Jingrui He', 'link': 'https://arxiv.org/abs/2502.08942', 'abstract': 'While many advances in time series models focus exclusively on numerical data, research on multimodal time series, particularly those involving contextual textual information commonly encountered in real-world scenarios, remains in its infancy. Consequently, effectively integrating the text modality remains challenging. In this work, we highlight an intuitive yet significant observation that has been overlooked by existing works: time-series-paired texts exhibit periodic properties that closely mirror those of the original time series. Building on this insight, we propose a novel framework, Texts as Time Series (TaTS), which considers the time-series-paired texts to be auxiliary variables of the time series. TaTS can be plugged into any existing numerical-only time series models and enable them to handle time series data with paired texts effectively. Through extensive experiments on both multimodal time series forecasting and imputation tasks across benchmark datasets with various existing time series models, we demonstrate that TaTS can enhance predictive performance and achieve outperformance without modifying model architectures.', 'abstract_zh': '尽管许多时间序列模型的进展主要集中在数值数据上，对多模态时间序列的研究尤其是涉及上下文文本信息的时间序列研究仍处于初级阶段。因此，有效地整合文本模态仍具有挑战性。在本文中，我们强调了一个直观但重要的观察，这一观察在现有工作中已被忽略：时间序列配对文本表现出与原始时间序列相似的周期性特性。基于这一洞察，我们提出了一种新颖的框架，名为时间序列中的文本（TaTS），该框架将时间序列配对文本视为时间序列的辅助变量。TaTS 可以插入任何现有的仅数值时间序列模型中，使其能够有效处理带有配对文本的时间序列数据。通过在多种基准数据集上的跨模态时间序列预测和插补任务中使用不同的现有时间序列模型进行广泛实验，我们证明了TaTS 可以提高预测性能，并在不修改模型架构的情况下实现超越。', 'title_zh': '时间之流中的语言：编织成统一时空叙事的时间序列配对文本'}
{'arxiv_id': 'arXiv:2502.08916', 'title': 'PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology', 'authors': 'Fatemeh Ghezloo, Mehmet Saygin Seyfioglu, Rustin Soraki, Wisdom O. Ikezogwo, Beibin Li, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna, Linda Shapiro', 'link': 'https://arxiv.org/abs/2502.08916', 'abstract': "Diagnosing diseases through histopathology whole slide images (WSIs) is fundamental in modern pathology but is challenged by the gigapixel scale and complexity of WSIs. Trained histopathologists overcome this challenge by navigating the WSI, looking for relevant patches, taking notes, and compiling them to produce a final holistic diagnostic. Traditional AI approaches, such as multiple instance learning and transformer-based models, fail short of such a holistic, iterative, multi-scale diagnostic procedure, limiting their adoption in the real-world. We introduce PathFinder, a multi-modal, multi-agent framework that emulates the decision-making process of expert pathologists. PathFinder integrates four AI agents, the Triage Agent, Navigation Agent, Description Agent, and Diagnosis Agent, that collaboratively navigate WSIs, gather evidence, and provide comprehensive diagnoses with natural language explanations. The Triage Agent classifies the WSI as benign or risky; if risky, the Navigation and Description Agents iteratively focus on significant regions, generating importance maps and descriptive insights of sampled patches. Finally, the Diagnosis Agent synthesizes the findings to determine the patient's diagnostic classification. Our Experiments show that PathFinder outperforms state-of-the-art methods in skin melanoma diagnosis by 8% while offering inherent explainability through natural language descriptions of diagnostically relevant patches. Qualitative analysis by pathologists shows that the Description Agent's outputs are of high quality and comparable to GPT-4o. PathFinder is also the first AI-based system to surpass the average performance of pathologists in this challenging melanoma classification task by 9%, setting a new record for efficient, accurate, and interpretable AI-assisted diagnostics in pathology. Data, code and models available at this https URL", 'abstract_zh': '通过对组织病理学全切片图像（WSIs）进行诊断是现代病理学的基础，但面临着GW级规模和复杂性的挑战。经过训练的专业病理学家通过导航WSIs、寻找相关斑块、做笔记并将它们汇总以生成最终的整体诊断来克服这一挑战。传统的AI方法，如多次实例学习和基于变换器的模型，未能实现这种整体的、迭代的、多尺度的诊断程序，限制了它们在现实世界中的应用。我们引入了PathFinder，一个多模态、多智能体框架，模仿专家病理学家的决策过程。PathFinder整合了四个AI代理——分流代理、导航代理、描述代理和诊断代理，它们协同导航WSIs，收集证据，并提供全面的诊断和自然语言解释。分流代理将WSIs分类为良性或风险类别；如果风险类别，则导航代理和描述代理迭代聚焦于重要区域，生成重要性和描述性洞察。最后，诊断代理综合这些发现以确定患者的诊断分类。实验结果显示，PathFinder在皮肤黑色素瘤诊断方面比最先进的方法提高了8%的性能，同时通过描述性斑块的自然语言描述提供了内在的可解释性。病理学家的定性分析表明，描述代理的输出质量高，可与GPT-4o媲美。PathFinder也是第一个在这一具有挑战性的黑色素瘤分类任务中超过平均病理学家表现9%的基于AI的系统，为高效、准确和可解释的AI辅助病理诊断设立了新纪录。数据、代码和模型可在以下链接获取。', 'title_zh': 'PathFinder: 多模态多 agent 系统在组织病理学诊断决策中的应用'}
{'arxiv_id': 'arXiv:2502.08826', 'title': 'Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation', 'authors': 'Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari', 'link': 'https://arxiv.org/abs/2502.08826', 'abstract': 'Large Language Models (LLMs) struggle with hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external dynamic information enhancing factual and updated grounding. Recent advances in multimodal learning have led to the development of Multimodal RAG, incorporating multiple modalities such as text, images, audio, and video to enhance the generated outputs. However, cross-modal alignment and reasoning introduce unique challenges to Multimodal RAG, distinguishing it from traditional unimodal RAG. This survey offers a structured and comprehensive analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks, evaluation, methodologies, and innovations in retrieval, fusion, augmentation, and generation. We precisely review training strategies, robustness enhancements, and loss functions, while also exploring the diverse Multimodal RAG scenarios. Furthermore, we discuss open challenges and future research directions to support advancements in this evolving field. This survey lays the foundation for developing more capable and reliable AI systems that effectively leverage multimodal dynamic external knowledge bases. Resources are available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）因依赖静态训练数据而在幻觉和过时知识方面存在挑战。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题，增强事实性和更新的知识基础。近年来多模态学习的进步促成了多模态RAG的发展，结合了多种模态，如文本、图像、音频和视频，以增强生成输出。然而，跨模态对齐和推理为多模态RAG带来了独特挑战，使其有别于传统的单模态RAG。本文综述提供了一种结构化的全面分析，涵盖了多模态RAG系统的数据集、指标、基准、评估、方法论以及检索、融合、增强和生成方面的创新。我们详细审查了训练策略、健壮性增强和损失函数，并探讨了多样的多模态RAG场景。此外，我们讨论了该领域的开放挑战和未来研究方向，以支持该领域的发展。本文为开发更强大和可靠、有效利用多模态动态外部知识库的AI系统奠定了基础。资源可在以下网址获得：this https URL。', 'title_zh': '在任意模态提问：一种全面的多模态检索增强生成综述'}
