{'arxiv_id': 'arXiv:2506.21536', 'title': 'PsyLite Technical Report', 'authors': 'Fangjun Ding, Renyu Zhang, Xinyu Feng, Chengye Xie, Zheng Zhang, Yanting Zhang', 'link': 'https://arxiv.org/abs/2506.21536', 'abstract': "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.", 'abstract_zh': '基于InternLM2.5-7B-chat的轻量级AI心理辅导模型PsyLite的研究', 'title_zh': 'PsyLite 技术报告'}
{'arxiv_id': 'arXiv:2506.21506', 'title': 'Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge', 'authors': 'Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su', 'link': 'https://arxiv.org/abs/2506.21506', 'abstract': 'Agentic search such as Deep Research systems, where large language models autonomously browse the web, synthesize information, and return comprehensive citation-backed answers, represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1,000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of nine frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, showing a great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.', 'abstract_zh': '代理搜索：Mind2Web 2——一种包含 130 个实时网页浏览和大量信息综合的现实、高质量和长期任务基准', 'title_zh': 'Mind2Web 2: 以代理为评审者的能动性搜索评估'}
{'arxiv_id': 'arXiv:2506.21490', 'title': 'Ad-Hoc Human-AI Coordination Challenge', 'authors': 'Tin Dizdarević, Ravi Hammond, Tobias Gessler, Anisoara Calinescu, Jonathan Cook, Matteo Gallici, Andrei Lupu, Jakob Nicolaus Foerster', 'link': 'https://arxiv.org/abs/2506.21490', 'abstract': 'Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{this https URL}{this https URL}.', 'abstract_zh': '实现人工智能代理与人类之间的无缝协调对于实际应用至关重要，但目前仍是一个重大开放挑战。自汉 Bürger 是一款包含不完美信息、受限通信、理论思维要求和协调行动的合作纸牌游戏，使其成为人类-人工智能协调的理想测试平台。然而，由于人类评估的挑战限制了其在人类-人工智能交互中的应用。在此项工作中，我们提出了即兴人类-人工智能协调挑战（AH2AC2），以克服成本高且难以复制的人类评估限制。我们开发了大规模人类数据集上的“人类代理代理”模型，作为 AH2AC2 中 robust、便宜且可重复的人类模拟评估伙伴。为了鼓励发展数据高效的方法，我们开源了一个包含 3,079 场游戏的数据集，故意限制可用的人类游戏数据量。我们分别呈现了两人和三人的汉 Bürger 场景的基础结果。为确保公平评估，我们通过受控评估系统托管代理模型，而不是公开发布。代码可在 \\href{this https URL}{this https URL} 获取。', 'title_zh': '即兴人类-人工智能协同挑战'}
{'arxiv_id': 'arXiv:2506.21458', 'title': 'Spatial Mental Modeling from Limited Views', 'authors': 'Baiqiao Yin, Qineng Wang, Pingyue Zhang, Jianshu Zhang, Kangrui Wang, Zihan Wang, Jieyu Zhang, Keshigeyan Chandrasegaran, Han Liu, Ranjay Krishna, Saining Xie, Manling Li, Jiajun Wu, Li Fei-Fei', 'link': 'https://arxiv.org/abs/2506.21458', 'abstract': 'Can Vision Language Models (VLMs) imagine the full scene from just a few views, like humans do? Humans form spatial mental models, internal representations of unseen space, to reason about layout, perspective, and motion. Our new MindCube benchmark with 21,154 questions across 3,268 images exposes this critical gap, where existing VLMs exhibit near-random performance. Using MindCube, we systematically evaluate how well VLMs build robust spatial mental models through representing positions (cognitive mapping), orientations (perspective-taking), and dynamics (mental simulation for "what-if" movements). We then explore three approaches to help VLMs approximate spatial mental models, including unseen intermediate views, natural language reasoning chains, and cognitive maps. The significant improvement comes from a synergistic approach, "map-then-reason", that jointly trains the model to first generate a cognitive map and then reason upon it. By training models to reason over these internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding reinforcement learning pushed performance even further to 70.7% (+32.9%). Our key insight is that such scaffolding of spatial mental models, actively constructing and utilizing internal structured spatial representations with flexible reasoning processes, significantly improves understanding of unobservable space.', 'abstract_zh': '视觉语言模型能否像人类一样仅从少数视角想象完整场景？MindCube：评估视觉语言模型构建空间mental模型能力的新基准', 'title_zh': '基于有限视角的空间心理建模'}
{'arxiv_id': 'arXiv:2506.21393', 'title': 'TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding', 'authors': 'Junwen Zhang, Pu Chen, Yin Zhang', 'link': 'https://arxiv.org/abs/2506.21393', 'abstract': "Multimodal understanding of tables in real-world contexts is challenging due to the complexity of structure, symbolic density, and visual degradation (blur, skew, watermarking, incomplete structures or fonts, multi-span or hierarchically nested layouts). Existing multimodal large language models (MLLMs) struggle with such WildStruct conditions, resulting in limited performance and poor generalization. To address these challenges, we propose TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture specifically designed for robust, structured reasoning over multimodal table data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which predicts latent semantic token roles (e.g., header, data cell, axis, formula) and dynamically routes table elements to specialized experts (Table-to-HTML, Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed by symbolic reasoning graphs. To facilitate effective alignment-driven pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of 1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and industry, utilized exclusively for model pretraining. For evaluation, we curate and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA, WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models under real-world multimodal degradation and structural complexity. Experimental results demonstrate that TableMoE significantly surpasses existing state-of-the-art models. Extensive ablation studies validate each core component, emphasizing the critical role of Neuro-Symbolic Routing and structured expert alignment. Through qualitative analyses, we further showcase TableMoE's interpretability and enhanced robustness, underscoring the effectiveness of integrating neuro-symbolic reasoning for multimodal table understanding.", 'abstract_zh': '多模态环境下现实世界表格的理解具有挑战性，由于结构复杂性、符号密集度以及视觉退化（模糊、倾斜、水印、不完整结构或字体、多跨或层次嵌套布局）等原因。现有的大规模语言模型在这些“WildStruct”条件下表现不佳，导致性能有限且泛化能力差。为解决这些挑战，我们提出TableMoE，一种专为多模态表格数据提供稳健结构推理的神经符号Mixture-of-Connector-Experts（MoCE）架构。TableMoE 特设一种创新的神经符号路由机制，该机制预测潜在语义令牌角色（例如，表头、数据单元格、轴、公式），并利用基于符号推理图的置信度感知门控策略将表格元素动态路由至专门的专家（表到HTML、表到JSON、表到代码）。为了促进有效的对齐驱动预训练，我们引入了大规模的TableMoE-Align数据集，包含120万张表格-HTML-JSON-代码四元组，这些数据仅用于模型预训练。为评估目的，我们精心策划并发布了四个具有挑战性的“WildStruct”基准：WMMFinQA、WMMTatQA、WMMTabDialog 和 WMMFinanceMath，这些基准旨在在现实世界多模态退化和结构复杂性条件下测试模型。实验结果表明，TableMoE 显著超越现有最先进的模型。广泛的消融研究验证了每个核心组件的作用，强调了神经符号路由和结构专家对齐的至关重要性。通过定量分析，我们进一步展示了TableMoE 的可解释性和增强的鲁棒性，突显了在多模态表格理解中结合神经符号推理的有效性。', 'title_zh': 'TableMoE: 结合神经与符号推理的多模态表格理解专家 reasoning 神经符号路由结构专家推理'}
{'arxiv_id': 'arXiv:2506.21329', 'title': 'Active Inference AI Systems for Scientific Discovery', 'authors': 'Karthik Duraisamy', 'link': 'https://arxiv.org/abs/2506.21329', 'abstract': 'The rapid evolution of artificial intelligence has led to expectations of transformative scientific discovery, yet current systems remain fundamentally limited by their operational architectures, brittle reasoning mechanisms, and their separation from experimental reality. Building on earlier work, we contend that progress in AI-driven science now depends on closing three fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap -- rather than on model size/data/test time compute. Scientific reasoning demands internal representations that support simulation of actions and response, causal structures that distinguish correlation from mechanism, and continuous calibration. We define active inference AI systems for scientific discovery as those that (i) maintain long-lived research memories grounded in causal self-supervised foundation models, (ii) symbolic or neuro-symbolic planners equipped with Bayesian guardrails, (iii) grow persistent knowledge graphs where thinking generates novel conceptual nodes, reasoning establishes causal edges, and real-world interaction prunes false connections while strengthening verified pathways, and (iv) refine their internal representations through closed-loop interaction with both high-fidelity simulators and automated laboratories - an operational loop where mental simulation guides action and empirical surprise reshapes understanding. In essence, we outline an architecture where discovery arises from the interplay between internal models that enable counterfactual reasoning and external validation that grounds hypotheses in reality. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties makes human judgment indispensable, not as a temporary scaffold but as a permanent architectural component.', 'abstract_zh': '人工智能的快速演化带来了变革性科学发现的期望，但当前系统依然在运行架构、脆弱的推理机制以及与实验现实的分离方面存在根本局限。基于前期工作，我们主张，AI驱动的科学研究的进步现在依赖于弥合三类根本性的差距——抽象差距、推理差距和现实差距，而不是依赖于模型规模、数据和测试时间计算能力。科学推理要求能够支持行动和响应模拟的内部表示，能够区分相关性与机制的因果结构，以及持续的校准。我们定义了进行科学发现的主动推断AI系统，这些系统需具备：(i) 基于因果自监督基础模型的长期研究记忆；(ii) 配备贝叶斯护栏的符号或神经符号规划者；(iii) 知识图谱的增长，其中思考生成新颖的概念节点，推理建立因果边，而现实世界交互去除错误连接并加强验证路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来精炼其内部表示——一种操作回路，其中心理模拟指导行动而实证惊讶重塑理解。本质上，我们勾勒出一种架构，其中发现源自内部模型所支持的反事实推理与外部验证的相互作用，将实验现实作为假设的基础。我们也认为，从模拟和实验获得的反馈固有的模糊性以及内在的不确定性使人为判断不可或缺，而不仅仅是作为暂时的架构支撑，而是作为永久性的架构组成部分。', 'title_zh': '基于活跃推断的AI系统及其在科学研究中的应用'}
{'arxiv_id': 'arXiv:2506.21310', 'title': 'IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems', 'authors': 'Pauline Speckmann, Mario Nadj, Christian Janiesch', 'link': 'https://arxiv.org/abs/2506.21310', 'abstract': "Although several post-hoc methods for explainable AI have been developed, most are static and neglect the user perspective, limiting their effectiveness for the target audience. In response, we developed the interactive explainable intelligent system called IXAII that offers explanations from four explainable AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored views for five user groups and gives users agency over the explanations' content and their format. We evaluated IXAII through interviews with experts and lay users. Our results indicate that IXAII, which provides different explanations with multiple visualization options, is perceived as helpful to increase transparency. By bridging the gaps between explainable AI methods, interactivity, and practical implementation, we provide a novel perspective on AI explanation practices and human-AI interaction.", 'abstract_zh': '尽管已经开发出几种事后解释的人工智能方法，但大多数方法都是静态的，忽视了用户视角，限制了它们对目标受众的有效性。为此，我们开发了交互式可解释智能系统IXAII，该系统提供了四种可解释人工智能方法（LIME、SHAP、Anchors和DiCE）的解释。我们的原型为五大用户群体提供了定制化的视图，并让用户能够控制解释的内容和格式。我们通过专家和普通用户的访谈对IXAII进行了评估。我们的结果表明，IXAII通过提供多种可视化选项的多种解释，被感知为有助于增加透明度。通过弥合可解释人工智能方法、交互性和实际实施之间的差距，我们为人工智能解释实践和人机交互提供了新的视角。', 'title_zh': 'IXAII：一种交互式可解释的人工智能接口用于决策支持系统'}
{'arxiv_id': 'arXiv:2506.21230', 'title': 'World-aware Planning Narratives Enhance Large Vision-Language Model Planner', 'authors': 'Junhao Shi, Zhaoye Fei, Siyin Wang, Qipeng Guo, Jingjing Gong, Xipeng QIu', 'link': 'https://arxiv.org/abs/2506.21230', 'abstract': 'Large Vision-Language Models (LVLMs) show promise for embodied planning tasks but struggle with complex scenarios involving unfamiliar environments and multi-step goals. Current approaches rely on environment-agnostic imitation learning that disconnects instructions from environmental contexts, causing models to struggle with context-sensitive instructions and rely on supplementary cues rather than visual reasoning during long-horizon interactions. In this work, we propose World-Aware Planning Narrative Enhancement (WAP), a framework that infuses LVLMs with comprehensive environmental understanding through four cognitive capabilities (visual appearance modeling, spatial reasoning, functional abstraction, and syntactic grounding) while developing and evaluating models using only raw visual observations through curriculum learning. Evaluations on the EB-ALFRED benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a 60.7 absolute improvement in task success rates, particularly in commonsense reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced open-source models outperform proprietary systems like GPT-4o and Claude-3.5-Sonnet by a large margin.', 'abstract_zh': 'Large Vision-Language Models with World-Aware Planning Narrative Enhancement show Promising Improvements in Complex Embodied Planning Tasks', 'title_zh': '世界意识规划叙事增强大型视觉语言模型规划者'}
{'arxiv_id': 'arXiv:2506.21215', 'title': 'Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?', 'authors': 'Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, Bo Han', 'link': 'https://arxiv.org/abs/2506.21215', 'abstract': "Causal reasoning capability is critical in advancing large language models (LLMs) toward strong artificial intelligence. While versatile LLMs appear to have demonstrated capabilities in understanding contextual causality and providing responses that obey the laws of causality, it remains unclear whether they perform genuine causal reasoning akin to humans. However, current evidence indicates the contrary. Specifically, LLMs are only capable of performing shallow (level-1) causal reasoning, primarily attributed to the causal knowledge embedded in their parameters, but they lack the capacity for genuine human-like (level-2) causal reasoning. To support this hypothesis, methodologically, we delve into the autoregression mechanism of transformer-based LLMs, revealing that it is not inherently causal. Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024, whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs exhibit a significant performance drop on CausalProbe-2024 compared to earlier benchmarks, indicating the fact that they primarily engage in level-1 causal reasoning. To bridge the gap towards level-2 causal reasoning, we draw inspiration from the fact that human reasoning is usually facilitated by general knowledge and intended goals. We propose G^2-Reasoner, a method that incorporates general knowledge and goal-oriented prompts into LLMs' causal reasoning processes. Experiments demonstrate that G^2-Reasoner significantly enhances LLMs' causal reasoning capability, particularly in fresh and counterfactual contexts. This work sheds light on a new path for LLMs to advance towards genuine causal reasoning, going beyond level-1 and making strides towards level-2.", 'abstract_zh': '因果推理能力是推动大型语言模型（LLMs）向强人工智能发展的关键。虽然多功能LLMs似乎展示了理解上下文因果关系并提供遵循因果法则的回应的能力，但尚不清楚它们是否进行了与人类类似的真正因果推理。然而，当前的证据表明并非如此。具体来说，LLMs仅具备浅层（第一层次）因果推理能力，主要归因于其参数中嵌入的因果知识，但它们缺乏与人类类似的深层（第二层次）因果推理能力。为了支持这一假设，从方法论上，我们深入探讨基于Transformer的LLMs的自回归机制，揭示出它并不是本原性的因果机制。从经验上，我们引入了一个新的因果问答基准——CausalProbe-2024，其语料库对研究中的LLMs来说几乎是前所未见的。LLMs在CausalProbe-2024上的表现大幅下降，表明它们主要进行的是浅层因果推理。为了弥补向深层因果推理的差距，我们从人类推理通常由一般知识和目标驱动的事实中得到启发。我们提出了G^2-Reasoner方法，该方法将一般知识和目标导向的提示纳入到LLMs的因果推理过程中。实验结果表明，G^2-Reasoner显著增强了LLMs的因果推理能力，特别是在新的和反事实的情景下。这项工作揭示了LLMs向真正因果推理前进的新路径，超越了浅层，并朝着深层迈进。', 'title_zh': '探索大型语言模型中的因果推理：现实还是幻象？'}
{'arxiv_id': 'arXiv:2506.20949', 'title': 'Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation', 'authors': 'Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji', 'link': 'https://arxiv.org/abs/2506.20949', 'abstract': "Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions. We propose a proof-of-concept framework that projects how model-generated advice could propagate through societal systems on a macroscopic scale over time, enabling more robust alignment. To assess the long-term safety awareness of language models, we also introduce a dataset of 100 indirect harm scenarios, testing models' ability to foresee adverse, non-obvious outcomes from seemingly harmless user prompts. Our approach achieves not only over 20% improvement on the new dataset but also an average win rate exceeding 70% against strong baselines on existing safety benchmarks (AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer agents.", 'abstract_zh': '基于语言模型的代理在高风险社会决策中的影响日益增大：一种评估长期安全意识的框架', 'title_zh': '超越反应性安全：基于长期模拟的风险感知大语言模型对齐'}
{'arxiv_id': 'arXiv:2506.20815', 'title': 'Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications', 'authors': 'Xinye Tang, Haijun Zhai, Chaitanya Belwal, Vineeth Thayanithi, Philip Baumann, Yogesh K Roy', 'link': 'https://arxiv.org/abs/2506.20815', 'abstract': 'LLM-powered applications are highly susceptible to the quality of user prompts, and crafting high-quality prompts can often be challenging especially for domain-specific applications. This paper presents a novel dynamic context-aware prompt recommendation system for domain-specific AI applications. Our solution combines contextual query analysis, retrieval-augmented knowledge grounding, hierarchical skill organization, and adaptive skill ranking to generate relevant and actionable prompt suggestions.\nThe system leverages behavioral telemetry and a two-stage hierarchical reasoning process to dynamically select and rank relevant skills, and synthesizes prompts using both predefined and adaptive templates enhanced with few-shot learning. Experiments on real-world datasets demonstrate that our approach achieves high usefulness and relevance, as validated by both automated and expert evaluations.', 'abstract_zh': '基于LLM的应用高度依赖用户的提示质量，而设计高质量的提示尤其是在特定领域应用中常常具有挑战性。本文提出了一种新颖的动态上下文感知提示推荐系统，适用于特定领域的AI应用。该解决方案结合了上下文查询分析、检索增强的知识 grounding、层级技能组织和自适应技能排名，以生成相关且可操作的提示建议。该系统利用行为遥测和两阶段层级推理过程动态选择和排序相关技能，并使用预定义和自适应模板结合少样本学习综合生成提示。实验结果在真实世界数据集上验证了该方法的高度实用性和相关性，得到了自动和专家评估的认可。', 'title_zh': '领域特定AI应用中的动态上下文感知提示推荐'}
{'arxiv_id': 'arXiv:2506.20737', 'title': 'MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation', 'authors': 'Gurusha Juneja, Alon Albalak, Wenyue Hua, William Yang Wang', 'link': 'https://arxiv.org/abs/2506.20737', 'abstract': 'The proliferation of LLM-based agents has led to increasing deployment of inter-agent collaboration for tasks like scheduling, negotiation, resource allocation etc. In such systems, privacy is critical, as agents often access proprietary tools and domain-specific databases requiring strict confidentiality. This paper examines whether LLM-based agents demonstrate an understanding of contextual privacy. And, if instructed, do these systems preserve inference time user privacy in non-adversarial multi-turn conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents primarily assess single-turn, low-complexity tasks where private information can be easily excluded. We first present a benchmark - MAGPIE comprising 158 real-life high-stakes scenarios across 15 domains. These scenarios are designed such that complete exclusion of private data impedes task completion yet unrestricted information sharing could lead to substantial losses. We then evaluate the current state-of-the-art LLMs on (a) their understanding of contextually private data and (b) their ability to collaborate without violating user privacy. Empirical experiments demonstrate that current models, including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual privacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the time. In multi-turn conversations, these models disclose private information in 59.9\\% and 50.5\\% of cases even under explicit privacy instructions. Furthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios. These results underscore that current models are not aligned towards both contextual privacy preservation and collaborative task-solving.', 'abstract_zh': '基于LLM的代理扩展导致了越来越多的代理间协作部署，用于如调度、谈判、资源分配等任务。在这种系统中，隐私至关重要，因为代理通常会访问专有工具和领域特定数据库，要求严格保密。本文考察了基于LLM的代理是否理解上下文隐私，并在非对抗性的多轮对话中，如果指示，是否能保护推理时间的用户隐私。现有针对上下文隐私评估的基准主要集中在单一回合、低复杂度的任务上，这些任务中私有信息容易被排除。我们首先提出了一个基准——MAGPIE，包含15个领域中的158个实际高风险场景。这些场景设计旨在完全排除私有数据会妨碍任务完成，而无限制的信息共享可能导致重大损失。然后，我们评估当前最先进的LLM的（a）对上下文隐私数据的理解以及（b）在不违反用户隐私的情况下协作的能力。实验证明，当前模型，包括GPT-4o和Claude-2.7-Sonnet，在理解上下文隐私方面缺乏稳健性，错误地将25.2%和43.6%的私有数据分类为可共享数据。在多轮对话中，即便在明确的隐私指令下，这些模型在59.9%和50.5%的情况下披露了私有信息。此外，在71%的场景中，多代理系统无法完成任务。这些结果强调当前模型未能同时实现上下文隐私保护和协作任务解决的目标。', 'title_zh': 'MAGPIE：一个多代理情境隐私评估数据集'}
{'arxiv_id': 'arXiv:2506.20702', 'title': 'The Singapore Consensus on Global AI Safety Research Priorities', 'authors': "Yoshua Bengio, Tegan Maharaj, Luke Ong, Stuart Russell, Dawn Song, Max Tegmark, Lan Xue, Ya-Qin Zhang, Stephen Casper, Wan Sie Lee, Sören Mindermann, Vanessa Wilfred, Vidhisha Balachandran, Fazl Barez, Michael Belinsky, Imane Bello, Malo Bourgon, Mark Brakel, Siméon Campos, Duncan Cass-Beggs, Jiahao Chen, Rumman Chowdhury, Kuan Chua Seah, Jeff Clune, Juntao Dai, Agnes Delaborde, Nouha Dziri, Francisco Eiras, Joshua Engels, Jinyu Fan, Adam Gleave, Noah Goodman, Fynn Heide, Dan Hendrycks, Cyrus Hodes, Bryan Low Kian Hsiang, Minlie Huang, Sami Jawhar, Wang Jingyu, Adam Tauman Kalai, Meindert Kamphuis, Mohan Kankanhalli, Subhash Kantamneni, Mathias Bonde Kirk, Thomas Kwa, Jeffrey Ladish, Kwok-Yan Lam, Wan Lee Sie, Taewhi Lee, Xiaojian Li, Jiajun Liu, Chaochao Lu, Yifan Mai, Richard Mallah, Julian Michael, Nick Moës, Simon Möller, Kihyuk Nam, Kwan Yee Ng, Mark Nitzberg, Besmira Nushi, Seán O hÉigeartaigh, Alejandro Ortega, Pierre Peigné, James Petrie, Benjamin Prud'Homme, Reihaneh Rabbany, Nayat Sanchez-Pi, Sarah Schwettmann, Buck Shlegeris, Saad Siddiqui, Aradhana Sinha, Martín Soto, Cheston Tan, Dong Ting, Robert Trager, Brian Tse, Anthony Tung K. H., Vanessa Wilfred, John Willes, Denise Wong, Wei Xu, Rongwu Xu, Yi Zeng, HongJiang Zhang, Djordje Žikelić", 'link': 'https://arxiv.org/abs/2506.20702', 'abstract': 'Rapidly improving AI capabilities and autonomy hold significant promise of transformation, but are also driving vigorous debate on how to ensure that AI is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem is therefore essential -- it helps people embrace AI with confidence and gives maximal space for innovation while avoiding backlash.\nThe "2025 Singapore Conference on AI (SCAI): International Scientific Exchange on AI Safety" aimed to support research in this space by bringing together AI scientists across geographies to identify and synthesise research priorities in AI safety. This resulting report builds on the International AI Safety Report chaired by Yoshua Bengio and backed by 33 governments. By adopting a defence-in-depth model, this report organises AI safety research domains into three types: challenges with creating trustworthy AI systems (Development), challenges with evaluating their risks (Assessment), and challenges with monitoring and intervening after deployment (Control).', 'abstract_zh': 'Rapidly提升的AI能力和自主性富含 transformative 的潜力，但也引发了关于如何确保AI安全（即可信、可靠和安全）的激烈 Debate。因此，构建一个可信赖的生态系统至关重要——它有助于人们充满信心地接受AI，最大化创新空间，同时避免抵触情绪。“2025年新加坡AI大会（SCAI）：AI安全国际科学交流”旨在通过汇聚来自不同地区的AI科学家，识别和综合AI安全的研究优先领域，来支持相关研究。这份报告基于Yoshua Bengio主席和33个政府支持的国际AI安全报告，采用多层次防御模式，将AI安全研究领域分为三个类型：创建可信AI系统所面临的挑战（开发）、评估其风险所面临的挑战（评估）以及部署后监控和干预所面临的挑战（控制）。', 'title_zh': '新加坡全球AI安全研究优先事项共识'}
{'arxiv_id': 'arXiv:2506.21552', 'title': 'Whole-Body Conditioned Egocentric Video Prediction', 'authors': 'Yutong Bai, Danny Tran, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik', 'link': 'https://arxiv.org/abs/2506.21552', 'abstract': "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human.", 'abstract_zh': '基于人体动作预测以自我为中心视频（PEVA）：给定过去视频和由相对3D肢体姿态表示的动作', 'title_zh': '全身条件下的 propioceptive 视频预测'}
{'arxiv_id': 'arXiv:2506.21550', 'title': 'mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale', 'authors': 'Xiaona Zhou, Constantin Brif, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2506.21550', 'abstract': 'Multivariate time series anomaly detection (MTS-AD) is critical in domains like healthcare, cybersecurity, and industrial monitoring, yet remains challenging due to complex inter-variable dependencies, temporal dynamics, and sparse anomaly labels. We introduce mTSBench, the largest benchmark to date for MTS-AD and unsupervised model selection, spanning 344 labeled time series across 19 datasets and 12 diverse application domains. mTSBench evaluates 24 anomaly detection methods, including large language model (LLM)-based detectors for multivariate time series, and systematically benchmarks unsupervised model selection techniques under standardized conditions. Consistent with prior findings, our results confirm that no single detector excels across datasets, underscoring the importance of model selection. However, even state-of-the-art selection methods remain far from optimal, revealing critical gaps. mTSBench provides a unified evaluation suite to enable rigorous, reproducible comparisons and catalyze future advances in adaptive anomaly detection and robust model selection.', 'abstract_zh': '多变量时间序列异常检测（MTS-AD）在医疗保健、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签，这一领域仍然具有挑战性。我们介绍了迄今为止最大的MTS-AD和无监督模型选择基准mTSBench，涵盖了19个数据集、12个不同的应用领域中的344个标注时间序列。mTSBench评估了24种异常检测方法，包括用于多变量时间序列的基于大型语言模型的检测器，并在标准化条件下系统性地基准测试无监督模型选择技术。与先前的研究相符，我们的结果显示没有单一检测器能在所有数据集中表现优异，强调了模型选择的重要性。然而，即使是最先进的选择方法也远未达到最优，揭示了关键的差距。mTSBench提供了一个统一的评估套件，以促进严格、可重复的比较，并推动适应性异常检测和稳健模型选择的未来进步。', 'title_zh': 'mTSBench：大规模多变量时间序列异常检测与模型选择基准测试'}
{'arxiv_id': 'arXiv:2506.21546', 'title': 'HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation', 'authors': 'Xinzhuo Li, Adheesh Juvekar, Xingyou Liu, Muntasir Wahed, Kiet A. Nguyen, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2506.21546', 'abstract': 'Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.', 'abstract_zh': 'Recent Progress in Vision-Language Segmentation and Its Challenges in Grounded Visual Understanding: Introducing HalluSegBench for Evaluating Hallucinations through Counterfactual Visual Reasoning', 'title_zh': 'HalluSegBench: 反事实视觉推理在分割幻觉评估中的应用'}
{'arxiv_id': 'arXiv:2506.21539', 'title': 'WorldVLA: Towards Autoregressive Action World Model', 'authors': 'Jun Cen, Chaohui Yu, Hangjie Yuan, Yuming Jiang, Siteng Huang, Jiayan Guo, Xin Li, Yibing Song, Hao Luo, Fan Wang, Deli Zhao, Hao Chen', 'link': 'https://arxiv.org/abs/2506.21539', 'abstract': "We present WorldVLA, an autoregressive action world model that unifies action and image understanding and generation. Our WorldVLA intergrates Vision-Language-Action (VLA) model and world model in one single framework. The world model predicts future images by leveraging both action and image understanding, with the purpose of learning the underlying physics of the environment to improve action generation. Meanwhile, the action model generates the subsequent actions based on image observations, aiding in visual understanding and in turn helps visual generation of the world model. We demonstrate that WorldVLA outperforms standalone action and world models, highlighting the mutual enhancement between the world model and the action model. In addition, we find that the performance of the action model deteriorates when generating sequences of actions in an autoregressive manner. This phenomenon can be attributed to the model's limited generalization capability for action prediction, leading to the propagation of errors from earlier actions to subsequent ones. To address this issue, we propose an attention mask strategy that selectively masks prior actions during the generation of the current action, which shows significant performance improvement in the action chunk generation task.", 'abstract_zh': 'WorldVLA：统一动作与图像理解与生成的自回归世界模型', 'title_zh': 'WorldVLA: 向 toward 自回归行动世界模型模型逼近'}
{'arxiv_id': 'arXiv:2506.21532', 'title': '"What\'s Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets', 'authors': 'Akshay Paruchuri, Maryam Aziz, Rohit Vartak, Ayman Ali, Best Uchehara, Xin Liu, Ishan Chatterjee, Monica Agrawal', 'link': 'https://arxiv.org/abs/2506.21532', 'abstract': 'People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. Code and artifacts to retrieve our analyses and combine them into a curated dataset can be found here: this https URL', 'abstract_zh': '人们越来越通过交互聊天机器人从大型语言模型获取医疗健康信息，但这些对话的本质及其固有风险尚待深入探索。本文通过过滤大规模对话AI数据集，构建了包含11,000个真实世界对话的HealthChat-11K数据集，这些对话由25,000条用户消息组成。我们使用HealthChat-11K和基于临床专家定义的分类体系，系统研究用户在寻求医疗健康信息时与大型语言模型的互动，涵盖21个不同的医学专科。我们的分析揭示了用户寻求健康信息的方式和原因，包括常见的交互模式、不完整背景信息的实例、情感行为，以及可能引导奉承的交互（如引导性问题），强调了在作为对话AI部署的大型语言模型中改进医疗健康支持能力的必要性。获取我们分析的代码和构建精编数据集的相关文件，请访问：this https URL', 'title_zh': '“医生，有什么事吗？”：分析用户在大规模对话AI数据集中寻求健康信息的方式'}
{'arxiv_id': 'arXiv:2506.21521', 'title': 'Potemkin Understanding in Large Language Models', 'authors': 'Marina Mancoridis, Bec Weeks, Keyon Vafa, Sendhil Mullainathan', 'link': 'https://arxiv.org/abs/2506.21521', 'abstract': "Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations.", 'abstract_zh': '大型语言模型（LLMs）通常通过基准数据集进行评估。但根据LLM对特定问题集的回答来推断其能力的合理性是什么？本文首先引入了一个正式框架来解答这一问题。关键在于，用于测试LLM的基准测试（如AP考试）同样也用于测试人类。然而，这引发了这样一个推论：只有当LLM对概念的理解方式类似于人类误解的方式时，这些基准测试才是有效的。否则，基准测试的成功仅展示了“纸牌屋理解”：一种由不可调和的答案所驱动的表象理解。我们提出了两种量化“纸牌屋理解”的方法：一种是使用专门设计的基准在三个领域中进行，另一种是使用通用程序，提供其普遍性的下限。我们发现“纸牌屋理解”在各种模型、任务和领域中普遍存在。我们还发现，这些失败不仅仅是理解错误，还反映了概念表示中的深层次内在不一致性。', 'title_zh': 'Potemkin理解在大规模语言模型中'}
{'arxiv_id': 'arXiv:2506.21508', 'title': 'skLEP: A Slovak General Language Understanding Benchmark', 'authors': 'Marek Šuppa, Andrej Ridzik, Daniel Hládek, Tomáš Javůrek, Viktória Ondrejová, Kristína Sásiková, Martin Tamajka, Marián Šimko', 'link': 'https://arxiv.org/abs/2506.21508', 'abstract': 'In this work, we introduce skLEP, the first comprehensive benchmark specifically designed for evaluating Slovak natural language understanding (NLU) models. We have compiled skLEP to encompass nine diverse tasks that span token-level, sentence-pair, and document-level challenges, thereby offering a thorough assessment of model capabilities. To create this benchmark, we curated new, original datasets tailored for Slovak and meticulously translated established English NLU resources. Within this paper, we also present the first systematic and extensive evaluation of a wide array of Slovak-specific, multilingual, and English pre-trained language models using the skLEP tasks. Finally, we also release the complete benchmark data, an open-source toolkit facilitating both fine-tuning and evaluation of models, and a public leaderboard at this https URL in the hopes of fostering reproducibility and drive future research in Slovak NLU.', 'abstract_zh': '本工作中，我们引入了skLEP，这是首个专门用于评估斯洛伐克自然语言理解（NLU）模型的综合基准。我们编制了涵盖九个不同任务的skLEP基准，这些任务涵盖了从token级到句子对级再到文档级的各种挑战，从而为模型能力提供了全面评估。为了创建这一基准，我们精心整理了新的原始数据集，专门针对斯洛伐克语，并详细翻译了现有的英语NLU资源。本文中，我们还首次系统且全面地评估了多种斯洛伐克特定的、多语言的和英语预训练语言模型在skLEP任务上的表现。此外，我们还发布了完整的基准数据、一个开源工具包，以方便模型的微调和评估，并在https://this.url提供了一个公共排行榜，旨在促进斯洛伐克NLU领域的可再现性和未来研究。', 'title_zh': '斯克LEP: 斯洛伐克通用语言理解基准'}
{'arxiv_id': 'arXiv:2506.21502', 'title': 'Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems', 'authors': "Francesco Vitale, Nicola Dall'Ora, Sebastiano Gaiardelli, Enrico Fraccaroli, Nicola Mazzocca, Franco Fummi", 'link': 'https://arxiv.org/abs/2506.21502', 'abstract': 'Fault diagnosis in Cyber-Physical Systems (CPSs) is essential for ensuring system dependability and operational efficiency by accurately detecting anomalies and identifying their root causes. However, the manual modeling of faulty behaviors often demands extensive domain expertise and produces models that are complex, error-prone, and difficult to interpret. To address this challenge, we present a novel unsupervised fault diagnosis methodology that integrates collective anomaly detection in multivariate time series, process mining, and stochastic simulation. Initially, collective anomalies are detected from low-level sensor data using multivariate time-series analysis. These anomalies are then transformed into structured event logs, enabling the discovery of interpretable process models through process mining. By incorporating timing distributions into the extracted Petri nets, the approach supports stochastic simulation of faulty behaviors, thereby enhancing root cause analysis and behavioral understanding. The methodology is validated using the Robotic Arm Dataset (RoAD), a widely recognized benchmark in smart manufacturing. Experimental results demonstrate its effectiveness in modeling, simulating, and classifying faulty behaviors in CPSs. This enables the creation of comprehensive fault dictionaries that support predictive maintenance and the development of digital twins for industrial environments.', 'abstract_zh': 'Cyber-物理系统（CPSs）中的故障诊断对于确保系统的可靠性和操作效率至关重要，通过精确检测异常并识别其根本原因。然而，手动建模故障行为往往需要大量的领域专业知识，并会产生复杂、易出错且难以解释的模型。为了解决这一挑战，我们提出了一种新颖的无监督故障诊断方法，该方法结合了多变量时间序列集体异常检测、过程挖掘和随机仿真。首先，使用多变量时间序列分析从低级传感器数据中检测集体异常。随后，将这些异常转换为结构化的事件日志，通过过程挖掘发现可解释的过程模型。通过将时间分布融入提取的Petri网中，该方法支持故障行为的随机仿真，从而增强根本原因分析和行为理解。该方法使用广泛认可的智能制造基准数据集Robotic Arm Dataset (RoAD) 进行验证。实验结果表明，该方法在模型构建、仿真和故障行为分类方面具有有效性，从而支持预测性维护并为工业环境开发数字孪生体。', 'title_zh': '基于过程挖掘的建模与仿真以增强网络物理系统故障诊断'}
{'arxiv_id': 'arXiv:2506.21484', 'title': 'TITAN: Query-Token based Domain Adaptive Adversarial Learning', 'authors': 'Tajamul Ashraf, Janibul Bashir', 'link': 'https://arxiv.org/abs/2506.21484', 'abstract': 'We focus on the source-free domain adaptive object detection (SF-DAOD) problem when source data is unavailable during adaptation and the model must adapt to an unlabeled target domain. The majority of approaches for the problem employ a self-supervised approach using a student-teacher (ST) framework where pseudo-labels are generated via a source-pretrained model for further fine-tuning. We observe that the performance of a student model often degrades drastically, due to the collapse of the teacher model, primarily caused by high noise in pseudo-labels, resulting from domain bias, discrepancies, and a significant domain shift across domains. To obtain reliable pseudo-labels, we propose a Target-based Iterative Query-Token Adversarial Network (TITAN), which separates the target images into two subsets: those similar to the source (easy) and those dissimilar (hard). We propose a strategy to estimate variance to partition the target domain. This approach leverages the insight that higher detection variances correspond to higher recall and greater similarity to the source domain. Also, we incorporate query-token-based adversarial modules into a student-teacher baseline framework to reduce the domain gaps between two feature representations. Experiments conducted on four natural imaging datasets and two challenging medical datasets have substantiated the superior performance of TITAN compared to existing state-of-the-art (SOTA) methodologies. We report an mAP improvement of +22.7, +22.2, +21.1, and +3.7 percent over the current SOTA on C2F, C2B, S2C, and K2C benchmarks, respectively.', 'abstract_zh': '基于目标的迭代查询-令牌对抗网络在源数据不可用时的无源领域自适应对象检测', 'title_zh': 'TITAN: 基于查询词/token的领域自适应对抗学习'}
{'arxiv_id': 'arXiv:2506.21478', 'title': 'SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture', 'authors': 'Kehan Sui, Jinxu Xiang, Fang Jin', 'link': 'https://arxiv.org/abs/2506.21478', 'abstract': 'Singing voice synthesis (SVS) aims to generate expressive and high-quality vocals from musical scores, requiring precise modeling of pitch, duration, and articulation. While diffusion-based models have achieved remarkable success in image and video generation, their application to SVS remains challenging due to the complex acoustic and musical characteristics of singing, often resulting in artifacts that degrade naturalness. In this work, we propose SmoothSinger, a conditional diffusion model designed to synthesize high quality and natural singing voices. Unlike prior methods that depend on vocoders as a final stage and often introduce distortion, SmoothSinger refines low-quality synthesized audio directly in a unified framework, mitigating the degradation associated with two-stage pipelines. The model adopts a reference-guided dual-branch architecture, using low-quality audio from any baseline system as a reference to guide the denoising process, enabling more expressive and context-aware synthesis. Furthermore, it enhances the conventional U-Net with a parallel low-frequency upsampling path, allowing the model to better capture pitch contours and long term spectral dependencies. To improve alignment during training, we replace reference audio with degraded ground truth audio, addressing temporal mismatch between reference and target signals. Experiments on the Opencpop dataset, a large-scale Chinese singing corpus, demonstrate that SmoothSinger achieves state-of-the-art results in both objective and subjective evaluations. Extensive ablation studies confirm its effectiveness in reducing artifacts and improving the naturalness of synthesized voices.', 'abstract_zh': '歌唱语音合成（Singing Voice Synthesis, SVS）旨在从音乐谱中生成具有表现力和高质量的语音，需要精确建模音高、时长和发音。尽管基于扩散的模型在图像和视频生成中取得了令人瞩目的成果，但在SVS中的应用仍具有挑战性，因为歌唱具有复杂的声学和音乐特性，往往会引入影响自然性的伪影。在本文中，我们提出SmoothSinger，这是一种条件扩散模型，旨在合成高质量和自然的歌唱语音。与依赖嗓音编码器作为最终阶段的先前方法不同，SmoothSinger在统一框架中直接细化低质量合成音频，从而减轻了两阶段管道相关的影响。该模型采用参考指导的双分支架构，使用任何基准系统生成的低质量音频作为参考，指导去噪过程，使得合成更具表现力和上下文感知。此外，它通过并行低频上采样路径增强常规的U-Net，使模型能够更好地捕捉音高轮廓和长时频谱依赖关系。为了提高训练期间的对齐，我们将参考音频替换为降级的真实目标音频，解决了参考信号与目标信号之间的时序不匹配问题。在大规模中文歌唱语料库Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均达到最先进的成果。广泛的消融研究进一步证实了其有效减少伪影和提高合成语音自然性的能力。', 'title_zh': 'SmoothSinger：带有多分辨率架构的条件扩散模型歌声合成'}
{'arxiv_id': 'arXiv:2506.21465', 'title': 'Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage', 'authors': "Gavin Lee Goodship, Luis Miralles-Pechuan, Stephen O'Sullivan", 'link': 'https://arxiv.org/abs/2506.21465', 'abstract': 'Extended Stability Runge-Kutta (ESRK) methods are crucial for solving large-scale computational problems in science and engineering, including weather forecasting, aerodynamic analysis, and complex biological modelling. However, balancing accuracy, stability, and computational efficiency remains challenging, particularly for high-order, low-storage schemes. This study introduces a hybrid Genetic Algorithm (GA) and Reinforcement Learning (RL) approach for automated heuristic discovery, optimising low-storage ESRK methods. Unlike traditional approaches that rely on manually designed heuristics or exhaustive numerical searches, our method leverages GA-driven mutations for search-space exploration and an RL-inspired state transition mechanism to refine heuristic selection dynamically. This enables systematic parameter reduction, preserving fourth-order accuracy while significantly improving computational this http URL proposed GA-RL heuristic optimisation framework is validated through rigorous testing on benchmark problems, including the 1D and 2D Brusselator systems and the steady-state Navier-Stokes equations. The best-performing heuristic achieves a 25\\% reduction in IPOPT runtime compared to traditional ESRK optimisation processes while maintaining numerical stability and accuracy. These findings demonstrate the potential of adaptive heuristic discovery to improve resource efficiency in high-fidelity simulations and broaden the applicability of low-storage Runge-Kutta methods in real-world computational fluid dynamics, physics simulations, and other demanding fields. This work establishes a new paradigm in heuristic optimisation for numerical methods, opening pathways for further exploration using Deep RL and AutoML-based heuristic search', 'abstract_zh': '基于遗传算法和强化学习的低存储ESRK方法自适应启发式优化', 'title_zh': '优化四阶龙格-库塔方法：一种高效的低存储动态启发式方法'}
{'arxiv_id': 'arXiv:2506.21443', 'title': 'Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection', 'authors': 'Ali Şenol, Garima Agrawal, Huan Liu', 'link': 'https://arxiv.org/abs/2506.21443', 'abstract': 'Detecting deceptive conversations on dynamic platforms is increasingly difficult due to evolving language patterns and Concept Drift (CD)\\-i.e., semantic or topical shifts that alter the context or intent of interactions over time. These shifts can obscure malicious intent or mimic normal dialogue, making accurate classification challenging. While Large Language Models (LLMs) show strong performance in natural language tasks, they often struggle with contextual ambiguity and hallucinations in risk\\-sensitive scenarios. To address these challenges, we present a Domain Knowledge (DK)\\-Enhanced LLM framework that integrates pretrained LLMs with structured, task\\-specific insights to perform fraud and concept drift detection. The proposed architecture consists of three main components: (1) a DK\\-LLM module to detect fake or deceptive conversations; (2) a drift detection unit (OCDD) to determine whether a semantic shift has occurred; and (3) a second DK\\-LLM module to classify the drift as either benign or fraudulent. We first validate the value of domain knowledge using a fake review dataset and then apply our full framework to SEConvo, a multiturn dialogue dataset that includes various types of fraud and spam attacks. Results show that our system detects fake conversations with high accuracy and effectively classifies the nature of drift. Guided by structured prompts, the LLaMA\\-based implementation achieves 98\\% classification accuracy. Comparative studies against zero\\-shot baselines demonstrate that incorporating domain knowledge and drift awareness significantly improves performance, interpretability, and robustness in high\\-stakes NLP applications.', 'abstract_zh': '动态平台上检测欺骗性对话日趋困难，原因在于语言模式不断演变和概念漂移（CD），即随时间改变互动语境或意图的语义或主题转移。这些转移可能会掩盖恶意意图或模仿正常对话，使得准确分类变得极具挑战性。尽管大型语言模型（LLMs）在自然语言任务中表现出色，但在风险管理敏感场景下往往难以应对上下文模糊和幻觉问题。为应对这些挑战，我们提出了一种领域知识（DK）增强的LLM框架，该框架结合了预训练的LLMs与结构化的任务特定洞察，以实现欺诈和概念漂移检测。所提出的架构包括三个主要组件：（1）一个DK-LLM模块，用于检测虚假或欺骗性对话；（2）一个漂移检测单元（OCDD），用于确定是否发生了语义转移；（3）一个第二个DK-LLM模块，用于将漂移分类为良性或欺诈。我们首先使用虚假评论数据集验证了领域知识的价值，然后将完整框架应用于包含各种欺诈和垃圾信息攻击的SEConvo多轮对话数据集。结果显示，我们的系统能够以高精度检测虚假对话，并有效分类漂移的性质。基于结构化提示的LLaMA实现达到了98%的分类精度。与零样本基线的对比研究表明，结合领域知识和漂移意识显著提升了高风险自然语言处理应用场景下的性能、可解释性和鲁棒性。', 'title_zh': '增强领域知识的LLM在欺诈和概念漂移检测中的应用'}
{'arxiv_id': 'arXiv:2506.21408', 'title': 'Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference', 'authors': 'Colin Samplawski, Adam D. Cobb, Manoj Acharya, Ramneet Kaur, Susmit Jha', 'link': 'https://arxiv.org/abs/2506.21408', 'abstract': 'Despite their widespread use, large language models (LLMs) are known to hallucinate incorrect information and be poorly calibrated. This makes the uncertainty quantification of these models of critical importance, especially in high-stakes domains, such as autonomy and healthcare. Prior work has made Bayesian deep learning-based approaches to this problem more tractable by performing inference over the low-rank adaptation (LoRA) parameters of a fine-tuned model. While effective, these approaches struggle to scale to larger LLMs due to requiring further additional parameters compared to LoRA. In this work we present $\\textbf{Scala}$ble $\\textbf{B}$ayesian $\\textbf{L}$ow-Rank Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By repurposing the LoRA parameters as projection matrices, we are able to map samples from this subspace into the full weight space of the LLM. This allows us to learn all the parameters of our approach using stochastic variational inference. Despite the low dimensionality of our subspace, we are able to achieve competitive performance with state-of-the-art approaches while only requiring ${\\sim}1000$ additional parameters. Furthermore, it allows us to scale up to the largest Bayesian LLM to date, with four times as a many base parameters as prior work.', 'abstract_zh': '可扩展的基于随机变分子空间推断的低秩贝叶斯适应（ScalaBL）', 'title_zh': '大规模语言模型通过随机变分子空间推断的可扩展贝叶斯低秩适应'}
{'arxiv_id': 'arXiv:2506.21384', 'title': 'Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation', 'authors': 'Guanting Dong, Xiaoxi Li, Yuyao Zhang, Mengjie Deng', 'link': 'https://arxiv.org/abs/2506.21384', 'abstract': 'Real-world live retrieval-augmented generation (RAG) systems face significant challenges when processing user queries that are often noisy, ambiguous, and contain multiple intents. While RAG enhances large language models (LLMs) with external knowledge, current systems typically struggle with such complex inputs, as they are often trained or evaluated on cleaner data. This paper introduces Omni-RAG, a novel framework designed to improve the robustness and effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs LLM-assisted query understanding to preprocess user inputs through three key modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs with tailored prompts to denoise queries (e.g., correcting spelling errors) and decompose multi-intent queries into structured sub-queries; (2) Intent-Aware Knowledge Retrieval, which performs retrieval for each sub-query from a corpus (i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking and Generation, where a reranker (i.e., BGE) refines document selection before a final response is generated by an LLM (i.e., Falcon-10B) using a chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG capabilities and the demands of real-world applications, such as those highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex and noisy queries.', 'abstract_zh': '面向现实场景的查询增强生成（RAG）系统在处理 noisy、模糊且含有多个意图的用户查询时面临重大挑战。Omni-RAG：一种提高RAG系统在实时开放域设置中稳健性和有效性的新型框架', 'title_zh': '利用大语言模型辅助的查询理解实现实时检索增强生成'}
{'arxiv_id': 'arXiv:2506.21382', 'title': 'Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection', 'authors': 'Zhi Zheng, Bochuan Zhou, Yuping Song', 'link': 'https://arxiv.org/abs/2506.21382', 'abstract': 'Cryptocurrency transaction fraud detection faces the dual challenges of increasingly complex transaction patterns and severe class imbalance. Traditional methods rely on manual feature engineering and struggle to capture temporal and structural dependencies in transaction networks. This paper proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that enhances detection performance through three modules: (1) designing an advanced temporal embedding module that fuses multi-scale time difference features with periodic position encoding; (2) constructing a temporal-aware triple attention mechanism that jointly optimizes structural, temporal, and global context attention; (3) employing weighted BCE loss to address class imbalance. Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT achieves an AUC of 0.9130, representing a 9.2% improvement over the best traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This method not only validates the enhancement effect of temporal awareness and triple attention mechanisms on graph neural networks, but also provides financial institutions with more reliable fraud detection tools, with its design principles generalizable to other temporal graph anomaly detection tasks.', 'abstract_zh': '加密货币交易欺诈检测面临着交易模式日益复杂和严重类别不平衡的双重挑战。传统的检测方法依赖于手动特征工程，并且难以捕捉交易网络中的时空依赖性。本文提出了一种增强时序aware图注意力网络（ATGAT），通过三个模块提升检测性能：（1）设计先进的时序嵌入模块，融合多尺度时间差特征与时序位置编码；（2）构建时序aware三重注意力机制，联合优化结构、时序和全局上下文注意力；（3）采用加权BCE损失以应对类别不平衡问题。实验证明，ATGAT在Elliptic++加密货币数据集上的AUC值为0.9130，分别比最佳传统方法XGBoost提升9.2%，比GCN提升12.0%，比标准GAT提升10.0%。该方法不仅验证了时序意识和三重注意力机制对图神经网络性能的提升效果，还为金融机构提供了更可靠的欺诈检测工具，并且其设计原则可推广到其他时序图异常检测任务中。', 'title_zh': '面向时间感知的图注意力网络加密货币交易欺诈检测'}
{'arxiv_id': 'arXiv:2506.21374', 'title': 'Pay Attention to Small Weights', 'authors': 'Chao Zhou, Tom Jacobs, Advait Gadhikar, Rebekka Burkholz', 'link': 'https://arxiv.org/abs/2506.21374', 'abstract': 'Finetuning large pretrained neural networks is known to be resource-intensive, both in terms of memory and computational cost. To mitigate this, a common approach is to restrict training to a subset of the model parameters. By analyzing the relationship between gradients and weights during finetuning, we observe a notable pattern: large gradients are often associated with small-magnitude weights. This correlation is more pronounced in finetuning settings than in training from scratch. Motivated by this observation, we propose NANOADAM, which dynamically updates only the small-magnitude weights during finetuning and offers several practical advantages: first, this criterion is gradient-free -- the parameter subset can be determined without gradient computation; second, it preserves large-magnitude weights, which are likely to encode critical features learned during pretraining, thereby reducing the risk of catastrophic forgetting; thirdly, it permits the use of larger learning rates and consistently leads to better generalization performance in experiments. We demonstrate this for both NLP and vision tasks.', 'abstract_zh': '微调大规模预训练神经网络通常资源密集，both in terms of memory and computational cost. 为缓解这一问题，常用的方法是限制训练参数子集。通过分析微调过程中梯度与权重的关系，我们发现一个显著模式：大梯度通常与小幅度权重相关。这种相关性在微调设置中比从头开始训练更为明显。基于这一观察，我们提出NANOADAM，在微调过程中仅动态更新小幅度权重，并提供了几个实际优势：首先，该标准无需梯度计算即可确定参数子集；其次，它保留了大幅度权重，这些权重很可能包含了预训练中学到的关键特征，从而降低灾难性遗忘的风险；第三，它允许使用更大的学习率，并在实验中始终表现出更好的泛化性能。我们分别在NLP和视觉任务中展示了这一点。', 'title_zh': '关注小权重'}
{'arxiv_id': 'arXiv:2506.21368', 'title': 'Real-time and personalized product recommendations for large e-commerce platforms', 'authors': 'Matteo Tolloso, Davide Bacciu, Shahab Mokarizadeh, Marco Varesi', 'link': 'https://arxiv.org/abs/2506.21368', 'abstract': 'We present a methodology to provide real-time and personalized product recommendations for large e-commerce platforms, specifically focusing on fashion retail. Our approach aims to achieve accurate and scalable recommendations with minimal response times, ensuring user satisfaction, leveraging Graph Neural Networks and parsimonious learning methodologies. Extensive experimentation with datasets from one of the largest e-commerce platforms demonstrates the effectiveness of our approach in forecasting purchase sequences and handling multi-interaction scenarios, achieving efficient personalized recommendations under real-world constraints.', 'abstract_zh': '我们提出了一种方法学，用于为大型电商平台提供实时和个性化的商品推荐，特别是针对时尚零售领域。我们的方法旨在在最小响应时间内实现准确且可扩展的推荐，确保用户满意度，并利用图神经网络和简约学习方法。通过对某大型电商平台数据集进行广泛实验，表明该方法在预测购买序列和处理多交互场景方面具有有效性，能够在现实世界约束下实现高效的个性化推荐。', 'title_zh': '面向大型电商平台的实时个性化产品推荐'}
{'arxiv_id': 'arXiv:2506.21367', 'title': 'rQdia: Regularizing Q-Value Distributions With Image Augmentation', 'authors': 'Sam Lerman, Jing Bi', 'link': 'https://arxiv.org/abs/2506.21367', 'abstract': 'rQdia regularizes Q-value distributions with augmented images in pixel-based deep reinforcement learning. With a simple auxiliary loss, that equalizes these distributions via MSE, rQdia boosts DrQ and SAC on 9/12 and 10/12 tasks respectively in the MuJoCo Continuous Control Suite from pixels, and Data-Efficient Rainbow on 18/26 Atari Arcade environments. Gains are measured in both sample efficiency and longer-term training. Moreover, the addition of rQdia finally propels model-free continuous control from pixels over the state encoding baseline.', 'abstract_zh': '基于像素的深度强化学习中，rQdia通过增强图像正则化Q值分布。通过对这些分布进行MSE均化，rQdia在MuJoCo连续控制套件的9/12和10/12任务中分别提升了DrQ和SAC的表现，并在26个Atari街机环境中18/26的任务中提升了Data-Efficient Rainbow的表现。收益在样本效率和长期训练方面均有体现。此外，rQdia的加入最终使得无模型连续控制从像素中超过状态编码 baseline。', 'title_zh': 'rQdia: 用图像增强正则化Q值分布'}
{'arxiv_id': 'arXiv:2506.21364', 'title': 'CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection', 'authors': 'Zhixin Cheng, Jiacheng Deng, Xinjun Li, Xiaotian Yin, Bohao Liao, Baoqun Yin, Wenfei Yang, Tianzhu Zhang', 'link': 'https://arxiv.org/abs/2506.21364', 'abstract': 'Detection-free methods typically follow a coarse-to-fine pipeline, extracting image and point cloud features for patch-level matching and refining dense pixel-to-point correspondences. However, differences in feature channel attention between images and point clouds may lead to degraded matching results, ultimately impairing registration accuracy. Furthermore, similar structures in the scene could lead to redundant correspondences in cross-modal matching. To address these issues, we propose Channel Adaptive Adjustment Module (CAA) and Global Optimal Selection Module (GOS). CAA enhances intra-modal features and suppresses cross-modal sensitivity, while GOS replaces local selection with global optimization. Experiments on RGB-D Scenes V2 and 7-Scenes demonstrate the superiority of our method, achieving state-of-the-art performance in image-to-point cloud registration.', 'abstract_zh': 'Detection-free方法通常采用粗到细的流程，提取图像和点云特征以进行像素块级别的匹配并细化密集的像素到点对应关系。然而，图像和点云特征通道注意力的差异可能导致匹配结果退化，最终影响注册精度。此外，场景中的相似结构可能会导致跨模态匹配中的冗余对应关系。为了解决这些问题，我们提出了通道自适应调整模块(CAA)和全局最优选择模块(GOS)。CAA增强内模特征并抑制跨模态敏感性，而GOS用全局优化替代局部选择。在RGB-D Scenes V2和7-Scenes数据集上的实验表明，我们的方法在图像到点云注册方面具有优越性，并达到了最先进的性能。', 'title_zh': 'CA-I2P：具有全局最优选择的通道自适应注册网络'}
{'arxiv_id': 'arXiv:2506.21333', 'title': 'A Systematic Review of Human-AI Co-Creativity', 'authors': 'Saloni Singh, Koen Hndriks, Drik Heylen, Kim Baraka', 'link': 'https://arxiv.org/abs/2506.21333', 'abstract': "The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.", 'abstract_zh': '协同创作社区在开发更复杂和定制化的支持和增强人类创造力的系统方面取得了显著进展。 previous work 的设计考量可以为未来系统提供宝贵且高效的基石。为支持这一努力，我们系统地回顾了62篇关于协同创作系统的论文。这些论文涵盖了从视觉艺术、设计到写作等多种应用领域，在这些应用中，AI 不仅作为工具，还作为创作过程中积极参与的合作方。通过这次回顾，我们确定了几个关键的设计维度：创作过程的阶段、创作任务、系统的主动性行为、用户控制、系统体现以及AI模型类型。研究发现表明，提供高用户控制的系统能够带来更高的满意度、信任感和更强的对创作成果的所有感。此外，当适应性强且上下文敏感时，主动系统可以增强合作。我们还提取了24条设计考量，强调了鼓励用户外化想法以及增加系统的社交存在感和透明度以培养信任的价值。尽管取得了一定进展，但仍存在一些重要缺口，例如早期创意阶段（如问题澄清）的支持有限，以及用户适应AI系统的问题。', 'title_zh': '人类与人工智能协同创造的系统性回顾'}
{'arxiv_id': 'arXiv:2506.21330', 'title': 'Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models', 'authors': 'Haoyang Wu, Tsun-Hsuan Wang, Mathias Lechner, Ramin Hasani, Jennifer A. Eckhoff, Paul Pak, Ozanan R. Meireles, Guy Rosman, Yutong Ban, Daniela Rus', 'link': 'https://arxiv.org/abs/2506.21330', 'abstract': 'Surgical workflow analysis is essential in robot-assisted surgeries, yet the long duration of such procedures poses significant challenges for comprehensive video analysis. Recent approaches have predominantly relied on transformer models; however, their quadratic attention mechanism restricts efficient processing of lengthy surgical videos. In this paper, we propose a novel hierarchical input-dependent state space model that leverages the linear scaling property of state space models to enable decision making on full-length videos while capturing both local and global dynamics. Our framework incorporates a temporally consistent visual feature extractor, which appends a state space model head to a visual feature extractor to propagate temporal information. The proposed model consists of two key modules: a local-aggregation state space model block that effectively captures intricate local dynamics, and a global-relation state space model block that models temporal dependencies across the entire video. The model is trained using a hybrid discrete-continuous supervision strategy, where both signals of discrete phase labels and continuous phase progresses are propagated through the network. Experiments have shown that our method outperforms the current state-of-the-art methods by a large margin (+2.8% on Cholec80, +4.3% on MICCAI2016, and +12.9% on Heichole datasets). Code will be publicly available after paper acceptance.', 'abstract_zh': '机器人辅助手术中的外科工作流程分析至关重要，但由于此类手术过程时间较长，给全面视频分析带来了显著挑战。近期方法主要依赖于变压器模型；然而，其二次注意力机制限制了对长手术视频的高效处理。本文提出了一种新颖的层次化输入依赖状态空间模型，利用状态空间模型的线性可扩展性，能够在保留局部和全局动态特征的同时，对全长视频进行决策。该框架结合了时序一致的视觉特征提取器，通过在视觉特征提取器后附加状态空间模型头部，从而传递时序信息。所提出的模型包括两个关键模块：一个局部聚合状态空间模型块，有效捕捉复杂的局部动态，以及一个全局关系状态空间模型块，建模整个视频中的时序依赖关系。该模型通过混合离散-连续监督策略进行训练，其中离散相位标签信号和连续相位进展信号均在网络中进行传播。实验结果表明，本方法在Cholec80、MICCAI2016和Heichole数据集上的性能均明显优于当前最先进的方法（分别高出+2.8%、+4.3%和+12.9%）。论文接受后将在公开平台上提供代码。', 'title_zh': '基于分层输入依赖状态空间模型的整体手术阶段识别'}
{'arxiv_id': 'arXiv:2506.21306', 'title': 'On Uniform Weighted Deep Polynomial approximation', 'authors': 'Kingsley Yeon, Steven B. Damelin', 'link': 'https://arxiv.org/abs/2506.21306', 'abstract': "It is a classical result in rational approximation theory that certain non-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be efficiently approximated using rational functions with root-exponential convergence in terms of degrees of freedom \\cite{Sta, GN}. In contrast, polynomial approximations admit only algebraic convergence by Jackson's theorem \\cite{Lub2}. Recent work shows that composite polynomial architectures can recover exponential approximation rates even without smoothness \\cite{KY}. In this work, we introduce and analyze a class of weighted deep polynomial approximants tailored for functions with asymmetric behavior-growing unbounded on one side and decaying on the other. By multiplying a learnable deep polynomial with a one-sided weight, we capture both local non-smoothness and global growth. We show numerically that this framework outperforms Taylor, Chebyshev, and standard deep polynomial approximants, even when all use the same number of parameters. To optimize these approximants in practice, we propose a stable graph-based parameterization strategy building on \\cite{Jar}.", 'abstract_zh': '非光滑或奇异函数（如$|x|$和$x^{1/p}$）可以用具有根指数收敛性的有理函数高效逼近，这是理性逼近理论中的一个经典结果［Sta, GN］。相比之下，多项式逼近只能通过Jackson定理给出代数收敛［Lub2］。近期研究表明，即使缺乏光滑性，复合多项式架构也可以恢复指数逼近速率［KY］。本工作中，我们引入并分析了一类针对单侧无界增长和两侧衰减的非对称行为函数的加权深度多项式逼近方法。通过将可学习的深层多项式与单侧权重相乘，我们捕捉到了局部非光滑性和全局增长特性。数值结果显示，该框架在相同的参数数量下优于Taylor、Chebyshev和标准深层多项式逼近方法。为了在实践中优化这些逼近方法，我们提出了一种基于［Jar］的稳定图结构参数化策略。', 'title_zh': '统一加权深层多项式逼近'}
{'arxiv_id': 'arXiv:2506.21298', 'title': 'Exploring Adapter Design Tradeoffs for Low Resource Music Generation', 'authors': 'Atharva Mehta, Shivam Chauhan, Monojit Choudhury', 'link': 'https://arxiv.org/abs/2506.21298', 'abstract': 'Fine-tuning large-scale music generation models, such as MusicGen and Mustango, is a computationally expensive process, often requiring updates to billions of parameters and, therefore, significant hardware resources. Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based methods, have emerged as a promising alternative, enabling adaptation with minimal trainable parameters while preserving model performance. However, the design choices for adapters, including their architecture, placement, and size, are numerous, and it is unclear which of these combinations would produce optimal adapters and why, for a given case of low-resource music genre. In this paper, we attempt to answer this question by studying various adapter configurations for two AI music models, MusicGen and Mustango, on two genres: Hindustani Classical and Turkish Makam music.\nOur findings reveal distinct trade-offs: convolution-based adapters excel in capturing fine-grained local musical details such as ornamentations and short melodic phrases, while transformer-based adapters better preserve long-range dependencies crucial for structured improvisation. Additionally, we analyze computational resource requirements across different adapter scales, demonstrating how mid-sized adapters (40M parameters) achieve an optimal balance between expressivity and quality. Furthermore, we find that Mustango, a diffusion-based model, generates more diverse outputs with better adherence to the description in the input prompt while lacking in providing stability in notes, rhythm alignment, and aesthetics. Also, it is computationally intensive and requires significantly more time to train. In contrast, autoregressive models like MusicGen offer faster training and are more efficient, and can produce better quality output in comparison, but have slightly higher redundancy in their generations.', 'abstract_zh': '大规模音乐生成模型（如MusicGen和Mustango）的精调是一个计算成本高昂的过程，通常需要更新数十亿的参数，并因此需要大量的硬件资源。参数高效精调（PEFT）技术，特别是基于适配器的方法，已经 emerged 作为一种有前途的替代方案，能够在最少的可训练参数下进行适应，同时保持模型性能。然而，适配器的设计选择，包括它们的架构、位置和规模，有很多种组合，并不清楚哪种组合会产生最优的适配器以及为什么，特别是在资源有限的音乐流派中。本文通过研究两种人工智能音乐模型（MusicGen和Mustango）在印度古典音乐和土耳其马卡姆音乐两种流派中的不同适配器配置，试图回答这个问题。\n\n我们的发现揭示了不同的权衡：基于卷积的适配器在捕捉如装饰和短旋律短语等细微的局部音乐细节方面表现出色，而基于变换器的适配器则更好地保留了对于结构即兴创作至关重要的长程依赖关系。此外，我们分析了不同规模适配器的计算资源需求，展示了中等规模的适配器（40M参数）如何在表达能力和质量之间实现最优平衡。此外，我们发现基于扩散模型的Mustango生成的输出多样且更符合输入提示的描述，但其在音高稳定性、节奏对齐和美学方面有所欠缺，在训练上也更为耗时。相比之下，自回归模型如MusicGen能够提供更快的训练速度并更为高效，可以生成更好的输出质量，但其生成过程存在轻微的冗余。', 'title_zh': '探索低资源音乐生成的适配器设计权衡'}
{'arxiv_id': 'arXiv:2506.21294', 'title': 'Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models', 'authors': 'Bram Willemsen, Gabriel Skantze', 'link': 'https://arxiv.org/abs/2506.21294', 'abstract': 'In this paper, we explore the use of a text-only, autoregressive language modeling approach for the extraction of referring expressions from visually grounded dialogue. More specifically, the aim is to investigate the extent to which the linguistic context alone can inform the detection of mentions that have a (visually perceivable) referent in the visual context of the conversation. To this end, we adapt a pretrained large language model (LLM) to perform a relatively course-grained annotation of mention spans in unfolding conversations by demarcating mention span boundaries in text via next-token prediction. Our findings indicate that even when using a moderately sized LLM, relatively small datasets, and parameter-efficient fine-tuning, a text-only approach can be effective, highlighting the relative importance of the linguistic context for this task. Nevertheless, we argue that the task represents an inherently multimodal problem and discuss limitations fundamental to unimodal approaches.', 'abstract_zh': '本研究探索仅使用文本的自回归语言模型方法从视觉接地对话中提取指代表达。具体而言，旨在调查仅基于语言背景在对话视觉上下文中的提及（可视觉感知的指代）检测的程度。为此，我们适应一个预训练的大语言模型对展开对话中的提及 spans 进行相对粗粒度的标注，通过下一-token 预测划分提及 span 的边界。研究发现，即使使用中等规模的预训练语言模型、较小的数据集和参数高效微调，仅文本的方法也可以有效，突显了语言背景在此任务中的相对重要性。然而，我们认为该任务本质上是一种多模态问题，并讨论单一模态方法的基本局限性。', 'title_zh': '基于视觉接地对话的自回归语言模型中的引用表达检测'}
{'arxiv_id': 'arXiv:2506.21288', 'title': 'Small Encoders Can Rival Large Decoders in Detecting Groundedness', 'authors': 'Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar', 'link': 'https://arxiv.org/abs/2506.21288', 'abstract': 'Augmenting large language models (LLMs) with external context significantly improves their performance in natural language processing (NLP) tasks. However, LLMs struggle to answer queries reliably when the provided context lacks information, often resorting to ungrounded speculation or internal knowledge. Groundedness - generating responses strictly supported by the context - is essential for ensuring factual consistency and trustworthiness. This study focuses on detecting whether a given query is grounded in a document provided in context before the costly answer generation by LLMs. Such a detection mechanism can significantly reduce both inference time and resource consumption. We show that lightweight, task specific encoder models such as RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in groundedness detection while reducing inference latency by orders of magnitude. The code is available at : this https URL', 'abstract_zh': '增强大型语言模型（LLMs）的外部上下文显著提高了其在自然语言处理（NLP）任务中的性能。然而，当提供的上下文缺乏信息时，LLMs往往难以可靠地回答查询，往往会 resort 到没有依据的推测或内部知识。基于上下文生成响应的可靠性 - 生成的响应必须严格基于提供的上下文 - 对确保事实一致性与可信度至关重要。本研究重点在于在LLMs生成昂贵的回答之前，检测给定查询是否基于提供的文档上下文，从而显著减少推理时间和资源消耗。我们展示了针对特定任务的轻量级编码器模型，如RoBERTa和NomicBERT，在经过精心策划的数据集微调后，可以在基于上下文的可靠性检测方面达到与最先进的LLMs（如Llama3 8B和GPT4o）相当的准确率，同时将推理延迟减少多个数量级。代码可在以下链接获取：this https URL。', 'title_zh': '小编码器可以与大解码器媲美，用于检测接地性'}
{'arxiv_id': 'arXiv:2506.21278', 'title': 'Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution', 'authors': 'Lukas Sablica, Kurt Hornik', 'link': 'https://arxiv.org/abs/2506.21278', 'abstract': 'We propose a novel variational autoencoder (VAE) architecture that employs a spherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian latent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy provides a more natural hyperspherical representation of latent variables, better capturing directional data while maintaining flexibility. Its heavy-tailed nature prevents over-regularization, ensuring efficient latent space utilization while offering a more expressive representation. Additionally, spCauchy circumvents the numerical instabilities inherent to vMF, which arise from computing normalization constants involving Bessel functions. Instead, it enables a fully differentiable and efficient reparameterization trick via Möbius transformations, allowing for stable and scalable training. The KL divergence can be computed through a rapidly converging power series, eliminating concerns of underflow or overflow associated with evaluation of ratios of hypergeometric functions. These properties make spCauchy a compelling alternative for VAEs, offering both theoretical advantages and practical efficiency in high-dimensional generative modeling.', 'abstract_zh': '我们提出了一种新颖的变分自编码器（VAE）架构，该架构采用球形洛希（spCauchy）潜空间分布。不同于传统的高斯潜空间或广泛使用的冯·梅尔-费舍尔（vMF）分布，spCauchy 提供了一种更自然的超球体表示方法，能够更好地捕捉方向性数据，同时保持灵活性。其厚尾性质防止了过度正则化，确保了潜空间的有效利用，同时提供了更具表现力的表示。此外，spCauchy 避免了 vMF 固有的数值不稳定性，这些不稳定性源于涉及贝塞尔函数的归一化常数的计算。相反，它通过莫比乌斯变换实现了完全可微和高效的重新参数化技巧，允许稳定和可扩展的训练。通过对数级迅速收敛的幂级数可以计算 Kullback-Leibler（KL）散度，消除了与超几何函数比值评估相关的下溢或上溢的担忧。这些属性使 spCauchy 成为 VAE 的有吸引力的替代方案，不仅在理论上具有优势，在高维生成建模中也具有实用效率。', 'title_zh': '超球面变分自编码器使用高效的球形柯西分布'}
{'arxiv_id': 'arXiv:2506.21269', 'title': 'Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou', 'authors': 'Pengfei Fan, Yuli Zhang, Xinheng Wang, Ruiyuan Jiang, Hankang Gu, Dongyao Jia, Shangbo Wang', 'link': 'https://arxiv.org/abs/2506.21269', 'abstract': 'This study presents and publicly releases the Suzhou Urban Road Acoustic Dataset (SZUR-Acoustic Dataset), which is accompanied by comprehensive data-acquisition protocols and annotation guidelines to ensure transparency and reproducibility of the experimental workflow. To model the coupling between vehicular noise and driving speed, we propose a bimodal-feature-fusion deep convolutional neural network (BMCNN). During preprocessing, an adaptive denoising and normalization strategy is applied to suppress environmental background interference; in the network architecture, parallel branches extract Mel-frequency cepstral coefficients (MFCCs) and wavelet-packet energy features, which are subsequently fused via a cross-modal attention mechanism in the intermediate feature space to fully exploit time-frequency information. Experimental results demonstrate that BMCNN achieves a classification accuracy of 87.56% on the SZUR-Acoustic Dataset and 96.28% on the public IDMT-Traffic dataset. Ablation studies and robustness tests on the Suzhou dataset further validate the contributions of each module to performance improvement and overfitting mitigation. The proposed acoustics-based speed classification method can be integrated into smart-city traffic management systems for real-time noise monitoring and speed estimation, thereby optimizing traffic flow control, reducing roadside noise pollution, and supporting sustainable urban planning.', 'abstract_zh': '苏州城市道路声学数据集及基于双模态特征融合的深度卷积神经网络方法（SZUR-声学数据集与BMCNN方法）', 'title_zh': '基于苏州的车辆声学数据集成用于增强城市交通管理：关于速度分类的研究'}
{'arxiv_id': 'arXiv:2506.21263', 'title': 'DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster', 'authors': 'Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich', 'link': 'https://arxiv.org/abs/2506.21263', 'abstract': 'The distributed training of foundation models, particularly large language models (LLMs), demands a high level of communication. Consequently, it is highly dependent on a centralized cluster with fast and reliable interconnects. Can we conduct training on slow networks and thereby unleash the power of decentralized clusters when dealing with models exceeding 100 billion parameters? In this paper, we propose DiLoCoX, a low-communication large-scale decentralized cluster training framework. It combines Pipeline Parallelism with Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local Training, and an Adaptive Gradient Compression Scheme. This combination significantly improves the scale of parameters and the speed of model pre-training. We justify the benefits of one-step-delay overlap of communication and local training, as well as the adaptive gradient compression scheme, through a theoretical analysis of convergence. Empirically, we demonstrate that DiLoCoX is capable of pre-training a 107B foundation model over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x speedup in distributed training while maintaining negligible degradation in model convergence. To the best of our knowledge, this is the first decentralized training framework successfully applied to models with over 100 billion parameters.', 'abstract_zh': '分布式训练基础模型，尤其是大型语言模型（LLMs），需要高度的通信。因此，它高度依赖于一个快速可靠的集中式集群。在处理超过100亿参数的模型时，我们能否在慢网络上进行训练，并释放分散式集群的潜力？在这项研究中，我们提出DiLoCoX，一种低通信大规模分散式集群训练框架。该框架结合了管道并行性、双优化器策略、一步延迟重叠通信与本地训练以及自适应梯度压缩方案。这种结合显著提高了参数规模和模型预训练速度。我们通过收敛理论分析证明了一步延迟重叠通信与本地训练以及自适应梯度压缩方案的优势。实证结果表明，DiLoCoX能够在1Gbps网络上预训练一个107B的基模型。与vanilla AllReduce相比，DiLoCoX在分布式训练中的速度提高了357倍，同时对模型收敛性几乎没有影响。据我们所知，这是首次成功将分散式训练框架应用于超过100亿参数的模型。', 'title_zh': 'DiLoCoX：去中心化聚类的低通信大规模训练框架'}
{'arxiv_id': 'arXiv:2506.21252', 'title': 'Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents', 'authors': 'Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao', 'link': 'https://arxiv.org/abs/2506.21252', 'abstract': 'As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is to use reward models as external feedback, but there is no clear on how to select reward models for agents. Thus, there is an urgent need to build a reward bench targeted at agents. To address these challenges, we propose Agent-RewardBench, a benchmark designed to evaluate reward modeling ability in MLLMs. The benchmark is characterized by three key features: (1) Multiple dimensions and real-world agent scenarios evaluation. It covers perception, planning, and safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality. We carefully sample from 10 diverse models, difficulty control to maintain task challenges, and manual verification to ensure the integrity of the data. Experiments demonstrate that even state-of-the-art multimodal models show limited performance, highlighting the need for specialized training in agent reward modeling. Code is available at github.', 'abstract_zh': '随着多模态大型语言模型（MLLMs）的发展，多模态代理在网页导航和体态智能等真实世界任务中展现出潜力。然而，由于缺乏外部反馈，这些代理在自我纠正和泛化方面存在问题。一种有希望的方法是使用奖励模型作为外部反馈，但尚不清楚如何选择适合代理的奖励模型。因此，迫切需要建立一个针对代理的奖励基准。为应对这些挑战，我们提出了Agent-RewardBench，一种旨在评估MLLMs奖励建模能力的基准。该基准具有三个关键特征：（1）多维度和真实世界代理场景评估，涵盖感知、规划和安全性，包括7种场景；（2）步骤级奖励评估，允许在任务的每个步骤上评估代理能力，提供更详细的规划过程中的性能视图；（3）适配难度和高质量。我们精心从10个不同的模型中采样，控制难度以保持任务挑战性，并通过人工验证确保数据完整性。实验表明，即使是最先进的多模态模型在代理奖励建模方面也表现出有限的表现，突显出在代理奖励建模方面的专业化训练需求。代码可在github上获取。', 'title_zh': 'Agent-RewardBench：朝向跨感知、规划和安全的现实世界多模态智能体 reward 模型统一基准'}
{'arxiv_id': 'arXiv:2506.21246', 'title': 'From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting', 'authors': 'Giorgos Demosthenous, Chryssis Georgiou, Eliada Polydorou', 'link': 'https://arxiv.org/abs/2506.21246', 'abstract': 'This study investigates the impact of data source diversity on the performance of cryptocurrency forecasting models by integrating various data categories, including technical indicators, on-chain metrics, sentiment and interest metrics, traditional market indices, and macroeconomic indicators. We introduce the Crypto100 index, representing the top 100 cryptocurrencies by market capitalization, and propose a novel feature reduction algorithm to identify the most impactful and resilient features from diverse data sources. Our comprehensive experiments demonstrate that data source diversity significantly enhances the predictive performance of forecasting models across different time horizons. Key findings include the paramount importance of on-chain metrics for both short-term and long-term predictions, the growing relevance of traditional market indices and macroeconomic indicators for longer-term forecasts, and substantial improvements in model accuracy when diverse data sources are utilized. These insights help demystify the short-term and long-term driving factors of the cryptocurrency market and lay the groundwork for developing more accurate and resilient forecasting models.', 'abstract_zh': '本研究通过整合技术指标、链上指标、情感和兴趣指标、传统市场指数和宏观经济指标等各类数据，探讨数据源多样性对加密货币预测模型性能的影响，并引入了代表市值前100加密货币的Crypto100指数，提出了一种新颖的特征减少算法，以识别来自多样数据源的最具影响和韧性的特征。综合实验表明，数据源多样性显著提高了预测模型在不同时间范围内的预测性能。关键发现包括链上指标对短期和长期预测的重要性、传统市场指数和宏观经济指标在长期预测中的日益相关性以及在利用多种数据源时模型准确性的显著提升。这些洞见有助于揭示加密货币市场的短期和长期驱动因素，并为进一步开发更准确和稳健的预测模型奠定了基础。', 'title_zh': '从区块链到宏观：评估数据源多样性在 cryptocurrency 市场预测中的重要性'}
{'arxiv_id': 'arXiv:2506.21211', 'title': '$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models', 'authors': 'Quanming Liu, Xupeng Bu, Zhichao Yan, Ru Li', 'link': 'https://arxiv.org/abs/2506.21211', 'abstract': 'Automatic Program Repair (APR) is a core technology in software development and maintenance, with aims to enable automated defect repair with minimal human intervention. In recent years, the substantial advancements in Large Language Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly enhanced the reasoning capabilities of these models. However, due to the complex logic and multi-step reasoning ability needed, the application of CoT techniques in the APR domain remains insufficient. This study systematically evaluates the performance of several common CoT techniques in APR tasks and proposes an innovative framework $T^3$, which integrates the powerful reasoning capabilities of LLMs with tree search, effectively improving the precision of generating candidate repair solutions. Furthermore, $T^3$ provides valuable guidance for optimizing sample selection and repair strategies in APR tasks, establishing a robust framework for achieving efficient automated debugging.', 'abstract_zh': 'Automatic程序修复中的Chain-of-Thought技术系统评价与T³框架', 'title_zh': '$T^3$: 基于多级树结构的大语言模型自动程序修复'}
{'arxiv_id': 'arXiv:2506.21209', 'title': 'BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models', 'authors': 'Louis Kerner, Michel Meintz, Bihe Zhao, Franziska Boenisch, Adam Dziedzic', 'link': 'https://arxiv.org/abs/2506.21209', 'abstract': "State-of-the-art text-to-image models like Infinity generate photorealistic images at an unprecedented speed. These models operate in a bitwise autoregressive manner over a discrete set of tokens that is practically infinite in size. However, their impressive generative power comes with a growing risk: as their outputs increasingly populate the Internet, they are likely to be scraped and reused as training data-potentially by the very same models. This phenomenon has been shown to lead to model collapse, where repeated training on generated content, especially from the models' own previous versions, causes a gradual degradation in performance. A promising mitigation strategy is watermarking, which embeds human-imperceptible yet detectable signals into generated images-enabling the identification of generated content. In this work, we introduce BitMark, a robust bitwise watermarking framework for Infinity. Our method embeds a watermark directly at the bit level of the token stream across multiple scales (also referred to as resolutions) during Infinity's image generation process. Our bitwise watermark subtly influences the bits to preserve visual fidelity and generation speed while remaining robust against a spectrum of removal techniques. Furthermore, it exhibits high radioactivity, i.e., when watermarked generated images are used to train another image generative model, this second model's outputs will also carry the watermark. The radioactive traces remain detectable even when only fine-tuning diffusion or image autoregressive models on images watermarked with our BitMark. Overall, our approach provides a principled step toward preventing model collapse in image generative models by enabling reliable detection of generated outputs.", 'abstract_zh': '最先进的文本到图像模型如Infinity以 unprecedented的速度生成逼真图像。这些模型以位级自回归的方式作用于一个 Practically无限大的离散标记集上。然而，它们强大的生成能力伴随着一个日益增长的风险：随着它们的输出越来越充斥互联网，这些输出很可能会被抓取并重新用作训练数据——甚至可能是由这些模型本身之前版本生成的内容。这种现象已被证明会导致模型崩溃，反复训练生成的内容会导致性能逐渐退化。一种有前景的缓解策略是水印技术，该技术在生成图像中嵌入人类无法察觉但可检测的信号，以识别生成的内容。在这项工作中，我们引入了BitMark，一种适用于Infinity的 robust位级水印框架。我们的方法在Infinity图像生成过程中，在标记流的不同尺度（也称为分辨率）直接嵌入水印。我们的位级水印微妙地影响位以保持视觉保真度和生成速度，同时对各种去除技术保持稳健。此外，它还表现出很高的放射性，即使用水印生成的图像来训练另一张图像生成模型时，这一第二个模型的输出也将携带水印。即使仅对带有BitMark水印的图像进行细调扩散或图像自回归模型，放射性痕迹仍然可被检测到。总体而言，我们的方法提供了一种有原则的步骤，以通过确保生成输出的可靠检测来防止图像生成模型中模型崩溃的发生。', 'title_zh': 'BitMark for Infinity: 水印化位级自回归图像生成模型'}
{'arxiv_id': 'arXiv:2506.21184', 'title': 'Task-Aware KV Compression For Cost-Effective Long Video Understanding', 'authors': 'Minghao Qin, Yan Shu, Peitian Zhang, Kun Lun, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu', 'link': 'https://arxiv.org/abs/2506.21184', 'abstract': "Long-video understanding (LVU) remains a severe challenge for existing multimodal large language models (MLLMs), primarily due to the prohibitive computational cost. Recent approaches have explored KV compression to mitigate this issue, but they often suffer from significant information loss at high compression ratios. In this paper, we introduce Video-X^2L, which flexibly preserves critical video information for each LVU task. Video-X^2L involves two key operations. The first one is called bi-level KV compression. During the MLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs: low-compression KVs (L-KVs) to capture fine-grained video details and high-compression KVs (H-KVs) to offer compact video representations. The second one is called selective KV re-loading. During the MLLM's decoding stage, Video-X^2L selectively re-loads L-KVs for the most critical video chunks while using H-KVs for other less important ones. This allows the MLLM to fully utilize task-specific information while maintaining the overall compactness. Video-X^2L is simple yet effective: it is free from additional training and directly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2L with a variety of popular LVU benchmarks, including VideoMME, MLVU, LongVideoBench, and VNBench. Our experiment result shows that Video-X^2L outperforms existing KV-compression methods by a huge advantage while substantially saving the computation cost.", 'abstract_zh': '长视频理解中的关键视频信息灵活保留方法：Video-X^2L', 'title_zh': '面向任务的KV压缩以实现低成本长视频理解'}
{'arxiv_id': 'arXiv:2506.21182', 'title': 'Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks', 'authors': 'Isaac Chung, Imene Kerboua, Marton Kardos, Roman Solomatin, Kenneth Enevoldsen', 'link': 'https://arxiv.org/abs/2506.21182', 'abstract': "The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation platform for text embedding models. While previous work has established the core benchmark methodology, this paper focuses on the engineering aspects that ensure MTEB's continued reproducibility and extensibility. We present our approach to maintaining robust continuous integration pipelines that validate dataset integrity, automate test execution, and assess benchmark results' generalizability. We detail the design choices that collectively enhance reproducibility and usability. Furthermore, we discuss our strategies for handling community contributions and extending the benchmark with new tasks and datasets. These engineering practices have been instrumental in scaling MTEB to become more comprehensive while maintaining quality and, ultimately, relevance to the field. Our experiences offer valuable insights for benchmark maintainers facing similar challenges in ensuring reproducibility and usability in machine learning evaluation frameworks. The MTEB repository is available at: this https URL", 'abstract_zh': '大规模文本嵌入基准 (MTEB) 已成为文本嵌入模型的标准评估平台。虽然之前的研究所确立了核心基准方法，本文则专注于确保 MTEB 持续可重复性和扩展性的工程方面。我们介绍了维护稳健的持续集成管道的方法，该管道验证数据集的完整性、自动化测试执行，并评估基准结果的推广能力。我们详细阐述了集体增强可重复性和易用性的设计选择。此外，我们讨论了处理社区贡献并通过新任务和数据集扩展基准的策略。这些工程实践在使 MTEB 更趋全面的同时保持质量，并最终保持对领域的相关性方面起到了关键作用。我们的经验为在机器学习评估框架中确保可重复性和易用性的标定维护者提供了宝贵的见解。MTEB 仓库可在以下链接找到：this https URL。', 'title_zh': '维护MTEB：迈向嵌入表示基准的长期可用性和可重复性'}
{'arxiv_id': 'arXiv:2506.21167', 'title': 'A Hierarchical Deep Learning Approach for Minority Instrument Detection', 'authors': "Dylan Sechet, Francesca Bugiotti, Matthieu Kowalski, Edouard d'Hérouville, Filip Langiewicz", 'link': 'https://arxiv.org/abs/2506.21167', 'abstract': 'Identifying instrument activities within audio excerpts is vital in music information retrieval, with significant implications for music cataloging and discovery. Prior deep learning endeavors in musical instrument recognition have predominantly emphasized instrument classes with ample data availability. Recent studies have demonstrated the applicability of hierarchical classification in detecting instrument activities in orchestral music, even with limited fine-grained annotations at the instrument level. Based on the Hornbostel-Sachs classification, such a hierarchical classification system is evaluated using the MedleyDB dataset, renowned for its diversity and richness concerning various instruments and music genres. This work presents various strategies to integrate hierarchical structures into models and tests a new class of models for hierarchical music prediction. This study showcases more reliable coarse-level instrument detection by bridging the gap between detailed instrument identification and group-level recognition, paving the way for further advancements in this domain.', 'abstract_zh': '识别音频段落中的乐器活动对于音乐信息检索至关重要，对音乐编目与发现具有重大意义。既有深度学习研究主要集中在数据丰富的乐器类别上。近期研究表明，层次分类方法在管弦乐中检测乐器活动具有可行性，即使细粒度的乐器标注有限。基于Hornbostel-Sachs分类体系，本研究使用MedleyDB数据集评估层次分类系统，该数据集涵盖多种乐器和音乐流派，具有多样性和丰富性。本研究提出了多种将层次结构整合到模型中的策略，并测试了一类新的层次音乐预测模型。此项研究通过弥合详细乐器识别与群体级识别之间的差距，展示了更可靠的粗粒度乐器检测方法，为该领域的进一步发展奠定了基础。', 'title_zh': '基于分层深度学习的少数乐器检测方法'}
{'arxiv_id': 'arXiv:2506.21162', 'title': 'A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation', 'authors': 'Shuwei Xing, Derek W. Cool, David Tessier, Elvis C.S. Chen, Terry M. Peters, Aaron Fenster', 'link': 'https://arxiv.org/abs/2506.21162', 'abstract': '3D ultrasound (US) imaging has shown significant benefits in enhancing the outcomes of percutaneous liver tumour ablation. Its clinical integration is crucial for transitioning 3D US into the therapeutic domain. However, challenges of tumour identification in US images continue to hinder its broader adoption. In this work, we propose a novel framework for integrating 3D US into the standard ablation workflow. We present a key component, a clinically viable 2D US-CT/MRI registration approach, leveraging 3D US as an intermediary to reduce registration complexity. To facilitate efficient verification of the registration workflow, we also propose an intuitive multimodal image visualization technique. In our study, 2D US-CT/MRI registration achieved a landmark distance error of approximately 2-4 mm with a runtime of 0.22s per image pair. Additionally, non-rigid registration reduced the mean alignment error by approximately 40% compared to rigid registration. Results demonstrated the efficacy of the proposed 2D US-CT/MRI registration workflow. Our integration framework advanced the capabilities of 3D US imaging in improving percutaneous tumour ablation, demonstrating the potential to expand the therapeutic role of 3D US in clinical interventions.', 'abstract_zh': '3D超声成像在增强经皮肝肿瘤消融效果方面的显著优势及其临床整合对于将3D超声引入治疗领域至关重要。然而，肿瘤在超声图像中的识别挑战继续阻碍其更广泛的采用。在此工作中，我们提出了一种新的框架，用于将3D超声整合到标准消融工作流程中。我们提出了一种临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介以降低配准复杂性。为了方便高效验证配准工作流程，我们还提出了一种直观的多模态图像可视化技术。在我们的研究中，2D超声-CT/MRI配准的地标距离误差约为2-4毫米，运行时间为每张图像对0.22秒。此外，非刚性配准相比刚性配准将平均对齐误差降低了约40%。结果表明，所提出的2D超声-CT/MRI配准工作流程的有效性。我们的集成框架提升了3D超声成像在改善经皮肿瘤消融方面的功能，展示了3D超声在临床干预中扩展治疗作用的潜力。', 'title_zh': '一种将3D超声集成到经皮肝肿瘤消融的新框架'}
{'arxiv_id': 'arXiv:2506.21154', 'title': 'Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation', 'authors': 'He Li, Haoang Chi, Mingyu Liu, Wanrong Huang, Liyang Xu, Wenjing Yang', 'link': 'https://arxiv.org/abs/2506.21154', 'abstract': 'The real world naturally has dimensions of time and space. Therefore, estimating the counterfactual outcomes with spatial-temporal attributes is a crucial problem. However, previous methods are based on classical statistical models, which still have limitations in performance and generalization. This paper proposes a novel framework for estimating counterfactual outcomes with spatial-temporal attributes using the Transformer, exhibiting stronger estimation ability. Under mild assumptions, the proposed estimator within this framework is consistent and asymptotically normal. To validate the effectiveness of our approach, we conduct simulation experiments and real data experiments. Simulation experiments show that our estimator has a stronger estimation capability than baseline methods. Real data experiments provide a valuable conclusion to the causal effect of conflicts on forest loss in Colombia. The source code is available at this https URL.', 'abstract_zh': '真实世界自然具有时间和空间维度。因此，具有时空属性的反事实结果估计是一个关键问题。然而，先前的方法基于经典统计模型，仍然在性能和泛化能力方面存在局限性。本文提出了一种新的框架，利用Transformer进行具有时空属性的反事实结果估计，展示了更强的估计能力。在温和的假设下，该框架中的所提估计量是一致且渐近正态的。为了验证我们方法的有效性，我们进行了仿真实验和真实数据实验。仿真实验表明，我们的估计量在估计能力上优于基线方法。真实数据实验提供了冲突对哥伦比亚森林损失因果效应的关键结论。源代码可在以下链接获取。', 'title_zh': '基于 Transformer 的空间-时间反事实结果估计'}
{'arxiv_id': 'arXiv:2506.21151', 'title': 'Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels', 'authors': 'Aida Moafi, Danial Moafi, Evgeny M. Mirkes, Gerry P. McCann, Abbas S. Alatrany, Jayanth R. Arnold, Mostafa Mehdipour Ghazi', 'link': 'https://arxiv.org/abs/2506.21151', 'abstract': "The accurate segmentation of myocardial scars from cardiac MRI is essential for clinical assessment and treatment planning. In this study, we propose a robust deep-learning pipeline for fully automated myocardial scar detection and segmentation by fine-tuning state-of-the-art models. The method explicitly addresses challenges of label noise from semi-automatic annotations, data heterogeneity, and class imbalance through the use of Kullback-Leibler loss and extensive data augmentation. We evaluate the model's performance on both acute and chronic cases and demonstrate its ability to produce accurate and smooth segmentations despite noisy labels. In particular, our approach outperforms state-of-the-art models like nnU-Net and shows strong generalizability in an out-of-distribution test set, highlighting its robustness across various imaging conditions and clinical tasks. These results establish a reliable foundation for automated myocardial scar quantification and support the broader clinical adoption of deep learning in cardiac imaging.", 'abstract_zh': '心脏MRI中心肌疤痕的准确分割对于临床评估和治疗计划至关重要。本研究提出了一种稳健的深度学习管道，用于完全自动的心肌疤痕检测和分割，通过微调先进模型来解决标签噪声、数据异质性和类别不平衡等挑战。方法通过使用Kullback-Leibler损失和大量数据增强，明确解决了上述挑战。我们在急性和慢性病例上评估了模型的性能并展示了其能够在噪声标签下生成准确且平滑的分割的能力。特别地，我们的方法在nnU-Net等先进模型中表现出色，并在分布外测试集中显示出强大的泛化能力，突显了其在各种成像条件和临床任务中的 robust 性。这些结果为自动心肌疤痕量化建立了可靠基础，并支持深度学习在心脏成像中的更广泛临床应用。', 'title_zh': '基于嘈杂标签的心脏MRI心肌疤痕分割的稳健深度学习'}
{'arxiv_id': 'arXiv:2506.21146', 'title': 'Linearity-based neural network compression', 'authors': 'Silas Dobler, Florian Lemmerich', 'link': 'https://arxiv.org/abs/2506.21146', 'abstract': 'In neural network compression, most current methods reduce unnecessary parameters by measuring importance and redundancy. To augment already highly optimized existing solutions, we propose linearity-based compression as a novel way to reduce weights in a neural network. It is based on the intuition that with ReLU-like activation functions, neurons that are almost always activated behave linearly, allowing for merging of subsequent layers. We introduce the theory underlying this compression and evaluate our approach experimentally. Our novel method achieves a lossless compression down to 1/4 of the original model size in over the majority of tested models. Applying our method on already importance-based pruned models shows very little interference between different types of compression, demonstrating the option of successful combination of techniques. Overall, our work lays the foundation for a new type of compression method that enables smaller and ultimately more efficient neural network models.', 'abstract_zh': '基于线性性的神经网络压缩方法', 'title_zh': '基于线性性的神经网络压缩'}
{'arxiv_id': 'arXiv:2506.21140', 'title': 'DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding', 'authors': 'Ziwei Wang, Hongbin Wang, Tianwang Jia, Xingyi He, Siyang Li, Dongrui Wu', 'link': 'https://arxiv.org/abs/2506.21140', 'abstract': 'Electroencephalography (EEG)-based brain-computer interfaces (BCIs) transform spontaneous/evoked neural activity into control commands for external communication. While convolutional neural networks (CNNs) remain the mainstream backbone for EEG decoding, their inherently short receptive field makes it difficult to capture long-range temporal dependencies and global inter-channel relationships. Recent CNN-Transformer (Conformers) hybrids partially address this issue, but most adopt a serial design, resulting in suboptimal integration of local and global features, and often overlook explicit channel-wise modeling. To address these limitations, we propose DBConformer, a dual-branch convolutional Transformer network tailored for EEG decoding. It integrates a temporal Conformer to model long-range temporal dependencies and a spatial Conformer to extract inter-channel interactions, capturing both temporal dynamics and spatial patterns in EEG signals. A lightweight channel attention module further refines spatial representations by assigning data-driven importance to EEG channels. Extensive experiments on five motor imagery (MI) datasets and two seizure detection datasets under three evaluation settings demonstrate that DBConformer consistently outperforms 10 competitive baseline models, with over eight times fewer parameters than the high-capacity EEG Conformer baseline. Further, the visualization results confirm that the features extracted by DBConformer are physiologically interpretable and aligned with sensorimotor priors in MI. The superior performance and interpretability of DBConformer make it reliable for robust and explainable EEG decoding. Code is publicized at this https URL.', 'abstract_zh': '基于脑电图（EEG）的脑机接口（BCIs）通过转化自发/诱发神经活动为对外部通信的控制命令。尽管卷积神经网络（CNNs）仍然是EEG解码的主要骨干网络，但其固有的短感受野使得难以捕捉长程时间依赖性和全局通道间关系。近期的CNN-Transformer（Conformers）混合模型部分解决了这一问题，但大多数采用串行设计，导致局部和全局特征的整合欠佳，并且往往忽略了显式的通道建模。为了解决这些局限，我们提出了一种适用于EEG解码的双分支卷积Transformer网络DBConformer。DBConformer结合了时间Conformer以建模长程时间依赖性，并结合空间Conformer以提取通道间交互作用，从而同时捕捉EEG信号的时空特征。轻量级通道注意模块进一步通过数据驱动的方式对EEG通道赋予重要性，以精炼空间表示。在三种评价设置下，对五个多导想象（MI）数据集和两个癫痫检测数据集进行的广泛实验表明，DBConformer在参数量远少于高容量EEG Conformer基线的情况下，始终优于十个竞争性基线模型。此外，可视化结果显示，DBConformer提取的特征具有生理可解释性，并与多导想象先验一致。DBConformer的优异性能和可解释性使其成为稳健且可解释的EEG解码的可靠选择。代码在以下链接公开：[this https URL]。', 'title_zh': 'DBConformer: 双支路卷积变换器用于EEG解码'}
{'arxiv_id': 'arXiv:2506.21138', 'title': 'How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE', 'authors': 'Abdelkarim El-Hajjami, Camille Salinesi', 'link': 'https://arxiv.org/abs/2506.21138', 'abstract': 'The shortage of publicly available, labeled requirements datasets remains a major barrier to advancing Artificial Intelligence for Requirements Engineering (AI4RE). While Large Language Models offer promising capabilities for synthetic data generation, systematic approaches to control and optimize the quality of generated requirements remain underexplored. This paper presents Synthline v1, an enhanced Product Line approach for generating synthetic requirements data that extends our earlier v0 version with advanced generation strategies and curation techniques. We investigate four research questions assessing how prompting strategies, automated prompt optimization, and post-generation curation affect data quality across four classification tasks: defect detection, functional vs. non-functional, quality vs. non-quality, and security vs. non-security. Our evaluation shows that multi-sample prompting significantly boosts both utility and diversity over single-sample generation, with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic Editing) for automated prompt optimization yields task-dependent results, greatly improving functional classification (+32.5 points) but reducing performance on others. Interestingly, similarity-based curation improves diversity but often harms classification performance, indicating that some redundancy may help ML models. Most importantly, our results show that synthetic requirements can match or outperform human-authored ones for specific tasks, with synthetic data surpassing human data for security (+7.8 points) and defect classification (+15.4 points). These findings offer practical insights for AI4RE and chart a viable path to mitigating dataset scarcity through systematic synthetic generation.', 'abstract_zh': '公开标注的需求数据集短缺仍然是推进人工智能在需求工程中的应用的主要障碍。尽管大型语言模型提供了生成合成数据的潜力，但控制和优化生成需求质量的系统方法仍处于探索阶段。本文介绍了Synthline v1，这是一种增强的产品线方法，用于生成合成需求数据，该方法在先前的v0版本基础上，增加了先进的生成策略和编目技术。我们探讨了四种研究问题，评估了提示策略、自动化提示优化和生成后编目的数据质量对四种分类任务（缺陷检测、功能性 vs 非功能性、质量 vs 非质量、安全 vs 非安全）的影响。评估结果显示，多样本提示在提升实用性和多样性方面显著优于单样本生成，F1分数提高了6到44个百分点。使用PACE（提示演员-评论者编辑）进行自动化提示优化在不同任务上表现出依赖性结果，极大提高了功能性分类（+32.5个百分点），但其他任务的表现有所下降。有趣的是，基于相似性的编目可以提高多样性，但往往会损害分类性能，表明一些冗余可能有助于机器学习模型。最重要的是，我们的研究结果表明，合成需求数据在特定任务上可以与甚至超过人工撰写的数据的表现，合成数据在安全性（+7.8个百分点）和缺陷分类（+15.4个百分点）方面超过了人类数据。这些发现为人工智能在需求工程中的应用提供了实际见解，并明确了通过系统合成生成缓解数据稀缺性的可行路径。', 'title_zh': '合成需求的质量如何？评估AI4RE中生成的数据集'}
{'arxiv_id': 'arXiv:2506.21129', 'title': 'Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks', 'authors': 'Deepak Kumar Panda, Adolfo Perrusquia, Weisi Guo', 'link': 'https://arxiv.org/abs/2506.21129', 'abstract': 'Reinforcement learning (RL) policies deployed in safety-critical systems, such as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are vulnerable to out-ofdistribution (OOD) adversarial attacks in the observation space. These attacks induce distributional shifts that significantly degrade value estimation, leading to unsafe or suboptimal decision making rendering the existing policy fragile. To address this vulnerability, we propose an antifragile RL framework designed to adapt against curriculum of incremental adversarial perturbations. The framework introduces a simulated attacker which incrementally increases the strength of observation-space perturbations which enables the RL agent to adapt and generalize across a wider range of OOD observations and anticipate previously unseen attacks. We begin with a theoretical characterization of fragility, formally defining catastrophic forgetting as a monotonic divergence in value function distributions with increasing perturbation strength. Building on this, we define antifragility as the boundedness of such value shifts and derive adaptation conditions under which forgetting is stabilized. Our method enforces these bounds through iterative expert-guided critic alignment using Wasserstein distance minimization across incrementally perturbed observations. We empirically evaluate the approach in a UAV deconfliction scenario involving dynamic 3D obstacles. Results show that the antifragile policy consistently outperforms standard and robust RL baselines when subjected to both projected gradient descent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative reward and over 30% fewer conflict events. These findings demonstrate the practical and theoretical viability of antifragile reinforcement learning for secure and resilient decision-making in environments with evolving threat scenarios.', 'abstract_zh': '在动态空域中部署于无人驾驶航空车辆(UAV)导航的安全关键系统中的强化学习(Reinforcement Learning, RL)策略容易受到观测空间中的离分布攻击(out-of-distribution adversarial attacks)的威胁。这些攻击引起分布偏移，显著恶化价值估计，导致不安全或次优的决策，使现有策略变得脆弱。为此，我们提出了一种抗脆弱的RL框架，该框架旨在对抗逐步增加的 adversarial 干扰。该框架引入了一个模拟攻击者，逐步增强观测空间中的干扰强度，使RL智能体能够适应和泛化到更广泛的离分布观测，并预见到先前未见过的攻击。我们从理论上对脆弱性进行了刻画，正式定义了灾难性遗忘作为价值函数分布随干扰强度增加的单调发散。在此基础上，我们定义抗脆弱性为这些价值变化的有界性，并导出了使遗忘被稳定化的适应条件。该方法通过 Wasserstein 距离最小化逐步干扰观测中的专家指导批评者对齐来实现这些边界。我们通过一个涉及动态3D障碍的无人驾驶航空车辆(UAV)冲突缓解场景，对该方法进行了实证评估。结果表明，当受到项目梯度下降(PGD)和GPS欺骗攻击时，抗脆弱策略始终优于标准RL基线和鲁棒RL基线，累计奖励提高了高达15%，冲突事件减少了超过30%。这些发现证明了在不断演变的威胁场景中，抗脆弱强化学习在安全和鲁棒决策制定方面的实用性和理论可行性。', 'title_zh': '基于课程引导的抗毁强化学习及观测空间攻击下的无人机冲突缓解'}
{'arxiv_id': 'arXiv:2506.21127', 'title': 'Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments', 'authors': 'Deepak Kumar Panda, Weisi Guo', 'link': 'https://arxiv.org/abs/2506.21127', 'abstract': 'The increasing automation of navigation for unmanned aerial vehicles (UAVs) has exposed them to adversarial attacks that exploit vulnerabilities in reinforcement learning (RL) through sensor manipulation. Although existing robust RL methods aim to mitigate such threats, their effectiveness has limited generalization to out-of-distribution shifts from the optimal value distribution, as they are primarily designed to handle fixed perturbation. To address this limitation, this paper introduces an antifragile RL framework that enhances adaptability to broader distributional shifts by incorporating a switching mechanism based on discounted Thompson sampling (DTS). This mechanism dynamically selects among multiple robust policies to minimize adversarially induced state-action-value distribution shifts. The proposed approach first derives a diverse ensemble of action robust policies by accounting for a range of perturbations in the policy space. These policies are then modeled as a multiarmed bandit (MAB) problem, where DTS optimally selects policies in response to nonstationary Bernoulli rewards, effectively adapting to evolving adversarial strategies. Theoretical framework has also been provided where by optimizing the DTS to minimize the overall regrets due to distributional shift, results in effective adaptation against unseen adversarial attacks thus inducing antifragility. Extensive numerical simulations validate the effectiveness of the proposed framework in complex navigation environments with multiple dynamic three-dimensional obstacles and with stronger projected gradient descent (PGD) and spoofing attacks. Compared to conventional robust, non-adaptive RL methods, the antifragile approach achieves superior performance, demonstrating shorter navigation path lengths and a higher rate of conflict-free navigation trajectories compared to existing robust RL techniques', 'abstract_zh': '无人飞行器导航自动化日益增加暴露了它们在感应器操控下利用强化学习 Vulnerabilities 的对抗性攻击风险。尽管现有的鲁棒强化学习方法旨在减轻这些威胁，但它们在应对最优价值分布之外的域外变化时效果有限，因为它们主要设计用于处理固定的扰动。为解决这一局限性，本文提出了一种抗脆强化学习框架，通过引入基于折扣曲杆采样的切换机制来增强对更广泛分布变化的适应性。该机制动态选择多个鲁棒策略，以最小化对抗性诱导的状态-动作-价值分布变化。该方法首先通过考虑策略空间中多种扰动的范围，推导出一个多样化的行动鲁棒策略集。这些策略被建模为一个多臂 bandit (MAB) 问题，其中折扣曲杆采样 (DTS) 优化地在响应非平稳伯努利奖励时选择策略，从而有效地适应不断变化的对抗性策略。通过优化 DTS 以最小化因分布变化引起的总体遗憾，从而实现对未见过的对抗性攻击的有效适应，增强系统的抗脆性。广泛的数值仿真验证了该框架在具有多个动态三维障碍物的复杂导航环境中对更强大投影梯度下降 (PGD) 和欺骗性攻击的有效性。与传统的非适应性鲁棒强化学习方法相比，抗脆方法实现了更优的性能，导航路径长度更短，并且冲突-free 导航轨迹的比例更高，优于现有的鲁棒强化学习技术。', 'title_zh': '鲁棒的策略切换以实现抗脆弱的无人机避障学习在对抗环境中的应用'}
{'arxiv_id': 'arXiv:2506.21119', 'title': 'Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models', 'authors': 'Xiaoshuang Ji, Zhendong Zhao, Xiaojun Chen, Xin Zhao, Zeyao Liu', 'link': 'https://arxiv.org/abs/2506.21119', 'abstract': 'Fine-tuning is a promising technique for leveraging Transformer-based language models in downstream tasks. As model sizes continue to grow, updating all model parameters becomes increasingly costly. Parameter-efficient fine-tuning methods effectively address this issue by selectively updating a small subset of parameters. However, fine-tuning and most existing parameter-efficient fine-tuning methods require updating the same number of parameters as the initial size, ignoring the unequal contribution across Transformer blocks and leading to extremely inefficient allocation of computing resources. In this paper, we propose Progtuning, the novel fine-tuning framework combined with progressive learning for Transformer-based language models. Specifically, Progtuning progressively reduces the number of updated transformer blocks based on the contribution. Remarkably, Progtuning optimizes resource allocation and reduces the number of updated parameters by approximately 25\\%, while still maintaining competitive performance. And it also exhibits high adaptability with parameter-efficient fine-tuning methods, demonstrating excellent performance across various adaptation scenarios.', 'abstract_zh': 'Progressuning：基于渐进学习的参数高效微调框架', 'title_zh': 'Proggtuning: 基于 Transformer 的语言模型逐级微调框架'}
{'arxiv_id': 'arXiv:2506.21116', 'title': 'IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes', 'authors': 'Yujia Liang, Jile Jiao, Zhicheng Wang, Xuetao Feng, Zixuan Ye, Yuan Wang, Hao Lu', 'link': 'https://arxiv.org/abs/2506.21116', 'abstract': 'Video Large Language Models (VideoLLMs) have demonstrated remarkable understanding capabilities, but are found struggling to tackle multi-shot scenarios,e.g., video clips with varying camera angles or scene changes. This challenge can render failures such as instance identity forgetting and key frame negligence. In this work, we first attribute the challenge to the lack of multi-shot annotations among existing datasets and therefore we introduce a new dataset termed MultiClip-Bench, featuring dense descriptions and instruction-based question-answering pairs tailored for multi-shot scenarios. We empirically find that the training set significantly boosts the multi-shot performance, while the testing benchmark provides a reliable measure of the model capability in multi-shot scenarios. By further analyzing and discovering that current models only encode instance features in a discrete or lossy manner, at the risk of missing identity information, we then contribute a new model IPFormer-VideoLLM. Its key idea is the injection of instance-level features as instance prompts through an efficient attention-based connector. This allows for the aggregation of instance-specific information across scenes. Experiments demonstrate that our proposed dataset and model not only enhance the multi-scene video understanding significantly, but also offer distinct advantages across various video benchmarks.', 'abstract_zh': 'Video Large Language Models (VideoLLMs) 在多轮场景下的理解能力有待提高：一个新的多剪辑基准MultiClip-Bench及IPFormer-VideoLLM模型', 'title_zh': 'IPFormer-VideoLLM: 提升多模态视频理解能力以应对多镜头场景'}
{'arxiv_id': 'arXiv:2506.21106', 'title': 'PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction', 'authors': 'Felipe Castaño, Eduardo Fidalgo, Enrique Alegre, Rocio Alaiz-Rodríguez, Raul Orduna, Francesco Zola', 'link': 'https://arxiv.org/abs/2506.21106', 'abstract': 'Phishing attacks pose a significant cybersecurity threat, evolving rapidly to bypass detection mechanisms and exploit human vulnerabilities. This paper introduces PhishKey to address the challenges of adaptability, robustness, and efficiency. PhishKey is a novel phishing detection method using automatic feature extraction from hybrid sources. PhishKey combines character-level processing with Convolutional Neural Networks (CNN) for URL classification, and a Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at the word level. CAPE reduces noise and ensures complete sample processing avoiding crop operations on the input data. The predictions from both modules are integrated using a soft-voting ensemble to achieve more accurate and reliable classifications. Experimental evaluations on four state-of-the-art datasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1 Score and shows strong resistance to adversarial manipulations such as injection attacks with minimal performance degradation.', 'abstract_zh': '钓鱼攻击构成重大的网络安全威胁，不断演化以规避检测机制并利用人类漏洞。本文介绍PhishKey以应对适应性、鲁棒性和效率的挑战。PhishKey是一种使用混合来源自动特征提取的新型钓鱼检测方法，结合了字符级处理与卷积神经网络（CNN）进行URL分类，并在词级上结合了基于质心的关键成分钓鱼提取器（CAPE）进行HTML内容分析。CAPE减少了噪声并确保完整样本处理，避免在输入数据上进行裁剪操作。两个模块的预测结果通过软投票集成，以实现更准确和可靠的分类。实验评估表明，PhishKey在四个最先进的数据集上具有有效性，其F1分数最高可达98.70%，并对如注入攻击等对抗性操纵显示出较强的抵抗力，性能下降 minimal。', 'title_zh': 'PhishKey: 一种基于中心点的自适应HTML组件提取增强的钓鱼检测新方法'}
{'arxiv_id': 'arXiv:2506.21102', 'title': 'Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning', 'authors': 'David Debot, Pietro Barbiero, Gabriele Dominici, Giuseppe Marra', 'link': 'https://arxiv.org/abs/2506.21102', 'abstract': 'Concept-Based Models (CBMs) are a class of deep learning models that provide interpretability by explaining predictions through high-level concepts. These models first predict concepts and then use them to perform a downstream task. However, current CBMs offer interpretability only for the final task prediction, while the concept predictions themselves are typically made via black-box neural networks. To address this limitation, we propose Hierarchical Concept Memory Reasoner (H-CMR), a new CBM that provides interpretability for both concept and task predictions. H-CMR models relationships between concepts using a learned directed acyclic graph, where edges represent logic rules that define concepts in terms of other concepts. During inference, H-CMR employs a neural attention mechanism to select a subset of these rules, which are then applied hierarchically to predict all concepts and the final task. Experimental results demonstrate that H-CMR matches state-of-the-art performance while enabling strong human interaction through concept and model interventions. The former can significantly improve accuracy at inference time, while the latter can enhance data efficiency during training when background knowledge is available.', 'abstract_zh': '基于概念的模型（CBMs）通过高级概念解释预测，提供可解释性，这些模型首先预测概念，然后使用这些概念执行下游任务。然而，当前的CBMs仅对最终任务预测提供可解释性，而概念预测本身通常通过黑盒神经网络生成。为解决这一局限，我们提出了层次概念记忆推理器（H-CMR），这是一种新的CBM，为概念和任务预测都提供可解释性。H-CMR使用学习到的有向无环图来建模概念之间的关系，其中边表示逻辑规则，这些规则以其他概念来定义概念。在推理过程中，H-CMR采用神经注意力机制来选择这些规则中的一组，然后逐级应用这些规则以预测所有概念和最终的任务。实验结果表明，H-CMR在匹配最新性能的同时，通过概念和模型干预增强了强大的人工交互能力。前者可以在推理时显著提高准确性，而后者可以在有背景知识的情况下增强训练时的数据效率。', 'title_zh': '基于注意力引导图学习的可解释层次概念推理'}
{'arxiv_id': 'arXiv:2506.21098', 'title': 'ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry', 'authors': 'Qinwen Chen, Wenbiao Tao, Zhiwei Zhu, Mingfan Xi, Liangzhong Guo, Yuan Wang, Wei Wang, Yunshi Lan', 'link': 'https://arxiv.org/abs/2506.21098', 'abstract': 'Community Question Answering (CQA) platforms can be deemed as important knowledge bases in community, but effectively leveraging historical interactions and domain knowledge in real-time remains a challenge. Existing methods often underutilize external knowledge, fail to incorporate dynamic historical QA context, or lack memory mechanisms suited for industrial deployment. We propose ComRAG, a retrieval-augmented generation framework for real-time industrial CQA that integrates static knowledge with dynamic historical QA pairs via a centroid-based memory mechanism designed for retrieval, generation, and efficient storage. Evaluated on three industrial CQA datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9% improvement in vector similarity, reducing latency by 8.7% to 23.3%, and lowering chunk growth from 20.23% to 2.06% over iterations.', 'abstract_zh': '基于中心点记忆机制的实时工业社区问答检索增强生成框架', 'title_zh': 'ComRAG：基于动态向量存储的即时行业社区问答检索增强生成'}
{'arxiv_id': 'arXiv:2506.21095', 'title': 'FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation', 'authors': 'Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale', 'link': 'https://arxiv.org/abs/2506.21095', 'abstract': "Federated Learning (FL) enables collaborative model training across multiple clients without sharing clients' private data. However, fairness remains a key concern, as biases in local clients' datasets can impact the entire federated system. Heterogeneous data distributions across clients may lead to models that are fairer for some clients than others. Although several fairness-enhancing solutions are present in the literature, most focus on mitigating bias for a single sensitive attribute, typically binary, overlooking the diverse and sometimes conflicting fairness needs of different clients. This limited perspective can limit the effectiveness of fairness interventions for the different clients. To support more robust and reproducible fairness research in FL, we aim to enable a consistent benchmarking of fairness-aware FL methods at both the global and client levels. In this paper, we contribute in three ways: (1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to evaluating fair FL methods under heterogeneous client bias; (2) we release four bias-heterogeneous datasets and corresponding benchmarks to compare fairness mitigation methods in a controlled environment; (3) we provide ready-to-use functions for evaluating fairness outcomes for these datasets.", 'abstract_zh': '联邦学习(Federated Learning)能够在不分享客户端私人数据的情况下，实现跨多个客户端的协作模型训练。然而，公平性仍然是一个关键问题，因为客户端本地数据集中的偏差会影响整个联邦系统。客户端之间异质的数据分布可能导致对于某些客户端来说更公平的模型，而对于其他客户端则不然。虽然文献中存在多种增强公平性的解决方案，但大多数方法仅关注减轻单一敏感属性的偏差，通常为二元属性，未能考虑到不同客户端多样且有时冲突的公平性需求。这种有限的视角可能限制了公平性干预措施对不同客户端的有效性。为了支持联邦学习中更 robust 和可重现的公平性研究，我们旨在从全球和客户端两个层面一致地评估公平意识联邦学习方法。在本文中，我们从三个方面做出了贡献：(1) 引入了FeDa4Fair库，用于生成适应评估公平联邦学习方法的异质客户端偏置的表格数据集；(2) 发布了四个异质偏差数据集及相关基准，以在可控环境中比较公平性缓解方法；(3) 提供了用于评估这些数据集公平性结果的现成函数。', 'title_zh': 'FeDa4Fair: 客户端级联邦数据集用于公平性评估'}
{'arxiv_id': 'arXiv:2506.21085', 'title': 'CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions', 'authors': 'Yangzhe Peng, Kaiyuan Gao, Liang He, Yuheng Cong, Haiguang Liu, Kun He, Lijun Wu', 'link': 'https://arxiv.org/abs/2506.21085', 'abstract': 'Molecular docking plays a crucial role in predicting the binding mode of ligands to target proteins, and covalent interactions, which involve the formation of a covalent bond between the ligand and the target, are particularly valuable due to their strong, enduring binding nature. However, most existing docking methods and deep learning approaches hardly account for the formation of covalent bonds and the associated structural changes. To address this gap, we introduce a comprehensive benchmark for covalent docking, CovDocker, which is designed to better capture the complexities of covalent binding. We decompose the covalent docking process into three main tasks: reactive location prediction, covalent reaction prediction, and covalent docking. By adapting state-of-the-art models, such as Uni-Mol and Chemformer, we establish baseline performances and demonstrate the effectiveness of the benchmark in accurately predicting interaction sites and modeling the molecular transformations involved in covalent binding. These results confirm the role of the benchmark as a rigorous framework for advancing research in covalent drug design. It underscores the potential of data-driven approaches to accelerate the discovery of selective covalent inhibitors and addresses critical challenges in therapeutic development.', 'abstract_zh': '共价对接在预测配体与靶蛋白结合模式中发挥着关键作用，共价相互作用因其强烈的持久性结合而尤为宝贵，但由于形成的共价键及其相关的结构变化，大多数现有的对接方法和深度学习方法很少考虑这些问题。为填补这一空白，我们介绍了一个全面的共价对接基准CovDocker，旨在更好地捕捉共价结合的复杂性。我们分解共价对接过程为三个主要任务：活性位点预测、共价反应预测和共价对接。通过采用最先进的模型如Uni-Mol和Chemformer，我们建立了基线性能，并展示了基准在准确预测相互作用位点和模拟共价结合过程中分子转变方面的有效性。这些结果确认了基准作为推动共价药物设计研究严格框架的作用。它强调了数据驱动方法在加速选择性共价抑制剂发现中的潜力，并解决了药物开发中的关键挑战。', 'title_zh': 'CovDocker: 基于任务、数据集和解决方案的共价药物设计基准测试'}
{'arxiv_id': 'arXiv:2506.21080', 'title': 'EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception', 'authors': 'Sanjoy Chowdhury, Subrata Biswas, Sayan Nag, Tushar Nagarajan, Calvin Murdock, Ishwarya Ananthabhotla, Yijun Qian, Vamsi Krishna Ithapu, Dinesh Manocha, Ruohan Gao', 'link': 'https://arxiv.org/abs/2506.21080', 'abstract': 'Modern perception models, particularly those designed for multisensory egocentric tasks, have achieved remarkable performance but often come with substantial computational costs. These high demands pose challenges for real-world deployment, especially in resource-constrained environments. In this paper, we introduce EgoAdapt, a framework that adaptively performs cross-modal distillation and policy learning to enable efficient inference across different egocentric perception tasks, including egocentric action recognition, active speaker localization, and behavior anticipation. Our proposed policy module is adaptable to task-specific action spaces, making it broadly applicable. Experimental results on three challenging egocentric datasets EPIC-Kitchens, EasyCom, and Aria Everyday Activities demonstrate that our method significantly enhances efficiency, reducing GMACs by up to 89.09%, parameters up to 82.02%, and energy up to 9.6x, while still on-par and in many cases outperforming, the performance of corresponding state-of-the-art models.', 'abstract_zh': '现代感知模型在多模态第一人称任务中取得了显著性能，但往往伴随着高昂的计算成本。这些高需求对实际部署构成了挑战，尤其是在资源受限的环境中。本文介绍了一种名为EgoAdapt的框架，该框架适应性地进行跨模态蒸馏和策略学习，以在不同的第一人称感知任务中实现高效的推理，包括第一人称动作识别、主动说话人定位和行为预测。我们提出的策略模块适用于特定任务的动作空间，使其具有广泛的适用性。在三个具有挑战性的一人称视角数据集中（EPIC-Kitchens、EasyCom和Aria Everyday Activities）的实验结果表明，我们的方法显著提高了效率，分别降低了89.09%的GMACs、82.02%的参数量和9.6倍的能耗，同时在许多情况下超过了对应的最佳模型的性能。', 'title_zh': 'EgoAdapt: 自适应多模态知识蒸馏与策略学习以实现高效的第一人称感知'}
{'arxiv_id': 'arXiv:2506.21049', 'title': 'A Semi-supervised Scalable Unified Framework for E-commerce Query Classification', 'authors': 'Chunyuan Yuan, Chong Zhang, Zheng Fang, Ming Pang, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law', 'link': 'https://arxiv.org/abs/2506.21049', 'abstract': "Query classification, including multiple subtasks such as intent and category prediction, is vital to e-commerce applications. E-commerce queries are usually short and lack context, and the information between labels cannot be used, resulting in insufficient prior information for modeling. Most existing industrial query classification methods rely on users' posterior click behavior to construct training samples, resulting in a Matthew vicious cycle. Furthermore, the subtasks of query classification lack a unified framework, leading to low efficiency for algorithm optimization.\nIn this paper, we propose a novel Semi-supervised Scalable Unified Framework (SSUF), containing multiple enhanced modules to unify the query classification tasks. The knowledge-enhanced module uses world knowledge to enhance query representations and solve the problem of insufficient query information. The label-enhanced module uses label semantics and semi-supervised signals to reduce the dependence on posterior labels. The structure-enhanced module enhances the label representation based on the complex label relations. Each module is highly pluggable, and input features can be added or removed as needed according to each subtask. We conduct extensive offline and online A/B experiments, and the results show that SSUF significantly outperforms the state-of-the-art models.", 'abstract_zh': '面向电子商务的半监督可扩展统一框架（SSUF）：增强模块化查询分类', 'title_zh': '半监督可扩展统一电商平台查询分类框架'}
{'arxiv_id': 'arXiv:2506.21045', 'title': 'Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling', 'authors': 'Hansam Cho, Seoung Bum Kim', 'link': 'https://arxiv.org/abs/2506.21045', 'abstract': 'Text-guided diffusion models have become essential for high-quality image synthesis, enabling dynamic image editing. In image editing, two crucial aspects are editability, which determines the extent of modification, and faithfulness, which reflects how well unaltered elements are preserved. However, achieving optimal results is challenging because of the inherent trade-off between editability and faithfulness. To address this, we propose Faithfulness Guidance and Scheduling (FGS), which enhances faithfulness with minimal impact on editability. FGS incorporates faithfulness guidance to strengthen the preservation of input image information and introduces a scheduling strategy to resolve misalignment between editability and faithfulness. Experimental results demonstrate that FGS achieves superior faithfulness while maintaining editability. Moreover, its compatibility with various editing methods enables precise, high-quality image edits across diverse tasks.', 'abstract_zh': '文本指导的保真度引导和调度（FGS）：在高保真图像合成中的动态图像编辑', 'title_zh': '基于指导和调度改进扩散模型驱动的图像编辑保真度'}
{'arxiv_id': 'arXiv:2506.21044', 'title': 'Efficient Skill Discovery via Regret-Aware Optimization', 'authors': 'He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong', 'link': 'https://arxiv.org/abs/2506.21044', 'abstract': 'Unsupervised skill discovery aims to learn diverse and distinguishable behaviors in open-ended reinforcement learning. For existing methods, they focus on improving diversity through pure exploration, mutual information optimization, and learning temporal representation. Despite that they perform well on exploration, they remain limited in terms of efficiency, especially for the high-dimensional situations. In this work, we frame skill discovery as a min-max game of skill generation and policy learning, proposing a regret-aware method on top of temporal representation learning that expands the discovered skill space along the direction of upgradable policy strength. The key insight behind the proposed method is that the skill discovery is adversarial to the policy learning, i.e., skills with weak strength should be further explored while less exploration for the skills with converged strength. As an implementation, we score the degree of strength convergence with regret, and guide the skill discovery with a learnable skill generator. To avoid degeneration, skill generation comes from an up-gradable population of skill generators. We conduct experiments on environments with varying complexities and dimension sizes. Empirical results show that our method outperforms baselines in both efficiency and diversity. Moreover, our method achieves a 15% zero shot improvement in high-dimensional environments, compared to existing methods.', 'abstract_zh': '无监督技能发现旨在在开放强化学习中学习多样且可区分的行为。现有方法侧重于通过纯粹探索、互信息优化以及学习时间表示来提升多样性。尽管这些方法在探索方面表现良好，但在效率方面仍然受限，尤其是在高维情况下。在本文中，我们将技能发现框定为技能生成和策略学习的最小最大博弈，并在此基础上提出了一种基于时间表示学习的方法，该方法沿着可升级策略强度的方向扩展发现的技能空间。提出方法的核心洞察是，技能发现与策略学习是对抗性的：即弱技能应进一步探索，而收敛技能则较少探索。作为实现，我们用遗憾分数衡量强度收敛的程度，并使用可学习的技能生成器引导技能发现。为了避免退化，技能生成来自于可升级的技能生成器群体。我们在不同复杂性和维度大小的环境中进行了实验。实验证明，我们的方法在效率和多样性方面均优于基线方法。此外，在高维环境中，我们的方法相比现有方法实现了15%的零样本改进。', 'title_zh': '基于后悔意识优化的高效技能发现'}
{'arxiv_id': 'arXiv:2506.21041', 'title': 'V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling', 'authors': 'Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran', 'link': 'https://arxiv.org/abs/2506.21041', 'abstract': 'Ensuring robust planning and decision-making under rare, diverse, and visually degraded long-tail scenarios remains a fundamental challenge for autonomous driving in urban environments. This issue becomes more critical in cooperative settings, where vehicles and infrastructure jointly perceive and reason across complex environments. To address this challenge, we propose V2X-REALM, a vision-language model (VLM)-based framework with adaptive multimodal learning for robust cooperative autonomous driving under long-tail scenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven long-tail scenario generation and evaluation pipeline that leverages foundation models to synthesize realistic long-tail conditions such as snow and fog across vehicle- and infrastructure-side views, enriching training diversity efficiently; (ii) a gated multi-scenario adaptive attention module that modulates the visual stream using scenario priors to recalibrate ambiguous or corrupted features; and (iii) a multi-task scenario-aware contrastive learning objective that improves multimodal alignment and promotes cross-scenario feature separability. Extensive experiments demonstrate that V2X-REALM significantly outperforms existing baselines in robustness, semantic reasoning, safety, and planning accuracy under complex, challenging driving conditions, advancing the scalability of end-to-end cooperative autonomous driving.', 'abstract_zh': '确保在罕见、多样且视觉退化的长尾场景下实现稳健的规划与决策是城市环境中自动驾驶面临的基本挑战。在协同场景中，这一问题尤为重要，因为车辆和基础设施需要共同感知和推理复杂环境。为应对这一挑战，我们提出了一种基于视觉语言模型（VLM）且具备自适应多模态学习的框架V2X-REALM，以在长尾场景下实现稳健的协同自动驾驶。V2X-REALM 包含三项核心创新：（i）一种基于提示驱动的长尾场景生成和评估流水线，利用基础模型合成如雪和雾等真实的长尾条件，有效丰富训练多样性；（ii）一种门控多场景自适应注意力模块，利用场景先验调节视觉流，重新校准不确定或损坏的特征；（iii）一种多任务场景感知对比学习目标，提高多模态对齐并促进跨场景特征可分离性。大量实验结果表明，V2X-REALM 在复杂且具有挑战性的驾驶条件下，在稳健性、语义推理、安全性和规划准确性方面显著优于现有基线，推动了端到端协同自动驾驶的可扩展性。', 'title_zh': 'V2X-REALM：基于视觉-语言模型的鲁棒端到端协同自动驾驶及自适应长尾建模'}
{'arxiv_id': 'arXiv:2506.21039', 'title': 'Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning', 'authors': 'Jaebak Hwang, Sanghyeon Lee, Jeongmo Kim, Seungyul Han', 'link': 'https://arxiv.org/abs/2506.21039', 'abstract': 'Long-horizon goal-conditioned tasks pose fundamental challenges for reinforcement learning (RL), particularly when goals are distant and rewards are sparse. While hierarchical and graph-based methods offer partial solutions, they often suffer from subgoal infeasibility and inefficient planning. We introduce Strict Subgoal Execution (SSE), a graph-based hierarchical RL framework that enforces single-step subgoal reachability by structurally constraining high-level decision-making. To enhance exploration, SSE employs a decoupled exploration policy that systematically traverses underexplored regions of the goal space. Furthermore, a failure-aware path refinement, which refines graph-based planning by dynamically adjusting edge costs according to observed low-level success rates, thereby improving subgoal reliability. Experimental results across diverse long-horizon benchmarks demonstrate that SSE consistently outperforms existing goal-conditioned RL and hierarchical RL approaches in both efficiency and success rate.', 'abstract_zh': '长时间目标条件任务对强化学习（RL）提出了根本性的挑战，特别是在目标遥远和奖励稀疏的情况下。我们引入了严格子目标执行（SSE），这是一种基于图的层次化RL框架，通过结构上约束高层决策来确保单步子目标可达性。为了增强探索，SSE 使用了一个解耦的探索策略，系统地探索目标空间中的未充分探索区域。此外，SSE 还采用了一种失败自意识路径优化策略，该策略根据观测到的低层成功率动态调整边的成本，从而提高子目标的可靠性。在多种长时间目标条件基准测试中的实验结果表明，SSE 在效率和成功率方面均显著优于现有的目标条件RL和层次化RL方法。', 'title_zh': '严格的子目标执行：层级强化学习中可靠长时规划'}
{'arxiv_id': 'arXiv:2506.21031', 'title': 'Large Language Models Acing Chartered Accountancy', 'authors': 'Jatin Gupta, Akhil Sharma, Saransh Singhania, Mohammad Adnan, Sakshi Deo, Ali Imam Abidi, Keshav Gupta', 'link': 'https://arxiv.org/abs/2506.21031', 'abstract': 'Advanced intelligent systems, particularly Large Language Models (LLMs), are significantly reshaping financial practices through advancements in Natural Language Processing (NLP). However, the extent to which these models effectively capture and apply domain-specific financial knowledge remains uncertain. Addressing a critical gap in the expansive Indian financial context, this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically designed to evaluate the financial, legal, and quantitative reasoning capabilities of LLMs. CA-Ben comprises structured question-answer datasets derived from the rigorous examinations conducted by the Institute of Chartered Accountants of India (ICAI), spanning foundational, intermediate, and advanced CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated using standardized protocols. Results indicate variations in performance, with Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and legal reasoning. Notable challenges emerged in numerical computations and legal interpretations. The findings emphasize the strengths and limitations of current LLMs, suggesting future improvements through hybrid reasoning and retrieval-augmented generation methods, particularly for quantitative analysis and accurate legal interpretation.', 'abstract_zh': '高级智能系统，特别是大规模语言模型（LLMs），通过自然语言处理（NLP）的进步正在显著重塑金融实践。然而，这些模型在有效地捕捉和应用特定领域金融知识方面的程度仍然不确定。填补广阔的印度金融背景中的一个关键空白，本文引入了CA-Ben，一个专门用于评估LLMs的财务、法律和定量推理能力的特许会计师基准。CA-Ben包括源自印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖特许会计师课程的基础、中级和高级阶段。六种知名的LLMs，即GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet 和 Microsoft Phi 4，使用标准化流程进行了评估。结果显示性能存在差异，Claude 3.5 Sonnet 和 GPT-4o 在概念性和法律推理方面表现突出。在数值计算和法律解释方面出现了显著挑战。研究结果强调了当前LLMs的优势和局限性，建议通过混合推理和检索增强生成方法在未来进行改进，特别是在定量分析和准确法律解释方面。', 'title_zh': '大型语言模型在专业会计师考试中的表现'}
{'arxiv_id': 'arXiv:2506.21017', 'title': 'Multimodal Prompt Alignment for Facial Expression Recognition', 'authors': 'Fuyan Ma, Yiran He, Bin Sun, Shutao Li', 'link': 'https://arxiv.org/abs/2506.21017', 'abstract': 'Prompt learning has been widely adopted to efficiently adapt vision-language models (VLMs) like CLIP for various downstream tasks. Despite their success, current VLM-based facial expression recognition (FER) methods struggle to capture fine-grained textual-visual relationships, which are essential for distinguishing subtle differences between facial expressions. To address this challenge, we propose a multimodal prompt alignment framework for FER, called MPA-FER, that provides fine-grained semantic guidance to the learning process of prompted visual features, resulting in more precise and interpretable representations. Specifically, we introduce a multi-granularity hard prompt generation strategy that utilizes a large language model (LLM) like ChatGPT to generate detailed descriptions for each facial expression. The LLM-based external knowledge is injected into the soft prompts by minimizing the feature discrepancy between the soft prompts and the hard prompts. To preserve the generalization abilities of the pretrained CLIP model, our approach incorporates prototype-guided visual feature alignment, ensuring that the prompted visual features from the frozen image encoder align closely with class-specific prototypes. Additionally, we propose a cross-modal global-local alignment module that focuses on expression-relevant facial features, further improving the alignment between textual and visual features. Extensive experiments demonstrate our framework outperforms state-of-the-art methods on three FER benchmark datasets, while retaining the benefits of the pretrained model and minimizing computational costs.', 'abstract_zh': '基于多模态提示对齐的面部表情识别框架(MPA-FER)', 'title_zh': '多模态提示对齐在面部表情识别中的应用'}
{'arxiv_id': 'arXiv:2506.20993', 'title': 'SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control', 'authors': 'Adithya Chittem, Aishna Shrivastava, Sai Tarun Pendela, Jagat Sesh Challa, Dhruv Kumar', 'link': 'https://arxiv.org/abs/2506.20993', 'abstract': 'Large language models (LLMs) have gained significant traction across a wide range of fields in recent years. There is also a growing expectation for them to display human-like personalities during interactions. To meet this expectation, numerous studies have proposed methods for modelling LLM personalities through psychometric evaluations. However, most existing models face two major limitations: they rely on the Big Five (OCEAN) framework, which only provides coarse personality dimensions, and they lack mechanisms for controlling trait intensity. In this paper, we address this gap by extending the Machine Personality Inventory (MPI), which originally used the Big Five model, to incorporate the 16 Personality Factor (16PF) model, allowing expressive control over sixteen distinct traits. We also developed a structured framework known as Specific Attribute Control (SAC) for evaluating and dynamically inducing trait intensity in LLMs. Our method introduces adjective-based semantic anchoring to guide trait intensity expression and leverages behavioural questions across five intensity factors: \\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and \\textit{Willingness}. Through experimentation, we find that modelling intensity as a continuous spectrum yields substantially more consistent and controllable personality expression compared to binary trait toggling. Moreover, we observe that changes in target trait intensity systematically influence closely related traits in psychologically coherent directions, suggesting that LLMs internalize multi-dimensional personality structures rather than treating traits in isolation. Our work opens new pathways for controlled and nuanced human-machine interactions in domains such as healthcare, education, and interviewing processes, bringing us one step closer to truly human-like social machines.', 'abstract_zh': '大型语言模型（LLMs）在多个领域中获得了显著的关注，人们对它们在交互中展示类人类个性寄予了越来越高的期望。为了满足这一期望，许多研究提出了通过心理测评建模LLMs个性的方法。然而，现有大多数模型面临两大局限：依赖于大五人格（OCEAN）模型，只能提供粗略的个性维度，且缺乏调控特质强度的机制。本文通过将原始使用大五人格模型的机器个性量表（MPI）扩展至整合16人格因素（16PF）模型，填补了这一空白，从而实现了对十六种不同特质的表达性控制。我们还开发了一个结构化的框架，名为特定属性控制（SAC），用于评估和动态诱导LLMs的特质强度。该方法通过形容词基础的语义锚定来引导特质强度的表达，并利用五个强度因素（Frequency、Depth、Threshold、Effort、Willingness）的行为性问题进行衡量。通过实验发现，将特质强度建模为连续谱系能显著提高个性表达的连贯性和可控性，相较于二元特质切换方法。此外，我们观察到目标特质强度的变化系统地影响了其他相关特质，并在心理连贯的方向上产生了调节，表明LLMs具备多维度的个性结构而非孤立地对待特质。我们的工作为医疗、教育和面试等领域中受控和细致的人机交互开辟了新的路径，使我们更接近于真正的类人类社会机器人。', 'title_zh': 'SAC：一种动态强度控制的测量和诱导LLMs人格特质的框架'}
{'arxiv_id': 'arXiv:2506.20988', 'title': 'Segment Anything in Pathology Images with Natural Language', 'authors': 'Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan, Hao Chen', 'link': 'https://arxiv.org/abs/2506.20988', 'abstract': "Pathology image segmentation is crucial in computational pathology for analyzing histological features relevant to cancer diagnosis and prognosis. However, current methods face major challenges in clinical applications due to limited annotated data and restricted category definitions. To address these limitations, we propose PathSegmentor, the first text-prompted segmentation foundation model designed specifically for pathology images. We also introduce PathSeg , the largest and most comprehensive dataset for pathology segmentation, built from 17 public sources and containing 275k image-mask-label triples across 160 diverse categories. With PathSegmentor, users can perform semantic segmentation using natural language prompts, eliminating the need for laborious spatial inputs such as points or boxes. Extensive experiments demonstrate that PathSegmentor outperforms specialized models with higher accuracy and broader applicability, while maintaining a compact architecture. It significantly surpasses existing spatial- and text-prompted models by 0.145 and 0.429 in overall Dice scores, respectively, showing strong robustness in segmenting complex structures and generalizing to external datasets. Moreover, PathSegmentor's outputs enhance the interpretability of diagnostic models through feature importance estimation and imaging biomarker discovery, offering pathologists evidence-based support for clinical decision-making. This work advances the development of explainable AI in precision oncology.", 'abstract_zh': '病理图像分割是计算病理学中分析与癌症诊断和预后相关的组织学特征的关键。然而，现有方法在临床应用中面临重大挑战，主要原因在于标注数据有限和类别定义受限。为解决这些局限性，我们提出PathSegmentor，这是首款专门为病理图像设计的文字引导分割基础模型。我们还引入了PathSeg，这是最大的最全面的病理分割数据集，包含来自17个公开数据源的275,000个图像-掩模-标签三元组，涵盖了160个不同类别。借助PathSegmentor，用户可以通过自然语言提示进行语义分割，从而消除了需要繁琐的空间输入（如点或框）的需要。广泛实验表明，PathSegmentor在准确性和适用性方面优于专门模型，同时保持紧凑的架构。它在总体交集数量Dice分数上分别比现有的空间提示和文字提示模型高出0.145和0.429，显示出在分割复杂结构和泛化到外部数据集上的强大鲁棒性。PathSegmentor的输出通过特征重要性估计和成像生物标志物发现增强了解释性诊断模型的可解释性，为病理学家提供了基于证据的临床决策支持。这项工作促进了精准肿瘤学中可解释AI的发展。', 'title_zh': '使用自然语言在病理图像中分割 Anything'}
{'arxiv_id': 'arXiv:2506.20980', 'title': 'Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs', 'authors': 'Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu', 'link': 'https://arxiv.org/abs/2506.20980', 'abstract': 'Real-world networks usually have a property of node heterophily, that is, the connected nodes usually have different features or different labels. This heterophily issue has been extensively studied in homogeneous graphs but remains under-explored in heterogeneous graphs, where there are multiple types of nodes and edges. Capturing node heterophily in heterogeneous graphs is very challenging since both node/edge heterogeneity and node heterophily should be carefully taken into consideration. Existing methods typically convert heterogeneous graphs into homogeneous ones to learn node heterophily, which will inevitably lose the potential heterophily conveyed by heterogeneous relations. To bridge this gap, we propose Relation-Aware Separation of Homophily and Heterophily (RASH), a novel contrastive learning framework that explicitly models high-order semantics of heterogeneous interactions and adaptively separates homophilic and heterophilic patterns. Particularly, RASH introduces dual heterogeneous hypergraphs to encode multi-relational bipartite subgraphs and dynamically constructs homophilic graphs and heterophilic graphs based on relation importance. A multi-relation contrastive loss is designed to align heterogeneous and homophilic/heterophilic views by maximizing mutual information. In this way, RASH simultaneously resolves the challenges of heterogeneity and heterophily in heterogeneous graphs. Extensive experiments on benchmark datasets demonstrate the effectiveness of RASH across various downstream tasks. The code is available at: this https URL.', 'abstract_zh': '基于关系的同质性和异质性分离框架：异质图中节点异质性建模与学习（Relation-Aware Separation of Homophily and Heterophily for Modeling Node Heterophily in Heterogeneous Graphs）', 'title_zh': '增强同ophil性和异ophil性分离：异质图中的关系感知学习'}
{'arxiv_id': 'arXiv:2506.20977', 'title': 'From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging', 'authors': 'Tao Liu, Dafeng Zhang, Gengchen Li, Shizhuo Liu, Yongqi Song, Senmao Li, Shiqi Yang, Boqian Li, Kai Wang, Yaxing Wang', 'link': 'https://arxiv.org/abs/2506.20977', 'abstract': 'Face aging has become a crucial task in computer vision, with applications ranging from entertainment to healthcare. However, existing methods struggle with achieving a realistic and seamless transformation across the entire lifespan, especially when handling large age gaps or extreme head poses. The core challenge lies in balancing age accuracy and identity preservation--what we refer to as the Age-ID trade-off. Most prior methods either prioritize age transformation at the expense of identity consistency or vice versa. In this work, we address this issue by proposing a two-pass face aging framework, named Cradle2Cane, based on few-step text-to-image (T2I) diffusion models. The first pass focuses on solving age accuracy by introducing an adaptive noise injection (AdaNI) mechanism. This mechanism is guided by including prompt descriptions of age and gender for the given person as the textual condition. Also, by adjusting the noise level, we can control the strength of aging while allowing more flexibility in transforming the face. However, identity preservation is weakly ensured here to facilitate stronger age transformations. In the second pass, we enhance identity preservation while maintaining age-specific features by conditioning the model on two identity-aware embeddings (IDEmb): SVR-ArcFace and Rotate-CLIP. This pass allows for denoising the transformed image from the first pass, ensuring stronger identity preservation without compromising the aging accuracy. Both passes are jointly trained in an end-to-end way. Extensive experiments on the CelebA-HQ test dataset, evaluated through Face++ and Qwen-VL protocols, show that our Cradle2Cane outperforms existing face aging methods in age accuracy and identity consistency.', 'abstract_zh': '基于少步文本到图像扩散模型的Cradle2Cane两阶段人脸老化框架', 'title_zh': '从婴儿到拐杖：一种高保真生命周期面部老化两步框架'}
{'arxiv_id': 'arXiv:2506.20967', 'title': 'DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing', 'authors': 'Lingling Cai, Kang Zhao, Hangjie Yuan, Xiang Wang, Yingya Zhang, Kejie Huang', 'link': 'https://arxiv.org/abs/2506.20967', 'abstract': 'The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85\\% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.', 'abstract_zh': '基于Video DiTs的高效零样本视频编辑方法', 'title_zh': 'DFVEdit: 条件增量流向量在零样本视频编辑中的应用'}
{'arxiv_id': 'arXiv:2506.20966', 'title': 'Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends', 'authors': 'Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou', 'link': 'https://arxiv.org/abs/2506.20966', 'abstract': "Vision-language-action (VLA) models extend vision-language models (VLM) by integrating action generation modules for robotic manipulation. Leveraging strengths of VLM in vision perception and instruction understanding, VLA models exhibit promising generalization across diverse manipulation tasks. However, applications demanding high precision and accuracy reveal performance gaps without further adaptation. Evidence from multiple domains highlights the critical role of post-training to align foundational models with downstream applications, spurring extensive research on post-training VLA models. VLA model post-training aims to address the challenge of improving an embodiment's ability to interact with the environment for the given tasks, analogous to the process of humans motor skills acquisition. Accordingly, this paper reviews post-training strategies for VLA models through the lens of human motor learning, focusing on three dimensions: environments, embodiments, and tasks. A structured taxonomy is introduced aligned with human learning mechanisms: (1) enhancing environmental perception, (2) improving embodiment awareness, (3) deepening task comprehension, and (4) multi-component integration. Finally, key challenges and trends in post-training VLA models are identified, establishing a conceptual framework to guide future research. This work delivers both a comprehensive overview of current VLA model post-training methods from a human motor learning perspective and practical insights for VLA model development. (Project website: this https URL)", 'abstract_zh': 'Vision-语言-行动（VLA）模型通过集成动作生成模块扩展了视觉-语言模型（VLM），以实现机器人的操作 manipulation。利用VLM在视觉感知和指令理解方面的优势，VLA模型在不同类型的操作任务中展现出良好的泛化能力。然而，对于要求高精度和高准确性的应用场景，表明需要进一步适应才能提高性能。跨多个领域的实验证据强调了后训练对调整基础模型以匹配下游应用的重要性，推动了对后训练VLA模型的广泛研究。VLA模型的后训练旨在通过改进实体与给定任务环境的互动能力来应对挑战，类似于人类运动技能的习得过程。本文从人类运动学习的角度回顾了VLA模型的后训练策略，重点关注三个维度：环境、实体和任务，并介绍了与人类学习机制相一致的结构化分类：1）增强环境感知，2）提高实体意识，3）深化任务理解，4）多组件集成。最后，本文指出了后训练VLA模型的关键挑战和趋势，为未来的研究提供了概念框架。这项工作不仅提供了从人类运动学习视角对当前VLA模型后训练方法的全面回顾，还为VLA模型开发提供了实用见解。（项目网站：this https URL）', 'title_zh': 'VLA模型后训练与人类运动学习之间的 parallel：进展、挑战与趋势'}
{'arxiv_id': 'arXiv:2506.20964', 'title': 'Evidence-based diagnostic reasoning with multi-agent copilot for human pathology', 'authors': 'Chengkuan Chen, Luca L. Weishaupt, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Bowen Chen, Anurag Vaidya, Long Phi Le, Guillaume Jaume, Ming Y. Lu, Faisal Mahmood', 'link': 'https://arxiv.org/abs/2506.20964', 'abstract': 'Pathology is experiencing rapid digital transformation driven by whole-slide imaging and artificial intelligence (AI). While deep learning-based computational pathology has achieved notable success, traditional models primarily focus on image analysis without integrating natural language instruction or rich, text-based context. Current multimodal large language models (MLLMs) in computational pathology face limitations, including insufficient training data, inadequate support and evaluation for multi-image understanding, and a lack of autonomous, diagnostic reasoning capabilities. To address these limitations, we introduce PathChat+, a new MLLM specifically designed for human pathology, trained on over 1 million diverse, pathology-specific instruction samples and nearly 5.5 million question answer turns. Extensive evaluations across diverse pathology benchmarks demonstrated that PathChat+ substantially outperforms the prior PathChat copilot, as well as both state-of-the-art (SOTA) general-purpose and other pathology-specific models. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI system leveraging PathChat+ to autonomously evaluate gigapixel whole-slide images (WSIs) through iterative, hierarchical diagnostic reasoning, reaching high accuracy on DDxBench, a challenging open-ended differential diagnosis benchmark, while also capable of generating visually grounded, humanly-interpretable summary reports.', 'abstract_zh': '病理学正经历由全视野显微成像和人工智能（AI）驱动的快速数字化转型。虽然基于深度学习的计算病理学取得了显著成就，但传统模型主要侧重于图像分析，未整合自然语言指令或丰富文本背景信息。当前计算病理学中的多模态大型语言模型（MLLMs）面临局限性，包括训练数据不足、对多图像理解的支持和评估不足，以及缺乏自主诊断推理能力。为解决这些局限性，我们提出PathChat+这一专门设计用于人类病理学的新MMLM，其基于超过100万份多元且病理特异性的指令样本及近550万轮问题-答案交互训练。在多种病理基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat副驾模型，同时也优于最先进的通用和特定于病理学的其他模型。此外，我们介绍SlideSeek，一种利用PathChat+实现自主诊断推理的多智能体AI系统，能够通过迭代分层诊断推理自主评估 gigapixel 全视野显微图像（WSIs），在具有挑战性的开放性鉴别诊断基准 DDxBench 上达到高准确率，同时还能生成基于视觉、可由人类解释的总结报告。', 'title_zh': '基于证据的多代理伴飞诊断推理在人类病理学中的应用'}
{'arxiv_id': 'arXiv:2506.20960', 'title': 'OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs', 'authors': 'Yiman Zhang, Ziheng Luo, Qiangyu Yan, Wei He, Borui Jiang, Xinghao Chen, Kai Han', 'link': 'https://arxiv.org/abs/2506.20960', 'abstract': 'In this paper, we introduce OmniEval, a benchmark for evaluating omni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory, and textual inputs. Compared with existing benchmarks, our OmniEval has several distinctive features: (i) Full-modal collaboration: We design evaluation tasks that highlight the strong coupling between audio and video, requiring models to effectively leverage the collaborative perception of all modalities; (ii) Diversity of videos: OmniEval includes 810 audio-visual synchronized videos, 285 Chinese videos and 525 English videos; (iii) Diversity and granularity of tasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended questions and 1205 multiple-choice questions. These questions are divided into 3 major task types and 12 sub-task types to achieve comprehensive evaluation. Among them, we introduce a more granular video localization task named Grounding. Then we conduct experiments on OmniEval with several omni-modality models. We hope that our OmniEval can provide a platform for evaluating the ability to construct and understand coherence from the context of all modalities. Codes and data could be found at this https URL.', 'abstract_zh': '本研究介绍了一种名为OmniEval的基准测试，用于评估如MiniCPM-O 2.6等全模态模型，涵盖了视觉、听觉和文本输入。与现有基准相比，我们的OmniEval具有以下几个distinctive特征：（i）全模态协作：设计评估任务以突出音频和视频之间的强大耦合，要求模型有效地利用所有模态的协作感知；（ii）多样的视频：OmniEval包括810个音频-视觉同步视频、285个中文视频和525个英语视频；（iii）多样性和细粒度的任务：OmniEval包含2617个问答对，其中包括1412个开放型问题和1205个多选题。这些问题被分为3大类任务和12个小类任务，以实现全面评估。其中，我们引入了一个更细粒度的视频定位任务，名为Grounding。然后在OmniEval上对若干全模态模型进行了实验。我们希望OmniEval能够提供一个平台，以评估在所有模态上下文中构建和理解连贯性的能力。代码和数据可在以下链接找到：this https URL。', 'title_zh': '全模态评估：一种基于视觉、听觉和文本输入的模态模型评价基准'}
{'arxiv_id': 'arXiv:2506.20957', 'title': 'Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding', 'authors': 'Jiameng Chen, Xiantao Cai, Jia Wu, Wenbin Hu', 'link': 'https://arxiv.org/abs/2506.20957', 'abstract': "Antibody design remains a critical challenge in therapeutic and diagnostic development, particularly for complex antigens with diverse binding interfaces. Current computational methods face two main limitations: (1) capturing geometric features while preserving symmetries, and (2) generalizing novel antigen interfaces. Despite recent advancements, these methods often fail to accurately capture molecular interactions and maintain structural integrity. To address these challenges, we propose \\textbf{AbMEGD}, an end-to-end framework integrating \\textbf{M}ulti-scale \\textbf{E}quivariant \\textbf{G}raph \\textbf{D}iffusion for antibody sequence and structure co-design. Leveraging advanced geometric deep learning, AbMEGD combines atomic-level geometric features with residue-level embeddings, capturing local atomic details and global sequence-structure interactions. Its E(3)-equivariant diffusion method ensures geometric precision, computational efficiency, and robust generalizability for complex antigens. Furthermore, experiments using the SAbDab database demonstrate a 10.13\\% increase in amino acid recovery, 3.32\\% rise in improvement percentage, and a 0.062~Å reduction in root mean square deviation within the critical CDR-H3 region compared to DiffAb, a leading antibody design model. These results highlight AbMEGD's ability to balance structural integrity with improved functionality, establishing a new benchmark for sequence-structure co-design and affinity optimization. The code is available at: this https URL.", 'abstract_zh': '抗体设计仍然是治疗和诊断开发中的一个关键挑战，特别是对于具有多样结合界面的复杂抗原。当前的计算方法面临两大主要限制：（1）在保留对称性的同时捕捉几何特征，（2）泛化新型抗原界面。尽管近期取得了一些进展，但这些方法往往无法准确捕捉分子相互作用并保持结构完整性。为应对这些挑战，我们提出了一种名为**AbMEGD**的端到端框架，该框架集成了**多尺度共变图形扩散**用于抗体序列和结构的协同设计。利用先进的几何深度学习，AbMEGD 结合了原子级几何特征与残基级嵌入，捕捉局部原子细节和全局序列-结构交互作用。其 E(3)-共变扩散方法确保了几何精度、计算效率和对复杂抗原的鲁棒泛化能力。此外，使用 SAbDab 数据库的实验结果表明，与领先抗体设计模型 DiffAb 相比，AbMEGD 在氨基酸回收率上提高了 10.13%，改进百分比提升了 3.32%，并在关键 CDR-H3 区域的均方根偏差上减少了 0.062 Å。这些结果突显了 AbMEGD 在平衡结构完整性和提高功能方面的能力，建立了序列-结构协同设计和亲和力优化的新基准。代码可从此链接获取：this <https://example.com> URL。', 'title_zh': '基于多尺度等变图扩散模型的抗体设计与优化以实现精准复杂抗原结合'}
{'arxiv_id': 'arXiv:2506.20946', 'title': 'Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models', 'authors': 'Donggoo Kang, Jangyeong Kim, Dasol Jeong, Junyoung Choi, Jeonga Wi, Hyunmin Lee, Joonho Gwon, Joonki Paik', 'link': 'https://arxiv.org/abs/2506.20946', 'abstract': 'Current texture synthesis methods, which generate textures from fixed viewpoints, suffer from inconsistencies due to the lack of global context and geometric understanding. Meanwhile, recent advancements in video generation models have demonstrated remarkable success in achieving temporally consistent videos. In this paper, we introduce VideoTex, a novel framework for seamless texture synthesis that leverages video generation models to address both spatial and temporal inconsistencies in 3D textures. Our approach incorporates geometry-aware conditions, enabling precise utilization of 3D mesh structures. Additionally, we propose a structure-wise UV diffusion strategy, which enhances the generation of occluded areas by preserving semantic information, resulting in smoother and more coherent textures. VideoTex not only achieves smoother transitions across UV boundaries but also ensures high-quality, temporally stable textures across video frames. Extensive experiments demonstrate that VideoTex outperforms existing methods in texture fidelity, seam blending, and stability, paving the way for dynamic real-time applications that demand both visual quality and temporal coherence.', 'abstract_zh': '基于视频生成的无缝纹理合成框架', 'title_zh': '基于几何感知扩散和时序视频模型的一致零样本3D纹理合成'}
{'arxiv_id': 'arXiv:2506.20927', 'title': 'Interpretable Representation Learning for Additive Rule Ensembles', 'authors': 'Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley', 'link': 'https://arxiv.org/abs/2506.20927', 'abstract': 'Small additive ensembles of symbolic rules offer interpretable prediction models. Traditionally, these ensembles use rule conditions based on conjunctions of simple threshold propositions $x \\geq t$ on a single input variable $x$ and threshold $t$, resulting geometrically in axis-parallel polytopes as decision regions. While this form ensures a high degree of interpretability for individual rules and can be learned efficiently using the gradient boosting approach, it relies on having access to a curated set of expressive and ideally independent input features so that a small ensemble of axis-parallel regions can describe the target variable well. Absent such features, reaching sufficient accuracy requires increasing the number and complexity of individual rules, which diminishes the interpretability of the model. Here, we extend classical rule ensembles by introducing logical propositions with learnable sparse linear transformations of input variables, i.e., propositions of the form $\\mathbf{x}^\\mathrm{T}\\mathbf{w} \\geq t$, where $\\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as general polytopes with oblique faces. We propose a learning method using sequential greedy optimization based on an iteratively reweighted formulation of logistic regression. Experimental results demonstrate that the proposed method efficiently constructs rule ensembles with the same test risk as state-of-the-art methods while significantly reducing model complexity across ten benchmark datasets.', 'abstract_zh': '符号规则的小加性集合提供可解释的预测模型。传统上，这些集合基于单个输入变量$x$和阈值$t$的简单阈值命题$x \\geq t$的共轭形式，几何上表现为轴平行多面体作为决策区域。虽然这种形式确保了单个规则的高度可解释性，并可通过梯度提升方法高效学习，但它依赖于能够访问表达且理想独立的输入特征集，以便用少量轴平行区域描述目标变量。缺乏此类特征的情况下，达到足够准确度需要增加个体规则的数量和复杂性，这会降低模型的可解释性。在这里，我们通过引入具有可学习的稀疏线性变换的输入变量的逻辑命题，扩展了经典的规则集合，即形式为$\\mathbf{x}^\\mathrm{T}\\mathbf{w} \\geq t$的命题，其中$\\mathbf{w}$是可学习的稀疏权重向量，允许决策区域为具有斜边面的一般多面体。我们提出了一种基于迭代加权的逻辑回归迭代格式的学习方法。实验结果表明，所提出的方法能够高效地构建与当今最佳方法具有相同测试风险的规则集合，同时显著降低模型复杂性，这一效果在十个基准数据集上得到验证。', 'title_zh': '可解释的表示学习在加性规则集中的应用'}
{'arxiv_id': 'arXiv:2506.20921', 'title': 'LLM-guided Chemical Process Optimization with a Multi-Agent Approach', 'authors': 'Tong Zeng, Srivathsan Badrinarayanan, Janghoon Ock, Cheng-Kai Lai, Amir Barati Farimani', 'link': 'https://arxiv.org/abs/2506.20921', 'abstract': "Chemical process optimization is crucial to maximize production efficiency and economic performance. Traditional methods, including gradient-based solvers, evolutionary algorithms, and parameter grid searches, become impractical when operating constraints are ill-defined or unavailable, requiring engineers to rely on subjective heuristics to estimate feasible parameter ranges. To address this constraint definition bottleneck, we present a multi-agent framework of large language model (LLM) agents that autonomously infer operating constraints from minimal process descriptions, then collaboratively guide optimization using the inferred constraints. Our AutoGen-based agentic framework employs OpenAI's o3 model, with specialized agents for constraint generation, parameter validation, simulation execution, and optimization guidance. Through two phases - autonomous constraint generation using embedded domain knowledge, followed by iterative multi-agent optimization - the framework eliminates the need for predefined operational bounds. Validated on the hydrodealkylation process across cost, yield, and yield-to-cost ratio metrics, the framework demonstrated competitive performance with conventional optimization methods while achieving better computational efficiency, requiring fewer iterations to converge. Our approach converged in under 20 minutes, achieving a 31-fold speedup over grid search. Beyond computational efficiency, the framework's reasoning-guided search demonstrates sophisticated process understanding, correctly identifying utility trade-offs, and applying domain-informed heuristics. This approach shows significant potential for optimization scenarios where operational constraints are poorly characterized or unavailable, particularly for emerging processes and retrofit applications.", 'abstract_zh': '化学过程优化是最大化生产效率和经济效益的关键。为了克服操作约束定义不明确或不可用的瓶颈，我们提出了一种基于多代理框架的大型语言模型（LLM）代理体系，该框架能够自动从最小的过程描述中推断出操作约束，并在此基础上协作指导优化。基于AutoGen的代理框架使用OpenAI的o3模型，具有专门用于约束生成、参数验证、仿真执行和优化指导的代理。通过两个阶段——利用嵌入的领域知识自主生成约束，随后进行迭代的多代理优化——该框架消除了预先定义的操作界限的需求。该框架在成本、产率和产率-成本比等指标上验证了与传统优化方法具有竞争力的性能，并且具有更好的计算效率，所需的迭代次数更少以达到收敛。我们的方法在不到20分钟内收敛，比网格搜索快了31倍。除了计算效率之外，该框架的推理引导搜索展示了复杂的工艺理解能力，能够正确识别能量贸易平衡，并应用基于领域的启发式方法。该方法对于操作约束描述不足或不可用的优化场景具有显著潜力，特别适用于新兴工艺和改造应用。', 'title_zh': '使用多Agent方法的LLM引导化学过程优化'}
{'arxiv_id': 'arXiv:2506.20917', 'title': 'Optimising Language Models for Downstream Tasks: A Post-Training Perspective', 'authors': 'Zhengyan Shi', 'link': 'https://arxiv.org/abs/2506.20917', 'abstract': 'Language models (LMs) have demonstrated remarkable capabilities in NLP, yet adapting them efficiently and robustly to specific tasks remains challenging. As their scale and complexity grow, fine-tuning LMs on labelled data often underutilizes available unlabelled data, leads to overfitting on small task-specific sets, and imposes significant computational costs. These limitations hamper their application to the open-ended landscape of real-world language tasks.\nThis thesis proposes a series of methods to better adapt LMs to downstream applications. First, we explore strategies for extracting task-relevant knowledge from unlabelled data, introducing a novel continued pre-training technique that outperforms state-of-the-art semi-supervised approaches. Next, we present a parameter-efficient fine-tuning method that substantially reduces memory and compute costs while maintaining competitive performance. We also introduce improved supervised fine-tuning methods that enable LMs to better follow instructions, especially when labelled data is scarce, enhancing their performance across a range of NLP tasks, including open-ended generation. Finally, we develop new evaluation methods and benchmarks, such as multi-hop spatial reasoning tasks, to assess LM capabilities and adaptation more comprehensively.\nThrough extensive empirical studies across diverse NLP tasks, our results demonstrate that these approaches substantially improve LM robustness, efficiency, and generalization, making them more adaptable to a broad range of applications. These advances mark a significant step towards more robust and efficient LMs, bringing us closer to the goal of artificial general intelligence.', 'abstract_zh': '语言模型（LMs）在自然语言处理（NLP）中展现了卓越的能力，但如何高效且稳健地将其适应到特定任务仍然具有挑战性。随着它们规模和复杂性的增加，在标注数据上微调LMs往往未能充分利用可用的未标注数据、在小规模任务特定集上容易过拟合，并且会产生重大的计算成本。这些限制阻碍了其在现实世界语言任务开放场景中的应用。\n\n本论文提出了一系列方法以更好地将LMs适配到下游应用。首先，我们探索从未标注数据中提取与任务相关知识的策略，引入了一种新型的连续预训练技术，该技术在半监督方法中表现出色。接着，我们提出了一种参数效率更高的微调方法，该方法大幅减少了内存和计算成本，同时保持了竞争力的性能。我们还介绍了改进的监督微调方法，使LMs能够更好地遵循指令，尤其是在标注数据稀缺的情况下，提高了其在各种NLP任务中的性能，包括开放生成。最后，我们开发了新的评估方法和基准测试，如多跳空间推理任务，以更全面地评估LM的能力和适应性。\n\n通过在多样化的NLP任务上进行广泛的实证研究，我们的结果表明，这些方法显著提升了LMs的稳健性、效率和泛化能力，使其能够更好地适应更广泛的用途。这些进展标志着向更稳健和高效的LMs迈进的重要一步，使我们更接近人工通用智能的目标。', 'title_zh': '优化语言模型以适应下游任务：一种后训练视角'}
{'arxiv_id': 'arXiv:2506.20915', 'title': 'ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models', 'authors': 'Mina Namazi, Alexander Nemecek, Erman Ayday', 'link': 'https://arxiv.org/abs/2506.20915', 'abstract': 'As the deployment of large language models (LLMs) grows in sensitive domains, ensuring the integrity of their computational provenance becomes a critical challenge, particularly in regulated sectors such as healthcare, where strict requirements are applied in dataset usage. We introduce ZKPROV, a novel cryptographic framework that enables zero-knowledge proofs of LLM provenance. It allows users to verify that a model is trained on a reliable dataset without revealing sensitive information about it or its parameters. Unlike prior approaches that focus on complete verification of the training process (incurring significant computational cost) or depend on trusted execution environments, ZKPROV offers a distinct balance. Our method cryptographically binds a trained model to its authorized training dataset(s) through zero-knowledge proofs while avoiding proof of every training step. By leveraging dataset-signed metadata and compact model parameter commitments, ZKPROV provides sound and privacy-preserving assurances that the result of the LLM is derived from a model trained on the claimed authorized and relevant dataset. Experimental results demonstrate the efficiency and scalability of the ZKPROV in generating this proof and verifying it, achieving a practical solution for real-world deployments. We also provide formal security guarantees, proving that our approach preserves dataset confidentiality while ensuring trustworthy dataset provenance.', 'abstract_zh': '大语言模型（LLMs）在敏感领域部署增长背景下，确保其计算溯源的完整性成为一个关键挑战，尤其是在受严格数据使用要求限制的医疗等领域。我们提出了ZKPROV，一种新的加密框架，能够提供LLM溯源的零知识证明。该框架允许用户验证模型是否基于可靠的训练数据集，而不泄露有关该数据集或其参数的敏感信息。与专注于整个训练过程完全验证（带来显著计算成本）或依赖受信任的执行环境的先前方法不同，ZKPROV 提供了一种独特的平衡。我们的方法通过零知识证明将训练后的模型绑定到其授权的训练数据集，同时避免验证每个训练步骤。借助数据集签名的元数据和紧凑的模型参数承诺，ZKPROV 提供了关于LLM结果源自声称授权的相关数据集的稳健且隐私保护的保证。实验结果展示了ZKPROV 在生成和验证此证明方面的高效性和可扩展性，实现了一种适用于实际部署的实用解决方案。我们还提供了正式的安全保证，证明了我们的方法在保护数据集机密性的同时确保可信的数据集溯源。', 'title_zh': 'ZKPROV: 零知识环境下的大规模语言模型数据溯源方法'}
{'arxiv_id': 'arXiv:2506.20886', 'title': 'Omniwise: Predicting GPU Kernels Performance with LLMs', 'authors': 'Zixian Wang, Cole Ramos, Muhammad A. Awad, Keith Lowery', 'link': 'https://arxiv.org/abs/2506.20886', 'abstract': "In recent years, the rapid advancement of deep neural networks (DNNs) has revolutionized artificial intelligence, enabling models with unprecedented capabilities in understanding, generating, and processing complex data. These powerful architectures have transformed a wide range of downstream applications, tackling tasks beyond human reach. In this paper, we introduce Omniwise, the first end-to-end, self-supervised fine-tuning pipeline that applies large language models (LLMs) to GPU kernel performance prediction--a novel use case in performance profiling. Omniwise is model-agnostic and lightweight, achieving strong results even with a small 3B-parameter model. It can predict key performance metrics, including memory bandwidth, cache hit rates, GFLOPs, and arithmetic intensity, directly from kernel code without the need for code execution or profiling tools. Our approach achieves over 90% of predictions within 10% relative error on GPU kernels executed on AMD MI250 and MI300X architectures. In addition to the pipeline, we develop an online inference server and a Visual Studio Code plugin that seamlessly integrate LLM-based performance prediction into developers' workflows.", 'abstract_zh': '近年来，深度神经网络（DNNs）的快速进步颠覆了人工智能，使模型在理解和生成复杂数据方面具备前所未有的能力。这些强大的架构已经转变了广泛的应用领域，解决了一些超出了人类能力范围的任务。在本文中，我们介绍了Omniwise，这是首个用于通过大型语言模型（LLMs）进行GPU内核性能预测的端到端自我监督微调管道——这是一个新的性能分析用例。Omniwise是模型无关的且轻量级的，即使使用一个小型的3B参数模型也能取得优异的结果。它可以仅从内核代码预测关键性能指标，如内存带宽、缓存命中率、GFLOPs和算术强度，而无需代码执行或性能分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU内核中的预测相对误差小于10%时，其准确率超过90%。此外，我们还开发了一个在线推理服务和一个Visual Studio Code插件，无缝地将基于LLM的性能预测集成到开发者的 workflows 中。', 'title_zh': 'Omniwise：使用大规模语言模型预测GPU内核性能'}
{'arxiv_id': 'arXiv:2506.20883', 'title': 'Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance', 'authors': 'Kyanna Dagenais, Istvan David', 'link': 'https://arxiv.org/abs/2506.20883', 'abstract': 'Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more efficient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.', 'abstract_zh': '通过受不确定人类指导约束的强化学习开发复杂模型转换序列：迈向RL驱动的人机交互工程方法', 'title_zh': '基于不确定性人类指导的强化学习复杂模型转换'}
{'arxiv_id': 'arXiv:2506.20877', 'title': 'THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion', 'authors': 'Calin Teodor Ioan', 'link': 'https://arxiv.org/abs/2506.20877', 'abstract': 'Monocular depth estimation methods traditionally train deep models to infer depth directly from RGB pixels. This implicit learning often overlooks explicit monocular cues that the human visual system relies on, such as occlusion boundaries, shading, and perspective. Rather than expecting a network to discover these cues unaided, we present ThirdEye, a cue-aware pipeline that deliberately supplies each cue through specialised, pre-trained, and frozen networks. These cues are fused in a three-stage cortical hierarchy (V1->V2->V3) equipped with a key-value working-memory module that weights them by reliability. An adaptive-bins transformer head then produces a high-resolution disparity map. Because the cue experts are frozen, ThirdEye inherits large amounts of external supervision while requiring only modest fine-tuning. This extended version provides additional architectural detail, neuroscientific motivation, and an expanded experimental protocol; quantitative results will appear in a future revision.', 'abstract_zh': '单目深度估计方法通常训练深度模型直接从RGB像素中推断深度。这种隐式的学习往往忽略了人类视觉系统依赖的显式单目线索，如遮挡边界、阴影和透视。我们不期望网络无辅助地发现这些线索，而是提出了ThirdEye，一种线索感知管道，通过专门的、预训练的和冻结的网络故意提供每种线索。这些线索在配备有关键值工作记忆模块的三层皮层结构（V1->V2->V3）中融合，该模块根据可靠性加权这些线索。然后，自适应区间变压器头部生成高分辨率的视差图。由于线索专家是冻结的，ThirdEye可以继承大量的外部监督，同时只需要适度的微调。本文提供了架构细节、神经科学动机以及扩展的实验协议；定量结果将在未来的修订中出现。', 'title_zh': 'THIRDEYE：基于脑启发多阶段融合的线索aware单目深度估计'}
{'arxiv_id': 'arXiv:2506.20869', 'title': 'Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation', 'authors': 'Md Toufique Hasan, Muhammad Waseem, Kai-Kristian Kemell, Ayman Asad Khan, Mika Saari, Pekka Abrahamsson', 'link': 'https://arxiv.org/abs/2506.20869', 'abstract': 'Retrieval-Augmented Generation (RAG) systems are emerging as a key approach for grounding Large Language Models (LLMs) in external knowledge, addressing limitations in factual accuracy and contextual relevance. However, there is a lack of empirical studies that report on the development of RAG-based implementations grounded in real-world use cases, evaluated through general user involvement, and accompanied by systematic documentation of lessons learned. This paper presents five domain-specific RAG applications developed for real-world scenarios across governance, cybersecurity, agriculture, industrial research, and medical diagnostics. Each system incorporates multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted LLMs, deployed through local servers or cloud APIs to meet distinct user needs. A web-based evaluation involving a total of 100 participants assessed the systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii) Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of Recommendation. Based on user feedback and our development experience, we documented twelve key lessons learned, highlighting technical, operational, and ethical challenges affecting the reliability and usability of RAG systems in practice.', 'abstract_zh': '基于检索增强生成的领域特定应用：面向实际场景的Large Language Models的开发与评价', 'title_zh': '面向实际应用的RAG系统工程：设计、开发与评估'}
{'arxiv_id': 'arXiv:2506.20851', 'title': 'Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach', 'authors': 'Srikar Reddy Gadusu, Larry Callahan, Samir Lababidi, Arunasri Nishtala, Sophia Healey, Hande McGinty', 'link': 'https://arxiv.org/abs/2506.20851', 'abstract': 'As data and knowledge expand rapidly, adopting systematic methodologies for ontology generation has become crucial. With the daily increases in data volumes and frequent content changes, the demand for databases to store and retrieve information for the creation of knowledge graphs has become increasingly urgent. The previously established Knowledge Acquisition and Representation Methodology (KNARM) outlines a systematic approach to address these challenges and create knowledge graphs. However, following this methodology highlights the existing challenge of seamlessly integrating Neo4j databases with the Web Ontology Language (OWL). Previous attempts to integrate data from Neo4j into an ontology have been discussed, but these approaches often require an understanding of description logics (DL) syntax, which may not be familiar to many users. Thus, a more accessible method is necessary to bridge this gap. This paper presents a user-friendly approach that utilizes Python and its rdflib library to support ontology development. We showcase our novel approach through a Neo4j database we created by integrating data from the Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) database. Using this dataset, we developed a Python script that automatically generates the required classes and their axioms, facilitating a smoother integration process. This approach offers a practical solution to the challenges of ontology generation in the context of rapidly growing adverse drug event datasets, supporting improved drug safety monitoring and public health decision-making.', 'abstract_zh': '随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。面对数据量的日常增长和内容的频繁变动，建立用于存储和检索信息以创建知识图谱的数据库需求日益迫切。先前建立的Knowledge Acquisition and Representation Methodology (KNARM)概述了一种系统化的解决方案，以应对这些挑战并创建知识图谱。然而，遵循这一方法揭示了将Neo4j数据库与Web Ontology Language (OWL)无缝集成的现有挑战。尽管已经讨论了将Neo4j数据整合到本体中的方法，但这些方法通常要求用户理解描述逻辑(DL)的语法，这可能不适用于许多用户。因此，需要一种更易用的方法来弥合这一差距。本文 presents一种用户友好的方法，利用Python及其rdflib库支持本体开发。我们通过将食品药品管理局(Food and Drug Administration, FDA)不良事件报告系统(Adverse Event Reporting System, FAERS)数据库中的数据整合到一个Neo4j数据库中来展示我们的新方法。利用此数据集，我们开发了一个Python脚本，该脚本可以自动生成所需的类及其公理，从而简化了集成过程。这种方法提供了一种实用的解决方案，以应对快速增长的不良药物事件数据集中的本体生成挑战，支持药物安全性监测和公共卫生决策的改进。', 'title_zh': '通过自动集成数据生成可靠的健康不良事件概况（GRAPH-AID）：一种半自动本体构建方法'}
{'arxiv_id': 'arXiv:2506.20841', 'title': 'FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization', 'authors': 'Ha Min Son, Shahbaz Rezaei, Xin Liu', 'link': 'https://arxiv.org/abs/2506.20841', 'abstract': 'Semi-supervised domain generalization (SSDG) aims to solve the problem of generalizing to out-of-distribution data when only a few labels are available. Due to label scarcity, applying domain generalization methods often underperform. Consequently, existing SSDG methods combine semi-supervised learning methods with various regularization terms. However, these methods do not explicitly regularize to learn domains invariant representations across all domains, which is a key goal for domain generalization. To address this, we introduce FixCLR. Inspired by success in self-supervised learning, we change two crucial components to adapt contrastive learning for explicit domain invariance regularization: utilization of class information from pseudo-labels and using only a repelling term. FixCLR can also be added on top of most existing SSDG and semi-supervised methods for complementary performance improvements. Our research includes extensive experiments that have not been previously explored in SSDG studies. These experiments include benchmarking different improvements to semi-supervised methods, evaluating the performance of pretrained versus non-pretrained models, and testing on datasets with many domains. Overall, FixCLR proves to be an effective SSDG method, especially when combined with other semi-supervised methods.', 'abstract_zh': '半监督领域泛化：FixCLR的方法与应用', 'title_zh': 'FixCLR：负类对比学习在半监督领域泛化中的应用'}
{'arxiv_id': 'arXiv:2506.20832', 'title': 'Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models', 'authors': 'Cansu Korkmaz, Ahmet Murat Tekalp, Zafer Dogan', 'link': 'https://arxiv.org/abs/2506.20832', 'abstract': 'Super-resolution (SR) is an ill-posed inverse problem with many feasible solutions consistent with a given low-resolution image. On one hand, regressive SR models aim to balance fidelity and perceptual quality to yield a single solution, but this trade-off often introduces artifacts that create ambiguity in information-critical applications such as recognizing digits or letters. On the other hand, diffusion models generate a diverse set of SR images, but selecting the most trustworthy solution from this set remains a challenge. This paper introduces a robust, automated framework for identifying the most trustworthy SR sample from a diffusion-generated set by leveraging the semantic reasoning capabilities of vision-language models (VLMs). Specifically, VLMs such as BLIP-2, GPT-4o, and their variants are prompted with structured queries to assess semantic correctness, visual quality, and artifact presence. The top-ranked SR candidates are then ensembled to yield a single trustworthy output in a cost-effective manner. To rigorously assess the validity of VLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid metric that quantifies SR reliability based on three complementary components: semantic similarity via CLIP embeddings, structural integrity using SSIM on edge maps, and artifact sensitivity through multi-level wavelet decomposition. We empirically show that TWS correlates strongly with human preference in both ambiguous and natural images, and that VLM-guided selections consistently yield high TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail to reflect information fidelity, our approach offers a principled, scalable, and generalizable solution for navigating the uncertainty of the diffusion SR space. By aligning outputs with human expectations and semantic correctness, this work sets a new benchmark for trustworthiness in generative SR.', 'abstract_zh': '一种基于视觉语言模型的高保真超分辨样本选择框架', 'title_zh': '利用视觉语言模型选择由扩散模型生成的可信赖超分辨率样本'}
{'arxiv_id': 'arXiv:2506.20822', 'title': 'Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes', 'authors': 'Quintin Myers, Yanjun Gao', 'link': 'https://arxiv.org/abs/2506.20822', 'abstract': 'Large language models (LLMs) are increasingly proposed for detecting and responding to violent content online, yet their ability to reason about morally ambiguous, real-world scenarios remains underexamined. We present the first study to evaluate LLMs using a validated social science instrument designed to measure human response to everyday conflict, namely the Violent Behavior Vignette Questionnaire (VBVQ). To assess potential bias, we introduce persona-based prompting that varies race, age, and geographic identity within the United States. Six LLMs developed across different geopolitical and organizational contexts are evaluated under a unified zero-shot setting. Our study reveals two key findings: (1) LLMs surface-level text generation often diverges from their internal preference for violent responses; (2) their violent tendencies vary across demographics, frequently contradicting established findings in criminology, social science, and psychology.', 'abstract_zh': '大规模语言模型（LLMs）被越来越多地提出用于检测和响应网络上的暴力内容，但它们在推理道德模糊的实际场景方面的能力仍然没有得到充分研究。我们首次使用一个经过验证的社会科学工具来评估LLMs，该工具旨在衡量人们对日常冲突的反应，即暴力行为情景问卷（VBVQ）。为了评估潜在偏见，我们引入了基于人物的提示，这些提示在美国范围内根据不同种族、年龄和地域身份进行变化。六种在不同的地缘政治和组织背景下开发的LLMs在统一的零样本设置下进行了评估。我们的研究揭示了两个关键发现：(1) LLMs的表面级文本生成往往与其内部偏好暴力反应相偏离；(2) 它们的暴力倾向在不同的人口统计学群体中各不相同，经常与犯罪学、社会科学和心理学中的既定发现相矛盾。', 'title_zh': '揭露LLM中隐藏的暴力倾向：基于行为情境的 demographic 分析'}
{'arxiv_id': 'arXiv:2506.20821', 'title': 'MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering', 'authors': 'Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh', 'link': 'https://arxiv.org/abs/2506.20821', 'abstract': 'Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span hundreds of pages and combine diverse modalities, including dense narrative text, structured tables, and complex figures. Answering questions over such content often requires joint reasoning across modalities, which strains traditional large language models (LLMs) and retrieval-augmented generation (RAG) pipelines due to token limitations, layout loss, and fragmented cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation framework purpose-built for financial QA. MultiFinRAG first performs multimodal extraction by grouping table and figure images into batches and sending them to a lightweight, quantized open-source multimodal LLM, which produces both structured JSON outputs and concise textual summaries. These outputs, along with narrative text, are embedded and indexed with modality-aware similarity thresholds for precise retrieval. A tiered fallback strategy then dynamically escalates from text-only to text+table+image contexts when necessary, enabling cross-modal reasoning while reducing irrelevant context. Despite running on commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy than ChatGPT-4o (free-tier) on complex financial QA tasks involving text, tables, images, and combined multimodal reasoning.', 'abstract_zh': '多模态金融QA系统：MultiFinRAG', 'title_zh': 'MultiFinRAG：一种优化的多模态检索增强生成（RAG）框架，用于金融问答'}
{'arxiv_id': 'arXiv:2506.20810', 'title': 'FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs', 'authors': 'Shashwat Khandelwal, Jakoba Petri-Koenig, Thomas B. Preußer, Michaela Blott, Shreejith Shanker', 'link': 'https://arxiv.org/abs/2506.20810', 'abstract': 'Recurrent neural networks (RNNs), particularly LSTMs, are effective for time-series tasks like sentiment analysis and short-term stock prediction. However, their computational complexity poses challenges for real-time deployment in resource constrained environments. While FPGAs offer a promising platform for energy-efficient AI acceleration, existing tools mainly target feed-forward networks, and LSTM acceleration typically requires full custom implementation. In this paper, we address this gap by leveraging the open-source and extensible FINN framework to enable the generalized deployment of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open Neural Network Exchange (ONNX) specification to model the recurrent nature of LSTM computations, enabling support for mixed quantisation within them and functional verification of LSTM-based models. Furthermore, we introduce custom transformations within the FINN compiler to map the quantised ONNX computation graph to hardware blocks from the HLS kernel library of the FINN compiler and Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM model for a mid-price stock prediction task using the widely used dataset and generating a corresponding hardware IP of the model using our flow, targeting the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator through our flow achieves a balance between performance (latency) and resource consumption, while matching (or bettering) inference accuracy of state-of-the-art models with reduced precision. We believe that the generalisable nature of the proposed flow will pave the way for resource-efficient RNN accelerator designs on FPGAs.', 'abstract_zh': '基于FINN框架的LSTM在FPGA上的通用部署', 'title_zh': 'FINN-GL: 通用混合精度扩展 for FPGA 加速的 LSTM'}
{'arxiv_id': 'arXiv:2506.20807', 'title': 'GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization', 'authors': 'Martin Andrews, Sam Witteveen', 'link': 'https://arxiv.org/abs/2506.20807', 'abstract': 'Optimizing GPU kernels for high performance is a complex task, often demanding deep architectural knowledge, extensive profiling, and iterative experimentation. This challenge is amplified when targeting newer or less-documented GPU architectures where traditional development aids are scarce. This paper introduces an LLM-powered "GPU Kernel Scientist," an automated methodology for iteratively refining accelerator kernels.\nOur methodology employs LLMs in a multi-stage, evolutionary process: (a) strategically selecting promising prior code versions as a basis for new iterations; (b) generating hypotheses for optimization experiments, based on existing code and assimilated knowledge from general GPU literature; and (c) autonomously implementing these experiments through code modification and subsequent submission to an external evaluation system, using only observed timing data as performance feedback. We detail how this approach navigates the challenges of the AMD MI300 target architecture and leverages LLMs to compensate for limited domain-specific human expertise.\nSince quantitative results from an ongoing performance competition were embargoed on paper submission date, we present the architectural design, operational workflow, and qualitative insights, highlighting the potential of LLM-driven agents to democratise and accelerate GPU kernel optimization, especially in resource-constrained or rapidly evolving hardware environments.', 'abstract_zh': '基于LLM的“GPU内核科学家”：一种自动迭代优化加速器内核的方法学', 'title_zh': 'GPU内核科学家：一个基于LLM的迭代内核优化框架'}
{'arxiv_id': 'arXiv:2506.20806', 'title': 'Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis', 'authors': 'Zhonghao Zhan, Huichi Zhou, Hamed Haddadi', 'link': 'https://arxiv.org/abs/2506.20806', 'abstract': 'Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks. Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios. This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These agents scrutinize graph structures derived from network flow data, identifying and potentially mitigating suspicious or adversarially perturbed elements before GNN processing. Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.', 'abstract_zh': '基于大型语言模型的代理pipeline增强图神经网络在网络入侵检测系统中的 robustness 和泛化能力研究', 'title_zh': 'Poster: 基于代理分析增强GNN在网络入侵检测中的鲁棒性'}
{'arxiv_id': 'arXiv:2506.20803', 'title': 'The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas', 'authors': 'Chenglei Si, Tatsunori Hashimoto, Diyi Yang', 'link': 'https://arxiv.org/abs/2506.20803', 'abstract': 'Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert ideas. However, a good idea should not simply appear to be novel, it should also result in better research after being executed. To test whether AI-generated ideas lead to better research outcomes, we conduct an execution study by recruiting 43 expert researchers to execute randomly-assigned ideas, either written by experts or generated by an LLM. Each expert spent over 100 hours implementing the idea and wrote a 4-page short paper to document the experiments. All the executed projects are then reviewed blindly by expert NLP researchers. Comparing the review scores of the same ideas before and after execution, the scores of the LLM-generated ideas decrease significantly more than expert-written ideas on all evaluation metrics (novelty, excitement, effectiveness, and overall; p < 0.05), closing the gap between LLM and human ideas observed at the ideation stage. When comparing the aggregated review scores from the execution study, we even observe that for many metrics there is a flip in rankings where human ideas score higher than LLM ideas. This ideation-execution gap highlights the limitations of current LLMs in generating truly effective research ideas and the challenge of evaluating research ideas in the absence of execution outcomes.', 'abstract_zh': '大型语言模型在加速科学研究管道方面显示出了潜力。这一过程的关键能力是生成新颖的研究想法，先前的研究发现，由大型语言模型生成的研究想法被判断为比人类专家的想法更具新颖性。然而，一个好的想法不仅应该看似新颖，还应该在执行后能够带来更好的研究成果。为了测试人工智能生成的想法是否能导致更优秀的研究成果，我们通过招募43位专家研究人员来执行随机分配的想法，这些想法要么由专家编写，要么由大型语言模型生成。每位专家花费超过100小时来实现想法，并撰写了4页的简短论文来记录实验。所有执行的项目随后由专家自然语言处理研究人员盲审。通过比较执行前后相同想法的评审分数，大型语言模型生成的想法在所有评价指标（新颖性、兴奋性、有效性以及总体评分）上的得分下降显著（p < 0.05），这表明执行阶段的结果缩小了在想法产生阶段观察到的大型语言模型与人类想法之间的差距。当比较执行研究中的综合评审分数时，我们甚至观察到许多指标中人类想法得分高于大型语言模型想法的情况。这个想法执行差异突显了当前大型语言模型生成真正有效的研究想法的局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。', 'title_zh': 'LLM生成的构思与人类研究构思的执行差距：执行结果对比'}
{'arxiv_id': 'arXiv:2506.20790', 'title': 'Stochastic Parameter Decomposition', 'authors': 'Lucius Bushnaq, Dan Braun, Lee Sharkey', 'link': 'https://arxiv.org/abs/2506.20790', 'abstract': 'A key step in reverse engineering neural networks is to decompose them into simpler parts that can be studied in relative isolation. Linear parameter decomposition -- a framework that has been proposed to resolve several issues with current decomposition methods -- decomposes neural network parameters into a sum of sparsely used vectors in parameter space. However, the current main method in this framework, Attribution-based Parameter Decomposition (APD), is impractical on account of its computational cost and sensitivity to hyperparameters. In this work, we introduce \\textit{Stochastic Parameter Decomposition} (SPD), a method that is more scalable and robust to hyperparameters than APD, which we demonstrate by decomposing models that are slightly larger and more complex than was possible to decompose with APD. We also show that SPD avoids other issues, such as shrinkage of the learned parameters, and better identifies ground truth mechanisms in toy models. By bridging causal mediation analysis and network decomposition methods, this demonstration opens up new research possibilities in mechanistic interpretability by removing barriers to scaling linear parameter decomposition methods to larger models. We release a library for running SPD and reproducing our experiments at this https URL.', 'abstract_zh': '神经网络逆向工程中的一个关键步骤是将它们分解为更简单的部分以便在相对隔离的环境中进行研究。Sparse Stochastic Parameter Decomposition (SPD)：一种比基于 Attribution 的参数分解 (APD) 更具扩展性和对超参数更稳健的方法及其应用', 'title_zh': '随机参数分解'}
{'arxiv_id': 'arXiv:2506.20759', 'title': 'Agile Management for Machine Learning: A Systematic Mapping Study', 'authors': 'Lucas Romao, Hugo Villamizar, Romeu Oliveira, Silvio Alonso, Marcos Kalinowski', 'link': 'https://arxiv.org/abs/2506.20759', 'abstract': '[Context] Machine learning (ML)-enabled systems are present in our society, driving significant digital transformations. The dynamic nature of ML development, characterized by experimental cycles and rapid changes in data, poses challenges to traditional project management. Agile methods, with their flexibility and incremental delivery, seem well-suited to address this dynamism. However, it is unclear how to effectively apply these methods in the context of ML-enabled systems, where challenges require tailored approaches. [Goal] Our goal is to outline the state of the art in agile management for ML-enabled systems. [Method] We conducted a systematic mapping study using a hybrid search strategy that combines database searches with backward and forward snowballing iterations. [Results] Our study identified 27 papers published between 2008 and 2024. From these, we identified eight frameworks and categorized recommendations and practices into eight key themes, such as Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable Model. The main challenge identified across studies was accurate effort estimation for ML-related tasks. [Conclusion] This study contributes by mapping the state of the art and identifying open gaps in the field. While relevant work exists, more robust empirical evaluation is still needed to validate these contributions.', 'abstract_zh': '机器学习赋能系统的敏捷管理现状综述：挑战与实践', 'title_zh': '机器学习中的敏捷管理：一项系统映射研究'}
{'arxiv_id': 'arXiv:2506.20748', 'title': 'Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots', 'authors': 'Jingshu Li, Zicheng Zhu, Renwen Zhang, Yi-Chieh Lee', 'link': 'https://arxiv.org/abs/2506.20748', 'abstract': "Chatbots are increasingly integrated into people's lives and are widely used to help people. Recently, there has also been growing interest in the reverse direction-humans help chatbots-due to a wide range of benefits including better chatbot performance, human well-being, and collaborative outcomes. However, little research has explored the factors that motivate people to help chatbots. To address this gap, we draw on the Computers Are Social Actors (CASA) framework to examine how chatbot anthropomorphism-including human-like identity, emotional expression, and non-verbal expression-influences human empathy toward chatbots and their subsequent prosocial behaviors and intentions. We also explore people's own interpretations of their prosocial behaviors toward chatbots. We conducted an online experiment (N = 244) in which chatbots made mistakes in a collaborative image labeling task and explained the reasons to participants. We then measured participants' prosocial behaviors and intentions toward the chatbots. Our findings revealed that human identity and emotional expression of chatbots increased participants' prosocial behavior and intention toward chatbots, with empathy mediating these effects. Qualitative analysis further identified two motivations for participants' prosocial behaviors: empathy for the chatbot and perceiving the chatbot as human-like. We discuss the implications of these results for understanding and promoting human prosocial behaviors toward chatbots.", 'abstract_zh': '聊天机器人日益融入人们的生活并在帮助人们方面得到广泛应用。近年来，人类帮助聊天机器人这一反向方向也引起越来越多的兴趣，这得益于广泛的好处，包括改进聊天机器人的表现、提高人类福祉以及促进协作成果。然而，很少有研究探讨促使人们帮助聊天机器人的动机。为解决这一差距，我们借助Computers Are Social Actors (CASA) 框架，研究聊天机器人拟人化（包括类似人类的身份、情感表达和非言语表达）如何影响人们对聊天机器人的同理心及其随后的亲社会行为和意图。同时，我们还探讨了参与者对自己向聊天机器人表现出的亲社会行为的解读。我们进行了一个网络实验（N = 244），在实验中，聊天机器人在一项协作图像标注任务中犯错并向参与者解释原因。我们随后测量了参与者对聊天机器人表现出的亲社会行为和意图。研究发现，聊天机器人具有类似人类的身份和情感表达会增加参与者对聊天机器人的亲社会行为和意图，同理心在这两个效应之间起中介作用。定性分析进一步识别了参与者产生亲社会行为的两种动机：对聊天机器人的同理心以及将聊天机器人视为拟人化的感知。我们讨论了这些结果对理解并促进人们对聊天机器人的亲社会行为的意义。', 'title_zh': '探索聊天机器人的拟人类化与其引发的人类同理心对人类向聊天机器人展现亲社会行为的影响'}
{'arxiv_id': 'arXiv:2506.20729', 'title': 'Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset', 'authors': 'Zhiqi Gao, Tianyi Li, Yurii Kvasiuk, Sai Chaitanya Tadepalli, Maja Rudolph, Daniel J.H. Chung, Frederic Sala, Moritz Münchmeyer', 'link': 'https://arxiv.org/abs/2506.20729', 'abstract': 'Large language models (LLMs) have shown strong capabilities in complex reasoning, and test-time scaling techniques can enhance their performance with comparably low cost. Many of these methods have been developed and evaluated on mathematical reasoning benchmarks such as AIME. This paper investigates whether the lessons learned from these benchmarks generalize to the domain of advanced theoretical physics. We evaluate a range of common test-time scaling methods on the TPBench physics dataset and compare their effectiveness with results on AIME. To better leverage the structure of physics problems, we develop a novel, symbolic weak-verifier framework to improve parallel scaling results. Our empirical results demonstrate that this method significantly outperforms existing test-time scaling approaches on TPBench. We also evaluate our method on AIME, confirming its effectiveness in solving advanced mathematical problems. Our findings highlight the power of step-wise symbolic verification for tackling complex scientific problems.', 'abstract_zh': '大型语言模型（LLMs）在复杂推理方面展现了强大的能力，测试时扩展技术可以在较低成本的情况下提升其性能。这些方法大多是在AIME等数学推理基准上开发和评估的。本文探讨了这些基准上的经验教训是否能够推广到高级理论物理领域。我们评估了多种常见的测试时扩展方法在TPBench物理数据集上的效果，并将其与在AIME上的结果进行比较。为了更好地利用物理问题的结构，我们开发了一种新的符号弱验证框架，以改善并行扩展的结果。我们的实验结果表明，该方法在TPBench上的表现显著优于现有的测试时扩展方法。我们还在AIME上测试了该方法，证实了其在解决高级数学问题方面的有效性。我们的研究突显了逐步符号验证在应对复杂科学问题方面的潜力。', 'title_zh': '测试时缩放技术在理论物理中的研究——TPBench数据集上方法比较'}
{'arxiv_id': 'arXiv:2506.20705', 'title': 'On Convolutions, Intrinsic Dimension, and Diffusion Models', 'authors': 'Kin Kwan Leung, Rasa Hosseinzadeh, Gabriel Loaiza-Ganem', 'link': 'https://arxiv.org/abs/2506.20705', 'abstract': 'The manifold hypothesis asserts that data of interest in high-dimensional ambient spaces, such as image data, lies on unknown low-dimensional submanifolds. Diffusion models (DMs) -- which operate by convolving data with progressively larger amounts of Gaussian noise and then learning to revert this process -- have risen to prominence as the most performant generative models, and are known to be able to learn distributions with low-dimensional support. For a given datum in one of these submanifolds, we should thus intuitively expect DMs to have implicitly learned its corresponding local intrinsic dimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari et al. (2024b) recently showed that this is indeed the case by linking this LID to the rate of change of the log marginal densities of the DM with respect to the amount of added noise, resulting in an LID estimator known as FLIPD. LID estimators such as FLIPD have a plethora of uses, among others they quantify the complexity of a given datum, and can be used to detect outliers, adversarial examples and AI-generated text. FLIPD achieves state-of-the-art performance at LID estimation, yet its theoretical underpinnings are incomplete since Kamkari et al. (2024b) only proved its correctness under the highly unrealistic assumption of affine submanifolds. In this work we bridge this gap by formally proving the correctness of FLIPD under realistic assumptions. Additionally, we show that an analogous result holds when Gaussian convolutions are replaced with uniform ones, and discuss the relevance of this result.', 'abstract_zh': '流形假设表明，高维环境空间中的有趣数据，如图像数据，位于未知的低维子流形上。扩散模型（DMs）通过逐步将数据与越来越多的高斯噪声进行卷积，然后学习反转这一过程而变得瞩目，并且已知能够学习具有低维支撑的概率分布。对于这些子流形中的任意一个数据点，我们直观地预期DMs已经隐式地学习到了其相应的局部固有维数（LID），即它所属的子流形的维数。Kamkari等（2024b）最近通过将这种LID与DM的对数边缘概率密度关于添加噪声量的变化率联系起来，展示了这一点，并由此提出了一种名为FLIPD的LID估算器。LID估算器如FLIPD有多种用途，其中之一是量化给定数据的复杂性，还可以用于检测异常值、对抗样本和AI生成的文本。FLIPD在LID估算方面达到了最先进的性能，但由于Kamkari等（2024b）仅在假设子流形为仿射的情况下证明了其正确性，其理论基础尚不完整。本文通过正式证明在现实假设下FLIPD的正确性弥补了这一不足。此外，我们展示了当高斯卷积替换为均匀卷积时也有类似的结果，并讨论了这一结果的相关性。', 'title_zh': '关于卷积、固有维度和扩散模型'}
{'arxiv_id': 'arXiv:2506.20701', 'title': 'Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models', 'authors': 'Vineet Jain, Kusha Sareen, Mohammad Pedramfar, Siamak Ravanbakhsh', 'link': 'https://arxiv.org/abs/2506.20701', 'abstract': 'Adapting a pretrained diffusion model to new objectives at inference time remains an open problem in generative modeling. Existing steering methods suffer from inaccurate value estimation, especially at high noise levels, which biases guidance. Moreover, information from past runs is not reused to improve sample quality, resulting in inefficient use of compute. Inspired by the success of Monte Carlo Tree Search, we address these limitations by casting inference-time alignment as a search problem that reuses past computations. We introduce a tree-based approach that samples from the reward-aligned target density by propagating terminal rewards back through the diffusion chain and iteratively refining value estimates with each additional generation. Our proposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact samples from the target distribution in the limit of infinite rollouts, and its greedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search for high reward samples. On MNIST and CIFAR-10 class-conditional generation, DTS matches the FID of the best-performing baseline with up to $10\\times$ less compute. In text-to-image generation and language completion tasks, DTS$^\\star$ effectively searches for high reward samples that match best-of-N with up to $5\\times$ less compute. By reusing information from previous generations, we get an anytime algorithm that turns additional compute into steadily better samples, providing a scalable approach for inference-time alignment of diffusion models.', 'abstract_zh': '在生成建模中，推理时适应预训练扩散模型以实现新目标仍是一个开放问题。现有的调控方法在高噪声水平下价值估计不准确，这会导致指导偏差。此外，过去运行中的信息未被重用以提高样本质量，导致计算资源的低效利用。受蒙特卡洛树搜索成功的启发，我们通过将推理时对齐视为一个重用过往计算的搜索问题来解决这些限制。我们提出了一种基于树的方法，通过在扩散链中反向传播终端奖励并随着每次生成迭代改进价值估计来从对齐的目标密度中采样。我们提出的Diffusion Tree Sampling (DTS)方法在无限迭代中从目标分布中产生渐近准确的样本，而其贪婪变体Diffusion Tree Search (DTS$^\\star$)则进行全局搜索以找到高奖励样本。在MNIST和CIFAR-10类条件生成任务中，DTS的计算量最多减少10倍仍能达到最佳基线的FID。在文本到图像生成和语言完成任务中，DTS$^\\star$有效搜索高奖励样本，计算量最多减少5倍仍能达到N次最佳。通过重用先前生成的信息，我们获得了一个随时可用的算法，可以将额外的计算资源转化为逐渐改进的样本，为扩散模型的推理时对齐提供了一种可扩展的方法。', 'title_zh': '扩散树采样：扩散模型的可扩展推理时序对齐'}
{'arxiv_id': 'arXiv:2506.20696', 'title': 'IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation', 'authors': 'Siyu Mu, Wei Xuan Chan, Choon Hwai Yap', 'link': 'https://arxiv.org/abs/2506.20696', 'abstract': 'Elucidating the biomechanical behavior of the myocardium is crucial for understanding cardiac physiology, but cannot be directly inferred from clinical imaging and typically requires finite element (FE) simulations. However, conventional FE methods are computationally expensive and often fail to reproduce observed cardiac motions. We propose IMC-PINN-FE, a physics-informed neural network (PINN) framework that integrates imaged motion consistency (IMC) with FE modeling for patient-specific left ventricular (LV) biomechanics. Cardiac motion is first estimated from MRI or echocardiography using either a pre-trained attention-based network or an unsupervised cyclic-regularized network, followed by extraction of motion modes. IMC-PINN-FE then rapidly estimates myocardial stiffness and active tension by fitting clinical pressure measurements, accelerating computation from hours to seconds compared to traditional inverse FE. Based on these parameters, it performs FE modeling across the cardiac cycle at 75x speedup. Through motion constraints, it matches imaged displacements more accurately, improving average Dice from 0.849 to 0.927, while preserving realistic pressure-volume behavior. IMC-PINN-FE advances previous PINN-FE models by introducing back-computation of material properties and better motion fidelity. Using motion from a single subject to reconstruct shape modes also avoids the need for large datasets and improves patient specificity. IMC-PINN-FE offers a robust and efficient approach for rapid, personalized, and image-consistent cardiac biomechanical modeling.', 'abstract_zh': '阐明心肌的生物力学行为对于理解心脏生理学至关重要，但无法直接从临床影像中推断，通常需要进行有限元（FE）模拟。然而，传统的FE方法计算成本高，往往无法再现观察到的心脏运动。我们提出了一种物理知情神经网络（PINN）框架IMC-PINN-FE，该框架将成像运动一致性（IMC）与FE建模相结合，用于患者特定的左心室（LV）生物力学。首先从MRI或超声心动图中使用预训练的基于注意力的网络或无监督的循环调节网络估计心脏运动，随后提取运动模式。IMC-PINN-FE通过拟合临床压力测量值迅速估计心肌刚度和主动张力，将计算时间从小时缩短到秒级，相比传统逆向FE加速了75倍。基于这些参数，它在心脏周期中进行FE建模，速度提高了75倍。通过运动约束，它更准确地匹配了成像位移，将平均Dice值从0.849提高到0.927，同时保持了真实的压力-体积行为。IMC-PINN-FE通过引入材料性质的反向计算和更好的运动保真度，提升了之前的PINN-FE模型。使用单个受试者的运动重建形变模式也避免了大量数据集的需求，提高了患者特异性。IMC-PINN-FE提供了一种稳健而高效的快速、个性化和影像一致的心脏生物力学建模方法。', 'title_zh': '基于图像运动一致性及 biomechanical 参数估计的患者特异性左心室有限元建模的物理知情神经网络'}
{'arxiv_id': 'arXiv:2506.20694', 'title': 'Evaluating PDE discovery methods for multiscale modeling of biological signals', 'authors': 'Andréa Ducos, Audrey Denizot, Thomas Guyet, Hugues Berry', 'link': 'https://arxiv.org/abs/2506.20694', 'abstract': 'Biological systems are non-linear, include unobserved variables and the physical principles that govern their dynamics are partly unknown. This makes the characterization of their behavior very challenging. Notably, their activity occurs on multiple interdependent spatial and temporal scales that require linking mechanisms across scales. To address the challenge of bridging gaps between scales, we leverage partial differential equations (PDE) discovery. PDE discovery suggests meso-scale dynamics characteristics from micro-scale data. In this article, we present our framework combining particle-based simulations and PDE discovery and conduct preliminary experiments to assess equation discovery in controlled settings. We evaluate five state-of-the-art PDE discovery methods on particle-based simulations of calcium diffusion in astrocytes. The performances of the methods are evaluated on both the form of the discovered equation and the forecasted temporal variations of calcium concentration. Our results show that several methods accurately recover the diffusion term, highlighting the potential of PDE discovery for capturing macroscopic dynamics in biological systems from microscopic data.', 'abstract_zh': '生物系统是非线性的，包含未观察到的变量，并且调控其动力学的物理原理部分未知。这使得对其行为的描述非常具有挑战性。值得注意的是，其活动跨越多个相互依赖的空间和时间尺度，需要跨尺度链接机制。为了应对跨尺度连接的挑战，我们利用偏微分方程（PDE）发现方法。PDE发现方法可以从微观尺度数据中推断出介观尺度的动力学特征。在本文中，我们提出了一种结合粒子模拟和PDE发现的框架，并在受控实验环境中初步评估了方程发现方法。我们使用五种最先进的PDE发现方法在星形胶质细胞中的钙扩散粒子模拟中进行评估。这些方法的表现分别从发现方程的形式和预测的钙浓度随时间的变化来评估。我们的结果表明，几种方法准确地恢复了扩散项，突显了PDE发现方法从微观数据中捕获生物系统宏观动态的潜力。', 'title_zh': '多尺度生物信号建模的偏微分方程发现方法评价'}
{'arxiv_id': 'arXiv:2506.20689', 'title': 'U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs', 'authors': 'Racheal Mukisa, Arvind K. Bansal', 'link': 'https://arxiv.org/abs/2506.20689', 'abstract': 'Artificial intelligence, including deep learning models, will play a transformative role in automated medical image analysis for the diagnosis of cardiac disorders and their management. Automated accurate delineation of cardiac images is the first necessary initial step for the quantification and automated diagnosis of cardiac disorders. In this paper, we propose a deep learning based enhanced UNet model, U-R-Veda, which integrates convolution transformations, vision transformer, residual links, channel-attention, and spatial attention, together with edge-detection based skip-connections for an accurate fully-automated semantic segmentation of cardiac magnetic resonance (CMR) images. The model extracts local-features and their interrelationships using a stack of combination convolution blocks, with embedded channel and spatial attention in the convolution block, and vision transformers. Deep embedding of channel and spatial attention in the convolution block identifies important features and their spatial localization. The combined edge information with channel and spatial attention as skip connection reduces information-loss during convolution transformations. The overall model significantly improves the semantic segmentation of CMR images necessary for improved medical image analysis. An algorithm for the dual attention module (channel and spatial attention) has been presented. Performance results show that U-R-Veda achieves an average accuracy of 95.2%, based on DSC metrics. The model outperforms the accuracy attained by other models, based on DSC and HD metrics, especially for the delineation of right-ventricle and left-ventricle-myocardium.', 'abstract_zh': '人工智能，包括深度学习模型，将在心血管疾病诊断及其管理的自动化医学图像分析中发挥变革性作用。准确的自动心脏图像分割是心脏疾病量化和自动化诊断的第一步必要步骤。本文提出了一种基于深度学习的增强UNet模型U-R-Veda，该模型结合了卷积变换、视觉变换器、残差连接、通道注意和空间注意，并通过基于边缘检测的跳跃连接实现心脏磁共振（CMR）图像的准确全自动语义分割。模型利用堆叠组合卷积块提取局部特征及其相互关系，并在卷积块中嵌入通道和空间注意，以及视觉变换器，以识别重要特征及其空间定位。结合边缘信息与通道和空间注意作为跳跃连接，减少了卷积变换中的信息损失。整体模型显著提高了必要的心脏磁共振图像语义分割性能，从而改进医学图像分析。提出了双注意模块（通道注意和空间注意）的算法。性能结果显示，U-R-Veda基于DSC指标的平均准确率为95.2%。该模型在基于DSC和HD指标的精度上优于其他模型，尤其是在右心室和左心室心肌的分割方面。', 'title_zh': 'U-R-VEDA：结合UNET、残差链接、边缘和双关注机制以及视觉变压器的心脏磁共振图像精确语义分割'}
{'arxiv_id': 'arXiv:2506.20685', 'title': 'Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems', 'authors': 'Sajid Hussain, Muhammad Sohail, Nauman Ali Khan, Naima Iltaf, Ihtesham ul Islam', 'link': 'https://arxiv.org/abs/2506.20685', 'abstract': 'Federated Learning (FL) has emerged as a transformative paradigm for distributed machine learning while preserving data privacy. However, existing approaches predominantly focus on model heterogeneity and aggregation techniques, largely overlooking the fundamental impact of dataset size characteristics on federated training dynamics. This paper introduces Size-Based Adaptive Federated Learning (SAFL), a novel progressive training framework that systematically organizes federated learning based on dataset size characteristics across heterogeneous multi-modal data. Our comprehensive experimental evaluation across 13 diverse datasets spanning 7 modalities (vision, text, time series, audio, sensor, medical vision, and multimodal) reveals critical insights: 1) an optimal dataset size range of 1000-1500 samples for federated learning effectiveness; 2) a clear modality performance hierarchy with structured data (time series, sensor) significantly outperforming unstructured data (text, multimodal); and 3) systematic performance degradation for large datasets exceeding 2000 samples. SAFL achieves an average accuracy of 87.68% across all datasets, with structured data modalities reaching 99%+ accuracy. The framework demonstrates superior communication efficiency, reducing total data transfer to 7.38 GB across 558 communications while maintaining high performance. Our real-time monitoring framework provides unprecedented insights into system resource utilization, network efficiency, and training dynamics. This work fills critical gaps in understanding how data characteristics should drive federated learning strategies, providing both theoretical insights and practical guidance for real-world FL deployments in neural network and learning systems.', 'abstract_zh': '基于数据集规模的自适应联邦学习（Size-Based Adaptive Federated Learning, SAFL）', 'title_zh': '渐进自适应大小联邦学习：跨模态异构数据系统综合框架'}
{'arxiv_id': 'arXiv:2506.20683', 'title': 'Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG', 'authors': 'Alexander Selivanov, Philip Müller, Özgün Turgut, Nil Stolt-Ansó, Daniel Rückert', 'link': 'https://arxiv.org/abs/2506.20683', 'abstract': 'An electrocardiogram (ECG) is a widely used, cost-effective tool for detecting electrical abnormalities in the heart. However, it cannot directly measure functional parameters, such as ventricular volumes and ejection fraction, which are crucial for assessing cardiac function. Cardiac magnetic resonance (CMR) is the gold standard for these measurements, providing detailed structural and functional insights, but is expensive and less accessible. To bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive Learning), a multimodal contrastive learning framework that enhances ECG representations by integrating spatio-temporal information from CMR. PTACL uses global patient-level contrastive loss and local temporal-level contrastive loss. The global loss aligns patient-level representations by pulling ECG and CMR embeddings from the same patient closer together, while pushing apart embeddings from different patients. Local loss enforces fine-grained temporal alignment within each patient by contrasting encoded ECG segments with corresponding encoded CMR frames. This approach enriches ECG representations with diagnostic information beyond electrical activity and transfers more insights between modalities than global alignment alone, all without introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL achieves better performance in two clinically relevant tasks: (1) retrieving patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac function parameters, such as ventricular volumes and ejection fraction. Our results highlight the potential of PTACL to enhance non-invasive cardiac diagnostics using ECG. The code is available at: this https URL', 'abstract_zh': '一种将心电图(ECG)表示与心脏磁共振(CMR)的空间-时间信息相结合的多模态对比学习框架：PTACL', 'title_zh': '全局和局部对比学习在心脏MRI和ECG联合表示中的应用'}
{'arxiv_id': 'arXiv:2506.20675', 'title': 'Utility-Driven Speculative Decoding for Mixture-of-Experts', 'authors': 'Anish Saxena, Po-An Tsai, Hritvik Taneja, Aamer Jaleel, Moinuddin Qureshi', 'link': 'https://arxiv.org/abs/2506.20675', 'abstract': 'GPU memory bandwidth is the main bottleneck for low-latency Large Language Model (LLM) inference. Speculative decoding leverages idle GPU compute by using a lightweight drafter to propose K tokens, which the LLM verifies in parallel, boosting token throughput. In conventional dense LLMs, all model weights are fetched each iteration, so speculation adds no latency overhead. Emerging Mixture of Experts (MoE) models activate only a subset of weights per token, greatly reducing data movement. However, we show that speculation is ineffective for MoEs: draft tokens collectively activate more weights, increasing data movement and verification time by 2-3x. When token throughput gains fail to offset this overhead, speculation causes slowdowns up to 1.5x, making it infeasible. Even when useful, the optimal K varies by task, model, and even between requests and iterations. Thus, despite widespread use in dense LLMs, speculation remains impractical in leading MoEs.\nWe present Cascade, a utility-driven framework that selectively enables speculation to avoid slowdowns and dynamically tunes K to accelerate MoE serving. Cascade uses a lightweight metric, speculation utility, the ratio of token gains to verification cost, which shows iteration-level locality, enabling periodic decisions via short test and longer set phases. For each request, Cascade disables speculation if utility drops below one during testing, and when utility exceeds one, tests multiple K-values to choose the utility-maximizing K for the set phase. We implement Cascade in vLLM and evaluate it on five popular MoEs with workloads spanning code, math, extraction, and mixed tasks. Cascade limits slowdown to 5% (vs. 1.5x) and improves throughput by 7-14% over static K, making speculative decoding practical for MoEs.', 'abstract_zh': 'GPU内存带宽是低延迟大语言模型（LLM）推理的主要瓶颈。推测性解码通过使用轻量级草案器提出K个令牌，由LLM并行验证，从而提升令牌吞吐量。在传统的密集型LLM中，每迭代一次都会获取所有模型权重，因此推测不会增加延迟开销。新兴的专家混合（MoE）模型每次仅激活权重子集，大大减少了数据移动。然而，我们发现推测对于MoE无效：草案令牌共同激活更多权重，增加数据移动和验证时间2-3倍。当令牌吞吐量增益无法抵消这种开销时，推测会导致多达1.5倍的性能下降，使其不可行。即使有用，最优的K值也因任务、模型甚至不同请求和迭代而异。因此，尽管在密集型LLM中广泛应用，推测对于领先的MoE仍不可行。\n\n我们提出了Cascade，一个以用途为导向的框架，选择性地启用推测以避免性能下降，并动态调整K值以加快MoE服务。Cascade使用一个轻量级指标——推测用途，即令牌增益与验证成本的比率，展示迭代级别的局部性，通过短测试期和较长设定期周期性地进行决策。对于每个请求，Cascade在测试过程中如果用途低于一个阈值则禁用推测，并在用途超过一个阈值时测试多个K值，选择设定期中用途最大的K值。我们在vLLM中实现Cascade，并在涵盖代码、数学、提取和混合任务的五个流行MoE上进行评估。Cascade将性能下降限制在5%（相对于1.5倍），并相对于固定K值改善吞吐量7-14%，使推测性解码对于MoE变得可行。', 'title_zh': '基于利用率推测性解码的混合专家模型'}
{'arxiv_id': 'arXiv:2506.20673', 'title': 'ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data', 'authors': 'Yongqian Sun, Xijie Pan, Xiao Xiong, Lei Tao, Jiaju Wang, Shenglin Zhang, Yuan Yuan, Yuqi Li, Kunlin Jian', 'link': 'https://arxiv.org/abs/2506.20673', 'abstract': 'Network failure diagnosis is challenging yet critical for high-performance computing (HPC) systems. Existing methods cannot be directly applied to HPC scenarios due to data heterogeneity and lack of accuracy. This paper proposes a novel framework, called ClusterRCA, to localize culprit nodes and determine failure types by leveraging multimodal data. ClusterRCA extracts features from topologically connected network interface controller (NIC) pairs to analyze the diverse, multimodal data in HPC systems. To accurately localize culprit nodes and determine failure types, ClusterRCA combines classifier-based and graph-based approaches. A failure graph is constructed based on the output of the state classifier, and then it performs a customized random walk on the graph to localize the root cause. Experiments on datasets collected by a top-tier global HPC device vendor show ClusterRCA achieves high accuracy in diagnosing network failure for HPC systems. ClusterRCA also maintains robust performance across different application scenarios.', 'abstract_zh': '高性能计算（HPC）系统中的网络故障诊断具有挑战性但至关重要。现有的方法无法直接应用于HPC场景，原因是数据异构性和缺乏准确性。本文提出了一种新颖的框架ClusterRCA，通过充分利用多模态数据来定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网络接口控制器（NIC）对中提取特征，以分析HPC系统的多样性多模态数据。为了准确地定位故障节点并确定故障类型，ClusterRCA结合了基于分类器的方法和基于图的方法。基于状态分类器的输出构建故障图，然后在图上执行自定义的随机游走以定位根本原因。实验结果表明，ClusterRCA在诊断HPC系统的网络故障方面具有高准确性，并且能在不同应用场景下保持稳健性能。', 'title_zh': 'ClusterRCA：使用多模态数据进行HPC系统网络故障诊断'}
{'arxiv_id': 'arXiv:2506.20243', 'title': 'CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment', 'authors': 'Papa Séga Wade, Mihai Andries, Ioannis Kanellos, Thierry Moudenc', 'link': 'https://arxiv.org/abs/2506.20243', 'abstract': 'Automatic fluency assessment (AFA) remains challenging, particularly in capturing speech rhythm, pauses, and disfluencies in non-native speakers. We introduce a chunk-based approach integrating self-supervised learning (SSL) models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths in phonetic, prosodic, and noisy speech modeling, with a hierarchical CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero voice activity detection (Silero-VAD), enabling fine-grained temporal analysis while mitigating over-segmentation artifacts. SSL embeddings are fused via a learnable weighted mechanism, balancing acoustic and linguistic features, and enriched with chunk-level fluency markers (e.g., speech rate, pause durations, n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on Avalinguo, surpassing this http URL-based segmentation baselines. These findings highlight chunk-based multi-SSL fusion for robust fluency evaluation, though future work should explore generalization to dialects with irregular prosody.', 'abstract_zh': '基于块的多自监督学习融合自动流畅性评估', 'title_zh': '基于块的多SSL融合自动流畅度评估'}
{'arxiv_id': 'arXiv:2504.15217', 'title': 'DRAGON: Distributional Rewards Optimize Diffusion Generative Models', 'authors': 'Yatong Bai, Jonah Casebeer, Somayeh Sojoudi, Nicholas J. Bryan', 'link': 'https://arxiv.org/abs/2504.15217', 'abstract': 'We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at this https URL.', 'abstract_zh': '我们都呈现了适用于生成优化的分布奖励框架（DRAGON），这是一种多功能框架，旨在根据期望结果微调媒体生成模型。与传统的基于人类反馈的强化学习（RLHF）或成对偏好方法（如直接偏好优化DPO）相比，DRAGON更具灵活性。DRAGON可以优化评估单个示例或它们的分布的奖励函数，使其兼容广泛实例、实例到分布以及分布到分布的奖励。利用这种灵活性，我们通过选择编码器和一组参考示例来构造一个示例分布，进而构建新的奖励函数。当使用跨模态编码器（如CLAP）时，参考示例可能属于不同的模态（例如，文本与音频）。然后，DRAGON收集在线和政策生成，对它们进行评分以构建积极示范集和负面集，并利用两者的对比来最大化奖励。在评估方面，我们使用20种不同的奖励函数对音频领域的文本到音乐扩散模型进行了微调，包括一个自定义的音乐美学模型、CLAP评分、Vendi多样性以及弗雷切音频距离（FAD）。我们进一步比较了单曲级和整个数据集级别的FAD设置，并消融了多种FAD编码器和参考集。在所有20个目标奖励中，DRAGON实现了81.45%的平均胜率。此外，基于示例集的奖励函数确实可以提升生成性能，并且与基于模型的奖励相当。通过适当的示例集，DRAGON在无需训练人类偏好注释的情况下实现了60.95%的人类投票音乐质量胜率。因此，DRAGON展示了设计和优化提高人类感知质量的奖励函数的新方法。示音频文件请参见此链接：https://。', 'title_zh': 'DRAGON: 分布性奖励优化扩散生成模型'}
