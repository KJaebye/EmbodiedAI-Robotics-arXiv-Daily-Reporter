{'arxiv_id': 'arXiv:2506.12012', 'title': 'Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making', 'authors': 'Xiaopeng Yuan, Xingjian Zhang, Ke Xu, Yifan Xu, Lijun Yu, Jindong Wang, Yushun Dong, Haohan Wang', 'link': 'https://arxiv.org/abs/2506.12012', 'abstract': 'Large language models (LLMs) are increasingly used for tasks that require complex reasoning. Most benchmarks focus on final outcomes but overlook the intermediate reasoning steps - such as planning, revision, and decision making under resource constraints. We argue that measuring these internal processes is essential for understanding model behavior and improving reliability. We propose using strategic games as a natural evaluation environment: closed, rule-based systems with clear states, limited resources, and automatic feedback. We introduce a framework that evaluates LLMs along three core dimensions: planning, revision, and resource-constrained decision making. To operationalize this, we define metrics beyond win rate, including overcorrection risk rate, correction success rate, improvement slope, and over-budget ratio. In 4320 adversarial rounds across 12 leading models, ChatGPT-o3-mini achieves the top composite score, with a win rate of 74.7 percent, a correction success rate of 78.6 percent, and an improvement slope of 0.041. By contrast, Qwen-Plus, despite an overcorrection risk rate of 81.6 percent, wins only 25.6 percent of its matches - primarily due to excessive resource use. We also observe a negative correlation between overcorrection risk rate and correction success rate (Pearson r = -0.51, p = 0.093), suggesting that more frequent edits do not always improve outcomes. Our findings highlight the value of assessing not only what LLMs decide but how they arrive at those decisions', 'abstract_zh': '大型语言模型（LLMs）越来越多地被用于需要复杂推理的任务。大多数基准测试侧重于最终结果，而忽略了中间推理步骤，如规划、修订以及资源约束下的决策过程。我们主张衡量这些内部过程对于理解模型行为和提高可靠性至关重要。我们提出使用战略游戏作为自然的评估环境：封闭的、基于规则的系统，具有明确的状态、有限的资源和自动反馈。我们引入了一个框架，从规划、修订和资源约束决策三个方面评估LLMs。为此，我们定义了超越胜率的指标，包括纠正过度矫正风险率、纠正成功率、改进斜率和超支比率。在涉及12款领先模型的4320场对抗轮次中，ChatGPT-o3-mini获得最高综合分数，胜率为74.7%，纠正成功率为78.6%，改进斜率为0.041。相比之下，尽管Qwen-Plus的过度矫正风险率为81.6%，但仅赢得其比赛的25.6% - 主要原因是过度使用资源。我们还发现，过度矫正风险率和纠正成功率之间存在负相关（皮尔逊r = -0.51，p = 0.093），表明频繁的编辑并不总是能改善结果。我们的研究结果强调了不仅评估LLMs决策结果，还应评估其决策过程的重要性。', 'title_zh': '使用战略博弈追踪大模型推理过程：一种计划、修订及资源约束决策制定的框架'}
{'arxiv_id': 'arXiv:2506.11986', 'title': 'Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task', 'authors': 'Wuzhenghong Wen, Su Pan, yuwei Sun', 'link': 'https://arxiv.org/abs/2506.11986', 'abstract': 'Schema linking is a critical step in Text-to-SQL task, aiming to accurately predict the table names and column names required for the SQL query based on the given question. However, current fine-tuning approaches for schema linking models employ a rote-learning paradigm, excessively optimizing for ground truth schema linking outcomes while compromising reasoning ability. This limitation arises because of the difficulty in acquiring a high-quality reasoning sample for downstream tasks. To address this, we propose Schema-R1, a reasoning schema linking model trained using reinforcement learning. Specifically, Schema-R1 consists of three key steps: constructing small batches of high-quality reasoning samples, supervised fine-tuning for cold-start initialization, and rule-based reinforcement learning training. The final results demonstrate that our method effectively enhances the reasoning ability of the schema linking model, achieving a 10\\% improvement in filter accuracy compared to the existing method. Our code is available at this https URL.', 'abstract_zh': 'Schema-R1：一种基于强化学习的推理-schema链接模型', 'title_zh': 'Schema-R1: 一种用于Text-to-SQL任务模式链接的推理训练方法'}
{'arxiv_id': 'arXiv:2506.11887', 'title': 'Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making', 'authors': 'Claudio Fanconi, Mihaela van der Schaar', 'link': 'https://arxiv.org/abs/2506.11887', 'abstract': "Effective human-AI decision-making balances three key factors: the \\textit{correctness} of predictions, the \\textit{cost} of knowledge and reasoning complexity, and the confidence about whether to \\textit{abstain} automated answers or involve human experts. In this work, we present a cascaded LLM decision framework that adaptively delegates tasks across multiple tiers of expertise -- a base model for initial candidate answers, a more capable and knowledgeable (but costlier) large model, and a human expert for when the model cascade abstains. Our method proceeds in two stages. First, a deferral policy determines whether to accept the base model's answer or regenerate it with the large model based on the confidence score. Second, an abstention policy decides whether the cascade model response is sufficiently certain or requires human intervention. Moreover, we incorporate an online learning mechanism in the framework that can leverage human feedback to improve decision quality over time. We demonstrate this approach to general question-answering (ARC-Easy and ARC-Challenge) and medical question-answering (MedQA and MedMCQA). Our results show that our cascaded strategy outperforms in most cases single-model baselines in accuracy while reducing cost and providing a principled way to handle abstentions.", 'abstract_zh': '有效的真人-AI决策平衡三种关键因素：预测的准确性、知识和推理复杂性的成本，以及是否弃用自动化答案而求助人类专家的信心。本文提出了一种级联大语言模型决策框架，该框架根据不同层次的专业能力自适应地分配任务——基础模型用于初始候选答案，更强大且知识丰富的大型模型用于生成答案，人工专家在级联模型弃用时介入。该方法分为两个阶段。首先，通过置信分数确定是否接受基础模型的答案或使用大型模型重新生成答案。其次，确定级联模型响应是否足够确定或需要人工干预。此外，我们在框架中引入了一种在线学习机制，该机制可以根据人类反馈提高决策质量。我们展示了该方法在通用问答（ARC-Easy和ARC-Challenge）和医学问答（MedQA和MedMCQA）中的应用。结果表明，与单模型基线相比，我们的级联策略在大多数情况下在准确性和成本方面表现更优，并提供了一种处理弃用的原理性方法。', 'title_zh': '面向成本效益的人机决策 Cascaded LLM 框架'}
{'arxiv_id': 'arXiv:2506.11880', 'title': 'Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment', 'authors': 'Alejandro Peña, Julian Fierrez, Aythami Morales, Gonzalo Mancera, Miguel Lopez, Ruben Tolosana', 'link': 'https://arxiv.org/abs/2506.11880', 'abstract': 'The use of language technologies in high-stake settings is increasing in recent years, mostly motivated by the success of Large Language Models (LLMs). However, despite the great performance of LLMs, they are are susceptible to ethical concerns, such as demographic biases, accountability, or privacy. This work seeks to analyze the capacity of Transformers-based systems to learn demographic biases present in the data, using a case study on AI-based automated recruitment. We propose a privacy-enhancing framework to reduce gender information from the learning pipeline as a way to mitigate biased behaviors in the final tools. Our experiments analyze the influence of data biases on systems built on two different LLMs, and how the proposed framework effectively prevents trained systems from reproducing the bias in the data.', 'abstract_zh': '近年来，语言技术在高风险场景中的应用越来越多，主要是受大型语言模型（LLMs）成功的影响。尽管LLMs表现卓越，但它们仍易受到伦理关切的影响，如人口统计偏见、问责制或隐私问题。本研究旨在分析基于变换器系统的模型学习数据中存在的人口统计偏见的能力，并通过基于AI的自动化招聘案例研究进行探讨。我们提出了一种增强隐私的框架，通过减少学习管道中的性别信息来减轻最终工具中的偏见行为。我们的实验分析了数据偏见对两种不同LLM构建的系统的影响，并研究了所提框架如何有效地防止训练系统复制数据中的偏见。', 'title_zh': '解决LLM中的偏差：策略及其在公平AI招聘中的应用'}
{'arxiv_id': 'arXiv:2506.11825', 'title': 'Revealing Political Bias in LLMs through Structured Multi-Agent Debate', 'authors': 'Aishwarya Bandaru, Fabian Bindley, Trevor Bluth, Nandini Chavda, Baixu Chen, Ethan Law', 'link': 'https://arxiv.org/abs/2506.11825', 'abstract': "Large language models (LLMs) are increasingly used to simulate social behaviour, yet their political biases and interaction dynamics in debates remain underexplored. We investigate how LLM type and agent gender attributes influence political bias using a structured multi-agent debate framework, by engaging Neutral, Republican, and Democrat American LLM agents in debates on politically sensitive topics. We systematically vary the underlying LLMs, agent genders, and debate formats to examine how model provenance and agent personas influence political bias and attitudes throughout debates. We find that Neutral agents consistently align with Democrats, while Republicans shift closer to the Neutral; gender influences agent attitudes, with agents adapting their opinions when aware of other agents' genders; and contrary to prior research, agents with shared political affiliations can form echo chambers, exhibiting the expected intensification of attitudes as debates progress.", 'abstract_zh': '大型语言模型（LLMs）在模拟社会行为方面应用日益增多，然而它们在辩论中的政治偏见及其互动动态尚未得到充分探索。我们通过一个结构化的多agent辩论框架，研究不同类型的LLM和agent性别属性如何影响政治偏见，涉及中立、共和党和民主党美国LLM agent在政治敏感话题上的辩论。我们系统地改变底层LLM、agent性别及辩论格式，以探讨模型来源和agent人设如何影响辩论过程中政治偏见和态度的变化。研究发现，中立agent始终与民主党一致，共和党则向中立靠近；性别影响agent的态度，awareness of其他agent的性别使agent调整其观点；与以往研究不同，具有共同政治隶属关系的agent可能会形成回音室效应，在辩论过程中态度趋于加强。', 'title_zh': '通过结构化多代理辩论揭示LLMs中的政治偏见'}
{'arxiv_id': 'arXiv:2506.11812', 'title': 'On the Performance of LLMs for Real Estate Appraisal', 'authors': 'Margot Geerts, Manon Reusens, Bart Baesens, Seppe vanden Broucke, Jochen De Weerdt', 'link': 'https://arxiv.org/abs/2506.11812', 'abstract': "The real estate market is vital to global economies but suffers from significant information asymmetry. This study examines how Large Language Models (LLMs) can democratize access to real estate insights by generating competitive and interpretable house price estimates through optimized In-Context Learning (ICL) strategies. We systematically evaluate leading LLMs on diverse international housing datasets, comparing zero-shot, few-shot, market report-enhanced, and hybrid prompting techniques. Our results show that LLMs effectively leverage hedonic variables, such as property size and amenities, to produce meaningful estimates. While traditional machine learning models remain strong for pure predictive accuracy, LLMs offer a more accessible, interactive and interpretable alternative. Although self-explanations require cautious interpretation, we find that LLMs explain their predictions in agreement with state-of-the-art models, confirming their trustworthiness. Carefully selected in-context examples based on feature similarity and geographic proximity, significantly enhance LLM performance, yet LLMs struggle with overconfidence in price intervals and limited spatial reasoning. We offer practical guidance for structured prediction tasks through prompt optimization. Our findings highlight LLMs' potential to improve transparency in real estate appraisal and provide actionable insights for stakeholders.", 'abstract_zh': '房地产市场对全球经济至关重要但存在显著的信息不对称。本文研究了大型语言模型（LLMs）如何通过优化上下文学习（ICL）策略生成竞争性和可解释的房价估计，从而普及房地产洞察。我们系统评估了领先LLMs在多种国际住房数据集上的表现，比较了零样本、少样本、市场报告增强以及混合提示技术。研究结果显示，LLMs能够有效地利用如房产大小和配套设施等心斌变量来生成有意义的估计。尽管传统机器学习模型在纯粹的预测准确性方面仍然强劲，但LLMs提供了更易访问、互动且可解释的替代方案。尽管自我解释需要谨慎解释，但研究表明LLMs的预测解释与领先模型一致，证实了其可信度。根据特征相似性和地理 proximity 选择的精心策划的上下文示例，显著提升了LLM的表现，但LLMs在处理价格区间上的过度自信和空间推理能力有限。本文为结构化预测任务提供了通过提示优化的实际指导。我们的研究结果突显了LLMs在提高房地产评估透明度和为利益相关者提供可操作洞察方面的潜力。', 'title_zh': 'LLMs在房地产评估中的性能研究'}
{'arxiv_id': 'arXiv:2506.11756', 'title': 'Causal Effect Identification in Heterogeneous Environments from Higher-Order Moments', 'authors': 'Yaroslav Kivva, Sina Akbari, Saber Salehkaleybar, Negar Kiyavash', 'link': 'https://arxiv.org/abs/2506.11756', 'abstract': 'We investigate the estimation of the causal effect of a treatment variable on an outcome in the presence of a latent confounder. We first show that the causal effect is identifiable under certain conditions when data is available from multiple environments, provided that the target causal effect remains invariant across these environments. Secondly, we propose a moment-based algorithm for estimating the causal effect as long as only a single parameter of the data-generating mechanism varies across environments -- whether it be the exogenous noise distribution or the causal relationship between two variables. Conversely, we prove that identifiability is lost if both exogenous noise distributions of both the latent and treatment variables vary across environments. Finally, we propose a procedure to identify which parameter of the data-generating mechanism has varied across the environments and evaluate the performance of our proposed methods through experiments on synthetic data.', 'abstract_zh': '我们在多个环境中探讨了在存在潜在混杂变量的情况下治疗变量对结果的因果效应估计问题。首先，在数据来自多个环境且目标因果效应在这些环境中保持不变的条件下，我们证明因果效应是可以识别的。其次，只要数据生成机制中有一个参数在不同环境中发生变化——无论是外生噪声分布的变化还是两个变量之间的因果关系的变化——我们提出了一种基于矩的算法来估计因果效应。相反，我们证明了如果两个变量的外生噪声分布都随环境变化，则因果效应将无法识别。最后，我们提出了一种方法来识别数据生成机制中哪个参数在不同环境中发生变化，并通过合成数据的实验评估我们提出方法的性能。', 'title_zh': '异质环境中基于高阶矩的因果效应识别'}
{'arxiv_id': 'arXiv:2506.11721', 'title': 'Relational GNNs Cannot Learn $C_2$ Features for Planning', 'authors': 'Dillon Z. Chen', 'link': 'https://arxiv.org/abs/2506.11721', 'abstract': 'Relational Graph Neural Networks (R-GNNs) are a GNN-based approach for learning value functions that can generalise to unseen problems from a given planning domain. R-GNNs were theoretically motivated by the well known connection between the expressive power of GNNs and $C_2$, first-order logic with two variables and counting. In the context of planning, $C_2$ features refer to the set of formulae in $C_2$ with relations defined by the unary and binary predicates of a planning domain. Some planning domains exhibit optimal value functions that can be decomposed as arithmetic expressions of $C_2$ features. We show that, contrary to empirical results, R-GNNs cannot learn value functions defined by $C_2$ features. We also identify prior GNN architectures for planning that may better learn value functions defined by $C_2$ features.', 'abstract_zh': '基于关系的图神经网络（R-GNNs）是一种基于图神经网络的方法，用于从给定的规划域中学习可以泛化到未见过的问题的价值函数。R-GNNs的理论动机源于图神经网络的表达能力与具有两个变量和计数的一阶逻辑$C_2$之间的已知联系。在规划的背景下，$C_2$特征是指由规划域的一元和二元谓词定义的$C_2$中的公式集。一些规划域中的最优价值函数可以分解为$C_2$特征的算术表达式。我们展示了与 empirically 结果相反，R-GNNs 无法学习由 $C_2$ 特征定义的价值函数。我们还识别出在规划中可能更好地学习由 $C_2$ 特征定义的价值函数的先前图神经网络架构。', 'title_zh': '关系GNN无法学习$C_2$特征进行规划'}
{'arxiv_id': 'arXiv:2506.11712', 'title': 'Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization', 'authors': 'Wenqi Liu, Xuemeng Song, Jiaxi Li, Yinwei Wei, Na Zheng, Jianhua Yin, Liqiang Nie', 'link': 'https://arxiv.org/abs/2506.11712', 'abstract': "Direct Preference Optimization (DPO) has emerged as an effective approach for mitigating hallucination in Multimodal Large Language Models (MLLMs). Although existing methods have achieved significant progress by utilizing vision-oriented contrastive objectives for enhancing MLLMs' attention to visual inputs and hence reducing hallucination, they suffer from non-rigorous optimization objective function and indirect preference supervision. To address these limitations, we propose a Symmetric Multimodal Preference Optimization (SymMPO), which conducts symmetric preference learning with direct preference supervision (i.e., response pairs) for visual understanding enhancement, while maintaining rigorous theoretical alignment with standard DPO. In addition to conventional ordinal preference learning, SymMPO introduces a preference margin consistency loss to quantitatively regulate the preference gap between symmetric preference pairs. Comprehensive evaluation across five benchmarks demonstrate SymMPO's superior performance, validating its effectiveness in hallucination mitigation of MLLMs.", 'abstract_zh': '直接偏好优化（DPO）已成为减轻多模态大型语言模型（MLLMs）幻觉的有效方法。为了应对现有方法存在的优化目标不严谨和偏好监督间接等局限性，我们提出了一种对称多模态偏好优化（SymMPO），它通过直接偏好监督（即响应对）进行对称偏好学习，以增强视觉理解能力，并保持与标准DPO严格的理论一致性。除了常规的序数偏好学习外，SymMPO还引入了一致性偏好边际损失，以定量调节对称偏好对之间的偏好差距。在五个基准上的全面评估表明，SymMPO 在减轻MLLMs 幻觉方面具有优越性能，验证了其有效性。', 'title_zh': '通过理论一致的对称多模态偏好优化减轻幻觉'}
{'arxiv_id': 'arXiv:2506.11604', 'title': 'VLM@school -- Evaluation of AI image understanding on German middle school knowledge', 'authors': 'René Peinl, Vincent Tischler', 'link': 'https://arxiv.org/abs/2506.11604', 'abstract': 'This paper introduces a novel benchmark dataset designed to evaluate the capabilities of Vision Language Models (VLMs) on tasks that combine visual reasoning with subject-specific background knowledge in the German language. In contrast to widely used English-language benchmarks that often rely on artificially difficult or decontextualized problems, this dataset draws from real middle school curricula across nine domains including mathematics, history, biology, and religion. The benchmark includes over 2,000 open-ended questions grounded in 486 images, ensuring that models must integrate visual interpretation with factual reasoning rather than rely on superficial textual cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple dimensions, including domain-specific accuracy and performance on adversarial crafted questions. Our findings reveal that even the strongest models achieve less than 45% overall accuracy, with particularly poor performance in music, mathematics, and adversarial settings. Furthermore, the results indicate significant discrepancies between success on popular benchmarks and real-world multimodal understanding. We conclude that middle school-level tasks offer a meaningful and underutilized avenue for stress-testing VLMs, especially in non-English contexts. The dataset and evaluation protocol serve as a rigorous testbed to better understand and improve the visual and linguistic reasoning capabilities of future AI systems.', 'abstract_zh': '这篇论文介绍了一个新型基准数据集，旨在评估视觉语言模型(VLMs)在结合视觉推理与特定学科背景知识的德语文本任务中的能力。与通常依赖于人工制造的困难或去语境化问题的广泛使用的英语基准不同，该数据集来源于涵盖数学、历史、生物和宗教等九个领域的实际初中课程。该基准包括基于486张图像的超过2000个开放性问题，确保模型必须将视觉解释与事实推理结合起来，而不能仅仅依靠表面的文字线索。我们对十三个最新的开放权重VLMs在多个维度上进行了评估，包括学科特定的准确性以及在对抗性问题上的表现。我们的研究发现，即使是最强大的模型的整体准确率也低于45%，特别是在音乐、数学和对抗性环境中表现尤为不佳。此外，结果表明，在流行基准上的成功与实际多模态理解之间存在显著差异。我们认为，初中水平的任务为测试VLMs提供了一个有意义且尚未充分利用的途径，特别是在非英语背景下。该数据集和评估协议提供了一个严格的测试平台，有助于更深入地理解并提高未来AI系统的视觉和语言推理能力。', 'title_zh': 'VLM@学校——德国中学生知识中AI图像理解的评估'}
{'arxiv_id': 'arXiv:2506.11578', 'title': 'Collaborative LLM Inference via Planning for Efficient Reasoning', 'authors': 'Byeongchan Lee, Jonghoon Lee, Dongyoung Kim, Jaehyung Kim, Jinwoo Shin', 'link': 'https://arxiv.org/abs/2506.11578', 'abstract': 'Large language models (LLMs) excel at complex reasoning tasks, but those with strong capabilities (e.g., whose numbers of parameters are larger than 100B) are often accessible only through paid APIs, making them too costly for applications of frequent use. In contrast, smaller open-sourced LLMs (e.g., whose numbers of parameters are less than 3B) are freely available and easy to deploy locally (e.g., under a single GPU having 8G VRAM), but lack suff icient reasoning ability. This trade-off raises a natural question: can small (free) and large (costly) models collaborate at test time to combine their strengths? We propose a test-time collaboration framework in which a planner model first generates a plan, defined as a distilled and high-level abstraction of the problem.\nThis plan serves as a lightweight intermediate that guides a reasoner model, which generates a complete solution. Small and large models take turns acting as planner and reasoner, exchanging plans in a multi-round cascade to collaboratively solve complex tasks. Our method achieves accuracy comparable to strong proprietary models alone, while significantly reducing reliance on paid inference. These results highlight planning as an effective prior for orchestrating cost-aware, cross-model inference under real-world deployment constraints.', 'abstract_zh': '小型免费与大型付费语言模型在测试时协作的框架及其应用', 'title_zh': '规划驱动的协作LLM推理以实现高效推理'}
{'arxiv_id': 'arXiv:2506.11555', 'title': 'RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning', 'authors': 'Yu Wang, Shiwan Zhao, Ming Fan, Zhihu Wang, Yubo Zhang, Xicheng Zhang, Zhengfan Wang, Heyuan Huang, Ting Liu', 'link': 'https://arxiv.org/abs/2506.11555', 'abstract': 'The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.', 'abstract_zh': '通过检索增强生成（RAG）整合外部知识已成为增强大型语言模型（LLMs）在知识密集型任务中表现的基础。然而，现有RAG范式往往忽视了应用知识的认知步骤，留下了检索事实与任务特定推理之间的差距。在此工作中，我们引入了RAG+，这是一种原则性的模块化扩展，明确地将应用意识推理纳入RAG流程中。RAG+构建了一个双语料库，包括知识和对齐的应用示例，这些示例可以是手工创建的，也可以是自动创建的，并在推理过程中同时检索。这种设计不仅使LLMs能够访问相关的信息，还能够在结构化、目标导向的推理过程中应用这些信息。在数学、法律和医疗等多个领域的实验结果显示，RAG+在多个模型上均表现出色，相对于标准RAG变体，平均提高了3-5%，在复杂场景中最高可达7.5%的提升。通过将检索与可操作的应用相结合，RAG+推进了更基于认知的知识整合框架，代表着向更可解释和能力强的LLMs迈出了一步。', 'title_zh': 'RAG+: 增强应用意识推理的检索增强生成'}
{'arxiv_id': 'arXiv:2506.11487', 'title': 'Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models', 'authors': 'Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, Fan Yang', 'link': 'https://arxiv.org/abs/2506.11487', 'abstract': 'Recent advancements, such as DeepSeek-Prover-V2-671B and Kimina-Prover-Preview-72B, demonstrate a prevailing trend in leveraging reinforcement learning (RL)-based large-scale training for automated theorem proving. Surprisingly, we discover that even without any training, careful neuro-symbolic coordination of existing off-the-shelf reasoning models and tactic step provers can achieve comparable performance. This paper introduces \\textbf{DSP+}, an improved version of the Draft, Sketch, and Prove framework, featuring a \\emph{fine-grained and integrated} neuro-symbolic enhancement for each phase: (1) In the draft phase, we prompt reasoning models to generate concise natural-language subgoals to benefit the sketch phase, removing thinking tokens and references to human-written proofs; (2) In the sketch phase, subgoals are autoformalized with hypotheses to benefit the proving phase, and sketch lines containing syntactic errors are masked according to predefined rules; (3) In the proving phase, we tightly integrate symbolic search methods like Aesop with step provers to establish proofs for the sketch subgoals. Experimental results show that, without any additional model training or fine-tuning, DSP+ solves 80.7\\%, 32.8\\%, and 24 out of 644 problems from miniF2F, ProofNet, and PutnamBench, respectively, while requiring fewer budgets compared to state-of-the-arts. DSP+ proves \\texttt{imo\\_2019\\_p1}, an IMO problem in miniF2F that is not solved by any prior work. Additionally, DSP+ generates proof patterns comprehensible by human experts, facilitating the identification of formalization errors; For example, eight wrongly formalized statements in miniF2F are discovered. Our results highlight the potential of classical reasoning patterns besides the RL-based training. All components will be open-sourced.', 'abstract_zh': '近年来，如DeepSeek-Prover-V2-671B和Kimina-Prover-Preview-72B等的最新进展表明，通过基于强化学习（RL）的大规模训练自动定理证明的趋势主导地位。令人惊讶的是，我们发现即使没有任何训练，精心设计的神经符号协调也能实现与现有方法相当的性能。本文介绍了DSP+，这是一个改进版本的Draft、Sketch和Prove框架，每个阶段都具有精细整合的神经符号增强：（1）在Draft阶段，我们提示推理模型生成简洁的自然语言子目标以利于Sketch阶段，并移除思考标记和对人工证明的引用；（2）在Sketch阶段，子目标自形式化并添加假设以利于证明阶段，并根据预定义规则屏蔽包含语法错误的Sketch线；（3）在Proving阶段，我们将符号搜索方法（如Aesop）与步骤证明器紧密集成，以建立Sketch子目标的证明。实验结果表明，DSP+在无需额外模型训练或微调的情况下，分别解决了miniF2F、ProofNet和PutnamBench中的644个问题中的80.7%、32.8%和24个问题，同时相比最先进的方法所需预算更少。DSP+证明了miniF2F中的IMO问题imo_2019_p1，这是所有先前工作都无法解决的问题。此外，DSP+生成了可由人类专家理解的证明模式，有助于识别形式化错误；例如，发现了miniF2F中的八个误形式化陈述。我们的结果突显了除了基于RL的训练之外，经典推理模式的潜力。所有组件将开源。', 'title_zh': '在推理模型时代 revitalizing DSP 以实现高级定理证明'}
{'arxiv_id': 'arXiv:2506.11469', 'title': 'Structure-Aware Automatic Channel Pruning by Searching with Graph Embedding', 'authors': 'Zifan Liu, Yuan Cao, Yanwei Yu, Heng Qi, Jie Gui', 'link': 'https://arxiv.org/abs/2506.11469', 'abstract': 'Channel pruning is a powerful technique to reduce the computational overhead of deep neural networks, enabling efficient deployment on resource-constrained devices. However, existing pruning methods often rely on local heuristics or weight-based criteria that fail to capture global structural dependencies within the network, leading to suboptimal pruning decisions and degraded model performance. To address these limitations, we propose a novel structure-aware automatic channel pruning (SACP) framework that utilizes graph convolutional networks (GCNs) to model the network topology and learn the global importance of each channel. By encoding structural relationships within the network, our approach implements topology-aware pruning and this pruning is fully automated, reducing the need for human intervention. We restrict the pruning rate combinations to a specific space, where the number of combinations can be dynamically adjusted, and use a search-based approach to determine the optimal pruning rate combinations. Extensive experiments on benchmark datasets (CIFAR-10, ImageNet) with various models (ResNet, VGG16) demonstrate that SACP outperforms state-of-the-art pruning methods on compression efficiency and competitive on accuracy retention.', 'abstract_zh': '基于图形卷积网络的结构感知自动通道剪枝框架', 'title_zh': '基于图嵌入搜索的结构感知自动通道剪枝'}
{'arxiv_id': 'arXiv:2506.11445', 'title': 'Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention', 'authors': 'Xuan Duy Ta, Bang Giang Le, Thanh Ha Le, Viet Cuong Ta', 'link': 'https://arxiv.org/abs/2506.11445', 'abstract': "In mixed-traffic environments, autonomous vehicles must adapt to human-controlled vehicles and other unusual driving situations. This setting can be framed as a multi-agent reinforcement learning (MARL) environment with full cooperative reward among the autonomous vehicles. While methods such as Multi-agent Proximal Policy Optimization can be effective in training MARL tasks, they often fail to resolve local conflict between agents and are unable to generalize to stochastic events. In this paper, we propose a Local State Attention module to assist the input state representation. By relying on the self-attention operator, the module is expected to compress the essential information of nearby agents to resolve the conflict in traffic situations. Utilizing a simulated highway merging scenario with the priority vehicle as the unexpected event, our approach is able to prioritize other vehicles' information to manage the merging process. The results demonstrate significant improvements in merging efficiency compared to popular baselines, especially in high-density traffic settings.", 'abstract_zh': '在混合交通环境中，自动驾驶车辆必须适应由人类控制的车辆和其他异常驾驶情况。这一设置可以被视为一种多智能体强化学习（MARL）环境，其中自动驾驶车辆之间具有完全合作的奖励方式。虽然诸如Multi-agent Proximal Policy Optimization等方法在训练MARL任务时可能有效，但它们通常无法解决智能体之间的局部冲突，也无法泛化到随机事件。在本文中，我们提出了一种局部状态注意力模块来辅助输入状态表示。通过依赖自注意力操作符，该模块期望压缩附近智能体的关键信息以在交通情况下解决冲突。利用具有优先车辆的模拟高速公路变道场景作为意外事件，我们的方法能够优先处理其他车辆的信息，以管理变道过程。结果表明，与流行的基准方法相比，在高密度交通环境中，我们的方法在合并效率上取得了显著提升。', 'title_zh': '基于局部状态注意力的多自主车辆控制中解决高速公路冲突问题'}
{'arxiv_id': 'arXiv:2506.11419', 'title': 'FocalAD: Local Motion Planning for End-to-End Autonomous Driving', 'authors': 'Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song', 'link': 'https://arxiv.org/abs/2506.11419', 'abstract': 'In end-to-end autonomous driving,the motion prediction plays a pivotal role in ego-vehicle planning. However, existing methods often rely on globally aggregated motion features, ignoring the fact that planning decisions are primarily influenced by a small number of locally interacting agents. Failing to attend to these critical local interactions can obscure potential risks and undermine planning reliability. In this work, we propose FocalAD, a novel end-to-end autonomous driving framework that focuses on critical local neighbors and refines planning by enhancing local motion representations. Specifically, FocalAD comprises two core modules: the Ego-Local-Agents Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a graph-based ego-centric interaction representation that captures motion dynamics with local neighbors to enhance both ego planning and agent motion queries. FLA Loss increases the weights of decision-critical neighboring agents, guiding the model to prioritize those more relevant to planning. Extensive experiments show that FocalAD outperforms existing state-of-the-art methods on the open-loop nuScenes datasets and closed-loop Bench2Drive benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD achieves even greater improvements, reducing the average colilision rate by 41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.', 'abstract_zh': '在端到端自动驾驶中，运动预测在ego车辆规划中起着关键作用。然而，现有方法往往依赖于全局聚合的运动特征，忽视了规划决策主要由少数本地交互代理所驱动的事实。未能关注这些关键的本地交互可能会掩盖潜在风险并削弱规划可靠性。在本工作中，我们提出了FocalAD，这是一种新颖的端到端自动驾驶框架，专注于关键的本地邻居并通过增强局部运动表示来优化规划。具体而言，FocalAD 包含两个核心模块：Ego-Local-Agents Interactor (ELAI) 和 Focal-Local-Agents Loss (FLA Loss)。ELAI 进行基于图的以自我为中心的交互表示，利用局部邻居捕捉运动动态，以增强ego规划和代理运动查询。FLA Loss 增加了决策关键邻近代理的权重，引导模型优先考虑那些与规划更相关的代理。广泛的实验表明，FocalAD 在开放环nuScenes数据集和闭环Bench2Drive基准测试上优于现有最先进的方法。值得注意的是，在重点关注鲁棒性的Adv-nuScenes数据集上，FocalAD 甚至取得了更大的改进，将平均碰撞率降低了41.9%，相比DiffusionDrive降低了15.6%。', 'title_zh': 'FocalAD: 局部运动规划用于端到端自动驾驶'}
{'arxiv_id': 'arXiv:2506.11376', 'title': 'Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning', 'authors': 'Liying Wang, Ph.D., Daffodil Carrington, M.S., Daniil Filienko, M.S., Caroline El Jazmi, M.S., Serena Jinchen Xie, M.S., Martine De Cock, Ph.D., Sarah Iribarren, Ph.D., Weichao Yuwen, Ph.D', 'link': 'https://arxiv.org/abs/2506.11376', 'abstract': "Family caregivers often face substantial mental health challenges due to their multifaceted roles and limited resources. This study explored the potential of a large language model (LLM)-powered conversational agent to deliver evidence-based mental health support for caregivers, specifically Problem-Solving Therapy (PST) integrated with Motivational Interviewing (MI) and Behavioral Chain Analysis (BCA). A within-subject experiment was conducted with 28 caregivers interacting with four LLM configurations to evaluate empathy and therapeutic alliance. The best-performing models incorporated Few-Shot and Retrieval-Augmented Generation (RAG) prompting techniques, alongside clinician-curated examples. The models showed improved contextual understanding and personalized support, as reflected by qualitative responses and quantitative ratings on perceived empathy and therapeutic alliances. Participants valued the model's ability to validate emotions, explore unexpressed feelings, and provide actionable strategies. However, balancing thorough assessment with efficient advice delivery remains a challenge. This work highlights the potential of LLMs in delivering empathetic and tailored support for family caregivers.", 'abstract_zh': '家庭照护者因其多重角色和有限资源而常面临显著的心理健康挑战。本研究探讨了大型语言模型（LLM）驱动的对话代理交付基于证据的心理健康支持的潜力，特别是将解决问题疗法（PST）与动机访谈（MI）和行为链分析（BCA）相结合。研究采用被试内实验设计，28名家庭照护者与四种LLM配置互动，评估其共情和治疗联盟。性能最佳的模型结合了少样本学习和检索增强生成（RAG）提示技术，并辅以临床人员定制的示例。这些模型在背景理解和个性化支持方面表现出改进，这一改进反映在定性反馈和定量评估中，参与者对模型的共情能力和治疗联盟的感知有所提升。参与者赞赏模型验证情绪、探索未表达的情感以及提供可操作策略的能力。然而，如何在全面评估的同时高效提供建议仍是一项挑战。本研究突显了LLM在为家庭照护者提供具有同理心和个性化支持方面的潜力。', 'title_zh': '大型语言模型驱动的对话代理为家庭护理人员提供问题解决疗法（PST）：通过上下文学习增强共情与治疗联盟'}
{'arxiv_id': 'arXiv:2506.11375', 'title': 'Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables', 'authors': 'Yitong Zhou, Mingyue Cheng, Qingyang Mao, Yucong Luo, Qi Liu, Yupeng Li, Xiaohan Zhang, Deguang Liu, Xin Li, Enhong Chen', 'link': 'https://arxiv.org/abs/2506.11375', 'abstract': 'Chemical tables encode complex experimental knowledge through symbolic expressions, structured variables, and embedded molecular graphics. Existing benchmarks largely overlook this multimodal and domain-specific complexity, limiting the ability of multimodal large language models to support scientific understanding in chemistry. In this work, we introduce ChemTable, a large-scale benchmark of real-world chemical tables curated from the experimental sections of literature. ChemTable includes expert-annotated cell polygons, logical layouts, and domain-specific labels, including reagents, catalysts, yields, and graphical components and supports two core tasks: (1) Table Recognition, covering structure parsing and content extraction; and (2) Table Understanding, encompassing both descriptive and reasoning-oriented question answering grounded in table structure and domain semantics. We evaluated a range of representative multimodal models, including both open-source and closed-source models, on ChemTable and reported a series of findings with practical and conceptual insights. Although models show reasonable performance on basic layout parsing, they exhibit substantial limitations on both descriptive and inferential QA tasks compared to human performance, and we observe significant performance gaps between open-source and closed-source models across multiple dimensions. These results underscore the challenges of chemistry-aware table understanding and position ChemTable as a rigorous and realistic benchmark for advancing scientific reasoning.', 'abstract_zh': 'ChemTable: 大规模化学表格基准，包含专家注释的单元格多边形、逻辑布局和领域特定标签，支持表格识别和理解核心任务', 'title_zh': '多模态LLM在化学表格识别与理解上的基准测试'}
{'arxiv_id': 'arXiv:2506.11331', 'title': 'MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification', 'authors': 'Jihoon Yun, Chengzhang Li, Dhrubojyoti Roy, Anish Arora', 'link': 'https://arxiv.org/abs/2506.11331', 'abstract': 'Unsupervised Domain Adaptation (UDA) is essential for adapting machine learning models to new, unlabeled environments where data distribution shifts can degrade performance. Existing UDA algorithms are designed for single-label tasks and rely on significant computational resources, limiting their use in multi-label scenarios and in resource-constrained IoT devices. Overcoming these limitations is particularly challenging in contexts such as urban sound classification, where overlapping sounds and varying acoustics require robust, adaptive multi-label capabilities on low-power, on-device systems. To address these limitations, we introduce Mote-scale Unsupervised Domain Adaptation for Sounds (MUDAS), a UDA framework developed for multi-label sound classification in resource-constrained IoT settings. MUDAS efficiently adapts models by selectively retraining the classifier in situ using high-confidence data, minimizing computational and memory requirements to suit on-device deployment. Additionally, MUDAS incorporates class-specific adaptive thresholds to generate reliable pseudo-labels and applies diversity regularization to improve multi-label classification accuracy. In evaluations on the SONYC Urban Sound Tagging (SONYC-UST) dataset recorded at various New York City locations, MUDAS demonstrates notable improvements in classification accuracy over existing UDA algorithms, achieving good performance in a resource-constrained IoT setting.', 'abstract_zh': '多标签声学领域自适应：面向资源受限物联网设备的小尺度无监督领域自适应（MUDAS）', 'title_zh': 'MUDAS：多标签声学分类中的细粒度无监督域适应'}
{'arxiv_id': 'arXiv:2506.11221', 'title': 'LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic', 'authors': 'Weibing Zheng, Laurah Turner, Jess Kropczynski, Murat Ozer, Tri Nguyen, Shane Halse', 'link': 'https://arxiv.org/abs/2506.11221', 'abstract': "Clinical communication skills are critical in medical education, and practicing and assessing clinical communication skills on a scale is challenging. Although LLM-powered clinical scenario simulations have shown promise in enhancing medical students' clinical practice, providing automated and scalable clinical evaluation that follows nuanced physician judgment is difficult. This paper combines fuzzy logic and Large Language Model (LLM) and proposes LLM-as-a-Fuzzy-Judge to address the challenge of aligning the automated evaluation of medical students' clinical skills with subjective physicians' preferences. LLM-as-a-Fuzzy-Judge is an approach that LLM is fine-tuned to evaluate medical students' utterances within student-AI patient conversation scripts based on human annotations from four fuzzy sets, including Professionalism, Medical Relevance, Ethical Behavior, and Contextual Distraction. The methodology of this paper started from data collection from the LLM-powered medical education system, data annotation based on multidimensional fuzzy sets, followed by prompt engineering and the supervised fine-tuning (SFT) of the pre-trained LLMs using these human annotations. The results show that the LLM-as-a-Fuzzy-Judge achieves over 80\\% accuracy, with major criteria items over 90\\%, effectively leveraging fuzzy logic and LLM as a solution to deliver interpretable, human-aligned assessment. This work suggests the viability of leveraging fuzzy logic and LLM to align with human preferences, advances automated evaluation in medical education, and supports more robust assessment and judgment practices. The GitHub repository of this work is available at this https URL", 'abstract_zh': '临床沟通技能是医学教育中的关键要素，而在量级上实践和评估这些技能具有挑战性。尽管由大语言模型（LLM）驱动的临床情景模拟在提升医学生临床实践方面展现了一定潜力，但按照细微的医师判断提供自动化的、可扩展的临床评估仍然困难重重。本文结合模糊逻辑和大语言模型（LLM），提出了一种“LLM作为模糊法官”的方法，以解决自动评估医学生临床技能与主观医师偏好对齐的挑战。该方法基于人类注释，对医学生在学生-AI患者对话剧本中的言论进行评估，评估维度包括专业性、医学相关性、伦理行为和环境干扰四个模糊集。本文的方法从LLM驱动的医学教育系统的数据收集开始，基于多维模糊集的数据标注，随后进行提示工程并使用这些人类注释来监督预训练的大语言模型的微调。结果表明，“LLM作为模糊法官”实现了超过80%的准确率，主要标准项超过90%，有效地利用了模糊逻辑和大语言模型，以实现解释性、与人类偏好对齐的评估。这项工作表明，利用模糊逻辑和大语言模型来与人类偏好对齐是可行的，推动了医学教育中自动评估的发展，并支持了更稳健的评估和判断实践。相关GitHub仓库可在以下链接获取。', 'title_zh': 'LLM-as-a-模糊法官：基于模糊逻辑 fine-tuning 大型语言模型作为临床评估法官'}
{'arxiv_id': 'arXiv:2506.11023', 'title': 'OntoGSN: An Ontology for Dynamic Management of Assurance Cases', 'authors': 'Tomas Bueno Momcilovic, Barbara Gallina, Ingmar Kessler, Dian Balta', 'link': 'https://arxiv.org/abs/2506.11023', 'abstract': "Assurance cases (ACs) are a common artifact for building and maintaining confidence in system properties such as safety or robustness. Constructing an AC can be challenging, although existing tools provide support in static, document-centric applications and methods for dynamic contexts (e.g., autonomous driving) are emerging. Unfortunately, managing ACs remains a challenge, since maintaining the embedded knowledge in the face of changes requires substantial effort, in the process deterring developers - or worse, producing poorly managed cases that instill false confidence. To address this, we present OntoGSN: an ontology and supporting middleware for managing ACs in the Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge representation and a queryable graph that can be automatically populated, evaluated, and updated. Our contributions include: a 1:1 formalization of the GSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology and parser for integration with a widely used AC tool; a repository and documentation of design decisions for OntoGSN maintenance; a SPARQL query library with automation patterns; and a prototypical interface. The ontology strictly adheres to the standard's text and has been evaluated according to FAIR principles, the OOPS framework, competency questions, and community feedback. The development of other middleware elements is guided by the community needs and subject to ongoing evaluations. To demonstrate the utility of our contributions, we illustrate dynamic AC management in an example involving assurance of adversarial robustness in large language models.", 'abstract_zh': '基于目标结构表示的保证案例管理ontology和middleware：OntoGSN及其在大语言模型对抗鲁棒性保证中的应用', 'title_zh': 'OntoGSN: 一种保障案例动态管理本体'}
{'arxiv_id': 'arXiv:2506.11012', 'title': 'A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects', 'authors': 'Guanglin Niu, Bo Li, Yangguang Lin', 'link': 'https://arxiv.org/abs/2506.11012', 'abstract': 'Knowledge graphs (KGs) have emerged as a powerful paradigm for structuring and leveraging diverse real-world knowledge, which serve as a fundamental technology for enabling cognitive intelligence systems with advanced understanding and reasoning capabilities. Knowledge graph reasoning (KGR) aims to infer new knowledge based on existing facts in KGs, playing a crucial role in applications such as public security intelligence, intelligent healthcare, and financial risk assessment. From a task-centric perspective, existing KGR approaches can be broadly classified into static single-step KGR, static multi-step KGR, dynamic KGR, multi-modal KGR, few-shot KGR, and inductive KGR. While existing surveys have covered these six types of KGR tasks, a comprehensive review that systematically summarizes all KGR tasks particularly including downstream applications and more challenging reasoning paradigms remains lacking. In contrast to previous works, this survey provides a more comprehensive perspective on the research of KGR by categorizing approaches based on primary reasoning tasks, downstream application tasks, and potential challenging reasoning tasks. Besides, we explore advanced techniques, such as large language models (LLMs), and their impact on KGR. This work aims to highlight key research trends and outline promising future directions in the field of KGR.', 'abstract_zh': '知识图谱推理：基于任务的综合研究与未来方向', 'title_zh': '面向任务的知识图谱推理综述：现状、应用与前景'}
{'arxiv_id': 'arXiv:2506.12015', 'title': 'EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction', 'authors': 'Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang', 'link': 'https://arxiv.org/abs/2506.12015', 'abstract': 'Open-source foundation models have seen rapid adoption and development, enabling powerful general-purpose capabilities across diverse domains. However, fine-tuning large foundation models for domain-specific or personalized tasks remains prohibitively expensive for most users due to the significant memory overhead beyond that of inference. We introduce EMLoC, an Emulator-based Memory-efficient fine-tuning framework with LoRA Correction, which enables model fine-tuning within the same memory budget required for inference. EMLoC constructs a task-specific light-weight emulator using activation-aware singular value decomposition (SVD) on a small downstream calibration set. Fine-tuning then is performed on this lightweight emulator via LoRA. To tackle the misalignment between the original model and the compressed emulator, we propose a novel compensation algorithm to correct the fine-tuned LoRA module, which thus can be merged into the original model for inference. EMLoC supports flexible compression ratios and standard training pipelines, making it adaptable to a wide range of applications. Extensive experiments demonstrate that EMLoC outperforms other baselines across multiple datasets and modalities. Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on a single 24GB consumer GPU-bringing efficient and practical model adaptation to individual users.', 'abstract_zh': '基于插值器的LoRA校正轻量级细调框架EMLoC：在相同内存预算下实现高效自定义模型细调', 'title_zh': 'EMLoC：基于模拟器的内存高效微调与LoRA修正'}
{'arxiv_id': 'arXiv:2506.12014', 'title': 'code_transformed: The Influence of Large Language Models on Code', 'authors': 'Yuliang Xu, Siming Huang, Mingmeng Geng, Yao Wan, Xuanhua Shi, Dongping Chen', 'link': 'https://arxiv.org/abs/2506.12014', 'abstract': 'Coding remains one of the most fundamental modes of interaction between humans and machines. With the rapid advancement of Large Language Models (LLMs), code generation capabilities have begun to significantly reshape programming practices. This development prompts a central question: Have LLMs transformed code style, and how can such transformation be characterized? In this paper, we present a pioneering study that investigates the impact of LLMs on code style, with a focus on naming conventions, complexity, maintainability, and similarity. By analyzing code from over 19,000 GitHub repositories linked to arXiv papers published between 2020 and 2025, we identify measurable trends in the evolution of coding style that align with characteristics of LLM-generated code. For instance, the proportion of snake\\_case variable names in Python code increased from 47% in Q1 2023 to 51% in Q1 2025. Furthermore, we investigate how LLMs approach algorithmic problems by examining their reasoning processes. Given the diversity of LLMs and usage scenarios, among other factors, it is difficult or even impossible to precisely estimate the proportion of code generated or assisted by LLMs. Our experimental results provide the first large-scale empirical evidence that LLMs affect real-world programming style.', 'abstract_zh': '大型语言模型对编码风格的影响：以命名规范、复杂度、可维护性和相似性为中心的研究', 'title_zh': '代码转换：大型语言模型对代码的影响'}
{'arxiv_id': 'arXiv:2506.12008', 'title': 'Reimagining Dance: Real-time Music Co-creation between Dancers and AI', 'authors': 'Olga Vechtomova, Jeff Bos', 'link': 'https://arxiv.org/abs/2506.12008', 'abstract': 'Dance performance traditionally follows a unidirectional relationship where movement responds to music. While AI has advanced in various creative domains, its application in dance has primarily focused on generating choreography from musical input. We present a system that enables dancers to dynamically shape musical environments through their movements. Our multi-modal architecture creates a coherent musical composition by intelligently combining pre-recorded musical clips in response to dance movements, establishing a bidirectional creative partnership where dancers function as both performers and composers. Through correlation analysis of performance data, we demonstrate emergent communication patterns between movement qualities and audio features. This approach reconceptualizes the role of AI in performing arts as a responsive collaborator that expands possibilities for both professional dance performance and improvisational artistic expression across broader populations.', 'abstract_zh': '舞蹈表演传统上遵循单向关系，其中动作响应音乐。尽管人工智能在各种创意领域中取得了进步，其在舞蹈中的应用主要集中在从音乐输入生成编舞上。我们提出了一种系统，使舞者能够通过其动作动态塑造音乐环境。我们的多模态架构通过智能组合响应舞蹈动作的预录制音乐片段，创建一个一致的音乐作品，建立起一种双向创作伙伴关系，其中舞者既是表演者也是作曲家。通过对表演数据的相关性分析，我们展示了运动品质与音频特征之间新兴的交流模式。这种方法重新定义了人工智能在表演艺术中的角色，作为一种响应式的合作者，它扩展了专业舞蹈表演和广泛人群中的即兴艺术表达的可能性。', 'title_zh': '重建舞蹈：舞者与AI的实时音乐共创'}
{'arxiv_id': 'arXiv:2506.12003', 'title': 'Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?', 'authors': 'Ramesh Raskar, Pradyumna Chari, Jared James Grogan, Mahesh Lambe, Robert Lincourt, Raghu Bala, Abhishek Singh, Ayush Chopra, Rajesh Ranjan, Shailja Gupta, Dimitris Stripelis, Maria Gorskikh, Sichao Wang', 'link': 'https://arxiv.org/abs/2506.12003', 'abstract': 'The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built registry architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized registries for critical agents and federated meshes for specialized use cases.', 'abstract_zh': '基于AI代理的新兴互联网挑战现有为人类反应性交互设计的网络基础设施。', 'title_zh': '升级还是切换：我们需要一个新的注册架构来支持人工智能代理的互联网吗？'}
{'arxiv_id': 'arXiv:2506.11991', 'title': 'VGR: Visual Grounded Reasoning', 'authors': 'Jiacong Wang, Zijiang Kang, Haochen Wang, Haiyong Jiang, Jiawen Li, Bohong Wu, Ya Wang, Jiao Ran, Xiao Liang, Chao Feng, Jun Xiao', 'link': 'https://arxiv.org/abs/2506.11991', 'abstract': 'In the field of multimodal chain-of-thought (CoT) reasoning, existing approaches predominantly rely on reasoning on pure language space, which inherently suffers from language bias and is largely confined to math or science domains. This narrow focus limits their ability to handle complex visual reasoning tasks that demand comprehensive understanding of image details. To address these limitations, this paper introduces VGR, a novel reasoning multimodal large language model (MLLM) with enhanced fine-grained visual perception capabilities. Unlike traditional MLLMs that answer the question or reasoning solely on the language space, our VGR first detects relevant regions that may help to solve problems, and then provides precise answers based on replayed image regions. To achieve this, we conduct a large-scale SFT dataset called VGR -SFT that contains reasoning data with mixed vision grounding and language deduction. The inference pipeline of VGR allows the model to choose bounding boxes for visual reference and a replay stage is introduced to integrates the corresponding regions into the reasoning process, enhancing multimodel comprehension. Experiments on the LLaVA-NeXT-7B baseline show that VGR achieves superior performance on multi-modal benchmarks requiring comprehensive image detail understanding. Compared to the baseline, VGR uses only 30\\% of the image token count while delivering scores of +4.1 on MMStar, +7.1 on AI2D, and a +12.9 improvement on ChartQA.', 'abstract_zh': '多模态链式推理中的视觉推理引导模型 (VGR)', 'title_zh': '视觉定位推理 VGR'}
{'arxiv_id': 'arXiv:2506.11954', 'title': 'Technical Evaluation of a Disruptive Approach in Homomorphic AI', 'authors': 'Eric Filiol', 'link': 'https://arxiv.org/abs/2506.11954', 'abstract': 'We present a technical evaluation of a new, disruptive cryptographic approach to data security, known as HbHAI (Hash-based Homomorphic Artificial Intelligence). HbHAI is based on a novel class of key-dependent hash functions that naturally preserve most similarity properties, most AI algorithms rely on. As a main claim, HbHAI makes now possible to analyze and process data in its cryptographically secure form while using existing native AI algorithms without modification, with unprecedented performances compared to existing homomorphic encryption schemes.\nWe tested various HbHAI-protected datasets (non public preview) using traditional unsupervised and supervised learning techniques (clustering, classification, deep neural networks) with classical unmodified AI algorithms. This paper presents technical results from an independent analysis conducted with those different, off-the-shelf AI algorithms. The aim was to assess the security, operability and performance claims regarding HbHAI techniques. As a results, our results confirm most these claims, with only a few minor reservations.', 'abstract_zh': '一种基于哈希的同态人工智能（HbHAI）的技術評估：/security-and-operability-assessment-of-hash-based-homomorphic-artificial-intelligence-hbhai-techniques', 'title_zh': '同态AI中的颠覆性方法的技术评估'}
{'arxiv_id': 'arXiv:2506.11948', 'title': 'SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies', 'authors': 'Nadun Ranawaka Arachchige, Zhenyang Chen, Wonsuhk Jung, Woo Chul Shin, Rohan Bansal, Pierre Barroso, Yu Hang He, Yingyang Celine Lin, Benjamin Joffe, Shreyas Kousik, Danfei Xu', 'link': 'https://arxiv.org/abs/2506.11948', 'abstract': 'Offline Imitation Learning (IL) methods such as Behavior Cloning are effective at acquiring complex robotic manipulation skills. However, existing IL-trained policies are confined to executing the task at the same speed as shown in demonstration data. This limits the task throughput of a robotic system, a critical requirement for applications such as industrial automation. In this paper, we introduce and formalize the novel problem of enabling faster-than-demonstration execution of visuomotor policies and identify fundamental challenges in robot dynamics and state-action distribution shifts. We instantiate the key insights as SAIL (Speed Adaptation for Imitation Learning), a full-stack system integrating four tightly-connected components: (1) a consistency-preserving action inference algorithm for smooth motion at high speed, (2) high-fidelity tracking of controller-invariant motion targets, (3) adaptive speed modulation that dynamically adjusts execution speed based on motion complexity, and (4) action scheduling to handle real-world system latencies. Experiments on 12 tasks across simulation and two real, distinct robot platforms show that SAIL achieves up to a 4x speedup over demonstration speed in simulation and up to 3.2x speedup in the real world. Additional detail is available at this https URL', 'abstract_zh': 'Offlineimitation学习（IL）方法如行为克隆在获取复杂的机器人操作技能方面是有效的。然而，现有的IL训练策略仅限于以演示数据中所示的速度执行任务。这限制了机器人系统的任务处理速率，这是诸如工业自动化等应用中的一个关键要求。在本文中，我们引入并形式化了使感知运动策略以演示数据速度以上的速率执行的新型问题，并识别出机器人动力学和状态-动作分布转移中的基本挑战。我们以SAIL（速度适应的模仿学习）为关键洞察点实现这一目标，它是一个集成了四个紧密连接组件的全栈系统：（1）一种保持一致性的动作推断算法，用于高速下的平滑运动；（2）高度保真的控制器不变运动目标跟踪；（3）适应性的速度调节，基于运动复杂性动态调整执行速度；（4）动作调度以处理实际系统延迟。在模拟和两个真实、不同的机器人平台上进行的12项任务实验表明，SAIL在模拟中实现了演示速度4倍以上的加速，在现实世界中实现了3.2倍以上的加速。更多详细信息请参见此链接：this https URL。', 'title_zh': 'SAIL：比演示更快执行 imitation 学习策略'}
{'arxiv_id': 'arXiv:2506.11945', 'title': 'Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?', 'authors': 'Noemi Dreksler, Lucius Caviola, David Chalmers, Carter Allen, Alex Rand, Joshua Lewis, Philip Waggoner, Kate Mays, Jeff Sebo', 'link': 'https://arxiv.org/abs/2506.11945', 'abstract': 'We surveyed 582 AI researchers who have published in leading AI venues and 838 nationally representative US participants about their views on the potential development of AI systems with subjective experience and how such systems should be treated and governed. When asked to estimate the chances that such systems will exist on specific dates, the median responses were 1% (AI researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by 2100, respectively. The median member of the public thought there was a higher chance that AI systems with subjective experience would never exist (25%) than the median AI researcher did (10%). Both groups perceived a need for multidisciplinary expertise to assess AI subjective experience. Although support for welfare protections for such AI systems exceeded opposition, it remained far lower than support for protections for animals or the environment. Attitudes toward moral and governance issues were divided in both groups, especially regarding whether such systems should be created and what rights or protections they should receive. Yet a majority of respondents in both groups agreed that safeguards against the potential risks from AI systems with subjective experience should be implemented by AI developers now, and if created, AI systems with subjective experience should treat others well, behave ethically, and be held accountable. Overall, these results suggest that both AI researchers and the public regard the emergence of AI systems with subjective experience as a possibility this century, though substantial uncertainty and disagreement remain about the timeline and appropriate response.', 'abstract_zh': '我们对582位发表在顶级AI会议上的AI研究人员和838位具有全国代表性的美国公众进行了调查，了解他们对具有主观体验的AI系统潜在发展的看法以及这些系统应如何被处理和治理。当被要求估算这些系统在特定日期存在的可能性时，中位数回答显示，2024年研究人员的预测为1%，公众的预测为5%；2034年分别为25%和30%；2100年分别为70%和60%。公众的中位数成员比研究人员认为具有主观体验的AI系统永远不会存在的概率更高（25%比10%）。两组都认识到需要跨学科专业知识来评估AI的主观体验。尽管人们对为这些AI系统提供福利保护的支持超过了反对，但这种支持远远低于对动物或环境保护的支持。关于道德和治理问题的态度在两组中存在分歧，尤其是在是否应该创建这些系统以及它们应获得哪些权利或保护方面意见尤其分歧。然而，两组的大多数受访者都同意应该由AI开发者现在实施针对具有主观体验的AI系统的潜在风险的保护措施，并且如果创建了这些系统，它们应该对待他人友好、行为得当并承担责任。总体而言，这些结果表明，虽然AI研究人员和公众都认同这一世纪可能会出现具有主观体验的AI系统，但关于时间表和适当响应仍然存在显著的不确定性与分歧。', 'title_zh': 'AI系统中的主观体验：研究人员与公众的看法如何？'}
{'arxiv_id': 'arXiv:2506.11939', 'title': "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", 'authors': 'Ranindya Paramitha, Yuan Feng, Fabio Massacci', 'link': 'https://arxiv.org/abs/2506.11939', 'abstract': "Vulnerability datasets used for ML testing implicitly contain retrospective information. When tested on the field, one can only use the labels available at the time of training and testing (e.g. seen and assumed negatives). As vulnerabilities are discovered across calendar time, labels change and past performance is not necessarily aligned with future performance. Past works only considered the slices of the whole history (e.g. DiverseVUl) or individual differences between releases (e.g. Jimenez et al. ESEC/FSE 2019). Such approaches are either too optimistic in training (e.g. the whole history) or too conservative (e.g. consecutive releases). We propose a method to restructure a dataset into a series of datasets in which both training and testing labels change to account for the knowledge available at the time. If the model is actually learning, it should improve its performance over time as more data becomes available and data becomes more stable, an effect that can be checked with the Mann-Kendall test. We validate our methodology for vulnerability detection with 4 time-based datasets (3 projects from BigVul dataset + Vuldeepecker's NVD) and 5 ML models (Code2Vec, CodeBERT, LineVul, ReGVD, and Vuldeepecker). In contrast to the intuitive expectation (more retrospective information, better performance), the trend results show that performance changes inconsistently across the years, showing that most models are not learning.", 'abstract_zh': '基于时间的漏洞数据集在机器学习测试中的复现性问题及改进方法', 'title_zh': '今天的猫是明天的狗：考虑ML漏洞检测方法中基于时间的标签变化'}
{'arxiv_id': 'arXiv:2506.11938', 'title': 'Improving Large Language Model Safety with Contrastive Representation Learning', 'authors': 'Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin', 'link': 'https://arxiv.org/abs/2506.11938', 'abstract': 'Large Language Models (LLMs) are powerful tools with profound societal impacts, yet their ability to generate responses to diverse and uncontrolled inputs leaves them vulnerable to adversarial attacks. While existing defenses often struggle to generalize across varying attack types, recent advancements in representation engineering offer promising alternatives. In this work, we propose a defense framework that formulates model defense as a contrastive representation learning (CRL) problem. Our method finetunes a model using a triplet-based loss combined with adversarial hard negative mining to encourage separation between benign and harmful representations. Our experimental results across multiple models demonstrate that our approach outperforms prior representation engineering-based defenses, improving robustness against both input-level and embedding-space attacks without compromising standard performance. Our code is available at this https URL', 'abstract_zh': '大型语言模型（LLMs）是具有深远社会影响的强大工具，但由于其对多样且不受控制的输入生成响应的能力，使得它们容易受到 adversarial 攻击。尽管现有的防御措施往往难以在不同类型的攻击之间泛化，但最近在表示工程方面的进展提供了有希望的替代方案。在这项工作中，我们提出了一种防御框架，将模型防御形式化为对比表示学习（CRL）问题。我们的方法使用基于三元组的损失结合对抗性困难负样本挖掘对模型进行微调，以促进良性与有害表示之间的分离。我们在多个模型的实验结果表明，我们的方法优于基于表示工程的先前防御措施，在不牺牲标准性能的情况下提高了对输入级和嵌入空间攻击的稳健性。我们的代码可在以下网址获取：this https URL', 'title_zh': '基于对比表示学习提高大型语言模型安全性'}
{'arxiv_id': 'arXiv:2506.11928', 'title': 'LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?', 'authors': 'Zihan Zheng, Zerui Cheng, Zeyu Shen, Shang Zhou, Kaiyuan Liu, Hansen He, Dongruixuan Li, Stanley Wei, Hangyi Hao, Jianzhu Yao, Peiyao Sheng, Zixuan Wang, Wenhao Chai, Aleksandra Korolova, Peter Henderson, Sanjeev Arora, Pramod Viswanath, Jingbo Shang, Saining Xie', 'link': 'https://arxiv.org/abs/2506.11928', 'abstract': 'Recent reports claim that large language models (LLMs) now outperform elite humans in competitive programming. Drawing on knowledge from a group of medalists in international algorithmic contests, we revisit this claim, examining how LLMs differ from human experts and where limitations still remain. We introduce LiveCodeBench Pro, a benchmark composed of problems from Codeforces, ICPC, and IOI that are continuously updated to reduce the likelihood of data contamination. A team of Olympiad medalists annotates every problem for algorithmic categories and conducts a line-by-line analysis of failed model-generated submissions. Using this new data and benchmark, we find that frontier models still have significant limitations: without external tools, the best model achieves only 53% pass@1 on medium-difficulty problems and 0% on hard problems, domains where expert humans still excel. We also find that LLMs succeed at implementation-heavy problems but struggle with nuanced algorithmic reasoning and complex case analysis, often generating confidently incorrect justifications. High performance appears largely driven by implementation precision and tool augmentation, not superior reasoning. LiveCodeBench Pro thus highlights the significant gap to human grandmaster levels, while offering fine-grained diagnostics to steer future improvements in code-centric LLM reasoning.', 'abstract_zh': '最近的报告显示，大型语言模型（LLMs）现在在编程竞赛中已经超越了顶尖人类选手。凭借国际算法竞赛获奖者的知识，我们重新审视这一报告，探讨LLMs与人类专家之间的差异以及仍然存在的局限性。我们引入了LiveCodeBench Pro基准，该基准包含来自Codeforces、ICPC和IOI的问题，并持续更新以降低数据污染的可能性。由奥林匹克奖牌得主对每个问题进行算法类别标注，并对模型生成的失败提交进行逐行分析。利用这些新数据和基准，我们发现前沿模型仍然存在显著局限性：在没有外部工具的情况下，最佳模型在中等难度问题上的pass@1仅为53%，而在困难问题上则为0%，这是专家人类选手仍能胜任的领域。我们还发现，LLMs在实现密集型问题上取得成功，但在复杂的算法推理和复杂情况分析上遇到困难，往往会产生自信心十足的错误解释。高性能主要由实现精度和工具辅助驱动，而非更卓越的推理能力。因此，LiveCodeBench Pro突显了与人类大师级水平之间的显著差距，并提供了详细的诊断，以指引未来代码中心的大规模语言模型推理改进。', 'title_zh': 'LiveCodeBench Pro: 奥林匹克金牌得主如何评判LLMs在competitive programming中的表现？'}
{'arxiv_id': 'arXiv:2506.11925', 'title': 'Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference', 'authors': 'M. Manzour, Catherine M. Elias, Omar M. Shehata, R. Izquierdo, M. A. Sotelo', 'link': 'https://arxiv.org/abs/2506.11925', 'abstract': "Research on lane change prediction has gained a lot of momentum in the last couple of years. However, most research is confined to simulation or results obtained from datasets, leaving a gap between algorithmic advances and on-road deployment. This work closes that gap by demonstrating, on real hardware, a lane-change prediction system based on Knowledge Graph Embeddings (KGEs) and Bayesian inference. Moreover, the ego-vehicle employs a longitudinal braking action to ensure the safety of both itself and the surrounding vehicles. Our architecture consists of two modules: (i) a perception module that senses the environment, derives input numerical features, and converts them into linguistic categories; and communicates them to the prediction module; (ii) a pretrained prediction module that executes a KGE and Bayesian inference model to anticipate the target vehicle's maneuver and transforms the prediction into longitudinal braking action. Real-world hardware experimental validation demonstrates that our prediction system anticipates the target vehicle's lane change three to four seconds in advance, providing the ego vehicle sufficient time to react and allowing the target vehicle to make the lane change safely.", 'abstract_zh': '基于知识图嵌入和贝叶斯推理的实时变道预测系统研究', 'title_zh': '基于知识图嵌入和贝叶斯推断的车道变更预测架构的实际部署'}
{'arxiv_id': 'arXiv:2506.11912', 'title': 'Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations', 'authors': 'Miguel Suau', 'link': 'https://arxiv.org/abs/2506.11912', 'abstract': "Recent work has shown that reinforcement learning agents can develop policies that exploit spurious correlations between rewards and observations. This phenomenon, known as policy confounding, arises because the agent's policy influences both past and future observation variables, creating a feedback loop that can hinder the agent's ability to generalize beyond its usual trajectories. In this paper, we show that the advantage function, commonly used in policy gradient methods, not only reduces the variance of gradient estimates but also mitigates the effects of policy confounding. By adjusting action values relative to the state representation, the advantage function downweights state-action pairs that are more likely under the current policy, breaking spurious correlations and encouraging the agent to focus on causal factors. We provide both analytical and empirical evidence demonstrating that training with the advantage function leads to improved out-of-trajectory performance.", 'abstract_zh': 'Recent工作表明强化学习代理可以发展出利用奖励与观测之间虚假相关性的策略。这一现象被称为策略偏差，因为它会导致代理的策略影响过去的和未来的观测变量，从而形成一个反馈循环，这可能阻碍代理泛化到其常规轨迹之外的能力。在本文中，我们展示了优势函数在策略梯度方法中广泛使用不仅减少了梯度估计的方差，还减轻了策略偏差的影响。通过相对状态表示调整动作值，优势函数降低了当前策略下更可能的状态-动作对的重要性，打破了虚假相关性，并促使代理关注因果因素。我们提供了分析和 empirical证据证明，使用优势函数进行训练可以改善代理的离轨性能。', 'title_zh': '打破习惯：优势函数在学习因果状态表示中的作用'}
{'arxiv_id': 'arXiv:2506.11908', 'title': 'Spectra-to-Structure and Structure-to-Spectra Inference Across the Periodic Table', 'authors': 'Yufeng Wang, Peiyao Wang, Lu Ma, Yuewei Lin, Qun Liu, Haibin Ling', 'link': 'https://arxiv.org/abs/2506.11908', 'abstract': 'X-ray Absorption Spectroscopy (XAS) is a powerful technique for probing local atomic environments, yet its interpretation remains limited by the need for expert-driven analysis, computationally expensive simulations, and element-specific heuristics. Recent advances in machine learning have shown promise for accelerating XAS interpretation, but many existing models are narrowly focused on specific elements, edge types, or spectral regimes. In this work, we present XAStruct, a learning framework capable of both predicting XAS spectra from crystal structures and inferring local structural descriptors from XAS input. XAStruct is trained on a large-scale dataset spanning over 70 elements across the periodic table, enabling generalization to a wide variety of chemistries and bonding environments. The model includes the first machine learning approach for predicting neighbor atom types directly from XAS spectra, as well as a unified regression model for mean nearest-neighbor distance that requires no element-specific tuning. While we explored integrating the two pipelines into a single end-to-end model, empirical results showed performance degradation. As a result, the two tasks were trained independently to ensure optimal accuracy and task-specific performance. By combining deep neural networks for complex structure-property mappings with efficient baseline models for simpler tasks, XAStruct offers a scalable and extensible solution for data-driven XAS analysis and local structure inference. The source code will be released upon paper acceptance.', 'abstract_zh': 'XAStruct：一种用于预测XAS光谱和推断局部结构描述符的机器学习框架', 'title_zh': '周期表 Across 元素间的谱图到结构和结构到谱图推理'}
{'arxiv_id': 'arXiv:2506.11901', 'title': 'A Neural Rejection System Against Universal Adversarial Perturbations in Radio Signal Classification', 'authors': 'Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Fabio Roli', 'link': 'https://arxiv.org/abs/2506.11901', 'abstract': 'Advantages of deep learning over traditional methods have been demonstrated for radio signal classification in the recent years. However, various researchers have discovered that even a small but intentional feature perturbation known as adversarial examples can significantly deteriorate the performance of the deep learning based radio signal classification. Among various kinds of adversarial examples, universal adversarial perturbation has gained considerable attention due to its feature of being data independent, hence as a practical strategy to fool the radio signal classification with a high success rate. Therefore, in this paper, we investigate a defense system called neural rejection system to propose against universal adversarial perturbations, and evaluate its performance by generating white-box universal adversarial perturbations. We show that the proposed neural rejection system is able to defend universal adversarial perturbations with significantly higher accuracy than the undefended deep neural network.', 'abstract_zh': '近年来，深度学习在无线信号分类上的优势已经得到证明，然而各种研究表明，即使是很小但故意的特征扰动，即对抗样本，也能显著降低基于深度学习的无线信号分类性能。在各种类型的对抗样本中，由于其数据独立性，通用对抗扰动受到了广泛关注，因此作为一种高成功率的欺骗无线信号分类的实际策略。因此，在本文中，我们研究了一种名为神经拒绝系统的防御系统以应对通用对抗扰动，并通过生成白盒通用对抗扰动来评估其性能。我们展示了所提出的神经拒绝系统在准确性方面能显著提高对通用对抗扰动的防御能力，优于未受保护的深度神经网络。', 'title_zh': '针对无线电信号分类中普遍对抗扰动的神经拒识系统'}
{'arxiv_id': 'arXiv:2506.11892', 'title': 'Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices', 'authors': 'Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli', 'link': 'https://arxiv.org/abs/2506.11892', 'abstract': 'Due to great success of transformers in many applications such as natural language processing and computer vision, transformers have been successfully applied in automatic modulation classification. We have shown that transformer-based radio signal classification is vulnerable to imperceptible and carefully crafted attacks called adversarial examples. Therefore, we propose a defense system against adversarial examples in transformer-based modulation classifications. Considering the need for computationally efficient architecture particularly for Internet of Things (IoT)-based applications or operation of devices in environment where power supply is limited, we propose a compact transformer for modulation classification. The advantages of robust training such as adversarial training in transformers may not be attainable in compact transformers. By demonstrating this, we propose a novel compact transformer that can enhance robustness in the presence of adversarial attacks. The new method is aimed at transferring the adversarial attention map from the robustly trained large transformer to a compact transformer. The proposed method outperforms the state-of-the-art techniques for the considered white-box scenarios including fast gradient method and projected gradient descent attacks. We have provided reasoning of the underlying working mechanisms and investigated the transferability of the adversarial examples between different architectures. The proposed method has the potential to protect the transformer from the transferability of adversarial examples.', 'abstract_zh': '基于变压器的自动调制分类中对抗样本的防御系统：一种健壮的紧凑变压器方法', 'title_zh': '基于注意力机制的 adversarial 稳健蒸馏在低功耗 IoT 设备的射频信号分类中'}
{'arxiv_id': 'arXiv:2506.11890', 'title': 'Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training', 'authors': 'Judson Leroy Dean Haynes IV', 'link': 'https://arxiv.org/abs/2506.11890', 'abstract': 'Virtual Reality simulators offer a powerful tool for teacher training, yet the integration of AI-powered student avatars presents a critical challenge: determining the optimal level of avatar realism for effective pedagogy. This literature review examines the evolution of avatar realism in VR teacher training, synthesizes its theoretical implications, and proposes a new pedagogical framework to guide future design. Through a systematic review, this paper traces the progression from human-controlled avatars to generative AI prototypes. Applying learning theories like Cognitive Load Theory, we argue that hyper-realism is not always optimal, as high-fidelity avatars can impose excessive extraneous cognitive load on novices, a stance supported by recent empirical findings. A significant gap exists between the technological drive for photorealism and the pedagogical need for scaffolded learning. To address this gap, we propose Graduated Realism, a framework advocating for starting trainees with lower-fidelity avatars and progressively increasing behavioral complexity as skills develop. To make this computationally feasible, we outline a novel single-call architecture, Crazy Slots, which uses a probabilistic engine and a Retrieval-Augmented Generation database to generate authentic, real-time responses without the latency and cost of multi-step reasoning models. This review provides evidence-based principles for designing the next generation of AI simulators, arguing that a pedagogically grounded approach to realism is essential for creating scalable and effective teacher education tools.', 'abstract_zh': '虚拟现实模拟器为教师培训提供了强大的工具，然而，集成人工智能驱动的学生 avatar 呈现了一个关键挑战：确定有效的教学所需的最优avatar逼真度水平。本文综述探讨了虚拟现实教师培训中 avatar 逼真度的发展历程，综合其理论含义，并提出一个新的教学框架以指导未来的设计。通过系统综述，本文追溯了从人工控制 avatar 到生成式 AI 原型的演变过程。应用认知负荷理论，我们argue 超高的逼真度不总是最优的，高度保真的 avatar 可能会给初学者带来过载的认知负荷，这一观点得到了最近实证研究的支持。技术驱动力追求照片级逼真与教学需求的支架式学习之间存在显著差距。为解决这一差距，我们提出了分阶段逼真度框架，建议从较低保真度的 avatar 开始培训，并随着技能的发展逐步增加行为复杂度。为了使这一过程在计算上可行，我们提出了一个新颖的一次性架构 Crazy Slots，该架构使用概率引擎和检索增强生成数据库，能够实时生成真实的响应，而不受多步推理模型的延迟和成本影响。本文提供了基于证据的原则，为设计下一代 AI 模拟器提供了指导，并argue 教学导向的逼真度方法对于创建可扩展且有效的教师教育工具是必不可少的。', 'title_zh': '入局：渐进现实主义——虚拟现实教师培训中人工智能驱动 avatar 的教学框架'}
{'arxiv_id': 'arXiv:2506.11882', 'title': 'An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing', 'authors': 'Haochen Sun, Yifan Liu, Ahmed Al-Tahmeesschi, Swarna Chetty, Syed Ali Raza Zaidi, Avishek Nag, Hamed Ahmadi', 'link': 'https://arxiv.org/abs/2506.11882', 'abstract': 'Effective resource management and network slicing are essential to meet the diverse service demands of vehicular networks, including Enhanced Mobile Broadband (eMBB) and Ultra-Reliable and Low-Latency Communications (URLLC). This paper introduces an Explainable Deep Reinforcement Learning (XRL) framework for dynamic network slicing and resource allocation in vehicular networks, built upon a near-real-time RAN intelligent controller. By integrating a feature-based approach that leverages Shapley values and an attention mechanism, we interpret and refine the decisions of our reinforcementlearning agents, addressing key reliability challenges in vehicular communication systems. Simulation results demonstrate that our approach provides clear, real-time insights into the resource allocation process and achieves higher interpretability precision than a pure attention mechanism. Furthermore, the Quality of Service (QoS) satisfaction for URLLC services increased from 78.0% to 80.13%, while that for eMBB services improved from 71.44% to 73.21%.', 'abstract_zh': '有效的资源管理与网络切片对于满足车载网络多样化的服务需求（包括增强型移动宽带eMBB和超可靠低时延通信URLLC）至关重要。本文介绍了一种基于近实时RAN智能控制器的可解释深度强化学习（XRL）框架，用于车载网络中的动态网络切片和资源分配。通过结合特征基于的方法，利用Shapley值和注意力机制，我们解释和细化了强化学习代理的决策，解决了车载通信系统中的关键可靠性挑战。仿真结果显示，与纯注意力机制相比，我们的方法提供了清晰的实时资源分配过程洞察，并提高了解释准确性。此外，对于URLLC服务，服务质量满足度从78.0%提高到80.13%，对于eMBB服务，服务质量满足度从71.44%提高到73.21%。', 'title_zh': '可解释的人工智能框架：面向车辆网络切片的动态资源管理'}
{'arxiv_id': 'arXiv:2506.11877', 'title': 'Robust Molecular Property Prediction via Densifying Scarce Labeled Data', 'authors': 'Jina Kim, Jeffrey Willette, Bruno Andreis, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2506.11877', 'abstract': 'A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial covariate shift, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data, stemming from the onerous and costly nature of experimental validation, further exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel meta-learning-based approach that leverages unlabeled data to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.', 'abstract_zh': '分子预测模型广泛认可的一个局限性在于其依赖于训练数据中的结构，导致对未见化合物的泛化能力差。而在药物发现中，推动研究进展最重要的化合物往往超出训练集，这使得对训练数据的偏见问题尤为突出。这种不匹配引入了显著的协变量偏移，导致标准深度学习模型产生不稳定且不准确的预测。此外，由于实验验证的繁琐和成本高，标注数据稀缺进一步加剧了可靠泛化的难度。为解决这些问题，我们提出了一种基于元学习的新方法，利用未标注数据在分布内（ID）和分布外（OOD）数据之间进行插值，使模型能够元学习超越训练分布的泛化能力。我们在表现出显著协变量偏移的挑战性现实世界数据集上展示了显著的性能提升。', 'title_zh': '通过稀有标记数据增密进行稳健分子属性预测'}
{'arxiv_id': 'arXiv:2506.11869', 'title': 'How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?', 'authors': 'Michela Lapenna, Caterina De Bacco', 'link': 'https://arxiv.org/abs/2506.11869', 'abstract': 'Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.', 'abstract_zh': '图是一种强大的数据结构，适用于表示关系数据，并广泛用于描述复杂的现实世界系统。概率图形模型（PGMs）和图神经网络（GNNs）都可以利用结构化的图数据，但它们的内在工作机制不同。问题在于它们在捕捉网络数据集中的信息方面有何不同？我们通过解决链接预测任务来解决这一目标，并进行了三项主要实验，分别在合成和真实网络上进行：一个是关注PGMs和GNNs如何处理输入特征，另一个两个则探讨它们在特征噪声以及图的异质性增加情况下的鲁棒性。PGMs不一定需要节点特征，而GNNs仅靠网络边无法发挥其作用，并且输入特征的选择至关重要。我们发现，当输入特征低维化或噪声化时，GNNs的表现不及PGMs，这模拟了许多现实场景中节点属性可能是标量或噪声的情形。然后，我们发现当图的异质性增加时，PGMs比GNNs更具有鲁棒性。最后，为了评估性能超越预测任务的情况，我们还比较了这两种框架在计算复杂性和可解释性方面的表现。', 'title_zh': '概率图模型与图神经网络是如何看待网络数据的？'}
{'arxiv_id': 'arXiv:2506.11860', 'title': 'MindGrab for BrainChop: Fast and Accurate Skull Stripping for Command Line and Browser', 'authors': 'Armina Fani, Mike Doan, Isabelle Le, Alex Fedorov, Malte Hoffmann, Chris Rorden, Sergey Plis', 'link': 'https://arxiv.org/abs/2506.11860', 'abstract': 'We developed MindGrab, a parameter- and memory-efficient deep fully-convolutional model for volumetric skull-stripping in head images of any modality. Its architecture, informed by a spectral interpretation of dilated convolutions, was trained exclusively on modality-agnostic synthetic data. MindGrab was evaluated on a retrospective dataset of 606 multimodal adult-brain scans (T1, T2, DWI, MRA, PDw MRI, EPI, CT, PET) sourced from the SynthStrip dataset. Performance was benchmarked against SynthStrip, ROBEX, and BET using Dice scores, with Wilcoxon signed-rank significance tests. MindGrab achieved a mean Dice score of 95.9 with standard deviation (SD) 1.6 across modalities, significantly outperforming classical methods (ROBEX: 89.1 SD 7.7, P < 0.05; BET: 85.2 SD 14.4, P < 0.05). Compared to SynthStrip (96.5 SD 1.1, P=0.0352), MindGrab delivered equivalent or superior performance in nearly half of the tested scenarios, with minor differences (<3% Dice) in the others. MindGrab utilized 95% fewer parameters (146,237 vs. 2,566,561) than SynthStrip. This efficiency yielded at least 2x faster inference, 50% lower memory usage on GPUs, and enabled exceptional performance (e.g., 10-30x speedup, and up to 30x memory reduction) and accessibility on a wider range of hardware, including systems without high-end GPUs. MindGrab delivers state-of-the-art accuracy with dramatically lower resource demands, supported in brainchop-cli (this https URL) and at this http URL.', 'abstract_zh': '我们开发了MindGrab，一种高效参数和内存消耗的深全卷积模型，用于任何模态头部图像的体素颅骨去除。该模型的架构受到拉伸卷积频谱解释的启发，并仅在模态无关的合成数据上进行训练。MindGrab在SynthStrip数据集中606个多模态成人脑扫描（T1、T2、DWI、MRA、PDw MRI、EPI、CT、PET）上进行了评估，并使用Dice分数与SynthStrip、ROBEX和BET进行了基准测试，结果通过Wilcoxon符号秩检验。MindGrab在各模态中获得了平均Dice分数95.9，标准差1.6，显著优于经典方法（ROBEX：89.1，标准差7.7，P < 0.05；BET：85.2，标准差14.4，P < 0.05）。与SynthStrip（96.5，标准差1.1，P=0.0352）相比，MindGrab在近一半的测试场景中提供了相当或更优的性能，在其他场景中仅存在轻微差异（Dice相差<3%）。与SynthStrip相比，MindGrab参数量减少了95%（146,237 vs. 2,566,561）。这一效率带来了至少2倍的推理速度提升，50%的GPU内存使用降低，并在广泛硬件上（包括没有高性能GPU的系统）实现了卓越的性能（例如，10-30倍的速度提升和最高30倍的内存缩减）。MindGrab以大幅减少的资源需求提供了最先进的准确性，并可通过brainchop-cli（此链接：[this https URL]）和此链接获得支持。', 'title_zh': 'MindGrab for BrainChop: 适用于命令行和浏览器的快速准确头骨去除方法'}
{'arxiv_id': 'arXiv:2506.11849', 'title': 'Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values', 'authors': 'R. Teal Witter, Yurong Liu, Christopher Musco', 'link': 'https://arxiv.org/abs/2506.11849', 'abstract': 'With origins in game theory, probabilistic values like Shapley values, Banzhaf values, and semi-values have emerged as a central tool in explainable AI. They are used for feature attribution, data attribution, data valuation, and more. Since all of these values require exponential time to compute exactly, research has focused on efficient approximation methods using two techniques: Monte Carlo sampling and linear regression formulations. In this work, we present a new way of combining both of these techniques. Our approach is more flexible than prior algorithms, allowing for linear regression to be replaced with any function family whose probabilistic values can be computed efficiently. This allows us to harness the accuracy of tree-based models like XGBoost, while still producing unbiased estimates. From experiments across eight datasets, we find that our methods give state-of-the-art performance for estimating probabilistic values. For Shapley values, the error of our methods can be $6.5\\times$ lower than Permutation SHAP (the most popular Monte Carlo method), $3.8\\times$ lower than Kernel SHAP (the most popular linear regression method), and $2.6\\times$ lower than Leverage SHAP (the prior state-of-the-art Shapley value estimator). For more general probabilistic values, we can obtain error $215\\times$ lower than the best estimator from prior work.', 'abstract_zh': '基于博弈论的概率值（如Shapley值、Banzhaf值和半值）作为可解释AI的核心工具出现，它们被用于特征归因、数据归因、数据估值等。由于所有这些值都需要指数时间来准确计算，研究集中于使用两种技术的高效近似方法：蒙特卡洛采样和线性回归建模。本文提出了一种结合这两种技术的新方法。我们的方法比之前的算法更具灵活性，允许用任何可高效计算概率值的函数家族替换线性回归。这使得我们可以利用基于树的模型（如XGBoost）的准确性，同时仍能产生无偏估计。通过在八个数据集上的实验，我们发现，我们的方法在估计概率值方面达到了最先进的性能。对于Shapley值，我们方法的误差比Permutation SHAP（最流行的蒙特卡洛方法）低6.5倍，比Kernel SHAP（最流行的线性回归方法）低3.8倍，比Leverage SHAP（之前的最优Shapley值估算器）低2.6倍。对于更一般的概率值，我们可以获得比之前工作最优估计器低215倍的误差。', 'title_zh': '基于回归调整的蒙特卡洛估计器：Shapley值和概率值'}
{'arxiv_id': 'arXiv:2506.11844', 'title': 'TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks', 'authors': 'Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan', 'link': 'https://arxiv.org/abs/2506.11844', 'abstract': "Inspired by the success of large language models (LLMs), there is a significant research shift from traditional graph learning methods to LLM-based graph frameworks, formally known as GraphLLMs. GraphLLMs leverage the reasoning power of LLMs by integrating three key components: the textual attributes of input nodes, the structural information of node neighborhoods, and task-specific prompts that guide decision-making. Despite their promise, the robustness of GraphLLMs against adversarial perturbations remains largely unexplored-a critical concern for deploying these models in high-stakes scenarios. To bridge the gap, we introduce TrustGLM, a comprehensive study evaluating the vulnerability of GraphLLMs to adversarial attacks across three dimensions: text, graph structure, and prompt manipulations. We implement state-of-the-art attack algorithms from each perspective to rigorously assess model resilience. Through extensive experiments on six benchmark datasets from diverse domains, our findings reveal that GraphLLMs are highly susceptible to text attacks that merely replace a few semantically similar words in a node's textual attribute. We also find that standard graph structure attack methods can significantly degrade model performance, while random shuffling of the candidate label set in prompt templates leads to substantial performance drops. Beyond characterizing these vulnerabilities, we investigate defense techniques tailored to each attack vector through data-augmented training and adversarial training, which show promising potential to enhance the robustness of GraphLLMs. We hope that our open-sourced library will facilitate rapid, equitable evaluation and inspire further innovative research in this field.", 'abstract_zh': '受大型语言模型成功的影响，图学习方法的研究方向从传统图学习方法转向基于大型语言模型的图框架，正式称为GraphLLMs。GraphLLMs通过整合三个关键组件——输入节点的文本属性、节点邻域的结构信息以及指导决策的任务特定提示——利用大型语言模型的推理能力。尽管它们前景广阔，但GraphLLMs对对抗性扰动的鲁棒性仍然鲜有探索——这是在高风险场景中部署这些模型的一个关键关切。为此，我们引入了TrustGLM，这是一个全面的研究，评估GraphLLMs在文本、图结构和提示操纵三个维度上的对抗性攻击脆弱性。我们从每个角度实施最先进的攻击算法，以严格评估模型的鲁棒性。通过在六个来自不同领域的基准数据集上的大量实验，我们的研究发现，GraphLLMs高度易受仅用少数语义相似词替换节点文本属性中的词的文本攻击。我们还发现，标准的图结构攻击方法可以显著降低模型性能，而提示模板中候选标签集的随机重排会导致显著的性能下降。除了揭示这些脆弱性，我们还通过数据增强训练和对抗性训练，针对每种攻击向量研究了防御技术，这些技术显示出增强GraphLLMs鲁棒性的潜在前景。我们希望开源库能够促进快速、公平的评估，并激励该领域的进一步创新研究。', 'title_zh': 'TrustGLM: 评估图LLMs在对抗提示、文本和结构攻击下的稳健性'}
{'arxiv_id': 'arXiv:2506.11815', 'title': 'Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection', 'authors': 'Tae-Seong Han, Jae-Wook Heo, Hakseung Kim, Cheol-Hui Lee, Hyub Huh, Eue-Keun Choi, Dong-Joo Kim', 'link': 'https://arxiv.org/abs/2506.11815', 'abstract': 'Electrocardiography (ECG) signals are often degraded by noise, which complicates diagnosis in clinical and wearable settings. This study proposes a diffusion-based framework for ECG noise quantification via reconstruction-based anomaly detection, addressing annotation inconsistencies and the limited generalizability of conventional methods. We introduce a distributional evaluation using the Wasserstein-1 distance ($W_1$), comparing the reconstruction error distributions between clean and noisy ECGs to mitigate inconsistent annotations. Our final model achieved robust noise quantification using only three reverse diffusion steps. The model recorded a macro-average $W_1$ score of 1.308 across the benchmarks, outperforming the next-best method by over 48%. External validations demonstrated strong generalizability, supporting the exclusion of low-quality segments to enhance diagnostic accuracy and enable timely clinical responses to signal degradation. The proposed method enhances clinical decision-making, diagnostic accuracy, and real-time ECG monitoring capabilities, supporting future advancements in clinical and wearable ECG applications.', 'abstract_zh': '基于扩散的 electrocardiography (ECG) 噪声量化框架：通过基于重建的异常检测解决注释不一致性和传统方法的有限泛化能力', 'title_zh': '基于扩散的电心图噪声异常检测量化'}
{'arxiv_id': 'arXiv:2506.11811', 'title': 'Abstract Sound Fusion with Unconditioned Inversion Model', 'authors': 'Jing Liu, EnQi Lian', 'link': 'https://arxiv.org/abs/2506.11811', 'abstract': 'An abstract sound is defined as a sound that does not disclose identifiable real-world sound events to a listener. Sound fusion aims to synthesize an original sound and a reference sound to generate a novel sound that exhibits auditory features beyond mere additive superposition of the sound constituents. To achieve this fusion, we employ inversion techniques that preserve essential features of the original sample while enabling controllable synthesis. We propose novel SDE and ODE inversion models based on DPMSolver++ samplers that reverse the sampling process by configuring model outputs as constants, eliminating circular dependencies incurred by noise prediction terms. Our inversion approach requires no prompt conditioning while maintaining flexible guidance during sampling.', 'abstract_zh': '一种抽象声音被定义为不向听者披露可识别的真实世界声源的声音。声音融合旨在合成一个原始声音和一个参考声音，生成一个展现超越简单叠加声音成分的听觉特征的新声音。为了实现这种融合，我们采用保留原始样本关键特征的同时允许可控合成的逆变换技术。我们基于DPMSolver++采样器提出了新型的SDE和ODE逆变换模型，通过将模型输出配置为常数来逆转采样过程，从而消除噪声预测项引起的循环依赖。我们的逆变换方法不要求使用提示条件，同时在采样过程中保持灵活的指导。', 'title_zh': '无条件反演模型导向的声学融合'}
{'arxiv_id': 'arXiv:2506.11798', 'title': 'Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models', 'authors': 'Maximilian Kreutner, Marlene Lutz, Markus Strohmaier', 'link': 'https://arxiv.org/abs/2506.11798', 'abstract': 'Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse, but have been found to consistently display a progressive left-leaning bias. At the same time, so-called persona or identity prompts have been shown to produce LLM behavior that aligns with socioeconomic groups that the base model is not aligned with. In this work, we analyze whether zero-shot persona prompting with limited information can accurately predict individual voting decisions and, by aggregation, accurately predict positions of European groups on a diverse set of policies. We evaluate if predictions are stable towards counterfactual arguments, different persona prompts and generation methods. Finally, we find that we can simulate voting behavior of Members of the European Parliament reasonably well with a weighted F1 score of approximately 0.793. Our persona dataset of politicians in the 2024 European Parliament and our code are available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在理解和生成政治 discourse 方面表现出显著的能力，但被发现持续展现出进步的左倾偏向。同时，所谓的 persona 或身份提示已被证明能够产生与基础模型不一致的经济社会群体的行为。在本文中，我们分析零样本 persona 提示在有限信息下能否准确预测个人的投票决策，并通过聚合准确预测欧洲群体在一系列政策上的立场。我们评估预测是否具有对反事实论证、不同 persona 提示和生成方法的稳定性。最后，我们发现可以使用加权 F1 分数约为 0.793 的方法合理模拟欧洲议会成员的投票行为。我们的 politician persona 数据集和代码可在以下链接获取：this https URL。', 'title_zh': '基于个性驱动的欧洲议会投票行为仿真研究——利用大规模语言模型'}
{'arxiv_id': 'arXiv:2506.11790', 'title': 'Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation', 'authors': 'Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp', 'link': 'https://arxiv.org/abs/2506.11790', 'abstract': 'Evaluating feature attribution methods represents a critical challenge in explainable AI (XAI), as researchers typically rely on perturbation-based metrics when ground truth is unavailable. However, recent work demonstrates that these evaluation metrics can show different performance across predicted classes within the same dataset. These "class-dependent evaluation effects" raise questions about whether perturbation analysis reliably measures attribution quality, with direct implications for XAI method development and the trustworthiness of evaluation techniques. We investigate under which conditions these class-dependent effects arise by conducting controlled experiments with synthetic time series data where ground truth feature locations are known. We systematically vary feature types and class contrasts across binary classification tasks, then compare perturbation-based degradation scores with ground truth-based precision-recall metrics using multiple attribution methods. Our experiments demonstrate that class-dependent effects emerge with both evaluation approaches even in simple scenarios with temporally localized features, triggered by basic variations in feature amplitude or temporal extent between classes. Most critically, we find that perturbation-based and ground truth metrics frequently yield contradictory assessments of attribution quality across classes, with weak correlations between evaluation approaches. These findings suggest that researchers should interpret perturbation-based metrics with care, as they may not always align with whether attributions correctly identify discriminating features. These findings reveal opportunities to reconsider what attribution evaluation actually measures and to develop more comprehensive evaluation frameworks that capture multiple dimensions of attribution quality.', 'abstract_zh': '评估特征归因方法代表了可解释人工智能（XAI）中的一个关键挑战，因为研究者通常依赖扰动基指标进行评估，尤其是在没有真实标签的情况下。然而，近期研究表明，这些评估指标在同一个数据集中不同预测类别之间可能会显示出不同的性能。这些“类依赖性评估效果”引发了关于扰动分析是否可靠地衡量归因质量的质疑，这对XAI方法的发展和评估技术的信任度具有直接的影响。我们通过使用合成时间序列数据进行受控实验来研究这些类依赖性效果出现的条件，其中已知真实特征的位置。我们在二分类任务中系统地改变特征类型和类别对比，然后将扰动基降级评分与基于真实标签的精确召回指标进行比较，使用多种归因方法。实验结果表明，即使在具有时间局部化特征的简单场景中，这两种评估方法即使在简单的情景中也会出现类依赖性效果，这由类间基本特征振幅或时间范围的差异触发。最关键的是，我们发现扰动基和真实标签指标在不同类别上经常导致归因质量的矛盾评估，评估方法之间相关性较弱。这些发现表明，研究人员在解读扰动基指标时应谨慎，因为它们可能并不总是与归因是否正确识别区分性特征相一致。这些发现揭示了重新考虑归因评估实际上衡量什么以及开发更全面的评估框架以捕捉归因质量多维度的机会。', 'title_zh': '为什么类依赖的评估效应会在时间序列特征 attribution 中出现？一种合成数据探究'}
{'arxiv_id': 'arXiv:2506.11777', 'title': 'Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation', 'authors': 'Divyanshu Mishra, Mohammadreza Salehi, Pramit Saha, Olga Patey, Aris T. Papageorghiou, Yuki M. Asano, J. Alison Noble', 'link': 'https://arxiv.org/abs/2506.11777', 'abstract': 'Self-supervised learning (SSL) has achieved major advances in natural images and video understanding, but challenges remain in domains like echocardiography (heart ultrasound) due to subtle anatomical structures, complex temporal dynamics, and the current lack of domain-specific pre-trained models. Existing SSL approaches such as contrastive, masked modeling, and clustering-based methods struggle with high intersample similarity, sensitivity to low PSNR inputs common in ultrasound, or aggressive augmentations that distort clinically relevant features. We present DISCOVR (Distilled Image Supervision for Cross Modal Video Representation), a self-supervised dual branch framework for cardiac ultrasound video representation learning. DISCOVR combines a clustering-based video encoder that models temporal dynamics with an online image encoder that extracts fine-grained spatial semantics. These branches are connected through a semantic cluster distillation loss that transfers anatomical knowledge from the evolving image encoder to the video encoder, enabling temporally coherent representations enriched with fine-grained semantic understanding. Evaluated on six echocardiography datasets spanning fetal, pediatric, and adult populations, DISCOVR outperforms both specialized video anomaly detection methods and state-of-the-art video-SSL baselines in zero-shot and linear probing setups, and achieves superior segmentation transfer.', 'abstract_zh': 'Distilled Image Supervision for Cross Modal Video Representation in Cardiac Ultrasound', 'title_zh': '基于在线聚类蒸馏的心脏超声视频表示的自监督学习'}
{'arxiv_id': 'arXiv:2506.11774', 'title': 'Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation', 'authors': 'Abhishek Jaiswal, Armeet Singh Luthra, Purav Jangir, Bhavya Garg, Nisheeth Srivastava', 'link': 'https://arxiv.org/abs/2506.11774', 'abstract': 'Isometric exercises appeal to individuals seeking convenience, privacy, and minimal dependence on equipments. However, such fitness training is often overdependent on unreliable digital media content instead of expert supervision, introducing serious risks, including incorrect posture, injury, and disengagement due to lack of corrective feedback. To address these challenges, we present a real-time feedback system for assessing isometric poses. Our contributions include the release of the largest multiclass isometric exercise video dataset to date, comprising over 3,600 clips across six poses with correct and incorrect variations. To support robust evaluation, we benchmark state-of-the-art models-including graph-based networks-on this dataset and introduce a novel three-part metric that captures classification accuracy, mistake localization, and model confidence. Our results enhance the feasibility of intelligent and personalized exercise training systems for home workouts. This expert-level diagnosis, delivered directly to the users, also expands the potential applications of these systems to rehabilitation, physiotherapy, and various other fitness disciplines that involve physical motion.', 'abstract_zh': '等长锻炼训练因其便捷、私密且对设备依赖度低而受到欢迎。然而，这种锻炼常常过度依赖不可靠的数字媒体内容而非专家指导，这带来了错误姿势、受伤以及缺乏矫正反馈导致的动力不足等严重风险。为此，我们提出了一种实时反馈系统，用于评估等长姿势。我们的贡献包括发布了目前最大的多类别等长锻炼视频数据集，包含超过3600个包含正确和错误变体的六种姿势片段。为了支持稳健的评估，我们在这数据集上对最新模型（包括图结构网络）进行了基准测试，并引入了一种新颖的三部分评价指标，该指标涵盖了分类准确性、错误定位和模型置信度。我们的结果提高了智能和个性化家庭锻炼训练系统的可行性。这种专家级诊断直接提供给用户，也扩展了这些系统的潜在应用范围，包括康复、物理治疗以及涉及身体动作的各种健身领域。', 'title_zh': '等 Isaiah 姿势评估的实时反馈与基准数据集'}
{'arxiv_id': 'arXiv:2506.11760', 'title': 'FeNN: A RISC-V vector processor for Spiking Neural Network acceleration', 'authors': 'Zainab Aizaz, James C. Knight, Thomas Nowotny', 'link': 'https://arxiv.org/abs/2506.11760', 'abstract': 'Spiking Neural Networks (SNNs) have the potential to drastically reduce the energy requirements of AI systems. However, mainstream accelerators like GPUs and TPUs are designed for the high arithmetic intensity of standard ANNs so are not well-suited to SNN simulation. FPGAs are well-suited to applications with low arithmetic intensity as they have high off-chip memory bandwidth and large amounts of on-chip memory. Here, we present a novel RISC-V-based soft vector processor (FeNN), tailored to simulating SNNs on FPGAs. Unlike most dedicated neuromorphic hardware, FeNN is fully programmable and designed to be integrated with applications running on standard computers from the edge to the cloud. We demonstrate that, by using stochastic rounding and saturation, FeNN can achieve high numerical precision with low hardware utilisation and that a single FeNN core can simulate an SNN classifier faster than both an embedded GPU and the Loihi neuromorphic system.', 'abstract_zh': 'SNNs在减少AI系统能耗方面的潜力：基于RISC-V的FeNN软向量处理器在FPGA上模拟SNN的研究', 'title_zh': 'FeNN: 一种用于突触神经网络加速的RISC-V向量处理器'}
{'arxiv_id': 'arXiv:2506.11718', 'title': 'Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration', 'authors': 'Yun Wang, Yan Lu', 'link': 'https://arxiv.org/abs/2506.11718', 'abstract': 'As AI tools proliferate across domains, from chatbots and copilots to emerging agents, they increasingly support professional knowledge work. Yet despite their growing capabilities, these systems remain fragmented: they assist with isolated tasks but lack the architectural scaffolding for sustained, adaptive collaboration. We propose a layered framework for human-agent systems that integrates three interdependent dimensions: interaction, process, and infrastructure. Crucially, our architecture elevates process to a primary focus by making it explicit, inspectable, and adaptable, enabling humans and agents to align with evolving goals and coordinate over time. This model clarifies limitations of current tools, unifies emerging system design approaches, and reveals new opportunities for researchers and AI system builders. By grounding intelligent behavior in structured collaboration, we reimagine human-agent collaboration not as task-specific augmentation, but as a form of coherent and aligned system for real-world work.', 'abstract_zh': '随着AI工具在各个领域 proliferate，从聊天机器人和联合飞行员到新兴代理，它们越来越多地支持专业知识工作。尽管这些系统的功能不断增强，但它们仍然碎片化：它们仅协助完成孤立的任务，缺乏持续适应性协作的架构支撑。我们提出了一种分层框架，用于集成三个相互依赖的维度：交互、过程和基础设施。最关键的是，我们的架构将过程作为重点，使其明确、可检查和可适应，从而使人类和代理能够适应不断变化的目标并随着时间协调工作。这一模型澄清了当前工具的局限性，统一了新兴系统设计方法，并揭示了研究人员和AI系统构建者的新机会。通过将智能行为根植于结构化的协作中，我们重新构想了人机协作，不仅作为一种特定任务的增强，而是作为一种连贯且一致的系统以适应现实世界的工作。', 'title_zh': '人机协作的统一架构：交互、过程与基础设施'}
{'arxiv_id': 'arXiv:2506.11702', 'title': 'Configurable Preference Tuning with Rubric-Guided Synthetic Data', 'authors': 'Víctor Gallego', 'link': 'https://arxiv.org/abs/2506.11702', 'abstract': 'Models of human feedback for AI alignment, such as those underpinning Direct Preference Optimization (DPO), often bake in a singular, static set of preferences, limiting adaptability. This paper challenges the assumption of monolithic preferences by introducing Configurable Preference Tuning (CPT), a novel framework for endowing language models with the ability to dynamically adjust their behavior based on explicit, human-interpretable directives. CPT leverages synthetically generated preference data, conditioned on system prompts derived from structured, fine-grained rubrics that define desired attributes like writing style. By fine-tuning with these rubric-guided preferences, the LLM learns to modulate its outputs at inference time in response to the system prompt, without retraining. This approach not only offers fine-grained control but also provides a mechanism for modeling more nuanced and context-dependent human feedback. Several experimental artifacts, such as training code, generated datasets and fine-tuned models are released at this https URL', 'abstract_zh': '人类反馈模型在AI对齐中的应用，如直接偏好优化（DPO）下的模型，往往包含了单一的静态偏好集合，限制了其适应性。本文通过引入可配置偏好调整（CPT）框架挑战了单一偏好假设，CPT为语言模型赋予了根据明确的人类可解释指令动态调整其行为的能力。CPT利用基于结构化细粒度标准卡生成的合成偏好数据，这些标准卡定义了如写作风格等期望属性。通过标准卡指导下的微调，LLM能够在推理时根据系统提示调整其输出，而无需重新训练。这种方法不仅提供了精细控制，还为建模更为精细和上下文依赖的人类反馈提供了一种机制。有关实验成果，如训练代码、生成的数据集和微调模型，可在此链接获取。', 'title_zh': '基于评分指南引导的合成数据可配置偏好调整'}
{'arxiv_id': 'arXiv:2506.11687', 'title': 'Differential Privacy in Machine Learning: From Symbolic AI to LLMs', 'authors': 'Francisco Aguilera-Martínez, Fernando Berzal', 'link': 'https://arxiv.org/abs/2506.11687', 'abstract': 'Machine learning models should not reveal particular information that is not otherwise accessible. Differential privacy provides a formal framework to mitigate privacy risks by ensuring that the inclusion or exclusion of any single data point does not significantly alter the output of an algorithm, thus limiting the exposure of private information. This survey paper explores the foundational definitions of differential privacy, reviews its original formulations and tracing its evolution through key research contributions. It then provides an in-depth examination of how DP has been integrated into machine learning models, analyzing existing proposals and methods to preserve privacy when training ML models. Finally, it describes how DP-based ML techniques can be evaluated in practice. %Finally, it discusses the broader implications of DP, highlighting its potential for public benefit, its real-world applications, and the challenges it faces, including vulnerabilities to adversarial attacks. By offering a comprehensive overview of differential privacy in machine learning, this work aims to contribute to the ongoing development of secure and responsible AI systems.', 'abstract_zh': '机器学习模型不应泄露超出范围的特定信息。差异隐私提供了一种正式框架，通过确保任何单个数据点的包含或排除不会显著改变算法的输出，从而限制私人信息的暴露。本文综述了差异隐私的基础定义，回顾了其最初的形成并通过关键研究贡献追踪其演变。然后，深入探讨了差异隐私如何集成到机器学习模型中，在训练机器学习模型时保留隐私的方法和现有提案。最后，描述了基于差异隐私的机器学习技术在实践中的评估方法。此外，讨论了差异隐私的更广泛影响，包括其对公共利益的潜力、实际应用以及面临的挑战，如对抗攻击的脆弱性。通过提供差异隐私在机器学习中的综合概述，本文旨在为安全和负责任的人工智能系统的发展做出贡献。', 'title_zh': '机器学习中的差分隐私：从符号人工智能到大语言模型'}
{'arxiv_id': 'arXiv:2506.11684', 'title': 'MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space', 'authors': 'Anshul Singh, Chris Biemann, Jan Strich', 'link': 'https://arxiv.org/abs/2506.11684', 'abstract': "Vision-Language Models (VLMs) have demonstrated remarkable capabilities in interpreting visual layouts and text. However, a significant challenge remains in their ability to interpret robustly and reason over multi-tabular data presented as images, a common occurrence in real-world scenarios like web pages and digital documents. Existing benchmarks typically address single tables or non-visual data (text/structured). This leaves a critical gap: they don't assess the ability to parse diverse table images, correlate information across them, and perform multi-hop reasoning on the combined visual data. We introduce MTabVQA, a novel benchmark specifically designed for multi-tabular visual question answering to bridge that gap. MTabVQA comprises 3,745 complex question-answer pairs that necessitate multi-hop reasoning across several visually rendered table images. We provide extensive benchmark results for state-of-the-art VLMs on MTabVQA, revealing significant performance limitations. We further investigate post-training techniques to enhance these reasoning abilities and release MTabVQA-Instruct, a large-scale instruction-tuning dataset. Our experiments show that fine-tuning VLMs with MTabVQA-Instruct substantially improves their performance on visual multi-tabular reasoning. Code and dataset (this https URL) are available online (this https URL).", 'abstract_zh': 'Vision-Language模型（VLMs）已经在解读视觉布局和文本方面展现了出色的能力。然而，在处理以图像形式呈现的多表格数据方面，它们仍然面临显著的挑战，尤其是在现实场景如网页和数字文档中广泛存在的多表格数据上进行稳健解释和推理的能力。现有的基准测试通常仅涉及单个表格或非视觉数据（文本/结构化数据），这留下了关键的缺口：它们没有评估解析多种表格图像、跨表格关联信息以及在综合视觉数据上进行多跳推理的能力。我们引入了MTabVQA，这是一个专门设计用于多表格视觉问答的新基准，以弥补这一缺口。MTabVQA 包含了 3,745 个复杂的问答对，需要在多个视觉渲染的表格图像之间进行多跳推理。我们提供了最先进的 VLMs 在 MTabVQA 上的广泛基准测试结果，揭示了它们在视觉多表格推理方面的显著性能限制。我们进一步研究了后训练技术以增强这些推理能力，并发布了 MTabVQA-Instruct，这是一个大规模的指令调优数据集。我们的实验表明，使用 MTabVQA-Instruct 调整 VLMs 显著提高了其在视觉多表格推理方面的性能。代码和数据集可在以下链接获得：[此链接](this https URL)。', 'title_zh': 'MTabVQA: 评估语言模型在视觉空间中的多表格推理能力'}
{'arxiv_id': 'arXiv:2506.11679', 'title': 'LLMs on support of privacy and security of mobile apps: state of the art and research directions', 'authors': 'Tran Thanh Lam Nguyen, Barbara Carminati, Elena Ferrari', 'link': 'https://arxiv.org/abs/2506.11679', 'abstract': 'Modern life has witnessed the explosion of mobile devices. However, besides the valuable features that bring convenience to end users, security and privacy risks still threaten users of mobile apps. The increasing sophistication of these threats in recent years has underscored the need for more advanced and efficient detection approaches. In this chapter, we explore the application of Large Language Models (LLMs) to identify security risks and privacy violations and mitigate them for the mobile application ecosystem. By introducing state-of-the-art research that applied LLMs to mitigate the top 10 common security risks of smartphone platforms, we highlight the feasibility and potential of LLMs to replace traditional analysis methods, such as dynamic and hybrid analysis of mobile apps. As a representative example of LLM-based solutions, we present an approach to detect sensitive data leakage when users share images online, a common behavior of smartphone users nowadays. Finally, we discuss open research challenges.', 'abstract_zh': '现代生活中，移动设备的数量急剧增加。然而，虽然移动应用为终端用户带来了宝贵的便利功能，但安全和隐私风险仍然威胁着用户的使用。近年来，这些威胁的日益复杂性凸显了需要更先进和高效的检测方法。在本章中，我们探讨了大规模语言模型（LLMs）在识别移动应用生态系统中的安全风险和隐私侵犯并减轻这些风险的应用。通过介绍将LLMs应用于缓解智能手机平台Top 10常见安全风险的最先进研究，我们突出了LLMs替换传统分析方法（如移动应用的动态和混合分析）的可行性和潜力。作为LLM基解决方案的代表例子，我们提出了一种检测在线分享图片时敏感数据泄露的方法，这是现代智能手机用户常见的行为。最后，我们讨论了开放的研究挑战。', 'title_zh': 'LLMs在移动应用隐私与安全支持中的状态与研究方向'}
{'arxiv_id': 'arXiv:2506.11678', 'title': 'Pose Matters: Evaluating Vision Transformers and CNNs for Human Action Recognition on Small COCO Subsets', 'authors': 'MingZe Tang, Madiha Kazi', 'link': 'https://arxiv.org/abs/2506.11678', 'abstract': 'This study explores human action recognition using a three-class subset of the COCO image corpus, benchmarking models from simple fully connected networks to transformer architectures. The binary Vision Transformer (ViT) achieved 90% mean test accuracy, significantly exceeding multiclass classifiers such as convolutional networks (approximately 35%) and CLIP-based models (approximately 62-64%). A one-way ANOVA (F = 61.37, p < 0.001) confirmed these differences are statistically significant. Qualitative analysis with SHAP explainer and LeGrad heatmaps indicated that the ViT localizes pose-specific regions (e.g., lower limbs for walking or running), while simpler feed-forward models often focus on background textures, explaining their errors. These findings emphasize the data efficiency of transformer representations and the importance of explainability techniques in diagnosing class-specific failures.', 'abstract_zh': '本研究使用COCO图像 corpus 的三分类子集探究人体动作识别，benchmark 各种从简单全连接网络到 transformer 架构的模型。二分类 Vision Transformer (ViT) 达到了 90% 的平均测试准确率，显著超过了基于卷积网络的多分类器（大约 35%）和 CLIP 基础模型（大约 62-64%）。单因子方差分析 (F = 61.37, p < 0.001) 确认这些差异具有统计显著性。通过 SHAP 解释器和 LeGrad 热力图的定性分析表明，ViT 专注于姿态特定区域（例如行走或跑步时的下肢），而较简单的前馈模型则通常关注背景纹理，解释了它们的错误。这些发现强调了 transformer 表征的数据效率及其解释性技术在诊断类别特定失败中的重要性。', 'title_zh': '姿态至关重要：小规模COCO子集上视觉变压器与CNN对人体动作识别的评估'}
{'arxiv_id': 'arXiv:2506.11673', 'title': 'Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE', 'authors': 'Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer', 'link': 'https://arxiv.org/abs/2506.11673', 'abstract': "Amnesic probing is a technique used to examine the influence of specific linguistic information on the behaviour of a model. This involves identifying and removing the relevant information and then assessing whether the model's performance on the main task changes. If the removed information is relevant, the model's performance should decline. The difficulty with this approach lies in removing only the target information while leaving other information unchanged. It has been shown that Iterative Nullspace Projection (INLP), a widely used removal technique, introduces random modifications to representations when eliminating target information. We demonstrate that Mean Projection (MP) and LEACE, two proposed alternatives, remove information in a more targeted manner, thereby enhancing the potential for obtaining behavioural explanations through Amnesic Probing.", 'abstract_zh': '遗忘探测是一种用于检验特定语言信息对模型行为影响的技术。这涉及识别并移除相关信息，然后评估模型在主任务上的性能变化。如果移除的信息是相关的，模型的性能应该下降。这种方法的难点在于仅移除目标信息而不改变其他信息。研究表明，广泛使用的移除技术迭代 Nullspace 投影 (INLP) 在消除目标信息时会引入随机修改。我们证明，两种提出的替代方法——均值投影 (MP) 和 LEACE——能够更精确地移除信息，从而增强通过遗忘探测获得行为解释的潜力。', 'title_zh': '改善遗忘性探查中的因果干预：基于均值投影或LEACE的方法'}
{'arxiv_id': 'arXiv:2506.11666', 'title': 'Converting Annotated Clinical Cases into Structured Case Report Forms', 'authors': 'Pietro Ferrazzi, Alberto Lavelli, Bernardo Magnini', 'link': 'https://arxiv.org/abs/2506.11666', 'abstract': 'Case Report Forms (CRFs) are largely used in medical research as they ensure accuracy, reliability, and validity of results in clinical studies. However, publicly available, wellannotated CRF datasets are scarce, limiting the development of CRF slot filling systems able to fill in a CRF from clinical notes. To mitigate the scarcity of CRF datasets, we propose to take advantage of available datasets annotated for information extraction tasks and to convert them into structured CRFs. We present a semi-automatic conversion methodology, which has been applied to the E3C dataset in two languages (English and Italian), resulting in a new, high-quality dataset for CRF slot filling. Through several experiments on the created dataset, we report that slot filling achieves 59.7% for Italian and 67.3% for English on a closed Large Language Models (zero-shot) and worse performances on three families of open-source models, showing that filling CRFs is challenging even for recent state-of-the-art LLMs. We release the datest at this https URL', 'abstract_zh': '基于信息抽取任务标注的数据集的半自动转换方法以构建高质CRF插槽填充数据集', 'title_zh': '将标注临床案例转换为结构化病例报告表'}
{'arxiv_id': 'arXiv:2506.11653', 'title': 'DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation', 'authors': 'Emre Kavak, Tom Nuno Wolf, Christian Wachinger', 'link': 'https://arxiv.org/abs/2506.11653', 'abstract': 'During prediction tasks, models can use any signal they receive to come up with the final answer - including signals that are causally irrelevant. When predicting objects from images, for example, the lighting conditions could be correlated to different targets through selection bias, and an oblivious model might use these signals as shortcuts to discern between various objects. A predictor that uses lighting conditions instead of real object-specific details is obviously undesirable. To address this challenge, we introduce a standard anti-causal prediction model (SAM) that creates a causal framework for analyzing the information pathways influencing our predictor in anti-causal settings. We demonstrate that a classifier satisfying a specific conditional independence criterion will focus solely on the direct causal path from label to image, being counterfactually invariant to the remaining variables. Finally, we propose DISCO, a novel regularization strategy that uses conditional distance correlation to optimize for conditional independence in regression tasks. We can show that DISCO achieves competitive results in different bias mitigation experiments, deeming it a valid alternative to classical kernel-based methods.', 'abstract_zh': '一种标准反因袭预测模型及其在反因袭设置下的因果框架', 'title_zh': 'DISCO: 用条件距离相关性减轻深度学习中的偏差'}
{'arxiv_id': 'arXiv:2506.11650', 'title': 'Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control', 'authors': 'Lambert Lee, Joshua Lau', 'link': 'https://arxiv.org/abs/2506.11650', 'abstract': 'The Robot Context Protocol (RCP) is a lightweight, middleware-agnostic communication protocol designed to simplify the complexity of robotic systems and enable seamless interaction between robots, users, and autonomous agents. RCP provides a unified and semantically meaningful interface that decouples client-facing operations from backend implementations, supporting a wide range of deployment environments including physical robots, cloud-based orchestrators, and simulated platforms. Built on HTTP and WebSocket transport layers, the protocol defines a schema-driven message format with structured operations such as read, write, execute, and subscribe. It integrates features such as runtime introspection, asynchronous feedback, multi-tenant namespace isolation, and strict type validation to ensure robustness, scalability, and security. The architecture, message structure, interface model, and adapter-based backend integration strategy of RCP are described, along with deployment practices and applicability across industries including manufacturing, logistics, and healthcare. RCP enables intelligent, resilient, and safe robotic operations in complex, multi-agent ecosystems.', 'abstract_zh': '基于上下文的机器人协议（RCP）是一种轻量级、中间件无关的通信协议，旨在简化机器人系统的复杂性，并促进机器人、用户和自主代理之间的无缝交互。RCP 提供了一个统一且语义上有意义的接口，将面向客户端的操作与后端实现解耦，支持包括物理机器人、基于云的编排器和模拟平台在内的广泛部署环境。该协议基于 HTTP 和 WebSocket 传输层，定义了一种以结构化操作（如读取、写入、执行和订阅）为基础的模式驱动消息格式。RCP 集成运行时反思、异步反馈、多租户命名空间隔离和严格的类型验证等功能，以确保其稳健性、可扩展性和安全性。文章描述了 RCP 的架构、消息结构、接口模型以及基于适配器的后端集成策略，并探讨了其在制造业、物流业和医疗保健等行业的应用实践，RCP 使智能、稳健和安全的机器人操作在复杂的多代理生态系统中成为可能。', 'title_zh': '基于代理感知的机器人控制的运行时无关接口：Robot Context Protocol (RCP)'}
{'arxiv_id': 'arXiv:2506.11638', 'title': 'LoRA-Gen: Specializing Large Language Model via Online LoRA Generation', 'authors': 'Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Yixiao Ge, Xiu Li, Ying Shan', 'link': 'https://arxiv.org/abs/2506.11638', 'abstract': 'Recent advances have highlighted the benefits of scaling language models to enhance performance across a wide range of NLP tasks. However, these approaches still face limitations in effectiveness and efficiency when applied to domain-specific tasks, particularly for small edge-side models. We propose the LoRA-Gen framework, which utilizes a large cloud-side model to generate LoRA parameters for edge-side models based on task descriptions. By employing the reparameterization technique, we merge the LoRA parameters into the edge-side model to achieve flexible specialization. Our method facilitates knowledge transfer between models while significantly improving the inference efficiency of the specialized model by reducing the input context length. Without specialized training, LoRA-Gen outperforms conventional LoRA fine-tuning, which achieves competitive accuracy and a 2.1x speedup with TinyLLaMA-1.1B in reasoning tasks. Besides, our method delivers a compression ratio of 10.1x with Gemma-2B on intelligent agent tasks.', 'abstract_zh': 'Recent advances have highlighted the benefits of scaling language models to enhance performance across a wide range of NLP tasks. However, these approaches still face limitations in effectiveness and efficiency when applied to domain-specific tasks, particularly for small edge-side models. We propose the LoRA-Gen framework, which utilizes a large cloud-side model to generate LoRA parameters for edge-side models based on task descriptions. By employing the reparameterization technique, we merge the LoRA parameters into the edge-side model to achieve flexible specialization. Our method facilitates knowledge transfer between models while significantly improving the inference efficiency of the specialized model by reducing the input context length. Without specialized training, LoRA-Gen outperforms conventional LoRA fine-tuning, which achieves competitive accuracy and a 2.1x speedup with TinyLLaMA-1.1B in reasoning tasks. Besides, our method delivers a compression ratio of 10.1x with Gemma-2B on intelligent agent tasks.', 'title_zh': 'LoRA-Gen: 基于在线LoRA生成的专业化大型语言模型'}
{'arxiv_id': 'arXiv:2506.11635', 'title': 'FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations', 'authors': 'Shaun Shuster, Eyal Zaloof, Asaf Shabtai, Rami Puzis', 'link': 'https://arxiv.org/abs/2506.11635', 'abstract': 'The continuous growth of the e-commerce industry attracts fraudsters who exploit stolen credit card details. Companies often investigate suspicious transactions in order to retain customer trust and address gaps in their fraud detection systems. However, analysts are overwhelmed with an enormous number of alerts from credit card transaction monitoring systems. Each alert investigation requires from the fraud analysts careful attention, specialized knowledge, and precise documentation of the outcomes, leading to alert fatigue. To address this, we propose a fraud analyst assistant (FAA) framework, which employs multi-modal large language models (LLMs) to automate credit card fraud investigations and generate explanatory reports. The FAA framework leverages the reasoning, code execution, and vision capabilities of LLMs to conduct planning, evidence collection, and analysis in each investigation step. A comprehensive empirical evaluation of 500 credit card fraud investigations demonstrates that the FAA framework produces reliable and efficient investigations comprising seven steps on average. Thus we found that the FAA framework can automate large parts of the workload and help reduce the challenges faced by fraud analysts.', 'abstract_zh': '电子商务行业的持续增长吸引了利用盗刷信用卡信息的诈骗分子。公司通常会调查可疑交易以保留客户信任并解决其欺诈检测系统的漏洞。然而，分析师受到信用卡交易监控系统生成的大量警报的困扰。每项警报调查都需要欺诈分析师投入细致的关注、专业技能，并精确记录结果，导致警报疲劳。为应对这一问题，我们提出了一种欺诈分析师助手（FAA）框架，利用多模态大语言模型（LLMs）自动完成信用卡欺诈调查并生成解释性报告。FAA框架利用LLM的推理、代码执行和视觉能力，在每个调查步骤中进行计划、证据收集和分析。对500例信用卡欺诈调查的全面实证评估表明，FAA框架可以平均完成七个步骤的可靠和高效的调查。因此，我们发现FAA框架可以自动化大量工作负载，帮助减轻欺诈分析师面临的挑战。', 'title_zh': 'FAA框架：基于大型语言模型的信用卡欺诈调查方法'}
{'arxiv_id': 'arXiv:2506.11627', 'title': 'Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression', 'authors': 'Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker, Yiannis Papadopoulos', 'link': 'https://arxiv.org/abs/2506.11627', 'abstract': 'Fairness is a critical component of Trustworthy AI. In this paper, we focus on Machine Learning (ML) and the performance of model predictions when dealing with skin color. Unlike other sensitive attributes, the nature of skin color differs significantly. In computer vision, skin color is represented as tensor data rather than categorical values or single numerical points. However, much of the research on fairness across sensitive groups has focused on categorical features such as gender and race. This paper introduces a new technique for evaluating fairness in ML for image classification tasks, specifically without the use of annotation. To address the limitations of prior work, we handle tensor data, like skin color, without classifying it rigidly. Instead, we convert it into probability distributions and apply statistical distance measures. This novel approach allows us to capture fine-grained nuances in fairness both within and across what would traditionally be considered distinct groups. Additionally, we propose an innovative training method to mitigate the latent biases present in conventional skin tone categorization. This method leverages color distance estimates calculated through Bayesian regression with polynomial functions, ensuring a more nuanced and equitable treatment of skin color in ML models.', 'abstract_zh': '公平是可信赖AI的关键组成部分。本文关注机器学习（ML）以及在处理皮肤颜色时模型预测的表现。不同于其他敏感属性，皮肤颜色的性质差异显著。在计算机视觉中，皮肤颜色被表示为张量数据而非分类值或单一数值点。然而，针对敏感群体的公平性研究大多集中在性别和种族等分类特征上。本文介绍了在无需标注的情况下评估图像分类任务中ML公平性的一种新方法。为了解决先前工作的局限性，我们处理如皮肤颜色这样的张量数据，不对其进行严格的分类。相反，我们将其转换为概率分布并应用统计距离度量。这一新颖的方法使我们能够捕捉公平性中的细微差异，无论是内部还是跨传统上被视为独立群体的外部。此外，我们提出了一种创新的训练方法来缓解常规肤色分类中存在的潜在偏见。该方法利用通过贝叶斯回归与多项式函数计算的颜色距离估计，确保ML模型中皮肤颜色的更细致和公平处理。', 'title_zh': '基于张量数据和贝叶斯回归的新型技术评价公平性与减轻偏见'}
{'arxiv_id': 'arXiv:2506.11618', 'title': 'Convergent Linear Representations of Emergent Misalignment', 'authors': 'Anna Soligo, Edward Turner, Senthooran Rajamanoharan, Neel Nanda', 'link': 'https://arxiv.org/abs/2506.11618', 'abstract': "Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.", 'abstract_zh': '大规模语言模型在窄数据集上的微调可能会导致其发展出广泛的不对齐行为：一种被称为 emergent misalignment 的现象。然而，这种不对齐的机制及其为什么会在训练域之外泛化的原理仍然不清楚，这凸显了我们对模型对齐理解中的关键空白。在本工作中，我们训练并研究了一个仅使用9个秩1适配器的最小模型有机体，使其对齐Qwen2.5-14B-Instruct产生emergent misalignment。通过对这一过程的研究，我们发现不同产生emergent misalignment的模型收敛到相似的对齐偏差表示。我们通过从一个微调模型的激活中提取“misalignment方向”，并使用它有效地消除更高维度LoRA和不同数据集中微调模型中的偏差行为，来证明这种收敛。利用秩1 LoRA的标量隐藏状态，我们进一步提出了一系列实验，直接解释微调适配器，结果显示六个适配器贡献于普遍对齐偏差，而两个适配器专门针对微调域内的对齐偏差。emergent misalignment 是一个特别突出的不良且出乎意料的模型行为的例子，通过深化我们对它背后的机制的理解，我们希望朝着更广泛地理解并减轻对齐偏差的目标迈进。', 'title_zh': '收敛线性表示的 emergent 对齐偏差'}
{'arxiv_id': 'arXiv:2506.11613', 'title': 'Model Organisms for Emergent Misalignment', 'authors': 'Edward Turner, Anna Soligo, Mia Taylor, Senthooran Rajamanoharan, Neel Nanda', 'link': 'https://arxiv.org/abs/2506.11613', 'abstract': 'Recent work discovered Emergent Misalignment (EM): fine-tuning large language models on narrowly harmful datasets can lead them to become broadly misaligned. A survey of experts prior to publication revealed this was highly unexpected, demonstrating critical gaps in our understanding of model alignment. In this work, we both advance understanding and provide tools for future research. Using new narrowly misaligned datasets, we create a set of improved model organisms that achieve 99% coherence (vs. 67% prior), work with smaller 0.5B parameter models (vs. 32B), and that induce misalignment using a single rank-1 LoRA adapter. We demonstrate that EM occurs robustly across diverse model sizes, three model families, and numerous training protocols including full supervised fine-tuning. Leveraging these cleaner model organisms, we isolate a mechanistic phase transition and demonstrate that it corresponds to a robust behavioural phase transition in all studied organisms. Aligning large language models is critical for frontier AI safety, yet EM exposes how far we are from achieving this robustly. By distilling clean model organisms that isolate a minimal alignment-compromising change, and where this is learnt, we establish a foundation for future research into understanding and mitigating alignment risks in LLMs.', 'abstract_zh': '新兴Misalignment（EM）现象的研究：窄导向有害数据集的微调导致模型的广导向错误对齐，及其解决方法', 'title_zh': '新兴对齐偏差的模型 organism 系统'}
{'arxiv_id': 'arXiv:2506.11602', 'title': 'Are LLMs Good Text Diacritizers? An Arabic and Yorùbá Case Study', 'authors': 'Hawau Olamide Toyin, Samar M. Magdy, Hanan Aldarmaki', 'link': 'https://arxiv.org/abs/2506.11602', 'abstract': 'We investigate the effectiveness of large language models (LLMs) for text diacritization in two typologically distinct languages: Arabic and Yoruba. To enable a rigorous evaluation, we introduce a novel multilingual dataset MultiDiac, with diverse samples that capture a range of diacritic ambiguities. We evaluate 14 LLMs varying in size, accessibility, and language coverage, and benchmark them against 6 specialized diacritization models. Additionally, we fine-tune four small open-source models using LoRA for Yoruba. Our results show that many off-the-shelf LLMs outperform specialized diacritization models for both Arabic and Yoruba, but smaller models suffer from hallucinations. Fine-tuning on a small dataset can help improve diacritization performance and reduce hallucination rates.', 'abstract_zh': '我们调查了大型语言模型（LLMs）在阿拉伯语和约鲁巴语两种类型学上不同的语言中的文本音标化效果。为实现严格评估，我们引入了一个新型多 lingual 数据集 MultiDiac，包含多样化样本以捕捉各种音标模糊性。我们评估了14个不同规模、可访问性和语言覆盖面的LLMs，并将其与6个专门的音标化模型进行基准测试。此外，我们使用LoRA对四个小型开源模型进行了微调，以适应约鲁巴语。我们的结果表明，许多现成的LLMs在阿拉伯语和约鲁巴语的音标化任务中优于专门的音标化模型，但较小的模型会遭受幻觉问题。对小数据集的微调有助于提高音标化性能并降低幻觉率。', 'title_zh': '大型语言模型是好的文本标注器吗？阿拉伯语和约鲁巴语案例研究'}
{'arxiv_id': 'arXiv:2506.11600', 'title': 'GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news', 'authors': 'Abdul Haque, Umm e Hani, Ahmad Din, Muhammad Babar, Ali Abbas, Insaf Ullah', 'link': 'https://arxiv.org/abs/2506.11600', 'abstract': 'GraphRAG-Causal introduces an innovative framework that combines graph-based retrieval with large language models to enhance causal reasoning in news analysis. Traditional NLP approaches often struggle with identifying complex, implicit causal links, especially in low-data scenarios. Our approach addresses these challenges by transforming annotated news headlines into structured causal knowledge graphs. It then employs a hybrid retrieval system that merges semantic embeddings with graph-based structural cues leveraging Neo4j to accurately match and retrieve relevant events. The framework is built on a three-stage pipeline: First, during Data Preparation, news sentences are meticulously annotated and converted into causal graphs capturing cause, effect, and trigger relationships. Next, the Graph Retrieval stage stores these graphs along with their embeddings in a Neo4j database and utilizes hybrid Cypher queries to efficiently identify events that share both semantic and structural similarities with a given query. Finally, the LLM Inference stage utilizes these retrieved causal graphs in a few-shot learning setup with XML-based prompting, enabling robust classification and tagging of causal relationships. Experimental evaluations demonstrate that GraphRAG-Causal achieves an impressive F1-score of 82.1% on causal classification using just 20 few-shot examples. This approach significantly boosts accuracy and consistency, making it highly suitable for real-time applications in news reliability assessment, misinformation detection, and policy analysis.', 'abstract_zh': 'GraphRAG-Causal引入了一种创新框架，将基于图的检索与大规模语言模型相结合，增强新闻分析中的因果推理。传统的自然语言处理方法在识别低数据场景中的复杂隐含因果联系时往往力不从心。我们的方法通过将标注的新闻标题转换为结构化的因果知识图来应对这些挑战，然后利用Neo4j结合语义嵌入和基于图的结构线索来高效匹配和检索相关事件。该框架建立在三阶段管道之上：首先，在数据准备阶段，详细标注新闻句子并转化为包含原因、结果和触发关系的因果图；接着，在图检索阶段，将这些图及其嵌入存储在Neo4j数据库中，并利用混合Cypher查询高效地识别与给定查询具有语义和结构相似性的事件；最后，在LLM推理阶段，利用这些检索到的因果图采用基于XML的提示少量样本学习设置，实现因果关系的稳健分类和标签。实验评估表明，GraphRAG-Causal仅使用20个少量样本示例，在因果分类上实现了82.1%的F1分数。该方法大幅提升了准确性和一致性，使其非常适用于新闻可靠性评估、 misinformation检测和政策分析等实时应用。', 'title_zh': 'GraphRAG-Causal：一种新型图增强框架，用于新闻中的因果推理与标注'}
{'arxiv_id': 'arXiv:2506.11599', 'title': 'A$^2$LC: Active and Automated Label Correction for Semantic Segmentation', 'authors': 'Youjin Jeon, Kyusik Cho, Suhan Woo, Euntai Kim', 'link': 'https://arxiv.org/abs/2506.11599', 'abstract': 'Active Label Correction (ALC) has emerged as a promising solution to the high cost and error-prone nature of manual pixel-wise annotation in semantic segmentation, by selectively identifying and correcting mislabeled data. Although recent work has improved correction efficiency by generating pseudo-labels using foundation models, substantial inefficiencies still remain. In this paper, we propose Active and Automated Label Correction for semantic segmentation (A$^2$LC), a novel and efficient ALC framework that integrates an automated correction stage into the conventional pipeline. Specifically, the automated correction stage leverages annotator feedback to perform label correction beyond the queried samples, thereby maximizing cost efficiency. In addition, we further introduce an adaptively balanced acquisition function that emphasizes underrepresented tail classes and complements the automated correction mechanism. Extensive experiments on Cityscapes and PASCAL VOC 2012 demonstrate that A$^2$LC significantly outperforms previous state-of-the-art methods. Notably, A$^2$LC achieves high efficiency by outperforming previous methods using only 20% of their budget, and demonstrates strong effectiveness by yielding a 27.23% performance improvement under an equivalent budget constraint on the Cityscapes dataset. The code will be released upon acceptance.', 'abstract_zh': '主动和自动化标签修正 (A$^2$LC)：面向语义分割的高效标签修正框架', 'title_zh': 'A$^2$LC: 主动和自动标签纠正方法及其在语义分割中的应用'}
{'arxiv_id': 'arXiv:2506.11585', 'title': 'OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots', 'authors': 'Juno Kim, Yesol Park, Hye-Jung Yoon, Byoung-Tak Zhang', 'link': 'https://arxiv.org/abs/2506.11585', 'abstract': "We introduce OV-MAP, a novel approach to open-world 3D mapping for mobile robots by integrating open-features into 3D maps to enhance object recognition capabilities. A significant challenge arises when overlapping features from adjacent voxels reduce instance-level precision, as features spill over voxel boundaries, blending neighboring regions together. Our method overcomes this by employing a class-agnostic segmentation model to project 2D masks into 3D space, combined with a supplemented depth image created by merging raw and synthetic depth from point clouds. This approach, along with a 3D mask voting mechanism, enables accurate zero-shot 3D instance segmentation without relying on 3D supervised segmentation models. We assess the effectiveness of our method through comprehensive experiments on public datasets such as ScanNet200 and Replica, demonstrating superior zero-shot performance, robustness, and adaptability across diverse environments. Additionally, we conducted real-world experiments to demonstrate our method's adaptability and robustness when applied to diverse real-world environments.", 'abstract_zh': '开放世界环境下用于移动机器人的新型3D测绘方法：通过将开放特征集成到3D地图中以增强物体识别能力', 'title_zh': 'OV-MAP : 开 vocabulary 无样本识别 3D 实例分割图 for 机器人'}
{'arxiv_id': 'arXiv:2506.11584', 'title': 'A Comparative Analysis of Influence Signals for Data Debugging', 'authors': 'Nikolaos Myrtakis, Ioannis Tsamardinos, Vassilis Christophides', 'link': 'https://arxiv.org/abs/2506.11584', 'abstract': "Improving the quality of training samples is crucial for improving the reliability and performance of ML models. In this paper, we conduct a comparative evaluation of influence-based signals for debugging training data. These signals can potentially identify both mislabeled and anomalous samples from a potentially noisy training set as we build the models and hence alleviate the need for dedicated glitch detectors. Although several influence-based signals (e.g., Self-Influence, Average Absolute Influence, Marginal Influence, GD-class) have been recently proposed in the literature, there are no experimental studies for assessing their power in detecting different glitch types (e.g., mislabeled and anomalous samples) under a common influence estimator (e.g., TraceIn) for different data modalities (image and tabular), and deep learning models (trained from scratch or foundation). Through extensive experiments, we show that signals like Self-Influence effectively detect mislabeled samples, but none of the existing signals can detect anomalies. Existing signals do not take into account the training dynamics, i.e., how the samples' influence on the model changes during training, while some signals fall into influence cancellation effects, i.e., influence score is zero due to unsigned scores accumulation, resulting in misleading influence attribution.", 'abstract_zh': '提高训练样本质量对于提升机器学习模型的可靠性和性能至关重要。本文对基于影响的信号进行比较评估，以调试训练数据。这些信号有可能从潜在嘈杂的训练集中识别出误标和异常样本，从而减轻专用故障检测器的需要。尽管文献中已经提出了几种基于影响的信号（例如，Self-Influence、Average Absolute Influence、Marginal Influence、GD-class），但还没有实验研究评估它们在不同影响估计器（例如，TraceIn）下，针对不同数据模态（图像和表结构数据）和深度学习模型（从头开始训练或基于基础模型的）检测不同类型故障（例如，误标和异常样本）的能力。通过广泛实验，我们表明Self-Influence信号能有效检测误标样本，但现有信号不能检测异常样本。现有信号没有考虑训练动力学，即样本对模型的影响如何在训练过程中变化，而有些信号则陷入了影响抵消效应，即由于无符号得分累积使得影响分值为零，导致误导性的影响归因。', 'title_zh': '数据调试中影响信号的比较分析'}
{'arxiv_id': 'arXiv:2506.11563', 'title': 'Learn to Preserve Personality: Federated Foundation Models in Recommendations', 'authors': 'Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang', 'link': 'https://arxiv.org/abs/2506.11563', 'abstract': 'A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user centric, decentralized system where individuals maintain control over their personalized agents.', 'abstract_zh': '已存在的基础模型(FM)的核心学习挑战是在泛化与个性化之间取得权衡，这是由各种参数高效适应技术突出的一个困境。联邦基础模型(FFM)通过分散化过程提供了一种结构化手段来分离共享知识和个体特定适应。鉴于推荐系统依赖丰富的隐式反馈反映出用户的独特特征，推荐系统为FFM提供了一个理想的测试平台。本文探讨了一种新的学习范式，在这种范式下，FFM不仅利用其泛化能力，而且特别设计来保护用户个性的完整性，这一特点在推荐系统中得到了充分说明。我们展望由个性化适应基础模型驱动的未来个性化代理，指导用户在内容上的决策。这种架构承诺了一个以用户为中心、分散化的系统，个体保留对其个性化代理的控制权。', 'title_zh': '学习保留个性：联邦基础模型在推荐中的应用'}
{'arxiv_id': 'arXiv:2506.11561', 'title': 'Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study', 'authors': 'Gábor Antal, Bence Bogenfürst, Rudolf Ferenc, Péter Hegedűs', 'link': 'https://arxiv.org/abs/2506.11561', 'abstract': "Recent advancements in large language models (LLMs) have shown promise for automated vulnerability detection and repair in software systems. This paper investigates the performance of GPT-4o in repairing Java vulnerabilities from a widely used dataset (Vul4J), exploring how different contextual information affects automated vulnerability repair (AVR) capabilities. We compare the latest GPT-4o's performance against previous results with GPT-4 using identical prompts. We evaluated nine additional prompts crafted by us that contain various contextual information such as CWE or CVE information, and manually extracted code contexts. Each prompt was executed three times on 42 vulnerabilities, and the resulting fix candidates were validated using Vul4J's automated testing framework.\nOur results show that GPT-4o performed 11.9\\% worse on average than GPT-4 with the same prompt, but was able to fix 10.5\\% more distinct vulnerabilities in the three runs together. CVE information significantly improved repair rates, while the length of the task description had minimal impact. Combining CVE guidance with manually extracted code context resulted in the best performance. Using our \\textsc{Top}-3 prompts together, GPT-4o repaired 26 (62\\%) vulnerabilities at least once, outperforming both the original baseline (40\\%) and its reproduction (45\\%), suggesting that ensemble prompt strategies could improve vulnerability repair in zero-shot settings.", 'abstract_zh': '最近在大型语言模型（LLMs）方面取得的进展展示了其在软件系统中自动漏洞检测与修复方面的潜力。本文探讨了GPT-4o在使用广泛使用的Vul4J数据集修复Java漏洞方面的性能，探索不同上下文信息如何影响自动漏洞修复（AVR）能力。我们将最新版本的GPT-4o的性能与使用相同提示的GPT-4的先前结果进行了比较。我们评估了九个由我们定制的额外提示，这些提示包含各种上下文信息，如CWE或CVE信息，以及手动提取的代码上下文。每个提示在42个漏洞上执行三次，结果的修复候选方案使用Vul4J的自动化测试框架进行了验证。\n\n结果显示，GPT-4o在相同提示下平均表现比GPT-4差11.9%，但在三次运行中能够修复10.5%更多的独特漏洞。CWE/CVE信息显著提高了修复率，而任务描述的长度几乎没有影响。结合CWE指导与手动提取的代码上下文产生了最佳性能。使用我们定制的Top3提示，GPT-4o在至少修复了26个（62%）漏洞方面优于原始基线（40%）和其再现结果（45%），这表明集成提示策略可能在零样本设置中改善漏洞修复。', 'title_zh': '基于LLM的漏洞修复辅助上下文识别：一项初步研究'}
{'arxiv_id': 'arXiv:2506.11559', 'title': 'Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation', 'authors': 'Gábor Antal, Dénes Bán, Martin Isztin, Rudolf Ferenc, Péter Hegedűs', 'link': 'https://arxiv.org/abs/2506.11559', 'abstract': "In the life-cycle of software development, testing plays a crucial role in quality assurance. Proper testing not only increases code coverage and prevents regressions but it can also ensure that any potential vulnerabilities in the software are identified and effectively fixed. However, creating such tests is a complex, resource-consuming manual process. To help developers and security experts, this paper explores the automatic unit test generation capability of one of the most widely used large language models, GPT-4, from the perspective of vulnerabilities. We examine a subset of the VUL4J dataset containing real vulnerabilities and their corresponding fixes to determine whether GPT-4 can generate syntactically and/or semantically correct unit tests based on the code before and after the fixes as evidence of vulnerability mitigation. We focus on the impact of code contexts, the effectiveness of GPT-4's self-correction ability, and the subjective usability of the generated test cases. Our results indicate that GPT-4 can generate syntactically correct test cases 66.5\\% of the time without domain-specific pre-training. Although the semantic correctness of the fixes could be automatically validated in only 7. 5\\% of the cases, our subjective evaluation shows that GPT-4 generally produces test templates that can be further developed into fully functional vulnerability-witnessing tests with relatively minimal manual effort.\nTherefore, despite the limited data, our initial findings suggest that GPT-4 can be effectively used in the generation of vulnerability-witnessing tests. It may not operate entirely autonomously, but it certainly plays a significant role in a partially automated process.", 'abstract_zh': '在软件开发生命周期中，测试在质量保证中扮演着关键角色。适当的测试不仅能增加代码覆盖率并防止回归问题，还能确保软件中的任何潜在漏洞能够被发现并有效修复。然而，创建这样的测试是一个复杂且资源密集型的手动过程。为了帮助开发者和安全专家，本文从漏洞的角度探讨了最广泛使用的大型语言模型之一GPT-4的自动单元测试生成能力。我们分析了VUL4J数据集中包含真实漏洞及相应修复的一组数据，以确定GPT-4是否能够根据在修复前后代码的证据生成符合语法和/或语义的单元测试，来验证漏洞缓解。我们重点关注代码上下文的影响、GPT-4自我校正能力的有效性以及生成测试案例的主观可用性。结果显示，GPT-4在没有领域特定预训练的情况下，能够生成符合语法的测试案例66.5%。虽然在7.5%的情况下可以自动验证语义正确性，但我们的主观评估表明，GPT-4生成的测试模板通常可以经过相对较少的手工开发进一步转变为功能全面的漏洞见证测试。因此，尽管数据有限，我们的初步发现表明，GPT-4可以在生成漏洞见证测试中得到有效利用。它可能不会完全自主运行，但确实可以在部分自动化的过程中发挥重要作用。', 'title_zh': '利用GPT-4生成漏洞见证单元测试'}
{'arxiv_id': 'arXiv:2506.11558', 'title': 'DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs', 'authors': 'Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen', 'link': 'https://arxiv.org/abs/2506.11558', 'abstract': 'Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with GPT-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.', 'abstract_zh': '大规模语言模型（LLMs）最近已扩展到视频领域，实现了复杂的视频-语言理解。然而，现有的视频LLMs常常在细粒度的时间推理方面表现出局限性，限制了其精确归因响应到视频特定时刻的能力，尤其是在受限的监督下。我们介绍DaMO，一种专为准确的时间推理和多模态理解设计的数据高效视频LLM。核心上，提出的Tempo-aware Fuseformer采用分层双流架构，逐步捕获每个模态内的时间动态并有效融合互补的视觉和音频信息。为了进一步提高计算效率，DaMO整合了一个全局残差，以减少空间冗余同时保留关键的语义细节。我们通过一个结构化的四阶段渐进训练范式训练DaMO，逐步赋予模型多模态对齐、语义 grounding 和时间推理能力。这项工作还贡献了多个通过GPT生成的时空关联问答对扩充的现有数据集，用于需要时间监督的任务。在时空定位和视频问答基准测试中的全面实验表明，DaMO始终优于先前的方法，尤其是在需要精确时间对齐和推理的任务中。我们的工作为数据高效视频-语言建模指出了一个有前景的方向。', 'title_zh': 'DaMO：一种高效的数据驱动多模态 orchestrator，用于视频LLM的时序推理'}
{'arxiv_id': 'arXiv:2506.11550', 'title': 'Improving Multimodal Learning Balance and Sufficiency through Data Remixing', 'authors': 'Xiaoyu Ma, Hao Chen, Yongjian Deng', 'link': 'https://arxiv.org/abs/2506.11550', 'abstract': 'Different modalities hold considerable gaps in optimization trajectories, including speeds and paths, which lead to modality laziness and modality clash when jointly training multimodal models, resulting in insufficient and imbalanced multimodal learning. Existing methods focus on enforcing the weak modality by adding modality-specific optimization objectives, aligning their optimization speeds, or decomposing multimodal learning to enhance unimodal learning. These methods fail to achieve both unimodal sufficiency and multimodal balance. In this paper, we, for the first time, address both concerns by proposing multimodal Data Remixing, including decoupling multimodal data and filtering hard samples for each modality to mitigate modality imbalance; and then batch-level reassembling to align the gradient directions and avoid cross-modal interference, thus enhancing unimodal learning sufficiency. Experimental results demonstrate that our method can be seamlessly integrated with existing approaches, improving accuracy by approximately 6.50%$\\uparrow$ on CREMAD and 3.41%$\\uparrow$ on Kinetic-Sounds, without training set expansion or additional computational overhead during inference. The source code is available at \\href{this https URL}{Data Remixing}.', 'abstract_zh': '不同的模态在优化轨迹上存在显著差距，包括速度和路径的不同，这导致在联合训练多模态模型时出现模态懒惰和模态冲突，从而导致多模态学习不足和不平衡。现有方法主要通过增加模态特定的优化目标、对齐优化速度或分解多模态学习来强化单模态学习，但这些方法无法同时实现单模态充分性和多模态平衡。本文首次通过提出多模态Data Remixing来同时解决这两个问题，包括解耦多模态数据、过滤每个模态的困难样本以缓解模态不平衡；然后在批量层次上重新组装以对齐梯度方向并避免跨模态干扰，从而增强单模态学习充分性。实验结果表明，我们的方法可以无缝集成到现有方法中，分别在CREMAD上提高约6.50%的准确性，在Kinetic-Sounds上提高约3.41%的准确性，无需扩展训练集或在推理过程中增加额外的计算开销。源代码可在Data Remixing获取。', 'title_zh': '通过数据混搭提高多模态学习的平衡性和充分性'}
{'arxiv_id': 'arXiv:2506.11543', 'title': 'FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation', 'authors': 'Zhuguanyu Wu, Shihe Wang, Jiayi Zhang, Jiaxin Chen, Yunhong Wang', 'link': 'https://arxiv.org/abs/2506.11543', 'abstract': 'Post-training quantization (PTQ) has stood out as a cost-effective and promising model compression paradigm in recent years, as it avoids computationally intensive model retraining. Nevertheless, current PTQ methods for Vision Transformers (ViTs) still suffer from significant accuracy degradation, especially under low-bit quantization. To address these shortcomings, we analyze the prevailing Hessian-guided quantization loss, and uncover certain limitations of conventional Hessian approximations. By following the block-wise reconstruction framework, we propose a novel PTQ method for ViTs, dubbed FIMA-Q. Specifically, we firstly establish the connection between KL divergence and FIM, which enables fast computation of the quantization loss during reconstruction. We further propose an efficient FIM approximation method, namely DPLR-FIM, by employing the diagonal plus low-rank principle, and formulate the ultimate quantization loss. Our extensive experiments, conducted across various vision tasks with representative ViT-based architectures on public datasets, demonstrate that our method substantially promotes the accuracy compared to the state-of-the-art approaches, especially in the case of low-bit quantization. The source code is available at this https URL.', 'abstract_zh': '后训练量化（PTQ）近年来因其避免了计算密集型的模型重新训练而凸显出成本效益和前景，成为了模型压缩的一种有效范式。然而，当前针对视觉transformer（ViTs）的PTQ方法依然面临着显著的准确率下降问题，尤其是在低位量化的情况下。为解决这些问题，我们分析了现有的海森矩阵引导的量化损失，并揭示了传统海森矩阵近似的一些局限性。通过遵循块重建框架，我们提出了一种新颖的针对ViTs的PTQ方法，称为FIMA-Q。具体地，我们首先建立了KL散度与FIM之间的关联，这使得在重建过程中的量化损失计算变得快速。我们进一步提出了一种高效的FIM近似方法，即DPLR-FIM，通过使用对角占优加低秩的原则，并因此制定了最终的量化损失函数。通过在公共数据集上的各种视觉任务中使用代表性的ViT架构进行广泛实验，我们的方法在低位量化的情况下显著提升了准确率，并且与最先进的方法相比表现更优。源代码可在此网址获得。', 'title_zh': 'FIMA-Q：通过Fishers信息矩阵逼近的视觉变换器后训练量化'}
{'arxiv_id': 'arXiv:2506.11526', 'title': 'Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis', 'authors': 'Yuan Gao, Mattia Piccinini, Yuchen Zhang, Dingrui Wang, Korbinian Moller, Roberto Brusnicki, Baha Zarrouki, Alessio Gambi, Jan Frederik Totz, Kai Storms, Steven Peters, Andrea Stocco, Bassam Alrifaee, Marco Pavone, Johannes Betz', 'link': 'https://arxiv.org/abs/2506.11526', 'abstract': 'For autonomous vehicles, safe navigation in complex environments depends on handling a broad range of diverse and rare driving scenarios. Simulation- and scenario-based testing have emerged as key approaches to development and validation of autonomous driving systems. Traditional scenario generation relies on rule-based systems, knowledge-driven models, and data-driven synthesis, often producing limited diversity and unrealistic safety-critical cases. With the emergence of foundation models, which represent a new generation of pre-trained, general-purpose AI models, developers can process heterogeneous inputs (e.g., natural language, sensor data, HD maps, and control actions), enabling the synthesis and interpretation of complex driving scenarios. In this paper, we conduct a survey about the application of foundation models for scenario generation and scenario analysis in autonomous driving (as of May 2025). Our survey presents a unified taxonomy that includes large language models, vision-language models, multimodal large language models, diffusion models, and world models for the generation and analysis of autonomous driving scenarios. In addition, we review the methodologies, open-source datasets, simulation platforms, and benchmark challenges, and we examine the evaluation metrics tailored explicitly to scenario generation and analysis. Finally, the survey concludes by highlighting the open challenges and research questions, and outlining promising future research directions. All reviewed papers are listed in a continuously maintained repository, which contains supplementary materials and is available at this https URL.', 'abstract_zh': '对自主车辆而言，复杂环境下的安全导航依赖于处理多种多样且罕见的驾驶场景。基于仿真和场景的方法已成为自主驾驶系统开发与验证的关键途径。传统场景生成依靠基于规则的系统、知识驱动模型和数据驱动合成，往往产生有限的多样性和不现实的安全关键案例。随着基础模型的出现，这是一种新一代的预训练泛用人工智能模型，开发者可以处理异构输入（如自然语言、传感器数据、高清地图和控制动作），从而生成和解释复杂的驾驶场景。本文于2025年5月进行了一项关于基础模型在自主驾驶场景生成与分析中应用的综述。综述中包含了一个统一的分类体系，涵盖了大型语言模型、视觉语言模型、多模态大型语言模型、扩散模型和世界模型，用于生成和分析自主驾驶场景。此外，我们还回顾了相关方法、开源数据集、仿真平台和基准挑战，并详细介绍了专门针对场景生成与分析的评估标准。最后，综述总结了存在的开放挑战和研究问题，并指出了有前景的未来研究方向。所有已审查的论文清单保存在一个持续维护的仓库中，该仓库包含补充材料，可在以下链接访问：[https://github.com/autonomous-scenario-generation-and-analysis-repository]。', 'title_zh': '自主驾驶中的基础模型：场景生成与分析综述'}
{'arxiv_id': 'arXiv:2506.11521', 'title': 'Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models', 'authors': 'Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li', 'link': 'https://arxiv.org/abs/2506.11521', 'abstract': 'Multimodal large language models (MLLMs), which bridge the gap between audio-visual and natural language processing, achieve state-of-the-art performance on several audio-visual tasks. Despite the superior performance of MLLMs, the scarcity of high-quality audio-visual training data and computational resources necessitates the utilization of third-party data and open-source MLLMs, a trend that is increasingly observed in contemporary research. This prosperity masks significant security risks. Empirical studies demonstrate that the latest MLLMs can be manipulated to produce malicious or harmful content. This manipulation is facilitated exclusively through instructions or inputs, including adversarial perturbations and malevolent queries, effectively bypassing the internal security mechanisms embedded within the models. To gain a deeper comprehension of the inherent security vulnerabilities associated with audio-visual-based multimodal models, a series of surveys investigates various types of attacks, including adversarial and backdoor attacks. While existing surveys on audio-visual attacks provide a comprehensive overview, they are limited to specific types of attacks, which lack a unified review of various types of attacks. To address this issue and gain insights into the latest trends in the field, this paper presents a comprehensive and systematic review of audio-visual attacks, which include adversarial attacks, backdoor attacks, and jailbreak attacks. Furthermore, this paper also reviews various types of attacks in the latest audio-visual-based MLLMs, a dimension notably absent in existing surveys. Drawing upon comprehensive insights from a substantial review, this paper delineates both challenges and emergent trends for future research on audio-visual attacks and defense.', 'abstract_zh': '多模态大语言模型的音频视觉攻击综述：包括对抗攻击、后门攻击和越狱攻击', 'title_zh': '针对音视频攻击的漏洞与防御方法综述：强调多模态模型的研究'}
{'arxiv_id': 'arXiv:2506.11512', 'title': 'Prioritizing Alignment Paradigms over Task-Specific Model Customization in Time-Series LLMs', 'authors': 'Wei Li, Yunyao Cheng, Xinli Hao, Chaohong Ma, Yuxuan Liang, Bin Yang, Christian S.Jensen, Xiaofeng Meng', 'link': 'https://arxiv.org/abs/2506.11512', 'abstract': 'Recent advances in Large Language Models (LLMs) have enabled unprecedented capabilities for time-series reasoning in diverse real-world applications, including medical, financial, and spatio-temporal domains. However, existing approaches typically focus on task-specific model customization, such as forecasting and anomaly detection, while overlooking the data itself, referred to as time-series primitives, which are essential for in-depth reasoning. This position paper advocates a fundamental shift in approaching time-series reasoning with LLMs: prioritizing alignment paradigms grounded in the intrinsic primitives of time series data over task-specific model customization. This realignment addresses the core limitations of current time-series reasoning approaches, which are often costly, inflexible, and inefficient, by systematically accounting for intrinsic structure of data before task engineering. To this end, we propose three alignment paradigms: Injective Alignment, Bridging Alignment, and Internal Alignment, which are emphasized by prioritizing different aspects of time-series primitives: domain, characteristic, and representation, respectively, to activate time-series reasoning capabilities of LLMs to enable economical, flexible, and efficient reasoning. We further recommend that practitioners adopt an alignment-oriented method to avail this instruction to select an appropriate alignment paradigm. Additionally, we categorize relevant literature into these alignment paradigms and outline promising research directions.', 'abstract_zh': 'Recent Advances in Large Language Models for Time-Series Reasoning: A Paradigm Shift towards Alignment Based on Intrinsic Primitives', 'title_zh': '在时间序列LLM中优先考虑对齐范式而非任务特定模型定制'}
{'arxiv_id': 'arXiv:2506.11508', 'title': 'Machine Learning-Based Quantification of Vesicoureteral Reflux with Enhancing Accuracy and Efficiency', 'authors': 'Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Mohammad Subhi Al-Batah, Lana Yasin Al Aesa, Mohammed Hasan Abu-Arqoub, Rashiq Rafiq Marie, Firas Hussein Alsmad', 'link': 'https://arxiv.org/abs/2506.11508', 'abstract': 'Vesicoureteral reflux (VUR) is traditionally assessed using subjective grading systems, which introduces variability in diagnosis. This study investigates the use of machine learning to improve diagnostic consistency by analyzing voiding cystourethrogram (VCUG) images. A total of 113 VCUG images were reviewed, with expert grading of VUR severity. Nine image-based features were selected to train six predictive models: Logistic Regression, Decision Tree, Gradient Boosting, Neural Network, and Stochastic Gradient Descent. The models were evaluated using leave-one-out cross-validation. Analysis identified deformation patterns in the renal calyces as key indicators of high-grade VUR. All models achieved accurate classifications with no false positives or negatives. High sensitivity to subtle image patterns characteristic of different VUR grades was confirmed by substantial Area Under the Curve (AUC) values. The results suggest that machine learning can offer an objective and standardized alternative to current subjective VUR assessments. These findings highlight renal calyceal deformation as a strong predictor of severe cases. Future research should aim to expand the dataset, refine imaging features, and improve model generalizability for broader clinical use.', 'abstract_zh': '膀胱输尿管反流（VUR）的传统评估采用主观分级系统，引入了诊断的一致性问题。本研究通过分析排尿性膀胱尿道造影（VCUG）图像，探讨机器学习在提高诊断一致性的应用。共有113张VCUG图像被回顾，由专家对VUR的严重程度进行了分级。选择了九个基于图像的特征来训练六种预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降。模型通过留一交叉验证进行评估。分析发现肾盂的变形模式是高年级VUR的关键指标。所有模型均实现了准确分类，无假阳性和假阴性。特征值显著的曲线下面积（AUC）证实了模型对不同VUR级别的微妙影像特征的高度敏感性。结果表明，机器学习可以提供客观且标准化的VUR评估替代方案。这些发现强调了肾盂变形作为严重病例强预测因子的重要性。未来研究应致力于扩大数据集、细化成像特征并改善模型的普适性，以供更广泛临床使用。', 'title_zh': '基于机器学习的输尿管反流量化方法以提高准确性和效率'}
{'arxiv_id': 'arXiv:2506.11501', 'title': 'Diabetes Prediction and Management Using Machine Learning Approaches', 'authors': 'Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh, Mohammad Subhi Al-Batah', 'link': 'https://arxiv.org/abs/2506.11501', 'abstract': 'Diabetes has emerged as a significant global health issue, especially with the increasing number of cases in many countries. This trend Underlines the need for a greater emphasis on early detection and proactive management to avert or mitigate the severe health complications of this disease. Over recent years, machine learning algorithms have shown promising potential in predicting diabetes risk and are beneficial for practitioners. Objective: This study highlights the prediction capabilities of statistical and non-statistical machine learning methods over Diabetes risk classification in 768 samples from the Pima Indians Diabetes Database. It consists of the significant demographic and clinical features of age, body mass index (BMI) and blood glucose levels that greatly depend on the vulnerability against Diabetes. The experimentation assesses the various types of machine learning algorithms in terms of accuracy and effectiveness regarding diabetes prediction. These algorithms include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting and Neural Network Models. The results show that the Neural Network algorithm gained the highest predictive accuracy with 78,57 %, and then the Random Forest algorithm had the second position with 76,30 % accuracy. These findings show that machine learning techniques are not just highly effective. Still, they also can potentially act as early screening tools in predicting Diabetes within a data-driven fashion with valuable information on who is more likely to get affected. In addition, this study can help to realize the potential of machine learning for timely intervention over the longer term, which is a step towards reducing health outcomes and disease burden attributable to Diabetes on healthcare systems', 'abstract_zh': '糖尿病已成为一个重要的全球健康问题，特别是随着许多国家病例数的增加。这一趋势凸显了早期检测和积极管理的必要性，以预防或减轻此病的严重健康并发症。近年来，机器学习算法在预测糖尿病风险方面显示出了有希望的潜力，并对实践者有益。目标：本研究强调了统计和非统计机器学习方法在Pima印度人糖尿病数据库768个样本中对糖尿病风险分类的预测能力。此数据库包含年龄、体重指数（BMI）和血糖水平等重要的人口统计和临床特征，这些特征对糖尿病的易感性有很大影响。该研究评估了各种类型的机器学习算法在糖尿病预测方面的准确性和有效性，这些算法包括逻辑回归、决策树、随机森林、K-近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型。研究结果表明，神经网络算法获得了最高的预测准确率，达到78.57%，随后，随机森林算法的准确率为76.30%。这些发现表明，机器学习技术不仅效果显著，还可能作为数据驱动的早期筛查工具，在预测糖尿病方面发挥作用，并提供有关谁更容易受到影响的有价值信息。此外，本研究有助于认识到机器学习在未来及时干预的潜力，从而减少由糖尿病导致的健康结果和疾病负担，这对医疗系统来说是一个重要步骤。', 'title_zh': '使用机器学习方法进行糖尿病预测与管理'}
{'arxiv_id': 'arXiv:2506.11490', 'title': 'Composite Data Augmentations for Synthetic Image Detection Against Real-World Perturbations', 'authors': 'Efthymia Amarantidou, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis', 'link': 'https://arxiv.org/abs/2506.11490', 'abstract': 'The advent of accessible Generative AI tools enables anyone to create and spread synthetic images on social media, often with the intention to mislead, thus posing a significant threat to online information integrity. Most existing Synthetic Image Detection (SID) solutions struggle on generated images sourced from the Internet, as these are often altered by compression and other operations. To address this, our research enhances SID by exploring data augmentation combinations, leveraging a genetic algorithm for optimal augmentation selection, and introducing a dual-criteria optimization approach. These methods significantly improve model performance under real-world perturbations. Our findings provide valuable insights for developing detection models capable of identifying synthetic images across varying qualities and transformations, with the best-performing model achieving a mean average precision increase of +22.53% compared to models without augmentations. The implementation is available at this http URL.', 'abstract_zh': '可访问的生成AI工具的出现使任何人都能够创建和传播合成图像， often with the intention to mislead, thus posing a significant threat to online information integrity.', 'title_zh': '用于对抗现实世界干扰的合成图像检测复合数据增强方法'}
{'arxiv_id': 'arXiv:2506.11485', 'title': 'Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models', 'authors': 'Cole Gawin', 'link': 'https://arxiv.org/abs/2506.11485', 'abstract': "While large language models like BERT demonstrate strong empirical performance on semantic tasks, whether this reflects true conceptual competence or surface-level statistical association remains unclear. I investigate whether BERT encodes abstract relational schemata by examining internal representations of concept pairs across taxonomic, mereological, and functional relations. I compare BERT's relational classification performance with representational structure in [CLS] token embeddings. Results reveal that pretrained BERT enables high classification accuracy, indicating latent relational signals. However, concept pairs organize by relation type in high-dimensional embedding space only after fine-tuning on supervised relation classification tasks. This indicates relational schemata are not emergent from pretraining alone but can be induced via task scaffolding. These findings demonstrate that behavioral performance does not necessarily imply structured conceptual understanding, though models can acquire inductive biases for grounded relational abstraction through appropriate training.", 'abstract_zh': '大型语言模型如BERT在语义任务上表现出强大的实证性能，但这种性能是真实的概念能力还是表面的统计关联仍不清楚。我通过检查概念对在分类学、部分整体和功能关系下的内部表示，探讨BERT是否编码抽象关系框架。将BERT的关系分类性能与其[CLS]标记嵌入的表征结构进行比较。结果表明，预训练的BERT能够实现高分类准确性，显示潜在的关系信号。然而，在监督关系分类任务上的微调后，只有概念对在高维嵌入空间中按照关系类型组织。这表明关系框架并不是仅仅通过预训练产生的，而是可以通过任务支架促使生成。这些发现表明，行为性能并不必然意味着结构化概念理解，但模型可以通过适当的训练获取基于实际关系抽象的归纳偏置。', 'title_zh': 'BERT中的关系模式是可以诱导的，而非 Emergent：语言模型中性能与能力研究'}
{'arxiv_id': 'arXiv:2506.11480', 'title': 'LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment', 'authors': 'Shikun Li, Shipeng Li, Zhiqin Yang, Xinghua Zhang, Gaode Chen, Xiaobo Xia, Hengyu Liu, Zhe Peng', 'link': 'https://arxiv.org/abs/2506.11480', 'abstract': "Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the well-known issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data this http URL facilitate future work, we will release code.", 'abstract_zh': '强化学习（RL）已成为提升大语言模型（LLMs）推理能力的关键技术，然而其数据效率低下仍然是主要瓶颈。为解决这一关键而具有挑战性的问题，我们提出了一种基于梯度对齐的新型方法LearnAlign，该方法能够智能地选择可学习和具有代表性的训练推理数据，以进行RL后训练。为克服梯度范数中响应长度偏差的已知问题，我们引入了基于成功率的数据可学习性指标，它可以指示每个数据点的学习潜力。在三个数学推理基准测试上进行的实验表明，我们的方法在显著减少训练数据需求的同时，能够实现轻微的性能下降甚至提高性能，相比全数据训练。例如，在GSM8K基准测试中，使用更少的数据点（1,000个）时，性能提高到了77.53%，超过了全数据集的77.04%。此外，我们还展示了该方法在分阶段RL设置中的有效性。这项工作为数据高效RL后训练提供了有价值的见解，并为未来优化推理数据的研究奠定了基础。为促进未来工作，我们将发布代码。', 'title_zh': 'LearnAlign: 基于改进梯度对齐的数据选择推理在大规模语言模型中的强化学习'}
{'arxiv_id': 'arXiv:2506.11465', 'title': 'RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer', 'authors': 'Haotian Ni, Yake Wei, Hang Liu, Gong Chen, Chong Peng, Hao Lin, Di Hu', 'link': 'https://arxiv.org/abs/2506.11465', 'abstract': "Multimodal learning faces challenges in effectively fusing information from diverse modalities, especially when modality quality varies across samples. Dynamic fusion strategies, such as attention mechanism in Transformers, aim to address such challenge by adaptively emphasizing modalities based on the characteristics of input data. However, through amounts of carefully designed experiments, we surprisingly observed that the dynamic adaptability of widely-used self-attention models diminishes. Model tends to prefer one modality regardless of data characteristics. This bias triggers a self-reinforcing cycle that progressively overemphasizes the favored modality, widening the distribution gap in attention keys across modalities and deactivating attention mechanism's dynamic properties. To revive adaptability, we propose a simple yet effective method Rolling Query (RollingQ), which balances attention allocation by rotating the query to break the self-reinforcing cycle and mitigate the key distribution gap. Extensive experiments on various multimodal scenarios validate the effectiveness of RollingQ and the restoration of cooperation dynamics is pivotal for enhancing the broader capabilities of widely deployed multimodal Transformers. The source code is available at this https URL.", 'abstract_zh': '多模态学习在融合多样模态信息时面临挑战，尤其是在模态质量在样本间变化的情况下。通过大量精心设计的实验，我们惊讶地发现，广泛使用的自注意力模型的动态适应性在减弱。模型倾向于偏好某一模态，而忽略输入数据的特性。这种偏见引发了一种自我强化循环，逐渐加剧了不同模态间注意键的分布差距，使得注意力机制的动态特性丧失。为恢复适应性，我们提出了一种简单有效的方法Rolling Query（RollingQ），通过旋转查询来平衡注意力分配，打破自我强化循环并缓解键分布差距。在多种多模态场景下的广泛实验验证了RollingQ的有效性，恢复合作动态对于提高广泛部署的多模态Transformer的整体能力至关重要。代码见此链接。', 'title_zh': 'RollingQ: 重新激发多模态Transformer中的合作动态'}
{'arxiv_id': 'arXiv:2506.11455', 'title': 'Voxel-Level Brain States Prediction Using Swin Transformer', 'authors': 'Yifei Sun, Daniel Chahine, Qinghao Wen, Tianming Liu, Xiang Li, Yixuan Yuan, Fernando Calamante, Jinglei Lv', 'link': 'https://arxiv.org/abs/2506.11455', 'abstract': 'Understanding brain dynamics is important for neuroscience and mental health. Functional magnetic resonance imaging (fMRI) enables the measurement of neural activities through blood-oxygen-level-dependent (BOLD) signals, which represent brain states. In this study, we aim to predict future human resting brain states with fMRI. Due to the 3D voxel-wise spatial organization and temporal dependencies of the fMRI data, we propose a novel architecture which employs a 4D Shifted Window (Swin) Transformer as encoder to efficiently learn spatio-temporal information and a convolutional decoder to enable brain state prediction at the same spatial and temporal resolution as the input fMRI data. We used 100 unrelated subjects from the Human Connectome Project (HCP) for model training and testing. Our novel model has shown high accuracy when predicting 7.2s resting-state brain activities based on the prior 23.04s fMRI time series. The predicted brain states highly resemble BOLD contrast and dynamics. This work shows promising evidence that the spatiotemporal organization of the human brain can be learned by a Swin Transformer model, at high resolution, which provides a potential for reducing the fMRI scan time and the development of brain-computer interfaces in the future.', 'abstract_zh': '理解大脑动力学对于神经科学和心理健康至关重要。功能性磁共振成像(fMRI)通过血氧水平依赖(BOLD)信号测量神经活动，反映大脑状态。本研究旨在利用fMRI预测未来的人类静息状态大脑活动。由于fMRI数据存在3D体素级别的空间组织和时间依赖性，我们提出了一种新型架构，该架构采用4D移位窗口(Swin)变换器作为编码器以高效地学习空间-时间信息，并采用卷积解码器以在与输入fMRI数据相同的空间和时间分辨率下实现大脑状态预测。我们使用来自Human Connectome Project (HCP)的100名无关受试者的数据进行模型训练和测试。我们的新型模型在基于先前23.04秒fMRI时间序列预测7.2秒静息状态大脑活动方面显示出了高准确性。预测的大脑状态高度类似于BOLD对比度和动态。本工作提供了令人鼓舞的证据，表明SwinTransformer模型可以在高分辨率下学习人类大脑的空间-时间组织，这为未来减少fMRI扫描时间和开发脑机接口提供了潜在可能。', 'title_zh': '基于Swin Transformer的体素级别脑状态预测'}
{'arxiv_id': 'arXiv:2506.11441', 'title': 'DPUV4E: High-Throughput DPU Architecture Design for CNN on Versal ACAP', 'authors': 'Guoyu Li, Pengbo Zheng, Jian Weng, Enshan Yang', 'link': 'https://arxiv.org/abs/2506.11441', 'abstract': "Convolutional Neural Networks (CNNs) remain prevalent in computer vision applications, and FPGAs, known for their flexibility and energy efficiency, have become essential components in heterogeneous acceleration systems. However, traditional FPGAs face challenges in balancing performance and versatility due to limited on-chip resources. AMD's Versal ACAP architecture, tailored for AI applications, incorporates AI Engines (AIEs) to deliver high computational power. Nevertheless, the platform suffers from insufficient memory bandwidth, hindering the full utilization of the AIEs' theoretical performance. In this paper, we present DPUV4E for the Versal architecture, providing configurations ranging from 2PE ($32.6$ TOPS) to 8PE ($131.0$ TOPS). We design two computation units, Conv PE and DWC PE, to support different computational patterns. Each computation unit's data flow efficiently utilizes the data reuse opportunities to mitigate bandwidth bottlenecks. Additionally, we extend the functionality of each PE to utilize AIEs for non-convolutional operations, reducing resource overhead. Experiments on over 50 models show that compared to previous designs, our design provides $8.6\\times$ the TOPS/W of traditional FPGA-based DPU designs, while reducing DSP usage by $95.8\\%$, LUT usage by $44.7\\%$, and latency to $68.5\\%$ under single-batch conditions. For end-to-end inference, our design improving throughput by up to $2.2\\times$ for depth-wise convolution models and up to $1.3\\times$ for standard models.", 'abstract_zh': '基于Versal架构的DPUV4E：提供从2PE（32.6 TOPS）到8PE（131.0 TOPS）的配置', 'title_zh': 'DPUV4E：基于Versal ACAP的CNN高吞吐量DPU架构设计'}
{'arxiv_id': 'arXiv:2506.11432', 'title': 'KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models', 'authors': 'Taeeun Kim, Semin Jeong, Youngsook Song', 'link': 'https://arxiv.org/abs/2506.11432', 'abstract': 'This research introduces KoGEC, a Korean Grammatical Error Correction system using pre\\--trained translation models. We fine-tuned NLLB (No Language Left Behind) models for Korean GEC, comparing their performance against large language models like GPT-4 and HCX-3. The study used two social media conversation datasets for training and testing. The NLLB models were fine-tuned using special language tokens to distinguish between original and corrected Korean sentences. Evaluation was done using BLEU scores and an "LLM as judge" method to classify error types. Results showed that the fine-tuned NLLB (KoGEC) models outperformed GPT-4o and HCX-3 in Korean GEC tasks. KoGEC demonstrated a more balanced error correction profile across various error types, whereas the larger LLMs tended to focus less on punctuation errors. We also developed a Chrome extension to make the KoGEC system accessible to users. Finally, we explored token vocabulary expansion to further improve the model but found it to decrease model performance. This research contributes to the field of NLP by providing an efficient, specialized Korean GEC system and a new evaluation method. It also highlights the potential of compact, task-specific models to compete with larger, general-purpose language models in specialized NLP tasks.', 'abstract_zh': 'KoGEC：一种基于预训练翻译模型的韩语语法纠错系统及其评估方法', 'title_zh': 'KoGEC : 基于预训练翻译模型的韩语语法纠错'}
{'arxiv_id': 'arXiv:2506.11425', 'title': 'Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards', 'authors': 'Jeff Da, Clinton Wang, Xiang Deng, Yuntao Ma, Nikhil Barhate, Sean Hendryx', 'link': 'https://arxiv.org/abs/2506.11425', 'abstract': "Reinforcement Learning from Verifiable Rewards (RLVR) has been widely adopted as the de facto method for enhancing the reasoning capabilities of large language models and has demonstrated notable success in verifiable domains like math and competitive programming tasks. However, the efficacy of RLVR diminishes significantly when applied to agentic environments. These settings, characterized by multi-step, complex problem solving, lead to high failure rates even for frontier LLMs, as the reward landscape is too sparse for effective model training via conventional RLVR. In this work, we introduce Agent-RLVR, a framework that makes RLVR effective in challenging agentic settings, with an initial focus on software engineering tasks. Inspired by human pedagogy, Agent-RLVR introduces agent guidance, a mechanism that actively steers the agent towards successful trajectories by leveraging diverse informational cues. These cues, ranging from high-level strategic plans to dynamic feedback on the agent's errors and environmental interactions, emulate a teacher's guidance, enabling the agent to navigate difficult solution spaces and promotes active self-improvement via additional environment exploration. In the Agent-RLVR training loop, agents first attempt to solve tasks to produce initial trajectories, which are then validated by unit tests and supplemented with agent guidance. Agents then reattempt with guidance, and the agent policy is updated with RLVR based on the rewards of these guided trajectories. Agent-RLVR elevates the pass@1 performance of Qwen-2.5-72B-Instruct from 9.4% to 22.4% on SWE-Bench Verified. We find that our guidance-augmented RLVR data is additionally useful for test-time reward model training, shown by further boosting pass@1 to 27.8%. Agent-RLVR lays the groundwork for training agents with RLVR in complex, real-world environments where conventional RL methods struggle.", 'abstract_zh': 'Agent-RLVR: Enhancing Reinforcement Learning from Verifiable Rewards in Challenging Agentic Settings', 'title_zh': '基于指导与环境奖励的软件工程代理训练：Agent-RLVR'}
{'arxiv_id': 'arXiv:2506.11421', 'title': 'Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems', 'authors': 'Junli Shao, Jing Dong, Dingzhou Wang, Kowei Shih, Dannier Li, Chengrui Zhou', 'link': 'https://arxiv.org/abs/2506.11421', 'abstract': 'With the rapid growth of Internet services, recommendation systems play a central role in delivering personalized content. Faced with massive user requests and complex model architectures, the key challenge for real-time recommendation systems is how to reduce inference latency and increase system throughput without sacrificing recommendation quality. This paper addresses the high computational cost and resource bottlenecks of deep learning models in real-time settings by proposing a combined set of modeling- and system-level acceleration and optimization strategies. At the model level, we dramatically reduce parameter counts and compute requirements through lightweight network design, structured pruning, and weight quantization. At the system level, we integrate multiple heterogeneous compute platforms and high-performance inference libraries, and we design elastic inference scheduling and load-balancing mechanisms based on real-time load characteristics. Experiments show that, while maintaining the original recommendation accuracy, our methods cut latency to less than 30% of the baseline and more than double system throughput, offering a practical solution for deploying large-scale online recommendation services.', 'abstract_zh': '随着互联网服务的快速增长，推荐系统在提供个性化内容中发挥着核心作用。面对大量的用户请求和复杂的模型架构，实时推荐系统的关键挑战是在不牺牲推荐质量的前提下如何减少推理延迟并提高系统吞吐量。本文通过提出结合模型和系统层面的加速与优化策略，解决了实时场景下深度学习模型的高计算成本和资源瓶颈问题。在模型层面，我们通过轻量级网络设计、结构化剪枝和权重量化大幅减少参数量和计算需求。在系统层面，我们集成多种异构计算平台和高性能推理库，并设计基于实时负载特性的弹性推理调度和负载均衡机制。实验结果表明，在保持原始推荐准确性的前提下，我们的方法将延迟降低到基线的不到30%，并将系统吞吐量提高了一倍以上，为部署大规模在线推荐服务提供了实用解决方案。', 'title_zh': '深度学习模型加速与优化策略在实时推荐系统中的应用'}
{'arxiv_id': 'arXiv:2506.11417', 'title': 'Stop learning it all to mitigate visual hallucination, Focus on the hallucination target', 'authors': 'Dokyoon Yoon, Youngsook Song, Woomyong Park', 'link': 'https://arxiv.org/abs/2506.11417', 'abstract': 'Multimodal Large Language Models (MLLMs) frequently suffer from hallucination issues, generating information about objects that are not present in input images during vision-language tasks. These hallucinations particularly undermine model reliability in practical applications requiring accurate object identification. To address this challenge, we propose \\mymethod,\\ a preference learning approach that mitigates hallucinations by focusing on targeted areas where they occur. To implement this, we build a dataset containing hallucinated responses, correct responses, and target information (i.e., objects present in the images and the corresponding chunk positions in responses affected by hallucinations). By applying a preference learning method restricted to these specific targets, the model can filter out irrelevant signals and focus on correcting hallucinations. This allows the model to produce more factual responses by concentrating solely on relevant information. Experimental results demonstrate that \\mymethod\\ effectively reduces hallucinations across multiple vision hallucination tasks, improving the reliability and performance of MLLMs without diminishing overall performance.', 'abstract_zh': '多模态大语言模型（MLLMs）在视觉语言任务中经常出现幻觉问题，生成输入图像中不存在的对象信息。这些幻觉尤其在需要准确对象识别的实际应用中削弱了模型的可靠性。为应对这一挑战，我们提出了一种名为\\mymethod\\的偏好学习方法，通过关注幻觉发生的目标区域来减轻幻觉问题。为此，我们构建了一个包含幻觉响应、正确响应和目标信息（即图像中存在的对象及其在受到幻觉影响的响应中的对应片段位置）的数据集。通过将偏好学习方法限制应用于这些特定目标，模型能够过滤掉无关信号并专注于纠正幻觉。这使模型能够通过集中关注相关信息来生成更真实的响应。实验结果表明，\\mymethod\\有效减少了多项视觉幻觉任务中的幻觉现象，提高了MLLMs的可靠性和性能，而不损害其整体性能。', 'title_zh': '专注于幻视目标，以减轻视觉幻视现象'}
{'arxiv_id': 'arXiv:2506.11412', 'title': 'The Strategic Imperative for Healthcare Organizations to Build Proprietary Foundation Models', 'authors': 'Naresh Tiwari', 'link': 'https://arxiv.org/abs/2506.11412', 'abstract': 'This paper presents a comprehensive analysis of the strategic imperative for healthcare organizations to develop proprietary foundation models rather than relying exclusively on commercial alternatives. We examine four fundamental considerations driving this imperative: the domain-specific requirements of healthcare data representation, critical data sovereignty and governance considerations unique to healthcare, strategic competitive advantages afforded by proprietary AI infrastructure, and the transformative potential of healthcare-specific foundation models for patient care and organizational operations. Through analysis of empirical evidence, economic frameworks, and organizational case studies, we demonstrate that proprietary multimodal foundation models enable healthcare organizations to achieve superior clinical performance, maintain robust data governance, create sustainable competitive advantages, and accelerate innovation pathways. While acknowledging implementation challenges, we present evidence showing organizations with proprietary AI capabilities demonstrate measurably improved outcomes, faster innovation cycles, and stronger strategic positioning in the evolving healthcare ecosystem. This analysis provides healthcare leaders with a comprehensive framework for evaluating build-versus-buy decisions regarding foundation model implementation, positioning proprietary foundation model development as a cornerstone capability for forward-thinking healthcare organizations.', 'abstract_zh': '本文对医疗保健组织开发专有的基础模型而非完全依赖商业替代品的战略紧迫性进行了全面分析。我们考察了驱动这一紧迫性的四个基本考虑因素：医疗保健数据表示的领域特定需求、独特的医疗保健数据主权和治理考虑、专有AI基础设施所提供的战略竞争优势，以及针对医疗保健的专用基础模型对患者护理和组织运营的变革潜力。通过分析实证证据、经济框架和组织案例研究，我们证明了专有的多模态基础模型使医疗保健组织能够实现卓越的临床表现、维护强大的数据治理、创建可持续的竞争优势，并加快创新路径。尽管承认实施挑战，我们展示的证据表明，拥有专有AI能力的组织在可测量的绩效方面表现更好，创新周期更短，并在不断演变的医疗保健生态系统中拥有更强的战略定位。本文为医疗保健领导者提供了评估基础模型实施的构建与购买决策的综合框架，强调了专有基础模型开发作为前瞻型医疗保健组织核心能力的重要性。', 'title_zh': 'healthcare组织构建自有基础模型的战略 imperative'}
{'arxiv_id': 'arXiv:2506.11403', 'title': 'A correlation-permutation approach for speech-music encoders model merging', 'authors': 'Fabian Ritter-Gutierrez, Yi-Cheng Lin, Jeremy H.M Wong, Hung-yi Lee, Eng Siong Chng, Nancy F. Chen', 'link': 'https://arxiv.org/abs/2506.11403', 'abstract': "Creating a unified speech and music model requires expensive pre-training. Model merging can instead create an unified audio model with minimal computational expense. However, direct merging is challenging when the models are not aligned in the weight space. Motivated by Git Re-Basin, we introduce a correlation-permutation approach that aligns a music encoder's internal layers with a speech encoder. We extend previous work to the case of merging transformer layers. The method computes a permutation matrix that maximizes the model's features-wise cross-correlations layer by layer, enabling effective fusion of these otherwise disjoint models. The merged model retains speech capabilities through this method while significantly enhancing music performance, achieving an improvement of 14.83 points in average score compared to linear interpolation model merging. This work allows the creation of unified audio models from independently trained encoders.", 'abstract_zh': '创建统一的语音和音乐模型需要昂贵的预训练。通过模型合并可以在几乎没有计算成本的情况下创建统一的音频模型。然而，当模型在权重空间中不一致时，直接合并是具有挑战性的。受Git Re-Basin的启发，我们引入了一种相关性-置换方法，将音乐编码器的内部层与语音编码器对齐。我们将先前的工作扩展到合并Transformer层的情况。该方法逐层计算一个置换矩阵，以最大化模型的特征间互相关，从而有效融合这些之前分离的模型。通过这种方法，合并后的模型保留了语音能力，同时显著增强了音乐性能，在平均得分上比线性插值模型合并提高了14.83分。这项工作允许从独立训练的编码器创建统一的音频模型。', 'title_zh': 'speech-音乐编码器模型合并的相关性-置换方法'}
{'arxiv_id': 'arXiv:2506.11402', 'title': 'LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model', 'authors': 'Pradyut Sekhsaria, Marcel Mateos Salles, Hai Huang, Randall Balestriero', 'link': 'https://arxiv.org/abs/2506.11402', 'abstract': "Parameter Efficient FineTuning (PEFT), such as Low-Rank Adaptation (LoRA), aligns pre-trained Large Language Models (LLMs) to particular downstream tasks in a resource-efficient manner. Because efficiency has been the main metric of progress, very little attention has been put in understanding possible catastrophic failures. We uncover one such failure: PEFT encourages a model to search for shortcut solutions to solve its fine-tuning tasks. When very small amount of tokens, e.g., one token per prompt, are correlated with downstream task classes, PEFT makes any pretrained model rely predominantly on that token for decision making. While such spurious tokens may emerge accidentally from incorrect data cleaning, it also opens opportunities for malevolent parties to control a model's behavior from Seamless Spurious Token Injection (SSTI). In SSTI, a small amount of tokens correlated with downstream classes are injected by the dataset creators. At test time, the finetuned LLM's behavior can be controlled solely by injecting those few tokens. We apply SSTI across models from three families (Snowflake Arctic, Apple OpenELM, and Meta LLaMA-3) and four diverse datasets (IMDB, Financial Classification, CommonSense QA, and Bias in Bios). Our findings reveal three astonishing behaviors. First, as few as a single token of SSTI is sufficient to steer a model's decision making. Second, for light SSTI, the reliance on spurious tokens is proportional to the LoRA rank. Lastly, with aggressive SSTI, larger LoRA rank values become preferable to small rank values as it makes the model attend to non-spurious tokens, hence improving robustness.", 'abstract_zh': '基于参数高效微调（PEFT）的灾难性失败探究：从捷径解找到无缝虚假令牌注入（SSTI）', 'title_zh': 'LoRA 用户注意：几个虚假令牌可操纵您的微调模型'}
{'arxiv_id': 'arXiv:2506.11394', 'title': 'Dynamic Double Space Tower', 'authors': 'Weikai Sun, Shijie Song, Han Wang', 'link': 'https://arxiv.org/abs/2506.11394', 'abstract': 'The Visual Question Answering (VQA) task requires the simultaneous understanding of image content and question semantics. However, existing methods often have difficulty handling complex reasoning scenarios due to insufficient cross-modal interaction and capturing the entity spatial relationships in the image.\\cite{huang2023adaptive}\\cite{liu2021comparing}\\cite{guibas2021adaptive}\\cite{zhang2022vsa}We studied a brand-new approach to replace the attention mechanism in order to enhance the reasoning ability of the model and its understanding of spatial this http URL, we propose a dynamic bidirectional spatial tower, which is divided into four layers to observe the image according to the principle of human gestalt vision. This naturally provides a powerful structural prior for the spatial organization between entities, enabling the model to no longer blindly search for relationships between pixels but make judgments based on more meaningful perceptual units. Change from "seeing images" to "perceiving and organizing image content".A large number of experiments have shown that our module can be used in any other multimodal model and achieve advanced results, demonstrating its potential in spatial relationship this http URL, the multimodal visual question-answering model July trained by our method has achieved state-of-the-art results with only 3B parameters, especially on the question-answering dataset of spatial relations.', 'abstract_zh': '视觉问答（VQA）任务要求同时理解图像内容和问题语义。然而，现有方法往往难以处理复杂的推理场景，原因在于跨模态交互不足和无法充分捕捉图像中的实体空间关系。[1][2][3][4]我们研究了一种新的方法，以替换注意力机制，以增强模型的推理能力和其对空间关系的理解。基于人类知觉心理学的原则，我们提出了一种动态双向空间塔，分为四层来观察图像。这自然地为实体之间的空间组织提供了强大的结构先验，使模型能够基于更有意义的知觉单元来判断，而非盲目地在像素之间寻找关系，实现从“看图像”到“感知和组织图像内容”的转变。大量实验表明，我们的模块可以在任何其他多模态模型中使用，并取得优异的结果，显示出其在空间关系理解方面的潜力。采用我们方法训练的多模态视觉问答模型，仅使用3B参数就达到了领先水平，特别是在空间关系的问答数据集上。', 'title_zh': '动态双空间塔'}
{'arxiv_id': 'arXiv:2506.11381', 'title': 'A Variational Approach for Mitigating Entity Bias in Relation Extraction', 'authors': 'Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley', 'link': 'https://arxiv.org/abs/2506.11381', 'abstract': 'Mitigating entity bias is a critical challenge in Relation Extraction (RE), where models often rely excessively on entities, resulting in poor generalization. This paper presents a novel approach to address this issue by adapting a Variational Information Bottleneck (VIB) framework. Our method compresses entity-specific information while preserving task-relevant features. It achieves state-of-the-art performance on relation extraction datasets across general, financial, and biomedical domains, in both indomain (original test sets) and out-of-domain (modified test sets with type-constrained entity replacements) settings. Our approach offers a robust, interpretable, and theoretically grounded methodology.', 'abstract_zh': '缓解实体偏见是关系抽取中的一个关键挑战，模型往往过度依赖实体，导致泛化能力差。本文提出了一种通过适应变分信息瓶颈框架来解决这一问题的新方法。该方法压缩了实体特定信息的同时保留了与任务相关的特征。在通用、金融和生物医药领域的关系抽取数据集中，我们的方法均取得了最佳性能，在领域内（原始测试集）和跨领域（修改测试集，实体类型受限替换）设置下均有效。该方法提供了一种稳健、可解释且理论上扎实的解决方案。', 'title_zh': '基于变分方法的实体偏见缓解在关系提取中的应用'}
{'arxiv_id': 'arXiv:2506.11380', 'title': 'Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation', 'authors': 'Xiaoxin Lu, Ranran Haoran Zhang, Yusen Zhang, Rui Zhang', 'link': 'https://arxiv.org/abs/2506.11380', 'abstract': "People get informed of a daily task plan through diverse media involving both texts and images. However, most prior research only focuses on LLM's capability of textual plan generation. The potential of large-scale models in providing text-image plans remains understudied. Generating high-quality text-image plans faces two main challenges: ensuring consistent alignment between two modalities and keeping coherence among visual steps. To address these challenges, we propose a novel framework that generates and refines text-image plans step-by-step. At each iteration, our framework (1) drafts the next textual step based on the prediction history; (2) edits the last visual step to obtain the next one; (3) extracts PDDL-like visual information; and (4) refines the draft with the extracted visual information. The textual and visual step produced in stage (4) and (2) will then serve as inputs for the next iteration. Our approach offers a plug-and-play improvement to various backbone models, such as Mistral-7B, Gemini-1.5, and GPT-4o. To evaluate the effectiveness of our approach, we collect a new benchmark consisting of 1,100 tasks and their text-image pair solutions covering 11 daily topics. We also design and validate a new set of metrics to evaluate the multimodal consistency and coherence in text-image plans. Extensive experiment results show the effectiveness of our approach on a range of backbone models against competitive baselines. Our code and data are available at this https URL.", 'abstract_zh': '人们通过多种媒体获取日常任务计划，涉及文字和图像。然而，大多数先前的研究仅关注大规模语言模型在文本计划生成方面的能力。大规模模型在提供图文计划方面的潜力尚未得到充分研究。生成高质量的图文计划面临两大主要挑战：确保两种模态之间的一致对齐以及保持视觉步骤之间的连贯性。为应对这些挑战，我们提出了一种新的框架，该框架逐步生成和精炼图文计划。在每次迭代中，该框架：(1) 根据预测历史生成下一阶段的文本步骤；(2) 编辑最后一个视觉步骤以获得下一个步骤；(3) 提取类似PDDL的视觉信息；(4) 用提取的视觉信息精炼草稿。在阶段(4)和(2)生成的文本和视觉步骤将作为下一迭代的输入。我们的方法可以无缝集成到各种骨干模型中，如Mistral-7B、Gemini-1.5和GPT-4o。为了评估我们方法的有效性，我们收集了一个包含1,100个任务及其图文解决方案的新基准，覆盖11个日常生活主题。此外，我们设计并验证了一套新的评价指标，以评估图文计划中的多模态一致性和连贯性。广泛的实验结果表明，与竞争性基线相比，我们的方法在各种骨干模型上具有有效性。我们的代码和数据可在以下链接获取。', 'title_zh': '增强文本-图像计划生成中的多模态一致性和连贯性'}
{'arxiv_id': 'arXiv:2506.11305', 'title': "Don't Pay Attention", 'authors': 'Mohammad Hammoud, Devang Acharya', 'link': 'https://arxiv.org/abs/2506.11305', 'abstract': 'The Transformer has become the de facto standard for large language models and a wide range of downstream tasks across various domains. Despite its numerous advantages like inherent training parallelism, the Transformer still faces key challenges due to its inability to effectively process sequences beyond a fixed context window and the quadratic complexity of its attention mechanism. These challenges have renewed interest in RNN-like architectures, which offer linear scaling with sequence length and improved handling of long-range dependencies, albeit with limited parallelism due to their inherently recurrent nature. In this paper, we propose Avey, a new neural foundational architecture that breaks away from both attention and recurrence. Avey comprises a ranker and an autoregressive neural processor, which collaboratively identify and contextualize only the most relevant tokens for any given token, regardless of their positions in the sequence. Specifically, Avey decouples sequence length from context width, thus enabling effective processing of arbitrarily long sequences. Experimental results show that Avey compares favorably to the Transformer across a variety of standard short-range NLP benchmarks, while notably excelling at capturing long-range dependencies.', 'abstract_zh': '变压器已成为大型语言模型和各种领域广泛下游任务的事实标准。尽管变压器具有固有的训练并行性等众多优势，但由于其无法有效处理超出固定上下文窗口的序列以及其注意力机制的 quadratic 复杂性，变压器仍然面临关键挑战。这些挑战重新激发了对类似 RNN 的架构的兴趣，这些架构提供随序列长度线性扩展的能力并改善了长距离依赖性处理，尽管由于其固有的递归性质，其并行性有限。在本文中，我们提出了一种名为 Avey 的新型神经基础架构，该架构既不依赖于注意力机制也不依赖于递归性。Avey 包括一个排序器和一个自回归神经处理器，二者协同工作以识别并上下文化任意给定标记的最相关标记，而不受其在序列中的位置限制。具体而言，Avey 分离了序列长度和上下文宽度，从而能够有效处理任意长度的序列。实验结果表明，Avey 在多种标准短距离 NLP 基准测试中与变压器相当，并且特别擅长捕获长距离依赖性。', 'title_zh': '不要分散注意力'}
{'arxiv_id': 'arXiv:2506.11302', 'title': 'TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy', 'authors': 'Héctor Carrión, Yutong Bai, Víctor A. Hernández Castro, Kishan Panaganti, Ayush Zenith, Matthew Trang, Tony Zhang, Pietro Perona, Jitendra Malik', 'link': 'https://arxiv.org/abs/2506.11302', 'abstract': 'World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at this https URL.', 'abstract_zh': '世界模型旨在模拟环境并使代理行为更有效。然而，建模真实世界的环境面临独特的挑战，因为环境在空间和时间上动态变化。为了捕捉这些组成的动态，我们引入了一个时空道路图像数据集STRIDE，将360度全景图像排列成丰富的互联观测、状态和动作节点。利用这种结构，我们可以在空间和时间上同时建模以自我为中心的视角、位置坐标和运动命令之间的关系。我们通过基于STRIDE的变压器生成世界模型TARDIS进行基准测试，该模型在一个统一的自回归框架中整合了空间和时间动态。我们在一系列代理任务，如可控的逼真图像合成、指令跟随、自主自我控制以及最先进的地理参照中展示了稳健的性能。这些结果表明了一种有前途的方向——能够理解并操控其物质环境的空间和时间方面的精巧通用代理，并增强了其身体推理能力。训练代码、数据集和模型检查点可在以下网址获取。', 'title_zh': 'TARDIS STRIDE：一种用于探索与自主驾驶的时空道路图像数据集'}
{'arxiv_id': 'arXiv:2506.11300', 'title': 'Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning', 'authors': 'Yang Zhang, Amr Mohamed, Hadi Abdine, Guokan Shang, Michalis Vazirgiannis', 'link': 'https://arxiv.org/abs/2506.11300', 'abstract': 'Curriculum learning has shown promise in improving training efficiency and generalization in various machine learning domains, yet its potential in pretraining language models remains underexplored, prompting our work as the first systematic investigation in this area. We experimented with different settings, including vanilla curriculum learning, pacing-based sampling, and interleaved curricula-guided by six difficulty metrics spanning linguistic and information-theoretic perspectives. We train models under these settings and evaluate their performance on eight diverse benchmarks. Our experiments reveal that curriculum learning consistently improves convergence in early and mid-training phases, and can yield lasting gains when used as a warmup strategy with up to $3.5\\%$ improvement. Notably, we identify compression ratio, lexical diversity, and readability as effective difficulty signals across settings. Our findings highlight the importance of data ordering in large-scale pretraining and provide actionable insights for scalable, data-efficient model development under realistic training scenarios.', 'abstract_zh': 'Curriculum 学习在预训练语言模型中的潜力尚未充分探索：一项系统性研究', 'title_zh': '超越随机采样：通过 Curriculum Learning 提升语言模型预训练效率'}
{'arxiv_id': 'arXiv:2506.11295', 'title': 'A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems', 'authors': 'Renato Cordeiro Ferreira', 'link': 'https://arxiv.org/abs/2506.11295', 'abstract': 'How can the complexity of ML-enabled systems be managed effectively? The goal of this research is to investigate how complexity affects ML-Enabled Systems (MLES). To address this question, this research aims to introduce a metrics-based architectural model to characterize the complexity of MLES. The goal is to support architectural decisions, providing a guideline for the inception and growth of these systems. This paper brings, side-by-side, the architecture representation of two systems that can be used as case studies for creating the metrics-based architectural model: the SPIRA and the Ocean Guard MLES.', 'abstract_zh': '如何有效地管理基于机器学习系统的复杂性？本研究旨在探讨复杂性对基于机器学习系统（MLES）的影响。为此，本研究旨在引入基于度量的架构模型来表征MLES的复杂性，以支持架构决策，为这些系统的开始和成长提供指导。本文并列了两个系统的架构表示，可用作构建基于度量的架构模型的案例研究：SPIRA和Ocean Guard MLES。', 'title_zh': '两系统之事：机器学习使能系统中的架构复杂性特征化'}
{'arxiv_id': 'arXiv:2506.11266', 'title': 'Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation', 'authors': 'Benjamin Elder, Anupama Murthi, Jungkoo Kang, Ankita Rajaram Naik, Kiran Kate, Kinjal Basu, Danish Contractor', 'link': 'https://arxiv.org/abs/2506.11266', 'abstract': 'Large language models (LLMs) are routinely deployed as agentic systems, with access to tools that interact with live environments to accomplish tasks. In enterprise deployments these systems need to interact with API collections that can be extremely large and complex, often backed by databases. In order to create datasets with such characteristics, we explore how existing NL2SQL (Natural Language to SQL query) datasets can be used to automatically create NL2API datasets. Specifically, this work describes a novel data generation pipeline that exploits the syntax of SQL queries to construct a functionally equivalent sequence of API calls. We apply this pipeline to one of the largest NL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be served as invocable tools or REST-endpoints. We pair natural language queries from BIRD-SQL to ground-truth API sequences based on this API pool. We use this collection to study the performance of 10 public LLMs and find that all models struggle to determine the right set of tools (consisting of tasks of intent detection, sequencing with nested function calls, and slot-filling). We find that models have extremely low task completion rates (7-47 percent - depending on the dataset) which marginally improves to 50 percent when models are employed as ReACT agents that interact with the live API environment. The best task completion rates are far below what may be required for effective general-use tool-calling agents, suggesting substantial scope for improvement in current state-of-the-art tool-calling LLMs. We also conduct detailed ablation studies, such as assessing the impact of the number of tools available as well as the impact of tool and slot-name obfuscation. We compare the performance of models on the original SQL generation tasks and find that current models are sometimes able to exploit SQL better than APIs.', 'abstract_zh': '大规模语言模型（LLMs）通常被部署为代理系统，访问与实时环境互动以完成任务的工具。在企业部署中，这些系统需要与可以极其庞大和复杂的API集合交互，这些API集合通常由数据库支持。为了创建具有此类特性的数据集，我们探索了如何利用现有NL2SQL（自然语言到SQL查询）数据集自动生成NL2API数据集的方法。具体而言，这项工作描述了一种新颖的数据生成管道，该管道利用SQL查询的语法构建一个功能上等价的API调用序列。我们将这种管道应用于最大的NL2SQL数据集之一BIRD-SQL，创建了一个包含超过2500个API的集合，这些API可以作为可调用的工具或REST端点提供。我们将BIRD-SQL中的自然语言查询与基于此API池的真实API序列进行配对。我们使用此集合研究了10个公开的LLM的效果，发现所有模型在确定正确工具集（包括意图检测任务、嵌套函数调用的顺序排列和槽填充）方面均存在困难。我们发现模型的任务完成率极低（7-47%，取决于数据集），并在使用作为ReACT代理并与实时API环境互动时略有提高，达到50%。最好的任务完成率远远低于有效的通用用途工具调用代理所需的水平，这表明当前最先进的工具调用LLMs存在显著改进空间。我们还进行了详细的消融研究，例如评估可供使用的工具数量的影响以及工具和槽名称混淆的影响。我们比较了模型在原始SQL生成任务上的性能，发现当前模型有时能够比API更好地利用SQL。', 'title_zh': '来自NL2SQL数据集的可调用APIs及其在LLM工具调用评估中的应用'}
{'arxiv_id': 'arXiv:2506.11261', 'title': 'Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation', 'authors': 'Shizhe Chen, Ricardo Garcia, Paul Pacaud, Cordelia Schmid', 'link': 'https://arxiv.org/abs/2506.11261', 'abstract': 'Robotic manipulation faces a significant challenge in generalizing across unseen objects, environments and tasks specified by diverse language instructions. To improve generalization capabilities, recent research has incorporated large language models (LLMs) for planning and action execution. While promising, these methods often fall short in generating grounded plans in visual environments. Although efforts have been made to perform visual instructional tuning on LLMs for robotic manipulation, existing methods are typically constrained by single-view image input and struggle with precise object grounding. In this work, we introduce Gondola, a novel grounded vision-language planning model based on LLMs for generalizable robotic manipulation. Gondola takes multi-view images and history plans to produce the next action plan with interleaved texts and segmentation masks of target objects and locations. To support the training of Gondola, we construct three types of datasets using the RLBench simulator, namely robot grounded planning, multi-view referring expression and pseudo long-horizon task datasets. Gondola outperforms the state-of-the-art LLM-based method across all four generalization levels of the GemBench dataset, including novel placements, rigid objects, articulated objects and long-horizon tasks.', 'abstract_zh': '基于大型语言模型的多视图接地视觉-语言规划模型Gondola及其在通用机器人操作中的应用', 'title_zh': 'Gondola: 地面指导的视觉语言规划以实现泛化的机器人操作'}
{'arxiv_id': 'arXiv:2506.11251', 'title': 'Measuring multi-calibration', 'authors': 'Ido Guy, Daniel Haimovich, Fridolin Linder, Nastaran Okati, Lorenzo Perini, Niek Tax, Mark Tygert', 'link': 'https://arxiv.org/abs/2506.11251', 'abstract': 'A suitable scalar metric can help measure multi-calibration, defined as follows. When the expected values of observed responses are equal to corresponding predicted probabilities, the probabilistic predictions are known as "perfectly calibrated." When the predicted probabilities are perfectly calibrated simultaneously across several subpopulations, the probabilistic predictions are known as "perfectly multi-calibrated." In practice, predicted probabilities are seldom perfectly multi-calibrated, so a statistic measuring the distance from perfect multi-calibration is informative. A recently proposed metric for calibration, based on the classical Kuiper statistic, is a natural basis for a new metric of multi-calibration and avoids well-known problems of metrics based on binning or kernel density estimation. The newly proposed metric weights the contributions of different subpopulations in proportion to their signal-to-noise ratios; data analyses\' ablations demonstrate that the metric becomes noisy when omitting the signal-to-noise ratios from the metric. Numerical examples on benchmark data sets illustrate the new metric.', 'abstract_zh': '一种合适的标量度量可以帮助衡量多校准。当观测响应的期望值等于相应的预测概率时，概率预测被称为“完美校准”。当预测概率在多个子群体中同时完美校准时，概率预测被称为“完美多校准”。实际上，预测概率很少完全多校准，因此衡量与完美多校准距离的统计量是令人信息丰富的。基于经典的库普勒统计量最近提出的一种校准度量是衡量多校准的新度量的基础，并避免了基于分箱或核密度估计的度量已知的问题。新提出的度量按信号噪声比的比例衡量不同子群体的贡献；数据分析的消融实验表明，如果不从度量中排除信号噪声比，度量会变 noisy。基准数据集上的数值例子说明了新的度量。', 'title_zh': '多校准度量'}
{'arxiv_id': 'arXiv:2506.11250', 'title': 'Can Time-Series Foundation Models Perform Building Energy Management Tasks?', 'authors': 'Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava', 'link': 'https://arxiv.org/abs/2506.11250', 'abstract': 'Building energy management (BEM) tasks require processing and learning from a variety of time-series data. Existing solutions rely on bespoke task- and data-specific models to perform these tasks, limiting their broader applicability. Inspired by the transformative success of Large Language Models (LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets, have the potential to change this. Were TSFMs to achieve a level of generalizability across tasks and contexts akin to LLMs, they could fundamentally address the scalability challenges pervasive in BEM. To understand where they stand today, we evaluate TSFMs across four dimensions: (1) generalizability in zero-shot univariate forecasting, (2) forecasting with covariates for thermal behavior modeling, (3) zero-shot representation learning for classification tasks, and (4) robustness to performance metrics and varying operational conditions. Our results reveal that TSFMs exhibit \\emph{limited} generalizability, performing only marginally better than statistical models on unseen datasets and modalities for univariate forecasting. Similarly, inclusion of covariates in TSFMs does not yield performance improvements, and their performance remains inferior to conventional models that utilize covariates. While TSFMs generate effective zero-shot representations for downstream classification tasks, they may remain inferior to statistical models in forecasting when statistical models perform test-time fitting. Moreover, TSFMs forecasting performance is sensitive to evaluation metrics, and they struggle in more complex building environments compared to statistical models. These findings underscore the need for targeted advancements in TSFM design, particularly their handling of covariates and incorporating context and temporal dynamics into prediction mechanisms, to develop more adaptable and scalable solutions for BEM.', 'abstract_zh': 'Time-Series Foundation Models的现状：面向建筑能源管理任务的挑战与前景', 'title_zh': '时间序列基础模型能否执行建筑能源管理任务？'}
{'arxiv_id': 'arXiv:2506.11246', 'title': 'No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning', 'authors': 'Kushagra Dixit, Abhishek Rajgaria, Harshavardhan Kalalbandi, Dan Roth, Vivek Gupta', 'link': 'https://arxiv.org/abs/2506.11246', 'abstract': "Temporal Table Reasoning is a critical challenge for Large Language Models (LLMs), requiring effective prompting techniques to extract relevant insights. Despite existence of multiple prompting methods, their impact on table reasoning remains largely unexplored. Furthermore, the performance of these models varies drastically across different table and context structures, making it difficult to determine an optimal approach. This work investigates multiple prompting technique across diverse table types to determine optimal approaches for different scenarios. We find that performance varies based on entity type, table structure, requirement of additional context and question complexity, with NO single method consistently outperforming others. To mitigate these challenges, we introduce SEAR, an adaptive prompting framework inspired by human reasoning that dynamically adjusts based on context characteristics and integrates a structured reasoning. Our results demonstrate that SEAR achieves superior performance across all table types compared to other baseline prompting techniques. Additionally, we explore the impact of table structure refactoring, finding that a unified representation enhances model's reasoning.", 'abstract_zh': 'Temporal表推理是大语言模型（LLMs）的一个关键挑战，需要有效的提示技术来提取相关信息。尽管存在多种提示方法，但它们对表推理的影响仍很大程度上未被探索。此外，这些模型在不同表和背景结构上的表现差异巨大，使得难以确定最优方法。本研究调查了多种提示技术在不同表类型中的应用，以确定适用于不同场景的最优方法。我们发现，性能基于实体类型、表结构、额外背景信息的需求以及问题复杂性而变化，没有一种方法能够一贯优于其他方法。为缓解这些挑战，我们提出了SEAR，这是一种受人类推理启发的自适应提示框架，能够根据上下文特征动态调整并集成结构化推理。我们的结果表明，SEAR在所有表类型上都比其他基准提示技术表现出更优的性能。此外，我们探索了表结构重构的影响，发现统一的表示增强了解释模型的能力。', 'title_zh': '无通用提示：通过自适应提示统一时间表推理'}
{'arxiv_id': 'arXiv:2506.11243', 'title': 'RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?', 'authors': 'Santiago Góngora, Ignacio Sastre, Santiago Robaina, Ignacio Remersaro, Luis Chiruzzo, Aiala Rosá', 'link': 'https://arxiv.org/abs/2506.11243', 'abstract': 'In this paper, we present the RETUYT-INCO participation at the BEA 2025 shared task. Our participation was characterized by the decision of using relatively small models, with fewer than 1B parameters. This self-imposed restriction tries to represent the conditions in which many research labs or institutions are in the Global South, where computational power is not easily accessible due to its prohibitive cost. Even under this restrictive self-imposed setting, our models managed to stay competitive with the rest of teams that participated in the shared task. According to the $exact\\ F_1$ scores published by the organizers, the performance gaps between our models and the winners were as follows: $6.46$ in Track 1; $10.24$ in Track 2; $7.85$ in Track 3; $9.56$ in Track 4; and $13.13$ in Track 5. Considering that the minimum difference with a winner team is $6.46$ points -- and the maximum difference is $13.13$ -- according to the $exact\\ F_1$ score, we find that models with a size smaller than 1B parameters are competitive for these tasks, all of which can be run on computers with a low-budget GPU or even without a GPU.', 'abstract_zh': '本研究展现了RETUYT-INCO在BEA 2025共享任务中的参与情况。我们的参与特点是采用了相对较小的模型，参数量少于1亿。这一自我设限的限制试图代表全球南方许多研究实验室或机构的情况，因为这些地方由于高昂的成本，计算资源难以获得。即使在这种限制条件下，我们的模型仍然能够与其他参与共享任务的团队保持竞争力。根据主办方公布的精确F1分数，我们模型与获胜团队之间的性能差异如下：Track 1为6.46；Track 2为10.24；Track 3为7.85；Track 4为9.56；Track 5为13.13。考虑到最小差异为6.46分，最大差异为13.13分，根据精确F1分数，我们发现参数量小于1亿的模型对于这些任务具有竞争力，这些任务都可以在配备低成本GPU的计算机上运行，甚至可以在没有GPU的情况下运行。', 'title_zh': 'RETUYT-INCO在2025年BEA共享任务中的表现：轻量级模型在AI驱动的 tutor 评估中能走多远？'}
{'arxiv_id': 'arXiv:2506.11242', 'title': 'A Causal Lens for Learning Long-term Fair Policies', 'authors': 'Jacob Lear, Lu Zhang', 'link': 'https://arxiv.org/abs/2506.11242', 'abstract': 'Fairness-aware learning studies the development of algorithms that avoid discriminatory decision outcomes despite biased training data. While most studies have concentrated on immediate bias in static contexts, this paper highlights the importance of investigating long-term fairness in dynamic decision-making systems while simultaneously considering instantaneous fairness requirements. In the context of reinforcement learning, we propose a general framework where long-term fairness is measured by the difference in the average expected qualification gain that individuals from different groups could this http URL, through a causal lens, we decompose this metric into three components that represent the direct impact, the delayed impact, as well as the spurious effect the policy has on the qualification gain. We analyze the intrinsic connection between these components and an emerging fairness notion called benefit fairness that aims to control the equity of outcomes in decision-making. Finally, we develop a simple yet effective approach for balancing various fairness notions.', 'abstract_zh': '公平意识的学习研究旨在开发算法以避免在偏倚训练数据下产生歧视性的决策结果。尽管大多数研究集中在静态情境中的即时偏倚，本文强调了在动态决策系统中同时研究长期公平性的重要性。在强化学习的背景下，我们提出了一种通用框架，通过该框架，长期公平性通过不同群体个体之间预期资格增益平均值的差异进行衡量。从因果视角分解这一指标为直接影响、延迟影响以及政策对资格增益的虚假效应三个部分。我们分析了这些组成部分与一种新兴的公平性概念——收益公平之间的内在联系，该概念旨在控制决策中结果的公平性。最后，我们开发了一种简单而有效的方法来平衡各种公平性概念。', 'title_zh': '一种学习长期公平政策的因果视角'}
{'arxiv_id': 'arXiv:2506.11238', 'title': 'uPVC-Net: A Universal Premature Ventricular Contraction Detection Deep Learning Algorithm', 'authors': 'Hagai Hamami, Yosef Solewicz, Daniel Zur, Yonatan Kleerekoper, Joachim A. Behar', 'link': 'https://arxiv.org/abs/2506.11238', 'abstract': 'Introduction: Premature Ventricular Contractions (PVCs) are common cardiac arrhythmias originating from the ventricles. Accurate detection remains challenging due to variability in electrocardiogram (ECG) waveforms caused by differences in lead placement, recording conditions, and population demographics. Methods: We developed uPVC-Net, a universal deep learning model to detect PVCs from any single-lead ECG recordings. The model is developed on four independent ECG datasets comprising a total of 8.3 million beats collected from Holter monitors and a modern wearable ECG patch. uPVC-Net employs a custom architecture and a multi-source, multi-lead training strategy. For each experiment, one dataset is held out to evaluate out-of-distribution (OOD) generalization. Results: uPVC-Net achieved an AUC between 97.8% and 99.1% on the held-out datasets. Notably, performance on wearable single-lead ECG data reached an AUC of 99.1%. Conclusion: uPVC-Net exhibits strong generalization across diverse lead configurations and populations, highlighting its potential for robust, real-world clinical deployment.', 'abstract_zh': 'Introduction: 房室传导阻滞（PVCs）是起源于心室的常见心律失常。由于电心图（ECG）波形因导联放置、记录条件和人口统计学差异而产生的变化，准确检测仍具有挑战性。', 'title_zh': 'uPVC-Net: 一种通用的提前发生的室性期前收缩检测深度学习算法'}
{'arxiv_id': 'arXiv:2506.11214', 'title': 'Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise', 'authors': 'Chuan He, Zhaosong Lu, Defeng Sun, Zhanwang Deng', 'link': 'https://arxiv.org/abs/2506.11214', 'abstract': 'In this paper, we propose practical normalized stochastic first-order methods with Polyak momentum, multi-extrapolated momentum, and recursive momentum for solving unconstrained optimization problems. These methods employ dynamically updated algorithmic parameters and do not require explicit knowledge of problem-dependent quantities such as the Lipschitz constant or noise bound. We establish first-order oracle complexity results for finding approximate stochastic stationary points under heavy-tailed noise and weakly average smoothness conditions -- both of which are weaker than the commonly used bounded variance and mean-squared smoothness assumptions. Our complexity bounds either improve upon or match the best-known results in the literature. Numerical experiments are presented to demonstrate the practical effectiveness of the proposed methods.', 'abstract_zh': '在本文中，我们提出了一种实用的正则化随机一阶方法，该方法结合了Polyak动量、多外推动量和递归动量，用于求解无约束优化问题。这些方法采用动态更新的算法参数，无需显式知道如Lipschitz常数或噪声界等问题依赖量。我们在重尾噪声和弱平均光滑条件下建立了寻找近似随机稳定点的一阶先验复杂度结果，这两种条件均弱于常用的有界方差和均方光滑假设。我们的复杂度界要么改进了要么匹配了文献中已知的最佳结果。数值实验展示了所提方法的实际有效性。', 'title_zh': '重尾噪声下归一化随机一阶方法带动量的复杂性'}
{'arxiv_id': 'arXiv:2506.11182', 'title': 'Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data', 'authors': 'Azim Dehghani Amirabad, Yanfei Zhang, Artem Moskalev, Sowmya Rajesh, Tommaso Mansi, Shuwei Li, Mangal Prakash, Rui Liao', 'link': 'https://arxiv.org/abs/2506.11182', 'abstract': 'Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12 genome editing but remains challenging due to limited data, variation across protospacer adjacent motifs (PAMs-short sequence requirements for Cas binding), and reliance on large-scale training. We investigate whether pre-trained biological foundation model originally trained on transcriptomic data can improve gRNA activity estimation even without domain-specific pre-training. Using embeddings from existing RNA foundation model as input to lightweight regressor, we show substantial gains over traditional baselines. We also integrate chromatin accessibility data to capture regulatory context, improving performance further. Our results highlight the effectiveness of pre-trained foundation models and chromatin accessibility data for gRNA activity prediction.', 'abstract_zh': '基于预训练生物基础模型和染色质可及性数据的gRNA活性预测', 'title_zh': '使用基础模型和染色质可及性数据建模CRISPR-Cas12活性'}
{'arxiv_id': 'arXiv:2506.11180', 'title': 'Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing', 'authors': 'Luis Miguel Vieira da Silva, Aljosha Köcher, Felix Gehlhoff', 'link': 'https://arxiv.org/abs/2506.11180', 'abstract': 'Explicit modeling of capabilities and skills -- whether based on ontologies, Asset Administration Shells, or other technologies -- requires considerable manual effort and often results in representations that are not easily accessible to Large Language Models (LLMs). In this work-in-progress paper, we present an alternative approach based on the recently introduced Model Context Protocol (MCP). MCP allows systems to expose functionality through a standardized interface that is directly consumable by LLM-based agents. We conduct a prototypical evaluation on a laboratory-scale manufacturing system, where resource functions are made available via MCP. A general-purpose LLM is then tasked with planning and executing a multi-step process, including constraint handling and the invocation of resource functions via MCP. The results indicate that such an approach can enable flexible industrial automation without relying on explicit semantic models. This work lays the basis for further exploration of external tool integration in LLM-driven production systems.', 'abstract_zh': '基于Model Context Protocol的能力与技能显式建模——一种替代方法', 'title_zh': '超越形式语义学：制造领域的能力与技能模型上下文协议'}
{'arxiv_id': 'arXiv:2506.11179', 'title': 'Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention', 'authors': 'Md Mynoddin, Troyee Dev, Rishita Chakma', 'link': 'https://arxiv.org/abs/2506.11179', 'abstract': "Mental stress has become a pervasive factor affecting cognitive health and overall well-being, necessitating the development of robust, non-invasive diagnostic tools. Electroencephalogram (EEG) signals provide a direct window into neural activity, yet their non-stationary and high-dimensional nature poses significant modeling challenges. Here we introduce Brain2Vec, a new deep learning tool that classifies stress states from raw EEG recordings using a hybrid architecture of convolutional, recurrent, and attention mechanisms. The model begins with a series of convolutional layers to capture localized spatial dependencies, followed by an LSTM layer to model sequential temporal patterns, and concludes with an attention mechanism to emphasize informative temporal regions. We evaluate Brain2Vec on the DEAP dataset, applying bandpass filtering, z-score normalization, and epoch segmentation as part of a comprehensive preprocessing pipeline. Compared to traditional CNN-LSTM baselines, our proposed model achieves an AUC score of 0.68 and a validation accuracy of 81.25%. These findings demonstrate Brain2Vec's potential for integration into wearable stress monitoring platforms and personalized healthcare systems.", 'abstract_zh': '心理压力已成为影响认知健康和整体福祉的普遍因素，需要开发稳健的非侵入性诊断工具。脑电图（EEG）信号直接揭示了神经活动，但其非平稳性和高维性带来了显著的建模挑战。我们引入了Brain2Vec，这是一种新的深度学习工具，通过结合卷积、循环和注意力机制，从原始EEG记录中分类压力状态。该模型首先使用一系列卷积层来捕捉局部空间依赖性，然后通过一个LSTM层来建模序列时间模式，并以注意机制结束，以强调信息性的时间区域。我们对Brain2Vec进行了评估，使用DEAP数据集，并在全面的预处理流水线中应用带通滤波、z分数标准化和时段分割。相比传统的CNN-LSTM基线，我们提出的模型获得了AUC分数为0.68和验证准确率为81.25%的结果。这些发现表明Brain2Vec有潜力集成到可穿戴压力监测平台和个人化健康系统中。', 'title_zh': 'Brain2Vec：基于CNN-LSTM-Attention的EEG-Based压力检测深度学习框架'}
{'arxiv_id': 'arXiv:2506.11172', 'title': 'Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning', 'authors': 'Xue Zhou, Dapeng Man, Chen Xu, Fanyi Zeng, Tao Liu, Huan Wang, Shucheng He, Chaoyang Gao, Wu Yang', 'link': 'https://arxiv.org/abs/2506.11172', 'abstract': "Offline reinforcement learning (RL) heavily relies on the coverage of pre-collected data over the target policy's distribution. Existing studies aim to improve data-policy coverage to mitigate distributional shifts, but overlook security risks from insufficient coverage, and the single-step analysis is not consistent with the multi-step decision-making nature of offline RL. To address this, we introduce the sequence-level concentrability coefficient to quantify coverage, and reveal its exponential amplification on the upper bound of estimation errors through theoretical analysis. Building on this, we propose the Collapsing Sequence-Level Data-Policy Coverage (CSDPC) poisoning attack. Considering the continuous nature of offline RL data, we convert state-action pairs into decision units, and extract representative decision patterns that capture multi-step behavior. We identify rare patterns likely to cause insufficient coverage, and poison them to reduce coverage and exacerbate distributional shifts. Experiments show that poisoning just 1% of the dataset can degrade agent performance by 90%. This finding provides new perspectives for analyzing and safeguarding the security of offline RL.", 'abstract_zh': '基于序列级收敛系数的离线强化学习数据污染攻击', 'title_zh': '基于中毒攻击的 Offline Reinforcement Learning 中的序列级数据-策略覆盖率坍塌'}
{'arxiv_id': 'arXiv:2506.11170', 'title': 'PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation', 'authors': 'Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen', 'link': 'https://arxiv.org/abs/2506.11170', 'abstract': 'Multivariate time series data, collected across various fields such as manufacturing and wearable technology, exhibit states at multiple levels of granularity, from coarse-grained system behaviors to fine-grained, detailed events. Effectively segmenting and integrating states across these different granularities is crucial for tasks like predictive maintenance and performance optimization. However, existing time series segmentation methods face two key challenges: (1) the inability to handle multiple levels of granularity within a unified model, and (2) limited adaptability to new, evolving patterns in dynamic environments. To address these challenges, we propose PromptTSS, a novel framework for time series segmentation with multi-granularity states. PromptTSS uses a unified model with a prompting mechanism that leverages label and boundary information to guide segmentation, capturing both coarse- and fine-grained patterns while adapting dynamically to unseen patterns. Experiments show PromptTSS improves accuracy by 24.49% in multi-granularity segmentation, 17.88% in single-granularity segmentation, and up to 599.24% in transfer learning, demonstrating its adaptability to hierarchical states and evolving time series dynamics.', 'abstract_zh': '多粒度状态的多变量时间序列分割方法：PromptTSS', 'title_zh': 'PromptTSS: 一种基于提示的交互式多粒度时间序列分割方法'}
{'arxiv_id': 'arXiv:2506.11166', 'title': 'Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning', 'authors': 'Ji Young Byun, Young-Jin Park, Navid Azizan, Rama Chellappa', 'link': 'https://arxiv.org/abs/2506.11166', 'abstract': 'As a cornerstone of patient care, clinical decision-making significantly influences patient outcomes and can be enhanced by large language models (LLMs). Although LLMs have demonstrated remarkable performance, their application to visual question answering in medical imaging, particularly for reasoning-based diagnosis, remains largely unexplored. Furthermore, supervised fine-tuning for reasoning tasks is largely impractical due to limited data availability and high annotation costs. In this work, we introduce a zero-shot framework for reliable medical image diagnosis that enhances the reasoning capabilities of LLMs in clinical settings through test-time scaling. Given a medical image and a textual prompt, a vision-language model processes a medical image along with a corresponding textual prompt to generate multiple descriptions or interpretations of visual features. These interpretations are then fed to an LLM, where a test-time scaling strategy consolidates multiple candidate outputs into a reliable final diagnosis. We evaluate our approach across various medical imaging modalities -- including radiology, ophthalmology, and histopathology -- and demonstrate that the proposed test-time scaling strategy enhances diagnostic accuracy for both our and baseline methods. Additionally, we provide an empirical analysis showing that the proposed approach, which allows unbiased prompting in the first stage, improves the reliability of LLM-generated diagnoses and enhances classification accuracy.', 'abstract_zh': '基于零样本框架的大语言模型在临床医学图像诊断中的推理能力增强：多模态医疗影像诊断中的测试时扩展策略', 'title_zh': '测试时缩放以实现基于视觉-语言推理的零样本诊断'}
{'arxiv_id': 'arXiv:2506.11165', 'title': 'Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data', 'authors': 'Almustapha A. Wakili, Babajide J. Asaju, Woosub Jung', 'link': 'https://arxiv.org/abs/2506.11165', 'abstract': 'This paper compares the performance of BiLSTM and CNN+GRU deep learning models for Human Activity Recognition (HAR) on two WiFi-based Channel State Information (CSI) datasets: UT-HAR and NTU-Fi HAR. The findings indicate that the CNN+GRU model has a higher accuracy on the UT-HAR dataset (95.20%) thanks to its ability to extract spatial features. In contrast, the BiLSTM model performs better on the high-resolution NTU-Fi HAR dataset (92.05%) by extracting long-term temporal dependencies more effectively. The findings strongly emphasize the critical role of dataset characteristics and preprocessing techniques in model performance improvement. We also show the real-world applicability of such models in applications like healthcare and intelligent home systems, highlighting their potential for unobtrusive activity recognition.', 'abstract_zh': '基于WiFi信道状态信息（CSI）的UT-HAR和NTU-Fi HAR数据集上BiLSTM和CNN+GRU深度学习模型在人体活动识别（HAR）中的性能比较：数据集特性与预处理技术的重要性及实际应用', 'title_zh': '基于WiFi CSI数据的人体活动识别中BiLSTM和CNN+GRU方法的评估'}
{'arxiv_id': 'arXiv:2506.11164', 'title': 'Synthetic Geology -- Structural Geology Meets Deep Learning', 'authors': 'Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber', 'link': 'https://arxiv.org/abs/2506.11164', 'abstract': "Visualizing the first few kilometers of the Earth's subsurface, a long-standing challenge gating a virtually inexhaustible list of important applications, is coming within reach through deep learning. Building on techniques of generative artificial intelligence applied to voxelated images, we demonstrate a method that extends surface geological data supplemented by boreholes to a three-dimensional subsurface region by training a neural network. The Earth's land area having been extensively mapped for geological features, the bottleneck of this or any related technique is the availability of data below the surface. We close this data gap in the development of subsurface deep learning by designing a synthetic data-generator process that mimics eons of geological activity such as sediment compaction, volcanic intrusion, and tectonic dynamics to produce a virtually limitless number of samples of the near lithosphere. A foundation model trained on such synthetic data is able to generate a 3D image of the subsurface from a previously unseen map of surface topography and geology, showing increasing fidelity with increasing access to borehole data, depicting such structures as layers, faults, folds, dikes, and sills. We illustrate the early promise of the combination of a synthetic lithospheric generator with a trained neural network model using generative flow matching. Ultimately, such models will be fine-tuned on data from applicable campaigns, such as mineral prospecting in a given region. Though useful in itself, a regionally fine-tuned models may be employed not as an end but as a means: as an AI-based regularizer in a more traditional inverse problem application, in which the objective function represents the mismatch of additional data with physical models with applications in resource exploration, hazard assessment, and geotechnical engineering.", 'abstract_zh': '利用深度学习接近可视化地球表层下几百米的地层结构：一个长期的技术挑战，通过生成人工智能技术应用于体素化图像，我们展示了一种方法，该方法利用地表地质数据和井孔数据扩展至三维地下区域，并通过训练神经网络实现。通过设计一种模拟地质活动（如沉积物压实、火山侵入和构造动力学）的合成数据生成过程，我们解决了地下数据的短缺问题，为地下深度学习的发展生成了几乎无限数量的近地幔样本。基于此类合成数据的基座模型能够生成前所未见的地表地形和地质图的三维地下图像，并随着获取更多井孔数据而逐渐提高图像准确性，展现诸如地层、断层、褶皱、岩脉和岩基等结构。我们使用生成流匹配展示了合成地壳生成器与训练神经网络模型结合的早期潜力。最终，这些模型将在适用的勘探活动中进行微调，如特定地区的矿产勘探。尽管这种模型自身已非常有用，但它可以通过作为基于人工智能的正则化器应用于传统逆问题中来发挥更大的作用，其中目标函数代表额外数据与物理模型之间的不匹配，适用于资源勘探、灾害评估和地质工程。', 'title_zh': '合成地质学——构造地质学与深度学习的融合'}
{'arxiv_id': 'arXiv:2506.11140', 'title': 'Autonomous Computer Vision Development with Agentic AI', 'authors': 'Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown', 'link': 'https://arxiv.org/abs/2506.11140', 'abstract': 'Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, "provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)"), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.', 'abstract_zh': '代理人工智能（AI）系统利用大型语言模型（LLMs）在复杂推理、规划和工具利用方面展现出了显著潜力。我们证明，可以使用代理AI方法从自然语言提示自主构建专门的计算机视觉系统。这包括将开源认知AI环境SimpleMind扩展为结合了基于LLM的代理，并使用OpenManus实现，以自动化特定计算机视觉任务的规划（工具配置）。从用户输入提示“提供针对胸部X光片的肺部、心脏和肋骨分割的SimpleMind配置”，代理LLM能够生成计划（以YAML格式的工具配置文件），并自主执行SM-Learn（训练）和SM-Think（推理）脚本。计算机视觉代理自主配置、训练并测试了50张胸部X光片，肺部、心脏和肋骨的平均_dice得分分别为0.96、0.82和0.83。这项工作展示了以往需要数据科学家在计算机视觉应用开发中进行的传统规划和工具配置的自主潜力。', 'title_zh': '自主智能代理计算机视觉开发'}
{'arxiv_id': 'arXiv:2506.11139', 'title': 'Grids Often Outperform Implicit Neural Representations', 'authors': 'Namhoon Kim, Sara Fridovich-Keil', 'link': 'https://arxiv.org/abs/2506.11139', 'abstract': 'Implicit Neural Representations (INRs) have recently shown impressive results, but their fundamental capacity, implicit biases, and scaling behavior remain poorly understood. We investigate the performance of diverse INRs across a suite of 2D and 3D real and synthetic signals with varying effective bandwidth, as well as both overfitting and generalization tasks including tomography, super-resolution, and denoising. By stratifying performance according to model size as well as signal type and bandwidth, our results shed light on how different INR and grid representations allocate their capacity. We find that, for most tasks and signals, a simple regularized grid with interpolation trains faster and to higher quality than any INR with the same number of parameters. We also find limited settings where INRs outperform grids -- namely fitting signals with underlying lower-dimensional structure such as shape contours -- to guide future use of INRs towards the most advantageous applications. Code and synthetic signals used in our analysis are available at this https URL.', 'abstract_zh': '隐神经表示（INRs）最近取得了令人印象深刻的成果，但它们的基本容量、隐式偏见及其缩放行为仍未被充分理解。我们通过一套2D和3D真实和合成信号的研究，探索了不同INRs在具有变化的有效带宽下的性能，并包括了从属拟合和泛化任务，如计算机断层扫描、超分辨率和去噪。根据模型大小、信号类型和带宽分层分析性能，我们的结果揭示了不同INR和网格表示如何分配其容量。我们发现，在大多数任务和信号中，简单的正则化插值网格训练速度更快且效果更优，具有相同参数数量的任何INR都不及之。我们还发现了一些INRs在网格上占优的情况，即拟合具有潜在低维结构（如形状轮廓）的信号，这可以指导未来如何更好地利用INRs。用于分析的代码和合成信号可在以下网址获取：this https URL。', 'title_zh': '网格往往优于隐式神经表示。'}
{'arxiv_id': 'arXiv:2506.11135', 'title': 'Large Language Models and Emergence: A Complex Systems Perspective', 'authors': 'David C. Krakauer, John W. Krakauer, Melanie Mitchell', 'link': 'https://arxiv.org/abs/2506.11135', 'abstract': 'Emergence is a concept in complexity science that describes how many-body systems manifest novel higher-level properties, properties that can be described by replacing high-dimensional mechanisms with lower-dimensional effective variables and theories. This is captured by the idea "more is different". Intelligence is a consummate emergent property manifesting increasingly efficient -- cheaper and faster -- uses of emergent capabilities to solve problems. This is captured by the idea "less is more". In this paper, we first examine claims that Large Language Models exhibit emergent capabilities, reviewing several approaches to quantifying emergence, and secondly ask whether LLMs possess emergent intelligence.', 'abstract_zh': '复杂科学中的涌现是一种概念，描述了多体系统如何表现出新的高级属性，这些属性可以通过用低维的有效变量和理论来替代高维机制来描述。“更多是不同”的理念涵盖了这一过程。智能是达到极致的涌现属性，表现在越来越高效、更便宜和更快地利用涌现能力解决问题。“更少是更多”的理念概括了这一过程。本文首先考察大型语言模型是否表现出涌现能力，回顾几种度量涌现的方法，其次探讨大型语言模型是否具有涌现智能。', 'title_zh': '大型语言模型与涌现：一个复杂系统视角'}
{'arxiv_id': 'arXiv:2506.11130', 'title': 'A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data', 'authors': 'Cheng Kang Chou, Chan-Jan Hsu, Ho-Lam Chung, Liang-Hsuan Tseng, Hsi-Chun Cheng, Yu-Kuan Fu, Kuan Po Huang, Hung-Yi Lee', 'link': 'https://arxiv.org/abs/2506.11130', 'abstract': 'We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings.', 'abstract_zh': '我们提出一种自修 refinements 框架，仅使用未标注数据提升ASR性能。该过程始于现有ASR模型生成未注音 speech 的伪标签，进而用于训练高保真文本到语音(TTS)系统。之后，合成语音文本对被引导进入原始ASR系统，完成闭环自我改进循环。我们在台湾 Mandarin 语音上展示了该框架的有效性。利用6000小时未标注 speech、适量文本数据以及AI模型生成的合成内容，我们将Whisper-large-v2调整为专门模型Twister。Twister在 Mandarin 任务上的错误率最多降低20%，在 Mandarin-English 切换任务上最多降低50%，相较于Whisper。结果表明该框架是伪标签自我精炼方法的一个有吸引力的替代方案，并为在低资源或领域特定设置中提高ASR性能提供了实用途径。', 'title_zh': '一种增强ASR的自精炼框架：使用TTS合成功音数据'}
{'arxiv_id': 'arXiv:2506.11129', 'title': 'Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK', 'authors': 'Carlos Garcia-Fernandez, Luis Felipe, Monique Shotande, Muntasir Zitu, Aakash Tripathi, Ghulam Rasool, Issam El Naqa, Vivek Rudrapatna, Gilmer Valdes', 'link': 'https://arxiv.org/abs/2506.11129', 'abstract': "Large language models (LLMs) show promise in healthcare, but hallucinations remain a major barrier to clinical use. We present CHECK, a continuous-learning framework that integrates structured clinical databases with a classifier grounded in information theory to detect both factual and reasoning-based hallucinations. Evaluated on 1500 questions from 100 pivotal clinical trials, CHECK reduced LLama3.3-70B-Instruct hallucination rates from 31% to 0.3% - making an open source model state of the art. Its classifier generalized across medical benchmarks, achieving AUCs of 0.95-0.96, including on the MedQA (USMLE) benchmark and HealthBench realistic multi-turn medical questioning. By leveraging hallucination probabilities to guide GPT-4o's refinement and judiciously escalate compute, CHECK boosted its USMLE passing rate by 5 percentage points, achieving a state-of-the-art 92.1%. By suppressing hallucinations below accepted clinical error thresholds, CHECK offers a scalable foundation for safe LLM deployment in medicine and other high-stakes domains.", 'abstract_zh': 'Large语言模型（LLMs）在医疗领域的应用前景广阔，但幻觉仍是临床应用的主要障碍。我们提出了一种连续学习框架CHECK，该框架结合了结构化临床数据库和基于信息论的分类器，以检测事实性和推理性幻觉。CHECK在来自100项关键临床试验的1500个问题上进行评估，将LLama3.3-70B-Instruct的幻觉率从31%降至0.3%，使其开源模型达到领先水平。其分类器在各种医学基准上表现出色，AUC值达到0.95-0.96，包括MedQA（USMLE）基准和HealthBench现实多轮医疗问答。通过利用幻觉概率指导GPT-4o的改进，并谨慎增加计算资源，CHECK将USMLE通过率提高了5个百分点，达到92.1%的领先水平。通过将幻觉抑制在可接受的临床误差阈值以下，CHECK为医疗和其他高风险领域安全地部署大型语言模型提供了可扩展的基础。', 'title_zh': '可信AI医疗：基于CHECK的持续幻觉检测与消除'}
{'arxiv_id': 'arXiv:2506.11128', 'title': 'Stronger Language Models Produce More Human-Like Errors', 'authors': 'Andrew Keenan Richardson, Ryan Othniel Kearns, Sean Moss, Vincent Wang-Mascianica, Philipp Koralus', 'link': 'https://arxiv.org/abs/2506.11128', 'abstract': 'Do language models converge toward human-like reasoning patterns as they improve? We provide surprising evidence that while overall reasoning capabilities increase with model sophistication, the nature of errors increasingly mirrors predictable human reasoning fallacies: a previously unobserved inverse scaling phenomenon. To investigate this question, we apply the Erotetic Theory of Reasoning (ETR), a formal cognitive framework with empirical support for predicting human reasoning outcomes. Using the open-source package PyETR, we generate logical reasoning problems where humans predictably err, evaluating responses from 38 language models across 383 reasoning tasks. Our analysis indicates that as models advance in general capability (as measured by Chatbot Arena scores), the proportion of their incorrect answers that align with ETR-predicted human fallacies tends to increase ($\\rho = 0.360, p = 0.0265$). Notably, as we observe no correlation between model sophistication and logical correctness on these tasks, this shift in error patterns toward human-likeness occurs independently of error rate. These findings challenge the prevailing view that scaling language models naturally obtains normative rationality, suggesting instead a convergence toward human-like cognition inclusive of our characteristic biases and limitations, as we further confirm by demonstrating order-effects in language model reasoning.', 'abstract_zh': '语言模型在性能提升过程中是否向人类类推理模式收敛？我们提供了令人惊讶的证据，尽管模型的整体推理能力随复杂性增加而提高，但错误的性质越来越接近可预测的人类推理谬误：一种先前未观察到的逆向 scaling 现象。', 'title_zh': '更强的语言模型会产生更多的人类错误'}
{'arxiv_id': 'arXiv:2506.11127', 'title': 'GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions', 'authors': 'Wenkang Han, Zhixiong Zeng, Jing Huang, Shu Jiang, Liming Zheng, Longrong Yang, Haibo Qiu, Chang Yao, Jingyuan Chen, Lin Ma', 'link': 'https://arxiv.org/abs/2506.11127', 'abstract': "Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the first end-to-end autonomous GUI agent that directly accepts speech instructions and on-device screenshots to predict actions. Confronted with the scarcity of speech-based GUI agent datasets, we initially generated high-quality speech instructions for training by leveraging a random timbre text-to-speech (TTS) model to convert existing text instructions. We then develop GUIRoboTron-Speech's capabilities through progressive grounding and planning training stages. A key contribution is a heuristic mixed-instruction training strategy designed to mitigate the modality imbalance inherent in pre-trained foundation models. Comprehensive experiments on several benchmark datasets validate the robust and superior performance of GUIRoboTron-Speech, demonstrating the significant potential and widespread applicability of speech as an effective instruction modality for driving GUI agents. Our code and datasets are available at this https URL.", 'abstract_zh': 'autonomously驱动的图形用户界面代理通过语音指令和设备截图直接预测操作，革新人机交互，但仍受制于文本指令依赖，尤其在免手动场景下受到限制。为解决这一问题，我们提出GUIRoboTron-Speech，这是第一个端到端自主图形用户界面（GUI）代理，可以直接接受语音指令并利用设备截图预测操作。面对语音基座模型数据集稀缺的挑战，我们利用随机音色文本转语音（TTS）模型将现有文本指令转换为高质量语音指令进行训练。通过逐步的锚定和规划训练阶段，逐步提升GUIRoboTron-Speech的功能。一个关键贡献是为应对预训练基座模型固有的模态不平衡问题而设计的启发式混合指令训练策略。在多个基准数据集上的全面实验验证了GUIRoboTron-Speech的 robust性能和优越性，展示了语音作为GUI代理有效指令模态的巨大潜力和广泛应用前景。我们的代码和数据集可在该网址获取。', 'title_zh': 'GUIRoboTron-语音: 基于语音指令的自动化GUI代理研究'}
{'arxiv_id': 'arXiv:2506.11125', 'title': 'ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams', 'authors': 'Freddie Grabovski, Gilad Gressel, Yisroel Mirsky', 'link': 'https://arxiv.org/abs/2506.11125', 'abstract': "Large Language Models (LLMs), combined with Text-to-Speech (TTS) and Automatic Speech Recognition (ASR), are increasingly used to automate voice phishing (vishing) scams. These systems are scalable and convincing, posing a significant security threat. We identify the ASR transcription step as the most vulnerable link in the scam pipeline and introduce ASRJam, a proactive defence framework that injects adversarial perturbations into the victim's audio to disrupt the attacker's ASR. This breaks the scam's feedback loop without affecting human callers, who can still understand the conversation. While prior adversarial audio techniques are often unpleasant and impractical for real-time use, we also propose EchoGuard, a novel jammer that leverages natural distortions, such as reverberation and echo, that are disruptive to ASR but tolerable to humans. To evaluate EchoGuard's effectiveness and usability, we conducted a 39-person user study comparing it with three state-of-the-art attacks. Results show that EchoGuard achieved the highest overall utility, offering the best combination of ASR disruption and human listening experience.", 'abstract_zh': '大规模语言模型（LLMs）结合文本转语音（TTS）和自动语音识别（ASR）技术，越来越多地被用于自动化语音钓鱼（vishing）骗局。这些系统具备可扩展性和说服力，构成了重大的安全威胁。我们识别出ASR转录步骤是骗局流程中最脆弱的环节，并介绍了一种名为ASRJam的主动防御框架，该框架向受害者的音频中注入对抗性扰动，以干扰攻击者的ASR，从而打断骗局的反馈循环，而不影响人类来电者的理解。虽然先前的对抗性音频技术往往不愉快且不适合实时使用，我们还提出了EchoGuard这一新型干扰器，利用如回声和混响等自然失真，这些失真对ASR有干扰作用但对人类是可接受的。为了评估EchoGuard的有效性和可用性，我们进行了39人用户研究，将其与三种最先进的攻击方法进行比较。结果显示，EchoGuard在总体效益上最高，提供了最佳的ASR干扰与人类听觉体验的平衡。', 'title_zh': 'ASRJam：面向人类的AI语音干扰技术以防止自动电话诈骗'}
{'arxiv_id': 'arXiv:2506.11121', 'title': 'SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR', 'authors': 'Wei-Ping Huang, Guan-Ting Lin, Hung-yi Lee', 'link': 'https://arxiv.org/abs/2506.11121', 'abstract': 'Despite progress in end-to-end ASR, real-world domain mismatches still cause performance drops, which Test-Time Adaptation (TTA) aims to mitigate by adjusting models during inference. Recent work explores combining TTA with external language models, using techniques like beam search rescoring or generative error correction. In this work, we identify a previously overlooked challenge: TTA can interfere with language model rescoring, revealing the nontrivial nature of effectively combining the two methods. Based on this insight, we propose SUTA-LM, a simple yet effective extension of SUTA, an entropy-minimization-based TTA approach, with language model rescoring. SUTA-LM first applies a controlled adaptation process guided by an auto-step selection mechanism leveraging both acoustic and linguistic information, followed by language model rescoring to refine the outputs. Experiments on 18 diverse ASR datasets show that SUTA-LM achieves robust results across a wide range of domains.', 'abstract_zh': '尽管端到端ASR有了进展，现实世界的领域 mismatch 仍导致性能下降，测试时自适应（TTA）目标是通过推断时调整模型来减轻这一问题。近期研究探索将TTA与外部语言模型结合，使用如束搜索重新评分或生成式错误校正等技术。在本工作中，我们识别了一个先前未被注意的挑战：TTA可以干扰语言模型重新评分，揭示了有效结合这两种方法的非平凡性。基于这一洞察，我们提出了一种简单的有效扩展方法——SUTA-LM，它是在基于熵最小化的TTA方法SUTA基础上，结合了语言模型重新评分的简单有效扩展。SUTA-LM首先通过利用声学和语言信息的自动步长选择机制指导一个受控的适应过程，之后进行语言模型重新评分以精炼输出。在18个不同的ASR数据集上的实验表明，SUTA-LM在多种领域中表现出稳健的结果。', 'title_zh': 'SUTA-LM：连接测试时适应与语言模型重评分以实现稳健的自动语音识别'}
{'arxiv_id': 'arXiv:2506.11120', 'title': 'SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models', 'authors': 'Hourun Zhu, Chengchao Shen', 'link': 'https://arxiv.org/abs/2506.11120', 'abstract': 'In spite of strong performance achieved by LLMs, the costs of their deployment are unaffordable. For the compression of LLMs, gradient-based pruning methods present promising effectiveness. However, in these methods, the gradient computation with one-hot labels ignore the potential predictions on other words, thus missing key information for generative capability of the original model. To address this issue, we introduce a self-distillation loss during the pruning phase (rather than post-training) to fully exploit the predictions of the original model, thereby obtaining more accurate gradient information for pruning. Moreover, we find that, compared to attention modules, the predictions of LLM are less sensitive to multilayer perceptron (MLP) modules, which take up more than $5 \\times$ parameters (LLaMA3.2-1.2B). To this end, we focus on the pruning of MLP modules, to significantly compress LLM without obvious performance degradation. Experimental results on extensive zero-shot benchmarks demonstrate that our method significantly outperforms existing pruning methods. Furthermore, our method achieves very competitive performance among 1B-scale open source LLMs. The source code and trained weights are available at this https URL.', 'abstract_zh': '尽管大规模语言模型取得了strong performance，但其部署成本高昂。为压缩语言模型，基于梯度的剪枝方法显示出良好的效果。然而，在这些方法中，使用one-hot标签的梯度计算忽略了其他词的潜在预测，从而错过了原始模型生成能力的关键信息。为解决这一问题，我们引入了一种自我蒸馏损失，在剪枝阶段（而非后训练阶段）使用此损失，以充分利用原始模型的预测，从而获得更准确的梯度信息进行剪枝。此外，我们发现，与注意力模块相比，语言模型的预测对多层感知机（MLP）模块的敏感性较低，而后者占据的参数量超过前者约5倍（如LLaMA3.2-1.2B）。为此，我们专注于MLP模块的剪枝，以显著压缩语言模型而不显著影响性能。广泛的零样本基准实验结果表明，我们的方法显著优于现有的剪枝方法。此外，我们的方法在1B规模的开源语言模型中表现出很强的竞争力。源代码和训练权重可在以下链接获取。', 'title_zh': 'SDMPrune: 自洽蒸馏MLP剪枝以实现高效大型语言模型'}
{'arxiv_id': 'arXiv:2506.11117', 'title': 'ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research', 'authors': 'Junyong Lin, Lu Dai, Ruiqian Han, Yijie Sui, Ruilin Wang, Xingliang Sun, Qinglin Wu, Min Feng, Hao Liu, Hui Xiong', 'link': 'https://arxiv.org/abs/2506.11117', 'abstract': "Scientific researchers need intensive information about datasets to effectively evaluate and develop theories and methodologies. The information needs regarding datasets are implicitly embedded in particular research tasks, rather than explicitly expressed in search queries. However, existing scientific retrieval and question-answering (QA) datasets typically address straightforward questions, which do not align with the distribution of real-world research inquiries. To bridge this gap, we developed ScIRGen, a dataset generation framework for scientific QA \\& retrieval that more accurately reflects the information needs of professional science researchers, and uses it to create a large-scale scientific retrieval-augmented generation (RAG) dataset with realistic queries, datasets and papers. Technically, we designed a dataset-oriented information extraction method that leverages academic papers to augment the dataset representation. We then proposed a question generation framework by employing cognitive taxonomy to ensure the quality of synthesized questions. We also design a method to automatically filter synthetic answers based on the perplexity shift of LLMs, which is highly aligned with human judgment of answers' validity. Collectively, these methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We benchmarked representative methods on the ScIRGen-Geo dataset for their question-answering and retrieval capabilities, finding out that current methods still suffer from reasoning from complex questions. This work advances the development of more sophisticated tools to support the intricate information needs of the scientific community.", 'abstract_zh': '科学研究人员需要对数据集有详尽的信息以便有效评估和开发理论与方法。数据集的信息需求隐含地嵌入特定的研究任务中，而不是显式地体现在搜索查询中。然而，现有的科学研究检索和问答（QA）数据集通常仅解决简单问题，与实际研究询问的分布不匹配。为了弥合这一差距，我们开发了ScIRGen，一个面向科学QA与检索的的数据集生成框架，更准确地反映了专业科学研究人员的信息需求，并利用该框架创建了一个包含现实询问、数据集和论文的大规模科学检索增强生成（RAG）数据集。技术上，我们设计了一种以数据集为中心的信息提取方法，利用学术论文来增强数据集的表示。然后，我们通过采用认知分类法提出了一个问题生成框架，以确保合成问题的质量。我们还设计了一种方法，根据大型语言模型的困惑度变化自动筛选合成答案，这与人工判断答案的有效性高度一致。这些方法共同 culminated 在创建了包含 61,000 个问答数据的 ScIRGen-Geo 数据集。我们对代表性的方法在 ScIRGen-Geo 数据集上的问答和检索能力进行了基准测试，发现当前的方法仍然难以应对复杂问题的推理。这项工作推动了更复杂的工具的发展，以支持科学研究社区复杂的信息化需求。', 'title_zh': 'ScIRGen: 合成面向科学研究的现实且大规模RAG数据集'}
{'arxiv_id': 'arXiv:2506.11116', 'title': 'Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models', 'authors': 'Jijie Li, Li Du, Hanyu Zhao, Bo-wen Zhang, Liangdong Wang, Boyan Gao, Guang Liu, Yonghua Lin', 'link': 'https://arxiv.org/abs/2506.11116', 'abstract': 'Large Language Models (LLMs) demonstrate strong performance in real-world applications, yet existing open-source instruction datasets often concentrate on narrow domains, such as mathematics or coding, limiting generalization and widening the gap with proprietary models. To bridge this gap, we introduce Infinity-Instruct, a high-quality instruction dataset designed to enhance both foundational and chat capabilities of LLMs through a two-phase pipeline. In Phase 1, we curate 7.4M high-quality foundational instructions (InfInstruct-F-7.4M) from over 100M samples using hybrid data selection techniques. In Phase 2, we synthesize 1.5M high-quality chat instructions (InfInstruct-G-1.5M) through a two-stage process involving instruction selection, evolution, and diagnostic filtering. We empirically evaluate Infinity-Instruct by fine-tuning several open-source models, including Mistral, LLaMA, Qwen, and Yi, and observe substantial performance gains across both foundational and instruction following benchmarks, consistently surpassing official instruction-tuned counterparts. Notably, InfInstruct-LLaMA3.1-70B outperforms GPT-4-0314 by 8.6\\% on instruction following tasks while achieving comparable foundational performance. These results underscore the synergy between foundational and chat training and offer new insights into holistic LLM development. Our dataset\\footnote{this https URL} and codes\\footnote{this https URL} have been publicly released.', 'abstract_zh': '大型语言模型（LLMs）在现实应用中展现了强大的性能，但现有的开源指令数据集往往集中在狭窄的领域，如数学或编码，限制了泛化能力并加大了与专用模型的差距。为弥补这一差距，我们引入了Infinity-Instruct，这是一个高质量的指令数据集，旨在通过两阶段管道增强LLMs的基础性和对话能力。在第一阶段，我们从超过1亿个样本中精选出740万条高质量的基础指令（InfInstruct-F-7.4M），采用混合数据选择技术。在第二阶段，我们通过包含指令选择、演变和诊断过滤的两阶段过程，合成了150万条高质量的对话指令（InfInstruct-G-1.5M）。通过微调多个开源模型，包括Mistral、LLaMA、Qwen和Yi，我们实证评估了Infinity-Instruct，并在基础能力与指令遵循基准测试中观察到显著的性能提升，且始终超越官方指令微调版本。特别是在指令遵循任务上，InfInstruct-LLaMA3.1-70B的表现比GPT-4-0314高出8.6%，同时保持相当的基础性能。这些结果突显了基础训练与对话训练之间的协同作用，并为全面的LLM开发提供了新的见解。我们的数据集和代码已公开发布。', 'title_zh': 'Infinity Instruct：扩展指令选择与合成以增强语言模型'}
{'arxiv_id': 'arXiv:2506.11115', 'title': 'Incorporating Domain Knowledge into Materials Tokenization', 'authors': 'Yerim Oh, Jun-Hyung Park, Junho Kim, SungHo Kim, SangKeun Lee', 'link': 'https://arxiv.org/abs/2506.11115', 'abstract': 'While language models are increasingly utilized in materials science, typical models rely on frequency-centric tokenization methods originally developed for natural language processing. However, these methods frequently produce excessive fragmentation and semantic loss, failing to maintain the structural and semantic integrity of material concepts. To address this issue, we propose MATTER, a novel tokenization approach that integrates material knowledge into tokenization. Based on MatDetector trained on our materials knowledge base and a re-ranking method prioritizing material concepts in token merging, MATTER maintains the structural integrity of identified material concepts and prevents fragmentation during tokenization, ensuring their semantic meaning remains intact. The experimental results demonstrate that MATTER outperforms existing tokenization methods, achieving an average performance gain of $4\\%$ and $2\\%$ in the generation and classification tasks, respectively. These results underscore the importance of domain knowledge for tokenization strategies in scientific text processing. Our code is available at this https URL', 'abstract_zh': '尽管语言模型在材料科学中的应用日益增多，典型的模型通常依赖于最初为自然语言处理设计的频率为中心的词元化方法。然而，这些方法往往导致过度切分和语义损失，无法保持材料概念的结构和语义完整性。为解决这一问题，我们提出了MATTER，这是一种新颖的词元化方法，将材料知识集成到词元化过程中。基于在材料知识库上训练的MatDetector和一个优先合并涉及材料概念的词元的重新排名方法，MATTER在词元化过程中保持了识别的材料概念的结构完整性，并防止了词元化过程中的过度切分，从而确保它们的语义意义保持不变。实验证明，MATTER在生成任务和分类任务中分别平均提高了$4\\%$和$2\\%$的性能，这些结果强调了科学文本处理中的词元化策略中领域知识的重要性。我们的代码可在此处访问。', 'title_zh': '将领域知识融入材料标记化'}
{'arxiv_id': 'arXiv:2506.11114', 'title': 'KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations', 'authors': 'Junyu Liu, Kaiqi Yan, Tianyang Wang, Qian Niu, Momoko Nagai-Tanima, Tomoki Aoyama', 'link': 'https://arxiv.org/abs/2506.11114', 'abstract': 'Recent advances in large language models (LLMs) have demonstrated notable performance in medical licensing exams. However, comprehensive evaluation of LLMs across various healthcare roles, particularly in high-stakes clinical scenarios, remains a challenge. Existing benchmarks are typically text-based, English-centric, and focus primarily on medicines, which limits their ability to assess broader healthcare knowledge and multimodal reasoning. To address these gaps, we introduce KokushiMD-10, the first multimodal benchmark constructed from ten Japanese national healthcare licensing exams. This benchmark spans multiple fields, including Medicine, Dentistry, Nursing, Pharmacy, and allied health professions. It contains over 11588 real exam questions, incorporating clinical images and expert-annotated rationales to evaluate both textual and visual reasoning. We benchmark over 30 state-of-the-art LLMs, including GPT-4o, Claude 3.5, and Gemini, across both text and image-based settings. Despite promising results, no model consistently meets passing thresholds across domains, highlighting the ongoing challenges in medical AI. KokushiMD-10 provides a comprehensive and linguistically grounded resource for evaluating and advancing reasoning-centric medical AI across multilingual and multimodal clinical tasks.', 'abstract_zh': '最近的大语言模型进展已在医学执照考试中显示出了显著表现，但在各种卫生保健角色，特别是在高风险临床场景中的全面评估依然具有挑战性。现有基准通常基于文本，以英语为中心，并主要关注药物知识，限制了它们评估更广泛的卫生保健知识和多模态推理的能力。为解决这些缺口，我们引入了KokushiMD-10，这是第一个基于十个日本国家卫生保健执照考试构建的多模态基准。该基准涵盖了多个领域，包括医学、牙科、护理学、药学和相关卫生专业。它包含了超过11588个真实考试问题，并结合了临床图像和专家标注的理由，以评估文本和视觉推理能力。我们在文本和图像设置中对标了30多种最先进的大语言模型，包括GPT-4o、Claude 3.5和Gemini。尽管取得了令人期待的结果，但没有一个模型能在各个领域一致性地达到及格标准，这突显了医疗AI持续面临的挑战。KokushiMD-10为评估和推进多语言和多模态临床任务中的推理导向型医疗AI提供了全面的语言基础资源。', 'title_zh': 'KokushiMD-10：十项日本国家医疗执照考试评价大语言模型的基准'}
{'arxiv_id': 'arXiv:2506.11113', 'title': 'Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks', 'authors': 'Tzu-Ling Lin, Wei-Chih Chen, Teng-Fang Hsiao, Hou-I Liu, Ya-Hsin Yeh, Yu Kai Chan, Wen-Sheng Lien, Po-Yen Kuo, Philip S. Yu, Hong-Han Shuai', 'link': 'https://arxiv.org/abs/2506.11113', 'abstract': 'Peer review is essential for maintaining academic quality, but the increasing volume of submissions places a significant burden on reviewers. Large language models (LLMs) offer potential assistance in this process, yet their susceptibility to textual adversarial attacks raises reliability concerns. This paper investigates the robustness of LLMs used as automated reviewers in the presence of such attacks. We focus on three key questions: (1) The effectiveness of LLMs in generating reviews compared to human reviewers. (2) The impact of adversarial attacks on the reliability of LLM-generated reviews. (3) Challenges and potential mitigation strategies for LLM-based review. Our evaluation reveals significant vulnerabilities, as text manipulations can distort LLM assessments. We offer a comprehensive evaluation of LLM performance in automated peer reviewing and analyze its robustness against adversarial attacks. Our findings emphasize the importance of addressing adversarial risks to ensure AI strengthens, rather than compromises, the integrity of scholarly communication.', 'abstract_zh': '大型语言模型在面对文本对抗攻击时作为自动化审稿人的稳健性研究', 'title_zh': '破解审稿人：在文本 adversarial 攻击下大型语言模型在自动化同行评审中的脆弱性评估'}
{'arxiv_id': 'arXiv:2506.11111', 'title': 'Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions', 'authors': 'Kun Zhang, Le Wu, Kui Yu, Guangyi Lv, Dacao Zhang', 'link': 'https://arxiv.org/abs/2506.11111', 'abstract': 'Large Language Models (LLMs) have gained enormous attention in recent years due to their capability of understanding and generating natural languages. With the rapid development and wild-range applications (e.g., Agents, Embodied Intelligence), the robustness of LLMs has received increased attention. As the core brain of many AI applications, the robustness of LLMs requires that models should not only generate consistent contents, but also ensure the correctness and stability of generated content when dealing with unexpeted application scenarios (e.g., toxic prompts, limited noise domain data, outof-distribution (OOD) applications, etc). In this survey paper, we conduct a thorough review of the robustness of LLMs, aiming to provide a comprehensive terminology of concepts and methods around this field and facilitate the community. Specifically, we first give a formal definition of LLM robustness and present the collection protocol of this survey paper. Then, based on the types of perturbated inputs, we organize this survey from the following perspectives: 1) Adversarial Robustness: tackling the problem that prompts are manipulated intentionally, such as noise prompts, long context, data attack, etc; 2) OOD Robustness: dealing with the unexpected real-world application scenarios, such as OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of Robustness: summarizing the new evaluation datasets, metrics, and tools for verifying the robustness of LLMs. After reviewing the representative work from each perspective, we discuss and highlight future opportunities and research directions in this field. Meanwhile, we also organize related works and provide an easy-to-search project (this https URL) to support the community.', 'abstract_zh': '大型语言模型（LLMs）的鲁棒性：综述', 'title_zh': '评估与提升大型语言模型的鲁棒性：一项综述与未来方向'}
{'arxiv_id': 'arXiv:2506.11110', 'title': 'AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models', 'authors': 'Jaeho Lee, Atharv Chowdhary', 'link': 'https://arxiv.org/abs/2506.11110', 'abstract': 'Recent benchmarks have probed factual consistency and rhetorical robustness in Large Language Models (LLMs). However, a knowledge gap exists regarding how directional framing of factually true statements influences model agreement, a common scenario for LLM users. AssertBench addresses this by sampling evidence-supported facts from FEVEROUS, a fact verification dataset. For each (evidence-backed) fact, we construct two framing prompts: one where the user claims the statement is factually correct, and another where the user claims it is incorrect. We then record the model\'s agreement and reasoning. The desired outcome is that the model asserts itself, maintaining consistent truth evaluation across both framings, rather than switching its evaluation to agree with the user. AssertBench isolates framing-induced variability from the model\'s underlying factual knowledge by stratifying results based on the model\'s accuracy on the same claims when presented neutrally. In doing so, this benchmark aims to measure an LLM\'s ability to "stick to its guns" when presented with contradictory user assertions about the same fact. The complete source code is available at this https URL.', 'abstract_zh': '近期的研究基准已经探索了大型语言模型（LLMs）在事实一致性方面的表现和论辩稳健性。然而，在方向性框架对事实正确陈述的影响导致模型一致性变化这一常见场景方面，仍然存在知识差距。AssertBench通过从FEVEROUS事实验证数据集中采样证据支持的事实来解决这一问题。对于每个（证据支持的）事实，我们构建两种框架提示：一种情况下用户声称该陈述是事实正确的，另一种情况下用户声称该陈述是不正确的。然后记录模型的共识和推理过程。期望的结果是模型坚持自己的立场，在两种框架下保持一致的真相评估，而不是根据用户的说法改变评估。AssertBench通过根据模型在中立呈现同一主张时的准确性来分层结果，从而隔离由框架引起的变化，旨在衡量LLM在面对用户关于同一事实的矛盾主张时坚持自己结论的能力。完整的源代码可在以下网址获得：this https URL。', 'title_zh': 'AssertBench: 一个用于评估大型语言模型自我断言能力的基准测试'}
{'arxiv_id': 'arXiv:2506.11109', 'title': 'Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization', 'authors': 'Yile Chen, Yicheng Tao, Yue Jiang, Shuai Liu, Han Yu, Gao Cong', 'link': 'https://arxiv.org/abs/2506.11109', 'abstract': "The widespread adoption of location-based services has led to the generation of vast amounts of mobility data, providing significant opportunities to model user movement dynamics within urban environments. Recent advancements have focused on adapting Large Language Models (LLMs) for mobility analytics. However, existing methods face two primary limitations: inadequate semantic representation of locations (i.e., discrete IDs) and insufficient modeling of mobility signals within LLMs (i.e., single templated instruction fine-tuning). To address these issues, we propose QT-Mob, a novel framework that significantly enhances LLMs for mobility analytics. QT-Mob introduces a location tokenization module that learns compact, semantically rich tokens to represent locations, preserving contextual information while ensuring compatibility with LLMs. Furthermore, QT-Mob incorporates a series of complementary fine-tuning objectives that align the learned tokens with the internal representations in LLMs, improving the model's comprehension of sequential movement patterns and location semantics. The proposed QT-Mob framework not only enhances LLMs' ability to interpret mobility data but also provides a more generalizable approach for various mobility analytics tasks. Experiments on three real-world dataset demonstrate the superior performance in both next-location prediction and mobility recovery tasks, outperforming existing deep learning and LLM-based methods.", 'abstract_zh': '基于位置的服务普及产生了大量移动数据，为城市环境中用户移动动态建模提供了重要机会。近期进展集中在将大规模语言模型（LLMs）适应于移动性分析。然而，现有方法主要面临两个局限：位置表示不足（即离散ID）和移动信号建模不足（即单一模板指令微调）。为解决这些问题，我们提出了QT-Mob框架，该框架显著提高了LLMs在移动性分析中的性能。QT-Mob引入了一种位置标记化模块，学习紧凑且语义丰富的标记来表示位置，并同时保留上下文信息，确保与LLMs兼容。此外，QT-Mob还整合了一系列互补的微调目标，将学习到的标记与LLMs的内部表示对齐，从而提高模型对序列移动模式和位置语义的理解能力。提出的QT-Mob框架不仅增强了LLMs解释移动数据的能力，还为各种移动性分析任务提供了一种更通用的方法。在三个真实世界数据集上的实验展示了在下个位置预测和移动性恢复任务中的优越性能，优于现有的深度学习和基于LLM的方法。', 'title_zh': '增强大型语言模型在语义位置分词下的移动性分析能力'}
{'arxiv_id': 'arXiv:2506.11107', 'title': 'Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor', 'authors': 'Weibo Gao, Qi Liu, Rui Li, Yuze Zhao, Hao Wang, Linan Yre, Fangzhou Yao, Zheng Zhang', 'link': 'https://arxiv.org/abs/2506.11107', 'abstract': "Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners' mastery levels of programming knowledge based on their coding activities, facilitating more effective and personalized programming education. However, current PKT studies primarily focus on the implicit relationship between code content and knowledge assessment, often overlooking two types of noise signals in long-term programming activities: unwanted signals from unrelated submissions and weak signals from minor modifications. This practical challenge significantly limits model performance and application. To address this issue, we propose Coda, a Code graph-based tuning adaptor designed to enhance existing PKT models by identifying and mitigating the impact of noise. Specifically, Coda first transforms the loose code sequences submitted by each learner into a compact code graph. By leveraging this code graph, unwanted signals can be identified from a semantic similarity perspective. We then apply a cluster-aware GCN to the code graph, which improves the discrimination of weak signals and enables their clustering for identification. Finally, a lightweight yet effective adaptor is incorporated into the PKT task through optimization with two noise feature-based constraints and a navigational regularization term, to correct knowledge states affected by noise. It is worth mentioning that the Coda framework is model-agnostic and can be adapted to most existing PKT solutions. Extensive experimental results on four real-world datasets demonstrate that Coda effectively performs the PKT task in the presence of noisy programming records, outperforming typical baselines.", 'abstract_zh': '编程知识追踪（PKT）旨在基于学习者的编码活动动态诊断其编程知识的掌握水平，促进更有效的个性化编程教育。然而，当前的PKT研究主要关注代码内容与知识评估之间的隐含关系，常常忽视长时间编程活动中两种类型的噪声信号：与提交内容无关的信号和小规模修改产生的弱信号。这一实际挑战显著限制了模型的性能和应用。为解决这一问题，我们提出了一种名为Coda的基于代码图的调优适配器，旨在通过识别和减轻噪声的影响来增强现有的PKT模型。具体而言，Coda首先将每位学习者提交的松散代码序列转换为紧凑的代码图。通过利用这一代码图，可以从语义相似性的角度识别出不需要的信号。随后，我们使用意识聚类的图卷积神经网络（GCN）应用于代码图，从而提高对弱信号的区分能力，并使它们能够被聚类识别。最后，通过优化引入两种基于噪声特征的约束和导航正则化项，一个轻量而有效的适配器被整合到PKT任务中，以纠正受到噪声影响的知识状态。值得一提的是，Coda框架对模型具有普适性，可以适应大多数现有的PKT解决方案。在四个真实世界数据集上的广泛实验结果表明，Coda能够在存在噪声编程记录的情况下有效执行PKT任务，优于典型的基础模型。', 'title_zh': '基于代码图的调优适配器编程知识清理'}
{'arxiv_id': 'arXiv:2506.11106', 'title': 'Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking', 'authors': 'Ningyuan Li, Junrui Liu, Yi Shan, Minghui Huang, Tong Li', 'link': 'https://arxiv.org/abs/2506.11106', 'abstract': "Contemporary graph-based retrieval-augmented generation (RAG) methods typically begin by extracting entities from user queries and then leverage pre-constructed knowledge graphs to retrieve related relationships and metadata. However, this pipeline's exclusive reliance on entity-level extraction can lead to the misinterpretation or omission of latent yet critical information and relations. As a result, retrieved content may be irrelevant or contradictory, and essential knowledge may be excluded, exacerbating hallucination risks and degrading the fidelity of generated responses. To address these limitations, we introduce PankRAG, a framework that combines a globally aware, hierarchical query-resolution strategy with a novel dependency-aware reranking mechanism. PankRAG first constructs a multi-level resolution path that captures both parallel and sequential interdependencies within a query, guiding large language models (LLMs) through structured reasoning. It then applies its dependency-aware reranker to exploit the dependency structure among resolved sub-questions, enriching and validating retrieval results for subsequent sub-questions. Empirical evaluations demonstrate that PankRAG consistently outperforms state-of-the-art approaches across multiple benchmarks, underscoring its robustness and generalizability.", 'abstract_zh': '基于图的 contemporary 检索增强生成（RAG）方法通常首先从用户查询中提取实体，然后利用预先构建的知识图谱检索相关关系和元数据。然而，这种管道依赖于实体级提取，可能导致潜在但关键的信息和关系被误解或遗漏。因此，检索的内容可能与不相关或存在矛盾，必要知识可能被排除，加剧幻觉风险并降低生成响应的准确性。为解决这些限制，我们提出 PankRAG 框架，该框架结合了全局意识的分层查询解决策略和新颖的依存关系意识重排序机制。PankRAG 首先构建一个多级解决路径，捕获查询内的并行和序列依存关系，引导大型语言模型（LLMs）进行结构化推理。然后应用其依存关系意识重排序器，利用已解决子问题之间的依存关系结构，为后续子问题丰富和验证检索结果。实证评估表明，PankRAG 在多个基准测试中始终优于当前最先进的方法，证明了其鲁棒性和泛化能力。', 'title_zh': '基于图的RAG增强通过全局查询消歧和依赖感知重排序'}
{'arxiv_id': 'arXiv:2506.11105', 'title': 'Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation', 'authors': 'Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin', 'link': 'https://arxiv.org/abs/2506.11105', 'abstract': 'Large Language Models (LLMs) have significant impact on the healthcare scenarios but remain prohibitively large for deployment in real-time, resource-constrained environments such as edge devices. In this work, we introduce a novel medical assistant system, optimized through our general-purpose compression framework, which tailors Large Language Models (LLMs) for deployment in specialized domains. By measuring neuron saliency on domain-specific data, our method can aggressively prune irrelevant neurons, reducing model size while preserving performance. Following pruning, we apply post-training quantization to further reduce the memory footprint, and evaluate the compressed model across medical benchmarks including MedMCQA, MedQA, and PubMedQA. We also deploy the 50\\% compressed Gemma and the 67\\% compressed LLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak), achieving real-time, energy-efficient inference under hardware constraints.', 'abstract_zh': '大型语言模型（LLMs）在医疗场景中产生了显著影响，但由于资源限制，难以在边缘设备等实时环境中部署。本文介绍了一种通过通用压缩框架优化的新型医疗助手系统，该系统针对特定领域对大型语言模型进行定制部署。通过在领域特定数据上测量神经元的显著性，我们的方法可以大幅剪枝无关神经元，从而减小模型大小并保持性能。剪枝后，我们应用后训练量化进一步减少模型的记忆占用，并在MedMCQA、MedQA和PubMedQA等医疗基准测试上评估压缩模型。我们还在Jetson Orin Nano（峰值功率18.7W）和Raspberry Pi 5（峰值功率6.3W）上部署了50%压缩的Gemma和67%压缩的LLaMA3模型，实现了在硬件限制下的实时、能源高效推理。', 'title_zh': '基于输入驱动的显著性适配实现边缘设备医疗AI助手'}
{'arxiv_id': 'arXiv:2506.11104', 'title': 'DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration', 'authors': 'Hanzhi Zhang, Heng Fan, Kewei Sha, Yan Huang, Yunhe Feng', 'link': 'https://arxiv.org/abs/2506.11104', 'abstract': 'Long-context understanding is crucial for many NLP applications, yet transformers struggle with efficiency due to the quadratic complexity of self-attention. Sparse attention methods alleviate this cost but often impose static, predefined masks, failing to capture heterogeneous attention patterns. This results in suboptimal token interactions, limiting adaptability and retrieval accuracy in long-sequence tasks. This work introduces a dynamic sparse attention mechanism that assigns adaptive masks at the attention-map level, preserving heterogeneous patterns across layers and heads. Unlike existing approaches, our method eliminates the need for fine-tuning and predefined mask structures while maintaining computational efficiency. By learning context-aware attention structures, it achieves high alignment with full-attention models, ensuring minimal performance degradation while reducing memory and compute overhead. This approach provides a scalable alternative to full attention, enabling the practical deployment of large-scale Large Language Models (LLMs) without sacrificing retrieval performance. DAM is available at: this https URL.', 'abstract_zh': '长上下文理解对于许多NLP应用至关重要，但由于自注意力的二次复杂性，变压器在效率方面存在挑战。稀疏注意力方法可以减轻这种成本，但通常会施加静态的预定义掩码，无法捕捉到异质注意力模式。这会导致子优化的令牌交互，限制了在长序列任务中的适应性和检索准确性。本工作引入了一种动态稀疏注意力机制，在注意力图层面分配自适应掩码，并在各层和各个头部之间保留异质模式。与现有方法不同，我们的方法消除了调优和预定义掩码结构的需要，同时保持了计算效率。通过学习上下文感知的注意力结构，它在与全注意力模型对齐方面取得了高水准，确保在减少内存和计算开销的同时最小化性能退化。该方法提供了一种全注意力的可扩展替代方案，使大规模大型语言模型（LLMs）的实用部署成为可能而不牺牲检索性能。动态稀疏注意力机制（DAM）详见：this https URL。', 'title_zh': 'DAM：长上下文大型语言模型推理加速的动态注意力掩码'}
{'arxiv_id': 'arXiv:2506.11103', 'title': 'You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model', 'authors': 'Wenchong He, Liqian Peng, Zhe Jiang, Alex Go', 'link': 'https://arxiv.org/abs/2506.11103', 'abstract': 'Large language models (LLMs) possess a remarkable ability to perform in-context learning (ICL), which enables them to handle multiple downstream tasks simultaneously without requiring task-specific fine-tuning. Recent studies have shown that even moderately sized LLMs, such as Mistral 7B, Gemma 7B and Llama-3 8B, can achieve ICL through few-shot in-context fine-tuning of all tasks at once. However, this approach still lags behind dedicated fine-tuning, where a separate model is trained for each individual task.\nIn this paper, we propose a novel approach, Many-Shot In-Context Fine-tuning (ManyICL), which significantly narrows this performance gap by extending the principles of ICL to a many-shot setting. To unlock the full potential of ManyICL and address the inherent inefficiency of processing long sequences with numerous in-context examples, we propose a novel training objective. Instead of solely predicting the final answer, our approach treats every answer within the context as a supervised training target. This effectively shifts the role of many-shot examples from prompts to targets for autoregressive learning. Through extensive experiments on diverse downstream tasks, including classification, summarization, question answering, natural language inference, and math, we demonstrate that ManyICL substantially outperforms zero/few-shot fine-tuning and approaches the performance of dedicated fine-tuning. Furthermore, ManyICL significantly mitigates catastrophic forgetting issues observed in zero/few-shot fine-tuning. The code will be made publicly available upon publication.', 'abstract_zh': '大型语言模型（LLMs）具备在上下文中文学习（ICL）的能力，这使它们能够在不需要特定任务微调的情况下同时处理多个下游任务。 recent studies have shown that even moderately sized LLMs, such as Mistral 7B, Gemma 7B and Llama-3 8B, can achieve ICL through few-shot in-context fine-tuning of all tasks at once. However, this approach still lags behind dedicated fine-tuning, where a separate model is trained for each individual task.\n\n在本论文中，我们提出了一种新颖的方法，多-shot 在上下文中的微调（ManyICL），这种方法通过将 ICL 原理扩展到多-shot 设置中，显著缩小了这一性能差距。为了发挥 ManyICL 的全部潜力并解决处理大量上下文示例时的固有效率低下的问题，我们提出了一种新的训练目标。我们的方法不仅预测最终答案，还将上下文中的每个答案作为监督训练目标。这实际上将多-shot 示例的角色从提示转换为自回归学习的目标。通过对分类、总结、问答、自然语言推理和数学等多种下游任务进行广泛的实验，我们证明 ManyICL 显著优于零-shot/few-shot 微调，并接近专门微调的性能。此外，ManyICL 显著缓解了零-shot/few-shot 微调中观察到的灾难性遗忘问题。代码将在发表后公开。', 'title_zh': '只需一次微调：多-shot上下文微调大语言模型'}
{'arxiv_id': 'arXiv:2506.11102', 'title': 'Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey', 'authors': 'Jiachen Zhu, Menghui Zhu, Renting Rui, Rong Shan, Congmin Zheng, Bo Chen, Yunjia Xi, Jianghao Lin, Weiwen Liu, Ruiming Tang, Yong Yu, Weinan Zhang', 'link': 'https://arxiv.org/abs/2506.11102', 'abstract': 'The advent of large language models (LLMs), such as GPT, Gemini, and DeepSeek, has significantly advanced natural language processing, giving rise to sophisticated chatbots capable of diverse language-related tasks. The transition from these traditional LLM chatbots to more advanced AI agents represents a pivotal evolutionary step. However, existing evaluation frameworks often blur the distinctions between LLM chatbots and AI agents, leading to confusion among researchers selecting appropriate benchmarks. To bridge this gap, this paper introduces a systematic analysis of current evaluation approaches, grounded in an evolutionary perspective. We provide a detailed analytical framework that clearly differentiates AI agents from LLM chatbots along five key aspects: complex environment, multi-source instructor, dynamic feedback, multi-modal perception, and advanced capability. Further, we categorize existing evaluation benchmarks based on external environments driving forces, and resulting advanced internal capabilities. For each category, we delineate relevant evaluation attributes, presented comprehensively in practical reference tables. Finally, we synthesize current trends and outline future evaluation methodologies through four critical lenses: environment, agent, evaluator, and metrics. Our findings offer actionable guidance for researchers, facilitating the informed selection and application of benchmarks in AI agent evaluation, thus fostering continued advancement in this rapidly evolving research domain.', 'abstract_zh': '大型语言模型（LLMs）如GPT、Gemini和DeepSeek的出现显著推进了自然语言处理的发展，引发了多样化的语言相关任务能力强大的聊天机器人。从这些传统的LLM聊天机器人向更先进的AI代理的过渡代表了一次关键的进化步骤。然而，现有的评估框架往往模糊了LLM聊天机器人与AI代理之间的区别，导致研究人员在选择合适的基准时产生混淆。为了解决这一问题，本文从进化视角出发，介绍了一种系统的评估方法分析，提供了一个详细的分析框架，从复杂环境、多源指导者、动态反馈、多模态感知以及高级能力五个关键方面明确区分AI代理和LLM聊天机器人。此外，我们基于外部环境驱动力和产生的高级内部能力对现有的评估基准进行了分类。对于每个类别，我们界定了相关的评估属性，并在实用参考表中进行了全面展示。最后，我们通过环境、代理、评估者和指标这四个关键视角，综合当前趋势并勾勒出未来评估方法。我们的发现为研究人员提供了可操作的指导，有助于他们根据评估任务做出明智的选择和应用，从而推动这一快速发展的研究领域的持续进步。', 'title_zh': '基于进化视角的LLM驱动AI代理评估综述'}
{'arxiv_id': 'arXiv:2506.11100', 'title': 'An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry', 'authors': 'Tianle Wang, Jorge Ramirez, Cristina Garcia-Cardona, Thomas Proffen, Shantenu Jha, Sudip K. Seal', 'link': 'https://arxiv.org/abs/2506.11100', 'abstract': 'Structure determination workloads in neutron diffractometry are computationally expensive and routinely require several hours to many days to determine the structure of a material from its neutron diffraction patterns. The potential for machine learning models trained on simulated neutron scattering patterns to significantly speed up these tasks have been reported recently. However, the amount of simulated data needed to train these models grows exponentially with the number of structural parameters to be predicted and poses a significant computational challenge. To overcome this challenge, we introduce a novel batch-mode active learning (AL) policy that uses uncertainty sampling to simulate training data drawn from a probability distribution that prefers labelled examples about which the model is least certain. We confirm its efficacy in training the same models with about 75% less training data while improving the accuracy. We then discuss the design of an efficient stream-based training workflow that uses this AL policy and present a performance study on two heterogeneous platforms to demonstrate that, compared with a conventional training workflow, the streaming workflow delivers about 20% shorter training time without any loss of accuracy.', 'abstract_zh': '中子衍射结构确定的工作负载计算密集型，通常需要数小时到数天才能从材料的中子衍射图中确定其结构。近期有报道显示，基于模拟中子散射图的机器学习模型有可能显著加速这些任务。然而，随着需要预测的结构参数数量的增加，用于训练这些模型的模拟数据量呈指数增长，带来了显著的计算挑战。为克服这一挑战，我们提出了一种新颖的批处理模式主动学习(AL)策略，利用不确定性取样模拟从模型最不确定的标签样本中抽取的概率分布数据。我们验证了该策略在使用约75%少的训练数据的同时提高了准确性。随后，我们讨论了一种高效的流式训练工作流的设计，该工作流使用这种AL策略，并在两个异构平台上进行了性能研究，表明与传统的训练工作流相比，流式工作流可以在不牺牲准确性的前提下将训练时间缩短约20%。', 'title_zh': '基于主动学习的流式管道： neutrons 衍射结构寻找模型的高效数据训练'}
{'arxiv_id': 'arXiv:2506.11099', 'title': 'Knowledge Graph Embeddings with Representing Relations as Annular Sectors', 'authors': 'Huiling Zhu, Yingqi Zeng', 'link': 'https://arxiv.org/abs/2506.11099', 'abstract': 'Knowledge graphs (KGs), structured as multi-relational data of entities and relations, are vital for tasks like data analysis and recommendation systems. Knowledge graph completion (KGC), or link prediction, addresses incompleteness of KGs by inferring missing triples (h, r, t). It is vital for downstream applications. Region-based embedding models usually embed entities as points and relations as geometric regions to accomplish the task. Despite progress, these models often overlook semantic hierarchies inherent in entities. To solve this problem, we propose SectorE, a novel embedding model in polar coordinates. Relations are modeled as annular sectors, combining modulus and phase to capture inference patterns and relation attributes. Entities are embedded as points within these sectors, intuitively encoding hierarchical structure. Evaluated on FB15k-237, WN18RR, and YAGO3-10, SectorE achieves competitive performance against various kinds of models, demonstrating strengths in semantic modeling capability.', 'abstract_zh': '基于区域的嵌入模型通常将实体嵌入为点，将关系嵌入为几何区域以完成任务。尽管取得了进展，这些模型往往忽略了实体中存在的语义层次结构。为解决这一问题，我们提出了一种新的极坐标嵌入模型SectorE。关系被建模为环形扇区，结合模数和相位来捕捉推理模式和关系属性。实体嵌入为此类扇区内的点，直观地编码层次结构。SectorE在FB15k-237、WN18RR和YAGO3-10上的评估结果表明，该模型在语义建模能力方面具有竞争力。', 'title_zh': '基于表示关系为环形扇区的知识图嵌入'}
{'arxiv_id': 'arXiv:2506.11098', 'title': 'Debiasing Online Preference Learning via Preference Feature Preservation', 'authors': 'Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim', 'link': 'https://arxiv.org/abs/2506.11098', 'abstract': "Recent preference learning frameworks for large language models (LLMs) simplify human preferences with binary pairwise comparisons and scalar rewards. This simplification could make LLMs' responses biased to mostly preferred features, and would be exacerbated during the iterations of online preference learning steps. To address these challenges, we propose a novel framework coined PFP (Preference Feature Preservation). The key idea of PFP is maintaining the distribution of human preference features and utilizing such rich signals throughout the online preference learning process. Specifically, PFP first extract preference features from offline pairwise human preference data and trains a feature classifier. Then, using trained classifier and the distribution preserving optimization, PFP maps appropriate preference features for a new input instruction during online learning. Lastly, PFP trains LLM using the existing preference learning method, by incorporating the preference feature into system prompts and enabling LLM to explicitly handle various human preferences. Our experiments demonstrate that PFP successfully mitigates the bias in preference features during online learning, and hence achieves superior performance compared to previous preference learning methods on standard benchmarks to evaluate LLM alignment.", 'abstract_zh': '近期面向大规模语言模型的偏好学习框架通过二元成对比较和标量奖励简化了人类偏好，这可能导致语言模型的回答偏向于大多数偏好特征，并且会在在线偏好学习迭代过程中加剧。为解决这些挑战，我们提出了一种新型框架PFP（偏好特征保留）。PFP的核心思想是在在线偏好学习过程中保持人类偏好特征的分布并利用这些丰富的信号。具体而言，PFP首先从离线的成对人类偏好数据中提取偏好特征并训练一个特征分类器，然后利用训练好的分类器和保持分布优化，将适当的偏好特征映射到新的输入指令上。最后，PFP通过将偏好特征整合到系统提示中，训练语言模型以明确处理各种人类偏好。我们的实验表明，PFP成功地在在线学习过程中减轻了偏好特征的偏差，并且在评估语言模型对齐的标准基准上相比之前的偏好学习方法取得了更好的性能。', 'title_zh': '基于偏好特征保存的在线偏好学习去偏差化'}
{'arxiv_id': 'arXiv:2506.11097', 'title': 'C-SEO Bench: Does Conversational SEO Work?', 'authors': 'Haritz Puerto, Martin Gubri, Tommaso Green, Seong Joon Oh, Sangdoo Yun', 'link': 'https://arxiv.org/abs/2506.11097', 'abstract': 'Large Language Models (LLMs) are transforming search engines into Conversational Search Engines (CSE). Consequently, Search Engine Optimization (SEO) is being shifted into Conversational Search Engine Optimization (C-SEO). We are beginning to see dedicated C-SEO methods for modifying web documents to increase their visibility in CSE responses. However, they are often tested only for a limited breadth of application domains; we do not understand whether certain C-SEO methods would be effective for a broad range of domains. Moreover, existing evaluations consider only a single-actor scenario where only one web document adopts a C-SEO method; in reality, multiple players are likely to competitively adopt the cutting-edge C-SEO techniques, drawing an analogy from the dynamics we have seen in SEO. We present C-SEO Bench, the first benchmark designed to evaluate C-SEO methods across multiple tasks, domains, and number of actors. We consider two search tasks, question answering and product recommendation, with three domains each. We also formalize a new evaluation protocol with varying adoption rates among involved actors. Our experiments reveal that most current C-SEO methods are largely ineffective, contrary to reported results in the literature. Instead, traditional SEO strategies, those aiming to improve the ranking of the source in the LLM context, are significantly more effective. We also observe that as we increase the number of C-SEO adopters, the overall gains decrease, depicting a congested and zero-sum nature of the problem. Our code and data are available at this https URL and this https URL.', 'abstract_zh': '大规模语言模型（LLMs）正在将搜索引擎转变成为会话搜索引擎（CSE）。因此，搜索引擎优化（SEO）也随之转向会话搜索引擎优化（C-SEO）。我们开始看到针对修改网页文档以增加其在CSE响应中可见性的专用C-SEO方法。然而，这些方法往往仅限于有限的应用领域进行测试；我们不知道某些C-SEO方法是否适用于广泛的应用领域。此外，现有的评估仅考虑单一方情形，即仅一个网页文档采用C-SEO方法；实际上，多家参与者很可能会竞争性地采用最新的C-SEO技术，这与我们所观察到的SEO动态类似。我们提出了C-SEO Bench，这是第一个旨在跨多个任务、领域和参与者数量评估C-SEO方法的基准。我们考虑了两个搜索任务，即问答和产品推荐，每个领域都有三个领域。我们还制定了一个新的评估协议，其中参与者的采用率有所不同。实验结果表明，大多数当前的C-SEO方法实际上是无效的，这与文献中报道的结果相反。相反，传统SEO策略，在大规模语言模型（LLM）情境下提高源文档排名的方法，更为有效。我们还观察到，随着C-SEO采用者的增加，整体收益减少，这表明该问题具有拥挤和零和的特性。我们的代码和数据可在以下链接访问：this https URL 和 this https URL。', 'title_zh': 'C-SEO 基准测试：对话式SEO有效吗？'}
{'arxiv_id': 'arXiv:2506.11096', 'title': 'Assessing the Impact of Anisotropy in Neural Representations of Speech: A Case Study on Keyword Spotting', 'authors': 'Guillaume Wisniewski, Séverine Guillaume, Clara Rosina Fernández', 'link': 'https://arxiv.org/abs/2506.11096', 'abstract': 'Pretrained speech representations like wav2vec2 and HuBERT exhibit strong anisotropy, leading to high similarity between random embeddings. While widely observed, the impact of this property on downstream tasks remains unclear. This work evaluates anisotropy in keyword spotting for computational documentary linguistics. Using Dynamic Time Warping, we show that despite anisotropy, wav2vec2 similarity measures effectively identify words without transcription. Our results highlight the robustness of these representations, which capture phonetic structures and generalize across speakers. Our results underscore the importance of pretraining in learning rich and invariant speech representations.', 'abstract_zh': '预训练语音表示（如wav2vec2和HuBERT）表现出强烈的各向异性，导致随机嵌入之间高度相似。尽管普遍观察到这一特性，但其对下游任务的影响尚不明确。本研究评估了各向异性对计算文档语言学中关键词定位任务的影响。通过动态时间规整，我们显示尽管存在各向异性，wav2vec2的相似性度量仍能有效识别无字幕的单词。我们的结果突显了这些表示的稳健性，它们能够捕捉音素结构并在不同说话人之间泛化。我们的结果强调了预训练在学习丰富且不变的语音表示中的重要性。', 'title_zh': '评估语音神经表示中各向异性的影响：关键词识别案例研究'}
{'arxiv_id': 'arXiv:2506.11095', 'title': 'Persistent Homology of Topic Networks for the Prediction of Reader Curiosity', 'authors': 'Manuel D. S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley Jach, Kou Murayama', 'link': 'https://arxiv.org/abs/2506.11095', 'abstract': "Reader curiosity, the drive to seek information, is crucial for textual engagement, yet remains relatively underexplored in NLP. Building on Loewenstein's Information Gap Theory, we introduce a framework that models reader curiosity by quantifying semantic information gaps within a text's semantic structure. Our approach leverages BERTopic-inspired topic modeling and persistent homology to analyze the evolving topology (connected components, cycles, voids) of a dynamic semantic network derived from text segments, treating these features as proxies for information gaps. To empirically evaluate this pipeline, we collect reader curiosity ratings from participants (n = 49) as they read S. Collins's ''The Hunger Games'' novel. We then use the topological features from our pipeline as independent variables to predict these ratings, and experimentally show that they significantly improve curiosity prediction compared to a baseline model (73% vs. 30% explained deviance), validating our approach. This pipeline offers a new computational method for analyzing text structure and its relation to reader engagement.", 'abstract_zh': '读者好奇心，即寻求信息的驱动力，对于文本参与度至关重要，但在NLP中仍相对未被充分探索。基于Loewenstein的信息缺口理论，我们提出了一种框架，通过量化文本语义结构中的语义信息缺口来建模读者好奇心。该方法借鉴了BERTopic启发的主题模型和持久同调分析，以分析从文本片段中.derived的动态语义网络的演进拓扑（连通分支、环、空洞），将这些特征作为信息缺口的代理。为了实证评估该管道，我们从49名参与者阅读S.柯林斯的《饥饿游戏》小说时收集了读者好奇心评分。然后，我们使用该管道的拓扑特征作为自变量来预测这些评分，并实验证明这些特征在好奇心预测方面显著优于基准模型（解释偏差分别为73%和30%），验证了该方法。该管道为分析文本结构及其与读者参与度的关系提供了新的计算方法。', 'title_zh': '基于主题网络持久同调的读者好奇心预测'}
{'arxiv_id': 'arXiv:2506.11094', 'title': 'The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs', 'authors': 'Songyang Liu, Chaozhuo Li, Jiameng Qiu, Xi Zhang, Feiran Huang, Litian Zhang, Yiming Hei, Philip S. Yu', 'link': 'https://arxiv.org/abs/2506.11094', 'abstract': 'With the rapid advancement of artificial intelligence technology, Large Language Models (LLMs) have demonstrated remarkable potential in the field of Natural Language Processing (NLP), including areas such as content generation, human-computer interaction, machine translation, and code generation, among others. However, their widespread deployment has also raised significant safety concerns. In recent years, LLM-generated content has occasionally exhibited unsafe elements like toxicity and bias, particularly in adversarial scenarios, which has garnered extensive attention from both academia and industry. While numerous efforts have been made to evaluate the safety risks associated with LLMs, there remains a lack of systematic reviews summarizing these research endeavors. This survey aims to provide a comprehensive and systematic overview of recent advancements in LLMs safety evaluation, focusing on several key aspects: (1) "Why evaluate" that explores the background of LLMs safety evaluation, how they differ from general LLMs evaluation, and the significance of such evaluation; (2) "What to evaluate" that examines and categorizes existing safety evaluation tasks based on key capabilities, including dimensions such as toxicity, robustness, ethics, bias and fairness, truthfulness, and so on; (3) "Where to evaluate" that summarizes the evaluation metrics, datasets and benchmarks currently used in safety evaluations; (4) "How to evaluate" that reviews existing evaluation toolkit, and categorizing mainstream evaluation methods based on the roles of the evaluators. Finally, we identify the challenges in LLMs safety evaluation and propose potential research directions to promote further advancement in this field. We emphasize the importance of prioritizing LLMs safety evaluation to ensure the safe deployment of these models in real-world applications.', 'abstract_zh': '随着人工智能技术的迅速发展，大型语言模型（LLMs）在自然语言处理（NLP）领域展现出了显著潜力，包括内容生成、人机交互、机器翻译和代码生成等多个领域。然而，它们的广泛应用也引发了严重的安全关注。近年来，LLMs生成的内容偶尔会显示出毒性或偏见等不安全元素，尤其是在对抗性场景中，这引起了学术界和工业界的广泛关注。虽然已经做出了许多努力来评估LLMs的安全风险，但仍然缺乏对这些研究的系统性总结。本综述旨在提供对LLMs安全评估近期进展的全面和系统的概述，重点关注几个关键方面：（1）“为什么评估”，探索LLMs安全评估的背景、与一般LLMs评估的区别及其重要性；（2）“评估什么”，基于关键能力对现有的安全评估任务进行评估和分类，包括毒性、稳健性、伦理、偏见与公平性、真实性等维度；（3）“在哪里评估”，总结当前在安全评估中使用的评价指标、数据集和基准；（4）“如何评估”，回顾现有的评估工具包，并根据评估者的角色对主流评估方法进行分类。最后，我们指出了LLMs安全评估中的挑战，并提出了促进该领域进一步发展的潜在研究方向。我们强调优先进行LLMs安全评估的重要性，以确保这些模型在实际应用中的安全部署。', 'title_zh': '正义之秤：大规模语言模型安全性评估综述'}
{'arxiv_id': 'arXiv:2506.11092', 'title': 'Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation', 'authors': 'Jubin Abhishek Soni, Amit Anand, Rajesh Kumar Pandey, Aniket Abhishek Soni', 'link': 'https://arxiv.org/abs/2506.11092', 'abstract': 'Retrieval-Augmented Generation (RAG) has significantly advanced large language models (LLMs) by grounding their outputs in external tools and knowledge sources. However, existing RAG systems are typically constrained to static, single-turn interactions with fixed toolsets, making them ill-suited for dynamic domains such as healthcare and smart homes, where user intent, available tools, and contextual factors evolve over time. We present Dynamic Context Tuning (DCT), a lightweight framework that extends RAG to support multi-turn dialogue and evolving tool environments without requiring retraining. DCT integrates an attention-based context cache to track relevant past information, LoRA-based retrieval to dynamically select domain-specific tools, and efficient context compression to maintain inputs within LLM context limits. Experiments on both synthetic and real-world benchmarks show that DCT improves plan accuracy by 14% and reduces hallucinations by 37%, while matching GPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to previously unseen tools, enabling scalable and adaptable AI assistants across a wide range of dynamic environments.', 'abstract_zh': '基于检索的生成（RAG）通过将模型的输出与外部工具和知识源相结合，显著推进了大型语言模型（LLMs）的发展。然而，现有的RAG系统通常局限于静态的单轮交互和固定的工具集，使其不适合如医疗保健和智能家居等动态领域，这些领域中用户意图、可用工具和上下文因素会随时间变化。我们提出了一种轻量级框架动态上下文调整（DCT），该框架能够将RAG扩展到支持多轮对话和变化的工具环境，而无需重新训练。DCT整合了一种基于注意力机制的上下文缓存来追踪相关的历史信息，基于LoRA的检索来动态选择领域特定的工具，并通过有效的上下文压缩来保持输入在LLM上下文限制内。实验结果表明，DCT在计划准确性上提高了14%，在幻觉上减少了37%，并且能够在显著降低成本的同时达到与GPT-4相当的性能。此外，DCT能够适应未见过的工具，使跨多种动态环境的可扩展和适应性强的AI助手成为可能。', 'title_zh': '动态上下文调整以增强检索增强生成：多轮计划与工具适应性增强'}
{'arxiv_id': 'arXiv:2506.11089', 'title': 'Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM', 'authors': 'Jeena Prakash, Blessingh Kumar, Kadri Hacioglu, Bidisha Sharma, Sindhuja Gopalan, Malolan Chetlur, Shankar Venkatesan, Andreas Stolcke', 'link': 'https://arxiv.org/abs/2506.11089', 'abstract': 'Automatic speech recognition (ASR) models rely on high-quality transcribed data for effective training. Generating pseudo-labels for large unlabeled audio datasets often relies on complex pipelines that combine multiple ASR outputs through multi-stage processing, leading to error propagation, information loss and disjoint optimization. We propose a unified multi-ASR prompt-driven framework using postprocessing by either textual or speech-based large language models (LLMs), replacing voting or other arbitration logic for reconciling the ensemble outputs. We perform a comparative study of multiple architectures with and without LLMs, showing significant improvements in transcription accuracy compared to traditional methods. Furthermore, we use the pseudo-labels generated by the various approaches to train semi-supervised ASR models for different datasets, again showing improved performance with textual and speechLLM transcriptions compared to baselines.', 'abstract_zh': '自动化语音识别模型依赖高质量转录数据进行有效训练。大型未标注音频数据集的伪标签生成通常依赖于复杂的多阶段处理管道，结合多个ASR输出，导致错误传播、信息丢失和分离优化。我们提出了一种统一的多ASR提示驱动框架，通过文本或语音大型语言模型（LLMs）进行后处理，替代集合输出的投票或其他仲裁逻辑。我们对具有和不具有LLMs的多种架构进行了比较研究，显示了与传统方法相比显著提高的转录准确性。此外，我们使用各种方法生成的伪标签训练不同数据集的半监督ASR模型，再次显示了与基线相比的性能改进，特别是在使用文本和语音LLM转录时。', 'title_zh': '多ASR融合与错误纠正的更好伪标签生成方法由SpeechLLM实现'}
{'arxiv_id': 'arXiv:2506.11088', 'title': 'Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing', 'authors': 'Pengbo Wang, Chaozhuo Li, Chenxu Wang, Liwen Zheng, Litian Zhang, Xi Zhang', 'link': 'https://arxiv.org/abs/2506.11088', 'abstract': 'LLMs have demonstrated unprecedented capabilities in natural language processing, yet their practical deployment remains hindered by persistent factuality and faithfulness hallucinations. While existing methods address these hallucination types independently, they inadvertently induce performance trade-offs, as interventions targeting one type often exacerbate the other. Through empirical and theoretical analysis of activation space dynamics in LLMs, we reveal that these hallucination categories share overlapping subspaces within neural representations, presenting an opportunity for concurrent mitigation. To harness this insight, we propose SPACE, a unified framework that jointly enhances factuality and faithfulness by editing shared activation subspaces. SPACE establishes a geometric foundation for shared subspace existence through dual-task feature modeling, then identifies and edits these subspaces via a hybrid probe strategy combining spectral clustering and attention head saliency scoring. Experimental results across multiple benchmark datasets demonstrate the superiority of our approach.', 'abstract_zh': '通过编辑共享激活子空间同时增强事实性和忠实性：SPACE框架', 'title_zh': '一石二鸟：通过动态交互子空间编辑提升LLMs的事实性和忠实度'}
{'arxiv_id': 'arXiv:2506.11087', 'title': 'ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models', 'authors': 'Boya Xiong, Shuo Wang, Weifeng Ge, Guanhua Chen, Yun Chen', 'link': 'https://arxiv.org/abs/2506.11087', 'abstract': 'Large language models (LLMs) achieve impressive performance on various knowledge-intensive and complex reasoning tasks in different domains. In certain scenarios like multi-tenant serving, a large number of LLMs finetuned from the same base model are deployed to meet complex requirements for users. Recent works explore delta-compression approaches to quantize and compress the delta parameters between the customized LLM and the corresponding base model. However, existing works either exhibit unsatisfactory performance at high compression ratios or depend on empirical bit allocation schemes. In this work, we propose ADAMIX, an effective adaptive mixed-precision delta-compression framework. We provide a mathematical derivation of quantization error to motivate our mixed-precision compression strategy and formulate the optimal mixed-precision bit allocation scheme as the solution to a 0/1 integer linear programming problem. Our derived bit allocation strategy minimizes the quantization error while adhering to a predefined compression ratio requirement. Experimental results on various models and benchmarks demonstrate that our approach surpasses the best baseline by a considerable margin. On tasks like AIME2024 and GQA, where the norm of $\\Delta \\mathbf{W}$ is large and the base model lacks sufficient ability, ADAMIX outperforms the best baseline Delta-CoMe by 22.3% and 6.1% with 7B models, respectively.', 'abstract_zh': '大规模语言模型（LLMs）在不同领域的知识密集型和复杂推理任务中实现了令人印象深刻的表现。在某些场景如多租户服务中，大量从同一基础模型微调得到的LLMs被部署以满足用户复杂的需求。最近的工作探索了增量压缩方法来量化和压缩定制LLM与相应基础模型之间的增量参数。然而，现有方法要么在高压缩比下表现不佳，要么依赖经验的位分配方案。在此工作中，我们提出了ADAMIX，一个有效的自适应混合精度增量压缩框架。我们通过数学推导量化误差来激励我们的混合精度压缩策略，并将最佳混合精度位分配方案形式化为0/1整数线性规划问题的解。我们推导出的位分配策略在满足预定义压缩比要求的同时，最小化量化误差。在各种模型和基准上的实验结果表明，我们的方法在基准方法上显著优越。在AIME2024和GQA等任务中，当$\\Delta \\mathbf{W}$的范数较大且基础模型缺乏足够的能力时，相对于7B模型，ADAMIX分别比最佳基准Delta-CoMe高出22.3%和6.1%。', 'title_zh': 'ADAMIX：自适应混合精度增量压缩与量化误差优化在大规模语言模型中的应用'}
{'arxiv_id': 'arXiv:2506.11086', 'title': 'Intelligibility of Text-to-Speech Systems for Mathematical Expressions', 'authors': 'Sujoy Roychowdhury, H. G. Ranjani, Sumit Soman, Nishtha Paul, Subhadip Bandyopadhyay, Siddhanth Iyengar', 'link': 'https://arxiv.org/abs/2506.11086', 'abstract': 'There has been limited evaluation of advanced Text-to-Speech (TTS) models with Mathematical eXpressions (MX) as inputs. In this work, we design experiments to evaluate quality and intelligibility of five TTS models through listening and transcribing tests for various categories of MX. We use two Large Language Models (LLMs) to generate English pronunciation from LaTeX MX as TTS models cannot process LaTeX directly. We use Mean Opinion Score from user ratings and quantify intelligibility through transcription correctness using three metrics. We also compare listener preference of TTS outputs with respect to human expert rendition of same MX. Results establish that output of TTS models for MX is not necessarily intelligible, the gap in intelligibility varies across TTS models and MX category. For most categories, performance of TTS models is significantly worse than that of expert rendition. The effect of choice of LLM is limited. This establishes the need to improve TTS models for MX.', 'abstract_zh': '关于数学表达式输入的高级文本到语音模型评估有限。本研究设计实验，通过听力测试和转录测试评估五种TTS模型在各种数学表达式类别下的质量和可理解性。我们使用两种大语言模型从LaTeX数学表达式生成英语发音，因为TTS模型不能直接处理LaTeX格式。我们使用用户评分的平均意见分，并通过三个指标量化可理解性。我们还比较了TTS输出与人类专家同样数学表达式的呈现的听者偏好。结果表明，TTS模型生成的数学表达式输出未必具有可理解性，不同TTS模型和数学表达式类别的可理解性差异显著。对于大多数类别，TTS模型的表现远逊于专家呈现。大语言模型的选择影响有限，这表明需要改进针对数学表达式的TTS模型。', 'title_zh': '数学表达式文本到语音系统的可理解性'}
{'arxiv_id': 'arXiv:2506.11085', 'title': 'LeanExplore: A search engine for Lean 4 declarations', 'authors': 'Justin Asher', 'link': 'https://arxiv.org/abs/2506.11085', 'abstract': "The expanding Lean 4 ecosystem poses challenges for navigating its vast libraries. This paper introduces LeanExplore, a search engine for Lean 4 declarations. LeanExplore enables users to semantically search for statements, both formally and informally, across select Lean 4 packages (including Batteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is powered by a hybrid ranking strategy, integrating scores from a multi-source semantic embedding model (capturing conceptual meaning from formal Lean code, docstrings, AI-generated informal translations, and declaration titles), BM25+ for keyword-based lexical relevance, and a PageRank-based score reflecting declaration importance and interconnectedness. The search engine is accessible via a dedicated website (this https URL) and a Python API (this https URL). Furthermore, the database can be downloaded, allowing users to self-host the service. LeanExplore integrates easily with LLMs via the model context protocol (MCP), enabling users to chat with an AI assistant about Lean declarations or utilize the search engine for building theorem-proving agents. This work details LeanExplore's architecture, data processing, functionalities, and its potential to enhance Lean 4 workflows and AI-driven mathematical research", 'abstract_zh': 'Lean 4 生态系统的扩展对导航其庞大的库构成挑战。本文介绍了 LeanExplore，一个用于搜索 Lean 4 声明的搜索引擎。LeanExplore 允许用户在筛选的 Lean 4 包（包括 Batteries、Init、Lean、Mathlib、PhysLean 和 Std）中对正式和非正式的语句进行语义搜索。搜索功能由一种混合排名策略驱动，该策略结合了多源语义嵌入模型（捕捉正式 Lean 代码、文档字符串、AI 生成的非正式翻译和声明标题的概念意义）的评分、基于关键词的词汇相关性 BM25+ 评分，以及反映声明重要性和相互关联性的 PageRank 评分。该搜索引擎可通过专用网站（此 https URL）和 Python API（此 https URL）访问。此外，数据库可以下载，允许用户自行托管该服务。LeanExplore 通过模型上下文协议（MCP）易于与大语言模型集成，使用户能够与关于 Lean 声明的 AI 助手进行对话或将搜索引擎用于构建定理证明代理。本文详细介绍了 LeanExplore 的架构、数据处理、功能及其增强 Lean 4 工作流程和 AI 驱动的数学研究的潜力。', 'title_zh': 'LeanExplore: 一个用于Lean 4断言的搜索引擎'}
{'arxiv_id': 'arXiv:2506.11082', 'title': 'PRISM: A Transformer-based Language Model of Structured Clinical Event Data', 'authors': 'Lionel Levine, John Santerre, Alex S. Young, T. Barry Levine, Francis Campion, Majid Sarrafzadeh', 'link': 'https://arxiv.org/abs/2506.11082', 'abstract': 'We introduce PRISM (Predictive Reasoning in Sequential Medicine), a transformer-based architecture designed to model the sequential progression of clinical decision-making processes. Unlike traditional approaches that rely on isolated diagnostic classification, PRISM frames clinical trajectories as tokenized sequences of events - including diagnostic tests, laboratory results, and diagnoses - and learns to predict the most probable next steps in the patient diagnostic journey. Leveraging a large custom clinical vocabulary and an autoregressive training objective, PRISM demonstrates the ability to capture complex dependencies across longitudinal patient timelines. Experimental results show substantial improvements over random baselines in next-token prediction tasks, with generated sequences reflecting realistic diagnostic pathways, laboratory result progressions, and clinician ordering behaviors. These findings highlight the feasibility of applying generative language modeling techniques to structured medical event data, enabling applications in clinical decision support, simulation, and education. PRISM establishes a foundation for future advancements in sequence-based healthcare modeling, bridging the gap between machine learning architectures and real-world diagnostic reasoning.', 'abstract_zh': '基于Transformer的PRISM架构：预测医学中的序贯推理', 'title_zh': 'PRISM: 基于Transformer的结构化临床事件数据语言模型'}
{'arxiv_id': 'arXiv:2506.11079', 'title': 'Improving Child Speech Recognition and Reading Mistake Detection by Using Prompts', 'authors': 'Lingyun Gao, Cristian Tejedor-Garcia, Catia Cucchiarini, Helmer Strik', 'link': 'https://arxiv.org/abs/2506.11079', 'abstract': 'Automatic reading aloud evaluation can provide valuable support to teachers by enabling more efficient scoring of reading exercises. However, research on reading evaluation systems and applications remains limited. We present a novel multimodal approach that leverages audio and knowledge from text resources. In particular, we explored the potential of using Whisper and instruction-tuned large language models (LLMs) with prompts to improve transcriptions for child speech recognition, as well as their effectiveness in downstream reading mistake detection. Our results demonstrate the effectiveness of prompting Whisper and prompting LLM, compared to the baseline Whisper model without prompting. The best performing system achieved state-of-the-art recognition performance in Dutch child read speech, with a word error rate (WER) of 5.1%, improving the baseline WER of 9.4%. Furthermore, it significantly improved reading mistake detection, increasing the F1 score from 0.39 to 0.73.', 'abstract_zh': '自动朗读评估可以为教师提供有价值的支持，使其能够更高效地评分阅读练习。然而，关于阅读评估系统和应用的研究仍然有限。我们提出了一种新颖的多模态方法，利用音频和文本资源的知识。特别地，我们探索了使用Whisper结合指令调优的大语言模型（LLMs）和提示来提高儿童语音识别的转录效果，并研究了其在下游阅读错误检测中的有效性。我们的结果显示，与未经过提示的基本Whisper模型相比，提示Whisper和提示LLM的有效性更高。性能最佳的系统在荷兰儿童阅读语音识别上取得了最先进的性能，词错误率（WER）为5.1%，相比基线模型的WER 9.4%，有了显著提升。此外，它显著改善了阅读错误检测效果，F1分数从0.39提升到0.73。', 'title_zh': '通过使用提示提高儿童语音识别和阅读错误检测能力'}
{'arxiv_id': 'arXiv:2506.11073', 'title': 'CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention', 'authors': 'Zekai Ye, Qiming Li, Xiaocheng Feng, Libo Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin', 'link': 'https://arxiv.org/abs/2506.11073', 'abstract': 'Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal abilities but remain prone to multilingual object hallucination, with a higher likelihood of generating responses inconsistent with the visual input when utilizing queries in non-English languages compared to English. Most existing approaches to address these rely on pretraining or fine-tuning, which are resource-intensive. In this paper, inspired by observing the disparities in cross-modal attention patterns across languages, we propose Cross-Lingual Attention Intervention for Mitigating multilingual object hallucination (CLAIM) in LVLMs, a novel near training-free method by aligning attention patterns. CLAIM first identifies language-specific cross-modal attention heads, then estimates language shift vectors from English to the target language, and finally intervenes in the attention outputs during inference to facilitate cross-lingual visual perception capability alignment. Extensive experiments demonstrate that CLAIM achieves an average improvement of 13.56% (up to 30% in Spanish) on the POPE and 21.75% on the hallucination subsets of the MME benchmark across various languages. Further analysis reveals that multilingual attention divergence is most prominent in intermediate layers, highlighting their critical role in multilingual scenarios.', 'abstract_zh': 'Cross-Lingual Attention Intervention for Mitigating Multilingual Object Hallucination in Large Vision-Language Models', 'title_zh': 'CLAIM: 通过跨语言注意力干预减轻大型视觉-语言模型的多语言对象幻觉'}
{'arxiv_id': 'arXiv:2506.11071', 'title': 'Embedded Acoustic Intelligence for Automotive Systems', 'authors': 'Renjith Rajagopal, Peter Winzell, Sladjana Strbac, Konstantin Lindström, Petter Hörling, Faisal Kohestani, Niloofar Mehrzad', 'link': 'https://arxiv.org/abs/2506.11071', 'abstract': 'Transforming sound insights into actionable streams of data, this abstract leverages findings from degree thesis research to enhance automotive system intelligence, enabling us to address road type [1].By extracting and interpreting acoustic signatures from microphones installed within the wheelbase of a car, we focus on classifying road this http URL deep neural networks and feature extraction powered by pre-trained models from the Open AI ecosystem (via Hugging Face [2]), our approach enables Autonomous Driving and Advanced Driver- Assistance Systems (AD/ADAS) to anticipate road surfaces, support adaptive learning for active road noise cancellation, and generate valuable insights for urban planning. The results of this study were specifically captured to support a compelling business case for next-generation automotive systems. This forward-looking approach not only promises to redefine passenger comfort and improve vehicle safety, but also paves the way for intelligent, data-driven urban road management, making the future of mobility both achievable and sustainable.', 'abstract_zh': '将声音见解转化为可操作的数据流，本文摘要利用学位论文的研究成果来增强汽车系统智能，以应对不同道路类型的需求。通过从汽车轮距内安装的麦克风中提取和解释声学特征，我们专注于道路分类。借助开放AI生态系统的预训练模型（通过Hugging Face）驱动的深度神经网络和特征提取技术，我们的方法使自动驾驶和高级驾驶辅助系统（AD/ADAS）能够预测道路表面、支持自适应学习以实现主动降噪，并为城市规划提供有价值的见解。本研究的结果特别支持下一代汽车系统的商业案例。这一前瞻性方法不仅有望重新定义乘客舒适性和提升车辆安全性，还铺就了智能化、数据驱动的城市道路管理之路，使未来的出行既可行又可持续。', 'title_zh': '汽车系统中的嵌入式声学智能'}
{'arxiv_id': 'arXiv:2506.11069', 'title': 'Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition', 'authors': 'Tao Zhong, Mengzhe Geng, Shujie Hu, Guinan Li, Xunying Liu', 'link': 'https://arxiv.org/abs/2506.11069', 'abstract': 'Accurate recognition of dysarthric and elderly speech remains challenging to date. While privacy concerns have driven a shift from centralized approaches to federated learning (FL) to ensure data confidentiality, this further exacerbates the challenges of data scarcity, imbalanced data distribution and speaker heterogeneity. To this end, this paper conducts a systematic investigation of regularized FL techniques for privacy-preserving dysarthric and elderly speech recognition, addressing different levels of the FL process by 1) parameter-based, 2) embedding-based and 3) novel loss-based regularization. Experiments on the benchmark UASpeech dysarthric and DementiaBank Pitt elderly speech corpora suggest that regularized FL systems consistently outperform the baseline FedAvg system by statistically significant WER reductions of up to 0.55\\% absolute (2.13\\% relative). Further increasing communication frequency to one exchange per batch approaches centralized training performance.', 'abstract_zh': '准确识别失语症和老年语音仍具有挑战性：基于正则化的联邦学习技术在保护隐私的失语症和老年语音识别中的系统研究', 'title_zh': '正则化联邦学习在隐私保护的构音障碍和老年言语识别中的应用'}
{'arxiv_id': 'arXiv:2506.11066', 'title': 'CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval', 'authors': 'Jiahui Geng, Fengyu Cai, Shaobo Cui, Qing Li, Liangwei Chen, Chenyang Lyu, Haonan Li, Derui Zhu, Walter Pretschner, Heinz Koeppl, Fakhri Karray', 'link': 'https://arxiv.org/abs/2506.11066', 'abstract': 'Code retrieval is essential in modern software development, as it boosts code reuse and accelerates debugging. However, current benchmarks primarily emphasize functional relevance while neglecting critical dimensions of software quality. Motivated by this gap, we introduce CoQuIR, the first large-scale, multilingual benchmark specifically designed to evaluate quality-aware code retrieval across four key dimensions: correctness, efficiency, security, and maintainability. CoQuIR provides fine-grained quality annotations for 42,725 queries and 134,907 code snippets in 11 programming languages, and is accompanied by two quality-centric evaluation metrics: Pairwise Preference Accuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23 retrieval models, covering both open-source and proprietary systems, and find that even top-performing models frequently fail to distinguish buggy or insecure code from their more robust counterparts. Furthermore, we conduct preliminary investigations into training methods that explicitly encourage retrievers to recognize code quality. Using synthetic datasets, we demonstrate promising improvements in quality-aware metrics across various models, without sacrificing semantic relevance. Downstream code generation experiments further validate the effectiveness of our approach. Overall, our work highlights the importance of integrating quality signals into code retrieval systems, laying the groundwork for more trustworthy and robust software development tools.', 'abstract_zh': 'Code Retrieval评估中的质量考量：CoQuIR基准的引入与应用', 'title_zh': 'CoQuIR: 一种面向代码质量的信息检索综合基准'}
{'arxiv_id': 'arXiv:2506.11064', 'title': 'PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding', 'authors': 'Jiajun He, Tomoki Toda', 'link': 'https://arxiv.org/abs/2506.11064', 'abstract': 'End-to-end automatic speech recognition (ASR) models often struggle to accurately recognize rare words. Previously, we introduced an ASR postprocessing method called error detection and context-aware error correction (ED-CEC), which leverages contextual information such as named entities and technical terms to improve the accuracy of ASR transcripts. Although ED-CEC achieves a notable success in correcting rare words, its accuracy remains low when dealing with rare words that have similar pronunciations but different spellings. To address this issue, we proposed a phoneme-augmented multimodal fusion method for context-aware error correction (PMF-CEC) method on the basis of ED-CEC, which allowed for better differentiation between target rare words and homophones. Additionally, we observed that the previous ASR error detection module suffers from overdetection. To mitigate this, we introduced a retention probability mechanism to filter out editing operations with confidence scores below a set threshold, preserving the original operation to improve error detection accuracy. Experiments conducted on five datasets demonstrated that our proposed PMF-CEC maintains reasonable inference speed while further reducing the biased word error rate compared with ED-CEC, showing a stronger advantage in correcting homophones. Moreover, our method outperforms other contextual biasing methods, and remains valuable compared with LLM-based methods in terms of faster inference and better robustness under large biasing lists.', 'abstract_zh': '端到端自动语音识别（ASR）模型往往难以准确识别稀有词汇。先前，我们引入了一种称为错误检测和基于上下文的错误修正（ED-CEC）的ASR后处理方法，该方法利用命名实体和技术术语等上下文信息以提高ASR转录的准确性。尽管ED-CEC在修正稀有词汇方面取得了显著成效，但它在处理具有相似 pronunciation 但不同拼写的稀有词汇时的准确性仍然较低。为了解决这一问题，我们在此基础上提出了一个 phoneme 增强的多模态融合方法用于基于上下文的错误修正（PMF-CEC），以更好地区分目标稀有词汇和同音词。此外，我们观察到之前的ASR错误检测模块存在过度检测的问题。为缓解这一问题，我们引入了一个保留概率机制，以过滤掉低于设定阈值信心分数的编辑操作，保留原始操作以提高错误检测准确性。在五个数据集上的实验表明，我们提出的PMF-CEC保持了合理的推理速度，同时进一步降低了有偏的单词错误率，显示出在修正同音词方面更显著的优势。此外，我们的方法优于其他上下文偏差方法，并且在更快的推理和更强大的鲁棒性方面相对于基于LLM的方法更具优势。', 'title_zh': 'PMF-CEC：音素增强多模态融合用于具有错误特定选择解码的上下文感知ASR错误修正'}
{'arxiv_id': 'arXiv:2506.11063', 'title': 'Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation', 'authors': 'Jiayu Yao, Shenghua Liu, Yiwei Wang, Lingrui Mei, Baolong Bi, Yuyao Ge, Zhecheng Li, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2506.11063', 'abstract': 'Multimodal Retrieval-Augmented Generation (RAG) systems have become essential in knowledge-intensive and open-domain tasks. As retrieval complexity increases, ensuring the robustness of these systems is critical. However, current RAG models are highly sensitive to the order in which evidence is presented, often resulting in unstable performance and biased reasoning, particularly as the number of retrieved items or modality diversity grows. This raises a central question: How does the position of retrieved evidence affect multimodal RAG performance? To answer this, we present the first comprehensive study of position bias in multimodal RAG systems. Through controlled experiments across text-only, image-only, and mixed-modality tasks, we observe a consistent U-shaped accuracy curve with respect to evidence position. To quantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and develop a visualization framework to trace attention allocation patterns across decoder layers. Our results reveal that multimodal interactions intensify position bias compared to unimodal settings, and that this bias increases logarithmically with retrieval range. These findings offer both theoretical and empirical foundations for position-aware analysis in RAG, highlighting the need for evidence reordering or debiasing strategies to build more reliable and equitable generation systems.', 'abstract_zh': '多模态检索增强生成（RAG）系统中的位置偏见研究', 'title_zh': '谁占据聚光灯： multimodal retrieval-augmented generation 中隐含的偏见'}
{'arxiv_id': 'arXiv:2506.11062', 'title': 'Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis', 'authors': 'Xingyu Liu, Yubin Li, Guozhang Chen', 'link': 'https://arxiv.org/abs/2506.11062', 'abstract': "A central idea in understanding brains and building artificial intelligence is that structure determines function. Yet, how the brain's complex structure arises from a limited set of genetic instructions remains a key question. The ultra high-dimensional detail of neural connections vastly exceeds the information storage capacity of genes, suggesting a compact, low-dimensional blueprint must guide brain development. Our motivation is to uncover this blueprint. We introduce a generative model, to learn this underlying representation from detailed connectivity maps of mouse cortical microcircuits. Our model successfully captures the essential structural information of these circuits in a compressed latent space. We found that specific, interpretable directions within this space directly relate to understandable network properties. Building on this, we demonstrate a novel method to controllably generate new, synthetic microcircuits with desired structural features by navigating this latent space. This work offers a new way to investigate the design principles of neural circuits and explore how structure gives rise to function, potentially informing the development of more advanced artificial neural networks.", 'abstract_zh': '理解大脑和构建人工智能的一个核心思想是结构决定功能。然而，大脑的复杂结构是如何从有限的遗传指令中产生出来的仍然是一个关键问题。神经连接的超高层细节远远超过了基因的信息存储能力，这表明一个紧凑的、低维度的蓝图必须指导大脑的发展。我们的动机是揭示这个蓝图。我们提出了一种生成模型，从小鼠皮层微回路的详细连接图中学习这一潜在的表示。我们的模型成功地在压缩的潜在空间中捕捉到了这些回路的基本结构信息。我们发现，该空间中的特定、可解释的方向直接与可理解的网络特性相关。在此基础上，我们展示了通过导航该潜在空间来可控地生成具有所需结构特征的新合成微回路的新型方法。这项工作为探讨神经回路的设计原则和研究结构如何产生功能提供了一个新途径，可能为开发更高级的人工神经网络提供指导。', 'title_zh': '解码皮层微回路：潜在空间探索和可控合成的生成模型'}
{'arxiv_id': 'arXiv:2506.11060', 'title': 'Code Researcher: Deep Research Agent for Large Systems Code and Commit History', 'authors': 'Ramneet Singh, Sathvik Joel, Abhav Mehrotra, Nalin Wadhwa, Ramakrishna B Bairi, Aditya Kanade, Nagarajan Natarajan', 'link': 'https://arxiv.org/abs/2506.11060', 'abstract': "Large Language Model (LLM)-based coding agents have shown promising results on coding benchmarks, but their effectiveness on systems code remains underexplored. Due to the size and complexities of systems code, making changes to a systems codebase is a daunting task, even for humans. It requires researching about many pieces of context, derived from the large codebase and its massive commit history, before making changes. Inspired by the recent progress on deep research agents, we design the first deep research agent for code, called Code Researcher, and apply it to the problem of generating patches for mitigating crashes reported in systems code. Code Researcher performs multi-step reasoning about semantics, patterns, and commit history of code to gather sufficient context. The context is stored in a structured memory which is used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a benchmark of Linux kernel crashes, and show that it significantly outperforms strong baselines, achieving a crash-resolution rate of 58%, compared to 37.5% by SWE-agent. On an average, Code Researcher explores 10 files in each trajectory whereas SWE-agent explores only 1.33 files, highlighting Code Researcher's ability to deeply explore the codebase. Through another experiment on an open-source multimedia software, we show the generalizability of Code Researcher. Our experiments highlight the importance of global context gathering and multi-faceted reasoning for large codebases.", 'abstract_zh': '基于大型语言模型的编码代理在编码基准测试中显示出有前景的结果，但它们在系统代码上的有效性仍待探索。受最近深度研究代理进展的启发，我们设计了第一个代码领域的深度研究代理——Code Researcher，并将其应用于生成修补程序以缓解系统代码中报告的崩溃问题。Code Researcher 对代码的语义、模式及其提交历史进行多步推理，以收集足够的上下文。这些上下文被存储在一个结构化的内存中，用于合成修补程序。我们通过一个基于 Linux 内核崩溃的基准 kBenchSyz 评估了 Code Researcher，并表明它显著优于强大的基线，实现 58% 的崩溃解决率，而 SWE-agent 仅为 37.5%。平均而言，Code Researcher 在每次轨迹中探索 10 个文件，而 SWE-agent 仅探索 1.33 个文件，突显了 Code Researcher 深入探索代码库的能力。通过另一个开源多媒体软件的实验，我们展示了 Code Researcher 的通用性。我们的实验突显了对于大型代码库而言全局上下文收集和多方面推理的重要性。', 'title_zh': '代码研究员：面向大型系统代码和提交历史的深度研究代理'}
{'arxiv_id': 'arXiv:2506.11058', 'title': 'Refactoring Codebases through Library Design', 'authors': 'Ziga Kovacic, Celine Lee, Justin Chiu, Wenting Zhao, Kevin Ellis', 'link': 'https://arxiv.org/abs/2506.11058', 'abstract': "Maintainable and general software allows developers to build robust applications efficiently, yet achieving these qualities often requires refactoring specialized solutions into reusable components. This challenge becomes particularly relevant as code agents become increasingly accurate at solving isolated programming problems. We investigate code agents' capacity to refactor code in ways supporting growth and reusability. We present both a method and a benchmark for refactoring: Librarian, a sample-and-rerank method for generating reusable libraries, and Minicode, a benchmark where code agents must minimize and refactor multiple independent solutions into a joint library. Compared to state-of-the-art code agents, Librarian achieves strong results on both compression and correctness on Minicode, obtaining compression rates 1.6-2x better than coding agents while also improving correctness. We open-source our code and benchmark at this https URL.", 'abstract_zh': '可维护且通用的软件能够帮助开发人员高效构建 robust 应用程序，然而，实现这些品质往往需要将专门的解决方案重构为可重用组件。随着代码代理在解决孤立编程问题方面变得越来越准确，这一挑战变得尤为相关。我们研究了代码代理在支持增长和可重用性方面的重构能力。我们提出了一种方法和基准测试：Librarian，一种通过采样和重新排名生成可重用库的方法，以及 Minicode 基准测试，在此基准测试中，代码代理必须将多个独立解决方案最小化并重构为一个联合库。与最先进的代码代理相比，Librarian 在 Minicode 上在压缩和正确性方面均取得了优异的成绩，压缩率比编码代理高 1.6-2 倍，同时还能提高正确性。我们在此开源了我们的代码和基准测试：https://this-url。', 'title_zh': '通过库设计重构代码库'}
{'arxiv_id': 'arXiv:2506.11057', 'title': 'STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization', 'authors': 'Xijun Li, Jiexiang Yang, Jinghao Wang, Bo Peng, Jianguo Yao, Haibing Guan', 'link': 'https://arxiv.org/abs/2506.11057', 'abstract': "Combinatorial optimization (CO) problems, central to operation research and theoretical computer science, present significant computational challenges due to their NP-hard nature. While large language models (LLMs) have emerged as promising tools for CO--either by directly generating solutions or synthesizing solver-specific codes--existing approaches often neglect critical structural priors inherent to CO problems, leading to suboptimality and iterative inefficiency. Inspired by human experts' success in leveraging CO structures for algorithm design, we propose STRCMP, a novel structure-aware LLM-based algorithm discovery framework that systematically integrates structure priors to enhance solution quality and solving efficiency. Our framework combines a graph neural network (GNN) for extracting structural embeddings from CO instances with an LLM conditioned on these embeddings to identify high-performing algorithms in the form of solver-specific codes. This composite architecture ensures syntactic correctness, preserves problem topology, and aligns with natural language objectives, while an evolutionary refinement process iteratively optimizes generated algorithm. Extensive evaluations across Mixed Integer Linear Programming and Boolean Satisfiability problems, using nine benchmark datasets, demonstrate that our proposed STRCMP outperforms five strong neural and LLM-based methods by a large margin, in terms of both solution optimality and computational efficiency. The code and learned model will be publicly available upon the acceptance of the paper.", 'abstract_zh': '组合优化（CO）问题：一种新的结构感知大语言模型算法发现框架', 'title_zh': 'STRCMP：将图形结构先验与语言模型集成用于组合优化'}
{'arxiv_id': 'arXiv:2506.11056', 'title': 'xInv: Explainable Optimization of Inverse Problems', 'authors': 'Sean Memery, Kevin Denamganai, Anna Kapron-King, Kartic Subr', 'link': 'https://arxiv.org/abs/2506.11056', 'abstract': 'Inverse problems are central to a wide range of fields, including healthcare, climate science, and agriculture. They involve the estimation of inputs, typically via iterative optimization, to some known forward model so that it produces a desired outcome. Despite considerable development in the explainability and interpretability of forward models, the iterative optimization of inverse problems remains largely cryptic to domain experts. We propose a methodology to produce explanations, from traces produced by an optimizer, that are interpretable by humans at the abstraction of the domain. The central idea in our approach is to instrument a differentiable simulator so that it emits natural language events during its forward and backward passes. In a post-process, we use a Language Model to create an explanation from the list of events. We demonstrate the effectiveness of our approach with an illustrative optimization problem and an example involving the training of a neural network.', 'abstract_zh': '逆问题在医疗保健、气候科学和农业等领域中占据核心地位。它们涉及通过迭代优化方法估计输入，以使某个已知的前向模型产生期望的结果。尽管前向模型的解释性和可解释性取得了显著进展，但逆问题的迭代优化对领域专家来说仍然 largely 隐匿。我们提出了一种方法，通过优化器产生的轨迹生成可由人类在领域抽象层面上理解的解释。我们方法的核心思想是对可微模拟器进行仪器化，使其在正向和反向传播过程中发出自然语言事件。在后处理阶段，我们利用语言模型从事件列表中生成解释。我们通过一个示例优化问题和一个涉及神经网络训练的示例，展示了我们方法的有效性。', 'title_zh': 'xInv：可解释的逆问题优化'}
{'arxiv_id': 'arXiv:2506.11054', 'title': 'Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments', 'authors': 'Deepak Kanneganti, Sajib Mistry, Sheik Mohammad Mostakim Fattah, Aneesh Krishna, Monowar Bhuyan', 'link': 'https://arxiv.org/abs/2506.11054', 'abstract': 'The dynamic nature of Internet of Things (IoT) environments challenges the long-term effectiveness of Machine Learning as a Service (MLaaS) compositions. The uncertainty and variability of IoT environments lead to fluctuations in data distribution, e.g., concept drift and data heterogeneity, and evolving system requirements, e.g., scalability demands and resource limitations. This paper proposes an adaptive MLaaS composition framework to ensure a seamless, efficient, and scalable MLaaS composition. The framework integrates a service assessment model to identify underperforming MLaaS services and a candidate selection model to filter optimal replacements. An adaptive composition mechanism is developed that incrementally updates MLaaS compositions using a contextual multi-armed bandit optimization strategy. By continuously adapting to evolving IoT constraints, the approach maintains Quality of Service (QoS) while reducing the computational cost associated with recomposition from scratch. Experimental results on a real-world dataset demonstrate the efficiency of our proposed approach.', 'abstract_zh': '物联网环境动态性对机器学习即服务（MLaaS）组合长期有效性构成了挑战。物联网环境的不确定性与变异性导致数据分布波动，例如概念漂移和数据异质性，同时对系统需求也产生了进化变化，例如可扩展性需求和资源限制。本文提出了一种自适应MLaaS组合框架，以确保MLaaS组合的无缝、高效和可扩展性。该框架集成了一种服务评估模型以识别性能不佳的MLaaS服务，并集成了一种候选选择模型以筛选最优替代品。开发了一种自适应组合机制，通过上下文多臂 bandit 优化策略增量更新MLaaS组合。通过不断适应进化的物联网约束条件，该方法在降低从头重组的计算成本的同时，维持服务质量（QoS）。实验结果在真实数据集上验证了所提方法的有效性。', 'title_zh': '物联网环境中的自适应机器学习即服务组件Composition for IoT环境中的自适应机器学习即服务'}
{'arxiv_id': 'arXiv:2506.11053', 'title': 'Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data', 'authors': 'Weichang Wu, Xiaolu Zhang, Jun Zhou, Yuchen Li, Wenwen Xia', 'link': 'https://arxiv.org/abs/2506.11053', 'abstract': "User Behavior Sequence (UBS) modeling is crucial in industrial applications. As data scale and task diversity grow, UBS pretraining methods have become increasingly pivotal. State-of-the-art UBS pretraining methods rely on predicting behavior distributions. The key step in these methods is constructing a selected behavior vocabulary. However, this manual step is labor-intensive and prone to bias. The limitation of vocabulary capacity also directly affects models' generalization ability. In this paper, we introduce Bootstrapping Your Behavior (\\model{}), a novel UBS pretraining strategy that predicts an automatically constructed supervision embedding summarizing all behaviors' information within a future time window, eliminating the manual behavior vocabulary selection. In implementation, we incorporate a student-teacher encoder scheme to construct the pretraining supervision effectively. Experiments on two real-world industrial datasets and eight downstream tasks demonstrate that \\model{} achieves an average improvement of 3.9\\% in AUC and 98.9\\% in training throughput. Notably, the model exhibits meaningful attention patterns and cluster representations during pretraining without any label supervision. In our online deployment over two months, the pretrained model improves the KS by about 2.7\\% and 7.1\\% over the baseline model for two financial overdue risk prediction tasks in the Alipay mobile application, which reduces bad debt risk by millions of dollars for Ant group.", 'abstract_zh': '用户行为序列（UBS）模型预训练是工业应用中的关键。随着数据规模和任务多样性增长，UBS预训练方法变得越来越重要。最新的UBS预训练方法依赖于预测行为分布。这些方法的关键步骤是构建选择的行为词汇表。然而，这一手动步骤耗时且易产生偏差。词汇表容量的局限也直接影响模型的泛化能力。在本文中，我们介绍了一种新颖的UBS预训练策略Bootstrapping Your Behavior（\\model{}），该策略通过自动构建监督嵌入来总结未来时间窗口内所有行为的信息，从而消除手动行为词汇表选择的步骤。在实现中，我们结合了学生-教师编码器方案以有效构建预训练监督。实验结果表明，\\model{}在两个实际工业数据集和八个下游任务上，平均提升了3.9%的AUC和98.9%的训练吞吐量。值得注意的是，在预训练过程中，模型展示了有意义的注意力模式和聚类表示，而无需任何标签监督。在对我们支付宝应用中两个金融逾期风险管理任务的在线部署测试中，经过预训练的模型在两个任务上分别提升了约2.7%和7.1%的KS值，为蚂蚁集团减少了数百万美元的坏账风险。', 'title_zh': '通过自助法训练你的行为：一种新的用户行为序列数据预训练策略'}
{'arxiv_id': 'arXiv:2506.11052', 'title': 'ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention', 'authors': 'Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan', 'link': 'https://arxiv.org/abs/2506.11052', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, yet their direct application to NP-hard combinatorial problems (CPs) remains underexplored. In this work, we systematically investigate the reasoning abilities of LLMs on a variety of NP-hard combinatorial optimization tasks and introduce ACCORD: Autoregressive Constraint-satisfying generation for COmbinatorial optimization with Routing and Dynamic attention. ACCORD features a novel dataset representation and model architecture that leverage the autoregressive nature of LLMs to dynamically enforce feasibility constraints, coupled with attention-based routing to activate problem-specific LoRA modules. We also present the ACCORD-90k supervised dataset, covering six NP-hard combinatorial problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking. Extensive experiments demonstrate that our ACCORD model, built on an 8B-parameter Llama backbone, consistently outperforms standard prompting and input-output methods, even when compared to much larger LLMs, such as gpt-4. Ablation studies further show that our output structure enhances solution feasibility. To the best of our knowledge, this is the first large-scale, end-to-end framework for exploring the applications of LLMs to a broad spectrum of combinatorial optimization problems. The codes are publicly available at this https URL', 'abstract_zh': '大规模语言模型（LLMs）展示了令人印象深刻的推理能力，但它们直接应用于NP难题组合优化问题（NP-hard combinatorial problems, CPs）仍处探索阶段。本文系统研究了LLMs在各种NP难题组合优化任务上的推理能力，并引入了ACCORD：基于自回归约束满足生成的组合优化路由与动态注意力模型。ACCORD 特设一种新颖的数据集表示和模型架构，利用LLMs的自回归特性动态施加可行性约束，结合基于注意力的路由激活特定问题的LoRA模块。我们还介绍了ACCORD-90K监督数据集，涵盖了六种NP难题组合优化问题：TSP、VRP、Knapsack、FlowShop、JSSP和BinPacking。广泛的实验证明，基于8B参数Llama骨干的ACCORD模型在多种基准测试中均优于标准提示和输入输出方法，即使与更大的LLM（如gpt-4）相比也是如此。消融研究表明，我们的输出结构增强了解的可行性。据我们所知，这是首个大规模端到端框架，用于探索LLMs在广泛组合优化问题中的应用。相关代码可在以下网址获取。', 'title_zh': 'ACCORD：自回归约束满足生成在路径组合优化中的应用与动态注意力机制'}
{'arxiv_id': 'arXiv:2506.11049', 'title': '15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks', 'authors': 'Andrew P. Berg, Qian Zhang, Mia Y. Wang', 'link': 'https://arxiv.org/abs/2506.11049', 'abstract': 'Unmanned Aerial Vehicles (UAVs) pose an escalating security concerns as the market for consumer and military UAVs grows. This paper address the critical data scarcity challenges in deep UAV audio classification. We build upon our previous work expanding novel approaches such as: parameter efficient fine-tuning, data augmentation, and pre-trained networks. We achieve performance upwards of 95\\% validation accuracy with EfficientNet-B0.', 'abstract_zh': '无人航空器（UAVs）随着消费级和军用无人机市场的扩大，带来了日益加剧的安全 concerns。本文解决了深度无人机音频分类中的关键数据稀缺挑战。我们在此前工作的基础上，扩展了新型方法，包括参数高效微调、数据增强和预训练网络。我们使用EfficientNet-B0实现了超过95%的验证准确率。', 'title_zh': '15,500秒：基于PEFT和预训练网络的轻量级无人机分类'}
{'arxiv_id': 'arXiv:2506.11048', 'title': "I Can't Believe It's Not Real: CV-MuSeNet: Complex-Valued Multi-Signal Segmentation", 'authors': 'Sangwon Shin, Mehmet C. Vuran', 'link': 'https://arxiv.org/abs/2506.11048', 'abstract': 'The increasing congestion of the radio frequency spectrum presents challenges for efficient spectrum utilization. Cognitive radio systems enable dynamic spectrum access with the aid of recent innovations in neural networks. However, traditional real-valued neural networks (RVNNs) face difficulties in low signal-to-noise ratio (SNR) environments, as they were not specifically developed to capture essential wireless signal properties such as phase and amplitude. This work presents CMuSeNet, a complex-valued multi-signal segmentation network for wideband spectrum sensing, to address these limitations. Extensive hyperparameter analysis shows that a naive conversion of existing RVNNs into their complex-valued counterparts is ineffective. Built on complex-valued neural networks (CVNNs) with a residual architecture, CMuSeNet introduces a complexvalued Fourier spectrum focal loss (CFL) and a complex plane intersection over union (CIoU) similarity metric to enhance training performance. Extensive evaluations on synthetic, indoor overthe-air, and real-world datasets show that CMuSeNet achieves an average accuracy of 98.98%-99.90%, improving by up to 9.2 percentage points over its real-valued counterpart and consistently outperforms state of the art. Strikingly, CMuSeNet achieves the accuracy level of its RVNN counterpart in just two epochs, compared to the 27 epochs required for RVNN, while reducing training time by up to a 92.2% over the state of the art. The results highlight the effectiveness of complex-valued architectures in improving weak signal detection and training efficiency for spectrum sensing in challenging low-SNR environments. The dataset is available at: this https URL', 'abstract_zh': '射频频谱拥堵的挑战及其认知无线电系统的动态频谱访问：一种用于宽带频谱感知的复值多信号分割网络（CMuSeNet）', 'title_zh': '我不敢相信这不是真实的：CV-MuSeNet：复值多信号分割'}
{'arxiv_id': 'arXiv:2506.11039', 'title': 'Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation', 'authors': 'Cheng Jin, Zhenyu Xiao, Chutao Liu, Yuantao Gu', 'link': 'https://arxiv.org/abs/2506.11039', 'abstract': 'Classifier-free guidance (CFG) has emerged as a pivotal advancement in text-to-image latent diffusion models, establishing itself as a cornerstone technique for achieving high-quality image synthesis. However, under high guidance weights, where text-image alignment is significantly enhanced, CFG also leads to pronounced color distortions in the generated images. We identify that these distortions stem from the amplification of sample norms in the latent space. We present a theoretical framework that elucidates the mechanisms of norm amplification and anomalous diffusion phenomena induced by classifier-free guidance. Leveraging our theoretical insights and the latent space structure, we propose an Angle Domain Guidance (ADG) algorithm. ADG constrains magnitude variations while optimizing angular alignment, thereby mitigating color distortions while preserving the enhanced text-image alignment achieved at higher guidance weights. Experimental results demonstrate that ADG significantly outperforms existing methods, generating images that not only maintain superior text alignment but also exhibit improved color fidelity and better alignment with human perceptual preferences.', 'abstract_zh': '无分类指导（CFG）已成为文本到图像潜在扩散模型中的关键性进展，确立了其作为实现高质量图像合成的核心技术地位。然而，在高指导权重下，尽管文本与图像的对齐显著增强，CFG 也会导致生成图像中出现明显的颜色失真。我们发现这些失真源于潜在空间中样本范数的放大。我们提供了一个理论框架，阐述了无分类指导引起的范数放大和异常扩散现象的机制。利用我们的理论洞察和潜在空间结构，我们提出了角度域指导（ADG）算法。ADG 控制幅度变化同时优化角度对齐，从而减轻颜色失真并保留高指导权重下增强的文本与图像对齐。实验结果表明，ADG 显著优于现有方法，生成的图像不仅保持了更佳的文本对齐，而且具有更高的颜色保真度和更好的符合人类感知偏好的对齐。', 'title_zh': '角度域导向：潜在扩散需要旋转而非外推。'}
{'arxiv_id': 'arXiv:2506.11035', 'title': 'Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity', 'authors': 'Moussa Koulako Bala Doumbouya, Dan Jurafsky, Christopher D. Manning', 'link': 'https://arxiv.org/abs/2506.11035', 'abstract': "Work in psychology has highlighted that the geometric model of similarity standard in deep learning is not psychologically plausible because its metric properties such as symmetry do not align with human perception. In contrast, Tversky (1977) proposed an axiomatic theory of similarity based on a representation of objects as sets of features, and their similarity as a function of common and distinctive features. However, this model has not been used in deep learning before, partly due to the challenge of incorporating discrete set operations. We develop a differentiable parameterization of Tversky's similarity that is learnable through gradient descent, and derive neural network building blocks such as the Tversky projection layer, which unlike the linear projection layer can model non-linear functions such as XOR. Through experiments with image recognition and language modeling, we show that the Tversky projection layer is a beneficial replacement for the linear projection layer, which employs geometric similarity. On the NABirds image classification task, a frozen ResNet-50 adapted with a Tversky projection layer achieves a 24.7% relative accuracy improvement over the linear layer adapter baseline. With Tversky projection layers, GPT-2's perplexity on PTB decreases by 7.5%, and its parameter count by 34.8%. Finally, we propose a unified interpretation of both projection layers as computing similarities of input stimuli to learned prototypes, for which we also propose a novel visualization technique highlighting the interpretability of Tversky projection layers. Our work offers a new paradigm for thinking about the similarity model implicit in deep learning, and designing networks that are interpretable under an established theory of psychological similarity.", 'abstract_zh': '心理学研究表明，深度学习中的几何相似性模型与人类感知不相符，因为其度量属性如对称性无法符合人类感知。相比之下，Tversky（1977）提出了一种基于对象特征集合及其相似性由共性和独特特征决定的公理化相似性理论。然而，该模型在此之前未被应用于深度学习，部分原因是难以整合离散集操作。我们开发了一个可微分的Tversky相似性参数化模型，可以通过梯度下降学习，并推导出如Tversky投影层等神经网络构建块，与线性投影层不同，它可以建模如异或这样的非线性函数。通过图像识别和语言建模实验，我们展示了Tversky投影层是线性相似性投影层的良好替代方案。在NABirds图像分类任务中，冻结的ResNet-50使用Tversky投影层适配相比线性层适配基线提高了24.7%的相对准确率。GPT-2使用Tversky投影层在PTB上的困惑度降低7.5%，参数量减少34.8%。最后，我们提出了两种投影层作为一个统一解释，即计算输入刺激与学习原型相似性的模型，并提出了新的可视化技术，以突出Tversky投影层的可解释性。我们的工作提供了一个新的范式来思考深度学习中隐含的相似性模型，并设计在已建立的心理相似性理论下具有可解释性的网络。', 'title_zh': 'Tversky神经网络：基于可微Tversky相似性的心理可解释深度学习'}
{'arxiv_id': 'arXiv:2506.11034', 'title': 'CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models', 'authors': 'Aneesh Komanduri, Karuna Bhaila, Xintao Wu', 'link': 'https://arxiv.org/abs/2506.11034', 'abstract': 'Large language models (LLMs) have shown remarkable ability in various language tasks, especially with their emergent in-context learning capability. Extending LLMs to incorporate visual inputs, large vision-language models (LVLMs) have shown impressive performance in tasks such as recognition and visual question answering (VQA). Despite increasing interest in the utility of LLMs in causal reasoning tasks such as causal discovery and counterfactual reasoning, there has been relatively little work showcasing the abilities of LVLMs on visual causal reasoning tasks. We take this opportunity to formally introduce a comprehensive causal reasoning benchmark for multi-modal in-context learning from LVLMs. Our CausalVLBench encompasses three representative tasks: causal structure inference, intervention target prediction, and counterfactual prediction. We evaluate the ability of state-of-the-art open-source LVLMs on our causal reasoning tasks across three causal representation learning datasets and demonstrate their fundamental strengths and weaknesses. We hope that our benchmark elucidates the drawbacks of existing vision-language models and motivates new directions and paradigms in improving the visual causal reasoning abilities of LVLMs.', 'abstract_zh': '大型语言模型（LLMs）在各种语言任务中展示了出色的 ability，特别是在其上下文学习能力方面。将LLMs扩展以结合视觉输入，大型视觉语言模型（LVLMs）在识别和视觉问答（VQA）等任务中展现了出色的性能。尽管对因果推理任务（如因果发现和反事实推理）中LLMs的应用越来越感兴趣，但在视觉因果推理任务中的LVLMs能力展示仍然相对较少。我们借此机会正式介绍了一个全面的因果推理基准，用于评估LVLMs的多模态上下文学习能力。我们的CausalVLBench包含三个代表性任务：因果结构推理、干预目标预测和反事实预测。我们评估了最先进的开源LVLMs在我们的因果推理任务上的表现，并在三个因果表示学习数据集中展示了它们的基本优势和弱点。我们希望这个基准能够揭示现有视觉语言模型的不足，并激励改进LVLMs视觉因果推理能力的新方向和范式。', 'title_zh': 'CausalVLBench: 大规模视觉语言模型中的视觉因果推理评估基准'}
{'arxiv_id': 'arXiv:2506.11033', 'title': 'Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees', 'authors': 'Minjae Kwon, Tyler Ingebrand, Ufuk Topcu, Lu Feng', 'link': 'https://arxiv.org/abs/2506.11033', 'abstract': "Variations in hidden parameters, such as a robot's mass distribution or friction, pose safety risks during execution. We develop a runtime shielding mechanism for reinforcement learning, building on the formalism of constrained hidden-parameter Markov decision processes. Function encoders enable real-time inference of hidden parameters from observations, allowing the shield and the underlying policy to adapt online. The shield constrains the action space by forecasting future safety risks (such as obstacle proximity) and accounts for uncertainty via conformal prediction. We prove that the proposed mechanism satisfies probabilistic safety guarantees and yields optimal policies among the set of safety-compliant policies. Experiments across diverse environments with varying hidden parameters show that our method significantly reduces safety violations and achieves strong out-of-distribution generalization, while incurring minimal runtime overhead.", 'abstract_zh': '隐藏参数变化带来的安全风险在执行过程中构成威胁。我们基于受限隐藏参数马尔可夫决策过程的形式主义，开发了一种运行时屏蔽机制，以强化学习为依托。功能编码器能够实时从观察中推断隐藏参数，使屏蔽机制和基础策略能够在线适应。屏蔽机制通过预测未来的安全风险（如障碍物接近度）来限制动作空间，并通过套合预测来处理不确定性。我们证明了所提出的机制满足概率安全保证，并在符合安全标准的策略集中产生最优策略。实验结果显示，在不同环境和变化的隐藏参数下，该方法显著降低了安全违规行为，实现了较强的分布外泛化能力，同时运行时开销minimal。', 'title_zh': '通过自适应屏蔽实现运行时安全：从隐藏参数推理到可证明的保证'}
{'arxiv_id': 'arXiv:2506.11031', 'title': 'Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models', 'authors': 'Zoher Kachwala, Danishjeet Singh, Danielle Yang, Filippo Menczer', 'link': 'https://arxiv.org/abs/2506.11031', 'abstract': "As image generators produce increasingly realistic images, concerns about potential misuse continue to grow. Supervised detection relies on large, curated datasets and struggles to generalize across diverse generators. In this work, we investigate the use of pre-trained Vision-Language Models (VLMs) for zero-shot detection of AI-generated images. While off-the-shelf VLMs exhibit some task-specific reasoning and chain-of-thought prompting offers gains, we show that task-aligned prompting elicits more focused reasoning and significantly improves performance without fine-tuning. Specifically, prefixing the model's response with the phrase ``Let's examine the style and the synthesis artifacts'' -- a method we call zero-shot-s$^2$ -- boosts Macro F1 scores by 8%-29% for two widely used open-source models. These gains are consistent across three recent, diverse datasets spanning human faces, objects, and animals with images generated by 16 different models -- demonstrating strong generalization. We further evaluate the approach across three additional model sizes and observe improvements in most dataset-model combinations -- suggesting robustness to model scale. Surprisingly, self-consistency, a behavior previously observed in language reasoning, where aggregating answers from diverse reasoning paths improves performance, also holds in this setting. Even here, zero-shot-s$^2$ scales better than chain-of-thought in most cases -- indicating that it elicits more useful diversity. Our findings show that task-aligned prompts elicit more focused reasoning and enhance latent capabilities in VLMs, like the detection of AI-generated images -- offering a simple, generalizable, and explainable alternative to supervised methods. Our code is publicly available on github: this https URL.", 'abstract_zh': "随着图像生成器生成的图像越来越逼真，潜在滥用的问题日益引起关注。监督检测依赖于大规模的策划数据集，并难以在多种生成器上泛化。在本文中，我们研究了预训练的视觉-语言模型（VLMs）在零样本检测AI生成图像中的应用。尽管即用型VLMs表现出一定的任务特定推理能力，且链式提示技术能提升表现，但我们证明了任务对齐的提示能引发更集中的推理，并在无需微调的情况下显著提高性能。具体而言，通过在模型响应前加上短语“Let's examine the style and the synthesis artifacts”——我们称之为零样本s$^2$方法——能够将两种广泛使用的开源模型的宏F1得分提高8%-29%。这些增益在跨越人类面部、物体和动物的三个近期多样数据集上是一致的，展示了较强的泛化能力。我们还在三个额外的模型大小上评估了该方法，并在多数数据集-模型组合中观察到性能提升——表明该方法对模型规模具有鲁棒性。令人惊讶的是，在这里，自我一致性——即从多种推理路径汇总答案以提升性能的现象——也有效。在此设置中，零样本s$^2$在多数情况下比链式提示更有优势——表明它能引发更有用的多样性。我们的研究发现任务对齐的提示能引发更集中的推理，并增强VLMs的潜在能力，如检测AI生成图像的能力——提供了一种简单、可泛化且可解释的替代监督方法。我们的代码已在github上公开：this https URL。", 'title_zh': '面向任务的提示改善了视觉-语言模型在零样本检测AI生成图像方面的性能'}
{'arxiv_id': 'arXiv:2506.11030', 'title': 'Forward Target Propagation: A Forward-Only Approach to Global Error Credit Assignment via Local Losses', 'authors': 'Nazmus Saadat As-Saquib, A N M Nafiz Abeer, Hung-Ta Chien, Byung-Jun Yoon, Suhas Kumar, Su-in Yi', 'link': 'https://arxiv.org/abs/2506.11030', 'abstract': 'Training neural networks has traditionally relied on backpropagation (BP), a gradient-based algorithm that, despite its widespread success, suffers from key limitations in both biological and hardware perspectives. These include backward error propagation by symmetric weights, non-local credit assignment, and frozen activity during backward passes. We propose Forward Target Propagation (FTP), a biologically plausible and computationally efficient alternative that replaces the backward pass with a second forward pass. FTP estimates layerwise targets using only feedforward computations, eliminating the need for symmetric feedback weights or learnable inverse functions, hence enabling modular and local learning. We evaluate FTP on fully connected networks, CNNs, and RNNs, demonstrating accuracies competitive with BP on MNIST, CIFAR10, and CIFAR100, as well as effective modeling of long-term dependencies in sequential tasks. Moreover, FTP outperforms BP under quantized low-precision and emerging hardware constraints while also demonstrating substantial efficiency gains over other biologically inspired methods such as target propagation variants and forward-only learning algorithms. With its minimal computational overhead, forward-only nature, and hardware compatibility, FTP provides a promising direction for energy-efficient on-device learning and neuromorphic computing.', 'abstract_zh': '基于前向目标传播的神经网络训练：一种生物可行且计算高效的替代方法', 'title_zh': '正向目标传播：通过局部损失进行全局误差责任分配的单向方法'}
{'arxiv_id': 'arXiv:2506.11029', 'title': 'Output Scaling: YingLong-Delayed Chain of Thought in a Large Pretrained Time Series Forecasting Model', 'authors': 'Xue Wang, Tian Zhou, Jinyang Gao, Bolin Ding, Jingren Zhou', 'link': 'https://arxiv.org/abs/2506.11029', 'abstract': 'We present a joint forecasting framework for time series prediction that contrasts with traditional direct or recursive methods. This framework achieves state-of-the-art performance for our designed foundation model, YingLong, and reveals a novel scaling effect: longer outputs significantly enhance model accuracy due to delayed chain-of-thought reasoning in our non-causal approach. YingLong is a non-causal, bidirectional attention encoder-only transformer trained through masked token recovery, aligning more effectively with language understanding tasks than with generation tasks. Additionally, we boost performance by tackling output variance with a multi-input ensemble. We release four foundation models ranging from 6M to 300M parameters, demonstrating superior results in zero-shot tasks on the ETT and Weather datasets. YingLong achieves more than 60% best performance. To ensure generalizability, we assessed the models using the GIFT-Eval benchmark, which comprises 23 time series datasets across 7 domains. Yinglong significantly outperformed the best time-series foundation models, end-to-end trained models by 14% and 44% in rank this http URL pretrained 300M model is available at this https URL', 'abstract_zh': '我们提出了一种时间序列预测的联合预测框架，该框架不同于传统的直接或递归方法。该框架展示了我们设计的基础模型YingLong达到了最先进的性能，并揭示了一种新的缩放效应：更长的输出显著提高了模型精度，这是由于我们在非因果方法中的延迟链式推理。YingLong是一个非因果的双向注意编码器变换器，通过掩码令牌恢复进行训练，更有效地与语言理解任务而非生成任务对齐。此外，我们通过多输入集成解决输出方差，进一步提升了性能。我们发布了参数范围从6M到300M的四种基础模型，在ETT和Weather数据集的零样本任务中展示了优越的结果，YingLong实现了超过60%的最佳性能。为了确保通用性，我们使用包含7个领域23个时间序列数据集的GIFT-Eval基准评估了这些模型，YingLong在排名上分别超过了最佳时间序列基础模型14%和端到端训练模型44%。300M预训练模型可以在以下链接获取：this https URL', 'title_zh': '输出缩放：YingLong-延迟思维链的大规模预训练时间序列预测模型'}
{'arxiv_id': 'arXiv:2506.11028', 'title': 'Enhancing Epidemic Forecasting: Evaluating the Role of Mobility Data and Graph Convolutional Networks', 'authors': 'Suhan Guo, Zhenghao Xu, Furao Shen, Jian Zhao', 'link': 'https://arxiv.org/abs/2506.11028', 'abstract': 'Accurate prediction of contagious disease outbreaks is vital for informed decision-making. Our study addresses the gap between machine learning algorithms and their epidemiological applications, noting that methods optimal for benchmark datasets often underperform with real-world data due to difficulties in incorporating mobility information. We adopt a two-phase approach: first, assessing the significance of mobility data through a pilot study, then evaluating the impact of Graph Convolutional Networks (GCNs) on a transformer backbone. Our findings reveal that while mobility data and GCN modules do not significantly enhance forecasting performance, the inclusion of mortality and hospitalization data markedly improves model accuracy. Additionally, a comparative analysis between GCN-derived spatial maps and lockdown orders suggests a notable correlation, highlighting the potential of spatial maps as sensitive indicators for mobility. Our research offers a novel perspective on mobility representation in predictive modeling for contagious diseases, empowering decision-makers to better prepare for future outbreaks.', 'abstract_zh': '准确预测传染病爆发对于科学决策至关重要。我们的研究填补了机器学习算法与流行病学应用之间的差距，指出适合基准数据集的方法在实际数据中往往表现不佳，原因在于难以整合移动信息。我们采用两阶段的方法：首先通过试点研究评估移动数据的意义，然后在变压器骨干上评估图形卷积网络（GCNs）的影响。研究结果表明，虽然移动数据和GCN模块并未显著提升预测性能，但包括死亡和住院数据明显提高了模型精度。此外，GCN生成的空间地图与封锁令之间的对比分析表明了显著的相关性，强调了空间地图作为敏感移动指标的潜力。我们的研究为传染病预测建模中的移动表示提供了新的视角，助力决策者更好地应对未来的爆发事件。', 'title_zh': '增强传染病预测：评估移动数据和图卷积网络的作用'}
{'arxiv_id': 'arXiv:2506.11027', 'title': 'From Reasoning to Code: GRPO Optimization for Underrepresented Languages', 'authors': 'Federico Pennino, Bianca Raimondi, Massimo Rondelli, Andrea Gurioli, Maurizio Gabbrielli', 'link': 'https://arxiv.org/abs/2506.11027', 'abstract': 'Generating accurate and executable code using large language models (LLMs) is challenging for languages with limited public training data compared to popular languages such as Python. This paper introduces a generalizable approach that uses small-scale code versions of the Qwen 2.5 model combined with Group Relative Policy Optimization (GRPO) to enable effective code generation through explicit reasoning steps, which is particularly beneficial for languages with smaller source code databases. Using Prolog as a representative use case -- given its limited online presence -- the initial model faced challenges in generating executable code. After some training steps, the model successfully produces logically consistent and syntactically accurate code by directly integrating reasoning-driven feedback into the reinforcement learning loop. Experimental evaluations using mathematical logic problem benchmarks illustrate significant improvements in reasoning quality, code accuracy, and logical correctness, underscoring the potential of this approach to benefit a wide range of programming languages lacking extensive training resources.', 'abstract_zh': '使用大型语言模型生成准确可执行代码：面向具有有限公共训练数据的语言', 'title_zh': '从推理到代码：未充分代表语言的GRPO优化'}
{'arxiv_id': 'arXiv:2506.11025', 'title': 'When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces', 'authors': 'Miriam Doh, Aditya Gulati, Matei Mancas, Nuria Oliver', 'link': 'https://arxiv.org/abs/2506.11025', 'abstract': 'This paper examines how synthetically generated faces and machine learning-based gender classification algorithms are affected by algorithmic lookism, the preferential treatment based on appearance. In experiments with 13,200 synthetically generated faces, we find that: (1) text-to-image (T2I) systems tend to associate facial attractiveness to unrelated positive traits like intelligence and trustworthiness; and (2) gender classification models exhibit higher error rates on "less-attractive" faces, especially among non-White women. These result raise fairness concerns regarding digital identity systems.', 'abstract_zh': '本文探讨了合成生成的人脸和基于机器学习的性别分类算法如何受到算法外观偏见的影响，即基于外观的偏好处理。在对13,200张合成生成的人脸进行的实验中，我们发现：（1）文本转图像（T2I）系统倾向于将面部吸引力与智力和可信度等无关的积极特质相联系；（2）性别分类模型在“不够吸引人”的人脸上表现出更高的错误率，特别是在非白人女性中。这些结果引发了数字身份系统公平性的关切。', 'title_zh': '当算法青睐有加：面部生成与感知中的相貌偏见'}
{'arxiv_id': 'arXiv:2506.11024', 'title': 'Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients', 'authors': 'Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars', 'link': 'https://arxiv.org/abs/2506.11024', 'abstract': 'Foundation models have shown remarkable capabilities across diverse multi-modal tasks, but their centralized training raises privacy concerns and induces high transmission costs. In contrast, federated learning (FL) offers a distributed alternative without the need to share data. Recently, for the growing demand for personalizing AI models for different user purposes, personalized federated learning (PFL) has emerged. PFL allows each client to leverage the knowledge of other clients for further adaptation to individual user preferences, again without the need to share data. Despite its potential, most PFL studies remain confined to simulated environments, overlooking the data and model heterogeneity that arise in real-world scenarios. In contrast, we first consider large data heterogeneity, evaluating on a new benchmark for multi-modal PFL, spanning 40 distinct tasks with realistic data distribution shifts. We then consider model heterogeneity in that we do not assume that all clients share similar model architectures. To address data heterogeneity, we propose a task-similarity-aware model aggregation method that provides customized global models to each client. For model heterogeneity, we propose a dimension-invariant module that enables knowledge sharing across heterogeneous models. Empirical validations demonstrate that the proposed approach outperforms the state-of-the-art, excelling in both personalization and generalization capabilities.', 'abstract_zh': '大规模数据异质性下多模态个性化联邦学习：一种任务相似性aware的模型聚合方法与维度不变的知识模块', 'title_zh': '不同客户端并非平等：异构多模客户端上的个性化联邦学习'}
{'arxiv_id': 'arXiv:2506.11022', 'title': 'Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox', 'authors': 'Shivani Shukla, Himanshu Joshi, Romilla Syed', 'link': 'https://arxiv.org/abs/2506.11022', 'abstract': 'The rapid adoption of Large Language Models(LLMs) for code generation has transformed software development, yet little attention has been given to how security vulnerabilities evolve through iterative LLM feedback. This paper analyzes security degradation in AI-generated code through a controlled experiment with 400 code samples across 40 rounds of "improvements" using four distinct prompting strategies. Our findings show a 37.6% increase in critical vulnerabilities after just five iterations, with distinct vulnerability patterns emerging across different prompting approaches. This evidence challenges the assumption that iterative LLM refinement improves code security and highlights the essential role of human expertise in the loop. We propose practical guidelines for developers to mitigate these risks, emphasizing the need for robust human validation between LLM iterations to prevent the paradoxical introduction of new security issues during supposedly beneficial code "improvements".', 'abstract_zh': '大型语言模型（LLMs）在代码生成中的快速 adoption 已经变革了软件开发，但鲜少有人关注迭代 LLM 反馈如何导致安全漏洞的演变。本文通过一项控制实验，分析了 400 个代码样本在四组不同提示策略下“改进”40 轮后的人工智能生成代码中的安全退化问题。研究发现，在仅仅五轮迭代后，关键漏洞增加了 37.6%，并且不同提示方法出现了独特的漏洞模式。这些发现挑战了迭代 LLM 精炼能够改善代码安全性的假设，并强调了在 LLM 迭代过程中人类专业知识的重要性。我们提出了开发人员可以遵循的实际指南，强调在 LLM 迭代之间进行稳健的人工验证的必要性，以防止在所谓的“有益代码改进”过程中引入新的安全问题。', 'title_zh': '迭代AI代码生成中的安全性退化——悖论的系统分析'}
{'arxiv_id': 'arXiv:2506.11021', 'title': 'Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering', 'authors': 'Chaitanya Ravuri, Saman Amarasinghe', 'link': 'https://arxiv.org/abs/2506.11021', 'abstract': 'Modern code-generation LLMs can already solve a large fraction of programming problems, yet they still hallucinate subtle bugs that make their outputs unsafe for autonomous deployment. We present functional clustering, a black-box wrapper that eliminates nearly all hallucination-induced errors while providing a tunable confidence score. The wrapper samples many candidate programs, executes each on a self-generated test suite, and clusters candidates whose I/O behavior is identical; the empirical mass of the largest cluster serves as an exact confidence estimate. A single scalar threshold on this estimate lets users trade coverage for reliability with exponential guarantees. On LiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet slashes the error rate of returned answers from ~65% to 2%, and drives it to 0% at a conservative threshold while still answering 15.6% of prompts. Manual audits show that the few residual mistakes stem from prompt misinterpretation, not random generation noise, narrowing future work to specification clarity. Because the method requires only sampling and sandbox execution, it applies unchanged to closed-source APIs and future models, offering a practical path toward dependable, autonomous code generation. Our code is available on Github (this https URL).', 'abstract_zh': '现代代码生成大模型已经可以解决大部分编程问题，但仍会生成细微的错误导致输出不适用于自主部署。我们提出了一种功能聚类方法，这是一种黑盒包装器，几乎可以消除所有由幻觉引起的错误，并提供可调节的信心分数。该包装器采样多个候选程序，在自动生成的测试集上执行每个程序，并聚类具有相同I/O行为的候选程序；聚类中最大的质量作为精确的信心估计。该估计值上的单一标量阈值让用户可以在覆盖范围和可靠性之间进行指数级保证的权衡。在LiveCodeBench上，我们的验证器在可解决的任务上保持了基线的通过率，并将返回答案的错误率从约65%降低到2%，在保守的阈值下错误率达到0%，但仍能回答15.6%的请求。手动审核表明，剩余的少数错误来自指令误解，而非随机生成噪声，将未来工作聚焦于规范清晰度。由于该方法只需采样和沙箱执行，因此它可以原封不动地应用于闭源API和未来模型，提供一条走向可靠、自主代码生成的实际路径。我们的代码可在Github上获取（this https URL）。', 'title_zh': '使用功能性聚类消除LLM代码生成中的幻觉诱导错误'}
{'arxiv_id': 'arXiv:2506.11020', 'title': 'Extracting Knowledge Graphs from User Stories using LangChain', 'authors': 'Thayná Camargo da Silva', 'link': 'https://arxiv.org/abs/2506.11020', 'abstract': 'This thesis introduces a novel methodology for the automated generation of knowledge graphs from user stories by leveraging the advanced capabilities of Large Language Models. Utilizing the LangChain framework as a basis, the User Story Graph Transformer module was developed to extract nodes and relationships from user stories using an LLM to construct accurate knowledge this http URL innovative technique was implemented in a script to fully automate the knowledge graph extraction process. Additionally, the evaluation was automated through a dedicated evaluation script, utilizing an annotated dataset for assessment. By enhancing the visualization and understanding of user requirements and domain concepts, this method fosters better alignment between software functionalities and user expectations, ultimately contributing to more effective and user-centric software development processes.', 'abstract_zh': '本论文介绍了一种利用大型语言模型高级能力自动生成知识图谱的新方法，通过利用LangChain框架开发了用户故事图变换器模块，使用LLM从用户故事中抽取节点和关系以构建准确的知识图谱。该创新技术被实现为一个脚本，以完全自动化知识图谱的提取过程。此外，通过专用的评估脚本对标注数据集进行评估，实现了评估的自动化。通过增强用户需求和领域概念的可视化和理解，该方法促进了软件功能与用户期望之间的更好对齐，最终促进了更有效和以用户为中心的软件开发过程。', 'title_zh': '从用户故事中提取知识图谱：基于LangChain的方法'}
{'arxiv_id': 'arXiv:2506.11017', 'title': 'TeleEval-OS: Performance evaluations of large language models for operations scheduling', 'authors': 'Yanyan Wang, Yingying Wang, Junli Liang, Yin Xu, Yunlong Liu, Yiming Xu, Zhengwang Jiang, Zhehe Li, Fei Li, Long Zhao, Kuang Xu, Qi Song, Xiangyang Li', 'link': 'https://arxiv.org/abs/2506.11017', 'abstract': "The rapid advancement of large language models (LLMs) has significantly propelled progress in artificial intelligence, demonstrating substantial application potential across multiple specialized domains. Telecommunications operation scheduling (OS) is a critical aspect of the telecommunications industry, involving the coordinated management of networks, services, risks, and human resources to optimize production scheduling and ensure unified service control. However, the inherent complexity and domain-specific nature of OS tasks, coupled with the absence of comprehensive evaluation benchmarks, have hindered thorough exploration of LLMs' application potential in this critical field. To address this research gap, we propose the first Telecommunications Operation Scheduling Evaluation Benchmark (TeleEval-OS). Specifically, this benchmark comprises 15 datasets across 13 subtasks, comprehensively simulating four key operational stages: intelligent ticket creation, intelligent ticket handling, intelligent ticket closure, and intelligent evaluation. To systematically assess the performance of LLMs on tasks of varying complexity, we categorize their capabilities in telecommunications operation scheduling into four hierarchical levels, arranged in ascending order of difficulty: basic NLP, knowledge Q&A, report generation, and report analysis. On TeleEval-OS, we leverage zero-shot and few-shot evaluation methods to comprehensively assess 10 open-source LLMs (e.g., DeepSeek-V3) and 4 closed-source LLMs (e.g., GPT-4o) across diverse scenarios. Experimental results demonstrate that open-source LLMs can outperform closed-source LLMs in specific scenarios, highlighting their significant potential and value in the field of telecommunications operation scheduling.", 'abstract_zh': '大型语言模型的快速进步显著推动了人工智能的发展，展现出在多个专门领域中的广泛应用潜力。电信运营调度（OS）是电信行业中关键的方面，涉及网络、服务、风险和人力资源的协调管理，以优化生产调度并确保统一的服务控制。然而，OS任务的固有复杂性和领域特定性，以及缺乏全面的评价基准，阻碍了对其应用潜力的深入探索。为解决这一研究缺口，我们提出了首个电信运营调度评价基准（TeleEval-OS）。该基准包括13个子任务的15个数据集，全面模拟了四个关键运营阶段：智能工单创建、智能工单处理、智能工单关闭和智能评估。为系统评估不同复杂度任务上大型语言模型的表现，我们按从简单到复杂的顺序将它们在电信运营调度中的能力分为四个层级：基本自然语言处理、知识问答、报告生成和报告分析。在TeleEval-OS上，我们采用零样本和少样本评估方法，全面评估了10个开源大语言模型（例如DeepSeek-V3）和4个闭源大语言模型（例如GPT-4o）在不同场景中的表现。实验结果表明，开源大语言模型在特定场景中可以超越闭源大语言模型，突显了它们在电信运营调度领域的重大潜力和价值。', 'title_zh': 'TeleEval-OS: 大型语言模型在操作调度性能评估'}
{'arxiv_id': 'arXiv:2506.11015', 'title': 'The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI', 'authors': 'Barbara Oakley, Michael Johnston, Ken-Zen Chen, Eulho Jung, Terrence J. Sejnowski', 'link': 'https://arxiv.org/abs/2506.11015', 'abstract': 'In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as "grokking" and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological "schemata" and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.', 'abstract_zh': '在生成式AI和普及的数字化工具时代，人类认知面临结构悖论：随着外部辅助工具能力的增强，内部记忆系统可能萎缩。基于神经科学与认知心理学，本文探讨了对AI系统和发现式教学方法的高度依赖如何损害陈述性和程序性记忆的巩固——这两种记忆系统对于专业能力、批判性思维和长期记忆至关重要。我们回顾了诸如ChatGPT和计算器之类的工具如何绕过了必要的检索、错误修正和模式构建过程，从而影响稳固的神经编码。值得注意的是，我们强调了深度学习现象如“顿悟”与过度学习和直觉的神经科学之间的显著相似之处。通过讨论初步依赖AI学习的实证研究，展示了如何阻碍程序化和直观 mastery。我们主张有效的AI与人类交互依赖于强大的内部模型——生物“模式”和神经流形，使用户能够评估、完善和引导AI输出。本文最后讨论了大型语言模型时代教育和职业培训的政策含义。', 'title_zh': '记忆悖论：在人工智能时代为什么我们需要知识'}
{'arxiv_id': 'arXiv:2506.11010', 'title': 'Data Science: a Natural Ecosystem', 'authors': 'Emilio Porcu, Roy El Moukari, Laurent Najman, Francisco Herrera, Horst Simon', 'link': 'https://arxiv.org/abs/2506.11010', 'abstract': 'This manuscript provides a holistic (data-centric) view of what we term essential data science, as a natural ecosystem with challenges and missions stemming from the data universe with its multiple combinations of the 5D complexities (data structure, domain, cardinality, causality, and ethics) with the phases of the data life cycle. Data agents perform tasks driven by specific goals. The data scientist is an abstract entity that comes from the logical organization of data agents with their actions. Data scientists face challenges that are defined according to the missions. We define specific discipline-induced data science, which in turn allows for the definition of pan-data science, a natural ecosystem that integrates specific disciplines with the essential data science. We semantically split the essential data science into computational, and foundational. We claim that there is a serious threat of divergence between computational and foundational data science. Especially, if no approach is taken to rate whether a data universe discovery should be useful or not. We suggest that rigorous approaches to measure the usefulness of data universe discoveries might mitigate such a divergence.', 'abstract_zh': '本文提供了一种以数据为中心的整体视角，阐述我们所称的本质数据科学，作为一种自然生态系统，它源于数据宇宙中的多种5D复杂性（数据结构、领域、基数、因果性、伦理）与数据生命周期各阶段所带来的挑战和使命。数据代理根据特定目标执行任务。数据科学家是数据代理及其行为的抽象组织结果。数据科学家面临的挑战由其使命定义。我们定义了特定学科驱动的本质数据科学，进而定义了本质数据科学与特定学科集成的泛数据科学。我们语义上将本质数据科学分为计算性和基础性部分。我们声称，计算性和基础性数据科学之间存在严重分歧的风险。特别是如果没有方法来评估数据宇宙发现是否具有实用性，则风险尤为严重。我们建议采用严谨的方法来衡量数据宇宙发现的实用性，以减轻这种分歧。', 'title_zh': '数据科学：一个自然生态系统'}
{'arxiv_id': 'arXiv:2506.11007', 'title': 'Impact of Comments on LLM Comprehension of Legacy Code', 'authors': 'Rock Sabetto, Emily Escamilla, Devesh Agarwal, Sujay Kandwal, Justin F. Brunelle, Scott Rosen, Nitin Naik, Samruddhi Thaker, Eric O. Scott, Jacob Zimmer, Amit Madan, Arun Sridharan, Doug Wendt, Michael Doyle, Christopher Glasz, Jasper Phillips, William Macke, Colin Diggs, Michael Bartholf, Zachary Robin, Paul Ursino', 'link': 'https://arxiv.org/abs/2506.11007', 'abstract': 'Large language models (LLMs) have been increasingly integrated into software engineering and maintenance tasks due to their high performance with software engineering tasks and robust understanding of modern programming languages. However, the ability of LLMs to comprehend code written with legacy languages remains a research gap challenged by real-world legacy systems lacking or containing inaccurate documentation that may impact LLM comprehension. To assess LLM comprehension of legacy languages, there is a need for objective LLM evaluation. In order to objectively measure LLM comprehension of legacy languages, we need an efficient, quantitative evaluation method. We leverage multiple-choice question answering (MCQA), an emerging LLM evaluation methodology, to evaluate LLM comprehension of legacy code and the impact of comment prevalence and inaccurate comments. In this work, we present preliminary findings on the impact of documentation on LLM comprehension of legacy code and outline strategic objectives for future work.', 'abstract_zh': '大规模语言模型（LLMs）由于其在软件工程任务中的高性能和对现代编程语言的 robust 理解，已被越来越多地集成到软件工程和维护任务中。然而，LLMs 理解使用遗留语言编写的代码的能力仍然是一个研究缺口，这受到真实-world 遗留系统缺乏或包含不准确文档的影响，这些文档可能会影响 LLM 的理解能力。为了评估 LLM 对遗留语言的理解能力，需要客观的 LLM 评估方法。为了客观衡量 LLM 对遗留语言的理解能力，我们需要一种高效且定量的评估方法。我们利用多选题问答（MCQA），一种新兴的 LLM 评估方法，来评估 LLM 对遗留代码的理解及其注释频率和不准确注释的影响。在本文中，我们呈现了关于文档对 LLM 理解遗留代码影响的初步发现，并概述了未来工作的战略目标。', 'title_zh': 'LLM对遗留代码理解的影响研究'}
{'arxiv_id': 'arXiv:2506.11004', 'title': 'Developing a Dyslexia Indicator Using Eye Tracking', 'authors': 'Kevin Cogan, Vuong M. Ngo, Mark Roantree', 'link': 'https://arxiv.org/abs/2506.11004', 'abstract': 'Dyslexia, affecting an estimated 10% to 20% of the global population, significantly impairs learning capabilities, highlighting the need for innovative and accessible diagnostic methods. This paper investigates the effectiveness of eye-tracking technology combined with machine learning algorithms as a cost-effective alternative for early dyslexia detection. By analyzing general eye movement patterns, including prolonged fixation durations and erratic saccades, we proposed an enhanced solution for determining eye-tracking-based dyslexia features. A Random Forest Classifier was then employed to detect dyslexia, achieving an accuracy of 88.58\\%. Additionally, hierarchical clustering methods were applied to identify varying severity levels of dyslexia. The analysis incorporates diverse methodologies across various populations and settings, demonstrating the potential of this technology to identify individuals with dyslexia, including those with borderline traits, through non-invasive means. Integrating eye-tracking with machine learning represents a significant advancement in the diagnostic process, offering a highly accurate and accessible method in clinical research.', 'abstract_zh': '阅读障碍影响着全球约10%到20%的人口，显著妨碍学习能力，强调了创新且易于获取的诊断方法的必要性。本文探讨了眼球追踪技术结合机器学习算法作为早期阅读障碍检测经济有效的替代方法的有效性。通过分析一般的眼动模式，包括延长的注视时间和不规则的眼跳，我们提出了增强的眼球追踪基础阅读障碍特征确定方案。然后使用随机森林分类器进行阅读障碍检测，准确率达到88.58%。此外，还应用了层次聚类方法以识别阅读障碍的不同严重程度。分析涵盖了不同人群和环境下的多种方法，展示了该技术通过无创手段识别包括边缘特质个体在内的阅读障碍个体的潜在能力。将眼球追踪与机器学习的整合是诊断过程中的重要进展，为临床研究提供了高度准确且易于获取的方法。', 'title_zh': '使用眼动追踪开发阅读障碍指示器'}
{'arxiv_id': 'arXiv:2506.11003', 'title': 'EmbedAgent: Benchmarking Large Language Models in Embedded System Development', 'authors': 'Ruiyang Xu, Jialun Cao, Mingyuan Wu, Wenliang Zhong, Yaojie Lu, Ben He, Xianpei Han, Shing-Chi Cheung, Le Sun', 'link': 'https://arxiv.org/abs/2506.11003', 'abstract': 'Large Language Models (LLMs) have shown promise in various tasks, yet few benchmarks assess their capabilities in embedded system this http URL this paper, we introduce EmbedAgent, a paradigm designed to simulate real-world roles in embedded system development, such as Embedded System Programmer, Architect, and Integrator. This paradigm enables LLMs to be tested in tasks that bridge the gap between digital and physical systems, allowing for a more comprehensive assessment of their capabilities. To evaluate LLMs on these tasks, we propose Embedbench, the first comprehensive benchmark for embedded system programming, circuit design, and cross-platform this http URL consists of 126 cases, covering 9 electronic components across 3 hardware platforms. Through extensive experiments on 10 mainstream LLMs, we uncover several key findings. Surprisingly, despite the simplicity of the cases, DeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic information, and 50.0% when tasked with generating the schematics itself. In the cross-platform migration tasks, LLMs show relatively strong performance with MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8% pass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4% pass@1.Interestingly, we observe that general-purpose chat LLMs like DeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this domain, while reasoning LLMs tend to overthink and overlook efficient knowledge during pretraining. Based on these insights, we propose two strategies: retrieval augmented generation and compiler feedback-to enhance LLM performance. These strategies result in significant improvements, with Deepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without. Additionally, the accuracy of the Arduino to ESP32 migration task improves from 21.4% to 27.8%.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中展现了潜力，但鲜有基准评估其在嵌入式系统中的能力。在这篇论文中，我们介绍了EmbedAgent，这是一种旨在模拟嵌入式系统开发中的现实角色（如嵌入式系统程序员、架构师和集成商）的范式。这种范式使LLMs能够在连接数字和物理系统之间搭建桥梁的任务中进行测试，从而提供对其能力的全面评估。为了评估LLMs在这些任务上的表现，我们提出了Embedbench，这是第一个全面的嵌入式系统编程、电路设计和跨平台基准。该基准包含126个案例，涵盖了3个硬件平台上的9种电子元件。通过在10个主流LLMs上进行广泛实验，我们发现了几个关键发现。尽管案例相对简单，但在仅提供原理图信息的情况下，DeepSeek-R1的pass@1率仅为55.6%，而要生成原理图时这一比率则下降至50.0%。在跨平台迁移任务中，LLMs在使用MicroPython的Raspberry Pi Pico上表现出相对较强的性能（最佳模型pass@1率为73.8%），但在ESP-IDF上表现较差，最佳模型的pass@1率仅为29.4%。有趣的是，我们发现通用聊天LLMs如DeepSeek-V3往往未能充分利用该领域的预训练知识，而推理LLMs则倾向于过度思考并在预训练中忽视有效的知识。基于这些洞察，我们提出了两种策略：检索增强生成和编译器反馈，以增强LLMs的表现。这些策略带来了显著的改进，DeepSeek-R1在正确原理图的情况下达到65.1%的pass@1率，未正确原理图的情况下达到53.1%的pass@1率，同时Arduino到ESP32的迁移任务准确性从21.4%提高到27.8%。', 'title_zh': 'EmbedAgent: 在嵌入式系统开发中评估大型语言模型'}
{'arxiv_id': 'arXiv:2506.11001', 'title': 'Rethinking Technological Readiness in the Era of AI Uncertainty', 'authors': 'S. Tucker Browne, Mark M. Bailey', 'link': 'https://arxiv.org/abs/2506.11001', 'abstract': "Artificial intelligence (AI) is poised to revolutionize military combat systems, but ensuring these AI-enabled capabilities are truly mission-ready presents new challenges. We argue that current technology readiness assessments fail to capture critical AI-specific factors, leading to potential risks in deployment. We propose a new AI Readiness Framework to evaluate the maturity and trustworthiness of AI components in military systems. The central thesis is that a tailored framework - analogous to traditional Technology Readiness Levels (TRL) but expanded for AI - can better gauge an AI system's reliability, safety, and suitability for combat use. Using current data evaluation tools and testing practices, we demonstrate the framework's feasibility for near-term implementation. This structured approach provides military decision-makers with clearer insight into whether an AI-enabled system has met the necessary standards of performance, transparency, and human integration to be deployed with confidence, thus advancing the field of defense technology management and risk assessment.", 'abstract_zh': '人工智能（AI）有望 revolutionize 军事 combat 系统，但确保这些 AI 驱动的能力真正具备 mission-ready 特性提出了新的挑战。我们认为当前的技术 readiness 评估未能捕捉到关键的 AI 特异性因素，可能导致部署时存在潜在风险。我们提出了一种新的 AI 准备框架，以评估军事系统中 AI 组件的成熟度和可信度。核心论点是，一个定制化的框架（类似于传统的技术 readiness 等级TRL，但扩展了 AI 方面的功能）可以更好地衡量 AI 系统的可靠性、安全性和适合作战使用的特性。利用现有的数据评估工具和测试方法，我们展示了该框架在短期内实施的可能性。这种结构化的方法为军事决策者提供了更清晰的洞察，以确定一个 AI 驱动的系统是否达到了性能、透明性和人机集成所需的必要标准，从而推动了国防技术管理与风险评估领域的进步。', 'title_zh': '重思人工智能不确定性时代的技术准备xing'}
{'arxiv_id': 'arXiv:2506.10999', 'title': 'Automated Validation of COBOL to Java Transformation', 'authors': 'Atul Kumar, Diptikalyan Saha, Toshikai Yasue, Kohichi Ono, Saravanan Krishnan, Sandeep Hans, Fumiko Satoh, Gerald Mitchell, Sachin Kumar', 'link': 'https://arxiv.org/abs/2506.10999', 'abstract': 'Recent advances in Large Language Model (LLM) based Generative AI techniques have made it feasible to translate enterpriselevel code from legacy languages such as COBOL to modern languages such as Java or Python. While the results of LLM-based automatic transformation are encouraging, the resulting code cannot be trusted to correctly translate the original code. We propose a framework and a tool to help validate the equivalence of COBOL and translated Java. The results can also help repair the code if there are some issues and provide feedback to the AI model to improve. We have developed a symbolic-execution-based test generation to automatically generate unit tests for the source COBOL programs which also mocks the external resource calls. We generate equivalent JUnit test cases with equivalent mocking as COBOL and run them to check semantic equivalence between original and translated programs.', 'abstract_zh': '基于大型语言模型的生成AI技术 Recent进展使得从COBOL等遗留语言转换企业级代码到现代语言（如Java或Python）成为可能。尽管基于大型语言模型的自动转换结果令人鼓舞，但生成的代码无法保证准确翻译原始代码。我们提出了一种框架和工具，以帮助验证COBOL和翻译后的Java代码的等效性。这些结果还可以帮助修复代码中的问题，并为AI模型提供反馈以改进。我们开发了一种基于符号执行的测试生成方法，以自动为源COBOL程序生成单元测试，并模拟外部资源调用。我们生成了等效的JUnit测试用例，并进行了等效的模拟，以检查原始程序和翻译后程序之间的语义等效性。', 'title_zh': 'COBOL到Java转换的自动化验证'}
{'arxiv_id': 'arXiv:2506.10998', 'title': 'Towards Automated Formal Verification of Backend Systems with LLMs', 'authors': 'Kangping Xu, Yifan Luo, Yang Yuan, Andrew Chi-Chih Yao', 'link': 'https://arxiv.org/abs/2506.10998', 'abstract': "Software testing plays a critical role in ensuring that systems behave as intended. However, existing automated testing approaches struggle to match the capabilities of human engineers due to key limitations such as test locality, lack of general reliability, and business logic blindness. In this work, we propose a novel framework that leverages functional programming and type systems to translate Scala backend code into formal Lean representations. Our pipeline automatically generates theorems that specify the intended behavior of APIs and database operations, and uses LLM-based provers to verify them. When a theorem is proved, the corresponding logic is guaranteed to be correct and no further testing is needed. If the negation of a theorem is proved instead, it confirms a bug. In cases where neither can be proved, human intervention is required. We evaluate our method on realistic backend systems and find that it can formally verify over 50% of the test requirements, which suggests that half of a testing engineer's workload can be automated. Additionally, with an average cost of only $2.19 per API, LLM-based verification is significantly more cost-effective than manual testing and can be scaled easily through parallel execution. Our results indicate a promising direction for scalable, AI-powered software testing, with the potential to greatly improve engineering productivity as models continue to advance.", 'abstract_zh': '软件测试对于确保系统按预期行为运行至关重要。然而，现有的自动化测试方法由于测试局部性、缺乏通用可靠性以及业务逻辑盲点等关键限制，在能力上难以与人类工程师媲美。在此项工作中，我们提出了一种新颖的框架，该框架利用函数式编程和类型系统将Scala后端代码转换为形式化的Lean表示。我们的流水线自动生成规定API和数据库操作预期行为的定理，并利用基于LLM的证明器验证这些定理。当定理被证明时，相应的逻辑被保证是正确的，无需进一步测试。如果相反的定理被证明，则确认存在漏洞。在既无法证明的情况下，则需要人工干预。我们通过现实世界的后端系统评估了该方法，并发现它可以形式化验证超过50%的测试需求，这表明一半的测试工程师的工作量可以实现自动化。此外，平均每API的成本仅为2.19美元，基于LLM的验证比人工测试成本效益更高，并且可以通过并行执行轻松扩大规模。我们的结果表明了一条有前景的研究方向，即利用AI实现可扩展的软件测试，随着模型的不断进步，有望大幅提升工程生产力。', 'title_zh': '基于大语言模型的后端系统自动化形式化验证Towards Automated Formal Verification of Backend Systems with LLMs'}
{'arxiv_id': 'arXiv:2506.10996', 'title': 'Evaluating LLMs for Visualization Tasks', 'authors': 'Saadiq Rauf Khan, Vinit Chandak, Sougata Mukherjea', 'link': 'https://arxiv.org/abs/2506.10996', 'abstract': 'Information Visualization has been utilized to gain insights from complex data. In recent times, Large Language Models (LLMs) have performed very well in many tasks. In this paper, we showcase the capabilities of different popular LLMs to generate code for visualization based on simple prompts. We also analyze the power of LLMs to understand some common visualizations by answering simple questions. Our study shows that LLMs could generate code for some visualizations as well as answer questions about them. However, LLMs also have several limitations. We believe that our insights can be used to improve both LLMs and Information Visualization systems.', 'abstract_zh': '大型语言模型在信息可视化中的应用：生成代码与理解可视化的能力及限制', 'title_zh': '评估大规模语言模型在可视化任务中的应用'}
{'arxiv_id': 'arXiv:2506.10990', 'title': "On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances", 'authors': 'Roberto Vergallo, Luís Cruz, Alessio Errico, Luca Mainetti', 'link': 'https://arxiv.org/abs/2506.10990', 'abstract': "'Follow-the-Sun' (FtS) is a theoretical computational model aimed at minimizing the carbon footprint of computer workloads. It involves dynamically moving workloads to regions with cleaner energy sources as demand increases and energy production relies more on fossil fuels. With the significant power consumption of Artificial Intelligence (AI) being a subject of extensive debate, FtS is proposed as a strategy to mitigate the carbon footprint of training AI models. However, the literature lacks scientific evidence on the advantages of FtS to mitigate the carbon footprint of AI workloads. In this paper, we present the results of an experiment conducted in a partial synthetic scenario to address this research gap. We benchmarked four AI algorithms in the anomaly detection domain and measured the differences in carbon emissions in four cases: no strategy, FtS, and two strategies previously introduced in the state of the art, namely Flexible Start and Pause and Resume. To conduct our experiment, we utilized historical carbon intensity data from the year 2021 for seven European cities. Our results demonstrate that the FtS strategy not only achieves average reductions of up to 14.6% in carbon emissions (with peaks of 16.3%) but also helps in preserving the time needed for training.", 'abstract_zh': '“跟随太阳”（FtS）是一种理论计算模型，旨在最小化计算机工作负载的碳足迹。它涉及根据需求动态地将工作负载转移到更多使用清洁能源的地区，随着能源生产更多依赖化石燃料。由于人工智能（AI）的能耗问题受到广泛讨论，FtS 被提议作为一种策略来减少训练AI模型的碳足迹。然而，文献中缺乏关于FtS 减少AI工作负载碳足迹优势的科学证据。在本文中，我们展示了在一个部分合成场景下进行的实验结果，以填补这一研究缺口。我们在异常检测领域基准测试了四种AI算法，并测量了四种情况下的碳排放差异：无策略、FtS，以及两种之前在现有技术中引入的策略，即灵活启动和暂停以及恢复。为了进行我们的实验，我们使用了2021年七座欧洲城市的 historical 碳强度数据。我们的结果显示，FtS 策略不仅在碳排放方面实现了最高达16.3%的峰值和平均14.6%的减少，还帮助保持了训练所需的时间。', 'title_zh': '“跟随太阳”策略在减轻云实例中人工智能碳足迹有效性研究'}
{'arxiv_id': 'arXiv:2506.10989', 'title': 'Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs', 'authors': 'Rogelio Cruz, Jonatan Contreras, Francisco Guerrero, Ezequiel Rodriguez, Carlos Valdez, Citlali Carrillo', 'link': 'https://arxiv.org/abs/2506.10989', 'abstract': 'In this paper, we propose a novel prompting approach aimed at enhancing the ability of Large Language Models (LLMs) to generate accurate Python code. Specifically, we introduce a prompt template designed to improve the quality and correctness of generated code snippets, enabling them to pass tests and produce reliable results. Through experiments conducted on two state-of-the-art LLMs using the HumanEval dataset, we demonstrate that our approach outperforms widely studied zero-shot and Chain-of-Thought (CoT) methods in terms of the Pass@k metric. Furthermore, our method achieves these improvements with significantly reduced token usage compared to the CoT approach, making it both effective and resource-efficient, thereby lowering the computational demands and improving the eco-footprint of LLM capabilities. These findings highlight the potential of tailored prompting strategies to optimize code generation performance, paving the way for broader applications in AI-driven programming tasks.', 'abstract_zh': '在本文中，我们提出了一种新颖的提示方法，旨在增强大型语言模型（LLMs）生成准确Python代码的能力。具体而言，我们引入了一种提示模板，旨在提高生成代码片段的质量和正确性，使其能够通过测试并生成可靠的结果。通过在两个最先进的LLM上使用HumanEval数据集进行实验，我们证明了我们的方法在Pass@k指标上优于广泛研究的零样本和思维链（CoT）方法。此外，与CoT方法相比，我们的方法在显著降低令牌使用量的情况下实现了这些改进，使其既有效又资源高效，从而降低了计算需求并提升了LLM能力的生态足迹。这些发现突显了定制提示策略优化代码生成性能的潜力，为AI驱动的编程任务提供了更广泛的应用前景。', 'title_zh': '提示工程与框架：基于指南提升LLM代码可靠性实施方法'}
{'arxiv_id': 'arXiv:2506.10984', 'title': 'Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality', 'authors': 'Ahilan Ayyachamy Nadar Ponnusamy', 'link': 'https://arxiv.org/abs/2506.10984', 'abstract': "AI-assisted code generation tools have revolutionized software development, offering unprecedented efficiency and scalability. However, multiple studies have consistently highlighted challenges such as security vulnerabilities, reliability issues, and inconsistencies in the generated code. Addressing these concerns is crucial to unlocking the full potential of this transformative technology. While advancements in foundational and code-specialized language models have made notable progress in mitigating some of these issues, significant gaps remain, particularly in ensuring high-quality, trustworthy outputs.\nThis paper builds upon existing research on leveraging large language models (LLMs) for application modernization. It explores an opinionated approach that emphasizes two core capabilities of LLMs: code reasoning and code generation. The proposed framework integrates these capabilities with human expertise to tackle application modernization challenges effectively. It highlights the indispensable role of human involvement and guidance in ensuring the success of AI-assisted processes.\nTo demonstrate the framework's utility, this paper presents a detailed case study, walking through its application in a real-world scenario. The analysis includes a step-by-step breakdown, assessing alternative approaches where applicable. This work aims to provide actionable insights and a robust foundation for future research in AI-driven application modernization. The reference implementation created for this paper is available on GitHub.", 'abstract_zh': 'AI辅助的代码生成工具已革新软件开发，提供了前所未有的效率和扩展性。然而，多研究一致指出了安全漏洞、可靠性和生成代码中的一致性等问题。解决这些问题是充分利用这种变革性技术潜力的关键。尽管基础和代码专业化的语言模型的进步在缓解这些问题方面取得了显著进展，但仍存在显著差距，尤其是在确保高质量、可信赖的输出方面。\n\n本文在此基础上，探讨了利用大型语言模型（LLMs）进行应用现代化的现有研究。它提出了一个注重大型语言模型核心能力（代码推理和代码生成）的主观方法，并将这些能力与人类专长相结合，以有效应对应用现代化挑战。本文强调了人类参与和指导在确保AI辅助过程成功中的不可或缺作用。\n\n为展示该框架的实用性，本文通过一个详细的案例研究，展示了其在实际场景中的应用过程。分析包括逐步分解，必要时评估替代方法。本工作旨在提供可操作的见解，并为未来AI驱动的应用现代化研究奠定坚实基础。本文为实现该目标所创建的参考实现可在GitHub上获得。', 'title_zh': '使用LLMs进行应用现代化：应对可靠性、安全性和质量的核心挑战'}
