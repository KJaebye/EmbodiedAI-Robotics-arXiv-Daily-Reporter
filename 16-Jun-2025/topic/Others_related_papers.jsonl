{'arxiv_id': 'arXiv:2506.11948', 'title': 'SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies', 'authors': 'Nadun Ranawaka Arachchige, Zhenyang Chen, Wonsuhk Jung, Woo Chul Shin, Rohan Bansal, Pierre Barroso, Yu Hang He, Yingyang Celine Lin, Benjamin Joffe, Shreyas Kousik, Danfei Xu', 'link': 'https://arxiv.org/abs/2506.11948', 'abstract': 'Offline Imitation Learning (IL) methods such as Behavior Cloning are effective at acquiring complex robotic manipulation skills. However, existing IL-trained policies are confined to executing the task at the same speed as shown in demonstration data. This limits the task throughput of a robotic system, a critical requirement for applications such as industrial automation. In this paper, we introduce and formalize the novel problem of enabling faster-than-demonstration execution of visuomotor policies and identify fundamental challenges in robot dynamics and state-action distribution shifts. We instantiate the key insights as SAIL (Speed Adaptation for Imitation Learning), a full-stack system integrating four tightly-connected components: (1) a consistency-preserving action inference algorithm for smooth motion at high speed, (2) high-fidelity tracking of controller-invariant motion targets, (3) adaptive speed modulation that dynamically adjusts execution speed based on motion complexity, and (4) action scheduling to handle real-world system latencies. Experiments on 12 tasks across simulation and two real, distinct robot platforms show that SAIL achieves up to a 4x speedup over demonstration speed in simulation and up to 3.2x speedup in the real world. Additional detail is available at this https URL', 'abstract_zh': '基于离线模仿学习的机器人更快执行视觉-运动策略的问题及其挑战与解决方案：SAIL方法', 'title_zh': 'SAIL: 优于示范的执行imitation learning策略'}
{'arxiv_id': 'arXiv:2506.11335', 'title': 'Measuring and Minimizing Disturbance of Marine Animals to Underwater Vehicles', 'authors': 'Levi Cai, Youenn Jézéquel, T. Aran Mooney, Yogesh Girdhar', 'link': 'https://arxiv.org/abs/2506.11335', 'abstract': 'Do fish respond to the presence of underwater vehicles, potentially biasing our estimates about them? If so, are there strategies to measure and mitigate this response? This work provides a theoretical and practical framework towards bias-free estimation of animal behavior from underwater vehicle observations. We also provide preliminary results from the field in coral reef environments to address these questions.', 'abstract_zh': '水下车辆的存在是否会影响鱼类的行为，从而偏差我们对它们的估计？如果是这样，是否有策略来测量和减轻这种反应？本研究提供了一种无偏差估计水下车辆观测动物行为的理论和实践框架。我们还提供了在珊瑚礁环境中的一些初步结果，以解决这些问题。', 'title_zh': '测量和减小对水下车辆干扰的marine动物的影响'}
{'arxiv_id': 'arXiv:2506.11263', 'title': 'Sensor Model Identification via Simultaneous Model Selection and State Variable Determination', 'authors': 'Christian Brommer, Alessandro Fornasier, Jan Steinbrener, Stephan Weiss', 'link': 'https://arxiv.org/abs/2506.11263', 'abstract': "We present a method for the unattended gray-box identification of sensor models commonly used by localization algorithms in the field of robotics. The objective is to determine the most likely sensor model for a time series of unknown measurement data, given an extendable catalog of predefined sensor models. Sensor model definitions may require states for rigid-body calibrations and dedicated reference frames to replicate a measurement based on the robot's localization state. A health metric is introduced, which verifies the outcome of the selection process in order to detect false positives and facilitate reliable decision-making. In a second stage, an initial guess for identified calibration states is generated, and the necessity of sensor world reference frames is evaluated. The identified sensor model with its parameter information is then used to parameterize and initialize a state estimation application, thus ensuring a more accurate and robust integration of new sensor elements. This method is helpful for inexperienced users who want to identify the source and type of a measurement, sensor calibrations, or sensor reference frames. It will also be important in the field of modular multi-agent scenarios and modularized robotic platforms that are augmented by sensor modalities during runtime. Overall, this work aims to provide a simplified integration of sensor modalities to downstream applications and circumvent common pitfalls in the usage and development of localization approaches.", 'abstract_zh': '一种无人值守的灰盒传感器模型识别方法：应用于机器人定位算法的传感器模型自识别与验证', 'title_zh': '基于同时进行模型选择和状态变量确定的传感器模型识别'}
{'arxiv_id': 'arXiv:2506.11262', 'title': 'Demonstration Sidetracks: Categorizing Systematic Non-Optimality in Human Demonstrations', 'authors': 'Shijie Fang, Hang Yu, Qidi Fang, Reuben M. Aronson, Elaine S. Short', 'link': 'https://arxiv.org/abs/2506.11262', 'abstract': "Learning from Demonstration (LfD) is a popular approach for robots to acquire new skills, but most LfD methods suffer from imperfections in human demonstrations. Prior work typically treats these suboptimalities as random noise. In this paper we study non-optimal behaviors in non-expert demonstrations and show that they are systematic, forming what we call demonstration sidetracks. Using a public space study with 40 participants performing a long-horizon robot task, we recreated the setup in simulation and annotated all demonstrations. We identify four types of sidetracks (Exploration, Mistake, Alignment, Pause) and one control pattern (one-dimension control). Sidetracks appear frequently across participants, and their temporal and spatial distribution is tied to task context. We also find that users' control patterns depend on the control interface. These insights point to the need for better models of suboptimal demonstrations to improve LfD algorithms and bridge the gap between lab training and real-world deployment. All demonstrations, infrastructure, and annotations are available at this https URL.", 'abstract_zh': '基于演示学习（LfD）是机器人获取新技能的一种流行方法，但大多数LfD方法在面对人类演示中的缺陷时效果不佳。以往研究通常将这些非最优行为视为随机噪声。本文研究非专家演示中的非最优行为，并证明这些行为是系统性的，我们称之为演示旁路。通过一项包含40名参与者在公共空间执行长期机器人任务的研究，我们在仿真中重现了实验设置并标注了所有演示。我们识别出四种类型的旁路（探索、错误、对齐、暂停）和一个控制模式（一维控制）。旁路在参与者之间频繁出现，其时间分布和空间分布与任务上下文紧密相关。我们还发现用户控制模式依赖于控制界面。这些洞察表明，为了改进LfD算法并缩小实验室培训与实际部署之间的差距，需要更好的非最优演示模型。所有演示、基础设施和标注均已公開。', 'title_zh': '非系统的非最优性类别化：演示中的示范侧轨'}
{'arxiv_id': 'arXiv:2506.11556', 'title': 'Scheduling Agile Earth Observation Satellites with Onboard Processing and Real-Time Monitoring', 'authors': 'Antonio M. Mercado-Martínez, Beatriz Soret, Antonio Jurado-Navas', 'link': 'https://arxiv.org/abs/2506.11556', 'abstract': 'The emergence of Agile Earth Observation Satellites (AEOSs) has marked a significant turning point in the field of Earth Observation (EO), offering enhanced flexibility in data acquisition. Concurrently, advancements in onboard satellite computing and communication technologies have greatly enhanced data compression efficiency, reducing network latency and congestion while supporting near real-time information delivery. In this paper, we address the Agile Earth Observation Satellite Scheduling Problem (AEOSSP), which involves determining the optimal sequence of target observations to maximize overall observation profit. Our approach integrates onboard data processing for real-time remote monitoring into the multi-satellite optimization problem. To this end, we define a set of priority indicators and develop a constructive heuristic method, further enhanced with a Local Search (LS) strategy. The results show that the proposed algorithm provides high-quality information by increasing the resolution of the collected frames by up to 10% on average, while reducing the variance in the monitoring frequency of the targets within the instance by up to 83%, ensuring more up-to-date information across the entire set compared to a First-In First-Out (FIFO) method.', 'abstract_zh': '敏捷地球观测卫星（AEOSs）的出现标志着地球观测（EO）领域的一个重要转折点，提供了数据采集的增强灵活性。同时，机载卫星计算和通信技术的进步极大提升了数据压缩效率，减少了网络延迟和拥塞，支持近乎实时的信息传输。在本文中，我们探讨了敏捷地球观测卫星调度问题（AEOSSP），该问题涉及确定目标观测的最佳顺序以最大化整体观测收益。我们结合了机载数据处理以实现实时远程监控来解决多卫星优化问题。为此，我们定义了一组优先级指标，并开发了一种构造性启发式方法，进一步结合了局部搜索（LS）策略。结果显示，所提出算法通过平均将收集帧的分辨率提高10%，并将目标监控频率的变化减少83%，提供了高质量信息，相比先进先出（FIFO）方法，整个集合的信息更加及时。', 'title_zh': '基于机载处理和实时监测的敏捷地球观测卫星调度'}
{'arxiv_id': 'arXiv:2506.11419', 'title': 'FocalAD: Local Motion Planning for End-to-End Autonomous Driving', 'authors': 'Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song', 'link': 'https://arxiv.org/abs/2506.11419', 'abstract': 'In end-to-end autonomous driving,the motion prediction plays a pivotal role in ego-vehicle planning. However, existing methods often rely on globally aggregated motion features, ignoring the fact that planning decisions are primarily influenced by a small number of locally interacting agents. Failing to attend to these critical local interactions can obscure potential risks and undermine planning reliability. In this work, we propose FocalAD, a novel end-to-end autonomous driving framework that focuses on critical local neighbors and refines planning by enhancing local motion representations. Specifically, FocalAD comprises two core modules: the Ego-Local-Agents Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a graph-based ego-centric interaction representation that captures motion dynamics with local neighbors to enhance both ego planning and agent motion queries. FLA Loss increases the weights of decision-critical neighboring agents, guiding the model to prioritize those more relevant to planning. Extensive experiments show that FocalAD outperforms existing state-of-the-art methods on the open-loop nuScenes datasets and closed-loop Bench2Drive benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD achieves even greater improvements, reducing the average colilision rate by 41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.', 'abstract_zh': '在端到端自动驾驶中，运动预测在ego车辆规划中起着关键作用。然而，现有方法往往依赖于全局聚合的运动特征，忽视了规划决策主要由少数本地交互代理所驱动的事实。未能关注这些关键的本地交互可能会掩盖潜在风险并削弱规划可靠性。在本工作中，我们提出了FocalAD，这是一种新颖的端到端自动驾驶框架，专注于关键的本地邻居并通过增强局部运动表示来优化规划。具体而言，FocalAD 包含两个核心模块：Ego-Local-Agents Interactor (ELAI) 和 Focal-Local-Agents Loss (FLA Loss)。ELAI 进行基于图的以自我为中心的交互表示，利用局部邻居捕捉运动动态，以增强ego规划和代理运动查询。FLA Loss 增加了决策关键邻近代理的权重，引导模型优先考虑那些与规划更相关的代理。广泛的实验表明，FocalAD 在开放环nuScenes数据集和闭环Bench2Drive基准测试上优于现有最先进的方法。值得注意的是，在重点关注鲁棒性的Adv-nuScenes数据集上，FocalAD 甚至取得了更大的改进，将平均碰撞率降低了41.9%，相比DiffusionDrive降低了15.6%。', 'title_zh': 'FocalAD: 局部运动规划用于端到端自动驾驶'}
{'arxiv_id': 'arXiv:2506.11986', 'title': 'Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task', 'authors': 'Wuzhenghong Wen, Su Pan, yuwei Sun', 'link': 'https://arxiv.org/abs/2506.11986', 'abstract': 'Schema linking is a critical step in Text-to-SQL task, aiming to accurately predict the table names and column names required for the SQL query based on the given question. However, current fine-tuning approaches for schema linking models employ a rote-learning paradigm, excessively optimizing for ground truth schema linking outcomes while compromising reasoning ability. This limitation arises because of the difficulty in acquiring a high-quality reasoning sample for downstream tasks. To address this, we propose Schema-R1, a reasoning schema linking model trained using reinforcement learning. Specifically, Schema-R1 consists of three key steps: constructing small batches of high-quality reasoning samples, supervised fine-tuning for cold-start initialization, and rule-based reinforcement learning training. The final results demonstrate that our method effectively enhances the reasoning ability of the schema linking model, achieving a 10\\% improvement in filter accuracy compared to the existing method. Our code is available at this https URL.', 'abstract_zh': 'Schema-R1：一种基于强化学习的推理-schema链接模型', 'title_zh': 'Schema-R1: 一种用于Text-to-SQL任务模式链接的推理训练方法'}
{'arxiv_id': 'arXiv:2506.11756', 'title': 'Causal Effect Identification in Heterogeneous Environments from Higher-Order Moments', 'authors': 'Yaroslav Kivva, Sina Akbari, Saber Salehkaleybar, Negar Kiyavash', 'link': 'https://arxiv.org/abs/2506.11756', 'abstract': 'We investigate the estimation of the causal effect of a treatment variable on an outcome in the presence of a latent confounder. We first show that the causal effect is identifiable under certain conditions when data is available from multiple environments, provided that the target causal effect remains invariant across these environments. Secondly, we propose a moment-based algorithm for estimating the causal effect as long as only a single parameter of the data-generating mechanism varies across environments -- whether it be the exogenous noise distribution or the causal relationship between two variables. Conversely, we prove that identifiability is lost if both exogenous noise distributions of both the latent and treatment variables vary across environments. Finally, we propose a procedure to identify which parameter of the data-generating mechanism has varied across the environments and evaluate the performance of our proposed methods through experiments on synthetic data.', 'abstract_zh': '我们在多个环境中探讨了在存在潜在混杂变量的情况下治疗变量对结果的因果效应估计问题。首先，在数据来自多个环境且目标因果效应在这些环境中保持不变的条件下，我们证明因果效应是可以识别的。其次，只要数据生成机制中有一个参数在不同环境中发生变化——无论是外生噪声分布的变化还是两个变量之间的因果关系的变化——我们提出了一种基于矩的算法来估计因果效应。相反，我们证明了如果两个变量的外生噪声分布都随环境变化，则因果效应将无法识别。最后，我们提出了一种方法来识别数据生成机制中哪个参数在不同环境中发生变化，并通过合成数据的实验评估我们提出方法的性能。', 'title_zh': '异质环境中基于高阶矩的因果效应识别'}
{'arxiv_id': 'arXiv:2506.11721', 'title': 'Relational GNNs Cannot Learn $C_2$ Features for Planning', 'authors': 'Dillon Z. Chen', 'link': 'https://arxiv.org/abs/2506.11721', 'abstract': 'Relational Graph Neural Networks (R-GNNs) are a GNN-based approach for learning value functions that can generalise to unseen problems from a given planning domain. R-GNNs were theoretically motivated by the well known connection between the expressive power of GNNs and $C_2$, first-order logic with two variables and counting. In the context of planning, $C_2$ features refer to the set of formulae in $C_2$ with relations defined by the unary and binary predicates of a planning domain. Some planning domains exhibit optimal value functions that can be decomposed as arithmetic expressions of $C_2$ features. We show that, contrary to empirical results, R-GNNs cannot learn value functions defined by $C_2$ features. We also identify prior GNN architectures for planning that may better learn value functions defined by $C_2$ features.', 'abstract_zh': '基于关系的图神经网络（R-GNNs）是一种基于图神经网络的方法，用于从给定的规划域中学习可以泛化到未见过的问题的价值函数。R-GNNs的理论动机源于图神经网络的表达能力与具有两个变量和计数的一阶逻辑$C_2$之间的已知联系。在规划的背景下，$C_2$特征是指由规划域的一元和二元谓词定义的$C_2$中的公式集。一些规划域中的最优价值函数可以分解为$C_2$特征的算术表达式。我们展示了与 empirically 结果相反，R-GNNs 无法学习由 $C_2$ 特征定义的价值函数。我们还识别出在规划中可能更好地学习由 $C_2$ 特征定义的价值函数的先前图神经网络架构。', 'title_zh': '关系GNN无法学习$C_2$特征进行规划'}
{'arxiv_id': 'arXiv:2506.11487', 'title': 'Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models', 'authors': 'Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, Fan Yang', 'link': 'https://arxiv.org/abs/2506.11487', 'abstract': 'Recent advancements, such as DeepSeek-Prover-V2-671B and Kimina-Prover-Preview-72B, demonstrate a prevailing trend in leveraging reinforcement learning (RL)-based large-scale training for automated theorem proving. Surprisingly, we discover that even without any training, careful neuro-symbolic coordination of existing off-the-shelf reasoning models and tactic step provers can achieve comparable performance. This paper introduces \\textbf{DSP+}, an improved version of the Draft, Sketch, and Prove framework, featuring a \\emph{fine-grained and integrated} neuro-symbolic enhancement for each phase: (1) In the draft phase, we prompt reasoning models to generate concise natural-language subgoals to benefit the sketch phase, removing thinking tokens and references to human-written proofs; (2) In the sketch phase, subgoals are autoformalized with hypotheses to benefit the proving phase, and sketch lines containing syntactic errors are masked according to predefined rules; (3) In the proving phase, we tightly integrate symbolic search methods like Aesop with step provers to establish proofs for the sketch subgoals. Experimental results show that, without any additional model training or fine-tuning, DSP+ solves 80.7\\%, 32.8\\%, and 24 out of 644 problems from miniF2F, ProofNet, and PutnamBench, respectively, while requiring fewer budgets compared to state-of-the-arts. DSP+ proves \\texttt{imo\\_2019\\_p1}, an IMO problem in miniF2F that is not solved by any prior work. Additionally, DSP+ generates proof patterns comprehensible by human experts, facilitating the identification of formalization errors; For example, eight wrongly formalized statements in miniF2F are discovered. Our results highlight the potential of classical reasoning patterns besides the RL-based training. All components will be open-sourced.', 'abstract_zh': '近年来，如DeepSeek-Prover-V2-671B和Kimina-Prover-Preview-72B等的最新进展表明，通过基于强化学习（RL）的大规模训练自动定理证明的趋势主导地位。令人惊讶的是，我们发现即使没有任何训练，精心设计的神经符号协调也能实现与现有方法相当的性能。本文介绍了DSP+，这是一个改进版本的Draft、Sketch和Prove框架，每个阶段都具有精细整合的神经符号增强：（1）在Draft阶段，我们提示推理模型生成简洁的自然语言子目标以利于Sketch阶段，并移除思考标记和对人工证明的引用；（2）在Sketch阶段，子目标自形式化并添加假设以利于证明阶段，并根据预定义规则屏蔽包含语法错误的Sketch线；（3）在Proving阶段，我们将符号搜索方法（如Aesop）与步骤证明器紧密集成，以建立Sketch子目标的证明。实验结果表明，DSP+在无需额外模型训练或微调的情况下，分别解决了miniF2F、ProofNet和PutnamBench中的644个问题中的80.7%、32.8%和24个问题，同时相比最先进的方法所需预算更少。DSP+证明了miniF2F中的IMO问题imo_2019_p1，这是所有先前工作都无法解决的问题。此外，DSP+生成了可由人类专家理解的证明模式，有助于识别形式化错误；例如，发现了miniF2F中的八个误形式化陈述。我们的结果突显了除了基于RL的训练之外，经典推理模式的潜力。所有组件将开源。', 'title_zh': '在推理模型时代 revitalizing DSP 以实现高级定理证明'}
{'arxiv_id': 'arXiv:2506.11469', 'title': 'Structure-Aware Automatic Channel Pruning by Searching with Graph Embedding', 'authors': 'Zifan Liu, Yuan Cao, Yanwei Yu, Heng Qi, Jie Gui', 'link': 'https://arxiv.org/abs/2506.11469', 'abstract': 'Channel pruning is a powerful technique to reduce the computational overhead of deep neural networks, enabling efficient deployment on resource-constrained devices. However, existing pruning methods often rely on local heuristics or weight-based criteria that fail to capture global structural dependencies within the network, leading to suboptimal pruning decisions and degraded model performance. To address these limitations, we propose a novel structure-aware automatic channel pruning (SACP) framework that utilizes graph convolutional networks (GCNs) to model the network topology and learn the global importance of each channel. By encoding structural relationships within the network, our approach implements topology-aware pruning and this pruning is fully automated, reducing the need for human intervention. We restrict the pruning rate combinations to a specific space, where the number of combinations can be dynamically adjusted, and use a search-based approach to determine the optimal pruning rate combinations. Extensive experiments on benchmark datasets (CIFAR-10, ImageNet) with various models (ResNet, VGG16) demonstrate that SACP outperforms state-of-the-art pruning methods on compression efficiency and competitive on accuracy retention.', 'abstract_zh': '基于图形卷积网络的结构感知自动通道剪枝框架', 'title_zh': '基于图嵌入搜索的结构感知自动通道剪枝'}
{'arxiv_id': 'arXiv:2506.11445', 'title': 'Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention', 'authors': 'Xuan Duy Ta, Bang Giang Le, Thanh Ha Le, Viet Cuong Ta', 'link': 'https://arxiv.org/abs/2506.11445', 'abstract': "In mixed-traffic environments, autonomous vehicles must adapt to human-controlled vehicles and other unusual driving situations. This setting can be framed as a multi-agent reinforcement learning (MARL) environment with full cooperative reward among the autonomous vehicles. While methods such as Multi-agent Proximal Policy Optimization can be effective in training MARL tasks, they often fail to resolve local conflict between agents and are unable to generalize to stochastic events. In this paper, we propose a Local State Attention module to assist the input state representation. By relying on the self-attention operator, the module is expected to compress the essential information of nearby agents to resolve the conflict in traffic situations. Utilizing a simulated highway merging scenario with the priority vehicle as the unexpected event, our approach is able to prioritize other vehicles' information to manage the merging process. The results demonstrate significant improvements in merging efficiency compared to popular baselines, especially in high-density traffic settings.", 'abstract_zh': '在混合交通环境中，自动驾驶车辆必须适应由人类控制的车辆和其他异常驾驶情况。这一设置可以被视为一种多智能体强化学习（MARL）环境，其中自动驾驶车辆之间具有完全合作的奖励方式。虽然诸如Multi-agent Proximal Policy Optimization等方法在训练MARL任务时可能有效，但它们通常无法解决智能体之间的局部冲突，也无法泛化到随机事件。在本文中，我们提出了一种局部状态注意力模块来辅助输入状态表示。通过依赖自注意力操作符，该模块期望压缩附近智能体的关键信息以在交通情况下解决冲突。利用具有优先车辆的模拟高速公路变道场景作为意外事件，我们的方法能够优先处理其他车辆的信息，以管理变道过程。结果表明，与流行的基准方法相比，在高密度交通环境中，我们的方法在合并效率上取得了显著提升。', 'title_zh': '基于局部状态注意力的多自主车辆控制中解决高速公路冲突问题'}
{'arxiv_id': 'arXiv:2506.11331', 'title': 'MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification', 'authors': 'Jihoon Yun, Chengzhang Li, Dhrubojyoti Roy, Anish Arora', 'link': 'https://arxiv.org/abs/2506.11331', 'abstract': 'Unsupervised Domain Adaptation (UDA) is essential for adapting machine learning models to new, unlabeled environments where data distribution shifts can degrade performance. Existing UDA algorithms are designed for single-label tasks and rely on significant computational resources, limiting their use in multi-label scenarios and in resource-constrained IoT devices. Overcoming these limitations is particularly challenging in contexts such as urban sound classification, where overlapping sounds and varying acoustics require robust, adaptive multi-label capabilities on low-power, on-device systems. To address these limitations, we introduce Mote-scale Unsupervised Domain Adaptation for Sounds (MUDAS), a UDA framework developed for multi-label sound classification in resource-constrained IoT settings. MUDAS efficiently adapts models by selectively retraining the classifier in situ using high-confidence data, minimizing computational and memory requirements to suit on-device deployment. Additionally, MUDAS incorporates class-specific adaptive thresholds to generate reliable pseudo-labels and applies diversity regularization to improve multi-label classification accuracy. In evaluations on the SONYC Urban Sound Tagging (SONYC-UST) dataset recorded at various New York City locations, MUDAS demonstrates notable improvements in classification accuracy over existing UDA algorithms, achieving good performance in a resource-constrained IoT setting.', 'abstract_zh': '多标签声学领域自适应：面向资源受限物联网设备的小尺度无监督领域自适应（MUDAS）', 'title_zh': 'MUDAS：多标签声学分类中的细粒度无监督域适应'}
{'arxiv_id': 'arXiv:2506.11023', 'title': 'OntoGSN: An Ontology for Dynamic Management of Assurance Cases', 'authors': 'Tomas Bueno Momcilovic, Barbara Gallina, Ingmar Kessler, Dian Balta', 'link': 'https://arxiv.org/abs/2506.11023', 'abstract': "Assurance cases (ACs) are a common artifact for building and maintaining confidence in system properties such as safety or robustness. Constructing an AC can be challenging, although existing tools provide support in static, document-centric applications and methods for dynamic contexts (e.g., autonomous driving) are emerging. Unfortunately, managing ACs remains a challenge, since maintaining the embedded knowledge in the face of changes requires substantial effort, in the process deterring developers - or worse, producing poorly managed cases that instill false confidence. To address this, we present OntoGSN: an ontology and supporting middleware for managing ACs in the Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge representation and a queryable graph that can be automatically populated, evaluated, and updated. Our contributions include: a 1:1 formalization of the GSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology and parser for integration with a widely used AC tool; a repository and documentation of design decisions for OntoGSN maintenance; a SPARQL query library with automation patterns; and a prototypical interface. The ontology strictly adheres to the standard's text and has been evaluated according to FAIR principles, the OOPS framework, competency questions, and community feedback. The development of other middleware elements is guided by the community needs and subject to ongoing evaluations. To demonstrate the utility of our contributions, we illustrate dynamic AC management in an example involving assurance of adversarial robustness in large language models.", 'abstract_zh': '基于目标结构表示的保证案例管理ontology和middleware：OntoGSN及其在大语言模型对抗鲁棒性保证中的应用', 'title_zh': 'OntoGSN: 一种保障案例动态管理本体'}
{'arxiv_id': 'arXiv:2506.11012', 'title': 'A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects', 'authors': 'Guanglin Niu, Bo Li, Yangguang Lin', 'link': 'https://arxiv.org/abs/2506.11012', 'abstract': 'Knowledge graphs (KGs) have emerged as a powerful paradigm for structuring and leveraging diverse real-world knowledge, which serve as a fundamental technology for enabling cognitive intelligence systems with advanced understanding and reasoning capabilities. Knowledge graph reasoning (KGR) aims to infer new knowledge based on existing facts in KGs, playing a crucial role in applications such as public security intelligence, intelligent healthcare, and financial risk assessment. From a task-centric perspective, existing KGR approaches can be broadly classified into static single-step KGR, static multi-step KGR, dynamic KGR, multi-modal KGR, few-shot KGR, and inductive KGR. While existing surveys have covered these six types of KGR tasks, a comprehensive review that systematically summarizes all KGR tasks particularly including downstream applications and more challenging reasoning paradigms remains lacking. In contrast to previous works, this survey provides a more comprehensive perspective on the research of KGR by categorizing approaches based on primary reasoning tasks, downstream application tasks, and potential challenging reasoning tasks. Besides, we explore advanced techniques, such as large language models (LLMs), and their impact on KGR. This work aims to highlight key research trends and outline promising future directions in the field of KGR.', 'abstract_zh': '知识图谱推理：基于任务的综合研究与未来方向', 'title_zh': '面向任务的知识图谱推理综述：现状、应用与前景'}
{'arxiv_id': 'arXiv:2506.12015', 'title': 'EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction', 'authors': 'Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang', 'link': 'https://arxiv.org/abs/2506.12015', 'abstract': 'Open-source foundation models have seen rapid adoption and development, enabling powerful general-purpose capabilities across diverse domains. However, fine-tuning large foundation models for domain-specific or personalized tasks remains prohibitively expensive for most users due to the significant memory overhead beyond that of inference. We introduce EMLoC, an Emulator-based Memory-efficient fine-tuning framework with LoRA Correction, which enables model fine-tuning within the same memory budget required for inference. EMLoC constructs a task-specific light-weight emulator using activation-aware singular value decomposition (SVD) on a small downstream calibration set. Fine-tuning then is performed on this lightweight emulator via LoRA. To tackle the misalignment between the original model and the compressed emulator, we propose a novel compensation algorithm to correct the fine-tuned LoRA module, which thus can be merged into the original model for inference. EMLoC supports flexible compression ratios and standard training pipelines, making it adaptable to a wide range of applications. Extensive experiments demonstrate that EMLoC outperforms other baselines across multiple datasets and modalities. Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on a single 24GB consumer GPU-bringing efficient and practical model adaptation to individual users.', 'abstract_zh': '基于插值器的LoRA校正轻量级细调框架EMLoC：在相同内存预算下实现高效自定义模型细调', 'title_zh': 'EMLoC：基于模拟器的内存高效微调与LoRA修正'}
{'arxiv_id': 'arXiv:2506.12003', 'title': 'Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?', 'authors': 'Ramesh Raskar, Pradyumna Chari, Jared James Grogan, Mahesh Lambe, Robert Lincourt, Raghu Bala, Abhishek Singh, Ayush Chopra, Rajesh Ranjan, Shailja Gupta, Dimitris Stripelis, Maria Gorskikh, Sichao Wang', 'link': 'https://arxiv.org/abs/2506.12003', 'abstract': 'The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built registry architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized registries for critical agents and federated meshes for specialized use cases.', 'abstract_zh': '基于AI代理的新兴互联网挑战现有为人类反应性交互设计的网络基础设施。', 'title_zh': '升级还是切换：我们需要一个新的注册架构来支持人工智能代理的互联网吗？'}
{'arxiv_id': 'arXiv:2506.11945', 'title': 'Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?', 'authors': 'Noemi Dreksler, Lucius Caviola, David Chalmers, Carter Allen, Alex Rand, Joshua Lewis, Philip Waggoner, Kate Mays, Jeff Sebo', 'link': 'https://arxiv.org/abs/2506.11945', 'abstract': 'We surveyed 582 AI researchers who have published in leading AI venues and 838 nationally representative US participants about their views on the potential development of AI systems with subjective experience and how such systems should be treated and governed. When asked to estimate the chances that such systems will exist on specific dates, the median responses were 1% (AI researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by 2100, respectively. The median member of the public thought there was a higher chance that AI systems with subjective experience would never exist (25%) than the median AI researcher did (10%). Both groups perceived a need for multidisciplinary expertise to assess AI subjective experience. Although support for welfare protections for such AI systems exceeded opposition, it remained far lower than support for protections for animals or the environment. Attitudes toward moral and governance issues were divided in both groups, especially regarding whether such systems should be created and what rights or protections they should receive. Yet a majority of respondents in both groups agreed that safeguards against the potential risks from AI systems with subjective experience should be implemented by AI developers now, and if created, AI systems with subjective experience should treat others well, behave ethically, and be held accountable. Overall, these results suggest that both AI researchers and the public regard the emergence of AI systems with subjective experience as a possibility this century, though substantial uncertainty and disagreement remain about the timeline and appropriate response.', 'abstract_zh': '我们对582位发表在顶级AI会议上的AI研究人员和838位具有全国代表性的美国公众进行了调查，了解他们对具有主观体验的AI系统潜在发展的看法以及这些系统应如何被处理和治理。当被要求估算这些系统在特定日期存在的可能性时，中位数回答显示，2024年研究人员的预测为1%，公众的预测为5%；2034年分别为25%和30%；2100年分别为70%和60%。公众的中位数成员比研究人员认为具有主观体验的AI系统永远不会存在的概率更高（25%比10%）。两组都认识到需要跨学科专业知识来评估AI的主观体验。尽管人们对为这些AI系统提供福利保护的支持超过了反对，但这种支持远远低于对动物或环境保护的支持。关于道德和治理问题的态度在两组中存在分歧，尤其是在是否应该创建这些系统以及它们应获得哪些权利或保护方面意见尤其分歧。然而，两组的大多数受访者都同意应该由AI开发者现在实施针对具有主观体验的AI系统的潜在风险的保护措施，并且如果创建了这些系统，它们应该对待他人友好、行为得当并承担责任。总体而言，这些结果表明，虽然AI研究人员和公众都认同这一世纪可能会出现具有主观体验的AI系统，但关于时间表和适当响应仍然存在显著的不确定性与分歧。', 'title_zh': 'AI系统中的主观体验：研究人员与公众的看法如何？'}
{'arxiv_id': 'arXiv:2506.11939', 'title': "Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches", 'authors': 'Ranindya Paramitha, Yuan Feng, Fabio Massacci', 'link': 'https://arxiv.org/abs/2506.11939', 'abstract': "Vulnerability datasets used for ML testing implicitly contain retrospective information. When tested on the field, one can only use the labels available at the time of training and testing (e.g. seen and assumed negatives). As vulnerabilities are discovered across calendar time, labels change and past performance is not necessarily aligned with future performance. Past works only considered the slices of the whole history (e.g. DiverseVUl) or individual differences between releases (e.g. Jimenez et al. ESEC/FSE 2019). Such approaches are either too optimistic in training (e.g. the whole history) or too conservative (e.g. consecutive releases). We propose a method to restructure a dataset into a series of datasets in which both training and testing labels change to account for the knowledge available at the time. If the model is actually learning, it should improve its performance over time as more data becomes available and data becomes more stable, an effect that can be checked with the Mann-Kendall test. We validate our methodology for vulnerability detection with 4 time-based datasets (3 projects from BigVul dataset + Vuldeepecker's NVD) and 5 ML models (Code2Vec, CodeBERT, LineVul, ReGVD, and Vuldeepecker). In contrast to the intuitive expectation (more retrospective information, better performance), the trend results show that performance changes inconsistently across the years, showing that most models are not learning.", 'abstract_zh': '基于时间的漏洞数据集在机器学习测试中的复现性问题及改进方法', 'title_zh': '今天的猫是明天的狗：考虑ML漏洞检测方法中基于时间的标签变化'}
{'arxiv_id': 'arXiv:2506.11925', 'title': 'Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference', 'authors': 'M. Manzour, Catherine M. Elias, Omar M. Shehata, R. Izquierdo, M. A. Sotelo', 'link': 'https://arxiv.org/abs/2506.11925', 'abstract': "Research on lane change prediction has gained a lot of momentum in the last couple of years. However, most research is confined to simulation or results obtained from datasets, leaving a gap between algorithmic advances and on-road deployment. This work closes that gap by demonstrating, on real hardware, a lane-change prediction system based on Knowledge Graph Embeddings (KGEs) and Bayesian inference. Moreover, the ego-vehicle employs a longitudinal braking action to ensure the safety of both itself and the surrounding vehicles. Our architecture consists of two modules: (i) a perception module that senses the environment, derives input numerical features, and converts them into linguistic categories; and communicates them to the prediction module; (ii) a pretrained prediction module that executes a KGE and Bayesian inference model to anticipate the target vehicle's maneuver and transforms the prediction into longitudinal braking action. Real-world hardware experimental validation demonstrates that our prediction system anticipates the target vehicle's lane change three to four seconds in advance, providing the ego vehicle sufficient time to react and allowing the target vehicle to make the lane change safely.", 'abstract_zh': '基于知识图嵌入和贝叶斯推理的实时变道预测系统研究', 'title_zh': '基于知识图嵌入和贝叶斯推断的车道变更预测架构的实际部署'}
{'arxiv_id': 'arXiv:2506.11912', 'title': 'Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations', 'authors': 'Miguel Suau', 'link': 'https://arxiv.org/abs/2506.11912', 'abstract': "Recent work has shown that reinforcement learning agents can develop policies that exploit spurious correlations between rewards and observations. This phenomenon, known as policy confounding, arises because the agent's policy influences both past and future observation variables, creating a feedback loop that can hinder the agent's ability to generalize beyond its usual trajectories. In this paper, we show that the advantage function, commonly used in policy gradient methods, not only reduces the variance of gradient estimates but also mitigates the effects of policy confounding. By adjusting action values relative to the state representation, the advantage function downweights state-action pairs that are more likely under the current policy, breaking spurious correlations and encouraging the agent to focus on causal factors. We provide both analytical and empirical evidence demonstrating that training with the advantage function leads to improved out-of-trajectory performance.", 'abstract_zh': 'Recent工作表明强化学习代理可以发展出利用奖励与观测之间虚假相关性的策略。这一现象被称为策略偏差，因为它会导致代理的策略影响过去的和未来的观测变量，从而形成一个反馈循环，这可能阻碍代理泛化到其常规轨迹之外的能力。在本文中，我们展示了优势函数在策略梯度方法中广泛使用不仅减少了梯度估计的方差，还减轻了策略偏差的影响。通过相对状态表示调整动作值，优势函数降低了当前策略下更可能的状态-动作对的重要性，打破了虚假相关性，并促使代理关注因果因素。我们提供了分析和 empirical证据证明，使用优势函数进行训练可以改善代理的离轨性能。', 'title_zh': '打破习惯：优势函数在学习因果状态表示中的作用'}
{'arxiv_id': 'arXiv:2506.11908', 'title': 'Spectra-to-Structure and Structure-to-Spectra Inference Across the Periodic Table', 'authors': 'Yufeng Wang, Peiyao Wang, Lu Ma, Yuewei Lin, Qun Liu, Haibin Ling', 'link': 'https://arxiv.org/abs/2506.11908', 'abstract': 'X-ray Absorption Spectroscopy (XAS) is a powerful technique for probing local atomic environments, yet its interpretation remains limited by the need for expert-driven analysis, computationally expensive simulations, and element-specific heuristics. Recent advances in machine learning have shown promise for accelerating XAS interpretation, but many existing models are narrowly focused on specific elements, edge types, or spectral regimes. In this work, we present XAStruct, a learning framework capable of both predicting XAS spectra from crystal structures and inferring local structural descriptors from XAS input. XAStruct is trained on a large-scale dataset spanning over 70 elements across the periodic table, enabling generalization to a wide variety of chemistries and bonding environments. The model includes the first machine learning approach for predicting neighbor atom types directly from XAS spectra, as well as a unified regression model for mean nearest-neighbor distance that requires no element-specific tuning. While we explored integrating the two pipelines into a single end-to-end model, empirical results showed performance degradation. As a result, the two tasks were trained independently to ensure optimal accuracy and task-specific performance. By combining deep neural networks for complex structure-property mappings with efficient baseline models for simpler tasks, XAStruct offers a scalable and extensible solution for data-driven XAS analysis and local structure inference. The source code will be released upon paper acceptance.', 'abstract_zh': 'XAStruct：一种用于预测XAS光谱和推断局部结构描述符的机器学习框架', 'title_zh': '周期表 Across 元素间的谱图到结构和结构到谱图推理'}
{'arxiv_id': 'arXiv:2506.11901', 'title': 'A Neural Rejection System Against Universal Adversarial Perturbations in Radio Signal Classification', 'authors': 'Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Fabio Roli', 'link': 'https://arxiv.org/abs/2506.11901', 'abstract': 'Advantages of deep learning over traditional methods have been demonstrated for radio signal classification in the recent years. However, various researchers have discovered that even a small but intentional feature perturbation known as adversarial examples can significantly deteriorate the performance of the deep learning based radio signal classification. Among various kinds of adversarial examples, universal adversarial perturbation has gained considerable attention due to its feature of being data independent, hence as a practical strategy to fool the radio signal classification with a high success rate. Therefore, in this paper, we investigate a defense system called neural rejection system to propose against universal adversarial perturbations, and evaluate its performance by generating white-box universal adversarial perturbations. We show that the proposed neural rejection system is able to defend universal adversarial perturbations with significantly higher accuracy than the undefended deep neural network.', 'abstract_zh': '近年来，深度学习在无线信号分类上的优势已经得到证明，然而各种研究表明，即使是很小但故意的特征扰动，即对抗样本，也能显著降低基于深度学习的无线信号分类性能。在各种类型的对抗样本中，由于其数据独立性，通用对抗扰动受到了广泛关注，因此作为一种高成功率的欺骗无线信号分类的实际策略。因此，在本文中，我们研究了一种名为神经拒绝系统的防御系统以应对通用对抗扰动，并通过生成白盒通用对抗扰动来评估其性能。我们展示了所提出的神经拒绝系统在准确性方面能显著提高对通用对抗扰动的防御能力，优于未受保护的深度神经网络。', 'title_zh': '针对无线电信号分类中普遍对抗扰动的神经拒识系统'}
{'arxiv_id': 'arXiv:2506.11892', 'title': 'Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices', 'authors': 'Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli', 'link': 'https://arxiv.org/abs/2506.11892', 'abstract': 'Due to great success of transformers in many applications such as natural language processing and computer vision, transformers have been successfully applied in automatic modulation classification. We have shown that transformer-based radio signal classification is vulnerable to imperceptible and carefully crafted attacks called adversarial examples. Therefore, we propose a defense system against adversarial examples in transformer-based modulation classifications. Considering the need for computationally efficient architecture particularly for Internet of Things (IoT)-based applications or operation of devices in environment where power supply is limited, we propose a compact transformer for modulation classification. The advantages of robust training such as adversarial training in transformers may not be attainable in compact transformers. By demonstrating this, we propose a novel compact transformer that can enhance robustness in the presence of adversarial attacks. The new method is aimed at transferring the adversarial attention map from the robustly trained large transformer to a compact transformer. The proposed method outperforms the state-of-the-art techniques for the considered white-box scenarios including fast gradient method and projected gradient descent attacks. We have provided reasoning of the underlying working mechanisms and investigated the transferability of the adversarial examples between different architectures. The proposed method has the potential to protect the transformer from the transferability of adversarial examples.', 'abstract_zh': '基于变压器的自动调制分类中对抗样本的防御系统：一种健壮的紧凑变压器方法', 'title_zh': '基于注意力机制的 adversarial 稳健蒸馏在低功耗 IoT 设备的射频信号分类中'}
{'arxiv_id': 'arXiv:2506.11890', 'title': 'Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training', 'authors': 'Judson Leroy Dean Haynes IV', 'link': 'https://arxiv.org/abs/2506.11890', 'abstract': 'Virtual Reality simulators offer a powerful tool for teacher training, yet the integration of AI-powered student avatars presents a critical challenge: determining the optimal level of avatar realism for effective pedagogy. This literature review examines the evolution of avatar realism in VR teacher training, synthesizes its theoretical implications, and proposes a new pedagogical framework to guide future design. Through a systematic review, this paper traces the progression from human-controlled avatars to generative AI prototypes. Applying learning theories like Cognitive Load Theory, we argue that hyper-realism is not always optimal, as high-fidelity avatars can impose excessive extraneous cognitive load on novices, a stance supported by recent empirical findings. A significant gap exists between the technological drive for photorealism and the pedagogical need for scaffolded learning. To address this gap, we propose Graduated Realism, a framework advocating for starting trainees with lower-fidelity avatars and progressively increasing behavioral complexity as skills develop. To make this computationally feasible, we outline a novel single-call architecture, Crazy Slots, which uses a probabilistic engine and a Retrieval-Augmented Generation database to generate authentic, real-time responses without the latency and cost of multi-step reasoning models. This review provides evidence-based principles for designing the next generation of AI simulators, arguing that a pedagogically grounded approach to realism is essential for creating scalable and effective teacher education tools.', 'abstract_zh': '虚拟现实模拟器为教师培训提供了强大的工具，然而，集成人工智能驱动的学生 avatar 呈现了一个关键挑战：确定有效的教学所需的最优avatar逼真度水平。本文综述探讨了虚拟现实教师培训中 avatar 逼真度的发展历程，综合其理论含义，并提出一个新的教学框架以指导未来的设计。通过系统综述，本文追溯了从人工控制 avatar 到生成式 AI 原型的演变过程。应用认知负荷理论，我们argue 超高的逼真度不总是最优的，高度保真的 avatar 可能会给初学者带来过载的认知负荷，这一观点得到了最近实证研究的支持。技术驱动力追求照片级逼真与教学需求的支架式学习之间存在显著差距。为解决这一差距，我们提出了分阶段逼真度框架，建议从较低保真度的 avatar 开始培训，并随着技能的发展逐步增加行为复杂度。为了使这一过程在计算上可行，我们提出了一个新颖的一次性架构 Crazy Slots，该架构使用概率引擎和检索增强生成数据库，能够实时生成真实的响应，而不受多步推理模型的延迟和成本影响。本文提供了基于证据的原则，为设计下一代 AI 模拟器提供了指导，并argue 教学导向的逼真度方法对于创建可扩展且有效的教师教育工具是必不可少的。', 'title_zh': '入局：渐进现实主义——虚拟现实教师培训中人工智能驱动 avatar 的教学框架'}
{'arxiv_id': 'arXiv:2506.11882', 'title': 'An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing', 'authors': 'Haochen Sun, Yifan Liu, Ahmed Al-Tahmeesschi, Swarna Chetty, Syed Ali Raza Zaidi, Avishek Nag, Hamed Ahmadi', 'link': 'https://arxiv.org/abs/2506.11882', 'abstract': 'Effective resource management and network slicing are essential to meet the diverse service demands of vehicular networks, including Enhanced Mobile Broadband (eMBB) and Ultra-Reliable and Low-Latency Communications (URLLC). This paper introduces an Explainable Deep Reinforcement Learning (XRL) framework for dynamic network slicing and resource allocation in vehicular networks, built upon a near-real-time RAN intelligent controller. By integrating a feature-based approach that leverages Shapley values and an attention mechanism, we interpret and refine the decisions of our reinforcementlearning agents, addressing key reliability challenges in vehicular communication systems. Simulation results demonstrate that our approach provides clear, real-time insights into the resource allocation process and achieves higher interpretability precision than a pure attention mechanism. Furthermore, the Quality of Service (QoS) satisfaction for URLLC services increased from 78.0% to 80.13%, while that for eMBB services improved from 71.44% to 73.21%.', 'abstract_zh': '有效的资源管理与网络切片对于满足车载网络多样化的服务需求（包括增强型移动宽带eMBB和超可靠低时延通信URLLC）至关重要。本文介绍了一种基于近实时RAN智能控制器的可解释深度强化学习（XRL）框架，用于车载网络中的动态网络切片和资源分配。通过结合特征基于的方法，利用Shapley值和注意力机制，我们解释和细化了强化学习代理的决策，解决了车载通信系统中的关键可靠性挑战。仿真结果显示，与纯注意力机制相比，我们的方法提供了清晰的实时资源分配过程洞察，并提高了解释准确性。此外，对于URLLC服务，服务质量满足度从78.0%提高到80.13%，对于eMBB服务，服务质量满足度从71.44%提高到73.21%。', 'title_zh': '可解释的人工智能框架：面向车辆网络切片的动态资源管理'}
{'arxiv_id': 'arXiv:2506.11877', 'title': 'Robust Molecular Property Prediction via Densifying Scarce Labeled Data', 'authors': 'Jina Kim, Jeffrey Willette, Bruno Andreis, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2506.11877', 'abstract': 'A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial covariate shift, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data, stemming from the onerous and costly nature of experimental validation, further exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel meta-learning-based approach that leverages unlabeled data to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.', 'abstract_zh': '分子预测模型广泛认可的一个局限性在于其依赖于训练数据中的结构，导致对未见化合物的泛化能力差。而在药物发现中，推动研究进展最重要的化合物往往超出训练集，这使得对训练数据的偏见问题尤为突出。这种不匹配引入了显著的协变量偏移，导致标准深度学习模型产生不稳定且不准确的预测。此外，由于实验验证的繁琐和成本高，标注数据稀缺进一步加剧了可靠泛化的难度。为解决这些问题，我们提出了一种基于元学习的新方法，利用未标注数据在分布内（ID）和分布外（OOD）数据之间进行插值，使模型能够元学习超越训练分布的泛化能力。我们在表现出显著协变量偏移的挑战性现实世界数据集上展示了显著的性能提升。', 'title_zh': '通过稀有标记数据增密进行稳健分子属性预测'}
{'arxiv_id': 'arXiv:2506.11869', 'title': 'How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?', 'authors': 'Michela Lapenna, Caterina De Bacco', 'link': 'https://arxiv.org/abs/2506.11869', 'abstract': 'Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.', 'abstract_zh': '图是一种强大的数据结构，适用于表示关系数据，并广泛用于描述复杂的现实世界系统。概率图形模型（PGMs）和图神经网络（GNNs）都可以利用结构化的图数据，但它们的内在工作机制不同。问题在于它们在捕捉网络数据集中的信息方面有何不同？我们通过解决链接预测任务来解决这一目标，并进行了三项主要实验，分别在合成和真实网络上进行：一个是关注PGMs和GNNs如何处理输入特征，另一个两个则探讨它们在特征噪声以及图的异质性增加情况下的鲁棒性。PGMs不一定需要节点特征，而GNNs仅靠网络边无法发挥其作用，并且输入特征的选择至关重要。我们发现，当输入特征低维化或噪声化时，GNNs的表现不及PGMs，这模拟了许多现实场景中节点属性可能是标量或噪声的情形。然后，我们发现当图的异质性增加时，PGMs比GNNs更具有鲁棒性。最后，为了评估性能超越预测任务的情况，我们还比较了这两种框架在计算复杂性和可解释性方面的表现。', 'title_zh': '概率图模型与图神经网络是如何看待网络数据的？'}
{'arxiv_id': 'arXiv:2506.11849', 'title': 'Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values', 'authors': 'R. Teal Witter, Yurong Liu, Christopher Musco', 'link': 'https://arxiv.org/abs/2506.11849', 'abstract': 'With origins in game theory, probabilistic values like Shapley values, Banzhaf values, and semi-values have emerged as a central tool in explainable AI. They are used for feature attribution, data attribution, data valuation, and more. Since all of these values require exponential time to compute exactly, research has focused on efficient approximation methods using two techniques: Monte Carlo sampling and linear regression formulations. In this work, we present a new way of combining both of these techniques. Our approach is more flexible than prior algorithms, allowing for linear regression to be replaced with any function family whose probabilistic values can be computed efficiently. This allows us to harness the accuracy of tree-based models like XGBoost, while still producing unbiased estimates. From experiments across eight datasets, we find that our methods give state-of-the-art performance for estimating probabilistic values. For Shapley values, the error of our methods can be $6.5\\times$ lower than Permutation SHAP (the most popular Monte Carlo method), $3.8\\times$ lower than Kernel SHAP (the most popular linear regression method), and $2.6\\times$ lower than Leverage SHAP (the prior state-of-the-art Shapley value estimator). For more general probabilistic values, we can obtain error $215\\times$ lower than the best estimator from prior work.', 'abstract_zh': '基于博弈论的概率值（如Shapley值、Banzhaf值和半值）作为可解释AI的核心工具出现，它们被用于特征归因、数据归因、数据估值等。由于所有这些值都需要指数时间来准确计算，研究集中于使用两种技术的高效近似方法：蒙特卡洛采样和线性回归建模。本文提出了一种结合这两种技术的新方法。我们的方法比之前的算法更具灵活性，允许用任何可高效计算概率值的函数家族替换线性回归。这使得我们可以利用基于树的模型（如XGBoost）的准确性，同时仍能产生无偏估计。通过在八个数据集上的实验，我们发现，我们的方法在估计概率值方面达到了最先进的性能。对于Shapley值，我们方法的误差比Permutation SHAP（最流行的蒙特卡洛方法）低6.5倍，比Kernel SHAP（最流行的线性回归方法）低3.8倍，比Leverage SHAP（之前的最优Shapley值估算器）低2.6倍。对于更一般的概率值，我们可以获得比之前工作最优估计器低215倍的误差。', 'title_zh': '基于回归调整的蒙特卡洛估计器：Shapley值和概率值'}
{'arxiv_id': 'arXiv:2506.11815', 'title': 'Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection', 'authors': 'Tae-Seong Han, Jae-Wook Heo, Hakseung Kim, Cheol-Hui Lee, Hyub Huh, Eue-Keun Choi, Dong-Joo Kim', 'link': 'https://arxiv.org/abs/2506.11815', 'abstract': 'Electrocardiography (ECG) signals are often degraded by noise, which complicates diagnosis in clinical and wearable settings. This study proposes a diffusion-based framework for ECG noise quantification via reconstruction-based anomaly detection, addressing annotation inconsistencies and the limited generalizability of conventional methods. We introduce a distributional evaluation using the Wasserstein-1 distance ($W_1$), comparing the reconstruction error distributions between clean and noisy ECGs to mitigate inconsistent annotations. Our final model achieved robust noise quantification using only three reverse diffusion steps. The model recorded a macro-average $W_1$ score of 1.308 across the benchmarks, outperforming the next-best method by over 48%. External validations demonstrated strong generalizability, supporting the exclusion of low-quality segments to enhance diagnostic accuracy and enable timely clinical responses to signal degradation. The proposed method enhances clinical decision-making, diagnostic accuracy, and real-time ECG monitoring capabilities, supporting future advancements in clinical and wearable ECG applications.', 'abstract_zh': '基于扩散的 electrocardiography (ECG) 噪声量化框架：通过基于重建的异常检测解决注释不一致性和传统方法的有限泛化能力', 'title_zh': '基于扩散的电心图噪声异常检测量化'}
{'arxiv_id': 'arXiv:2506.11811', 'title': 'Abstract Sound Fusion with Unconditioned Inversion Model', 'authors': 'Jing Liu, EnQi Lian', 'link': 'https://arxiv.org/abs/2506.11811', 'abstract': 'An abstract sound is defined as a sound that does not disclose identifiable real-world sound events to a listener. Sound fusion aims to synthesize an original sound and a reference sound to generate a novel sound that exhibits auditory features beyond mere additive superposition of the sound constituents. To achieve this fusion, we employ inversion techniques that preserve essential features of the original sample while enabling controllable synthesis. We propose novel SDE and ODE inversion models based on DPMSolver++ samplers that reverse the sampling process by configuring model outputs as constants, eliminating circular dependencies incurred by noise prediction terms. Our inversion approach requires no prompt conditioning while maintaining flexible guidance during sampling.', 'abstract_zh': '一种抽象声音被定义为不向听者披露可识别的真实世界声源的声音。声音融合旨在合成一个原始声音和一个参考声音，生成一个展现超越简单叠加声音成分的听觉特征的新声音。为了实现这种融合，我们采用保留原始样本关键特征的同时允许可控合成的逆变换技术。我们基于DPMSolver++采样器提出了新型的SDE和ODE逆变换模型，通过将模型输出配置为常数来逆转采样过程，从而消除噪声预测项引起的循环依赖。我们的逆变换方法不要求使用提示条件，同时在采样过程中保持灵活的指导。', 'title_zh': '无条件反演模型导向的声学融合'}
{'arxiv_id': 'arXiv:2506.11790', 'title': 'Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation', 'authors': 'Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp', 'link': 'https://arxiv.org/abs/2506.11790', 'abstract': 'Evaluating feature attribution methods represents a critical challenge in explainable AI (XAI), as researchers typically rely on perturbation-based metrics when ground truth is unavailable. However, recent work demonstrates that these evaluation metrics can show different performance across predicted classes within the same dataset. These "class-dependent evaluation effects" raise questions about whether perturbation analysis reliably measures attribution quality, with direct implications for XAI method development and the trustworthiness of evaluation techniques. We investigate under which conditions these class-dependent effects arise by conducting controlled experiments with synthetic time series data where ground truth feature locations are known. We systematically vary feature types and class contrasts across binary classification tasks, then compare perturbation-based degradation scores with ground truth-based precision-recall metrics using multiple attribution methods. Our experiments demonstrate that class-dependent effects emerge with both evaluation approaches even in simple scenarios with temporally localized features, triggered by basic variations in feature amplitude or temporal extent between classes. Most critically, we find that perturbation-based and ground truth metrics frequently yield contradictory assessments of attribution quality across classes, with weak correlations between evaluation approaches. These findings suggest that researchers should interpret perturbation-based metrics with care, as they may not always align with whether attributions correctly identify discriminating features. These findings reveal opportunities to reconsider what attribution evaluation actually measures and to develop more comprehensive evaluation frameworks that capture multiple dimensions of attribution quality.', 'abstract_zh': '评估特征归因方法代表了可解释人工智能（XAI）中的一个关键挑战，因为研究者通常依赖扰动基指标进行评估，尤其是在没有真实标签的情况下。然而，近期研究表明，这些评估指标在同一个数据集中不同预测类别之间可能会显示出不同的性能。这些“类依赖性评估效果”引发了关于扰动分析是否可靠地衡量归因质量的质疑，这对XAI方法的发展和评估技术的信任度具有直接的影响。我们通过使用合成时间序列数据进行受控实验来研究这些类依赖性效果出现的条件，其中已知真实特征的位置。我们在二分类任务中系统地改变特征类型和类别对比，然后将扰动基降级评分与基于真实标签的精确召回指标进行比较，使用多种归因方法。实验结果表明，即使在具有时间局部化特征的简单场景中，这两种评估方法即使在简单的情景中也会出现类依赖性效果，这由类间基本特征振幅或时间范围的差异触发。最关键的是，我们发现扰动基和真实标签指标在不同类别上经常导致归因质量的矛盾评估，评估方法之间相关性较弱。这些发现表明，研究人员在解读扰动基指标时应谨慎，因为它们可能并不总是与归因是否正确识别区分性特征相一致。这些发现揭示了重新考虑归因评估实际上衡量什么以及开发更全面的评估框架以捕捉归因质量多维度的机会。', 'title_zh': '为什么类依赖的评估效应会在时间序列特征 attribution 中出现？一种合成数据探究'}
{'arxiv_id': 'arXiv:2506.11774', 'title': 'Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation', 'authors': 'Abhishek Jaiswal, Armeet Singh Luthra, Purav Jangir, Bhavya Garg, Nisheeth Srivastava', 'link': 'https://arxiv.org/abs/2506.11774', 'abstract': 'Isometric exercises appeal to individuals seeking convenience, privacy, and minimal dependence on equipments. However, such fitness training is often overdependent on unreliable digital media content instead of expert supervision, introducing serious risks, including incorrect posture, injury, and disengagement due to lack of corrective feedback. To address these challenges, we present a real-time feedback system for assessing isometric poses. Our contributions include the release of the largest multiclass isometric exercise video dataset to date, comprising over 3,600 clips across six poses with correct and incorrect variations. To support robust evaluation, we benchmark state-of-the-art models-including graph-based networks-on this dataset and introduce a novel three-part metric that captures classification accuracy, mistake localization, and model confidence. Our results enhance the feasibility of intelligent and personalized exercise training systems for home workouts. This expert-level diagnosis, delivered directly to the users, also expands the potential applications of these systems to rehabilitation, physiotherapy, and various other fitness disciplines that involve physical motion.', 'abstract_zh': '等长锻炼训练因其便捷、私密且对设备依赖度低而受到欢迎。然而，这种锻炼常常过度依赖不可靠的数字媒体内容而非专家指导，这带来了错误姿势、受伤以及缺乏矫正反馈导致的动力不足等严重风险。为此，我们提出了一种实时反馈系统，用于评估等长姿势。我们的贡献包括发布了目前最大的多类别等长锻炼视频数据集，包含超过3600个包含正确和错误变体的六种姿势片段。为了支持稳健的评估，我们在这数据集上对最新模型（包括图结构网络）进行了基准测试，并引入了一种新颖的三部分评价指标，该指标涵盖了分类准确性、错误定位和模型置信度。我们的结果提高了智能和个性化家庭锻炼训练系统的可行性。这种专家级诊断直接提供给用户，也扩展了这些系统的潜在应用范围，包括康复、物理治疗以及涉及身体动作的各种健身领域。', 'title_zh': '等 Isaiah 姿势评估的实时反馈与基准数据集'}
{'arxiv_id': 'arXiv:2506.11760', 'title': 'FeNN: A RISC-V vector processor for Spiking Neural Network acceleration', 'authors': 'Zainab Aizaz, James C. Knight, Thomas Nowotny', 'link': 'https://arxiv.org/abs/2506.11760', 'abstract': 'Spiking Neural Networks (SNNs) have the potential to drastically reduce the energy requirements of AI systems. However, mainstream accelerators like GPUs and TPUs are designed for the high arithmetic intensity of standard ANNs so are not well-suited to SNN simulation. FPGAs are well-suited to applications with low arithmetic intensity as they have high off-chip memory bandwidth and large amounts of on-chip memory. Here, we present a novel RISC-V-based soft vector processor (FeNN), tailored to simulating SNNs on FPGAs. Unlike most dedicated neuromorphic hardware, FeNN is fully programmable and designed to be integrated with applications running on standard computers from the edge to the cloud. We demonstrate that, by using stochastic rounding and saturation, FeNN can achieve high numerical precision with low hardware utilisation and that a single FeNN core can simulate an SNN classifier faster than both an embedded GPU and the Loihi neuromorphic system.', 'abstract_zh': 'SNNs在减少AI系统能耗方面的潜力：基于RISC-V的FeNN软向量处理器在FPGA上模拟SNN的研究', 'title_zh': 'FeNN: 一种用于突触神经网络加速的RISC-V向量处理器'}
{'arxiv_id': 'arXiv:2506.11718', 'title': 'Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration', 'authors': 'Yun Wang, Yan Lu', 'link': 'https://arxiv.org/abs/2506.11718', 'abstract': 'As AI tools proliferate across domains, from chatbots and copilots to emerging agents, they increasingly support professional knowledge work. Yet despite their growing capabilities, these systems remain fragmented: they assist with isolated tasks but lack the architectural scaffolding for sustained, adaptive collaboration. We propose a layered framework for human-agent systems that integrates three interdependent dimensions: interaction, process, and infrastructure. Crucially, our architecture elevates process to a primary focus by making it explicit, inspectable, and adaptable, enabling humans and agents to align with evolving goals and coordinate over time. This model clarifies limitations of current tools, unifies emerging system design approaches, and reveals new opportunities for researchers and AI system builders. By grounding intelligent behavior in structured collaboration, we reimagine human-agent collaboration not as task-specific augmentation, but as a form of coherent and aligned system for real-world work.', 'abstract_zh': '随着AI工具在各个领域 proliferate，从聊天机器人和联合飞行员到新兴代理，它们越来越多地支持专业知识工作。尽管这些系统的功能不断增强，但它们仍然碎片化：它们仅协助完成孤立的任务，缺乏持续适应性协作的架构支撑。我们提出了一种分层框架，用于集成三个相互依赖的维度：交互、过程和基础设施。最关键的是，我们的架构将过程作为重点，使其明确、可检查和可适应，从而使人类和代理能够适应不断变化的目标并随着时间协调工作。这一模型澄清了当前工具的局限性，统一了新兴系统设计方法，并揭示了研究人员和AI系统构建者的新机会。通过将智能行为根植于结构化的协作中，我们重新构想了人机协作，不仅作为一种特定任务的增强，而是作为一种连贯且一致的系统以适应现实世界的工作。', 'title_zh': '人机协作的统一架构：交互、过程与基础设施'}
{'arxiv_id': 'arXiv:2506.11702', 'title': 'Configurable Preference Tuning with Rubric-Guided Synthetic Data', 'authors': 'Víctor Gallego', 'link': 'https://arxiv.org/abs/2506.11702', 'abstract': 'Models of human feedback for AI alignment, such as those underpinning Direct Preference Optimization (DPO), often bake in a singular, static set of preferences, limiting adaptability. This paper challenges the assumption of monolithic preferences by introducing Configurable Preference Tuning (CPT), a novel framework for endowing language models with the ability to dynamically adjust their behavior based on explicit, human-interpretable directives. CPT leverages synthetically generated preference data, conditioned on system prompts derived from structured, fine-grained rubrics that define desired attributes like writing style. By fine-tuning with these rubric-guided preferences, the LLM learns to modulate its outputs at inference time in response to the system prompt, without retraining. This approach not only offers fine-grained control but also provides a mechanism for modeling more nuanced and context-dependent human feedback. Several experimental artifacts, such as training code, generated datasets and fine-tuned models are released at this https URL', 'abstract_zh': '人类反馈模型在AI对齐中的应用，如直接偏好优化（DPO）下的模型，往往包含了单一的静态偏好集合，限制了其适应性。本文通过引入可配置偏好调整（CPT）框架挑战了单一偏好假设，CPT为语言模型赋予了根据明确的人类可解释指令动态调整其行为的能力。CPT利用基于结构化细粒度标准卡生成的合成偏好数据，这些标准卡定义了如写作风格等期望属性。通过标准卡指导下的微调，LLM能够在推理时根据系统提示调整其输出，而无需重新训练。这种方法不仅提供了精细控制，还为建模更为精细和上下文依赖的人类反馈提供了一种机制。有关实验成果，如训练代码、生成的数据集和微调模型，可在此链接获取。', 'title_zh': '基于评分指南引导的合成数据可配置偏好调整'}
{'arxiv_id': 'arXiv:2506.11687', 'title': 'Differential Privacy in Machine Learning: From Symbolic AI to LLMs', 'authors': 'Francisco Aguilera-Martínez, Fernando Berzal', 'link': 'https://arxiv.org/abs/2506.11687', 'abstract': 'Machine learning models should not reveal particular information that is not otherwise accessible. Differential privacy provides a formal framework to mitigate privacy risks by ensuring that the inclusion or exclusion of any single data point does not significantly alter the output of an algorithm, thus limiting the exposure of private information. This survey paper explores the foundational definitions of differential privacy, reviews its original formulations and tracing its evolution through key research contributions. It then provides an in-depth examination of how DP has been integrated into machine learning models, analyzing existing proposals and methods to preserve privacy when training ML models. Finally, it describes how DP-based ML techniques can be evaluated in practice. %Finally, it discusses the broader implications of DP, highlighting its potential for public benefit, its real-world applications, and the challenges it faces, including vulnerabilities to adversarial attacks. By offering a comprehensive overview of differential privacy in machine learning, this work aims to contribute to the ongoing development of secure and responsible AI systems.', 'abstract_zh': '机器学习模型不应泄露超出范围的特定信息。差异隐私提供了一种正式框架，通过确保任何单个数据点的包含或排除不会显著改变算法的输出，从而限制私人信息的暴露。本文综述了差异隐私的基础定义，回顾了其最初的形成并通过关键研究贡献追踪其演变。然后，深入探讨了差异隐私如何集成到机器学习模型中，在训练机器学习模型时保留隐私的方法和现有提案。最后，描述了基于差异隐私的机器学习技术在实践中的评估方法。此外，讨论了差异隐私的更广泛影响，包括其对公共利益的潜力、实际应用以及面临的挑战，如对抗攻击的脆弱性。通过提供差异隐私在机器学习中的综合概述，本文旨在为安全和负责任的人工智能系统的发展做出贡献。', 'title_zh': '机器学习中的差分隐私：从符号人工智能到大语言模型'}
{'arxiv_id': 'arXiv:2506.11679', 'title': 'LLMs on support of privacy and security of mobile apps: state of the art and research directions', 'authors': 'Tran Thanh Lam Nguyen, Barbara Carminati, Elena Ferrari', 'link': 'https://arxiv.org/abs/2506.11679', 'abstract': 'Modern life has witnessed the explosion of mobile devices. However, besides the valuable features that bring convenience to end users, security and privacy risks still threaten users of mobile apps. The increasing sophistication of these threats in recent years has underscored the need for more advanced and efficient detection approaches. In this chapter, we explore the application of Large Language Models (LLMs) to identify security risks and privacy violations and mitigate them for the mobile application ecosystem. By introducing state-of-the-art research that applied LLMs to mitigate the top 10 common security risks of smartphone platforms, we highlight the feasibility and potential of LLMs to replace traditional analysis methods, such as dynamic and hybrid analysis of mobile apps. As a representative example of LLM-based solutions, we present an approach to detect sensitive data leakage when users share images online, a common behavior of smartphone users nowadays. Finally, we discuss open research challenges.', 'abstract_zh': '现代生活中，移动设备的数量急剧增加。然而，虽然移动应用为终端用户带来了宝贵的便利功能，但安全和隐私风险仍然威胁着用户的使用。近年来，这些威胁的日益复杂性凸显了需要更先进和高效的检测方法。在本章中，我们探讨了大规模语言模型（LLMs）在识别移动应用生态系统中的安全风险和隐私侵犯并减轻这些风险的应用。通过介绍将LLMs应用于缓解智能手机平台Top 10常见安全风险的最先进研究，我们突出了LLMs替换传统分析方法（如移动应用的动态和混合分析）的可行性和潜力。作为LLM基解决方案的代表例子，我们提出了一种检测在线分享图片时敏感数据泄露的方法，这是现代智能手机用户常见的行为。最后，我们讨论了开放的研究挑战。', 'title_zh': 'LLMs在移动应用隐私与安全支持中的状态与研究方向'}
{'arxiv_id': 'arXiv:2506.11673', 'title': 'Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE', 'authors': 'Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer', 'link': 'https://arxiv.org/abs/2506.11673', 'abstract': "Amnesic probing is a technique used to examine the influence of specific linguistic information on the behaviour of a model. This involves identifying and removing the relevant information and then assessing whether the model's performance on the main task changes. If the removed information is relevant, the model's performance should decline. The difficulty with this approach lies in removing only the target information while leaving other information unchanged. It has been shown that Iterative Nullspace Projection (INLP), a widely used removal technique, introduces random modifications to representations when eliminating target information. We demonstrate that Mean Projection (MP) and LEACE, two proposed alternatives, remove information in a more targeted manner, thereby enhancing the potential for obtaining behavioural explanations through Amnesic Probing.", 'abstract_zh': '遗忘探测是一种用于检验特定语言信息对模型行为影响的技术。这涉及识别并移除相关信息，然后评估模型在主任务上的性能变化。如果移除的信息是相关的，模型的性能应该下降。这种方法的难点在于仅移除目标信息而不改变其他信息。研究表明，广泛使用的移除技术迭代 Nullspace 投影 (INLP) 在消除目标信息时会引入随机修改。我们证明，两种提出的替代方法——均值投影 (MP) 和 LEACE——能够更精确地移除信息，从而增强通过遗忘探测获得行为解释的潜力。', 'title_zh': '改善遗忘性探查中的因果干预：基于均值投影或LEACE的方法'}
{'arxiv_id': 'arXiv:2506.11666', 'title': 'Converting Annotated Clinical Cases into Structured Case Report Forms', 'authors': 'Pietro Ferrazzi, Alberto Lavelli, Bernardo Magnini', 'link': 'https://arxiv.org/abs/2506.11666', 'abstract': 'Case Report Forms (CRFs) are largely used in medical research as they ensure accuracy, reliability, and validity of results in clinical studies. However, publicly available, wellannotated CRF datasets are scarce, limiting the development of CRF slot filling systems able to fill in a CRF from clinical notes. To mitigate the scarcity of CRF datasets, we propose to take advantage of available datasets annotated for information extraction tasks and to convert them into structured CRFs. We present a semi-automatic conversion methodology, which has been applied to the E3C dataset in two languages (English and Italian), resulting in a new, high-quality dataset for CRF slot filling. Through several experiments on the created dataset, we report that slot filling achieves 59.7% for Italian and 67.3% for English on a closed Large Language Models (zero-shot) and worse performances on three families of open-source models, showing that filling CRFs is challenging even for recent state-of-the-art LLMs. We release the datest at this https URL', 'abstract_zh': '基于信息抽取任务标注的数据集的半自动转换方法以构建高质CRF插槽填充数据集', 'title_zh': '将标注临床案例转换为结构化病例报告表'}
{'arxiv_id': 'arXiv:2506.11653', 'title': 'DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation', 'authors': 'Emre Kavak, Tom Nuno Wolf, Christian Wachinger', 'link': 'https://arxiv.org/abs/2506.11653', 'abstract': 'During prediction tasks, models can use any signal they receive to come up with the final answer - including signals that are causally irrelevant. When predicting objects from images, for example, the lighting conditions could be correlated to different targets through selection bias, and an oblivious model might use these signals as shortcuts to discern between various objects. A predictor that uses lighting conditions instead of real object-specific details is obviously undesirable. To address this challenge, we introduce a standard anti-causal prediction model (SAM) that creates a causal framework for analyzing the information pathways influencing our predictor in anti-causal settings. We demonstrate that a classifier satisfying a specific conditional independence criterion will focus solely on the direct causal path from label to image, being counterfactually invariant to the remaining variables. Finally, we propose DISCO, a novel regularization strategy that uses conditional distance correlation to optimize for conditional independence in regression tasks. We can show that DISCO achieves competitive results in different bias mitigation experiments, deeming it a valid alternative to classical kernel-based methods.', 'abstract_zh': '一种标准反因袭预测模型及其在反因袭设置下的因果框架', 'title_zh': 'DISCO: 用条件距离相关性减轻深度学习中的偏差'}
{'arxiv_id': 'arXiv:2506.11627', 'title': 'Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression', 'authors': 'Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker, Yiannis Papadopoulos', 'link': 'https://arxiv.org/abs/2506.11627', 'abstract': 'Fairness is a critical component of Trustworthy AI. In this paper, we focus on Machine Learning (ML) and the performance of model predictions when dealing with skin color. Unlike other sensitive attributes, the nature of skin color differs significantly. In computer vision, skin color is represented as tensor data rather than categorical values or single numerical points. However, much of the research on fairness across sensitive groups has focused on categorical features such as gender and race. This paper introduces a new technique for evaluating fairness in ML for image classification tasks, specifically without the use of annotation. To address the limitations of prior work, we handle tensor data, like skin color, without classifying it rigidly. Instead, we convert it into probability distributions and apply statistical distance measures. This novel approach allows us to capture fine-grained nuances in fairness both within and across what would traditionally be considered distinct groups. Additionally, we propose an innovative training method to mitigate the latent biases present in conventional skin tone categorization. This method leverages color distance estimates calculated through Bayesian regression with polynomial functions, ensuring a more nuanced and equitable treatment of skin color in ML models.', 'abstract_zh': '公平是可信赖AI的关键组成部分。本文关注机器学习（ML）以及在处理皮肤颜色时模型预测的表现。不同于其他敏感属性，皮肤颜色的性质差异显著。在计算机视觉中，皮肤颜色被表示为张量数据而非分类值或单一数值点。然而，针对敏感群体的公平性研究大多集中在性别和种族等分类特征上。本文介绍了在无需标注的情况下评估图像分类任务中ML公平性的一种新方法。为了解决先前工作的局限性，我们处理如皮肤颜色这样的张量数据，不对其进行严格的分类。相反，我们将其转换为概率分布并应用统计距离度量。这一新颖的方法使我们能够捕捉公平性中的细微差异，无论是内部还是跨传统上被视为独立群体的外部。此外，我们提出了一种创新的训练方法来缓解常规肤色分类中存在的潜在偏见。该方法利用通过贝叶斯回归与多项式函数计算的颜色距离估计，确保ML模型中皮肤颜色的更细致和公平处理。', 'title_zh': '基于张量数据和贝叶斯回归的新型技术评价公平性与减轻偏见'}
{'arxiv_id': 'arXiv:2506.11600', 'title': 'GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news', 'authors': 'Abdul Haque, Umm e Hani, Ahmad Din, Muhammad Babar, Ali Abbas, Insaf Ullah', 'link': 'https://arxiv.org/abs/2506.11600', 'abstract': 'GraphRAG-Causal introduces an innovative framework that combines graph-based retrieval with large language models to enhance causal reasoning in news analysis. Traditional NLP approaches often struggle with identifying complex, implicit causal links, especially in low-data scenarios. Our approach addresses these challenges by transforming annotated news headlines into structured causal knowledge graphs. It then employs a hybrid retrieval system that merges semantic embeddings with graph-based structural cues leveraging Neo4j to accurately match and retrieve relevant events. The framework is built on a three-stage pipeline: First, during Data Preparation, news sentences are meticulously annotated and converted into causal graphs capturing cause, effect, and trigger relationships. Next, the Graph Retrieval stage stores these graphs along with their embeddings in a Neo4j database and utilizes hybrid Cypher queries to efficiently identify events that share both semantic and structural similarities with a given query. Finally, the LLM Inference stage utilizes these retrieved causal graphs in a few-shot learning setup with XML-based prompting, enabling robust classification and tagging of causal relationships. Experimental evaluations demonstrate that GraphRAG-Causal achieves an impressive F1-score of 82.1% on causal classification using just 20 few-shot examples. This approach significantly boosts accuracy and consistency, making it highly suitable for real-time applications in news reliability assessment, misinformation detection, and policy analysis.', 'abstract_zh': 'GraphRAG-Causal引入了一种创新框架，将基于图的检索与大规模语言模型相结合，增强新闻分析中的因果推理。传统的自然语言处理方法在识别低数据场景中的复杂隐含因果联系时往往力不从心。我们的方法通过将标注的新闻标题转换为结构化的因果知识图来应对这些挑战，然后利用Neo4j结合语义嵌入和基于图的结构线索来高效匹配和检索相关事件。该框架建立在三阶段管道之上：首先，在数据准备阶段，详细标注新闻句子并转化为包含原因、结果和触发关系的因果图；接着，在图检索阶段，将这些图及其嵌入存储在Neo4j数据库中，并利用混合Cypher查询高效地识别与给定查询具有语义和结构相似性的事件；最后，在LLM推理阶段，利用这些检索到的因果图采用基于XML的提示少量样本学习设置，实现因果关系的稳健分类和标签。实验评估表明，GraphRAG-Causal仅使用20个少量样本示例，在因果分类上实现了82.1%的F1分数。该方法大幅提升了准确性和一致性，使其非常适用于新闻可靠性评估、 misinformation检测和政策分析等实时应用。', 'title_zh': 'GraphRAG-Causal：一种新型图增强框架，用于新闻中的因果推理与标注'}
{'arxiv_id': 'arXiv:2506.11584', 'title': 'A Comparative Analysis of Influence Signals for Data Debugging', 'authors': 'Nikolaos Myrtakis, Ioannis Tsamardinos, Vassilis Christophides', 'link': 'https://arxiv.org/abs/2506.11584', 'abstract': "Improving the quality of training samples is crucial for improving the reliability and performance of ML models. In this paper, we conduct a comparative evaluation of influence-based signals for debugging training data. These signals can potentially identify both mislabeled and anomalous samples from a potentially noisy training set as we build the models and hence alleviate the need for dedicated glitch detectors. Although several influence-based signals (e.g., Self-Influence, Average Absolute Influence, Marginal Influence, GD-class) have been recently proposed in the literature, there are no experimental studies for assessing their power in detecting different glitch types (e.g., mislabeled and anomalous samples) under a common influence estimator (e.g., TraceIn) for different data modalities (image and tabular), and deep learning models (trained from scratch or foundation). Through extensive experiments, we show that signals like Self-Influence effectively detect mislabeled samples, but none of the existing signals can detect anomalies. Existing signals do not take into account the training dynamics, i.e., how the samples' influence on the model changes during training, while some signals fall into influence cancellation effects, i.e., influence score is zero due to unsigned scores accumulation, resulting in misleading influence attribution.", 'abstract_zh': '提高训练样本质量对于提升机器学习模型的可靠性和性能至关重要。本文对基于影响的信号进行比较评估，以调试训练数据。这些信号有可能从潜在嘈杂的训练集中识别出误标和异常样本，从而减轻专用故障检测器的需要。尽管文献中已经提出了几种基于影响的信号（例如，Self-Influence、Average Absolute Influence、Marginal Influence、GD-class），但还没有实验研究评估它们在不同影响估计器（例如，TraceIn）下，针对不同数据模态（图像和表结构数据）和深度学习模型（从头开始训练或基于基础模型的）检测不同类型故障（例如，误标和异常样本）的能力。通过广泛实验，我们表明Self-Influence信号能有效检测误标样本，但现有信号不能检测异常样本。现有信号没有考虑训练动力学，即样本对模型的影响如何在训练过程中变化，而有些信号则陷入了影响抵消效应，即由于无符号得分累积使得影响分值为零，导致误导性的影响归因。', 'title_zh': '数据调试中影响信号的比较分析'}
{'arxiv_id': 'arXiv:2506.11563', 'title': 'Learn to Preserve Personality: Federated Foundation Models in Recommendations', 'authors': 'Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang', 'link': 'https://arxiv.org/abs/2506.11563', 'abstract': 'A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user centric, decentralized system where individuals maintain control over their personalized agents.', 'abstract_zh': '已存在的基础模型(FM)的核心学习挑战是在泛化与个性化之间取得权衡，这是由各种参数高效适应技术突出的一个困境。联邦基础模型(FFM)通过分散化过程提供了一种结构化手段来分离共享知识和个体特定适应。鉴于推荐系统依赖丰富的隐式反馈反映出用户的独特特征，推荐系统为FFM提供了一个理想的测试平台。本文探讨了一种新的学习范式，在这种范式下，FFM不仅利用其泛化能力，而且特别设计来保护用户个性的完整性，这一特点在推荐系统中得到了充分说明。我们展望由个性化适应基础模型驱动的未来个性化代理，指导用户在内容上的决策。这种架构承诺了一个以用户为中心、分散化的系统，个体保留对其个性化代理的控制权。', 'title_zh': '学习保留个性：联邦基础模型在推荐中的应用'}
{'arxiv_id': 'arXiv:2506.11521', 'title': 'Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models', 'authors': 'Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li', 'link': 'https://arxiv.org/abs/2506.11521', 'abstract': 'Multimodal large language models (MLLMs), which bridge the gap between audio-visual and natural language processing, achieve state-of-the-art performance on several audio-visual tasks. Despite the superior performance of MLLMs, the scarcity of high-quality audio-visual training data and computational resources necessitates the utilization of third-party data and open-source MLLMs, a trend that is increasingly observed in contemporary research. This prosperity masks significant security risks. Empirical studies demonstrate that the latest MLLMs can be manipulated to produce malicious or harmful content. This manipulation is facilitated exclusively through instructions or inputs, including adversarial perturbations and malevolent queries, effectively bypassing the internal security mechanisms embedded within the models. To gain a deeper comprehension of the inherent security vulnerabilities associated with audio-visual-based multimodal models, a series of surveys investigates various types of attacks, including adversarial and backdoor attacks. While existing surveys on audio-visual attacks provide a comprehensive overview, they are limited to specific types of attacks, which lack a unified review of various types of attacks. To address this issue and gain insights into the latest trends in the field, this paper presents a comprehensive and systematic review of audio-visual attacks, which include adversarial attacks, backdoor attacks, and jailbreak attacks. Furthermore, this paper also reviews various types of attacks in the latest audio-visual-based MLLMs, a dimension notably absent in existing surveys. Drawing upon comprehensive insights from a substantial review, this paper delineates both challenges and emergent trends for future research on audio-visual attacks and defense.', 'abstract_zh': '多模态大语言模型的音频视觉攻击综述：包括对抗攻击、后门攻击和越狱攻击', 'title_zh': '针对音视频攻击的漏洞与防御方法综述：强调多模态模型的研究'}
{'arxiv_id': 'arXiv:2506.11508', 'title': 'Machine Learning-Based Quantification of Vesicoureteral Reflux with Enhancing Accuracy and Efficiency', 'authors': 'Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Mohammad Subhi Al-Batah, Lana Yasin Al Aesa, Mohammed Hasan Abu-Arqoub, Rashiq Rafiq Marie, Firas Hussein Alsmad', 'link': 'https://arxiv.org/abs/2506.11508', 'abstract': 'Vesicoureteral reflux (VUR) is traditionally assessed using subjective grading systems, which introduces variability in diagnosis. This study investigates the use of machine learning to improve diagnostic consistency by analyzing voiding cystourethrogram (VCUG) images. A total of 113 VCUG images were reviewed, with expert grading of VUR severity. Nine image-based features were selected to train six predictive models: Logistic Regression, Decision Tree, Gradient Boosting, Neural Network, and Stochastic Gradient Descent. The models were evaluated using leave-one-out cross-validation. Analysis identified deformation patterns in the renal calyces as key indicators of high-grade VUR. All models achieved accurate classifications with no false positives or negatives. High sensitivity to subtle image patterns characteristic of different VUR grades was confirmed by substantial Area Under the Curve (AUC) values. The results suggest that machine learning can offer an objective and standardized alternative to current subjective VUR assessments. These findings highlight renal calyceal deformation as a strong predictor of severe cases. Future research should aim to expand the dataset, refine imaging features, and improve model generalizability for broader clinical use.', 'abstract_zh': '膀胱输尿管反流（VUR）的传统评估采用主观分级系统，引入了诊断的一致性问题。本研究通过分析排尿性膀胱尿道造影（VCUG）图像，探讨机器学习在提高诊断一致性的应用。共有113张VCUG图像被回顾，由专家对VUR的严重程度进行了分级。选择了九个基于图像的特征来训练六种预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降。模型通过留一交叉验证进行评估。分析发现肾盂的变形模式是高年级VUR的关键指标。所有模型均实现了准确分类，无假阳性和假阴性。特征值显著的曲线下面积（AUC）证实了模型对不同VUR级别的微妙影像特征的高度敏感性。结果表明，机器学习可以提供客观且标准化的VUR评估替代方案。这些发现强调了肾盂变形作为严重病例强预测因子的重要性。未来研究应致力于扩大数据集、细化成像特征并改善模型的普适性，以供更广泛临床使用。', 'title_zh': '基于机器学习的输尿管反流量化方法以提高准确性和效率'}
{'arxiv_id': 'arXiv:2506.11501', 'title': 'Diabetes Prediction and Management Using Machine Learning Approaches', 'authors': 'Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh, Mohammad Subhi Al-Batah', 'link': 'https://arxiv.org/abs/2506.11501', 'abstract': 'Diabetes has emerged as a significant global health issue, especially with the increasing number of cases in many countries. This trend Underlines the need for a greater emphasis on early detection and proactive management to avert or mitigate the severe health complications of this disease. Over recent years, machine learning algorithms have shown promising potential in predicting diabetes risk and are beneficial for practitioners. Objective: This study highlights the prediction capabilities of statistical and non-statistical machine learning methods over Diabetes risk classification in 768 samples from the Pima Indians Diabetes Database. It consists of the significant demographic and clinical features of age, body mass index (BMI) and blood glucose levels that greatly depend on the vulnerability against Diabetes. The experimentation assesses the various types of machine learning algorithms in terms of accuracy and effectiveness regarding diabetes prediction. These algorithms include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting and Neural Network Models. The results show that the Neural Network algorithm gained the highest predictive accuracy with 78,57 %, and then the Random Forest algorithm had the second position with 76,30 % accuracy. These findings show that machine learning techniques are not just highly effective. Still, they also can potentially act as early screening tools in predicting Diabetes within a data-driven fashion with valuable information on who is more likely to get affected. In addition, this study can help to realize the potential of machine learning for timely intervention over the longer term, which is a step towards reducing health outcomes and disease burden attributable to Diabetes on healthcare systems', 'abstract_zh': '糖尿病已成为一个重要的全球健康问题，特别是随着许多国家病例数的增加。这一趋势凸显了早期检测和积极管理的必要性，以预防或减轻此病的严重健康并发症。近年来，机器学习算法在预测糖尿病风险方面显示出了有希望的潜力，并对实践者有益。目标：本研究强调了统计和非统计机器学习方法在Pima印度人糖尿病数据库768个样本中对糖尿病风险分类的预测能力。此数据库包含年龄、体重指数（BMI）和血糖水平等重要的人口统计和临床特征，这些特征对糖尿病的易感性有很大影响。该研究评估了各种类型的机器学习算法在糖尿病预测方面的准确性和有效性，这些算法包括逻辑回归、决策树、随机森林、K-近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型。研究结果表明，神经网络算法获得了最高的预测准确率，达到78.57%，随后，随机森林算法的准确率为76.30%。这些发现表明，机器学习技术不仅效果显著，还可能作为数据驱动的早期筛查工具，在预测糖尿病方面发挥作用，并提供有关谁更容易受到影响的有价值信息。此外，本研究有助于认识到机器学习在未来及时干预的潜力，从而减少由糖尿病导致的健康结果和疾病负担，这对医疗系统来说是一个重要步骤。', 'title_zh': '使用机器学习方法进行糖尿病预测与管理'}
{'arxiv_id': 'arXiv:2506.11490', 'title': 'Composite Data Augmentations for Synthetic Image Detection Against Real-World Perturbations', 'authors': 'Efthymia Amarantidou, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis', 'link': 'https://arxiv.org/abs/2506.11490', 'abstract': 'The advent of accessible Generative AI tools enables anyone to create and spread synthetic images on social media, often with the intention to mislead, thus posing a significant threat to online information integrity. Most existing Synthetic Image Detection (SID) solutions struggle on generated images sourced from the Internet, as these are often altered by compression and other operations. To address this, our research enhances SID by exploring data augmentation combinations, leveraging a genetic algorithm for optimal augmentation selection, and introducing a dual-criteria optimization approach. These methods significantly improve model performance under real-world perturbations. Our findings provide valuable insights for developing detection models capable of identifying synthetic images across varying qualities and transformations, with the best-performing model achieving a mean average precision increase of +22.53% compared to models without augmentations. The implementation is available at this http URL.', 'abstract_zh': '可访问的生成AI工具的出现使任何人都能够创建和传播合成图像， often with the intention to mislead, thus posing a significant threat to online information integrity.', 'title_zh': '用于对抗现实世界干扰的合成图像检测复合数据增强方法'}
{'arxiv_id': 'arXiv:2506.11421', 'title': 'Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems', 'authors': 'Junli Shao, Jing Dong, Dingzhou Wang, Kowei Shih, Dannier Li, Chengrui Zhou', 'link': 'https://arxiv.org/abs/2506.11421', 'abstract': 'With the rapid growth of Internet services, recommendation systems play a central role in delivering personalized content. Faced with massive user requests and complex model architectures, the key challenge for real-time recommendation systems is how to reduce inference latency and increase system throughput without sacrificing recommendation quality. This paper addresses the high computational cost and resource bottlenecks of deep learning models in real-time settings by proposing a combined set of modeling- and system-level acceleration and optimization strategies. At the model level, we dramatically reduce parameter counts and compute requirements through lightweight network design, structured pruning, and weight quantization. At the system level, we integrate multiple heterogeneous compute platforms and high-performance inference libraries, and we design elastic inference scheduling and load-balancing mechanisms based on real-time load characteristics. Experiments show that, while maintaining the original recommendation accuracy, our methods cut latency to less than 30% of the baseline and more than double system throughput, offering a practical solution for deploying large-scale online recommendation services.', 'abstract_zh': '随着互联网服务的快速增长，推荐系统在提供个性化内容中发挥着核心作用。面对大量的用户请求和复杂的模型架构，实时推荐系统的关键挑战是在不牺牲推荐质量的前提下如何减少推理延迟并提高系统吞吐量。本文通过提出结合模型和系统层面的加速与优化策略，解决了实时场景下深度学习模型的高计算成本和资源瓶颈问题。在模型层面，我们通过轻量级网络设计、结构化剪枝和权重量化大幅减少参数量和计算需求。在系统层面，我们集成多种异构计算平台和高性能推理库，并设计基于实时负载特性的弹性推理调度和负载均衡机制。实验结果表明，在保持原始推荐准确性的前提下，我们的方法将延迟降低到基线的不到30%，并将系统吞吐量提高了一倍以上，为部署大规模在线推荐服务提供了实用解决方案。', 'title_zh': '深度学习模型加速与优化策略在实时推荐系统中的应用'}
{'arxiv_id': 'arXiv:2506.11403', 'title': 'A correlation-permutation approach for speech-music encoders model merging', 'authors': 'Fabian Ritter-Gutierrez, Yi-Cheng Lin, Jeremy H.M Wong, Hung-yi Lee, Eng Siong Chng, Nancy F. Chen', 'link': 'https://arxiv.org/abs/2506.11403', 'abstract': "Creating a unified speech and music model requires expensive pre-training. Model merging can instead create an unified audio model with minimal computational expense. However, direct merging is challenging when the models are not aligned in the weight space. Motivated by Git Re-Basin, we introduce a correlation-permutation approach that aligns a music encoder's internal layers with a speech encoder. We extend previous work to the case of merging transformer layers. The method computes a permutation matrix that maximizes the model's features-wise cross-correlations layer by layer, enabling effective fusion of these otherwise disjoint models. The merged model retains speech capabilities through this method while significantly enhancing music performance, achieving an improvement of 14.83 points in average score compared to linear interpolation model merging. This work allows the creation of unified audio models from independently trained encoders.", 'abstract_zh': '创建统一的语音和音乐模型需要昂贵的预训练。通过模型合并可以在几乎没有计算成本的情况下创建统一的音频模型。然而，当模型在权重空间中不一致时，直接合并是具有挑战性的。受Git Re-Basin的启发，我们引入了一种相关性-置换方法，将音乐编码器的内部层与语音编码器对齐。我们将先前的工作扩展到合并Transformer层的情况。该方法逐层计算一个置换矩阵，以最大化模型的特征间互相关，从而有效融合这些之前分离的模型。通过这种方法，合并后的模型保留了语音能力，同时显著增强了音乐性能，在平均得分上比线性插值模型合并提高了14.83分。这项工作允许从独立训练的编码器创建统一的音频模型。', 'title_zh': 'speech-音乐编码器模型合并的相关性-置换方法'}
{'arxiv_id': 'arXiv:2506.11381', 'title': 'A Variational Approach for Mitigating Entity Bias in Relation Extraction', 'authors': 'Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley', 'link': 'https://arxiv.org/abs/2506.11381', 'abstract': 'Mitigating entity bias is a critical challenge in Relation Extraction (RE), where models often rely excessively on entities, resulting in poor generalization. This paper presents a novel approach to address this issue by adapting a Variational Information Bottleneck (VIB) framework. Our method compresses entity-specific information while preserving task-relevant features. It achieves state-of-the-art performance on relation extraction datasets across general, financial, and biomedical domains, in both indomain (original test sets) and out-of-domain (modified test sets with type-constrained entity replacements) settings. Our approach offers a robust, interpretable, and theoretically grounded methodology.', 'abstract_zh': '缓解实体偏见是关系抽取中的一个关键挑战，模型往往过度依赖实体，导致泛化能力差。本文提出了一种通过适应变分信息瓶颈框架来解决这一问题的新方法。该方法压缩了实体特定信息的同时保留了与任务相关的特征。在通用、金融和生物医药领域的关系抽取数据集中，我们的方法均取得了最佳性能，在领域内（原始测试集）和跨领域（修改测试集，实体类型受限替换）设置下均有效。该方法提供了一种稳健、可解释且理论上扎实的解决方案。', 'title_zh': '基于变分方法的实体偏见缓解在关系提取中的应用'}
{'arxiv_id': 'arXiv:2506.11295', 'title': 'A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems', 'authors': 'Renato Cordeiro Ferreira', 'link': 'https://arxiv.org/abs/2506.11295', 'abstract': 'How can the complexity of ML-enabled systems be managed effectively? The goal of this research is to investigate how complexity affects ML-Enabled Systems (MLES). To address this question, this research aims to introduce a metrics-based architectural model to characterize the complexity of MLES. The goal is to support architectural decisions, providing a guideline for the inception and growth of these systems. This paper brings, side-by-side, the architecture representation of two systems that can be used as case studies for creating the metrics-based architectural model: the SPIRA and the Ocean Guard MLES.', 'abstract_zh': '如何有效地管理基于机器学习系统的复杂性？本研究旨在探讨复杂性对基于机器学习系统（MLES）的影响。为此，本研究旨在引入基于度量的架构模型来表征MLES的复杂性，以支持架构决策，为这些系统的开始和成长提供指导。本文并列了两个系统的架构表示，可用作构建基于度量的架构模型的案例研究：SPIRA和Ocean Guard MLES。', 'title_zh': '两系统之事：机器学习使能系统中的架构复杂性特征化'}
{'arxiv_id': 'arXiv:2506.11251', 'title': 'Measuring multi-calibration', 'authors': 'Ido Guy, Daniel Haimovich, Fridolin Linder, Nastaran Okati, Lorenzo Perini, Niek Tax, Mark Tygert', 'link': 'https://arxiv.org/abs/2506.11251', 'abstract': 'A suitable scalar metric can help measure multi-calibration, defined as follows. When the expected values of observed responses are equal to corresponding predicted probabilities, the probabilistic predictions are known as "perfectly calibrated." When the predicted probabilities are perfectly calibrated simultaneously across several subpopulations, the probabilistic predictions are known as "perfectly multi-calibrated." In practice, predicted probabilities are seldom perfectly multi-calibrated, so a statistic measuring the distance from perfect multi-calibration is informative. A recently proposed metric for calibration, based on the classical Kuiper statistic, is a natural basis for a new metric of multi-calibration and avoids well-known problems of metrics based on binning or kernel density estimation. The newly proposed metric weights the contributions of different subpopulations in proportion to their signal-to-noise ratios; data analyses\' ablations demonstrate that the metric becomes noisy when omitting the signal-to-noise ratios from the metric. Numerical examples on benchmark data sets illustrate the new metric.', 'abstract_zh': '一种合适的标量度量可以帮助衡量多校准。当观测响应的期望值等于相应的预测概率时，概率预测被称为“完美校准”。当预测概率在多个子群体中同时完美校准时，概率预测被称为“完美多校准”。实际上，预测概率很少完全多校准，因此衡量与完美多校准距离的统计量是令人信息丰富的。基于经典的库普勒统计量最近提出的一种校准度量是衡量多校准的新度量的基础，并避免了基于分箱或核密度估计的度量已知的问题。新提出的度量按信号噪声比的比例衡量不同子群体的贡献；数据分析的消融实验表明，如果不从度量中排除信号噪声比，度量会变 noisy。基准数据集上的数值例子说明了新的度量。', 'title_zh': '多校准度量'}
{'arxiv_id': 'arXiv:2506.11250', 'title': 'Can Time-Series Foundation Models Perform Building Energy Management Tasks?', 'authors': 'Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava', 'link': 'https://arxiv.org/abs/2506.11250', 'abstract': 'Building energy management (BEM) tasks require processing and learning from a variety of time-series data. Existing solutions rely on bespoke task- and data-specific models to perform these tasks, limiting their broader applicability. Inspired by the transformative success of Large Language Models (LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets, have the potential to change this. Were TSFMs to achieve a level of generalizability across tasks and contexts akin to LLMs, they could fundamentally address the scalability challenges pervasive in BEM. To understand where they stand today, we evaluate TSFMs across four dimensions: (1) generalizability in zero-shot univariate forecasting, (2) forecasting with covariates for thermal behavior modeling, (3) zero-shot representation learning for classification tasks, and (4) robustness to performance metrics and varying operational conditions. Our results reveal that TSFMs exhibit \\emph{limited} generalizability, performing only marginally better than statistical models on unseen datasets and modalities for univariate forecasting. Similarly, inclusion of covariates in TSFMs does not yield performance improvements, and their performance remains inferior to conventional models that utilize covariates. While TSFMs generate effective zero-shot representations for downstream classification tasks, they may remain inferior to statistical models in forecasting when statistical models perform test-time fitting. Moreover, TSFMs forecasting performance is sensitive to evaluation metrics, and they struggle in more complex building environments compared to statistical models. These findings underscore the need for targeted advancements in TSFM design, particularly their handling of covariates and incorporating context and temporal dynamics into prediction mechanisms, to develop more adaptable and scalable solutions for BEM.', 'abstract_zh': 'Time-Series Foundation Models的现状：面向建筑能源管理任务的挑战与前景', 'title_zh': '时间序列基础模型能否执行建筑能源管理任务？'}
{'arxiv_id': 'arXiv:2506.11242', 'title': 'A Causal Lens for Learning Long-term Fair Policies', 'authors': 'Jacob Lear, Lu Zhang', 'link': 'https://arxiv.org/abs/2506.11242', 'abstract': 'Fairness-aware learning studies the development of algorithms that avoid discriminatory decision outcomes despite biased training data. While most studies have concentrated on immediate bias in static contexts, this paper highlights the importance of investigating long-term fairness in dynamic decision-making systems while simultaneously considering instantaneous fairness requirements. In the context of reinforcement learning, we propose a general framework where long-term fairness is measured by the difference in the average expected qualification gain that individuals from different groups could this http URL, through a causal lens, we decompose this metric into three components that represent the direct impact, the delayed impact, as well as the spurious effect the policy has on the qualification gain. We analyze the intrinsic connection between these components and an emerging fairness notion called benefit fairness that aims to control the equity of outcomes in decision-making. Finally, we develop a simple yet effective approach for balancing various fairness notions.', 'abstract_zh': '公平意识的学习研究旨在开发算法以避免在偏倚训练数据下产生歧视性的决策结果。尽管大多数研究集中在静态情境中的即时偏倚，本文强调了在动态决策系统中同时研究长期公平性的重要性。在强化学习的背景下，我们提出了一种通用框架，通过该框架，长期公平性通过不同群体个体之间预期资格增益平均值的差异进行衡量。从因果视角分解这一指标为直接影响、延迟影响以及政策对资格增益的虚假效应三个部分。我们分析了这些组成部分与一种新兴的公平性概念——收益公平之间的内在联系，该概念旨在控制决策中结果的公平性。最后，我们开发了一种简单而有效的方法来平衡各种公平性概念。', 'title_zh': '一种学习长期公平政策的因果视角'}
{'arxiv_id': 'arXiv:2506.11238', 'title': 'uPVC-Net: A Universal Premature Ventricular Contraction Detection Deep Learning Algorithm', 'authors': 'Hagai Hamami, Yosef Solewicz, Daniel Zur, Yonatan Kleerekoper, Joachim A. Behar', 'link': 'https://arxiv.org/abs/2506.11238', 'abstract': 'Introduction: Premature Ventricular Contractions (PVCs) are common cardiac arrhythmias originating from the ventricles. Accurate detection remains challenging due to variability in electrocardiogram (ECG) waveforms caused by differences in lead placement, recording conditions, and population demographics. Methods: We developed uPVC-Net, a universal deep learning model to detect PVCs from any single-lead ECG recordings. The model is developed on four independent ECG datasets comprising a total of 8.3 million beats collected from Holter monitors and a modern wearable ECG patch. uPVC-Net employs a custom architecture and a multi-source, multi-lead training strategy. For each experiment, one dataset is held out to evaluate out-of-distribution (OOD) generalization. Results: uPVC-Net achieved an AUC between 97.8% and 99.1% on the held-out datasets. Notably, performance on wearable single-lead ECG data reached an AUC of 99.1%. Conclusion: uPVC-Net exhibits strong generalization across diverse lead configurations and populations, highlighting its potential for robust, real-world clinical deployment.', 'abstract_zh': 'Introduction: 房室传导阻滞（PVCs）是起源于心室的常见心律失常。由于电心图（ECG）波形因导联放置、记录条件和人口统计学差异而产生的变化，准确检测仍具有挑战性。', 'title_zh': 'uPVC-Net: 一种通用的提前发生的室性期前收缩检测深度学习算法'}
{'arxiv_id': 'arXiv:2506.11214', 'title': 'Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise', 'authors': 'Chuan He, Zhaosong Lu, Defeng Sun, Zhanwang Deng', 'link': 'https://arxiv.org/abs/2506.11214', 'abstract': 'In this paper, we propose practical normalized stochastic first-order methods with Polyak momentum, multi-extrapolated momentum, and recursive momentum for solving unconstrained optimization problems. These methods employ dynamically updated algorithmic parameters and do not require explicit knowledge of problem-dependent quantities such as the Lipschitz constant or noise bound. We establish first-order oracle complexity results for finding approximate stochastic stationary points under heavy-tailed noise and weakly average smoothness conditions -- both of which are weaker than the commonly used bounded variance and mean-squared smoothness assumptions. Our complexity bounds either improve upon or match the best-known results in the literature. Numerical experiments are presented to demonstrate the practical effectiveness of the proposed methods.', 'abstract_zh': '在本文中，我们提出了一种实用的正则化随机一阶方法，该方法结合了Polyak动量、多外推动量和递归动量，用于求解无约束优化问题。这些方法采用动态更新的算法参数，无需显式知道如Lipschitz常数或噪声界等问题依赖量。我们在重尾噪声和弱平均光滑条件下建立了寻找近似随机稳定点的一阶先验复杂度结果，这两种条件均弱于常用的有界方差和均方光滑假设。我们的复杂度界要么改进了要么匹配了文献中已知的最佳结果。数值实验展示了所提方法的实际有效性。', 'title_zh': '重尾噪声下归一化随机一阶方法带动量的复杂性'}
{'arxiv_id': 'arXiv:2506.11182', 'title': 'Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data', 'authors': 'Azim Dehghani Amirabad, Yanfei Zhang, Artem Moskalev, Sowmya Rajesh, Tommaso Mansi, Shuwei Li, Mangal Prakash, Rui Liao', 'link': 'https://arxiv.org/abs/2506.11182', 'abstract': 'Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12 genome editing but remains challenging due to limited data, variation across protospacer adjacent motifs (PAMs-short sequence requirements for Cas binding), and reliance on large-scale training. We investigate whether pre-trained biological foundation model originally trained on transcriptomic data can improve gRNA activity estimation even without domain-specific pre-training. Using embeddings from existing RNA foundation model as input to lightweight regressor, we show substantial gains over traditional baselines. We also integrate chromatin accessibility data to capture regulatory context, improving performance further. Our results highlight the effectiveness of pre-trained foundation models and chromatin accessibility data for gRNA activity prediction.', 'abstract_zh': '基于预训练生物基础模型和染色质可及性数据的gRNA活性预测', 'title_zh': '使用基础模型和染色质可及性数据建模CRISPR-Cas12活性'}
{'arxiv_id': 'arXiv:2506.11179', 'title': 'Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention', 'authors': 'Md Mynoddin, Troyee Dev, Rishita Chakma', 'link': 'https://arxiv.org/abs/2506.11179', 'abstract': "Mental stress has become a pervasive factor affecting cognitive health and overall well-being, necessitating the development of robust, non-invasive diagnostic tools. Electroencephalogram (EEG) signals provide a direct window into neural activity, yet their non-stationary and high-dimensional nature poses significant modeling challenges. Here we introduce Brain2Vec, a new deep learning tool that classifies stress states from raw EEG recordings using a hybrid architecture of convolutional, recurrent, and attention mechanisms. The model begins with a series of convolutional layers to capture localized spatial dependencies, followed by an LSTM layer to model sequential temporal patterns, and concludes with an attention mechanism to emphasize informative temporal regions. We evaluate Brain2Vec on the DEAP dataset, applying bandpass filtering, z-score normalization, and epoch segmentation as part of a comprehensive preprocessing pipeline. Compared to traditional CNN-LSTM baselines, our proposed model achieves an AUC score of 0.68 and a validation accuracy of 81.25%. These findings demonstrate Brain2Vec's potential for integration into wearable stress monitoring platforms and personalized healthcare systems.", 'abstract_zh': '心理压力已成为影响认知健康和整体福祉的普遍因素，需要开发稳健的非侵入性诊断工具。脑电图（EEG）信号直接揭示了神经活动，但其非平稳性和高维性带来了显著的建模挑战。我们引入了Brain2Vec，这是一种新的深度学习工具，通过结合卷积、循环和注意力机制，从原始EEG记录中分类压力状态。该模型首先使用一系列卷积层来捕捉局部空间依赖性，然后通过一个LSTM层来建模序列时间模式，并以注意机制结束，以强调信息性的时间区域。我们对Brain2Vec进行了评估，使用DEAP数据集，并在全面的预处理流水线中应用带通滤波、z分数标准化和时段分割。相比传统的CNN-LSTM基线，我们提出的模型获得了AUC分数为0.68和验证准确率为81.25%的结果。这些发现表明Brain2Vec有潜力集成到可穿戴压力监测平台和个人化健康系统中。', 'title_zh': 'Brain2Vec：基于CNN-LSTM-Attention的EEG-Based压力检测深度学习框架'}
{'arxiv_id': 'arXiv:2506.11172', 'title': 'Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning', 'authors': 'Xue Zhou, Dapeng Man, Chen Xu, Fanyi Zeng, Tao Liu, Huan Wang, Shucheng He, Chaoyang Gao, Wu Yang', 'link': 'https://arxiv.org/abs/2506.11172', 'abstract': "Offline reinforcement learning (RL) heavily relies on the coverage of pre-collected data over the target policy's distribution. Existing studies aim to improve data-policy coverage to mitigate distributional shifts, but overlook security risks from insufficient coverage, and the single-step analysis is not consistent with the multi-step decision-making nature of offline RL. To address this, we introduce the sequence-level concentrability coefficient to quantify coverage, and reveal its exponential amplification on the upper bound of estimation errors through theoretical analysis. Building on this, we propose the Collapsing Sequence-Level Data-Policy Coverage (CSDPC) poisoning attack. Considering the continuous nature of offline RL data, we convert state-action pairs into decision units, and extract representative decision patterns that capture multi-step behavior. We identify rare patterns likely to cause insufficient coverage, and poison them to reduce coverage and exacerbate distributional shifts. Experiments show that poisoning just 1% of the dataset can degrade agent performance by 90%. This finding provides new perspectives for analyzing and safeguarding the security of offline RL.", 'abstract_zh': '基于序列级收敛系数的离线强化学习数据污染攻击', 'title_zh': '基于中毒攻击的 Offline Reinforcement Learning 中的序列级数据-策略覆盖率坍塌'}
{'arxiv_id': 'arXiv:2506.11170', 'title': 'PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation', 'authors': 'Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen', 'link': 'https://arxiv.org/abs/2506.11170', 'abstract': 'Multivariate time series data, collected across various fields such as manufacturing and wearable technology, exhibit states at multiple levels of granularity, from coarse-grained system behaviors to fine-grained, detailed events. Effectively segmenting and integrating states across these different granularities is crucial for tasks like predictive maintenance and performance optimization. However, existing time series segmentation methods face two key challenges: (1) the inability to handle multiple levels of granularity within a unified model, and (2) limited adaptability to new, evolving patterns in dynamic environments. To address these challenges, we propose PromptTSS, a novel framework for time series segmentation with multi-granularity states. PromptTSS uses a unified model with a prompting mechanism that leverages label and boundary information to guide segmentation, capturing both coarse- and fine-grained patterns while adapting dynamically to unseen patterns. Experiments show PromptTSS improves accuracy by 24.49% in multi-granularity segmentation, 17.88% in single-granularity segmentation, and up to 599.24% in transfer learning, demonstrating its adaptability to hierarchical states and evolving time series dynamics.', 'abstract_zh': '多粒度状态的多变量时间序列分割方法：PromptTSS', 'title_zh': 'PromptTSS: 一种基于提示的交互式多粒度时间序列分割方法'}
{'arxiv_id': 'arXiv:2506.11165', 'title': 'Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data', 'authors': 'Almustapha A. Wakili, Babajide J. Asaju, Woosub Jung', 'link': 'https://arxiv.org/abs/2506.11165', 'abstract': 'This paper compares the performance of BiLSTM and CNN+GRU deep learning models for Human Activity Recognition (HAR) on two WiFi-based Channel State Information (CSI) datasets: UT-HAR and NTU-Fi HAR. The findings indicate that the CNN+GRU model has a higher accuracy on the UT-HAR dataset (95.20%) thanks to its ability to extract spatial features. In contrast, the BiLSTM model performs better on the high-resolution NTU-Fi HAR dataset (92.05%) by extracting long-term temporal dependencies more effectively. The findings strongly emphasize the critical role of dataset characteristics and preprocessing techniques in model performance improvement. We also show the real-world applicability of such models in applications like healthcare and intelligent home systems, highlighting their potential for unobtrusive activity recognition.', 'abstract_zh': '基于WiFi信道状态信息（CSI）的UT-HAR和NTU-Fi HAR数据集上BiLSTM和CNN+GRU深度学习模型在人体活动识别（HAR）中的性能比较：数据集特性与预处理技术的重要性及实际应用', 'title_zh': '基于WiFi CSI数据的人体活动识别中BiLSTM和CNN+GRU方法的评估'}
{'arxiv_id': 'arXiv:2506.11139', 'title': 'Grids Often Outperform Implicit Neural Representations', 'authors': 'Namhoon Kim, Sara Fridovich-Keil', 'link': 'https://arxiv.org/abs/2506.11139', 'abstract': 'Implicit Neural Representations (INRs) have recently shown impressive results, but their fundamental capacity, implicit biases, and scaling behavior remain poorly understood. We investigate the performance of diverse INRs across a suite of 2D and 3D real and synthetic signals with varying effective bandwidth, as well as both overfitting and generalization tasks including tomography, super-resolution, and denoising. By stratifying performance according to model size as well as signal type and bandwidth, our results shed light on how different INR and grid representations allocate their capacity. We find that, for most tasks and signals, a simple regularized grid with interpolation trains faster and to higher quality than any INR with the same number of parameters. We also find limited settings where INRs outperform grids -- namely fitting signals with underlying lower-dimensional structure such as shape contours -- to guide future use of INRs towards the most advantageous applications. Code and synthetic signals used in our analysis are available at this https URL.', 'abstract_zh': '隐神经表示（INRs）最近取得了令人印象深刻的成果，但它们的基本容量、隐式偏见及其缩放行为仍未被充分理解。我们通过一套2D和3D真实和合成信号的研究，探索了不同INRs在具有变化的有效带宽下的性能，并包括了从属拟合和泛化任务，如计算机断层扫描、超分辨率和去噪。根据模型大小、信号类型和带宽分层分析性能，我们的结果揭示了不同INR和网格表示如何分配其容量。我们发现，在大多数任务和信号中，简单的正则化插值网格训练速度更快且效果更优，具有相同参数数量的任何INR都不及之。我们还发现了一些INRs在网格上占优的情况，即拟合具有潜在低维结构（如形状轮廓）的信号，这可以指导未来如何更好地利用INRs。用于分析的代码和合成信号可在以下网址获取：this https URL。', 'title_zh': '网格往往优于隐式神经表示。'}
{'arxiv_id': 'arXiv:2506.11130', 'title': 'A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data', 'authors': 'Cheng Kang Chou, Chan-Jan Hsu, Ho-Lam Chung, Liang-Hsuan Tseng, Hsi-Chun Cheng, Yu-Kuan Fu, Kuan Po Huang, Hung-Yi Lee', 'link': 'https://arxiv.org/abs/2506.11130', 'abstract': 'We propose a self-refining framework that enhances ASR performance with only unlabeled datasets. The process starts with an existing ASR model generating pseudo-labels on unannotated speech, which are then used to train a high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs are bootstrapped into the original ASR system, completing the closed-loop self-improvement cycle. We demonstrated the effectiveness of the framework on Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a moderate amount of text data, and synthetic content from the AI models, we adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching benchmarks compared to Whisper. Results highlight the framework as a compelling alternative to pseudo-labeling self-distillation approaches and provides a practical pathway for improving ASR performance in low-resource or domain-specific settings.', 'abstract_zh': '我们提出一种自修 refinements 框架，仅使用未标注数据提升ASR性能。该过程始于现有ASR模型生成未注音 speech 的伪标签，进而用于训练高保真文本到语音(TTS)系统。之后，合成语音文本对被引导进入原始ASR系统，完成闭环自我改进循环。我们在台湾 Mandarin 语音上展示了该框架的有效性。利用6000小时未标注 speech、适量文本数据以及AI模型生成的合成内容，我们将Whisper-large-v2调整为专门模型Twister。Twister在 Mandarin 任务上的错误率最多降低20%，在 Mandarin-English 切换任务上最多降低50%，相较于Whisper。结果表明该框架是伪标签自我精炼方法的一个有吸引力的替代方案，并为在低资源或领域特定设置中提高ASR性能提供了实用途径。', 'title_zh': '一种增强ASR的自精炼框架：使用TTS合成功音数据'}
{'arxiv_id': 'arXiv:2506.11127', 'title': 'GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions', 'authors': 'Wenkang Han, Zhixiong Zeng, Jing Huang, Shu Jiang, Liming Zheng, Longrong Yang, Haibo Qiu, Chang Yao, Jingyuan Chen, Lin Ma', 'link': 'https://arxiv.org/abs/2506.11127', 'abstract': "Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the first end-to-end autonomous GUI agent that directly accepts speech instructions and on-device screenshots to predict actions. Confronted with the scarcity of speech-based GUI agent datasets, we initially generated high-quality speech instructions for training by leveraging a random timbre text-to-speech (TTS) model to convert existing text instructions. We then develop GUIRoboTron-Speech's capabilities through progressive grounding and planning training stages. A key contribution is a heuristic mixed-instruction training strategy designed to mitigate the modality imbalance inherent in pre-trained foundation models. Comprehensive experiments on several benchmark datasets validate the robust and superior performance of GUIRoboTron-Speech, demonstrating the significant potential and widespread applicability of speech as an effective instruction modality for driving GUI agents. Our code and datasets are available at this https URL.", 'abstract_zh': 'autonomously驱动的图形用户界面代理通过语音指令和设备截图直接预测操作，革新人机交互，但仍受制于文本指令依赖，尤其在免手动场景下受到限制。为解决这一问题，我们提出GUIRoboTron-Speech，这是第一个端到端自主图形用户界面（GUI）代理，可以直接接受语音指令并利用设备截图预测操作。面对语音基座模型数据集稀缺的挑战，我们利用随机音色文本转语音（TTS）模型将现有文本指令转换为高质量语音指令进行训练。通过逐步的锚定和规划训练阶段，逐步提升GUIRoboTron-Speech的功能。一个关键贡献是为应对预训练基座模型固有的模态不平衡问题而设计的启发式混合指令训练策略。在多个基准数据集上的全面实验验证了GUIRoboTron-Speech的 robust性能和优越性，展示了语音作为GUI代理有效指令模态的巨大潜力和广泛应用前景。我们的代码和数据集可在该网址获取。', 'title_zh': 'GUIRoboTron-语音: 基于语音指令的自动化GUI代理研究'}
{'arxiv_id': 'arXiv:2506.11117', 'title': 'ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research', 'authors': 'Junyong Lin, Lu Dai, Ruiqian Han, Yijie Sui, Ruilin Wang, Xingliang Sun, Qinglin Wu, Min Feng, Hao Liu, Hui Xiong', 'link': 'https://arxiv.org/abs/2506.11117', 'abstract': "Scientific researchers need intensive information about datasets to effectively evaluate and develop theories and methodologies. The information needs regarding datasets are implicitly embedded in particular research tasks, rather than explicitly expressed in search queries. However, existing scientific retrieval and question-answering (QA) datasets typically address straightforward questions, which do not align with the distribution of real-world research inquiries. To bridge this gap, we developed ScIRGen, a dataset generation framework for scientific QA \\& retrieval that more accurately reflects the information needs of professional science researchers, and uses it to create a large-scale scientific retrieval-augmented generation (RAG) dataset with realistic queries, datasets and papers. Technically, we designed a dataset-oriented information extraction method that leverages academic papers to augment the dataset representation. We then proposed a question generation framework by employing cognitive taxonomy to ensure the quality of synthesized questions. We also design a method to automatically filter synthetic answers based on the perplexity shift of LLMs, which is highly aligned with human judgment of answers' validity. Collectively, these methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We benchmarked representative methods on the ScIRGen-Geo dataset for their question-answering and retrieval capabilities, finding out that current methods still suffer from reasoning from complex questions. This work advances the development of more sophisticated tools to support the intricate information needs of the scientific community.", 'abstract_zh': '科学研究人员需要对数据集有详尽的信息以便有效评估和开发理论与方法。数据集的信息需求隐含地嵌入特定的研究任务中，而不是显式地体现在搜索查询中。然而，现有的科学研究检索和问答（QA）数据集通常仅解决简单问题，与实际研究询问的分布不匹配。为了弥合这一差距，我们开发了ScIRGen，一个面向科学QA与检索的的数据集生成框架，更准确地反映了专业科学研究人员的信息需求，并利用该框架创建了一个包含现实询问、数据集和论文的大规模科学检索增强生成（RAG）数据集。技术上，我们设计了一种以数据集为中心的信息提取方法，利用学术论文来增强数据集的表示。然后，我们通过采用认知分类法提出了一个问题生成框架，以确保合成问题的质量。我们还设计了一种方法，根据大型语言模型的困惑度变化自动筛选合成答案，这与人工判断答案的有效性高度一致。这些方法共同 culminated 在创建了包含 61,000 个问答数据的 ScIRGen-Geo 数据集。我们对代表性的方法在 ScIRGen-Geo 数据集上的问答和检索能力进行了基准测试，发现当前的方法仍然难以应对复杂问题的推理。这项工作推动了更复杂的工具的发展，以支持科学研究社区复杂的信息化需求。', 'title_zh': 'ScIRGen: 合成面向科学研究的现实且大规模RAG数据集'}
{'arxiv_id': 'arXiv:2506.11115', 'title': 'Incorporating Domain Knowledge into Materials Tokenization', 'authors': 'Yerim Oh, Jun-Hyung Park, Junho Kim, SungHo Kim, SangKeun Lee', 'link': 'https://arxiv.org/abs/2506.11115', 'abstract': 'While language models are increasingly utilized in materials science, typical models rely on frequency-centric tokenization methods originally developed for natural language processing. However, these methods frequently produce excessive fragmentation and semantic loss, failing to maintain the structural and semantic integrity of material concepts. To address this issue, we propose MATTER, a novel tokenization approach that integrates material knowledge into tokenization. Based on MatDetector trained on our materials knowledge base and a re-ranking method prioritizing material concepts in token merging, MATTER maintains the structural integrity of identified material concepts and prevents fragmentation during tokenization, ensuring their semantic meaning remains intact. The experimental results demonstrate that MATTER outperforms existing tokenization methods, achieving an average performance gain of $4\\%$ and $2\\%$ in the generation and classification tasks, respectively. These results underscore the importance of domain knowledge for tokenization strategies in scientific text processing. Our code is available at this https URL', 'abstract_zh': '尽管语言模型在材料科学中的应用日益增多，典型的模型通常依赖于最初为自然语言处理设计的频率为中心的词元化方法。然而，这些方法往往导致过度切分和语义损失，无法保持材料概念的结构和语义完整性。为解决这一问题，我们提出了MATTER，这是一种新颖的词元化方法，将材料知识集成到词元化过程中。基于在材料知识库上训练的MatDetector和一个优先合并涉及材料概念的词元的重新排名方法，MATTER在词元化过程中保持了识别的材料概念的结构完整性，并防止了词元化过程中的过度切分，从而确保它们的语义意义保持不变。实验证明，MATTER在生成任务和分类任务中分别平均提高了$4\\%$和$2\\%$的性能，这些结果强调了科学文本处理中的词元化策略中领域知识的重要性。我们的代码可在此处访问。', 'title_zh': '将领域知识融入材料标记化'}
{'arxiv_id': 'arXiv:2506.11107', 'title': 'Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor', 'authors': 'Weibo Gao, Qi Liu, Rui Li, Yuze Zhao, Hao Wang, Linan Yre, Fangzhou Yao, Zheng Zhang', 'link': 'https://arxiv.org/abs/2506.11107', 'abstract': "Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners' mastery levels of programming knowledge based on their coding activities, facilitating more effective and personalized programming education. However, current PKT studies primarily focus on the implicit relationship between code content and knowledge assessment, often overlooking two types of noise signals in long-term programming activities: unwanted signals from unrelated submissions and weak signals from minor modifications. This practical challenge significantly limits model performance and application. To address this issue, we propose Coda, a Code graph-based tuning adaptor designed to enhance existing PKT models by identifying and mitigating the impact of noise. Specifically, Coda first transforms the loose code sequences submitted by each learner into a compact code graph. By leveraging this code graph, unwanted signals can be identified from a semantic similarity perspective. We then apply a cluster-aware GCN to the code graph, which improves the discrimination of weak signals and enables their clustering for identification. Finally, a lightweight yet effective adaptor is incorporated into the PKT task through optimization with two noise feature-based constraints and a navigational regularization term, to correct knowledge states affected by noise. It is worth mentioning that the Coda framework is model-agnostic and can be adapted to most existing PKT solutions. Extensive experimental results on four real-world datasets demonstrate that Coda effectively performs the PKT task in the presence of noisy programming records, outperforming typical baselines.", 'abstract_zh': '编程知识追踪（PKT）旨在基于学习者的编码活动动态诊断其编程知识的掌握水平，促进更有效的个性化编程教育。然而，当前的PKT研究主要关注代码内容与知识评估之间的隐含关系，常常忽视长时间编程活动中两种类型的噪声信号：与提交内容无关的信号和小规模修改产生的弱信号。这一实际挑战显著限制了模型的性能和应用。为解决这一问题，我们提出了一种名为Coda的基于代码图的调优适配器，旨在通过识别和减轻噪声的影响来增强现有的PKT模型。具体而言，Coda首先将每位学习者提交的松散代码序列转换为紧凑的代码图。通过利用这一代码图，可以从语义相似性的角度识别出不需要的信号。随后，我们使用意识聚类的图卷积神经网络（GCN）应用于代码图，从而提高对弱信号的区分能力，并使它们能够被聚类识别。最后，通过优化引入两种基于噪声特征的约束和导航正则化项，一个轻量而有效的适配器被整合到PKT任务中，以纠正受到噪声影响的知识状态。值得一提的是，Coda框架对模型具有普适性，可以适应大多数现有的PKT解决方案。在四个真实世界数据集上的广泛实验结果表明，Coda能够在存在噪声编程记录的情况下有效执行PKT任务，优于典型的基础模型。', 'title_zh': '基于代码图的调优适配器编程知识清理'}
{'arxiv_id': 'arXiv:2506.11100', 'title': 'An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry', 'authors': 'Tianle Wang, Jorge Ramirez, Cristina Garcia-Cardona, Thomas Proffen, Shantenu Jha, Sudip K. Seal', 'link': 'https://arxiv.org/abs/2506.11100', 'abstract': 'Structure determination workloads in neutron diffractometry are computationally expensive and routinely require several hours to many days to determine the structure of a material from its neutron diffraction patterns. The potential for machine learning models trained on simulated neutron scattering patterns to significantly speed up these tasks have been reported recently. However, the amount of simulated data needed to train these models grows exponentially with the number of structural parameters to be predicted and poses a significant computational challenge. To overcome this challenge, we introduce a novel batch-mode active learning (AL) policy that uses uncertainty sampling to simulate training data drawn from a probability distribution that prefers labelled examples about which the model is least certain. We confirm its efficacy in training the same models with about 75% less training data while improving the accuracy. We then discuss the design of an efficient stream-based training workflow that uses this AL policy and present a performance study on two heterogeneous platforms to demonstrate that, compared with a conventional training workflow, the streaming workflow delivers about 20% shorter training time without any loss of accuracy.', 'abstract_zh': '中子衍射结构确定的工作负载计算密集型，通常需要数小时到数天才能从材料的中子衍射图中确定其结构。近期有报道显示，基于模拟中子散射图的机器学习模型有可能显著加速这些任务。然而，随着需要预测的结构参数数量的增加，用于训练这些模型的模拟数据量呈指数增长，带来了显著的计算挑战。为克服这一挑战，我们提出了一种新颖的批处理模式主动学习(AL)策略，利用不确定性取样模拟从模型最不确定的标签样本中抽取的概率分布数据。我们验证了该策略在使用约75%少的训练数据的同时提高了准确性。随后，我们讨论了一种高效的流式训练工作流的设计，该工作流使用这种AL策略，并在两个异构平台上进行了性能研究，表明与传统的训练工作流相比，流式工作流可以在不牺牲准确性的前提下将训练时间缩短约20%。', 'title_zh': '基于主动学习的流式管道： neutrons 衍射结构寻找模型的高效数据训练'}
{'arxiv_id': 'arXiv:2506.11099', 'title': 'Knowledge Graph Embeddings with Representing Relations as Annular Sectors', 'authors': 'Huiling Zhu, Yingqi Zeng', 'link': 'https://arxiv.org/abs/2506.11099', 'abstract': 'Knowledge graphs (KGs), structured as multi-relational data of entities and relations, are vital for tasks like data analysis and recommendation systems. Knowledge graph completion (KGC), or link prediction, addresses incompleteness of KGs by inferring missing triples (h, r, t). It is vital for downstream applications. Region-based embedding models usually embed entities as points and relations as geometric regions to accomplish the task. Despite progress, these models often overlook semantic hierarchies inherent in entities. To solve this problem, we propose SectorE, a novel embedding model in polar coordinates. Relations are modeled as annular sectors, combining modulus and phase to capture inference patterns and relation attributes. Entities are embedded as points within these sectors, intuitively encoding hierarchical structure. Evaluated on FB15k-237, WN18RR, and YAGO3-10, SectorE achieves competitive performance against various kinds of models, demonstrating strengths in semantic modeling capability.', 'abstract_zh': '基于区域的嵌入模型通常将实体嵌入为点，将关系嵌入为几何区域以完成任务。尽管取得了进展，这些模型往往忽略了实体中存在的语义层次结构。为解决这一问题，我们提出了一种新的极坐标嵌入模型SectorE。关系被建模为环形扇区，结合模数和相位来捕捉推理模式和关系属性。实体嵌入为此类扇区内的点，直观地编码层次结构。SectorE在FB15k-237、WN18RR和YAGO3-10上的评估结果表明，该模型在语义建模能力方面具有竞争力。', 'title_zh': '基于表示关系为环形扇区的知识图嵌入'}
{'arxiv_id': 'arXiv:2506.11095', 'title': 'Persistent Homology of Topic Networks for the Prediction of Reader Curiosity', 'authors': 'Manuel D. S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley Jach, Kou Murayama', 'link': 'https://arxiv.org/abs/2506.11095', 'abstract': "Reader curiosity, the drive to seek information, is crucial for textual engagement, yet remains relatively underexplored in NLP. Building on Loewenstein's Information Gap Theory, we introduce a framework that models reader curiosity by quantifying semantic information gaps within a text's semantic structure. Our approach leverages BERTopic-inspired topic modeling and persistent homology to analyze the evolving topology (connected components, cycles, voids) of a dynamic semantic network derived from text segments, treating these features as proxies for information gaps. To empirically evaluate this pipeline, we collect reader curiosity ratings from participants (n = 49) as they read S. Collins's ''The Hunger Games'' novel. We then use the topological features from our pipeline as independent variables to predict these ratings, and experimentally show that they significantly improve curiosity prediction compared to a baseline model (73% vs. 30% explained deviance), validating our approach. This pipeline offers a new computational method for analyzing text structure and its relation to reader engagement.", 'abstract_zh': '读者好奇心，即寻求信息的驱动力，对于文本参与度至关重要，但在NLP中仍相对未被充分探索。基于Loewenstein的信息缺口理论，我们提出了一种框架，通过量化文本语义结构中的语义信息缺口来建模读者好奇心。该方法借鉴了BERTopic启发的主题模型和持久同调分析，以分析从文本片段中.derived的动态语义网络的演进拓扑（连通分支、环、空洞），将这些特征作为信息缺口的代理。为了实证评估该管道，我们从49名参与者阅读S.柯林斯的《饥饿游戏》小说时收集了读者好奇心评分。然后，我们使用该管道的拓扑特征作为自变量来预测这些评分，并实验证明这些特征在好奇心预测方面显著优于基准模型（解释偏差分别为73%和30%），验证了该方法。该管道为分析文本结构及其与读者参与度的关系提供了新的计算方法。', 'title_zh': '基于主题网络持久同调的读者好奇心预测'}
{'arxiv_id': 'arXiv:2506.11085', 'title': 'LeanExplore: A search engine for Lean 4 declarations', 'authors': 'Justin Asher', 'link': 'https://arxiv.org/abs/2506.11085', 'abstract': "The expanding Lean 4 ecosystem poses challenges for navigating its vast libraries. This paper introduces LeanExplore, a search engine for Lean 4 declarations. LeanExplore enables users to semantically search for statements, both formally and informally, across select Lean 4 packages (including Batteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is powered by a hybrid ranking strategy, integrating scores from a multi-source semantic embedding model (capturing conceptual meaning from formal Lean code, docstrings, AI-generated informal translations, and declaration titles), BM25+ for keyword-based lexical relevance, and a PageRank-based score reflecting declaration importance and interconnectedness. The search engine is accessible via a dedicated website (this https URL) and a Python API (this https URL). Furthermore, the database can be downloaded, allowing users to self-host the service. LeanExplore integrates easily with LLMs via the model context protocol (MCP), enabling users to chat with an AI assistant about Lean declarations or utilize the search engine for building theorem-proving agents. This work details LeanExplore's architecture, data processing, functionalities, and its potential to enhance Lean 4 workflows and AI-driven mathematical research", 'abstract_zh': 'Lean 4 生态系统的扩展对导航其庞大的库构成挑战。本文介绍了 LeanExplore，一个用于搜索 Lean 4 声明的搜索引擎。LeanExplore 允许用户在筛选的 Lean 4 包（包括 Batteries、Init、Lean、Mathlib、PhysLean 和 Std）中对正式和非正式的语句进行语义搜索。搜索功能由一种混合排名策略驱动，该策略结合了多源语义嵌入模型（捕捉正式 Lean 代码、文档字符串、AI 生成的非正式翻译和声明标题的概念意义）的评分、基于关键词的词汇相关性 BM25+ 评分，以及反映声明重要性和相互关联性的 PageRank 评分。该搜索引擎可通过专用网站（此 https URL）和 Python API（此 https URL）访问。此外，数据库可以下载，允许用户自行托管该服务。LeanExplore 通过模型上下文协议（MCP）易于与大语言模型集成，使用户能够与关于 Lean 声明的 AI 助手进行对话或将搜索引擎用于构建定理证明代理。本文详细介绍了 LeanExplore 的架构、数据处理、功能及其增强 Lean 4 工作流程和 AI 驱动的数学研究的潜力。', 'title_zh': 'LeanExplore: 一个用于Lean 4断言的搜索引擎'}
{'arxiv_id': 'arXiv:2506.11071', 'title': 'Embedded Acoustic Intelligence for Automotive Systems', 'authors': 'Renjith Rajagopal, Peter Winzell, Sladjana Strbac, Konstantin Lindström, Petter Hörling, Faisal Kohestani, Niloofar Mehrzad', 'link': 'https://arxiv.org/abs/2506.11071', 'abstract': 'Transforming sound insights into actionable streams of data, this abstract leverages findings from degree thesis research to enhance automotive system intelligence, enabling us to address road type [1].By extracting and interpreting acoustic signatures from microphones installed within the wheelbase of a car, we focus on classifying road this http URL deep neural networks and feature extraction powered by pre-trained models from the Open AI ecosystem (via Hugging Face [2]), our approach enables Autonomous Driving and Advanced Driver- Assistance Systems (AD/ADAS) to anticipate road surfaces, support adaptive learning for active road noise cancellation, and generate valuable insights for urban planning. The results of this study were specifically captured to support a compelling business case for next-generation automotive systems. This forward-looking approach not only promises to redefine passenger comfort and improve vehicle safety, but also paves the way for intelligent, data-driven urban road management, making the future of mobility both achievable and sustainable.', 'abstract_zh': '将声音见解转化为可操作的数据流，本文摘要利用学位论文的研究成果来增强汽车系统智能，以应对不同道路类型的需求。通过从汽车轮距内安装的麦克风中提取和解释声学特征，我们专注于道路分类。借助开放AI生态系统的预训练模型（通过Hugging Face）驱动的深度神经网络和特征提取技术，我们的方法使自动驾驶和高级驾驶辅助系统（AD/ADAS）能够预测道路表面、支持自适应学习以实现主动降噪，并为城市规划提供有价值的见解。本研究的结果特别支持下一代汽车系统的商业案例。这一前瞻性方法不仅有望重新定义乘客舒适性和提升车辆安全性，还铺就了智能化、数据驱动的城市道路管理之路，使未来的出行既可行又可持续。', 'title_zh': '汽车系统中的嵌入式声学智能'}
{'arxiv_id': 'arXiv:2506.11069', 'title': 'Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition', 'authors': 'Tao Zhong, Mengzhe Geng, Shujie Hu, Guinan Li, Xunying Liu', 'link': 'https://arxiv.org/abs/2506.11069', 'abstract': 'Accurate recognition of dysarthric and elderly speech remains challenging to date. While privacy concerns have driven a shift from centralized approaches to federated learning (FL) to ensure data confidentiality, this further exacerbates the challenges of data scarcity, imbalanced data distribution and speaker heterogeneity. To this end, this paper conducts a systematic investigation of regularized FL techniques for privacy-preserving dysarthric and elderly speech recognition, addressing different levels of the FL process by 1) parameter-based, 2) embedding-based and 3) novel loss-based regularization. Experiments on the benchmark UASpeech dysarthric and DementiaBank Pitt elderly speech corpora suggest that regularized FL systems consistently outperform the baseline FedAvg system by statistically significant WER reductions of up to 0.55\\% absolute (2.13\\% relative). Further increasing communication frequency to one exchange per batch approaches centralized training performance.', 'abstract_zh': '准确识别失语症和老年语音仍具有挑战性：基于正则化的联邦学习技术在保护隐私的失语症和老年语音识别中的系统研究', 'title_zh': '正则化联邦学习在隐私保护的构音障碍和老年言语识别中的应用'}
{'arxiv_id': 'arXiv:2506.11066', 'title': 'CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval', 'authors': 'Jiahui Geng, Fengyu Cai, Shaobo Cui, Qing Li, Liangwei Chen, Chenyang Lyu, Haonan Li, Derui Zhu, Walter Pretschner, Heinz Koeppl, Fakhri Karray', 'link': 'https://arxiv.org/abs/2506.11066', 'abstract': 'Code retrieval is essential in modern software development, as it boosts code reuse and accelerates debugging. However, current benchmarks primarily emphasize functional relevance while neglecting critical dimensions of software quality. Motivated by this gap, we introduce CoQuIR, the first large-scale, multilingual benchmark specifically designed to evaluate quality-aware code retrieval across four key dimensions: correctness, efficiency, security, and maintainability. CoQuIR provides fine-grained quality annotations for 42,725 queries and 134,907 code snippets in 11 programming languages, and is accompanied by two quality-centric evaluation metrics: Pairwise Preference Accuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23 retrieval models, covering both open-source and proprietary systems, and find that even top-performing models frequently fail to distinguish buggy or insecure code from their more robust counterparts. Furthermore, we conduct preliminary investigations into training methods that explicitly encourage retrievers to recognize code quality. Using synthetic datasets, we demonstrate promising improvements in quality-aware metrics across various models, without sacrificing semantic relevance. Downstream code generation experiments further validate the effectiveness of our approach. Overall, our work highlights the importance of integrating quality signals into code retrieval systems, laying the groundwork for more trustworthy and robust software development tools.', 'abstract_zh': 'Code Retrieval评估中的质量考量：CoQuIR基准的引入与应用', 'title_zh': 'CoQuIR: 一种面向代码质量的信息检索综合基准'}
{'arxiv_id': 'arXiv:2506.11064', 'title': 'PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding', 'authors': 'Jiajun He, Tomoki Toda', 'link': 'https://arxiv.org/abs/2506.11064', 'abstract': 'End-to-end automatic speech recognition (ASR) models often struggle to accurately recognize rare words. Previously, we introduced an ASR postprocessing method called error detection and context-aware error correction (ED-CEC), which leverages contextual information such as named entities and technical terms to improve the accuracy of ASR transcripts. Although ED-CEC achieves a notable success in correcting rare words, its accuracy remains low when dealing with rare words that have similar pronunciations but different spellings. To address this issue, we proposed a phoneme-augmented multimodal fusion method for context-aware error correction (PMF-CEC) method on the basis of ED-CEC, which allowed for better differentiation between target rare words and homophones. Additionally, we observed that the previous ASR error detection module suffers from overdetection. To mitigate this, we introduced a retention probability mechanism to filter out editing operations with confidence scores below a set threshold, preserving the original operation to improve error detection accuracy. Experiments conducted on five datasets demonstrated that our proposed PMF-CEC maintains reasonable inference speed while further reducing the biased word error rate compared with ED-CEC, showing a stronger advantage in correcting homophones. Moreover, our method outperforms other contextual biasing methods, and remains valuable compared with LLM-based methods in terms of faster inference and better robustness under large biasing lists.', 'abstract_zh': '端到端自动语音识别（ASR）模型往往难以准确识别稀有词汇。先前，我们引入了一种称为错误检测和基于上下文的错误修正（ED-CEC）的ASR后处理方法，该方法利用命名实体和技术术语等上下文信息以提高ASR转录的准确性。尽管ED-CEC在修正稀有词汇方面取得了显著成效，但它在处理具有相似 pronunciation 但不同拼写的稀有词汇时的准确性仍然较低。为了解决这一问题，我们在此基础上提出了一个 phoneme 增强的多模态融合方法用于基于上下文的错误修正（PMF-CEC），以更好地区分目标稀有词汇和同音词。此外，我们观察到之前的ASR错误检测模块存在过度检测的问题。为缓解这一问题，我们引入了一个保留概率机制，以过滤掉低于设定阈值信心分数的编辑操作，保留原始操作以提高错误检测准确性。在五个数据集上的实验表明，我们提出的PMF-CEC保持了合理的推理速度，同时进一步降低了有偏的单词错误率，显示出在修正同音词方面更显著的优势。此外，我们的方法优于其他上下文偏差方法，并且在更快的推理和更强大的鲁棒性方面相对于基于LLM的方法更具优势。', 'title_zh': 'PMF-CEC：音素增强多模态融合用于具有错误特定选择解码的上下文感知ASR错误修正'}
{'arxiv_id': 'arXiv:2506.11062', 'title': 'Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis', 'authors': 'Xingyu Liu, Yubin Li, Guozhang Chen', 'link': 'https://arxiv.org/abs/2506.11062', 'abstract': "A central idea in understanding brains and building artificial intelligence is that structure determines function. Yet, how the brain's complex structure arises from a limited set of genetic instructions remains a key question. The ultra high-dimensional detail of neural connections vastly exceeds the information storage capacity of genes, suggesting a compact, low-dimensional blueprint must guide brain development. Our motivation is to uncover this blueprint. We introduce a generative model, to learn this underlying representation from detailed connectivity maps of mouse cortical microcircuits. Our model successfully captures the essential structural information of these circuits in a compressed latent space. We found that specific, interpretable directions within this space directly relate to understandable network properties. Building on this, we demonstrate a novel method to controllably generate new, synthetic microcircuits with desired structural features by navigating this latent space. This work offers a new way to investigate the design principles of neural circuits and explore how structure gives rise to function, potentially informing the development of more advanced artificial neural networks.", 'abstract_zh': '理解大脑和构建人工智能的一个核心思想是结构决定功能。然而，大脑的复杂结构是如何从有限的遗传指令中产生出来的仍然是一个关键问题。神经连接的超高层细节远远超过了基因的信息存储能力，这表明一个紧凑的、低维度的蓝图必须指导大脑的发展。我们的动机是揭示这个蓝图。我们提出了一种生成模型，从小鼠皮层微回路的详细连接图中学习这一潜在的表示。我们的模型成功地在压缩的潜在空间中捕捉到了这些回路的基本结构信息。我们发现，该空间中的特定、可解释的方向直接与可理解的网络特性相关。在此基础上，我们展示了通过导航该潜在空间来可控地生成具有所需结构特征的新合成微回路的新型方法。这项工作为探讨神经回路的设计原则和研究结构如何产生功能提供了一个新途径，可能为开发更高级的人工神经网络提供指导。', 'title_zh': '解码皮层微回路：潜在空间探索和可控合成的生成模型'}
{'arxiv_id': 'arXiv:2506.11058', 'title': 'Refactoring Codebases through Library Design', 'authors': 'Ziga Kovacic, Celine Lee, Justin Chiu, Wenting Zhao, Kevin Ellis', 'link': 'https://arxiv.org/abs/2506.11058', 'abstract': "Maintainable and general software allows developers to build robust applications efficiently, yet achieving these qualities often requires refactoring specialized solutions into reusable components. This challenge becomes particularly relevant as code agents become increasingly accurate at solving isolated programming problems. We investigate code agents' capacity to refactor code in ways supporting growth and reusability. We present both a method and a benchmark for refactoring: Librarian, a sample-and-rerank method for generating reusable libraries, and Minicode, a benchmark where code agents must minimize and refactor multiple independent solutions into a joint library. Compared to state-of-the-art code agents, Librarian achieves strong results on both compression and correctness on Minicode, obtaining compression rates 1.6-2x better than coding agents while also improving correctness. We open-source our code and benchmark at this https URL.", 'abstract_zh': '可维护且通用的软件能够帮助开发人员高效构建 robust 应用程序，然而，实现这些品质往往需要将专门的解决方案重构为可重用组件。随着代码代理在解决孤立编程问题方面变得越来越准确，这一挑战变得尤为相关。我们研究了代码代理在支持增长和可重用性方面的重构能力。我们提出了一种方法和基准测试：Librarian，一种通过采样和重新排名生成可重用库的方法，以及 Minicode 基准测试，在此基准测试中，代码代理必须将多个独立解决方案最小化并重构为一个联合库。与最先进的代码代理相比，Librarian 在 Minicode 上在压缩和正确性方面均取得了优异的成绩，压缩率比编码代理高 1.6-2 倍，同时还能提高正确性。我们在此开源了我们的代码和基准测试：https://this-url。', 'title_zh': '通过库设计重构代码库'}
{'arxiv_id': 'arXiv:2506.11056', 'title': 'xInv: Explainable Optimization of Inverse Problems', 'authors': 'Sean Memery, Kevin Denamganai, Anna Kapron-King, Kartic Subr', 'link': 'https://arxiv.org/abs/2506.11056', 'abstract': 'Inverse problems are central to a wide range of fields, including healthcare, climate science, and agriculture. They involve the estimation of inputs, typically via iterative optimization, to some known forward model so that it produces a desired outcome. Despite considerable development in the explainability and interpretability of forward models, the iterative optimization of inverse problems remains largely cryptic to domain experts. We propose a methodology to produce explanations, from traces produced by an optimizer, that are interpretable by humans at the abstraction of the domain. The central idea in our approach is to instrument a differentiable simulator so that it emits natural language events during its forward and backward passes. In a post-process, we use a Language Model to create an explanation from the list of events. We demonstrate the effectiveness of our approach with an illustrative optimization problem and an example involving the training of a neural network.', 'abstract_zh': '逆问题在医疗保健、气候科学和农业等领域中占据核心地位。它们涉及通过迭代优化方法估计输入，以使某个已知的前向模型产生期望的结果。尽管前向模型的解释性和可解释性取得了显著进展，但逆问题的迭代优化对领域专家来说仍然 largely 隐匿。我们提出了一种方法，通过优化器产生的轨迹生成可由人类在领域抽象层面上理解的解释。我们方法的核心思想是对可微模拟器进行仪器化，使其在正向和反向传播过程中发出自然语言事件。在后处理阶段，我们利用语言模型从事件列表中生成解释。我们通过一个示例优化问题和一个涉及神经网络训练的示例，展示了我们方法的有效性。', 'title_zh': 'xInv：可解释的逆问题优化'}
{'arxiv_id': 'arXiv:2506.11054', 'title': 'Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments', 'authors': 'Deepak Kanneganti, Sajib Mistry, Sheik Mohammad Mostakim Fattah, Aneesh Krishna, Monowar Bhuyan', 'link': 'https://arxiv.org/abs/2506.11054', 'abstract': 'The dynamic nature of Internet of Things (IoT) environments challenges the long-term effectiveness of Machine Learning as a Service (MLaaS) compositions. The uncertainty and variability of IoT environments lead to fluctuations in data distribution, e.g., concept drift and data heterogeneity, and evolving system requirements, e.g., scalability demands and resource limitations. This paper proposes an adaptive MLaaS composition framework to ensure a seamless, efficient, and scalable MLaaS composition. The framework integrates a service assessment model to identify underperforming MLaaS services and a candidate selection model to filter optimal replacements. An adaptive composition mechanism is developed that incrementally updates MLaaS compositions using a contextual multi-armed bandit optimization strategy. By continuously adapting to evolving IoT constraints, the approach maintains Quality of Service (QoS) while reducing the computational cost associated with recomposition from scratch. Experimental results on a real-world dataset demonstrate the efficiency of our proposed approach.', 'abstract_zh': '物联网环境动态性对机器学习即服务（MLaaS）组合长期有效性构成了挑战。物联网环境的不确定性与变异性导致数据分布波动，例如概念漂移和数据异质性，同时对系统需求也产生了进化变化，例如可扩展性需求和资源限制。本文提出了一种自适应MLaaS组合框架，以确保MLaaS组合的无缝、高效和可扩展性。该框架集成了一种服务评估模型以识别性能不佳的MLaaS服务，并集成了一种候选选择模型以筛选最优替代品。开发了一种自适应组合机制，通过上下文多臂 bandit 优化策略增量更新MLaaS组合。通过不断适应进化的物联网约束条件，该方法在降低从头重组的计算成本的同时，维持服务质量（QoS）。实验结果在真实数据集上验证了所提方法的有效性。', 'title_zh': '物联网环境中的自适应机器学习即服务组件Composition for IoT环境中的自适应机器学习即服务'}
{'arxiv_id': 'arXiv:2506.11053', 'title': 'Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data', 'authors': 'Weichang Wu, Xiaolu Zhang, Jun Zhou, Yuchen Li, Wenwen Xia', 'link': 'https://arxiv.org/abs/2506.11053', 'abstract': "User Behavior Sequence (UBS) modeling is crucial in industrial applications. As data scale and task diversity grow, UBS pretraining methods have become increasingly pivotal. State-of-the-art UBS pretraining methods rely on predicting behavior distributions. The key step in these methods is constructing a selected behavior vocabulary. However, this manual step is labor-intensive and prone to bias. The limitation of vocabulary capacity also directly affects models' generalization ability. In this paper, we introduce Bootstrapping Your Behavior (\\model{}), a novel UBS pretraining strategy that predicts an automatically constructed supervision embedding summarizing all behaviors' information within a future time window, eliminating the manual behavior vocabulary selection. In implementation, we incorporate a student-teacher encoder scheme to construct the pretraining supervision effectively. Experiments on two real-world industrial datasets and eight downstream tasks demonstrate that \\model{} achieves an average improvement of 3.9\\% in AUC and 98.9\\% in training throughput. Notably, the model exhibits meaningful attention patterns and cluster representations during pretraining without any label supervision. In our online deployment over two months, the pretrained model improves the KS by about 2.7\\% and 7.1\\% over the baseline model for two financial overdue risk prediction tasks in the Alipay mobile application, which reduces bad debt risk by millions of dollars for Ant group.", 'abstract_zh': '用户行为序列（UBS）模型预训练是工业应用中的关键。随着数据规模和任务多样性增长，UBS预训练方法变得越来越重要。最新的UBS预训练方法依赖于预测行为分布。这些方法的关键步骤是构建选择的行为词汇表。然而，这一手动步骤耗时且易产生偏差。词汇表容量的局限也直接影响模型的泛化能力。在本文中，我们介绍了一种新颖的UBS预训练策略Bootstrapping Your Behavior（\\model{}），该策略通过自动构建监督嵌入来总结未来时间窗口内所有行为的信息，从而消除手动行为词汇表选择的步骤。在实现中，我们结合了学生-教师编码器方案以有效构建预训练监督。实验结果表明，\\model{}在两个实际工业数据集和八个下游任务上，平均提升了3.9%的AUC和98.9%的训练吞吐量。值得注意的是，在预训练过程中，模型展示了有意义的注意力模式和聚类表示，而无需任何标签监督。在对我们支付宝应用中两个金融逾期风险管理任务的在线部署测试中，经过预训练的模型在两个任务上分别提升了约2.7%和7.1%的KS值，为蚂蚁集团减少了数百万美元的坏账风险。', 'title_zh': '通过自助法训练你的行为：一种新的用户行为序列数据预训练策略'}
{'arxiv_id': 'arXiv:2506.11030', 'title': 'Forward Target Propagation: A Forward-Only Approach to Global Error Credit Assignment via Local Losses', 'authors': 'Nazmus Saadat As-Saquib, A N M Nafiz Abeer, Hung-Ta Chien, Byung-Jun Yoon, Suhas Kumar, Su-in Yi', 'link': 'https://arxiv.org/abs/2506.11030', 'abstract': 'Training neural networks has traditionally relied on backpropagation (BP), a gradient-based algorithm that, despite its widespread success, suffers from key limitations in both biological and hardware perspectives. These include backward error propagation by symmetric weights, non-local credit assignment, and frozen activity during backward passes. We propose Forward Target Propagation (FTP), a biologically plausible and computationally efficient alternative that replaces the backward pass with a second forward pass. FTP estimates layerwise targets using only feedforward computations, eliminating the need for symmetric feedback weights or learnable inverse functions, hence enabling modular and local learning. We evaluate FTP on fully connected networks, CNNs, and RNNs, demonstrating accuracies competitive with BP on MNIST, CIFAR10, and CIFAR100, as well as effective modeling of long-term dependencies in sequential tasks. Moreover, FTP outperforms BP under quantized low-precision and emerging hardware constraints while also demonstrating substantial efficiency gains over other biologically inspired methods such as target propagation variants and forward-only learning algorithms. With its minimal computational overhead, forward-only nature, and hardware compatibility, FTP provides a promising direction for energy-efficient on-device learning and neuromorphic computing.', 'abstract_zh': '基于前向目标传播的神经网络训练：一种生物可行且计算高效的替代方法', 'title_zh': '正向目标传播：通过局部损失进行全局误差责任分配的单向方法'}
{'arxiv_id': 'arXiv:2506.11029', 'title': 'Output Scaling: YingLong-Delayed Chain of Thought in a Large Pretrained Time Series Forecasting Model', 'authors': 'Xue Wang, Tian Zhou, Jinyang Gao, Bolin Ding, Jingren Zhou', 'link': 'https://arxiv.org/abs/2506.11029', 'abstract': 'We present a joint forecasting framework for time series prediction that contrasts with traditional direct or recursive methods. This framework achieves state-of-the-art performance for our designed foundation model, YingLong, and reveals a novel scaling effect: longer outputs significantly enhance model accuracy due to delayed chain-of-thought reasoning in our non-causal approach. YingLong is a non-causal, bidirectional attention encoder-only transformer trained through masked token recovery, aligning more effectively with language understanding tasks than with generation tasks. Additionally, we boost performance by tackling output variance with a multi-input ensemble. We release four foundation models ranging from 6M to 300M parameters, demonstrating superior results in zero-shot tasks on the ETT and Weather datasets. YingLong achieves more than 60% best performance. To ensure generalizability, we assessed the models using the GIFT-Eval benchmark, which comprises 23 time series datasets across 7 domains. Yinglong significantly outperformed the best time-series foundation models, end-to-end trained models by 14% and 44% in rank this http URL pretrained 300M model is available at this https URL', 'abstract_zh': '我们提出了一种时间序列预测的联合预测框架，该框架不同于传统的直接或递归方法。该框架展示了我们设计的基础模型YingLong达到了最先进的性能，并揭示了一种新的缩放效应：更长的输出显著提高了模型精度，这是由于我们在非因果方法中的延迟链式推理。YingLong是一个非因果的双向注意编码器变换器，通过掩码令牌恢复进行训练，更有效地与语言理解任务而非生成任务对齐。此外，我们通过多输入集成解决输出方差，进一步提升了性能。我们发布了参数范围从6M到300M的四种基础模型，在ETT和Weather数据集的零样本任务中展示了优越的结果，YingLong实现了超过60%的最佳性能。为了确保通用性，我们使用包含7个领域23个时间序列数据集的GIFT-Eval基准评估了这些模型，YingLong在排名上分别超过了最佳时间序列基础模型14%和端到端训练模型44%。300M预训练模型可以在以下链接获取：this https URL', 'title_zh': '输出缩放：YingLong-延迟思维链的大规模预训练时间序列预测模型'}
{'arxiv_id': 'arXiv:2506.11028', 'title': 'Enhancing Epidemic Forecasting: Evaluating the Role of Mobility Data and Graph Convolutional Networks', 'authors': 'Suhan Guo, Zhenghao Xu, Furao Shen, Jian Zhao', 'link': 'https://arxiv.org/abs/2506.11028', 'abstract': 'Accurate prediction of contagious disease outbreaks is vital for informed decision-making. Our study addresses the gap between machine learning algorithms and their epidemiological applications, noting that methods optimal for benchmark datasets often underperform with real-world data due to difficulties in incorporating mobility information. We adopt a two-phase approach: first, assessing the significance of mobility data through a pilot study, then evaluating the impact of Graph Convolutional Networks (GCNs) on a transformer backbone. Our findings reveal that while mobility data and GCN modules do not significantly enhance forecasting performance, the inclusion of mortality and hospitalization data markedly improves model accuracy. Additionally, a comparative analysis between GCN-derived spatial maps and lockdown orders suggests a notable correlation, highlighting the potential of spatial maps as sensitive indicators for mobility. Our research offers a novel perspective on mobility representation in predictive modeling for contagious diseases, empowering decision-makers to better prepare for future outbreaks.', 'abstract_zh': '准确预测传染病爆发对于科学决策至关重要。我们的研究填补了机器学习算法与流行病学应用之间的差距，指出适合基准数据集的方法在实际数据中往往表现不佳，原因在于难以整合移动信息。我们采用两阶段的方法：首先通过试点研究评估移动数据的意义，然后在变压器骨干上评估图形卷积网络（GCNs）的影响。研究结果表明，虽然移动数据和GCN模块并未显著提升预测性能，但包括死亡和住院数据明显提高了模型精度。此外，GCN生成的空间地图与封锁令之间的对比分析表明了显著的相关性，强调了空间地图作为敏感移动指标的潜力。我们的研究为传染病预测建模中的移动表示提供了新的视角，助力决策者更好地应对未来的爆发事件。', 'title_zh': '增强传染病预测：评估移动数据和图卷积网络的作用'}
{'arxiv_id': 'arXiv:2506.11025', 'title': 'When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces', 'authors': 'Miriam Doh, Aditya Gulati, Matei Mancas, Nuria Oliver', 'link': 'https://arxiv.org/abs/2506.11025', 'abstract': 'This paper examines how synthetically generated faces and machine learning-based gender classification algorithms are affected by algorithmic lookism, the preferential treatment based on appearance. In experiments with 13,200 synthetically generated faces, we find that: (1) text-to-image (T2I) systems tend to associate facial attractiveness to unrelated positive traits like intelligence and trustworthiness; and (2) gender classification models exhibit higher error rates on "less-attractive" faces, especially among non-White women. These result raise fairness concerns regarding digital identity systems.', 'abstract_zh': '本文探讨了合成生成的人脸和基于机器学习的性别分类算法如何受到算法外观偏见的影响，即基于外观的偏好处理。在对13,200张合成生成的人脸进行的实验中，我们发现：（1）文本转图像（T2I）系统倾向于将面部吸引力与智力和可信度等无关的积极特质相联系；（2）性别分类模型在“不够吸引人”的人脸上表现出更高的错误率，特别是在非白人女性中。这些结果引发了数字身份系统公平性的关切。', 'title_zh': '当算法青睐有加：面部生成与感知中的相貌偏见'}
{'arxiv_id': 'arXiv:2506.11024', 'title': 'Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients', 'authors': 'Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars', 'link': 'https://arxiv.org/abs/2506.11024', 'abstract': 'Foundation models have shown remarkable capabilities across diverse multi-modal tasks, but their centralized training raises privacy concerns and induces high transmission costs. In contrast, federated learning (FL) offers a distributed alternative without the need to share data. Recently, for the growing demand for personalizing AI models for different user purposes, personalized federated learning (PFL) has emerged. PFL allows each client to leverage the knowledge of other clients for further adaptation to individual user preferences, again without the need to share data. Despite its potential, most PFL studies remain confined to simulated environments, overlooking the data and model heterogeneity that arise in real-world scenarios. In contrast, we first consider large data heterogeneity, evaluating on a new benchmark for multi-modal PFL, spanning 40 distinct tasks with realistic data distribution shifts. We then consider model heterogeneity in that we do not assume that all clients share similar model architectures. To address data heterogeneity, we propose a task-similarity-aware model aggregation method that provides customized global models to each client. For model heterogeneity, we propose a dimension-invariant module that enables knowledge sharing across heterogeneous models. Empirical validations demonstrate that the proposed approach outperforms the state-of-the-art, excelling in both personalization and generalization capabilities.', 'abstract_zh': '大规模数据异质性下多模态个性化联邦学习：一种任务相似性aware的模型聚合方法与维度不变的知识模块', 'title_zh': '不同客户端并非平等：异构多模客户端上的个性化联邦学习'}
{'arxiv_id': 'arXiv:2506.11015', 'title': 'The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI', 'authors': 'Barbara Oakley, Michael Johnston, Ken-Zen Chen, Eulho Jung, Terrence J. Sejnowski', 'link': 'https://arxiv.org/abs/2506.11015', 'abstract': 'In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as "grokking" and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological "schemata" and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.', 'abstract_zh': '在生成式AI和普及的数字化工具时代，人类认知面临结构悖论：随着外部辅助工具能力的增强，内部记忆系统可能萎缩。基于神经科学与认知心理学，本文探讨了对AI系统和发现式教学方法的高度依赖如何损害陈述性和程序性记忆的巩固——这两种记忆系统对于专业能力、批判性思维和长期记忆至关重要。我们回顾了诸如ChatGPT和计算器之类的工具如何绕过了必要的检索、错误修正和模式构建过程，从而影响稳固的神经编码。值得注意的是，我们强调了深度学习现象如“顿悟”与过度学习和直觉的神经科学之间的显著相似之处。通过讨论初步依赖AI学习的实证研究，展示了如何阻碍程序化和直观 mastery。我们主张有效的AI与人类交互依赖于强大的内部模型——生物“模式”和神经流形，使用户能够评估、完善和引导AI输出。本文最后讨论了大型语言模型时代教育和职业培训的政策含义。', 'title_zh': '记忆悖论：在人工智能时代为什么我们需要知识'}
{'arxiv_id': 'arXiv:2506.11010', 'title': 'Data Science: a Natural Ecosystem', 'authors': 'Emilio Porcu, Roy El Moukari, Laurent Najman, Francisco Herrera, Horst Simon', 'link': 'https://arxiv.org/abs/2506.11010', 'abstract': 'This manuscript provides a holistic (data-centric) view of what we term essential data science, as a natural ecosystem with challenges and missions stemming from the data universe with its multiple combinations of the 5D complexities (data structure, domain, cardinality, causality, and ethics) with the phases of the data life cycle. Data agents perform tasks driven by specific goals. The data scientist is an abstract entity that comes from the logical organization of data agents with their actions. Data scientists face challenges that are defined according to the missions. We define specific discipline-induced data science, which in turn allows for the definition of pan-data science, a natural ecosystem that integrates specific disciplines with the essential data science. We semantically split the essential data science into computational, and foundational. We claim that there is a serious threat of divergence between computational and foundational data science. Especially, if no approach is taken to rate whether a data universe discovery should be useful or not. We suggest that rigorous approaches to measure the usefulness of data universe discoveries might mitigate such a divergence.', 'abstract_zh': '本文提供了一种以数据为中心的整体视角，阐述我们所称的本质数据科学，作为一种自然生态系统，它源于数据宇宙中的多种5D复杂性（数据结构、领域、基数、因果性、伦理）与数据生命周期各阶段所带来的挑战和使命。数据代理根据特定目标执行任务。数据科学家是数据代理及其行为的抽象组织结果。数据科学家面临的挑战由其使命定义。我们定义了特定学科驱动的本质数据科学，进而定义了本质数据科学与特定学科集成的泛数据科学。我们语义上将本质数据科学分为计算性和基础性部分。我们声称，计算性和基础性数据科学之间存在严重分歧的风险。特别是如果没有方法来评估数据宇宙发现是否具有实用性，则风险尤为严重。我们建议采用严谨的方法来衡量数据宇宙发现的实用性，以减轻这种分歧。', 'title_zh': '数据科学：一个自然生态系统'}
{'arxiv_id': 'arXiv:2506.11004', 'title': 'Developing a Dyslexia Indicator Using Eye Tracking', 'authors': 'Kevin Cogan, Vuong M. Ngo, Mark Roantree', 'link': 'https://arxiv.org/abs/2506.11004', 'abstract': 'Dyslexia, affecting an estimated 10% to 20% of the global population, significantly impairs learning capabilities, highlighting the need for innovative and accessible diagnostic methods. This paper investigates the effectiveness of eye-tracking technology combined with machine learning algorithms as a cost-effective alternative for early dyslexia detection. By analyzing general eye movement patterns, including prolonged fixation durations and erratic saccades, we proposed an enhanced solution for determining eye-tracking-based dyslexia features. A Random Forest Classifier was then employed to detect dyslexia, achieving an accuracy of 88.58\\%. Additionally, hierarchical clustering methods were applied to identify varying severity levels of dyslexia. The analysis incorporates diverse methodologies across various populations and settings, demonstrating the potential of this technology to identify individuals with dyslexia, including those with borderline traits, through non-invasive means. Integrating eye-tracking with machine learning represents a significant advancement in the diagnostic process, offering a highly accurate and accessible method in clinical research.', 'abstract_zh': '阅读障碍影响着全球约10%到20%的人口，显著妨碍学习能力，强调了创新且易于获取的诊断方法的必要性。本文探讨了眼球追踪技术结合机器学习算法作为早期阅读障碍检测经济有效的替代方法的有效性。通过分析一般的眼动模式，包括延长的注视时间和不规则的眼跳，我们提出了增强的眼球追踪基础阅读障碍特征确定方案。然后使用随机森林分类器进行阅读障碍检测，准确率达到88.58%。此外，还应用了层次聚类方法以识别阅读障碍的不同严重程度。分析涵盖了不同人群和环境下的多种方法，展示了该技术通过无创手段识别包括边缘特质个体在内的阅读障碍个体的潜在能力。将眼球追踪与机器学习的整合是诊断过程中的重要进展，为临床研究提供了高度准确且易于获取的方法。', 'title_zh': '使用眼动追踪开发阅读障碍指示器'}
{'arxiv_id': 'arXiv:2506.11001', 'title': 'Rethinking Technological Readiness in the Era of AI Uncertainty', 'authors': 'S. Tucker Browne, Mark M. Bailey', 'link': 'https://arxiv.org/abs/2506.11001', 'abstract': "Artificial intelligence (AI) is poised to revolutionize military combat systems, but ensuring these AI-enabled capabilities are truly mission-ready presents new challenges. We argue that current technology readiness assessments fail to capture critical AI-specific factors, leading to potential risks in deployment. We propose a new AI Readiness Framework to evaluate the maturity and trustworthiness of AI components in military systems. The central thesis is that a tailored framework - analogous to traditional Technology Readiness Levels (TRL) but expanded for AI - can better gauge an AI system's reliability, safety, and suitability for combat use. Using current data evaluation tools and testing practices, we demonstrate the framework's feasibility for near-term implementation. This structured approach provides military decision-makers with clearer insight into whether an AI-enabled system has met the necessary standards of performance, transparency, and human integration to be deployed with confidence, thus advancing the field of defense technology management and risk assessment.", 'abstract_zh': '人工智能（AI）有望 revolutionize 军事 combat 系统，但确保这些 AI 驱动的能力真正具备 mission-ready 特性提出了新的挑战。我们认为当前的技术 readiness 评估未能捕捉到关键的 AI 特异性因素，可能导致部署时存在潜在风险。我们提出了一种新的 AI 准备框架，以评估军事系统中 AI 组件的成熟度和可信度。核心论点是，一个定制化的框架（类似于传统的技术 readiness 等级TRL，但扩展了 AI 方面的功能）可以更好地衡量 AI 系统的可靠性、安全性和适合作战使用的特性。利用现有的数据评估工具和测试方法，我们展示了该框架在短期内实施的可能性。这种结构化的方法为军事决策者提供了更清晰的洞察，以确定一个 AI 驱动的系统是否达到了性能、透明性和人机集成所需的必要标准，从而推动了国防技术管理与风险评估领域的进步。', 'title_zh': '重思人工智能不确定性时代的技术准备xing'}
{'arxiv_id': 'arXiv:2506.10990', 'title': "On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances", 'authors': 'Roberto Vergallo, Luís Cruz, Alessio Errico, Luca Mainetti', 'link': 'https://arxiv.org/abs/2506.10990', 'abstract': "'Follow-the-Sun' (FtS) is a theoretical computational model aimed at minimizing the carbon footprint of computer workloads. It involves dynamically moving workloads to regions with cleaner energy sources as demand increases and energy production relies more on fossil fuels. With the significant power consumption of Artificial Intelligence (AI) being a subject of extensive debate, FtS is proposed as a strategy to mitigate the carbon footprint of training AI models. However, the literature lacks scientific evidence on the advantages of FtS to mitigate the carbon footprint of AI workloads. In this paper, we present the results of an experiment conducted in a partial synthetic scenario to address this research gap. We benchmarked four AI algorithms in the anomaly detection domain and measured the differences in carbon emissions in four cases: no strategy, FtS, and two strategies previously introduced in the state of the art, namely Flexible Start and Pause and Resume. To conduct our experiment, we utilized historical carbon intensity data from the year 2021 for seven European cities. Our results demonstrate that the FtS strategy not only achieves average reductions of up to 14.6% in carbon emissions (with peaks of 16.3%) but also helps in preserving the time needed for training.", 'abstract_zh': '“跟随太阳”（FtS）是一种理论计算模型，旨在最小化计算机工作负载的碳足迹。它涉及根据需求动态地将工作负载转移到更多使用清洁能源的地区，随着能源生产更多依赖化石燃料。由于人工智能（AI）的能耗问题受到广泛讨论，FtS 被提议作为一种策略来减少训练AI模型的碳足迹。然而，文献中缺乏关于FtS 减少AI工作负载碳足迹优势的科学证据。在本文中，我们展示了在一个部分合成场景下进行的实验结果，以填补这一研究缺口。我们在异常检测领域基准测试了四种AI算法，并测量了四种情况下的碳排放差异：无策略、FtS，以及两种之前在现有技术中引入的策略，即灵活启动和暂停以及恢复。为了进行我们的实验，我们使用了2021年七座欧洲城市的 historical 碳强度数据。我们的结果显示，FtS 策略不仅在碳排放方面实现了最高达16.3%的峰值和平均14.6%的减少，还帮助保持了训练所需的时间。', 'title_zh': '“跟随太阳”策略在减轻云实例中人工智能碳足迹有效性研究'}
