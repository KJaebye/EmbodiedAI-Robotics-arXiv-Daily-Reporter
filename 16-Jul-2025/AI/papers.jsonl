{'arxiv_id': 'arXiv:2507.11538', 'title': 'How Many Instructions Can LLMs Follow at Once?', 'authors': 'Daniel Jaroslawicz, Brendan Whiting, Parth Shah, Karime Maamari', 'link': 'https://arxiv.org/abs/2507.11538', 'abstract': 'Production-grade LLM systems require robust adherence to dozens or even hundreds of instructions simultaneously. However, the instruction-following capabilities of LLMs at high instruction densities have not yet been characterized, as existing benchmarks only evaluate models on tasks with a single or few instructions. We introduce IFScale, a simple benchmark of 500 keyword-inclusion instructions for a business report writing task to measure how instruction-following performance degrades as instruction density increases. We evaluate 20 state-of-the-art models across seven major providers and find that even the best frontier models only achieve 68% accuracy at the max density of 500 instructions. Our analysis reveals model size and reasoning capability to correlate with 3 distinct performance degradation patterns, bias towards earlier instructions, and distinct categories of instruction-following errors. Our insights can help inform design of instruction-dense prompts in real-world applications and highlight important performance-latency tradeoffs. We open-source the benchmark and all results for further analysis at this https URL.', 'abstract_zh': '生产级LLM系统需要严格遵守成百上千条指令。然而，现有基准仅评估模型在单一或少量指令任务上的表现，尚未描述大模型在高指令密度下的指令遵循能力。为此，我们提出了IFScale基准测试，包含500条关键词包含指令，以评估指令密度增加时的指令遵循性能下降情况。我们对来自七家主要提供商的20个领先模型进行了评估，发现即使最好的前沿模型在最大密度500条指令下的准确率也只有68%。我们的分析揭示了模型大小和推理能力与三种不同的性能下降模式、偏向早期指令的趋势及不同类别指令遵循错误之间的关联。我们的洞见有助于指导实际应用中复杂指令提示的设计，并突出性能与延迟之间的关键权衡。我们开源了基准测试及所有结果以供进一步分析。', 'title_zh': '大规模语言模型一次能遵循多少指令？'}
{'arxiv_id': 'arXiv:2507.11527', 'title': 'DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering', 'authors': 'Yinsheng Li, Zhen Dong, Yi Shao', 'link': 'https://arxiv.org/abs/2507.11527', 'abstract': "Large Language Model (LLM) agents have shown great potential for solving real-world problems and promise to be a solution for tasks automation in industry. However, more benchmarks are needed to systematically evaluate automation agents from an industrial perspective, for example, in Civil Engineering. Therefore, we propose DrafterBench for the comprehensive evaluation of LLM agents in the context of technical drawing revision, a representation task in civil engineering. DrafterBench contains twelve types of tasks summarized from real-world drawing files, with 46 customized functions/tools and 1920 tasks in total. DrafterBench is an open-source benchmark to rigorously test AI agents' proficiency in interpreting intricate and long-context instructions, leveraging prior knowledge, and adapting to dynamic instruction quality via implicit policy awareness. The toolkit comprehensively assesses distinct capabilities in structured data comprehension, function execution, instruction following, and critical reasoning. DrafterBench offers detailed analysis of task accuracy and error statistics, aiming to provide deeper insight into agent capabilities and identify improvement targets for integrating LLMs in engineering applications. Our benchmark is available at this https URL, with the test set hosted at this https URL.", 'abstract_zh': '大规模语言模型（LLM）代理在技术和制图修订任务中的综合评估：DrafterBench', 'title_zh': 'DrafterBench: 大型语言模型在土木工程任务自动化中的基准测试'}
{'arxiv_id': 'arXiv:2507.11482', 'title': 'Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light', 'authors': 'Mani Hamidi, Terrence W. Deacon', 'link': 'https://arxiv.org/abs/2507.11482', 'abstract': 'Three core tenets of reinforcement learning (RL)--concerning the definition of agency, the objective of learning, and the scope of the reward hypothesis--have been highlighted as key targets for conceptual revision, with major implications for theory and application. We propose a framework, inspired by open-ended evolutionary theory, to reconsider these three "dogmas." We revisit each assumption and address related concerns raised alongside them. To make our arguments relevant to RL as a model of biological learning, we first establish that evolutionary dynamics can plausibly operate within living brains over an individual\'s lifetime, and are not confined to cross-generational processes. We begin by revisiting the second dogma, drawing on evolutionary insights to enrich the "adaptation-rather-than-search" view of learning. We then address the third dogma regarding the limits of the reward hypothesis, using analogies from evolutionary fitness to illuminate the scalar reward vs. multi-objective debate. After discussing practical implications for exploration in RL, we turn to the first--and arguably most fundamental--issue: the absence of a formal account of agency. We argue that unlike the other two problems, the evolutionary paradigm alone cannot resolve the agency question, though it gestures in a productive direction. We advocate integrating ideas from origins-of-life theory, where the thermodynamics of sustenance and replication offer promising foundations for understanding agency and resource-constrained reinforcement learning in biological systems.', 'abstract_zh': '强化学习（RL）的三大核心原则——关于代理的定义、学习的目标以及奖励假设的范围——已被视为概念修订的关键目标，对理论和应用具有重要影响。我们提出一个框架，受到开放性进化理论的启发，重新考虑这三种“教条”。我们重新审视每项假设，并解决与它们相关的顾虑。为使我们的论点与RL作为生物学习模型相关，我们首先确立进化动力学在个体生命期内合理地在活脑中运行，而不局限于代际过程。我们首先重新审视第二个教条，借鉴进化生物学的见解，丰富“适应而非搜索”的学习视图。接着，我们解决关于奖励假设限度的第三个教条，利用进化适应性的类比来阐明标量奖励与多目标奖励之间的争论。在讨论探索在RL中的实际影响之后，我们转向第一个——或许是最重要的——问题：缺乏对代理的正式描述。我们认为，不同于其他两个问题，进化范式本身无法解决代理问题，但它指出了一个有成效的方向。我们倡导整合生命起源理论中的观点，其中维持和复制的热力学原理为理解代理和资源约束下的生物系统强化学习提供了有希望的基础。', 'title_zh': '在进化视角下揭示强化学习的三大 dogma'}
{'arxiv_id': 'arXiv:2507.11479', 'title': 'Perspective-Aware AI in Extended Reality', 'authors': 'Daniel Platnick, Matti Gruener, Marjan Alirezaie, Kent Larson, Dava J. Newman, Hossein Rahnama', 'link': 'https://arxiv.org/abs/2507.11479', 'abstract': "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive experiences-yet current systems fall short due to shallow user modeling and limited cognitive context. We introduce Perspective-Aware AI in Extended Reality (PAiR), a foundational framework for integrating Perspective-Aware AI (PAi) with XR to enable interpretable, context-aware experiences grounded in user identity. PAi is built on Chronicles: reasoning-ready identity models learned from multimodal digital footprints that capture users' cognitive and experiential evolution. PAiR employs these models in a closed-loop system linking dynamic user states with immersive environments. We present PAiR's architecture, detailing its modules and system flow, and demonstrate its utility through two proof-of-concept scenarios implemented in the Unity-based OpenDome engine. PAiR opens a new direction for human-AI interaction by embedding perspective-based identity models into immersive systems.", 'abstract_zh': 'AI增强扩展现实（XR）旨在提供适应性和沉浸式体验—但由于浅层用户建模和有限的认知上下文，当前系统尚存不足。我们提出一种基于视角意识AI在扩展现实中的框架（PAiR），以整合视角意识AI（PAi）并使体验基于用户的身份具有可解释性和上下文意识。PAi基于Chronicles构建：从多模态数字足迹中学习的认知准备就绪身份模型，捕捉用户的认知和体验演变。PAiR通过闭环系统将动态用户状态与沉浸式环境联系起来应用这些模型。我们展示了PAiR的架构，详细说明其模块和系统流程，并通过在基于Unity的OpenDome引擎中实现的两个概念验证场景展示了其实用性。PAiR为基于视角身份模型的人机交互开辟了新方向。', 'title_zh': '视角感知AI在扩展现实中的应用'}
{'arxiv_id': 'arXiv:2507.11473', 'title': 'Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety', 'authors': 'Tomek Korbak, Mikita Balesni, Elizabeth Barnes, Yoshua Bengio, Joe Benton, Joseph Bloom, Mark Chen, Alan Cooney, Allan Dafoe, Anca Dragan, Scott Emmons, Owain Evans, David Farhi, Ryan Greenblatt, Dan Hendrycks, Marius Hobbhahn, Evan Hubinger, Geoffrey Irving, Erik Jenner, Daniel Kokotajlo, Victoria Krakovna, Shane Legg, David Lindner, David Luan, Aleksander Mądry, Julian Michael, Neel Nanda, Dave Orr, Jakub Pachocki, Ethan Perez, Mary Phuong, Fabien Roger, Joshua Saxe, Buck Shlegeris, Martín Soto, Eric Steinberger, Jasmine Wang, Wojciech Zaremba, Bowen Baker, Rohin Shah, Vlad Mikulik', 'link': 'https://arxiv.org/abs/2507.11473', 'abstract': 'AI systems that "think" in human language offer a unique opportunity for AI safety: we can monitor their chains of thought (CoT) for the intent to misbehave. Like all other known AI oversight methods, CoT monitoring is imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows promise and we recommend further research into CoT monitorability and investment in CoT monitoring alongside existing safety methods. Because CoT monitorability may be fragile, we recommend that frontier model developers consider the impact of development decisions on CoT monitorability.', 'abstract_zh': '基于人类语言“思考”的AI系统为AI安全提供了独特机会：我们可以通过监控其思维链（CoT）来检查其是否有违规意图。尽管CoT监控方法并不完善，并且可能会漏掉一些违规行为，但这种方法显示出了潜力，我们建议进一步研究CoT可监控性，并在现有安全方法之外投资于CoT监控。由于CoT可监控性可能较为脆弱，我们建议前沿模型开发者考虑其开发决策对CoT可监控性的影响。', 'title_zh': 'Chain of Thought Monitorability: 一种新的脆弱性机会，关乎AI安全'}
{'arxiv_id': 'arXiv:2507.11467', 'title': 'Modeling Code: Is Text All You Need?', 'authors': 'Daniel Nichols, Konstantinos Parasyris, Harshitha Menon, Brian R. Bartoldson, Giorgis Georgakoudis, Tal Ben-Nun, Abhinav Bhatele', 'link': 'https://arxiv.org/abs/2507.11467', 'abstract': 'Code LLMs have become extremely popular recently for modeling source code across a variety of tasks, such as generation, translation, and summarization. However, transformer-based models are limited in their capabilities to reason through structured, analytical properties of code, such as control and data flow. Previous work has explored the modeling of these properties with structured data and graph neural networks. However, these approaches lack the generative capabilities and scale of modern LLMs. In this work, we introduce a novel approach to combine the strengths of modeling both code as text and more structured forms.', 'abstract_zh': '代码LLM在多种任务中的应用近年来十分流行，涵盖了生成、翻译和摘要等任务。然而，基于变换器的模型在推理代码的结构化和分析性质（如控制流和数据流）方面能力有限。先前的研究探索了使用结构化数据和图神经网络来建模这些性质，但这些方法缺乏现代LLM的生成能力和规模。在本文中，我们提出了一种新颖的方法，结合了将代码建模为文本和更结构化形式的优势。', 'title_zh': '代码建模：文本足够吗？'}
{'arxiv_id': 'arXiv:2507.11352', 'title': 'Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces', 'authors': 'Yunhao Yang, Neel P. Bhatt, Christian Ellis, Alvaro Velasquez, Zhangyang Wang, Ufuk Topcu', 'link': 'https://arxiv.org/abs/2507.11352', 'abstract': 'Logistics operators, from battlefield coordinators rerouting airlifts ahead of a storm to warehouse managers juggling late trucks, often face life-critical decisions that demand both domain expertise and rapid and continuous replanning. While popular methods like integer programming yield logistics plans that satisfy user-defined logical constraints, they are slow and assume an idealized mathematical model of the environment that does not account for uncertainty. On the other hand, large language models (LLMs) can handle uncertainty and promise to accelerate replanning while lowering the barrier to entry by translating free-form utterances into executable plans, yet they remain prone to misinterpretations and hallucinations that jeopardize safety and cost. We introduce a neurosymbolic framework that pairs the accessibility of natural-language dialogue with verifiable guarantees on goal interpretation. It converts user requests into structured planning specifications, quantifies its own uncertainty at the field and token level, and invokes an interactive clarification loop whenever confidence falls below an adaptive threshold. A lightweight model, fine-tuned on just 100 uncertainty-filtered examples, surpasses the zero-shot performance of GPT-4.1 while cutting inference latency by nearly 50%. These preliminary results highlight a practical path toward certifiable, real-time, and user-aligned decision-making for complex logistics.', 'abstract_zh': '神经符号框架在复杂物流中的可认证实时和用户对齐决策', 'title_zh': '物流领域的基础模型：迈向可验证、对话式规划接口'}
{'arxiv_id': 'arXiv:2507.11334', 'title': 'CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking', 'authors': 'Yuehao Huang, Liang Liu, Shuangming Lei, Yukai Ma, Hao Su, Jianbiao Mei, Pengxiang Zhao, Yaqing Gu, Yong Liu, Jiajun Lv', 'link': 'https://arxiv.org/abs/2507.11334', 'abstract': 'Mobile robots are increasingly required to navigate and interact within unknown and unstructured environments to meet human demands. Demand-driven navigation (DDN) enables robots to identify and locate objects based on implicit human intent, even when object locations are unknown. However, traditional data-driven DDN methods rely on pre-collected data for model training and decision-making, limiting their generalization capability in unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that emulates the human cognitive and learning mechanisms by integrating fast and slow thinking systems and selectively identifying key objects essential to fulfilling user demands. CogDDN identifies appropriate target objects by semantically aligning detected objects with the given instructions. Furthermore, it incorporates a dual-process decision-making module, comprising a Heuristic Process for rapid, efficient decisions and an Analytic Process that analyzes past errors, accumulates them in a knowledge base, and continuously improves performance. Chain of Thought (CoT) reasoning strengthens the decision-making process. Extensive closed-loop evaluations on the AI2Thor simulator with the ProcThor dataset show that CogDDN outperforms single-view camera-only methods by 15%, demonstrating significant improvements in navigation accuracy and adaptability. The project page is available at this https URL.', 'abstract_zh': '基于VLM的认知驱动导航（CogDDN）框架：模拟人类认知与学习机制以实现需求导向的环境交互', 'title_zh': 'CogDDN：基于认知需求驱动的导航与决策优化及双过程思维方法'}
{'arxiv_id': 'arXiv:2507.11323', 'title': 'Contestability in Quantitative Argumentation', 'authors': 'Xiang Yin, Nico Potyka, Antonio Rago, Timotheus Kampik, Francesca Toni', 'link': 'https://arxiv.org/abs/2507.11323', 'abstract': "Contestable AI requires that AI-driven decisions align with human preferences. While various forms of argumentation have been shown to support contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks (EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs can be deployed for this purpose. Specifically, we introduce the contestability problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences) to achieve a desired strength for a specific argument of interest (i.e., a topic argument). To address this problem, we propose gradient-based relation attribution explanations (G-RAEs), which quantify the sensitivity of the topic argument's strength to changes in individual edge weights, thus providing interpretable guidance for weight adjustments towards contestability. Building on G-RAEs, we develop an iterative algorithm that progressively adjusts the edge weights to attain the desired strength. We evaluate our approach experimentally on synthetic EW-QBAFs that simulate the structural characteristics of personalised recommender systems and multi-layer perceptrons, and demonstrate that it can solve the problem effectively.", 'abstract_zh': '可争议AI要求AI驱动的决策与人类偏好保持一致。虽然各种形式的论证已被证明可以支持可争议性，但边缘加权定量 bipolar 论证框架（EW-QBAFs）尚未引起广泛关注。在本文中，我们展示了如何使用EW-QBAFs实现这一目标。具体来说，我们引入了EW-QBAFs的可争议性问题，该问题探讨如何通过修改边权重（例如，偏好）来实现特定论题的期望强度。为了解决这一问题，我们提出了基于梯度的关系归因解释（G-RAEs），以量化论题论点强度对个体边权重变化的敏感性，从而提供具有可解释性的指导，用于权重调整以促进可争议性。基于G-RAEs，我们开发了一种迭代算法，以渐进方式调整边权重以达到期望的强度。我们通过合成EW-QBAFs进行实验性评估，这些合成框架模拟了个性化推荐系统和多层感知机的结构特性，并证明了该方法可以有效解决该问题。', 'title_zh': '量化论证中的可议性'}
{'arxiv_id': 'arXiv:2507.11288', 'title': 'Opus: A Prompt Intention Framework for Complex Workflow Generation', 'authors': 'Théo Fagnoni, Mahsun Altin, Chia En Chung, Phillip Kingston, Alan Tuning, Dana O. Mohamed, Inès Adnani', 'link': 'https://arxiv.org/abs/2507.11288', 'abstract': 'This paper introduces the Opus Prompt Intention Framework, designed to improve complex Workflow Generation with instruction-tuned Large Language Models (LLMs). We propose an intermediate Intention Capture layer between user queries and Workflow Generation, implementing the Opus Workflow Intention Framework, which consists of extracting Workflow Signals from user queries, interpreting them into structured Workflow Intention objects, and generating Workflows based on these Intentions. Our results show that this layer enables LLMs to produce logical and meaningful outputs that scale reliably as query complexity increases. On a synthetic benchmark of 1,000 multi-intent query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to Workflow Generation yields consistent improvements in semantic Workflow similarity metrics. In this paper, we introduce the Opus Prompt Intention Framework by applying the concepts of Workflow Signal and Workflow Intention to LLM-driven Workflow Generation. We present a reproducible, customizable LLM-based Intention Capture system to extract Workflow Signals and Workflow Intentions from user queries. Finally, we provide empirical evidence that the proposed system significantly improves Workflow Generation quality compared to direct generation from user queries, particularly in cases of Mixed Intention Elicitation.', 'abstract_zh': 'Opus Prompt Intention Framework: 一种用于改进指令调优大规模语言模型驱动的工作流生成的框架', 'title_zh': 'Opus：复杂工作流生成的提示意图框架'}
{'arxiv_id': 'arXiv:2507.11277', 'title': 'Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems', 'authors': 'Dany Moshkovich, Sergey Zeltyn', 'link': 'https://arxiv.org/abs/2507.11277', 'abstract': 'Large Language Models (LLMs) are increasingly deployed within agentic systems-collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges.\nThis paper introduces AgentOps: a comprehensive framework for observing, analyzing, optimizing, and automating operation of agentic AI systems. We identify distinct needs across four key roles-developers, testers, site reliability engineers (SREs), and business users-each of whom engages with the system at different points in its lifecycle. We present the AgentOps Automation Pipeline, a six-stage process encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation. Throughout, we emphasize the critical role of automation in managing uncertainty and enabling self-improving AI systems-not by eliminating uncertainty, but by taming it to ensure safe, adaptive, and effective operation.', 'abstract_zh': '大型语言模型（LLMs）日益被部署在智能代理系统中，这些系统是由配备语言模型的强大代理组成的集合，通过记忆、工具和动态规划执行复杂的适应性工作流。虽然这些系统提供了强大的新能力，但也引入了概率推理、不断演化的记忆状态和动态执行路径带来的独特不确定性形式。传统的软件可观测性和运营实践在解决这些挑战时力不从心。\n\n本文介绍了智能代理运营（AgentOps）：一个全面的框架，用于观察、分析、优化和自动化智能代理AI系统的运营。我们确定了四个关键角色——开发者、测试员、站点可靠性工程师（SRE）和业务用户在系统生命周期不同阶段对系统的参与需求。我们提出了智能代理运营自动化流水线，一个六阶段过程，涵盖行为观察、指标收集、问题检测、根本原因分析、优化建议和运行时自动化。在整个过程中，我们强调自动化在管理不确定性并实现自我改进的AI系统中的关键作用——不是通过消除不确定性，而是通过驾驭不确定性以确保安全、适应性和有效的运行。', 'title_zh': '通过自动化管理不确定性：观察、分析与优化代理人工智能系统'}
{'arxiv_id': 'arXiv:2507.11229', 'title': 'DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion', 'authors': 'Jin Li, Zezhong Ding, Xike Xie', 'link': 'https://arxiv.org/abs/2507.11229', 'abstract': 'Knowledge graphs (KGs) are vital for enabling knowledge reasoning across various domains. Recent KG reasoning methods that integrate both global and local information have achieved promising results. However, existing methods often suffer from score over-smoothing, which blurs the distinction between correct and incorrect answers and hinders reasoning effectiveness. To address this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with dual-pathway global-local fusion. DuetGraph tackles over-smoothing by segregating -- rather than stacking -- the processing of local (via message passing) and global (via attention) information into two distinct pathways, preventing mutual interference and preserving representational discrimination. In addition, DuetGraph introduces a coarse-to-fine optimization, which partitions entities into high- and low-score subsets. This strategy narrows the candidate space and sharpens the score gap between the two subsets, which alleviates over-smoothing and enhances inference quality. Extensive experiments on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA) performance, with up to an 8.7% improvement in reasoning quality and a 1.8$\\times$ acceleration in training efficiency.', 'abstract_zh': '基于粗细路径全局-局部融合的知识图谱推理机制DuetGraph', 'title_zh': 'DuetGraph: 从粗到细的知识图谱推理与双重路径全局-局部融合'}
{'arxiv_id': 'arXiv:2507.11150', 'title': 'Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming', 'authors': 'Alessandro Bertagnon, Marcello Dalpasso, Michele Favalli, Marco Gavanelli', 'link': 'https://arxiv.org/abs/2507.11150', 'abstract': 'In the design of integrated circuits, one critical metric is the maximum delay introduced by combinational modules within the circuit. This delay is crucial because it represents the time required to perform a computation: in an Arithmetic-Logic Unit it represents the maximum time taken by the circuit to perform an arithmetic operation. When such a circuit is part of a larger, synchronous system, like a CPU, the maximum delay directly impacts the maximum clock frequency of the entire system. Typically, hardware designers use Static Timing Analysis to compute an upper bound of the maximum delay because it can be determined in polynomial time. However, relying on this upper bound can lead to suboptimal processor speeds, thereby missing performance opportunities. In this work, we tackle the challenging task of computing the actual maximum delay, rather than an approximate value. Since the problem is computationally hard, we model it in Answer Set Programming (ASP), a logic language featuring extremely efficient solvers. We propose non-trivial encodings of the problem into ASP. Experimental results show that ASP is a viable solution to address complex problems in hardware design.', 'abstract_zh': '在集成电路设计中，一个关键指标是电路中组合模块引入的最大延迟。这一延迟至关重要，因为它代表了完成计算所需的时间：在算术逻辑单元中，它代表了电路执行算术操作所花费的最大时间。当这样一个电路是更大规模同步系统（如CPU）的一部分时，最大延迟直接关系到系统的最大时钟频率。通常，硬件设计师使用静态时序分析来计算最大延迟的一个上限，因为这个上限可以在多项式时间内确定。然而，依赖这一上限可能导致处理器速度不足，从而错失性能机会。在本工作中，我们致力于计算实际的最大延迟，而非一个近似值。由于该问题是计算上困难的，我们将其建模为回答集编程（ASP），这是一种包含极其高效求解器的逻辑语言。我们提出了问题的非平凡编码方法。实验结果表明，ASP 是解决硬件设计中复杂问题的一个可行方案。', 'title_zh': '数字集成电路的细粒度时序分析在回答集程序设计中'}
{'arxiv_id': 'arXiv:2507.11135', 'title': 'Collaborative Trustworthiness for Good Decision Making in Autonomous Systems', 'authors': 'Selma Saidi, Omar Laimona, Christoph Schmickler, Dirk Ziegenbein', 'link': 'https://arxiv.org/abs/2507.11135', 'abstract': 'Autonomous systems are becoming an integral part of many application domains, like in the mobility sector. However, ensuring their safe and correct behaviour in dynamic and complex environments remains a significant challenge, where systems should autonomously make decisions e.g., about manoeuvring. We propose in this paper a general collaborative approach for increasing the level of trustworthiness in the environment of operation and improve reliability and good decision making in autonomous system. In the presence of conflicting information, aggregation becomes a major issue for trustworthy decision making based on collaborative data sharing. Unlike classical approaches in the literature that rely on consensus or majority as aggregation rule, we exploit the fact that autonomous systems have different quality attributes like perception quality. We use this criteria to determine which autonomous systems are trustworthy and borrow concepts from social epistemology to define aggregation and propagation rules, used for automated decision making. We use Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and propagation, and formulate reduction rules to reduce the size of the BDDs and allow efficient computation structures for collaborative automated reasoning.', 'abstract_zh': '自主系统正逐渐成为许多应用领域的核心组成部分，如在移动领域。然而，在动态和复杂环境中确保其安全正确的行为仍然是一个重大挑战，系统需要自主做出决策，例如关于机动行为。本文提出了一种通用的协作方法，以提高运行环境的信任度，并改善自主系统的可靠性和良好的决策能力。在存在冲突信息的情况下，聚合成为基于协作数据共享进行可信决策的主要问题。与文献中依赖一致意见或多数投票的古典方法不同，我们利用自主系统具有不同的质量属性（如感知质量）这一事实。我们使用这一标准来确定哪些自主系统是可信的，并借鉴社会认识论的概念来定义聚合和传播规则，用于自动化决策。我们使用二值决策图（BDDs）作为信念聚合和传播的形式化模型，并提出了简化规则以减小BDDs的规模，从而实现协作自动推理的有效计算结构。', 'title_zh': '自主系统中协同可信性对良好决策的影响'}
{'arxiv_id': 'arXiv:2507.11127', 'title': 'Defining neurosymbolic AI', 'authors': 'Lennert De Smet, Luc De Raedt', 'link': 'https://arxiv.org/abs/2507.11127', 'abstract': 'Neurosymbolic AI focuses on integrating learning and reasoning, in particular, on unifying logical and neural representations. Despite the existence of an alphabet soup of neurosymbolic AI systems, the field is lacking a generally accepted formal definition of what neurosymbolic models and inference really are. We introduce a formal definition for neurosymbolic AI that makes abstraction of its key ingredients. More specifically, we define neurosymbolic inference as the computation of an integral over a product of a logical and a belief function. We show that our neurosymbolic AI definition makes abstraction of key representative neurosymbolic AI systems.', 'abstract_zh': '神经符号AI聚焦于学习与推理的整合，特别是逻辑表示与神经表示的统一。尽管存在各种神经符号AI系统，但该领域缺乏对其所指的神经符号模型和推理的一般接受的正式定义。我们提出了一种正式定义神经符号AI，抽象了其关键成分。具体而言，我们定义神经符号推理为逻辑函数与信念函数乘积的积分计算。我们展示了我们的神经符号AI定义抽象了关键的代表性神经符号AI系统。', 'title_zh': '定义神经符号人工智能'}
{'arxiv_id': 'arXiv:2507.11117', 'title': 'AI Agent Architecture for Decentralized Trading of Alternative Assets', 'authors': 'Ailiya Borjigin, Cong He, Charles CC Lee, Wei Zhou', 'link': 'https://arxiv.org/abs/2507.11117', 'abstract': 'Decentralized trading of real-world alternative assets (e.g., gold) requires bridging physical asset custody with blockchain systems while meeting strict requirements for compliance, liquidity, and risk management. We present GoldMine OS, a research oriented architecture that employs multiple specialized AI agents to automate and secure the tokenization and exchange of physical gold into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart contracts for critical risk controls with off chain AI agents for decision making, blending the transparency and reliability of blockchains with the flexibility of AI driven automation. We describe four cooperative agents (Compliance, Token Issuance, Market Making, and Risk Control) and a coordinating core, and evaluate the system through simulation and a controlled pilot deployment. In experiments the prototype delivers on demand token issuance in under 1.2 s, more than 100 times faster than manual workflows. The Market Making agent maintains tight liquidity with spreads often below 0.5 percent even under volatile conditions. Fault injection tests show resilience: an oracle price spoofing attack is detected and mitigated within 10 s, and a simulated vault mis reporting halts issuance immediately with minimal user impact. The architecture scales to 5000 transactions per second with 10000 concurrent users in benchmarks. These results indicate that an AI agent based decentralized exchange for alternative assets can satisfy rigorous performance and safety requirements. We discuss broader implications for democratizing access to traditionally illiquid assets and explain how our governance model -- multi signature agent updates and on chain community voting on risk parameters -- provides ongoing transparency, adaptability, and formal assurance of system integrity.', 'abstract_zh': '去中心化的实物替代资产（如黄金）交易需要将物理资产保管与区块链系统相结合，同时满足严格的合规、流动性及风险管理要求。我们提出了GoldMine OS，一种研究导向的架构，采用多个专门的AI代理自动化并安全地将实物黄金Token化为基于区块链的稳定币（OZ）。我们的方法结合了链上智能合约进行关键的风险控制与链下AI代理进行决策，将区块链的透明性和可靠性与AI驱动自动化的优势结合起来。我们描述了四个协作代理（合规性、Token发行、做市与风险管理）和一个协调核心，并通过仿真和受控试点部署评估了系统。实验结果表明，原型可在1.2秒内响应需求发行Token，比手工流程快100多倍。做市代理在波动条件下维持紧密的流动性，价差通常低于0.5％。故障注入测试表明系统的弹性：模拟预言机价格欺骗攻击在10秒内被检测并缓解，模拟金库报告错误立即停止发行，对用户的影响最小。架构在基准测试中可实现每秒5000笔交易、同时支持10000个并发用户。这些结果表明，基于AI代理的去中心化交易平台可以满足严格的性能和安全要求。我们讨论了这种架构对传统流动性差的资产实现民主化访问的更广泛影响，并解释了我们的治理模型——多签名代理更新和链上社区对风险参数的投票——如何提供持续的透明性、适应性和系统完整性的正式验证。', 'title_zh': 'AI代理架构 for 分布式交易替代资产'}
{'arxiv_id': 'arXiv:2507.11083', 'title': 'Function-to-Style Guidance of LLMs for Code Translation', 'authors': 'Longhui Zhang, Bin Wang, Jiahao Wang, Xiaofeng Zhao, Min Zhang, Hao Yang, Meishan Zhang, Yu Li, Jing Li, Jun Yu, Min Zhang', 'link': 'https://arxiv.org/abs/2507.11083', 'abstract': 'Large language models (LLMs) have made significant strides in code translation tasks. However, ensuring both the correctness and readability of translated code remains a challenge, limiting their effective adoption in real-world software development. In this work, we propose F2STrans, a function-to-style guiding paradigm designed to progressively improve the performance of LLMs in code translation. Our approach comprises two key stages: (1) Functional learning, which optimizes translation correctness using high-quality source-target code pairs mined from online programming platforms, and (2) Style learning, which improves translation readability by incorporating both positive and negative style examples. Additionally, we introduce a novel code translation benchmark that includes up-to-date source code, extensive test cases, and manually annotated ground-truth translations, enabling comprehensive functional and stylistic evaluations. Experiments on both our new benchmark and existing datasets demonstrate that our approach significantly improves code translation performance. Notably, our approach enables Qwen-1.5B to outperform prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code translation scenarios.', 'abstract_zh': '大规模语言模型（LLMs）在代码翻译任务中取得了显著进展。然而，确保翻译代码的正确性和可读性仍然是一个挑战，限制了其在实际软件开发中的有效应用。在本工作中，我们提出了一种基于功能导向的代码翻译范式F2STrans，旨在逐步提升LLMs在代码翻译中的性能。我们的方法包括两个关键阶段：（1）功能学习，通过从在线编程平台中挖掘高质量的源-目标代码对来优化翻译正确性；（2）风格学习，通过结合正反面的风格示例来提升翻译可读性。此外，我们引入了一个新的代码翻译基准，其中包括最新的源代码、广泛的测试案例以及人工标注的真实翻译，从而能够进行全面的功能和风格评估。在我们新的基准和现有数据集上的实验表明，我们的方法显著提升了代码翻译性能。值得注意的是，我们的方法使得Qwen-1.5B在20个不同的代码翻译场景中平均性能优于增强提示的Qwen-32B和GPT-4。', 'title_zh': 'LLM代码翻译的功能与风格指导'}
{'arxiv_id': 'arXiv:2507.11079', 'title': 'Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander', 'authors': 'Li Wang, Qizhen Wu, Lei Chen', 'link': 'https://arxiv.org/abs/2507.11079', 'abstract': 'In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.', 'abstract_zh': '在多智能地面车辆对抗中，从态势感知自主演化多代理战术决策仍然是一项重大挑战。传统手工规则方法在复杂多变的战场环境中变得脆弱，当前的强化学习方法主要侧重于动作操控而非战略决策，缺乏可解释性。在此，我们提出一种基于视觉语言模型的指挥官，以解决自主对抗中的智能感知到决策推理问题。我们的方法结合视觉语言模型进行场景理解以及轻量级大型语言模型进行战略推理，在共享语义空间中实现统一的感知与决策，具有较强的适应性和可解释性。与基于规则的搜索和强化学习方法不同，两模块的结合建立了完整的链路过程，反映了人类指挥官的认知过程。仿真实验和消融实验验证了所提出的方法在基线模型上的胜率超过80%。', 'title_zh': '基于视觉-语言模型指挥官的多无人地面车辆战术决策'}
{'arxiv_id': 'arXiv:2507.11060', 'title': 'Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing', 'authors': 'Yilmazcan Ozyurt, Tunaberk Almaci, Stefan Feuerriegel, Mrinmaya Sachan', 'link': 'https://arxiv.org/abs/2507.11060', 'abstract': 'We introduce ExRec, a general framework for personalized exercise recommendation with semantically-grounded knowledge tracing. Our method builds on the observation that existing exercise recommendation approaches simulate student performance via knowledge tracing (KT) but they often overlook two key aspects: (a) the semantic content of questions and (b) the sequential, structured progression of student learning. To address this, our ExRec presents an end-to-end pipeline, from annotating the KCs of questions and learning their semantic representations to training KT models and optimizing several reinforcement learning (RL) methods. Moreover, we improve standard Q-learning-based continuous RL methods via a tailored model-based value estimation (MVE) approach that directly leverages the components of KT model in estimating cumulative knowledge improvement. We validate the effectiveness of our ExRec using various RL methods across four real-world tasks with different educational goals in online math learning. We further show that ExRec generalizes robustly to new, unseen questions and that it produces interpretable student learning trajectories. Together, our findings highlight the promise of KT-guided RL for effective personalization in education.', 'abstract_zh': '基于语义指导的知识追踪的个性化锻炼推荐框架：ExRec', 'title_zh': '基于语义引导的知识追踪的个性化锻炼推荐'}
{'arxiv_id': 'arXiv:2507.10993', 'title': 'Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction', 'authors': 'Emir Durakovic, Min-Hong Shih', 'link': 'https://arxiv.org/abs/2507.10993', 'abstract': "Due to climate-induced changes, many habitats are experiencing range shifts away from their traditional geographic locations (Piguet, 2011). We propose a solution to accurately model whether bird species are present in a specific habitat through the combination of Convolutional Neural Networks (CNNs) (O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery and environmental features (e.g., temperature, precipitation, elevation) to predict bird presence across various climates. The CNN model captures spatial characteristics of landscapes such as forestation, water bodies, and urbanization, whereas the tabular method uses ecological and geographic data. Both systems predict the distribution of birds with an average accuracy of 85%, offering a scalable but reliable method to understand bird migration.", 'abstract_zh': '由于气候诱导的变化，许多栖息地正经历着范围移迁，远离其传统的地理位置（Piguet, 2011）。我们提出通过卷积神经网络（CNNs）与表格数据的结合来准确建模特定栖息地中鸟类物种的存在性。我们的方法利用卫星图像和环境特征（如温度、降水、海拔）来预测各种气候下的鸟类分布。CNN模型捕获了景观的空间特征，如森林布局、水体和城市化，而表格方法则使用生态和地理数据。两种系统在鸟类分布的预测上平均准确率为85%，提供了一种可扩展且可靠的了解鸟类迁徙的方法。', 'title_zh': 'modeling 生态位转变：结合卷积神经网络和表格数据进行物种迁移预测'}
{'arxiv_id': 'arXiv:2507.10923', 'title': 'Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization', 'authors': 'Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen', 'link': 'https://arxiv.org/abs/2507.10923', 'abstract': 'Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and denovo design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.', 'abstract_zh': '蛋白质语言模型已成为序列生成的强大工具，为功能优化和从头设计提供了显著优势。然而，这些模型也存在生成有害蛋白质序列的重大风险，如增强病毒传染性或逃避免疫响应等。这些问题突显了关键的生物安全和伦理挑战。为应对这些挑战，我们提出了一种知识导向的偏好优化（KPO）框架，该框架通过蛋白质安全知识图谱整合先验知识。该框架利用高效的图修剪策略来识别优选序列，并运用强化学习来最小化生成有害蛋白质的风险。实验结果表明，KPO 有效降低了产生危险序列的可能性，同时保持了高功能，为在生物技术中应用生成模型提供了稳健的安全保障框架。', 'title_zh': '通过知识偏好优化增强安全可控的蛋白质生成'}
{'arxiv_id': 'arXiv:2507.10911', 'title': 'Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation', 'authors': 'Yicong Wu, Ting Chen, Irit Hochberg, Zhoujian Sun, Ruth Edry, Zhengxing Huang, Mor Peleg', 'link': 'https://arxiv.org/abs/2507.10911', 'abstract': 'Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts. Existing decision support systems face scalability limitations. Inspired by the way in which general practitioners (GP) manage multimorbidity patients, occasionally convening multidisciplinary team (MDT) collaboration, this study investigated the feasibility and value of using a Large Language Model (LLM)-based multi-agent system (MAS) for safer therapy recommendations. We designed a single agent and a MAS framework simulating MDT decision-making by enabling discussion among LLM agents to resolve medical conflicts. The systems were evaluated on therapy planning tasks for multimorbidity patients using benchmark cases. We compared MAS performance with single-agent approaches and real-world benchmarks. An important contribution of our study is the definition of evaluation metrics that go beyond the technical precision and recall and allow the inspection of clinical goals met and medication burden of the proposed advices to a gold standard benchmark. Our results show that with current LLMs, a single agent GP performs as well as MDTs. The best-scoring models provide correct recommendations that address all clinical goals, yet the advices are incomplete. Some models also present unnecessary medications, resulting in unnecessary conflicts between medication and conditions or drug-drug interactions.', 'abstract_zh': '基于大规模语言模型的多Agent系统在慢性多病患者治疗推荐中的可行性和价值研究', 'title_zh': '基于LLM的多代理在安全疗法推荐评估中获得的教训'}
{'arxiv_id': 'arXiv:2507.10894', 'title': 'NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization', 'authors': 'Zongtao He, Liuyi Wang, Lu Chen, Chengju Liu, Qijun Chen', 'link': 'https://arxiv.org/abs/2507.10894', 'abstract': 'Language-guided navigation is a cornerstone of embodied AI, enabling agents to interpret language instructions and navigate complex environments. However, expert-provided instructions are limited in quantity, while synthesized annotations often lack quality, making them insufficient for large-scale research. To address this, we propose NavComposer, a novel framework for automatically generating high-quality navigation instructions. NavComposer explicitly decomposes semantic entities such as actions, scenes, and objects, and recomposes them into natural language instructions. Its modular architecture allows flexible integration of state-of-the-art techniques, while the explicit use of semantic entities enhances both the richness and accuracy of instructions. Moreover, it operates in a data-agnostic manner, supporting adaptation to diverse navigation trajectories without domain-specific training. Complementing NavComposer, we introduce NavInstrCritic, a comprehensive annotation-free evaluation system that assesses navigation instructions on three dimensions: contrastive matching, semantic consistency, and linguistic diversity. NavInstrCritic provides a holistic evaluation of instruction quality, addressing limitations of traditional metrics that rely heavily on expert annotations. By decoupling instruction generation and evaluation from specific navigation agents, our method enables more scalable and generalizable research. Extensive experiments provide direct and practical evidence for the effectiveness of our method.', 'abstract_zh': '基于语言的导航是实体AI的基石，使代理能够解析语言指令并导航复杂环境。然而，专家提供的指令数量有限，而合成的注释往往质量不足，无法满足大规模研究的需要。为了解决这一问题，我们提出NavComposer，一种自动生成高质量导航指令的新型框架。NavComposer明确分解了语义实体，如动作、场景和对象，并重新组合成自然语言指令。其模块化架构允许灵活集成当前最先进的技术，而明确使用语义实体增强了指令的丰富性和准确性。此外，它以数据无关的方式运行，支持针对多样化的导航轨迹进行适应，无需特定领域的训练。与NavComposer互补，我们引入了NavInstrCritic，这是一种全面的无注释评估系统，从对比匹配、语义一致性和语言多样性三个维度评估导航指令。NavInstrCritic提供了一种整体性的指令质量评估，克服了传统评估指标严重依赖专家注释的局限性。通过将指令生成和评估与特定导航代理解耦，我们的方法能够促进更大规模和更通用的研究。广泛的实验提供了直接且实用的有效性证据。', 'title_zh': 'NavComposer: 通过动作-场景-对象模块化组成导航指令的trajectory生成方法'}
{'arxiv_id': 'arXiv:2507.10860', 'title': 'WhisperKit: On-device Real-time ASR with Billion-Scale Transformers', 'authors': 'Atila Orhon, Arda Okan, Berkin Durmus, Zach Nagengast, Eduardo Pacheco', 'link': 'https://arxiv.org/abs/2507.10860', 'abstract': 'Real-time Automatic Speech Recognition (ASR) is a fundamental building block for many commercial applications of ML, including live captioning, dictation, meeting transcriptions, and medical scribes. Accuracy and latency are the most important factors when companies select a system to deploy. We present WhisperKit, an optimized on-device inference system for real-time ASR that significantly outperforms leading cloud-based systems. We benchmark against server-side systems that deploy a diverse set of models, including a frontier model (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and an open-source model (Fireworks large-v3-turbo).Our results show that WhisperKit matches the lowest latency at 0.46s while achieving the highest accuracy 2.2% WER. The optimizations behind the WhisperKit system are described in detail in this paper.', 'abstract_zh': '实时自动语音识别(ASR)优化系统WhisperKit：显著超越领先云服务系统的装置端推理解决方案', 'title_zh': 'WhisperKit：基于设备的实时ASR与十亿规模变压器'}
{'arxiv_id': 'arXiv:2507.10831', 'title': 'AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks', 'authors': 'Yilin Xia, Heng Zheng, Shawn Bowers, Bertram Ludäscher', 'link': 'https://arxiv.org/abs/2507.10831', 'abstract': 'Argumentation frameworks (AFs) provide formal approaches for legal reasoning, but identifying sources of ambiguity and explaining argument acceptance remains challenging for non-experts. We present AF-XRAY, an open-source toolkit for exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY introduces: (i) layered visualizations based on game-theoretic argument length revealing well-founded derivation structures; (ii) classification of attack edges by semantic roles (primary, secondary, blunders); (iii) overlay visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded semantics; and (iv) identification of critical attack sets whose suspension resolves undecided arguments. Through systematic generation of critical attack sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling users to pinpoint specific causes of ambiguity and explore alternative resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by Bench-Capon) to show that our tool supports teleological legal reasoning by revealing how different assumptions lead to different justified conclusions.', 'abstract_zh': 'Argumentation frameworks (AFs)为法律推理提供了形式化的研究方法，但识别模糊源和解释论据接受仍具有挑战性，尤其对于非专家而言。我们提出了AF-XRAY，一个用于探索、分析和可视化抽象法律推理AF的开源工具包。AF-XRAY引入了基于博弈论论据长度的分层可视化，揭示了稳固的演绎结构；通过语义角色（主要攻击、次要攻击、失误）分类攻击边；在模棱两可的三值基础语义上叠加可视化不同的二值解决方案；并识别关键攻击集，其吊销可解决未决论点。通过系统生成关键攻击集，AF-XRAY将模棱两可的情景转化为可靠解决方案，使用户能够明确具体导致模糊的原因并探索替代解决方案。我们使用实际案例（如Bench-Capon模型的野生动植物）来表明，该工具支持目的论法律推理，展示了不同假设如何导致不同的正当结论。', 'title_zh': 'AF-XRAY：法律论证框架中歧义的视觉解释与解析'}
{'arxiv_id': 'arXiv:2507.10803', 'title': 'Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case', 'authors': 'JaMor Hairston, Ritvik Ranjan, Sahithi Lakamana, Anthony Spadaro, Selen Bozkurt, Jeanmarie Perrone, Abeed Sarker', 'link': 'https://arxiv.org/abs/2507.10803', 'abstract': 'Background Large language models (LLMs) face challenges in inductive thematic analysis, a task requiring deep interpretive and domain-specific expertise. We evaluated the feasibility of using LLMs to replicate expert-driven thematic analysis of social media data. Methods Using two temporally non-intersecting Reddit datasets on xylazine (n=286 and n=686, for model optimization and validation, respectively) with twelve expert-derived themes, we evaluated five LLMs against expert coding. We modeled the task as a series of binary classifications, rather than a single, multi-label classification, employing zero-, single-, and few-shot prompting strategies and measuring performance via accuracy, precision, recall, and F1-score. Results On the validation set, GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score: 0.71). For high-prevalence themes, model-derived thematic distributions closely mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use: 16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based approaches can automate thematic analyses, offering a scalable supplement for qualitative research. Keywords: thematic analysis, large language models, natural language processing, qualitative analysis, social media, prompt engineering, public health', 'abstract_zh': '背景：大规模语言模型在归纳主题分析任务中面临挑战，该任务需要深入的解释性和领域特定的专业知识。我们评估了使用大规模语言模型复制专家驱动的社交媒体数据主题分析可行性的方法。方法：使用两个时间上不重叠的关于xylazine的Reddit数据集（分别为n=286和n=686，用于模型优化和验证），包含十二个专家提取的主题，我们对五个大规模语言模型进行了评估，以与专家编码进行比较。我们将任务模型化为一系列二分类任务，而不是一个单一的多标签分类任务，采用了零样本、单样本和少样本提示策略，并通过准确率、精确率、召回率和F1分数来衡量性能。结果：在验证集上，使用两样本提示的GPT-4o性能最佳（准确率：90.9%；F1分数：0.71）。对于高频率主题，模型提取的主题分布与专家分类高度一致（例如，xylazine使用情况：13.6% vs. 17.8%；莫顿类使用情况：16.5% vs. 17.8%）。结论：我们的研究结果表明，少样本的大规模语言模型方法可以自动化主题分析，为定量研究提供可扩展的补充。关键词：主题分析，大规模语言模型，自然语言处理，定量分析，社交媒体，提示工程，公共卫生', 'title_zh': '使用大语言模型自动主题分析：Xylazine伤口管理社交媒体讨论案例研究'}
{'arxiv_id': 'arXiv:2507.10798', 'title': 'Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions', 'authors': 'Asim H. Gazi, Bhanu T. Gullapalli, Daiqi Gao, Benjamin M. Marlin, Vivek Shetty, Susan A. Murphy', 'link': 'https://arxiv.org/abs/2507.10798', 'abstract': 'Timely decision making is critical to the effectiveness of mobile health (mHealth) interventions. At predefined timepoints called "decision points," intelligent mHealth systems such as just-in-time adaptive interventions (JITAIs) estimate an individual\'s biobehavioral context from sensor or survey data and determine whether and how to intervene. For interventions targeting habitual behavior (e.g., oral hygiene), effectiveness often hinges on delivering support shortly before the target behavior is likely to occur. Current practice schedules decision points at a fixed interval (e.g., one hour) before user-provided behavior times, and the fixed interval is kept the same for all individuals. However, this one-size-fits-all approach performs poorly for individuals with irregular routines, often scheduling decision points after the target behavior has already occurred, rendering interventions ineffective. In this paper, we propose SigmaScheduling, a method to dynamically schedule decision points based on uncertainty in predicted behavior times. When behavior timing is more predictable, SigmaScheduling schedules decision points closer to the predicted behavior time; when timing is less certain, SigmaScheduling schedules decision points earlier, increasing the likelihood of timely intervention. We evaluated SigmaScheduling using real-world data from 68 participants in a 10-week trial of Oralytics, a JITAI designed to improve daily toothbrushing. SigmaScheduling increased the likelihood that decision points preceded brushing events in at least 70% of cases, preserving opportunities to intervene and impact behavior. Our results indicate that SigmaScheduling can advance precision mHealth, particularly for JITAIs targeting time-sensitive, habitual behaviors such as oral hygiene or dietary habits.', 'abstract_zh': '及时决策对于移动健康(mHealth)干预的有效性至关重要。基于预定义的时间点称为“决策点”，智能mHealth系统如及时自适应干预(JITAIs)会从传感器数据或调查数据中估算个体的生理行为上下文，并决定是否以及如何干预。对于旨在改变习惯性行为（例如口腔卫生）的干预措施，功效往往取决于在目标行为很可能发生之前不久提供支持。当前的做法是在用户提供的行为时间前固定间隔（例如一小时）安排决策点，并且该固定间隔对所有个体保持一致。然而，这种一刀切的方法对于具有不规则日常活动的个体性能较差，经常导致决策点安排在目标行为已经发生之后，使得干预无效。本文中，我们提出了SigmaScheduling方法，该方法基于预测行为时间的不确定性动态安排决策点。当行为时间可预测性较高时，SigmaScheduling将决策点更接近预测行为时间安排；当时间不确定性较大时，SigmaScheduling则更早地安排决策点，以增加及时干预的可能性。我们使用Oralytics在10周时间内的68名参与者中进行的实际数据评估了SigmaScheduling，Oralytics是一种旨在改善日常刷牙行为的JITAI工具。SigmaScheduling提高了决策点在至少70%的情况下发生在刷牙之前的概率，从而保留了干预和影响行为的机会。我们的结果表明，SigmaScheduling可以推进精准mHealth，特别适用于如口腔卫生或饮食习惯等时间敏感的习惯性行为的JITAIs。', 'title_zh': '基于不确定性指导的决策点调度方法在智能移动健康干预中的应用'}
{'arxiv_id': 'arXiv:2507.10761', 'title': 'Detecting AI Assistance in Abstract Complex Tasks', 'authors': 'Tyler King, Nikolos Gurney, John H. Miller, Volkan Ustun', 'link': 'https://arxiv.org/abs/2507.10761', 'abstract': 'Detecting assistance from artificial intelligence is increasingly important as they become ubiquitous across complex tasks such as text generation, medical diagnosis, and autonomous driving. Aid detection is challenging for humans, especially when looking at abstract task data. Artificial neural networks excel at classification thanks to their ability to quickly learn from and process large amounts of data -- assuming appropriate preprocessing. We posit detecting help from AI as a classification task for such models. Much of the research in this space examines the classification of complex but concrete data classes, such as images. Many AI assistance detection scenarios, however, result in data that is not machine learning-friendly. We demonstrate that common models can effectively classify such data when it is appropriately preprocessed. To do so, we construct four distinct neural network-friendly image formulations along with an additional time-series formulation that explicitly encodes the exploration/exploitation of users, which allows for generalizability to other abstract tasks. We benchmark the quality of each image formulation across three classical deep learning architectures, along with a parallel CNN-RNN architecture that leverages the additional time series to maximize testing performance, showcasing the importance of encoding temporal and spatial quantities for detecting AI aid in abstract tasks.', 'abstract_zh': '随着人工智能在复杂任务如文本生成、医疗诊断和自主驾驶中变得无处不在，检测人工智能提供的帮助变得日益重要。在面对抽象任务数据时，人工神经网络因其能够快速学习和处理大量数据而适用于分类任务——前提是适当的预处理。我们将检测来自AI的帮助视为这种模型的分类任务。该领域中的许多研究都关注复杂但具体的数据类别的分类，如图像。然而，许多人工智能辅助检测场景会产生对机器学习不友好的数据。我们证明，在适当预处理的情况下，常用模型可以有效分类此类数据。为此，我们构建了四种不同的神经网络友好型图像表示，并额外构造了一个明确编码用户探索/开发过程的时间序列表示，这使模型具有泛化到其他抽象任务的能力。我们使用三种经典深度学习架构以及一个利用额外时间序列以最大化测试性能的并行CNN-RNN架构，对每种图像表示的质量进行了基准测试，强调了在检测抽象任务中的人工智能辅助时编码时间和空间量的重要性。', 'title_zh': '检测AI在复杂任务摘要中的辅助作用'}
{'arxiv_id': 'arXiv:2507.10758', 'title': 'IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models', 'authors': 'Nikesh Prajapati, Bimal Karki, Saroj Gopali, Akbar Siami Namin', 'link': 'https://arxiv.org/abs/2507.10758', 'abstract': 'This paper intends to detect IoT malicious attacks through deep learning models and demonstrates a comprehensive evaluation of the deep learning and graph-based models regarding malicious network traffic detection. The models particularly are based on GraphSAGE, Bidirectional encoder representations from transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM) Multi-Head Attention and BI-LSTM and LSTM models. The chosen models demonstrated great performance to model temporal patterns and detect feature significance. The observed performance are mainly due to the fact that IoT system traffic patterns are both sequential and diverse, leaving a rich set of temporal patterns for the models to learn. Experimental results showed that BERT maintained the best performance. It achieved 99.94% accuracy rate alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which demonstrates its capabilities through temporal dependency capture. The Multi-Head Attention offered promising results by providing good detection capabilities with interpretable results. On the other side, the Multi-Head Attention model required significant processing time like BI-LSTM variants. The GraphSAGE model achieved good accuracy while requiring the shortest training time but yielded the lowest accuracy, precision, and F1 score compared to the other models', 'abstract_zh': '通过深度学习模型检测物联网恶意攻击：基于图的模型和序列模型的综合评估', 'title_zh': '基于深度学习和GraphSAGE模型的物联网恶意软件网络流量检测'}
{'arxiv_id': 'arXiv:2507.10750', 'title': 'AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition', 'authors': 'Pandu Devarakota, Nicolas Tsesmetzis, Faruk O. Alpak, Apurva Gala, Detlef Hohl', 'link': 'https://arxiv.org/abs/2507.10750', 'abstract': "Thanks to the availability of massive amounts of data, computing resources, and advanced algorithms, AI has entered nearly every sector. This has sparked significant investment and interest, particularly in building data centers with the necessary hardware and software to develop and operate AI models and AI-based workflows. In this technical review article, we present energy consumption scenarios of data centers and impact on GHG emissions, considering both near-term projections (up to 2030) and long-term outlook (2035 and beyond). We address the quintessential question of whether AI will have a net positive, neutral, or negative impact on CO2 emissions by 2035. Additionally, we discuss AI's potential to automate, create efficient and disruptive workflows across various fields related to energy production, supply and consumption. In the near-term scenario, the growing demand for AI will likely strain computing resources, lead to increase in electricity consumption and therefore associated CO2 emissions. This is due to the power-hungry nature of big data centers and the requirements for training and running of large and complex AI models, as well as the penetration of AI assistant search and applications for public use. However, the long-term outlook could be more promising. AI has the potential to be a game-changer in CO2 reduction. Its ability to further automate and optimize processes across industries, from energy production to logistics, could significantly decrease our carbon footprint. This positive impact is anticipated to outweigh the initial emissions bump, creating value for businesses and society in areas where traditional solutions have fallen short. In essence, AI might cause some initial growing pains for the environment, but it has the potential to support climate mitigation efforts.", 'abstract_zh': '得益于大量数据、计算资源和先进算法的 availability，AI 已几乎进入每一个领域。这引发了显著的投资和兴趣，尤其是在建设必要的硬件和软件以开发和运行 AI 模型及 AI 基础工作流方面。在本文中，我们综合了短期预测（至2030年）和长期展望（2035年及以后），讨论了数据中心的能量消耗情景及其对温室气体排放的影响。我们探讨了到2035年，AI 是否会对二氧化碳排放产生净积极、中性和消极影响。此外，我们还讨论了 AI 在能源生产、供应和消费相关领域的自动化和创造高效颠覆性工作流的潜力。在短期内，AI 需求的增长可能会给计算资源带来压力，导致电力消耗和相关二氧化碳排放的增加。这主要是由于大数据中心耗电量大以及训练和运行大型复杂 AI 模型的需求，以及 AI 辅助搜索和公共应用的普及。然而，长期来看，情况可能更有前景。AI 有可能成为减少二氧化碳排放的决定性因素。其在工业各领域进一步自动化和优化过程的能力，从能源生产到物流，有可能显著降低我们的碳足迹。这一积极影响预计会超过初始排放增加的影响，为在传统解决方案失败的领域创造业务和社会价值。总的来说，AI 可能会短期内对环境造成一些痛苦，但它有潜力支持气候变化缓解努力。', 'title_zh': 'AI与净零转型：能源需求、排放及过渡潜力'}
{'arxiv_id': 'arXiv:2507.10740', 'title': 'Parsing Musical Structure to Enable Meaningful Variations', 'authors': 'Maziar Kanani, Sean O Leary, James McDermott', 'link': 'https://arxiv.org/abs/2507.10740', 'abstract': "This paper presents a novel rule-based approach for generating music by varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [ 1], that is a structure representing all repetitions in the tune. The Sequitur algorithm [2 ] is used for this. The result is a grammar. We then carry out mutation on the grammar, rather than on a tune directly. There are potentially 19 types of mutations such as adding, removing, swapping or reversing parts of the grammar that can be applied to the grammars. The system employs one of the mutations randomly in this step to automatically manipulate the grammar. Following the mutation, we need to expand the grammar which returns a new tune. The output after 1 or more mutations will be a new tune related to the original tune. Our study examines how tunes change gradually over the course of multiple mutations. Edit distances, structural complexity and length of the tunes are used to show how a tune is changed after multiple mutations. In addition, the size of effect of each mutation type is analyzed. As a final point, we review the musical aspect of the output tunes. It should be noted that the study only focused on generating new pitch sequences. The study is based on an Irish traditional tune dataset and a list of integers has been used to represent each tune's pitch values.", 'abstract_zh': '基于规则的方法生成音乐的新颖途径：通过变化现有曲调实现音乐生成', 'title_zh': '解析音乐结构以实现有意义的变化'}
{'arxiv_id': 'arXiv:2507.10644', 'title': 'From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents', 'authors': 'Tatiana Petrova, Aleksandr Puzikov, Boris Bliznukov, Radu State', 'link': 'https://arxiv.org/abs/2507.10644', 'abstract': "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.", 'abstract_zh': 'Web of Agents (WoA)的演化综述：从多代理系统到语义web的智能代理架构演变', 'title_zh': '从语义 web 和MAS到有能动性的AI：代理网络中的统一叙事'}
{'arxiv_id': 'arXiv:2507.10630', 'title': 'Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs', 'authors': 'Ye Yang, Xue Xiao, Ping Yin, Taotao Xie', 'link': 'https://arxiv.org/abs/2507.10630', 'abstract': 'API calls by large language models (LLMs) offer a cutting-edge approach for data analysis. However, their ability to effectively utilize tools via API calls remains underexplored in knowledge-intensive domains like meteorology. This paper introduces KG2data, a system that integrates knowledge graphs, LLMs, ReAct agents, and tool-use technologies to enable intelligent data acquisition and query handling in the meteorological field. Using a virtual API, we evaluate API call accuracy across three metrics: name recognition failure, hallucination failure, and call correctness. KG2data achieves superior performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based systems by addressing their limited access to domain-specific knowledge, which hampers performance on complex or terminology-rich queries. By using a knowledge graph as persistent memory, our system enhances content retrieval, complex query handling, domain-specific reasoning, semantic relationship resolution, and heterogeneous data integration. It also mitigates the high cost of fine-tuning LLMs, making the system more adaptable to evolving domain knowledge and API structures. In summary, KG2data provides a novel solution for intelligent, knowledge-based question answering and data analysis in domains with high knowledge demands.', 'abstract_zh': '大规模语言模型（LLMs）的API调用为数据解析提供了前沿的方法，但在气象等知识密集型领域，它们通过API调用有效利用工具的能力仍待探索。本文介绍了一种KG2data系统，该系统结合了知识图谱、LLMs、ReAct代理和工具使用技术，以在气象领域实现智能数据采集和查询处理。通过虚拟API，我们根据命名识别失败、幻觉失败和调用正确性三个指标评估API调用的准确性。KG2data在三个指标上的性能分别为1.43%、0%、88.57%，显著优于RAG2data（16%，10%，72.14%）和chat2data（7.14%，8.57%，71.43%）。与典型的基于LLM的系统相比，KG2data通过解决LLMs对领域特定知识访问有限的问题，提高了处理复杂或术语丰富的查询的能力。利用知识图谱作为持久化内存，我们的系统增强了内容检索、复杂查询处理、领域特定推理、语义关系解析和异构数据集成，并降低了对LLM微调的高成本，使系统更具适应性，能够更好地应对领域知识和API结构的演变。总之，KG2data为高知识需求领域提供了智能、基于知识的问题回答和数据分析的创新解决方案。', 'title_zh': '通过知识图谱增强大型语言模型的API调用能力'}
{'arxiv_id': 'arXiv:2507.10624', 'title': 'Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning', 'authors': 'Zheng Zhang', 'link': 'https://arxiv.org/abs/2507.10624', 'abstract': 'Large Language Models (LLMs) display striking surface fluency yet systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy, and logical consistency. This paper offers a structural diagnosis of such failures, revealing a persistent gap between \\textit{comprehension} and \\textit{competence}. Through controlled experiments and architectural analysis, we demonstrate that LLMs often articulate correct principles without reliably applying them--a failure rooted not in knowledge access, but in computational execution. We term this phenomenon the computational \\textit{split-brain syndrome}, where instruction and action pathways are geometrically and functionally dissociated. This core limitation recurs across domains, from mathematical operations to relational inferences, and explains why model behavior remains brittle even under idealized prompting. We argue that LLMs function as powerful pattern completion engines, but lack the architectural scaffolding for principled, compositional reasoning. Our findings delineate the boundary of current LLM capabilities and motivate future models with metacognitive control, principle lifting, and structurally grounded execution. This diagnosis also clarifies why mechanistic interpretability findings may reflect training-specific pattern coordination rather than universal computational principles, and why the geometric separation between instruction and execution pathways suggests limitations in neural introspection and mechanistic analysis.', 'abstract_zh': '大型语言模型（LLMs）表现出色的表面流畅性，但在需要符号推理、算术准确性和逻辑一致性的任务上系统性地失败。本文提供了一种结构性诊断，揭示了理解与能力之间持续存在的差距。通过受控实验和架构分析，我们证明LLMs往往能够表述正确的原则，但无法可靠地应用这些原则——这种失败并非源于知识访问，而是计算执行的不足。我们称之为计算分裂脑综合症，其中指令路径和行动路径在空间上和功能上是分离的。这一核心限制在各个领域都存在，从数学运算到关系推理，并解释了即使在理想化的提示下，模型行为仍然脆弱的原因。我们认为LLMs充当强大的模式补全引擎，但缺乏用于原理化、组合推理的架构支撑。我们的发现界定了当前LLM能力的边界，并促使未来的模型具备元认知控制、原理提升和结构支撑的执行能力。此外，这一诊断也阐明了机制可解释性研究可能反映出训练特定的模式协调，而非普适的计算原理，并解释了指令路径和执行路径的几何分离如何表明神经内省和机制分析的局限性。', 'title_zh': '理解而无能力：大语言模型在符号计算与推理方面的架构限制'}
{'arxiv_id': 'arXiv:2507.10571', 'title': 'Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning', 'authors': 'Konstantinos I. Roumeliotis, Ranjan Sapkota, Manoj Karkee, Nikolaos D. Tselikas', 'link': 'https://arxiv.org/abs/2507.10571', 'abstract': 'Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint is extensible to diagnostics, biology, and other trust-critical domains. All models, prompts, results, and system components including the complete software source code are openly released to support reproducibility, transparency, and community benchmarking at Github: this https URL', 'abstract_zh': '现代人工智能（AI）越来越多地依赖融合视觉和语言理解的多agent架构。然而，一个紧迫的挑战依然存在：我们在零样本设置下，即没有任何微调的情况下，如何信任这些agent？我们提出了一种新颖的模块化Agentic AI视觉分类框架，该框架结合了一般主义多模态agent、非视觉推理协调器和检索增强生成（RAG）模块。应用于苹果叶病诊断，我们对三种配置进行了基准测试：（I）基于信心的零样本协调、（II）微调后的agent性能得到提升、（III）通过基于CLIP的图像检索和再评价循环增强的信任校准协调。使用信任校准指标（ECE、OCR、CCC），协调器在agent之间调整信任。我们的结果显示，在使用信任感知协调和RAG的零样本设置中，准确率提高了77.94%，整体达到85.63%。GPT-4o展示了更好的校准，而Qwen-2.5-VL则表现出过大的自信。此外，通过迭代再评价将图像-RAG与视觉上相似的案例结合起来，能够纠正agent的过自信。该系统将感知（视觉agent）与元推理（协调器）分离，使多agent AI具备可扩展性和可解释性。该蓝图可以扩展到诊断、生物学和其他依赖信任的领域。所有模型、提示、结果和系统组件包括完整的软件源代码均已在Github公开发布，以支持可重复性、透明性和社区基准测试：this https URL。', 'title_zh': 'Orchestrator-Agent Trust: 一种具有信任意识编排和基于RAG的推理的模块化代理AI视觉分类系统'}
{'arxiv_id': 'arXiv:2507.10566', 'title': 'AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems', 'authors': 'Hung Ming Liu', 'link': 'https://arxiv.org/abs/2507.10566', 'abstract': "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development of Emergent Communication has long been constrained by the ``Joint Exploration Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' . Traditional methods address this by introducing inductive biases to facilitate communication emergence . This study fundamentally questions whether such artificial inductive biases are, in fact, over-engineering. Through experiments with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an endogenous symbol system, their neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. This aligns with recent neuroscience findings suggesting that the human brain does not directly use human language for internal thought , and resonates with research on ``soft thinking'' capabilities in Large Language Models (LLMs) . Compared to traditional explicit communication methods, AIM demonstrates stronger generality and efficiency. The interpretable analysis toolkit developed in this study confirms that symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the ``Neural Communication Hypothesis'', the ``Tool-First Principle'', and the ``Semantic Interpretability Paradigm''. Future research will explore the integration of Hierarchical Quantized Variational Autoencoders (HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This discovery offers new avenues for bridging symbolism and connectionism.", 'abstract_zh': '在分布式多智能体 reinforcement 学习（MARL）中，自发通信的发展长期以来受到“联合探索困境”的限制，导致智能体陷入“通信真空均衡”。传统方法通过引入归纳偏置来促进通信的自发出现。本研究从根本上质疑这种人工归纳偏置是否是一种过度工程。通过基于向量量化变分自编码器（VQ-VAE）的“AI 母语”（AIM）框架的实验，我们证明，在智能体具备内生符号系统的情况下，它们的神经表示自然展现出自发语义压缩和纳什均衡驱动的意义收敛，能够实现有效的象征性通信，无需外部归纳偏置。这与近期的神经科学发现相一致，表明人类大脑不直接使用人类语言进行内部思考，并与大型语言模型（LLMs）的“软思考”能力研究相呼应。与传统的显式通信方法相比，AIM 展现出更强的通用性和效率。本研究开发的可解释分析工具包证实符号使用表现出显著的幂律分布，从而产生三个主要的理论洞察：“神经通信假说”、“工具优先原则”和“语义可解释性范式”。未来的研究将探讨将分层量化变分自编码器（HQ-VAE）集成以增强 AIM 的复杂表达能力，并研究“强化学习（RL）低级预训练”的潜在可能性。这一发现为沟通符号主义和连接主义的连通提供了新途径。', 'title_zh': 'AI母语：通过内生符号系统在多智能体 reinforcement 学习中实现自主沟通'}
{'arxiv_id': 'arXiv:2507.10562', 'title': 'SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents', 'authors': 'Hari Masoor', 'link': 'https://arxiv.org/abs/2507.10562', 'abstract': "Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a novel framework that enables persistent, secure, and semantically searchable memory sharing among AI agents. Our protocol addresses three critical challenges: (1) persistent context preservation across agent sessions, (2) secure multi-agent collaboration with fine-grained access control, and (3) efficient semantic discovery of relevant historical context. SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness across diverse domains including multi-agent software development, healthcare AI with HIPAA compliance, and multi-modal processing pipelines. Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation. SAMEP enables a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees.", 'abstract_zh': '当前的AI代理架构面临着临时内存限制的问题，这妨碍了跨会话和代理边界的有效协作和知识共享。我们提出了SAMEP（Secure Agent Memory Exchange Protocol）这一新颖框架，以实现AI代理之间持久、安全且语义可搜索的记忆共享。我们的协议解决了三个关键挑战：（1）跨代理会话的持久上下文保存，（2）细粒度访问控制下的安全多代理协作，以及（3）高效的语义发现相关历史上下文。SAMEP实现了一个分布式的记忆仓库，支持向量基的语义搜索，加密访问控制（AES-256-GCM）以及与现有代理通信协议（MCP, A2A）兼容的标准API。我们展示了SAMEP在多代理软件开发、符合HIPAA规范的医疗AI以及多模态处理流水线等多个领域的有效性。实验结果显示，冗余计算减少73%，上下文相关性提高89%，并且完全符合审计追踪生成等监管要求。SAMEP开启了持久化协作AI代理生态系统的新型范式，同时保持了安全和隐私保障。', 'title_zh': 'SAMEP：跨AI代理的持久上下文共享安全协议'}
{'arxiv_id': 'arXiv:2507.11539', 'title': 'Streaming 4D Visual Geometry Transformer', 'authors': 'Dong Zhuo, Wenzhao Zheng, Jiahe Guo, Yuqi Wu, Jie Zhou, Jiwen Lu', 'link': 'https://arxiv.org/abs/2507.11539', 'abstract': 'Perceiving and reconstructing 4D spatial-temporal geometry from videos is a fundamental yet challenging computer vision task. To facilitate interactive and real-time applications, we propose a streaming 4D visual geometry transformer that shares a similar philosophy with autoregressive large language models. We explore a simple and efficient design and employ a causal transformer architecture to process the input sequence in an online manner. We use temporal causal attention and cache the historical keys and values as implicit memory to enable efficient streaming long-term 4D reconstruction. This design can handle real-time 4D reconstruction by incrementally integrating historical information while maintaining high-quality spatial consistency. For efficient training, we propose to distill knowledge from the dense bidirectional visual geometry grounded transformer (VGGT) to our causal model. For inference, our model supports the migration of optimized efficient attention operator (e.g., FlashAttention) from the field of large language models. Extensive experiments on various 4D geometry perception benchmarks demonstrate that our model increases the inference speed in online scenarios while maintaining competitive performance, paving the way for scalable and interactive 4D vision systems. Code is available at: this https URL.', 'abstract_zh': '从视频中感知和重构4D时空几何是一个基本但具有挑战性的计算机视觉任务。为了支持交互式和实时应用，我们提出了一种流式4D视觉几何变换器，其设计理念与自回归大规模语言模型类似。我们探索了一个简单而高效的架构，并采用因果变换器架构在线处理输入序列。我们利用时间因果注意力，并通过隐式记忆缓存历史键值对，以实现高效流式4D重建。该设计能够在增量集成历史信息的同时保持高质量的空间一致性。为了提高训练效率，我们提出从密集双向视觉几何基础变换器（VGGT）中提炼知识到我们的因果模型中。对于推理，我们的模型支持从大规模语言模型领域迁移优化的高效注意力算子（例如，FlashAttention）。在各种4D几何感知基准上的广泛实验表明，我们的模型在保持竞争力的同时提升了在线场景下的推理速度，为可扩展和交互式的4D视觉系统铺平了道路。代码可在以下链接获取：this https URL。', 'title_zh': 'Streaming 4D Visual Geometry Transformer'}
{'arxiv_id': 'arXiv:2507.11515', 'title': 'AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air', 'authors': 'Shiyi Yang, Xiaoxue Yu, Rongpeng Li, Jianhang Zhu, Zhifeng Zhao, Honggang Zhang', 'link': 'https://arxiv.org/abs/2507.11515', 'abstract': 'Operating Large Language Models (LLMs) on edge devices is increasingly challenged by limited communication bandwidth and strained computational and memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable. Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ fixed or heuristic rank configurations, and the subsequent over-the-air transmission of all LoRA parameters could be rather inefficient. To address this limitation, we develop AirLLM, a hierarchical diffusion policy framework for communication-aware LoRA adaptation. Specifically, AirLLM models the rank configuration as a structured action vector that spans all LoRA-inserted projections. To solve the underlying high-dimensional sequential decision-making problem, a Proximal Policy Optimization (PPO) agent generates coarse-grained decisions by jointly observing wireless states and linguistic complexity, which are then refined via Denoising Diffusion Implicit Models (DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The two modules are optimized alternatively, with the DDIM trained under the Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards. Experiments under varying signal-to-noise ratios demonstrate that AirLLM consistently enhances fine-tuning performance while significantly reducing transmission costs, highlighting the effectiveness of reinforcement-driven, diffusion-refined rank adaptation for scalable and efficient remote fine-tuning over the air.', 'abstract_zh': '基于通信感知的层级扩散洛拉适应框架（AirLLM）：强化学习驱动的远程细调优化', 'title_zh': 'AirLLM：基于扩散策略的适配LoRA远端微调空中语言模型'}
{'arxiv_id': 'arXiv:2507.11513', 'title': 'Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization', 'authors': 'Serge Gratton, Alena Kopaničáková, Philippe Toint', 'link': 'https://arxiv.org/abs/2507.11513', 'abstract': 'Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are presented that handle bound constraints, inexact gradients and use second-order information when this http URL first is a multi-level method exploiting a hierarchical description of the problem and the second is a domain-decomposition method covering the standard addditive Schwarz decompositions. Both are generalizations of the first-order AdaGrad algorithm for unconstrained optimization. Because these algorithms share a common theoretical framework, a single convergence/complexity theory is provided which covers them both. Its main result is that, with high probability, both methods need at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to compute an $\\epsilon$-approximate first-order critical point of the bound-constrained problem. Extensive numerical experiments are discussed on applications ranging from PDE-based problems to deep neural network training, illustrating their remarkable computational efficiency.', 'abstract_zh': '两种适用于边界约束、不精确梯度且利用二阶信息的OBJ-Free优化算法：一种是基于问题分层描述的多级方法，另一种是域分解方法，涵盖标准的加性 Schwarz 分解。这两种方法是无约束优化中一阶 AdaGrad 算法的一般化。由于这些算法共享相同的理论框架，提供了一个同时涵盖两者的一致收敛性和复杂度理论。其主要结果是，这两种方法在高概率下最多需要 $O(\\epsilon^{-2})$ 次迭代和梯度评估来计算边界约束问题的 $\\epsilon$-近似一阶临界点。讨论了从PDE问题到深度神经网络训练的应用实例，展示了它们卓越的计算效率。', 'title_zh': '递归界约束AdaGrad及其在多尺度和域分解最小化中的应用'}
{'arxiv_id': 'arXiv:2507.11488', 'title': 'COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation', 'authors': 'Pakizar Shamoi, Nuray Toganas, Muragul Muratbekova, Elnara Kadyrgali, Adilet Yerkin, Ayan Igali, Malika Ziyada, Ayana Adilova, Aron Karatayev, Yerdauit Torekhan', 'link': 'https://arxiv.org/abs/2507.11488', 'abstract': "Colors are omnipresent in today's world and play a vital role in how humans perceive and interact with their surroundings. However, it is challenging for computers to imitate human color perception. This paper introduces the Human Perception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based Representation and Interpretation), designed to bridge the gap between computational color representations and human visual perception. The proposed model uses fuzzy sets and logic to create a framework for color categorization. Using a three-phase experimental approach, the study first identifies distinguishable color stimuli for hue, saturation, and intensity through preliminary experiments, followed by a large-scale human categorization survey involving more than 1000 human subjects. The resulting data are used to extract fuzzy partitions and generate membership functions that reflect real-world perceptual uncertainty. The model incorporates a mechanism for adaptation that allows refinement based on feedback and contextual changes. Comparative evaluations demonstrate the model's alignment with human perception compared to traditional color models, such as RGB, HSV, and LAB. To the best of our knowledge, no previous research has documented the construction of a model for color attribute specification based on a sample of this size or a comparable sample of the human population (n = 2496). Our findings are significant for fields such as design, artificial intelligence, marketing, and human-computer interaction, where perceptually relevant color representation is critical.", 'abstract_zh': '基于人类感知的模糊颜色模型COLIBRI：颜色语言学的表征与解释', 'title_zh': 'COLIBRI 模糊模型：基于颜色语言的表示与解释'}
{'arxiv_id': 'arXiv:2507.11443', 'title': 'COLI: A Hierarchical Efficient Compressor for Large Images', 'authors': 'Haoran Wang, Hanyu Pei, Yang Lyu, Kai Zhang, Li Li, Feng-Lei Fan', 'link': 'https://arxiv.org/abs/2507.11443', 'abstract': "The escalating adoption of high-resolution, large-field-of-view imagery amplifies the need for efficient compression methodologies. Conventional techniques frequently fail to preserve critical image details, while data-driven approaches exhibit limited generalizability. Implicit Neural Representations (INRs) present a promising alternative by learning continuous mappings from spatial coordinates to pixel intensities for individual images, thereby storing network weights rather than raw pixels and avoiding the generalization problem. However, INR-based compression of large images faces challenges including slow compression speed and suboptimal compression ratios. To address these limitations, we introduce COLI (Compressor for Large Images), a novel framework leveraging Neural Representations for Videos (NeRV). First, recognizing that INR-based compression constitutes a training process, we accelerate its convergence through a pretraining-finetuning paradigm, mixed-precision training, and reformulation of the sequential loss into a parallelizable objective. Second, capitalizing on INRs' transformation of image storage constraints into weight storage, we implement Hyper-Compression, a novel post-training technique to substantially enhance compression ratios while maintaining minimal output distortion. Evaluations across two medical imaging datasets demonstrate that COLI consistently achieves competitive or superior PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while accelerating NeRV training by up to 4 times.", 'abstract_zh': '高分辨率大视野图像采用的激增放大了高效压缩方法的需求。传统的技术往往无法保留关键图像细节，而数据驱动的方法则表现出有限的泛化能力。隐式神经表示（INRs）通过从空间坐标到像素强度学习连续映射为单个图像提供了一种有前景的替代方案，从而存储网络权重而非原始像素，从而避免了泛化问题。然而，基于INR的大图像压缩面临挑战，包括压缩速度慢和压缩比不佳。为了克服这些限制，我们提出了COLI（Compressor for Large Images），一种利用视频神经表示（NeRV）的新型框架。首先，鉴于INR基压缩是一个训练过程，我们通过预训练-微调范式、混合精度训练和将顺序损失重新表述为可并行的目标来加速其收敛。其次，利用INRs将图像存储约束转化为权重存储的特点，我们实现了Hyper-Compression，这是一种新型的后训练技术，能够大幅提高压缩比同时保持最小的输出失真。针对两个医学成像数据集的评估表明，COLI在显著降低每像素比特数（bpp）的同时，实现了竞争力或优越的PSNR和SSIM指标，同时可使NeRV训练加速多达4倍。', 'title_zh': 'COLI：一种高效的分层大型图像压缩器'}
{'arxiv_id': 'arXiv:2507.11436', 'title': 'Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures', 'authors': 'Behtom Adeli, John McLinden, Pankaj Pandey, Ming Shao, Yalda Shahriari', 'link': 'https://arxiv.org/abs/2507.11436', 'abstract': 'Activation functions are critical to the performance of deep neural networks, particularly in domains such as functional near-infrared spectroscopy (fNIRS), where nonlinearity, low signal-to-noise ratio (SNR), and signal variability poses significant challenges to model accuracy. However, the impact of activation functions on deep learning (DL) performance in the fNIRS domain remains underexplored and lacks systematic investigation in the current literature. This study evaluates a range of conventional and field-specific activation functions for fNIRS classification tasks using multiple deep learning architectures, including the domain-specific fNIRSNet, AbsoluteNet, MDNN, and shallowConvNet (as the baseline), all tested on a single dataset recorded during an auditory task. To ensure fair a comparison, all networks were trained and tested using standardized preprocessing and consistent training parameters. The results show that symmetrical activation functions such as Tanh and the Absolute value function Abs(x) can outperform commonly used functions like the Rectified Linear Unit (ReLU), depending on the architecture. Additionally, a focused analysis of the role of symmetry was conducted using a Modified Absolute Function (MAF), with results further supporting the effectiveness of symmetrical activation functions on performance gains. These findings underscore the importance of selecting proper activation functions that align with the signal characteristics of fNIRS data.', 'abstract_zh': '激活函数对功能性近红外光谱成像领域深度学习性能的影响研究', 'title_zh': '提高fNIRS分类性能：深度神经架构中激活函数研究'}
{'arxiv_id': 'arXiv:2507.11415', 'title': 'U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV', 'authors': 'Hongbo Ye, Fenghe Tang, Peiang Zhao, Zhen Huang, Dexin Zhao, Minghao Bian, S.Kevin Zhou', 'link': 'https://arxiv.org/abs/2507.11415', 'abstract': 'Achieving equity in healthcare accessibility requires lightweight yet high-performance solutions for medical image segmentation, particularly in resource-limited settings. Existing methods like U-Net and its variants often suffer from limited global Effective Receptive Fields (ERFs), hindering their ability to capture long-range dependencies. To address this, we propose U-RWKV, a novel framework leveraging the Recurrent Weighted Key-Value(RWKV) architecture, which achieves efficient long-range modeling at O(N) computational cost. The framework introduces two key innovations: the Direction-Adaptive RWKV Module(DARM) and the Stage-Adaptive Squeeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan mechanisms to aggregate contextual cues across images, mitigating directional bias while preserving global context and maintaining high computational efficiency. SASE dynamically adapts its architecture to different feature extraction stages, balancing high-resolution detail preservation and semantic relationship capture. Experiments demonstrate that U-RWKV achieves state-of-the-art segmentation performance with high computational efficiency, offering a practical solution for democratizing advanced medical imaging technologies in resource-constrained environments. The code is available at this https URL.', 'abstract_zh': '实现医疗服务公平性要求在资源受限环境中采用轻量且高性能的医疗图像分割解决方案。现有的方法如U-Net及其变体常常受到有限全局有效感受野(ERFs)的限制，影响其捕捉长程依赖的能力。为解决这一问题，我们提出了U-RWKV，这是一种利用循环加权键值(RWKV)架构的新框架，能够在O(N)计算代价下实现高效的长程建模。该框架引入了两大创新：方向自适应RWKV模块(DARM)和阶段自适应Squeeze-and-Excitation模块(SASE)。DARM利用双RWKV和四扫描机制在图像间聚合上下文线索，减轻方向偏见同时保留全局上下文并维持高计算效率。SASE动态适应不同特征提取阶段的架构，平衡高分辨率细节保真和语义关系捕捉。实验表明，U-RWKV在保持高计算效率的同时实现了最先进的分割性能，提供了一种实用的解决方案，以在资源受限环境中普及高级医疗成像技术。相关代码可在以下链接访问。', 'title_zh': 'U-RWKV：具有方向自适应性的小型化医学图像分割方法'}
{'arxiv_id': 'arXiv:2507.11408', 'title': 'KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?', 'authors': 'Soumadeep Saha, Akshay Chaturvedi, Saptarshi Saha, Utpal Garain, Nicholas Asher', 'link': 'https://arxiv.org/abs/2507.11408', 'abstract': 'Chain-of-thought traces have been shown to improve performance of large language models in a plethora of reasoning tasks, yet there is no consensus on the mechanism through which this performance boost is achieved. To shed more light on this, we introduce Causal CoT Graphs (CCGs), which are directed acyclic graphs automatically extracted from reasoning traces that model fine-grained causal dependencies in the language model output. A collection of $1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their associated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed empirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in the CCG are mediators for the final answer, a condition necessary for reasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating that models internally realise structures akin to our graphs. KisMATH enables controlled, graph-aligned interventions and opens up avenues for further investigation into the role of chain-of-thought in LLM reasoning.', 'abstract_zh': 'Chain-of-Thought Traces in Large Language Models: An Analysis via Causal CoT Graphs', 'title_zh': 'KisMATH：LLM们是否具备数学推理中隐含结构的知识？'}
{'arxiv_id': 'arXiv:2507.11407', 'title': 'EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes', 'authors': 'LG AI Research, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Kyubeen Han, Seokhee Hong, Junwon Hwang, Taewan Hwang, Joonwon Jang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Euisoon Kim, Hyosang Kim, Jihoon Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Gwangho Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Young Min Paik, Yongmin Park, Youngyong Park, Sanghyun Seo, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun', 'link': 'https://arxiv.org/abs/2507.11407', 'abstract': 'This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via this https URL.', 'abstract_zh': '本技术报告介绍了EXAONE 4.0，该版本整合了非推理模式和推理模式，既保持了EXAONE 3.5的优秀易用性，又具备了EXAONE Deep的高级推理能力。为了为有意识的AI时代铺平道路，EXAONE 4.0增加了有意识工具使用等关键功能，其多语言能力扩展支持西班牙语、英语和韩语。EXAONE 4.0模型系列包括两种尺寸：一个中型32B模型，优化高性能使用，以及一个小型1.2B模型，专门为设备端应用设计。与其他同类开放权重模型相比，EXAONE 4.0表现出色，并且即使与最先进的模型相比也能保持竞争力。这些模型可供研究使用，并可通过此链接直接下载。', 'title_zh': 'EXAONE 4.0: 统一的大语言模型整合非推理与推理模式'}
{'arxiv_id': 'arXiv:2507.11387', 'title': 'From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties', 'authors': 'Gennaro Auricchio, Giovanni Brigati, Paolo Giudici, Giuseppe Toscani', 'link': 'https://arxiv.org/abs/2507.11387', 'abstract': 'Selecting an appropriate divergence measure is a critical aspect of machine learning, as it directly impacts model performance. Among the most widely used, we find the Kullback-Leibler (KL) divergence, originally introduced in kinetic theory as a measure of relative entropy between probability distributions. Just as in machine learning, the ability to quantify the proximity of probability distributions plays a central role in kinetic theory. In this paper, we present a comparative review of divergence measures rooted in kinetic theory, highlighting their theoretical foundations and exploring their potential applications in machine learning and artificial intelligence.', 'abstract_zh': '在机器学习中选择适当的离散度测度是一项关键任务，因为它直接影响模型性能。在最为常用的离散度测度中，有克里格-莱布利（KL）离散度，最初在动能理论中作为概率分布相对熵的度量被引入。就像在机器学习中一样，量化概率分布的接近程度在动能理论中起着核心作用。在本文中，我们对源自动能理论的离散度测度进行了比较性的综述，强调其理论基础并探索其在机器学习和人工智能中的潜在应用。', 'title_zh': '从动力学理论到人工智能：高维 divergences 的再发现及其性质'}
{'arxiv_id': 'arXiv:2507.11372', 'title': 'Attributes Shape the Embedding Space of Face Recognition Models', 'authors': 'Pierrick Leroy, Antonio Mastropietro, Marco Nurisso, Francesco Vaccarino', 'link': 'https://arxiv.org/abs/2507.11372', 'abstract': 'Face Recognition (FR) tasks have made significant progress with the advent of Deep Neural Networks, particularly through margin-based triplet losses that embed facial images into high-dimensional feature spaces. During training, these contrastive losses focus exclusively on identity information as labels. However, we observe a multiscale geometric structure emerging in the embedding space, influenced by interpretable facial (e.g., hair color) and image attributes (e.g., contrast). We propose a geometric approach to describe the dependence or invariance of FR models to these attributes and introduce a physics-inspired alignment metric. We evaluate the proposed metric on controlled, simplified models and widely used FR models fine-tuned with synthetic data for targeted attribute augmentation. Our findings reveal that the models exhibit varying degrees of invariance across different attributes, providing insight into their strengths and weaknesses and enabling deeper interpretability. Code available here: this https URL}{this https URL', 'abstract_zh': '基于深度神经网络的Face Recognition任务通过基于边际的三元组损失将面部图像嵌入到高维特征空间中取得了显著进展。在训练过程中，这些对比损失专注于身份信息作为标签。然而，我们观察到嵌入空间中出现了一种多尺度几何结构，受到可解释的面部特征（例如，发色）和图像属性（例如，对比度）的影响。我们提出了一种几何方法来描述Face Recognition模型对这些属性的依赖性或不变性，并引入了一种受物理启发的对齐度量。我们在受控的简化模型和广泛使用的通过合成数据微调以针对特定属性增强的Face Recognition模型上评估了提出的度量标准。我们的研究结果表明，模型在不同属性上的不变性程度不同，这为深入了解模型的优势和劣势提供了见解，并使解释更加深入。代码可在此获取：this https URL', 'title_zh': '属性塑造面部识别模型的嵌入空间'}
{'arxiv_id': 'arXiv:2507.11367', 'title': 'Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning', 'authors': 'Daniel Tanneberg', 'link': 'https://arxiv.org/abs/2507.11367', 'abstract': 'Training neural networks with reinforcement learning (RL) typically relies on backpropagation (BP), necessitating storage of activations from the forward pass for subsequent backward updates. Furthermore, backpropagating error signals through multiple layers often leads to vanishing or exploding gradients, which can degrade learning performance and stability. We propose a novel approach that trains each layer of the neural network using local signals during the forward pass in RL settings. Our approach introduces local, layer-wise losses leveraging the principle of matching pairwise distances from multi-dimensional scaling, enhanced with optional reward-driven guidance. This method allows each hidden layer to be trained using local signals computed during forward propagation, thus eliminating the need for backward passes and storing intermediate activations. Our experiments, conducted with policy gradient methods across common RL benchmarks, demonstrate that this backpropagation-free method achieves competitive performance compared to their classical BP-based counterpart. Additionally, the proposed method enhances stability and consistency within and across runs, and improves performance especially in challenging environments.', 'abstract_zh': '使用强化学习训练神经网络：无需反向传播的方法', 'title_zh': '局部成对距离匹配的无需反向传播强化学习'}
{'arxiv_id': 'arXiv:2507.11345', 'title': 'Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM', 'authors': 'Oscar Lima, Marc Vinci, Sunandita Patra, Sebastian Stock, Joachim Hertzberg, Martin Atzmueller, Malik Ghallab, Dana Nau, Paolo Traverso', 'link': 'https://arxiv.org/abs/2507.11345', 'abstract': 'Robotic task execution faces challenges due to the inconsistency between symbolic planner models and the rich control structures actually running on the robot. In this paper, we present the first physical deployment of an integrated actor-planner system that shares hierarchical operational models for both acting and planning, interleaving the Reactive Acting Engine (RAE) with an anytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile manipulator in a real-world deployment for an object collection task. Our experiments demonstrate robust task execution under action failures and sensor noise, and provide empirical insights into the interleaved acting-and-planning decision making process.', 'abstract_zh': '机器人任务执行由于符号规划模型与机器人实际运行的丰富控制结构之间的一致性问题而面临挑战。本文提出了第一个将层级操作模型同时用于执行和规划的集成执行-规划系统的真实物理部署，该系统交替使用反应性执行引擎（RAE）和一个类似UCT的可中断蒙特卡洛规划器（UPOM）。我们在一个移动 manipulator 上为一个物体收集任务实现 RAE+UPOM，并进行了实证研究，表明在动作失败和传感器噪声条件下的任务执行具有鲁棒性，并提供了交替执行和规划决策过程的经验见解。', 'title_zh': '基于RAE+UPOM的移动机器人分层操作模型行动与规划研究'}
{'arxiv_id': 'arXiv:2507.11331', 'title': 'SystolicAttention: Fusing FlashAttention within a Single Systolic Array', 'authors': 'Jiawei Lin, Guokai Chen, Yuanlong Li, Thomas Bourgeat', 'link': 'https://arxiv.org/abs/2507.11331', 'abstract': 'Transformer models rely heavily on scaled dot-product attention (SDPA), typically implemented using the FlashAttention algorithm. However, current systolic-array-based accelerators face significant challenges when executing FlashAttention. Systolic arrays can only achieve high utilization for consecutive and large matrix multiplications. In contrast, FlashAttention requires frequently interleaved matrix multiplications and softmax operations.\nThe frequent data swaps between the systolic array and external vector units result in low systolic array utilization. This is further exacerbated by the fact that softmax involves numerous non-matrix operations, which are not well-suited for systolic arrays. Moreover, the concurrent execution of matrix multiplication on systolic arrays and softmax on vector units leads to register file and SRAM port contention, further degrading performance.\nTo overcome these limitations, we propose FSA, an enhanced systolic array architecture that enables the entire FlashAttention algorithm to run entirely within a single systolic array, eliminating the need for external vector units. At the core of FSA is SystolicAttention, a novel scheduling algorithm that maps FlashAttention operations onto systolic arrays with fine-grained, element-wise overlap. This significantly improves array utilization while preserving the original floating-point operation order to maintain numerical stability.\nWe implement FSA in synthesizable RTL and evaluate its performance against state-of-the-art commercial accelerators. Our results show that FSA achieves 1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS NeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area overhead.', 'abstract_zh': 'Transformers模型 heavily依赖标量点积注意力（SDPA），通常使用FlashAttention算法实现。然而，当前的 systolic-array 基础加速器在执行FlashAttention时面临重大挑战。systolic阵列只能在连续和大规模矩阵乘法中达到高利用率。相比之下，FlashAttention需要频繁地交替进行矩阵乘法和softmax操作。systolic阵列与外部向量单元之间的频繁数据交换导致阵列利用率低下。此外，softmax操作包含大量的非矩阵运算，这并不适合systolic阵列。进一步地，systolic阵列中并行执行矩阵乘法和向量单元中的softmax操作会导致寄存器文件和SRAM端口争用，进一步降低性能。\n\n为了克服这些限制，我们提出了一种增强的systolic阵列架构FSA，使得整个FlashAttention算法能够在单个systolic阵列中完全运行，从而省去了外部向量单元的需求。FSA的核心是SystolicAttention，这是一种新颖的调度算法，能够以细粒度、元素级的方式将FlashAttention操作映射到systolic阵列上。这显著提高了阵列利用率，同时保持原始的浮点运算顺序以确保数值稳定性。\n\n我们在综合RTL中实现了FSA，并将其性能与最新的商业加速器进行了评估。结果显示，与AWS NeuronCore-v2和Google TPUv5e相比，FSA分别实现了约1.77倍和4.83倍更高的注意力FLOPs/s利用率，仅增加了约10%的面积开销。', 'title_zh': 'systolicAttention: 将FlashAttention融合到单个 systolic阵列中'}
{'arxiv_id': 'arXiv:2507.11330', 'title': 'Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge', 'authors': 'Wenqing Wu, Chengzhi Zhang, Yi Zhao', 'link': 'https://arxiv.org/abs/2507.11330', 'abstract': "Novelty is a crucial criterion in the peer review process for evaluating academic papers. Traditionally, it's judged by experts or measure by unique reference combinations. Both methods have limitations: experts have limited knowledge, and the effectiveness of the combination method is uncertain. Moreover, it's unclear if unique citations truly measure novelty. The large language model (LLM) possesses a wealth of knowledge, while human experts possess judgment abilities that the LLM does not possess. Therefore, our research integrates the knowledge and abilities of LLM and human experts to address the limitations of novelty assessment. The most common novelty in academic papers is the introduction of new methods. In this paper, we propose leveraging human knowledge and LLM to assist pretrained language models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we extract sentences related to the novelty of the academic paper from peer review reports and use LLM to summarize the methodology section of the academic paper, which are then used to fine-tune PLMs. In addition, we have designed a text-guided fusion module with novel Sparse-Attention to better integrate human and LLM knowledge. We compared the method we proposed with a large number of baselines. Extensive experiments demonstrate that our method achieves superior performance.", 'abstract_zh': '新颖性是学术论文同行评审过程中一个关键的评价标准。传统上，新颖性由专家判断或通过独特的参考组合进行度量。这两种方法都有局限性：专家的知识有限，组合方法的有效性也不确定。此外，独特的引用是否能真正度量新颖性也存疑。大规模语言模型（LLM）拥有丰富的知识，而人类专家则具有LLM不具备的判断能力。因此，我们的研究将LLM的知识和能力与人类专家的知识相结合，以克服新颖性评估的局限性。学术论文中最常见的新颖性在于引入新的方法。本文提出利用人类知识和LLM辅助预训练语言模型（PLMs，如BERT等）预测论文方法的新颖性。具体而言，我们从同行评审报告中提取与论文新颖性相关的句子，并使用LLM总结学术论文的方法部分，然后用于微调PLMs。此外，我们还设计了一个文本引导的融合模块，采用新颖的稀疏注意机制，更好地整合人类和LLM的知识。我们将提出的方法与多种基线进行了比较。广泛的经验表明，我们的方法取得了更好的性能。', 'title_zh': '学术论文新颖性评价的协作方法：融合人类与大规模语言模型知识'}
{'arxiv_id': 'arXiv:2507.11329', 'title': "Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI", 'authors': 'Hagar Shmuely, Michal Rivlin, Or Perlman', 'link': 'https://arxiv.org/abs/2507.11329', 'abstract': "Traditional approaches for molecular imaging of Parkinson's disease (PD) in vivo require radioactive isotopes, lengthy scan times, or deliver only low spatial resolution. Recent advances in saturation transfer-based PD magnetic resonance imaging (MRI) have provided biochemical insights, although the image contrast is semi-quantitative and nonspecific. Here, we combined a rapid molecular MRI acquisition paradigm with deep learning based reconstruction for multi-metabolite quantification of glutamate, mobile proteins, semisolid, and mobile macromolecules in an acute MPTP (1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine) mouse model. The quantitative parameter maps are in general agreement with the histology and MR spectroscopy, and demonstrate that semisolid magnetization transfer (MT), amide, and aliphatic relayed nuclear Overhauser effect (rNOE) proton volume fractions may serve as PD biomarkers.", 'abstract_zh': '传统体内帕金森病分子成像方法需要放射性同位素、长扫描时间或仅提供低空间分辨率。最近基于饱和转移的帕金森病磁共振成像（MRI）取得了进展，提供了生化见解，尽管图像对比度是半定量且非特异性的。我们结合了快速分子MRI采集范式并与基于深度学习的重建相结合，对MPTP急性小鼠模型中的谷氨酸、移动蛋白、半固体和移动大分子进行了多代谢物定量分析。定量参数图与组织学和磁共振波谱分析基本一致，并表明半固体交换转移（MT）、酰胺和支链脂肪酸相关核Overhauser效应（rNOE）氢体积分数可能作为帕金森病生物标志物。', 'title_zh': '使用AI增强分子磁共振成像的帕金森病多代谢物定量成像'}
{'arxiv_id': 'arXiv:2507.11325', 'title': 'HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging', 'authors': 'Arefin Ittesafun Abian, Ripon Kumar Debnath, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Asif Karim, Reem E. Mohamed, Sami Azam', 'link': 'https://arxiv.org/abs/2507.11325', 'abstract': 'Accurate liver and tumor segmentation on abdominal CT images is critical for reliable diagnosis and treatment planning, but remains challenging due to complex anatomical structures, variability in tumor appearance, and limited annotated data. To address these issues, we introduce Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network (HANS-Net), a novel segmentation framework that synergistically combines hyperbolic convolutions for hierarchical geometric representation, a wavelet-inspired decomposition module for multi-scale texture learning, a biologically motivated synaptic plasticity mechanism for adaptive feature enhancement, and an implicit neural representation branch to model fine-grained and continuous anatomical boundaries. Additionally, we incorporate uncertainty-aware Monte Carlo dropout to quantify prediction confidence and lightweight temporal attention to improve inter-slice consistency without sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap error (VOE) of 11.91%. Furthermore, cross-dataset validation on the 3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of 1.525 mm, and VOE of 19.71%, indicating strong generalization across different datasets. These results confirm the effectiveness and robustness of HANS-Net in providing anatomically consistent, accurate, and confident liver and tumor segmentation.', 'abstract_zh': 'Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network for Accurate Liver and Tumor Segmentation in Abdominal CT Images', 'title_zh': 'HANS-Net：双曲卷积与自适应时空注意力在CT成像中用于准确且泛化能力强的肝脏和肿瘤分割'}
{'arxiv_id': 'arXiv:2507.11316', 'title': 'Internal Value Alignment in Large Language Models through Controlled Value Vector Activation', 'authors': 'Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian', 'link': 'https://arxiv.org/abs/2507.11316', 'abstract': 'Aligning Large Language Models (LLMs) with human values has attracted increasing attention since it provides clarity, transparency, and the ability to adapt to evolving scenarios. In this paper, we introduce a Controlled Value Vector Activation (ConVA) method that directly aligns the internal values of LLMs by interpreting how a value is encoded in their latent representations and modifies relevant activations to ensure consistent values in LLMs. To ensure an accurate and unbiased interpretation, we propose a context-controlled value vector identification method. To consistently control values without sacrificing model performance, we introduce a gated value vector activation method for effective and minimum degree of value control. Experiments show that our method achieves the highest control success rate across 10 basic values without hurting LLM performance and fluency, and ensures target values even with opposite and potentially malicious input prompts. Source code and data are available at~ this https URL.', 'abstract_zh': '控制值向量激活（ConVA）方法：通过直接调整大型语言模型的内部价值实现与人类价值观的对齐', 'title_zh': '通过控制价值向量激活实现大型语言模型内部价值对齐'}
{'arxiv_id': 'arXiv:2507.11269', 'title': 'Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound', 'authors': 'Tal Fiskus, Uri Shaham', 'link': 'https://arxiv.org/abs/2507.11269', 'abstract': 'Deep reinforcement learning (DRL) agents excel in solving complex decision-making tasks across various domains. However, they often require a substantial number of training steps and a vast experience replay buffer, leading to significant computational and resource demands. To address these challenges, we introduce a novel theoretical result that leverages the Neyman-Rubin potential outcomes framework into DRL. Unlike most methods that focus on bounding the counterfactual loss, we establish a causal bound on the factual loss, which is analogous to the on-policy loss in DRL. This bound is computed by storing past value network outputs in the experience replay buffer, effectively utilizing data that is usually discarded. Extensive experiments across the Atari 2600 and MuJoCo domains on various agents, such as DQN and SAC, achieve up to 2,427% higher reward ratio, outperforming the same agents without our proposed term, and reducing the experience replay buffer size by up to 96%, significantly improving sample efficiency at negligible cost.', 'abstract_zh': '深度强化学习（DRL）智能体在解决各类复杂决策任务方面表现出色。然而，它们常常需要大量的训练步骤和庞大的经验重放缓冲区，导致显著的计算和资源需求。为应对这些挑战，我们引入了一种新的理论成果，将Neyman-Rubin潜在结果框架应用于DRL。与大多数方法专注于界定制外事实损失不同，我们建立了界定制内事实损失，这类似于DRL中的随策策略损失。该界通过在经验重放缓冲区中存储过去的值网络输出来计算，有效地利用了通常会被丢弃的数据。在Atari 2600和MuJoCo领域的广泛实验中，对各种智能体（如DQN和SAC）进行的实验显示出高达2,427%的奖励比率提升，优于未引入我们提议项的相同智能体，并将经验重放缓冲区大小减少高达96%，显著提高了样本效率，成本几乎可以忽略不计。', 'title_zh': '将沙变 gold：通过因果界线回收数据以桥接策略内学习与策略外学习'}
{'arxiv_id': 'arXiv:2507.11267', 'title': 'YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery', 'authors': 'Aon Safdar, Usman Akram, Waseem Anwar, Basit Malik, Mian Ibad Ali', 'link': 'https://arxiv.org/abs/2507.11267', 'abstract': 'Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared (TI) imagery in the defense and surveillance domain is a challenging computer vision (CV) task in comparison to the commercial autonomous vehicle perception domain. Limited datasets, peculiar domain-specific and TI modality-specific challenges, i.e., limited hardware, scale invariance issues due to greater distances, deliberate occlusion by tactical vehicles, lower sensor resolution and resultant lack of structural information in targets, effects of weather, temperature, and time of day variations, and varying target to clutter ratios all result in increased intra-class variability and higher inter-class similarity, making accurate real-time ATR a challenging CV task. Resultantly, contemporary state-of-the-art (SOTA) deep learning architectures underperform in the ATR domain. We propose a modified anchor-based single-stage detector, called YOLOatr, based on a modified YOLOv5s, with optimal modifications to the detection heads, feature fusion in the neck, and a custom augmentation profile. We evaluate the performance of our proposed model on a comprehensive DSIAC MWIR dataset for real-time ATR over both correlated and decorrelated testing protocols. The results demonstrate that our proposed model achieves state-of-the-art ATR performance of up to 99.6%.', 'abstract_zh': '自动目标检测（ATD）和识别（ATR）从红外（TI）图像在防御与监控领域的挑战性计算机视觉（CV）任务：基于商业自动驾驶汽车感知领域的比较', 'title_zh': 'YOLOatr：基于深度学习的热红外图像自动目标检测与定位'}
{'arxiv_id': 'arXiv:2507.11222', 'title': 'An Agentic Flow for Finite State Machine Extraction using Prompt Chaining', 'authors': 'Fares Wael, Youssef Maklad, Ali Hamdi, Wael Elsersy', 'link': 'https://arxiv.org/abs/2507.11222', 'abstract': 'Finite-State Machines (FSMs) are critical for modeling the operational logic of network protocols, enabling verification, analysis, and vulnerability discovery. However, existing FSM extraction techniques face limitations such as scalability, incomplete coverage, and ambiguity in natural language specifications. In this paper, we propose FlowFSM, a novel agentic framework that leverages Large Language Models (LLMs) combined with prompt chaining and chain-of-thought reasoning to extract accurate FSMs from raw RFC documents. FlowFSM systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs. Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM achieves high extraction precision while minimizing hallucinated transitions, showing promising results. Our findings highlight the potential of agent-based LLM systems in the advancement of protocol analysis and FSM inference for cybersecurity and reverse engineering applications.', 'abstract_zh': '基于大型语言模型的agentic框架FlowFSM：从原始RFC文档中精准提取有限状态机', 'title_zh': '基于提示链的有限状态机提取代理流程'}
{'arxiv_id': 'arXiv:2507.11210', 'title': 'Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias', 'authors': 'Rushia Harada, Yuken Kimura, Keito Inoshita', 'link': 'https://arxiv.org/abs/2507.11210', 'abstract': "Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.", 'abstract_zh': '家庭环境中的心灵福祉涉及常规度量常常忽略的微妙心理动态。特别是，被称为理想家长偏见的无意识父母期望会抑制儿童的情感表达和自主性。这种抑制通常源于旨在良好的但具有价值导向的沟通，从家庭外部难以察觉或解决。聚焦于这些潜在动态，本研究探索基于大规模语言模型（LLM）的心理安全家庭沟通支持。我们构建了一个包含30个场景的日语亲子对话语料库，每个场景都标注了理想家长偏见和抑制情感的元数据。基于此语料库，我们开发了一种基于角色扮演的大规模语言模型多代理对话支持框架，该框架分析对话并生成反馈。专业代理检测抑制情感，描述父母话语中的隐含理想家长偏见，并推断出如儿童的年龄和背景等上下文属性。元代理将这些输出汇总为结构化的报告，然后传递给五个选定的专家代理。这些代理通过结构化的四步讨论过程协作生成同理心和可操作的反馈。实验显示，该系统可以在中等准确度下检测抑制情感的类别，并生成具有高同理心和实际性的反馈。此外，结合此反馈的模拟后续对话显示出情绪表达和相互理解的改进迹象，表明该框架在支持家庭互动的积极转变方面具有潜力。', 'title_zh': '基于角色扮演的LLM驱动多-agent支持框架：检测与解决家庭沟通偏见'}
{'arxiv_id': 'arXiv:2507.11198', 'title': 'Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding', 'authors': 'Conrad Borchers, Bahar Shahrokhian, Francesco Balzan, Elham Tajik, Sreecharan Sankaranarayanan, Sebastian Simon', 'link': 'https://arxiv.org/abs/2507.11198', 'abstract': 'Large Language Models (LLMs) enable new possibilities for qualitative research at scale, including coding and data annotation. While multi-agent systems (MAS) can emulate human coding workflows, their benefits over single-agent coding remain poorly understood. We conducted an experimental study of how agent persona and temperature shape consensus-building and coding accuracy of dialog segments based on a codebook with 8 codes. Our open-source MAS mirrors deductive human coding through structured agent discussion and consensus arbitration. Using six open-source LLMs (with 3 to 32 billion parameters) and 18 experimental configurations, we analyze over 77,000 coding decisions against a gold-standard dataset of human-annotated transcripts from online math tutoring sessions. Temperature significantly impacted whether and when consensus was reached across all six LLMs. MAS with multiple personas (including neutral, assertive, or empathetic), significantly delayed consensus in four out of six LLMs compared to uniform personas. In three of those LLMs, higher temperatures significantly diminished the effects of multiple personas on consensus. However, neither temperature nor persona pairing lead to robust improvements in coding accuracy. Single agents matched or outperformed MAS consensus in most conditions. Only one model (OpenHermesV2:7B) and code category showed above-chance gains from MAS deliberation when temperature was 0.5 or lower and especially when the agents included at least one assertive persona. Qualitative analysis of MAS collaboration for these configurations suggests that MAS may nonetheless aid in narrowing ambiguous code applications that could improve codebooks and human-AI coding. We contribute new insight into the limits of LLM-based qualitative methods, challenging the notion that diverse MAS personas lead to better outcomes. We open-source our MAS and experimentation code.', 'abstract_zh': '大型语言模型（LLMs）为大规模定性研究提供了新的可能性，包括编码和数据注释。尽管多智能体系统（MAS）可以模拟人类编码工作流，但它们在多智能体编码方面的优势仍然 poorly understood（缺乏充分理解）。我们通过一个包含8个代码的代码本，研究了代理角色和温度如何影响基于对话片段的共识构建和编码准确性。我们的开源MAS通过对结构化代理讨论和共识仲裁来模拟演绎性的人类编码。使用六种开源LLM（参数量在3亿到32亿之间）和18种实验配置，我们对超过77,000个编码决策进行了分析，这些数据来源于在线数学辅导会话的人类标注转录数据集。温度显著影响了所有六种LLM中是否以及何时达成共识。包含多个角色（包括中立、自信或 Empathetic）的MAS，在四种情况下显著延迟了在六种LLM中的共识，相比统一的角色。在三种LLM中，较高的温度显著削弱了多个角色对共识的影响。然而，温度和角色配对均未导致编码准确性的稳定提升。单个代理在大多数情况下与MAS的共识相匹配甚至表现更好。仅有一个模型（OpenHermesV2:7B）和代码类别，在温度为0.5或更低时，以及尤其是在代理中至少包含一个自信角色时，从MAS讨论中获得了超出随机猜测的收益。对于这些配置下的MAS合作定性分析表明，MAS可能有助于缩小模糊代码应用的范围，从而改善代码本和人类-AI编码。我们为LLM基础的定性方法提供了新的见解，挑战了多样化的MAS角色会导致更好结果的观点。我们开源了我们的MAS和实验代码。', 'title_zh': '温度和人格塑造LLM代理共识， minimal 准确度提升在定性编码中。'}
{'arxiv_id': 'arXiv:2507.11185', 'title': 'An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment', 'authors': 'Md. Emon Akter Sourov, Md. Sabbir Hossen, Pabon Shaha, Mohammad Minoar Hossain, Md Sadiq Iqbal', 'link': 'https://arxiv.org/abs/2507.11185', 'abstract': "Heart disease remains a major global health concern, particularly in regions with limited access to medical resources and diagnostic facilities. Traditional diagnostic methods often fail to accurately identify and manage heart disease risks, leading to adverse outcomes. Machine learning has the potential to significantly enhance the accuracy, efficiency, and speed of heart disease diagnosis. In this study, we proposed a comprehensive framework that combines classification models for heart disease detection and regression models for risk prediction. We employed the Heart Disease dataset, which comprises 1,035 cases. To address the issue of class imbalance, the Synthetic Minority Oversampling Technique (SMOTE) was applied, resulting in the generation of an additional 100,000 synthetic data points. Performance metrics, including accuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to evaluate the model's effectiveness. Among the classification models, Random Forest emerged as the standout performer, achieving an accuracy of 97.2% on real data and 97.6% on synthetic data. For regression tasks, Linear Regression demonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic datasets, respectively, with the lowest error metrics. Additionally, Explainable AI techniques were employed to enhance the interpretability of the models. This study highlights the potential of machine learning to revolutionize heart disease diagnosis and risk prediction, thereby facilitating early intervention and enhancing clinical decision-making.", 'abstract_zh': '心脏疾病仍然是全球健康的重大关切，特别是在医疗资源和诊断设施有限的地区。传统诊断方法往往无法准确识别和管理心脏疾病风险，导致不良结果。机器学习有可能显著提高心脏疾病诊断的准确性、效率和速度。在本研究中，我们提出了一种综合框架，结合分类模型进行心脏疾病检测和回归模型进行风险预测。我们采用了包含1,035例病例的心脏疾病数据集，并通过合成少数类过采样技术（SMOTE）解决了类别不平衡问题，生成了额外的100,000个合成数据点。使用准确率、精确率、召回率、F1分数、R2、均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）等性能指标来评估模型的有效性。在分类模型中，随机森林表现突出，在实际数据和合成数据上的准确率分别为97.2%和97.6%。对于回归任务，线性回归在实际和合成数据集上的R2值分别为0.992和0.984，具有最低的误差指标。此外，我们还采用了可解释的AI技术以增强模型的可解释性。本研究强调了机器学习在革新心脏疾病诊断和风险预测方面的潜力，从而促进早期干预并增强临床决策。', 'title_zh': '可解释的人工智能增强机器学习方法在心血管疾病检测与风险评估中的应用'}
{'arxiv_id': 'arXiv:2507.11181', 'title': 'Mixture of Experts in Large Language Models', 'authors': 'Danyang Zhang, Junhao Song, Ziqian Bi, Yingfang Yuan, Tianyang Wang, Joe Yeong, Junfeng Hao', 'link': 'https://arxiv.org/abs/2507.11181', 'abstract': 'This paper presents a comprehensive review of the Mixture-of-Experts (MoE) architecture in large language models, highlighting its ability to significantly enhance model performance while maintaining minimal computational overhead. Through a systematic analysis spanning theoretical foundations, core architectural designs, and large language model (LLM) applications, we examine expert gating and routing mechanisms, hierarchical and sparse MoE configurations, meta-learning approaches, multimodal and multitask learning scenarios, real-world deployment cases, and recent advances and challenges in deep learning. Our analysis identifies key advantages of MoE, including superior model capacity compared to equivalent Bayesian approaches, improved task-specific performance, and the ability to scale model capacity efficiently. We also underscore the importance of ensuring expert diversity, accurate calibration, and reliable inference aggregation, as these are essential for maximizing the effectiveness of MoE architectures. Finally, this review outlines current research limitations, open challenges, and promising future directions, providing a foundation for continued innovation in MoE architecture and its applications.', 'abstract_zh': '这篇论文对大型语言模型中的Mixture-of-Experts（MoE）架构进行了全面回顾，强调了其在显著提升模型性能的同时保持了较小的计算开销。通过系统分析理论基础、核心架构设计、以及大型语言模型（LLM）应用，我们考察了专家门控和路由机制、层级和稀疏MoE配置、元学习方法、多模态和多任务学习场景、真实世界部署案例以及深度学习中的最新进展和挑战。我们的分析指出了MoE的关键优势，包括与等效的贝叶斯方法相比更强大的模型容量、更好的任务特定性能以及高效扩展模型容量的能力。我们还强调了确保专家多样性、准确校准和可靠的推理聚合的重要性，这些对于最大化MoE架构的有效性至关重要。最后，本文概述了当前研究限制、开放挑战以及有希望的未来发展方向，为MoE架构及其应用的持续创新奠定了基础。', 'title_zh': '大型语言模型中的专家混合模型'}
{'arxiv_id': 'arXiv:2507.11178', 'title': 'Gradient Regularization-based Neural Granger Causality', 'authors': 'Meiliang Liu, Huiwen Dong, Xiaoxiao Yang, Yunfang Xu, Zijin Li, Zhengye Si, Xinyue Yang, Zhiwen Zhao', 'link': 'https://arxiv.org/abs/2507.11178', 'abstract': "With the advancement of deep learning technologies, various neural network-based Granger causality models have been proposed. Although these models have demonstrated notable improvements, several limitations remain. Most existing approaches adopt the component-wise architecture, necessitating the construction of a separate model for each time series, which results in substantial computational costs. In addition, imposing the sparsity-inducing penalty on the first-layer weights of the neural network to extract causal relationships weakens the model's ability to capture complex interactions. To address these limitations, we propose Gradient Regularization-based Neural Granger Causality (GRNGC), which requires only one time series prediction model and applies $L_{1}$ regularization to the gradient between model's input and output to infer Granger causality. Moreover, GRNGC is not tied to a specific time series forecasting model and can be implemented with diverse architectures such as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical simulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC outperforms existing baselines and significantly reduces computational overhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder urothelial carcinoma datasets further validate the model's effectiveness in reconstructing gene regulatory networks.", 'abstract_zh': '基于梯度正则化的神经格兰杰因果模型（GRNGC）', 'title_zh': '基于梯度正则化的神经格朗日因果关系'}
{'arxiv_id': 'arXiv:2507.11168', 'title': 'Improving Wi-Fi Network Performance Prediction with Deep Learning Models', 'authors': 'Gabriele Formis, Amanda Ericson, Stefan Forsstrom, Kyi Thar, Gianluca Cena, Stefano Scanzio', 'link': 'https://arxiv.org/abs/2507.11168', 'abstract': "The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.", 'abstract_zh': '无线网络中工业和关键任务应用对可靠性和确定性的日益增长需求推动了新创新方法的发展：基于卷积神经网络和长短期记忆的Wi-Fi信道质量预测研究', 'title_zh': '使用深度学习模型提高Wi-Fi网络性能预测'}
{'arxiv_id': 'arXiv:2507.11153', 'title': 'Assessing Color Vision Test in Large Vision-language Models', 'authors': 'Hongfei Ye, Bin Chen, Wenxi Liu, Yu Zhang, Zhao Li, Dandan Ni, Hongyang Chen', 'link': 'https://arxiv.org/abs/2507.11153', 'abstract': 'With the widespread adoption of large vision-language models, the capacity for color vision in these models is crucial. However, the color vision abilities of large visual-language models have not yet been thoroughly explored. To address this gap, we define a color vision testing task for large vision-language models and construct a dataset \\footnote{Anonymous Github Showing some of the data this https URL} that covers multiple categories of test questions and tasks of varying difficulty levels. Furthermore, we analyze the types of errors made by large vision-language models and propose fine-tuning strategies to enhance their performance in color vision tests.', 'abstract_zh': '随着大型多模态模型的广泛应用，这些模型的色彩识别能力至关重要。然而，大型视觉-语言模型的色彩识别能力尚未得到充分研究。为弥补这一空白，我们定义了一个针对大型视觉-语言模型的色彩识别测试任务，并构建了一个数据集（匿名GitHub链接，部分内容可查看：https://github.com/），该数据集涵盖了多种类别、不同难度级别的测试问题和任务。此外，我们分析了大型视觉-语言模型在色彩识别测试中犯下的错误类型，并提出了一些微调策略以提高其在色彩识别测试中的表现。', 'title_zh': '评估大型视觉语言模型的颜色视觉测试'}
{'arxiv_id': 'arXiv:2507.11152', 'title': 'Latent Space Consistency for Sparse-View CT Reconstruction', 'authors': 'Duoyou Chen, Yunqing Chen, Can Zhang, Zhou Wang, Cheng Chen, Ruoxiu Xiao', 'link': 'https://arxiv.org/abs/2507.11152', 'abstract': 'Computed Tomography (CT) is a widely utilized imaging modality in clinical settings. Using densely acquired rotational X-ray arrays, CT can capture 3D spatial features. However, it is confronted with challenged such as significant time consumption and high radiation exposure. CT reconstruction methods based on sparse-view X-ray images have garnered substantial attention from researchers as they present a means to mitigate costs and risks. In recent years, diffusion models, particularly the Latent Diffusion Model (LDM), have demonstrated promising potential in the domain of 3D CT reconstruction. Nonetheless, due to the substantial differences between the 2D latent representation of X-ray modalities and the 3D latent representation of CT modalities, the vanilla LDM is incapable of achieving effective alignment within the latent space. To address this issue, we propose the Consistent Latent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature contrastive learning to efficiently extract latent 3D information from 2D X-ray images and achieve latent space alignment between modalities. Experimental results indicate that CLS-DM outperforms classical and state-of-the-art generative models in terms of standard voxel-level metrics (PSNR, SSIM) on the LIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing the effectiveness and economic viability of sparse X-ray reconstructed CT but can also be generalized to other cross-modal transformation tasks, such as text-to-image synthesis. We have made our code publicly available at this https URL to facilitate further research and applications in other domains.', 'abstract_zh': '基于一致性潜空间扩散模型的稀视角CT重建', 'title_zh': '潜在空间一致性在稀少量子CT重建中的应用'}
{'arxiv_id': 'arXiv:2507.11129', 'title': 'MMOne: Representing Multiple Modalities in One Scene', 'authors': 'Zhifeng Gu, Bing Wang', 'link': 'https://arxiv.org/abs/2507.11129', 'abstract': 'Humans perceive the world through multimodal cues to understand and interact with the environment. Learning a scene representation for multiple modalities enhances comprehension of the physical world. However, modality conflicts, arising from inherent distinctions among different modalities, present two critical challenges: property disparity and granularity disparity. To address these challenges, we propose a general framework, MMOne, to represent multiple modalities in one scene, which can be readily extended to additional modalities. Specifically, a modality modeling module with a novel modality indicator is proposed to capture the unique properties of each modality. Additionally, we design a multimodal decomposition mechanism to separate multi-modal Gaussians into single-modal Gaussians based on modality differences. We address the essential distinctions among modalities by disentangling multimodal information into shared and modality-specific components, resulting in a more compact and efficient multimodal scene representation. Extensive experiments demonstrate that our method consistently enhances the representation capability for each modality and is scalable to additional modalities. The code is available at this https URL.', 'abstract_zh': '人类通过多模态 cues 认知和交互环境。学习多模态场景表示增强对物理世界的理解。然而，不同模态固有差异导致的模态冲突——属性差异和粒度差异——构成了两个关键挑战。为应对这些挑战，我们提出了一种通用框架 MMOne，能够在一个场景中表示多种模态，并可便捷扩展至其他模态。具体而言，我们提出了一种包含新型模态指示器的模态建模模块来捕获每种模态的独特属性。此外，我们设计了一种多模态分解机制，根据模态差异将多模态高斯分布分解为单模态高斯分布。通过将多模态信息拆解为共享和模态特定组件，我们解决了模态间的基本差异，从而获得更为紧凑和高效的多模态场景表示。大量实验表明，我们的方法能够一致地提升每种模态的表示能力，并具备扩展到其他模态的潜力。代码已发布在该网址。', 'title_zh': 'MMOne: 在一个场景中表示多种模态'}
{'arxiv_id': 'arXiv:2507.11096', 'title': 'EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing', 'authors': 'Vassilis Sioros, Alexandros Potamianos, Giorgos Paraskevopoulos', 'link': 'https://arxiv.org/abs/2507.11096', 'abstract': "In this study, we investigate leveraging cross-attention control for efficient audio editing within auto-regressive models. Inspired by image editing methodologies, we develop a Prompt-to-Prompt-like approach that guides edits through cross and self-attention mechanisms. Integrating a diffusion-based strategy, influenced by Auffusion, we extend the model's functionality to support refinement edits, establishing a baseline for prompt-guided audio editing. Additionally, we introduce an alternative approach by incorporating MUSICGEN, a pre-trained frozen auto-regressive model, and propose three editing mechanisms, based on Replacement, Reweighting, and Refinement of the attention scores. We employ commonly-used music-specific evaluation metrics and a human study, to gauge time-varying controllability, adherence to global text cues, and overall audio realism. The automatic and human evaluations indicate that the proposed combination of prompt-to-prompt guidance with autoregressive generation models significantly outperforms the diffusion-based baseline in terms of melody, dynamics, and tempo of the generated audio. Our code is available at this https URL", 'abstract_zh': '本研究探讨了在自回归模型中利用跨注意力控制进行高效音频编辑的方法。受图像编辑方法的启发，我们开发了一种类似于Prompt-to-Prompt的方法，通过跨注意力和自我注意力机制引导编辑。结合Auffusion的扩散策略，我们扩展了模型的功能，支持细化编辑，并建立了基于提示引导音频编辑的基本模型。此外，我们引入了一种替代方法，通过引入MUSICGEN（一个预先训练并冻结的自回归模型），并提出了基于替换、重赋权重和注意力分数细化三种编辑机制。我们使用常用的音乐特定评估指标和人类研究，来评估时间变化的可控性、对全局文本提示的遵守程度以及整体音频的真实性。自动和人工评估表明，所提出的提示到提示引导与自回归生成模型的结合，显著优于基于扩散的基本模型，在生成音频的旋律、动态和节拍方面表现更优。代码可在以下链接获取。', 'title_zh': 'EditGen: 利用跨注意力控制实现基于指令的自回归音频编辑'}
{'arxiv_id': 'arXiv:2507.11081', 'title': 'Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification', 'authors': 'Chang Peng, Bao Yang, Meiqi Li, Ge Zhang, Hui Sun, Zhenyu Jiang', 'link': 'https://arxiv.org/abs/2507.11081', 'abstract': "Ground penetrating radar (GPR) has become a rapid and non-destructive solution for road subsurface distress (RSD) detection. However, RSD recognition from GPR images is labor-intensive and heavily relies on inspectors' expertise. Deep learning offers the possibility for automatic RSD recognition, but its current performance is limited by two factors: Scarcity of high-quality dataset for network training and insufficient capability of network to distinguish RSD. In this study, a rigorously validated 3D GPR dataset containing 2134 samples of diverse types was constructed through field scanning. Based on the finding that the YOLO model trained with one of the three scans of GPR images exhibits varying sensitivity to specific type of RSD, we proposed a novel cross-verification strategy with outstanding accuracy in RSD recognition, achieving recall over 98.6% in field tests. The approach, integrated into an online RSD detection system, can reduce the labor of inspection by around 90%.", 'abstract_zh': '地面穿透雷达(GPR)已成为一种快速且非破坏性的解方案，用于道路地下病害(RSD)检测。然而，从GPR图像中识别RSD劳动密集且高度依赖检查人员的专业知识。深度学习为自动RSD识别提供了可能性，但其当前表现受限于两个因素：用于网络训练的高质量数据集稀缺以及网络区分RSD的能力不足。在此研究中，通过现场扫描构建了一个严格的验证3D GPR数据集，包含2134个不同类型样本。基于训练其中一个GPR图像扫描的YOLO模型对特定类型RSD表现出不同程度敏感性的发现，我们提出了一个准确的跨验证策略，在现场测试中RSD识别召回率超过98.6%。该方法整合到在线RSD检测系统中，可将检查工作量减少约90%。', 'title_zh': '基于深度学习交叉验证的地面穿透雷达图像自动道路地下病害识别'}
{'arxiv_id': 'arXiv:2507.11075', 'title': 'Joint angle model based learning to refine kinematic human pose estimation', 'authors': 'Chang Peng, Yifei Zhou, Huifeng Xi, Shiqing Huang, Chuangye Chen, Jianming Yang, Bao Yang, Zhenyu Jiang', 'link': 'https://arxiv.org/abs/2507.11075', 'abstract': 'Marker-free human pose estimation (HPE) has found increasing applications in various fields. Current HPE suffers from occasional errors in keypoint recognition and random fluctuation in keypoint trajectories when analyzing kinematic human poses. The performance of existing deep learning-based models for HPE refinement is considerably limited by inaccurate training datasets in which the keypoints are manually annotated. This paper proposed a novel method to overcome the difficulty through joint angle-based modeling. The key techniques include: (i) A joint angle-based model of human pose, which is robust to describe kinematic human poses; (ii) Approximating temporal variation of joint angles through high order Fourier series to get reliable "ground truth"; (iii) A bidirectional recurrent network is designed as a post-processing module to refine the estimation of well-established HRNet. Trained with the high-quality dataset constructed using our method, the network demonstrates outstanding performance to correct wrongly recognized joints and smooth their spatiotemporal trajectories. Tests show that joint angle-based refinement (JAR) outperforms the state-of-the-art HPE refinement network in challenging cases like figure skating and breaking.', 'abstract_zh': '基于关节角度的人体姿态估计方法', 'title_zh': '基于关节角度模型的学习以细化人体姿态估计'}
{'arxiv_id': 'arXiv:2507.11071', 'title': 'LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection', 'authors': 'Isaiah Thompson Ocansey, Ritwik Bhattacharya, Tanmay Sen', 'link': 'https://arxiv.org/abs/2507.11071', 'abstract': 'Log anomaly detection using traditional rule based or deep learning based methods is often challenging due to the large volume and highly complex nature of log sequence. So effective way of detection of anomalous sequence of logs is crucial for system maintenance and development. This paper proposes parameter efficient finetuning specifically low rank adaptation (LoRA) and adapter based approaches for finding contextual anomalies in sequence of logs in large log data set. It compares different tiny large language models (LLMs) on the Thunderbird dataset. The results show that LoRA based finetuning provides substantial performance improvements of 18 to 19 percentage over LogBert based full finetuning approach, achieving accuracy scores between 97.76% and 98.83% compared to 79.37%.', 'abstract_zh': '使用传统基于规则或深度学习的方法进行日志异常检测往往由于日志序列的大量和高度复杂性而具有挑战性。因此，有效的日志异常序列检测方法对于系统维护和开发至关重要。本文提出了一种参数高效的微调方法，特别是低秩适应（LoRA）和适配器基方法，以在大数据日志集中发现日志序列中的上下文异常。该研究在Thunderbird数据集上比较了不同的小型大型语言模型（LLMs）。结果表明，基于LoRA的微调在日志BERT完全微调方法上提供了18%到19%的显著性能提升，准确率达到了97.76%至98.83%，而后者仅为79.37%。', 'title_zh': 'LogTinyLLM：基于上下文的日志异常检测小型大型语言模型'}
{'arxiv_id': 'arXiv:2507.11064', 'title': 'Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems', 'authors': 'Sehyun Ryu, Hyun Jong Yang', 'link': 'https://arxiv.org/abs/2507.11064', 'abstract': 'Reducing feedback overhead in beyond 5G networks is a critical challenge, as the growing number of antennas in modern massive MIMO systems substantially increases the channel state information (CSI) feedback demand in frequency division duplex (FDD) systems. To address this, extensive research has focused on CSI compression and prediction, with neural network-based approaches gaining momentum and being considered for integration into the 3GPP 5G-Advanced standards. While deep learning has been effectively applied to CSI-limited beamforming and handover optimization, reference signal allocation under such constraints remains surprisingly underexplored. To fill this gap, we introduce the concept of channel prediction-based reference signal allocation (CPRS), which jointly optimizes channel prediction and DM-RS allocation to improve data throughput without requiring CSI feedback. We further propose a standards-compliant ViViT/CNN-based architecture that implements CPRS by treating evolving CSI matrices as sequential image-like data, enabling efficient and adaptive transmission in dynamic environments. Simulation results using ray-tracing channel data generated in NVIDIA Sionna validate the proposed method, showing up to 36.60% throughput improvement over benchmark strategies.', 'abstract_zh': '减小超5G网络中的反馈开销是一个关键挑战，随着现代大规模MIMO系统中天线数量的增加，频率分割双工（FDD）系统中的信道状态信息（CSI）反馈需求显著增加。为解决这一问题，大量研究集中于CSI压缩和预测，基于神经网络的方法日益受到关注，并被认为有望整合到3GPP 5G-Advanced标准中。尽管深度学习已被有效应用于CSI受限的波束形成和切换优化，但在此类约束下的参考信号分配仍然惊讶地未被充分探索。为填补这一空白，我们提出了基于信道预测的参考信号分配（CPRS）的概念，该方法联合优化信道预测和DM-RS分配，以提高数据吞吐量，而无需CSI反馈。我们进一步提出了一种符合标准的基于ViViT/CNN的架构，通过将 evolving CSI矩阵视为序贯图像-like数据来实现CPRS，从而在动态环境中实现高效且自适应的传输。使用NVIDIA Sionna生成的射线跟踪通道数据进行的仿真结果验证了所提出的方法，显示吞吐量提高了36.60%，优于基准策略。', 'title_zh': '符合标准的DM-RS分配方法：基于时域信道预测的大规模MIMO系统'}
{'arxiv_id': 'arXiv:2507.11061', 'title': 'Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling', 'authors': 'Hayeon Kim, Ji Ha Jang, Se Young Chun', 'link': 'https://arxiv.org/abs/2507.11061', 'abstract': 'Recent advances in 3D neural representations and instance-level editing models have enabled the efficient creation of high-quality 3D content. However, achieving precise local 3D edits remains challenging, especially for Gaussian Splatting, due to inconsistent multi-view 2D part segmentations and inherently ambiguous nature of Score Distillation Sampling (SDS) loss. To address these limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that enables precise and drastic part-level modifications. First, we introduce a robust 3D mask generation module with our 3D-Geometry Aware Label Prediction (3D-GALP), which uses spherical harmonics (SH) coefficients to model view-dependent label variations and soft-label property, yielding accurate and consistent part segmentations across viewpoints. Second, we propose a regularized SDS loss that combines the standard SDS loss with additional regularizers. In particular, an L1 anchor loss is introduced via our Scheduled Latent Mixing and Part (SLaMP) editing method, which generates high-quality part-edited 2D images and confines modifications only to the target region while preserving contextual coherence. Additional regularizers, such as Gaussian prior removal, further improve flexibility by allowing changes beyond the existing context, and robust 3D masking prevents unintended edits. Experimental results demonstrate that our RoMaP achieves state-of-the-art local 3D editing on both reconstructed and generated Gaussian scenes and objects qualitatively and quantitatively, making it possible for more robust and flexible part-level 3D Gaussian editing.', 'abstract_zh': 'Recent Advances in 3D神经表示和实例级编辑模型使得高效创建高质量3D内容成为可能，然而，实现精确的局部3D编辑仍然具有挑战性，尤其是在高斯成簇方面，这主要是由于多视角2D部件分割的一致性问题和Score Distillation Sampling (SDS)损失固有的含糊性。为解决这些限制，我们提出RoMaP，一种新颖的局部3D高斯编辑框架，能够实现精确和剧烈的部件级修改。首先，我们引入了一种鲁棒的3D掩码生成模块，使用球谐系数（SH）来建模视角依赖的标签变化和软标签特性，从而在不同视角下获得准确且一致的部件分割。其次，我们提出了一种正则化的SDS损失，将标准的SDS损失与附加正则化器相结合。特别是，通过我们的Scheduled Latent Mixing and Part (SLaMP)编辑方法，引入了L1锚定损失，该方法生成高质量的部件编辑2D图像，并将修改仅限于目标区域，同时保持上下文的一致性。附加的正则化器，如高斯先验去除，进一步提高了灵活性，允许超出现有上下文的更改，并且鲁棒的3D掩码防止了非预期的修改。实验结果表明，我们的RoMaP在重构和生成的高斯场景和对象的局部3D编辑方面达到了最先进的水平，无论是定性还是定量评估，都使其成为更鲁棒和灵活的部件级3D高斯编辑的可能性。', 'title_zh': '带正则化评分蒸馏采样的鲁棒3D-掩码部分级编辑在3D高斯点绘制中'}
{'arxiv_id': 'arXiv:2507.11059', 'title': 'SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks', 'authors': 'Pavel Adamenko, Mikhail Ivanov, Aidar Valeev, Rodion Levichev, Pavel Zadorozhny, Ivan Lopatin, Dmitry Babayev, Alena Fenogenova, Valentin Malykh', 'link': 'https://arxiv.org/abs/2507.11059', 'abstract': 'The rapid advancement of Large Language Models (LLMs) in software engineering has revealed critical limitations in existing benchmarks, particularly the widely used SWE-bench dataset. Recent studies have uncovered severe data contamination issues, e.g. SWE-bench reports 32.67% of successful patches involve direct solution leakage and 31.08\\% pass due to inadequate test cases. We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to address these fundamental challenges through an automated collection of real-world GitHub issues and rigorous quality validation. Our approach implements a reliable pipeline that ensures quality while minimizing contamination risks, resulting in approximately 10,000 potential tasks with 300 samples currently available. Evaluation using the Aider coding agent demonstrates strong discriminative power in state-of-the-art models. We report performance across a dozen recent LLMs evaluated on tasks collected between September 2024 and June 2025.', 'abstract_zh': '大语言模型在软件工程中的迅速发展揭示了现有基准的严重局限性，特别是广泛使用的SWE-bench数据集。近期研究发现了严重的数据污染问题，例如，SWE-bench报告32.67%的成功补丁涉及直接解题泄露，31.08%通过了由于不足的测试案例。我们引入SWE-MERA，这是一种动态的、不断更新的基准，旨在通过自动收集GitHub实际问题并进行严格的品质验证来解决这些根本性挑战。我们的方法实施了一种可靠的流水线，确保品质同时最大限度地减少污染风险，目前已收集大约10,000个潜在任务，其中300个样本可用。使用Aider编码代理进行评估展示了最先进的模型的强大区分能力。我们在2024年9月至2025年6月期间收集的任务上评估了十几种近期的大语言模型。', 'title_zh': 'SWE-MERA：一种动态基准，用于自主评估大型语言模型在软件工程任务中的表现'}
{'arxiv_id': 'arXiv:2507.11053', 'title': 'GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices', 'authors': 'Danish Gufran, Sudeep Pasricha', 'link': 'https://arxiv.org/abs/2507.11053', 'abstract': 'Accurate indoor localization is crucial for enabling spatial context in smart environments and navigation systems. Wi-Fi Received Signal Strength (RSS) fingerprinting is a widely used indoor localization approach due to its compatibility with mobile embedded devices. Deep Learning (DL) models improve accuracy in localization tasks by learning RSS variations across locations, but they assume fingerprint vectors exist in a Euclidean space, failing to incorporate spatial relationships and the non-uniform distribution of real-world RSS noise. This results in poor generalization across heterogeneous mobile devices, where variations in hardware and signal processing distort RSS readings. Graph Neural Networks (GNNs) can improve upon conventional DL models by encoding indoor locations as nodes and modeling their spatial and signal relationships as edges. However, GNNs struggle with non-Euclidean noise distributions and suffer from the GNN blind spot problem, leading to degraded accuracy in environments with dense access points (APs). To address these challenges, we propose GATE, a novel framework that constructs an adaptive graph representation of fingerprint vectors while preserving an indoor state-space topology, modeling the non-Euclidean structure of RSS noise to mitigate environmental noise and address device heterogeneity. GATE introduces 1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a novel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind spot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic graph adaptation. Extensive real-world evaluations across multiple indoor spaces with varying path lengths, AP densities, and heterogeneous devices demonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and 1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor localization frameworks.', 'abstract_zh': '准确的室内定位对于在智能环境和导航系统中启用空间上下文至关重要。基于Wi-Fi接收信号强度（RSS）指纹识别的室内定位方法因其与移动嵌入式设备的兼容性而广泛使用。深度学习（DL）模型通过学习不同位置的RSS变化来提高定位精度，但它们假设指纹向量存在于欧几里得空间中，未能纳入空间关系和现实世界RSS噪声的非均匀分布。这导致在不同种类的移动设备上泛化能力较差，因为硬件和信号处理的变化会扭曲RSS读数。图神经网络（GNNs）可以通过将室内位置编码为节点，并建模它们的空间和信号关系来增强传统的DL模型。然而，GNNs在处理非欧几里得噪声分布时存在困难，并且遭受GNN盲点问题的影响，在密集访问点（APs）的环境中会导致精度下降。为了解决这些挑战，我们提出了一种名为GATE的新框架，该框架构建了指纹向量的自适应图表示，同时保留了室内的状态空间拓扑，并建模RSS噪声的非欧几里得结构以减轻环境噪声并解决设备异质性问题。GATE引入了1）一种新的注意超空间向量（AHV）以增强信息传递，2）一种新的多维超空间向量（MDHV）以减轻GNN盲点问题，并3）一种新的实时边构造（RTEC）方法以实现动态图适应。在多个室内空间中，通过对不同路径长度、AP密度和异质设备的广泛现实世界评估表明，与现有的室内部定位框架相比，GATE实现了1.6到4.72倍更低的平均定位误差和1.85到4.57倍更低的最坏情况误差。', 'title_zh': 'GATE：基于实时边构建的图注意力神经网络在移动嵌入式设备上实现 robust 室内定位'}
{'arxiv_id': 'arXiv:2507.11052', 'title': 'LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP', 'authors': 'Haowei Yang, Ziyu Shen, Junli Shao, Luyao Men, Xinyue Han, Jing Dong', 'link': 'https://arxiv.org/abs/2507.11052', 'abstract': 'Timely identification and accurate risk stratification of cardiovascular disease (CVD) remain essential for reducing global mortality. While existing prediction models primarily leverage structured data, unstructured clinical notes contain valuable early indicators. This study introduces a novel LLM-augmented clinical NLP pipeline that employs domain-adapted large language models for symptom extraction, contextual reasoning, and correlation from free-text reports. Our approach integrates cardiovascular-specific fine-tuning, prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III and CARDIO-NLP datasets demonstrate improved performance in precision, recall, F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by cardiologists. Challenges such as contextual hallucination, which occurs when plausible information contracts with provided source, and temporal ambiguity, which is related with models struggling with chronological ordering of events are addressed using prompt engineering and hybrid rule-based verification. This work underscores the potential of LLMs in clinical decision support systems (CDSS), advancing early warning systems and enhancing the translation of patient narratives into actionable risk assessments.', 'abstract_zh': '及时识别和准确分层心血管疾病（CVD）风险对于降低全球死亡率仍然至关重要。尽管现有的预测模型主要利用结构化数据，但未结构化的临床笔记包含有价值的早期指标。本研究引入了一种新型的LLM增强临床NLP管道，采用领域适应的大语言模型进行症状提取、上下文推理和自由文本报告中的相关性分析。我们的方法结合了心血管特定的微调、基于提示的推断和实体感知推理。在MIMIC-III和CARDIO-NLP数据集上的评估结果显示，在精确度、召回率、F1分数和AUROC方面均有所提升，并且经过心脏病专家评估具有高度的临床相关性（κ=0.82）。通过提示工程和混合规则验证应对了上下文幻觉和时间模糊性等挑战。本工作突显了LLM在临床决策支持系统（CDSS）中的潜在价值，推进了早期预警系统的改进，并增强了患者叙述转化为可操作的风险评估的转化。', 'title_zh': 'LLM增强症状分析在心血管疾病风险预测中的临床NLP研究'}
{'arxiv_id': 'arXiv:2507.11017', 'title': 'First-Order Error Matters: Accurate Compensation for Quantized Large Language Models', 'authors': 'Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu', 'link': 'https://arxiv.org/abs/2507.11017', 'abstract': 'Post-training quantization (PTQ) offers an efficient approach to compressing large language models (LLMs), significantly reducing memory access and computational costs. Existing compensation-based weight calibration methods often rely on a second-order Taylor expansion to model quantization error, under the assumption that the first-order term is negligible in well-trained full-precision models. However, we reveal that the progressive compensation process introduces accumulated first-order deviations between latent weights and their full-precision counterparts, making this assumption fundamentally flawed. To address this, we propose FOEM, a novel PTQ method that explicitly incorporates first-order gradient terms to improve quantization error compensation. FOEM approximates gradients by directly computing the difference between latent and full-precision weights, avoiding the high cost and limited generalization of backpropagation-based gradient computation. This approach introduces minimal additional computational overhead. Moreover, FOEM leverages precomputed Cholesky factors to efficiently recover the inverse of Hessian submatrices in real time. Extensive experiments across a wide range of models and benchmarks demonstrate that FOEM consistently outperforms the classical GPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of Llama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from 51.7% to 74.9%, approaching the full-precision performance of 78.6%. Furthermore, FOEM can be seamlessly integrated with advanced techniques such as GPTAQ and SpinQuant, yielding additional improvements under the challenging W4A4KV4 setting, and further narrowing the accuracy gap with full-precision baselines beyond what current state-of-the-art methods achieve. The code is available at this https URL.', 'abstract_zh': '.POST-TRAINING 量化 (PTQ) 提供了一种高效的方法来压缩大规模语言模型 (LLMs)，显著减少了内存访问和计算成本。现有的基于补偿的权重标定方法往往依赖于二阶泰勒展开来建模量化误差，并假设在充分训练的全精度模型中一阶项是可忽略的。然而，我们揭示了渐进补偿过程在潜在权重与其全精度对应值之间引入了一阶偏差累计，使这一假设从根本上变为错误。为此，我们提出了FOEM，这是一种新颖的PTQ方法，明确引入了一阶梯度项以改进量化误差补偿。FOEM 通过直接计算潜在权重和全精度权重之间的差异来近似梯度，避免了基于反向传播的梯度计算高成本和有限泛化能力。这种做法引入了最小的额外计算开销。此外，FOEM 利用预计算的 Cholesky 因子以高效方式实时恢复海森矩阵的逆。广泛的实验表明，FOEM 在多种模型和基准测试中表现始终优于经典的GPTQ方法。在3比特权重量化中，FOEM 将Llama3-8B的困惑度降低了89.6%，并将Llama3-70B的5-shot MMLU准确性从51.7%提高到74.9%，接近全精度性能的78.6%。此外，FOEM 可以无缝集成到如GPTAQ和SpinQuant等高级技术中，在具有挑战性的W4A4KV4设置下提供额外改进，并进一步缩小与全精度基线之间的准确性差距，超越当前最先进的方法的实现。代码可在此处获取。', 'title_zh': '一阶误差很重要：准确补偿量化大型语言模型'}
{'arxiv_id': 'arXiv:2507.11015', 'title': 'Semantically Informed Salient Regions Guided Radiology Report Generation', 'authors': 'Zeyi Hou, Zeqiang Wei, Ruixin Yan, Ning Lang, Xiuzhuang Zhou', 'link': 'https://arxiv.org/abs/2507.11015', 'abstract': 'Recent advances in automated radiology report generation from chest X-rays using deep learning algorithms have the potential to significantly reduce the arduous workload of radiologists. However, due to the inherent massive data bias in radiology images, where abnormalities are typically subtle and sparsely distributed, existing methods often produce fluent yet medically inaccurate reports, limiting their applicability in clinical practice. To address this issue effectively, we propose a Semantically Informed Salient Regions-guided (SISRNet) report generation method. Specifically, our approach explicitly identifies salient regions with medically critical characteristics using fine-grained cross-modal semantics. Then, SISRNet systematically focuses on these high-information regions during both image modeling and report generation, effectively capturing subtle abnormal findings, mitigating the negative impact of data bias, and ultimately generating clinically accurate reports. Compared to its peers, SISRNet demonstrates superior performance on widely used IU-Xray and MIMIC-CXR datasets.', 'abstract_zh': '近年来，利用深度学习算法从胸部X光片自动生成放射学报告的进展，有可能显著减轻放射科医生的繁重工作负担。然而，由于放射学图像中固有的大量数据偏差，其中异常通常极为细微且分布稀疏，现有方法往往会生成流畅但医学上不准确的报告，限制了其在临床实践中的应用。为有效解决这一问题，我们提出了一种基于语义引导的重要区域（SISRNet）报告生成方法。具体而言，我们的方法通过细粒度的跨模态语义明确识别具有医学关键特征的重要区域。然后，SISRNet在图像建模和报告生成过程中系统地关注这些信息丰富区域，有效捕捉细微的异常发现，减轻数据偏差的负面影响，并最终生成临床准确的报告。与同类方法相比，SISRNet在广泛使用的IU-Xray和MIMIC-CXR数据集中展示了更优的性能。', 'title_zh': '语义驱动的突出区域指导的放射学报告生成'}
{'arxiv_id': 'arXiv:2507.10999', 'title': 'SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition', 'authors': 'Quan Bi Pay, Vishnu Monn Baskaran, Junn Yong Loo, KokSheik Wong, Simon See', 'link': 'https://arxiv.org/abs/2507.10999', 'abstract': 'The resurgence of convolutional neural networks (CNNs) in visual recognition tasks, exemplified by ConvNeXt, has demonstrated their capability to rival transformer-based architectures through advanced training methodologies and ViT-inspired design principles. However, both CNNs and transformers exhibit a simplicity bias, favoring straightforward features over complex structural representations. Furthermore, modern CNNs often integrate MLP-like blocks akin to those in transformers, but these blocks suffer from significant information redundancies, necessitating high expansion ratios to sustain competitive performance. To address these limitations, we propose SpaRTAN, a lightweight architectural design that enhances spatial and channel-wise information processing. SpaRTAN employs kernels with varying receptive fields, controlled by kernel size and dilation factor, to capture discriminative multi-order spatial features effectively. A wave-based channel aggregation module further modulates and reinforces pixel interactions, mitigating channel-wise redundancies. Combining the two modules, the proposed network can efficiently gather and dynamically contextualize discriminative features. Experimental results in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable parameter efficiency while maintaining competitive performance. In particular, on the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M parameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver strong performance through an efficient design. On the COCO benchmark, it achieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M parameters. The code is publicly available at [this https URL].', 'abstract_zh': '卷积神经网络（CNNs）在视觉识别任务中的 resurgence，以 ConvNeXt 为例，证明了其通过先进的训练方法和受 ViT 启发的设计原则，能够与基于变换器的架构相媲美。然而，这两种方法都存在简化偏见，偏好简单的特征而非复杂的结构表示。此外，现代 CNN 经常整合类似于变换器中的 MLP 块，但这些块存在着显著的信息冗余，需要高的扩展比以维持竞争力的表现。为了解决这些限制，我们提出了 SpaRTAN，一种轻量级的架构设计，增强空间和通道级的信息处理。SpaRTAN 使用可由kernel大小和膨胀因子控制的具有不同接收域的 kernel，以有效地捕捉具有鉴别性的多阶空间特征。一种基于波的通道聚合模块进一步调节和强化像素间的交互，缓解通道级的冗余。结合这两个模块，提出的网络能够高效地收集和动态地上下文化鉴别特征。实验结果显示，SpaRTAN 在保持竞争力的同时实现了显著的参数效率，在 ImageNet 和 COCO 挑战中分别以仅 3.8M 参数和约 1.0 GFLOPs 达到 77.7% 的准确率，并在 COCO 挑战中以仅 21.5M 参数达到 50.0% 的 AP，超过了之前的最佳结果。相关的代码已公开发布。', 'title_zh': 'SpaRTAN: 基于空间强化标记的聚合网络 för 视觉识别'}
{'arxiv_id': 'arXiv:2507.10998', 'title': 'Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data', 'authors': 'Zhipeng He, Alexander Stevens, Chun Ouyang, Johannes De Smedt, Alistair Barros, Catarina Moreira', 'link': 'https://arxiv.org/abs/2507.10998', 'abstract': 'Adversarial attacks on tabular data present fundamental challenges distinct from image or text domains due to the heterogeneous nature of mixed categorical and numerical features. Unlike images where pixel perturbations maintain visual similarity, tabular data lacks intuitive similarity metrics, making it difficult to define imperceptible modifications. Additionally, traditional gradient-based methods prioritise $\\ell_p$-norm constraints, often producing adversarial examples that deviate from the original data distributions, making them detectable. We propose a latent space perturbation framework using a mixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial examples. The proposed VAE integrates categorical embeddings and numerical features into a unified latent manifold, enabling perturbations that preserve statistical consistency. We specify In-Distribution Success Rate (IDSR) to measure the proportion of adversarial examples that remain statistically indistinguishable from the input distribution. Evaluation across six publicly available datasets and three model architectures demonstrates that our method achieves substantially lower outlier rates and more consistent performance compared to traditional input-space attacks and other VAE-based methods adapted from image domain approaches. Our comprehensive analysis includes hyperparameter sensitivity, sparsity control mechanisms, and generative architectural comparisons, revealing that VAE-based attacks depend critically on reconstruction quality but offer superior practical utility when sufficient training data is available. This work highlights the importance of on-manifold perturbations for realistic adversarial attacks on tabular data, offering a robust approach for practical deployment. The source code can be accessed through this https URL.', 'abstract_zh': '针对表格数据的对抗攻击由于混合的类别和数值特征的异质性质，提出了不同于图像或文本域的基本挑战。我们提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，以生成不可感知的对抗样本。所提出的VAE将类别嵌入和数值特征整合到统一的潜在流形中，使扰动能够保持统计一致性。我们通过In-Distribution Success Rate（IDSR）衡量对抗样本在统计上与输入分布差异不大的比例。在六个公开数据集和三种模型架构上的评估表明，与传统输入空间攻击和其他源自图像域方法的VAE基方法相比，我们的方法实现了显著更低的异常值率和更一致的性能。我们的全面分析包括超参数敏感性、稀疏性控制机制和生成架构比较，揭示了基于VAE的攻击在有足够的训练数据时对重构质量的依赖性，但提供了优于其他方法的实用优势。这项工作强调了在表格数据上进行现实对抗攻击时沿流形扰动的重要性，提供了一种适用于实际部署的稳健方法。源代码可通过以下链接访问：这个https URL。', 'title_zh': '在流形上的不可感知 adversarial 攻击构建方法：针对表格数据'}
{'arxiv_id': 'arXiv:2507.10995', 'title': 'Misalignment from Treating Means as Ends', 'authors': 'Henrik Marklund, Alex Infanger, Benjamin Van Roy', 'link': 'https://arxiv.org/abs/2507.10995', 'abstract': "Reward functions, learned or manually specified, are rarely perfect. Instead of accurately expressing human goals, these reward functions are often distorted by human beliefs about how best to achieve those goals. Specifically, these reward functions often express a combination of the human's terminal goals -- those which are ends in themselves -- and the human's instrumental goals -- those which are means to an end. We formulate a simple example in which even slight conflation of instrumental and terminal goals results in severe misalignment: optimizing the misspecified reward function results in poor performance when measured by the true reward function. This example distills the essential properties of environments that make reinforcement learning highly sensitive to conflation of instrumental and terminal goals. We discuss how this issue can arise with a common approach to reward learning and how it can manifest in real environments.", 'abstract_zh': '奖励函数，无论是学习得到的还是人工指定的，往往并不完美。这些奖励函数通常受到人类如何最好地实现目标的信念扭曲，而不是准确表达人类的目标。具体来说，这些奖励函数往往包含了人类的终端目标——这些目标本身即为目的，以及工具性目标——这些目标是达到其他目标的手段。我们提出一个简单的例子，即使轻微地混同工具性目标和终端目标也会导致严重的不一致性：优化这个错指定的奖励函数会导致在真正的奖励函数下表现不佳。该例子提炼了使强化学习对混同工具性目标和终端目标高度敏感的环境的基本特性。我们讨论这种问题如何通过一种常见的奖励学习方法出现，以及它在真实环境中的可能表现形式。', 'title_zh': '将均值视为最终目标的偏移'}
{'arxiv_id': 'arXiv:2507.10990', 'title': 'High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization', 'authors': 'Rodney Lafuente-Mercado', 'link': 'https://arxiv.org/abs/2507.10990', 'abstract': 'Scaling reinforcement learning (RL) workloads often requires distributing environment simulation across compute clusters. Existing frameworks entangle simulation, learning logic, and orchestration into monolithic systems, limiting modularity and reusability. We present ClusterEnv, a lightweight, learner-agnostic interface for distributed environment execution that mirrors the Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples simulation from training by offloading reset() and step() operations to remote workers while keeping learning centralized. To address policy staleness in distributed execution, we propose Adaptive Actor Policy Synchronization (AAPS), a divergence-triggered update mechanism that reduces synchronization overhead without sacrificing performance. ClusterEnv integrates cleanly into existing RL pipelines, supports both on-policy and off-policy methods, and requires minimal code changes. Experiments on discrete control tasks demonstrate that AAPS achieves high sample efficiency with significantly fewer weight updates. Source code is available at this https URL.', 'abstract_zh': '分布式执行环境的轻量级、学习器无关接口：ClusterEnv及其在强化学习工作负载扩展中的应用', 'title_zh': '高 throughput 分布式强化学习通过自适应策略同步'}
{'arxiv_id': 'arXiv:2507.10985', 'title': 'Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison', 'authors': 'Andrew Valdivia, Yueming Zhang, Hailu Xu, Amir Ghasemkhani, Xin Qin', 'link': 'https://arxiv.org/abs/2507.10985', 'abstract': "This paper presents a novel approach for detecting mispronunciations by analyzing deviations between a user's original speech and their voice-cloned counterpart with corrected pronunciation. We hypothesize that regions with maximal acoustic deviation between the original and cloned utterances indicate potential mispronunciations. Our method leverages recent advances in voice cloning to generate a synthetic version of the user's voice with proper pronunciation, then performs frame-by-frame comparisons to identify problematic segments. Experimental results demonstrate the effectiveness of this approach in pinpointing specific pronunciation errors without requiring predefined phonetic rules or extensive training data for each target language.", 'abstract_zh': '本文提出了一种通过分析用户原始发音与其带有正确发音的克隆语音之间的偏差来检测误发音的新方法。我们假设原始发音与克隆发音之间声学偏差最大的区域可能表明潜在的误发音。该方法利用近期语音克隆技术生成用户带有正确发音的合成语音版本，然后进行帧对帧比较以识别问题段落。实验结果证明了该方法在无需预定义 Phonetic 规则或针对每个目标语言进行大量训练数据的情况下，能够精准定位特定的发音错误。', 'title_zh': '通过声音克隆和声学对比进行发音偏差分析'}
{'arxiv_id': 'arXiv:2507.10977', 'title': 'Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection', 'authors': 'Quan Bi Pay, Vishnu Monn Baskaran, Junn Yong Loo, KokSheik Wong, Simon See', 'link': 'https://arxiv.org/abs/2507.10977', 'abstract': 'Human-object interaction (HOI) detection is essential for accurately localizing and characterizing interactions between humans and objects, providing a comprehensive understanding of complex visual scenes across various domains. However, existing HOI detectors often struggle to deliver reliable predictions efficiently, relying on resource-intensive training methods and inefficient architectures. To address these challenges, we conceptualize a wavelet attention-like backbone and a novel ray-based encoder architecture tailored for HOI detection. Our wavelet backbone addresses the limitations of expressing middle-order interactions by aggregating discriminative features from the low- and high-order interactions extracted from diverse convolutional filters. Concurrently, the ray-based encoder facilitates multi-scale attention by optimizing the focus of the decoder on relevant regions of interest and mitigating computational overhead. As a result of harnessing the attenuated intensity of learnable ray origins, our decoder aligns query embeddings with emphasized regions of interest for accurate predictions. Experimental results on benchmark datasets, including ImageNet and HICO-DET, showcase the potential of our proposed architecture. The code is publicly available at [this https URL].', 'abstract_zh': '人体-物体交互（HOI）检测对于准确定位和描述人类与物体之间的交互至关重要，有助于对各种领域中复杂视觉场景进行全面理解。然而，现有的HOI检测器往往难以高效地提供可靠的预测，依赖于资源密集型的训练方法和低效的网络结构。为了解决这些问题，我们提出了一种小波注意力_like主干和一种新的基于射线的编码器架构，专为HOI检测设计。我们的小波主干通过从多种卷积滤波器中提取的低阶和高阶交互中聚合 discriminative 特征，解决了表达中阶交互的局限性。同时，基于射线的编码器通过优化解码器对相关感兴趣区域的关注并减轻计算开销，实现了多尺度注意力。通过利用可学习射线原点的衰减强度，我们的解码器将查询嵌入与强调的感兴趣区域对齐，以实现准确的预测。在ImageNet和HICO-DET等基准数据集上的实验结果展示了我们提出架构的潜力。相关代码已在[此链接]公开。', 'title_zh': '多尺度小波注意力与基于射线的编码对人体-物体交互检测的概念化'}
{'arxiv_id': 'arXiv:2507.10957', 'title': 'Modeling Understanding of Story-Based Analogies Using Large Language Models', 'authors': 'Kalit Inani, Keshav Kabra, Vijay Marupudi, Sashank Varma', 'link': 'https://arxiv.org/abs/2507.10957', 'abstract': 'Recent advancements in Large Language Models (LLMs) have brought them closer to matching human cognition across a variety of tasks. How well do these models align with human performance in detecting and mapping analogies? Prior research has shown that LLMs can extract similarities from analogy problems but lack robust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the current study focused on a story-based analogical mapping task and conducted a fine-grained evaluation of LLM reasoning abilities compared to human performance. First, it explored the semantic representation of analogies in LLMs, using sentence embeddings to assess whether they capture the similarity between the source and target texts of an analogy, and the dissimilarity between the source and distractor texts. Second, it investigated the effectiveness of explicitly prompting LLMs to explain analogies. Throughout, we examine whether LLMs exhibit similar performance profiles to those observed in humans by evaluating their reasoning at the level of individual analogies, and not just at the level of overall accuracy (as prior studies have done). Our experiments include evaluating the impact of model size (8B vs. 70B parameters) and performance variation across state-of-the-art model architectures such as GPT-4 and LLaMA3. This work advances our understanding of the analogical reasoning abilities of LLMs and their potential as models of human reasoning.', 'abstract_zh': '最近大型语言模型（LLMs）的发展使它们在各种任务上更接近人类认知。这些模型在检测和映射类比方面与人类表现的匹配程度如何？先前的研究表明，LLMs可以从类比问题中提取相似性，但在稳健的人类-like推理方面存在不足。在此基础上，本研究专注于基于故事的类比映射任务，并对LLMs的推理能力与人类表现进行了细致评估。首先，研究探索了LLMs中类比的语义表示，使用句子嵌入评估它们是否捕捉了源文本和目标文本之间的相似性，以及源文本和干扰文本之间的不相似性。其次，研究调查了显式提示LLMs解释类比的有效性。在整个过程中，我们通过评估个体类比的推理能力，而不是仅评估总体准确性（如先前研究所做的），考察LLMs是否表现出与人类相似的表现模式。我们的实验还包括评估模型大小（8B vs. 70B参数）及在当前先进模型架构如GPT-4和LLaMA3上的性能差异。这项工作推进了我们对LLMs类比推理能力和其作为人类推理模型的潜力的理解。', 'title_zh': '基于故事类类比的理解建模研究'}
{'arxiv_id': 'arXiv:2507.10951', 'title': 'Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures', 'authors': 'Siyu Yu, Zihan Qin, Tingshan Liu, Beiya Xu, R. Jacob Vogelstein, Jason Brown, Joshua T. Vogelstein', 'link': 'https://arxiv.org/abs/2507.10951', 'abstract': 'The complete connectome of the Drosophila larva brain offers a unique opportunity to investigate whether biologically evolved circuits can support artificial intelligence. We convert this wiring diagram into a Biological Processing Unit (BPU), a fixed recurrent network derived directly from synaptic connectivity. Despite its modest size 3,000 neurons and 65,000 weights between them), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10, surpassing size-matched MLPs. Scaling the BPU via structured connectome expansions further improves CIFAR-10 performance, while modality-specific ablations reveal the uneven contributions of different sensory subsystems. On the ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000 games achieves 60% move accuracy, nearly 10x better than any size transformer. Moreover, CNN-BPU models with ~2M parameters outperform parameter-matched Transformers, and with a depth-6 minimax search at inference, reach 91.7% accuracy, exceeding even a 9M-parameter Transformer baseline. These results demonstrate the potential of biofidelic neural architectures to support complex cognitive tasks and motivate scaling to larger and more intelligent connectomes in future work.', 'abstract_zh': '果蝇幼虫脑的完整连接组提供了一个独特的机会，以研究生物进化电路是否能支持人工智能。我们将其连接图转换为生物处理单元（BPU），这是一种直接源自突触连接的固定循环网络。尽管其规模较小（3,000个神经元和它们之间65,000个权重），未经修改的BPU在MNIST上的准确率达到98%，CIFAR-10上的准确率为58%，超越了相同规模的多层感知机（MLP）。通过对BPU进行结构化连接组扩展进行放大规模进一步提高了CIFAR-10的性能，而模态特定的消融实验揭示了不同感觉子系统不均匀的贡献。在ChessBench数据集上，仅使用10,000场比赛训练的轻量级GNN-BPU模型实现了60%的走棋准确性，几乎是任何大小的变换器的10倍。此外，具有约200万个参数的CNN-BPU模型超过了参数匹配的变换器，并且在推理过程中进行深度为6的极小极大搜索，准确率达到了91.7%，甚至超过了900万个参数的变换器基线。这些结果展示了生物忠实神经架构支持复杂认知任务的潜力，并激励未来工作将这些架构扩展到更大、更智能的连接组。', 'title_zh': '生物处理单元：利用昆虫连接组先行探索生物仿真的神经架构'}
{'arxiv_id': 'arXiv:2507.10933', 'title': 'Artificial Finance: How AI Thinks About Money', 'authors': 'Orhan Erdem, Ragavi Pobbathi Ashok', 'link': 'https://arxiv.org/abs/2507.10933', 'abstract': "In this paper, we explore how large language models (LLMs) approach financial decision-making by systematically comparing their responses to those of human participants across the globe. We posed a set of commonly used financial decision-making questions to seven leading LLMs, including five models from the GPT series(GPT-4o, GPT-4.5, o1, o3-mini), Gemini 2.0 Flash, and DeepSeek R1. We then compared their outputs to human responses drawn from a dataset covering 53 nations. Our analysis reveals three main results. First, LLMs generally exhibit a risk-neutral decision-making pattern, favoring choices aligned with expected value calculations when faced with lottery-type questions. Second, when evaluating trade-offs between present and future, LLMs occasionally produce responses that appear inconsistent with normative reasoning. Third, when we examine cross-national similarities, we find that the LLMs' aggregate responses most closely resemble those of participants from Tanzania. These findings contribute to the understanding of how LLMs emulate human-like decision behaviors and highlight potential cultural and training influences embedded within their outputs.", 'abstract_zh': '本文通过系统比较七种领先的大型语言模型（包括GPT系列的GPT-4o、GPT-4.5、o1、o3-mini，Gemini 2.0 Flash和DeepSeek R1）和来自覆盖53个国家的人类参与者数据集的响应，探讨了大型语言模型在金融决策中的方法。研究发现三个主要结果：首先，大型语言模型通常表现出风险中立的决策模式，倾向于在彩票类型问题中选择符合预期价值计算的结果；其次，在评估现在和未来之间的权衡时，大型语言模型偶尔会产生与规范推理不符的回应；第三，当考察跨境相似性时，发现大型语言模型的综合回应最接近坦桑尼亚参与者的回应。这些发现有助于理解大型语言模型如何模拟类似人类的决策行为，并突出其输出中嵌入的文化和训练影响。', 'title_zh': '人工智能金融：AI如何思考金钱'}
{'arxiv_id': 'arXiv:2507.10920', 'title': 'HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training', 'authors': 'Seungho Choi', 'link': 'https://arxiv.org/abs/2507.10920', 'abstract': 'Large language models (LLMs) often show poor performance in low-resource languages like Korean, partly due to unique linguistic challenges such as homophonous Sino-Korean words that are indistinguishable in Hangul script. To address this semantic ambiguity, we propose HanjaBridge, a novel meaning-injection technique integrated into a continual pre-training (CPT) framework. Instead of deterministically mapping a word to a single Hanja (Chinese character), HanjaBridge presents the model with all possible Hanja candidates for a given homograph, encouraging the model to learn contextual disambiguation. This process is paired with token-level knowledge distillation to prevent catastrophic forgetting. Experimental results show that HanjaBridge significantly improves Korean language understanding, achieving a 21\\% relative improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment between Korean and Chinese through shared Hanja, we observe a strong positive cross-lingual transfer. Furthermore, these gains persist even when Hanja augmentation is omitted at inference time, ensuring practical efficiency with no additional run-time cost.', 'abstract_zh': 'Large语言模型（LLMs）在韩语等低资源语言上常表现出较差的效果，部分原因是由于韩语中特有的语义挑战，如同音异义的汉语借词，在hangul字母中无法区分。为解决这一语义歧义问题，我们提出了一种名为HanjaBridge的新颖意义注入技术，将其集成到持续预训练（CPT）框架中。不同于将一个词确定性地映射到单个汉字，HanjaBridge为给定的同形词展示所有可能的汉字候选，促使模型学习上下文消歧。该过程配有标记级的知识蒸馏，以防止灾难性遗忘。实验结果表明，HanjaBridge显著提高了韩语理解能力，在KoBALT基准测试上取得了21%的相对改进。值得注意的是，通过共享汉字强化韩语和汉语之间的语义对齐，我们观察到强烈的跨语言迁移效果。此外，即使在推理时不使用汉字扩充，这些增益仍然存在，确保了实际中的高效性且无额外运行时成本。', 'title_zh': 'HanjaBridge：通过 Hanja 增强预训练解决韩语大规模语言模型的语义歧义'}
{'arxiv_id': 'arXiv:2507.10904', 'title': 'Class-Proportional Coreset Selection for Difficulty-Separable Data', 'authors': 'Elisa Tsai, Haizhong Zheng, Atul Prakash', 'link': 'https://arxiv.org/abs/2507.10904', 'abstract': 'High-quality training data is essential for building reliable and efficient machine learning systems. One-shot coreset selection addresses this by pruning the dataset while maintaining or even improving model performance, often relying on training-dynamics-based data difficulty scores. However, most existing methods implicitly assume class-wise homogeneity in data difficulty, overlooking variation in data difficulty across different classes.\nIn this work, we challenge this assumption by showing that, in domains such as network intrusion detection and medical imaging, data difficulty often clusters by class. We formalize this as class-difficulty separability and introduce the Class Difficulty Separability Coefficient (CDSC) as a quantitative measure. We demonstrate that high CDSC values correlate with performance degradation in class-agnostic coreset methods, which tend to overrepresent easy majority classes while neglecting rare but informative ones.\nTo address this, we introduce class-proportional variants of multiple sampling strategies. Evaluated on five diverse datasets spanning security and medical domains, our methods consistently achieve state-of-the-art data efficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a class-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows remarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and recall 0.19%. In contrast, the class-agnostic CCS baseline, the next best method, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and 4.11% in recall.\nWe further show that aggressive pruning enhances generalization in noisy, imbalanced, and large-scale datasets. Our results underscore that explicitly modeling class-difficulty separability leads to more effective, robust, and generalizable data pruning, particularly in high-stakes scenarios.', 'abstract_zh': '高质量训练数据对于构建可靠高效的机器学习系统至关重要。基于训练动力学的数据难度评分的一次性核心集选择通过裁剪数据集同时保持或甚至提高模型性能。然而，现有的大多数方法隐含地假设数据难度在类内均匀分布，忽略了不同类间数据难度的变异性。\n\n在本工作中，我们挑战了这一假设，通过实验证明在网络入侵检测和医学成像等领域，数据难度往往按类聚类。我们将其形式化为类难度可分性，并引入了类难度分离系数（CDSC）作为定量度量。我们证明了高CDSC值与类无关核心集方法性能下降相关，这些方法倾向于过度代表易见的多数类而忽视稀有但信息丰富的类。\n\n为此，我们引入了多种采样策略的类比例变体。在覆盖集中核心集选择（CCS-CP）的类比例变体等方面，在五个涵盖安全和医疗领域的大不相同的數據集中，我们的方法始终保持了最先进的数据效率。例如，在CTU-13数据集上，极端99%的裁剪率下，CCS-CP的类比例变体表现出显著的稳定性，准确率仅下降2.58%，精确率0.49%，召回率0.19%。与之相反，类无关的CCS基线方法，作为第二好的方法，在准确率、精确率和召回率方面的下降分别达到7.59%、4.57%和4.11%。\n\n此外，我们还展示了在嘈杂、不平衡和大规模数据集上具有激进裁剪增强泛化能力。我们的结果表明，明确建模类难度可分性可导致更有效、更稳健和更具推广能力的数据裁剪，尤其是在高风险场景中。', 'title_zh': '难度可分数据的类别比例核心集选择方法'}
{'arxiv_id': 'arXiv:2507.10898', 'title': 'MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning', 'authors': 'Jugal Gajjar, Kamalasankari Subramaniakuppusamy, Noha El Kachach', 'link': 'https://arxiv.org/abs/2507.10898', 'abstract': 'The growing complexity of cyber threats and the limitations of traditional vulnerability detection tools necessitate novel approaches for securing software systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI pipeline for autonomous code security analysis and remediation. MalCodeAI combines code decomposition and semantic reasoning using fine-tuned Qwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA) within the MLX framework, and delivers scalable, accurate results across 14 programming languages. In Phase 1, the model achieved a validation loss as low as 0.397 for functional decomposition and summarization of code segments after 200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In Phase 2, for vulnerability detection and remediation, it achieved a best validation loss of 0.199 using the same number of iterations and trainable layers but with an increased learning rate of 4 x 10^(-5), effectively identifying security flaws and suggesting actionable fixes. MalCodeAI supports red-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot generalization to detect complex, zero-day vulnerabilities. In a qualitative evaluation involving 15 developers, the system received high scores in usefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of outputs (mean 7.53/10), confirming its practical value in real-world development workflows. This work marks a significant advancement toward intelligent, explainable, and developer-centric software security solutions.', 'abstract_zh': '面向复杂网络威胁的软件系统新型保护方法：MalCodeAI多阶段AI代码安全分析与修复pipeline', 'title_zh': 'MalCodeAI: 基于语言无关代码推理的自主漏洞检测与修复'}
{'arxiv_id': 'arXiv:2507.10895', 'title': 'Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition', 'authors': 'Xiaocong Zeng, Craig Michoski, Yan Pang, Dongyang Kuang', 'link': 'https://arxiv.org/abs/2507.10895', 'abstract': 'In this work, we address the often-overlooked issue of Timescale Dependent Label Inconsistency (TsDLI) in training neural network models for EEG-based human emotion recognition. To mitigate TsDLI and enhance model generalization and explainability, we propose two novel regularization strategies: Local Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods incorporate classical mathematical principles--specifically, functions of bounded variation and commute-time distances--within a graph theoretic framework. Complementing our regularizers, we introduce a suite of new evaluation metrics that better capture the alignment between temporally local predictions and their associated global emotion labels. We validate our approach through comprehensive experiments on two widely used EEG emotion datasets, DREAMER and DEAP, across a range of neural architectures including LSTM and transformer-based models. Performance is assessed using five distinct metrics encompassing both quantitative accuracy and qualitative consistency. Results consistently show that our proposed methods outperform state-of-the-art baselines, delivering superior aggregate performance and offering a principled trade-off between interpretability and predictive power under label inconsistency. Notably, LVL achieves the best aggregate rank across all benchmarked backbones and metrics, while LGCL frequently ranks the second, highlighting the effectiveness of our framework.', 'abstract_zh': '在基于EEG的人类情绪识别中应对时间尺度依赖标签不一致性的时间尺度依赖标签不一致性问题：提出两种新型正则化策略以增强模型的泛化能力和可解释性', 'title_zh': '时间尺度依赖的标签不一致性下基于通勤距离的正则化方法在EEG情绪识别中的应用'}
{'arxiv_id': 'arXiv:2507.10893', 'title': 'Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency', 'authors': 'Minjong Cheon, Eunhan Goo, Su-Hyeon Shin, Muhammad Ahmed, Hyungjun Kim', 'link': 'https://arxiv.org/abs/2507.10893', 'abstract': "Recently, AI-based weather forecast models have achieved impressive advances. These models have reached accuracy levels comparable to traditional NWP systems, marking a significant milestone in data-driven weather prediction. However, they mostly leverage Transformer-based architectures, which often leads to high training complexity and resource demands due to the massive parameter sizes. In this study, we introduce a modernized CNN-based model for global weather forecasting that delivers competitive accuracy while significantly reducing computational requirements. To present a systematic modernization roadmap, we highlight key architectural enhancements across multiple design scales from an earlier CNN-based approach. KAI-a incorporates a scale-invariant architecture and InceptionNeXt-based blocks within a geophysically-aware design, tailored to the structure of Earth system data. Trained on the ERA5 daily dataset with 67 atmospheric variables, the model contains about 7 million parameters and completes training in just 12 hours on a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the performance of state-of-the-art models in medium-range weather forecasting, while offering a significantly lightweight design. Furthermore, case studies on the 2018 European heatwave and the East Asian summer monsoon demonstrate KAI-a's robust skill in capturing extreme events, reinforcing its practical utility.", 'abstract_zh': '基于AI的天气预报模型最近取得了显著进展：现代CNN模型在降低计算需求的同时实现竞争性准确度', 'title_zh': '基于现代计算效率提升的CNN气象预报模型现代化研究'}
{'arxiv_id': 'arXiv:2507.10886', 'title': 'How to Protect Models against Adversarial Unlearning?', 'authors': 'Patryk Jasiorski, Marek Klonowski, Michał Woźniak', 'link': 'https://arxiv.org/abs/2507.10886', 'abstract': "AI models need to be unlearned to fulfill the requirements of legal acts such as the AI Act or GDPR, and also because of the need to remove toxic content, debiasing, the impact of malicious instances, or changes in the data distribution structure in which a model works. Unfortunately, removing knowledge may cause undesirable side effects, such as a deterioration in model performance. In this paper, we investigate the problem of adversarial unlearning, where a malicious party intentionally sends unlearn requests to deteriorate the model's performance maximally. We show that this phenomenon and the adversary's capabilities depend on many factors, primarily on the backbone model itself and strategy/limitations in selecting data to be unlearned. The main result of this work is a new method of protecting model performance from these side effects, both in the case of unlearned behavior resulting from spontaneous processes and adversary actions.", 'abstract_zh': '探讨对抗性遗忘问题：保护模型性能免受恶意遗忘请求的影响', 'title_zh': '如何保护模型免受对抗性遗忘攻击？'}
{'arxiv_id': 'arXiv:2507.10865', 'title': 'Overview of the TREC 2022 deep learning track', 'authors': 'Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Jimmy Lin, Ellen M. Voorhees, Ian Soboroff', 'link': 'https://arxiv.org/abs/2507.10865', 'abstract': "This is the fourth year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we also leverage both the refreshed passage and document collections that were released last year leading to a nearly $16$ times increase in the size of the passage collection and nearly four times increase in the document collection size. Unlike previous years, in 2022 we mainly focused on constructing a more complete test collection for the passage retrieval task, which has been the primary focus of the track. The document ranking task was kept as a secondary task, where document-level labels were inferred from the passage-level labels. Our analysis shows that similar to previous years, deep neural ranking models that employ large scale pretraining continued to outperform traditional retrieval methods. Due to the focusing our judging resources on passage judging, we are more confident in the quality of this year's queries and judgments, with respect to our ability to distinguish between runs and reuse the dataset in future. We also see some surprises in overall outcomes. Some top-performing runs did not do dense retrieval. Runs that did single-stage dense retrieval were not as competitive this year as they were last year.", 'abstract_zh': 'TREC深度学习赛道的第四年：MS MARCO数据集的应用与测试集合的扩展', 'title_zh': 'TREC 2022 深度学习赛道综述'}
{'arxiv_id': 'arXiv:2507.10864', 'title': 'A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n', 'authors': 'Saadat Behzadi, Danial Sharifrazi, Bita Mesbahzadeh, Javad Hassannataj Joloudarid, Roohallah Alizadehsani', 'link': 'https://arxiv.org/abs/2507.10864', 'abstract': 'Objectives: Timely and accurate detection of colorectal polyps plays a crucial role in diagnosing and preventing colorectal cancer, a major cause of mortality worldwide. This study introduces a new, lightweight, and efficient framework for polyp detection that combines the Local Outlier Factor (LOF) algorithm for filtering noisy data with the YOLO-v11n deep learning model.\nStudy design: An experimental study leveraging deep learning and outlier removal techniques across multiple public datasets.\nMethods: The proposed approach was tested on five diverse and publicly available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene. Since these datasets originally lacked bounding box annotations, we converted their segmentation masks into suitable detection labels. To enhance the robustness and generalizability of our model, we apply 5-fold cross-validation and remove anomalous samples using the LOF method configured with 30 neighbors and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a fast and resource-efficient object detection architecture optimized for real-time applications. We train the model using a combination of modern augmentation strategies to improve detection accuracy under diverse conditions.\nResults: Our approach significantly improves polyp localization performance, achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5 of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods, our model demonstrates enhanced accuracy and efficiency.\nConclusions: These results suggest that the proposed method is well-suited for real-time colonoscopy support in clinical settings. Overall, the study underscores how crucial data preprocessing and model efficiency are when designing effective AI systems for medical imaging.', 'abstract_zh': '目的：及时准确地检测结肠息肉在诊断和预防结肠癌中起着关键作用，结肠癌是全球的主要死因之一。本研究介绍了一种新的轻量级高效息肉检测框架，该框架通过局部异常因子（LOF）算法过滤噪声数据并与YOLO-v11n深度学习模型相结合。\n\n研究设计：利用深度学习和离群值去除技术，在多个公开数据集中进行的实验研究。\n\n方法：所提出的方法在CVC-ColonDB、CVC-ClinicDB、Kvasir-SEG、ETIS和EndoScene这五个多样且公开可得的数据集上进行了测试。由于这些数据集原本缺乏边界框注释，我们将它们的分割掩膜转换为合适的检测标签。为了增强模型的鲁棒性和通用性，我们采用了5折交叉验证，并使用LOF方法（配置为30个邻居和污染比率为5%）移除异常样本。清洗后的数据被输入到YOLO-v11n中，这是一种为实时应用优化的快速且资源高效的物体检测架构。我们通过结合现代数据增强策略来训练模型，以在不同条件下提高检测准确性。\n\n结果：我们的方法显著提高了息肉定位性能，实现了精度95.83%、召回率91.85%、F1分值93.48%、mAP@0.5 96.48%和mAP@0.5:0.95 77.75%。与之前的YOLO基线方法相比，我们的模型显示出更高的准确性和效率。\n\n结论：这些结果表明，所提出的方法适用于临床环境中的实时结肠镜检查支持。总体而言，本研究强调了在设计有效的医疗成像AI系统时，数据预处理和模型效率的重要性。', 'title_zh': '基于LOF预处理和YOLO-v11n的轻量级稳健实时结直肠息肉检测框架'}
{'arxiv_id': 'arXiv:2507.10854', 'title': 'PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark', 'authors': 'Thomas Dalton, Hemanth Gowda, Girish Rao, Sachin Pargi, Alireza Hadj Khodabakhshi, Joseph Rombs, Stephan Jou, Manish Marwah', 'link': 'https://arxiv.org/abs/2507.10854', 'abstract': 'Phishing remains a pervasive and growing threat, inflicting heavy economic and reputational damage. While machine learning has been effective in real-time detection of phishing attacks, progress is hindered by lack of large, high-quality datasets and benchmarks. In addition to poor-quality due to challenges in data collection, existing datasets suffer from leakage and unrealistic base rates, leading to overly optimistic performance results. In this paper, we introduce PhreshPhish, a large-scale, high-quality dataset of phishing websites that addresses these limitations. Compared to existing public datasets, PhreshPhish is substantially larger and provides significantly higher quality, as measured by the estimated rate of invalid or mislabeled data points. Additionally, we propose a comprehensive suite of benchmark datasets specifically designed for realistic model evaluation by minimizing leakage, increasing task difficulty, enhancing dataset diversity, and adjustment of base rates more likely to be seen in the real world. We train and evaluate multiple solution approaches to provide baseline performance on the benchmark sets. We believe the availability of this dataset and benchmarks will enable realistic, standardized model comparison and foster further advances in phishing detection. The datasets and benchmarks are available on Hugging Face (this https URL).', 'abstract_zh': '钓鱼攻击仍然是一种普遍且不断增长的威胁，对经济和声誉造成重大损害。虽然机器学习在实时检测钓鱼攻击方面表现出效，但缺乏大规模、高质量的数据集和基准数据阻碍了进展。现有的数据集因数据收集挑战而导致质量低下，同时还存在数据泄漏和不切实际的基础率问题，导致过度乐观的性能结果。在本文中，我们介绍了PhreshPhish，这是一个大规模、高质量的钓鱼网站数据集，解决了这些限制。与现有的公共数据集相比，PhreshPhish 更大且数据质量更高，通过估计无效或误标数据点的比例来衡量。此外，我们提出了一整套专门设计的基准数据集，用于最小化数据泄漏、增加任务难度、增强数据集多样性，并调整更接近现实世界的基础率。我们对多个解决方案进行了训练和评估，提供了基准集上的基线性能。我们相信，该数据集和基准的可用性将促进钓鱼检测的现实标准化模型比较，并推动进一步的技术进步。数据集和基准可在 Hugging Face 上获取（此链接：this https URL）。', 'title_zh': 'PhreshPhish: 一个真实世界、高质量、大规模的网络钓鱼网站数据集及基准'}
{'arxiv_id': 'arXiv:2507.10846', 'title': 'Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization', 'authors': 'Casey Wall, Longwei Wang, Rodrigue Rizk, KC Santosh', 'link': 'https://arxiv.org/abs/2507.10846', 'abstract': 'Interpreting the decision-making process of Convolutional Neural Networks (CNNs) is critical for deploying models in high-stakes domains. Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method for visual explanations, yet it typically focuses on the final convolutional layer or naïvely averages across layers, strategies that can obscure important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a novel, human-tunable extension of Grad-CAM that generates robust and coherent saliency maps by aggregating information across all convolutional layers. To mitigate the influence of noisy or extreme attribution values, Winsor-CAM applies Winsorization, a percentile-based outlier attenuation technique. A user-controllable threshold allows for semantic-level tuning, enabling flexible exploration of model behavior across representational hierarchies. Evaluations on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable heatmaps and achieves superior performance in localization metrics, including intersection-over-union and center-of-mass alignment, when compared to Grad-CAM and uniform layer-averaging baselines. Winsor-CAM advances the goal of trustworthy AI by offering interpretable, multi-layer insights with human-in-the-loop control.', 'abstract_zh': 'Winsor-CAM: 一种基于Winsor化的人工可控多层解释方法', 'title_zh': 'Winsor-CAM:通过层wise Winsorization的人类可调节视觉解释'}
{'arxiv_id': 'arXiv:2507.10843', 'title': 'Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps', 'authors': 'Motoki Omura, Yusuke Mukuta, Kazuki Ota, Takayuki Osa, Tatsuya Harada', 'link': 'https://arxiv.org/abs/2507.10843', 'abstract': 'Offline reinforcement learning (RL) aims to learn an optimal policy from a static dataset, making it particularly valuable in scenarios where data collection is costly, such as robotics. A major challenge in offline RL is distributional shift, where the learned policy deviates from the dataset distribution, potentially leading to unreliable out-of-distribution actions. To mitigate this issue, regularization techniques have been employed. While many existing methods utilize density ratio-based measures, such as the $f$-divergence, for regularization, we propose an approach that utilizes the Wasserstein distance, which is robust to out-of-distribution data and captures the similarity between actions. Our method employs input-convex neural networks (ICNNs) to model optimal transport maps, enabling the computation of the Wasserstein distance in a discriminator-free manner, thereby avoiding adversarial training and ensuring stable learning. Our approach demonstrates comparable or superior performance to widely used existing methods on the D4RL benchmark dataset. The code is available at this https URL .', 'abstract_zh': '离线强化学习（RL）旨在从静态数据集中学习最优策略，使其在数据收集成本较高的场景下（如机器人领域）尤为重要。离线RL的一个主要挑战是分布偏移，即学习到的策略与数据集分布不一致，可能导致无法泛化的动作。为缓解这一问题，引入了正则化技术。虽然许多现有方法采用基于密度比的度量，如$f$散度进行正则化，我们提出了一种利用Wasserstein距离的方法，Wasserstein距离对异常数据具有鲁棒性，并能够捕捉动作之间的相似性。该方法使用输入凸神经网络（ICNNs）来建模最优传输映射，通过鉴别器-Free的方式计算Wasserstein距离，从而避免 adversarial 训练并确保学习的稳定性。我们的方法在D4RL基准数据集上展示了与现有广泛使用的方法相当或更优的性能。代码可在以下链接获取：this https URL。', 'title_zh': '基于最优传输映射的 Wasserstein 正则化离线强化学习'}
{'arxiv_id': 'arXiv:2507.10827', 'title': 'Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition', 'authors': 'Mengzhe Geng, Patrick Littell, Aidan Pine, PENÁĆ, Marc Tessier, Roland Kuhn', 'link': 'https://arxiv.org/abs/2507.10827', 'abstract': 'The SENĆOTEN language, spoken on the Saanich peninsula of southern Vancouver Island, is in the midst of vigorous language revitalization efforts to turn the tide of language loss as a result of colonial language policies. To support these on-the-ground efforts, the community is turning to digital technology. Automatic Speech Recognition (ASR) technology holds great promise for accelerating language documentation and the creation of educational resources. However, developing ASR systems for SENĆOTEN is challenging due to limited data and significant vocabulary variation from its polysynthetic structure and stress-driven metathesis. To address these challenges, we propose an ASR-driven documentation pipeline that leverages augmented speech data from a text-to-speech (TTS) system and cross-lingual transfer learning with Speech Foundation Models (SFMs). An n-gram language model is also incorporated via shallow fusion or n-best restoring to maximize the use of available data. Experiments on the SENĆOTEN dataset show a word error rate (WER) of 19.34% and a character error rate (CER) of 5.09% on the test set with a 57.02% out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the potential of our ASR-driven pipeline to support SENĆOTEN language documentation.', 'abstract_zh': 'SENĆOTEN语言在南温哥华岛萨尼奇半岛上的 revitalization 努力正处于蓬勃发展的阶段，旨在扭转殖民语言政策导致的语言流失。为支持这些实地努力，该社区转向了数字技术。自动语音识别（ASR）技术有望加速语言记录和教育资源的创建。然而，由于数据有限且由于其多合词结构和音节驱动的转移现象导致的词汇变化显著，为SENĆOTEN开发ASR系统具有挑战性。为应对这些挑战，我们提出了一种基于ASR的语言记录管道，该管道利用文本转语音（TTS）系统扩增的语音数据，并通过语音基础模型（SFMs）进行跨语言迁移学习。还通过浅层融合或n-best恢复结合n-gram语言模型，以充分利用可用数据。在SENĆOTEN数据集上的实验结果显示，在测试集上的词错误率（WER）为19.34%，字符错误率（CER）为5.09%，且在词汇外率（OOV）为57.02%的情况下。过滤掉轻型cédilla相关的错误后，WER提高到14.32%（在未见过的单词上为26.48%），CER降低到3.45%，这表明我们的ASR驱动管道在支持SENĆOTEN语言记录方面的潜力。', 'title_zh': '使用自动语音识别支持SENĆOTEN语言记录工作'}
{'arxiv_id': 'arXiv:2507.10822', 'title': 'Past, Present and Future: Exploring Adaptive AI in Software Development Bots', 'authors': 'Omar Elsisi, Glaucia Melo', 'link': 'https://arxiv.org/abs/2507.10822', 'abstract': 'Conversational agents, such as chatbots and virtual assistants, have become essential in software development, boosting productivity, collaboration, and automating various tasks. This paper examines the role of adaptive AI-powered conversational agents in software development, highlighting their ability to offer dynamic, context-aware assistance to developers. Unlike traditional rule-based systems, adaptive AI agents use machine learning and natural language processing to learn from interactions and improve over time, providing more personalized and responsive help. We look at how these tools have evolved from simple query-based systems to advanced AI-driven solutions like GitHub Copilot and Microsoft Teams bots. We also explore the challenges of integrating adaptive AI into software development processes. The study aims to assess the benefits and limitations of these systems, address concerns like data privacy and ethical issues, and offer insights into their future use in the field. Ultimately, adaptive AI chatbots have great potential to revolutionize software development by delivering real-time, customized support and enhancing the efficiency of development cycles.', 'abstract_zh': '适应性AI驱动的对话代理在软件开发中的角色研究：从简单查询系统到GitHub Copilot和Microsoft Teams机器人的演变及其挑战', 'title_zh': '过去、现在和未来：探索软件开发机器人中的自适应AI'}
{'arxiv_id': 'arXiv:2507.10820', 'title': 'Semantic Context for Tool Orchestration', 'authors': 'Robert Müller', 'link': 'https://arxiv.org/abs/2507.10820', 'abstract': 'This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.', 'abstract_zh': '本文展示了语义上下文（SC），利用描述性工具信息，是稳健工具编排的基础组件。我们的贡献包括三个方面。首先，我们使用上下文臂赛选引入SC-LinUCB，并提供理论基础，证明它能实现更低的遗憾并以动态动作空间中表现出良好的适应性。其次，我们通过大规模语言模型并行实验证明，SC 对于成功进行上下文内学习（在静态情况下实现高效学习和在非平稳情况下实现稳健适应）至关重要。第三，我们提出了FiReAct 管道，并在一个包含超过10,000个工具的基准测试中证明，基于SC 的检索使大语言模型能够有效地在大动作空间中编排。这些发现为构建更高效、适应性强和可扩展的编排代理提供了全面指南。', 'title_zh': '工具编排的语义上下文'}
{'arxiv_id': 'arXiv:2507.10812', 'title': 'React to This (RTT): A Nonverbal Turing Test for Embodied AI', 'authors': 'Chuxuan Zhang, Yasaman Etesam, Angelica Lim', 'link': 'https://arxiv.org/abs/2507.10812', 'abstract': 'We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: "Can machines think?" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: "Can machines react?" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.', 'abstract_zh': '我们提出一种测试具身AI代理在交互意识和可信度方面的方法，特别是在人类将其推至极限的情景中。图灵引入了模仿游戏来探索“机器能思考吗？”这一问题。随后的全面图灵测试将这一概念扩展到不仅仅是言语交流，还包括感知和物理交互。在此基础上，我们提出了一个新的指导问题：“机器能作出反应吗？”并引入了RTT测试来评估非言语行为，展示了一个初步实验的结果。', 'title_zh': '基于身体的AI的非言语图灵测试： React to This (RTT)'}
{'arxiv_id': 'arXiv:2507.10786', 'title': '"Is it always watching? Is it always listening?" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots', 'authors': 'Henry Bell, Jabari Kwesi, Hiba Laabadli, Pardis Emami-Naeini', 'link': 'https://arxiv.org/abs/2507.10786', 'abstract': "Equipped with artificial intelligence (AI) and advanced sensing capabilities, social robots are gaining interest among consumers in the United States. These robots seem like a natural evolution of traditional smart home devices. However, their extensive data collection capabilities, anthropomorphic features, and capacity to interact with their environment make social robots a more significant security and privacy threat. Increased risks include data linkage, unauthorized data sharing, and the physical safety of users and their homes. It is critical to investigate U.S. users' security and privacy needs and concerns to guide the design of social robots while these devices are still in the early stages of commercialization in the U.S. market. Through 19 semi-structured interviews, we identified significant security and privacy concerns, highlighting the need for transparency, usability, and robust privacy controls to support adoption. For educational applications, participants worried most about misinformation, and in medical use cases, they worried about the reliability of these devices. Participants were also concerned with the data inference that social robots could enable. We found that participants expect tangible privacy controls, indicators of data collection, and context-appropriate functionality.", 'abstract_zh': '配备人工智能和先进感应能力的社会机器人在美国消费者中引起了关注。这些机器人似乎是传统智能家居设备的自然进化。然而，它们广泛的数据收集能力、拟人特征以及与环境互动的能力使社会机器人成为更大的安全和隐私威胁。增加的风险包括数据链接、未授权数据共享以及用户和其家庭的身体安全。在这些设备在美国市场商业化初期，亟需调查美国用户的安全和隐私需求与关切，以指导社会机器人的设计。通过19次半结构化访谈，我们确定了显著的安全和隐私关切，强调了透明度、易用性和 robust 的隐私控制以支持采用的重要性。对于教育应用，参与者最担忧的是虚假信息，而在医疗应用场景中，他们担心这些设备的可靠性。参与者还对社会机器人可能导致的数据推论表示担忧。我们发现参与者期望实际的隐私控制、数据收集的指示器以及上下文适当的功能。', 'title_zh': '“一直都在监控吗？一直都在倾听吗？”探究家庭社交机器人面临的上下文隐私与安全问题'}
{'arxiv_id': 'arXiv:2507.10778', 'title': 'Warehouse Spatial Question Answering with LLM Agent', 'authors': 'Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, Kwangju Kim, Chung-I Huang, Jenq-Neng Hwang', 'link': 'https://arxiv.org/abs/2507.10778', 'abstract': "Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: this https URL", 'abstract_zh': '现有的多模态大规模语言模型在空间理解方面存在挑战。先前的方法通过大规模多模态大型语言模型微调来增强其空间理解能力。本文提出了一种数据高效的方法。我们提出了一种具有强大和先进空间推理能力的LLM代理系统，该系统可以用于解决复杂室内仓库场景中的空间问答任务。我们的系统整合了多种工具，使LLM代理能够进行空间推理和API工具交互以回答给定的复杂空间问题。在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛应用表明，我们的系统在物体检索、计数和距离估计等任务中实现了高准确性和高效性。代码available at: this https URL。', 'title_zh': '基于LLM代理的仓库空间问答'}
{'arxiv_id': 'arXiv:2507.10775', 'title': 'A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers', 'authors': 'Jeffrey Joan Sam, Janhavi Sathe, Nikhil Chigali, Naman Gupta, Radhey Ruparel, Yicheng Jiang, Janmajay Singh, James W. Berck, Arko Barman', 'link': 'https://arxiv.org/abs/2507.10775', 'abstract': "Spacecraft deployed in outer space are routinely subjected to various forms of damage due to exposure to hazardous environments. In addition, there are significant risks to the subsequent process of in-space repairs through human extravehicular activity or robotic manipulation, incurring substantial operational costs. Recent developments in image segmentation could enable the development of reliable and cost-effective autonomous inspection systems. While these models often require large amounts of training data to achieve satisfactory results, publicly available annotated spacecraft segmentation data are very scarce. Here, we present a new dataset of nearly 64k annotated spacecraft images that was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds generated using NASA's TTALOS pipeline. To mimic camera distortions and noise in real-world image acquisition, we also added different types of noise and distortion to the images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to generate performance benchmarks for the dataset under well-defined hardware and inference time constraints to mimic real-world image segmentation challenges for real-time onboard applications in space on NASA's inspector spacecraft. The resulting models, when tested under these constraints, achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second. The dataset and models for performance benchmark are available at this https URL.", 'abstract_zh': '在外空间部署的航天器由于暴露在有害环境中，往往会遭受各种形式的损伤。此外，通过宇航员出舱活动或机器人操作进行在轨维修过程存在较高的风险，导致大量运营成本。最近图像分割技术的发展能够促进可靠且低成本的自主检测系统的开发。尽管这些模型通常需要大量训练数据才能达到满意的结果，但公开可用的标注航天器分割数据极为稀缺。在此，我们使用真实航天器模型，并结合NASA TTALOS管道生成的现实和合成背景混合图像，创建了一个近64,000张标注航天器图像的新数据集。为了模拟实际图像获取中的相机失真和噪声，我们还向图像中添加了不同类型的噪声和失真。最后，我们针对特定硬件和推断时间约束对YOLOv8和YOLOv11分割模型进行了微调，以生成该数据集下的性能基准，模拟NASA检查员航天器在太空中实时应用时的实际图像分割挑战。在这些约束条件下进行测试后，所得模型的Dice分数为0.92，Hausdorff距离为0.69，推理时间为约0.5秒。该数据集和用于性能基准的模型可在以下链接获取：this https URL。', 'title_zh': '一种新的数据集及实时空间目标分割性能基准评估方法在机载飞行计算机中应用'}
{'arxiv_id': 'arXiv:2507.10755', 'title': 'Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias', 'authors': 'Rina Khan, Catherine Stinson', 'link': 'https://arxiv.org/abs/2507.10755', 'abstract': 'Facial expression recognition (FER) algorithms classify facial expressions into emotions such as happy, sad, or angry. An evaluative challenge facing FER algorithms is the fall in performance when detecting spontaneous expressions compared to posed expressions. An ethical (and evaluative) challenge facing FER algorithms is that they tend to perform poorly for people of some races and skin colors. These challenges are linked to the data collection practices employed in the creation of FER datasets. In this study, we audit two state-of-the-art FER datasets. We take random samples from each dataset and examine whether images are spontaneous or posed. In doing so, we propose a methodology for identifying spontaneous or posed images. We discover a significant number of images that were posed in the datasets purporting to consist of in-the-wild images. Since performance of FER models vary between spontaneous and posed images, the performance of models trained on these datasets will not represent the true performance if such models were to be deployed in in-the-wild applications. We also observe the skin color of individuals in the samples, and test three models trained on each of the datasets to predict facial expressions of people from various races and skin tones. We find that the FER models audited were more likely to predict people labeled as not white or determined to have dark skin as showing a negative emotion such as anger or sadness even when they were smiling. This bias makes such models prone to perpetuate harm in real life applications.', 'abstract_zh': '面部表情识别（FER）算法将面部表情分类为快乐、悲伤或愤怒等情绪。FER算法面临的评估挑战在于，在检测自发表情时的性能低于检测摆造型表情时的性能。FER算法还面临伦理和评估方面的挑战，即它们往往在某些种族和肤色的人群中表现不佳。这些问题与构建FER数据集时采用的数据采集实践有关。在本研究中，我们审计了两个最先进的FER数据集。我们从每个数据集中随机抽取样本，并检查这些图像是否为自发表情或摆造型表情。在此过程中，我们提出了识别自发或摆造型图像的方法。我们发现，声称包含野外拍摄图像的数据集中存在大量摆造型图像。由于FER模型在自发表情和摆造型表情上的性能不同，如果这些模型用于野外应用，其性能将无法代表真实性能。我们还观察了样本中个体的肤色，并在每个数据集上训练了三种模型，以预测来自不同种族和肤色的人的面部表情。我们发现，审计的FER模型更有可能将被标记为非白人或被确定为深肤色的人预测为显示负面情绪如愤怒或悲伤，即使他们在微笑。这种偏见使这些模型在实际应用中更容易造成危害。', 'title_zh': '审计面部情感识别数据集中的摆拍表情和种族偏见'}
{'arxiv_id': 'arXiv:2507.10741', 'title': 'Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language', 'authors': 'Andrew C. Li, Toryn Q. Klassen, Andrew Wang, Parand A. Alamdari, Sheila A. McIlraith', 'link': 'https://arxiv.org/abs/2507.10741', 'abstract': 'Grounding language in complex perception (e.g. pixels) and action is a key challenge when building situated agents that can interact with humans via language. In past works, this is often solved via manual design of the language grounding or by curating massive datasets relating language to elements of the environment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for grounding formal language from data, and eliciting behaviours by directly tasking RL agents through this language. By virtue of data-driven learning, our framework avoids the manual design of domain-specific elements like reward functions or symbol detectors. By virtue of compositional formal language semantics, our framework achieves data-efficient grounding and generalization to arbitrary language compositions. Experiments on an image-based gridworld and a MuJoCo robotics domain show that our approach reliably maps formal language instructions to behaviours with limited data while end-to-end, data-driven approaches fail.', 'abstract_zh': '将语言嵌入复杂感知（例如像素）和行动中是构建能够通过语言与人类交互的智能体的一个关键挑战。以往的工作常常通过人工设计语言嵌入或构建大量将语言与环境元素关联的数据集来解决这一问题。我们提出了一种神经符号框架——Ground-Compose-Reinforce，用于从数据中进行形式语言的嵌入，并通过这种语言直接对RL智能体进行任务指派以引出其行为。得益于数据驱动的学习，我们的框架避免了人工设计领域特定的元素，如奖励函数或符号检测器。得益于组合理式语言语义，我们的框架实现了数据高效嵌入和对任意语言组合的泛化。在基于图像的格世界和MuJoCo机器人学领域中的实验表明，我们的方法能够在有限的数据下可靠地将形式语言指令映射为行为，而端到端的数据驱动方法则失败了。', 'title_zh': '基于地面-组成-强化：通过形式语言任务化 reinforcement learning 代理'}
{'arxiv_id': 'arXiv:2507.10695', 'title': 'Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health', 'authors': 'Jabari Kwesi, Jiaxun Cao, Riya Manchanda, Pardis Emami-Naeini', 'link': 'https://arxiv.org/abs/2507.10695', 'abstract': 'Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly "rule-based" offerings that do not leverage generative AI. Little empirical research currently measures users\' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of "intangible vulnerability," where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.', 'abstract_zh': '个体日益依赖大型语言模型（LLM）驱动的对话代理寻求情感支持。尽管先前的研究已经探讨了专门设计用于心理健康目的的聊天机器人的隐私和安全问题，但这些聊天机器人大多是基于规则的解决方案，并未利用生成式AI。目前，很少有实证研究测量用户在使用通用型LLM驱动的聊天机器人管理并改善心理健康时的隐私和安全担忧、态度和期望。通过与美国参与者进行21次半结构化访谈，我们识别出了关键的误解和一般的风险意识缺乏问题。参与者将LLMs展现的人类同理心与人类责任感混为一谈，并错误地认为他们与这些聊天机器人的互动受与受过许可训练的心理治疗师相同的法规（如HIPAA）保护。我们提出了“无形脆弱性”的概念，指的是情感或心理披露相比有形信息（如财务或位置数据）被低估。为了解决这一问题，我们提出了建议，以更有效地保护用户在通用型LLM驱动的聊天机器人中的心理健康披露。', 'title_zh': '探索用户在使用通用型大语言模型聊天机器人进行心理健康管理方面的安全和隐私态度与关切'}
{'arxiv_id': 'arXiv:2507.10678', 'title': 'A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks', 'authors': 'Cutter Dawes, Simon Segert, Kamesh Krishnamurthy, Jonathan D. Cohen', 'link': 'https://arxiv.org/abs/2507.10678', 'abstract': 'A major challenge in the use of neural networks both for modeling human cognitive function and for artificial intelligence is the design of systems with the capacity to efficiently learn functions that support radical generalization. At the roots of this is the capacity to discover and implement symmetry functions. In this paper, we investigate a paradigmatic example of radical generalization through the use of symmetry: base addition. We present a group theoretic analysis of base addition, a fundamental and defining characteristic of which is the carry function -- the transfer of the remainder, when a sum exceeds the base modulus, to the next significant place. Our analysis exposes a range of alternative carry functions for a given base, and we introduce quantitative measures to characterize these. We then exploit differences in carry functions to probe the inductive biases of neural networks in symmetry learning, by training neural networks to carry out base addition using different carries, and comparing efficacy and rate of learning as a function of their structure. We find that even simple neural networks can achieve radical generalization with the right input format and carry function, and that learning speed is closely correlated with carry function structure. We then discuss the relevance this has for cognitive science and machine learning.', 'abstract_zh': '神经网络中用于建模人类认知功能和人工智能的重大挑战之一是在高效学习支持深刻泛化的函数方面设计系统的能力。这一挑战的根源在于发现和实现对称函数的能力。本文通过使用对称性探讨了一个深刻的泛化范例：基数进位。我们对基数进位进行了群论分析，其基本特征是进位函数——当和数超过基数模时，将余数转移到下一位显著位置。我们的分析揭示了给定基数下的多种替代进位函数，并引入了量化指标来表征这些函数。然后，我们利用进位函数的差异来探究神经网络在对称学习中的归纳偏见，通过使用不同的进位函数训练神经网络进行基数进位，并比较其效率和学习速率与结构的关系。我们发现，即使简单的神经网络在合适的输入格式和进位函数下也能实现深刻的泛化，且学习速度与进位函数结构密切相关。最后，我们讨论了这一发现对认知科学和机器学习的相关性。', 'title_zh': '基于群论分析的基础进位运算的对称性及其可学会性研究'}
{'arxiv_id': 'arXiv:2507.10646', 'title': 'CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance', 'authors': 'Myeongsoo Kim, Shweta Garg, Baishakhi Ray, Varun Kumar, Anoop Deoras', 'link': 'https://arxiv.org/abs/2507.10646', 'abstract': "Programming assistants powered by large language models have transformed software development, yet most benchmarks focus narrowly on code generation tasks. Recent efforts like InfiBench and StackEval attempt to address this gap using Stack Overflow data but remain limited to single-turn interactions in isolated contexts, require significant manual curation, and fail to represent complete project environments. We introduce CodeAssistBench (CAB), the first benchmark framework for evaluating multi-turn programming assistance in realistic settings that address real-world questions about actual codebases. Unlike existing programming Q&A benchmarks, CAB automatically generates scalable datasets from question-related GitHub issues using configurable parameters (e.g., repository creation date, star count, programming languages), and includes automatic containerization of codebases for evaluation. It then evaluates models through simulated users in these containerized environments with full codebase access. Using this framework, we constructed a test set of 3,286 real-world programming questions across 231 repositories, spanning seven programming languages and diverse problem domains. Our evaluation of leading LLMs reveals a substantial capability gap: while models perform well on Stack Overflow questions with success rates of 70-83%, they resolve only up to 16.49% of CAB's recent issues. This discrepancy highlights the challenges of providing assistance in complex, project-specific contexts versus answering standalone questions.", 'abstract_zh': '由大规模语言模型驱动的编程助手已经革新了软件开发，但大多数基准测试主要集中在代码生成任务上。InfiBench和StackEval等最近的努力尝试利用Stack Overflow数据来解决这一问题，但仍局限于孤立情境中的单轮交互，需要大量人工整理，并未能代表完整的项目环境。我们提出了CodeAssistBench (CAB)，这是第一个用于评估多轮编程辅助的基准框架，可在现实情境中评估关于实际代码库的现实问题。与现有的编程问答基准不同，CAB通过可配置参数（如仓库创建日期、星标数、编程语言）自动生成可扩展的数据集，并包括对代码库进行自动容器化以进行评估。随后，在这些容器化环境中通过模拟用户进行评估，提供完整的代码库访问权限。通过该框架，我们构建了一个包含3,286个实际编程问题的测试集，跨越231个仓库，涉及七种编程语言和多种问题领域。我们的评估结果揭示了领头的语言模型之间存在显著的能力差距：尽管模型在Stack Overflow问题上的成功率在70-83%之间表现良好，但它们仅解决CAB的最近问题的16.49%。这一差异突显了在复杂、项目特定的背景下提供帮助与回答独立问题的挑战。', 'title_zh': 'CodeAssistBench (CAB): 数据集与基于多轮对话的代码辅助基准测试'}
{'arxiv_id': 'arXiv:2507.10643', 'title': 'TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models', 'authors': 'Yuchi Tang, Iñaki Esnaola, Suzanne Mason, George Panoutsos', 'link': 'https://arxiv.org/abs/2507.10643', 'abstract': 'Existing post-hoc model-agnostic methods generate external explanations for opaque models, primarily by locally attributing the model output to its input features. However, they often lack an explicit and systematic framework for quantifying the contribution of individual features. Building on the Taylor expansion framework introduced by Deng et al. (2024) to unify existing local attribution methods, we propose a rigorous set of postulates -- "precision", "federation", and "zero-discrepancy" -- to govern Taylor term-specific attribution. Guided by these postulates, we introduce TaylorPODA (Taylor expansion-derived imPortance-Order aDapted Attribution), which incorporates an additional "adaptation" property. This property enables alignment with task-specific goals, especially in post-hoc settings lacking ground-truth explanations. Empirical evaluations demonstrate that TaylorPODA achieves competitive results against baseline methods, providing principled and visualization-friendly explanations. This work represents a step toward the trustworthy deployment of opaque models by offering explanations with stronger theoretical grounding.', 'abstract_zh': '现有的后验模型无导方法通过局部归因模型输出到输入特征来为不透明模型生成外部解释，但往往缺乏明确且系统的框架来量化单个特征的贡献。基于Deng等（2024）引入的用于统一现有局部归因方法的泰勒展开框架，我们提出了一套严格的公理——“精确性”、“联邦性”和“零偏差”——来管理泰勒项特定的归因。遵循这些公理，我们提出了TaylorPODA（泰勒展开衍生的重要性和适应性归因），并引入了额外的“适应性”性质。该性质使得解释能够与特定任务目标对齐，特别是在缺乏ground-truth解释的后验 scenarios 中。实证评估表明，TaylorPODA 在与基准方法的对比中取得了竞争力的结果，提供了具有更强理论支撑且易于可视化解释。这项工作代表了在增强不透明模型可信赖部署方面迈出的一步，通过提供具有更强理论基础的解释。', 'title_zh': '基于泰勒展开的后验归因改进方法：TaylorPODA'}
{'arxiv_id': 'arXiv:2507.10642', 'title': 'First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network', 'authors': 'Andrew Gascoyne, Wendy Lomas', 'link': 'https://arxiv.org/abs/2507.10642', 'abstract': 'A growing issue within conservation bioacoustics is the task of analysing the vast amount of data generated from the use of passive acoustic monitoring devices. In this paper, we present an alternative AI model which has the potential to help alleviate this problem. Our model formulation addresses the key issues encountered when using current AI models for bioacoustic analysis, namely the: limited training data available; environmental impact, particularly in energy consumption and carbon footprint of training and implementing these models; and associated hardware requirements. The model developed in this work uses associative memory via a transparent, explainable Hopfield neural network to store signals and detect similar signals which can then be used to classify species. Training is rapid ($3$\\,ms), as only one representative signal is required for each target sound within a dataset. The model is fast, taking only $5.4$\\,s to pre-process and classify all $10384$ publicly available bat recordings, on a standard Apple MacBook Air. The model is also lightweight with a small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low computational demands make the model ideal for use on a variety of standard personal devices with potential for deployment in the field via edge-processing devices. It is also competitively accurate, with up to $86\\%$ precision on the dataset used to evaluate the model. In fact, we could not find a single case of disagreement between model and manual identification via expert field guides. Although a dataset of bat echolocation calls was chosen to demo this first-of-its-kind AI model, trained on only two representative calls, the model is not species specific. In conclusion, we propose an equitable AI model that has the potential to be a game changer for fast, lightweight, sustainable, transparent, explainable and accurate bioacoustic analysis.', 'abstract_zh': '生物声学中一个日益突出的问题是如何处理由被动声学监测设备生成的大规模数据。本文提出了一种替代的人工智能模型，旨在缓解这一问题。该模型解决了当前用于生物声学分析的人工智能模型面临的几个关键问题，包括有限的训练数据、环境影响（尤其是训练和实施这些模型的能耗和碳足迹）以及相关的硬件需求。本文开发的模型利用透明可解释的霍普菲尔德神经网络的关联记忆来存储信号并检测相似信号，从而进行物种分类。训练快速（3毫秒），只需要每个目标声音数据集中的一组代表性信号。该模型速度快，仅需5.4秒即可预处理并分类全部10384个公开的蝙蝠录音，运行于标准的苹果MacBook Air上。该模型也具有轻量化特点，内存占用仅为144.09兆字节。因此，低计算需求使得该模型适用于各种标准个人设备，并具有通过边缘处理设备在现场部署的潜力。此外，该模型还具有竞争力的准确度，精度可达86%。实际上，在利用该模型进行评估的数据集中，模型与专家实地指南的手动识别之间没有发现任何分歧。尽管该模型最初用于演示目的的数据集选择了蝙蝠回声定位叫声，并且仅基于两个代表性叫声进行训练，但该模型并非针对特定物种。综上所述，我们提出了一种公平的人工智能模型，该模型有望成为快速、轻量化、可持续、透明和准确的生物声学分析的变革者。', 'title_zh': '首创的基于轻量级关联记忆霍皮菲尔德神经网络的生物声学检测AI模型'}
{'arxiv_id': 'arXiv:2507.10641', 'title': 'A Code Comprehension Benchmark for Large Language Models for Code', 'authors': 'Jayant Havare, Saurav Chaudhary, Ganesh Ramakrishnan, Kaushik Maharajan, Srikanth Tamilselvam', 'link': 'https://arxiv.org/abs/2507.10641', 'abstract': 'Large Language Models have shown impressive capabilities in coding tasks like code generation and code completion, as they have been trained on a large amount of code data. Also, since one of the core pretraining objectives is Next Token Prediction, these models tends to learn surface-level syntactic patterns in code. However, this does not guarantee code comprehension ability i.e. the ability to capture the semantics of the code. In our opinion, this is the reason why these models often underperform on tasks that require deeper semantic understanding, such as code debugging and code optimization. To address this, we propose fine-tuning these models specifically for code comprehension tasks using large-scale datasets, enabling them to develop a more robust understanding of code semantics. We evaluate three code models of varying sizes on a suite of code comprehension tasks designed to assess semantic understanding beyond surface-level syntactic pattern matching. In particular, we analyze performance on the Subjectivity Grading Task and observe that model performance improves after fine-tuning on relevant downstream tasks. The most significant improvement is seen in the QWQ-32B model, where accuracy increases from 70% to 83.47%. A similar or explainable trend is observed across other models, clearly indicating an enhancement in code comprehension ability. Among the models studied, the DPO-fine-tuned Codestral-22B achieves the highest micro-accuracy of 87.66% on the Subjectivity Grading Task.', 'abstract_zh': '大型语言模型在编码任务如代码生成和代码补全方面展示了令人印象深刻的 capability，因为它们是在大量的代码数据上进行训练的。由于其中一个核心预训练目标是下一个 token 预测，这些模型倾向于学习代码的表层句法模式。然而，这并不能保证代码理解能力，即捕获代码语义的能力。依我们之见，这是这些模型在需要深度语义理解的任务（如代码调试和代码优化）中常常表现不佳的原因。为了解决这个问题，我们建议使用大规模数据集对这些模型进行细调，以专门针对代码理解任务，使它们能够更牢固地理解代码语义。我们在一系列设计用于评估超越表层句法模式匹配的语义理解的代码理解任务上评估了三种不同规模的代码模型。特别地，我们分析了主观性评分任务上的表现，并观察到在相关下游任务上进行细调后，模型性能有所提升。QWQ-32B 模型表现尤为显著，准确率从 70% 提高到 83.47%。其他模型中也观察到相似的或可解释的趋势，明确表明代码理解能力有所增强。在研究的模型中，DPO-Fine-tuned Codestral-22B 在主观性评分任务上实现了最高的微准确率 87.66%。', 'title_zh': '大型语言模型理解代码的基准数据集'}
{'arxiv_id': 'arXiv:2507.10639', 'title': 'SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies', 'authors': 'Simon Nau, Jan Krummenauer, André Zimmermann', 'link': 'https://arxiv.org/abs/2507.10639', 'abstract': 'State-of-the-art large language models (LLMs) show high performance across a wide range of tasks in many domains of science. In the field of electronic design automation (EDA), it is yet to be determined to what extent they are capable to understand, adapt, and dimension electronic circuits. This paper focuses on the application of LLMs to switched-mode power supply (SMPS) design on printed circuit boards (PCBs). Particular challenges for LLMs in this context include their limited ability to interpret results from key simulation tools like SPICE and the multi-step design process. To address these challenges, we suggest SPICEAssistant, a framework that provides a broad selection of tools to an LLM. The tools serve as an interface to SPICE, allowing the LLM to interact flexibly with the simulator to estimate the impact of its modifications to the circuit. To evaluate the performance of SPICEAssistant, we defined a benchmark consisting of 256 questions testing the ability to adapt circuit netlists to fulfil different SMPS design tasks. The benchmarking results show that simulation feedback effectively improves SMPS design capabilities of LLMs. An increasing number of simulation iterations leads to enhanced performance. The SPICEAssistant framework significantly outperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.', 'abstract_zh': '最先进的大型语言模型（LLMs）在科学多个领域的广泛任务中表现出高度性能。在电子设计自动化（EDA）领域，尚未明确LLMs在理解、适应和优化电子电路方面的能力。本文专注于将LLMs应用于印制电路板（PCBs）上的开关模式电源（SMPS）设计。在这一背景下，LLMs面临的特定挑战包括其解释关键仿真工具（如SPICE）结果的能力有限，以及多步骤的设计过程。为解决这些问题，我们建议采用SPICEAssistant框架，该框架为LLMs提供了一系列工具，作为与SPICE交互的接口，使LLMs能够灵活地与仿真器互动以评估其对电路修改的影响。为了评估SPICEAssistant的性能，我们定义了一个基准测试，其中包括256个问题，测试LLMs调整电路网表以完成不同SMPS设计任务的能力。基准测试结果表明，仿真反馈有效提升了LLMs的SMPS设计能力。逐步增加的仿真迭代次数提高了性能。SPICEAssistant框架在基准测试中显著优于独立的LLM GPT-4o，约38%。', 'title_zh': 'SPICEAssistant：使用SPICE仿真工具进行开关模式电源电路设计的大型语言模型'}
{'arxiv_id': 'arXiv:2507.10637', 'title': 'A Simple Baseline for Stable and Plastic Neural Networks', 'authors': 'É. Künzel, A. Jaziri, V. Ramesh', 'link': 'https://arxiv.org/abs/2507.10637', 'abstract': 'Continual learning in computer vision requires that models adapt to a continuous stream of tasks without forgetting prior knowledge, yet existing approaches often tip the balance heavily toward either plasticity or stability. We introduce RDBP, a simple, low-overhead baseline that unites two complementary mechanisms: ReLUDown, a lightweight activation modification that preserves feature sensitivity while preventing neuron dormancy, and Decreasing Backpropagation, a biologically inspired gradient-scheduling scheme that progressively shields early layers from catastrophic updates. Evaluated on the Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and stability of state-of-the-art methods while reducing computational cost. RDBP thus provides both a practical solution for real-world continual learning and a clear benchmark against which future continual learning strategies can be measured.', 'abstract_zh': '计算机视觉中的持续学习要求模型能够适应连续的任务流并保留先前的知识，但现有方法往往在塑性和稳定性之间偏向一方。我们提出了RDBP，一种简单且低开销的基线方法，结合了两种互补机制：ReLUDown，一种轻量级的激活修改，保留特征敏感性同时防止神经元休眠，以及递减反向传播，一种受生物启发的梯度调度方案，逐步屏蔽早期层免遭灾难性更新。在持续ImageNet基准上评估，RDBP在塑性和稳定性方面与最先进的方法相当或超越，同时降低了计算成本。因此，RDBP不仅提供了一种实用的现实世界持续学习解决方案，还提供了一个明确的基准，未来持续学习策略可据此进行衡量。', 'title_zh': '稳定且可塑的神经网络的一个简单基线'}
{'arxiv_id': 'arXiv:2507.10636', 'title': 'GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem', 'authors': 'Jianing Zhi, Xinghua Li, Zidong Chen', 'link': 'https://arxiv.org/abs/2507.10636', 'abstract': 'The rapid development of urban low-altitude unmanned aerial vehicle (UAV) economy poses new challenges for dynamic site selection of UAV landing points and supply stations. Traditional deep reinforcement learning methods face computational complexity bottlenecks, particularly with standard attention mechanisms, when handling large-scale urban-level location problems. This paper proposes GeoHopNet, a Hopfield-augmented sparse spatial attention network specifically designed for dynamic UAV site location problems. Our approach introduces four core innovations: (1) distance-biased multi-head attention mechanism that explicitly encodes spatial geometric information; (2) K-nearest neighbor sparse attention that reduces computational complexity from $O(N^2)$ to $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory regularization strategy. Experimental results demonstrate that GeoHopNet extends the boundary of solvable problem sizes. For large-scale instances with 1,000 nodes, where standard attention models become prohibitively slow (over 3 seconds per instance) and traditional solvers fail, GeoHopNet finds high-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared to the state-of-the-art ADNet baseline on 100-node instances, our method improves solution quality by 22.2\\% and is 1.8$\\times$ faster.', 'abstract_zh': 'GeoHopNet：一种用于动态无人机着陆点和供给站选址问题的霍普菲尔德增强稀疏空间注意力网络', 'title_zh': 'GeoHopNet：Hopfield强化稀疏空间注意力机制在动态无人机站点定位问题中的应用'}
{'arxiv_id': 'arXiv:2507.10632', 'title': 'Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process', 'authors': 'Issei Saito, Masatoshi Nagano, Tomoaki Nakamura, Daichi Mochihashi, Koki Mimura', 'link': 'https://arxiv.org/abs/2507.10632', 'abstract': 'In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series segmentation method that incorporates random Fourier features (RFF) to address the high computational cost of the Gaussian process hidden semi-Markov model (GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring inversion of an N times N kernel matrix during training, where N is the number of data points. As the scale of the data increases, matrix inversion incurs a significant computational cost. To address this, the proposed method approximates the Gaussian process with linear regression using RFF, preserving expressive power while eliminating the need for inversion of the kernel matrix. Experiments on the Carnegie Mellon University (CMU) motion-capture dataset demonstrate that the proposed method achieves segmentation performance comparable to that of conventional methods, with approximately 278 times faster segmentation on time-series data comprising 39,200 frames.', 'abstract_zh': '本研究提出了一种快速无监督时间序列分割方法RFF-GP-HSMM，该方法通过引入随机傅里叶特征（RFF）来解决高斯过程隐半马尔可夫模型（GP-HSMM）的高计算成本问题。', 'title_zh': '基于随机傅里叶特征的高斯过程的可扩展无监督分割'}
{'arxiv_id': 'arXiv:2507.10629', 'title': 'SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition', 'authors': 'Song Cheng, Qiannan Cheng, Linbo Jin, Lei Yi, Guannan Zhang', 'link': 'https://arxiv.org/abs/2507.10629', 'abstract': "Transforming natural language into SQL queries (NL2SQL) is crucial for data-driven business applications. Existing frameworks, trained on open-source datasets, struggle with complex business logic and lack domain-specific data for fine-tuning. Additionally, evaluation methods often require annotated data and executable database environments, which are scarce in real-world scenarios. To address these challenges, we propose SQLord, an enterprise-level NL2SQL framework. First, SQLord introduces a data reverse generation approach to convert raw SQL statements into annotated data for supervised fine-tuning (SFT). Second, it proposes a decomposition method for complex queries using an automated workflow generator. Additionally, SQLord features a comprehensive GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios. Offline tests significantly outperform state of the art baselines, and online accuracy consistently exceeds 90, highlighting SQLord's advantages and effectiveness in complex real world scenarios. SQLord has been successfully applied across multiple scenarios on the world's largest B2B e-commerce platform.", 'abstract_zh': '将自然语言转换为SQL查询（NL2SQL）对于数据驱动的企业应用至关重要。现有的框架在开源数据集上训练，难以处理复杂的业务逻辑，并缺乏领域特定的数据进行微调。此外，评估方法通常需要标注数据和可执行的数据库环境，而在实际场景中这些资源稀缺。为解决这些问题，我们提出了SQLord，一个面向企业的NL2SQL框架。首先，SQLord引入了数据逆向生成方法，将原始SQL语句转换为标注数据以进行监督微调（SFT）。其次，它提出了复杂查询的分解方法，并使用自动化工作流生成器。此外，SQLord还具备全面的GPT-Judge评估框架，包括执行评估（EXE）、查询-SQL评估（QSE）和SQL-SQL评估（SSE），以适应不同的场景。离线测试显著优于最新的基线方法，在线准确率始终超过90%，突显了SQLord在复杂实际场景中的优势和有效性。SQLord已在世界上最大的B2B电子商务平台上成功应用于多个场景。', 'title_zh': 'SQLord：一种基于逆向数据生成和工作流分解的企业级文本到SQL解决方案'}
{'arxiv_id': 'arXiv:2507.10628', 'title': 'GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning', 'authors': 'Ziru Liu, Cheng Gong, Xinyu Fu, Yaofang Liu, Ran Chen, Shoubo Hu, Suiyun Zhang, Rui Liu, Qingfu Zhang, Dandan Tu', 'link': 'https://arxiv.org/abs/2507.10628', 'abstract': "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. This challenge is particularly acute for smaller, more resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework. GHPO dynamically calibrates task difficulty by employing adaptive prompt refinement to provide targeted guidance. This unique approach adaptively balances direct imitation learning for problems currently beyond the model's reach with exploration-based reinforcement learning for more manageable tasks, effectively creating a smooth and optimized learning curriculum. Extensive experiments demonstrate that GHPO achieves an average performance gain of approximately 5% across six challenging mathematics benchmarks, consistently outperforming strong on-policy reinforcement learning and curriculum learning baselines. Further analysis confirms that our framework significantly enhances both training stability and final reasoning performance, thus offering a scalable and efficient solution for developing powerful and robust reasoning models.", 'abstract_zh': "可验证奖励增强学习（RLVR） recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework.", 'title_zh': 'GHPO: 自适应指导以实现稳定高效的LLM强化学习'}
{'arxiv_id': 'arXiv:2507.10626', 'title': 'Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction', 'authors': 'Lintao Wang, Shiwen Xu, Michael Horton, Joachim Gudmundsson, Zhiyong Wang', 'link': 'https://arxiv.org/abs/2507.10626', 'abstract': 'Predicting soccer match outcomes is a challenging task due to the inherently unpredictable nature of the game and the numerous dynamic factors influencing results. While it conventionally relies on meticulous feature engineering, deep learning techniques have recently shown a great promise in learning effective player and team representations directly for soccer outcome prediction. However, existing methods often overlook the heterogeneous nature of interactions among players and teams, which is crucial for accurately modeling match dynamics. To address this gap, we propose HIGFormer (Heterogeneous Interaction Graph Transformer), a novel graph-augmented transformer-based deep learning model for soccer outcome prediction. HIGFormer introduces a multi-level interaction framework that captures both fine-grained player dynamics and high-level team interactions. Specifically, it comprises (1) a Player Interaction Network, which encodes player performance through heterogeneous interaction graphs, combining local graph convolutions with a global graph-augmented transformer; (2) a Team Interaction Network, which constructs interaction graphs from a team-to-team perspective to model historical match relationships; and (3) a Match Comparison Transformer, which jointly analyzes both team and player-level information to predict match outcomes. Extensive experiments on the WyScout Open Access Dataset, a large-scale real-world soccer dataset, demonstrate that HIGFormer significantly outperforms existing methods in prediction accuracy. Furthermore, we provide valuable insights into leveraging our model for player performance evaluation, offering a new perspective on talent scouting and team strategy analysis.', 'abstract_zh': '基于异质交互图变换器的足球比赛结果预测', 'title_zh': '基于球员-团队异质交互图变换器的足球比赛结果预测'}
{'arxiv_id': 'arXiv:2507.10622', 'title': 'Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs', 'authors': 'HyeYoung Lee, Muhammad Nadeem, Pavel Tsoi', 'link': 'https://arxiv.org/abs/2507.10622', 'abstract': 'The rapid expansion of Internet of Things (IoT) networks has led to a surge in security vulnerabilities, emphasizing the critical need for robust anomaly detection and classification techniques. In this work, we propose a novel approach for identifying anomalies in IoT network traffic by leveraging the Mel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model known for its effectiveness in feature extraction and image-based tasks. Learnable MFCCs enable adaptive spectral feature representation, capturing the temporal patterns inherent in network traffic more effectively than traditional fixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the data into a higher-dimensional space, enhancing class separability and enabling more effective multiclass classification. Our approach combines the strengths of MFCCs with the robust feature extraction capabilities of ResNet-18, offering a powerful framework for anomaly detection. The proposed model is evaluated on three widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and IoTID20. The experimental results highlight the potential of integrating adaptive signal processing techniques with deep learning architectures to achieve robust and scalable anomaly detection in heterogeneous IoT network landscapes.', 'abstract_zh': '物联网网络的迅速扩展引发了安全漏洞的激增，强调了需要强大的异常检测和分类技术的重要性。在此项工作中，我们提出了一种通过利用梅尔频率倒谱系数（MFCC）和ResNet-18（一种在特征提取和图像任务中 effectiveness 优异的深度学习模型）来识别物联网网络流量中异常的新方法。可学习的MFCC能够实现自适应频谱特征表示，相比传统的固定MFCC更能有效捕捉网络流量中的时序模式。我们证明，将原始信号转换为MFCC能够将数据映射到更高维度的空间，增强类间的可分性，并使多类分类更加有效。该方法结合了MFCC的优势与ResNet-18强大的特征提取能力，提供了一种强大的异常检测框架。所提出的模型在CICIoT2023、NSL-KDD和IoTID20三个广泛使用的物联网入侵检测数据集上进行了评估。实验结果表明，将自适应信号处理技术与深度学习架构相结合，能够在异构的物联网网络环境中实现稳健且可扩展的异常检测。', 'title_zh': '基于MFCC的谱特征提取在鲁棒网络入侵检测中的应用'}
{'arxiv_id': 'arXiv:2507.10621', 'title': 'Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats', 'authors': 'Quanyan Zhu', 'link': 'https://arxiv.org/abs/2507.10621', 'abstract': 'Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation.\nThe rise of Large Language Models (LLMs) and agentic AI offers a new path to bridge this gap. LLM-powered agents can operationalize abstract strategies into real-world decisions. Conversely, game theory can inform the reasoning and coordination of these agents across complex workflows. LLMs also challenge classical game-theoretic assumptions, such as perfect rationality or static payoffs, prompting new models aligned with cognitive and computational realities. This co-evolution promises richer theoretical foundations and novel solution concepts. Agentic AI also reshapes software design: systems must now be modular, adaptive, and trust-aware from the outset.\nThis chapter explores the intersection of game theory, agentic AI, and cybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic, Bayesian, and signaling games) and solution concepts. We then examine how LLM agents can enhance cyber defense and introduce LLM-driven games that embed reasoning into AI agents. Finally, we explore multi-agent workflows and coordination games, outlining how this convergence fosters secure, intelligent, and adaptive cyber systems.', 'abstract_zh': '游戏理论、自主AI与网络安全的交集', 'title_zh': '博弈论邂逅大语言模型与自主AI：重塑智能威胁时代的网络安全'}
{'arxiv_id': 'arXiv:2507.10620', 'title': 'LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions', 'authors': 'Chenxi Liu, Hao Miao, Cheng Long, Yan Zhao, Ziyue Li, Panos Kalnis', 'link': 'https://arxiv.org/abs/2507.10620', 'abstract': 'Large Language Models (LLMs) have emerged as a promising paradigm for time series analytics, leveraging their massive parameters and the shared sequential nature of textual and time series data. However, a cross-modality gap exists between time series and textual data, as LLMs are pre-trained on textual corpora and are not inherently optimized for time series. In this tutorial, we provide an up-to-date overview of LLM-based cross-modal time series analytics. We introduce a taxonomy that classifies existing approaches into three groups based on cross-modal modeling strategies, e.g., conversion, alignment, and fusion, and then discuss their applications across a range of downstream tasks. In addition, we summarize several open challenges. This tutorial aims to expand the practical application of LLMs in solving real-world problems in cross-modal time series analytics while balancing effectiveness and efficiency. Participants will gain a thorough understanding of current advancements, methodologies, and future research directions in cross-modal time series analytics.', 'abstract_zh': '大型语言模型（LLMs）已在时间序列分析领域展现出 promising 的范式，通过利用其庞大的参数和文本数据与时间序列数据共享的序列特性。然而，时间序列数据与文本数据之间存在跨模态差距，因为LLMs是在文本语料库上进行预训练的，并未固有地优化时间序列分析。在本教程中，我们将提供基于LLM的时间序列跨模态分析的最新综述。我们介绍了基于跨模态建模策略的分类体系，将其划分为转换、对齐和融合三种类别，并讨论了它们在一系列下游任务中的应用。此外，我们总结了几项-open-challenges。本教程旨在平衡效用与效率，扩大LLMs在解决跨模态时间序列分析中实际问题的应用范围。参与者将深入了解跨模态时间序列分析的最新进展、方法论及未来研究方向。', 'title_zh': 'LLMs融入跨模态时间序列分析：概览与发展方向'}
{'arxiv_id': 'arXiv:2507.10619', 'title': 'Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks', 'authors': 'Oluwaseyi Giwa, Tobi Awodunmila, Muhammad Ahmed Mohsin, Ahsan Bilal, Muhammad Ali Jamshed', 'link': 'https://arxiv.org/abs/2507.10619', 'abstract': 'The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety risks associated with unguided exploration, which can cause severe network interference. To address these challenges, we propose a meta-learning framework that enables agents to learn a robust initial policy and rapidly adapt to new wireless scenarios with minimal data. We implement three meta-learning architectures, model-agnostic meta-learning (MAML), recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate them against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a clear performance gap. The attention-based meta-learning agent reaches a peak mean network throughput of 48 Mbps, while the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method reduces SINR and latency violations by more than 50% compared to PPO. It also shows quick adaptation, with a fairness index 0.7, showing better resource allocation. This work proves that meta-learning is a very effective and safer option for intelligent control in complex wireless systems.', 'abstract_zh': '5G/6G网络中基于元学习的频谱动态分配：一种高效安全的资源管理方法', 'title_zh': '元强化学习在动态无线网络中快速高效频谱分配中的应用'}
{'arxiv_id': 'arXiv:2507.10618', 'title': 'Compute Requirements for Algorithmic Innovation in Frontier AI Models', 'authors': 'Peter Barnett', 'link': 'https://arxiv.org/abs/2507.10618', 'abstract': 'Algorithmic innovation in the pretraining of large language models has driven a massive reduction in the total compute required to reach a given level of capability. In this paper we empirically investigate the compute requirements for developing algorithmic innovations. We catalog 36 pre-training algorithmic innovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate both the total FLOP used in development and the FLOP/s of the hardware utilized. Innovations using significant resources double in their requirements each year. We then use this dataset to investigate the effect of compute caps on innovation. Our analysis suggests that compute caps alone are unlikely to dramatically slow AI algorithmic progress. Even stringent compute caps -- such as capping total operations to the compute used to train GPT-2 or capping hardware capacity to 8 H100 GPUs -- could still have allowed for half of the cataloged innovations.', 'abstract_zh': '算法创新在大型语言模型的预训练中的进步推动了达到特定能力所需总计算量的大幅减少。本文通过实证研究探索算法创新所需的计算需求。我们列出了在Llama 3和DeepSeek-V3中使用的36项预训练算法创新，并为每项创新估算了开发过程中使用的总FLOP以及所用硬件的FLOP/s。使用大量资源的创新每年其需求翻倍。我们利用此数据集研究计算限制对创新的影响。我们的分析表明，仅靠计算限制不大可能显著减慢AI算法的进步。即使是非常严格的计算限制——如将总操作量限制为训练GPT-2所用的计算量或将硬件容量限制为8个H100 GPU——也可能仍允许实现所列创新的一半。', 'title_zh': '算法创新在前沿AI模型中的计算需求'}
{'arxiv_id': 'arXiv:2507.10616', 'title': 'Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them', 'authors': 'Neel Rajani, Aryo Pradipta Gema, Seraphina Goldfarb-Tarrant, Ivan Titov', 'link': 'https://arxiv.org/abs/2507.10616', 'abstract': 'Training large language models (LLMs) for reasoning via maths and code datasets has become a major new focus in LLM post-training. Two particularly popular approaches are reinforcement learning (RL) and supervised fine-tuning (SFT), but their training dynamics are poorly understood. We present a comparative analysis of RL and SFT on the same maths problems with the same model and similar hyperparameters. We find that RL yields minor in-domain gains on maths and slight degradation on knowledge-intensive benchmarks like MMLU, while both trends are more pronounced in SFT. We also analyse model parameters across checkpoints, observing that both algorithms modify query and key weights the most. Meanwhile, SFT exhibits greater updates and also affects mid-layer MLPs more, leading us to hypothesise that this may have caused the out-of-domain degradation. We therefore investigate whether freezing parts of the model during training can mitigate the reduced performance on knowledge-intensive benchmarks. However, our results are inconclusive, with benefits on GPQA:Diamond and degradation on other benchmarks. Taken together, our observations provide a preliminary indication for why RL amplifies existing capabilities, while SFT replaces old skills with new ones.', 'abstract_zh': '通过数学和代码数据集进行逻辑推理训练的大语言模型（LLMs）已成为LLM后训练中的一个主要新重点。强化学习（RL）和监督微调（SFT）是两种特别流行的方法，但它们的训练动态尚不完全理解。我们对同一数学问题、同一模型和相似超参数条件下，RL和SFT进行了比较分析。我们发现，RL在数学领域内仅带来轻微提升，但在知识密集型基准测试如MMLU上表现出轻微下降；而这种趋势在SFT中更为明显。我们还分析了检查点中的模型参数，观察到两种算法中最常修改的是查询和键权重。同时，SFT表现出更大的更新，并且更多地影响中间层的MLP，使我们假设这可能是导致领域外下降的原因。因此，我们探究在训练过程中冻结部分模型是否能缓解在知识密集型基准测试中的性能下降。然而，我们的结果不够明确，对GPQA:Diamond有利，但在其他基准测试中表现出下降。综合我们的观察，这为解释为什么RL放大现有能力、而SFT用新技能取代旧技能提供了初步线索。', 'title_zh': '刀片 vs. 卤头：GRPO 强化现有能力，SFT 取而代之'}
{'arxiv_id': 'arXiv:2507.10614', 'title': 'Fine-tuning Large Language Model for Automated Algorithm Design', 'authors': 'Fei Liu, Rui Zhang, Xi Lin, Zhichao Lu, Qingfu Zhang', 'link': 'https://arxiv.org/abs/2507.10614', 'abstract': 'The integration of large language models (LLMs) into automated algorithm design has shown promising potential. A prevalent approach embeds LLMs within search routines to iteratively generate and refine candidate algorithms. However, most existing methods rely on off-the-shelf LLMs trained for general coding tasks,leaving a key question open: Do we need LLMs specifically tailored for algorithm design? If so, how can such LLMs be effectively obtained and how well can they generalize across different algorithm design tasks? In this paper, we take a first step toward answering these questions by exploring fine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank based (DAR) sampling strategy to balance training data diversity and quality, then we leverage direct preference optimization to efficiently align LLM outputs with task objectives. Our experiments, conducted on Llama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm design tasks. Results suggest that finetuned LLMs can significantly outperform their off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and match the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover, we observe promising generalization: LLMs finetuned on specific algorithm design tasks also improve performance on related tasks with varying settings. These findings highlight the value of task-specific adaptation for LLMs in algorithm design and open new avenues for future research.', 'abstract_zh': '大型语言模型在自动化算法设计中的整合展示了潜在的应用前景。一种常见的方法是将大型语言模型嵌入搜索过程中，以迭代地生成和优化候选算法。然而，现有方法大多依赖于通用编码任务训练的标准大型语言模型，这留下了一个关键问题：是否需要专门针对算法设计的大型语言模型？如果是的话，如何有效获取这样的大型语言模型，以及它们在不同算法设计任务上的泛化能力如何？在本文中，我们通过探索针对算法设计的大型语言模型微调，迈出了解答这些问题的第一步。我们引入了一种旨在平衡训练数据多样性和质量的多样性感知排名（DAR）采样策略，然后利用直接偏好优化对大型语言模型的输出进行高效调整，使其与任务目标相匹配。实验在Llama-3.2-1B-Instruct和Llama-3.1-8B-Instruct上进行，涵盖三个不同的算法设计任务。结果表明，微调后的大型语言模型可以显著优于标准大型语言模型，尤其是在可接受集合问题上，小型的Llama-3.2-1B-Instruct的表现甚至可以匹纯洁大型的Llama-3.1-8B-Instruct。此外，我们观察到泛化能力：专门针对特定算法设计任务进行微调的大型语言模型，也可以在设置不同的相关任务中提高性能。这些发现突显了针对算法设计任务对大型语言模型进行任务特定适应的价值，并为未来的研究开辟了新的方向。', 'title_zh': '大规模语言模型的微调以实现自动化算法设计'}
{'arxiv_id': 'arXiv:2507.10613', 'title': 'Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs', 'authors': 'Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang', 'link': 'https://arxiv.org/abs/2507.10613', 'abstract': 'Traditional scaling laws in natural language processing suggest that increasing model size and training data enhances performance. However, recent studies reveal deviations, particularly in large language models, where performance improvements decelerate, which is a phenomenon known as sub-scaling. This paper revisits these scaling laws by examining the impact of data quality and training strategies on model performance. Through extensive empirical analysis of over 400 models, we identify high data density and non-optimal resource allocation as key factors contributing to sub-scaling. High data density leads to diminishing returns due to redundant information, while optimal resource allocation is crucial for sustained performance improvements. We propose a sub-optimal scaling law that better predicts performance in sub-scaling regimes, highlighting the importance of data quality and diversity.', 'abstract_zh': '传统自然语言处理中的缩放定律表明，增加模型规模和训练数据可以提升性能。然而，近期的研究揭示了偏差，特别是在大型语言模型中，性能提升趋于减缓，这一现象被称为亚缩放。本文通过研究数据质量和训练策略对模型性能的影响，重新审视这些缩放定律。通过对超过400个模型的广泛实证分析，我们发现高数据密度和非最优资源配置是导致亚缩放的关键因素。高数据密度导致因冗余信息而产生边际效益递减，而最优资源配置对于持续性能提升至关重要。我们提出了一种亚最优缩放定律，更好地预测亚缩放区域的性能，强调了数据质量和多样性的重要性。', 'title_zh': '亚线性律：数据密度和训练策略在大规模语言模型中的作用'}
{'arxiv_id': 'arXiv:2507.10611', 'title': 'FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise', 'authors': 'Mengwen Ye, Yingzi Huangfu, Shujian Gao, Wei Ren, Weifan Liu, Zekuan Yu', 'link': 'https://arxiv.org/abs/2507.10611', 'abstract': 'Federated Learning (FL) emerged as a solution for collaborative medical image classification while preserving data privacy. However, label noise, which arises from inter-institutional data variability, can cause training instability and degrade model performance. Existing FL methods struggle with noise heterogeneity and the imbalance in medical data. Motivated by these challenges, we propose FedGSCA, a novel framework for enhancing robustness in noisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates noise knowledge from all clients, effectively addressing noise heterogeneity and improving global model stability. Furthermore, we develop a Client Adaptive Adjustment (CAA) mechanism that combines adaptive threshold pseudo-label generation and Robust Credal Labeling Loss. CAA dynamically adjusts to class distributions, ensuring the inclusion of minority samples and carefully managing noisy labels by considering multiple plausible labels. This dual approach mitigates the impact of noisy data and prevents overfitting during local training, which improves the generalizability of the model. We evaluate FedGSCA on one real-world colon slides dataset and two synthetic medical datasets under various noise conditions, including symmetric, asymmetric, extreme, and heterogeneous types. The results show that FedGSCA outperforms the state-of-the-art methods, excelling in extreme and heterogeneous noise scenarios. Moreover, FedGSCA demonstrates significant advantages in improving model stability and handling complex noise, making it well-suited for real-world medical federated learning scenarios.', 'abstract_zh': '联邦学习（FL）作为一种在保护数据隐私的同时进行协作医学图像分类的解决方案而出现。然而，由机构间数据变异引起的标签噪声会导致训练不稳定并降低模型性能。现有的FL方法难以应对噪声异质性和医学数据的不平衡。为应对这些挑战，我们提出了一种增强鲁棒性的新型框架FedGSCA，用于嘈杂的医学联邦学习。FedGSCA引入了全局样本选择器，该选择器从所有客户端聚合噪声知识，有效解决了噪声异质性并提高了全局模型稳定性。此外，我们开发了一种客户端自适应调整（CAA）机制，该机制结合了自适应阈值伪标签生成和鲁棒区间标签损失。CAA机制动态适应类别分布，确保少数样本的包含，并通过考虑多个可能标签仔细管理噪声标签。这种双重方法减轻了嘈杂数据的影响，并防止了本地训练中的过拟合，从而提高了模型的泛化能力。我们在一个真实的结肠切片数据集和两个合成的医学数据集上对FedGSCA进行了评估，涵盖对称、不对称、极端和异质性等多种噪声条件。实验结果表明，FedGSCA在极端和异质噪声场景中超越了最先进的方法。此外，FedGSCA在提高模型稳定性和处理复杂噪声方面表现出显著优势，使其非常适合实际的医学联邦学习场景。', 'title_zh': 'FedGSCA: 面向标签噪声的医疗联邦学习方法，包含全局样本选择器和客户端自适应调整器'}
{'arxiv_id': 'arXiv:2507.10610', 'title': 'LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents', 'authors': 'Zihe Yan, Zhuosheng Zhang', 'link': 'https://arxiv.org/abs/2507.10610', 'abstract': 'Graphical user interface (GUI) agents built on multimodal large language models (MLLMs) have recently demonstrated strong decision-making abilities in screen-based interaction tasks. However, they remain highly vulnerable to pop-up-based environmental injection attacks, where malicious visual elements divert model attention and lead to unsafe or incorrect actions. Existing defense methods either require costly retraining or perform poorly under inductive interference. In this work, we systematically study how such attacks alter the attention behavior of GUI agents and uncover a layer-wise attention divergence pattern between correct and incorrect outputs. Based on this insight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that selectively amplifies attention and MLP modules in critical layers. LaSM improves the alignment between model saliency and task-relevant regions without additional training. Extensive experiments across 12 types of pop-up perturbations and 4 different model backbones show that LaSM consistently enhances the defense success rate. When combined with prompt-level alerts, LaSM achieves over 98\\% robustness even under strong inductive attacks. Our findings reveal that attention misalignment is a core vulnerability in MLLM agents and can be effectively addressed through selective layer-wise modulation.', 'abstract_zh': '基于多模态大型语言模型的图形用户界面（GUI）代理在屏幕交互任务中展示了强大的决策能力，但仍然高度易受基于弹出窗口的环境注入攻击的影响，这些恶意视觉元素会转移模型的注意力并导致不安全或错误的操作。现有防护方法要么需要昂贵的重新训练，要么在归纳干扰下表现不佳。在本工作中，我们系统地研究了此类攻击如何改变GUI代理的注意力行为，并发现正确和错误输出之间存在逐层注意力偏差模式。基于这一洞察，我们提出了一种名为LaSM的逐层放大机制，该机制选择性地放大关键层中的注意力和MLP模块。LaSM在无需额外训练的情况下提高了模型显著性和任务相关区域之间的对齐程度。我们在包括12种不同类型弹出窗口扰动和4种不同模型架构的广泛实验中显示，LaSM始终提高了防护成功率。结合提示级别警报时，LaSM即使在强归纳攻击下也能实现超过98%的鲁棒性。我们的研究发现，注意力偏差是多模态大型语言模型代理的核心脆弱性，并可以通过选择性的逐层调节有效解决。', 'title_zh': 'LaSM：面向GUI代理弹窗攻击的层级缩放机制'}
{'arxiv_id': 'arXiv:2507.10607', 'title': 'Neural Expectation Operators', 'authors': 'Qian Qi', 'link': 'https://arxiv.org/abs/2507.10607', 'abstract': 'This paper introduces \\textbf{Measure Learning}, a paradigm for modeling ambiguity via non-linear expectations. We define Neural Expectation Operators as solutions to Backward Stochastic Differential Equations (BSDEs) whose drivers are parameterized by neural networks. The main mathematical contribution is a rigorous well-posedness theorem for BSDEs whose drivers satisfy a local Lipschitz condition in the state variable $y$ and quadratic growth in its martingale component $z$. This result circumvents the classical global Lipschitz assumption, is applicable to common neural network architectures (e.g., with ReLU activations), and holds for exponentially integrable terminal data, which is the sharp condition for this setting. Our primary innovation is to build a constructive bridge between the abstract, and often restrictive, assumptions of the deep theory of quadratic BSDEs and the world of machine learning, demonstrating that these conditions can be met by concrete, verifiable neural network designs. We provide constructive methods for enforcing key axiomatic properties, such as convexity, by architectural design. The theory is extended to the analysis of fully coupled Forward-Backward SDE systems and to the asymptotic analysis of large interacting particle systems, for which we establish both a Law of Large Numbers (propagation of chaos) and a Central Limit Theorem. This work provides the foundational mathematical framework for data-driven modeling under ambiguity.', 'abstract_zh': '这篇论文介绍了通过非线性期望建模不确定性的一种范式——度量学习。我们定义了神经期望算子，它是满足特定条件的后向随机微分方程（BSDE）的解，其驱动项由神经网络参数化。主要的数学贡献是一道严谨的存在唯一性定理，该定理适用于满足状态变量局部Lipschitz条件和鞅分量二次增长条件的BSDE，这绕过了经典的全局Lipschitz假设，适用于常见的神经网络结构（例如使用ReLU激活函数），并且适用于指数可积的终端数据，这是该设置下的尖锐条件。我们的主要创新在于，在抽象且通常具有限制性的二次BSDE深理论假设与机器学习的世界之间建立了一个建设性的桥梁，证明了这些条件可以通过具体的验证性神经网络设计实现。我们提供了通过结构设计来强制执行关键公理性质的方法，如凸性。该理论扩展到了完全耦合的前向-后向SDE系统及大规模相互作用粒子系统的渐近分析，在后者中我们建立了大数定律（混乱的传播）以及中心极限定理。本工作提供了在不确定性条件下数据驱动建模的理论基础。', 'title_zh': '神经期望算子'}
{'arxiv_id': 'arXiv:2507.10606', 'title': 'DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design', 'authors': 'Bing-Yue Wu, Vidya A. Chhabria', 'link': 'https://arxiv.org/abs/2507.10606', 'abstract': 'Machine learning (ML) has demonstrated significant promise in various physical design (PD) tasks. However, model generalizability remains limited by the availability of high-quality, large-scale training datasets. Creating such datasets is often computationally expensive and constrained by IP. While very few public datasets are available, they are typically static, slow to generate, and require frequent updates. To address these limitations, we present DALI-PD, a scalable framework for generating synthetic layout heatmaps to accelerate ML in PD research. DALI-PD uses a diffusion model to generate diverse layout heatmaps via fast inference in seconds. The heatmaps include power, IR drop, congestion, macro placement, and cell density maps. Using DALI-PD, we created a dataset comprising over 20,000 layout configurations with varying macro counts and placements. These heatmaps closely resemble real layouts and improve ML accuracy on downstream ML tasks such as IR drop or congestion prediction.', 'abstract_zh': '基于扩散模型的DALI-PD：规模化生成合成布局热图以加速物理设计中的机器学习研究', 'title_zh': 'DALI-PD：基于扩散的合成布局热图生成方法在物理设计中的应用'}
{'arxiv_id': 'arXiv:2507.10605', 'title': 'RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services', 'authors': 'Fei Zhao, Chonggang Lu, Yue Wang, Zheyong Xie, Ziyan Liu, Haofu Qian, JianZhao Huang, Fangcheng Shi, Zijie Meng, Hongcheng Guo, Mingqian He, Xinze Lyu, Yiming Lu, Ziyang Xiang, Zheyu Ye, Chengqiang Lu, Zhe Xu, Yi Wu, Yao Hu, Yan Gao, Jun Fan, Xiaolong Jiang, Weiting Liu, Boyang Wang, Shaosheng Cao', 'link': 'https://arxiv.org/abs/2507.10605', 'abstract': 'As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.', 'abstract_zh': '作为现代信息传播的主要媒介，社交网络服务（SNS）经历了 rapid growth，这对平台内容管理和互动质量的提升提出了重大挑战。近年来，大型语言模型（LLMs）的发展提供了潜在的解决方案，但现有研究主要集中在孤立的任务上，不仅在单一场景中面临数据规模增大的边际效益递减问题，还无法灵活适应多样的现实世界情境。为应对这些挑战，我们引入了 RedOne，这是一种领域特定的 LLM，旨在打破单任务基线的性能瓶颈，并为 SNS 建立全面的基础。RedOne 通过包含持续预训练、监督微调和偏好优化的三阶段训练策略进行了开发，使用的是大规模的真实世界数据集。通过广泛的实验，RedOne 维持了强大的一般能力，并在8项主要 SNS 任务中平均提高了14.02%，在 SNS 双语评估基准测试中提高了7.56%。此外，在线测试结果显示，与单任务微调基线模型相比，RedOne 将有害内容检测的曝光率降低了11.23%，提高了张贴查看后的点击页率14.95%。这些结果确立了 RedOne 作为一个在 SNS 中表现出色的领域特定 LLM 的地位，展示了其在各种任务上的卓越泛化能力和在实际场景中的广泛应用潜力。', 'title_zh': 'RedOne: 揭示社交媒体服务中的领域特定LLM后训练'}
{'arxiv_id': 'arXiv:2507.10602', 'title': 'Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees', 'authors': 'Maximilian Stölzle, T. Konstantin Rusch, Zach J. Patterson, Rodrigo Pérez-Dattari, Francesco Stella, Josie Hughes, Cosimo Della Santina, Daniela Rus', 'link': 'https://arxiv.org/abs/2507.10602', 'abstract': 'Learning from demonstration provides a sample-efficient approach to acquiring complex behaviors, enabling robots to move robustly, compliantly, and with fluidity. In this context, Dynamic Motion Primitives offer built - in stability and robustness to disturbances but often struggle to capture complex periodic behaviors. Moreover, they are limited in their ability to interpolate between different tasks. These shortcomings substantially narrow their applicability, excluding a wide class of practically meaningful tasks such as locomotion and rhythmic tool use. In this work, we introduce Orbitally Stable Motion Primitives (OSMPs) - a framework that combines a learned diffeomorphic encoder with a supercritical Hopf bifurcation in latent space, enabling the accurate acquisition of periodic motions from demonstrations while ensuring formal guarantees of orbital stability and transverse contraction. Furthermore, by conditioning the bijective encoder on the task, we enable a single learned policy to represent multiple motion objectives, yielding consistent zero-shot generalization to unseen motion objectives within the training distribution. We validate the proposed approach through extensive simulation and real-world experiments across a diverse range of robotic platforms - from collaborative arms and soft manipulators to a bio-inspired rigid-soft turtle robot - demonstrating its versatility and effectiveness in consistently outperforming state-of-the-art baselines such as diffusion policies, among others.', 'abstract_zh': '基于演示学习提供了高效样本获取复杂行为的方法，使机器人能够以稳定性、鲁棒性和流畅性移动。在此背景下，轨道稳定运动基元具有内置的稳定性和对干扰的鲁棒性，但往往难以捕捉复杂周期行为，且在不同任务之间的插值能力有限。这些不足极大地限制了其应用范围，排除了许多实际意义重大的任务，如运动和节律性工具使用。在本文中，我们提出了轨道稳定运动基元（OSMPs）——一种结合学习差分编码器与潜在空间超临界霍普极限环的框架，能够从演示中准确获取周期性运动，并确保轨道稳定性和横向收缩的正式保证。此外，通过将双射编码器与任务相关联，我们使得单一学习策略能够表示多个运动目标，在训练分布内的一次性泛化到未见过的运动目标。我们通过广泛的仿真实验和实际世界实验，在多种不同的机器人平台上验证了所提出的方法，从协作臂和软 manipulators 到生物启发的刚体软体龟机器人，展示了其多样性和有效性，其性能在与现有的先进技术如扩散策略等的对比中持续表现更优。', 'title_zh': '学习 rhythm 中的运动：具有轨道稳定保证的任务条件运动策略'}
{'arxiv_id': 'arXiv:2507.10599', 'title': 'Emergence of Hierarchical Emotion Organization in Large Language Models', 'authors': 'Bo Zhao, Maya Okawa, Eric J. Bigelow, Rose Yu, Tomer Ullman, Ekdeep Singh Lubana, Hidenori Tanaka', 'link': 'https://arxiv.org/abs/2507.10599', 'abstract': "As large language models (LLMs) increasingly power conversational agents, understanding how they model users' emotional states is critical for ethical deployment. Inspired by emotion wheels -- a psychological framework that argues emotions organize hierarchically -- we analyze probabilistic dependencies between emotional states in model outputs. We find that LLMs naturally form hierarchical emotion trees that align with human psychological models, and larger models develop more complex hierarchies. We also uncover systematic biases in emotion recognition across socioeconomic personas, with compounding misclassifications for intersectional, underrepresented groups. Human studies reveal striking parallels, suggesting that LLMs internalize aspects of social perception. Beyond highlighting emergent emotional reasoning in LLMs, our results hint at the potential of using cognitively-grounded theories for developing better model evaluations.", 'abstract_zh': '随着大型语言模型（LLMs）越来越多地驱动对话代理，了解它们如何建模用户的情感状态对于伦理应用至关重要。受情绪轮盘这一心理学框架的启发，该框架认为情绪是层次化的，我们分析了模型输出中情感状态的概率依赖性。我们发现，LLMs自然形成了与人类心理学模型相一致的层级情绪树，且更大的模型发展出更复杂的层级结构。我们还发现了跨社会经济人物的情绪识别系统性偏差，而交叉影响的边缘群体出现了累积的分类错误。人类研究揭示了令人震惊的相似之处，表明LLMs内化了社会知觉的某些方面。除了突显LLMs中涌现的情感推理之外，我们的结果暗示了使用认知驱动的理论来开发更好模型评估的潜力。', 'title_zh': '大型语言模型中层级情绪组织的涌现'}
{'arxiv_id': 'arXiv:2507.10596', 'title': 'PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification', 'authors': 'Yogachandran Rahulamathavan, Misbah Farooq, Varuna De Silva', 'link': 'https://arxiv.org/abs/2507.10596', 'abstract': 'Large Language Models (LLMs) excel in text classification, but their complexity hinders interpretability, making it difficult to understand the reasoning behind their predictions. Explainable AI (XAI) methods like LIME and SHAP offer local explanations by identifying influential words, but they rely on computationally expensive perturbations. These methods typically generate thousands of perturbed sentences and perform inferences on each, incurring a substantial computational burden, especially with LLMs. To address this, we propose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation (PLEX), a novel method that leverages the contextual embeddings extracted from the LLM and a ``Siamese network" style neural network trained to align with feature importance scores. This one-off training eliminates the need for subsequent perturbations, enabling efficient explanations for any new sentence. We demonstrate PLEX\'s effectiveness on four different classification tasks (sentiment, fake news, fake COVID-19 news and depression), showing more than 92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test" reveals that PLEX accurately identifies influential words, leading to a similar decline in classification accuracy as observed with LIME and SHAP when these words are removed. Notably, in some cases, PLEX demonstrates superior performance in capturing the impact of key features. PLEX dramatically accelerates explanation, reducing time and computational overhead by two and four orders of magnitude, respectively. This work offers a promising solution for explainable LLM-based text classification.', 'abstract_zh': 'Perturbation-free Local Explanation (PLEX) for Explainable Large Language Models-based Text Classification', 'title_zh': 'PLEX：基于LLM的文本分类的无扰动局部解释'}
{'arxiv_id': 'arXiv:2507.10595', 'title': 'Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs', 'authors': 'Yaowen Hu, Wenxuan Tu, Yue Liu, Miaomiao Li, Wenpeng Lu, Zhigang Luo, Xinwang Liu, Ping Chen', 'link': 'https://arxiv.org/abs/2507.10595', 'abstract': 'Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised task aimed at partitioning nodes with incomplete attributes into distinct clusters. Addressing this challenging issue is vital for practical applications. However, research in this area remains underexplored. Existing imputation methods for attribute-missing graphs often fail to account for the varying amounts of information available across node neighborhoods, leading to unreliable results, especially for nodes with insufficient known neighborhood. To address this issue, we propose a novel method named Divide-Then-Rule Graph Completion (DTRGC). This method first addresses nodes with sufficient known neighborhood information and treats the imputed results as new knowledge to iteratively impute more challenging nodes, while leveraging clustering information to correct imputation errors. Specifically, Dynamic Cluster-Aware Feature Propagation (DCFP) initializes missing node attributes by adjusting propagation weights based on the clustering structure. Subsequently, Hierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing nodes into three groups based on the completeness of their neighborhood attributes. The imputation is performed hierarchically, prioritizing the groups with nodes that have the most available neighborhood information. The cluster structure is then used to refine the imputation and correct potential errors. Finally, Hop-wise Representation Enhancement (HRE) integrates information across multiple hops, thereby enriching the expressiveness of node representations. Experimental results on six widely used graph datasets show that DTRGC significantly improves the clustering performance of various DGC methods under attribute-missing graphs.', 'abstract_zh': '基于属性缺失图的分层图补全（DTRGC）：一种新颖的方法', 'title_zh': '分而治之：一种基于聚类的分层插值器，用于属性缺失图'}
{'arxiv_id': 'arXiv:2507.10594', 'title': 'Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features', 'authors': 'Shengda Zhuo, Di Wu, Yi He, Shuqiang Huang, Xindong Wu', 'link': 'https://arxiv.org/abs/2507.10594', 'abstract': 'Online learning, where feature spaces can change over time, offers a flexible learning paradigm that has attracted considerable attention. However, it still faces three significant challenges. First, the heterogeneity of real-world data streams with mixed feature types presents challenges for traditional parametric modeling. Second, data stream distributions can shift over time, causing an abrupt and substantial decline in model performance. Third, it is often infeasible to label every data instance due to time and cost constraints. To address these issues, we proposed OL-MDISF (Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features), which constructs a latent copula-based representation for heterogeneous features, detects drifts via ensemble entropy and latent mismatch, and performs structure-aware pseudo-labeling.\nThis companion paper serves as a standalone technical reference to OL-MDISF. It provides a contextual discussion of related work in mixed-type modeling, drift adaptation, and weak supervision, as well as a comprehensive set of experiments across 14 real-world datasets under two types of drift scenarios. These include CER trends, ablation studies, sensitivity analyses, and temporal ensemble dynamics. We hope this document offers a reproducible benchmark for online learning on complex, weakly supervised streaming data.', 'abstract_zh': '在线学习中的特征空间随时间变化提供了一种灵活的学习范式，吸引了广泛关注。然而，它仍面临三个重大挑战。首先，包含混合特征类型的现实世界数据流的异质性给传统参数建模带来了挑战。其次，数据流分布会随时间发生变化，导致模型性能突然且显著下降。第三，由于时间成本限制，标记每条数据实例往往是不现实的。为了解决这些问题，我们提出了OL-MDISF（在线学习中的混合类型、漂移和不完整流特征），该方法构建了一个基于潜在copula的表示，通过集成熵和潜在不匹配来检测漂移，并进行结构感知的伪标签生成。这篇同伴论文作为OL-MDISF的独立技术参考，提供了关于混合类型建模、漂移适应和弱监督的相关工作讨论，并在两种类型的漂移场景下对14个真实世界数据集进行了全面实验，包括CER趋势分析、消融研究、敏感性分析和时间集成动态。我们希望这份文档为复杂、弱监督流数据的在线学习提供可重复的基准。', 'title_zh': '扩展OL-MDISF：面向混合类型、漂移和不完全流式特征的在线学习'}
{'arxiv_id': 'arXiv:2507.10593', 'title': 'ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs', 'authors': 'Peng Ding', 'link': 'https://arxiv.org/abs/2507.10593', 'abstract': 'Large Language Model (LLM) applications are increasingly relying on external tools to extend their capabilities beyond text generation. However, current tool integration approaches suffer from fragmentation, protocol limitations, and implementation complexity, leading to substantial development overhead. This paper presents Toolregistry, a protocol-agnostic tool management library that simplifies tool registration, representation, execution, and lifecycle management via a unified interface. Our evaluation demonstrates that \\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x performance improvements through concurrent execution, and 100% compatibility with OpenAI function calling standards. Real-world case studies show significant improvements in development efficiency and code maintainability across diverse integration scenarios. \\toolregistry is open-source and available at this https URL, with comprehensive documentation at this https URL.', 'abstract_zh': '大型语言模型（LLM）的应用越来越多地依赖外部工具来扩展其文本生成之外的能力。然而，当前的工具集成方法存在碎片化、协议限制和实现复杂性的问题，导致了大量的开发开销。本文介绍了Toolregistry，一种协议无关的工具管理库，通过统一接口简化了工具注册、表示、执行和生命周期管理。我们的评估显示，Toolregistry在工具集成代码上实现了60-80%的减少，并通过并行执行实现了高达3.1倍的性能提升，同时完全兼容OpenAI函数调用标准。实际案例研究显示，在各种集成场景中，Toolregistry显著提高了开发效率和代码可维护性。Toolregistry是开源的，并可在以下网址获取：this https URL，详细文档请参见以下网址：this https URL。', 'title_zh': 'ToolRegistry：一种面向函数调用LLM的协议agnostic工具管理库'}
{'arxiv_id': 'arXiv:2507.10591', 'title': 'MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation', 'authors': 'Vanderson Rocha, Diego Kreutz, Gabriel Canto, Hendrio Bragança, Eduardo Feitosa', 'link': 'https://arxiv.org/abs/2507.10591', 'abstract': 'Feature selection is vital for building effective predictive models, as it reduces dimensionality and emphasizes key features. However, current research often suffers from limited benchmarking and reliance on proprietary datasets. This severely hinders reproducibility and can negatively impact overall performance. To address these limitations, we introduce the MH-FSF framework, a comprehensive, modular, and extensible platform designed to facilitate the reproduction and implementation of feature selection methods. Developed through collaborative research, MH-FSF provides implementations of 17 methods (11 classical, 6 domain-specific) and enables systematic evaluation on 10 publicly available Android malware datasets. Our results reveal performance variations across both balanced and imbalanced datasets, highlighting the critical need for data preprocessing and selection criteria that account for these asymmetries. We demonstrate the importance of a unified platform for comparing diverse feature selection techniques, fostering methodological consistency and rigor. By providing this framework, we aim to significantly broaden the existing literature and pave the way for new research directions in feature selection, particularly within the context of Android malware detection.', 'abstract_zh': '特征选择对于构建有效的预测模型至关重要，因为它可以降低维度并强调关键特征。然而，当前的研究往往受限于有限的基准测试和对专有数据集的依赖。这严重阻碍了可重复性并可能负面影响整体性能。为解决这些局限性，我们提出了MH-FSF框架，这是一个全面、模块化和可扩展的平台，旨在促进特征选择方法的重现和实现。MH-FSF通过合作研究提供了17种方法（11种经典方法、6种领域特定方法）的实现，并在10个公开可用的Android恶意软件数据集上进行系统的评估。我们的结果显示，在平衡和不平衡数据集上存在性能差异，突显了在这些不对称性中考虑数据预处理和选择标准的迫切需求。我们证明了提供统一平台以比较多样化的特征选择技术的重要性，促进方法论的一致性和严谨性。通过提供这一框架，我们希望能够显著拓宽现有文献并为特征选择领域的新兴研究方向铺平道路，特别是在Android恶意软件检测的背景下。', 'title_zh': 'MH-FSF：克服特征选择评估中基准测试和可重复性限制的统一框架'}
{'arxiv_id': 'arXiv:2507.10590', 'title': 'Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime', 'authors': 'Mojtaba Eshghie', 'link': 'https://arxiv.org/abs/2507.10590', 'abstract': "Language Model (LM) pipelines can dynamically refine their outputs against programmatic constraints. However, their effectiveness collapses when faced with competing soft constraints, leading to inefficient backtracking loops where satisfying one constraint violates another. We introduce Meta Self-Refining, a framework that equips LM pipelines with a meta-corrective layer to repair these competitions at runtime/inference-time. Our approach monitors the pipeline's execution history to detect oscillatory failures. Upon detection, it invokes a meta-repairer LM that analyzes the holistic state of the backtracking attempts and synthesizes a strategic instruction to balance the competing requirements. This self-repair instruction guides the original LM out of a failing refining loop towards a successful output. Our results show Meta Self-Refining can successfully repair these loops, leading to more efficient LM programs.", 'abstract_zh': '语言模型（LM）管道可以动态地在其输出中应用程序化约束的修正。然而，当面对竞争性的软约束时，其效果会失效，导致无效的回溯循环，满足一个约束会违反另一个约束。我们引入了Meta Self-Refining框架，该框架为LM管道配备了元校正层，在运行时/推理时修复这些竞争。我们的方法监控管道的执行历史以检测振荡失败。检测到后，它会调用一个元修复器LM，分析回溯尝试的总体状态并合成一个战略指令以平衡竞争需求。该自我修复指令引导原始LM从失败的修正循环中走出，生成成功的输出。我们的结果表明，Meta Self-Refining能够成功修复这些循环，使LM程序更加高效。', 'title_zh': '运行时元自完善竞争约束修正语言模型管道'}
{'arxiv_id': 'arXiv:2507.10589', 'title': 'Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays', 'authors': 'Gaurav Singh', 'link': 'https://arxiv.org/abs/2507.10589', 'abstract': "Pneumonia, particularly when induced by diseases like COVID-19, remains a critical global health challenge requiring rapid and accurate diagnosis. This study presents a comprehensive comparison of traditional machine learning and state-of-the-art deep learning approaches for automated pneumonia detection using chest X-rays (CXRs). We evaluate multiple methodologies, ranging from conventional machine learning techniques (PCA-based clustering, Logistic Regression, and Support Vector Classification) to advanced deep learning architectures including Convolutional Neural Networks (Modified LeNet, DenseNet-121) and various Vision Transformer (ViT) implementations (Deep-ViT, Compact Convolutional Transformer, and Cross-ViT). Using a dataset of 5,856 pediatric CXR images, we demonstrate that Vision Transformers, particularly the Cross-ViT architecture, achieve superior performance with 88.25% accuracy and 99.42% recall, surpassing traditional CNN approaches. Our analysis reveals that architectural choices impact performance more significantly than model size, with Cross-ViT's 75M parameters outperforming larger models. The study also addresses practical considerations including computational efficiency, training requirements, and the critical balance between precision and recall in medical diagnostics. Our findings suggest that Vision Transformers offer a promising direction for automated pneumonia detection, potentially enabling more rapid and accurate diagnosis during health crises.", 'abstract_zh': '肺炎，尤其是由COVID-19等疾病引起的肺炎，仍然是一个关键的全球健康挑战，需要快速而准确的诊断。本研究全面比较了传统机器学习方法和最新的深度学习方法在胸部X光片（CXR）上自动检测肺炎的应用。我们评估了多种方法，从传统的机器学习技术（基于PCA的聚类、逻辑回归和支持向量分类）到先进的深度学习架构（包括修正后的LeNet、DenseNet-121），以及多种视觉变换器（ViT）实现（Deep-ViT、紧凑卷积变换器和Cross-ViT）。使用包含5,856张儿科CXR图像的数据集，我们展示了视觉变换器，尤其是Cross-ViT架构，取得了88.25%的准确率和99.42%的召回率，超越了传统的CNN方法。我们的分析表明，架构选择比模型大小对性能影响更大，Cross-ViT的75M参数在性能上超过了更大的模型。本研究还讨论了计算效率、训练需求以及医学诊断中精确度和召回率之间的关键平衡。我们的研究结果表明，视觉变换器为自动肺炎检测提供了有前途的方向，可能在健康危机期间实现更快更准确的诊断。', 'title_zh': '基于胸部X光片的自动化肺炎检测：视觉-transformer与传统深度学习方法的 comparative analysis'}
{'arxiv_id': 'arXiv:2507.10587', 'title': 'Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing', 'authors': 'Dennis Ulmer, Alexandra Lorson, Ivan Titov, Christian Hardmeier', 'link': 'https://arxiv.org/abs/2507.10587', 'abstract': 'Human users increasingly rely on natural language interactions with large language models (LLMs) in order to receive help on a large variety of tasks and problems. However, the trustworthiness and perceived legitimacy of LLMs is undermined by the fact that their output is frequently stated in very confident terms, even when its accuracy is questionable. Therefore, there is a need to signal the confidence of the language model to a user in order to reap the benefits of human-machine collaboration and mitigate potential harms. Verbalized uncertainty is the expression of confidence with linguistic means, an approach that integrates perfectly into language-based interfaces. Nevertheless, most recent research in natural language processing (NLP) overlooks the nuances surrounding human uncertainty communication and the data biases that influence machine uncertainty communication. We argue for anthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty communication requires a degree of linguistic authenticity and personalization to the user, which could be achieved by emulating human communication. We present a thorough overview over the research in human uncertainty communication, survey ongoing research, and perform additional analyses to demonstrate so-far overlooked biases in verbalized uncertainty. We conclude by pointing out unique factors in human-machine communication of uncertainty and deconstruct anthropomimetic uncertainty into future research directions for NLP.', 'abstract_zh': '人类用户越来越多地依赖大型语言模型（LLMs）的自然语言交互以获得各种任务和问题的帮助，但模型输出经常以极其自信的语气表述，即使其准确性存疑，这损害了人们对LLMs的可信度和合法性感知。因此，需要向用户提供模型信心信号，以充分利用人机协作的好处并减轻潜在危害。口头化的不确定性是通过语言手段表达信心的方法，这一方法与基于语言的接口完美契合。然而，自然语言处理（NLP）领域的最新研究大多忽视了人类不确定性沟通的细微之处以及影响机器不确定性沟通的数据偏见。我们主张仿人类不确定性，即直观且可信的不确定性沟通需要一定程度的语言 authenticity和个性化，可以通过模仿人类沟通来实现。我们对人类不确定性沟通的研究进行了全面回顾，调查正在进行中的研究，并进行额外分析以展示口头化不确定性中的未被注意到的偏见。最后，我们指出了人机不确定性沟通中的独特因素，并将仿人类不确定性分解为未来NLP研究方向。', 'title_zh': '拟人类不确定性：语言模型中口头化不确定性的缺失要素'}
{'arxiv_id': 'arXiv:2507.10586', 'title': 'AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters', 'authors': 'Kaushik Dwivedi, Padmanabh Patanjali Mishra', 'link': 'https://arxiv.org/abs/2507.10586', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable fluency across a range of natural language tasks, yet remain vulnerable to hallucinations - factual inaccuracies that undermine trust in real world deployment. We present AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that tackles hallucination in large language models through lightweight LoRA-based adapters and KL-regularized training. Our pipeline integrates automated prompt rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in retrieved evidence. A hallucination detection module, using both classifier-based and self-evaluation techniques, assigns confidence scores to generated outputs, triggering an optional feedback correction loop. This loop enforces factual alignment via contrastive KL loss and adapter fine tuning. We demonstrate that AutoRAG-LoRA significantly reduces the factual drift while preserving the efficiency and modularity of the model.', 'abstract_zh': 'Large Language Models (LLMs) 在自然语言任务中表现出色，但易产生幻觉——事实不准确的陈述，这削弱了实际应用中的可信度。我们提出了AutoRAG-LoRA，一种通过轻量级LoRA适配器和KL正则化训练来解决大型语言模型幻觉问题的模块化框架。该框架整合了自动提示重写、混合检索和低秩适配器调优，以使生成的回应基于检索到的证据。一个幻觉检测模块，结合分类器和自我评估技术，为生成的输出打分，并触发可选的反馈纠正循环。该循环通过对比KL损失和适配器微调来强制执行事实一致性。我们证明，AutoRAG-LoRA 显著减少了事实偏离，同时保持了模型的高效性和模块性。', 'title_zh': 'AutoRAG-LoRA：由幻觉触发的知识轻量级适调'}
{'arxiv_id': 'arXiv:2507.10585', 'title': 'A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations', 'authors': 'Isar Nejadgholi, Mona Omidyeganeh, Marc-Antoine Drouin, Jonathan Boisvert', 'link': 'https://arxiv.org/abs/2507.10585', 'abstract': 'Effective AI governance requires structured approaches for stakeholders to access and verify AI system behavior. With the rise of large language models, Natural Language Explanations (NLEs) are now key to articulating model behavior, which necessitates a focused examination of their characteristics and governance implications. We draw on Explainable AI (XAI) literature to create an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, including task, data, audience, and goals; (2) Generation and Presentation, covering generation methods, inputs, interactivity, outputs, and forms; and (3) Evaluation, focusing on content, presentation, and user-centered properties, as well as the setting of the evaluation. This taxonomy provides a framework for researchers, auditors, and policymakers to characterize, design, and enhance NLEs for transparent AI systems.', 'abstract_zh': '有效的AI治理需要结构化的途径以使各方能够访问和验证AI系统的行为。随着大规模语言模型的兴起，自然语言解释（NLEs）已成为说明模型行为的关键，这需要对它们的特性和治理影响进行聚焦研究。我们借鉴可解释AI（XAI）文献，创建了一个适应基于提示的NLE的更新版XAI分类框架，涵盖三个维度：（1）背景，包括任务、数据、受众和目标；（2）生成与呈现，涵盖生成方法、输入、交互性、输出和形式；以及（3）评估，侧重于内容、呈现、以用户为中心的特性，以及评估环境。该分类框架为研究人员、审计员和政策制定者提供了一个框架，用于表征、设计和优化透明AI系统的NLE。', 'title_zh': '基于提示的自然语言解释设计与评估分类框架'}
{'arxiv_id': 'arXiv:2507.10584', 'title': 'ARPaCCino: An Agentic-RAG for Policy as Code Compliance', 'authors': 'Francesco Romeo, Luigi Arena, Francesco Blefari, Francesco Aurelio Pironti, Matteo Lupinacci, Angelo Furfaro', 'link': 'https://arxiv.org/abs/2507.10584', 'abstract': "Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows.", 'abstract_zh': '基于代理的Policy as Code (PaC)的自动化生成与验证：结合大语言模型、检索增强生成和工具验证的ARPaCCino系统', 'title_zh': 'ARPaCCino: 一种代理驱动的RAG政策即代码合规性助手'}
{'arxiv_id': 'arXiv:2507.10583', 'title': '$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection', 'authors': 'Daniil Orel, Indraneil Paul, Iryna Gurevych, Preslav Nakov', 'link': 'https://arxiv.org/abs/2507.10583', 'abstract': "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most extensive open data suite for training and evaluating machine-generated code detectors, comprising over a million code samples, seven programming languages, outputs from 43 coding models, and over three real-world coding domains. Alongside fully AI-generated samples, our collection includes human-AI co-authored code, as well as adversarial samples explicitly crafted to evade detection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite of encoder-only detectors trained using a multi-task objective over $\\texttt{DroidCollection}$. Our experiments show that existing detectors' performance fails to generalise to diverse coding domains and programming languages outside of their narrow training data. Additionally, we demonstrate that while most detectors are easily compromised by humanising the output distributions using superficial prompting and alignment approaches, this problem can be easily amended by training on a small amount of adversarial data. Finally, we demonstrate the effectiveness of metric learning and uncertainty-based resampling as means to enhance detector training on possibly noisy distributions.", 'abstract_zh': '本工作中，我们编纂了规模最大、最全面的开放数据集库$\\textbf{$\\texttt{DroidCollection}$}$，用于训练和评估机器生成代码检测器，包含超过一百万条代码样本、七种编程语言、43种编程模型的输出以及超过三个实际编程领域。除了完全由AI生成的样本外，我们的数据集还包括人机合著代码以及故意设计以规避检测的对抗样本。随后，我们开发了$\\textbf{$\\texttt{DroidDetect}$}$检测套件，该套件的检测器仅基于$\\texttt{DroidCollection}$上的多任务目标训练。实验结果表明，现有检测器的性能无法泛化到其狭窄训练数据集以外的多样编程领域和编程语言。此外，我们证明了通过使用表面性的提示和对齐方法使人机化输出分布，大多数检测器容易被篡改，这一问题可以通过少量对抗数据的训练得以轻易解决。最后，我们展示了使用度量学习和基于不确定性重采样作为提高检测器训练效率的有效方法。', 'title_zh': 'Droid: 一种用于AI生成代码检测的资源套件'}
{'arxiv_id': 'arXiv:2507.10581', 'title': 'Universal Approximation Theorem for a Single-Layer Transformer', 'authors': 'Esmail Gumaan', 'link': 'https://arxiv.org/abs/2507.10581', 'abstract': 'Deep learning employs multi-layer neural networks trained via the backpropagation algorithm. This approach has achieved success across many domains and relies on adaptive gradient methods such as the Adam optimizer. Sequence modeling evolved from recurrent neural networks to attention-based models, culminating in the Transformer architecture. Transformers have achieved state-of-the-art performance in natural language processing (for example, BERT and GPT-3) and have been applied in computer vision and computational biology. However, theoretical understanding of these models remains limited. In this paper, we examine the mathematical foundations of deep learning and Transformers and present a novel theoretical result. We review key concepts from linear algebra, probability, and optimization that underpin deep learning, and we analyze the multi-head self-attention mechanism and the backpropagation algorithm in detail. Our main contribution is a universal approximation theorem for Transformers: we prove that a single-layer Transformer, comprising one self-attention layer followed by a position-wise feed-forward network with ReLU activation, can approximate any continuous sequence-to-sequence mapping on a compact domain to arbitrary precision. We provide a formal statement and a complete proof. Finally, we present case studies that demonstrate the practical implications of this result. Our findings advance the theoretical understanding of Transformer models and help bridge the gap between theory and practice.', 'abstract_zh': '深度学习采用多层神经网络并通过反向传播算法训练。这种方法已在许多领域取得成功，并依赖于自适应梯度方法，如Adam优化器。序列建模从递归神经网络发展到基于注意力的模型，最终形成了Transformer架构。Transformer在自然语言处理（例如BERT和GPT-3）中达到了最先进的性能，并被应用于计算机视觉和计算生物学。然而，对这些模型的理解仍缺乏理论上的认识。在本文中，我们探讨了深度学习和Transformer的数学基础，并提出了一个新的理论成果。我们回顾了线性代数、概率和优化中的核心概念，这些概念支撑了深度学习，并详细分析了多头自注意力机制和反向传播算法。我们的主要贡献是为Transformer提出一个普遍逼近定理：证明一个包含一个自注意力层后跟一个具有ReLU激活的位置-wise前馈网络的单层Transformer，可以任意精度地逼近紧致领域上的任意连续序列到序列映射。我们提供了正式陈述并给出了完整证明。最后，我们展示了案例研究以说明该结果的实际影响。我们的发现推进了对Transformer模型理论的理解，并有助于理论与实践之间的鸿沟。', 'title_zh': '单层变换器的通用逼近定理'}
{'arxiv_id': 'arXiv:2507.10580', 'title': 'An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation', 'authors': 'Vimaleswar A, Prabhu Nandan Sahu, Nilesh Kumar Sahu, Haroon R Lone', 'link': 'https://arxiv.org/abs/2507.10580', 'abstract': "Mental health plays a crucial role in the overall well-being of an individual. In recent years, digital platforms have been increasingly used to expand mental health and emotional support. However, there are persistent challenges related to limited user accessibility, internet connectivity, and data privacy, which highlight the need for an offline, smartphone-based solution. To address these challenges, we propose EmoSApp (Emotional Support App): an entirely offline, smartphone-based conversational app designed for mental health and emotional support. The system leverages Large Language Models (LLMs), specifically fine-tuned, quantized and deployed using Torchtune and Executorch for resource-constrained devices, allowing all inferences to occur on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of 14,582 mental-health QA pairs, along with the multi-turn conversational data.\nThrough qualitative human evaluation with the student population, we demonstrate that EmoSApp has the ability to respond coherently, empathetically, maintain interactive dialogue, and provide relevant suggestions to user's mental health problems. Additionally, quantitative evaluations on nine standard commonsense and reasoning benchmarks demonstrate the efficacy of our fine-tuned, quantized model in low-resource settings. By prioritizing on-device deployment and specialized domain adaptation, EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions.", 'abstract_zh': '情感健康在个体的整体福祉中扮演着关键角色。近年来，数字平台被越来越多地用于扩展心理健康和情感支持。然而，有限的用户访问性、互联网连接性和数据隐私等问题依然存在，突显了需要一种离线的智能手机基于解决方案的必要性。为应对这些挑战，我们提出EmoSApp（情感支持应用）：一种完全离线的，基于智能手机的对话应用，旨在提供情感支持和心理健康服务。该系统利用了大型语言模型（LLMs），特别是通过Torchtune和Executorch进行细调和部署，适用于资源受限的设备，使得所有推理都在智能手机上进行。为使EmoSApp具备强大的领域专业知识，我们在一个包含14,582个心理健康问答对的自定义知识数据集上对LLaMA-3.2-1B-Instruct模型进行了细调，并结合了多轮对话数据。\n\n通过针对学生群体的定性人类评估，我们证明EmoSApp能够一贯地、富有同情心地响应，保持互动对话，并向用户的情感健康问题提供相关建议。此外，在九个标准常识和推理基准上的定量评估表明，我们的细调和量化模型在资源受限环境中具有有效性。通过优先考虑设备上部署和专门的领域适应，EmoSApp为未来便携、安全和高度定制的AI驱动心理健康解决方案提供了蓝图。', 'title_zh': '面向心理健康的离线移动对话代理：基于学生中心评估的情感对话与心理文本学习'}
{'arxiv_id': 'arXiv:2507.10579', 'title': 'Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors', 'authors': 'Ekaterina Kochmar, Kaushal Kumar Maurya, Kseniia Petukhova, KV Aditya Srivatsa, Anaïs Tack, Justin Vasselli', 'link': 'https://arxiv.org/abs/2507.10579', 'abstract': "This shared task has aimed to assess pedagogical abilities of AI tutors powered by large language models (LLMs), focusing on evaluating the quality of tutor responses aimed at student's mistake remediation within educational dialogues. The task consisted of five tracks designed to automatically evaluate the AI tutor's performance across key dimensions of mistake identification, precise location of the mistake, providing guidance, and feedback actionability, grounded in learning science principles that define good and effective tutor responses, as well as the track focusing on detection of the tutor identity. The task attracted over 50 international teams across all tracks. The submitted models were evaluated against gold-standard human annotations, and the results, while promising, show that there is still significant room for improvement in this domain: the best results for the four pedagogical ability assessment tracks range between macro F1 scores of 58.34 (for providing guidance) and 71.81 (for mistake identification) on three-class problems, with the best F1 score in the tutor identification track reaching 96.98 on a 9-class task. In this paper, we overview the main findings of the shared task, discuss the approaches taken by the teams, and analyze their performance. All resources associated with this task are made publicly available to support future research in this critical domain.", 'abstract_zh': '这项共享任务旨在评估由大型语言模型（LLMs）驱动的人工智能辅导系统的教学能力，重点在于评估辅导系统在教育对话中纠正学生错误时响应质量。该任务包括五个赛道，旨在从错误识别、错误位置精确性、提供指导以及反馈执行力等方面自动评估人工智能辅导员的性能，这些维度基于学习科学原则，定义了良好的有效辅导响应标准，并且还包括辅导身份检测的赛道。来自全球的50多支团队参加了所有赛道的比赛。提交的模型接受了金标准人类注释的评估，结果虽然令人振奋，但仍显示在此领域还有很大的改进空间：四个人工智能辅导系统教学能力评估赛道的最佳结果分别涵盖三类问题中的宏F1分数为58.34（提供指导）和71.81（错误识别），而辅导身份检测赛道的最佳F1分数为96.98，涉及九类任务。本文概述了共享任务的主要发现，讨论了参赛团队所采用的方法，并分析了他们的表现。所有与该任务相关的资源均向公众开放，以支持该关键领域的未来研究。', 'title_zh': 'BEA 2025 共享任务关于人工智能辅导工具教学能力评估的成果'}
{'arxiv_id': 'arXiv:2507.10578', 'title': 'When and Where do Data Poisons Attack Textual Inversion?', 'authors': 'Jeremy Styborski, Mingzhi Lyu, Jiayou Lu, Nupur Kapur, Adams Kong', 'link': 'https://arxiv.org/abs/2507.10578', 'abstract': 'Poisoning attacks pose significant challenges to the robustness of diffusion models (DMs). In this paper, we systematically analyze when and where poisoning attacks textual inversion (TI), a widely used personalization technique for DMs. We first introduce Semantic Sensitivity Maps, a novel method for visualizing the influence of poisoning on text embeddings. Second, we identify and experimentally verify that DMs exhibit non-uniform learning behavior across timesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias and inject adversarial signals predominantly at lower timesteps. Lastly, we observe that adversarial signals distract learning away from relevant concept regions within training data, corrupting the TI process. Based on these insights, we propose Safe-Zone Training (SZT), a novel defense mechanism comprised of 3 key components: (1) JPEG compression to weaken high-frequency poison signals, (2) restriction to high timesteps during TI training to avoid adversarial signals at lower timesteps, and (3) loss masking to constrain learning to relevant regions. Extensive experiments across multiple poisoning methods demonstrate that SZT greatly enhances the robustness of TI against all poisoning attacks, improving generative quality beyond prior published defenses. Code: this http URL Data: this http URL', 'abstract_zh': '中毒攻击对扩散模型（DMs）的鲁棒性构成重大挑战。在本文中，我们系统分析了中毒攻击如何影响文本反转（TI），这是一种广泛使用的DM个性化技术。我们首先介绍了语义敏感图，这是一种新型的可视化方法，用于展示中毒对文本嵌入的影响。其次，我们发现并实验证明了DMs在时间步具有非均匀的学习行为，重点关注低噪声样本。中毒攻击继承了这一偏差，并在较早的时间步注入敌对信号。最后，我们观察到敌对信号会将学习过程引导至与训练数据中相关概念区域无关的方向，破坏TI过程。基于这些见解，我们提出了一种新的防御机制——安全区训练（SZT），其包含三个关键组件：（1）JPEG压缩以削弱高频毒信号，（2）在TI训练期间限制使用高时间步以避免低时间步的敌对信号，（3）损失屏蔽以限制学习到相关区域。广泛的实验表明，SZT显著增强了TI在所有中毒攻击下的鲁棒性，并且改善了生成质量，超越了先前发布的防御措施。代码：详见链接。数据：详见链接。', 'title_zh': '何时何地数据毒药攻击文本反转？'}
{'arxiv_id': 'arXiv:2507.10577', 'title': 'Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions', 'authors': 'Logé Cécile, Ghori Rehan', 'link': 'https://arxiv.org/abs/2507.10577', 'abstract': "Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender.\nTruth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented Generation (RAG) approach - drawing on sources like Wikipedia, Google Search, Google FactCheck - to accurately assess their veracity and generates a nuanced and comprehensive report. Through rigorous prompt engineering, Trend Bender leverages this report along with a curated corpus of relevant articles to generate insightful and persuasive comments designed to stimulate a productive debate. With a carefully set up self-evaluation loop, this agent is able to iteratively improve its style and refine its output.\nWe demonstrate the system's capabilities through experiments on established benchmark datasets and a real-world deployment on YouTube, showcasing its potential to engage users and potentially influence perspectives. Our findings highlight the high accuracy of our fact-checking agent, and confirm the potential of AI-driven interventions in combating misinformation and fostering a more informed online space.", 'abstract_zh': '人工智能赋能的系统在YouTube上对抗 misinformation及其应用研究', 'title_zh': '真相探查者与趋势颠覆者：用于检查YouTube视频事实并影响观点的AI代理'}
{'arxiv_id': 'arXiv:2507.10576', 'title': 'Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?', 'authors': 'Bhakti Khera, Rezvan Alamian, Pascal A. Scherz, Stephan M. Goetz', 'link': 'https://arxiv.org/abs/2507.10576', 'abstract': 'The legal field already uses various large language models (LLMs) in actual applications, but their quantitative performance and reasons for it are underexplored. We evaluated several open-source and proprietary LLMs -- including GPT-series, Anthropic, Deepseek and Llama-3, variants -- on parts of the European Qualifying Examination (EQE) for future European Patent Attorneys. OpenAI o1 led with 0.82 accuracy and 0.81 F1 score, whereas (Amazon Web Services) AWS Llama 3.1 8B lagged at 0.50 accuracy, and a Python-deployed Llama 3.1 8B scored 0.55. The latter two are within the range of mere guessing for the two-answer forced-choice design. None of the evaluated models could have passed the examination fully, as accuracy never exceeded the average threshold of 0.90 required for professional-level standards -- also not models that are regularly promoted for their assumed beyond-PhD- and bar-admitted-lawyer-level performance. GPT-4o excelled at integrating text and graphics, while Claude 3 Opus often lost formatting coherence. Human patent experts evaluated the textual justifications and uncovered various critical shortcomings of each model. They valued clarity and legal rationale over the raw correctness of the answers, which revealed misalignment between automatic metrics and expert judgment. Model outputs were sensitive to modest temperature changes and prompt wording, which underscores the remaining necessity of expert oversight. Future work should target logical consistency, robust multimodality, and adaptive prompting to approach human-level patent proficiency. In summary, despite the outstanding performance of recent large models, the general public might overestimate their performance. The field has a long way to go to develop a virtual patent attorney. This paper wants to point out several specific limitations that need solutions.', 'abstract_zh': '现有的法律领域已经在实际应用中使用了各种大型语言模型（LLMs），但其量化性能及原因尚未充分探索。我们评估了几种开源和专有LLM——包括GPT系列、Anthropic、Deepseek和Llama-3变体——在欧洲资格考试（EQE）的部分试题上，以供未来欧洲专利代理人使用。OpenAI o1以0.82的准确率和0.81的F1分数领先，而(Amazon Web Services) AWS Llama 3.1 8B仅为0.50的准确率，一个部署在Python中的Llama 3.1 8B得分为0.55。后两种在两选项强制选择设计中仅略高于纯粹猜测的范围。没有任何评估模型能够全面通过考试，即使是对被认为超越博士和通过律师考试的模型也是如此，其准确率从未超过专业水平所需的平均阈值0.90。人类专利专家评估了文本解释，并发现了每个模型的各种关键不足。他们更重视清晰度和法律依据，而非答案的纯粹正确性，这揭示了自动指标与专家判断之间的不一致。模型输出对温度变化和提示措辞的变化非常敏感，这强调了专业监督的必要性。未来的工作应专注于逻辑一致性、稳健的多媒体能力和适应性提示，以接近人类水平的专利熟练度。总的来说，尽管最近的大规模模型表现出色，但公众可能对其性能存在过度估计。该领域还需走很长一段路以发展出虚拟专利代理人。本文旨在指出需要解决的若干具体限制。', 'title_zh': '大型语言模型在通过实际专利律师考试时，能否既理解和应用专利法规？'}
{'arxiv_id': 'arXiv:2507.10574', 'title': 'Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance', 'authors': 'Jae Wan Shim', 'link': 'https://arxiv.org/abs/2507.10574', 'abstract': 'We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel measure derived from the information theory. In comparison to the standard cross entropy loss function, the proposed one has an additional term that depends on the predicted probability of the true class. This feature serves to enhance the optimization process in classification tasks involving one-hot encoded class labels. The proposed one has been evaluated on a ResNet-based model using the CIFAR-100 dataset. Preliminary results show that the proposed one consistently outperforms the standard cross entropy loss function in terms of classification accuracy. Moreover, the proposed one maintains simplicity, achieving practically the same efficiency to the traditional cross entropy loss. These findings suggest that our approach could broaden the scope for future research into loss function design.', 'abstract_zh': '我们提出线性自适应交叉熵损失函数。这是一种源自信息理论的新型度量。与标准交叉熵损失函数相比，所提出的方法包含一个额外项，该项依赖于真实类别的预测概率。该特性有助于在使用独热编码类标签的分类任务中优化过程。所提出的方法在基于ResNet的模型和CIFAR-100数据集上进行了评估。初步结果显示，所提出的方法在分类准确率上始终优于标准交叉熵损失函数。此外，所提出的方法保持了简洁性，达到与传统交叉熵损失相似的效率。这些发现表明，我们的方法可能为未来关于损失函数设计的研究拓宽视野。', 'title_zh': '改进交叉熵通过线性自适应损失函数优化分类性能'}
{'arxiv_id': 'arXiv:2507.10564', 'title': 'Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing', 'authors': 'Sameera Bharadwaja H., Siddhrath Jandial, Shashank S. Agashe, Rajesh Kumar Reddy Moore, Youngkwan Kim', 'link': 'https://arxiv.org/abs/2507.10564', 'abstract': 'We consider the problem of tool-to-tool matching (TTTM), also called, chamber matching in the context of a semiconductor manufacturing equipment. Traditional TTTM approaches utilize static configuration data or depend on a golden reference which are difficult to obtain in a commercial manufacturing line. Further, existing methods do not extend very well to a heterogeneous setting, where equipment are of different make-and-model, sourced from different equipment vendors. We propose novel TTTM analysis pipelines to overcome these issues. We hypothesize that a mismatched equipment would have higher variance and/or higher number of modes in the data. Our best univariate method achieves a correlation coefficient >0.95 and >0.5 with the variance and number of modes, respectively showing that the proposed methods are effective. Also, the best multivariate method achieves a correlation coefficient >0.75 with the top-performing univariate methods, showing its effectiveness. Finally, we analyze the sensitivity of the multivariate algorithms to the algorithm hyper-parameters.', 'abstract_zh': '半导体制造设备中工具到工具匹配问题分析', 'title_zh': '基于工具到工具匹配的差异得分计算方法研究（半导体制造）'}
{'arxiv_id': 'arXiv:2507.10563', 'title': 'A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment', 'authors': 'Antonis Messinis', 'link': 'https://arxiv.org/abs/2507.10563', 'abstract': 'With increasing wastewater rates, achieving energy-neutral purification is challenging. We introduce a coral-reef-inspired Swarm Interaction Network for carbon-neutral wastewater treatment, combining morphogenetic abstraction with multi-task carbon awareness. Scalability stems from linear token complexity, mitigating the energy-removal problem. Compared with seven baselines, our approach achieves 96.7\\% removal efficiency, 0.31~kWh~m$^{-3}$ energy consumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis demonstrates robustness under sensor drift. Field scenarios--insular lagoons, brewery spikes, and desert greenhouses--show potential diesel savings of up to 22\\%. However, data-science staffing remains an impediment. Future work will integrate AutoML wrappers within the project scope, although governance restrictions pose interpretability challenges that require further visual analytics.', 'abstract_zh': '基于珊瑚礁启发的 Swarm Interaction Network 促进碳中和废水处理：结合形态发生抽象与多任务碳意识', 'title_zh': '珊瑚礁启发的 swarm 智能的生物模拟方法及其在碳中和废水处理中的应用'}
{'arxiv_id': 'arXiv:2507.10559', 'title': 'NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research', 'authors': 'Shomir Wilson', 'link': 'https://arxiv.org/abs/2507.10559', 'abstract': "Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about LLMs' capabilities and limitations. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.", 'abstract_zh': 'Recent developments in大型语言模型（LLMs）引发了公众对自然语言处理（NLP）的浓厚兴趣。这种关注在主流媒体中有所体现，有时会邀请NLP研究人员与广大读者分享他们的知识和观点。本论文旨在利用当前的机遇，针对研究领域和个人研究人员，分享关于沟通LLMs的能力和限制的建议。这些建议涵盖了三个主题：模糊术语是公众理解的障碍、不合理的期望是可持续增长的障碍、伦理失败是持续支持的障碍。文章通过引用已发表的NLP研究和流行新闻报道中的例子来阐述这些主题，旨在促进与公众的有效、透明沟通，以增强公众的理解并鼓励对研究的支持。', 'title_zh': 'NLP遇见世界：关于自然语言处理研究面向公众对话的改进之路'}
{'arxiv_id': 'arXiv:2111.06614', 'title': 'Collaboration Promotes Group Resilience in Multi-Agent AI', 'authors': 'Sarah Keren, Matthias Gerstgrasser, Ofir Abu, Jeffrey Rosenschein', 'link': 'https://arxiv.org/abs/2111.06614', 'abstract': 'To effectively operate in various dynamic scenarios, RL agents must be resilient to unexpected changes in their environment. Previous work on this form of resilience has focused on single-agent settings. In this work, we introduce and formalize a multi-agent variant of resilience, which we term group resilience. We further hypothesize that collaboration with other agents is key to achieving group resilience; collaborating agents adapt better to environmental perturbations in multi-agent reinforcement learning (MARL) settings. We test our hypothesis empirically by evaluating different collaboration protocols and examining their effect on group resilience. Our experiments show that all the examined collaborative approaches achieve higher group resilience than their non-collaborative counterparts.', 'abstract_zh': '为了在各种动态场景中有效运作，RL代理必须对其环境中的意外变化具有弹性。先前对此类弹性的研究主要集中在单代理设置上。在此项工作中，我们引入并形式化了一个多代理弹性变体，我们称之为群体弹性。我们进一步假设与其他代理的合作对于实现群体弹性至关重要；在多代理强化学习（MARL）设置中，合作代理更能适应环境扰动。我们通过评估不同的合作协议并检查它们对群体弹性的影響来实证测试我们的假设。我们的实验表明，所有检查的合作方法在群体弹性方面都优于其非合作对应方法。', 'title_zh': '多智能体AI中的合作促进群体韧性'}
