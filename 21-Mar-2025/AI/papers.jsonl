{'arxiv_id': 'arXiv:2503.16416', 'title': 'Survey on Evaluation of LLM-based Agents', 'authors': 'Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun Zhao, Roy Bar-Haim, Arman Cohan, Michal Shmueli-Scheuer', 'link': 'https://arxiv.org/abs/2503.16416', 'abstract': 'The emergence of LLM-based agents represents a paradigm shift in AI, enabling autonomous systems to plan, reason, use tools, and maintain memory while interacting with dynamic environments. This paper provides the first comprehensive survey of evaluation methodologies for these increasingly capable agents. We systematically analyze evaluation benchmarks and frameworks across four critical dimensions: (1) fundamental agent capabilities, including planning, tool use, self-reflection, and memory; (2) application-specific benchmarks for web, software engineering, scientific, and conversational agents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating agents. Our analysis reveals emerging trends, including a shift toward more realistic, challenging evaluations with continuously updated benchmarks. We also identify critical gaps that future research must address-particularly in assessing cost-efficiency, safety, and robustness, and in developing fine-grained, and scalable evaluation methods. This survey maps the rapidly evolving landscape of agent evaluation, reveals the emerging trends in the field, identifies current limitations, and proposes directions for future research.', 'abstract_zh': '基于LLM的代理 emergence 代表了AI范式的转变，使自主系统能够在与动态环境交互时进行规划、推理、使用工具和保持记忆。本文提供了对这些日益 capable 代理评估方法的首次全面综述。我们系统地从四个关键维度分析了评估基准和框架：（1）基本代理能力，包括规划、工具使用、自我反思和记忆；（2）针对Web、软件工程、科学和对话代理的应用特定基准；（3）普遍适用代理的基准；以及（4）代理评估框架。我们的分析揭示了新兴趋势，包括转向更现实和更具挑战性的评估，基准持续更新。我们还指出了未来研究必须解决的关键缺口，特别是评估成本效率、安全性和鲁棒性的问题，以及开发精细和可扩展的评估方法。本文描绘了代理评估快速变化的格局，揭示了领域的新兴趋势，指出了当前的局限性，并提出了未来研究的方向。', 'title_zh': 'LLM-based代理评估研究'}
{'arxiv_id': 'arXiv:2503.16402', 'title': "The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination", 'authors': 'Yifan Sun, Han Wang, Dongbai Li, Gang Wang, Huan Zhang', 'link': 'https://arxiv.org/abs/2503.16402', 'abstract': 'Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples in the training set-has raised increasing concerns in Large Language Model (LLM) evaluation, leading to falsely inflated performance estimates and undermining evaluation reliability. To address this, researchers have proposed various mitigation strategies to update existing benchmarks, including modifying original questions or generating new ones based on them. However, a rigorous examination of the effectiveness of these mitigation strategies remains lacking. In this paper, we design a systematic and controlled pipeline along with two novel metrics-fidelity and contamination resistance-to provide a fine-grained and comprehensive assessment of existing BDC mitigation strategies. Previous assessment methods, such as accuracy drop and accuracy matching, focus solely on aggregate accuracy, often leading to incomplete or misleading conclusions. Our metrics address this limitation by emphasizing question-level evaluation result matching. Extensive experiments with 10 LLMs, 5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios reveal that no existing strategy significantly improves resistance over the vanilla case (i.e., no benchmark update) across all benchmarks, and none effectively balances fidelity and contamination resistance. These findings underscore the urgent need for designing more effective BDC mitigation strategies. Our code repository is available at this https URL.', 'abstract_zh': '基准数据污染（BDC）-在训练集中包含基准测试样本-日益引发了对大型语言模型（LLM）评估的担忧，导致性能估计被虚假地夸大，并削弱了评估的可靠性。为了应对这一问题，研究人员提出了各种缓解策略来更新现有基准，包括修改原始问题或基于它们生成新的问题。然而，这些缓解策略的有效性评估仍然缺乏严谨性。本文设计了一个系统且可控的流程，并引入了两种新的评估指标——忠实度和污染抵抗力，以提供对现有BDC缓解策略的细致和全面评估。之前的方法，如准确率下降和准确率匹配，仅关注整体准确率，常常导致不完整或误导性的结论。我们的指标通过强调问题级评估结果匹配来克服这一局限性。大规模实验（涉及10个LLM、5个基准、20种BDC缓解策略和2种污染情景）表明，没有任何现有策略在所有基准上显著提高抵抗性，而且没有任何策略能够有效平衡忠实度和污染抵抗力。这些发现突显了设计更有效的BDC缓解策略的迫切需求。我们的代码库可在此处访问：this https URL。', 'title_zh': '新皇帝的衣物：对大规模语言模型基准数据污染缓解策略的严谨考察'}
{'arxiv_id': 'arXiv:2503.16385', 'title': 'Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation', 'authors': 'Yijia Luo, Yulin Song, Xingyao Zhang, Jiaheng Liu, Weixun Wang, GengRu Chen, Wenbo Su, Bo Zheng', 'link': 'https://arxiv.org/abs/2503.16385', 'abstract': 'Recent advancements in large language models (LLMs) have demonstrated remarkable reasoning capabilities through long chain-of-thought (CoT) reasoning. The R1 distillation scheme has emerged as a promising approach for training cost-effective models with enhanced reasoning abilities. However, the underlying mechanisms driving its effectiveness remain unclear. This study examines the universality of distillation data and identifies key components that enable the efficient transfer of long-chain reasoning capabilities in LLM distillation. Our findings reveal that the effectiveness of long CoT reasoning distillation from teacher models like Qwen-QwQ degrades significantly on nonhomologous models, challenging the assumed universality of current distillation methods. To gain deeper insights into the structure and patterns of long CoT reasoning, we propose DLCoT (Deconstructing Long Chain-of-Thought), a distillation data enhancement framework. DLCoT consists of three key steps: (1) data segmentation to decompose complex long CoT structures, (2) simplification by eliminating unsolvable and redundant solutions, and (3) optimization of intermediate error states. Our approach significantly improves model performance and token efficiency, facilitating the development of high-performance LLMs.', 'abstract_zh': '近期大型语言模型（LLMs）的发展展示了通过长链推理（CoT）推理的出色能力。R1蒸馏方案已成为一种有前景的方法，用于训练具有增强推理能力的成本效益模型。然而，其有效性的内在机制仍不清楚。本研究探讨了蒸馏数据的普适性，并识别出能够使LLM蒸馏中高效转移长链推理能力的关键组件。研究发现，从如Qwen-QwQ等教师模型中提取长CoT推理的蒸馏效果在非同源模型上显著下降，这一结果挑战了当前蒸馏方法假设的普适性。为深入探讨长CoT推理的结构和模式，我们提出了DLCoT（拆解长链推理）蒸馏数据增强框架。DLCoT包括三个关键步骤：(1) 数据分割以分解复杂的长CoT结构，(2) 简化以删除不可解和冗余的解决方案，(3) 中介错误状态的优化。我们的方法显著提高了模型性能和标记效率，有助于开发高性能的LLM。', 'title_zh': '拆解长链推理：一种结构化推理优化框架用于长链推理精简'}
{'arxiv_id': 'arXiv:2503.16371', 'title': 'Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming', 'authors': 'Minori Narita, Ryo Kuroiwa, J. Christopher Beck', 'link': 'https://arxiv.org/abs/2503.16371', 'abstract': 'Domain-Independent Dynamic Programming (DIDP) is a state-space search paradigm based on dynamic programming for combinatorial optimization. In its current implementation, DIDP guides the search using user-defined dual bounds. Reinforcement learning (RL) is increasingly being applied to combinatorial optimization problems and shares several key structures with DP, being represented by the Bellman equation and state-based transition systems. We propose using reinforcement learning to obtain a heuristic function to guide the search in DIDP. We develop two RL-based guidance approaches: value-based guidance using Deep Q-Networks and policy-based guidance using Proximal Policy Optimization. Our experiments indicate that RL-based guidance significantly outperforms standard DIDP and problem-specific greedy heuristics with the same number of node expansions. Further, despite longer node evaluation times, RL guidance achieves better run-time performance than standard DIDP on three of four benchmark domains.', 'abstract_zh': '基于动态规划的领域独立动态规划 (DIDP) 是一种基于动态规划的组合优化状态空间搜索范式。我们提出使用强化学习来获得一种启发式函数以指导DIDP的搜索。我们开发了两种基于强化学习的指导方法：基于深度Q网络的价值函数指导和基于接近策略优化的策略指导。实验表明，基于强化学习的指导显著优于标准DIDP和相同节点扩展次数的问题特定贪婪启发式方法。此外，尽管节点评估时间较长，但基于强化学习的指导在三个基准领域中仍能实现更好的运行时性能。', 'title_zh': '基于强化学习的启发式方法以指导领域无关的动态规划'}
{'arxiv_id': 'arXiv:2503.16348', 'title': 'Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds', 'authors': 'Murray Shanahan', 'link': 'https://arxiv.org/abs/2503.16348', 'abstract': 'Is it possible to articulate a conception of consciousness that is compatible with the exotic characteristics of contemporary, disembodied AI systems, and that can stand up to philosophical scrutiny? How would subjective time and selfhood show up for an entity that conformed to such a conception? Trying to answer these questions, even metaphorically, stretches the language of consciousness to breaking point. Ultimately, the attempt yields something like emptiness, in the Buddhist sense, and helps to undermine our dualistic inclinations towards subjectivity and selfhood.', 'abstract_zh': '当代脱域AI系统之奇特特性与意识观念的兼容性：经哲学审视是否可行？这样一种观念下的主观时间与自我的表现如何？尝试着从这种观念出发，即使是在比喻的意义上，也将意识的语言推向极限。最终，这种尝试呈现出一种类似于佛教意义上的空性，有助于瓦解我们对主观性和自我的二元倾向。', 'title_zh': '可接受的分离存在的观念：未知领域在可能心灵的空间中'}
{'arxiv_id': 'arXiv:2503.16335', 'title': 'Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model', 'authors': 'Seshu Babu Barma, Mohanakrishnan Hariharan, Satish Arvapalli', 'link': 'https://arxiv.org/abs/2503.16335', 'abstract': 'An AI-powered quality engineering platform uses artificial intelligence to boost software quality assessments through automated defect prediction and optimized performance alongside improved feature extraction. Existing models result in difficulties addressing noisy data types together with imbalances, pattern recognition complexities, ineffective feature extraction, and generalization weaknesses. To overcome those existing challenges in this research, we develop a new model Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model (ADE-QVAET), that combines a Quantum Variational Autoencoder-Transformer (QVAET) to obtain high-dimensional latent features and maintain sequential dependencies together with contextual relationships, resulting in superior defect prediction accuracy. Adaptive Differential Evolution (ADE) Optimization utilizes an adaptive parameter tuning method that enhances model convergence and predictive performance. ADE-QVAET integrates advanced AI techniques to create a robust solution for scalable and accurate software defect prediction that represents a top-level AI-driven technology for quality engineering applications. The proposed ADE-QVAET model attains high accuracy, precision, recall, and f1-score during the training percentage (TP) 90 of 98.08%, 92.45%, 94.67%, and 98.12%.', 'abstract_zh': '一种基于AI的质量工程平台通过自动缺陷预测和优化性能来提升软件质量评估，同时改进特征提取。现有模型难以解决噪声数据类型、数据不平衡、模式识别复杂性、无效特征提取和泛化能力弱等问题。为克服这些挑战，我们开发了一种新的模型——自适应差分进化基于量子变分自编码器-转换器模型（ADE-QVAET），该模型结合了量子变分自编码器-转换器（QVAET）以获取高维潜在特征并保持顺序依赖性和上下文关系，从而实现卓越的缺陷预测准确性。自适应差分进化（ADE）优化利用自适应参数调优方法，增强模型收敛性和预测性能。ADE-QVAET结合先进的AI技术，为可扩展和准确的软件缺陷预测提供了稳健的解决方案，并代表了质量工程应用顶级的AI驱动技术。所提出的ADE-QVAET模型在训练百分比（TP）90时达到高精度、精准度、召回率和F1分数分别为98.08%、92.45%、94.67%和98.12%。', 'title_zh': '基于自适应差分进化量子变分自编码-变换模型的软件质量 assurance 提升方法'}
{'arxiv_id': 'arXiv:2503.16326', 'title': 'OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence', 'authors': 'Long Yuan, Fengran Mo, Kaiyu Huang, Wenjie Wang, Wangyuxuan Zhai, Xiaoyu Zhu, You Li, Jinan Xu, Jian-Yun Nie', 'link': 'https://arxiv.org/abs/2503.16326', 'abstract': 'The rapid advancement of multimodal large language models (LLMs) has opened new frontiers in artificial intelligence, enabling the integration of diverse large-scale data types such as text, images, and spatial information. In this paper, we explore the potential of multimodal LLMs (MLLM) for geospatial artificial intelligence (GeoAI), a field that leverages spatial data to address challenges in domains including Geospatial Semantics, Health Geography, Urban Geography, Urban Perception, and Remote Sensing. We propose a MLLM (OmniGeo) tailored to geospatial applications, capable of processing and analyzing heterogeneous data sources, including satellite imagery, geospatial metadata, and textual descriptions. By combining the strengths of natural language understanding and spatial reasoning, our model enhances the ability of instruction following and the accuracy of GeoAI systems. Results demonstrate that our model outperforms task-specific models and existing LLMs on diverse geospatial tasks, effectively addressing the multimodality nature while achieving competitive results on the zero-shot geospatial tasks. Our code will be released after publication.', 'abstract_zh': '多模态大型语言模型在地理空间人工智能领域的潜力：OmniGeo模型的研究', 'title_zh': 'OmniGeo：面向地理空间人工智能的多模态大型语言模型'}
{'arxiv_id': 'arXiv:2503.16307', 'title': 'Speeding up design and making to reduce time-to-project and time-to-market: an AI-Enhanced approach in engineering education', 'authors': 'Giovanni Adorni, Daniele Grosso', 'link': 'https://arxiv.org/abs/2503.16307', 'abstract': 'This paper explores the integration of AI tools, such as ChatGPT and GitHub Copilot, in the Software Architecture for Embedded Systems course. AI-supported workflows enabled students to rapidly prototype complex projects, emphasizing real-world applications like SLAM robotics. Results demon-started enhanced problem-solving, faster development, and more sophisticated outcomes, with AI augmenting but not replacing human decision-making.', 'abstract_zh': '本文探讨了在嵌入式系统课程中整合AI工具（如ChatGPT和GitHub Copilot）的方法。AI支持的工作流程使学生能够快速原型设计复杂项目，强调了诸如SLAM机器人等实际应用。结果显示，这种做法提高了问题解决能力、加快了开发速度，并产生了更为复杂的结果，AI辅助但并未取代人类决策。', 'title_zh': '加快设计与制造以减少项目时间和市场时间：工程教育中的AI增强方法'}
{'arxiv_id': 'arXiv:2503.16203', 'title': 'Logic Explanation of AI Classifiers by Categorical Explaining Functors', 'authors': 'Stefano Fioravanti, Francesco Giannini, Paolo Frazzetto, Fabio Zanasi, Pietro Barbiero', 'link': 'https://arxiv.org/abs/2503.16203', 'abstract': "The most common methods in explainable artificial intelligence are post-hoc techniques which identify the most relevant features used by pretrained opaque models. Some of the most advanced post hoc methods can generate explanations that account for the mutual interactions of input features in the form of logic rules. However, these methods frequently fail to guarantee the consistency of the extracted explanations with the model's underlying reasoning. To bridge this gap, we propose a theoretically grounded approach to ensure coherence and fidelity of the extracted explanations, moving beyond the limitations of current heuristic-based approaches. To this end, drawing from category theory, we introduce an explaining functor which structurally preserves logical entailment between the explanation and the opaque model's reasoning. As a proof of concept, we validate the proposed theoretical constructions on a synthetic benchmark verifying how the proposed approach significantly mitigates the generation of contradictory or unfaithful explanations.", 'abstract_zh': '可解释人工智能中最常见的方法是后 hoc 技术，这些技术识别预训练的不透明模型中最重要的特征。一些最先进的后 hoc 方法可以通过逻辑规则的形式生成解释输入特征相互作用的解释。然而，这些方法常常无法保证提取的解释与模型内部推理的一致性和忠实性。为了解决这一问题，我们提出一种理论支持的方法来确保提取解释的连贯性和忠实性，超越当前基于启发式的方法的限制。为此，我们借鉴范畴论，引入了一个解释泛函，结构上保持解释与不透明模型推理之间的逻辑蕴含。作为概念验证，我们在一个合成基准上验证了所提出理论构造的有效性，证明了该方法显著减少了生成矛盾或不忠实解释的情况。', 'title_zh': '由范畴解释函子提供的AI分类器逻辑解释'}
{'arxiv_id': 'arXiv:2503.16191', 'title': 'Large Language Models for Water Distribution Systems Modeling and Decision-Making', 'authors': 'Yinon Goldshtein, Gal Perelman, Assaf Schuster, Avi Ostfeld', 'link': 'https://arxiv.org/abs/2503.16191', 'abstract': 'The design, operations, and management of water distribution systems (WDS) involve complex mathematical models. These models are continually improving due to computational advancements, leading to better decision-making and more efficient WDS management. However, the significant time and effort required for modeling, programming, and analyzing results remain substantial challenges. Another issue is the professional burden, which confines the interaction with models, databases, and other sophisticated tools to a small group of experts, thereby causing non-technical stakeholders to depend on these experts or make decisions without modeling support. Furthermore, explaining model results is challenging even for experts, as it is often unclear which conditions cause the model to reach a certain state or recommend a specific policy. The recent advancements in Large Language Models (LLMs) open doors for a new stage in human-model interaction. This study proposes a framework of plain language interactions with hydraulic and water quality models based on LLM-EPANET architecture. This framework is tested with increasing levels of complexity of queries to study the ability of LLMs to interact with WDS models, run complex simulations, and report simulation results. The performance of the proposed framework is evaluated across several categories of queries and hyper-parameter configurations, demonstrating its potential to enhance decision-making processes in WDS management.', 'abstract_zh': '基于LLM-EPANET架构的水流与水质模型自然语言交互框架设计、运行与管理', 'title_zh': '大型语言模型在水分配系统建模与决策中的应用'}
{'arxiv_id': 'arXiv:2503.16041', 'title': 'GreenIQ: A Deep Search Platform for Comprehensive Carbon Market Analysis and Automated Report Generation', 'authors': 'Bisola Faith Kayode, Akinyemi Sadeeq Akintola, Oluwole Fagbohun, Egonna Anaesiuba-Bristol, Onyekachukwu Ojumah, Oluwagbade Odimayo, Toyese Oloyede, Aniema Inyang, Teslim Kazeem, Habeeb Alli, Udodirim Ibem Offia, Prisca Chinazor Amajuoyi', 'link': 'https://arxiv.org/abs/2503.16041', 'abstract': 'This study introduces GreenIQ, an AI-powered deep search platform designed to revolutionise carbon market intelligence through autonomous analysis and automated report generation. Carbon markets operate across diverse regulatory landscapes, generating vast amounts of heterogeneous data from policy documents, industry reports, academic literature, and real-time trading platforms. Traditional research approaches remain labour-intensive, slow, and difficult to scale. GreenIQ addresses these limitations through a multi-agent architecture powered by Large Language Models (LLMs), integrating five specialised AI agents: a Main Researcher Agent for intelligent information retrieval, a Report Writing Agent for structured synthesis, a Final Reviewer Agent for accuracy verification, a Data Visualisation Agent for enhanced interpretability, and a Translator Agent for multilingual adaptation. The system achieves seamless integration of structured and unstructured information with AI-driven citation verification, ensuring high transparency and reliability. GreenIQ delivers a 99.2\\% reduction in processing time and a 99.7\\% cost reduction compared to traditional research methodologies. A novel AI persona-based evaluation framework involving 16 domain-specific AI personas highlights its superior cross-jurisdictional analytical capabilities and regulatory insight generation. GreenIQ sets new standards in AI-driven research synthesis, policy analysis, and sustainability finance by streamlining carbon market research. It offers an efficient and scalable framework for environmental and financial intelligence, enabling more accurate, timely, and cost-effective decision-making in complex regulatory landscapes', 'abstract_zh': 'GreenIQ：一种基于AI的深度搜索平台，通过自主分析和自动化报告生成重塑碳市场智能', 'title_zh': 'GreenIQ：综合碳市场分析与自动化报告生成的深度搜索平台'}
{'arxiv_id': 'arXiv:2503.15985', 'title': 'Exploring the Reliability of Self-explanation and its Relationship with Classification in Language Model-driven Financial Analysis', 'authors': 'Han Yuan, Li Zhang, Zheng Ma', 'link': 'https://arxiv.org/abs/2503.15985', 'abstract': 'Language models (LMs) have exhibited exceptional versatility in reasoning and in-depth financial analysis through their proprietary information processing capabilities. Previous research focused on evaluating classification performance while often overlooking explainability or pre-conceived that refined explanation corresponds to higher classification accuracy. Using a public dataset in finance domain, we quantitatively evaluated self-explanations by LMs, focusing on their factuality and causality. We identified the statistically significant relationship between the accuracy of classifications and the factuality or causality of self-explanations. Our study built an empirical foundation for approximating classification confidence through self-explanations and for optimizing classification via proprietary reasoning.', 'abstract_zh': '语言模型在金融领域的推理和深入分析中通过其专有信息处理能力展示了卓越的灵活性和深度。先前的研究集中在评估分类性能上，往往忽视了解释性或预设精心解释与更高分类准确性的对应关系。使用金融领域的公共数据集，我们定量评估了语言模型的自我解释，重点在于其事实性和因果性。我们发现了分类准确性和自我解释的事实性或因果性之间的统计显著关系。我们的研究为通过自我解释逼近分类置信度以及通过专有推理优化分类奠定了实证基础。', 'title_zh': '探索自我解释的可靠性及其与语言模型驱动财务分析分类的关系'}
{'arxiv_id': 'arXiv:2503.15947', 'title': 'Unreal-MAP: Unreal-Engine-Based General Platform for Multi-Agent Reinforcement Learning', 'authors': 'Tianyi Hu, Qingxu Fu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu', 'link': 'https://arxiv.org/abs/2503.15947', 'abstract': 'In this paper, we propose Unreal Multi-Agent Playground (Unreal-MAP), an MARL general platform based on the Unreal-Engine (UE). Unreal-MAP allows users to freely create multi-agent tasks using the vast visual and physical resources available in the UE community, and deploy state-of-the-art (SOTA) MARL algorithms within them. Unreal-MAP is user-friendly in terms of deployment, modification, and visualization, and all its components are open-source. We also develop an experimental framework compatible with algorithms ranging from rule-based to learning-based provided by third-party frameworks. Lastly, we deploy several SOTA algorithms in example tasks developed via Unreal-MAP, and conduct corresponding experimental analyses. We believe Unreal-MAP can play an important role in the MARL field by closely integrating existing algorithms with user-customized tasks, thus advancing the field of MARL.', 'abstract_zh': '基于Unreal-Engine的Unreal多智能体 playground (Unreal-MAP)：一个多智能体强化学习通用平台', 'title_zh': 'Unreal-MAP：基于UnrealEngine的多 agents 强化学习通用平台'}
{'arxiv_id': 'arXiv:2503.15937', 'title': 'Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment', 'authors': 'Gaole Dai, Shiqi Jiang, Ting Cao, Yuanchun Li, Yuqing Yang, Rui Tan, Mo Li, Lili Qiu', 'link': 'https://arxiv.org/abs/2503.15937', 'abstract': "We propose V-Droid, a mobile GUI task automation agent. Unlike previous mobile agents that utilize Large Language Models (LLMs) as generators to directly generate actions at each step, V-Droid employs LLMs as verifiers to evaluate candidate actions before making final decisions. To realize this novel paradigm, we introduce a comprehensive framework for constructing verifier-driven mobile agents: the discretized action space construction coupled with the prefilling-only workflow to accelerate the verification process, the pair-wise progress preference training to significantly enhance the verifier's decision-making capabilities, and the scalable human-agent joint annotation scheme to efficiently collect the necessary data at scale. V-Droid sets a new state-of-the-art task success rate across several public mobile task automation benchmarks: 59.5% on AndroidWorld, 38.3% on AndroidLab, and 49% on MobileAgentBench, surpassing existing agents by 9.5%, 2.1%, and 9%, respectively. Furthermore, V-Droid achieves an impressively low latency of 0.7 seconds per step, making it the first mobile agent capable of delivering near-real-time, effective decision-making capabilities.", 'abstract_zh': '我们提出V-Droid，一种移动GUI任务自动化代理。', 'title_zh': '移动GUI代理的发展：基于验证者的实际部署方法'}
{'arxiv_id': 'arXiv:2503.15876', 'title': 'DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System', 'authors': 'Kai Chen, Zebing Sun', 'link': 'https://arxiv.org/abs/2503.15876', 'abstract': 'This paper introduces DeepPsy-Agent, an innovative psychological support system that combines the three-stage helping theory in psychology with deep learning techniques. The system consists of two core components: (1) a multi-stage response-capable dialogue model (\\textit{deeppsy-chat}), which enhances reasoning capabilities through stage-awareness and deep-thinking analysis to generate high-quality responses; and (2) a real-time stage transition detection model that identifies contextual shifts to guide the dialogue towards more effective intervention stages. Based on 30,000 real psychological hotline conversations, we employ AI-simulated dialogues and expert re-annotation strategies to construct a high-quality multi-turn dialogue dataset. Experimental results demonstrate that DeepPsy-Agent outperforms general-purpose large language models (LLMs) in key metrics such as problem exposure completeness, cognitive restructuring success rate, and action adoption rate. Ablation studies further validate the effectiveness of stage-awareness and deep-thinking modules, showing that stage information contributes 42.3\\% to performance, while the deep-thinking module increases root-cause identification by 58.3\\% and reduces ineffective suggestions by 72.1\\%. This system addresses critical challenges in AI-based psychological support through dynamic dialogue management and deep reasoning, advancing intelligent mental health services.', 'abstract_zh': 'DeepPsy-Agent：一种结合心理支持三阶段理论与深度学习的心理支持系统', 'title_zh': 'DeepPsy-Agent: 一个阶段意识和深度思考的情感支持代理系统'}
{'arxiv_id': 'arXiv:2503.15848', 'title': 'Entropy-based Exploration Conduction for Multi-step Reasoning', 'authors': 'Jinghan Zhang, Xiting Wang, Fengran Mo, Yeyang Zhou, Wanfu Gao, Kunpeng Liu', 'link': 'https://arxiv.org/abs/2503.15848', 'abstract': "In large language model (LLM) reasoning, multi-step processes have proven effective for solving complex tasks. However, the depth of exploration can significantly affect the reasoning performance. Existing methods to automatically decide the depth often bring high costs and lack flexibility, and thus undermine the model's reasoning accuracy. To address these issues, we propose Entropy-based Exploration Depth Conduction (Entro-duction), a novel method that dynamically adjusts the exploration depth during multi-step reasoning by monitoring LLM's output entropy and variance entropy. We employ these two metrics to capture the model's current uncertainty and the fluctuation of uncertainty across consecutive reasoning steps. Based on the observed changes, the LLM selects whether to deepen, expand or stop exploration according to the probability. In this way, we balance the reasoning accuracy and exploration effectiveness. Experimental results across four benchmark datasets demonstrate the efficacy of Entro-duction. We further conduct experiments and analysis on the components of Entro-duction to discuss their contributions to reasoning performance.", 'abstract_zh': '基于熵的推理深度调控（熵导引）：一种多步推理中动态调整探索深度的新方法', 'title_zh': '基于熵的多步推理探索引导'}
{'arxiv_id': 'arXiv:2503.15847', 'title': 'Beyond Local Selection: Global Cut Selection for Enhanced Mixed-Integer Programming', 'authors': 'Shuli Zeng, Sijia Zhang, Shaoang Li, Feng Wu, Xiang-Yang Li', 'link': 'https://arxiv.org/abs/2503.15847', 'abstract': 'In mixed-integer programming (MIP) solvers, cutting planes are essential for Branch-and-Cut (B&C) algorithms as they reduce the search space and accelerate the solving process. Traditional methods rely on hard-coded heuristics for cut plane selection but fail to leverage problem-specific structural features. Recent machine learning approaches use neural networks for cut selection but focus narrowly on the efficiency of single-node within the B&C algorithm, without considering the broader contextual information. To address this, we propose Global Cut Selection (GCS), which uses a bipartite graph to represent the search tree and combines graph neural networks with reinforcement learning to develop cut selection strategies. Unlike prior methods, GCS applies cutting planes across all nodes, incorporating richer contextual information. Experiments show GCS significantly improves solving efficiency for synthetic and large-scale real-world MIPs compared to traditional and learning-based methods.', 'abstract_zh': '全局割选择（GCS）：基于图神经网络和强化学习的割选择方法', 'title_zh': '超越局部选择：全局割选择以增强混合整数规划'}
{'arxiv_id': 'arXiv:2503.15817', 'title': 'Ranking Counterfactual Explanations', 'authors': 'Suryani Lim, Henri Prade, Gilles Richard', 'link': 'https://arxiv.org/abs/2503.15817', 'abstract': 'AI-driven outcomes can be challenging for end-users to understand. Explanations can address two key questions: "Why this outcome?" (factual) and "Why not another?" (counterfactual). While substantial efforts have been made to formalize factual explanations, a precise and comprehensive study of counterfactual explanations is still lacking. This paper proposes a formal definition of counterfactual explanations, proving some properties they satisfy, and examining the relationship with factual explanations. Given that multiple counterfactual explanations generally exist for a specific case, we also introduce a rigorous method to rank these counterfactual explanations, going beyond a simple minimality condition, and to identify the optimal ones. Our experiments with 12 real-world datasets highlight that, in most cases, a single optimal counterfactual explanation emerges. We also demonstrate, via three metrics, that the selected optimal explanation exhibits higher representativeness and can explain a broader range of elements than a random minimal counterfactual. This result highlights the effectiveness of our approach in identifying more robust and comprehensive counterfactual explanations.', 'abstract_zh': 'AI驱动的成果对终端用户来说可能难以理解。解释可以解决两个关键问题：“为什么是这个结果？”（事实性）和“为什么不是另一个？”（反事实性）。尽管在形式化事实性解释方面已做出了大量努力，但对反事实性解释的精确和全面研究仍显不足。本文提出了反事实解释的形式化定义，证明了它们满足的一些性质，并探讨了它们与事实性解释的关系。由于特定情况下通常存在多个反事实解释，我们还介绍了一种严谨的方法来对这些反事实解释进行排序，超越了简单的最小性条件，以识别最优的解释。我们的实验结果表明，在大多数情况下，会涌现出一个最优的反事实解释。我们还通过三个指标展示了所选的最优解释具有更高的代表性和可以解释更广泛的元素，不同于随机的最小反事实。这一结果突显了我们方法在识别更稳健和全面的反事实解释方面的有效性。', 'title_zh': '-counterfactual 解释的排名'}
{'arxiv_id': 'arXiv:2503.15815', 'title': 'Attention Pruning: Automated Fairness Repair of Language Models via Surrogate Simulated Annealing', 'authors': 'Vishnu Asutosh Dasu, Md Rafi ur Rashid, Vipul Gupta, Saeid Tizpaz-Niari, Gang Tan', 'link': 'https://arxiv.org/abs/2503.15815', 'abstract': "This paper explores pruning attention heads as a post-processing bias mitigation method for large language models (LLMs). Modern AI systems such as LLMs are expanding into sensitive social contexts where fairness concerns become especially crucial. Since LLMs develop decision-making patterns by training on massive datasets of human-generated content, they naturally encode and perpetuate societal biases. While modifying training datasets and algorithms is expensive and requires significant resources; post-processing techniques-such as selectively deactivating neurons and attention heads in pre-trained LLMs-can provide feasible and effective approaches to improve fairness. However, identifying the optimal subset of parameters to prune presents a combinatorial challenge within LLMs' immense parameter space, requiring solutions that efficiently balance competing objectives across the frontiers of model fairness and utility.\nTo address the computational challenges, we explore a search-based program repair approach via randomized simulated annealing. Given the prohibitive evaluation costs in billion-parameter LLMs, we develop surrogate deep neural networks that efficiently model the relationship between attention head states (active/inactive) and their corresponding fairness/utility metrics. This allows us to perform optimization over the surrogate models and efficiently identify optimal subsets of attention heads for selective pruning rather than directly searching through the LLM parameter space. This paper introduces Attention Pruning, a fairness-aware surrogate simulated annealing approach to prune attention heads in LLMs that disproportionately contribute to bias while minimally impacting overall model utility. Our experiments show that Attention Pruning achieves up to $40\\%$ reduction in gender bias and outperforms the state-of-the-art bias mitigation strategies.", 'abstract_zh': '本文探索剪枝注意力头作为大型语言模型（LLMs）后处理偏见缓解方法的可能。现代人工智能系统如LLMs正逐步进入敏感的社会情境中，在这些情境中公平性问题尤为重要。由于LLMs通过大规模的人类生成内容训练而形成决策模式，它们自然会编码并延续社会偏见。虽然修改训练数据集和算法成本高昂且需要大量资源，但后处理技术（如在预训练LLMs中选择性地禁用神经元和注意力头）可以提供一种可行有效的提高公平性的方法。然而，在LLMs巨大的参数空间中确定要剪枝的最优参数子集是一个组合优化难题，需要能够高效平衡模型公平性和实用性之间竞争目标的解决方案。\n\n为应对计算挑战，我们通过随机模拟退火方法探索基于搜索的程序修复方法。鉴于在十亿参数级LLMs中的评估成本高昂，我们开发了代理深度神经网络来高效建模注意力头状态（激活/非激活）与其相应的公平性/实用性指标之间的关系，从而可以在代理模型上进行优化，并高效识别出选择性剪枝的最优注意力头子集，而不是直接在LLM参数空间中进行搜索。本文提出了注意力剪枝（Attention Pruning）方法，这是一种具备公平性意识的代理模拟退火方法，用于剪枝那些不对等加剧偏见但仍能最大限度保持模型总体实用性的注意力头。实验结果表明，注意力剪枝可实现高达40%的性别偏见减少，并优于最先进的偏见缓解策略。', 'title_zh': '注意力剪枝：通过代理模拟退火实现语言模型的自动化公平性修复'}
{'arxiv_id': 'arXiv:2503.15807', 'title': 'Video-VoT-R1: An efficient video inference model integrating image packing and AoE architecture', 'authors': 'Cheng Li, Jiexiong Liu, Yixuan Chen, Yanqin Jia', 'link': 'https://arxiv.org/abs/2503.15807', 'abstract': 'In the field of video-language pretraining, existing models face numerous challenges in terms of inference efficiency and multimodal data processing. This paper proposes a KunLunBaize-VoT-R1 video inference model based on a long-sequence image encoder, along with its training and application methods. By integrating image packing technology, the Autonomy-of-Experts (AoE) architecture, and combining the video of Thought (VoT), a large language model (LLM) trained with large-scale reinforcement learning, and multiple training techniques, the efficiency and accuracy of the model in video inference tasks are effectively improved. Experiments show that this model performs outstandingly in multiple tests, providing a new solution for video-language understanding.', 'abstract_zh': '在视频语言预训练领域，现有模型在推理效率和多模态数据处理方面面临诸多挑战。本文提出了一种基于长序列图像编码器的KunLunBaize-VoT-R1视频推理模型及其训练与应用方法。通过整合图像封装技术、Autonomy-of-Experts (AoE) 架构，并结合思辨视频（VoT）、大规模强化学习训练的大语言模型（LLM）以及多种训练技术，有效提升了模型在视频推理任务中的效率和准确性。实验结果表明，该模型在多项测试中表现出色，为视频语言理解提供了一种新的解决方案。', 'title_zh': 'Video-VoT-R1：一种结合图像打包和AoE架构的高效视频推理模型'}
{'arxiv_id': 'arXiv:2503.15762', 'title': 'Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to Personalized Educational Content Generation', 'authors': 'Elena Malnatsky, Shenghui Wang, Koen V. Hindriks, Mike E.U. Ligthart', 'link': 'https://arxiv.org/abs/2503.15762', 'abstract': 'Dialogic learning fosters motivation and deeper understanding in education through purposeful and structured dialogues. Foundational models offer a transformative potential for child-robot interactions, enabling the design of personalized, engaging, and scalable interactions. However, their integration into educational contexts presents challenges in terms of ensuring age-appropriate and safe content and alignment with pedagogical goals. We introduce a hybrid approach to designing personalized educational dialogues in child-robot interactions. By combining rule-based systems with LLMs for selective offline content generation and human validation, the framework ensures educational quality and developmental appropriateness. We illustrate this approach through a project aimed at enhancing reading motivation, in which a robot facilitated book-related dialogues.', 'abstract_zh': '对话式学习通过有目的和结构化的对话促进动机和深层次理解。基础模型为儿童与机器人互动提供了变革性的潜力，使之成为个性化、 engaging 和可扩展的互动设计的基础。然而，将这些模型整合到教育环境中，确保内容适合年龄和安全，并与教学目标一致，存在挑战。我们提出了一种混合方法，用于设计儿童与机器人互动中的个性化教育对话。通过将基于规则的系统与大语言模型结合，用于选择性地离线生成内容并进行人工验证，该框架确保了教育质量和发展适宜性。我们通过一个旨在增强阅读动机的项目，展示了这种方法，在该项目中，机器人促进了与图书相关的话题讨论。', 'title_zh': '儿童与机器人互动的对话式学习：个性化教育内容生成的混合方法'}
{'arxiv_id': 'arXiv:2503.15752', 'title': 'Using Language Models to Decipher the Motivation Behind Human Behaviors', 'authors': 'Yutong Xie, Qiaozhu Mei, Walter Yuan, Matthew O. Jackson', 'link': 'https://arxiv.org/abs/2503.15752', 'abstract': 'AI presents a novel tool for deciphering the motivations behind human behaviors. We show that by varying prompts to a large language model, we can elicit a full range of human behaviors in a variety of different scenarios in terms of classic economic games. Then by analyzing which prompts are needed to elicit which behaviors, we can infer (decipher) the motivations behind the human behaviors. We also show how one can analyze the prompts to reveal relationships between the classic economic games, providing new insight into what different economic scenarios induce people to think about. We also show how this deciphering process can be used to understand differences in the behavioral tendencies of different populations.', 'abstract_zh': 'AI为解码人类行为背后的动机提供了新型工具。我们展示了通过调整对大型语言模型的提示，可以在多种经典经济博弈场景中引出人类行为的全方位展现。通过分析哪种提示能够引出哪种行为，我们可以推断出人类行为背后的动机。我们还展示了如何通过分析提示来揭示经典经济博弈之间的关系，提供了对不同经济场景如何影响人们思维的新见解。我们还说明了这种解码过程可以用来理解不同人群行为倾向的差异。', 'title_zh': '使用语言模型解析人类行为背后的动机'}
{'arxiv_id': 'arXiv:2503.15739', 'title': 'ECLAIR: Enhanced Clarification for Interactive Responses', 'authors': 'John Murzaku, Zifan Liu, Md Mehrab Tanjim, Vaishnavi Muppala, Xiang Chen, Yunyao Li', 'link': 'https://arxiv.org/abs/2503.15739', 'abstract': "We present ECLAIR (Enhanced CLArification for Interactive Responses), a novel unified and end-to-end framework for interactive disambiguation in enterprise AI assistants. ECLAIR generates clarification questions for ambiguous user queries and resolves ambiguity based on the user's this http URL introduce a generalized architecture capable of integrating ambiguity information from multiple downstream agents, enhancing context-awareness in resolving ambiguities and allowing enterprise specific definition of agents. We further define agents within our system that provide domain-specific grounding information. We conduct experiments comparing ECLAIR to few-shot prompting techniques and demonstrate ECLAIR's superior performance in clarification question generation and ambiguity resolution.", 'abstract_zh': 'ECLAIR：增强的交互澄清框架以实现企业AI助理的交互去模糊处理', 'title_zh': 'ECLAIR: 增强的交互式响应澄清方法'}
{'arxiv_id': 'arXiv:2503.15726', 'title': 'Reinforcement Learning Environment with LLM-Controlled Adversary in D&D 5th Edition Combat', 'authors': 'Joseph Emmanuel DL Dayo, Michel Onasis S. Ogbinar, Prospero C. Naval Jr', 'link': 'https://arxiv.org/abs/2503.15726', 'abstract': 'The objective of this study is to design and implement a reinforcement learning (RL) environment using D\\&D 5E combat scenarios to challenge smaller RL agents through interaction with a robust adversarial agent controlled by advanced Large Language Models (LLMs) like GPT-4o and LLaMA 3 8B. This research employs Deep Q-Networks (DQN) for the smaller agents, creating a testbed for strategic AI development that also serves as an educational tool by simulating dynamic and unpredictable combat scenarios. We successfully integrated sophisticated language models into the RL framework, enhancing strategic decision-making processes. Our results indicate that while RL agents generally outperform LLM-controlled adversaries in standard metrics, the strategic depth provided by LLMs significantly enhances the overall AI capabilities in this complex, rule-based setting. The novelty of our approach and its implications for mastering intricate environments and developing adaptive strategies are discussed, alongside potential innovations in AI-driven interactive simulations. This paper aims to demonstrate how integrating LLMs can create more robust and adaptable AI systems, providing valuable insights for further research and educational applications.', 'abstract_zh': '本研究旨在通过使用D&D 5E战斗场景设计并实现一个强化学习（RL）环境，挑战较小的RL代理，使其通过与由先进大规模语言模型（LLMs）如GPT-4o和LLaMA 3 8B控制的强大对抗代理进行交互来提升实力。本研究采用深度Q网络（DQN）为较小的代理设计模型，为战略AI的发展提供了一个测试平台，同时也作为教育工具通过模拟动态和不可预测的战斗场景。我们成功将复杂的语言模型集成到RL框架中，增强了战略决策过程。我们的结果显示，虽然RL代理在标准指标上通常优于由LLM控制的对手，但LLM提供的战略深度显著提升了这一复杂、规则基础设置中的整体AI能力。本文讨论了本方法的创新性及其对掌握复杂环境和开发适应性策略的影响，并探讨了AI驱动的交互模拟潜在创新。本文旨在展示如何将LLM集成到RL系统中，以创建更为 robust 和适应性强的AI系统，并为进一步研究和教育应用提供宝贵的见解。', 'title_zh': '基于LLM控制对手的《 Dungeons & Dragons 5e 战斗》强化学习环境'}
{'arxiv_id': 'arXiv:2503.15655', 'title': 'R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs', 'authors': 'Zefeng Lin, Yi Xiao, Zhiqiang Mo, Qifan Zhang, Jie Wang, Jiayang Chen, Jiajing Zhang, Hui Zhang, Zhengyi Liu, Xianyong Fang, Xiaohua Xu', 'link': 'https://arxiv.org/abs/2503.15655', 'abstract': 'Automatically adapting novels into screenplays is important for the TV, film, or opera industries to promote products with low costs. The strong performances of large language models (LLMs) in long-text generation call us to propose a LLM based framework Reader-Rewriter (R$^2$) for this task. However, there are two fundamental challenges here. First, the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second, the causality-embedded plot lines should be effectively extracted for coherent rewriting. Therefore, two corresponding tactics are proposed: 1) A hallucination-aware refinement method (HAR) to iteratively discover and eliminate the affections of hallucinations; and 2) a causal plot-graph construction method (CPC) based on a greedy cycle-breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques, R$^2$ utilizes two modules to mimic the human screenplay rewriting process: The Reader module adopts a sliding window and CPC to build the causal plot graphs, while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R$^2$, which substantially outperforms three existing approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison at the overall win rate for GPT-4o.', 'abstract_zh': '自动适应小说改编为剧本对于电视、电影或歌剧行业以低成本推广产品至关重要。大型语言模型（LLMs）在长文本生成方面的出色表现促使我们提出一种基于LLMs的框架Reader-Rewriter（R$^2$），用于此任务。然而，这里有两个根本性的挑战。首先，LLMs可能会导致情节提取和剧本生成不一致。其次，需要有效提取嵌入因果关系的情节线以实现连贯的重写。为此，提出了相应的策略：1）一种意识幻觉修正方法（HAR），通过迭代发现并消除幻觉的影响；2）基于贪婪循环中断算法的因果情节图构建方法（CPC），以有效构建具有事件因果关系的情节线。结合这些高效技术，R$^2$通过两个模块模拟人类剧本重写过程：Reader模块采用滑动窗口和CPC构建因果情节图，而Rewriter模块基于这些图生成场景大纲和剧本。HAR被集成到两个模块中，以实现对LLMs准确的推理。实验结果表明，R$^2$在GPT-4o的整体胜率对三个现有方法的比较中表现出显著优势（绝对提高率分别为51.3%、22.6%和57.1%）。', 'title_zh': 'R$^2$: 一个基于LLM的新 novel 到剧本生成框架，包含因果情节图'}
{'arxiv_id': 'arXiv:2503.15580', 'title': 'How Well Can AI Build SD Models?', 'authors': "William Schoenberg, Davidson Girard, Saras Chung, Ellen O'Neill, Janet Velasquez, Sara Metcalf", 'link': 'https://arxiv.org/abs/2503.15580', 'abstract': 'Introduction: As system dynamics (SD) embraces automation, AI offers efficiency but risks bias from missing data and flawed models. Models that omit multiple perspectives and data threaten model quality, whether created by humans or with the assistance of AI. To reduce uncertainty about how well AI can build SD models, we introduce two metrics for evaluation of AI-generated causal maps: technical correctness (causal translation) and adherence to instructions (conformance).\nApproach: We developed an open source project called sd-ai to provide a basis for collaboration in the SD community, aiming to fully harness the potential of AI based tools like ChatGPT for dynamic modeling. Additionally, we created an evaluation theory along with a comprehensive suite of tests designed to evaluate any such tools developed within the sd-ai ecosystem.\nResults: We tested 11 different LLMs on their ability to do causal translation as well as conform to user instruction. gpt-4.5-preview was the top performer, scoring 92.9% overall, excelling in both tasks. o1 scored 100% in causal translation. gpt-4o identified all causal links but struggled with positive polarity in decreasing terms. While gpt-4.5-preview and o1 are most accurate, gpt-4o is the cheapest.\nDiscussion: Causal translation and conformance tests applied to the sd-ai engine reveal significant variations across lLLMs, underscoring the need for continued evaluation to ensure responsible development of AI tools for dynamic modeling. To address this, an open collaboration among tool developers, modelers, and stakeholders is launched to standardize measures for evaluating the capacity of AI tools to improve the modeling process.', 'abstract_zh': '引言：随着系统动力学（SD）采用自动化，AI提供了效率但带来了由于缺少数据和模型缺陷导致的偏差风险。忽略多个视角和数据的模型都会威胁到模型质量，无论这些模型是人为创建的还是借助AI创建的。为减少对AI能否有效构建SD模型的不确定，我们引入了两个评估AI生成因果图的指标：技术正确性（因果转换）和遵循指令（符合性）。\n\n方法：我们开发了一个开源项目sd-ai，旨在为系统动力学社区提供合作基础，旨在充分利用基于AI的工具（如ChatGPT）在动态建模方面的潜力。此外，我们还创建了评价理论，并构建了一整套测试，旨在评估sd-ai生态系统内开发的所有此类工具。\n\n结果：我们测试了11种不同的LLM，评估其在因果转换以及遵循用户指令方面的能力。gpt-4.5-preview表现最佳，总体得分为92.9%，在两项任务中均表现出色。o1在因果转换中得分为100%。gpt-4o识别了所有因果关系但在线性减少术语中遇到困难。尽管gpt-4.5-preview和o1最准确，但gpt-4o是最经济的选择。\n\n讨论：应用于sd-ai引擎的因果转换和符合性测试揭示了各种LLM之间存在显著差异，突显了继续评估以确保负责任开发用于动态建模的AI工具的重要性。为此，我们启动了一次开放合作，包括工具开发者、模型构建者和利益相关者之间的合作，以标准化评估AI工具在提高建模过程能力方面的标准。', 'title_zh': 'AI能够构建SD模型到什么程度？'}
{'arxiv_id': 'arXiv:2503.15558', 'title': 'Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning', 'authors': 'NVIDIA, Alisson Azzolini, Hannah Brandon, Prithvijit Chattopadhyay, Huayu Chen, Jinju Chu, Yin Cui, Jenna Diamond, Yifan Ding, Francesco Ferroni, Rama Govindaraju, Jinwei Gu, Siddharth Gururani, Imad El Hanafi, Zekun Hao, Jacob Huffman, Jingyi Jin, Brendan Johnson, Rizwan Khan, George Kurian, Elena Lantz, Nayeon Lee, Zhaoshuo Li, Xuan Li, Tsung-Yi Lin, Yen-Chen Lin, Ming-Yu Liu, Andrew Mathau, Yun Ni, Lindsey Pavao, Wei Ping, David W. Romero, Misha Smelyanskiy, Shuran Song, Lyne Tchapmi, Andrew Z. Wang, Boxin Wang, Haoxiang Wang, Fangyin Wei, Jiashu Xu, Yao Xu, Xiaodong Yang, Zhuolin Yang, Xiaohui Zeng, Zhe Zhang', 'link': 'https://arxiv.org/abs/2503.15558', 'abstract': 'Physical AI systems need to perceive, understand, and perform complex actions in the physical world. In this paper, we present the Cosmos-Reason1 models that can understand the physical world and generate appropriate embodied decisions (e.g., next step action) in natural language through long chain-of-thought reasoning processes. We begin by defining key capabilities for Physical AI reasoning, with a focus on physical common sense and embodied reasoning. To represent physical common sense, we use a hierarchical ontology that captures fundamental knowledge about space, time, and physics. For embodied reasoning, we rely on a two-dimensional ontology that generalizes across different physical embodiments. Building on these capabilities, we develop two multimodal large language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B. We curate data and train our models in four stages: vision pre-training, general supervised fine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL) as the post-training. To evaluate our models, we build comprehensive benchmarks for physical common sense and embodied reasoning according to our ontologies. Evaluation results show that Physical AI SFT and reinforcement learning bring significant improvements. To facilitate the development of Physical AI, we will make our code and pre-trained models available under the NVIDIA Open Model License at this https URL.', 'abstract_zh': '物理AI系统需要在物理世界中感知、理解和执行复杂的动作。本文介绍了能够理解物理世界并通过长链条思考推理过程生成适当的实体化决策（如下一步行动）的Cosmos-Reason1模型。我们首先定义了物理AI推理的关键能力，重点关注物理常识和实体化推理。为了表示物理常识，我们使用了一个层级ontology来捕捉关于空间、时间和物理的基础知识。对于实体化推理，我们依赖一个二维ontology，在不同的物理实体上进行泛化。基于这些能力，我们开发了两个多模态大型语言模型：Cosmos-Reason1-8B和Cosmos-Reason1-56B。我们按照四个阶段整理数据并训练我们的模型：视觉预训练、通用监督微调（SFT）、物理AI微调和物理AI强化学习（RL）作为后训练。为了评估我们的模型，我们根据我们的ontology构建了全面的物理常识和实体化推理基准。评估结果显示，物理AI微调和强化学习带来了显著改进。为了促进物理AI的发展，我们将按照NVIDIA开源模型许可证在此提供的代码和预训练模型开源。', 'title_zh': 'Cosmos-Reason1: 从物理常识到具身推理'}
{'arxiv_id': 'arXiv:2503.16421', 'title': 'MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance', 'authors': 'Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Qi Dai, Zuxuan Wu', 'link': 'https://arxiv.org/abs/2503.16421', 'abstract': 'Recent advances in video generation have led to remarkable improvements in visual quality and temporal coherence. Upon this, trajectory-controllable video generation has emerged to enable precise object motion control through explicitly defined spatial paths. However, existing methods struggle with complex object movements and multi-object motion control, resulting in imprecise trajectory adherence, poor object consistency, and compromised visual quality. Furthermore, these methods only support trajectory control in a single format, limiting their applicability in diverse scenarios. Additionally, there is no publicly available dataset or benchmark specifically tailored for trajectory-controllable video generation, hindering robust training and systematic evaluation. To address these challenges, we introduce MagicMotion, a novel image-to-video generation framework that enables trajectory control through three levels of conditions from dense to sparse: masks, bounding boxes, and sparse boxes. Given an input image and trajectories, MagicMotion seamlessly animates objects along defined trajectories while maintaining object consistency and visual quality. Furthermore, we present MagicData, a large-scale trajectory-controlled video dataset, along with an automated pipeline for annotation and filtering. We also introduce MagicBench, a comprehensive benchmark that assesses both video quality and trajectory control accuracy across different numbers of objects. Extensive experiments demonstrate that MagicMotion outperforms previous methods across various metrics. Our project page are publicly available at this https URL.', 'abstract_zh': '近期在视频生成方面的进展显著提升了视觉质量和时间连贯性。在此基础上，轨迹可控的视频生成技术应运而生，能够通过明确定义的空间路径实现精确的物体运动控制。然而，现有方法在处理复杂的物体运动和多物体运动控制时存在困难，导致轨迹遵从不精确、物体一致性差以及视觉质量下降。此外，这些方法仅支持单一格式的轨迹控制，限制了它们在不同场景中的应用。同时，缺乏专门针对轨迹可控视频生成的公开数据集和基准，阻碍了稳健训练和系统评估。为了解决这些问题，我们提出MagicMotion，这是一种新颖的图像到视频生成框架，能够通过从密集到稀疏的三个条件层次实现轨迹控制：掩码、边界框和稀疏盒。给定输入图像和轨迹，MagicMotion能够无缝地沿定义的轨迹动画化物体，同时保持物体一致性和视觉质量。此外，我们还提供了MagicData，这是一个大规模的轨迹可控视频数据集，并提出了一种自动注释和过滤管道。我们还引入了MagicBench，这是一种综合基准，评估不同物体数量下的视频质量和轨迹控制准确性。大量实验表明，MagicMotion在多种度量标准上优于先前的方法。我们的项目页面在此网址公开：这个 https URL。', 'title_zh': 'MagicMotion：基于密集到稀疏轨迹指导的可控视频生成'}
{'arxiv_id': 'arXiv:2503.16412', 'title': 'DreamTexture: Shape from Virtual Texture with Analysis by Augmentation', 'authors': 'Ananta R. Bhattarai, Xingzhe He, Alla Sheffer, Helge Rhodin', 'link': 'https://arxiv.org/abs/2503.16412', 'abstract': 'DreamFusion established a new paradigm for unsupervised 3D reconstruction from virtual views by combining advances in generative models and differentiable rendering. However, the underlying multi-view rendering, along with supervision from large-scale generative models, is computationally expensive and under-constrained. We propose DreamTexture, a novel Shape-from-Virtual-Texture approach that leverages monocular depth cues to reconstruct 3D objects. Our method textures an input image by aligning a virtual texture with the real depth cues in the input, exploiting the inherent understanding of monocular geometry encoded in modern diffusion models. We then reconstruct depth from the virtual texture deformation with a new conformal map optimization, which alleviates memory-intensive volumetric representations. Our experiments reveal that generative models possess an understanding of monocular shape cues, which can be extracted by augmenting and aligning texture cues -- a novel monocular reconstruction paradigm that we call Analysis by Augmentation.', 'abstract_zh': 'DreamTexture：一种利用单目深度线索的虚拟纹理形变重建方法', 'title_zh': 'DreamTexture: 从虚拟纹理推断形状的分析增强方法'}
{'arxiv_id': 'arXiv:2503.16408', 'title': 'RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints', 'authors': 'Yiran Qin, Li Kang, Xiufeng Song, Zhenfei Yin, Xiaohong Liu, Xihui Liu, Ruimao Zhang, Lei Bai', 'link': 'https://arxiv.org/abs/2503.16408', 'abstract': 'Designing effective embodied multi-agent systems is critical for solving complex real-world tasks across domains. Due to the complexity of multi-agent embodied systems, existing methods fail to automatically generate safe and efficient training data for such systems. To this end, we propose the concept of compositional constraints for embodied multi-agent systems, addressing the challenges arising from collaboration among embodied agents. We design various interfaces tailored to different types of constraints, enabling seamless interaction with the physical world. Leveraging compositional constraints and specifically designed interfaces, we develop an automated data collection framework for embodied multi-agent systems and introduce the first benchmark for embodied multi-agent manipulation, RoboFactory. Based on RoboFactory benchmark, we adapt and evaluate the method of imitation learning and analyzed its performance in different difficulty agent tasks. Furthermore, we explore the architectures and training strategies for multi-agent imitation learning, aiming to build safe and efficient embodied multi-agent systems.', 'abstract_zh': '设计有效的具身多智能体系统对于解决跨领域复杂现实任务至关重要。由于具身多智能体系统的复杂性，现有方法无法自动生成此类系统的安全高效训练数据。为此，我们提出了具身多智能体系统的组成约束概念，以应对具身智能体协作带来的挑战。我们设计了适用于不同类型约束的各种接口，使系统能够无缝与物理世界交互。借助组成约束和专门设计的接口，我们开发了具身多智能体系统的自动化数据采集框架，并引入了首个具身多智能体操作基准RoboFactory。基于RoboFactory基准，我们调整并评估了模仿学习的方法，并分析了其在不同难度智能体任务中的性能。此外，我们探讨了多智能体模仿学习的架构和训练策略，旨在构建安全高效的具身多智能体系统。', 'title_zh': 'RoboFactory: 探索基于组合约束的实体代理协作'}
{'arxiv_id': 'arXiv:2503.16399', 'title': 'SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World', 'authors': 'Chen Chen, Zhirui Wang, Taowei Sheng, Yi Jiang, Yundu Li, Peirui Cheng, Luning Zhang, Kaiqiang Chen, Yanfeng Hu, Xue Yang, Xian Sun', 'link': 'https://arxiv.org/abs/2503.16399', 'abstract': 'Existing vision-based 3D occupancy prediction methods are inherently limited in accuracy due to their exclusive reliance on street-view imagery, neglecting the potential benefits of incorporating satellite views. We propose SA-Occ, the first Satellite-Assisted 3D occupancy prediction model, which leverages GPS & IMU to integrate historical yet readily available satellite imagery into real-time applications, effectively mitigating limitations of ego-vehicle perceptions, involving occlusions and degraded performance in distant regions. To address the core challenges of cross-view perception, we propose: 1) Dynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions caused by the temporal asynchrony between satellite and street views; 2) 3D-Proj Guidance, a module that enhances 3D feature extraction from inherently 2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the sampling density between street and satellite views. Evaluated on Occ3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among single-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring only 6.93 ms of additional latency per frame. Our code and newly curated dataset are available at this https URL.', 'abstract_zh': '基于卫星辅助的3D占用率预测模型SA-Occ', 'title_zh': 'SA-Occ: 卫星辅助的三维占用预测在现实世界中'}
{'arxiv_id': 'arXiv:2503.16394', 'title': 'Do Visual Imaginations Improve Vision-and-Language Navigation Agents?', 'authors': 'Akhil Perincherry, Jacob Krantz, Stefan Lee', 'link': 'https://arxiv.org/abs/2503.16394', 'abstract': 'Vision-and-Language Navigation (VLN) agents are tasked with navigating an unseen environment using natural language instructions. In this work, we study if visual representations of sub-goals implied by the instructions can serve as navigational cues and lead to increased navigation performance. To synthesize these visual representations or imaginations, we leverage a text-to-image diffusion model on landmark references contained in segmented instructions. These imaginations are provided to VLN agents as an added modality to act as landmark cues and an auxiliary loss is added to explicitly encourage relating these with their corresponding referring expressions. Our findings reveal an increase in success rate (SR) of around 1 point and up to 0.5 points in success scaled by inverse path length (SPL) across agents. These results suggest that the proposed approach reinforces visual understanding compared to relying on language instructions alone. Code and data for our work can be found at this https URL.', 'abstract_zh': '基于视觉-语言导航（VLN）代理在使用自然语言指令导航未知环境时，我们研究视觉子目标表示是否可以作为导航线索并提高导航性能。为了合成这些视觉表示或想象，我们利用文本到图像扩散模型，该模型基于分割指令中的地标参考。这些想象被提供给VLN代理作为额外的模态，用作地标线索，并添加了一个辅助损失来明确鼓励与相应的引用表达式相关联。我们的研究结果表明，代理的成功率（SR）提高了约1个百分点，成功尺度倒数路径长度（SPL）提高了最多0.5个百分点。这些结果表明，与仅依赖语言指令相比，所提出的方法增强了视觉理解能力。我们的代码和数据可在以下链接找到：this https URL。', 'title_zh': '视觉想象能否提高视觉语言导航代理的能力？'}
{'arxiv_id': 'arXiv:2503.16392', 'title': 'Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment', 'authors': 'Anket Mehra, Andreas Aßmuth, Malte Prieß', 'link': 'https://arxiv.org/abs/2503.16392', 'abstract': 'With AI-based software becoming widely available, the risk of exploiting its capabilities, such as high automation and complex pattern recognition, could significantly increase. An AI used offensively to attack non-AI assets is referred to as offensive AI.\nCurrent research explores how offensive AI can be utilized and how its usage can be classified. Additionally, methods for threat modeling are being developed for AI-based assets within organizations. However, there are gaps that need to be addressed. Firstly, there is a need to quantify the factors contributing to the AI threat. Secondly, there is a requirement to create threat models that analyze the risk of being attacked by AI for vulnerability assessment across all assets of an organization. This is particularly crucial and challenging in cloud environments, where sophisticated infrastructure and access control landscapes are prevalent. The ability to quantify and further analyze the threat posed by offensive AI enables analysts to rank vulnerabilities and prioritize the implementation of proactive countermeasures.\nTo address these gaps, this paper introduces the Graph of Effort, an intuitive, flexible, and effective threat modeling method for analyzing the effort required to use offensive AI for vulnerability exploitation by an adversary. While the threat model is functional and provides valuable support, its design choices need further empirical validation in future work.', 'abstract_zh': '基于AI软件的广泛可用性，利用其高度自动化和复杂模式识别能力的风险可能显著增加。使用AI进行攻击而非AI资产的攻击行为被称为进攻性AI。\n\n当前的研究探索了进攻性AI的使用方式及其使用方式的分类方法。同时，组织内部基于AI的资产的威胁建模方法也在逐步发展。然而，仍存在一些需要填补的空白。首先，需要量化构成AI威胁的因素。其次，需要创建分析AI攻击风险的威胁模型，以评估所有组织资产的漏洞。特别是在云环境中，这种需求尤为迫切和具有挑战性，因为复杂的基础设施和访问控制环境普遍存在。能够量化并进一步分析进攻性AI所带来的威胁，使分析师能够对漏洞进行排名并优先实施主动防御措施。\n\n为了解决这些空白，本文介绍了努力图（Graph of Effort）这一直观、灵活且有效的威胁建模方法，用于分析攻击者利用进攻性AI进行漏洞利用所需的努力。虽然威胁模型功能强大并提供了宝贵的支撑，但其设计选择在未来工作中的需要进一步的实证验证。', 'title_zh': '努力图谱：量化AI使用风险以评估漏洞'}
{'arxiv_id': 'arXiv:2503.16389', 'title': 'Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation', 'authors': 'Kristin Qi, Xinhan Di', 'link': 'https://arxiv.org/abs/2503.16389', 'abstract': 'Retinal Optical Coherence Tomography (OCT) segmentation is essential for diagnosing pathology. Traditional methods focus on either spatial or spectral domains, overlooking their combined dependencies. We propose a triple-encoder network that integrates CNNs for spatial features, Fast Fourier Convolution (FFC) for spectral features, and attention mechanisms to capture global relationships across both domains. Attention fusion modules integrate convolution and cross-attention to further enhance features. Our method achieves an average Dice score improvement from 0.855 to 0.864, outperforming prior work.', 'abstract_zh': '视网膜光学相干断层扫描(OCT)分割对于诊断病理至关重要。传统的分割方法侧重于空间或光谱域，忽视了二者之间的联合依赖性。我们提出了一种三编码器网络，该网络将卷积神经网络用于空间特征提取、快速傅里叶卷积(FFC)用于光谱特征提取，并采用注意机制捕捉两个域之间的全局关系。注意融合模块结合卷积和交叉注意以进一步增强特征。我们的方法实现了平均Dice分数从0.855提高到0.864，超越了先前的工作。', 'title_zh': '空间光谱域中的注意力三编码器网络在医学图像分割中的应用'}
{'arxiv_id': 'arXiv:2503.16365', 'title': 'JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse', 'authors': 'Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang', 'link': 'https://arxiv.org/abs/2503.16365', 'abstract': "Recently, action-based decision-making in open-world environments has gained significant attention. Visual Language Action (VLA) models, pretrained on large-scale web datasets, have shown promise in decision-making tasks. However, previous work has primarily focused on action post-training, often neglecting enhancements to the foundational model itself. In response, we introduce a novel approach, Act from Visual Language Post-Training, which refines Visual Language Models (VLMs) through visual and linguistic guidance in a self-supervised manner. This enhancement improves the models' capabilities in world knowledge, visual recognition, and spatial grounding in open-world environments. Following the above post-training paradigms, we obtain the first VLA models in Minecraft that can follow human instructions on over 1k different atomic tasks, including crafting, smelting, cooking, mining, and killing. Our experiments demonstrate that post-training on non-trajectory tasks leads to a significant 40% improvement over the best agent baseline on a diverse set of atomic tasks. Furthermore, we demonstrate that our approach surpasses traditional imitation learning-based policies in Minecraft, achieving state-of-the-art performance. We have open-sourced the code, models, and datasets to foster further research. The project page can be found in this https URL.", 'abstract_zh': '开放世界环境中基于动作的决策制定最近获得了广泛关注。通过大规模网络数据预训练的视觉语言动作（VLA）模型在决策任务中展现出了巨大潜力。然而，先前的工作主要集中在动作的后训练上，往往忽略了对基础模型本身的改进。为应对这一问题，我们提出了一种新颖的方法——后训练下基于视觉语言的动作制定（Act from Visual Language Post-Training），该方法通过视觉和语言指导对视觉语言模型（VLMs）进行自我监督的完善。这种改进提升了模型在开放世界环境中的世界知识、视觉识别和空间定位能力。按照上述后训练范式，我们在Minecraft中首次获得了能够遵循人类指令完成超过1000种不同原子任务的VLA模型，包括制作、冶炼、烹饪、采矿和杀敌。实验结果表明，针对非轨迹任务的后训练相比最佳代理基线在多种原子任务上取得了显著的40%的提升。此外，我们展示了该方法在Minecraft中超越了传统的模仿学习策略，达到了最先进的性能。我们已开源了代码、模型和数据集以促进进一步的研究。项目页面可在以下链接访问：这个https URL。', 'title_zh': 'JARVIS-VLA：训练后大规模视觉语言模型以通过键盘和鼠标玩视觉游戏'}
{'arxiv_id': 'arXiv:2503.16364', 'title': 'Neural Networks: According to the Principles of Grassmann Algebra', 'authors': 'Z. Zarezadeh, N. Zarezadeh', 'link': 'https://arxiv.org/abs/2503.16364', 'abstract': 'In this paper, we explore the algebra of quantum idempotents and the quantization of fermions which gives rise to a Hilbert space equal to the Grassmann algebra associated with the Lie algebra. Since idempotents carry representations of the algebra under consideration, they form algebraic varieties and smooth manifolds in the natural topology. In addition to the motivation of linking up mathematical physics with machine learning, it is also shown that by using idempotents and invariant subspace of the corresponding algebras, these representations encode and perhaps provide a probabilistic interpretation of reasoning and relational paths in geometrical terms.', 'abstract_zh': '本文探索量子幂等元的代数及其所对应的张量规范化旋子，这产生了与李代数关联的葛森代数相等的希尔伯特空间。由于幂等元携带了所考虑代数的表示，它们在自然拓扑下形成了代数簇和光滑流形。除了将数学物理与机器学习联系起来的动力外，还展示了通过使用幂等元和相应代数的不变子空间，这些表示编码了基于几何术语的推理和关系路径的可能概率解释。', 'title_zh': '神经网络：根据 Grassmann 代数原理'}
{'arxiv_id': 'arXiv:2503.16356', 'title': 'CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners', 'authors': 'Yunzhi Yao, Jizhan Fang, Jia-Chen Gu, Ningyu Zhang, Shumin Deng, Huajun Chen, Nanyun Peng', 'link': 'https://arxiv.org/abs/2503.16356', 'abstract': 'Knowledge Editing (KE) enables the modification of outdated or incorrect information in large language models (LLMs). While existing KE methods can update isolated facts, they struggle to generalize these updates to multi-hop reasoning tasks that depend on the modified knowledge. Through an analysis of reasoning circuits -- the neural pathways LLMs use for knowledge-based inference, we observe that current layer-localized KE approaches, such as MEMIT and WISE, which edit only single or a few model layers, struggle to effectively incorporate updated information into these reasoning pathways. To address this limitation, we propose CaKE (Circuit-aware Knowledge Editing), a novel method that enables more effective integration of updated knowledge in LLMs. CaKE leverages strategically curated data, guided by our circuits-based analysis, that enforces the model to utilize the modified knowledge, stimulating the model to develop appropriate reasoning circuits for newly integrated knowledge. Experimental results show that CaKE enables more accurate and consistent use of updated knowledge across related reasoning tasks, leading to an average of 20% improvement in multi-hop reasoning accuracy on MQuAKE dataset compared to existing KE methods. We release the code and data in this https URL.', 'abstract_zh': '知识编辑（KE）使在大规模语言模型（LLMs）中修改过时或不正确信息成为可能。虽然现有的KE方法可以更新孤立的事实，但在依赖修改知识的多跳推理任务中，它们难以推广这些更新。通过对推理电路——LLMs用于基于知识的推理的神经路径进行分析，我们观察到当前局部层级的KE方法，如MEMIT和WISE，只能编辑单个或少数几个模型层，难以有效地将更新信息整合到这些推理路径中。为解决这一局限性，我们提出了一种名为CaKE（电路感知知识编辑）的新颖方法，该方法使得在LLMs中更有效地整合更新知识成为可能。CaKE利用了由我们的基于电路的分析指导筛选出来的数据，该数据强制模型使用修改后的知识，促使模型为新整合的知识开发出适当的推理电路。实验结果显示，CaKE在MQuAKE数据集上的多跳推理准确性平均提高了20%，优于现有的KE方法。我们在此提供代码和数据：https://xxxxxx。', 'title_zh': 'CaKE: 电路感知编辑促进可泛化的知识学习者'}
{'arxiv_id': 'arXiv:2503.16342', 'title': 'HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks', 'authors': 'Haoqi He, Yan Xiao', 'link': 'https://arxiv.org/abs/2503.16342', 'abstract': 'Estimating the global Lipschitz constant of neural networks is crucial for understanding and improving their robustness and generalization capabilities. However, precise calculations are NP-hard, and current semidefinite programming (SDP) methods face challenges such as high memory usage and slow processing speeds. In this paper, we propose \\textbf{HiQ-Lip}, a hybrid quantum-classical hierarchical method that leverages Coherent Ising Machines (CIMs) to estimate the global Lipschitz constant. We tackle the estimation by converting it into a Quadratic Unconstrained Binary Optimization (QUBO) problem and implement a multilevel graph coarsening and refinement strategy to adapt to the constraints of contemporary quantum hardware. Our experimental evaluations on fully connected neural networks demonstrate that HiQ-Lip not only provides estimates comparable to state-of-the-art methods but also significantly accelerates the computation process. In specific tests involving two-layer neural networks with 256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate upper bounds than the existing best method, LiPopt. These findings highlight the promising utility of small-scale quantum devices in advancing the estimation of neural network robustness.', 'abstract_zh': '基于混合量子-经典层次方法的HiQ-Lip：利用相干伊辛机估计神经网络的全局利普希茨常数', 'title_zh': 'HiQ-Lip: 全局ReLU网络Lipschitz常数估算的第一种量子-古典分级方法'}
{'arxiv_id': 'arXiv:2503.16328', 'title': 'Knowledge-guided machine learning model with soil moisture for corn yield prediction under drought conditions', 'authors': 'Xiaoyu Wang, Yijia Xu, Jingyi Huang, Zhengwei Yang, Zhou Zhang', 'link': 'https://arxiv.org/abs/2503.16328', 'abstract': "Remote sensing (RS) techniques, by enabling non-contact acquisition of extensive ground observations, have become a valuable tool for corn yield prediction. Traditional process-based (PB) models are limited by fixed input features and struggle to incorporate large volumes of RS data. In contrast, machine learning (ML) models are often criticized for being ``black boxes'' with limited interpretability. To address these limitations, we used Knowledge-Guided Machine Learning (KGML), which combined the strengths of both approaches and fully used RS data. However, previous KGML methods overlooked the crucial role of soil moisture in plant growth. To bridge this gap, we proposed the Knowledge-Guided Machine Learning with Soil Moisture (KGML-SM) framework, using soil moisture as an intermediate variable to emphasize its key role in plant development. Additionally, based on the prior knowledge that the model may overestimate under drought conditions, we designed a drought-aware loss function that penalizes predicted yield in drought-affected areas. Our experiments showed that the KGML-SM model outperformed other ML models. Finally, we explored the relationships between drought, soil moisture, and corn yield prediction, assessing the importance of various features and analyzing how soil moisture impacts corn yield predictions across different regions and time periods.", 'abstract_zh': '基于土壤湿度的指导机器学习框架（KGML-SM）在玉米产量预测中的应用', 'title_zh': '基于土壤湿度的知识引导机器学习模型在干旱条件下玉米产量预测'}
{'arxiv_id': 'arXiv:2503.16311', 'title': 'Structured-Noise Masked Modeling for Video, Audio and Beyond', 'authors': 'Aritra Bhowmik, Fida Mohammad Thoker, Carlos Hinojosa, Bernard Ghanem, Cees G. M. Snoek', 'link': 'https://arxiv.org/abs/2503.16311', 'abstract': 'Masked modeling has emerged as a powerful self-supervised learning framework, but existing methods largely rely on random masking, disregarding the structural properties of different modalities. In this work, we introduce structured noise-based masking, a simple yet effective approach that naturally aligns with the spatial, temporal, and spectral characteristics of video and audio data. By filtering white noise into distinct color noise distributions, we generate structured masks that preserve modality-specific patterns without requiring handcrafted heuristics or access to the data. Our approach improves the performance of masked video and audio modeling frameworks without any computational overhead. Extensive experiments demonstrate that structured noise masking achieves consistent improvement over random masking for standard and advanced masked modeling methods, highlighting the importance of modality-aware masking strategies for representation learning.', 'abstract_zh': '基于结构化噪声的掩码：一种符合视频和音频数据空间、时间和频谱特性的简单有效方法', 'title_zh': '结构化噪声掩蔽建模及其在视频、音频等领域的应用'}
{'arxiv_id': 'arXiv:2503.16304', 'title': 'Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1', 'authors': 'Peiran Gu, Fuhao Duan, Wenhao Li, Bochen Xu, Ying Cai, Teng Yao, Chenxun Zhuo, Tianming Liu, Bao Ge', 'link': 'https://arxiv.org/abs/2503.16304', 'abstract': "In recent years, the development of Large Language Models (LLMs) has made significant breakthroughs in the field of natural language processing and has gradually been applied to the field of humanities and social sciences research. LLMs have a wide range of application value in the field of humanities and social sciences because of its strong text understanding, generation and reasoning capabilities. In humanities and social sciences research, LLMs can analyze large-scale text data and make inferences.\nThis article analyzes the large language model DeepSeek-R1 from seven aspects: low-resource language translation, educational question-answering, student writing improvement in higher education, logical reasoning, educational measurement and psychometrics, public health policy analysis, and art this http URL we compare the answers given by DeepSeek-R1 in the seven aspects with the answers given by o1-preview. DeepSeek-R1 performs well in the humanities and social sciences, answering most questions correctly and logically, and can give reasonable analysis processes and explanations. Compared with o1-preview, it can automatically generate reasoning processes and provide more detailed explanations, which is suitable for beginners or people who need to have a detailed understanding of this knowledge, while o1-preview is more suitable for quick reading.\nThrough analysis, it is found that LLM has broad application potential in the field of humanities and social sciences, and shows great advantages in improving text analysis efficiency, language communication and other fields. LLM's powerful language understanding and generation capabilities enable it to deeply explore complex problems in the field of humanities and social sciences, and provide innovative tools for academic research and practical applications.", 'abstract_zh': '近年来，大型语言模型（LLMs）在自然语言处理领域取得了显著突破，并逐渐应用于人文学科和社会科学领域的研究。由于其强大的文本理解和生成及推理能力，LLMs在人文学科和社会科学领域具有广泛的应用价值。在人文学科和社会科学研究中，LLMs可以分析大规模文本数据并进行推断。\n\n本文从七个方面分析了DeepSeek-R1大型语言模型：低资源语言翻译、教育问答、高等教育中学生写作提高、逻辑推理、教育测量与心理测量、公共卫生政策分析以及艺术。我们比较了DeepSeek-R1在七个方面的答案与o1-preview的答案。DeepSeek-R1在人文学科和社会科学领域表现良好，答案大多正确合理，并能给出合理的分析过程和解释。与o1-preview相比，DeepSeek-R1能自动生成推理过程并提供更详细的解释，适合初学者或需要详细了解此知识的人，而o1-preview更适合快速阅读。\n\n通过对DeepSeek-R1和o1-preview进行分析，发现LLM在人文学科和社会科学领域具有广泛的应用潜力，并且在提高文本分析效率、语言交流等领域展现出显著优势。LLM强大的语言理解和生成能力使其能够深入探索人文学科和社会科学领域的复杂问题，并为学术研究和实际应用提供创新工具。', 'title_zh': '科技与人文融合：使用DeepSeek-R1评估大型语言模型对社会科学研究的影响'}
{'arxiv_id': 'arXiv:2503.16302', 'title': 'Unleashing Vecset Diffusion Model for Fast Shape Generation', 'authors': 'Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qinxiang Lin, Jinwei Huang, Yuhong Liu, Jie Jiang, Chunchao Guo, Xiangyu Yue', 'link': 'https://arxiv.org/abs/2503.16302', 'abstract': '3D shape generation has greatly flourished through the development of so-called "native" 3D diffusion, particularly through the Vecset Diffusion Model (VDM). While recent advancements have shown promising results in generating high-resolution 3D shapes, VDM still struggles with high-speed generation. Challenges exist because of difficulties not only in accelerating diffusion sampling but also VAE decoding in VDM, areas under-explored in previous works. To address these challenges, we present FlashVDM, a systematic framework for accelerating both VAE and DiT in VDM. For DiT, FlashVDM enables flexible diffusion sampling with as few as 5 inference steps and comparable quality, which is made possible by stabilizing consistency distillation with our newly introduced Progressive Flow Distillation. For VAE, we introduce a lightning vecset decoder equipped with Adaptive KV Selection, Hierarchical Volume Decoding, and Efficient Network Design. By exploiting the locality of the vecset and the sparsity of shape surface in the volume, our decoder drastically lowers FLOPs, minimizing the overall decoding overhead. We apply FlashVDM to Hunyuan3D-2 to obtain Hunyuan3D-2 Turbo. Through systematic evaluation, we show that our model significantly outperforms existing fast 3D generation methods, achieving comparable performance to the state-of-the-art while reducing inference time by over 45x for reconstruction and 32x for generation. Code and models are available at this https URL.', 'abstract_zh': '基于“原生”3D扩散的高效3D形状生成：FlashVDM框架', 'title_zh': '解锁Vecset扩散模型以实现快速形状生成'}
{'arxiv_id': 'arXiv:2503.16290', 'title': 'Diffusion-augmented Graph Contrastive Learning for Collaborative Filter', 'authors': 'Fan Huang, Wei Wang', 'link': 'https://arxiv.org/abs/2503.16290', 'abstract': 'Graph-based collaborative filtering has been established as a prominent approach in recommendation systems, leveraging the inherent graph topology of user-item interactions to model high-order connectivity patterns and enhance recommendation performance. Recent advances in Graph Contrastive Learning (GCL) have demonstrated promising potential to alleviate data sparsity issues by improving representation learning through contrastive view generation and mutual information maximization. However, existing approaches lack effective data augmentation strategies. Structural augmentation risks distorting fundamental graph topology, while feature-level perturbation techniques predominantly employ uniform noise scales that fail to account for node-specific characteristics. To solve these challenges, we propose Diffusion-augmented Contrastive Learning (DGCL), an innovative framework that integrates diffusion models with contrastive learning for enhanced collaborative filtering. Our approach employs a diffusion process that learns node-specific Gaussian distributions of representations, thereby generating semantically consistent yet diversified contrastive views through reverse diffusion sampling. DGCL facilitates adaptive data augmentation based on reconstructed representations, considering both semantic coherence and node-specific features. In addition, it explores unrepresented regions of the latent sparse feature space, thereby enriching the diversity of contrastive views. Extensive experimental results demonstrate the effectiveness of DGCL on three public datasets.', 'abstract_zh': '基于图的协同过滤已确立为推荐系统中的突出方法，通过利用用户项交互的内在图拓扑来建模高阶连接模式并提升推荐性能。最近在图对比学习（GCL）方面的进展展示了通过对比视图生成和最大互信息来改进表示学习以缓解数据稀疏问题的潜在优势。然而，现有方法缺乏有效的数据增强策略。结构增强有损地扭曲基本图拓扑，而特征层面的扰动技术主要采用均匀噪声尺度，未能考虑节点特定特性。为了解决这些挑战，我们提出了扩散增强对比学习（DGCL）框架，该框架将扩散模型与对比学习相结合以增强协同过滤。我们的方法通过学习节点特定的高斯分布进行扩散过程，从而通过逆向扩散采样生成语义一致但多样的对比视图。DGCL根据重建后的表示实现自适应数据增强，同时考虑语义连贯性和节点特定特性。此外，它探索了潜在稀疏特征空间的未表示区域，从而丰富了对比视图的多样性。广泛的实验结果在三个公开数据集上验证了DGCL的有效性。', 'title_zh': '基于扩散增强图对比学习的协作过滤'}
{'arxiv_id': 'arXiv:2503.16248', 'title': 'AI Agents in Cryptoland: Practical Attacks and No Silver Bullet', 'authors': 'Atharv Singh Patlan, Peiyao Sheng, S. Ashwin Hebbar, Prateek Mittal, Pramod Viswanath', 'link': 'https://arxiv.org/abs/2503.16248', 'abstract': "The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness, yet also introduces underexplored security risks, as these agents dynamically interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. Through empirical analysis of ElizaOS, a decentralized AI agent framework for automated Web3 operations, we demonstrate how adversaries can manipulate context by injecting malicious instructions into prompts or historical interaction records, leading to unintended asset transfers and protocol violations which could be financially devastating. Our findings indicate that prompt-based defenses are insufficient, as malicious inputs can corrupt an agent's stored context, creating cascading vulnerabilities across interactions and platforms. This research highlights the urgent need to develop AI agents that are both secure and fiduciarily responsible.", 'abstract_zh': 'AI代理与Web3生态系统的集成利用了其互补潜力以增强自主性和开放性，但同时也引入了未充分探索的安全风险，因为这些代理会动态与金融协议和不可变智能合约交互。本文探讨了在实际场景中 adversarial 攻击威胁下基于区块链的金融生态系统中AI代理的脆弱性。我们引入了上下文操纵的概念——这是一个全面的攻击向量，利用未受保护的上下文面，包括输入通道、内存模块和外部数据源。通过对ElizaOS的实证分析——这是一个用于自动化Web3操作的去中心化AI代理框架——我们展示了攻击者如何通过注入恶意指令到提示或历史交互记录中操纵上下文，导致意外资产转移和协议违规，这些都可能是财政灾难性的。我们的研究发现表明，基于提示的防御措施是不足的，因为恶意输入可以破坏代理存储的上下文，从而在交互和平台之间引发级联漏洞。本研究强调了开发既安全又具有信托责任的AI代理的迫切需求。', 'title_zh': 'AI代理在加密世界中的攻防：没有万能灵药'}
{'arxiv_id': 'arXiv:2503.16227', 'title': 'Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming', 'authors': 'Jeremy C.-H. Wang, Ming Hou, David Dunwoody, Marko Ilievski, Justin Tomasi, Edward Chao, Carl Pigeon', 'link': 'https://arxiv.org/abs/2503.16227', 'abstract': 'This paper examines how trust is formed, maintained, or diminished over time in the context of human-autonomy teaming with an optionally piloted aircraft. Whereas traditional factor-based trust models offer a static representation of human confidence in technology, here we discuss how variations in the underlying factors lead to variations in trust, trust thresholds, and human behaviours. Over 200 hours of flight test data collected over a multi-year test campaign from 2021 to 2023 were reviewed. The dispositional-situational-learned, process-performance-purpose, and IMPACTS homeostasis trust models are applied to illuminate trust trends during nominal autonomous flight operations. The results offer promising directions for future studies on trust dynamics and design-for-trust in human-autonomy teaming.', 'abstract_zh': '本文探讨了在 Optionally Piloted Aircraft 的人类-自主团队环境中，信任是如何随时间形成、维持或减弱的。传统的基于因素的信任模型提供了技术信任的静态表示，而本文讨论了底层因素的变化如何导致信任、信任阈值和人类行为的变化。通过对2021年至2023年多年度试验 campaign 收集的超过200小时飞行测试数据的审查，应用了 dispositional-situational-learned、process-performance-purpose 和 IMPACTS 自稳态信任模型，以阐明名义自主飞行操作期间的信任趋势。研究结果为未来关于信任动态和信任设计的研究提供了有力的方向。', 'title_zh': '可选有人驾驶飞行测试：人机团队信任动态案例研究'}
{'arxiv_id': 'arXiv:2503.16212', 'title': 'MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion', 'authors': 'Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan', 'link': 'https://arxiv.org/abs/2503.16212', 'abstract': 'Large Language Models (LLMs) have shown impressive progress in mathematical reasoning. While data augmentation is promising to enhance mathematical problem-solving ability, current approaches are predominantly limited to instance-level modifications-such as rephrasing or generating syntactic variations-which fail to capture and leverage the intrinsic relational structures inherent in mathematical knowledge. Inspired by human learning processes, where mathematical proficiency develops through systematic exposure to interconnected concepts, we introduce MathFusion, a novel framework that enhances mathematical reasoning through cross-problem instruction synthesis. MathFusion implements this through three fusion strategies: (1) sequential fusion, which chains related problems to model solution dependencies; (2) parallel fusion, which combines analogous problems to reinforce conceptual understanding; and (3) conditional fusion, which creates context-aware selective problems to enhance reasoning flexibility. By applying these strategies, we generate a new dataset, \\textbf{MathFusionQA}, followed by fine-tuning models (DeepSeekMath-7B, Mistral-7B, Llama3-8B) on it. Experimental results demonstrate that MathFusion achieves substantial improvements in mathematical reasoning while maintaining high data efficiency, boosting performance by 18.0 points in accuracy across diverse benchmarks while requiring only 45K additional synthetic instructions, representing a substantial improvement over traditional single-instruction approaches. Our datasets, models, and code are publicly available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在数学推理方面展示出了显著的进步。虽然数据扩增有望增强数学问题解决能力，但当前的方法主要局限于实例级别的修改，如重新表述或生成句法变化，这未能捕捉和利用数学知识中固有的内在关系结构。借鉴人类学习过程，数学能力是通过系统接触相互关联的概念而发展的，我们引入了MathFusion，这是一个新颖的框架，通过跨问题指令合成来增强数学推理能力。MathFusion通过三种融合策略实现这一点：（1）序列融合，将相关问题串联起来建模解决方案依赖性；（2）并行融合，结合类似的问题以强化概念理解；（3）条件融合，创建情境感知的精选问题以增强推理的灵活性。通过应用这些策略，我们生成了一个新的数据集MathFusionQA，随后在该数据集上微调模型（DeepSeekMath-7B、Mistral-7B、Llama3-8B）。实验证明，MathFusion在数学推理方面取得了显著进步，同时保持了高效的数据利用，其准确性能在多种基准测试中提高18.0个百分点，仅需额外45K合成指令，这相比传统的单一指令方法有显著改进。我们的数据集、模型和代码已在此处公开：this https URL。', 'title_zh': 'MathFusion: 通过指令融合增强大语言模型的数学问题解决能力'}
{'arxiv_id': 'arXiv:2503.16184', 'title': 'Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation', 'authors': 'Andrea Maracani, Savas Ozkan, Sijun Cho, Hyowon Kim, Eunchung Noh, Jeongwon Min, Cho Jung Min, Dookun Park, Mete Ozay', 'link': 'https://arxiv.org/abs/2503.16184', 'abstract': 'Scaling architectures have been proven effective for improving Scene Text Recognition (STR), but the individual contribution of vision encoder and text decoder scaling remain under-explored. In this work, we present an in-depth empirical analysis and demonstrate that, contrary to previous observations, scaling the decoder yields significant performance gains, always exceeding those achieved by encoder scaling alone. We also identify label noise as a key challenge in STR, particularly in real-world data, which can limit the effectiveness of STR models. To address this, we propose Cloze Self-Distillation (CSD), a method that mitigates label noise by distilling a student model from context-aware soft predictions and pseudolabels generated by a teacher model. Additionally, we enhance the decoder architecture by introducing differential cross-attention for STR. Our methodology achieves state-of-the-art performance on 10 out of 11 benchmarks using only real data, while significantly reducing the parameter size and computational costs.', 'abstract_zh': '基于视觉编码器和文本解码器缩放的场景文本识别性能分析：消除标签噪声并引入差异性交叉注意力机制', 'title_zh': '高效模型缩放与填空自蒸馏的场景文本识别准确性提升'}
{'arxiv_id': 'arXiv:2503.16161', 'title': 'Towards Lighter and Robust Evaluation for Retrieval Augmented Generation', 'authors': 'Alex-Razvan Ispas, Charles-Elie Simon, Fabien Caspani, Vincent Guigue', 'link': 'https://arxiv.org/abs/2503.16161', 'abstract': "Large Language Models are prompting us to view more NLP tasks from a generative perspective. At the same time, they offer a new way of accessing information, mainly through the RAG framework. While there have been notable improvements for the autoregressive models, overcoming hallucination in the generated answers remains a continuous problem. A standard solution is to use commercial LLMs, such as GPT4, to evaluate these algorithms. However, such frameworks are expensive and not very transparent. Therefore, we propose a study which demonstrates the interest of open-weight models for evaluating RAG hallucination. We develop a lightweight approach using smaller, quantized LLMs to provide an accessible and interpretable metric that gives continuous scores for the generated answer with respect to their correctness and faithfulness. This score allows us to question decisions' reliability and explore thresholds to develop a new AUC metric as an alternative to correlation with human judgment.", 'abstract_zh': '大型语言模型正促使我们从生成视角重新审视更多NLP任务。同时，它们通过RAG框架提供了一种新的信息访问方式。尽管自回归模型已有显著改进，但生成答案中的幻觉问题仍然是一个持续存在的挑战。一种标准的解决方案是使用商业大语言模型，如GPT4，来评估这些算法。然而，此类框架成本高昂且不够透明。因此，我们提出一项研究，展示开源权重模型在评估RAG幻觉方面的重要性。我们开发了一种轻量级方法，使用较小的量化大语言模型来提供一个易于理解和解释的度量标准，该度量标准针对生成答案的正确性和忠实性提供连续评分。这一评分使我们能够质疑决策的可靠性，并探索阈值以开发一种新的AUC度量标准，作为与人工判断相关性的替代方案。', 'title_zh': '面向更轻量级和稳健的检索增强生成评估'}
{'arxiv_id': 'arXiv:2503.16159', 'title': 'Neural Combinatorial Optimization for Real-World Routing', 'authors': 'Jiwoo Son, Zhikai Zhao, Federico Berto, Chuanbo Hua, Changhyun Kwon, Jinkyoo Park', 'link': 'https://arxiv.org/abs/2503.16159', 'abstract': 'Vehicle Routing Problems (VRPs) are a class of NP-hard problems ubiquitous in several real-world logistics scenarios that pose significant challenges for optimization. Neural Combinatorial Optimization (NCO) has emerged as a promising alternative to classical approaches, as it can learn fast heuristics to solve VRPs. However, most research works in NCO for VRPs focus on simplified settings, which do not account for asymmetric distances and travel durations that cannot be derived by simple Euclidean distances and unrealistic data distributions, hindering real-world deployment. This work introduces RRNCO (Real Routing NCO) to bridge the gap of NCO between synthetic and real-world VRPs in the critical aspects of both data and modeling. First, we introduce a new, openly available dataset with real-world data containing a diverse dataset of locations, distances, and duration matrices from 100 cities, considering realistic settings with actual routing distances and durations obtained from Open Source Routing Machine (OSRM). Second, we propose a novel approach that efficiently processes both node and edge features through contextual gating, enabling the construction of more informed node embedding, and we finally incorporate an Adaptation Attention Free Module (AAFM) with neural adaptive bias mechanisms that effectively integrates not only distance matrices but also angular relationships between nodes, allowing our model to capture rich structural information. RRNCO achieves state-of-the-art results in real-world VRPs among NCO methods. We make our dataset and code publicly available at this https URL.', 'abstract_zh': 'Real Routing Neural Combinatorial Optimization', 'title_zh': '神经组合优化在实际路径规划中的应用'}
{'arxiv_id': 'arXiv:2503.16144', 'title': 'Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs', 'authors': 'Djamel Eddine Khelladi, Charly Reux, Mathieu Acher', 'link': 'https://arxiv.org/abs/2503.16144', 'abstract': "Large language model (LLM)-based test generation has gained attention in software engineering, yet most studies evaluate LLMs' ability to generate unit tests in a single attempt for a given language, missing the opportunity to leverage LLM diversity for more robust testing. This paper introduces PolyTest, a novel approach that enhances test generation by exploiting polyglot and temperature-controlled diversity. PolyTest systematically leverages these properties in two complementary ways: (1) Cross-lingual test generation, where tests are generated in multiple languages at zero temperature and then unified; (2) Diverse test sampling, where multiple test sets are generated within the same language at a higher temperature before unification. A key insight is that LLMs can generate diverse yet contradicting tests -- same input, different expected outputs -- across languages and generations. PolyTest mitigates inconsistencies by unifying test sets, fostering self-consistency and improving overall test quality. Unlike single-language or single-attempt approaches, PolyTest enhances testing without requiring on-the-fly execution, making it particularly beneficial for weaker-performing languages. We evaluate PolyTest on Llama3-70B, GPT-4o, and GPT-3.5 using EvalPlus, generating tests in five languages (Java, C, Python, JavaScript, and a CSV-based format) at temperature 0 and sampling multiple sets at temperature 1. We observe that LLMs frequently generate contradicting tests across settings, and that PolyTest significantly improves test quality across all considered metrics -- number of tests, passing rate, statement/branch coverage (up to +9.01%), and mutation score (up to +11.23%). Finally, PolyTest outperforms Pynguin in test generation, passing rate, and mutation score.", 'abstract_zh': '基于大型语言模型（LLM）的测试生成在软件工程中引起了关注，但大多数研究只评估LLM单次生成给定语言单元测试的能力，忽视了利用LLM多样性的机会以实现更 robust 的测试。本文引入了 PolyTest，这是一种新颖的方法，通过利用多语言能力和温度控制多样性来增强测试生成。PolyTest 通过以下两种互补的方式系统地利用这些特性：（1）跨语言测试生成，其中在零温度下生成多语言测试并统一；（2）多样测试采样，在同一语言中在较高温度下生成多个测试集，然后进行统一。一个关键见解是，LLM 可以生成多样的但互相矛盾的测试——相同的输入，不同的预期输出——跨越语言和生成过程。PolyTest 通过统一测试集减轻不一致性的发生，促进自我一致性并提高整体测试质量。与单语言或单次尝试的方法不同，PolyTest 在无需实时执行的情况下增强测试，使其特别适合弱表现的语言。我们使用 EvalPlus 在 Llama3-70B、GPT-4o 和 GPT-3.5 上评估 PolyTest，生成五种语言（Java、C、Python、JavaScript 以及一种基于 CSV 的格式）的测试，并在温度 0 下生成测试集，在温度 1 下采样多个测试集。我们发现 LLM 在不同设置中频繁生成互相矛盾的测试，并且 PolyTest 在所有考虑的指标——测试数量、通过率、语句/分支覆盖率（最多 +9.01%）和变异评分（最多 +11.23%）——中显著提高了测试质量。最后，PolyTest 在测试生成、通过率和变异评分方面优于 Pynguin。', 'title_zh': '统合与胜出：利用大语言模型生成多语言、多样化且自一致性的单元测试'}
{'arxiv_id': 'arXiv:2503.16112', 'title': 'PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming', 'authors': 'Liming Liu, Jiangkai Wu, Haoyang Wang, Peiheng Wang, Xinggong Zhang, Zongming Guo', 'link': 'https://arxiv.org/abs/2503.16112', 'abstract': 'Traditional video compression algorithms exhibit significant quality degradation at extremely low bitrates. Promptus emerges as a new paradigm for video streaming, substantially cutting down the bandwidth essential for video streaming. However, Promptus is computationally intensive and can not run in real-time on mobile devices. This paper presents PromptMobile, an efficient acceleration framework tailored for on-device Promptus. Specifically, we propose (1) a two-stage efficient generation framework to reduce computational cost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant computations by 16.6\\%, (3) system-level optimizations to further enhance efficiency. The evaluations demonstrate that compared with the original Promptus, PromptMobile achieves a 13.6x increase in image generation speed. Compared with other streaming methods, PromptMobile achives an average LPIPS improvement of 0.016 (compared with H.265), reducing 60\\% of severely distorted frames (compared to VQGAN).', 'abstract_zh': '传统视频压缩算法在极低比特率下会显著降低视频质量。Promptus作为一种新的视频流媒体 paradigm，极大地减少了视频流媒体所需的带宽。然而，Promptus计算密集型且无法在移动设备上实时运行。本文提出了PromptMobile，一个针对 Promptus 的高效加速框架。具体来说，我们提出了一种两阶段有效生成框架，将计算成本降低8.1倍，一种细粒度的帧间缓存机制，将冗余计算减少16.6%，以及系统级优化进一步提高效率。评估结果显示，与原始的 Promptus 相比，PromptMobile 的图像生成速度提高了13.6倍。与其它流媒体方法相比，PromptMobile 在 LPIPS 上平均改进了0.016（与 H.265 相比），减少了60%严重失真的帧（与 VQGAN 相比）。', 'title_zh': 'PromptMobile: 适用于低带宽移动视频流传输的高效提示方案'}
{'arxiv_id': 'arXiv:2503.16091', 'title': 'AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence', 'authors': 'Abdullah Mamun, Diane J. Cook, Hassan Ghasemzadeh', 'link': 'https://arxiv.org/abs/2503.16091', 'abstract': 'Adherence to prescribed treatments is crucial for individuals with chronic conditions to avoid costly or adverse health outcomes. For certain patient groups, intensive lifestyle interventions are vital for enhancing medication adherence. Accurate forecasting of treatment adherence can open pathways to developing an on-demand intervention tool, enabling timely and personalized support. With the increasing popularity of smartphones and wearables, it is now easier than ever to develop and deploy smart activity monitoring systems. However, effective forecasting systems for treatment adherence based on wearable sensors are still not widely available. We close this gap by proposing Adherence Forecasting and Intervention with Machine Intelligence (AIMI). AIMI is a knowledge-guided adherence forecasting system that leverages smartphone sensors and previous medication history to estimate the likelihood of forgetting to take a prescribed medication. A user study was conducted with 27 participants who took daily medications to manage their cardiovascular diseases. We designed and developed CNN and LSTM-based forecasting models with various combinations of input features and found that LSTM models can forecast medication adherence with an accuracy of 0.932 and an F-1 score of 0.936. Moreover, through a series of ablation studies involving convolutional and recurrent neural network architectures, we demonstrate that leveraging known knowledge about future and personalized training enhances the accuracy of medication adherence forecasting. Code available: this https URL.', 'abstract_zh': '基于机器智能的依从性预测与干预（AIMI）', 'title_zh': 'AIMI：在稀疏事件预测中的未来知识利用和个人化方法以提高治疗依从性'}
{'arxiv_id': 'arXiv:2503.16085', 'title': 'Allostatic Control of Persistent States in Spiking Neural Networks for perception and computation', 'authors': 'Aung Htet, Alejandro Rodriguez Jimenez, Sarah Hamburg, Alessandro Di Nuovo', 'link': 'https://arxiv.org/abs/2503.16085', 'abstract': 'We introduce a novel model for updating perceptual beliefs about the environment by extending the concept of Allostasis to the control of internal representations. Allostasis is a fundamental regulatory mechanism observed in animal physiology that orchestrates responses to maintain a dynamic equilibrium in bodily needs and internal states. In this paper, we focus on an application in numerical cognition, where a bump of activity in an attractor network is used as a spatial numerical representation. While existing neural networks can maintain persistent states, to date, there is no unified framework for dynamically controlling spatial changes in neuronal activity in response to environmental changes. To address this, we couple a well known allostatic microcircuit, the Hammel model, with a ring attractor, resulting in a Spiking Neural Network architecture that can modulate the location of the bump as a function of some reference input. This localized activity in turn is used as a perceptual belief in a simulated subitization task a quick enumeration process without counting. We provide a general procedure to fine-tune the model and demonstrate the successful control of the bump location. We also study the response time in the model with respect to changes in parameters and compare it with biological data. Finally, we analyze the dynamics of the network to understand the selectivity and specificity of different neurons to distinct categories present in the input. The results of this paper, particularly the mechanism for moving persistent states, are not limited to numerical cognition but can be applied to a wide range of tasks involving similar representations.', 'abstract_zh': '我们通过将allostasis的概念扩展到内部表征的控制，引入了一种新的模型来更新对环境的感知信念。本文聚焦于数值认知的应用，在此类应用中，吸引子网络中的活动峰被用作空间数值表示。尽管现有的神经网络可以维持持久状态，但迄今为止，仍缺乏一个统一的框架来动态控制神经活动的空间变化以应对环境变化。为解决这一问题，我们将一个著名的allostasis微回路——Hammel模型，与环形吸引子相结合，从而获得一种尖峰神经网络架构，该架构可以通过某些参考输入的功能来调节活动峰的位置。这种局部活动在模拟瞬时数量感任务中作为感知信念使用，这是一种无需计数的快速枚举过程。我们提供了一种通用的微调程序，并证明了对活动峰位置的有效控制。此外，我们研究了模型的响应时间关于参数变化的响应，并将其与生物数据进行了比较。最后，我们分析了网络的动力学，以理解不同神经元对输入中不同类别的选择性和特异性。本文的结果，特别是在移动持久状态机制方面，不仅适用于数值认知，还适用于涉及类似表示的各种任务。', 'title_zh': '持续状态下的 allostatic 控制在脉冲神经网络中的感知与计算'}
{'arxiv_id': 'arXiv:2503.16075', 'title': '3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge', 'authors': 'Marek Wodzinski, Henning Müller', 'link': 'https://arxiv.org/abs/2503.16075', 'abstract': 'Lightsheet microscopy is a powerful 3-D imaging technique that addresses limitations of traditional optical and confocal microscopy but suffers from a low penetration depth and reduced image quality at greater depths. Multiview lightsheet microscopy improves 3-D resolution by combining multiple views but simultaneously increasing the complexity and the photon budget, leading to potential photobleaching and phototoxicity. The FuseMyCells challenge, organized in conjunction with the IEEE ISBI 2025 conference, aims to benchmark deep learning-based solutions for fusing high-quality 3-D volumes from single 3-D views, potentially simplifying procedures and conserving the photon budget. In this work, we propose a contribution to the FuseMyCells challenge based on a two-step procedure. The first step processes a downsampled version of the image to capture the entire region of interest, while the second step uses a patch-based approach for high-resolution inference, incorporating adversarial loss to enhance visual outcomes. This method addresses challenges related to high data resolution, the necessity of global context, and the preservation of high-frequency details. Experimental results demonstrate the effectiveness of our approach, highlighting its potential to improve 3-D image fusion quality and extend the capabilities of lightsheet microscopy. The average SSIM for the nucleus and membranes is greater than 0.85 and 0.91, respectively.', 'abstract_zh': 'Lightsheet 光学显微成像是一个强大的三维成像技术，克服了传统光学和共焦显微镜的限制，但受到穿透深度低和深层图像质量差的限制。多视角 Lightsheet 显微成像通过结合多个视角提高三维分辨率，但同时增加了复杂性和光子预算，可能导致荧光淬灭和光毒性。FuseMyCells 挑战，作为 IEEE ISBI 2025 会议的一部分，旨在基准测试基于深度学习的解决方案，以融合单个三维视角的高质量三维体数据，可能简化程序并节省光子预算。在本工作中，我们根据两步程序提出了对 FuseMyCells 挑战的贡献。第一步处理图像的下采样版本以捕捉整个感兴趣区域，第二步使用基于补丁的方法进行高分辨率推理，并结合对手损失以增强视觉结果。该方法解决了高数据分辨率、全局上下文的必要性和高频细节保留等方面的挑战。实验结果表明了我们方法的有效性，强调了其提高三维图像融合质量并扩展 Lightsheet 显微镜功能的潜力。核和膜的平均 SSIM 分别大于 0.85 和 0.91。', 'title_zh': '基于两步对抗网络的Lightsheet显微镜3D图像融合：对FuseMyCells挑战的贡献'}
{'arxiv_id': 'arXiv:2503.16072', 'title': 'Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection', 'authors': 'Sergey Berezin, Reza Farahbakhsh, Noel Crespi', 'link': 'https://arxiv.org/abs/2503.16072', 'abstract': 'The fundamental problem of toxicity detection lies in the fact that the term "toxicity" is ill-defined. Such uncertainty causes researchers to rely on subjective and vague data during model training, which leads to non-robust and inaccurate results, following the \'garbage in - garbage out\' paradigm. This study introduces a novel, objective, and context-aware framework for toxicity detection, leveraging stress levels as a key determinant of toxicity. We propose new definition, metric and training approach as a parts of our framework and demonstrate it\'s effectiveness using a dataset we collected.', 'abstract_zh': '毒性的检测基本问题在于“毒性和”的概念界定不清。这种不确定性导致研究人员在模型训练过程中依赖主观和模糊的数据，从而产生不 robust 和不准确的结果，遵循“垃圾进-垃圾出”的原则。本研究提出了一种新颖的、客观的、上下文感知的毒性和检测框架，利用压力水平作为毒性和的关键决定因素。我们提出了一种新的定义、度量标准和训练方法作为该框架的一部分，并通过我们收集的数据集展示了其有效性。', 'title_zh': '重新定义毒性：一种基于压力级别且客观情境感知的检测方法'}
{'arxiv_id': 'arXiv:2503.16071', 'title': 'Tuning LLMs by RAG Principles: Towards LLM-native Memory', 'authors': 'Jiale Wei, Shuchi Wu, Ruochen Liu, Xiang Ying, Jingbo Shang, Fangbo Tao', 'link': 'https://arxiv.org/abs/2503.16071', 'abstract': 'Memory, additional information beyond the training of large language models (LLMs), is crucial to various real-world applications, such as personal assistant. The two mainstream solutions to incorporate memory into the generation process are long-context LLMs and retrieval-augmented generation (RAG). In this paper, we first systematically compare these two types of solutions on three renovated/new datasets and show that (1) long-context solutions, although more expensive, shall be easier to capture the big picture and better answer queries which require considering the memory as a whole; and (2) when the queries concern specific information, RAG solutions shall be more competitive especially when the keywords can be explicitly matched. Therefore, we propose a novel method RAG-Tuned-LLM which fine-tunes a relative small (e.g., 7B) LLM using the data generated following the RAG principles, so it can combine the advantages of both solutions. Extensive experiments on three datasets demonstrate that RAG-Tuned-LLM can beat long-context LLMs and RAG methods across a wide range of query types.', 'abstract_zh': '大规模语言模型（LLM）中的记忆，及其超越训练的信息对于各种实际应用至关重要，如个人助手。将记忆整合到生成过程中的两种主流解决方案是长上下文LLM和检索增强生成（RAG）。在本文中，我们首先系统地在三个更新后的/新数据集上比较了这两种解决方案，并表明：（1）尽管成本更高，长上下文解决方案更易于捕捉整体情况，更适合回答需要考虑整体记忆的问题；（2）当问题涉及特定信息时，RAG解决方案更具竞争力，特别是在关键词可以明确匹配的情况下。因此，我们提出了一种新型方法RAG-Tuned-LLM，通过遵循RAG原则生成的数据对相对较小（例如，7B）的LLM进行微调，使其能够结合两种解决方案的优势。在三个数据集上的广泛实验表明，RAG-Tuned-LLM在多种查询类型下可以击败长上下文LLM和RAG方法。', 'title_zh': '基于RAG原则调整LLMs：走向内置记忆的LLMs'}
{'arxiv_id': 'arXiv:2503.16064', 'title': 'PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval', 'authors': 'Qiang Zou, Shuli Cheng, Jiayi Chen', 'link': 'https://arxiv.org/abs/2503.16064', 'abstract': 'Cross-modal hashing is a promising approach for efficient data retrieval and storage optimization. However, contemporary methods exhibit significant limitations in semantic preservation, contextual integrity, and information redundancy, which constrains retrieval efficacy. We present PromptHash, an innovative framework leveraging affinity prompt-aware collaborative learning for adaptive cross-modal hashing. We propose an end-to-end framework for affinity-prompted collaborative hashing, with the following fundamental technical contributions: (i) a text affinity prompt learning mechanism that preserves contextual information while maintaining parameter efficiency, (ii) an adaptive gated selection fusion architecture that synthesizes State Space Model with Transformer network for precise cross-modal feature integration, and (iii) a prompt affinity alignment strategy that bridges modal heterogeneity through hierarchical contrastive learning. To the best of our knowledge, this study presents the first investigation into affinity prompt awareness within collaborative cross-modal adaptive hash learning, establishing a paradigm for enhanced semantic consistency across modalities. Through comprehensive evaluation on three benchmark multi-label datasets, PromptHash demonstrates substantial performance improvements over existing approaches. Notably, on the NUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in image-to-text and text-to-image retrieval tasks, respectively. The code is publicly available at this https URL.', 'abstract_zh': '跨模态哈希是高效数据检索和存储优化的一种有前途的方法。然而，当代方法在语义保真度、语境完整性以及信息冗余方面表现出显著的局限性，这限制了检索效果。我们提出了PromptHash，这是一种利用亲和度提示感知协作学习机制的创新框架，用于自适应跨模态哈希。我们提出了一种端到端的亲和度提示协同哈希框架，具有以下基本技术贡献：(i) 一种文本亲和度提示学习机制，能够在保持参数效率的同时保留语境信息，(ii) 一种自适应门控选择融合架构，将状态空间模型与Transformer网络结合以精确合成跨模态特征集成，以及(iii) 一种提示亲和度对齐策略，通过层次对比学习弥合模态异质性。据我们所知，这是首次对协同跨模态自适应哈希学习中的亲和度提示意识进行研究，建立了提升各模态间语义一致性的新范式。通过在三个基准多标签数据集上的全面评估，PromptHash展现了相对于现有方法的显著性能提升。特别是在NUS-WIDE数据集上，我们的方法分别在图像到文本和文本到图像检索任务中取得了18.22%和18.65%的显著提升。代码已在以下网址公开：this https URL。', 'title_zh': 'PromptHash: 基于提示驱动的协作跨模态学习适应性哈希检索'}
{'arxiv_id': 'arXiv:2503.16063', 'title': 'Two-stage Incomplete Utterance Rewriting on Editing Operation', 'authors': 'Zhiyu Cao, Peifeng Li, Qiaoming Zhu, Yaxin Fan', 'link': 'https://arxiv.org/abs/2503.16063', 'abstract': 'Previous work on Incomplete Utterance Rewriting (IUR) has primarily focused on generating rewritten utterances based solely on dialogue context, ignoring the widespread phenomenon of coreference and ellipsis in dialogues. To address this issue, we propose a novel framework called TEO (\\emph{Two-stage approach on Editing Operation}) for IUR, in which the first stage generates editing operations and the second stage rewrites incomplete utterances utilizing the generated editing operations and the dialogue context. Furthermore, an adversarial perturbation strategy is proposed to mitigate cascading errors and exposure bias caused by the inconsistency between training and inference in the second stage. Experimental results on three IUR datasets show that our TEO outperforms the SOTA models significantly.', 'abstract_zh': '基于两阶段编辑操作的对话中不完整表述重写框架TEO', 'title_zh': '两阶段不完整语句编辑重写'}
{'arxiv_id': 'arXiv:2503.16057', 'title': 'Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts', 'authors': 'Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min', 'link': 'https://arxiv.org/abs/2503.16057', 'abstract': 'Diffusion models have emerged as mainstream framework in visual generation. Building upon this success, the integration of Mixture of Experts (MoE) methods has shown promise in enhancing model scalability and performance. In this paper, we introduce Race-DiT, a novel MoE model for diffusion transformers with a flexible routing strategy, Expert Race. By allowing tokens and experts to compete together and select the top candidates, the model learns to dynamically assign experts to critical tokens. Additionally, we propose per-layer regularization to address challenges in shallow layer learning, and router similarity loss to prevent mode collapse, ensuring better expert utilization. Extensive experiments on ImageNet validate the effectiveness of our approach, showcasing significant performance gains while promising scaling properties.', 'abstract_zh': '基于专家混合的方法在增强扩散变压器模型的可扩展性和性能方面的研究：Race-DiT模型及其灵活路由策略', 'title_zh': '专家赛跑：一种用于扩展扩散变换器的混合专家灵活路由策略'}
{'arxiv_id': 'arXiv:2503.16047', 'title': 'Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic', 'authors': 'Bisola Faith Kayode, Akinyemi Sadeeq Akintola, Oluwole Fagbohun, Egonna Anaesiuba-Bristol, Onyekachukwu Ojumah, Oluwagbade Odimayo, Toyese Oloyede, Aniema Inyang, Teslim Kazeem, Habeeb Alli, Udodirim Ibem Offia, Prisca Chinazor Amajuoyi', 'link': 'https://arxiv.org/abs/2503.16047', 'abstract': "Denial-of-Service (DoS) attacks remain a critical threat to network security, disrupting services and causing significant economic losses. Traditional detection methods, including statistical and rule-based models, struggle to adapt to evolving attack patterns. To address this challenge, we propose a novel Temporal-Spatial Attention Network (TSAN) architecture for detecting Denial of Service (DoS) attacks in network traffic. By leveraging both temporal and spatial features of network traffic, our approach captures complex traffic patterns and anomalies that traditional methods might miss. The TSAN model incorporates transformer-based temporal encoding, convolutional spatial encoding, and a cross-attention mechanism to fuse these complementary feature spaces. Additionally, we employ multi-task learning with auxiliary tasks to enhance the model's robustness. Experimental results on the NSL-KDD dataset demonstrate that TSAN outperforms state-of-the-art models, achieving superior accuracy, precision, recall, and F1-score while maintaining computational efficiency for real-time deployment. The proposed architecture offers an optimal balance between detection accuracy and computational overhead, making it highly suitable for real-world network security applications.", 'abstract_zh': '时空注意力网络（TSAN）架构用于检测网络流量中的拒绝服务（DoS）攻击', 'title_zh': '基于时空注意力网络（TSAN）的网络流量DoS攻击检测'}
{'arxiv_id': 'arXiv:2503.16045', 'title': 'Open Science and Artificial Intelligence for supporting the sustainability of the SRC Network: The espSRC case', 'authors': 'J. Garrido, S. Sánchez-Expósito, A. Ruiz-Falcó, J. Ruedas, M. Á. Mendoza, V. Vázquez, M. Parra, J. Sánchez, I. Labadie, L. Darriba, J. Moldón, M. Rodriguez-Álvarez, J. Díaz, L. Verdes-Montenegro', 'link': 'https://arxiv.org/abs/2503.16045', 'abstract': 'The SKA Observatory (SKAO), a landmark project in radio astronomy, seeks to address fundamental questions in astronomy. To process its immense data output, approximately 700 PB/year, a global network of SKA Regional Centres (SR-CNet) will provide the infrastructure, tools, computational power needed for scientific analysis and scientific support. The Spanish SRC (espSRC) focuses on ensuring the sustainability of this network by reducing its environmental impact, integrating green practices into data platforms, and developing Open Science technologies to enable reproducible research. This paper discusses and summarizes part of the research and development activities that the team is conducting to reduce the SRC energy consumption at the espSRC and SRCNet. The paper also discusses fundamental research on trusted repositories to support Open Science practices.', 'abstract_zh': 'SKA望远镜 observatory（SKAO），一项射电天文学领域的里程碑项目，旨在解答天文学中的基本问题。为了处理其巨大的数据输出，约每年700 PB，SKA区域中心（SKA Regional Centres, SR-CNet）全球网络将提供必要的基础设施、工具和计算能力以支持科学分析和科学支持。西班牙区域中心（Spanish SRC, espSRC）致力于通过减少能源消耗、整合绿色实践于数据平台以及开发开放科学技术来确保该网络的可持续性，以促进可再现研究。本文讨论并总结了团队正在进行的部分研究和开发活动，以降低espSRC和SRCNet的能源消耗。此外，本文还讨论了支持开放科学实践的受信任存储库的基本研究。', 'title_zh': '开放科学与人工智_agent_for支撑SRC网络的可持续性:espSRC案例'}
{'arxiv_id': 'arXiv:2503.16043', 'title': 'Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation', 'authors': 'Zhiyu Cao, Peifeng Li, Yaxin Fan, Qiaoming Zhu', 'link': 'https://arxiv.org/abs/2503.16043', 'abstract': 'Although existing fashionable generation methods on Incomplete Utterance Rewriting (IUR) can generate coherent utterances, they often result in the inclusion of irrelevant and redundant tokens in rewritten utterances due to their inability to focus on critical tokens in dialogue context. Furthermore, the limited size of the training datasets also contributes to the insufficient training of the IUR model. To address the first issue, we propose a multi-task learning framework EO-IUR (Editing Operation-guided Incomplete Utterance Rewriting) that introduces the editing operation labels generated by sequence labeling module to guide generation model to focus on critical tokens. Furthermore, we introduce a token-level heterogeneous graph to represent dialogues. To address the second issue, we propose a two-dimensional utterance augmentation strategy, namely editing operation-based incomplete utterance augmentation and LLM-based historical utterance augmentation. The experimental results on three datasets demonstrate that our EO-IUR outperforms previous state-of-the-art (SOTA) baselines in both open-domain and task-oriented dialogue. The code will be available at this https URL.', 'abstract_zh': '尽管现有的不完备话语修正方法可以在不完整话语重写（IUR）中生成连贯的话语，但由于它们无法关注对话上下文中的关键词汇，常常导致生成的话语包含无关和冗余的词汇。此外，训练数据集规模有限也导致IUR模型训练不足。为解决第一个问题，我们提出了一种多任务学习框架EO-IUR（编辑操作引导的不完备话语修正），该框架通过引入由序列标注模块生成的编辑操作标签来引导生成模型关注关键词汇。为进一步解决第二个问题，我们提出了两种话语增强策略，即基于编辑操作的不完备话语增强和基于大型语言模型的历史话语增强。在三个数据集上的实验结果表明，我们的EO-IUR在开放式和任务导向对话中均优于先前的最优基线方法。代码将在此链接处提供。', 'title_zh': '基于编辑操作指导和话语扩增的不完整句子重写'}
{'arxiv_id': 'arXiv:2503.16036', 'title': 'Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models', 'authors': 'Zhihang Liu, Chen-Wei Xie, Pandeng Li, Liming Zhao, Longxiang Tang, Yun Zheng, Chuanbin Liu, Hongtao Xie', 'link': 'https://arxiv.org/abs/2503.16036', 'abstract': 'Recent Multi-modal Large Language Models (MLLMs) have been challenged by the computational overhead resulting from massive video frames, often alleviated through compression strategies. However, the visual content is not equally contributed to user instructions, existing strategies (\\eg, average pool) inevitably lead to the loss of potentially useful information. To tackle this, we propose the Hybrid-level Instruction Injection Strategy for Conditional Token Compression in MLLMs (HICom), utilizing the instruction as a condition to guide the compression from both local and global levels. This encourages the compression to retain the maximum amount of user-focused information while reducing visual tokens to minimize computational burden. Specifically, the instruction condition is injected into the grouped visual tokens at the local level and the learnable tokens at the global level, and we conduct the attention mechanism to complete the conditional compression. From the hybrid-level compression, the instruction-relevant visual parts are highlighted while the temporal-spatial structure is also preserved for easier understanding of LLMs. To further unleash the potential of HICom, we introduce a new conditional pre-training stage with our proposed dataset HICom-248K. Experiments show that our HICom can obtain distinguished video understanding ability with fewer tokens, increasing the performance by 2.43\\% average on three multiple-choice QA benchmarks and saving 78.8\\% tokens compared with the SOTA method. The code is available at this https URL.', 'abstract_zh': 'Recent Multi-modal Large Language Models中的混合级指令注入策略用于条件_token压缩 (HICom)', 'title_zh': '多模态大语言模型中视频-token压缩的混合层级指令注入'}
{'arxiv_id': 'arXiv:2503.16025', 'title': 'Single Image Iterative Subject-driven Generation and Editing', 'authors': 'Yair Shpitzer, Gal Chechik, Idan Schwartz', 'link': 'https://arxiv.org/abs/2503.16025', 'abstract': 'Personalizing image generation and editing is particularly challenging when we only have a few images of the subject, or even a single image. A common approach to personalization is concept learning, which can integrate the subject into existing models relatively quickly, but produces images whose quality tends to deteriorate quickly when the number of subject images is small. Quality can be improved by pre-training an encoder, but training restricts generation to the training distribution, and is time consuming. It is still an open hard challenge to personalize image generation and editing from a single image without training. Here, we present SISO, a novel, training-free approach based on optimizing a similarity score with an input subject image. More specifically, SISO iteratively generates images and optimizes the model based on loss of similarity with the given subject image until a satisfactory level of similarity is achieved, allowing plug-and-play optimization to any image generator. We evaluated SISO in two tasks, image editing and image generation, using a diverse data set of personal subjects, and demonstrate significant improvements over existing methods in image quality, subject fidelity, and background preservation.', 'abstract_zh': '基于输入主题图像优化相似度评分的单图像个性化图像生成与编辑方法', 'title_zh': '单图像迭代主题驱动生成与编辑'}
{'arxiv_id': 'arXiv:2503.16024', 'title': 'The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement', 'authors': 'Ruihan Yang, Fanghua Ye, Jian Li, Siyu Yuan, Yikai Zhang, Zhaopeng Tu, Xiaolong Li, Deqing Yang', 'link': 'https://arxiv.org/abs/2503.16024', 'abstract': 'Large language models (LLMs) have recently transformed from text-based assistants to autonomous agents capable of planning, reasoning, and iteratively improving their actions. While numerical reward signals and verifiers can effectively rank candidate actions, they often provide limited contextual guidance. In contrast, natural language feedback better aligns with the generative capabilities of LLMs, providing richer and more actionable suggestions. However, parsing and implementing this feedback effectively can be challenging for LLM-based agents. In this work, we introduce Critique-Guided Improvement (CGI), a novel two-player framework, comprising an actor model that explores an environment and a critic model that generates detailed nature language feedback. By training the critic to produce fine-grained assessments and actionable revisions, and the actor to utilize these critiques, our approach promotes more robust exploration of alternative strategies while avoiding local optima. Experiments in three interactive environments show that CGI outperforms existing baselines by a substantial margin. Notably, even a small critic model surpasses GPT-4 in feedback quality. The resulting actor achieves state-of-the-art performance, demonstrating the power of explicit iterative guidance to enhance decision-making in LLM-based agents.', 'abstract_zh': '大型语言模型(Large Language Models, LLMs)从基于文本的助手演变成为能够规划、推理并迭代改进其行动的自主代理。虽然数值奖励信号和验证器可以有效排名候选行动，但它们往往提供有限的上下文指导。相比之下，自然语言反馈与LLMs的生成能力更相符，能提供更加丰富和可操作的建议。然而，有效地解析和实施这种反馈对基于LLM的代理来说具有挑战性。在这种背景下，我们提出了批判指导改进(Critique-Guided Improvement, CGI)，这是一种新颖的两玩家框架，包括一个探索环境的actor模型和一个生成详细自然语言反馈的critic模型。通过训练critic生成细致的评估并提出可操作的修订，以及训练actor利用这些批判性反馈，我们的方法促进了更稳健的替代策略探索，避免了局部最优。在三个交互环境中进行的实验表明，CGI显著优于现有基线。值得注意的是，即使一个小型critic模型也超越了GPT-4的反馈质量。由此产生的actor实现了最新的性能，展示了对基于LLM的代理决策制定进行明确迭代指导的力量。', 'title_zh': '语言的灯塔：通过批评指导改进增强LLM代理'}
{'arxiv_id': 'arXiv:2503.16021', 'title': 'Autonomous AI imitators increase diversity in homogeneous information ecosystems', 'authors': 'Emil Bakkensen Johansen, Oliver Baumann', 'link': 'https://arxiv.org/abs/2503.16021', 'abstract': "Recent breakthroughs in large language models (LLMs) have facilitated autonomous AI agents capable of imitating human-generated content. This technological advancement raises fundamental questions about AI's potential impact on the diversity and democratic value of information ecosystems. Here, we introduce a large-scale simulation framework to examine AI-based imitation in news, a context critically influential for public discourse. By systematically testing two distinct imitation strategies across a range of information environments varying in initial diversity, we demonstrate that AI-generated articles do not uniformly homogenize content. Instead, AI's influence is strongly context-dependent: AI-generated articles can introduce valuable diversity in originally homogeneous news environments, while potentially diminishing diversity in contexts that initially display high heterogeneity. These results illustrate that the baseline diversity of an information space critically shapes AI's impact, challenging assumptions that AI-driven imitation uniformly threatens information diversity. Instead, when information is initially homogeneous, AI-driven imitation can expand perspectives, styles, and topics. This is especially important in news contexts, where information diversity fosters richer public debate by exposing citizens to alternative viewpoints, challenging biases, and preventing narrative monopolies, which is essential for a resilient democracy.", 'abstract_zh': '近期大规模语言模型的突破促进了能够模仿人类生成内容的自主AI代理。这一技术进步引发了关于AI对信息生态系统多样性和民主价值潜在影响的基本问题。本文介绍了一个大规模模拟框架，以探讨基于AI的新闻模仿现象，这在公共辩论中具有关键影响。通过系统地测试两种不同的模仿策略在多样性初始水平变化的信息环境中，我们表明，AI生成的文章并非均匀同质化内容。相反，AI的影响在很大程度上取决于具体情境：在原本同质的新闻环境中，AI生成的文章可以引入有价值的多样性；而在初始多样性高的环境中，AI可能减少多样性。这些结果表明，信息空间的基线多样性对其影响至关重要，挑战了AI驱动模仿会统一对信息多样性的威胁这一假设。相反，在信息最初同质化的环境中，AI驱动的模仿可以扩展视角、风格和话题。这对于新闻领域尤为重要，因为信息多样性促进了更丰富的公共辩论，使公民接触到不同的观点，挑战偏见，防止单一叙事垄断，这对于建设性的民主是非常关键的。', 'title_zh': '自主AI模仿者增加同质信息生态系统的多样性'}
{'arxiv_id': 'arXiv:2503.15984', 'title': 'DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration', 'authors': 'Suraj Singh, Anastasia Batsheva, Oleg Y. Rogov, Ahmed Bouridane', 'link': 'https://arxiv.org/abs/2503.15984', 'abstract': "Contemporary image restoration and super-resolution techniques effectively harness deep neural networks, markedly outperforming traditional methods. However, astrophotography presents unique challenges for deep learning due to limited training data. This work explores hybrid strategies, such as the Deep Image Prior (DIP) model, which facilitates blind training but is susceptible to overfitting, artifact generation, and instability when handling noisy images. We propose enhancements to the DIP model's baseline performance through several advanced techniques. First, we refine the model to process multiple frames concurrently, employing the Back Projection method and the TVNet model. Next, we adopt a Markov approach incorporating Monte Carlo estimation, Langevin dynamics, and a variational input technique to achieve unbiased estimates with minimal variance and counteract overfitting effectively. Collectively, these modifications reduce the likelihood of noise learning and mitigate loss function fluctuations during training, enhancing result stability. We validated our algorithm across multiple image sets of astronomical and celestial objects, achieving performance that not only mitigates limitations of Lucky Imaging, a classical computer vision technique that remains a standard in astronomical image reconstruction but surpasses the original DIP model, state of the art transformer- and diffusion-based models, underscoring the significance of our improvements.", 'abstract_zh': '当代图像恢复和超分辨率技术有效利用了深度神经网络，显著优于传统方法。然而，由于训练数据有限，天文学成像对深度学习提出了独特挑战。本文探索了混合策略，如Deep Image Prior (DIP)模型，该模型可实现盲训练，但在处理噪声图像时容易过拟合、生成伪影和不稳定。我们通过多种高级技术增强了DIP模型的基本性能。首先，我们将模型改进为同时处理多帧图像，采用后投影方法和TVNet模型。其次，我们采用马尔可夫方法结合蒙特卡洛估计、朗格vin动力学和变分输入技术，实现无偏差且方差小的估计，并有效防止过拟合。这些修改降低了噪声学习的可能性，并在训练过程中减少了损失函数波动，提高结果稳定性。我们使用多个天文和天体图像数据集验证了该算法，其性能不仅缓解了幸运成像这一传统计算机视觉技术的局限性，还超越了原始DIP模型和最先进的基于变换器和扩散的模型，突显了我们改进的重要性。', 'title_zh': 'DIPLI: 深度图像先验 Lucky 成像 Methods for 盲 动力学天文图像恢复'}
{'arxiv_id': 'arXiv:2503.15983', 'title': 'InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer', 'authors': 'Tony Zhang, Rickard Brännvall', 'link': 'https://arxiv.org/abs/2503.15983', 'abstract': "This work explores optimizing transformer-based language models by integrating model compression techniques with inhibitor attention, a novel alternative attention mechanism. Inhibitor attention employs Manhattan distances and ReLU activations instead of the matrix multiplications and softmax activation of the conventional scaled dot-product attention. This shift offers potential computational and energy savings while maintaining model effectiveness. We propose further adjustments to improve the inhibitor mechanism's training efficiency and evaluate its performance on the DistilBERT architecture. Our knowledge distillation experiments indicate that the modified inhibitor transformer model can achieve competitive performance on standard NLP benchmarks, including General Language Understanding Evaluation (GLUE) and sentiment analysis tasks.", 'abstract_zh': '通过结合模型压缩技术与抑制注意机制优化基于变压器的语言模型', 'title_zh': 'InhibiDistilBert: ReLU和加法基于的Transformer的知识蒸馏'}
{'arxiv_id': 'arXiv:2503.15969', 'title': 'Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation', 'authors': 'Clive Tinashe Marimo, Benedikt Blumenstiel, Maximilian Nitsche, Johannes Jakubik, Thomas Brunschwiler', 'link': 'https://arxiv.org/abs/2503.15969', 'abstract': 'Vision-language models for Earth observation (EO) typically rely on the visual spectrum of data as the only model input, thus failing to leverage the rich spectral information available in the multispectral channels recorded by satellites. Therefore, in this paper, we introduce Llama3-MS-CLIP, the first vision-language model pre-trained with contrastive learning on a large-scale multispectral dataset and report on the performance gains due to the extended spectral range. Furthermore, we present the largest-to-date image-caption dataset for multispectral data, consisting of one million Sentinel-2 samples and corresponding textual descriptions generated with Llama3-LLaVA-Next and Overture Maps data. We develop a scalable captioning pipeline, which is validated by domain experts. We evaluate Llama3-MS-CLIP on multispectral zero-shot image classification and retrieval using three datasets of varying complexity. Our results demonstrate that Llama3-MS-CLIP significantly outperforms other RGB-based approaches, improving classification accuracy by 6.77% on average and retrieval performance by 4.63% mAP compared to the second-best model. Our results emphasize the relevance of multispectral vision-language learning. We release the image-caption dataset, code, and model weights under an open-source license.', 'abstract_zh': 'Vision-language模型应用于地球观测（EO）通常仅依赖视觉谱数据作为模型输入，未能充分利用多光谱卫星记录的丰富光谱信息。因此，在本文中，我们介绍了Llama3-MS-CLIP，这是首个采用对比学习在大规模多光谱数据集上进行预训练的vision-language模型，并报告了由于光谱范围的扩展所带来的性能提升。此外，我们呈现了迄今为止最大的多光谱数据图像配对集，包含一百万份Sentinel-2样本及其由Llama3-LLaVA-Next和Overture Maps数据生成的文本描述。我们开发了一种可扩展的配对管道，并通过领域专家验证。我们利用三个不同复杂度的数据集对Llama3-MS-CLIP进行多光谱零样本图像分类和检索评估。我们的结果显示，Llama3-MS-CLIP显著优于其他基于RGB的方法，在分类精度方面平均提高了6.77%，检索性能的mAP提高了4.63%，优于其他模型。我们的结果强调了多光谱vision-language学习的相关性。我们以开源许可发布图像配对集、代码和模型权重。', 'title_zh': '超越可见光：地球观测的多光谱视觉-语言学习'}
{'arxiv_id': 'arXiv:2503.15953', 'title': 'GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth', 'authors': 'Mohammed Attaoui, Fabrizio Pastore', 'link': 'https://arxiv.org/abs/2503.15953', 'abstract': 'The generation of synthetic inputs via simulators driven by search algorithms is essential for cost-effective testing of Deep Neural Network (DNN) components for safety-critical systems. However, in many applications, simulators are unable to produce the ground-truth data needed for automated test oracles and to guide the search process.\nTo tackle this issue, we propose an approach for the generation of inputs for computer vision DNNs that integrates a generative network to ensure simulator fidelity and employs heuristic-based search fitnesses that leverage transformation consistency, noise resistance, surprise adequacy, and uncertainty estimation. We compare the performance of our fitnesses with that of a traditional fitness function leveraging ground truth; further, we assess how the integration of a GAN not leveraging the ground truth impacts on test and retraining effectiveness.\nOur results suggest that leveraging transformation consistency is the best option to generate inputs for both DNN testing and retraining; it maximizes input diversity, spots the inputs leading to worse DNN performance, and leads to best DNN performance after retraining. Besides enabling simulator-based testing in the absence of ground truth, our findings pave the way for testing solutions that replace costly simulators with diffusion and large language models, which might be more affordable than simulators, but cannot generate ground-truth data.', 'abstract_zh': '通过搜索算法驱动模拟器生成合成输入以生成计算机视觉深度神经网络组件的成本有效测试数据是一个关键问题。然而，在许多应用中，模拟器无法产生所需的ground-truth数据以供自动测试或acles使用，也无法引导搜索过程。为解决这一问题，我们提出了一种结合生成网络确保模拟器保真度并利用基于启发式的搜索适应度的方法，这些适应度利用了变换一致性、噪声鲁棒性、惊喜恰当性和不确定性估计。我们将我们的适应度与利用ground-truth的传统适应度进行比较；此外，我们评估了不利用ground-truth的生成对抗网络（GAN）集成对测试和重新训练效果的影响。研究结果表明，利用变换一致性是生成用于DNN测试和重新训练输入的最佳选项，它最大化输入多样性，识别出导致DNN性能变差的输入，并在重新训练后达到最佳DNN性能。此外，我们的发现为使用扩散模型和大语言模型替代昂贵模拟器以进行测试铺平了道路，这些模型可能比模拟器更经济实惠，但无法生成ground-truth数据。', 'title_zh': 'GAN增强的基于仿真驱动的DNN测试在无地面真实数据情况下的应用'}
{'arxiv_id': 'arXiv:2503.15948', 'title': "Don't Fight Hallucinations, Use Them: Estimating Image Realism using NLI over Atomic Facts", 'authors': 'Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Alexander Panchenko, Vasily Konovalov', 'link': 'https://arxiv.org/abs/2503.15948', 'abstract': "Quantifying the realism of images remains a challenging problem in the field of artificial intelligence. For example, an image of Albert Einstein holding a smartphone violates common-sense because modern smartphone were invented after Einstein's death. We introduce a novel method for assessing image realism using Large Vision-Language Models (LVLMs) and Natural Language Inference (NLI). Our approach is based on the premise that LVLMs may generate hallucinations when confronted with images that defy common sense. Using LVLM to extract atomic facts from these images, we obtain a mix of accurate facts and erroneous hallucinations. We proceed by calculating pairwise entailment scores among these facts, subsequently aggregating these values to yield a singular reality score. This process serves to identify contradictions between genuine facts and hallucinatory elements, signaling the presence of images that violate common sense. Our approach has achieved a new state-of-the-art performance in zero-shot mode on the WHOOPS! dataset.", 'abstract_zh': '量化图像的真实度仍然是人工智能领域的一项挑战性问题。例如，爱因斯坦手持智能手机的图像违反常识，因为现代智能手机是在爱因斯坦去世之后才发明的。我们提出了一种使用大型视觉-语言模型（LVLM）和自然语言推理（NLI）评估图像真实度的新方法。该方法基于假设，当LVLM遇到违反常识的图像时，可能会产生幻觉。通过使用LVLM从这些图像中提取原子事实，我们获得了准确事实和错误幻觉的混合体。接下来，我们计算这些事实之间的成对蕴含得分，并将其聚合为单一的真实度得分。这个过程有助于识别真正事实与幻觉元素之间的矛盾，指出了违反常识的图像的存在。我们的方法在WHOOPS!数据集上以零样本模式达到了新的最佳性能。', 'title_zh': '不要与幻觉抗争，利用它们：使用原子事实进行图像现实性估计'}
{'arxiv_id': 'arXiv:2503.15924', 'title': 'Towards Automatic Continual Learning: A Self-Adaptive Framework for Continual Instruction Tuning', 'authors': 'Peiyi Lin, Fukai Zhang, Kai Niu, Hao Fu', 'link': 'https://arxiv.org/abs/2503.15924', 'abstract': 'Continual instruction tuning enables large language models (LLMs) to learn incrementally while retaining past knowledge, whereas existing methods primarily focus on how to retain old knowledge rather than on selecting which new knowledge to learn. In domain-specific contexts, maintaining data quality and managing system constraints remain key challenges. To address these issues, we propose an automated continual instruction tuning framework that dynamically filters incoming data, which identify and reduce redundant data across successive updates. Our approach utilizes a small proxy model for efficient perplexity-based filtering, and updates the proxy to ensure that the filtering criteria remain aligned with the evolving state of the deployed model. Compared to existing static data selection methods, our framework can effectively handle incrementally acquired data and shifting distributions. Additionally, it addresses practical deployment challenges by enabling seamless model updates, supporting version rollback and incorporating automatic checkpoint evaluation. We evaluated the system in real-world medical scenarios. It reduced computational costs by 66.7% and improved model performance, and achieved autonomous updates, thus demonstrating its effectiveness for automatic continual instruction tuning.', 'abstract_zh': '连续指令调优使大规模语言模型能够在保留过去知识的同时增量学习，而现有方法主要关注如何保留旧知识而不是选择学习哪些新知识。在专业领域背景下，保持数据质量和管理系统约束仍然是关键挑战。为应对这些挑战，我们提出了一种自动连续指令调优框架，该框架能够动态筛选流入数据，识别并减少 successive 更新过程中的冗余数据。该方法利用一个小尺寸代理模型进行高效的语言混乱度为基础的筛选，并更新代理模型以确保筛选标准与部署模型的不断演变状态保持一致。与现有的静态数据选择方法相比，我们的框架能够有效处理增量获取的数据和分布偏移。此外，该框架通过支持无缝模型更新、版本回退和自动检查点评估来应对实际部署挑战。我们在实际医疗场景中评估了该系统，结果显示其将计算成本降低了66.7%，提升了模型性能，并实现了自主更新，从而证明了其在自动连续指令调优方面的有效性。', 'title_zh': '向自动连续学习迈进：一种自适应连续指令调整框架'}
{'arxiv_id': 'arXiv:2503.15918', 'title': 'Denoising-based Contractive Imitation Learning', 'authors': 'Macheng Shen, Jishen Peng, Zefang Huang', 'link': 'https://arxiv.org/abs/2503.15918', 'abstract': 'A fundamental challenge in imitation learning is the \\emph{covariate shift} problem. Existing methods to mitigate covariate shift often require additional expert interactions, access to environment dynamics, or complex adversarial training, which may not be practical in real-world applications. In this paper, we propose a simple yet effective method (DeCIL) to mitigate covariate shift by incorporating a denoising mechanism that enhances the contraction properties of the state transition mapping. Our approach involves training two neural networks: a dynamics model ( f ) that predicts the next state from the current state, and a joint state-action denoising policy network ( d ) that refines this state prediction via denoising and outputs the corresponding action. We provide theoretical analysis showing that the denoising network acts as a local contraction mapping, reducing the error propagation of the state transition and improving stability. Our method is straightforward to implement and can be easily integrated with existing imitation learning frameworks without requiring additional expert data or complex modifications to the training procedure. Empirical results demonstrate that our approach effectively improves success rate of various imitation learning tasks under noise perturbation.', 'abstract_zh': '仿生学习中的一个基本挑战是协变量偏移问题。现有缓解协变量偏移的方法通常需要额外的专家交互、访问环境动力学或复杂的对抗性训练，这些在实际应用中可能并不实用。在本文中，我们提出了一种简单而有效的方法（DeCIL），通过引入一种去噪机制来增强状态转换映射的收缩性质以缓解协变量偏移。我们的方法包括训练两个神经网络：一个动力学模型（f），它根据当前状态预测下一个状态；以及一个联合状态-动作去噪策略网络（d），它通过去噪来细化这个状态预测并输出相应的动作。我们提供了理论分析以证明去噪网络作为局部收缩映射的作用，从而减少状态转换过程中的误差传播并提高稳定性。该方法易于实现，并且可以轻松与现有的仿生学习框架集成，无需额外的专家数据或复杂的训练程序修改。实验证明，该方法在噪声干扰下有效提高了各种仿生学习任务的成功率。', 'title_zh': '基于去噪收缩模仿学习'}
{'arxiv_id': 'arXiv:2503.15910', 'title': 'No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather', 'authors': 'Junsung Park, Hwijeong Lee, Inha Kang, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2503.15910', 'abstract': 'Existing domain generalization methods for LiDAR semantic segmentation under adverse weather struggle to accurately predict "things" categories compared to "stuff" categories. In typical driving scenes, "things" categories can be dynamic and associated with higher collision risks, making them crucial for safe navigation and planning. Recognizing the importance of "things" categories, we identify their performance drop as a serious bottleneck in existing approaches. We observed that adverse weather induces degradation of semantic-level features and both corruption of local features, leading to a misprediction of "things" as "stuff". To mitigate these corruptions, we suggest our method, NTN - segmeNt Things for No-accident. To address semantic-level feature corruption, we bind each point feature to its superclass, preventing the misprediction of things classes into visually dissimilar categories. Additionally, to enhance robustness against local corruption caused by adverse weather, we define each LiDAR beam as a local region and propose a regularization term that aligns the clean data with its corrupted counterpart in feature space. NTN achieves state-of-the-art performance with a +2.6 mIoU gain on the SemanticKITTI-to-SemanticSTF benchmark and +7.9 mIoU on the SemanticPOSS-to-SemanticSTF benchmark. Notably, NTN achieves a +4.8 and +7.9 mIoU improvement on "things" classes, respectively, highlighting its effectiveness.', 'abstract_zh': '基于LiDAR语义分割的恶劣天气域泛化方法中“things”类别预测的性能瓶颈及其解决', 'title_zh': '无物，空无：突出安全关键类以提高恶劣天气下LiDAR语义分割的鲁棒性'}
{'arxiv_id': 'arXiv:2503.15908', 'title': 'Enhancing Close-up Novel View Synthesis via Pseudo-labeling', 'authors': 'Jiatong Xia, Libo Sun, Lingqiao Liu', 'link': 'https://arxiv.org/abs/2503.15908', 'abstract': 'Recent methods, such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have demonstrated remarkable capabilities in novel view synthesis. However, despite their success in producing high-quality images for viewpoints similar to those seen during training, they struggle when generating detailed images from viewpoints that significantly deviate from the training set, particularly in close-up views. The primary challenge stems from the lack of specific training data for close-up views, leading to the inability of current methods to render these views accurately. To address this issue, we introduce a novel pseudo-label-based learning strategy. This approach leverages pseudo-labels derived from existing training data to provide targeted supervision across a wide range of close-up viewpoints. Recognizing the absence of benchmarks for this specific challenge, we also present a new dataset designed to assess the effectiveness of both current and future methods in this area. Our extensive experiments demonstrate the efficacy of our approach.', 'abstract_zh': 'Recent Methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS)展现出了在新颖视图合成方面的卓越能力。然而，尽管这些方法在生成与训练视角相似的高质量图像方面表现出色，但在生成与训练集差异较大的视角（尤其是近距离视角）的详细图像时存在局限性。主要挑战源自近距离视角缺乏特定训练数据，导致当前方法难以准确渲染这些视角。为解决这一问题，我们提出了一种新型的伪标签驱动的学习策略。该方法利用现有训练数据衍生的伪标签，为广泛的近距离视角提供针对性监督。鉴于缺乏针对这一特定挑战的基准测试，我们还提供了一个新数据集，用于评估当前和未来方法在该领域的有效性。我们的大量实验结果证明了该方法的有效性。', 'title_zh': '基于伪标签增强近距离新颖视角合成'}
{'arxiv_id': 'arXiv:2503.15905', 'title': 'Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation', 'authors': 'Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li, Kang Liao, Yao Zhao', 'link': 'https://arxiv.org/abs/2503.15905', 'abstract': "In this paper, we propose Jasmine, the first Stable Diffusion (SD)-based self-supervised framework for monocular depth estimation, which effectively harnesses SD's visual priors to enhance the sharpness and generalization of unsupervised prediction. Previous SD-based methods are all supervised since adapting diffusion models for dense prediction requires high-precision supervision. In contrast, self-supervised reprojection suffers from inherent challenges (e.g., occlusions, texture-less regions, illumination variance), and the predictions exhibit blurs and artifacts that severely compromise SD's latent priors. To resolve this, we construct a novel surrogate task of hybrid image reconstruction. Without any additional supervision, it preserves the detail priors of SD models by reconstructing the images themselves while preventing depth estimation from degradation. Furthermore, to address the inherent misalignment between SD's scale and shift invariant estimation and self-supervised scale-invariant depth estimation, we build the Scale-Shift GRU. It not only bridges this distribution gap but also isolates the fine-grained texture of SD output against the interference of reprojection loss. Extensive experiments demonstrate that Jasmine achieves SoTA performance on the KITTI benchmark and exhibits superior zero-shot generalization across multiple datasets.", 'abstract_zh': 'Jasmine：基于Stable Diffusion的首个自监督单目深度估计框架', 'title_zh': 'Jasmin: 利用扩散先验进行自监督深度估计'}
{'arxiv_id': 'arXiv:2503.15904', 'title': 'From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling', 'authors': 'Evan Chen, Run-Jun Zhan, Yan-Bai Lin, Hung-Hsuan Chen', 'link': 'https://arxiv.org/abs/2503.15904', 'abstract': 'Large Language Models (LLMs) have revolutionized natural language processing, yet concerns persist regarding their tendency to reflect or amplify social biases present in their training data. This study introduces a novel evaluation framework to uncover gender biases in LLMs, focusing on their occupational narratives. Unlike previous methods relying on structured scenarios or carefully crafted prompts, our approach leverages free-form storytelling to reveal biases embedded in the models. Systematic analyses show an overrepresentation of female characters across occupations in six widely used LLMs. Additionally, our findings reveal that LLM-generated occupational gender rankings align more closely with human stereotypes than actual labor statistics. These insights underscore the need for balanced mitigation strategies to ensure fairness while avoiding the reinforcement of new stereotypes.', 'abstract_zh': '大型语言模型中的性别偏见评估：基于职业叙事的新型框架', 'title_zh': '从结构化提示到开放叙事：通过开放式讲故事衡量LLM中的性别偏见'}
{'arxiv_id': 'arXiv:2503.15901', 'title': 'A multi-model approach using XAI and anomaly detection to predict asteroid hazards', 'authors': 'Amit Kumar Mondal, Nafisha Aslam, Prasenjit Maji, Hemanta Kumar Mondal', 'link': 'https://arxiv.org/abs/2503.15901', 'abstract': 'The potential for catastrophic collision makes near-Earth asteroids (NEAs) a serious concern. Planetary defense depends on accurately classifying potentially hazardous asteroids (PHAs), however the complexity of the data hampers conventional techniques. This work offers a sophisticated method for accurately predicting hazards by combining machine learning, deep learning, explainable AI (XAI), and anomaly detection. Our approach extracts essential parameters like size, velocity, and trajectory from historical and real-time asteroid data. A hybrid algorithm improves prediction accuracy by combining several cutting-edge models. A forecasting module predicts future asteroid behavior, and Monte Carlo simulations evaluate the likelihood of collisions. Timely mitigation is made possible by a real-time alarm system that notifies worldwide monitoring stations. This technique enhances planetary defense efforts by combining real-time alarms with sophisticated predictive modeling.', 'abstract_zh': '近地小行星（NEAs）潜在的 catastrophic 碰撞使其成为严重关切对象。行星防御依赖于准确分类潜在危险小行星（PHAs），然而数据的复杂性阻碍了传统技术。本工作提出了一种结合机器学习、深度学习、可解释AI（XAI）和异常检测的复杂方法，以精确预测潜在风险。该方法从历史和实时小行星数据中提取关键参数，如大小、速度和轨道。混合算法通过结合多种先进模型提高预测准确性。预报模块预测未来小行星行为，蒙特卡洛模拟评估碰撞的可能性。实时警报系统使得及时的缓解措施成为可能，通知全球监测站。该技术通过结合实时警报和复杂的预测建模增强了行星防御努力。', 'title_zh': '基于XAI和异常检测的多模型方法预测小行星危害'}
{'arxiv_id': 'arXiv:2503.15890', 'title': 'Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do', 'authors': 'Yoav Wald, Mark Goldstein, Yonathan Efroni, Wouter A.C. van Amsterdam, Rajesh Ranganath', 'link': 'https://arxiv.org/abs/2503.15890', 'abstract': 'Problems in fields such as healthcare, robotics, and finance requires reasoning about the value both of what decision or action to take and when to take it. The prevailing hope is that artificial intelligence will support such decisions by estimating the causal effect of policies such as how to treat patients or how to allocate resources over time. However, existing methods for estimating the effect of a policy struggle with \\emph{irregular time}. They either discretize time, or disregard the effect of timing policies. We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models, such as transformers. EDQ provides accurate estimates under standard assumptions. We validate the approach through experiments on survival time and tumor growth tasks.', 'abstract_zh': '医疗、机器人技术及金融等领域中存在的问题要求对何时采取何种决策及其效果进行推理。现有的希望是，人工智能能通过估计政策（如如何治疗患者或如何在时间上分配资源）的效果来支持这样的决策。然而，现有的政策效果估计方法在处理不规则时间时存在困难。它们要么离散化时间，要么忽视政策时间效应。我们提出了一种新的深度Q算法，称为最早分歧Q评估（EDQ），它能同时估计何时及采取何种行动的效果。EDQ利用递归构建Q函数，兼容灵活的序列模型（如变换器）。在标准假设下，EDQ能提供准确的估计。我们通过生存时间和肿瘤生长任务的实验验证了该方法。', 'title_zh': '反复的时间：基于深度Q效应估计的何时以及做什么的干预研究'}
{'arxiv_id': 'arXiv:2503.15889', 'title': 'LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices', 'authors': 'Cynthia Dong, Hong Jia, Young D. Kwon, Georgios Rizos, Cecilia Mascolo', 'link': 'https://arxiv.org/abs/2503.15889', 'abstract': 'While there are many advantages to deploying machine learning models on edge devices, the resource constraints of mobile platforms, the dynamic nature of the environment, and differences between the distribution of training versus in-the-wild data make such deployments challenging. Current test-time adaptation methods are often memory-intensive and not designed to be quantization-compatible or deployed on low-resource devices. To address these challenges, we present LeanTTA, a novel backpropagation-free and stateless framework for quantized test-time adaptation tailored to edge devices. Our approach minimizes computational costs by dynamically updating normalization statistics without backpropagation, which frees LeanTTA from the common pitfall of relying on large batches and historical data, making our method robust to realistic deployment scenarios. Our approach is the first to enable further computational gains by combining partial adaptation with quantized module fusion. We validate our framework across sensor modalities, demonstrating significant improvements over state-of-the-art TTA methods, including a 15.7% error reduction, peak memory usage of only 11.2MB for ResNet18, and fast adaptation within an order-of-magnitude of normal inference speeds on-device. LeanTTA provides a robust solution for achieving the right trade offs between accuracy and system efficiency in edge deployments, addressing the unique challenges posed by limited data and varied operational conditions.', 'abstract_zh': 'LeanTTA：面向边缘设备的无回传状态less量化测试时自适应框架', 'title_zh': 'LeanTTA: 一种无反向传播且无状态的边缘设备上量化测试时适应方法'}
{'arxiv_id': 'arXiv:2503.15888', 'title': 'Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models', 'authors': 'Baolong Bi, Shenghua Liu, Yiwei Wang, Yilong Xu, Junfeng Fang, Lingrui Mei, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2503.15888', 'abstract': "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large Language Models (LLMs) by integrating external knowledge. However, conflicts between parametric knowledge and retrieved context pose challenges, particularly when retrieved information is unreliable or the model's internal knowledge is outdated. In such cases, LLMs struggle to determine whether to rely more on their own parameters or the conflicted context. To address this, we propose **CK-PLUG**, a plug-and-play method for controlling LLMs' reliance on parametric and contextual knowledge. We introduce a novel knowledge consistency metric, Confidence Gain, which detects knowledge conflicts by measuring entropy shifts in token probability distributions after context insertion. CK-PLUG then enables fine-grained control over knowledge preference by adjusting the probability distribution of tokens with negative confidence gain through a single tuning parameter. Experiments demonstrate CK-PLUG's ability to significantly regulate knowledge reliance in counterfactual RAG scenarios while maintaining generation fluency and knowledge accuracy. For instance, on Llama3-8B, memory recall (MR) of RAG response can be adjusted within a broad range (9.9%-71.9%), compared to the baseline of 42.1%. Moreover, CK-PLUG supports adaptive control based on the model's confidence in both internal and external knowledge, achieving consistent performance improvements across various general RAG tasks. Our code is available at: $\\href{this https URL}{\\text{this https URL}}$.", 'abstract_zh': 'CK-PLUG：一种控制大语言模型参数性和上下文性知识依赖性的插件式方法', 'title_zh': '参数 vs. 上下文：语言模型中知识依赖的细粒度控制'}
{'arxiv_id': 'arXiv:2503.15867', 'title': 'TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data', 'authors': 'Rohit Kundu, Athula Balachandran, Amit K. Roy-Chowdhury', 'link': 'https://arxiv.org/abs/2503.15867', 'abstract': 'Detecting DeepFakes has become a crucial research area as the widespread use of AI image generators enables the effortless creation of face-manipulated and fully synthetic content, yet existing methods are often limited to binary classification (real vs. fake) and lack interpretability. To address these challenges, we propose TruthLens, a novel and highly generalizable framework for DeepFake detection that not only determines whether an image is real or fake but also provides detailed textual reasoning for its predictions. Unlike traditional methods, TruthLens effectively handles both face-manipulated DeepFakes and fully AI-generated content while addressing fine-grained queries such as "Does the eyes/nose/mouth look real or fake?"\nThe architecture of TruthLens combines the global contextual understanding of multimodal large language models like PaliGemma2 with the localized feature extraction capabilities of vision-only models like DINOv2. This hybrid design leverages the complementary strengths of both models, enabling robust detection of subtle manipulations while maintaining interpretability. Extensive experiments on diverse datasets demonstrate that TruthLens outperforms state-of-the-art methods in detection accuracy (by 2-14%) and explainability, in both in-domain and cross-data settings, generalizing effectively across traditional and emerging manipulation techniques.', 'abstract_zh': '检测深度伪造已成为一个至关重要的研究领域，随着AI图像生成器的广泛使用，使得面部操纵和完全合成的内容得以轻松创建，但现有方法往往仅限于二元分类（真实 vs. 伪造）且缺乏可解释性。为应对这些挑战，我们提出TruthLens，这是一个新颖且高度通用的深度伪造检测框架，不仅确定图像是真实还是伪造的，还提供详细的文本推理解释其预测。与传统方法不同，TruthLens 能够有效处理面部操纵的深度伪造和完全由AI生成的内容，同时解决细粒度问题，如“眼睛/鼻子/嘴巴看起来是真实还是伪造的？”。\n\nTruthLens的架构结合了多模态大型语言模型PaliGemma2的全局上下文理解和仅视觉模型DINOv2的局部特征提取能力。这种混合设计利用了两种模型互补的优势，实现对细微篡改的 robust 检测，同时保持可解释性。在多种数据集上的广泛实验表明，TruthLens 在检测准确性和可解释性方面均优于现有最先进的方法（提高2-14%），并在领域内外数据集上表现出了有效的泛化能力，能够应对传统和新兴篡改技术。', 'title_zh': 'TruthLens: 可解释的深度假新闻检测方法及其对人脸篡改与全合成数据的应用'}
{'arxiv_id': 'arXiv:2503.15865', 'title': 'Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement', 'authors': 'Jong-Hyun Jeonga, Hongki Jo, Qiang Zhou, Tahsin Afroz Hoque Nishat, Lang Wu', 'link': 'https://arxiv.org/abs/2503.15865', 'abstract': 'Wireless sensor networks (WSNs) have become a promising solution for structural health monitoring (SHM), especially in hard-to-reach or remote locations. Battery-powered WSNs offer various advantages over wired systems, however limited battery life has always been one of the biggest obstacles in practical use of the WSNs, regardless of energy harvesting methods. While various methods have been studied for battery health management, existing methods exclusively aim to extend lifetime of individual batteries, lacking a system level view. A consequence of applying such methods is that batteries in a WSN tend to fail at different times, posing significant difficulty on planning and scheduling of battery replacement trip. This study investigate a deep reinforcement learning (DRL) method for active battery degradation management by optimizing duty cycle of WSNs at the system level. This active management strategy effectively reduces earlier failure of battery individuals which enable group replacement without sacrificing WSN performances. A simulated environment based on a real-world WSN setup was developed to train a DRL agent and learn optimal duty cycle strategies. The performance of the strategy was validated in a long-term setup with various network sizes, demonstrating its efficiency and scalability.', 'abstract_zh': '无线传感器网络（WSNs）已成为结构健康监测（SHM）的一个有前景的解决方案，特别是在难以到达或偏远的位置。基于电池的WSNs相较于有线系统具有多种优势，然而电池寿命有限始终是实际应用中的一个主要障碍，无论是否采用能量采集方法。尽管已经研究了多种电池健康管理方法，但现有方法仅专注于延长单个电池的寿命，缺乏系统层面的整体视角。这种方法的应用导致WSNs中的电池可能在不同时间失效，给电池更换计划和调度带来了重大挑战。本研究探讨了一种通过优化WSNs的系统级工作周期来主动管理电池退化状态的深度强化学习（DRL）方法。这种主动管理策略有效减少了单个电池过早失效的情况，使得能够进行团体更换而不牺牲WSNs的整体性能。基于实际WSNs配置的模拟环境被开发用于训练DRL代理并学习最优工作周期策略。通过长期设置下的各种网络规模验证了该策略的性能，展示了其效率和可扩展性。', 'title_zh': '使用深度强化学习进行群体电池更换的无线传感器网络中电池退化主动管理'}
{'arxiv_id': 'arXiv:2503.15855', 'title': 'VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling', 'authors': 'Hyojun Go, Byeongjun Park, Hyelin Nam, Byung-Hoon Kim, Hyungjin Chung, Changick Kim', 'link': 'https://arxiv.org/abs/2503.15855', 'abstract': 'We propose VideoRFSplat, a direct text-to-3D model leveraging a video generation model to generate realistic 3D Gaussian Splatting (3DGS) for unbounded real-world scenes. To generate diverse camera poses and unbounded spatial extent of real-world scenes, while ensuring generalization to arbitrary text prompts, previous methods fine-tune 2D generative models to jointly model camera poses and multi-view images. However, these methods suffer from instability when extending 2D generative models to joint modeling due to the modality gap, which necessitates additional models to stabilize training and inference. In this work, we propose an architecture and a sampling strategy to jointly model multi-view images and camera poses when fine-tuning a video generation model. Our core idea is a dual-stream architecture that attaches a dedicated pose generation model alongside a pre-trained video generation model via communication blocks, generating multi-view images and camera poses through separate streams. This design reduces interference between the pose and image modalities. Additionally, we propose an asynchronous sampling strategy that denoises camera poses faster than multi-view images, allowing rapidly denoised poses to condition multi-view generation, reducing mutual ambiguity and enhancing cross-modal consistency. Trained on multiple large-scale real-world datasets (RealEstate10K, MVImgNet, DL3DV-10K, ACID), VideoRFSplat outperforms existing text-to-3D direct generation methods that heavily depend on post-hoc refinement via score distillation sampling, achieving superior results without such refinement.', 'abstract_zh': 'VideoRFSplat：一种直接文本到3D模型，利用视频生成模型生成现实场景的逼真3D高斯斑点', 'title_zh': '视频级场景级文本到3D高斯点云的直接生成：具有灵活姿态和多视图联合建模'}
{'arxiv_id': 'arXiv:2503.15837', 'title': 'Fùxì: A Benchmark for Evaluating Language Models on Ancient Chinese Text Understanding and Generation', 'authors': 'Shangqing Zhao, Yuhao Zhou, Yupei Ren, Zhe Chen, Chenghao Jia, Fang Zhe, Zhaogaung Long, Shu Liu, Man Lan', 'link': 'https://arxiv.org/abs/2503.15837', 'abstract': "Ancient Chinese text processing presents unique challenges for large language models (LLMs) due to its distinct linguistic features, complex structural constraints, and rich cultural context. While existing benchmarks have primarily focused on evaluating comprehension through multiple-choice questions, there remains a critical gap in assessing models' generative capabilities in classical Chinese. We introduce Fùxì, a comprehensive benchmark that evaluates both understanding and generation capabilities across 21 diverse tasks. Our benchmark distinguishes itself through three key contributions: (1) balanced coverage of both comprehension and generation tasks, including novel tasks like poetry composition and couplet completion, (2) specialized evaluation metrics designed specifically for classical Chinese text generation, combining rule-based verification with fine-tuned LLM evaluators, and (3) a systematic assessment framework that considers both linguistic accuracy and cultural authenticity. Through extensive evaluation of state-of-the-art LLMs, we reveal significant performance gaps between understanding and generation tasks, with models achieving promising results in comprehension but struggling considerably in generation tasks, particularly those requiring deep cultural knowledge and adherence to classical formats. Our findings highlight the current limitations in ancient Chinese text processing and provide insights for future model development. The benchmark, evaluation toolkit, and baseline results are publicly available to facilitate research in this domain.", 'abstract_zh': '古代中文文本处理对大型语言模型（LLMs）提出了独特的挑战，这源于其独特的语言特征、复杂的结构约束以及丰富的文化背景。尽管现有基准主要侧重于通过选择题评估理解能力，但在评估模型在古典中文方面的生成能力上仍存在关键缺口。我们提出了傅 sik（Fùxì），这是一个综合基准，涵盖了21个多样化的任务，评估模型的理解和生成能力。该基准通过三个方面区分自身：（1）在理解和生成任务之间实现平衡覆盖，包括如诗歌创作和对联填充等新型任务；（2）专门设计的评估指标，针对古典中文文本生成进行定制，结合基于规则的验证和微调的LLM评估器；（3）系统性评估框架，同时考虑语言准确性和文化真实性。通过广泛评估最先进的LLMs，我们揭示了理解和生成任务之间显著的性能差距，模型在理解方面取得令人鼓舞的结果，但在生成任务上却表现不佳，尤其是那些需要深厚文化知识和遵循古典格式的任务。我们的研究结果指出了古代中文文本处理的当前局限性，并为未来模型开发提供了见解。该基准、评估工具包和基线结果均已公开，以促进该领域的研究。', 'title_zh': '傅氏：古代中文文本理解与生成语言模型benchmark'}
{'arxiv_id': 'arXiv:2503.15818', 'title': 'Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection', 'authors': 'Haotian Ma, Lin Gu, Siyi Wu, Yingying Zhu', 'link': 'https://arxiv.org/abs/2503.15818', 'abstract': '3D point cloud has been widely used in applications such as self-driving cars, robotics, CAD models, etc. To the best of our knowledge, these applications raised the issue of privacy leakage in 3D point clouds, which has not been studied well. Different from the 2D image privacy, which is related to texture and 2D geometric structure, the 3D point cloud is texture-less and only relevant to 3D geometric structure. In this work, we defined the 3D point cloud privacy problem and proposed an efficient privacy-preserving framework named PointFlowGMM that can support downstream classification and segmentation tasks without seeing the original data. Using a flow-based generative model, the point cloud is projected into a latent Gaussian mixture distributed subspace. We further designed a novel angular similarity loss to obfuscate the original geometric structure and reduce the model size from 767MB to 120MB without a decrease in recognition performance. The projected point cloud in the latent space is orthogonally rotated randomly to further protect the original geometric structure, the class-to-class relationship is preserved after rotation, thus, the protected point cloud can support the recognition task. We evaluated our model on multiple datasets and achieved comparable recognition results on encrypted point clouds compared to the original point clouds.', 'abstract_zh': '3D点云隐私保护问题及其高效框架PointFlowGMM研究', 'title_zh': '计算高效且识别友好的3D点云隐私保护'}
{'arxiv_id': 'arXiv:2503.15808', 'title': 'ChatGPT and U(X): A Rapid Review on Measuring the User Experience', 'authors': 'Katie Seaborn', 'link': 'https://arxiv.org/abs/2503.15808', 'abstract': 'ChatGPT, powered by a large language model (LLM), has revolutionized everyday human-computer interaction (HCI) since its 2022 release. While now used by millions around the world, a coherent pathway for evaluating the user experience (UX) ChatGPT offers remains missing. In this rapid review (N = 58), I explored how ChatGPT UX has been approached quantitatively so far. I focused on the independent variables (IVs) manipulated, the dependent variables (DVs) measured, and the methods used for measurement. Findings reveal trends, gaps, and emerging consensus in UX assessments. This work offers a first step towards synthesizing existing approaches to measuring ChatGPT UX, urgent trajectories to advance standardization and breadth, and two preliminary frameworks aimed at guiding future research and tool development. I seek to elevate the field of ChatGPT UX by empowering researchers and practitioners in optimizing user interactions with ChatGPT and similar LLM-based systems.', 'abstract_zh': 'ChatGPT，作为一种大规模语言模型（LLM），自2022年发布以来已 revolutionized 每日的人机交互（HCI）。尽管现在全球有数百万人在使用，但迄今为止评估ChatGPT用户体验（UX）的统一途径仍然缺失。在此快速综述（N = 58）中，我探讨了迄今为止如何从定量角度研究ChatGPT UX。我的关注点是操纵的独立变量（IVs）、测量的依赖变量（DVs）以及采用的测量方法。研究发现显示了UX评估的趋势、空白和新兴共识。这项工作朝着综合现有衡量ChatGPT UX的方法迈出了一步，指出了急需推进标准化和范围扩大化的紧迫路径，并提出了两个初步框架以指导未来的研究和工具开发。我力争通过赋能研究人员和实践者来优化用户与ChatGPT及其类似LLM系统的交互，提升ChatGPT UX领域的研究水平。', 'title_zh': 'ChatGPT和U(X)：关于衡量用户体验的快速综述'}
{'arxiv_id': 'arXiv:2503.15796', 'title': 'Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction', 'authors': 'Xinlong Zhai, Chunchen Wang, Ruijia Wang, Jiazheng Kang, Shujie Li, Boyu Chen, Tengfei Ma, Zikai Zhou, Cheng Yang, Chuan Shi', 'link': 'https://arxiv.org/abs/2503.15796', 'abstract': 'Drug-target interaction prediction (DTI) is essential in various applications including drug discovery and clinical application. There are two perspectives of input data widely used in DTI prediction: Intrinsic data represents how drugs or targets are constructed, and extrinsic data represents how drugs or targets are related to other biological entities. However, any of the two perspectives of input data can be scarce for some drugs or targets, especially for those unpopular or newly discovered. Furthermore, ground-truth labels for specific interaction types can also be scarce. Therefore, we propose the first method to tackle DTI prediction under input data and/or label scarcity. To make our model functional when only one perspective of input data is available, we design two separate experts to process intrinsic and extrinsic data respectively and fuse them adaptively according to different samples. Furthermore, to make the two perspectives complement each other and remedy label scarcity, two experts synergize with each other in a mutually supervised way to exploit the enormous unlabeled data. Extensive experiments on 3 real-world datasets under different extents of input data scarcity and/or label scarcity demonstrate our model outperforms states of the art significantly and steadily, with a maximum improvement of 53.53%. We also test our model without any data scarcity and it still outperforms current methods.', 'abstract_zh': '药物-靶标相互作用预测（DTI）在药物发现和临床应用中至关重要。存在两种广泛用于DTI预测的输入数据视角：内在数据表示药物或靶标是如何构建的，外在数据表示药物或靶标与其他生物实体的关联。然而，对于某些药物或靶标，任何一种视角的输入数据可能都很稀缺，尤其是在这些药物或靶标不常用或新被发现的情况下。此外，特定相互作用类型的_ground-truth标签也可能稀缺。因此，我们提出了首个在输入数据和/或标签稀缺条件下解决DTI预测的方法。为了使模型在仅有一种视角的输入数据时仍可运行，我们设计了两个分别处理内在和外在数据的专业模块，并根据不同样本自适应地融合它们。此外，为了使两种视角互补并弥补标签稀缺性，这两个专业模块以互监督的方式协同工作，利用大量未标记的数据。在不同程度的输入数据和/或标签稀缺条件下，对三个真实世界数据集的广泛实验表明，我们的模型显著且稳健地优于当前最先进的方法，最大改进幅度达53.53%。我们还在没有任何数据稀缺的情况下测试了该模型，其性能仍优于当前方法。', 'title_zh': '分离结合：协同专家混合在数据稀缺的药物-靶标相互作用预测中的应用'}
{'arxiv_id': 'arXiv:2503.15783', 'title': 'Grammar and Gameplay-aligned RL for Game Description Generation with LLMs', 'authors': 'Tsunehiko Tanaka, Edgar Simo-Serra', 'link': 'https://arxiv.org/abs/2503.15783', 'abstract': 'Game Description Generation (GDG) is the task of generating a game description written in a Game Description Language (GDL) from natural language text. Previous studies have explored generation methods leveraging the contextual understanding capabilities of Large Language Models (LLMs); however, accurately reproducing the game features of the game descriptions remains a challenge. In this paper, we propose reinforcement learning-based fine-tuning of LLMs for GDG (RLGDG). Our training method simultaneously improves grammatical correctness and fidelity to game concepts by introducing both grammar rewards and concept rewards. Furthermore, we adopt a two-stage training strategy where Reinforcement Learning (RL) is applied following Supervised Fine-Tuning (SFT). Experimental results demonstrate that our proposed method significantly outperforms baseline methods using SFT alone.', 'abstract_zh': '基于强化学习的大型语言模型微调以生成游戏描述 (RLGDG)', 'title_zh': '语法与游戏内容-aligned 的强化学习在使用大语言模型生成游戏描述中的应用'}
{'arxiv_id': 'arXiv:2503.15779', 'title': 'MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion', 'authors': 'Haoxuan Ma, Xishun Liao, Yifan Liu, Qinhua Jiang, Chris Stanford, Shangqing Cao, Jiaqi Ma', 'link': 'https://arxiv.org/abs/2503.15779', 'abstract': "Human mobility modeling is critical for urban planning and transportation management, yet existing datasets often lack the resolution and semantic richness required for comprehensive analysis. To address this, we proposed a cross-domain data fusion framework that integrates multi-modal data of distinct nature and spatio-temporal resolution, including geographical, mobility, socio-demographic, and traffic information, to construct a privacy-preserving and semantically enriched human travel trajectory dataset. This framework is demonstrated through two case studies in Los Angeles (LA) and Egypt, where a domain adaptation algorithm ensures its transferability across diverse urban contexts. Quantitative evaluation shows that the generated synthetic dataset accurately reproduces mobility patterns observed in empirical data. Moreover, large-scale traffic simulations for LA County based on the generated synthetic demand align well with observed traffic. On California's I-405 corridor, the simulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume and 4.36% for speed compared to Caltrans PeMS observations.", 'abstract_zh': '跨域数据融合框架在洛杉矶和埃及的城市规划与交通管理中的应用研究', 'title_zh': 'MobiFuse: 通过跨域数据融合学习通用的人类移动模式'}
{'arxiv_id': 'arXiv:2503.15772', 'title': 'Detecting LLM-Written Peer Reviews', 'authors': 'Vishisht Rao, Aounon Kumar, Himabindu Lakkaraju, Nihar B. Shah', 'link': 'https://arxiv.org/abs/2503.15772', 'abstract': 'Editors of academic journals and program chairs of conferences require peer reviewers to write their own reviews. However, there is growing concern about the rise of lazy reviewing practices, where reviewers use large language models (LLMs) to generate reviews instead of writing them independently. Existing tools for detecting LLM-generated content are not designed to differentiate between fully LLM-generated reviews and those merely polished by an LLM. In this work, we employ a straightforward approach to identify LLM-generated reviews - doing an indirect prompt injection via the paper PDF to ask the LLM to embed a watermark. Our focus is on presenting watermarking schemes and statistical tests that maintain a bounded family-wise error rate, when a venue evaluates multiple reviews, with a higher power as compared to standard methods like Bonferroni correction. These guarantees hold without relying on any assumptions about human-written reviews. We also consider various methods for prompt injection including font embedding and jailbreaking. We evaluate the effectiveness and various tradeoffs of these methods, including different reviewer defenses. We find a high success rate in the embedding of our watermarks in LLM-generated reviews across models. We also find that our approach is resilient to common reviewer defenses, and that the bounds on error rates in our statistical tests hold in practice while having the power to flag LLM-generated reviews, while Bonferroni correction is infeasible.', 'abstract_zh': '基于水印方案和统计检验的LLM生成的评审意见检测方法', 'title_zh': '检测由大型语言模型撰写的同行评审'}
{'arxiv_id': 'arXiv:2503.15768', 'title': 'Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer', 'authors': 'Alexandra DeLucia, Mark Dredze', 'link': 'https://arxiv.org/abs/2503.15768', 'abstract': 'Abstractive multi-document summarization (MDS) is the task of automatically summarizing information in multiple documents, from news articles to conversations with multiple speakers. The training approaches for current MDS models can be grouped into four approaches: end-to-end with special pre-training ("direct"), chunk-then-summarize, extract-then-summarize, and inference with GPT-style models. In this work, we evaluate MDS models across training approaches, domains, and dimensions (reference similarity, quality, and factuality), to analyze how and why models trained on one domain can fail to summarize documents from another (News, Science, and Conversation) in the zero-shot domain transfer setting. We define domain-transfer "failure" as a decrease in factuality, higher deviation from the target, and a general decrease in summary quality. In addition to exploring domain transfer for MDS models, we examine potential issues with applying popular summarization metrics out-of-the-box.', 'abstract_zh': '抽象多文档总结（MDS）是自动从多篇文档中总结信息的任务，范围从新闻文章到多讲话者对话。当前MDS模型的训练方法可以归为四种：端到端带有特殊预训练（“直接”）、分块再总结、抽取再总结，以及基于GPT风格的推理方法。在本研究中，我们评估了不同训练方法、领域及维度（参考相似度、质量和事实性）下的MDS模型，以分析并探讨为何在零样本领域迁移设置中，一个领域的模型无法有效总结其他领域的文档（新闻、科学和对话）。我们定义领域迁移“失败”为事实性下降、偏离目标程度增加以及总结质量总体下降。除了探索MDS模型的领域迁移外，我们还考察了直接应用流行总结评估指标可能存在的问题。', 'title_zh': '适合所有尺寸吗？：多文档总结领域迁移中的失败度量'}
{'arxiv_id': 'arXiv:2503.15764', 'title': 'Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach', 'authors': 'Yong Xiao, Guangming Shi, Ping Zhang', 'link': 'https://arxiv.org/abs/2503.15764', 'abstract': 'The promising potential of AI and network convergence in improving networking performance and enabling new service capabilities has recently attracted significant interest. Existing network AI solutions, while powerful, are mainly built based on the close-loop and passive learning framework, resulting in major limitations in autonomous solution finding and dynamic environmental adaptation. Agentic AI has recently been introduced as a promising solution to address the above limitations and pave the way for true generally intelligent and beneficial AI systems. The key idea is to create a networking ecosystem to support a diverse range of autonomous and embodied AI agents in fulfilling their goals. In this paper, we focus on the novel challenges and requirements of agentic AI networking. We propose AgentNet, a novel framework for supporting interaction, collaborative learning, and knowledge transfer among AI agents. We introduce a general architectural framework of AgentNet and then propose a generative foundation model (GFM)-based implementation in which multiple GFM-as-agents have been created as an interactive knowledge-base to bootstrap the development of embodied AI agents according to different task requirements and environmental features. We consider two application scenarios, digital-twin-based industrial automation and metaverse-based infotainment system, to describe how to apply AgentNet for supporting efficient task-driven collaboration and interaction among AI agents.', 'abstract_zh': 'AI和网络融合的promise及其在提升网络性能和赋能新服务能力方面的潜力 recently attracted significant interest.现有的网络AI解决方案虽强大，但主要基于闭环和被动学习框架，导致自主解决方案发现和动态环境适应能力受限。近期，代理AI作为一种有前途的解决方案被引入，以解决上述限制并为真正的普遍智能和有益的AI系统铺平道路。核心思想是创建一个网络生态系统，支持各种自主和具身的AI代理实现其目标。在本文中，我们关注代理AI网络的新挑战和要求。我们提出AgentNet，一种支持AI代理之间交互、协作学习和知识转移的新型框架。我们介绍了AgentNet的一般架构，并提出了一种基于生成基础模型（GFM）的实现，其中创建了多个GFM代理作为交互知识库，根据不同的任务需求和环境特征，促进具身AI代理的发展。我们考虑了基于数字孪生的工业自动化和基于元宇宙的交互娱乐系统两个应用场景，以描述如何应用AgentNet支持AI代理之间的高效任务驱动协同和交互。', 'title_zh': '面向6G的能动AI网络构建：生成式基础模型作为代理的方法'}
{'arxiv_id': 'arXiv:2503.15758', 'title': 'ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism', 'authors': 'Venmugil Elango', 'link': 'https://arxiv.org/abs/2503.15758', 'abstract': 'Transformer-based models have emerged as a leading architecture for natural language processing, natural language generation, and image generation tasks. A fundamental element of the transformer architecture is self-attention, which allows the model to capture intricate dependencies within the data. However, the self-attention mechanism also incurs significant computational and memory costs, particularly for long sequences.\nIn this paper, we introduce ATTENTION2D, a novel approach that exploits parallelism along two dimensions - query and key/value - of the self-attention operation. This method enables efficient distribution and parallelization of computations across multiple devices. Our approach facilitates asymptotically faster training and inference phases compared to previous methods, without relying on approximations or incurring additional computational or memory overheads. Furthermore, unlike existing techniques that struggle to scale with an increasing number of processing units, our approach effectively scales with additional processing units.\nOur experimental results confirm the effectiveness of our method in improving communication efficiency and scalability. Compared to Ring Attention, our approach demonstrated up to a 5x performance boost on a GPT-3-like model using 64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64 NVIDIA H100 GPUs across 64 nodes.', 'abstract_zh': '基于Transformer的模型已成为自然语言处理、自然语言生成和图像生成任务的主要架构。Transformer架构中的基本要素是自我注意力机制，它允许模型捕获数据中的复杂依赖关系。然而，自我注意力机制也会产生显著的计算和内存成本，尤其是在处理长序列时。\n\n在本文中，我们提出了ATTENTION2D，这是一种新颖的方法，该方法利用了自我注意力操作过程中的两个维度——查询和键/值维度的并行性。这种方法能够在多个设备上实现计算的高效分布和并行化。我们的方法相较于以前的方法能够在不依赖近似或增加额外计算和内存开销的情况下，实现渐近更快的训练和推理阶段。此外，与现有技术不同，我们的方法能够有效地随着处理单元数量的增加而扩展。\n\n我们的实验结果证实了该方法在提高通信效率和扩展性方面的有效性。与Ring Attention相比，在64个NVIDIA A100 GPU（分布在16个节点上）的GPT-3类似模型上，我们的方法表现出高达5倍的性能提升；在64个NVIDIA H100 GPU（分布在64个节点上）上，我们的方法表现出高达9.4倍的性能提升。', 'title_zh': '注意力二维：通信高效的分布式自我注意力机制'}
{'arxiv_id': 'arXiv:2503.15754', 'title': 'AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration', 'authors': 'Andy Zhou, Kevin Wu, Francesco Pinto, Zhaorun Chen, Yi Zeng, Yu Yang, Shuang Yang, Sanmi Koyejo, James Zou, Bo Li', 'link': 'https://arxiv.org/abs/2503.15754', 'abstract': "As large language models (LLMs) become increasingly capable, security and safety evaluation are crucial. While current red teaming approaches have made strides in assessing LLM vulnerabilities, they often rely heavily on human input and lack comprehensive coverage of emerging attack vectors. This paper introduces AutoRedTeamer, a novel framework for fully automated, end-to-end red teaming against LLMs. AutoRedTeamer combines a multi-agent architecture with a memory-guided attack selection mechanism to enable continuous discovery and integration of new attack vectors. The dual-agent framework consists of a red teaming agent that can operate from high-level risk categories alone to generate and execute test cases and a strategy proposer agent that autonomously discovers and implements new attacks by analyzing recent research. This modular design allows AutoRedTeamer to adapt to emerging threats while maintaining strong performance on existing attack vectors. We demonstrate AutoRedTeamer's effectiveness across diverse evaluation settings, achieving 20% higher attack success rates on HarmBench against Llama-3.1-70B while reducing computational costs by 46% compared to existing approaches. AutoRedTeamer also matches the diversity of human-curated benchmarks in generating test cases, providing a comprehensive, scalable, and continuously evolving framework for evaluating the security of AI systems.", 'abstract_zh': '面向大语言模型的全自动端到端红队测评框架AutoRedTeamer', 'title_zh': '自动红队攻击者：基于终身攻击集成的自主红队技术'}
{'arxiv_id': 'arXiv:2503.15724', 'title': 'Reward Training Wheels: Adaptive Auxiliary Rewards for Robotics Reinforcement Learning', 'authors': 'Linji Wang, Tong Xu, Yuanjie Lu, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.15724', 'abstract': "Robotics Reinforcement Learning (RL) often relies on carefully engineered auxiliary rewards to supplement sparse primary learning objectives to compensate for the lack of large-scale, real-world, trial-and-error data. While these auxiliary rewards accelerate learning, they require significant engineering effort, may introduce human biases, and cannot adapt to the robot's evolving capabilities during training. In this paper, we introduce Reward Training Wheels (RTW), a teacher-student framework that automates auxiliary reward adaptation for robotics RL. To be specific, the RTW teacher dynamically adjusts auxiliary reward weights based on the student's evolving capabilities to determine which auxiliary reward aspects require more or less emphasis to improve the primary objective. We demonstrate RTW on two challenging robot tasks: navigation in highly constrained spaces and off-road vehicle mobility on vertically challenging terrain. In simulation, RTW outperforms expert-designed rewards by 2.35% in navigation success rate and improves off-road mobility performance by 122.62%, while achieving 35% and 3X faster training efficiency, respectively. Physical robot experiments further validate RTW's effectiveness, achieving a perfect success rate (5/5 trials vs. 2/5 for expert-designed rewards) and improving vehicle stability with up to 47.4% reduction in orientation angles.", 'abstract_zh': '基于奖励训练轮的机器人强化学习辅助奖励自动化调整框架', 'title_zh': '奖励训练辅助轮：机器人强化学习的自适应辅助奖励'}
{'arxiv_id': 'arXiv:2503.15707', 'title': 'Safety Aware Task Planning via Large Language Models in Robotics', 'authors': 'Azal Ahmad Khan, Michael Andrev, Muhammad Ali Murtaza, Sergio Aguilera, Rui Zhang, Jie Ding, Seth Hutchinson, Ali Anwar', 'link': 'https://arxiv.org/abs/2503.15707', 'abstract': "The integration of large language models (LLMs) into robotic task planning has unlocked better reasoning capabilities for complex, long-horizon workflows. However, ensuring safety in LLM-driven plans remains a critical challenge, as these models often prioritize task completion over risk mitigation. This paper introduces SAFER (Safety-Aware Framework for Execution in Robotics), a multi-LLM framework designed to embed safety awareness into robotic task planning. SAFER employs a Safety Agent that operates alongside the primary task planner, providing safety feedback. Additionally, we introduce LLM-as-a-Judge, a novel metric leveraging LLMs as evaluators to quantify safety violations within generated task plans. Our framework integrates safety feedback at multiple stages of execution, enabling real-time risk assessment, proactive error correction, and transparent safety evaluation. We also integrate a control framework using Control Barrier Functions (CBFs) to ensure safety guarantees within SAFER's task planning. We evaluated SAFER against state-of-the-art LLM planners on complex long-horizon tasks involving heterogeneous robotic agents, demonstrating its effectiveness in reducing safety violations while maintaining task efficiency. We also verify the task planner and safety planner through actual hardware experiments involving multiple robots and a human.", 'abstract_zh': '基于大型语言模型的机器人任务规划中安全性意识框架SAFER：多模型集成的安全评估与保障', 'title_zh': '基于大型语言模型的机器人安全意识任务规划'}
{'arxiv_id': 'arXiv:2503.15703', 'title': 'Predicting Multi-Agent Specialization via Task Parallelizability', 'authors': 'Elizabeth Mieczkowski, Ruaridh Mon-Williams, Neil Bramley, Christopher G. Lucas, Natalia Velez, Thomas L. Griffiths', 'link': 'https://arxiv.org/abs/2503.15703', 'abstract': 'Multi-agent systems often rely on specialized agents with distinct roles rather than general-purpose agents that perform the entire task independently. However, the conditions that govern the optimal degree of specialization remain poorly understood. In this work, we propose that specialist teams outperform generalist ones when environmental constraints limit task parallelizability -- the potential to execute task components concurrently. Drawing inspiration from distributed systems, we introduce a heuristic to predict the relative efficiency of generalist versus specialist teams by estimating the speed-up achieved when two agents perform a task in parallel rather than focus on complementary subtasks. We validate this heuristic through three multi-agent reinforcement learning (MARL) experiments in Overcooked-AI, demonstrating that key factors limiting task parallelizability influence specialization. We also observe that as the state space expands, agents tend to converge on specialist strategies, even when generalist ones are theoretically more efficient, highlighting potential biases in MARL training algorithms. Our findings provide a principled framework for interpreting specialization given the task and environment, and introduce a novel benchmark for evaluating whether MARL finds optimal strategies.', 'abstract_zh': '多智能体系统往往依赖于具有明确角色的专业智能体，而非能够独立完成整个任务的一般智能体。然而，最优专业化程度的条件仍不清楚。在本项工作中，我们提出，在环境约束限制任务并行化能力的情况下，专业团队的表现优于通用团队。借鉴分布式系统原理，我们提出了一种启发式方法，通过估计两个智能体并行执行任务与专注于互补子任务时所获加速的差异，来预测专业团队与通用团队的相对效率。我们通过Overcooked-AI中的三个多智能体强化学习实验验证了这一启发式方法，展示了限制任务并行化的关键因素影响专业化程度。我们还观察到，随着状态空间的扩大，智能体倾向于采用专业策略，即使理论上通用策略更高效，这揭示了MARL训练算法可能存在偏差。我们的研究为给定任务和环境下的专业化提供了一个原理性的框架，并引入了一个新的基准来评估MARL是否找到了最优策略。', 'title_zh': '基于任务并行性的多代理专业化预测'}
{'arxiv_id': 'arXiv:2503.15699', 'title': 'Representational Similarity via Interpretable Visual Concepts', 'authors': 'Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona', 'link': 'https://arxiv.org/abs/2503.15699', 'abstract': 'How do two deep neural networks differ in how they arrive at a decision? Measuring the similarity of deep networks has been a long-standing open question. Most existing methods provide a single number to measure the similarity of two networks at a given layer, but give no insight into what makes them similar or dissimilar. We introduce an interpretable representational similarity method (RSVC) to compare two networks. We use RSVC to discover shared and unique visual concepts between two models. We show that some aspects of model differences can be attributed to unique concepts discovered by one model that are not well represented in the other. Finally, we conduct extensive evaluation across different vision model architectures and training protocols to demonstrate its effectiveness.', 'abstract_zh': '两种深度神经网络在决策过程中的差异如何？如何衡量深度网络的相似性一直是一个悬而未决的问题。现有的大多数方法在同一层提供一个数值来衡量两个网络的相似性，但无法说明它们相似或不同的原因。我们提出了一个可解释的表示相似性方法（RSVC）来比较两个网络。我们使用RSVC来发现两个模型之间的共享和独特的视觉概念。我们表明，模型差异的一些方面可以归因于一个模型发现的独特概念，而这些概念在另一个模型中未得到良好体现。最后，我们在不同的视觉模型架构和训练协议下进行了大量评估，以证明其有效性。', 'title_zh': '可解释视觉概念驱动的表示相似性'}
{'arxiv_id': 'arXiv:2503.15661', 'title': 'UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction', 'authors': 'Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Juan A. Rodriguez, Montek Kalsi, Rabiul Awal, Nicolas Chapados, M. Tamer Özsu, Aishwarya Agrawal, David Vazquez, Christopher Pal, Perouz Taslakian, Spandana Gella, Sai Rajeswar', 'link': 'https://arxiv.org/abs/2503.15661', 'abstract': "Autonomous agents that navigate Graphical User Interfaces (GUIs) to automate tasks like document editing and file management can greatly enhance computer workflows. While existing research focuses on online settings, desktop environments, critical for many professional and everyday tasks, remain underexplored due to data collection challenges and licensing issues. We introduce UI-Vision, the first comprehensive, license-permissive benchmark for offline, fine-grained evaluation of computer use agents in real-world desktop environments. Unlike online benchmarks, UI-Vision provides: (i) dense, high-quality annotations of human demonstrations, including bounding boxes, UI labels, and action trajectories (clicks, drags, and keyboard inputs) across 83 software applications, and (ii) three fine-to-coarse grained tasks-Element Grounding, Layout Grounding, and Action Prediction-with well-defined metrics to rigorously evaluate agents' performance in desktop environments. Our evaluation reveals critical limitations in state-of-the-art models like UI-TARS-72B, including issues with understanding professional software, spatial reasoning, and complex actions like drag-and-drop. These findings highlight the challenges in developing fully autonomous computer use agents. By releasing UI-Vision as open-source, we aim to advance the development of more capable agents for real-world desktop tasks.", 'abstract_zh': '自主导航图形用户界面的代理能够自动化文档编辑和文件管理等任务，极大地提升了计算机工作流程。虽然现有研究主要集中在在线环境中，但许多专业和日常任务所需的桌面环境由于数据收集挑战和许可问题仍被忽视。我们引入了UI-Vision，这是首个全面且许可宽松的基准，用于离线、细致地评估计算机使用代理在真实桌面环境中的性能。与在线基准不同，UI-Vision 提供了：（i）包含边界框、UI 标签和操作轨迹（点击、拖拽和键盘输入）的高质量人类演示密集标注，覆盖83个软件应用程序，以及（ii）三个从细粒度到粗粒度的任务——元素定位、布局定位和动作预测，具有明确的评价指标，以严格评估代理在桌面环境中的表现。我们的评估揭示了诸如UI-TARS-72B等最先进的模型的关键局限性，包括理解和处理专业软件、空间推理以及拖拽等复杂操作的问题。这些发现突显了开发完全自主的计算机使用代理面临的挑战。通过将UI-Vision开源，我们希望促进更强大代理的发展，用于真实的桌面任务。', 'title_zh': 'UI-Vision: 以桌面为中心的GUI视觉感知与交互基准'}
{'arxiv_id': 'arXiv:2503.15650', 'title': 'Survey on Generalization Theory for Graph Neural Networks', 'authors': 'Antonis Vasileiou, Stefanie Jegelka, Ron Levie, Christopher Morris', 'link': 'https://arxiv.org/abs/2503.15650', 'abstract': 'Message-passing graph neural networks (MPNNs) have emerged as the leading approach for machine learning on graphs, attracting significant attention in recent years. While a large set of works explored the expressivity of MPNNs, i.e., their ability to separate graphs and approximate functions over them, comparatively less attention has been directed toward investigating their generalization abilities, i.e., making meaningful predictions beyond the training data. Here, we systematically review the existing literature on the generalization abilities of MPNNs. We analyze the strengths and limitations of various studies in these domains, providing insights into their methodologies and findings. Furthermore, we identify potential avenues for future research, aiming to deepen our understanding of the generalization abilities of MPNNs.', 'abstract_zh': '消息传递图神经网络（MPNNs）已成为图上机器学习的主导方法，近年来吸引了大量关注。尽管大量研究探索了MPNNs的表达能力，即它们区分图形和近似其上函数的能力，但相对较少的研究关注其泛化能力，即在训练数据之外进行有意义的预测。在此，我们系统地回顾了现有文献中关于MPNNs泛化能力的研究。我们分析了这些领域各种研究的优势和局限性，提供了有关其方法和发现的见解。此外，我们确定了未来研究的潜在方向，以加深我们对MPNNs泛化能力的理解。', 'title_zh': '图神经网络泛化理论综述'}
{'arxiv_id': 'arXiv:2503.15639', 'title': 'A Context-Driven Training-Free Network for Lightweight Scene Text Segmentation and Recognition', 'authors': 'Ritabrata Chakraborty, Shivakumara Palaiahnakote, Umapada Pal, Cheng-Lin Liu', 'link': 'https://arxiv.org/abs/2503.15639', 'abstract': 'Modern scene text recognition systems often depend on large end-to-end architectures that require extensive training and are prohibitively expensive for real-time scenarios. In such cases, the deployment of heavy models becomes impractical due to constraints on memory, computational resources, and latency. To address these challenges, we propose a novel, training-free plug-and-play framework that leverages the strengths of pre-trained text recognizers while minimizing redundant computations. Our approach uses context-based understanding and introduces an attention-based segmentation stage, which refines candidate text regions at the pixel level, improving downstream recognition. Instead of performing traditional text detection that follows a block-level comparison between feature map and source image and harnesses contextual information using pretrained captioners, allowing the framework to generate word predictions directly from scene this http URL texts are semantically and lexically evaluated to get a final score. Predictions that meet or exceed a pre-defined confidence threshold bypass the heavier process of end-to-end text STR profiling, ensuring faster inference and cutting down on unnecessary computations. Experiments on public benchmarks demonstrate that our paradigm achieves performance on par with state-of-the-art systems, yet requires substantially fewer resources.', 'abstract_zh': '现代场景文本识别系统往往依赖于大型端到端架构，需要大量训练且在实时场景下成本高昂。在这种情况下，由于内存、计算资源和延迟的限制，部署复杂的模型变得不切实际。为了解决这些挑战，我们提出了一种新型的无需训练即插即用框架，该框架利用预训练文本识别器的优点，同时减少冗余计算。我们的方法使用基于上下文的理解，并引入注意力机制的分割阶段，在像素级别细化候选文本区域，改善后端识别效果。该框架直接从场景中生成单词预测，而无需进行传统的基于块级别的特征图与源图像比较的文本检测，同时利用预训练的图像描述生成器来利用上下文信息。文本在语义和词汇上进行评估以获得最终评分。达到或超过预设置信阈值的预测绕过端到端文本STR特性提取的较重过程，确保更快的推断并减少不必要的计算。实验表明，我们的范式在公共基准测试上性能与最先进的系统相当，但所需资源显著减少。', 'title_zh': '面向上下文的无需训练网络轻量级场景文本分割与识别'}
{'arxiv_id': 'arXiv:2503.15629', 'title': 'Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning', 'authors': 'Luc McCutcheon, Bahman Gharesifard, Saber Fallah', 'link': 'https://arxiv.org/abs/2503.15629', 'abstract': 'Control Lyapunov functions are traditionally used to design a controller which ensures convergence to a desired state, yet deriving these functions for nonlinear systems remains a complex challenge. This paper presents a novel, sample-efficient method for neural approximation of nonlinear Lyapunov functions, leveraging self-supervised Reinforcement Learning (RL) to enhance training data generation, particularly for inaccurately represented regions of the state space. The proposed approach employs a data-driven World Model to train Lyapunov functions from off-policy trajectories. The method is validated on both standard and goal-conditioned robotic tasks, demonstrating faster convergence and higher approximation accuracy compared to the state-of-the-art neural Lyapunov approximation baseline. The code is available at: this https URL', 'abstract_zh': '基于自我监督强化学习的非线性Lyapunov函数的样本高效神经近似方法', 'title_zh': '自监督强化学习下的神经Lyapunov函数逼近'}
{'arxiv_id': 'arXiv:2503.15621', 'title': 'LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning', 'authors': 'Federico Cocchi, Nicholas Moratelli, Davide Caffagni, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara', 'link': 'https://arxiv.org/abs/2503.15621', 'abstract': 'Recent progress in Multimodal Large Language Models (MLLMs) has highlighted the critical roles of both the visual backbone and the underlying language model. While prior work has primarily focused on scaling these components to billions of parameters, the trade-offs between model size, architecture, and performance remain underexplored. Additionally, inconsistencies in training data and evaluation protocols have hindered direct comparisons, making it difficult to derive optimal design choices. In this paper, we introduce LLaVA-MORE, a new family of MLLMs that integrates recent language models with diverse visual backbones. To ensure fair comparisons, we employ a unified training protocol applied consistently across all architectures. Our analysis systematically explores both small- and medium-scale LLMs -- including Phi-4, LLaMA-3.1, and Gemma-2 -- to evaluate multimodal reasoning, generation, and instruction following, while examining the relationship between model size and performance. Beyond evaluating the LLM impact on final results, we conduct a comprehensive study of various visual encoders, ranging from CLIP-based architectures to alternatives such as DINOv2, SigLIP, and SigLIP2. Additional experiments investigate the effects of increased image resolution and variations in pre-training datasets. Overall, our results provide insights into the design of more effective MLLMs, offering a reproducible evaluation framework that facilitates direct comparisons and can guide future model development. Our source code and trained models are publicly available at: this https URL.', 'abstract_zh': '近期多模态大型语言模型的发展强调了视觉骨干和底层语言模型的critical作用。尽管先前的工作主要集中在扩展这些组件到几十亿的参数上，但模型规模、架构与性能之间的trade-offs尚未得到充分探索。此外，训练数据的一致性和评估协议的不一致阻碍了直接比较，使得难以得出最优设计选择。本文介绍了LLaVA-MORE，这是一种新的多模态大型语言模型家族，将近期的语言模型与多样的视觉骨干相整合。为了确保公平比较，我们在所有架构中一致地应用了统一的训练协议。我们的分析系统地探索了从小型到中型规模的多模态语言模型，包括Phi-4、LLaMA-3.1和Gemma-2，以评估其在多模态推理、生成和指令遵循方面的表现，并考察了模型规模与性能之间的关系。除了评估大型语言模型对最终结果的影响外，我们还对从CLIP架构到DINOv2、SigLIP和SigLIP2等多种视觉编码器进行了全面研究。额外的实验调查了图像分辨率增加和预训练数据集变化的效果。总体而言，我们的结果为更有效的多模态大型语言模型的设计提供了见解，提供了一个可重复的评估框架，以促进直接比较并指导未来的模型开发。我们的源代码和训练模型可在以下链接公开获取：this https URL。', 'title_zh': 'LLaVA-MORE：增强视觉指令调优的LLM和视觉骨干网络比较研究'}
{'arxiv_id': 'arXiv:2503.15620', 'title': 'Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings', 'authors': 'Austin Xu, Srijan Bansal, Yifei Ming, Semih Yavuz, Shafiq Joty', 'link': 'https://arxiv.org/abs/2503.15620', 'abstract': "The large language model (LLM)-as-judge paradigm has been used to meet the demand for a cheap, reliable, and fast evaluation of model outputs during AI system development and post-deployment monitoring. While judge models -- LLMs finetuned to specialize in assessing and critiquing model outputs -- have been touted as general purpose evaluators, they are typically evaluated only on non-contextual scenarios, such as instruction following. The omission of contextual settings -- those where external information is used as context to generate an output -- is surprising given the increasing prevalence of retrieval-augmented generation (RAG) and summarization use cases. Contextual assessment is uniquely challenging, as evaluation often depends on practitioner priorities, leading to conditional evaluation criteria (e.g., comparing responses based on factuality and then considering completeness if they are equally factual). To address the gap, we propose ContextualJudgeBench, a judge benchmark with 2,000 challenging response pairs across eight splits inspired by real-world contextual evaluation scenarios. We build our benchmark with a multi-pronged data construction pipeline that leverages both existing human annotations and model-based perturbations. Our comprehensive study across 11 judge models and 9 general purpose models, reveals that the contextual information and its assessment criteria present a significant challenge to even state-of-the-art models. For example, OpenAI's o1, the best-performing model, barely reaches 55% consistent accuracy.", 'abstract_zh': '大规模语言模型作为裁判的范式已被用于满足AI系统开发和部署后监控中对经济、可靠和快速的模型输出评估需求。尽管裁判模型——专门 fine-tuned 以评估和批判模型输出的大规模语言模型——被宣传为通用评估工具，但它们通常仅在非上下文情况下（如指令跟随）进行评估。在日益常见检索增强生成（RAG）和总结应用场景中忽略上下文设置是令人惊讶的。上下文评估尤为具有挑战性，因为评估往往依赖于实践者优先级，导致条件评估标准（例如，基于事实性比较响应，然后考虑完整性）。为了解决这一差距，我们提出了ContextualJudgeBench，这是一个包含2000个具有挑战性的响应对的数据集，灵感来源于8个基于现实世界的上下文评估场景。我们通过综合利用现有的人工标注和模型驱动的扰动构建了基准测试集。在对11个裁判模型和9个通用模型进行全面研究后，我们发现上下文信息及其评估标准对最先进的模型也构成重大挑战。例如，OpenAI的o1，表现最佳的模型，仅达到约55%的一致准确性。', 'title_zh': '背景重要吗？ContextualJudgeBench：评估情境驱动的大型语言模型法官工具'}
{'arxiv_id': 'arXiv:2503.15617', 'title': 'CAM-Seg: A Continuous-valued Embedding Approach for Semantic Image Generation', 'authors': 'Masud Ahmed, Zahid Hasan, Syed Arefinul Haque, Abu Zaher Md Faridee, Sanjay Purushotham, Suya You, Nirmalya Roy', 'link': 'https://arxiv.org/abs/2503.15617', 'abstract': 'Traditional transformer-based semantic segmentation relies on quantized embeddings. However, our analysis reveals that autoencoder accuracy on segmentation mask using quantized embeddings (e.g. VQ-VAE) is 8% lower than continuous-valued embeddings (e.g. KL-VAE). Motivated by this, we propose a continuous-valued embedding framework for semantic segmentation. By reformulating semantic mask generation as a continuous image-to-embedding diffusion process, our approach eliminates the need for discrete latent representations while preserving fine-grained spatial and semantic details. Our key contribution includes a diffusion-guided autoregressive transformer that learns a continuous semantic embedding space by modeling long-range dependencies in image features. Our framework contains a unified architecture combining a VAE encoder for continuous feature extraction, a diffusion-guided transformer for conditioned embedding generation, and a VAE decoder for semantic mask reconstruction. Our setting facilitates zero-shot domain adaptation capabilities enabled by the continuity of the embedding space. Experiments across diverse datasets (e.g., Cityscapes and domain-shifted variants) demonstrate state-of-the-art robustness to distribution shifts, including adverse weather (e.g., fog, snow) and viewpoint variations. Our model also exhibits strong noise resilience, achieving robust performance ($\\approx$ 95% AP compared to baseline) under gaussian noise, moderate motion blur, and moderate brightness/contrast variations, while experiencing only a moderate impact ($\\approx$ 90% AP compared to baseline) from 50% salt and pepper noise, saturation and hue shifts. Code available: this https URL', 'abstract_zh': '基于连续值嵌入的语义分割连续值嵌入框架提高了语义分割的准确性，特别是在使用量化的嵌入（如VQ-VAE）进行分割掩码生成时，相比连续值嵌入（如KL-VAE）低8%的自动编码器精度。受此启发，我们提出了一种连续值嵌入框架用于语义分割。通过将语义掩码生成重新表述为连续图像到嵌入的扩散过程，我们的方法消除了离散潜在表示的需求，同时保留了细粒度的空间和语义细节。我们的主要贡献包括一个由连续依赖关系建模引导的自回归变压器，该变压器通过学习连续语义嵌入空间来生成条件嵌入。我们的框架结合了一个基于VAE的连续特征提取编码器、一个由扩散引导的变压器用于条件嵌入生成，以及一个基于VAE的解码器用于语义掩码重建。我们的设置通过嵌入空间的连续性实现了零-shot领域适应能力。实验涵盖了多种数据集（如Cityscapes及其领域偏移变体），证明了对分布偏移具有最先进的鲁棒性，包括不良天气（如雾、雪）和视角变化。我们的模型还表现出强大的噪声鲁棒性，在高斯噪声、中等运动模糊和中等亮度/对比度变化下获得稳健性能（约95%的AP，与基线相比），而在50%的盐和胡椒噪声、饱和度和色调偏移下仅表现出中等影响（约90%的AP，与基线相比）。', 'title_zh': 'CAM-Seg：一种用于语义图像生成的连续值嵌入方法'}
{'arxiv_id': 'arXiv:2503.15615', 'title': 'PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL', 'authors': 'Joshua McClellan, Greyson Brothers, Furong Huang, Pratap Tokekar', 'link': 'https://arxiv.org/abs/2503.15615', 'abstract': 'Equivariant Graph Neural Networks (EGNNs) have emerged as a promising approach in Multi-Agent Reinforcement Learning (MARL), leveraging symmetry guarantees to greatly improve sample efficiency and generalization. However, real-world environments often exhibit inherent asymmetries arising from factors such as external forces, measurement inaccuracies, or intrinsic system biases. This paper introduces \\textit{Partially Equivariant Graph NeUral Networks (PEnGUiN)}, a novel architecture specifically designed to address these challenges. We formally identify and categorize various types of partial equivariance relevant to MARL, including subgroup equivariance, feature-wise equivariance, regional equivariance, and approximate equivariance. We theoretically demonstrate that PEnGUiN is capable of learning both fully equivariant (EGNN) and non-equivariant (GNN) representations within a unified framework. Through extensive experiments on a range of MARL problems incorporating various asymmetries, we empirically validate the efficacy of PEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both EGNNs and standard GNNs in asymmetric environments, highlighting their potential to improve the robustness and applicability of graph-based MARL algorithms in real-world scenarios.', 'abstract_zh': '部分同构图神经网络（PEnGUiN）：一种应对多智能体 reinforcement 学习中固有不对称性的新型架构', 'title_zh': 'PEnGUiN: 部分等变图神经网络在样本高效多智能体 reinforcement 学习中的应用'}
{'arxiv_id': 'arXiv:2503.15576', 'title': 'A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana', 'authors': 'Alba Márquez-Rodríguez, Miguel Ángel Mohedano-Munoz, Manuel J. Marín-Jiménez, Eduardo Santamaría-García, Giulia Bastianelli, Pedro Jordano, Irene Mendoza', 'link': 'https://arxiv.org/abs/2503.15576', 'abstract': 'Passive Acoustic Monitoring with automatic recorders is essential for ecosystem conservation but generates vast unsupervised audio data, posing challenges for extracting meaningful information. Deep Learning techniques offer a promising solution. BirdNET, a widely used model for bird identification, has shown success in many study systems but is limited in some regions due to biases in its training data. A key challenge in bird species detection is that many recordings either lack target species or contain overlapping vocalizations. To overcome these problems, we developed a multi-stage pipeline for automatic bird vocalization identification in Doñana National Park (SW Spain), a region facing significant conservation threats. Our approach included a Bird Song Detector to isolate vocalizations and custom classifiers trained with BirdNET embeddings. We manually annotated 461 minutes of audio from three habitats across nine locations, yielding 3,749 annotations for 34 classes. Spectrograms facilitated the use of image processing techniques. Applying the Bird Song Detector before classification improved species identification, as all classification models performed better when analyzing only the segments where birds were detected. Specifically, the combination of the Bird Song Detector and fine-tuned BirdNET compared to the baseline without the Bird Song Detector. Our approach demonstrated the effectiveness of integrating a Bird Song Detector with fine-tuned classification models for bird identification at local soundscapes. These findings highlight the need to adapt general-purpose tools for specific ecological challenges, as demonstrated in Doñana. Automatically detecting bird species serves for tracking the health status of this threatened ecosystem, given the sensitivity of birds to environmental changes, and helps in the design of conservation measures for reducing biodiversity loss', 'abstract_zh': '基于自动录音器的被动声学监测对于生态系统保护至关重要，但会产生大量未监督的音频数据，提取有意义的信息面临挑战。深度学习技术提供了一种有希望的解决方案。BirdNET是一种广泛用于鸟类识别的模型，在许多研究系统中取得了成功，但在某些地区由于训练数据的偏差受到限制。鸟类检测的关键挑战在于很多录音缺乏目标物种或包含重叠鸣叫声。为克服这些问题，在西班牙西南部的陶尔纳那国家公园，我们开发了一种多阶段管道，用于自动识别鸟类鸣叫声，该地区面临着严重的保护威胁。我们的方法包括一种鸟类歌声检测器以单独鸣叫声，并使用BirdNET嵌入训练自定义分类器。我们手动标注了来自九个地点三个生境的461分钟音频，产生了34个类别的3,749个标注。频谱图促进了图像处理技术的应用。在分类之前应用鸟类歌声检测器提高了物种识别，因为所有分类模型在仅分析检测到鸟类的段落时表现更好。具体而言，将鸟类歌声检测器与微调后的BirdNET结合使用比不使用鸟类歌声检测器的基线模型效果更好。我们的方法证明了将鸟类歌声检测器与微调分类模型结合使用对于局部声景中的鸟类识别是有效的。这些研究结果突显了根据特定生态挑战适应通用工具的需求，如在陶尔纳那所展示的。通过自动检测鸟类物种可以监测这一受威胁生态系统的健康状况，鉴于鸟类对环境变化的高度敏感性，这也有助于设计减少生物多样性丧失的保护措施。', 'title_zh': '基于深度学习的鸣禽识别辅助器：以杜南纳地区为例的研究'}
{'arxiv_id': 'arXiv:2503.15555', 'title': 'Whole-Body Image-to-Image Translation for a Virtual Scanner in a Healthcare Digital Twin', 'authors': 'Valerio Guarrasi, Francesco Di Feola, Rebecca Restivo, Lorenzo Tronchin, Paolo Soda', 'link': 'https://arxiv.org/abs/2503.15555', 'abstract': 'Generating positron emission tomography (PET) images from computed tomography (CT) scans via deep learning offers a promising pathway to reduce radiation exposure and costs associated with PET imaging, improving patient care and accessibility to functional imaging. Whole-body image translation presents challenges due to anatomical heterogeneity, often limiting generalized models. We propose a framework that segments whole-body CT images into four regions-head, trunk, arms, and legs-and uses district-specific Generative Adversarial Networks (GANs) for tailored CT-to-PET translation. Synthetic PET images from each region are stitched together to reconstruct the whole-body scan. Comparisons with a baseline non-segmented GAN and experiments with Pix2Pix and CycleGAN architectures tested paired and unpaired scenarios. Quantitative evaluations at district, whole-body, and lesion levels demonstrated significant improvements with our district-specific GANs. Pix2Pix yielded superior metrics, ensuring precise, high-quality image synthesis. By addressing anatomical heterogeneity, this approach achieves state-of-the-art results in whole-body CT-to-PET translation. This methodology supports healthcare Digital Twins by enabling accurate virtual PET scans from CT data, creating virtual imaging representations to monitor, predict, and optimize health outcomes.', 'abstract_zh': '通过深度学习将计算机断层扫描（CT）图像转换为正电子发射断层扫描（PET）图像 offers a promising pathway to reduce radiation exposure and costs associated with PET imaging, improving patient care and accessibility to functional imaging.通过对全身CT图像进行分区并使用特定区域的生成对抗网络（GAN）进行定制化的CT-to-PET转换，解决了由于解剖异质性带来的挑战。', 'title_zh': '全身图像到图像转换以实现医疗健康数字孪生中的虚拟扫描仪'}
{'arxiv_id': 'arXiv:2503.15551', 'title': 'Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack', 'authors': 'Murong Yue, Ziyu Yao', 'link': 'https://arxiv.org/abs/2503.15551', 'abstract': 'Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions into a batch, leading to unwanted interference across all queries, which can result in the inclusion of harmful content, such as phishing links, or the disruption of logical reasoning. In this paper, we construct BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of two types and 8k batch instances, to study the batch prompting vulnerability systematically. Our evaluation of both closed-source and open-weight LLMs demonstrates that all LLMs are susceptible to batch-prompting attacks. We then explore multiple defending approaches. While the prompting-based defense shows limited effectiveness for smaller LLMs, the probing-based approach achieves about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic analysis to understand the attack and identify attention heads that are responsible for it.', 'abstract_zh': '批量提示中存在严重安全漏洞：恶意用户可注入攻击指令以干扰所有查询，导致包含有害内容或扰乱逻辑推理。本文构建了BATCHSAFEBENCH基准，包含150种攻击指令和8000个批量实例，系统研究批量提示的安全漏洞。我们对封闭源和开源权重的大语言模型的评估表明，所有模型都易受批量提示攻击。我们还探索了多种防御方法，虽然基于提示的防御对小型模型效果有限，但基于探测的方法在检测攻击方面可达95%的准确率。此外，我们进行了机理分析以理解攻击并标识负责该攻击的注意力头。', 'title_zh': '高效但脆弱：评估与防御大模型批量提示攻击'}
{'arxiv_id': 'arXiv:2503.15550', 'title': 'Zero-Knowledge Federated Learning: A New Trustworthy and Privacy-Preserving Distributed Learning Paradigm', 'authors': 'Yuxin Jin, Taotao Wang, Qing Yang, Long Shi, Shengli Zhang', 'link': 'https://arxiv.org/abs/2503.15550', 'abstract': 'Federated Learning (FL) has emerged as a promising paradigm in distributed machine learning, enabling collaborative model training while preserving data privacy. However, despite its many advantages, FL still contends with significant challenges -- most notably regarding security and trust. Zero-Knowledge Proofs (ZKPs) offer a potential solution by establishing trust and enhancing system integrity throughout the FL process. Although several studies have explored ZKP-based FL (ZK-FL), a systematic framework and comprehensive analysis are still lacking. This article makes two key contributions. First, we propose a structured ZK-FL framework that categorizes and analyzes the technical roles of ZKPs across various FL stages and tasks. Second, we introduce a novel algorithm, Verifiable Client Selection FL (Veri-CS-FL), which employs ZKPs to refine the client selection process. In Veri-CS-FL, participating clients generate verifiable proofs for the performance metrics of their local models and submit these concise proofs to the server for efficient verification. The server then selects clients with high-quality local models for uploading, subsequently aggregating the contributions from these selected clients. By integrating ZKPs, Veri-CS-FL not only ensures the accuracy of performance metrics but also fortifies trust among participants while enhancing the overall efficiency and security of FL systems.', 'abstract_zh': '联邦学习(Federated Learning)作为一种分布式机器学习的有前途的范式，能够在保护数据隐私的同时实现协作模型训练。然而，尽管联邦学习具有许多优势，仍面临诸多挑战，特别是在安全性和可信度方面。零知识证明(Zero-Knowledge Proofs, ZKPs)提供了一种潜在的解决方案，通过在整个联邦学习过程中建立信任和增强系统完整性。尽管已有若干研究探讨了基于零知识证明的联邦学习(ZK-FL)，但系统框架和全面分析仍然缺乏。本文做出两项关键贡献。首先，我们提出了一种结构化的ZK-FL框架，对ZKPs在不同联邦学习阶段和技术任务中的技术角色进行了分类和分析。其次，我们引入了一种新的算法——可验证客户端选择联邦学习(Verifiable Client Selection Federated Learning, Veri-CS-FL)，该算法利用零知识证明来优化客户端选择过程。在Veri-CS-FL中，参与的客户端生成其本地模型性能指标的可验证证明，并将这些简洁的证明提交给服务器进行高效验证。服务器随后选择具有高质量本地模型的客户端以进行上传，并汇总这些选定客户端的贡献。通过整合零知识证明，Veri-CS-FL不仅确保了性能指标的准确性，还增强了参与者之间的信任，同时提高了整个联邦学习系统的效率和安全性。', 'title_zh': '零知识联邦学习：一种新的可信赖和隐私保护的分布式学习范式'}
{'arxiv_id': 'arXiv:2503.15549', 'title': 'Rendering Transparency to Ranking in Educational Assessment via Bayesian Comparative Judgement', 'authors': 'Andy Gray, Alma Rahat, Stephen Lindsay, Jen Pearson, Tom Crick', 'link': 'https://arxiv.org/abs/2503.15549', 'abstract': "Ensuring transparency in educational assessment is increasingly critical, particularly post-pandemic, as demand grows for fairer and more reliable evaluation methods. Comparative Judgement (CJ) offers a promising alternative to traditional assessments, yet concerns remain about its perceived opacity. This paper examines how Bayesian Comparative Judgement (BCJ) enhances transparency by integrating prior information into the judgement process, providing a structured, data-driven approach that improves interpretability and accountability.\nBCJ assigns probabilities to judgement outcomes, offering quantifiable measures of uncertainty and deeper insights into decision confidence. By systematically tracking how prior data and successive judgements inform final rankings, BCJ clarifies the assessment process and helps identify assessor disagreements. Multi-criteria BCJ extends this by evaluating multiple learning outcomes (LOs) independently, preserving the richness of CJ while producing transparent, granular rankings aligned with specific assessment goals. It also enables a holistic ranking derived from individual LOs, ensuring comprehensive evaluations without compromising detailed feedback.\nUsing a real higher education dataset with professional markers in the UK, we demonstrate BCJ's quantitative rigour and ability to clarify ranking rationales. Through qualitative analysis and discussions with experienced CJ practitioners, we explore its effectiveness in contexts where transparency is crucial, such as high-stakes national assessments. We highlight the benefits and limitations of BCJ, offering insights into its real-world application across various educational settings.", 'abstract_zh': '确保教育评估的透明性在大流行后变得日益重要，随着对更公平、更可靠评价方法的需求不断增加，比较判断（CJ）提供了一种有前景的替代方案，但对其透明度仍存在担忧。本文研究了贝叶斯比较判断（BCJ）如何通过整合_prior_信息来增强透明性，提供了一个结构化、数据驱动的方法，以提高可解释性和责任感。BCJ为判断结果分配概率，提供可量化的不确定性度量和对决策信心的更深层次洞察。通过系统地跟踪先验数据和后续判断如何影响最终排名，BCJ阐明了评价过程，并有助于识别评估者之间的分歧。多标准BCJ在此基础上通过独立评估多个学习成果（LO），保留了CJ的丰富性，同时生成与特定评估目标相一致的透明、细化的排名。它还能够从单个LO获得一个整体排名，确保全面评价同时不牺牲详细的反馈。使用英国专业标记的真实高等教育数据集，我们展示了BCJ的量化严谨性和对排名理据的澄清能力。通过定性分析和与经验丰富的CJ实践者的讨论，我们探讨了其在透明性至关重要的背景下，如高风险国家评估中的有效性。我们指出了BCJ的优势和局限性，提供了其在各种教育环境中实际应用的见解。', 'title_zh': '基于贝叶斯比较判断的教育评估中透明度排序的研究'}
{'arxiv_id': 'arXiv:2503.15548', 'title': 'Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval', 'authors': 'Pengcheng Zhou, Yinglun Feng, Zhongliang Yang', 'link': 'https://arxiv.org/abs/2503.15548', 'abstract': 'The widespread adoption of Retrieval-Augmented Generation (RAG) systems in real-world applications has heightened concerns about the confidentiality and integrity of their proprietary knowledge bases. These knowledge bases, which play a critical role in enhancing the generative capabilities of Large Language Models (LLMs), are increasingly vulnerable to breaches that could compromise sensitive information. To address these challenges, this paper proposes an advanced encryption methodology designed to protect RAG systems from unauthorized access and data leakage. Our approach encrypts both textual content and its corresponding embeddings prior to storage, ensuring that all data remains securely encrypted. This mechanism restricts access to authorized entities with the appropriate decryption keys, thereby significantly reducing the risk of unintended data exposure. Furthermore, we demonstrate that our encryption strategy preserves the performance and functionality of RAG pipelines, ensuring compatibility across diverse domains and applications. To validate the robustness of our method, we provide comprehensive security proofs that highlight its resilience against potential threats and vulnerabilities. These proofs also reveal limitations in existing approaches, which often lack robustness, adaptability, or reliance on open-source models. Our findings suggest that integrating advanced encryption techniques into the design and deployment of RAG systems can effectively enhance privacy safeguards. This research contributes to the ongoing discourse on improving security measures for AI-driven services and advocates for stricter data protection standards within RAG architectures.', 'abstract_zh': 'Retrieval-Augmented Generation系统中加密方法的研究：提高保密性和完整性的先进策略', 'title_zh': '隐私意识的RAG：安全隔离的知识检索'}
{'arxiv_id': 'arXiv:2503.15547', 'title': 'Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents', 'authors': 'Juhee Kim, Woohyuk Choi, Byoungyoung Lee', 'link': 'https://arxiv.org/abs/2503.15547', 'abstract': "Large Language Models (LLMs) are combined with plugins to create powerful LLM agents that provide a wide range of services. Unlike traditional software, LLM agent's behavior is determined at runtime by natural language prompts from either user or plugin's data. This flexibility enables a new computing paradigm with unlimited capabilities and programmability, but also introduces new security risks, vulnerable to privilege escalation attacks. Moreover, user prompt is prone to be interpreted in an insecure way by LLM agents, creating non-deterministic behaviors that can be exploited by attackers. To address these security risks, we propose Prompt Flow Integrity (PFI), a system security-oriented solution to prevent privilege escalation in LLM agents. Analyzing the architectural characteristics of LLM agents, PFI features three mitigation techniques -- i.e., untrusted data identification, enforcing least privilege on LLM agents, and validating unsafe data flows. Our evaluation result shows that PFI effectively mitigates privilege escalation attacks while successfully preserving the utility of LLM agents.", 'abstract_zh': '大型语言模型（LLMs）结合插件创建强大的LLM代理，提供广泛的服務。与传统软件不同，LLM代理的行为在运行时由用户或插件的数据以自然语言提示确定。这种灵活性开启了具有无限能力和编程性的新计算范式，但也引入了新的安全风险，容易遭受权限提升攻击。此外，用户提示容易被LLM代理以不安全的方式解释，导致不可预测的行为，这些行为可能被攻击者利用。为了应对这些安全风险，我们提出了一种系统安全性导向的解决方案——提示流完整性（PFI），以防止LLM代理中的权限提升。通过对LLM代理的架构特征进行分析，PFI具备三种缓解技术——不信任数据识别、对LLM代理施加最小权限控制以及验证不安全的数据流。我们的评估结果表明，PFI有效缓解了权限提升攻击，同时成功保留了LLM代理的实用性。', 'title_zh': '增强提示流程完整性以防止LLM代理权限提升'}
{'arxiv_id': 'arXiv:2503.15546', 'title': 'Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions', 'authors': 'Shraddha Pradipbhai Shah, Aditya Vilas Deshpande', 'link': 'https://arxiv.org/abs/2503.15546', 'abstract': 'The integration of Large Language Models (LLMs) into autonomous robotic agents for conducting online transactions poses significant cybersecurity challenges. This study aims to enforce robust cybersecurity constraints to mitigate the risks associated with data breaches, transaction fraud, and system manipulation. The background focuses on the rise of LLM-driven robotic systems in e-commerce, finance, and service industries, alongside the vulnerabilities they introduce. A novel security architecture combining blockchain technology with multi-factor authentication (MFA) and real-time anomaly detection was implemented to safeguard transactions. Key performance metrics such as transaction integrity, response time, and breach detection accuracy were evaluated, showing improved security and system performance. The results highlight that the proposed architecture reduced fraudulent transactions by 90%, improved breach detection accuracy to 98%, and ensured secure transaction validation within a latency of 0.05 seconds. These findings emphasize the importance of cybersecurity in the deployment of LLM-driven robotic systems and suggest a framework adaptable to various online platforms.', 'abstract_zh': '大型语言模型（LLMs）在自主机器人代理中进行在线交易的集成带来了重大的网络安全挑战。本研究旨在通过强化网络安全约束来缓解数据泄露、交易欺诈和系统操控相关风险。背景部分侧重于LLM驱动的机器人系统在电子商务、金融和服务业中的兴起及由此带来的一系列脆弱性。本研究实施了一种结合区块链技术和多因素认证（MFA）及实时异常检测的新安全架构，以保障交易的安全。通过关键性能指标如交易完整性、响应时间和入侵检测准确性评估，结果显示该架构提高了安全性并优化了系统性能。研究结果表明，所提出的架构将欺诈性交易减少了90%，将入侵检测准确性提高到98%，并确保在0.05秒的延迟内完成安全交易验证。这些发现强调了在部署LLM驱动的机器人系统中网络安全的重要性，并提出了一种适用于各种在线平台的框架。', 'title_zh': '基于LLM驱动的机器人代理在线交易的网络安全约束强化'}
{'arxiv_id': 'arXiv:2503.15544', 'title': 'A Logic of Uncertain Interpretation', 'authors': 'Adam Bjorndahl', 'link': 'https://arxiv.org/abs/2503.15544', 'abstract': 'We introduce a logical framework for reasoning about "uncertain interpretations" and investigate two key applications: a new semantics for implication capturing a kind of "meaning entailment", and a conservative notion of "evidentially supported" belief that takes the form of a Dempster-Shafer belief function.', 'abstract_zh': '我们引入了一种逻辑框架来推理“不确定解释”，并探讨了两种关键应用：一种新的蕴含语义，捕捉某种“意义蕴含”；以及一种保守的“证据支持”的信念概念，表现为德莫佛-舍费尔信念函数。', 'title_zh': '不确定解释逻辑'}
{'arxiv_id': 'arXiv:2503.15542', 'title': 'Identifying Likely-Reputable Blockchain Projects on Ethereum', 'authors': 'Cyrus Malik, Josef Bajada, Joshua Ellul', 'link': 'https://arxiv.org/abs/2503.15542', 'abstract': 'Identifying reputable Ethereum projects remains a critical challenge within the expanding blockchain ecosystem. The ability to distinguish between legitimate initiatives and potentially fraudulent schemes is non-trivial. This work presents a systematic approach that integrates multiple data sources with advanced analytics to evaluate credibility, transparency, and overall trustworthiness. The methodology applies machine learning techniques to analyse transaction histories on the Ethereum blockchain.\nThe study classifies accounts based on a dataset comprising 2,179 entities linked to illicit activities and 3,977 associated with reputable projects. Using the LightGBM algorithm, the approach achieves an average accuracy of 0.984 and an average AUC of 0.999, validated through 10-fold cross-validation. Key influential factors include time differences between transactions and received_tnx.\nThe proposed methodology provides a robust mechanism for identifying reputable Ethereum projects, fostering a more secure and transparent investment environment. By equipping stakeholders with data-driven insights, this research enables more informed decision-making, risk mitigation, and the promotion of legitimate blockchain initiatives. Furthermore, it lays the foundation for future advancements in trust assessment methodologies, contributing to the continued development and maturity of the Ethereum ecosystem.', 'abstract_zh': '识别值得信赖的以太坊项目仍然是扩展中的区块链生态系统中的一项关键挑战。区分合法项目和潜在欺诈方案并非易事。本文提出了一种系统性方法，将多种数据源与高级分析技术相结合，以评估信誉、透明度和整体可信度。该方法利用机器学习技术分析以太坊区块链上的交易历史。\n\n该研究基于包含2,179个与非法活动相关的实体和3,977个与值得信赖项目相关的实体的数据集，对账户进行了分类。通过使用LightGBM算法，该方法在10折交叉验证中实现了平均准确率0.984和平均AUC值0.999。关键影响因素包括交易之间的时差和received_tnx。\n\n所提出的方法为识别值得信赖的以太坊项目提供了 robust 机制，促进了更安全和透明的投资环境。通过为利益相关者提供数据驱动的洞察，该研究使决策更加明智，风险控制更加有效，并促进合法区块链项目的推广。此外，该研究为基础信任评估方法的进一步发展奠定了基础，有助于以太坊生态系统的持续发展和成熟。', 'title_zh': '识别很可能具备良好声誉的以太坊区块链项目'}
{'arxiv_id': 'arXiv:2503.15538', 'title': 'There must be encapsulated nonconceptual content in vision', 'authors': 'Vincent C. Müller', 'link': 'https://arxiv.org/abs/2503.15538', 'abstract': 'In this paper I want to propose an argument to support Jerry Fodor\'s thesis (Fodor 1983) that input systems are modular and thus informationally encapsulated. The argument starts with the suggestion that there is a "grounding problem" in perception, i. e. that there is a problem in explaining how perception that can yield a visual experience is possible, how sensation can become meaningful perception of something for the subject. Given that visual experience is actually possible, this invites a transcendental argument that explains the conditions of its possibility. I propose that one of these conditions is the existence of a visual module in Fodor\'s sense that allows the step from sensation to object-identifying perception, thus enabling visual experience. It seems to follow that there is informationally encapsulated nonconceptual content in visual perception.', 'abstract_zh': '本文旨在提出一个论据，以支持杰里·福多（Fodor 1983）的观点，即输入系统是模块化的，因此是信息封装的。该论据从感知存在“基础问题”的建议开始，即解释如何可能产生视觉经验，如何使感觉转化为主体对事物有意义的感知存在困难。鉴于视觉经验实际上是可能的，这促使我们进行一个先验论证来解释其可能性的条件。我提出其中一个条件是福多意义上存在的视觉模块，它使从感觉过渡到对象识别的感知成为可能，从而使得视觉经验成为可能。据此可以认为视觉感知中存在信息封装的非概念性内容。', 'title_zh': '视觉中必须存在非概念化内容。'}
{'arxiv_id': 'arXiv:2503.15530', 'title': 'A Beautiful Mind: Principles and Strategies for AI-Augmented Human Reasoning', 'authors': 'Sean Koon', 'link': 'https://arxiv.org/abs/2503.15530', 'abstract': "Amidst the race to create more intelligent machines, this paper asserts a critical need to invest in human reasoning so that people can manage the many new challenges and opportunities of the future. As people face accelerating changes and complexities in our society, there is a risk that we will rely on AI in ways that reduce our own agency as humans. This paper outlines a human-centered augmented reasoning paradigm by 1. Articulating fundamental principles for augmented reasoning tools, emphasizing their ergonomic, pre-conclusive, directable, exploratory, enhancing, and integrated nature; 2. Proposing a 'many tasks, many tools' approach to ensuring human control, and 3. Offering examples of interaction modes that can serve as bridges between human reasoning and AI algorithms.", 'abstract_zh': '在创建更智能机器的竞争中，本文强调了投资于人类推理以应对未来众多新挑战和机遇的迫切需要。随着社会加速变化和复杂性增加，存在一种风险，即我们可能会以减少自身人类自主性的姿态过度依赖AI。本文通过以下三个方面提出了以人类为中心的增强推理范式：1. 阐述增强推理工具的基本原则，强调其人体工学性、非结论性、可指引性、探索性、增强性以及整合性；2. 提出“多种任务，多种工具”的方法以确保人类控制；3. 提供示例以作为人类推理与AI算法之间的桥梁交互模式。', 'title_zh': '美丽的大脑：AI增强人类推理的原则与策略'}
{'arxiv_id': 'arXiv:2503.15528', 'title': 'Complying with the EU AI Act: Innovations in Explainable and User-Centric Hand Gesture Recognition', 'authors': 'Sarah Seifi, Tobias Sukianto, Cecilia Carbonelli, Lorenzo Servadei, Robert Wille', 'link': 'https://arxiv.org/abs/2503.15528', 'abstract': "The EU AI Act underscores the importance of transparency, user-centricity, and robustness in AI systems, particularly for high-risk systems. In response, we present advancements in XentricAI, an explainable hand gesture recognition (HGR) system designed to meet these regulatory requirements. XentricAI adresses fundamental challenges in HGR, such as the opacity of black-box models using explainable AI methods and the handling of distributional shifts in real-world data through transfer learning techniques. We extend an existing radar-based HGR dataset by adding 28,000 new gestures, with contributions from multiple users across varied locations, including 24,000 out-of-distribution gestures. Leveraging this real-world dataset, we enhance XentricAI's capabilities by integrating a variational autoencoder module for improved gesture anomaly detection, incorporating user-specific thresholding. This integration enables the identification of 11.50% more anomalous gestures. Our extensive evaluations demonstrate a 97.5% sucess rate in characterizing these anomalies, significantly improving system explainability. Furthermore, the implementation of transfer learning techniques has shown a substantial increase in user adaptability, with an average improvement of at least 15.17%. This work contributes to the development of trustworthy AI systems by providing both technical advancements and regulatory compliance, offering a commercially viable solution that aligns with the EU AI Act requirements.", 'abstract_zh': '欧盟AI法案强调了透明性、用户中心性和鲁棒性在AI系统中的重要性，特别是对于高风险系统。为此，我们提出了XentricAI的进展，这是一种解释性的手势识别（HGR）系统，旨在满足这些监管要求。XentricAI解决了手势识别中的根本挑战，如使用解释性AI方法解决黑盒模型的不透明性问题，并通过迁移学习技术处理实际数据中的分布移变。我们扩展了一个现有的雷达基手势识别数据集，添加了28,000个新手势，这些手势来自多个用户，遍布不同的地点，其中24,000个属于分布外手势。利用这个实际数据集，我们通过集成变分自编码器模块提高了XentricAI的手势异常检测能力，并引入了用户特定的阈值。这种集成使得能够识别出11.50%更多的异常手势。广泛的评估显示，该系统在特征化这些异常方面成功率达到97.5%，显著提高了系统的解释性。此外，迁移学习技术的实施显示了用户适应性的显著提高，平均改进幅度至少为15.17%。这项工作通过提供技术和合规改进，促进了值得信赖的AI系统的发展，提供了一个符合欧盟AI法案要求的商业可行解决方案。', 'title_zh': '遵循欧盟人工智能法案：可解释性和用户中心的手势识别创新'}
{'arxiv_id': 'arXiv:2503.15527', 'title': 'Exploring the Panorama of Anxiety Levels: A Multi-Scenario Study Based on Human-Centric Anxiety Level Detection and Personalized Guidance', 'authors': 'Longdi Xian, Junhao Xu', 'link': 'https://arxiv.org/abs/2503.15527', 'abstract': "More and more people are experiencing pressure from work, life, and education. These pressures often lead to an anxious state of mind, or even the early symptoms of suicidal ideation. With the advancement of artificial intelligence (AI) technology, large language models have become one of the most prominent technologies. They are often used for detecting psychological disorders. However, current studies primarily provide categorization results without offering interpretable explanations for these results. To address this gap, this study adopts a person-centered perspective and focuses on GPT-generated multi-scenario simulated conversations. These simulated conversations were selected as data samples for the study. Various transformer-based encoder models were utilized to develop a classification model capable of identifying different levels of anxiety. Additionally, a knowledge base focusing on anxiety was constructed using LangChain and GPT-4. When analyzing classification results, this knowledge base was able to provide explanations and reasons most relevant to the interlocutor's anxiety situation. The study demonstrates that the proposed model achieves over 94% accuracy in categorical prediction, and the advice provided is highly personalized and relevant.", 'abstract_zh': '越来越多的人正经历着工作、生活和教育带来的压力，这些压力常常导致焦虑情绪，甚至出现自杀念头的早期症状。随着人工智能技术的发展，大型语言模型已成为最具代表性的技术之一，常被用于检测心理障碍。然而，现有研究主要提供分类结果，缺乏对这些结果的可解释性分析。为解决这一问题，本研究采用以人为核心的观点，专注于GPT生成的多场景模拟对话。这些模拟对话被选作研究的数据样本。利用各种基于变换器的编码器模型，开发了一种分类模型，能够识别不同级别的焦虑。此外，通过LangChain和GPT-4构建了一个关注焦虑的知识库，在分析分类结果时，该知识库能够提供与对话者焦虑情况最相关的解释和原因。研究显示，所提出的模型在类别预测中的准确率超过94%，提供的建议高度个性化且相关。', 'title_zh': '探究焦虑水平全景：基于以人为中心的焦虑水平检测与个性化指导的多场景研究'}
{'arxiv_id': 'arXiv:2503.15525', 'title': 'The Use of Artificial Intelligence Tools in Assessing Content Validity: A Comparative Study with Human Experts', 'authors': 'Hatice Gurdil, Hatice Ozlem Anadol, Yesim Beril Soguksu', 'link': 'https://arxiv.org/abs/2503.15525', 'abstract': 'In this study, it was investigated whether AI evaluators assess the content validity of B1-level English reading comprehension test items in a manner similar to human evaluators. A 25-item multiple-choice test was developed, and these test items were evaluated by four human and four AI evaluators. No statistically significant difference was found between the scores given by human and AI evaluators, with similar evaluation trends observed. The Content Validity Ratio (CVR) and the Item Content Validity Index (I-CVI) were calculated and analyzed using the Wilcoxon Signed-Rank Test, with no statistically significant difference. The findings revealed that in some cases, AI evaluators could replace human evaluators. However, differences in specific items were thought to arise from varying interpretations of the evaluation criteria. Ensuring linguistic clarity and clearly defining criteria could contribute to more consistent evaluations. In this regard, the development of hybrid evaluation systems, in which AI technologies are used alongside human experts, is recommended.', 'abstract_zh': '本研究 investigate 了 AI 评价者是否以类似人类评价者的方式评估 B1 级英语阅读理解测试项目的内容有效性。开发了一项包含 25 道多项选择题的测试，这些测试项目由四名人类评价者和四名 AI 评价者进行了评估。 human 和 AI 评价者给出的分数没有统计学显著差异，且评价趋势相似。使用威尔科克森符号秩检验计算并分析了内容有效性比率 (CVR) 和项目内容有效性指数 (I-CVI)，同样没有统计学显著差异。研究发现，在某些情况下，AI 评价者可以替代人类评价者。然而，特定项目的差异被认为源于对评价标准的不同解释。为了提高一致性，确保语言清晰并明确界定标准是有帮助的。因此，建议开发人机结合的评价系统，其中 AI 技术与人类专家相结合。', 'title_zh': '使用人工智能工具评估内容效度：与人类专家的比较研究'}
{'arxiv_id': 'arXiv:2503.15524', 'title': 'KHAIT: K-9 Handler Artificial Intelligence Teaming for Collaborative Sensemaking', 'authors': 'Matthew Wilchek, Linhan Wang, Sally Dickinson, Erica Feuerbacher, Kurt Luther, Feras A. Batarseh', 'link': 'https://arxiv.org/abs/2503.15524', 'abstract': "In urban search and rescue (USAR) operations, communication between handlers and specially trained canines is crucial but often complicated by challenging environments and the specific behaviors canines are trained to exhibit when detecting a person. Since a USAR canine often works out of sight of the handler, the handler lacks awareness of the canine's location and situation, known as the 'sensemaking gap.' In this paper, we propose KHAIT, a novel approach to close the sensemaking gap and enhance USAR effectiveness by integrating object detection-based Artificial Intelligence (AI) and Augmented Reality (AR). Equipped with AI-powered cameras, edge computing, and AR headsets, KHAIT enables precise and rapid object detection from a canine's perspective, improving survivor localization. We evaluate this approach in a real-world USAR environment, demonstrating an average survival allocation time decrease of 22%, enhancing the speed and accuracy of operations.", 'abstract_zh': '在城市搜救（USAR）作业中，搜救人员与特训犬之间的通信至关重要，但常被复杂环境和犬只在搜索人员视线之外时表现出的特定行为所困扰。由于搜救犬往往在搜救人员视线之外工作，搜救人员缺乏对犬只位置和情况的了解，这称为“解释差距”。本文提出了一种名为KHAIT的新方法，通过结合基于物体检测的人工智能（AI）和增强现实（AR），以缩小解释差距并增强USAR的有效性。KHAIT配备有基于AI的摄像头、边缘计算和AR头显，能够从犬只视角进行精确快速的物体检测，提高幸存者定位的准确性和速度。我们在实际的城市搜救环境中评估了该方法，结果显示搜救时间平均减少了22%，提升了作业的速度和准确性。', 'title_zh': 'KHAIT: K-9-handler人工智能协同感知解析 teamwork'}
{'arxiv_id': 'arXiv:2503.15521', 'title': 'From Divergence to Consensus: Evaluating the Role of Large Language Models in Facilitating Agreement through Adaptive Strategies', 'authors': 'Loukas Triantafyllopoulos, Dimitris Kalles', 'link': 'https://arxiv.org/abs/2503.15521', 'abstract': "Achieving consensus in group decision-making often involves overcoming significant challenges, particularly in reconciling diverse perspectives and mitigating biases that hinder agreement. Traditional methods relying on human facilitators are often constrained by scalability and efficiency, especially in large-scale, fast-paced discussions. To address these challenges, this study proposes a novel framework employing large language models (LLMs) as automated facilitators within a custom-built multi-user chat system. Leveraging cosine similarity as a core metric, this approach evaluates the ability of three state-of-the-art LLMs- ChatGPT 4.0, Mistral Large 2, and AI21 Jamba Instruct- to synthesize consensus proposals that align with participants' viewpoints. Unlike conventional techniques, the system integrates adaptive facilitation strategies, including clarifying misunderstandings, summarizing discussions, and proposing compromises, enabling the LLMs to iteratively refine consensus proposals based on user feedback. Experimental results demonstrate the superiority of ChatGPT 4.0, which achieves higher alignment with participant opinions, requiring fewer iterations to reach consensus compared to its counterparts. Moreover, analysis reveals the nuanced performance of the models across various sustainability-focused discussion topics, such as climate action, quality education, good health and well-being, and access to clean water and sanitation. These findings highlight the transformative potential of LLM-driven facilitation for improving collective decision-making processes and underscore the importance of advancing evaluation metrics and cross-cultural adaptability in future research.", 'abstract_zh': '在群体决策中实现共识往往涉及克服重大挑战，特别是在协调多元化视角和减轻妨碍一致性的偏见方面。依赖人类协调者的传统方法在大规模、快节奏的讨论中常常受限于可扩展性和效率。为应对这些挑战，本研究提出了一种新型框架，利用大语言模型（LLMs）作为自动协调者，嵌入到自定义的多人聊天系统中。借助余弦相似度作为核心指标，该方法评估了ChatGPT 4.0、Mistral Large 2和AI21 Jamba Instruct三种最先进的大语言模型综合共识提案的能力，这些提案能够与参与者观点相契合。与传统技术不同，该系统整合了适应性的协调策略，包括澄清误解、总结讨论和提出妥协方案，使LLMs能够基于用户反馈迭代地精炼共识提案。实验结果表明，ChatGPT 4.0在实现更高程度的意见契合度方面优于其他模型，需要较少的迭代就能达成共识。此外，分析还揭示了这些模型在各种可持续发展相关讨论主题上的精细表现，如气候行动、高质量教育、良好健康与福祉以及清洁水和卫生设施的可及性。这些发现突显了以LLM驱动的协调对于改进集体决策过程的变革潜力，并强调了在未来研究中提高评估指标和跨文化适应性的重要性。', 'title_zh': '从分歧到一致：评估大语言模型在通过适应性策略促进达成共识中的作用'}
{'arxiv_id': 'arXiv:2503.15517', 'title': 'Analysis of AI Effectiveness in Reducing Human Errors in Processing Transportation Requests', 'authors': 'Oleksandr Korostin', 'link': 'https://arxiv.org/abs/2503.15517', 'abstract': 'This article examines the characteristics of human errors in processing transportation requests. The role of artificial intelligence (AI) in maritime transportation is explored. The main methods and technologies used for automating and optimizing the handling of transportation requests are analyzed, along with their impact on reducing the number of errors. Examples of successful AI implementation in large companies are provided, confirming the positive influence of these technologies on overall operational efficiency and customer service levels.', 'abstract_zh': '本文研究了处理运输请求中的人为错误特征，探讨了人工智能在海运运输中的作用，并分析了自动化和优化运输请求处理的主要方法和技术及其减少错误数量的影响。提供了大型公司成功实施人工智能的例子，证实了这些技术对整体运营效率和客户服务水平的积极影响。', 'title_zh': '分析AI在减少处理运输请求中的人为错误方面的有效性'}
{'arxiv_id': 'arXiv:2503.15516', 'title': 'In Pursuit of Predictive Models of Human Preferences Toward AI Teammates', 'authors': 'Ho Chit Siu, Jaime D. Peña, Yutai Zhou, Ross E. Allen', 'link': 'https://arxiv.org/abs/2503.15516', 'abstract': 'We seek measurable properties of AI agents that make them better or worse teammates from the subjective perspective of human collaborators. Our experiments use the cooperative card game Hanabi -- a common benchmark for AI-teaming research. We first evaluate AI agents on a set of objective metrics based on task performance, information theory, and game theory, which are measurable without human interaction. Next, we evaluate subjective human preferences toward AI teammates in a large-scale (N=241) human-AI teaming experiment. Finally, we correlate the AI-only objective metrics with the human subjective preferences. Our results refute common assumptions from prior literature on reinforcement learning, revealing new correlations between AI behaviors and human preferences. We find that the final game score a human-AI team achieves is less predictive of human preferences than esoteric measures of AI action diversity, strategic dominance, and ability to team with other AI. In the future, these correlations may help shape reward functions for training human-collaborative AI.', 'abstract_zh': '我们从人类合作者的主观视角出发，寻求衡量AI代理作为队友优劣的可测量属性。我们的实验使用合作纸牌游戏Hanabi——这是AI合作者研究的常见基准。首先，我们根据任务性能、信息论和博弈论对AI代理进行客观度量评估，这些度量无需人类交互即可实现。接下来，我们在大规模（N=241）的人机团队试验中评估人类对AI队友的主观偏好。最后，我们将仅基于AI的客观度量与人类的主观偏好进行关联。我们的结果反驳了先前关于强化学习文献中的常见假设，揭示了AI行为与人类偏好之间新的关联性。我们发现，人类-AI团队最终的游戏得分不如AI行为的神秘度量（如行为多样性、战略优势和与其他AI协作的能力）对人类偏好的预测能力强。未来，这些关联可能有助于塑造训练人类协作AI的奖励函数。', 'title_zh': '追求预测人类对AI队友偏好的模型'}
{'arxiv_id': 'arXiv:2503.15515', 'title': 'Towards Computer-Using Personal Agents', 'authors': 'Piero A. Bonatti, John Domingue, Anna Lisa Gentile, Andreas Harth, Olaf Hartig, Aidan Hogan, Katja Hose, Ernesto Jimenez-Ruiz, Deborah L. McGuinness, Chang Sun, Ruben Verborgh, Jesse Wright', 'link': 'https://arxiv.org/abs/2503.15515', 'abstract': "Computer-Using Agents (CUA) enable users to automate increasingly-complex tasks using graphical interfaces such as browsers. As many potential tasks require personal data, we propose Computer-Using Personal Agents (CUPAs) that have access to an external repository of the user's personal data. Compared with CUAs, CUPAs offer users better control of their personal data, the potential to automate more tasks involving personal data, better interoperability with external sources of data, and better capabilities to coordinate with other CUPAs in order to solve collaborative tasks involving the personal data of multiple users.", 'abstract_zh': '使用计算机的个人代理（CUPA）通过图形界面如浏览器使用户能够自动化执行日益复杂的任务。由于许多潜在的任务需要个人数据，我们提出使用外部个人数据仓库的个人代理（CUPA）以增强用户对其个人数据的控制、实现更多涉及个人数据的任务自动化、提高与外部数据源的互操作性以及更好地协调与其他CUPA以解决涉及多名用户个人数据的协作任务。', 'title_zh': '面向计算机使用的人工智能个人代理'}
{'arxiv_id': 'arXiv:2503.15514', 'title': 'Superhuman AI Disclosure: Impacts on Toxicity, Fairness, and Trust Vary by Expertise and Persona Attributes', 'authors': 'Jaymari Chua, Chen Wang, Lina Yao', 'link': 'https://arxiv.org/abs/2503.15514', 'abstract': 'As artificial intelligence demonstrates surpassing human performance across real-world tasks, disclosing superhuman capabilities poses challenges for fairness, accountability, and trust. To investigate how transparency impacts attitudes and perceptions, we introduce a grounded and validated set of synthetic personas reflecting diverse fairness concerns and technology acceptance levels. Then we evaluate responses in two contrasting domains: (1) a competitive player in StarCraft II, where strategy and high-skill gameplay often elicit toxic interactions, and (2) a cooperative personal-assistant in providing information. Across numerous interactions spanning persona profiles, we test non-disclosure versus explicit superhuman labelling under controlled game outcomes and usage contexts. Our findings reveal sharp domain-specific effects: in StarCraft II, explicitly labelling AI as superhuman, novice personas who learned of it reported lower toxicity and higher fairness-attributing defeat to advanced skill rather than hidden cheating-whereas expert personas found the disclosure statements irksome but still less deceptive than non-disclosure. Conversely, in the LLM as personal-assistant setting, disclosure of superhuman capabilities improved perceived trustworthiness, though it risked AI overreliance among certain persona segments. We release Dataset X-containing persona cards-including profile attributes, disclosure prompts, and detailed interaction logs, accompanied by reproducible protocols and disclaimers for adapting them to diverse tasks. Our results demonstrate that transparency is not a cure-all: while it reduces suspicion and enhances trust in cooperative contexts, it may inflame resistance or disappointment in competitive domains.', 'abstract_zh': '随着人工智能在实际任务中展现出超越人类的表现，披露超人类能力对公平性、责任制和信任提出了挑战。为了探究透明性如何影响态度和认知，我们引入了一套基于实证并经过验证的合成人物角色，这些角色反映了多样化的公平问题和技术接受水平。然后我们在两个对比领域进行了评估：（1）《星际争霸II》的竞技玩家，其中策略和高水平的游戏常常引发有毒互动；（2）作为提供信息的合作个人助手。我们在多种人物角色档案的交互中，测试了不披露与显式标签超人类能力在受控游戏结果和使用环境下的效果。我们的发现揭示了特定领域的影响：在《星际争霸II》中，明确标记AI为超人类，初学者人物认为其负面行为减少，更倾向于将失败归因于高级技能而非隐藏作弊——而专家人物则对披露声明感到不悦，但仍比不披露更不具有欺骗性。相反，在大型语言模型作为个人助手的设置中，披露超人类能力提高了可信度，但某些人物角色群体可能会过度依赖AI。我们发布了Dataset X——包含人物卡片的资料集，包括人物属性、披露提示及详细的交互日志，并附有可复制的协议和免责声明以适应各种任务。我们的研究结果表明，透明性并非万能解：虽然它在合作情境中减少疑虑并增强信任，但在竞争领域可能会加剧抵抗或失望。', 'title_zh': '超人类AI披露：毒性、公平性和信任的影响因专家水平和角色属性而异'}
{'arxiv_id': 'arXiv:2503.15512', 'title': 'Beyond Accuracy, SHAP, and Anchors -- On the difficulty of designing effective end-user explanations', 'authors': 'Zahra Abba Omar, Nadia Nahar, Jacob Tjaden, Inès M. Gilles, Fikir Mekonnen, Jane Hsieh, Christian Kästner, Alka Menon', 'link': 'https://arxiv.org/abs/2503.15512', 'abstract': "Modern machine learning produces models that are impossible for users or developers to fully understand -- raising concerns about trust, oversight and human dignity. Transparency and explainability methods aim to provide some help in understanding models, but it remains challenging for developers to design explanations that are understandable to target users and effective for their purpose. Emerging guidelines and regulations set goals but may not provide effective actionable guidance to developers. In a controlled experiment with 124 participants, we investigate whether and how specific forms of policy guidance help developers design explanations for an ML-powered screening tool for diabetic retinopathy. Contrary to our expectations, we found that participants across the board struggled to produce quality explanations, comply with the provided policy requirements for explainability, and provide evidence of compliance. We posit that participant noncompliance is in part due to a failure to imagine and anticipate the needs of their audience, particularly non-technical stakeholders. Drawing on cognitive process theory and the sociological imagination to contextualize participants' failure, we recommend educational interventions.", 'abstract_zh': '现代机器学习产生的模型难以让用户或开发者完全理解——这引发了关于信任、监管和人类尊严的担忧。透明性和可解释性方法旨在帮助理解模型，但开发者为目标用户设计可理解且有效的解释仍然具有挑战性。新兴的指导方针和法规设定目标，但未必能为开发者提供有效的可操作指导。在一项涉及124名参与者的受控实验中，我们研究了特定形式的政策指引是否以及如何帮助开发者设计一个糖尿病视网膜病变机器学习筛查工具的解释。与我们的预期相反，我们发现所有参与者的解释质量低劣，未能遵守提供的可解释性要求，也无法提供合规证据。我们认为，参与者未能遵守指引的部分原因是未能设想和预见其受众的需求，特别是非技术利益相关者的需求。结合认知过程理论和社会学想象力来解释参与者的表现不佳，我们建议实施教育干预措施。', 'title_zh': '超越准确性、SHAP和Anchors——关于设计有效用户解释的困难'}
{'arxiv_id': 'arXiv:2503.15502', 'title': 'MapColorAI: Designing Contextually Relevant Choropleth Map Color Schemes Using a Large Language Model', 'authors': 'Nai Yang, Yijie Wang, Fan Wu, Zhiwei Wei', 'link': 'https://arxiv.org/abs/2503.15502', 'abstract': "Choropleth maps, which utilize color schemes to visualize spatial patterns and trends, are simple yet effective tools for geographic data analysis. As such, color scheme design is a critical aspect of choropleth map creation. The traditional coloring methods offered by GIS tools such as ArcGIS and QGIS are not user-friendly for non-professionals. On the one hand, these tools provide numerous color schemes, making it hard to decide which one best matches the theme. On the other hand, it is difficult to fulfill some ambiguous and personalized coloring needs of users, such as requests for 'summer-like' map colors. To address these shortcomings, we develop a novel system that leverages a large language model and map color design principles to generate contextually relevant and user-aligned choropleth map color schemes. The system follows a three-stage process: Data processing, which provides an overview of the data and classifies the data into meaningful classes; Color Concept Design, where the color theme and color mode are conceptualized based on data characteristics and user intentions; and Color Scheme Design, where specific colors are assigned to classes based on generated color theme, color mode, and user requirements. Our system incorporates an interactive interface, providing necessary visualization for choropleth map color design and allowing users to customize and refine color choices flexibly. Through user studies and evaluations, the system demonstrates acceptable usability, accuracy, and flexibility, with users highlighting the tool's efficiency and ease of use.", 'abstract_zh': 'choropleth 图表：一种利用颜色方案可视化空间模式和趋势的简单而有效的地理数据工具，其色彩方案设计是choropleth 图表创建的关键方面。GIS 工具如 ArcGIS 和 QGIS 提供的传统着色方法对于非专业人士不够用户友好。一方面，这些工具提供了众多的颜色方案，使得难以决定哪个方案最符合主题。另一方面，很难满足用户的模糊和个性化着色需求，例如“夏日”风格的颜色请求。为解决这些不足，我们开发了一个全新的系统，该系统利用大规模语言模型和地图颜色设计原则来生成上下文相关且用户对齐的choropleth 图表颜色方案。该系统遵循三阶段过程：数据处理，提供数据概览并按有意义的类别对数据进行分类；颜色概念设计，基于数据特性和用户意图构想颜色主题和颜色模式；颜色方案设计，根据生成的颜色主题、颜色模式和用户要求为类别分配特定颜色。该系统集成了交互式界面，为choropleth 图表颜色设计提供必要的可视化，允许用户灵活地自定义和调整颜色选择。通过用户研究和评估，该系统展示了可接受的易用性、准确性和灵活性，用户还强调了该工具的高效性和易用性。', 'title_zh': 'MapColorAI: 使用大型语言模型设计上下文相关的大比例尺地图颜色方案'}
{'arxiv_id': 'arXiv:2503.15501', 'title': 'Development of an Inclusive Educational Platform Using Open Technologies and Machine Learning: A Case Study on Accessibility Enhancement', 'authors': 'Jimi Togni', 'link': 'https://arxiv.org/abs/2503.15501', 'abstract': 'This study addresses the pressing challenge of educational inclusion for students with special needs by proposing and developing an inclusive educational platform. Integrating machine learning, natural language processing, and cross-platform interfaces, the platform features key functionalities such as speech recognition functionality to support voice commands and text generation via voice input; real-time object recognition using the YOLOv5 model, adapted for educational environments; Grapheme-to-Phoneme (G2P) conversion for Text-to-Speech systems using seq2seq models with attention, ensuring natural and fluent voice synthesis; and the development of a cross-platform mobile application in Flutter with on-device inference execution using TensorFlow Lite. The results demonstrated high accuracy, usability, and positive impact in educational scenarios, validating the proposal as an effective tool for educational inclusion. This project underscores the importance of open and accessible technologies in promoting inclusive and quality education.', 'abstract_zh': '本研究通过提出并发展一个包容性教育平台，应对特殊需求学生教育包容性的迫切挑战。该平台集成机器学习、自然语言处理和跨平台接口，具备语音识别功能支持语音命令和通过语音输入生成文本；使用YOLOv5模型进行实时物体识别，适应教育环境；使用带有注意力机制的seq2seq模型进行字母到音素转换以确保语音合成自然流畅；并开发了一个使用Flutter的跨平台移动应用程序，在设备端执行TensorFlow Lite推理。结果表明该平台在教育场景中具有高准确性、易用性和积极影响，验证了该提案是一个有效的教育包容工具。本项目强调开放和可访问技术在促进包容性和高质量教育方面的重要性。', 'title_zh': '使用开放技术和机器学习开发的包容性教育平台：无障碍性增强案例研究'}
{'arxiv_id': 'arXiv:2503.15499', 'title': 'Approach to Visual Attractiveness of Event Space Through Data-Driven Environment and Spatial Perception', 'authors': 'Aliffi Majiid, Riaz-Ul-Haque Mian, Kouki Kurohara, Yen-Khang Nguyen-Tran', 'link': 'https://arxiv.org/abs/2503.15499', 'abstract': "Revitalizing Japan's remote areas has become a crucial task, and Matsue City exemplifies this effort in its temporary event spaces, created through collective efforts to foster urban vibrancy and bring together residents and visitors. This research examines the relationship between data-driven in-sights using generative AI and visual attractiveness by evaluating tempo-rary events in Matsue City, particularly considering the cognitive-cultural differences in processing visual information of the participants. The first phase employs semantic keyword extraction from interviews, categorizing responses into physical elements, activities, and atmosphere. The second phase analyzes spatial perception through three categories: layout hierar-chy, product visibility, and visual attention. The correlation indicates that successful event design requires a balance between spatial efficiency and diverse needs, with a spatial organization that optimizes visitor flow and visibility strategies considering cultural and demographic diversity. These findings contribute to understanding the urban quality of temporary event spaces and offer a replicable framework for enhancing the visual appeal of events in remote areas throughout Japan.", 'abstract_zh': '日本偏远地区的 revitalization 成为了关键任务，松江市通过集体努力创建临时活动空间，促进城市活力并汇聚居民和游客，成为了这一努力的典范。本研究通过生成AI生成的数据驱动见解与视觉吸引力之间的关系，评估松江市临时活动的特点，特别考虑参与者在处理视觉信息方面的认知文化差异。第一阶段从访谈中提取语义关键词，将回应分类为物理元素、活动和氛围。第二阶段通过布局层次、产品可见性和视觉注意力三个维度分析空间感知。相关性表明，成功的活动设计需要在空间效率和多样化需求之间取得平衡，考虑文化与人口多样性的情况下优化访客流动和视觉策略。这些发现有助于理解临时活动空间的城市品质，并为增强日本偏远地区活动的视觉吸引力提供可复制的框架。', 'title_zh': '基于数据驱动环境与空间感知的事件空间视觉吸引力评估方法'}
{'arxiv_id': 'arXiv:2503.15498', 'title': 'Revival: Collaborative Artistic Creation through Human-AI Interactions in Musical Creativity', 'authors': 'Keon Ju M. Lee, Philippe Pasquier, Jun Yuri', 'link': 'https://arxiv.org/abs/2503.15498', 'abstract': "Revival is an innovative live audiovisual performance and music improvisation by our artist collective K-Phi-A, blending human and AI musicianship to create electronic music with audio-reactive visuals. The performance features real-time co-creative improvisation between a percussionist, an electronic music artist, and AI musical agents. Trained in works by deceased composers and the collective's compositions, these agents dynamically respond to human input and emulate complex musical styles. An AI-driven visual synthesizer, guided by a human VJ, produces visuals that evolve with the musical landscape. Revival showcases the potential of AI and human collaboration in improvisational artistic creation.", 'abstract_zh': 'Revival：K-Phi-A的创新现场音视频表演与音乐即兴创作，融合人类与AI音乐才能，呈现音频反应视觉并与人类即兴互动的电子音乐。', 'title_zh': 'Revival: 通过人机互动在音乐创作中的协作艺术创作'}
{'arxiv_id': 'arXiv:2503.15497', 'title': 'The Impact of Big Five Personality Traits on AI Agent Decision-Making in Public Spaces: A Social Simulation Study', 'authors': 'Mingjun Ren, Wentao Xu', 'link': 'https://arxiv.org/abs/2503.15497', 'abstract': 'This study investigates how the Big Five personality traits influence decision-making processes in AI agents within public spaces. Using AgentVerse framework and GPT-3.5-turbo, we simulated interactions among 10 AI agents, each embodying different dimensions of the Big Five personality traits, in a classroom environment responding to misinformation. The experiment assessed both public expressions ([Speak]) and private thoughts ([Think]) of agents, revealing significant correlations between personality traits and decision-making patterns. Results demonstrate that Openness to Experience had the strongest impact on information acceptance, with curious agents showing high acceptance rates and cautious agents displaying strong skepticism. Extraversion and Conscientiousness also showed notable influence on decision-making, while Neuroticism and Agreeableness exhibited more balanced responses. Additionally, we observed significant discrepancies between public expressions and private thoughts, particularly in agents with friendly and extroverted personalities, suggesting that social context influences decision-making behavior. Our findings contribute to understanding how personality traits shape AI agent behavior in social settings and have implications for developing more nuanced and context-aware AI systems.', 'abstract_zh': '本研究探讨了五大人格特质如何影响公共空间中AI代理的决策过程。我们使用AgentVerse框架和GPT-3.5-turbo模拟了10个AI代理在教室环境中的互动，每个代理代表五大人格特质的不同维度，应对错误信息。实验评估了代理的公开表达（[Speak]）和内心想法（[Think]），揭示了人格特质与决策模式之间的显著相关性。研究结果表明，开放性对信息接受的影响最大，好奇的代理显示出高的接受率，谨慎的代理表现出强烈的怀疑态度。外向性和尽责性也对决策产生了显著影响，而神经质和宜人性则表现出较为平衡的响应。此外，我们还观察到公共表达和内心想法之间存在显著差异，特别是在友好和外向的人格特质的代理中，这表明社会背景影响决策行为。本研究为理解人格特质如何塑造社会环境中AI代理的行为提供了见解，并为开发更具微妙性和情境意识的AI系统提供了启示。', 'title_zh': '五大人格特质对公共空间中AI代理决策的影响：一项社会仿真研究'}
{'arxiv_id': 'arXiv:2503.15495', 'title': 'Entwicklung einer Webanwendung zur Generierung von skolemisierten RDF Daten für die Verwaltung von Lieferketten', 'authors': 'Roman Laas', 'link': 'https://arxiv.org/abs/2503.15495', 'abstract': 'Für eine frühzeitige Erkennung von Lieferengpässen müssen Lieferketten in einer geeigneten digitalen Form vorliegen, damit sie verarbeitet werden können. Der für die Datenmodellierung benötigte Arbeitsaufwand ist jedoch, gerade IT-fremden Personen, nicht zuzumuten. Es wurde deshalb im Rahmen dieser Arbeit eine Webanwendung entwickelt, welche die zugrunde liegende Komplexität für den Benutzer verschleiern soll. Konkret handelt es sich dabei um eine grafische Benutzeroberfläche, auf welcher Templates instanziiert und miteinander verknüpft werden können. Für die Definition dieser Templates wurden in dieser Arbeit geeignete Konzepte erarbeitet und erweitert. Zur Erhebung der Benutzerfreundlichkeit der Webanwendung wurde abschließend eine Nutzerstudie mit mehreren Testpersonen durchgeführt. Diese legte eine Vielzahl von nützlichen Verbesserungsvorschlägen offen.\n--\nFor early detection of supply bottlenecks, supply chains must be available in a suitable digital form so that they can be processed. However, the amount of work required for data modeling cannot be expected of people who are not familiar with IT topics. Therefore, a web application was developed in the context of this thesis, which is supposed to disguise the underlying complexity for the user. Specifically, this is a graphical user interface on which templates can be instantiated and linked to each other. Suitable concepts for the definition of these templates were developed and extended in this thesis. Finally, a user study with several test persons was conducted to determine the usability of the web application. This revealed a large number of useful suggestions for improvement.', 'abstract_zh': 'early detection of supply bottlenecks through a user-friendly web application', 'title_zh': '开发一种生成斯科勒姆化RDF数据的Web应用以管理供应链'}
{'arxiv_id': 'arXiv:2503.15494', 'title': 'AI-Powered Assistive Technologies for Visual Impairment', 'authors': 'Prudhvi Naayini, Praveen Kumar Myakala, Chiranjeevi Bura, Anil Kumar Jonnalagadda, Srikanth Kamatala', 'link': 'https://arxiv.org/abs/2503.15494', 'abstract': "Artificial Intelligence (AI) is revolutionizing assistive technologies. It offers innovative solutions to enhance the quality of life for individuals with visual impairments. This review examines the development, applications, and impact of AI-powered tools in key domains, such as computer vision, natural language processing (NLP), and wearable devices. Specific advancements include object recognition for identifying everyday items, scene description for understanding surroundings, and NLP-driven text-to-speech systems for accessing digital information. Assistive technologies like smart glasses, smartphone applications, and AI-enabled navigation aids are discussed, demonstrating their ability to support independent travel, facilitate social interaction, and increase access to education and employment opportunities.\nThe integration of deep learning models, multimodal interfaces, and real-time data processing has transformed the functionality and usability of these tools, fostering inclusivity and empowerment. This article also addresses critical challenges, including ethical considerations, affordability, and adaptability in diverse environments. Future directions highlight the need for interdisciplinary collaboration to refine these technologies, ensuring equitable access and sustainable innovation. By providing a comprehensive overview, this review underscores AI's transformative potential in promoting independence, enhancing accessibility, and fostering social inclusion for visually impaired individuals.", 'abstract_zh': '人工智能（AI）正在革新辅助技术。它提供了创新解决方案，以提高视力受损个体的生活质量。本文审查了AI驱动工具在计算机视觉、自然语言处理（NLP）、可穿戴设备等关键领域的发展、应用及影响。具体进步包括物体识别以识别日常物品、场景描述以理解环境以及通过NLP驱动的文本转语音系统访问数字信息。讨论了智能眼镜、智能手机应用程序和AI驱动的导航辅助设备，展示了它们支持独立出行、促进社交互动和增加教育和就业机会的能力。深度学习模型、多模态接口和实时数据处理的集成已经转型了这些工具的功能和易用性，促进了包容性和赋能。本文还探讨了关键挑战，包括伦理考虑、可负担性和在不同环境中的适应性。未来方向强调需要跨学科合作以完善这些技术，确保公平获取和可持续创新。通过提供全面概述，本文突显了AI在促进独立性、增强可访问性和促进社会包容方面具有变革潜力，特别是对于视力受损个体。', 'title_zh': 'AI驱动的视觉障碍辅助技术'}
{'arxiv_id': 'arXiv:2503.15492', 'title': 'World of ScoreCraft: Novel Multi Scorer Experiment on the Impact of a Decision Support System in Sleep Staging', 'authors': 'Benedikt Holm, Arnar Óskarsson, Björn Elvar Þorleifsson, Hörður Þór Hafsteinsson, Sigríður Sigurðardóttir, Heiður Grétarsdóttir, Kenan Hoelke, Gabriel Marc Marie Jouan, Thomas Penzel, Erna Sif Arnardottir, María Óskarsdóttir', 'link': 'https://arxiv.org/abs/2503.15492', 'abstract': 'Manual scoring of polysomnography (PSG) is a time intensive task, prone to inter scorer variability that can impact diagnostic reliability. This study investigates the integration of decision support systems (DSS) into PSG scoring workflows, focusing on their effects on accuracy, scoring time, and potential biases toward recommendations from artificial intelligence (AI) compared to human generated recommendations. Using a novel online scoring platform, we conducted a repeated measures study with sleep technologists,\nwho scored traditional and self applied PSGs. Participants were occasionally presented with recommendations labeled as either human or AI generated. We found that traditional PSGs tended to be scored slightly more accurately than self applied PSGs, but this difference was not statistically significant. Correct recommendations significantly improved scoring accuracy for both PSG types, while incorrect recommendations reduced accuracy. No significant bias was observed toward or against AI generated recommendations compared to human generated recommendations. These findings highlight the potential of AI to enhance PSG scoring reliability. However, ensuring the accuracy of AI outputs is critical to maximizing its benefits. Future research should explore the long term impacts of DSS on scoring workflows and strategies for integrating AI in clinical practice.', 'abstract_zh': 'PSG打分的人工决策支持系统集成：对准确性、打分时间和人工智能推荐偏倚的影响研究', 'title_zh': 'ScoreCraft 世界：新型多评分者实验，探讨决策支持系统对睡眠分期的影响'}
{'arxiv_id': 'arXiv:2503.15489', 'title': 'PersonaAI: Leveraging Retrieval-Augmented Generation and Personalized Context for AI-Driven Digital Avatars', 'authors': 'Elvis Kimara, Kunle S. Oguntoye, Jian Sun', 'link': 'https://arxiv.org/abs/2503.15489', 'abstract': "This paper introduces PersonaAI, a cutting-edge application that leverages Retrieval-Augmented Generation (RAG) and the LLAMA model to create highly personalized digital avatars capable of accurately mimicking individual personalities. Designed as a cloud-based mobile application, PersonaAI captures user data seamlessly, storing it in a secure database for retrieval and analysis. The result is a system that provides context-aware, accurate responses to user queries, enhancing the potential of AI-driven personalization.\nWhy should you care? PersonaAI combines the scalability of RAG with the efficiency of prompt-engineered LLAMA3, offering a lightweight, sustainable alternative to traditional large language model (LLM) training methods. The system's novel approach to data collection, utilizing real-time user interactions via a mobile app, ensures enhanced context relevance while maintaining user privacy. By open-sourcing our implementation, we aim to foster adaptability and community-driven development.\nPersonaAI demonstrates how AI can transform interactions by merging efficiency, scalability, and personalization, making it a significant step forward in the future of digital avatars and personalized AI.", 'abstract_zh': 'PersonaAI：一种结合检索增强生成和LLAMA模型的个性化数字avatar应用', 'title_zh': 'PersonaAI：利用检索增强生成和个性化上下文驱动的数字 Avatar 技术'}
