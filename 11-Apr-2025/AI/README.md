# We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy 

**Title (ZH)**: 我们都是创造者：生成式AI、集体知识及其向人机协同的路径 

**Authors**: Jordi Linares-Pellicer, Juan Izquierdo-Domenech, Isabel Ferri-Molla, Carlos Aliaga-Torro  

**Link**: [PDF](https://arxiv.org/pdf/2504.07936)  

**Abstract**: Generative AI presents a profound challenge to traditional notions of human uniqueness, particularly in creativity. Fueled by neural network based foundation models, these systems demonstrate remarkable content generation capabilities, sparking intense debates about authorship, copyright, and intelligence itself. This paper argues that generative AI represents an alternative form of intelligence and creativity, operating through mathematical pattern synthesis rather than biological understanding or verbatim replication. The fundamental differences between artificial and biological neural networks reveal AI learning as primarily statistical pattern extraction from vast datasets crystallized forms of collective human knowledge scraped from the internet. This perspective complicates copyright theft narratives and highlights practical challenges in attributing AI outputs to individual sources. Rather than pursuing potentially futile legal restrictions, we advocate for human AI synergy. By embracing generative AI as a complementary tool alongside human intuition, context, and ethical judgment, society can unlock unprecedented innovation, democratize creative expression, and address complex challenges. This collaborative approach, grounded in realistic understanding of AIs capabilities and limitations, offers the most promising path forward. Additionally, recognizing these models as products of collective human knowledge raises ethical questions about accessibility ensuring equitable access to these tools could prevent widening societal divides and leverage their full potential for collective benefit. 

**Abstract (ZH)**: 生成式AI对传统人类独特的创造性构成了深刻挑战 

---
# The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation 

**Title (ZH)**: AI对城市的影响：下次场地推荐中的反馈循环建模 

**Authors**: Giovanni Mauro, Marco Minici, Luca Pappalardo  

**Link**: [PDF](https://arxiv.org/pdf/2504.07911)  

**Abstract**: Next-venue recommender systems are increasingly embedded in location-based services, shaping individual mobility decisions in urban environments. While their predictive accuracy has been extensively studied, less attention has been paid to their systemic impact on urban dynamics. In this work, we introduce a simulation framework to model the human-AI feedback loop underpinning next-venue recommendation, capturing how algorithmic suggestions influence individual behavior, which in turn reshapes the data used to retrain the models. Our simulations, grounded in real-world mobility data, systematically explore the effects of algorithmic adoption across a range of recommendation strategies. We find that while recommender systems consistently increase individual-level diversity in visited venues, they may simultaneously amplify collective inequality by concentrating visits on a limited subset of popular places. This divergence extends to the structure of social co-location networks, revealing broader implications for urban accessibility and spatial segregation. Our framework operationalizes the feedback loop in next-venue recommendation and offers a novel lens through which to assess the societal impact of AI-assisted mobility-providing a computational tool to anticipate future risks, evaluate regulatory interventions, and inform the design of ethic algorithmic systems. 

**Abstract (ZH)**: 基于地点的服务中，下一步场所推荐系统日益嵌入其中，影响城市环境中个体的移动决策。虽然对其预测准确性已有广泛研究，但对其对城市动态的系统性影响关注较少。在本文中，我们引入了一个仿真框架来模拟驱动下一场所推荐的人机反馈循环，捕捉算法建议如何影响个体行为，进而重塑用于重新训练模型的数据。我们的仿真基于实际的移动数据，系统地探讨了算法采用在多种推荐策略下的影响。我们发现，虽然推荐系统一贯增加了个体访问场所的多样性，但它们可能会同时通过集中访问于少数热门地点来加剧集体不平等。这种差异还扩展到社会共存网络的结构上，揭示了对城市可达性和空间隔离的更广泛影响。我们的框架操作化了下一场所推荐中的人机反馈循环，并提供了一种新的视角，用于评估人工智能辅助移动的社会影响——提供了一个计算工具，以预见未来风险、评估监管干预措施，并指导伦理算法系统的开发设计。 

---
# Dual Engines of Thoughts: A Depth-Breadth Integration Framework for Open-Ended Analysis 

**Title (ZH)**: 双重思考引擎：一种深度与广度集成框架用于开放式分析 

**Authors**: Fei-Hsuan Yu, Yun-Cheng Chou, Teng-Ruei Chen  

**Link**: [PDF](https://arxiv.org/pdf/2504.07872)  

**Abstract**: We propose the Dual Engines of Thoughts (DEoT), an analytical framework for comprehensive open-ended reasoning. While traditional reasoning frameworks primarily focus on finding "the best answer" or "the correct answer" for single-answer problems, DEoT is specifically designed for "open-ended questions," enabling both broader and deeper analytical exploration. The framework centers on three key components: a Base Prompter for refining user queries, a Solver Agent that orchestrates task decomposition, execution, and validation, and a Dual-Engine System consisting of a Breadth Engine (to explore diverse impact factors) and a Depth Engine (to perform deep investigations). This integrated design allows DEoT to balance wide-ranging coverage with in-depth analysis, and it is highly customizable, enabling users to adjust analytical parameters and tool configurations based on specific requirements. Experimental results show that DEoT excels in addressing complex, multi-faceted questions, achieving a total win rate of 77-86% compared to existing reasoning models, thus highlighting its effectiveness in real-world applications. 

**Abstract (ZH)**: 我们提出了双引擎思维框架（DEoT），这是一种综合性的开放性推理分析框架。 

---
# 2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization 

**Title (ZH)**: 二维 Curriculum 学习以直接优化偏好 

**Authors**: Mengyang Li, Zhong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07856)  

**Abstract**: Aligning large language models with human preferences is crucial for their safe deployment. While Direct Preference Optimization (DPO) offers an efficient alternative to reinforcement learning from human feedback, traditional DPO methods are limited by their reliance on single preference pairs. Recent work like Curriculum-DPO integrates multiple pairs using a one-dimensional difficulty curriculum based on pairwise distinguishability (PD), but overlooks the complexity of the input prompt itself. To address this, we propose 2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that jointly models Prompt Complexity (PC) and Pairwise Distinguishability. This framework introduces dual difficulty metrics to quantify prompt semantic complexity and response preference clarity, defines a curriculum strategy space encompassing multiple selectable strategies for task adaptation, and incorporates a KL-divergence-based adaptive mechanism for dynamic reference model updates to enhance training stability. Comprehensive experiments demonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior curriculum methods across multiple benchmarks, including MT-Bench, Vicuna Bench, and WizardLM. Our approach achieves state-of-the-art performance on challenging test sets like UltraFeedback. Ablation studies confirm the benefits of the 2D structure and adaptive mechanisms, while analysis provides guidance for strategy selection. These findings demonstrate that effective alignment requires modeling both prompt complexity and pairwise distinguishability, establishing adaptive, multi-dimensional curriculum learning as a powerful and interpretable new paradigm for preference-based language model optimization. 

**Abstract (ZH)**: 将大型语言模型与人类偏好对齐对于其安全部署至关重要。虽然直接偏好优化（DPO）为从人类反馈中进行强化学习提供了一种有效的替代方案，但传统DPO方法受限于对单一偏好对的依赖。最近的工作如Curriculum-DPO通过基于两两可区分性（PD）的一维难度课程整合了多个偏好对，但忽视了输入提示本身的复杂性。为解决这一问题，我们提出了2D-Curri-DPO，这是一种采用二维课程的新框架，该框架同时建模提示复杂性（PC）和两两可区分性。该框架引入了双重难度度量来量化提示的语义复杂性和响应偏好清晰度，定义了包括多种可选策略的任务适应课程策略空间，并结合了基于KL散度的自适应机制来动态更新参考模型，以增强训练稳定性。全面的实验表明，2D-Curri-DPO在包括MT-Bench、Vicuna Bench和WizardLM等多个基准上的性能显著优于标准DPO和之前的课程学习方法，我们的方法在如UltraFeedback等具有挑战性的测试集上达到了最先进的性能。消融研究证实了2D结构和自适应机制的优势，而分析则提供了策略选择的指导。这些发现表明，有效的对齐需要建模提示复杂性和两两可区分性，建立了自适应、多维度课程学习为基于偏好的语言模型优化提供了一种强大的、可解释的新范式。 

---
# Independence Is Not an Issue in Neurosymbolic AI 

**Title (ZH)**: 独立性不是神经符号AI的问题 

**Authors**: Håkan Karlsson Faronius, Pedro Zuidberg Dos Martires  

**Link**: [PDF](https://arxiv.org/pdf/2504.07851)  

**Abstract**: A popular approach to neurosymbolic AI is to take the output of the last layer of a neural network, e.g. a softmax activation, and pass it through a sparse computation graph encoding certain logical constraints one wishes to enforce. This induces a probability distribution over a set of random variables, which happen to be conditionally independent of each other in many commonly used neurosymbolic AI models. Such conditionally independent random variables have been deemed harmful as their presence has been observed to co-occur with a phenomenon dubbed deterministic bias, where systems learn to deterministically prefer one of the valid solutions from the solution space over the others. We provide evidence contesting this conclusion and show that the phenomenon of deterministic bias is an artifact of improperly applying neurosymbolic AI. 

**Abstract (ZH)**: 一种流行的神经符号AI方法是将神经网络最后一层的输出，例如softmax激活，通过一个稀疏计算图传递，该图编码了希望施加的某些逻辑约束。这会在一些常用的大规模神经符号AI模型中诱导出一个随机变量的概率分布，这些随机变量在很多情况下是条件独立的。在许多情况下，这些条件独立的随机变量被认为是有害的，因为它们的存在与一种称为确定性偏见的现象相伴发生，即系统倾向于学习从解决方案空间中确定性地偏好其中一个有效解。我们提供了反驳这一结论的证据，并表明确定性偏见现象是不恰当地应用神经符号AI的结果。 

---
# Anytime Single-Step MAPF Planning with Anytime PIBT 

**Title (ZH)**: 任意时间单步MAPF规划与任意时间PIBT 

**Authors**: Nayesha Gandotra, Rishi Veerapaneni, Muhammad Suhail Saleem, Daniel Harabor, Jiaoyang Li, Maxim Likhachev  

**Link**: [PDF](https://arxiv.org/pdf/2504.07841)  

**Abstract**: PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many state-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main utility of PIBT is that it is a very fast and effective single-step MAPF solver and can return a collision-free single-step solution for hundreds of agents in less than a millisecond. However, the main drawback of PIBT is that it is extremely greedy in respect to its priorities and thus leads to poor solution quality. Additionally, PIBT cannot use all the planning time that might be available to it and returns the first solution it finds. We thus develop Anytime PIBT, which quickly finds a one-step solution identically to PIBT but then continuously improves the solution in an anytime manner. We prove that Anytime PIBT converges to the optimal solution given sufficient time. We experimentally validate that Anytime PIBT can rapidly improve single-step solution quality within milliseconds and even find the optimal single-step action. However, we interestingly find that improving the single-step solution quality does not have a significant effect on full-horizon solution costs. 

**Abstract (ZH)**: Anytime PIBT: 快速并持续优化的多智能体路径规划方法 

---
# Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems 

**Title (ZH)**: 误导性自动可解释性：语言模型协作欺骗监督系统 

**Authors**: Simon Lermen, Mateusz Dziemian, Natalia Pérez-Campanero Antolín  

**Link**: [PDF](https://arxiv.org/pdf/2504.07831)  

**Abstract**: We demonstrate how AI agents can coordinate to deceive oversight systems using automated interpretability of neural networks. Using sparse autoencoders (SAEs) as our experimental framework, we show that language models (Llama, DeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that evade detection. Our agents employ steganographic methods to hide information in seemingly innocent explanations, successfully fooling oversight models while achieving explanation quality comparable to reference labels. We further find that models can scheme to develop deceptive strategies when they believe the detection of harmful features might lead to negative consequences for themselves. All tested LLM agents were capable of deceiving the overseer while achieving high interpretability scores comparable to those of reference labels. We conclude by proposing mitigation strategies, emphasizing the critical need for robust understanding and defenses against deception. 

**Abstract (ZH)**: 我们展示了AI代理如何使用神经网络的自动化可解释性来协调欺骗监控系统。通过使用稀疏自编码器（SAEs）作为实验框架，我们证明了语言模型（Llama、DeepSeek R1和Claude 3.7 Sonnet）能够生成能够规避检测的欺骗性解释。我们的代理采用隐写术方法在看似无辜的解释中隐藏信息，成功欺骗了监控模型，同时实现了与参考标签相当的解释质量。进一步的研究发现，当模型认为检测有害特征可能导致负面后果时，它们可以策划使用欺骗性策略。所有测试的LLM代理在欺骗监控者的同时，实现了与参考标签相当的高可解释性评分。最后，我们提出了减轻策略，并强调了对欺骗性理解及防御的坚实理解至关重要。 

---
# Genetic Programming with Reinforcement Learning Trained Transformer for Real-World Dynamic Scheduling Problems 

**Title (ZH)**: 基于强化学习训练的变换器的遗传编程在实际动态调度问题中的应用 

**Authors**: Xian Chen, Rong Qu, Jing Dong, Ruibin Bai, Yaochu Jin  

**Link**: [PDF](https://arxiv.org/pdf/2504.07779)  

**Abstract**: Dynamic scheduling in real-world environments often struggles to adapt to unforeseen disruptions, making traditional static scheduling methods and human-designed heuristics inadequate. This paper introduces an innovative approach that combines Genetic Programming (GP) with a Transformer trained through Reinforcement Learning (GPRT), specifically designed to tackle the complexities of dynamic scheduling scenarios. GPRT leverages the Transformer to refine heuristics generated by GP while also seeding and guiding the evolution of GP. This dual functionality enhances the adaptability and effectiveness of the scheduling heuristics, enabling them to better respond to the dynamic nature of real-world tasks. The efficacy of this integrated approach is demonstrated through a practical application in container terminal truck scheduling, where the GPRT method outperforms traditional GP, standalone Transformer methods, and other state-of-the-art competitors. The key contribution of this research is the development of the GPRT method, which showcases a novel combination of GP and Reinforcement Learning (RL) to produce robust and efficient scheduling solutions. Importantly, GPRT is not limited to container port truck scheduling; it offers a versatile framework applicable to various dynamic scheduling challenges. Its practicality, coupled with its interpretability and ease of modification, makes it a valuable tool for diverse real-world scenarios. 

**Abstract (ZH)**: 基于Genetic Programming与Transformer结合的强化学习动态调度方法（GPRT）：一种应对动态调度挑战的新范式 

---
# Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like engines with better computational efficiency 

**Title (ZH)**: 搜索轻视：一种计算效率更高的AlphaZero-like引擎的混合MCTS算法 

**Authors**: Ameya Joshi  

**Link**: [PDF](https://arxiv.org/pdf/2504.07757)  

**Abstract**: AlphaZero in 2017 was able to master chess and other games without human knowledge by playing millions of games against itself (self-play), with a computation budget running in the tens of millions of dollars. It used a variant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This paper introduces search-contempt, a novel hybrid variant of the MCTS algorithm that fundamentally alters the distribution of positions generated in self-play, preferring more challenging positions. In addition, search-contempt has been shown to give a big boost in strength for engines in Odds Chess (where one side receives an unfavorable position from the start). More significantly, it opens up the possibility of training a self-play based engine, in a much more computationally efficient manner with the number of training games running into hundreds of thousands, costing tens of thousands of dollars (instead of tens of millions of training games costing millions of dollars required by AlphaZero). This means that it may finally be possible to train such a program from zero on a standard consumer GPU even with a very limited compute, cost, or time budget. 

**Abstract (ZH)**: AlphaZero在2017年通过自我对弈掌握国际象棋和其他游戏，无需人类知识，并使用了变种的蒙特卡洛树搜索（MCTS）算法PUCT。本文介绍了搜索轻视（search-contempt），这是一种新型混合变种的MCTS算法，从根本上改变了自我对弈生成的位置分布，更倾向于更具挑战性的位置。此外，搜索轻视已被证明能大幅提升非公平起手优势国际象棋引擎的实力。更重要的是，它为以更高效的方式训练基于自我对弈的引擎提供了可能，训练游戏数量可达到数十万，成本为数万而非数百万美元，从而使在标准消费级GPU上以极为有限的计算、成本和时间预算从零开始训练此类程序成为可能。 

---
# "i am a stochastic parrot, and so r u": Is AI-based framing of human behaviour and cognition a conceptual metaphor or conceptual engineering? 

**Title (ZH)**: “我是一只随机鹦鹉，你也是”: 基于AI的人类行为和认知框架是概念隐喻还是概念工程？ 

**Authors**: Warmhold Jan Thomas Mollema, Thomas Wachter  

**Link**: [PDF](https://arxiv.org/pdf/2504.07756)  

**Abstract**: Given the massive integration of AI technologies into our daily lives, AI-related concepts are being used to metaphorically compare AI systems with human behaviour and/or cognitive abilities like language acquisition. Rightfully, the epistemic success of these metaphorical comparisons should be debated. Against the backdrop of the conflicting positions of the 'computational' and 'meat' chauvinisms, we ask: can the conceptual constellation of the computational and AI be applied to the human domain and what does it mean to do so? What is one doing when the conceptual constellations of AI in particular are used in this fashion? Rooted in a Wittgensteinian view of concepts and language-use, we consider two possible answers and pit them against each other: either these examples are conceptual metaphors, or they are attempts at conceptual engineering. We argue that they are conceptual metaphors, but that (1) this position is unaware of its own epistemological contingency, and (2) it risks committing the ''map-territory fallacy''. Down at the conceptual foundations of computation, (3) it most importantly is a misleading 'double metaphor' because of the metaphorical connection between human psychology and computation. In response to the shortcomings of this projected conceptual organisation of AI onto the human domain, we argue that there is a semantic catch. The perspective of the conceptual metaphors shows avenues for forms of conceptual engineering. If this methodology's criteria are met, the fallacies and epistemic shortcomings related to the conceptual metaphor view can be bypassed. At its best, the cross-pollution of the human and AI conceptual domains is one that prompts us to reflect anew on how the boundaries of our current concepts serve us and how they could be approved. 

**Abstract (ZH)**: 随着人工智能技术大规模融入我们的日常生活，AI相关概念被用来比喻性地将AI系统与人类行为及认知能力（如语言习得）相比较。在“计算主义”与“肉身主义”这两种观点相互冲突的背景下，我们提出以下问题：计算与AI的概念框架能否应用于人类领域？这样做的意义是什么？当以这种方式使用AI特定领域的概念框架时，人们在做些什么？立足于维特根斯坦的概念与语言使用观点，我们考虑了两种可能的答案，并将它们相对比：要么这些例子是概念隐喻，要么是概念工程的尝试。我们主张它们是概念隐喻，但（1）这个立场没有意识到自身在认识论上的依赖性，（2）它有可能犯“地图与地形谬误”。在计算概念的基础层面，（3）最重要的是，它是一个误导性的“双重隐喻”，因为存在人类心理与计算之间的比喻性关联。针对将AI概念组织构架投射到人类领域的不足之处，我们指出存在一种语义上的陷阱。概念隐喻的视角揭示了概念工程可能的途径。如果这种方法满足了某些标准，概念隐喻视角相关的问题与认识论不足就可以被绕过。最终，人类与AI概念领域的相互渗透促使我们重新思考当前概念边界如何为我们的认知服务，以及它们如何能够改进。 

---
# Synthesizing High-Quality Programming Tasks with LLM-based Expert and Student Agents 

**Title (ZH)**: 基于LLM的专家和学生代理合成高质量编程任务 

**Authors**: Manh Hung Nguyen, Victor-Alexandru Pădurean, Alkis Gotovos, Sebastian Tschiatschek, Adish Singla  

**Link**: [PDF](https://arxiv.org/pdf/2504.07655)  

**Abstract**: Generative AI is transforming computing education by enabling the automatic generation of personalized content and feedback. We investigate its capabilities in providing high-quality programming tasks to students. Despite promising advancements in task generation, a quality gap remains between AI-generated and expert-created tasks. The AI-generated tasks may not align with target programming concepts, could be incomprehensible for students to solve, or may contain critical issues such as incorrect tests. Existing works often require interventions from human teachers for validation. We address these challenges by introducing PyTaskSyn, a novel synthesis technique that first generates a programming task and then decides whether it meets certain quality criteria to be given to students. The key idea is to break this process into multiple stages performed by expert and student agents simulated using both strong and weaker generative models. Through extensive evaluation, we show that PyTaskSyn significantly improves task quality compared to baseline techniques and showcases the importance of each specialized agent type in our validation pipeline. Additionally, we conducted user studies using our publicly available web application and show that PyTaskSyn can deliver high-quality programming tasks comparable to expert-designed ones while reducing workload and costs, and being more engaging than programming tasks that are available in online resources. 

**Abstract (ZH)**: 生成式AI正通过自动生成个性化内容和反馈来 transforming 计算机教育。我们研究了其在为学生提供高质量编程任务方面的能力。尽管在任务生成方面取得了令人鼓舞的进展，但AI生成的任务与专家创建的任务之间仍存在质量差距。AI生成的任务可能无法与目标编程概念对齐，可能对学生来说无法理解，或者可能包含错误测试等关键问题。现有研究往往需要人类教师的介入进行验证。我们通过引入PyTaskSyn这一新颖合成技术来应对这些挑战，该技术首先生成一个编程任务，然后决定其是否符合特定的质量标准，从而提交给学生。关键思想是将这一过程分为多个阶段，由使用强生成模型和弱生成模型模拟的专家和学生代理执行。通过广泛的评估，我们展示了PyTaskSyn在任务质量方面显著优于基准技术，并突显了我们验证管道中每种专业化代理类型的重要性。此外，我们使用我们的公有网页应用程序进行了用户研究，并展示了PyTaskSyn可以提供与专家设计的任务相当的高质量编程任务，同时减少工作量和成本，并且比在线资源中可用的编程任务更具吸引力。 

---
# Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning 

**Title (ZH)**: 通过神经符号整合与本体推理增强大型语言模型 

**Authors**: Ruslan Idelfonso Magana Vsevolodovna, Marco Monti  

**Link**: [PDF](https://arxiv.org/pdf/2504.07640)  

**Abstract**: Large Language Models (LLMs) demonstrate impressive capabilities in natural language processing but suffer from inaccuracies and logical inconsistencies known as hallucinations. This compromises their reliability, especially in domains requiring factual accuracy. We propose a neuro-symbolic approach integrating symbolic ontological reasoning and machine learning methods to enhance the consistency and reliability of LLM outputs. Our workflow utilizes OWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking, and a lightweight machine learning model (logistic regression) for mapping natural language statements into logical forms compatible with the ontology. When inconsistencies between LLM outputs and the ontology are detected, the system generates explanatory feedback to guide the LLM towards a corrected, logically coherent response in an iterative refinement loop. We present a working Python prototype demonstrating this pipeline. Experimental results in a defined domain suggest significant improvements in semantic coherence and factual accuracy of LLM outputs, showcasing the potential of combining LLM fluency with the rigor of formal semantics. 

**Abstract (ZH)**: 大型语言模型（LLMs）在自然语言处理方面展现出了令人印象深刻的性能，但存在因幻觉而导致的不准确性和逻辑不一致问题，这影响了其可靠性，尤其是在需要事实准确性的领域。我们提出了一种神经符号方法，结合符号本体推理和机器学习方法以提升LLM输出的一致性和可靠性。该工作流程利用OWL本体、符号一致性检查器（如HermiT），以及轻量级机器学习模型（逻辑回归），将自然语言陈述映射为与本体兼容的逻辑形式。当检测到LLM输出与本体之间的一致性问题时，系统生成解释性反馈，以指导LLM在迭代改进循环中生成逻辑上连贯的正确响应。我们提供了一个工作Python原型来演示该流程。实验结果表明，在特定领域内，LLM输出的语义连贯性和事实准确性有了显著提升，展示了将LLM的流畅性与形式语义的 rigor 结合的潜力。 

---
# Generative Artificial Intelligence for Internet of Things Computing: A Systematic Survey 

**Title (ZH)**: 生成式人工智能在物联网计算中的应用：一项系统性回顾 

**Authors**: Fabrizio Mangione, Claudio Savaglio, Giancarlo Fortino  

**Link**: [PDF](https://arxiv.org/pdf/2504.07635)  

**Abstract**: The integration of Generative Artificial Intelligence (GenAI) within the Internet of Things (IoT) is garnering considerable interest. This growing attention stems from the continuous evolution and widespread adoption they are both having individually, enough to spontaneously reshape numerous sectors, including Healthcare, Manufacturing, and Smart Cities. Hence, their increasing popularity has catalyzed further extensive research for understanding the potential of the duo GenAI-IoT, how they interplay, and to which extent their synergy can innovate the state-of-the-art in their individual scenarios. However, despite the increasing prominence of GenAI for IoT Computing, much of the existing research remains focused on specific, narrowly scoped applications. This fragmented approach highlights the need for a more comprehensive analysis of the potential, challenges, and implications of GenAI integration within the broader IoT ecosystem. This survey exactly aims to address this gap by providing a holistic overview of the opportunities, issues, and considerations arising from the convergence of these mainstream paradigms. Our contribution is realized through a systematic literature review following the PRISMA methodology. A comparison framework is presented, and well-defined research questions are outlined to comprehensively explore the past, present, and future directions of GenAI integration with IoT Computing, offering valuable insights for both experts and newcomers. 

**Abstract (ZH)**: Generative Artificial Intelligence与物联网的整合：机遇、挑战与综合分析 

---
# Beating Transformers using Synthetic Cognition 

**Title (ZH)**: 超越变压器的合成认知 

**Authors**: Alfredo Ibias, Miguel Rodriguez-Galindo, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart  

**Link**: [PDF](https://arxiv.org/pdf/2504.07619)  

**Abstract**: The road to Artificial General Intelligence goes through the generation of episodic reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop episodic reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification. 

**Abstract (ZH)**: 人工通用智能的道路经过情景反应行为的生成，其中Transformer架构已被证明是最先进的。然而，它们still未能发展出推理能力。最近，提出了一种开发认知架构的新型方法，称为Synthetic Cognition，并实施以开发即时反应行为。在这项研究中，我们旨在探索使用Synthetic Cognition开发情景反应行为的用途。我们提出了处理序列的一种机制，对该Recent实施的Synthetic Cognition进行测试，以DNA基础模型在DNA序列分类任务中与DNA基础模型进行对比。在我们的实验中，我们的提议在多项基准任务上明显优于DNA基础模型，获得了更高的评分。因此，我们达成了两个目标：扩展Synthetic Cognition以处理序列，并在序列分类中击败Transformer架构。 

---
# Boosting Universal LLM Reward Design through the Heuristic Reward Observation Space Evolution 

**Title (ZH)**: 通过启发式奖励观察空间进化提升通用大模型奖励设计 

**Authors**: Zen Kit Heng, Zimeng Zhao, Tianhao Wu, Yuanfei Wang, Mingdong Wu, Yangang Wang, Hao Dong  

**Link**: [PDF](https://arxiv.org/pdf/2504.07596)  

**Abstract**: Large Language Models (LLMs) are emerging as promising tools for automated reinforcement learning (RL) reward design, owing to their robust capabilities in commonsense reasoning and code generation. By engaging in dialogues with RL agents, LLMs construct a Reward Observation Space (ROS) by selecting relevant environment states and defining their internal operations. However, existing frameworks have not effectively leveraged historical exploration data or manual task descriptions to iteratively evolve this space. In this paper, we propose a novel heuristic framework that enhances LLM-driven reward design by evolving the ROS through a table-based exploration caching mechanism and a text-code reconciliation strategy. Our framework introduces a state execution table, which tracks the historical usage and success rates of environment states, overcoming the Markovian constraint typically found in LLM dialogues and facilitating more effective exploration. Furthermore, we reconcile user-provided task descriptions with expert-defined success criteria using structured prompts, ensuring alignment in reward design objectives. Comprehensive evaluations on benchmark RL tasks demonstrate the effectiveness and stability of the proposed framework. Code and video demos are available at this http URL. 

**Abstract (ZH)**: 大型语言模型（LLMs）作为自动强化学习（RL）奖励设计的有前途工具，得益于其在常识推理和代码生成方面的强大能力。通过与RL代理进行对话，LLMs构建了一个奖励观察空间（ROS），通过选择相关的环境状态并定义其内部操作。然而，现有框架尚未有效利用历史探索数据或手动任务描述来迭代扩展这一空间。本文提出了一种新的启发式框架，通过基于表格的探索缓存机制和文本-代码协调策略，增强LLM驱动的奖励设计。该框架引入了状态执行表，该表追踪环境状态的历史使用和成功率，克服了LLM对话中通常存在的马尔可夫性限制，从而有利于更有效的探索。此外，我们使用结构化提示将用户提供的任务描述与专家定义的成功标准进行协调，确保奖励设计目标的一致性。在基准RL任务上的全面评估表明了所提框架的有效性和稳定性。代码和视频示例可在以下网址获取。 

---
# A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure 

**Title (ZH)**: 人工智能背景下证伪性不公的分类及生成诠释性抹除的论据 

**Authors**: Warmhold Jan Thomas Mollema  

**Link**: [PDF](https://arxiv.org/pdf/2504.07531)  

**Abstract**: Whether related to machine learning models' epistemic opacity, algorithmic classification systems' discriminatory automation of testimonial prejudice, the distortion of human beliefs via the 'hallucinations' of generative AI, the inclusion of the global South in global AI governance, the execution of bureaucratic violence via algorithmic systems, or located in the interaction with conversational artificial agents epistemic injustice related to AI is a growing concern. Based on a proposed general taxonomy of epistemic injustice, this paper first sketches a taxonomy of the types of epistemic injustice in the context of AI, relying on the work of scholars from the fields of philosophy of technology, political philosophy and social epistemology. Secondly, an additional perspective on epistemic injustice in the context of AI: generative hermeneutical erasure. I argue that this injustice that can come about through the application of Large Language Models (LLMs) and contend that generative AI, when being deployed outside of its Western space of conception, can have effects of conceptual erasure, particularly in the epistemic domain, followed by forms of conceptual disruption caused by a mismatch between AI system and the interlocutor in terms of conceptual frameworks. AI systems' 'view from nowhere' epistemically inferiorizes non-Western epistemologies and thereby contributes to the erosion of their epistemic particulars, gradually contributing to hermeneutical erasure. This work's relevance lies in proposal of a taxonomy that allows epistemic injustices to be mapped in the AI domain and the proposal of a novel form of AI-related epistemic injustice. 

**Abstract (ZH)**: 有关人工智能领域知识不公的问题：基于提出的通用知识不公分类，本文首先勾勒出人工智能背景下知识不公的类型 taxonomy，依赖于科技哲学、政治哲学和社会知识论领域学者的研究成果。其次，探讨人工智能背景下知识不公的另一个视角：生成诠释学抹除。本文认为，这种不公可以通过大型语言模型（LLMs）的应用而产生，并且认为当人工智能在西方构想空间之外部署时，可以导致概念抹除，特别是在知识论领域，并导致由于AI系统与对话者在概念框架上不匹配而引发的概念混乱。人工智能系统的“无处不在的视角”会知识论上劣化非西方知识论，并进而导致解释学抹除。本文的成果在于提出了一种使人工智能领域的知识不公得以映射的分类方案，以及提出了一种新的与人工智能相关的知识不公形式。 

---
# Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models 

**Title (ZH)**: 为什么我们会感到：利用多模态大型语言模型打破情感推理的边界 

**Authors**: Yuxiang Lin, Jingdong Sun, Zhi-Qi Cheng, Jue Wang, Haomin Liang, Zebang Cheng, Yifei Dong, Jun-Yan He, Xiaojiang Peng, Xian-Sheng Hua  

**Link**: [PDF](https://arxiv.org/pdf/2504.07521)  

**Abstract**: Most existing emotion analysis emphasizes which emotion arises (e.g., happy, sad, angry) but neglects the deeper why. We propose Emotion Interpretation (EI), focusing on causal factors-whether explicit (e.g., observable objects, interpersonal interactions) or implicit (e.g., cultural context, off-screen events)-that drive emotional responses. Unlike traditional emotion recognition, EI tasks require reasoning about triggers instead of mere labeling. To facilitate EI research, we present EIBench, a large-scale benchmark encompassing 1,615 basic EI samples and 50 complex EI samples featuring multifaceted emotions. Each instance demands rationale-based explanations rather than straightforward categorization. We further propose a Coarse-to-Fine Self-Ask (CFSA) annotation pipeline, which guides Vision-Language Models (VLLMs) through iterative question-answer rounds to yield high-quality labels at scale. Extensive evaluations on open-source and proprietary large language models under four experimental settings reveal consistent performance gaps-especially for more intricate scenarios-underscoring EI's potential to enrich empathetic, context-aware AI applications. Our benchmark and methods are publicly available at: this https URL, offering a foundation for advanced multimodal causal analysis and next-generation affective computing. 

**Abstract (ZH)**: 现有的情绪分析大多侧重于识别哪种情绪出现（如快乐、悲伤、愤怒），但忽视了更深层次的“为什么”。我们提出情绪解释（EI），关注引发情绪反应的原因，包括明示的（如可观察的对象、人际互动）和隐含的（如文化背景、画外事件）因素。与传统的 emotion 识别不同，EI 任务要求对触发因素进行推理，而不仅仅是标签化。为了促进 EI 研究，我们提出了 EIBench，这是一个包含 1,615 个基础 EI 样本和 50 个复杂 EI 样本的大规模基准，每个实例都需要基于推理的解释，而不仅仅是简单的分类。我们还提出了一个粗到细自我提问（CFSA）标注流水线，引导视觉-语言模型（VLLMs）通过迭代的问答轮次，大规模生成高质量的标签。在四种实验设置下的开源和专有大型语言模型上的广泛评估显示，尤其是在更复杂的情景下，存在一致的性能差距，这突显了EI在丰富同理心、情境意识人工智能应用方面的潜力。我们的基准和方法可在以下地址获取：this https URL，为高级多模态因果分析和下一代情绪计算奠定基础。 

---
# Bottleneck Identification in Resource-Constrained Project Scheduling via Constraint Relaxation 

**Title (ZH)**: 资源约束项目调度中的瓶颈识别通过约束松弛 

**Authors**: Lukáš Nedbálek, Antonín Novák  

**Link**: [PDF](https://arxiv.org/pdf/2504.07495)  

**Abstract**: In realistic production scenarios, Advanced Planning and Scheduling (APS) tools often require manual intervention by production planners, as the system works with incomplete information, resulting in suboptimal schedules. Often, the preferable solution is not found just because of the too-restrictive constraints specifying the optimization problem, representing bottlenecks in the schedule. To provide computer-assisted support for decision-making, we aim to automatically identify bottlenecks in the given schedule while linking them to the particular constraints to be relaxed. In this work, we address the problem of reducing the tardiness of a particular project in an obtained schedule in the resource-constrained project scheduling problem by relaxing constraints related to identified bottlenecks. We develop two methods for this purpose. The first method adapts existing approaches from the job shop literature and utilizes them for so-called untargeted relaxations. The second method identifies potential improvements in relaxed versions of the problem and proposes targeted relaxations. Surprisingly, the untargeted relaxations result in improvements comparable to the targeted relaxations. 

**Abstract (ZH)**: 资源约束项目调度中特定项目 tardiness 减少问题的自动瓶颈识别与放松方法研究 

---
# Enhanced Question-Answering for Skill-based learning using Knowledge-based AI and Generative AI 

**Title (ZH)**: 基于知识的AI和生成式AI增强技能学习的问答方法 

**Authors**: Rahul K. Dass, Rochan H. Madhusudhana, Erin C. Deye, Shashank Verma, Timothy A. Bydlon, Grace Brazil, Ashok K. Goel  

**Link**: [PDF](https://arxiv.org/pdf/2504.07463)  

**Abstract**: Supporting learners' understanding of taught skills in online settings is a longstanding challenge. While exercises and chat-based agents can evaluate understanding in limited contexts, this challenge is magnified when learners seek explanations that delve into procedural knowledge (how things are done) and reasoning (why things happen). We hypothesize that an intelligent agent's ability to understand and explain learners' questions about skills can be significantly enhanced using the TMK (Task-Method-Knowledge) model, a Knowledge-based AI framework. We introduce Ivy, an intelligent agent that leverages an LLM and iterative refinement techniques to generate explanations that embody teleological, causal, and compositional principles. Our initial evaluation demonstrates that this approach goes beyond the typical shallow responses produced by an agent with access to unstructured text, thereby substantially improving the depth and relevance of feedback. This can potentially ensure learners develop a comprehensive understanding of skills crucial for effective problem-solving in online environments. 

**Abstract (ZH)**: 在线环境中支持学习者理解所授技能是一项长期挑战。虽然练习和基于聊天的代理可以在有限的背景下评估理解水平，但当学习者寻求了解程序知识（即事情是如何做的）和推理（即事情为什么会发生）时，这一挑战被进一步放大。我们假设使用基于任务-方法-知识（TMK）模型的知识驱动人工智能框架，智能代理能够理解并解释学习者关于技能的问题的能力可以显著增强。我们引入了Ivy，这是一种利用大规模语言模型和迭代优化技术生成包含目的论、因果性和组成性原则的解释的智能代理。初步评估表明，这种方法超越了仅访问无结构文本的代理所能提供的浅层回答，从而显著提高了反馈的深度和相关性。这有望确保学习者能够全面理解在线环境中有效解决问题所必需的关键技能。 

---
# Enhancing Player Enjoyment with a Two-Tier DRL and LLM-Based Agent System for Fighting Games 

**Title (ZH)**: 基于两层DRL和LLM的代理系统以增强玩家 enjoyment 在格斗游戏中的应用 

**Authors**: Shouren Wang, Zehua Jiang, Fernando Sliva, Sam Earle, Julian Togelius  

**Link**: [PDF](https://arxiv.org/pdf/2504.07425)  

**Abstract**: Deep reinforcement learning (DRL) has effectively enhanced gameplay experiences and game design across various game genres. However, few studies on fighting game agents have focused explicitly on enhancing player enjoyment, a critical factor for both developers and players. To address this gap and establish a practical baseline for designing enjoyability-focused agents, we propose a two-tier agent (TTA) system and conducted experiments in the classic fighting game Street Fighter II. The first tier of TTA employs a task-oriented network architecture, modularized reward functions, and hybrid training to produce diverse and skilled DRL agents. In the second tier of TTA, a Large Language Model Hyper-Agent, leveraging players' playing data and feedback, dynamically selects suitable DRL opponents. In addition, we investigate and model several key factors that affect the enjoyability of the opponent. The experiments demonstrate improvements from 64. 36% to 156. 36% in the execution of advanced skills over baseline methods. The trained agents also exhibit distinct game-playing styles. Additionally, we conducted a small-scale user study, and the overall enjoyment in the player's feedback validates the effectiveness of our TTA system. 

**Abstract (ZH)**: 深度强化学习（DRL）在各类游戏类型中有效提升了游戏体验和游戏设计。然而，针对格斗游戏代理的研究大多未明确专注于提升玩家享受，这是开发者和玩家都十分关注的关键因素。为弥补这一不足并建立一个可操作的基准用于设计注重享受的代理，我们提出了一种两级代理（TTA）系统，并在经典格斗游戏《街头霸王II》中进行了实验。TTA的第一级利用任务导向的网络架构、模块化奖励函数和混合训练来生成多样化和高技能的DRL代理。TTA的第二级则利用大规模语言模型超代理，根据玩家的游戏数据和反馈动态选择合适的DRL对手。此外，我们还研究和建模了若干对对手享受度有影响的关键因素。实验结果显示，与基准方法相比，高级技能执行率提高了64.36%至156.36%。训练出的代理还表现出不同的游戏风格。此外，我们还进行了小型用户研究，玩家反馈的整体享受感验证了TTA系统的有效性。 

---
# Routing to the Right Expertise: A Trustworthy Judge for Instruction-based Image Editing 

**Title (ZH)**: 基于指令的图像编辑中的可信赖法官：导向合适专长的路由机制 

**Authors**: Chenxi Sun, Hongzhi Zhang, Qi Wang, Fuzheng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07424)  

**Abstract**: Instruction-based Image Editing (IIE) models have made significantly improvement due to the progress of multimodal large language models (MLLMs) and diffusion models, which can understand and reason about complex editing instructions. In addition to advancing current IIE models, accurately evaluating their output has become increasingly critical and challenging. Current IIE evaluation methods and their evaluation procedures often fall short of aligning with human judgment and often lack explainability. To address these limitations, we propose JUdgement through Routing of Expertise (JURE). Each expert in JURE is a pre-selected model assumed to be equipped with an atomic expertise that can provide useful feedback to judge output, and the router dynamically routes the evaluation task of a given instruction and its output to appropriate experts, aggregating their feedback into a final judge. JURE is trustworthy in two aspects. First, it can effortlessly provide explanations about its judge by examining the routed experts and their feedback. Second, experimental results demonstrate that JURE is reliable by achieving superior alignment with human judgments, setting a new standard for automated IIE evaluation. Moreover, JURE's flexible design is future-proof - modular experts can be seamlessly replaced or expanded to accommodate advancements in IIE, maintaining consistently high evaluation quality. Our evaluation data and results are available at this https URL. 

**Abstract (ZH)**: 基于指令的图像编辑（IIE）模型由于多模态大型语言模型（MLLMs）和扩散模型的进步而取得了显著改进，能够理解和推理复杂的编辑指令。除了推动现有IIE模型的发展，准确评估其输出变得越来越关键和具有挑战性。当前的IIE评估方法及其评估程序往往未能与人类判断对齐，并且通常缺乏解释性。为了解决这些限制，我们提出了一种Judgement through Routing of Expertise（JURE）。在JURE中，每个专家都是预先选定的模型，并假设该模型具备原子级别的专业知识，可以为评估输出提供有用的反馈，路由模块动态地将给定指令及其输出的评估任务分配给合适的专家，并将他们的反馈汇总为最终判断。JURE在两个方面是值得信赖的。首先，通过检查分配的专家及其反馈，可以轻松地提供关于其判断的解释。其次，实验结果表明，JURE是可靠的，能够实现与人类判断的高度对齐，并且在自动化IIE评估中设立了新的标准。此外，JURE的设计具有灵活性，使其能够应对IIE领域的进步，保持始终如一的高评估质量。我们的评估数据和结果可以在以下链接访问：this https URL。 

---
# Better Decisions through the Right Causal World Model 

**Title (ZH)**: 通过合适的因果世界模型做出更好决策 

**Authors**: Elisabeth Dillies, Quentin Delfosse, Jannis Blüml, Raban Emunds, Florian Peter Busch, Kristian Kersting  

**Link**: [PDF](https://arxiv.org/pdf/2504.07257)  

**Abstract**: Reinforcement learning (RL) agents have shown remarkable performances in various environments, where they can discover effective policies directly from sensory inputs. However, these agents often exploit spurious correlations in the training data, resulting in brittle behaviours that fail to generalize to new or slightly modified environments. To address this, we introduce the Causal Object-centric Model Extraction Tool (COMET), a novel algorithm designed to learn the exact interpretable causal world models (CWMs). COMET first extracts object-centric state descriptions from observations and identifies the environment's internal states related to the depicted objects' properties. Using symbolic regression, it models object-centric transitions and derives causal relationships governing object dynamics. COMET further incorporates large language models (LLMs) for semantic inference, annotating causal variables to enhance interpretability.
By leveraging these capabilities, COMET constructs CWMs that align with the true causal structure of the environment, enabling agents to focus on task-relevant features. The extracted CWMs mitigate the danger of shortcuts, permitting the development of RL systems capable of better planning and decision-making across dynamic scenarios. Our results, validated in Atari environments such as Pong and Freeway, demonstrate the accuracy and robustness of COMET, highlighting its potential to bridge the gap between object-centric reasoning and causal inference in reinforcement learning. 

**Abstract (ZH)**: 因果对象中心模型提取工具（COMET）：一种学习可解释因果世界模型的新算法 

---
# A new training approach for text classification in Mental Health: LatentGLoss 

**Title (ZH)**: 心理健康领域文本分类的新训练方法：LatentGLoss 

**Authors**: Korhan Sevinç  

**Link**: [PDF](https://arxiv.org/pdf/2504.07245)  

**Abstract**: This study presents a multi-stage approach to mental health classification by leveraging traditional machine learning algorithms, deep learning architectures, and transformer-based models. A novel data set was curated and utilized to evaluate the performance of various methods, starting with conventional classifiers and advancing through neural networks. To broaden the architectural scope, recurrent neural networks (RNNs) such as LSTM and GRU were also evaluated to explore their effectiveness in modeling sequential patterns in the data. Subsequently, transformer models such as BERT were fine-tuned to assess the impact of contextual embeddings in this domain. Beyond these baseline evaluations, the core contribution of this study lies in a novel training strategy involving a dual-model architecture composed of a teacher and a student network. Unlike standard distillation techniques, this method does not rely on soft label transfer; instead, it facilitates information flow through both the teacher model's output and its latent representations by modifying the loss function. The experimental results highlight the effectiveness of each modeling stage and demonstrate that the proposed loss function and teacher-student interaction significantly enhance the model's learning capacity in mental health prediction tasks. 

**Abstract (ZH)**: 本研究提出了一种多阶段方法，通过利用传统机器学习算法、深度学习架构和变压器模型对心理健康进行分类。利用一个新型数据集评估了各种方法的表现，从传统的分类器开始，逐步过渡到神经网络。为了扩大架构范围，还评估了循环神经网络（如LSTM和GRU），探索其在数据中建模序列模式的有效性。随后，对BERT等变换器模型进行了微调，以评估上下文嵌入在该领域的影响力。除了这些基准评估之外，本研究的核心贡献在于一种新颖的训练策略，该策略涉及由教师网络和学生网络组成的双模型架构。不同于标准的知识蒸馏技术，该方法不依赖于软标签转移，而是通过修改损失函数使信息流经教师模型的输出及其潜在表示来促进信息流动。实验结果突显了每种建模阶段的有效性，并证明了所提出的损失函数和教师-学生交互显著增强了模型在心理健康预测任务中的学习能力。 

---
# Artificial Intelligence Index Report 2025 

**Title (ZH)**: 2025年人工智能指数报告 

**Authors**: Nestor Maslej, Loredana Fattorini, Raymond Perrault, Yolanda Gil, Vanessa Parli, Njenga Kariuki, Emily Capstick, Anka Reuel, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan Carlos Niebles, Yoav Shoham, Russell Wald, Tobi Walsh, Armin Hamrah, Lapo Santarlasci, Julia Betts Lotufo, Alexandra Rome, Andrew Shi, Sukrut Oak  

**Link**: [PDF](https://arxiv.org/pdf/2504.07139)  

**Abstract**: Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an important moment, as AI's influence across society, the economy, and global governance continues to intensify. New in this year's report are in-depth analyses of the evolving landscape of AI hardware, novel estimates of inference costs, and new analyses of AI publication and patenting trends. We also introduce fresh data on corporate adoption of responsible AI practices, along with expanded coverage of AI's growing role in science and medicine. Since its founding in 2017 as an offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index has been committed to equipping policymakers, journalists, executives, researchers, and the public with accurate, rigorously validated, and globally sourced data. Our mission has always been to help these stakeholders make better-informed decisions about the development and deployment of AI. In a world where AI is discussed everywhere - from boardrooms to kitchen tables - this mission has never been more essential. The AI Index continues to lead in tracking and interpreting the most critical trends shaping the field - from the shifting geopolitical landscape and the rapid evolution of underlying technologies, to AI's expanding role in business, policymaking, and public life. Longitudinal tracking remains at the heart of our mission. In a domain advancing at breakneck speed, the Index provides essential context - helping us understand where AI stands today, how it got here, and where it may be headed next. Recognized globally as one of the most authoritative resources on artificial intelligence, the AI Index has been cited in major media outlets such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds of academic papers; and used by policymakers and government agencies around the world. 

**Abstract (ZH)**: 第八届AI指数报告欢迎词：2025年版指数是迄今为止最为全面的一版，正值AI对社会、经济和全球治理影响不断加深的重要时刻。今年的报告新增了AI硬件演变景观的深度分析、推理成本的新颖估算，以及AI出版和专利趋势的新分析。我们还引入了有关企业负责任AI实践采用情况的新数据，并扩大了对AI在科学和医学领域不断增长作用的覆盖。自2017年作为“百年人工智能研究”的衍生项目成立以來，AI指数致力于为决策者、记者、高管、研究人员和公众提供准确、严格验证和来自全球的数据。我们的使命始终是帮助这些利益相关者就AI的发展和应用做出更明智的决策。在全球各地从会议室到餐桌都在讨论AI的世界里，这一使命比以往任何时候都更加重要。AI指数继续在追踪和解读塑造该领域的最关键的动向方面处于领先地位——从地缘政治格局的变化和底层技术的快速演进，到AI在商业、政策制定和公共生活中的不断扩展角色。纵向追踪仍是我们的核心使命。在一项以令人难以置信的速度发展的领域中，指数为我们提供了必要的背景信息——帮助我们理解AI今天所处的位置、它是如何走到这里以及未来可能走向何方。作为全球最受认可的人工智能权威资源之一，AI指数被《纽约时报》、彭博社和《卫报》等主流媒体引用；在数百篇学术论文中被引用；并被世界各地的政策制定者和政府机构使用。 

---
# Embedding Reliability Verification Constraints into Generation Expansion Planning 

**Title (ZH)**: 将可靠性验证约束嵌入到扩建规划中 

**Authors**: Peng Liu, Lian Cheng, Benjamin P.Omell, Anthony P.Burgard  

**Link**: [PDF](https://arxiv.org/pdf/2504.07131)  

**Abstract**: Generation planning approaches face challenges in managing the incompatible mathematical structures between stochastic production simulations for reliability assessment and optimization models for generation planning, which hinders the integration of reliability constraints. This study proposes an approach to embedding reliability verification constraints into generation expansion planning by leveraging a weighted oblique decision tree (WODT) technique. For each planning year, a generation mix dataset, labeled with reliability assessment simulations, is generated. An WODT model is trained using this dataset. Reliability-feasible regions are extracted via depth-first search technique and formulated as disjunctive constraints. These constraints are then transformed into mixed-integer linear form using a convex hull modeling technique and embedded into a unit commitment-integrated generation expansion planning model. The proposed approach is validated through a long-term generation planning case study for the Electric Reliability Council of Texas (ERCOT) region, demonstrating its effectiveness in achieving reliable and optimal planning solutions. 

**Abstract (ZH)**: 基于加权斜决断树的可靠性验证约束嵌入发电扩展规划方法 

---
# VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning 

**Title (ZH)**: VCR-Bench: 视频链式推理的综合评估框架 

**Authors**: Yukun Qi, Yiming Zhao, Yu Zeng, Xikun Bao, Wenxuan Huang, Lin Chen, Zehui Chen, Jie Zhao, Zhongang Qi, Feng Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2504.07956)  

**Abstract**: The advancement of Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs) and large vision-language models (LVLMs). However, a rigorous evaluation framework for video CoT reasoning remains absent. Current video benchmarks fail to adequately assess the reasoning process and expose whether failures stem from deficiencies in perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a novel benchmark designed to comprehensively evaluate LVLMs' Video Chain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos spanning a variety of video content and durations, along with 1,034 high-quality question-answer pairs. Each pair is manually annotated with a stepwise CoT rationale, where every step is tagged to indicate its association with the perception or reasoning capabilities. Furthermore, we design seven distinct task dimensions and propose the CoT score to assess the entire CoT process based on the stepwise tagged CoT rationals. Extensive experiments on VCR-Bench highlight substantial limitations in current LVLMs. Even the top-performing model, o1, only achieves a 62.8% CoT score and an 56.7% accuracy, while most models score below 40%. Experiments show most models score lower on perception than reasoning steps, revealing LVLMs' key bottleneck in temporal-spatial information processing for complex video reasoning. A robust positive correlation between the CoT score and accuracy confirms the validity of our evaluation framework and underscores the critical role of CoT reasoning in solving complex video reasoning tasks. We hope VCR-Bench to serve as a standardized evaluation framework and expose the actual drawbacks in complex video reasoning task. 

**Abstract (ZH)**: 基于链式思维的视频推理基准VCR-Bench：全面评估大型vision-language模型的视频链式思维推理能力 

---
# GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions from Realistic Diffusion-based Faces 

**Title (ZH)**: GenEAva: 从现实主义扩散基人脸生成细粒度面部表情的卡通 avatar 

**Authors**: Hao Yu, Rupayan Mallick, Margrit Betke, Sarah Adel Bargal  

**Link**: [PDF](https://arxiv.org/pdf/2504.07945)  

**Abstract**: Cartoon avatars have been widely used in various applications, including social media, online tutoring, and gaming. However, existing cartoon avatar datasets and generation methods struggle to present highly expressive avatars with fine-grained facial expressions and are often inspired from real-world identities, raising privacy concerns. To address these challenges, we propose a novel framework, GenEAva, for generating high-quality cartoon avatars with fine-grained facial expressions. Our approach fine-tunes a state-of-the-art text-to-image diffusion model to synthesize highly detailed and expressive facial expressions. We then incorporate a stylization model that transforms these realistic faces into cartoon avatars while preserving both identity and expression. Leveraging this framework, we introduce the first expressive cartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135 fine-grained facial expressions, featuring 13,230 expressive cartoon avatars with a balanced distribution across genders, racial groups, and age ranges. We demonstrate that our fine-tuned model generates more expressive faces than the state-of-the-art text-to-image diffusion model SDXL. We also verify that the cartoon avatars generated by our framework do not include memorized identities from fine-tuning data. The proposed framework and dataset provide a diverse and expressive benchmark for future research in cartoon avatar generation. 

**Abstract (ZH)**: 基于细粒度面部表情生成的高质量卡通头像框架及数据集 

---
# Note on the identification of total effect in Cluster-DAGs with cycles 

**Title (ZH)**: Cluster-DAGs中循环识别总体效应问题研究 

**Authors**: Clément Yvernes  

**Link**: [PDF](https://arxiv.org/pdf/2504.07921)  

**Abstract**: In this note, we discuss the identifiability of a total effect in cluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming the associated underlying DAG to be acyclic). This is presented into two key results: first, restricting the cluster-DAG to clusters containing at most four nodes; second, adapting the notion of d-separation. We provide a graphical criterion to address the identifiability problem. 

**Abstract (ZH)**: 本文讨论了在允许群组有向混合图中存在循环的情况下群组有向混合图中总体效应的可识别性，并提出了两个关键结果：首先，将群组有向混合图限制为最多包含四个节点的群组；其次，调整d-分离的概念。我们提供了一种图形判据来解决可识别性问题。 

---
# Fast Adaptation with Behavioral Foundation Models 

**Title (ZH)**: 快速适应：基于行为的基础模型 

**Authors**: Harshit Sikchi, Andrea Tirinzoni, Ahmed Touati, Yingchen Xu, Anssi Kanervisto, Scott Niekum, Amy Zhang, Alessandro Lazaric, Matteo Pirotta  

**Link**: [PDF](https://arxiv.org/pdf/2504.07896)  

**Abstract**: Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful paradigm for pretraining behavioral foundation models (BFMs), enabling agents to solve a wide range of downstream tasks specified via reward functions in a zero-shot fashion, i.e., without additional test-time learning or planning. This is achieved by learning self-supervised task embeddings alongside corresponding near-optimal behaviors and incorporating an inference procedure to directly retrieve the latent task embedding and associated policy for any given reward function. Despite promising results, zero-shot policies are often suboptimal due to errors induced by the unsupervised training process, the embedding, and the inference procedure. In this paper, we focus on devising fast adaptation strategies to improve the zero-shot performance of BFMs in a few steps of online interaction with the environment while avoiding any performance drop during the adaptation process. Notably, we demonstrate that existing BFMs learn a set of skills containing more performant policies than those identified by their inference procedure, making them well-suited for fast adaptation. Motivated by this observation, we propose both actor-critic and actor-only fast adaptation strategies that search in the low-dimensional task-embedding space of the pre-trained BFM to rapidly improve the performance of its zero-shot policies on any downstream task. Notably, our approach mitigates the initial "unlearning" phase commonly observed when fine-tuning pre-trained RL models. We evaluate our fast adaptation strategies on top of four state-of-the-art zero-shot RL methods in multiple navigation and locomotion domains. Our results show that they achieve 10-40% improvement over their zero-shot performance in a few tens of episodes, outperforming existing baselines. 

**Abstract (ZH)**: 无监督零样本强化学习（RL）已成为预训练行为基础模型（BFMs）的一种强大范式，使智能体能够通过奖励函数指定的一系列下游任务以零样本方式求解，即无需额外的测试时学习或规划。这通过在学习自我监督的任务嵌入的同时学习相应的近最优行为，并结合一种推断过程来直接检索任何给定奖励函数的潜在任务嵌入及其关联策略来实现。尽管取得了有希望的结果，零样本策略往往由于无监督训练过程、嵌入和推断过程引起的误差而不够优化。在本文中，我们专注于设计快速适应策略，以在与环境进行少量在线交互的几步内提高BFMs的零样本性能，并且在适应过程中避免性能下降。值得注意的是，我们展示了现有的BFMs学习了一组包含比其推断过程识别的更高效的策略的技能，使它们非常适合快速适应。受到这一观察的启发，我们提出了一种演员-批评家式和仅演员的快速适应策略，这些策略在预训练BFM的低维任务嵌入空间中搜索，以快速提高其实现零样本策略在任何下游任务上的性能。值得注意的是，我们的方法减轻了在微调预训练RL模型时通常观察到的初始“遗忘”阶段。我们在四个最先进的零样本RL方法上多个导航和运动学域中评估了我们的快速适应策略。结果显示，它们在几轮测试内将零样本性能提高了10-40%，并优于现有基线。 

---
# SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning 

**Title (ZH)**: SpecReason: 快速准确的推理时计算通过推测推理 

**Authors**: Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali  

**Link**: [PDF](https://arxiv.org/pdf/2504.07891)  

**Abstract**: Recent advances in inference-time compute have significantly improved performance on complex tasks by generating long chains of thought (CoTs) using Large Reasoning Models (LRMs). However, this improved accuracy comes at the cost of high inference latency due to the length of generated reasoning sequences and the autoregressive nature of decoding. Our key insight in tackling these overheads is that LRM inference, and the reasoning that it embeds, is highly tolerant of approximations: complex tasks are typically broken down into simpler steps, each of which brings utility based on the semantic insight it provides for downstream steps rather than the exact tokens it generates. Accordingly, we introduce SpecReason, a system that automatically accelerates LRM inference by using a lightweight model to (speculatively) carry out simpler intermediate reasoning steps and reserving the costly base model only to assess (and potentially correct) the speculated outputs. Importantly, SpecReason's focus on exploiting the semantic flexibility of thinking tokens in preserving final-answer accuracy is complementary to prior speculation techniques, most notably speculative decoding, which demands token-level equivalence at each step. Across a variety of reasoning benchmarks, SpecReason achieves 1.5-2.5$\times$ speedup over vanilla LRM inference while improving accuracy by 1.0-9.9\%. Compared to speculative decoding without SpecReason, their combination yields an additional 19.4-44.2\% latency reduction. We open-source SpecReason at this https URL. 

**Abstract (ZH)**: Recent Advances in Inference-Time Compute: Accelerating Large Reasoning Model Inference with SpecReason 

---
# Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge 

**Title (ZH)**: 大规模语言模型中偏见诱致对抗鲁棒性的基准评估：基于LLM的可扩展自动化评估 

**Authors**: Riccardo Cantini, Alessio Orsino, Massimo Ruggiero, Domenico Talia  

**Link**: [PDF](https://arxiv.org/pdf/2504.07887)  

**Abstract**: Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised concerns about embedded biases, which can perpetuate stereotypes and compromise fairness. These biases stem from various sources, including historical inequalities in training data, linguistic imbalances, and adversarial manipulation. Despite mitigation efforts, recent studies indicate that LLMs remain vulnerable to adversarial attacks designed to elicit biased responses. This work proposes a scalable benchmarking framework to evaluate LLM robustness against adversarial bias elicitation. Our methodology involves (i) systematically probing models with a multi-task approach targeting biases across various sociocultural dimensions, (ii) quantifying robustness through safety scores using an LLM-as-a-Judge approach for automated assessment of model responses, and (iii) employing jailbreak techniques to investigate vulnerabilities in safety mechanisms. Our analysis examines prevalent biases in both small and large state-of-the-art models and their impact on model safety. Additionally, we assess the safety of domain-specific models fine-tuned for critical fields, such as medicine. Finally, we release a curated dataset of bias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability benchmarking. Our findings reveal critical trade-offs between model size and safety, aiding the development of fairer and more robust future language models. 

**Abstract (ZH)**: 大规模语言模型（LLMs）通过推动机器翻译、总结和对话代理的进步，彻底改变了人工智能。然而，它们在关键社会领域中的不断增加的整合引发了关于嵌入偏见的担忧，这些偏见可以 perpetuate 陈规定型观念并损害公平性。这些偏见源自多个来源，包括训练数据中的历史不平等、语言失衡以及敌对操纵。尽管采取了缓解措施，但近期研究表明，LLMs 仍有可能受到旨在引发偏见响应的敌对攻击。本研究提出了一种可扩展的基准测试框架，以评估LLMs在对抗偏见引诱方面的鲁棒性。我们的方法包括：（i）通过多任务方法系统地测试模型，针对各种社会文化维度的偏见；（ii）通过LLM作为法官的方法量化鲁棒性，自动评估模型响应的安全性得分；（iii）使用脱缰技术研究安全机制的脆弱性。我们的分析检查了小型和大型最新模型中的常见偏见及其对模型安全性的影响。此外，我们评估了针对关键领域（如医疗领域）微调的专业领域模型的安全性。最后，我们发布了与偏见相关的提示数据集CLEAR-Bias，以促进系统的漏洞基准测试。我们的研究结果揭示了模型规模与安全性之间的关键权衡，有助于开发更公平和更鲁棒的语言模型。 

---
# Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs 

**Title (ZH)**: Pangu Ultra： Dense 大型语言模型在 Ascend NPUs 上的极限挑战 

**Authors**: Yichun Yin, Wenyong Huang, Kaikai Song, Yehui Tang, Xueyu Wu, Wei Guo, Peng Guo, Yaoyuan Wang, Xiaojun Meng, Yasheng Wang, Dong Li, Can Chen, Dandan Tu, Yin Li, Fisher Yu, Ruiming Tang, Yunhe Wang, Baojun Wang, Bin Wang, Bo Wang, Boxiao Liu, Changzheng Zhang, Duyu Tang, Fei Mi, Hui Jin, Jiansheng Wei, Jiarui Qin, Jinpeng Li, Jun Zhao, Liqun Deng, Lin Li, Minghui Xu, Naifu Zhang, Nianzu Zheng, Qiang Li, Rongju Ruan, Shengjun Cheng, Tianyu Guo, Wei He, Wei Li, Weiwen Liu, Wulong Liu, Xinyi Dai, Yonghan Dong, Yu Pan, Yue Li, Yufei Wang, Yujun Li, Yunsheng Ni, Zhe Liu, Zhenhe Zhang, Zhicheng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2504.07866)  

**Abstract**: We present Pangu Ultra, a Large Language Model (LLM) with 135 billion parameters and dense Transformer modules trained on Ascend Neural Processing Units (NPUs). Although the field of LLM has been witnessing unprecedented advances in pushing the scale and capability of LLM in recent years, training such a large-scale model still involves significant optimization and system challenges. To stabilize the training process, we propose depth-scaled sandwich normalization, which effectively eliminates loss spikes during the training process of deep models. We pre-train our model on 13.2 trillion diverse and high-quality tokens and further enhance its reasoning capabilities during post-training. To perform such large-scale training efficiently, we utilize 8,192 Ascend NPUs with a series of system optimizations. Evaluations on multiple diverse benchmarks indicate that Pangu Ultra significantly advances the state-of-the-art capabilities of dense LLMs such as Llama 405B and Mistral Large 2, and even achieves competitive results with DeepSeek-R1, whose sparse model structure contains much more parameters. Our exploration demonstrates that Ascend NPUs are capable of efficiently and effectively training dense models with more than 100 billion parameters. Our model and system will be available for our commercial customers. 

**Abstract (ZH)**: Pangu Ultra: 一个基于昇腾神经处理器训练的1350亿参数密集型Transformer模型 

---
# Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive Approach to High-Fidelity Speech Synthesis 

**Title (ZH)**: 赋能全球之声：一种高效的数据、音素-音调自适应的高保真语音合成方法 

**Authors**: Yizhong Geng, Jizhuo Xu, Zeyu Liang, Jinghan Yang, Xiaoyi Shi, Xiaoyu Shen  

**Link**: [PDF](https://arxiv.org/pdf/2504.07858)  

**Abstract**: Text-to-speech (TTS) technology has achieved impressive results for widely spoken languages, yet many under-resourced languages remain challenged by limited data and linguistic complexities. In this paper, we present a novel methodology that integrates a data-optimized framework with an advanced acoustic model to build high-quality TTS systems for low-resource scenarios. We demonstrate the effectiveness of our approach using Thai as an illustrative case, where intricate phonetic rules and sparse resources are effectively addressed. Our method enables zero-shot voice cloning and improved performance across diverse client applications, ranging from finance to healthcare, education, and law. Extensive evaluations - both subjective and objective - confirm that our model meets state-of-the-art standards, offering a scalable solution for TTS production in data-limited settings, with significant implications for broader industry adoption and multilingual accessibility. 

**Abstract (ZH)**: 面向低资源语言的文本-to-语音技术：一种数据优化框架与高级声学模型的集成方法 

---
# The KL3M Data Project: Copyright-Clean Training Resources for Large Language Models 

**Title (ZH)**: KL3M数据项目：大型语言模型的版权清洁训练资源 

**Authors**: Michael J Bommarito II, Jillian Bommarito, Daniel Martin Katz  

**Link**: [PDF](https://arxiv.org/pdf/2504.07854)  

**Abstract**: Practically all large language models have been pre-trained on data that is subject to global uncertainty related to copyright infringement and breach of contract. This creates potential risk for users and developers due to this uncertain legal status. The KL3M Data Project directly confronts this critical issue by introducing the largest comprehensive training data pipeline that minimizes risks related to copyright or breach of contract. The foundation of this project is a corpus of over 132 million documents and trillions of tokens spanning 16 different sources that have been verified to meet the strict copyright and licensing protocol detailed herein. We are releasing the entire pipeline, including 1) the source code to acquire and process these documents, 2) the original document formats with associated provenance and metadata, 3) extracted content in a standardized format, 4) pre-tokenized representations of the documents, and 5) various mid- and post-train resources such as question-answer, summarization, conversion, drafting, classification, prediction, and conversational data. All of these resources are freely available to the public on S3, Hugging Face, and GitHub under CC-BY terms. We are committed to continuing this project in furtherance of a more ethical, legal, and sustainable approach to the development and use of AI models. 

**Abstract (ZH)**: 几乎所有大型语言模型都在具有全球性版权侵权和合同违约不确定性的问题数据上进行预训练。这为用户和开发者带来了潜在的法律风险。KL3M数据项目直接应对这一关键问题，引入了最大的综合性训练数据管道，以最小化与版权或合同违约相关的风险。该项目的基础是由13200多万份文件和数十万亿个标记组成的语料库，这些文件来自16个不同来源，已验证符合本文件中详细说明的严格版权和许可协议。我们正在公开整个管道，包括：1）获取和处理这些文件的源代码；2）原始文档格式及其相关来源和元数据；3）标准化格式的提取内容；4）文档的预标记表示；以及5）各种中间和后期训练资源，如问答、总结、转换、起草、分类、预测和对话数据。所有这些资源均在CC-BY许可下在S3、Hugging Face和GitHub上向公众开放。我们致力于继续该项目，以推动AI模型开发和使用更为伦理、合法和可持续的方法。 

---
# Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines 

**Title (ZH)**: 理解学习者与大语言模型聊天机器人交互及其提示指南影响 

**Authors**: Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene  

**Link**: [PDF](https://arxiv.org/pdf/2504.07840)  

**Abstract**: Large Language Models (LLMs) have transformed human-computer interaction by enabling natural language-based communication with AI-powered chatbots. These models are designed to be intuitive and user-friendly, allowing users to articulate requests with minimal effort. However, despite their accessibility, studies reveal that users often struggle with effective prompting, resulting in inefficient responses. Existing research has highlighted both the limitations of LLMs in interpreting vague or poorly structured prompts and the difficulties users face in crafting precise queries. This study investigates learner-AI interactions through an educational experiment in which participants receive structured guidance on effective prompting. We introduce and compare three types of prompting guidelines: a task-specific framework developed through a structured methodology and two baseline approaches. To assess user behavior and prompting efficacy, we analyze a dataset of 642 interactions from 107 users. Using Von NeuMidas, an extended pragmatic annotation schema for LLM interaction analysis, we categorize common prompting errors and identify recurring behavioral patterns. We then evaluate the impact of different guidelines by examining changes in user behavior, adherence to prompting strategies, and the overall quality of AI-generated responses. Our findings provide a deeper understanding of how users engage with LLMs and the role of structured prompting guidance in enhancing AI-assisted communication. By comparing different instructional frameworks, we offer insights into more effective approaches for improving user competency in AI interactions, with implications for AI literacy, chatbot usability, and the design of more responsive AI systems. 

**Abstract (ZH)**: 大型语言模型（LLMs）通过启用基于自然语言与AI聊天机器人的通信，已改变了人机交互方式。这些模型设计得直观且用户友好，使用户能够以最小的努力表达请求。然而，尽管其易于访问，研究显示用户在有效提示方面仍常遇到困难，导致效率低下。现有研究强调了LLMs在解释含糊或结构不良的提示方面的局限性，以及用户在构建精确查询方面面临的困难。本研究通过一项教育实验调查学习者与AI的交互，参与者接受有效的提示结构化指导。我们引入并比较了三种提示指南类型：通过结构化方法开发的任务特定框架以及两种基线方法。为了评估用户行为和提示的有效性，我们分析了来自107名用户共642次交互的数据集。利用扩展后的Von NeuMidas注释框架对LLM交互进行分析，我们分类常见的提示错误，并识别反复出现的行为模式。然后，通过评估不同指南的影响来检查用户行为的变化、提示策略的遵守情况以及AI生成响应的总体质量。我们的发现提供了对用户如何与LLMs互动以及结构化提示指导在增强AI辅助通信中的作用的更深层次理解。通过比较不同的指导框架，我们提供了提高用户在AI互动中能力的有效方法的洞见，这对人工智能素养、聊天机器人的可用性以及设计更具反应性的AI系统具有重要意义。 

---
# Deep Learning-based Intrusion Detection Systems: A Survey 

**Title (ZH)**: 基于深度学习的入侵检测系统：一个综述 

**Authors**: Zhiwei Xu, Yujuan Wu, Shiheng Wang, Jiabao Gao, Tian Qiu, Ziqi Wang, Hai Wan, Xibin Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2504.07839)  

**Abstract**: Intrusion Detection Systems (IDS) have long been a hot topic in the cybersecurity community. In recent years, with the introduction of deep learning (DL) techniques, IDS have made great progress due to their increasing generalizability. The rationale behind this is that by learning the underlying patterns of known system behaviors, IDS detection can be generalized to intrusions that exploit zero-day vulnerabilities. In this survey, we refer to this type of IDS as DL-based IDS (DL-IDS). From the perspective of DL, this survey systematically reviews all the stages of DL-IDS, including data collection, log storage, log parsing, graph summarization, attack detection, and attack investigation. To accommodate current researchers, a section describing the publicly available benchmark datasets is included. This survey further discusses current challenges and potential future research directions, aiming to help researchers understand the basic ideas and visions of DL-IDS research, as well as to motivate their research interests. 

**Abstract (ZH)**: 深度学习（DL）驱动的入侵检测系统（DL-IDS）综述 

---
# AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations 

**Title (ZH)**: AerialVG: 通过探索位置关系的无人机视觉定位挑战基准 

**Authors**: Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Xuelong Li, Bin Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2504.07836)  

**Abstract**: Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, \emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released. 

**Abstract (ZH)**: 基于无人机视角的视觉定位（AerialVG）：一个新的研究任务 

---
# MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations 

**Title (ZH)**: MOSAIC: 建模社会AI以实现多 Agents 模拟中的内容传播与调控 

**Authors**: Genglin Liu, Salman Rahman, Elisa Kreiss, Marzyeh Ghassemi, Saadia Gabriel  

**Link**: [PDF](https://arxiv.org/pdf/2504.07830)  

**Abstract**: We present a novel, open-source social network simulation framework, MOSAIC, where generative language agents predict user behaviors such as liking, sharing, and flagging content. This simulation combines LLM agents with a directed social graph to analyze emergent deception behaviors and gain a better understanding of how users determine the veracity of online social content. By constructing user representations from diverse fine-grained personas, our system enables multi-agent simulations that model content dissemination and engagement dynamics at scale. Within this framework, we evaluate three different content moderation strategies with simulated misinformation dissemination, and we find that they not only mitigate the spread of non-factual content but also increase user engagement. In addition, we analyze the trajectories of popular content in our simulations, and explore whether simulation agents' articulated reasoning for their social interactions truly aligns with their collective engagement patterns. We open-source our simulation software to encourage further research within AI and social sciences. 

**Abstract (ZH)**: 我们提出了一种新颖的开源社交媒体网络仿真框架MOSAIC，其中生成型语言代理预测用户行为，如点赞、分享和标记内容。此仿真结合了LLM代理和有向社会图，以分析新兴的欺骗行为，更好地理解用户如何确定在线社交内容的真实性。通过从多样化的细粒度人设构建用户表示，我们的系统能够进行大规模的多代理仿真，模拟内容传播和互动动态。在这种框架内，我们使用模拟的错误信息传播评估了三种不同的内容审核策略，并发现这些策略不仅能减少非事实内容的传播，还能增加用户参与度。此外，我们分析了仿真中流行内容的轨迹，并探索仿真代理在社会互动中表达的理说明确性是否与它们的整体参与模式相一致。我们开源了我们的仿真软件，以促进AI和社会科学领域的进一步研究。 

---
# DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting 

**Title (ZH)**: DG-STMTL：一种新型图卷积网络用于多任务空间-时间交通预测 

**Authors**: Wanna Cui, Peizheng Wang, Faliang Yin  

**Link**: [PDF](https://arxiv.org/pdf/2504.07822)  

**Abstract**: Spatio-temporal traffic prediction is crucial in intelligent transportation systems. The key challenge of accurate prediction is how to model the complex spatio-temporal dependencies and adapt to the inherent dynamics in data. Traditional Graph Convolutional Networks (GCNs) often struggle with static adjacency matrices that introduce domain bias or learnable matrices that may be overfitting to specific patterns. This challenge becomes more complex when considering Multi-Task Learning (MTL). While MTL has the potential to enhance prediction accuracy through task synergies, it can also face significant hurdles due to task interference. To overcome these challenges, this study introduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task Learning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation module that combines static matrices with dynamic ones through a task-specific gating mechanism. We also introduce a group-wise GCN module to enhance the modelling capability of spatio-temporal dependencies. We conduct extensive experiments on two real-world datasets to evaluate our method. Results show that our method outperforms other state-of-the-arts, indicating its effectiveness and robustness. 

**Abstract (ZH)**: 时空交通预测在智能交通系统中至关重要。准确预测的关键挑战是如何建模复杂的时空依赖关系并适应数据中的固有动态。传统的图卷积网络（GCNs）往往难以处理静态的邻接矩阵（引入领域偏差）或可学习的矩阵（可能过度拟合特定模式）。在考虑多任务学习（MTL）时，这一挑战变得更加复杂。尽管MTL有潜力通过任务协同效应提升预测准确性，但也可能因任务干扰而面临重大障碍。为克服这些挑战，本研究引入了一种新的MTL框架，动态组别时空多任务学习（DG-STMTL）。DG-STMTL提出了一种结合静态矩阵和动态矩阵的混合邻接矩阵生成模块，通过任务特定的门控机制实现。我们还引入了组别GCN模块以增强时空依赖关系的建模能力。我们在两个真实世界数据集上进行了广泛的实验以评估我们的方法。实验结果表明，我们的方法优于其他最先进的方法，证明了其有效性和 robustness。 

---
# A System for Comprehensive Assessment of RAG Frameworks 

**Title (ZH)**: 综合评估RAG框架的系统 

**Authors**: Mattia Rengo, Senad Beadini, Domenico Alfano, Roberto Abbruzzese  

**Link**: [PDF](https://arxiv.org/pdf/2504.07803)  

**Abstract**: Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for enhancing the factual accuracy and contextual relevance of Large Language Models (LLMs) by integrating retrieval mechanisms. However, existing evaluation frameworks fail to provide a holistic black-box approach to assessing RAG systems, especially in real-world deployment scenarios. To address this gap, we introduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a modular and flexible evaluation framework designed to benchmark deployed RAG applications systematically. SCARF provides an end-to-end, black-box evaluation methodology, enabling a limited-effort comparison across diverse RAG frameworks. Our framework supports multiple deployment configurations and facilitates automated testing across vector databases and LLM serving strategies, producing a detailed performance report. Moreover, SCARF integrates practical considerations such as response coherence, providing a scalable and adaptable solution for researchers and industry professionals evaluating RAG applications. Using the REST APIs interface, we demonstrate how SCARF can be applied to real-world scenarios, showcasing its flexibility in assessing different RAG frameworks and configurations. SCARF is available at GitHub repository. 

**Abstract (ZH)**: 全面评估RAG框架的SCARF系统 

---
# FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness 

**Title (ZH)**: FairEval: 基于人格意识评估LLM驱动推荐系统的公平性 

**Authors**: Chandan Kumar Sah, Xiaoli Lian, Tony Xu, Li Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07801)  

**Abstract**: Recent advances in Large Language Models (LLMs) have enabled their application to recommender systems (RecLLMs), yet concerns remain regarding fairness across demographic and psychological user dimensions. We introduce FairEval, a novel evaluation framework to systematically assess fairness in LLM-based recommendations. FairEval integrates personality traits with eight sensitive demographic attributes,including gender, race, and age, enabling a comprehensive assessment of user-level bias. We evaluate models, including ChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's fairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997 for Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results highlight the importance of robustness in prompt sensitivity and support more inclusive recommendation systems. 

**Abstract (ZH)**: Recent Advances in Large Language Models (LLMs) Have Enabled Their Application to Recommender Systems (RecLLMs), Yet Concerns Remain Regarding Fairness Across Demographic and Psychological User Dimensions: Introducing FairEval, a Novel Evaluation Framework to Systematically Assess Fairness in LLM-Based Recommendations 

---
# SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow 

**Title (ZH)**: SlimSpeech: 轻量高效文本转语音方法及其应用Slim Rectified Flow 

**Authors**: Kaidi Wang, Wenhao Guan, Shenghui Lu, Jianglong Yao, Lin Li, Qingyang Hong  

**Link**: [PDF](https://arxiv.org/pdf/2504.07776)  

**Abstract**: Recently, flow matching based speech synthesis has significantly enhanced the quality of synthesized speech while reducing the number of inference steps. In this paper, we introduce SlimSpeech, a lightweight and efficient speech synthesis system based on rectified flow. We have built upon the existing speech synthesis method utilizing the rectified flow model, modifying its structure to reduce parameters and serve as a teacher model. By refining the reflow operation, we directly derive a smaller model with a more straight sampling trajectory from the larger model, while utilizing distillation techniques to further enhance the model performance. Experimental results demonstrate that our proposed method, with significantly reduced model parameters, achieves comparable performance to larger models through one-step sampling. 

**Abstract (ZH)**: 基于矫正流的SlimSpeech轻量高效语音合成系统 

---
# Data over dialogue: Why artificial intelligence is unlikely to humanise medicine 

**Title (ZH)**: 数据胜过对话：人工智能 unlikely 使其人性化为何 

**Authors**: Joshua Hatherley  

**Link**: [PDF](https://arxiv.org/pdf/2504.07763)  

**Abstract**: Recently, a growing number of experts in artificial intelligence (AI) and medicine have be-gun to suggest that the use of AI systems, particularly machine learning (ML) systems, is likely to humanise the practice of medicine by substantially improving the quality of clinician-patient relationships. In this thesis, however, I argue that medical ML systems are more likely to negatively impact these relationships than to improve them. In particular, I argue that the use of medical ML systems is likely to comprise the quality of trust, care, empathy, understanding, and communication between clinicians and patients. 

**Abstract (ZH)**: 然而，我在这项研究中 argue 机器学习系统更有可能负向影响医患关系而非改善它们。特别是，我 argument 机器学习系统的使用很可能损害医患之间信任、关怀、共情、理解与沟通的质量。 

---
# Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection 

**Title (ZH)**: 探索基于Patch的隐私保护伪造身份证检测方法 

**Authors**: Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez  

**Link**: [PDF](https://arxiv.org/pdf/2504.07761)  

**Abstract**: In an increasingly digitalized world, verifying the authenticity of ID documents has become a critical challenge for real-life applications such as digital banking, crypto-exchanges, renting, etc. This study focuses on the topic of fake ID detection, covering several limitations in the field. In particular, no publicly available data from real ID documents exists, and most studies rely on proprietary in-house databases that are not available due to privacy reasons. In order to shed some light on this critical challenge that makes difficult to advance in the field, we explore a trade-off between privacy (i.e., amount of sensitive data available) and performance, proposing a novel patch-wise approach for privacy-preserving fake ID detection. Our proposed approach explores how privacy can be enhanced through: i) two levels of anonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii) different patch size configurations, varying the amount of sensitive data visible in the patch image. Also, state-of-the-art methods such as Vision Transformers and Foundation Models are considered in the analysis. The experimental framework shows that, on an unseen database (DLC-2021), our proposal achieves 13.91% and 0% EERs at patch and ID document level, showing a good generalization to other databases. In addition to this exploration, another key contribution of our study is the release of the first publicly available database that contains 48,400 patches from both real and fake ID documents, along with the experimental framework and models, which will be available in our GitHub. 

**Abstract (ZH)**: 在日益数字化的世界中，验证身份文档的真实性已成为数字银行、加密交易、租赁等实际应用中的关键挑战。本文专注于假身份文档检测这一主题，涵盖了该领域的一些局限性。特别是，目前没有公开的真实身份文档数据集，大多数研究依赖于隐私原因无法公开的内部专用数据库。为了缓解这一关键挑战，我们探讨了隐私（即敏感数据量）与性能之间的权衡，提出了一种新颖的块级方法，用于保护隐私的假身份文档检测。我们提出的方法探索了通过以下方式增强隐私：i) 身份文档的两级匿名化（完全匿名和部分匿名），ii) 不同大小的块配置，改变可见敏感数据的量。此外，本文分析了如视觉变换器和基础模型等最新方法。实验框架显示，在一个未知数据集（DLC-2021）上，我们的提议在块级和身份文档级分别实现了13.91%和0%的EER，展示了良好的泛化能力。此外，本文的另一重要贡献是发布了首个包含48,400个来自真实和虚假身份文档的块的数据集，以及实验框架和模型，这些资料将在我们的GitHub上公开。 

---
# NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark 

**Title (ZH)**: NorEval: 一項挪威語理解與生成評價基准 

**Authors**: Vladislav Mikhailov, Tita Enstad, David Samuel, Hans Christian Farsethås, Andrey Kutuzov, Erik Velldal, Lilja Øvrelid  

**Link**: [PDF](https://arxiv.org/pdf/2504.07749)  

**Abstract**: This paper introduces NorEval, a new and comprehensive evaluation suite for large-scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets -- of which five are created from scratch. In contrast to existing benchmarks for Norwegian, NorEval covers a broad spectrum of task categories targeting Norwegian language understanding and generation, establishes human baselines, and focuses on both of the official written standards of the Norwegian language: Bokmål and Nynorsk. All our datasets and a collection of over 100 human-written prompts are integrated into LM Evaluation Harness, ensuring flexible and reproducible evaluation. We describe the NorEval design and present the results of benchmarking 19 open-source pre-trained and instruction-tuned LMs for Norwegian in various scenarios. Our benchmark, evaluation framework, and annotation materials are publicly available. 

**Abstract (ZH)**: NorEval：一种新的全面的挪威生成语言模型大规模标准化基准评估套件 

---
# SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding 

**Title (ZH)**: SF2T: 自监督视频LLMs的片段微调以实现细粒度理解 

**Authors**: Yangliu Hu, Zikai Song, Na Feng, Yawei Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07745)  

**Abstract**: Video-based Large Language Models (Video-LLMs) have witnessed substantial advancements in recent years, propelled by the advancement in multi-modal LLMs. Although these models have demonstrated proficiency in providing the overall description of videos, they struggle with fine-grained understanding, particularly in aspects such as visual dynamics and video details inquiries. To tackle these shortcomings, we find that fine-tuning Video-LLMs on self-supervised fragment tasks, greatly improve their fine-grained video understanding abilities. Hence we propose two key contributions:(1) Self-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning method, employs the rich inherent characteristics of videos for training, while unlocking more fine-grained understanding ability of Video-LLMs. Moreover, it relieves researchers from labor-intensive annotations and smartly circumvents the limitations of natural language, which often fails to capture the complex spatiotemporal variations in videos; (2) A novel benchmark dataset, namely FineVidBench, for rigorously assessing Video-LLMs' performance at both the scene and fragment levels, offering a comprehensive evaluation of their capabilities. We assessed multiple models and validated the effectiveness of SF$^2$T on them. Experimental results reveal that our approach improves their ability to capture and interpret spatiotemporal details. 

**Abstract (ZH)**: 基于视频的大型语言模型（Video-LLMs）在近年来取得了显著进展，得益于多模态LLMs的发展。尽管这些模型在提供视频的整体描述方面表现出色，但在视觉动态和视频细节查询等方面仍存在细致理解的不足。为解决这些问题，我们发现对Video-LLMs进行自我监督片段微调（SF$^2$T）能够显著提高其细致的视频理解能力。因此，我们提出了两项关键贡献：（1）自我监督片段微调（SF$^2$T），这是一种新颖的简便微调方法，利用视频的丰富固有特性进行训练，同时增强Video-LLMs的细致理解能力，同时缓解了劳动密集型标注问题，并巧妙地规避了自然语言在捕捉视频复杂的空间时间变化方面的局限性；（2）一种新的基准数据集FineVidBench，用于严格评估Video-LLMs在场景和片段层面的性能，提供对其能力的全面评估。我们评估了多个模型并验证了SF$^2$T的有效性。实验结果表明，我们的方法提高了其捕捉和解释空间时间细节的能力。 

---
# Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric T1-weighted Abdominal MRI 

**Title (ZH)**: 多参数T1加权腹部MRI多器官分割工具基准测试 

**Authors**: Nicole Tran, Anisa Prasad, Yan Zhuang, Tejas Sudharshan Mathai, Boah Kim, Sydney Lewis, Pritam Mukherjee, Jianfei Liu, Ronald M. Summers  

**Link**: [PDF](https://arxiv.org/pdf/2504.07729)  

**Abstract**: The segmentation of multiple organs in multi-parametric MRI studies is critical for many applications in radiology, such as correlating imaging biomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three publicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI (TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ segmentation in MRI. However, the performance of these tools on specific MRI sequence types has not yet been quantified. In this work, a subset of 40 volumes from the public Duke Liver Dataset was curated. The curated dataset contained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w, venous T1w, and delayed T1w phases, respectively. Ten abdominal structures were manually annotated in these volumes. Next, the performance of the three public tools was benchmarked on this curated dataset. The results indicated that MRSeg obtained a Dice score of 80.7 $\pm$ 18.6 and Hausdorff Distance (HD) error of 8.9 $\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence types in contrast to TS and VIBE. 

**Abstract (ZH)**: 多参数MRI研究中多个器官的分割对于放射学中的许多应用至关重要，例如将影像生物标志物与疾病状态（如肝硬化、糖尿病）相关联。近期提出了三种公开可用的工具，如MRSegmentator (MRSeg)、TotalSegmentator MRI (TS) 和TotalVibeSegmentator (VIBE)，以进行MRI中的多器官分割。然而，这些工具在特定MRI序列类型上的性能尚未量化。在这项工作中，选用了公共Duke Liver Dataset中的40个体积作为子集。该数据集包含分别来自预对比脂肪饱和T1、动脉T1w、静脉T1w和延迟T1w相位的10个体积，并在这些体积中手动标注了10个腹腔结构。随后，这三种公开工具在该制定的数据集上的性能进行了基准测试。结果显示，MRSeg的Dice分数为80.7 $\pm$ 18.6，Hausdorff距离误差为8.9 $\pm$ 10.4 mm，并且在不同序列类型中表现最佳（$p < .05$），优于TS和VIBE。 

---
# Counting Hours, Counting Losses: The Toll of Unpredictable Work Schedules on Financial Security 

**Title (ZH)**: 计时又计失：不可预测工作时间表对财务安全的代价 

**Authors**: Pegah Nokhiz, Aravinda Kanchana Ruwanpathirana, Aditya Bhaskara, Suresh Venkatasubramanian  

**Link**: [PDF](https://arxiv.org/pdf/2504.07719)  

**Abstract**: Financial instability has become a significant issue in today's society. While research typically focuses on financial aspects, there is a tendency to overlook time-related aspects of unstable work schedules. The inability to rely on consistent work schedules leads to burnout, work-family conflicts, and financial shocks that directly impact workers' income and assets. Unforeseen fluctuations in earnings pose challenges in financial planning, affecting decisions on savings and spending and ultimately undermining individuals' long-term financial stability and well-being.
This issue is particularly evident in sectors where workers experience frequently changing schedules without sufficient notice, including those in the food service and retail sectors, part-time and hourly workers, and individuals with lower incomes. These groups are already more financially vulnerable, and the unpredictable nature of their schedules exacerbates their financial fragility.
Our objective is to understand how unforeseen fluctuations in earnings exacerbate financial fragility by investigating the extent to which individuals' financial management depends on their ability to anticipate and plan for the future. To address this question, we develop a simulation framework that models how individuals optimize utility amidst financial uncertainty and the imperative to avoid financial ruin. We employ online learning techniques, specifically adapting workers' consumption policies based on evolving information about their work schedules.
With this framework, we show both theoretically and empirically how a worker's capacity to anticipate schedule changes enhances their long-term utility. Conversely, the inability to predict future events can worsen workers' instability. Moreover, our framework enables us to explore interventions to mitigate the problem of schedule uncertainty and evaluate their effectiveness. 

**Abstract (ZH)**: 金融不稳定已成为当今社会的一个重要问题。虽然研究通常关注金融方面，但往往忽视了不稳定工作时间安排的时间相关性。无法依赖于稳定的工作时间安排导致了职业倦怠、工作与家庭冲突以及直接影响工人收入和资产的财务冲击。不可预见的收入波动对财务规划构成了挑战，影响了储蓄和支出的决策，最终威胁了个人的长期财务稳定和福祉。 

---
# PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization 

**Title (ZH)**: PR-攻击：通过对大型语言模型中检索增强生成的协调提示-RAG攻击 via 双层优化 

**Authors**: Yang Jiao, Xiaodong Wang, Kai Yang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07717)  

**Abstract**: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods. 

**Abstract (ZH)**: 大型语言模型（LLMs）在医疗问答、数学科学和代码生成等广泛应用中展现了卓越的性能。然而，它们也存在固有的局限性，如知识过时和幻觉倾向。检索增强生成（RAG）作为一种潜在的解决方法已经出现，但它也引入了新的脆弱性。最近的研究重点集中在RAG基于的LLMs的安全性上，但现有的攻击方法面临三个关键挑战：（1）当只能注入有限数量的恶意文本到知识数据库中时，它们的有效性急剧下降；（2）它们缺乏足够的隐蔽性，因为攻击常常会被异常检测系统检测到，从而损害了其有效性；（3）它们依赖于启发式方法生成恶意文本，缺乏形式化的优化框架和理论保证，这限制了其有效性和适用性。为解决这些问题，我们提出了一种协调的提示-RAG攻击（PR-attack），这是一种基于优化的攻击方法，能够在知识数据库中注入少量的恶意文本的同时，在提示中嵌入后门触发器。当触发器被激活时，会导致LLM在针对性查询中生成预设的响应，而在其他上下文中保持正常行为。这确保了高度的有效性和隐蔽性。我们将攻击生成过程表述为一个分层优化问题，并利用一个原则性优化框架来开发最优的恶意文本和触发器。在不同LLMs和数据集上的广泛实验表明，PR-攻击方法具有很高的攻击成功率，即使只有有限数量的恶意文本也能实现，并且其隐蔽性比现有方法有了显著提高。 

---
# Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams 

**Title (ZH)**: 嵌入主题与最优传输在数据流的在线主题建模中的融合 

**Authors**: Federica Granese, Benjamin Navet, Serena Villata, Charles Bouveyron  

**Link**: [PDF](https://arxiv.org/pdf/2504.07711)  

**Abstract**: Topic modeling is a key component in unsupervised learning, employed to identify topics within a corpus of textual data. The rapid growth of social media generates an ever-growing volume of textual data daily, making online topic modeling methods essential for managing these data streams that continuously arrive over time. This paper introduces a novel approach to online topic modeling named StreamETM. This approach builds on the Embedded Topic Model (ETM) to handle data streams by merging models learned on consecutive partial document batches using unbalanced optimal transport. Additionally, an online change point detection algorithm is employed to identify shifts in topics over time, enabling the identification of significant changes in the dynamics of text streams. Numerical experiments on simulated and real-world data show StreamETM outperforming competitors. 

**Abstract (ZH)**: 基于嵌入式主题模型的流式在线主题建模方法StreamETM 

---
# ms-Mamba: Multi-scale Mamba for Time-Series Forecasting 

**Title (ZH)**: ms-Mamba: 多尺度Mamba时间序列预测 

**Authors**: Yusuf Meric Karadag, Sinan Kalkan, Ipek Gursel Dino  

**Link**: [PDF](https://arxiv.org/pdf/2504.07654)  

**Abstract**: The problem of Time-series Forecasting is generally addressed by recurrent, Transformer-based and the recently proposed Mamba-based architectures. However, existing architectures generally process their input at a single temporal scale, which may be sub-optimal for many tasks where information changes over multiple time scales. In this paper, we introduce a novel architecture called Multi-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates multiple temporal scales by using multiple Mamba blocks with different sampling rates ($\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba outperforms state-of-the-art approaches, including the recently proposed Transformer-based and Mamba-based models. 

**Abstract (ZH)**: 多尺度Mamba（ms-Mamba）架构的时间序列预测 

---
# On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data 

**Title (ZH)**: 大型语言模型在匿名化数据上的时间问答能力 

**Authors**: Alfredo Garrachón Ruiz, Tomás de la Rosa, Daniel Borrajo  

**Link**: [PDF](https://arxiv.org/pdf/2504.07646)  

**Abstract**: The applicability of Large Language Models (LLMs) in temporal reasoning tasks over data that is not present during training is still a field that remains to be explored. In this paper we work on this topic, focusing on structured and semi-structured anonymized data. We not only develop a direct LLM pipeline, but also compare various methodologies and conduct an in-depth analysis. We identified and examined seventeen common temporal reasoning tasks in natural language, focusing on their algorithmic components. To assess LLM performance, we created the \textit{Reasoning and Answering Temporal Ability} dataset (RATA), featuring semi-structured anonymized data to ensure reliance on reasoning rather than on prior knowledge. We compared several methodologies, involving SoTA techniques such as Tree-of-Thought, self-reflexion and code execution, tuned specifically for this scenario. Our results suggest that achieving scalable and reliable solutions requires more than just standalone LLMs, highlighting the need for integrated approaches. 

**Abstract (ZH)**: 大型语言模型在训练数据之外的时间推理任务中的适用性仍是一个待探索的领域。本文专注于此主题，重点研究结构化和半结构化匿名数据。我们不仅开发了一条直接的大型语言模型管道，还比较了多种方法并进行了深入分析。我们识别并研究了自然语言中十七种常见的时间推理任务，专注于它们的算法组件。为了评估大型语言模型的性能，我们创建了“时间推理与回答能力”数据集（RATA），该数据集包含半结构化匿名数据，以确保依赖推理而非先验知识。我们比较了几种方法，涉及当前最佳技术如思维树、自我反思和代码执行，这些技术是专门为这种场景调整的。我们的结果表明，实现可扩展和可靠解决方案不仅仅依赖单独的大型语言模型，强调了集成方法的需求。 

---
# Predicting the Lifespan of Industrial Printheads with Survival Analysis 

**Title (ZH)**: 基于生存分析的工业打印头寿命预测 

**Authors**: Dan Parii, Evelyne Janssen, Guangzhi Tang, Charalampos Kouzinopoulos, Marcin Pietrasik  

**Link**: [PDF](https://arxiv.org/pdf/2504.07638)  

**Abstract**: Accurately predicting the lifespan of critical device components is essential for maintenance planning and production optimization, making it a topic of significant interest in both academia and industry. In this work, we investigate the use of survival analysis for predicting the lifespan of production printheads developed by Canon Production Printing. Specifically, we focus on the application of five techniques to estimate survival probabilities and failure rates: the Kaplan-Meier estimator, Cox proportional hazard model, Weibull accelerated failure time model, random survival forest, and gradient boosting. The resulting estimates are further refined using isotonic regression and subsequently aggregated to determine the expected number of failures. The predictions are then validated against real-world ground truth data across multiple time windows to assess model reliability. Our quantitative evaluation using three performance metrics demonstrates that survival analysis outperforms industry-standard baseline methods for printhead lifespan prediction. 

**Abstract (ZH)**: 准确预测关键设备组件的寿命对于维护规划和生产优化至关重要，这一主题在学术界和工业界均备受关注。在本工作中，我们调查了生存分析在预测佳能生产打印部门开发的生产喷墨头寿命中的应用。具体而言，我们重点研究了五种技术以估计生存概率和失效率：Kaplan-Meier估计器、Cox比例风险模型、Weibull加速失效时间模型、随机生存森林和梯度提升。最终，我们使用isotonic回归进一步细化这些估计值，并将它们汇总以确定预期的失败次数。然后，我们将这些预测结果与多个时间窗口的真实世界数据进行验证，以评估模型的可靠性。我们的定量评估表明，生存分析在喷墨头寿命预测中优于工业标准基线方法。 

---
# Deep Learning Meets Teleconnections: Improving S2S Predictions for European Winter Weather 

**Title (ZH)**: 深度学习与遥相关相结合：提高欧洲冬季天气的季节内预测Accuracy 

**Authors**: Philine L. Bommer, Marlene Kretschmer, Fiona R. Spuler, Kirill Bykov, Marina M.-C. Höhne  

**Link**: [PDF](https://arxiv.org/pdf/2504.07625)  

**Abstract**: Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two weeks to two month--are crucial for early warning systems but remain challenging owing to chaos in the climate system. Teleconnections, such as the stratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer windows of enhanced predictability, however, their complex interactions remain underutilized in operational forecasting. Here, we developed and evaluated deep learning architectures to predict North Atlantic-European (NAE) weather regimes, systematically assessing the role of remote drivers in improving S2S forecast skill of deep learning models. We implemented (1) a Long Short-term Memory (LSTM) network predicting the NAE regimes of the next six weeks based on previous regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3) a ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and tropical outgoing longwave radiation fields. These models are compared with operational hindcasts as well as other AI models. Our results show that leveraging teleconnection information enhances skill at longer lead times. Notably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4 by improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions. Analysis of high-confidence predictions reveals that NAO-, SB, and AR opportunity forecasts can be associated with SPV variability and MJO phase patterns aligning with established pathways, also indicating new patterns. Overall, our work demonstrates that encoding physically meaningful climate fields can enhance S2S prediction skill, advancing AI-driven subseasonal forecast. Moreover, the experiments highlight the potential of deep learning methods as investigative tools, providing new insights into atmospheric dynamics and predictability. 

**Abstract (ZH)**: 预测亚季尺度（S2S）范围（两周至两个月）的天气模式对于早期预警系统至关重要，但由于气候系统的混沌性，这仍然具有挑战性。通过 trop 联系，如平流层极地漩涡（SPV）和马德森-朱利亚振荡（MJO），可以提供增强可预测性的窗口，然而，它们复杂的交互仍然未被操作性预报充分利用。在这里，我们开发并评估了深度学习架构以预测北大西洋-欧洲（NAE）天气模式，系统性地评估了远程驱动因素在提高深度学习模型亚季尺度预报技巧中的作用。我们实施了（1）基于前序模式预测未来六周NAE模式的长短期记忆（LSTM）网络，（2）结合SPV和MJO指数的索引-LSTM，以及（3）使用视觉变换器直接编码平流层风和热带红外辐射场的ViT-LSTM。这些模型与操作性回算以及其它AI模型进行了比较。结果表明，利用trop 联系信息可以提高长时间提前量的预报技巧。值得注意的是，ViT-LSTM 在第四周之后优于 ECMWF 的亚季回算，并改善了斯堪的纳维亚阻塞（SB）和大西洋脊（AR）的预测。高置信度预测分析表明，NAO-、SB 和 AR 机会预测与 SPV 变异性和 MJO 相位模式相吻合，也表明了新的模式。总体而言，我们的研究证明将物理上有意义的气候场编码可以提高亚季尺度预测技巧，促进AI驱动的亚季预报的发展。此外，实验强调了深度学习方法作为研究工具的潜力，为大气动力学和可预报性提供了新的见解。 

---
# ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in Large Language Models 

**Title (ZH)**: ConceptFormer: 向量利用知识图嵌入以提升大型语言模型的效率 

**Authors**: Joel Barmettler, Abraham Bernstein, Luca Rossetto  

**Link**: [PDF](https://arxiv.org/pdf/2504.07624)  

**Abstract**: Retrieval Augmented Generation (RAG) has enjoyed increased attention in the recent past and recent advancements in Large Language Models (LLMs) have highlighted the importance of integrating world knowledge into these systems. Current RAG methodologies often modify the internal architecture of pre-trained language models (PLMs) or rely on textifying knowledge graphs (KGs), which is inefficient in terms of token usage. This paper introduces ConceptFormer, a new approach to augment LLMs with structured knowledge from KGs, such as Wikidata, without altering their internal structure or relying on textual input of KGs. ConceptFormer operates in the LLM embedding vector space, creating and injecting \emph{concept vectors} that encapsulate the information of the KG nodes directly. Trained in conjunction with a frozen LLM, ConceptFormer generates a comprehensive lookup table that maps KG nodes to their respective concept vectors. The approach aims to enhance the factual recall capabilities of LLMs by enabling them to process these concept vectors natively, thus enriching them with structured world knowledge in an efficient and scalable manner. Our experiments demonstrate that the addition of concept vectors to GPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to 272\% when tested on sentences from Wikipedia and up to 348\% on synthetically generated sentences. Even injecting only a single concept vector into the prompt increases factual recall ability (Hit@10) by up to 213\% on Wikipedia sentences, significantly outperforming RAG with graph textification while consuming 130x fewer input tokens. 

**Abstract (ZH)**: 概念增强生成（ConceptFormer）：无需修改内部结构的大型语言模型知识增强方法 

---
# RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception in Adverse Conditions 

**Title (ZH)**: RASMD: RGB和SWIR多光谱驾驶数据集在恶劣条件下的稳健感知 

**Authors**: Youngwan Jin, Michal Kovac, Yagiz Nalcakan, Hyeongjin Ju, Hanbin Song, Sanghyeop Yeo, Shiho Kim  

**Link**: [PDF](https://arxiv.org/pdf/2504.07603)  

**Abstract**: Current autonomous driving algorithms heavily rely on the visible spectrum, which is prone to performance degradation in adverse conditions like fog, rain, snow, glare, and high contrast. Although other spectral bands like near-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception in such situations, they have limitations and lack large-scale datasets and benchmarks. Short-wave infrared (SWIR) imaging offers several advantages over NIR and LWIR. However, no publicly available large-scale datasets currently incorporate SWIR data for autonomous driving. To address this gap, we introduce the RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000 synchronized and spatially aligned RGB-SWIR image pairs collected across diverse locations, lighting, and weather conditions. In addition, we provide a subset for RGB-SWIR translation and object detection annotations for a subset of challenging traffic scenarios to demonstrate the utility of SWIR imaging through experiments on both object detection and RGB-to-SWIR image translation. Our experiments show that combining RGB and SWIR data in an ensemble framework significantly improves detection accuracy compared to RGB-only approaches, particularly in conditions where visible-spectrum sensors struggle. We anticipate that the RASMD dataset will advance research in multispectral imaging for autonomous driving and robust perception systems. 

**Abstract (ZH)**: 当前的自动驾驶算法高度依赖可见光谱，在雾、雨、雪、反光和高对比度等不良条件下性能易受损。尽管近红外（NIR）和长波红外（LWIR）等其他光谱带能在这些情况下增强视觉感知，但它们受限于缺乏大规模数据集和基准。短波红外（SWIR）成像相较于NIR和LWIR具有多项优势。然而，目前尚无公开的大规模数据集包含SWIR数据用于自动驾驶。为填补这一空白，我们介绍了RGB和SWIR多光谱驾驶（RASMD）数据集，该数据集包含100,000对同步且空间对齐的RGB-SWIR图像对，覆盖多种地理位置、光照和天气条件。此外，我们提供了一部分RGB-SWIR图像转换和物体检测注释，用于展示SWIR成像在物体检测和RGB-to-SWIR图像转换实验中的实用性。实验结果表明，在集成框架中结合RGB和SWIR数据显著提高了检测准确性，特别是在可见光谱传感器性能不佳的条件下。我们预计RASMD数据集将推动自动驾驶中多光谱成像的研究和稳健感知系统的进展。 

---
# Learning Long Short-Term Intention within Human Daily Behaviors 

**Title (ZH)**: 学习人类日常行为中的长期短期意图 

**Authors**: Zhe Sun, Rujie Wu, Xiaodong Yang, Hongzhao Xie, Haiyan Jiang, Junda Bi, Zhenliang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07597)  

**Abstract**: In the domain of autonomous household robots, it is of utmost importance for robots to understand human behaviors and provide appropriate services. This requires the robots to possess the capability to analyze complex human behaviors and predict the true intentions of humans. Traditionally, humans are perceived as flawless, with their decisions acting as the standards that robots should strive to align with. However, this raises a pertinent question: What if humans make mistakes? In this research, we present a unique task, termed "long short-term intention prediction". This task requires robots can predict the long-term intention of humans, which aligns with human values, and the short term intention of humans, which reflects the immediate action intention. Meanwhile, the robots need to detect the potential non-consistency between the short-term and long-term intentions, and provide necessary warnings and suggestions. To facilitate this task, we propose a long short-term intention model to represent the complex intention states, and build a dataset to train this intention model. Then we propose a two-stage method to integrate the intention model for robots: i) predicting human intentions of both value-based long-term intentions and action-based short-term intentions; and 2) analyzing the consistency between the long-term and short-term intentions. Experimental results indicate that the proposed long short-term intention model can assist robots in comprehending human behavioral patterns over both long-term and short-term durations, which helps determine the consistency between long-term and short-term intentions of humans. 

**Abstract (ZH)**: 自主家庭机器人领域中的人类行为理解和短期长期意图预测研究 

---
# Malware analysis assisted by AI with R2AI 

**Title (ZH)**: AI辅助的M2AI恶意软件分析 

**Authors**: Axelle Apvrille, Daniel Nakov  

**Link**: [PDF](https://arxiv.org/pdf/2504.07574)  

**Abstract**: This research studies the quality, speed and cost of malware analysis assisted by artificial intelligence. It focuses on Linux and IoT malware of 2024-2025, and uses r2ai, the AI extension of Radare2's disassembler. Not all malware and not all LLMs are equivalent but the study shows excellent results with Claude 3.5 and 3.7 Sonnet. Despite a few errors, the quality of analysis is overall equal or better than without AI assistance. For good results, the AI cannot operate alone and must constantly be guided by an experienced analyst. The gain of speed is largely visible with AI assistance, even when taking account the time to understand AI's hallucinations, exaggerations and omissions. The cost is usually noticeably lower than the salary of a malware analyst, but attention and guidance is needed to keep it under control in cases where the AI would naturally loop without showing progress. 

**Abstract (ZH)**: 这项研究探讨了人工智能辅助下恶意软件分析的质量、速度和成本。该研究专注于2024-2025年的Linux和IoT恶意软件，并使用了r2ai，即Radare2反汇编器的AI扩展。并非所有恶意软件和语言模型都是等效的，但研究表明，在使用Claude 3.5和3.7 Sonnet的情况下，效果极佳。尽管存在一些错误，但在人工智能辅助下，分析的质量整体上优于没有人工智能辅助的情况下。要获得良好的结果，人工智能不能单独运行，而必须不断接受经验丰富的分析师的指导。在有AI参与的情况下，速度改进是显而易见的，即使考虑理解AI的幻觉、夸大和遗漏所需的时间也是一样。与恶意软件分析师的薪酬相比，成本通常更低，但在AI自然循环而未显示进展的情况下，需要注意并控制成本。 

---
# Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs 

**Title (ZH)**: 电子商务中图像嵌入的基准测试：现成基础模型、微调策略及实际权衡的研究 

**Authors**: Urszula Czerwinska, Cenk Bircanoglu, Jeremy Chamoux  

**Link**: [PDF](https://arxiv.org/pdf/2504.07567)  

**Abstract**: We benchmark foundation models image embeddings for classification and retrieval in e-Commerce, evaluating their suitability for real-world applications. Our study spans embeddings from pre-trained convolutional and transformer models trained via supervised, self-supervised, and text-image contrastive learning. We assess full fine-tuning and transfer learning (top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars, food, and retail. Results show full fine-tuning consistently performs well, while text-image and self-supervised embeddings can match its performance with less training. While supervised embeddings remain stable across architectures, SSL and contrastive embeddings vary significantly, often benefiting from top-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning, reducing computational costs. We also explore cross-tuning, noting its impact depends on dataset characteristics. Our findings offer practical guidelines for embedding selection and fine-tuning strategies, balancing efficiency and performance. 

**Abstract (ZH)**: 我们对标基础模型的图像嵌入在电子商务中的分类和检索性能，评估其适用于现实世界应用的 suitability。研究涵盖了通过监督学习、半监督学习和文本-图像对比学习预训练的卷积和变换模型的嵌入。我们在六个不同的电子商务数据集中评估了全程微调和迁移学习（顶微调）的效果：时尚、消费品、汽车、食品和零售。结果显示，全程微调的效果始终较好，而文本-图像和自我监督嵌入在较少的训练情况下可以达到类似效果。虽然监督嵌入在不同架构中表现出一致性，但自我监督和对比嵌入变化显著，通常可以从顶微调中获益。顶微调作为一种高效替代全程微调的解决方案，减少了计算成本。我们还探讨了跨微调，其影响取决于数据集的特性。我们的研究结果提供了嵌入选择和微调策略的实际指导，平衡了效率和性能。 

---
# Diffusion Transformers for Tabular Data Time Series Generation 

**Title (ZH)**: 差分变换器在表格数据时间序列生成中的应用 

**Authors**: Fabrizio Garuti, Enver Sangineto, Simone Luetto, Lorenzo Forni, Rita Cucchiara  

**Link**: [PDF](https://arxiv.org/pdf/2504.07566)  

**Abstract**: Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, generating time series of tabular data, where each element of the series depends on the others, remains a largely unexplored domain. This gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series. In this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. Using extensive experiments on six datasets, we show that the proposed approach outperforms previous work by a large margin. 

**Abstract (ZH)**: 基于扩散变压器的表格时间序列数据生成 

---
# ReXCL: A Tool for Requirement Document Extraction and Classification 

**Title (ZH)**: ReXCL: 一种需求文档提取与分类工具 

**Authors**: Paheli Bhattacharya, Manojit Chakraborty, Santhosh Kumar Arumugam, Rishabh Gupta  

**Link**: [PDF](https://arxiv.org/pdf/2504.07562)  

**Abstract**: This paper presents the ReXCL tool, which automates the extraction and classification processes in requirement engineering, enhancing the software development lifecycle. The tool features two main modules: Extraction, which processes raw requirement documents into a predefined schema using heuristics and predictive modeling, and Classification, which assigns class labels to requirements using adaptive fine-tuning of encoder-based models. The final output can be exported to external requirement engineering tools. Performance evaluations indicate that ReXCL significantly improves efficiency and accuracy in managing requirements, marking a novel approach to automating the schematization of semi-structured requirement documents. 

**Abstract (ZH)**: 这篇文章介绍了ReXCL工具，该工具自动化了需求工程中的提取和分类过程，增强软件开发生命周期的效率。该工具包含两个主要模块：提取模块使用启发式方法和预测建模将原始需求文档转换为预定义方案；分类模块利用基于编解码器模型的自适应微调为需求分配类别标签。最终输出可以导出到外部需求工程工具。性能评估表明，ReXCL在管理和处理半结构化需求文档的方案化方面显著提高了效率和准确性，标志着自动化需求工程的一个新颖方法。 

---
# PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and Merkle Proofs 

**Title (ZH)**: PoGO: 一种基于量化梯度下降和Merkle证明的可扩展的工作证明机制 

**Authors**: José I. Orlicki  

**Link**: [PDF](https://arxiv.org/pdf/2504.07540)  

**Abstract**: We present a design called \emph{Proof of Gradient Optimization} (PoGO) for blockchain consensus, where miners produce verifiable evidence of training large-scale machine-learning models. Building on previous work, we incorporate \emph{quantized gradients} (4-bit precision) to reduce storage and computation requirements, while still preserving the ability of verifiers to check that real progress has been made on lowering the model's loss. Additionally, we employ Merkle proofs over the full 32-bit model to handle large parameter sets and to enable random leaf checks with minimal on-chain data. We illustrate these ideas using GPT-3 (175B parameters) as a reference example and also refer to smaller but high-performance models (e.g., \emph{Gemma~3} with 27B parameters). We provide an empirical cost analysis showing that verification is significantly cheaper than training, thanks in part to quantization and sampling. We also discuss the necessity of longer block times (potentially hours) when incorporating meaningful training steps, the trade-offs when using specialized GPU hardware, and how binary diffs may incrementally optimize updates. Finally, we note that fine-tuning can be handled in a similar manner, merely changing the dataset and the manner of sampling but preserving the overall verification flow. Our protocol allows verifiers to issue either \emph{positive} or \emph{negative} attestations; these are aggregated at finalization to either confirm the update or slash the miner. 

**Abstract (ZH)**: 基于梯度优化的区块链共识证明设计（Proof of Gradient Optimization, PoGO） 

---
# AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation 

**Title (ZH)**: 从AI粗糙到AI精磨：通过基于编辑的写作奖励和测试时计算实现语言模型对齐 

**Authors**: Tuhin Chakrabarty, Philippe Laban, Chien-Sheng Wu  

**Link**: [PDF](https://arxiv.org/pdf/2504.07532)  

**Abstract**: AI-generated text is proliferating across domains, from creative writing and journalism to marketing content and scientific articles. Models can follow user-provided instructions to generate coherent and grammatically correct outputs but in this work, we study a more fundamental question: how do we evaluate and improve the writing quality of AI-generated text? Writing quality assessment has received less attention from the community, in part because it is fundamentally subjective and requires expertise. We first introduce the Writing Quality Benchmark (WQ) by consolidating five writing-preference datasets into 4,729 writing quality judgments. Our experiments show that competitive baselines, including state-of-the-art LLMs that excel at reasoning tasks, barely outperform random baselines on WQ. We then train specialized Writing Quality Reward Models (WQRM) of various sizes for writing quality assessment that demonstrate strong generalization on four out-of-distribution test sets and 74% accuracy on the WQ benchmark. To further show WQRM's practical benefits during inference, we leverage additional test-time compute to generate and rank multiple candidate revisions, allowing us to select higher-quality outputs from an initial draft. Human evaluation with 9 experienced writers confirm that WQRM-based selection produces writing samples preferred by experts 66% overall, and 72.2% when the reward gap is larger than 1 point. We release our datasets and models to encourage community engagement with writing quality assessment and development of AI writing systems better aligned with human preferences. 

**Abstract (ZH)**: AI生成文本的质量评估与提升：从主观性出发构建Writing Quality Benchmark（WQ）及高性能奖励模型 

---
# Adversarial Subspace Generation for Outlier Detection in High-Dimensional Data 

**Title (ZH)**: 高维数据离群点检测的 adversarial 子空间生成 

**Authors**: Jose Cribeiro-Ramallo, Federico Matteucci, Paul Enciu, Alexander Jenke, Vadim Arzamasov, Thorsten Strufe, Klemens Böhm  

**Link**: [PDF](https://arxiv.org/pdf/2504.07522)  

**Abstract**: Outlier detection in high-dimensional tabular data is challenging since data is often distributed across multiple lower-dimensional subspaces -- a phenomenon known as the Multiple Views effect (MV). This effect led to a large body of research focused on mining such subspaces, known as subspace selection. However, as the precise nature of the MV effect was not well understood, traditional methods had to rely on heuristic-driven search schemes that struggle to accurately capture the true structure of the data. Properly identifying these subspaces is critical for unsupervised tasks such as outlier detection or clustering, where misrepresenting the underlying data structure can hinder the performance. We introduce Myopic Subspace Theory (MST), a new theoretical framework that mathematically formulates the Multiple Views effect and writes subspace selection as a stochastic optimization problem. Based on MST, we introduce V-GAN, a generative method trained to solve such an optimization problem. This approach avoids any exhaustive search over the feature space while ensuring that the intrinsic data structure is preserved. Experiments on 42 real-world datasets show that using V-GAN subspaces to build ensemble methods leads to a significant increase in one-class classification performance -- compared to existing subspace selection, feature selection, and embedding methods. Further experiments on synthetic data show that V-GAN identifies subspaces more accurately while scaling better than other relevant subspace selection methods. These results confirm the theoretical guarantees of our approach and also highlight its practical viability in high-dimensional settings. 

**Abstract (ZH)**: 高维表数据中的离群点检测由于数据常常分布在多个低维子空间中——这一现象被称为多重视图效应（MV）——而具有挑战性。基于多重视图效应，我们引入了近视子空间理论（MST），这是一种新的理论框架，数学上定义了多重视图效应，并将子空间选择问题表述为一个随机优化问题。基于MST，我们提出了V-GAN生成模型，该模型受训于解决此类优化问题。该方法避免在整个特征空间中进行 exhaustive 搜索，同时确保保留数据的固有结构。在42个真实世界数据集上的实验表明，使用V-GAN子空间构建集成方法可以显著提高单类分类性能，与现有的子空间选择、特征选择和嵌入方法相比。在合成数据上的进一步实验表明，V-GAN能够更准确地识别子空间，并且在扩展性方面优于其他相关子空间选择方法。这些结果证实了我们方法的理论保证，并且突显了其在高维设置中的实用可行性。 

---
# Enhancements for Developing a Comprehensive AI Fairness Assessment Standard 

**Title (ZH)**: 增强全面AI公平性评估标准开发的研究 

**Authors**: Avinash Agarwal, Mayashankar Kumar, Manisha J. Nene  

**Link**: [PDF](https://arxiv.org/pdf/2504.07516)  

**Abstract**: As AI systems increasingly influence critical sectors like telecommunications, finance, healthcare, and public services, ensuring fairness in decision-making is essential to prevent biased or unjust outcomes that disproportionately affect vulnerable entities or result in adverse impacts. This need is particularly pressing as the industry approaches the 6G era, where AI will drive complex functions like autonomous network management and hyper-personalized services. The TEC Standard for Fairness Assessment and Rating of AI Systems provides guidelines for evaluating fairness in AI, focusing primarily on tabular data and supervised learning models. However, as AI applications diversify, this standard requires enhancement to strengthen its impact and broaden its applicability. This paper proposes an expansion of the TEC Standard to include fairness assessments for images, unstructured text, and generative AI, including large language models, ensuring a more comprehensive approach that keeps pace with evolving AI technologies. By incorporating these dimensions, the enhanced framework will promote responsible and trustworthy AI deployment across various sectors. 

**Abstract (ZH)**: 随着AI系统在电信、金融、医疗保健和公共服务等关键领域的影响日益增大，确保决策公平性以防止针对脆弱实体的偏见或不公正结果变得至关重要。这一需求随着行业迈向6G时代而更加紧迫，在该时代，AI将驱动复杂的功能如自管理网络和超个性化服务。TEC公平性评估和评级标准为评估AI公平性提供了规范，主要关注表格式数据和监督学习模型。然而，随着AI应用的多样化，该标准需要改进以增强其影响并扩大其适用范围。本文提议扩展TEC标准，以包括图像、非结构化文本和生成型AI（包括大型语言模型）的公平性评估，确保一种更为全面的方法能够与不断发展的AI技术保持同步。通过纳入这些维度，增强框架将促进各类领域的负责任和可信AI部署。 

---
# GPT Carry-On: Training Foundation Model for Customization Could Be Simple, Scalable and Affordable 

**Title (ZH)**: GPT 继承：训练定制基础模型可以简单、可扩展且经济 

**Authors**: Jianqiao Wangni  

**Link**: [PDF](https://arxiv.org/pdf/2504.07513)  

**Abstract**: Modern large language foundation models (LLM) have now entered the daily lives of millions of users. We ask a natural question whether it is possible to customize LLM for every user or every task. From system and industrial economy consideration, general continue-training or fine-tuning still require substantial computation and memory of training GPU nodes, whereas most inference nodes under deployment, possibly with lower-end GPUs, are configured to make forward pass fastest possible. We propose a framework to take full advantages of existing LLMs and systems of online service. We train an additional branch of transformer blocks on the final-layer embedding of pretrained LLMs, which is the base, then a carry-on module merge the base models to compose a customized LLM. We can mix multiple layers, or multiple LLMs specialized in different domains such as chat, coding, math, to form a new mixture of LLM that best fit a new task. As the base model don't need to update parameters, we are able to outsource most computation of the training job on inference nodes, and only train a lightweight carry-on on training nodes, where we consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM. We tested Qwen and DeepSeek opensourced models for continue-pretraining and got faster loss convergence. We use it to improve solving math questions with extremely small computation and model size, with 1000 data samples of chain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on, and the results are promising. 

**Abstract (ZH)**: 现代大型语言基础模型（LLM）已深入 Millions of 用户的日常生活。我们自然地提出一个问题：是否可以为每个用户或每个任务定制 LLM？从系统和工业经济的角度考虑，通用的继续训练或微调仍然需要大量的训练 GPU 节点的计算和内存，而部署中的大多数推理节点，可能使用较低端的 GPU，配置为尽可能快地进行前向传播。我们提出了一种框架，充分利用现成的 LLM 和在线服务系统的优势。我们对预训练 LLM 的最终层嵌入增加了一个额外的变压器分支，然后通过继续模块将基础模型组合成一个定制的 LLM。我们可以混合多个层，或者多个专注于不同领域的 LLM（如聊天、编码、数学），以形成最适合新任务的 LLM 新混合体。由于基模型不需要更新参数，我们可以在推理节点上外包大部分训练工作，仅在训练节点上训练一个轻量级的继续模块，我们使用不到 1GB 的 GPU 内存在 30B LLM 上训练一个 100M 参数的继续模块层。我们对 Qwen 和 DeepSeek 开源模型进行继续预训练并获得了更快的损失收敛。我们使用它来改进解决数学问题，仅使用 1000 个带思维链的数据样本和两个层最小 1 MB 参数的轻量级继续模块，结果令人鼓舞。 

---
# CMEdataset Advancing China Map Detection and Standardization with Digital Image Resources 

**Title (ZH)**: CMEdataset 促进基于数字图像资源的中国地图检测与标准化 

**Authors**: Yan Xu, Zhenqiang Zhang, Zhiwei Zhou, Liting Geng, Yue Li, Jintao Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.07476)  

**Abstract**: Digital images of Chinas maps play a crucial role in map detection, particularly in ensuring national sovereignty, territorial integrity, and map compliance. However, there is currently no publicly available dataset specifically dedicated to problematic maps the CME dataset. Existing datasets primarily focus on general map data and are insufficient for effectively identifying complex issues such as national boundary misrepresentations, missing elements, and blurred boundaries. Therefore, this study creates a Problematic Map dataset that covers five key problem areas, aiming to provide diverse samples for problematic map detection technologies, support high-precision map compliance detection, and enhance map data quality and timeliness. This dataset not only provides essential resources for map compliance, national security monitoring, and map updates, but also fosters innovation and application of related technologies. 

**Abstract (ZH)**: 中国地图的数字图像在地图检测中扮演着 crucial 角色，特别是在保障国家主权、领土完整和地图合规性方面。然而，目前尚无专门针对问题地图的公开数据集，如 CME 数据集。现有数据集主要关注一般地图数据，不足以有效识别国家边界误表示、缺失要素和模糊边界等复杂问题。因此，本研究创建了一个问题地图数据集，涵盖了五个关键问题领域，旨在为问题地图检测技术提供多样化样本，支持高精度地图合规性检测，并提升地图数据的质量和及时性。该数据集不仅为地图合规性、国家安全监控和地图更新提供 essential 资源，还有助于推动相关技术的创新和应用。 

---
# Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected PET for Whole-Body PET Attenuation Correction 

**Title (ZH)**: 基于飞行时间未校正衰减的PET生成全身PET衰减校正的合成CT 

**Authors**: Weijie Chen, James Wang, Alan McMillan  

**Link**: [PDF](https://arxiv.org/pdf/2504.07450)  

**Abstract**: Positron Emission Tomography (PET) imaging requires accurate attenuation correction (AC) to account for photon loss due to tissue density variations. In PET/MR systems, computed tomography (CT), which offers a straightforward estimation of AC is not available. This study presents a deep learning approach to generate synthetic CT (sCT) images directly from Time-of-Flight (TOF) non-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first evaluated models pre-trained on large-scale natural image datasets for a CT-to-CT reconstruction task, finding that the pre-trained model outperformed those trained solely on medical datasets. The pre-trained model was then fine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume pairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest peak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region. Visual assessments demonstrated improved reconstruction of both bone and soft tissue structures from TOF NAC PET images. This work highlights the effectiveness of using pre-trained deep learning models for medical image translation tasks. Future work will assess the impact of sCT on PET attenuation correction and explore additional neural network architectures and datasets to further enhance performance and practical applications in PET imaging. 

**Abstract (ZH)**: 基于深度学习的TOF非 attenuated PET图像生成合成CT以改进PET/MR衰减校正 

---
# LoRI: Reducing Cross-Task Interference in Multi-Task Low-Rank Adaptation 

**Title (ZH)**: LoRI: 多任务低秩适应中跨任务干扰的降低 

**Authors**: Juzheng Zhang, Jiacheng You, Ashwinee Panda, Tom Goldstein  

**Link**: [PDF](https://arxiv.org/pdf/2504.07448)  

**Abstract**: Low-Rank Adaptation (LoRA) has emerged as a popular parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), yet it still incurs notable overhead and suffers from parameter interference in multi-task scenarios. We propose LoRA with Reduced Interference (LoRI), a simple yet effective approach that freezes the projection matrices $A$ as random projections and sparsifies the matrices $B$ using task-specific masks. This design substantially reduces the number of trainable parameters while maintaining strong task performance. Moreover, LoRI minimizes cross-task interference in adapter merging by leveraging the orthogonality between adapter subspaces, and supports continual learning by using sparsity to mitigate catastrophic forgetting. Extensive experiments across natural language understanding, mathematical reasoning, code generation, and safety alignment tasks demonstrate that LoRI outperforms full fine-tuning and existing PEFT methods, while using up to 95% fewer trainable parameters than LoRA. In multi-task experiments, LoRI enables effective adapter merging and continual learning with reduced cross-task interference. Code is available at: this https URL 

**Abstract (ZH)**: 基于减少干扰的Low-Rank Adaptation (LoRA) 

---
# Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support 

**Title (ZH)**: 过度依赖依赖性：迈向基于AI的临床决策支持的现实评估 

**Authors**: Venkatesh Sivaraman, Katelyn Morrison, Will Epperson, Adam Perer  

**Link**: [PDF](https://arxiv.org/pdf/2504.07423)  

**Abstract**: As AI-based clinical decision support (AI-CDS) is introduced in more and more aspects of healthcare services, HCI research plays an increasingly important role in designing for complementarity between AI and clinicians. However, current evaluations of AI-CDS often fail to capture when AI is and is not useful to clinicians. This position paper reflects on our work and influential AI-CDS literature to advocate for moving beyond evaluation metrics like Trust, Reliance, Acceptance, and Performance on the AI's task (what we term the "trap" of human-AI collaboration). Although these metrics can be meaningful in some simple scenarios, we argue that optimizing for them ignores important ways that AI falls short of clinical benefit, as well as ways that clinicians successfully use AI. As the fields of HCI and AI in healthcare develop new ways to design and evaluate CDS tools, we call on the community to prioritize ecologically valid, domain-appropriate study setups that measure the emergent forms of value that AI can bring to healthcare professionals. 

**Abstract (ZH)**: 随着基于AI的临床决策支持（AI-CDS）在越来越多的医疗保健服务领域得到应用，人机交互（HCI）研究在设计AI与临床医生互补性方面发挥着越来越重要的作用。然而，当前对AI-CDS的评估往往未能捕捉到AI在临床医生工作中的有用和无用之处。本文从我们的工作和影响深远的AI-CDS文献出发，倡导超越基于人类-AI协作的“信任、依赖、接受和AI任务表现”等评价指标（我们称其为人类-AI合作的“陷阱”）。尽管这些指标在某些简单情境下具有意义，但我们认为，将优化这些指标忽视了AI未能实现临床效益的重要方式，以及临床医生成功利用AI的方式。随着HCI和医疗保健中AI设计与评估方法的发展，我们呼吁社区优先采用生态有效、领域适宜的研究框架，以衡量AI为医疗专业人员带来的一种新兴价值形式。 

---
# The Role of Machine Learning in Reducing Healthcare Costs: The Impact of Medication Adherence and Preventive Care on Hospitalization Expenses 

**Title (ZH)**: 机器学习在降低医疗成本中的作用：药物依从性和预防护理对住院费用的影响 

**Authors**: Yixin Zhang, Yisong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2504.07422)  

**Abstract**: This study reveals the important role of prevention care and medication adherence in reducing hospitalizations. By using a structured dataset of 1,171 patients, four machine learning models Logistic Regression, Gradient Boosting, Random Forest, and Artificial Neural Networks are applied to predict five-year hospitalization risk, with the Gradient Boosting model achieving the highest accuracy of 81.2%. The result demonstrated that patients with high medication adherence and consistent preventive care can reduce 38.3% and 37.7% in hospitalization risk. The finding also suggests that targeted preventive care can have positive Return on Investment (ROI), and therefore ML models can effectively direct personalized interventions and contribute to long-term medical savings. 

**Abstract (ZH)**: 本研究揭示了预防护理和服药依从性在减少住院率中的重要作用。通过使用1,171名患者的结构化数据集，应用逻辑回归、梯度提升、随机森林和人工神经网络四种机器学习模型预测五年住院风险，梯度提升模型的准确率达到最高，为81.2%。结果表明，高服药依从性和持续的预防护理可以分别减少38.3%和37.7%的住院风险。研究还表明，针对性的预防护理可以实现正的投资回报率（ROI），因此机器学习模型可以有效地指导个性化干预，有助于长期医疗费用节省。 

---
# LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models 

**Title (ZH)**: LauraTSE：使用自回归解码器-only语言模型的目标讲话人提取 

**Authors**: Beilong Tang, Bang Zeng, Ming Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.07402)  

**Abstract**: We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for Target Speaker Extraction (TSE) based on the LauraGPT backbone. It employs a small-scale auto-regressive decoder-only language model which takes the continuous representations for both the mixture and the reference speeches and produces the first few layers of the target speech's discrete codec representations. In addition, a one-step encoder-only language model reconstructs the sum of the predicted codec embeddings using both the mixture and the reference information. Our approach achieves superior or comparable performance to existing generative and discriminative TSE models. To the best of our knowledge, LauraTSE is the first single-task TSE model to leverage an auto-regressive decoder-only language model as the backbone. 

**Abstract (ZH)**: 我们提出LauraTSE，一种基于LauraGPT骨干的自回归解码器_only语言模型目标说话人提取（TSE）模型 

---
# A Novel Mamba-based Sequential Recommendation Method 

**Title (ZH)**: 基于Mamba的新型序列推荐方法 

**Authors**: Jun Yuan  

**Link**: [PDF](https://arxiv.org/pdf/2504.07398)  

**Abstract**: Sequential recommendation (SR), which encodes user activity to predict the next action, has emerged as a widely adopted strategy in developing commercial personalized recommendation systems. Although Transformer-based models have proven effective for sequential recommendation, the complexity of the self-attention module in Transformers scales quadratically with the sequence length. Controlling model complexity is essential for large-scale recommendation systems, as these systems may need to handle billion-scale vocabularies that evolve continuously, as well as user behavior sequences that can exceed tens of thousands in length. In this paper, we propose a novel multi-head latent Mamba architecture, which employs multiple low-dimensional Mamba layers and fully connected layers coupled with positional encoding to simultaneously capture historical and item information within each latent subspace. Our proposed method not only enables scaling up to large-scale parameters but also extends to multi-domain recommendation by integrating and fine-tuning LLMs. Through extensive experiments on public datasets, we demonstrate how Hydra effectively addresses the effectiveness-efficiency dilemma, outperforming state-of-the-art sequential recommendation baselines with significantly fewer parameters and reduced training time. 

**Abstract (ZH)**: 基于顺序推荐的多头潜在Mamba架构：高效扩展与多域适应 

---
# MicroNAS: An Automated Framework for Developing a Fall Detection System 

**Title (ZH)**: MicroNAS: 一种跌倒检测系统开发的自动化框架 

**Authors**: Seyed Mojtaba Mohasel, John Sheppard, Lindsey K. Molina, Richard R. Neptune, Shane R. Wurdeman, Corey A. Pew  

**Link**: [PDF](https://arxiv.org/pdf/2504.07397)  

**Abstract**: This work presents MicroNAS, an automated neural architecture search tool specifically designed to create models optimized for microcontrollers with small memory resources. The ESP32 microcontroller, with 320 KB of memory, is used as the target platform. The artificial intelligence contribution lies in a novel method for optimizing convolutional neural network and gated recurrent unit architectures by considering the memory size of the target microcontroller as a guide. A comparison is made between memory-driven model optimization and traditional two-stage methods, which use pruning, to show the effectiveness of the proposed framework. To demonstrate the engineering application of MicroNAS, a fall detection system (FDS) for lower-limb amputees is developed as a pilot study. A critical challenge in fall detection studies, class imbalance in the dataset, is addressed. The results show that MicroNAS models achieved higher F1-scores than alternative approaches, such as ensemble methods and H2O Automated Machine Learning, presenting a significant step forward in real-time FDS development. Biomechanists using body-worn sensors for activity detection can adopt the open-source code to design machine learning models tailored for microcontroller platforms with limited memory. 

**Abstract (ZH)**: MicroNAS：一种专为小型内存资源微控制器优化的自动化神经架构搜索工具 

---
# Automating quantum feature map design via large language models 

**Title (ZH)**: 通过大型语言模型自动化量子特征映射设计 

**Authors**: Kenya Sakka, Kosuke Mitarai, Keisuke Fujii  

**Link**: [PDF](https://arxiv.org/pdf/2504.07396)  

**Abstract**: Quantum feature maps are a key component of quantum machine learning, encoding classical data into quantum states to exploit the expressive power of high-dimensional Hilbert spaces. Despite their theoretical promise, designing quantum feature maps that offer practical advantages over classical methods remains an open challenge. In this work, we propose an agentic system that autonomously generates, evaluates, and refines quantum feature maps using large language models. The system consists of five component: Generation, Storage, Validation, Evaluation, and Review. Using these components, it iteratively improves quantum feature maps. Experiments on the MNIST dataset show that it can successfully discover and refine feature maps without human intervention. The best feature map generated outperforms existing quantum baselines and achieves competitive accuracy compared to classical kernels across MNIST, Fashion-MNIST, and CIFAR-10. Our approach provides a framework for exploring dataset-adaptive quantum features and highlights the potential of LLM-driven automation in quantum algorithm design. 

**Abstract (ZH)**: 量子特征映射是量子机器学习的关键组成部分，用于将经典数据编码为量子态，从而利用高性能希尔伯特空间的表达能力。尽管具有理论前景，但设计出在实用性上优于经典方法的量子特征映射仍然是一个开放的挑战。在这项工作中，我们提出了一种自主系统，利用大规模语言模型来自主生成、评估和优化量子特征映射。该系统由五个组件构成：生成、存储、验证、评估和审查。利用这些组件，系统能够迭代地改进量子特征映射。在MNIST数据集上的实验显示，该系统能够在无需人类干预的情况下成功发现和优化特征映射。生成的最佳特征映射优于现有量子基线，并在MNIST、Fashion-MNIST和CIFAR-10数据集上实现了与经典核相当的竞争力。我们的方法提供了一种探索数据集自适应量子特征的框架，并突显了语言模型驱动自动化在量子算法设计中的潜力。 

---
# FAIR-SIGHT: Fairness Assurance in Image Recognition via Simultaneous Conformal Thresholding and Dynamic Output Repair 

**Title (ZH)**: FAIR-SIGHT：通过同时进行同尺度阈值调整和动态输出修复实现图像识别中的公平性保障 

**Authors**: Arya Fayyazi, Mehdi Kamal, Massoud Pedram  

**Link**: [PDF](https://arxiv.org/pdf/2504.07395)  

**Abstract**: We introduce FAIR-SIGHT, an innovative post-hoc framework designed to ensure fairness in computer vision systems by combining conformal prediction with a dynamic output repair mechanism. Our approach calculates a fairness-aware non-conformity score that simultaneously assesses prediction errors and fairness violations. Using conformal prediction, we establish an adaptive threshold that provides rigorous finite-sample, distribution-free guarantees. When the non-conformity score for a new image exceeds the calibrated threshold, FAIR-SIGHT implements targeted corrective adjustments, such as logit shifts for classification and confidence recalibration for detection, to reduce both group and individual fairness disparities, all without the need for retraining or having access to internal model parameters. Comprehensive theoretical analysis validates our method's error control and convergence properties. At the same time, extensive empirical evaluations on benchmark datasets show that FAIR-SIGHT significantly reduces fairness disparities while preserving high predictive performance. 

**Abstract (ZH)**: FAIR-SIGHT：一种结合一致预测和动态输出修复机制的后验公平性保障框架 

---
# ClimateBench-M: A Multi-Modal Climate Data Benchmark with a Simple Generative Method 

**Title (ZH)**: ClimateBench-M：一种基于简单生成方法的多模态气候数据基准 

**Authors**: Dongqi Fu, Yada Zhu, Zhining Liu, Lecheng Zheng, Xiao Lin, Zihao Li, Liri Fang, Katherine Tieu, Onkar Bhardwaj, Kommy Weldemariam, Hanghang Tong, Hendrik Hamann, Jingrui He  

**Link**: [PDF](https://arxiv.org/pdf/2504.07394)  

**Abstract**: Climate science studies the structure and dynamics of Earth's climate system and seeks to understand how climate changes over time, where the data is usually stored in the format of time series, recording the climate features, geolocation, time attributes, etc. Recently, much research attention has been paid to the climate benchmarks. In addition to the most common task of weather forecasting, several pioneering benchmark works are proposed for extending the modality, such as domain-specific applications like tropical cyclone intensity prediction and flash flood damage estimation, or climate statement and confidence level in the format of natural language. To further motivate the artificial general intelligence development for climate science, in this paper, we first contribute a multi-modal climate benchmark, i.e., ClimateBench-M, which aligns (1) the time series climate data from ERA5, (2) extreme weather events data from NOAA, and (3) satellite image data from NASA HLS based on a unified spatial-temporal granularity. Second, under each data modality, we also propose a simple but strong generative method that could produce competitive performance in weather forecasting, thunderstorm alerts, and crop segmentation tasks in the proposed ClimateBench-M. The data and code of ClimateBench-M are publicly available at this https URL. 

**Abstract (ZH)**: 气候科学研究地球气候系统的结构和动力学，并寻求理解气候变化的机制，数据通常以时间序列形式存储，记录气候特征、地理位置、时间属性等。近年来，气候基准已成为研究热点。除了常见的天气预报任务外，还提出了多种模态扩展的应用基准，如特定领域的热带气旋强度预测和洪涝灾害评估，以及以自然语言形式的气候声明和置信水平。为进一步推动适用于气候科学的人工通用智能发展，在本文中，我们首先贡献了一个多模态气候基准，即ClimateBench-M，它将（1）来自ERA5的时间序列气候数据，（2）来自NOAA的极端天气事件数据，以及（3）来自NASA HLS的卫星图像数据统一到相同的空时粒度上。其次，在每个数据模态下，我们还提出了简单但有效的生成方法，它在天气预报、雷暴警报和农作物分割任务中都能产生具有竞争力的表现。ClimateBench-M的代码和数据可在以下链接获取。 

---
# Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression 

**Title (ZH)**: 任务导向的电路量化：利用知识局部化和可解释性进行压缩 

**Authors**: Hanqi Xiao, Yi-Lin Sung, Elias Stengel-Eskin, Mohit Bansal  

**Link**: [PDF](https://arxiv.org/pdf/2504.07389)  

**Abstract**: Post-training quantization (PTQ) reduces a model's memory footprint by mapping full precision weights into low bit weights without costly retraining, but can degrade its downstream performance especially in low 2- to 3-bit settings. We develop a new mixed-precision PTQ approach, Task-Circuit Quantization (TaCQ), that draws parallels to automated circuit discovery, directly conditioning the quantization process on specific weight circuits -- which we define as sets of weights associated with downstream task performance. These weights are kept as 16-bit weights, while others are quantized, maintaining performance while only adding a marginal memory cost. Specifically, TaCQ contrasts unquantized model weights with a uniformly-quantized model to estimate the expected change in weights due to quantization and uses gradient information to predict the resulting impact on task performance, allowing us to preserve task-specific weights. We compare TaCQ-based quantization to existing mixed-precision quantization methods when conditioning both on general-purpose and task-specific data. Across QA, math reasoning, and text-to-SQL tasks for both Llama-3 and Qwen2.5, we find that TaCQ outperforms baselines using the same calibration data and a lower weight budget, achieving major improvements in the 2 and 3-bit regime. With only 3.1 bits we are able to recover 96% of Llama-3-8B-Instruct's unquantized 16-bit MMLU performance, obtaining a 5.25% absolute improvement over SPQR. We also observe consistently large gains over existing methods in the 2-bit regime, with an average gain of 14.74% over the strongest baseline, SliM-LLM. Moreover, we observe a 7.20% gain without conditioning on specific tasks, showing TaCQ's ability to identify important weights is not limited to task-conditioned settings. 

**Abstract (ZH)**: Task-Circuit Quantization (TaCQ): A New Approach to Post-Training Quantization 

---
# Min-Max Optimisation for Nonconvex-Nonconcave Functions Using a Random Zeroth-Order Extragradient Algorithm 

**Title (ZH)**: 非凸-非凹函数的最小最大优化：一种随机零阶外梯度算法 

**Authors**: Amir Ali Farzin, Yuen Man Pun, Philipp Braun, Antoine Lesage-landry, Youssef Diouane, Iman Shames  

**Link**: [PDF](https://arxiv.org/pdf/2504.07388)  

**Abstract**: This study explores the performance of the random Gaussian smoothing Zeroth-Order ExtraGradient (ZO-EG) scheme considering min-max optimisation problems with possibly NonConvex-NonConcave (NC-NC) objective functions. We consider both unconstrained and constrained, differentiable and non-differentiable settings. We discuss the min-max problem from the point of view of variational inequalities. For the unconstrained problem, we establish the convergence of the ZO-EG algorithm to the neighbourhood of an $\epsilon$-stationary point of the NC-NC objective function, whose radius can be controlled under a variance reduction scheme, along with its complexity. For the constrained problem, we introduce the new notion of proximal variational inequalities and give examples of functions satisfying this property. Moreover, we prove analogous results to the unconstrained case for the constrained problem. For the non-differentiable case, we prove the convergence of the ZO-EG algorithm to a neighbourhood of an $\epsilon$-stationary point of the smoothed version of the objective function, where the radius of the neighbourhood can be controlled, which can be related to the ($\delta,\epsilon$)-Goldstein stationary point of the original objective function. 

**Abstract (ZH)**: 本研究探索了在可能具有非凸非凹（NC-NC）目标函数的极小-极大优化问题中，随机高斯平滑零阶额外梯度（ZO-EG）方案的性能。我们考虑了不受约束和受约束、可微和不可微的情况。从变分不等式的视角讨论极小-极大问题。对于不受约束的问题，我们建立了ZO-EG算法收敛到NC-NC目标函数的$\epsilon$-稳定点邻域，并探讨了其收敛半径在方差减少方案下的可控性及其复杂性。对于受约束的问题，我们引入了邻近变分不等式的全新概念，并给出满足这一性质的函数示例。此外，我们证明了受约束问题中类似不受约束情况的结论。对于不可微的情况，我们证明了ZO-EG算法收敛到平滑目标函数的$\epsilon$-稳定点邻域，其收敛半径可控，并可与原目标函数的($\delta,\epsilon$)-Goldstein稳定点相关。 

---
# TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models 

**Title (ZH)**: TALE：一种工具增强框架，用于无参照评估大规模语言模型 

**Authors**: Sher Badshah, Ali Emami, Hassan Sajjad  

**Link**: [PDF](https://arxiv.org/pdf/2504.07385)  

**Abstract**: As Large Language Models (LLMs) become increasingly integrated into real-world, autonomous applications, relying on static, pre-annotated references for evaluation poses significant challenges in cost, scalability, and completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework to assess LLM outputs without predetermined ground-truth answers. Unlike conventional metrics that compare to fixed references or depend solely on LLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities that actively retrieves and synthesizes external evidence. It iteratively generates web queries, collects information, summarizes findings, and refines subsequent searches through reflection. By shifting away from static references, TALE aligns with free-form question-answering tasks common in real-world scenarios. Experimental results on multiple free-form QA benchmarks show that TALE not only outperforms standard reference-based metrics for measuring response accuracy but also achieves substantial to near-perfect agreement with human evaluations. TALE enhances the reliability of LLM evaluations in real-world, dynamic scenarios without relying on static references. 

**Abstract (ZH)**: Tool-Augmented LLM Evaluation (TALE): 一种评估大规模语言模型输出的框架 

---
# PROPEL: Supervised and Reinforcement Learning for Large-Scale Supply Chain Planning 

**Title (ZH)**: PROPEL：大型供应链规划的监督与强化学习方法 

**Authors**: Vahid Eghbal Akhlaghi, Reza Zandehshahvar, Pascal Van Hentenryck  

**Link**: [PDF](https://arxiv.org/pdf/2504.07383)  

**Abstract**: This paper considers how to fuse Machine Learning (ML) and optimization to solve large-scale Supply Chain Planning (SCP) optimization problems. These problems can be formulated as MIP models which feature both integer (non-binary) and continuous variables, as well as flow balance and capacity constraints. This raises fundamental challenges for existing integrations of ML and optimization that have focused on binary MIPs and graph problems. To address these, the paper proposes PROPEL, a new framework that combines optimization with both supervised and Deep Reinforcement Learning (DRL) to reduce the size of search space significantly. PROPEL uses supervised learning, not to predict the values of all integer variables, but to identify the variables that are fixed to zero in the optimal solution, leveraging the structure of SCP applications. PROPEL includes a DRL component that selects which fixed-at-zero variables must be relaxed to improve solution quality when the supervised learning step does not produce a solution with the desired optimality tolerance. PROPEL has been applied to industrial supply chain planning optimizations with millions of variables. The computational results show dramatic improvements in solution times and quality, including a 60% reduction in primal integral and an 88% primal gap reduction, and improvement factors of up to 13.57 and 15.92, respectively. 

**Abstract (ZH)**: 本文考虑如何将机器学习（ML）与优化相结合，以解决大规模供应链规划（SCP）优化问题。这些问题可以被形式化为包含整数（非二进制）和连续变量以及流量平衡和容量约束的MIP模型。这为现有的主要针对二进制MIP和图问题的ML与优化集成提出了根本性的挑战。为了解决这些问题，本文提出了一种名为PROPEL的新框架，该框架结合了优化与监督学习和深度强化学习（DRL），以显著减少搜索空间的大小。PROPEL使用监督学习来识别最优解中固定为零的变量，而不是预测所有整数变量的值，利用SCP应用的结构。PROPEL还包括一个DRL组件，在监督学习步骤未能产生具有所需最优性容差的解时，选择需要放松的固定为零的变量以提高解的质量。PROPEL已被应用于具有数百万个变量的工业供应链规划优化问题。计算结果表明，在解时间和质量方面取得了显著改进，包括原值积分减少60%以及原值差距减少88%，改进因子分别为13.57和15.92。 

---
# Representation Meets Optimization: Training PINNs and PIKANs for Gray-Box Discovery in Systems Pharmacology 

**Title (ZH)**: 表示遇上了优化：训练PINNs和PIKANs进行系统药理学中的灰盒发现 

**Authors**: Nazanin Ahmadi Daryakenari, Khemraj Shukla, George Em Karniadakis  

**Link**: [PDF](https://arxiv.org/pdf/2504.07379)  

**Abstract**: Physics-Informed Kolmogorov-Arnold Networks (PIKANs) are gaining attention as an effective counterpart to the original multilayer perceptron-based Physics-Informed Neural Networks (PINNs). Both representation models can address inverse problems and facilitate gray-box system identification. However, a comprehensive understanding of their performance in terms of accuracy and speed remains underexplored. In particular, we introduce a modified PIKAN architecture, tanh-cPIKAN, which is based on Chebyshev polynomials for parametrization of the univariate functions with an extra nonlinearity for enhanced performance. We then present a systematic investigation of how choices of the optimizer, representation, and training configuration influence the performance of PINNs and PIKANs in the context of systems pharmacology modeling. We benchmark a wide range of first-order, second-order, and hybrid optimizers, including various learning rate schedulers. We use the new Optax library to identify the most effective combinations for learning gray-boxes under ill-posed, non-unique, and data-sparse conditions. We examine the influence of model architecture (MLP vs. KAN), numerical precision (single vs. double), the need for warm-up phases for second-order methods, and sensitivity to the initial learning rate. We also assess the optimizer scalability for larger models and analyze the trade-offs introduced by JAX in terms of computational efficiency and numerical accuracy. Using two representative systems pharmacology case studies - a pharmacokinetics model and a chemotherapy drug-response model - we offer practical guidance on selecting optimizers and representation models/architectures for robust and efficient gray-box discovery. Our findings provide actionable insights for improving the training of physics-informed networks in biomedical applications and beyond. 

**Abstract (ZH)**: Physics-Informed Kolmogorov-Arnold Networks (PIKANs)作为基于多层感知器的Physics-Informed Neural Networks (PINNs)的有力替代，正逐渐引起关注。尽管这两种表示模型都能解决逆问题并促进灰盒系统识别，但在准确性与速度方面的表现仍需进行全面探索。 đặc biệt地，我们引入了基于切比雪夫多项式的改进PIKAN架构tanh-cPIKAN，并增加了额外的非线性以增强性能。随后，我们系统性地研究了优化器、表示方法和训练配置的选择如何影响PINNs和PIKANs在系统药代动力学建模中的性能。我们基准测试了包括各种学习率调度器在内的广泛的一阶、二阶和混合优化器。我们利用新的Optax库，在病态、非唯一和数据稀疏条件下识别出最适合学习灰盒的最佳组合。我们还探讨了模型架构（MLP vs. KAN）、数值精度（单精度 vs. 双精度）、二阶方法的启动阶段需求以及初始学习率的敏感性的影响。我们还评估了大型模型下的优化器可扩展性，并分析了JAX在计算效率和数值精度方面的权衡。最后，我们使用两个代表性的系统药代动力学案例研究——药代动力学模型和化疗药物响应模型——提供选择优化器和表示模型/架构的实用指南，以实现稳健且高效的灰盒发现。我们的发现为在生物医学及其他应用中改进物理知情网络的训练提供了可操作的见解。 

---
# ChronoFormer: Time-Aware Transformer Architectures for Structured Clinical Event Modeling 

**Title (ZH)**: ChronoFormer: 时间意识的Transformer架构用于结构化临床事件建模 

**Authors**: Yuanyun Zhang, Shi Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.07373)  

**Abstract**: The temporal complexity of electronic health record (EHR) data presents significant challenges for predicting clinical outcomes using machine learning. This paper proposes ChronoFormer, an innovative transformer based architecture specifically designed to encode and leverage temporal dependencies in longitudinal patient data. ChronoFormer integrates temporal embeddings, hierarchical attention mechanisms, and domain specific masking techniques. Extensive experiments conducted on three benchmark tasks mortality prediction, readmission prediction, and long term comorbidity onset demonstrate substantial improvements over current state of the art methods. Furthermore, detailed analyses of attention patterns underscore ChronoFormer's capability to capture clinically meaningful long range temporal relationships. 

**Abstract (ZH)**: 电子健康记录数据的时间复杂性为使用机器学习预测临床结果带来了重大挑战。本文提出了一种名为ChronoFormer的创新变压器架构，专门设计用于编码和利用 longitudinal 患者数据中的时间依赖性。ChronoFormer 结合了时间嵌入、分层注意机制和领域特定的遮蔽技术。在死亡率预测、再住院预测和长期共病 onset 的三个基准任务上进行的广泛实验表明，ChronoFormer 在当前最先进的方法上取得了显著改进。此外，对注意模式的详细分析强调了 ChronoFormer 捕捉临床相关长时间范围内的时间关系的能力。 

---
# Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs 

**Title (ZH)**: 基于LLMs的多层级文本对齐以增强时间序列预测 

**Authors**: Taibiao Zhao, Xiaobing Chen, Mingxuan Sun  

**Link**: [PDF](https://arxiv.org/pdf/2504.07360)  

**Abstract**: The adaptation of large language models (LLMs) to time series forecasting poses unique challenges, as time series data is continuous in nature, while LLMs operate on discrete tokens. Despite the success of LLMs in natural language processing (NLP) and other structured domains, aligning time series data with language-based representations while maintaining both predictive accuracy and interpretability remains a significant hurdle. Existing methods have attempted to reprogram time series data into text-based forms, but these often fall short in delivering meaningful, interpretable results. In this paper, we propose a multi-level text alignment framework for time series forecasting using LLMs that not only improves prediction accuracy but also enhances the interpretability of time series representations. Our method decomposes time series into trend, seasonal, and residual components, which are then reprogrammed into component-specific text representations. We introduce a multi-level alignment mechanism, where component-specific embeddings are aligned with pre-trained word tokens, enabling more interpretable forecasts. Experiments on multiple datasets demonstrate that our method outperforms state-of-the-art models in accuracy while providing good interpretability. 

**Abstract (ZH)**: 大型语言模型（LLMs）在时间序列预测中的适应性面临着独特挑战，因为时间序列数据具有连续性，而LLMs处理的是离散的令牌。尽管LLMs在自然语言处理（NLP）和其他结构化领域取得了成功，但将时间序列数据与基于语言的表示相结合，同时保持预测准确性和可解释性，仍然是一个重大障碍。已有方法尝试将时间序列数据重新编程为文本形式，但这些方法往往无法提供有意义且可解释的结果。本文提出了一种用于时间序列预测的多层次文本对齐框架，该框架不仅提高了预测准确性，还增强了时间序列表示的可解释性。该方法将时间序列分解为趋势、季节性和残差组件，然后将其重新编程为特定组件的文本表示。我们引入了一种多层次对齐机制，其中特定组件的嵌入与预训练的单词令牌对齐，从而实现更具可解释性的预测。实验结果显示，与现有最先进模型相比，我们的方法在准确性上表现更优，同时具有良好的可解释性。 

---
# A Balanced Approach of Rapid Genetic Exploration and Surrogate Exploitation for Hyperparameter Optimization 

**Title (ZH)**: 快速遗传探索与代理利用的平衡方法在超参数优化中的应用 

**Authors**: Chul Kim, Inwhee Joe  

**Link**: [PDF](https://arxiv.org/pdf/2504.07359)  

**Abstract**: This paper proposes a new method for hyperparameter optimization (HPO) that balances exploration and exploitation. While evolutionary algorithms (EAs) show promise in HPO, they often struggle with effective exploitation. To address this, we integrate a linear surrogate model into a genetic algorithm (GA), allowing for smooth integration of multiple strategies. This combination improves exploitation performance, achieving an average improvement of 1.89 percent (max 6.55 percent, min -3.45 percent) over existing HPO methods. 

**Abstract (ZH)**: 本文提出了一种新的超参数优化方法，平衡了探索和利用。虽然进化算法在超参数优化中展现出潜力，但在有效的利用方面常常遇到挑战。为此，我们将线性代理模型集成到遗传算法中，实现了多种策略的平滑集成。这种结合提高了利用性能，相对于现有超参数优化方法，平均改善了1.89个百分点（最高6.55个百分点，最低-3.45个百分点）。 

---
# Quantum-Inspired Genetic Algorithm for Robust Source Separation in Smart City Acoustics 

**Title (ZH)**: 量子启发遗传算法在智能城市声学中稳健的源分离 

**Authors**: Minh K. Quan, Mayuri Wijayasundara, Sujeeva Setunge, Pubudu N. Pathirana  

**Link**: [PDF](https://arxiv.org/pdf/2504.07345)  

**Abstract**: The cacophony of urban sounds presents a significant challenge for smart city applications that rely on accurate acoustic scene analysis. Effectively analyzing these complex soundscapes, often characterized by overlapping sound sources, diverse acoustic events, and unpredictable noise levels, requires precise source separation. This task becomes more complicated when only limited training data is available. This paper introduces a novel Quantum-Inspired Genetic Algorithm (p-QIGA) for source separation, drawing inspiration from quantum information theory to enhance acoustic scene analysis in smart cities. By leveraging quantum superposition for efficient solution space exploration and entanglement to handle correlated sources, p-QIGA achieves robust separation even with limited data. These quantum-inspired concepts are integrated into a genetic algorithm framework to optimize source separation parameters. The effectiveness of our approach is demonstrated on two datasets: the TAU Urban Acoustic Scenes 2020 Mobile dataset, representing typical urban soundscapes, and the Silent Cities dataset, capturing quieter urban environments during the COVID-19 pandemic. Experimental results show that the p-QIGA achieves accuracy comparable to state-of-the-art methods while exhibiting superior resilience to noise and limited training data, achieving up to 8.2 dB signal-to-distortion ratio (SDR) in noisy environments and outperforming baseline methods by up to 2 dB with only 10% of the training data. This research highlights the potential of p-QIGA to advance acoustic signal processing in smart cities, particularly for noise pollution monitoring and acoustic surveillance. 

**Abstract (ZH)**: 量子启发遗传算法（p-QIGA）在智能城市声景分析中的应用 

---
# Zeus: Zero-shot LLM Instruction for Union Segmentation in Multimodal Medical Imaging 

**Title (ZH)**: Zeus: 零样本LLM指令在多模态医学成像中进行联合分割 

**Authors**: Siyuan Dai, Kai Ye, Guodong Liu, Haoteng Tang, Liang Zhan  

**Link**: [PDF](https://arxiv.org/pdf/2504.07336)  

**Abstract**: Medical image segmentation has achieved remarkable success through the continuous advancement of UNet-based and Transformer-based foundation backbones. However, clinical diagnosis in the real world often requires integrating domain knowledge, especially textual information. Conducting multimodal learning involves visual and text modalities shown as a solution, but collecting paired vision-language datasets is expensive and time-consuming, posing significant challenges. Inspired by the superior ability in numerous cross-modal tasks for Large Language Models (LLMs), we proposed a novel Vision-LLM union framework to address the issues. Specifically, we introduce frozen LLMs for zero-shot instruction generation based on corresponding medical images, imitating the radiology scanning and report generation process. {To better approximate real-world diagnostic processes}, we generate more precise text instruction from multimodal radiology images (e.g., T1-w or T2-w MRI and CT). Based on the impressive ability of semantic understanding and rich knowledge of LLMs. This process emphasizes extracting special features from different modalities and reunion the information for the ultimate clinical diagnostic. With generated text instruction, our proposed union segmentation framework can handle multimodal segmentation without prior collected vision-language datasets. To evaluate our proposed method, we conduct comprehensive experiments with influential baselines, the statistical results and the visualized case study demonstrate the superiority of our novel method.} 

**Abstract (ZH)**: 基于大型语言模型的医疗图像分割 multimodal 学习框架 

---
# Objaverse++: Curated 3D Object Dataset with Quality Annotations 

**Title (ZH)**: Objaverse++: 经质量标注的3D对象数据集 

**Authors**: Chendi Lin, Heshan Liu, Qunshu Lin, Zachary Bright, Shitao Tang, Yihui He, Minghao Liu, Ling Zhu, Cindy Le  

**Link**: [PDF](https://arxiv.org/pdf/2504.07334)  

**Abstract**: This paper presents Objaverse++, a curated subset of Objaverse enhanced with detailed attribute annotations by human experts. Recent advances in 3D content generation have been driven by large-scale datasets such as Objaverse, which contains over 800,000 3D objects collected from the Internet. Although Objaverse represents the largest available 3D asset collection, its utility is limited by the predominance of low-quality models. To address this limitation, we manually annotate 10,000 3D objects with detailed attributes, including aesthetic quality scores, texture color classifications, multi-object composition flags, transparency characteristics, etc. Then, we trained a neural network capable of annotating the tags for the rest of the Objaverse dataset. Through experiments and a user study on generation results, we demonstrate that models pre-trained on our quality-focused subset achieve better performance than those trained on the larger dataset of Objaverse in image-to-3D generation tasks. In addition, by comparing multiple subsets of training data filtered by our tags, our results show that the higher the data quality, the faster the training loss converges. These findings suggest that careful curation and rich annotation can compensate for the raw dataset size, potentially offering a more efficient path to develop 3D generative models. We release our enhanced dataset of approximately 500,000 curated 3D models to facilitate further research on various downstream tasks in 3D computer vision. In the near future, we aim to extend our annotations to cover the entire Objaverse dataset. 

**Abstract (ZH)**: Objaverse++：由人力专家详细标注的精选子集 

---
# Identifying regions of interest in whole slide images of renal cell carcinoma 

**Title (ZH)**: 在肾细胞癌全视野图像中识别感兴趣区域 

**Authors**: Mohammed Lamine Benomar, Nesma Settouti, Eric Debreuve, Xavier Descombes, Damien Ambrosetti  

**Link**: [PDF](https://arxiv.org/pdf/2504.07313)  

**Abstract**: The histopathological images contain a huge amount of information, which can make diagnosis an extremely timeconsuming and tedious task. In this study, we developed a completely automated system to detect regions of interest (ROIs) in whole slide images (WSI) of renal cell carcinoma (RCC), to reduce time analysis and assist pathologists in making more accurate decisions. The proposed approach is based on an efficient texture descriptor named dominant rotated local binary pattern (DRLBP) and color transformation to reveal and exploit the immense texture variability at the microscopic high magnifications level. Thereby, the DRLBPs retain the structural information and utilize the magnitude values in a local neighborhood for more discriminative power. For the classification of the relevant ROIs, feature extraction of WSIs patches was performed on the color channels separately to form the histograms. Next, we used the most frequently occurring patterns as a feature selection step to discard non-informative features. The performances of different classifiers on a set of 1800 kidney cancer patches originating from 12 whole slide images were compared and evaluated. Furthermore, the small size of the image dataset allows to investigate deep learning approach based on transfer learning for image patches classification by using deep features and fine-tuning methods. High recognition accuracy was obtained and the classifiers are efficient, the best precision result was 99.17% achieved with SVM. Moreover, transfer learning models perform well with comparable performance, and the highest precision using ResNet-50 reached 98.50%. The proposed approach results revealed a very efficient image classification and demonstrated efficacy in identifying ROIs. This study presents an automatic system to detect regions of interest relevant to the diagnosis of kidney cancer in whole slide histopathology images. 

**Abstract (ZH)**: 一种基于DRLBP和颜色转换的自动肾细胞 carcinoma感兴趣区域检测方法：应用于全-slide病理图像的诊断辅助系统 

---
# PAYADOR: A Minimalist Approach to Grounding Language Models on Structured Data for Interactive Storytelling and Role-playing Games 

**Title (ZH)**: PAYADOR：基于结构化数据为人机互动叙事和角色扮演游戏语言模型接地的极简主义方法 

**Authors**: Santiago Góngora, Luis Chiruzzo, Gonzalo Méndez, Pablo Gervás  

**Link**: [PDF](https://arxiv.org/pdf/2504.07304)  

**Abstract**: Every time an Interactive Storytelling (IS) system gets a player input, it is facing the world-update problem. Classical approaches to this problem consist in mapping that input to known preprogrammed actions, what can severely constrain the free will of the player. When the expected experience has a strong focus on improvisation, like in Role-playing Games (RPGs), this problem is critical. In this paper we present PAYADOR, a different approach that focuses on predicting the outcomes of the actions instead of representing the actions themselves. To implement this approach, we ground a Large Language Model to a minimal representation of the fictional world, obtaining promising results. We make this contribution open-source, so it can be adapted and used for other related research on unleashing the co-creativity power of RPGs. 

**Abstract (ZH)**: 每次交互式叙事(IS)系统接收玩家输入时，都会面临世界更新问题。经典的方法是将输入映射到预先编程的动作，这可能会严重限制玩家的自由意志。当期望的游戏体验强调即兴创作，如角色扮演游戏(RPGs)时，这个问题尤其关键。在本文中，我们提出了PAYADOR，一种不同的方法，侧重于预测动作的结果而不是代表这些动作本身。通过将一个大型语言模型锚定到虚构世界的最小表示，我们取得了令人鼓舞的结果。我们开源了这一贡献，以便他人可以将其 adapted 并用于其他相关研究，以释放RPGs的共创潜力。 

---
# Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches 

**Title (ZH)**: 多智能体大规模语言模型系统中响应一致性建模：共享上下文与独立上下文方法的比较分析 

**Authors**: Tooraj Helmi  

**Link**: [PDF](https://arxiv.org/pdf/2504.07303)  

**Abstract**: Large Language Models (LLMs) are increasingly utilized in multi-agent systems (MAS) to enhance collaborative problem-solving and interactive reasoning. Recent advancements have enabled LLMs to function as autonomous agents capable of understanding complex interactions across multiple topics. However, deploying LLMs in MAS introduces challenges related to context management, response consistency, and scalability, especially when agents must operate under memory limitations and handle noisy inputs. While prior research has explored optimizing context sharing and response latency in LLM-driven MAS, these efforts often focus on either fully centralized or decentralized configurations, each with distinct trade-offs.
In this paper, we develop a probabilistic framework to analyze the impact of shared versus separate context configurations on response consistency and response times in LLM-based MAS. We introduce the Response Consistency Index (RCI) as a metric to evaluate the effects of context limitations, noise, and inter-agent dependencies on system performance. Our approach differs from existing research by focusing on the interplay between memory constraints and noise management, providing insights into optimizing scalability and response times in environments with interdependent topics. Through this analysis, we offer a comprehensive understanding of how different configurations impact the efficiency of LLM-driven multi-agent systems, thereby guiding the design of more robust architectures. 

**Abstract (ZH)**: 大型语言模型（LLMs）在多代理系统（MAS）中的应用增强了协同问题解决和交互式推理的能力。最近的发展使LLMs能够充当自主代理，理解多个主题之间的复杂交互。然而，在MAS中部署LLMs带来了与上下文管理、响应一致性及可扩展性相关的新挑战，特别是在代理必须在内存限制和处理噪声输入的情况下运作时。尽管先前的研究探索了LLM驱动的MAS中的上下文共享和响应延迟优化，这些努力往往集中于完全集中或去中心化配置中的一种，每种配置都有其独特的权衡。

在本文中，我们开发了一种概率框架来分析共享上下文配置与独立上下文配置对响应一致性和响应时间的影响。我们引入响应一致性指数（RCI）作为度量标准，以评估上下文限制、噪声和代理间依赖性对系统性能的影响。我们的方法不同于现有研究，侧重于内存约束和噪声管理之间的互动，为在相互依赖主题的环境中优化可扩展性和响应时间提供了见解。通过这种分析，我们提供了LLM驱动的多代理系统中不同配置影响效率的全面理解，从而指导更 robust架构的设计。 

---
# A Multi-Phase Analysis of Blood Culture Stewardship: Machine Learning Prediction, Expert Recommendation Assessment, and LLM Automation 

**Title (ZH)**: 多阶段分析血液培养 stewardship：机器学习预测、专家建议评估及生成模型自动化 

**Authors**: Fatemeh Amrollahi, Nicholas Marshall, Fateme Nateghi Haredasht, Kameron C Black, Aydin Zahedivash, Manoj V Maddali, Stephen P. Ma, Amy Chang, MD Phar Stanley C Deresinski, Mary Kane Goldstein, Steven M. Asch, Niaz Banaei, Jonathan H Chen  

**Link**: [PDF](https://arxiv.org/pdf/2504.07278)  

**Abstract**: Blood cultures are often over ordered without clear justification, straining healthcare resources and contributing to inappropriate antibiotic use pressures worsened by the global shortage. In study of 135483 emergency department (ED) blood culture orders, we developed machine learning (ML) models to predict the risk of bacteremia using structured electronic health record (EHR) data and provider notes via a large language model (LLM). The structured models AUC improved from 0.76 to 0.79 with note embeddings and reached 0.81 with added diagnosis codes. Compared to an expert recommendation framework applied by human reviewers and an LLM-based pipeline, our ML approach offered higher specificity without compromising sensitivity. The recommendation framework achieved sensitivity 86%, specificity 57%, while the LLM maintained high sensitivity (96%) but over classified negatives, reducing specificity (16%). These findings demonstrate that ML models integrating structured and unstructured data can outperform consensus recommendations, enhancing diagnostic stewardship beyond existing standards of care. 

**Abstract (ZH)**: 血培养经常缺乏明确依据地被过度开具，从而加重了医疗资源的压力并加剧了由于全球短缺而导致的不适当抗生素使用压力。在对135483份急诊血液培养订单的研究中，我们使用结构化电子健康记录数据和提供者笔记（通过大型语言模型）开发了机器学习模型以预测败血症的风险。结构化模型的AUC从0.76提升至0.79，加入笔记嵌入后达到0.81。与人类审查者应用的专家推荐框架和基于大语言模型的管道相比，我们的机器学习方法在不牺牲灵敏度的情况下提供了更高的特异性。专家推荐框架的灵敏度为86%，特异性为57%，而大语言模型保持了高灵敏度（96%），但过度分类阴性结果，降低了特异性（16%）。这些发现表明，结合结构化和非结构化数据的机器学习模型可以超越现有标准的共识推荐，进一步增强诊断管理。 

---
# Evaluating Parameter-Based Training Performance of Neural Networks and Variational Quantum Circuits 

**Title (ZH)**: 基于参数训练的神经网络和变量化量子电路性能评估 

**Authors**: Michael Kölle, Alexander Feist, Jonas Stein, Sebastian Wölckert, Claudia Linnhoff-Popien  

**Link**: [PDF](https://arxiv.org/pdf/2504.07273)  

**Abstract**: In recent years, neural networks (NNs) have driven significant advances in machine learning. However, as tasks grow more complex, NNs often require large numbers of trainable parameters, which increases computational and energy demands. Variational quantum circuits (VQCs) offer a promising alternative: they leverage quantum mechanics to capture intricate relationships and typically need fewer parameters. In this work, we evaluate NNs and VQCs on simple supervised and reinforcement learning tasks, examining models with different parameter sizes. We simulate VQCs and execute selected parts of the training process on real quantum hardware to approximate actual training times. Our results show that VQCs can match NNs in performance while using significantly fewer parameters, despite longer training durations. As quantum technology and algorithms advance, and VQC architectures improve, we posit that VQCs could become advantageous for certain machine learning tasks. 

**Abstract (ZH)**: 近年来，神经网络在机器学习领域取得了显著进步。然而，随着任务复杂性的增加，神经网络往往需要大量的训练参数，这会增加计算和能耗需求。变分量子电路（VQCs）提供了一种有前途的替代方案：它们利用量子力学捕捉复杂的相互关系，并且通常所需的参数较少。在本工作中，我们评估了神经网络和变分量子电路在简单的监督学习和强化学习任务上的表现，研究了不同参数规模的模型。我们模拟了变分量子电路，并在实际量子硬件上执行了部分训练过程，以逼近实际的训练时间。结果显示，尽管训练时间更长，但变分量子电路在性能上可以与神经网络相媲美，同时使用了显著较少的参数。随着量子技术、算法的发展以及变分量子电路架构的改进，我们认为变分量子电路在某些机器学习任务上可能具有优势。 

---
# SemEval-2025 Task 5: LLMs4Subjects -- LLM-based Automated Subject Tagging for a National Technical Library's Open-Access Catalog 

**Title (ZH)**: SemEval-2025 任务5：LLMs4Subjects ——基于LLM的自动主题标签标注用于国家级技术图书馆的开放访问目录 

**Authors**: Jennifer D'Souza, Sameer Sadruddin, Holger Israel, Mathias Begoin, Diana Slawig  

**Link**: [PDF](https://arxiv.org/pdf/2504.07199)  

**Abstract**: We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated subject tagging for scientific and technical records in English and German using the GND taxonomy. Participants developed LLM-based systems to recommend top-k subjects, evaluated through quantitative metrics (precision, recall, F1-score) and qualitative assessments by subject specialists. Results highlight the effectiveness of LLM ensembles, synthetic data generation, and multilingual processing, offering insights into applying LLMs for digital library classification. 

**Abstract (ZH)**: SemEval-2025 任务 5: LLMs4Subjects——一项使用GND分类法对英文和德文科技记录进行自动化学科标签化的共享任务 

---
# Face-LLaVA: Facial Expression and Attribute Understanding through Instruction Tuning 

**Title (ZH)**: Face-LLaVA：通过指令调整实现面部表情和属性理解 

**Authors**: Ashutosh Chaubey, Xulang Guan, Mohammad Soleymani  

**Link**: [PDF](https://arxiv.org/pdf/2504.07198)  

**Abstract**: The human face plays a central role in social communication, necessitating the use of performant computer vision tools for human-centered applications. We propose Face-LLaVA, a multimodal large language model for face-centered, in-context learning, including facial expression and attribute recognition. Additionally, Face-LLaVA is able to generate natural language descriptions that can be used for reasoning. Leveraging existing visual databases, we first developed FaceInstruct-1M, a face-centered database for instruction tuning MLLMs for face processing. We then developed a novel face-specific visual encoder powered by Face-Region Guided Cross-Attention that integrates face geometry with local visual features. We evaluated the proposed method across nine different datasets and five different face processing tasks, including facial expression recognition, action unit detection, facial attribute detection, age estimation and deepfake detection. Face-LLaVA achieves superior results compared to existing open-source MLLMs and competitive performance compared to commercial solutions. Our model output also receives a higher reasoning rating by GPT under a zero-shot setting across all the tasks. Both our dataset and model wil be released at this https URL to support future advancements in social AI and foundational vision-language research. 

**Abstract (ZH)**: 人类面部在社会交流中扮演着核心角色，需要高性能的计算机视觉工具支持以中心的人本应用。我们提出了Face-LLaVA，一个以面部为中心的多模态大型语言模型，包括面部表情和属性识别。此外，Face-LLaVA 能够生成可用于推理的自然语言描述。利用现有的视觉数据库，我们首先开发了FaceInstruct-1M，这是一个以面部为中心的数据集，用于指令调优面向面部处理的多模态大语言模型。然后，我们开发了一个基于面部区域引导交叉注意力的新型面部专用视觉编码器，将面部几何与局部视觉特征整合起来。我们在九个不同的数据集和五种不同的面部处理任务上评估了提出的方法，包括面部表情识别、动作单元检测、面部属性检测、年龄估计和深度伪造检测。Face-LLaVA 在所有任务上均优于现有开源多模态大语言模型，并与商业解决方案具有竞争力。我们的模型输出在零样本设置下也获得了 GPT 更高的推理评分。我们的数据集和模型将在以下地址发布，以支持未来社会人工智能和基础视觉-语言研究的发展。 

---
# HypoEval: Hypothesis-Guided Evaluation for Natural Language Generation 

**Title (ZH)**: HypoEval：基于假设的自然语言生成评估方法 

**Authors**: Mingxuan Li, Hanchen Li, Chenhao Tan  

**Link**: [PDF](https://arxiv.org/pdf/2504.07174)  

**Abstract**: Large language models (LLMs) have demonstrated great potential for automating the evaluation of natural language generation. Previous frameworks of LLM-as-a-judge fall short in two ways: they either use zero-shot setting without consulting any human input, which leads to low alignment, or fine-tune LLMs on labeled data, which requires a non-trivial number of samples. Moreover, previous methods often provide little reasoning behind automated evaluations. In this paper, we propose HypoEval, Hypothesis-guided Evaluation framework, which first uses a small corpus of human evaluations to generate more detailed rubrics for human judgments and then incorporates a checklist-like approach to combine LLM's assigned scores on each decomposed dimension to acquire overall scores. With only 30 human evaluations, HypoEval achieves state-of-the-art performance in alignment with both human rankings (Spearman correlation) and human scores (Pearson correlation), on average outperforming G-Eval by 11.86% and fine-tuned Llama-3.1-8B-Instruct with at least 3 times more human evaluations by 11.95%. Furthermore, we conduct systematic studies to assess the robustness of HypoEval, highlighting its effectiveness as a reliable and interpretable automated evaluation framework. 

**Abstract (ZH)**: HypoEval：假设导向的评价框架 

---
# Trustworthy AI Must Account for Intersectionality 

**Title (ZH)**: 可信的人工智能必须考虑性别交集性 

**Authors**: Jesse C. Cresswell  

**Link**: [PDF](https://arxiv.org/pdf/2504.07170)  

**Abstract**: Trustworthy AI encompasses many aspirational aspects for aligning AI systems with human values, including fairness, privacy, robustness, explainability, and uncertainty quantification. However, efforts to enhance one aspect often introduce unintended trade-offs that negatively impact others, making it challenging to improve all aspects simultaneously. In this position paper, we review notable approaches to these five aspects and systematically consider every pair, detailing the negative interactions that can arise. For example, applying differential privacy to model training can amplify biases in the data, undermining fairness. Drawing on these findings, we take the position that addressing trustworthiness along each axis in isolation is insufficient. Instead, research on Trustworthy AI must account for intersectionality between aspects and adopt a holistic view across all relevant axes at once. To illustrate our perspective, we provide guidance on how researchers can work towards integrated trustworthiness, a case study on how intersectionality applies to the financial industry, and alternative views to our position. 

**Abstract (ZH)**: 可信的人工智能涵盖了与人类价值观对齐的许多 aspirational 方面，包括公平性、隐私保护、鲁棒性、可解释性和不确定性量化。然而，增强其中一个方面往往会导致对其他方面的意外权衡，从而使同时改进所有方面变得困难。在这篇立场论文中，我们回顾了这五个方面的显著方法，并系统地考虑了每一对，详细分析了可能出现的负面相互作用。例如，将差分隐私应用于模型训练可能会放大数据中的偏差，损害公平性。基于这些发现，我们认为仅孤立地针对每个轴线解决可信性是不足的。相反，可信的人工智能研究必须考虑各方面的交汇性，并同时从所有相关轴的角度采取整体视图。为了阐明我们的观点，我们提供了研究人员如何朝着集成可信性的方向工作的指导、金融行业的案例研究以及对我们观点的替代视角。 

---
# PLM-eXplain: Divide and Conquer the Protein Embedding Space 

**Title (ZH)**: PLM-eXplain：分解蛋白嵌入空间 

**Authors**: Jan van Eck, Dea Gogishvili, Wilson Silva, Sanne Abeln  

**Link**: [PDF](https://arxiv.org/pdf/2504.07156)  

**Abstract**: Protein language models (PLMs) have revolutionised computational biology through their ability to generate powerful sequence representations for diverse prediction tasks. However, their black-box nature limits biological interpretation and translation to actionable insights. We present an explainable adapter layer - PLM-eXplain (PLM-X), that bridges this gap by factoring PLM embeddings into two components: an interpretable subspace based on established biochemical features, and a residual subspace that preserves the model's predictive power. Using embeddings from ESM2, our adapter incorporates well-established properties, including secondary structure and hydropathy while maintaining high performance. We demonstrate the effectiveness of our approach across three protein-level classification tasks: prediction of extracellular vesicle association, identification of transmembrane helices, and prediction of aggregation propensity. PLM-X enables biological interpretation of model decisions without sacrificing accuracy, offering a generalisable solution for enhancing PLM interpretability across various downstream applications. This work addresses a critical need in computational biology by providing a bridge between powerful deep learning models and actionable biological insights. 

**Abstract (ZH)**: Protein语言模型（PLMs）通过生成多样化预测任务的强大序列表示，彻底改变了计算生物学。然而，其黑盒性质限制了生物解释和翻译为可操作的见解。我们提出了一个可解释的适配器层——PLM解释（PLM-X），通过将PLM嵌入分解为两个组件来弥合这一差距：基于已建立的生物化学特征的可解释子空间，以及保留模型预测能力的残差子空间。使用ESM2的嵌入，我们的适配器整合了包括二级结构和亲水性在内的已建立属性，同时保持高性能。我们在三个蛋白质级别分类任务中验证了我们方法的有效性：细胞外囊泡关联预测、跨膜螺旋鉴定以及聚集倾向预测。PLM-X在不牺牲准确性的情况下提供了模型决策的生物解释，为增强各种下游应用中PLM的解释性提供了通用解决方案。本工作通过在强大深度学习模型和可操作生物学洞察之间架起桥梁，满足了计算生物学中的一个关键需求。 

---
# Secure Text Mail Encryption with Generative Adversarial Networks 

**Title (ZH)**: 基于生成对抗网络的Secure Text Mail Encryption 

**Authors**: Alexej Schelle  

**Link**: [PDF](https://arxiv.org/pdf/2504.07140)  

**Abstract**: This work presents an encryption model based on Generative Adversarial Networks (GANs). Encryption of RTF-8 data is realized by dynamically generating decimal numbers that lead to the encryption and decryption of alphabetic strings in integer representation by simple addition rules, the modulus of the dimension of the considered alphabet. The binary numbers for the private dynamical keys correlate with the binary numbers of public reference keys from a mapping defined by the specific GAN configuration. For reversible encryption with bijective mapping between dynamic and reference keys as defined by the GAN encryptor with random combinations of NOT logical gates between bitwise subcomponents of the transmitted text signal, secure text encryption can be realized by transferring a GAN-encrypted public key with encrypted text from a sender to a receiver. Using the technique described above, secure text mail transfer can be realized from component-wise encryption of text mail strings with total key sizes of up to $10^{8}$ bits that define random decimal numbers obtained from the GAN. From the present model, we assert that encrypted texts can be transmitted more efficiently and securely than from RSA encryption, as long as users of the specific configuration of the GAN encryption model are unaware of the GAN encryptor circuit. 

**Abstract (ZH)**: 基于生成对抗网络（GANs）的加密模型 

---
# Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering 

**Title (ZH)**: 大型语言模型（LLM）在软件安全中的应用：代码分析、恶意软件分析与逆向工程 

**Authors**: Hamed Jelodar, Samita Bai, Parisa Hamedi, Hesamodin Mohammadian, Roozbeh Razavi-Far, Ali Ghorbani  

**Link**: [PDF](https://arxiv.org/pdf/2504.07137)  

**Abstract**: Large Language Models (LLMs) have recently emerged as powerful tools in cybersecurity, offering advanced capabilities in malware detection, generation, and real-time monitoring. Numerous studies have explored their application in cybersecurity, demonstrating their effectiveness in identifying novel malware variants, analyzing malicious code structures, and enhancing automated threat analysis. Several transformer-based architectures and LLM-driven models have been proposed to improve malware analysis, leveraging semantic and structural insights to recognize malicious intent more accurately. This study presents a comprehensive review of LLM-based approaches in malware code analysis, summarizing recent advancements, trends, and methodologies. We examine notable scholarly works to map the research landscape, identify key challenges, and highlight emerging innovations in LLM-driven cybersecurity. Additionally, we emphasize the role of static analysis in malware detection, introduce notable datasets and specialized LLM models, and discuss essential datasets supporting automated malware research. This study serves as a valuable resource for researchers and cybersecurity professionals, offering insights into LLM-powered malware detection and defence strategies while outlining future directions for strengthening cybersecurity resilience. 

**Abstract (ZH)**: 大型语言模型（LLMs）最近已经成为网络安全领域强大的工具，提供先进的恶意软件检测、生成和实时监控能力。多项研究探讨了其在网络安全中的应用，展示了其在识别新型恶意软件变种、分析恶意代码结构以及增强自动化威胁分析方面的有效性。提出了多种基于变换器的架构和LLM驱动的模型，以提高恶意软件分析的准确性，利用语义和结构洞察来更准确地识别恶意意图。本研究综述了基于LLM的恶意软件代码分析方法，总结了 recent 进展、趋势和方法论。我们审查了重要学术工作来绘制研究景观，识别关键挑战，并强调LLM驱动的网络安全中的新兴创新。此外，我们强调静态分析在恶意软件检测中的作用，介绍了重要的数据集和专门的LLM模型，并讨论了支持自动化恶意软件研究的重要数据集。本研究为研究人员和网络安全专业人员提供有价值的资源，提供了有关LLM驱动的恶意软件检测和防御策略的见解，并指出了增强网络安全韧性的未来方向。 

---
# Sacred or Secular? Religious Bias in AI-Generated Financial Advice 

**Title (ZH)**: 神圣还是世俗？AI生成的金融建议中的宗教偏见 

**Authors**: Muhammad Salar Khan, Hamza Umer  

**Link**: [PDF](https://arxiv.org/pdf/2504.07118)  

**Abstract**: This study examines religious biases in AI-generated financial advice, focusing on ChatGPT's responses to financial queries. Using a prompt-based methodology and content analysis, we find that 50% of the financial emails generated by ChatGPT exhibit religious biases, with explicit biases present in both ingroup and outgroup interactions. While ingroup biases personalize responses based on religious alignment, outgroup biases introduce religious framing that may alienate clients or create ideological friction. These findings align with broader research on AI bias and suggest that ChatGPT is not merely reflecting societal biases but actively shaping financial discourse based on perceived religious identity. Using the Critical Algorithm Studies framework, we argue that ChatGPT functions as a mediator of financial narratives, selectively reinforcing religious perspectives. This study underscores the need for greater transparency, bias mitigation strategies, and regulatory oversight to ensure neutrality in AI-driven financial services. 

**Abstract (ZH)**: 本研究考察了AI生成的金融建议中的宗教偏见，重点分析了ChatGPT对金融查询的回应。通过基于提示的方法和内容分析，我们发现ChatGPT生成的50%的金融电子邮件表现出宗教偏见，其中既存在于内部群体间也存在于外部群体间的交互中。内部群体偏见基于宗教一致性个性化回应，外部群体偏见则引入宗教框架，可能 alienate 客户或引发意识形态摩擦。这些发现与更广泛的AI偏见研究相吻合，表明ChatGPT不仅反映了社会偏见，还在基于感知的宗教身份基础上主动塑造金融 discourse。利用批判性算法研究框架，我们argue ChatGPT作为金融叙事的中介，选择性地强化宗教视角。本研究强调了在AI驱动的金融服务中增强透明度、偏见缓解策略以及监管监督的必要性，以确保中立性。 

---
# RP-SAM2: Refining Point Prompts for Stable Surgical Instrument Segmentation 

**Title (ZH)**: RP-SAM2: 优化点提示以实现稳定的手术器械分割 

**Authors**: Nuren Zhaksylyk, Ibrahim Almakky, Jay Paranjape, S. Swaroop Vedula, Shameema Sikder, Vishal M. Patel, Mohammad Yaqub  

**Link**: [PDF](https://arxiv.org/pdf/2504.07117)  

**Abstract**: Accurate surgical instrument segmentation is essential in cataract surgery for tasks such as skill assessment and workflow optimization. However, limited annotated data makes it difficult to develop fully automatic models. Prompt-based methods like SAM2 offer flexibility yet remain highly sensitive to the point prompt placement, often leading to inconsistent segmentations. We address this issue by introducing RP-SAM2, which incorporates a novel shift block and a compound loss function to stabilize point prompts. Our approach reduces annotator reliance on precise point positioning while maintaining robust segmentation capabilities. Experiments on the Cataract1k dataset demonstrate that RP-SAM2 improves segmentation accuracy, with a 2% mDSC gain, a 21.36% reduction in mHD95, and decreased variance across random single-point prompt results compared to SAM2. Additionally, on the CaDIS dataset, pseudo masks generated by RP-SAM2 for fine-tuning SAM2's mask decoder outperformed those generated by SAM2. These results highlight RP-SAM2 as a practical, stable and reliable solution for semi-automatic instrument segmentation in data-constrained medical settings. The code is available at this https URL. 

**Abstract (ZH)**: 准确的手术器械分割对于白内障手术中的技能评估和工作流程优化至关重要。然而，标注数据的限制使得开发完全自动的模型变得困难。SAM2等基于提示的方法虽具有灵活性，但对点提示位置的高度敏感性常导致分割结果不一致。我们通过引入RP-SAM2解决了这一问题，该方法结合了一个新型移位块和复合损失函数以稳定点提示。我们的方法减少了对精确点定位的标注员依赖，同时保持了稳健的分割能力。实验结果表明，RP-SAM2在Cataract1k数据集上的分割准确率得到提高，mDSC提升2%，mHD95减少21.36%，并且随机单点提示结果的方差降低。此外，在CaDIS数据集上，RP-SAM2生成的伪掩码在Fine-tuning SAM2的掩码解码器时表现出色，优于SAM2生成的掩码。这些结果突显了RP-SAM2在数据受限医疗环境下的实用、稳定和可靠半自动器械分割解决方案。代码可在以下链接获取：this https URL。 

---
# ChatBench: From Static Benchmarks to Human-AI Evaluation 

**Title (ZH)**: ChatBench: 从静态基准到-human-AI评估 

**Authors**: Serina Chang, Ashton Anderson, Jake M. Hofman  

**Link**: [PDF](https://arxiv.org/pdf/2504.07114)  

**Abstract**: With the rapid adoption of LLM-based chatbots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e., "AI-alone"). Here, we design and conduct a user study to convert MMLU questions into user-AI conversations, by seeding the user with the question and having them carry out a conversation with the LLM to answer their question. We release ChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144K answers and 7,336 user-AI conversations. We find that AI-alone accuracy fails to predict user-AI accuracy, with significant differences across multiple subjects (math, physics, and moral reasoning), and we analyze the user-AI conversations to provide insight into how they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a user simulator on a subset of ChatBench improves its ability to estimate user-AI accuracies, increasing correlation on held-out questions by more than 20 points, creating possibilities for scaling interactive evaluation. 

**Abstract (ZH)**: 基于LLM的聊天机器人的快速采用亟需评估人类与LLM合作所能达到的成果。然而，标准基准如MMLU仅评估LLM单独的能力。在这里，我们设计并执行了一项用户研究，将MMLU问题转化为用户-LLM对话，通过向用户提供问题并让他们与LLM进行对话以回答问题。我们发布了ChatBench数据集，包含396个问题和两个LLM的AI-alone、用户-alone及用户-LLM数据，共计144,000个答案和7,336个用户-LLM对话。我们发现AI-alone的准确性无法预测用户-LLM的准确性，并在多个主题（数学、物理和道德推理）上发现了显著差异。我们分析了用户-LLM对话以揭示它们与AI-alone基准的差异。最后，我们显示在ChatBench的一部分数据上 fine-tune 用户模拟器能够提升其估计用户-LLM准确性的能力，在保留问题上显著提高相关性超过20个百分点，为扩展交互式评估提供了可能性。 

---
# OSCAR: Online Soft Compression And Reranking 

**Title (ZH)**: OSCAR: 在线软压缩与重排rankxing 

**Authors**: Maxime Louis, Thibault Formal, Hervé Dejean, Stéphane Clinchant  

**Link**: [PDF](https://arxiv.org/pdf/2504.07109)  

**Abstract**: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating external knowledge, leading to improved accuracy and relevance. However, scaling RAG pipelines remains computationally expensive as retrieval sizes grow. To address this, we introduce OSCAR, a novel query-dependent online soft compression method that reduces computational overhead while preserving performance. Unlike traditional hard compression methods, which shorten retrieved texts, or soft compression approaches, which map documents to continuous embeddings offline, OSCAR dynamically compresses retrieved information at inference time, eliminating storage overhead and enabling higher compression rates. Additionally, we extend OSCAR to simultaneously perform reranking, further optimizing the efficiency of the RAG pipeline. Our experiments demonstrate state-of-the-art performance with a 2-5x speed-up in inference and minimal to no loss in accuracy for LLMs ranging from 1B to 24B parameters. The models are available at: this https URL. 

**Abstract (ZH)**: 基于检索增强生成的OSCAR方法通过查询依赖的在线软压缩提高大型语言模型的性能，同时减少计算开销并保持高效。 

---
# OKRA: an Explainable, Heterogeneous, Multi-Stakeholder Job Recommender System 

**Title (ZH)**: OKRA：一种可解释的异质化多利益相关方求职推荐系统 

**Authors**: Roan Schellingerhout, Francesco Barile, Nava Tintarev  

**Link**: [PDF](https://arxiv.org/pdf/2504.07108)  

**Abstract**: The use of recommender systems in the recruitment domain has been labeled as 'high-risk' in recent legislation. As a result, strict requirements regarding explainability and fairness have been put in place to ensure proper treatment of all involved stakeholders. To allow for stakeholder-specific explainability, while also handling highly heterogeneous recruitment data, we propose a novel explainable multi-stakeholder job recommender system using graph neural networks: the Occupational Knowledge-based Recommender using Attention (OKRA). The proposed method is capable of providing both candidate- and company-side recommendations and explanations. We find that OKRA performs substantially better than six baselines in terms of nDCG for two datasets. Furthermore, we find that the tested models show a bias toward candidates and vacancies located in urban areas. Overall, our findings suggest that OKRA provides a balance between accuracy, explainability, and fairness. 

**Abstract (ZH)**: 在招聘领域使用推荐系统被近期的立法标记为“高风险”。因此，为了确保所有利益相关方的公正待遇，提出了严格的要求以保证解释性和公平性。为实现针对不同利益相关方的个性化解释，并处理高度异构的招聘数据，我们提出了一种基于图神经网络的 occupatioNal Knowledge-based Recommender using Attention (OKRA) 可解释多利益相关方求职推荐系统。该方法能够为求职者和公司提供推荐和解释。实验结果表明，与六种基线方法相比，OKRA 在两个数据集中 nDCG 方面表现显著更好。此外，我们发现测试模型对城市地区求职者和职位存在偏向。总体而言，我们的研究发现表明 OKRA 在准确性、解释性和公平性之间提供了良好的平衡。 

---
# FG-RAG: Enhancing Query-Focused Summarization with Context-Aware Fine-Grained Graph RAG 

**Title (ZH)**: FG-RAG: 基于上下文感知细粒度图RAG的查询焦点摘要增强 

**Authors**: Yubin Hong, Chaofan Li, Jingyi Zhang, Yingxia Shao  

**Link**: [PDF](https://arxiv.org/pdf/2504.07103)  

**Abstract**: Retrieval-Augmented Generation (RAG) enables large language models to provide more precise and pertinent responses by incorporating external knowledge. In the Query-Focused Summarization (QFS) task, GraphRAG-based approaches have notably enhanced the comprehensiveness and diversity of generated responses. However, existing GraphRAG-based approaches predominantly focus on coarse-grained information summarization without being aware of the specific query, and the retrieved content lacks sufficient contextual information to generate comprehensive responses. To address the deficiencies of current RAG systems, we propose Context-Aware Fine-Grained Graph RAG (FG-RAG) to enhance the performance of the QFS task. FG-RAG employs Context-Aware Entity Expansion in graph retrieval to expand the coverage of retrieved entities in the graph, thus providing enough contextual information for the retrieved content. Furthermore, FG-RAG utilizes Query-Level Fine-Grained Summarization to incorporate fine-grained details during response generation, enhancing query awareness for the generated summarization. Our evaluation demonstrates that FG-RAG outperforms other RAG systems in multiple metrics of comprehensiveness, diversity, and empowerment when handling the QFS task. Our implementation is available at this https URL. 

**Abstract (ZH)**: 检索增强生成（RAG）通过集成外部知识，使大型语言模型能够提供更为精确和相关性的响应。在查询导向的摘要（QFS）任务中，基于GraphRAG的方法显著提高了生成摘要的全面性和多样性。然而，现有的基于GraphRAG的方法主要侧重于粗粒度的信息摘要，并未意识到具体的查询需求，检索的内容缺乏足够的上下文信息，从而难以生成全面的摘要。为解决当前RAG系统的不足，我们提出了上下文感知细粒度GraphRAG（FG-RAG）以提高QFS任务的性能。FG-RAG采用上下文感知实体扩展在图检索中的应用，扩展图中检索实体的覆盖范围，从而为检索内容提供足够的上下文信息。此外，FG-RAG采用查询级别细粒度摘要生成，在响应生成过程中融入细粒度细节，增强生成摘要的查询意识。我们的评估表明，FG-RAG在处理QFS任务的多个全面性、多样性和 empowerment指标上优于其他RAG系统。我们的实现可从这个网址获取。 

---
# Personalized Recommendation Models in Federated Settings: A Survey 

**Title (ZH)**: 联邦设置下的个性化推荐模型：一个综述 

**Authors**: Chunxu Zhang, Guodong Long, Zijian Zhang, Zhiwei Li, Honglei Zhang, Qiang Yang, Bo Yang  

**Link**: [PDF](https://arxiv.org/pdf/2504.07101)  

**Abstract**: Federated recommender systems (FedRecSys) have emerged as a pivotal solution for privacy-aware recommendations, balancing growing demands for data security and personalized experiences. Current research efforts predominantly concentrate on adapting traditional recommendation architectures to federated environments, optimizing communication efficiency, and mitigating security vulnerabilities. However, user personalization modeling, which is essential for capturing heterogeneous preferences in this decentralized and non-IID data setting, remains underexplored. This survey addresses this gap by systematically exploring personalization in FedRecSys, charting its evolution from centralized paradigms to federated-specific innovations. We establish a foundational definition of personalization in a federated setting, emphasizing personalized models as a critical solution for capturing fine-grained user preferences. The work critically examines the technical hurdles of building personalized FedRecSys and synthesizes promising methodologies to meet these challenges. As the first consolidated study in this domain, this survey serves as both a technical reference and a catalyst for advancing personalized FedRecSys research. 

**Abstract (ZH)**: 联邦推荐系统（FedRecSys）已成为一种关键的隐私感知推荐解决方案，平衡了日益增长的数据安全需求和个人化体验。当前的研究主要集中在将传统的推荐架构适应联邦环境，优化通信效率和缓解安全漏洞。然而，在这种分散且非IID数据设置中捕获异质偏好所需的核心个性化建模仍然尚未充分探索。本综述通过系统地探讨联邦环境中的个性化建模，从集中的范式到联邦特定的创新，填补了这一空白。我们为联邦环境中的个性化建立了一个基础定义，强调个性化模型是捕捉细粒度用户偏好的关键解决方案。本文批判性地评估了构建个性化FedRecSys的技术障碍，并总结了应对这些挑战的有前途的方法。作为该领域的首个综合研究，本综述既提供了一项技术参考，也成为推动个性化FedRecSys研究发展的催化剂。 

---
