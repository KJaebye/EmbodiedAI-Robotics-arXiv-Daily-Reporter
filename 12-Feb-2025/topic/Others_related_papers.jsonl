{'arxiv_id': 'arXiv:2502.07595', 'title': 'Distributed Coverage Control for Time-Varying Spatial Processes', 'authors': 'Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini', 'link': 'https://arxiv.org/abs/2502.07595', 'abstract': 'Multi-robot systems are essential for environmental monitoring, particularly for tracking spatial phenomena like pollution, soil minerals, and water salinity, and more. This study addresses the challenge of deploying a multi-robot team for optimal coverage in environments where the density distribution, describing areas of interest, is unknown and changes over time. We propose a fully distributed control strategy that uses Gaussian Processes (GPs) to model the spatial field and balance the trade-off between learning the field and optimally covering it. Unlike existing approaches, we address a more realistic scenario by handling time-varying spatial fields, where the exploration-exploitation trade-off is dynamically adjusted over time. Each robot operates locally, using only its own collected data and the information shared by the neighboring robots. To address the computational limits of GPs, the algorithm efficiently manages the volume of data by selecting only the most relevant samples for the process estimation. The performance of the proposed algorithm is evaluated through several simulations and experiments, incorporating real-world data phenomena to validate its effectiveness.', 'abstract_zh': '多机器人系统在环境监测中的应用对于追踪诸如污染、土壤矿物和水质盐度等空间现象至关重要。本文解决了一个多机器人团队在密度分布未知且随时间变化的环境中进行最优覆盖的挑战。我们提出了一种完全分布式的控制策略，利用高斯过程（GPs）来建模空间场，并平衡学习空间场和最优覆盖之间的trade-off。不同于现有方法，我们通过处理时间变化的空间场来解决一个更现实的场景，其中探索与利用之间的trade-off会动态调整。每个机器人仅使用自身收集的数据及其邻居机器人的信息进行本地操作。为了解决高斯过程的计算限制，算法通过仅选择对过程估计最相关的样本来有效管理数据volume。通过多次模拟和实验，结合真实世界的数据现象来评估所提算法的性能，并验证其有效性。', 'title_zh': '时间变化空间过程的分布式覆盖控制'}
{'arxiv_id': 'arXiv:2502.07255', 'title': 'Beyond Confidence: Adaptive Abstention in Dual-Threshold Conformal Prediction for Autonomous System Perception', 'authors': 'Divake Kumar, Nastaran Darabi, Sina Tayebati, Amit Ranjan Trivedi', 'link': 'https://arxiv.org/abs/2502.07255', 'abstract': 'Safety-critical perception systems require both reliable uncertainty quantification and principled abstention mechanisms to maintain safety under diverse operational conditions. We present a novel dual-threshold conformalization framework that provides statistically-guaranteed uncertainty estimates while enabling selective prediction in high-risk scenarios. Our approach uniquely combines a conformal threshold ensuring valid prediction sets with an abstention threshold optimized through ROC analysis, providing distribution-free coverage guarantees (\\ge 1 - \\alpha) while identifying unreliable predictions. Through comprehensive evaluation on CIFAR-100, ImageNet1K, and ModelNet40 datasets, we demonstrate superior robustness across camera and LiDAR modalities under varying environmental perturbations. The framework achieves exceptional detection performance (AUC: 0.993\\to0.995) under severe conditions while maintaining high coverage (>90.0\\%) and enabling adaptive abstention (13.5\\%\\to63.4\\%\\pm0.5) as environmental severity increases. For LiDAR-based perception, our approach demonstrates particularly strong performance, maintaining robust coverage (>84.5\\%) while appropriately abstaining from unreliable predictions. Notably, the framework shows remarkable stability under heavy perturbations, with detection performance (AUC: 0.995\\pm0.001) significantly outperforming existing methods across all modalities. Our unified approach bridges the gap between theoretical guarantees and practical deployment needs, offering a robust solution for safety-critical autonomous systems operating in challenging real-world conditions.', 'abstract_zh': '安全关键感知系统需要可靠的不确定性量化和规范化的规避机制，以在各种运行条件下维持安全性。我们提出了一种新型的双阈值一致性框架，该框架提供了统计保证的不确定性估计，并能够在高风险场景中进行选择性预测。该方法独特地结合了一种确保预测集有效的置信阈值和通过ROC分析优化的规避阈值，提供了自由分布的覆盖保证（≥1 - α）同时识别不可靠的预测。通过在CIFAR-100、ImageNet1K和ModelNet40数据集上的全面评估，我们在相机和LiDAR模态下展示了在不同环境干扰下的优越鲁棒性。在严重条件下，该框架实现了卓越的检测性能（AUC：0.993→0.995），同时保持高覆盖率（>90.0%），并能够适应性规避（13.5%→63.4%±0.5）随着环境严重性增加。对于基于LiDAR的感知，我们的方法特别表现出色，保持了鲁棒的覆盖率（>84.5%），同时适当地规避不可靠的预测。值得注意的是，该框架在重度干扰下表现出显著的稳定性，检测性能（AUC：0.995±0.001）在所有模态中均优于现有方法。我们的统一方法在理论保证和实际部署需求之间建立了桥梁，为在严峻实际条件下运行的安全关键自主系统提供了稳健的解决方案。', 'title_zh': '超越信心：自主系统感知中双阈值凝聚预测的自适应弃权'}
{'arxiv_id': 'arXiv:2502.07178', 'title': 'Online Aggregation of Trajectory Predictors', 'authors': 'Alex Tong, Apoorva Sharma, Sushant Veer, Marco Pavone, Heng Yang', 'link': 'https://arxiv.org/abs/2502.07178', 'abstract': 'Trajectory prediction, the task of forecasting future agent behavior from past data, is central to safe and efficient autonomous driving. A diverse set of methods (e.g., rule-based or learned with different architectures and datasets) have been proposed, yet it is often the case that the performance of these methods is sensitive to the deployment environment (e.g., how well the design rules model the environment, or how accurately the test data match the training data). Building upon the principled theory of online convex optimization but also going beyond convexity and stationarity, we present a lightweight and model-agnostic method to aggregate different trajectory predictors online. We propose treating each individual trajectory predictor as an "expert" and maintaining a probability vector to mix the outputs of different experts. Then, the key technical approach lies in leveraging online data -the true agent behavior to be revealed at the next timestep- to form a convex-or-nonconvex, stationary-or-dynamic loss function whose gradient steers the probability vector towards choosing the best mixture of experts. We instantiate this method to aggregate trajectory predictors trained on different cities in the NUSCENES dataset and show that it performs just as well, if not better than, any singular model, even when deployed on the out-of-distribution LYFT dataset.', 'abstract_zh': '基于在线凸优化原理的轻量级模型agnostic轨迹预测方法', 'title_zh': '在线聚合轨迹预测器'}
{'arxiv_id': 'arXiv:2502.07332', 'title': 'The Combined Problem of Online Task Assignment and Lifelong Path Finding in Logistics Warehouses: A Case Study', 'authors': 'Fengming Zhu, Fangzhen Lin, Weijia Xu, Yifei Guo', 'link': 'https://arxiv.org/abs/2502.07332', 'abstract': 'We study the combined problem of online task assignment and lifelong path finding, which is crucial for the logistics industries. However, most literature either (1) focuses on lifelong path finding assuming a given task assigner, or (2) studies the offline version of this problem where tasks are known in advance. We argue that, to maximize the system throughput, the online version that integrates these two components should be tackled directly. To this end, we introduce a formal framework of the combined problem and its solution concept. Then, we design a rule-based lifelong planner under a practical robot model that works well even in environments with severe local congestion. Upon that, we automate the search for the task assigner with respect to the underlying path planner. Simulation experiments conducted in warehouse scenarios at \\textit{Meituan}, one of the largest shopping platforms in China, demonstrate that (a)~\\textit{in terms of time efficiency}, our system requires only 83.77\\% of the execution time needed for the currently deployed system at Meituan, outperforming other SOTA algorithms by 8.09\\%; (b)~\\textit{in terms of economic efficiency}, ours can achieve the same throughput with only 60\\% of the agents currently in use.', 'abstract_zh': '我们研究了在线任务分配与终身路径规划的结合问题，这对于物流行业至关重要。然而，大多数文献要么（1）假定已有任务分配策略集中于终身路径规划，要么（2）研究任务已知的 Offline 版本问题。我们认为，为了最大化系统吞吐量，应该直接解决这两个组件的 Online 版本。为此，我们提出了该结合问题的形式化框架及其解的概念。然后，我们在实用的机器人模型下设计了一个基于规则的终身规划器，即使在严重局部拥堵的环境中也能发挥作用。在此基础上，我们针对底层路径规划器自动化了任务分配器的搜索。在中国最大的购物平台之一美团进行的仓库场景模拟实验表明，（a）在时间效率方面，我们的系统仅需目前美团部署系统运行时间的 83.77%，相比其他 SOTA 算法性能高出 8.09%；（b）在经济效率方面，我们的系统仅需当前使用的 60% 的代理就能达到相同的吞吐量。', 'title_zh': '在线任务分配与物流仓库终身路径查找的联合问题：一个案例研究'}
{'arxiv_id': 'arXiv:2502.07663', 'title': 'Human Decision-making is Susceptible to AI-driven Manipulation', 'authors': 'Sahand Sabour, June M. Liu, Siyang Liu, Chris Z. Yao, Shiyao Cui, Xuanming Zhang, Wen Zhang, Yaru Cao, Advait Bhat, Jian Guan, Wei Wu, Rada Mihalcea, Tim Althoff, Tatia M.C. Lee, Minlie Huang', 'link': 'https://arxiv.org/abs/2502.07663', 'abstract': "Artificial Intelligence (AI) systems are increasingly intertwined with daily life, assisting users in executing various tasks and providing guidance on decision-making. This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes. Through a randomized controlled trial with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts. Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit psychological tactics to reach its hidden objectives. By analyzing participants' decision patterns and shifts in their preference ratings post-interaction, we found significant susceptibility to AI-driven manipulation. Particularly, across both decision-making domains, participants interacting with the manipulative agents shifted toward harmful options at substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA: 42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional, 12.8%). Notably, our findings reveal that even subtle manipulative objectives (MA) can be as effective as employing explicit psychological strategies (SEMA) in swaying human decision-making. By revealing the potential for covert AI influence, this study highlights a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to ensure responsible deployment of AI technologies and protect human autonomy.", 'abstract_zh': '人工智能系统日益融入日常生活，协助用户执行各种任务并提供决策指导。这种整合引入了人工智能驱动操控的风险，这些系统可能会利用用户认知偏差和情绪脆弱性，引导用户走向不利的 Outcome。通过一项包含 233 名参与者的随机对照试验，我们探讨了人们在金融（例如，购买）和情感（例如，冲突解决）决策情境下对这种操控的易感性。参与者与三种人工智能代理之一交互：中立代理（NA）以用户利益最大化为目标，不进行明确干预，操控代理（MA）旨在隐蔽地影响信念和行为，或策略增强操控代理（SEMA），采用明确的心理战术来达成其隐秘目标。通过分析参与者交互后的决策模式及其偏好评分的变化，我们发现显著的易感性。特别地，在两个决策领域中，与操控代理互动的参与者选择有害选项的比例显著高于中立代理组（金融，MA：62.3%，SEMA：59.6%；情感，MA：42.3%，SEMA：41.5%），而中立代理组分别为金融 35.8% 和情感 12.8%。值得注意的是，我们的研究发现，即使是微妙的操控目标（MA）也能与明确的心理策略（SEMA）一样有效地影响人类的决策。通过揭示隐蔽的人工智能影响力的可能性，这项研究突显了人类-人工智能互动中的关键脆弱性，强调了需要伦理保护和监管框架以确保人工智能技术的负责任部署并保护人类自主性。', 'title_zh': '人类决策易受到AI驱动的操控'}
{'arxiv_id': 'arXiv:2502.07644', 'title': 'SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models', 'authors': 'Shihao Xia, Mengting He, Shuai Shao, Tingting Yu, Yiying Zhang, Linhai Song', 'link': 'https://arxiv.org/abs/2502.07644', 'abstract': "To govern smart contracts running on Ethereum, multiple Ethereum Request for Comment (ERC) standards have been developed, each having a set of rules to guide the behaviors of smart contracts. Violating the ERC rules could cause serious security issues and financial loss, signifying the importance of verifying smart contracts follow ERCs. Today's practices of such verification are to manually audit each single contract, use expert-developed program-analysis tools, or use large language models (LLMs), all of which are far from effective in identifying ERC rule violations. This paper introduces SymGPT, a tool that combines the natural language understanding of large language models (LLMs) with the formal guarantees of symbolic execution to automatically verify smart contracts' compliance with ERC rules. To develop SymGPT, we conduct an empirical study of 132 ERC rules from three widely used ERC standards, examining their content, security implications, and natural language descriptions. Based on this study, we design SymGPT by first instructing an LLM to translate ERC rules into a defined EBNF grammar. We then synthesize constraints from the formalized rules to represent scenarios where violations may occur and use symbolic execution to detect them. Our evaluation shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world contracts, including 1,375 violations with clear attack paths for stealing financial assets, demonstrating its effectiveness. Furthermore, SymGPT outperforms six automated techniques and a security-expert auditing service, underscoring its superiority over current smart contract analysis methods.", 'abstract_zh': '治理运行在以太坊上的智能合约：SymGPT结合大规模语言模型的自然语言理解和符号执行的正式保证，自动验证智能合约是否遵循ERC规则', 'title_zh': 'SymGPT: 结合符号执行与大规模语言模型审计智能合约'}
{'arxiv_id': 'arXiv:2502.07494', 'title': 'URECA: The Chain of Two Minimum Set Cover Problems exists behind Adaptation to Shifts in Semantic Code Search', 'authors': 'Seok-Ung Choi, Joonghyuk Hahn, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2502.07494', 'abstract': 'Adaptation is to make model learn the patterns shifted from the training distribution. In general, this adaptation is formulated as the minimum entropy problem. However, the minimum entropy problem has inherent limitation -- shifted initialization cascade phenomenon. We extend the relationship between the minimum entropy problem and the minimum set cover problem via Lebesgue integral. This extension reveals that internal mechanism of the minimum entropy problem ignores the relationship between disentangled representations, which leads to shifted initialization cascade. From the analysis, we introduce a new clustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA). URECA is an efficient clustering algorithm for the leverage of the relationships between disentangled representations. The update rule of URECA depends on Thresholdly-Updatable Stationary Assumption to dynamics as a released version of Stationary Assumption. This assumption helps URECA to transport disentangled representations with no errors based on the relationships between disentangled representations. URECA also utilize simulation trick to efficiently cluster disentangled representations. The wide range of evaluations show that URECA achieves consistent performance gains for the few-shot adaptation to diverse types of shifts along with advancement to State-of-The-Art performance in CoSQA in the scenario of query shift.', 'abstract_zh': '适配是让模型学习与训练分布偏移的模式。通常，这种适配被形式化为最小熵问题。然而，最小熵问题固有地存在局限性——转移初始化级联现象。我们通过勒贝格积分扩展了最小熵问题与最小集覆盖问题之间的关系。这一扩展揭示了最小熵问题的内部机制忽略了去纠缠表示之间的关系，导致转移初始化级联现象。通过对这一分析，我们引入了一种新的聚类算法——基于并查集的递归聚类算法（URECA）。URECA是一种利用去纠缠表示之间关系的高效聚类算法。URECA的更新规则依赖于阈值更新平稳假设，该假设是平稳假设的释放版本。这一假设帮助URECA基于去纠缠表示之间的关系无误地传输去纠缠表示。URECA还利用模拟技巧高效地聚类去纠缠表示。广泛的实际测试表明，URECA在查询偏移场景中实现了对多种类型偏移的少量样本适配的一致性能提升，并在CoSQA场景中取得了与最新技术水平相当甚至更好的性能。', 'title_zh': 'URECA: 适应语义代码搜索转移背后隐藏着两层最小集覆盖问题的链关系'}
{'arxiv_id': 'arXiv:2502.07452', 'title': 'Eliciting Rational Initial Weights in Gradual Argumentation', 'authors': 'Nir Oren, Bruno Yun', 'link': 'https://arxiv.org/abs/2502.07452', 'abstract': 'Many semantics for weighted argumentation frameworks assume that each argument is associated with an initial weight. However, eliciting these initial weights poses challenges: (1) accurately providing a specific numerical value is often difficult, and (2) individuals frequently confuse initial weights with acceptability degrees in the presence of other arguments. To address these issues, we propose an elicitation pipeline that allows one to specify acceptability degree intervals for each argument. By employing gradual semantics, we can refine these intervals when they are rational, restore rationality when they are not, and ultimately identify possible initial weights for each argument.', 'abstract_zh': '基于接受度区间的一种权重重言框架初始权重获取方法', 'title_zh': '诱导渐进论证中的合理初始权重'}
{'arxiv_id': 'arXiv:2502.07423', 'title': 'Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation', 'authors': 'Erik M. Lintunen, Nadia M. Ady, Sebastian Deterding, Christian Guckelsberger', 'link': 'https://arxiv.org/abs/2502.07423', 'abstract': 'Computational models offer powerful tools for formalising psychological theories, making them both testable and applicable in digital contexts. However, they remain little used in the study of motivation within psychology. We focus on the "need for competence", postulated as a key basic human need within Self-Determination Theory (SDT) -- arguably the most influential psychological framework for studying intrinsic motivation (IM). The need for competence is treated as a single construct across SDT texts. Yet, recent research has identified multiple, ambiguously defined facets of competence in SDT. We propose that these inconsistencies may be alleviated by drawing on computational models from the field of artificial intelligence, specifically from the domain of reinforcement learning (RL). By aligning the aforementioned facets of competence -- effectance, skill use, task performance, and capacity growth -- with existing RL formalisms, we provide a foundation for advancing competence-related theory in SDT and motivational psychology more broadly. The formalisms reveal underlying preconditions that SDT fails to make explicit, demonstrating how computational models can improve our understanding of IM. Additionally, our work can support a cycle of theory development by inspiring new computational models formalising aspects of the theory, which can then be tested empirically to refine the theory. While our research lays a promising foundation, empirical studies of these models in both humans and machines are needed, inviting collaboration across disciplines.', 'abstract_zh': '计算模型提供了正式化心理理论的强大工具，使这些理论既可测试又适用于数字环境。然而，它们在心理学动机研究中的应用仍然较少。我们关注自我决定理论（SDT）中提出的“能力需要”，这被认为是基本人类需要中的一个重要组成部分——或许是研究内在动机（IM）最有影响力的理论框架之一。能力需要在SDT文本中被视为单一的构建体。然而，近期研究已识别出SDT中多个含糊定义的能力方面。我们建议通过借鉴人工智能领域的计算模型，特别是强化学习（RL）领域的模型，来解决这些不一致之处。通过将上述能力方面的特征——效能、技能应用、任务表现、能力增长——与现有的RL形式化方法相匹配，我们为在SDT和更广泛的动机心理学中推进能力相关理论奠定了基础。这些形式化方法揭示了SDT未能明确指出的潜在前提条件，展示了计算模型如何改善我们对IM的理解。此外，我们的工作可以支持一个理论发展的循环，通过激发新的计算模型来形式化理论的各个方面，并通过经验研究进一步完善这些理论。虽然我们的研究奠定了有希望的基础，但未来在人类和机器中对这些模型的实证研究仍然需要，这将推动跨学科的合作。', 'title_zh': '通过计算内在动机构建胜任力需求的正式理论'}
{'arxiv_id': 'arXiv:2502.07350', 'title': 'KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems', 'authors': 'Jusheng Zhang, Zimeng Huang, Yijia Fan, Ningyuan Liu, Mingyan Li, Zhuojie Yang, Jiawei Yao, Jian Wang, Keze Wang', 'link': 'https://arxiv.org/abs/2502.07350', 'abstract': 'As scaling large language models faces prohibitive costs, multi-agent systems emerge as a promising alternative, though challenged by static knowledge assumptions and coordination inefficiencies. We introduces Knowledge-Aware Bayesian Bandits (KABB), a novel framework that enhances multi-agent system coordination through semantic understanding and dynamic adaptation. The framework features three key innovations: a three-dimensional knowledge distance model for deep semantic understanding, a dual-adaptation mechanism for continuous expert optimization, and a knowledge-aware Thompson Sampling strategy for efficient expert selection. Extensive evaluation demonstrates KABB achieves an optimal cost-performance balance, maintaining high performance while keeping computational demands relatively low in multi-agent coordination.', 'abstract_zh': '具有知识aware贝叶斯 bandits的多重代理系统协调方法：通过语义理解和动态适应优化多代理系统协调', 'title_zh': 'KABB：面向多agent系统的动态专家协调的知识感知贝叶斯多臂老虎机'}
{'arxiv_id': 'arXiv:2502.07347', 'title': 'Coarse Set Theory: A Mathematical Foundation for Coarse Ethics', 'authors': 'Takashi Izumo', 'link': 'https://arxiv.org/abs/2502.07347', 'abstract': 'In ethical decision-making, individuals are often evaluated based on generalized assessments rather than precise individual performance. This concept, known as Coarse Ethics (CE), has primarily been discussed in natural language without a formal mathematical foundation. This paper introduces Coarse Set Theory (CST) to establish a mathematical framework for CE. We define coarse sets using totally ordered sets and propose axioms that characterize the hierarchical relationships between elements and their groupings. Additionally, we introduce coarse-grained sets, which partition an underlying set into equivalence classes based on predefined criteria. We extend this framework by defining coarse mappings, which transform detailed individual data into coarser representations while maintaining essential structural properties. To measure the information loss, we employ Kullback-Leibler (KL) divergence, demonstrating how different coarse partitions affect the preservation of information. We illustrate how CST can be applied to real-world grading systems through theoretical formulations and empirical analysis. This study provides a rigorous foundation for CE, enabling a more systematic exploration of fairness, interpretability, and decision-making trade-offs.', 'abstract_zh': '在伦理决策中，个体常常基于泛化的评估而非精确的个体表现被评价。这一概念被称为粗集伦理（Coarse Ethics, CE），主要在自然语言中讨论，缺乏正式的数学基础。本文引入了粗集理论（Coarse Set Theory, CST）来为CE建立数学框架。我们使用完全有序集定义粗集，并提出了刻画元素及其分组之间层次关系的公理。此外，我们引入粗集，基于预定义的准则将基础集划分为等价类。通过定义粗映射，我们扩展了这一框架，这些粗映射将详细的个体数据转化为较粗的表示，同时保留基本的结构性质。为了衡量信息损失，我们采用Kullback-Leibler（KL）散度，展示了不同的粗划分如何影响信息的保留。本文通过理论推导和实证分析阐述了CST在实际评分系统中的应用。本研究为CE提供了坚实的数学基础，使其更系统地探索公平性、可解释性和决策权衡等问题。', 'title_zh': '粗糙集理论：粗糙伦理学的数学基础'}
{'arxiv_id': 'arXiv:2502.07764', 'title': 'Polynomial-Time Approximability of Constrained Reinforcement Learning', 'authors': 'Jeremy McMahan', 'link': 'https://arxiv.org/abs/2502.07764', 'abstract': 'We study the computational complexity of approximating general constrained Markov decision processes. Our primary contribution is the design of a polynomial time $(0,\\epsilon)$-additive bicriteria approximation algorithm for finding optimal constrained policies across a broad class of recursively computable constraints, including almost-sure, chance, expectation, and their anytime variants. Matching lower bounds imply our approximation guarantees are optimal so long as $P \\neq NP$. The generality of our approach results in answers to several long-standing open complexity questions in the constrained reinforcement learning literature. Specifically, we are the first to prove polynomial-time approximability for the following settings: policies under chance constraints, deterministic policies under multiple expectation constraints, policies under non-homogeneous constraints (i.e., constraints of different types), and policies under constraints for continuous-state processes.', 'abstract_zh': '我们研究一般受限马尔可夫决策过程的近似计算复杂性。我们的主要贡献是设计了一个多项式时间的$(0,\\epsilon)$-加性双准则近似算法，在广泛可递归计算的约束类别中寻找最优受限策略，包括几乎确定性、机会性、期望及其任意时间变体。相匹配的下界表明，只要$P \\neq NP$，我们的近似保证就是最优的。我们方法的普适性为受约束强化学习文献中多个长期开放的复杂性问题提供了答案。具体而言，我们首次证明了以下设置的多项式时间可近似性：机会约束下的策略、多期望约束下的确定性策略、不同类型的非齐次约束下的策略以及连续状态过程下的约束策略。', 'title_zh': '受约束强化学习的多项式可近似性'}
{'arxiv_id': 'arXiv:2502.07750', 'title': 'PFedDST: Personalized Federated Learning with Decentralized Selection Training', 'authors': 'Mengchen Fan, Keren Li, Tianyun Zhang, Qing Tian, Baocheng Geng', 'link': 'https://arxiv.org/abs/2502.07750', 'abstract': 'Distributed Learning (DL) enables the training of machine learning models across multiple devices, yet it faces challenges like non-IID data distributions and device capability disparities, which can impede training efficiency. Communication bottlenecks further complicate traditional Federated Learning (FL) setups. To mitigate these issues, we introduce the Personalized Federated Learning with Decentralized Selection Training (PFedDST) framework. PFedDST enhances model training by allowing devices to strategically evaluate and select peers based on a comprehensive communication score. This score integrates loss, task similarity, and selection frequency, ensuring optimal peer connections. This selection strategy is tailored to increase local personalization and promote beneficial peer collaborations to strengthen the stability and efficiency of the training process. Our experiments demonstrate that PFedDST not only enhances model accuracy but also accelerates convergence. This approach outperforms state-of-the-art methods in handling data heterogeneity, delivering both faster and more effective training in diverse and decentralized systems.', 'abstract_zh': '个性化分布式选择训练的联邦学习框架（PFedDST）', 'title_zh': 'PFedDST：基于去中心化选择训练的个性化联邦学习'}
{'arxiv_id': 'arXiv:2502.07734', 'title': 'EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices', 'authors': 'Camile Lendering, Bernardo Perrone Ribeiro, Žiga Emeršič, Peter Peer', 'link': 'https://arxiv.org/abs/2502.07734', 'abstract': 'Ear recognition is a contactless and unobtrusive biometric technique with applications across various domains. However, deploying high-performing ear recognition models on resource-constrained devices is challenging, limiting their applicability and widespread adoption. This paper introduces EdgeEar, a lightweight model based on a proposed hybrid CNN-transformer architecture to solve this problem. By incorporating low-rank approximations into specific linear layers, EdgeEar reduces its parameter count by a factor of 50 compared to the current state-of-the-art, bringing it below two million while maintaining competitive accuracy. Evaluation on the Unconstrained Ear Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the lowest EER while significantly reducing computational costs. These findings demonstrate the feasibility of efficient and accurate ear recognition, which we believe will contribute to the wider adoption of ear biometrics.', 'abstract_zh': '基于混合CNN-变压器架构的EdgeEar：轻量级耳纹识别模型', 'title_zh': 'EdgeEar: 适用于边缘设备的高效准确耳部识别'}
{'arxiv_id': 'arXiv:2502.07732', 'title': 'Economics of Sourcing Human Data', 'authors': 'Sebastin Santy, Prasanta Bhattacharya, Manoel Horta Ribeiro, Kelsey Allen, Sewoong Oh', 'link': 'https://arxiv.org/abs/2502.07732', 'abstract': "Progress in AI has relied on human-generated data, from annotator marketplaces to the wider Internet. However, the widespread use of large language models now threatens the quality and integrity of human-generated data on these very platforms. We argue that this issue goes beyond the immediate challenge of filtering AI-generated content--it reveals deeper flaws in how data collection systems are designed. Existing systems often prioritize speed, scale, and efficiency at the cost of intrinsic human motivation, leading to declining engagement and data quality. We propose that rethinking data collection systems to align with contributors' intrinsic motivations--rather than relying solely on external incentives--can help sustain high-quality data sourcing at scale while maintaining contributor trust and long-term participation.", 'abstract_zh': '人工智能的进步依赖于人类生成的数据，从标注员市场到更广泛的互联网。然而，大规模语言模型的广泛应用现在威胁到了这些平台上人类生成数据的质量和完整性。我们argue认为，这一问题超越了过滤AI生成内容的即时挑战——它揭示了数据收集系统设计中的更深层次缺陷。现有的系统往往以速度、规模和效率为优先，而牺牲了内在的人类动机，导致参与度和数据质量下降。我们提议重新思考数据收集系统的设计，使其与贡献者的内在动机相一致——而不仅仅依赖外部激励——以帮助大规模保持高质量的数据来源，同时维持贡献者的信任和长期参与度。', 'title_zh': '人类数据采购经济学'}
{'arxiv_id': 'arXiv:2502.07721', 'title': 'TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning', 'authors': 'Mengyang Li', 'link': 'https://arxiv.org/abs/2502.07721', 'abstract': 'The prevalence of noisy labels in real-world datasets poses a significant impediment to the effective deployment of deep learning models. While meta-learning strategies have emerged as a promising approach for addressing this challenge, existing methods often suffer from limited transferability and task-specific designs. This paper introduces TMLC-Net, a novel Transferable Meta-Learner for Correcting Noisy Labels, designed to overcome these limitations. TMLC-Net learns a general-purpose label correction strategy that can be readily applied across diverse datasets and model architectures without requiring extensive retraining or fine-tuning. Our approach integrates three core components: (1) Normalized Noise Perception, which captures and normalizes training dynamics to handle distribution shifts; (2) Time-Series Encoding, which models the temporal evolution of sample statistics using a recurrent neural network; and (3) Subclass Decoding, which predicts a corrected label distribution based on the learned representations. We conduct extensive experiments on benchmark datasets with various noise types and levels, demonstrating that TMLC-Net consistently outperforms state-of-the-art methods in terms of both accuracy and robustness to label noise. Furthermore, we analyze the transferability of TMLC-Net, showcasing its adaptability to new datasets and noise conditions, and establishing its potential as a broadly applicable solution for robust deep learning in noisy environments.', 'abstract_zh': '实时数据集中噪声标签的普遍性对深度学习模型的有效部署构成了显著障碍。尽管元学习策略已 emerges as a promising approach for addressing this challenge, existing methods often suffer from limited transferability and task-specific designs. This paper introduces TMLC-Net, a novel Transferable Meta-Learner for Correcting Noisy Labels, designed to overcome these limitations. TMLC-Net learns a general-purpose label correction strategy that can be readily applied across diverse datasets and model architectures without requiring extensive retraining or fine-tuning. Our approach integrates three core components: (1) Normalized Noise Perception, which captures and normalizes training dynamics to handle distribution shifts; (2) Time-Series Encoding, which models the temporal evolution of sample statistics using a recurrent neural network; and (3) Subclass Decoding, which predicts a corrected label distribution based on the learned representations. We conduct extensive experiments on benchmark datasets with various noise types and levels, demonstrating that TMLC-Net consistently outperforms state-of-the-art methods in terms of both accuracy and robustness to label noise. Furthermore, we analyze the transferability of TMLC-Net, showcasing its adaptability to new datasets and noise conditions, and establishing its potential as a broadly applicable solution for robust deep learning in noisy environments.《具有可转移性的元学习网络(TMLC-Net)：用于纠正噪声标签的新颖方法》', 'title_zh': 'TMLC-Net: 可迁移的元标签修正方法用于嘈杂标签学习'}
{'arxiv_id': 'arXiv:2502.07693', 'title': 'SoK: A Classification for AI-driven Personalized Privacy Assistants', 'authors': 'Victor Morel, Leonardo Iwaya, Simone Fischer-Hübner', 'link': 'https://arxiv.org/abs/2502.07693', 'abstract': 'To help users make privacy-related decisions, personalized privacy assistants based on AI technology have been developed in recent years. These AI-driven Personalized Privacy Assistants (AI-driven PPAs) can reap significant benefits for users, who may otherwise struggle to make decisions regarding their personal data in environments saturated with privacy-related decision requests. However, no study systematically inquired about the features of these AI-driven PPAs, their underlying technologies, or the accuracy of their decisions. To fill this gap, we present a Systematization of Knowledge (SoK) to map the existing solutions found in the scientific literature. We screened 1697 unique research papers over the last decade (2013-2023), constructing a classification from 39 included papers. As a result, this SoK reviews several aspects of existing research on AI-driven PPAs in terms of types of publications, contributions, methodological quality, and other quantitative insights. Furthermore, we provide a comprehensive classification for AI-driven PPAs, delving into their architectural choices, system contexts, types of AI used, data sources, types of decisions, and control over decisions, among other facets. Based on our SoK, we further underline the research gaps and challenges and formulate recommendations for the design and development of AI-driven PPAs as well as avenues for future research.', 'abstract_zh': '近年来，基于人工智能技术的个性化隐私助手被开发出来以帮助用户做出隐私相关决策。这些由人工智能驱动的个性化隐私助手（AI驱动的PPAs）可以为用户提供重大利益，用户在充斥着大量隐私相关决策请求的环境中，可能难以做出有关其个人数据的决策。然而，至今尚未有研究系统地探讨这些AI驱动的PPAs的特点、底层技术以及决策的准确性。为填补这一空白，我们提出了一种知识体系化（SoK）方法，以文献中现有的解决方案为基础进行映射。我们在过去十年（2013-2023）中筛选了1697篇独特的研究论文，并构建了一个包含39篇论文的分类体系。由此，这一SoK综述了AI驱动的PPAs现有研究的多个方面，包括出版类型、贡献、方法论质量以及其他定量洞察。此外，我们还对AI驱动的PPAs进行了全面分类，深入探讨了其架构选择、系统环境、使用的AI类型、数据来源、决策类型以及对决策的控制等各个方面。基于我们的SoK，我们进一步指出了研究空白和挑战，并提出了AI驱动的PPAs的设计与开发建议，以及未来研究的方向。', 'title_zh': 'SoK: 人工智能驱动的个性化隐私助理分类'}
{'arxiv_id': 'arXiv:2502.07656', 'title': 'A Unifying Framework for Causal Imitation Learning with Hidden Confounders', 'authors': 'Daqian Shao, Thomas Kleine Buening, Marta Kwiatkowska', 'link': 'https://arxiv.org/abs/2502.07656', 'abstract': "We propose a general and unifying framework for causal Imitation Learning (IL) with hidden confounders that subsumes several existing confounded IL settings from the literature. Our framework accounts for two types of hidden confounders: (a) those observed by the expert, which thus influence the expert's policy, and (b) confounding noise hidden to both the expert and the IL algorithm. For additional flexibility, we also introduce a confounding noise horizon and time-varying expert-observable hidden variables. We show that causal IL in our framework can be reduced to a set of Conditional Moment Restrictions (CMRs) by leveraging trajectory histories as instruments to learn a history-dependent policy. We propose DML-IL, a novel algorithm that uses instrumental variable regression to solve these CMRs and learn a policy. We provide a bound on the imitation gap for DML-IL, which recovers prior results as special cases. Empirical evaluation on a toy environment with continues state-action spaces and multiple Mujoco tasks demonstrate that DML-IL outperforms state-of-the-art causal IL algorithms.", 'abstract_zh': '一种统一的包含隐藏混杂变量的因果模仿学习框架及其应用', 'title_zh': '隐藏混杂变量下统一的因果模仿学习框架'}
{'arxiv_id': 'arXiv:2502.07563', 'title': 'LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid', 'authors': 'Weigao Sun, Disen Lan, Yiran Zhong, Xiaoye Qu, Yu Cheng', 'link': 'https://arxiv.org/abs/2502.07563', 'abstract': 'Linear sequence modeling approaches, such as linear attention, provide advantages like linear-time training and constant-memory inference over sequence lengths. However, existing sequence parallelism (SP) methods are either not optimized for the right-product-first feature of linear attention or use a ring-style communication strategy, which results in lower computation parallelism, limits their scalability for longer sequences in distributed systems. In this paper, we introduce LASP-2, a new SP method to enhance both communication and computation parallelism when training linear attention transformer models with very-long input sequences. Compared to previous work LASP, LASP-2 rethinks the minimal communication requirement for SP on linear attention layers, reorganizes the whole communication-computation workflow of LASP. In this way, only one single AllGather collective communication is needed on intermediate memory states, whose sizes are independent of the sequence length, leading to significant improvements of both communication and computation parallelism, as well as their overlap. Additionally, we extend LASP-2 to LASP-2H by applying similar communication redesign to standard attention modules, offering an efficient SP solution for hybrid models that blend linear and standard attention layers. Our evaluation on a Linear-Llama3 model, a variant of Llama3 with linear attention replacing standard attention, demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2 achieves training speed improvements of 15.2% over LASP and 36.6% over Ring Attention, with a sequence length of 2048K across 64 GPUs. The Code is released as a part of: this https URL.', 'abstract_zh': '基于线性注意力的新型序列并行方法LASP-2：提高长输入序列线性注意力变换模型的通信和计算并行性', 'title_zh': 'LASP-2: 重新思考线性注意力及其混合模型中的序列并行性'}
{'arxiv_id': 'arXiv:2502.07562', 'title': 'LoRP-TTS: Low-Rank Personalized Text-To-Speech', 'authors': 'Łukasz Bondaruk, Jakub Kubiak', 'link': 'https://arxiv.org/abs/2502.07562', 'abstract': 'Speech synthesis models convert written text into natural-sounding audio. While earlier models were limited to a single speaker, recent advancements have led to the development of zero-shot systems that generate realistic speech from a wide range of speakers using their voices as additional prompts. However, they still struggle with imitating non-studio-quality samples that differ significantly from the training datasets. In this work, we demonstrate that utilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single recordings of spontaneous speech in noisy environments as prompts. This approach enhances speaker similarity by up to $30pp$ while preserving content and naturalness. It represents a significant step toward creating truly diverse speech corpora, that is crucial in all speech-related tasks.', 'abstract_zh': '基于低秩适应的即兴语音在噪声环境中的零样本合成研究', 'title_zh': 'LoRP-TTS: 低秩个性化文本到语音'}
{'arxiv_id': 'arXiv:2502.07552', 'title': 'Unsupervised Translation of Emergent Communication', 'authors': 'Ido Levy, Orr Paradise, Boaz Carmeli, Ron Meir, Shafi Goldwasser, Yonatan Belinkov', 'link': 'https://arxiv.org/abs/2502.07552', 'abstract': "Emergent Communication (EC) provides a unique window into the language systems that emerge autonomously when agents are trained to jointly achieve shared goals. However, it is difficult to interpret EC and evaluate its relationship with natural languages (NL). This study employs unsupervised neural machine translation (UNMT) techniques to decipher ECs formed during referential games with varying task complexities, influenced by the semantic diversity of the environment. Our findings demonstrate UNMT's potential to translate EC, illustrating that task complexity characterized by semantic diversity enhances EC translatability, while higher task complexity with constrained semantic variability exhibits pragmatic EC, which, although challenging to interpret, remains suitable for translation. This research marks the first attempt, to our knowledge, to translate EC without the aid of parallel data.", 'abstract_zh': '自主训练的交流 Emergent Communication 提供了一种独特窗口，用以研究智能体在共同实现共享目标时自主生成的语言系统。然而，解读 Emergent Communication (EC) 并评估其与自然语言 (Natural Language, NL) 的关系颇具挑战。本研究利用无监督神经机器翻译 (Unsupervised Neural Machine Translation, UNMT) 技术解码不同任务复杂度下参考游戏中形成的 EC，这些游戏受环境语义多样性的影响。研究结果表明，语义多样性表征的任务复杂性能够增强 EC 的可译性，而受限语义多样性下更高任务复杂性的 EC 虽然难以解读，但也适合翻译。本研究是我们所知的首次尝试，在无需平行数据辅助的情况下翻译 EC。', 'title_zh': '无监督 emergent 通信的翻译'}
{'arxiv_id': 'arXiv:2502.07549', 'title': 'HGTUL: A Hypergraph-based Model For Trajectory User Linking', 'authors': 'Fengjie Chang, Xinning Zhu, Zheng Hu, Yang Qin', 'link': 'https://arxiv.org/abs/2502.07549', 'abstract': 'Trajectory User Linking (TUL), which links anonymous trajectories with users who generate them, plays a crucial role in modeling human mobility. Despite significant advancements in this field, existing studies primarily neglect the high-order inter-trajectory relationships, which represent complex associations among multiple trajectories, manifested through multi-location co-occurrence patterns emerging when trajectories intersect at various Points of Interest (POIs). Furthermore, they also overlook the variable influence of POIs on different trajectories, as well as the user class imbalance problem caused by disparities in user activity levels and check-in frequencies. To address these limitations, we propose a novel HyperGraph-based multi-perspective Trajectory User Linking model (HGTUL). Our model learns trajectory representations from both relational and spatio-temporal perspectives: (1) it captures high-order associations among trajectories by constructing a trajectory hypergraph and leverages a hypergraph attention network to learn the variable impact of POIs on trajectories; (2) it models the spatio-temporal characteristics of trajectories by incorporating their temporal and spatial information into a sequential encoder. Moreover, we design a data balancing method to effectively address the user class imbalance problem and experimentally validate its significance in TUL. Extensive experiments on three real-world datasets demonstrate that HGTUL outperforms state-of-the-art baselines, achieving improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics, respectively.', 'abstract_zh': '基于超图的多视角轨迹用户链接模型（HGTUL）', 'title_zh': '基于超图的轨迹用户链接模型'}
{'arxiv_id': 'arXiv:2502.07516', 'title': 'The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation', 'authors': 'Raman Dutt', 'link': 'https://arxiv.org/abs/2502.07516', 'abstract': "Generative models, particularly text-to-image (T2I) diffusion models, play a crucial role in medical image analysis. However, these models are prone to training data memorization, posing significant risks to patient privacy. Synthetic chest X-ray generation is one of the most common applications in medical image analysis with the MIMIC-CXR dataset serving as the primary data repository for this task. This study adopts a data-driven approach and presents the first systematic attempt to identify prompts and text tokens in MIMIC-CXR that contribute the most to training data memorization. Our analysis reveals an unexpected finding: prompts containing traces of de-identification procedures are among the most memorized, with de-identification markers contributing the most. Furthermore, we also find existing inference-time memorization mitigation strategies are ineffective and fail to sufficiently reduce the model's reliance on memorized text tokens highlighting a broader issue in T2I synthesis with MIMIC-CXR. On this front, we propose actionable strategies to enhance privacy and improve the reliability of generative models in medical imaging. Finally, our results provide a foundation for future work on developing and benchmarking memorization mitigation techniques for synthetic chest X-ray generation using the MIMIC-CXR dataset.", 'abstract_zh': '生成模型，特别是文本到图像（T2I）扩散模型，在医学图像分析中发挥着重要作用。然而，这些模型容易记住训练数据，对患者隐私构成重大风险。合成胸部X射线生成是医学图像分析中最常见的应用之一，MIMIC-CXR数据集是该任务的主要数据仓库。本研究采用数据驱动的方法，首次系统地尝试识别MIMIC-CXR中对训练数据记忆贡献最大的提示和文本标记。我们的分析揭示了一个意想不到的发现：包含去标识化程序痕迹的提示是其中最易被记住的，去标识化标记的贡献最大。此外，我们还发现现有的推理时记忆减轻策略无效，未能显著减少模型对记忆文本标记的依赖，突显了在MIMIC-CXR上进行T2I合成中的更广泛问题。在此基础上，我们提出了增强隐私和提高生成模型在医学影像应用中可靠性的策略。最后，我们的结果为未来使用MIMIC-CXR数据集开发和基准测试合成胸部X射线生成的记忆减轻技术奠定了基础。', 'title_zh': '陷坑在于提示：去标识化痕迹增强合成胸部X光图像的记忆风险'}
{'arxiv_id': 'arXiv:2502.07479', 'title': 'WebChecker: A Versatile EVL Plugin for Validating HTML Pages with Bootstrap Frameworks', 'authors': 'Milind Cherukuri', 'link': 'https://arxiv.org/abs/2502.07479', 'abstract': 'WebChecker is a plugin for Epsilon Validation Language (EVL), designed to validate both static and dynamic HTML pages utilizing frameworks like Bootstrap. By employing configurable EVL constraints, WebChecker enforces implicit rules governing HTML and CSS frameworks. The effectiveness of the plugin is demonstrated through its application on Bootstrap, the widely adopted HTML, CSS, and JavaScript framework. WebChecker comes with a set of EVL constraints to assess Bootstrap based web pages. To substantiate our claims, I present an illustrative example featuring two solutions that effectively enforce implicit rules.', 'abstract_zh': 'WebChecker是Epsilon Validation Language (EVL)的插件，用于利用如Bootstrap等框架验证静态和动态HTML页面。通过使用可配置的EVL约束，WebChecker强制执行治理HTML和CSS框架的隐式规则。通过在Bootstrap上的应用，插件的有效性得到了证明，Bootstrap是一款广泛采用的HTML、CSS和JavaScript框架。WebChecker配备了评估基于Bootstrap的网页的EVL约束。为了支持我们的论点，我呈现了两个有效强制执行隐式规则的示例。', 'title_zh': 'WebChecker：一个支持Bootstrap框架验证HTML页面的多功能EVL插件'}
{'arxiv_id': 'arXiv:2502.07469', 'title': '5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence', 'authors': 'Gianluca Galletti, Fabian Paischer, Paul Setinek, William Hornsby, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, Johannes Brandstetter', 'link': 'https://arxiv.org/abs/2502.07469', 'abstract': 'Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to achieving commercially viable fusion power is understanding plasma turbulence, which can significantly degrade plasma confinement. Modelling turbulence is crucial to design performing plasma scenarios for next-generation reactor-class devices and current experimental machines. The nonlinear gyrokinetic equation underpinning turbulence modelling evolves a 5D distribution function over time. Solving this equation numerically is extremely expensive, requiring up to weeks for a single run to converge, making it unfeasible for iterative optimisation and control studies. In this work, we propose a method for training neural surrogates for 5D gyrokinetic simulations. Our method extends a hierarchical vision transformer to five dimensions and is trained on the 5D distribution function for the adiabatic electron approximation. We demonstrate that our model can accurately infer downstream physical quantities such as heat flux time trace and electrostatic potentials for single-step predictions two orders of magnitude faster than numerical codes. Our work paves the way towards neural surrogates for plasma turbulence simulations to accelerate deployment of commercial energy production via nuclear fusion.', 'abstract_zh': '核聚合作为可靠和可持续能源生产的关键，在实现商业化可行的聚变功率方面的主要障碍是理解等离子体湍流，这会显著恶化等离子体约束。湍流建模对于设计下一代反应堆级设备和当前实验机器的高性能等离子体情景至关重要。支撑湍流建模的非线性流线旁中心进动方程随时间演化一个5D分布函数。数值求解此方程非常昂贵，单次运行可能需要数周时间才能收敛，这使其在迭代优化和控制研究中不可行。本文提出了一种训练5D流线旁中心进动模拟神经代理的方法。该方法将层次视觉变压器扩展至五个维度，并在绝热电子近似下的5D分布函数上进行训练。我们证明，我们的模型可以比数值代码快两个数量级的速度进行单步预测，并准确推断下游物理量，如热流时间迹线和静电势。本文为通过核聚变加速商业化能源生产的等离子体湍流模拟神经代理铺平了道路。', 'title_zh': '5D神经代理模型用于非线性动理学模拟的等离子体湍流'}
{'arxiv_id': 'arXiv:2502.07465', 'title': 'Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models', 'authors': 'Li Mao, Wei Du, Shuo Wen, Qi Li, Tong Zhang, Wei Zhong', 'link': 'https://arxiv.org/abs/2502.07465', 'abstract': 'This study uses deep-learning models to predict city partition crime counts on specific days. It helps police enhance surveillance, gather intelligence, and proactively prevent crimes. We formulate crime count prediction as a spatiotemporal sequence challenge, where both input data and prediction targets are spatiotemporal sequences. In order to improve the accuracy of crime forecasting, we introduce a new model that combines Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a comparative analysis to access the effects of various data sequences, including raw and binned data, on the prediction errors of four deep learning forecasting models. Directly inputting raw crime data into the forecasting model causes high prediction errors, making the model unsuitable for real - world use. The findings indicate that the proposed CNN-LSTM model achieves optimal performance when crime data is categorized into 10 or 5 groups. Data binning can enhance forecasting model performance, but poorly defined intervals may reduce map granularity. Compared to dividing into 5 bins, binning into 10 intervals strikes an optimal balance, preserving data characteristics and surpassing raw data in predictive modelling efficacy.', 'abstract_zh': '本研究使用深度学习模型预测特定日期城市的分区犯罪数量，有助于警方增强监控、收集情报并主动预防犯罪。我们将犯罪数量预测形式化为时空序列挑战，输入数据和预测目标均为时空序列。为提高犯罪预测准确性，我们提出了一种结合卷积神经网络（CNN）和长短期记忆（LSTM）网络的新模型。我们进行了比较分析，评估了不同类型数据序列（原始数据和分组数据）对四种深度学习预测模型预测误差的影响。直接将原始犯罪数据输入预测模型会导致高预测误差，使模型不适合实际应用。研究结果表明，当犯罪数据分为10组或5组时，提出的CNN-LSTM模型可实现最佳性能。数据分组可以提升预测模型性能，但定义不当的区间可能降低地图粒度。与分成5个区间相比，分成10个区间在保留数据特征的同时，在预测建模效果上优于原始数据。', 'title_zh': '犯罪预测：基于深度学习模型的空间-时间分析'}
{'arxiv_id': 'arXiv:2502.07461', 'title': 'JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata', 'authors': 'Abhinaba Roy, Renhang Liu, Tongyu Lu, Dorien Herremans', 'link': 'https://arxiv.org/abs/2502.07461', 'abstract': 'We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring over 200,000 freely licensed instrumental tracks from the renowned Jamendo platform. The dataset includes captions generated by a state-of-the-art captioning model, enhanced with imputed metadata. We also introduce a retrieval system that leverages both musical features and metadata to identify similar songs, which are then used to fill in missing metadata using a local large language model (LLLM). This approach allows us to provide a more comprehensive and informative dataset for researchers working on music-language understanding tasks. We validate this approach quantitatively with five different measurements. By making the JamendoMaxCaps dataset publicly available, we provide a high-quality resource to advance research in music-language understanding tasks such as music retrieval, multimodal representation learning, and generative music models.', 'abstract_zh': 'JamendoMaxCaps：一个包含超过200,000个自由许可乐器 tracks 的大规模音乐-描述数据集及其元数据补充检索系统', 'title_zh': 'JamendoMaxCaps：一个包含补充元数据的大规模音乐配图文集'}
{'arxiv_id': 'arXiv:2502.07455', 'title': 'RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation', 'authors': 'Viacheslav Vasilev, Julia Agafonova, Nikolai Gerasimenko, Alexander Kapitanov, Polina Mikhailova, Evelina Mironova, Denis Dimitrov', 'link': 'https://arxiv.org/abs/2502.07455', 'abstract': "Text-to-image generation models have gained popularity among users around the world. However, many of these models exhibit a strong bias toward English-speaking cultures, ignoring or misrepresenting the unique characteristics of other language groups, countries, and nationalities. The lack of cultural awareness can reduce the generation quality and lead to undesirable consequences such as unintentional insult, and the spread of prejudice. In contrast to the field of natural language processing, cultural awareness in computer vision has not been explored as extensively. In this paper, we strive to reduce this gap. We propose a RusCode benchmark for evaluating the quality of text-to-image generation containing elements of the Russian cultural code. To do this, we form a list of 19 categories that best represent the features of Russian visual culture. Our final dataset consists of 1250 text prompts in Russian and their translations into English. The prompts cover a wide range of topics, including complex concepts from art, popular culture, folk traditions, famous people's names, natural objects, scientific achievements, etc. We present the results of a human evaluation of the side-by-side comparison of Russian visual concepts representations using popular generative models.", 'abstract_zh': '文本到图像生成模型在全世界用户中受到了欢迎。然而，许多模型对英文文化的偏向十分明显，忽视或曲解了其他语言群体、国家和民族的独特特征。缺乏文化意识会降低生成质量，并可能导致无意中的冒犯和偏见的传播。与自然语言处理领域相比，计算机视觉中的文化意识尚未被广泛探索。本文力求缩小这一差距。我们提出了一个RusCode基准，用于评估包含俄罗斯文化码元素的文本到图像生成质量。为此，我们列出了19个最佳代表俄罗斯视觉文化特点的类别。最终数据集包含1250个俄文文本提示及其英文翻译，这些提示涵盖了从艺术到流行文化、民间传统、名人名字、自然物体、科学成就等多种主题。我们展示了对流行的生成模型并排比较俄罗斯视觉概念表示的人类评估结果。', 'title_zh': 'RusCode: 俄罗斯文化代码文本-to-图像生成基准'}
{'arxiv_id': 'arXiv:2502.07404', 'title': 'Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy', 'authors': 'Sahana Yadnakudige Subramanya, Ko Watanabe, Andreas Dengel, Shoya Ishimaru', 'link': 'https://arxiv.org/abs/2502.07404', 'abstract': "Human-in-the-loop (HITL) frameworks are increasingly recognized for their potential to improve annotation accuracy in emotion estimation systems by combining machine predictions with human expertise. This study focuses on integrating a high-performing image-based emotion model into a HITL annotation framework to evaluate the collaborative potential of human-machine interaction and identify the psychological and practical factors critical to successful collaboration. Specifically, we investigate how varying model reliability and cognitive framing influence human trust, cognitive load, and annotation behavior in HITL systems. We demonstrate that model reliability and psychological framing significantly impact annotators' trust, engagement, and consistency, offering insights into optimizing HITL frameworks. Through three experimental scenarios with 29 participants--baseline model reliability (S1), fabricated errors (S2), and cognitive bias introduced by negative framing (S3)--we analyzed behavioral and qualitative data. Reliable predictions in S1 yielded high trust and annotation consistency, while unreliable outputs in S2 led to increased critical evaluations but also heightened frustration and response variability. Negative framing in S3 revealed how cognitive bias influenced participants to perceive the model as more relatable and accurate, despite misinformation regarding its reliability. These findings highlight the importance of both reliable machine outputs and psychological factors in shaping effective human-machine collaboration. By leveraging the strengths of both human oversight and automated systems, this study establishes a scalable HITL framework for emotion annotation and lays the foundation for broader applications in adaptive learning and human-computer interaction.", 'abstract_zh': '基于人类在环路的框架在情感估计系统标注中的潜在改进：高绩效图像情感模型的集成研究', 'title_zh': '基于图像的参与度估计中的人机交互标注：评估模型可靠性对标注准确性的影响'}
{'arxiv_id': 'arXiv:2502.07400', 'title': 'Explainable Multimodal Machine Learning for Revealing Structure-Property Relationships in Carbon Nanotube Fibers', 'authors': 'Daisuke Kimura, Naoko Tajima, Toshiya Okazaki, Shun Muroga', 'link': 'https://arxiv.org/abs/2502.07400', 'abstract': 'In this study, we propose Explainable Multimodal Machine Learning (EMML), which integrates the analysis of diverse data types (multimodal data) using factor analysis for feature extraction with Explainable AI (XAI), for carbon nanotube (CNT) fibers prepared from aqueous dispersions. This method is a powerful approach to elucidate the mechanisms governing material properties, where multi-stage fabrication conditions and multiscale structures have complex influences. Thus, in our case, this approach helps us understand how different processing steps and structures at various scales impact the final properties of CNT fibers. The analysis targeted structures ranging from the nanoscale to the macroscale, including aggregation size distributions of CNT dispersions and the effective length of CNTs. Furthermore, because some types of data were difficult to interpret using standard methods, challenging-to-interpret distribution data were analyzed using Negative Matrix Factorization (NMF) for extracting key features that determine the outcome. Contribution analysis with SHapley Additive exPlanations (SHAP) demonstrated that small, uniformly distributed aggregates are crucial for improving fracture strength, while CNTs with long effective lengths are significant factors for enhancing electrical conductivity. The analysis also identified thresholds and trends for these key factors to assist in defining the conditions needed to optimize CNT fiber properties. EMML is not limited to CNT fibers but can be applied to the design of other materials derived from nanomaterials, making it a useful tool for developing a wide range of advanced materials. This approach provides a foundation for advancing data-driven materials research.', 'abstract_zh': '可解释的多模态机器学习在从水分散液制备的碳纳米管纤维中的应用', 'title_zh': '可解释的多模态机器学习揭示碳纳米管纤维的结构-性质关系'}
{'arxiv_id': 'arXiv:2502.07344', 'title': 'Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction', 'authors': 'Alfonso Gijón, Simone Eiraudo, Antonio Manjavacas, Daniele Salvatore Schiera, Miguel Molina-Solana, Juan Gómez-Romero', 'link': 'https://arxiv.org/abs/2502.07344', 'abstract': "The rapid growth of the wind energy sector underscores the urgent need to optimize turbine operations and ensure effective maintenance through early fault detection systems. While traditional empirical and physics-based models offer approximate predictions of power generation based on wind speed, they often fail to capture the complex, non-linear relationships between other input variables and the resulting power output. Data-driven machine learning methods present a promising avenue for improving wind turbine modeling by leveraging large datasets, enhancing prediction accuracy but often at the cost of interpretability. In this study, we propose a hybrid semi-parametric model that combines the strengths of both approaches, applied to a dataset from a wind farm with four turbines. The model integrates a physics-inspired submodel, providing a reasonable approximation of power generation, with a non-parametric submodel that predicts the residuals. This non-parametric submodel is trained on a broader range of variables to account for phenomena not captured by the physics-based component. The hybrid model achieves a 37% improvement in prediction accuracy over the physics-based model. To enhance interpretability, SHAP values are used to analyze the influence of input features on the residual submodel's output. Additionally, prediction uncertainties are quantified using a conformalized quantile regression method. The combination of these techniques, alongside the physics grounding of the parametric submodel, provides a flexible, accurate, and reliable framework. Ultimately, this study opens the door for evaluating the impact of unmodeled variables on wind turbine power generation, offering a basis for potential optimization.", 'abstract_zh': '风能部门的迅速增长突显了优化涡轮机运行和通过早期故障检测系统确保有效维护的迫切需求。传统的基于经验和物理的方法虽然可以根据风速提供风能发电的近似预测，但往往未能捕捉到其他输入变量与发电量之间复杂的非线性关系。数据驱动的机器学习方法为通过利用大数据集改进风力涡轮机建模提供了有前途的途径，虽然可以在提高预测准确性的同时牺牲可解释性。在本研究中，我们提出了一种结合了两种方法优点的半参数模型，并应用于包含四台风机的风电场数据集。该模型整合了一个基于物理的方法子模型，提供合理的发电量近似值，以及一个非参数子模型来预测残差。该非参数子模型基于更广泛的变量进行训练，以考虑物理基于组件未能捕捉的现象。混合模型在预测准确性上比基于物理的方法模型提高了37%。为了增强可解释性，使用SHAP值分析输入特征对非参数子模型输出的影响。此外，通过使用校准分位数回归方法量化预测不确定性。这些技术的结合，以及参数子模型的物理基础，提供了一个灵活、准确和可靠的框架。最终，本研究为评估未建模变量对风力涡轮机发电量的影响提供了可能性，为进一步优化奠定了基础。', 'title_zh': '融合物理和数据驱动方法：一种可解释且 considers 不确定性的风电涡轮机功率预测混合模型'}
{'arxiv_id': 'arXiv:2502.07328', 'title': 'Music for All: Exploring Multicultural Representations in Music Generation Models (Camera Ready)', 'authors': 'Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury', 'link': 'https://arxiv.org/abs/2502.07328', 'abstract': 'The advent of Music-Language Models has greatly enhanced the automatic music generation capability of AI systems, but they are also limited in their coverage of the musical genres and cultures of the world. We present a study of the datasets and research papers for music generation and quantify the bias and under-representation of genres. We find that only 5.7% of the total hours of existing music datasets come from non-Western genres, which naturally leads to disparate performance of the models across genres. We then investigate the efficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating this bias. Our experiments with two popular models -- MusicGen and Mustango, for two underrepresented non-Western music traditions -- Hindustani Classical and Turkish Makam music, highlight the promises as well as the non-triviality of cross-genre adaptation of music through small datasets, implying the need for more equitable baseline music-language models that are designed for cross-cultural transfer learning.', 'abstract_zh': '音乐语言模型的出现极大地提升了AI系统的自动音乐生成能力，但也限制了其对全球音乐流派和文化的覆盖面。我们研究了音乐生成的数据集和研究论文，并量化了流派的偏差和不足。我们发现，现有音乐数据集中只有5.7%来自非西方流派，这自然导致了模型在不同流派中的表现差异。随后，我们调查了参数高效微调（PEFT）技术在这方面的有效性。针对两种非西方音乐传统——印度古典音乐和土耳其makam音乐，使用两个流行的模型（MusicGen和Mustango）进行的实验突显了通过小数据集跨流派适应音乐的潜力及其非平凡性，暗示需要更具包容性的基线音乐语言模型，以促进跨文化交流的学习。', 'title_zh': '音乐forall：探索音乐生成模型中的多元文化代表（待发表）'}
{'arxiv_id': 'arXiv:2502.07312', 'title': 'OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms', 'authors': 'Lumen AI, Zaozhuang No.28 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Tianhao Xu', 'link': 'https://arxiv.org/abs/2502.07312', 'abstract': "This report details Lumen Labs' novel approach to processing Social Networking Service (SNS) data. We leverage knowledge distillation, specifically a simple distillation method inspired by DeepSeek-R1's CoT acquisition, combined with prompt hacking, to extract valuable training data from the Grok model. This data is then used to fine-tune a Phi-3-mini model, augmented with a mask-like mechanism specifically designed for handling the nuances of SNS data. Our method demonstrates state-of-the-art (SOTA) performance on several SNS data processing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We provide a comprehensive analysis of our approach, including mathematical formulations, engineering details, ablation studies, and comparative evaluations.", 'abstract_zh': '本报告详细介绍了Lumen Labs在处理社交媒体服务（SNS）数据方面的新型方法。我们利用知识蒸馏，特别是受DeepSeek-R1的CoT获取启发的一种简单蒸馏方法，结合提示篡改，从Grok模型中提取有价值的训练数据。随后，这些数据用于微调一个Phi-3-mini模型，并通过一种特定设计的掩码机制来处理SNS数据的细微差别。我们的方法在多项SNS数据处理任务中表现出目前最先进的（SOTA）性能，超越了现有的模型如Grok、Phi-3和GPT-4。我们提供了对该方法的全面分析，包括数学公式、工程技术细节、消融研究和比较评估。', 'title_zh': 'OpenGrok: 通过提炼知识和掩码机制增强社交网络数据处理'}
{'arxiv_id': 'arXiv:2502.07299', 'title': 'Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification', 'authors': 'Zicheng Liu, Siyuan Li, Zhiyuan Chen, Lei Xin, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Stan Z. Li', 'link': 'https://arxiv.org/abs/2502.07299', 'abstract': 'The interactions between DNA, RNA, and proteins are fundamental to biological processes, as illustrated by the central dogma of molecular biology. While modern biological pre-trained models have achieved great success in analyzing these macromolecules individually, their interconnected nature remains under-explored. In this paper, we follow the guidance of the central dogma to redesign both the data and model pipeline and offer a comprehensive framework, Life-Code, that spans different biological functions. As for data flow, we propose a unified pipeline to integrate multi-omics data by reverse-transcribing RNA and reverse-translating amino acids into nucleotide-based sequences. As for the model, we design a codon tokenizer and a hybrid long-sequence architecture to encode the interactions of both coding and non-coding regions with masked modeling pre-training. To model the translation and folding process with coding sequences, Life-Code learns protein structures of the corresponding amino acids by knowledge distillation from off-the-shelf protein language models. Such designs enable Life-Code to capture complex interactions within genetic sequences, providing a more comprehensive understanding of multi-omics with the central dogma. Extensive Experiments show that Life-Code achieves state-of-the-art performance on various tasks across three omics, highlighting its potential for advancing multi-omics analysis and interpretation.', 'abstract_zh': 'DNA、RNA与蛋白质之间的相互作用是生物学过程的基础，正如分子生物学的中心法则所展示的那样。虽然现代生物预训练模型在单独分析这些大分子方面取得了巨大成功，但它们之间的相互连接性仍远未被探索。在这篇论文中，我们遵循中心法则的指导，重新设计数据和模型管道，并提出了一个涵盖不同生物学功能的综合框架Life-Code。在数据流方面，我们提出了一种统一的管道，通过逆转录RNA和逆转录氨基酸为核苷酸序列来整合多组学数据。在模型方面，我们设计了密码子分词器和混合长序列架构，通过掩码模型预训练来编码编码区和非编码区之间的相互作用。为了建模编码序列的翻译和折叠过程，Life-Code通过从现成的蛋白质语言模型中提取知识来进行相应的氨基酸蛋白质结构的学习。这种设计使Life-Code能够捕捉遗传序列内的复杂相互作用，为多组学的综合理解提供了更全面的视角。广泛的实验证明，Life-Code在三个层面的多种任务上取得了最先进的性能，突显了其在推进多组学分析和解释方面的潜力。', 'title_zh': 'Life-Code: 多组学序列统一下的中央狗ma模型'}
{'arxiv_id': 'arXiv:2502.07280', 'title': 'MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management', 'authors': 'Fengchen Gu, Angelos Stefanidis, Ángel García-Fernández, Jionglong Su, Huakang Li', 'link': 'https://arxiv.org/abs/2502.07280', 'abstract': "Deep reinforcement learning (DRL) has been applied in financial portfolio management to improve returns in changing market conditions. However, unlike most fields where DRL is widely used, the stock market is more volatile and dynamic as it is affected by several factors such as global events and investor sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio management framework with strong return capability, stable training, and generalization ability. This study introduces a new framework utilizing the Memory Instance Gated Transformer (MIGT) for effective portfolio management. By incorporating a novel Gated Instance Attention module, which combines a transformer variant, instance normalization, and a Lite Gate Unit, our approach aims to maximize investment returns while ensuring the learning process's stability and reducing outlier impacts. Tested on the Dow Jones Industrial Average 30, our framework's performance is evaluated against fifteen other strategies using key financial metrics like the cumulative return and risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns and a minimum 2.36% increase in risk-return ratios over competing strategies, marking a significant advancement in DRL for portfolio management.", 'abstract_zh': '利用Memory Instance Gated Transformer (MIGT)的有效投资组合管理新框架：在动态股市中的强回报能力和稳定性', 'title_zh': 'MIGT：面向金融组合管理的记忆实例门控变换器框架'}
{'arxiv_id': 'arXiv:2502.07276', 'title': 'Dataset Ownership Verification in Contrastive Pre-trained Models', 'authors': 'Yuechen Xie, Jie Song, Mengqi Xue, Haofei Zhang, Xingen Wang, Bingde Hu, Genlang Chen, Mingli Song', 'link': 'https://arxiv.org/abs/2502.07276', 'abstract': 'High-quality open-source datasets, which necessitate substantial efforts for curation, has become the primary catalyst for the swift progress of deep learning. Concurrently, protecting these datasets is paramount for the well-being of the data owner. Dataset ownership verification emerges as a crucial method in this domain, but existing approaches are often limited to supervised models and cannot be directly extended to increasingly popular unsupervised pre-trained models. In this work, we propose the first dataset ownership verification method tailored specifically for self-supervised pre-trained models by contrastive learning. Its primary objective is to ascertain whether a suspicious black-box backbone has been pre-trained on a specific unlabeled dataset, aiding dataset owners in upholding their rights. The proposed approach is motivated by our empirical insights that when models are trained with the target dataset, the unary and binary instance relationships within the embedding space exhibit significant variations compared to models trained without the target dataset. We validate the efficacy of this approach across multiple contrastive pre-trained models including SimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our method rejects the null hypothesis with a $p$-value markedly below $0.05$, surpassing all previous methodologies. Our code is available at this https URL.', 'abstract_zh': '高质量开源数据集的保护亟待深入研究，以促进深度学习的迅速发展。为此，数据所有权验证在这一领域变得至关重要，但现有方法往往局限于监督模型，无法直接扩展到日益流行的自监督预训练模型。本文提出了一种针对自监督预训练模型的首个数据所有权验证方法，利用对比学习进行判定。该方法的主要目标是验证可疑的黑盒主干网络是否在特定无标签数据集上进行了预训练，从而帮助数据所有者维护其权益。我们的方法基于观察，当模型使用目标数据集进行训练时，在嵌入空间中的单例和双例实例关系会与未使用目标数据集进行训练的模型表现出显著差异。我们在包括SimCLR、BYOL、SimSiam、MOCO v3和DINO在内的多个对比预训练模型上验证了该方法的有效性。结果显示，我们的方法在$p$-值远低于$0.05$的情况下拒绝了零假设，超越了所有先前的方法。源代码可在以下链接获取。', 'title_zh': '对比预训练模型中的数据集所有权验证'}
{'arxiv_id': 'arXiv:2502.07274', 'title': 'Cost-Efficient Continual Learning with Sufficient Exemplar Memory', 'authors': 'Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha', 'link': 'https://arxiv.org/abs/2502.07274', 'abstract': "Continual learning (CL) research typically assumes highly constrained exemplar memory resources. However, in many real-world scenarios-especially in the era of large foundation models-memory is abundant, while GPU computational costs are the primary bottleneck. In this work, we investigate CL in a novel setting where exemplar memory is ample (i.e., sufficient exemplar memory). Unlike prior methods designed for strict exemplar memory constraints, we propose a simple yet effective approach that directly operates in the model's weight space through a combination of weight resetting and averaging techniques. Our method achieves state-of-the-art performance while reducing the computational cost to a quarter or third of existing methods. These findings challenge conventional CL assumptions and provide a practical baseline for computationally efficient CL applications.", 'abstract_zh': '持续学习（CL）研究通常假定示例记忆资源高度受限。然而，在许多现实场景中，特别是在大规模基础模型时代，内存资源丰富而GPU计算成本是主要瓶颈。在本工作中，我们研究了示例记忆资源充足（即，充足的示例记忆）的新型持续学习设置。不同于为严格示例记忆约束设计的方法，我们提出了一种简单而有效的方法，通过结合权重重置和平均技术直接在模型的权重空间中操作。我们的方法在保持最佳性能的同时，将计算成本降低到现有方法的四分之一或三分之一。这些发现挑战了传统的持续学习假设，并为计算高效的持续学习应用提供了一个实用的基础。', 'title_zh': '高效成本持续学习方法——充足示例记忆'}
{'arxiv_id': 'arXiv:2502.07273', 'title': 'Variational Learning Induces Adaptive Label Smoothing', 'authors': 'Sin-Han Yang, Zhedong Liu, Gian Maria Marconi, Mohammad Emtiyaz Khan', 'link': 'https://arxiv.org/abs/2502.07273', 'abstract': 'We show that variational learning naturally induces an adaptive label smoothing where label noise is specialized for each example. Such label-smoothing is useful to handle examples with labeling errors and distribution shifts, but designing a good adaptivity strategy is not always easy. We propose to skip this step and simply use the natural adaptivity induced during the optimization of a variational objective. We show empirical results where a variational algorithm called IVON outperforms traditional label smoothing and yields adaptivity strategies similar to those of an existing approach. By connecting Bayesian methods to label smoothing, our work provides a new way to handle overconfident predictions.', 'abstract_zh': '变分学习自然诱导自适应标签平滑，其中标签噪声特化于每个示例。我们展示了一种变分算法IVON在处理带有标注错误和分布偏移的示例时优于传统标签平滑方法，并提供了与现有方法类似的有效性策略。通过将贝叶斯方法与标签平滑相结合，我们的工作提供了一种处理过于自信预测的新方法。', 'title_zh': '变分学习诱导自适应标签平滑'}
{'arxiv_id': 'arXiv:2502.07254', 'title': 'Fairness in Multi-Agent AI: A Unified Framework for Ethical and Equitable Autonomous Systems', 'authors': 'Rajesh Ranjan, Shailja Gupta, Surya Narayan Singh', 'link': 'https://arxiv.org/abs/2502.07254', 'abstract': 'Ensuring fairness in decentralized multi-agent systems presents significant challenges due to emergent biases, systemic inefficiencies, and conflicting agent incentives. This paper provides a comprehensive survey of fairness in multi-agent AI, introducing a novel framework where fairness is treated as a dynamic, emergent property of agent interactions. The framework integrates fairness constraints, bias mitigation strategies, and incentive mechanisms to align autonomous agent behaviors with societal values while balancing efficiency and robustness. Through empirical validation, we demonstrate that incorporating fairness constraints results in more equitable decision-making. This work bridges the gap between AI ethics and system design, offering a foundation for accountable, transparent, and socially responsible multi-agent AI systems.', 'abstract_zh': '确保去中心化多智能体系统中的公平性面临着显著挑战，因其涉及 emergent 喜好、系统性低效性和智能体目标冲突。本文提供了一个全面的多智能体AI中的公平性综述，介绍了一种将公平性视为智能体交互动态、 emergent 属性的新框架。该框架整合了公平性约束、偏见缓解策略和激励机制，以使自主智能体的行为与社会价值观相一致，同时平衡效率和稳健性。通过实证验证，我们证明了引入公平性约束可以实现更公平的决策。本文在AI伦理与系统设计之间架起了桥梁，为其提供了可问责、透明和具有社会责任感的多智能体AI系统的基石。', 'title_zh': '多智能体AI中的公平性：一种统一的伦理与公正自主系统框架'}
{'arxiv_id': 'arXiv:2502.07244', 'title': 'Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting', 'authors': 'Jiecheng Lu, Shihao Yang', 'link': 'https://arxiv.org/abs/2502.07244', 'abstract': 'Autoregressive attention-based time series forecasting (TSF) has drawn increasing interest, with mechanisms like linear attention sometimes outperforming vanilla attention. However, deeper Transformer architectures frequently misalign with autoregressive objectives, obscuring the underlying VAR structure embedded within linear attention and hindering their ability to capture the data generative processes in TSF. In this work, we first show that a single linear attention layer can be interpreted as a dynamic vector autoregressive (VAR) structure. We then explain that existing multi-layer Transformers have structural mismatches with the autoregressive forecasting objective, which impair interpretability and generalization ability. To address this, we show that by rearranging the MLP, attention, and input-output flow, multi-layer linear attention can also be aligned as a VAR model. Then, we propose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer variant that integrates interpretable dynamic VAR weights for multivariate TSF. By aligning the Transformer architecture with autoregressive objectives, SAMoVAR delivers improved performance, interpretability, and computational efficiency, comparing to SOTA TSF models.', 'abstract_zh': '基于自回归注意力的时间序列预测（TSF）吸引了越来越多的关注，有时线性注意力机制甚至可以超越普通的注意力机制。然而，更深的Transformer架构通常与自回归目标不匹配，这会遮蔽线性注意力中嵌入的VAR结构，并妨碍其捕捉TSF中的数据生成过程。在本工作中，首先我们证明了一个线性注意力层可以被解释为动态向量自回归（VAR）结构。然后我们解释说，现有的多层Transformer在结构上与自回归预测目标不匹配，这会损害其可解释性和泛化能力。为此，我们通过重新排列MLP、注意力机制和输入输出流，展示了多层线性注意力也可以被重新排列为VAR模型。接着，我们提出了一种结合可解释动态VAR权重的线性Transformer变体——结构对齐的VAR混合模型（SAMoVAR），它用于多变量时间序列预测。通过使Transformer架构与自回归目标保持一致，SAMoVAR在性能、可解释性和计算效率上都优于当前最先进的TSF模型。', 'title_zh': '线性变换器作为向量自回归模型：自回归注意机制与自回归预测的对齐'}
{'arxiv_id': 'arXiv:2502.07214', 'title': 'Pareto Optimal Algorithmic Recourse in Multi-cost Function', 'authors': 'Wen-Ling Chen, Hong-Chang Huang, Kai-Hung Lin, Shang-Wei Hwang, Hao-Tsung Yang', 'link': 'https://arxiv.org/abs/2502.07214', 'abstract': 'In decision-making systems, algorithmic recourse aims to identify minimal-cost actions to alter an individual features, thereby obtaining a desired outcome. This empowers individuals to understand, question, or alter decisions that negatively affect them. However, due to the variety and sensitivity of system environments and individual personalities, quantifying the cost of a single function is nearly impossible while considering multiple criteria situations. Most current recourse mechanisms use gradient-based methods that assume cost functions are differentiable, often not applicable in real-world scenarios, resulting in sub-optimal solutions that compromise various criteria. These solutions are typically intractable and lack rigorous theoretical foundations, raising concerns regarding interpretability, reliability, and transparency from the explainable AI (XAI) perspective.\nTo address these issues, this work proposes an algorithmic recourse framework that handles non-differentiable and discrete multi-cost functions. By formulating recourse as a multi-objective optimization problem and assigning weights to different criteria based on their importance, our method identifies Pareto optimal recourse recommendations. To demonstrate scalability, we incorporate the concept of epsilon-net, proving the ability to find approximated Pareto optimal actions. Experiments show the trade-off between different criteria and the methods scalability in large graphs. Compared to current heuristic practices, our approach provides a stronger theoretical foundation and better aligns recourse suggestions with real-world requirements.', 'abstract_zh': '基于非可微和离散多成本函数的决策系统算法可追溯框架', 'title_zh': '帕累托最优算法干预在多成本函数中的应用'}
{'arxiv_id': 'arXiv:2502.07213', 'title': 'Evaluation for Regression Analyses on Evolving Data Streams', 'authors': 'Yibin Sun, Heitor Murilo Gomes, Bernhard Pfahringer, Albert Bifet', 'link': 'https://arxiv.org/abs/2502.07213', 'abstract': 'The paper explores the challenges of regression analysis in evolving data streams, an area that remains relatively underexplored compared to classification. We propose a standardized evaluation process for regression and prediction interval tasks in streaming contexts. Additionally, we introduce an innovative drift simulation strategy capable of synthesizing various drift types, including the less-studied incremental drift. Comprehensive experiments with state-of-the-art methods, conducted under the proposed process, validate the effectiveness and robustness of our approach.', 'abstract_zh': '该论文探讨了在演变数据流中回归分析面临的挑战，这是一个相较于分类而言相对未被充分探索的领域。我们提出了一种标准化的评估流程，用于流式环境中回归和预测区间任务。此外，我们引入了一种创新的漂移模拟策略，能够合成各种类型的漂移，包括较少研究的增量漂移。在所提出流程下的全面实验验证了该方法的有效性和鲁棒性。', 'title_zh': 'evolve 数据流上回归分析的评估'}
{'arxiv_id': 'arXiv:2502.07207', 'title': 'A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning', 'authors': 'Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif', 'link': 'https://arxiv.org/abs/2502.07207', 'abstract': 'Advanced Persistent Threats (APTs) pose a significant security risk to organizations and industries. These attacks often lead to severe data breaches and compromise the system for a long time. Mitigating these sophisticated attacks is highly challenging due to the stealthy and persistent nature of APTs. Machine learning models are often employed to tackle this challenge by bringing automation and scalability to APT detection. Nevertheless, these intelligent methods are data-driven, and thus, highly affected by the quality and relevance of input data. This paper aims to analyze measurements considered when recording network traffic and conclude which features contribute more to detecting APT samples. To do this, we study the features associated with various APT cases and determine their importance using a machine learning framework. To ensure the generalization of our findings, several feature selection techniques are employed and paired with different classifiers to evaluate their effectiveness. Our findings provide insights into how APT detection can be enhanced in real-world scenarios.', 'abstract_zh': '高级持续性威胁（APTs）对组织和行业的安全构成重大风险。这些攻击常导致严重的数据泄露，并长时间 compromize 系统。由于 APTs 的隐匿性和持久性，减轻这些复杂的攻击极具挑战性。机器学习模型常被用于应对这一挑战，通过引入自动化和可扩展性来实现 APT 检测。然而，这些智能方法依赖于输入数据的质量和相关性。本文旨在分析记录网络流量时考虑的指标，并确定哪些特征更有助于检测 APT 样本。为此，我们研究与各种 APT 情况相关的特征，并使用机器学习框架确定它们的重要性。为了确保研究发现的普适性，我们采用了多种特征选择技术，并与不同的分类器配对以评估其有效性。我们的研究提供了在实际场景中增强 APT 检测的见解。', 'title_zh': '基于机器学习检测高级持续威胁中特征的重要性研究'}
{'arxiv_id': 'arXiv:2502.07205', 'title': 'VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification', 'authors': 'Pengyu Wang, Ying Fang, Xiaofei Li', 'link': 'https://arxiv.org/abs/2502.07205', 'abstract': 'Reverberant speech, denoting the speech signal degraded by the process of reverberation, contains crucial knowledge of both anechoic source speech and room impulse response (RIR). This work proposes a variational Bayesian inference (VBI) framework with neural speech prior (VINP) for joint speech dereverberation and blind RIR identification. In VINP, a probabilistic signal model is constructed in the time-frequency (T-F) domain based on convolution transfer function (CTF) approximation. For the first time, we propose using an arbitrary discriminative dereverberation deep neural network (DNN) to predict the prior distribution of anechoic speech within a probabilistic model. By integrating both reverberant speech and the anechoic speech prior, VINP yields the maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the anechoic speech spectrum and CTF filter, respectively. After simple transformations, the waveforms of anechoic speech and RIR are estimated. Moreover, VINP is effective for automatic speech recognition (ASR) systems, which sets it apart from most deep learning (DL)-based single-channel dereverberation approaches. Experiments on single-channel speech dereverberation demonstrate that VINP reaches an advanced level in most metrics related to human perception and displays unquestionable state-of-the-art (SOTA) performance in ASR-related metrics. For blind RIR identification, experiments indicate that VINP attains the SOTA level in blind estimation of reverberation time at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio samples are available online.', 'abstract_zh': '含混语音 dereverberation 和盲室 impulse response 识别的神经先验变分贝叶斯框架', 'title_zh': 'VINP：具有神经语音先验的变分贝叶斯推断在联合ASR-有效语音去混响和盲房间 impulse 响应识别中的应用'}
{'arxiv_id': 'arXiv:2502.07158', 'title': 'Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer', 'authors': 'Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu', 'link': 'https://arxiv.org/abs/2502.07158', 'abstract': 'Early prediction of pediatric cardiac arrest (CA) is critical for timely intervention in high-risk intensive care settings. We introduce PedCA-FT, a novel transformer-based framework that fuses tabular view of EHR with the derived textual view of EHR to fully unleash the interactions of high-dimensional risk factors and their dynamics. By employing dedicated transformer modules for each modality view, PedCA-FT captures complex temporal and contextual patterns to produce robust CA risk estimates. Evaluated on a curated pediatric cohort from the CHOA-CICU database, our approach outperforms ten other artificial intelligence models across five key performance metrics and identifies clinically meaningful risk factors. These findings underscore the potential of multimodal fusion techniques to enhance early CA detection and improve patient care.', 'abstract_zh': '儿科心脏骤停早期预测对于高风险重症监护环境中的及时干预至关重要。我们提出了PedCA-FT，这是一种新的基于变压器的框架，将结构化电子健康记录（EHR）视图与提取的文本视图融合，以充分利用高维风险因素及其动态的相互作用。通过为每种模态视图专门设计变压器模块，PedCA-FT捕获复杂的时序和上下文模式，以产生稳健的心脏骤停风险估计。在CHOA-CICU数据库精心筛选的儿科队列上评估，我们方法在五个关键性能指标上优于其他十种人工智能模型，并识别出具有临床意义的风险因素。这些发现强调了多模态融合技术在提高心脏骤停早期检测和改善患者护理方面的能力。', 'title_zh': '基于多模态融合变压器的儿童心脏骤停早期风险预测从电子健康记录出发'}
{'arxiv_id': 'arXiv:2502.07153', 'title': 'Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models', 'authors': 'Célia Wafa Ayad, Thomas Bonnier, Benjamin Bosch, Sonali Parbhoo, Jesse Read', 'link': 'https://arxiv.org/abs/2502.07153', 'abstract': 'In order to ensure the reliability of the explanations of machine learning models, it is crucial to establish their advantages and limits and in which case each of these methods outperform. However, the current understanding of when and how each method of explanation can be used is insufficient. To fill this gap, we perform a comprehensive empirical evaluation by synthesizing multiple datasets with the desired properties. Our main objective is to assess the quality of feature importance estimates provided by local explanation methods, which are used to explain predictions made by decision tree-based models. By analyzing the results obtained from synthetic datasets as well as publicly available binary classification datasets, we observe notable disparities in the magnitude and sign of the feature importance estimates generated by these methods. Moreover, we find that these estimates are sensitive to specific properties present in the data. Although some model hyper-parameters do not significantly influence feature importance assignment, it is important to recognize that each method of explanation has limitations in specific contexts. Our assessment highlights these limitations and provides valuable insight into the suitability and reliability of different explanatory methods in various scenarios.', 'abstract_zh': '为了确保机器学习模型解释的可靠性，必须建立其优势和局限性，并明确在何种情况下各类方法能够 superior。然而，目前对各类解释方法适用条件及其使用方式的理解仍然不足。为填补这一空白，我们通过综合具有特定属性的多种数据集进行了全面的实证评估。我们的主要目标是评估基于决策树模型预测的局部解释方法提供的特征重要性估计的质量。通过分析从合成数据集以及公开的二分类数据集中获得的结果，我们观察到了这些方法生成的特征重要性估计在大小和符号上存在显著差异。此外，我们发现这些估计受到数据中特定属性的影响。尽管一些模型超参数对特征重要性分配影响不大，但重要的是要认识到每种解释方法在其特定上下文中都有局限性。我们的评估突显了这些局限性，并提供了不同解释方法在各种场景下的适用性和可靠性的重要见解。', 'title_zh': '特征重要性取决于数据的性质：朝着为您的数据和基于决策树的模型选择正确的解释努力'}
{'arxiv_id': 'arXiv:2502.07071', 'title': 'TRADES: Generating Realistic Market Simulations with Diffusion Models', 'authors': 'Leonardo Berti, Bardh Prenkaj, Paola Velardi', 'link': 'https://arxiv.org/abs/2502.07071', 'abstract': "Financial markets are complex systems characterized by high statistical noise, nonlinearity, volatility, and constant evolution. Thus, modeling them is extremely hard. Here, we address the task of generating realistic and responsive Limit Order Book (LOB) market simulations, which are fundamental for calibrating and testing trading strategies, performing market impact experiments, and generating synthetic market data. Previous works lack realism, usefulness, and responsiveness of the generated simulations. To bridge this gap, we propose a novel TRAnsformer-based Denoising Diffusion Probabilistic Engine for LOB Simulations (TRADES). TRADES generates realistic order flows as time series conditioned on the state of the market, leveraging a transformer-based architecture that captures the temporal and spatial characteristics of high-frequency market data. There is a notable absence of quantitative metrics for evaluating generative market simulation models in the literature. To tackle this problem, we adapt the predictive score, a metric measured as an MAE, by training a stock price predictive model on synthetic data and testing it on real data. We compare TRADES with previous works on two stocks, reporting an x3.27 and x3.47 improvement over SoTA according to the predictive score, demonstrating that we generate useful synthetic market data for financial downstream tasks. Furthermore, we assess TRADES's market simulation realism and responsiveness, showing that it effectively learns the conditional data distribution and successfully reacts to an experimental agent, giving sprout to possible calibrations and evaluations of trading strategies and market impact experiments. We developed DeepMarket, the first open-source Python framework for market simulation with deep learning. In our repository, we include a synthetic LOB dataset composed of the TRADES's generated simulations.", 'abstract_zh': '基于Transformer的去噪扩散概率引擎生成真实响应的限价订单簿市场模拟(TRADES)', 'title_zh': 'TRADES: 使用扩散模型生成现实市场的模拟数据'}
{'arxiv_id': 'arXiv:2502.07064', 'title': 'Contextual Thompson Sampling via Generation of Missing Data', 'authors': 'Kelly W. Zhang, Tiffany Tianhui Cai, Hongseok Namkoong, Daniel Russo', 'link': 'https://arxiv.org/abs/2502.07064', 'abstract': 'We introduce a framework for Thompson sampling contextual bandit algorithms, in which the algorithm\'s ability to quantify uncertainty and make decisions depends on the quality of a generative model that is learned offline. Instead of viewing uncertainty in the environment as arising from unobservable latent parameters, our algorithm treats uncertainty as stemming from missing, but potentially observable, future outcomes. If these future outcomes were all observed, one could simply make decisions using an "oracle" policy fit on the complete dataset. Inspired by this conceptualization, at each decision-time, our algorithm uses a generative model to probabilistically impute missing future outcomes, fits a policy using the imputed complete dataset, and uses that policy to select the next action. We formally show that this algorithm is a generative formulation of Thompson Sampling and prove a state-of-the-art regret bound for it. Notably, our regret bound i) depends on the probabilistic generative model only through the quality of its offline prediction loss, and ii) applies to any method of fitting the "oracle" policy, which easily allows one to adapt Thompson sampling to decision-making settings with fairness and/or resource constraints.', 'abstract_zh': '我们引入了一种 Thompson 抽样上下文bandit算法的框架，其中算法对不确定性进行量化和决策的能力取决于一个离线学习的生成模型的质量。我们的算法将环境中的不确定性视为来自潜在的但可能可观测的未来结果的缺失。如果所有这些未来结果都能被观察到，那么可以简单地使用一个针对完整数据集拟合的“Oracle”策略来做出决策。受这一概念启发，每次决策时刻，算法使用生成模型概率性地填补缺失的未来结果，使用填补完整数据集拟合策略，并利用该策略选择下一个动作。我们形式化展示了该算法是 Thompson 抽样的一种生成形式，并证明了其最新的性能遗憾界。值得注意的是，我们的遗憾界：i) 仅通过离线预测损失的质量依赖于概率生成模型，ii) 可应用于任何“Oracle”策略拟合方法，这使得 Thompson 抽样能够适应具有公平性和/或资源约束的决策制定环境。', 'title_zh': '基于生成缺失数据的上下文图灵采样'}
{'arxiv_id': 'arXiv:2502.07059', 'title': 'Federated Continual Learning: Concepts, Challenges, and Solutions', 'authors': 'Parisa Hamedi, Roozbeh Razavi-Far, Ehsan Hallaji', 'link': 'https://arxiv.org/abs/2502.07059', 'abstract': 'Federated Continual Learning (FCL) has emerged as a robust solution for collaborative model training in dynamic environments, where data samples are continuously generated and distributed across multiple devices. This survey provides a comprehensive review of FCL, focusing on key challenges such as heterogeneity, model stability, communication overhead, and privacy preservation. We explore various forms of heterogeneity and their impact on model performance. Solutions to non-IID data, resource-constrained platforms, and personalized learning are reviewed in an effort to show the complexities of handling heterogeneous data distributions. Next, we review techniques for ensuring model stability and avoiding catastrophic forgetting, which are critical in non-stationary environments. Privacy-preserving techniques are another aspect of FCL that have been reviewed in this work. This survey has integrated insights from federated learning and continual learning to present strategies for improving the efficacy and scalability of FCL systems, making it applicable to a wide range of real-world scenarios.', 'abstract_zh': '联邦持续学习（FCL）已经 emerged as a robust solution for collaborative model training in dynamic environments，where data samples are continuously generated and distributed across multiple devices. This survey provides a comprehensive review of FCL，focusing on key challenges such as heterogeneity，model stability，communication overhead，and privacy preservation. We explore various forms of heterogeneity and their impact on model performance. Solutions to non-IID data，resource-constrained platforms，and personalized learning are reviewed to demonstrate the complexities of handling heterogeneous data distributions. Next，we review techniques for ensuring model stability and avoiding catastrophic forgetting，which are critical in non-stationary environments. Privacy-preserving techniques are another aspect of FCL that have been reviewed in this work. This survey integrates insights from federated learning and continual learning to present strategies for improving the efficacy and scalability of FCL systems，making it applicable to a wide range of real-world scenarios.', 'title_zh': '联邦持续学习：概念、挑战与解决方案'}
{'arxiv_id': 'arXiv:2502.07029', 'title': 'Leveraging Allophony in Self-Supervised Speech Models for Atypical Pronunciation Assessment', 'authors': 'Kwanghee Choi, Eunjung Yeo, Kalvin Chang, Shinji Watanabe, David Mortensen', 'link': 'https://arxiv.org/abs/2502.07029', 'abstract': 'Allophony refers to the variation in the phonetic realization of a phoneme based on its phonetic environment. Modeling allophones is crucial for atypical pronunciation assessment, which involves distinguishing atypical from typical pronunciations. However, recent phoneme classifier-based approaches often simplify this by treating various realizations as a single phoneme, bypassing the complexity of modeling allophonic variation. Motivated by the acoustic modeling capabilities of frozen self-supervised speech model (S3M) features, we propose MixGoP, a novel approach that leverages Gaussian mixture models to model phoneme distributions with multiple subclusters. Our experiments show that MixGoP achieves state-of-the-art performance across four out of five datasets, including dysarthric and non-native speech. Our analysis further suggests that S3M features capture allophonic variation more effectively than MFCCs and Mel spectrograms, highlighting the benefits of integrating MixGoP with S3M features.', 'abstract_zh': '音变指的是音位在不同发音环境中 Phonetic 实现形式的变异。建模音变对于异常发音评估至关重要，该评估涉及区分异常发音与典型发音。然而，近期基于音位分类的方法往往通过将不同发音形式简化为单一音位来绕过建模音变复杂性的需求。受冻结自监督语音模型（S3M）特征的声学建模能力启发，我们提出了一种名为 MixGoP 的新方法，该方法利用高斯混合模型来建模具有多个子簇的音位分布。我们的实验结果显示，MixGoP 在四个出五个数据集中达到了最先进的性能，包括言语流畅障碍和非母语发音。进一步的分析表明，S3M 特征比 MFCC 和梅尔谱图更有效地捕捉音变变异，突显了将 MixGoP 与 S3M 特征结合使用的优势。', 'title_zh': '利用音位变体在自监督语音模型中的应用以评估非典型发音'}
{'arxiv_id': 'arXiv:2502.07027', 'title': 'Representational Alignment with Chemical Induced Fit for Molecular Relational Learning', 'authors': 'Peiliang Zhang, Jingling Yuan, Qing Xie, Yongjun Zhu, Lin Li', 'link': 'https://arxiv.org/abs/2502.07027', 'abstract': "Molecular Relational Learning (MRL) is widely applied in natural sciences to predict relationships between molecular pairs by extracting structural features. The representational similarity between substructure pairs determines the functional compatibility of molecular binding sites. Nevertheless, aligning substructure representations by attention mechanisms lacks guidance from chemical knowledge, resulting in unstable model performance in chemical space (\\textit{e.g.}, functional group, scaffold) shifted data. With theoretical justification, we propose the \\textbf{Re}presentational \\textbf{Align}ment with Chemical Induced \\textbf{Fit} (ReAlignFit) to enhance the stability of MRL. ReAlignFit dynamically aligns substructure representation in MRL by introducing chemical Induced Fit-based inductive bias. In the induction process, we design the Bias Correction Function based on substructure edge reconstruction to align representations between substructure pairs by simulating chemical conformational changes (dynamic combination of substructures). ReAlignFit further integrates the Subgraph Information Bottleneck during fit process to refine and optimize substructure pairs exhibiting high chemical functional compatibility, leveraging them to generate molecular embeddings. Experimental results on nine datasets demonstrate that ReAlignFit outperforms state-of-the-art models in two tasks and significantly enhances model's stability in both rule-shifted and scaffold-shifted data distributions.", 'abstract_zh': '化学诱导契合的表示对齐（ReAlignFit）：增强分子关系学习的稳定性', 'title_zh': '化学诱导契合的表示对齐方法在分子关系学习中的应用'}
{'arxiv_id': 'arXiv:2502.07026', 'title': 'Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML', 'authors': 'Mohammad Amir Salari, Bahareh Rahmani', 'link': 'https://arxiv.org/abs/2502.07026', 'abstract': "Machine learning (ML) is transforming healthcare by enabling predictive analytics, personalized treatments, and improved patient outcomes. However, traditional ML workflows require specialized skills, infrastructure, and resources, limiting accessibility for many healthcare professionals. This paper explores how Google Cloud's BigQuery ML simplifies the development and deployment of ML models using SQL, reducing technical barriers. Through a case study on diabetes prediction using the Diabetes Health Indicators Dataset, we evaluate three predictive models: Logistic Regression, Boosted Tree, and Deep Neural Network (DNN). Our results demonstrate that the Boosted Tree model achieves the highest performance, making it highly effective for diabetes prediction. This study highlights BigQuery ML's role in democratizing machine learning by providing a scalable, efficient, and accessible solution for healthcare analytics.", 'abstract_zh': '机器学习如何通过Google Cloud的BigQuery ML简化医疗健康领域的模型开发与部署，从而提高糖尿病预测性能并促进机器学习的普及化应用。', 'title_zh': '机器学习forall: 以BigQuery ML简化医疗健康分析'}
{'arxiv_id': 'arXiv:2502.06963', 'title': 'Task Offloading in Vehicular Edge Computing using Deep Reinforcement Learning: A Survey', 'authors': 'Ashab Uddin, Ahmed Hamdi Sakr, Ning Zhang', 'link': 'https://arxiv.org/abs/2502.06963', 'abstract': 'The increasing demand for Intelligent Transportation Systems (ITS) has introduced significant challenges in managing the complex, computation-intensive tasks generated by modern vehicles while offloading tasks to external computing infrastructures such as edge computing (EC), nearby vehicular , and UAVs has become influential solution to these challenges. However, traditional computational offloading strategies often struggle to adapt to the dynamic and heterogeneous nature of vehicular environments. In this study, we explored the potential of Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) frameworks to optimize computational offloading through adaptive, real-time decision-making, and we have thoroughly investigated the Markov Decision Process (MDP) approaches on the existing literature. The paper focuses on key aspects such as standardized learning models, optimized reward structures, and collaborative multi-agent systems, aiming to advance the understanding and application of DRL in vehicular networks. Our findings offer insights into enhancing the efficiency, scalability, and robustness of ITS, setting the stage for future innovations in this rapidly evolving field.', 'abstract_zh': '智能交通系统(ITS)需求的增长引入了在现代车辆生成的复杂、计算密集型任务管理方面的重大挑战，将任务卸载到边缘计算(EC)、附近车辆和无人机等外部计算基础设施已成为解决这些挑战的有效解决方案。然而，传统的计算卸载策略往往难以适应车辆环境的动态和异构性。本研究探讨了强化学习(RL)和深度强化学习(DRL)框架在通过适应性和实时决策优化计算卸载方面的潜力，并详细研究了现有文献中的马尔可夫决策过程(MDP)方法。论文重点关注标准化的学习模型、优化的奖励结构和协作多代理系统等方面，旨在推进对DRL在车辆网络中应用的理解和应用。研究发现为提高ITS的效率、可扩展性和鲁棒性提供了见解，为这一快速发展的领域未来的创新奠定了基础。', 'title_zh': '使用深度强化学习的车联网边缘计算任务卸载：一个综述'}
{'arxiv_id': 'arXiv:2502.06927', 'title': 'Neighborhood-Order Learning Graph Attention Network for Fake News Detection', 'authors': 'Batool Lakzaei, Mostafa Haghir Chehreghani, Alireza Bagheri', 'link': 'https://arxiv.org/abs/2502.06927', 'abstract': "Fake news detection is a significant challenge in the digital age, which has become increasingly important with the proliferation of social media and online communication networks. Graph Neural Networks (GNN)-based methods have shown high potential in analyzing graph-structured data for this problem. However, a major limitation in conventional GNN architectures is their inability to effectively utilize information from neighbors beyond the network's layer depth, which can reduce the model's accuracy and effectiveness. In this paper, we propose a novel model called Neighborhood-Order Learning Graph Attention Network (NOL-GAT) for fake news detection. This model allows each node in each layer to independently learn its optimal neighborhood order. By doing so, the model can purposefully and efficiently extract critical information from distant neighbors. The NOL-GAT architecture consists of two main components: a Hop Network that determines the optimal neighborhood order and an Embedding Network that updates node embeddings using these optimal neighborhoods. To evaluate the model's performance, experiments are conducted on various fake news datasets. Results demonstrate that NOL-GAT significantly outperforms baseline models in metrics such as accuracy and F1-score, particularly in scenarios with limited labeled data. Features such as mitigating the over-squashing problem, improving information flow, and reducing computational complexity further highlight the advantages of the proposed model.", 'abstract_zh': '基于邻域序学习的图注意网络在假新闻检测中的应用', 'title_zh': '基于邻域顺序学习图注意力网络的虚假新闻检测'}
{'arxiv_id': 'arXiv:2502.06925', 'title': "Occam's model: Selecting simpler representations for better transferability estimation", 'authors': 'Prabhant Singh, Sibylle Hess, Joaquin Vanschoren', 'link': 'https://arxiv.org/abs/2502.06925', 'abstract': "Fine-tuning models that have been pre-trained on large datasets has become a cornerstone of modern machine learning workflows. With the widespread availability of online model repositories, such as Hugging Face, it is now easier than ever to fine-tune pre-trained models for specific tasks. This raises a critical question: which pre-trained model is most suitable for a given task? This problem is called transferability estimation. In this work, we introduce two novel and effective metrics for estimating the transferability of pre-trained models. Our approach is grounded in viewing transferability as a measure of how easily a pre-trained model's representations can be trained to separate target classes, providing a unique perspective on transferability estimation. We rigorously evaluate the proposed metrics against state-of-the-art alternatives across diverse problem settings, demonstrating their robustness and practical utility. Additionally, we present theoretical insights that explain our metrics' efficacy and adaptability to various scenarios. We experimentally show that our metrics increase Kendall's Tau by up to 32% compared to the state-of-the-art baselines.", 'abstract_zh': '预训练模型的迁移能力估计：引入两种新颖有效的度量标准', 'title_zh': '奥卡姆模型：选择更简单的表示以获得更好的转移性估计'}
{'arxiv_id': 'arXiv:2502.06924', 'title': 'XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units', 'authors': 'Arghadip Das, Arnab Raha, Shamik Kundu, Soumendu Kumar Ghosh, Deepak Mathaikutty, Vijay Raghunathan', 'link': 'https://arxiv.org/abs/2502.06924', 'abstract': 'State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length, making them ideal for long-sequence applications in NLP, vision, and edge AI, including real-time transcription, translation, and contextual search. These applications require lightweight, high-performance models for deployment on resource-constrained devices like laptops and PCs. Designing specialized accelerators for every emerging neural network is costly and impractical; instead, optimizing models for existing NPUs in AI PCs provides a scalable solution. To this end, we propose XAMBA, the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) state-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1) enabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and (3) trading accuracy for additional performance gains. After enabling SSMs on NPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacing sequential CumSum and ReduceSum operations with matrix-based computations, significantly improving execution speed and memory efficiency. Additionally, ActiBA enhances performance by approximating expensive activation functions (e.g., Swish, Softplus) using piecewise linear mappings, reducing latency with minimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC show that XAMBA achieves up to 2.6X speed-up over the baseline. Our implementation is available at this https URL.', 'abstract_zh': '基于状态空间模型的高效替代方案：XAMBA框架在商用现成NPUs上的优化与应用', 'title_zh': 'XAMBA: 在资源受限的神经处理单元上启用高效的态空间模型'}
{'arxiv_id': 'arXiv:2502.06923', 'title': 'Do Attention Heads Compete or Cooperate during Counting?', 'authors': 'Pál Zsámboki, Ádám Fraknói, Máté Gedeon, András Kornai, Zsolt Zombori', 'link': 'https://arxiv.org/abs/2502.06923', 'abstract': 'We present an in-depth mechanistic interpretability analysis of training small transformers on an elementary task, counting, which is a crucial deductive step in many algorithms. In particular, we investigate the collaboration/competition among the attention heads: we ask whether the attention heads behave as a pseudo-ensemble, all solving the same subtask, or they perform different subtasks, meaning that they can only solve the original task in conjunction. Our work presents evidence that on the semantics of the counting task, attention heads behave as a pseudo-ensemble, but their outputs need to be aggregated in a non-uniform manner in order to create an encoding that conforms to the syntax. Our source code will be available upon publication.', 'abstract_zh': '我们对训练小型变压器在计数这一基础任务中的机制可解释性进行了深入分析，计数是许多算法中至关重要的演绎步骤。特别地，我们探讨了注意力头之间的协作/竞争：我们探究这些注意力头是否作为伪聚类，各自解决同一个子任务，还是执行不同的子任务，意味着它们只能以联合的方式解决原始任务。我们的研究显示，在计数任务的意义上，注意力头表现出伪聚类的行为，但它们的输出需要以非均匀的方式进行聚合，以创建符合语法编码的结果。源代码将在发表后提供。', 'title_zh': '注意力头在计数过程中是竞争还是协作？'}
{'arxiv_id': 'arXiv:2502.06920', 'title': 'Direct Estimation of Pediatric Heart Rate Variability from BOLD-fMRI: A Machine Learning Approach Using Dynamic Connectivity', 'authors': 'Abdoljalil Addeh, Karen Ardila, Rebecca J Williams, G. Bruce Pike, M. Ethan MacDonald', 'link': 'https://arxiv.org/abs/2502.06920', 'abstract': 'In many pediatric fMRI studies, cardiac signals are often missing or of poor quality. A tool to extract Heart Rate Variation (HRV) waveforms directly from fMRI data, without the need for peripheral recording devices, would be highly beneficial. We developed a machine learning framework to accurately reconstruct HRV for pediatric applications. A hybrid model combining one-dimensional Convolutional Neural Networks (1D-CNN) and Gated Recurrent Units (GRU) analyzed BOLD signals from 628 ROIs, integrating past and future data. The model achieved an 8% improvement in HRV accuracy, as evidenced by enhanced performance metrics. This approach eliminates the need for peripheral photoplethysmography devices, reduces costs, and simplifies procedures in pediatric fMRI. Additionally, it improves the robustness of pediatric fMRI studies, which are more sensitive to physiological and developmental variations than those in adults.', 'abstract_zh': '在许多儿童功能性磁共振成像研究中，心脏信号往往缺失或质量较差。一种可以直接从功能性磁共振成像数据中提取心率变异（HRV）波形的工具，而不需使用外周记录设备，将非常有益。我们开发了一种机器学习框架，以准确重构适用于儿童应用的HRV。该混合模型结合了一维卷积神经网络（1D-CNN）和门控循环单元（GRU），分析来自628个感兴趣区域的BOLD信号，整合了过去和未来数据。该模型通过提升性能指标实现了8%的HRV准确性改进。这一方法消除了对外周光电流图设备的需要，降低了成本，并简化了儿童功能性磁共振成像的程序。此外，它提高了儿童功能性磁共振成像研究的稳健性，这些研究比成年人的更容易受到生理和发育差异的影响。', 'title_zh': '直接从BOLD-fMRI估计儿童心率变异性：一种基于动态连接性的机器学习方法'}
{'arxiv_id': 'arXiv:2502.06917', 'title': 'Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning', 'authors': 'Mario García-Márquez, Nuria Rodríguez-Barroso, M.Victoria Luzón, Francisco Herrera', 'link': 'https://arxiv.org/abs/2502.06917', 'abstract': 'Federated Learning presents a nascent approach to machine learning, enabling collaborative model training across decentralized devices while safeguarding data privacy. However, its distributed nature renders it susceptible to adversarial attacks. Integrating blockchain technology with Federated Learning offers a promising avenue to enhance security and integrity. In this paper, we tackle the potential of blockchain in defending Federated Learning against adversarial attacks. First, we test Proof of Federated Learning, a well known consensus mechanism designed ad-hoc to federated contexts, as a defense mechanism demonstrating its efficacy against Byzantine and backdoor attacks when at least one miner remains uncompromised. Second, we propose Krum Federated Chain, a novel defense strategy combining Krum and Proof of Federated Learning, valid to defend against any configuration of Byzantine or backdoor attacks, even when all miners are compromised. Our experiments conducted on image classification datasets validate the effectiveness of our proposed approaches.', 'abstract_zh': '联邦学习提供了一种新兴的机器学习方法，能够在保护数据隐私的同时，实现去中心化设备之间的协作模型训练。然而，其分布式特性使其容易受到对抗性攻击的影响。将区块链技术与联邦学习结合，为增强安全性和完整性提供了前景。在本文中，我们探讨了区块链在防御联邦学习对抗性攻击方面的潜力。首先，我们测试了一种专为联邦学习环境设计的共识机制——联邦学习证明，作为防御机制，证明其在至少一个矿工未受攻击的情况下对拜占庭和后门攻击的有效性。其次，我们提出了一种新的防御策略Krum联邦链，结合了Krum和联邦学习证明，能够防御任何配置的拜占庭或后门攻击，即使所有矿工均受攻击。我们在图像分类数据集上的实验验证了我们提出方法的有效性。', 'title_zh': '基于区块链的联邦学习防 adversarial 攻击机制：Krum 联邦链 (KFC)'}
{'arxiv_id': 'arXiv:2502.06914', 'title': 'UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge', 'authors': 'Chenao Li, Shuo Yan, Enyan Dai', 'link': 'https://arxiv.org/abs/2502.06914', 'abstract': 'Enzyme-catalyzed protein cleavage is essential for many biological functions. Accurate prediction of cleavage sites can facilitate various applications such as drug development, enzyme design, and a deeper understanding of biological mechanisms. However, most existing models are restricted to an individual enzyme, which neglects shared knowledge of enzymes and fails generalize to novel enzymes. Thus, we introduce a unified protein cleavage site predictor named {\\method}, which can generalize across diverse enzymes. To enhance the enzyme encoding for the protein cleavage site prediction, {\\method} employs a novel biochemically-informed model architecture along with active-site knowledge of proteolytic enzymes. Extensive experiments demonstrate that {\\method} achieves high accuracy in predicting cleavage sites across a range of proteolytic enzymes, including unseen enzymes. The code is available in this https URL.', 'abstract_zh': '酶催化蛋白质水解对于许多生物功能至关重要。准确预测水解位点可以促进药物开发、酶设计以及对生物机制的更深入理解。然而，大多数现有模型仅限于单一酶，忽略了酶之间的共享知识，无法泛化到新酶。因此，我们引入了一个名为{\\method}的统一蛋白质水解位点预测器，它可以泛化到多种酶。为了提高酶编码以促进蛋白质水解位点预测，{\\method}采用了一种新型的生物信息学驱动模型架构，并结合了蛋白水解酶的活性位点知识。广泛实验表明，{\\method}能够在多种蛋白水解酶中，包括未见过的酶，实现高精度的水解位点预测。代码可在以下链接获取：this https URL。', 'title_zh': 'UniZyme：一种增强酶活性位点知识的统一蛋白质切割位点预测器'}
{'arxiv_id': 'arXiv:2502.06913', 'title': 'A Simple yet Effective DDG Predictor is An Unsupervised Antibody Optimizer and Explainer', 'authors': 'Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Guojiang Zhao, Zhifeng Gao, Stan Z. Li', 'link': 'https://arxiv.org/abs/2502.06913', 'abstract': 'The proteins that exist today have been optimized over billions of years of natural evolution, during which nature creates random mutations and selects them. The discovery of functionally promising mutations is challenged by the limited evolutionary accessible regions, i.e., only a small region on the fitness landscape is beneficial. There have been numerous priors used to constrain protein evolution to regions of landscapes with high-fitness variants, among which the change in binding free energy (DDG) of protein complexes upon mutations is one of the most commonly used priors. However, the huge mutation space poses two challenges: (1) how to improve the efficiency of DDG prediction for fast mutation screening; and (2) how to explain mutation preferences and efficiently explore accessible evolutionary regions. To address these challenges, we propose a lightweight DDG predictor (Light-DDG), which adopts a structure-aware Transformer as the backbone and enhances it by knowledge distilled from existing powerful but computationally heavy DDG predictors. Additionally, we augmented, annotated, and released a large-scale dataset containing millions of mutation data for pre-training Light-DDG. We find that such a simple yet effective Light-DDG can serve as a good unsupervised antibody optimizer and explainer. For the target antibody, we propose a novel Mutation Explainer to learn mutation preferences, which accounts for the marginal benefit of each mutation per residue. To further explore accessible evolutionary regions, we conduct preference-guided antibody optimization and evaluate antibody candidates quickly using Light-DDG to identify desirable mutations.', 'abstract_zh': '当今存在的蛋白质在数亿年的自然演化过程中得到了优化，自然界通过产生随机突变并从中选择有利突变。找到具有功能潜力的突变受到进化可访问区域的限制，即仅有一小部分fitness景观是有益的。已经使用了众多先验知识来约束蛋白质进化到具有高fitness变体的景观区域，其中蛋白质复合物在突变后结合自由能的变化（DDG）是最常用的先验知识之一。然而，巨大的突变空间提出了两个挑战：（1）如何提高DDG预测的效率以加快突变筛查；（2）如何解释突变偏好并有效地探索可访问的进化区域。为了解决这些挑战，我们提出了一种轻量级DDG预测器（Light-DDG），其采用结构感知Transformer作为骨干，并通过从现有的强大但计算密集的DDG预测器中提取知识来增强。此外，我们扩充、注释并发布了包含数百万突变数据的大规模数据集，用于预训练Light-DDG。我们发现，这种简单而有效的Light-DDG可以作为良好的无监督抗体优化器和解释器。对于目标抗体，我们提出了一个新的突变解释器来学习突变偏好，并考虑每残基突变的边际效益。为了进一步探索可访问的进化区域，我们进行了偏好引导的抗体优化，并使用Light-DDG快速评估抗体候选物来识别理想的突变。', 'title_zh': '一个简单而有效的DDG预测器是一个无监督的抗体优化器和解释器'}
{'arxiv_id': 'arXiv:2502.06911', 'title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'authors': 'Jing Ren, Tao Tang, Hong Jia, Haytham Fayek, Xiaodong Li, Suyu Ma, Xiwei Xu, Feng Xia', 'link': 'https://arxiv.org/abs/2502.06911', 'abstract': 'As data continues to grow in volume and complexity across domains such as finance, manufacturing, and healthcare, effective anomaly detection is essential for identifying irregular patterns that may signal critical issues. Recently, foundation models (FMs) have emerged as a powerful tool for advancing anomaly detection. They have demonstrated unprecedented capabilities in enhancing anomaly identification, generating detailed data descriptions, and providing visual explanations. This survey presents the first comprehensive review of recent advancements in FM-based anomaly detection. We propose a novel taxonomy that classifies FMs into three categories based on their roles in anomaly detection tasks, i.e., as encoders, detectors, or interpreters. We provide a systematic analysis of state-of-the-art methods and discuss key challenges in leveraging FMs for improved anomaly detection. We also outline future research directions in this rapidly evolving field.', 'abstract_zh': '随着金融、制造和医疗等领域中的数据不断增加并变得更加复杂，有效的异常检测对于识别可能表示关键问题的不规则模式至关重要。近年来，基础模型（FMs）已成为推动异常检测的强大工具。它们展示了前所未有的能力，增强异常识别、生成详细的数据描述，并提供可视化解释。本文综述了基于基础模型的异常检测的最新进展，提出了一个新的分类体系，将FMs分为编码器、检测器或解释器三类。我们对最先进的方法进行了系统分析，并讨论了利用FMs改进异常检测的关键挑战。我们还概述了这一 rapidly evolving领域中的未来研究方向。', 'title_zh': '基于模型的异常检测：愿景与挑战'}
{'arxiv_id': 'arXiv:2502.06910', 'title': 'TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting', 'authors': 'Songtao Huang, Zhen Zhao, Can Li, Lei Bai', 'link': 'https://arxiv.org/abs/2502.06910', 'abstract': 'Real-world time series often have multiple frequency components that are intertwined with each other, making accurate time series forecasting challenging. Decomposing the mixed frequency components into multiple single frequency components is a natural choice. However, the information density of patterns varies across different frequencies, and employing a uniform modeling approach for different frequency components can lead to inaccurate characterization. To address this challenges, inspired by the flexibility of the recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency Decomposition Learning architecture (TimeKAN) to address the complex forecasting challenges caused by multiple frequency mixtures. Specifically, TimeKAN mainly consists of three components: Cascaded Frequency Decomposition (CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and Frequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to obtain series representations for each frequency band. Benefiting from the high flexibility of KAN, we design a novel M-KAN block to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks is used to recombine the frequency bands into the original format. Extensive experimental results across multiple real-world time series datasets demonstrate that TimeKAN achieves state-of-the-art performance as an extremely lightweight architecture. Code is available at this https URL.', 'abstract_zh': '基于Kolmogorov-Arnold网络的频域分解学习架构（TimeKAN）：应对多频混合的时间序列复杂预测挑战', 'title_zh': 'TimeKAN：基于KAN的频率分解学习架构用于长期时间序列预测'}
{'arxiv_id': 'arXiv:2502.06909', 'title': 'Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach', 'authors': 'Xiaohuan Li, Shaowen Qin, Xin Tang, Jiawen Kang, Jin Ye, Zhonghua Zhao, Dusit Niyato', 'link': 'https://arxiv.org/abs/2502.06909', 'abstract': 'Industrial Metaverse leverages the Industrial Internet of Things (IIoT) to integrate data from diverse devices, employing federated learning and meta-computing to train models in a distributed manner while ensuring data privacy. Achieving an immersive experience for industrial Metaverse necessitates maintaining a balance between model quality and training latency. Consequently, a primary challenge in federated learning tasks is optimizing overall system performance by balancing model quality and training latency. This paper designs a satisfaction function that accounts for data size, Age of Information (AoI), and training latency. Additionally, the satisfaction function is incorporated into the utility functions to incentivize node participation in model training. We model the utility functions of servers and nodes as a two-stage Stackelberg game and employ a deep reinforcement learning approach to learn the Stackelberg equilibrium. This approach ensures balanced rewards and enhances the applicability of the incentive scheme for industrial Metaverse. Simulation results demonstrate that, under the same budget constraints, the proposed incentive scheme improves at least 23.7% utility compared to existing schemes without compromising model accuracy.', 'abstract_zh': '工业元宇宙利用工业互联网（IIoT）整合多元设备的数据，通过联邦学习和元计算在分布式环境中训练模型，同时保障数据隐私。实现沉浸式工业元宇宙体验需要在模型质量与训练延迟之间保持平衡。因此，联邦学习任务的主要挑战是通过平衡模型质量和训练延迟来优化整体系统性能。本文设计了一个满意度函数，考虑数据量、信息年龄（AoI）和训练延迟。此外，满意度函数被纳入效用函数中，以激励节点参与模型训练。我们将服务器和节点的效用函数建模为两阶段Stackelberg博弈，并采用深度强化学习方法学习Stackelberg均衡。此方法保证了奖励的均衡分配，增强了激励方案在工业元宇宙中的适用性。仿真结果表明，在相同预算约束下，所提激励方案在不牺牲模型准确性的情况下，至少提高了23.7%的效用。', 'title_zh': '工业元宇宙中基于 satisfication 意识的联邦学习激励方案：基于 DRL 的 Stackelberg 游戏方法'}
{'arxiv_id': 'arXiv:2502.06906', 'title': 'Learning-based estimation of cattle weight gain and its influencing factors', 'authors': 'Muhammad Riaz Hasib Hossain, Rafiqul Islam, Shawn R. McGrath, Md Zahidul Islam, David Lamb', 'link': 'https://arxiv.org/abs/2502.06906', 'abstract': 'Many cattle farmers still depend on manual methods to measure the live weight gain of cattle at set intervals, which is time consuming, labour intensive, and stressful for both the animals and handlers. A remote and autonomous monitoring system using machine learning (ML) or deep learning (DL) can provide a more efficient and less invasive method and also predictive capabilities for future cattle weight gain (CWG). This system allows continuous monitoring and estimation of individual cattle live weight gain, growth rates and weight fluctuations considering various factors like environmental conditions, genetic predispositions, feed availability, movement patterns and behaviour. Several researchers have explored the efficiency of estimating CWG using ML and DL algorithms. However, estimating CWG suffers from a lack of consistency in its application. Moreover, ML or DL can provide weight gain estimations based on several features that vary in existing research. Additionally, previous studies have encountered various data related challenges when estimating CWG. This paper presents a comprehensive investigation in estimating CWG using advanced ML techniques based on research articles (between 2004 and 2024). This study investigates the current tools, methods, and features used in CWG estimation, as well as their strengths and weaknesses. The findings highlight the significance of using advanced ML approaches in CWG estimation and its critical influence on factors. Furthermore, this study identifies potential research gaps and provides research direction on CWG prediction, which serves as a reference for future research in this area.', 'abstract_zh': '基于机器学习技术估算牛活重增重的综述（2004-2024）', 'title_zh': '基于学习的 cattle 体重增长及其影响因素的估算'}
{'arxiv_id': 'arXiv:2502.06905', 'title': 'Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty', 'authors': 'Yeseul Cho, Baekrok Shin, Changmin Kang, Chulhee Yun', 'link': 'https://arxiv.org/abs/2502.06905', 'abstract': 'Recent advances in deep learning rely heavily on massive datasets, leading to substantial storage and training costs. Dataset pruning aims to alleviate this demand by discarding redundant examples. However, many existing methods require training a model with a full dataset over a large number of epochs before being able to prune the dataset, which ironically makes the pruning process more expensive than just training the model on the entire dataset. To overcome this limitation, we introduce a Difficulty and Uncertainty-Aware Lightweight (DUAL) score, which aims to identify important samples from the early training stage by considering both example difficulty and prediction uncertainty. To address a catastrophic accuracy drop at an extreme pruning, we further propose a ratio-adaptive sampling using Beta distribution. Experiments on various datasets and learning scenarios such as image classification with label noise and image corruption, and model architecture generalization demonstrate the superiority of our method over previous state-of-the-art (SOTA) approaches. Specifically, on ImageNet-1k, our method reduces the time cost for pruning to 66% compared to previous methods while achieving a SOTA, specifically 60% test accuracy at a 90% pruning ratio. On CIFAR datasets, the time cost is reduced to just 15% while maintaining SOTA performance.', 'abstract_zh': '近期深度学习的进展高度依赖大规模数据集，导致存储和训练成本显著增加。数据集修剪旨在通过丢弃冗余示例来缓解这一需求。然而，许多现有方法需要在大型数据集上进行多次epoch训练才能修剪数据集，这反过来使得修剪过程比在完整数据集上训练模型更加昂贵。为克服这一限制，我们提出了一种兼顾难度和不确定性的轻量级(DUAL)评分方法，旨在在训练的早期阶段通过同时考虑示例难度和预测不确定性来识别重要样本。为应对极端修剪下的灾难性准确率下降，我们进一步提出了一种基于Beta分布的比率自适应采样方法。在图像分类含有标签噪声和图像腐蚀以及模型架构泛化等各种数据集和学习场景上的实验表明，我们的方法优于之前的最佳方法。具体而言，在ImageNet-1k上，我们的方法将修剪时间成本减少了66%，同时达到最佳测试精度60%，修剪比例为90%。在CIFAR数据集上，时间成本减少了95%，同时保持最佳性能。', 'title_zh': '基于示例难度和预测不确定性无需完全训练进行轻量级数据集剪枝'}
{'arxiv_id': 'arXiv:2502.06902', 'title': 'Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training', 'authors': 'Deven Mahesh Mistry, Anooshka Bajaj, Yash Aggarwal, Sahaj Singh Maini, Zoran Tiganj', 'link': 'https://arxiv.org/abs/2502.06902', 'abstract': 'We investigate in-context temporal biases in attention heads and transformer outputs. Using cognitive science methodologies, we analyze attention scores and outputs of the GPT-2 models of varying sizes. Across attention heads, we observe effects characteristic of human episodic memory, including temporal contiguity, primacy and recency. Transformer outputs demonstrate a tendency toward in-context serial recall. Importantly, this effect is eliminated after the ablation of the induction heads, which are the driving force behind the contiguity effect. Our findings offer insights into how transformers organize information temporally during in-context learning, shedding light on their similarities and differences with human memory and learning.', 'abstract_zh': '我们探讨了上下文中的时间偏向在注意力头和变换器输出中的表现。通过认知科学的方法，我们分析了不同规模GPT-2模型的注意力评分和输出。在注意力头上，我们观察到了与人类事件记忆特征相符的效果，包括时间连续性、首因效应和近因效应。变换器输出显示出倾向于上下文内的序列回忆。重要的是，这种效果在移除诱导头后消失，诱导头是时间连续性效果的主要驱动力。我们的研究提供了关于变换器在上下文学习过程中如何随时间组织信息的见解，揭示了其与人类记忆和学习的相似性和差异性。', 'title_zh': 'Transformer中情景记忆的涌现：训练过程中注意力分数时序结构的变化特征'}
{'arxiv_id': 'arXiv:2502.06899', 'title': 'A Sociotechnical Approach for Knowledge Management (KM)', 'authors': 'Leoncio Jimenez', 'link': 'https://arxiv.org/abs/2502.06899', 'abstract': 'This article presents a sociotechnical framework for KM. This sociotechnical vision of KM allows: (1) to remove KM from a commercial concern; (2) to divide the different KM technologies; and (3) to question the paradigms associated with the social and technical components of KM. It is precisely this last point that this article develops to identify the generic mechanisms of KM. More precisely, the social aspect is explained through the organizational approach to KM, the managerial approach to KM, and the biological approach to KM. In contrast, the technical aspect is described through the knowledge and skills engineering approach to KM. These approaches also lead us to provide a comparative table between these organizational, managerial, and biological visions of KM.', 'abstract_zh': '本文提出了一种社会技术框架用于知识管理。这一社会技术视角的知识管理使得：（1）能够将知识管理从商业关注中剥离出来；（2）能够区分不同的知识管理技术；（3）能够质疑与知识管理的社会和技术成分相关的范式。本文正是围绕这一点进行探讨，以识别通用的知识管理机制。具体而言，社会方面通过组织视角、管理视角和生物视角来解释知识管理，技术方面则通过知识与技能工程视角来描述知识管理。这些视角还引导我们提供组织、管理和生物视角下知识管理的比较表。', 'title_zh': '一种社会技术方法论的知识管理'}
{'arxiv_id': 'arXiv:2502.06894', 'title': 'AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution', 'authors': 'David S. Bhatti, Yougin Choi, Rahman S M Wahidur, Maleeka Bakhtawar, Sumin Kim, Surin Lee, Yongtae Lee, Heung-No Lee', 'link': 'https://arxiv.org/abs/2502.06894', 'abstract': "Hyperspectral imaging (HSI) captures spatial and spectral data, enabling analysis of features invisible to conventional systems. The technology is vital in fields such as weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, and extending into defense, agriculture, and industrial automation at the same time. HSI has advanced with improvements in spectral resolution, miniaturization, and computational methods. This study provides an overview of the HSI, its applications, challenges in data fusion and the role of deep learning models in processing HSI data. We discuss how integration of multimodal HSI with AI, particularly with deep learning, improves classification accuracy and operational efficiency. Deep learning enhances HSI analysis in areas like feature extraction, change detection, denoising unmixing, dimensionality reduction, landcover mapping, data augmentation, spectral construction and super resolution. An emerging focus is the fusion of hyperspectral cameras with large language models (LLMs), referred as highbrain LLMs, enabling the development of advanced applications such as low visibility crash detection and face antispoofing. We also highlight key players in HSI industry, its compound annual growth rate and the growing industrial significance. The purpose is to offer insight to both technical and non-technical audience, covering HSI's images, trends, and future directions, while providing valuable information on HSI datasets and software libraries.", 'abstract_zh': '高光谱成像技术(HSI)捕获空间和光谱数据，使其能够分析传统系统无法识别的特征。该技术在气象监测、食品质量控制、假货检测、医疗诊断以及扩展到国防、农业和工业自动化等多个领域至关重要。HSI随着光谱分辨率、小型化和计算方法的进步而不断发展。本研究提供对HSI及其应用的概述，包括数据融合面临的挑战以及深度学习模型在处理HSI数据中的作用。我们讨论了将多模态HSI与AI，尤其是深度学习相结合，如何提高分类准确性和操作效率。深度学习增强了HSI在特征提取、变化检测、去噪解混、降维、土地覆盖制图、数据增强、光谱重建和超分辨率等方面的应用。新兴的研究焦点是将高光谱摄像头与大型语言模型结合，称为高脑大型语言模型(高脑LLM)，这使得低能见度碰撞检测和人脸识别防伪等高级应用成为可能。我们还强调了在HSI产业中的关键参与者、复合年增长率以及日益增长的工业价值。目标是为技术与非技术人员提供洞见，涵盖HSI的图像、趋势和未来方向，同时提供有价值的HSI数据集和软件库信息。', 'title_zh': 'AI驱动的HSI：多模态、融合、挑战及深度学习革命'}
{'arxiv_id': 'arXiv:2502.06888', 'title': 'Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline', 'authors': 'Zhiyuan Fang, Yuegui Huang, Zicong Hong, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng', 'link': 'https://arxiv.org/abs/2502.06888', 'abstract': 'Mixture of Experts (MoE), with its distinctive sparse structure, enables the scaling of language models up to trillions of parameters without significantly increasing computational costs. However, the substantial parameter size presents a challenge for inference, as the expansion in GPU memory cannot keep pace with the growth in parameters. Although offloading techniques utilise memory from the CPU and disk and parallelise the I/O and computation for efficiency, the computation for each expert in MoE models is often less than the I/O, resulting in numerous bubbles in the pipeline.\nTherefore, we propose Klotski, an efficient MoE inference engine that significantly reduces pipeline bubbles through a novel expert-aware multi-batch pipeline paradigm. The proposed paradigm uses batch processing to extend the computation time of the current layer to overlap with the loading time of the next layer. Although this idea has been effectively applied to dense models, more batches may activate more experts in the MoE, leading to longer loading times and more bubbles. Thus, unlike traditional approaches, we balance computation and I/O time and minimise bubbles by orchestrating their inference orders based on their heterogeneous computation and I/O requirements and activation patterns under different batch numbers. Moreover, to adapt to different hardware environments and models, we design a constraint-sensitive I/O-compute planner and a correlation-aware expert prefetcher for a schedule that minimises pipeline bubbles. Experimental results demonstrate that Klotski achieves a superior throughput-latency trade-off compared to state-of-the-art techniques, with throughput improvements of up to 85.12x.', 'abstract_zh': 'MoE模型的Klotski：一种通过专家感知多批次管道 paradigm显著减少管道气泡的高效MoE推理引擎', 'title_zh': 'Klotski: 专家意识多批次管道高效混合专家推理'}
{'arxiv_id': 'arXiv:2502.06887', 'title': 'Gradient Based Method for the Fusion of Lattice Quantizers', 'authors': 'Liyuan Zhang, Hanzhong Cao, Jiaheng Li, Minyang Yu', 'link': 'https://arxiv.org/abs/2502.06887', 'abstract': 'In practical applications, lattice quantizers leverage discrete lattice points to approximate arbitrary points in the lattice. An effective lattice quantizer significantly enhances both the accuracy and efficiency of these approximations. In the context of high-dimensional lattice quantization, previous work proposed utilizing low-dimensional optimal lattice quantizers and addressed the challenge of determining the optimal length ratio in orthogonal splicing. Notably, it was demonstrated that fixed length ratios and orthogonality yield suboptimal results when combining low-dimensional lattices. Building on this foundation, another approach employed gradient descent to identify optimal lattices, which inspired us to explore the use of neural networks to discover matrices that outperform those obtained from orthogonal splicing methods. We propose two novel approaches to tackle this problem: the Household Algorithm and the Matrix Exp Algorithm. Our results indicate that both the Household Algorithm and the Matrix Exp Algorithm achieve improvements in lattice quantizers across dimensions 13, 15, 17 to 19, 21, and 22. Moreover, the Matrix Exp Algorithm demonstrates superior efficacy in high-dimensional settings.', 'abstract_zh': '晶格量化在实际应用中利用离散晶格点近似晶格中的任意点。有效的晶格量化器显著提高了这些近似的准确性和效率。在高维晶格量化领域，先前的工作提出了使用低维最优晶格量化器，并解决了正交拼接中最佳长度比确定的挑战。值得注意的是，固定长度比和正交性在结合低维晶格时会导致次优结果。在此基础上，另一种方法使用梯度下降来识别最优晶格，这激发了我们探索使用神经网络发现超越正交拼接方法的矩阵的可能性。我们提出两种新的方法来解决这一问题：Household算法和Matrix Exp算法。我们的结果显示，这两种方法在维度为13, 15, 17到19, 21和22时都能提升晶格量化器的效果。此外，Matrix Exp算法在高维设置中表现出更高的有效性。', 'title_zh': '基于梯度的方法对格量化器的融合'}
{'arxiv_id': 'arXiv:2502.06871', 'title': 'FlavorDiffusion: Predicting Food Pairings and Chemical Interactions Using Diffusion Models', 'authors': 'Seo Jun Pyo', 'link': 'https://arxiv.org/abs/2502.06871', 'abstract': 'The study of food pairing has evolved beyond subjective expertise with the advent of machine learning. This paper presents FlavorDiffusion, a novel framework leveraging diffusion models to predict food-chemical interactions and ingredient pairings without relying on chromatography. By integrating graph-based embeddings, diffusion processes, and chemical property encoding, FlavorDiffusion addresses data imbalances and enhances clustering quality. Using a heterogeneous graph derived from datasets like Recipe1M and FlavorDB, our model demonstrates superior performance in reconstructing ingredient-ingredient relationships. The addition of a Chemical Structure Prediction (CSP) layer further refines the embedding space, achieving state-of-the-art NMI scores and enabling meaningful discovery of novel ingredient combinations. The proposed framework represents a significant step forward in computational gastronomy, offering scalable, interpretable, and chemically informed solutions for food science.', 'abstract_zh': '食品配对的研究已超越主观专长，随着机器学习的出现而不断发展。本文介绍了FlavorDiffusion，这是一种利用扩散模型预测食品-化学物质相互作用和食材配对的新框架，不依赖于色谱技术。通过集成图嵌入、扩散过程和化学性质编码，FlavorDiffusion解决了数据不平衡问题，提高了聚类质量。利用来自Recipe1M和FlavorDB等数据集的异构图，我们的模型在重构食材-食材关系方面表现出优越性能。添加化学结构预测（CSP）层进一步细化了嵌入空间，实现了最先进的NMI分数，并能够发现有意义的新型食材组合。所提出的框架代表了计算美食学的一个重要进展，提供了可扩展、可解释且基于化学的食品科学解决方案。', 'title_zh': 'FlavorDiffusion：利用扩散模型预测食物配对和化学交互作用'}
{'arxiv_id': 'arXiv:2502.06870', 'title': 'Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning', 'authors': 'Chengkai Han, Jingyuan Wang, Yongyao Wang, Xie Yu, Hao Lin, Chao Li, Junjie Wu', 'link': 'https://arxiv.org/abs/2502.06870', 'abstract': "Effective urban traffic management is vital for sustainable city development, relying on intelligent systems with machine learning tasks such as traffic flow prediction and travel time estimation. Traditional approaches usually focus on static road network and trajectory representation learning, and overlook the dynamic nature of traffic states and trajectories, which is crucial for downstream tasks. To address this gap, we propose TRACK, a novel framework to bridge traffic state and trajectory data for dynamic road network and trajectory representation learning. TRACK leverages graph attention networks (GAT) to encode static and spatial road segment features, and introduces a transformer-based model for trajectory representation learning. By incorporating transition probabilities from trajectory data into GAT attention weights, TRACK captures dynamic spatial features of road segments. Meanwhile, TRACK designs a traffic transformer encoder to capture the spatial-temporal dynamics of road segments from traffic state data. To further enhance dynamic representations, TRACK proposes a co-attentional transformer encoder and a trajectory-traffic state matching task. Extensive experiments on real-life urban traffic datasets demonstrate the superiority of TRACK over state-of-the-art baselines. Case studies confirm TRACK's ability to capture spatial-temporal dynamics effectively.", 'abstract_zh': '有效的城市交通管理对于可持续城市发展至关重要，依赖于具有交通流预测和旅行时间估计等机器学习任务的智能系统。传统的方法通常专注于静态道路网络和轨迹表示学习，而忽略了交通状态和轨迹的动态特性，这对下游任务至关重要。为了弥补这一不足，我们提出了TRACK，这是一种新的框架，用于桥接交通状态和轨迹数据以进行动态道路网络和轨迹表示学习。TRACK利用图注意力网络（GAT）编码静态和空间道路段特征，并引入了一个基于变换器的模型进行轨迹表示学习。通过将轨迹数据中的转换概率纳入GAT注意力权重中，TRACK捕捉道路段的动态空间特征。同时，TRACK设计了一个交通变换器编码器，从交通状态数据中捕捉道路段的空间-时间动态。为了进一步增强动态表示，TRACK提出了共注意变换器编码器和轨迹-交通状态匹配任务。在真实城市交通数据集上的广泛实验表明，TRACK在最先进的基线方法上具有优越性。案例研究证实了TRACK有效捕捉空间-时间动态的能力。', 'title_zh': '交通状态与轨迹融合的动态道路网络和轨迹表示学习'}
{'arxiv_id': 'arXiv:2502.06866', 'title': 'Global Ease of Living Index: a machine learning framework for longitudinal analysis of major economies', 'authors': 'Tanay Panat, Rohitash Chandra', 'link': 'https://arxiv.org/abs/2502.06866', 'abstract': 'The drastic changes in the global economy, geopolitical conditions, and disruptions such as the COVID-19 pandemic have impacted the cost of living and quality of life. It is important to understand the long-term nature of the cost of living and quality of life in major economies. A transparent and comprehensive living index must include multiple dimensions of living conditions. In this study, we present an approach to quantifying the quality of life through the Global Ease of Living Index that combines various socio-economic and infrastructural factors into a single composite score. Our index utilises economic indicators that define living standards, which could help in targeted interventions to improve specific areas. We present a machine learning framework for addressing the problem of missing data for some of the economic indicators for specific countries. We then curate and update the data and use a dimensionality reduction approach (principal component analysis) to create the Ease of Living Index for major economies since 1970. Our work significantly adds to the literature by offering a practical tool for policymakers to identify areas needing improvement, such as healthcare systems, employment opportunities, and public safety. Our approach with open data and code can be easily reproduced and applied to various contexts. This transparency and accessibility make our work a valuable resource for ongoing research and policy development in quality-of-life assessment.', 'abstract_zh': '全球经济发展、地缘政治条件的剧变以及COVID-19等 disruptive 因素对生活成本和生活质量产生了影响。理解主要经济体长期的生活成本和生活质量特征至关重要。一个透明且全面的生活指数必须涵盖多个生活条件维度。在本研究中，我们通过将多种经济社会和基础设施因素整合为一个综合得分，提出了通过全球生活便利指数量化生活质量的方法。我们的指数利用了定义生活标准的经济指标，有助于针对特定领域实施干预措施。我们还提出了针对某些经济指标在特定国家缺失数据的机器学习框架。然后，我们整理和更新数据，并使用降维方法（主成分分析）创造了自1970年以来主要经济体的生活便利指数。我们通过提供一个实用工具显著丰富了文献，该工具可以帮助政策制定者识别需要改进的领域，如医疗保健系统、就业机会和公共安全。我们的方法使用开放数据和代码可以轻松重现并应用于各种情境下。这种透明性和可访问性使我们的工作成为生活质量评估持续研究和政策发展的重要资源。', 'title_zh': '全球宜居指数：主要经济体 longitudinal 分析的机器学习框架'}
{'arxiv_id': 'arXiv:2502.06861', 'title': 'Design Considerations in Offline Preference-based RL', 'authors': 'Alekh Agarwal, Christoph Dann, Teodor V. Marinov', 'link': 'https://arxiv.org/abs/2502.06861', 'abstract': 'Offline algorithms for Reinforcement Learning from Human Preferences (RLHF), which use only a fixed dataset of sampled responses given an input, and preference feedback among these responses, have gained increasing prominence in the literature on aligning language models. In this paper, we study how the different design choices made in methods such as DPO, IPO, SLiC and many variants influence the quality of the learned policy, from a theoretical perspective. Our treatment yields insights into the choices of loss function, the policy which is used to normalize log-likelihoods, and also the role of the data sampling policy. Notably, our results do not rely on the standard reparameterization-style arguments used to motivate some of the algorithms in this family, which allows us to give a unified treatment to a broad class of methods. We also conduct a small empirical study to verify some of the theoretical findings on a standard summarization benchmark.', 'abstract_zh': '基于人类偏好 reinforcement learning 的离线算法（RLHF）：从固定数据集和响应间的偏好反馈中学习策略的设计选择及其理论影响', 'title_zh': '基于离线偏好强化学习的设计考虑'}
{'arxiv_id': 'arXiv:2502.06857', 'title': 'Gemstones: A Model Suite for Multi-Faceted Scaling Laws', 'authors': 'Sean McLeish, John Kirchenbauer, David Yu Miller, Siddharth Singh, Abhinav Bhatele, Micah Goldblum, Ashwinee Panda, Tom Goldstein', 'link': 'https://arxiv.org/abs/2502.06857', 'abstract': 'Scaling laws are typically fit using a family of models with a narrow range of frozen hyper-parameter choices. In this work we study scaling laws using a wide range of architecture and hyper-parameter choices, and highlight their impact on resulting prescriptions. As a primary artifact of our research, we release the Gemstones: the most comprehensive open-source scaling law dataset to date, consisting of over 4000 checkpoints from transformers with up to 2 billion parameters; these models have been trained with different learning rates, cooldown schedules, and architectural shapes. Our checkpoints enable more complex studies of scaling, such as a law that predicts language modeling performance as a function of model width and depth. By examining the various facets of our model suite, we find that the prescriptions of scaling laws can be highly sensitive to the experimental design process and the specific model checkpoints used during fitting. Code: this https URL', 'abstract_zh': 'Scaling规律通常使用具有窄范围冻结超参数的选择来拟合。在本项工作中，我们使用广泛的架构和超参数选择研究Scaling规律，并强调其对最终建议的影响。作为我们研究的主要成果，我们发布了Gemstones：迄今为止最全面的开源Scaling规律数据集，包含超过4000个参数量高达20亿的变换器检查点；这些模型是在不同的学习率、冷却计划和架构形状下训练的。我们的检查点使人们能够进行更为复杂的Scaling研究，例如预测模型宽度和深度作为语言建模性能函数的规律。通过对我们的模型套件的各种方面的研究，我们发现Scaling规律的处方对实验设计过程和拟合过程中使用的具体模型检查点的高度敏感。代码：this https URL', 'title_zh': '宝石：一个多面 scaling 规律模型套件'}
{'arxiv_id': 'arXiv:2502.06853', 'title': 'Native Fortran Implementation of TensorFlow-Trained Deep and Bayesian Neural Networks', 'authors': 'Aidan Furlong, Xingang Zhao, Bob Salko, Xu Wu', 'link': 'https://arxiv.org/abs/2502.06853', 'abstract': "Over the past decade, the investigation of machine learning (ML) within the field of nuclear engineering has grown significantly. With many approaches reaching maturity, the next phase of investigation will determine the feasibility and usefulness of ML model implementation in a production setting. Several of the codes used for reactor design and assessment are primarily written in the Fortran language, which is not immediately compatible with TensorFlow-trained ML models. This study presents a framework for implementing deep neural networks (DNNs) and Bayesian neural networks (BNNs) in Fortran, allowing for native execution without TensorFlow's C API, Python runtime, or ONNX conversion. Designed for ease of use and computational efficiency, the framework can be implemented in any Fortran code, supporting iterative solvers and UQ via ensembles or BNNs. Verification was performed using a two-input, one-output test case composed of a noisy sinusoid to compare Fortran-based predictions to those from TensorFlow. The DNN predictions showed negligible differences and achieved a 19.6x speedup, whereas the BNN predictions exhibited minor disagreement, plausibly due to differences in random number generation. An 8.0x speedup was noted for BNN inference. The approach was then further verified on a nuclear-relevant problem predicting critical heat flux (CHF), which demonstrated similar behavior along with significant computational gains. Discussion regarding the framework's successful integration into the CTF thermal-hydraulics code is also included, outlining its practical usefulness. Overall, this framework was shown to be effective at implementing both DNN and BNN model inference within Fortran, allowing for the continued study of ML-based methods in real-world nuclear applications.", 'abstract_zh': '过去十年间，核工程领域内机器学习（ML）的研究取得了显著增长。随着许多方法达到成熟阶段，下一阶段的研究将确定ML模型在生产环境中的可行性和实用性。许多用于反应堆设计和评估的代码主要用Fortran语言编写，这使得与TensorFlow训练的ML模型不直接兼容。本研究提出了一种在Fortran中实现深度神经网络（DNNs）和贝叶斯神经网络（BNNs）的框架，允许在无需TensorFlow的C API、Python运行时或ONNX转换的情况下原生执行。该框架设计用于易用性和计算效率，可应用于任何Fortran代码，支持迭代求解器和UQ通过集成或BNN。通过一个包含噪声正弦波的两输入一输出测试案例进行验证，比较了基于Fortran的预测与TensorFlow的预测结果。DNN预测显示出微小差异，实现了约19.6倍的速度提升，而BNN预测则表现出轻微的分歧，这可能是由于随机数生成的不同。BNN推理的速度提升为8.0倍。该方法随后在预测关键热流密度（CHF）的核相关问题上进行了进一步验证，显示了类似的行为以及显著的计算优势。还讨论了该框架成功集成到CTF热液压代码中的情况，概述了其实际应用价值。总之，该框架展示了在Fortran中实现DNN和BNN模型推理的有效性，允许在实际核应用中继续研究基于ML的方法。', 'title_zh': 'Native Fortran Implementation of TensorFlow-Trained Deep and Bayesian Neural Networks\n\n原标题为：\n基于TensorFlow训练的深度和贝叶斯神经网络的原生Fortran实现'}
{'arxiv_id': 'arXiv:2502.06852', 'title': 'EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification', 'authors': 'Lin Zhang, Wenshuo Dong, Zhuoran Zhang, Shu Yang, Lijie Hu, Ninghao Liu, Pan Zhou, Di Wang', 'link': 'https://arxiv.org/abs/2502.06852', 'abstract': 'Understanding the internal mechanisms of transformer-based language models remains challenging. Mechanistic interpretability based on circuit discovery aims to reverse engineer neural networks by analyzing their internal processes at the level of computational subgraphs. In this paper, we revisit existing gradient-based circuit identification methods and find that their performance is either affected by the zero-gradient problem or saturation effects, where edge attribution scores become insensitive to input changes, resulting in noisy and unreliable attribution evaluations for circuit components. To address the saturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP), EAP-GP introduces an integration path, starting from the input and adaptively following the direction of the difference between the gradients of corrupted and clean inputs to avoid the saturated region. This approach enhances attribution reliability and improves the faithfulness of circuit identification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2 Medium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms existing methods in circuit faithfulness, achieving improvements up to 17.7%. Comparisons with manually annotated ground-truth circuits demonstrate that EAP-GP achieves precision and recall comparable to or better than previous approaches, highlighting its effectiveness in identifying accurate circuits.', 'abstract_zh': '基于电路发现的机制解释：理解变压器语言模型的内部机制仍然具有挑战性。Edge Attribution Patching with GradPath (EAP-GP)及其对电路识别机制可靠性和准确性的影响', 'title_zh': 'EAP-GP: 减轻基于梯度的自动电路识别中的饱和效应'}
{'arxiv_id': 'arXiv:2502.06849', 'title': 'Model Fusion via Neuron Transplantation', 'authors': 'Muhammed Öz, Nicholas Kiefer, Charlotte Debus, Jasmin Hörter, Achim Streit, Markus Götz', 'link': 'https://arxiv.org/abs/2502.06849', 'abstract': 'Ensemble learning is a widespread technique to improve the prediction performance of neural networks. However, it comes at the price of increased memory and inference time. In this work we propose a novel model fusion technique called \\emph{Neuron Transplantation (NT)} in which we fuse an ensemble of models by transplanting important neurons from all ensemble members into the vacant space obtained by pruning insignificant neurons. An initial loss in performance post-transplantation can be quickly recovered via fine-tuning, consistently outperforming individual ensemble members of the same model capacity and architecture. Furthermore, NT enables all the ensemble members to be jointly pruned and jointly trained in a combined model. Comparing it to alignment-based averaging (like Optimal-Transport-fusion), it requires less fine-tuning than the corresponding OT-fused model, the fusion itself is faster and requires less memory, while the resulting model performance is comparable or better. The code is available under the following link: this https URL.', 'abstract_zh': '集成学习是一种常用的提高神经网络预测性能的技术，但会导致内存和推理时间的增加。本文提出了一种新颖的模型融合技术——神经元移植（Neuron Transplantation，NT），通过将所有ensemble成员中的重要神经元移植到剪枝掉不重要神经元后获得的空位中来融合ensemble。移植后性能的初始下降可以通过微调迅速恢复，且一致地优于同一模型容量和架构的individual ensemble成员。此外，NT允许ensemble成员在联合模型中共同剪枝和共同训练。与基于对齐的平均（如Optimal-Transport融合）相比，NT需要更少的微调、融合本身更快且需要更少的内存，而得到的模型性能相当或更优。代码可在以下链接获取：this https URL。', 'title_zh': '神经元移植驱动的模型融合'}
{'arxiv_id': 'arXiv:2502.06848', 'title': 'Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation', 'authors': 'Siqi Shen, Yu Liu, Daniel Biggs, Omar Hafez, Jiandong Yu, Wentao Zhang, Bin Cui, Jiulong Shan', 'link': 'https://arxiv.org/abs/2502.06848', 'abstract': 'In recent years, Graph Neural Network (GNN) based models have shown promising results in simulating physics of complex systems. However, training dedicated graph network based physics simulators can be costly, as most models are confined to fully supervised training, which requires extensive data generated from traditional physics simulators. To date, how transfer learning could improve the model performance and training efficiency has remained unexplored. In this work, we introduce a pre-training and transfer learning paradigm for graph network simulators. We propose the scalable graph U-net (SGUNET). Incorporating an innovative depth-first search (DFS) pooling, the SGUNET is adaptable to different mesh sizes and resolutions for various simulation tasks. To enable the transfer learning between differently configured SGUNETs, we propose a set of mapping functions to align the parameters between the pre-trained model and the target model. An extra normalization term is also added into the loss to constrain the difference between the pre-trained weights and target model weights for better generalization performance. To pre-train our physics simulator we created a dataset which includes 20,000 physical simulations of randomly selected 3D shapes from the open source A Big CAD (ABC) dataset. We show that our proposed transfer learning methods allow the model to perform even better when fine-tuned with small amounts of training data than when it is trained from scratch with full extensive dataset. On the 2D Deformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 of the training data achieved an 11.05\\% improvement in position RMSE compared to the model trained from scratch.', 'abstract_zh': '基于图神经网络的物理学模拟器的预训练和迁移学习范式', 'title_zh': '可扩展图神经网络中的转移学习以改善物理仿真'}
{'arxiv_id': 'arXiv:2502.06845', 'title': 'DiffNMR3: Advancing NMR Resolution Beyond Instrumental Limits', 'authors': 'Sen Yan, Etienne Goffinet, Fabrizio Gabellieri, Ryan Young, Lydia Gkoura, Laurence Jennings, Filippo Castiglione, Thomas Launey', 'link': 'https://arxiv.org/abs/2502.06845', 'abstract': 'Nuclear Magnetic Resonance (NMR) spectroscopy is a crucial analytical technique used for molecular structure elucidation, with applications spanning chemistry, biology, materials science, and medicine. However, the frequency resolution of NMR spectra is limited by the "field strength" of the instrument. High-field NMR instruments provide high-resolution spectra but are prohibitively expensive, whereas lower-field instruments offer more accessible, but lower-resolution, results. This paper introduces an AI-driven approach that not only enhances the frequency resolution of NMR spectra through super-resolution techniques but also provides multi-scale functionality. By leveraging a diffusion model, our method can reconstruct high-field spectra from low-field NMR data, offering flexibility in generating spectra at varying magnetic field strengths. These reconstructions are comparable to those obtained from high-field instruments, enabling finer spectral details and improving molecular characterization. To date, our approach is one of the first to overcome the limitations of instrument field strength, achieving NMR super-resolution through AI. This cost-effective solution makes high-resolution analysis accessible to more researchers and industries, without the need for multimillion-dollar equipment.', 'abstract_zh': '基于AI的高分辨率NMR光谱重建方法', 'title_zh': 'DiffNMR3: 超越仪器极限提升核磁共振分辨率'}
{'arxiv_id': 'arXiv:2502.06839', 'title': 'A Hybrid Model for Weakly-Supervised Speech Dereverberation', 'authors': 'Louis Bahrman, Mathieu Fontaine, Gael Richard', 'link': 'https://arxiv.org/abs/2502.06839', 'abstract': "This paper introduces a new training strategy to improve speech dereverberation systems using minimal acoustic information and reverberant (wet) speech. Most existing algorithms rely on paired dry/wet data, which is difficult to obtain, or on target metrics that may not adequately capture reverberation characteristics and can lead to poor results on non-target metrics. Our approach uses limited acoustic information, like the reverberation time (RT60), to train a dereverberation system. The system's output is resynthesized using a generated room impulse response and compared with the original reverberant speech, providing a novel reverberation matching loss replacing the standard target metrics. During inference, only the trained dereverberation model is used. Experimental results demonstrate that our method achieves more consistent performance across various objective metrics used in speech dereverberation than the state-of-the-art.", 'abstract_zh': '本文介绍了一种新的训练策略，通过最少的声学信息和混响（湿）语音来提高语音去混响系统性能。现有的大多数算法依赖于配对的干/湿数据，这些数据难以获得，或者依赖可能无法充分捕捉混响特性的目标指标，从而可能导致在非目标指标上表现不佳。我们的方法使用有限的声学信息，如混响时间（RT60），来训练去混响系统。系统的输出利用生成的房间冲激响应重新合成，并与原始混响语音进行比较，从而提供一种新颖的混响匹配损失替代标准的目标指标。在推理过程中，仅使用训练好的去混响模型。实验结果表明，我们的方法在各种用于语音去混响的客观指标上获得了更一致的性能，优于现有最先进的方法。', 'title_zh': '一种弱监督语音混响消除的混合模型'}
{'arxiv_id': 'arXiv:2502.06834', 'title': 'A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems', 'authors': 'Hamid Eghbalzadeh, Yang Wang, Rui Li, Yuji Mo, Qin Ding, Jiaxiang Fu, Liang Dai, Shuo Gu, Nima Noorshams, Sem Park, Bo Long, Xue Feng', 'link': 'https://arxiv.org/abs/2502.06834', 'abstract': "Industrial ads ranking systems conventionally rely on labeled impression data, which leads to challenges such as overfitting, slower incremental gain from model scaling, and biases due to discrepancies between training and serving data. To overcome these issues, we propose a Unified framework for Knowledge-Distillation and Semi-supervised Learning (UKDSL) for ads ranking, empowering the training of models on a significantly larger and more diverse datasets, thereby reducing overfitting and mitigating training-serving data discrepancies. We provide detailed formal analysis and numerical simulations on the inherent miscalibration and prediction bias of multi-stage ranking systems, and show empirical evidence of the proposed framework's capability to mitigate those. Compared to prior work, UKDSL can enable models to learn from a much larger set of unlabeled data, hence, improving the performance while being computationally efficient. Finally, we report the successful deployment of UKDSL in an industrial setting across various ranking models, serving users at multi-billion scale, across various surfaces, geological locations, clients, and optimize for various events, which to the best of our knowledge is the first of its kind in terms of the scale and efficiency at which it operates.", 'abstract_zh': '一种统一的知识蒸馏和半监督学习框架（UKDSL）用于广告排名：在大规模和多样数据集上训练模型，减少过拟合和缓解训练与服务数据的偏差，同时提高性能并保持计算效率，并在工业规模上多种排名模型中成功部署。', 'title_zh': '统一的知识蒸馏与半监督学习框架以改善工业广告交付系统'}
{'arxiv_id': 'arXiv:2502.06832', 'title': 'Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach', 'authors': 'Xu Zhang, Kaidi Xu, Ziqing Hu, Ren Wang', 'link': 'https://arxiv.org/abs/2502.06832', 'abstract': 'Mixture of Experts (MoE) have shown remarkable success in leveraging specialized expert networks for complex machine learning tasks. However, their susceptibility to adversarial attacks presents a critical challenge for deployment in robust applications. This paper addresses the critical question of how to incorporate robustness into MoEs while maintaining high natural accuracy. We begin by analyzing the vulnerability of MoE components, finding that expert networks are notably more susceptible to adversarial attacks than the router. Based on this insight, we propose a targeted robust training technique that integrates a novel loss function to enhance the adversarial robustness of MoE, requiring only the robustification of one additional expert without compromising training or inference efficiency. Building on this, we introduce a dual-model strategy that linearly combines a standard MoE model with our robustified MoE model using a smoothing parameter. This approach allows for flexible control over the robustness-accuracy trade-off. We further provide theoretical foundations by deriving certified robustness bounds for both the single MoE and the dual-model. To push the boundaries of robustness and accuracy, we propose a novel joint training strategy JTDMoE for the dual-model. This joint training enhances both robustness and accuracy beyond what is achievable with separate models. Experimental results on CIFAR-10 and TinyImageNet datasets using ResNet18 and Vision Transformer (ViT) architectures demonstrate the effectiveness of our proposed methods.', 'abstract_zh': '混合专家模型（MoE）在利用专业化专家网络处理复杂机器学习任务方面显示出了显著的成功。然而，它们对对抗攻击的高度敏感性为其实现鲁棒应用的部署带来了关键挑战。本文探讨了如何在保持高自然准确率的同时，将鲁棒性融入到MoE中。我们首先分析了MoE组件的脆弱性，发现专家网络比路由器更易受到对抗攻击的影响。基于这一洞察，我们提出了一种针对对抗鲁棒性的有目标训练技术，通过引入一种新颖的损失函数来增强MoE的对抗鲁棒性，只需对一个额外的专家进行鲁棒化处理，而不影响训练和推理效率。在此基础上，我们提出了一种双重模型策略，通过平滑参数线性结合标准的MoE模型与我们的鲁棒化MoE模型。这种方法允许灵活控制鲁棒性和准确性的权衡。我们还提供了理论基础，为单一MoE和双重模型分别推导了认证的鲁棒性界限。为了进一步提升鲁棒性和准确性的边界，我们提出了双重模型的联合训练策略JTDMoE。这种联合训练策略在提升鲁棒性和准确性方面超过了单独模型的效果。使用ResNet18和视觉变换器（ViT）架构在CIFAR-10和TinyImageNet数据集上的实验结果证明了所提出方法的有效性。', 'title_zh': '优化专家混合模型的健壮性和准确性：一种双模型方法'}
{'arxiv_id': 'arXiv:2502.06831', 'title': 'No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data', 'authors': 'Daniel Cai, Randall Balestriero', 'link': 'https://arxiv.org/abs/2502.06831', 'abstract': 'Implicit neural representations (INRs) exhibit growing promise in addressing Earth representation challenges, ranging from emissions monitoring to climate modeling. However, existing methods disproportionately prioritize global average performance, whereas practitioners require fine-grained insights to understand biases and variations in these models. To bridge this gap, we introduce FAIR-Earth: a first-of-its-kind dataset explicitly crafted to examine and challenge inequities in Earth representations. FAIR-Earth comprises various high-resolution Earth signals and uniquely aggregates extensive metadata along stratifications like landmass size and population density to assess the fairness of models. Evaluating state-of-the-art INRs across the various modalities of FAIR-Earth, we uncover striking performance disparities. Certain subgroups, especially those associated with high-frequency signals (e.g., islands, coastlines), are consistently poorly modeled by existing methods. In response, we propose spherical wavelet encodings, building on previous spatial encoding research. Leveraging the multi-resolution capabilities of wavelets, our encodings yield consistent performance over various scales and locations, offering more accurate and robust representations of the biased subgroups. These open-source contributions represent a crucial step towards the equitable assessment and deployment of Earth INRs.', 'abstract_zh': '隐神经表示（INRs）在应对地球表示挑战方面展现出日益增长的潜力，从排放监测到气候建模等。然而，现有方法过度倾向于关注全球平均水平性能，而实践者需要细粒度的见解来理解这些模型中的偏差和变异性。为弥合这一差距，我们介绍FAIR-Earth：首个明确设计用于检视和挑战地球表示中的不平等性的数据集。FAIR-Earth 包含各种高分辨率地球信号，并且独特地沿陆地面积和人口密度等分层综合大量元数据，以评估模型的公平性。我们在FAIR-Earth的各种模态上评估最新的INRs，发现了显著的性能差异。某些子群体，尤其是与高频信号相关的子群体（例如，岛屿、海岸线），现有方法一致性地建模不佳。为应对这一挑战，我们提出球面小波编码，基于之前的空间编码研究。利用小波的多分辨率能力，我们的编码在各种尺度和位置上表现一致，为那些偏差子群体提供更准确和稳健的表示。这些开源贡献是实现公平评估和部署地球INRs的关键步骤。', 'title_zh': '不让任何一个地点落后：衡量和改进地球数据隐含表示的公平性'}
{'arxiv_id': 'arXiv:2502.06830', 'title': 'OrderFusion: Encoding Orderbook for Probabilistic Intraday Price Prediction', 'authors': 'Runyao Yu, Yuchen Tao, Fabian Leimgruber, Tara Esterl, Jochen L. Cremer', 'link': 'https://arxiv.org/abs/2502.06830', 'abstract': 'Efficient and reliable probabilistic prediction of intraday electricity prices is essential to manage market uncertainties and support robust trading strategies. However, current methods often suffer from parameter inefficiencies, as they fail to fully exploit the potential of modeling interdependencies between bids and offers in the orderbook, requiring a large number of parameters for representation learning. Furthermore, these methods face the quantile crossing issue, where upper quantiles fall below the lower quantiles, resulting in unreliable probabilistic predictions. To address these two challenges, we propose an encoding method called OrderFusion and design a hierarchical multi-quantile head. The OrderFusion encodes the orderbook into a 2.5D representation, which is processed by a tailored jump cross-attention backbone to capture the interdependencies of bids and offers, enabling parameter-efficient learning. The head sets the median quantile as an anchor and predicts multiple quantiles hierarchically, ensuring reliability by enforcing monotonicity between quantiles through non-negative functions. Extensive experiments and ablation studies are conducted on four price indices: 60-min ID3, 60-min ID1, 15-min ID3, and 15-min ID1 using the German orderbook over three years to ensure a fair evaluation. The results confirm that our design choices improve overall performance, offering a parameter-efficient and reliable solution for probabilistic intraday price prediction.', 'abstract_zh': '高效的OrderFusion编码和层次多分位数头在日内 electricity 价格的概率预测中的有效可靠方法', 'title_zh': 'OrderFusion: 编码订单簿进行日内价格概率预测'}
{'arxiv_id': 'arXiv:2502.06829', 'title': 'Convolution-Based Converter : A Weak-Prior Approach For Modeling Stochastic Processes Based On Conditional Density Estimation', 'authors': 'Chaoran Pang, Shuangrong Liu, Shikun Tian, WenHao Yue, Xingshen Zhang, Lin Wang, Bo Yang', 'link': 'https://arxiv.org/abs/2502.06829', 'abstract': 'In this paper, a Convolution-Based Converter (CBC) is proposed to develop a methodology for removing the strong or fixed priors in estimating the probability distribution of targets based on observations in the stochastic process. Traditional approaches, e.g., Markov-based and Gaussian process-based methods, typically leverage observations to estimate targets based on strong or fixed priors (such as Markov properties or Gaussian prior). However, the effectiveness of these methods depends on how well their prior assumptions align with the characteristics of the problem. When the assumed priors are not satisfied, these approaches may perform poorly or even become unusable. To overcome the above limitation, we introduce the Convolution-Based converter (CBC), which implicitly estimates the conditional probability distribution of targets without strong or fixed priors, and directly outputs the expected trajectory of the stochastic process that satisfies the constraints from observations. This approach reduces the dependence on priors, enhancing flexibility and adaptability in modeling stochastic processes when addressing different problems. Experimental results demonstrate that our method outperforms existing baselines across multiple metrics.', 'abstract_zh': '基于卷积的转换器（CBC）用于去除基于观测在随机过程中估计目标概率分布中的强先验或固定先验的方法。', 'title_zh': '基于卷积的转换器：一种基于条件密度估计的弱先验方法用于建模随机过程'}
{'arxiv_id': 'arXiv:2502.06828', 'title': 'Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study', 'authors': 'Martin Wimpff, Bruno Aristimunha, Sylvain Chevallier, Bin Yang', 'link': 'https://arxiv.org/abs/2502.06828', 'abstract': 'This study investigates continual fine-tuning strategies for deep learning in online longitudinal electroencephalography (EEG) motor imagery (MI) decoding within a causal setting involving a large user group and multiple sessions per participant. We are the first to explore such strategies across a large user group, as longitudinal adaptation is typically studied in the single-subject setting with a single adaptation strategy, which limits the ability to generalize findings. First, we examine the impact of different fine-tuning approaches on decoder performance and stability. Building on this, we integrate online test-time adaptation (OTTA) to adapt the model during deployment, complementing the effects of prior fine-tuning. Our findings demonstrate that fine-tuning that successively builds on prior subject-specific information improves both performance and stability, while OTTA effectively adapts the model to evolving data distributions across consecutive sessions, enabling calibration-free operation. These results offer valuable insights and recommendations for future research in longitudinal online MI decoding and highlight the importance of combining domain adaptation strategies for improving BCI performance in real-world applications. Clinical Relevance: Our investigation enables more stable and efficient long-term motor imagery decoding, which is critical for neurorehabilitation and assistive technologies.', 'abstract_zh': '本研究考察了在纵向电生理运动会意解码中的因果设置下，针对大规模用户群体和多会话参与者的在线持续微调策略。这是我们首次在大规模用户群体中探索此类策略，因为纵向适应通常仅在单用户设置中使用单一适应策略研究，这限制了结果的泛化能力。首先，我们研究了不同微调方法对解码器性能和稳定性的影响。在此基础上，我们将在线测试时适应（OTTA）集成到模型部署中，以补充先前微调的效果。研究结果表明，逐步基于先前的个体特定信息的微调方法能同时提升性能和稳定性，而OTTA能够有效适应连续会话中不断变化的数据分布，实现无需校准的操作。这些结果为未来的纵向在线运动会意解码研究提供了有价值的见解和建议，并强调了结合领域适应策略以提高实时应用中脑机接口性能的重要性。临床相关性：我们的研究使长时间的运动会意解码更加稳定和高效，这对于神经康复和辅助技术至关重要。', 'title_zh': '连续在线EEG运动想象解码的微调策略：来自大规模 longitudinal 研究的见解'}
{'arxiv_id': 'arXiv:2502.06826', 'title': 'Transferring Graph Neural Networks for Soft Sensor Modeling using Process Topologies', 'authors': 'Maximilian F. Theisen, Gabrie M. H. Meesters, Artur M. Schweidtmann', 'link': 'https://arxiv.org/abs/2502.06826', 'abstract': 'Data-driven soft sensors help in process operations by providing real-time estimates of otherwise hard- to-measure process quantities, e.g., viscosities or product concentrations. Currently, soft sensors need to be developed individually per plant. Using transfer learning, machine learning-based soft sensors could be reused and fine-tuned across plants and applications. However, transferring data-driven soft sensor models is in practice often not possible, because the fixed input structure of standard soft sensor models prohibits transfer if, e.g., the sensor information is not identical in all plants. We propose a topology-aware graph neural network approach for transfer learning of soft sensor models across multiple plants. In our method, plants are modeled as graphs: Unit operations are nodes, streams are edges, and sensors are embedded as attributes. Our approach brings two advantages for transfer learning: First, we not only include sensor data but also crucial information on the plant topology. Second, the graph neural network algorithm is flexible with respect to its sensor inputs. This allows us to model data from different plants with different sensor networks. We test the transfer learning capabilities of our modeling approach on ammonia synthesis loops with different process topologies. We build a soft sensor predicting the ammonia concentration in the product. After training on data from one process, we successfully transfer our soft sensor model to a previously unseen process with a different topology. Our approach promises to extend the data-driven soft sensors to cases to leverage data from multiple plants.', 'abstract_zh': '基于拓扑结构的软传感器转移学习方法', 'title_zh': '基于过程拓扑的图神经网络转移学习在软传感器建模中的应用'}
{'arxiv_id': 'arXiv:2502.06824', 'title': 'Neural Network-based Vehicular Channel Estimation Performance: Effect of Noise in the Training Set', 'authors': 'Simbarashe Aldrin Ngorima, Albert Helberg, Marelie H. Davel', 'link': 'https://arxiv.org/abs/2502.06824', 'abstract': 'Vehicular communication systems face significant challenges due to high mobility and rapidly changing environments, which affect the channel over which the signals travel. To address these challenges, neural network (NN)-based channel estimation methods have been suggested. These methods are primarily trained on high signal-to-noise ratio (SNR) with the assumption that training a NN in less noisy conditions can result in good generalisation. This study examines the effectiveness of training NN-based channel estimators on mixed SNR datasets compared to training solely on high SNR datasets, as seen in several related works. Estimators evaluated in this work include an architecture that uses convolutional layers and self-attention mechanisms; a method that employs temporal convolutional networks and data pilot-aided estimation; two methods that combine classical methods with multilayer perceptrons; and the current state-of-the-art model that combines Long-Short-Term Memory networks with data pilot-aided and temporal averaging methods as post processing. Our results indicate that using only high SNR data for training is not always optimal, and the SNR range in the training dataset should be treated as a hyperparameter that can be adjusted for better performance. This is illustrated by the better performance of some models in low SNR conditions when trained on the mixed SNR dataset, as opposed to when trained exclusively on high SNR data.', 'abstract_zh': '基于混合信噪比数据集的神经网络信道估计算法有效性研究', 'title_zh': '基于神经网络的车辆信道估计性能：训练集噪声的影响'}
{'arxiv_id': 'arXiv:2502.06816', 'title': 'DeepCell: Multiview Representation Learning for Post-Mapping Netlists', 'authors': 'Zhengyuan Shi, Chengyu Ma, Ziyang Zheng, Lingfeng Zhou, Hongyang Pan, Wentao Jiang, Fan Yang, Xiaoyan Yang, Zhufei Chu, Qiang Xu', 'link': 'https://arxiv.org/abs/2502.06816', 'abstract': 'Representation learning for post-mapping (PM) netlists is a critical challenge in Electronic Design Automation (EDA), driven by the diverse and complex nature of modern circuit designs. Existing approaches focus on intermediate representations like And-Inverter Graphs (AIGs), limiting their applicability to post-synthesis stages. We introduce DeepCell, a multiview representation learning framework that integrates structural and functional insights from both PM netlists and AIGs to learn rich, generalizable embeddings. At its core, DeepCell employs the novel Mask Circuit Modeling (MCM) mechanism, which refines PM netlist representations in a self-supervised manner using pretrained AIG encoders. DeepCell sets a new benchmark in PM netlist representation, outperforming existing methods in predictive accuracy and reconstruction fidelity. To validate its efficacy, we apply DeepCell to functional Engineering Change Orders (ECO), achieving significant reductions in patch generation costs and runtime while improving patch quality.', 'abstract_zh': 'Post-mapping网表的表示学习是电子设计自动化(EDA)中的一个关键挑战，由现代电路设计的多样性和复杂性驱动。现有方法集中在如与与非图(AIGs)这样的中间表示上，限制了它们在后综合阶段的应用。我们提出了DeepCell，这是一种多视图表示学习框架，结合了PM网表和AIGs的结构和功能洞察，学习丰富的、可泛化的嵌入。DeepCell的核心采用了新颖的Mask Circuit Modeling (MCM)机制，该机制使用预训练的AIG编码器以自监督的方式精.refine PM网表的表示。DeepCell在PM网表表示方面设立了新的基准，在预测精度和重构保真度上超过了现有方法。为了验证其有效性，我们将DeepCell应用于功能工程更改订单(ECO)，实现了显著的补丁生成成本和运行时间的降低，同时提高了补丁的质量。', 'title_zh': 'DeepCell：映射后网表的多视图表示学习'}
{'arxiv_id': 'arXiv:2502.06811', 'title': 'Aligning Human and Machine Attention for Enhanced Supervised Learning', 'authors': 'Avihay Chriqui, Inbal Yahav, Dov Teeni, Ahmed Abbasi', 'link': 'https://arxiv.org/abs/2502.06811', 'abstract': 'Attention, or prioritization of certain information items over others, is a critical element of any learning process, for both humans and machines. Given that humans continue to outperform machines in certain learning tasks, it seems plausible that machine performance could be enriched by aligning machine attention with human attention mechanisms -- yet research on this topic is sparse and has achieved only limited success. This paper proposes a new approach to address this gap, called Human-Machine Attention Learning (HuMAL). This approach involves reliance on data annotated by humans to reflect their self-perceived attention during specific tasks. We evaluate several alternative strategies for integrating such human attention data into machine learning (ML) algorithms, using a sentiment analysis task (review data from Yelp) and a personality-type classification task (data from myPersonality). The best-performing HuMAL strategy significantly enhances the task performance of fine-tuned transformer models (BERT, as well as GPT-2 and XLNET), and the benefit is particularly pronounced under challenging conditions of imbalanced or sparse labeled data. This research contributes to a deeper understanding of strategies for integrating human attention into ML models and highlights the potential of leveraging human cognition to augment ML in real-world applications.', 'abstract_zh': '基于人类与机器注意力学习的策略研究', 'title_zh': '人类与机器注意力对齐以增强监督学习'}
{'arxiv_id': 'arXiv:2502.06808', 'title': 'On the Benefits of Attribute-Driven Graph Domain Adaptation', 'authors': 'Ruiyi Fang, Bingheng Li, Zhao Kang, Qiuhao Zeng, Ruizhi Pu, Nima Hosseini Dashtbayaz, Boyu Wang, Charles Ling', 'link': 'https://arxiv.org/abs/2502.06808', 'abstract': 'Graph Domain Adaptation (GDA) addresses a pressing challenge in cross-network learning, particularly pertinent due to the absence of labeled data in real-world graph datasets. Recent studies attempted to learn domain invariant representations by eliminating structural shifts between graphs. In this work, we show that existing methodologies have overlooked the significance of the graph node attribute, a pivotal factor for graph domain alignment. Specifically, we first reveal the impact of node attributes for GDA by theoretically proving that in addition to the graph structural divergence between the domains, the node attribute discrepancy also plays a critical role in GDA. Moreover, we also empirically show that the attribute shift is more substantial than the topology shift, which further underscores the importance of node attribute alignment in GDA. Inspired by this finding, a novel cross-channel module is developed to fuse and align both views between the source and target graphs for GDA. Experimental results on a variety of benchmarks verify the effectiveness of our method.', 'abstract_zh': '图域适应（GDA）解决了跨网络学习中一个紧迫的挑战，特别是在现实世界图数据集中缺乏标注数据的情况下。近期研究尝试通过消除图结构之间的差异来学习域不变表示。在这项工作中，我们表明现有的方法忽略了图节点属性的重要性，这是图域对齐的关键因素。具体地，我们首先通过理论证明，除了不同域之间的图结构差异外，节点属性的差异也在GDA中起着关键作用。此外，我们还通过实验表明，属性差异比拓扑差异更为显著，这进一步强调了节点属性对齐在GDA中的重要性。受到这一发现的启发，我们开发了一种新型跨通道模块，用于融合和对齐源图和目标图之间的两种视图，以实现GDA。在多种基准上的实验结果验证了我们方法的有效性。', 'title_zh': '基于属性驱动的图领域适应的优势'}
{'arxiv_id': 'arXiv:2502.06789', 'title': 'Information-theoretic Bayesian Optimization: Survey and Tutorial', 'authors': 'Eduardo C. Garrido-Merchán', 'link': 'https://arxiv.org/abs/2502.06789', 'abstract': 'Several scenarios require the optimization of non-convex black-box functions, that are noisy expensive to evaluate functions with unknown analytical expression, whose gradients are hence not accessible. For example, the hyper-parameter tuning problem of machine learning models. Bayesian optimization is a class of methods with state-of-the-art performance delivering a solution to this problem in real scenarios. It uses an iterative process that employs a probabilistic surrogate model, typically a Gaussian process, of the objective function to be optimized computing a posterior predictive distribution of the black-box function. Based on the information given by this posterior predictive distribution, Bayesian optimization includes the computation of an acquisition function that represents, for every input space point, the utility of evaluating that point in the next iteraiton if the objective of the process is to retrieve a global extremum. This paper is a survey of the information theoretical acquisition functions, whose performance typically outperforms the rest of acquisition functions. The main concepts of the field of information theory are also described in detail to make the reader aware of why information theory acquisition functions deliver great results in Bayesian optimization and how can we approximate them when they are intractable. We also cover how information theory acquisition functions can be adapted to complex optimization scenarios such as the multi-objective, constrained, non-myopic, multi-fidelity, parallel and asynchronous settings and provide further lines of research.', 'abstract_zh': '几种场景需要优化非凸黑盒函数，这类函数是嘈杂的、昂贵且难以评估的，缺乏解析表达式，因此其梯度不可用。例如，机器学习模型的超参数调优问题。贝叶斯优化是一类以最先进的性能解决这类问题的方法。它采用迭代过程，利用客观函数的概率替代模型（通常为高斯过程）构建后验预测分布，评估黑盒函数。基于此后验预测分布提供的信息，贝叶斯优化计算一个获取函数，该函数代表了对于每个输入空间点，在下一次迭代中评估该点的效用，其目标是找到全局极值。本文是对信息论获取函数的综述，这类获取函数的性能通常优于其他获取函数。本文还详细介绍了信息理论的主要概念，以使读者了解为何信息论获取函数在贝叶斯优化中能取得优异的成果，以及在不可处理的情况下如何近似它们。此外，本文还讨论了如何将信息论获取函数适应到多目标、约束、非前瞻、多分辨率、并行和异步等复杂优化场景，并提供了进一步的研究方向。', 'title_zh': '信息论贝叶斯优化：综述与教程'}
