{'arxiv_id': 'arXiv:2509.16176', 'title': 'Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories', 'authors': 'Yifan Lin, Sophie Ziyu Liu, Ran Qi, George Z. Xue, Xinping Song, Chao Qin, Hugh H.-T. Liu', 'link': 'https://arxiv.org/abs/2509.16176', 'abstract': 'We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories (ACDC), an autonomous drone cinematography system driven by natural language communication between human directors and drones. The main limitation of previous drone cinematography workflows is that they require manual selection of waypoints and view angles based on predefined human intent, which is labor-intensive and yields inconsistent performance. In this paper, we propose employing large language models (LLMs) and vision foundation models (VFMs) to convert free-form natural language prompts directly into executable indoor UAV video tours. Specifically, our method comprises a vision-language retrieval pipeline for initial waypoint selection, a preference-based Bayesian optimization framework that refines poses using aesthetic feedback, and a motion planner that generates safe quadrotor trajectories. We validate ACDC through both simulation and hardware-in-the-loop experiments, demonstrating that it robustly produces professional-quality footage across diverse indoor scenes without requiring expertise in robotics or cinematography. These results highlight the potential of embodied AI agents to close the loop from open-vocabulary dialogue to real-world autonomous aerial cinematography.', 'abstract_zh': '基于对话提示到影视航迹的自主无人机 cinematography 系统：从对话线索到 Cinematic 航迹 (ACDC)', 'title_zh': '代理无人机摄影：从对话线索到电影轨迹'}
{'arxiv_id': 'arXiv:2509.16145', 'title': 'Modeling Elastic-Body Dynamics of Fish Swimming Using a Variational Framework', 'authors': 'Zhiheng Chen, Wei Wang', 'link': 'https://arxiv.org/abs/2509.16145', 'abstract': "Fish-inspired aquatic robots are gaining increasing attention in research communities due to their high swimming speeds and efficient propulsion enabled by flexible bodies that generate undulatory motions. To support the design optimizations and control of such systems, accurate, interpretable, and computationally tractable modeling of the underlying swimming dynamics is indispensable. In this letter, we present a full-body dynamics model for fish swimming, rigorously derived from Hamilton's principle. The model captures the continuously distributed elasticity of a deformable fish body undergoing large deformations and incorporates fluid-structure coupling effects, enabling self-propelled motion without prescribing kinematics. A preliminary parameter study explores the influence of actuation frequency and body stiffness on swimming speed and cost of transport (COT). Simulation results indicate that swimming speed and energy efficiency exhibit opposing trends with tail-beat frequency and that both body stiffness and body length have distinct optimal values. These findings provide insights into biological swimming mechanisms and inform the design of high-performance soft robotic swimmers.", 'abstract_zh': '鱼启发的水下机器人的全身体动力学模型：从哈密尔顿原理严格推导，探究驱动频率和身体刚度对游泳速度和运能成本的影响', 'title_zh': '使用变分框架建模鱼类游泳的弹性体动力学'}
{'arxiv_id': 'arXiv:2509.16136', 'title': 'Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning', 'authors': 'Changwei Yao, Xinzi Liu, Chen Li, Marios Savvides', 'link': 'https://arxiv.org/abs/2509.16136', 'abstract': 'Designing effective reward functions remains a major challenge in reinforcement learning (RL), often requiring considerable human expertise and iterative refinement. Recent advances leverage Large Language Models (LLMs) for automated reward design, but these approaches are limited by hallucinations, reliance on human feedback, and challenges with handling complex, multi-step tasks. In this work, we introduce Reward Evolution with Graph-of-Thoughts (RE-GoT), a novel bi-level framework that enhances LLMs with structured graph-based reasoning and integrates Visual Language Models (VLMs) for automated rollout evaluation. RE-GoT first decomposes tasks into text-attributed graphs, enabling comprehensive analysis and reward function generation, and then iteratively refines rewards using visual feedback from VLMs without human intervention. Extensive experiments on 10 RoboGen and 4 ManiSkill2 tasks demonstrate that RE-GoT consistently outperforms existing LLM-based baselines. On RoboGen, our method improves average task success rates by 32.25%, with notable gains on complex multi-step tasks. On ManiSkill2, RE-GoT achieves an average success rate of 93.73% across four diverse manipulation tasks, significantly surpassing prior LLM-based approaches and even exceeding expert-designed rewards. Our results indicate that combining LLMs and VLMs with graph-of-thoughts reasoning provides a scalable and effective solution for autonomous reward evolution in RL.', 'abstract_zh': '基于图思维的奖励进化（RE-GoT）：结合结构化图推理和视觉语言模型的级联框架', 'title_zh': '基于图思考的奖励演化框架：双层语言模型在强化学习中的应用'}
{'arxiv_id': 'arXiv:2509.16122', 'title': 'Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors', 'authors': 'Carter Sifferman, Mohit Gupta, Michael Gleicher', 'link': 'https://arxiv.org/abs/2509.16122', 'abstract': 'We provide a method for detecting and localizing objects near a robot arm using arm-mounted miniature time-of-flight sensors. A key challenge when using arm-mounted sensors is differentiating between the robot itself and external objects in sensor measurements. To address this challenge, we propose a computationally lightweight method which utilizes the raw time-of-flight information captured by many off-the-shelf, low-resolution time-of-flight sensor. We build an empirical model of expected sensor measurements in the presence of the robot alone, and use this model at runtime to detect objects in proximity to the robot. In addition to avoiding robot self-detections in common sensor configurations, the proposed method enables extra flexibility in sensor placement, unlocking configurations which achieve more efficient coverage of a radius around the robot arm. Our method can detect small objects near the arm and localize the position of objects along the length of a robot link to reasonable precision. We evaluate the performance of the method with respect to object type, location, and ambient light level, and identify limiting factors on performance inherent in the measurement principle. The proposed method has potential applications in collision avoidance and in facilitating safe human-robot interaction.', 'abstract_zh': '使用安装在机器人臂上的微型飞行时间传感器检测和定位附近物体的方法', 'title_zh': '基于微型飞行时间传感器的机器人 manipulator 近处物体高效检测方法'}
{'arxiv_id': 'arXiv:2509.16079', 'title': 'Real-Time Planning and Control with a Vortex Particle Model for Fixed-Wing UAVs in Unsteady Flows', 'authors': 'Ashwin Gupta, Kevin Wolfe, Gino Perrotta, Joseph Moore', 'link': 'https://arxiv.org/abs/2509.16079', 'abstract': 'Unsteady aerodynamic effects can have a profound impact on aerial vehicle flight performance, especially during agile maneuvers and in complex aerodynamic environments. In this paper, we present a real-time planning and control approach capable of reasoning about unsteady aerodynamics. Our approach relies on a lightweight vortex particle model, parallelized to allow GPU acceleration, and a sampling-based policy optimization strategy capable of leveraging the vortex particle model for predictive reasoning. We demonstrate, through both simulation and hardware experiments, that by replanning with our unsteady aerodynamics model, we can improve the performance of aggressive post-stall maneuvers in the presence of unsteady environmental flow disturbances.', 'abstract_zh': '不稳态气动力效应对空中车辆飞行性能有着深远影响，特别是在快速机动和复杂气动力环境中。本文提出了一种实时规划与控制方法，能够对不稳态气动力进行推理。该方法依赖于轻量级涡旋粒子模型，该模型已并行化以允许GPU加速，并采用基于采样的策略优化方法，能够利用涡旋粒子模型进行预测推理。通过仿真和硬件实验，我们证明了通过利用不稳态气动力模型进行重新规划，可以在不稳态环境气流扰动下提高飞机激进后失速机动的性能。', 'title_zh': '基于旋涡粒子模型的固定翼无人机在非定常流场中的实时规划与控制'}
{'arxiv_id': 'arXiv:2509.16072', 'title': 'I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models', 'authors': 'Clemence Grislain, Hamed Rahimi, Olivier Sigaud, Mohamed Chetouani', 'link': 'https://arxiv.org/abs/2509.16072', 'abstract': 'Language-conditioned robotic manipulation in open-world settings requires not only accurate task execution but also the ability to detect failures for robust deployment in real-world environments. Although recent advances in vision-language models (VLMs) have significantly improved the spatial reasoning and task-planning capabilities of robots, they remain limited in their ability to recognize their own failures. In particular, a critical yet underexplored challenge lies in detecting semantic misalignment errors, where the robot executes a task that is semantically meaningful but inconsistent with the given instruction. To address this, we propose a method for building datasets targeting Semantic Misalignment Failures detection, from existing language-conditioned manipulation datasets. We also present I-FailSense, an open-source VLM framework with grounded arbitration designed specifically for failure detection. Our approach relies on post-training a base VLM, followed by training lightweight classification heads, called FS blocks, attached to different internal layers of the VLM and whose predictions are aggregated using an ensembling mechanism. Experiments show that I-FailSense outperforms state-of-the-art VLMs, both comparable in size and larger, in detecting semantic misalignment errors. Notably, despite being trained only on semantic misalignment detection, I-FailSense generalizes to broader robotic failure categories and effectively transfers to other simulation environments and real-world with zero-shot or minimal post-training. The datasets and models are publicly released on HuggingFace (Webpage: this https URL).', 'abstract_zh': '开放场景中基于语言条件的机器人操作需要精确的任务执行能力和故障检测能力，以确保在现实环境中的稳健部署。尽管近期视觉语言模型在空间推理和任务规划能力方面取得了显著进步，但仍限于无法识别自身的故障。特别地，发现语义对齐错误这一关键但未充分探索的挑战尤为突出，这是一种机器人执行虽然具有语义意义但与给定指令不一致的任务情况。为解决这一问题，我们提出了一种用于构建针对语义对齐故障检测的数据集的方法，源自现有语言条件操作数据集。我们还介绍了I-FailSense，一个具备基于事实仲裁机制的开源视觉语言模型框架，专门用于故障检测。该方法基于对基础视觉语言模型进行后训练，随后训练附接在模型不同内部层的轻量级分类头FS块，并通过集成机制聚合预测结果。实验结果显示，I-FailSense 在检测语义对齐错误方面优于最新的视觉语言模型，无论是大小相当的还是更大的模型。值得注意的是，尽管仅用于语义对齐检测的训练，I-FailSense 在更广泛的机器人故障类别中表现出良好的泛化能力，并且能够零样本或少量后训练有效转移到其他模拟环境和现实世界。数据集和模型已在HuggingFace上公开发布（网页: this https URL）。', 'title_zh': 'I-FailSense: 向通用机器人故障检测的语言视觉模型方向探索'}
{'arxiv_id': 'arXiv:2509.16063', 'title': 'DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation', 'authors': 'Yue Su, Chubin Zhang, Sijin Chen, Liufan Tan, Yansong Tang, Jianan Wang, Xihui Liu', 'link': 'https://arxiv.org/abs/2509.16063', 'abstract': 'Learning whole-body mobile manipulation via imitation is essential for generalizing robotic skills to diverse environments and complex tasks. However, this goal is hindered by significant challenges, particularly in effectively processing complex observation, achieving robust generalization, and generating coherent actions. To address these issues, we propose DSPv2, a novel policy architecture. DSPv2 introduces an effective encoding scheme that aligns 3D spatial features with multi-view 2D semantic features. This fusion enables the policy to achieve broad generalization while retaining the fine-grained perception necessary for precise control. Furthermore, we extend the Dense Policy paradigm to the whole-body mobile manipulation domain, demonstrating its effectiveness in generating coherent and precise actions for the whole-body robotic platform. Extensive experiments show that our method significantly outperforms existing approaches in both task performance and generalization ability. Project page is available at: this https URL.', 'abstract_zh': '通过模仿学习全身移动操作对于将机器人技能泛化到多样环境和复杂任务至关重要。然而，这一目标受制于重大挑战，特别是有效处理复杂观测、实现坚稳健性泛化以及生成连贯动作。为解决这些问题，我们提出DSPv2，一种新型策略架构。DSPv2引入了一种有效的编码方案，将3D空间特征与多视图2D语义特征对齐，从而实现广泛的泛化同时保留精细感知以进行精确控制。此外，我们将密集策略范式扩展到全身移动操作领域，并在全身机器人平台中展示了其生成连贯和精确动作的有效性。大量实验表明，我们的方法在任务性能和泛化能力上显著优于现有方法。项目页面链接为：this https URL。', 'title_zh': 'DSPv2: 提升的密集策略以实现有效和泛化的全身移动 manipulation'}
{'arxiv_id': 'arXiv:2509.16061', 'title': 'Latent Conditioned Loco-Manipulation Using Motion Priors', 'authors': 'Maciej Stępień, Rafael Kourdis, Constant Roux, Olivier Stasse', 'link': 'https://arxiv.org/abs/2509.16061', 'abstract': 'Although humanoid and quadruped robots provide a wide range of capabilities, current control methods, such as Deep Reinforcement Learning, focus mainly on single skills. This approach is inefficient for solving more complicated tasks where high-level goals, physical robot limitations and desired motion style might all need to be taken into account. A more effective approach is to first train a multipurpose motion policy that acquires low-level skills through imitation, while providing latent space control over skill execution. Then, this policy can be used to efficiently solve downstream tasks. This method has already been successful for controlling characters in computer graphics. In this work, we apply the approach to humanoid and quadrupedal loco-manipulation by imitating either simple synthetic motions or kinematically retargeted dog motions. We extend the original formulation to handle constraints, ensuring deployment safety, and use a diffusion discriminator for better imitation quality. We verify our methods by performing loco-manipulation in simulation for the H1 humanoid and Solo12 quadruped, as well as deploying policies on Solo12 hardware. Videos and code are available at this https URL', 'abstract_zh': '尽管类人机器人和四足机器人的能力范围广泛，当前的控制方法，如深度强化学习，主要关注单一技能。对于需要高级目标、物理机器人限制和期望运动风格综合考量的复杂任务，这种做法效率较低。一种更有效的做法是首先训练一个多功能运动策略，通过模仿获取低级技能，同时提供技能执行的潜在空间控制。然后，该策略可用于高效解决下游任务。这种方法已经在控制计算机图形中的角色方面取得了成功。在本文中，我们将该方法应用于类人机器人和四足机器人以进行移动操作与操纵，模仿简单的合成动作或动力学适配的狗动作。我们将原始模型扩展以处理约束，确保部署安全性，并使用扩散判别器以提高模仿质量。我们通过在模拟中进行移动操作来验证方法，用于H1类人机器人和Solo12四足机器人，并在Solo12硬件上部署策略。相关视频和代码可在以下链接获取。', 'title_zh': '基于运动先验的隐含条件局部操作'}
{'arxiv_id': 'arXiv:2509.16053', 'title': 'Compose by Focus: Scene Graph-based Atomic Skills', 'authors': 'Han Qi, Changhe Chen, Heng Yang', 'link': 'https://arxiv.org/abs/2509.16053', 'abstract': 'A key requirement for generalist robots is compositional generalization - the ability to combine atomic skills to solve complex, long-horizon tasks. While prior work has primarily focused on synthesizing a planner that sequences pre-learned skills, robust execution of the individual skills themselves remains challenging, as visuomotor policies often fail under distribution shifts induced by scene composition. To address this, we introduce a scene graph-based representation that focuses on task-relevant objects and relations, thereby mitigating sensitivity to irrelevant variation. Building on this idea, we develop a scene-graph skill learning framework that integrates graph neural networks with diffusion-based imitation learning, and further combine "focused" scene-graph skills with a vision-language model (VLM) based task planner. Experiments in both simulation and real-world manipulation tasks demonstrate substantially higher success rates than state-of-the-art baselines, highlighting improved robustness and compositional generalization in long-horizon tasks.', 'abstract_zh': '通用机器人的一项关键要求是组合泛化能力——将原子技能组合以解决复杂、长时间 horizon 的任务。为解决个体技能稳健执行的挑战，我们提出了一种基于场景图的表示方法，该方法侧重于与任务相关的对象和关系，从而减轻对无关变异的敏感性。在此基础上，我们开发了一种结合图神经网络和基于扩散的模仿学习的场景图技能学习框架，并进一步将场景图技能与基于视觉语言模型的任务规划器相结合。在模拟和现实世界的操作任务中的实验结果表明，与最先进的基线方法相比，成功率显著提高，强调了在长时间任务中改进的稳健性和组合泛化能力。', 'title_zh': '焦点驱动的组成：基于场景图的原子技能'}
{'arxiv_id': 'arXiv:2509.16037', 'title': 'Learning Safety for Obstacle Avoidance via Control Barrier Functions', 'authors': 'Shuo Liu, Zhe Huang, Calin A. Belta', 'link': 'https://arxiv.org/abs/2509.16037', 'abstract': "Obstacle avoidance is central to safe navigation, especially for robots with arbitrary and nonconvex geometries operating in cluttered environments. Existing Control Barrier Function (CBF) approaches often rely on analytic clearance computations, which are infeasible for complex geometries, or on polytopic approximations, which become intractable when robot configurations are unknown. To address these limitations, this paper trains a residual neural network on a large dataset of robot-obstacle configurations to enable fast and tractable clearance prediction, even at unseen configurations. The predicted clearance defines the radius of a Local Safety Ball (LSB), which ensures continuous-time collision-free navigation. The LSB boundary is encoded as a Discrete-Time High-Order CBF (DHOCBF), whose constraints are incorporated into a nonlinear optimization framework. To improve feasibility, a novel relaxation technique is applied. The resulting framework ensure that the robot's rigid-body motion between consecutive time steps remains collision-free, effectively bridging discrete-time control and continuous-time safety. We show that the proposed method handles arbitrary, including nonconvex, robot geometries and generates collision-free, dynamically feasible trajectories in cluttered environments. Experiments demonstrate millisecond-level solve times and high prediction accuracy, highlighting both safety and efficiency beyond existing CBF-based methods.", 'abstract_zh': '障碍物避免对于安全导航至关重要，尤其是对于在复杂环境中有任意和非凸几何结构的机器人。现有的控制障碍函数（CBF）方法往往依赖于解析的清除计算，这在复杂几何结构情况下是不可行的，或者依赖于多面体近似，当机器人姿态未知时会变得不可行。为了解决这些局限，本文在一个大规模的机器人-障碍物配置数据集上训练了一个残差神经网络，以实现即使是未见过的配置也能快速和有效地进行清除预测。预测的清除定义了一个局部安全球（LSB）的半径，该球确保连续时间内的无碰撞导航。LSB的边界被编码为离散时间高阶控制障碍函数（DHOCBF），其约束被整合到非线性优化框架中。为了提高可行性，提出了一种新的松弛技术。由此形成的框架确保机器人在连续时间步之间的刚体运动始终保持无碰撞，有效地在离散时间和连续时间安全之间架起桥梁。我们展示了所提出的方法能够处理任意形状，包括非凸形状的机器人几何结构，并在复杂环境中生成无碰撞且动力学可行的轨迹。实验表明，该方法具有毫秒级的求解时间和高预测精度，突显了其在安全性和效率方面超越现有CBF基方法的优势。', 'title_zh': '基于控制屏障函数的避障安全学习'}
{'arxiv_id': 'arXiv:2509.16032', 'title': 'A Matter of Height: The Impact of a Robotic Object on Human Compliance', 'authors': 'Michael Faber, Andrey Grishko, Julian Waksberg, David Pardo, Tomer Leivy, Yuval Hazan, Emanuel Talmansky, Benny Megidish, Hadas Erel', 'link': 'https://arxiv.org/abs/2509.16032', 'abstract': "Robots come in various forms and have different characteristics that may shape the interaction with them. In human-human interactions, height is a characteristic that shapes human dynamics, with taller people typically perceived as more persuasive. In this work, we aspired to evaluate if the same impact replicates in a human-robot interaction and specifically with a highly non-humanoid robotic object. The robot was designed with modules that could be easily added or removed, allowing us to change its height without altering other design features. To test the impact of the robot's height, we evaluated participants' compliance with its request to volunteer to perform a tedious task. In the experiment, participants performed a cognitive task on a computer, which was framed as the main experiment. When done, they were informed that the experiment was completed. While waiting to receive their credits, the robotic object, designed as a mobile robotic service table, entered the room, carrying a tablet that invited participants to complete a 300-question questionnaire voluntarily. We compared participants' compliance in two conditions: A Short robot composed of two modules and 95cm in height and a Tall robot consisting of three modules and 132cm in height. Our findings revealed higher compliance with the Short robot's request, demonstrating an opposite pattern to human dynamics. We conclude that while height has a substantial social impact on human-robot interactions, it follows a unique pattern of influence. Our findings suggest that designers cannot simply adopt and implement elements from human social dynamics to robots without testing them first.", 'abstract_zh': '机器人呈现多种形态，具有不同的特性，这些特性可能会影响与之的互动。在人与人之间的互动中，身高是一种特性，会影响人际关系动态，通常更高的个体被认为更具说服力。在这项工作中，我们旨在评估这种情况在人与机器人互动中是否同样有效，特别是对于一个高度非人形的机器人对象。机器人设计有可轻松添加或移除的模块，使我们能够改变其高度而不改变其他设计特征。为测试机器人高度的影响，我们评估了参与者对其请求他们自愿完成一项枯燥任务的遵从性。在实验中，参与者在计算机上完成了一个认知任务，这被视为主要实验。完成后，他们被告知实验已经结束。在等待领奖金时，被设计成移动服务机器人的机器人对象，携带平板电脑进入房间，邀请参与者自愿完成一份包含300个问题的问卷。我们比较了在两种条件下参与者的遵从性：一种是高95厘米由两个模块组成的短机器人，另一种是高132厘米由三个模块组成的高机器人。我们的研究发现，参与者对短机器人的请求遵从性更高，显示出与人类互动动态相反的模式。我们得出结论，尽管身高在人机互动中对社会影响很大，但其影响模式是独特的。我们的研究结果表明，设计师不能简单地借鉴和应用人类社会动态的元素到机器人中，而无需首先进行测试。', 'title_zh': '高度问题：机器人物体对人类遵从性的影响'}
{'arxiv_id': 'arXiv:2509.16006', 'title': 'Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning', 'authors': 'Francesco Argenziano, Elena Umili, Francesco Leotta, Daniele Nardi', 'link': 'https://arxiv.org/abs/2509.16006', 'abstract': 'Recent years have witnessed a growing interest in automating labor-intensive and complex activities, i.e., those consisting of multiple atomic tasks, by deploying robots in dynamic and unpredictable environments such as industrial and agricultural settings. A key characteristic of these contexts is that activities are not predefined: while they involve a limited set of possible tasks, their combinations may vary depending on the situation. Moreover, despite recent advances in robotics, the ability for humans to monitor the progress of high-level activities - in terms of past, present, and future actions - remains fundamental to ensure the correct execution of safety-critical processes. In this paper, we introduce a general architecture that integrates Large Language Models (LLMs) with automated planning, enabling humans to specify high-level activities (also referred to as processes) using natural language, and to monitor their execution by querying a robot. We also present an implementation of this architecture using state-of-the-art components and quantitatively evaluate the approach in a real-world precision agriculture scenario.', 'abstract_zh': '近年来，人们越来越关注通过在动态和不可预测的环境中部署机器人来自动化劳动密集型和复杂的活动，这些活动由多个原子任务组成。这些环境的一个关键特点是活动不是预先定义的：虽然涉及一组有限的任务，但其组合可能会根据具体情况而变化。此外，尽管机器人技术取得了近期进展，人类继续监控高层次活动（包括过去、现在和未来的行动）以确保关键安全过程的正确执行仍然是基本需求。本文提出了一种通用架构，将大型语言模型（LLMs）与自动规划相结合，使人类能够使用自然语言指定高层次活动（也称为过程），并通过查询机器人来监控其执行。我们还使用最先进的组件实现了该架构，并在实际的精准农业场景中定量评估了该方法。', 'title_zh': '通过大语言模型和符号推理定义与监控复杂机器人活动'}
{'arxiv_id': 'arXiv:2509.15968', 'title': 'CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine', 'authors': 'Shiyu Fang, Yiming Cui, Haoyang Liang, Chen Lv, Peng Hang, Jian Sun', 'link': 'https://arxiv.org/abs/2509.15968', 'abstract': "Autonomous Driving (AD) systems have made notable progress, but their performance in long-tail, safety-critical scenarios remains limited. These rare cases contribute a disproportionate number of accidents. Vision-Language Action (VLA) models have strong reasoning abilities and offer a potential solution, but their effectiveness is limited by the lack of high-quality data and inefficient learning in such conditions. To address these challenges, we propose CoReVLA, a continual learning end-to-end autonomous driving framework that improves the performance in long-tail scenarios through a dual-stage process of data Collection and behavior Refinement. First, the model is jointly fine-tuned on a mixture of open-source driving QA datasets, allowing it to acquire a foundational understanding of driving scenarios. Next, CoReVLA is deployed within the Cave Automatic Virtual Environment (CAVE) simulation platform, where driver takeover data is collected from real-time interactions. Each takeover indicates a long-tail scenario that CoReVLA fails to handle reliably. Finally, the model is refined via Direct Preference Optimization (DPO), allowing it to learn directly from human preferences and thereby avoid reward hacking caused by manually designed rewards. Extensive open-loop and closed-loop experiments demonstrate that the proposed CoReVLA model can accurately perceive driving scenarios and make appropriate decisions. On the Bench2Drive benchmark, CoReVLA achieves a Driving Score (DS) of 72.18 and a Success Rate (SR) of 50%, outperforming state-of-the-art methods by 7.96 DS and 15% SR under long-tail, safety-critical scenarios. Furthermore, case studies demonstrate the model's ability to continually improve its performance in similar failure-prone scenarios by leveraging past takeover experiences. All codea and preprocessed datasets are available at: this https URL", 'abstract_zh': '自主驾驶（AD）系统取得了显著进展，但在长尾、安全关键场景中的表现仍然有限。这些罕见情况导致了不成比例的事故。视觉-语言-动作（VLA）模型具备强大的推理能力，可能提供解决方案，但由于缺乏高质量数据以及在这些条件下学习效率低下，其效果受限。为解决这些挑战，我们提出了一种持续学习端到端自主驾驶框架CoReVLA，通过数据收集和行为细化的双重过程，提高长尾场景中的性能。首先，模型在开源驾驶QA数据集中联合微调，使其获得驾驶场景的基本理解。接着，CoReVLA在Cave自动虚拟环境（CAVE）模拟平台上部署，收集实时交互中的驾驶接管数据。每次接管都表示一个CoReVLA无法可靠处理的长尾场景。最后，模型通过直接偏好优化（DPO）进行细化，使其可以直接从人类偏好中学习，从而避免手动设计奖励引起的奖励作弊。大量开环和闭环实验表明，所提出的CoReVLA模型能够准确感知驾驶场景并做出适当决策。在Bench2Drive基准测试中，CoReVLA的驾驶得分为72.18，成功率50%，在长尾、安全关键场景中分别优于现有最佳方法7.96分和15%的成功率。此外，案例研究显示该模型能够通过利用过去的接管经验，持续改进类似可能出现故障的场景中的表现。所有代码和预处理数据集可在以下链接获取：this https URL。', 'title_zh': 'CoReVLA：一种用于长尾场景的端到端自主驾驶框架（基于收集与精炼的双阶段方法）'}
{'arxiv_id': 'arXiv:2509.15956', 'title': 'Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms', 'authors': 'Alexandre Pacheco, Hanqing Zhao, Volker Strobel, Tarik Roukny, Gregory Dudek, Andreagiovanni Reina, Marco Dorigo', 'link': 'https://arxiv.org/abs/2509.15956', 'abstract': "Blockchain consensus, rooted in the principle ``don't trust, verify'', limits access to real-world data, which may be ambiguous or inaccessible to some participants. Oracles address this limitation by supplying data to blockchains, but existing solutions may reduce autonomy, transparency, or reintroduce the need for trust. We propose Swarm Oracle: a decentralized network of autonomous robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer communication to collectively verify real-world data and provide it to smart contracts on public blockchains. Swarm Oracle leverages the built-in decentralization, fault tolerance and mobility of robot swarms, which can flexibly adapt to meet information requests on-demand, even in remote locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates robots from multiple stakeholders, protecting the system from single-party biases but also introducing potential adversarial behavior. To ensure the secure, trustless and global consensus required by blockchains, we employ a Byzantine fault-tolerant protocol that enables robots from different stakeholders to operate together, reaching social agreements of higher quality than the estimates of individual robots. Through extensive experiments using both real and simulated robots, we showcase how consensus on uncertain environmental information can be achieved, despite several types of attacks orchestrated by large proportions of the robots, and how a reputation system based on blockchain tokens lets Swarm Oracle autonomously recover from faults and attacks, a requirement for long-term operation.", 'abstract_zh': '基于自治机器人蜂群的 Swarm Oracle：一种分布式数据验证系统', 'title_zh': 'swarm oracle: 通过机器人蜂群实现的无信任区块链协议'}
{'arxiv_id': 'arXiv:2509.15953', 'title': 'Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal', 'authors': 'Chang Yu, Siyu Ma, Wenxin Du, Zeshun Zong, Han Xue, Wendi Chen, Cewu Lu, Yin Yang, Xuchen Han, Joseph Masterjohn, Alejandro Castro, Chenfanfu Jiang', 'link': 'https://arxiv.org/abs/2509.15953', 'abstract': 'Turning garments right-side out is a challenging manipulation task: it is highly dynamic, entails rapid contact changes, and is subject to severe visual occlusion. We introduce Right-Side-Out, a zero-shot sim-to-real framework that effectively solves this challenge by exploiting task structures. We decompose the task into Drag/Fling to create and stabilize an access opening, followed by Insert&Pull to invert the garment. Each step uses a depth-inferred, keypoint-parameterized bimanual primitive that sharply reduces the action space while preserving robustness. Efficient data generation is enabled by our custom-built, high-fidelity, GPU-parallel Material Point Method (MPM) simulator that models thin-shell deformation and provides robust and efficient contact handling for batched rollouts. Built on the simulator, our fully automated pipeline scales data generation by randomizing garment geometry, material parameters, and viewpoints, producing depth, masks, and per-primitive keypoint labels without any human annotations. With a single depth camera, policies trained entirely in simulation deploy zero-shot on real hardware, achieving up to 81.3% success rate. By employing task decomposition and high fidelity simulation, our framework enables tackling highly dynamic, severely occluded tasks without laborious human demonstrations.', 'abstract_zh': '正反面翻转衣物是一项具有挑战性的操作任务：它高度动态，涉及快速的接触变化，并且受到严重的视觉遮挡。我们提出了Right-Side-Out，一种通过利用任务结构有效解决这一挑战的零样本模拟到现实的框架。', 'title_zh': '从右翻转：学习零样本模拟到现实的服装翻转'}
{'arxiv_id': 'arXiv:2509.15937', 'title': 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning', 'authors': 'Shaopeng Zhai, Qi Zhang, Tianyi Zhang, Fuxian Huang, Haoran Zhang, Ming Zhou, Shengzhe Zhang, Litao Liu, Sixu Lin, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2509.15937', 'abstract': 'Robotic real-world reinforcement learning (RL) with vision-language-action (VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient exploration. We introduce VLAC, a general process reward model built upon InternVL and trained on large scale heterogeneous datasets. Given pairwise observations and a language goal, it outputs dense progress delta and done signal, eliminating task-specific reward engineering, and supports one-shot in-context transfer to unseen tasks and environments. VLAC is trained on vision-language datasets to strengthen perception, dialogic and reasoning capabilities, together with robot and human trajectories data that ground action generation and progress estimation, and additionally strengthened to reject irrelevant prompts as well as detect regression or stagnation by constructing large numbers of negative and semantically mismatched samples. With prompt control, a single VLAC model alternately generating reward and action tokens, unifying critic and policy. Deployed inside an asynchronous real-world RL loop, we layer a graded human-in-the-loop protocol (offline demonstration replay, return and explore, human guided explore) that accelerates exploration and stabilizes early learning. Across four distinct real-world manipulation tasks, VLAC lifts success rates from about 30\\% to about 90\\% within 200 real-world interaction episodes; incorporating human-in-the-loop interventions yields a further 50% improvement in sample efficiency and achieves up to 100% final success.', 'abstract_zh': '基于视力-语言-动作模型的机器人现实世界强化学习（RL）受稀疏的手工设计奖励和低效探索的限制。我们引入了VLAC，这是一种基于InternVL构建的一般过程奖励模型，并在大规模异构数据集上进行训练。给定成对的观察和语言目标，它输出密集的进展增量和结束信号，消除任务特定的奖励工程，并支持对未见过的任务和环境的一次性上下文转移。VLAC通过在视力-语言数据集上进行训练来增强感知、对话和推理能力，结合机器人和人类轨迹数据以强化行动生成和进展估计，并通过构建大量的否定样本和语义不匹配样本来进一步增强，从而拒绝无关提示，并识别退化或停滞。通过提示控制，单个VLAC模型交替生成奖励和动作标记，统一批评与策略。在其内部嵌入异步现实世界RL循环中，我们叠加了一种分层的人机循环协议（离线演示回放、收益和探索、人类引导探索），以加速探索并稳定早期学习。在四个不同的现实世界操作任务中，VLAC在200次真实世界的交互环节内将成功率从约30%提升至约90%；结合人机循环干预进一步提高了样本效率50%，并实现了最终100%的成功率。', 'title_zh': '一种用于机器人现实世界强化学习的视觉-语言-动作-评论模型'}
{'arxiv_id': 'arXiv:2509.15917', 'title': 'An MPC framework for efficient navigation of mobile robots in cluttered environments', 'authors': 'Johannes Köhler, Daniel Zhang, Raffaele Soloperto, Andrea Carron, Melanie Zeilinger', 'link': 'https://arxiv.org/abs/2509.15917', 'abstract': 'We present a model predictive control (MPC) framework for efficient navigation of mobile robots in cluttered environments. The proposed approach integrates a finite-segment shortest path planner into the finite-horizon trajectory optimization of the MPC. This formulation ensures convergence to dynamically selected targets and guarantees collision avoidance, even under general nonlinear dynamics and cluttered environments. The approach is validated through hardware experiments on a small ground robot, where a human operator dynamically assigns target locations. The robot successfully navigated through complex environments and reached new targets within 2-3 seconds.', 'abstract_zh': '我们提出了一种模型预测控制（MPC）框架，用于_cluttered环境中小型地面机器人的高效导航。该方法将有限段最短路径规划器集成到MPC的有限时间轨迹优化中，确保在一般非线性动力学和_cluttered环境中动态选择目标并实现碰撞避免。该方法通过硬件实验得到了验证，其中人工操作员动态分配目标位置，机器人能在2-3秒内成功导航通过复杂环境并到达新目标。', 'title_zh': '基于模型预测控制的移动机器人在复杂环境中的高效导航框架'}
{'arxiv_id': 'arXiv:2509.15880', 'title': 'Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder', 'authors': 'An Dinh Vuong, Minh Nhat Vu, Ian Reid', 'link': 'https://arxiv.org/abs/2509.15880', 'abstract': 'Existing RGB-based imitation learning approaches typically employ traditional vision encoders such as ResNet or ViT, which lack explicit 3D reasoning capabilities. Recent geometry-grounded vision models, such as VGGT~\\cite{wang2025vggt}, provide robust spatial understanding and are promising candidates to address this limitation. This work investigates the integration of geometry-aware visual representations into robotic manipulation. Our results suggest that incorporating the geometry-aware vision encoder into imitation learning frameworks, including ACT and DP, yields up to 6.5% improvement over standard vision encoders in success rate across single- and bi-manual manipulation tasks in both simulation and real-world settings. Despite these benefits, most geometry-grounded models require high computational cost, limiting their deployment in practical robotic systems. To address this challenge, we propose eVGGT, an efficient geometry-aware encoder distilled from VGGT. eVGGT is nearly 9 times faster and 5 times smaller than VGGT, while preserving strong 3D reasoning capabilities. Code and pretrained models will be released to facilitate further research in geometry-aware robotics.', 'abstract_zh': '基于几何信息的视觉表示在机器人操作中的应用研究', 'title_zh': '提高基于高效几何aware视觉编码器的机器人操作性能'}
{'arxiv_id': 'arXiv:2509.15876', 'title': 'High-Bandwidth Tactile-Reactive Control for Grasp Adjustment', 'authors': 'Yonghyeon Lee, Tzu-Yuan Lin, Alexander Alexiev, Sangbae Kim', 'link': 'https://arxiv.org/abs/2509.15876', 'abstract': "Vision-only grasping systems are fundamentally constrained by calibration errors, sensor noise, and grasp pose prediction inaccuracies, leading to unavoidable contact uncertainty in the final stage of grasping. High-bandwidth tactile feedback, when paired with a well-designed tactile-reactive controller, can significantly improve robustness in the presence of perception errors. This paper contributes to controller design by proposing a purely tactile-feedback grasp-adjustment algorithm. The proposed controller requires neither prior knowledge of the object's geometry nor an accurate grasp pose, and is capable of refining a grasp even when starting from a crude, imprecise initial configuration and uncertain contact points. Through simulation studies and real-world experiments on a 15-DoF arm-hand system (featuring an 8-DoF hand) equipped with fingertip tactile sensors operating at 200 Hz, we demonstrate that our tactile-reactive grasping framework effectively improves grasp stability.", 'abstract_zh': '基于触觉反馈的手抓调整算法能够显著提高抓取的 robustness，特别是在感知错误存在的情况下。本文提出了一种纯触觉反馈的抓取调整算法，无需对象几何形状的先验知识或精确的抓取姿态，即使从粗糙且不精确的初始配置和不确定的接触点开始，也能改进抓取。通过在配备8自由度手并带有指尖触觉传感器（采样率200 Hz）的15自由度臂手系统上的模拟实验和现实世界实验，证明了所提出的触觉反应式抓取框架有效提高了抓取稳定性。', 'title_zh': '高频触觉反应控制以调整抓取'}
{'arxiv_id': 'arXiv:2509.15830', 'title': 'Coordinated Multi-Drone Last-mile Delivery: Learning Strategies for Energy-aware and Timely Operations', 'authors': 'Chuhao Qin, Arun Narayanan, Evangelos Pournaras', 'link': 'https://arxiv.org/abs/2509.15830', 'abstract': 'Drones have recently emerged as a faster, safer, and cost-efficient way for last-mile deliveries of parcels, particularly for urgent medical deliveries highlighted during the pandemic. This paper addresses a new challenge of multi-parcel delivery with a swarm of energy-aware drones, accounting for time-sensitive customer requirements. Each drone plans an optimal multi-parcel route within its battery-restricted flight range to minimize delivery delays and reduce energy consumption. The problem is tackled by decomposing it into three sub-problems: (1) optimizing depot locations and service areas using K-means clustering; (2) determining the optimal flight range for drones through reinforcement learning; and (3) planning and selecting multi-parcel delivery routes via a new optimized plan selection approach. To integrate these solutions and enhance long-term efficiency, we propose a novel algorithm leveraging actor-critic-based multi-agent deep reinforcement learning. Extensive experimentation using realistic delivery datasets demonstrate an exceptional performance of the proposed algorithm. We provide new insights into economic efficiency (minimize energy consumption), rapid operations (reduce delivery delays and overall execution time), and strategic guidance on depot deployment for practical logistics applications.', 'abstract_zh': '无人机在多包裹交付中的能效挑战与解决方案：基于强化学习的最优路径规划与多无人机集群部署', 'title_zh': '协调多无人机最后一英里交付：面向能量感知和及时运营的学习策略'}
{'arxiv_id': 'arXiv:2509.15807', 'title': 'FlyKites: Human-centric Interactive Exploration and Assistance under Limited Communication', 'authors': 'Yuyang Zhang, Zhuoli Tian, Jinsheng Wei, Meng Guo', 'link': 'https://arxiv.org/abs/2509.15807', 'abstract': 'Fleets of autonomous robots have been deployed for exploration of unknown scenes for features of interest, e.g., subterranean exploration, reconnaissance, search and rescue missions. During exploration, the robots may encounter un-identified targets, blocked passages, interactive objects, temporary failure, or other unexpected events, all of which require consistent human assistance with reliable communication for a time period. This however can be particularly challenging if the communication among the robots is severely restricted to only close-range exchange via ad-hoc networks, especially in extreme environments like caves and underground tunnels. This paper presents a novel human-centric interactive exploration and assistance framework called FlyKites, for multi-robot systems under limited communication. It consists of three interleaved components: (I) the distributed exploration and intermittent communication (called the "spread mode"), where the robots collaboratively explore the environment and exchange local data among the fleet and with the operator; (II) the simultaneous optimization of the relay topology, the operator path, and the assignment of robots to relay roles (called the "relay mode"), such that all requested assistance can be provided with minimum delay; (III) the human-in-the-loop online execution, where the robots switch between different roles and interact with the operator adaptively. Extensive human-in-the-loop simulations and hardware experiments are performed over numerous challenging scenes.', 'abstract_zh': '基于有限通信的多机器人系统人本交互探索与辅助框架：FlyKites', 'title_zh': 'FlyKites: 以人为本的有限通信条件下的交互探索与辅助'}
{'arxiv_id': 'arXiv:2509.15737', 'title': 'SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments', 'authors': 'Heye Huang, Yibin Yang, Wang Chen, Tiantian Chen, Xiaopeng Li, Sikai Chen', 'link': 'https://arxiv.org/abs/2509.15737', 'abstract': 'Multi-vehicle trajectory planning is a non-convex problem that becomes increasingly difficult in dense environments due to the rapid growth of collision constraints. Efficient exploration of feasible behaviors and resolution of tight interactions are essential for real-time, large-scale coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and Trajectory Planning, a hierarchical framework that combines priority-based search with distributed optimization to achieve efficient and feasible multi-vehicle planning. The upper layer explores diverse interaction modes using reinforcement learning-based priority estimation and large-step hybrid A* search, while the lower layer refines solutions via parallelizable convex optimization. By partitioning space among neighboring vehicles and constructing robust feasible corridors, the method decouples the joint non-convex problem into convex subproblems solved efficiently in parallel. This design alleviates the step-size trade-off while ensuring kinematic feasibility and collision avoidance. Experiments show that SMART consistently outperforms baselines. On 50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles, while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves above 95% success up to 50 vehicles and remains feasible up to 90 vehicles, with runtimes more than an order of magnitude faster than optimization-only approaches. Built on vehicle-to-everything communication, SMART incorporates vehicle-infrastructure cooperation through roadside sensing and agent coordination, improving scalability and safety. Real-world experiments further validate this design, achieving planning times as low as 0.014 s while preserving cooperative behaviors.', 'abstract_zh': '可扩展多智能体推理与轨迹规划：基于优先级的搜索与分布式优化相结合的层次框架', 'title_zh': 'SMART：密集环境可扩展多 Agents 原理推理与轨迹规划'}
{'arxiv_id': 'arXiv:2509.15733', 'title': 'GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation', 'authors': 'Quanhao Qian, Guoyang Zhao, Gongjie Zhang, Jiuniu Wang, Ran Xu, Junlong Gao, Deli Zhao', 'link': 'https://arxiv.org/abs/2509.15733', 'abstract': 'Effective robotic manipulation relies on a precise understanding of 3D scene geometry, and one of the most straightforward ways to acquire such geometry is through multi-view observations. Motivated by this, we present GP3 -- a 3D geometry-aware robotic manipulation policy that leverages multi-view input. GP3 employs a spatial encoder to infer dense spatial features from RGB observations, which enable the estimation of depth and camera parameters, leading to a compact yet expressive 3D scene representation tailored for manipulation. This representation is fused with language instructions and translated into continuous actions via a lightweight policy head. Comprehensive experiments demonstrate that GP3 consistently outperforms state-of-the-art methods on simulated benchmarks. Furthermore, GP3 transfers effectively to real-world robots without depth sensors or pre-mapped environments, requiring only minimal fine-tuning. These results highlight GP3 as a practical, sensor-agnostic solution for geometry-aware robotic manipulation.', 'abstract_zh': 'GP3：一种基于多视图输入的3D几何感知机器人 manipulation 政策', 'title_zh': 'GP3: 一种基于三维几何的多视图图像机器人操纵策略'}
{'arxiv_id': 'arXiv:2509.15717', 'title': 'Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference', 'authors': 'Haoran Ding, Anqing Duan, Zezhou Sun, Dezhen Song, Yoshihiko Nakamura', 'link': 'https://arxiv.org/abs/2509.15717', 'abstract': "Visual observations from different viewpoints can significantly influence the performance of visuomotor policies in robotic manipulation. Among these, egocentric (in-hand) views often provide crucial information for precise control. However, in some applications, equipping robots with dedicated in-hand cameras may pose challenges due to hardware constraints, system complexity, and cost. In this work, we propose to endow robots with imaginative perception - enabling them to 'imagine' in-hand observations from agent views at inference time. We achieve this via novel view synthesis (NVS), leveraging a fine-tuned diffusion model conditioned on the relative pose between the agent and in-hand views cameras. Specifically, we apply LoRA-based fine-tuning to adapt a pretrained NVS model (ZeroNVS) to the robotic manipulation domain. We evaluate our approach on both simulation benchmarks (RoboMimic and MimicGen) and real-world experiments using a Unitree Z1 robotic arm for a strawberry picking task. Results show that synthesized in-hand views significantly enhance policy inference, effectively recovering the performance drop caused by the absence of real in-hand cameras. Our method offers a scalable and hardware-light solution for deploying robust visuomotor policies, highlighting the potential of imaginative visual reasoning in embodied agents.", 'abstract_zh': '不同的视角视觉观察能够显著影响机器人操作中的视运动策略性能。在这其中，第一人称（在手）视角往往提供精确控制的关键信息。然而，在某些应用中，为机器人配备专用在手摄像头可能会由于硬件限制、系统复杂性和成本问题而带来挑战。在本文中，我们提出赋予机器人想象感知——使机器人能够在推理时“想象”来自执行者视角的在手观察。我们通过新颖的观点合成（NVS）实现这一目标，利用在执行者和在手视角摄像头之间相对姿态条件下细调的扩散模型。具体而言，我们采用基于LoRA的细调方法，将预训练的NVS模型（ZeroNVS）适应到机器人操作领域。我们在模拟基准（RoboMimic和MimicGen）和使用Unitree Z1机器人手臂进行的草莓采摘真实世界实验中评估了该方法。结果表明，合成的在手视角显著提升了策略推理性能，有效弥补了缺少真实在手摄像头而导致的性能下降。我们的方法提供了一种可扩展且硬件要求较低的解决方案，用于部署稳健的视运动策略，并突显了想象视觉推理在实体代理中的潜力。', 'title_zh': '基于推理的想象：合成手持视角以实现鲁棒的视听运动策略推理'}
{'arxiv_id': 'arXiv:2509.15673', 'title': 'Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion', 'authors': 'Yinong Cao, Xin He, Yuwei Chen, Chenyang Zhang, Chengyu Pu, Bingtao Wang, Kaile Wu, Shouzheng Zhu, Fei Han, Shijie Liu, Chunlai Li, Jianyu Wang', 'link': 'https://arxiv.org/abs/2509.15673', 'abstract': 'Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems rely on a single camera, leading to limited spatial coverage and degraded robustness. We present Omni-LIVO, the first tightly coupled multi-camera LIVO system that bridges the FoV mismatch between wide-angle LiDAR and conventional cameras. Omni-LIVO introduces a Cross-View direct tracking strategy that maintains photometric consistency across non-overlapping views, and extends the Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive covariance weighting. The system is evaluated on public benchmarks and our custom dataset, showing improved accuracy and robustness over state-of-the-art LIVO, LIO, and visual-inertial baselines. Code and dataset will be released upon publication.', 'abstract_zh': '广视野LiDAR传感器提供了大面积环境下的密集几何信息，但现有的LiDAR-惯性-视觉里程计（LIVO）系统大多仅依赖单一摄像头，导致空间覆盖率有限和鲁棒性下降。本文提出了Omni-LIVO，这是一种首次将宽角LiDAR与常规摄像头视野不匹配问题紧密结合的多摄像头LIVO系统。Omni-LIVO引入了一种跨视图直接跟踪策略，以在非重叠视图中保持光电一致性，并通过多视图更新和自适应协方差加权扩展了错误状态迭代卡尔曼滤波器（ESIKF）。系统在公共基准数据集和我们自建的数据集上进行了评估，结果显示其在姿态估计准确性与鲁棒性方面优于当前最先进的LIVO、LIO和视觉惯性基准方法。代码和数据集将在发表后公开。', 'title_zh': '全方位LiDAR-Omni: 基于光度迁移和ESIKF融合的鲁棒多摄像机RGB彩色视觉-惯性-LiDAR里程计'}
{'arxiv_id': 'arXiv:2509.15613', 'title': 'Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization', 'authors': 'Sven Hinderer, Pascal Schlachter, Zhibin Yu, Xiaofeng Wu, Bin Yang', 'link': 'https://arxiv.org/abs/2509.15613', 'abstract': 'We extend our work on a novel indoor positioning system (IPS) for autonomous mobile robots (AMRs) based on radar sensing of local, passive radar reflectors. Through the combination of simple reflectors and a single-channel frequency modulated continuous wave (FMCW) radar, high positioning accuracy at low system cost can be achieved. Further, a multi-objective (MO) particle swarm optimization (PSO) algorithm is presented that optimizes the 2D placement of radar reflectors in complex room settings.', 'abstract_zh': '基于雷达感知局部被动雷达反射器的新型室内定位系统扩展研究：低成本高精度的单通道FMCW雷达与多目标粒子 swarm 优化算法优化雷达反射器布局', 'title_zh': '基于主动雷达传感和被动反射器的室内定位：反射器布置优化'}
{'arxiv_id': 'arXiv:2509.15610', 'title': 'Miniature soft robot with magnetically reprogrammable surgical functions', 'authors': 'Chelsea Shan Xian Ng, Yu Xuan Yeoh, Nicholas Yong Wei Foo, Keerthana Radhakrishnan, Guo Zhan Lum', 'link': 'https://arxiv.org/abs/2509.15610', 'abstract': 'Miniature robots are untethered actuators, which have significant potential to make existing minimally invasive surgery considerably safer and painless, and enable unprecedented treatments because they are much smaller and dexterous than existing surgical robots. Of the miniature robots, the magnetically actuated ones are the most functional and dexterous. However, existing magnetic miniature robots are currently impractical for surgery because they are either restricted to possessing at most two on-board functionalities or having limited five degrees-of-freedom (DOF) locomotion. Some of these actuators are also only operational under specialized environments where actuation from strong external magnets must be at very close proximity (< 4 cm away). Here we present a millimeter-scale soft robot where its magnetization profile can be reprogrammed upon command to perform five surgical functionalities: drug-dispensing, cutting through biological tissues (simulated with gelatin), gripping, storing (biological) samples and remote heating. By possessing full six-DOF motions, including the sixth-DOF rotation about its net magnetic moment, our soft robot can also roll and two-anchor crawl across challenging unstructured environments, which are impassable by its five-DOF counterparts. Because our actuating magnetic fields are relatively uniform and weak (at most 65 mT and 1.5 T/m), such fields can theoretically penetrate through biological tissues harmlessly and allow our soft robot to remain controllable within the depths of the human body. We envision that this work marks a major milestone for the advancement of soft actuators, and towards revolutionizing minimally invasive treatments with untethered miniature robots that have unprecedented functionalities.', 'abstract_zh': '毫米级软磁驱动机器人可在命令下重编程磁化轮廓，执行五种手术功能：药物释放、切割生物组织、抓取、存储生物样本和远程加热。通过具备六自由度运动，包括其净磁矩的第六自由度旋转，该软机器人还可以在结构复杂的环境中进行滚动和双锚点爬行，这是其五自由度同类无法实现的。由于我们的驱动磁场相对均匀且较弱（最大65 mT和1.5 T/m），这些磁场理论上可以无害地穿透生物组织，使软机器人能够在人体内部深处保持可控。我们展望这项工作是软驱动器发展的重要里程碑，并将推动以具有前所未有的功能的无绳微型机器人革新微创治疗方法。', 'title_zh': '磁性可重新编程外科功能的微型软机器人'}
{'arxiv_id': 'arXiv:2509.15607', 'title': 'PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models', 'authors': 'Ruiqi Wang, Dezhong Zhao, Ziqin Yuan, Tianyu Shao, Guohua Chen, Dominic Kao, Sungeun Hong, Byung-Cheol Min', 'link': 'https://arxiv.org/abs/2509.15607', 'abstract': 'Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of large language models and vision-language models in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation, which reduces early-stage query ambiguity by warm-starting the trajectory buffer with bootstrapped samples, and hindsight trajectory augmentation, which enables counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines.', 'abstract_zh': '基于偏好强化学习的PRIMT框架：利用基础模型克服偏好输入和奖励学习挑战', 'title_zh': 'PRIMT：基于偏好的强化学习与多模态反馈及路径合成'}
{'arxiv_id': 'arXiv:2509.15600', 'title': 'ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation', 'authors': 'Jinkai Qiu, Yungjun Kim, Gaurav Sethia, Tanmay Agarwal, Siddharth Ghodasara, Zackory Erickson, Jeffrey Ichnowski', 'link': 'https://arxiv.org/abs/2509.15600', 'abstract': 'Efficiently delivering items to an ongoing surgery in a hospital operating room can be a matter of life or death. In modern hospital settings, delivery robots have successfully transported bulk items between rooms and floors. However, automating item-level operating room logistics presents unique challenges in perception, efficiency, and maintaining sterility. We propose the Operating Room Bot (ORB), a robot framework to automate logistics tasks in hospital operating rooms (OR). ORB leverages a robust, hierarchical behavior tree (BT) architecture to integrate diverse functionalities of object recognition, scene interpretation, and GPU-accelerated motion planning. The contributions of this paper include: (1) a modular software architecture facilitating robust mobile manipulation through behavior trees; (2) a novel real-time object recognition pipeline integrating YOLOv7, Segment Anything Model 2 (SAM2), and Grounded DINO; (3) the adaptation of the cuRobo parallelized trajectory optimization framework to real-time, collision-free mobile manipulation; and (4) empirical validation demonstrating an 80% success rate in OR supply retrieval and a 96% success rate in restocking operations. These contributions establish ORB as a reliable and adaptable system for autonomous OR logistics.', 'abstract_zh': '高效地将物品送达医院手术室可以关乎生死。在现代医院环境中，送货机器人已成功实现房间间和楼层间的批量物品运输。然而，自动化手术室内的物品级物流面临独特的感知、效率和保持无菌性的挑战。我们提出手术室机器人（ORB），一种用于医院手术室（OR）内自动化物流任务的机器人框架。ORB 利用稳健的分层行为树（BT）架构整合了物体识别、场景解释和GPU加速运动规划等多种功能。本文的贡献包括：（1）一种模块化的软件架构，通过行为树实现稳健的移动操作；（2）一种结合YOLOv7、Segment Anything Model 2（SAM2）和Grounded DINO的新颖实时物体识别流水线；（3）将cuRobo并行轨迹优化框架适应于实时、无碰撞的移动操作；（4）实验证明ORB在OR物资检索中成功率达到80%，在补货操作中成功率达到96%。这些贡献确立了ORB作为可靠且适应性强的自主OR物流系统的地位。', 'title_zh': 'ORB：手术室机器人，通过移动操作自动化手术室物流'}
{'arxiv_id': 'arXiv:2509.15597', 'title': 'Distributed Nash Equilibrium Seeking Algorithm in Aggregative Games for Heterogeneous Multi-Robot Systems', 'authors': 'Yi Dong, Zhongguo Li, Sarvapali D. Ramchurn, Xiaowei Huang', 'link': 'https://arxiv.org/abs/2509.15597', 'abstract': 'This paper develops a distributed Nash Equilibrium seeking algorithm for heterogeneous multi-robot systems. The algorithm utilises distributed optimisation and output control to achieve the Nash equilibrium by leveraging information shared among neighbouring robots. Specifically, we propose a distributed optimisation algorithm that calculates the Nash equilibrium as a tailored reference for each robot and designs output control laws for heterogeneous multi-robot systems to track it in an aggregative game. We prove that our algorithm is guaranteed to converge and result in efficient outcomes. The effectiveness of our approach is demonstrated through numerical simulations and empirical testing with physical robots.', 'abstract_zh': '本文开发了异构多机器人系统中的分布式纳什均衡寻求算法。该算法利用分布式优化和输出控制，通过利用邻近机器人之间共享的信息来实现纳什均衡。具体而言，我们提出了一种分布式优化算法，为每个机器人计算一个定制化的纳什均衡参考，并设计了输出控制律以使异构多机器人系统在聚合博弈中跟踪该参考。我们证明了该算法能够收敛并产生高效的结果。通过数值仿真和物理机器人实验验证了我们方法的有效性。', 'title_zh': '异构多机器人系统中聚合博弈的分布式纳什均衡搜索算法'}
{'arxiv_id': 'arXiv:2509.15583', 'title': 'Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization', 'authors': 'Runxin Zhao, Chunxiang Wang, Hanyang Zhuang, Ming Yang', 'link': 'https://arxiv.org/abs/2509.15583', 'abstract': 'Vehicle localization using roadside LiDARs can provide centimeter-level accuracy for cloud-controlled vehicles while simultaneously serving multiple vehicles, enhanc-ing safety and efficiency. While most existing studies rely on repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages such as eliminating blind zones and being more cost-effective. However, its application in roadside perception and localization remains limited. To address this, we present a dataset for infrastructure-based vehicle localization, with data collected from both repetitive and non-repetitive scanning LiDARs, in order to benchmark the performance of different LiDAR scanning patterns. The dataset contains 5,445 frames of point clouds across eight vehicle trajectory sequences, with diverse trajectory types. Our experiments establish base-lines for infrastructure-based vehicle localization and compare the performance of these methods using both non-repetitive and repetitive scanning LiDARs. This work offers valuable insights for selecting the most suitable LiDAR scanning pattern for infrastruc-ture-based vehicle localization. Our dataset is a signifi-cant contribution to the scientific community, supporting advancements in infrastructure-based perception and vehicle localization. The dataset and source code are publicly available at: this https URL.', 'abstract_zh': '基于路边LiDAR的车辆定位可以为云端控制车辆提供厘米级精度，同时服务于多辆车辆，增强安全性和效率。尽管大多数现有研究依赖重复扫描LiDAR，非重复扫描LiDAR具有消除盲区和更经济的优点，但其在路边感知与定位中的应用仍然有限。为了解决这个问题，我们提出了一个基于基础设施的车辆定位数据集，收集了重复扫描和非重复扫描LiDAR的数据，以评估不同LiDAR扫描模式的性能。该数据集包含八个车辆轨迹序列中的5,445帧点云数据，涵盖了多种轨迹类型。我们的实验建立了基于基础设施的车辆定位基准，并使用非重复扫描和重复扫描LiDAR比较了不同方法的性能。该研究为选择最适合基于基础设施的车辆定位的LiDAR扫描模式提供了有价值的见解。我们的数据集对科学界是一个重要的贡献，支持基础设施感知和车辆定位技术的发展。该数据集和源代码可在以下链接公开获取：this https URL。', 'title_zh': 'Bench-RNR：基于基础设施车辆定位的重复扫描与非重复扫描LiDAR基准测试数据集'}
{'arxiv_id': 'arXiv:2509.15582', 'title': 'Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios', 'authors': 'Yuting Zeng, Zhiwen Zheng, You Zhou, JiaLing Xiao, Yongbin Yu, Manping Fan, Bo Gong, Liyong Ren', 'link': 'https://arxiv.org/abs/2509.15582', 'abstract': "This paper proposes a momentum-constrained hybrid heuristic trajectory optimization framework (MHHTOF) tailored for assistive navigation in visually impaired scenarios, integrating trajectory sampling generation, optimization and evaluation with residual-enhanced deep reinforcement learning (DRL). In the first stage, heuristic trajectory sampling cluster (HTSC) is generated in the Frenet coordinate system using third-order interpolation with fifth-order polynomials and momentum-constrained trajectory optimization (MTO) constraints to ensure smoothness and feasibility. After first stage cost evaluation, the second stage leverages a residual-enhanced actor-critic network with LSTM-based temporal feature modeling to adaptively refine trajectory selection in the Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with weight transfer aligns semantic priorities across stages, supporting human-centered optimization. Experimental results demonstrate that the proposed LSTM-ResB-PPO achieves significantly faster convergence, attaining stable policy performance in approximately half the training iterations required by the PPO baseline, while simultaneously enhancing both reward outcomes and training stability. Compared to baseline method, the selected model reduces average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle risks by over 77%. These findings validate the framework's effectiveness in enhancing robustness, safety, and real-time feasibility in complex assistive planning tasks.", 'abstract_zh': '基于动量约束的混合启发式轨迹优化框架（MHHTOF）：残差增强的深度强化学习在视觉障碍场景中的辅助导航中应用', 'title_zh': '基于动量约束的混合启发式轨迹优化框架及残差增强DRL在视觉 impaired 情景中的应用'}
{'arxiv_id': 'arXiv:2509.15565', 'title': 'Distribution Estimation for Global Data Association via Approximate Bayesian Inference', 'authors': 'Yixuan Jia, Mason B. Peterson, Qingyuan Li, Yulun Tian, Jonathan P. How', 'link': 'https://arxiv.org/abs/2509.15565', 'abstract': 'Global data association is an essential prerequisite for robot operation in environments seen at different times or by different robots. Repetitive or symmetric data creates significant challenges for existing methods, which typically rely on maximum likelihood estimation or maximum consensus to produce a single set of associations. However, in ambiguous scenarios, the distribution of solutions to global data association problems is often highly multimodal, and such single-solution approaches frequently fail. In this work, we introduce a data association framework that leverages approximate Bayesian inference to capture multiple solution modes to the data association problem, thereby avoiding premature commitment to a single solution under ambiguity. Our approach represents hypothetical solutions as particles that evolve according to a deterministic or randomized update rule to cover the modes of the underlying solution distribution. Furthermore, we show that our method can incorporate optimization constraints imposed by the data association formulation and directly benefit from GPU-parallelized optimization. Extensive simulated and real-world experiments with highly ambiguous data show that our method correctly estimates the distribution over transformations when registering point clouds or object maps.', 'abstract_zh': '全球数据关联是机器人在不同时段或不同机器人环境中操作的 essential 预先条件。重复或对称数据为现有方法带来了重大挑战，这些方法通常依赖最大似然估计或最大一致估计来生成单个关联集。然而，在模棱两可的场景中，全局数据关联问题的解分布往往是高度多模态的，这种单一解的方法经常失败。本文引入了一种数据关联框架，利用近似贝叶斯推断来捕捉数据关联问题的多个解模态，从而在模棱两可的情况下避免过早对单一解做出承诺。我们的方法将假设解表示为粒子，这些粒子根据确定性或随机更新规则演变以涵盖基础解分布的模态。此外，我们展示了我们的方法可以整合由数据关联形式提出的优化约束，并直接从中受益 GPU 并行化优化。广泛模拟和真实世界实验表明，在注册点云或对象地图时，我们的方法可以正确估计变换分布。', 'title_zh': '基于近似貝叶斯推断的全球数据关联分布估计'}
{'arxiv_id': 'arXiv:2509.15507', 'title': 'STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response', 'authors': 'Shenghai Yuan, Weixiang Guo, Tianxin Hu, Yu Yang, Jinyu Chen, Rui Qian, Zhongyuan Liu, Lihua Xie', 'link': 'https://arxiv.org/abs/2509.15507', 'abstract': "In emergency response missions, first responders must navigate cluttered indoor environments where occlusions block direct line-of-sight, concealing both life-threatening hazards and victims in need of rescue. We present STARC, a see-through AR framework for human-robot collaboration that fuses mobile-robot mapping with responder-mounted LiDAR sensing. A ground robot running LiDAR-inertial odometry performs large-area exploration and 3D human detection, while helmet- or handheld-mounted LiDAR on the responder is registered to the robot's global map via relative pose estimation. This cross-LiDAR alignment enables consistent first-person projection of detected humans and their point clouds - rendered in AR with low latency - into the responder's view. By providing real-time visualization of hidden occupants and hazards, STARC enhances situational awareness and reduces operator risk. Experiments in simulation, lab setups, and tactical field trials confirm robust pose alignment, reliable detections, and stable overlays, underscoring the potential of our system for fire-fighting, disaster relief, and other safety-critical operations. Code and design will be open-sourced upon acceptance.", 'abstract_zh': '在应急响应任务中，一线救援人员必须穿越拥挤的室内环境，其中遮挡物阻挡了直接视线，隐藏了生命威胁的危险和需要救援的受害者。我们提出了一种名为STARC的透明AR框架，用于人机协作，融合了移动机器人建图与救援人员佩戴的LiDAR感测。地面机器人运行LiDAR-惯性_odometry进行大面积探索和3D人类检测，而救援人员头盔或手持设备上的LiDAR与机器人全局地图通过相对姿态估计进行配准。这种跨LiDAR对齐使得检测到的人员及其点云能够在AR中以低延迟的一致第一人称投影到救援人员的视野中。通过实时可视化隐藏的占用者和危险，STARC增强了情况意识并降低了操作者风险。在仿真、实验室配置和战术现场试验中，STARC的稳健姿态对齐、可靠的检测和稳定叠加得到了证实，彰显了其在火灾救援、灾难救助和其他关键安全操作中的潜力。代码和设计将在接受后开源。', 'title_zh': 'STARC: 贯穿墙体增强现实框架在紧急响应中的人机协作'}
{'arxiv_id': 'arXiv:2509.15491', 'title': 'Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems', 'authors': 'Reza Pirayeshshirazinezhad, Nima Fathi', 'link': 'https://arxiv.org/abs/2509.15491', 'abstract': 'We present an explainable AI-enhanced supervisory control framework for multi-agent robotics that combines (i) a timed-automata supervisor for safe, auditable mode switching, (ii) robust continuous control (Lyapunov-based controller for large-angle maneuver; sliding-mode controller (SMC) with boundary layers for precision and disturbance rejection), and (iii) an explainable predictor that maps mission context to gains and expected performance (energy, error). Monte Carlo-driven optimization provides the training data, enabling transparent real-time trade-offs.\nWe validated the approach in two contrasting domains, spacecraft formation flying and autonomous underwater vehicles (AUVs). Despite different environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion, and tight tracking needs, making them representative of general robotic systems. In the space mission, the supervisory logic selects parameters that meet mission criteria. In AUV leader-follower tests, the same SMC structure maintains a fixed offset under stochastic currents with bounded steady error. In spacecraft validation, the SMC controller achieved submillimeter alignment with 21.7% lower tracking error and 81.4% lower energy consumption compared to Proportional-Derivative PD controller baselines. At the same time, in AUV tests, SMC maintained bounded errors under stochastic currents. These results highlight both the portability and the interpretability of the approach for safety-critical, resource-constrained multi-agent robotics.', 'abstract_zh': '一种基于定时自动机的可解释AI增强监督控制框架：应用于多agent机器人系统的鲁棒连续控制与解释预测方法及其在航天器编队飞行和自主水下车辆中的验证', 'title_zh': '可解释AI增强的监督控制在鲁棒多 ));机器人系统中的应用'}
{'arxiv_id': 'arXiv:2509.15443', 'title': 'Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning', 'authors': 'Xingyu Chen, Hanyu Wu, Sikai Wu, Mingliang Zhou, Diyun Xiang, Haodong Zhang', 'link': 'https://arxiv.org/abs/2509.15443', 'abstract': 'Human-to-humanoid imitation learning aims to learn a humanoid whole-body controller from human motion. Motion retargeting is a crucial step in enabling robots to acquire reference trajectories when exploring locomotion skills. However, current methods focus on motion retargeting frame by frame, which lacks scalability. Could we directly convert large-scale human motion into robot-executable motion through a more efficient approach? To address this issue, we propose Implicit Kinodynamic Motion Retargeting (IKMR), a novel efficient and scalable retargeting framework that considers both kinematics and dynamics. In kinematics, IKMR pretrains motion topology feature representation and a dual encoder-decoder architecture to learn a motion domain mapping. In dynamics, IKMR integrates imitation learning with the motion retargeting network to refine motion into physically feasible trajectories. After fine-tuning using the tracking results, IKMR can achieve large-scale physically feasible motion retargeting in real time, and a whole-body controller could be directly trained and deployed for tracking its retargeted trajectories. We conduct our experiments both in the simulator and the real robot on a full-size humanoid robot. Extensive experiments and evaluation results verify the effectiveness of our proposed framework.', 'abstract_zh': '从人类到人形机器人的模仿学习旨在从人类动作中学习人形全身控制器。运动目标映射是使机器人在探索运动技能时能够获得参考轨迹的关键步骤。然而，当前方法侧重于逐帧进行运动目标映射，缺乏扩展性。我们能否通过更高效的方法直接将大规模人类运动转换为可执行的机器人运动？为了解决这一问题，我们提出了隐式动力学运动目标映射（IKMR），这是一种既考虑运动学又考虑动力学的新颖高效且可扩展的映射框架。在运动学中，IKMR 预训练运动拓扑特征表示和双编码器-解码器架构以学习运动域映射。在动力学中，IKMR将模仿学习与运动目标映射网络集成，以细化运动为物理上可行的轨迹。经过跟踪结果的微调后，IKMR可以在实时中实现大规模物理上可行的运动目标映射，并可以直接训练和部署全身控制器以跟踪其目标映射的轨迹。我们在仿真实验室和真实机器人上对全尺寸人形机器人进行了实验。广泛的实验和评估结果验证了我们所提出框架的有效性。', 'title_zh': '基于隐式动力学的人类到类人机器人模仿学习运动重定向'}
{'arxiv_id': 'arXiv:2509.15423', 'title': 'Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing', 'authors': 'Christopher Oeltjen, Carson Sobolewski, Saleh Faghfoorian, Lorant Domokos, Giancarlo Vidal, Ivan Ruchkin', 'link': 'https://arxiv.org/abs/2509.15423', 'abstract': 'Accurate knowledge of the tire-road friction coefficient (TRFC) is essential for vehicle safety, stability, and performance, especially in autonomous racing, where vehicles often operate at the friction limit. However, TRFC cannot be directly measured with standard sensors, and existing estimation methods either depend on vehicle or tire models with uncertain parameters or require large training datasets. In this paper, we present a lightweight approach for online slip detection and TRFC estimation. Our approach relies solely on IMU and LiDAR measurements and the control actions, without special dynamical or tire models, parameter identification, or training data. Slip events are detected in real time by comparing commanded and measured motions, and the TRFC is then estimated directly from observed accelerations under no-slip conditions. Experiments with a 1:10-scale autonomous racing car across different friction levels demonstrate that the proposed approach achieves accurate and consistent slip detections and friction coefficients, with results closely matching ground-truth measurements. These findings highlight the potential of our simple, deployable, and computationally efficient approach for real-time slip monitoring and friction coefficient estimation in autonomous driving.', 'abstract_zh': '基于IMU和LiDAR的在线侧滑检测与摩擦系数估算', 'title_zh': '在线打滑检测与摩擦系数估计在自主赛车中的应用'}
{'arxiv_id': 'arXiv:2509.15412', 'title': 'Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control', 'authors': 'Easop Lee, Samuel A. Moore, Boyuan Chen', 'link': 'https://arxiv.org/abs/2509.15412', 'abstract': 'We present Sym2Real, a fully data-driven framework that provides a principled way to train low-level adaptive controllers in a highly data-efficient manner. Using only about 10 trajectories, we achieve robust control of both a quadrotor and a racecar in the real world, without expert knowledge or simulation tuning. Our approach achieves this data efficiency by bringing symbolic regression to real-world robotics while addressing key challenges that prevent its direct application, including noise sensitivity and model degradation that lead to unsafe control. Our key observation is that the underlying physics is often shared for a system regardless of internal or external changes. Hence, we strategically combine low-fidelity simulation data with targeted real-world residual learning. Through experimental validation on quadrotor and racecar platforms, we demonstrate consistent data-efficient adaptation across six out-of-distribution sim2sim scenarios and successful sim2real transfer across five real-world conditions. More information and videos can be found at at this http URL', 'abstract_zh': 'Sym2Real: 一个数据驱动的框架，以高效数据方式训练低级自适应控制器', 'title_zh': 'Sym2Real: 基于残差学习的符号动力学在数据高效自适应控制中的应用'}
{'arxiv_id': 'arXiv:2509.15404', 'title': 'Trust-Aware Embodied Bayesian Persuasion for Mixed-Autonomy', 'authors': 'Shaoting Peng, Katherine Driggs-Campbell, Roy Dong', 'link': 'https://arxiv.org/abs/2509.15404', 'abstract': "Safe and efficient interaction between autonomous vehicles (AVs) and human-driven vehicles (HVs) is a critical challenge for future transportation systems. While game-theoretic models capture how AVs influence HVs, they often suffer from a long-term decay of influence and can be perceived as manipulative, eroding the human's trust. This can paradoxically lead to riskier human driving behavior over repeated interactions. In this paper, we address this challenge by proposing the Trust-Aware Embodied Bayesian Persuasion (TA-EBP) framework. Our work makes three key contributions: First, we apply Bayesian persuasion to model communication at traffic intersections, offering a transparent alternative to traditional game-theoretic models. Second, we introduce a trust parameter to the persuasion framework, deriving a theorem for the minimum trust level required for influence. Finally, we ground the abstract signals of Bayesian persuasion theory into a continuous, physically meaningful action space, deriving a second theorem for the optimal signal magnitude, realized as an AV's forward nudge. Additionally, we validate our framework in a mixed-autonomy traffic simulation, demonstrating that TA-EBP successfully persuades HVs to drive more cautiously, eliminating collisions and improving traffic flow compared to baselines that either ignore trust or lack communication. Our work provides a transparent and non-strategic framework for influence in human-robot interaction, enhancing both safety and efficiency.", 'abstract_zh': '可信意识嵌入贝叶斯劝导框架（TA-EBP）：自动驾驶汽车与有人驾驶车辆安全高效互动的研究', 'title_zh': '具有信任意识的混合自主性体态说服技术'}
{'arxiv_id': 'arXiv:2509.15325', 'title': 'Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound', 'authors': 'Ryan S. Yeung, David G. Black, Septimiu E. Salcudean', 'link': 'https://arxiv.org/abs/2509.15325', 'abstract': "Teleoperated ultrasound can improve diagnostic medical imaging access for remote communities. Having accurate force feedback is important for enabling sonographers to apply the appropriate probe contact force to optimize ultrasound image quality. However, large time delays in communication make direct force feedback impractical. Prior work investigated using point cloud-based model-mediated teleoperation and internal potential field models to estimate contact forces and torques. We expand on this by introducing a method to update the internal potential field model of the patient with measured positions and forces for more transparent model-mediated tele-ultrasound. We first generate a point cloud model of the patient's surface and transmit this to the sonographer in a compact data structure. This is converted to a static voxelized volume where each voxel contains a potential field value. These values determine the forces and torques, which are rendered based on overlap between the voxelized volume and a point shell model of the ultrasound transducer. We solve for the potential field using a convex quadratic that combines the spatial Laplace operator with measured forces. This was evaluated on volunteer patients ($n=3$) by computing the accuracy of rendered forces. Results showed the addition of measured forces to the model reduced the force magnitude error by an average of 7.23 N and force vector angle error by an average of 9.37$^{\\circ}$ compared to using only Laplace's equation.", 'abstract_zh': '远程操控超声可以改善偏远社区的诊断医学成像访问。基于点云的模型介导远程操控和内部势场模型可提高接触力估计，实现更透明的模型介导远程超声。', 'title_zh': '基于测量与势场的患者建模以实现模型中介的远程超声波检查'}
{'arxiv_id': 'arXiv:2509.15273', 'title': 'Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI', 'authors': 'Fei Ni, Min Zhang, Pengyi Li, Yifu Yuan, Lingfeng Zhang, Yuecheng Liu, Peilong Han, Longxin Kou, Shaojin Ma, Jinbin Qiao, David Gamaliel Arcos Bravo, Yuening Wang, Xiao Hu, Zhanguang Zhang, Xianze Yao, Yutong Li, Zhao Zhang, Ying Wen, Ying-Cong Chen, Xiaodan Liang, Liang Lin, Bin He, Haitham Bou-Ammar, He Wang, Huazhe Xu, Jiankang Deng, Shan Luo, Shuqiang Jiang, Wei Pan, Yang Gao, Stefanos Zafeiriou, Jan Peters, Yuzheng Zhuang, Yingxue Zhang, Yan Zheng, Hongyao Tang, Jianye Hao', 'link': 'https://arxiv.org/abs/2509.15273', 'abstract': 'Embodied AI development significantly lags behind large foundation models due to three critical challenges: (1) lack of systematic understanding of core capabilities needed for Embodied AI, making research lack clear objectives; (2) absence of unified and standardized evaluation systems, rendering cross-benchmark evaluation infeasible; and (3) underdeveloped automated and scalable acquisition methods for embodied data, creating critical bottlenecks for model scaling. To address these obstacles, we present Embodied Arena, a comprehensive, unified, and evolving evaluation platform for Embodied AI. Our platform establishes a systematic embodied capability taxonomy spanning three levels (perception, reasoning, task execution), seven core capabilities, and 25 fine-grained dimensions, enabling unified evaluation with systematic research objectives. We introduce a standardized evaluation system built upon unified infrastructure supporting flexible integration of 22 diverse benchmarks across three domains (2D/3D Embodied Q&A, Navigation, Task Planning) and 30+ advanced models from 20+ worldwide institutes. Additionally, we develop a novel LLM-driven automated generation pipeline ensuring scalable embodied evaluation data with continuous evolution for diversity and comprehensiveness. Embodied Arena publishes three real-time leaderboards (Embodied Q&A, Navigation, Task Planning) with dual perspectives (benchmark view and capability view), providing comprehensive overviews of advanced model capabilities. Especially, we present nine findings summarized from the evaluation results on the leaderboards of Embodied Arena. This helps to establish clear research veins and pinpoint critical research problems, thereby driving forward progress in the field of Embodied AI.', 'abstract_zh': '体态AI的发展显著落后于大型基础模型，主要原因包括三个关键挑战：缺乏对体态AI所需核心能力的系统理解，导致研究缺乏明确的目标；缺乏统一和标准化的评估体系，使得跨基准评估不可行；以及体态数据的自动化和可扩展获取方法欠发达，成为模型扩展的关键瓶颈。为应对这些障碍，我们提出了一种全面、统一和演化的评估平台——体态竞技场，用于体态AI。该平台构建了一个跨越三个层次（感知、推理、任务执行）、七个核心能力和25个细粒度维度的系统体态能力分类体系，从而实现统一评估并明确研究目标。我们引入了一个基于统一基础设施的标准化评估系统，该系统支持22个跨三个领域（2D/3D体态问答、导航、任务规划）的基准的灵活集成，并来自全球20多个研究机构的30多种高级模型。此外，我们开发了一种新颖的基于大模型的自动化生成流水线，确保能够实现可扩展的体态评估数据，并持续进化以增强多样性和全面性。体态竞技场发布了三个实时排行榜（体态问答、导航、任务规划），从基准视角和能力视角提供高级模型能力的全面概述。特别地，我们总结了体态竞技场排行榜评估结果中的九项发现，这些发现有助于明确研究方向并指出关键研究问题，从而推动体态AI领域的发展。', 'title_zh': '具身竞技场：一个全面、统一且不断演化的具身AI评估平台'}
{'arxiv_id': 'arXiv:2509.15264', 'title': 'GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection', 'authors': 'Aasfee Mosharraf Bhuiyan, Md Luban Mehda, Md. Thawhid Hasan Puspo, Jubayer Amin Pritom', 'link': 'https://arxiv.org/abs/2509.15264', 'abstract': "This paper presents the design, development and testing of GiAnt, an affordable hexapod which is inspired by the efficient motions of ants. The decision to model GiAnt after ants rather than other insects is rooted in ants' natural adaptability to a variety of terrains. This bio-inspired approach gives it a significant advantage in outdoor applications, offering terrain flexibility along with efficient energy use. It features a lightweight 3D-printed and laser cut structure weighing 1.75 kg with dimensions of 310 mm x 200 mm x 120 mm. Its legs have been designed with a simple Single Degree of Freedom (DOF) using a link and crank mechanism. It is great for conquering challenging terrains such as grass, rocks, and steep surfaces. Unlike traditional robots using four wheels for motion, its legged design gives superior adaptability to uneven and rough surfaces. GiAnt's control system is built on Arduino, allowing manual operation. An effective way of controlling the legs of GiAnt was achieved by gait analysis. It can move up to 8 cm of height easily with its advanced leg positioning system. Furthermore, equipped with machine learning and image processing technology, it can identify 81 different objects in a live monitoring system. It represents a significant step towards creating accessible hexapod robots for research, exploration, and surveying, offering unique advantages in adaptability and control simplicity.", 'abstract_zh': 'GiAnt：一种受蚂蚁启发的经济型六足机器人及其设计、开发与测试', 'title_zh': 'GiAnt：一种生物启发的六足机器人，用于自适应地形导航和对象检测'}
{'arxiv_id': 'arXiv:2509.15254', 'title': 'DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects', 'authors': 'Ngoc Huy Nguyen, Kazuki Shibata, Takamitsu Matsubara', 'link': 'https://arxiv.org/abs/2509.15254', 'abstract': "In this study, we address the problem of in-flight object catching using a quadruped robot with a basket. Our objective is to accurately predict the impact point, defined as the object's landing position. This task poses two key challenges: the absence of public datasets capturing diverse objects under unsteady aerodynamics, which are essential for training reliable predictors; and the difficulty of accurate early-stage impact point prediction when trajectories appear similar across objects. To overcome these issues, we construct a real-world dataset of 8,000 trajectories from 20 objects, providing a foundation for advancing in-flight object catching under complex aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP), consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that separates trajectories by dynamics to enable early-stage discrimination and generalization, and (ii) an Impact Point Predictor (IPP) that estimates the impact point from these features. Two IPP variants are implemented: an Neural Acceleration Estimator (NAE)-based method that predicts trajectories and derives the impact point, and a Direct Point Estimator (DPE)-based method that directly outputs it. Experimental results show that our dataset is more diverse and complex than existing dataset, and that our method outperforms baselines on both 15 seen and 5 unseen objects. Furthermore, we show that improved early-stage prediction enhances catching success in simulation and demonstrate the effectiveness of our approach through real-world experiments. The demonstration is available at this https URL.", 'abstract_zh': '在本研究中，我们使用带有篮子的四足机器人解决了飞行中捕获物体的问题。我们的目标是对物体的着陆位置进行准确预测，定义为冲击点。这项任务面临两个关键挑战：缺乏涵盖不同物体并在不稳定空气动力学条件下进行捕获的公开数据集，这些数据集对于训练可靠的预测器是必要的；以及在物体轨迹相似时难以进行准确的早期冲击点预测。为了解决这些问题，我们构建了一个包含20个物体8,000条轨迹的真实世界数据集，为在复杂空气动力学条件下进行飞行中物体捕获的研究奠定了基础。然后，我们提出了判别冲击点预测器（DIPP），由两个模块组成：（i）判别性特征嵌入（DFE）模块，通过区分轨迹的动力学特性来实现早期阶段的判别和泛化；（ii）冲击点预测器（IPP），从这些特征中估计冲击点。我们实现了两种IPP变体：一种基于神经加速度估计器（NAE）的方法，用于预测轨迹并推导出冲击点，另一种基于直接点估计器（DPE）的方法，直接输出冲击点。实验结果表明，我们的数据集比现有数据集更具多样性和复杂性，并且我们的方法在15个已见物体和5个未见物体上均优于基线方法。此外，我们展示了早期阶段预测的改进如何在仿真中提高捕获成功率，并通过实际实验展示了我们方法的有效性。演示内容可在以下链接查看：这个 https URL', 'title_zh': 'DIPP：用于捕获多样在飞行对象的辨别性影响点预测器'}
{'arxiv_id': 'arXiv:2509.15987', 'title': 'Towards Sharper Object Boundaries in Self-Supervised Depth Estimation', 'authors': 'Aurélien Cecille, Stefan Duffner, Franck Davoine, Rémi Agier, Thibault Neveu', 'link': 'https://arxiv.org/abs/2509.15987', 'abstract': 'Accurate monocular depth estimation is crucial for 3D scene understanding, but existing methods often blur depth at object boundaries, introducing spurious intermediate 3D points. While achieving sharp edges usually requires very fine-grained supervision, our method produces crisp depth discontinuities using only self-supervision. Specifically, we model per-pixel depth as a mixture distribution, capturing multiple plausible depths and shifting uncertainty from direct regression to the mixture weights. This formulation integrates seamlessly into existing pipelines via variance-aware loss functions and uncertainty propagation. Extensive evaluations on KITTI and VKITTIv2 show that our method achieves up to 35% higher boundary sharpness and improves point cloud quality compared to state-of-the-art baselines.', 'abstract_zh': '单目深度估计的准确度对于3D场景理解至关重要，但现有方法往往在物体边界处产生模糊深度，引入虚假的中间3D点。虽然获得清晰边缘通常需要精细的监督，我们的方法仅通过自我监督即可产生锐利的深度不连续性。具体而言，我们将像素级深度建模为混合分布，捕捉多个可能的深度值并将不确定性从直接回归转移到混合权重上。该模型通过方差意识的损失函数和不确定性传播无缝集成到现有管道中。在KITTI和VKITTIv2上的广泛评估表明，我们的方法在边界锐度上可达到35%的提升，并改善了点云质量，优于现有的基线方法。', 'title_zh': '向自监督深度估计中更锐利的物体边界靠拢'}
{'arxiv_id': 'arXiv:2509.15984', 'title': 'CoPAD : Multi-source Trajectory Fusion and Cooperative Trajectory Prediction with Anchor-oriented Decoder in V2X Scenarios', 'authors': 'Kangyu Wu, Jiaqi Qiao, Ya Zhang', 'link': 'https://arxiv.org/abs/2509.15984', 'abstract': 'Recently, data-driven trajectory prediction methods have achieved remarkable results, significantly advancing the development of autonomous driving. However, the instability of single-vehicle perception introduces certain limitations to trajectory prediction. In this paper, a novel lightweight framework for cooperative trajectory prediction, CoPAD, is proposed. This framework incorporates a fusion module based on the Hungarian algorithm and Kalman filtering, along with the Past Time Attention (PTA) module, mode attention module and anchor-oriented decoder (AoD). It effectively performs early fusion on multi-source trajectory data from vehicles and road infrastructure, enabling the trajectories with high completeness and accuracy. The PTA module can efficiently capture potential interaction information among historical trajectories, and the mode attention module is proposed to enrich the diversity of predictions. Additionally, the decoder based on sparse anchors is designed to generate the final complete trajectories. Extensive experiments show that CoPAD achieves the state-of-the-art performance on the DAIR-V2X-Seq dataset, validating the effectiveness of the model in cooperative trajectory prediction in V2X scenarios.', 'abstract_zh': '基于匈牙利算法和卡尔曼滤波的多源融合模块的Cooperative Trajectory Prediction框架（CoPAD）', 'title_zh': 'CoPAD：面向锚点的解码器多源轨迹融合与协作轨迹预测在V2X场景中'}
{'arxiv_id': 'arXiv:2509.15981', 'title': 'Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations', 'authors': 'Yujie Zhu, Charles A. Hepburn, Matthew Thorpe, Giovanni Montana', 'link': 'https://arxiv.org/abs/2509.15981', 'abstract': 'In reinforcement learning with sparse rewards, demonstrations can accelerate learning, but determining when to imitate them remains challenging. We propose Smooth Policy Regularisation from Demonstrations (SPReD), a framework that addresses the fundamental question: when should an agent imitate a demonstration versus follow its own policy? SPReD uses ensemble methods to explicitly model Q-value distributions for both demonstration and policy actions, quantifying uncertainty for comparisons. We develop two complementary uncertainty-aware methods: a probabilistic approach estimating the likelihood of demonstration superiority, and an advantage-based approach scaling imitation by statistical significance. Unlike prevailing methods (e.g. Q-filter) that make binary imitation decisions, SPReD applies continuous, uncertainty-proportional regularisation weights, reducing gradient variance during training. Despite its computational simplicity, SPReD achieves remarkable gains in experiments across eight robotics tasks, outperforming existing approaches by up to a factor of 14 in complex tasks while maintaining robustness to demonstration quality and quantity. Our code is available at this https URL.', 'abstract_zh': '在稀疏奖励的强化学习中，演示可以加速学习，但确定何时模仿仍具挑战性。我们提出了一种平滑策略正则化框架（SPReD），该框架解决了基本问题：代理何时应该模仿演示，何时应遵循其自身策略？SPReD 使用集成方法显式建模演示和策略动作的 Q 值分布，量化不确定性以进行比较。我们开发了两种互补的不确定性感知方法：一种概率方法估计演示优越性的概率，以及一种基于优势的方法，通过统计显著性调整模仿。与现有的二元模仿决策方法（如 Q-filter）不同，SPReD 应用连续的、与不确定性成比例的正则化权重，在训练期间降低梯度方差。尽管计算上很简单，但在八个机器人任务的实验中，SPReD 在复杂任务中的表现比现有方法提高了一倍多，同时保持了对演示质量和数量的鲁棒性。我们的代码可在以下网址获取：this https URL。', 'title_zh': '基于不确定性平滑策略正则化的小样本强化学习'}
{'arxiv_id': 'arXiv:2509.15909', 'title': 'A CARLA-based Simulation of Electrically Driven Forklifts', 'authors': 'David Claus, Christiane Thielemann, Hans-Georg Stark', 'link': 'https://arxiv.org/abs/2509.15909', 'abstract': "This paper presents the simulation of the operation of an electric forklift fleet within an intralogistics scenario. For this purpose, the open source simulation tool CARLA is used; according to our knowledge this is a novel approach in the context of logistics simulation. First, CARLA is used to generate and visualize a realistic 3D outdoor warehouse scenario, incorporating a number of randomly moving forklifts. In a next step, intralogistics transport tasks, such as pick-and-place, are simulated for the forklift fleet, including shortest-path finding. Furthermore, the capability to play back localization data, previously recorded from a ''real'' forklift fleet, is this http URL play back is done in the original recreated environment, thereby enabling the visualization of the forklifts movements. Finally, the energy consumption of the forklift trucks is simulated by integrating a physical battery model that generates the state of charge (SOC) of each truck as a function of load and activity. To demonstrate the wide range of possible applications for the CARLA simulation platform, we describe two use cases. The first deals with the problem of detecting regions with critically high traffic densities, the second with optimal placement of charging stations for the forklift trucks. Both use cases are calculated for an exemplary warehouse model.", 'abstract_zh': '本文介绍了一种在物流场景中使用开源仿真工具CARLA模拟电叉车车队运行的仿真方法；这是一种新颖的物流仿真方法。首先，使用CARLA生成并可视化一个真实的三维室外仓库场景，并包含一组随机移动的叉车。接着，模拟叉车车队的内物流运输任务，如拣选和放置，包括最短路径查找。此外，该仿真平台还具备回放实际叉车车队记录的定位数据的能力，并能够在原始重构的环境中进行回放，从而可视化叉车的运动。最后，通过集成一个物理电池模型来模拟叉车的能耗，该模型根据负载和活动生成每辆叉车的状态电量(SOC)。为了展示CARLA仿真平台的广泛适用性，我们描述了两个使用案例。第一个案例涉及检测交通密度极高区域的问题，第二个案例涉及优化叉车充电站的布局。这两个案例均基于一个示例仓库模型进行计算。', 'title_zh': '基于CARLA的电动叉车仿真模拟'}
{'arxiv_id': 'arXiv:2509.15799', 'title': 'Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control', 'authors': 'Max Studt, Georg Schildbach', 'link': 'https://arxiv.org/abs/2509.15799', 'abstract': 'Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control.', 'abstract_zh': '基于层次框架的战术决策与模型预测控制相结合在动态、约束丰富的环境中的安全协调行为研究', 'title_zh': '基于低层级MPC的多层次强化学习多agents控制'}
{'arxiv_id': 'arXiv:2509.15778', 'title': 'All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control', 'authors': 'Mohammad Bahari, Amir Hossein Barjini, Pauli Mustalahti, Jouni Mattila', 'link': 'https://arxiv.org/abs/2509.15778', 'abstract': 'This paper presents a unified framework that integrates modeling, optimization, and sensorless control of an all-electric heavy-duty robotic manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). An EMLA model is formulated to capture motor electromechanics and direction-dependent transmission efficiencies, while a mathematical model of the HDRM, incorporating both kinematics and dynamics, is established to generate joint-space motion profiles for prescribed TCP trajectories. A safety-ensured trajectory generator, tailored to this model, maps Cartesian goals to joint space while enforcing joint-limit and velocity margins. Based on the resulting force and velocity demands, a multi-objective Non-dominated Sorting Genetic Algorithm II (NSGA-II) is employed to select the optimal EMLA configuration. To accelerate this optimization, a deep neural network, trained with EMLA parameters, is embedded in the optimization process to predict steady-state actuator efficiency from trajectory profiles. For the chosen EMLA design, a physics-informed Kriging surrogate, anchored to the analytic model and refined with experimental data, learns residuals of EMLA outputs to support force and velocity sensorless control. The actuator model is further embedded in a hierarchical virtual decomposition control (VDC) framework that outputs voltage commands. Experimental validation on a one-degree-of-freedom EMLA testbed confirms accurate trajectory tracking and effective sensorless control under varying loads.', 'abstract_zh': '一种集成了电动机械线性执行器(EMLA)驱动的全电重型机器人 manipulator (HDRM) 的建模、优化和无传感器控制的统一框架', 'title_zh': '全电驱动重型机器人 manipulator: 执行器配置优化与无传感器控制'}
{'arxiv_id': 'arXiv:2509.15730', 'title': 'A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation', 'authors': 'Lukas Laakmann, Seyyid A. Ciftci, Christian Janiesch', 'link': 'https://arxiv.org/abs/2509.15730', 'abstract': 'Robotic process automation (RPA) is a lightweight approach to automating business processes using software robots that emulate user actions at the graphical user interface level. While RPA has gained popularity for its cost-effective and timely automation of rule-based, well-structured tasks, its symbolic nature has inherent limitations when approaching more complex tasks currently performed by human agents. Machine learning concepts enabling intelligent RPA provide an opportunity to broaden the range of automatable tasks. In this paper, we conduct a literature review to explore the connections between RPA and machine learning and organize the joint concept intelligent RPA into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML integration and RPA-ML interaction. Together, they comprise eight dimensions: architecture and ecosystem, capabilities, data basis, intelligence level, and technical depth of integration as well as deployment environment, lifecycle phase, and user-robot relation.', 'abstract_zh': '基于机器学习的智能机器人流程自动化：架构、能力、数据基础、智能水平和技术集成深度分类研究', 'title_zh': '机器学习在智能机器人流程自动化中的新兴分类框架'}
{'arxiv_id': 'arXiv:2509.15536', 'title': 'SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models', 'authors': 'Sen Wang, Jingyi Tian, Le Wang, Zhimin Liao, Jiayi Li, Huaiyi Dong, Kun Xia, Sanping Zhou, Wei Tang, Hua Gang', 'link': 'https://arxiv.org/abs/2509.15536', 'abstract': "World models allow agents to simulate the consequences of actions in imagined environments for planning, control, and long-horizon decision-making. However, existing autoregressive world models struggle with visually coherent predictions due to disrupted spatial structure, inefficient decoding, and inadequate motion modeling. In response, we propose \\textbf{S}cale-wise \\textbf{A}utoregression with \\textbf{M}otion \\textbf{P}r\\textbf{O}mpt (\\textbf{SAMPO}), a hybrid framework that combines visual autoregressive modeling for intra-frame generation with causal modeling for next-frame generation. Specifically, SAMPO integrates temporal causal decoding with bidirectional spatial attention, which preserves spatial locality and supports parallel decoding within each scale. This design significantly enhances both temporal consistency and rollout efficiency. To further improve dynamic scene understanding, we devise an asymmetric multi-scale tokenizer that preserves spatial details in observed frames and extracts compact dynamic representations for future frames, optimizing both memory usage and model performance. Additionally, we introduce a trajectory-aware motion prompt module that injects spatiotemporal cues about object and robot trajectories, focusing attention on dynamic regions and improving temporal consistency and physical realism. Extensive experiments show that SAMPO achieves competitive performance in action-conditioned video prediction and model-based control, improving generation quality with 4.4$\\times$ faster inference. We also evaluate SAMPO's zero-shot generalization and scaling behavior, demonstrating its ability to generalize to unseen tasks and benefit from larger model sizes.", 'abstract_zh': 'Scales-Aware Autoregression with Motion Prompt for Enhancing Visual Consistency and Efficiency', 'title_zh': 'SAMPO：尺度aware自回归与运动提示生成的世界模型'}
{'arxiv_id': 'arXiv:2509.15513', 'title': 'KoopCast: Trajectory Forecasting via Koopman Operators', 'authors': 'Jungjin Lee, Jaeuk Shin, Gihwan Kim, Joonho Han, Insoon Yang', 'link': 'https://arxiv.org/abs/2509.15513', 'abstract': 'We present KoopCast, a lightweight yet efficient model for trajectory forecasting in general dynamic environments. Our approach leverages Koopman operator theory, which enables a linear representation of nonlinear dynamics by lifting trajectories into a higher-dimensional space. The framework follows a two-stage design: first, a probabilistic neural goal estimator predicts plausible long-term targets, specifying where to go; second, a Koopman operator-based refinement module incorporates intention and history into a nonlinear feature space, enabling linear prediction that dictates how to go. This dual structure not only ensures strong predictive accuracy but also inherits the favorable properties of linear operators while faithfully capturing nonlinear dynamics. As a result, our model offers three key advantages: (i) competitive accuracy, (ii) interpretability grounded in Koopman spectral theory, and (iii) low-latency deployment. We validate these benefits on ETH/UCY, the Waymo Open Motion Dataset, and nuScenes, which feature rich multi-agent interactions and map-constrained nonlinear motion. Across benchmarks, KoopCast consistently delivers high predictive accuracy together with mode-level interpretability and practical efficiency.', 'abstract_zh': 'KoopCast:一种轻量高效的动态环境轨迹预测模型', 'title_zh': 'KoopCast：基于柯普曼算子的轨迹预测'}
{'arxiv_id': 'arXiv:2509.15400', 'title': 'Exploring multimodal implicit behavior learning for vehicle navigation in simulated cities', 'authors': 'Eric Aislan Antonelo, Gustavo Claudio Karl Couto, Christian Möller', 'link': 'https://arxiv.org/abs/2509.15400', 'abstract': "Standard Behavior Cloning (BC) fails to learn multimodal driving decisions, where multiple valid actions exist for the same scenario. We explore Implicit Behavioral Cloning (IBC) with Energy-Based Models (EBMs) to better capture this multimodality. We propose Data-Augmented IBC (DA-IBC), which improves learning by perturbing expert actions to form the counterexamples of IBC training and using better initialization for derivative-free inference. Experiments in the CARLA simulator with Bird's-Eye View inputs demonstrate that DA-IBC outperforms standard IBC in urban driving tasks designed to evaluate multimodal behavior learning in a test environment. The learned energy landscapes are able to represent multimodal action distributions, which BC fails to achieve.", 'abstract_zh': '标准的行为克隆（BC）无法学习多模态驾驶决策，其中存在多个对同一场景有效的行动。我们探索使用能量基础模型（EBMs）的隐式行为克隆（IBC）以更好地捕捉这种多模态性。我们提出了数据增强隐式行为克隆（DA-IBC），通过扰动专家行动来形成IBC训练的反例，并使用更好的初始化进行无导数推断以提高学习效果。在CARLA模拟器中的鸟瞰视角输入下的实验表明，DA-IBC在评估测试环境中的多模态行为学习的城镇驾驶任务中优于标准的IBC。学习到的能量景观能够表示多模态行动分布，而BC无法实现这一点。', 'title_zh': '探索多模态隐含行为学习在模拟城市中的车辆导航'}
{'arxiv_id': 'arXiv:2509.15293', 'title': 'How Good are Foundation Models in Step-by-Step Embodied Reasoning?', 'authors': 'Dinura Dissanayake, Ahmed Heakl, Omkar Thawakar, Noor Ahsan, Ritesh Thawkar, Ketan More, Jean Lahoud, Rao Anwer, Hisham Cholakkal, Ivan Laptev, Fahad Shahbaz Khan, Salman Khan', 'link': 'https://arxiv.org/abs/2509.15293', 'abstract': 'Embodied agents operating in the physical world must make decisions that are not only effective but also safe, spatially coherent, and grounded in context. While recent advances in large multimodal models (LMMs) have shown promising capabilities in visual understanding and language generation, their ability to perform structured reasoning for real-world embodied tasks remains underexplored. In this work, we aim to understand how well foundation models can perform step-by-step reasoning in embodied environments. To this end, we propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to evaluate the reasoning capabilities of LMMs in complex embodied decision-making scenarios. Our benchmark spans a diverse set of tasks that require agents to interpret multimodal observations, reason about physical constraints and safety, and generate valid next actions in natural language. We present (i) a large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation framework that disentangles perceptual grounding from action reasoning, and (iii) empirical analysis of several leading LMMs under this setting. Our benchmark includes over 1.1k samples with detailed step-by-step reasoning across 10 tasks and 8 embodiments, covering three different robot types. Our results highlight both the potential and current limitations of LMMs in embodied reasoning, pointing towards key challenges and opportunities for future research in robot intelligence. Our data and code will be made publicly available.', 'abstract_zh': '基于身体代理在物理世界中的操作必须做出既有效又安全、空间上连贯且基于上下文的决策。尽管大型多模态模型在视觉理解与语言生成方面展现出有前景的能力，但它们在执行真实世界身体化任务的结构化推理方面的能力仍待探索。本文旨在理解基础模型在身体化环境中的逐步推理能力。为此，我们提出了基础模型身体化推理（FoMER）基准，该基准用于评估多模态模型在复杂身体化决策场景中的推理能力。我们的基准涵盖了多种任务，要求代理解读多模态观测结果、推理物理约束和安全性，并以自然语言生成有效的后续行动。我们展示了（i）大规模且精挑细选的身体化推理任务集，（ii）一种新的评估框架，用于分离感知接地与行动推理，以及（iii）在这一设置下几种领先多模态模型的实证分析。我们的基准包含超过1100个样本，涉及10个任务和8种不同的身体化代理，涵盖三种不同类型的机器人。我们的结果突显了多模态模型在身体化推理中的潜力与当前局限，并指出了未来机器人智能研究中的关键挑战与机遇。我们的数据和代码将公开发布。', 'title_zh': '大型预训练模型在分步具身推理任务中的表现如何？'}
