{'arxiv_id': 'arXiv:2502.18161', 'title': 'iTrash: Incentivized Token Rewards for Automated Sorting and Handling', 'authors': 'Pablo Ortega, Eduardo Castelló Ferrer', 'link': 'https://arxiv.org/abs/2502.18161', 'abstract': 'As robotic systems (RS) become more autonomous, they are becoming increasingly used in small spaces and offices to automate tasks such as cleaning, infrastructure maintenance, or resource management. In this paper, we propose iTrash, an intelligent trashcan that aims to improve recycling rates in small office spaces. For that, we ran a 5 day experiment and found that iTrash can produce an efficiency increase of more than 30% compared to traditional trashcans. The findings derived from this work, point to the fact that using iTrash not only increase recyclying rates, but also provides valuable data such as users behaviour or bin usage patterns, which cannot be taken from a normal trashcan. This information can be used to predict and optimize some tasks in these spaces. Finally, we explored the potential of using blockchain technology to create economic incentives for recycling, following a Save-as-you-Throw (SAYT) model.', 'abstract_zh': '随着机器人系统（RS）变得更加自主，它们在小空间和办公室中被用于自动化清洁、基础设施维护或资源管理等任务。本文提出了一种名为iTrash的智能垃圾桶，旨在提高小办公室空间内的回收率。我们进行了一项为期5天的实验，发现iTrash相较于传统垃圾桶可以提高效率超过30%。本文研究结果表明，使用iTrash不仅能提高回收率，还能提供有价值的数据，如用户行为或垃圾桶使用模式，这些信息无法从普通垃圾桶中获取。这些信息可用于预测和优化这些空间内的某些任务。最后，我们探讨了利用区块链技术创建基于“边扔边省”（Save-as-you-Throw，SAYT）模型的回收经济激励机制的潜在可能性。', 'title_zh': 'iTrash: 基于激励的代币奖励自动分类与处理'}
{'arxiv_id': 'arXiv:2502.18062', 'title': 'Ordered Genetic Algorithm for Entrance Dependent Vehicle Routing Problem in Farms', 'authors': 'Haotian Xu, Xiaohui Fan, Jialin Zhu, Qing Zhuo, Tao Zhang', 'link': 'https://arxiv.org/abs/2502.18062', 'abstract': 'Vehicle Routing Problems (VRP) are widely studied issues that play important roles in many production scenarios. We have noticed that in some practical scenarios of VRP, the size of cities and their entrances can significantly influence the optimization process. To address this, we have constructed the Entrance Dependent VRP (EDVRP) to describe such problems. We provide a mathematical formulation for the EDVRP in farms and propose an Ordered Genetic Algorithm (OGA) to solve it. The effectiveness of OGA is demonstrated through our experiments, which involve a multitude of randomly generated cases. The results indicate that OGA offers certain advantages compared to a random strategy baseline and a genetic algorithm without ordering. Furthermore, the novel operators introduced in this paper have been validated through ablation experiments, proving their effectiveness in enhancing the performance of the algorithm.', 'abstract_zh': '入口依赖车辆路线问题及其有序遗传算法求解', 'title_zh': '基于入口依赖的农场车辆路径问题的有序遗传算法'}
{'arxiv_id': 'arXiv:2502.18015', 'title': 'From planning to policy: distilling $\\texttt{Skill-RRT}$ for long-horizon prehensile and non-prehensile manipulation', 'authors': 'Haewon Jung, Donguk Lee, Haecheol Park, JunHyeop Kim, Beomjoon Kim', 'link': 'https://arxiv.org/abs/2502.18015', 'abstract': 'Current robots face challenges in manipulation tasks that require a long sequence of prehensile and non-prehensile skills. This involves handling contact-rich interactions and chaining multiple skills while considering their long-term consequences. This paper presents a framework that leverages imitation learning to distill a planning algorithm, capable of solving long-horizon problems but requiring extensive computation time, into a policy for efficient action inference. We introduce $\\texttt{Skill-RRT}$, an extension of the rapidly-exploring random tree (RRT) that incorporates skill applicability checks and intermediate object pose sampling for efficient long-horizon planning. To enable skill chaining, we propose $\\textit{connectors}$, goal-conditioned policies that transition between skills while minimizing object disturbance. Using lazy planning, connectors are selectively trained on relevant transitions, reducing the cost of training. High-quality demonstrations are generated with $\\texttt{Skill-RRT}$ and refined by a noise-based replay mechanism to ensure robust policy performance. The distilled policy, trained entirely in simulation, zero-shot transfer to the real world, and achieves over 80% success rates across three challenging manipulation tasks. In simulation, our approach outperforms the state-of-the-art skill-based reinforcement learning method, $\\texttt{MAPLE}$, and $\\texttt{Skill-RRT}$.', 'abstract_zh': '当前的机器人在执行需要长时间序列的抓持和非抓持技能的操作任务时面临挑战。这涉及到处理丰富的接触交互，并在考虑其长期后果的同时串联多种技能。本文提出了一种框架，利用模仿学习将能够解决长期问题但需要大量计算时间的规划算法提炼为一种高效的策略。我们引入了$\\texttt{Skill-RRT}$，这是一种扩展的快速扩展随机树（RRT），结合了技能适用性检查和中间物体姿态采样，以实现高效的长期规划。为了实现技能串联，我们提出了连接器（$\\textit{connectors}$），这是一种条件于目标的策略，可在最小化物体扰动的情况下在技能之间进行过渡。通过懒规划，连接器仅在相关过渡上进行训练，从而降低训练成本。高质量的演示由$\\texttt{Skill-RRT}$生成，并通过基于噪声的重放机制进一步优化，以确保策略性能的稳健。该提炼出的策略完全在仿真中训练，并实现了一种零样本的现实世界转移，在三项具有挑战性的操作任务中成功率超过80%。在仿真中，我们的方法在技能基强化学习方法$\\texttt{MAPLE}$和$\\texttt{Skill-RRT}$的基础上表现出色。', 'title_zh': '从规划到政策：提炼Skill-RRT用于长期 horizon 的抓取和非抓取操作 manipulation'}
{'arxiv_id': 'arXiv:2502.18064', 'title': 'HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers', 'authors': 'Yifeng Wang, Yi Zhao', 'link': 'https://arxiv.org/abs/2502.18064', 'abstract': 'Low-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.', 'abstract_zh': '低成本加速度计在现代社会中扮演着至关重要的角色，得益于其小型化、易于集成、可穿戴和大规模生产的优势，使其广泛应用于汽车系统、航空航天和可穿戴技术。然而，这种广泛使用的传感器面临着严重的精度和量程限制。为此，我们提出了一种精炼能量正则化和最优监督生成对抗网络（HEROS-GAN），该方法将低成本传感器信号转化为高精度等效信号，从而克服了低成本加速度计的精度和量程限制。由于缺乏帧级配对的低成本和高成本信号进行训练，我们提出了最优运输监督（OTS），利用最优运输理论来探索未配对数据之间的潜在一致性，从而最大化监督信息。此外，我们提出了一种调制拉普拉斯能量（MLE），向生成器注入适当的能量，促使生成器打破量程限制，增强局部变化并丰富信号细节。鉴于缺乏专用数据集，我们特别建立了包含数万个样本的低成本加速度计信号增强数据集（LASED），这是首个用于提高加速度计精度和量程的数据集，并发布在Github上。实验结果表明，单独使用OTS或MLE的GAN都能比之前最先进的信号增强方法优越一个数量级。结合OTS和MLE的HEROS-GAN取得了显著成果，加速度计的量程翻倍，信号噪声降低两个数量级，建立了加速度计信号处理的基准。', 'title_zh': 'HEROS-GAN：精炼能量正则化和最优监督生成对抗网络以提升低成本加速度计的精度和量程'}
{'arxiv_id': 'arXiv:2502.18425', 'title': 'PyEvalAI: AI-assisted evaluation of Jupyter Notebooks for immediate personalized feedback', 'authors': 'Nils Wandel, David Stotko, Alexander Schier, Reinhard Klein', 'link': 'https://arxiv.org/abs/2502.18425', 'abstract': 'Grading student assignments in STEM courses is a laborious and repetitive task for tutors, often requiring a week to assess an entire class. For students, this delay of feedback prevents iterating on incorrect solutions, hampers learning, and increases stress when exercise scores determine admission to the final exam. Recent advances in AI-assisted education, such as automated grading and tutoring systems, aim to address these challenges by providing immediate feedback and reducing grading workload. However, existing solutions often fall short due to privacy concerns, reliance on proprietary closed-source models, lack of support for combining Markdown, LaTeX and Python code, or excluding course tutors from the grading process. To overcome these limitations, we introduce PyEvalAI, an AI-assisted evaluation system, which automatically scores Jupyter notebooks using a combination of unit tests and a locally hosted language model to preserve privacy. Our approach is free, open-source, and ensures tutors maintain full control over the grading process. A case study demonstrates its effectiveness in improving feedback speed and grading efficiency for exercises in a university-level course on numerics.', 'abstract_zh': 'STEM课程作业评分是导师的一项耗费时间和重复的工作，通常评估一个班级需要一周时间。对于学生来说，这种反馈延迟阻碍了他们对错误解决方案的迭代，影响学习，并在练习成绩决定是否能参加最终考试时增加压力。近年来，辅助教育的AI技术，如自动化评分和辅导系统，旨在通过提供即时反馈和减少评分工作量来解决这些挑战。然而，现有的解决方案往往因为隐私问题、依赖专有封闭源模型、不支持结合Markdown、LaTeX和Python代码或不包括课程导师在评分过程中等原因而存在不足。为克服这些限制，我们引入了PyEvalAI，这是一种AI辅助评估系统，通过结合单元测试和本地托管的语言模型自动评分，以保护隐私。我们的方法是免费开源的，并确保导师能够完全控制评分过程。案例研究证明了其在大学数值课程中提高练习反馈速度和评分效率方面的有效性。', 'title_zh': 'PyEvalAI：AI辅助的Jupyter Notebook评估以提供即时个性化反馈'}
{'arxiv_id': 'arXiv:2502.18406', 'title': 'The Gradient of Algebraic Model Counting', 'authors': 'Jaron Maene, Luc De Raedt', 'link': 'https://arxiv.org/abs/2502.18406', 'abstract': 'Algebraic model counting unifies many inference tasks on logic formulas by exploiting semirings. Rather than focusing on inference, we consider learning, especially in statistical-relational and neurosymbolic AI, which combine logical, probabilistic and neural representations. Concretely, we show that the very same semiring perspective of algebraic model counting also applies to learning. This allows us to unify various learning algorithms by generalizing gradients and backpropagation to different semirings. Furthermore, we show how cancellation and ordering properties of a semiring can be exploited for more memory-efficient backpropagation. This allows us to obtain some interesting variations of state-of-the-art gradient-based optimisation methods for probabilistic logical models. We also discuss why algebraic model counting on tractable circuits does not lead to more efficient second-order optimization. Empirically, our algebraic backpropagation exhibits considerable speed-ups as compared to existing approaches.', 'abstract_zh': '代数模型计数通过利用半环统一了许多逻辑公式上的推理任务。不同于关注推理，我们探讨学习，特别是在统计关系和神经符号AI中，这些领域结合了逻辑、概率和神经表示。具体而言，我们展示了相同的半环视角也适用于学习。这使我们可以通过将梯度和反向传播一般化到不同的半环来统一各种学习算法。此外，我们展示了如何利用半环的取消和排序性质以更高效地进行反向传播。这使我们能够获得一些有趣的状态-of-the-art概率逻辑模型梯度优化方法的变体。我们还讨论了为什么在可处理电路上的代数模型计数不会导致更高效的二阶优化。实验上，我们的代数反向传播相比现有方法表现出显著的速度提升。', 'title_zh': '代数模型计数的梯度'}
{'arxiv_id': 'arXiv:2502.18315', 'title': 'GraphRank Pro+: Advancing Talent Analytics Through Knowledge Graphs and Sentiment-Enhanced Skill Profiling', 'authors': 'Sirisha Velampalli, Chandrashekar Muniyappa', 'link': 'https://arxiv.org/abs/2502.18315', 'abstract': 'The extraction of information from semi-structured text, such as resumes, has long been a challenge due to the diverse formatting styles and subjective content organization. Conventional solutions rely on specialized logic tailored for specific use cases. However, we propose a revolutionary approach leveraging structured Graphs, Natural Language Processing (NLP), and Deep Learning. By abstracting intricate logic into Graph structures, we transform raw data into a comprehensive Knowledge Graph. This innovative framework enables precise information extraction and sophisticated querying. We systematically construct dictionaries assigning skill weights, paving the way for nuanced talent analysis. Our system not only benefits job recruiters and curriculum designers but also empowers job seekers with targeted query-based filtering and ranking capabilities.', 'abstract_zh': '从半结构化文本中提取信息由于多样化的格式风格和主观的内容组织长期是一项挑战。传统解决方案依赖于针对特定用途定制的专业逻辑。然而，我们提出了一种革命性的方法，利用结构化图、自然语言处理（NLP）和深度学习。通过将复杂的逻辑抽象为图结构，我们将原始数据转换为全面的知识图谱。这一创新框架使精确的信息抽取和复杂的查询成为可能。我们系统地构建词典分配技能权重，为精细的人才分析铺平道路。该系统不仅有利于招聘人员和课程设计师，还为求职者提供了基于查询的过滤和排名能力。', 'title_zh': 'GraphRank Pro+: 通过知识图谱和情绪增强技能画像推动人才分析advance'}
{'arxiv_id': 'arXiv:2502.18060', 'title': 'Defining bias in AI-systems: Biased models are fair models', 'authors': 'Chiara Lindloff, Ingo Siegert', 'link': 'https://arxiv.org/abs/2502.18060', 'abstract': 'The debate around bias in AI systems is central to discussions on algorithmic fairness. However, the term bias often lacks a clear definition, despite frequently being contrasted with fairness, implying that an unbiased model is inherently fair. In this paper, we challenge this assumption and argue that a precise conceptualization of bias is necessary to effectively address fairness concerns. Rather than viewing bias as inherently negative or unfair, we highlight the importance of distinguishing between bias and discrimination. We further explore how this shift in focus can foster a more constructive discourse within academic debates on fairness in AI systems.', 'abstract_zh': 'AI系统中的偏差辩论是算法公平性讨论中的核心议题。然而，偏差一词往往缺乏明确的定义，尽管它常被与公平性对立使用，暗示无偏见的模型必然是公平的。本文挑战这一假设，认为需要对偏差进行精确的概念化以便有效应对公平性问题。我们强调区分偏差与歧视的重要性，而不是将偏差视为固有的负面或不公平。此外，我们探讨了这种焦点转移如何促进学术界对AI系统公平性的建设性讨论。', 'title_zh': '定义AI系统中的偏见：有偏见的模型即公平的模型'}
{'arxiv_id': 'arXiv:2502.17999', 'title': 'GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes', 'authors': 'Michele Fiori, Davide Mor, Gabriele Civitarese, Claudio Bettini', 'link': 'https://arxiv.org/abs/2502.17999', 'abstract': 'Sensor-based Human Activity Recognition (HAR) in smart home environments is crucial for several applications, especially in the healthcare domain. The majority of the existing approaches leverage deep learning models. While these approaches are effective, the rationale behind their outputs is opaque. Recently, eXplainable Artificial Intelligence (XAI) approaches emerged to provide intuitive explanations to the output of HAR models. To the best of our knowledge, these approaches leverage classic deep models like CNNs or RNNs. Recently, Graph Neural Networks (GNNs) proved to be effective for sensor-based HAR. However, existing approaches are not designed with explainability in mind. In this work, we propose the first explainable Graph Neural Network explicitly designed for smart home HAR. Our results on two public datasets show that this approach provides better explanations than state-of-the-art methods while also slightly improving the recognition rate.', 'abstract_zh': '基于传感器的智能家居环境中的人体活动识别（HAR）在多个应用中至关重要，尤其是在医疗健康领域。现有的大多数方法依赖深度学习模型。尽管这些方法有效，但它们的输出 rationale 难以理解。最近，可解释人工智能（XAI）方法出现，旨在提供直观的解释以供HAR模型使用。据我们所知，这些方法主要依赖于经典的深度模型，如CNN或RNN。最近，图形神经网络（GNN）证明了对于基于传感器的HAR的有效性。然而，现有的方法并未考虑可解释性。在本工作中，我们提出了第一个专门为智能家居HAR设计的可解释图形神经网络。我们在两个公共数据集上的结果表明，该方法不仅提供了比现有最佳方法更好的解释，还在一定程度上提高了识别率。', 'title_zh': 'GNN-XAR：一种可解释的家庭智能活动识别图神经网络'}
{'arxiv_id': 'arXiv:2502.17925', 'title': 'LeanProgress: Guiding Search for Neural Theorem Proving via Proof Progress Prediction', 'authors': 'Suozhi Huang, Peiyang Song, Robert Joseph George, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2502.17925', 'abstract': 'Mathematical reasoning remains a significant challenge for Large Language Models (LLMs) due to hallucinations. When combined with formal proof assistants like Lean, these hallucinations can be eliminated through rigorous verification, making theorem proving reliable. However, even with formal verification, LLMs still struggle with long proofs and complex mathematical formalizations. While Lean with LLMs offers valuable assistance with retrieving lemmas, generating tactics, or even complete proofs, it lacks a crucial capability: providing a sense of proof progress. This limitation particularly impacts the overall development efficiency in large formalization projects. We introduce LeanProgress, a method that predicts the progress in the proof. Training and evaluating our models made on a large corpus of Lean proofs from Lean Workbook Plus and Mathlib4 and how many steps remain to complete it, we employ data preprocessing and balancing techniques to handle the skewed distribution of proof lengths. Our experiments show that LeanProgress achieves an overall prediction accuracy of 75.1\\% in predicting the amount of progress and, hence, the remaining number of steps. When integrated into a best-first search framework using Reprover, our method shows a 3.8\\% improvement on Mathlib4 compared to baseline performances of 41.2\\%, particularly for longer proofs. These results demonstrate how proof progress prediction can enhance both automated and interactive theorem proving, enabling users to make more informed decisions about proof strategies.', 'abstract_zh': 'Large Language Models (LLMs)中的数学推理仍因幻觉而构成重大挑战。结合形式证明助手Lean后，这些幻觉可以通过严格的验证消除，从而使定理证明变得可靠。然而，即使经过形式验证，LLMs依然难以处理长证明和复杂的数学形式化。虽然Lean与LLMs结合可以为检索引理、生成策略或甚至完整证明提供有价值的帮助，但它缺乏一个关键能力：提供证明进度感。这一限制尤其影响大规模形式化项目的整体开发效率。我们介绍了LeanProgress，这是一种预测证明进度的方法。我们在Lean Workbook Plus和Mathlib4的大规模Lean证明语料库上训练和评估了我们的模型，预测剩余步骤的数量，并采用数据预处理和平衡技术来处理证明长度的偏斜分布。我们的实验结果显示，LeanProgress在预测证明进度和剩余步骤数量方面总体准确率为75.1%。将其集成到使用Reprover的最佳首先搜索框架中时，与基准性能41.2%相比，我们的方法在Mathlib4上显示出3.8%的改进，特别是在较长的证明中。这些结果表明，证明进度预测可以增强自动化的和交互式的定理证明，使用户能够就证明策略做出更加明智的决策。', 'title_zh': 'LeanProgress: 通过证明进度预测指导神经定理证明搜索'}
{'arxiv_id': 'arXiv:2502.17921', 'title': 'Unmasking Gender Bias in Recommendation Systems and Enhancing Category-Aware Fairness', 'authors': 'Tahsin Alamgir Kheya, Mohamed Reda Bouadjenek, Sunil Aryal', 'link': 'https://arxiv.org/abs/2502.17921', 'abstract': "Recommendation systems are now an integral part of our daily lives. We rely on them for tasks such as discovering new movies, finding friends on social media, and connecting job seekers with relevant opportunities. Given their vital role, we must ensure these recommendations are free from societal stereotypes. Therefore, evaluating and addressing such biases in recommendation systems is crucial. Previous work evaluating the fairness of recommended items fails to capture certain nuances as they mainly focus on comparing performance metrics for different sensitive groups. In this paper, we introduce a set of comprehensive metrics for quantifying gender bias in recommendations. Specifically, we show the importance of evaluating fairness on a more granular level, which can be achieved using our metrics to capture gender bias using categories of recommended items like genres for movies. Furthermore, we show that employing a category-aware fairness metric as a regularization term along with the main recommendation loss during training can help effectively minimize bias in the models' output. We experiment on three real-world datasets, using five baseline models alongside two popular fairness-aware models, to show the effectiveness of our metrics in evaluating gender bias. Our metrics help provide an enhanced insight into bias in recommended items compared to previous metrics. Additionally, our results demonstrate how incorporating our regularization term significantly improves the fairness in recommendations for different categories without substantial degradation in overall recommendation performance.", 'abstract_zh': '推荐系统中的性别偏见量化及其缓解方法', 'title_zh': '揭示推荐系统中的性别偏见并增强类别意识公平性'}
{'arxiv_id': 'arXiv:2502.17903', 'title': 'Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption', 'authors': 'Lars Krupp, Daniel Geißler, Paul Lukowicz, Jakob Karolus', 'link': 'https://arxiv.org/abs/2502.17903', 'abstract': 'Improvements in the area of large language models have shifted towards the construction of models capable of using external tools and interpreting their outputs. These so-called web agents have the ability to interact autonomously with the internet. This allows them to become powerful daily assistants handling time-consuming, repetitive tasks while supporting users in their daily activities. While web agent research is thriving, the sustainability aspect of this research direction remains largely unexplored. We provide an initial exploration of the energy and CO2 cost associated with web agents. Our results show how different philosophies in web agent creation can severely impact the associated expended energy. We highlight lacking transparency regarding the disclosure of model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. As such, our work advocates a change in thinking when evaluating web agents, warranting dedicated metrics for energy consumption and sustainability.', 'abstract_zh': '大型语言模型领域的改进已转向构建能够使用外部工具并解释其输出的模型。这些所谓的网络代理具备自主与互联网交互的能力。这使得它们能够成为处理耗时且重复的任务的强大日常助手，同时支持用户的日常活动。尽管网络代理研究蓬勃发展，但这一研究方向的可持续性方面仍鲜有探索。我们对网络代理相关的能源及二氧化碳成本进行了初步探索。结果显示，网络代理创建中不同的哲学观点可能导致显著的能源消耗差异。此外，我们指出，在估算能源消耗时，一些网络代理缺乏透明度，未披露模型参数和过程是一个限制因素。因此，我们的研究倡导在评估网络代理时改变思维方式，需要专门的能源消耗和可持续性指标。', 'title_zh': '面向可持续的网络代理：呼吁透明度和专门的能源消耗指标'}
{'arxiv_id': 'arXiv:2502.17840', 'title': 'A Combinatorial Identities Benchmark for Theorem Proving via Automated Theorem Generation', 'authors': 'Beibei Xiong, Hangyu Lv, Haojia Shan, Jianlin Wang, Zhengfeng Yang, Lihong Zhi', 'link': 'https://arxiv.org/abs/2502.17840', 'abstract': 'Large language models (LLMs) have significantly advanced formal theorem proving, yet the scarcity of high-quality training data constrains their capabilities in complex mathematical domains. Combinatorics, a cornerstone of mathematics, provides essential tools for analyzing discrete structures and solving optimization problems. However, its inherent complexity makes it particularly challenging for automated theorem proving (ATP) for combinatorial identities. To address this, we manually construct LeanComb, combinatorial identities benchmark in Lean, which is, to our knowledge, the first formalized theorem proving benchmark built for combinatorial identities. We develop an Automated Theorem Generator for Combinatorial Identities, ATG4CI, which combines candidate tactics suggested by a self-improving large language model with a Reinforcement Learning Tree Search approach for tactic prediction. By utilizing ATG4CI, we generate a LeanComb-Enhanced dataset comprising 260K combinatorial identities theorems, each with a complete formal proof in Lean, and experimental evaluations demonstrate that models trained on this dataset can generate more effective tactics, thereby improving success rates in automated theorem proving for combinatorial identities.', 'abstract_zh': '大规模语言模型（LLMs）在正式定理证明方面取得了显著进展，但高质量训练数据的稀缺限制了其在复杂数学领域的能力。组合数学作为数学的基础，提供了分析离散结构和解决优化问题的重要工具。然而，其固有的复杂性使其特别适合组合恒等式的自动定理证明（ATP）具有挑战性。为解决这一问题，我们手动构建了LeanComb，这是一个用于组合恒等式的Lean基准测试集，据我们所知，这是首个专门构建用于组合恒等式的形式化定理证明基准测试集。我们开发了一种组合恒等式自动定理生成器ATG4CI，该生成器结合了一种自我提升的大规模语言模型建议的候选策略和基于强化学习树搜索的方法进行策略预测。利用ATG4CI，我们生成了包含26万条组合恒等式定理的LeanComb增强数据集，每条定理都有完整的Lean形式证明，并且实验评估表明，在此数据集上训练的模型可以生成更有效的策略，从而提高组合恒等式自动定理证明的成功率。', 'title_zh': '一个组合恒等式基准测试集，用于通过自动定理生成进行定理证明。'}
{'arxiv_id': 'arXiv:2502.17643', 'title': 'Socratic: Enhancing Human Teamwork via AI-enabled Coaching', 'authors': 'Sangwon Seo, Bing Han, Rayan E. Harari, Roger D. Dias, Marco A. Zenati, Eduardo Salas, Vaibhav Unhelkar', 'link': 'https://arxiv.org/abs/2502.17643', 'abstract': "Coaches are vital for effective collaboration, but cost and resource constraints often limit their availability during real-world tasks. This limitation poses serious challenges in life-critical domains that rely on effective teamwork, such as healthcare and disaster response. To address this gap, we propose and realize an innovative application of AI: task-time team coaching. Specifically, we introduce Socratic, a novel AI system that complements human coaches by providing real-time guidance during task execution. Socratic monitors team behavior, detects misalignments in team members' shared understanding, and delivers automated interventions to improve team performance. We validated Socratic through two human subject experiments involving dyadic collaboration. The results demonstrate that the system significantly enhances team performance with minimal interventions. Participants also perceived Socratic as helpful and trustworthy, supporting its potential for adoption. Our findings also suggest promising directions both for AI research and its practical applications to enhance human teamwork.", 'abstract_zh': '教练对于有效的协作至关重要，但在现实任务中，成本和资源限制往往限制了其可用性。这种限制在依赖有效团队合作的生命攸关领域（如医疗保健和灾难响应）提出了严峻挑战。为解决这一问题，我们提出并实现了人工智能的一种创新应用：任务时间团队辅导。具体而言，我们引入了Socratic这一全新的人工智能系统，通过在任务执行过程中提供实时指导来补充人类教练。Socratic监控团队行为，检测团队成员之间共享理解的偏差，并通过自动化干预提高团队绩效。我们通过两项涉及双人协作的人类受控实验验证了Socratic的效果。结果表明，系统在尽量减少干预的情况下显著提升了团队绩效。参与者还认为Socratic非常有用和可信，支持其潜在的广泛应用。我们的研究结果还为人工智能研究及其增强人类团队合作的实际应用指出了积极的方向。', 'title_zh': 'Socratic：通过AI赋能的教练技术提升人类团队协作能力'}
{'arxiv_id': 'arXiv:2502.18462', 'title': 'Scalable Equilibrium Sampling with Sequential Boltzmann Generators', 'authors': 'Charlie B. Tan, Avishek Joey Bose, Chen Lin, Leon Klein, Michael M. Bronstein, Alexander Tong', 'link': 'https://arxiv.org/abs/2502.18462', 'abstract': 'Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann generators tackle this problem by pairing powerful normalizing flows with importance sampling to obtain statistically independent samples under the target distribution. In this paper, we extend the Boltzmann generator framework and introduce Sequential Boltzmann generators (SBG) with two key improvements. The first is a highly efficient non-equivariant Transformer-based normalizing flow operating directly on all-atom Cartesian coordinates. In contrast to equivariant continuous flows of prior methods, we leverage exactly invertible non-equivariant architectures which are highly efficient both during sample generation and likelihood computation. As a result, this unlocks more sophisticated inference strategies beyond standard importance sampling. More precisely, as a second key improvement we perform inference-time scaling of flow samples using annealed Langevin dynamics which transports samples toward the target distribution leading to lower variance (annealed) importance weights which enable higher fidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art performance w.r.t. all metrics on molecular systems, demonstrating the first equilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides that were so far intractable for prior Boltzmann generators.', 'abstract_zh': '在统计物理中，热力学平衡下的分子状态可扩展采样一直是长期挑战。波尔兹曼生成器通过将强大的归一化流动与重要性采样相结合，获得目标分布下的统计独立样本来应对这一问题。在本文中，我们扩展了波尔兹曼生成器框架，并引入了顺序波尔兹曼生成器（SBG），其中包括两个关键改进。首先，SBG采用高效的高度非等变Transformer基归一化流动，直接作用于全原子笛卡尔坐标。与先前方法中的等变连续流动相比，我们利用完全可逆的高度非等变架构，在样本生成和概率计算中均非常高效。这使得可以使用更复杂的推理策略，而不仅仅局限于标准的重要采样。其次，SBG在推理阶段利用退火拉梅尔动力学对流动样本进行缩放，将样本向目标分布转移，从而获得较低方差（退火）重要权重，使得顺序蒙特卡洛方法能够实现更高质量的重采样。SBG在分子系统上的所有指标上均实现了最佳性能，展示了首次在笛卡尔坐标中对三肽、四肽和六肽进行热力学平衡采样，这些肽对于先前的波尔兹曼生成器来说此前是无法处理的。', 'title_zh': '可扩展的平衡采样方法：顺序玻尔兹曼生成器'}
{'arxiv_id': 'arXiv:2502.18438', 'title': 'ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies', 'authors': 'Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio', 'link': 'https://arxiv.org/abs/2502.18438', 'abstract': "In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories. It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world. We conducted several experiments using ToMCAT in a simulated cooking domain. Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance. We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them.", 'abstract_zh': '基于理论共情的多智能体合作框架：ToMCAT', 'title_zh': 'ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies-solving合作代理的理论心智通过多代理扩散策略的ToMCAT'}
{'arxiv_id': 'arXiv:2502.18412', 'title': 'Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data', 'authors': 'Paula Santos', 'link': 'https://arxiv.org/abs/2502.18412', 'abstract': 'This study presents a comparative evaluation of a Variational Autoencoder (VAE) enhanced with Minimum Description Length (MDL) regularization against a Standard Autoencoder for reconstructing high-dimensional gynecological data. The MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE) and more structured latent representations, driven by effective KL divergence regularization. Statistical analyses confirm these performance improvements are significant. Furthermore, the MDL-VAE shows consistent training and validation losses and achieves efficient inference times, underscoring its robustness and practical viability. Our findings suggest that incorporating MDL principles into VAE architectures can substantially improve data reconstruction and generalization, making it a promising approach for advanced applications in healthcare data modeling and analysis.', 'abstract_zh': '本研究对Minimum Description Length (MDL) 正则化增强的变分自编码器（MDL-VAE）与标准自编码器在重建高维妇科数据方面的性能进行了比较评估。统计分析证实了这些性能改进具有显著性。此外，MDL-VAE表现出一致的训练和验证损失，并实现了高效的推理时间，凸显了其鲁棒性和实际可行性。我们的研究结果表明，将MDL原理融入到变分自编码器架构中可以显著提高数据重建和泛化能力，使其成为高级健康数据分析应用的有前途的方法。', 'title_zh': 'MDL-VAE与标准VAE在202年妇科数据上的比较分析'}
{'arxiv_id': 'arXiv:2502.18410', 'title': 'TSKANMixer: Kolmogorov-Arnold Networks with MLP-Mixer Model for Time Series Forecasting', 'authors': 'Young-Chae Hong, Bei Xiao, Yangho Chen', 'link': 'https://arxiv.org/abs/2502.18410', 'abstract': 'Time series forecasting has long been a focus of research across diverse fields, including economics, energy, healthcare, and traffic management. Recent works have introduced innovative architectures for time series models, such as the Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs) to enhance prediction accuracy by effectively capturing both spatial and temporal dependencies within the data. In this paper, we investigate the capabilities of the Kolmogorov-Arnold Networks (KANs) for time-series forecasting by modifying TSMixer with a KAN layer (TSKANMixer). Experimental results demonstrate that TSKANMixer tends to improve prediction accuracy over the original TSMixer across multiple datasets, ranking among the top-performing models compared to other time series approaches. Our results show that the KANs are promising alternatives to improve the performance of time series forecasting by replacing or extending traditional MLPs.', 'abstract_zh': '时间序列预测一直是跨经济学、能源、医疗保健和交通管理等多元领域的研究重点。最近的研究引入了时间序列模型的新架构，如Time-Series Mixer (TSMixer)，其通过多层感知机（MLPs）有效捕捉数据中的时空依赖性以提高预测准确性。本文通过将Kolmogorov-Arnold Networks (KANs)层整合到TSMixer中，即TSKANMixer，来探究KANs在时间序列预测中的能力。实验结果表明，TSKANMixer在多个数据集上往往能提高预测准确性，并与其他时间序列方法相比名列前茅。我们的结果表明，KANs是改进时间序列预测性能的有前途的替代或扩展传统MLPs的选择。', 'title_zh': 'TSKANMixer: 拟 Kolmogorov-Arnold 网络与 MLP-Mixer 模型在时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2502.18357', 'title': 'Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation', 'authors': 'Jessica He, Stephanie Houde, Justin D. Weisz', 'link': 'https://arxiv.org/abs/2502.18357', 'abstract': "AI systems powered by large language models can act as capable assistants for writing and editing. In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s). One question that arises in these scenarios is the extent to which AI should be credited for its contributions. We examined knowledge workers' views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative. Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions. Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations. Our results motivate and inform new approaches for crediting AI contributions to co-created work.", 'abstract_zh': '由大型语言模型驱动的AI系统可以作为写作和编辑的有能力的助手。在这些任务中，AI系统作为共创伙伴，在其人类同伴的陪伴下，对正在创造的作品做出新颖的贡献。这些场景中出现的一个问题是，AI应为其贡献获得多大程度的信用。我们通过调查研究（N=155）考察了知识工作者对归因的看法，并发现他们在不同类型的贡献、数量和主动性方面分配了不同的信用程度。与人类同伴相比，我们观察到一个一致的模式：AI在同等贡献中获得的信用较少。参与者认为披露AI的参与很重要，并使用多种标准来做出归因判断，包括贡献质量、个人价值观和技术考虑。我们的研究结果激励并指导了新的方法，用于承认共同创造工作中AI的贡献。', 'title_zh': '哪些贡献值得 credited？人类与AI协同创作中的归因感知'}
{'arxiv_id': 'arXiv:2502.18298', 'title': 'Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach', 'authors': 'Taha Ahmadi Pargo, Mohsen Akbarpour Shirazi, Dawud Fadai', 'link': 'https://arxiv.org/abs/2502.18298', 'abstract': "Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries. On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss. One of these technologies is the Internet of Things (IoT). Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems. Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems. In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval. The designed system comprises sensors, a central agent, and irrigation nodes. These agents follow defined rules to maintain soil moisture at a desired level cooperatively. For system simulation, a hybrid agent-based and system dynamics model was designed. In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach. The proposed model, was implemented in AnyLogic computer simulation software. Utilizing the simulation model, irrigation rules were examined. The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed. Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests. Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time.", 'abstract_zh': '基于普罗米修斯本体导向软件工程方法的智能灌溉系统设计与分析', 'title_zh': '基于混合基于代理和系统动力学方法的智能高效物联网灌溉系统设计'}
{'arxiv_id': 'arXiv:2502.18296', 'title': 'Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies', 'authors': 'James C. A. Main, Mickael Randour', 'link': 'https://arxiv.org/abs/2502.18296', 'abstract': 'We consider multi-dimensional payoff functions in Markov decision processes, and ask whether a given expected payoff vector can be achieved or not. In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.\nWe study the structure of the set of expected payoff vectors of all strategies given a multi-dimensional payoff function and its consequences regarding randomisation requirements for strategies. In particular, we prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision. Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies.', 'abstract_zh': '我们在马尔可夫决策过程中的多维收益函数下考虑给定的期望收益向量能否被实现的问题，并证明纯策略（即不采用随机化）通常不足以解决问题。我们研究给定多维收益函数下的所有策略的期望收益向量集的结构及其对策略中随机化要求的影响。特别地，我们证明对于任何收益，在所有策略下其期望值都是有定义的，只需混合有限个纯策略即可在任意精度上近似任何期望收益向量。进一步地，对于任何在所有策略下期望收益都有限的收益，只需混合有限个策略即可精确获得任何期望收益。', 'title_zh': '用有限的原料调出任何鸡尾酒：多目标MDPs中收益集的结构及其对随机化策略的影响'}
{'arxiv_id': 'arXiv:2502.18225', 'title': 'Liver Cirrhosis Stage Estimation from MRI with Deep Learning', 'authors': 'Jun Zeng, Debesh Jha, Ertugrul Aktas, Elif Keles, Alpay Medetalibeyoglu, Matthew Antalek, Amir A. Borhani, Daniela P. Ladner, Gorkem Durak, Ulas Bagci', 'link': 'https://arxiv.org/abs/2502.18225', 'abstract': 'We present an end-to-end deep learning framework for automated liver cirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe scarring (fibrosis) of the liver and a common endpoint of various chronic liver diseases. Early diagnosis is vital to prevent complications such as decompensation and cancer, which significantly decreases life expectancy. However, diagnosing cirrhosis in its early stages is challenging, and patients often present with life-threatening complications. Our approach integrates multi-scale feature learning with sequence-specific attention mechanisms to capture subtle tissue variations across cirrhosis progression stages. Using CirrMRI600+, a large-scale publicly available dataset of 628 high-resolution MRI scans from 339 patients, we demonstrate state-of-the-art performance in three-stage cirrhosis classification. Our best model achieves 72.8% accuracy on T1W and 63.8% on T2W sequences, significantly outperforming traditional radiomics-based approaches. Through extensive ablation studies, we show that our architecture effectively learns stage-specific imaging biomarkers. We establish new benchmarks for automated cirrhosis staging and provide insights for developing clinically applicable deep learning systems. The source code will be available at this https URL.', 'abstract_zh': '一种用于多序列MRI自动化肝硬化阶段估计的端到端深度学习框架', 'title_zh': '基于深度学习的肝脏 cirrhosis 阶段从 MRI 估计'}
{'arxiv_id': 'arXiv:2502.18218', 'title': 'FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records', 'authors': 'Bingke Zhu, Xiaoxiao Wang, Minghui Jia, Yihan Tao, Xiao Kong, Ali Luo, Yingying Chen, Ming Tang, Jinqiao Wang', 'link': 'https://arxiv.org/abs/2502.18218', 'abstract': 'Stellar flare events are critical observational samples for astronomical research; however, recorded flare events remain limited. Stellar flare forecasting can provide additional flare event samples to support research efforts. Despite this potential, no specialized models for stellar flare forecasting have been proposed to date. In this paper, we present extensive experimental evidence demonstrating that both stellar physical properties and historical flare records are valuable inputs for flare forecasting tasks. We then introduce FLARE (Forecasting Light-curve-based Astronomical Records via features Ensemble), the first-of-its-kind large model specifically designed for stellar flare forecasting. FLARE integrates stellar physical properties and historical flare records through a novel Soft Prompt Module and Residual Record Fusion Module. Our experiments on the publicly available Kepler light curve dataset demonstrate that FLARE achieves superior performance compared to other methods across all evaluation metrics. Finally, we validate the forecast capability of our model through a comprehensive case study.', 'abstract_zh': '恒星耀斑事件是天文学研究中重要的观测样本；然而，记录的耀斑事件仍有限。恒星耀斑预测可以提供额外的耀斑事件样本以支持研究工作。尽管存在这种潜力，但目前尚未提出专门用于恒星耀斑预测的模型。本文提供了广泛实验证据，证明恒星物理性质和历史耀斑记录都是耀斑预测任务的重要输入。我们随后介绍了FLARE（通过特征集成预测基于光曲线的天文记录），这是首个专门设计用于恒星耀斑预测的大型模型。FLARE通过新颖的Soft Prompt Module和残差记录融合模块整合恒星物理性质和历史耀斑记录。我们在公开可用的Kepler光曲线数据集上的实验表明，FLARE在所有评估指标中均表现出优越性能。最后，我们通过全面的案例研究验证了我们模型的预测能力。', 'title_zh': 'FLARE：基于恒星物理性质和历史记录的耀斑预测框架'}
{'arxiv_id': 'arXiv:2502.18202', 'title': 'DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches', 'authors': 'Atik Faysal, Mohammad Rostami, Taha Boushine, Reihaneh Gh. Roshan, Huaxia Wang, Nikhil Muralidhar', 'link': 'https://arxiv.org/abs/2502.18202', 'abstract': 'We introduce DenoMAE2.0, an enhanced denoising masked autoencoder that integrates a local patch classification objective alongside traditional reconstruction loss to improve representation learning and robustness. Unlike conventional Masked Autoencoders (MAE), which focus solely on reconstructing missing inputs, DenoMAE2.0 introduces position-aware classification of unmasked patches, enabling the model to capture fine-grained local features while maintaining global coherence. This dual-objective approach is particularly beneficial in semi-supervised learning for wireless communication, where high noise levels and data scarcity pose significant challenges. We conduct extensive experiments on modulation signal classification across a wide range of signal-to-noise ratios (SNRs), from extremely low to moderately high conditions and in a low data regime. Our results demonstrate that DenoMAE2.0 surpasses its predecessor, Deno-MAE, and other baselines in both denoising quality and downstream classification accuracy. DenoMAE2.0 achieves a 1.1% improvement over DenoMAE on our dataset and 11.83%, 16.55% significant improved accuracy gains on the RadioML benchmark, over DenoMAE, for constellation diagram classification of modulation signals.', 'abstract_zh': 'DenoMAE2.0: 增强的去噪掩蔽自编码器及其在无线通信半监督学习中的应用', 'title_zh': 'DenoMAE2.0: 通过分类局部 patches 提高去噪掩蔽自编码器性能'}
{'arxiv_id': 'arXiv:2502.18176', 'title': 'CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification', 'authors': 'Mingkun Zhang, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2502.18176', 'abstract': "In this paper, we aim to build an adversarially robust zero-shot image classifier. We ground our work on CLIP, a vision-language pre-trained encoder model that can perform zero-shot classification by matching an image with text prompts ``a photo of a <class-name>.''. Purification is the path we choose since it does not require adversarial training on specific attack types and thus can cope with any foreseen attacks. We then formulate purification risk as the KL divergence between the joint distributions of the purification process of denoising the adversarial samples and the attack process of adding perturbations to benign samples, through bidirectional Stochastic Differential Equations (SDEs). The final derived results inspire us to explore purification in the multi-modal latent space of CLIP. We propose two variants for our CLIPure approach: CLIPure-Diff which models the likelihood of images' latent vectors with the DiffusionPrior module in DaLLE-2 (modeling the generation process of CLIP's latent vectors), and CLIPure-Cos which models the likelihood with the cosine similarity between the embeddings of an image and ``a photo of a.''. As far as we know, CLIPure is the first purification method in multi-modal latent space and CLIPure-Cos is the first purification method that is not based on generative models, which substantially improves defense efficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13 datasets that previous CLIP-based defense methods used for evaluating zero-shot classification robustness. Results show that CLIPure boosts the SOTA robustness by a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on ImageNet, and 108% relative improvements of average robustness on the 13 datasets over previous SOTA. The code is available at this https URL.", 'abstract_zh': '基于CLIP的多模态-latent空间对抗鲁棒零样本图像分类方法CLIPure', 'title_zh': 'CLIPure：通过CLIP在潜在空间中净化实现对抗稳健的零样本分类'}
{'arxiv_id': 'arXiv:2502.18153', 'title': 'SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation', 'authors': 'Dahun Shin, Dongyeop Lee, Jinseok Chung, Namhoon Lee', 'link': 'https://arxiv.org/abs/2502.18153', 'abstract': 'Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.', 'abstract_zh': '逼近二次优化方法在泛化能力上往往逊于一阶方法。本文从损失景观的角度探讨这一问题，发现现有的二次优化方法倾向于收敛到比SGD更尖锐的极小值。为此，我们提出Sassha，一种新型的二次优化方法，旨在通过显式地减少解的尖锐性来增强泛化能力，同时在优化轨迹中稳定近似海塞矩阵的计算。实际上，该尖锐性最小化方案还设计了懒惰的海塞矩阵更新机制，以确保效率和平坦性。为了验证其效果，我们在一系列标准深度学习实验中测试了Sassha，结果显示其泛化性能与甚至优于其他方法。我们提供了包括收敛性、鲁棒性、稳定性、效率和成本在内的全面分析。', 'title_zh': 'SASSHA: 尖锐感知自适应二阶优化与稳定海森矩阵逼近'}
{'arxiv_id': 'arXiv:2502.18137', 'title': 'SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference', 'authors': 'Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen', 'link': 'https://arxiv.org/abs/2502.18137', 'abstract': 'An efficient attention implementation is essential for large models due to its quadratic time complexity. Fortunately, attention commonly exhibits sparsity, i.e., many values in the attention map are near zero, allowing for the omission of corresponding computations. Many studies have utilized the sparse pattern to accelerate attention. However, most existing works focus on optimizing attention within specific models by exploiting certain sparse patterns of the attention map. A universal sparse attention that guarantees both the speedup and end-to-end performance of diverse models remains elusive. In this paper, we propose SpargeAttn, a universal sparse and quantized attention for any model. Our method uses a two-stage online filter: in the first stage, we rapidly and accurately predict the attention map, enabling the skip of some matrix multiplications in attention. In the second stage, we design an online softmax-aware filter that incurs no extra overhead and further skips some matrix multiplications. Experiments show that our method significantly accelerates diverse models, including language, image, and video generation, without sacrificing end-to-end metrics. The codes are available at this https URL.', 'abstract_zh': '一种高效的注意力实现对于大型模型至关重要，因为其时间复杂度为二次。幸运的是，注意力通常表现出稀疏性，即注意力图中的许多值接近零，允许省略相应的计算。许多研究利用稀疏性来加速注意力机制。然而，大多数现有工作集中在通过利用注意力图的特定稀疏模式来优化特定模型的注意力机制上。一个同时保证多种模型加速和端到端性能的通用稀疏注意力机制仍然难以捉摸。本文提出了一种适用于任何模型的通用稀疏和量化注意力机制SpargeAttn。我们的方法使用两阶段在线过滤器：第一阶段我们快速准确地预测注意力图，从而省略一些矩阵乘法；第二阶段我们设计了一种在线Softmax感知过滤器，无需额外开销并进一步省略一些矩阵乘法。实验表明，我们的方法能够在不牺牲端到端指标的情况下显著加速包括语言、图像和视频生成等多种模型。源代码可在以下网址获取。', 'title_zh': 'SpargeAttn: 准确的稀疏注意力加速任意模型推断'}
{'arxiv_id': 'arXiv:2502.18122', 'title': 'EU-Nets: Enhanced, Explainable and Parsimonious U-Nets', 'authors': 'B. Sun, P. Liò', 'link': 'https://arxiv.org/abs/2502.18122', 'abstract': 'In this study, we propose MHEX+, a framework adaptable to any U-Net architecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets, which enhance explainability and uncertainty estimation, addressing the limitations of traditional U-Net models while improving performance and stability. A key innovation is the Equivalent Convolutional Kernel, which unifies consecutive convolutional layers, boosting interpretability. For uncertainty estimation, we propose the collaboration gradient approach, measuring gradient consistency across decoder layers. Notably, EU-Nets achieve an average accuracy improvement of 1.389\\% and a variance reduction of 0.83\\% across all networks and datasets in our experiments, requiring fewer than 0.1M parameters.', 'abstract_zh': '本研究提出MHEX+，一种适用于任何U-Net架构的框架。基于MHEX+，我们引入了增强可解释性和不确定性估计的新型U-Net变体EU-Nets，克服了传统U-Net模型的局限性，同时提高了性能和稳定性。关键创新是等价卷积核，它统一了连续卷积层，提升了解释性。对于不确定性估计，我们提出了一种合作梯度方法，衡量解码器层之间的梯度一致性。值得注意的是，EU-Nets在我们的实验中实现了所有网络和数据集的平均准确性提升1.389%和方差减少0.83%，同时所需参数少于0.1M。', 'title_zh': 'EU-网络：增强、可解释且简洁的U-网络'}
{'arxiv_id': 'arXiv:2502.18097', 'title': 'The Built-In Robustness of Decentralized Federated Averaging to Bad Data', 'authors': 'Samuele Sabella, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti', 'link': 'https://arxiv.org/abs/2502.18097', 'abstract': 'Decentralized federated learning (DFL) enables devices to collaboratively train models over complex network topologies without relying on a central controller. In this setting, local data remains private, but its quality and quantity can vary significantly across nodes. The extent to which a fully decentralized system is vulnerable to poor-quality or corrupted data remains unclear, but several factors could contribute to potential risks. Without a central authority, there can be no unified mechanism to detect or correct errors, and each node operates with a localized view of the data distribution, making it difficult for the node to assess whether its perspective aligns with the true distribution. Moreover, models trained on low-quality data can propagate through the network, amplifying errors. To explore the impact of low-quality data on DFL, we simulate two scenarios with degraded data quality -- one where the corrupted data is evenly distributed in a subset of nodes and one where it is concentrated on a single node -- using a decentralized implementation of FedAvg. Our results reveal that averaging-based decentralized learning is remarkably robust to localized bad data, even when the corrupted data resides in the most influential nodes of the network. Counterintuitively, this robustness is further enhanced when the corrupted data is concentrated on a single node, regardless of its centrality in the communication network topology. This phenomenon is explained by the averaging process, which ensures that no single node -- however central -- can disproportionately influence the overall learning process.', 'abstract_zh': '去中心化的联邦学习（DFL） enables 设备在无需依赖中心控制器的情况下，通过复杂网络拓扑协作训练模型。在这种设置中，本地数据保持私有，但其质量和数量在节点间可以有显著差异。完全去中心化系统受低质量或被篡改数据的影响程度仍然不清楚，但有几个因素可能增加潜在风险。缺乏中央权威机构，就没有统一机制来检测或纠正错误，每个节点仅拥有局部数据分布视图，难以评估其视角是否与真实分布一致。此外，基于低质量数据训练的模型可以通过网络传播，放大错误。为了探索低质量数据对 DFL 的影响，我们使用去中心化的 FedAvg 实现模拟了两种数据质量降级场景——一种是被篡改数据均匀分布在一个子集节点中，另一种是被篡改数据集中在单个节点中。结果显示，基于平均值的去中心化学习对局部劣质数据表现出惊人的鲁棒性，即使被篡改数据位于网络中最具影响力的节点中也是如此。令人意外的是，当被篡改数据集中在单个节点中时，这种鲁棒性反而增强了，无论该节点在通信网络拓扑中的中心性如何。这种现象可通过平均过程解释，该过程确保没有单一节点——无论其多么中心——能够不成比例地影响整体学习过程。', 'title_zh': '内置鲁棒性的去中心化联邦平均对不良数据的抵抗能力'}
{'arxiv_id': 'arXiv:2502.18026', 'title': 'ExPath: Towards Explaining Targeted Pathways for Biological Knowledge Bases', 'authors': 'Rikuto Kotoge, Ziwei Yang, Zheng Chen, Yushun Dong, Yasuko Matsubara, Jimeng Sun, Yasushi Sakurai', 'link': 'https://arxiv.org/abs/2502.18026', 'abstract': 'Biological knowledge bases provide systemically functional pathways of cells or organisms in terms of molecular interaction. However, recognizing more targeted pathways, particularly when incorporating wet-lab experimental data, remains challenging and typically requires downstream biological analyses and expertise. In this paper, we frame this challenge as a solvable graph learning and explaining task and propose a novel pathway inference framework, ExPath, that explicitly integrates experimental data, specifically amino acid sequences (AA-seqs), to classify various graphs (bio-networks) in biological databases. The links (representing pathways) that contribute more to classification can be considered as targeted pathways. Technically, ExPath comprises three components: (1) a large protein language model (pLM) that encodes and embeds AA-seqs into graph, overcoming traditional obstacles in processing AA-seq data, such as BLAST; (2) PathMamba, a hybrid architecture combining graph neural networks (GNNs) with state-space sequence modeling (Mamba) to capture both local interactions and global pathway-level dependencies; and (3) PathExplainer, a subgraph learning module that identifies functionally critical nodes and edges through trainable pathway masks. We also propose ML-oriented biological evaluations and a new metric. The experiments involving 301 bio-networks evaluations demonstrate that pathways inferred by ExPath maintain biological meaningfulness. We will publicly release curated 301 bio-network data soon.', 'abstract_zh': '生物知识库提供了基于分子相互作用的细胞或 organism 的系统功能路径。然而，在结合湿实验室实验数据的情况下识别更具针对性的路径仍具有挑战性，通常需要下游生物学分析和专业知识。本文将这一挑战视为可解决的图学习和解释任务，并提出了一种新的路径推理框架 ExPath，该框架明确整合了实验数据，特别是氨基酸序列（AA-seqs），以对生物数据库中的各种图（生物网络）进行分类。对分类贡献更大的连接可以视为针对性路径。技术上，ExPath 包含三个组成部分：（1）一个大规模蛋白质语言模型（pLM），它将氨基酸序列编码并嵌入图中，克服了处理氨基酸序列数据的传统障碍，如 BLAST；（2）PathMamba，这是一种将图神经网络（GNNs）与状态空间序列建模（Mamba）结合的混合架构，用于捕获局部相互作用和全局路径级依赖性；（3）PathExplainer，这是一种子图学习模块，通过可训练的路径掩码识别功能关键节点和边。我们还提出了面向机器学习的生物评价和一个新的度量标准。涉及 301 个生物网络的实验表明，ExPath 推断出的路径具有生物学意义。我们很快将公开发布 301 个生物网络数据。', 'title_zh': 'ExPath：面向生物知识库的路径解释方法研究'}
{'arxiv_id': 'arXiv:2502.18017', 'title': 'ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents', 'authors': 'Qiuchen Wang, Ruixue Ding, Zehui Chen, Weiqi Wu, Shihang Wang, Pengjun Xie, Feng Zhao', 'link': 'https://arxiv.org/abs/2502.18017', 'abstract': "Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model's reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark.", 'abstract_zh': '理解视觉丰富文档中的信息仍然是传统检索增强生成（RAG）方法的一项重大挑战。现有的基准主要集中在基于图像的问答（QA），忽视了密集视觉文档中高效检索、理解和推理的基本挑战。为了弥补这一差距，我们引入了ViDoSeek，一个旨在评估RAG在需要复杂推理的视觉丰富文档上的性能的新颖数据集。基于此，我们识别出当前RAG方法的关键局限性：（i）纯粹基于视觉的检索方法难以有效整合文本和视觉特征，（ii）先前的方法通常分配了不足的推理令牌，限制了它们的有效性。为了应对这些挑战，我们提出了ViDoRAG，一种针对视觉文档上复杂推理的新型多代理RAG框架。ViDoRAG采用基于高斯混合模型（GMM）的混合策略，有效地处理多模态检索。为了进一步激发模型的推理能力，我们引入了一种迭代的代理工作流，包括探索、总结和反思，提供了一个框架用于在RAG领域研究测试时标度问题。广泛的ViDoSeek实验验证了我们方法的有效性和普适性。值得注意的是，ViDoRAG在竞争性的ViDoSeek基准上性能优于现有方法，超过10%。', 'title_zh': '视觉文档检索增强生成 via 动态迭代推理代理'}
{'arxiv_id': 'arXiv:2502.18002', 'title': 'Radon-Nikodým Derivative: Re-imagining Anomaly Detection from a Measure Theoretic Perspective', 'authors': 'Shlok Mehendale, Aditya Challa, Rahul Yedida, Sravan Danda, Santonu Sarkar, Snehanshu Saha', 'link': 'https://arxiv.org/abs/2502.18002', 'abstract': 'Which principle underpins the design of an effective anomaly detection loss function? The answer lies in the concept of \\rnthm{} theorem, a fundamental concept in measure theory. The key insight is -- Multiplying the vanilla loss function with the \\rnthm{} derivative improves the performance across the board. We refer to this as RN-Loss. This is established using PAC learnability of anomaly detection. We further show that the \\rnthm{} derivative offers important insights into unsupervised clustering based anomaly detections as well. We evaluate our algorithm on 96 datasets, including univariate and multivariate data from diverse domains, including healthcare, cybersecurity, and finance. We show that RN-Derivative algorithms outperform state-of-the-art methods on 68\\% of Multivariate datasets (based on F-1 scores) and also achieves peak F1-scores on 72\\% of time series (Univariate) datasets.', 'abstract_zh': '哪种原则支撑了有效异常检测损失函数的设计？答案在于测度论中的\\ rnthm{}定理。关键见解在于——将标准损失函数与\\ rnthm{}导数相乘可以全面提升性能。我们称此为RN-Loss。我们使用PAC学习能力来确立这一点。进一步研究表明，\\ rnthm{}导数还为基于无监督聚类的异常检测提供了重要的见解。我们在96个数据集上评估了我们的算法，包括来自健康医疗、网络安全和金融等多个领域的单变量和多变量数据。结果显示，基于F-1分数，RN-导数算法在68%的多变量数据集上优于现有最佳方法，并在72%的时间序列（单变量）数据集上实现了最高的F1分数。', 'title_zh': 'Radon-Nikodým 导数：从测度论角度重构异常检测'}
{'arxiv_id': 'arXiv:2502.17986', 'title': 'Broadening Discovery through Structural Models: Multimodal Combination of Local and Structural Properties for Predicting Chemical Features', 'authors': 'Nikolai Rekut, Alexey Orlov, Klea Ziu, Elizaveta Starykh, Martin Takac, Aleksandr Beznosikov', 'link': 'https://arxiv.org/abs/2502.17986', 'abstract': 'In recent years, machine learning has profoundly reshaped the field of chemistry, facilitating significant advancements across various applications, including the prediction of molecular properties and the generation of molecular structures. Language models and graph-based models are extensively utilized within this domain, consistently achieving state-of-the-art results across an array of tasks. However, the prevailing practice of representing chemical compounds in the SMILES format -- used by most datasets and many language models -- presents notable limitations as a training data format. In contrast, chemical fingerprints offer a more physically informed representation of compounds, thereby enhancing their suitability for model training. This study aims to develop a language model that is specifically trained on fingerprints. Furthermore, we introduce a bimodal architecture that integrates this language model with a graph model. Our proposed methodology synthesizes these approaches, utilizing RoBERTa as the language model and employing Graph Isomorphism Networks (GIN), Graph Convolutional Networks (GCN) and Graphormer as graph models. This integration results in a significant improvement in predictive performance compared to conventional strategies for tasks such as Quantitative Structure-Activity Relationship (QSAR) and the prediction of nuclear magnetic resonance (NMR) spectra, among others.', 'abstract_zh': '近年来，机器学习深刻重塑了化学领域，推动了分子性质预测和分子结构生成等各类应用的重要进展。语言模型和图基模型在此领域被广泛使用，始终在众多任务上取得最先进成果。然而，大多数数据集和语言模型使用的SMILES表示格式作为训练数据格式存在明显局限性。相比之下，化学指纹提供了更物理化的化合物表示，从而增强了其作为模型训练数据的适用性。本研究旨在开发一种专门在指纹上训练的语言模型，并引入了一种双模架构，将这种语言模型与图模型结合。我们提出的方法综合了这些方法，使用RoBERTa作为语言模型，并采用Graph Isomorphism Networks (GIN)、Graph Convolutional Networks (GCN) 和Graphormer作为图模型。这种集成在定量结构-活性关系（QSAR）和核磁共振（NMR）谱预测等任务上显著提升了预测性能。', 'title_zh': '通过结构模型扩展发现：结合局部和结构属性的多模态组合预测化学特征'}
{'arxiv_id': 'arXiv:2502.17941', 'title': 'Optimal Brain Apoptosis', 'authors': 'Mingyuan Sun, Zheng Fang, Jiaxu Wang, Junjie Jiang, Delei Kong, Chenming Hu, Yuetong Fang, Renjing Xu', 'link': 'https://arxiv.org/abs/2502.17941', 'abstract': 'The increasing complexity and parameter count of Convolutional Neural Networks (CNNs) and Transformers pose challenges in terms of computational efficiency and resource demands. Pruning has been identified as an effective strategy to address these challenges by removing redundant elements such as neurons, channels, or connections, thereby enhancing computational efficiency without heavily compromising performance. This paper builds on the foundational work of Optimal Brain Damage (OBD) by advancing the methodology of parameter importance estimation using the Hessian matrix. Unlike previous approaches that rely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel pruning method that calculates the Hessian-vector product value directly for each parameter. By decomposing the Hessian matrix across network layers and identifying conditions under which inter-layer Hessian submatrices are non-zero, we propose a highly efficient technique for computing the second-order Taylor expansion of parameters. This approach allows for a more precise pruning process, particularly in the context of CNNs and Transformers, as validated in our experiments including VGG19, ResNet32, ResNet50, and ViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at this https URL.', 'abstract_zh': '不断增长的卷积神经网络（CNNs）和变换器的复杂性和参数量给计算效率和资源需求带来了挑战。剪枝已被识别为一种有效的策略，通过移除冗余的元素如神经元、通道或连接，从而在不严重影响性能的情况下提升计算效率。本文在Optimal Brain Damage（OBD）的基础上，推进了使用Hessian矩阵估计参数重要性的方法。不同于以往依赖近似的方法，我们提出了Optimal Brain Apoptosis（OBA），一种新的剪枝方法，直接计算每个参数的Hessian-向量积值。通过在网络层间分解Hessian矩阵，并识别层间Hessian子矩阵非零的条件，我们提出了一种高效计算参数二阶泰勒展开的方法。这种方法在卷积神经网络（CNNs）和变换器（Transformers）中实现了更精确的剪枝过程，这一点在针对VGG19、ResNet32、ResNet50和ViT-B/16在CIFAR10、CIFAR100和ImageNet数据集上的实验中得到了验证。我们的代码可在以下链接获取。', 'title_zh': '最优大脑凋亡'}
{'arxiv_id': 'arXiv:2502.17929', 'title': 'Integrating Boosted learning with Differential Evolution (DE) Optimizer: A Prediction of Groundwater Quality Risk Assessment in Odisha', 'authors': 'Sonalika Subudhi, Alok Kumar Pati, Sephali Bose, Subhasmita Sahoo, Avipsa Pattanaik, Biswa Mohan Acharya', 'link': 'https://arxiv.org/abs/2502.17929', 'abstract': 'Groundwater is eventually undermined by human exercises, such as fast industrialization, urbanization, over-extraction, and contamination from agrarian and urban sources. From among the different contaminants, the presence of heavy metals like cadmium (Cd), chromium (Cr), arsenic (As), and lead (Pb) proves to have serious dangers when present in huge concentrations in groundwater. Long-term usage of these poisonous components may lead to neurological disorders, kidney failure and different sorts of cancer. To address these issues, this study developed a machine learning-based predictive model to evaluate the Groundwater Quality Index (GWQI) and identify the main contaminants which are affecting the water quality. It has been achieved with the help of a hybrid machine learning model i.e. LCBoost Fusion . The model has undergone several processes like data preprocessing, hyperparameter tuning using Differential Evolution (DE) optimization, and evaluation through cross-validation. The LCBoost Fusion model outperforms individual models (CatBoost and LightGBM), by achieving low RMSE (0.6829), MSE (0.5102), MAE (0.3147) and a high R$^2$ score of 0.9809. Feature importance analysis highlights Potassium (K), Fluoride (F) and Total Hardness (TH) as the most influential indicators of groundwater contamination. This research successfully demonstrates the application of machine learning in assessing groundwater quality risks in Odisha. The proposed LCBoost Fusion model offers a reliable and efficient approach for real-time groundwater monitoring and risk mitigation. These findings will help the environmental organizations and the policy makers to map out targeted places for sustainable groundwater management. Future work will focus on using remote sensing data and developing an interactive decision-making system for groundwater quality assessment.', 'abstract_zh': '地下水最终由于快速工业化、城市化、过度开采以及来自农业和城市来源的污染而遭到破坏。在这诸多污染物中，镉（Cd）、铬（Cr）、砷（As）和铅（Pb）等重金属在高浓度下对地下水造成了严重威胁。长期使用这些有毒成分可能会导致神经紊乱、肾衰竭和不同类型的癌症。为解决这些问题，本研究开发了一种基于机器学习的预测模型，以评估地下水质量指数（GWQI）并识别主要的污染物。该模型借助一种混合机器学习模型即LCBoost Fusion实现。经过数据预处理、使用差分进化（DE）优化的超参数调优以及交叉验证评估等多个过程，LCBoost Fusion模型优于单独使用的模型（CatBoost和LightGBM），其RMSE为0.6829，MSE为0.5102，MAE为0.3147，R$^2$得分为0.9809。特征重要性分析表明，钾（K）、氟（F）和总硬度（TH）是地下水污染最重要的指标。本研究成功展示了在奥里萨邦应用机器学习评估地下水质量风险的方法。提出的LCBoost Fusion模型提供了一种可靠且高效的实时地下水监控和风险缓解方法。这些发现将帮助环保组织和政策制定者确定可持续地下水管理的重点区域。未来工作将侧重于使用遥感数据并开发交互式决策系统来评估地下水质量。', 'title_zh': '将增强学习与差分进化优化器相结合：奥dish地下水质量风险评估的预测'}
{'arxiv_id': 'arXiv:2502.17928', 'title': 'Structure-prior Informed Diffusion Model for Graph Source Localization with Limited Data', 'authors': 'Hongyi Chen, Jingtao Ding, Xiaojun Liang, Yong Li, Xiao-Ping Zhang', 'link': 'https://arxiv.org/abs/2502.17928', 'abstract': "The source localization problem in graph information propagation is crucial for managing various network disruptions, from misinformation spread to infrastructure failures. While recent deep generative approaches have shown promise in this domain, their effectiveness is limited by the scarcity of real-world propagation data. This paper introduces SIDSL (\\textbf{S}tructure-prior \\textbf{I}nformed \\textbf{D}iffusion model for \\textbf{S}ource \\textbf{L}ocalization), a novel framework that addresses three key challenges in limited-data scenarios: unknown propagation patterns, complex topology-propagation relationships, and class imbalance between source and non-source nodes. SIDSL incorporates topology-aware priors through graph label propagation and employs a propagation-enhanced conditional denoiser with a GNN-parameterized label propagation module (GNN-LP). Additionally, we propose a structure-prior biased denoising scheme that initializes from structure-based source estimations rather than random noise, effectively countering class imbalance issues. Experimental results across four real-world datasets demonstrate SIDSL's superior performance, achieving 7.5-13.3% improvements in F1 scores compared to state-of-the-art methods. Notably, when pretrained with simulation data of synthetic patterns, SIDSL maintains robust performance with only 10% of training data, surpassing baselines by more than 18.8%. These results highlight SIDSL's effectiveness in real-world applications where labeled data is scarce.", 'abstract_zh': '基于图信息传播的源定位问题对于管理和应对各种网络中断（从 misinformation 传播到基础设施故障）至关重要。尽管近期的深度生成方法在这一领域展现出了潜力，但它们的有效性受限于真实传播数据的稀缺。本文提出了SIDSL（结构先验导向的传播模型用于源定位），这是一种针对少量数据场景中三个关键挑战的新框架：未知的传播模式、复杂的拓扑-传播关系以及源节点与非源节点之间的类别不平衡。SIDSL 通过图标签传播引入了拓扑感知先验，并使用了传播增强条件降噪器，包含了一个基于 GNN 的标签传播模块（GNN-LP）。此外，我们提出了一种结构先验导向的降噪方案，从基于结构的源估测初始化，有效克服了类别不平衡问题。在四个真实世界数据集上的实验结果表明，SIDSL 在 F1 分数方面表现优异，比最先进的方法提高了 7.5-13.3%。特别地，预训练时使用合成模式的仿真数据，即使只有 10% 的训练数据，SIDSL 仍然表现出色，超过基线方法超过 18.8%。这些结果突显了 SIDSL 在缺乏标注数据的实际应用中的有效性。', 'title_zh': '基于结构先验的受限数据图源定位扩散模型'}
{'arxiv_id': 'arXiv:2502.17912', 'title': 'Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs', 'authors': 'Yuhan Chen, Yihong Luo, Yifan Song, Pengwen Dai, Jing Tang, Xiaochun Cao', 'link': 'https://arxiv.org/abs/2502.17912', 'abstract': 'Despite extensive research efforts focused on OOD detection on images, OOD detection on nodes in graph learning remains underexplored. The dependence among graph nodes hinders the trivial adaptation of existing approaches on images that assume inputs to be i.i.d. sampled, since many unique features and challenges specific to graphs are not considered, such as the heterophily issue. Recently, GNNSafe, which considers node dependence, adapted energy-based detection to the graph domain with state-of-the-art performance, however, it has two serious issues: 1) it derives node energy from classification logits without specifically tailored training for modeling data distribution, making it less effective at recognizing OOD data; 2) it highly relies on energy propagation, which is based on homophily assumption and will cause significant performance degradation on heterophilic graphs, where the node tends to have dissimilar distribution with its neighbors. To address the above issues, we suggest training EBMs by MLE to enhance data distribution modeling and remove energy propagation to overcome the heterophily issues. However, training EBMs via MLE requires performing MCMC sampling on both node feature and node neighbors, which is challenging due to the node interdependence and discrete graph topology. To tackle the sampling challenge, we introduce DeGEM, which decomposes the learning process into two parts: a graph encoder that leverages topology information for node representations and an energy head that operates in latent space. Extensive experiments validate that DeGEM, without OOD exposure during training, surpasses previous state-of-the-art methods, achieving an average AUROC improvement of 6.71% on homophilic graphs and 20.29% on heterophilic graphs, and even outperform methods trained with OOD exposure. Our code is available at: this https URL.', 'abstract_zh': '尽管在图像数据上的离域检测（OOD检测）已经得到了广泛的研究，但图学习中节点的离域检测仍缺乏探索。图节点之间的依赖关系阻碍了现有假设输入为独立同分布抽样图像方法的直接适应，因为许多与图特有的问题和挑战未被考虑，例如异质性问题。近期，GNNSafe 考虑到了节点依赖性，将基于能量的检测引入图域中，并取得了最先进的性能，然而它存在两个严重的问题：1）其节点能量来源于分类logits，没有专门针对建模数据分布的训练，使其在识别离域数据方面效果不佳；2）其高度依赖能量传播机制，该机制基于同质性假设，在异质图上会导致显著的性能下降，即节点与其邻居的分布差异较大。为解决上述问题，我们建议通过极大似然估计（MLE）训练能量分布模型以增强数据分布建模，并移除能量传播以克服异质性问题。然而，通过MLE训练能量分布模型需要在节点特征和节点邻居上进行马尔可夫链蒙特卡洛（MCMC）采样，这因节点间的依赖关系和离散的图拓扑结构而具有挑战性。为应对采样挑战，我们引入了DeGEM，它将学习过程分解为两部分：一个利用拓扑信息进行节点表示的图编码器和一个在潜在空间操作的能量头。大量实验验证了DeGEM在训练过程中无需暴露于离域数据的情况下，超过了之前的最先进的方法，在同质图上平均AUROC提高了6.71%，在异质图上提高了20.29%，甚至优于在暴露于离域数据下训练的方法。我们的代码可在：this https URL。', 'title_zh': '异质图中节点离分布检测的解耦图能量模型'}
{'arxiv_id': 'arXiv:2502.17911', 'title': 'Enhancing Speech Quality through the Integration of BGRU and Transformer Architectures', 'authors': 'Souliman Alghnam, Mohammad Alhussien, Khaled Shaheen', 'link': 'https://arxiv.org/abs/2502.17911', 'abstract': 'Speech enhancement plays an essential role in improving the quality of speech signals in noisy environments. This paper investigates the efficacy of integrating Bidirectional Gated Recurrent Units (BGRU) and Transformer models for speech enhancement tasks. Through a comprehensive experimental evaluation, our study demonstrates the superiority of this hybrid architecture over traditional methods and standalone models. The combined BGRU-Transformer framework excels in capturing temporal dependencies and learning complex signal patterns, leading to enhanced noise reduction and improved speech quality. Results show significant performance gains compared to existing approaches, highlighting the potential of this integrated model in real-world applications. The seamless integration of BGRU and Transformer architectures not only enhances system robustness but also opens the road for advanced speech processing techniques. This research contributes to the ongoing efforts in speech enhancement technology and sets a solid foundation for future investigations into optimizing model architectures, exploring many application scenarios, and advancing the field of speech processing in noisy environments.', 'abstract_zh': '演讲增强在噪声环境下的语音信号质量提升中发挥着关键作用。本文研究了将双向门控循环单元(BGRU)和Transformer模型集成应用于演讲增强任务的效果。通过全面的实验评估，我们的研究证明了这种混合架构优于传统方法和单一模型。结合的BGRU-Transformer框架在捕捉时序依赖性和学习复杂信号模式方面表现出色，从而提高了噪声抑制性能和语音质量。结果表明，与现有方法相比具有显著的性能提升，突显了该集成模型在实际应用中的潜力。BGRU和Transformer架构的无缝集成不仅增强了系统的鲁棒性，还为先进的语音处理技术铺平了道路。本文为语音增强技术的持续发展做出了贡献，并为未来优化模型架构、探索多种应用场景以及推进噪声环境下语音处理领域奠定了坚实的基础。', 'title_zh': '通过结合BGRU和Transformer架构提升语音质量'}
{'arxiv_id': 'arXiv:2502.17909', 'title': 'FactFlow: Automatic Fact Sheet Generation and Customization from Tabular Dataset via AI Chain Design & Implementation', 'authors': 'Minh Duc Vu, Jieshan Chen, Zhenchang Xing, Qinghua Lu, Xiwei Xu, Qian Fu', 'link': 'https://arxiv.org/abs/2502.17909', 'abstract': 'With the proliferation of data across various domains, there is a critical demand for tools that enable non-experts to derive meaningful insights without deep data analysis skills. To address this need, existing automatic fact sheet generation tools offer heuristic-based solutions to extract facts and generate stories. However, they inadequately grasp the semantics of data and struggle to generate narratives that fully capture the semantics of the dataset or align the fact sheet with specific user needs. Addressing these shortcomings, this paper introduces \\tool, a novel tool designed for the automatic generation and customisation of fact sheets. \\tool applies the concept of collaborative AI workers to transform raw tabular dataset into comprehensive, visually compelling fact sheets. We define effective taxonomy to profile AI worker for specialised tasks. Furthermore, \\tool empowers users to refine these fact sheets through intuitive natural language commands, ensuring the final outputs align closely with individual preferences and requirements. Our user evaluation with 18 participants confirms that \\tool not only surpasses state-of-the-art baselines in automated fact sheet production but also provides a positive user experience during customization tasks.', 'abstract_zh': '随着数据在各个领域中的泛滥，存在对无需深厚数据分析技能就能帮助非专家提取有意义见解的工具的迫切需求。为此，现有的自动事实表生成工具提供基于启发式的解决方案来提取事实并生成故事。然而，这些工具在理解数据语义方面存在不足，难以生成能够全面捕捉数据集语义或与特定用户需求相一致的叙述。为应对这些不足，本文介绍了\\tool这一新型工具，旨在自动生成和定制事实表。\\tool利用协作AI工作者的概念，将原始表格数据转换为全面且具有视觉吸引力的事实表。我们定义了有效的分类学来为专门任务配置AI工作者。此外，\\tool通过直观的自然语言命令赋予用户进一步调整这些事实表的能力，确保最终输出与个人偏好和需求紧密契合。我们的用户评估（涉及18名参与者）表明，\\tool不仅在自动事实表生成方面超过了现有的先进基准，还在定制任务中提供了积极的用户体验。', 'title_zh': 'FactFlow：通过AI链设计与实现从表格数据集自动生成和定制事实概要'}
{'arxiv_id': 'arXiv:2502.17893', 'title': 'Sample-efficient diffusion-based control of complex nonlinear systems', 'authors': 'Hongyi Chen, Jingtao Ding, Jianhai Shu, Xinchun Yu, Xiaojun Liang, Yong Li, Xiao-Ping Zhang', 'link': 'https://arxiv.org/abs/2502.17893', 'abstract': 'Complex nonlinear system control faces challenges in achieving sample-efficient, reliable performance. While diffusion-based methods have demonstrated advantages over classical and reinforcement learning approaches in long-term control performance, they are limited by sample efficiency. This paper presents SEDC (Sample-Efficient Diffusion-based Control), a novel diffusion-based control framework addressing three core challenges: high-dimensional state-action spaces, nonlinear system dynamics, and the gap between non-optimal training data and near-optimal control solutions. Through three innovations - Decoupled State Diffusion, Dual-Mode Decomposition, and Guided Self-finetuning - SEDC achieves 39.5\\%-49.4\\% better control accuracy than baselines while using only 10\\% of the training samples, as validated across three complex nonlinear dynamic systems. Our approach represents a significant advancement in sample-efficient control of complex nonlinear systems. The implementation of the code can be found at this https URL.', 'abstract_zh': '基于扩散的方法在实现复杂非线性系统高效可靠控制方面面临挑战。虽然基于扩散的方法在长期控制性能上优于传统和强化学习方法，但它们受限于样本效率。本文提出了SEDC（高效基于扩散的控制），一种解决三个核心挑战的新颖基于扩散的控制框架：高维状态-动作空间、非线性系统动力学以及非最优训练数据与近最优控制解之间的差距。通过三项创新——解耦状态扩散、双模式分解和引导自微调，SEDC在三个复杂非线性动态系统验证中仅使用10%的训练样本就实现了39.5%-49.4%的控制精度改进。我们的方法代表了复杂非线性系统高效控制的重要进步。相关代码实现可访问该网址。', 'title_zh': '基于扩散的复杂非线性系统高效样本控制'}
{'arxiv_id': 'arXiv:2502.17887', 'title': 'Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models', 'authors': 'Andrei Apostol, Maria Nutu', 'link': 'https://arxiv.org/abs/2502.17887', 'abstract': "In Romania, cardiovascular problems are the leading cause of death, accounting for nearly one-third of annual fatalities. The severity of this situation calls for innovative diagnosis method for cardiovascular diseases. This article aims to explore efficient, light-weight and rapid methods for arrhythmia diagnosis, in resource-constrained healthcare settings. Due to the lack of Romanian public medical data, we trained our systems using international public datasets, having in mind that the ECG signals are the same regardless the patients' nationality. Within this purpose, we combined multiple datasets, usually used in the field of arrhythmias classification: PTB-XL electrocardiography dataset , PTB Diagnostic ECG Database, China 12-Lead ECG Challenge Database, Georgia 12-Lead ECG Challenge Database, and St. Petersburg INCART 12-lead Arrhythmia Database. For the input data, we employed ECG signal processing methods, specifically a variant of the Pan-Tompkins algorithm, useful in arrhythmia classification because it provides a robust and efficient method for detecting QRS complexes in ECG signals. Additionally, we used machine learning techniques, widely used for the task of classification, including convolutional neural networks (1D CNNs, 2D CNNs, ResNet) and Vision Transformers (ViTs). The systems were evaluated in terms of accuracy and F1 score. We annalysed our dataset from two perspectives. First, we fed the systems with the ECG signals and the GRU-based 1D CNN model achieved the highest accuracy of 93.4% among all the tested architectures. Secondly, we transformed ECG signals into images and the CNN2D model achieved an accuracy of 92.16%.", 'abstract_zh': '在罗马尼亚，心血管问题是最主要的死亡原因，约占年度死亡人数的三分之一。为了应对这一严峻形势，本文旨在探索资源受限 healthcare 环境下高效、轻量化和快速的心律失常诊断方法。由于缺乏罗马尼亚公共医疗数据，我们使用国际公开数据集进行系统训练，考虑到心电图信号与患者国籍无关。为此，我们将心律失常分类领域常用的多个数据集结合起来，包括 PTB-XL 心电图数据集、PTB 诊断心电图数据库、中国12导联心电图挑战数据库、格鲁吉亚12导联心电图挑战数据库以及圣彼得堡 INCART 12导联心律失常数据库。对于输入数据，我们采用心电图信号处理方法，特别是改进的 Pan-Tompkins 算法，因为该算法能提供一种稳健且高效的方法来检测心电图信号中的 QRS 波群。此外，我们还采用了卷积神经网络（1D CNN、2D CNN、ResNet）和视觉变换器（ViTs）等机器学习技术，用于分类任务。系统从准确率和F1分数两个方面进行了评估。我们从两个角度分析了数据集。首先，我们用心电图信号喂给系统，GRU 基于的 1D CNN 模型取得了所有测试架构中最高的准确率 93.4%。其次，我们将心电图信号转换为图像，2D CNN 模型的准确率为 92.16%。', 'title_zh': '基于卷积和变换器的深度学习模型的12导联心电图心律失常分类'}
{'arxiv_id': 'arXiv:2502.17872', 'title': 'Contrastive Learning with Nasty Noise', 'authors': 'Ziruo Zhao', 'link': 'https://arxiv.org/abs/2502.17872', 'abstract': 'Contrastive learning has emerged as a powerful paradigm for self-supervised representation learning. This work analyzes the theoretical limits of contrastive learning under nasty noise, where an adversary modifies or replaces training samples. Using PAC learning and VC-dimension analysis, lower and upper bounds on sample complexity in adversarial settings are established. Additionally, data-dependent sample complexity bounds based on the l2-distance function are derived.', 'abstract_zh': '对比学习在恶劣噪声下的理论极限：对抗设置下的样本复杂性分析', 'title_zh': '带恶劣噪声的对比学习'}
{'arxiv_id': 'arXiv:2502.17839', 'title': 'Say Less, Mean More: Leveraging Pragmatics in Retrieval-Augmented Generation', 'authors': 'Haris Riaz, Ellen Riloff, Mihai Surdeanu', 'link': 'https://arxiv.org/abs/2502.17839', 'abstract': 'We propose a simple, unsupervised method that injects pragmatic principles in retrieval-augmented generation (RAG) frameworks such as Dense Passage Retrieval~\\cite{karpukhin2020densepassageretrievalopendomain} to enhance the utility of retrieved contexts. Our approach first identifies which sentences in a pool of documents retrieved by RAG are most relevant to the question at hand, cover all the topics addressed in the input question and no more, and then highlights these sentences within their context, before they are provided to the LLM, without truncating or altering the context in any other way. We show that this simple idea brings consistent improvements in experiments on three question answering tasks (ARC-Challenge, PubHealth and PopQA) using five different LLMs. It notably enhances relative accuracy by up to 19.7\\% on PubHealth and 10\\% on ARC-Challenge compared to a conventional RAG system.', 'abstract_zh': '我们提出一种简单的无监督方法，将语用原则注入到检索增强生成（RAG）框架中，如密集段落检索（DPR）~\\cite{karpukhin2020densepassageretrievalopendomain}，以增强检索上下文的实用性。该方法首先识别RAG检索出的文档集中哪些句子与问题最相关，覆盖输入问题涉及的所有话题但不过多包含无关内容，然后在将这些句子提供给LLM之前突出显示这些句子，而不会以任何方式截断或修改上下文。实验结果显示，该简单想法在三个问答任务（ARC-Challenge、PubHealth和PopQA）上使用五种不同LLM时均带来了持续改进。特别是在PubHealth和ARC-Challenge任务上，相对于传统RAG系统，相对准确性分别提升19.7%和10%。', 'title_zh': '说的更少，意味更多：利用语用学在检索增强生成中的作用'}
{'arxiv_id': 'arXiv:2502.17821', 'title': 'CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems', 'authors': 'Rui Liu, Yu Shen, Peng Gao, Pratap Tokekar, Ming Lin', 'link': 'https://arxiv.org/abs/2502.17821', 'abstract': 'Multi-modality learning has become a crucial technique for improving the performance of machine learning applications across domains such as autonomous driving, robotics, and perception systems. While existing frameworks such as Auxiliary Modality Learning (AML) effectively utilize multiple data sources during training and enable inference with reduced modalities, they primarily operate in a single-agent context. This limitation is particularly critical in dynamic environments, such as connected autonomous vehicles (CAV), where incomplete data coverage can lead to decision-making blind spots. To address these challenges, we propose Collaborative Auxiliary Modality Learning ($\\textbf{CAML}$), a novel multi-agent multi-modality framework that enables agents to collaborate and share multimodal data during training while allowing inference with reduced modalities per agent during testing. We systematically analyze the effectiveness of $\\textbf{CAML}$ from the perspective of uncertainty reduction and data coverage, providing theoretical insights into its advantages over AML. Experimental results in collaborative decision-making for CAV in accident-prone scenarios demonstrate that \\ours~achieves up to a ${\\bf 58.13}\\%$ improvement in accident detection. Additionally, we validate $\\textbf{CAML}$ on real-world aerial-ground robot data for collaborative semantic segmentation, achieving up to a ${\\bf 10.61}\\%$ improvement in mIoU.', 'abstract_zh': '多模态学习已成为提高自主驾驶、机器人技术和感知系统等领域机器学习应用性能的关键技术。虽然现有的框架如辅助模态学习（AML）在训练期间有效利用多种数据源并在推理时减少模态数量方面表现出色，但它们主要在这种代理单一的背景下运作。这一限制在诸如连接的自动驾驶车辆（CAV）等动态环境中尤为重要，不完整的数据覆盖可能导致决策盲点。为应对这些挑战，我们提出了协作辅助模态学习（CAML），这是一种新型多代理多模态框架，使代理在训练期间能够协作和共享多模态数据，并在测试时每个代理使用减少的模态进行推理。我们从不确定性减少和数据覆盖的角度系统分析了CAML的有效性，提供了与AML相比其优势的理论见解。在事故多发场景中的协作决策实验结果显示，CAML在事故检测方面可实现高达58.13%的提升。此外，我们还在真实的空地机器人数据上验证了CAML在协作语义分割中的应用，mIoU提升了高达10.61%。', 'title_zh': 'CAML：多代理系统中的协作辅助模态学习'}
{'arxiv_id': 'arXiv:2502.17801', 'title': 'Research on Enhancing Cloud Computing Network Security using Artificial Intelligence Algorithms', 'authors': 'Yuqing Wang, Xiao Yang', 'link': 'https://arxiv.org/abs/2502.17801', 'abstract': 'Cloud computing environments are increasingly vulnerable to security threats such as distributed denial-of-service (DDoS) attacks and SQL injection. Traditional security mechanisms, based on rule matching and feature recognition, struggle to adapt to evolving attack strategies. This paper proposes an adaptive security protection framework leveraging deep learning to construct a multi-layered defense architecture. The proposed system is evaluated in a real-world business environment, achieving a detection accuracy of 97.3%, an average response time of 18 ms, and an availability rate of 99.999%. Experimental results demonstrate that the proposed method significantly enhances detection accuracy, response efficiency, and resource utilization, offering a novel and effective approach to cloud computing security.', 'abstract_zh': '基于深度学习的适应性安全保护框架在云计算安全中的应用研究', 'title_zh': '基于人工 Intelligence 算法提升云 computing 网络安全性研究'}
{'arxiv_id': 'arXiv:2502.17771', 'title': 'Sample Selection via Contrastive Fragmentation for Noisy Label Regression', 'authors': 'Chris Dongjoo Kim, Sangwoo Moon, Jihwan Moon, Dongyeon Woo, Gunhee Kim', 'link': 'https://arxiv.org/abs/2502.17771', 'abstract': 'As with many other problems, real-world regression is plagued by the presence of noisy labels, an inevitable issue that demands our attention. Fortunately, much real-world data often exhibits an intrinsic property of continuously ordered correlations between labels and features, where data points with similar labels are also represented with closely related features. In response, we propose a novel approach named ConFrag, where we collectively model the regression data by transforming them into disjoint yet contrasting fragmentation pairs. This enables the training of more distinctive representations, enhancing the ability to select clean samples. Our ConFrag framework leverages a mixture of neighboring fragments to discern noisy labels through neighborhood agreement among expert feature extractors. We extensively perform experiments on six newly curated benchmark datasets of diverse domains, including age prediction, price prediction, and music production year estimation. We also introduce a metric called Error Residual Ratio (ERR) to better account for varying degrees of label noise. Our approach consistently outperforms fourteen state-of-the-art baselines, being robust against symmetric and random Gaussian label noise.', 'abstract_zh': '就像许多其他问题一样，实际世界的回归问题受到噪声标签的困扰，这是一个不可避免的问题，需要我们关注。幸运的是，大量实际数据往往表现出标签和特征之间内在的连续有序关联性，其中具有相似标签的数据点也表现为密切相关的特征。为应对这一挑战，我们提出了一种名为ConFrag的新方法，通过将回归数据转换为既不相连又具有对比性的碎片对来进行集体建模。这使得能够训练出更加独特的表示，增强选择清洁样本的能力。我们的ConFrag框架利用邻近碎片的混合，通过专家特征提取器之间的邻域一致性来区分噪声标签。我们在六个新编curated的不同领域基准数据集上进行了广泛实验，包括年龄预测、价格预测和音乐制作年份估计。我们还引入了一个称为错误残差比率（ERR）的指标，以更好地反映不同水平的标签噪声。我们的方法在对抗对称和随机高斯噪声的标注数据方面表现出色，始终优于十四种最先进的基线方法。', 'title_zh': '基于对比碎片化的选择性采样用于噪声标签回归'}
{'arxiv_id': 'arXiv:2502.17751', 'title': 'Graded Neural Networks', 'authors': 'Tony Shaska', 'link': 'https://arxiv.org/abs/2502.17751', 'abstract': 'This paper presents a novel framework for graded neural networks (GNNs) built over graded vector spaces $\\V_\\w^n$, extending classical neural architectures by incorporating algebraic grading. Leveraging a coordinate-wise grading structure with scalar action $\\lambda \\star \\x = (\\lambda^{q_i} x_i)$, defined by a tuple $\\w = (q_0, \\ldots, q_{n-1})$, we introduce graded neurons, layers, activation functions, and loss functions that adapt to feature significance. Theoretical properties of graded spaces are established, followed by a comprehensive GNN design, addressing computational challenges like numerical stability and gradient scaling. Potential applications span machine learning and photonic systems, exemplified by high-speed laser-based implementations. This work offers a foundational step toward graded computation, unifying mathematical rigor with practical potential, with avenues for future empirical and hardware exploration.', 'abstract_zh': '本文提出了一个基于分级向量空间\\V_\\w^n的新型分级神经网络（GNNs）框架，通过引入代数分级扩展了经典神经架构。利用元组\\w = (q_0, \\ldots, q_{n-1}) 定义的逐坐标分级结构和标量作用\\lambda \\star \\x = (\\lambda^{q_i} x_i)，引入了适应特征重要性的分级神经元、层级、激活函数和损失函数。建立了分级空间的理论性质，并提出了一整套GNN设计，解决了计算挑战如数值稳定性与梯度缩放。潜在应用涉及机器学习和光子系统，以高速激光基实现为例。本文为分级计算奠定了基础步骤，统一了数学严谨性与实际潜力，并为未来的经验和硬件探索提供了途径。', 'title_zh': '分层神经网络'}
{'arxiv_id': 'arXiv:2502.17726', 'title': 'The GigaMIDI Dataset with Features for Expressive Music Performance Detection', 'authors': 'Keon Ju Maverick Lee, Jeff Ens, Sara Adkins, Pedro Sarmento, Mathieu Barthet, Philippe Pasquier', 'link': 'https://arxiv.org/abs/2502.17726', 'abstract': 'The Musical Instrument Digital Interface (MIDI), introduced in 1983, revolutionized music production by allowing computers and instruments to communicate efficiently. MIDI files encode musical instructions compactly, facilitating convenient music sharing. They benefit Music Information Retrieval (MIR), aiding in research on music understanding, computational musicology, and generative music. The GigaMIDI dataset contains over 1.4 million unique MIDI files, encompassing 1.8 billion MIDI note events and over 5.3 million MIDI tracks. GigaMIDI is currently the largest collection of symbolic music in MIDI format available for research purposes under fair dealing. Distinguishing between non-expressive and expressive MIDI tracks is challenging, as MIDI files do not inherently make this distinction. To address this issue, we introduce a set of innovative heuristics for detecting expressive music performance. These include the Distinctive Note Velocity Ratio (DNVR) heuristic, which analyzes MIDI note velocity; the Distinctive Note Onset Deviation Ratio (DNODR) heuristic, which examines deviations in note onset times; and the Note Onset Median Metric Level (NOMML) heuristic, which evaluates onset positions relative to metric levels. Our evaluation demonstrates these heuristics effectively differentiate between non-expressive and expressive MIDI tracks. Furthermore, after evaluation, we create the most substantial expressive MIDI dataset, employing our heuristic, NOMML. This curated iteration of GigaMIDI encompasses expressively-performed instrument tracks detected by NOMML, containing all General MIDI instruments, constituting 31% of the GigaMIDI dataset, totalling 1,655,649 tracks.', 'abstract_zh': 'MIDI文件的革命：GigaMIDI数据集及其在区分表情与非表情MIDI轨道中的应用', 'title_zh': 'GigaMIDI数据集及其用于表达性音乐表演检测的特征'}
{'arxiv_id': 'arXiv:2502.17725', 'title': 'Solving the Traveling Salesman Problem via Different Quantum Computing Architectures', 'authors': 'Venkat Padmasola, Zhaotong Li, Rupak Chatterjee, Wesley Dyk', 'link': 'https://arxiv.org/abs/2502.17725', 'abstract': 'We study the application of emerging photonic and quantum computing architectures to solving the Traveling Salesman Problem (TSP), a well-known NP-hard optimization problem. We investigate several approaches: Simulated Annealing (SA), Quadratic Unconstrained Binary Optimization (QUBO-Ising) methods implemented on quantum annealers and Optical Coherent Ising Machines, as well as the Quantum Approximate Optimization Algorithm (QAOA) and the Quantum Phase Estimation (QPE) algorithm on gate-based quantum computers.\nQAOA and QPE were tested on the IBM Quantum platform. The QUBO-Ising method was explored using the D-Wave quantum annealer, which operates on superconducting Josephson junctions, and the QCI Dirac machine, a nonlinear optoelectronic Ising machine. Gate-based quantum computers demonstrated accurate results for small TSP instances in simulation. However, real quantum devices are hindered by noise and limited scalability. Circuit complexity grows with problem size, restricting performance to TSP instances with a maximum of 6 nodes.\nIn contrast, Ising-based architectures show improved scalability for larger problem sizes. SQUID-based Ising machines can handle TSP instances with up to 12 nodes, while nonlinear optoelectronic Ising machines extend this capability to 18 nodes. Nevertheless, the solutions tend to be suboptimal due to hardware limitations and challenges in achieving ground state convergence as the problem size increases. Despite these limitations, Ising machines demonstrate significant time advantages over classical methods, making them a promising candidate for solving larger-scale TSPs efficiently.', 'abstract_zh': '我们研究了新兴的光子和量子计算架构在解决旅行商问题（TSP）中的应用，TSP是一个著名的NP难优化问题。我们探讨了几种方法：模拟退火（SA）、在量子退火器和光学相干伊辛机上实现的二次无约束二元优化（QUBO-Ising）方法，以及门基量子计算机上的量子近似优化算法（QAOA）和量子相位估计算法（QPE）。QAOA和QPE在IBM Quantum平台上进行了测试。QUBO-Ising方法在D-Wave量子退火器和QCI Dirac光学非线性光电伊辛机上进行了探索，D-Wave量子退火器基于超导约瑟夫森结工作。门基量子计算机在小规模TSP实例的仿真中展现了准确的结果，但实际量子设备受到噪声和可扩展性限制，随着问题规模的增大，电路复杂度的增加限制了性能，最多只能处理6个节点的问题实例。相比之下，基于伊辛模型的架构对于处理大规模问题表现出更好的可扩展性。基于SQUID的伊辛机能够处理多达12个节点的问题，而光学非线性光电伊辛机将这一能力扩展到18个节点。然而，由于硬件限制和在处理大规模问题时难以达到基态收敛，解决方案往往不是最优的。尽管存在这些限制，伊辛机在解决大规Linux系统问题时显示出显著的时间优势，使其成为解决大规模TSP的有效候选方法。', 'title_zh': '通过不同量子计算架构解决旅行商问题'}
{'arxiv_id': 'arXiv:2502.17715', 'title': 'Bridging Information Gaps with Comprehensive Answers: Improving the Diversity and Informativeness of Follow-Up Questions', 'authors': 'Zhe Liu, Taekyu Kang, Haoyu Wang, Seyed Hossein Alavi, Vered Shwartz', 'link': 'https://arxiv.org/abs/2502.17715', 'abstract': 'Effective conversational systems are expected to dynamically generate contextual follow-up questions to elicit new information while maintaining the conversation flow. While humans excel at asking diverse and informative questions by intuitively assessing both obtained and missing information, existing models often fall short of human performance on this task. To mitigate this, we propose a method that generates diverse and informative questions based on targeting unanswered information using a hypothetical LLM-generated "comprehensive answer". Our method is applied to augment an existing follow-up questions dataset. The experimental results demonstrate that language models fine-tuned on the augmented datasets produce follow-up questions of significantly higher quality and diversity. This promising approach could be effectively adopted to future work to augment information-seeking dialogues for reducing ambiguities and improving the accuracy of LLM answers.', 'abstract_zh': '有效的对话系统应能动态生成与场景相关的问题，以获取新信息并保持对话流畅。虽然人类能够通过直观评估已获得和缺失的信息来提出多样性和信息性的问题，现有模型在这方面往往无法达到人类的表现。为解决这一问题，我们提出了一种方法，该方法基于假设的LLM生成的“全面答案”来针对未解答的信息生成多样性和信息性的问题。该方法应用于扩展现有的后续问题数据集。实验结果表明，针对扩展数据集微调的语言模型生成的后续问题在质量和多样性方面显著提高。这一有前景的方法可以有效地应用于未来工作，以增强信息寻求对话，减少歧义并提高LLM答案的准确性。', 'title_zh': '填补信息空白 với综合答案：提高后续问题的多样性和信息量'}
{'arxiv_id': 'arXiv:2502.17714', 'title': 'On the usability of generative AI: Human generative AI', 'authors': 'Anna Ravera, Cristina Gena', 'link': 'https://arxiv.org/abs/2502.17714', 'abstract': 'Generative AI systems are transforming content creation, but their usability remains a key challenge. This paper examines usability factors such as user experience, transparency, control, and cognitive load. Common challenges include unpredictability and difficulties in fine-tuning outputs. We review evaluation metrics like efficiency, learnability, and satisfaction, highlighting best practices from various domains. Improving interpretability, intuitive interfaces, and user feedback can enhance usability, making generative AI more accessible and effective.', 'abstract_zh': '生成式AI系统正在变革内容创作，但其可用性仍是一项关键挑战。本文探讨了包括用户体验、透明度、控制和认知负荷在内的可用性因素。常见挑战包括输出的不可预测性和调优困难。我们回顾了效率、易学性和满意度等评估指标，强调了来自不同领域的最佳实践。提高可解释性、直观的界面和用户反馈可以提升可用性，使生成式AI更加易于使用且效果更佳。', 'title_zh': '关于生成性AI的可用性：人类生成性AI'}
{'arxiv_id': 'arXiv:2502.17703', 'title': 'To Patch or Not to Patch: Motivations, Challenges, and Implications for Cybersecurity', 'authors': 'Jason R. C. Nurse', 'link': 'https://arxiv.org/abs/2502.17703', 'abstract': "As technology has become more embedded into our society, the security of modern-day systems is paramount. One topic which is constantly under discussion is that of patching, or more specifically, the installation of updates that remediate security vulnerabilities in software or hardware systems. This continued deliberation is motivated by complexities involved with patching; in particular, the various incentives and disincentives for organizations and their cybersecurity teams when deciding whether to patch. In this paper, we take a fresh look at the question of patching and critically explore why organizations and IT/security teams choose to patch or decide against it (either explicitly or due to inaction). We tackle this question by aggregating and synthesizing prominent research and industry literature on the incentives and disincentives for patching, specifically considering the human aspects in the context of these motives. Through this research, this study identifies key motivators such as organizational needs, the IT/security team's relationship with vendors, and legal and regulatory requirements placed on the business and its staff. There are also numerous significant reasons discovered for why the decision is taken not to patch, including limited resources (e.g., person-power), challenges with manual patch management tasks, human error, bad patches, unreliable patch management tools, and the perception that related vulnerabilities would not be exploited. These disincentives, in combination with the motivators above, highlight the difficult balance that organizations and their security teams need to maintain on a daily basis. Finally, we conclude by discussing implications of these findings and important future considerations.", 'abstract_zh': '随着技术越来越深入融入我们的社会，现代系统的安全性变得至关重要。关于补丁安装的问题，尤其是软件或硬件系统中安全漏洞修复的更新安装，一直是持续讨论的焦点。这种持续的讨论受到补丁安装复杂性的推动；特别是组织及其网络安全团队在决定是否安装补丁时的各种动机和抑制因素。本文从一个新的角度探讨补丁安装问题，并深入探讨组织和IT/安全团队选择安装补丁或不安装补丁（无论是明确选择不安装还是因无行动而未安装）的原因。我们通过综合和合成有关补丁安装动机和抑制因素的主要研究和行业文献，并特别考虑这些动机的人文方面，来回答这个问题。通过这项研究，本文确定了关键的动机，如组织需求、IT/安全团队与供应商的关系以及对企业和员工的法律和监管要求。还发现了许多不安装补丁的重要原因，包括资源有限（例如人力）、手动补丁管理任务的挑战、人为错误、不良补丁、不可靠的补丁管理工具以及认为相关漏洞不会被利用的感知。这些抑制因素与上述动机的结合，突显了组织及其安全团队在日常工作中需要维持的困难平衡。最后，本文讨论了这些发现的影响和重要的未来考虑。', 'title_zh': '要不要打补丁：动机、挑战及网络安全影响'}
{'arxiv_id': 'arXiv:2502.17665', 'title': 'Effective Field Neural Network', 'authors': 'Xi Liu, Yujun Zhao, Chun Yu Wan, Yang Zhang, Junwei Liu', 'link': 'https://arxiv.org/abs/2502.17665', 'abstract': 'In recent years, with the rapid development of machine learning, physicists have been exploring its new applications in solving or alleviating the curse of dimensionality in many-body problems. In order to accurately reflect the underlying physics of the problem, domain knowledge must be encoded into the machine learning algorithms. In this work, inspired by field theory, we propose a new set of machine learning models called effective field neural networks (EFNNs) that can automatically and efficiently capture important many-body interactions through multiple self-refining processes. Taking the classical $3$-spin infinite-range model and the quantum double exchange model as case studies, we explicitly demonstrate that EFNNs significantly outperform fully-connected deep neural networks (DNNs) and the effective model. Furthermore, with the help of convolution operations, the EFNNs learned in a small system can be seamlessly used in a larger system without additional training and the relative errors even decrease, which further demonstrates the efficacy of EFNNs in representing core physical behaviors.', 'abstract_zh': '近年来，随着机器学习的快速發展，物理学家在探索将其应用于解決或緩解多體問題的維度災難方面取得了新進展。為了準確反映問題的基礎物理特性，必須將領域知識編碼到機器學習算法中。在本工作中，受到場論的思想啟發，我們提出了一種新的機器學習模型有效場神經網絡（EFNNs），該模型能夠通過多個自反修諫過程自動且高效地捕獲重要多體交互作用。以经典的3自旋无穷范围模型和量子双交换模型为例，我们Explicitly展示了EFNNs显著优于全连接深度神经网络（DNNs）和有效模型。此外，借助卷积操作，EFNNs可以在小系统中学习后无缝应用于大系统中，而无需额外训练，相对误差甚至减小，这进一步证明了EFNNs在表示核心物理行为方面的有效性。', 'title_zh': '有效场神经网络'}
{'arxiv_id': 'arXiv:2502.17651', 'title': 'METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling', 'authors': 'Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng', 'link': 'https://arxiv.org/abs/2502.17651', 'abstract': 'Chart generation aims to generate code to produce charts satisfying the desired visual properties, e.g., texts, layout, color, and type. It has great potential to empower the automatic professional report generation in financial analysis, research presentation, education, and healthcare. In this work, we build a vision-language model (VLM) based multi-agent framework for effective automatic chart generation. Generating high-quality charts requires both strong visual design skills and precise coding capabilities that embed the desired visual properties into code. Such a complex multi-modal reasoning process is difficult for direct prompting of VLMs. To resolve these challenges, we propose METAL, a multi-agent framework that decomposes the task of chart generation into the iterative collaboration among specialized agents. METAL achieves 5.2% improvement in accuracy over the current best result in the chart generation task. The METAL framework exhibits the phenomenon of test-time scaling: its performance increases monotonically as the logarithmic computational budget grows from 512 to 8192 tokens. In addition, we find that separating different modalities during the critique process of METAL boosts the self-correction capability of VLMs in the multimodal context.', 'abstract_zh': '基于视觉-语言模型的多agent框架下的图表生成方法', 'title_zh': 'METAL：一种用于图表生成的多agent框架，具备测试时扩展能力'}
{'arxiv_id': 'arXiv:2502.17650', 'title': 'Wearable Meets LLM for Stress Management: A Duoethnographic Study Integrating Wearable-Triggered Stressors and LLM Chatbots for Personalized Interventions', 'authors': 'Sameer Neupane, Poorvesh Dongre, Denis Gracanin, Santosh Kumar', 'link': 'https://arxiv.org/abs/2502.17650', 'abstract': 'We use a duoethnographic approach to study how wearable-integrated LLM chatbots can assist with personalized stress management, addressing the growing need for immediacy and tailored interventions. Two researchers interacted with custom chatbots over 22 days, responding to wearable-detected physiological prompts, recording stressor phrases, and using them to seek tailored interventions from their LLM-powered chatbots. They recorded their experiences in autoethnographic diaries and analyzed them during weekly discussions, focusing on the relevance, clarity, and impact of chatbot-generated interventions. Results showed that even though most events triggered by the wearable were meaningful, only one in five warranted an intervention. It also showed that interventions tailored with brief event descriptions were more effective than generic ones. By examining the intersection of wearables and LLM, this research contributes to developing more effective, user-centric mental health tools for real-time stress relief and behavior change.', 'abstract_zh': '我们采用双重民族志方法研究穿戴设备集成的大语言模型聊天机器人在个人压力管理中的辅助作用，以应对即时性和个性化干预日益增长的需求。两名研究人员在22天内与定制聊天机器人互动，响应穿戴设备检测到的生理信号提示、记录压力源短语，并使用这些信息寻求基于大语言模型的聊天机器人提供的个性化干预措施。他们记录了自己的体验并在每周的讨论中进行分析，重点关注聊天机器人生成的干预措施的相关性、清晰度和影响。研究结果显示，尽管大多数由穿戴设备触发的事件具有重要意义，但仅五分之一的事件需要干预。同时发现，使用简要事件描述定制的干预措施比通用的干预措施更有效。通过探讨穿戴设备与大语言模型的交集，本研究为开发更有效、以用户为中心的实时减压和行为改变的心理健康工具做出了贡献。', 'title_zh': '可穿戴设备结合大语言模型进行压力管理：一种整合可穿戴设备触发的压力源和大语言模型聊天机器人的个性化干预 dúoyíngnuòlùn jiājié héqiǎojiǎngxínɡ de yālì guǎnlǐ：yī zhǒnɡ hélián kěwaklıān bèiqiè tífù de yālì yuán hé dàyǎ jiǎnɡxínɡ mó’érlénɡ de ɡè rèn huīnéng ɡānjūn dúoyíng'}
{'arxiv_id': 'arXiv:2502.17639', 'title': 'Requirements for Quality Assurance of AI Models for Early Detection of Lung Cancer', 'authors': 'Horst K. Hahn, Matthias S. May, Volker Dicken, Michael Walz, Rainer Eßeling, Bianca Lassen-Schmidt, Robert Rischen, Jens Vogel-Claussen, Konstantin Nikolaou, Jörg Barkhausen', 'link': 'https://arxiv.org/abs/2502.17639', 'abstract': "Lung cancer is the second most common cancer and the leading cause of cancer-related deaths worldwide. Survival largely depends on tumor stage at diagnosis, and early detection with low-dose CT can significantly reduce mortality in high-risk patients. AI can improve the detection, measurement, and characterization of pulmonary nodules while reducing assessment time. However, the training data, functionality, and performance of available AI systems vary considerably, complicating software selection and regulatory evaluation. Manufacturers must specify intended use and provide test statistics, but they can choose their training and test data, limiting standardization and comparability. Under the EU AI Act, consistent quality assurance is required for AI-based nodule detection, measurement, and characterization.\nThis position paper proposes systematic quality assurance grounded in a validated reference dataset, including real screening cases plus phantom data to verify volume and growth rate measurements. Regular updates shall reflect demographic shifts and technological advances, ensuring ongoing relevance. Consequently, ongoing AI quality assurance is vital. Regulatory challenges are also adressed. While the MDR and the EU AI Act set baseline requirements, they do not adequately address self-learning algorithms or their updates. A standardized, transparent quality assessment - based on sensitivity, specificity, and volumetric accuracy - enables an objective evaluation of each AI solution's strengths and weaknesses. Establishing clear testing criteria and systematically using updated reference data lay the groundwork for comparable performance metrics, informing tenders, guidelines, and recommendations.", 'abstract_zh': '肺癌是全球第二常见的癌症，并且是癌症相关死亡的主要原因。生存率主要取决于诊断时的肿瘤分期，早期通过低剂量CT检测可显著降低高风险患者的死亡率。AI可以提高肺结节的检测、测量和表征能力，同时减少评估时间。然而，现有AI系统的训练数据、功能和性能差异较大，这给软件选择和监管评估带来了复杂性。制造商必须明确预期用途并提供测试统计，但可以自行选择训练和测试数据，这限制了标准化和可比性。根据《欧盟AI法案》，基于验证参考数据（包括真实的筛查病例及模拟数据以验证体积和生长率测量）的一致质量保证是必需的。\n\n本文提出了基于验证参考数据的系统质量保证，包括真实筛查病例和模拟数据，以验证体积和生长率测量。定期更新应反映人口结构变化和技术进步，以确保持续相关性。因此，持续的AI质量保证至关重要。本文还解决了监管挑战。虽然MDR和《欧盟AI法案》设定了基本要求，但并未充分解决自学习算法及其更新的问题。基于灵敏度、特异性和容积准确性进行的标准化、透明的质量评估能够客观评价每个AI解决方案的优势和不足。明确测试标准并系统使用更新的参考数据，为可比性能指标奠定了基础，有助于标书、指南和建议的制定。', 'title_zh': 'AI模型早期检测肺癌的质量保证要求'}
{'arxiv_id': 'arXiv:2502.17624', 'title': 'Theory-guided Pseudo-spectral Full Waveform Inversion via Deep Neural Networks', 'authors': 'Christopher Zerafa, Pauline Galea, Cristiana Sebu', 'link': 'https://arxiv.org/abs/2502.17624', 'abstract': 'Full-Waveform Inversion seeks to achieve a high-resolution model of the subsurface through the application of multi-variate optimization to the seismic inverse problem. Although now a mature technology, FWI has limitations related to the choice of the appropriate solver for the forward problem in challenging environments requiring complex assumptions, and very wide angle and multi-azimuth data necessary for full reconstruction are often not available.\nDeep Learning techniques have emerged as excellent optimization frameworks. Data-driven methods do not impose a wave propagation model and are not exposed to modelling errors. On the contrary, deterministic models are governed by the laws of physics.\nSeismic FWI has recently started to be investigated as a Deep Learning framework. Focus has been on the time-domain, while the pseudo-spectral domain has not been yet explored. However, classical FWI experienced major breakthroughs when pseudo-spectral approaches were employed. This work addresses the lacuna that exists in incorporating the pseudo-spectral approach within Deep Learning. This has been done by re-formulating the pseudo-spectral FWI problem as a Deep Learning algorithm for a theory-driven pseudo-spectral approach. A novel Recurrent Neural Network framework is proposed. This is qualitatively assessed on synthetic data, applied to a two-dimensional Marmousi dataset and evaluated against deterministic and time-based approaches.\nPseudo-spectral theory-guided FWI using RNN was shown to be more accurate than classical FWI with only 0.05 error tolerance and 1.45\\% relative percent-age error. Indeed, this provides more stable convergence, able to identify faults better and has more low frequency content than classical FWI. Moreover, RNN was more suited than classical FWI at edge detection in the shallow and deep sections due to cleaner receiver residuals.', 'abstract_zh': '全波形 inversion基于多变量优化解决地震逆问题以实现地下高分辨率模型。尽管全波形 inversion已成为一种成熟的技術，但在复杂环境下，适当前向问题求解器的选择仍是其局限性之一。全貌和多方位数据对于完整重建往往是不可得的。\n\n深度学习技术已经发展成为优秀的优化框架。数据驱动的方法无需设定波传播模型，也不会受到模型误差的影响。相反，确定性模型则遵循物理定律。\n\n地震全波形 inversion最近开始作为深度学习框架进行研究。研究主要集中在时域，而伪谱域尚未被探索。然而，经典全波形 inversion在伪谱方法被采用时经历了重大突破。本工作填补了将伪谱方法融入深度学习的空白。通过将伪谱全波形 inversion问题重新表述为理论导向的伪谱深度学习算法，提出了一种新颖的循环神经网络框架。该方法在合成数据上进行了定性评估，并应用于二维Marmousi数据集，与确定性和基于时间的方法进行了对比。\n\n基于RNN的伪谱理论导向全波形 inversion表现优于仅采用0.05误差容限和1.45%相对误差的经典全波形 inversion，提供了更稳定的收敛性，能够更好地识别断层，并具有更多的低频成分。此外，RNN在浅部和深部区块边缘检测方面比经典全波形 inversion更具优势，因为其接收器残差更干净。', 'title_zh': '基于理论指导的伪谱全波形反演深度神经网络方法'}
{'arxiv_id': 'arXiv:2502.17613', 'title': 'Flexible Counterfactual Explanations with Generative Models', 'authors': 'Stig Hellemans, Andres Algaba, Sam Verboven, Vincent Ginis', 'link': 'https://arxiv.org/abs/2502.17613', 'abstract': "Counterfactual explanations provide actionable insights to achieve desired outcomes by suggesting minimal changes to input features. However, existing methods rely on fixed sets of mutable features, which makes counterfactual explanations inflexible for users with heterogeneous real-world constraints. Here, we introduce Flexible Counterfactual Explanations, a framework incorporating counterfactual templates, which allows users to dynamically specify mutable features at inference time. In our implementation, we use Generative Adversarial Networks (FCEGAN), which align explanations with user-defined constraints without requiring model retraining or additional optimization. Furthermore, FCEGAN is designed for black-box scenarios, leveraging historical prediction datasets to generate explanations without direct access to model internals. Experiments across economic and healthcare datasets demonstrate that FCEGAN significantly improves counterfactual explanations' validity compared to traditional benchmark methods. By integrating user-driven flexibility and black-box compatibility, counterfactual templates support personalized explanations tailored to user constraints.", 'abstract_zh': '灵活的反事实解释：结合反事实模板以适应异质实际约束的框架', 'title_zh': '基于生成模型的灵活反事实解释'}
{'arxiv_id': 'arXiv:2502.17608', 'title': 'Data-Driven Pseudo-spectral Full Waveform Inversion via Deep Neural Networks', 'authors': 'Christopher Zerafa, Pauline Galea, Cristiana Sebu', 'link': 'https://arxiv.org/abs/2502.17608', 'abstract': 'FWI seeks to achieve a high-resolution model of the subsurface through the application of multi-variate optimization to the seismic inverse problem. Although now a mature technology, FWI has limitations related to the choice of the appropriate solver for the forward problem in challenging environments requiring complex assumptions, and very wide angle and multi-azimuth data necessary for full reconstruction are often not available.\nDeep Learning techniques have emerged as excellent optimization frameworks. These exist between data and theory-guided methods. Data-driven methods do not impose a wave propagation model and are not exposed to modelling errors. On the contrary, deterministic models are governed by the laws of physics.\nApplication of seismic FWI has recently started to be investigated within Deep Learning. This has focussed on the time-domain approach, while the pseudo-spectral domain has not been yet explored. However, classical FWI experienced major breakthroughs when pseudo-spectral approaches were employed. This work addresses the lacuna that exists in incorporating the pseudo-spectral approach within Deep Learning. This has been done by re-formulating the pseudo-spectral FWI problem as a Deep Learning algorithm for a data-driven pseudo-spectral approach. A novel DNN framework is proposed. This is formulated theoretically, qualitatively assessed on synthetic data, applied to a two-dimensional Marmousi dataset and evaluated against deterministic and time-based approaches.\nInversion of data-driven pseudo-spectral DNN was found to outperform classical FWI for deeper and over-thrust areas. This is due to the global approximator nature of the technique and hence not bound by forward-modelling physical constraints from ray-tracing.', 'abstract_zh': '基于伪谱的深度学习全波场逆问题方法', 'title_zh': '基于深度神经网络的数据驱动伪谱全波形反演'}
{'arxiv_id': 'arXiv:2502.17585', 'title': 'Synergizing Deep Learning and Full-Waveform Inversion: Bridging Data-Driven and Theory-Guided Approaches for Enhanced Seismic Imaging', 'authors': 'Christopher Zerafa, Pauline Galea, Cristiana Sebu', 'link': 'https://arxiv.org/abs/2502.17585', 'abstract': "This review explores the integration of deep learning (DL) with full-waveform inversion (FWI) for enhanced seismic imaging and subsurface characterization. It covers FWI and DL fundamentals, geophysical applications (velocity estimation, deconvolution, tomography), and challenges (model complexity, data quality). The review also outlines future research directions, including hybrid, generative, and physics-informed models for improved accuracy, efficiency, and reliability in subsurface property estimation. The synergy between DL and FWI has the potential to transform geophysics, providing new insights into Earth's subsurface.", 'abstract_zh': '深学习与全波形反演集成在地震成像与地下表征中的研究综述', 'title_zh': '深度融合学习与全波形反演：数据驱动与理论指导相结合的地震成像增强方法'}
{'arxiv_id': 'arXiv:2502.17537', 'title': 'On the Vulnerability of Concept Erasure in Diffusion Models', 'authors': 'Lucas Beerens, Alex D. Richardson, Kaicheng Zhang, Dongdong Chen', 'link': 'https://arxiv.org/abs/2502.17537', 'abstract': 'The proliferation of text-to-image diffusion models has raised significant privacy and security concerns, particularly regarding the generation of copyrighted or harmful images. To address these issues, research on machine unlearning has developed various concept erasure methods, which aim to remove the effect of unwanted data through post-hoc training. However, we show these erasure techniques are vulnerable, where images of supposedly erased concepts can still be generated using adversarially crafted prompts. We introduce RECORD, a coordinate-descent-based algorithm that discovers prompts capable of eliciting the generation of erased content. We demonstrate that RECORD significantly beats the attack success rate of current state-of-the-art attack methods. Furthermore, our findings reveal that models subjected to concept erasure are more susceptible to adversarial attacks than previously anticipated, highlighting the urgency for more robust unlearning approaches. We open source all our code at this https URL', 'abstract_zh': '文本到图像扩散模型的普及引发了显著的隐私和安全关切，特别是关于版权受保护或有害图像的生成。为应对这些问题，关于机器遗忘的研究开发了各种概念擦除方法，旨在通过后训练去除不想要数据的影响。然而，我们揭示这些擦除技术存在漏洞， adversarially 制作的提示仍然能够生成被擦除的概念图像。我们介绍了基于坐标下降的 RECORD 算法，该算法能够发现能够引发被擦除内容生成的提示。我们证明了 RECORD 明显优于当前最先进的攻击方法的成功率。此外，我们的研究发现，遭受概念擦除的模型比预期更易受到对抗性攻击，强调了更稳健的遗忘方法的迫切需求。我们已在以下网址开源了所有代码：this https URL。', 'title_zh': '扩散模型中概念擦除的脆弱性研究'}
{'arxiv_id': 'arXiv:2502.17533', 'title': 'From Euler to AI: Unifying Formulas for Mathematical Constants', 'authors': 'Tomer Raz, Michael Shalyt, Elyasheev Leibtag, Rotem Kalisch, Yaron Hadad, Ido Kaminer', 'link': 'https://arxiv.org/abs/2502.17533', 'abstract': "The constant $\\pi$ has fascinated scholars for centuries, inspiring the derivation of countless formulas rooted in profound mathematical insight. This abundance of formulas raises a question: Are they interconnected, and can a unifying structure explain their relationships?\nWe propose a systematic methodology for discovering and proving formula equivalences, leveraging modern large language models, large-scale data processing, and novel mathematical algorithms. Analyzing 457,145 arXiv papers, over a third of the validated formulas for $\\pi$ were proven to be derivable from a single mathematical object - including formulas by Euler, Gauss, Lord Brouncker, and newer ones from algorithmic discoveries by the Ramanujan Machine.\nOur approach extends to other constants, such as $e$, $\\zeta(3)$, and Catalan's constant, proving its broad applicability. This work represents a step toward the automatic unification of mathematical knowledge, laying a foundation for AI-driven discoveries of connections across scientific domains.", 'abstract_zh': '圆周率π长久以来一直吸引着学者们的关注，激发了无数蕴含深刻数学洞察的公式推导。这些公式的丰富多样性引发了一个问题：它们之间是否存在联系，是否有一种统一的结构可以解释这些关系？\n我们提出了一种系统性方法来发现和证明公式等价性，利用现代大规模语言模型、大规模数据处理以及新型数学算法。分析了457,145篇arXiv论文，超过三分之一的已验证π公式都可以追溯到单一的数学对象——包括欧拉、高斯、布朗克爵士以及拉马努詹机器中新发现算法给出的公式。\n我们的方法还可以推广到其他常数，如e、ζ(3)和卡塔兰常数，证明了其广泛的应用性。这项工作朝着自动统一数学知识的方向迈进了一步，为基于AI的跨学科领域发现联系奠定了基础。', 'title_zh': '从欧拉到AI：数学常数的统一致公式'}
{'arxiv_id': 'arXiv:2502.17531', 'title': 'Laplace-Beltrami Operator for Gaussian Splatting', 'authors': 'Hongyu Zhou, Zorah Lähner', 'link': 'https://arxiv.org/abs/2502.17531', 'abstract': 'With the rising popularity of 3D Gaussian splatting and the expanse of applications from rendering to 3D reconstruction, there comes also a need for geometry processing applications directly on this new representation. While considering the centers of Gaussians as a point cloud or meshing them is an option that allows to apply existing algorithms, this might ignore information present in the data or be unnecessarily expensive. Additionally, Gaussian splatting tends to contain a large number of outliers which do not affect the rendering quality but need to be handled correctly in order not to produce noisy results in geometry processing applications. In this work, we propose a formulation to compute the Laplace-Beltrami operator, a widely used tool in geometry processing, directly on Gaussian splatting using the Mahalanobis distance. While conceptually similar to a point cloud Laplacian, our experiments show superior accuracy on the point clouds encoded in the Gaussian splatting centers and, additionally, the operator can be used to evaluate the quality of the output during optimization.', 'abstract_zh': '随着3D高斯簇集的 popularity 上升及其在渲染到 3D 重建等应用领域的扩展，对于这种新表示形式直接进行几何处理的应用需求也随之增加。虽然可以将高斯簇的中心视为点云或将它们网格化以便应用现有算法，但这可能会忽略数据中包含的信息，或者导致不必要的高价。此外，高斯簇集通常包含大量不影响渲染质量但需要在几何处理应用中正确处理的离群值。在本工作中，我们提出了一种直接在高斯簇集上计算拉普拉斯-贝尔特拉米算子的公式，利用马哈拉诺比斯距离。尽管从概念上类似于点云拉普拉斯算子，我们的实验表明，这种方法在编码于高斯簇集中点云上的准确度更优，此外，该算子还可以在优化过程中评估输出质量。', 'title_zh': '拉普拉斯-贝尔特拉米算子在高斯点云计算中的应用'}
{'arxiv_id': 'arXiv:2502.17527', 'title': 'Perceptual Noise-Masking with Music through Deep Spectral Envelope Shaping', 'authors': 'Clémentine Berger, Roland Badeau, Slim Essid', 'link': 'https://arxiv.org/abs/2502.17527', 'abstract': "People often listen to music in noisy environments, seeking to isolate themselves from ambient sounds. Indeed, a music signal can mask some of the noise's frequency components due to the effect of simultaneous masking. In this article, we propose a neural network based on a psychoacoustic masking model, designed to enhance the music's ability to mask ambient noise by reshaping its spectral envelope with predicted filter frequency responses. The model is trained with a perceptual loss function that balances two constraints: effectively masking the noise while preserving the original music mix and the user's chosen listening level. We evaluate our approach on simulated data replicating a user's experience of listening to music with headphones in a noisy environment. The results, based on defined objective metrics, demonstrate that our system improves the state of the art.", 'abstract_zh': '人们通常在嘈杂环境中听音乐，试图隔离环境噪音。实际上，音乐信号可以通过同时掩蔽效应掩盖部分噪声的频率成分。本文提出了一种基于心理声学掩蔽模型的神经网络，旨在通过预测滤波器频率响应重塑音乐的频谱包络，增强其掩蔽环境噪声的能力。该模型通过感知损失函数进行训练，平衡两个约束：有效掩蔽噪声同时保持原始音乐混音和用户选定的聆听水平。我们在模拟用户在嘈杂环境中通过耳机听音乐的经验数据上评估了该方法。基于定义的客观指标，结果表明我们的系统提升了现有技术的水平。', 'title_zh': '通过深度频谱包络整形实现音乐掩蔽感知噪声'}
{'arxiv_id': 'arXiv:2502.17518', 'title': 'Ensemble RL through Classifier Models: Enhancing Risk-Return Trade-offs in Trading Strategies', 'authors': 'Zheli Xiong', 'link': 'https://arxiv.org/abs/2502.17518', 'abstract': 'This paper presents a comprehensive study on the use of ensemble Reinforcement Learning (RL) models in financial trading strategies, leveraging classifier models to enhance performance. By combining RL algorithms such as A2C, PPO, and SAC with traditional classifiers like Support Vector Machines (SVM), Decision Trees, and Logistic Regression, we investigate how different classifier groups can be integrated to improve risk-return trade-offs. The study evaluates the effectiveness of various ensemble methods, comparing them with individual RL models across key financial metrics, including Cumulative Returns, Sharpe Ratios (SR), Calmar Ratios, and Maximum Drawdown (MDD). Our results demonstrate that ensemble methods consistently outperform base models in terms of risk-adjusted returns, providing better management of drawdowns and overall stability. However, we identify the sensitivity of ensemble performance to the choice of variance threshold {\\tau}, highlighting the importance of dynamic {\\tau} adjustment to achieve optimal performance. This study emphasizes the value of combining RL with classifiers for adaptive decision-making, with implications for financial trading, robotics, and other dynamic environments.', 'abstract_zh': '本文全面研究了集成强化学习（RL）模型在金融交易策略中的应用，通过结合A2C、PPO、SAC等RL算法与SVM、决策树、逻辑回归等传统分类器，探讨不同分类器组合如何改善风险收益权衡。研究评估了各种集成方法的有效性，并与单一RL模型在累计回报、夏普比率、卡马比率和最大回撤等关键金融指标上进行比较。结果表明，集成方法在风险调整回报方面始终优于基础模型，提供了更好的回撤管理和整体稳定性。然而，研究指出集成性能对方差阈值τ的选择高度敏感，强调了动态调整τ的重要性以实现最佳性能。本文强调了将RL与分类器结合用于自适应决策的价值，对金融交易、机器人技术和其他动态环境具有重要意义。', 'title_zh': '通过分类器模型的集成RL：优化交易策略中的风险收益权衡'}
{'arxiv_id': 'arXiv:2502.17515', 'title': 'Towards User-level Private Reinforcement Learning with Human Feedback', 'authors': 'Jiaming Zhang, Mingxi Lei, Meng Ding, Mengdi Li, Zihang Xiang, Difei Xu, Jinhui Xu, Di Wang', 'link': 'https://arxiv.org/abs/2502.17515', 'abstract': 'Reinforcement Learning with Human Feedback (RLHF) has emerged as an influential technique, enabling the alignment of large language models (LLMs) with human preferences. Despite the promising potential of RLHF, how to protect user preference privacy has become a crucial issue. Most previous work has focused on using differential privacy (DP) to protect the privacy of individual data. However, they have concentrated primarily on item-level privacy protection and have unsatisfactory performance for user-level privacy, which is more common in RLHF. This study proposes a novel framework, AUP-RLHF, which integrates user-level label DP into RLHF. We first show that the classical random response algorithm, which achieves an acceptable performance in item-level privacy, leads to suboptimal utility when in the user-level settings. We then establish a lower bound for the user-level label DP-RLHF and develop the AUP-RLHF algorithm, which guarantees $(\\varepsilon, \\delta)$ user-level privacy and achieves an improved estimation error. Experimental results show that AUP-RLHF outperforms existing baseline methods in sentiment generation and summarization tasks, achieving a better privacy-utility trade-off.', 'abstract_zh': '基于人类反馈的强化学习（RLHF）与用户偏好隐私保护：AUP-RLHF框架', 'title_zh': '面向用户的私有强化学习与人类反馈'}
{'arxiv_id': 'arXiv:2502.17514', 'title': 'SAE-V: Interpreting Multimodal Models for Enhanced Alignment', 'authors': 'Hantao Lou, Changye Li, Jiaming Ji, Yaodong Yang', 'link': 'https://arxiv.org/abs/2502.17514', 'abstract': "With the integration of image modality, the semantic space of multimodal large language models (MLLMs) is more complex than text-only models, making their interpretability more challenging and their alignment less stable, particularly susceptible to low-quality data, which can lead to inconsistencies between modalities, hallucinations, and biased outputs. As a result, developing interpretability methods for MLLMs is crucial for improving alignment quality and efficiency. In text-only LLMs, Sparse Autoencoders (SAEs) have gained attention for their ability to interpret latent representations. However, extending SAEs to multimodal settings presents new challenges due to modality fusion and the difficulty of isolating cross-modal representations. To address these challenges, we introduce SAE-V, a mechanistic interpretability framework that extends the SAE paradigm to MLLMs. By identifying and analyzing interpretable features along with their corresponding data, SAE-V enables fine-grained interpretation of both model behavior and data quality, facilitating a deeper understanding of cross-modal interactions and alignment dynamics. Moreover, by utilizing cross-modal feature weighting, SAE-V provides an intrinsic data filtering mechanism to enhance model alignment without requiring additional models. Specifically, when applied to the alignment process of MLLMs, SAE-V-based data filtering methods could achieve more than 110% performance with less than 50% data. Our results highlight SAE-V's ability to enhance interpretability and alignment in MLLMs, providing insights into their internal mechanisms.", 'abstract_zh': '基于图像的模态整合使多模态大规模语言模型（MLLMs）的语义空间更加复杂，这使得解释其行为更加具有挑战性，模型对齐也更加不稳定，特别容易受到低质量数据的影响，从而导致模态间不一致、幻觉和有偏输出。因此，开发针对MLLMs的解释性方法对于提高对齐质量和效率至关重要。在仅文本的大规模语言模型（text-only LLMs）中，稀疏自编码器（SAEs）由于其能够解释潜在表示的能力而备受关注。然而，将SAEs扩展到多模态设置中带来了新的挑战，这些挑战主要来自于模态融合和跨模态表示难以隔离。为了解决这些挑战，我们提出了SAE-V，这是一种基于机理的解释框架，将SAE范式扩展到MLLMs中。通过识别和分析可解释的特征及其对应的多模态数据，SAE-V能够对模型行为和数据质量进行精细解释，有助于更深入地理解跨模态交互和对齐动力学。此外，通过利用跨模态特征加权，SAE-V提供了一个内在的数据过滤机制，无需额外模型即可增强模型对齐。具体来说，在MLLMs的对齐过程中，基于SAE-V的数据过滤方法可以在少于50%数据的情况下达到超过110%的性能提升。我们的结果突显了SAE-V增强MLLMs解释性和对齐能力的能力，并提供了其内部机制的见解。', 'title_zh': 'SAE-V: 多模态模型的解释以提高对齐效果'}
{'arxiv_id': 'arXiv:2502.17513', 'title': 'Int2Int: a framework for mathematics with transformers', 'authors': 'François Charton', 'link': 'https://arxiv.org/abs/2502.17513', 'abstract': 'This paper documents Int2Int, an open source code base for using transformers on problems of mathematical research, with a focus on number theory and other problems involving integers. Int2Int is a complete PyTorch implementation of a transformer architecture, together with training and evaluation loops, and classes and functions to represent, generate and decode common mathematical objects. Ancillary code for data preparation, and Jupyter Notebooks for visualizing experimental results are also provided. This document presents the main features of Int2Int, serves as its user manual, and provides guidelines on how to extend it. Int2Int is released under the MIT licence, at this https URL.', 'abstract_zh': '本论文记录了Int2Int，一个用于数学研究问题的开源代码库，重点关注数论及其他涉及整数的问题。Int2Int是基于PyTorch的变压器架构的完整实现，并包含训练和评估循环，以及表示、生成和解码常见数学对象的类和函数。还提供了数据准备辅助代码和用于可视化实验结果的Jupyter Notebook。本文档介绍了Int2Int的主要功能，作为其用户手册，并提供了扩展它的指导。Int2Int在MIT许可证下发布，详见此处：https://github.com/int2int/int2int', 'title_zh': 'Int2Int：一种基于变换器的数学框架'}
{'arxiv_id': 'arXiv:2502.17505', 'title': 'Inverse Surrogate Model of a Soft X-Ray Spectrometer using Domain Adaptation', 'authors': 'Enrico Ahlers, Peter Feuer-Forson, Gregor Hartmann, Rolf Mitzner, Peter Baumgärtel, Jens Viefhaus', 'link': 'https://arxiv.org/abs/2502.17505', 'abstract': 'In this study, we present a method to create a robust inverse surrogate model for a soft X-ray spectrometer. During a beamtime at an electron storage ring, such as BESSY II, instrumentation and beamlines are required to be correctly aligned and calibrated for optimal experimental conditions. In order to automate these processes, machine learning methods can be developed and implemented, but in many cases these methods require the use of an inverse model which maps the output of the experiment, such as a detector image, to the parameters of the device. Due to limited experimental data, such models are often trained with simulated data, which creates the challenge of compensating for the inherent differences between simulation and experiment. In order to close this gap, we demonstrate the application of data augmentation and adversarial domain adaptation techniques, with which we can predict absolute coordinates for the automated alignment of our spectrometer. Bridging the simulation-experiment gap with minimal real-world data opens new avenues for automated experimentation using machine learning in scientific instrumentation.', 'abstract_zh': '在本研究中，我们提出了一种用于软X射线能谱仪的稳健逆代理模型的方法。在电子储存环（如BESSY II）的束流时间内，需要正确对准和校准仪器和光束线以获得最佳实验条件。为了自动化这些过程，可以开发和实施机器学习方法，但在很多情况下，这些方法需要使用逆模型将实验输出（如探测器图像）映射到设备参数。由于实验数据有限，通常需要使用模拟数据进行训练，这造成了模拟与实验之间固有差异的补偿挑战。为了弥合这一差距，我们展示了数据扩增和对抗域适应技术的应用，这些技术可以预测绝对坐标以实现对我们的能谱仪的自动化对准。使用少量实际数据弥合模拟与实验之间的差距为科学仪器中机器学习驱动的自动化实验开创了新的途径。', 'title_zh': '软X射线谱仪的域适应逆代理模型'}
{'arxiv_id': 'arXiv:2502.17503', 'title': 'Doctor-in-the-Loop: An Explainable, Multi-View Deep Learning Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer', 'authors': 'Alice Natalina Caragliano, Filippo Ruffini, Carlo Greco, Edy Ippolito, Michele Fiore, Claudia Tacconi, Lorenzo Nibid, Giuseppe Perrone, Sara Ramella, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2502.17503', 'abstract': "Non-small cell lung cancer (NSCLC) remains a major global health challenge, with high post-surgical recurrence rates underscoring the need for accurate pathological response predictions to guide personalized treatments. Although artificial intelligence models show promise in this domain, their clinical adoption is limited by the lack of medically grounded guidance during training, often resulting in non-explainable intrinsic predictions. To address this, we propose Doctor-in-the-Loop, a novel framework that integrates expert-driven domain knowledge with explainable artificial intelligence techniques, directing the model toward clinically relevant anatomical regions and improving both interpretability and trustworthiness. Our approach employs a gradual multi-view strategy, progressively refining the model's focus from broad contextual features to finer, lesion-specific details. By incorporating domain insights at every stage, we enhance predictive accuracy while ensuring that the model's decision-making process aligns more closely with clinical reasoning. Evaluated on a dataset of NSCLC patients, Doctor-in-the-Loop delivers promising predictive performance and provides transparent, justifiable outputs, representing a significant step toward clinically explainable artificial intelligence in oncology.", 'abstract_zh': '非小细胞肺癌（NSCLC）仍是一项重大的全球健康挑战，术后高复发率突显了需要准确的病理反应预测以指导个性化治疗的必要性。尽管人工智能模型在这一领域显示出潜力，但由于训练过程中缺乏医学依据的指导，其临床应用受到限制，常常导致不可解释的内在预测。为解决这一问题，我们提出了一种名为“医生在环”的新型框架，该框架将专家驱动的领域知识与可解释的人工智能技术相结合，使模型更关注临床相关解剖区域，并提高模型的可解释性和可信度。我们的方法采用逐步多视图策略，逐步细化模型对从宏观上下文特征到更精细、病灶特定细节的聚焦。通过在每个阶段都融入领域见解，我们增强了预测准确性，同时确保模型的决策过程与临床推理更一致。在NSCLC患者的数据库上进行评估，“医生在环”提供了令人鼓舞的预测性能，并提供了透明且可解释的输出，代表了在肿瘤学中实现临床可解释的人工智能的重要一步。', 'title_zh': '医生参与循环的解释性多视图深度学习框架：非小细胞肺癌病理反应预测'}
{'arxiv_id': 'arXiv:2502.17500', 'title': 'Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm', 'authors': 'Andrzej Cichocki', 'link': 'https://arxiv.org/abs/2502.17500', 'abstract': 'In this paper we propose and investigate a new class of Generalized Exponentiated Gradient (GEG) algorithms using Mirror Descent (MD) approaches, and applying as a regularization function the Bregman divergence with two-parameter deformation of logarithm as a link function. This link function (referred to as the Euler logarithm) is associated with a wide class of generalized entropies. In order to derive novel GEG/MD updates, we estimate generalized exponential function, which closely approximates the inverse of the Euler two-parameter logarithm. The characteristic/shape and properties of the Euler logarithm and its inverse -- deformed exponential functions are tuned by two or even more hyperparameters. By learning these hyperparameters, we can adapt to distribution of training data, and we can adjust them to achieve desired properties of gradient descent algorithms. The concept of generalized entropies and associated deformed logarithms provide deeper insight into novel gradient descent updates.\nIn literature, there exist nowadays over fifty mathematically well-defined entropic functionals and associated deformed logarithms, so impossible to investigate all of them in one research paper. Therefore, we focus here on a wide-class of trace-form entropies and associated generalized logarithm. We applied the developed algorithms for Online Portfolio Selection (OPLS) in order to improve its performance and robustness.', 'abstract_zh': '本文提出并研究了一类新的广义指数梯度（GEG）算法，该算法基于镜像下降（MD）方法，并使用带有两参数变形对数作为关联函数的Bregman发散作为正则化函数。该关联函数（称为欧拉对数）与一类广义熵相关。为了导出新的GEG/MD更新，我们估计广义指数函数，该函数紧密逼近欧拉两参数对数的逆函数。欧拉对数及其逆函数——变形指数函数的特点/形状和属性由两个或更多的超参数调节。通过学习这些超参数，可适应训练数据的分布，并可调整它们以实现梯度下降算法所需的特性。广义熵和相关的变形对数为新型梯度下降更新提供了更深层次的理解。\n\n文献中目前存在超过五十种数学上严格定义的熵泛函及相关变形对数，因此在一篇研究论文中无法全面调查它们。因此，本文集中在一类迹形式熵及其相关的广义对数上。我们开发的算法应用于在线组合选择（OPLS）以提高其性能和鲁棒性。', 'title_zh': '广义指数梯度算法使用欧拉两参数对数函数'}
{'arxiv_id': 'arXiv:2502.17499', 'title': 'Accuracy of Wearable ECG Parameter Calculation Method for Long QT and First-Degree A-V Block Detection: A Multi-Center Real-World Study with External Validations Compared to Standard ECG Machines and Cardiologist Assessments', 'authors': 'Sumei Fan, Deyun Zhang, Yue Wang, Shijia Geng, Kun Lu, Meng Sang, Weilun Xu, Haixue Wang, Qinghao Zhao, Chuandong Cheng, Peng Wang, Shenda Hong', 'link': 'https://arxiv.org/abs/2502.17499', 'abstract': 'In recent years, wearable devices have revolutionized cardiac monitoring by enabling continuous, non-invasive ECG recording in real-world settings. Despite these advances, the accuracy of ECG parameter calculations (PR interval, QRS interval, QT interval, etc.) from wearables remains to be rigorously validated against conventional ECG machines and expert clinician assessments. In this large-scale, multicenter study, we evaluated FeatureDB, a novel algorithm for automated computation of ECG parameters from wearable single-lead signals Three diverse datasets were employed: the AHMU-FH dataset (n=88,874), the CSE dataset (n=106), and the HeartVoice-ECG-lite dataset (n=369) with annotations provided by two experienced cardiologists. FeatureDB demonstrates a statistically significant correlation with key parameters (PR interval, QRS duration, QT interval, and QTc) calculated by standard ECG machines and annotated by clinical doctors. Bland-Altman analysis confirms a high level of this http URL,FeatureDB exhibited robust diagnostic performance in detecting Long QT syndrome (LQT) and atrioventricular block interval abnormalities (AVBI),with excellent area under the ROC curve (LQT: 0.836, AVBI: 0.861),accuracy (LQT: 0.856, AVBI: 0.845),sensitivity (LQT: 0.815, AVBI: 0.877),and specificity (LQT: 0.856, AVBI: 0.845).This further validates its clinical reliability. These results validate the clinical applicability of FeatureDB for wearable ECG analysis and highlight its potential to bridge the gap between traditional diagnostic methods and emerging wearable this http URL,this study supports integrating wearable ECG devices into large-scale cardiovascular disease management and early intervention strategies,and it highlights the potential of wearable ECG technologies to deliver accurate,clinically relevant cardiac monitoring while advancing broader applications in cardiovascular care.', 'abstract_zh': '穿戴设备在心电图参数计算中的准确性和临床应用：FeatureDB算法在大型多中心研究中的评估', 'title_zh': '穿戴式ECG参数计算方法用于长QT和一度房室传导阻滞检测的准确性：一项多中心真实世界研究，并与标准ECG机器及心脏病专家评估进行外部验证'}
{'arxiv_id': 'arXiv:2502.17493', 'title': 'Pursuing Top Growth with Novel Loss Function', 'authors': 'Ruoyu Guo, Haochen Qiu', 'link': 'https://arxiv.org/abs/2502.17493', 'abstract': "Making consistently profitable financial decisions in a continuously evolving and volatile stock market has always been a difficult task. Professionals from different disciplines have developed foundational theories to anticipate price movement and evaluate securities such as the famed Capital Asset Pricing Model (CAPM). In recent years, the role of artificial intelligence (AI) in asset pricing has been growing. Although the black-box nature of deep learning models lacks interpretability, they have continued to solidify their position in the financial industry. We aim to further enhance AI's potential and utility by introducing a return-weighted loss function that will drive top growth while providing the ML models a limited amount of information. Using only publicly accessible stock data (open/close/high/low, trading volume, sector information) and several technical indicators constructed from them, we propose an efficient daily trading system that detects top growth opportunities. Our best models achieve 61.73% annual return on daily rebalancing with an annualized Sharpe Ratio of 1.18 over 1340 testing days from 2019 to 2024, and 37.61% annual return with an annualized Sharpe Ratio of 0.97 over 1360 testing days from 2005 to 2010. The main drivers for success, especially independent of any domain knowledge, are the novel return-weighted loss function, the integration of categorical and continuous data, and the ML model architecture. We also demonstrate the superiority of our novel loss function over traditional loss functions via several performance metrics and statistical evidence.", 'abstract_zh': '在不断变化和波动的股票市场上做出一致盈利的金融决策一直是一项艰巨的任务。来自不同学科的专业人士开发了基础理论来预测价格波动和评估证券，例如著名的资本资产定价模型（CAPM）。近年来，人工智能（AI）在资产定价中的作用日益增长。尽管深度学习模型的黑箱性质缺乏解释性，它们在金融行业中的地位仍然得到了巩固。我们通过引入一种基于收益加权的损失函数来进一步增强AI的潜力和实用性，该函数将驱动顶级增长同时为ML模型提供有限的信息。仅使用公开可获取的股票数据（开盘价/收盘价/最高价/最低价、交易量、行业信息）以及从中构建的若干技术指标，我们提出了一种高效的每日交易系统，以检测顶级增长机会。我们的最佳模型在2019年至2024年的1340个测试日实现了年化61.73%的回报率和年化Sharpe比率1.18，在2005年至2010年的1360个测试日实现了年化37.61%的回报率和年化Sharpe比率0.97。尤其是在没有领域知识的情况下，成功的主要驱动因素是新颖的收益加权损失函数、类别数据和连续数据的整合以及ML模型架构。我们还通过多种性能指标和统计证据展示了我们新型损失函数相对于传统损失函数的优势。', 'title_zh': '追求新型损失函数下的顶级增长'}
{'arxiv_id': 'arXiv:2502.17490', 'title': 'A generalized dual potential for inelastic Constitutive Artificial Neural Networks: A JAX implementation at finite strains', 'authors': 'Hagen Holthusen, Kevin Linka, Ellen Kuhl, Tim Brepols', 'link': 'https://arxiv.org/abs/2502.17490', 'abstract': "We present a methodology for designing a generalized dual potential, or pseudo potential, for inelastic Constitutive Artificial Neural Networks (iCANNs). This potential, expressed in terms of stress invariants, inherently satisfies thermodynamic consistency for large deformations. In comparison to our previous work, the new potential captures a broader spectrum of material behaviors, including pressure-sensitive inelasticity.\nTo this end, we revisit the underlying thermodynamic framework of iCANNs for finite strain inelasticity and derive conditions for constructing a convex, zero-valued, and non-negative dual potential. To embed these principles in a neural network, we detail the architecture's design, ensuring a priori compliance with thermodynamics.\nTo evaluate the proposed architecture, we study its performance and limitations discovering visco-elastic material behavior, though the method is not limited to visco-elasticity. In this context, we investigate different aspects in the strategy of discovering inelastic materials. Our results indicate that the novel architecture robustly discovers interpretable models and parameters, while autonomously revealing the degree of inelasticity.\nThe iCANN framework, implemented in JAX, is publicly accessible at this https URL.", 'abstract_zh': '一种广义双重势能的设计方法：应用于不可积Artificial Neural Networks的非弹性行为', 'title_zh': '广义对偶势函数在有限应变下对非弹性本构人工神经网络的应用：基于JAX的实现'}
{'arxiv_id': 'arXiv:2502.17489', 'title': 'Using Graph Convolutional Networks to Address fMRI Small Data Problems', 'authors': 'Thomas Screven, Andras Necz, Jason Smucny, Ian Davidson', 'link': 'https://arxiv.org/abs/2502.17489', 'abstract': "Although great advances in the analysis of neuroimaging data have been made, a major challenge is a lack of training data. This is less problematic in tasks such as diagnosis, where much data exists, but particularly prevalent in harder problems such as predicting treatment responses (prognosis), where data is focused and hence limited. Here, we address the learning from small data problems for medical imaging using graph neural networks. This is particularly challenging as the information about the patients is themselves graphs (regions of interest connectivity graphs). We show how a spectral representation of the connectivity data allows for efficient propagation that can yield approximately 12\\% improvement over traditional deep learning methods using the exact same data. We show that our method's superior performance is due to a data smoothing result that can be measured by closing the number of triangle inequalities and thereby satisfying transitivity.", 'abstract_zh': '尽管在神经影像数据分析方面取得了巨大进展，但训练数据不足仍然是一个主要挑战。在诊断这类任务中，由于数据丰富，这一问题较不突出，但在预测治疗反应（预后）这类更难的问题中，数据集中且有限，问题尤为突出。为了解决小数据学习问题，我们使用图神经网络处理医学影像。由于患者信息本身即为图（感兴趣区域连接图），这一问题尤为具有挑战性。我们展示了如何通过谱表示连接数据来实现高效传播，这可以使我们的方法在使用相同数据的情况下，比传统深度学习方法性能提高约12%。我们证明，我们的方法性能优越的原因在于一种数据平滑效果，这可以通过减少三角不等式的数量来衡量，并因此满足传递性。', 'title_zh': '使用图卷积网络解决fMRI小数据问题'}
{'arxiv_id': 'arXiv:2502.17480', 'title': 'Brain-to-Text Decoding: A Non-invasive Approach via Typing', 'authors': "Jarod Lévy, Mingfang Zhang, Svetlana Pinet, Jérémy Rapin, Hubert Banville, Stéphane d'Ascoli, Jean-Rémi King", 'link': 'https://arxiv.org/abs/2502.17480', 'abstract': 'Modern neuroprostheses can now restore communication in patients who have lost the ability to speak or move. However, these invasive devices entail risks inherent to neurosurgery. Here, we introduce a non-invasive method to decode the production of sentences from brain activity and demonstrate its efficacy in a cohort of 35 healthy volunteers. For this, we present Brain2Qwerty, a new deep learning architecture trained to decode sentences from either electro- (EEG) or magneto-encephalography (MEG), while participants typed briefly memorized sentences on a QWERTY keyboard. With MEG, Brain2Qwerty reaches, on average, a character-error-rate (CER) of 32% and substantially outperforms EEG (CER: 67%). For the best participants, the model achieves a CER of 19%, and can perfectly decode a variety of sentences outside of the training set. While error analyses suggest that decoding depends on motor processes, the analysis of typographical errors suggests that it also involves higher-level cognitive factors. Overall, these results narrow the gap between invasive and non-invasive methods and thus open the path for developing safe brain-computer interfaces for non-communicating patients.', 'abstract_zh': '非侵入性方法从脑活动解码句子以恢复沟通：一项在35名健康志愿者中的有效性演示', 'title_zh': '脑到文本解码：一种通过打字的无侵入性方法'}
{'arxiv_id': 'arXiv:2502.17475', 'title': 'ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis', 'authors': 'Xu Wang, Jiaju Kang, Puyu Han', 'link': 'https://arxiv.org/abs/2502.17475', 'abstract': "We present ECG-Expert-QA, a comprehensive multimodal dataset designed for evaluating diagnostic capabilities in ECG interpretation, integrating real clinical data with systematically generated synthetic cases. The dataset encompasses six fundamental diagnostic tasks, comprising 47,211 meticulously curated question-answer pairs that span a spectrum of clinical scenarios, from basic rhythm analysis to complex case interpretation. By simulating challenging clinical cases through a rigorous medical knowledge-guided process, ECG-Expert-QA not only enhances the availability of annotated diagnostic data but also significantly increases the complexity and diversity of clinical presentations, including rare cardiac conditions and temporal progression patterns. This design enables comprehensive evaluation of medical language models across multiple dimensions, including diagnostic accuracy, clinical reasoning, and knowledge integration. To facilitate global research collaboration, ECG-Expert-QA is available in both Chinese and English versions, with rigorous quality control ensuring linguistic and clinical consistency. The dataset's challenging diagnostic tasks, which include interpretation of complex arrhythmias, identification of subtle ischemic changes, and integration of clinical context, establish it as an effective benchmark for advancing AI-assisted ECG interpretation and pushing the boundaries of current diagnostic models. Our dataset is open-source and available at this https URL.", 'abstract_zh': 'ECG-Expert-QA：一个全面的多模态数据集，用于评估ECG解释的诊断能力，结合实际临床数据与系统生成的合成病例。', 'title_zh': 'ECG-Expert-QA：用于心脏疾病诊断的大规模语言模型评估基准'}
{'arxiv_id': 'arXiv:2502.17469', 'title': 'PixleepFlow: A Pixel-Based Lifelog Framework for Predicting Sleep Quality and Stress Level', 'authors': 'Younghoon Na', 'link': 'https://arxiv.org/abs/2502.17469', 'abstract': "The analysis of lifelogs can yield valuable insights into an individual's daily life, particularly with regard to their health and well-being. The accurate assessment of quality of life is necessitated by the use of diverse sensors and precise synchronization. To rectify this issue, this study proposes the image-based sleep quality and stress level estimation flow (PixleepFlow). PixleepFlow employs a conversion methodology into composite image data to examine sleep patterns and their impact on overall health. Experiments were conducted using lifelog datasets to ascertain the optimal combination of data formats. In addition, we identified which sensor information has the greatest influence on the quality of life through Explainable Artificial Intelligence(XAI). As a result, PixleepFlow produced more significant results than various data formats. This study was part of a written-based competition, and the additional findings from the lifelog dataset are detailed in Section Section IV. More information about PixleepFlow can be found at this https URL.", 'abstract_zh': '基于图像的睡眠质量和压力水平估计流程（PixleepFlow）对日常生活的影响分析', 'title_zh': '基于像素的 lifelog 框架：预测睡眠质量与压力水平'}
{'arxiv_id': 'arXiv:2502.17462', 'title': 'The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG', 'authors': 'Francesco Stefano Carzaniga, Gary Tom Hoppeler, Michael Hersche, Kaspar Anton Schindler, Abbas Rahimi', 'link': 'https://arxiv.org/abs/2502.17462', 'abstract': 'All data modalities are not created equal, even when the signal they measure comes from the same source. In the case of the brain, two of the most important data modalities are the scalp electroencephalogram (EEG), and the intracranial electroencephalogram (iEEG). They are used by human experts, supported by deep learning (DL) models, to accomplish a variety of tasks, such as seizure detection and motor imagery classification. Although the differences between EEG and iEEG are well understood by human experts, the performance of DL models across these two modalities remains under-explored. To help characterize the importance of clean data on the performance of DL models, we propose BrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that training BrainCodec on iEEG and then transferring to EEG yields higher reconstruction quality than training on EEG directly. In addition, we also find that training BrainCodec on both EEG and iEEG improves fidelity when reconstructing EEG. Our work indicates that data sources with higher SNR, such as iEEG, provide better performance across the board also in the medical time-series domain. BrainCodec also achieves up to a 64x compression on iEEG and EEG without a notable decrease in quality. BrainCodec markedly surpasses current state-of-the-art compression models both in final compression ratio and in reconstruction fidelity. We also evaluate the fidelity of the compressed signals objectively on a seizure detection and a motor imagery task performed by standard DL models. Here, we find that BrainCodec achieves a reconstruction fidelity high enough to ensure no performance degradation on the downstream tasks. Finally, we collect the subjective assessment of an expert neurologist, that confirms the high reconstruction quality of BrainCodec in a realistic scenario. The code is available at this https URL.', 'abstract_zh': '不同类型的脑电数据并非同等重要，即使它们源自相同的源。在大脑成像中，头皮脑电图（EEG）和颅内脑电图（iEEG）是最为重要的两种数据模态。人类专家和深度学习（DL）模型利用这些数据模态完成各种任务，例如癫痫检测和运动想象分类。尽管人类专家对EEG和iEEG之间的差异有深入的理解，但这些两种模态下DL模型的性能尚待探索。为了帮助确定干净数据对DL模型性能的重要性，我们提出了脑编码器（BrainCodec），一种高保真EEG和iEEG神经压缩器。我们发现，使用iEEG训练BrainCodec然后转换到EEG进行训练，可以得到比直接使用EEG训练更高的重建质量。此外，我们还发现，使用EEG和iEEG两种数据模态训练BrainCodec，可以提高重建EEG的保真度。我们的研究结果显示，信噪比更高的数据源，如iEEG，在医学时间序列领域也能提供更优的整体性能。BrainCodec在iEEG和EEG上的压缩比高达64倍，同时保真度无明显下降。BrainCodec在最终压缩比和重建保真度上均显著优于当前最先进的压缩模型。我们还客观地评估了标准DL模型执行的癫痫检测和运动想象任务中压缩信号的保真度。结果显示，BrainCodec的重建保真度足够高，以确保下游任务的性能不受影响。最后，我们收集了一名专家神经学家的主观评估，证实了BrainCodec在实际场景中的高重建质量。代码可在以下链接获取。', 'title_zh': 'cleaner 生物信号的重要性：高保真神经压缩器使 cleaner iEEG 能够向 noisier EEG 转移'}
{'arxiv_id': 'arXiv:2502.17460', 'title': 'Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation', 'authors': 'Bálint Tóth, Dominik Senti, Thorir Mar Ingolfsson, Jeffrey Zweidler, Alexandre Elsig, Luca Benini, Yawei Li', 'link': 'https://arxiv.org/abs/2502.17460', 'abstract': 'Blood pressure (BP) is a key indicator of cardiovascular health. As hypertension remains a global cause of morbidity and mortality, accurate, continuous, and non-invasive BP monitoring is therefore of paramount importance. Photoplethysmography (PPG) and electrocardiography (ECG) can potentially enable continuous BP monitoring, yet training accurate and robust machine learning (ML) models remains challenging due to variability in data quality and patient-specific factors. Recently, multiple research groups explored Electroencephalographic (EEG)--based foundation models and demonstrated their exceptional ability to learn rich temporal resolution. Considering the morphological similarities between different biosignals, the question arises of whether a model pre-trained on one modality can effectively be exploited to improve the accuracy of a different signal type. In this work, we take an initial step towards generalized biosignal foundation models by investigating whether model representations learned from abundant EEG data can effectively be transferred to ECG/PPG data solely with fine-tuning, without the need for large-scale additional pre-training, for the BP estimation task. Evaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach achieves near state-of-the-art accuracy for diastolic BP (mean absolute error of 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP (mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8 quantization, reducing the smallest model size by over 3.5x (from 13.73 MB down to 3.83 MB) while preserving performance, thereby enabling unobtrusive, real-time BP monitoring on resource-constrained wearable devices.', 'abstract_zh': '基于脑电图的通用生物信号基础模型：EditTextlightlyadaptedfromabundanteegdatatofine-tuneecg/ppgdatasforbloodpressureestimation', 'title_zh': '基于EEG的生物信号基础模型在ECG和PPG数据上的微调与量化以估计血压'}
{'arxiv_id': 'arXiv:2502.17457', 'title': 'MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition', 'authors': 'Mehran Shabanpour, Kasra Rad, Sadaf Khademi, Arash Mohammadi', 'link': 'https://arxiv.org/abs/2502.17457', 'abstract': "High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework's robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.", 'abstract_zh': '高密度表面肌电图（HDsEMG）在人机交互（HCI）中的新兴资源及其MoEMba框架：利用选择性状态空间模型提升手势识别', 'title_zh': 'MoEMba：一种基于Mamba的专家混合模型高密度EMG_hand手势识别'}
{'arxiv_id': 'arXiv:2502.17456', 'title': 'Survey on Recent Progress of AI for Chemistry: Methods, Applications, and Opportunities', 'authors': 'Ding Hu, Pengxiang Hua, Zhen Huang', 'link': 'https://arxiv.org/abs/2502.17456', 'abstract': 'The development of artificial intelligence (AI) techniques has brought revolutionary changes across various realms. In particular, the use of AI-assisted methods to accelerate chemical research has become a popular and rapidly growing trend, leading to numerous groundbreaking works. In this paper, we provide a comprehensive review of current AI techniques in chemistry from a computational perspective, considering various aspects in the design of methods. We begin by discussing the characteristics of data from diverse sources, followed by an overview of various representation methods. Next, we review existing models for several topical tasks in the field, and conclude by highlighting some key challenges that warrant further attention.', 'abstract_zh': '人工智能技术的发展在各个领域带来了革命性的变化，特别是AI辅助方法加速化学研究已成为一个流行且迅速增长的趋势，产生了众多开创性的工作。本文从计算视角对当前化学中的AI技术进行了全面回顾，考虑了方法设计的各个方面。首先讨论来自各种来源的数据特性，随后概述各种表示方法，接着回顾了该领域几个专题任务的现有模型，并最后强调了一些值得进一步关注的关键挑战。', 'title_zh': '近期AI在化学领域进展调研：方法、应用及机遇'}
{'arxiv_id': 'arXiv:2502.17454', 'title': 'Smart Sampling Strategies for Wireless Industrial Data Acquisition', 'authors': 'Marcos Soto', 'link': 'https://arxiv.org/abs/2502.17454', 'abstract': 'In industrial environments, data acquisition accuracy is crucial for process control and optimization. Wireless telemetry has proven to be a valuable tool for improving efficiency in well-testing operations, enabling bidirectional communication and real-time control of downhole tools. However, high sampling frequencies present challenges in telemetry, including data storage, transmission, computational resource consumption, and battery life of wireless devices. This study explores how optimizing data acquisition strategies can reduce aliasing effects and systematic errors while improving sampling rates without compromising measurement accuracy. A reduction of 80% in sampling frequency was achieved without degrading measurement quality, demonstrating the potential for resource optimization in industrial environments.', 'abstract_zh': '在工业环境中的数据采集精度对于过程控制和优化至关重要。无线遥测已被证明是提高油井测试操作效率的有效工具，能够实现双向通信和井下工具的实时控制。然而，高采样频率给遥测带来了挑战，包括数据存储、传输、计算资源消耗以及无线设备的电池寿命。本研究探讨了如何通过优化数据采集策略来减少抽样频率、降低aliasing效应和系统误差，同时提高采样率而不牺牲测量精度。结果表明，可以在不降低测量质量的情况下将采样频率减少80%，展示了在工业环境中资源优化的潜力。', 'title_zh': '智能无线工业数据采集的智能采样策略'}
{'arxiv_id': 'arXiv:2502.17447', 'title': "AirTag, You're It: Reverse Logistics and Last Mile Dynamics", 'authors': 'David Noever, Forrest McKee', 'link': 'https://arxiv.org/abs/2502.17447', 'abstract': 'This study addresses challenges in reverse logistics, a frequently overlooked but essential component of last-mile delivery, particularly in disaster relief scenarios where infrastructure disruptions demand adaptive solutions. While hub-and-spoke logistics networks excel at long-distance scalability, they often fail to optimize closely spaced spokes reliant on distant hubs, introducing inefficiencies in transit times and resource allocation. Using 20 Apple AirTags embedded in packages, this research provides empirical insights into logistical flows, capturing granular spatial and temporal data through Bluetooth LE (BLE) 5 trackers integrated with the Apple Find My network. These trackers demonstrated their value in monitoring dynamic cargo movements, enabling real-time adjustments in mobile hub placement and route optimization, particularly in disaster relief contexts like Hurricane Helene. A novel application of discrete event simulation (DES) further explored the saddle point in hub-spoke configurations, where excessive hub reliance clashes with diminishing spoke interaction demand. By coupling simulation results with empirical AirTag tracking, the study highlights the potential of BLE technology to refine reverse logistics, reduce delays, and improve operational flexibility in both routine and crisis-driven delivery networks.', 'abstract_zh': '本研究探讨了逆向物流面临的挑战，这是getLastmile配送中一个经常被忽视但至关重要的组成部分，特别是在基础设施中断需求适应性解决方案的灾后救援场景中。尽管枢纽和辐条物流网络在长距离方面表现出色，但在优化紧密布设而依赖远端枢纽的辐条时，它们往往引入了传输时间和资源配置的低效率。利用20个集成在包裹中的Apple AirTags，本研究提供了实证见解，通过BLE 5追踪器集成Apple Find My网络捕获了详细的时空数据。这些追踪器展示了其在监测动态货物移动中的价值，允许在移动枢纽放置和路线优化方面进行实时调整，特别是在飓风海伦这样的灾后救援情境中。通过将离散事件模拟（DES）与新型应用相结合，进一步探讨了枢纽和辐条配置中的鞍点，即过度依赖枢纽与辐条间互动需求下降之间的冲突。通过将模拟结果与AirTag追踪数据结合，本研究突显了BLE技术在改进逆向物流、减少延误以及提高常规和危机驱动配送网络操作灵活性方面的潜力。', 'title_zh': 'AirTag,你负责：逆向物流与最后一公里动态'}
{'arxiv_id': 'arXiv:2502.17446', 'title': 'DCentNet: Decentralized Multistage Biomedical Signal Classification using Early Exits', 'authors': 'Xiaolin Li, Binhua Huang, Barry Cardiff, Deepu John', 'link': 'https://arxiv.org/abs/2502.17446', 'abstract': 'DCentNet is a novel decentralized multistage signal classification approach designed for biomedical data from IoT wearable sensors, integrating early exit points (EEP) to enhance energy efficiency and processing speed. Unlike traditional centralized processing methods, which result in high energy consumption and latency, DCentNet partitions a single CNN model into multiple sub-networks using EEPs. By introducing encoder-decoder pairs at EEPs, the system compresses large feature maps before transmission, significantly reducing wireless data transfer and power usage. If an input is confidently classified at an EEP, processing stops early, optimizing efficiency. Initial sub-networks can be deployed on fog or edge devices to further minimize energy consumption. A genetic algorithm is used to optimize EEP placement, balancing performance and complexity. Experimental results on ECG classification show that with one EEP, DCentNet reduces wireless data transmission by 94.54% and complexity by 21%, while maintaining original accuracy and sensitivity. With two EEPs, sensitivity reaches 98.36%, accuracy 97.74%, wireless data transmission decreases by 91.86%, and complexity is reduced by 22%. Implemented on an ARM Cortex-M4 MCU, DCentNet achieves an average power saving of 73.6% compared to continuous wireless ECG transmission.', 'abstract_zh': 'DCentNet：一种集成早期退出点的分散多阶段生物医学信号分类方法', 'title_zh': 'DCentNet: 分布式多阶段生物医学信号分类方法及早退出'}
{'arxiv_id': 'arXiv:2502.17445', 'title': 'Interpretable Dual-Filter Fuzzy Neural Networks for Affective Brain-Computer Interfaces', 'authors': 'Xiaowei Jiang, Yanan Chen, Nikhil Ranjan Pal, Yu-Cheng Chang, Yunkai Yang, Thomas Do, Chin-Teng Lin', 'link': 'https://arxiv.org/abs/2502.17445', 'abstract': 'Fuzzy logic provides a robust framework for enhancing explainability, particularly in domains requiring the interpretation of complex and ambiguous signals, such as brain-computer interface (BCI) systems. Despite significant advances in deep learning, interpreting human emotions remains a formidable challenge. In this work, we present iFuzzyAffectDuo, a novel computational model that integrates a dual-filter fuzzy neural network architecture for improved detection and interpretation of emotional states from neuroimaging data. The model introduces a new membership function (MF) based on the Laplace distribution, achieving superior accuracy and interpretability compared to traditional approaches. By refining the extraction of neural signals associated with specific emotions, iFuzzyAffectDuo offers a human-understandable framework that unravels the underlying decision-making processes. We validate our approach across three neuroimaging datasets using functional Near-Infrared Spectroscopy (fNIRS) and Electroencephalography (EEG), demonstrating its potential to advance affective computing. These findings open new pathways for understanding the neural basis of emotions and their application in enhancing human-computer interaction.', 'abstract_zh': '模糊逻辑提供了一种增强可解释性的坚实框架，特别是在需要解释复杂和模糊信号的领域，如脑机接口（BCI）系统。尽管深度学习取得了显著进展，但解释人类情感仍然是一个艰巨的挑战。在此项工作中，我们提出了iFuzzyAffectDuo，一种新颖的计算模型，该模型结合了双滤波模糊神经网络架构，以提高情绪状态从神经影像数据中检测和解释的准确性与可解释性。该模型引入了基于拉普拉斯分布的新隶属函数（MF），其准确性和可解释性优于传统方法。通过细化与特定情绪相关的神经信号提取，iFuzzyAffectDuo 提供了一种人类可理解的框架，揭示了潜在的决策过程。我们使用功能性近红外光谱成像（fNIRS）和脑电图（EEG）的三个神经影像数据集验证了该方法，展示了其在促进情感计算方面的潜力。这些发现为理解情绪的神经基础及其在增强人机交互中的应用开辟了新的途径。', 'title_zh': '可解释的双滤波模糊神经网络在情绪脑机接口中的应用'}
{'arxiv_id': 'arXiv:2502.17443', 'title': 'AI Agentic workflows and Enterprise APIs: Adapting API architectures for the age of AI agents', 'authors': 'Vaibhav Tupe, Shrinath Thube', 'link': 'https://arxiv.org/abs/2502.17443', 'abstract': "The rapid advancement of Generative AI has catalyzed the emergence of autonomous AI agents, presenting unprecedented challenges for enterprise computing infrastructures. Current enterprise API architectures are predominantly designed for human-driven, predefined interaction patterns, rendering them ill-equipped to support intelligent agents' dynamic, goal-oriented behaviors. This research systematically examines the architectural adaptations for enterprise APIs to support AI agentic workflows effectively. Through a comprehensive analysis of existing API design paradigms, agent interaction models, and emerging technological constraints, the paper develops a strategic framework for API transformation. The study employs a mixed-method approach, combining theoretical modeling, comparative analysis, and exploratory design principles to address critical challenges in standardization, performance, and intelligent interaction. The proposed research contributes a conceptual model for next-generation enterprise APIs that can seamlessly integrate with autonomous AI agent ecosystems, offering significant implications for future enterprise computing architectures.", 'abstract_zh': '生成式人工智能的快速发展催生了自主人工智能代理的出现，为企业计算基础设施带来了前所未有的挑战。当前的企业API架构主要针对由人类驱动的预定义交互模式设计，使其无法有效支持智能代理的动态、目标导向的行为。本文系统地探讨了企业API架构的适配，以有效支持人工智能代理工作流。通过全面分析现有的API设计范式、代理交互模型和新兴的技术约束，该论文提出了API转型的战略框架。研究采用了混合方法，结合理论建模、比较分析和探索性设计原则，以应对标准制定、性能和智能交互的关键挑战。提出的研究所提供的概念模型可以无缝集成到自主人工智能代理生态系统中，并对未来的企业计算架构具有重要意义。', 'title_zh': 'AI代理工作流与企业API：适应AI代理时代的数据架构适配'}
