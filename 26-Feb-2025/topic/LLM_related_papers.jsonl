{'arxiv_id': 'arXiv:2502.17529', 'title': 'ConvoyLLM: Dynamic Multi-Lane Convoy Control Using LLMs', 'authors': 'Liping Lu, Zhican He, Duanfeng Chu, Rukang Wang, Saiqian Peng, Pan Zhou', 'link': 'https://arxiv.org/abs/2502.17529', 'abstract': 'This paper proposes a novel method for multi-lane convoy formation control that uses large language models (LLMs) to tackle coordination challenges in dynamic highway environments. Each connected and autonomous vehicle in the convoy uses a knowledge-driven approach to make real-time adaptive decisions based on various scenarios. Our method enables vehicles to dynamically perform tasks, including obstacle avoidance, convoy joining/leaving, and escort formation switching, all while maintaining the overall convoy structure. We design a Interlaced formation control strategy based on locally dynamic distributed graphs, ensuring the convoy remains stable and flexible. We conduct extensive experiments in the SUMO simulation platform across multiple traffic scenarios, and the results demonstrate that the proposed method is effective, robust, and adaptable to dynamic environments. The code is available at: this https URL.', 'abstract_zh': '本文提出了一种使用大型语言模型（LLMs）解决动态高速公路上多车道车队编队控制协调难题的新方法。每辆连接的自动驾驶车辆使用知识驱动的方法，根据各种场景做出实时适应性决策。我们的方法使车辆能够动态执行包括障碍物避免、车队加入/离开以及护航编队切换等任务，同时保持整个车队结构的稳定。我们设计了一种基于局部动态分散图的穿插编队控制策略，确保车队保持稳定和灵活性。我们在SUMO仿真平台上对多种交通场景进行了广泛的实验，结果表明所提出的方法是有效的、 robust的，并且能够适应动态环境。代码可在以下链接获取：this https URL。', 'title_zh': 'ConvoyLLM：使用大规模语言模型进行动态多车道车队控制'}
{'arxiv_id': 'arXiv:2502.18439', 'title': 'MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning', 'authors': 'Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman Ozdaglar, Kaiqing Zhang, Joo-Kyung Kim', 'link': 'https://arxiv.org/abs/2502.18439', 'abstract': "Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.", 'abstract_zh': '利用多个大型语言模型（LLMs）构建协作多代理工作流表现出显著潜力。然而，大多数前期研究主要关注通过提示开箱即用的LLMs，依赖其固有的协作能力，这可能并未如近期所显示的那样改善LLMs的表现。本文介绍了一种新的后训练范式MAPoRL（多代理后共训练以强化学习促进协同LLMs），以明确激发协同行为并进一步释放多代理LLMs框架的力量。在MAPoRL中，多个LLMs首先独立生成自己的响应，并进行多轮讨论以合作提高最终答案。最后，一个MAPoRL验证器通过分配验证答案正确性的分数来评估答案和讨论，同时通过鼓励纠正性和说服性的讨论来增强激励机制。该分数作为共训练奖励，并通过多代理强化学习进行最大化。与现有的LLM后训练范式不同，MAPoRL提倡使用强化学习共同训练多个LLMs以获得更好的泛化能力。我们的实验分析表明，单独训练单个LLM不足以引发有效的协作。相比之下，多代理共训练可以在各种基准测试中提升协作性能，并扩展到未见过的领域。', 'title_zh': 'MAPoRL: 多智能体共训练后微调促进合作型大规模语言模型的强化学习方法'}
{'arxiv_id': 'arXiv:2502.18387', 'title': 'How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities', 'authors': 'Minhua Lin, Hui Liu, Xianfeng Tang, Jingying Zeng, Zhenwei Dai, Chen Luo, Zheng Li, Xiang Zhang, Qi He, Suhang Wang', 'link': 'https://arxiv.org/abs/2502.18387', 'abstract': "Search plays a fundamental role in problem-solving across various domains, with most real-world decision-making problems being solvable through systematic search. Drawing inspiration from recent discussions on search and learning, we systematically explore the complementary relationship between search and Large Language Models (LLMs) from three perspectives. First, we analyze how learning can enhance search efficiency and propose Search via Learning (SeaL), a framework that leverages LLMs for effective and efficient search. Second, we further extend SeaL to SeaL-C to ensure rigorous completeness during search. Our evaluation across three real-world planning tasks demonstrates that SeaL achieves near-perfect accuracy while reducing search spaces by up to 99.1% compared to traditional approaches. Finally, we explore how far LLMs are from real search by investigating whether they can develop search capabilities independently. Our analysis reveals that while current LLMs struggle with efficient search in complex problems, incorporating systematic search strategies significantly enhances their problem-solving capabilities. These findings not only validate the effectiveness of our approach but also highlight the need for improving LLMs' search abilities for real-world applications.", 'abstract_zh': '搜索在各个领域的问题解决中起着基础性作用，大多数现实世界中的决策问题可以通过系统的搜索方法来解决。受到搜索与学习近期讨论的启发，我们从三个方面系统地探讨了搜索与大型语言模型（LLMs）之间的互补关系。首先，我们分析了学习如何提升搜索效率，并提出了基于LLMs的搜索框架Search via Learning (SeaL)，以实现高效搜索。其次，我们将SeaL扩展为SeaL-C，以确保搜索过程的严格完备性。我们的评估结果显示，SeaL在三项真实世界规划任务中的准确率达到接近完美，并将搜索空间减少了高达99.1%。最后，我们探讨了当前LLMs在独立开发搜索能力方面的局限性，并分析了系统化搜索策略如何显著增强其解决问题的能力。这些发现不仅验证了我们方法的有效性，还强调了提高LLMs搜索能力以适应现实世界应用的必要性。', 'title_zh': '大型语言模型与实际搜索相差多远？关于效率、完备性及内在能力的全面研究'}
{'arxiv_id': 'arXiv:2502.18371', 'title': 'MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning', 'authors': 'Sepehr Asgarian, Qayam Jetha, Jouhyun Jeon', 'link': 'https://arxiv.org/abs/2502.18371', 'abstract': "In the competitive landscape of advertising, success hinges on effectively navigating and leveraging complex interactions among consumers, advertisers, and advertisement platforms. These multifaceted interactions compel advertisers to optimize strategies for modeling consumer behavior, enhancing brand recall, and tailoring advertisement content. To address these challenges, we present MindMem, a multimodal predictive model for advertisement memorability. By integrating textual, visual, and auditory data, MindMem achieves state-of-the-art performance, with a Spearman's correlation coefficient of 0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently surpassing existing methods. Furthermore, our analysis identified key factors influencing advertisement memorability, such as video pacing, scene complexity, and emotional resonance. Expanding on this, we introduced MindMem-ReAd (MindMem-Driven Re-generated Advertisement), which employs Large Language Model-based simulations to optimize advertisement content and placement, resulting in up to a 74.12% improvement in advertisement memorability. Our results highlight the transformative potential of Artificial Intelligence in advertising, offering advertisers a robust tool to drive engagement, enhance competitiveness, and maximize impact in a rapidly evolving market.", 'abstract_zh': '在广告竞争 landscape 中，成功取决于有效地导航和利用消费者、广告商和广告平台之间错综复杂的相互作用。这些多维度的相互作用促使广告商优化策略以建模消费者行为、增强品牌回忆并定制广告内容。为应对这些挑战，我们提出了 MindMem，一种多模态预测模型，用于广告记忆性。通过整合文本、视觉和音频数据，MindMem 实现了最先进的性能，其在 LAMBDA 数据集上的 Spearman 相关系数为 0.631，在 Memento10K 数据集上的相关系数为 0.731，始终超越现有方法。此外，我们的分析确定了影响广告记忆性的关键因素，如视频节奏、场景复杂性和情感共鸣。在此基础上，我们引入了 MindMem-ReAd（由 MindMem 驱动的重新生成广告），利用基于大语言模型的模拟优化广告内容和投放，广告记忆提升高达 74.12%。我们的结果突显了人工智能在广告领域的变革潜力，为广告商提供了一种强大的工具，以推动参与度、增强竞争力并最大化在快速变化市场中的影响力。', 'title_zh': 'MindMem：多模态预测广告记忆性的人工智能与深度学习方法'}
{'arxiv_id': 'arXiv:2502.18274', 'title': 'Citrus: Leveraging Expert Cognitive Pathways in a Medical Language Model for Advanced Medical Decision Support', 'authors': 'Guoxin Wang, Minyu Gao, Shuai Yang, Ya Zhang, Lizhi He, Liang Huang, Hanlin Xiao, Yexuan Zhang, Wanyue Li, Lu Chen, Jintao Fei, Xin Li', 'link': 'https://arxiv.org/abs/2502.18274', 'abstract': 'Large language models (LLMs), particularly those with reasoning capabilities, have rapidly advanced in recent years, demonstrating significant potential across a wide range of applications. However, their deployment in healthcare, especially in disease reasoning tasks, is hindered by the challenge of acquiring expert-level cognitive data. In this paper, we introduce Citrus, a medical language model that bridges the gap between clinical expertise and AI reasoning by emulating the cognitive processes of medical experts. The model is trained on a large corpus of simulated expert disease reasoning data, synthesized using a novel approach that accurately captures the decision-making pathways of clinicians. This approach enables Citrus to better simulate the complex reasoning processes involved in diagnosing and treating medical this http URL further address the lack of publicly available datasets for medical reasoning tasks, we release the last-stage training data, including a custom-built medical diagnostic dialogue dataset. This open-source contribution aims to support further research and development in the field. Evaluations using authoritative benchmarks such as MedQA, covering tasks in medical reasoning and language understanding, show that Citrus achieves superior performance compared to other models of similar size. These results highlight Citrus potential to significantly enhance medical decision support systems, providing a more accurate and efficient tool for clinical decision-making.', 'abstract_zh': '大型语言模型（LLMs），特别是那些具有推理能力的模型，在近年来迅速发展，展示了在广泛的应用领域中的巨大潜力。然而，它们在医疗领域的部署，尤其是在疾病推理任务中的应用，受限于难以获取专家级的认知数据。本文介绍了一种名为Citrus的医疗语言模型，通过模拟医疗专家的认知过程，填补了临床专业知识和AI推理之间的差距。模型是在一个大型的模拟专家疾病推理数据集上进行训练的，该数据集采用了新颖的方法合成，准确地捕捉了临床人员的决策路径。这种做法使得Citrus能够更好地模拟诊断和治疗过程中所涉及的复杂推理过程。为了解决医疗推理任务中缺乏公开数据集的问题，我们发布了训练数据的最终阶段，包括一个自建的医疗诊断对话数据集。这一开源贡献旨在支持该领域的进一步研究和开发。使用权威基准如MedQA进行的评估涵盖医疗推理和语言理解任务，结果显示Citrus在性能上优于其他同类大小的模型。这些结果突显了Citrus在显著增强医疗决策支持系统方面的重要性，提供了一个更准确和高效的临床决策工具。', 'title_zh': '柑橘：在医疗语言模型中利用专家认知路径以实现高级医疗决策支持'}
{'arxiv_id': 'arXiv:2502.17882', 'title': 'Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers', 'authors': 'Hannah Calzi Kleidermacher, James Zou', 'link': 'https://arxiv.org/abs/2502.17882', 'abstract': 'Scientific research is inherently global. However, the vast majority of academic journals are published exclusively in English, creating barriers for non-native-English-speaking researchers. In this study, we leverage large language models (LLMs) to translate published scientific articles while preserving their native JATS XML formatting, thereby developing a practical, automated approach for implementation by academic journals. Using our approach, we translate articles across multiple scientific disciplines into 28 languages. To evaluate translation accuracy, we introduce a novel question-and-answer (QA) benchmarking method, in which an LLM generates comprehension-based questions from the original text and then answers them based on the translated text. Our benchmark results show an average performance of 95.9%, showing that the key scientific details are accurately conveyed. In a user study, we translate the scientific papers of 15 researchers into their native languages, finding that the authors consistently found the translations to accurately capture the original information in their articles. Interestingly, a third of the authors found many technical terms "overtranslated," expressing a preference to keep terminology more familiar in English untranslated. Finally, we demonstrate how in-context learning techniques can be used to align translations with domain-specific preferences such as mitigating overtranslation, highlighting the adaptability and utility of LLM-driven scientific translation. The code and translated articles are available at this https URL.', 'abstract_zh': '科学研究本质上是全球性的。然而，绝大多数学术期刊仅以英文出版，为非英语母语的研究者设置了障碍。本研究利用大规模语言模型（LLMs）翻译已发表的科学文章，同时保留其原生的JATS XML格式，从而开发了一种适用于学术期刊的实用自动化方法。使用本方法，我们将多学科的论文翻译成28种语言。为了评估翻译准确性，我们引入了一种新颖的问答（QA）基准测试方法，其中大规模语言模型从原文生成基于理解的问题，并基于译文作答。基准测试结果表明平均正确率为95.9%，表明关键科学细节得到了准确传达。在一项用户研究中，我们将15位研究人员的科学论文翻译成他们的母语，发现作者一致认为翻译准确捕捉了原文信息。有趣的是，三分之一的作者发现许多技术术语被过度翻译，更倾向于保留一些术语不翻译。最后，我们展示了如何使用上下文学习技术对翻译与学科特定偏好进行对齐，例如减少过度翻译，突显了基于大规模语言模型的科学翻译的适应性和实用性。代码和翻译的文章可在以下网址获取。', 'title_zh': '跨语言科学：评估LLM在多语言翻译科学论文中的表现'}
{'arxiv_id': 'arXiv:2502.17807', 'title': 'DocPuzzle: A Process-Aware Benchmark for Evaluating Realistic Long-Context Reasoning Capabilities', 'authors': 'Tianyi Zhuang, Chuqiao Kuang, Xiaoguang Li, Yihua Teng, Jihao Wu, Yasheng Wang, Lifeng Shang', 'link': 'https://arxiv.org/abs/2502.17807', 'abstract': 'We present DocPuzzle, a rigorously constructed benchmark for evaluating long-context reasoning capabilities in large language models (LLMs). This benchmark comprises 100 expert-level QA problems requiring multi-step reasoning over long real-world documents. To ensure the task quality and complexity, we implement a human-AI collaborative annotation-validation pipeline. DocPuzzle introduces an innovative evaluation framework that mitigates guessing bias through checklist-guided process analysis, establishing new standards for assessing reasoning capacities in LLMs. Our evaluation results show that: 1)Advanced slow-thinking reasoning models like o1-preview(69.7%) and DeepSeek-R1(66.3%) significantly outperform best general instruct models like Claude 3.5 Sonnet(57.7%); 2)Distilled reasoning models like DeepSeek-R1-Distill-Qwen-32B(41.3%) falls far behind the teacher model, suggesting challenges to maintain the generalization of reasoning capabilities relying solely on distillation.', 'abstract_zh': 'DocPuzzle: 一个严格构建的基准，用于评估大规模语言模型的长上下文推理能力', 'title_zh': 'DocPuzzle: 一种评估现实长上下文推理能力的过程感知基准'}
{'arxiv_id': 'arXiv:2502.17749', 'title': 'Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features', 'authors': 'Shinwoo Park, Hyundong Jin, Jeong-won Cha, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2502.17749', 'abstract': 'Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset LPcode consisting of pairs of human-written code and LLM-paraphrased code using various LLMs.\nWe statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop LPcodedec, a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. LPcodedec outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.', 'abstract_zh': '最近大语言模型在代码生成方面的进展引发了对知识产权保护的严重关切。恶意用户可以利用大语言模型生成与原版高度相似的变形代码。尽管大语言模型协助代码变形的潜力不断增长，但在这一检测方面的研究仍然有限，这突显了迫切需要开发检测系统。为此，我们提出了两个任务。第一个任务是检测由大语言模型生成的代码是否为人类编写代码的变形版本。第二个任务是识别使用了哪个大语言模型来变形原始代码。为这两个任务，我们构建了一个数据集LPcode，包含人类编写代码和由各种大语言模型生成的变形代码的配对。我们统计上证实了人类编写和大语言模型生成的代码在命名一致性、代码结构和可读性等方面的显著差异。基于这些发现，我们开发了LPcodedec检测方法，该方法可以识别人类编写和大语言模型生成代码之间的变形关系，并确定用于生成变形的哪个大语言模型。LPcodedec在两个任务上的表现优于最佳基线，分别提高了2.64%和15.17%的F1分数，同时分别实现了1343倍和213倍的速度提升。', 'title_zh': '基于编码风格特征的LLM重述代码检测及负责任的LLM识别'}
{'arxiv_id': 'arXiv:2502.17710', 'title': 'Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures', 'authors': 'Akhila Yerukola, Saadia Gabriel, Nanyun Peng, Maarten Sap', 'link': 'https://arxiv.org/abs/2502.17710', 'abstract': 'Gestures are an integral part of non-verbal communication, with meanings that vary across cultures, and misinterpretations that can have serious social and diplomatic consequences. As AI systems become more integrated into global applications, ensuring they do not inadvertently perpetuate cultural offenses is critical. To this end, we introduce Multi-Cultural Set of Inappropriate Gestures and Nonverbal Signs (MC-SIGNS), a dataset of 288 gesture-country pairs annotated for offensiveness, cultural significance, and contextual factors across 25 gestures and 85 countries. Through systematic evaluation using MC-SIGNS, we uncover critical limitations: text-to-image (T2I) systems exhibit strong US-centric biases, performing better at detecting offensive gestures in US contexts than in non-US ones; large language models (LLMs) tend to over-flag gestures as offensive; and vision-language models (VLMs) default to US-based interpretations when responding to universal concepts like wishing someone luck, frequently suggesting culturally inappropriate gestures. These findings highlight the urgent need for culturally-aware AI safety mechanisms to ensure equitable global deployment of AI technologies.', 'abstract_zh': '多文化不合适手势和非言语信号数据集（MC-SIGNS）：揭示文化aware AI安全机制的迫切需求', 'title_zh': '关注手势：评估AI对具有文化冒犯性的非言语手势的敏感性'}
{'arxiv_id': 'arXiv:2502.17701', 'title': 'From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs', 'authors': 'Ruxiao Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu', 'link': 'https://arxiv.org/abs/2502.17701', 'abstract': 'Evacuation decision prediction is critical for efficient and effective wildfire response by helping emergency management anticipate traffic congestion and bottlenecks, allocate resources, and minimize negative impacts. Traditional statistical methods for evacuation decision prediction fail to capture the complex and diverse behavioral logic of different individuals. In this work, for the first time, we introduce FLARE, short for facilitating LLM for advanced reasoning on wildfire evacuation decision prediction, a Large Language Model (LLM)-based framework that integrates behavioral theories and models to streamline the Chain-of-Thought (CoT) reasoning and subsequently integrate with memory-based Reinforcement Learning (RL) module to provide accurate evacuation decision prediction and understanding. Our proposed method addresses the limitations of using existing LLMs for evacuation behavioral predictions, such as limited survey data, mismatching with behavioral theory, conflicting individual preferences, implicit and complex mental states, and intractable mental state-behavior mapping. Experiments on three post-wildfire survey datasets show an average of 20.47% performance improvement over traditional theory-informed behavioral models, with strong cross-event generalizability. Our complete code is publicly available at this https URL', 'abstract_zh': '高效的野生火灾疏散决策预测对于帮助紧急管理机构预见交通拥堵和瓶颈、合理分配资源并最小化负面影响至关重要。传统统计方法在预测疏散决策时无法捕捉不同个体复杂多样的行为逻辑。在此工作中，我们首次提出了FLARE，即促进大型语言模型进行野生火灾疏散决策预测的高级推理框架，该框架基于大型语言模型，整合行为理论和模型以简化Chain-of-Thought（CoT）推理，并结合基于记忆的强化学习模块，提供精确的疏散决策预测和理解。我们提出的方法解决了现有大型语言模型在疏散行为预测中的局限性，如有限的调查数据、理论匹配不一致、个体偏好冲突、复杂的心理状态以及难以解决的心理状态-行为映射问题。在三个野生火灾后的调查数据集上的实验显示，与传统的理论驱动行为模型相比，我们的方法平均提高了20.47%的性能，并具有较强的跨事件泛化能力。完整的代码已公开在该网址。', 'title_zh': '从感知到决策：基于行为理论指导的大语言模型 wildfire 撤离决策预测'}
{'arxiv_id': 'arXiv:2502.17601', 'title': 'Representation Engineering for Large-Language Models: Survey and Research Challenges', 'authors': 'Lukasz Bartoszcze, Sarthak Munshi, Bryan Sukidi, Jennifer Yen, Zejia Yang, David Williams-King, Linh Le, Kosi Asuzu, Carsten Maple', 'link': 'https://arxiv.org/abs/2502.17601', 'abstract': 'Large-language models are capable of completing a variety of tasks, but remain unpredictable and intractable. Representation engineering seeks to resolve this problem through a new approach utilizing samples of contrasting inputs to detect and edit high-level representations of concepts such as honesty, harmfulness or power-seeking. We formalize the goals and methods of representation engineering to present a cohesive picture of work in this emerging discipline. We compare it with alternative approaches, such as mechanistic interpretability, prompt-engineering and fine-tuning. We outline risks such as performance decrease, compute time increases and steerability issues. We present a clear agenda for future research to build predictable, dynamic, safe and personalizable LLMs.', 'abstract_zh': '大规模语言模型能够完成多种任务，但仍具有不可预测性和难以处理的特点。表示工程学通过利用对比输入样本的新方法来解决这一问题，旨在检测和编辑诸如诚实、危害性或权力追求等概念的高层表示。我们正式化表示工程学的目标和方法，呈现这一新兴学科工作的整体图景。我们将它与机械可解释性、提示工程和微调等替代方法进行比较。我们概述了可能出现的风险，如性能下降、计算时间增加和可控性问题。我们提出了一个明确的未来研究议程，旨在构建可预测、动态、安全和个人化的大规模语言模型。', 'title_zh': '大规模语言模型的表示工程：综述与研究挑战'}
{'arxiv_id': 'arXiv:2502.17578', 'title': 'How Do Large Language Monkeys Get Their Power (Laws)?', 'authors': 'Rylan Schaeffer, Joshua Kazdan, John Hughes, Jordan Juravsky, Sara Price, Aengus Lynch, Erik Jones, Robert Kirk, Azalia Mirhoseini, Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2502.17578', 'abstract': 'Recent research across mathematical problem solving, proof assistant programming and multimodal jailbreaking documents a striking finding: when (multimodal) language model tackle a suite of tasks with multiple attempts per task -- succeeding if any attempt is correct -- then the negative log of the average success rate scales a power law in the number of attempts. In this work, we identify an apparent puzzle: a simple mathematical calculation predicts that on each problem, the failure rate should fall exponentially with the number of attempts. We confirm this prediction empirically, raising a question: from where does aggregate polynomial scaling emerge? We then answer this question by demonstrating per-problem exponential scaling can be made consistent with aggregate polynomial scaling if the distribution of single-attempt success probabilities is heavy tailed such that a small fraction of tasks with extremely low success probabilities collectively warp the aggregate success trend into a power law - even as each problem scales exponentially on its own. We further demonstrate that this distributional perspective explains previously observed deviations from power law scaling, and provides a simple method for forecasting the power law exponent with an order of magnitude lower relative error, or equivalently, ${\\sim}2-4$ orders of magnitude less inference compute. Overall, our work contributes to a better understanding of how neural language model performance improves with scaling inference compute and the development of scaling-predictable evaluations of (multimodal) language models.', 'abstract_zh': '近来关于数学问题求解、证明助手编程和多模态 Jailbreaking 的研究揭示了一个引人注目的发现：当（多模态）语言模型在每项任务中有多次尝试机会，并且只要有一次尝试正确即算成功时，平均成功率的负对数与尝试次数之间呈现出幂律关系。在本文中，我们识别出一个明显的悖论：一个简单的数学计算表明，每道题目的失败率应该随着尝试次数的增加而呈现出指数级下降。我们通过实验证实了这一预测，提出了一个疑问：整体幂律关系是如何出现的？我们通过证明如果单次尝试成功率的概率分布具有重尾特征，即使每道题目单独来看呈现出指数级下降的趋势，但一小部分具有极低成功率的任务可以集体影响整体成功率趋势，使其呈现出幂律关系，从而回答了这一问题。我们还证明了这种概率分布视角可以解释之前观察到的幂律关系偏离现象，并提供了一种使用相对误差低一个数量级的方法来预测幂律指数，或者等效地说，可减少约2到4个数量级的推理计算量。整体而言，我们的工作促进了对神经语言模型性能随推理计算量增加而提升机制的理解，并为（多模态）语言模型的可预测扩展性评估提供了贡献。', 'title_zh': '大型语言模型是如何获得其权力（法律）的？'}
{'arxiv_id': 'arXiv:2502.17541', 'title': 'Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction', 'authors': 'Michal Bravansky, Vaclav Kubon, Suhas Hariharan, Robert Kirk', 'link': 'https://arxiv.org/abs/2502.17541', 'abstract': 'Interpreting data is central to modern research. Large language models (LLMs) show promise in providing such natural language interpretations of data, yet simple feature extraction methods such as prompting often fail to produce accurate and versatile descriptions for diverse datasets and lack control over granularity and scale. To address these limitations, we propose a domain-agnostic method for dataset featurization that provides precise control over the number of features extracted while maintaining compact and descriptive representations comparable to human expert labeling. Our method optimizes the selection of informative binary features by evaluating the ability of an LLM to reconstruct the original data using those features. We demonstrate its effectiveness in dataset modeling tasks and through two case studies: (1) Constructing a feature representation of jailbreak tactics that compactly captures both the effectiveness and diversity of a larger set of human-crafted attacks; and (2) automating the discovery of features that align with human preferences, achieving accuracy and robustness comparable to expert-crafted features. Moreover, we show that the pipeline scales effectively, improving as additional features are sampled, making it suitable for large and diverse datasets.', 'abstract_zh': '现代研究中数据分析解释至关重要。大规模语言模型（LLMs）显示出了提供自然语言数据解释的潜力，然而简单的特征提取方法如提示常常无法为多样化的数据集生成准确且多样化的描述，并且缺乏对细节和规模的控制。为了解决这些局限性，我们提出了一种跨领域的数据集特征化方法，该方法能够精确控制提取的特征数量，同时保持紧凑且描述性的表示，与人类专家标注相媲美。我们的方法通过评估LLM使用这些特征重构原始数据的能力，来优化选择信息性二元特征。我们通过数据集建模任务和两个案例研究展示了其有效性：（1）构建一个包含更大规模人类设计攻击的有效性和多样性的狱破战术特征表示；（2）自动化发现与人类偏好相匹配的特征，实现与专家设计特征相当的准确性和鲁棒性。此外，我们展示了该流水线具有良好的扩展性，随着更多特征的采样而改进，使其适用于大规模和多样化的数据集。', 'title_zh': '数据集特征化：通过无监督数据重构发现自然语言特征'}
{'arxiv_id': 'arXiv:2502.17487', 'title': 'User Intent to Use DeekSeep for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study', 'authors': 'Avishek Choudhury, Yeganeh Shahsavar, Hamid Shamszare', 'link': 'https://arxiv.org/abs/2502.17487', 'abstract': 'Large language models (LLMs) increasingly serve as interactive healthcare resources, yet user acceptance remains underexplored. This study examines how ease of use, perceived usefulness, trust, and risk perception interact to shape intentions to adopt DeepSeek, an emerging LLM-based platform, for healthcare purposes. A cross-sectional survey of 556 participants from India, the United Kingdom, and the United States was conducted to measure perceptions and usage patterns. Structural equation modeling assessed both direct and indirect effects, including potential quadratic relationships. Results revealed that trust plays a pivotal mediating role: ease of use exerts a significant indirect effect on usage intentions through trust, while perceived usefulness contributes to both trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Notably, significant non-linear paths were observed for ease of use and risk, indicating threshold or plateau effects. The measurement model demonstrated strong reliability and validity, supported by high composite reliabilities, average variance extracted, and discriminant validity measures. These findings extend technology acceptance and health informatics research by illuminating the multifaceted nature of user adoption in sensitive domains. Stakeholders should invest in trust-building strategies, user-centric design, and risk mitigation measures to encourage sustained and safe uptake of LLMs in healthcare. Future work can employ longitudinal designs or examine culture-specific variables to further clarify how user perceptions evolve over time and across different regulatory environments. Such insights are critical for harnessing AI to enhance outcomes.', 'abstract_zh': '大型语言模型（LLMs）日益成为互动型健康资源，但用户接受度尚未得到充分探索。本研究分析了便捷性、 perceived usefulness、信任和风险感知如何交互作用，进而影响用户采用基于LLM的新兴平台DeepSeek进行健康目的的意图。通过对来自印度、英国和美国的556名参与者的横断面调查，评估了感知和使用模式。结构方程建模评估了直接和间接影响，包括潜在的二次关系。研究结果揭示了信任起关键的中介作用：便捷性通过信任对使用意图产生显著的间接影响，而 perceived usefulness则促进了信任发展和直接采用。相比之下，风险感知消极地影响使用意图，强调了稳健的数据治理和透明度的重要性。值得注意的是，观察到便捷性和风险的显著非线性路径，表明存在阈值或平台效应。测量模型展示了强可靠性与有效性，这一点由较高的综合可靠性、抽取的平均方差和辨别性效度指标得到支持。这些发现扩展了技术接受和卫生信息学研究，揭示了敏感领域中用户采用的多维性质。利益相关者应投资于信任构建策略、以用户为中心的设计和风险缓解措施，以促进LLMs在医疗健康中的持续安全使用。未来的研究可以通过采用纵向设计或考察文化特定变量，进一步澄清用户感知如何随时间发展并在不同监管环境中变化。这些见解对于利用AI改善成果至关重要。', 'title_zh': '用户在健康护理目的下使用DeekSeep的意图及其对大型语言模型的信任：跨国调查研究'}
{'arxiv_id': 'arXiv:2502.18452', 'title': 'FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response', 'authors': 'Mollie Shichman, Claire Bonial, Austin Blodgett, Taylor Hudson, Francis Ferraro, Rachel Rudinger', 'link': 'https://arxiv.org/abs/2502.18452', 'abstract': 'Large Language Models (LLMs) have the potential for substantial common sense reasoning. However, these capabilities are often emergent in larger models. This means smaller models that can be run locally are less helpful and capable with respect to certain reasoning tasks. To meet our problem space requirements, we fine-tune smaller LLMs to disaster domains, as these domains involve complex and low-frequency physical common sense knowledge. We introduce a pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models, where domain experts and linguists combine their knowledge to make high-quality seed data that is used to generate synthetic data for fine-tuning. We create a set of 130 seed instructions for synthetic generation, a synthetic dataset of 25000 instructions, and 119 evaluation instructions relating to both general and earthquake-specific object affordances. We fine-tune several LLaMa and Mistral instruction-tuned models and find that FRIDA models outperform their base models at a variety of sizes. We then run an ablation study to understand which kinds of synthetic data most affect performance and find that training physical state and object function common sense knowledge alone improves over FRIDA models trained on all data. We conclude that the FRIDA pipeline is capable of instilling general common sense, but needs to be augmented with information retrieval for specific domain knowledge.', 'abstract_zh': '大型语言模型（LLMs）在常识推理方面具有潛力，但這些能力通常在較大的模型中 gradually 形成。这意味着较小的本地可运行模型在某些推理任务上较少有帮助。为了满足我们的问题空间要求，我们将较小的LLMs微调到灾害领域，因为这些领域涉及复杂的低频物理常识知识。我们提出了一种流水线来创建现场准备就绪指令解码代理（FRIDA）模型，其中领域专家和语言学家结合他们的知识生成高质量的种子数据，并用其生成合成数据以进行微调。我们创建了一组130个种子指令用于合成生成，一个包含25000个指令的合成数据集，以及涉及通用和地震特定物体功能性指令的119个评估指令。我们对LLaMa和Mistral指令微调模型进行了微调并发现，FRIDA模型在各种规模下均超越了其基础模型。然后我们进行了一项消融研究以了解哪种类型的合成数据对性能影响最大，发现单独训练物理状态和物体功能常识知识提高了FRIDA模型的性能。我们得出结论，FRIDA流水线可以灌输一般的常识，但需要增加信息检索来获取特定领域的知识。', 'title_zh': 'FRIDA 挽救了！基于对象的常识推理中合成数据有效性分析在灾害响应中的应用'}
{'arxiv_id': 'arXiv:2502.18449', 'title': 'SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution', 'authors': 'Yuxiang Wei, Olivier Duchenne, Jade Copet, Quentin Carbonneaux, Lingming Zhang, Daniel Fried, Gabriel Synnaeve, Rishabh Singh, Sida I. Wang', 'link': 'https://arxiv.org/abs/2502.18449', 'abstract': "The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, this paper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for real-world software engineering. Leveraging a lightweight rule-based reward (e.g., the similarity score between ground-truth and LLM-generated solutions), SWE-RL enables LLMs to autonomously recover a developer's reasoning processes and solutions by learning from extensive open-source software evolution data -- the record of a software's entire lifecycle, including its code snapshots, code changes, and events such as issues and pull requests. Trained on top of Llama 3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve rate on SWE-bench Verified -- a human-verified collection of real-world GitHub issues. To our knowledge, this is the best performance reported for medium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs like GPT-4o. Surprisingly, despite performing RL solely on software evolution data, Llama3-SWE-RL has even emerged with generalized reasoning skills. For example, it shows improved results on five out-of-domain tasks, namely, function coding, library use, code reasoning, mathematics, and general language understanding, whereas a supervised-finetuning baseline even leads to performance degradation on average. Overall, SWE-RL opens up a new direction to improve the reasoning capabilities of LLMs through reinforcement learning on massive software engineering data.", 'abstract_zh': 'Recent DeepSeek-R1版本展示了强化学习在提升大型语言模型通用推理能力方面的巨大潜力。DeepSeek-R1及其后续工作主要集中在将强化学习应用于编程和数学问题上，而本文介绍了SWE-RL，这是首个在实际软件工程中规模化应用基于强化学习的大型语言模型推理方法。通过利用轻量级规则为基础的奖励机制（如ground-truth与LLM生成解决方案的相似度得分），SWE-RL使LLMs能够通过学习开放源代码软件演化数据中的大量信息，自主恢复开发者的推理过程和解决方案——这些数据包括代码快照、代码变更以及诸如问题和拉取请求等事件。基于Llama 3训练，我们的推理模型Llama3-SWE-RL-70B在SWE-bench Verified（一个由人类验证的真实GitHub问题集合）上达到了41.0%的解题率。据我们所知，这在目前中型(<100B)LLM中是最佳性能，甚至可以与GPT-4o等领先私有LLM相媲美。令人惊讶的是，尽管仅在软件演化数据上进行RL训练，Llama3-SWE-RL仍展现出泛化的推理能力。例如，在五个离域任务（函数编码、库使用、代码推理、数学和通用语言理解）上表现出改进的结果，而监督微调基线在平均上甚至导致性能下降。总体而言，SWE-RL为通过大规模软件工程数据上的强化学习提高LLM推理能力开辟了新的方向。', 'title_zh': 'SWE-RL：通过开放软件演化中的强化学习提升大语言模型推理能力'}
{'arxiv_id': 'arXiv:2502.18448', 'title': 'Disambiguate First Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing', 'authors': 'Irina Saparina, Mirella Lapata', 'link': 'https://arxiv.org/abs/2502.18448', 'abstract': 'Handling ambiguity and underspecification is an important challenge in natural language interfaces, particularly for tasks like text-to-SQL semantic parsing. We propose a modular approach that resolves ambiguity using natural language interpretations before mapping these to logical forms (e.g., SQL queries). Although LLMs excel at parsing unambiguous utterances, they show strong biases for ambiguous ones, typically predicting only preferred interpretations. We constructively exploit this bias to generate an initial set of preferred disambiguations and then apply a specialized infilling model to identify and generate missing interpretations. To train the infilling model, we introduce an annotation method that uses SQL execution to validate different meanings. Our approach improves interpretation coverage and generalizes across datasets with different annotation styles, database structures, and ambiguity types.', 'abstract_zh': '处理自然语言接口中的模糊性和缺指性是自然语言处理任务的重要挑战，特别是在将文本转换为SQL语义解析的任务中。我们提出了一种模块化方法，首先使用自然语言解释来解决模糊性，然后再映射这些解释到逻辑形式（例如，SQL查询）。尽管大语言模型在解析无歧义的语句方面表现出色，但它们在歧义语句上的预测通常表现出强烈的偏好，通常只预测首选的解释。我们有建设性地利用这种偏好来生成一组首选的消歧解释，然后应用一个专门的填充模型来识别和生成缺失的解释。为了训练填充模型，我们引入了一种标注方法，该方法使用SQL执行来验证不同的意义。我们的方法提高了解释覆盖范围，并能在具有不同标注风格、数据库结构和模糊性类型的多个数据集中泛化。', 'title_zh': '先消歧后解析：语义解析中生成解释以解决歧义问题'}
{'arxiv_id': 'arXiv:2502.18431', 'title': 'TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning', 'authors': 'Frederikus Hudi, Genta Indra Winata, Ruochen Zhang, Alham Fikri Aji', 'link': 'https://arxiv.org/abs/2502.18431', 'abstract': "Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems. In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning. Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection. Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks. In contrast, humans are capable of solving all tasks when given sufficient time. Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently. Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems.", 'abstract_zh': '大规模语言模型中推理能力的评估：TextGames基准研究', 'title_zh': '文本游戏：通过语言模型推理学习自我对弈文本基础益智游戏'}
{'arxiv_id': 'arXiv:2502.18293', 'title': 'AMPO: Active Multi-Preference Optimization', 'authors': 'Taneesh Gupta, Rahul Madhavan, Xuchao Zhang, Chetan Bansal, Saravan Rajmohan', 'link': 'https://arxiv.org/abs/2502.18293', 'abstract': 'Multi-preference optimization enriches language-model alignment beyond pairwise preferences by contrasting entire sets of helpful and undesired responses, thereby enabling richer training signals for large language models. During self-play alignment, these models often produce numerous candidate answers per query, rendering it computationally infeasible to include all responses in the training objective. In this work, we propose $\\textit{Active Multi-Preference Optimization}$ (AMPO), a novel approach that combines on-policy generation, a multi-preference group-contrastive loss, and active subset selection. Specifically, we score and embed large candidate pools of responses and then select a small, yet informative, subset that covers reward extremes and distinct semantic clusters for preference optimization. Our contrastive training scheme is capable of identifying not only the best and worst answers but also subtle, underexplored modes that are crucial for robust alignment. Theoretically, we provide guarantees for expected reward maximization using our active selection method, and empirically, AMPO achieves state-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B.', 'abstract_zh': '多偏好优化扩展了大型语言模型对齐的方法，通过对比整个有益和不期望回答的集合，超越了成对偏好，从而为大型语言模型提供更丰富的训练信号。在自我对齐过程中，这些模型经常为每个查询生成众多候选答案，使包括所有回答在训练目标中变得计算上不可行。在本文中，我们提出了一种名为$\\textit{Active Multi-Preference Optimization}$（AMPO）的新方法，该方法结合了策略生成、多偏好群体对比损失以及主动子集选择。具体地，我们对大型候选回答池进行评分和嵌入，然后选择一个小而具有信息量的子集，该子集涵盖了奖励极值和不同的语义簇，用于偏好优化。我们的对比训练方案不仅能够识别最佳和最差的答案，还能识别对于稳健对齐至关重要的未开发模式。从理论上，我们提供了使用我们主动选择方法进行预期奖励最大化的保证；从实验上，AMPO在使用Llama 8B模型进行$\\textit{AlpacaEval}$测试时达到了最先进的结果。', 'title_zh': 'AMPO: 主动多偏好优化'}
{'arxiv_id': 'arXiv:2502.18209', 'title': 'LAG: LLM agents for Leaderboard Auto Generation on Demanding', 'authors': 'Jian Wu, Jiayu Zhang, Dongyuan Li, Linyi Yang, Aoxiao Zhong, Renhe Jiang, Qingsong Wen, Yue Zhang', 'link': 'https://arxiv.org/abs/2502.18209', 'abstract': "This paper introduces Leaderboard Auto Generation (LAG), a novel and well-organized framework for automatic generation of leaderboards on a given research topic in rapidly evolving fields like Artificial Intelligence (AI). Faced with a large number of AI papers updated daily, it becomes difficult for researchers to track every paper's proposed methods, experimental results, and settings, prompting the need for efficient automatic leaderboard construction. While large language models (LLMs) offer promise in automating this process, challenges such as multi-document summarization, leaderboard generation, and experiment fair comparison still remain under exploration. LAG solves these challenges through a systematic approach that involves the paper collection, experiment results extraction and integration, leaderboard generation, and quality evaluation. Our contributions include a comprehensive solution to the leaderboard construction problem, a reliable evaluation method, and experimental results showing the high quality of leaderboards.", 'abstract_zh': 'Leaderboard 自动生成（LAG）：一种适用于快速发展的人工智能研究领域的新型有效框架', 'title_zh': 'LAG: LLM代理在具有挑战性的排行榜自动生成中'}
{'arxiv_id': 'arXiv:2502.18179', 'title': 'Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs', 'authors': 'Gaye Colakoglu, Gürkan Solmaz, Jonathan Fürst', 'link': 'https://arxiv.org/abs/2502.18179', 'abstract': 'This paper defines and explores the design space for information extraction (IE) from layout-rich documents using large language models (LLMs). The three core challenges of layout-aware IE with LLMs are 1) data structuring, 2) model engagement, and 3) output refinement. Our study delves into the sub-problems within these core challenges, such as input representation, chunking, prompting, and selection of LLMs and multimodal models. It examines the outcomes of different design choices through a new layout-aware IE test suite, benchmarking against the state-of-art (SoA) model LayoutLMv3. The results show that the configuration from one-factor-at-a-time (OFAT) trial achieves near-optimal results with 14.1 points F1-score gain from the baseline model, while full factorial exploration yields only a slightly higher 15.1 points gain at around 36x greater token usage. We demonstrate that well-configured general-purpose LLMs can match the performance of specialized models, providing a cost-effective alternative. Our test-suite is freely available at this https URL.', 'abstract_zh': '本文定义并探索了使用大型语言模型（LLMs）从布局丰富文档中提取信息（IE）的设计空间。布局感知IE的核心挑战包括1）数据结构化、2）模型参与，以及3）输出精炼。本研究深入探讨了这些核心挑战下的子问题，如输入表示、切分、提示以及LLMs和多模态模型的选择。通过一个新的布局感知IE测试套件，本研究基于最新的基准模型LayoutLMv3进行评估，考察了不同设计选择的结果。结果显示，单一因素试验（OFAT）配置从基线模型获得了14.1点的F1分数提升，而全面的因素探索则在大约36倍的令牌使用量下只获得了略高的15.1点提升。本研究证明，配置良好的通用语言模型可以匹配专业模型的性能，提供一种成本效益较高的替代方案。测试套件在此网址免费获取。', 'title_zh': '问题解决了吗？使用LLMs的布局丰富文档的信息提取设计空间'}
{'arxiv_id': 'arXiv:2502.18168', 'title': 'SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models', 'authors': 'Zhang Yuxuan, Li Ruizhe', 'link': 'https://arxiv.org/abs/2502.18168', 'abstract': "With the rapid development of large language models (LLMs), fully fine-tuning (FT) these models has become increasingly impractical due to the high computational demands. Additionally, FT can lead to catastrophic forgetting. As an alternative, Low-Rank Adaptation (LoRA) has been proposed, which fine-tunes only a small subset of parameters, achieving similar performance to FT while significantly reducing resource requirements. However, since LoRA inherits FT's design, the issue of catastrophic forgetting remains.\nTo address these challenges, we propose SECURA: Sigmoid-Enhanced CUR Decomposition LoRA, a novel parameter-efficient fine-tuning (PEFT) variant that mitigates catastrophic forgetting while improving fine-tuning performance. Our method introduces a new normalization technique, SigNorm, to enhance parameter retention and overall performance.\nSECURA has been evaluated on a variety of tasks, including mathematical problem-solving (GSM8K), challenging question-answering (CNNDM), translation (NewsDE), and complex multiple-choice reasoning (LogiQA). Experimental results show that SECURA achieves an average fine-tuning improvement of 3.59% across four multiple-choice question (MCQ) tasks and a 2.51% improvement across five question-answering (QA) tasks on models such as Gemma2 2b, Qwen2 1.5b, Qwen 2 7b, Llama3 8b, and Llama3.1 8b, compared to DoRA. Moreover, SECURA demonstrates superior knowledge retention capabilities, maintaining more than 70% accuracy on basic LLM knowledge across 16 continual learning tests, outperforming Experience Replay (ER), Sequential Learning (SEQ), EWC, I-LoRA, and CUR-LoRA.", 'abstract_zh': '随着大型语言模型（LLM）的迅速发展，全量微调（FT）这些模型因高计算需求而变得越来越不现实，同时FT还会导致灾难性遗忘。作为替代方案，低秩适应（LoRA）被提出，它仅微调一小部分参数，从而在显著减少资源需求的同时达到与FT相似的性能。然而，由于LoRA继承了FT的设计，灾难性遗忘的问题仍然存在。\n\n为解决这些挑战，我们提出了SECURA：Sigmoid-Enhanced CUR分解LoRA，一种新的参数高效微调（PEFT）变体，能够在缓解灾难性遗忘的同时提升微调性能。该方法引入了一种新的归一化技术SigNorm，以增强参数保留和总体性能。\n\n实验结果表明，SECURA在多种任务上均表现出色，包括数学问题解决（GSM8K）、挑战性问答（CNNDM）、翻译（NewsDE）和复杂多项选择推理（LogiQA）。实验结果显示，在Gemma2 2b、Qwen2 1.5b、Qwen 2 7b、Llama3 8b和Llama3.1 8b等模型上，与DoRA相比，SECURA在四个多项选择问题（MCQ）任务上的微调性能平均提高了3.59%，在五个问答（QA）任务上的性能提高了2.51%。此外，SECURA在基本LLM知识上的知识保留能力更优，在16次连续学习测试中保持了超过70%的准确性，优于Experience Replay（ER）、Sequential Learning（SEQ）、EWC、I-LoRA和CUR-LoRA。', 'title_zh': 'SECURA：增强的Sigmoid-CUR分解方法，保留不间断的低秩适应性在大规模语言模型中'}
{'arxiv_id': 'arXiv:2502.18156', 'title': 'Can LLMs Explain Themselves Counterfactually?', 'authors': 'Zahra Dehghanighobadi, Asja Fischer, Muhammad Bilal Zafar', 'link': 'https://arxiv.org/abs/2502.18156', 'abstract': 'Explanations are an important tool for gaining insights into the behavior of ML models, calibrating user trust and ensuring regulatory compliance. Past few years have seen a flurry of post-hoc methods for generating model explanations, many of which involve computing model gradients or solving specially designed optimization problems. However, owing to the remarkable reasoning abilities of Large Language Model (LLMs), self-explanation, that is, prompting the model to explain its outputs has recently emerged as a new paradigm. In this work, we study a specific type of self-explanations, self-generated counterfactual explanations (SCEs). We design tests for measuring the efficacy of LLMs in generating SCEs. Analysis over various LLM families, model sizes, temperature settings, and datasets reveals that LLMs sometimes struggle to generate SCEs. Even when they do, their prediction often does not agree with their own counterfactual reasoning.', 'abstract_zh': '自解释：大型语言模型生成-counterfactual解释的研究', 'title_zh': 'LLMs能否进行反事实解释？'}
{'arxiv_id': 'arXiv:2502.18147', 'title': 'Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations', 'authors': 'Lucy Farnik, Tim Lawson, Conor Houghton, Laurence Aitchison', 'link': 'https://arxiv.org/abs/2502.18147', 'abstract': 'Sparse autoencoders (SAEs) have been successfully used to discover sparse and human-interpretable representations of the latent activations of LLMs. However, we would ultimately like to understand the computations performed by LLMs and not just their representations. The extent to which SAEs can help us understand computations is unclear because they are not designed to "sparsify" computations in any sense, only latent activations. To solve this, we propose Jacobian SAEs (JSAEs), which yield not only sparsity in the input and output activations of a given model component but also sparsity in the computation (formally, the Jacobian) connecting them. With a naïve implementation, the Jacobians in LLMs would be computationally intractable due to their size. One key technical contribution is thus finding an efficient way of computing Jacobians in this setup. We find that JSAEs extract a relatively large degree of computational sparsity while preserving downstream LLM performance approximately as well as traditional SAEs. We also show that Jacobians are a reasonable proxy for computational sparsity because MLPs are approximately linear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a greater degree of computational sparsity on pre-trained LLMs than on the equivalent randomized LLM. This shows that the sparsity of the computational graph appears to be a property that LLMs learn through training, and suggests that JSAEs might be more suitable for understanding learned transformer computations than standard SAEs.', 'abstract_zh': 'Jacobian 自编码器 (JSAEs) 用于发现 LLMs 的紧凑且计算可解释的表示', 'title_zh': 'Jacobian稀疏自编码器：使计算稀疏，而不仅仅是激活函数'}
{'arxiv_id': 'arXiv:2502.18138', 'title': 'Large Language Model Driven Agents for Simulating Echo Chamber Formation', 'authors': 'Chenhao Gu, Ling Luo, Zainab Razia Zaidi, Shanika Karunasekera', 'link': 'https://arxiv.org/abs/2502.18138', 'abstract': 'The rise of echo chambers on social media platforms has heightened concerns about polarization and the reinforcement of existing beliefs. Traditional approaches for simulating echo chamber formation have often relied on predefined rules and numerical simulations, which, while insightful, may lack the nuance needed to capture complex, real-world interactions. In this paper, we present a novel framework that leverages large language models (LLMs) as generative agents to simulate echo chamber dynamics within social networks. The novelty of our approach is that it incorporates both opinion updates and network rewiring behaviors driven by LLMs, allowing for a context-aware and semantically rich simulation of social interactions. Additionally, we utilize real-world Twitter (now X) data to benchmark the LLM-based simulation against actual social media behaviors, providing insights into the accuracy and realism of the generated opinion trends. Our results demonstrate the efficacy of LLMs in modeling echo chamber formation, capturing both structural and semantic dimensions of opinion clustering. %This work contributes to a deeper understanding of social influence dynamics and offers a new tool for studying polarization in online communities.', 'abstract_zh': '社交媒体平台上的回声室效应兴起加剧了对 polarization 和现有信念强化的关注。本文提出了一种新颖框架，利用大规模语言模型（LLMs）作为生成代理来模拟社交网络内的回声室动态。该方法的 novelty 在于通过 LLMs 驱动意见更新和网络重构行为，实现一种具有上下文感知和语义丰富性的社交互动模拟。此外，我们使用真实的 Twitter（现 X）数据来验证基于 LLM 的模拟与实际社交媒体行为的契合度，提供生成意见趋势准确性和真实性的洞见。研究结果表明，LLMs 在建模回声室效应方面是有效的，能够捕捉意见簇的结构和语义维度。%本文加深了对社会影响动态的理解，并提供了一个研究在线社区极化的新工具。', 'title_zh': '大型语言模型驱动的代理模拟回声室效应形成'}
{'arxiv_id': 'arXiv:2502.18116', 'title': 'Bayesian Optimization for Controlled Image Editing via LLMs', 'authors': 'Chengkun Cai, Haoliang Liu, Xu Zhao, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq-Neng Hwang, Serge Belongie, Lei Li', 'link': 'https://arxiv.org/abs/2502.18116', 'abstract': "In the rapidly evolving field of image generation, achieving precise control over generated content and maintaining semantic consistency remain significant limitations, particularly concerning grounding techniques and the necessity for model fine-tuning. To address these challenges, we propose BayesGenie, an off-the-shelf approach that integrates Large Language Models (LLMs) with Bayesian Optimization to facilitate precise and user-friendly image editing. Our method enables users to modify images through natural language descriptions without manual area marking, while preserving the original image's semantic integrity. Unlike existing techniques that require extensive pre-training or fine-tuning, our approach demonstrates remarkable adaptability across various LLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian optimization strategy to automatically refine the inference process parameters, achieving high-precision image editing with minimal user intervention. Through extensive experiments across diverse scenarios, we demonstrate that our framework significantly outperforms existing methods in both editing accuracy and semantic preservation, as validated using different LLMs including Claude3 and GPT-4.", 'abstract_zh': '在图像生成快速发展的领域中，实现对生成内容的精确控制和保持语义一致性仍然是重要的限制，特别是在 grounding 技术和模型微调的必要性方面。为了解决这些挑战，我们提出了 BayesGenie，一种将大型语言模型（LLMs）与贝叶斯优化相结合的现成方法，以促进精确和用户友好的图像编辑。该方法允许用户通过自然语言描述来修改图像而不进行手动区域标记，同时保留原始图像的语义完整性。与需要大量预训练或微调的现有技术不同，我们的方法通过其模型无感知的设计展示了在各种 LLMs 上的显著适应性。BayesGenie 采用适应性的贝叶斯优化策略自动细化推理过程参数，实现高精度的图像编辑并减少用户干预。通过在多样场景下的广泛实验，我们证明了我们的框架在编辑准确性和语义保真度方面显著优于现有方法，并得到了包括 Claude3 和 GPT-4 在内的不同 LLMs 的验证。', 'title_zh': '基于LLMs的可控图像编辑的贝叶斯优化'}
{'arxiv_id': 'arXiv:2502.18080', 'title': 'Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning', 'authors': 'Wenkai Yang, Shuming Ma, Yankai Lin, Furu Wei', 'link': 'https://arxiv.org/abs/2502.18080', 'abstract': "Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits of increasing test-time compute by extending the CoT lengths of Large Language Models (LLMs), we are concerned about a potential issue hidden behind the current pursuit of test-time scaling: Would excessively scaling the CoT length actually bring adverse effects to a model's reasoning performance? Our explorations on mathematical reasoning tasks reveal an unexpected finding that scaling with longer CoTs can indeed impair the reasoning performance of LLMs in certain domains. Moreover, we discover that there exists an optimal scaled length distribution that differs across different domains. Based on these insights, we propose a Thinking-Optimal Scaling strategy. Our method first uses a small set of seed data with varying response length distributions to teach the model to adopt different reasoning efforts for deep thinking. Then, the model selects its shortest correct response under different reasoning efforts on additional problems for self-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct outperform other distillation-based 32B o1-like models across various math benchmarks, and achieve performance on par with QwQ-32B-Preview.", 'abstract_zh': '最近的研究表明，让模型通过更长的Chain of Thoughts（CoTs）进行更多思考可以显著提高其在复杂推理任务中的表现。尽管当前研究继续探索通过延长大型语言模型（LLMs）的CoT长度来增加测试时计算量带来的益处，但我们担心当前追求测试时扩展背后隐藏的问题：过度扩展CoT长度是否会对模型的推理性能产生不利影响？我们的探索在数学推理任务中揭示了一个意外的发现：在某些领域，使用更长的CoTs进行扩展确实会损害LLMs的推理性能。此外，我们发现不同领域存在不同的最优扩展长度分布。基于这些洞察，我们提出了一种思考最优扩展策略。该方法首先使用具有不同响应长度分布的一组种子数据来教导模型根据不同推理努力进行深入思考。然后，模型在不同推理努力下选择其最短的正确响应进行自我改进。基于Qwen2.5-32B-Instruct构建的自我改进模型在各种数学基准测试中优于其他基于蒸馏的32B o1-like模型，并且性能与QwQ-32B-Preview相当。', 'title_zh': '面向推理最优测试时计算量的扩展研究'}
{'arxiv_id': 'arXiv:2502.18040', 'title': 'AutoCas: Autoregressive Cascade Predictor in Social Networks via Large Language Models', 'authors': 'Yuhao Zheng, Chenghua Gong, Rui Sun, Juyuan Zhang, Liming Pan, Linyuan Lv', 'link': 'https://arxiv.org/abs/2502.18040', 'abstract': 'Popularity prediction in information cascades plays a crucial role in social computing, with broad applications in viral marketing, misinformation control, and content recommendation. However, information propagation mechanisms, user behavior, and temporal activity patterns exhibit significant diversity, necessitating a foundational model capable of adapting to such variations. At the same time, the amount of available cascade data remains relatively limited compared to the vast datasets used for training large language models (LLMs). Recent studies have demonstrated the feasibility of leveraging LLMs for time-series prediction by exploiting commonalities across different time-series domains. Building on this insight, we introduce the Autoregressive Information Cascade Predictor (AutoCas), an LLM-enhanced model designed specifically for cascade popularity prediction. Unlike natural language sequences, cascade data is characterized by complex local topologies, diffusion contexts, and evolving dynamics, requiring specialized adaptations for effective LLM integration. To address these challenges, we first tokenize cascade data to align it with sequence modeling principles. Next, we reformulate cascade diffusion as an autoregressive modeling task to fully harness the architectural strengths of LLMs. Beyond conventional approaches, we further introduce prompt learning to enhance the synergy between LLMs and cascade prediction. Extensive experiments demonstrate that AutoCas significantly outperforms baseline models in cascade popularity prediction while exhibiting scaling behavior inherited from LLMs. Code is available at this repository: this https URL', 'abstract_zh': '信息 cascade 中的流行度预测在社会计算中起着关键作用，广泛应用于病毒营销、虚假信息控制和内容推荐。然而，信息传播机制、用户行为和时间活动模式表现出显著的多样性，需要一种能适应这些变化的基礎模型。同时，可用的 cascade 数据量相对有限，远少于用于训练大型语言模型（LLMs）的大规模数据集。近期研究表明，通过利用不同时间序列领域的共性，可以利用 LLMs 进行时间序列预测。基于这一认识，我们提出了 Autoregressive Information Cascade Predictor (AutoCas)，一种增强的 LLM 模型，专门用于 cascade 流行度预测。不同于自然语言序列，cascade 数据特征复杂，包含复杂的地方拓扑、传播上下文和演变动力学，需要专门的适应以有效集成 LLMs。为了解决这些挑战，我们首先对 cascade 数据进行分词，使其与序列建模原则对齐。接着，我们将 cascade 传播重新表述为一个自回归建模任务，以充分利用 LLMs 的架构优势。除此之外，我们还引入了提示学习以增强 LLMs 和 cascade 预测之间的协同作用。广泛的实验表明，AutoCas 在 cascade 流行度预测方面显著优于基准模型，并且表现出继承自 LLMs 的可扩展性。代码可在以下仓库获取：this https URL。', 'title_zh': 'AutoCas: 社交网络中基于大规模语言模型的自回归级联预测器'}
{'arxiv_id': 'arXiv:2502.18020', 'title': 'AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages', 'authors': 'Joshua Sakthivel Raju, Sanjay S, Jaskaran Singh Walia, Srinivas Raghav, Vukosi Marivate', 'link': 'https://arxiv.org/abs/2502.18020', 'abstract': "Language model compression through knowledge distillation has emerged as a promising approach for deploying large language models in resource-constrained environments. However, existing methods often struggle to maintain performance when distilling multilingual models, especially for low-resource languages. In this paper, we present a novel hybrid distillation approach that combines traditional knowledge distillation with a simplified attention matching mechanism, specifically designed for multilingual contexts. Our method introduces an extremely compact student model architecture, significantly smaller than conventional multilingual models. We evaluate our approach on five African languages: Kinyarwanda, Swahili, Hausa, Igbo, and Yoruba. The distilled student model; AfroXLMR-Comet successfully captures both the output distribution and internal attention patterns of a larger teacher model (AfroXLMR-Large) while reducing the model size by over 85%. Experimental results demonstrate that our hybrid approach achieves competitive performance compared to the teacher model, maintaining an accuracy within 85% of the original model's performance while requiring substantially fewer computational resources. Our work provides a practical framework for deploying efficient multilingual models in resource-constrained environments, particularly benefiting applications involving African languages.", 'abstract_zh': '通过知识蒸馏的语言模型压缩在资源受限环境中部署大规模语言模型已 emerges as a promising approach.然而，现有方法在蒸馏多语言模型时往往难以保持性能，尤其是对于低资源语言。在本文中，我们提出了一种新颖的混合蒸馏方法，结合了传统的知识蒸馏和简化后的注意力匹配机制，特别适用于多语言环境。我们的方法引入了一种极其紧凑的学生模型架构，明显小于传统的多语言模型。我们在五种非洲语言： Kirundi、Swahili、Hausa、Igbo 和 Yoruba 上评估了我们的方法。蒸馏后的学生模型 AfroXLMR-Comet 成功地捕捉到了更大教师模型（AfroXLMR-Large）的输出分布和内部注意力模式，同时将模型大小减少了超过 85%。实验结果表明，我们的混合方法在性能上与教师模型相当，在计算资源需求显著减少的情况下，准确率达到了原模型性能的 85% 以内。我们的工作提供了一种实用的框架，用于在资源受限环境中部署高效的多语言模型，特别有利于涉及非洲语言的应用。', 'title_zh': 'AfroXLMR-Comet: 基于注意力匹配的多语言知识蒸馏方法及其在低资源语言中的应用'}
{'arxiv_id': 'arXiv:2502.18008', 'title': 'NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms', 'authors': 'Yashan Wang, Shangda Wu, Jianhuai Hu, Xingjian Du, Yueqi Peng, Yongxin Huang, Shuai Fan, Xiaobing Li, Feng Yu, Maosong Sun', 'link': 'https://arxiv.org/abs/2502.18008', 'abstract': 'We introduce NotaGen, a symbolic music generation model aiming to explore the potential of producing high-quality classical sheet music. Inspired by the success of Large Language Models (LLMs), NotaGen adopts pre-training, fine-tuning, and reinforcement learning paradigms (henceforth referred to as the LLM training paradigms). It is pre-trained on 1.6M pieces of music, and then fine-tuned on approximately 9K high-quality classical compositions conditioned on "period-composer-instrumentation" prompts. For reinforcement learning, we propose the CLaMP-DPO method, which further enhances generation quality and controllability without requiring human annotations or predefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in symbolic music generation models with different architectures and encoding schemes. Furthermore, subjective A/B tests show that NotaGen outperforms baseline models against human compositions, greatly advancing musical aesthetics in symbolic music this http URL project homepage is this https URL.', 'abstract_zh': 'NotaGen：一种探索高质量古典乐谱生成潜力的符号化音乐生成模型', 'title_zh': 'NotaGen：大规模语言模型训练范式在符号音乐生成中提升音乐性'}
{'arxiv_id': 'arXiv:2502.17987', 'title': 'MAGE: Multi-Head Attention Guided Embeddings for Low Resource Sentiment Classification', 'authors': 'Varun Vashisht, Samar Singh, Mihir Konduskar, Jaskaran Singh Walia, Vukosi Marivate', 'link': 'https://arxiv.org/abs/2502.17987', 'abstract': 'Due to the lack of quality data for low-resource Bantu languages, significant challenges are presented in text classification and other practical implementations. In this paper, we introduce an advanced model combining Language-Independent Data Augmentation (LiDA) with Multi-Head Attention based weighted embeddings to selectively enhance critical data points and improve text classification performance. This integration allows us to create robust data augmentation strategies that are effective across various linguistic contexts, ensuring that our model can handle the unique syntactic and semantic features of Bantu languages. This approach not only addresses the data scarcity issue but also sets a foundation for future research in low-resource language processing and classification tasks.', 'abstract_zh': '由于缺乏高质量的数据资源，Bantu低资源语言在文本分类和其他实际应用中面临重大挑战。本文介绍了一种结合了语言独立数据增强（LiDA）与多头注意力加权嵌入的先进模型，以选择性地增强关键数据点并提高文本分类性能。这种集成方案使我们能够创建适用于各种语言背景的稳健数据增强策略，确保模型能够处理Bantu语言的特殊句法和语义特征。这种方法不仅解决了数据稀缺问题，也为未来低资源语言处理和分类任务的研究奠定了基础。', 'title_zh': 'MAGE: 多头注意力引导嵌入低资源情感分类'}
{'arxiv_id': 'arXiv:2502.17967', 'title': 'LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena', 'authors': 'Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou', 'link': 'https://arxiv.org/abs/2502.17967', 'abstract': 'Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at this https URL.', 'abstract_zh': '近年来，大规模语言模型（LLMs）在自然语言处理任务中的性能有了显著提升，但其在动态、未见过的任务中，特别是数值推理任务中的泛化能力仍存在挑战。现有基准主要评估LLMs在具有预定义最优解的问题上的表现，这可能与现实世界中没有明确答案的情景不一致。为了弥合这一差距，我们设计了Agent Trading Arena，这是一个通过零和博弈模拟复杂经济系统的虚拟数值游戏，在该游戏中，代理投资股票组合。我们的实验表明，当处理呈现文本形式的股票数据时，LLMs在代数推理方面挣扎，往往关注局部细节而非整体趋势。相比之下，当展示可视化数据（如散点图或K线图）时，LLMs在几何推理方面的表现显著更好，这表明可视化表示可以增强数值推理能力。通过引入反射模块，该能力进一步提升，有助于复杂数据的分析和解释。我们在NASDAQ股票数据集上验证了这些发现，显示LLMs在处理可视化数据方面表现出更强的推理能力。我们的代码和数据可在以下网址获取。', 'title_zh': 'LLM在交易 arena 中对几何的理解优于代数：基于LLM的智能体的数值理解'}
{'arxiv_id': 'arXiv:2502.17955', 'title': "Language Models' Factuality Depends on the Language of Inquiry", 'authors': 'Tushar Aggarwal, Kumar Tanmay, Ayush Agrawal, Kumar Ayush, Hamid Palangi, Paul Pu Liang', 'link': 'https://arxiv.org/abs/2502.17955', 'abstract': "Multilingual language models (LMs) are expected to recall factual knowledge consistently across languages, yet they often fail to transfer knowledge between languages even when they possess the correct information in one of the languages. For example, we find that an LM may correctly identify Rashed Al Shashai as being from Saudi Arabia when asked in Arabic, but consistently fails to do so when asked in English or Swahili. To systematically investigate this limitation, we introduce a benchmark of 10,000 country-related facts across 13 languages and propose three novel metrics: Factual Recall Score, Knowledge Transferability Score, and Cross-Lingual Factual Knowledge Transferability Score-to quantify factual recall and knowledge transferability in LMs across different languages. Our results reveal fundamental weaknesses in today's state-of-the-art LMs, particularly in cross-lingual generalization where models fail to transfer knowledge effectively across different languages, leading to inconsistent performance sensitive to the language used. Our findings emphasize the need for LMs to recognize language-specific factual reliability and leverage the most trustworthy information across languages. We release our benchmark and evaluation framework to drive future research in multilingual knowledge transfer.", 'abstract_zh': '多语言语言模型（LMs）在不同语言中一致地回忆事实知识存在期望，但它们往往在一种语言中有正确信息时仍无法在不同语言之间转移知识。为了系统地探讨这一限制，我们引入了一个包含13种语言中10,000条国家相关的事实的基准，并提出三项新的度量标准：事实回忆分值、知识可转移性分值和跨语言事实知识可转移性分值，以量化不同语言中LMs的事实回忆和知识可转移性。我们的结果揭示了当今最先进的LMs的基本不足之处，特别是在跨语言泛化方面，模型无法有效跨语言转移知识，导致使用不同语言时性能不一致。我们的发现强调LMs需要识别语言特定的事实可靠性，并在不同语言中利用最可信的信息。我们发布了该基准和评估框架，以推动多语言知识转移的未来研究。', 'title_zh': '语言模型的事实性取决于查询语言。'}
{'arxiv_id': 'arXiv:2502.17947', 'title': 'DeepSeek-R1 Outperforms Gemini 2.0 Pro, OpenAI o1, and o3-mini in Bilingual Complex Ophthalmology Reasoning', 'authors': 'Pusheng Xu, Yue Wu, Kai Jin, Xiaolan Chen, Mingguang He, Danli Shi', 'link': 'https://arxiv.org/abs/2502.17947', 'abstract': 'Purpose: To evaluate the accuracy and reasoning ability of DeepSeek-R1 and three other recently released large language models (LLMs) in bilingual complex ophthalmology cases. Methods: A total of 130 multiple-choice questions (MCQs) related to diagnosis (n = 39) and management (n = 91) were collected from the Chinese ophthalmology senior professional title examination and categorized into six topics. These MCQs were translated into English using DeepSeek-R1. The responses of DeepSeek-R1, Gemini 2.0 Pro, OpenAI o1 and o3-mini were generated under default configurations between February 15 and February 20, 2025. Accuracy was calculated as the proportion of correctly answered questions, with omissions and extra answers considered incorrect. Reasoning ability was evaluated through analyzing reasoning logic and the causes of reasoning error. Results: DeepSeek-R1 demonstrated the highest overall accuracy, achieving 0.862 in Chinese MCQs and 0.808 in English MCQs. Gemini 2.0 Pro, OpenAI o1, and OpenAI o3-mini attained accuracies of 0.715, 0.685, and 0.692 in Chinese MCQs (all P<0.001 compared with DeepSeek-R1), and 0.746 (P=0.115), 0.723 (P=0.027), and 0.577 (P<0.001) in English MCQs, respectively. DeepSeek-R1 achieved the highest accuracy across five topics in both Chinese and English MCQs. It also excelled in management questions conducted in Chinese (all P<0.05). Reasoning ability analysis showed that the four LLMs shared similar reasoning logic. Ignoring key positive history, ignoring key positive signs, misinterpretation medical data, and too aggressive were the most common causes of reasoning errors. Conclusion: DeepSeek-R1 demonstrated superior performance in bilingual complex ophthalmology reasoning tasks than three other state-of-the-art LLMs. While its clinical applicability remains challenging, it shows promise for supporting diagnosis and clinical decision-making.', 'abstract_zh': '目的：评估DeepSeek-R1及其对比的三种最近发布的大型语言模型（LLMs）在双语复杂眼科病例中的准确性和推理能力。方法：收集了130道与诊断（n=39）和管理（n=91）相关的多项选择题（MCQs），并按照六个主题进行了分类。使用DeepSeek-R1将这些MCQs翻译成英文。在2025年2月15日至20日之间，四种LLMs（默认配置）生成了响应。准确性计算为正确回答的问题比例，未作答和额外答案视为错误。推理能力通过分析推理逻辑及其错误原因进行评估。结果：DeepSeek-R1在总体准确率上最高，中文MCQs为0.862，英文MCQs为0.808。Gemini 2.0 Pro、OpenAI o1和OpenAI o3-mini在中文MCQs中的准确率分别为0.715、0.685和0.692（所有值与DeepSeek-R1相比P<0.001），英文MCQs分别为0.746（P=0.115）、0.723（P=0.027）和0.577（P<0.001）。DeepSeek-R1在所有五个主题的中文和英文MCQs中的准确率最高。在中文管理问题中，其表现也最好（所有P<0.05）。推理能力分析显示，四种LLMs的推理逻辑相似。忽略关键阳性病史、忽略关键阳性体征、误解读医疗数据和过于激进是最常见的推理错误原因。结论：DeepSeek-R1在双语复杂眼科推理任务中表现优于三种其他最先进的LLMs。尽管其临床应用仍具有挑战性，但它在支持诊断和临床决策方面具有潜力。', 'title_zh': 'DeepSeek-R1 在双语复杂眼科推理任务中性能优于 Gemini 2.0 Pro、OpenAI o1 和 o3-mini'}
{'arxiv_id': 'arXiv:2502.17910', 'title': 'Scaling LLM Pre-training with Vocabulary Curriculum', 'authors': 'Fangyuan Yu', 'link': 'https://arxiv.org/abs/2502.17910', 'abstract': 'Modern language models rely on static vocabularies, fixed before pretraining, in contrast to the adaptive vocabulary acquisition observed in human language learning. To bridge this gap, we introduce vocabulary curriculum learning, an approach that improves pretraining efficiency with log-linear scaling gains relative to vocabulary size. Our method alternates between entropy-guided vocabulary expansion and model optimization, enabling models to learn transferable representations across diverse tokenization granularities. This approach naturally gives rise to an optimal computation allocation pattern: longer tokens capture predictable content, while shorter tokens focus on more complex, harder-to-predict contexts. Experiments on small-scale GPT models demonstrate improved scaling efficiency, reinforcing the effectiveness of dynamic tokenization. We release our code to support further research and plan to extend our experiments to larger models and diverse domains.', 'abstract_zh': '现代语言模型依赖于预训练前固定的静态词汇表，而在人类语言学习中观察到的是适应性词汇获取。为弥合这一差距，我们提出了词汇课程学习，该方法通过相对于词汇量的对数线性缩放增益来提高预训练效率。该方法交替进行基于熵的词汇扩展和模型优化，使模型能够在不同的标记化粒度下学习可转移的表示。这种做法自然导致了最优的计算分配模式：较长的标记捕获可预测的内容，而较短的标记则专注于更复杂、更难以预测的上下文。在小型GPT模型上的实验显示了增强的缩放效率，证实了动态标记化的效果。我们发布了代码以支持进一步的研究，并计划将实验扩展到更大的模型和不同的领域。', 'title_zh': 'LLM预训练的词汇量递增 scaling LLM预训练与词汇 Curriculum'}
{'arxiv_id': 'arXiv:2502.17900', 'title': 'Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs', 'authors': 'Che Liu, Cheng Ouyang, Zhongwei Wan, Haozhe Wang, Wenjia Bai, Rossella Arcucci', 'link': 'https://arxiv.org/abs/2502.17900', 'abstract': 'Recent advances in multimodal ECG representation learning center on aligning ECG signals with paired free-text reports. However, suboptimal alignment persists due to the complexity of medical language and the reliance on a full 12-lead setup, which is often unavailable in under-resourced settings. To tackle these issues, we propose **K-MERL**, a knowledge-enhanced multimodal ECG representation learning framework. **K-MERL** leverages large language models to extract structured knowledge from free-text reports and employs a lead-aware ECG encoder with dynamic lead masking to accommodate arbitrary lead inputs. Evaluations on six external ECG datasets show that **K-MERL** achieves state-of-the-art performance in zero-shot classification and linear probing tasks, while delivering an average **16%** AUC improvement over existing methods in partial-lead zero-shot classification.', 'abstract_zh': '近年来，多模态心电图表示学习的进展集中在对齐心电图信号与配对的自由文本报告。但由于医疗语言的复杂性和对完整12导联设置的依赖，在资源不足的环境中，这种对齐仍然不尽如人意。为解决这些问题，我们提出了一种知识增强的多模态心电图表示学习框架 **K-MERL**。K-MERL 利用大型语言模型从自由文本报告中提取结构化知识，并采用Aware Leads的心电图编码器结合动态导联遮掩，以适应任意导联输入。在六个外部心电图数据集上的评估表明，K-MERL 在零样本分类和线性探测任务中达到了最先进的性能，同时在部分导联零样本分类中比现有方法平均提高了16%的AUC值。', 'title_zh': '增强知识的多模态心电图表示学习：任意导联输入'}
{'arxiv_id': 'arXiv:2502.17898', 'title': 'VeriPlan: Integrating Formal Verification and LLMs into End-User Planning', 'authors': 'Christine Lee, David Porfirio, Xinyu Jessica Wang, Kevin Zhao, Bilge Mutlu', 'link': 'https://arxiv.org/abs/2502.17898', 'abstract': 'Automated planning is traditionally the domain of experts, utilized in fields like manufacturing and healthcare with the aid of expert planning tools. Recent advancements in LLMs have made planning more accessible to everyday users due to their potential to assist users with complex planning tasks. However, LLMs face several application challenges within end-user planning, including consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a system that applies formal verification techniques, specifically model checking, to enhance the reliability and flexibility of LLMs for end-user planning. In addition to the LLM planner, VeriPlan includes three additional core features -- a rule translator, flexibility sliders, and a model checker -- that engage users in the verification process. Through a user study (n=12), we evaluate VeriPlan, demonstrating improvements in the perceived quality, usability, and user satisfaction of LLMs. Our work shows the effective integration of formal verification and user-control features with LLMs for end-user planning tasks.', 'abstract_zh': '自动规划传统上是专家的领域，借助专家规划工具在制造和医疗等领域中应用。近期大型语言模型的进步使规划任务因能够辅助用户处理复杂规划任务而更加适用于普通用户。然而，大型语言模型在面向最终用户的规划中仍面临一致性、准确性和用户信任等问题。本文介绍了一种名为VeriPlan的系统，该系统利用形式验证技术——模型检查——来增强大型语言模型在最终用户规划中的可靠性和灵活性。VeriPlan还包括三个核心功能——规则翻译器、灵活性调节器和模型检查器——以使用户参与到验证过程。通过一项用户研究（n=12），我们评估了VeriPlan，展示了大型语言模型在感知质量、易用性和用户满意度方面的改进。我们的工作展示了将形式验证和用户控制功能有效集成到大型语言模型中以完成面向最终用户的规划任务的有效性。', 'title_zh': 'VeriPlan: 将形式验证与大规模语言模型集成到最终用户规划中'}
{'arxiv_id': 'arXiv:2502.17832', 'title': 'MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks', 'authors': 'Hyeonjeong Ha, Qiusi Zhan, Jeonghwan Kim, Dimitrios Bralios, Saikrishna Sanniboina, Nanyun Peng, Kai-wei Chang, Daniel Kang, Heng Ji', 'link': 'https://arxiv.org/abs/2502.17832', 'abstract': 'Multimodal large language models (MLLMs) equipped with Retrieval Augmented Generation (RAG) leverage both their rich parametric knowledge and the dynamic, external knowledge to excel in tasks such as Question Answering. While RAG enhances MLLMs by grounding responses in query-relevant external knowledge, this reliance poses a critical yet underexplored safety risk: knowledge poisoning attacks, where misinformation or irrelevant knowledge is intentionally injected into external knowledge bases to manipulate model outputs to be incorrect and even harmful. To expose such vulnerabilities in multimodal RAG, we propose MM-PoisonRAG, a novel knowledge poisoning attack framework with two attack strategies: Localized Poisoning Attack (LPA), which injects query-specific misinformation in both text and images for targeted manipulation, and Globalized Poisoning Attack (GPA) to provide false guidance during MLLM generation to elicit nonsensical responses across all queries. We evaluate our attacks across multiple tasks, models, and access settings, demonstrating that LPA successfully manipulates the MLLM to generate attacker-controlled answers, with a success rate of up to 56% on MultiModalQA. Moreover, GPA completely disrupts model generation to 0% accuracy with just a single irrelevant knowledge injection. Our results highlight the urgent need for robust defenses against knowledge poisoning to safeguard multimodal RAG frameworks.', 'abstract_zh': '多模态大语言模型的知识中毒攻击：MM-PoisonRAG框架', 'title_zh': 'MM-PoisonRAG: 阻断多模态RAG的局部和全局中毒攻击'}
{'arxiv_id': 'arXiv:2502.17814', 'title': 'An Overview of Large Language Models for Statisticians', 'authors': 'Wenlong Ji, Weizhe Yuan, Emily Getzen, Kyunghyun Cho, Michael I. Jordan, Song Mei, Jason E Weston, Weijie J. Su, Jing Xu, Linjun Zhang', 'link': 'https://arxiv.org/abs/2502.17814', 'abstract': 'Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problems -- in areas such as uncertainty quantification, decision-making, causal inference, and distribution shift -- require a deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster a deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges.', 'abstract_zh': '大规模语言模型（LLMs）已成为人工智能（AI）领域的变革性工具，展示出在文本生成、推理和决策等多种任务中的卓越能力。虽然其成功主要得益于计算能力的提升和深度学习架构的进步，但在不确定性量化、决策制定、因果推断和分布迁移等问题领域出现的新挑战，则需要统计学领域更深入的参与。本文探讨了统计学家如何在促进LLMs的发展中发挥重要作用，特别是那些旨在增强人类用户信任和透明度的努力。因此，我们重点关注不确定性量化、可解释性、公平性、隐私、水印和模型适应等议题。我们还考虑了LLMs在统计分析中的潜在角色。通过弥合AI与统计学之间的差距，我们旨在促进更深层次的协作，推动LLMs理论基础和实际应用的进步，最终塑造其在解决复杂社会挑战中的角色。', 'title_zh': '大型语言模型Overview for Statisticians'}
{'arxiv_id': 'arXiv:2502.17787', 'title': 'AIR: Complex Instruction Generation via Automatic Iterative Refinement', 'authors': 'Wei Liu, Yancheng He, Hui Huang, Chengwei Hu, Jiaheng Liu, Shilong Li, Wenbo Su, Bo Zheng', 'link': 'https://arxiv.org/abs/2502.17787', 'abstract': "With the development of large language models, their ability to follow simple instructions has significantly improved. However, adhering to complex instructions remains a major challenge. Current approaches to generating complex instructions are often irrelevant to the current instruction requirements or suffer from limited scalability and diversity. Moreover, methods such as back-translation, while effective for simple instruction generation, fail to leverage the rich contents and structures in large web corpora. In this paper, we propose a novel automatic iterative refinement framework to generate complex instructions with constraints, which not only better reflects the requirements of real scenarios but also significantly enhances LLMs' ability to follow complex instructions. The AIR framework consists of two stages: (1)Generate an initial instruction from a document; (2)Iteratively refine instructions with LLM-as-judge guidance by comparing the model's output with the document to incorporate valuable constraints. Finally, we construct the AIR-10K dataset with 10K complex instructions and demonstrate that instructions generated with our approach significantly improve the model's ability to follow complex instructions, outperforming existing methods for instruction generation.", 'abstract_zh': '随着大型语言模型的发展，它们遵循简单指令的能力显著提高，但遵守复杂指令仍然是一项重大挑战。当前生成复杂指令的方法往往与当前指令要求无关，或者受限于有限的可扩展性和多样性。此外，虽然反向翻译等方法对简单指令生成有效，但无法充分利用大规模网页语料库中的丰富内容和结构。在本文中，我们提出了一种新颖的自动迭代 refinement 框架，以生成受约束的复杂指令，不仅能更好地反映实际场景的需求，还能显著增强大型语言模型遵循复杂指令的能力。该 AIR 框架包含两个阶段：（1）从文档生成初始指令；（2）通过将模型输出与文档进行比较，利用 AIR 判官的指导进行迭代指令 refinement，逐步纳入有价值的需求约束。最后，我们构建了包含10,000条复杂指令的AIR-10K数据集，并证明使用我们方法生成的指令显著提高了模型遵循复杂指令的能力，优于现有指令生成方法。', 'title_zh': 'AIR：通过自动迭代 refining 的复杂指令生成'}
{'arxiv_id': 'arXiv:2502.17773', 'title': 'Uncertainty Quantification for LLM-Based Survey Simulations', 'authors': 'Chengpiao Huang, Yuhang Wu, Kaizheng Wang', 'link': 'https://arxiv.org/abs/2502.17773', 'abstract': 'We investigate the reliable use of simulated survey responses from large language models (LLMs) through the lens of uncertainty quantification. Our approach converts synthetic data into confidence sets for population parameters of human responses, addressing the distribution shift between the simulated and real populations. A key innovation lies in determining the optimal number of simulated responses: too many produce overly narrow confidence sets with poor coverage, while too few yield excessively loose estimates. To resolve this, our method adaptively selects the simulation sample size, ensuring valid average-case coverage guarantees. It is broadly applicable to any LLM, irrespective of its fidelity, and any procedure for constructing confidence sets. Additionally, the selected sample size quantifies the degree of misalignment between the LLM and the target human population. We illustrate our method on real datasets and LLMs.', 'abstract_zh': '我们通过不确定性量化的角度调查了大规模语言模型（LLMs）模拟调查响应的可靠使用方法。我们的方法将合成数据转换为人类响应总体参数的置信集，解决了模拟群体与真实群体之间的分布偏移问题。这一创新的关键在于确定模拟响应的最佳数量：数量过多会产生覆盖不佳的过窄置信区间，而数量过少则会导致过于宽松的估计。为解决这一问题，我们的方法自适应地选择模拟样本大小，确保有效的平均情况覆盖率保证。该方法适用于任何LLM，无论其保真度如何，以及任何置信区间构建方法。此外，选定的样本大小量化了LLM与目标人类群体之间的不一致程度。我们在实际数据集和LLM上展示了该方法。', 'title_zh': '基于LLM的调查模拟中的不确定性量化'}
{'arxiv_id': 'arXiv:2502.17764', 'title': 'DeepSeek vs. ChatGPT: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks', 'authors': 'Qile Jiang, Zhiwei Gao, George Em Karniadakis', 'link': 'https://arxiv.org/abs/2502.17764', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for tackling a wide range of problems, including those in scientific computing, particularly in solving partial differential equations (PDEs). However, different models exhibit distinct strengths and preferences, resulting in varying levels of performance. In this paper, we compare the capabilities of the most advanced LLMs--ChatGPT and DeepSeek--along with their reasoning-optimized versions in addressing computational challenges. Specifically, we evaluate their proficiency in solving traditional numerical problems in scientific computing as well as leveraging scientific machine learning techniques for PDE-based problems. We designed all our experiments so that a non-trivial decision is required, e.g. defining the proper space of input functions for neural operator learning. Our findings reveal that the latest model, ChatGPT o3-mini-high, usually delivers the most accurate results while also responding significantly faster than its reasoning counterpart, DeepSeek R1. This enhanced speed and accuracy make ChatGPT o3-mini-high a more practical and efficient choice for diverse computational tasks at this juncture.', 'abstract_zh': '大型语言模型（LLMs）在科学计算中的应用日益增多，特别是用于求解偏微分方程（PDEs）问题。然而，不同模型表现出不同的优势和偏好，导致性能差异。本文比较了最先进的LLMs——ChatGPT和DeepSeek及其推理优化版本在处理计算挑战方面的能力。具体来说，我们评估了它们在解决科学计算中的传统数值问题以及利用科学机器学习技术求解基于PDE的问题方面的 proficiency。我们设计的所有实验都要求做出非平凡的决策，例如为神经算子学习定义合适的输入函数空间。研究发现，最新版本的ChatGPT o3-mini-high通常能提供最准确的结果，并且响应速度比其推理优化版本DeepSeek R1快得多。这种增强的速度和准确性使ChatGPT o3-mini-high目前成为多种计算任务中的更实用和高效的选项。', 'title_zh': 'DeepSeek vs. ChatGPT: 科学计算和科学机器学习任务的比较研究'}
{'arxiv_id': 'arXiv:2502.17763', 'title': 'Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM', 'authors': 'Yuqing Wang, Xiao Yang', 'link': 'https://arxiv.org/abs/2502.17763', 'abstract': 'Traditional security protection methods struggle to address sophisticated attack vectors in large-scale distributed systems, particularly when balancing detection accuracy with data privacy concerns. This paper presents a novel distributed security threat detection system that integrates federated learning with multimodal large language models (LLMs). Our system leverages federated learning to ensure data privacy while employing multimodal LLMs to process heterogeneous data sources including network traffic, system logs, images, and sensor data. Experimental evaluation on a 10TB distributed dataset demonstrates that our approach achieves 96.4% detection accuracy, outperforming traditional baseline models by 4.1 percentage points. The system reduces both false positive and false negative rates by 1.8 and 2.4 percentage points respectively. Performance analysis shows that our system maintains efficient processing capabilities in distributed environments, requiring 180 seconds for model training and 3.8 seconds for threat detection across the distributed network. These results demonstrate significant improvements in detection accuracy and computational efficiency while preserving data privacy, suggesting strong potential for real-world deployment in large-scale security systems.', 'abstract_zh': '传统安全防护方法在大规模分布式系统中难以应对复杂的攻击向量，特别是在平衡检测精度与数据隐私之间时。本文提出了一种将联邦学习与多模态大型语言模型（LLMs）集成的新型分布式安全威胁检测系统。该系统利用联邦学习确保数据隐私，并采用多模态LLMs处理包括网络流量、系统日志、图像和传感器数据在内的异构数据源。在包含10TB数据的分布式数据集上的实验评估表明，本方法的检测准确率为96.4%，比传统的基线模型高出4.1个百分点。该系统分别将误报率和漏报率降低了1.8和2.4个百分点。性能分析显示，该系统在分布式环境中保持了高效的处理能力，模型训练需要180秒，分布式网络中的威胁检测需要3.8秒。这些结果展示了在保持数据隐私的同时，在检测精度和计算效率方面取得的重大改进，表明在大规模安全系统中具有很强的实际部署潜力。', 'title_zh': '集成联邦学习和多模态大语言模型的分布式安全威胁检测系统的设计与实现'}
{'arxiv_id': 'arXiv:2502.17728', 'title': 'LLM Inference Acceleration via Efficient Operation Fusion', 'authors': 'Mahsa Salmani, Ilya Soloveychik', 'link': 'https://arxiv.org/abs/2502.17728', 'abstract': 'The rapid development of the Transformer-based Large Language Models (LLMs) in recent years has been closely linked to their ever-growing and already enormous sizes. Many LLMs contain hundreds of billions of parameters and require dedicated hardware resources for training and inference. One of the key challenges inherent to the Transformer architecture is the requirement to support numerous non-linear transformations that involves normalization. For instance, each decoder block typically contains at least one Softmax operation and two Layernorms. The computation of the corresponding normalization scaling factors becomes a major bottleneck as it requires spatial collective operations. In other words, when it comes to the computation of denominators for Softmax and Layernorm, all vector elements must be aggregated into a single location, requiring significant communication. These collective operations slow down inference on Transformers by approximately 20%, defeating the whole purpose of distributed in-memory compute. In this work, we propose an extremely efficient technique that can completely hide the overhead caused by such collective operations. Note that each Softmax and Layernorm operation is typically followed by a linear layer. Since non-linear and linear operations are performed on different hardware engines, they can be easily parallelized once the algebra allows such commutation. By leveraging the inherent properties of linear operations, we can defer the normalization of the preceding Softmax and Layernorm until after the linear layer is computed. Now we can compute the collective scaling factors concurrently with the matrix multiplication and completely hide the latency of the former behind the latter. Such parallelization preserves the numerical accuracy while significantly improving the hardware utilization and reducing the overall latency.', 'abstract_zh': '基于Transformer的大语言模型的快速发展与其日益庞大的规模密切相关。其中许多模型包含数百亿参数，并需要专用的硬件资源进行训练和推理。Transformer架构的一个核心挑战是需要支持大量的非线性变换，这些变换涉及归一化操作。例如，每个解码器块通常包含至少一个Softmax操作和两个LayerNorm。相应归一化缩放因子的计算成为了一个主要瓶颈，因为它需要空间上的集体操作。换句话说，在Softmax和LayerNorm的分母计算中，所有向量元素必须聚合到一个位置，这需要大量的通信。这些集体操作会将Transformer的推理速度降低约20%，违背了分布式内存计算的初衷。本文提出了一种极其高效的技术，可以完全隐藏由此类集体操作引起的开销。注意到每个Softmax和LayerNorm操作通常后跟一个线性层。由于非线性和线性操作是在不同的硬件引擎上进行的，一旦代数允许交换，它们可以很容易地并行化。通过利用线性操作的固有特性，我们可以在计算线性层之后推迟前面的Softmax和LayerNorm的归一化。现在我们可以在进行矩阵乘法的同时并行计算集体缩放因子，并完全隐藏前者在后者之后的延迟。这种并行化保留了数值精度，显著提高了硬件利用率并减少了总体延迟。', 'title_zh': 'LLM运算融合加速方法'}
{'arxiv_id': 'arXiv:2502.17721', 'title': 'Aligning Compound AI Systems via System-level DPO', 'authors': 'Xiangwen Wang, Yibo Jacky Zhang, Zhoujie Ding, Katherine Tsai, Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2502.17721', 'abstract': 'Compound AI systems, comprising multiple interacting components such as LLM agents and external tools, demonstrate state-of-the-art results across diverse tasks. It is hence crucial to align components within the system to produce consistent results that match human expectations. However, conventional alignment methods, such as Direct Preference Optimization (DPO), are not directly applicable to compound AI systems. These challenges include the non-differentiable interactions between components, making end-to-end gradient optimization infeasible. Additionally, system-level preferences cannot be directly translated into component-level preferences, further complicating alignment. We address the issues by formulating compound AI systems as Directed Acyclic Graphs (DAGs), capturing the connections between agents and the data generation processes. We propose a system-level DPO (SysDPO) to jointly align compound systems by adapting the DPO to operate on these DAGs. We study the joint alignment of an LLM and a diffusion model to demonstrate the effectiveness of our approach. Our exploration provides insights into the alignment of compound AI systems and lays a foundation for future advancements.', 'abstract_zh': '复合AI系统中包含多个相互作用组件（如LLM代理和外部工具）在多种任务中展现出最先进的结果。因此，将系统内的组件调整一致，以产生符合人类预期的结果变得至关重要。然而，传统的对齐方法，如直接偏好优化（DPO），并不适用于复合AI系统。这些挑战包括组件之间的非可微交互，使得端到端的梯度优化不可行。此外，系统级别的偏好无法直接转换为组件级别的偏好，进一步增加了对齐的复杂性。我们通过将复合AI系统形式化为有向无环图（DAGs），捕捉代理之间的连接和数据生成过程，提出了系统级的DPO（SysDPO），以在DAGs上调整DPO来联合对齐复合系统。我们研究了一种LLM与扩散模型的联合对齐，以展示我们方法的有效性。我们的探索为复合AI系统的对齐提供了洞察，并为未来的发展奠定了基础。', 'title_zh': '基于系统级DPO对齐复合AI系统'}
{'arxiv_id': 'arXiv:2502.17720', 'title': 'Spontaneous Giving and Calculated Greed in Language Models', 'authors': 'Yuxuan Li, Hirokazu Shirado', 'link': 'https://arxiv.org/abs/2502.17720', 'abstract': 'Large language models, when trained with reinforcement learning, demonstrate advanced problem-solving capabilities through reasoning techniques like chain of thoughts and reflection. However, it is unclear how these reasoning capabilities extend to social intelligence. In this study, we investigate how reasoning influences model outcomes in social dilemmas. First, we examine the effects of chain-of-thought and reflection techniques in a public goods game. We then extend our analysis to six economic games on cooperation and punishment, comparing off-the-shelf non-reasoning and reasoning models. We find that reasoning models reduce cooperation and norm enforcement, prioritizing individual rationality. Consequently, groups with more reasoning models exhibit less cooperation and lower gains through repeated interactions. These behaviors parallel human tendencies of "spontaneous giving and calculated greed." Our results suggest the need for AI architectures that incorporate social intelligence alongside reasoning capabilities to ensure that AI supports, rather than disrupts, human cooperative intuition.', 'abstract_zh': '大型语言模型在通过强化学习训练后，通过链式思考和反思等推理技巧展示了高级的问题解决能力。然而，这些推理能力如何扩展到社交智能尚不清楚。本研究探讨了推理对社会困境中模型结果的影响。首先，我们在公共物品游戏中研究链式思考和反思技术的效果。然后，我们将分析扩展到六个涉及合作与惩罚的经济游戏，比较现成的非推理和推理模型。我们发现，推理模型减少了合作和规范执行，优先考虑个体理性。因此，具有更多推理模型的群体在重复互动中表现出更少的合作和更低的收益。这些行为与人类的“自发给予和精心算计的贪婪”倾向相似。我们的研究结果显示，为了确保人工智能支持而非破坏人类的合作直觉，需要并入社交智能的AI架构。', 'title_zh': '自发给予与计算贪婪：语言模型中的表现'}
{'arxiv_id': 'arXiv:2502.17709', 'title': 'Contrastive Visual Data Augmentation', 'authors': 'Yu Zhou, Bingxuan Li, Mohan Tang, Xiaomeng Jin, Te-Lin Wu, Kuan-Hao Huang, Heng Ji, Kai-Wei Chang, Nanyun Peng', 'link': 'https://arxiv.org/abs/2502.17709', 'abstract': 'Large multimodal models (LMMs) often struggle to recognize novel concepts, as they rely on pre-trained knowledge and have limited ability to capture subtle visual details. Domain-specific knowledge gaps in training also make them prone to confusing visually similar, commonly misrepresented, or low-resource concepts. To help LMMs better align nuanced visual features with language, improving their ability to recognize and reason about novel or rare concepts, we propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA extracts key contrastive textual and visual features of target concepts against the known concepts they are misrecognized as, and then uses multimodal generative models to produce targeted synthetic data. Automatic filtering of extracted features and augmented images is implemented to guarantee their quality, as verified by human annotators. We show the effectiveness and efficiency of CoDA on low-resource concept and diverse scene recognition datasets including INaturalist and SUN. We additionally collect NovelSpecies, a benchmark dataset consisting of newly discovered animal species that are guaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these three datasets show CoDA significantly improves SOTA visual data augmentation strategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains in accuracy.', 'abstract_zh': 'Large 多模态模型（LMMs）往往难以识别新的概念，因为它们依赖于预训练的知识，并且在捕捉细微的视觉细节方面能力有限。训练中的领域特定知识差距也使它们容易混淆视觉上相似、常见误表征或低资源的概念。为了帮助 LMMs 更好地将复杂的视觉特征与语言对齐，提高它们识别和推理新或稀有概念的能力，我们提出了一种对比视觉数据增强（CoDA）策略。CoDA 从目标概念与它们被误识别为的已知概念的关键对比文本和视觉特征中提取，然后使用多模态生成模型生成针对性的合成数据。通过人工注释者验证，实现了自动提取特征和增强图像的质量过滤。我们在包含 INaturalist 和 SUN 的低资源概念和多样场景识别数据集上展示了 CoDA 的有效性与效率。此外，我们收集了 NovelSpecies，这是一个基准数据集，其中包含确保 LMMs 未见过的新发现动物物种。对于这三个数据集上的 LLava-1.6 一次-shot 更新结果，CoDA 在准确性上分别提高了 NovelSpecies 12.3%、SUN 5.1% 和 iNat 6.0%。', 'title_zh': '对比视觉数据增强'}
{'arxiv_id': 'arXiv:2502.17666', 'title': 'Yes, Q-learning Helps Offline In-Context RL', 'authors': 'Denis Tarasov, Alexander Nikulin, Ilya Zisman, Albina Klepach, Andrei Polubarov, Nikita Lyubaykin, Alexander Derevyagin, Igor Kiselev, Vladislav Kurenkov', 'link': 'https://arxiv.org/abs/2502.17666', 'abstract': "In this work, we explore the integration of Reinforcement Learning (RL) approaches within a scalable offline In-Context RL (ICRL) framework. Through experiments across more than 150 datasets derived from GridWorld and MuJoCo environments, we demonstrate that optimizing RL objectives improves performance by approximately 40% on average compared to the widely established Algorithm Distillation (AD) baseline across various dataset coverages, structures, expertise levels, and environmental complexities. Our results also reveal that offline RL-based methods outperform online approaches, which are not specifically designed for offline scenarios. These findings underscore the importance of aligning the learning objectives with RL's reward-maximization goal and demonstrate that offline RL is a promising direction for application in ICRL settings.", 'abstract_zh': '本研究探讨了在可扩展的离线情境强化学习(ICRL)框架中集成强化学习(RL)方法的可能性。通过跨越150多个源自GridWorld和MuJoCo环境的数据集的实验，我们证明与广泛采用的算法蒸馏(AD)基线相比，优化RL目标可以平均提高约40%的性能，这一改善在不同数据集覆盖度、结构、专家水平和环境复杂性下均有表现。研究结果还表明，基于离线RL的方法在一般不为离线场景设计的在线方法之上表现出色。这些发现强调了将学习目标与RL的奖励最大化目标对齐的重要性，并展示了在ICRL设置中应用离线RL是一个有前景的方向。', 'title_zh': '是的，Q-learning有助于离线场景内的RL学习。'}
{'arxiv_id': 'arXiv:2502.17657', 'title': 'StatLLM: A Dataset for Evaluating the Performance of Large Language Models in Statistical Analysis', 'authors': 'Xinyi Song, Lina Lee, Kexin Xie, Xueying Liu, Xinwei Deng, Yili Hong', 'link': 'https://arxiv.org/abs/2502.17657', 'abstract': 'The coding capabilities of large language models (LLMs) have opened up new opportunities for automatic statistical analysis in machine learning and data science. However, before their widespread adoption, it is crucial to assess the accuracy of code generated by LLMs. A major challenge in this evaluation lies in the absence of a benchmark dataset for statistical code (e.g., SAS and R). To fill in this gap, this paper introduces StatLLM, an open-source dataset for evaluating the performance of LLMs in statistical analysis. The StatLLM dataset comprises three key components: statistical analysis tasks, LLM-generated SAS code, and human evaluation scores. The first component includes statistical analysis tasks spanning a variety of analyses and datasets, providing problem descriptions, dataset details, and human-verified SAS code. The second component features SAS code generated by ChatGPT 3.5, ChatGPT 4.0, and Llama 3.1 for those tasks. The third component contains evaluation scores from human experts in assessing the correctness, effectiveness, readability, executability, and output accuracy of the LLM-generated code. We also illustrate the unique potential of the established benchmark dataset for (1) evaluating and enhancing natural language processing metrics, (2) assessing and improving LLM performance in statistical coding, and (3) developing and testing of next-generation statistical software - advancements that are crucial for data science and machine learning research.', 'abstract_zh': '大型语言模型（LLMs）的编码能力为机器学习和数据科学中的自动统计分析打开了新的机会。然而，在广泛采用之前，评估LLMs生成代码的准确性至关重要。鉴于此，本文引入了StatLLM，这是一个开源数据集，用于评估LLMs在统计分析中的性能。StatLLM数据集包括三个关键组件：统计分析任务、LLM生成的SAS代码以及人类评估得分。该数据集的第一个组件包括涵盖多种分析和数据集的统计分析任务，提供问题描述、数据集细节和人工验证的SAS代码。第二个组件展示了ChatGPT 3.5、ChatGPT 4.0和Llama 3.1为这些任务生成的SAS代码。第三个组件包含专家对LLM生成代码的正确性、有效性、可读性、可执行性和输出准确性的人类评估得分。此外，本文还阐述了已建立基准数据集的独特潜力，用于（1）评估和提升自然语言处理指标，（2）评估和提升LLMs在统计编码中的性能，以及（3）开发和测试下一代统计软件——这些都是数据科学和机器学习研究的关键进展。', 'title_zh': 'StatLLM：用于评估大型语言模型在统计分析性能的数据集'}
{'arxiv_id': 'arXiv:2502.17638', 'title': 'Towards Robust Legal Reasoning: Harnessing Logical LLMs in Law', 'authors': 'Manuj Kant, Sareh Nabi, Manav Kant, Roland Scharrer, Megan Ma, Marzieh Nabi', 'link': 'https://arxiv.org/abs/2502.17638', 'abstract': "Legal services rely heavily on text processing. While large language models (LLMs) show promise, their application in legal contexts demands higher accuracy, repeatability, and transparency. Logic programs, by encoding legal concepts as structured rules and facts, offer reliable automation, but require sophisticated text extraction. We propose a neuro-symbolic approach that integrates LLMs' natural language understanding with logic-based reasoning to address these limitations.\nAs a legal document case study, we applied neuro-symbolic AI to coverage-related queries in insurance contracts using both closed and open-source LLMs. While LLMs have improved in legal reasoning, they still lack the accuracy and consistency required for complex contract analysis. In our analysis, we tested three methodologies to evaluate whether a specific claim is covered under a contract: a vanilla LLM, an unguided approach that leverages LLMs to encode both the contract and the claim, and a guided approach that uses a framework for the LLM to encode the contract. We demonstrated the promising capabilities of LLM + Logic in the guided approach.", 'abstract_zh': '法律服务高度依赖文本处理。虽然大型语言模型（LLMs）显示出潜力，但在法律情境中的应用需更高的准确度、可重复性和透明度。通过将法律概念编码为结构化规则和事实的逻辑程序提供了可靠的自动化，但需要复杂的文本提取。我们提出了一种神经符号方法，将LLMs的自然语言理解与基于逻辑的推理相结合，以解决这些限制。\n\n作为法律文件案例研究，我们使用闭源和开源LLMs将神经符号AI应用于保险合同的覆盖查询中。虽然LLMs在法律推理方面有所改进，但仍缺乏复杂合同分析所需的准确性和一致性。在我们的分析中，我们测试了三种方法来评估特定索赔是否在合同范围内： Vanilla LLM，一种未引导的方法，利用LLMs编码合同和索赔，以及一种引导方法，使用框架让LLMs编码合同。我们展示了引导方法中LLM + Logic的有前景的能力。', 'title_zh': '面向稳健的法律推理：利用逻辑大语言模型来推动法律领域的发展'}
{'arxiv_id': 'arXiv:2502.17605', 'title': 'PICASO: Permutation-Invariant Context Composition with State Space Models', 'authors': 'Tian Yu Liu, Alessandro Achille, Matthew Trager, Aditya Golatkar, Luca Zancato, Stefano Soatto', 'link': 'https://arxiv.org/abs/2502.17605', 'abstract': "Providing Large Language Models with relevant contextual knowledge at inference time has been shown to greatly improve the quality of their generations. This is often achieved by prepending informative passages of text, or 'contexts', retrieved from external knowledge bases to their input. However, processing additional contexts online incurs significant computation costs that scale with their length. State Space Models (SSMs) offer a promising solution by allowing a database of contexts to be mapped onto fixed-dimensional states from which to start the generation. A key challenge arises when attempting to leverage information present across multiple contexts, since there is no straightforward way to condition generation on multiple independent states in existing SSMs. To address this, we leverage a simple mathematical relation derived from SSM dynamics to compose multiple states into one that efficiently approximates the effect of concatenating textual contexts. Since the temporal ordering of contexts can often be uninformative, we enforce permutation-invariance by efficiently averaging states obtained via our composition algorithm across all possible context orderings. We evaluate our resulting method on WikiText and MSMARCO in both zero-shot and fine-tuned settings, and show that we can match the strongest performing baseline while enjoying on average 5.4x speedup.", 'abstract_zh': '为大型语言模型在推理时提供相关的上下文知识已被证明能显著提高其生成质量。这通常通过在输入前添加来自外部知识库的信息性文本片段或“上下文”来实现。然而，实时处理额外的上下文会带来显著的计算成本，这些成本随着上下文长度的增加而增加。状态空间模型（SSMs）通过允许将上下文数据库映射到固定维度的状态，从而从中开始生成，提供了颇具前景的解决方案。当尝试利用多个上下文中存在但无关紧要的信息时，一个关键挑战在于无法直接根据不同独立状态对生成进行条件约束。为解决这一问题，我们利用SSM动力学中的一种简单数学关系，将多个状态组合成一个能够高效模拟文本上下文串联效果的状态。由于上下文的时间顺序往往无关紧要，我们通过对通过组合算法获得的状态进行高效平均，来强制状态不变性，从而考虑所有可能的上下文顺序。我们在WikiText和MSMARCO上分别在零样本和微调设置中评估了该方法，结果显示，我们能够匹配表现最强的基线模型，同时平均加速5.4倍。', 'title_zh': 'PICASO: 基于状态空间模型的排列不变上下文组合'}
{'arxiv_id': 'arXiv:2502.17598', 'title': 'Hallucination Detection in LLMs Using Spectral Features of Attention Maps', 'authors': 'Jakub Binkowski, Denis Janiak, Albert Sawczyn, Bogdan Gabrys, Tomasz Kajdanowicz', 'link': 'https://arxiv.org/abs/2502.17598', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable performance across various tasks but remain prone to hallucinations. Detecting hallucinations is essential for safety-critical applications, and recent methods leverage attention map properties to this end, though their effectiveness remains limited. In this work, we investigate the spectral features of attention maps by interpreting them as adjacency matrices of graph structures. We propose the $\\text{LapEigvals}$ method, which utilises the top-$k$ eigenvalues of the Laplacian matrix derived from the attention maps as an input to hallucination detection probes. Empirical evaluations demonstrate that our approach achieves state-of-the-art hallucination detection performance among attention-based methods. Extensive ablation studies further highlight the robustness and generalisation of $\\text{LapEigvals}$, paving the way for future advancements in the hallucination detection domain.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中表现出色，但仍易产生幻觉。检测幻觉对于安全性关键应用至关重要，尽管近期方法通过利用注意力图的特性来实现这一目标，但其有效性仍有限。在本工作中，我们通过将注意力图解释为图结构的相邻矩阵来研究其频谱特征。我们提出了LapEigvals方法，该方法利用从注意力图导出的拉普拉斯矩阵的前k个特征值作为幻觉检测探针的输入。实验评估表明，我们的方法在基于注意力的方法中实现了最先进的幻觉检测性能。广泛的消融研究进一步突显了LapEigvals的鲁棒性和泛化能力，为幻觉检测领域的未来进步铺平了道路。', 'title_zh': 'LLMs中基于注意力图谱特征的幻觉检测'}
{'arxiv_id': 'arXiv:2502.17535', 'title': 'The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?', 'authors': 'Zhenheng Tang, Xiang Liu, Qian Wang, Peijie Dong, Bingsheng He, Xiaowen Chu, Bo Li', 'link': 'https://arxiv.org/abs/2502.17535', 'abstract': 'Motivated by reducing the computational and storage costs of LLMs, model compression and KV cache compression have attracted much attention from researchers. However, current methods predominantly emphasize maintaining the performance of compressed LLMs, as measured by perplexity or simple accuracy on tasks of common sense knowledge QA and basic arithmetic reasoning. In this blog, we present a brief review of recent advancements in LLMs related to retrieval-augmented generation, multi-step reasoning, external tools, and computational expressivity, all of which substantially enhance LLM performance. Then, we propose a lottery LLM hypothesis suggesting that for a given LLM and task, there exists a smaller lottery LLM capable of producing the same performance as the original LLM with the assistance of multi-step reasoning and external tools. Based on the review of current progress in LLMs, we discuss and summarize the essential capabilities that the lottery LLM and KV cache compression must possess, which are currently overlooked in existing methods.', 'abstract_zh': '受减轻大规模语言模型计算和存储成本的驱动，模型压缩和KV缓存压缩引起了研究人员的广泛关注。然而，当前方法主要侧重于保持压缩后的大规模语言模型的性能，这通常通过困惑度或常识知识问答和基本算术推理任务的简单准确性来衡量。在这篇博文中，我们简要回顾了与检索增强生成、多步推理、外部工具和计算表达性相关的最新大规模语言模型进展，这些进展显著提升了语言模型的性能。然后，我们提出了一种彩票语言模型假说，认为对于给定的语言模型和任务，存在一个更小的彩票语言模型，在多步推理和外部工具的帮助下，能够产生与原始语言模型相同的效果。基于当前大规模语言模型的发展，我们讨论并总结了彩票语言模型和KV缓存压缩目前被现有方法所忽视的必要能力。', 'title_zh': '彩票LLM假设：重新思考LLM压缩应保留的能力？'}
{'arxiv_id': 'arXiv:2502.17521', 'title': 'Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation', 'authors': 'Simin Chen, Yiming Chen, Zexin Li, Yifan Jiang, Zhongwei Wan, Yixin He, Dezhi Ran, Tianle Gu, Haizhou Li, Tao Xie, Baishakhi Ray', 'link': 'https://arxiv.org/abs/2502.17521', 'abstract': 'Data contamination has received increasing attention in the era of large language models (LLMs) due to their reliance on vast Internet-derived training corpora. To mitigate the risk of potential data contamination, LLM benchmarking has undergone a transformation from static to dynamic benchmarking. In this work, we conduct an in-depth analysis of existing static to dynamic benchmarking methods aimed at reducing data contamination risks. We first examine methods that enhance static benchmarks and identify their inherent limitations. We then highlight a critical gap-the lack of standardized criteria for evaluating dynamic benchmarks. Based on this observation, we propose a series of optimal design principles for dynamic benchmarking and analyze the limitations of existing dynamic benchmarks. This survey provides a concise yet comprehensive overview of recent advancements in data contamination research, offering valuable insights and a clear guide for future research efforts. We maintain a GitHub repository to continuously collect both static and dynamic benchmarking methods for LLMs. The repository can be found at this link.', 'abstract_zh': '大数据污染在大规模语言模型时代日益受到关注，因此动态基准测试成为减轻数据污染风险的重要途径。本文深入分析现有从静态到动态基准测试的方法，旨在减少数据污染风险。我们首先探讨了提升静态基准测试的方法，并指出了其固有局限性。然后，我们指出一个关键不足——缺乏标准化的动态基准测试评估标准。基于此观察，我们提出了动态基准测试的设计原则，并分析了现有动态基准测试的局限性。本文提供了一个简洁而全面的数据污染研究进展概览，为未来研究提供了宝贵的见解和清晰的指导。我们维护一个GitHub仓库，持续收集大规模语言模型的静态和动态基准测试方法。仓库链接请见此网址。', 'title_zh': '大数据污染背景下大型语言模型基准测试的 recent 进展：从静态评价到动态评价'}
{'arxiv_id': 'arXiv:2502.17510', 'title': 'Recurrent Knowledge Identification and Fusion for Language Model Continual Learning', 'authors': 'Yujie Feng, Xujia Wang, Zexin Lu, Shenghong Fu, Guangyuan Shi, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu', 'link': 'https://arxiv.org/abs/2502.17510', 'abstract': 'Continual learning (CL) is crucial for deploying large language models (LLMs) in dynamic real-world environments without costly retraining. While recent model ensemble and model merging methods guided by parameter importance have gained popularity, they often struggle to balance knowledge transfer and forgetting, mainly due to the reliance on static importance estimates during sequential training. In this paper, we present Recurrent-KIF, a novel CL framework for Recurrent Knowledge Identification and Fusion, which enables dynamic estimation of parameter importance distributions to enhance knowledge transfer. Inspired by human continual learning, Recurrent-KIF employs an inner loop that rapidly adapts to new tasks while identifying important parameters, coupled with an outer loop that globally manages the fusion of new and historical knowledge through redundant knowledge pruning and key knowledge merging. These inner-outer loops iteratively perform multiple rounds of fusion, allowing Recurrent-KIF to leverage intermediate training information and adaptively adjust fusion strategies based on evolving importance distributions. Extensive experiments on two CL benchmarks with various model sizes (from 770M to 13B) demonstrate that Recurrent-KIF effectively mitigates catastrophic forgetting and enhances knowledge transfer.', 'abstract_zh': '持续学习（CL）对于在动态现实环境中部署大规模语言模型（LLMs）至关重要，无需高昂的重新训练成本。尽管基于参数重要性的模型集成和模型融合方法近年来 popularity，它们在平衡知识传递和遗忘方面往往遇到困难，主要归因于顺序训练过程中依赖静态的重要性估计。在本文中，我们提出了循环-KIF，一种新颖的循环知识识别与融合（Recurrent Knowledge Identification and Fusion）持续学习框架，能够动态估计参数重要性分布以增强知识传递。受人类持续学习启发，循环-KIF 采用一个内部循环迅速适应新任务并识别重要参数，结合一个外部循环通过冗余知识剪枝和关键知识合并来全局管理新旧知识的融合。这些内部-外部循环迭代进行多次融合，使循环-KIF 能够利用中间训练信息并根据演化的的重要性分布自适应调整融合策略。在两个不同规模模型（从770M到13B）的持续学习基准实验中，广泛的实验结果表明循环-KIF 有效地缓解了灾难性遗忘并增强了知识传递。', 'title_zh': '循环知识识别与融合在语言模型持续学习中的应用'}
{'arxiv_id': 'arXiv:2502.17507', 'title': 'C-3DPO: Constrained Controlled Classification for Direct Preference Optimization', 'authors': 'Kavosh Asadi, Julien Han, Xingzi Xu, Dominique Perrault-Joncas, Shoham Sabach, Karim Bouyarmane, Mohammad Ghavamzadeh', 'link': 'https://arxiv.org/abs/2502.17507', 'abstract': 'Direct preference optimization (DPO)-style algorithms have emerged as a promising approach for solving the alignment problem in AI. We present a novel perspective that formulates these algorithms as implicit classification algorithms. This classification framework enables us to recover many variants of DPO-style algorithms by choosing appropriate classification labels and loss functions. We then leverage this classification framework to demonstrate that the underlying problem solved in these algorithms is under-specified, making them susceptible to probability collapse of the winner-loser responses. We address this by proposing a set of constraints designed to control the movement of probability mass between the winner and loser in the reference and target policies. Our resulting algorithm, which we call Constrained Controlled Classification DPO (\\texttt{C-3DPO}), has a meaningful RLHF interpretation. By hedging against probability collapse, \\texttt{C-3DPO} provides practical improvements over vanilla \\texttt{DPO} when aligning several large language models using standard preference datasets.', 'abstract_zh': '直接偏好优化（DPO）风格的算法已成为解决人工智能对齐问题的一种有 promise 的方法。我们提出了一种新的视角，将这些算法形式化为隐式分类算法。该分类框架允许我们通过选择合适的分类标签和损失函数来恢复许多种 DPO 风格的算法。然后，借助这一分类框架，我们证明这些算法解决的基础问题存在定义不足，使其容易出现赢家输家响应的概率崩溃。为此，我们提出了一系列约束条件，旨在控制参考策略和目标策略中赢家和输家之间概率质量的移动。我们提出的一种新的算法，称为受约束的控制分类 DPO（\\texttt{C-3DPO}），具有有意义的自监督人工智能对齐解释。通过抵消概率崩溃风险，\\texttt{C-3DPO} 在使用标准偏好数据集对齐多个大型语言模型时提供了实际改进。', 'title_zh': 'C-3DPO：受约束的控制分类以实现直接偏好优化'}
{'arxiv_id': 'arXiv:2502.17506', 'title': 'RAG-Enhanced Collaborative LLM Agents for Drug Discovery', 'authors': 'Namkyeong Lee, Edward De Brouwer, Ehsan Hajiramezanali, Chanyoung Park, Gabriele Scalia', 'link': 'https://arxiv.org/abs/2502.17506', 'abstract': 'Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMs in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses -- all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches.', 'abstract_zh': 'Recent advances in大型语言模型（LLMs）在加速药物发现中的应用潜力已经显现。然而，生物化学数据的专业性质往往需要成本高昂的领域特定微调，提出了关键挑战。首先，这阻碍了更灵活的通用LLMs在前沿药物发现任务中的应用。更重要的是，这阻碍了快速整合通过实验和研究不断生成的大量科学数据。为了研究这些挑战，我们提出了CLADD，这是一种通过检索增强生成（RAG）赋能的针对药物发现任务的自主系统。通过多个LLM代理的合作，CLADD动态检索生物医学知识库中的信息，上下文化查询分子，并整合相关证据生成响应，而无需领域特定微调。至关重要的是，我们解决了将RAG工作流应用于生物化学数据的关键障碍，包括数据异质性、模糊性和多源整合。我们展示了该框架在各种药物发现任务中的灵活性和有效性，表明其性能优于通用和领域特定的大规模语言模型以及传统的深度学习方法。', 'title_zh': 'RAG增强的合作型大语言模型药物发现代理'}
{'arxiv_id': 'arXiv:2502.17504', 'title': 'Protein Large Language Models: A Comprehensive Survey', 'authors': 'Yijia Xiao, Wanjia Zhao, Junkai Zhang, Yiqiao Jin, Han Zhang, Zhicheng Ren, Renliang Sun, Haixin Wang, Guancheng Wan, Pan Lu, Xiao Luo, Yu Zhang, James Zou, Yizhou Sun, Wei Wang', 'link': 'https://arxiv.org/abs/2502.17504', 'abstract': 'Protein-specific large language models (Protein LLMs) are revolutionizing protein science by enabling more efficient protein structure prediction, function annotation, and design. While existing surveys focus on specific aspects or applications, this work provides the first comprehensive overview of Protein LLMs, covering their architectures, training datasets, evaluation metrics, and diverse applications. Through a systematic analysis of over 100 articles, we propose a structured taxonomy of state-of-the-art Protein LLMs, analyze how they leverage large-scale protein sequence data for improved accuracy, and explore their potential in advancing protein engineering and biomedical research. Additionally, we discuss key challenges and future directions, positioning Protein LLMs as essential tools for scientific discovery in protein science. Resources are maintained at this https URL.', 'abstract_zh': '蛋白质特异性大规模语言模型（Protein LLMs）正通过提高蛋白质结构预测、功能注释和设计的效率，革新蛋白质科学。尽管现有综述侧重于特定方面或应用，本工作首次全面概述了Protein LLMs，涵盖其架构、训练数据集、评估指标和多样化的应用。通过对超过100篇文章的系统分析，我们提出了一种结构化的State-of-the-Art Protein LLMs分类体系，分析了它们如何利用大规模蛋白质序列数据以提高准确性，并探讨了它们在推进蛋白质工程和生物医药研究中的潜力。此外，我们讨论了关键挑战和未来方向，将Protein LLMs定位为蛋白质科学研究中必不可少的发现工具。相关资源维护在该网址：https://。', 'title_zh': '蛋白质大型语言模型：综合调查'}
{'arxiv_id': 'arXiv:2502.17501', 'title': 'CoKV: Optimizing KV Cache Allocation via Cooperative Game', 'authors': 'Qiheng Sun, Hongwei Zhang, Haocheng Xia, Jiayao Zhang, Jinfei Liu, Kui Ren', 'link': 'https://arxiv.org/abs/2502.17501', 'abstract': 'Large language models (LLMs) have achieved remarkable success on various aspects of human life. However, one of the major challenges in deploying these models is the substantial memory consumption required to store key-value pairs (KV), which imposes significant resource demands. Recent research has focused on KV cache budget allocation, with several approaches proposing head-level budget distribution by evaluating the importance of individual attention heads. These methods, however, assess the importance of heads independently, overlooking their cooperative contributions within the model, which may result in a deviation from their true impact on model performance. In light of this limitation, we propose CoKV, a novel method that models the cooperation between heads in model inference as a cooperative game. By evaluating the contribution of each head within the cooperative game, CoKV can allocate the cache budget more effectively. Extensive experiments show that CoKV achieves state-of-the-art performance on the LongBench benchmark using LLama-3-8B-Instruct and Mistral-7B models.', 'abstract_zh': '大型语言模型（LLMs）在人类生活的多个方面取得了显著成功。然而，部署这些模型的一个主要挑战是存储键值对（KV）所需的大量内存消耗，这带来了显著的资源需求。近期研究聚焦于KV缓存预算分配，提出了一些方法通过评估单个注意力头的重要性来进行头部预算分配。然而，这些方法独立评估每个头的重要性，忽视了它们在模型中的协同贡献，可能导致对其对模型性能真实影响的偏差。为克服这一局限，我们提出了一种名为CoKV的新方法，该方法将模型推理中头部之间的合作视为合作博弈。通过评估每个头在合作博弈中的贡献，CoKV能够更有效地分配缓存预算。大量实验表明，CoKV在LongBench基准上使用LLama-3-8B-Instruct和Mistral-7B模型时实现了最先进的性能。', 'title_zh': 'CoKV：通过合作博弈优化KV缓存分配'}
{'arxiv_id': 'arXiv:2502.17498', 'title': 'Improving Value-based Process Verifier via Structural Prior Injection', 'authors': 'Zetian Sun, Dongfang Li, Baotian Hu, Jun Yu, Min Zhang', 'link': 'https://arxiv.org/abs/2502.17498', 'abstract': "In the Large Language Model(LLM) reasoning scenario, people often estimate state value via Monte Carlo sampling. Though Monte Carlo estimation is an elegant method with less inductive bias, noise and errors are inevitably introduced due to the limited sampling. To handle the problem, we inject the structural prior into the value representation and transfer the scalar value into the expectation of a pre-defined categorical distribution, representing the noise and errors from a distribution perspective. Specifically, by treating the result of Monte Carlo sampling as a single sample from the prior ground-truth Binomial distribution, we quantify the sampling error as the mismatch between posterior estimated distribution and ground-truth distribution, which is thus optimized via distribution selection optimization. We test the performance of value-based process verifiers on Best-of-N task and Beam search task. Compared with the scalar value representation, we show that reasonable structural prior injection induced by different objective functions or optimization methods can improve the performance of value-based process verifiers for about 1$\\sim$2 points at little-to-no cost. We also show that under different structural prior, the verifiers' performances vary greatly despite having the same optimal solution, indicating the importance of reasonable structural prior injection.", 'abstract_zh': '在大型语言模型(LLM)推理场景中，人们常通过蒙特卡洛采样估计状态值。尽管蒙特卡洛估计方法简洁且具有较少的归纳偏置，但由于采样量有限，噪声和误差不可避免地被引入。为解决这一问题，我们向价值表示中注入结构先验，将标量值转换为预定义分类分布的期望，从分布的角度代表噪声和误差。具体而言，我们将蒙特卡洛采样的结果视为先验真实二项分布的一个样本，量化采样误差为后验估计分布与真实分布之间的不匹配程度，并通过分布选择优化进行优化。我们在Best-of-N任务和Beam搜索任务中测试基于价值的过程验证器的性能。与标量值表示相比，我们显示通过不同目标函数或优化方法引入合理的结构先验可以仅以微小或无成本提高大约1-2个点的验证器性能。同时，我们表明，在不同结构先验下，尽管最优解相同，验证器的性能差异很大，这强调了合理结构先验注入的重要性。', 'title_zh': '基于结构先验注入的价值导向过程验证器改进'}
{'arxiv_id': 'arXiv:2502.17494', 'title': 'External Large Foundation Model: How to Efficiently Serve Trillions of Parameters for Online Ads Recommendation', 'authors': 'Mingfu Liang, Xi Liu, Rong Jin, Boyang Liu, Qiuling Suo, Qinghai Zhou, Song Zhou, Laming Chen, Hua Zheng, Zhiyuan Li, Shali Jiang, Jiyan Yang, Xiaozhen Xia, Fan Yang, Yasmine Badr, Ellie Wen, Shuyu Xu, Hansey Chen, Zhengyu Zhang, Jade Nie, Chunzhi Yang, Zhichen Zeng, Weilin Zhang, Xingliang Huang, Qianru Li, Shiquan Wang, Evelyn Lyu, Wenjing Lu, Rui Zhang, Wenjun Wang, Jason Rudy, Mengyue Hang, Kai Wang, Yinbin Ma, Shuaiwen Wang, Sihan Zeng, Tongyi Tang, Xiaohan Wei, Longhao Jin, Jamey Zhang, Marcus Chen, Jiayi Zhang, Angie Huang, Chi Zhang, Zhengli Zhao, Jared Yang, Qiang Jin, Xian Chen, Amit Anand Amlesahwaram, Lexi Song, Liang Luo, Yuchen Hao, Nan Xiao, Yavuz Yetim, Luoshang Pan, Gaoxiang Liu, Yuxi Hu, Yuzhen Huang, Jackie Xu, Rich Zhu, Xin Zhang, Yiqun Liu, Hang Yin, Yuxin Chen, Buyun Zhang, Xiaoyi Liu, Sylvia Wang, Wenguang Mao, Zhijing Li, Qin Huang, Chonglin Sun, Shupin Mao, Jingzheng Qin, Peggy Yao, Jae-Woo Choi, Bin Gao, Ernest Wang, Lei Zhang, Wen-Yen Chen, Ted Lee, Jay Zha, Yi Meng, Alex Gong, Edison Gao, Alireza Vahdatpour, Yiping Han, Yantao Yao, Toshinari Kureha, Shuo Chang, Musharaf Sultan, John Bocharov, Sagar Chordia, Xiaorui Gan, Peng Sun, Rocky Liu, Bo Long, Wenlin Chen, Santanu Kolay, Huayu Li', 'link': 'https://arxiv.org/abs/2502.17494', 'abstract': 'Ads recommendation is a prominent service of online advertising systems and has been actively studied. Recent studies indicate that scaling-up and advanced design of the recommendation model can bring significant performance improvement. However, with a larger model scale, such prior studies have a significantly increasing gap from industry as they often neglect two fundamental challenges in industrial-scale applications. First, training and inference budgets are restricted for the model to be served, exceeding which may incur latency and impair user experience. Second, large-volume data arrive in a streaming mode with data distributions dynamically shifting, as new users/ads join and existing users/ads leave the system. We propose the External Large Foundation Model (ExFM) framework to address the overlooked challenges. Specifically, we develop external distillation and a data augmentation system (DAS) to control the computational cost of training/inference while maintaining high performance. We design the teacher in a way like a foundation model (FM) that can serve multiple students as vertical models (VMs) to amortize its building cost. We propose Auxiliary Head and Student Adapter to mitigate the data distribution gap between FM and VMs caused by the streaming data issue. Comprehensive experiments on internal industrial-scale applications and public datasets demonstrate significant performance gain by ExFM.', 'abstract_zh': '外部大型基础模型框架（ExFM）：应对工业规模应用中的挑战', 'title_zh': '外部大型基础模型：如何高效地为在线广告推荐服务万亿参数'}
{'arxiv_id': 'arXiv:2502.17442', 'title': 'Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement', 'authors': 'Xiaoqing Zhang, Yuhan Liu, Flood Sung, Xiuying Chen, Rui Yan', 'link': 'https://arxiv.org/abs/2502.17442', 'abstract': "Code generation is crucial in software engineering for automating the coding process efficiently. While test-time computation methods show promise, they suffer from high latency due to multiple computation rounds. To overcome this, we introduce ThinkCoder, a framework that combines thorough exploration with optimal refinement. The exploration phase diversifies the solution space by searching for potential solutions, followed by a refinement phase that enhances precision. This approach allows us to select the best solution through careful consideration before taking action, avoiding excessive trial and error. To further minimize test-time computation overhead, we introduce preference-driven optimization with Reinforced Self-Training (ReST), which uses exploration trajectories from ThinkCoder to guide LLM's evolution. By learning preferences, this approach improves LLM's exploration efficiency, reducing computational costs while maintaining accuracy. ThinkCoder boosts the performance of multiple base LLMs, excelling on benchmarks like HumanEval and MBPP. Compared to SOTA models, it improves Pass@1 by 1.5\\% over MapCoder with just 21.7\\% of the computation cost. Against AgentCoder, ThinkCoder achieves a 0.6\\% higher Pass@1 after 2 rounds, outperforming AgentCoder's 5 rounds. Additionally, ReST with success trajectories enhances efficiency, allowing models like LLaMA2-7B to achieve competitive results using only 20\\% of the computational resources. These results highlight the framework's effectiveness and scalability.", 'abstract_zh': '代码生成对于软件工程中的自动化编码过程至关重要。尽管测试时的计算方法显示出潜力，但由于需要多轮计算，它们会遭受高延迟的问题。为解决这一问题，我们引入了ThinkCoder框架，该框架结合了深入的探索和最优的精炼。探索阶段通过寻找潜在解决方案来多样化解空间，随后的精炼阶段则提高精确度。这种方法使我们能够在采取行动之前仔细考虑并选择最佳解决方案，避免过多的试错。为了进一步减少测试时的计算开销，我们引入了基于偏好的优化与强化自我训练（ReST）方法，该方法利用ThinkCoder的探索轨迹来引导LLM的进化。通过学习偏好，这种方法提高了LLM的探索效率，降低了计算成本同时保持准确性。ThinkCoder提高了多个基础LLM的性能，在HumanEval和MBPP等基准测试中表现出色。与SOTA模型相比，ThinkCoder使用仅21.7%的计算成本就能将MapCoder的Pass@1提高1.5%。与AgentCoder相比，ThinkCoder在2轮后将Pass@1提高了0.6%，优于AgentCoder的5轮。此外，使用成功轨迹的ReST使得模型如LLaMA2-7B仅使用20%的计算资源就能达到竞争力的结果。这些结果突显了该框架的有效性和可扩展性。', 'title_zh': '深思而后行！通过全面探索与最优细化实现高效代码生成'}
{'arxiv_id': 'arXiv:2502.17439', 'title': 'Large Language Models as Realistic Microservice Trace Generators', 'authors': 'Donghyun Kim, Sriram Ravula, Taemin Ha, Alexandros G. Dimakis, Daehyeok Kim, Aditya Akella', 'link': 'https://arxiv.org/abs/2502.17439', 'abstract': 'Computer system workload traces, which record hardware or software events during application execution, are essential for understanding the behavior of complex systems and managing their processing and memory resources. However, obtaining real-world traces can be challenging due to the significant collection overheads in performance and privacy concerns that arise in proprietary systems. As a result, synthetic trace generation is considered a promising alternative to using traces collected in real-world production deployments. This paper proposes to train a large language model (LLM) to generate synthetic workload traces, specifically microservice call graphs. To capture complex and arbitrary hierarchical structures and implicit constraints in such traces, we fine-tune LLMs to generate each layer recursively, making call graph generation a sequence of easier steps. To further enforce learning constraints in traces and generate uncommon situations, we apply additional instruction tuning steps to align our model with the desired trace features. Our evaluation results show that our model can generate diverse realistic traces under various conditions and outperform existing methods in accuracy and validity. We show that our synthetically generated traces can effectively substitute real-world data in optimizing or tuning systems management tasks. We also show that our model can be adapted to perform key downstream trace-related tasks, specifically, predicting key trace features and infilling missing data given partial traces. Codes are available in this https URL.', 'abstract_zh': '计算机系统工作负载轨迹是记录应用执行期间硬件或软件事件的数据，对于理解复杂系统的行为和管理其处理和内存资源至关重要。然而，由于在性能和隐私方面存在显著的收集开销，获取真实世界的轨迹可能具有挑战性。因此，合成轨迹生成被视为使用真实世界生产部署中收集的轨迹的有前景的替代方案。本文提出使用大型语言模型（LLM）生成合成工作负载轨迹，特别是生成微服务调用图。为捕捉此类轨迹中复杂且任意的层次结构和隐含约束，我们递归调优LLM以生成每一层，从而使调用图生成成为一系列较简单步骤。为了进一步强化轨迹中的学习约束并生成不常见的情况，我们应用额外的指令调优步骤，使模型与所需的轨迹特征对齐。我们的评估结果表明，我们的模型可以在各种条件下生成多样化的现实轨迹，并在准确性和有效性方面优于现有方法。我们展示了我们生成的合成轨迹可以有效替代真实世界的数据，以优化或调整系统管理任务。我们还展示了我们的模型可以适应执行关键下游轨迹相关任务，具体而言，预测关键轨迹特征并在部分轨迹下填充缺失数据。代码可在以下链接获得：[这个链接]。', 'title_zh': '大规模语言模型作为现实微服务跟踪生成器'}
