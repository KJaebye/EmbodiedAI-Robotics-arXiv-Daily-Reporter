{'arxiv_id': 'arXiv:2507.08726', 'title': 'Learning human-to-robot handovers through 3D scene reconstruction', 'authors': 'Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh', 'link': 'https://arxiv.org/abs/2507.08726', 'abstract': 'Learning robot manipulation policies from raw, real-world image data requires a large number of robot-action trials in the physical environment. Although training using simulations offers a cost-effective alternative, the visual domain gap between simulation and robot workspace remains a major limitation. Gaussian Splatting visual reconstruction methods have recently provided new directions for robot manipulation by generating realistic environments. In this paper, we propose the first method for learning supervised-based robot handovers solely from RGB images without the need of real-robot training or real-robot data collection. The proposed policy learner, Human-to-Robot Handover using Sparse-View Gaussian Splatting (H2RH-SGS), leverages sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes to generate robot demonstrations containing image-action pairs captured with a camera mounted on the robot gripper. As a result, the simulated camera pose changes in the reconstructed scene can be directly translated into gripper pose changes. We train a robot policy on demonstrations collected with 16 household objects and {\\em directly} deploy this policy in the real environment. Experiments in both Gaussian Splatting reconstructed scene and real-world human-to-robot handover experiments demonstrate that H2RH-SGS serves as a new and effective representation for the human-to-robot handover task.', 'abstract_zh': '从RGB图像学习基于监督的机器人手递策略：基于稀疏视图高斯散点图重建的方法', 'title_zh': '基于3D场景重建的人机交接学习'}
{'arxiv_id': 'arXiv:2507.08656', 'title': 'Multi-critic Learning for Whole-body End-effector Twist Tracking', 'authors': 'Aravind Elanjimattathil Vijayan, Andrei Cramariuc, Mattia Risiglione, Christian Gehring, Marco Hutter', 'link': 'https://arxiv.org/abs/2507.08656', 'abstract': 'Learning whole-body control for locomotion and arm motions in a single policy has challenges, as the two tasks have conflicting goals. For instance, efficient locomotion typically favors a horizontal base orientation, while end-effector tracking may benefit from base tilting to extend reachability. Additionally, current Reinforcement Learning (RL) approaches using a pose-based task specification lack the ability to directly control the end-effector velocity, making smoothly executing trajectories very challenging. To address these limitations, we propose an RL-based framework that allows for dynamic, velocity-aware whole-body end-effector control. Our method introduces a multi-critic actor architecture that decouples the reward signals for locomotion and manipulation, simplifying reward tuning and allowing the policy to resolve task conflicts more effectively. Furthermore, we design a twist-based end-effector task formulation that can track both discrete poses and motion trajectories. We validate our approach through a set of simulation and hardware experiments using a quadruped robot equipped with a robotic arm. The resulting controller can simultaneously walk and move its end-effector and shows emergent whole-body behaviors, where the base assists the arm in extending the workspace, despite a lack of explicit formulations.', 'abstract_zh': '基于强化学习的动态端效应器全身体态控制框架：解决移动和臂动任务间的冲突', 'title_zh': '全身末端执行器螺旋追踪的多评价者学习方法'}
{'arxiv_id': 'arXiv:2507.08366', 'title': 'Intelligent Control of Spacecraft Reaction Wheel Attitude Using Deep Reinforcement Learning', 'authors': 'Ghaith El-Dalahmeh, Mohammad Reza Jabbarpour, Bao Quoc Vo, Ryszard Kowalczyk', 'link': 'https://arxiv.org/abs/2507.08366', 'abstract': 'Reliable satellite attitude control is essential for the success of space missions, particularly as satellites increasingly operate autonomously in dynamic and uncertain environments. Reaction wheels (RWs) play a pivotal role in attitude control, and maintaining control resilience during RW faults is critical to preserving mission objectives and system stability. However, traditional Proportional Derivative (PD) controllers and existing deep reinforcement learning (DRL) algorithms such as TD3, PPO, and A2C often fall short in providing the real time adaptability and fault tolerance required for autonomous satellite operations. This study introduces a DRL-based control strategy designed to improve satellite resilience and adaptability under fault conditions. Specifically, the proposed method integrates Twin Delayed Deep Deterministic Policy Gradient (TD3) with Hindsight Experience Replay (HER) and Dimension Wise Clipping (DWC) referred to as TD3-HD to enhance learning in sparse reward environments and maintain satellite stability during RW failures. The proposed approach is benchmarked against PD control and leading DRL algorithms. Experimental results show that TD3-HD achieves significantly lower attitude error, improved angular velocity regulation, and enhanced stability under fault conditions. These findings underscore the proposed method potential as a powerful, fault tolerant, onboard AI solution for autonomous satellite attitude control.', 'abstract_zh': '可靠的卫星姿态控制对于空间任务的成功至关重要，尤其是在卫星越来越多地在动态和不确定环境中自主运行的情况下。反应轮（RW）在姿态控制中扮演着关键角色，维持RW故障期间的姿态控制鲁棒性对于实现任务目标和系统稳定性至关重要。然而，传统的比例微分（PD）控制器以及现有的深度增强学习（DRL）算法如TD3、PPO和A2C往往无法提供自主卫星运营所必需的实时适应性和故障容忍性。本研究提出了一种基于DRL的控制策略，旨在在故障条件下提高卫星的鲁棒性和适应性。具体而言，提出的方法将双延迟深度确定性策略梯度（TD3）与事后经验重播（HER）和维度裁剪（DWC）相结合，称为TD3-HD，以增强在稀疏奖励环境中学习并保持RW故障期间的卫星稳定性。提出的策略与PD控制以及领先DRL算法进行了对比。实验结果表明，TD3-HD在故障条件下实现了显著更低的姿态误差、改进的角速度调节和增强的稳定性。这些发现突显了所提出的方法作为自主卫星姿态控制的强健、故障容错型机载AI解决方案的巨大潜力。', 'title_zh': '基于深度强化学习的航天器反应轮姿态智能控制'}
{'arxiv_id': 'arXiv:2507.08303', 'title': 'Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots', 'authors': 'Yang Zhang, Zhanxiang Cao, Buqing Nie, Haoyang Li, Yue Gao', 'link': 'https://arxiv.org/abs/2507.08303', 'abstract': "Humanoid robots show significant potential in daily tasks. However, reinforcement learning-based motion policies often suffer from robustness degradation due to the sim-to-real dynamics gap, thereby affecting the agility of real robots. In this work, we propose a novel robust adversarial training paradigm designed to enhance the robustness of humanoid motion policies in real worlds. The paradigm introduces a learnable adversarial attack network that precisely identifies vulnerabilities in motion policies and applies targeted perturbations, forcing the motion policy to enhance its robustness against perturbations through dynamic adversarial training. We conduct experiments on the Unitree G1 humanoid robot for both perceptive locomotion and whole-body control tasks. The results demonstrate that our proposed method significantly enhances the robot's motion robustness in real world environments, enabling successful traversal of challenging terrains and highly agile whole-body trajectory tracking.", 'abstract_zh': '类人机器人在日常任务中展现出显著潜力。然而，基于强化学习的运动策略往往会因模拟到现实的动力学差距而导致鲁棒性下降，从而影响实际机器人动作的敏捷性。本文提出了一种新颖的鲁棒对抗训练范式，旨在增强类人运动策略在真实世界中的鲁棒性。该范式引入了一个可学习的对抗攻击网络，能够精确识别运动策略中的漏洞并施加针对性的扰动，迫使运动策略通过动态对抗训练提升其对干扰的鲁棒性。我们在Unitree G1类人机器人上分别进行了感知移动和全身控制任务实验。结果表明，所提出的方法显著增强了机器人的运动鲁棒性，使其能够在复杂地形中成功穿越并实现高度敏捷的全身轨迹跟踪。', 'title_zh': '基于关键对抗攻击学习 robust 运动技能的人形机器人'}
{'arxiv_id': 'arXiv:2507.08224', 'title': 'Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning', 'authors': 'Chan Young Park, Jillian Fisher, Marius Memmel, Dipika Khullar, Andy Yun, Abhishek Gupta, Yejin Choi', 'link': 'https://arxiv.org/abs/2507.08224', 'abstract': 'Large language models (LLMs) have shown promise in robotic procedural planning, yet their human-centric reasoning often omits the low-level, grounded details needed for robotic execution. Vision-language models (VLMs) offer a path toward more perceptually grounded plans, but current methods either rely on expensive, large-scale models or are constrained to narrow simulation settings. We introduce SelfReVision, a lightweight and scalable self-improvement framework for vision-language procedural planning. SelfReVision enables small VLMs to iteratively critique, revise, and verify their own plans-without external supervision or teacher models-drawing inspiration from chain-of-thought prompting and self-instruct paradigms. Through this self-distillation loop, models generate higher-quality, execution-ready plans that can be used both at inference and for continued fine-tuning. Using models varying from 3B to 72B, our results show that SelfReVision not only boosts performance over weak base VLMs but also outperforms models 100X the size, yielding improved control in downstream embodied tasks.', 'abstract_zh': 'SelfReVision：一种轻量级可扩展的自我改进框架，用于视觉语言程序规划', 'title_zh': '让大模型更友好数字人：自批判性低级程序推理提取'}
{'arxiv_id': 'arXiv:2507.08112', 'title': 'Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion', 'authors': 'Lamiaa H. Zain, Hossam H. Ammar, Raafat E. Shalaby', 'link': 'https://arxiv.org/abs/2507.08112', 'abstract': "Obstacle avoidance is crucial for mobile robots' navigation in both known and unknown environments. This research designs, trains, and tests two custom Convolutional Neural Networks (CNNs), using color and depth images from a depth camera as inputs. Both networks adopt sensor fusion to produce an output: the mobile robot's angular velocity, which serves as the robot's steering command. A newly obtained visual dataset for navigation was collected in diverse environments with varying lighting conditions and dynamic obstacles. During data collection, a communication link was established over Wi-Fi between a remote server and the robot, using Robot Operating System (ROS) topics. Velocity commands were transmitted from the server to the robot, enabling synchronized recording of visual data and the corresponding steering commands. Various evaluation metrics, such as Mean Squared Error, Variance Score, and Feed-Forward time, provided a clear comparison between the two networks and clarified which one to use for the application.", 'abstract_zh': '移动机器人在已知和未知环境中的避障导航至关重要。本研究设计、训练并测试了两个自定义卷积神经网络（CNN），使用深度摄像头的彩色和深度图像作为输入。两个网络均采用传感器融合生成输出：移动机器人的角速度，作为机器人的转向指令。在一个包含多种照明条件和动态障碍物的环境中，收集了新的导航视觉数据集。在数据收集过程中，通过Wi-Fi在远程服务器和机器人之间建立了通信连接，并使用ROS话题传输速度指令，实现在服务器和机器人之间同步记录视觉数据及其对应的转向指令。通过多种评估指标，如均方误差、方差分数和前向传递时间，对两个网络进行了清晰比较，明确了适用于该应用的网络。', 'title_zh': '基于端到端CNN融合的模仿学习用于障碍 avoidance'}
{'arxiv_id': 'arXiv:2507.08707', 'title': 'SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations', 'authors': 'Peter Crowley, Zachary Serlin, Tyler Paine, Makai Mann, Michael Benjamin, Calin Belta', 'link': 'https://arxiv.org/abs/2507.08707', 'abstract': 'Inverse Reinforcement Learning (IRL) presents a powerful paradigm for learning complex robotic tasks from human demonstrations. However, most approaches make the assumption that expert demonstrations are available, which is often not the case. Those that allow for suboptimality in the demonstrations are not designed for long-horizon goals or adversarial tasks. Many desirable robot capabilities fall into one or both of these categories, thus highlighting a critical shortcoming in the ability of IRL to produce field-ready robotic agents. We introduce Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations (SPLASH), which advances the state-of-the-art in learning from suboptimal demonstrations to long-horizon and adversarial settings. We empirically validate SPLASH on a maritime capture-the-flag task in simulation, and demonstrate real-world applicability with sim-to-real translation experiments on autonomous unmanned surface vehicles. We show that our proposed methods allow SPLASH to significantly outperform the state-of-the-art in reward learning from suboptimal demonstrations.', 'abstract_zh': '基于偏好且样本高效的逆强化学习：从次优化层次示学习长时域对抗任务（SPLASH）', 'title_zh': 'SPLASH! 基于偏好样本高效逆强化学习方法，用于从次优分层示范学习长期对抗任务'}
{'arxiv_id': 'arXiv:2507.08392', 'title': 'Multi-Agent LLMs as Ethics Advocates in AI-Based Systems', 'authors': 'Asma Yamani, Malak Baslyman, Moataz Ahmed', 'link': 'https://arxiv.org/abs/2507.08392', 'abstract': 'Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.', 'abstract_zh': '将伦理纳入需求获取过程对于创建伦理对齐的系统是必要的。 although eliciting manual ethics requirements是有效的，但它需要来自多个利益相关者的多样化输入，这由于时间和资源限制而具有挑战性。此外，它在需求获取过程中往往被给予较低的优先级。本研究提出了一种框架，在多智能体LLM环境中引入伦理倡导代理，以生成伦理要求草案。该代理基于系统描述对伦理问题进行批判并提供输入。所提出框架通过来自不同情境的两个案例研究进行评估，证明它捕获了研究人员在30分钟访谈中识别出的大多数伦理要求，并引入了若干其他相关要求。然而，这也突出了生成伦理要求的可靠性问题，强调了在此敏感领域需要人类反馈的重要性。我们认为，这项工作有助于促进伦理在需求工程过程中的更广泛采用，最终导致更伦理对齐的产品。', 'title_zh': '多智能体大型语言模型作为AI基于系统中的伦理倡导者'}
{'arxiv_id': 'arXiv:2507.08210', 'title': 'From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration', 'authors': 'Fryderyk Mantiuk, Hanqi Zhou, Charley M. Wu', 'link': 'https://arxiv.org/abs/2507.08210', 'abstract': 'What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.', 'abstract_zh': '什么是驱使智能代理探索世界同时又维持环境控制的动力？从玩耍的儿童到实验室中的科学家，智能代理必须在好奇心（寻求知识的驱动力）与胜任力（掌握和控制环境的驱动力）之间寻求平衡。将认知理论中的内在动机与强化学习相结合，我们探讨了在好奇心（新颖性或信息获取）与胜任力（能力感）之间通过不断演化内部表征如何进行权衡。我们比较了两个基于模型的代理：一个使用手工设计的状态抽象（表格），另一个学习内部世界模型（Dreamer）。表格代理展示了好奇心和胜任力在探索中以不同模式引导探索，而优先考虑两者则能提高探索效率。Dreamer代理揭示了探索与表示学习之间的双向交互作用，类似于好奇心与胜任力在发展过程中的共同进化。我们的研究将适应性探索正式化为追求未知与可控之间的平衡，为认知理论和高效强化学习提供了启示。', 'title_zh': '从好奇心到能力：世界模型如何与探索动力学互动'}
{'arxiv_id': 'arXiv:2507.08793', 'title': 'Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning', 'authors': 'James McCarthy, Radu Marinescu, Elizabeth Daly, Ivana Dusparic', 'link': 'https://arxiv.org/abs/2507.08793', 'abstract': "Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies that minimise the likelihood of rare and catastrophic constraint violations caused by an environment's inherent randomness. In general, risk-aversion leads to conservative exploration of the environment which typically results in converging to sub-optimal policies that fail to adequately maximise reward or, in some cases, fail to achieve the goal. In this paper, we propose an exploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic (ORAC), which constructs an exploratory policy by maximising a local upper confidence bound of the state-action reward value function whilst minimising a local lower confidence bound of the risk-averse state-action cost value function. Specifically, at each step, the weighting assigned to the cost value is increased or decreased if it exceeds or falls below the safety constraint value. This way the policy is encouraged to explore uncertain regions of the environment to discover high reward states whilst still satisfying the safety constraints. Our experimental results demonstrate that the ORAC approach prevents convergence to sub-optimal policies and improves significantly the reward-cost trade-off in various continuous control tasks such as Safety-Gymnasium and a complex building energy management environment CityLearn.", 'abstract_zh': "Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies that minimize the likelihood of rare and catastrophic constraint violations caused by an environment's inherent randomness. In this paper, we propose an exploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic (ORAC), which constructs an exploratory policy by maximizing a local upper confidence bound of the state-action reward value function while minimizing a local lower confidence bound of the risk-averse state-action cost value function. Specifically, at each step, the weighting assigned to the cost value is increased or decreased if it exceeds or falls below the safety constraint value. This way, the policy is encouraged to explore uncertain regions of the environment to discover high-reward states while still satisfying the safety constraints. Our experimental results demonstrate that the ORAC approach prevents convergence to sub-optimal policies and significantly improves the reward-cost trade-off in various continuous control tasks such as Safety-Gymnasium and a complex building energy management environment CityLearn.", 'title_zh': '风险规避约束强化学习中的乐观探索'}
{'arxiv_id': 'arXiv:2507.08624', 'title': 'Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance', 'authors': 'Gábor Baranyi, Zsolt Csibi, Kristian Fenech, Áron Fóthi, Zsófia Gaál, Joul Skaf, András Lőrincz', 'link': 'https://arxiv.org/abs/2507.08624', 'abstract': 'This paper introduces the Ambient Intelligence Rehabilitation Support (AIRS) framework, an advanced artificial intelligence-based solution tailored for home rehabilitation environments. AIRS integrates cutting-edge technologies, including Real-Time 3D Reconstruction (RT-3DR), intelligent navigation, and large Vision-Language Models (VLMs), to create a comprehensive system for machine-guided physical rehabilitation. The general AIRS framework is demonstrated in rehabilitation scenarios following total knee replacement (TKR), utilizing a database of 263 video recordings for evaluation. A smartphone is employed within AIRS to perform RT-3DR of living spaces and has a body-matched avatar to provide visual feedback about the excercise. This avatar is necessary in (a) optimizing exercise configurations, including camera placement, patient positioning, and initial poses, and (b) addressing privacy concerns and promoting compliance with the AI Act. The system guides users through the recording process to ensure the collection of properly recorded videos. AIRS employs two feedback mechanisms: (i) visual 3D feedback, enabling direct comparisons between prerecorded clinical exercises and patient home recordings and (ii) VLM-generated feedback, providing detailed explanations and corrections for exercise errors. The framework also supports people with visual and hearing impairments. It also features a modular design that can be adapted to broader rehabilitation contexts. AIRS software components are available for further use and customization.', 'abstract_zh': '基于环境智能的康复支持框架（AIRS）：一种适用于家庭康复环境的先进人工智能解决方案', 'title_zh': '适应性框架：用于康复辅助的环境智能'}
{'arxiv_id': 'arXiv:2507.08284', 'title': 'Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training', 'authors': 'Aleksei Ilin, Gor Matevosyan, Xueying Ma, Vladimir Eremin, Suhaa Dada, Muqun Li, Riyaaz Shaik, Haluk Noyan Tokgozoglu', 'link': 'https://arxiv.org/abs/2507.08284', 'abstract': 'We introduce a lightweight yet highly effective safety guardrail framework for language models, demonstrating that small-scale language models can achieve, and even surpass, the performance of larger counterparts in content moderation tasks. This is accomplished through high-fidelity synthetic data generation and adversarial training. The synthetic data generation process begins with human-curated seed data, which undergoes query augmentation and paraphrasing to create diverse and contextually rich examples. This augmented data is then subjected to multiple rounds of curation, ensuring high fidelity and relevance. Inspired by recent advances in the Generative Adversarial Network (GAN) architecture, our adversarial training employs reinforcement learning to guide a generator that produces challenging synthetic examples. These examples are used to fine-tune the safety classifier, enhancing its ability to detect and mitigate harmful content. Additionally, we incorporate strategies from recent research on efficient LLM training, leveraging the capabilities of smaller models to improve the performance of larger generative models. With iterative adversarial training and the generation of diverse, high-quality synthetic data, our framework enables small language models (SLMs) to serve as robust safety guardrails. This approach not only reduces computational overhead but also enhances resilience against adversarial attacks, offering a scalable and efficient solution for content moderation in AI systems.', 'abstract_zh': '一种轻量且高效的语言模型安全防护框架：小型语言模型在内容审核任务中的性能超越', 'title_zh': '基于合成数据和RL指导的对抗训练的轻量级安全防护栏'}
{'arxiv_id': 'arXiv:2507.08262', 'title': 'CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations', 'authors': 'Wenbo Cui, Chengyang Zhao, Yuhui Chen, Haoran Li, Zhizheng Zhang, Dongbin Zhao, He Wang', 'link': 'https://arxiv.org/abs/2507.08262', 'abstract': "Building a robust perception module is crucial for visuomotor policy learning. While recent methods incorporate pre-trained 2D foundation models into robotic perception modules to leverage their strong semantic understanding, they struggle to capture 3D spatial information and generalize across diverse camera viewpoints. These limitations hinder the policy's effectiveness, especially in fine-grained robotic manipulation scenarios. To address these challenges, we propose CL3R, a novel 3D pre-training framework designed to enhance robotic manipulation policies. Our method integrates both spatial awareness and semantic understanding by employing a point cloud Masked Autoencoder to learn rich 3D representations while leveraging pre-trained 2D foundation models through contrastive learning for efficient semantic knowledge transfer. Additionally, we propose a 3D visual representation pre-training framework for robotic tasks. By unifying coordinate systems across datasets and introducing random fusion of multi-view point clouds, we mitigate camera view ambiguity and improve generalization, enabling robust perception from novel viewpoints at test time. Extensive experiments in both simulation and the real world demonstrate the superiority of our method, highlighting its effectiveness in visuomotor policy learning for robotic manipulation.", 'abstract_zh': '构建 robust 的感知模块对于视觉-运动策略学习至关重要。尽管近期方法将预训练的 2D 基础模型整合到机器人感知模块中以利用其强大的语义理解能力，但它们难以捕捉 3D 空间信息并泛化到多样的相机视角。这些限制阻碍了策略的有效性，特别是在精细的机器人操作场景中。为应对这些挑战，我们提出 CL3R，一种新颖的 3D 预训练框架，旨在增强机器人的操作策略。我们的方法通过采用点云 Masked Autoencoder 学习丰富的 3D 表示，并通过对比学习利用预训练的 2D 基础模型实现高效的语义知识迁移，从而结合空间意识和语义理解。此外，我们还提出了一种用于机器人家务任务的 3D 视觉表示预训练框架。通过统一数据集的坐标系统并引入多视点点云的随机融合，我们减轻了相机视角的模糊性并提升了泛化能力，在测试时能够从新颖的视角实现稳健的感知。广泛的模拟和实际实验展示了我们方法的优势，突显了其在机器人操作中的视觉-运动策略学习中的有效性。', 'title_zh': 'CL3R: 三维重建与对比学习以增强机器人操作表示'}
{'arxiv_id': 'arXiv:2507.08197', 'title': 'Consciousness as a Jamming Phase', 'authors': 'Kaichen Ouyang', 'link': 'https://arxiv.org/abs/2507.08197', 'abstract': "This paper develops a neural jamming phase diagram that interprets the emergence of consciousness in large language models as a critical phenomenon in high-dimensional disordered this http URL establishing analogies with jamming transitions in granular matter and other complex systems, we identify three fundamental control parameters governing the phase behavior of neural networks: temperature, volume fraction, and this http URL theory provides a unified physical explanation for empirical scaling laws in artificial intelligence, demonstrating how computational cooling, density optimization, and noise reduction collectively drive systems toward a critical jamming surface where generalized intelligence emerges. Remarkably, the same thermodynamic principles that describe conventional jamming transitions appear to underlie the emergence of consciousness in neural networks, evidenced by shared critical signatures including divergent correlation lengths and scaling this http URL work explains neural language models' critical scaling through jamming physics, suggesting consciousness is a jamming phase that intrinsically connects knowledge components via long-range correlations.", 'abstract_zh': '这篇论文开发了一种神经阻尼相图，将大型语言模型中意识的出现解释为高维无序系统中的临界现象。通过建立与颗粒物质和其他复杂系统中阻塞转变的类比，我们确定了三个基本的控制参数，这些参数决定了神经网络的相行为：温度、体积分数和交联率。该理论为人工智能中的经验标度定律提供了一个统一的物理解释，展示了计算冷却、密度优化和噪声减少如何集体驱使系统向临界阻塞表面靠近，在该表面上普遍智能得以产生。值得注意的是，描述常规阻塞转变的同一热力学原理似乎也支配着神经网络中意识的出现，这由共享的临界特征，如发散的关联长度和标度关系所证实。本文通过阻塞物理学解释了神经语言模型的临界标度，暗示意识是一种内在地通过长程关联连接知识组件的阻塞相。', 'title_zh': '意识作为一种阻塞相态'}
