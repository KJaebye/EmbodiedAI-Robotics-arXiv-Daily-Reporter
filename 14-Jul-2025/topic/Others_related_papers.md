# Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework 

**Title (ZH)**: 面向鲁棒传感器融合地面SLAM：一项全面基准与鲁棒框架研究 

**Authors**: Deteng Zhang, Junjie Zhang, Yan Sun, Tao Li, Hao Yin, Hongzhao Xie, Jie Yin  

**Link**: [PDF](https://arxiv.org/pdf/2507.08364)  

**Abstract**: Considerable advancements have been achieved in SLAM methods tailored for structured environments, yet their robustness under challenging corner cases remains a critical limitation. Although multi-sensor fusion approaches integrating diverse sensors have shown promising performance improvements, the research community faces two key barriers: On one hand, the lack of standardized and configurable benchmarks that systematically evaluate SLAM algorithms under diverse degradation scenarios hinders comprehensive performance assessment. While on the other hand, existing SLAM frameworks primarily focus on fusing a limited set of sensor types, without effectively addressing adaptive sensor selection strategies for varying environmental conditions.
To bridge these gaps, we make three key contributions: First, we introduce M3DGR dataset: a sensor-rich benchmark with systematically induced degradation patterns including visual challenge, LiDAR degeneracy, wheel slippage and GNSS denial. Second, we conduct a comprehensive evaluation of forty SLAM systems on M3DGR, providing critical insights into their robustness and limitations under challenging real-world conditions. Third, we develop a resilient modular multi-sensor fusion framework named Ground-Fusion++, which demonstrates robust performance by coupling GNSS, RGB-D, LiDAR, IMU (Inertial Measurement Unit) and wheel odometry. Codes and datasets are publicly available. 

**Abstract (ZH)**: 针对结构化环境定制的SLAM方法取得了显著进展，但在挑战性corner cases中的鲁棒性仍存在重大局限。尽管将各种传感器融合的方法显示出了有前景的性能提升，但研究界面临两大关键障碍：一方面，缺乏标准化和可配置的基准来系统评估多种退化场景下SLAM算法的性能，阻碍了综合性能评估。另一方面，现有的SLAM框架主要集中在融合有限类型的传感器上，未能有效解决适应不同环境条件的传感器选择策略。为弥合这些差距，我们做出了三项关键贡献：首先，我们引入了M3DGR数据集：一个包含系统诱导退化模式的传感器丰富基准，包括视觉挑战、LiDAR退化、车轮打滑和GNSS拒识。其次，我们在M3DGR上对四十种SLAM系统进行了全面评估，提供了在挑战性现实环境条件下其鲁棒性和局限性的关键洞见。第三，我们开发了一种鲁棒的模块化多传感器融合框架，名为Ground-Fusion++，通过结合GNSS、RGB-D、LiDAR、IMU（惯性测量单元）和车轮里程计，展示了鲁棒性能。代码和数据集已公开。 

---
# System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility 

**Title (ZH)**: 系统-of-系统建模与优化：一种多式联运 Mobility 整合框架 

**Authors**: Paul Saves, Jasper Bussemaker, Rémi Lafage, Thierry Lefebvre, Nathalie Bartoli, Youssef Diouane, Joseph Morlier  

**Link**: [PDF](https://arxiv.org/pdf/2507.08715)  

**Abstract**: For developing innovative systems architectures, modeling and optimization techniques have been central to frame the architecting process and define the optimization and modeling problems. In this context, for system-of-systems the use of efficient dedicated approaches (often physics-based simulations) is highly recommended to reduce the computational complexity of the targeted applications. However, exploring novel architectures using such dedicated approaches might pose challenges for optimization algorithms, including increased evaluation costs and potential failures. To address these challenges, surrogate-based optimization algorithms, such as Bayesian optimization utilizing Gaussian process models have emerged. 

**Abstract (ZH)**: 开发创新型系统架构时，建模与优化技术是框架 architects 过程和定义优化与建模问题的核心。在这种背景下，对于系统-of-系统来说，使用高效的专用方法（通常是基于物理的模拟）来降低目标应用的计算复杂性是高度推荐的。然而，使用此类专用方法探索新型架构可能会给优化算法带来挑战，包括增加评估成本和潜在的失败。为此，基于代理模型的优化算法，如利用高斯过程模型的贝叶斯优化，已逐渐兴起。 

---
# A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis 

**Title (ZH)**: 多粒度概念稀疏激活与层次知识图融合框架在罕见病诊断中的应用 

**Authors**: Mingda Zhang, Na Zhao, Jianglong Qin, Guoyu Ye, Ruixiang Tang  

**Link**: [PDF](https://arxiv.org/pdf/2507.08529)  

**Abstract**: Despite advances from medical large language models in healthcare, rare-disease diagnosis remains hampered by insufficient knowledge-representation depth, limited concept understanding, and constrained clinical reasoning. We propose a framework that couples multi-granularity sparse activation of medical concepts with a hierarchical knowledge graph. Four complementary matching algorithms, diversity control, and a five-level fallback strategy enable precise concept activation, while a three-layer knowledge graph (taxonomy, clinical features, instances) provides structured, up-to-date context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09, ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89 approaching the 0.90 clinical threshold. Expert evaluation confirms improvements in information quality, reasoning, and professional expression, suggesting our approach shortens the "diagnostic odyssey" for rare-disease patients. 

**Abstract (ZH)**: 尽管医疗大型语言模型在医疗领域的进展，罕见疾病诊断仍受限于知识表示深度不足、概念理解有限和临床推理能力受限。我们提出了一种框架，结合多粒度稀疏激活的医疗概念与层次知识图谱。四种互补的匹配算法、多样性控制以及五级后备策略实现了精确的概念激活，而三层知识图谱（分类学、临床特征、实例）提供了结构化、及时的上下文。在BioASQ罕见疾病问答数据集上的实验结果显示，BLEU分数提高了0.09，ROUGE分数提高了0.05，准确率提高了0.12，峰值准确率达到0.89，接近临床阈值0.90。专家评审确认在信息质量、推理和专业表达方面的改进，表明我们的方法缩短了罕见疾病患者的“诊断之旅”。 

---
# Why this and not that? A Logic-based Framework for Contrastive Explanations 

**Title (ZH)**: 为什么是这个而不是那个？一种基于逻辑的对比解释框架 

**Authors**: Tobias Geibinger, Reijo Jaakkola, Antti Kuusisto, Xinghan Liu, Miikka Vilander  

**Link**: [PDF](https://arxiv.org/pdf/2507.08454)  

**Abstract**: We define several canonical problems related to contrastive explanations, each answering a question of the form ''Why P but not Q?''. The problems compute causes for both P and Q, explicitly comparing their differences. We investigate the basic properties of our definitions in the setting of propositional logic. We show, inter alia, that our framework captures a cardinality-minimal version of existing contrastive explanations in the literature. Furthermore, we provide an extensive analysis of the computational complexities of the problems. We also implement the problems for CNF-formulas using answer set programming and present several examples demonstrating how they work in practice. 

**Abstract (ZH)**: 我们定义了几类与对比解释相关的规范性问题，每个问题回答的形式均为“为什么P而不是Q？”这些问题计算P和Q的原因，并明确比较它们的差异。我们在命题逻辑的框架下研究我们定义的基本性质。我们证明了，例如，我们的框架捕捉到了文献中已存在的对比解释的基数最小版本。此外，我们还对这些问题的计算复杂性进行了详尽分析。我们还使用回答集编程实现CNF公式上的这些问题，并提供了几个示例，演示它们在实际中的工作方式。 

---
# Abductive Computational Systems: Creative Abduction and Future Directions 

**Title (ZH)**: 演绎计算系统：创造性演绎与未来方向 

**Authors**: Abhinav Sood, Kazjon Grace, Stephen Wan, Cecile Paris  

**Link**: [PDF](https://arxiv.org/pdf/2507.08264)  

**Abstract**: Abductive reasoning, reasoning for inferring explanations for observations, is often mentioned in scientific, design-related and artistic contexts, but its understanding varies across these domains. This paper reviews how abductive reasoning is discussed in epistemology, science and design, and then analyses how various computational systems use abductive reasoning. Our analysis shows that neither theoretical accounts nor computational implementations of abductive reasoning adequately address generating creative hypotheses. Theoretical frameworks do not provide a straightforward model for generating creative abductive hypotheses, computational systems largely implement syllogistic forms of abductive reasoning. We break down abductive computational systems into components and conclude by identifying specific directions for future research that could advance the state of creative abductive reasoning in computational systems. 

**Abstract (ZH)**: abduction推理，即为基于观察推求解释的推理，在科学、设计相关和艺术领域中常被提及，但在这些领域的理解有所不同。本文回顾了 abduction 推理在认识论、科学和设计中的讨论方式，然后分析了各种计算系统如何使用 abduction 推理。我们的分析表明，无论是理论 Accounts 还是计算实现的 abduction 推理，都不能充分解决生成创造性假设的问题。理论框架没有提供生成创造性 abduction 假设的直观模型，计算系统主要采用前提演绎形式的 abduction 推理。我们将 abduction 计算系统分解成组件，并提出具体的研究方向，以促进计算系统中创造性 abduction 推理的发展。 

---
# Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm 

**Title (ZH)**: 给AI代理提供接入加密货币和智能合约的权限创造了新的AI危害向量 

**Authors**: Bill Marino, Ari Juels  

**Link**: [PDF](https://arxiv.org/pdf/2507.08249)  

**Abstract**: There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could lead to these new vectors of harm. Next, we describe each of these new vectors of harm in detail. Finally, we conclude with a call for more technical research aimed at preventing and mitigating these harms and, thereby making it safer to endow AI agents with cryptocurrencies and smart contracts. 

**Abstract (ZH)**: 随着对给AI代理赋予加密货币及其智能合约接入权限的兴趣日益增长，这有可能导致强大的新AI危害向量。但本立场论文认为，这样做可能会带来新的AI危害。为支持这一论点，我们首先探讨了加密货币和智能合约的独特属性，这些属性可能导致这些新的危害向量。接着，我们详细描述了这些新的危害向量。最后，我们呼吁开展更多旨在预防和减轻这些危害的技术研究，从而使得赋予AI代理加密货币和智能合约变得更安全。 

---
# Grounding Methods for Neural-Symbolic AI 

**Title (ZH)**: 神经符号AI中的 grounding 方法 

**Authors**: Rodrigo Castellano Ontiveros, Francesco Giannini, Marco Gori, Giuseppe Marra, Michelangelo Diligenti  

**Link**: [PDF](https://arxiv.org/pdf/2507.08216)  

**Abstract**: A large class of Neural-Symbolic (NeSy) methods employs a machine learner to process the input entities, while relying on a reasoner based on First-Order Logic to represent and process more complex relationships among the entities. A fundamental role for these methods is played by the process of logic grounding, which determines the relevant substitutions for the logic rules using a (sub)set of entities. Some NeSy methods use an exhaustive derivation of all possible substitutions, preserving the full expressive power of the logic knowledge. This leads to a combinatorial explosion in the number of ground formulas to consider and, therefore, strongly limits their scalability. Other methods rely on heuristic-based selective derivations, which are generally more computationally efficient, but lack a justification and provide no guarantees of preserving the information provided to and returned by the reasoner. Taking inspiration from multi-hop symbolic reasoning, this paper proposes a parametrized family of grounding methods generalizing classic Backward Chaining. Different selections within this family allow us to obtain commonly employed grounding methods as special cases, and to control the trade-off between expressiveness and scalability of the reasoner. The experimental results show that the selection of the grounding criterion is often as important as the NeSy method itself. 

**Abstract (ZH)**: 一种大型神经符号（NeSy）方法使用机器学习处理输入实体，同时依赖基于一阶逻辑的推理器来表示和处理实体间更为复杂的关系。这些方法中的基础作用由逻辑基础化过程发挥，该过程利用实体集（子集）确定逻辑规则的相关替换。一些NeSy方法通过穷尽所有可能的替换衍生，保留了逻辑知识的全部表达能力。这导致需要考虑的地面公式数量呈组合爆炸增长，因此严重限制了其可扩展性。其他方法依赖基于启发式的选择性衍生，通常更具计算效率，但缺乏解释性且无法保证推理器所提供的和返回的信息。借鉴多跳符号推理的思路，本文提出了一类参数化的基础化方法，推广了经典的向后链接。该家族的不同选择使我们能够获得常用的几种基础化方法，并能够控制推理器的表达能力和可扩展性之间的权衡关系。实验结果表明，基础化标准的选择往往与NeSy方法本身同样重要。 

---
# Human Creativity and AI 

**Title (ZH)**: 人类创造力与人工智能 

**Authors**: Shengyi Xie  

**Link**: [PDF](https://arxiv.org/pdf/2507.08001)  

**Abstract**: With the advancement of science and technology, the philosophy of creativity has undergone significant reinterpretation. This paper investigates contemporary research in the fields of psychology, cognitive neuroscience, and the philosophy of creativity, particularly in the context of the development of artificial intelligence (AI) techniques. It aims to address the central question: Can AI exhibit creativity? The paper reviews the historical perspectives on the philosophy of creativity and explores the influence of psychological advancements on the study of creativity. Furthermore, it analyzes various definitions of creativity and examines the responses of naturalism and cognitive neuroscience to the concept of creativity. 

**Abstract (ZH)**: 科学和技术的进步促使对创造力哲学进行了重新解读。本文探讨了心理学、认知神经科学和创造力哲学领域的当代研究，特别是人工智能技术发展的背景。本文旨在探讨中心问题：人工智能能否表现出创造力？文章回顾了创造力哲学的历史观点，并探讨了心理学进步对创造力研究的影响。此外，文章分析了创造力的各种定义，并考察了自然主义和认知神经科学对创造力概念的回应。 

---
# NeuralOS: Towards Simulating Operating Systems via Neural Generative Models 

**Title (ZH)**: NeuralOS: 通过神经生成模型模拟操作系统 

**Authors**: Luke Rivard, Sun Sun, Hongyu Guo, Wenhu Chen, Yuntian Deng  

**Link**: [PDF](https://arxiv.org/pdf/2507.08800)  

**Abstract**: We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems. 

**Abstract (ZH)**: NeuralOS：一种通过直接预测屏幕帧来模拟操作系统图形用户界面的神经框架 

---
# On Barriers to Archival Audio Processing 

**Title (ZH)**: 关于归档音频处理的障碍 

**Authors**: Peter Sullivan, Muhammad Abdul-Mageed  

**Link**: [PDF](https://arxiv.org/pdf/2507.08768)  

**Abstract**: In this study, we leverage a unique UNESCO collection of mid-20th century radio recordings to probe the robustness of modern off-the-shelf language identification (LID) and speaker recognition (SR) methods, especially with respect to the impact of multilingual speakers and cross-age recordings. Our findings suggest that LID systems, such as Whisper, are increasingly adept at handling second-language and accented speech. However, speaker embeddings remain a fragile component of speech processing pipelines that is prone to biases related to the channel, age, and language. Issues which will need to be overcome should archives aim to employ SR methods for speaker indexing. 

**Abstract (ZH)**: 本研究利用UNESCO中期20世纪无线电录音的独特集合，探究现代现成语言识别（LID）和说话人识别（SR）方法的稳健性，尤其是多语言说话人和跨年龄录音的影响。研究发现，语言识别系统，如Whisper，越来越擅长处理二语和口音 speech。然而，说话人嵌入仍然是语音处理管道中的一个脆弱组件，容易受到通道、年龄和语言相关的偏见影响。这些问题需要在档案馆利用说话人识别方法进行说话人索引时予以克服。 

---
# A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification 

**Title (ZH)**: 带有特征提取和K均值聚类的混合多井霍普菲尔德-CNNfor MNIST分类 

**Authors**: Ahmed Farooq  

**Link**: [PDF](https://arxiv.org/pdf/2507.08766)  

**Abstract**: This study presents a hybrid model for classifying handwritten digits in the MNIST dataset, combining convolutional neural networks (CNNs) with a multi-well Hopfield network. The approach employs a CNN to extract high-dimensional features from input images, which are then clustered into class-specific prototypes using k-means clustering. These prototypes serve as attractors in a multi-well energy landscape, where a Hopfield network performs classification by minimizing an energy function that balances feature similarity and class this http URL model's design enables robust handling of intraclass variability, such as diverse handwriting styles, while providing an interpretable framework through its energy-based decision process. Through systematic optimization of the CNN architecture and the number of wells, the model achieves a high test accuracy of 99.2% on 10,000 MNIST images, demonstrating its effectiveness for image classification tasks. The findings highlight the critical role of deep feature extraction and sufficient prototype coverage in achieving high performance, with potential for broader applications in pattern recognition. 

**Abstract (ZH)**: 本研究提出了一种结合卷积神经网络（CNN）和多阱霍普菲尔德网络的混合模型，用于MNIST手写数字数据集的分类。该方法利用CNN从输入图像中提取高维特征，并使用k-means聚类将这些特征聚类成类特定的原型。这些原型在多阱能量景观中作为吸引子，霍普菲尔德网络通过最小化平衡特征相似性和类别的能量函数来进行分类。该模型的设计能够稳健地处理类内变异性，如多种手写风格，并通过基于能量的决策过程提供可解释的框架。通过系统优化CNN架构和阱的数量，该模型在10,000个MNIST图像上的测试准确率达到99.2%，展示了其在图像分类任务中的有效性。研究结果强调了深入特征提取和足够原型覆盖对实现高性能的关键作用，并具有在模式识别中更广泛的应用潜力。 

---
# Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data 

**Title (ZH)**: 基于离线数据的强化学习中不可行动作惩罚和奖励缩放 

**Authors**: Jeonghye Kim, Yongjae Shin, Whiyoung Jung, Sunghoon Hong, Deunsol Yoon, Youngchul Sung, Kanghoon Lee, Woohyung Lim  

**Link**: [PDF](https://arxiv.org/pdf/2507.08761)  

**Abstract**: Reinforcement learning with offline data suffers from Q-value extrapolation errors. To address this issue, we first demonstrate that linear extrapolation of the Q-function beyond the data range is particularly problematic. To mitigate this, we propose guiding the gradual decrease of Q-values outside the data range, which is achieved through reward scaling with layer normalization (RS-LN) and a penalization mechanism for infeasible actions (PA). By combining RS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a range of tasks, demonstrating superior performance compared to state-of-the-art algorithms in both offline training and online fine-tuning on the D4RL benchmark, with notable success in the challenging AntMaze Ultra task. 

**Abstract (ZH)**: Offline Data-Reinforcement Learning Suffers from Q-value Extrapolation Errors: A New Algorithm PARSMitigates This Issue Through Reward Scaling with Layer Normalization and Penalization Mechanism 

---
# Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection 

**Title (ZH)**: Geo-ORBIT: 一种场景自适应车道几何检测的联邦数字孪生框架 

**Authors**: Rei Tamaru, Pei Li, Bin Ran  

**Link**: [PDF](https://arxiv.org/pdf/2507.08743)  

**Abstract**: Digital Twins (DT) have the potential to transform traffic management and operations by creating dynamic, virtual representations of transportation systems that sense conditions, analyze operations, and support decision-making. A key component for DT of the transportation system is dynamic roadway geometry sensing. However, existing approaches often rely on static maps or costly sensors, limiting scalability and adaptability. Additionally, large-scale DTs that collect and analyze data from multiple sources face challenges in privacy, communication, and computational efficiency. To address these challenges, we introduce Geo-ORBIT (Geometrical Operational Roadway Blueprint with Integrated Twin), a unified framework that combines real-time lane detection, DT synchronization, and federated meta-learning. At the core of Geo-ORBIT is GeoLane, a lightweight lane detection model that learns lane geometries from vehicle trajectory data using roadside cameras. We extend this model through Meta-GeoLane, which learns to personalize detection parameters for local entities, and FedMeta-GeoLane, a federated learning strategy that ensures scalable and privacy-preserving adaptation across roadside deployments. Our system is integrated with CARLA and SUMO to create a high-fidelity DT that renders highway scenarios and captures traffic flows in real-time. Extensive experiments across diverse urban scenes show that FedMeta-GeoLane consistently outperforms baseline and meta-learning approaches, achieving lower geometric error and stronger generalization to unseen locations while drastically reducing communication overhead. This work lays the foundation for flexible, context-aware infrastructure modeling in DTs. The framework is publicly available at this https URL. 

**Abstract (ZH)**: 数字孪生（DT）有潜力通过创建交通系统的动态虚拟表示，感知状况、分析运行情况和支持决策来转型交通管理与运营。交通系统的数字孪生的关键组件是动态道路几何感知。然而，现有的方法往往依赖于静态地图或昂贵的传感器，限制了其可扩展性和适应性。此外，从多个来源收集和分析数据的大规模数字孪生面临着隐私、通信和计算效率方面的挑战。为了解决这些挑战，我们介绍了Geo-ORBIT（几何操作道路蓝图与集成孪生），这是一种结合了实时车道检测、数字孪生同步和联邦元学习的统一框架。Geo-ORBIT的核心是GeoLane，这是一种轻量级的车道检测模型，通过路边摄像头从车辆轨迹数据中学习车道几何。我们通过Meta-GeoLane扩展了该模型，使其能够为本地实体个性化检测参数，并通过FedMeta-GeoLane的联邦学习策略实现跨路边部署的可扩展和隐私保护的适应。我们的系统与CARLA和SUMO集成，创建了一个高保真的数字孪生，实时渲染高速公路场景并捕捉交通流。在多种城市场景的广泛实验中，FedMeta-GeoLane在几何误差和对未见过的位置的泛化能力方面表现出色，同时大幅减少了通信开销。这项工作为数字孪生中的灵活、上下文感知基础设施建模奠定了基础。该框架可在以下网址公开获取：this https URL。 

---
# Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series 

**Title (ZH)**: 自适应非线性向量自回归：噪声混沌时间序列的稳健forecasting 

**Authors**: Azimov Sherkhon, Susana Lopez-Moreno, Eric Dolores-Cuenca, Sieun Lee, Sangil Kim  

**Link**: [PDF](https://arxiv.org/pdf/2507.08738)  

**Abstract**: Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have shown promise in forecasting chaotic dynamical systems, such as the Lorenz-63 model and El Nino-Southern Oscillation. However, their reliance on fixed nonlinearities - polynomial expansions in NVAR or random feature maps in RC - limits their adaptability to high noise or real-world data. These methods also scale poorly in high-dimensional settings due to costly matrix inversion during readout computation. We propose an adaptive NVAR model that combines delay-embedded linear inputs with features generated by a shallow, learnable multi-layer perceptron (MLP). The MLP and linear readout are jointly trained using gradient-based optimization, enabling the model to learn data-driven nonlinearities while preserving a simple readout structure. Unlike standard NVAR, our approach avoids the need for an exhaustive and sensitive grid search over ridge and delay parameters. Instead, tuning is restricted to neural network hyperparameters, improving scalability. Initial experiments on chaotic systems tested under noise-free and synthetically noisy conditions showed that the adaptive model outperformed the standard NVAR in predictive accuracy and showed robust forecasting under noisy conditions with a lower observation frequency. 

**Abstract (ZH)**: 自适应非线性向量自回归模型结合浅层可学习多层感知机在混沌动态系统预测中的应用 

---
# Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling 

**Title (ZH)**: 通过 plateau 阶段活性 profiling 减轻灾难性遗忘 

**Authors**: Idan Mashiach, Oren Glickman, Tom Tirer  

**Link**: [PDF](https://arxiv.org/pdf/2507.08736)  

**Abstract**: Catastrophic forgetting in deep neural networks occurs when learning new tasks degrades performance on previously learned tasks due to knowledge overwriting. Among the approaches to mitigate this issue, regularization techniques aim to identify and constrain "important" parameters to preserve previous knowledge. In the highly nonconvex optimization landscape of deep learning, we propose a novel perspective: tracking parameters during the final training plateau is more effective than monitoring them throughout the entire training process. We argue that parameters that exhibit higher activity (movement and variability) during this plateau reveal directions in the loss landscape that are relatively flat, making them suitable for adaptation to new tasks while preserving knowledge from previous ones. Our comprehensive experiments demonstrate that this approach achieves superior performance in balancing catastrophic forgetting mitigation with strong performance on newly learned tasks. 

**Abstract (ZH)**: 深度神经网络中的灾难性遗忘现象发生在学习新任务时因知识覆盖而导致之前学习任务表现下降。为缓解这一问题的方法中，正则化技术旨在识别并约束“重要”的参数以保留先前的知识。在深度学习高度非凸的优化景观中，我们提出一种新颖的观点：在最终训练平台期追踪参数比在整个训练过程中监测参数更有效。我们认为，在此平台期活动性（运动和变化）较高的参数揭示了损失景观中相对平坦的方向，使其适合适应新任务的同时保留先前的知识。全面的实验表明，该方法在缓解灾难性遗忘和新任务强表现之间取得了更优的平衡性能。 

---
# Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning 

**Title (ZH)**: 双重分层漂移适应在线配置性能学习 

**Authors**: Zezhen Xiang, Jingzhi Gong, Tao Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.08730)  

**Abstract**: Modern configurable software systems need to learn models that correlate configuration and performance. However, when the system operates in dynamic environments, the workload variations, hardware changes, and system updates will inevitably introduce concept drifts at different levels - global drifts, which reshape the performance landscape of the entire configuration space; and local drifts, which only affect certain sub-regions of that space. As such, existing offline and transfer learning approaches can struggle to adapt to these implicit and unpredictable changes in real-time, rendering configuration performance learning challenging. To address this, we propose DHDA, an online configuration performance learning framework designed to capture and adapt to these drifts at different levels. The key idea is that DHDA adapts to both the local and global drifts using dually hierarchical adaptation: at the upper level, we redivide the data into different divisions, within each of which the local model is retrained, to handle global drifts only when necessary. At the lower level, the local models of the divisions can detect local drifts and adapt themselves asynchronously. To balance responsiveness and efficiency, DHDA combines incremental updates with periodic full retraining to minimize redundant computation when no drifts are detected. Through evaluating eight software systems and against state-of-the-art approaches, we show that DHDA achieves considerably better accuracy and can effectively adapt to drifts with up to 2x improvements, while incurring reasonable overhead and is able to improve different local models in handling concept drift. 

**Abstract (ZH)**: 现代可配置软件系统需要学习关联配置和性能的模型。然而，当系统在动态环境中运行时，工作负载变化、硬件更新和系统更新将不可避免地在不同层次上引入概念漂移——全局漂移，重塑整个配置空间的性能景观；局部漂移，仅影响该空间的某些子区域。因此，现有的离线和迁移学习方法在实时适应这些隐含且难以预测的变化方面可能会遇到困难，使得配置性能学习变得挑战重重。为了解决这一问题，我们提出了DHDA，这是一种在线配置性能学习框架，旨在捕捉并适应不同层次的概念漂移。关键思想是DHDA使用双重分层适应来适应局部和全局漂移：在较高层次上，我们重新划分数据为不同的部分，在每个部分中重新训练局部模型，仅在必要时处理全局漂移。在较低层次，各部分的局部模型可以异步检测局部漂移并自行适应。为了平衡响应性和效率，DHDA结合增量更新与定期全面重训练，以最小化未检测到漂移时的冗余计算。通过评估八个软件系统并与其他先进方法进行对比，我们展示了DHDA实现了显著的准确性提升，并能在最多2倍的性能提升下有效适应漂移，同时引入合理的开销，并能够提高不同局部模型处理概念漂移的能力。 

---
# Monitoring Risks in Test-Time Adaptation 

**Title (ZH)**: 测试时适应中的风险监控 

**Authors**: Mona Schirmer, Metod Jazbec, Christian A. Naesseth, Eric Nalisnick  

**Link**: [PDF](https://arxiv.org/pdf/2507.08721)  

**Abstract**: Encountering shifted data at test time is a ubiquitous challenge when deploying predictive models. Test-time adaptation (TTA) methods address this issue by continuously adapting a deployed model using only unlabeled test data. While TTA can extend the model's lifespan, it is only a temporary solution. Eventually the model might degrade to the point that it must be taken offline and retrained. To detect such points of ultimate failure, we propose pairing TTA with risk monitoring frameworks that track predictive performance and raise alerts when predefined performance criteria are violated. Specifically, we extend existing monitoring tools based on sequential testing with confidence sequences to accommodate scenarios in which the model is updated at test time and no test labels are available to estimate the performance metrics of interest. Our extensions unlock the application of rigorous statistical risk monitoring to TTA, and we demonstrate the effectiveness of our proposed TTA monitoring framework across a representative set of datasets, distribution shift types, and TTA methods. 

**Abstract (ZH)**: 在测试时遭遇偏移数据是部署预测模型时的一个普遍挑战。测试时自适应（TTA）方法通过仅使用未标记的测试数据连续适应部署模型来解决这一问题。虽然TTA可以延长模型的寿命，但它仅是一个临时解决方案。最终，模型可能会退化到必须下线并重新训练的程度。为了检测这种最终失败点，我们提出将TTA与风险监控框架相结合，这些框架跟踪预测性能并在预定义的性能标准被违反时发出警报。SPECIFICALLY，我们扩展了基于顺序测试和置信序列的现有监控工具，以适应模型在测试时更新且无法获取测试标签以估计所需性能指标的场景。我们的扩展解锁了严格统计风险监控在TTA中的应用，并通过代表性数据集、分布偏移类型和TTA方法展示了我们提出的TTA监控框架的有效性。 

---
# ONION: A Multi-Layered Framework for Participatory ER Design 

**Title (ZH)**: 洋葱模型：一种参与式ER设计的多层框架 

**Authors**: Viktoriia Makovska, George Fletcher, Julia Stoyanovich  

**Link**: [PDF](https://arxiv.org/pdf/2507.08702)  

**Abstract**: We present ONION, a multi-layered framework for participatory Entity-Relationship (ER) modeling that integrates insights from design justice, participatory AI, and conceptual modeling. ONION introduces a five-stage methodology: Observe, Nurture, Integrate, Optimize, Normalize. It supports progressive abstraction from unstructured stakeholder input to structured ER diagrams.
Our approach aims to reduce designer bias, promote inclusive participation, and increase transparency through the modeling process. We evaluate ONION through real-world workshops focused on sociotechnical systems in Ukraine, highlighting how diverse stakeholder engagement leads to richer data models and deeper mutual understanding. Early results demonstrate ONION's potential to host diversity in early-stage data modeling. We conclude with lessons learned, limitations and challenges involved in scaling and refining the framework for broader adoption. 

**Abstract (ZH)**: We Presented ONION, 一种融合设计正义、参与式AI和概念建模洞察的多层实体-关系 modeling框架及其五阶段方法学 

---
# A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes 

**Title (ZH)**: 独立居家老年人日常活动个性化形式验证框架 

**Authors**: Ricardo Contreras, Filip Smola, Nuša Farič, Jiawei Zheng, Jane Hillston, Jacques D. Fleuriot  

**Link**: [PDF](https://arxiv.org/pdf/2507.08701)  

**Abstract**: There is an imperative need to provide quality of life to a growing population of older adults living independently. Personalised solutions that focus on the person and take into consideration their preferences and context are key. In this work, we introduce a framework for representing and reasoning about the Activities of Daily Living of older adults living independently at home. The framework integrates data from sensors and contextual information that aggregates semi-structured interviews, home layouts and sociological observations from the participants. We use these data to create formal models, personalised for each participant according to their preferences and context. We formulate requirements that are specific to each individual as properties encoded in Linear Temporal Logic and use a model checker to verify whether each property is satisfied by the model. When a property is violated, a counterexample is generated giving the cause of the violation. We demonstrate the framework's generalisability by applying it to different participants, highlighting its potential to enhance the safety and well-being of older adults ageing in place. 

**Abstract (ZH)**: 独立居住的老年人提高生活质量的迫切需求需要个性化解决方案。本研究引入了一个框架，用于表示和推理独立居住老年人的日常生活活动。该框架整合了来自传感器的数据以及半结构化访谈、家庭布局和参与者的社会观察等上下文信息。我们使用这些数据为每位参与者创建形式模型，并根据其偏好和情境进行个性化。我们将针对每位个人的具体要求编码为线性时序逻辑属性，并使用模型检查器验证这些属性是否由模型满足。当属性被违反时，会产生反例以指出违规的原因。我们通过将其应用于不同的参与者，展示了该框架的普遍性，并突出了其在原地老化老年人的安全和福祉方面的潜力。 

---
# Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees 

**Title (ZH)**: 资源分配中的安全深度强化学习及其峰值年龄信息违例保证 

**Authors**: Berire Gunes Reyhan, Sinem Coleri  

**Link**: [PDF](https://arxiv.org/pdf/2507.08653)  

**Abstract**: In Wireless Networked Control Systems (WNCSs), control and communication systems must be co-designed due to their strong interdependence. This paper presents a novel optimization theory-based safe deep reinforcement learning (DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction while optimizing performance, for the first time in the literature. The approach minimizes power consumption under key constraints, including Peak Age of Information (PAoI) violation probability, transmit power, and schedulability in the finite blocklength regime. PAoI violation probability is uniquely derived by combining stochastic maximum allowable transfer interval (MATI) and maximum allowable packet delay (MAD) constraints in a multi-sensor network. The framework consists of two stages: optimization theory and safe DRL. The first stage derives optimality conditions to establish mathematical relationships among variables, simplifying and decomposing the problem. The second stage employs a safe DRL model where a teacher-student framework guides the DRL agent (student). The control mechanism (teacher) evaluates compliance with system constraints and suggests the nearest feasible action when needed. Extensive simulations show that the proposed framework outperforms rule-based and other optimization theory based DRL benchmarks, achieving faster convergence, higher rewards, and greater stability. 

**Abstract (ZH)**: 无线网络控制系统（WNCSs）中，控制与通信系统必须由于其紧密的相互依赖性而协同设计。本文提出了一种基于优化理论的全新安全深度强化学习（DRL）框架，确保在优化性能的同时满足约束条件，这是文献中的首次尝试。该方法在关键约束条件下（包括峰值年龄信息（PAoI）违规概率、传输功率和有限块长度范围内的可调度性）最小化能耗。PAoI违规概率是通过结合多传感器网络中的随机最大允许传输间隔（MATI）和最大允许包延迟（MAD）约束唯一推导出来的。该框架包括两个阶段：优化理论和安全DRL。第一个阶段推导出最优条件，建立变量之间的数学关系，使问题更简洁和分解。第二阶段采用一种安全DRL模型，其中导师-学生框架引导DRL代理（学生）。控制机制（导师）评估系统约束的遵守情况，并在必要时建议最近可行的操作。大量仿真实验表明，所提出的框架优于基于规则和其他优化理论的DRL基准，实现了更快的收敛速度、更高的奖励和更大的稳定性。 

---
# DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images 

**Title (ZH)**: DatasetAgent：一种新型多智能体系统，用于从真实世界图像自动生成数据集 

**Authors**: Haoran Sun, Haoyu Bian, Shaoning Zeng, Yunbo Rao, Xu Xu, Lin Mei, Jianping Gou  

**Link**: [PDF](https://arxiv.org/pdf/2507.08648)  

**Abstract**: Common knowledge indicates that the process of constructing image datasets usually depends on the time-intensive and inefficient method of manual collection and annotation. Large models offer a solution via data generation. Nonetheless, real-world data are obviously more valuable comparing to artificially intelligence generated data, particularly in constructing image datasets. For this reason, we propose a novel method for auto-constructing datasets from real-world images by a multiagent collaborative system, named as DatasetAgent. By coordinating four different agents equipped with Multi-modal Large Language Models (MLLMs), as well as a tool package for image optimization, DatasetAgent is able to construct high-quality image datasets according to user-specified requirements. In particular, two types of experiments are conducted, including expanding existing datasets and creating new ones from scratch, on a variety of open-source datasets. In both cases, multiple image datasets constructed by DatasetAgent are used to train various vision models for image classification, object detection, and image segmentation. 

**Abstract (ZH)**: 现有的常识表明，构建图像数据集的过程通常依赖于耗时且低效的手动收集和标注方法。大型模型通过数据生成提供了一种解决方案。然而，现实世界数据显然比人工智能生成的数据更具价值，特别是在构建图像数据集方面。因此，我们提出了一种由多智能体协作系统实现的自动数据集构建方法，名为DatasetAgent。通过协调四个不同智能体，配备多模态大型语言模型（MLLMs），以及一个图像优化工具包，DatasetAgent能够根据用户指定的要求构建高质量的图像数据集。特别地，在多种开源数据集上进行了两种类型实验，包括扩展现有数据集和从零开始创建新的数据集。在两种情况下，均由DatasetAgent构建的多个图像数据集被用于训练各种视觉模型，用于图像分类、目标检测和图像分割。 

---
# Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA) 

**Title (ZH)**: 使用小波增强随机谱注意力（WERSA）实现线性时间下的超长序列注意力扩展 

**Authors**: Vincenzo Dentamaro  

**Link**: [PDF](https://arxiv.org/pdf/2507.08637)  

**Abstract**: Transformer models are computationally costly on long sequences since regular attention has quadratic $O(n^2)$ time complexity. We introduce Wavelet-Enhanced Random Spectral Attention (WERSA), a novel mechanism of linear $O(n)$ time complexity that is pivotal to enable successful long-sequence processing without the performance trade-off. WERSA merges content-adaptive random spectral features together with multi-resolution Haar wavelets and learnable parameters to selectively attend to informative scales of data while preserving linear efficiency.
Large-scale comparisons \textbf{on single GPU} and across various benchmarks (vision, NLP, hierarchical reasoning) and various attention mechanisms (like Multiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer, Waveformer), reveal uniform advantages of WERSA. It achieves best accuracy in all tests. On ArXiv classification, WERSA improves accuracy over vanilla attention by 1.2\% (86.2\% vs 85.0\%) while cutting training time by 81\% (296s vs 1554s) and FLOPS by 73.4\% (26.2G vs 98.4G). Significantly, WERSA excels where vanilla and FlashAttention-2 fail: on ArXiv-128k's extremely lengthy sequences, it achieves best accuracy (79.1\%) and AUC (0.979) among viable methods, operating on data that gives Out-Of-Memory errors to quadratic methods while being \textbf{twice as fast} as Waveformer, its next-best competitor.
By significantly reducing computational loads without compromising accuracy, WERSA makes possible more practical, more affordable, long-context models, in particular on low-resource hardware, for more sustainable and more scalable AI development. 

**Abstract (ZH)**: Wavelet-Enhanced Random Spectral Attention: A Linear Time Complexity Mechanism Enabling Efficient Long-Sequence Processing Without Performance Trade-Off 

---
# Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates 

**Title (ZH)**: 规范化标注 vs 外交式标注：来自乌拉圭手写出生证明的自动信息提取案例研究 

**Authors**: Natalia Bottaioli, Solène Tarride, Jérémy Anger, Seginus Mowlavi, Marina Gardella, Antoine Tadros, Gabriele Facciolo, Rafael Grompone von Gioi, Christopher Kermorvant, Jean-Michel Morel, Javier Preciozzi  

**Link**: [PDF](https://arxiv.org/pdf/2507.08636)  

**Abstract**: This study evaluates the recently proposed Document Attention Network (DAN) for extracting key-value information from Uruguayan birth certificates, handwritten in Spanish. We investigate two annotation strategies for automatically transcribing handwritten documents, fine-tuning DAN with minimal training data and annotation effort. Experiments were conducted on two datasets containing the same images (201 scans of birth certificates written by more than 15 different writers) but with different annotation methods. Our findings indicate that normalized annotation is more effective for fields that can be standardized, such as dates and places of birth, whereas diplomatic annotation performs much better for fields containing names and surnames, which can not be standardized. 

**Abstract (ZH)**: 本研究评估了最近提出的文档注意力网络（DAN）对乌拉圭出生证明（手写西班牙文）中关键信息的提取效果，并调查了两种标注策略以自动转录手写文档，在训练数据和标注努力最少的情况下对DAN进行微调。实验在包含相同图像的两个数据集（201份由15名以上不同书写者撰写的出生证明扫描件）上进行，但使用了不同的标注方法。研究发现，标准化标注对可以标准化的字段（如出生日期和出生地点）更有效，而外交标注在包含姓名和姓氏等无法标准化的字段时表现更好。 

---
# Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift 

**Title (ZH)**: 面向不平衡 covariate shift 下的联邦学习协作公平性研究 

**Authors**: Tianrun Yu, Jiaqi Wang, Haoyu Wang, Mingquan Lin, Han Liu, Nelson S. Yee, Fenglong Ma  

**Link**: [PDF](https://arxiv.org/pdf/2507.08617)  

**Abstract**: Collaborative fairness is a crucial challenge in federated learning. However, existing approaches often overlook a practical yet complex form of heterogeneity: imbalanced covariate shift. We provide a theoretical analysis of this setting, which motivates the design of FedAKD (Federated Asynchronous Knowledge Distillation)- simple yet effective approach that balances accurate prediction with collaborative fairness. FedAKD consists of client and server updates. In the client update, we introduce a novel asynchronous knowledge distillation strategy based on our preliminary analysis, which reveals that while correctly predicted samples exhibit similar feature distributions across clients, incorrectly predicted samples show significant variability. This suggests that imbalanced covariate shift primarily arises from misclassified samples. Leveraging this insight, our approach first applies traditional knowledge distillation to update client models while keeping the global model fixed. Next, we select correctly predicted high-confidence samples and update the global model using these samples while keeping client models fixed. The server update simply aggregates all client models. We further provide a theoretical proof of FedAKD's convergence. Experimental results on public datasets (FashionMNIST and CIFAR10) and a real-world Electronic Health Records (EHR) dataset demonstrate that FedAKD significantly improves collaborative fairness, enhances predictive accuracy, and fosters client participation even under highly heterogeneous data distributions. 

**Abstract (ZH)**: 协作公平性是联邦学习中的关键挑战。然而，现有方法往往会忽视一种实际且复杂的异质性形式：特征偏移不均衡。我们对该场景进行了理论分析，这激发了FedAKD（联邦异步知识蒸馏）这一简单而有效的方法的设计，该方法平衡了准确预测与协作公平性。FedAKD包括客户端和服务器更新。在客户端更新中，我们引入了一种基于初步分析的新颖的异步知识蒸馏策略，揭示了尽管正确预测的样本在不同客户端上具有相似的特征分布，但错误预测的样本显示出显著的差异性。这表明特征偏移不均衡主要源自分类错误的样本。利用这一见解，我们的方法首先应用传统知识蒸馏更新客户端模型，同时固定全局模型。随后，我们选择高置信度的正确预测样本，用这些样本更新全局模型，同时保持客户端模型不变。服务器更新只是聚合所有客户端模型。我们还提供了FedAKD收敛性的理论证明。实验结果表明，FedAKD显著改善了协作公平性、增强了预测准确性，并即使在高度异质的数据分布下也促进了客户端的参与。 

---
# Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy 

**Title (ZH)**: 通过提示工程生成原型人格：一项关于效率、有效性和 Empathy 的案例研究 

**Authors**: Fernando Ayach, Vitor Lameirão, Raul Leão, Jerfferson Felizardo, Rafael Sobrinho, Vanessa Borges, Patrícia Matsubara, Awdren Fontão  

**Link**: [PDF](https://arxiv.org/pdf/2507.08594)  

**Abstract**: Proto-personas are commonly used during early-stage Product Discovery, such as Lean Inception, to guide product definition and stakeholder alignment. However, the manual creation of proto-personas is often time-consuming, cognitively demanding, and prone to bias. In this paper, we propose and empirically investigate a prompt engineering-based approach to generate proto-personas with the support of Generative AI (GenAI). Our goal is to evaluate the approach in terms of efficiency, effectiveness, user acceptance, and the empathy elicited by the generated personas. We conducted a case study with 19 participants embedded in a real Lean Inception, employing a qualitative and quantitative methods design. The results reveal the approach's efficiency by reducing time and effort and improving the quality and reusability of personas in later discovery phases, such as Minimum Viable Product (MVP) scoping and feature refinement. While acceptance was generally high, especially regarding perceived usefulness and ease of use, participants noted limitations related to generalization and domain specificity. Furthermore, although cognitive empathy was strongly supported, affective and behavioral empathy varied significantly across participants. These results contribute novel empirical evidence on how GenAI can be effectively integrated into software Product Discovery practices, while also identifying key challenges to be addressed in future iterations of such hybrid design processes. 

**Abstract (ZH)**: 基于提示工程的生成式AI支持下proto-人物角色生成方法及其有效性研究 

---
# RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features 

**Title (ZH)**: 基于影像omics特征的可定制医疗图像检索框架 

**Authors**: Inye Na, Nejung Rue, Jiwon Chung, Hyunjin Park  

**Link**: [PDF](https://arxiv.org/pdf/2507.08546)  

**Abstract**: Medical image retrieval is a valuable field for supporting clinical decision-making, yet current methods primarily support 2D images and require fully annotated queries, limiting clinical flexibility. To address this, we propose RadiomicsRetrieval, a 3D content-based retrieval framework bridging handcrafted radiomics descriptors with deep learning-based embeddings at the tumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits volumetric data to leverage richer spatial context in medical images. We employ a promptable segmentation model (e.g., SAM) to derive tumor-specific image embeddings, which are aligned with radiomics features extracted from the same tumor via contrastive learning. These representations are further enriched by anatomical positional embedding (APE). As a result, RadiomicsRetrieval enables flexible querying based on shape, location, or partial feature sets. Extensive experiments on both lung CT and brain MRI public datasets demonstrate that radiomics features significantly enhance retrieval specificity, while APE provides global anatomical context essential for location-based searches. Notably, our framework requires only minimal user prompts (e.g., a single point), minimizing segmentation overhead and supporting diverse clinical scenarios. The capability to query using either image embeddings or selected radiomics attributes highlights its adaptability, potentially benefiting diagnosis, treatment planning, and research on large-scale medical imaging repositories. Our code is available at this https URL. 

**Abstract (ZH)**: 医学影像检索是支持临床决策的重要领域，现有的方法主要支持2D图像且需要完全标注的查询，限制了临床的灵活性。为了解决这一问题，我们提出了一种名为RadiomicsRetrieval的3D内容基于检索框架，将手工构建的影像组学描述符与基于深度学习的肿瘤级嵌入相结合。与现有的2D方法不同，RadiomicsRetrieval充分利用了体数据，利用了医学影像中的更丰富的空间语境。我们采用可提示的分割模型（如SAM）来提取肿瘤特异性图像嵌入，这些嵌入与通过对比学习从同一肿瘤中提取的影像组学特征对齐。进一步通过解剖位置嵌入（APE）增强了这些表示。结果，RadiomicsRetrieval使得基于形状、位置或部分特征集的灵活查询成为可能。在肺CT和脑MRI公开数据集上的广泛实验表明，影像组学特征显著提高了检索的特异性，而解剖位置嵌入（APE）提供了基于位置搜索所需的重要全局解剖上下文。值得注意的是，我们的框架仅需极少的用户提示（例如，一个点），从而减少了分割开销并支持了多种临床场景。既能使用图像嵌入也能使用选择的影像组学属性进行查询的能力突显了其适应性，有望造福于大规模医学影像库的诊断、治疗计划和研究。我们的代码可在以下链接获得：this https URL。 

---
# White-Basilisk: A Hybrid Model for Code Vulnerability Detection 

**Title (ZH)**: 白蜥蜴：一种代码漏洞检测的混合模型 

**Authors**: Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris Ioannidis  

**Link**: [PDF](https://arxiv.org/pdf/2507.08540)  

**Abstract**: The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a novel approach to vulnerability detection that demonstrates superior performance while challenging prevailing assumptions in AI model scaling. Utilizing an innovative architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process sequences of unprecedented length enables comprehensive analysis of extensive codebases in a single pass, surpassing the context limitations of current Large Language Models (LLMs). White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research not only establishes new benchmarks in code security but also provides empirical evidence that compact, efficiently designed models can outperform larger counterparts in specialized tasks, potentially redefining optimization strategies in AI development for domain-specific applications. 

**Abstract (ZH)**: 白骨草：一种在有效性上超越现有假设的新型漏洞检测方法 

---
# MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling 

**Title (ZH)**: MIDI-VALLE: 通过神经编码器语言建模提高表达性钢琴表演合成 

**Authors**: Jingjing Tang, Xin Wang, Zhe Zhang, Junichi Yamagishi, Geraint Wiggins, George Fazekas  

**Link**: [PDF](https://arxiv.org/pdf/2507.08530)  

**Abstract**: Generating expressive audio performances from music scores requires models to capture both instrument acoustics and human interpretation. Traditional music performance synthesis pipelines follow a two-stage approach, first generating expressive performance MIDI from a score, then synthesising the MIDI into audio. However, the synthesis models often struggle to generalise across diverse MIDI sources, musical styles, and recording environments. To address these challenges, we propose MIDI-VALLE, a neural codec language model adapted from the VALLE framework, which was originally designed for zero-shot personalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio synthesis, we improve the architecture to condition on a reference audio performance and its corresponding MIDI. Unlike previous TTS-based systems that rely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens, facilitating a more consistent and robust modelling of piano performances. Furthermore, the model's generalisation ability is enhanced by training on an extensive and diverse piano performance dataset. Evaluation results show that MIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving over 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the listening test, MIDI-VALLE received 202 votes compared to 58 for the baseline, demonstrating improved synthesis quality and generalisation across diverse performance MIDI inputs. 

**Abstract (ZH)**: 从乐谱生成表达性强的音频表演需要模型捕捉乐器音色和人类诠释。传统的音乐表演合成管道采用两阶段方法，首先从乐谱生成具有表现力的MIDI表演，然后将其合成成为音频。然而，合成模型往往难以在多样化的MIDI源、音乐风格和录音环境中做到泛化。为应对这些挑战，我们提出MIDI-VALLE，这是一种源自零样本个性化文本转语音（TTS）合成框架VALLE的神经编码语言模型。对于表演MIDI到音频的合成，我们改进了架构，使其能够根据参考音频表演及其对应的MIDI进行条件化。与依赖琴键展开图的以前的TTS系统不同，MIDI-VALLE将MIDI和音频编码为离散令牌，促进了更一致和鲁棒的钢琴表演建模。此外，通过在广泛多样化的钢琴表演数据集上训练，模型的泛化能力得到了增强。评估结果表明，MIDI-VALLE在ATEPP和Maestro数据集中实现了超过75%更低的Frechet音频距离，显著优于最先进的基线模型。在听觉测试中，MIDI-VALLE获得了202票，而基线模型为58票，这表明其在多样化的MIDI表演输入上的合成质量和泛化能力得到了提高。 

---
# PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts 

**Title (ZH)**: SemEval-2025 任务 11 中的 PromotionGo：一种面向特征的跨语言短文本多情绪检测框架 

**Authors**: Ziyi Huang, Xia Cui  

**Link**: [PDF](https://arxiv.org/pdf/2507.08499)  

**Abstract**: This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection (Track A), which focuses on multi-label emotion detection in short texts. We propose a feature-centric framework that dynamically adapts document representations and learning algorithms to optimize language-specific performance. Our study evaluates three key components: document representation, dimensionality reduction, and model training in 28 languages, highlighting five for detailed analysis. The results show that TF-IDF remains highly effective for low-resource languages, while contextual embeddings like FastText and transformer-based document representations, such as those produced by Sentence-BERT, exhibit language-specific strengths. Principal Component Analysis (PCA) reduces training time without compromising performance, particularly benefiting FastText and neural models such as Multi-Layer Perceptrons (MLP). Computational efficiency analysis underscores the trade-off between model complexity and processing cost. Our framework provides a scalable solution for multilingual emotion detection, addressing the challenges of linguistic diversity and resource constraints. 

**Abstract (ZH)**: 本文介绍了我们用于SemEval 2025 Task 11：跨越文本情感检测中的鸿沟（Track A）的系统，该任务专注于短文本的多标签情感检测。我们提出了一种以特征为中心的框架，动态调整文档表示和学习算法以优化语言特定的表现。研究评估了三种关键组件：文档表示、降维和模型训练，涵盖28种语言，并详细分析了其中五种。结果显示，TF-IDF 对于低资源语言仍然非常有效，而如FastText这样的上下文嵌入和由Sentence-BERT生成的基于变换器的文档表示在不同语言上展现出语言特定的优势。主成分分析（PCA）在不牺牲性能的情况下减少了训练时间，特别是在FastText和多层感知机（MLP）等神经模型上。计算效率分析强调了模型复杂性和处理成本之间的权衡。我们的框架提供了一种针对多语言情感检测的可扩展解决方案，应对语言多样性和资源限制的挑战。 

---
# Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach 

**Title (ZH)**: 增强论文连贯性评估：一种新型项目反应理论方法 

**Authors**: Bruno Alexandre Rosa, Hilário Oliveira, Luiz Rodrigues, Eduardo Araujo Oliveira, Rafael Ferreira Mello  

**Link**: [PDF](https://arxiv.org/pdf/2507.08487)  

**Abstract**: Essays are considered a valuable mechanism for evaluating learning outcomes in writing. Textual cohesion is an essential characteristic of a text, as it facilitates the establishment of meaning between its parts. Automatically scoring cohesion in essays presents a challenge in the field of educational artificial intelligence. The machine learning algorithms used to evaluate texts generally do not consider the individual characteristics of the instances that comprise the analysed corpus. In this meaning, item response theory can be adapted to the context of machine learning, characterising the ability, difficulty and discrimination of the models used. This work proposes and analyses the performance of a cohesion score prediction approach based on item response theory to adjust the scores generated by machine learning models. In this study, the corpus selected for the experiments consisted of the extended Essay-BR, which includes 6,563 essays in the style of the National High School Exam (ENEM), and the Brazilian Portuguese Narrative Essays, comprising 1,235 essays written by 5th to 9th grade students from public schools. We extracted 325 linguistic features and treated the problem as a machine learning regression task. The experimental results indicate that the proposed approach outperforms conventional machine learning models and ensemble methods in several evaluation metrics. This research explores a potential approach for improving the automatic evaluation of cohesion in educational essays. 

**Abstract (ZH)**: essays被认为是评估写作学习成果的一种有价值的机制。文本连贯性是文本的一个重要特征，因为它有助于文本各部分之间意义的建立。在教育人工智能领域，自动评分连贯性是一项挑战。用于评估文本的机器学习算法通常不会考虑所分析语料库中个体实例的独特特征。在这种意义上，可以将项目反应理论适应机器学习的语境，表征所使用的模型的能力、难度和区分度。本文提出并分析了一种基于项目反应理论的连贯性评分预测方法，以调整机器学习模型生成的分数。在本研究中，用于实验的语料库包括扩展的Essay-BR，其中包含6,563篇按照全国高中考试（ENEM）风格撰写的作文，以及由公立学校5至9年级学生撰写的1,235篇巴西葡萄牙语叙事作文。我们提取了325个语言特征，并将问题视为一个机器学习回归任务。实验结果表明，所提出的方法在多个评估指标上优于传统机器学习模型和集成方法。本文探索了提高教育作文中连贯性自动评估的一种潜在方法。 

---
# A document is worth a structured record: Principled inductive bias design for document recognition 

**Title (ZH)**: 一份文档等同于一个结构化的记录：,



 principled 归并为 “合理的”,



 inductive bias design 归并为 “归纳偏置设计”,



 document recognition 归并为 “文档识别”。



因此，翻译后的标题为：



一份文档等同于一个结构化的记录：合理的归纳偏置设计用于文档识别。 

**Authors**: Benjamin Meyer, Lukas Tuggener, Sascha Hänzi, Daniel Schmid, Erdal Ayfer, Benjamin F. Grewe, Ahmed Abdulkadir, Thilo Stadelmann  

**Link**: [PDF](https://arxiv.org/pdf/2507.08458)  

**Abstract**: Many document types use intrinsic, convention-driven structures that serve to encode precise and structured information, such as the conventions governing engineering drawings. However, state-of-the-art approaches treat document recognition as a mere computer vision problem, neglecting these underlying document-type-specific structural properties, making them dependent on sub-optimal heuristic post-processing and rendering many less frequent or more complicated document types inaccessible to modern document recognition. We suggest a novel perspective that frames document recognition as a transcription task from a document to a record. This implies a natural grouping of documents based on the intrinsic structure inherent in their transcription, where related document types can be treated (and learned) similarly. We propose a method to design structure-specific inductive biases for the underlying machine-learned end-to-end document recognition systems, and a respective base transformer architecture that we successfully adapt to different structures. We demonstrate the effectiveness of the so-found inductive biases in extensive experiments with progressively complex record structures from monophonic sheet music, shape drawings, and simplified engineering drawings. By integrating an inductive bias for unrestricted graph structures, we train the first-ever successful end-to-end model to transcribe engineering drawings to their inherently interlinked information. Our approach is relevant to inform the design of document recognition systems for document types that are less well understood than standard OCR, OMR, etc., and serves as a guide to unify the design of future document foundation models. 

**Abstract (ZH)**: 基于结构转换的文档识别新视角：从文档到记录的转录任务 

---
# Space filling positionality and the Spiroformer 

**Title (ZH)**: 空间填充位置性与Spiroformer 

**Authors**: M. Maurin, M.Á. Evangelista-Alvarado, P. Suárez-Serrato  

**Link**: [PDF](https://arxiv.org/pdf/2507.08456)  

**Abstract**: Transformers excel when dealing with sequential data. Generalizing transformer models to geometric domains, such as manifolds, we encounter the problem of not having a well-defined global order. We propose a solution with attention heads following a space-filling curve. As a first experimental example, we present the Spiroformer, a transformer that follows a polar spiral on the $2$-sphere. 

**Abstract (ZH)**: Transformer模型在处理序列数据方面表现出色。将Transformer模型推广到几何领域，如流形，我们遇到了缺乏全局顺序定义的问题。我们提出了一种解决方案，即让注意力头遵循空间填充曲线。作为首个实验示例，我们介绍了Spiroformer模型，该模型在二维球面上遵循螺旋轨迹。 

---
# Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization 

**Title (ZH)**: 面向AI原生RAN：运营商视角的6G Day 1标准化 

**Authors**: Nan Li, Qi Sun, Lehan Wang, Xiaofei Xu, Jinri Huang, Chunhui Liu, Jing Gao, Yuhong Huang, Chih-Lin I  

**Link**: [PDF](https://arxiv.org/pdf/2507.08403)  

**Abstract**: Artificial Intelligence/Machine Learning (AI/ML) has become the most certain and prominent feature of 6G mobile networks. Unlike 5G, where AI/ML was not natively integrated but rather an add-on feature over existing architecture, 6G shall incorporate AI from the onset to address its complexity and support ubiquitous AI applications. Based on our extensive mobile network operation and standardization experience from 2G to 5G, this paper explores the design and standardization principles of AI-Native radio access networks (RAN) for 6G, with a particular focus on its critical Day 1 architecture, functionalities and capabilities. We investigate the framework of AI-Native RAN and present its three essential capabilities to shed some light on the standardization direction; namely, AI-driven RAN processing/optimization/automation, reliable AI lifecycle management (LCM), and AI-as-a-Service (AIaaS) provisioning. The standardization of AI-Native RAN, in particular the Day 1 features, including an AI-Native 6G RAN architecture, were proposed. For validation, a large-scale field trial with over 5000 5G-A base stations have been built and delivered significant improvements in average air interface latency, root cause identification, and network energy consumption with the proposed architecture and the supporting AI functions. This paper aims to provide a Day 1 framework for 6G AI-Native RAN standardization design, balancing technical innovation with practical deployment. 

**Abstract (ZH)**: 人工智能/机器学习（AI/ML）已成为6G移动网络最具确定性和显著特征的部分。与5G中AI/ML不是原生集成而是作为现有架构上的附加功能不同，6G将从一开始就整合AI以应对其复杂性并支持广泛的人工智能应用。基于我们从2G到5G的广泛移动网络运行和标准化经验，本文探讨了AI原生无线接入网（RAN）的设计和标准化原则，特别是其关键的“上线”架构、功能和能力。我们研究了AI原生RAN的框架并提出了其三项基本能力，以阐明标准化方向；即AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理（LCM）以及AI即服务（AIaaS）的供应用。针对AI原生RAN特别是“上线”特性，包括AI原生6G RAN架构，提出了标准化建议。为进一步验证，搭建了超过5000个5G-A基站的大规模实地试验，并在所提出的架构和支持的AI功能下实现了平均空中接口延迟、根本原因识别和网络能耗的显著改进。本文旨在提供一个平衡技术创新与实际部署的6G AI原生RAN标准化设计框架。 

---
# Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement 

**Title (ZH)**: 基于Dirac重平衡与分布纠缠的单域泛化方法用于多模态跨癌种预后 

**Authors**: Jia-Xuan Jiang, Jiashuai Liu, Hongtao Wu, Yifeng Wu, Zhong Wang, Qi Bi, Yefeng Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2507.08340)  

**Abstract**: Deep learning has shown remarkable performance in integrating multimodal data for survival prediction. However, existing multimodal methods mainly focus on single cancer types and overlook the challenge of generalization across cancers. In this work, we are the first to reveal that multimodal prognosis models often generalize worse than unimodal ones in cross-cancer scenarios, despite the critical need for such robustness in clinical practice. To address this, we propose a new task: Cross-Cancer Single Domain Generalization for Multimodal Prognosis, which evaluates whether models trained on a single cancer type can generalize to unseen cancers. We identify two key challenges: degraded features from weaker modalities and ineffective multimodal integration. To tackle these, we introduce two plug-and-play modules: Sparse Dirac Information Rebalancer (SDIR) and Cancer-aware Distribution Entanglement (CADE). SDIR mitigates the dominance of strong features by applying Bernoulli-based sparsification and Dirac-inspired stabilization to enhance weaker modality signals. CADE, designed to synthesize the target domain distribution, fuses local morphological cues and global gene expression in latent space. Experiments on a four-cancer-type benchmark demonstrate superior generalization, laying the foundation for practical, robust cross-cancer multimodal prognosis. Code is available at this https URL 

**Abstract (ZH)**: 跨癌种单域泛化多模态预后任务 

---
# Audio Inpanting using Discrete Diffusion Model 

**Title (ZH)**: 使用离散扩散模型的音频修复 

**Authors**: Tali Dror, Iftach Shoham, Moshe Buchris, Oren Gal, Haim Permuter, Gilad Katz, Eliya Nachmani  

**Link**: [PDF](https://arxiv.org/pdf/2507.08333)  

**Abstract**: Audio inpainting refers to the task of reconstructing missing segments in corrupted audio recordings. While prior approaches-including waveform and spectrogram-based diffusion models-have shown promising results for short gaps, they often degrade in quality when gaps exceed 100 milliseconds (ms). In this work, we introduce a novel inpainting method based on discrete diffusion modeling, which operates over tokenized audio representations produced by a pre-trained audio tokenizer. Our approach models the generative process directly in the discrete latent space, enabling stable and semantically coherent reconstruction of missing audio. We evaluate the method on the MusicNet dataset using both objective and perceptual metrics across gap durations up to 300 ms. We further evaluated our approach on the MTG dataset, extending the gap duration to 500 ms. Experimental results demonstrate that our method achieves competitive or superior performance compared to existing baselines, particularly for longer gaps, offering a robust solution for restoring degraded musical recordings. Audio examples of our proposed method can be found at this https URL 

**Abstract (ZH)**: 音频修复指的是重构受损音频记录中缺失段落的任务。虽然先前的方法——包括基于波形和谱图的扩散模型——在处理短缺损时显示出有希望的结果，但当缺损超过100毫秒时，其质量往往会下降。在本文中，我们引入了一种基于离散扩散建模的新型修复方法，该方法运行在预训练音频分词器生成的令牌化音频表示上。我们的方法直接在离散潜在空间中建模生成过程，从而实现对缺失音频的稳定且语义一致的重构。我们在MusicNet数据集上使用客观和感知度量对方法进行了评估，覆盖从1毫秒到300毫秒的缺损时间。我们还在MTG数据集上进一步评估了我们的方法，将缺损时间扩展到500毫秒。实验结果表明，与现有基线方法相比，我们的方法在较长缺损时实现了具有竞争力或更优的性能，提供了一种恢复降质音乐记录的稳健解决方案。我们的方法示例音频可以在以下链接找到：this https URL。 

---
# Generative AI in Science: Applications, Challenges, and Emerging Questions 

**Title (ZH)**: 生成式AI在科学中的应用、挑战及新兴问题 

**Authors**: Ryan Harries, Cornelia Lawson, Philip Shapira  

**Link**: [PDF](https://arxiv.org/pdf/2507.08310)  

**Abstract**: This paper examines the impact of Generative Artificial Intelligence (GenAI) on scientific practices, conducting a qualitative review of selected literature to explore its applications, benefits, and challenges. The review draws on the OpenAlex publication database, using a Boolean search approach to identify scientific literature related to GenAI (including large language models and ChatGPT). Thirty-nine highly cited papers and commentaries are reviewed and qualitatively coded. Results are categorized by GenAI applications in science, scientific writing, medical practice, and education and training. The analysis finds that while there is a rapid adoption of GenAI in science and science practice, its long-term implications remain unclear, with ongoing uncertainties about its use and governance. The study provides early insights into GenAI's growing role in science and identifies questions for future research in this evolving field. 

**Abstract (ZH)**: 本文考察生成性人工智能（GenAI）对科学研究实践的影响，通过定性综述选定的文献，探讨其应用、益处和挑战。综述基于OpenAlex出版数据库，采用布尔搜索方法，识别与GenAI（包括大型语言模型和ChatGPT）相关的科学文献。审查了39篇高被引论文和评论，并进行了定性编码。结果按GenAI在科学、科研写作、医疗实践以及教育和培训中的应用进行分类。分析发现，尽管GenAI在科学和科学研究中的应用快速发展，但其长期影响尚不明确，对其使用和治理仍存在持续的不确定性。该研究提供了关于GenAI在科学中日益重要作用的早期见解，并指出了这一不断发展的领域中未来研究的问题。 

---
# Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks 

**Title (ZH)**: 用于攻击量子神经网络的量子特性木马（QuPTs） 

**Authors**: Sounak Bhowmik, Travis S. Humble, Himanshu Thapliyal  

**Link**: [PDF](https://arxiv.org/pdf/2507.08202)  

**Abstract**: Quantum neural networks (QNN) hold immense potential for the future of quantum machine learning (QML). However, QNN security and robustness remain largely unexplored. In this work, we proposed novel Trojan attacks based on the quantum computing properties in a QNN-based binary classifier. Our proposed Quantum Properties Trojans (QuPTs) are based on the unitary property of quantum gates to insert noise and Hadamard gates to enable superposition to develop Trojans and attack QNNs. We showed that the proposed QuPTs are significantly stealthier and heavily impact the quantum circuits' performance, specifically QNNs. The most impactful QuPT caused a deterioration of 23% accuracy of the compromised QNN under the experimental setup. To the best of our knowledge, this is the first work on the Trojan attack on a fully quantum neural network independent of any hybrid classical-quantum architecture. 

**Abstract (ZH)**: 量子神经网络（QNN）在量子机器学习（QML）的未来中具有巨大的潜力。然而，QNN的安全性和鲁棒性尚未得到充分探索。在本工作中，我们基于量子计算属性提出了新型的QNN二元分类器中的特洛伊木马攻击。我们提出的量子特性特洛伊木马（QuPTs）利用量子门的幺正性质插入噪声，使用哈达玛门实现叠加，以开发特洛伊木马并攻击QNN。我们展示，提出的QuPTs在实验设置中对量子电路性能，特别是QNNs，产生了重大影响。最有效的QuPT在实验设置中导致受损QNN准确率下降23%。据我们所知，这是首个独立于任何混合经典-量子架构的QNN特洛伊木马攻击工作。 

---
# Overview of the TREC 2021 deep learning track 

**Title (ZH)**: TREC 2021 深度学习赛道概览 

**Authors**: Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Jimmy Lin  

**Link**: [PDF](https://arxiv.org/pdf/2507.08191)  

**Abstract**: This is the third year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we refreshed both the document and the passage collections which also led to a nearly four times increase in the document collection size and nearly $16$ times increase in the size of the passage collection. Deep neural ranking models that employ large scale pretraininig continued to outperform traditional retrieval methods this year. We also found that single stage retrieval can achieve good performance on both tasks although they still do not perform at par with multistage retrieval pipelines. Finally, the increase in the collection size and the general data refresh raised some questions about completeness of NIST judgments and the quality of the training labels that were mapped to the new collections from the old ones which we discuss in this report. 

**Abstract (ZH)**: 这是TREC深度学习赛道的第三年。与往年一样，我们利用MS MARCO数据集提供了数百万人标注的训练标签，用于段落和文档排名任务。此外，今年我们刷新了文档和段落集合，这导致文档集合的规模几乎增加了四倍，段落集合的规模增加了约十六倍。采用大规模预训练的深度神经排名模型继续在今年的实验中超过传统检索方法。我们还发现，单阶段检索在两个任务上都能取得较好的性能，尽管它们仍然无法与多阶段检索管道相匹敌。最后，集合规模的增加和整体数据的刷新引发了关于NIST判断完整性和从旧集合映射到新集合的训练标签质量的一些问题，我们在本报告中对此进行了讨论。 

---
# Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity 

**Title (ZH)**: 重新思考时空异常检测：因果驱动的网络安全愿景 

**Authors**: Arun Vignesh Malarkkan, Haoyue Bai, Xinyuan Wang, Anjali Kaushik, Dongjie Wang, Yanjie Fu  

**Link**: [PDF](https://arxiv.org/pdf/2507.08177)  

**Abstract**: As cyber-physical systems grow increasingly interconnected and spatially distributed, ensuring their resilience against evolving cyberattacks has become a critical priority. Spatio-Temporal Anomaly detection plays an important role in ensuring system security and operational integrity. However, current data-driven approaches, largely driven by black-box deep learning, face challenges in interpretability, adaptability to distribution shifts, and robustness under evolving system dynamics. In this paper, we advocate for a causal learning perspective to advance anomaly detection in spatially distributed infrastructures that grounds detection in structural cause-effect relationships. We identify and formalize three key directions: causal graph profiling, multi-view fusion, and continual causal graph learning, each offering distinct advantages in uncovering dynamic cause-effect structures across time and space. Drawing on real-world insights from systems such as water treatment infrastructures, we illustrate how causal models provide early warning signals and root cause attribution, addressing the limitations of black-box detectors. Looking ahead, we outline the future research agenda centered on multi-modality, generative AI-driven, and scalable adaptive causal frameworks. Our objective is to lay a new research trajectory toward scalable, adaptive, explainable, and spatially grounded anomaly detection systems. We hope to inspire a paradigm shift in cybersecurity research, promoting causality-driven approaches to address evolving threats in interconnected infrastructures. 

**Abstract (ZH)**: 随着网络物理系统日益互联和空间分布，确保其抵御 evolving网络攻击的能力已成为一项 Critical Priority。时空异常检测在保障系统安全和操作完整性方面发挥着重要作用。然而，当前以黑盒深度学习为主的数据驱动方法在可解释性、分布变化适应性和在不断演变的系统动力学下的鲁棒性方面面临挑战。本文倡导从因果学习的角度推进分布式基础设施中的异常检测，使检测基于结构性因果关系。我们确定并形式化了三个关键方向：因果图剖析、多视图融合和持续因果图学习，每个方向都提供了在时间和空间上揭示动态因果结构的独特优势。借助水处理基础设施等系统的实际洞见，我们展示了因果模型如何提供早期预警信号和根本原因归因，解决了黑盒检测器的局限性。展望未来，我们指出了以多模态、生成AI驱动和可扩展自适应因果框架为中心的未来研究议程。我们的目标是为可扩展、自适应、可解释和空间性基础的异常检测系统奠定新的研究轨迹。我们期望激发网络安全研究中的范式转变，促进因果驱动的方法以应对互联基础设施中的不断演变威胁。 

---
# KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence 

**Title (ZH)**: KP-A: 促进能动网络智能的一体化网络知识平面 

**Authors**: Yun Tang, Mengbang Zou, Zeinab Nezami, Syed Ali Raza Zaidi, Weisi Guo  

**Link**: [PDF](https://arxiv.org/pdf/2507.08164)  

**Abstract**: The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts. 

**Abstract (ZH)**: 大语言模型（LLMs）和自主系统的发展使具有高级智能的自主6G网络成为可能，包括自我配置、自我优化和自我修复。然而，当前个体智能任务的实现需要孤立的知识检索管道，导致数据流冗余和解释不一致。借鉴Open-RAN在服务模型统一方面的工作（以支持互操作性和供应商多样性），我们提出KP-A：一种专门为了自主网络智能设计的统一网络知识平面。通过将网络知识获取和管理与智能逻辑分离，KP-A 简化了智能工程师的开发并降低了维护复杂性。通过提供直观且一致的知识接口，KP-A 也增强了网络智能代理之间的互操作性。我们在两个典型的智能任务中展示了KP-A：实时网络知识问答和边缘AI服务编排。所有实现成果均已开源，以支持可重复性和未来标准化工作的进行。 

---
# AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration 

**Title (ZH)**: AmpLyze: 一种用于预测溶血浓度的深度学习模型 

**Authors**: Peng Qiu, Hanqi Feng, Barnabas Poczos  

**Link**: [PDF](https://arxiv.org/pdf/2507.08162)  

**Abstract**: Red-blood-cell lysis (HC50) is the principal safety barrier for antimicrobial-peptide (AMP) therapeutics, yet existing models only say "toxic" or "non-toxic." AmpLyze closes this gap by predicting the actual HC50 value from sequence alone and explaining the residues that drive toxicity. The model couples residue-level ProtT5/ESM2 embeddings with sequence-level descriptors in dual local and global branches, aligned by a cross-attention module and trained with log-cosh loss for robustness to assay noise. The optimal AmpLyze model reaches a PCC of 0.756 and an MSE of 0.987, outperforming classical regressors and the state-of-the-art. Ablations confirm that both branches are essential, and cross-attention adds a further 1% PCC and 3% MSE improvement. Expected-Gradients attributions reveal known toxicity hotspots and suggest safer substitutions. By turning hemolysis assessment into a quantitative, sequence-based, and interpretable prediction, AmpLyze facilitates AMP design and offers a practical tool for early-stage toxicity screening. 

**Abstract (ZH)**: 红细胞裂解半数有效浓度（HC50）是抗菌肽（AMP）治疗安全性的重要屏障，现有模型仅能区分“有毒”或“无毒”。AmpLyze 通过仅从序列预测实际HC50值并解释驱动毒性的残基，填补了这一空白。该模型将残基级ProtT5/ESM2嵌入与序列级描述子结合，在双局部和全局分支中进行表征，并通过交叉注意力模块对齐，使用对试验噪声具有鲁棒性的对数双曲余弦损失进行训练。优化后的AmpLyze模型达到了相关系数（PCC）0.756和均方误差（MSE）0.987，优于经典回归器和当前最佳方法。消融实验表明两个分支都是必需的，交叉注意力进一步提高了1%的PCC和3%的MSE。梯度期望归因揭示了已知毒性热点，并建议了更安全的替换方案。通过将溶血评估转化为定量、序列基础和可解释的预测，AmpLyze 促进了AMP的设计，并提供了一种早期毒性筛查的实用工具。 

---
# ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction 

**Title (ZH)**: ALCo-FM：自适应长上下文基础模型用于事故预测 

**Authors**: Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath  

**Link**: [PDF](https://arxiv.org/pdf/2507.08153)  

**Abstract**: Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: this https URL 

**Abstract (ZH)**: 交通事故是高影响但频率较低的事件，需要长期上下文多模态推理以实现准确的风险预测。本文介绍了一种统一的自适应长期上下文基础模型ALCo-FM，该模型计算波动预评分以动态选择输入数据的上下文窗口，并通过浅层交叉注意机制编码和融合这些多模态数据。经过局部GAT层和基于H3六边形网格的BigBird风格稀疏全局变压器处理，并结合蒙特卡洛 Dropout 提供置信度，该模型提供了性能优越且校准良好的预测结果。ALCo-FM 使用加权损失在15个美国城市的数据上进行训练，并在保留城市上进行少量数据微调，最终在大规模城市风险预测中优于超过20个最先进的基线模型，准确率为0.94，F1分为0.92，ECE为0.04。代码和数据集可从以下链接获取：this https URL。 

---
# Quasi-Random Physics-informed Neural Networks 

**Title (ZH)**: 拟随机物理知情神经网络 

**Authors**: Tianchi Yu, Ivan Oseledets  

**Link**: [PDF](https://arxiv.org/pdf/2507.08121)  

**Abstract**: Physics-informed neural networks have shown promise in solving partial differential equations (PDEs) by integrating physical constraints into neural network training, but their performance is sensitive to the sampling of points. Based on the impressive performance of quasi Monte-Carlo methods in high dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of random points directly from the domain. Theoretically, QRPINNs have been proven to have a better convergence rate than PINNs. Empirically, experiments demonstrate that QRPINNs significantly outperform PINNs and some representative adaptive sampling methods, especially in high-dimensional PDEs. Furthermore, combining QRPINNs with adaptive sampling can further improve the performance. 

**Abstract (ZH)**: 物理信息神经网络通过将物理约束整合到神经网络训练中，在求解偏微分方程(PDEs)方面表现出潜力，但其性能对点的采样敏感。基于蒙特卡洛方法在高维问题上出色的性能，本文提出了一种基于低偏差序列采样的拟蒙特卡洛物理信息神经网络(QRPINNs)，而不是直接从域中随机采样点。理论上，QRPINNs的收敛速度优于物理信息神经网络(PINNs)。实验上，实验结果表明，QRPINNs在高维PDEs中的表现显著优于PINNs和一些代表性自适应采样方法。此外，将QRPINNs与自适应采样相结合可以进一步提高性能。 

---
# Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently 

**Title (ZH)**: 树结构帕兹恩估计器可以更高效地解决黑盒组合优化问题 

**Authors**: Kenshin Abe, Yunzhuo Wang, Shuhei Watanabe  

**Link**: [PDF](https://arxiv.org/pdf/2507.08053)  

**Abstract**: Tree-structured Parzen estimator (TPE) is a versatile hyperparameter optimization (HPO) method supported by popular HPO tools. Since these HPO tools have been developed in line with the trend of deep learning (DL), the problem setups often used in the DL domain have been discussed for TPE such as multi-objective optimization and multi-fidelity optimization. However, the practical applications of HPO are not limited to DL, and black-box combinatorial optimization is actively utilized in some domains, e.g., chemistry and biology. As combinatorial optimization has been an untouched, yet very important, topic in TPE, we propose an efficient combinatorial optimization algorithm for TPE. In this paper, we first generalize the categorical kernel with the numerical kernel in TPE, enabling us to introduce a distance structure to the categorical kernel. Then we discuss modifications for the newly developed kernel to handle a large combinatorial search space. These modifications reduce the time complexity of the kernel calculation with respect to the size of a combinatorial search space. In the experiments using synthetic problems, we verified that our proposed method identifies better solutions with fewer evaluations than the original TPE. Our algorithm is available in Optuna, an open-source framework for HPO. 

**Abstract (ZH)**: 基于树结构帕兹恩估计器的组合优化算法 

---
# An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis 

**Title (ZH)**: 增强的隐私保护联邦少样本学习框架用于呼吸系统疾病诊断 

**Authors**: Ming Wang, Zhaoyang Duan, Dong Xue, Fangzhou Liu, Zhongheng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.08050)  

**Abstract**: The labor-intensive nature of medical data annotation presents a significant challenge for respiratory disease diagnosis, resulting in a scarcity of high-quality labeled datasets in resource-constrained settings. Moreover, patient privacy concerns complicate the direct sharing of local medical data across institutions, and existing centralized data-driven approaches, which rely on amounts of available data, often compromise data privacy. This study proposes a federated few-shot learning framework with privacy-preserving mechanisms to address the issues of limited labeled data and privacy protection in diagnosing respiratory diseases. In particular, a meta-stochastic gradient descent algorithm is proposed to mitigate the overfitting problem that arises from insufficient data when employing traditional gradient descent methods for neural network training. Furthermore, to ensure data privacy against gradient leakage, differential privacy noise from a standard Gaussian distribution is integrated into the gradients during the training of private models with local data, thereby preventing the reconstruction of medical images. Given the impracticality of centralizing respiratory disease data dispersed across various medical institutions, a weighted average algorithm is employed to aggregate local diagnostic models from different clients, enhancing the adaptability of a model across diverse scenarios. Experimental results show that the proposed method yields compelling results with the implementation of differential privacy, while effectively diagnosing respiratory diseases using data from different structures, categories, and distributions. 

**Abstract (ZH)**: 医疗数据注释的劳动密集性质为呼吸疾病诊断带来了显著挑战，导致资源受限环境中高质量标注数据的稀缺。此外，患者隐私担忧使机构间直接共享本地医疗数据变得复杂，现有的依赖大量可用数据的集中式数据驱动方法经常牺牲数据隐私。本研究提出了一种带有隐私保护机制的联邦少-shot学习框架，以解决诊断呼吸疾病时标注数据有限和隐私保护的问题。特别是，提出了一种元随机梯度下降算法来缓解使用传统梯度下降方法训练神经网络时由数据不足引起的过拟合问题。此外，为了防止梯度泄露导致的隐私泄露，整合了标准高斯分布的差分隐私噪声到本地数据训练的私有模型的梯度中，从而防止重建医疗图像。鉴于呼吸疾病数据分散在各个医疗机构之间难以集中化，采用了加权平均算法聚合不同客户端的诊断模型，增强了模型在多种场景下的适应性。实验结果表明，所提出的方法在实施差分隐私的同时，能够有效诊断来自不同结构、类别和分布的数据，取得了令人信服的结果。 

---
# ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints 

**Title (ZH)**: ConsNoTrainLoRA: 受约束的低秩适配器的数据驱动权重初始化 

**Authors**: Debasmit Das, Hyoungwoo Park, Munawar Hayat, Seokeon Choi, Sungrack Yun, Fatih Porikli  

**Link**: [PDF](https://arxiv.org/pdf/2507.08044)  

**Abstract**: Foundation models are pre-trained on large-scale datasets and subsequently fine-tuned on small-scale datasets using parameter-efficient fine-tuning (PEFT) techniques like low-rank adapters (LoRA). In most previous works, LoRA weight matrices are randomly initialized with a fixed rank across all attachment points. In this paper, we improve convergence and final performance of LoRA fine-tuning, using our proposed data-driven weight initialization method, ConsNoTrainLoRA (CNTLoRA). We express LoRA initialization as a domain shift problem where we use multiple constraints relating the pre-training and fine-tuning activations. By reformulating these constraints, we obtain a closed-form estimate of LoRA weights that depends on pre-training weights and fine-tuning activation vectors and hence requires no training during initialization. This weight estimate is decomposed to initialize the up and down matrices with proposed flexibility of variable ranks. With the proposed initialization method, we fine-tune on downstream tasks such as image generation, image classification and image understanding. Both quantitative and qualitative results demonstrate that CNTLoRA outperforms standard and data-driven weight initialization methods. Extensive analyses and ablations further elucidate the design choices of our framework, providing an optimal recipe for faster convergence and enhanced performance. 

**Abstract (ZH)**: 使用数据驱动的权重初始化方法ConsNoTrainLoRA提高LoRA微调的收敛性和最终性能 

---
# AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research 

**Title (ZH)**: AblationBench: 评估实证人工智能研究中消融自动化规划的评估工具 

**Authors**: Talor Abramovich, Gal Chechik  

**Link**: [PDF](https://arxiv.org/pdf/2507.08038)  

**Abstract**: Autonomous agents built on language models (LMs) are showing increasing popularity in many fields, including scientific research. AI co-scientists aim to support or automate parts of the research process using these agents. A key component of empirical AI research is the design of ablation experiments. To this end, we introduce AblationBench, a benchmark suite for evaluating agents on ablation planning tasks in empirical AI research. It includes two tasks: AuthorAblation, which helps authors propose ablation experiments based on a method section and contains 83 instances, and ReviewerAblation, which helps reviewers find missing ablations in a full paper and contains 350 instances. For both tasks, we develop LM-based judges that serve as an automatic evaluation framework. Our experiments with frontier LMs show that these tasks remain challenging, with the best-performing LM system identifying only 29% of the original ablations on average. Lastly, we analyze the limitations of current LMs on these tasks, and find that chain-of-thought prompting outperforms the currently existing agent-based approach. 

**Abstract (ZH)**: 基于语言模型的自主代理在多个领域显示出日益增长的 popularity，包括科学研究。AI合作科学家旨在利用这些代理支持或自动化研究过程的部分环节。经验性人工智能研究的一个关键组成部分是消融实验的设计。为此，我们引入了AblationBench，这是一个评估代理在经验性人工智能研究中的消融规划任务的基准套件。它包括两个任务：AuthorAblation，帮助作者根据方法部分提出消融实验，包含83个实例；ReviewerAblation，帮助审稿人发现完整论文中的缺失消融实验，包含350个实例。对于这两个任务，我们开发了基于语言模型的评判器，作为自动评价框架。我们的实验表明，最出色的LM系统平均仅能识别出原始消融实验的29%。最后，我们分析了当前LM在这两个任务中的局限性，并发现链式思考提示优于现有基于代理的方法。 

---
# Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis 

**Title (ZH)**: 揭示有效的图像 captioning 先 contextual 配置：外部与内部分析 

**Authors**: Li Li, Yongliang Wu, Jingze Zhu, Jiawei Peng, Jianfei Cai, Xu Yang  

**Link**: [PDF](https://arxiv.org/pdf/2507.08021)  

**Abstract**: The evolution of large models has witnessed the emergence of In-Context Learning (ICL) capabilities. In Natural Language Processing (NLP), numerous studies have demonstrated the effectiveness of ICL. Inspired by the success of Large Language Models (LLMs), researchers have developed Large Multimodal Models (LMMs) with ICL capabilities. However, explorations of demonstration configuration for multimodal ICL remain preliminary. Additionally, the controllability of In-Context Examples (ICEs) provides an efficient and cost-effective means to observe and analyze the inference characteristics of LMMs under varying inputs. This paper conducts a comprehensive external and internal investigation of multimodal in-context learning on the image captioning task. Externally, we explore demonstration configuration strategies through three dimensions: shot number, image retrieval, and caption assignment. We employ multiple metrics to systematically and thoroughly evaluate and summarize key findings. Internally, we analyze typical LMM attention characteristics and develop attention-based metrics to quantify model behaviors. We also conduct auxiliary experiments to explore the feasibility of attention-driven model acceleration and compression. We further compare performance variations between LMMs with identical model design and pretraining strategies and explain the differences from the angles of pre-training data features. Our study reveals both how ICEs configuration strategies impact model performance through external experiments and characteristic typical patterns through internal inspection, providing dual perspectives for understanding multimodal ICL in LMMs. Our method of combining external and internal analysis to investigate large models, along with our newly proposed metrics, can be applied to broader research areas. 

**Abstract (ZH)**: 大规模模型进化见证了基于上下文学习（ICL）能力的 emergence。在自然语言处理（NLP）领域，大量研究已经证明了ICL的有效性。受大型语言模型（LLMs）成功的启发，研究人员开发了具备ICL能力的大规模多模态模型（LMMs）。然而，多模态ICL的示范配置探索仍处于初级阶段。此外，In-Context Examples（ICEs）的可控性为观察和分析在不同输入下LMMs的推理特性提供了一种高效且经济的手段。本文对图像 captioning 任务中的多模态基于上下文学习进行全面的外部和内部研究。外部方面，我们通过三个维度探索示范配置策略：图的数量、图像检索和字幕分配。我们采用多种指标系统地、全面地评估和总结关键发现。内部方面，我们分析典型的大规模多模态模型的注意力特性，开发基于注意力的指标来量化模型行为。我们还进行了辅助实验，探索基于注意力的模型加速和压缩的可行性。我们进一步比较了具有相同模型设计和预训练策略的大规模多模态模型之间的性能差异，并从预训练数据特征的角度解释差异。我们的研究表明，通过外部实验 ICEs 配置策略如何影响模型性能，以及通过内部检查找到典型的模式，提供了理解大规模多模态模型中多模态ICL的双重视角。我们的外部和内部分析相结合的方法，以及新提出的指标，可以应用于更广泛的科研领域。 

---
# MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model 

**Title (ZH)**: MedicalBERT：使用预训练的BERT模型增强生物医学自然语言处理 

**Authors**: K. Sahit Reddy, N. Ragavenderan, Vasanth K., Ganesh N. Naik, Vishalakshi Prabhu, Nagaraja G. S  

**Link**: [PDF](https://arxiv.org/pdf/2507.08013)  

**Abstract**: Recent advances in natural language processing (NLP) have been driven bypretrained language models like BERT, RoBERTa, T5, and GPT. Thesemodels excel at understanding complex texts, but biomedical literature, withits domain-specific terminology, poses challenges that models likeWord2Vec and bidirectional long short-term memory (Bi-LSTM) can't fullyaddress. GPT and T5, despite capturing context, fall short in tasks needingbidirectional understanding, unlike BERT. Addressing this, we proposedMedicalBERT, a pretrained BERT model trained on a large biomedicaldataset and equipped with domain-specific vocabulary that enhances thecomprehension of biomedical terminology. MedicalBERT model is furtheroptimized and fine-tuned to address diverse tasks, including named entityrecognition, relation extraction, question answering, sentence similarity, anddocument classification. Performance metrics such as the F1-score,accuracy, and Pearson correlation are employed to showcase the efficiencyof our model in comparison to other BERT-based models such as BioBERT,SciBERT, and ClinicalBERT. MedicalBERT outperforms these models onmost of the benchmarks, and surpasses the general-purpose BERT model by5.67% on average across all the tasks evaluated respectively. This work alsounderscores the potential of leveraging pretrained BERT models for medicalNLP tasks, demonstrating the effectiveness of transfer learning techniques incapturing domain-specific information.
(PDF) MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model. Available from: this https URL [accessed Jul 06 2025]. 

**Abstract (ZH)**: MedicalBERT：利用预训练BERT模型增强 biomedical 自然语言处理 

---
# RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning 

**Title (ZH)**: RepeaTTS：通过重复微调实现特征发现 

**Authors**: Atli Sigurgeirsson, Simon King  

**Link**: [PDF](https://arxiv.org/pdf/2507.08012)  

**Abstract**: A Prompt-based Text-To-Speech model allows a user to control different aspects of speech, such as speaking rate and perceived gender, through natural language instruction. Although user-friendly, such approaches are on one hand constrained: control is limited to acoustic features exposed to the model during training, and too flexible on the other: the same inputs yields uncontrollable variation that are reflected in the corpus statistics.
We investigate a novel fine-tuning regime to address both of these issues at the same time by exploiting the uncontrollable variance of the model. Through principal component analysis of thousands of synthesised samples, we determine latent features that account for the highest proportion of the output variance and incorporate them as new labels for secondary fine-tuning. We evaluate the proposed methods on two models trained on an expressive Icelandic speech corpus, one with emotional disclosure and one without. In the case of the model without emotional disclosure, the method yields both continuous and discrete features that improve overall controllability of the model. 

**Abstract (ZH)**: 基于提示的文本转语音模型通过自然语言指令允许用户控制语音的不同方面，如发音速率和感知性别。虽然这种方法用户友好，但在控制方面仍然受限：控制仅限于模型训练期间暴露的声学特征，而在灵活性方面则不足：相同的输入导致不可控的变异，这些变异在语料库统计中显现出来。

我们研究了一种新的微调制度，同时解决这两方面的问题，通过利用模型的不可控变异。通过数千个合成样本的主成分分析，我们确定了能够解释输出变异最大比例的潜在特征，并将它们作为次要微调的新标签进行集成。我们在这两个分别基于富有表现力的冰岛语音语料库训练的模型上评估了所提出的方法，一个带有情感披露，另一个没有。在没有情感披露的模型的情况下，该方法产生了连续和离散特征，从而提高了模型的整体可控性。 

---
# Energy Management for Renewable-Colocated Artificial Intelligence Data Centers 

**Title (ZH)**: 可再生能源共址人工智能数据中心的能源管理 

**Authors**: Siying Li, Lang Tong, Timothy D. Mount  

**Link**: [PDF](https://arxiv.org/pdf/2507.08011)  

**Abstract**: We develop an energy management system (EMS) for artificial intelligence (AI) data centers with colocated renewable generation. Under a profit-maximizing framework, the EMS of renewable-colocated data center (RCDC) co-optimizes AI workload scheduling, on-site renewable utilization, and electricity market participation. Within both wholesale and retail market participation models, the economic benefit of the RCDC operation is maximized. Empirical evaluations using real-world traces of electricity prices, data center power consumption, and renewable generation demonstrate significant profit gains from renewable and AI data center colocations. 

**Abstract (ZH)**: 我们开发了一种针对共址可再生能源的 Artificial Intelligence 数据中心的能源管理系统 (EMS)。在利润最大化框架下，RCDC的EMS同时优化了AI工作负载调度、现场可再生能源利用以及电力市场参与。无论是在批发还是零售市场参与模型中，RCDC的操作经济收益都被最大化。使用实际的电力价格、数据中心电力消耗和可再生能源生成数据进行的实证评估表明，可再生能源与AI数据中心共址具有显著的经济效益。 

---
# Unraveling the Potential of Diffusion Models in Small Molecule Generation 

**Title (ZH)**: 探究扩散模型在小分子生成中的潜力 

**Authors**: Peining Zhang, Daniel Baker, Minghu Song, Jinbo Bi  

**Link**: [PDF](https://arxiv.org/pdf/2507.08005)  

**Abstract**: Generative AI presents chemists with novel ideas for drug design and facilitates the exploration of vast chemical spaces. Diffusion models (DMs), an emerging tool, have recently attracted great attention in drug R\&D. This paper comprehensively reviews the latest advancements and applications of DMs in molecular generation. It begins by introducing the theoretical principles of DMs. Subsequently, it categorizes various DM-based molecular generation methods according to their mathematical and chemical applications. The review further examines the performance of these models on benchmark datasets, with a particular focus on comparing the generation performance of existing 3D methods. Finally, it concludes by emphasizing current challenges and suggesting future research directions to fully exploit the potential of DMs in drug discovery. 

**Abstract (ZH)**: 生成式AI为化学家提供了新的药物设计思路，并促进了广泛化学空间的探索。扩散模型（DMs）作为一种新兴工具，近年来在药物研发（R&D）中引起了广泛关注。本文全面回顾了DMs在分子生成方面的最新进展和应用。首先介绍了DMs的理论原则。随后，根据其数学和化学应用对各种DM基分子生成方法进行了分类。回顾进一步分析了这些模型在基准数据集上的性能，特别关注了现有三维方法的生成性能比较。最后，本文强调了当前面临的挑战，并建议未来的研究方向，以充分挖掘DMs在药物发现中的潜力。 

---
