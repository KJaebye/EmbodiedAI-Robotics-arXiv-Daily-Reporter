# On-Demand Scenario Generation for Testing Automated Driving Systems 

**Title (ZH)**: 按需生成测试场景自动化驾驶系统 

**Authors**: Songyang Yan, Xiaodong Zhang, Kunkun Hao, haojie xin, Yonggang Luo, Jucheng Yang, Ming Fan, Chao Yang, Jun Sun, Zijiang Yang  

**Link**: [PDF](https://arxiv.org/pdf/2505.14053)  

**Abstract**: The safety and reliability of Automated Driving Systems (ADS) are paramount, necessitating rigorous testing methodologies to uncover potential failures before deployment. Traditional testing approaches often prioritize either natural scenario sampling or safety-critical scenario generation, resulting in overly simplistic or unrealistic hazardous tests. In practice, the demand for natural scenarios (e.g., when evaluating the ADS's reliability in real-world conditions), critical scenarios (e.g., when evaluating safety in critical situations), or somewhere in between (e.g., when testing the ADS in regions with less civilized drivers) varies depending on the testing objectives. To address this issue, we propose the On-demand Scenario Generation (OSG) Framework, which generates diverse scenarios with varying risk levels. Achieving the goal of OSG is challenging due to the complexity of quantifying the criticalness and naturalness stemming from intricate vehicle-environment interactions, as well as the need to maintain scenario diversity across various risk levels. OSG learns from real-world traffic datasets and employs a Risk Intensity Regulator to quantitatively control the risk level. It also leverages an improved heuristic search method to ensure scenario diversity. We evaluate OSG on the Carla simulators using various ADSs. We verify OSG's ability to generate scenarios with different risk levels and demonstrate its necessity by comparing accident types across risk levels. With the help of OSG, we are now able to systematically and objectively compare the performance of different ADSs based on different risk levels. 

**Abstract (ZH)**: 自动驾驶系统（ADS）的安全性和可靠性至关重要，需要采用严谨的测试方法在部署前发现潜在故障。传统的测试方法往往侧重于自然场景采样或安全关键场景生成，导致测试过于简单或不现实。实践中，根据测试目标的不同，对自然场景（例如，在评估ADS在实际条件下的可靠性时）、关键场景（例如，在评估极端情况下的安全性时），或处于两者之间的场景（例如，在测试并未文明驾驶区域的ADS时）的需求会有所变化。为解决这一问题，我们提出了需求驱动场景生成（OSG）框架，该框架能够生成具有不同风险级别的多样化场景。实现OSG的目标具有挑战性，因为需要量化复杂的车辆-环境交互带来的关键性和自然性，同时保持不同风险级别下的场景多样性。OSG通过学习真实世界交通数据集，并采用风险强度调节器来定量控制风险水平，同时利用改进的启发式搜索方法来确保场景多样性。我们在Carla模拟器上使用各种ADS对OSG进行了评估，验证了OSG生成不同风险级别场景的能力，并通过比较不同风险级别下的事故类型证明了其必要性。借助OSG，我们现在能够基于不同的风险级别系统地和客观地比较不同ADS的性能。 

---
# Hypothesis on the Functional Advantages of the Selection-Broadcast Cycle Structure: Global Workspace Theory and Dealing with a Real-Time World 

**Title (ZH)**: 功能选择-广播周期结构假设：全局工作空间理论与应对实时世界 

**Authors**: Junya Nakanishi, Jun Baba, Yuichiro Yoshikawa, Hiroko Kamide, Hiroshi Ishiguro  

**Link**: [PDF](https://arxiv.org/pdf/2505.13969)  

**Abstract**: This paper discusses the functional advantages of the Selection-Broadcast Cycle structure proposed by Global Workspace Theory (GWT), inspired by human consciousness, particularly focusing on its applicability to artificial intelligence and robotics in dynamic, real-time scenarios. While previous studies often examined the Selection and Broadcast processes independently, this research emphasizes their combined cyclic structure and the resulting benefits for real-time cognitive systems. Specifically, the paper identifies three primary benefits: Dynamic Thinking Adaptation, Experience-Based Adaptation, and Immediate Real-Time Adaptation. This work highlights GWT's potential as a cognitive architecture suitable for sophisticated decision-making and adaptive performance in unsupervised, dynamic environments. It suggests new directions for the development and implementation of robust, general-purpose AI and robotics systems capable of managing complex, real-world tasks. 

**Abstract (ZH)**: 全球工作空间理论中的选择-广播周期结构的功能优势及其在动态实时场景下的人工智能和机器人应用 

---
# MultiDrive: A Co-Simulation Framework Bridging 2D and 3D Driving Simulation for AV Software Validation 

**Title (ZH)**: MultiDrive: 一种连接2D和3D驾驶模拟的协同仿真框架，用于AV软件验证 

**Authors**: Marc Kaufeld, Korbinian Moller, Alessio Gambi, Paolo Arcaini, Johannes Betz  

**Link**: [PDF](https://arxiv.org/pdf/2505.13959)  

**Abstract**: Scenario-based testing using simulations is a cornerstone of Autonomous Vehicles (AVs) software validation. So far, developers needed to choose between low-fidelity 2D simulators to explore the scenario space efficiently, and high-fidelity 3D simulators to study relevant scenarios in more detail, thus reducing testing costs while mitigating the sim-to-real gap. This paper presents a novel framework that leverages multi-agent co-simulation and procedural scenario generation to support scenario-based testing across low- and high-fidelity simulators for the development of motion planning algorithms. Our framework limits the effort required to transition scenarios between simulators and automates experiment execution, trajectory analysis, and visualization. Experiments with a reference motion planner show that our framework uncovers discrepancies between the planner's intended and actual behavior, thus exposing weaknesses in planning assumptions under more realistic conditions. Our framework is available at: this https URL 

**Abstract (ZH)**: 基于场景的测试使用模拟是自主车辆（AVs）软件验证的基石。目前，开发人员需要在低保真度2D模拟器以高效探索场景空间和高保真度3D模拟器以更详细地研究相关场景之间进行选择，从而降低测试成本并减少模拟到现实的差距。本文提出了一种新的框架，利用多智能体协同模拟和生成程序化场景来支持低保真度和高保真度模拟器之间的场景基于测试，以开发运动规划算法。该框架限制了在模拟器之间过渡场景所需的努力，并自动化了实验执行、轨迹分析和可视化。参考运动规划器的实验表明，该框架揭示了规划器预期行为与实际行为之间的差异，从而在更现实的条件下暴露了规划假设的弱点。该框架可在以下链接获取：this https URL 

---
# Safety2Drive: Safety-Critical Scenario Benchmark for the Evaluation of Autonomous Driving 

**Title (ZH)**: Safety2Drive: 面向自动驾驶安全评估的安全关键场景基准 

**Authors**: Jingzheng Li, Tiancheng Wang, Xingyu Peng, Jiacheng Chen, Zhijun Chen, Bing Li, Xianglong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2505.13872)  

**Abstract**: Autonomous Driving (AD) systems demand the high levels of safety assurance. Despite significant advancements in AD demonstrated on open-source benchmarks like Longest6 and Bench2Drive, existing datasets still lack regulatory-compliant scenario libraries for closed-loop testing to comprehensively evaluate the functional safety of AD. Meanwhile, real-world AD accidents are underrepresented in current driving datasets. This scarcity leads to inadequate evaluation of AD performance, posing risks to safety validation and practical deployment. To address these challenges, we propose Safety2Drive, a safety-critical scenario library designed to evaluate AD systems. Safety2Drive offers three key contributions. (1) Safety2Drive comprehensively covers the test items required by standard regulations and contains 70 AD function test items. (2) Safety2Drive supports the safety-critical scenario generalization. It has the ability to inject safety threats such as natural environment corruptions and adversarial attacks cross camera and LiDAR sensors. (3) Safety2Drive supports multi-dimensional evaluation. In addition to the evaluation of AD systems, it also supports the evaluation of various perception tasks, such as object detection and lane detection. Safety2Drive provides a paradigm from scenario construction to validation, establishing a standardized test framework for the safe deployment of AD. 

**Abstract (ZH)**: 自主驾驶（AD）系统需要高安全性保障。尽管在如Longest6和Bench2Drive等开源基准测试中已经显示了AD的重大进展，现有的数据集在全面评估AD的功能安全性方面仍缺乏符合监管标准的闭环测试场景库。同时，当前驾驶数据集中真实的AD事故严重不足。这种不足导致对AD性能评估不足，给安全性验证和 practical 部署带来风险。为解决这些挑战，我们提出了Safety2Drive，一个用于评估AD系统的安全关键场景库。Safety2Drive 包含三项关键贡献。(1) Safety2Drive 全面覆盖了标准监管所需的所有测试项目，包含70项AD功能测试项目。(2) Safety2Drive 支持安全关键场景的泛化，能够注入安全威胁如自然环境篡改和跨摄像头与LiDAR传感器的对抗攻击。(3) Safety2Drive 支持多维度评估。除了评估AD系统之外，它还支持评估各种感知任务，如目标检测和车道检测。Safety2Drive 提供从场景构建到验证的范式，建立了一个标准化测试框架以确保AD的安全部署。 

---
# Risk-Averse Traversal of Graphs with Stochastic and Correlated Edge Costs for Safe Global Planetary Mobility 

**Title (ZH)**: 具有随机且相关边成本的图的风险规避遍历以实现安全全球行星移动 

**Authors**: Olivier Lamarre, Jonathan Kelly  

**Link**: [PDF](https://arxiv.org/pdf/2505.13674)  

**Abstract**: In robotic planetary surface exploration, strategic mobility planning is an important task that involves finding candidate long-distance routes on orbital maps and identifying segments with uncertain traversability. Then, expert human operators establish safe, adaptive traverse plans based on the actual navigation difficulties encountered in these uncertain areas. In this paper, we formalize this challenge as a new, risk-averse variant of the Canadian Traveller Problem (CTP) tailored to global planetary mobility. The objective is to find a traverse policy minimizing a conditional value-at-risk (CVaR) criterion, which is a risk measure with an intuitive interpretation. We propose a novel search algorithm that finds exact CVaR-optimal policies. Our approach leverages well-established optimal AND-OR search techniques intended for (risk-agnostic) expectation minimization and extends these methods to the risk-averse domain. We validate our approach through simulated long-distance planetary surface traverses; we employ real orbital maps of the Martian surface to construct problem instances and use terrain maps to express traversal probabilities in uncertain regions. Our results illustrate different adaptive decision-making schemes depending on the level of risk aversion. Additionally, our problem setup allows accounting for traversability correlations between similar areas of the environment. In such a case, we empirically demonstrate how information-seeking detours can mitigate risk. 

**Abstract (ZH)**: 行星表面探测中基于风险规避的机器人战略移动规划 

---
# Learning Collision Risk from Naturalistic Driving with Generalised Surrogate Safety Measures 

**Title (ZH)**: 基于自然驾驶数据学习碰撞风险的一般化代理安全性度量方法 

**Authors**: Yiru Jiao, Simeon C. Calvert, Sander van Cranenburgh, Hans van Lint  

**Link**: [PDF](https://arxiv.org/pdf/2505.13556)  

**Abstract**: Accurate and timely alerts for drivers or automated systems to unfolding collisions remains a challenge in road safety, particularly in highly interactive urban traffic. Existing approaches require labour-intensive annotation of sparse risk, struggle to consider varying interaction context, or are useful only in the scenarios they are designed for. To address these limits, this study introduces the generalised surrogate safety measure (GSSM), a new approach that learns exclusively from naturalistic driving without crash or risk labels. GSSM captures the patterns of normal driving and estimates the extent to which a traffic interaction deviates from the norm towards unsafe extreme. Utilising neural networks, normal interactions are characterised by context-conditioned distributions of multi-directional spacing between road users. In the same interaction context, a spacing closer than normal entails higher risk of potential collision. Then a context-adaptive risk score and its associated probability can be calculated based on the theory of extreme values. Any measurable factors, such as motion kinematics, weather, lighting, can serve as part of the context, allowing for diverse coverage of safety-critical interactions. Multiple public driving datasets are used to train GSSMs, which are tested with 4,875 real-world crashes and near-crashes reconstructed from the SHRP2 NDS. A vanilla GSSM using only instantaneous states achieves AUPRC of 0.9 and secures a median time advance of 2.6 seconds to prevent potential collisions. Additional data and contextual factors provide further performance gains. Across various interaction types such as rear-end, merging, and crossing, the accuracy and timeliness of GSSM consistently outperforms existing baselines. GSSM therefore establishes a scalable, context-aware, and generalisable foundation to proactively quantify collision risk in traffic interactions. 

**Abstract (ZH)**: 基于全新自然驾驶数据的泛化代理安全度量方法：交通事故风险的准确及时预警 

---
# FlowQ: Energy-Guided Flow Policies for Offline Reinforcement Learning 

**Title (ZH)**: FlowQ：基于能量引导的离线强化学习流策略 

**Authors**: Marvin Alles, Nutan Chen, Patrick van der Smagt, Botond Cseke  

**Link**: [PDF](https://arxiv.org/pdf/2505.14139)  

**Abstract**: The use of guidance to steer sampling toward desired outcomes has been widely explored within diffusion models, especially in applications such as image and trajectory generation. However, incorporating guidance during training remains relatively underexplored. In this work, we introduce energy-guided flow matching, a novel approach that enhances the training of flow models and eliminates the need for guidance at inference time. We learn a conditional velocity field corresponding to the flow policy by approximating an energy-guided probability path as a Gaussian path. Learning guided trajectories is appealing for tasks where the target distribution is defined by a combination of data and an energy function, as in reinforcement learning. Diffusion-based policies have recently attracted attention for their expressive power and ability to capture multi-modal action distributions. Typically, these policies are optimized using weighted objectives or by back-propagating gradients through actions sampled by the policy. As an alternative, we propose FlowQ, an offline reinforcement learning algorithm based on energy-guided flow matching. Our method achieves competitive performance while the policy training time is constant in the number of flow sampling steps. 

**Abstract (ZH)**: 基于能量引导的流匹配方法在训练中的应用：一种在推断时不需引导的新型增强方法 

---
# Learning to Insert for Constructive Neural Vehicle Routing Solver 

**Title (ZH)**: 学习插入以构建构造性神经车辆路径求解器 

**Authors**: Fu Luo, Xi Lin, Mengyuan Zhong, Fei Liu, Zhenkun Wang, Jianyong Sun, Qingfu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2505.13904)  

**Abstract**: Neural Combinatorial Optimisation (NCO) is a promising learning-based approach for solving Vehicle Routing Problems (VRPs) without extensive manual design. While existing constructive NCO methods typically follow an appending-based paradigm that sequentially adds unvisited nodes to partial solutions, this rigid approach often leads to suboptimal results. To overcome this limitation, we explore the idea of insertion-based paradigm and propose Learning to Construct with Insertion-based Paradigm (L2C-Insert), a novel learning-based method for constructive NCO. Unlike traditional approaches, L2C-Insert builds solutions by strategically inserting unvisited nodes at any valid position in the current partial solution, which can significantly enhance the flexibility and solution quality. The proposed framework introduces three key components: a novel model architecture for precise insertion position prediction, an efficient training scheme for model optimization, and an advanced inference technique that fully exploits the insertion paradigm's flexibility. Extensive experiments on both synthetic and real-world instances of the Travelling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that L2C-Insert consistently achieves superior performance across various problem sizes. 

**Abstract (ZH)**: 基于插入策略的学习建构神经组合优化（L2C-Insert）：一种用于车辆路线问题的新型学习方法 

---
# PseudoNeg-MAE: Self-Supervised Point Cloud Learning using Conditional Pseudo-Negative Embeddings 

**Title (ZH)**: 伪负样本MAE：基于条件伪负样本嵌入的自监督点云学习 

**Authors**: Sutharsan Mahendren, Saimunur Rahman, Piotr Koniusz, Tharindu Fernando, Sridha Sridharan, Clinton Fookes, Peyman Moghadam  

**Link**: [PDF](https://arxiv.org/pdf/2409.15832)  

**Abstract**: We propose PseudoNeg-MAE, a novel self-supervised learning framework that enhances global feature representation of point cloud masked autoencoder by making them both discriminative and sensitive to transformations. Traditional contrastive learning methods focus on achieving invariance, discarding transformation-specific information. Recent approaches incorporate transformation sensitivity by explicitly modeling relationships between original and transformed inputs. However, they report an invariant-collapse phenomenon, where the predictor degenerates into identity mappings, resulting in latent representations that have limited variation across transformations. We propose a novel loss that explicitly penalizes invariant collapse, enabling the network to capture richer transformation cues while preserving discriminative representations. PseudoNeg-MAE uses a parametric network COPE, which learns the localized displacements caused by transformations within the latent space. However, jointly training COPE with the MAE leads to undesirable trivial solutions where COPE outputs collapse to an identity. To address this, we propose a loss that uses transformation-conditioned pseudo-negatives, to penalize such trivial invariant solutions. We validate PseudoNeg-MAE on shape classification and relative pose estimation tasks, where it achieves competitive performance on the ModelNet40 and ScanObjectNN datasets under challenging evaluation protocols and demonstrates superior accuracy in estimating relative poses compared to supervised methods. 

**Abstract (ZH)**: PseudoNeg-MAE：一种增强点云掩码自编码器全局特征表示的新型自监督学习框架 

---
# SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment 

**Title (ZH)**: SAFEPATH: 在早期对齐防止链式推理中的有害 reasoning 

**Authors**: Wonje Jeung, Sangyeon Yoon, Minsuk Kahng, Albert No  

**Link**: [PDF](https://arxiv.org/pdf/2505.14667)  

**Abstract**: Large Reasoning Models (LRMs) have become powerful tools for complex problem solving, but their structured reasoning pathways can lead to unsafe outputs when exposed to harmful prompts. Existing safety alignment methods reduce harmful outputs but can degrade reasoning depth, leading to significant trade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated jailbreak attacks. To address this, we introduce SAFEPATH, a lightweight alignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at the start of their reasoning, in response to harmful prompts, while leaving the rest of the reasoning process unsupervised. Empirical results across multiple benchmarks indicate that SAFEPATH effectively reduces harmful outputs while maintaining reasoning performance. Specifically, SAFEPATH reduces harmful responses by up to 90.0% and blocks 83.3% of jailbreak attempts in the DeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than Direct Refusal and 314.1x less than SafeChain. We further introduce a zero-shot variant that requires no fine-tuning. In addition, we provide a comprehensive analysis of how existing methods in LLMs generalize, or fail, when applied to reasoning-centric models, revealing critical gaps and new directions for safer AI. 

**Abstract (ZH)**: SAFEPATH：一种减轻有害输出的轻量级对齐方法 

---
# Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study 

**Title (ZH)**: 多智能体强化学习与固定时间控制在交通信号优化中的比较：一个仿真研究 

**Authors**: Saahil Mahato  

**Link**: [PDF](https://arxiv.org/pdf/2505.14544)  

**Abstract**: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges. 

**Abstract (ZH)**: 城市交叉口的交通拥堵显著影响着出行时间、燃油消耗和排放。传统的固定时间信号控制系统往往缺乏有效管理动态交通模式的适应性。本研究探讨了多代理强化学习（MARL）在仿真环境中优化多个交叉口交通信号协调的应用。利用Pygame开发了仿真模型，模拟了具有随机生成车辆流量的相互连接的交叉口网络，以反映现实中的交通变化。实现了去中心化的MARL控制器，其中每个交通信号作为自主代理，基于局部观察和邻近代理的信息做出决策。使用平均车辆等待时间和总体通过量等指标与固定时间基线控制器进行了性能评估。MARL方法在统计上显示出显著改进，包括减少了平均等待时间和提高了通过量。这些发现表明，基于MARL的动态控制策略在提高城市交通管理效率方面具有巨大潜力。建议进一步研究以解决可扩展性和实际实施挑战。 

---
# A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version) 

**Title (ZH)**: 一种基于边条件事件模型的一般注意逻辑（扩展版本） 

**Authors**: Gaia Belardinelli, Thomas Bolander, Sebastian Watzl  

**Link**: [PDF](https://arxiv.org/pdf/2505.14539)  

**Abstract**: In this work, we present the first general logic of attention. Attention is a powerful cognitive ability that allows agents to focus on potentially complex information, such as logically structured propositions, higher-order beliefs, or what other agents pay attention to. This ability is a strength, as it helps to ignore what is irrelevant, but it can also introduce biases when some types of information or agents are systematically ignored. Existing dynamic epistemic logics for attention cannot model such complex attention scenarios, as they only model attention to atomic formulas. Additionally, such logics quickly become cumbersome, as their size grows exponentially in the number of agents and announced literals. Here, we introduce a logic that overcomes both limitations. First, we generalize edge-conditioned event models, which we show to be as expressive as standard event models yet exponentially more succinct (generalizing both standard event models and generalized arrow updates). Second, we extend attention to arbitrary formulas, allowing agents to also attend to other agents' beliefs or attention. Our work treats attention as a modality, like belief or awareness. We introduce attention principles that impose closure properties on that modality and that can be used in its axiomatization. Throughout, we illustrate our framework with examples of AI agents reasoning about human attentional biases, demonstrating how such agents can discover attentional biases. 

**Abstract (ZH)**: 本工作提出了第一个通用注意力逻辑。 

---
# BACON: A fully explainable AI model with graded logic for decision making problems 

**Title (ZH)**: BACON: 一种基于分级逻辑的可完全解释的AI决策模型 

**Authors**: Haishi Bai, Jozo Dujmovic, Jianwu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.14510)  

**Abstract**: As machine learning models and autonomous agents are increasingly deployed in high-stakes, real-world domains such as healthcare, security, finance, and robotics, the need for transparent and trustworthy explanations has become critical. To ensure end-to-end transparency of AI decisions, we need models that are not only accurate but also fully explainable and human-tunable. We introduce BACON, a novel framework for automatically training explainable AI models for decision making problems using graded logic. BACON achieves high predictive accuracy while offering full structural transparency and precise, logic-based symbolic explanations, enabling effective human-AI collaboration and expert-guided refinement. We evaluate BACON with a diverse set of scenarios: classic Boolean approximation, Iris flower classification, house purchasing decisions and breast cancer diagnosis. In each case, BACON provides high-performance models while producing compact, human-verifiable decision logic. These results demonstrate BACON's potential as a practical and principled approach for delivering crisp, trustworthy explainable AI. 

**Abstract (ZH)**: 随着机器学习模型和自主代理在高风险的实际领域如医疗、安全、金融和机器人技术中的广泛应用，对透明和可信赖的解释需求变得至关重要。为确保AI决策的端到端透明度，我们需要不仅准确、而且完全可解释且可由人类调整的模型。我们提出了BACON，一种使用分级逻辑自动训练决策制定问题解释性AI模型的新框架。BACON在保持高预测准确性的基础上，提供了完整的结构透明度和精确诊断逻辑符号解释，从而促进有效的人类-AI协作和专家引导的优化。我们通过一系列不同的场景评估了BACON：经典布尔近似、鸢尾花分类、房屋购买决策以及乳腺癌诊断。在每一个案例中，BACON都提供了高性能模型，并生成了紧凑且可由人类验证的决策逻辑。这些结果展示了BACON作为一种实际且原则性的方法，具有为用户提供清晰且可信赖的解释性AI的潜力。 

---
# SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation 

**Title (ZH)**: 范围：压缩数学推理步骤以实现高效的自动化过程标注 

**Authors**: Huimin Xu, Xin Mao, Feng-Lin Li, Xiaobao Wu, Wang Chen, Wei Zhang, Anh Tuan Luu  

**Link**: [PDF](https://arxiv.org/pdf/2505.14419)  

**Abstract**: Process Reward Models (PRMs) have demonstrated promising results in mathematical reasoning, but existing process annotation approaches, whether through human annotations or Monte Carlo simulations, remain computationally expensive. In this paper, we introduce Step COmpression for Process Estimation (SCOPE), a novel compression-based approach that significantly reduces annotation costs. We first translate natural language reasoning steps into code and normalize them through Abstract Syntax Tree, then merge equivalent steps to construct a prefix tree. Unlike simulation-based methods that waste numerous samples on estimation, SCOPE leverages a compression-based prefix tree where each root-to-leaf path serves as a training sample, reducing the complexity from $O(NMK)$ to $O(N)$. We construct a large-scale dataset containing 196K samples with only 5% of the computational resources required by previous methods. Empirical results demonstrate that PRMs trained on our dataset consistently outperform existing automated annotation approaches on both Best-of-N strategy and ProcessBench. 

**Abstract (ZH)**: 基于步骤压缩的过程估计（SCOPE）在过程奖励模型中的应用 

---
# Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning 

**Title (ZH)**: 超越首个错误：过程奖励模型在反思性数学推理中的应用 

**Authors**: Zhaohui Yang, Chenghua He, Xiaowen Shi, Linjing Li, Qiyue Yin, Shihong Deng, Daxin Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2505.14391)  

**Abstract**: Many studies focus on data annotation techniques for training effective PRMs. However, current methods encounter a significant issue when applied to long CoT reasoning processes: they tend to focus solely on the first incorrect step and all preceding steps, assuming that all subsequent steps are incorrect. These methods overlook the unique self-correction and reflection mechanisms inherent in long CoT, where correct reasoning steps may still occur after initial reasoning mistakes. To address this issue, we propose a novel data annotation method for PRMs specifically designed to score the long CoT reasoning process. Given that under the reflection pattern, correct and incorrect steps often alternate, we introduce the concepts of Error Propagation and Error Cessation, enhancing PRMs' ability to identify both effective self-correction behaviors and reasoning based on erroneous steps. Leveraging an LLM-based judger for annotation, we collect 1.7 million data samples to train a 7B PRM and evaluate it at both solution and step levels. Experimental results demonstrate that compared to existing open-source PRMs and PRMs trained on open-source datasets, our PRM achieves superior performance across various metrics, including search guidance, BoN, and F1 scores. Compared to widely used MC-based annotation methods, our annotation approach not only achieves higher data efficiency but also delivers superior performance. Detailed analysis is also conducted to demonstrate the stability and generalizability of our method. 

**Abstract (ZH)**: 一种针对长链推理过程的新型数据标注方法：增强PRMs的错误传播与终止识别能力 

---
# SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation 

**Title (ZH)**: SCAN: 基于语义文档布局分析的文本和视觉检索增强生成 

**Authors**: Yuyang Dong, Nobuhiro Ueda, Krisztián Boros, Daiki Ito, Takuya Sera, Masafumi Oyamada  

**Link**: [PDF](https://arxiv.org/pdf/2505.14381)  

**Abstract**: With the increasing adoption of Large Language Models (LLMs) and Vision-Language Models (VLMs), rich document analysis technologies for applications like Retrieval-Augmented Generation (RAG) and visual RAG are gaining significant attention. Recent research indicates that using VLMs can achieve better RAG performance, but processing rich documents still remains a challenge since a single page contains large amounts of information. In this paper, we present SCAN (\textbf{S}emanti\textbf{C} Document Layout \textbf{AN}alysis), a novel approach enhancing both textual and visual Retrieval-Augmented Generation (RAG) systems working with visually rich documents. It is a VLM-friendly approach that identifies document components with appropriate semantic granularity, balancing context preservation with processing efficiency. SCAN uses a coarse-grained semantic approach that divides documents into coherent regions covering continuous components. We trained the SCAN model by fine-tuning object detection models with sophisticated annotation datasets. Our experimental results across English and Japanese datasets demonstrate that applying SCAN improves end-to-end textual RAG performance by up to 9.0\% and visual RAG performance by up to 6.4\%, outperforming conventional approaches and even commercial document processing solutions. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）和视觉语言模型（VLMs）的广泛应用，用于检索增强生成（RAG）及其视觉扩展的应用富文本分析技术正受到广泛关注。近期研究表明，使用VLMs可以实现更好的RAG性能，但处理富文本文档仍是一项挑战，因为单页包含大量信息。本文提出SCAN（语义文档布局分析），这是一种增强文本和视觉RAG系统的创新方法，特别适用于视觉丰富的文档。SCAN是一个VLM友好的方法，能够以适当的语义粒度识别文档组件，平衡上下文保留与处理效率。SCAN采用粗粒度语义方法，将文档划分为连贯的区域，覆盖连续的组件。我们通过使用详细注释数据集微调对象检测模型来训练SCAN模型。跨英语和日语数据集的实验结果表明，使用SCAN可以分别提高端到端文本RAG性能最多9.0%和视觉RAG性能最多6.4%，超过传统方法，甚至超过商用文档处理解决方案。 

---
# Dynamic Replanning for Improved Public Transport Routing 

**Title (ZH)**: 改进公交路线规划的动态重新规划方法 

**Authors**: Abdallah Abuaisha, Bojie Shen, Daniel Harabor, Peter Stuckey, Mark Wallace  

**Link**: [PDF](https://arxiv.org/pdf/2505.14193)  

**Abstract**: Delays in public transport are common, often impacting users through prolonged travel times and missed transfers. Existing solutions for handling delays remain limited; backup plans based on historical data miss opportunities for earlier arrivals, while snapshot planning accounts for current delays but not future ones. With the growing availability of live delay data, users can adjust their journeys in real-time. However, the literature lacks a framework that fully exploits this advantage for system-scale dynamic replanning. To address this, we formalise the dynamic replanning problem in public transport routing and propose two solutions: a "pull" approach, where users manually request replanning, and a novel "push" approach, where the server proactively monitors and adjusts journeys. Our experiments show that the push approach outperforms the pull approach, achieving significant speedups. The results also reveal substantial arrival time savings enabled by dynamic replanning. 

**Abstract (ZH)**: 公共交通延误常见， Often impacting乘客通过延长的旅行时间和错过换乘。现有的延误处理解决方案仍然有限；基于历史数据的备用计划错过了 earlier到达的机会，而快照规划则考虑到当前的延误但不考虑未来的延误。随着实时延误数据的日益可用，用户可以实时调整他们的行程。然而，缺乏一个全面利用这一优势的大规模动态重新规划框架。为解决这一问题，我们正式化了公共交通路由中的动态重新规划问题，并提出了两种解决方案：一种是“拉”方法，用户手动请求重新规划，以及一种新颖的“推”方法，服务器主动监控并调整行程。我们的实验表明，推方法优于拉方法，实现了显著的速度提升。结果还表明，动态重新规划能够实现显著的到达时间节省。 

---
# Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition 

**Title (ZH)**: 多模态低秩专家混合模型用于情感分析和情绪识别 

**Authors**: Shuo Zhang, Jinsong Zhang, Zhejun Zhang, Lei Li  

**Link**: [PDF](https://arxiv.org/pdf/2505.14143)  

**Abstract**: Multi-task learning (MTL) enables the efficient transfer of extra knowledge acquired from other tasks. The high correlation between multimodal sentiment analysis (MSA) and multimodal emotion recognition (MER) supports their joint training. However, existing methods primarily employ hard parameter sharing, ignoring parameter conflicts caused by complex task correlations. In this paper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture of Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts to distinctly model common and unique task characteristics, thereby avoiding parameter conflicts. Additionally, inspired by low-rank structures in the Mixture of Experts (MoE) framework, we design low-rank expert networks to reduce parameter and computational overhead as the number of experts increases. Extensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that MMoLRE achieves state-of-the-art performance on the MSA task and competitive results on the MER task. 

**Abstract (ZH)**: 多任务学习（MTL）使从其他任务中获得的额外知识能够有效转移。多模态情感分析（MSA）与多模态情绪识别（MER）之间的高相关性支持它们的联合训练。然而，现有方法主要采用硬参数共享，忽视了由复杂任务相关性引起的参数冲突。在本文中，我们提出了一种用于MSA和MER的新型MTL方法，称为多模态低秩专家混合（MMoLRE）。MMoLRE利用共享专家和任务特定专家来分别建模共同和独特任务特性，从而避免参数冲突。此外，受Experts混合（MoE）框架中低秩结构的启发，我们设计了低秩专家网络，以减少随着专家数量增加而导致的参数和计算开销。在CMU-MOSI和CMU-MOSEI基准上的广泛实验表明，MMoLRE在MSA任务上达到了最先进的性能，并在MER任务上取得了竞争力的结果。 

---
# Memory Assignment for Finite-Memory Strategies in Adversarial Patrolling Games 

**Title (ZH)**: 有限记忆策略下的巡逻博弈中内存分配 

**Authors**: Vojtěch Kůr, Vít Musil, Vojtěch Řehák  

**Link**: [PDF](https://arxiv.org/pdf/2505.14137)  

**Abstract**: Adversarial Patrolling games form a subclass of Security games where a Defender moves between locations, guarding vulnerable targets. The main algorithmic problem is constructing a strategy for the Defender that minimizes the worst damage an Attacker can cause. We focus on the class of finite-memory (also known as regular) Defender's strategies that experimentally outperformed other competing classes. A finite-memory strategy can be seen as a positional strategy on a finite set of states. Each state consists of a pair of a location and a certain integer value--called memory. Existing algorithms improve the transitional probabilities between the states but require that the available memory size itself is assigned at each location manually. Choosing the right memory assignment is a well-known open and hard problem that hinders the usability of finite-memory strategies. We solve this issue by developing a general method that iteratively changes the memory assignment. Our algorithm can be used in connection with \emph{any} black-box strategy optimization tool. We evaluate our method on various experiments and show its robustness by solving instances of various patrolling models. 

**Abstract (ZH)**: adversarial patrolling博弈属于一类安全博弈，其中防守者在不同位置之间移动以保护易受攻击的目标。主要的算法问题是构造一个防守者策略，以最小化攻击者可能造成的最坏伤害。我们专注于一类有限记忆（也称为正规）防守者策略，这些策略在实验中表现优于其他竞争类策略。有限记忆策略可以视为在有限状态集上的一种位置策略。每个状态由一个位置和一个特定的整数值（称为记忆）组成。现有算法通过改进状态间的转移概率，但要求在每个位置手动分配可用的记忆大小。正确选择记忆分配是一个已知的开放且困难的问题，阻碍了有限记忆策略的实用性。我们通过开发一种迭代改变记忆分配的通用方法解决了这一问题。我们的算法可以与任何黑盒策略优化工具结合使用。我们在各种实验中评估了该方法，并通过解决不同巡护模型的实例来证明其稳健性。 

---
# Personalized Student Knowledge Modeling for Future Learning Resource Prediction 

**Title (ZH)**: 未来学习资源预测的个性化学生知识建模 

**Authors**: Soroush Hashemifar, Sherry Sahebi  

**Link**: [PDF](https://arxiv.org/pdf/2505.14072)  

**Abstract**: Despite advances in deep learning for education, student knowledge tracing and behavior modeling face persistent challenges: limited personalization, inadequate modeling of diverse learning activities (especially non-assessed materials), and overlooking the interplay between knowledge acquisition and behavioral patterns. Practical limitations, such as fixed-size sequence segmentation, frequently lead to the loss of contextual information vital for personalized learning. Moreover, reliance on student performance on assessed materials limits the modeling scope, excluding non-assessed interactions like lectures. To overcome these shortcomings, we propose Knowledge Modeling and Material Prediction (KMaP), a stateful multi-task approach designed for personalized and simultaneous modeling of student knowledge and behavior. KMaP employs clustering-based student profiling to create personalized student representations, improving predictions of future learning resource preferences. Extensive experiments on two real-world datasets confirm significant behavioral differences across student clusters and validate the efficacy of the KMaP model. 

**Abstract (ZH)**: 尽管深度学习在教育领域的进展显著，但学生的知识追踪和行为建模仍然面临持续的挑战：个性化能力有限、对多样化的学习活动（尤其是未评估材料）建模不足，以及忽略知识获取与行为模式之间的相互作用。实际限制，如固定大小序列的分割，往往会导致对个性化学习至关重要的上下文信息丢失。此外，依赖于学生在已评估材料上的表现限制了建模范围，排除了如讲座等非评估互动。为克服这些不足，我们提出了一种状态依赖的多任务方法——Knowledge Modeling and Material Prediction（KMaP），旨在同时实现个性化的学生知识和行为建模。KMaP 通过基于聚类的学生画像生成个性化的学生表示，从而改进对未来学习资源偏好的预测。在两个真实世界数据集上的广泛实验验证了学生集群间显著的行为差异，并证实了KMaP模型的有效性。 

---
# Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning 

**Title (ZH)**: 解耦多跨度演化网络对抗时间知识图谱推理 

**Authors**: Hao Dong, Ziyue Qiao, Zhiyuan Ning, Qi Hao, Yi Du, Pengyang Wang, Yuanchun Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2505.14020)  

**Abstract**: Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs (KGs), incorporate the temporal feature to express the transience of knowledge by describing when facts occur. TKG extrapolation aims to infer possible future facts based on known history, which has garnered significant attention in recent years. Some existing methods treat TKG as a sequence of independent subgraphs to model temporal evolution patterns, demonstrating impressive reasoning performance. However, they still have limitations: 1) In modeling subgraph semantic evolution, they usually neglect the internal structural interactions between subgraphs, which are actually crucial for encoding TKGs. 2) They overlook the potential smooth features that do not lead to semantic changes, which should be distinguished from the semantic evolution process. Therefore, we propose a novel Disentangled Multi-span Evolutionary Network (DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution strategy that captures local neighbor features while perceiving historical neighbor semantic information, thus enabling internal interactions between subgraphs during the evolution process. To maximize the capture of semantic change patterns, we design a disentangle component that adaptively separates nodes' active and stable features, used to dynamically control the influence of historical semantics on future evolution. Extensive experiments conducted on four real-world TKG datasets show that DiMNet demonstrates substantial performance in TKG reasoning, and outperforms the state-of-the-art up to 22.7% in MRR. 

**Abstract (ZH)**: 时态知识图谱（TKGs）作为静态知识图谱（KGs）的扩展，通过描述事实发生的时间来体现知识的时效性。时态知识图谱外推旨在基于已知的历史事实推断可能的未来事实，近年来引起了广泛关注。现有的一些方法将时态知识图谱视为独立子图序列以建模时间演化模式，表现出令人印象深刻的推理性能。然而，它们仍然存在局限性：1）在建模子图语义演化时，通常忽视了子图之间的内部结构交互，这是编码时态知识图谱的关键。2）忽略了可能的平滑特征，这些特征不会引发语义变化，应在语义演化过程中与之区分开。因此，我们提出了一种新颖的解耦多跨度演化网络（DiMNet）用于时态知识图谱推理。具体而言，我们设计了一种多跨度演化策略，既能捕获局部邻居特征又能感知历史邻居语义信息，在演化过程中促进子图之间的内部交互。为了最大化捕捉语义变化模式，我们设计了一个解耦组件，该组件能够自适应地分离节点的活跃和稳定特征，用于动态控制历史语义对未来演化的影响力。在四个真实世界时态知识图谱数据集上的广泛实验表明，DiMNet在时态知识图谱推理中展现出显著的性能，并在MRR指标上优于现有最佳方法多达22.7%。 

---
# VeRecycle: Reclaiming Guarantees from Probabilistic Certificates for Stochastic Dynamical Systems after Change 

**Title (ZH)**: VeRecycle: 变更后从随机证书中回收随机动力学系统保证技术 

**Authors**: Sterre Lutz, Matthijs T.J. Spaan, Anna Lukina  

**Link**: [PDF](https://arxiv.org/pdf/2505.14001)  

**Abstract**: Autonomous systems operating in the real world encounter a range of uncertainties. Probabilistic neural Lyapunov certification is a powerful approach to proving safety of nonlinear stochastic dynamical systems. When faced with changes beyond the modeled uncertainties, e.g., unidentified obstacles, probabilistic certificates must be transferred to the new system dynamics. However, even when the changes are localized in a known part of the state space, state-of-the-art requires complete re-certification, which is particularly costly for neural certificates. We introduce VeRecycle, the first framework to formally reclaim guarantees for discrete-time stochastic dynamical systems. VeRecycle efficiently reuses probabilistic certificates when the system dynamics deviate only in a given subset of states. We present a general theoretical justification and algorithmic implementation. Our experimental evaluation shows scenarios where VeRecycle both saves significant computational effort and achieves competitive probabilistic guarantees in compositional neural control. 

**Abstract (ZH)**: 自主系统在真实世界中的运行会遇到各种不确定性。概率神经李雅普诺夫认证是证明非线性随机动力学系统安全性的强大方法。在遇到超出建模不确定性范围的变化时，例如未识别的障碍物，必须将概率证书转移到新的系统动力学中。即使变化局限于已知状态空间的一部分，现有的最先进的方法仍需要完全重新认证，这对神经证书尤其昂贵。我们介绍了VeRecycle，这是第一个正式回收离散时间随机动力学系统保证的框架。VeRecycle在系统动力学仅在给定的状态子集发生变化时，能够高效地重用概率证书。我们提供了一般性的理论依据和算法实现。实验评估显示，在组合神经控制中，VeRecycle既能节省显著的计算资源，又能实现具有竞争力的概率保证。 

---
# Parallel Belief Revision via Order Aggregation 

**Title (ZH)**: 并行信念修订通过顺序聚合 

**Authors**: Jake Chandler, Richard Booth  

**Link**: [PDF](https://arxiv.org/pdf/2505.13914)  

**Abstract**: Despite efforts to better understand the constraints that operate on single-step parallel (aka "package", "multiple") revision, very little work has been carried out on how to extend the model to the iterated case. A recent paper by Delgrande & Jin outlines a range of relevant rationality postulates. While many of these are plausible, they lack an underlying unifying explanation. We draw on recent work on iterated parallel contraction to offer a general method for extending serial iterated belief revision operators to handle parallel change. This method, based on a family of order aggregators known as TeamQueue aggregators, provides a principled way to recover the independently plausible properties that can be found in the literature, without yielding the more dubious ones. 

**Abstract (ZH)**: 尽管对单步并行（亦称“包”、“多次”）修订的操作约束已有一定理解，但在扩展模型至迭代情形方面的工作仍然很少。德尔格兰德与金近期的一篇论文概述了一系列相关理性公理。尽管这些公理中的许多具有合理性，但缺乏一个基础性的统一解释。我们借鉴迭代并行收缩的最近研究成果，提出了一种一般方法，用于将串行迭代信念修订算子扩展为处理并行变化。该方法基于一类称为TeamQueue聚合器的聚合器家族，提供了一种有原则的方法来恢复文献中独立合理的属性，同时避免获得更为可疑的属性。 

---
# TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning 

**Title (ZH)**: TelePlanNet：一种高效的电信网络规划的人工智能驱动框架 

**Authors**: Zongyuan Deng, Yujie Cai, Qing Liu, Shiyao Mu, Bin Lyu, Zhen Yang  

**Link**: [PDF](https://arxiv.org/pdf/2505.13831)  

**Abstract**: The selection of base station sites is a critical challenge in 5G network planning, which requires efficient optimization of coverage, cost, user satisfaction, and practical constraints. Traditional manual methods, reliant on human expertise, suffer from inefficiencies and are limited to an unsatisfied planning-construction consistency. Existing AI tools, despite improving efficiency in certain aspects, still struggle to meet the dynamic network conditions and multi-objective needs of telecom operators' networks. To address these challenges, we propose TelePlanNet, an AI-driven framework tailored for the selection of base station sites, integrating a three-layer architecture for efficient planning and large-scale automation. By leveraging large language models (LLMs) for real-time user input processing and intent alignment with base station planning, combined with training the planning model using the improved group relative policy optimization (GRPO) reinforcement learning, the proposed TelePlanNet can effectively address multi-objective optimization, evaluates candidate sites, and delivers practical solutions. Experiments results show that the proposed TelePlanNet can improve the consistency to 78%, which is superior to the manual methods, providing telecom operators with an efficient and scalable tool that significantly advances cellular network planning. 

**Abstract (ZH)**: 基于AI的5G基站选址框架TelePlanNet：面向多目标优化的大规模自动化规划 

---
# Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments 

**Title (ZH)**: AI队友的模型卡片：高风险环境中人类-AI团队熟悉方法的比较 

**Authors**: Ryan Bowers, Richard Agbeyibor, Jack Kolb, Karen Feigh  

**Link**: [PDF](https://arxiv.org/pdf/2505.13773)  

**Abstract**: We compare three methods of familiarizing a human with an artificial intelligence (AI) teammate ("agent") prior to operation in a collaborative, fast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In a between-subjects user study (n=60), participants either read documentation about the agent, trained alongside the agent prior to the mission, or were given no familiarization. Results showed that the most valuable information about the agent included details of its decision-making algorithms and its relative strengths and weaknesses compared to the human. This information allowed the familiarization groups to form sophisticated team strategies more quickly than the control group. Documentation-based familiarization led to the fastest adoption of these strategies, but also biased participants towards risk-averse behavior that prevented high scores. Participants familiarized through direct interaction were able to infer much of the same information through observation, and were more willing to take risks and experiment with different control modes, but reported weaker understanding of the agent's internal processes. Significant differences were seen between individual participants' risk tolerance and methods of AI interaction, which should be considered when designing human-AI control interfaces. Based on our findings, we recommend a human-AI team familiarization method that combines AI documentation, structured in-situ training, and exploratory interaction. 

**Abstract (ZH)**: 我们比较了三种在协作、快节奏的 intelligence、surveillance 和 reconnaissance (ISR) 环境中让人类与人工 Intelligence (AI) 同伴（"代理"）熟悉的方法。在一项涉及 60 名参与者的组间用户研究中，参与者要么阅读关于代理的文档，要么在任务前与代理一起训练，要么没有任何熟悉过程。结果显示，关于代理最有价值的信息包括其决策算法细节及其与人类相比的优势和劣势。这些信息使熟悉组能够比对照组更快地形成复杂的团队策略。基于文档的熟悉方法导致参与者最快地采用这些策略，但也使他们倾向于风险规避行为，阻碍了高分的获得。通过直接互动熟悉代理的参与者可以通过观察推断出很多相同的信息，并且更愿意承担风险和尝试不同的控制模式，但报告了对代理内部过程的理解较弱。不同个体参与者的风险容忍度与与 AI 交互的方法之间存在显著差异，这在设计人类-AI 控制界面时应予以考虑。基于我们的发现，我们建议将 AI 文档、结构化的现场培训和探索性互动相结合的人类-AI 团队熟悉方法。 

---
# MAFA: A multi-agent framework for annotation 

**Title (ZH)**: MAFA：多代理框架进行标注 

**Authors**: Mahmood Hegazy, Aaron Rodrigues, Azzam Naeem  

**Link**: [PDF](https://arxiv.org/pdf/2505.13668)  

**Abstract**: Modern applications require accurate and efficient retrieval of information in response to user queries. Mapping user utterances to the most relevant Frequently Asked Questions (FAQs) is a crucial component of these systems. Traditional approaches often rely on a single model or technique, which may not capture the nuances of diverse user inquiries. In this paper, we introduce a multi-agent framework for FAQ annotation that combines multiple specialized agents with different approaches and a judge agent that reranks candidates to produce optimal results. Our agents utilize a structured reasoning approach inspired by Attentive Reasoning Queries (ARQs), which guides them through systematic reasoning steps using targeted, task-specific JSON queries. Our framework features a specialized few-shot example strategy, where each agent receives different few-shots, enhancing ensemble diversity and coverage of the query space. We evaluate our framework on a real-world banking dataset as well as public benchmark datasets (LCQMC and FiQA), demonstrating significant improvements over single-agent approaches across multiple metrics, including a 14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12% improvement in Mean Reciprocal Rank on our dataset, and similar gains on public benchmarks when compared with traditional single agent annotation techniques. Our framework is particularly effective at handling ambiguous queries, making it well-suited for deployment in production applications while showing strong generalization capabilities across different domains and languages. 

**Abstract (ZH)**: 现代应用程序需要对用户查询进行准确且高效的响应信息检索。将用户陈述映射到最相关的常见问题（FAQ）是这些系统的关键组成部分。传统方法通常依赖单一模型或技术，这可能无法捕捉到多样的用户询问的细微差别。在本文中，我们引入了一种基于多代理的FAQ标注框架，结合了多个专业代理和不同的方法，并通过一个评审代理重新排序候选项以生成最优结果。我们的代理利用了Attentive Reasoning Queries（ARQs）启发的结构化推理方法，利用针对性的任务特定JSON查询引导他们进行系统的推理步骤。我们的框架包含一个专门的小样本示例策略，其中每个代理接收不同的小样本，从而增强组合的多样性和查询空间的覆盖率。我们在实际银行数据集以及公开基准数据集（LCQMC和FiQA）上评估了我们的框架，结果显示在多个指标上相比单代理方法有显著改进，包括Top-1准确性提升14%，Top-5准确性提升18%，以及我们的数据集上Mean Reciprocal Rank提高12%，并在公开基准上相比传统单代理标注技术也有类似的改进。我们的框架特别适用于处理含糊查询，使其非常适合部署在生产应用程序中，同时在不同的领域和语言中展示出强大的泛化能力。 

---
# Counter-Inferential Behavior in Natural and Artificial Cognitive Systems 

**Title (ZH)**: 自然与人工认知系统中的反向推理行为 

**Authors**: Serge Dolgikh  

**Link**: [PDF](https://arxiv.org/pdf/2505.13551)  

**Abstract**: This study explores the emergence of counter-inferential behavior in natural and artificial cognitive systems, that is, patterns in which agents misattribute empirical success or suppress adaptation, leading to epistemic rigidity or maladaptive stability. We analyze archetypal scenarios in which such behavior arises: reinforcement of stability through reward imbalance, meta-cognitive attribution of success to internal superiority, and protective reframing under perceived model fragility. Rather than arising from noise or flawed design, these behaviors emerge through structured interactions between internal information models, empirical feedback, and higher-order evaluation mechanisms. Drawing on evidence from artificial systems, biological cognition, human psychology, and social dynamics, we identify counter-inferential behavior as a general cognitive vulnerability that can manifest even in otherwise well-adapted systems. The findings highlight the importance of preserving minimal adaptive activation under stable conditions and suggest design principles for cognitive architectures that can resist rigidity under informational stress. 

**Abstract (ZH)**: 这一研究探讨了自然和人工认知系统中反向推理行为的涌现，即代理将实证成功归因于内部优越性或抑制适应性，导致知识上的僵化或适应不良的稳定性。我们分析了此类行为产生的典型场景：通过奖励失衡强化稳定性、元认知将成功归因于内部优越性以及在感知到模型脆弱性时的保护性重新解释。这些行为并非源自噪声或设计缺陷，而是通过内部信息模型、实证反馈和高级评估机制之间的结构化互动而涌现。借鉴来自人工系统、生物认知、人类心理学和社会动力学的证据，我们确定反向推理行为是普遍存在的认知脆弱性，即使在适应良好的系统中也可能表现出来。研究结果强调了在稳定条件下保持最小适应激活的重要性，并提出了可以抵抗信息压力下僵化的认知架构设计原则。 

---
# A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem 

**Title (ZH)**: 基于Beam Search和Iterated Local Search的启发式算法：用于 maritime inventory routing 问题 

**Authors**: Nathalie Sanghikian, Rafael Meirelles, Rafael Martinelli, Anand Subramanian  

**Link**: [PDF](https://arxiv.org/pdf/2505.13522)  

**Abstract**: Maritime Inventory Routing Problem (MIRP) plays a crucial role in the integration of global maritime commerce levels. However, there are still no well-established methodologies capable of efficiently solving large MIRP instances or their variants due to the high complexity of the problem. The adoption of exact methods, typically based on Mixed Integer Programming (MIP), for daily operations is nearly impractical due to the CPU time required, as planning must be executed multiple times while ensuring high-quality results within acceptable time limits. Non-MIP-based heuristics are less frequently applied due to the highly constrained nature of the problem, which makes even the construction of an effective initial solution challenging. Papageorgiou et al. (2014) introduced a single-product MIRP as the foundation for MIRPLib, aiming to provide a collection of publicly available benchmark instances. However, only a few studies that propose new methodologies have been published since then. To encourage the use of MIRPLib and facilitate result comparisons, this study presents a heuristic approach that does not rely on mathematical optimization techniques to solve a deterministic, finite-horizon, single-product MIRP. The proposed heuristic combines a variation of a Beam Search algorithm with an Iterated Local Search procedure. Among the 72 instances tested, the developed methodology can improve the best-known solution for ten instances within an acceptable CPU time. 

**Abstract (ZH)**: 海上存货路由问题（MIRP）在全球海运贸易的集成中扮演着重要角色。然而，由于问题的高复杂性，尚未建立起能够有效解决大规模MIRP实例或其变体的方法学。采用基于混合整数规划（MIP）的精确方法在日常运营中几乎不可行，因为计划必须多次执行，同时在可接受的时间内保证高质量的结果。非MIP的启发式方法由于问题是高度约束的，构建有效初始解也颇具挑战。Papageorgiou等人（2014）引入了一个单一产品MIRP作为MIRPLib的基础，旨在提供一集合众可用的基准实例。然而，此后仅有少数研究提出了新的方法学。为鼓励使用MIRPLib并促进结果比较，本研究提出了一种不依赖于数学优化技术的启发式方法，用于解决确定性、有限期区、单一产品MIRP。所提出的启发式方法结合了Beam Search算法的一种变体与迭代局部搜索过程，在72个测试实例中，在可接受的计算时间范围内，可以改进十个实例的最优已知解。 

---
# ADALog: Adaptive Unsupervised Anomaly detection in Logs with Self-attention Masked Language Model 

**Title (ZH)**: ADALog：基于自注意力掩蔽语言模型的日志自适应无监督异常检测 

**Authors**: Przemek Pospieszny, Wojciech Mormul, Karolina Szyndler, Sanjeev Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2505.13496)  

**Abstract**: Modern software systems generate extensive heterogeneous log data with dynamic formats, fragmented event sequences, and varying temporal patterns, making anomaly detection both crucial and challenging. To address these complexities, we propose ADALog, an adaptive, unsupervised anomaly detection framework designed for practical applicability across diverse real-world environments. Unlike traditional methods reliant on log parsing, strict sequence dependencies, or labeled data, ADALog operates on individual unstructured logs, extracts intra-log contextual relationships, and performs adaptive thresholding on normal data. The proposed approach utilizes a transformer-based, pretrained bidirectional encoder with a masked language modeling task, fine-tuned on normal logs to capture domain-specific syntactic and semantic patterns essential for accurate anomaly detection. Anomalies are identified via token-level reconstruction probabilities, aggregated into log-level scores, with adaptive percentile-based thresholding calibrated only on normal data. This allows the model to dynamically adapt to evolving system behaviors while avoiding rigid, heuristic-based thresholds common in traditional systems. We evaluate ADALog on benchmark datasets BGL, Thunderbird, and Spirit, showing strong generalization and competitive performance compared to state-of-the-art supervised and unsupervised methods. Additional ablation studies examine the effects of masking, fine-tuning, and token positioning on model behavior and interpretability. 

**Abstract (ZH)**: 现代软件系统生成大量异构的日志数据，具有动态格式、破碎的事件序列和变化的时间模式，使得异常检测变得既重要又具有挑战性。为应对这些复杂性，我们提出了ADALog，这是一种针对多样现实环境具备实际适用性的自适应无监督异常检测框架。与传统依赖日志解析、严格序列依赖或标记数据的方法不同，ADALog 基于个体无结构日志运行，提取内部日志上下文关系，并对正常数据进行自适应阈值处理。所提出的办法利用基于Transformer的双向编码器进行预训练，并通过掩码语言建模任务进一步微调，以捕捉特定领域内的句法和语义模式，这对于准确的异常检测至关重要。通过词元级重建概率识别异常，最终将这些得分聚合为日志级别分数，并通过仅在正常数据上校准的自适应分位数阈值进行调整。这种方法使模型能够动态适应系统行为的变化，避免了传统系统中常见的僵化启发式阈值。我们在基准数据集BGL、Thunderbird 和Spirit上评估了ADALog，展示了其强大的泛化能力和与先进监督和无监督方法相当的竞争力。通过消融研究进一步探讨了掩码、微调和词元定位对模型行为和可解释性的影响。 

---
# Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer 

**Title (ZH)**: 概念图引导的知识迁移的对比跨课程知识追踪 

**Authors**: Wenkang Han, Wang Lin, Liya Hu, Zhenlong Dai, Yiyun Zhou, Mengze Li, Zemin Liu, Chang Yao, Jingyuan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2505.13489)  

**Abstract**: Knowledge tracing (KT) aims to predict learners' future performance based on historical learning interactions. However, existing KT models predominantly focus on data from a single course, limiting their ability to capture a comprehensive understanding of learners' knowledge states. In this paper, we propose TransKT, a contrastive cross-course knowledge tracing method that leverages concept graph guided knowledge transfer to model the relationships between learning behaviors across different courses, thereby enhancing knowledge state estimation. Specifically, TransKT constructs a cross-course concept graph by leveraging zero-shot Large Language Model (LLM) prompts to establish implicit links between related concepts across different courses. This graph serves as the foundation for knowledge transfer, enabling the model to integrate and enhance the semantic features of learners' interactions across courses. Furthermore, TransKT includes an LLM-to-LM pipeline for incorporating summarized semantic features, which significantly improves the performance of Graph Convolutional Networks (GCNs) used for knowledge transfer. Additionally, TransKT employs a contrastive objective that aligns single-course and cross-course knowledge states, thereby refining the model's ability to provide a more robust and accurate representation of learners' overall knowledge states. 

**Abstract (ZH)**: 跨课程知识追踪方法TransKT：基于概念图引导的知识转移 

---
# NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search 

**Title (ZH)**: NExT-Search: 重建生成式AI搜索的用户反馈生态系统 

**Authors**: Sunhao Dai, Wenjie Wang, Liang Pang, Jun Xu, See-Kiong Ng, Ji-Rong Wen, Tat-Seng Chua  

**Link**: [PDF](https://arxiv.org/pdf/2505.14680)  

**Abstract**: Generative AI search is reshaping information retrieval by offering end-to-end answers to complex queries, reducing users' reliance on manually browsing and summarizing multiple web pages. However, while this paradigm enhances convenience, it disrupts the feedback-driven improvement loop that has historically powered the evolution of traditional Web search. Web search can continuously improve their ranking models by collecting large-scale, fine-grained user feedback (e.g., clicks, dwell time) at the document level. In contrast, generative AI search operates through a much longer search pipeline, spanning query decomposition, document retrieval, and answer generation, yet typically receives only coarse-grained feedback on the final answer. This introduces a feedback loop disconnect, where user feedback for the final output cannot be effectively mapped back to specific system components, making it difficult to improve each intermediate stage and sustain the feedback loop. In this paper, we envision NExT-Search, a next-generation paradigm designed to reintroduce fine-grained, process-level feedback into generative AI search. NExT-Search integrates two complementary modes: User Debug Mode, which allows engaged users to intervene at key stages; and Shadow User Mode, where a personalized user agent simulates user preferences and provides AI-assisted feedback for less interactive users. Furthermore, we envision how these feedback signals can be leveraged through online adaptation, which refines current search outputs in real-time, and offline update, which aggregates interaction logs to periodically fine-tune query decomposition, retrieval, and generation models. By restoring human control over key stages of the generative AI search pipeline, we believe NExT-Search offers a promising direction for building feedback-rich AI search systems that can evolve continuously alongside human feedback. 

**Abstract (ZH)**: 生成型AI搜索正在通过提供端到端的答案来重塑信息检索，减少用户对手动浏览和总结多个网页的依赖。然而，虽然这种范式增强了便利性，但它打断了历史上推动传统Web搜索演化的基于反馈改进的循环。Web搜索可以通过收集大规模、细粒度的用户反馈（如点击、驻留时间）不断改进其排名模型。相比之下，生成型AI搜索涉及一个更长的搜索流程，包括查询分解、文档检索和答案生成，但通常只能在最终答案上获得粗粒度的反馈。这引入了一种反馈循环断开的情况，即用户对最终输出的反馈无法有效地映射到具体的系统组件，使得难以改进每个中间阶段并维持反馈循环。在本文中，我们设想了NExT-Search，这是一种新一代范式，旨在将细粒度的、过程级的反馈重新引入生成型AI搜索。NExT-Search整合了两种互补模式：用户调试模式，允许积极参与的用户在关键阶段进行干预；以及影子用户模式，个性化用户代理模拟用户偏好并为不太交互的用户提供AI辅助反馈。此外，我们设想这些反馈信号可通过在线适应来利用，即在实时调整当前搜索输出，以及通过离线更新来汇总交互日志以定期微调查询分解、检索和生成模型。通过恢复人在生成型AI搜索流程关键阶段的控制权，我们相信NExT-Search为构建伴随人类反馈不断演进的反馈丰富型AI搜索系统提供了有前景的方向。 

---
# Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks 

**Title (ZH)**: 可解释的AI在整合了IoT的6G无线网络中保障医疗服务中应用 

**Authors**: Navneet Kaur, Lav Gupta  

**Link**: [PDF](https://arxiv.org/pdf/2505.14659)  

**Abstract**: As healthcare systems increasingly adopt advanced wireless networks and connected devices, securing medical applications has become critical. The integration of Internet of Medical Things devices, such as robotic surgical tools, intensive care systems, and wearable monitors has enhanced patient care but introduced serious security risks. Cyberattacks on these devices can lead to life threatening consequences, including surgical errors, equipment failure, and data breaches. While the ITU IMT 2030 vision highlights 6G's transformative role in healthcare through AI and cloud integration, it also raises new security concerns. This paper explores how explainable AI techniques like SHAP, LIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve trust and transparency in 6G enabled healthcare. We support our approach with experimental analysis and highlight promising results. 

**Abstract (ZH)**: 随着医疗系统越来越多地采用先进的无线网络和连接设备，保障医疗应用的安全已成为关键问题。医疗物联网设备的整合，如机器人手术工具、重症监护系统和可穿戴监测器，虽然提高了患者护理水平，但也引入了严重的安全风险。对这些设备的网络攻击可能导致致命后果，包括手术错误、设备故障和数据泄露。尽管ITU IMT 2030愿景强调6G通过AI和云计算在医疗领域中的变革性作用，但也提出了新的安全挑战。本文探讨了可解释AI技术（如SHAP、LIME和DiCE）如何揭示漏洞、强化防御并提高6G赋能医疗领域的信任和透明度。我们通过实验分析支持我们的方法，并强调了令人鼓舞的结果。 

---
# Bellman operator convergence enhancements in reinforcement learning algorithms 

**Title (ZH)**: 贝尔曼运算子收敛性增强在强化学习算法中的应用 

**Authors**: David Krame Kadurha, Domini Jocema Leko Moutouo, Yae Ulrich Gaba  

**Link**: [PDF](https://arxiv.org/pdf/2505.14564)  

**Abstract**: This paper reviews the topological groundwork for the study of reinforcement learning (RL) by focusing on the structure of state, action, and policy spaces. We begin by recalling key mathematical concepts such as complete metric spaces, which form the foundation for expressing RL problems. By leveraging the Banach contraction principle, we illustrate how the Banach fixed-point theorem explains the convergence of RL algorithms and how Bellman operators, expressed as operators on Banach spaces, ensure this convergence. The work serves as a bridge between theoretical mathematics and practical algorithm design, offering new approaches to enhance the efficiency of RL. In particular, we investigate alternative formulations of Bellman operators and demonstrate their impact on improving convergence rates and performance in standard RL environments such as MountainCar, CartPole, and Acrobot. Our findings highlight how a deeper mathematical understanding of RL can lead to more effective algorithms for decision-making problems. 

**Abstract (ZH)**: 本文回顾了强化学习（RL）研究中的拓扑基础，重点关注状态、动作和策略空间的结构。我们首先回顾了完备度量空间等关键数学概念，这些概念构成了表达RL问题的基础。通过利用布劳切克收缩原理，我们解释了布劳切克不动点定理如何解释RL算法的收敛性，并展示了作为巴纳赫空间上算子的贝尔曼算子如何确保这一收敛性。这项工作架起了理论数学与实际算法设计之间的桥梁，提供了改进RL效率的新方法。特别地，我们探讨了贝尔曼算子的替代形式，并展示了它们如何在诸如MountainCar、CartPole和Acrobot等标准RL环境中提高收敛速度和性能。我们的研究发现突显了对RL进行更深层次的数学理解如何可能导致更有效的决策问题算法。 

---
# SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification 

**Title (ZH)**: SSPS: 自监督正样本采样以实现鲁棒的自监督说话人验证 

**Authors**: Theo Lepage, Reda Dehak  

**Link**: [PDF](https://arxiv.org/pdf/2505.14561)  

**Abstract**: Self-Supervised Learning (SSL) has led to considerable progress in Speaker Verification (SV). The standard framework uses same-utterance positive sampling and data-augmentation to generate anchor-positive pairs of the same speaker. This is a major limitation, as this strategy primarily encodes channel information from the recording condition, shared by the anchor and positive. We propose a new positive sampling technique to address this bottleneck: Self-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find an appropriate positive, i.e., of the same speaker identity but a different recording condition, in the latent space using clustering assignments and a memory queue of positive embeddings. SSPS improves SV performance for both SimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods on VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by lowering intra-speaker variance, providing comparable performance to DINO-SSPS. 

**Abstract (ZH)**: 自监督学习（SSL）在演讲者验证（SV）中取得了显著进展。标准框架通过同一句话的正样本采样和数据增强生成同发言人的锚-正样本对。这是一大局限性，因为这种策略主要编码录音条件下的信道信息，而这对锚样本和正样本是共享的。我们提出了一种新的正样本采样技术以解决这一瓶颈：自监督正样本采样（SSPS）。对于给定的锚样本，SSPS旨在在潜在空间中通过聚类分配和正样本嵌入的存储队列找到合适的正样本，即同发言人物identity但不同录音条件的样本。SSPS提高了SimCLR和DINO的SV性能，分别达到2.57%和2.53%的EER，并在VoxCeleb1-O上优于最新的SSL方法。特别是，SimCLR-SSPS通过对内发言人差异性的降低实现了58%的EER减少，提供与DINO-SSPS相当的性能。 

---
# Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting 

**Title (ZH)**: 基于物理的气象动力学学习方法及其在天气降尺度和预报中的应用 

**Authors**: Yingtao Luo, Shikai Fang, Binqing Wu, Qingsong Wen, Liang Sun  

**Link**: [PDF](https://arxiv.org/pdf/2505.14555)  

**Abstract**: Weather forecasting is essential but remains computationally intensive and physically incomplete in traditional numerical weather prediction (NWP) methods. Deep learning (DL) models offer efficiency and accuracy but often ignore physical laws, limiting interpretability and generalization. We propose PhyDL-NWP, a physics-guided deep learning framework that integrates physical equations with latent force parameterization into data-driven models. It predicts weather variables from arbitrary spatiotemporal coordinates, computes physical terms via automatic differentiation, and uses a physics-informed loss to align predictions with governing dynamics. PhyDL-NWP enables resolution-free downscaling by modeling weather as a continuous function and fine-tunes pre-trained models with minimal overhead, achieving up to 170x faster inference with only 55K parameters. Experiments show that PhyDL-NWP improves both forecasting performance and physical consistency. 

**Abstract (ZH)**: 基于物理指导的深度学习天气预报框架 

---
# Trustworthy Reputation Games and Applications to Proof-of-Reputation Blockchains 

**Title (ZH)**: 可信赖的声誉博弈及其在声誉证明区块链中的应用 

**Authors**: Petros Drineas, Rohit Nema, Rafail Ostrovsky, Vassilis Zikas  

**Link**: [PDF](https://arxiv.org/pdf/2505.14551)  

**Abstract**: Reputation systems play an essential role in the Internet era, as they enable people to decide whom to trust, by collecting and aggregating data about users' behavior. Recently, several works proposed the use of reputation for the design and scalability improvement of decentralized (blockchain) ledgers; however, such systems are prone to manipulation and to our knowledge no game-theoretic treatment exists that can support their economic robustness.
In this work we put forth a new model for the design of what we call, {\em trustworthy reputation systems}. Concretely, we describe a class of games, which we term {\em trustworthy reputation games}, that enable a set of users to report a function of their beliefs about the trustworthiness of each server in a set -- i.e., their estimate of the probability that this server will behave according to its specified strategy -- in a way that satisfies the following properties:
1. It is $(\epsilon$-)best response for any rational user in the game to play a prescribed (truthful) strategy according to their true belief.
2. Assuming that the users' beliefs are not too far from the {\em true} trustworthiness of the servers, playing the above ($\epsilon-$)Nash equilibrium allows anyone who observes the users' strategies to estimate the relative trustworthiness of any two servers.
Our utilities and decoding function build on a connection between the well known PageRank algorithm and the problem of trustworthiness discovery, which can be of independent interest. Finally, we show how the above games are motivated by and can be leveraged in proof-of-reputation (PoR) blockchains. 

**Abstract (ZH)**: 可信任的声誉系统设计模型 

---
# Exploring Graph Representations of Logical Forms for Language Modeling 

**Title (ZH)**: 探索逻辑形式的图表示用于语言 modeling 

**Authors**: Michael Sullivan  

**Link**: [PDF](https://arxiv.org/pdf/2505.14523)  

**Abstract**: We make the case for language models over logical forms (LFLMs), arguing that such models are more data-efficient than their textual counterparts. To that end, we introduce the Graph-based Formal-Logical Distributional Semantics (GFoLDS) prototype, a pretrained LM over graph representations of logical forms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong experimental evidence that LFLMs can leverage the built-in, basic linguistic knowledge inherent in such models to immediately begin learning more complex patterns. On downstream tasks, we show that GFoLDS vastly outperforms textual, transformer LMs pretrained on similar amounts of data, indicating that LFLMs can learn with substantially less data than models over plain text. Furthermore, we show that the performance of this model is likely to scale with additional parameters and pretraining data, suggesting the viability of LFLMs in real-world applications. 

**Abstract (ZH)**: 我们主张语言模型优于逻辑形式（LFLMs），认为这类模型在数据效率方面优于其文本对应模型。为此，我们介绍了基于图表示逻辑形式的预训练语言模型（GFoLDS）原型，作为LFLMs的一个概念验证。通过GFoLDS，我们展示了强有力的实验证据，表明LFLMs能够利用这些模型内置的基础语言知识，立即开始学习更复杂的模式。在下游任务上，我们展示GFoLDS在使用相似量级数据预训练的情况下，远超文本变压器LM，表明LFLMs可以通过显著较少的数据进行学习。此外，我们展示了该模型的性能可能随着参数量和预训练数据的增加而扩展，这表明LFLMs在实际应用中的可行性。 

---
# How Managers Perceive AI-Assisted Conversational Training for Workplace Communication 

**Title (ZH)**: 管理者对AI辅助对话式培训在工作场所沟通中的感知 

**Authors**: Lance T Wilhelm, Xiaohan Ding, Kirk McInnis Knutsen, Buse Carik, Eugenia H Rho  

**Link**: [PDF](https://arxiv.org/pdf/2505.14452)  

**Abstract**: Effective workplace communication is essential for managerial success, yet many managers lack access to tailored and sustained training. Although AI-assisted communication systems may offer scalable training solutions, little is known about how managers envision the role of AI in helping them improve their communication skills. To investigate this, we designed a conversational role-play system, CommCoach, as a functional probe to understand how managers anticipate using AI to practice their communication skills. Through semi-structured interviews, participants emphasized the value of adaptive, low-risk simulations for practicing difficult workplace conversations. They also highlighted opportunities, including human-AI teaming, transparent and context-aware feedback, and greater control over AI-generated personas. AI-assisted communication training should balance personalization, structured learning objectives, and adaptability to different user styles and contexts. However, achieving this requires carefully navigating tensions between adaptive and consistent AI feedback, realism and potential bias, and the open-ended nature of AI conversations versus structured workplace discourse. 

**Abstract (ZH)**: 有效的职场沟通对于管理成功至关重要，但许多管理者缺乏量身定制且持续的培训机会。尽管基于AI的沟通系统可能提供可扩展的培训解决方案，但仍不清楚管理者如何设想AI在帮助他们提升沟通技能方面的作用。为此，我们设计了一个对话式角色扮演系统CommCoach，作为一种功能性的探针，以了解管理者如何看待使用AI练习沟通技能的方式。通过半结构化的访谈，参与者强调了适应性、低风险模拟对练习困难职场对话的价值，并指出了包括人机合作、透明且情境感知的反馈以及对AI生成人物的更大控制在内的机遇。基于AI的沟通培训应平衡个性化、结构化的学习目标以及对不同类型用户风格和情境的适应性。然而，实现这一点需要仔细权衡适应性与一致的AI反馈、真实性与潜在偏见之间的矛盾，以及非结构化的人工智能对话与结构化的职场交流之间的差异。 

---
# RefiDiff: Refinement-Aware Diffusion for Efficient Missing Data Imputation 

**Title (ZH)**: RefiDiff: 重视细化的扩散方法用于高效的缺失数据插补 

**Authors**: Md Atik Ahamed, Qiang Ye, Qiang Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2505.14451)  

**Abstract**: Missing values in high-dimensional, mixed-type datasets pose significant challenges for data imputation, particularly under Missing Not At Random (MNAR) mechanisms. Existing methods struggle to integrate local and global data characteristics, limiting performance in MNAR and high-dimensional settings. We propose an innovative framework, RefiDiff, combining local machine learning predictions with a novel Mamba-based denoising network capturing interrelationships among distant features and samples. Our approach leverages pre-refinement for initial warm-up imputations and post-refinement to polish results, enhancing stability and accuracy. By encoding mixed-type data into unified tokens, RefiDiff enables robust imputation without architectural or hyperparameter tuning. RefiDiff outperforms state-of-the-art (SOTA) methods across missing-value settings, excelling in MNAR with a 4x faster training time than SOTA DDPM-based approaches. Extensive evaluations on nine real-world datasets demonstrate its robustness, scalability, and effectiveness in handling complex missingness patterns. 

**Abstract (ZH)**: 高维混合型数据集中缺失值的存在在数据插补中提出了重大挑战，尤其是在非随机缺失（MNAR）机制下。现有方法难以整合局部和全局数据特性，限制了其在MNAR和高维设置下的性能。我们提出了一种创新框架RefiDiff，结合了局部机器学习预测和一个基于新型Mamba的去噪网络，该网络捕获了远程特征和样本之间的相互关系。该方法利用预插补进行初始预热插补，并在后续进行润色以增强稳定性和准确性。通过将混合型数据编码为统一的tokens，RefiDiff能够在无需调整架构或超参数的情况下实现稳健的插补。RefiDiff在各种缺失值设置中优于现有最佳方法（SOTA），在MNAR情况下具有4倍于SOTA DDPM基方法的训练速度。在九个真实世界数据集上的广泛评估证明了其稳健性、可扩展性和在处理复杂缺失模式方面的有效性。 

---
# Interpretable Neural System Dynamics: Combining Deep Learning with System Dynamics Modeling to Support Critical Applications 

**Title (ZH)**: 可解释的神经系统动力学：将深层学习与系统动力学建模相结合以支持关键应用 

**Authors**: Riccardo D'Elia  

**Link**: [PDF](https://arxiv.org/pdf/2505.14428)  

**Abstract**: The objective of this proposal is to bridge the gap between Deep Learning (DL) and System Dynamics (SD) by developing an interpretable neural system dynamics framework. While DL excels at learning complex models and making accurate predictions, it lacks interpretability and causal reliability. Traditional SD approaches, on the other hand, provide transparency and causal insights but are limited in scalability and require extensive domain knowledge. To overcome these limitations, this project introduces a Neural System Dynamics pipeline, integrating Concept-Based Interpretability, Mechanistic Interpretability, and Causal Machine Learning. This framework combines the predictive power of DL with the interpretability of traditional SD models, resulting in both causal reliability and scalability. The efficacy of the proposed pipeline will be validated through real-world applications of the EU-funded AutoMoTIF project, which is focused on autonomous multimodal transportation systems. The long-term goal is to collect actionable insights that support the integration of explainability and safety in autonomous systems. 

**Abstract (ZH)**: 本提案的目的是通过建立可解释的神经系统动力学框架，弥合深度学习和系统动力学之间的差距。虽然深度学习在学习复杂模型和进行准确预测方面表现出色，但在可解释性和因果可靠性方面存在不足。传统的系统动力学方法提供了透明度和因果洞察，但在可扩展性方面有所限制，并且需要广泛的专业领域知识。为克服这些局限性，本项目引入了一种神经系统动力学管道，整合了基于概念的可解释性、机理可解释性和因果机器学习。该框架结合了深度学习的预测能力和传统系统动力学模型的可解释性，实现了因果可靠性和可扩展性。通过欧盟资助的AutoMoTIF项目的真实世界应用，验证所提出管道的有效性，该研究专注于自主多模态交通系统。长期目标是收集可操作的见解，以支持自主系统中解释性和安全性的整合。 

---
# When Bias Backfires: The Modulatory Role of Counterfactual Explanations on the Adoption of Algorithmic Bias in XAI-Supported Human Decision-Making 

**Title (ZH)**: 当偏差适得其反：反事实解释在XAI支持的人类决策中对算法偏差采用的调节作用 

**Authors**: Ulrike Kuhl, Annika Bush  

**Link**: [PDF](https://arxiv.org/pdf/2505.14377)  

**Abstract**: Although the integration of artificial intelligence (AI) into everyday tasks improves efficiency and objectivity, it also risks transmitting bias to human decision-making. In this study, we conducted a controlled experiment that simulated hiring decisions to examine how biased AI recommendations - augmented with or without counterfactual explanations - influence human judgment over time. Participants, acting as hiring managers, completed 60 decision trials divided into a baseline phase without AI, followed by a phase with biased (X)AI recommendations (favoring either male or female candidates), and a final post-interaction phase without AI. Our results indicate that the participants followed the AI recommendations 70% of the time when the qualifications of the given candidates were comparable. Yet, only a fraction of participants detected the gender bias (8 out of 294). Crucially, exposure to biased AI altered participants' inherent preferences: in the post-interaction phase, participants' independent decisions aligned with the bias when no counterfactual explanations were provided before, but reversed the bias when explanations were given. Reported trust did not differ significantly across conditions. Confidence varied throughout the study phases after exposure to male-biased AI, indicating nuanced effects of AI bias on decision certainty. Our findings point to the importance of calibrating XAI to avoid unintended behavioral shifts in order to safeguard equitable decision-making and prevent the adoption of algorithmic bias. 

**Abstract (ZH)**: 尽管将人工智能（AI）集成到日常任务中可以提高效率和客观性，但也存在将偏见传递给人类决策的风险。在此研究中，我们进行了一个受控实验，模拟招聘决策过程，以探究带有或不带有反事实解释的有偏见的AI建议如何随时间影响人类判断。参与者作为招聘经理，完成了60次决策试验，分为没有AI的基线阶段，有偏见（X）AI建议（偏向男性或女性候选人）的阶段，以及最后的无AI后交互阶段。结果显示，当候选人资质相似时，参与者有70%的时间采纳了AI建议。然而，只有少数参与者（8/294）检测到性别偏见。关键的是，接触有偏见的AI改变了参与者的固有偏好：在后交互阶段，未提供反事实解释时，参与者的独立决策与偏见一致，提供了解释时则逆转了偏见。报告的可信度在各条件下没有显著差异。在接触偏向男性候选人的AI后，信心程度在整个研究阶段有所不同，表明AI偏见对决策确定性的影响是复杂的。我们的研究表明，为了确保公平决策并防止算法偏见的采纳，需要调整XAI以避免无意中的行为变化。 

---
# FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation 

**Title (ZH)**: FMSD-TTS: 少量样本多说话人多方言文本到语音合成及其用于Ü--tsang、Amdo和Kham语音数据集生成 

**Authors**: Yutong Liu, Ziyue Zhang, Ban Ma-bao, Yuqing Cai, Yongbin Yu, Renzeng Duojie, Xiangxiang Wang, Fan Gao, Cheng Huang, Nyima Tashi  

**Link**: [PDF](https://arxiv.org/pdf/2505.14351)  

**Abstract**: Tibetan is a low-resource language with minimal parallel speech corpora spanning its three major dialects-Ü-Tsang, Amdo, and Kham-limiting progress in speech modeling. To address this issue, we propose FMSD-TTS, a few-shot, multi-speaker, multi-dialect text-to-speech framework that synthesizes parallel dialectal speech from limited reference audio and explicit dialect labels. Our method features a novel speaker-dialect fusion module and a Dialect-Specialized Dynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and linguistic variations across dialects while preserving speaker identity. Extensive objective and subjective evaluations demonstrate that FMSD-TTS significantly outperforms baselines in both dialectal expressiveness and speaker similarity. We further validate the quality and utility of the synthesized speech through a challenging speech-to-speech dialect conversion task. Our contributions include: (1) a novel few-shot TTS system tailored for Tibetan multi-dialect speech synthesis, (2) the public release of a large-scale synthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source evaluation toolkit for standardized assessment of speaker similarity, dialect consistency, and audio quality. 

**Abstract (ZH)**: 藏语是一种资源稀少的语言，其三种主要方言—— Ü-Tsang、Amdo 和 Kham 的平行语音语料库极少，限制了语音建模的进步。为解决这一问题，我们提出了一种少量样本、多说话人、多方言的文本到语音框架 FMSD-TTS，该框架可以从有限的参考音频和显式的方言标签中合成平行的方言语音。该方法包括一种新颖的说话人-方言融合模块和一种方言专业化动态路由网络 (DSDR-Net)，以捕捉不同方言之间的细微的声学和语言变异，同时保留说话人身份。广泛的客观和主观评估表明，FMSD-TTS 在方言表达能力和说话人相似度方面显著优于基线方法。我们还通过一项具有挑战性的语音到语音方言转换任务进一步验证了合成语音的质量和实用性。我们的贡献包括：(1) 一种针对藏语多方言语音合成的新型少量样本 TTS 系统，(2) 由 FMSD-TTS 生成的大量合成藏语语音语料库的公开发布，以及 (3) 一种开源评估工具包，用于标准化评估说话人相似度、方言一致性和音频质量。 

---
# Upgrading Democracies with Fairer Voting Methods 

**Title (ZH)**: 提升民主质量的公平投票方法 

**Authors**: Evangelos Pournaras, Srijoni Majumdar, Thomas Wellings, Joshua C. Yang, Fatemeh B. Heravan, Regula Hänggli Fricker, Dirk Helbing  

**Link**: [PDF](https://arxiv.org/pdf/2505.14349)  

**Abstract**: Voting methods are instrumental design element of democracies. Citizens use them to express and aggregate their preferences to reach a collective decision. However, voting outcomes can be as sensitive to voting rules as they are to people's voting choices. Despite the significance and inter-disciplinary scientific progress on voting methods, several democracies keep relying on outdated voting methods that do not fit modern, pluralistic societies well, while lacking social innovation. Here, we demonstrate how one can upgrade real-world democracies, namely by using alternative preferential voting methods such as cumulative voting and the method of equal shares designed for a proportional representation of voters' preferences. By rigorously assessing a new participatory budgeting approach applied in the city of Aarau, Switzerland, we unravel the striking voting outcomes of fair voting methods: more winning projects with the same budget and broader geographic and preference representation of citizens by the elected projects, in particular for voters who used to be under-represented, while promoting novel project ideas. We provide profound causal evidence showing that citizens prefer proportional voting methods, which possess strong legitimacy without the need of very technical specialized explanations. We also reveal strong underlying democratic values exhibited by citizens who support fair voting methods such as altruism and compromise. These findings come with a global momentum to unleash a new and long-awaited participation blueprint of how to upgrade democracies. 

**Abstract (ZH)**: 投票方法是民主制度的关键设计元素。公民利用它们来表达和聚合偏好以达成集体决策。然而，投票结果可能会因投票规则和选民投票选择而敏感。尽管投票方法的重要性及其多学科科学进展显著，仍有几个民主国家继续依赖不适用于现代多元社会的过时投票方法，缺乏社会创新。在这里，我们展示了如何通过使用累积投票和等额份额方法等替代偏好投票方法来提升现实世界的民主制度，从而实现更公平的投票结果：在相同的预算下更多项目获胜，并且当选项目更广泛地代表了公民的地理和偏好分布，特别是对于以往被忽视的选民群体，同时促进新颖项目理念。我们提供了严谨的因果证据表明，公民偏好公平的投票方法，这些方法具有强大的合法性，无需复杂的专门解释。我们还揭示了支持公正投票方法的公民所体现的强大民主价值观，如利他主义和妥协。这些发现推动了全球范围内的参与式蓝图，展示了如何升级民主制度。 

---
# Enhancing Classification with Semi-Supervised Deep Learning Using Distance-Based Sample Weights 

**Title (ZH)**: 基于距离权重的半监督深度学习分类增强 

**Authors**: Aydin Abedinia, Shima Tabakhi, Vahid Seydi  

**Link**: [PDF](https://arxiv.org/pdf/2505.14345)  

**Abstract**: Recent advancements in semi-supervised deep learning have introduced effective strategies for leveraging both labeled and unlabeled data to improve classification performance. This work proposes a semi-supervised framework that utilizes a distance-based weighting mechanism to prioritize critical training samples based on their proximity to test data. By focusing on the most informative examples, the method enhances model generalization and robustness, particularly in challenging scenarios with noisy or imbalanced datasets. Building on techniques such as uncertainty consistency and graph-based representations, the approach addresses key challenges of limited labeled data while maintaining scalability. Experiments on twelve benchmark datasets demonstrate significant improvements across key metrics, including accuracy, precision, and recall, consistently outperforming existing methods. This framework provides a robust and practical solution for semi-supervised learning, with potential applications in domains such as healthcare and security where data limitations pose significant challenges. 

**Abstract (ZH)**: 最近在半监督深度学习领域的进展引入了有效策略，以利用标记和未标记数据来提高分类性能。本项工作提出了一种基于距离加权的半监督框架，该框架根据样本与测试数据的接近程度优先处理关键训练样本，通过关注最具信息量的例证，该方法增强了模型的泛化能力和鲁棒性，特别是在噪声或不平衡数据集的挑战性场景中。该方法借助不确定性一致性和图表示技术，解决了有限标记数据的关键挑战，同时保持了可扩展性。实验表明，在包括准确率、精确率和召回率在内的关键指标上，该方法显著优于现有方法。该框架为半监督学习提供了稳健且实用的解决方案，具有在数据限制构成重大挑战的医疗保健和安全等领域潜在应用。 

---
# Handloom Design Generation Using Generative Networks 

**Title (ZH)**: 使用生成网络的手织设计生成 

**Authors**: Rajat Kanti Bhattacharjee, Meghali Nandi, Amrit Jha, Gunajit Kalita, Ferdous Ahmed Barbhuiya  

**Link**: [PDF](https://arxiv.org/pdf/2505.14330)  

**Abstract**: This paper proposes deep learning techniques of generating designs for clothing, focused on handloom fabric and discusses the associated challenges along with its application. The capability of generative neural network models in understanding artistic designs and synthesizing those is not yet explored well. In this work, multiple methods are employed incorporating the current state of the art generative models and style transfer algorithms to study and observe their performance for the task. The results are then evaluated through user score. This work also provides a new dataset NeuralLoom for the task of the design generation. 

**Abstract (ZH)**: 本文提出深度学习方法生成手织布服装设计，并讨论相关挑战及其应用。生成神经网络模型在理解艺术设计并合成设计方面的潜力尚未得到充分探索。本工作中，采用了当前最先进的生成模型和风格迁移算法等多种方法来研究和观察其在该任务中的表现。通过用户评分对结果进行评估。此外，本文还提供了一个新的数据集NeuralLoom以用于设计生成任务。 

---
# MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains 

**Title (ZH)**: 多表：表数据域多维度评估的综合性基准套件 

**Authors**: Kyungeun Lee, Moonjung Eo, Hye-Seung Cho, Dongmin Kim, Ye Seul Sim, Seoyoon Kim, Min-Kook Suh, Woohyung Lim  

**Link**: [PDF](https://arxiv.org/pdf/2505.14312)  

**Abstract**: Despite the widespread use of tabular data in real-world applications, most benchmarks rely on average-case metrics, which fail to reveal how model behavior varies across diverse data regimes. To address this, we propose MultiTab, a benchmark suite and evaluation framework for multi-dimensional, data-aware analysis of tabular learning algorithms. Rather than comparing models only in aggregate, MultiTab categorizes 196 publicly available datasets along key data characteristics, including sample size, label imbalance, and feature interaction, and evaluates 13 representative models spanning a range of inductive biases. Our analysis shows that model performance is highly sensitive to such regimes: for example, models using sample-level similarity excel on datasets with large sample sizes or high inter-feature correlation, while models encoding inter-feature dependencies perform best with weakly correlated features. These findings reveal that inductive biases do not always behave as intended, and that regime-aware evaluation is essential for understanding and improving model behavior. MultiTab enables more principled model design and offers practical guidance for selecting models tailored to specific data characteristics. All datasets, code, and optimization logs are publicly available at this https URL. 

**Abstract (ZH)**: 尽管表格数据在实际应用中广泛使用，大多数基准测试依赖于平均情况指标，这未能揭示模型在不同数据范围下的行为差异。为解决这一问题，我们提出了一种名为MultiTab的基准测试套件及评估框架，用于多维、数据导向的表格学习算法分析。MultiTab 不仅按样本大小、标签不平衡和特征交互等关键数据特征对196个公开数据集进行分类，还评估了13种代表性模型，涵盖了不同的归纳偏置。我们的分析表明，模型性能对这些范围高度敏感：例如，基于样本级相似性的模型在大样本大小或高特征间关联的数据集上表现优异，而编码特征间依赖性的模型在弱相关特征的数据集上表现最佳。这些发现揭示了归纳偏置并不总是按预期表现，因此针对特定数据范围的评估对于理解并改进模型行为至关重要。MultiTab 促进了更加原则化的模型设计，并提供了根据特定数据特征选择模型的实用指导。所有数据集、代码和优化日志均在该网址公开：this https URL。 

---
# Benchmarking data encoding methods in Quantum Machine Learning 

**Title (ZH)**: 量子机器学习中数据编码方法的基准测试 

**Authors**: Orlane Zang, Grégoire Barrué, Tony Quertier  

**Link**: [PDF](https://arxiv.org/pdf/2505.14295)  

**Abstract**: Data encoding plays a fundamental and distinctive role in Quantum Machine Learning (QML). While classical approaches process data directly as vectors, QML may require transforming classical data into quantum states through encoding circuits, known as quantum feature maps or quantum embeddings. This step leverages the inherently high-dimensional and non-linear nature of Hilbert space, enabling more efficient data separation in complex feature spaces that may be inaccessible to classical methods. This encoding part significantly affects the performance of the QML model, so it is important to choose the right encoding method for the dataset to be encoded. However, this choice is generally arbitrary, since there is no "universal" rule for knowing which encoding to choose based on a specific set of data. There are currently a variety of encoding methods using different quantum logic gates. We studied the most commonly used types of encoding methods and benchmarked them using different datasets. 

**Abstract (ZH)**: 量子态编码在量子机器学习（QML）中扮演着基础且独特的角色。尽管经典方法直接将数据处理为向量，QML 可能需要通过编码电路，即量子特征映射或量子嵌入，将经典数据转变为量子态。这一步骤利用了希尔伯特空间固有的高维和非线性性质，使其能够在经典方法难以访问的复杂特征空间中更高效地实现数据分离。这一编码步骤显著影响QML模型的性能，因此选择适合的数据集编码方法至关重要。然而，这种选择通常是任意的，因为没有适用于特定数据集的“通用”规则来确定选择哪种编码方法。目前存在多种采用不同量子逻辑门的编码方法。我们研究了最常用的几种编码方法，并使用不同数据集进行了基准测试。 

---
# AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis 

**Title (ZH)**: AquaSignal：一种稳健的水下声学分析综合框架 

**Authors**: Eirini Panteli, Paulo E. Santos, Nabil Humphrey  

**Link**: [PDF](https://arxiv.org/pdf/2505.14285)  

**Abstract**: This paper presents AquaSignal, a modular and scalable pipeline for preprocessing, denoising, classification, and novelty detection of underwater acoustic signals. Designed to operate effectively in noisy and dynamic marine environments, AquaSignal integrates state-of-the-art deep learning architectures to enhance the reliability and accuracy of acoustic signal analysis. The system is evaluated on a combined dataset from the Deepship and Ocean Networks Canada (ONC) benchmarks, providing a diverse set of real-world underwater scenarios. AquaSignal employs a U-Net architecture for denoising, a ResNet18 convolutional neural network for classifying known acoustic events, and an AutoEncoder-based model for unsupervised detection of novel or anomalous signals. To our knowledge, this is the first comprehensive study to apply and evaluate this combination of techniques on maritime vessel acoustic data. Experimental results show that AquaSignal improves signal clarity and task performance, achieving 71% classification accuracy and 91% accuracy in novelty detection. Despite slightly lower classification performance compared to some state-of-the-art models, differences in data partitioning strategies limit direct comparisons. Overall, AquaSignal demonstrates strong potential for real-time underwater acoustic monitoring in scientific, environmental, and maritime domains. 

**Abstract (ZH)**: AquaSignal：一种模块化可扩展的水下声信号预处理、去噪、分类和新颖性检测流水线 

---
# X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning 

**Title (ZH)**: X-KAN：通过进化基于规则的机器学习优化局部柯莫洛夫-阿诺尔德网络 

**Authors**: Hiroki Shiraishi, Hisao Ishibuchi, Masaya Nakata  

**Link**: [PDF](https://arxiv.org/pdf/2505.14273)  

**Abstract**: Function approximation is a critical task in various fields. However, existing neural network approaches struggle with locally complex or discontinuous functions due to their reliance on a single global model covering the entire problem space. We propose X-KAN, a novel method that optimizes multiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary rule-based machine learning framework called XCSF. X-KAN combines KAN's high expressiveness with XCSF's adaptive partitioning capability by implementing local KAN models as rule consequents and defining local regions via rule antecedents. Our experimental results on artificial test functions and real-world datasets demonstrate that X-KAN significantly outperforms conventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms of approximation accuracy. Notably, X-KAN effectively handles functions with locally complex or discontinuous structures that are challenging for conventional KAN, using a compact set of rules (average 7.2 $\pm$ 2.3 rules). These results validate the effectiveness of using KAN as a local model in XCSF, which evaluates the rule fitness based on both accuracy and generality. Our X-KAN implementation is available at this https URL. 

**Abstract (ZH)**: X-KAN：基于XCSF框架的多方块Kolmogorov-Arnold网络函数近似方法 

---
# Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks 

**Title (ZH)**: 过程监控中的混合自适应建模：结合序列编码器和物理知情神经网络 

**Authors**: Mouad Elaarabi, Domenico Borzacchiello, Philippe Le Bot, Nathan Lauzeral, Sebastien Comas-Cardona  

**Link**: [PDF](https://arxiv.org/pdf/2505.14252)  

**Abstract**: In this work, we explore the integration of Sequence Encoding for Online Parameter Identification with Physics-Informed Neural Networks to create a model that, once trained, can be utilized for real time applications with variable parameters, boundary conditions, and initial conditions. Recently, the combination of PINNs with Sparse Regression has emerged as a method for performing dynamical system identification through supervised learning and sparse regression optimization, while also solving the dynamics using PINNs. However, this approach can be limited by variations in parameters or boundary and initial conditions, requiring retraining of the model whenever changes occur. In this work, we introduce an architecture that employs Deep Sets or Sequence Encoders to encode dynamic parameters, boundary conditions, and initial conditions, using these encoded features as inputs for the PINN, enabling the model to adapt to changes in parameters, BCs, and ICs. We apply this approach to three different problems. First, we analyze the Rossler ODE system, demonstrating the robustness of the model with respect to noise and its ability to generalize. Next, we explore the model's capability in a 2D Navier-Stokes PDE problem involving flow past a cylinder with a parametric sinusoidal inlet velocity function, showing that the model can encode pressure data from a few points to identify the inlet velocity profile and utilize physics to compute velocity and pressure throughout the domain. Finally, we address a 1D heat monitoring problem using real data from the heating of glass fiber and thermoplastic composite plates. 

**Abstract (ZH)**: 基于序列编码的物理知情神经网络在实时参数识别中的应用研究 

---
# Fast and close Shannon entropy approximation 

**Title (ZH)**: 快速且接近的香农熵近似 

**Authors**: Illia Horenko, Davide Bassetti, Lukáš Pospíšil  

**Link**: [PDF](https://arxiv.org/pdf/2505.14234)  

**Abstract**: Shannon entropy (SE) and its quantum mechanical analogue von Neumann entropy are key components in many tools used in physics, information theory, machine learning (ML) and quantum computing. Besides of the significant amounts of SE computations required in these fields, the singularity of the SE gradient is one of the central mathematical reason inducing the high cost, frequently low robustness and slow convergence of such tools. Here we propose the Fast Entropy Approximation (FEA) - a non-singular rational approximation of Shannon entropy and its gradient that achieves a mean absolute error of $10^{-3}$, which is approximately $20$ times lower than comparable state-of-the-art methods. FEA allows around $50\%$ faster computation, requiring only $5$ to $6$ elementary computational operations, as compared to tens of elementary operations behind the fastest entropy computation algorithms with table look-ups, bitshifts, or series approximations. On a set of common benchmarks for the feature selection problem in machine learning, we show that the combined effect of fewer elementary operations, low approximation error, and a non-singular gradient allows significantly better model quality and enables ML feature extraction that is two to three orders of magnitude faster and computationally cheaper when incorporating FEA into AI tools. 

**Abstract (ZH)**: 香农熵（SE）及其量子力学类比冯诺伊曼熵是物理学、信息论、机器学习（ML）和量子计算中许多工具的关键组成部分。除了在这些领域中大量计算香农熵的需求外，香农熵梯度的奇异性是导致这些工具高昂成本、经常较低鲁棒性和缓慢收敛的主要数学原因之一。我们提出了快速熵近似（FEA）——一种非奇异的有理数约简方法，实现绝对误差为 \(10^{-3}\)，大约比目前最先进的方法低20倍。FEA 允许约50%更快的计算，只需5到6个基本计算操作，而最快速的熵计算算法则需要数十个基本操作，涉及表格查找、位移或级数近似。在机器学习中特征选择问题的一组常见基准上，我们展示了较少的基本操作、低近似误差和非奇异梯度的综合效果，使得模型质量显著提高，并且将FEA整合到AI工具中时，使ML特征提取速度提高了两到三个数量级，计算成本也大大降低。 

---
# Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned 

**Title (ZH)**: 低资源环境下联邦学习的研究：非洲胸部成像研究中的挑战与经验教训 

**Authors**: Jorge Fabila, Lidia Garrucho, Víctor M. Campello, Carlos Martín-Isla, Karim Lekadir  

**Link**: [PDF](https://arxiv.org/pdf/2505.14217)  

**Abstract**: This study explores the use of Federated Learning (FL) for tuberculosis (TB) diagnosis using chest X-rays in low-resource settings across Africa. FL allows hospitals to collaboratively train AI models without sharing raw patient data, addressing privacy concerns and data scarcity that hinder traditional centralized models. The research involved hospitals and research centers in eight African countries. Most sites used local datasets, while Ghana and The Gambia used public ones. The study compared locally trained models with a federated model built across all institutions to evaluate FL's real-world feasibility. Despite its promise, implementing FL in sub-Saharan Africa faces challenges such as poor infrastructure, unreliable internet, limited digital literacy, and weak AI regulations. Some institutions were also reluctant to share model updates due to data control concerns. In conclusion, FL shows strong potential for enabling AI-driven healthcare in underserved regions, but broader adoption will require improvements in infrastructure, education, and regulatory support. 

**Abstract (ZH)**: 本研究探索在非洲低资源地区使用联邦学习（FL）结合胸部X光进行结核病（TB）诊断的应用。FL使医院能够在不共享原始患者数据的情况下协作训练AI模型，从而解决传统集中模型中困扰的数据隐私和数据稀缺问题。该研究涉及非洲八个国家的医院和研究中心。大多数地点使用本地数据集，而加纳和冈比亚使用公开数据集。研究将本地训练的模型与跨所有机构构建的联邦模型进行比较，以评估FL在实际应用中的可行性。尽管FL具有巨大潜力，但在撒哈拉以南非洲地区实施仍面临基础设施差、互联网不稳定、数字素养有限以及AI监管不足等挑战。一些机构还因数据控制问题而对分享模型更新持保留态度。总之，FL展示了在偏远地区推动AI驱动医疗保健的强大潜力，但更广泛的应用将需要在基础设施、教育和监管支持方面进行改进。 

---
# Challenges and Limitations in the Synthetic Generation of mHealth Sensor Data 

**Title (ZH)**: 合成生成mHealth传感器数据的挑战与局限性 

**Authors**: Flavio Di Martino, Franca Delmastro  

**Link**: [PDF](https://arxiv.org/pdf/2505.14206)  

**Abstract**: The widespread adoption of mobile sensors has the potential to provide massive and heterogeneous time series data, driving Artificial Intelligence applications in mHealth. However, data collection remains limited due to stringent ethical regulations, privacy concerns, and other constraints, hindering progress in the field. Synthetic data generation, particularly through Generative Adversarial Networks and Diffusion Models, has emerged as a promising solution to address both data scarcity and privacy issues. Yet, these models are often limited to short-term, unimodal signal patterns. This paper presents a systematic evaluation of state-of-the-art generative models for time series synthesis, with a focus on their ability to jointly handle multi-modality, long-range dependencies, and conditional generation-key challenges in the mHealth domain. To ensure a fair comparison, we introduce a novel evaluation framework designed to measure both the intrinsic quality of synthetic data and its utility in downstream predictive tasks. Our findings reveal critical limitations in the existing approaches, particularly in maintaining cross-modal consistency, preserving temporal coherence, and ensuring robust performance in train-on-synthetic, test-on-real, and data augmentation scenarios. Finally, we present our future research directions to enhance synthetic time series generation and improve the applicability of generative models in mHealth. 

**Abstract (ZH)**: 广泛采用的移动传感器有可能提供庞大的异质时间序列数据，推动健康医疗领域的智能应用。然而，由于严格的伦理规范、隐私担忧和其他限制，数据收集仍然受到限制，阻碍了该领域的进展。生成式对抗网络和扩散模型等生成数据的生成方法已成为解决数据短缺和隐私问题的有前途的解决方案。尽管如此，这些模型往往仅限于处理短期的单模态信号模式。本文系统评估了当前最先进的生成模型在时间序列合成中的性能，重点在于它们在健康医疗领域处理多模态性、长距离依赖性和条件生成等关键挑战的能力。为了确保公平比较，我们引入了一个新的评估框架，用于测量合成数据的内在质量和其在下游预测任务中的实用性。我们的研究发现揭示了现有方法的关键局限性，特别是在维护跨模态一致性、保持时间连贯性以及保证在训练使用合成数据、测试使用真实数据和数据增强场景中的鲁棒性能方面。最后，我们提出了未来的研究方向，以增强时间序列生成的合成效果，并提高生成模型在健康医疗领域的适用性。 

---
# FLASH-D: FlashAttention with Hidden Softmax Division 

**Title (ZH)**: FLASH-D: FlashAttention with Hidden Softmax Division 

**Authors**: Kosmas Alexandridis, Vasileios Titopoulos, Giorgos Dimitrakopoulos  

**Link**: [PDF](https://arxiv.org/pdf/2505.14201)  

**Abstract**: The transformer's attention mechanism has revolutionized AI and machine learning, with its efficient computation being crucial to its performance. However, calculating attention involves matrix operations interspersed with softmax rescaling, which inherently slows down computation and requires processing the entire input sequence. Building on online softmax computation, FlashAttention integrates softmax calculation with matrix arithmetic, enabling tiled computation independent of sequence length. While optimized for GPUs, FlashAttention's simplicity makes it amenable to direct hardware acceleration. This work re-evaluates the core FlashAttention kernel, presenting FLASH-D a mathematically equivalent, yet simplified, formulation that achieves: (a) hiding softmax division within other non-linear function evaluations; (b) inherently numerically stable computation of exponentials, eliminating the need for maximum value subtraction; and (c) a reduction in computational cost without introducing numerical approximations to the FlashAttention kernel. Importantly, the essential FlashAttention properties that facilitate efficient tiled implementation are fully preserved. Hardware implementation results at 28nm demonstrate that this proposed formulation achieves a 22.8% reduction in area and a 20.3% reduction in power, on average, compared to state-of-the-art parallel hardware architectures without any performance penalty. 

**Abstract (ZH)**: FlashAttention的数学等价简化形式FLASH-D：保持高效分块实现的同时减少计算成本和硬件面积能耗 

---
# $α$-GAN by Rényi Cross Entropy 

**Title (ZH)**: α-GAN通过Rényi交叉熵 

**Authors**: Ni Ding, Miao Qiao, Jiaxing Xu, Yiping Ke, Xiaoyu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2505.14190)  

**Abstract**: This paper proposes $\alpha$-GAN, a generative adversarial network using Rényi measures. The value function is formulated, by Rényi cross entropy, as an expected certainty measure incurred by the discriminator's soft decision as to where the sample is from, true population or the generator. The discriminator tries to maximize the Rényi certainty about sample source, while the generator wants to reduce it by injecting fake samples. This forms a min-max problem with the solution parameterized by the Rényi order $\alpha$. This $\alpha$-GAN reduces to vanilla GAN at $\alpha = 1$, where the value function is exactly the binary cross entropy. The optimization of $\alpha$-GAN is over probability (vector) space. It is shown that the gradient is exponentially enlarged when Rényi order is in the range $\alpha \in (0,1)$. This makes convergence faster, which is verified by experimental results. A discussion shows that choosing $\alpha \in (0,1)$ may be able to solve some common problems, e.g., vanishing gradient. A following observation reveals that this range has not been fully explored in the existing Rényi version GANs. 

**Abstract (ZH)**: α-GAN：使用 Rényi 度量的生成对抗网络 

---
# Enhancing Abstractive Summarization of Scientific Papers Using Structure Information 

**Title (ZH)**: 基于结构信息增强科学论文的抽象总结 

**Authors**: Tong Bao, Heng Zhang, Chengzhi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2505.14179)  

**Abstract**: Abstractive summarization of scientific papers has always been a research focus, yet existing methods face two main challenges. First, most summarization models rely on Encoder-Decoder architectures that treat papers as sequences of words, thus fail to fully capture the structured information inherent in scientific papers. Second, existing research often use keyword mapping or feature engineering to identify the structural information, but these methods struggle with the structural flexibility of scientific papers and lack robustness across different disciplines. To address these challenges, we propose a two-stage abstractive summarization framework that leverages automatic recognition of structural functions within scientific papers. In the first stage, we standardize chapter titles from numerous scientific papers and construct a large-scale dataset for structural function recognition. A classifier is then trained to automatically identify the key structural components (e.g., Background, Methods, Results, Discussion), which provides a foundation for generating more balanced summaries. In the second stage, we employ Longformer to capture rich contextual relationships across sections and generating context-aware summaries. Experiments conducted on two domain-specific scientific paper summarization datasets demonstrate that our method outperforms advanced baselines, and generates more comprehensive summaries. The code and dataset can be accessed at this https URL. 

**Abstract (ZH)**: 科学论文的抽象总结一直是研究重点，但现有方法面临两大挑战。首先，大多数总结模型依赖于编码-解码架构，将论文视为单词序列，从而未能充分捕捉科学论文中固有的结构信息。其次，现有研究通常使用关键词映射或特征工程来识别结构性信息，但这些方法难以应对科学论文的结构性灵活性，并在不同学科间缺乏鲁棒性。为应对这些挑战，我们提出了一种两阶段抽象总结框架，利用自动识别科学论文中的结构功能。在第一阶段，我们将大量科学论文的标准章节标题进行标准化，并构建一个大规模的数据集以识别结构功能，通过训练分类器自动识别关键结构组成部分（如背景、方法、结果、讨论），为生成更均衡的摘要奠定基础。在第二阶段，我们使用Longformer捕捉各章节间的丰富上下文关系并生成上下文感知的摘要。在两个特定领域的科学论文总结数据集上进行的实验表明，我们的方法优于先进基准模型，并生成了更全面的摘要。代码和数据集可在以下链接访问。 

---
# Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging 

**Title (ZH)**: 局部专家混合模型：通过模型合并实现基本上免费的测试时训练 

**Authors**: Ryo Bertolissi, Jonas Hübotter, Ido Hakimi, Andreas Krause  

**Link**: [PDF](https://arxiv.org/pdf/2505.14136)  

**Abstract**: Mixture of expert (MoE) models are a promising approach to increasing model capacity without increasing inference cost, and are core components of many state-of-the-art language models. However, current MoE models typically use only few experts due to prohibitive training and inference cost. We propose Test-Time Model Merging (TTMM) which scales the MoE paradigm to an order of magnitude more experts and uses model merging to avoid almost any test-time overhead. We show that TTMM is an approximation of test-time training (TTT), which fine-tunes an expert model for each prediction task, i.e., prompt. TTT has recently been shown to significantly improve language models, but is computationally expensive. We find that performance of TTMM improves with more experts and approaches the performance of TTT. Moreover, we find that with a 1B parameter base model, TTMM is more than 100x faster than TTT at test-time by amortizing the cost of TTT at train-time. Thus, TTMM offers a promising cost-effective approach to scale test-time training. 

**Abstract (ZH)**: 基于测试时模型合并的专家混合模型扩展 

---
# A Methodological Framework for Measuring Spatial Labeling Similarity 

**Title (ZH)**: 空间标签相似性衡量的方法论框架 

**Authors**: Yihang Du, Jiaying Hu, Suyang Hou, Yueyang Ding, Xiaobo Sun  

**Link**: [PDF](https://arxiv.org/pdf/2505.14128)  

**Abstract**: Spatial labeling assigns labels to specific spatial locations to characterize their spatial properties and relationships, with broad applications in scientific research and practice. Measuring the similarity between two spatial labelings is essential for understanding their differences and the contributing factors, such as changes in location properties or labeling methods. An adequate and unbiased measurement of spatial labeling similarity should consider the number of matched labels (label agreement), the topology of spatial label distribution, and the heterogeneous impacts of mismatched labels. However, existing methods often fail to account for all these aspects. To address this gap, we propose a methodological framework to guide the development of methods that meet these requirements. Given two spatial labelings, the framework transforms them into graphs based on location organization, labels, and attributes (e.g., location significance). The distributions of their graph attributes are then extracted, enabling an efficient computation of distributional discrepancy to reflect the dissimilarity level between the two labelings. We further provide a concrete implementation of this framework, termed Spatial Labeling Analogy Metric (SLAM), along with an analysis of its theoretical foundation, for evaluating spatial labeling results in spatial transcriptomics (ST) \textit{as per} their similarity with ground truth labeling. Through a series of carefully designed experimental cases involving both simulated and real ST data, we demonstrate that SLAM provides a comprehensive and accurate reflection of labeling quality compared to other well-established evaluation metrics. Our code is available at this https URL. 

**Abstract (ZH)**: 空间标注将标签分配给特定的空间位置，用于表征其空间属性和关系，在科学研究和实践中具有广泛的应用。空间标注相似性的度量对于理解其差异及其影响因素（如位置属性的变化或标注方法的变化）至关重要。一种适当的、无偏的时空标注相似性度量应考虑匹配标签的数量（标签一致度）、空间标签分布的拓扑结构以及未匹配标签的异质影响。然而，现有方法往往未能涵盖所有这些方面。为解决这一问题，我们提出了一种方法学框架，以指导开发满足这些要求的方法。给定两个空间标注，该框架基于位置组织、标签和属性（如位置显著性）将它们转换为图形。然后提取这些图形属性的分布，从而通过计算分布差异来有效反映两个标注之间的不相似程度。我们进一步提供了一个具体实现该框架的方法，称为时空标注类比度量（SLAM），并对其理论基础进行了分析，以评估空间转录组学（ST）中的时空标注结果与真实标注的相似性。通过涉及模拟和真实ST数据的一系列精心设计的实验案例，我们证明了SLAM相较于其他成熟的评估指标能够提供全面而准确的标注质量反映。代码可在以下链接获取。 

---
# Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning 

**Title (ZH)**: 自上而下调制的对比 Consolidation 实现稀疏监督连续学习 

**Authors**: Viet Anh Khoa Tran, Emre Neftci, Willem. A. M. Wybo  

**Link**: [PDF](https://arxiv.org/pdf/2505.14125)  

**Abstract**: Biological brains learn continually from a stream of unlabeled data, while integrating specialized information from sparsely labeled examples without compromising their ability to generalize. Meanwhile, machine learning methods are susceptible to catastrophic forgetting in this natural learning setting, as supervised specialist fine-tuning degrades performance on the original task. We introduce task-modulated contrastive learning (TMCL), which takes inspiration from the biophysical machinery in the neocortex, using predictive coding principles to integrate top-down information continually and without supervision. We follow the idea that these principles build a view-invariant representation space, and that this can be implemented using a contrastive loss. Then, whenever labeled samples of a new class occur, new affine modulations are learned that improve separation of the new class from all others, without affecting feedforward weights. By co-opting the view-invariance learning mechanism, we then train feedforward weights to match the unmodulated representation of a data sample to its modulated counterparts. This introduces modulation invariance into the representation space, and, by also using past modulations, stabilizes it. Our experiments show improvements in both class-incremental and transfer learning over state-of-the-art unsupervised approaches, as well as over comparable supervised approaches, using as few as 1% of available labels. Taken together, our work suggests that top-down modulations play a crucial role in balancing stability and plasticity. 

**Abstract (ZH)**: 生物大脑从未标记数据流中持续学习，并从中整合稀疏标注示例的专业信息，而不损害泛化能力。同时，机器学习方法在这一自然学习环境中容易出现灾难性遗忘，因为有监督的专业微调会削弱原始任务的表现。我们引入了任务调节对比学习（TMCL），该方法受到新皮层生物物理机制的启发，利用预测编码原理持续且无监督地整合自上向下的信息。我们遵循这些原理构建了视不变表征空间的观点，并认为这可以通过对比损失来实现。每当出现新类别的标注样本时，新的仿射调节将被学习，以改善新类与所有其他类的区分，而不影响前向权重。通过利用视不变学习机制，我们训练前向权重将数据样本的未调节表示与其调节对应物匹配。这为表征空间引入了调节不变性，并通过使用过去的调节使其更加稳定。我们的实验展示了与现有无监督方法以及相近的有监督方法相比，在使用少量（仅1%）可用标签的情况下，在类别增量学习和转移学习方面的改进。我们的工作表明，自上而下的调节在平衡稳定性和可塑性方面扮演着至关重要的角色。 

---
# Collaborative Unlabeled Data Optimization 

**Title (ZH)**: 协作无标签数据优化 

**Authors**: Xinyi Shang, Peng Sun, Fengyuan Liu, Tao Lin  

**Link**: [PDF](https://arxiv.org/pdf/2505.14117)  

**Abstract**: This paper pioneers a novel data-centric paradigm to maximize the utility of unlabeled data, tackling a critical question: How can we enhance the efficiency and sustainability of deep learning training by optimizing the data itself? We begin by identifying three key limitations in existing model-centric approaches, all rooted in a shared bottleneck: knowledge extracted from data is locked to model parameters, hindering its reusability and scalability. To this end, we propose CoOpt, a highly efficient, parallelized framework for collaborative unlabeled data optimization, thereby effectively encoding knowledge into the data itself. By distributing unlabeled data and leveraging publicly available task-agnostic models, CoOpt facilitates scalable, reusable, and sustainable training pipelines. Extensive experiments across diverse datasets and architectures demonstrate its efficacy and efficiency, achieving 13.6% and 6.8% improvements on Tiny-ImageNet and ImageNet-1K, respectively, with training speedups of $1.94 \times $ and $1.2 \times$. 

**Abstract (ZH)**: 本文开创了一种以数据为中心的新范式，以最大化未标记数据的用途，探讨了一个关键问题：通过优化数据本身如何提高深度学习训练的效率和可持续性？我们首先识别了现有模型为中心方法的三个关键限制，这些限制都源于同一个瓶颈：从数据中提取的知识被锁定在模型参数中，阻碍了其重用性和可扩展性。为此，我们提出了CoOpt，这是一种高效的并行协作未标记数据优化框架，从而有效地将知识编码到数据本身中。通过分发未标记数据并利用可用的、任务无关的模型，CoOpt促进了可扩展、可重用和可持续的训练管道。跨多种数据集和架构的广泛实验显示了其有效性和效率，分别在Tiny-ImageNet和ImageNet-1K上实现了13.6%和6.8%的改进，并且训练速度分别提高了1.94倍和1.2倍。 

---
# NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI 

**Title (ZH)**: NOVA：用于脑MRI异常定位和临床推理的基准测试 

**Authors**: Cosmin I. Bercea, Jun Li, Philipp Raffler, Evamaria O. Riedel, Lena Schmitzer, Angela Kurz, Felix Bitzer, Paula Roßmüller, Julian Canisius, Mirjam L. Beyrle, Che Liu, Wenjia Bai, Bernhard Kainz, Julia A. Schnabel, Benedikt Wiestler  

**Link**: [PDF](https://arxiv.org/pdf/2505.14064)  

**Abstract**: In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Out-of-distribution detection identifies whether an input stems from an unseen distribution, while open-world recognition flags such inputs to ensure the system remains robust as ever-emerging, previously $unknown$ categories appear and must be addressed without retraining. Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging. However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.
We therefore present $NOVA$, a challenging, real-life $evaluation-only$ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an $extreme$ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space. Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops across all tasks, establishing NOVA as a rigorous testbed for advancing models that can detect, localize, and reason about truly unknown anomalies. 

**Abstract (ZH)**: NOVA：一个挑战性的实际评价基准，用于评估分布外泛化能力 

---
# Adaptive Cyclic Diffusion for Inference Scaling 

**Title (ZH)**: 自适应循环扩散推理扩展 

**Authors**: Gyubin Lee, Truong Nhat Nguyen Bao, Jaesik Yoon, Dongwoo Lee, Minsu Kim, Yoshua Bengio, Sungjin Ahn  

**Link**: [PDF](https://arxiv.org/pdf/2505.14036)  

**Abstract**: Diffusion models have demonstrated strong generative capabilities across domains ranging from image synthesis to complex reasoning tasks. However, most inference-time scaling methods rely on fixed denoising schedules, limiting their ability to allocate computation based on instance difficulty or task-specific demands adaptively. We introduce the challenge of adaptive inference-time scaling-dynamically adjusting computational effort during inference-and propose Adaptive Bi-directional Cyclic Diffusion (ABCD), a flexible, search-based inference framework. ABCD refines outputs through bi-directional diffusion cycles while adaptively controlling exploration depth and termination. It comprises three components: Cyclic Diffusion Search, Automatic Exploration-Exploitation Balancing, and Adaptive Thinking Time. Experiments show that ABCD improves performance across diverse tasks while maintaining computational efficiency. 

**Abstract (ZH)**: 自适应推理时动态调整计算努力的扩散模型：Flexible, Search-Based Inference Framework for Adaptive Inference-Time Scaling 

---
# CSAGC-IDS: A Dual-Module Deep Learning Network Intrusion Detection Model for Complex and Imbalanced Data 

**Title (ZH)**: CSAGC-IDS：一种适用于复杂和不平衡数据的双模块深度学习网络入侵检测模型 

**Authors**: Yifan Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2505.14027)  

**Abstract**: As computer networks proliferate, the gravity of network intrusions has escalated, emphasizing the criticality of network intrusion detection systems for safeguarding security. While deep learning models have exhibited promising results in intrusion detection, they face challenges in managing high-dimensional, complex traffic patterns and imbalanced data categories. This paper presents CSAGC-IDS, a network intrusion detection model based on deep learning techniques. CSAGC-IDS integrates SC-CGAN, a self-attention-enhanced convolutional conditional generative adversarial network that generates high-quality data to mitigate class imbalance. Furthermore, CSAGC-IDS integrates CSCA-CNN, a convolutional neural network enhanced through cost sensitive learning and channel attention mechanism, to extract features from complex traffic data for precise detection. Experiments conducted on the NSL-KDD dataset. CSAGC-IDS achieves an accuracy of 84.55% and an F1-score of 84.52% in five-class classification task, and an accuracy of 91.09% and an F1 score of 92.04% in binary classification this http URL, this paper provides an interpretability analysis of the proposed model, using SHAP and LIME to explain the decision-making mechanisms of the model. 

**Abstract (ZH)**: 随着计算机网络的普及，网络入侵的严重性不断增加，强调了网络入侵检测系统在保障安全方面的关键作用。尽管深度学习模型在入侵检测方面取得了Promising的结果，但它们在处理高维度、复杂流量模式以及不平衡的数据类别方面仍面临挑战。本文提出了一种基于深度学习技术的网络入侵检测模型CSAGC-IDS。CSAGC-IDS结合了增强注意力机制的SC-CGAN，生成高质量数据以缓解类别不平衡问题。此外，CSAGC-IDS还结合了CSCA-CNN，这是一种通过成本敏感学习和通道注意力机制增强的卷积神经网络，用于从复杂的流量数据中提取特征以实现精确检测。在NSL-KDD数据集上进行了实验。CSAGC-IDS在五类分类任务中实现了84.55%的准确率和84.52%的F1分数，在二类分类任务中实现了91.09%的准确率和92.04%的F1分数。本文还对该模型进行了可解释性分析，使用SHAP和LIME来解释模型的决策机制。 

---
# FedGraM: Defending Against Untargeted Attacks in Federated Learning via Embedding Gram Matrix 

**Title (ZH)**: FedGraM: 在嵌入格拉姆矩阵中抵御联邦学习中的非 targeted 攻击 

**Authors**: Di Wu, Qian Li, Heng Yang, Yong Han  

**Link**: [PDF](https://arxiv.org/pdf/2505.14024)  

**Abstract**: Federated Learning (FL) enables geographically distributed clients to collaboratively train machine learning models by sharing only their local models, ensuring data privacy. However, FL is vulnerable to untargeted attacks that aim to degrade the global model's performance on the underlying data distribution. Existing defense mechanisms attempt to improve FL's resilience against such attacks, but their effectiveness is limited in practical FL environments due to data heterogeneity. On the contrary, we aim to detect and remove the attacks to mitigate their impact. Generalization contribution plays a crucial role in distinguishing untargeted attacks. Our observations indicate that, with limited data, the divergence between embeddings representing different classes provides a better measure of generalization than direct accuracy. In light of this, we propose a novel robust aggregation method, FedGraM, designed to defend against untargeted attacks in FL. The server maintains an auxiliary dataset containing one sample per class to support aggregation. This dataset is fed to the local models to extract embeddings. Then, the server calculates the norm of the Gram Matrix of the embeddings for each local model. The norm serves as an indicator of each model's inter-class separation capability in the embedding space. FedGraM identifies and removes potentially malicious models by filtering out those with the largest norms, then averages the remaining local models to form the global model. We conduct extensive experiments to evaluate the performance of FedGraM. Our empirical results show that with limited data samples used to construct the auxiliary dataset, FedGraM achieves exceptional performance, outperforming state-of-the-art defense methods. 

**Abstract (ZH)**: 联邦学习（FL）使得地理上分布的客户端能够通过共享其本地模型来协作训练机器学习模型，从而确保数据隐私。然而，FL容易受到针对基础数据分布性能进行降级的非靶向攻击。现有的防护机制试图提高FL对抗此类攻击的能力，但在实际的FL环境中，由于数据异质性，其效果有限。相反，我们旨在检测并移除这些攻击以减轻其影响。泛化贡献在区分非靶向攻击中起着关键作用。我们的观察表明，即使在有限数据的情况下，不同类别的嵌入表示之间的差异提供了比直接准确率更好的泛化度量。基于此，我们提出了一种新的稳健聚合方法FedGraM，旨在防御FL中的非靶向攻击。服务器维护一个辅助数据集，其中包含每个类别的一个样本，以支持聚合。将该数据集提供给局部模型以提取嵌入。然后，服务器计算每个局部模型嵌入的格拉姆矩阵的范数。范数作为模型在嵌入空间中不同类别间分离能力的指标。FedGraM通过筛选掉具有最大范数的潜在恶意模型，并平均其余局部模型来形成全局模型。我们进行了广泛的实验来评估FedGraM的性能。我们的实验证明，即使使用有限的数据样本构建辅助数据集，FedGraM也表现出色，优于最先进的防护方法。 

---
# Towards Comprehensive and Prerequisite-Free Explainer for Graph Neural Networks 

**Title (ZH)**: 面向图神经网络的全面且无需先验知识的解释器 

**Authors**: Han Zhang, Yan Wang, Guanfeng Liu, Pengfei Ding, Huaxiong Wang, Kwok-Yan Lam  

**Link**: [PDF](https://arxiv.org/pdf/2505.14005)  

**Abstract**: To enhance the reliability and credibility of graph neural networks (GNNs) and improve the transparency of their decision logic, a new field of explainability of GNNs (XGNN) has emerged. However, two major limitations severely degrade the performance and hinder the generalizability of existing XGNN methods: they (a) fail to capture the complete decision logic of GNNs across diverse distributions in the entire dataset's sample space, and (b) impose strict prerequisites on edge properties and GNN internal accessibility. To address these limitations, we propose OPEN, a novel c\textbf{O}mprehensive and \textbf{P}rerequisite-free \textbf{E}xplainer for G\textbf{N}Ns. OPEN, as the first work in the literature, can infer and partition the entire dataset's sample space into multiple environments, each containing graphs that follow a distinct distribution. OPEN further learns the decision logic of GNNs across different distributions by sampling subgraphs from each environment and analyzing their predictions, thus eliminating the need for strict prerequisites. Experimental results demonstrate that OPEN captures nearly complete decision logic of GNNs, outperforms state-of-the-art methods in fidelity while maintaining similar efficiency, and enhances robustness in real-world scenarios. 

**Abstract (ZH)**: 增强图神经网络可靠性和可信度并提升其决策逻辑透明性的新解释性方法OPEN：一种无前提的全面图神经网络解释器 

---
# CAFES: A Collaborative Multi-Agent Framework for Multi-Granular Multimodal Essay Scoring 

**Title (ZH)**: CAFES：一种协作多agents框架，用于多粒度多模态作文评分 

**Authors**: Jiamin Su, Yibo Yan, Zhuoran Gao, Han Zhang, Xiang Liu, Xuming Hu  

**Link**: [PDF](https://arxiv.org/pdf/2505.13965)  

**Abstract**: Automated Essay Scoring (AES) is crucial for modern education, particularly with the increasing prevalence of multimodal assessments. However, traditional AES methods struggle with evaluation generalizability and multimodal perception, while even recent Multimodal Large Language Model (MLLM)-based approaches can produce hallucinated justifications and scores misaligned with human judgment. To address the limitations, we introduce CAFES, the first collaborative multi-agent framework specifically designed for AES. It orchestrates three specialized agents: an Initial Scorer for rapid, trait-specific evaluations; a Feedback Pool Manager to aggregate detailed, evidence-grounded strengths; and a Reflective Scorer that iteratively refines scores based on this feedback to enhance human alignment. Extensive experiments, using state-of-the-art MLLMs, achieve an average relative improvement of 21% in Quadratic Weighted Kappa (QWK) against ground truth, especially for grammatical and lexical diversity. Our proposed CAFES framework paves the way for an intelligent multimodal AES system. The code will be available upon acceptance. 

**Abstract (ZH)**: 自动化作文评分（AES）对于现代教育至关重要，特别是在多模态评估日益普遍的情况下。然而，传统的AES方法在评估通用性和多模态感知方面存在局限性，即使最新的基于多模态大型语言模型（MLLM）的方法也可能产生虚构的解释和与人类判断不一致的评分。为了解决这些限制，我们引入了CAFES，这是第一个专为AES设计的合作多智能体框架。它 orchestrates 三个专门化的智能体：初始评分器进行快速、针对特征的评估；反馈池管理器汇集详细、有证据支持的优点；以及反思评分器基于这些反馈迭代调整评分，以增强与人类的一致性。使用最先进的MLLM进行的广泛实验显示，与真实值相比，在Quadratic Weighted Kappa (QWK)方面的平均相对改进率为21%，尤其是在语法和词汇多样性方面。我们提出的CAFES框架为智能化多模态AES系统铺平了道路。代码将在接受后提供。 

---
# CLEVER: A Curated Benchmark for Formally Verified Code Generation 

**Title (ZH)**: CLEVER: 一个正式验证代码生成的精选基准 

**Authors**: Amitayush Thakur, Jasper Lee, George Tsoukalas, Meghana Sistla, Matthew Zhao, Stefan Zetzche, Greg Durrett, Yisong Yue, Swarat Chaudhuri  

**Link**: [PDF](https://arxiv.org/pdf/2505.13938)  

**Abstract**: We introduce ${\rm C{\small LEVER}}$, a high-quality, curated benchmark of 161 problems for end-to-end verified code generation in Lean. Each problem consists of (1) the task of generating a specification that matches a held-out ground-truth specification, and (2) the task of generating a Lean implementation that provably satisfies this specification. Unlike prior benchmarks, ${\rm C{\small LEVER}}$ avoids test-case supervision, LLM-generated annotations, and specifications that leak implementation logic or allow vacuous solutions. All outputs are verified post-hoc using Lean's type checker to ensure machine-checkable correctness. We use ${\rm C{\small LEVER}}$ to evaluate several few-shot and agentic approaches based on state-of-the-art language models. These methods all struggle to achieve full verification, establishing it as a challenging frontier benchmark for program synthesis and formal reasoning. Our benchmark can be found on GitHub(this https URL) as well as HuggingFace(this https URL). All our evaluation code is also available online(this https URL). 

**Abstract (ZH)**: 我们介绍${\rm C{\small LEVER}}$，这是一个高质量的手动编排基准，包含161个问题，用于Lean中的端到端验证代码生成。每个问题包括（1）生成一个与保留的真实规格相匹配的规范的任务，以及（2）生成一个Lean实现的任务，该实现可以证明满足此规范。与先前的基准不同，${\rm C{\small LEVER}}$避免了测试用例的监督、由LLM生成的注释、泄露实现逻辑的规范或允许空解的规范。所有输出都使用Lean的类型检查器进行事后验证，以确保机器可验证的正确性。我们使用${\rm C{\small LEVER}}$来评估几种基于先进语言模型的少样本和自主方法。这些方法在完全验证方面都表现不佳，将其确立为程序合成和形式推理领域的具有挑战性的前沿基准。我们的基准可以在GitHub（这个 https URL）和HuggingFace（这个 https URL）上找到。我们所有的评估代码也在网上公开（这个 https URL）。 

---
# Bronchovascular Tree-Guided Weakly Supervised Learning Method for Pulmonary Segment Segmentation 

**Title (ZH)**: 支气管血管树引导的弱监督学习方法用于肺段分割 

**Authors**: Ruijie Zhao, Zuopeng Tan, Xiao Xue, Longfei Zhao, Bing Li, Zicheng Liao, Ying Ming, Jiaru Wang, Ran Xiao, Sirong Piao, Rui Zhao, Qiqi Xu, Wei Song  

**Link**: [PDF](https://arxiv.org/pdf/2505.13911)  

**Abstract**: Pulmonary segment segmentation is crucial for cancer localization and surgical planning. However, the pixel-wise annotation of pulmonary segments is laborious, as the boundaries between segments are indistinguishable in medical images. To this end, we propose a weakly supervised learning (WSL) method, termed Anatomy-Hierarchy Supervised Learning (AHSL), which consults the precise clinical anatomical definition of pulmonary segments to perform pulmonary segment segmentation. Since pulmonary segments reside within the lobes and are determined by the bronchovascular tree, i.e., artery, airway and vein, the design of the loss function is founded on two principles. First, segment-level labels are utilized to directly supervise the output of the pulmonary segments, ensuring that they accurately encompass the appropriate bronchovascular tree. Second, lobe-level supervision indirectly oversees the pulmonary segment, ensuring their inclusion within the corresponding lobe. Besides, we introduce a two-stage segmentation strategy that incorporates bronchovascular priori information. Furthermore, a consistency loss is proposed to enhance the smoothness of segment boundaries, along with an evaluation metric designed to measure the smoothness of pulmonary segment boundaries. Visual inspection and evaluation metrics from experiments conducted on a private dataset demonstrate the effectiveness of our method. 

**Abstract (ZH)**: 肺段分割对于癌症定位和手术规划至关重要。然而，医学图像中肺段边界难以区分，像素级标注肺段耗时费力。为此，我们提出了一种弱监督学习（WSL）方法，称为解剖层级监督学习（AHSL），该方法依据精确的临床解剖定义进行肺段分割。由于肺段位于肺叶内部，并由支气管血管树决定，即动脉、气道和静脉，损失函数的设计基于两个原则。首先，使用肺段级标签直接监督肺段输出，确保其准确包含适当的支气管血管树。其次，使用肺叶级监督间接监督肺段，确保其包含在对应的肺叶内部。此外，我们引入了一种结合支气管血管先验信息的两阶段分割策略，并提出了一致性损失以增强分割边界平滑性，同时设计了评估指标以测量肺段边界平滑性。实验结果和视觉检验表明了该方法的有效性。 

---
# Utilizing Strategic Pre-training to Reduce Overfitting: Baguan -- A Pre-trained Weather Forecasting Model 

**Title (ZH)**: 利用策略性预训练减少过拟合：Baguan —— 一个预训练天气预报模型 

**Authors**: Peisong Niu, Ziqing Ma, Tian Zhou, Weiqi Chen, Lefei Shen, Rong Jin, Liang Sun  

**Link**: [PDF](https://arxiv.org/pdf/2505.13873)  

**Abstract**: Weather forecasting has long posed a significant challenge for humanity. While recent AI-based models have surpassed traditional numerical weather prediction (NWP) methods in global forecasting tasks, overfitting remains a critical issue due to the limited availability of real-world weather data spanning only a few decades. Unlike fields like computer vision or natural language processing, where data abundance can mitigate overfitting, weather forecasting demands innovative strategies to address this challenge with existing data. In this paper, we explore pre-training methods for weather forecasting, finding that selecting an appropriately challenging pre-training task introduces locality bias, effectively mitigating overfitting and enhancing performance. We introduce Baguan, a novel data-driven model for medium-range weather forecasting, built on a Siamese Autoencoder pre-trained in a self-supervised manner and fine-tuned for different lead times. Experimental results show that Baguan outperforms traditional methods, delivering more accurate forecasts. Additionally, the pre-trained Baguan demonstrates robust overfitting control and excels in downstream tasks, such as subseasonal-to-seasonal (S2S) modeling and regional forecasting, after fine-tuning. 

**Abstract (ZH)**: weather forecasting的长期挑战一直是人类面临的重要问题。尽管近年来基于AI的模型在全局预报任务中超越了传统的数值天气预报（NWP）方法，但由于可用于训练的实际天气数据仅跨越了几十年的时间，过拟合仍然是一个关键问题。与计算机视觉或自然语言处理等数据丰富的领域不同，天气预报需要创新的方法来利用现有数据解决过拟合问题。在本文中，我们探索了天气预报的预训练方法，发现选择一个合适挑战性的预训练任务引入了局部偏差，有效缓解了过拟合并提高了性能。我们提出了Baguan，这是一种基于自监督预训练的双胞胎自编码器的新型数据驱动的中短期天气预报模型，并针对不同的预测时间进行了微调。实验结果表明，Baguan 在准确度上优于传统方法，并且预训练的Baguan在下游任务如次季节至季节（S2S）建模和区域预报中表现出稳健的过拟合控制能力和优越性。 

---
# Forensic deepfake audio detection using segmental speech features 

**Title (ZH)**: 使用段落语音特征进行法医深度假音频检测 

**Authors**: Tianle Yang, Chengzhe Sun, Siwei Lyu, Phil Rose  

**Link**: [PDF](https://arxiv.org/pdf/2505.13847)  

**Abstract**: This study explores the potential of using acoustic features of segmental speech sounds to detect deepfake audio. These features are highly interpretable because of their close relationship with human articulatory processes and are expected to be more difficult for deepfake models to replicate. The results demonstrate that certain segmental features commonly used in forensic voice comparison are effective in identifying deep-fakes, whereas some global features provide little value. These findings underscore the need to approach audio deepfake detection differently for forensic voice comparison and offer a new perspective on leveraging segmental features for this purpose. 

**Abstract (ZH)**: 本研究探讨了使用段落语音声学特征检测深度伪造音频的潜力。这些特征由于与人类发音过程的密切关系而具有高度可解释性，并且预计更难以被深度伪造模型复制。研究结果表明，常用于法医语音比较的某些段落特征在识别深度伪造方面是有效的，而一些全局特征则提供little价值。这些发现强调了在法医语音比较中需采用不同的音频深度伪造检测方法，并从利用段落特征的角度提供了新的视角。 

---
# Articulatory Feature Prediction from Surface EMG during Speech Production 

**Title (ZH)**: 从说话生产过程中表面肌电预测发音特征 

**Authors**: Jihwan Lee, Kevin Huang, Kleanthis Avramidis, Simon Pistrosch, Monica Gonzalez-Machorro, Yoonjeong Lee, Björn Schuller, Louis Goldstein, Shrikanth Narayanan  

**Link**: [PDF](https://arxiv.org/pdf/2505.13814)  

**Abstract**: We present a model for predicting articulatory features from surface electromyography (EMG) signals during speech production. The proposed model integrates convolutional layers and a Transformer block, followed by separate predictors for articulatory features. Our approach achieves a high prediction correlation of approximately 0.9 for most articulatory features. Furthermore, we demonstrate that these predicted articulatory features can be decoded into intelligible speech waveforms. To our knowledge, this is the first method to decode speech waveforms from surface EMG via articulatory features, offering a novel approach to EMG-based speech synthesis. Additionally, we analyze the relationship between EMG electrode placement and articulatory feature predictability, providing knowledge-driven insights for optimizing EMG electrode configurations. The source code and decoded speech samples are publicly available. 

**Abstract (ZH)**: 我们提出了一种基于表面电肌图（EMG）信号预测发音特征的模型。该模型集成了卷积层和Transformer块，并分别针对发音特征进行了预测。我们的方法对于大多数发音特征实现了约0.9的高预测相关性。此外，我们展示了这些预测的发音特征可以解码为可理解的声波形态。据我们所知，这是首次通过发音特征从表面EMG解码声波形态的方法，为基于EMG的语音合成提供了新型方法。此外，我们分析了EMG电极放置与发音特征可预测性之间的关系，提供了优化EMG电极配置的知识驱动洞察。源代码和解码的语音样本已公开。 

---
# RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework 

**Title (ZH)**: 基于RAG/LLM增强的切换驱动多态元启发式框架 

**Authors**: Faramarz Safi Esfahani, Ghassan Beydoun, Morteza Saberi, Brad McCusker, Biswajeet Pradhan  

**Link**: [PDF](https://arxiv.org/pdf/2505.13808)  

**Abstract**: Metaheuristic algorithms are widely used for solving complex optimization problems, yet their effectiveness is often constrained by fixed structures and the need for extensive tuning. The Polymorphic Metaheuristic Framework (PMF) addresses this limitation by introducing a self-adaptive metaheuristic switching mechanism driven by real-time performance feedback and dynamic algorithmic selection. PMF leverages the Polymorphic Metaheuristic Agent (PMA) and the Polymorphic Metaheuristic Selection Agent (PMSA) to dynamically select and transition between metaheuristic algorithms based on key performance indicators, ensuring continuous adaptation. This approach enhances convergence speed, adaptability, and solution quality, outperforming traditional metaheuristics in high-dimensional, dynamic, and multimodal environments. Experimental results on benchmark functions demonstrate that PMF significantly improves optimization efficiency by mitigating stagnation and balancing exploration-exploitation strategies across various problem landscapes. By integrating AI-driven decision-making and self-correcting mechanisms, PMF paves the way for scalable, intelligent, and autonomous optimization frameworks, with promising applications in engineering, logistics, and complex decision-making systems. 

**Abstract (ZH)**: Polymeric元启发式框架：基于实时性能反馈的自适应元启发式切换机制及其应用 

---
# Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation 

**Title (ZH)**: 可解释的轨迹，出人意料的结果：基于轨迹的知识蒸馏中的断层探究 

**Authors**: Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati  

**Link**: [PDF](https://arxiv.org/pdf/2505.13792)  

**Abstract**: Question Answering (QA) poses a challenging and critical problem, particularly in today's age of interactive dialogue systems such as ChatGPT, Perplexity, Microsoft Copilot, etc. where users demand both accuracy and transparency in the model's outputs. Since smaller language models (SLMs) are computationally more efficient but often under-perform compared to larger models, Knowledge Distillation (KD) methods allow for finetuning these smaller models to improve their final performance. Lately, the intermediate tokens or the so called `reasoning' traces produced by Chain-of-Thought (CoT) or by reasoning models such as DeepSeek R1 are used as a training signal for KD. However, these reasoning traces are often verbose and difficult to interpret or evaluate. In this work, we aim to address the challenge of evaluating the faithfulness of these reasoning traces and their correlation with the final performance. To this end, we employ a KD method leveraging rule-based problem decomposition. This approach allows us to break down complex queries into structured sub-problems, generating interpretable traces whose correctness can be readily evaluated, even at inference time. Specifically, we demonstrate this approach on Open Book QA, decomposing the problem into a Classification step and an Information Retrieval step, thereby simplifying trace evaluation. Our SFT experiments with correct and incorrect traces on the CoTemp QA, Microsoft Machine Reading Comprehension QA, and Facebook bAbI QA datasets reveal the striking finding that correct traces do not necessarily imply that the model outputs the correct final solution. Similarly, we find a low correlation between correct final solutions and intermediate trace correctness. These results challenge the implicit assumption behind utilizing reasoning traces for improving SLMs' final performance via KD. 

**Abstract (ZH)**: Knowledge Distillation of Question Answering: Addressing the Evaluation of Reasoning Traces and Their Correlation with Final Performance 

---
# Understanding Task Representations in Neural Networks via Bayesian Ablation 

**Title (ZH)**: 通过贝叶斯消融理解神经网络中的任务表示 

**Authors**: Andrew Nam, Declan Campbell, Thomas Griffiths, Jonathan Cohen, Sarah-Jane Leslie  

**Link**: [PDF](https://arxiv.org/pdf/2505.13742)  

**Abstract**: Neural networks are powerful tools for cognitive modeling due to their flexibility and emergent properties. However, interpreting their learned representations remains challenging due to their sub-symbolic semantics. In this work, we introduce a novel probabilistic framework for interpreting latent task representations in neural networks. Inspired by Bayesian inference, our approach defines a distribution over representational units to infer their causal contributions to task performance. Using ideas from information theory, we propose a suite of tools and metrics to illuminate key model properties, including representational distributedness, manifold complexity, and polysemanticity. 

**Abstract (ZH)**: 神经网络由于其灵活性和涌现性质是认知建模的强大工具，但由于其亚符号语义，解释其学习表示仍然具有挑战性。本文引入了一种新的概率框架，用于解释神经网络中的潜任务表示。受贝叶斯推理的启发，我们的方法定义了一个表示单元的分布，以推断其对任务性能的因果贡献。借助信息理论的思想，我们提出了一系列工具和指标，以揭示模型的关键属性，包括表示的分布式性、流形的复杂性和多谓性。 

---
# Improving Compositional Generation with Diffusion Models Using Lift Scores 

**Title (ZH)**: 使用升分值提高组成性生成能力的扩散模型 

**Authors**: Chenning Yu, Sicun Gao  

**Link**: [PDF](https://arxiv.org/pdf/2505.13740)  

**Abstract**: We introduce a novel resampling criterion using lift scores, for improving compositional generation in diffusion models. By leveraging the lift scores, we evaluate whether generated samples align with each single condition and then compose the results to determine whether the composed prompt is satisfied. Our key insight is that lift scores can be efficiently approximated using only the original diffusion model, requiring no additional training or external modules. We develop an optimized variant that achieves relatively lower computational overhead during inference while maintaining effectiveness. Through extensive experiments, we demonstrate that lift scores significantly improved the condition alignment for compositional generation across 2D synthetic data, CLEVR position tasks, and text-to-image synthesis. Our code is available at this http URL. 

**Abstract (ZH)**: 我们提出了一种新的基于提升得分的重采样准则，以提高扩散模型中的组合生成能力。通过利用提升得分，我们评估生成样本是否与每个单独条件对齐，然后将结果组合以确定组合提示是否满足。我们的关键见解是，提升得分可以仅使用原始扩散模型高效近似，无需额外训练或外部模块。我们开发了一种优化变体，在推理时具有相对较低的计算开销，但仍保持有效性。通过广泛的实验，我们证明了提升得分显著改善了在2D合成数据、CLEVR位置任务和文本到图像合成中的条件对齐。我们的代码可在以下网址获得。 

---
# Self-Reinforced Graph Contrastive Learning 

**Title (ZH)**: 自我强化图对比学习 

**Authors**: Chou-Ying Hsieh, Chun-Fu Jang, Cheng-En Hsieh, Qian-Hui Chen, Sy-Yen Kuo  

**Link**: [PDF](https://arxiv.org/pdf/2505.13650)  

**Abstract**: Graphs serve as versatile data structures in numerous real-world domains-including social networks, molecular biology, and knowledge graphs-by capturing intricate relational information among entities. Among graph-based learning techniques, Graph Contrastive Learning (GCL) has gained significant attention for its ability to derive robust, self-supervised graph representations through the contrasting of positive and negative sample pairs. However, a critical challenge lies in ensuring high-quality positive pairs so that the intrinsic semantic and structural properties of the original graph are preserved rather than distorted. To address this issue, we propose SRGCL (Self-Reinforced Graph Contrastive Learning), a novel framework that leverages the model's own encoder to dynamically evaluate and select high-quality positive pairs. We designed a unified positive pair generator employing multiple augmentation strategies, and a selector guided by the manifold hypothesis to maintain the underlying geometry of the latent space. By adopting a probabilistic mechanism for selecting positive pairs, SRGCL iteratively refines its assessment of pair quality as the encoder's representational power improves. Extensive experiments on diverse graph-level classification tasks demonstrate that SRGCL, as a plug-in module, consistently outperforms state-of-the-art GCL methods, underscoring its adaptability and efficacy across various domains. 

**Abstract (ZH)**: 自强化图对比学习（SRGCL）：一种动态高质正样本生成与选择的新型框架 

---
# Learning (Approximately) Equivariant Networks via Constrained Optimization 

**Title (ZH)**: 学习（大致）等变的网络通过约束优化 

**Authors**: Andrei Manolache, Luiz F.O. Chamon, Mathias Niepert  

**Link**: [PDF](https://arxiv.org/pdf/2505.13631)  

**Abstract**: Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations. 

**Abstract (ZH)**: 自校准约束不变性（ACE）：通过同调原理引导的松弛不变性方法 

---
# Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses 

**Title (ZH)**: 面向方向的神经声场网络在环状声场冲激响应少量样本插值中的应用 

**Authors**: Christopher Ick, Gordon Wichern, Yoshiki Masuyama, François Germain, Jonathan Le Roux  

**Link**: [PDF](https://arxiv.org/pdf/2505.13617)  

**Abstract**: The characteristics of a sound field are intrinsically linked to the geometric and spatial properties of the environment surrounding a sound source and a listener. The physics of sound propagation is captured in a time-domain signal known as a room impulse response (RIR). Prior work using neural fields (NFs) has allowed learning spatially-continuous representations of RIRs from finite RIR measurements. However, previous NF-based methods have focused on monaural omnidirectional or at most binaural listeners, which does not precisely capture the directional characteristics of a real sound field at a single point. We propose a direction-aware neural field (DANF) that more explicitly incorporates the directional information by Ambisonic-format RIRs. While DANF inherently captures spatial relations between sources and listeners, we further propose a direction-aware loss. In addition, we investigate the ability of DANF to adapt to new rooms in various ways including low-rank adaptation. 

**Abstract (ZH)**: 一种考虑方向性的神经场（DANF）及其在新的声学环境中的应用 

---
# OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making 

**Title (ZH)**: OMGPT：一种基于数据驱动的操作决策序列建模框架 

**Authors**: Hanzhao Wang, Guanting Chen, Kalyan Talluri, Xiaocheng Li  

**Link**: [PDF](https://arxiv.org/pdf/2505.13580)  

**Abstract**: We build a Generative Pre-trained Transformer (GPT) model from scratch to solve sequential decision making tasks arising in contexts of operations research and management science which we call OMGPT. We first propose a general sequence modeling framework to cover several operational decision making tasks as special cases, such as dynamic pricing, inventory management, resource allocation, and queueing control. Under the framework, all these tasks can be viewed as a sequential prediction problem where the goal is to predict the optimal future action given all the historical information. Then we train a transformer-based neural network model (OMGPT) as a natural and powerful architecture for sequential modeling. This marks a paradigm shift compared to the existing methods for these OR/OM tasks in that (i) the OMGPT model can take advantage of the huge amount of pre-trained data; (ii) when tackling these problems, OMGPT does not assume any analytical model structure and enables a direct and rich mapping from the history to the future actions. Either of these two aspects, to the best of our knowledge, is not achieved by any existing method. We establish a Bayesian perspective to theoretically understand the working mechanism of the OMGPT on these tasks, which relates its performance with the pre-training task diversity and the divergence between the testing task and pre-training tasks. Numerically, we observe a surprising performance of the proposed model across all the above tasks. 

**Abstract (ZH)**: 我们从头构建了一个生成预训练变压器（GPT）模型来解决运筹学和管理科学领域中出现的序列决策任务，我们将该模型称为OMGPT。我们首先提出了一种通用的序列建模框架，涵盖了动态定价、库存管理、资源分配和排队控制等多重运营决策任务。在该框架下，所有这些任务都可以被视为一个序列预测问题，目标是在给定所有历史信息的情况下预测最优的未来行动。然后，我们训练了一个基于变换器的神经网络模型（OMGPT），作为一种自然且强大的序列建模架构。这标志着与现有这些运筹学/运营管理任务方法相比的重大转变，即（i）OMGPT模型可以利用大量的预训练数据；（ii）在解决这些问题时，OMGPT不需要假设有分析模型结构，并直接且丰富地将历史映射到未来的行动。这两方面的任意一项，据我们所知，当前任何现有方法都无法实现。我们从贝叶斯视角理论上理解OMGPT在这些任务中的工作机制，将其性能与预训练任务的多样性以及测试任务与预训练任务之间的差异联系起来。数值结果表明，所提出的模型在上述所有任务中表现出令人惊讶的性能。 

---
# FreeMesh: Boosting Mesh Generation with Coordinates Merging 

**Title (ZH)**: FreeMesh: 基于坐标合并提升网格生成 

**Authors**: Jian Liu, Haohan Weng, Biwen Lei, Xianghui Yang, Zibo Zhao, Zhuo Chen, Song Guo, Tao Han, Chunchao Guo  

**Link**: [PDF](https://arxiv.org/pdf/2505.13573)  

**Abstract**: The next-coordinate prediction paradigm has emerged as the de facto standard in current auto-regressive mesh generation methods. Despite their effectiveness, there is no efficient measurement for the various tokenizers that serialize meshes into sequences. In this paper, we introduce a new metric Per-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers theoretically without any training. Building upon PTME, we propose a plug-and-play tokenization technique called coordinate merging. It further improves the compression ratios of existing tokenizers by rearranging and merging the most frequent patterns of coordinates. Through experiments on various tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we further validate the performance of our method. We hope that the proposed PTME and coordinate merging can enhance the existing mesh tokenizers and guide the further development of native mesh generation. 

**Abstract (ZH)**: 下一个坐标预测范式已成为当前自回归网格生成方法的事实标准。尽管它们很有效，但目前尚无高效的度量标准来评估各种序列化的网格分词器。在本文中，我们引入了一种新的度量标准——每令牌网格熵（PTME），以在无需训练的情况下理论性地评估现有的网格分词器。基于PTME，我们提出了一种即插即用的分词技术——坐标合并，它通过重新排列和合并最频繁的坐标模式进一步提高了现有分词器的压缩比。通过在MeshXL、MeshAnything V2和Edgerunner等多种分词方法上的实验，我们进一步验证了我们方法的性能。我们希望所提出的PTME和坐标合并能够提升现有的网格分词器，并指导原生网格生成的进一步发展。 

---
# Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs 

**Title (ZH)**: Q${}^2$Forge: 创建知识图上问答能力问题和SPARQL查询 

**Authors**: Yousouf Taghzouti, Franck Michel, Tao Jiang, Louis-Félix Nothias, Fabien Gandon  

**Link**: [PDF](https://arxiv.org/pdf/2505.13572)  

**Abstract**: The SPARQL query language is the standard method to access knowledge graphs (KGs). However, formulating SPARQL queries is a significant challenge for non-expert users, and remains time-consuming for the experienced ones. Best practices recommend to document KGs with competency questions and example queries to contextualise the knowledge they contain and illustrate their potential applications. In practice, however, this is either not the case or the examples are provided in limited numbers. Large Language Models (LLMs) are being used in conversational agents and are proving to be an attractive solution with a wide range of applications, from simple question-answering about common knowledge to generating code in a targeted programming language. However, training and testing these models to produce high quality SPARQL queries from natural language questions requires substantial datasets of question-query pairs. In this paper, we present Q${}^2$Forge that addresses the challenge of generating new competency questions for a KG and corresponding SPARQL queries. It iteratively validates those queries with human feedback and LLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular, meaning that the different modules of the application (CQ generation, query generation and query refinement) can be used separately, as an integrated pipeline, or replaced by alternative services. The result is a complete pipeline from competency question formulation to query evaluation, supporting the creation of reference query sets for any target KG. 

**Abstract (ZH)**: Q${}^2$Forge：生成知识图谱新胜任力问题及其SPARQL查询的迭代验证方法 

---
# Learning Dynamics of RNNs in Closed-Loop Environments 

**Title (ZH)**: RNNs在闭环环境中的学习动力学 

**Authors**: Yoav Ger, Omri Barak  

**Link**: [PDF](https://arxiv.org/pdf/2505.13567)  

**Abstract**: Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer powerful models of brain computation. However, typical training paradigms rely on open-loop, supervised settings, whereas real-world learning unfolds in closed-loop environments. Here, we develop a mathematical theory describing the learning dynamics of linear RNNs trained in closed-loop contexts. We first demonstrate that two otherwise identical RNNs, trained in either closed- or open-loop modes, follow markedly different learning trajectories. To probe this divergence, we analytically characterize the closed-loop case, revealing distinct stages aligned with the evolution of the training loss. Specifically, we show that the learning dynamics of closed-loop RNNs, in contrast to open-loop ones, are governed by an interplay between two competing objectives: short-term policy improvement and long-term stability of the agent-environment interaction. Finally, we apply our framework to a realistic motor control task, highlighting its broader applicability. Taken together, our results underscore the importance of modeling closed-loop dynamics in a biologically plausible setting. 

**Abstract (ZH)**: 基于神经科学启发任务训练的循环神经网络提供了强大的大脑计算模型。然而，典型的训练范式依赖于开环监督设置，而现实世界的学习则发生在闭环环境中。在这里，我们发展了一种数学理论，描述了在闭环环境中训练的线性循环神经网络的学习动态。我们首先证明，两种否则完全相同的循环神经网络，在闭环或开环模式下训练时，其学习轨迹存在显著差异。为了探究这种差异，我们对闭环情况进行了理论分析，揭示了与训练损失演化阶段相一致的不同阶段。具体而言，我们展示闭环循环神经网络的学习动力学，与开环循环神经网络相比，受短期策略改善和长期环境交互稳定性的竞争目标的相互作用所支配。最后，我们将我们的框架应用于一个现实的运动控制任务，展示了其更广泛的应用潜力。我们的结果共同强调了在生物合现实的情景下建模闭环动态的重要性。 

---
# Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks 

**Title (ZH)**: 将可信赖人工智能与民主相契合：机遇与风险双重分类框架 

**Authors**: Oier Mentxaka, Natalia Díaz-Rodríguez, Mark Coeckelbergh, Marcos López de Prado, Emilia Gómez, David Fernández Llorca, Enrique Herrera-Viedma, Francisco Herrera  

**Link**: [PDF](https://arxiv.org/pdf/2505.13565)  

**Abstract**: Artificial Intelligence (AI) poses both significant risks and valuable opportunities for democratic governance. This paper introduces a dual taxonomy to evaluate AI's complex relationship with democracy: the AI Risks to Democracy (AIRD) taxonomy, which identifies how AI can undermine core democratic principles such as autonomy, fairness, and trust; and the AI's Positive Contributions to Democracy (AIPD) taxonomy, which highlights AI's potential to enhance transparency, participation, efficiency, and evidence-based policymaking.
Grounded in the European Union's approach to ethical AI governance, and particularly the seven Trustworthy AI requirements proposed by the European Commission's High-Level Expert Group on AI, each identified risk is aligned with mitigation strategies based on EU regulatory and normative frameworks. Our analysis underscores the transversal importance of transparency and societal well-being across all risk categories and offers a structured lens for aligning AI systems with democratic values.
By integrating democratic theory with practical governance tools, this paper offers a normative and actionable framework to guide research, regulation, and institutional design to support trustworthy, democratic AI. It provides scholars with a conceptual foundation to evaluate the democratic implications of AI, equips policymakers with structured criteria for ethical oversight, and helps technologists align system design with democratic principles. In doing so, it bridges the gap between ethical aspirations and operational realities, laying the groundwork for more inclusive, accountable, and resilient democratic systems in the algorithmic age. 

**Abstract (ZH)**: 人工智能（AI）对民主治理既构成了显著的风险，也带来了宝贵的机会。本文引入了一种双重分类法来评估AI与民主之间的复杂关系：AI对民主的风险（AIRD）分类，识别AI如何削弱自治、公平和信任等核心民主原则；以及AI对民主的正向贡献（AIPD）分类，强调AI在增强透明度、参与度、效率和基于证据的政策制定方面的潜力。 

---
# Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression 

**Title (ZH)**: 突破压缩上限：无数据管道实现超高效增量压缩 

**Authors**: Xiaohui Wang, Peng Ye, Chenyu Huang, Shenghe Zheng, Bo Zhang, Wanli Ouyang, Tao Chen  

**Link**: [PDF](https://arxiv.org/pdf/2505.13563)  

**Abstract**: With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression. 

**Abstract (ZH)**: 基于无数据的超高效delta压缩管道UltraDelta：实现超高效压缩与强大性能 

---
# Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback 

**Title (ZH)**: 基于带惩罚反馈的矩阵博弈中竞争协同演化带来的随机乐观策略 

**Authors**: Shishen Lin  

**Link**: [PDF](https://arxiv.org/pdf/2505.13562)  

**Abstract**: Learning in games is a fundamental problem in machine learning and artificial intelligence, with numerous applications~\citep{silver2016mastering,schrittwieser2020mastering}. This work investigates two-player zero-sum matrix games with an unknown payoff matrix and bandit feedback, where each player observes their actions and the corresponding noisy payoff. Prior studies have proposed algorithms for this setting~\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with \citet{o2021matrix} demonstrating the effectiveness of deterministic optimism (e.g., \ucb) in achieving sublinear regret. However, the potential of randomised optimism in matrix games remains theoretically unexplored.
We propose Competitive Co-evolutionary Bandit Learning (\coebl), a novel algorithm that integrates evolutionary algorithms (EAs) into the bandit framework to implement randomised optimism through EA variation operators. We prove that \coebl achieves sublinear regret, matching the performance of deterministic optimism-based methods. To the best of our knowledge, this is the first theoretical regret analysis of an evolutionary bandit learning algorithm in matrix games.
Empirical evaluations on diverse matrix game benchmarks demonstrate that \coebl not only achieves sublinear regret but also consistently outperforms classical bandit algorithms, including \exptr~\citep{auer2002nonstochastic}, the variant \exptrni~\citep{cai2024uncoupled}, and \ucb~\citep{o2021matrix}. These results highlight the potential of evolutionary bandit learning, particularly the efficacy of randomised optimism via evolutionary algorithms in game-theoretic settings. 

**Abstract (ZH)**: 学习博弈是机器学习和人工智能中的一个基础问题，具有广泛的应用~\citep{silver2016mastering,schrittwieser2020mastering}。本文探讨了观测噪声支付的两人零和矩阵博弈问题，其中支付矩阵未知且仅提供带宽反馈，每个玩家仅能观察到自己的行为及其相应的噪声支付。先前的研究提出了此类设置的算法~\citep{o2021matrix,maiti2023query,cai2024uncoupled}，\citet{o2021matrix}展示了确定性乐观策略（例如，\ucb）在实现次线性遗憾方面的有效性。然而，随机乐观策略在矩阵博弈中的潜力仍缺乏理论上的探讨。
本文提出了竞争协同进化带宽学习 (\coebl)，这是一种将进化算法 (EAs) 集成到带宽框架中的新算法，通过进化算法的变异算子实现随机乐观策略。我们证明了 \coebl 实现了次线性遗憾，与基于确定性乐观策略的方法具有相同的表现。据我们所知，这是第一个关于进化带宽学习算法在矩阵博弈中遗憾分析的理论结果。
在各种矩阵博弈基准上的 empirical 评估表明，\coebl 不仅实现了次线性遗憾，而且在包括 \exptr~\citep{auer2002nonstochastic}、\exptrni~\citep{cai2024uncoupled} 和 \ucb~\citep{o2021matrix} 在内的经典带宽算法中表现更优。这些结果突显了进化带宽学习的潜力，特别是在博弈论设置中进化算法实现随机乐观策略的有效性。 

---
# AMAQA: A Metadata-based QA Dataset for RAG Systems 

**Title (ZH)**: AMAQA：一种基于元数据的QA数据集用于RAG系统 

**Authors**: Davide Bruni, Marco Avvenuti, Nicola Tonellotto, Maurizio Tesconi  

**Link**: [PDF](https://arxiv.org/pdf/2505.13557)  

**Abstract**: Retrieval-augmented generation (RAG) systems are widely used in question-answering (QA) tasks, but current benchmarks lack metadata integration, hindering evaluation in scenarios requiring both textual data and external information. To address this, we present AMAQA, a new open-access QA dataset designed to evaluate tasks combining text and metadata. The integration of metadata is especially important in fields that require rapid analysis of large volumes of data, such as cybersecurity and intelligence, where timely access to relevant information is critical. AMAQA includes about 1.1 million English messages collected from 26 public Telegram groups, enriched with metadata such as timestamps, topics, emotional tones, and toxicity indicators, which enable precise and contextualized queries by filtering documents based on specific criteria. It also includes 450 high-quality QA pairs, making it a valuable resource for advancing research on metadata-driven QA and RAG systems. To the best of our knowledge, AMAQA is the first single-hop QA benchmark to incorporate metadata and labels such as topics covered in the messages. We conduct extensive tests on the benchmark, establishing a new standard for future research. We show that leveraging metadata boosts accuracy from 0.12 to 0.61, highlighting the value of structured context. Building on this, we explore several strategies to refine the LLM input by iterating over provided context and enriching it with noisy documents, achieving a further 3-point gain over the best baseline and a 14-point improvement over simple metadata filtering. The dataset is available at this https URL 

**Abstract (ZH)**: retrieval-enhanced 生成（RAG）系统广泛应用于问答（QA）任务，但当前基准缺乏元数据集成，阻碍了在需要文本数据和外部信息的情景下的评估。为解决这一问题，我们提出了AMAQA，一个新开放访问的QA数据集，旨在评估结合文本和元数据的任务。元数据的集成尤其重要，特别是在需要快速分析大量数据的领域，如网络安全和情报领域，及时获取相关信息至关重要。AMAQA 包含来自 26 个公共 Telegram 组的约 110 万条英语消息，这些消息经过元数据增强，包括时间戳、主题、情感基调和毒性指标，这些元数据可以基于特定标准过滤文档，实现精确和上下文化的查询。此外，它还包括 450 对高质量的 QA 对，使其成为推进基于元数据的 QA 和 RAG 系统研究的重要资源。据我们所知，AMAQA 是第一个将元数据和消息涵盖的主题标签等标签结合的单跳 QA 基准。我们在基准上进行了广泛的测试，建立了未来研究的新标准。我们表明，利用元数据将准确性从 0.12 提高到 0.61，突显了结构化上下文的价值。在此基础上，我们探索了多种策略来细化 LL M 输入，通过迭代提供的上下文并用具有噪声的文档补充，实现了对最佳基准的 3 分进一步提升和对简单元数据过滤的 14 分改进。数据集可在以下链接获取：this https URL 

---
# JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation 

**Title (ZH)**: JIR-竞技场：首个即时信息推荐基准数据集 

**Authors**: Ke Yang, Kevin Ros, Shankar Kumar Senthil Kumar, ChengXiang Zhai  

**Link**: [PDF](https://arxiv.org/pdf/2505.13550)  

**Abstract**: Just-in-time Information Recommendation (JIR) is a service designed to deliver the most relevant information precisely when users need it, , addressing their knowledge gaps with minimal effort and boosting decision-making and efficiency in daily life. Advances in device-efficient deployment of foundation models and the growing use of intelligent wearable devices have made always-on JIR assistants feasible. However, there has been no systematic effort to formally define JIR tasks or establish evaluation frameworks. To bridge this gap, we present the first mathematical definition of JIR tasks and associated evaluation metrics. Additionally, we introduce JIR-Arena, a multimodal benchmark dataset featuring diverse, information-request-intensive scenarios to evaluate JIR systems across critical dimensions: i) accurately inferring user information needs, ii) delivering timely and relevant recommendations, and iii) avoiding irrelevant content that may distract users.
Developing a JIR benchmark dataset poses challenges due to subjectivity in estimating user information needs and uncontrollable system variables affecting reproducibility. To address these, JIR-Arena: i) combines input from multiple humans and large AI models to approximate information need distributions; ii) assesses JIR quality through information retrieval outcomes using static knowledge base snapshots; and iii) employs a multi-turn, multi-entity validation framework to improve objectivity and generality. Furthermore, we implement a baseline JIR system capable of processing real-time information streams aligned with user inputs. Our evaluation of this baseline system on JIR-Arena indicates that while foundation model-based JIR systems simulate user needs with reasonable precision, they face challenges in recall and effective content retrieval. To support future research in this new area, we fully release our code and data. 

**Abstract (ZH)**: 即时信息推荐 (JIR) 是一种服务，旨在在用户需要时提供最相关的信息，填补他们的知识空白，以最小的努力提升日常生活中的决策能力和效率。随着基础模型在设备上的高效部署和智能可穿戴设备的广泛应用，持续的即时信息推荐 (JIR) 助手变得可行。然而，尚未有任何系统性的努力来正式定义 JIR 任务或建立评估框架。为弥补这一空白，我们首次给出了 JIR 任务的数学定义及其相关的评估指标。此外，我们引入了 JIR-Arena，这是一个多模态基准数据集，包含多样化的、信息请求密集的场景，用于从关键维度评估 JIR 系统：i）准确推断用户的信息需求，ii）及时并提供相关推荐，iii）避免分心的不相关内容。

建立 JIR 基准数据集面临着挑战，包括估计用户信息需求的主观性以及影响可重现性的系统变量的不可控性。为解决这些问题，JIR-Arena：i）结合多名人类和大型 AI 模型的输入来近似信息需求分布；ii）通过使用静态知识库快照的信息检索结果评估 JIR 质量；iii）采用多轮、多实体验证框架提高客观性和通用性。此外，我们实现了一个基础模型驱动的 JIR 系统，能够实时处理与用户输入对齐的信息流。我们在 JIR-Arena 上对这一基础系统进行评估的结果表明，尽管基础模型驱动的 JIR 系统能够以合理的精度模拟用户需求，但在召回率和有效的内容检索方面仍面临挑战。为了支持这一新领域未来的研究，我们完全开源了我们的代码和数据。 

---
# Multi-head Temporal Latent Attention 

**Title (ZH)**: 多头时间潜注意力 

**Authors**: Keqi Deng, Philip C. Woodland  

**Link**: [PDF](https://arxiv.org/pdf/2505.13544)  

**Abstract**: While Transformer self-attention offers strong parallelism, the Key-Value (KV) cache grows linearly with sequence length and becomes a bottleneck for inference efficiency. Multi-head latent attention was recently developed to compress the KV cache into a low-rank latent space. This paper proposes Multi-head Temporal Latent Attention (MTLA), which further reduces the KV cache size along the temporal dimension, greatly lowering the memory footprint of self-attention inference. MTLA employs a hyper-network to dynamically merge temporally adjacent KV cache vectors. To address the mismatch between the compressed KV cache and processed sequence lengths, a stride-aware causal mask is proposed to ensure efficient parallel training and consistency with inference behaviour. Experiments across tasks, including speech translation, speech recognition, speech understanding and text summarisation, demonstrate that MTLA achieves competitive performance compared to standard Multi-Head Attention (MHA), while greatly improving inference speed and GPU memory usage. For example, on a English-German speech translation task, MTLA achieves a 5.3x speedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA, while maintaining translation quality. 

**Abstract (ZH)**: 基于多头 temporal 潜在注意的 KV 缓存压缩（Multi-head Temporal Latent Attention for KV Cache Compression） 

---
# InterFeat: An Automated Pipeline for Finding Interesting Hypotheses in Structured Biomedical Data 

**Title (ZH)**: InterFeat: 一种自动化的流程，用于在结构化生物医学数据中发现有趣的假设。 

**Authors**: Dan Ofer, Michal Linial, Dafna Shahaf  

**Link**: [PDF](https://arxiv.org/pdf/2505.13534)  

**Abstract**: Finding interesting phenomena is the core of scientific discovery, but it is a manual, ill-defined concept. We present an integrative pipeline for automating the discovery of interesting simple hypotheses (feature-target relations with effect direction and a potential underlying mechanism) in structured biomedical data. The pipeline combines machine learning, knowledge graphs, literature search and Large Language Models. We formalize "interestingness" as a combination of novelty, utility and plausibility. On 8 major diseases from the UK Biobank, our pipeline consistently recovers risk factors years before their appearance in the literature. 40--53% of our top candidates were validated as interesting, compared to 0--7% for a SHAP-based baseline. Overall, 28% of 109 candidates were interesting to medical experts. The pipeline addresses the challenge of operationalizing "interestingness" scalably and for any target. We release data and code: this https URL 

**Abstract (ZH)**: 一种集成管道用于自动化发现结构化生物医学数据中的有趣简单假设 

---
# Distributional Soft Actor-Critic with Harmonic Gradient for Safe and Efficient Autonomous Driving in Multi-lane Scenarios 

**Title (ZH)**: 基于谐波梯度的分布软actor-critic在多车道场景中安全高效的自动驾驶 

**Authors**: Feihong Zhang, Guojian Zhan, Bin Shuai, Tianyi Zhang, Jingliang Duan, Shengbo Eben Li  

**Link**: [PDF](https://arxiv.org/pdf/2505.13532)  

**Abstract**: Reinforcement learning (RL), known for its self-evolution capability, offers a promising approach to training high-level autonomous driving systems. However, handling constraints remains a significant challenge for existing RL algorithms, particularly in real-world applications. In this paper, we propose a new safety-oriented training technique called harmonic policy iteration (HPI). At each RL iteration, it first calculates two policy gradients associated with efficient driving and safety constraints, respectively. Then, a harmonic gradient is derived for policy updating, minimizing conflicts between the two gradients and consequently enabling a more balanced and stable training process. Furthermore, we adopt the state-of-the-art DSAC algorithm as the backbone and integrate it with our HPI to develop a new safe RL algorithm, DSAC-H. Extensive simulations in multi-lane scenarios demonstrate that DSAC-H achieves efficient driving performance with near-zero safety constraint violations. 

**Abstract (ZH)**: 强化学习（RL）因其自我进化能力，提供了训练高级自动驾驶系统的一种有希望的方法。然而，处理约束仍然是现有RL算法的一个重大挑战，尤其是在实际应用中。在本文中，我们提出了一种新的安全性导向训练技术，称为谐波策略迭代（HPI）。在每次RL迭代中，它首先分别计算与高效驾驶和安全约束相关的两个策略梯度，然后导出一个谐波梯度用于策略更新，通过最小化两个梯度之间的冲突，从而实现更平衡和稳定的训练过程。此外，我们采用最新的DSAC算法作为骨干，并将其与我们的HPI相结合，开发出一种新的安全RL算法DSAC-H。在多车道场景中的 extensive 模拟表明，DSAC-H 能够实现高效的驾驶性能，几乎不违反安全约束。 

---
# Learning to Program Quantum Measurements for Machine Learning 

**Title (ZH)**: 学习编写量子测量程序以应用于机器学习 

**Authors**: Samual Yen-Chi Chen, Huan-Hsin Tseng, Hsin-Yi Lin, Shinjae Yoo  

**Link**: [PDF](https://arxiv.org/pdf/2505.13525)  

**Abstract**: The rapid advancements in quantum computing (QC) and machine learning (ML) have sparked significant interest, driving extensive exploration of quantum machine learning (QML) algorithms to address a wide range of complex challenges. The development of high-performance QML models requires expert-level expertise, presenting a key challenge to the widespread adoption of QML. Critical obstacles include the design of effective data encoding strategies and parameterized quantum circuits, both of which are vital for the performance of QML models. Furthermore, the measurement process is often neglected-most existing QML models employ predefined measurement schemes that may not align with the specific requirements of the targeted problem. We propose an innovative framework that renders the observable of a quantum system-specifically, the Hermitian matrix-trainable. This approach employs an end-to-end differentiable learning framework, enabling simultaneous optimization of the neural network used to program the parameterized observables and the standard quantum circuit parameters. Notably, the quantum observable parameters are dynamically programmed by the neural network, allowing the observables to adapt in real time based on the input data stream. Through numerical simulations, we demonstrate that the proposed method effectively programs observables dynamically within variational quantum circuits, achieving superior results compared to existing approaches. Notably, it delivers enhanced performance metrics, such as higher classification accuracy, thereby significantly improving the overall effectiveness of QML models. 

**Abstract (ZH)**: 量子计算和机器学习的迅猛发展激发了广泛兴趣，推动了量子机器学习算法的探索，以应对各种复杂挑战。高性能量子机器学习模型的开发需要专家级的专业知识，成为其广泛应用的关键障碍。关键障碍包括有效的数据编码策略和参数化量子电路的设计，这两个方面对量子机器学习模型的性能至关重要。此外，测量过程往往被忽视——大多数现有量子机器学习模型采用预定义的测量方案，可能不适用于特定问题的需求。我们提出了一种创新框架，使其可观测值——具体而言，是厄米矩阵——可训练。该方法采用端到端可微学习框架，同时优化用于编程参数化可观测值的神经网络和标准量子电路参数。值得注意的是，观测值参数由神经网络动态编程，使观测值能够根据输入数据流实时调整。通过数值仿真，我们证明了所提出的方法能够有效在变分量子电路中动态编程可观测值，相比现有方法取得了更优的结果。它还实现了更高的分类准确性等改进性能指标，从而显著提高了量子机器学习模型的整体有效性。 

---
# ACPs: Agent Collaboration Protocols for the Internet of Agents 

**Title (ZH)**: 代理协作协议：代理互联网中的协作协议 

**Authors**: Jun Liu, Ke Yu, Keliang Chen, Ke Li, Yuxinyue Qian, Xiaolian Guo, Haozhe Song, Yinming Li  

**Link**: [PDF](https://arxiv.org/pdf/2505.13523)  

**Abstract**: With the rapid advancement of artificial intelligence, the proliferation of autonomous agents has introduced new challenges in interoperability, scalability, and coordination. The Internet of Agents (IoA) aims to interconnect heterogeneous agents through standardized communication protocols, enabling seamless collaboration and intelligent task execution. However, existing agent communication protocols such as MCP, A2A, and ANP remain fragmented and scenario-specific. To address this gap, we propose Agent Collaboration Protocols (ACPs), a comprehensive protocol suite for the IoA. ACPs include registration, discovery, interaction, and tooling protocols to support trustable access, capability orchestration, and workflow construction. We present the architecture, key technologies, and application workflows of ACPs, and demonstrate its effectiveness in a collaborative restaurant booking scenario. ACPs lay the foundation for building a secure, open, and scalable agent internet infrastructure. 

**Abstract (ZH)**: 随着人工智能的迅速发展，自主代理的 proliferate 引入了互操作性、可扩展性和协调性的新挑战。代理互联网 (IoA) 致力于通过标准化通信协议互联异构代理，实现无缝协作和智能任务执行。然而，现有的代理通信协议如 MCP、A2A 和 ANP 仍然fragmented 和场景特定。为解决这一问题，我们提出了代理协作协议 (ACPs)，这是一种适用于 IoA 的综合协议套件。ACPs 包括注册、发现、交互和工具协议，以支持可信访问、能力编排和工作流构建。我们介绍了 ACPs 的架构、关键技术及其应用工作流，并在协作餐厅预订场景中展示了其有效性。ACPs 为构建安全、开放和可扩展的代理互联网基础设施奠定了基础。 

---
# Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering 

**Title (ZH)**: 超越检索：联合监督与多模态文档排序在教材问答中的应用 

**Authors**: Hessa Alawwad, Usman Naseem, Areej Alhothali, Ali Alkhathlan, Amani Jamal  

**Link**: [PDF](https://arxiv.org/pdf/2505.13520)  

**Abstract**: Textbook question answering (TQA) is a complex task, requiring the interpretation of complex multimodal context. Although recent advances have improved overall performance, they often encounter difficulties in educational settings where accurate semantic alignment and task-specific document retrieval are essential. In this paper, we propose a novel approach to multimodal textbook question answering by introducing a mechanism for enhancing semantic representations through multi-objective joint training. Our model, Joint Embedding Training With Ranking Supervision for Textbook Question Answering (JETRTQA), is a multimodal learning framework built on a retriever--generator architecture that uses a retrieval-augmented generation setup, in which a multimodal large language model generates answers. JETRTQA is designed to improve the relevance of retrieved documents in complex educational contexts. Unlike traditional direct scoring approaches, JETRTQA learns to refine the semantic representations of questions and documents through a supervised signal that combines pairwise ranking and implicit supervision derived from answers. We evaluate our method on the CK12-QA dataset and demonstrate that it significantly improves the discrimination between informative and irrelevant documents, even when they are long, complex, and multimodal. JETRTQA outperforms the previous state of the art, achieving a 2.4\% gain in accuracy on the validation set and 11.1\% on the test set. 

**Abstract (ZH)**: 多模态教科书问答（TQA）是一种复杂的任务，需要解释复杂的多模态背景信息。尽管最近的进展提高了整体性能，但在需要准确语义对齐和任务特定文档检索的教学环境中，仍面临挑战。本文提出了一种通过多目标联合训练增强语义表示的新方法来解决多模态教科书问答问题。我们的模型“基于排名监督的联合嵌入训练用于教科书问答”（JETRTQA）是一种基于检索-生成架构的多模态学习框架，使用了检索增强生成设置，其中多模态大型语言模型生成答案。JETRTQA旨在提高在复杂教育背景下检索到的文档的相关性。与传统的直接评分方法不同，JETRTQA通过结合成对排序监督和从答案推导出的隐式监督的监督信号，学习细化问题和文档的语义表示。我们在CK12-QA数据集上评估了该方法，并证明它显著提高了信息性文档和无关文档之间的区分能力，即使它们是长、复杂且多模态的。JETRTQA在验证集上实现了2.4%的准确率提升，在测试集上实现了11.1%的提升。 

---
# Continuous Domain Generalization 

**Title (ZH)**: 连续域泛化 

**Authors**: Zekun Cai, Yiheng Yao, Guangji Bai, Renhe Jiang, Xuan Song, Ryosuke Shibasaki, Liang Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2505.13519)  

**Abstract**: Real-world data distributions often shift continuously across multiple latent factors such as time, geography, and socioeconomic context. However, existing domain generalization approaches typically treat domains as discrete or evolving along a single axis (e.g., time), which fails to capture the complex, multi-dimensional nature of real-world variation. This paper introduces the task of Continuous Domain Generalization (CDG), which aims to generalize predictive models to unseen domains defined by arbitrary combinations of continuous variation descriptors. We present a principled framework grounded in geometric and algebraic theory, showing that optimal model parameters across domains lie on a low-dimensional manifold. To model this structure, we propose a Neural Lie Transport Operator (NeuralLTO), which enables structured parameter transitions by enforcing geometric continuity and algebraic consistency. To handle noisy or incomplete domain descriptors, we introduce a gating mechanism to suppress irrelevant dimensions and a local chart-based strategy for robust generalization. Extensive experiments on synthetic and real-world datasets-including remote sensing, scientific documents, and traffic forecasting-demonstrate that our method significantly outperforms existing baselines in generalization accuracy and robustness under descriptor imperfections. 

**Abstract (ZH)**: 连续域泛化（CDG）中的预测模型泛化研究 

---
# Data Balancing Strategies: A Survey of Resampling and Augmentation Methods 

**Title (ZH)**: 数据平衡策略：重采样和 augmentation 方法综述 

**Authors**: Behnam Yousefimehr, Mehdi Ghatee, Mohammad Amin Seifi, Javad Fazli, Sajed Tavakoli, Zahra Rafei, Shervin Ghaffari, Abolfazl Nikahd, Mahdi Razi Gandomani, Alireza Orouji, Ramtin Mahmoudi Kashani, Sarina Heshmati, Negin Sadat Mousavi  

**Link**: [PDF](https://arxiv.org/pdf/2505.13518)  

**Abstract**: Imbalanced data poses a significant obstacle in machine learning, as an unequal distribution of class labels often results in skewed predictions and diminished model accuracy. To mitigate this problem, various resampling strategies have been developed, encompassing both oversampling and undersampling techniques aimed at modifying class proportions. Conventional oversampling approaches like SMOTE enhance the representation of the minority class, whereas undersampling methods focus on trimming down the majority class. Advances in deep learning have facilitated the creation of more complex solutions, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), which are capable of producing high-quality synthetic examples. This paper reviews a broad spectrum of data balancing methods, classifying them into categories including synthetic oversampling, adaptive techniques, generative models, ensemble-based strategies, hybrid approaches, undersampling, and neighbor-based methods. Furthermore, it highlights current developments in resampling techniques and discusses practical implementations and case studies that validate their effectiveness. The paper concludes by offering perspectives on potential directions for future exploration in this domain. 

**Abstract (ZH)**: 不平衡数据在机器学习中构成重大障碍，不均衡的类别标签分布往往导致预测偏差和模型准确度降低。为缓解这一问题，发展了多种重采样策略，包括过采样和欠采样技术，以调整类别比例。传统的过采样方法如SMOTE增强了少数类的代表性，而欠采样方法则侧重于减少多数类的数量。深度学习的进步催生了更复杂的方法，如生成对抗网络（GANs）和变分自编码器（VAEs），这些方法能够生成高质量的合成样本。本文综述了广泛的数据平衡方法，将它们分类为合成过采样、自适应技术、生成模型、基于集成的方法、混合方法、欠采样和邻近基于的方法。此外，文章还强调了重采样技术的最新进展，并讨论了实际实施和案例研究，以验证其有效性。最后，本文提出了未来研究方向的展望。 

---
# Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency 

**Title (ZH)**: 变压器架构的最优控制：增强泛化能力、稳健性和效率 

**Authors**: Kelvin Kan, Xingjian Li, Benjamin J. Zhang, Tuhin Sahai, Stanley Osher, Markos A. Katsoulakis  

**Link**: [PDF](https://arxiv.org/pdf/2505.13499)  

**Abstract**: We study Transformers through the perspective of optimal control theory, using tools from continuous-time formulations to derive actionable insights into training and architecture design. This framework improves the performance of existing Transformer models while providing desirable theoretical guarantees, including generalization and robustness. Our framework is designed to be plug-and-play, enabling seamless integration with established Transformer models and requiring only slight changes to the implementation. We conduct seven extensive experiments on tasks motivated by text generation, sentiment analysis, image classification, and point cloud classification. Experimental results show that the framework improves the test performance of the baselines, while being more parameter-efficient. On character-level text generation with nanoGPT, our framework achieves a 46% reduction in final test loss while using 42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in final test loss, demonstrating scalability to larger models. To the best of our knowledge, this is the first work that applies optimal control theory to both the training and architecture of Transformers. It offers a new foundation for systematic, theory-driven improvements and moves beyond costly trial-and-error approaches. 

**Abstract (ZH)**: 我们从最优控制理论的角度研究Transformer，利用连续时间形式化的工具来获取关于训练和架构设计的实际洞察。该框架在提升现有Transformer模型性能的同时，提供了泛化能力和鲁棒性等理想的理论保证。该框架设计为即插即用，可以无缝集成到已有的Transformer模型中，并且只需对实现进行轻微修改。我们通过七个涉及文本生成、情感分析、图像分类和点云分类等任务的广泛实验进行了验证。实验结果表明，该框架在基础模型上提升了测试性能，且更具参数效率。在字符级别文本生成任务中，使用nanoGPT时，该框架在最终测试损失上实现了46%的下降，同时使用42%较少的参数。在GPT-2上，该框架实现了5.6%的最终测试损失下降，展示了其对更大模型的扩展性。据我们所知，这是首次将最优控制理论应用于Transformer的训练与架构中，为系统性的、理论驱动的改进提供了新的基础，并超越了昂贵的试错方法。 

---
# Algorithmic Tradeoffs in Fair Lending: Profitability, Compliance, and Long-Term Impact 

**Title (ZH)**: 算法权衡在公平信贷中的作用：盈利性、合规性和长期影响 

**Authors**: Aayam Bansal, Harsh Vardhan Narsaria  

**Link**: [PDF](https://arxiv.org/pdf/2505.13469)  

**Abstract**: As financial institutions increasingly rely on machine learning models to automate lending decisions, concerns about algorithmic fairness have risen. This paper explores the tradeoff between enforcing fairness constraints (such as demographic parity or equal opportunity) and maximizing lender profitability. Through simulations on synthetic data that reflects real-world lending patterns, we quantify how different fairness interventions impact profit margins and default rates. Our results demonstrate that equal opportunity constraints typically impose lower profit costs than demographic parity, but surprisingly, removing protected attributes from the model (fairness through unawareness) outperforms explicit fairness interventions in both fairness and profitability metrics. We further identify the specific economic conditions under which fair lending becomes profitable and analyze the feature-specific drivers of unfairness. These findings offer practical guidance for designing lending algorithms that balance ethical considerations with business objectives. 

**Abstract (ZH)**: 随着金融机构越来越依赖机器学习模型来自动化贷款决策，关于算法公平性的担忧日益增加。本文探讨了强制执行公平约束（如人口统计对等或同等机遇）与最大化贷方盈利能力之间的权衡。通过模拟反映真实世界贷款模式的合成数据，我们量化了不同公平干预措施对利润margin和违约率的影响。研究结果表明，同等机遇约束通常对利润的影响较小，而意外的是，从模型中移除保护性属性（无知公平）在公平性和盈利能力指标上均优于显式公平干预措施。我们进一步界定了使公平贷款变得盈利的具体经济条件，并分析了不公平性的特征特定驱动因素。这些发现为设计兼顾伦理考虑和商业目标的贷款算法提供了实用指导。 

---
# Uncertainty Quantification for Prior-Data Fitted Networks using Martingale Posteriors 

**Title (ZH)**: 基于鞅后验分布的先验-数据拟合网络的不确定性量化 

**Authors**: Thomas Nagler, David Rügamer  

**Link**: [PDF](https://arxiv.org/pdf/2505.11325)  

**Abstract**: Prior-data fitted networks (PFNs) have emerged as promising foundation models for prediction from tabular data sets, achieving state-of-the-art performance on small to moderate data sizes without tuning. While PFNs are motivated by Bayesian ideas, they do not provide any uncertainty quantification for predictive means, quantiles, or similar quantities. We propose a principled and efficient sampling procedure to construct Bayesian posteriors for such estimates based on Martingale posteriors, and prove its convergence. Several simulated and real-world data examples showcase the uncertainty quantification of our method in inference applications. 

**Abstract (ZH)**: 基于Martingale后验的Prior-data fitted网络的贝叶斯后验构建及其收敛性证明和不确定性量化 

---
# Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws 

**Title (ZH)**: 参考模型指导学习：改进泛化界限和标度定律 

**Authors**: Xiyuan Wei, Ming Lin, Fanjiang Ye, Fengguang Song, Liangliang Cao, My T. Thai, Tianbao Yang  

**Link**: [PDF](https://arxiv.org/pdf/2505.06699)  

**Abstract**: This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named $\textbf{model steering}$. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called $\textbf{DRRho risk minimization}$, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches. 

**Abstract (ZH)**: 这篇论文 formalizes 一种新兴的学习范式，通过战略数据选择或加权来指导和增强目标模型训练，使用训练好的模型作为参考，将其命名为 $\textbf{模型引导 (Model Steering)}$。虽然已经在这方面使用了各种 ad-hoc 方法，包括大型基础模型的训练，但其基本原理尚未得到充分理解，导致性能不佳。在本文中，我们提出了一个基于 Distributionally Robust Optimization (DRO) 的理论驱动框架，称为 $\textbf{DRRho 风险最小化 (DRRho Risk Minimization)}$，并通过泛化分析提供了有关为何此方法在没有参考模型的情况下训练时能提高泛化能力和数据效率的理论见解。据我们所知，这是首次为这一新兴学习范式提供此类理论见解，这对理解并实践模型引导有着重要意义。基于这些见解及其与对比学习和 DRO 之间的联系，我们提出了一种新的参考模型辅助的对比语言-图像预训练方法，称为 DRRho-CLIP。广泛的实验验证了这些理论见解，揭示了与没有参考模型的 CLIP 相比更优异的扩展规律，并展示了其在现有启发式方法上的优越性。标题：

模型引导：$\textbf{DRRho风险最小化框架及其在对比语言-图像预训练中的应用 (Model Steering: DRRho Risk Minimization Framework and Its Application in Contrastive Language-Image Pretraining)}$ 

---
