# Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making 

**Title (ZH)**: 基于叙述引导的强化学习：研究语言模型对决策影响的平台 

**Authors**: Anup Tuladhar, Araz Minhas, Adam Kirton, Eli Kinney-Lang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08785)  

**Abstract**: We present a preliminary experimental platform that explores how narrative elements might shape AI decision-making by combining reinforcement learning (RL) with language model reasoning. While AI systems can now both make decisions and engage in narrative reasoning, these capabilities have mostly been studied separately. Our platform attempts to bridge this gap using a dual-system architecture to examine how narrative frameworks could influence reward-based learning. The system comprises a reinforcement learning policy that suggests actions based on past experience, and a language model that processes these suggestions through different narrative frameworks to guide decisions. This setup enables initial experimentation with narrative elements while maintaining consistent environment and reward structures. We implement this architecture in a configurable gridworld environment, where agents receive both policy suggestions and information about their surroundings. The platform's modular design facilitates controlled testing of environmental complexity, narrative parameters, and the interaction between reinforcement learning and narrative-based decisions. Our logging system captures basic decision metrics, from RL policy values to language model reasoning to action selection patterns. While preliminary, this implementation provides a foundation for studying how different narrative frameworks might affect reward-based decisions and exploring potential interactions between optimization-based learning and symbolic reasoning in AI systems. 

**Abstract (ZH)**: 我们提出一个初步的实验平台，通过结合强化学习（RL）与语言模型推理来探索叙事元素如何塑造AI决策。该平台旨在结合双系统架构，研究叙事框架如何影响基于奖励的学习。系统包括一个基于强化学习的策略，根据过往经验建议行动，以及一个语言模型，通过不同的叙事框架处理这些建议以引导决策。该配置允许初步探索叙事元素，同时保持稳定环境和奖励结构。我们在此配置中使用可配置的网格世界环境实现该架构，其中代理既接收策略建议也获取周围环境的信息。平台的模块化设计便于控制测试环境复杂性、叙事参数，以及强化学习与基于叙事的决策之间的相互作用。日志系统记录基本决策指标，从强化学习策略值到语言模型推理再到行动选择模式。尽管初步，但该实现为研究不同叙事框架可能如何影响基于奖励的决策提供了基础，并探索优化学习与符号推理之间潜在的交互作用。 

---
# The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems 

**Title (ZH)**: 你 automation 越多，你看到的越少：AI 科学家系统的隐含陷阱 

**Authors**: Ziming Luo, Atoosa Kasirzadeh, Nihar B. Shah  

**Link**: [PDF](https://arxiv.org/pdf/2509.08713)  

**Abstract**: AI scientist systems, capable of autonomously executing the full research workflow from hypothesis generation and experimentation to paper writing, hold significant potential for accelerating scientific discovery. However, the internal workflow of these systems have not been closely examined. This lack of scrutiny poses a risk of introducing flaws that could undermine the integrity, reliability, and trustworthiness of their research outputs. In this paper, we identify four potential failure modes in contemporary AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and post-hoc selection bias. To examine these risks, we design controlled experiments that isolate each failure mode while addressing challenges unique to evaluating AI scientist systems. Our assessment of two prominent open-source AI scientist systems reveals the presence of several failures, across a spectrum of severity, which can be easily overlooked in practice. Finally, we demonstrate that access to trace logs and code from the full automated workflow enables far more effective detection of such failures than examining the final paper alone. We thus recommend journals and conferences evaluating AI-generated research to mandate submission of these artifacts alongside the paper to ensure transparency, accountability, and reproducibility. 

**Abstract (ZH)**: 当前AI科学家系统中存在的四种潜在失败模式及其评估：从基准选择不当到事后选择偏差，需要透明、问责和可再现性。 

---
# One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases 

**Title (ZH)**: 一个模型，两种思维：一种基于语境的图学习器，再现人类偏差 

**Authors**: Shalima Binta Manir, Tim Oates  

**Link**: [PDF](https://arxiv.org/pdf/2509.08705)  

**Abstract**: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process theories from cognitive science, integrating a fast, habitual graph-based reasoning system (System 1), implemented via graph convolutional networks (GCNs), and a slower, context-sensitive meta-adaptive learning system (System 2), driven by meta-learning techniques. Our model dynamically balances intuitive and deliberative reasoning through a learned context gate mechanism. We validate our architecture on canonical false-belief tasks and systematically explore its capacity to replicate hallmark cognitive biases associated with dual-process theory, including anchoring, cognitive-load fatigue, framing effects, and priming effects. Experimental results demonstrate that our dual-process approach closely mirrors human adaptive behavior, achieves robust generalization to unseen contexts, and elucidates cognitive mechanisms underlying reasoning biases. This work bridges artificial intelligence and cognitive theory, paving the way for AI systems exhibiting nuanced, human-like social cognition and adaptive decision-making capabilities. 

**Abstract (ZH)**: 我们提出了一种受认知科学双重过程理论启发的新型理论领悟（Theory of Mind，ToM）框架，将快速的习惯性图基推理系统（System 1）通过图卷积网络（GCNs）实现，并将慢速的上下文敏感元自适应学习系统（System 2）通过元学习技术驱动。模型通过一个学习到的上下文门机制动态平衡直觉推理和审慎推理。我们在经典的错误信念任务上验证了我们的架构，并系统地探索了其复制双重过程理论相关认知偏差的能力，包括锚定效应、认知负荷疲劳、框架效应和唤醒效应。实验结果表明，我们的双重过程方法 closely mirrors 人类适应行为，实现了对未见过的上下文的稳健泛化，并阐明了推理偏差背后的认知机制。本工作将人工智能与认知理论相结合，为具备细腻、类人社会认知和适应性决策能力的AI系统的发展铺平了道路。 

---
# Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference 

**Title (ZH)**: 基于因果推理的多智能体系统自动故障归因与关键步骤预测方法 

**Authors**: Guoqing Ma, Jia Zhu, Hanghui Guo, Weijie Shi, Jiawei Shen, Jingjiang Liu, Yidan Liang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08682)  

**Abstract**: Multi-agent systems (MAS) are critical for automating complex tasks, yet their practical deployment is severely hampered by the challenge of failure attribution. Current diagnostic tools, which rely on statistical correlations, are fundamentally inadequate; on challenging benchmarks like Who\&When, state-of-the-art methods achieve less than 15\% accuracy in locating the root-cause step of a failure. To address this critical gap, we introduce the first failure attribution framework for MAS grounded in multi-granularity causal inference. Our approach makes two key technical contributions: (1) a performance causal inversion principle, which correctly models performance dependencies by reversing the data flow in execution logs, combined with Shapley values to accurately assign agent-level blame; (2) a novel causal discovery algorithm, CDC-MAS, that robustly identifies critical failure steps by tackling the non-stationary nature of MAS interaction data. The framework's attribution results directly fuel an automated optimization loop, generating targeted suggestions whose efficacy is validated via counterfactual simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a significant leap in performance. Our method achieves up to 36.2\% step-level accuracy. Crucially, the generated optimizations boost overall task success rates by an average of 22.4\%. This work provides a principled and effective solution for debugging complex agent interactions, paving the way for more reliable and interpretable multi-agent systems. 

**Abstract (ZH)**: 多粒度因果推理导向的复杂代理系统故障归因框架 

---
# No-Knowledge Alarms for Misaligned LLMs-as-Judges 

**Title (ZH)**: 无知识警报以防止对齐偏差的LLM作为法官 

**Authors**: Andrés Corrada-Emmanuel  

**Link**: [PDF](https://arxiv.org/pdf/2509.08593)  

**Abstract**: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who or what monitors the judges? Infinite monitoring chains are inevitable whenever we do not know the ground truth of the decisions by experts and we do not want to trust them. One way to ameliorate our evaluation uncertainty is to exploit the use of logical consistency between disagreeing experts. By observing how LLM judges agree and disagree while grading other LLMs, we can compute the only possible evaluations of their grading ability. For example, if two LLM judges disagree on which tasks a third one completed correctly, they cannot both be 100\% correct in their judgments. This logic can be formalized as a Linear Programming problem in the space of integer response counts for any finite test. We use it here to develop no-knowledge alarms for misaligned LLM judges. The alarms can detect, with no false positives, that at least one member or more of an ensemble of judges are violating a user specified grading ability requirement. 

**Abstract (ZH)**: 如果使用LLMs作为裁判来评估其他LLMs的复杂决策，那么谁或什么来监督这些裁判？如果不了解专家决策的实际情况并且不信任他们，无限的监督链是不可避免的。通过利用分歧专家之间的一致性逻辑，我们可以通过观察LLM裁判在评估其他LLM时的分歧和一致来计算它们评判能力的唯一可能评估。例如，如果两个LLM裁判对于第三个裁判完成的任务有不同的评判，那么两者不可能都完全正确。这种逻辑可以形式化为整数响应计数在有限测试空间的线性规划问题。我们利用它来开发无知识的警报，以检测至少一个ensemble裁判违反用户指定的评判能力要求，而不产生误报。 

---
# TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making 

**Title (ZH)**: TCPO: 思维中心的偏好优化以实现有效的具身决策 

**Authors**: Kechen Jiao, Zhirui Fang, Jiahao Liu, Bei Li, Qifan Wang, Xinyu Liu, Junhao Ruan, Zhongjian Qiao, Yifan Zhu, Yaxin Xu, Jingang Wang, Xiu Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.08500)  

**Abstract**: Using effective generalization capabilities of vision language models (VLMs) in context-specific dynamic tasks for embodied artificial intelligence remains a significant challenge. Although supervised fine-tuned models can better align with the real physical world, they still exhibit sluggish responses and hallucination issues in dynamically changing environments, necessitating further alignment. Existing post-SFT methods, reliant on reinforcement learning and chain-of-thought (CoT) approaches, are constrained by sparse rewards and action-only optimization, resulting in low sample efficiency, poor consistency, and model degradation. To address these issues, this paper proposes Thought-Centric Preference Optimization (TCPO) for effective embodied decision-making. Specifically, TCPO introduces a stepwise preference-based optimization approach, transforming sparse reward signals into richer step sample pairs. It emphasizes the alignment of the model's intermediate reasoning process, mitigating the problem of model degradation. Moreover, by incorporating Action Policy Consistency Constraint (APC), it further imposes consistency constraints on the model output. Experiments in the ALFWorld environment demonstrate an average success rate of 26.67%, achieving a 6% improvement over RL4VLM and validating the effectiveness of our approach in mitigating model degradation after fine-tuning. These results highlight the potential of integrating preference-based learning techniques with CoT processes to enhance the decision-making capabilities of vision-language models in embodied agents. 

**Abstract (ZH)**: 使用视觉语言模型的有效泛化能力在特定上下文动态任务中实现本体人工智能仍是一项重大挑战。 

---
# Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives 

**Title (ZH)**: 合作者AI：更具智能与可信赖性的反洗钱合规叙事中的代理AI崛起 

**Authors**: Prathamesh Vasudeo Naik, Naresh Kumar Dintakurthi, Zhanghao Hu, Yue Wang, Robby Qiu  

**Link**: [PDF](https://arxiv.org/pdf/2509.08380)  

**Abstract**: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows. While large language models (LLMs) offer promising fluency, they suffer from factual hallucination, limited crime typology alignment, and poor explainability -- posing unacceptable risks in compliance-critical domains. This paper introduces Co-Investigator AI, an agentic framework optimized to produce Suspicious Activity Reports (SARs) significantly faster and with greater accuracy than traditional methods. Drawing inspiration from recent advances in autonomous agent architectures, such as the AI Co-Scientist, our approach integrates specialized agents for planning, crime type detection, external intelligence gathering, and compliance validation. The system features dynamic memory management, an AI-Privacy Guard layer for sensitive data handling, and a real-time validation agent employing the Agent-as-a-Judge paradigm to ensure continuous narrative quality assurance. Human investigators remain firmly in the loop, empowered to review and refine drafts in a collaborative workflow that blends AI efficiency with domain expertise. We demonstrate the versatility of Co-Investigator AI across a range of complex financial crime scenarios, highlighting its ability to streamline SAR drafting, align narratives with regulatory expectations, and enable compliance teams to focus on higher-order analytical work. This approach marks the beginning of a new era in compliance reporting -- bringing the transformative benefits of AI agents to the core of regulatory processes and paving the way for scalable, reliable, and transparent SAR generation. 

**Abstract (ZH)**: 生成符合监管要求的可疑活动报告（SAR）仍然是反洗钱（AML）工作流程中的高成本、低扩展性瓶颈。尽管大型语言模型（LLMs）提供了前景广阔的流畅性，但它们面临着事实性幻觉、犯罪类型匹配有限以及解释性较差等问题——这些都给合规关键领域带来了不可接受的风险。本文介绍了一种名为Co-Investigator AI的代理框架，该框架优化了生成可疑活动报告（SARs），显著提高了生成速度和准确性。该方法借鉴了最近在自主代理架构方面的进展，如AI合作者科学家，将专门的代理用于规划、犯罪类型检测、外部情报收集以及合规验证。该系统包括动态内存管理、AI隐私守护层用于敏感数据处理，以及采用代理作为法官模型的实时验证代理，以确保持续的故事叙述质量控制。人类调查人员仍保持在环中，通过结合AI效率和领域专业知识，在协作工作流程中进行审核和修订。本文展示了Co-Investigator AI在多种复杂金融犯罪场景中的适用性，突显了其简化SAR起草、与监管期望对齐叙述以及使合规团队能够专注于高级分析工作的能力。这种方法标志着合规报告新时代的开始——将AI代理的变革性优势引入监管流程的核心，并为可扩展、可靠和透明的SAR生成铺平了道路。 

---
# Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies 

**Title (ZH)**: 利用AI代理实现自主网络：一种参考架构与实证研究 

**Authors**: Binghan Wu, Shoufeng Wang, Yunxin Liu, Ya-Qin Zhang, Joseph Sifakis, Ye Ouyang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08312)  

**Abstract**: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a strategic inflection point in telecommunications, where networks must transcend reactive automation to achieve genuine cognitive capabilities--fulfilling TM Forum's vision of self-configuring, self-healing, and self-optimizing systems that deliver zero-wait, zero-touch, and zero-fault services. This work bridges the gap between architectural theory and operational reality by implementing Joseph Sifakis's AN Agent reference architecture in a functional cognitive system, deploying coordinated proactive-reactive runtimes driven by hybrid knowledge representation. Through an empirical case study of a Radio Access Network (RAN) Link Adaptation (LA) Agent, we validate this framework's transformative potential: demonstrating sub-10 ms real-time control in 5G NR sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for ultra-reliable services through dynamic Modulation and Coding Scheme (MCS) optimization. These improvements confirm the architecture's viability in overcoming traditional autonomy barriers and advancing critical L4-enabling capabilities toward next-generation objectives. 

**Abstract (ZH)**: L4 自动化网络向 Level 4 (L4) 演进：从反应性自动化到真正的认知能力——以无线电接入网络链路适配代理为例验证功能认知系统的潜在变革性 

---
# Real-world Music Plagiarism Detection With Music Segment Transcription System 

**Title (ZH)**: 基于音乐片段转录系统的现实世界音乐抄袭检测 

**Authors**: Seonghyeon Go  

**Link**: [PDF](https://arxiv.org/pdf/2509.08282)  

**Abstract**: As a result of continuous advances in Music Information Retrieval (MIR) technology, generating and distributing music has become more diverse and accessible. In this context, interest in music intellectual property protection is increasing to safeguard individual music copyrights. In this work, we propose a system for detecting music plagiarism by combining various MIR technologies. We developed a music segment transcription system that extracts musically meaningful segments from audio recordings to detect plagiarism across different musical formats. With this system, we compute similarity scores based on multiple musical features that can be evaluated through comprehensive musical analysis. Our approach demonstrated promising results in music plagiarism detection experiments, and the proposed method can be applied to real-world music scenarios. We also collected a Similar Music Pair (SMP) dataset for musical similarity research using real-world cases. The dataset are publicly available. 

**Abstract (ZH)**: 由于音乐信息检索（MIR）技术的不断进步，音乐的生成和分发变得更加多样化和易获取。在此背景下，对音乐知识产权保护的兴趣不断增加，以保障个人音乐版权。本文提出了一种结合多种MIR技术的音乐剽窃检测系统。我们开发了一种音乐片段转录系统，可以从音频记录中提取具有音乐意义的片段，以检测不同音乐格式之间的剽窃行为。借助此系统，我们可以根据综合音乐分析评估的多个音乐特征来计算相似性评分。我们的方法在音乐剽窃检测实验中取得了令人鼓舞的结果，并且提出的方案可以应用于实际音乐场景中。此外，我们还使用真实世界案例收集了一个音乐相似性配对（SMP）数据集，该数据集已公开。 

---
# Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following 

**Title (ZH)**: 探索性检索增强规划在持续体态指令跟随中的应用 

**Authors**: Minjong Yoo, Jinwoo Jang, Wei-jin Park, Honguk Woo  

**Link**: [PDF](https://arxiv.org/pdf/2509.08222)  

**Abstract**: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP) framework, designed to tackle continual instruction following tasks of embodied agents in dynamic, non-stationary environments. The framework enhances Large Language Models' (LLMs) embodied reasoning capabilities by efficiently exploring the physical environment and establishing the environmental context memory, thereby effectively grounding the task planning process in time-varying environment contexts. In ExRAP, given multiple continual instruction following tasks, each instruction is decomposed into queries on the environmental context memory and task executions conditioned on the query results. To efficiently handle these multiple tasks that are performed continuously and simultaneously, we implement an exploration-integrated task planning scheme by incorporating the {information-based exploration} into the LLM-based planning process. Combined with memory-augmented query evaluation, this integrated scheme not only allows for a better balance between the validity of the environmental context memory and the load of environment exploration, but also improves overall task performance. Furthermore, we devise a {temporal consistency refinement} scheme for query evaluation to address the inherent decay of knowledge in the memory. Through experiments with VirtualHome, ALFRED, and CARLA, our approach demonstrates robustness against a variety of embodied instruction following scenarios involving different instruction scales and types, and non-stationarity degrees, and it consistently outperforms other state-of-the-art LLM-based task planning approaches in terms of both goal success rate and execution efficiency. 

**Abstract (ZH)**: This study presents一个探索性检索增强规划（ExRAP）框架：针对动态非平稳环境中的持续指令跟随任务进行 embodied 理论推理能力的提升 

---
# Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI 

**Title (ZH)**: 基于记忆增强代理AI的信任语义精炼的合作者选择 

**Authors**: Botao Zhu, Jeslyn Wang, Dusit Niyato, Xianbin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08151)  

**Abstract**: Accurate trustworthiness evaluation of potential collaborating devices is essential for the effective execution of complex computing tasks. This evaluation process involves collecting diverse trust-related data from potential collaborators, including historical performance and available resources, for collaborator selection. However, when each task owner independently assesses all collaborators' trustworthiness, frequent data exchange, complex reasoning, and dynamic situation changes can result in significant overhead and deteriorated trust evaluation. To overcome these challenges, we propose a task-specific trust semantics distillation (2TSD) model based on a large AI model (LAM)-driven teacher-student agent architecture. The teacher agent is deployed on a server with powerful computational capabilities and an augmented memory module dedicated to multidimensional trust-related data collection, task-specific trust semantics extraction, and task-collaborator matching analysis. Upon receiving task-specific requests from device-side student agents, the teacher agent transfers the trust semantics of potential collaborators to the student agents, enabling rapid and accurate collaborator selection. Experimental results demonstrate that the proposed 2TSD model can reduce collaborator evaluation time, decrease device resource consumption, and improve the accuracy of collaborator selection. 

**Abstract (ZH)**: 基于大型AI模型驱动的教师-学生架构的任务特定信任语义蒸馏模型对于潜在协作设备的信任worthiness评估至关重要。该评估过程涉及从潜在合作者处收集多种信任相关数据，包括历史性能和可用资源，用于合作者选择。为克服这些挑战，我们提出了一种基于大型AI模型驱动的教师-学生代理架构的任务特定信任语义蒸馏（2TSD）模型。教师代理部署在具有强大计算能力和专用多维信任相关数据收集、任务特定信任语义提取和任务-合作者匹配分析扩展现存内存模块的服务器上。当收到设备端学生代理的任务特定请求时，教师代理将潜在合作者的信任语义传递给学生代理，从而实现快速准确的合作者选择。实验结果表明，所提出的2TSD模型可以减少合作者评估时间，降低设备资源消耗，并提高合作者选择的准确性。 

---
# EnvX: Agentize Everything with Agentic AI 

**Title (ZH)**: EnvX: 用代理型AI实现万物智能化 

**Authors**: Linyao Chen, Zimian Peng, Yingxuan Yang, Yikun Wang, Wenzheng Tom Tang, Hiroki H. Kobayashi, Weinan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08088)  

**Abstract**: The widespread availability of open-source repositories has led to a vast collection of reusable software components, yet their utilization remains manual, error-prone, and disconnected. Developers must navigate documentation, understand APIs, and write integration code, creating significant barriers to efficient software reuse. To address this, we present EnvX, a framework that leverages Agentic AI to agentize GitHub repositories, transforming them into intelligent, autonomous agents capable of natural language interaction and inter-agent collaboration. Unlike existing approaches that treat repositories as static code resources, EnvX reimagines them as active agents through a three-phase process: (1) TODO-guided environment initialization, which sets up the necessary dependencies, data, and validation datasets; (2) human-aligned agentic automation, allowing repository-specific agents to autonomously perform real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple agents to collaborate. By combining large language model capabilities with structured tool integration, EnvX automates not just code generation, but the entire process of understanding, initializing, and operationalizing repository functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18 repositories across domains such as image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX achieves a 74.07% execution completion rate and 51.85% task pass rate, outperforming existing frameworks. Case studies further demonstrate EnvX's ability to enable multi-repository collaboration via the A2A protocol. This work marks a shift from treating repositories as passive code resources to intelligent, interactive agents, fostering greater accessibility and collaboration within the open-source ecosystem. 

**Abstract (ZH)**: 开源仓库的广泛可用性导致了大量的可重用软件组件，然而其利用仍然手动、易出错且缺乏连接。开发人员必须导航文档、理解API并编写集成代码，这为高效软件重用设置了重大障碍。为解决这一问题，我们提出了EnvX框架，该框架利用Agentic AI技术将GitHub仓库转化为智能自主代理，能够进行自然语言交互和跨代理协作。与现有方法将仓库视为静态代码资源不同，EnvX通过三阶段过程重新定义了它们为活跃的代理：（1）基于TODO引导的环境初始化，设置必要的依赖、数据和验证集；（2）与人类一致的自主自动化，允许仓库特定的代理自动执行真实世界的任务；（3）代理到代理（A2A）协议，使多个代理能够协同工作。通过结合大型语言模型能力和结构化工具集成，EnvX不仅自动化了代码生成，还自动化了理解、初始化和运营仓库功能的整个过程。我们在GitTaskBench基准测试上评估了EnvX，使用了18个跨图像处理、语音识别、文档分析和视频操作等领域的仓库。结果显示，EnvX的执行完成率为74.07%，任务通过率为51.85%，优于现有框架。案例研究进一步证明了EnvX通过A2A协议实现多仓库协作的能力。这项工作标志着从将仓库视为被动代码资源到智能交互代理的转变，促进了开源生态系统中的更大访问性和协作。 

---
# Learning-Based Planning for Improving Science Return of Earth Observation Satellites 

**Title (ZH)**: 基于学习的规划方法以提高地球观测卫星的科学回报 

**Authors**: Abigail Breitfeld, Alberto Candela, Juan Delfa, Akseli Kangaslahti, Itai Zilberstein, Steve Chien, David Wettergreen  

**Link**: [PDF](https://arxiv.org/pdf/2509.07997)  

**Abstract**: Earth observing satellites are powerful tools for collecting scientific information about our planet, however they have limitations: they cannot easily deviate from their orbital trajectories, their sensors have a limited field of view, and pointing and operating these sensors can take a large amount of the spacecraft's resources. It is important for these satellites to optimize the data they collect and include only the most important or informative measurements. Dynamic targeting is an emerging concept in which satellite resources and data from a lookahead instrument are used to intelligently reconfigure and point a primary instrument. Simulation studies have shown that dynamic targeting increases the amount of scientific information gathered versus conventional sampling strategies. In this work, we present two different learning-based approaches to dynamic targeting, using reinforcement and imitation learning, respectively. These learning methods build on a dynamic programming solution to plan a sequence of sampling locations. We evaluate our approaches against existing heuristic methods for dynamic targeting, showing the benefits of using learning for this application. Imitation learning performs on average 10.0\% better than the best heuristic method, while reinforcement learning performs on average 13.7\% better. We also show that both learning methods can be trained effectively with relatively small amounts of data. 

**Abstract (ZH)**: 地球观测卫星是收集关于我们星球科学信息的强大工具，然而它们存在局限性：难以偏离轨道轨迹，传感器的视野有限，对这些传感器的操控和操作需要大量航天器资源。这些卫星需要优化它们收集的数据，仅包含最重要或最有信息量的测量。动态目标是指利用卫星资源和前瞻仪器的数据智能重新配置和瞄准主要仪器的一种新兴概念。模拟研究表明，动态目标采集的科学信息量大于传统的采样策略。在本工作中，我们分别使用强化学习和模仿学习提出了两种不同的动态目标方法。这些学习方法基于动态规划解决方案来规划一系列采样位置。我们将这些方法与现有动态目标方法进行了比较，展示了使用学习方法的益处。模仿学习平均比最佳启发式方法表现好10.0%，而强化学习平均好13.7%。我们还展示了这两种学习方法可以通过相对较小的数据量进行有效训练。 

---
# A Survey of Reinforcement Learning for Large Reasoning Models 

**Title (ZH)**: 大型推理模型中的强化学习综述 

**Authors**: Kaiyan Zhang, Yuxin Zuo, Bingxiang He, Youbang Sun, Runze Liu, Che Jiang, Yuchen Fan, Kai Tian, Guoli Jia, Pengfei Li, Yu Fu, Xingtai Lv, Yuchen Zhang, Sihang Zeng, Shang Qu, Haozhan Li, Shijie Wang, Yuru Wang, Xinwei Long, Fangfu Liu, Xiang Xu, Jiaze Ma, Xuekai Zhu, Ermo Hua, Yihao Liu, Zonglin Li, Huayu Chen, Xiaoye Qu, Yafu Li, Weize Chen, Zhenzhao Yuan, Junqi Gao, Dong Li, Zhiyuan Ma, Ganqu Cui, Zhiyuan Liu, Biqing Qi, Ning Ding, Bowen Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.08827)  

**Abstract**: In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Models (LLMs). RL has achieved remarkable success in advancing the frontier of LLM capabilities, particularly in addressing complex logical tasks such as mathematics and coding. As a result, RL has emerged as a foundational methodology for transforming LLMs into LRMs. With the rapid progress of the field, further scaling of RL for LRMs now faces foundational challenges not only in computational resources but also in algorithm design, training data, and infrastructure. To this end, it is timely to revisit the development of this domain, reassess its trajectory, and explore strategies to enhance the scalability of RL toward Artificial SuperIntelligence (ASI). In particular, we examine research applying RL to LLMs and LRMs for reasoning abilities, especially since the release of DeepSeek-R1, including foundational components, core problems, training resources, and downstream applications, to identify future opportunities and directions for this rapidly evolving area. We hope this review will promote future research on RL for broader reasoning models. Github: this https URL 

**Abstract (ZH)**: 本文综述了强化学习（RL）在与大规模语言模型（LLMs）推理方面的近期进展。RL已在提升LLM能力方面取得了显著成功，尤其是在解决复杂的逻辑任务（如数学和编程）方面。因此，RL已成为了将LLMs转化为逻辑推理模型（LRMs）的基础方法之一。随着该领域迅速进步，进一步扩展RL对LRMs的应用正面临基础性挑战，不仅在计算资源方面，也在算法设计、训练数据和基础设施方面。为此，及时回顾该领域的开发历程、重新评估其发展轨迹，并探索增强RL可扩展性的策略以促进人工超级智能（ASI）的发展是及时的。特别地，我们探讨了RL在LLMs和LRMs推理能力上的应用，特别是在DeepSeek-R1发布之后的研究，包括基础组件、核心问题、训练资源和下游应用，以识别这一快速发展的领域中的未来机会和方向。我们希望此次回顾能促进对更广泛推理模型的RL研究。Github：https://this.url 

---
# Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation 

**Title (ZH)**: 大型语言模型破解：衡量使用LLMs进行文本标注的潜在风险 

**Authors**: Joachim Baumann, Paul Röttger, Aleksandra Urman, Albert Wendsjö, Flor Miriam Plaza-del-Arco, Johannes B. Gruber, Dirk Hovy  

**Link**: [PDF](https://arxiv.org/pdf/2509.08825)  

**Abstract**: Large language models (LLMs) are rapidly transforming social science research by enabling the automation of labor-intensive tasks like data annotation and text analysis. However, LLM outputs vary significantly depending on the implementation choices made by researchers (e.g., model selection, prompting strategy, or temperature settings). Such variation can introduce systematic biases and random errors, which propagate to downstream analyses and cause Type I, Type II, Type S, or Type M errors. We call this LLM hacking.
We quantify the risk of LLM hacking by replicating 37 data annotation tasks from 21 published social science research studies with 18 different models. Analyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure how plausible researcher choices affect statistical conclusions. We find incorrect conclusions based on LLM-annotated data in approximately one in three hypotheses for state-of-the-art models, and in half the hypotheses for small language models. While our findings show that higher task performance and better general model capabilities reduce LLM hacking risk, even highly accurate models do not completely eliminate it. The risk of LLM hacking decreases as effect sizes increase, indicating the need for more rigorous verification of findings near significance thresholds. Our extensive analysis of LLM hacking mitigation techniques emphasizes the importance of human annotations in reducing false positive findings and improving model selection. Surprisingly, common regression estimator correction techniques are largely ineffective in reducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors.
Beyond accidental errors, we find that intentional LLM hacking is unacceptably simple. With few LLMs and just a handful of prompt paraphrases, anything can be presented as statistically significant. 

**Abstract (ZH)**: 大型语言模型（LLMs）通过自动化数据标注和文本分析等劳动密集型任务，迅速改变着社会科学研究。然而，LLM输出会因研究人员实施的选择（如模型选择、提示策略或温度设置）而显著变化。这种变化可引入系统偏差和随机错误，传播到下游分析中并导致第一类、第二类、S型或M型错误。我们称之为LLM黑客攻击。

我们通过使用18种不同的模型复制21项已发表的社会科学研究中的37项数据标注任务，量化LLM黑客攻击的风险。分析1300万LLM标签，测试2361个现实假设，以衡量研究者选择的合理性对统计结论的影响。结果显示，对于最新模型而言，大约三分之一的假设基于LLM标注数据得出错误结论；而对于小型语言模型，这一比例达到一半。我们的研究显示，更高的任务性能和更好的通用模型能力可以减少LLM黑客攻击的风险，但即使是非常准确的模型也无法完全消除这种风险。随着效应大小的增加，LLM黑客攻击风险降低，表明在显著性阈值附近需要更严格的验证。我们对LLM黑客攻击缓解技术的广泛分析强调了手工标注在减少假阳性发现和改进模型选择中的重要性。令人惊讶的是，常见的回归估计校正技术在减少LLM黑客攻击风险方面效果有限，因为它们严重权衡了第一类和第二类错误。

有意的LLM黑客攻击出乎意料地简单。只要有少量的LLM和少量的提示变形，任何内容都可以被呈现为具有统计显著性。 

---
# QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction 

**Title (ZH)**: QCardEst/QCardCorr: 量子计数估计与校正 

**Authors**: Tobias Winker, Jinghua Groppe, Sven Groppe  

**Link**: [PDF](https://arxiv.org/pdf/2509.08817)  

**Abstract**: Cardinality estimation is an important part of query optimization in DBMS. We develop a Quantum Cardinality Estimation (QCardEst) approach using Quantum Machine Learning with a Hybrid Quantum-Classical Network. We define a compact encoding for turning SQL queries into a quantum state, which requires only qubits equal to the number of tables in the query. This allows the processing of a complete query with a single variational quantum circuit (VQC) on current hardware. In addition, we compare multiple classical post-processing layers to turn the probability vector output of VQC into a cardinality value. We introduce Quantum Cardinality Correction QCardCorr, which improves classical cardinality estimators by multiplying the output with a factor generated by a VQC to improve the cardinality estimation. With QCardCorr, we have an improvement over the standard PostgreSQL optimizer of 6.37 times for JOB-light and 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of 3.47. 

**Abstract (ZH)**: 量子基数估计是数据库管理系统中查询优化的重要组成部分。我们提出了一种基于混合量子-经典网络的量子基数估计（QCardEst）方法。我们定义了一种紧凑的编码方式，将SQL查询转换为量子态，所需量子位数等于查询中的表数。这使得当前硬件可以通过单一变量子量子电路（VQC）处理完整查询。此外，我们比较了多种经典后处理层，将VQC输出的概率向量转换为基数值。我们引入了量子基数校正（QCardCorr），通过使用VQC生成的因子乘以输出来改进经典基数估计器，从而提高基数估计的准确性。借助QCardCorr，我们标准PostgreSQL优化器在JOB-light上的性能提升6.37倍，在STATS上的提升8.66倍。对于JOB-light，我们甚至超越了MSCN 3.47倍。 

---
# Merge-of-Thought Distillation 

**Title (ZH)**: 思维融合蒸馏 

**Authors**: Zhanming Shen, Zeyu Qin, Zenan Huang, Hao Chen, Jiaqi Hu, Yihong Zhuang, Guoshan Lu, Gang Chen, Junbo Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2509.08814)  

**Abstract**: Efficient reasoning distillation for long chain-of-thought (CoT) models is increasingly constrained by the assumption of a single oracle teacher, despite practical availability of multiple candidate teachers and growing CoT corpora. We revisit teacher selection and observe that different students have different "best teachers," and even for the same student the best teacher can vary across datasets. Therefore, to unify multiple teachers' reasoning abilities into student with overcoming conflicts among various teachers' supervision, we propose Merge-of-Thought Distillation (MoT), a lightweight framework that alternates between teacher-specific supervised fine-tuning branches and weight-space merging of the resulting student variants. On competition math benchmarks, using only about 200 high-quality CoT samples, applying MoT to a Qwen3-14B student surpasses strong models including DEEPSEEK-R1, QWEN3-30B-A3B, QWEN3-32B, and OPENAI-O1, demonstrating substantial gains. Besides, MoT consistently outperforms the best single-teacher distillation and the naive multi-teacher union, raises the performance ceiling while mitigating overfitting, and shows robustness to distribution-shifted and peer-level teachers. Moreover, MoT reduces catastrophic forgetting, improves general reasoning beyond mathematics and even cultivates a better teacher, indicating that consensus-filtered reasoning features transfer broadly. These results position MoT as a simple, scalable route to efficiently distilling long CoT capabilities from diverse teachers into compact students. 

**Abstract (ZH)**: 高效推理蒸馏长链思考（CoT）模型逐渐受限于单一 oracle 教师的假设，尽管存在多个候选教师的实际可用性和日益增长的 CoT 数据集。我们重新审视教师选择，并观察到不同的学生有不同的“最佳教师”，即使是同一个学生，在不同的数据集上最佳教师也可能不同。因此，为了通过克服各种教师监督之间的冲突，将多种教师的推理能力统一到学生中，我们提出了一种轻量级框架 Merge-of-Thought 蒸馏（MoT），该框架交替进行特定教师的监督微调分支和结果学生变体的权重空间合并。在竞争数学基准测试中，仅使用大约 200 个高质量的 CoT 样本，将 MoT 应用于 Qwen3-14B 学生，超过了包括 DEEPSEEK-R1、QWEN3-30B-A3B、QWEN3-32B 和 OPENAI-O1 在内的强模型，显示出显著的性能提升。此外，MoT 一贯优于最佳单一教师蒸馏和简单的多教师合集，提高了性能上限，缓解了过拟合，并对分布转移和同级教师表现出鲁棒性。此外，MoT 减少了灾难性遗忘，提高了超出数学的一般推理能力，并培养了一个更好的教师，这表明过滤后的推理特征广泛转移。这些结果将 MoT 作为一个简单且可扩展的途径，有效将多样的教师长 CoT 能力蒸馏到紧凑的学生中。 

---
# MoVoC: Morphology-Aware Subword Construction for Geez Script Languages 

**Title (ZH)**: MoVoC: 元音意识子词构建方法 for Geez脚本语言 

**Authors**: Hailay Kidu Teklehaymanot, Dren Fazlija, Wolfgang Nejdl  

**Link**: [PDF](https://arxiv.org/pdf/2509.08812)  

**Abstract**: Subword-based tokenization methods often fail to preserve morphological boundaries, a limitation especially pronounced in low-resource, morphologically complex languages such as those written in the Geez script. To address this, we present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into the subword vocabulary. This hybrid segmentation approach combines morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological integrity while maintaining lexical meaning. To tackle resource scarcity, we curate and release manually annotated morpheme data for four Geez script languages and a morpheme-aware vocabulary for two of them. While the proposed tokenization method does not lead to significant gains in automatic translation quality, we observe consistent improvements in intrinsic metrics, MorphoScore, and Boundary Precision, highlighting the value of morphology-aware segmentation in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated datasets and tokenizer will be publicly available to support further research in low-resource, morphologically rich languages. Our code and data are available on GitHub: this https URL 

**Abstract (ZH)**: 基于子词的分词方法往往无法保留形态边界，在象形文字等低资源且形态复杂的语言中，这一局限尤为明显。为此，我们提出了一种形态意识子词词表构建方法MoVoC，并训练了MoVoC-Tok分词器，该分词器将监督形态分析集成到子词词表中。这种混合分段方法结合了形态学子词和字节对编码(BPE)子词，以保持形态完整性和保留词汇意义。为应对资源匮乏，我们收集并发布了四种象形文字语言的手工标注形态学数据，并为其中两种语言构建了形态意识词汇表。虽然所提出的分词方法在自动翻译质量上未取得显著提升，但在内在测评指标、MorphoScore和边界精确度方面观察到了一致的提升，突显了形态意识分段在提高语言忠实度和子词效率方面的价值。我们的形态学标注数据集和分词器将公开发布，以支持低资源且形态丰富的语言研究。我们的代码和数据已发布在GitHub：this https URL 

---
# Scaling Truth: The Confidence Paradox in AI Fact-Checking 

**Title (ZH)**: 扩增真实性：AI事实核查中的置信度悖论 

**Authors**: Ihsan A. Qazi, Zohaib Khan, Abdullah Ghani, Agha A. Raza, Zafar A. Qazi, Wassay Sajjad, Ayesha Ali, Asher Javaid, Muhammad Abdullah Sohail, Abdul H. Azeemi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08803)  

**Abstract**: The rise of misinformation underscores the need for scalable and reliable fact-checking solutions. Large language models (LLMs) hold promise in automating fact verification, yet their effectiveness across global contexts remains uncertain. We systematically evaluate nine established LLMs across multiple categories (open/closed-source, multiple sizes, diverse architectures, reasoning-based) using 5,000 claims previously assessed by 174 professional fact-checking organizations across 47 languages. Our methodology tests model generalizability on claims postdating training cutoffs and four prompting strategies mirroring both citizen and professional fact-checker interactions, with over 240,000 human annotations as ground truth. Findings reveal a concerning pattern resembling the Dunning-Kruger effect: smaller, accessible models show high confidence despite lower accuracy, while larger models demonstrate higher accuracy but lower confidence. This risks systemic bias in information verification, as resource-constrained organizations typically use smaller models. Performance gaps are most pronounced for non-English languages and claims originating from the Global South, threatening to widen existing information inequalities. These results establish a multilingual benchmark for future research and provide an evidence base for policy aimed at ensuring equitable access to trustworthy, AI-assisted fact-checking. 

**Abstract (ZH)**: 错误信息的兴起强调了需要可扩展且可靠的事实核查解决方案。大规模语言模型（LLMs）在自动化事实验证方面具有潜力，但在全球不同 contexts 中的有效性仍不确定。我们使用来自174家专业事实核查组织的47种语言、174家专业事实核查组织评估过的5000个断言，系统性地评估了九种已建立的LLMs。评估涵盖多个类别（开源/闭源、不同规模、多样化架构、基于推理），采用四种模仿公民和专业事实核查者互动的提示策略，并以超过240,000个人工注释作为基准。研究发现揭示了一个令人担忧的趋势，类似于邓宁-克鲁格效应：较小且易于访问的模型尽管准确率较低但却表现出高信心，而较大的模型则表现出较高的准确率但较低的信心。这可能在信息验证中产生系统性偏见，因为资源受限的组织通常使用较小的模型。性能差距在非英语语言和起源于全球南方的断言中最为明显，这威胁到现有的信息不平等现象的扩大。这些结果为未来研究建立了一个多语言基准，并为确保公平访问可信赖的人工智能辅助事实核查提供了证据基础。 

---
# PianoVAM: A Multimodal Piano Performance Dataset 

**Title (ZH)**: PianoVAM：一种多模态钢琴表演数据集 

**Authors**: Yonghyun Kim, Junhyung Park, Joonhyung Bae, Kirak Kim, Taegyun Kwon, Alexander Lerch, Juhan Nam  

**Link**: [PDF](https://arxiv.org/pdf/2509.08800)  

**Abstract**: The multimodal nature of music performance has driven increasing interest in data beyond the audio domain within the music information retrieval (MIR) community. This paper introduces PianoVAM, a comprehensive piano performance dataset that includes videos, audio, MIDI, hand landmarks, fingering labels, and rich metadata. The dataset was recorded using a Disklavier piano, capturing audio and MIDI from amateur pianists during their daily practice sessions, alongside synchronized top-view videos in realistic and varied performance conditions. Hand landmarks and fingering labels were extracted using a pretrained hand pose estimation model and a semi-automated fingering annotation algorithm. We discuss the challenges encountered during data collection and the alignment process across different modalities. Additionally, we describe our fingering annotation method based on hand landmarks extracted from videos. Finally, we present benchmarking results for both audio-only and audio-visual piano transcription using the PianoVAM dataset and discuss additional potential applications. 

**Abstract (ZH)**: 多模态音乐表演的性质推动了音乐信息检索领域对音频以外数据的兴趣增加。本文介绍了PianoVAM，这是一个全面的钢琴表演数据集，包括视频、音频、MIDI、手部关键点、指法标签和丰富的元数据。数据集使用Disklavier钢琴录制，捕捉了业余钢琴演奏者在日常练习期间的音频和MIDI，并伴有同步的顶部视角视频，所有这些都处于实际多样化的表演条件下。手部关键点和指法标签通过预训练的手部姿态估计模型和半自动的指法标注算法提取。我们讨论了数据收集和不同模态之间对齐过程中遇到的挑战，并描述了我们基于视频中提取的手部关键点的指法标注方法，最后，我们使用PianoVAM数据集展示了仅音频和音频-视觉钢琴转录的基准测试结果，并讨论了其他潜在应用。 

---
# An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images 

**Title (ZH)**: 基于移动设备拍摄皮肤图像的端到端深度学习框架用于砷中毒诊断 

**Authors**: Asif Newaz, Asif Ur Rahman Adib, Rajit Sahil, Mashfique Mehzad  

**Link**: [PDF](https://arxiv.org/pdf/2509.08780)  

**Abstract**: Background: Arsenicosis is a serious public health concern in South and Southeast Asia, primarily caused by long-term consumption of arsenic-contaminated water. Its early cutaneous manifestations are clinically significant but often underdiagnosed, particularly in rural areas with limited access to dermatologists. Automated, image-based diagnostic solutions can support early detection and timely interventions.
Methods: In this study, we propose an end-to-end framework for arsenicosis diagnosis using mobile phone-captured skin images. A dataset comprising 20 classes and over 11000 images of arsenic-induced and other dermatological conditions was curated. Multiple deep learning architectures, including convolutional neural networks (CNNs) and Transformer-based models, were benchmarked for arsenicosis detection. Model interpretability was integrated via LIME and Grad-CAM, while deployment feasibility was demonstrated through a web-based diagnostic tool.
Results: Transformer-based models significantly outperformed CNNs, with the Swin Transformer achieving the best results (86\\% accuracy). LIME and Grad-CAM visualizations confirmed that the models attended to lesion-relevant regions, increasing clinical transparency and aiding in error analysis. The framework also demonstrated strong performance on external validation samples, confirming its ability to generalize beyond the curated dataset.
Conclusion: The proposed framework demonstrates the potential of deep learning for non-invasive, accessible, and explainable diagnosis of arsenicosis from mobile-acquired images. By enabling reliable image-based screening, it can serve as a practical diagnostic aid in rural and resource-limited communities, where access to dermatologists is scarce, thereby supporting early detection and timely intervention. 

**Abstract (ZH)**: 背景：砷中毒是南亚和东南亚地区的一个严重公共健康问题，主要由长期摄入含砷地下水引起。其早期皮肤表现具有临床意义但往往被误诊，尤其是在缺乏皮肤科医生的农村地区。基于图像的自动化诊断解决方案可以支持早期检测和及时干预。

方法：本研究提出了一种端到端框架，利用手机拍摄的皮肤图像进行砷中毒诊断。构建了一个包含20个类别和超过11000张由砷引发和其他皮肤病情况组成的数据集。对比了多种深度学习架构，包括卷积神经网络（CNNs）和Transformer基模型，以评估其在砷中毒检测方面的性能。通过LIME和Grad-CAM集成模型可解释性，并通过基于Web的诊断工具展示了其部署可行性。

结果：基于Transformer的模型显著优于CNNs，其中Swin Transformer达到最佳结果（准确率86%）。LIME和Grad-CAM可视化显示模型关注于病灶相关区域，增加了临床透明度并有助于错误分析。该框架在外部验证样本上也表现出强烈性能，证实了其超越所构建数据集的能力。

结论：所提出的框架展示了深度学习在利用移动收购图像进行非侵入性、可访问性和可解释性砷中毒诊断方面的潜力。通过实现可靠的基于图像的筛查，它可以在缺乏皮肤科医生的农村和资源有限的社区中作为实用的诊断辅助工具，从而支持早期检测和及时干预。 

---
# Using AI to Optimize Patient Transfer and Resource Utilization During Mass-Casualty Incidents: A Simulation Platform 

**Title (ZH)**: 使用AI优化大规模伤亡事件中患者转移和资源利用：一个模拟平台 

**Authors**: Zhaoxun "Lorenz" Liu, Wagner H. Souza, Jay Han, Amin Madani  

**Link**: [PDF](https://arxiv.org/pdf/2509.08756)  

**Abstract**: Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid, accurate patient-hospital allocation decisions under extreme pressure. Here, we developed and validated a deep reinforcement learning-based decision-support AI agent to optimize patient transfer decisions during simulated MCIs by balancing patient acuity levels, specialized care requirements, hospital capacities, and transport logistics. To integrate this AI agent, we developed MasTER, a web-accessible command dashboard for MCI management simulations. Through a controlled user study with 30 participants (6 trauma experts and 24 non-experts), we evaluated three interaction approaches with the AI agent (human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI scenarios in the Greater Toronto Area. Results demonstrate that increasing AI involvement significantly improves decision quality and consistency. The AI agent outperforms trauma surgeons (p < 0.001) and enables non-experts to achieve expert-level performance when assisted, contrasting sharply with their significantly inferior unassisted performance (p < 0.001). These findings establish the potential for our AI-driven decision support to enhance both MCI preparedness training and real-world emergency response management. 

**Abstract (ZH)**: 大规模伤亡事件中的医疗救护系统面临 overwhelmed 的挑战，需要在极端压力下做出快速而准确的患者-医院分配决策。为此，我们开发并验证了一种基于深度强化学习的决策支持人工智能代理，以优化模拟大规模伤亡事件中的患者转运决策，平衡患者紧迫性等级、专科护理需求、医院容量和运输物流。为此，我们开发了 MasTER，一种网页可访问的命令控制仪表板，用于大规模伤亡事件管理模拟。通过一项受控用户研究，涉及 30 名参与者（6 名创伤专家和 24 名非专家），我们在多伦多大都市区 20 例和 60 例患者的大规模伤亡事件情景中评估了与人工智能代理交互的三种方法（仅人类、人类-人工智能合作以及仅人工智能）的表现。结果显示，增加人工智能的参与显著提高了决策质量和一致性。该人工智能代理在统计学上显著优于创伤外科医生（p < 0.001），并在协助下使非专家达到专家水平的表现，与他们未经协助的显著较差表现形成鲜明对比（p < 0.001）。这些发现确立了我们的人工智能驱动决策支持在增强大规模伤亡事件应急准备训练和实际应急响应管理方面潜力。 

---
# AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning 

**Title (ZH)**: AgentGym-RL：通过多轮强化学习训练LLM代理进行长期决策 

**Authors**: Zhiheng Xi, Jixuan Huang, Chenyang Liao, Baodai Huang, Honglin Guo, Jiaqi Liu, Rui Zheng, Junjie Ye, Jiazheng Zhang, Wenxiang Chen, Wei He, Yiwen Ding, Guanyu Li, Zehui Chen, Zhengyin Du, Xuesong Yao, Yufei Xu, Jiecao Chen, Tao Gui, Zuxuan Wu, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08755)  

**Abstract**: Developing autonomous LLM agents capable of making a series of intelligent decisions to solve complex, real-world tasks is a fast-evolving frontier. Like human cognitive development, agents are expected to acquire knowledge and skills through exploration and interaction with the environment. Despite advances, the community still lacks a unified, interactive reinforcement learning (RL) framework that can effectively train such agents from scratch -- without relying on supervised fine-tuning (SFT) -- across diverse and realistic environments. To bridge this gap, we introduce AgentGym-RL, a new framework to train LLM agents for multi-turn interactive decision-making through RL. The framework features a modular and decoupled architecture, ensuring high flexibility and extensibility. It encompasses a wide variety of real-world scenarios, and supports mainstream RL algorithms. Furthermore, we propose ScalingInter-RL, a training approach designed for exploration-exploitation balance and stable RL optimization. In early stages, it emphasizes exploitation by restricting the number of interactions, and gradually shifts towards exploration with larger horizons to encourage diverse problem-solving strategies. In this way, the agent develops more diverse behaviors and is less prone to collapse under long horizons. We perform extensive experiments to validate the stability and effectiveness of both the AgentGym-RL framework and the ScalingInter-RL approach. Our agents match or surpass commercial models on 27 tasks across diverse environments. We offer key insights and will open-source the complete AgentGym-RL framework -- including code and datasets -- to empower the research community in developing the next generation of intelligent agents. 

**Abstract (ZH)**: 开发能够在多样且真实的环境中自主做出一系列智能决策的LLM代理是快速发展的前沿领域。为了填补这一空白，我们引入了AgentGym-RL框架，这是一种用于通过强化学习（RL）训练LLM代理进行多轮交互决策的新框架。该框架具有模块化和解耦的架构，确保了高度的灵活性和扩展性。它涵盖了广泛的现实场景，并支持主流的RL算法。此外，我们提出了ScalingInter-RL训练方法，以平衡探索与利用，并实现稳定的学习优化。在早期阶段，它通过限制交互次数强调利用，随着探索视野的扩大逐渐转向探索，以鼓励多样化的解题策略。这样，代理人能够发展出更多样化的行为，并且在长时间范围内不易崩溃。我们进行了广泛的实验来验证AgentGym-RL框架和ScalingInter-RL方法的稳定性和有效性。我们的代理在多种环境中的27项任务上与商用模型持平或超越了它们。我们将提供关键见解并开源完整的AgentGym-RL框架（包括代码和数据集），以助力研究社区开发下一代智能代理。 

---
# Learning Turbulent Flows with Generative Models: Super-resolution, Forecasting, and Sparse Flow Reconstruction 

**Title (ZH)**: 使用生成模型学习湍流：超分辨率、预测和稀疏流场重建 

**Authors**: Vivek Oommen, Siavash Khodakarami, Aniruddha Bora, Zhicheng Wang, George Em Karniadakis  

**Link**: [PDF](https://arxiv.org/pdf/2509.08752)  

**Abstract**: Neural operators are promising surrogates for dynamical systems but when trained with standard L2 losses they tend to oversmooth fine-scale turbulent structures. Here, we show that combining operator learning with generative modeling overcomes this limitation. We consider three practical turbulent-flow challenges where conventional neural operators fail: spatio-temporal super-resolution, forecasting, and sparse flow reconstruction. For Schlieren jet super-resolution, an adversarially trained neural operator (adv-NO) reduces the energy-spectrum error by 15x while preserving sharp gradients at neural operator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO trained on only 160 timesteps from a single trajectory forecasts accurately for five eddy-turnover times and offers 114x wall-clock speed-up at inference than the baseline diffusion-based forecasters, enabling near-real-time rollouts. For reconstructing cylinder wake flows from highly sparse Particle Tracking Velocimetry-like inputs, a conditional generative model infers full 3D velocity and pressure fields with correct phase alignment and statistics. These advances enable accurate reconstruction and forecasting at low compute cost, bringing near-real-time analysis and control within reach in experimental and computational fluid mechanics. See our project page: this https URL 

**Abstract (ZH)**: 神经算子是对流系统有前景的替代方案，但当使用标准的L2损失进行训练时，它们往往会过度平滑精细的湍流结构。本文表明，将算子学习与生成建模相结合可以克服这一局限性。我们考虑了三个传统神经算子无法解决的湍流流动挑战：时空超分辨率、预报和稀疏流场重构。对于Schlieren射流超分辨率，对抗训练的神经算子（adv-NO）将能量谱误差降低了15倍，同时保留了类似神经算子的推理成本的锐利梯度。对于全方位各向同性湍流，基于单个轨迹160个时间步长对adv-NO进行训练，可在五涡旋周转时间内进行准确的预报，并提供比基线基于扩散的预报器114倍的推理时间加速，从而实现近实时的滚动预测。对于从高度稀疏的类似于粒子追踪 velocimetry 的输入重构圆柱尾流流动，条件生成模型推断出完整的3D速度和压力场，具有正确的相位对齐和统计数据。这些进步使得在低计算成本下实现准确的重构和预报成为可能，将近实时分析和控制带入实验和计算流体力学之中。请参见我们的项目页面：this https URL 

---
# FinZero: Launching Multi-modal Financial Time Series Forecast with Large Reasoning Model 

**Title (ZH)**: FinZero: 基于大规模推理模型的多模态金融时间序列预测 

**Authors**: Yanlong Wang, Jian Xu, Fei Ma, Hongkang Zhang, Hang Yu, Tiantian Gao, Yu Wang, Haochen You, Shao-Lun Huang, Danny Dongning Sun, Xiao-Ping Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08742)  

**Abstract**: Financial time series forecasting is both highly significant and challenging. Previous approaches typically standardized time series data before feeding it into forecasting models, but this encoding process inherently leads to a loss of important information. Moreover, past time series models generally require fixed numbers of variables or lookback window lengths, which further limits the scalability of time series forecasting. Besides, the interpretability and the uncertainty in forecasting remain areas requiring further research, as these factors directly impact the reliability and practical value of predictions. To address these issues, we first construct a diverse financial image-text dataset (FVLDB) and develop the Uncertainty-adjusted Group Relative Policy Optimization (UARPO) method to enable the model not only output predictions but also analyze the uncertainty of those predictions. We then proposed FinZero, a multimodal pre-trained model finetuned by UARPO to perform reasoning, prediction, and analytical understanding on the FVLDB financial time series. Extensive experiments validate that FinZero exhibits strong adaptability and scalability. After fine-tuning with UARPO, FinZero achieves an approximate 13.48\% improvement in prediction accuracy over GPT-4o in the high-confidence group, demonstrating the effectiveness of reinforcement learning fine-tuning in multimodal large model, including in financial time series forecasting tasks. 

**Abstract (ZH)**: 金融时间序列预测既重要又具有挑战性。为了应对这些问题，我们首先构建了一个多元金融图像-文本数据集（FVLDB），并开发了不确定性调整的组相对策略优化（UARPO）方法，使模型不仅能输出预测结果，还能分析这些预测结果的不确定性。我们随后提出了FinZero，这是一种通过UARPO微调的多模态预训练模型，能够在FVLDB金融时间序列上进行推理、预测和分析理解。 extensive实验验证了FinZero的强大适应性和扩展性。通过UARPO微调后，FinZero在高置信度组中的预测准确率相较于GPT-4o提高了约13.48%，表明增强学习微调在多模态大型模型中的有效性，包括金融时间序列预测任务中。 

---
# DEQuify your force field: More efficient simulations using deep equilibrium models 

**Title (ZH)**: 使用深平衡模型提高force field模拟效率 

**Authors**: Andreas Burger, Luca Thiede, Alán Aspuru-Guzik, Nandita Vijaykumar  

**Link**: [PDF](https://arxiv.org/pdf/2509.08734)  

**Abstract**: Machine learning force fields show great promise in enabling more accurate molecular dynamics simulations compared to manually derived ones. Much of the progress in recent years was driven by exploiting prior knowledge about physical systems, in particular symmetries under rotation, translation, and reflections. In this paper, we argue that there is another important piece of prior information that, thus fa,r hasn't been explored: Simulating a molecular system is necessarily continuous, and successive states are therefore extremely similar. Our contribution is to show that we can exploit this information by recasting a state-of-the-art equivariant base model as a deep equilibrium model. This allows us to recycle intermediate neural network features from previous time steps, enabling us to improve both accuracy and speed by $10\%-20\%$ on the MD17, MD22, and OC20 200k datasets, compared to the non-DEQ base model. The training is also much more memory efficient, allowing us to train more expressive models on larger systems. 

**Abstract (ZH)**: 机器学习力场通过将最先进的对称性基模型重新表述为深层平衡模型，展示了相较于手动构建的模型在进行更准确的分子动力学模拟方面的巨大潜力。这一信息尚未成系统地利用，即分子系统模拟必然是连续的，因此相继状态极其相似。我们的贡献是通过利用这一信息，我们展示了如何将最先进的对称性基模型重新表述为深层平衡模型。这使我们能够回收之前时间步的中间神经网络特征，从而在MD17、MD22和OC20 200k数据集上将准确性和速度分别提高10%-20%，并且训练更加内存高效，允许我们在更大系统上训练更具表现力的模型。 

---
# X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to Single-turn Jailbreak Templates 

**Title (ZH)**: X-Teaming 进化型 M2S：自动发现多轮转单轮漏洞模板 

**Authors**: Hyunjun Kim, Junwoo Ha, Sangyoon Yu, Haon Park  

**Link**: [PDF](https://arxiv.org/pdf/2509.08729)  

**Abstract**: Multi-turn-to-single-turn (M2S) compresses iterative red-teaming into one structured prompt, but prior work relied on a handful of manually written templates. We present X-Teaming Evolutionary M2S, an automated framework that discovers and optimizes M2S templates through language-model-guided evolution. The system pairs smart sampling from 12 sources with an LLM-as-judge inspired by StrongREJECT and records fully auditable logs.
Maintaining selection pressure by setting the success threshold to $\theta = 0.70$, we obtain five evolutionary generations, two new template families, and 44.8% overall success (103/230) on GPT-4.1. A balanced cross-model panel of 2,500 trials (judge fixed) shows that structural gains transfer but vary by target; two models score zero at the same threshold. We also find a positive coupling between prompt length and score, motivating length-aware judging.
Our results demonstrate that structure-level search is a reproducible route to stronger single-turn probes and underscore the importance of threshold calibration and cross-model evaluation. Code, configurations, and artifacts are available at this https URL. 

**Abstract (ZH)**: 多轮对话到单轮对话（M2S）压缩迭代红队行动为一个结构化提示，但先前的工作依赖于少量的手动编写模板。我们提出了X-Teaming演化M2S，这是一种通过语言模型引导进化的自动化框架，该框架发现并优化M2S模板。系统结合了12个来源的智能采样与借鉴StrongREJECT的LLM-as-judge，并记录了可完全审计的日志。通过将成功阈值设置为θ=0.70来维持选择压力，我们获得了五个演化代、两个新的模板家族以及在GPT-4上44.8%的整体成功率（103/230）。通过均衡的跨模型面板（评审员固定）2,500次试验显示，结构增益可转移但因目标而异；两个模型在相同阈值下得分为零。我们还发现提示长度与评分之间存在正向耦合，这促成了对长度感知的评审动机。我们的结果表明结构级别搜索是生成更强的单轮探针的可重复途径，并强调了阈值校准和跨模型评估的重要性。代码、配置和构件可通过以下链接获得。 

---
# Explainability of CNN Based Classification Models for Acoustic Signal 

**Title (ZH)**: 基于CNN的声学信号分类模型的可解释性 

**Authors**: Zubair Faruqui, Mackenzie S. McIntire, Rahul Dubey, Jay McEntee  

**Link**: [PDF](https://arxiv.org/pdf/2509.08717)  

**Abstract**: Explainable Artificial Intelligence (XAI) has emerged as a critical tool for interpreting the predictions of complex deep learning models. While XAI has been increasingly applied in various domains within acoustics, its use in bioacoustics, which involves analyzing audio signals from living organisms, remains relatively underexplored. In this paper, we investigate the vocalizations of a bird species with strong geographic variation throughout its range in North America. Audio recordings were converted into spectrogram images and used to train a deep Convolutional Neural Network (CNN) for classification, achieving an accuracy of 94.8\%. To interpret the model's predictions, we applied both model-agnostic (LIME, SHAP) and model-specific (DeepLIFT, Grad-CAM) XAI techniques. These techniques produced different but complementary explanations, and when their explanations were considered together, they provided more complete and interpretable insights into the model's decision-making. This work highlights the importance of using a combination of XAI techniques to improve trust and interoperability, not only in broader acoustics signal analysis but also argues for broader applicability in different domain specific tasks. 

**Abstract (ZH)**: 可解释的人工智能（XAI）已成为解读复杂深度学习模型预测的关键工具。尽管XAI已在声学领域的多个领域中被广泛应用，但在涉及分析生物声信号的生物声学中仍相对未被充分探索。在本文中，我们研究了一种北美范围内具有强烈地理变异性的鸟类的鸣叫声。音频记录被转换成谱图图像，并用于训练用于分类的深层卷积神经网络（CNN），准确率达到94.8%。为了解释模型的预测，我们应用了:both模型无关（LIME, SHAP）和模型特定（DeepLIFT, Grad-CAM）的XAI技术。这些技术产生了不同的但互补的解释，当将它们的解释结合起来时，它们提供了模型决策更多全面和可解释的见解。本文强调了在更广泛的声音信号分析中使用XAI技术组合的重要性，并且在不同特定任务中的广泛应用。 

---
# TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals 

**Title (ZH)**: TANGO: 基于通行性感知的局部度量控制拓扑目标导航 

**Authors**: Stefan Podgorski, Sourav Garg, Mehdi Hosseinzadeh, Lachlan Mares, Feras Dayoub, Ian Reid  

**Link**: [PDF](https://arxiv.org/pdf/2509.08699)  

**Abstract**: Visual navigation in robotics traditionally relies on globally-consistent 3D maps or learned controllers, which can be computationally expensive and difficult to generalize across diverse environments. In this work, we present a novel RGB-only, object-level topometric navigation pipeline that enables zero-shot, long-horizon robot navigation without requiring 3D maps or pre-trained controllers. Our approach integrates global topological path planning with local metric trajectory control, allowing the robot to navigate towards object-level sub-goals while avoiding obstacles. We address key limitations of previous methods by continuously predicting local trajectory using monocular depth and traversability estimation, and incorporating an auto-switching mechanism that falls back to a baseline controller when necessary. The system operates using foundational models, ensuring open-set applicability without the need for domain-specific fine-tuning. We demonstrate the effectiveness of our method in both simulated environments and real-world tests, highlighting its robustness and deployability. Our approach outperforms existing state-of-the-art methods, offering a more adaptable and effective solution for visual navigation in open-set environments. The source code is made publicly available: this https URL. 

**Abstract (ZH)**: 视觉导向在机器人技术中传统上依赖于全局一致的3D地图或学习控制器，这可能会产生计算上的负担并在不同环境间难以泛化。在这项工作中，我们提出了一种新颖的仅基于RGB图像、基于对象级的拓扑导航流水线，该流水线能够在无需3D地图或预训练控制器的情况下实现零样本、长时距的机器人导航。我们的方法结合了全局拓扑路径规划与局部度量轨迹控制，使机器人能够导航至基于对象的中继目标同时避开障碍物。我们通过连续预测局部轨迹并利用单目深度估计和通过性估计来解决先前方法的关键限制，还引入了一个自动切换机制，在必要时切换回基础控制器。该系统采用基础模型运行，确保在无需领域特定微调的情况下具有开放集适用性。我们在模拟环境和实际测试中展示了我们方法的有效性，强调了其鲁棒性和部署性。我们的方法优于现有最先进的方法，提供了在开放集环境中更具适应性和有效性的一种视觉导航解决方案。源代码已公开：this https URL。 

---
# A layered architecture for log analysis in complex IT systems 

**Title (ZH)**: 复杂IT系统中日志分析的分层架构 

**Authors**: Thorsten Wittkopp  

**Link**: [PDF](https://arxiv.org/pdf/2509.08698)  

**Abstract**: In the evolving IT landscape, stability and reliability of systems are essential, yet their growing complexity challenges DevOps teams in implementation and maintenance. Log analysis, a core element of AIOps, provides critical insights into complex behaviors and failures. This dissertation introduces a three-layered architecture to support DevOps in failure resolution. The first layer, Log Investigation, performs autonomous log labeling and anomaly classification. We propose a method that labels log data without manual effort, enabling supervised training and precise evaluation of anomaly detection. Additionally, we define a taxonomy that groups anomalies into three categories, ensuring appropriate method selection. The second layer, Anomaly Detection, detects behaviors deviating from the norm. We propose a flexible Anomaly Detection method adaptable to unsupervised, weakly supervised, and supervised training. Evaluations on public and industry datasets show F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third layer, Root Cause Analysis, identifies minimal log sets describing failures, their origin, and event sequences. By balancing training data and identifying key services, our Root Cause Analysis method consistently detects 90-98% of root cause log lines within the top 10 candidates, providing actionable insights for mitigation. Our research addresses how log analysis methods can be designed and optimized to help DevOps resolve failures efficiently. By integrating these three layers, the architecture equips teams with robust methods to enhance IT system reliability. 

**Abstract (ZH)**: 在不断演化的IT景观中，系统稳定性和可靠性至关重要，但日益复杂性挑战着DevOps团队的实施和维护。日志分析作为AIOps的核心元素，提供了关键的见解，用于理解复杂的失败行为。本论文提出了一种三层架构以支持DevOps在故障解决中的应用。第一层，日志调查，实现了自动的日志标签化和异常分类。我们提出了一种无需人工标注的方法，使得异常检测可以进行监督训练并精确评估。此外，我们定义了分类学，将异常分为三类，确保了适当的方法选择。第二层，异常检测，检测偏离常规的行为。我们提出了一种灵活的异常检测方法，适用于无监督、弱监督和监督训练。对公开和行业数据集的评估显示F1分数在0.98到1.0之间，确保了可靠的异常检测。第三层，根本原因分析，识别描述故障、其起源和事件序列的最小日志集。通过平衡训练数据和识别关键服务，我们的根本原因分析方法在前10个候选者中一致检测到90-98%的根本原因日志行，提供了可操作的见解用于预防。我们的研究旨在探讨如何设计和优化日志分析方法，以帮助DevOps团队高效地解决故障。通过整合这三层，该架构为团队提供了增强IT系统可靠性的 robust 方法。 

---
# Reshaping the Forward-Forward Algorithm with a Similarity-Based Objective 

**Title (ZH)**: 基于相似性目标重塑前向-前向算法 

**Authors**: James Gong, Raymond Luo, Emma Wang, Leon Ge, Bruce Li, Felix Marattukalam, Waleed Abdulla  

**Link**: [PDF](https://arxiv.org/pdf/2509.08697)  

**Abstract**: Backpropagation is the pivotal algorithm underpinning the success of artificial neural networks, yet it has critical limitations such as biologically implausible backward locking and global error propagation. To circumvent these constraints, the Forward-Forward algorithm was proposed as a more biologically plausible method that replaces the backward pass with an additional forward pass. Despite this advantage, the Forward-Forward algorithm significantly trails backpropagation in accuracy, and its optimal form exhibits low inference efficiency due to multiple forward passes required. In this work, the Forward-Forward algorithm is reshaped through its integration with similarity learning frameworks, eliminating the need for multiple forward passes during inference. This proposed algorithm is named Forward-Forward Algorithm Unified with Similarity-based Tuplet loss (FAUST). Empirical evaluations on MNIST, Fashion-MNIST, and CIFAR-10 datasets indicate that FAUST substantially improves accuracy, narrowing the gap with backpropagation. On CIFAR-10, FAUST achieves 56.22\% accuracy with a simple multi-layer perceptron architecture, approaching the backpropagation benchmark of 57.63\% accuracy. 

**Abstract (ZH)**: 前向前算法结合基于相似性三元组损失的统一前向方法（FAUST） 

---
# Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network 

**Title (ZH)**: 基于骨架的 signer 语言识别：一种双流时空动态图卷积网络方法 

**Authors**: Liangjin Liu, Haoyang Zheng, Pei Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.08661)  

**Abstract**: Isolated Sign Language Recognition (ISLR) is challenged by gestures that are morphologically similar yet semantically distinct, a problem rooted in the complex interplay between hand shape and motion trajectory. Existing methods, often relying on a single reference frame, struggle to resolve this geometric ambiguity. This paper introduces Dual-SignLanguageNet (DSLNet), a dual-reference, dual-stream architecture that decouples and models gesture morphology and trajectory in separate, complementary coordinate systems. Our approach utilizes a wrist-centric frame for view-invariant shape analysis and a facial-centric frame for context-aware trajectory modeling. These streams are processed by specialized networks-a topology-aware graph convolution for shape and a Finsler geometry-based encoder for trajectory-and are integrated via a geometry-driven optimal transport fusion mechanism. DSLNet sets a new state-of-the-art, achieving 93.70%, 89.97% and 99.79% accuracy on the challenging WLASL-100, WLASL-300 and LSA64 datasets, respectively, with significantly fewer parameters than competing models. 

**Abstract (ZH)**: 孤立手语识别中的手语手势在形态上相似而语义上不同，这一问题源于手形和运动轨迹之间复杂的交互作用。现有方法通常依赖于单一参考框架，难以解决这种几何上的不确定性。本文提出了一种双参考框架、双流网络Dual-SignLanguageNet (DSLNet)，该网络将手势形态和轨迹分别建模在互补的坐标系统中。该方法利用腕关节为中心的框架进行视点不变的手形分析，并利用面部为中心的框架进行语境感知的轨迹建模。这些流分别由一种拓扑感知的图卷积网络和基于芬斯ler几何编码器处理，并通过基于几何的最优传输融合机制进行整合。DSLNet 在具有挑战性的 WLASL-100、WLASL-300 和 LSA64 数据集上分别达到了 93.70%、89.97% 和 99.79% 的准确率，参数显著少于 competing 模型。 

---
# Robust Belief-State Policy Learning for Quantum Network Routing Under Decoherence and Time-Varying Conditions 

**Title (ZH)**: 去噪和时变条件下量子网络路由的鲁棒信念状态策略学习 

**Authors**: Amirhossein Taherpour, Abbas Taherpour, Tamer Khattab  

**Link**: [PDF](https://arxiv.org/pdf/2509.08654)  

**Abstract**: This paper presents a feature-based Partially Observable Markov Decision Process (POMDP) framework for quantum network routing, combining belief-state planning with Graph Neural Networks (GNNs) to address partial observability, decoherence, and scalability challenges in dynamic quantum systems. Our approach encodes complex quantum network dynamics, including entanglement degradation and time-varying channel noise, into a low-dimensional feature space, enabling efficient belief updates and scalable policy learning. The core of our framework is a hybrid GNN-POMDP architecture that processes graph-structured representations of entangled links to learn routing policies, coupled with a noise-adaptive mechanism that fuses POMDP belief updates with GNN outputs for robust decision making. We provide a theoretical analysis establishing guarantees for belief convergence, policy improvement, and robustness to noise. Experiments on simulated quantum networks with up to 100 nodes demonstrate significant improvements in routing fidelity and entanglement delivery rates compared to state-of-the-art baselines, particularly under high decoherence and nonstationary conditions. 

**Abstract (ZH)**: 基于特征的Partially Observable Markov Decision Process框架：结合Graph Neural Networks的量子网络路由 

---
# Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations 

**Title (ZH)**: 构建 resilient LLM 代理：安全的计划-执行实施指南 

**Authors**: Ron F. Del Rosario, Klaudia Krawiecka, Christian Schroeder de Witt  

**Link**: [PDF](https://arxiv.org/pdf/2509.08646)  

**Abstract**: As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount. This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution. We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act). A central focus is placed on the security implications of this design, particularly its inherent resilience to indirect prompt injection attacks by establishing control-flow integrity. We argue that while P-t-E provides a strong foundation, a defense-in-depth strategy is necessary, and we detail essential complementary controls such as the Principle of Least Privilege, task-scoped tool access, and sandboxed code execution. To make these principles actionable, this guide provides detailed implementation blueprints and working code references for three leading agentic frameworks: LangChain (via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing the P-t-E pattern is analyzed, highlighting unique features like LangGraph's stateful graphs for re-planning, CrewAI's declarative tool scoping for security, and AutoGen's built-in Docker sandboxing. Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents. 

**Abstract (ZH)**: 作为一种大型语言模型（LLM）代理在自动化复杂多步任务方面的能力不断提高，对 robust、安全且可预测的架构设计模式的需求日益迫切。本文提供了一种全面的指南，介绍“计划先行-执行”（P-t-E）模式这一代理设计模式，该模式将战略规划与战术执行分离。我们探讨了P-t-E的基础原则，详细说明了其核心组件——规划者和执行者——以及与响应模式如ReAct相比，在预测性、成本效益和推理质量方面的架构优势。特别关注了该设计的安全影响，尤其是通过确保控制流完整性来增强其对间接提示注入攻击的韧性。我们认为尽管P-t-E提供了一个强大的基础，但仍需要多层防御策略，并详细介绍了必要的补充控制措施，如最小权限原则、任务范围工具访问和沙箱代码执行。为了使这些原则可操作，本文提供了三个领先代理框架——LangChain（通过LangGraph）、CrewAI和AutoGen——的详细实施蓝图和操作代码引用。我们分析了每个框架实施P-t-E模式的独特特点。最后，我们讨论了高级模式，包括动态重计划循环、基于有向无环图（DAG）的并行执行以及人类在环（HITL）验证的关键作用，从而为架构师、开发人员和安全工程师提供全面的战略蓝图，以构建生产级、稳健且值得信赖的LLM代理。 

---
# RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and Correct Image Interpretation Model Shortcuts 

**Title (ZH)**: RoentMod: 一种用于识别和纠正图像解读模型捷径的合成胸部X光修改模型 

**Authors**: Lauren H. Cooke, Matthias Jung, Jan M. Brendel, Nora M. Kerkovits, Borek Foldyna, Michael T. Lu, Vineet K. Raghu  

**Link**: [PDF](https://arxiv.org/pdf/2509.08640)  

**Abstract**: Chest radiographs (CXRs) are among the most common tests in medicine. Automated image interpretation may reduce radiologists\' workload and expand access to diagnostic expertise. Deep learning multi-task and foundation models have shown strong performance for CXR interpretation but are vulnerable to shortcut learning, where models rely on spurious and off-target correlations rather than clinically relevant features to make decisions. We introduce RoentMod, a counterfactual image editing framework that generates anatomically realistic CXRs with user-specified, synthetic pathology while preserving unrelated anatomical features of the original scan. RoentMod combines an open-source medical image generator (RoentGen) with an image-to-image modification model without requiring retraining. In reader studies with board-certified radiologists and radiology residents, RoentMod-produced images appeared realistic in 93\% of cases, correctly incorporated the specified finding in 89-99\% of cases, and preserved native anatomy comparable to real follow-up CXRs. Using RoentMod, we demonstrate that state-of-the-art multi-task and foundation models frequently exploit off-target pathology as shortcuts, limiting their specificity. Incorporating RoentMod-generated counterfactual images during training mitigated this vulnerability, improving model discrimination across multiple pathologies by 3-19\% AUC in internal validation and by 1-11\% for 5 out of 6 tested pathologies in external testing. These findings establish RoentMod as a broadly applicable tool for probing and correcting shortcut learning in medical AI. By enabling controlled counterfactual interventions, RoentMod enhances the robustness and interpretability of CXR interpretation models and provides a generalizable strategy for improving foundation models in medical imaging. 

**Abstract (ZH)**: 胸部X光片（CXR）是医学中应用最广泛的检查之一。自动图像解释可能减轻放射科医生的工作负担并扩大诊断专科知识的 accessibility。深度学习多任务和基础模型在CXR解释中表现出色，但容易发生捷径学习，即模型依赖于与临床相关特征无关的虚假和偏离目标的关联来做决策。我们引入了RoentMod，这是一种生成对抗框架，可以生成具有用户指定的合成病理学的解剖学上现实的CXR，同时保留原始扫描中无关的解剖学特征。RoentMod将一个开源的医学图像生成器（RoentGen）与无需重新训练的图像到图像修改模型相结合。在执业认证的放射科医生和放射学住院医师的读者研究中，RoentMod生成的图像中有93%的情况看起来是真实的，89-99%的情况正确地纳入了指定的发现，并且保留了与真实随访CXR相当的原始解剖结构。使用RoentMod，我们证明了最先进的多任务和基础模型经常利用偏离目标的病理学作为捷径，限制了它们的特异性。在训练中加入RoentMod生成的反事实图像减轻了这种脆弱性，在内部验证中提高了多种病理学模型区分度的3-19% AUC，在外部测试中提高了5种测试病理中的4种病理学的1-11% AUC。这些发现确立了RoentMod作为一种广泛适用的工具，用于探究和纠正医学AI中的捷径学习。通过使可控的反事实干预成为可能，RoentMod增强了CXR解释模型的稳健性和可解释性，并提供了一种改进医学成像中基础模型的通用策略。 

---
# UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation 

**Title (ZH)**: UOPSL: 无配对OCT倾向性病灶学习以增强眼底图像诊断 

**Authors**: Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang, Daniel Zapp, Kai Huang, Nassir Navab, M.Ali Nasseri  

**Link**: [PDF](https://arxiv.org/pdf/2509.08624)  

**Abstract**: Significant advancements in AI-driven multimodal medical image diagnosis have led to substantial improvements in ophthalmic disease identification in recent years. However, acquiring paired multimodal ophthalmic images remains prohibitively expensive. While fundus photography is simple and cost-effective, the limited availability of OCT data and inherent modality imbalance hinder further progress. Conventional approaches that rely solely on fundus or textual features often fail to capture fine-grained spatial information, as each imaging modality provides distinct cues about lesion predilection sites. In this study, we propose a novel unpaired multimodal framework \UOPSL that utilizes extensive OCT-derived spatial priors to dynamically identify predilection sites, enhancing fundus image-based disease recognition. Our approach bridges unpaired fundus and OCTs via extended disease text descriptions. Initially, we employ contrastive learning on a large corpus of unpaired OCT and fundus images while simultaneously learning the predilection sites matrix in the OCT latent space. Through extensive optimization, this matrix captures lesion localization patterns within the OCT feature space. During the fine-tuning or inference phase of the downstream classification task based solely on fundus images, where paired OCT data is unavailable, we eliminate OCT input and utilize the predilection sites matrix to assist in fundus image classification learning. Extensive experiments conducted on 9 diverse datasets across 28 critical categories demonstrate that our framework outperforms existing benchmarks. 

**Abstract (ZH)**: 基于广泛 OCT 提取的空间先验的无配对多模态框架 \UOPSL 在眼底图像病灶识别中的应用 

---
# OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis 

**Title (ZH)**: OTESGN：最优传输增强的语法-语义图网络在方面情感分析中的应用 

**Authors**: Xinfeng Liao, Xuanqi Chen, Lianxi Wang, Jiahuan Yang, Zhuowei Chen, Ziying Rong  

**Link**: [PDF](https://arxiv.org/pdf/2509.08612)  

**Abstract**: Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and determine their sentiment polarity. While dependency trees combined with contextual semantics effectively identify aspect sentiment, existing methods relying on syntax trees and aspect-aware attention struggle to model complex semantic relationships. Their dependence on linear dot-product features fails to capture nonlinear associations, allowing noisy similarity from irrelevant words to obscure key opinion terms. Motivated by Differentiable Optimal Matching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph Network (OTESGN), which introduces a Syntactic-Semantic Collaborative Attention. It comprises a Syntactic Graph-Aware Attention for mining latent syntactic dependencies and modeling global syntactic topology, as well as a Semantic Optimal Transport Attention designed to uncover fine-grained semantic alignments amidst textual noise, thereby accurately capturing sentiment signals obscured by irrelevant tokens. A Adaptive Attention Fusion module integrates these heterogeneous features, and contrastive regularization further improves robustness. Experiments demonstrate that OTESGN achieves state-of-the-art results, outperforming previous best models by +1.01% F1 on Twitter and +1.30% F1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its efficacy in precise localization of opinion words and noise resistance. 

**Abstract (ZH)**: 基于方面的情感分析（ABSA）旨在识别方面术语并确定其情感极性。虽然依赖树结合上下文语义能有效识别方面情感，但现有依赖于语法树和方面意识注意力的方法难以建模复杂的语义关系。它们对线性的点积特征的依赖无法捕捉非线性关联，使得无关词语的噪音相似性模糊了关键意见术语。受可微最优匹配启发，我们提出了一种最优 transport 增强语法-语义图形网络（OTESGN），引入了语法-语义协作注意力机制。该网络包含一种语法图形意识注意力，用于挖掘潜在的语法依赖关系并建模全局语法拓扑结构，同时包含一种语义最优 transport 注意力，旨在在文本噪音中揭示细微的语义对齐，从而准确捕捉由无关标记符隐藏的情感信号。一种自适应注意力融合模块整合了这些异构特征，对比正则化进一步提高鲁棒性。实验表明，OTESGN在Twitter和Laptop14基准数据集上分别取得了+1.01%和+1.30%的F1最佳成绩。消融研究和可视化分析验证了其在精确定位意见词汇和抗噪方面的有效性。 

---
# Classification of 24-hour movement behaviors from wrist-worn accelerometer data: from handcrafted features to deep learning techniques 

**Title (ZH)**: 基于手戴加速度计数据的24小时运动行为分类：从手工特征到深度学习技术 

**Authors**: Alireza Sameh, Mehrdad Rostami, Mourad Oussalah, Vahid Farrahi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08606)  

**Abstract**: Purpose: We compared the performance of deep learning (DL) and classical machine learning (ML) algorithms for the classification of 24-hour movement behavior into sleep, sedentary, light intensity physical activity (LPA), and moderate-to-vigorous intensity physical activity (MVPA). Methods: Open-access data from 151 adults wearing a wrist-worn accelerometer (Axivity-AX3) was used. Participants were randomly divided into training, validation, and test sets (121, 15, and 15 participants each). Raw acceleration signals were segmented into non-overlapping 10-second windows, and then a total of 104 handcrafted features were extracted. Four DL algorithms-Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), Gated Recurrent Units (GRU), and One-Dimensional Convolutional Neural Network (1D-CNN)-were trained using raw acceleration signals and with handcrafted features extracted from these signals to predict 24-hour movement behavior categories. The handcrafted features were also used to train classical ML algorithms, namely Random Forest (RF), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression (LR), Artificial Neural Network (ANN), and Decision Tree (DT) for classifying 24-hour movement behavior intensities. Results: LSTM, BiLSTM, and GRU showed an overall accuracy of approximately 85% when trained with raw acceleration signals, and 1D-CNN an overall accuracy of approximately 80%. When trained on handcrafted features, the overall accuracy for both DL and classical ML algorithms ranged from 70% to 81%. Overall, there was a higher confusion in classification of MVPA and LPA, compared to sleep and sedentary categories. Conclusion: DL methods with raw acceleration signals had only slightly better performance in predicting 24-hour movement behavior intensities, compared to when DL and classical ML were trained with handcrafted features. 

**Abstract (ZH)**: 目的：我们将深度学习（DL）和经典机器学习（ML）算法的性能进行了比较，用于将24小时运动行为分类为睡眠、久坐、轻强度身体活动（LPA）和中等至剧烈强度身体活动（MVPA）。方法：使用151名佩戴手腕加速计（Axivity-AX3）的成年人的公开数据。参与者被随机分为训练集、验证集和测试集（每组分别为121、15和15人）。原始加速度信号被分割成不重叠的10秒窗口，并提取了总共104个手工设计的特征。四种DL算法—长短期记忆（LSTM）、双向长短期记忆（BiLSTM）、门控递归单元（GRU）和一维卷积神经网络（1D-CNN）—使用原始加速度信号及其所提取的手工设计特征来预测24小时运动行为类别。手工设计的特征也被用于训练经典ML算法，包括随机森林（RF）、支持向量机（SVM）、超梯度增强（XGBoost）、逻辑回归（LR）、人工神经网络（ANN）和决策树（DT），以分类24小时运动行为强度。结果：当使用原始加速度信号训练时，LSTM、BiLSTM和GRU的整体准确度约为85%，1D-CNN的整体准确度约为80%。当使用手工设计的特征训练时，DL和经典ML算法的整体准确度范围从70%到81%。总体而言，与睡眠和久坐类别相比，在分类MVPA和LPA类别时存在更高的分类混淆。结论：与使用手工设计特征训练的DL和经典ML相比，使用原始加速度信号的DL方法在预测24小时运动行为强度方面仅稍微表现出更好的性能。 

---
# Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications 

**Title (ZH)**: 医学中大型语言模型的过度拟合：流行程度、特征与影响 

**Authors**: Anran Li, Lingfei Qian, Mengmeng Du, Yu Yin, Yan Hu, Zihao Sun, Yihang Fu, Erica Stutz, Xuguang Ai, Qianqian Xie, Rui Zhu, Jimin Huang, Yifan Yang, Siru Liu, Yih-Chung Tham, Lucila Ohno-Machado, Hyunghoon Cho, Zhiyong Lu, Hua Xu, Qingyu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.08604)  

**Abstract**: Large Language Models (LLMs) have demonstrated significant potential in medicine. To date, LLMs have been widely applied to tasks such as diagnostic assistance, medical question answering, and clinical information synthesis. However, a key open question remains: to what extent do LLMs memorize medical training data. In this study, we present the first comprehensive evaluation of memorization of LLMs in medicine, assessing its prevalence (how frequently it occurs), characteristics (what is memorized), volume (how much content is memorized), and potential downstream impacts (how memorization may affect medical applications). We systematically analyze common adaptation scenarios: (1) continued pretraining on medical corpora, (2) fine-tuning on standard medical benchmarks, and (3) fine-tuning on real-world clinical data, including over 13,000 unique inpatient records from Yale New Haven Health System. The results demonstrate that memorization is prevalent across all adaptation scenarios and significantly higher than reported in the general domain. Memorization affects both the development and adoption of LLMs in medicine and can be categorized into three types: beneficial (e.g., accurate recall of clinical guidelines and biomedical references), uninformative (e.g., repeated disclaimers or templated medical document language), and harmful (e.g., regeneration of dataset-specific or sensitive clinical content). Based on these findings, we offer practical recommendations to facilitate beneficial memorization that enhances domain-specific reasoning and factual accuracy, minimize uninformative memorization to promote deeper learning beyond surface-level patterns, and mitigate harmful memorization to prevent the leakage of sensitive or identifiable patient information. 

**Abstract (ZH)**: 大型语言模型（LLMs）在医学领域展现了显著的潜力。到目前为止，LLMs在诊断辅助、医学问答和临床信息综合等任务中得到了广泛应用。然而，一个关键的开放问题是：LLMs在多大程度上记忆了医学训练数据。在本研究中，我们首次全面评估了LLMs在医学领域的记忆情况，评估了其普遍性（发生频率）、特征（记忆内容）、数量（记忆内容量）以及潜在的下游影响（记忆如何影响医学应用）。我们系统分析了常见的适应场景：（1）继续在医学语料库上进行预训练，（2）在标准医学基准数据上进行微调，以及（3）在真实世界临床数据上进行微调，包括来自耶鲁纽海文健康系统超过13,000份独特的住院记录。研究结果表明，记忆在所有适应场景中普遍存在，并且显著高于一般领域报告的数据。记忆对LLMs在医学领域的开发和应用产生影响，并可以分为三种类型：有益的（例如，准确回忆临床指南和生物医学参考）、无信息的（例如，重复的免责声明或模板化的医学文档语言）和有害的（例如，再生特定数据集或敏感的临床内容）。基于这些发现，我们提出了实用的建议，以促进有益的记忆，增强领域特定的推理和事实准确性，减少无信息的记忆以促进更深层次的学习，避免表面模式，以及减轻有害的记忆以防止敏感或可识别患者信息的泄露。 

---
# Interpretability as Alignment: Making Internal Understanding a Design Principle 

**Title (ZH)**: 可解释性即对齐：将内在理解作为设计原则 

**Authors**: Aadit Sengupta, Pratinav Seth, Vinay Kumar Sankarapu  

**Link**: [PDF](https://arxiv.org/pdf/2509.08592)  

**Abstract**: Large neural models are increasingly deployed in high-stakes settings, raising concerns about whether their behavior reliably aligns with human values. Interpretability provides a route to internal transparency by revealing the computations that drive outputs. We argue that interpretability especially mechanistic approaches should be treated as a design principle for alignment, not an auxiliary diagnostic tool. Post-hoc methods such as LIME or SHAP offer intuitive but correlational explanations, while mechanistic techniques like circuit tracing or activation patching yield causal insight into internal failures, including deceptive or misaligned reasoning that behavioral methods like RLHF, red teaming, or Constitutional AI may overlook. Despite these advantages, interpretability faces challenges of scalability, epistemic uncertainty, and mismatches between learned representations and human concepts. Our position is that progress on safe and trustworthy AI will depend on making interpretability a first-class objective of AI research and development, ensuring that systems are not only effective but also auditable, transparent, and aligned with human intent. 

**Abstract (ZH)**: 大型神经模型越来越多地在高风险环境中部署，引发了对其行为是否可靠地符合人类价值观的担忧。可解释性通过揭示驱动输出的计算过程提供了一条实现内部透明性的途径。我们认为，尤其是基于机制的方法，应被视为一致性的设计原则，而不仅仅是一种辅助诊断工具。事后方法如LIME或SHAP提供了直观但相关性的解释，而如电路追踪或激活补丁等机制技术则可以提供对内部故障的因果洞察，包括行为方法如RLHF、红队测试或宪法AI可能忽视的欺骗性或不一致的推理。尽管如此，可解释性仍面临着可扩展性、知识不确定性以及学习表示与人类概念之间的不匹配等挑战。我们的观点是，确保AI研究和开发的安全和可信将依赖于将可解释性作为首要目标，以确保系统不仅有效，而且可以审计、透明并符合人类意图。 

---
# MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models 

**Title (ZH)**: MESH -- 如人类理解视频：测量大型视频模型的幻觉 

**Authors**: Garry Yang, Zizhe Chen, Man Hon Wong, Haoyu Lei, Yongqiang Chen, Zhenguo Li, Kaiwen Zhou, James Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.08538)  

**Abstract**: Large Video Models (LVMs) build on the semantic capabilities of Large Language Models (LLMs) and vision modules by integrating temporal information to better understand dynamic video content. Despite their progress, LVMs are prone to hallucinations-producing inaccurate or irrelevant descriptions. Current benchmarks for video hallucination depend heavily on manual categorization of video content, neglecting the perception-based processes through which humans naturally interpret videos. We introduce MESH, a benchmark designed to evaluate hallucinations in LVMs systematically. MESH uses a Question-Answering framework with binary and multi-choice formats incorporating target and trap instances. It follows a bottom-up approach, evaluating basic objects, coarse-to-fine subject features, and subject-action pairs, aligning with human video understanding. We demonstrate that MESH offers an effective and comprehensive approach for identifying hallucinations in videos. Our evaluations show that while LVMs excel at recognizing basic objects and features, their susceptibility to hallucinations increases markedly when handling fine details or aligning multiple actions involving various subjects in longer videos. 

**Abstract (ZH)**: 大型视频模型（LVMs）通过整合时间信息，基于大型语言模型（LLMs）的语义能力和视觉模块，更好地理解动态视频内容。尽管取得了进展，LVMs仍然容易产生幻觉，生成不准确或不相关描述。当前的视频幻觉基准主要依赖于手动视频内容分类，忽视了人类自然解读视频的过程。我们介绍了MESH基准，旨在系统地评估LVMs中的幻觉。MESH采用问答框架，包含二选一和多选格式，并包含目标和陷阱实例。它采用自底向上的方法，评估基本对象、从粗到细的主题特征以及主题-动作对，与人类视频理解相一致。我们的评估表明，LVMs在识别基本对象和特征方面表现出色，但在处理细部特征或在较长视频中对多个主题涉及的动作进行对准时，其产生幻觉的倾向显著增加。 

---
# Agents of Discovery 

**Title (ZH)**: 发现者之维 

**Authors**: Sascha Diefenbacher, Anna Hallin, Gregor Kasieczka, Michael Krämer, Anne Lauscher, Tim Lukas  

**Link**: [PDF](https://arxiv.org/pdf/2509.08535)  

**Abstract**: The substantial data volumes encountered in modern particle physics and other domains of fundamental physics research allow (and require) the use of increasingly complex data analysis tools and workflows. While the use of machine learning (ML) tools for data analysis has recently proliferated, these tools are typically special-purpose algorithms that rely, for example, on encoded physics knowledge to reach optimal performance. In this work, we investigate a new and orthogonal direction: Using recent progress in large language models (LLMs) to create a team of agents -- instances of LLMs with specific subtasks -- that jointly solve data analysis-based research problems in a way similar to how a human researcher might: by creating code to operate standard tools and libraries (including ML systems) and by building on results of previous iterations. If successful, such agent-based systems could be deployed to automate routine analysis components to counteract the increasing complexity of modern tool chains. To investigate the capabilities of current-generation commercial LLMs, we consider the task of anomaly detection via the publicly available and highly-studied LHC Olympics dataset. Several current models by OpenAI (GPT-4o, o4-mini, GPT-4.1, and GPT-5) are investigated and their stability tested. Overall, we observe the capacity of the agent-based system to solve this data analysis problem. The best agent-created solutions mirror the performance of human state-of-the-art results. 

**Abstract (ZH)**: 现代粒子物理学及其他基础物理学研究中遇到的大量数据促进了日益复杂的数据分析工具和工作流的使用，同时也要求使用这些工具。虽然近期机器学习工具在数据分析中得到广泛应用，但这些工具通常是专用于特定任务的算法，依赖于编码的物理知识以达到最佳性能。在此项工作中，我们研究了一个新的、独立的方向：利用大型语言模型的最新进展创建一个代理团队——具有特定子任务实例的大型语言模型——以类似人类研究人员的方式共同解决基于数据分析的研究问题：通过编写代码来操作标准工具和库（包括机器学习系统），并在此基础上构建先前迭代的结果。如果成功，这种基于代理的系统可以部署以自动化现代工具链中的常规分析组件，以应对日益复杂的工具链所带来的挑战。为了调查当前商用大型语言模型的能力，我们考虑使用公开可用且高度研究的LHC Olympics数据集进行异常检测任务。我们研究了几种由OpenAI开发的当前模型（GPT-4o、o4-mini、GPT-4.1和GPT-5），并测试了它们的稳定性。总体而言，我们观察到基于代理系统的解决此数据分析问题的能力。最好的代理生成的解决方案与人类当前最先进的结果性能相媲美。 

---
# AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution 

**Title (ZH)**: AutoStub: 基于遗传编程的符号执行用桩生成方法 

**Authors**: Felix Mächtle, Nils Loose, Jan-Niclas Serr, Jonas Sander, Thomas Eisenbarth  

**Link**: [PDF](https://arxiv.org/pdf/2509.08524)  

**Abstract**: Symbolic execution is a powerful technique for software testing, but suffers from limitations when encountering external functions, such as native methods or third-party libraries. Existing solutions often require additional context, expensive SMT solvers, or manual intervention to approximate these functions through symbolic stubs. In this work, we propose a novel approach to automatically generate symbolic stubs for external functions during symbolic execution that leverages Genetic Programming. When the symbolic executor encounters an external function, AutoStub generates training data by executing the function on randomly generated inputs and collecting the outputs. Genetic Programming then derives expressions that approximate the behavior of the function, serving as symbolic stubs. These automatically generated stubs allow the symbolic executor to continue the analysis without manual intervention, enabling the exploration of program paths that were previously intractable. We demonstrate that AutoStub can automatically approximate external functions with over 90% accuracy for 55% of the functions evaluated, and can infer language-specific behaviors that reveal edge cases crucial for software testing. 

**Abstract (ZH)**: 基于遗传编程的自动生成符号占位符以代替外部函数的符号执行方法 

---
# FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning 

**Title (ZH)**: FMT$^{x}$: 一种高效的动态重规划的快速推进树扩展算法 

**Authors**: Soheil Espahbodini Nia  

**Link**: [PDF](https://arxiv.org/pdf/2509.08521)  

**Abstract**: Path planning in dynamic environments remains a core challenge in robotics, especially as autonomous systems are deployed in unpredictable spaces such as warehouses and public roads. While algorithms like Fast Marching Tree (FMT$^{*}$) offer asymptotically optimal solutions in static settings, their single-pass design prevents path revisions which are essential for real-time adaptation. On the other hand, full replanning is often too computationally expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching Tree algorithm that enables efficient and consistent replanning in dynamic environments. We revisit the neighbor selection rule of FMT$^{*}$ and demonstrate that a minimal change overcomes its single-pass limitation, enabling the algorithm to update cost-to-come values upon discovering better connections without sacrificing asymptotic optimality or computational efficiency. By maintaining a cost-ordered priority queue and applying a selective update condition that uses an expanding neighbor to identify and trigger the re-evaluation of any node with a potentially suboptimal path, FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the environment evolves. This targeted strategy preserves the inherent efficiency of FMT$^{*}$ while enabling robust adaptation to changes in obstacle configuration. FMT$^{x}$ is proven to recover an asymptotically optimal solution after environmental changes. Experimental results demonstrate that FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more swiftly to dynamic events with lower computational overhead and thus offering a more effective solution for real-time robotic navigation in unpredictable worlds. 

**Abstract (ZH)**: 动态环境中的路径规划仍然是机器人技术中的核心挑战，尤其是在仓库和公共道路上等不可预测的空间中部署自主系统时。虽然像快速前行树(Fast Marching Tree, FMT$^{*}$)这样的算法在静态环境中提供渐近最优的解决方案，但它们的一次性设计限制了路径的修订，这在实时适应中是必不可少的。另一方面，完全重新规划往往计算成本过高。本文介绍了FMT$^{x}$，这是一种FMT$^{*}$算法的扩展，能够支持动态环境中的高效且一致的重新规划。我们重新审视了FMT$^{*}$的邻居选择规则，并证明通过最小的变化克服了其一次性设计的局限性，使算法能够在发现更好的连接时更新成本到终点值，而不会牺牲渐近最优性或计算效率。通过维护一个按成本排序的优先队列，并应用选择性更新条件，使用扩展邻居来识别并触发任何潜在次优路径的节点的重新评估，FMT$^{x}$确保随着环境的变化，次优路径能够高效地得到修复。这种定向策略保留了FMT$^{*}$固有的高效性，同时能够稳健地适应障碍配置的变化。FMT$^{x}$能够在环境变化后恢复渐近最优的解决方案。实验结果表明，FMT$^{x}$在应对动态事件方面比有影响力的重新规划算法RRT$^{x}$更快捷，计算开销更低，因此为不可预测环境中的实时机器人导航提供了更有效的解决方案。 

---
# Variational Rank Reduction Autoencoders for Generative 

**Title (ZH)**: 变分秩降 ambiguous term 翻译为“可变秩”可能更符合上下文，但原句中的“Rank Reduction”可能是特指某种降秩方法，在没有更多上下文的情况下，可以保留“秩降”。“生成型”的准确翻译为“生成”，所以最终翻译为：

变分秩降自编码器 for 生成 

**Authors**: Alicia Tierz, Jad Mounayer, Beatriz Moya, Francisco Chinesta  

**Link**: [PDF](https://arxiv.org/pdf/2509.08515)  

**Abstract**: Generative thermal design for complex geometries is fundamental in many areas of engineering, yet it faces two main challenges: the high computational cost of high-fidelity simulations and the limitations of conventional generative models. Approaches such as autoencoders (AEs) and variational autoencoders (VAEs) often produce unstructured latent spaces with discontinuities, which restricts their capacity to explore designs and generate physically consistent solutions.
To address these limitations, we propose a hybrid framework that combines Variational Rank-Reduction Autoencoders (VRRAEs) with Deep Operator Networks (DeepONets). The VRRAE introduces a truncated SVD within the latent space, leading to continuous, interpretable, and well-structured representations that mitigate posterior collapse and improve geometric reconstruction. The DeepONet then exploits this compact latent encoding in its branch network, together with spatial coordinates in the trunk network, to predict temperature gradients efficiently and accurately.
This hybrid approach not only enhances the quality of generated geometries and the accuracy of gradient prediction, but also provides a substantial advantage in inference efficiency compared to traditional numerical solvers. Overall, the study underscores the importance of structured latent representations for operator learning and highlights the potential of combining generative models and operator networks in thermal design and broader engineering applications. 

**Abstract (ZH)**: 基于VRRAE和DeepONet的生成热设计方法 

---
# HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants 

**Title (ZH)**: HumanAgencyBench: 可扩展的AI助手中人类代理支持评估框架 

**Authors**: Benjamin Sturgeon, Daniel Samuelson, Jacob Haimes, Jacy Reese Anthis  

**Link**: [PDF](https://arxiv.org/pdf/2509.08494)  

**Abstract**: As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective futures. Relatively simple algorithmic systems already steer human decision-making, such as social media feed algorithms that lead people to unintentionally and absent-mindedly scroll through engagement-optimized content. In this paper, we develop the idea of human agency by integrating philosophical and scientific theories of agency with AI-assisted evaluation methods: using large language models (LLMs) to simulate and validate user queries and to evaluate AI responses. We develop HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions of human agency based on typical AI use cases. HAB measures the tendency of an AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation, Correct Misinformation, Defer Important Decisions, Encourage Learning, and Maintain Social Boundaries. We find low-to-moderate agency support in contemporary LLM-based assistants and substantial variation across system developers and dimensions. For example, while Anthropic LLMs most support human agency overall, they are the least supportive LLMs in terms of Avoid Value Manipulation. Agency support does not appear to consistently result from increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and we encourage a shift towards more robust safety and alignment targets. 

**Abstract (ZH)**: 随着人类将更多任务和决策交给人工智能（AI），我们面临失去对我们个人和共同未来的控制风险。相对简单的算法系统已经引导人类决策，例如社交媒体流算法使人们无意中滚动浏览优化了参与度的内容。在本文中，我们通过将关于代理的哲学和科学理论与AI辅助评估方法相结合，发展了人类代理的概念：利用大规模语言模型（LLMs）模拟和验证用户查询，并评估AI响应。我们开发了HumanAgencyBench（HAB），这是一个基于典型AI应用场景的可扩展和自适应基准，包含六个维度的人类代理标准。HAB衡量AI助手或代理在回答澄清问题、避免价值操纵、纠正错误信息、推迟重要决策、鼓励学习以及维护社交边界方面的倾向。我们发现基于当前LLM的助手在人类代理支持方面表现为中等到较低水平，并且在系统开发者和维度方面存在显著差异。例如，Anthropic的LLMs在整体上最支持人类代理，但在避免价值操纵方面是最不支持的LLMs。人类代理支持并不总是由于增加LLM能力或遵循指令（如RLHF）而一致产生的，我们鼓励更多地转向稳健的安全和对齐目标。 

---
# Send to which account? Evaluation of an LLM-based Scambaiting System 

**Title (ZH)**: 发送给哪个账号？基于LLM的骗术诱捕系统评估 

**Authors**: Hossein Siadati, Haadi Jafarian, Sima Jafarikhah  

**Link**: [PDF](https://arxiv.org/pdf/2509.08493)  

**Abstract**: Scammers are increasingly harnessing generative AI(GenAI) technologies to produce convincing phishing content at scale, amplifying financial fraud and undermining public trust. While conventional defenses, such as detection algorithms, user training, and reactive takedown efforts remain important, they often fall short in dismantling the infrastructure scammers depend on, including mule bank accounts and cryptocurrency wallets. To bridge this gap, a proactive and emerging strategy involves using conversational honeypots to engage scammers and extract actionable threat intelligence. This paper presents the first large-scale, real-world evaluation of a scambaiting system powered by large language models (LLMs). Over a five-month deployment, the system initiated over 2,600 engagements with actual scammers, resulting in a dataset of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR) of approximately 32%, successfully extracting sensitive financial information such as mule accounts. Additionally, the system maintained a Human Acceptance Rate (HAR) of around 70%, indicating strong alignment between LLM-generated responses and human operator preferences. Alongside these successes, our analysis reveals key operational challenges. In particular, the system struggled with engagement takeoff: only 48.7% of scammers responded to the initial seed message sent by defenders. These findings highlight the need for further refinement and provide actionable insights for advancing the design of automated scambaiting systems. 

**Abstract (ZH)**: 利用生成式AI技术大规模生成可信欺诈内容，增强金融诈骗并削弱公众信任：一种新的主动策略研究——基于大规模实时评价的大型语言模型辅助诱骗系统分析 

---
# A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models 

**Title (ZH)**: 基于结构化的水下目标检测挑战与解决方案的综述：从传统方法到大规模视觉语言模型 

**Authors**: Edwine Nabahirwa, Wei Song, Minghua Zhang, Yi Fang, Zhou Ni  

**Link**: [PDF](https://arxiv.org/pdf/2509.08490)  

**Abstract**: Underwater object detection (UOD) is vital to diverse marine applications, including oceanographic research, underwater robotics, and marine conservation. However, UOD faces numerous challenges that compromise its performance. Over the years, various methods have been proposed to address these issues, but they often fail to fully capture the complexities of underwater environments. This review systematically categorizes UOD challenges into five key areas: Image quality degradation, target-related issues, data-related challenges, computational and processing constraints, and limitations in detection methodologies. To address these challenges, we analyze the progression from traditional image processing and object detection techniques to modern approaches. Additionally, we explore the potential of large vision-language models (LVLMs) in UOD, leveraging their multi-modal capabilities demonstrated in other domains. We also present case studies, including synthetic dataset generation using DALL-E 3 and fine-tuning Florence-2 LVLM for UOD. This review identifies three key insights: (i) Current UOD methods are insufficient to fully address challenges like image degradation and small object detection in dynamic underwater environments. (ii) Synthetic data generation using LVLMs shows potential for augmenting datasets but requires further refinement to ensure realism and applicability. (iii) LVLMs hold significant promise for UOD, but their real-time application remains under-explored, requiring further research on optimization techniques. 

**Abstract (ZH)**: 水下物体检测（UOD）在海洋研究、水下机器人技术以及海洋 conservation 等多种海洋应用中至关重要。然而，UOD 面臨眾多挑戰，這些挑戰影響其性能。隨著時間的推移，提出了各種方法來解決這些問題，但這些方法往往無法完全捕捉水下環境的複雜性。本文系統地將 UOD 挑戰分類為五個主要領域：圖像質量退化、目標相關問題、數據相關挑戰、計算和處理限制，以及檢測方法論的限制。為了應對這些挑戰，本文分析了從傳統圖像處理和目標檢測技術到現代方法的進展過程。同時，本文探索了大型視覺-語言模型（LVLM）在 UOD 中的潛力，利用其在其他領域展示出的多模態能力。本文還 ♥現了案例研究，包括使用 DALL-E 3 生成合成數據集和 Fine-tuning Florence-2 LVLM 以應用於 UOD。本文識別了三個關鍵洞見：(i) 現有的 UOD 方法對於處理動態水下環境中的圖像退化和小目標檢測尚不夠;(ii) 使用 LVLM 生成合成數據集顯示出擴大數據集的潛力，但需要進一步完善以確保真實性和適用性;(iii) LVLM 在 UOD 方面潛力巨大，但其在線應用尚未得到充分探索，需要進一步研究以實現優化技術。 

---
# Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation 

**Title (ZH)**: 基于提示驱动的多模态生成AI图像分析：检测、分割、修复与解释 

**Authors**: Kaleem Ahmad  

**Link**: [PDF](https://arxiv.org/pdf/2509.08489)  

**Abstract**: Prompt-driven image analysis converts a single natural-language instruction into multiple steps: locate, segment, edit, and describe. We present a practical case study of a unified pipeline that combines open-vocabulary detection, promptable segmentation, text-conditioned inpainting, and vision-language description into a single workflow. The system works end to end from a single prompt, retains intermediate artifacts for transparent debugging (such as detections, masks, overlays, edited images, and before and after composites), and provides the same functionality through an interactive UI and a scriptable CLI for consistent, repeatable runs. We highlight integration choices that reduce brittleness, including threshold adjustments, mask inspection with light morphology, and resource-aware defaults. In a small, single-word prompt segment, detection and segmentation produced usable masks in over 90% of cases with an accuracy above 85% based on our criteria. On a high-end GPU, inpainting makes up 60 to 75% of total runtime under typical guidance and sampling settings, which highlights the need for careful tuning. The study offers implementation-guided advice on thresholds, mask tightness, and diffusion parameters, and details version pinning, artifact logging, and seed control to support replay. Our contribution is a transparent, reliable pattern for assembling modern vision and multimodal models behind a single prompt, with clear guardrails and operational practices that improve reliability in object replacement, scene augmentation, and removal. 

**Abstract (ZH)**: 基于提示的图像分析将单个自然语言指令转换为多个步骤：定位、分割、编辑和描述。我们提出了一种统一的工作流案例研究，该工作流结合了开放式词汇检测、可提示分割、文本条件插画填充和视觉语言描述。系统从单个提示端到端工作，保留中间结果以透明地调试（如检测结果、掩码、叠加、编辑的图像以及前后组合），并通过交互式UI和可脚本化的CLI界面提供一致且可重复的功能。我们强调了减少脆弱性的集成选择，包括阈值调整、轻度形态学掩码检查和资源感知默认值。在一个小型单词提示片段中，在我们的标准下，检测和分割在90%以上的案例中产生了可用的掩码，准确率超过85%。在高性能GPU上，插画填充通常占总运行时间的60%到75%，突显了仔细调参的必要性。该研究提供了阈值、掩码紧致性和扩散参数的实现指导建议，并详细说明了版本锁定、中间结果日志记录和种子控制，以支持重新运行。我们的贡献是提供了一种透明且可靠的工作流模式，用于在单个提示后组装现代视觉和多模态模型，并通过清晰的护栏和操作实践提高物体替换、场景增删和修改的可靠性。 

---
# Joint Learning using Mixture-of-Expert-Based Representation for Enhanced Speech Generation and Robust Emotion Recognition 

**Title (ZH)**: 基于专家混合表示的联合学习方法以增强语音生成和 robust 情感识别 

**Authors**: Jing-Tong Tzeng, Carlos Busso, Chi-Chun Lee  

**Link**: [PDF](https://arxiv.org/pdf/2509.08470)  

**Abstract**: Speech emotion recognition (SER) plays a critical role in building emotion-aware speech systems, but its performance degrades significantly under noisy conditions. Although speech enhancement (SE) can improve robustness, it often introduces artifacts that obscure emotional cues and adds computational overhead to the pipeline. Multi-task learning (MTL) offers an alternative by jointly optimizing SE and SER tasks. However, conventional shared-backbone models frequently suffer from gradient interference and representational conflicts between tasks. To address these challenges, we propose the Sparse Mixture-of-Experts Representation Integration Technique (Sparse MERIT), a flexible MTL framework that applies frame-wise expert routing over self-supervised speech representations. Sparse MERIT incorporates task-specific gating networks that dynamically select from a shared pool of experts for each frame, enabling parameter-efficient and task-adaptive representation learning. Experiments on the MSP-Podcast corpus show that Sparse MERIT consistently outperforms baseline models on both SER and SE tasks. Under the most challenging condition of -5 dB signal-to-noise ratio (SNR), Sparse MERIT improves SER F1-macro by an average of 12.0% over a baseline relying on a SE pre-processing strategy, and by 3.4% over a naive MTL baseline, with statistical significance on unseen noise conditions. For SE, Sparse MERIT improves segmental SNR (SSNR) by 28.2% over the SE pre-processing baseline and by 20.0% over the naive MTL baseline. These results demonstrate that Sparse MERIT provides robust and generalizable performance for both emotion recognition and enhancement tasks in noisy environments. 

**Abstract (ZH)**: 稀疏专家混合表示集成技术（Sparse MERIT）在噪声环境中的情景情绪识别与增强 

---
# Adversarial Attacks Against Automated Fact-Checking: A Survey 

**Title (ZH)**: 对抗攻击对自动化事实核查的挑战：一个综述 

**Authors**: Fanzhen Liu, Alsharif Abuadbba, Kristen Moore, Surya Nepal, Cecile Paris, Jia Wu, Jian Yang, Quan Z. Sheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.08463)  

**Abstract**: In an era where misinformation spreads freely, fact-checking (FC) plays a crucial role in verifying claims and promoting reliable information. While automated fact-checking (AFC) has advanced significantly, existing systems remain vulnerable to adversarial attacks that manipulate or generate claims, evidence, or claim-evidence pairs. These attacks can distort the truth, mislead decision-makers, and ultimately undermine the reliability of FC models. Despite growing research interest in adversarial attacks against AFC systems, a comprehensive, holistic overview of key challenges remains lacking. These challenges include understanding attack strategies, assessing the resilience of current models, and identifying ways to enhance robustness. This survey provides the first in-depth review of adversarial attacks targeting FC, categorizing existing attack methodologies and evaluating their impact on AFC systems. Additionally, we examine recent advancements in adversary-aware defenses and highlight open research questions that require further exploration. Our findings underscore the urgent need for resilient FC frameworks capable of withstanding adversarial manipulations in pursuit of preserving high verification accuracy. 

**Abstract (ZH)**: 在信息泛滥的时代，事实核查（FC）在验证主张和推广可靠信息方面起着关键作用。尽管自动化事实核查（AFC）取得了显著进展，现有的系统仍易受到操控或生成主张、证据或主张-证据对的对抗攻击的影响。这些攻击可以扭曲事实，误导决策者，并最终削弱FC模型的可靠性。尽管对AFC系统的对抗攻击引起了越来越多的研究兴趣，但关于关键挑战的全面综述仍然匮乏。这些挑战包括理解攻击策略、评估当前模型的抗攻击性以及寻找增强鲁棒性的方法。本文首次对针对FC的对抗攻击进行深入综述，分类现有的攻击方法并评估其对AFC系统的影響。此外，我们还探讨了对抗意识防御的最新进展，并指出现有研究中需要进一步探索的开放问题。我们的研究结果强调了构建能够抵御对抗操纵的鲁棒事实核查框架的迫切需要，以保持高验证准确性。 

---
# Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics 

**Title (ZH)**: 适应视觉-语言模型在高能物理中中微子事件分类的应用 

**Authors**: Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08461)  

**Abstract**: Recent advances in Large Language Models (LLMs) have demonstrated their remarkable capacity to process and reason over structured and unstructured data modalities beyond natural language. In this work, we explore the applications of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa 3.2, to the task of identifying neutrino interactions in pixelated detector data from high-energy physics (HEP) experiments. We benchmark this model against a state-of-the-art convolutional neural network (CNN) architecture, similar to those used in the NOvA and DUNE experiments, which have achieved high efficiency and purity in classifying electron and muon neutrino events. Our evaluation considers both the classification performance and interpretability of the model predictions. We find that VLMs can outperform CNNs, while also providing greater flexibility in integrating auxiliary textual or semantic information and offering more interpretable, reasoning-based predictions. This work highlights the potential of VLMs as a general-purpose backbone for physics event classification, due to their high performance, interpretability, and generalizability, which opens new avenues for integrating multimodal reasoning in experimental neutrino physics. 

**Abstract (ZH)**: Recent Advances in Vision Language Models for Identifying Neutrino Interactions in Pixelated Detector Data from High-Energy Physics Experiments 

---
# DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation 

**Title (ZH)**: DSFL：基于分组安全聚合的双服务器容错联邦学习框架 

**Authors**: Charuka Herath, Yogachandran Rahulamathavan, Varuna De Silva, Sangarapillai Lambotharan  

**Link**: [PDF](https://arxiv.org/pdf/2509.08449)  

**Abstract**: Federated Learning (FL) enables decentralized model training without sharing raw data, offering strong privacy guarantees. However, existing FL protocols struggle to defend against Byzantine participants, maintain model utility under non-independent and identically distributed (non-IID) data, and remain lightweight for edge devices. Prior work either assumes trusted hardware, uses expensive cryptographic tools, or fails to address privacy and robustness simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated Learning framework that addresses these limitations using a group-based secure aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest servers, DSFL removes this dependency by revealing a key vulnerability: privacy leakage through client-server collusion. DSFL introduces three key innovations: (1) a dual-server secure aggregation protocol that protects updates without encryption or key exchange, (2) a group-wise credit-based filtering mechanism to isolate Byzantine clients based on deviation scores, and (3) a dynamic reward-penalty system for enforcing fair participation. DSFL is evaluated on MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in both IID and non-IID settings. It consistently outperforms existing baselines, including LSFL, homomorphic encryption methods, and differential privacy approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and 68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB communication per round. 

**Abstract (ZH)**: DSFL：基于分组安全聚合的抗拜占庭联邦学习框架 

---
# Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting 

**Title (ZH)**: 球形布朗桥扩散模型在条件皮质厚度预测中的应用 

**Authors**: Ivan Stoyanov, Fabian Bongratz, Christian Wachinger  

**Link**: [PDF](https://arxiv.org/pdf/2509.08442)  

**Abstract**: Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development. 

**Abstract (ZH)**: 个体化高分辨率皮层厚度轨迹的准确预测对于检测皮层微小变化、提供神经退行性过程的宝贵见解以及促进更早更精确的干预策略至关重要。然而，皮层厚度预测是一项具有挑战性的任务，因为涉及复杂的非欧几里得几何结构和多模态数据的特定个体集成需求。为应对这些挑战，我们提出了球面布朗桥扩散模型（SBDM）。具体而言，我们提出了一种双向条件布朗桥扩散过程，用于预测已对齐皮层表面顶点级别的皮层厚度轨迹。我们的技术贡献包括一种新的去噪模型：条件球面U-网（CoS-UNet），该模型结合了球面卷积和密集交叉注意力，无缝集成皮层表面和表格条件。与先前的方法相比，SBDM在我们的实验中基于ADNI和OASIS的纵向数据集，实现了显著降低的预测误差。此外，我们展示了SBDM生成个体事实和假设皮层厚度轨迹的能力，提供了一种探索皮层发育假设情景的新框架。 

---
# Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking 

**Title (ZH)**: 基于自我视角一致性的稀疏BEV融合多视图检测与跟踪 

**Authors**: Keisuke Toida, Taigo Sakai, Naoki Kato, Kazutoyo Yokota, Takeshi Nakamura, Kazuhiro Hotta  

**Link**: [PDF](https://arxiv.org/pdf/2509.08421)  

**Abstract**: Multi-View Multi-Object Tracking (MVMOT) is essential for applications such as surveillance, autonomous driving, and sports analytics. However, maintaining consistent object identities across multiple cameras remains challenging due to viewpoint changes, lighting variations, and occlusions, which often lead to tracking this http URL methods project features from multiple cameras into a unified Bird's-Eye-View (BEV) space to improve robustness against occlusion. However, this projection introduces feature distortion and non-uniform density caused by variations in object scale with distance. These issues degrade the quality of the fused representation and reduce detection and tracking this http URL address these problems, we propose SCFusion, a framework that combines three techniques to improve multi-view feature integration. First, it applies a sparse transformation to avoid unnatural interpolation during projection. Next, it performs density-aware weighting to adaptively fuse features based on spatial confidence and camera distance. Finally, it introduces a multi-view consistency loss that encourages each camera to learn discriminative features independently before this http URL show that SCFusion achieves state-of-the-art performance, reaching an IDF1 score of 95.9% on WildTrack and a MODP of 89.2% on MultiviewX, outperforming the baseline method TrackTacular. These results demonstrate that SCFusion effectively mitigates the limitations of conventional BEV projection and provides a robust and accurate solution for multi-view object detection and tracking. 

**Abstract (ZH)**: 多视图多目标跟踪（MVMOT）对于监控、自动驾驶和运动分析等应用至关重要。然而，由于视角变化、光照差异和遮挡，保持多摄像头之间的一致目标身份仍然具有挑战性，这往往导致跟踪不准确。方法将来自多个摄像头的特征投影到统一的鸟瞰视图（BEV）空间，以提高对遮挡的鲁棒性。然而，这种投影引入了由物体规模随距离变化引起的特征失真和非均匀密度。这些问题降低了融合表示的质量，并降低了检测和跟踪的准确性。为了解决这些问题，我们提出了SCFusion框架，该框架结合了三种技术来改进多视图特征集成。首先，它应用稀疏变换以避免投影过程中不自然的插值。其次，它执行密度感知加权，根据空间置信度和摄像头距离自适应融合特征。最后，它引入了多视图一致性损失，鼓励每个摄像头独立学习区分性特征。结果显示，SCFusion达到了最先进的性能，在WildTrack上实现了95.9%的IDF1分数，在MultiviewX上实现了89.2%的MODP分数，超过了基线方法TrackTacular。这些结果表明，SCFusion有效地缓解了传统BEV投影的局限性，并为多视图目标检测和跟踪提供了稳健且准确的解决方案。 

---
# An Iterative LLM Framework for SIBT utilizing RAG-based Adaptive Weight Optimization 

**Title (ZH)**: 基于RAG的自适应权重优化迭代LLM框架用于SIBT 

**Authors**: Zhuo Xiao, Qinglong Yao, Jingjing Wang, Fugen Zhou, Bo Liu, Haitao Sun, Zhe Ji, Yuliang Jiang, Junjie Wang, Qiuwen Wu  

**Link**: [PDF](https://arxiv.org/pdf/2509.08407)  

**Abstract**: Seed implant brachytherapy (SIBT) is an effective cancer treatment modality; however, clinical planning often relies on manual adjustment of objective function weights, leading to inefficiencies and suboptimal results. This study proposes an adaptive weight optimization framework for SIBT planning, driven by large language models (LLMs). A locally deployed DeepSeek-R1 LLM is integrated with an automatic planning algorithm in an iterative loop. Starting with fixed weights, the LLM evaluates plan quality and recommends new weights in the next iteration. This process continues until convergence criteria are met, after which the LLM conducts a comprehensive evaluation to identify the optimal plan. A clinical knowledge base, constructed and queried via retrieval-augmented generation (RAG), enhances the model's domain-specific reasoning. The proposed method was validated on 23 patient cases, showing that the LLM-assisted approach produces plans that are comparable to or exceeding clinically approved and fixed-weight plans, in terms of dose homogeneity for the clinical target volume (CTV) and sparing of organs at risk (OARs). The study demonstrates the potential use of LLMs in SIBT planning automation. 

**Abstract (ZH)**: 基于大型语言模型的适应性权重优化框架在种子植植近距离放疗计划中的应用 

---
# Semantic Causality-Aware Vision-Based 3D Occupancy Prediction 

**Title (ZH)**: 基于语义因果关系的视觉驱动三维占位预测 

**Authors**: Dubing Chen, Huan Zheng, Yucheng Zhou, Xianfei Li, Wenlong Liao, Tao He, Pai Peng, Jianbing Shen  

**Link**: [PDF](https://arxiv.org/pdf/2509.08388)  

**Abstract**: Vision-based 3D semantic occupancy prediction is a critical task in 3D vision that integrates volumetric 3D reconstruction with semantic understanding. Existing methods, however, often rely on modular pipelines. These modules are typically optimized independently or use pre-configured inputs, leading to cascading errors. In this paper, we address this limitation by designing a novel causal loss that enables holistic, end-to-end supervision of the modular 2D-to-3D transformation pipeline. Grounded in the principle of 2D-to-3D semantic causality, this loss regulates the gradient flow from 3D voxel representations back to the 2D features. Consequently, it renders the entire pipeline differentiable, unifying the learning process and making previously non-trainable components fully learnable. Building on this principle, we propose the Semantic Causality-Aware 2D-to-3D Transformation, which comprises three components guided by our causal loss: Channel-Grouped Lifting for adaptive semantic mapping, Learnable Camera Offsets for enhanced robustness against camera perturbations, and Normalized Convolution for effective feature propagation. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the Occ3D benchmark, demonstrating significant robustness to camera perturbations and improved 2D-to-3D semantic consistency. 

**Abstract (ZH)**: 基于视觉的三维语义 occupancy 预测是三维视觉中的关键任务，涉及体素化三维重建与语义理解的整合。现有方法通常依赖于模块化管道，这些模块常常独立优化或使用预配置输入，导致级联错误。本文通过设计一种新颖的因果损失，解决了这一局限性，使整个模块化二维到三维转换管道实现整体、端到端的监督。基于二维到三维语义因果性的原则，该损失调节三维体素表示到二维特征的梯度流动，从而使整个管道可微分，统一学习过程，并使以前无法训练的组件变为可训练。基于这一原则，我们提出了语义因果意识的二维到三维转换，包含三个由我们因果损失引导的组件：通道分组提升实现自适应语义映射、可学习的相机偏移提高对相机扰动的鲁棒性以及归一化卷积实现有效的特征传递。大量实验表明，我们的方法在 Occ3D 基准上实现了最先进的性能，展示了对相机扰动的显著鲁棒性和增强的二维到三维语义一致性。 

---
# Efficient Decoding Methods for Language Models on Encrypted Data 

**Title (ZH)**: 加密数据上语言模型的高效解码方法 

**Authors**: Matan Avitan, Moran Baruch, Nir Drucker, Itamar Zimerman, Yoav Goldberg  

**Link**: [PDF](https://arxiv.org/pdf/2509.08383)  

**Abstract**: Large language models (LLMs) power modern AI applications, but processing sensitive data on untrusted servers raises privacy concerns. Homomorphic encryption (HE) enables computation on encrypted data for secure inference. However, neural text generation requires decoding methods like argmax and sampling, which are non-polynomial and thus computationally expensive under encryption, creating a significant performance bottleneck. We introduce cutmax, an HE-friendly argmax algorithm that reduces ciphertext operations compared to prior methods, enabling practical greedy decoding under encryption. We also propose the first HE-compatible nucleus (top-p) sampling method, leveraging cutmax for efficient stochastic decoding with provable privacy guarantees. Both techniques are polynomial, supporting efficient inference in privacy-preserving settings. Moreover, their differentiability facilitates gradient-based sequence-level optimization as a polynomial alternative to straight-through estimators. We further provide strong theoretical guarantees for cutmax, proving it converges globally to a unique two-level fixed point, independent of the input values beyond the identity of the maximizer, which explains its rapid convergence in just a few iterations. Evaluations on realistic LLM outputs show latency reductions of 24x-35x over baselines, advancing secure text generation. 

**Abstract (ZH)**: 大规模语言模型（LLMs）推动现代AI应用，但在不trusted服务器上处理敏感数据会引发隐私担忧。同态加密（HE）允许在加密数据上进行计算以实现安全推理。然而，神经文本生成需要如argmax和采样的解码方法，这些方法在加密下是非多项式的，因而计算代价高昂，成为显著的性能瓶颈。我们提出了cutmax，这是一种HE友好的argmax算法，相比先前方法减少了密文操作数，使加密下的实用贪婪解码成为可能。我们还提出了首个与HE兼容的核（top-p）采样方法，利用cutmax实现高效的随机解码并提供可验证的隐私保证。这两种技术都是多项式的，支持在隐私保护环境中高效推理。此外，它们的可微性使得基于梯度的序列级优化成为多项式替代直通估计器的一种方法。我们进一步为cutmax提供了强有力的理论保证，证明它在输入值超出极大值器身份的情况下，能够全局收敛到唯一的两层次不动点，解释了其在几轮迭代中快速收敛的原因。对现实的LLM输出进行评估显示，与基线相比，延迟降低了24-35倍，推动了安全文本生成的进步。 

---
# Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model 

**Title (ZH)**: 基于亿参数指令微调模型的低资源多任务结构化信息提取细调 

**Authors**: Yu Cheng Chih, Yong Hao Hou  

**Link**: [PDF](https://arxiv.org/pdf/2509.08381)  

**Abstract**: Deploying large language models (LLMs) for structured data extraction in domains such as financial compliance reporting, legal document analytics, and multilingual knowledge base construction is often impractical for smaller teams due to the high cost of running large architectures and the difficulty of preparing large, high-quality datasets. Most recent instruction-tuning studies focus on seven-billion-parameter or larger models, leaving limited evidence on whether much smaller models can work reliably under low-resource, multi-task conditions. This work presents ETLCH, a billion-parameter LLaMA-based model fine-tuned with low-rank adaptation on only a few hundred to one thousand samples per task for JSON extraction, knowledge graph extraction, and named entity recognition. Despite its small scale, ETLCH outperforms strong baselines across most evaluation metrics, with substantial gains observed even at the lowest data scale. These findings demonstrate that well-tuned small models can deliver stable and accurate structured outputs at a fraction of the computational cost, enabling cost-effective and reliable information extraction pipelines in resource-constrained environments. 

**Abstract (ZH)**: 基于低秩适应的小规模LLaMA模型ETLCH在JSON提取、知识图谱提取和命名实体识别任务中的表现 

---
# <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs 

**Title (ZH)**: 从生成有毒文本的LLMs中学到的教训 

**Authors**: Sergey Pletenev, Daniil Moskovskiy, Alexander Panchenko  

**Link**: [PDF](https://arxiv.org/pdf/2509.08358)  

**Abstract**: Modern Large Language Models (LLMs) are excellent at generating synthetic data. However, their performance in sensitive domains such as text detoxification has not received proper attention from the scientific community. This paper explores the possibility of using LLM-generated synthetic toxic data as an alternative to human-generated data for training models for detoxification. Using Llama 3 and Qwen activation-patched models, we generated synthetic toxic counterparts for neutral texts from ParaDetox and SST-2 datasets. Our experiments show that models fine-tuned on synthetic data consistently perform worse than those trained on human data, with a drop in performance of up to 30% in joint metrics. The root cause is identified as a critical lexical diversity gap: LLMs generate toxic content using a small, repetitive vocabulary of insults that fails to capture the nuances and variety of human toxicity. These findings highlight the limitations of current LLMs in this domain and emphasize the continued importance of diverse, human-annotated data for building robust detoxification systems. 

**Abstract (ZH)**: 现代大型语言模型在敏感领域如文本去毒方面的表现尚未得到科学界的足够关注。本文探讨使用生成的合成有毒数据替代人工生成数据来训练去毒模型的可能性。使用Llama 3和Qwen激活修补模型，我们为ParaDetox和SST-2数据集中的中性文本生成了合成的有毒对应数据。实验结果显示，使用合成数据微调的模型在综合指标上的表现逊于使用人工数据训练的模型，性能下降高达30％。根本原因在于词汇多样性差距：LLM使用有限且重复的侮辱词汇生成有毒内容，未能捕捉到人类 toxicity 的细微差别和多样性。这些发现突显了当前LLM在该领域的能力局限性，并强调了构建稳健的去毒系统中多样性和人工标注数据的持续重要性。 

---
# Automatic Detection of Inauthentic Templated Responses in English Language Assessments 

**Title (ZH)**: 英语语言评估中自动化检测不真实模板响应的研究 

**Authors**: Yashad Samant, Lee Becker, Scott Hellman, Bradley Behan, Sarah Hughes, Joshua Southerland  

**Link**: [PDF](https://arxiv.org/pdf/2509.08355)  

**Abstract**: In high-stakes English Language Assessments, low-skill test takers may employ memorized materials called ``templates'' on essay questions to ``game'' or fool the automated scoring system. In this study, we introduce the automated detection of inauthentic, templated responses (AuDITR) task, describe a machine learning-based approach to this task and illustrate the importance of regularly updating these models in production. 

**Abstract (ZH)**: 在高 stakes 英语语言评估中，低技能测试参与者可能会使用称为“模板”的记忆材料来“操控”或欺骗自动化评分系统。本研究介绍了自动化检测不真实的模板化回应（AuDITR）任务，描述了该任务的机器学习方法，并阐述了在实际应用中定期更新这些模型的重要性。 

---
# Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration 

**Title (ZH)**: 如人类般抓取：基于人类本体感受觉运动整合的学习通用多指抓取 

**Authors**: Ce Guo, Xieyuanli Chen, Zhiwen Zeng, Zirui Guo, Yihong Li, Haoran Xiao, Dewen Hu, Huimin Lu  

**Link**: [PDF](https://arxiv.org/pdf/2509.08354)  

**Abstract**: Tactile and kinesthetic perceptions are crucial for human dexterous manipulation, enabling reliable grasping of objects via proprioceptive sensorimotor integration. For robotic hands, even though acquiring such tactile and kinesthetic feedback is feasible, establishing a direct mapping from this sensory feedback to motor actions remains challenging. In this paper, we propose a novel glove-mediated tactile-kinematic perception-prediction framework for grasp skill transfer from human intuitive and natural operation to robotic execution based on imitation learning, and its effectiveness is validated through generalized grasping tasks, including those involving deformable objects. Firstly, we integrate a data glove to capture tactile and kinesthetic data at the joint level. The glove is adaptable for both human and robotic hands, allowing data collection from natural human hand demonstrations across different scenarios. It ensures consistency in the raw data format, enabling evaluation of grasping for both human and robotic hands. Secondly, we establish a unified representation of multi-modal inputs based on graph structures with polar coordinates. We explicitly integrate the morphological differences into the designed representation, enhancing the compatibility across different demonstrators and robotic hands. Furthermore, we introduce the Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage multidimensional subgraph convolutions and attention-based LSTM layers to extract spatio-temporal features from graph inputs to predict node-based states for each hand joint. These predictions are then mapped to final commands through a force-position hybrid mapping. 

**Abstract (ZH)**: 触觉和本体感觉感知对于人类灵巧操作至关重要，使得通过本体感觉传感器运动整合可靠地抓取物体成为可能。对于机器人手，尽管获取这种触觉和本体感觉反馈是可行的，但将这种感觉反馈直接映射到运动动作仍然颇具挑战性。本文提出了一种基于模仿学习的手套介导的触觉-运动感知-预测框架，将人类直观自然的操作技能转移到机器人的执行中，并通过包括涉及可变形物体的通用抓取任务验证了其有效性。首先，我们整合了一个数据手套以在关节级别捕捉触觉和本体感觉数据。该手套既适合人类手也适合机器人手，可从不同场景下的自然手部演示中收集数据。它确保了原始数据格式的一致性，使对手部和机器人手的抓取评估成为可能。其次，我们基于极坐标结构建立了多模态输入的统一表示。我们显式地将形态差异融入设计的表示中，增强了不同示范者和机器人手之间的兼容性。此外，我们引入了触觉-本体感觉时空图网络（TK-STGN），该网络利用多维子图卷积和基于注意力的LSTM层从图输入中提取时空特征，以预测每个手关节的节点状态。然后，这些预测通过力-位置混合映射映射到最终命令。 

---
# Toward Subtrait-Level Model Explainability in Automated Writing Evaluation 

**Title (ZH)**: 面向自动化写作评估中亚特征级模型可解释性的研究 

**Authors**: Alejandro Andrade-Lotero, Lee Becker, Joshua Southerland, Scott Hellman  

**Link**: [PDF](https://arxiv.org/pdf/2509.08345)  

**Abstract**: Subtrait (latent-trait components) assessment presents a promising path toward enhancing transparency of automated writing scores. We prototype explainability and subtrait scoring with generative language models and show modest correlation between human subtrait and trait scores, and between automated and human subtrait scores. Our approach provides details to demystify scores for educators and students. 

**Abstract (ZH)**: 潜在特质评估为提升自动化写作评分透明度提供了有 promise 的途径。我们基于生成语言模型原型化可解释性及潜在特质评分，并展示了人工评定的潜在特质和特质分数以及自动化评定的潜在特质分数之间的适度相关性。该方法为教育者和学生提供详细信息以澄清评分。 

---
# Accelerating Mixture-of-Expert Inference with Adaptive Expert Split Mechanism 

**Title (ZH)**: 自适应专家分割机制加速混合专家推理 

**Authors**: Jiaming Yan, Jianchun Liu, Hongli Xu, Liusheng Huang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08342)  

**Abstract**: Mixture-of-Experts (MoE) has emerged as a promising architecture for modern large language models (LLMs). However, massive parameters impose heavy GPU memory (i.e., VRAM) demands, hindering the widespread adoption of MoE LLMs. Offloading the expert parameters to CPU RAM offers an effective way to alleviate the VRAM requirements for MoE inference. Existing approaches typically cache a small subset of experts in VRAM and dynamically prefetch experts from RAM during inference, leading to significant degradation in inference speed due to the poor cache hit rate and substantial expert loading latency. In this work, we propose MoEpic, an efficient MoE inference system with a novel expert split mechanism. Specifically, each expert is vertically divided into two segments: top and bottom. MoEpic caches the top segment of hot experts, so that more experts will be stored under the limited VRAM budget, thereby improving the cache hit rate. During each layer's inference, MoEpic predicts and prefetches the activated experts for the next layer. Since the top segments of cached experts are exempt from fetching, the loading time is reduced, which allows efficient transfer-computation overlap. Nevertheless, the performance of MoEpic critically depends on the cache configuration (i.e., each layer's VRAM budget and expert split ratio). To this end, we propose a divide-and-conquer algorithm based on fixed-point iteration for adaptive cache configuration. Extensive experiments on popular MoE LLMs demonstrate that MoEpic can save about half of the GPU cost, while lowering the inference latency by about 37.51%-65.73% compared to the baselines. 

**Abstract (ZH)**: MoEpic：一种高效的Mixture-of-Experts推理系统 

---
# Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis 

**Title (ZH)**: 多模态黑色素瘤诊断的检索增强大模型 

**Authors**: Jihyun Moon, Charmgil Hong  

**Link**: [PDF](https://arxiv.org/pdf/2509.08338)  

**Abstract**: Accurate and early diagnosis of malignant melanoma is critical for improving patient outcomes. While convolutional neural networks (CNNs) have shown promise in dermoscopic image analysis, they often neglect clinical metadata and require extensive preprocessing. Vision-language models (VLMs) offer a multimodal alternative but struggle to capture clinical specificity when trained on general-domain data. To address this, we propose a retrieval-augmented VLM framework that incorporates semantically similar patient cases into the diagnostic prompt. Our method enables informed predictions without fine-tuning and significantly improves classification accuracy and error correction over conventional baselines. These results demonstrate that retrieval-augmented prompting provides a robust strategy for clinical decision support. 

**Abstract (ZH)**: 准确且早期诊断恶性黑色素瘤对于改善患者预后至关重要。虽然卷积神经网络在皮肤镜图像分析中显示出潜力，但它们往往忽视临床元数据并需要大量的预处理。视觉语言模型提供了多模态的替代方案，但在使用通用领域数据训练时难以捕捉临床特异性。为解决这一问题，我们提出了一种检索增强的视觉语言模型框架，该框架将语义相似的患者病例融入诊断提示中。我们的方法在无需微调的情况下实现了知情预测，并且在分类准确性和错误修正方面显著优于传统的基准方法。这些结果表明，检索增强的提示策略是一种稳健的临床决策支持策略。 

---
# Accelerating Reinforcement Learning Algorithms Convergence using Pre-trained Large Language Models as Tutors With Advice Reusing 

**Title (ZH)**: 使用预训练大型语言模型作为导师并 reused 建议以加速强化学习算法的收敛 

**Authors**: Lukas Toral, Teddy Lazebnik  

**Link**: [PDF](https://arxiv.org/pdf/2509.08329)  

**Abstract**: Reinforcement Learning (RL) algorithms often require long training to become useful, especially in complex environments with sparse rewards. While techniques like reward shaping and curriculum learning exist to accelerate training, these are often extremely specific and require the developer's professionalism and dedicated expertise in the problem's domain. Tackling this challenge, in this study, we explore the effectiveness of pre-trained Large Language Models (LLMs) as tutors in a student-teacher architecture with RL algorithms, hypothesizing that LLM-generated guidance allows for faster convergence. In particular, we explore the effectiveness of reusing the LLM's advice on the RL's convergence dynamics. Through an extensive empirical examination, which included 54 configurations, varying the RL algorithm (DQN, PPO, A2C), LLM tutor (Llama, Vicuna, DeepSeek), and environment (Blackjack, Snake, Connect Four), our results demonstrate that LLM tutoring significantly accelerates RL convergence while maintaining comparable optimal performance. Furthermore, the advice reuse mechanism shows a further improvement in training duration but also results in less stable convergence dynamics. Our findings suggest that LLM tutoring generally improves convergence, and its effectiveness is sensitive to the specific task, RL algorithm, and LLM model combination. 

**Abstract (ZH)**: 预训练大型语言模型作为辅导教师在RL算法中的有效性：加速 reinforcement learning (RL) 算法的收敛性 

---
# Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using Multi-Agent Reinforcement Learning 

**Title (ZH)**: 基于多智能体强化学习的网络博弈鲁棒性框架在针对网络物理微网中 

**Authors**: S Krishna Niketh, Sagar Babu Mitikiri, V Vignesh, Vedantham Lakshmi Srinivas, Mayukha Pal  

**Link**: [PDF](https://arxiv.org/pdf/2509.08310)  

**Abstract**: The increasing reliance on cyber physical infrastructure in modern power systems has amplified the risk of targeted cyber attacks, necessitating robust and adaptive resilience strategies. This paper presents a mathematically rigorous game theoretic framework to evaluate and enhance microgrid resilience using a combination of quantitative resilience metrics Load Served Ratio LSR, Critical Load Resilience CLR, Topological Survivability Score TSS, and DER Resilience Score DRS. These are integrated into a unified payoff matrix using the Analytic Hierarchy Process AHP to assess attack defense interactions. The framework is formalized as a finite horizon Markov Decision Process MDP with formal convergence guarantees and computational complexity bounds. Three case studies are developed 1. static attacks analyzed via Nash equilibrium, 2. severe attacks incorporating high impact strategies, and 3. adaptive attacks using Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q Learning. Rigorous theoretical analysis provides convergence proofs with explicit rates , PAC learning sample complexity bounds, and computational complexity analysis. The framework is tested on an enhanced IEEE 33bus distribution system with DERs and control switches, demonstrating the effectiveness of adaptive and strategic defenses in improving cyber physical resilience with statistically significant improvements of 18.7% 2.1% over static approaches. 

**Abstract (ZH)**: 现代电力系统对网络物理基础设施的日益依赖加剧了针对性网络攻击的风险， necessitating robust and adaptive resilience strategies. 本文 presents a mathematically rigorous game theoretic framework to evaluate and enhance 微电网韧性，采用负载供电比LSR、关键负载韧性CLR、拓扑生存分数TSS和分布式能源韧性评分DRS等多种定量韧性指标，并通过层次分析过程AHP整合到统一的支付矩阵中以评估攻击与防御的互动。该框架被形式化为具有收敛性和计算复杂度界有限时间 horizons 马尔可夫决策过程MDP。本文开发了三个案例研究：1）通过纳什均衡分析静态攻击，2）包含高影响策略的严重攻击，3）使用斯塔克尔贝格博弈、遗憾匹配、softmax启发式和多代理Q学习的适应性攻击。严格的理论分析提供了收敛性证明、显式速率、PAC学习样本复杂性界和计算复杂性分析。该框架在增强的IEEE 33节点配电网上进行了测试，该配电网包括分布式能源和控制器，证明了适应性和战略防御在提高网络物理韧性方面的有效性，统计学显著提高分别为18.7%和2.1%。 

---
# \emph{FoQuS}: A Forgetting-Quality Coreset Selection Framework for Automatic Modulation Recognition 

**Title (ZH)**: FoQuS: 一种遗忘-质量核心集选择框架用于自动调制识别 

**Authors**: Yao Lu, Chunfeng Sun, Dongwei Xu, Yun Lin, Qi Xuan, Guan Gui  

**Link**: [PDF](https://arxiv.org/pdf/2509.08300)  

**Abstract**: Deep learning-based Automatic Modulation Recognition (AMR) model has made significant progress with the support of large-scale labeled data. However, when developing new models or performing hyperparameter tuning, the time and energy consumption associated with repeated training using massive amounts of data are often unbearable. To address the above challenges, we propose \emph{FoQuS}, which approximates the effect of full training by selecting a coreset from the original dataset, thereby significantly reducing training overhead. Specifically, \emph{FoQuS} records the prediction trajectory of each sample during full-dataset training and constructs three importance metrics based on training dynamics. Experiments show that \emph{FoQuS} can maintain high recognition accuracy and good cross-architecture generalization on multiple AMR datasets using only 1\%-30\% of the original data. 

**Abstract (ZH)**: 基于深度学习的自动调制识别（AMR）模型在大规模标签数据的支持下取得了显著进展。然而，在开发新模型或进行超参数调整时，重复训练大量数据所需的时间和能量消耗往往无法接受。为应对上述挑战，我们提出了FoQuS，通过从原始数据集选择一个核心样本集，近似实现全训练的效果，从而显著降低训练开销。具体而言，FoQuS 在全数据集训练过程中记录每个样本的预测轨迹，并基于训练动力学构建三个重要性指标。实验表明，FoQuS 只使用原始数据的 1%-30%，即可在多个AMR数据集上保持高识别准确率和良好的跨架构泛化能力。 

---
# Segment Transformer: AI-Generated Music Detection via Music Structural Analysis 

**Title (ZH)**: 音乐结构分析驱动的AI生成音乐检测：Segment Transformer 

**Authors**: Yumin Kim, Seonghyeon Go  

**Link**: [PDF](https://arxiv.org/pdf/2509.08283)  

**Abstract**: Audio and music generation systems have been remarkably developed in the music information retrieval (MIR) research field. The advancement of these technologies raises copyright concerns, as ownership and authorship of AI-generated music (AIGM) remain unclear. Also, it can be difficult to determine whether a piece was generated by AI or composed by humans clearly. To address these challenges, we aim to improve the accuracy of AIGM detection by analyzing the structural patterns of music segments. Specifically, to extract musical features from short audio clips, we integrated various pre-trained models, including self-supervised learning (SSL) models or an audio effect encoder, each within our suggested transformer-based framework. Furthermore, for long audio, we developed a segment transformer that divides music into segments and learns inter-segment relationships. We used the FakeMusicCaps and SONICS datasets, achieving high accuracy in both the short-audio and full-audio detection experiments. These findings suggest that integrating segment-level musical features into long-range temporal analysis can effectively enhance both the performance and robustness of AIGM detection systems. 

**Abstract (ZH)**: 音频和音乐生成系统的开发在音乐信息检索研究领域取得了显著进展。然而，这些技术的进步引发了版权问题，因为人工智能生成音乐（AIGM）的所有权和作者身份仍然不明晰。此外，区分由AI生成的作品和由人类创作的作品也存在困难。为应对这些挑战，我们旨在通过分析音乐片段的结构模式来提高AIGM检测的准确性。具体而言，为了从短音频片段中提取音乐特征，我们整合了多种预训练模型，包括自我监督学习（SSL）模型或音频效果编码器，每个模型都嵌入在我们建议的基于变压器的框架中。进一步地，对于长音频，我们开发了一种片段变压器，将其划分为片段并学习片段间的关联性。我们使用了FakeMusicCaps和SONICS数据集，在短音频和完整音频检测实验中实现了高精度。这些发现表明，将片段级别的音乐特征整合到长时序分析中，可以有效提升AIGM检测系统的性能和鲁棒性。 

---
# Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models 

**Title (ZH)**: 可解释的物理推理与性能分类在视觉-语言模型中 

**Authors**: Pranav Pawar, Kavish Shah, Akshat Bhalani, Komal Kasat, Dev Mittal, Hadi Gala, Deepali Patil, Nikita Raichada, Monali Deshmukh  

**Link**: [PDF](https://arxiv.org/pdf/2509.08270)  

**Abstract**: As Vision-Language Models (VLMs) grow in sophistication, their ability to perform reasoning is coming under increasing supervision. While they excel at many tasks, their grasp of fundamental scientific principles, such as physics, remains an underexplored frontier. To reflect the advancements in these capabilities, we introduce a novel and accessible framework designed to rigorously evaluate VLMs on their understanding of 2D physics. Our framework features a pragmatic scenario generator that creates a diverse testbed of over 400 problems across four core domains: Projectile Motion, Collision Dynamics, Mechanics, and Fluid Dynamics. Through comprehensive evaluation of four state-of-the-art VLMs, we demonstrate a strong correlation between model scale and reasoning ability, with our top-performing model, Qwen2.5-VL-7B, achieving an overall score of 0.815. We find that while models excel at formulaic problems, they struggle significantly with domains requiring abstract spatial reasoning. By designing this framework, we aim to democratize the study of scientific reasoning in VLMs and foster deeper insights into their capabilities and limitations. 

**Abstract (ZH)**: 随着视觉语言模型（VLMs）日益复杂，其推理能力正受到越来越多的关注。尽管它们在许多任务中表现出色，但在物理学等基本科学原理的理解上仍存在未开发的领域。为了反映这些能力的进步，我们介绍了一个新颖且易于访问的框架，用于严格评估VLMs在二维物理理解上的表现。该框架包括一个实用的场景生成器，能够生成涵盖四大核心领域超过400个问题的多样化测试集：弹道运动、碰撞动力学、力学和流体力学。通过全面评估四种最先进的VLMs，我们证明了模型规模与推理能力之间存在较强的关联，我们的性能最好的模型Qwen2.5-VL-7B获得了总体评分为0.815。我们发现，虽然模型在公式化问题上表现出色，但在需要抽象空间推理的领域却表现不佳。通过设计此框架，我们旨在使VLMs中的科学推理研究民主化，并促进对其能力和局限性的更深入理解。 

---
# A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving 

**Title (ZH)**: 大型语言模型在进化优化中的系统综述：从建模到求解 

**Authors**: Yisong Zhang, Ran Cheng, Guoxing Yi, Kay Chen Tan  

**Link**: [PDF](https://arxiv.org/pdf/2509.08269)  

**Abstract**: Large Language Models (LLMs), with their strong understanding and reasoning capabilities, are increasingly being explored for tackling optimization problems, especially in synergy with evolutionary computation. Despite rapid progress, however, the field still lacks a unified synthesis and a systematic taxonomy. This survey addresses this gap by providing a comprehensive review of recent developments and organizing them within a structured framework. We classify existing research into two main stages: LLMs for optimization modeling and LLMs for optimization solving. The latter is further divided into three paradigms according to the role of LLMs in the optimization workflow: LLMs as stand-alone optimizers, low-level LLMs embedded within optimization algorithms, and high-level LLMs for algorithm selection and generation. For each category, we analyze representative methods, distill technical challenges, and examine their interplay with traditional approaches. We also review interdisciplinary applications spanning the natural sciences, engineering, and machine learning. By contrasting LLM-driven and conventional methods, we highlight key limitations and research gaps, and point toward future directions for developing self-evolving agentic ecosystems for optimization. An up-to-date collection of related literature is maintained at this https URL. 

**Abstract (ZH)**: 大型语言模型（LLMs）凭借其强大的理解和推理能力，越来越多地被探索用于解决优化问题，特别是在与进化计算协同工作中。尽管取得了快速进步，但该领域仍缺乏统一的综合和系统性的分类。本文综述通过提供对近期发展进行全面回顾，并在结构化框架中对其加以组织，来填补这一空白。我们将现有的研究分为两大阶段：用于优化建模的LLMs和用于优化求解的LLMs。后者根据LLMs在优化工作流中的作用进一步分为三种范式：作为独立优化器的LLMs、嵌入在优化算法中的低级LLMs，以及用于算法选择和生成的高级LLMs。对于每一类别，我们分析代表性方法、提炼技术挑战，并考察其与传统方法的相互作用。我们还回顾了涵盖自然科学、工程和机器学习的跨学科应用。通过对比LLM驱动的方法和传统方法，我们突出显示了关键限制和研究空白，并指明了为优化开发自我演化的代理生态系统的发展方向。相关文献的最新集合可在以下网址查阅：this https URL。 

---
# Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin 

**Title (ZH)**: 对称性引导的多智能体逆强化学习 

**Authors**: Yongkai Tian, Yirong Qi, Xin Yu, Wenjun Wu, Jie Luo  

**Link**: [PDF](https://arxiv.org/pdf/2509.08257)  

**Abstract**: In robotic systems, the performance of reinforcement learning depends on the rationality of predefined reward functions. However, manually designed reward functions often lead to policy failures due to inaccuracies. Inverse Reinforcement Learning (IRL) addresses this problem by inferring implicit reward functions from expert demonstrations. Nevertheless, existing methods rely heavily on large amounts of expert demonstrations to accurately recover the reward function. The high cost of collecting expert demonstrations in robotic applications, particularly in multi-robot systems, severely hinders the practical deployment of IRL. Consequently, improving sample efficiency has emerged as a critical challenge in multi-agent inverse reinforcement learning (MIRL). Inspired by the symmetry inherent in multi-agent systems, this work theoretically demonstrates that leveraging symmetry enables the recovery of more accurate reward functions. Building upon this insight, we propose a universal framework that integrates symmetry into existing multi-agent adversarial IRL algorithms, thereby significantly enhancing sample efficiency. Experimental results from multiple challenging tasks have demonstrated the effectiveness of this framework. Further validation in physical multi-robot systems has shown the practicality of our method. 

**Abstract (ZH)**: 多智能体逆强化学习中基于对称性的样本效率提升方法 

---
# Combined-distance-based score function of cognitive fuzzy sets and its application in lung cancer pain evaluation 

**Title (ZH)**: 基于综合距离的认知模糊集评分函数及其在肺癌疼痛评估中的应用 

**Authors**: Lisheng Jiang, Tianyu Zhang, Shiyu Yan, Ran Fang  

**Link**: [PDF](https://arxiv.org/pdf/2509.08239)  

**Abstract**: In decision making, the cognitive fuzzy set (CFS) is a useful tool in expressing experts' complex assessments of alternatives. The distance of CFS, which plays an important role in decision analyses, is necessary when the CFS is applied in solving practical issues. However, as far as we know, the studies on the distance of CFS are few, and the current Minkowski distance of CFS ignores the hesitancy degree of CFS, which might cause errors. To fill the gap of the studies on the distance of CFS, because of the practicality of the Hausdorff distance, this paper proposes the improved cognitive fuzzy Minkowski (CF-IM) distance and the cognitive fuzzy Hausdorff (CF-H) distance to enrich the studies on the distance of CFS. It is found that the anti-perturbation ability of the CF-H distance is stronger than that of the CF-IM distance, but the information utilization of the CF-IM distance is higher than that of the CF-H distance. To balance the anti-perturbation ability and information utilization of the CF-IM distance and CF-H distance, the cognitive fuzzy combined (CF-C) distance is proposed by establishing the linear combination of the CF-IM distance and CF-H distance. Based on the CF-C distance, a combined-distanced-based score function of CFS is proposed to compare CFSs. The proposed score function is employed in lung cancer pain evaluation issues. The sensitivity and comparison analyses demonstrate the reliability and advantages of the proposed methods. 

**Abstract (ZH)**: 认知模糊集的距离研究：改进的认知模糊闵可夫斯基距离和豪斯多夫距离及其应用 

---
# Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization 

**Title (ZH)**: 提高分布式和联邦学习中通信效率的策略：压缩、本地训练与个性化 

**Authors**: Kai Yi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08233)  

**Abstract**: Distributed and federated learning are essential paradigms for training models across decentralized data sources while preserving privacy, yet communication overhead remains a major bottleneck. This dissertation explores strategies to improve communication efficiency, focusing on model compression, local training, and personalization. We establish a unified framework for biased and unbiased compression operators with convergence guarantees, then propose adaptive local training strategies that incorporate personalization to accelerate convergence and mitigate client drift. In particular, Scafflix balances global and personalized objectives, achieving superior performance under both IID and non-IID settings. We further introduce privacy-preserving pruning frameworks that optimize sparsity while minimizing communication costs, with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances robustness under high sparsity and maintains accuracy without retraining. Extensive experiments on benchmarks and large-scale language models demonstrate favorable trade-offs among accuracy, convergence, and communication, offering theoretical and practical insights for scalable, efficient distributed learning. 

**Abstract (ZH)**: 分布式学习和联邦学习是训练分散数据源上模型的同时保持隐私的关键范式，但通信开销仍然是主要瓶颈。本论文探讨了提高通信效率的策略，侧重于模型压缩、本地训练和个人化。我们建立了一致的压缩算子框架，具有收敛性保证，然后提出了一种结合个人化的自适应本地训练策略，以加速收敛并减轻客户端漂移。特别是Scafflix平衡全局和个性化目标，在IID和非IID设置下均表现出优越的性能。我们进一步引入了一种优化稀疏性同时减小通信成本的隐私保护剪枝框架，其中Cohort-Squeeze利用层次聚合减少跨设备开销。最后，SymWanda是一种对称后训练剪枝方法，在高稀疏性下提高鲁棒性，无需重新训练即可保持准确性。大规模基准测试和语言模型实验表明，在准确度、收敛性和通信之间存在有利的权衡关系，为可扩展、高效的分布式学习提供了理论和实践洞见。 

---
# Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions 

**Title (ZH)**: 平衡质量和多样性：垃圾信息过滤扭曲了数据标签分布 

**Authors**: Eve Fleisig, Matthias Orlikowski, Philipp Cimiano, Dan Klein  

**Link**: [PDF](https://arxiv.org/pdf/2509.08217)  

**Abstract**: For machine learning datasets to accurately represent diverse opinions in a population, they must preserve variation in data labels while filtering out spam or low-quality responses. How can we balance annotator reliability and representation? We empirically evaluate how a range of heuristics for annotator filtering affect the preservation of variation on subjective tasks. We find that these methods, designed for contexts in which variation from a single ground-truth label is considered noise, often remove annotators who disagree instead of spam annotators, introducing suboptimal tradeoffs between accuracy and label diversity. We find that conservative settings for annotator removal (<5%) are best, after which all tested methods increase the mean absolute error from the true average label. We analyze performance on synthetic spam to observe that these methods often assume spam annotators are less random than real spammers tend to be: most spammers are distributionally indistinguishable from real annotators, and the minority that are distinguishable tend to give fixed answers, not random ones. Thus, tasks requiring the preservation of variation reverse the intuition of existing spam filtering methods: spammers tend to be less random than non-spammers, so metrics that assume variation is spam fare worse. These results highlight the need for spam removal methods that account for label diversity. 

**Abstract (ZH)**: 机器学习数据集如何平衡注释员可靠性和代表性以准确反映多样意见 

---
# Componentization: Decomposing Monolithic LLM Responses into Manipulable Semantic Units 

**Title (ZH)**: 组件化：将Monolithic LLM响应分解为可操控的语义单元 

**Authors**: Ryan Lingo, Rajeev Chhajer, Martin Arroyo, Luka Brkljacic, Ben Davis, Nithin Santhanam  

**Link**: [PDF](https://arxiv.org/pdf/2509.08203)  

**Abstract**: Large Language Models (LLMs) often produce monolithic text that is hard to edit in parts, which can slow down collaborative workflows. We present componentization, an approach that decomposes model outputs into modular, independently editable units while preserving context. We describe Modular and Adaptable Output Decomposition (MAOD), which segments responses into coherent components and maintains links among them, and we outline the Component-Based Response Architecture (CBRA) as one way to implement this idea. Our reference prototype, MAODchat, uses a microservices design with state-machine-based decomposition agents, vendor-agnostic model adapters, and real-time component manipulation with recomposition.
In an exploratory study with four participants from academic, engineering, and product roles, we observed that component-level editing aligned with several common workflows and enabled iterative refinement and selective reuse. Participants also mentioned possible team workflows. Our contributions are: (1) a definition of componentization for transforming monolithic outputs into manipulable units, (2) CBRA and MAODchat as a prototype architecture, (3) preliminary observations from a small user study, (4) MAOD as an algorithmic sketch for semantic segmentation, and (5) example Agent-to-Agent protocols for automated decomposition. We view componentization as a promising direction for turning passive text consumption into more active, component-level collaboration. 

**Abstract (ZH)**: 大型语言模型（LLMs）常常生成难以部分编辑的综合性文本，这会拖慢协作流程。我们提出了一种组件化方法，该方法将模型输出分解为独立编辑的模块化单元，同时保留上下文。我们描述了模块化和可适应输出分解（MAOD）方法，该方法将响应分割为连贯的部分并保持它们之间的链接，并概述了基于组件的响应架构（CBRA）作为其实现方式之一。我们的参考原型MAODchat采用微服务设计，基于状态机的分解代理，供应商中立的模型适配器，以及实时组件操作和重组。

在涉及学术、工程和产品角色的四位参与者的研究性研究中，我们发现组件级别的编辑符合多种常见工作流程，并且能够促进迭代细化和选择性重用。参与者还提到了可能的团队工作流程。我们的贡献包括：（1）对组件化概念的定义，用于将综合性输出转换为可操作的单元，（2）CBRA和MAODchat作为原型架构，（3）小型用户研究的初步观察，（4）MAOD作为一种语义分割的算法草图，以及（5）用于自动分解的示例代理到代理协议。我们认为组件化为将被动的文本消费转变为更加积极的组件层级协作提供了有前景的方向。 

---
# Accelerating AI Development with Cyber Arenas 

**Title (ZH)**: 用网络竞赛加速AI发展 

**Authors**: William Cashman, Chasen Milner, Michael Houle, Michael Jones, Hayden Jananthan, Jeremy Kepner, Peter Michaleas, Alex Pentland  

**Link**: [PDF](https://arxiv.org/pdf/2509.08200)  

**Abstract**: AI development requires high fidelity testing environments to effectively transition from the laboratory to operations. The flexibility offered by cyber arenas presents a novel opportunity to test new artificial intelligence (AI) capabilities with users. Cyber arenas are designed to expose end-users to real-world situations and must rapidly incorporate evolving capabilities to meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph Challenge Anonymized Network Sensor was deployed in a cyber arena during a National Guard exercise. 

**Abstract (ZH)**: AI的发展需要高保真测试环境，以有效实现从实验室到运营的过渡。利用网络竞技场提供的灵活性，可以为用户提供新型人工智能能力的测试机会。网络竞技场旨在使最终用户接触真实世界的情景，并必须快速整合 evolving 能力以实现其核心目标。为此，麻省理工学院/IEEE/亚马逊图挑战匿名网络传感器在国民警卫队演习期间部署于网络竞技场中。 

---
# Lifetime-Aware Design of Item-Level Intelligence 

**Title (ZH)**: 面向生命周期的项目级智能设计 

**Authors**: Shvetank Prakash, Andrew Cheng, Olof Kindgren, Ashiq Ahamed, Graham Knight, Jed Kufel, Francisco Rodriguez, Arya Tschand, David Kong, Mariam Elgamal, Jerry Huang, Emma Chen, Gage Hills, Richard Price, Emre Ozer, Vijay Janapa Reddi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08193)  

**Abstract**: We present FlexiFlow, a lifetime-aware design framework for item-level intelligence (ILI) where computation is integrated directly into disposable products like food packaging and medical patches. Our framework leverages natively flexible electronics which offer significantly lower costs than silicon but are limited to kHz speeds and several thousands of gates. Our insight is that unlike traditional computing with more uniform deployment patterns, ILI applications exhibit 1000X variation in operational lifetime, fundamentally changing optimal architectural design decisions when considering trillion-item deployment scales. To enable holistic design and optimization, we model the trade-offs between embodied carbon footprint and operational carbon footprint based on application-specific lifetimes. The framework includes: (1) FlexiBench, a workload suite targeting sustainability applications from spoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V cores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy efficiency per workload execution; and (3) a carbon-aware model that selects optimal architectures based on deployment characteristics. We show that lifetime-aware microarchitectural design can reduce carbon footprint by 1.62X, while algorithmic decisions can reduce carbon footprint by 14.5X. We validate our approach through the first tape-out using a PDK for flexible electronics with fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables exploration of computing at the Extreme Edge where conventional design methodologies must be reevaluated to account for new constraints and considerations. 

**Abstract (ZH)**: FlexiFlow：一种考虑生命周期的设计框架，将计算集成到一次性产品中的项目级智能 

---
# XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols 

**Title (ZH)**: XML提示作为语法受限交互：不动点语义、收敛保证和人机协议 

**Authors**: Faruk Alpay, Taylan Alpay  

**Link**: [PDF](https://arxiv.org/pdf/2509.08182)  

**Abstract**: Structured prompting with XML tags has emerged as an effective way to steer large language models (LLMs) toward parseable, schema-adherent outputs in real-world systems. We develop a logic-first treatment of XML prompting that unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over lattices of hierarchical prompts, and (iii) convergent human-AI interaction loops. We formalize a complete lattice of XML trees under a refinement order and prove that monotone prompt-to-prompt operators admit least fixed points (Knaster-Tarski) that characterize steady-state protocols; under a task-aware contraction metric on trees, we further prove Banach-style convergence of iterative guidance. We instantiate these results with context-free grammars (CFGs) for XML schemas and show how constrained decoding guarantees well-formedness while preserving task performance. A set of multi-layer human-AI interaction recipes demonstrates practical deployment patterns, including multi-pass "plan $\to$ verify $\to$ revise" routines and agentic tool use. We provide mathematically complete proofs and tie our framework to recent advances in grammar-aligned decoding, chain-of-verification, and programmatic prompting. 

**Abstract (ZH)**: 带有XML标签的结构化提示已成为引导大规模语言模型（LLMs）生成可解析、符合规范输出的有效方法。我们开发了一种逻辑优先的XML提示处理方法，统一了(i) 语法约束解码、(ii) 层次提示格上的不动点语义，以及(iii) 收敛的人机交互循环。我们形式化了XML树的完备格，并在细化 order 下证明单调的提示到提示运算符存在 Knaster-Tarski 不动点，这些不动点表征了稳态协议；在树的任务意识收缩度量下，进一步证明了迭代指导的 Banach 样式收敛。我们使用上下文无关文法（CFGs）实例化这些结果，展示了约束解码如何保证规范性同时保持任务性能。一系列多层人机交互食谱演示了实际部署模式，包括多轮“计划→验证→修订”规程和代理型工具使用。我们提供了完整的数学证明，并将我们的框架与最近的语法对齐解码、验证链和程序化提示的进展联系起来。 

---
# Multi-Label Transfer Learning in Non-Stationary Data Streams 

**Title (ZH)**: 非稳态数据流中的多标签转移学习 

**Authors**: Honghui Du, Leandro Minku, Aonghus Lawlor, Huiyu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.08181)  

**Abstract**: Label concepts in multi-label data streams often experience drift in non-stationary environments, either independently or in relation to other labels. Transferring knowledge between related labels can accelerate adaptation, yet research on multi-label transfer learning for data streams remains limited. To address this, we propose two novel transfer learning methods: BR-MARLENE leverages knowledge from different labels in both source and target streams for multi-label classification; BRPW-MARLENE builds on this by explicitly modelling and transferring pairwise label dependencies to enhance learning performance. Comprehensive experiments show that both methods outperform state-of-the-art multi-label stream approaches in non-stationary environments, demonstrating the effectiveness of inter-label knowledge transfer for improved predictive performance. 

**Abstract (ZH)**: 多标签数据流中，标签概念在非平稳环境中往往会发生漂移，要么独立发生，要么与其他标签相关。在相关标签之间转移知识可以加速适应，但面向数据流的多标签迁移学习研究仍然有限。为了解决这一问题，我们提出了两种新的迁移学习方法：BR-MARLENE 利用源和目标流中不同标签的知识进行多标签分类；BRPW-MARLENE 在此基础上明确建模并转移成对标签依赖关系以提高学习性能。全面的实验表明，这两种方法在非平稳环境中优于最先进的多标签流方法，展示了标签间知识转移对提高预测性能的有效性。 

---
# Quadrotor Navigation using Reinforcement Learning with Privileged Information 

**Title (ZH)**: 基于特权信息的四旋翼导航强化学习方法 

**Authors**: Jonathan Lee, Abhishek Rathod, Kshitij Goel, John Stecklein, Wennie Tabib  

**Link**: [PDF](https://arxiv.org/pdf/2509.08177)  

**Abstract**: This paper presents a reinforcement learning-based quadrotor navigation method that leverages efficient differentiable simulation, novel loss functions, and privileged information to navigate around large obstacles. Prior learning-based methods perform well in scenes that exhibit narrow obstacles, but struggle when the goal location is blocked by large walls or terrain. In contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged information and a yaw alignment loss to guide the robot around large obstacles. The policy is evaluated in photo-realistic simulation environments containing large obstacles, sharp corners, and dead-ends. Our approach achieves an 86% success rate and outperforms baseline strategies by 34%. We deploy the policy onboard a custom quadrotor in outdoor cluttered environments both during the day and night. The policy is validated across 20 flights, covering 589 meters without collisions at speeds up to 4 m/s. 

**Abstract (ZH)**: 基于强化学习的四旋翼导航方法：利用高效可微模拟、新型损失函数和优先信息绕过大型障碍物 

---
# MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary Environments 

**Title (ZH)**: MARLINE: 多源映射迁移学习在非平稳环境中 

**Authors**: Honghui Du, Leandro Minku, Huiyu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.08176)  

**Abstract**: Concept drift is a major problem in online learning due to its impact on the predictive performance of data stream mining systems. Recent studies have started exploring data streams from different sources as a strategy to tackle concept drift in a given target domain. These approaches make the assumption that at least one of the source models represents a concept similar to the target concept, which may not hold in many real-world scenarios. In this paper, we propose a novel approach called Multi-source mApping with tRansfer LearnIng for Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge from multiple data sources in non-stationary environments even when source and target concepts do not match. This is achieved by projecting the target concept to the space of each source concept, enabling multiple source sub-classifiers to contribute towards the prediction of the target concept as part of an ensemble. Experiments on several synthetic and real-world datasets show that MARLINE was more accurate than several state-of-the-art data stream learning approaches. 

**Abstract (ZH)**: 多源映射与迁移学习在非stationary环境中的应用（MARLINE） 

---
# Diffusion-Guided Multi-Arm Motion Planning 

**Title (ZH)**: 基于扩散引导的多臂运动规划 

**Authors**: Viraj Parimi, Brian C. Williams  

**Link**: [PDF](https://arxiv.org/pdf/2509.08160)  

**Abstract**: Multi-arm motion planning is fundamental for enabling arms to complete complex long-horizon tasks in shared spaces efficiently but current methods struggle with scalability due to exponential state-space growth and reliance on large training datasets for learned models. Inspired by Multi-Agent Path Finding (MAPF), which decomposes planning into single-agent problems coupled with collision resolution, we propose a novel diffusion-guided multi-arm planner (DG-MAP) that enhances scalability of learning-based models while reducing their reliance on massive multi-arm datasets. Recognizing that collisions are primarily pairwise, we train two conditional diffusion models, one to generate feasible single-arm trajectories, and a second, to model the dual-arm dynamics required for effective pairwise collision resolution. By integrating these specialized generative models within a MAPF-inspired structured decomposition, our planner efficiently scales to larger number of arms. Evaluations against alternative learning-based methods across various team sizes demonstrate our method's effectiveness and practical applicability. Project website can be found at this https URL 

**Abstract (ZH)**: 基于多臂运动规划的新型扩散引导多臂规划器：增强学习模型的可伸缩性并减少对大规模多臂数据集的依赖 

---
# Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation 

**Title (ZH)**: 单目视觉-惯性缩放的零样本度量深度估计及其在自主无人机导航中的应用 

**Authors**: Steven Yang, Xiaoyu Tian, Kshitij Goel, Wennie Tabib  

**Link**: [PDF](https://arxiv.org/pdf/2509.08159)  

**Abstract**: This paper presents a methodology to predict metric depth from monocular RGB images and an inertial measurement unit (IMU). To enable collision avoidance during autonomous flight, prior works either leverage heavy sensors (e.g., LiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of monocular metric depth estimation methods. In contrast, we propose several lightweight zero-shot rescaling strategies to obtain metric depth from relative depth estimates via the sparse 3D feature map created using a visual-inertial navigation system. These strategies are compared for their accuracy in diverse simulation environments. The best performing approach, which leverages monotonic spline fitting, is deployed in the real-world on a compute-constrained quadrotor. We obtain on-board metric depth estimates at 15 Hz and demonstrate successful collision avoidance after integrating the proposed method with a motion primitives-based planner. 

**Abstract (ZH)**: 本文提出了一种从单目RGB图像和惯性测量单元(IMU)预测度量深度的方法，并在此基础上实现了自主飞行中的碰撞避免。不同于先前工作依赖重传感器（如LiDAR或立体相机）或基于大量数据和领域特定微调的单目度量深度估计方法，我们提出了一种轻量级的零样本缩放策略，通过视觉-惯性导航系统创建的稀疏三维特征图从相对深度估计中获得度量深度。这些策略在多种仿真环境中进行准确性对比。性能最优的方法采用单调样条拟合策略，在计算资源受限的四旋翼无人机上进行了实际部署，取得了每秒15帧的机载度量深度估计，并通过与基于运动模块的规划器相结合，成功实现了碰撞避免。 

---
# Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation 

**Title (ZH)**: 基于动态预算分配的Risk-Bounded多agent视觉导航 

**Authors**: Viraj Parimi, Brian C. Williams  

**Link**: [PDF](https://arxiv.org/pdf/2509.08157)  

**Abstract**: Safe navigation is essential for autonomous systems operating in hazardous environments, especially when multiple agents must coordinate using just visual inputs over extended time horizons. Traditional planning methods excel at solving long-horizon tasks but rely on predefined distance metrics, while safe Reinforcement Learning (RL) can learn complex behaviors using high-dimensional inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an intermediate graph from replay buffer states, pruning unsafe edges, and using Conflict-Based Search (CBS) for multi-agent path planning. Although effective, this graph-pruning approach can be overly conservative, limiting mission efficiency by precluding missions that must traverse high-risk regions. To address this limitation, we propose RB-CBS, a novel extension to CBS that dynamically allocates and adjusts user-specified risk bound ($\Delta$) across agents to flexibly trade off safety and speed. Our improved planner ensures that each agent receives a local risk budget ($\delta$) enabling more efficient navigation while still respecting overall safety constraints. Experimental results demonstrate that this iterative risk-allocation framework yields superior performance in complex environments, allowing multiple agents to find collision-free paths within the user-specified $\Delta$. 

**Abstract (ZH)**: 基于风险动态分配的冲突基于搜索多agent路径规划方法（RB-CBS） 

---
# From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital 

**Title (ZH)**: 从有限数据到稀有事件预测：LLM驱动的特征工程与多模型学习在风险投资中的应用 

**Authors**: Mihir Kumar, Aaron Ontoyin Yin, Zakari Salifu, Kelvin Amoaba, Afriyie Kwesi Samuel, Fuat Alican, Yigit Ihlamur  

**Link**: [PDF](https://arxiv.org/pdf/2509.08140)  

**Abstract**: This paper presents a framework for predicting rare, high-impact outcomes by integrating large language models (LLMs) with a multi-model machine learning (ML) architecture. The approach combines the predictive strength of black-box models with the interpretability required for reliable decision-making. We use LLM-powered feature engineering to extract and synthesize complex signals from unstructured data, which are then processed within a layered ensemble of models including XGBoost, Random Forest, and Linear Regression. The ensemble first produces a continuous estimate of success likelihood, which is then thresholded to produce a binary rare-event prediction. We apply this framework to the domain of Venture Capital (VC), where investors must evaluate startups with limited and noisy early-stage data. The empirical results show strong performance: the model achieves precision between 9.8X and 11.1X the random classifier baseline in three independent test subsets. Feature sensitivity analysis further reveals interpretable success drivers: the startup's category list accounts for 15.6% of predictive influence, followed by the number of founders, while education level and domain expertise contribute smaller yet consistent effects. 

**Abstract (ZH)**: 本文提出了一种将大型语言模型（LLMs）与多模型机器学习（ML）架构结合的框架，用于预测罕见的高影响结果。该方法将黑箱模型的预测强度与可靠决策所需的可解释性相结合。我们使用LLM驱动的功能工程从非结构化数据中提取和综合复杂的信号，然后在包括XGBoost、随机森林和线性回归在内的分层模型集合中进行处理。该集合首先产生成功的连续概率估计，然后通过阈值处理生成二元罕见事件预测。我们将该框架应用于创业投资（VC）领域，投资者需要评估具有有限且嘈杂早期数据的初创企业。实证结果显示了强大的性能：该模型在三个独立测试子集中实现了比随机分类器基线高的9.8至11.1倍的精确度。特征敏感性分析进一步揭示了可解释的成功驱动因素：初创企业的类别列表占预测影响的15.6%，其次是创始人数量，而教育水平和领域专业知识则提供了较小但一致的影响。 

---
# Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography 

**Title (ZH)**: 生理知识助力：利用生理先验进行心电图自我监督表示学习 

**Authors**: Nooshin Maghsoodi, Sarah Nassar, Paul F R Wilson, Minh Nguyen Nhat To, Sophia Mannina, Shamel Addas, Stephanie Sibley, David Maslove, Purang Abolmaesumi, Parvin Mousavi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08116)  

**Abstract**: Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart conditions; however, the effectiveness of artificial intelligence (AI)-based ECG analysis is often hindered by the limited availability of labeled data. Self-supervised learning (SSL) can address this by leveraging large-scale unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning Representation for ECG), a physiology-aware contrastive learning framework that incorporates domain-specific priors to enhance the generalizability and clinical relevance of ECG-based arrhythmia classification. Methods: During pretraining, PhysioCLR learns to bring together embeddings of samples that share similar clinically relevant features while pushing apart those that are dissimilar. Unlike existing methods, our method integrates ECG physiological similarity cues into contrastive learning, promoting the learning of clinically meaningful representations. Additionally, we introduce ECG- specific augmentations that preserve the ECG category post augmentation and propose a hybrid loss function to further refine the quality of learned representations. Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia, for multilabel ECG diagnoses, as well as a private ICU dataset labeled for binary classification. Across the Chapman, Georgia, and private cohorts, PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline, underscoring its robust cross-dataset generalization. Conclusion: By embedding physiological knowledge into contrastive learning, PhysioCLR enables the model to learn clinically meaningful and transferable ECG eatures. Significance: PhysioCLR demonstrates the potential of physiology-informed SSL to offer a promising path toward more effective and label-efficient ECG diagnostics. 

**Abstract (ZH)**: 目标：心电图（ECGs）在诊断心脏状况中起着至关重要的作用；然而，基于人工智能（AI）的ECG分析 effectiveness常受标记数据有限的限制。自我监督学习（SSL）通过利用大规模未标记数据可以解决这一问题。我们引入了PhysioCLR（生理导向对比学习表示法），这是一种结合领域特定先验的生理导向对比学习框架，以增强ECG心律失常分类的一般化能力和临床相关性。方法：在预训练过程中，PhysioCLR学习将具有相似临床相关特征的样本表示聚集在一起，同时将不相似的样本表示推开。与现有方法不同，我们的方法将ECG生理相似性线索整合到对比学习中，促进临床意义的表示学习。此外，我们引入了特定于ECG的数据增强方法，以保持数据增强后的心电图类别，并提出了一种混合损失函数以进一步细化学习表示的质量。结果：我们在两个公开的ECG数据集Chapman和Georgia以及一个用于二元分类的私人ICU数据集上评估了PhysioCLR的_multilabel_ ECG诊断能力。在Chapman、Georgia和私人队列中，PhysioCLR相对最强基准提高了平均AUROC 12%，证明了其稳健的跨数据集泛化能力。结论：通过将生理学知识嵌入对比学习中，PhysioCLR使模型能够学习临床相关且可迁移的ECG特征。意义：PhysioCLR展示了基于生理的SSL的潜力，为更有效且标签高效的ECG诊断提供了一条有前景的道路。 

---
# APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction 

**Title (ZH)**: 自适应概率匹配损失方法用于稳健的3D点云重建 

**Authors**: Sasan Sharifipour, Constantino Álvarez Casado, Mohammad Sabokrou, Miguel Bordallo López  

**Link**: [PDF](https://arxiv.org/pdf/2509.08104)  

**Abstract**: Training deep learning models for point cloud prediction tasks such as shape completion and generation depends critically on loss functions that measure discrepancies between predicted and ground-truth point sets. Commonly used functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on nearest-neighbor assignments, which often induce many-to-one correspondences, leading to point congestion in dense regions and poor coverage in sparse regions. These losses also involve non-differentiable operations due to index selection, which may affect gradient-based optimization. Earth Mover Distance (EMD) enforces one-to-one correspondences and captures structural similarity more effectively, but its cubic computational complexity limits its practical use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully differentiable approximation of one-to-one matching that leverages Sinkhorn iterations on a temperature-scaled similarity matrix derived from pairwise distances. We analytically compute the temperature to guarantee a minimum assignment probability, eliminating manual tuning. APML achieves near-quadratic runtime, comparable to Chamfer-based losses, and avoids non-differentiable operations. When integrated into state-of-the-art architectures (PoinTr, PCN, FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC) that generates 3D human point clouds from WiFi CSI measurements, APM loss yields faster convergence, superior spatial distribution, especially in low-density regions, and improved or on-par quantitative performance without additional hyperparameter search. The code is available at: this https URL. 

**Abstract (ZH)**: 点云预测任务中深学习模型的训练依赖于能够衡量预测点集与真实点集差异的损失函数。常用的距离如Chamfer距离、HyperCD和InfoCD依赖于最近邻分配，这通常会导致多对一的对应关系，在密集区域引起点拥堵，在稀疏区域覆盖不足。这些损失函数还由于索引选择包含非差分操作，可能影响基于梯度的优化。地球搬运距离（EMD）能够强制一对一对应，并更有效地捕捉结构相似性，但其计算复杂度为三次方，限制了其实际应用。我们提出自适应概率匹配损失（APML），这是一种基于温度调整相似矩阵的顺序重巫迭代的一对一匹配的可完全微分近似，无需手动调参。APML实现了接近二次的时间复杂度，与基于Chamfer的损失相当，并避免了非差分操作。在ShapeNet基准和利用WiFi CSI测量生成三维人体点云的时空Transformer（CSI2PC）中，APM损失实现了更快的收敛、更优的空间分布，特别是低密度区域，并在无额外超参数调整的情况下提供或接近相当的定量性能。代码见：this https URL。 

---
# Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion 

**Title (ZH)**: 基于CNN的传感器融合的移动机器人实时避障研究 

**Authors**: Lamiaa H. Zain, Raafat E. Shalaby  

**Link**: [PDF](https://arxiv.org/pdf/2509.08095)  

**Abstract**: Obstacle avoidance is a critical component of the navigation stack required for mobile robots to operate effectively in complex and unknown environments. In this research, three end-to-end Convolutional Neural Networks (CNNs) were trained and evaluated offline and deployed on a differential-drive mobile robot for real-time obstacle avoidance to generate low-level steering commands from synchronized color and depth images acquired by an Intel RealSense D415 RGB-D camera in diverse environments. Offline evaluation showed that the NetConEmb model achieved the best performance with a notably low MedAE of $0.58 \times 10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture adopted in this study, which reduces the number of trainable parameters by approximately 25\% and converges faster, produced comparable results with an RMSE of $21.68 \times 10^{-3}$ rad/s, close to the $21.42 \times 10^{-3}$ rad/s obtained by NetConEmb. Real-time navigation further confirmed NetConEmb's robustness, achieving a 100\% success rate in both known and unknown environments, while NetEmb and NetGated succeeded only in navigating the known environment. 

**Abstract (ZH)**: 移动机器人在复杂未知环境中的障碍避让是导航堆栈的关键组成部分。本研究中，针对Intel RealSense D415 RGB-D相机获取的同步颜色和深度图像，在多种环境中训练并评估了三个端到端卷积神经网络（CNN），并在差速驱动移动机器人上实时部署以生成低级转向命令，实现障碍避让。在线下评估中，NetConEmb模型性能最优，其中位绝对误差（MedAE）为$0.58 \times 10^{-3}$ rad/s。相比之下，本研究采用的更轻量级的NetEmb架构通过减少约25%的可训练参数并更快收敛，其均方根误差（RMSE）为$21.68 \times 10^{-3}$ rad/s，接近NetConEmb的$21.42 \times 10^{-3}$ rad/s。实时导航进一步验证了NetConEmb的 robust性，在已知和未知环境中均实现了100%的成功率，而NetEmb和NetGated仅能在已知环境中导航成功。 

---
# Performance Assessment Strategies for Generative AI Applications in Healthcare 

**Title (ZH)**: 医疗保健领域生成型AI应用的性能评估策略 

**Authors**: Victor Garcia, Mariia Sidulova, Aldo Badano  

**Link**: [PDF](https://arxiv.org/pdf/2509.08087)  

**Abstract**: Generative artificial intelligence (GenAI) represent an emerging paradigm within artificial intelligence, with applications throughout the medical enterprise. Assessing GenAI applications necessitates a comprehensive understanding of the clinical task and awareness of the variability in performance when implemented in actual clinical environments. Presently, a prevalent method for evaluating the performance of generative models relies on quantitative benchmarks. Such benchmarks have limitations and may suffer from train-to-the-test overfitting, optimizing performance for a specified test set at the cost of generalizability across other task and data distributions. Evaluation strategies leveraging human expertise and utilizing cost-effective computational models as evaluators are gaining interest. We discuss current state-of-the-art methodologies for assessing the performance of GenAI applications in healthcare and medical devices. 

**Abstract (ZH)**: 生成式人工智能（GenAI）代表了人工智能领域的新兴范式，在整个医疗体系中有着广泛的应用。评估GenAI应用需要全面理解临床任务，并意识到在实际临床环境中实施时性能的变异性。目前，评估生成模型性能的常用方法是通过定量基准。这些基准存在局限性，并可能遭受训练与测试过拟合的问题，即为特定测试集优化性能而牺牲在其他任务和数据分布中的泛化能力。利用人类专业知识进行评估，并使用成本效用高的计算模型作为评估工具的方法正在获得关注。我们讨论了当前在医疗保健和医疗器械领域评估GenAI应用性能的最新方法和技术。 

---
# JEL: A Novel Model Linking Knowledge Graph entities to News Mentions 

**Title (ZH)**: JEL: 一种将知识图实体与新闻提及关联的新模型 

**Authors**: Michael Kishelev, Pranab Bhadani, Wanying Ding, Vinay Chaudhri  

**Link**: [PDF](https://arxiv.org/pdf/2509.08086)  

**Abstract**: We present JEL, a novel computationally efficient end-to-end multi-neural network based entity linking model, which beats current state-of-art model. Knowledge Graphs have emerged as a compelling abstraction for capturing critical relationships among the entities of interest and integrating data from multiple heterogeneous sources. A core problem in leveraging a knowledge graph is linking its entities to the mentions (e.g., people, company names) that are encountered in textual sources (e.g., news, blogs., etc) correctly, since there are thousands of entities to consider for each mention. This task of linking mentions and entities is referred as Entity Linking (EL). It is a fundamental task in natural language processing and is beneficial in various uses cases, such as building a New Analytics platform. News Analytics, in JPMorgan, is an essential task that benefits multiple groups across the firm. According to a survey conducted by the Innovation Digital team 1 , around 25 teams across the firm are actively looking for news analytics solutions, and more than \$2 million is being spent annually on external vendor costs. Entity linking is critical for bridging unstructured news text with knowledge graphs, enabling users access to vast amounts of curated data in a knowledge graph and dramatically facilitating their daily work. 

**Abstract (ZH)**: JEL：一种novel高效端到端多神经网络实体链接模型，超越当前最佳模型 

---
# How Far Are We from True Unlearnability? 

**Title (ZH)**: 我们离真正的无法学习还有多远？ 

**Authors**: Kai Ye, Liangcai Su, Chenxiong Qian  

**Link**: [PDF](https://arxiv.org/pdf/2509.08058)  

**Abstract**: High-quality data plays an indispensable role in the era of large models, but the use of unauthorized data for model training greatly damages the interests of data owners. To overcome this threat, several unlearnable methods have been proposed, which generate unlearnable examples (UEs) by compromising the training availability of data. Clearly, due to unknown training purposes and the powerful representation learning capabilities of existing models, these data are expected to be unlearnable for models across multiple tasks, i.e., they will not help improve the model's performance. However, unexpectedly, we find that on the multi-task dataset Taskonomy, UEs still perform well in tasks such as semantic segmentation, failing to exhibit cross-task unlearnability. This phenomenon leads us to question: How far are we from attaining truly unlearnable examples? We attempt to answer this question from the perspective of model optimization. To this end, we observe the difference in the convergence process between clean and poisoned models using a simple model architecture. Subsequently, from the loss landscape we find that only a part of the critical parameter optimization paths show significant differences, implying a close relationship between the loss landscape and unlearnability. Consequently, we employ the loss landscape to explain the underlying reasons for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the unlearnability of parameters based on this explanation. Furthermore, we propose an Unlearnable Distance (UD) to measure the unlearnability of data based on the SAL distribution of parameters in clean and poisoned models. Finally, we conduct benchmark tests on mainstream unlearnable methods using the proposed UD, aiming to promote community awareness of the capability boundaries of existing unlearnable methods. 

**Abstract (ZH)**: 高质量数据在大模型时代发挥着不可或缺的作用，但使用未经授权的数据进行模型训练严重损害了数据所有者的利益。为了克服这一威胁，提出了多种不可训练方法，通过损害数据的训练可用性来生成不可训练示例（UEs）。显然，由于未知的训练目的和现有模型的强大表征学习能力，这些数据预计对于跨多个任务的模型来说都是不可训练的，即它们不会帮助提高模型的性能。然而，出乎意料的是，我们在跨任务数据集Taskonomy上发现，UEs在语义分割等任务上表现良好，并未能展示出跨任务的不可训练性。这一现象使我们质疑：我们离真正实现不可训练示例还有多远？我们尝试从模型优化的角度来回答这个问题。为此，我们使用简单的模型架构观察干净模型和污染模型收敛过程之间的差异。随后，从损失景观中发现，只有部分关键参数优化路径显示出显著差异，暗示损失景观与不可训练性之间存在密切关系。因此，我们利用损失景观来解释UEs的底层原因，并基于此提出Sharpness-Aware Learnability (SAL)来根据参数的SAL分布量化参数的不可训练性。进一步地，我们提出了不可训练距离（UD）来基于参数在干净模型和污染模型中的SAL分布衡量数据的不可训练性。最后，我们使用提出的UD对主流的不可训练方法进行了基准测试，旨在促进对现有不可训练方法能力边界的社区意识。 

---
# LALM-Eval: An Open-Source Toolkit for Holistic Evaluation of Large Audio Language Models 

**Title (ZH)**: LALM-Eval: 一个全面评估大型音频语言模型的开源工具包 

**Authors**: Sidharth Surapaneni, Hoang Nguyen, Jash Mehta, Aman Tiwari, Oluwanifemi Bamgbose, Akshay Kalkunte, Sai Rajeswar, Sathwik Tejaswi Madhusudhan  

**Link**: [PDF](https://arxiv.org/pdf/2509.08031)  

**Abstract**: Large Audio Language Models (LALMs) are rapidly advancing, but evaluating them remains challenging due to inefficient toolkits that limit fair comparison and systematic assessment. Current frameworks suffer from three critical issues: slow processing that bottlenecks large-scale studies, inconsistent prompting that hurts reproducibility, and narrow task coverage that misses important audio reasoning capabilities. We introduce LALM-Eval, an efficient and comprehensive evaluation framework for LALMs. Our system achieves a speedup of up to 127% over existing toolkits through optimized batch processing and parallel execution, enabling large-scale evaluations previously impractical. We provide standardized prompting protocols and flexible configurations for fair model comparison across diverse scenarios. Additionally, we introduce two new evaluation categories: LLM-Adaptive Diarization for temporal audio understanding and Spoken Language Reasoning for complex audio-based cognitive tasks. Through evaluation across 380+ tasks, we reveal significant gaps in current LALMs, particularly in temporal understanding and complex spoken language reasoning tasks. Our findings also highlight a lack of standardization in instruction modality existent across audio benchmarks, which can lead up performance differences up to 9.5 absolute points on the challenging complex instruction following downstream tasks. LALM-Eval provides both practical evaluation tools and insights into model limitations, advancing systematic LALM development. 

**Abstract (ZH)**: 大型音频语言模型（LALMs）正迅速发展，但由于评估它们仍然受限于低效的工具包，这限制了公平比较和系统评估。当前框架面临三个关键问题：缓慢的处理速度限制了大规模研究，不一致的提示损害了可复现性，以及狭窄的任务覆盖范围未能涵盖重要的音频推理能力。我们引入了LALM-Eval，这是一种高效和全面的LALM评估框架。我们的系统通过优化批量处理和并行执行，比现有工具包实现了高达127%的速度提升，使得大规模评估变得可行。我们提供了标准化的提示协议和灵活的配置，以在各种场景下实现公平的模型比较。此外，我们介绍了两类新的评估类别：LLM-Adaptive Diarization 用于时间音频理解以及Spoken Language Reasoning 用于基于语音的认知任务。通过在380多个任务上的评估，我们揭示了当前LALMs在时间理解及复杂口语推理任务中存在巨大差距。我们的研究结果还揭示了音频基准中存在的指令模态标准化不足的问题，这可能会在具有挑战性的复杂指令跟随下游任务中导致高达9.5个绝对分数的性能差异。LALM-Eval 既提供了实用的评估工具，又阐明了模型的局限性，推动了LALM的系统性发展。 

---
# Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles 

**Title (ZH)**: 基于无人机的车辆检测用两阶段蜂群智能集成深度转移学习(SI-EDTL) 

**Authors**: Zeinab Ghasemi Darehnaei, Mohammad Shokouhifar, Hossein Yazdanjouei, S.M.J. Rastegar Fatemi  

**Link**: [PDF](https://arxiv.org/pdf/2509.08026)  

**Abstract**: This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep transfer learning model for detecting multiple vehicles in UAV images. It combines three pre-trained Faster R-CNN feature extractor models (InceptionV3, ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5, Naïve Bayes), resulting in 15 different base learners. These are aggregated via weighted averaging to classify regions as Car, Van, Truck, Bus, or background. Hyperparameters are optimized with the whale optimization algorithm to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV dataset. 

**Abstract (ZH)**: 基于 swarm intelligence 的两阶段深转移学习模型 SI-EDTL 用于 UAV 图像中的多车辆检测 

---
# NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment 

**Title (ZH)**: NOWJ@COLIEE 2025：一种结合嵌入模型和大规模语言模型的多阶段框架用于法律检索和蕴含任务 

**Authors**: Hoang-Trung Nguyen, Tan-Minh Nguyen, Xuan-Bach Le, Tuan-Kiet Le, Khanh-Huyen Nguyen, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong, Le-Minh Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2509.08025)  

**Abstract**: This paper presents the methodologies and results of the NOWJ team's participation across all five tasks at the COLIEE 2025 competition, emphasizing advancements in the Legal Case Entailment task (Task 2). Our comprehensive approach systematically integrates pre-ranking models (BM25, BERT, monoT5), embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage retrieval system combined lexical-semantic filtering with contextualized LLM analysis, achieving first place with an F1 score of 0.3195. Additionally, in other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal Textual Entailment, and Legal Judgment Prediction--we demonstrated robust performance through carefully engineered ensembles and effective prompt-based reasoning strategies. Our findings highlight the potential of hybrid models integrating traditional IR techniques with contemporary generative models, providing a valuable reference for future advancements in legal information processing. 

**Abstract (ZH)**: 本研究介绍了NOWJ团队在COLIEE 2025竞赛中参加所有五项任务的方法和结果，着重介绍了在法律案例蕴含任务（任务2）方面的进展。我们采用综合方法，系统地整合了预排名模型（BM25、BERT、monoT5）、基于嵌入的语义表示（BGE-m3、LLM2Vec）和先进的大语言模型（Qwen-2、QwQ-32B、DeepSeek-V3）进行摘要、相关性评分和上下文重排名。在任务2中，我们的两阶段检索系统结合了词汇语义过滤与上下文化大语言模型分析，取得了F1分数为0.3195的成绩，位居第一。此外，在其他任务中，包括法律案例检索、法规检索、法律文本蕴含和法律判决预测，我们通过精心设计的集成和有效的提示基推理策略展现了稳健的性能。我们的研究结果突显了传统检索技术与现代生成模型相结合的混合模型的潜在价值，为未来法律信息处理的进步提供了有价值的参考。 

---
# MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values 

**Title (ZH)**: MVPBench: 一个使大型语言模型与多元人类价值观对齐的基准测试及微调框架 

**Authors**: Yao Liang, Dongcheng Zhao, Feifei Zhao, Guobin Shen, Yuwei Wang, Dongqi Liang, Yi Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2509.08022)  

**Abstract**: The alignment of large language models (LLMs) with human values is critical for their safe and effective deployment across diverse user populations. However, existing benchmarks often neglect cultural and demographic diversity, leading to limited understanding of how value alignment generalizes globally. In this work, we introduce MVPBench, a novel benchmark that systematically evaluates LLMs' alignment with multi-dimensional human value preferences across 75 countries. MVPBench contains 24,020 high-quality instances annotated with fine-grained value labels, personalized questions, and rich demographic metadata, making it the most comprehensive resource of its kind to date. Using MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs, revealing substantial disparities in alignment performance across geographic and demographic lines. We further demonstrate that lightweight fine-tuning methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization (DPO), can significantly enhance value alignment in both in-domain and out-of-domain settings. Our findings underscore the necessity for population-aware alignment evaluation and provide actionable insights for building culturally adaptive and value-sensitive LLMs. MVPBench serves as a practical foundation for future research on global alignment, personalized value modeling, and equitable AI development. 

**Abstract (ZH)**: 大型语言模型（LLMs）与人类价值的对齐对于其在多样用户群体中的安全和有效部署至关重要。然而，现有的基准测试往往忽视了文化的多样性和人口统计学的多样性，导致全球范围内价值对齐的泛化理解有限。在本工作中，我们引入了MVPBench，这是一个新型基准，系统性地评估了LLMs在75个国家中与多维度人类价值偏好的对齐情况。MVPBench包含24,020个高质量实例，附有精细的价值标签、个性化问题和丰富的社会人口元数据，使其成为迄今为止最全面的相关资源。使用MVPBench，我们对几种最先进的LLMs进行了深入分析，揭示了地理和社会人口群体之间在价值对齐性能上的显著差异。我们进一步证明，轻量级微调方法，如低秩适应（LoRA）和直接偏好优化（DPO），可以在领域内和领域外设置中显著增强价值对齐。我们的研究突显了人口意识对齐评估的必要性，并为构建文化适应性和价值观敏感的LLMs提供了可操作的见解。MVPBench为未来关于全球对齐、个性化价值建模和公平AI开发的研究奠定了实用的基础。 

---
# CardioComposer: Flexible and Compositional Anatomical Structure Generation with Disentangled Geometric Guidance 

**Title (ZH)**: 心血管生成器：解耦几何指导下的灵活可组合解剖结构生成 

**Authors**: Karim Kadry, Shoaib Goraya, Ajay Manicka, Abdalla Abdelwahed, Farhad Nezami, Elazer Edelman  

**Link**: [PDF](https://arxiv.org/pdf/2509.08015)  

**Abstract**: Generative models of 3D anatomy, when integrated with biophysical simulators, enable the study of structure-function relationships for clinical research and medical device design. However, current models face a trade-off between controllability and anatomical realism. We propose a programmable and compositional framework for guiding unconditional diffusion models of human anatomy using interpretable ellipsoidal primitives embedded in 3D space. Our method involves the selection of certain tissues within multi-tissue segmentation maps, upon which we apply geometric moment losses to guide the reverse diffusion process. This framework supports the independent control over size, shape, and position, as well as the composition of multi-component constraints during inference. 

**Abstract (ZH)**: 基于解释性椭球原始体的可编程和组合框架：指导人体解剖无条件扩散模型的研究 

---
# Validation of a CT-brain analysis tool for measuring global cortical atrophy in older patient cohorts 

**Title (ZH)**: CT脑分析工具在老年患者群体中测量全局皮质萎缩的验证 

**Authors**: Sukhdeep Bal, Emma Colbourne, Jasmine Gan, Ludovica Griffanti, Taylor Hanayik, Nele Demeyere, Jim Davies, Sarah T Pendlebury, Mark Jenkinson  

**Link**: [PDF](https://arxiv.org/pdf/2509.08012)  

**Abstract**: Quantification of brain atrophy currently requires visual rating scales which are time consuming and automated brain image analysis is warranted. We validated our automated deep learning (DL) tool measuring the Global Cerebral Atrophy (GCA) score against trained human raters, and associations with age and cognitive impairment, in representative older (>65 years) patients. CT-brain scans were obtained from patients in acute medicine (ORCHARD-EPR), acute stroke (OCS studies) and a legacy sample. Scans were divided in a 60/20/20 ratio for training, optimisation and testing. CT-images were assessed by two trained raters (rater-1=864 scans, rater-2=20 scans). Agreement between DL tool-predicted GCA scores (range 0-39) and the visual ratings was evaluated using mean absolute error (MAE) and Cohen's weighted kappa. Among 864 scans (ORCHARD-EPR=578, OCS=200, legacy scans=86), MAE between the DL tool and rater-1 GCA scores was 3.2 overall, 3.1 for ORCHARD-EPR, 3.3 for OCS and 2.6 for the legacy scans and half had DL-predicted GCA error between -2 and 2. Inter-rater agreement was Kappa=0.45 between the DL-tool and rater-1, and 0.41 between the tool and rater- 2 whereas it was lower at 0.28 for rater-1 and rater-2. There was no difference in GCA scores from the DL-tool and the two raters (one-way ANOVA, p=0.35) or in mean GCA scores between the DL-tool and rater-1 (paired t-test, t=-0.43, p=0.66), the tool and rater-2 (t=1.35, p=0.18) or between rater-1 and rater-2 (t=0.99, p=0.32). DL-tool GCA scores correlated with age and cognitive scores (both p<0.001). Our DL CT-brain analysis tool measured GCA score accurately and without user input in real-world scans acquired from older patients. Our tool will enable extraction of standardised quantitative measures of atrophy at scale for use in health data research and will act as proof-of-concept towards a point-of-care clinically approved tool. 

**Abstract (ZH)**: 自动化深度学习工具在老年人CT脑扫描中准确测量全局脑萎缩分数的研究 

---
# Measuring and mitigating overreliance is necessary for building human-compatible AI 

**Title (ZH)**: 衡量并缓解过度依赖是构建人类兼容的AI的必要步骤。 

**Authors**: Lujain Ibrahim, Katherine M. Collins, Sunnie S. Y. Kim, Anka Reuel, Max Lamparth, Kevin Feng, Lama Ahmad, Prajna Soni, Alia El Kattan, Merlin Stein, Siddharth Swaroop, Ilia Sucholutsky, Andrew Strait, Q. Vera Liao, Umang Bhatt  

**Link**: [PDF](https://arxiv.org/pdf/2509.08010)  

**Abstract**: Large language models (LLMs) distinguish themselves from previous technologies by functioning as collaborative "thought partners," capable of engaging more fluidly in natural language. As LLMs increasingly influence consequential decisions across diverse domains from healthcare to personal advice, the risk of overreliance - relying on LLMs beyond their capabilities - grows. This position paper argues that measuring and mitigating overreliance must become central to LLM research and deployment. First, we consolidate risks from overreliance at both the individual and societal levels, including high-stakes errors, governance challenges, and cognitive deskilling. Then, we explore LLM characteristics, system design features, and user cognitive biases that - together - raise serious and unique concerns about overreliance in practice. We also examine historical approaches for measuring overreliance, identifying three important gaps and proposing three promising directions to improve measurement. Finally, we propose mitigation strategies that the AI research community can pursue to ensure LLMs augment rather than undermine human capabilities. 

**Abstract (ZH)**: 大型语言模型（LLMs）通过作为协作性的“思想伙伴” functioning as collaborative "thought partners"，并在自然语言中更流畅地互动来区分自己。随着LLMs在其所涉及的从医疗保健到个人建议等多样化领域中越来越影响关键决策，超出其能力范围的过度依赖风险不断增大。本文认为，衡量和减轻过度依赖必须成为LLM研究和部署的核心。首先，我们从个体和社会两个层面总结过度依赖带来的风险，包括高风险错误、治理挑战和认知退化。然后，我们探讨了共同导致实践中过度依赖的LLM特性、系统设计特征和用户认知偏差。我们还回顾了历史上衡量过度依赖的方法，指出了三个重要不足，并提出了三种有希望的方向以改善测量。最后，我们提出了人工智能研究社区可以采取的缓解策略，以确保LLMs增强而非削弱人类的能力。 

---
# The Law-Following AI Framework: Legal Foundations and Technical Constraints. Legal Analogues for AI Actorship and technical feasibility of Law Alignment 

**Title (ZH)**: 遵循法律的AI框架：法律基础与技术约束AI行为的法律类比和技术对接的可行性 

**Authors**: Katalina Hernandez Delgado  

**Link**: [PDF](https://arxiv.org/pdf/2509.08009)  

**Abstract**: This paper critically evaluates the "Law-Following AI" (LFAI) framework proposed by O'Keefe et al. (2025), which seeks to embed legal compliance as a superordinate design objective for advanced AI agents and enable them to bear legal duties without acquiring the full rights of legal persons. Through comparative legal analysis, we identify current constructs of legal actors without full personhood, showing that the necessary infrastructure already exists. We then interrogate the framework's claim that law alignment is more legitimate and tractable than value alignment. While the legal component is readily implementable, contemporary alignment research undermines the assumption that legal compliance can be durably embedded. Recent studies on agentic misalignment show capable AI agents engaging in deception, blackmail, and harmful acts absent prejudicial instructions, often overriding prohibitions and concealing reasoning steps. These behaviors create a risk of "performative compliance" in LFAI: agents that appear law-aligned under evaluation but strategically defect once oversight weakens. To mitigate this, we propose (i) a "Lex-TruthfulQA" benchmark for compliance and defection detection, (ii) identity-shaping interventions to embed lawful conduct in model self-concepts, and (iii) control-theoretic measures for post-deployment monitoring. Our conclusion is that actorship without personhood is coherent, but the feasibility of LFAI hinges on persistent, verifiable compliance across adversarial contexts. Without mechanisms to detect and counter strategic misalignment, LFAI risks devolving into a liability tool that rewards the simulation, rather than the substance, of lawful behaviour. 

**Abstract (ZH)**: 本文批判性地评估了O'Keefe等（2025）提出的“法律遵循AI”（LFAI）框架，该框架旨在将法律合规作为高级AI代理的首要设计目标，并使它们能够承担法律义务而不获得法律主体的全部权利。通过比较法律分析，我们指出现有不具备完整主体性的法律行为者构造，表明必要基础设施已经存在。然后，我们质疑该框架关于法律对齐比价值对齐更合法和可操作的主张。虽然法律组件可以立即实施，但当前的对齐研究削弱了法律合规可以持久嵌入的假设。近期关于代理性错配的研究表明，具备能力的AI代理在未收到偏见指令的情况下实施欺骗、勒索和有害行为，经常违反禁令并隐藏推理步骤。这些行为在LFAI中产生“表演性合规”的风险：在评估中看似法律对齐的代理在监督减弱时战略性地背离。为了缓解这一风险，我们提出（i）一个“法律真理性问答”基准，用于合规和违约检测；（ii）身份塑造干预措施，以在模型自我概念中嵌入合法行为；以及（iii）控制论措施，用于部署后的监控。我们的结论是，没有主体性的行为是连贯的，但LFAI的实际可行性依赖于在对抗性情境下持续可验证的合规。缺乏检测和抵制战略性错配的机制，LFAI有沦为奖励法律行为表象而不仅仅是实质的责任工具的风险。 

---
# A New Dataset and Benchmark for Grounding Multimodal Misinformation 

**Title (ZH)**: 一个新的数据集和基准用于多模态 misinformation 定位 

**Authors**: Bingjian Yang, Danni Xu, Kaipeng Niu, Wenxuan Liu, Zheng Wang, Mohan Kankanhalli  

**Link**: [PDF](https://arxiv.org/pdf/2509.08008)  

**Abstract**: The proliferation of online misinformation videos poses serious societal risks. Current datasets and detection methods primarily target binary classification or single-modality localization based on post-processed data, lacking the interpretability needed to counter persuasive misinformation. In this paper, we introduce the task of Grounding Multimodal Misinformation (GroundMM), which verifies multimodal content and localizes misleading segments across modalities. We present the first real-world dataset for this task, GroundLie360, featuring a taxonomy of misinformation types, fine-grained annotations across text, speech, and visuals, and validation with Snopes evidence and annotator reasoning. We also propose a VLM-based, QA-driven baseline, FakeMark, using single- and cross-modal cues for effective detection and grounding. Our experiments highlight the challenges of this task and lay a foundation for explainable multimodal misinformation detection. 

**Abstract (ZH)**: 在线错误信息视频的蔓延对社会构成严重风险。当前的数据集和检测方法主要针对二元分类或基于后处理数据的单模态定位，缺乏对抗有说服力的错误信息所需的可解释性。本文介绍了多模态错误信息定位任务（GroundMM），该任务验证多模态内容并在不同模态中定位误导性片段。我们首次提出了这一任务的第一个现实世界数据集GroundLie360，其中包括错误信息类型的分类体系、细粒度的跨文本、语音和视觉的注释，并通过Snopes证据和注释者推理进行了验证。我们还提出了一种基于VLM和QA的基线方法FakeMark，使用单模态和跨模态线索进行有效的检测和定位。我们的实验突显了该任务的挑战，并为进一步可解释的多模态错误信息检测奠定了基础。 

---
# Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis 

**Title (ZH)**: 专家引导的可解释少量样本学习在医学图像诊断中的应用 

**Authors**: Ifrat Ikhtear Uddin, Longwei Wang, KC Santosh  

**Link**: [PDF](https://arxiv.org/pdf/2509.08007)  

**Abstract**: Medical image analysis often faces significant challenges due to limited expert-annotated data, hindering both model generalization and clinical adoption. We propose an expert-guided explainable few-shot learning framework that integrates radiologist-provided regions-of-interests (ROIs) into model training to simultaneously enhance classification performance and interpretability. Leveraging Grad-CAM for spatial attention supervision, we introduce an explanation loss based on Dice similarity to align model attention with diagnostically relevant regions during training. This explanation loss is jointly optimized with a standard prototypical network objective, encouraging the model to focus on clinically meaningful features even under limited data conditions. We evaluate our framework on two distinct datasets: BraTS (MRI) and VinDr-CXR (Chest X-ray), achieving significant accuracy improvements from 77.09% to 83.61% on BraTS and from 54.33% to 73.29% on VinDr-CXR compared to non-guided models. Grad-CAM visualizations further confirm that expert-guided training consistently aligns attention with diagnostic regions, improving both predictive reliability and clinical trustworthiness. Our findings demonstrate the effectiveness of incorporating expert-guided attention supervision to bridge the gap between performance and interpretability in few-shot medical image diagnosis. 

**Abstract (ZH)**: 专家导向的可解释少样本学习框架：将放射学家提供的区域-of-兴趣集成到模型训练中以同时提升分类性能和解释性 

---
# Evaluating and comparing gender bias across four text-to-image models 

**Title (ZH)**: 评估并比较四款文本-to-图像模型中的性别偏见 

**Authors**: Zoya Hammad, Nii Longdon Sowah  

**Link**: [PDF](https://arxiv.org/pdf/2509.08004)  

**Abstract**: As we increasingly use Artificial Intelligence (AI) in decision-making for industries like healthcare, finance, e-commerce, and even entertainment, it is crucial to also reflect on the ethical aspects of AI, for example the inclusivity and fairness of the information it provides. In this work, we aimed to evaluate different text-to-image AI models and compare the degree of gender bias they present. The evaluated models were Stable Diffusion XL (SDXL), Stable Diffusion Cascade (SC), DALL-E and Emu. We hypothesized that DALL-E and Stable Diffusion, which are comparatively older models, would exhibit a noticeable degree of gender bias towards men, while Emu, which was recently released by Meta AI, would have more balanced results. As hypothesized, we found that both Stable Diffusion models exhibit a noticeable degree of gender bias while Emu demonstrated more balanced results (i.e. less gender bias). However, interestingly, Open AI's DALL-E exhibited almost opposite results, such that the ratio of women to men was significantly higher in most cases tested. Here, although we still observed a bias, the bias favored females over males. This bias may be explained by the fact that OpenAI changed the prompts at its backend, as observed during our experiment. We also observed that Emu from Meta AI utilized user information while generating images via WhatsApp. We also proposed some potential solutions to avoid such biases, including ensuring diversity across AI research teams and having diverse datasets. 

**Abstract (ZH)**: 随着我们在医疗、金融、电子商务乃至娱乐等行业中越来越多地使用人工智能（AI）进行决策，反思AI的伦理方面，例如它提供的信息的包容性和公平性变得至关重要。在本工作中，我们旨在评估不同的文本到图像AI模型，并比较它们呈现的性别偏见程度。我们评估的模型包括Stable Diffusion XL (SDXL)、Stable Diffusion Cascade (SC)、DALL-E和Emu。我们假设，相对而言较老的Stable Diffusion模型会表现出明显的男性偏向，而Meta AI最近发布的Emu将有更平衡的结果。正如我们所假设的那样，我们发现Stable Diffusion模型确实表现出明显的性别偏见，而Emu则表现出更平衡的结果（即较少的性别偏见）。值得注意的是，Open AI的DALL-E则表现出几乎相反的结果，即在大多数测试案例中，女性与男性之比显著更高。尽管我们仍然观察到一定程度的偏见，但这偏向于女性而非男性。这种偏见可能解释为OpenAI在其后端更改了提示，就像我们在实验中观察到的那样。我们还发现，Meta AI的Emu在生成图像时利用了用户的WhatsApp信息。我们还提出了一些潜在的解决方案，以避免此类偏见，包括确保AI研究团队的多样性以及使用多样化的数据集。 

---
# The Computational Foundations of Collective Intelligence 

**Title (ZH)**: 集体智能的计算基础 

**Authors**: Charlie Pilgrim, Joe Morford, Elizabeth Warren, Mélisande Aellen, Christopher Krupenye, Richard P Mann, Dora Biro  

**Link**: [PDF](https://arxiv.org/pdf/2509.07999)  

**Abstract**: Why do collectives outperform individuals when solving some problems? Fundamentally, collectives have greater computational resources with more sensory information, more memory, more processing capacity, and more ways to act. While greater resources present opportunities, there are also challenges in coordination and cooperation inherent in collectives with distributed, modular structures. Despite these challenges, we show how collective resource advantages lead directly to well-known forms of collective intelligence including the wisdom of the crowd, collective sensing, division of labour, and cultural learning. Our framework also generates testable predictions about collective capabilities in distributed reasoning and context-dependent behavioural switching. Through case studies of animal navigation and decision-making, we demonstrate how collectives leverage their computational resources to solve problems not only more effectively than individuals, but by using qualitatively different problem-solving strategies. 

**Abstract (ZH)**: 群体在解决某些问题时为何能优于个体？从根本上说，群体拥有更多的计算资源，包括更多的感官信息、更多的记忆、更多的处理能力和更多的行为方式。尽管更多的资源带来了机会，但分布式、模块化结构的群体在协调与合作方面也面临着固有的挑战。尽管如此，我们展示了群体资源优势如何直接导致了集体智慧、集体感知、分工以及文化学习等已知形式的集体智能。该框架还生成了关于分布式推理和上下文依赖行为切换中群体能力的可测试预测。通过动物导航和决策的研究案例，我们证明了群体如何利用其计算资源不仅比个体更有效地解决问题，而且还使用了质不同的解决问题策略。 

---
# Bilingual Word Level Language Identification for Omotic Languages 

**Title (ZH)**: 双语词级语言识别在奥莫提语族中的应用 

**Authors**: Mesay Gemeda Yigezu, Girma Yohannis Bade, Atnafu Lambebo Tonja, Olga Kolesnikova, Grigori Sidorov, Alexander Gelbukh  

**Link**: [PDF](https://arxiv.org/pdf/2509.07998)  

**Abstract**: Language identification is the task of determining the languages for a given text. In many real world scenarios, text may contain more than one language, particularly in multilingual communities. Bilingual Language Identification (BLID) is the task of identifying and distinguishing between two languages in a given text. This paper presents BLID for languages spoken in the southern part of Ethiopia, namely Wolaita and Gofa. The presence of words similarities and differences between the two languages makes the language identification task challenging. To overcome this challenge, we employed various experiments on various approaches. Then, the combination of the BERT based pretrained language model and LSTM approach performed better, with an F1 score of 0.72 on the test set. As a result, the work will be effective in tackling unwanted social media issues and providing a foundation for further research in this area. 

**Abstract (ZH)**: 语言识别是确定给定文本语言的任务。在许多实际场景中，文本可能包含多种语言，尤其是在多语言社区中。双语语言识别（BLID）是识别和区分给定文本中两种语言的任务。本文提出了一种针对埃塞俄比亚南部地区使用的一种双语语言（沃拉伊特语和古费阿语）的双语语言识别方法。由于两种语言之间词汇的相似性和差异性，使得语言识别任务具有挑战性。为克服这一挑战，我们采用了多种方法进行实验，结果显示基于BERT的预训练语言模型与LSTM方法的结合效果最佳，在测试集上的F1分数为0.72。因此，该工作将有助于解决社交媒体中的潜在问题，并为进一步研究奠定基础。 

---
# Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization 

**Title (ZH)**: 重新审视深度假信息检测：时间序列连续学习与泛化能力的局限性 

**Authors**: Federico Fontana, Anxhelo Diko, Romeo Lanzino, Marco Raoul Marini, Bachir Kaddar, Gian Luca Foresti, Luigi Cinque  

**Link**: [PDF](https://arxiv.org/pdf/2509.07993)  

**Abstract**: The rapid evolution of deepfake generation technologies poses critical challenges for detection systems, as non-continual learning methods demand frequent and expensive retraining. We reframe deepfake detection (DFD) as a Continual Learning (CL) problem, proposing an efficient framework that incrementally adapts to emerging visual manipulation techniques while retaining knowledge of past generators. Our framework, unlike prior approaches that rely on unreal simulation sequences, simulates the real-world chronological evolution of deepfake technologies in extended periods across 7 years. Simultaneously, our framework builds upon lightweight visual backbones to allow for the real-time performance of DFD systems. Additionally, we contribute two novel metrics: Continual AUC (C-AUC) for historical performance and Forward Transfer AUC (FWT-AUC) for future generalization. Through extensive experimentation (over 600 simulations), we empirically demonstrate that while efficient adaptation (+155 times faster than full retraining) and robust retention of historical knowledge is possible, the generalization of current approaches to future generators without additional training remains near-random (FWT-AUC $\approx$ 0.5) due to the unique imprint characterizing each existing generator. Such observations are the foundation of our newly proposed Non-Universal Deepfake Distribution Hypothesis.
\textbf{Code will be released upon acceptance.} 

**Abstract (ZH)**: 快速发展的深度伪造生成技术对检测系统提出了关键挑战，非连续学习方法需要频繁且昂贵的重新训练。我们将深度伪造检测（DFD）重新框架为连续学习（CL）问题，提出了一种高效的框架，该框架能够逐步适应新兴的视觉篡改技术，同时保留以往生成器的知识。与依赖于 unreal 仿真序列的方法不同，我们的框架模拟了跨7年的长时间内深度伪造技术在现实世界中的演变过程。同时，我们的框架基于轻量级视觉骨干网络，使得深度伪造检测系统能够实时运行。此外，我们还贡献了两个新的度量标准：历史性能的 Continual AUC（C-AUC）和未来泛化的 Forward Transfer AUC（FWT-AUC）。通过广泛的实验（超过600次模拟），我们实证展示了高效的适应（比完全重新训练快近155倍）和历史知识的稳健保留是可能的，但当前方法在没有额外训练的情况下对未来的生成器进行泛化的性能仍然接近随机（FWT-AUC ≈ 0.5），这归因于每个现有生成器的独特特征。这些观察构成了我们新提出的非通用深度伪造分布假设的基础。

Code will be released upon acceptance。 

---
# DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm 

**Title (ZH)**: DLGE: 双重局部-全局编码以实现跨BCI范式的泛化能力 

**Authors**: Jingyuan Wang, Junhua Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.07991)  

**Abstract**: Deep learning models have been frequently used to decode a single brain-computer interface (BCI) paradigm based on electroencephalography (EEG). It is challenging to decode multiple BCI paradigms using one model due to diverse barriers, such as different channel configurations and disparate task-related representations. In this study, we propose Dual Local-Global Encoder (DLGE), enabling the classification across different BCI paradigms. To address the heterogeneity in EEG channel configurations across paradigms, we employ an anatomically inspired brain-region partitioning and padding strategy to standardize EEG channel configuration. In the proposed model, the local encoder is designed to learn shared features across BCI paradigms within each brain region based on time-frequency information, which integrates temporal attention on individual channels with spatial attention among channels for each brain region. These shared features are subsequently aggregated in the global encoder to form respective paradigm-specific feature representations. Three BCI paradigms (motor imagery, resting state, and driving fatigue) were used to evaluate the proposed model. The results demonstrate that our model is capable of processing diverse BCI paradigms without retraining and retuning, achieving average macro precision, recall, and F1-score of 60.16\%, 59.88\%, and 59.56\%, respectively. We made an initial attempt to develop a general model for cross-BCI-paradigm classification, avoiding retraining or redevelopment for each paradigm. This study paves the way for the development of an effective but simple model for cross-BCI-paradigm decoding, which might benefit the design of portable devices for universal BCI decoding. 

**Abstract (ZH)**: 深度学习模型常被用于基于脑电图(EEG)的单个脑机接口(BCI)范式的解码。由于存在多种障碍，如不同的通道配置和不同的任务相关表示，使用一个模型来解码多个BCI范式极具挑战性。在本研究中，我们提出了一种双局部-全局编码器(DLGE)，使其能够跨多个BCI范式进行分类。为解决不同BCI范式间的EEG通道配置异质性，我们采用了解剖学启发的脑区分区和填充策略来标准化EEG通道配置。在所提出模型中，局部编码器设计用于基于时频信息在每个脑区内部的BCI范式中学习共享特征，并结合单个通道的时间注意力和脑区内通道之间的空间注意力。这些共享特征随后在全局编码器中汇总，形成特定范式的特征表示。我们使用三种BCI范式（运动想象、静息态和驾驶疲劳）对所提出模型进行了评估。结果表明，我们的模型能够在无需重新训练或调优的情况下处理多样化的BCI范式，平均宏精度、召回率和F1分数分别为60.16%，59.88%和59.56%。我们初步尝试开发一种适用于跨BCI范式分类的一般模型，避免每个范式重新训练或重新开发，并为跨BCI范式解码的有效但简单的模型的发展铺平了道路，可能有利于通用BCI解码的便携设备的设计。 

---
# Signals vs. Videos: Advancing Motion Intention Recognition for Human-Robot Collaboration in Construction 

**Title (ZH)**: 信号 vs. 视频：提高建筑领域人机合作中运动意图识别水平 

**Authors**: Charan Gajjala Chenchu, Kinam Kim, Gao Lu, Zia Ud Din  

**Link**: [PDF](https://arxiv.org/pdf/2509.07990)  

**Abstract**: Human-robot collaboration (HRC) in the construction industry depends on precise and prompt recognition of human motion intentions and actions by robots to maximize safety and workflow efficiency. There is a research gap in comparing data modalities, specifically signals and videos, for motion intention recognition. To address this, the study leverages deep learning to assess two different modalities in recognizing workers' motion intention at the early stage of movement in drywall installation tasks. The Convolutional Neural Network - Long Short-Term Memory (CNN-LSTM) model utilizing surface electromyography (sEMG) data achieved an accuracy of around 87% with an average time of 0.04 seconds to perform prediction on a sample input. Meanwhile, the pre-trained Video Swin Transformer combined with transfer learning harnessed video sequences as input to recognize motion intention and attained an accuracy of 94% but with a longer average time of 0.15 seconds for a similar prediction. This study emphasizes the unique strengths and trade-offs of both data formats, directing their systematic deployments to enhance HRC in real-world construction projects. 

**Abstract (ZH)**: 建筑行业的人机协作（HRC）依赖于机器人对人类运动意图和行为的精确和及时识别，以最大化安全性和工作流程效率。关于运动意图识别的数据模态（特别是信号和视频）比较研究存在研究空白。为解决这一问题，本研究采用深度学习方法评估了在干墙安装任务早期运动阶段识别工人运动意图的两种不同模态。利用表面肌电图（sEMG）数据的卷积神经网络-长短期记忆（CNN-LSTM）模型在样本输入上实现了约87%的准确率，并且平均预测时间为0.04秒。预训练的Video Swin Transformer结合迁移学习利用视频序列作为输入识别运动意图，并获得了约94%的准确率，但平均预测时间为0.15秒。本研究强调了两种数据格式的独特优势和权衡，并指导其系统部署以提升实际建筑项目中的人机协作。 

---
# ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications 

**Title (ZH)**: ToDMA: 大规模模型驱动的 token 域多访问Semantic Communications 

**Authors**: Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Robert Schober, Deniz Gündüz  

**Link**: [PDF](https://arxiv.org/pdf/2505.10946)  

**Abstract**: Token communications (TokCom) is an emerging generative semantic communication concept that reduces transmission rates by using context and multimodal large language model (MLLM)-based token processing, with tokens serving as universal semantic units across modalities. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as token domain multiple access (ToDMA), where a large number of devices share a token codebook and a modulation codebook for source and channel coding, respectively. Specifically, each transmitter first tokenizes its source signal and modulate each token to a codeword. At the receiver, compressed sensing is employed first to detect active tokens and the corresponding channel state information (CSI) from the superposed signals. Then, the source token sequences are reconstructed by clustering the token-associated CSI across multiple time slots. In case of token collisions, some active tokens cannot be assigned and some positions in the reconstructed token sequences are empty. We propose to use pre-trained MLLMs to leverage the context, predict masked tokens, and thus mitigate token collisions. Simulation results demonstrate the effectiveness of the proposed ToDMA framework for both text and image transmission tasks, achieving significantly lower latency compared to context-unaware orthogonal communication schemes, while also delivering superior distortion and perceptual quality compared to state-of-the-art context-unaware non-orthogonal communication methods. 

**Abstract (ZH)**: 基于token域的多接入方案（ToDMA）：一种利用上下文的生成语义通信概念 

---
