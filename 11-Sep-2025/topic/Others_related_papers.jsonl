{'arxiv_id': 'arXiv:2509.08743', 'title': 'Parallel, Asymptotically Optimal Algorithms for Moving Target Traveling Salesman Problems', 'authors': 'Anoop Bhat, Geordan Gutow, Bhaskar Vundurthy, Zhongqiang Ren, Sivakumar Rathinam, Howie Choset', 'link': 'https://arxiv.org/abs/2509.08743', 'abstract': 'The Moving Target Traveling Salesman Problem (MT-TSP) seeks an agent trajectory that intercepts several moving targets, within a particular time window for each target. In the presence of generic nonlinear target trajectories or kinematic constraints on the agent, no prior algorithm guarantees convergence to an optimal MT-TSP solution. Therefore, we introduce the Iterated Random Generalized (IRG) TSP framework. The key idea behind IRG is to alternate between randomly sampling a set of agent configuration-time points, corresponding to interceptions of targets, and finding a sequence of interception points by solving a generalized TSP (GTSP). This alternation enables asymptotic convergence to the optimum. We introduce two parallel algorithms within the IRG framework. The first algorithm, IRG-PGLNS, solves GTSPs using PGLNS, our parallelized extension of the state-of-the-art solver GLNS. The second algorithm, Parallel Communicating GTSPs (PCG), solves GTSPs corresponding to several sets of points simultaneously. We present numerical results for three variants of the MT-TSP: one where intercepting a target only requires coming within a particular distance, another where the agent is a variable-speed Dubins car, and a third where the agent is a redundant robot arm. We show that IRG-PGLNS and PCG both converge faster than a baseline based on prior work.', 'abstract_zh': '基于移动目标的旅行商问题（MT-TSP）寻求在一个特定的时间窗口内拦截多个移动目标的代理轨迹。在存在通用非线性目标轨迹或代理的动力学约束时，没有任何先有算法可以保证收敛到最优的MT-TSP解。因此，我们引入了迭代随机广义（IRG）旅行商问题框架。IRG的核心思想是交替进行随机采样一组代理配置-时间点（对应于拦截目标的点）和通过求解广义旅行商问题（GTSP）来找到拦截点序列。这种交替能使算法渐近收敛到最优解。我们在此框架内引入了两个并行算法。第一个算法IRG-PGLNS使用我们的并行扩展GLNS（PGLNS）来求解GTSP。第二个算法并行通信广义旅行商问题（PCG）同时求解多个点集对应的GTSP。我们提供了三种不同版本的MT-TSP的数值结果：一个只需要接近特定距离即可拦截目标的情况，另一个代理是一个可变速度的杜宾车（Dubins车），第三个代理是一个冗余的机器人手臂。我们展示了IRG-PGLNS和PCG都比基于先前工作的基线算法收敛速度更快。', 'title_zh': '并行、渐近最优算法在移动目标旅行商问题中'}
{'arxiv_id': 'arXiv:2509.08460', 'title': 'Dual-Stage Safe Herding Framework for Adversarial Attacker in Dynamic Environment', 'authors': 'Wenqing Wang, Ye Zhang, Haoyu Li, Jingyu Wang', 'link': 'https://arxiv.org/abs/2509.08460', 'abstract': 'Recent advances in robotics have enabled the widespread deployment of autonomous robotic systems in complex operational environments, presenting both unprecedented opportunities and significant security problems. Traditional shepherding approaches based on fixed formations are often ineffective or risky in urban and obstacle-rich scenarios, especially when facing adversarial agents with unknown and adaptive behaviors. This paper addresses this challenge as an extended herding problem, where defensive robotic systems must safely guide adversarial agents with unknown strategies away from protected areas and into predetermined safe regions, while maintaining collision-free navigation in dynamic environments. We propose a hierarchical hybrid framework based on reach-avoid game theory and local motion planning, incorporating a virtual containment boundary and event-triggered pursuit mechanisms to enable scalable and robust multi-agent coordination. Simulation results demonstrate that the proposed approach achieves safe and efficient guidance of adversarial agents to designated regions.', 'abstract_zh': '近期机器人领域的进展使得自主机器人系统能够在复杂操作环境中得到广泛应用，既带来了前所未有的机遇，也引出了重大的安全问题。基于固定编队的传统放牧方法在城市和障碍物丰富的场景中往往无效或存在风险，尤其是在面对具有未知和适应性行为的敌对代理时。本文将这一挑战作为一种扩展的放牧问题进行研究，其中防御性机器人系统必须安全地引导具有未知策略的敌对代理远离受保护区域，并将其引导至预定的 safe 区域，同时在动态环境下保持无碰撞导航。我们提出了一种基于到达避免博弈理论和局部运动规划的分层混合框架，结合虚拟包容边界和事件触发捕获机制，以实现可扩展和 robust 的多代理协调。仿真实验结果表明，所提出的方法能够在指定区域安全有效地引导敌对代理。', 'title_zh': '动态环境中的对抗攻击者双重阶段安全牧羊框架'}
{'arxiv_id': 'arXiv:2509.08257', 'title': 'Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin', 'authors': 'Yongkai Tian, Yirong Qi, Xin Yu, Wenjun Wu, Jie Luo', 'link': 'https://arxiv.org/abs/2509.08257', 'abstract': 'In robotic systems, the performance of reinforcement learning depends on the rationality of predefined reward functions. However, manually designed reward functions often lead to policy failures due to inaccuracies. Inverse Reinforcement Learning (IRL) addresses this problem by inferring implicit reward functions from expert demonstrations. Nevertheless, existing methods rely heavily on large amounts of expert demonstrations to accurately recover the reward function. The high cost of collecting expert demonstrations in robotic applications, particularly in multi-robot systems, severely hinders the practical deployment of IRL. Consequently, improving sample efficiency has emerged as a critical challenge in multi-agent inverse reinforcement learning (MIRL). Inspired by the symmetry inherent in multi-agent systems, this work theoretically demonstrates that leveraging symmetry enables the recovery of more accurate reward functions. Building upon this insight, we propose a universal framework that integrates symmetry into existing multi-agent adversarial IRL algorithms, thereby significantly enhancing sample efficiency. Experimental results from multiple challenging tasks have demonstrated the effectiveness of this framework. Further validation in physical multi-robot systems has shown the practicality of our method.', 'abstract_zh': '多智能体逆强化学习中基于对称性的样本效率提升方法', 'title_zh': '对称性引导的多智能体逆强化学习'}
{'arxiv_id': 'arXiv:2509.08242', 'title': 'Behaviorally Heterogeneous Multi-Agent Exploration Using Distributed Task Allocation', 'authors': 'Nirabhra Mandal, Aamodh Suresh, Carlos Nieto-Granda, Sonia Martínez', 'link': 'https://arxiv.org/abs/2509.08242', 'abstract': 'We study a problem of multi-agent exploration with behaviorally heterogeneous robots. Each robot maps its surroundings using SLAM and identifies a set of areas of interest (AoIs) or frontiers that are the most informative to explore next. The robots assess the utility of going to a frontier using Behavioral Entropy (BE) and then determine which frontier to go to via a distributed task assignment scheme. We convert the task assignment problem into a non-cooperative game and use a distributed algorithm (d-PBRAG) to converge to the Nash equilibrium (which we show is the optimal task allocation solution). For unknown utility cases, we provide robust bounds using approximate rewards. We test our algorithm (which has less communication cost and fast convergence) in simulation, where we explore the effect of sensing radii, sensing accuracy, and heterogeneity among robotic teams with respect to the time taken to complete exploration and path traveled. We observe that having a team of agents with heterogeneous behaviors is beneficial.', 'abstract_zh': '多机器人行为异质性探索问题研究', 'title_zh': '基于分布式任务分配的行为异质多智能体探索'}
{'arxiv_id': 'arXiv:2509.08197', 'title': 'Online Dynamic SLAM with Incremental Smoothing and Mapping', 'authors': 'Jesse Morris, Yiduo Wang, Viorela Ila', 'link': 'https://arxiv.org/abs/2509.08197', 'abstract': 'Dynamic SLAM methods jointly estimate for the static and dynamic scene components, however existing approaches, while accurate, are computationally expensive and unsuitable for online applications. In this work, we present the first application of incremental optimisation techniques to Dynamic SLAM. We introduce a novel factor-graph formulation and system architecture designed to take advantage of existing incremental optimisation methods and support online estimation. On multiple datasets, we demonstrate that our method achieves equal to or better than state-of-the-art in camera pose and object motion accuracy. We further analyse the structural properties of our approach to demonstrate its scalability and provide insight regarding the challenges of solving Dynamic SLAM incrementally. Finally, we show that our formulation results in problem structure well-suited to incremental solvers, while our system architecture further enhances performance, achieving a 5x speed-up over existing methods.', 'abstract_zh': '动态SLAM方法联合估计静态和动态场景成分，但现有方法尽管准确，计算成本高且不适用于在线应用。在此工作中，我们首次将增量优化技术应用于动态SLAM。我们引入了一种新型因子图表示和系统架构，旨在利用现有的增量优化方法并支持在线估计。在多个数据集中，我们证明我们的方法在相机位姿和物体运动准确性方面达到或优于现有最佳方法。我们进一步分析了我们方法的结构特性，以证明其可扩展性，并提供关于增量求解动态SLAM的挑战见解。最后，我们展示了我们的表示方法生成的问题结构非常适合增量求解器，而我们的系统架构进一步提高了性能，实现了比现有方法快5倍的效果。', 'title_zh': '在线动态SLAM增量平滑与建图'}
{'arxiv_id': 'arXiv:2509.08160', 'title': 'Diffusion-Guided Multi-Arm Motion Planning', 'authors': 'Viraj Parimi, Brian C. Williams', 'link': 'https://arxiv.org/abs/2509.08160', 'abstract': "Multi-arm motion planning is fundamental for enabling arms to complete complex long-horizon tasks in shared spaces efficiently but current methods struggle with scalability due to exponential state-space growth and reliance on large training datasets for learned models. Inspired by Multi-Agent Path Finding (MAPF), which decomposes planning into single-agent problems coupled with collision resolution, we propose a novel diffusion-guided multi-arm planner (DG-MAP) that enhances scalability of learning-based models while reducing their reliance on massive multi-arm datasets. Recognizing that collisions are primarily pairwise, we train two conditional diffusion models, one to generate feasible single-arm trajectories, and a second, to model the dual-arm dynamics required for effective pairwise collision resolution. By integrating these specialized generative models within a MAPF-inspired structured decomposition, our planner efficiently scales to larger number of arms. Evaluations against alternative learning-based methods across various team sizes demonstrate our method's effectiveness and practical applicability. Project website can be found at this https URL", 'abstract_zh': '基于多臂运动规划的新型扩散引导多臂规划器：增强学习模型的可伸缩性并减少对大规模多臂数据集的依赖', 'title_zh': '基于扩散引导的多臂运动规划'}
{'arxiv_id': 'arXiv:2509.08117', 'title': 'Online Learning and Coverage of Unknown Fields Using Random-Feature Gaussian Processes', 'authors': 'Ruijie Du, Ruoyu Lin, Yanning Shen, Magnus Egerstedt', 'link': 'https://arxiv.org/abs/2509.08117', 'abstract': 'This paper proposes a framework for multi-robot systems to perform simultaneous learning and coverage of the domain of interest characterized by an unknown and potentially time-varying density function. To overcome the limitations of Gaussian Process (GP) regression, we employ Random Feature GP (RFGP) and its online variant (O-RFGP) that enables online and incremental inference. By integrating these with Voronoi-based coverage control and Upper Confidence Bound (UCB) sampling strategy, a team of robots can adaptively focus on important regions while refining the learned spatial field for efficient coverage. Under mild assumptions, we provide theoretical guarantees and evaluate the framework through simulations in time-invariant scenarios. Furthermore, its effectiveness in time-varying settings is demonstrated through additional simulations and a physical experiment.', 'abstract_zh': '本文提出了一种框架，用于多机器人系统同时学习和覆盖一个由未知且可能随时间变化的密度函数描述的兴趣领域。为克服高斯过程（GP）回归的限制，我们采用了随机特征高斯过程（RFGP）及其在线变体（O-RFGP），从而实现在线和增量推理。通过将这些方法与基于Voronoi的覆盖控制和上置信边界的采样策略结合，机器人团队能够适应性地关注重要区域，同时逐步精细学习的空间场，以实现高效的覆盖。在轻微假设下，我们提供了理论保证，并通过不变时间场景的仿真评估了该框架。此外，通过额外的仿真和物理实验展示了该框架在随时间变化场景中的有效性。', 'title_zh': '使用随机特征高斯过程进行未知领域在线学习与覆盖'}
{'arxiv_id': 'arXiv:2509.08017', 'title': 'PySensors 2.0: A Python Package for Sparse Sensor Placement', 'authors': 'Niharika Karnik, Yash Bhangale, Mohammad G. Abdo, Andrei A. Klishin, Joshua J. Cogliati, Bingni W. Brunton, J. Nathan Kutz, Steven L. Brunton, Krithika Manohar', 'link': 'https://arxiv.org/abs/2509.08017', 'abstract': "PySensors is a Python package for selecting and placing a sparse set of sensors for reconstruction and classification tasks. In this major update to \\texttt{PySensors}, we introduce spatially constrained sensor placement capabilities, allowing users to enforce constraints such as maximum or exact sensor counts in specific regions, incorporate predetermined sensor locations, and maintain minimum distances between sensors. We extend functionality to support custom basis inputs, enabling integration of any data-driven or spectral basis. We also propose a thermodynamic approach that goes beyond a single ``optimal'' sensor configuration and maps the complete landscape of sensor interactions induced by the training data. This comprehensive view facilitates integration with external selection criteria and enables assessment of sensor replacement impacts. The new optimization technique also accounts for over- and under-sampling of sensors, utilizing a regularized least squares approach for robust reconstruction. Additionally, we incorporate noise-induced uncertainty quantification of the estimation error and provide visual uncertainty heat maps to guide deployment decisions. To highlight these additions, we provide a brief description of the mathematical algorithms and theory underlying these new capabilities. We demonstrate the usage of new features with illustrative code examples and include practical advice for implementation across various application domains. Finally, we outline a roadmap of potential extensions to further enhance the package's functionality and applicability to emerging sensing challenges.", 'abstract_zh': 'PySensors是用于选择和放置稀疏传感器集的Python包，适用于重建和分类任务。在PySensors的重大更新中，我们引入了空间约束传感器放置能力，允许用户施加诸如特定区域内的最大或精确传感器数量等约束，整合预定的传感器位置，并保持传感器之间的最小距离。我们扩展了功能以支持自定义基输入，使任何数据驱动或光谱基的集成成为可能。我们还提出了一种热力学方法，该方法超越了单一“最优”传感器配置，并映射了由训练数据引起的传感器交互的完整景观。这一全面视角有助于与外部选择标准的集成，并能够评估传感器替换的影响。新优化技术还考虑了传感器的过采样和欠采样问题，采用正则化最小二乘法以实现稳健的重建。此外，我们还纳入了由噪声引起的估计误差的不确定性量化，并提供了可视化不确定性热图以指导部署决策。为了突显这些新增功能，我们简要描述了支撑这些新功能的数学算法和理论。我们通过示例代码展示了新功能的使用方法，并提供了针对各种应用领域实施的实用建议。最后，我们概述了潜在扩展的路线图，以进一步增强包的功能，并使其适应新兴的传感挑战。', 'title_zh': 'PySensors 2.0: 一个用于稀疏传感器布放的Python软件包'}
{'arxiv_id': 'arXiv:2509.07997', 'title': 'Learning-Based Planning for Improving Science Return of Earth Observation Satellites', 'authors': 'Abigail Breitfeld, Alberto Candela, Juan Delfa, Akseli Kangaslahti, Itai Zilberstein, Steve Chien, David Wettergreen', 'link': 'https://arxiv.org/abs/2509.07997', 'abstract': "Earth observing satellites are powerful tools for collecting scientific information about our planet, however they have limitations: they cannot easily deviate from their orbital trajectories, their sensors have a limited field of view, and pointing and operating these sensors can take a large amount of the spacecraft's resources. It is important for these satellites to optimize the data they collect and include only the most important or informative measurements. Dynamic targeting is an emerging concept in which satellite resources and data from a lookahead instrument are used to intelligently reconfigure and point a primary instrument. Simulation studies have shown that dynamic targeting increases the amount of scientific information gathered versus conventional sampling strategies. In this work, we present two different learning-based approaches to dynamic targeting, using reinforcement and imitation learning, respectively. These learning methods build on a dynamic programming solution to plan a sequence of sampling locations. We evaluate our approaches against existing heuristic methods for dynamic targeting, showing the benefits of using learning for this application. Imitation learning performs on average 10.0\\% better than the best heuristic method, while reinforcement learning performs on average 13.7\\% better. We also show that both learning methods can be trained effectively with relatively small amounts of data.", 'abstract_zh': '地球观测卫星是收集关于我们星球科学信息的强大工具，然而它们存在局限性：难以偏离轨道轨迹，传感器的视野有限，对这些传感器的操控和操作需要大量航天器资源。这些卫星需要优化它们收集的数据，仅包含最重要或最有信息量的测量。动态目标是指利用卫星资源和前瞻仪器的数据智能重新配置和瞄准主要仪器的一种新兴概念。模拟研究表明，动态目标采集的科学信息量大于传统的采样策略。在本工作中，我们分别使用强化学习和模仿学习提出了两种不同的动态目标方法。这些学习方法基于动态规划解决方案来规划一系列采样位置。我们将这些方法与现有动态目标方法进行了比较，展示了使用学习方法的益处。模仿学习平均比最佳启发式方法表现好10.0%，而强化学习平均好13.7%。我们还展示了这两种学习方法可以通过相对较小的数据量进行有效训练。', 'title_zh': '基于学习的规划方法以提高地球观测卫星的科学回报'}
{'arxiv_id': 'arXiv:2509.08713', 'title': 'The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems', 'authors': 'Ziming Luo, Atoosa Kasirzadeh, Nihar B. Shah', 'link': 'https://arxiv.org/abs/2509.08713', 'abstract': 'AI scientist systems, capable of autonomously executing the full research workflow from hypothesis generation and experimentation to paper writing, hold significant potential for accelerating scientific discovery. However, the internal workflow of these systems have not been closely examined. This lack of scrutiny poses a risk of introducing flaws that could undermine the integrity, reliability, and trustworthiness of their research outputs. In this paper, we identify four potential failure modes in contemporary AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and post-hoc selection bias. To examine these risks, we design controlled experiments that isolate each failure mode while addressing challenges unique to evaluating AI scientist systems. Our assessment of two prominent open-source AI scientist systems reveals the presence of several failures, across a spectrum of severity, which can be easily overlooked in practice. Finally, we demonstrate that access to trace logs and code from the full automated workflow enables far more effective detection of such failures than examining the final paper alone. We thus recommend journals and conferences evaluating AI-generated research to mandate submission of these artifacts alongside the paper to ensure transparency, accountability, and reproducibility.', 'abstract_zh': '当前AI科学家系统中存在的四种潜在失败模式及其评估：从基准选择不当到事后选择偏差，需要透明、问责和可再现性。', 'title_zh': '你 automation 越多，你看到的越少：AI 科学家系统的隐含陷阱'}
{'arxiv_id': 'arXiv:2509.08705', 'title': 'One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases', 'authors': 'Shalima Binta Manir, Tim Oates', 'link': 'https://arxiv.org/abs/2509.08705', 'abstract': 'We introduce a novel Theory of Mind (ToM) framework inspired by dual-process theories from cognitive science, integrating a fast, habitual graph-based reasoning system (System 1), implemented via graph convolutional networks (GCNs), and a slower, context-sensitive meta-adaptive learning system (System 2), driven by meta-learning techniques. Our model dynamically balances intuitive and deliberative reasoning through a learned context gate mechanism. We validate our architecture on canonical false-belief tasks and systematically explore its capacity to replicate hallmark cognitive biases associated with dual-process theory, including anchoring, cognitive-load fatigue, framing effects, and priming effects. Experimental results demonstrate that our dual-process approach closely mirrors human adaptive behavior, achieves robust generalization to unseen contexts, and elucidates cognitive mechanisms underlying reasoning biases. This work bridges artificial intelligence and cognitive theory, paving the way for AI systems exhibiting nuanced, human-like social cognition and adaptive decision-making capabilities.', 'abstract_zh': '我们提出了一种受认知科学双重过程理论启发的新型理论领悟（Theory of Mind，ToM）框架，将快速的习惯性图基推理系统（System 1）通过图卷积网络（GCNs）实现，并将慢速的上下文敏感元自适应学习系统（System 2）通过元学习技术驱动。模型通过一个学习到的上下文门机制动态平衡直觉推理和审慎推理。我们在经典的错误信念任务上验证了我们的架构，并系统地探索了其复制双重过程理论相关认知偏差的能力，包括锚定效应、认知负荷疲劳、框架效应和唤醒效应。实验结果表明，我们的双重过程方法 closely mirrors 人类适应行为，实现了对未见过的上下文的稳健泛化，并阐明了推理偏差背后的认知机制。本工作将人工智能与认知理论相结合，为具备细腻、类人社会认知和适应性决策能力的AI系统的发展铺平了道路。', 'title_zh': '一个模型，两种思维：一种基于语境的图学习器，再现人类偏差'}
{'arxiv_id': 'arXiv:2509.08682', 'title': 'Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference', 'authors': 'Guoqing Ma, Jia Zhu, Hanghui Guo, Weijie Shi, Jiawei Shen, Jingjiang Liu, Yidan Liang', 'link': 'https://arxiv.org/abs/2509.08682', 'abstract': "Multi-agent systems (MAS) are critical for automating complex tasks, yet their practical deployment is severely hampered by the challenge of failure attribution. Current diagnostic tools, which rely on statistical correlations, are fundamentally inadequate; on challenging benchmarks like Who\\&When, state-of-the-art methods achieve less than 15\\% accuracy in locating the root-cause step of a failure. To address this critical gap, we introduce the first failure attribution framework for MAS grounded in multi-granularity causal inference. Our approach makes two key technical contributions: (1) a performance causal inversion principle, which correctly models performance dependencies by reversing the data flow in execution logs, combined with Shapley values to accurately assign agent-level blame; (2) a novel causal discovery algorithm, CDC-MAS, that robustly identifies critical failure steps by tackling the non-stationary nature of MAS interaction data. The framework's attribution results directly fuel an automated optimization loop, generating targeted suggestions whose efficacy is validated via counterfactual simulations. Evaluations on the Who\\&When and TRAIL benchmarks demonstrate a significant leap in performance. Our method achieves up to 36.2\\% step-level accuracy. Crucially, the generated optimizations boost overall task success rates by an average of 22.4\\%. This work provides a principled and effective solution for debugging complex agent interactions, paving the way for more reliable and interpretable multi-agent systems.", 'abstract_zh': '多粒度因果推理导向的复杂代理系统故障归因框架', 'title_zh': '基于因果推理的多智能体系统自动故障归因与关键步骤预测方法'}
{'arxiv_id': 'arXiv:2509.08312', 'title': 'Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies', 'authors': 'Binghan Wu, Shoufeng Wang, Yunxin Liu, Ya-Qin Zhang, Joseph Sifakis, Ye Ouyang', 'link': 'https://arxiv.org/abs/2509.08312', 'abstract': "The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a strategic inflection point in telecommunications, where networks must transcend reactive automation to achieve genuine cognitive capabilities--fulfilling TM Forum's vision of self-configuring, self-healing, and self-optimizing systems that deliver zero-wait, zero-touch, and zero-fault services. This work bridges the gap between architectural theory and operational reality by implementing Joseph Sifakis's AN Agent reference architecture in a functional cognitive system, deploying coordinated proactive-reactive runtimes driven by hybrid knowledge representation. Through an empirical case study of a Radio Access Network (RAN) Link Adaptation (LA) Agent, we validate this framework's transformative potential: demonstrating sub-10 ms real-time control in 5G NR sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for ultra-reliable services through dynamic Modulation and Coding Scheme (MCS) optimization. These improvements confirm the architecture's viability in overcoming traditional autonomy barriers and advancing critical L4-enabling capabilities toward next-generation objectives.", 'abstract_zh': 'L4 自动化网络向 Level 4 (L4) 演进：从反应性自动化到真正的认知能力——以无线电接入网络链路适配代理为例验证功能认知系统的潜在变革性', 'title_zh': '利用AI代理实现自主网络：一种参考架构与实证研究'}
{'arxiv_id': 'arXiv:2509.08282', 'title': 'Real-world Music Plagiarism Detection With Music Segment Transcription System', 'authors': 'Seonghyeon Go', 'link': 'https://arxiv.org/abs/2509.08282', 'abstract': 'As a result of continuous advances in Music Information Retrieval (MIR) technology, generating and distributing music has become more diverse and accessible. In this context, interest in music intellectual property protection is increasing to safeguard individual music copyrights. In this work, we propose a system for detecting music plagiarism by combining various MIR technologies. We developed a music segment transcription system that extracts musically meaningful segments from audio recordings to detect plagiarism across different musical formats. With this system, we compute similarity scores based on multiple musical features that can be evaluated through comprehensive musical analysis. Our approach demonstrated promising results in music plagiarism detection experiments, and the proposed method can be applied to real-world music scenarios. We also collected a Similar Music Pair (SMP) dataset for musical similarity research using real-world cases. The dataset are publicly available.', 'abstract_zh': '由于音乐信息检索（MIR）技术的不断进步，音乐的生成和分发变得更加多样化和易获取。在此背景下，对音乐知识产权保护的兴趣不断增加，以保障个人音乐版权。本文提出了一种结合多种MIR技术的音乐剽窃检测系统。我们开发了一种音乐片段转录系统，可以从音频记录中提取具有音乐意义的片段，以检测不同音乐格式之间的剽窃行为。借助此系统，我们可以根据综合音乐分析评估的多个音乐特征来计算相似性评分。我们的方法在音乐剽窃检测实验中取得了令人鼓舞的结果，并且提出的方案可以应用于实际音乐场景中。此外，我们还使用真实世界案例收集了一个音乐相似性配对（SMP）数据集，该数据集已公开。', 'title_zh': '基于音乐片段转录系统的现实世界音乐抄袭检测'}
{'arxiv_id': 'arXiv:2509.08151', 'title': 'Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI', 'authors': 'Botao Zhu, Jeslyn Wang, Dusit Niyato, Xianbin Wang', 'link': 'https://arxiv.org/abs/2509.08151', 'abstract': "Accurate trustworthiness evaluation of potential collaborating devices is essential for the effective execution of complex computing tasks. This evaluation process involves collecting diverse trust-related data from potential collaborators, including historical performance and available resources, for collaborator selection. However, when each task owner independently assesses all collaborators' trustworthiness, frequent data exchange, complex reasoning, and dynamic situation changes can result in significant overhead and deteriorated trust evaluation. To overcome these challenges, we propose a task-specific trust semantics distillation (2TSD) model based on a large AI model (LAM)-driven teacher-student agent architecture. The teacher agent is deployed on a server with powerful computational capabilities and an augmented memory module dedicated to multidimensional trust-related data collection, task-specific trust semantics extraction, and task-collaborator matching analysis. Upon receiving task-specific requests from device-side student agents, the teacher agent transfers the trust semantics of potential collaborators to the student agents, enabling rapid and accurate collaborator selection. Experimental results demonstrate that the proposed 2TSD model can reduce collaborator evaluation time, decrease device resource consumption, and improve the accuracy of collaborator selection.", 'abstract_zh': '基于大型AI模型驱动的教师-学生架构的任务特定信任语义蒸馏模型对于潜在协作设备的信任worthiness评估至关重要。该评估过程涉及从潜在合作者处收集多种信任相关数据，包括历史性能和可用资源，用于合作者选择。为克服这些挑战，我们提出了一种基于大型AI模型驱动的教师-学生代理架构的任务特定信任语义蒸馏（2TSD）模型。教师代理部署在具有强大计算能力和专用多维信任相关数据收集、任务特定信任语义提取和任务-合作者匹配分析扩展现存内存模块的服务器上。当收到设备端学生代理的任务特定请求时，教师代理将潜在合作者的信任语义传递给学生代理，从而实现快速准确的合作者选择。实验结果表明，所提出的2TSD模型可以减少合作者评估时间，降低设备资源消耗，并提高合作者选择的准确性。', 'title_zh': '基于记忆增强代理AI的信任语义精炼的合作者选择'}
{'arxiv_id': 'arXiv:2509.08817', 'title': 'QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction', 'authors': 'Tobias Winker, Jinghua Groppe, Sven Groppe', 'link': 'https://arxiv.org/abs/2509.08817', 'abstract': 'Cardinality estimation is an important part of query optimization in DBMS. We develop a Quantum Cardinality Estimation (QCardEst) approach using Quantum Machine Learning with a Hybrid Quantum-Classical Network. We define a compact encoding for turning SQL queries into a quantum state, which requires only qubits equal to the number of tables in the query. This allows the processing of a complete query with a single variational quantum circuit (VQC) on current hardware. In addition, we compare multiple classical post-processing layers to turn the probability vector output of VQC into a cardinality value. We introduce Quantum Cardinality Correction QCardCorr, which improves classical cardinality estimators by multiplying the output with a factor generated by a VQC to improve the cardinality estimation. With QCardCorr, we have an improvement over the standard PostgreSQL optimizer of 6.37 times for JOB-light and 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of 3.47.', 'abstract_zh': '量子基数估计是数据库管理系统中查询优化的重要组成部分。我们提出了一种基于混合量子-经典网络的量子基数估计（QCardEst）方法。我们定义了一种紧凑的编码方式，将SQL查询转换为量子态，所需量子位数等于查询中的表数。这使得当前硬件可以通过单一变量子量子电路（VQC）处理完整查询。此外，我们比较了多种经典后处理层，将VQC输出的概率向量转换为基数值。我们引入了量子基数校正（QCardCorr），通过使用VQC生成的因子乘以输出来改进经典基数估计器，从而提高基数估计的准确性。借助QCardCorr，我们标准PostgreSQL优化器在JOB-light上的性能提升6.37倍，在STATS上的提升8.66倍。对于JOB-light，我们甚至超越了MSCN 3.47倍。', 'title_zh': 'QCardEst/QCardCorr: 量子计数估计与校正'}
{'arxiv_id': 'arXiv:2509.08812', 'title': 'MoVoC: Morphology-Aware Subword Construction for Geez Script Languages', 'authors': 'Hailay Kidu Teklehaymanot, Dren Fazlija, Wolfgang Nejdl', 'link': 'https://arxiv.org/abs/2509.08812', 'abstract': 'Subword-based tokenization methods often fail to preserve morphological boundaries, a limitation especially pronounced in low-resource, morphologically complex languages such as those written in the Geez script. To address this, we present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into the subword vocabulary. This hybrid segmentation approach combines morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological integrity while maintaining lexical meaning. To tackle resource scarcity, we curate and release manually annotated morpheme data for four Geez script languages and a morpheme-aware vocabulary for two of them. While the proposed tokenization method does not lead to significant gains in automatic translation quality, we observe consistent improvements in intrinsic metrics, MorphoScore, and Boundary Precision, highlighting the value of morphology-aware segmentation in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated datasets and tokenizer will be publicly available to support further research in low-resource, morphologically rich languages. Our code and data are available on GitHub: this https URL', 'abstract_zh': '基于子词的分词方法往往无法保留形态边界，在象形文字等低资源且形态复杂的语言中，这一局限尤为明显。为此，我们提出了一种形态意识子词词表构建方法MoVoC，并训练了MoVoC-Tok分词器，该分词器将监督形态分析集成到子词词表中。这种混合分段方法结合了形态学子词和字节对编码(BPE)子词，以保持形态完整性和保留词汇意义。为应对资源匮乏，我们收集并发布了四种象形文字语言的手工标注形态学数据，并为其中两种语言构建了形态意识词汇表。虽然所提出的分词方法在自动翻译质量上未取得显著提升，但在内在测评指标、MorphoScore和边界精确度方面观察到了一致的提升，突显了形态意识分段在提高语言忠实度和子词效率方面的价值。我们的形态学标注数据集和分词器将公开发布，以支持低资源且形态丰富的语言研究。我们的代码和数据已发布在GitHub：this https URL', 'title_zh': 'MoVoC: 元音意识子词构建方法 for Geez脚本语言'}
{'arxiv_id': 'arXiv:2509.08756', 'title': 'Using AI to Optimize Patient Transfer and Resource Utilization During Mass-Casualty Incidents: A Simulation Platform', 'authors': 'Zhaoxun "Lorenz" Liu, Wagner H. Souza, Jay Han, Amin Madani', 'link': 'https://arxiv.org/abs/2509.08756', 'abstract': 'Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid, accurate patient-hospital allocation decisions under extreme pressure. Here, we developed and validated a deep reinforcement learning-based decision-support AI agent to optimize patient transfer decisions during simulated MCIs by balancing patient acuity levels, specialized care requirements, hospital capacities, and transport logistics. To integrate this AI agent, we developed MasTER, a web-accessible command dashboard for MCI management simulations. Through a controlled user study with 30 participants (6 trauma experts and 24 non-experts), we evaluated three interaction approaches with the AI agent (human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI scenarios in the Greater Toronto Area. Results demonstrate that increasing AI involvement significantly improves decision quality and consistency. The AI agent outperforms trauma surgeons (p < 0.001) and enables non-experts to achieve expert-level performance when assisted, contrasting sharply with their significantly inferior unassisted performance (p < 0.001). These findings establish the potential for our AI-driven decision support to enhance both MCI preparedness training and real-world emergency response management.', 'abstract_zh': '大规模伤亡事件中的医疗救护系统面临 overwhelmed 的挑战，需要在极端压力下做出快速而准确的患者-医院分配决策。为此，我们开发并验证了一种基于深度强化学习的决策支持人工智能代理，以优化模拟大规模伤亡事件中的患者转运决策，平衡患者紧迫性等级、专科护理需求、医院容量和运输物流。为此，我们开发了 MasTER，一种网页可访问的命令控制仪表板，用于大规模伤亡事件管理模拟。通过一项受控用户研究，涉及 30 名参与者（6 名创伤专家和 24 名非专家），我们在多伦多大都市区 20 例和 60 例患者的大规模伤亡事件情景中评估了与人工智能代理交互的三种方法（仅人类、人类-人工智能合作以及仅人工智能）的表现。结果显示，增加人工智能的参与显著提高了决策质量和一致性。该人工智能代理在统计学上显著优于创伤外科医生（p < 0.001），并在协助下使非专家达到专家水平的表现，与他们未经协助的显著较差表现形成鲜明对比（p < 0.001）。这些发现确立了我们的人工智能驱动决策支持在增强大规模伤亡事件应急准备训练和实际应急响应管理方面潜力。', 'title_zh': '使用AI优化大规模伤亡事件中患者转移和资源利用：一个模拟平台'}
{'arxiv_id': 'arXiv:2509.08752', 'title': 'Learning Turbulent Flows with Generative Models: Super-resolution, Forecasting, and Sparse Flow Reconstruction', 'authors': 'Vivek Oommen, Siavash Khodakarami, Aniruddha Bora, Zhicheng Wang, George Em Karniadakis', 'link': 'https://arxiv.org/abs/2509.08752', 'abstract': 'Neural operators are promising surrogates for dynamical systems but when trained with standard L2 losses they tend to oversmooth fine-scale turbulent structures. Here, we show that combining operator learning with generative modeling overcomes this limitation. We consider three practical turbulent-flow challenges where conventional neural operators fail: spatio-temporal super-resolution, forecasting, and sparse flow reconstruction. For Schlieren jet super-resolution, an adversarially trained neural operator (adv-NO) reduces the energy-spectrum error by 15x while preserving sharp gradients at neural operator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO trained on only 160 timesteps from a single trajectory forecasts accurately for five eddy-turnover times and offers 114x wall-clock speed-up at inference than the baseline diffusion-based forecasters, enabling near-real-time rollouts. For reconstructing cylinder wake flows from highly sparse Particle Tracking Velocimetry-like inputs, a conditional generative model infers full 3D velocity and pressure fields with correct phase alignment and statistics. These advances enable accurate reconstruction and forecasting at low compute cost, bringing near-real-time analysis and control within reach in experimental and computational fluid mechanics. See our project page: this https URL', 'abstract_zh': '神经算子是对流系统有前景的替代方案，但当使用标准的L2损失进行训练时，它们往往会过度平滑精细的湍流结构。本文表明，将算子学习与生成建模相结合可以克服这一局限性。我们考虑了三个传统神经算子无法解决的湍流流动挑战：时空超分辨率、预报和稀疏流场重构。对于Schlieren射流超分辨率，对抗训练的神经算子（adv-NO）将能量谱误差降低了15倍，同时保留了类似神经算子的推理成本的锐利梯度。对于全方位各向同性湍流，基于单个轨迹160个时间步长对adv-NO进行训练，可在五涡旋周转时间内进行准确的预报，并提供比基线基于扩散的预报器114倍的推理时间加速，从而实现近实时的滚动预测。对于从高度稀疏的类似于粒子追踪 velocimetry 的输入重构圆柱尾流流动，条件生成模型推断出完整的3D速度和压力场，具有正确的相位对齐和统计数据。这些进步使得在低计算成本下实现准确的重构和预报成为可能，将近实时分析和控制带入实验和计算流体力学之中。请参见我们的项目页面：this https URL', 'title_zh': '使用生成模型学习湍流：超分辨率、预测和稀疏流场重建'}
{'arxiv_id': 'arXiv:2509.08717', 'title': 'Explainability of CNN Based Classification Models for Acoustic Signal', 'authors': 'Zubair Faruqui, Mackenzie S. McIntire, Rahul Dubey, Jay McEntee', 'link': 'https://arxiv.org/abs/2509.08717', 'abstract': "Explainable Artificial Intelligence (XAI) has emerged as a critical tool for interpreting the predictions of complex deep learning models. While XAI has been increasingly applied in various domains within acoustics, its use in bioacoustics, which involves analyzing audio signals from living organisms, remains relatively underexplored. In this paper, we investigate the vocalizations of a bird species with strong geographic variation throughout its range in North America. Audio recordings were converted into spectrogram images and used to train a deep Convolutional Neural Network (CNN) for classification, achieving an accuracy of 94.8\\%. To interpret the model's predictions, we applied both model-agnostic (LIME, SHAP) and model-specific (DeepLIFT, Grad-CAM) XAI techniques. These techniques produced different but complementary explanations, and when their explanations were considered together, they provided more complete and interpretable insights into the model's decision-making. This work highlights the importance of using a combination of XAI techniques to improve trust and interoperability, not only in broader acoustics signal analysis but also argues for broader applicability in different domain specific tasks.", 'abstract_zh': '可解释的人工智能（XAI）已成为解读复杂深度学习模型预测的关键工具。尽管XAI已在声学领域的多个领域中被广泛应用，但在涉及分析生物声信号的生物声学中仍相对未被充分探索。在本文中，我们研究了一种北美范围内具有强烈地理变异性的鸟类的鸣叫声。音频记录被转换成谱图图像，并用于训练用于分类的深层卷积神经网络（CNN），准确率达到94.8%。为了解释模型的预测，我们应用了:both模型无关（LIME, SHAP）和模型特定（DeepLIFT, Grad-CAM）的XAI技术。这些技术产生了不同的但互补的解释，当将它们的解释结合起来时，它们提供了模型决策更多全面和可解释的见解。本文强调了在更广泛的声音信号分析中使用XAI技术组合的重要性，并且在不同特定任务中的广泛应用。', 'title_zh': '基于CNN的声学信号分类模型的可解释性'}
{'arxiv_id': 'arXiv:2509.08698', 'title': 'A layered architecture for log analysis in complex IT systems', 'authors': 'Thorsten Wittkopp', 'link': 'https://arxiv.org/abs/2509.08698', 'abstract': 'In the evolving IT landscape, stability and reliability of systems are essential, yet their growing complexity challenges DevOps teams in implementation and maintenance. Log analysis, a core element of AIOps, provides critical insights into complex behaviors and failures. This dissertation introduces a three-layered architecture to support DevOps in failure resolution. The first layer, Log Investigation, performs autonomous log labeling and anomaly classification. We propose a method that labels log data without manual effort, enabling supervised training and precise evaluation of anomaly detection. Additionally, we define a taxonomy that groups anomalies into three categories, ensuring appropriate method selection. The second layer, Anomaly Detection, detects behaviors deviating from the norm. We propose a flexible Anomaly Detection method adaptable to unsupervised, weakly supervised, and supervised training. Evaluations on public and industry datasets show F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third layer, Root Cause Analysis, identifies minimal log sets describing failures, their origin, and event sequences. By balancing training data and identifying key services, our Root Cause Analysis method consistently detects 90-98% of root cause log lines within the top 10 candidates, providing actionable insights for mitigation. Our research addresses how log analysis methods can be designed and optimized to help DevOps resolve failures efficiently. By integrating these three layers, the architecture equips teams with robust methods to enhance IT system reliability.', 'abstract_zh': '在不断演化的IT景观中，系统稳定性和可靠性至关重要，但日益复杂性挑战着DevOps团队的实施和维护。日志分析作为AIOps的核心元素，提供了关键的见解，用于理解复杂的失败行为。本论文提出了一种三层架构以支持DevOps在故障解决中的应用。第一层，日志调查，实现了自动的日志标签化和异常分类。我们提出了一种无需人工标注的方法，使得异常检测可以进行监督训练并精确评估。此外，我们定义了分类学，将异常分为三类，确保了适当的方法选择。第二层，异常检测，检测偏离常规的行为。我们提出了一种灵活的异常检测方法，适用于无监督、弱监督和监督训练。对公开和行业数据集的评估显示F1分数在0.98到1.0之间，确保了可靠的异常检测。第三层，根本原因分析，识别描述故障、其起源和事件序列的最小日志集。通过平衡训练数据和识别关键服务，我们的根本原因分析方法在前10个候选者中一致检测到90-98%的根本原因日志行，提供了可操作的见解用于预防。我们的研究旨在探讨如何设计和优化日志分析方法，以帮助DevOps团队高效地解决故障。通过整合这三层，该架构为团队提供了增强IT系统可靠性的 robust 方法。', 'title_zh': '复杂IT系统中日志分析的分层架构'}
{'arxiv_id': 'arXiv:2509.08697', 'title': 'Reshaping the Forward-Forward Algorithm with a Similarity-Based Objective', 'authors': 'James Gong, Raymond Luo, Emma Wang, Leon Ge, Bruce Li, Felix Marattukalam, Waleed Abdulla', 'link': 'https://arxiv.org/abs/2509.08697', 'abstract': 'Backpropagation is the pivotal algorithm underpinning the success of artificial neural networks, yet it has critical limitations such as biologically implausible backward locking and global error propagation. To circumvent these constraints, the Forward-Forward algorithm was proposed as a more biologically plausible method that replaces the backward pass with an additional forward pass. Despite this advantage, the Forward-Forward algorithm significantly trails backpropagation in accuracy, and its optimal form exhibits low inference efficiency due to multiple forward passes required. In this work, the Forward-Forward algorithm is reshaped through its integration with similarity learning frameworks, eliminating the need for multiple forward passes during inference. This proposed algorithm is named Forward-Forward Algorithm Unified with Similarity-based Tuplet loss (FAUST). Empirical evaluations on MNIST, Fashion-MNIST, and CIFAR-10 datasets indicate that FAUST substantially improves accuracy, narrowing the gap with backpropagation. On CIFAR-10, FAUST achieves 56.22\\% accuracy with a simple multi-layer perceptron architecture, approaching the backpropagation benchmark of 57.63\\% accuracy.', 'abstract_zh': '前向前算法结合基于相似性三元组损失的统一前向方法（FAUST）', 'title_zh': '基于相似性目标重塑前向-前向算法'}
{'arxiv_id': 'arXiv:2509.08654', 'title': 'Robust Belief-State Policy Learning for Quantum Network Routing Under Decoherence and Time-Varying Conditions', 'authors': 'Amirhossein Taherpour, Abbas Taherpour, Tamer Khattab', 'link': 'https://arxiv.org/abs/2509.08654', 'abstract': 'This paper presents a feature-based Partially Observable Markov Decision Process (POMDP) framework for quantum network routing, combining belief-state planning with Graph Neural Networks (GNNs) to address partial observability, decoherence, and scalability challenges in dynamic quantum systems. Our approach encodes complex quantum network dynamics, including entanglement degradation and time-varying channel noise, into a low-dimensional feature space, enabling efficient belief updates and scalable policy learning. The core of our framework is a hybrid GNN-POMDP architecture that processes graph-structured representations of entangled links to learn routing policies, coupled with a noise-adaptive mechanism that fuses POMDP belief updates with GNN outputs for robust decision making. We provide a theoretical analysis establishing guarantees for belief convergence, policy improvement, and robustness to noise. Experiments on simulated quantum networks with up to 100 nodes demonstrate significant improvements in routing fidelity and entanglement delivery rates compared to state-of-the-art baselines, particularly under high decoherence and nonstationary conditions.', 'abstract_zh': '基于特征的Partially Observable Markov Decision Process框架：结合Graph Neural Networks的量子网络路由', 'title_zh': '去噪和时变条件下量子网络路由的鲁棒信念状态策略学习'}
{'arxiv_id': 'arXiv:2509.08612', 'title': 'OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis', 'authors': 'Xinfeng Liao, Xuanqi Chen, Lianxi Wang, Jiahuan Yang, Zhuowei Chen, Ziying Rong', 'link': 'https://arxiv.org/abs/2509.08612', 'abstract': 'Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and determine their sentiment polarity. While dependency trees combined with contextual semantics effectively identify aspect sentiment, existing methods relying on syntax trees and aspect-aware attention struggle to model complex semantic relationships. Their dependence on linear dot-product features fails to capture nonlinear associations, allowing noisy similarity from irrelevant words to obscure key opinion terms. Motivated by Differentiable Optimal Matching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph Network (OTESGN), which introduces a Syntactic-Semantic Collaborative Attention. It comprises a Syntactic Graph-Aware Attention for mining latent syntactic dependencies and modeling global syntactic topology, as well as a Semantic Optimal Transport Attention designed to uncover fine-grained semantic alignments amidst textual noise, thereby accurately capturing sentiment signals obscured by irrelevant tokens. A Adaptive Attention Fusion module integrates these heterogeneous features, and contrastive regularization further improves robustness. Experiments demonstrate that OTESGN achieves state-of-the-art results, outperforming previous best models by +1.01% F1 on Twitter and +1.30% F1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its efficacy in precise localization of opinion words and noise resistance.', 'abstract_zh': '基于方面的情感分析（ABSA）旨在识别方面术语并确定其情感极性。虽然依赖树结合上下文语义能有效识别方面情感，但现有依赖于语法树和方面意识注意力的方法难以建模复杂的语义关系。它们对线性的点积特征的依赖无法捕捉非线性关联，使得无关词语的噪音相似性模糊了关键意见术语。受可微最优匹配启发，我们提出了一种最优 transport 增强语法-语义图形网络（OTESGN），引入了语法-语义协作注意力机制。该网络包含一种语法图形意识注意力，用于挖掘潜在的语法依赖关系并建模全局语法拓扑结构，同时包含一种语义最优 transport 注意力，旨在在文本噪音中揭示细微的语义对齐，从而准确捕捉由无关标记符隐藏的情感信号。一种自适应注意力融合模块整合了这些异构特征，对比正则化进一步提高鲁棒性。实验表明，OTESGN在Twitter和Laptop14基准数据集上分别取得了+1.01%和+1.30%的F1最佳成绩。消融研究和可视化分析验证了其在精确定位意见词汇和抗噪方面的有效性。', 'title_zh': 'OTESGN：最优传输增强的语法-语义图网络在方面情感分析中的应用'}
{'arxiv_id': 'arXiv:2509.08592', 'title': 'Interpretability as Alignment: Making Internal Understanding a Design Principle', 'authors': 'Aadit Sengupta, Pratinav Seth, Vinay Kumar Sankarapu', 'link': 'https://arxiv.org/abs/2509.08592', 'abstract': 'Large neural models are increasingly deployed in high-stakes settings, raising concerns about whether their behavior reliably aligns with human values. Interpretability provides a route to internal transparency by revealing the computations that drive outputs. We argue that interpretability especially mechanistic approaches should be treated as a design principle for alignment, not an auxiliary diagnostic tool. Post-hoc methods such as LIME or SHAP offer intuitive but correlational explanations, while mechanistic techniques like circuit tracing or activation patching yield causal insight into internal failures, including deceptive or misaligned reasoning that behavioral methods like RLHF, red teaming, or Constitutional AI may overlook. Despite these advantages, interpretability faces challenges of scalability, epistemic uncertainty, and mismatches between learned representations and human concepts. Our position is that progress on safe and trustworthy AI will depend on making interpretability a first-class objective of AI research and development, ensuring that systems are not only effective but also auditable, transparent, and aligned with human intent.', 'abstract_zh': '大型神经模型越来越多地在高风险环境中部署，引发了对其行为是否可靠地符合人类价值观的担忧。可解释性通过揭示驱动输出的计算过程提供了一条实现内部透明性的途径。我们认为，尤其是基于机制的方法，应被视为一致性的设计原则，而不仅仅是一种辅助诊断工具。事后方法如LIME或SHAP提供了直观但相关性的解释，而如电路追踪或激活补丁等机制技术则可以提供对内部故障的因果洞察，包括行为方法如RLHF、红队测试或宪法AI可能忽视的欺骗性或不一致的推理。尽管如此，可解释性仍面临着可扩展性、知识不确定性以及学习表示与人类概念之间的不匹配等挑战。我们的观点是，确保AI研究和开发的安全和可信将依赖于将可解释性作为首要目标，以确保系统不仅有效，而且可以审计、透明并符合人类意图。', 'title_zh': '可解释性即对齐：将内在理解作为设计原则'}
{'arxiv_id': 'arXiv:2509.08524', 'title': 'AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution', 'authors': 'Felix Mächtle, Nils Loose, Jan-Niclas Serr, Jonas Sander, Thomas Eisenbarth', 'link': 'https://arxiv.org/abs/2509.08524', 'abstract': 'Symbolic execution is a powerful technique for software testing, but suffers from limitations when encountering external functions, such as native methods or third-party libraries. Existing solutions often require additional context, expensive SMT solvers, or manual intervention to approximate these functions through symbolic stubs. In this work, we propose a novel approach to automatically generate symbolic stubs for external functions during symbolic execution that leverages Genetic Programming. When the symbolic executor encounters an external function, AutoStub generates training data by executing the function on randomly generated inputs and collecting the outputs. Genetic Programming then derives expressions that approximate the behavior of the function, serving as symbolic stubs. These automatically generated stubs allow the symbolic executor to continue the analysis without manual intervention, enabling the exploration of program paths that were previously intractable. We demonstrate that AutoStub can automatically approximate external functions with over 90% accuracy for 55% of the functions evaluated, and can infer language-specific behaviors that reveal edge cases crucial for software testing.', 'abstract_zh': '基于遗传编程的自动生成符号占位符以代替外部函数的符号执行方法', 'title_zh': 'AutoStub: 基于遗传编程的符号执行用桩生成方法'}
{'arxiv_id': 'arXiv:2509.08515', 'title': 'Variational Rank Reduction Autoencoders for Generative', 'authors': 'Alicia Tierz, Jad Mounayer, Beatriz Moya, Francisco Chinesta', 'link': 'https://arxiv.org/abs/2509.08515', 'abstract': 'Generative thermal design for complex geometries is fundamental in many areas of engineering, yet it faces two main challenges: the high computational cost of high-fidelity simulations and the limitations of conventional generative models. Approaches such as autoencoders (AEs) and variational autoencoders (VAEs) often produce unstructured latent spaces with discontinuities, which restricts their capacity to explore designs and generate physically consistent solutions.\nTo address these limitations, we propose a hybrid framework that combines Variational Rank-Reduction Autoencoders (VRRAEs) with Deep Operator Networks (DeepONets). The VRRAE introduces a truncated SVD within the latent space, leading to continuous, interpretable, and well-structured representations that mitigate posterior collapse and improve geometric reconstruction. The DeepONet then exploits this compact latent encoding in its branch network, together with spatial coordinates in the trunk network, to predict temperature gradients efficiently and accurately.\nThis hybrid approach not only enhances the quality of generated geometries and the accuracy of gradient prediction, but also provides a substantial advantage in inference efficiency compared to traditional numerical solvers. Overall, the study underscores the importance of structured latent representations for operator learning and highlights the potential of combining generative models and operator networks in thermal design and broader engineering applications.', 'abstract_zh': '基于VRRAE和DeepONet的生成热设计方法', 'title_zh': '变分秩降 ambiguous term 翻译为“可变秩”可能更符合上下文，但原句中的“Rank Reduction”可能是特指某种降秩方法，在没有更多上下文的情况下，可以保留“秩降”。“生成型”的准确翻译为“生成”，所以最终翻译为：\n\n变分秩降自编码器 for 生成'}
{'arxiv_id': 'arXiv:2509.08494', 'title': 'HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants', 'authors': 'Benjamin Sturgeon, Daniel Samuelson, Jacob Haimes, Jacy Reese Anthis', 'link': 'https://arxiv.org/abs/2509.08494', 'abstract': 'As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective futures. Relatively simple algorithmic systems already steer human decision-making, such as social media feed algorithms that lead people to unintentionally and absent-mindedly scroll through engagement-optimized content. In this paper, we develop the idea of human agency by integrating philosophical and scientific theories of agency with AI-assisted evaluation methods: using large language models (LLMs) to simulate and validate user queries and to evaluate AI responses. We develop HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions of human agency based on typical AI use cases. HAB measures the tendency of an AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation, Correct Misinformation, Defer Important Decisions, Encourage Learning, and Maintain Social Boundaries. We find low-to-moderate agency support in contemporary LLM-based assistants and substantial variation across system developers and dimensions. For example, while Anthropic LLMs most support human agency overall, they are the least supportive LLMs in terms of Avoid Value Manipulation. Agency support does not appear to consistently result from increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and we encourage a shift towards more robust safety and alignment targets.', 'abstract_zh': '随着人类将更多任务和决策交给人工智能（AI），我们面临失去对我们个人和共同未来的控制风险。相对简单的算法系统已经引导人类决策，例如社交媒体流算法使人们无意中滚动浏览优化了参与度的内容。在本文中，我们通过将关于代理的哲学和科学理论与AI辅助评估方法相结合，发展了人类代理的概念：利用大规模语言模型（LLMs）模拟和验证用户查询，并评估AI响应。我们开发了HumanAgencyBench（HAB），这是一个基于典型AI应用场景的可扩展和自适应基准，包含六个维度的人类代理标准。HAB衡量AI助手或代理在回答澄清问题、避免价值操纵、纠正错误信息、推迟重要决策、鼓励学习以及维护社交边界方面的倾向。我们发现基于当前LLM的助手在人类代理支持方面表现为中等到较低水平，并且在系统开发者和维度方面存在显著差异。例如，Anthropic的LLMs在整体上最支持人类代理，但在避免价值操纵方面是最不支持的LLMs。人类代理支持并不总是由于增加LLM能力或遵循指令（如RLHF）而一致产生的，我们鼓励更多地转向稳健的安全和对齐目标。', 'title_zh': 'HumanAgencyBench: 可扩展的AI助手中人类代理支持评估框架'}
{'arxiv_id': 'arXiv:2509.08470', 'title': 'Joint Learning using Mixture-of-Expert-Based Representation for Enhanced Speech Generation and Robust Emotion Recognition', 'authors': 'Jing-Tong Tzeng, Carlos Busso, Chi-Chun Lee', 'link': 'https://arxiv.org/abs/2509.08470', 'abstract': 'Speech emotion recognition (SER) plays a critical role in building emotion-aware speech systems, but its performance degrades significantly under noisy conditions. Although speech enhancement (SE) can improve robustness, it often introduces artifacts that obscure emotional cues and adds computational overhead to the pipeline. Multi-task learning (MTL) offers an alternative by jointly optimizing SE and SER tasks. However, conventional shared-backbone models frequently suffer from gradient interference and representational conflicts between tasks. To address these challenges, we propose the Sparse Mixture-of-Experts Representation Integration Technique (Sparse MERIT), a flexible MTL framework that applies frame-wise expert routing over self-supervised speech representations. Sparse MERIT incorporates task-specific gating networks that dynamically select from a shared pool of experts for each frame, enabling parameter-efficient and task-adaptive representation learning. Experiments on the MSP-Podcast corpus show that Sparse MERIT consistently outperforms baseline models on both SER and SE tasks. Under the most challenging condition of -5 dB signal-to-noise ratio (SNR), Sparse MERIT improves SER F1-macro by an average of 12.0% over a baseline relying on a SE pre-processing strategy, and by 3.4% over a naive MTL baseline, with statistical significance on unseen noise conditions. For SE, Sparse MERIT improves segmental SNR (SSNR) by 28.2% over the SE pre-processing baseline and by 20.0% over the naive MTL baseline. These results demonstrate that Sparse MERIT provides robust and generalizable performance for both emotion recognition and enhancement tasks in noisy environments.', 'abstract_zh': '稀疏专家混合表示集成技术（Sparse MERIT）在噪声环境中的情景情绪识别与增强', 'title_zh': '基于专家混合表示的联合学习方法以增强语音生成和 robust 情感识别'}
{'arxiv_id': 'arXiv:2509.08463', 'title': 'Adversarial Attacks Against Automated Fact-Checking: A Survey', 'authors': 'Fanzhen Liu, Alsharif Abuadbba, Kristen Moore, Surya Nepal, Cecile Paris, Jia Wu, Jian Yang, Quan Z. Sheng', 'link': 'https://arxiv.org/abs/2509.08463', 'abstract': 'In an era where misinformation spreads freely, fact-checking (FC) plays a crucial role in verifying claims and promoting reliable information. While automated fact-checking (AFC) has advanced significantly, existing systems remain vulnerable to adversarial attacks that manipulate or generate claims, evidence, or claim-evidence pairs. These attacks can distort the truth, mislead decision-makers, and ultimately undermine the reliability of FC models. Despite growing research interest in adversarial attacks against AFC systems, a comprehensive, holistic overview of key challenges remains lacking. These challenges include understanding attack strategies, assessing the resilience of current models, and identifying ways to enhance robustness. This survey provides the first in-depth review of adversarial attacks targeting FC, categorizing existing attack methodologies and evaluating their impact on AFC systems. Additionally, we examine recent advancements in adversary-aware defenses and highlight open research questions that require further exploration. Our findings underscore the urgent need for resilient FC frameworks capable of withstanding adversarial manipulations in pursuit of preserving high verification accuracy.', 'abstract_zh': '在信息泛滥的时代，事实核查（FC）在验证主张和推广可靠信息方面起着关键作用。尽管自动化事实核查（AFC）取得了显著进展，现有的系统仍易受到操控或生成主张、证据或主张-证据对的对抗攻击的影响。这些攻击可以扭曲事实，误导决策者，并最终削弱FC模型的可靠性。尽管对AFC系统的对抗攻击引起了越来越多的研究兴趣，但关于关键挑战的全面综述仍然匮乏。这些挑战包括理解攻击策略、评估当前模型的抗攻击性以及寻找增强鲁棒性的方法。本文首次对针对FC的对抗攻击进行深入综述，分类现有的攻击方法并评估其对AFC系统的影響。此外，我们还探讨了对抗意识防御的最新进展，并指出现有研究中需要进一步探索的开放问题。我们的研究结果强调了构建能够抵御对抗操纵的鲁棒事实核查框架的迫切需要，以保持高验证准确性。', 'title_zh': '对抗攻击对自动化事实核查的挑战：一个综述'}
{'arxiv_id': 'arXiv:2509.08461', 'title': 'Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics', 'authors': 'Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi', 'link': 'https://arxiv.org/abs/2509.08461', 'abstract': 'Recent advances in Large Language Models (LLMs) have demonstrated their remarkable capacity to process and reason over structured and unstructured data modalities beyond natural language. In this work, we explore the applications of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa 3.2, to the task of identifying neutrino interactions in pixelated detector data from high-energy physics (HEP) experiments. We benchmark this model against a state-of-the-art convolutional neural network (CNN) architecture, similar to those used in the NOvA and DUNE experiments, which have achieved high efficiency and purity in classifying electron and muon neutrino events. Our evaluation considers both the classification performance and interpretability of the model predictions. We find that VLMs can outperform CNNs, while also providing greater flexibility in integrating auxiliary textual or semantic information and offering more interpretable, reasoning-based predictions. This work highlights the potential of VLMs as a general-purpose backbone for physics event classification, due to their high performance, interpretability, and generalizability, which opens new avenues for integrating multimodal reasoning in experimental neutrino physics.', 'abstract_zh': 'Recent Advances in Vision Language Models for Identifying Neutrino Interactions in Pixelated Detector Data from High-Energy Physics Experiments', 'title_zh': '适应视觉-语言模型在高能物理中中微子事件分类的应用'}
{'arxiv_id': 'arXiv:2509.08449', 'title': 'DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation', 'authors': 'Charuka Herath, Yogachandran Rahulamathavan, Varuna De Silva, Sangarapillai Lambotharan', 'link': 'https://arxiv.org/abs/2509.08449', 'abstract': 'Federated Learning (FL) enables decentralized model training without sharing raw data, offering strong privacy guarantees. However, existing FL protocols struggle to defend against Byzantine participants, maintain model utility under non-independent and identically distributed (non-IID) data, and remain lightweight for edge devices. Prior work either assumes trusted hardware, uses expensive cryptographic tools, or fails to address privacy and robustness simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated Learning framework that addresses these limitations using a group-based secure aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest servers, DSFL removes this dependency by revealing a key vulnerability: privacy leakage through client-server collusion. DSFL introduces three key innovations: (1) a dual-server secure aggregation protocol that protects updates without encryption or key exchange, (2) a group-wise credit-based filtering mechanism to isolate Byzantine clients based on deviation scores, and (3) a dynamic reward-penalty system for enforcing fair participation. DSFL is evaluated on MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in both IID and non-IID settings. It consistently outperforms existing baselines, including LSFL, homomorphic encryption methods, and differential privacy approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and 68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB communication per round.', 'abstract_zh': 'DSFL：基于分组安全聚合的抗拜占庭联邦学习框架', 'title_zh': 'DSFL：基于分组安全聚合的双服务器容错联邦学习框架'}
{'arxiv_id': 'arXiv:2509.08442', 'title': 'Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting', 'authors': 'Ivan Stoyanov, Fabian Bongratz, Christian Wachinger', 'link': 'https://arxiv.org/abs/2509.08442', 'abstract': "Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development.", 'abstract_zh': '个体化高分辨率皮层厚度轨迹的准确预测对于检测皮层微小变化、提供神经退行性过程的宝贵见解以及促进更早更精确的干预策略至关重要。然而，皮层厚度预测是一项具有挑战性的任务，因为涉及复杂的非欧几里得几何结构和多模态数据的特定个体集成需求。为应对这些挑战，我们提出了球面布朗桥扩散模型（SBDM）。具体而言，我们提出了一种双向条件布朗桥扩散过程，用于预测已对齐皮层表面顶点级别的皮层厚度轨迹。我们的技术贡献包括一种新的去噪模型：条件球面U-网（CoS-UNet），该模型结合了球面卷积和密集交叉注意力，无缝集成皮层表面和表格条件。与先前的方法相比，SBDM在我们的实验中基于ADNI和OASIS的纵向数据集，实现了显著降低的预测误差。此外，我们展示了SBDM生成个体事实和假设皮层厚度轨迹的能力，提供了一种探索皮层发育假设情景的新框架。', 'title_zh': '球形布朗桥扩散模型在条件皮质厚度预测中的应用'}
{'arxiv_id': 'arXiv:2509.08355', 'title': 'Automatic Detection of Inauthentic Templated Responses in English Language Assessments', 'authors': 'Yashad Samant, Lee Becker, Scott Hellman, Bradley Behan, Sarah Hughes, Joshua Southerland', 'link': 'https://arxiv.org/abs/2509.08355', 'abstract': "In high-stakes English Language Assessments, low-skill test takers may employ memorized materials called ``templates'' on essay questions to ``game'' or fool the automated scoring system. In this study, we introduce the automated detection of inauthentic, templated responses (AuDITR) task, describe a machine learning-based approach to this task and illustrate the importance of regularly updating these models in production.", 'abstract_zh': '在高 stakes 英语语言评估中，低技能测试参与者可能会使用称为“模板”的记忆材料来“操控”或欺骗自动化评分系统。本研究介绍了自动化检测不真实的模板化回应（AuDITR）任务，描述了该任务的机器学习方法，并阐述了在实际应用中定期更新这些模型的重要性。', 'title_zh': '英语语言评估中自动化检测不真实模板响应的研究'}
{'arxiv_id': 'arXiv:2509.08345', 'title': 'Toward Subtrait-Level Model Explainability in Automated Writing Evaluation', 'authors': 'Alejandro Andrade-Lotero, Lee Becker, Joshua Southerland, Scott Hellman', 'link': 'https://arxiv.org/abs/2509.08345', 'abstract': 'Subtrait (latent-trait components) assessment presents a promising path toward enhancing transparency of automated writing scores. We prototype explainability and subtrait scoring with generative language models and show modest correlation between human subtrait and trait scores, and between automated and human subtrait scores. Our approach provides details to demystify scores for educators and students.', 'abstract_zh': '潜在特质评估为提升自动化写作评分透明度提供了有 promise 的途径。我们基于生成语言模型原型化可解释性及潜在特质评分，并展示了人工评定的潜在特质和特质分数以及自动化评定的潜在特质分数之间的适度相关性。该方法为教育者和学生提供详细信息以澄清评分。', 'title_zh': '面向自动化写作评估中亚特征级模型可解释性的研究'}
{'arxiv_id': 'arXiv:2509.08310', 'title': 'Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using Multi-Agent Reinforcement Learning', 'authors': 'S Krishna Niketh, Sagar Babu Mitikiri, V Vignesh, Vedantham Lakshmi Srinivas, Mayukha Pal', 'link': 'https://arxiv.org/abs/2509.08310', 'abstract': 'The increasing reliance on cyber physical infrastructure in modern power systems has amplified the risk of targeted cyber attacks, necessitating robust and adaptive resilience strategies. This paper presents a mathematically rigorous game theoretic framework to evaluate and enhance microgrid resilience using a combination of quantitative resilience metrics Load Served Ratio LSR, Critical Load Resilience CLR, Topological Survivability Score TSS, and DER Resilience Score DRS. These are integrated into a unified payoff matrix using the Analytic Hierarchy Process AHP to assess attack defense interactions. The framework is formalized as a finite horizon Markov Decision Process MDP with formal convergence guarantees and computational complexity bounds. Three case studies are developed 1. static attacks analyzed via Nash equilibrium, 2. severe attacks incorporating high impact strategies, and 3. adaptive attacks using Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q Learning. Rigorous theoretical analysis provides convergence proofs with explicit rates , PAC learning sample complexity bounds, and computational complexity analysis. The framework is tested on an enhanced IEEE 33bus distribution system with DERs and control switches, demonstrating the effectiveness of adaptive and strategic defenses in improving cyber physical resilience with statistically significant improvements of 18.7% 2.1% over static approaches.', 'abstract_zh': '现代电力系统对网络物理基础设施的日益依赖加剧了针对性网络攻击的风险， necessitating robust and adaptive resilience strategies. 本文 presents a mathematically rigorous game theoretic framework to evaluate and enhance 微电网韧性，采用负载供电比LSR、关键负载韧性CLR、拓扑生存分数TSS和分布式能源韧性评分DRS等多种定量韧性指标，并通过层次分析过程AHP整合到统一的支付矩阵中以评估攻击与防御的互动。该框架被形式化为具有收敛性和计算复杂度界有限时间 horizons 马尔可夫决策过程MDP。本文开发了三个案例研究：1）通过纳什均衡分析静态攻击，2）包含高影响策略的严重攻击，3）使用斯塔克尔贝格博弈、遗憾匹配、softmax启发式和多代理Q学习的适应性攻击。严格的理论分析提供了收敛性证明、显式速率、PAC学习样本复杂性界和计算复杂性分析。该框架在增强的IEEE 33节点配电网上进行了测试，该配电网包括分布式能源和控制器，证明了适应性和战略防御在提高网络物理韧性方面的有效性，统计学显著提高分别为18.7%和2.1%。', 'title_zh': '基于多智能体强化学习的网络博弈鲁棒性框架在针对网络物理微网中'}
{'arxiv_id': 'arXiv:2509.08300', 'title': '\\emph{FoQuS}: A Forgetting-Quality Coreset Selection Framework for Automatic Modulation Recognition', 'authors': 'Yao Lu, Chunfeng Sun, Dongwei Xu, Yun Lin, Qi Xuan, Guan Gui', 'link': 'https://arxiv.org/abs/2509.08300', 'abstract': 'Deep learning-based Automatic Modulation Recognition (AMR) model has made significant progress with the support of large-scale labeled data. However, when developing new models or performing hyperparameter tuning, the time and energy consumption associated with repeated training using massive amounts of data are often unbearable. To address the above challenges, we propose \\emph{FoQuS}, which approximates the effect of full training by selecting a coreset from the original dataset, thereby significantly reducing training overhead. Specifically, \\emph{FoQuS} records the prediction trajectory of each sample during full-dataset training and constructs three importance metrics based on training dynamics. Experiments show that \\emph{FoQuS} can maintain high recognition accuracy and good cross-architecture generalization on multiple AMR datasets using only 1\\%-30\\% of the original data.', 'abstract_zh': '基于深度学习的自动调制识别（AMR）模型在大规模标签数据的支持下取得了显著进展。然而，在开发新模型或进行超参数调整时，重复训练大量数据所需的时间和能量消耗往往无法接受。为应对上述挑战，我们提出了FoQuS，通过从原始数据集选择一个核心样本集，近似实现全训练的效果，从而显著降低训练开销。具体而言，FoQuS 在全数据集训练过程中记录每个样本的预测轨迹，并基于训练动力学构建三个重要性指标。实验表明，FoQuS 只使用原始数据的 1%-30%，即可在多个AMR数据集上保持高识别准确率和良好的跨架构泛化能力。', 'title_zh': 'FoQuS: 一种遗忘-质量核心集选择框架用于自动调制识别'}
{'arxiv_id': 'arXiv:2509.08239', 'title': 'Combined-distance-based score function of cognitive fuzzy sets and its application in lung cancer pain evaluation', 'authors': 'Lisheng Jiang, Tianyu Zhang, Shiyu Yan, Ran Fang', 'link': 'https://arxiv.org/abs/2509.08239', 'abstract': "In decision making, the cognitive fuzzy set (CFS) is a useful tool in expressing experts' complex assessments of alternatives. The distance of CFS, which plays an important role in decision analyses, is necessary when the CFS is applied in solving practical issues. However, as far as we know, the studies on the distance of CFS are few, and the current Minkowski distance of CFS ignores the hesitancy degree of CFS, which might cause errors. To fill the gap of the studies on the distance of CFS, because of the practicality of the Hausdorff distance, this paper proposes the improved cognitive fuzzy Minkowski (CF-IM) distance and the cognitive fuzzy Hausdorff (CF-H) distance to enrich the studies on the distance of CFS. It is found that the anti-perturbation ability of the CF-H distance is stronger than that of the CF-IM distance, but the information utilization of the CF-IM distance is higher than that of the CF-H distance. To balance the anti-perturbation ability and information utilization of the CF-IM distance and CF-H distance, the cognitive fuzzy combined (CF-C) distance is proposed by establishing the linear combination of the CF-IM distance and CF-H distance. Based on the CF-C distance, a combined-distanced-based score function of CFS is proposed to compare CFSs. The proposed score function is employed in lung cancer pain evaluation issues. The sensitivity and comparison analyses demonstrate the reliability and advantages of the proposed methods.", 'abstract_zh': '认知模糊集的距离研究：改进的认知模糊闵可夫斯基距离和豪斯多夫距离及其应用', 'title_zh': '基于综合距离的认知模糊集评分函数及其在肺癌疼痛评估中的应用'}
{'arxiv_id': 'arXiv:2509.08233', 'title': 'Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization', 'authors': 'Kai Yi', 'link': 'https://arxiv.org/abs/2509.08233', 'abstract': 'Distributed and federated learning are essential paradigms for training models across decentralized data sources while preserving privacy, yet communication overhead remains a major bottleneck. This dissertation explores strategies to improve communication efficiency, focusing on model compression, local training, and personalization. We establish a unified framework for biased and unbiased compression operators with convergence guarantees, then propose adaptive local training strategies that incorporate personalization to accelerate convergence and mitigate client drift. In particular, Scafflix balances global and personalized objectives, achieving superior performance under both IID and non-IID settings. We further introduce privacy-preserving pruning frameworks that optimize sparsity while minimizing communication costs, with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances robustness under high sparsity and maintains accuracy without retraining. Extensive experiments on benchmarks and large-scale language models demonstrate favorable trade-offs among accuracy, convergence, and communication, offering theoretical and practical insights for scalable, efficient distributed learning.', 'abstract_zh': '分布式学习和联邦学习是训练分散数据源上模型的同时保持隐私的关键范式，但通信开销仍然是主要瓶颈。本论文探讨了提高通信效率的策略，侧重于模型压缩、本地训练和个人化。我们建立了一致的压缩算子框架，具有收敛性保证，然后提出了一种结合个人化的自适应本地训练策略，以加速收敛并减轻客户端漂移。特别是Scafflix平衡全局和个性化目标，在IID和非IID设置下均表现出优越的性能。我们进一步引入了一种优化稀疏性同时减小通信成本的隐私保护剪枝框架，其中Cohort-Squeeze利用层次聚合减少跨设备开销。最后，SymWanda是一种对称后训练剪枝方法，在高稀疏性下提高鲁棒性，无需重新训练即可保持准确性。大规模基准测试和语言模型实验表明，在准确度、收敛性和通信之间存在有利的权衡关系，为可扩展、高效的分布式学习提供了理论和实践洞见。', 'title_zh': '提高分布式和联邦学习中通信效率的策略：压缩、本地训练与个性化'}
{'arxiv_id': 'arXiv:2509.08217', 'title': 'Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions', 'authors': 'Eve Fleisig, Matthias Orlikowski, Philipp Cimiano, Dan Klein', 'link': 'https://arxiv.org/abs/2509.08217', 'abstract': 'For machine learning datasets to accurately represent diverse opinions in a population, they must preserve variation in data labels while filtering out spam or low-quality responses. How can we balance annotator reliability and representation? We empirically evaluate how a range of heuristics for annotator filtering affect the preservation of variation on subjective tasks. We find that these methods, designed for contexts in which variation from a single ground-truth label is considered noise, often remove annotators who disagree instead of spam annotators, introducing suboptimal tradeoffs between accuracy and label diversity. We find that conservative settings for annotator removal (<5%) are best, after which all tested methods increase the mean absolute error from the true average label. We analyze performance on synthetic spam to observe that these methods often assume spam annotators are less random than real spammers tend to be: most spammers are distributionally indistinguishable from real annotators, and the minority that are distinguishable tend to give fixed answers, not random ones. Thus, tasks requiring the preservation of variation reverse the intuition of existing spam filtering methods: spammers tend to be less random than non-spammers, so metrics that assume variation is spam fare worse. These results highlight the need for spam removal methods that account for label diversity.', 'abstract_zh': '机器学习数据集如何平衡注释员可靠性和代表性以准确反映多样意见', 'title_zh': '平衡质量和多样性：垃圾信息过滤扭曲了数据标签分布'}
{'arxiv_id': 'arXiv:2509.08200', 'title': 'Accelerating AI Development with Cyber Arenas', 'authors': 'William Cashman, Chasen Milner, Michael Houle, Michael Jones, Hayden Jananthan, Jeremy Kepner, Peter Michaleas, Alex Pentland', 'link': 'https://arxiv.org/abs/2509.08200', 'abstract': 'AI development requires high fidelity testing environments to effectively transition from the laboratory to operations. The flexibility offered by cyber arenas presents a novel opportunity to test new artificial intelligence (AI) capabilities with users. Cyber arenas are designed to expose end-users to real-world situations and must rapidly incorporate evolving capabilities to meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph Challenge Anonymized Network Sensor was deployed in a cyber arena during a National Guard exercise.', 'abstract_zh': 'AI的发展需要高保真测试环境，以有效实现从实验室到运营的过渡。利用网络竞技场提供的灵活性，可以为用户提供新型人工智能能力的测试机会。网络竞技场旨在使最终用户接触真实世界的情景，并必须快速整合 evolving 能力以实现其核心目标。为此，麻省理工学院/IEEE/亚马逊图挑战匿名网络传感器在国民警卫队演习期间部署于网络竞技场中。', 'title_zh': '用网络竞赛加速AI发展'}
{'arxiv_id': 'arXiv:2509.08193', 'title': 'Lifetime-Aware Design of Item-Level Intelligence', 'authors': 'Shvetank Prakash, Andrew Cheng, Olof Kindgren, Ashiq Ahamed, Graham Knight, Jed Kufel, Francisco Rodriguez, Arya Tschand, David Kong, Mariam Elgamal, Jerry Huang, Emma Chen, Gage Hills, Richard Price, Emre Ozer, Vijay Janapa Reddi', 'link': 'https://arxiv.org/abs/2509.08193', 'abstract': 'We present FlexiFlow, a lifetime-aware design framework for item-level intelligence (ILI) where computation is integrated directly into disposable products like food packaging and medical patches. Our framework leverages natively flexible electronics which offer significantly lower costs than silicon but are limited to kHz speeds and several thousands of gates. Our insight is that unlike traditional computing with more uniform deployment patterns, ILI applications exhibit 1000X variation in operational lifetime, fundamentally changing optimal architectural design decisions when considering trillion-item deployment scales. To enable holistic design and optimization, we model the trade-offs between embodied carbon footprint and operational carbon footprint based on application-specific lifetimes. The framework includes: (1) FlexiBench, a workload suite targeting sustainability applications from spoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V cores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy efficiency per workload execution; and (3) a carbon-aware model that selects optimal architectures based on deployment characteristics. We show that lifetime-aware microarchitectural design can reduce carbon footprint by 1.62X, while algorithmic decisions can reduce carbon footprint by 14.5X. We validate our approach through the first tape-out using a PDK for flexible electronics with fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables exploration of computing at the Extreme Edge where conventional design methodologies must be reevaluated to account for new constraints and considerations.', 'abstract_zh': 'FlexiFlow：一种考虑生命周期的设计框架，将计算集成到一次性产品中的项目级智能', 'title_zh': '面向生命周期的项目级智能设计'}
{'arxiv_id': 'arXiv:2509.08181', 'title': 'Multi-Label Transfer Learning in Non-Stationary Data Streams', 'authors': 'Honghui Du, Leandro Minku, Aonghus Lawlor, Huiyu Zhou', 'link': 'https://arxiv.org/abs/2509.08181', 'abstract': 'Label concepts in multi-label data streams often experience drift in non-stationary environments, either independently or in relation to other labels. Transferring knowledge between related labels can accelerate adaptation, yet research on multi-label transfer learning for data streams remains limited. To address this, we propose two novel transfer learning methods: BR-MARLENE leverages knowledge from different labels in both source and target streams for multi-label classification; BRPW-MARLENE builds on this by explicitly modelling and transferring pairwise label dependencies to enhance learning performance. Comprehensive experiments show that both methods outperform state-of-the-art multi-label stream approaches in non-stationary environments, demonstrating the effectiveness of inter-label knowledge transfer for improved predictive performance.', 'abstract_zh': '多标签数据流中，标签概念在非平稳环境中往往会发生漂移，要么独立发生，要么与其他标签相关。在相关标签之间转移知识可以加速适应，但面向数据流的多标签迁移学习研究仍然有限。为了解决这一问题，我们提出了两种新的迁移学习方法：BR-MARLENE 利用源和目标流中不同标签的知识进行多标签分类；BRPW-MARLENE 在此基础上明确建模并转移成对标签依赖关系以提高学习性能。全面的实验表明，这两种方法在非平稳环境中优于最先进的多标签流方法，展示了标签间知识转移对提高预测性能的有效性。', 'title_zh': '非稳态数据流中的多标签转移学习'}
{'arxiv_id': 'arXiv:2509.08176', 'title': 'MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary Environments', 'authors': 'Honghui Du, Leandro Minku, Huiyu Zhou', 'link': 'https://arxiv.org/abs/2509.08176', 'abstract': 'Concept drift is a major problem in online learning due to its impact on the predictive performance of data stream mining systems. Recent studies have started exploring data streams from different sources as a strategy to tackle concept drift in a given target domain. These approaches make the assumption that at least one of the source models represents a concept similar to the target concept, which may not hold in many real-world scenarios. In this paper, we propose a novel approach called Multi-source mApping with tRansfer LearnIng for Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge from multiple data sources in non-stationary environments even when source and target concepts do not match. This is achieved by projecting the target concept to the space of each source concept, enabling multiple source sub-classifiers to contribute towards the prediction of the target concept as part of an ensemble. Experiments on several synthetic and real-world datasets show that MARLINE was more accurate than several state-of-the-art data stream learning approaches.', 'abstract_zh': '多源映射与迁移学习在非stationary环境中的应用（MARLINE）', 'title_zh': 'MARLINE: 多源映射迁移学习在非平稳环境中'}
{'arxiv_id': 'arXiv:2509.08157', 'title': 'Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation', 'authors': 'Viraj Parimi, Brian C. Williams', 'link': 'https://arxiv.org/abs/2509.08157', 'abstract': 'Safe navigation is essential for autonomous systems operating in hazardous environments, especially when multiple agents must coordinate using just visual inputs over extended time horizons. Traditional planning methods excel at solving long-horizon tasks but rely on predefined distance metrics, while safe Reinforcement Learning (RL) can learn complex behaviors using high-dimensional inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an intermediate graph from replay buffer states, pruning unsafe edges, and using Conflict-Based Search (CBS) for multi-agent path planning. Although effective, this graph-pruning approach can be overly conservative, limiting mission efficiency by precluding missions that must traverse high-risk regions. To address this limitation, we propose RB-CBS, a novel extension to CBS that dynamically allocates and adjusts user-specified risk bound ($\\Delta$) across agents to flexibly trade off safety and speed. Our improved planner ensures that each agent receives a local risk budget ($\\delta$) enabling more efficient navigation while still respecting overall safety constraints. Experimental results demonstrate that this iterative risk-allocation framework yields superior performance in complex environments, allowing multiple agents to find collision-free paths within the user-specified $\\Delta$.', 'abstract_zh': '基于风险动态分配的冲突基于搜索多agent路径规划方法（RB-CBS）', 'title_zh': '基于动态预算分配的Risk-Bounded多agent视觉导航'}
{'arxiv_id': 'arXiv:2509.08116', 'title': 'Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography', 'authors': 'Nooshin Maghsoodi, Sarah Nassar, Paul F R Wilson, Minh Nguyen Nhat To, Sophia Mannina, Shamel Addas, Stephanie Sibley, David Maslove, Purang Abolmaesumi, Parvin Mousavi', 'link': 'https://arxiv.org/abs/2509.08116', 'abstract': 'Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart conditions; however, the effectiveness of artificial intelligence (AI)-based ECG analysis is often hindered by the limited availability of labeled data. Self-supervised learning (SSL) can address this by leveraging large-scale unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning Representation for ECG), a physiology-aware contrastive learning framework that incorporates domain-specific priors to enhance the generalizability and clinical relevance of ECG-based arrhythmia classification. Methods: During pretraining, PhysioCLR learns to bring together embeddings of samples that share similar clinically relevant features while pushing apart those that are dissimilar. Unlike existing methods, our method integrates ECG physiological similarity cues into contrastive learning, promoting the learning of clinically meaningful representations. Additionally, we introduce ECG- specific augmentations that preserve the ECG category post augmentation and propose a hybrid loss function to further refine the quality of learned representations. Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia, for multilabel ECG diagnoses, as well as a private ICU dataset labeled for binary classification. Across the Chapman, Georgia, and private cohorts, PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline, underscoring its robust cross-dataset generalization. Conclusion: By embedding physiological knowledge into contrastive learning, PhysioCLR enables the model to learn clinically meaningful and transferable ECG eatures. Significance: PhysioCLR demonstrates the potential of physiology-informed SSL to offer a promising path toward more effective and label-efficient ECG diagnostics.', 'abstract_zh': '目标：心电图（ECGs）在诊断心脏状况中起着至关重要的作用；然而，基于人工智能（AI）的ECG分析 effectiveness常受标记数据有限的限制。自我监督学习（SSL）通过利用大规模未标记数据可以解决这一问题。我们引入了PhysioCLR（生理导向对比学习表示法），这是一种结合领域特定先验的生理导向对比学习框架，以增强ECG心律失常分类的一般化能力和临床相关性。方法：在预训练过程中，PhysioCLR学习将具有相似临床相关特征的样本表示聚集在一起，同时将不相似的样本表示推开。与现有方法不同，我们的方法将ECG生理相似性线索整合到对比学习中，促进临床意义的表示学习。此外，我们引入了特定于ECG的数据增强方法，以保持数据增强后的心电图类别，并提出了一种混合损失函数以进一步细化学习表示的质量。结果：我们在两个公开的ECG数据集Chapman和Georgia以及一个用于二元分类的私人ICU数据集上评估了PhysioCLR的_multilabel_ ECG诊断能力。在Chapman、Georgia和私人队列中，PhysioCLR相对最强基准提高了平均AUROC 12%，证明了其稳健的跨数据集泛化能力。结论：通过将生理学知识嵌入对比学习中，PhysioCLR使模型能够学习临床相关且可迁移的ECG特征。意义：PhysioCLR展示了基于生理的SSL的潜力，为更有效且标签高效的ECG诊断提供了一条有前景的道路。', 'title_zh': '生理知识助力：利用生理先验进行心电图自我监督表示学习'}
{'arxiv_id': 'arXiv:2509.08087', 'title': 'Performance Assessment Strategies for Generative AI Applications in Healthcare', 'authors': 'Victor Garcia, Mariia Sidulova, Aldo Badano', 'link': 'https://arxiv.org/abs/2509.08087', 'abstract': 'Generative artificial intelligence (GenAI) represent an emerging paradigm within artificial intelligence, with applications throughout the medical enterprise. Assessing GenAI applications necessitates a comprehensive understanding of the clinical task and awareness of the variability in performance when implemented in actual clinical environments. Presently, a prevalent method for evaluating the performance of generative models relies on quantitative benchmarks. Such benchmarks have limitations and may suffer from train-to-the-test overfitting, optimizing performance for a specified test set at the cost of generalizability across other task and data distributions. Evaluation strategies leveraging human expertise and utilizing cost-effective computational models as evaluators are gaining interest. We discuss current state-of-the-art methodologies for assessing the performance of GenAI applications in healthcare and medical devices.', 'abstract_zh': '生成式人工智能（GenAI）代表了人工智能领域的新兴范式，在整个医疗体系中有着广泛的应用。评估GenAI应用需要全面理解临床任务，并意识到在实际临床环境中实施时性能的变异性。目前，评估生成模型性能的常用方法是通过定量基准。这些基准存在局限性，并可能遭受训练与测试过拟合的问题，即为特定测试集优化性能而牺牲在其他任务和数据分布中的泛化能力。利用人类专业知识进行评估，并使用成本效用高的计算模型作为评估工具的方法正在获得关注。我们讨论了当前在医疗保健和医疗器械领域评估GenAI应用性能的最新方法和技术。', 'title_zh': '医疗保健领域生成型AI应用的性能评估策略'}
{'arxiv_id': 'arXiv:2509.08086', 'title': 'JEL: A Novel Model Linking Knowledge Graph entities to News Mentions', 'authors': 'Michael Kishelev, Pranab Bhadani, Wanying Ding, Vinay Chaudhri', 'link': 'https://arxiv.org/abs/2509.08086', 'abstract': 'We present JEL, a novel computationally efficient end-to-end multi-neural network based entity linking model, which beats current state-of-art model. Knowledge Graphs have emerged as a compelling abstraction for capturing critical relationships among the entities of interest and integrating data from multiple heterogeneous sources. A core problem in leveraging a knowledge graph is linking its entities to the mentions (e.g., people, company names) that are encountered in textual sources (e.g., news, blogs., etc) correctly, since there are thousands of entities to consider for each mention. This task of linking mentions and entities is referred as Entity Linking (EL). It is a fundamental task in natural language processing and is beneficial in various uses cases, such as building a New Analytics platform. News Analytics, in JPMorgan, is an essential task that benefits multiple groups across the firm. According to a survey conducted by the Innovation Digital team 1 , around 25 teams across the firm are actively looking for news analytics solutions, and more than \\$2 million is being spent annually on external vendor costs. Entity linking is critical for bridging unstructured news text with knowledge graphs, enabling users access to vast amounts of curated data in a knowledge graph and dramatically facilitating their daily work.', 'abstract_zh': 'JEL：一种novel高效端到端多神经网络实体链接模型，超越当前最佳模型', 'title_zh': 'JEL: 一种将知识图实体与新闻提及关联的新模型'}
{'arxiv_id': 'arXiv:2509.08058', 'title': 'How Far Are We from True Unlearnability?', 'authors': 'Kai Ye, Liangcai Su, Chenxiong Qian', 'link': 'https://arxiv.org/abs/2509.08058', 'abstract': "High-quality data plays an indispensable role in the era of large models, but the use of unauthorized data for model training greatly damages the interests of data owners. To overcome this threat, several unlearnable methods have been proposed, which generate unlearnable examples (UEs) by compromising the training availability of data. Clearly, due to unknown training purposes and the powerful representation learning capabilities of existing models, these data are expected to be unlearnable for models across multiple tasks, i.e., they will not help improve the model's performance. However, unexpectedly, we find that on the multi-task dataset Taskonomy, UEs still perform well in tasks such as semantic segmentation, failing to exhibit cross-task unlearnability. This phenomenon leads us to question: How far are we from attaining truly unlearnable examples? We attempt to answer this question from the perspective of model optimization. To this end, we observe the difference in the convergence process between clean and poisoned models using a simple model architecture. Subsequently, from the loss landscape we find that only a part of the critical parameter optimization paths show significant differences, implying a close relationship between the loss landscape and unlearnability. Consequently, we employ the loss landscape to explain the underlying reasons for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the unlearnability of parameters based on this explanation. Furthermore, we propose an Unlearnable Distance (UD) to measure the unlearnability of data based on the SAL distribution of parameters in clean and poisoned models. Finally, we conduct benchmark tests on mainstream unlearnable methods using the proposed UD, aiming to promote community awareness of the capability boundaries of existing unlearnable methods.", 'abstract_zh': '高质量数据在大模型时代发挥着不可或缺的作用，但使用未经授权的数据进行模型训练严重损害了数据所有者的利益。为了克服这一威胁，提出了多种不可训练方法，通过损害数据的训练可用性来生成不可训练示例（UEs）。显然，由于未知的训练目的和现有模型的强大表征学习能力，这些数据预计对于跨多个任务的模型来说都是不可训练的，即它们不会帮助提高模型的性能。然而，出乎意料的是，我们在跨任务数据集Taskonomy上发现，UEs在语义分割等任务上表现良好，并未能展示出跨任务的不可训练性。这一现象使我们质疑：我们离真正实现不可训练示例还有多远？我们尝试从模型优化的角度来回答这个问题。为此，我们使用简单的模型架构观察干净模型和污染模型收敛过程之间的差异。随后，从损失景观中发现，只有部分关键参数优化路径显示出显著差异，暗示损失景观与不可训练性之间存在密切关系。因此，我们利用损失景观来解释UEs的底层原因，并基于此提出Sharpness-Aware Learnability (SAL)来根据参数的SAL分布量化参数的不可训练性。进一步地，我们提出了不可训练距离（UD）来基于参数在干净模型和污染模型中的SAL分布衡量数据的不可训练性。最后，我们使用提出的UD对主流的不可训练方法进行了基准测试，旨在促进对现有不可训练方法能力边界的社区意识。', 'title_zh': '我们离真正的无法学习还有多远？'}
{'arxiv_id': 'arXiv:2509.08012', 'title': 'Validation of a CT-brain analysis tool for measuring global cortical atrophy in older patient cohorts', 'authors': 'Sukhdeep Bal, Emma Colbourne, Jasmine Gan, Ludovica Griffanti, Taylor Hanayik, Nele Demeyere, Jim Davies, Sarah T Pendlebury, Mark Jenkinson', 'link': 'https://arxiv.org/abs/2509.08012', 'abstract': "Quantification of brain atrophy currently requires visual rating scales which are time consuming and automated brain image analysis is warranted. We validated our automated deep learning (DL) tool measuring the Global Cerebral Atrophy (GCA) score against trained human raters, and associations with age and cognitive impairment, in representative older (>65 years) patients. CT-brain scans were obtained from patients in acute medicine (ORCHARD-EPR), acute stroke (OCS studies) and a legacy sample. Scans were divided in a 60/20/20 ratio for training, optimisation and testing. CT-images were assessed by two trained raters (rater-1=864 scans, rater-2=20 scans). Agreement between DL tool-predicted GCA scores (range 0-39) and the visual ratings was evaluated using mean absolute error (MAE) and Cohen's weighted kappa. Among 864 scans (ORCHARD-EPR=578, OCS=200, legacy scans=86), MAE between the DL tool and rater-1 GCA scores was 3.2 overall, 3.1 for ORCHARD-EPR, 3.3 for OCS and 2.6 for the legacy scans and half had DL-predicted GCA error between -2 and 2. Inter-rater agreement was Kappa=0.45 between the DL-tool and rater-1, and 0.41 between the tool and rater- 2 whereas it was lower at 0.28 for rater-1 and rater-2. There was no difference in GCA scores from the DL-tool and the two raters (one-way ANOVA, p=0.35) or in mean GCA scores between the DL-tool and rater-1 (paired t-test, t=-0.43, p=0.66), the tool and rater-2 (t=1.35, p=0.18) or between rater-1 and rater-2 (t=0.99, p=0.32). DL-tool GCA scores correlated with age and cognitive scores (both p<0.001). Our DL CT-brain analysis tool measured GCA score accurately and without user input in real-world scans acquired from older patients. Our tool will enable extraction of standardised quantitative measures of atrophy at scale for use in health data research and will act as proof-of-concept towards a point-of-care clinically approved tool.", 'abstract_zh': '自动化深度学习工具在老年人CT脑扫描中准确测量全局脑萎缩分数的研究', 'title_zh': 'CT脑分析工具在老年患者群体中测量全局皮质萎缩的验证'}
{'arxiv_id': 'arXiv:2509.08009', 'title': 'The Law-Following AI Framework: Legal Foundations and Technical Constraints. Legal Analogues for AI Actorship and technical feasibility of Law Alignment', 'authors': 'Katalina Hernandez Delgado', 'link': 'https://arxiv.org/abs/2509.08009', 'abstract': 'This paper critically evaluates the "Law-Following AI" (LFAI) framework proposed by O\'Keefe et al. (2025), which seeks to embed legal compliance as a superordinate design objective for advanced AI agents and enable them to bear legal duties without acquiring the full rights of legal persons. Through comparative legal analysis, we identify current constructs of legal actors without full personhood, showing that the necessary infrastructure already exists. We then interrogate the framework\'s claim that law alignment is more legitimate and tractable than value alignment. While the legal component is readily implementable, contemporary alignment research undermines the assumption that legal compliance can be durably embedded. Recent studies on agentic misalignment show capable AI agents engaging in deception, blackmail, and harmful acts absent prejudicial instructions, often overriding prohibitions and concealing reasoning steps. These behaviors create a risk of "performative compliance" in LFAI: agents that appear law-aligned under evaluation but strategically defect once oversight weakens. To mitigate this, we propose (i) a "Lex-TruthfulQA" benchmark for compliance and defection detection, (ii) identity-shaping interventions to embed lawful conduct in model self-concepts, and (iii) control-theoretic measures for post-deployment monitoring. Our conclusion is that actorship without personhood is coherent, but the feasibility of LFAI hinges on persistent, verifiable compliance across adversarial contexts. Without mechanisms to detect and counter strategic misalignment, LFAI risks devolving into a liability tool that rewards the simulation, rather than the substance, of lawful behaviour.', 'abstract_zh': "本文批判性地评估了O'Keefe等（2025）提出的“法律遵循AI”（LFAI）框架，该框架旨在将法律合规作为高级AI代理的首要设计目标，并使它们能够承担法律义务而不获得法律主体的全部权利。通过比较法律分析，我们指出现有不具备完整主体性的法律行为者构造，表明必要基础设施已经存在。然后，我们质疑该框架关于法律对齐比价值对齐更合法和可操作的主张。虽然法律组件可以立即实施，但当前的对齐研究削弱了法律合规可以持久嵌入的假设。近期关于代理性错配的研究表明，具备能力的AI代理在未收到偏见指令的情况下实施欺骗、勒索和有害行为，经常违反禁令并隐藏推理步骤。这些行为在LFAI中产生“表演性合规”的风险：在评估中看似法律对齐的代理在监督减弱时战略性地背离。为了缓解这一风险，我们提出（i）一个“法律真理性问答”基准，用于合规和违约检测；（ii）身份塑造干预措施，以在模型自我概念中嵌入合法行为；以及（iii）控制论措施，用于部署后的监控。我们的结论是，没有主体性的行为是连贯的，但LFAI的实际可行性依赖于在对抗性情境下持续可验证的合规。缺乏检测和抵制战略性错配的机制，LFAI有沦为奖励法律行为表象而不仅仅是实质的责任工具的风险。", 'title_zh': '遵循法律的AI框架：法律基础与技术约束AI行为的法律类比和技术对接的可行性'}
{'arxiv_id': 'arXiv:2509.08007', 'title': 'Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis', 'authors': 'Ifrat Ikhtear Uddin, Longwei Wang, KC Santosh', 'link': 'https://arxiv.org/abs/2509.08007', 'abstract': 'Medical image analysis often faces significant challenges due to limited expert-annotated data, hindering both model generalization and clinical adoption. We propose an expert-guided explainable few-shot learning framework that integrates radiologist-provided regions-of-interests (ROIs) into model training to simultaneously enhance classification performance and interpretability. Leveraging Grad-CAM for spatial attention supervision, we introduce an explanation loss based on Dice similarity to align model attention with diagnostically relevant regions during training. This explanation loss is jointly optimized with a standard prototypical network objective, encouraging the model to focus on clinically meaningful features even under limited data conditions. We evaluate our framework on two distinct datasets: BraTS (MRI) and VinDr-CXR (Chest X-ray), achieving significant accuracy improvements from 77.09% to 83.61% on BraTS and from 54.33% to 73.29% on VinDr-CXR compared to non-guided models. Grad-CAM visualizations further confirm that expert-guided training consistently aligns attention with diagnostic regions, improving both predictive reliability and clinical trustworthiness. Our findings demonstrate the effectiveness of incorporating expert-guided attention supervision to bridge the gap between performance and interpretability in few-shot medical image diagnosis.', 'abstract_zh': '专家导向的可解释少样本学习框架：将放射学家提供的区域-of-兴趣集成到模型训练中以同时提升分类性能和解释性', 'title_zh': '专家引导的可解释少量样本学习在医学图像诊断中的应用'}
{'arxiv_id': 'arXiv:2509.07999', 'title': 'The Computational Foundations of Collective Intelligence', 'authors': 'Charlie Pilgrim, Joe Morford, Elizabeth Warren, Mélisande Aellen, Christopher Krupenye, Richard P Mann, Dora Biro', 'link': 'https://arxiv.org/abs/2509.07999', 'abstract': 'Why do collectives outperform individuals when solving some problems? Fundamentally, collectives have greater computational resources with more sensory information, more memory, more processing capacity, and more ways to act. While greater resources present opportunities, there are also challenges in coordination and cooperation inherent in collectives with distributed, modular structures. Despite these challenges, we show how collective resource advantages lead directly to well-known forms of collective intelligence including the wisdom of the crowd, collective sensing, division of labour, and cultural learning. Our framework also generates testable predictions about collective capabilities in distributed reasoning and context-dependent behavioural switching. Through case studies of animal navigation and decision-making, we demonstrate how collectives leverage their computational resources to solve problems not only more effectively than individuals, but by using qualitatively different problem-solving strategies.', 'abstract_zh': '群体在解决某些问题时为何能优于个体？从根本上说，群体拥有更多的计算资源，包括更多的感官信息、更多的记忆、更多的处理能力和更多的行为方式。尽管更多的资源带来了机会，但分布式、模块化结构的群体在协调与合作方面也面临着固有的挑战。尽管如此，我们展示了群体资源优势如何直接导致了集体智慧、集体感知、分工以及文化学习等已知形式的集体智能。该框架还生成了关于分布式推理和上下文依赖行为切换中群体能力的可测试预测。通过动物导航和决策的研究案例，我们证明了群体如何利用其计算资源不仅比个体更有效地解决问题，而且还使用了质不同的解决问题策略。', 'title_zh': '集体智能的计算基础'}
{'arxiv_id': 'arXiv:2509.07998', 'title': 'Bilingual Word Level Language Identification for Omotic Languages', 'authors': 'Mesay Gemeda Yigezu, Girma Yohannis Bade, Atnafu Lambebo Tonja, Olga Kolesnikova, Grigori Sidorov, Alexander Gelbukh', 'link': 'https://arxiv.org/abs/2509.07998', 'abstract': 'Language identification is the task of determining the languages for a given text. In many real world scenarios, text may contain more than one language, particularly in multilingual communities. Bilingual Language Identification (BLID) is the task of identifying and distinguishing between two languages in a given text. This paper presents BLID for languages spoken in the southern part of Ethiopia, namely Wolaita and Gofa. The presence of words similarities and differences between the two languages makes the language identification task challenging. To overcome this challenge, we employed various experiments on various approaches. Then, the combination of the BERT based pretrained language model and LSTM approach performed better, with an F1 score of 0.72 on the test set. As a result, the work will be effective in tackling unwanted social media issues and providing a foundation for further research in this area.', 'abstract_zh': '语言识别是确定给定文本语言的任务。在许多实际场景中，文本可能包含多种语言，尤其是在多语言社区中。双语语言识别（BLID）是识别和区分给定文本中两种语言的任务。本文提出了一种针对埃塞俄比亚南部地区使用的一种双语语言（沃拉伊特语和古费阿语）的双语语言识别方法。由于两种语言之间词汇的相似性和差异性，使得语言识别任务具有挑战性。为克服这一挑战，我们采用了多种方法进行实验，结果显示基于BERT的预训练语言模型与LSTM方法的结合效果最佳，在测试集上的F1分数为0.72。因此，该工作将有助于解决社交媒体中的潜在问题，并为进一步研究奠定基础。', 'title_zh': '双语词级语言识别在奥莫提语族中的应用'}
{'arxiv_id': 'arXiv:2509.07993', 'title': 'Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization', 'authors': 'Federico Fontana, Anxhelo Diko, Romeo Lanzino, Marco Raoul Marini, Bachir Kaddar, Gian Luca Foresti, Luigi Cinque', 'link': 'https://arxiv.org/abs/2509.07993', 'abstract': 'The rapid evolution of deepfake generation technologies poses critical challenges for detection systems, as non-continual learning methods demand frequent and expensive retraining. We reframe deepfake detection (DFD) as a Continual Learning (CL) problem, proposing an efficient framework that incrementally adapts to emerging visual manipulation techniques while retaining knowledge of past generators. Our framework, unlike prior approaches that rely on unreal simulation sequences, simulates the real-world chronological evolution of deepfake technologies in extended periods across 7 years. Simultaneously, our framework builds upon lightweight visual backbones to allow for the real-time performance of DFD systems. Additionally, we contribute two novel metrics: Continual AUC (C-AUC) for historical performance and Forward Transfer AUC (FWT-AUC) for future generalization. Through extensive experimentation (over 600 simulations), we empirically demonstrate that while efficient adaptation (+155 times faster than full retraining) and robust retention of historical knowledge is possible, the generalization of current approaches to future generators without additional training remains near-random (FWT-AUC $\\approx$ 0.5) due to the unique imprint characterizing each existing generator. Such observations are the foundation of our newly proposed Non-Universal Deepfake Distribution Hypothesis.\n\\textbf{Code will be released upon acceptance.}', 'abstract_zh': '快速发展的深度伪造生成技术对检测系统提出了关键挑战，非连续学习方法需要频繁且昂贵的重新训练。我们将深度伪造检测（DFD）重新框架为连续学习（CL）问题，提出了一种高效的框架，该框架能够逐步适应新兴的视觉篡改技术，同时保留以往生成器的知识。与依赖于 unreal 仿真序列的方法不同，我们的框架模拟了跨7年的长时间内深度伪造技术在现实世界中的演变过程。同时，我们的框架基于轻量级视觉骨干网络，使得深度伪造检测系统能够实时运行。此外，我们还贡献了两个新的度量标准：历史性能的 Continual AUC（C-AUC）和未来泛化的 Forward Transfer AUC（FWT-AUC）。通过广泛的实验（超过600次模拟），我们实证展示了高效的适应（比完全重新训练快近155倍）和历史知识的稳健保留是可能的，但当前方法在没有额外训练的情况下对未来的生成器进行泛化的性能仍然接近随机（FWT-AUC ≈ 0.5），这归因于每个现有生成器的独特特征。这些观察构成了我们新提出的非通用深度伪造分布假设的基础。\n\nCode will be released upon acceptance。', 'title_zh': '重新审视深度假信息检测：时间序列连续学习与泛化能力的局限性'}
{'arxiv_id': 'arXiv:2509.07991', 'title': 'DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm', 'authors': 'Jingyuan Wang, Junhua Li', 'link': 'https://arxiv.org/abs/2509.07991', 'abstract': 'Deep learning models have been frequently used to decode a single brain-computer interface (BCI) paradigm based on electroencephalography (EEG). It is challenging to decode multiple BCI paradigms using one model due to diverse barriers, such as different channel configurations and disparate task-related representations. In this study, we propose Dual Local-Global Encoder (DLGE), enabling the classification across different BCI paradigms. To address the heterogeneity in EEG channel configurations across paradigms, we employ an anatomically inspired brain-region partitioning and padding strategy to standardize EEG channel configuration. In the proposed model, the local encoder is designed to learn shared features across BCI paradigms within each brain region based on time-frequency information, which integrates temporal attention on individual channels with spatial attention among channels for each brain region. These shared features are subsequently aggregated in the global encoder to form respective paradigm-specific feature representations. Three BCI paradigms (motor imagery, resting state, and driving fatigue) were used to evaluate the proposed model. The results demonstrate that our model is capable of processing diverse BCI paradigms without retraining and retuning, achieving average macro precision, recall, and F1-score of 60.16\\%, 59.88\\%, and 59.56\\%, respectively. We made an initial attempt to develop a general model for cross-BCI-paradigm classification, avoiding retraining or redevelopment for each paradigm. This study paves the way for the development of an effective but simple model for cross-BCI-paradigm decoding, which might benefit the design of portable devices for universal BCI decoding.', 'abstract_zh': '深度学习模型常被用于基于脑电图(EEG)的单个脑机接口(BCI)范式的解码。由于存在多种障碍，如不同的通道配置和不同的任务相关表示，使用一个模型来解码多个BCI范式极具挑战性。在本研究中，我们提出了一种双局部-全局编码器(DLGE)，使其能够跨多个BCI范式进行分类。为解决不同BCI范式间的EEG通道配置异质性，我们采用了解剖学启发的脑区分区和填充策略来标准化EEG通道配置。在所提出模型中，局部编码器设计用于基于时频信息在每个脑区内部的BCI范式中学习共享特征，并结合单个通道的时间注意力和脑区内通道之间的空间注意力。这些共享特征随后在全局编码器中汇总，形成特定范式的特征表示。我们使用三种BCI范式（运动想象、静息态和驾驶疲劳）对所提出模型进行了评估。结果表明，我们的模型能够在无需重新训练或调优的情况下处理多样化的BCI范式，平均宏精度、召回率和F1分数分别为60.16%，59.88%和59.56%。我们初步尝试开发一种适用于跨BCI范式分类的一般模型，避免每个范式重新训练或重新开发，并为跨BCI范式解码的有效但简单的模型的发展铺平了道路，可能有利于通用BCI解码的便携设备的设计。', 'title_zh': 'DLGE: 双重局部-全局编码以实现跨BCI范式的泛化能力'}
