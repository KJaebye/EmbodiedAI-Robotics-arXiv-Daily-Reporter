{'arxiv_id': 'arXiv:2506.13762', 'title': 'Touch begins where vision ends: Generalizable policies for contact-rich manipulation', 'authors': 'Zifan Zhao, Siddhant Haldar, Jinda Cui, Lerrel Pinto, Raunaq Bhirangi', 'link': 'https://arxiv.org/abs/2506.13762', 'abstract': "Data-driven approaches struggle with precise manipulation; imitation learning requires many hard-to-obtain demonstrations, while reinforcement learning yields brittle, non-generalizable policies. We introduce VisuoTactile Local (ViTaL) policy learning, a framework that solves fine-grained manipulation tasks by decomposing them into two phases: a reaching phase, where a vision-language model (VLM) enables scene-level reasoning to localize the object of interest, and a local interaction phase, where a reusable, scene-agnostic ViTaL policy performs contact-rich manipulation using egocentric vision and tactile sensing. This approach is motivated by the observation that while scene context varies, the low-level interaction remains consistent across task instances. By training local policies once in a canonical setting, they can generalize via a localize-then-execute strategy. ViTaL achieves around 90% success on contact-rich tasks in unseen environments and is robust to distractors. ViTaL's effectiveness stems from three key insights: (1) foundation models for segmentation enable training robust visual encoders via behavior cloning; (2) these encoders improve the generalizability of policies learned using residual RL; and (3) tactile sensing significantly boosts performance in contact-rich tasks. Ablation studies validate each of these insights, and we demonstrate that ViTaL integrates well with high-level VLMs, enabling robust, reusable low-level skills. Results and videos are available at this https URL.", 'abstract_zh': '基于视觉-触觉局部策略学习：细粒度操作任务的两阶段方法', 'title_zh': '触觉始于视觉终结：接触丰富的操作通用策略'}
{'arxiv_id': 'arXiv:2506.13761', 'title': 'Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins', 'authors': 'Chuanruo Ning, Kuan Fang, Wei-Chiu Ma', 'link': 'https://arxiv.org/abs/2506.13761', 'abstract': 'Recent advancements in open-world robot manipulation have been largely driven by vision-language models (VLMs). While these models exhibit strong generalization ability in high-level planning, they struggle to predict low-level robot controls due to limited physical-world understanding. To address this issue, we propose a model predictive control framework for open-world manipulation that combines the semantic reasoning capabilities of VLMs with physically-grounded, interactive digital twins of the real-world environments. By constructing and simulating the digital twins, our approach generates feasible motion trajectories, simulates corresponding outcomes, and prompts the VLM with future observations to evaluate and select the most suitable outcome based on language instructions of the task. To further enhance the capability of pre-trained VLMs in understanding complex scenes for robotic control, we leverage the flexible rendering capabilities of the digital twin to synthesize the scene at various novel, unoccluded viewpoints. We validate our approach on a diverse set of complex manipulation tasks, demonstrating superior performance compared to baseline methods for language-conditioned robotic control using VLMs.', 'abstract_zh': '开放世界机器人操作中的 recent 进展主要得益于视觉语言模型（VLMs）。为了克服这些模型在低级机器人控制方面因物理世界理解有限而表现出的不足，我们提出了一种结合 VLMs 的语义推理能力和基于物理的交互数字孪生的开放世界操控模型预测控制框架。通过构建和模拟数字孪生，我们的方法生成可行的运动轨迹，模拟相应的结果，并通过任务的语言指令提示 VLMs 来评估和选择最合适的结局。为了进一步增强预训练 VLMs 在理解复杂场景以进行机器人控制的能力，我们利用数字孪生的灵活渲染能力合成各种新颖、无遮挡视角的场景。我们在一系列复杂操控任务上验证了该方法，展示了在基于 VLMs 的语言条件robots控制方面相较于基线方法的优越性能。', 'title_zh': '面向未来的Prompting：具有互动数字孪生的开放世界模型预测控制'}
{'arxiv_id': 'arXiv:2506.13751', 'title': 'LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction', 'authors': 'Haoru Xue, Xiaoyu Huang, Dantong Niu, Qiayuan Liao, Thomas Kragerud, Jan Tommy Gravdahl, Xue Bin Peng, Guanya Shi, Trevor Darrell, Koushil Screenath, Shankar Sastry', 'link': 'https://arxiv.org/abs/2506.13751', 'abstract': 'Vision-language-action (VLA) models have demonstrated strong semantic understanding and zero-shot generalization, yet most existing systems assume an accurate low-level controller with hand-crafted action "vocabulary" such as end-effector pose or root velocity. This assumption confines prior work to quasi-static tasks and precludes the agile, whole-body behaviors required by humanoid whole-body control (WBC) tasks. To capture this gap in the literature, we start by introducing the first sim-to-real-ready, vision-language, closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10 categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot Behavior, a hierarchical latent instruction-following framework for humanoid vision-language WBC, the first of its kind. At the top level, a vision-language policy learns a latent action vocabulary from synthetically rendered kinematic demonstrations; at the low level, a reinforcement-learned WBC policy consumes these latent verbs to generate dynamics-level commands. In our benchmark, LeVERB can zero-shot attain a 80% success rate on simple visual navigation tasks, and 58.5% success rate overall, outperforming naive hierarchical whole-body VLA implementation by 7.8 times.', 'abstract_zh': 'Vision-语言-动作（VLA）模型展示了强大的语义理解和零样本泛化能力，但现有系统大多假设一个精确的低级控制器，并且使用手工构建的动作“词汇表”，如末端执行器姿态或根速度。这种假设限制了先前的工作仅适用于准静态任务，并排除了类人全身控制（WBC）任务所需的敏捷的全身行为。为了填补文献中的这一缺口，我们首先引入了一个首个适应于类人WBC的仿真实验室至现实场景、视-语言闭环基准，包含超过150个来自10个类别的任务。随后，我们提出LeVERB：潜在于语言-视-觉编码的机器人行为，一个分层的潜在线性指令跟随框架，用于类人视-语言WBC，这是此类方法的先驱。在顶层，一个视-语言策略从合成渲染的动力学演示中学习潜在的动作词汇；在底层，一个强化学习的WBC策略消耗这些潜在的动词以生成动力学层的指令。在我们的基准中，LeVERB能够在简单的视觉导航任务上零样本达到80%的成功率，并且总体成功率为58.5%，比简单的分层全身VLA实现高出7.8倍。', 'title_zh': 'LeVERB: 具潜变量视觉-语言指令的类人全身控制'}
{'arxiv_id': 'arXiv:2506.13679', 'title': 'ROSA: Harnessing Robot States for Vision-Language and Action Alignment', 'authors': 'Yuqing Wen, Kefan Gu, Haoxuan Liu, Yucheng Zhao, Tiancai Wang, Haoqiang Fan, Xiaoyan Sun', 'link': 'https://arxiv.org/abs/2506.13679', 'abstract': 'Vision-Language-Action (VLA) models have recently made significant advance in multi-task, end-to-end robotic control, due to the strong generalization capabilities of Vision-Language Models (VLMs). A fundamental challenge in developing such models is effectively aligning the vision-language space with the robotic action space. Existing approaches typically rely on directly fine-tuning VLMs using expert demonstrations. However, this strategy suffers from a spatio-temporal gap, resulting in considerable data inefficiency and heavy reliance on human labor. Spatially, VLMs operate within a high-level semantic space, whereas robotic actions are grounded in low-level 3D physical space; temporally, VLMs primarily interpret the present, while VLA models anticipate future actions. To overcome these challenges, we propose a novel training paradigm, ROSA, which leverages robot state estimation to improve alignment between vision-language and action spaces. By integrating robot state estimation data obtained via an automated process, ROSA enables the VLA model to gain enhanced spatial understanding and self-awareness, thereby boosting performance and generalization. Extensive experiments in both simulated and real-world environments demonstrate the effectiveness of ROSA, particularly in low-data regimes.', 'abstract_zh': '基于机器人状态估计的视觉-语言-动作模型训练 paradigm (ROSA)', 'title_zh': 'ROSA: 利用机器人状态实现视觉-语言和动作对齐'}
{'arxiv_id': 'arXiv:2506.13640', 'title': 'Towards Efficient Occupancy Mapping via Gaussian Process Latent Field Shaping', 'authors': 'Cedric Le Gentil, Cedric Pradalier, Timothy D. Barfoot', 'link': 'https://arxiv.org/abs/2506.13640', 'abstract': "Occupancy mapping has been a key enabler of mobile robotics. Originally based on a discrete grid representation, occupancy mapping has evolved towards continuous representations that can predict the occupancy status at any location and account for occupancy correlations between neighbouring areas. Gaussian Process (GP) approaches treat this task as a binary classification problem using both observations of occupied and free space. Conceptually, a GP latent field is passed through a logistic function to obtain the output class without actually manipulating the GP latent field. In this work, we propose to act directly on the latent function to efficiently integrate free space information as a prior based on the shape of the sensor's field-of-view. A major difference with existing methods is the change in the classification problem, as we distinguish between free and unknown space. The `occupied' area is the infinitesimally thin location where the class transitions from free to unknown. We demonstrate in simulated environments that our approach is sound and leads to competitive reconstruction accuracy.", 'abstract_zh': "occupancy 状态映射是移动机器人技术的关键推动因素。最初基于离散栅格表示，occupancy 状态映射已发展为可以预测任何位置的occupancy状态并考虑相邻区域occupancy相关性的连续表示。高斯过程（GP）方法将此任务视为二分类问题，利用占用空间和空闲空间的观测数据。概念上，通过逻辑函数处理GP潜在场以获得输出类别，而不实际操作GP潜在场。在本工作中，我们提出直接作用于潜在函数，利用传感器视场形状有效地整合空闲空间信息作为先验。与现有方法的主要区别在于分类问题的变化，因为我们将空闲空间与未知空间区分开来。'占用'区域是类别从空闲过渡到未知的无穷小位置。我们在模拟环境中展示了我们方法的有效性和竞争力的重建精度。", 'title_zh': '基于高斯过程潜在场塑形的高效占用映射'}
{'arxiv_id': 'arXiv:2506.13498', 'title': 'A Survey on Imitation Learning for Contact-Rich Tasks in Robotics', 'authors': 'Toshiaki Tsuji, Yasuhiro Kato, Gokhan Solak, Heng Zhang, Tadej Petrič, Francesco Nori, Arash Ajoudani', 'link': 'https://arxiv.org/abs/2506.13498', 'abstract': 'This paper comprehensively surveys research trends in imitation learning for contact-rich robotic tasks. Contact-rich tasks, which require complex physical interactions with the environment, represent a central challenge in robotics due to their nonlinear dynamics and sensitivity to small positional deviations. The paper examines demonstration collection methodologies, including teaching methods and sensory modalities crucial for capturing subtle interaction dynamics. We then analyze imitation learning approaches, highlighting their applications to contact-rich manipulation. Recent advances in multimodal learning and foundation models have significantly enhanced performance in complex contact tasks across industrial, household, and healthcare domains. Through systematic organization of current research and identification of challenges, this survey provides a foundation for future advancements in contact-rich robotic manipulation.', 'abstract_zh': '本文全面综述了模仿学习在接触丰富型机器人任务中的研究趋势。接触丰富型任务由于其非线性动力学特性和对小位置偏差的高度敏感性，要求与环境进行复杂的物理交互，构成了机器人技术中的核心挑战。本文考察了演示收集方法，包括教学方法和用于捕捉微妙交互动力学的关键感官模态。我们随后分析了模仿学习方法，突出了其在接触丰富型操作中的应用。近年来，多模态学习和基础模型的进展显著提升了工业、家庭和医疗保健领域复杂接触任务的性能。通过对当前研究的系统组织和挑战的识别，本文提供了一个推动接触丰富型机器人操作未来发展的基础。', 'title_zh': '机器人领域接触密集型任务的imitation learning综述'}
{'arxiv_id': 'arXiv:2506.13478', 'title': 'Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework', 'authors': 'Hemjyoti Das, Minh Nhat Vu, Christian Ott', 'link': 'https://arxiv.org/abs/2506.13478', 'abstract': 'In this work, we present a novel approach to augment a model-based control method with a reinforcement learning (RL) agent and demonstrate a swing-up maneuver with a suspended aerial manipulation platform. These platforms are targeted towards a wide range of applications on construction sites involving cranes, with swing-up maneuvers allowing it to perch at a given location, inaccessible with purely the thrust force of the platform. Our proposed approach is based on a hierarchical control framework, which allows different tasks to be executed according to their assigned priorities. An RL agent is then subsequently utilized to adjust the reference set-point of the lower-priority tasks to perform the swing-up maneuver, which is confined in the nullspace of the higher-priority tasks, such as maintaining a specific orientation and position of the end-effector. Our approach is validated using extensive numerical simulation studies.', 'abstract_zh': '基于强化学习的模型驱动控制方法在悬停空中操作平台 perch 操作中的应用研究', 'title_zh': '基于层次控制框架的悬空操作平台摆动起立动作学习'}
{'arxiv_id': 'arXiv:2506.13453', 'title': 'Towards a Formal Specification for Self-organized Shape Formation in Swarm Robotics', 'authors': 'YR Darr, MA Niazi', 'link': 'https://arxiv.org/abs/2506.13453', 'abstract': 'The self-organization of robots for the formation of structures and shapes is a stimulating application of the swarm robotic system. It involves a large number of autonomous robots of heterogeneous behavior, coordination among them, and their interaction with the dynamic environment. This process of complex structure formation is considered a complex system, which needs to be modeled by using any modeling approach. Although the formal specification approach along with other formal methods has been used to model the behavior of robots in a swarm. However, to the best of our knowledge, the formal specification approach has not been used to model the self-organization process in swarm robotic systems for shape formation. In this paper, we use a formal specification approach to model the shape formation task of swarm robots. We use Z (Zed) language of formal specification, which is a state-based language, to model the states of the entities of the systems. We demonstrate the effectiveness of Z for the self-organized shape formation. The presented formal specification model gives the outlines for designing and implementing the swarm robotic system for the formation of complex shapes and structures. It also provides the foundation for modeling the complex shape formation process for swarm robotics using a multi-agent system in a simulation-based environment. Keywords: Swarm robotics, Self-organization, Formal specification, Complex systems', 'abstract_zh': '机器人自组织形成结构和形状是一种激动人心的群机器人系统应用。它涉及大量异质行为的自主机器人、它们之间的协调以及与动态环境的交互。这一复杂结构形成过程被视为一个复杂的系统，需要采用任何建模方法进行建模。尽管形式化规范方法及其他形式化方法已被用于建模群机器人行为，但据我们所知，形式化规范方法尚未被用于建模群机器人系统中形状形成过程的自组织过程。在本文中，我们使用形式化规范方法来建模群机器人的形状形成任务。我们采用状态基语言Z语言来建模系统实体的状态。本文展示了Z语言在自组织形状形成中的有效性。提出的正式规范模型为设计和实现用于形成复杂形状和结构的群机器人系统提供了指南。它还为基于多代理系统的模拟环境建模复杂的形状形成过程提供了基础。关键词：群机器人，自组织，形式化规范，复杂系统', 'title_zh': '面向自组织形状形成形式化规范的研究'}
{'arxiv_id': 'arXiv:2506.13432', 'title': 'Adaptive Model-Base Control of Quadrupeds via Online System Identification using Kalman Filter', 'authors': 'Jonas Haack, Franek Stark, Shubham Vyas, Frank Kirchner, Shivesh Kumar', 'link': 'https://arxiv.org/abs/2506.13432', 'abstract': 'Many real-world applications require legged robots to be able to carry variable payloads. Model-based controllers such as model predictive control (MPC) have become the de facto standard in research for controlling these systems. However, most model-based control architectures use fixed plant models, which limits their applicability to different tasks. In this paper, we present a Kalman filter (KF) formulation for online identification of the mass and center of mass (COM) of a four-legged robot. We evaluate our method on a quadrupedal robot carrying various payloads and find that it is more robust to strong measurement noise than classical recursive least squares (RLS) methods. Moreover, it improves the tracking performance of the model-based controller with varying payloads when the model parameters are adjusted at runtime.', 'abstract_zh': '基于卡尔曼滤波的四足机器人载重在线辨识方法及其应用', 'title_zh': '基于卡尔曼滤波的在线系统识别的四足动物自适应模型ベース控制'}
{'arxiv_id': 'arXiv:2506.13428', 'title': 'VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation', 'authors': 'Jiaming Chen, Yiyu Jiang, Aoshen Huang, Yang Li, Wei Pan', 'link': 'https://arxiv.org/abs/2506.13428', 'abstract': 'Dual-arm cooperative manipulation holds great promise for tackling complex real-world tasks that demand seamless coordination and adaptive dynamics. Despite substantial progress in learning-based motion planning, most approaches struggle to generalize across diverse manipulation tasks and adapt to dynamic, unstructured environments, particularly in scenarios involving interactions between two objects such as assembly, tool use, and bimanual grasping. To address these challenges, we introduce a novel VLM-Assisted Siamese Flow Diffusion (VLM-SFD) framework for efficient imitation learning in dual-arm cooperative manipulation. The proposed VLM-SFD framework exhibits outstanding adaptability, significantly enhancing the ability to rapidly adapt and generalize to diverse real-world tasks from only a minimal number of human demonstrations. Specifically, we propose a Siamese Flow Diffusion Network (SFDNet) employs a dual-encoder-decoder Siamese architecture to embed two target objects into a shared latent space, while a diffusion-based conditioning process-conditioned by task instructions-generates two-stream object-centric motion flows that guide dual-arm coordination. We further design a dynamic task assignment strategy that seamlessly maps the predicted 2D motion flows into 3D space and incorporates a pre-trained vision-language model (VLM) to adaptively assign the optimal motion to each robotic arm over time. Experiments validate the effectiveness of the proposed method, demonstrating its ability to generalize to diverse manipulation tasks while maintaining high efficiency and adaptability. The code and demo videos are publicly available on our project website this https URL.', 'abstract_zh': '基于VLM辅助的Siamese流扩散框架在双臂协同操作中的高效模仿学习', 'title_zh': 'VLM-SFD：基于VLM的双臂协同 manipulation Siamese 流扩散框架'}
{'arxiv_id': 'arXiv:2506.13367', 'title': 'Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation', 'authors': 'Utkarsh Bajpai, Julius Rückin, Cyrill Stachniss, Marija Popović', 'link': 'https://arxiv.org/abs/2506.13367', 'abstract': 'Mobile robots exploring indoor environments increasingly rely on vision-language models to perceive high-level semantic cues in camera images, such as object categories. Such models offer the potential to substantially advance robot behaviour for tasks such as object-goal navigation (ObjectNav), where the robot must locate objects specified in natural language by exploring the environment. Current ObjectNav methods heavily depend on prompt engineering for perception and do not address the semantic uncertainty induced by variations in prompt phrasing. Ignoring semantic uncertainty can lead to suboptimal exploration, which in turn limits performance. Hence, we propose a semantic uncertainty-informed active perception pipeline for ObjectNav in indoor environments. We introduce a novel probabilistic sensor model for quantifying semantic uncertainty in vision-language models and incorporate it into a probabilistic geometric-semantic map to enhance spatial understanding. Based on this map, we develop a frontier exploration planner with an uncertainty-informed multi-armed bandit objective to guide efficient object search. Experimental results demonstrate that our method achieves ObjectNav success rates comparable to those of state-of-the-art approaches, without requiring extensive prompt engineering.', 'abstract_zh': '室内环境探索的移动机器人 increasingly relies on 视觉-语言模型来感知相机图像中的高阶语义线索，如物体类别。此类模型为物体目标导航（ObjectNav）任务中的机器人行为提供了潜在的显著进步，其中机器人必须通过探索环境来定位用自然语言指定的物体。当前的 ObjectNav 方法高度依赖于感知方面的提示工程，并未解决由提示措辞变化引起的语义不确定性问题。忽略语义不确定性可能导致次优探索，从而限制了性能。因此，我们提出了一种基于语义不确定性主动感知的室内环境物体目标导航管道。我们引入了一种新颖的概率传感器模型，用于量化视觉-语言模型中的语义不确定性，并将其集成到概率几何语义地图中以增强空间理解。基于此地图，我们开发了一种具有不确定性指导的多臂bandit目标的前沿探索计划器，以指导高效的物体搜索。实验结果表明，我们的方法在不需要大量提示工程的情况下，实现了与现有最佳方法相当的物体目标导航成功率。', 'title_zh': '基于不确定性指导的开放词汇目标导航主动感知'}
{'arxiv_id': 'arXiv:2506.13149', 'title': 'Cognitive Synergy Architecture: SEGO for Human-Centric Collaborative Robots', 'authors': 'Jaehong Oh', 'link': 'https://arxiv.org/abs/2506.13149', 'abstract': 'This paper presents SEGO (Semantic Graph Ontology), a cognitive mapping architecture designed to integrate geometric perception, semantic reasoning, and explanation generation into a unified framework for human-centric collaborative robotics. SEGO constructs dynamic cognitive scene graphs that represent not only the spatial configuration of the environment but also the semantic relations and ontological consistency among detected objects. The architecture seamlessly combines SLAM-based localization, deep-learning-based object detection and tracking, and ontology-driven reasoning to enable real-time, semantically coherent mapping.', 'abstract_zh': '基于语义图本体的认知映射架构：面向人类中心的协作机器人几何感知、语义推理与解释生成统一框架', 'title_zh': '认知协同架构：SEGO为人机协同机器人服务'}
{'arxiv_id': 'arXiv:2506.13100', 'title': 'A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method', 'authors': 'Zhanhua Xin, Zhihao Wang, Shenghao Zhang, Wanchao Chi, Yan Meng, Shihan Kong, Yan Xiong, Chong Zhang, Yuzhen Liu, Junzhi Yu', 'link': 'https://arxiv.org/abs/2506.13100', 'abstract': "In the field of multi-sensor fusion for simultaneous localization and mapping (SLAM), monocular cameras and IMUs are widely used to build simple and effective visual-inertial systems. However, limited research has explored the integration of motor-encoder devices to enhance SLAM performance. By incorporating such devices, it is possible to significantly improve active capability and field of view (FOV) with minimal additional cost and structural complexity. This paper proposes a novel visual-inertial-encoder tightly coupled odometry (VIEO) based on a ViDAR (Video Detection and Ranging) device. A ViDAR calibration method is introduced to ensure accurate initialization for VIEO. In addition, a platform motion decoupled active SLAM method based on deep reinforcement learning (DRL) is proposed. Experimental data demonstrate that the proposed ViDAR and the VIEO algorithm significantly increase cross-frame co-visibility relationships compared to its corresponding visual-inertial odometry (VIO) algorithm, improving state estimation accuracy. Additionally, the DRL-based active SLAM algorithm, with the ability to decouple from platform motion, can increase the diversity weight of the feature points and further enhance the VIEO algorithm's performance. The proposed methodology sheds fresh insights into both the updated platform design and decoupled approach of active SLAM systems in complex environments.", 'abstract_zh': '多传感器融合领域中单相机和IMU在同时定位与建图（SLAM）中的应用及其与电机编码器的集成研究：基于ViDAR的紧耦合视觉-惯性-编码器里程计及其在主动SLAM中的应用', 'title_zh': '一种结合视觉惯性编码 odometry 和基于强化学习的主动 SLAM 方法的新颖 ViDAR 设备'}
{'arxiv_id': 'arXiv:2506.13079', 'title': 'CHARM: Considering Human Attributes for Reinforcement Modeling', 'authors': 'Qidi Fang, Hang Yu, Shijie Fang, Jindan Huang, Qiuyu Chen, Reuben M. Aronson, Elaine S. Short', 'link': 'https://arxiv.org/abs/2506.13079', 'abstract': "Reinforcement Learning from Human Feedback has recently achieved significant success in various fields, and its performance is highly related to feedback quality. While much prior work acknowledged that human teachers' characteristics would affect human feedback patterns, there is little work that has closely investigated the actual effects. In this work, we designed an exploratory study investigating how human feedback patterns are associated with human characteristics. We conducted a public space study with two long horizon tasks and 46 participants. We found that feedback patterns are not only correlated with task statistics, such as rewards, but also correlated with participants' characteristics, especially robot experience and educational background. Additionally, we demonstrated that human feedback value can be more accurately predicted with human characteristics compared to only using task statistics. All human feedback and characteristics we collected, and codes for our data collection and predicting more accurate human feedback are available at this https URL", 'abstract_zh': '从人类反馈中学习的强化学习近年来在各个领域取得了显著成功，其性能高度依赖于反馈质量。尽管先前研究认识到人类教师的特质会影响反馈模式，但鲜有研究深入探讨其实际影响。在本工作中，我们设计了一项探索性研究，调查人类反馈模式与人类特质之间的关联。我们通过一项包含两个长期任务的公共场所研究，共招募了46名参与者。我们发现，反馈模式不仅与任务统计数据（如奖励）相关，还与参与者的特质密切相关，尤其是机器人经验与教育背景。此外，我们证明了与仅使用任务统计数据相比，人类特质可以更准确地预测人类反馈的价值。所有收集的人类反馈和特质数据，以及我们用于数据收集和更准确预测人类反馈的代码，均可通过以下链接访问：this https URL。', 'title_zh': 'CHARM: 考虑人类属性的强化学习模型'}
{'arxiv_id': 'arXiv:2506.12851', 'title': 'KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills', 'authors': 'Weiji Xie, Jinrui Han, Jiakun Zheng, Huanyu Li, Xinzhe Liu, Jiyuan Shi, Weinan Zhang, Chenjia Bai, Xuelong Li', 'link': 'https://arxiv.org/abs/2506.12851', 'abstract': 'Humanoid robots are promising to acquire various skills by imitating human behaviors. However, existing algorithms are only capable of tracking smooth, low-speed human motions, even with delicate reward and curriculum design. This paper presents a physics-based humanoid control framework, aiming to master highly-dynamic human behaviors such as Kungfu and dancing through multi-steps motion processing and adaptive motion tracking. For motion processing, we design a pipeline to extract, filter out, correct, and retarget motions, while ensuring compliance with physical constraints to the maximum extent. For motion imitation, we formulate a bi-level optimization problem to dynamically adjust the tracking accuracy tolerance based on the current tracking error, creating an adaptive curriculum mechanism. We further construct an asymmetric actor-critic framework for policy training. In experiments, we train whole-body control policies to imitate a set of highly-dynamic motions. Our method achieves significantly lower tracking errors than existing approaches and is successfully deployed on the Unitree G1 robot, demonstrating stable and expressive behaviors. The project page is this https URL.', 'abstract_zh': '仿人机器人有望通过模仿人类行为来获得各种技能。然而，现有算法仅能跟踪平滑的低速人类动作，即使借助精细的奖励和课程设计。本文提出了一种基于物理的仿人控制框架，旨在通过多步动作处理和自适应动作跟踪掌握高度动态的人类行为，如功夫和舞蹈。在动作处理方面，我们设计了一条管线来提取、过滤、修正和目标化动作，同时确保最大程度遵守物理约束。在动作模仿方面，我们构建了一个双层优化问题来动态调整跟踪准确性容差，基于当前跟踪误差创造了一个自适应课程机制。此外，我们构建了一个不对称的演员-评论家框架用于策略训练。在实验中，我们训练了全身控制策略来模仿一系列高度动态的动作。我们的方法在跟踪误差方面显著优于现有方法，并成功部署在Unitree G1机器人上，展示了稳定而丰富的行为。项目页面：https://your-project-page-url', 'title_zh': 'KungfuBot：基于物理的人形全身控制学习高度动态技能'}
{'arxiv_id': 'arXiv:2506.12779', 'title': 'From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots', 'authors': 'Yuxuan Wang, Ming Yang, Weishuai Zeng, Yu Zhang, Xinrun Xu, Haobin Jiang, Ziluo Ding, Zongqing Lu', 'link': 'https://arxiv.org/abs/2506.12779', 'abstract': 'Achieving general agile whole-body control on humanoid robots remains a major challenge due to diverse motion demands and data conflicts. While existing frameworks excel in training single motion-specific policies, they struggle to generalize across highly varied behaviors due to conflicting control requirements and mismatched data distributions. In this work, we propose BumbleBee (BB), an expert-generalist learning framework that combines motion clustering and sim-to-real adaptation to overcome these challenges. BB first leverages an autoencoder-based clustering method to group behaviorally similar motions using motion features and motion descriptions. Expert policies are then trained within each cluster and refined with real-world data through iterative delta action modeling to bridge the sim-to-real gap. Finally, these experts are distilled into a unified generalist controller that preserves agility and robustness across all motion types. Experiments on two simulations and a real humanoid robot demonstrate that BB achieves state-of-the-art general whole-body control, setting a new benchmark for agile, robust, and generalizable humanoid performance in the real world.', 'abstract_zh': 'BumbleBee：一种结合运动聚类和仿真到现实适应的专家-通才学习框架以实现 humanoid 机器人的一般敏捷全身控制', 'title_zh': '从专家到通才： toward 人类形机器人全身控制的通用方法'}
{'arxiv_id': 'arXiv:2506.12769', 'title': 'RL from Physical Feedback: Aligning Large Motion Models with Humanoid Control', 'authors': 'Junpeng Yue, Zepeng Wang, Yuxuan Wang, Weishuai Zeng, Jiangxing Wang, Xinrun Xu, Yu Zhang, Sipeng Zheng, Ziluo Ding, Zongqing Lu', 'link': 'https://arxiv.org/abs/2506.12769', 'abstract': 'This paper focuses on a critical challenge in robotics: translating text-driven human motions into executable actions for humanoid robots, enabling efficient and cost-effective learning of new behaviors. While existing text-to-motion generation methods achieve semantic alignment between language and motion, they often produce kinematically or physically infeasible motions unsuitable for real-world deployment. To bridge this sim-to-real gap, we propose Reinforcement Learning from Physical Feedback (RLPF), a novel framework that integrates physics-aware motion evaluation with text-conditioned motion generation. RLPF employs a motion tracking policy to assess feasibility in a physics simulator, generating rewards for fine-tuning the motion generator. Furthermore, RLPF introduces an alignment verification module to preserve semantic fidelity to text instructions. This joint optimization ensures both physical plausibility and instruction alignment. Extensive experiments show that RLPF greatly outperforms baseline methods in generating physically feasible motions while maintaining semantic correspondence with text instruction, enabling successful deployment on real humanoid robots.', 'abstract_zh': '本文聚焦于机器人领域的一个关键挑战：将文本驱动的人类动作转化为可执行的动作，使类人机器人能够高效且经济地学习新行为。尽管现有的从文本生成动作的方法在语义上实现了语言与动作的对齐，但它们往往生成出在动力学或物理上不可行的动作，不适合实际部署。为了解决这一从模拟到现实的差距，我们提出了一种新的框架——物理反馈强化学习（RLPF），它将物理感知的动作评估与文本条件下的动作生成相结合。RLPF 使用一个动作追踪策略在物理模拟器中评估动作的可行性，并生成奖励以 fine-tune 动作生成器。此外，RLPF 引入了一个对齐验证模块以保持与文本指令的语义一致性。这种联合优化确保了物理上的合理性和指令的一致性。广泛实验表明，RLPF 在生成物理上可行的动作方面显著优于基线方法，同时保持与文本指令的语义对应关系，从而成功部署在实际类人机器人上。', 'title_zh': '从物理反馈学习RL：将大型运动模型与类人控制对齐'}
{'arxiv_id': 'arXiv:2506.12742', 'title': 'Physics-informed Neural Motion Planning via Domain Decomposition in Large Environments', 'authors': 'Yuchen Liu, Alexiy Buynitsky, Ruiqi Ni, Ahmed H. Qureshi', 'link': 'https://arxiv.org/abs/2506.12742', 'abstract': 'Physics-informed Neural Motion Planners (PiNMPs) provide a data-efficient framework for solving the Eikonal Partial Differential Equation (PDE) and representing the cost-to-go function for motion planning. However, their scalability remains limited by spectral bias and the complex loss landscape of PDE-driven training. Domain decomposition mitigates these issues by dividing the environment into smaller subdomains, but existing methods enforce continuity only at individual spatial points. While effective for function approximation, these methods fail to capture the spatial connectivity required for motion planning, where the cost-to-go function depends on both the start and goal coordinates rather than a single query point. We propose Finite Basis Neural Time Fields (FB-NTFields), a novel neural field representation for scalable cost-to-go estimation. Instead of enforcing continuity in output space, FB-NTFields construct a latent space representation, computing the cost-to-go as a distance between the latent embeddings of start and goal coordinates. This enables global spatial coherence while integrating domain decomposition, ensuring efficient large-scale motion planning. We validate FB-NTFields in complex synthetic and real-world scenarios, demonstrating substantial improvements over existing PiNMPs. Finally, we deploy our method on a Unitree B1 quadruped robot, successfully navigating indoor environments. The supplementary videos can be found at this https URL.', 'abstract_zh': '基于物理的神经运动规划器（PiNMPs）提供了一种高效的框架来求解Eikonal偏微分方程（PDE）并表示运动规划的成本函数。然而，它们的扩展性受限于频谱偏差和由PDE驱动的训练复合损失景观。域分解通过将环境划分为较小的子域来缓解这些问题，但现有方法仅在个别空间点上保证连续性。虽然这些方法在函数逼近方面有效，但它们无法捕捉到运动规划所需的空间连续性，其中成本函数依赖于起点和目标坐标，而不仅仅是单一查询点。我们提出了一种新的基于有限基的神经时间场（FB-NTFields）来进行可扩展的成本函数估计。与在输出空间中保证连续性不同，FB-NTFields 构建了一个潜空间表示，通过计算起点和目标坐标的潜嵌入之间的距离来计算成本函数。这使得全局空间一致性成为可能，同时结合了域分解，从而确保了大规模运动规划的高效性。我们在复杂的合成和真实场景中验证了FB-NTFields，展示了其相对于现有PiNMPs的显著改进。最后，我们在一个Unitree B1 四足机器人上部署了我们的方法，成功导航了室内环境。补充视频可以在以下链接找到：this https URL。', 'title_zh': '基于域分解的大环境物理知情神经运动规划'}
{'arxiv_id': 'arXiv:2506.12710', 'title': 'Multimodal Large Language Models-Enabled UAV Swarm: Towards Efficient and Intelligent Autonomous Aerial Systems', 'authors': 'Yuqi Ping, Tianhao Liang, Huahao Ding, Guangyu Lei, Junwei Wu, Xuan Zou, Kuan Shi, Rui Shao, Chiya Zhang, Weizheng Zhang, Weijie Yuan, Tingting Zhang', 'link': 'https://arxiv.org/abs/2506.12710', 'abstract': 'Recent breakthroughs in multimodal large language models (MLLMs) have endowed AI systems with unified perception, reasoning and natural-language interaction across text, image and video streams. Meanwhile, Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic, safety-critical missions that demand rapid situational understanding and autonomous adaptation. This paper explores potential solutions for integrating MLLMs with UAV swarms to enhance the intelligence and adaptability across diverse tasks. Specifically, we first outline the fundamental architectures and functions of UAVs and MLLMs. Then, we analyze how MLLMs can enhance the UAV system performance in terms of target detection, autonomous navigation, and multi-agent coordination, while exploring solutions for integrating MLLMs into UAV systems. Next, we propose a practical case study focused on the forest fire fighting. To fully reveal the capabilities of the proposed framework, human-machine interaction, swarm task planning, fire assessment, and task execution are investigated. Finally, we discuss the challenges and future research directions for the MLLMs-enabled UAV swarm. An experiment illustration video could be found online at this https URL.', 'abstract_zh': '最近在多模态大型语言模型方面的突破赋予了AI系统在文本、图像和视频流中统一感知、推理和自然语言交互的能力。与此同时，无人机(UAV)群在未来动态且安全关键的任务中越来越被部署，这些任务要求快速的情境理解和自主适应。本文探讨了将多模态大型语言模型与无人机群集成以增强跨多种任务的智能和适应性的潜在解决方案。具体来说，我们首先概述了无人机和多模态大型语言模型的基本架构和功能。然后，我们分析了多模态大型语言模型如何在目标检测、自主导航和多智能体协调方面提升无人机系统性能，并探讨了将多模态大型语言模型集成到无人机系统中的解决方案。接下来，我们提出了一个以森林火灾扑救为重点的应用案例研究。为了充分展示所提出框架的能力，我们研究了人机交互、集群任务规划、火灾评估和任务执行。最后，我们讨论了由多模态大型语言模型赋能的无人机群面临的挑战和未来研究方向。有关实验示意图视频可以在以下网址在线查看：这个 https URL。', 'title_zh': '基于多模态大型语言模型的无人机 swarm： toward 高效且智能的自主空中系统'}
{'arxiv_id': 'arXiv:2506.12678', 'title': 'Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence', 'authors': 'Pranay Gupta, Henny Admoni, Andrea Bajcsy', 'link': 'https://arxiv.org/abs/2506.12678', 'abstract': 'End-to-end visuomotor policies trained using behavior cloning have shown a remarkable ability to generate complex, multi-modal low-level robot behaviors. However, at deployment time, these policies still struggle to act reliably when faced with out-of-distribution (OOD) visuals induced by objects, backgrounds, or environment changes. Prior works in interactive imitation learning solicit corrective expert demonstrations under the OOD conditions -- but this can be costly and inefficient. We observe that task success under OOD conditions does not always warrant novel robot behaviors. In-distribution (ID) behaviors can directly be transferred to OOD conditions that share functional similarities with ID conditions. For example, behaviors trained to interact with in-distribution (ID) pens can apply to interacting with a visually-OOD pencil. The key challenge lies in disambiguating which ID observations functionally correspond to the OOD observation for the task at hand. We propose that an expert can provide this OOD-to-ID functional correspondence. Thus, instead of collecting new demonstrations and re-training at every OOD encounter, our method: (1) detects the need for feedback by first checking if current observations are OOD and then identifying whether the most similar training observations show divergent behaviors, (2) solicits functional correspondence feedback to disambiguate between those behaviors, and (3) intervenes on the OOD observations with the functionally corresponding ID observations to perform deployment-time generalization. We validate our method across diverse real-world robotic manipulation tasks with a Franka Panda robotic manipulator. Our results show that test-time functional correspondences can improve the generalization of a vision-based diffusion policy to OOD objects and environment conditions with low feedback.', 'abstract_zh': '端到端的视觉-运动策略通过行为克隆训练，展示了生成复杂多模态低级机器人行为的 remarkable 能力。然而，在部署时，这些策略在面对由物体、背景或环境变化引起的 out-of-distribution (OOD) 视觉时，仍然难以可靠地行动。之前在交互式模仿学习中的前期工作在 OOD 条件下寻求专家的纠正演示——但这可能是昂贵且低效的。我们观察到，任务在 OOD 条件下的成功并不总是需要新的机器人行为。与 ID 条件共享功能相似性的 ID 行为可以直接转移到 OOD 条件中。例如，训练用于与 in-distribution (ID) 笔交互的行为可以应用到与之在视觉上 OOD 的铅笔交互上。关键挑战在于，辨别当前 OOD 观察与任务相关的功能相似的 ID 观察。我们提出专家可以提供这种 OOD 到 ID 的功能对应关系。因此，我们的方法不是在每遇到一次 OOD 就收集新的演示和重新训练，而是：(1) 通过首先检查当前观察是否为 OOD，然后确定最相似的训练观察是否表现出不同的行为来检测需要反馈的需求；(2) 请求功能对应反馈以在这些行为之间进行去模糊；(3) 使用功能对应的 ID 观察干预 OOD 观察，以实现部署时的一般化。我们在不同的真实世界机器人操作任务中使用 Franka Panda 机器人操作器验证了我们的方法。我们的结果表明，测试时的功能对应关系可以降低反馈成本，提高基于视觉的扩散策略对 OOD 对象和环境条件的一般化能力。', 'title_zh': '通过类比适应：通过功能对应实现知觉运动策略的OOD泛化'}
{'arxiv_id': 'arXiv:2506.12676', 'title': 'Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks', 'authors': 'Yingyi Kuang, Luis J. Manso, George Vogiatzis', 'link': 'https://arxiv.org/abs/2506.12676', 'abstract': 'Reinforcement learning for multi-goal robot manipulation tasks poses significant challenges due to the diversity and complexity of the goal space. Techniques such as Hindsight Experience Replay (HER) have been introduced to improve learning efficiency for such tasks. More recently, researchers have combined HER with advanced imitation learning methods such as Generative Adversarial Imitation Learning (GAIL) to integrate demonstration data and accelerate training speed. However, demonstration data often fails to provide enough coverage for the goal space, especially when acquired from human teleoperation. This biases the learning-from-demonstration process toward mastering easier sub-tasks instead of tackling the more challenging ones. In this work, we present Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL), a novel framework specifically designed for multi-goal robot manipulation tasks. By integrating self-adaptive learning principles with goal-conditioned GAIL, our approach enhances imitation learning efficiency, even when limited, suboptimal demonstrations are available. Experimental results validate that our method significantly improves learning efficiency across various multi-goal manipulation scenarios -- including complex in-hand manipulation tasks -- using suboptimal demonstrations provided by both simulation and human experts.', 'abstract_zh': '基于目标自适应生成对抗模仿学习（Goal-SAGAIL）方法在多目标机器人操作任务中的应用', 'title_zh': '基于目标的自适应生成对抗模仿学习（Goal-SAGAIL）用于多目标机器人操作任务'}
{'arxiv_id': 'arXiv:2506.12507', 'title': 'Sense and Sensibility: What makes a social robot convincing to high-school students?', 'authors': 'Pablo Gonzalez-Oliveras, Olov Engwall, Ali Reza Majlesi', 'link': 'https://arxiv.org/abs/2506.12507', 'abstract': "This study with 40 high-school students demonstrates the high influence of a social educational robot on students' decision-making for a set of eight true-false questions on electric circuits, for which the theory had been covered in the students' courses. The robot argued for the correct answer on six questions and the wrong on two, and 75% of the students were persuaded by the robot to perform beyond their expected capacity, positively when the robot was correct and negatively when it was wrong. Students with more experience of using large language models were even more likely to be influenced by the robot's stance -- in particular for the two easiest questions on which the robot was wrong -- suggesting that familiarity with AI can increase susceptibility to misinformation by AI.\nWe further examined how three different levels of portrayed robot certainty, displayed using semantics, prosody and facial signals, affected how the students aligned with the robot's answer on specific questions and how convincing they perceived the robot to be on these questions. The students aligned with the robot's answers in 94.4% of the cases when the robot was portrayed as Certain, 82.6% when it was Neutral and 71.4% when it was Uncertain. The alignment was thus high for all conditions, highlighting students' general susceptibility to accept the robot's stance, but alignment in the Uncertain condition was significantly lower than in the Certain. Post-test questionnaire answers further show that students found the robot most convincing when it was portrayed as Certain. These findings highlight the need for educational robots to adjust their display of certainty based on the reliability of the information they convey, to promote students' critical thinking and reduce undue influence.", 'abstract_zh': '这项研究以40名高中生为对象，展示了社会教育机器人对一组关于电路的真假判断问题（学生在课程中已经学习过相关理论）决策过程的高影响力。机器人对六个问题给出了正确的答案，对两个问题给出了错误的答案，并且75%的学生在机器人给出正确答案时提高了自己的表现水平，而在错误答案时则表现较差。具有更多大型语言模型使用经验的学生更容易受到机器人立场的影响——尤其是对于机器人错误的两个最简单的问题，这表明对AI的熟悉程度可能会增加对AI假信息的易感性。我们进一步探究了通过语义、语调和面部信号三种不同水平的机器人确定性表达，对学生在特定问题上对机器人回答的认同程度以及他们认为机器人说辞说服力的影响。当机器人被呈现为确定时，学生有94.4%的案例与机器人的答案一致，中性时有82.6%，不确定时有71.4%。因此，在所有条件下，学生的认同度都很高，但不确定性条件下的认同度明显低于确定性条件。问卷调查进一步表明，当机器人表现得最确定时，学生们觉得它最令人信服。这些发现突显了教育机器人根据所传达信息的可靠性调整其确定性显示的必要性，以促进学生的批判性思维并减少不必要的影响。', 'title_zh': '感性和理性：什么让社交机器人对高中生产生说服力？'}
{'arxiv_id': 'arXiv:2506.12374', 'title': 'AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making', 'authors': 'Wenbo Li, Shiyi Wang, Yiteng Chen, Huiping Zhuang, Qingyao Wu', 'link': 'https://arxiv.org/abs/2506.12374', 'abstract': 'Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for robotic manipulation within high-dimensional representation spaces. However, current approaches often project them into compressed intermediate representations, discarding important task-specific information such as fine-grained spatial or semantic details. To address this, we propose AntiGrounding, a new framework that reverses the instruction grounding process. It lifts candidate actions directly into the VLM representation space, renders trajectories from multiple views, and uses structured visual question answering for instruction-based decision making. This enables zero-shot synthesis of optimal closed-loop robot trajectories for new tasks. We also propose an offline policy refinement module that leverages past experience to enhance long-term performance. Experiments in both simulation and real-world environments show that our method outperforms baselines across diverse robotic manipulation tasks.', 'abstract_zh': 'Vision-Language模型（VLMs）在高维表示空间中编码了机器人操作的知识和推理能力。然而，当前的方法通常将这些模型投影到压缩的中间表示中，丢弃了重要的任务特定信息，如细粒度的空间或语义细节。为了解决这一问题，我们提出了一种新的框架AntiGrounding，该框架逆转了指令锚定过程。它直接将候选操作提升到VLM表示空间，从多视角渲染轨迹，并使用结构化视觉问答进行基于指令的决策。这使得我们的方法能够零样本合成新的任务最优闭环机器人轨迹。我们还提出了一种 Offline 策略细化模块，利用过去的经验来增强长期性能。在模拟和真实环境中的实验表明，我们的方法在各种机器人操作任务中均优于基线方法。', 'title_zh': '抗地基：将机器人动作提升至跨模态学习表示空间中的决策制定'}
{'arxiv_id': 'arXiv:2506.12314', 'title': 'Explosive Output to Enhance Jumping Ability: A Variable Reduction Ratio Design Paradigm for Humanoid Robots Knee Joint', 'authors': 'Xiaoshuai Ma, Haoxiang Qi, Qingqing Li, Haochen Xu, Xuechao Chen, Junyao Gao, Zhangguo Yu, Qiang Huang', 'link': 'https://arxiv.org/abs/2506.12314', 'abstract': 'Enhancing the explosive power output of the knee joints is critical for improving the agility and obstacle-crossing capabilities of humanoid robots. However, a mismatch between the knee-to-center-of-mass (CoM) transmission ratio and jumping demands, coupled with motor performance degradation at high speeds, restricts the duration of high-power output and limits jump performance. To address these problems, this paper introduces a novel knee joint design paradigm employing a dynamically decreasing reduction ratio for explosive output during jump. Analysis of motor output characteristics and knee kinematics during jumping inspired a coupling strategy in which the reduction ratio gradually decreases as the joint extends. A high initial ratio rapidly increases torque at jump initiation, while its gradual reduction minimizes motor speed increments and power losses, thereby maintaining sustained high-power output. A compact and efficient linear actuator-driven guide-rod mechanism realizes this coupling strategy, supported by parameter optimization guided by explosive jump control strategies. Experimental validation demonstrated a 63 cm vertical jump on a single-joint platform (a theoretical improvement of 28.1\\% over the optimal fixed-ratio joints). Integrated into a humanoid robot, the proposed design enabled a 1.1 m long jump, a 0.5 m vertical jump, and a 0.5 m box jump.', 'abstract_zh': '增强膝关节的爆发力输出对于提高类人机器人敏捷性和越障能力至关重要。然而，膝关节到质心的传动比与跳跃需求之间的不匹配，以及高速度下的电机性能下降，限制了高功率输出的持续时间和跳跃性能。为此，本文提出了一种新的膝关节设计范式，在跳跃期间采用动态递减的减速比以提高爆发力输出。电机输出特性和跳跃期间膝关节运动学的分析启发了该耦合策略，即关节延伸时减速比逐渐减小。较高的初始比迅速增加跳跃初期的扭矩，而其逐渐减小最大限度地减少了电机速度增量和功率损失，从而维持了持续的高功率输出。紧凑高效的线性作动器驱动滑杆机制实现了这一耦合策略，并得到了爆炸跳跃控制策略指导下的参数优化的支持。实验验证显示，单关节平台上的垂直跳跃高度提高了63厘米（理论上比最优固定比关节提高了28.1%）。将该设计集成到类人机器人中，实现了1.1米的长跳、0.5米的垂直跳和0.5米的方块跳。', 'title_zh': '爆炸式输出以提升跳跃能力： humanoid 机器人膝关节变减速比设计范式'}
{'arxiv_id': 'arXiv:2506.12312', 'title': 'Perspective on Utilizing Foundation Models for Laboratory Automation in Materials Research', 'authors': 'Kan Hatakeyama-Sato, Toshihiko Nishida, Kenta Kitamura, Yoshitaka Ushiku, Koichi Takahashi, Yuta Nabae, Teruaki Hayakawa', 'link': 'https://arxiv.org/abs/2506.12312', 'abstract': 'This review explores the potential of foundation models to advance laboratory automation in the materials and chemical sciences. It emphasizes the dual roles of these models: cognitive functions for experimental planning and data analysis, and physical functions for hardware operations. While traditional laboratory automation has relied heavily on specialized, rigid systems, foundation models offer adaptability through their general-purpose intelligence and multimodal capabilities. Recent advancements have demonstrated the feasibility of using large language models (LLMs) and multimodal robotic systems to handle complex and dynamic laboratory tasks. However, significant challenges remain, including precision manipulation of hardware, integration of multimodal data, and ensuring operational safety. This paper outlines a roadmap highlighting future directions, advocating for close interdisciplinary collaboration, benchmark establishment, and strategic human-AI integration to realize fully autonomous experimental laboratories.', 'abstract_zh': '基础模型在材料与化学科学领域实验室自动化中的潜力及其展望：跨学科合作、基准建立及人机协同的战略方向', 'title_zh': '利用基础模型推动材料研究领域的实验室自动化 Perspective on Utilizing Foundation Models for Laboratory Automation in Materials Research'}
{'arxiv_id': 'arXiv:2506.12248', 'title': 'ProVox: Personalization and Proactive Planning for Situated Human-Robot Collaboration', 'authors': 'Jennifer Grannen, Siddharth Karamcheti, Blake Wulfe, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2506.12248', 'abstract': 'Collaborative robots must quickly adapt to their partner\'s intent and preferences to proactively identify helpful actions. This is especially true in situated settings where human partners can continually teach robots new high-level behaviors, visual concepts, and physical skills (e.g., through demonstration), growing the robot\'s capabilities as the human-robot pair work together to accomplish diverse tasks. In this work, we argue that robots should be able to infer their partner\'s goals from early interactions and use this information to proactively plan behaviors ahead of explicit instructions from the user. Building from the strong commonsense priors and steerability of large language models, we introduce ProVox ("Proactive Voice"), a novel framework that enables robots to efficiently personalize and adapt to individual collaborators. We design a meta-prompting protocol that empowers users to communicate their distinct preferences, intent, and expected robot behaviors ahead of starting a physical interaction. ProVox then uses the personalized prompt to condition a proactive language model task planner that anticipates a user\'s intent from the current interaction context and robot capabilities to suggest helpful actions; in doing so, we alleviate user burden, minimizing the amount of time partners spend explicitly instructing and supervising the robot. We evaluate ProVox through user studies grounded in household manipulation tasks (e.g., assembling lunch bags) that measure the efficiency of the collaboration, as well as features such as perceived helpfulness, ease of use, and reliability. Our analysis suggests that both meta-prompting and proactivity are critical, resulting in 38.7% faster task completion times and 31.9% less user burden relative to non-active baselines. Supplementary material, code, and videos can be found at this https URL.', 'abstract_zh': '协作机器人必须迅速适应合作伙伴的意图和偏好，主动识别有益的动作。特别是在人类合作伙伴可以持续向机器人传授新的高级行为、视觉概念和物理技能（例如，通过示范）的情境中，这一点尤为重要，随着人机团队共同完成多样化任务，机器人的能力逐渐增强。在本研究中，我们主张机器人应能够从早期互动中推断出合作伙伴的目标，并利用这些信息在用户明确指示之前主动规划行为。基于大型语言模型的强大先验知识和可控性，我们引入了ProVox（“前瞻声音”），这是一种新型框架，使机器人能够有效地个性化并适应不同的合作者。我们设计了一种元提示协议，使用户能够在开始物理交互之前传达各自的偏好、意图和期望的机器人行为。ProVox 然后使用个性化的提示来条件化一个前瞻性的语言模型任务规划器，该规划器根据当前交互上下文和机器人能力预测用户意图以建议有益的动作；从而减轻用户负担，减少合作伙伴明确指导和监督机器人的时间。我们通过基于家庭操作任务（如组装午餐包）的用户研究来评估 ProVox，衡量协作效率以及诸如感知有效性、易用性和可靠性等特征。我们的分析表明，元提示和前瞻性都是至关重要的，相对非主动基线，任务完成时间加快了38.7%，用户负担减少了31.9%。更多信息、代码和视频请访问此链接。', 'title_zh': 'ProVox: 基于情境的个性化与主动规划的人机协作'}
{'arxiv_id': 'arXiv:2506.12239', 'title': 'ViTaSCOPE: Visuo-tactile Implicit Representation for In-hand Pose and Extrinsic Contact Estimation', 'authors': 'Jayjun Lee, Nima Fazeli', 'link': 'https://arxiv.org/abs/2506.12239', 'abstract': 'Mastering dexterous, contact-rich object manipulation demands precise estimation of both in-hand object poses and external contact locations$\\unicode{x2013}$tasks particularly challenging due to partial and noisy observations. We present ViTaSCOPE: Visuo-Tactile Simultaneous Contact and Object Pose Estimation, an object-centric neural implicit representation that fuses vision and high-resolution tactile feedback. By representing objects as signed distance fields and distributed tactile feedback as neural shear fields, ViTaSCOPE accurately localizes objects and registers extrinsic contacts onto their 3D geometry as contact fields. Our method enables seamless reasoning over complementary visuo-tactile cues by leveraging simulation for scalable training and zero-shot transfers to the real-world by bridging the sim-to-real gap. We evaluate our method through comprehensive simulated and real-world experiments, demonstrating its capabilities in dexterous manipulation scenarios.', 'abstract_zh': '基于视觉和触觉同时估计物体姿态和外部接触位置：ViTaSCOPEmissive 触觉隐式表示', 'title_zh': 'ViTaSCOPE: 视触隐式表示用于手内姿态和外在接触估计'}
{'arxiv_id': 'arXiv:2506.12184', 'title': 'SPLATART: Articulated Gaussian Splatting with Estimated Object Structure', 'authors': 'Stanley Lewis, Vishal Chandra, Tom Gao, Odest Chadwicke Jenkins', 'link': 'https://arxiv.org/abs/2506.12184', 'abstract': 'Representing articulated objects remains a difficult problem within the field of robotics. Objects such as pliers, clamps, or cabinets require representations that capture not only geometry and color information, but also part seperation, connectivity, and joint parametrization. Furthermore, learning these representations becomes even more difficult with each additional degree of freedom. Complex articulated objects such as robot arms may have seven or more degrees of freedom, and the depth of their kinematic tree may be notably greater than the tools, drawers, and cabinets that are the typical subjects of articulated object research. To address these concerns, we introduce SPLATART - a pipeline for learning Gaussian splat representations of articulated objects from posed images, of which a subset contains image space part segmentations. SPLATART disentangles the part separation task from the articulation estimation task, allowing for post-facto determination of joint estimation and representation of articulated objects with deeper kinematic trees than previously exhibited. In this work, we present data on the SPLATART pipeline as applied to the syntheic Paris dataset objects, and qualitative results on a real-world object under spare segmentation supervision. We additionally present on articulated serial chain manipulators to demonstrate usage on deeper kinematic tree structures.', 'abstract_zh': '基于 posed 图像学习articulated 对象的 Gaussian splat 表示 - SPLATART 管道', 'title_zh': 'SPLATART: 基于估计算法结构的articulated高斯抽样'}
{'arxiv_id': 'arXiv:2506.12095', 'title': 'DoublyAware: Dual Planning and Policy Awareness for Temporal Difference Learning in Humanoid Locomotion', 'authors': 'Khang Nguyen, An T. Le, Jan Peters, Minh Nhat Vu', 'link': 'https://arxiv.org/abs/2506.12095', 'abstract': 'Achieving robust robot learning for humanoid locomotion is a fundamental challenge in model-based reinforcement learning (MBRL), where environmental stochasticity and randomness can hinder efficient exploration and learning stability. The environmental, so-called aleatoric, uncertainty can be amplified in high-dimensional action spaces with complex contact dynamics, and further entangled with epistemic uncertainty in the models during learning phases. In this work, we propose DoublyAware, an uncertainty-aware extension of Temporal Difference Model Predictive Control (TD-MPC) that explicitly decomposes uncertainty into two disjoint interpretable components, i.e., planning and policy uncertainties. To handle the planning uncertainty, DoublyAware employs conformal prediction to filter candidate trajectories using quantile-calibrated risk bounds, ensuring statistical consistency and robustness against stochastic dynamics. Meanwhile, policy rollouts are leveraged as structured informative priors to support the learning phase with Group-Relative Policy Constraint (GRPC) optimizers that impose a group-based adaptive trust-region in the latent action space. This principled combination enables the robot agent to prioritize high-confidence, high-reward behavior while maintaining effective, targeted exploration under uncertainty. Evaluated on the HumanoidBench locomotion suite with the Unitree 26-DoF H1-2 humanoid, DoublyAware demonstrates improved sample efficiency, accelerated convergence, and enhanced motion feasibility compared to RL baselines. Our simulation results emphasize the significance of structured uncertainty modeling for data-efficient and reliable decision-making in TD-MPC-based humanoid locomotion learning.', 'abstract_zh': '实现具备鲁棒性的类人机器人学习：基于模型的强化学习中的不确定性处理', 'title_zh': '双重awareness: 人类体态运动中时差学习的双向规划与策略awareness'}
{'arxiv_id': 'arXiv:2506.13505', 'title': 'UAV Object Detection and Positioning in a Mining Industrial Metaverse with Custom Geo-Referenced Data', 'authors': 'Vasiliki Balaska, Ioannis Tsampikos Papapetros, Katerina Maria Oikonomou, Loukas Bampis, Antonios Gasteratos', 'link': 'https://arxiv.org/abs/2506.13505', 'abstract': 'The mining sector increasingly adopts digital tools to improve operational efficiency, safety, and data-driven decision-making. One of the key challenges remains the reliable acquisition of high-resolution, geo-referenced spatial information to support core activities such as extraction planning and on-site monitoring. This work presents an integrated system architecture that combines UAV-based sensing, LiDAR terrain modeling, and deep learning-based object detection to generate spatially accurate information for open-pit mining environments. The proposed pipeline includes geo-referencing, 3D reconstruction, and object localization, enabling structured spatial outputs to be integrated into an industrial digital twin platform. Unlike traditional static surveying methods, the system offers higher coverage and automation potential, with modular components suitable for deployment in real-world industrial contexts. While the current implementation operates in post-flight batch mode, it lays the foundation for real-time extensions. The system contributes to the development of AI-enhanced remote sensing in mining by demonstrating a scalable and field-validated geospatial data workflow that supports situational awareness and infrastructure safety.', 'abstract_zh': '采矿业 increasingly 采用数字工具以提高运营效率、安全性和数据驱动的决策能力。可靠获取高分辨率、地理参考的空间信息仍然是关键挑战，以支持诸如开采规划和现场监测等核心活动。本研究提出了一种集成系统架构，结合了无人机载感测、LiDAR地形建模和基于深度学习的对象检测，以生成适用于露天采矿环境的空间准确信息。提议的管道包括地理参考、3D重建和物体定位，使结构化空间输出能够集成到工业数字孪生平台中。与传统的静态测量方法不同，该系统提供了更广泛的覆盖范围和更高的自动化潜力，模块化的组件适用于在实际工业环境中部署。尽管当前实现运行在飞行后批处理模式，但它为实时扩展奠定了基础。该系统通过演示一个可扩展且实地验证的地理空间数据流程，支持态势感知和基础设施安全，为采矿中人工智能增强的遥感发展做出了贡献。', 'title_zh': '矿产工业元宇宙中基于自定义地理参考数据的无人机目标检测与定位'}
{'arxiv_id': 'arXiv:2506.13189', 'title': 'Multimodal "Puppeteer": An Exploration of Robot Teleoperation Via Virtual Counterpart with LLM-Driven Voice and Gesture Interaction in Augmented Reality', 'authors': 'Yuchong Zhang, Bastian Orthmann, Shichen Ji, Michael Welle, Jonne Van Haastregt, Danica Kragic', 'link': 'https://arxiv.org/abs/2506.13189', 'abstract': 'The integration of robotics and augmented reality (AR) holds transformative potential for advancing human-robot interaction (HRI), offering enhancements in usability, intuitiveness, accessibility, and collaborative task performance. This paper introduces and evaluates a novel multimodal AR-based robot puppeteer framework that enables intuitive teleoperation via virtual counterpart through large language model (LLM)-driven voice commands and hand gesture interactions. Utilizing the Meta Quest 3, users interact with a virtual counterpart robot in real-time, effectively "puppeteering" its physical counterpart within an AR environment. We conducted a within-subject user study with 42 participants performing robotic cube pick-and-place with pattern matching tasks under two conditions: gesture-only interaction and combined voice-and-gesture interaction. Both objective performance metrics and subjective user experience (UX) measures were assessed, including an extended comparative analysis between roboticists and non-roboticists. The results provide key insights into how multimodal input influences contextual task efficiency, usability, and user satisfaction in AR-based HRI. Our findings offer practical design implications for designing effective AR-enhanced HRI systems.', 'abstract_zh': '机器人与增强现实技术的整合为提升人机交互（HRI）具有变革性的潜力，通过提供易用性、直观性、可访问性和协作任务性能的增强。本文介绍并评估了一种新颖的基于多模态AR的机器人傀儡师框架，该框架通过大型语言模型（LLM）驱动的语音命令和手势交互，实现了虚拟对应物的直观远程操作。利用Meta Quest 3，用户可以实时与虚拟对应物机器人进行交互，并在AR环境中有效地“操纵”其物理对应物。我们对42名参与者进行了单一被试者用户研究，他们在两种条件下完成机器人立方体匹配任务：仅手势交互和结合语音-手势交互。我们评估了客观性能指标和主观用户体验（UX）指标，包括对机器人专家与非机器人专家的扩展比较分析。研究结果提供了关于多模态输入如何影响基于AR的人机交互环境中的任务效率、易用性和用户满意度的关键见解。我们的发现为设计有效增强的AR人机交互系统提供了实用的设计建议。', 'title_zh': '多模态“操偶师”：基于LLM驱动的语音和手势交互在增强现实中的虚拟对应物机器人远程操作探索'}
{'arxiv_id': 'arXiv:2506.12822', 'title': 'Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models', 'authors': 'Tung Minh Luu, Younghwan Lee, Donghoon Lee, Sunho Kim, Min Jun Kim, Chang D. Yoo', 'link': 'https://arxiv.org/abs/2506.12822', 'abstract': 'Designing effective reward functions remains a fundamental challenge in reinforcement learning (RL), as it often requires extensive human effort and domain expertise. While RL from human feedback has been successful in aligning agents with human intent, acquiring high-quality feedback is costly and labor-intensive, limiting its scalability. Recent advancements in foundation models present a promising alternative--leveraging AI-generated feedback to reduce reliance on human supervision in reward learning. Building on this paradigm, we introduce ERL-VLM, an enhanced rating-based RL method that effectively learns reward functions from AI feedback. Unlike prior methods that rely on pairwise comparisons, ERL-VLM queries large vision-language models (VLMs) for absolute ratings of individual trajectories, enabling more expressive feedback and improved sample efficiency. Additionally, we propose key enhancements to rating-based RL, addressing instability issues caused by data imbalance and noisy labels. Through extensive experiments across both low-level and high-level control tasks, we demonstrate that ERL-VLM significantly outperforms existing VLM-based reward generation methods. Our results demonstrate the potential of AI feedback for scaling RL with minimal human intervention, paving the way for more autonomous and efficient reward learning.', 'abstract_zh': '设计有效的奖励函数仍然是强化学习中的一项基本挑战，这通常需要大量的人力投入和专业知识。虽然从人类反馈中进行的强化学习在使智能体与人类意图保持一致方面取得了成功，但获取高质量的反馈代价高昂且劳动密集，限制了其可扩展性。近期基础模型的进展提供了一种有前景的替代方案——利用AI生成的反馈来减少对人类监督的依赖。在此基础上，我们引入了ERL-VLM，这是一种增强的基于评分的强化学习方法，可以从AI反馈中有效学习奖励函数。与以前依赖成对比较的方法不同，ERL-VLM 查询大型视觉-语言模型（VLM）以获取单个轨迹的绝对评分，这使得反馈更具表现力并提高了样本效率。此外，我们还提出了基于评分的强化学习的关键改进，以解决由数据不平衡和嘈杂标签引起的数据不稳定问题。通过在不同层面的控制任务上的广泛实验，我们证明了ERL-VLM 显著优于现有的基于VLM的奖励生成方法。我们的结果表明，AI反馈有望在最少的人工干预下扩大强化学习的应用范围，为更自主和高效的奖励学习铺平了道路。', 'title_zh': '基于评分的强化学习增强以有效地利用大型视觉-语言模型的反馈'}
{'arxiv_id': 'arXiv:2506.13741', 'title': 'PB$^2$: Preference Space Exploration via Population-Based Methods in Preference-Based Reinforcement Learning', 'authors': 'Brahim Driss, Alex Davey, Riad Akrour', 'link': 'https://arxiv.org/abs/2506.13741', 'abstract': 'Preference-based reinforcement learning (PbRL) has emerged as a promising approach for learning behaviors from human feedback without predefined reward functions. However, current PbRL methods face a critical challenge in effectively exploring the preference space, often converging prematurely to suboptimal policies that satisfy only a narrow subset of human preferences. In this work, we identify and address this preference exploration problem through population-based methods. We demonstrate that maintaining a diverse population of agents enables more comprehensive exploration of the preference landscape compared to single-agent approaches. Crucially, this diversity improves reward model learning by generating preference queries with clearly distinguishable behaviors, a key factor in real-world scenarios where humans must easily differentiate between options to provide meaningful feedback. Our experiments reveal that current methods may fail by getting stuck in local optima, requiring excessive feedback, or degrading significantly when human evaluators make errors on similar trajectories, a realistic scenario often overlooked by methods relying on perfect oracle teachers. Our population-based approach demonstrates robust performance when teachers mislabel similar trajectory segments and shows significantly enhanced preference exploration capabilities,particularly in environments with complex reward landscapes.', 'abstract_zh': '基于偏好强化学习的偏好探索问题研究：基于群体的方法', 'title_zh': 'PB$^2$: 基于群体方法的偏奋试验空间探索在偏奋试程学习中的应用'}
{'arxiv_id': 'arXiv:2506.12952', 'title': 'Constitutive Components for Human-Like Autonomous Artificial Intelligence', 'authors': 'Kazunori D Yamada', 'link': 'https://arxiv.org/abs/2506.12952', 'abstract': 'This study is the first to clearly identify the functions required to construct artificial entities capable of behaving autonomously like humans, and organizes them into a three-layer functional hierarchy. Specifically, it defines three levels: Core Functions, which enable interaction with the external world; the Integrative Evaluation Function, which selects actions based on perception and memory; and the Self Modification Function, which dynamically reconfigures behavioral principles and internal components. Based on this structure, the study proposes a stepwise model of autonomy comprising reactive, weak autonomous, and strong autonomous levels, and discusses its underlying design principles and developmental aspects. It also explores the relationship between these functions and existing artificial intelligence design methods, addressing their potential as a foundation for general intelligence and considering future applications and ethical implications. By offering a theoretical framework that is independent of specific technical methods, this work contributes to a deeper understanding of autonomy and provides a foundation for designing future artificial entities with strong autonomy.', 'abstract_zh': '本研究首次清晰地界定了构建能够像人类一样自主行为的人工实体所需的功能，并将其组织成三层功能层次结构。具体而言，它定义了三个层次：核心功能，使实体能够与外部世界交互；综合评估功能，基于感知和记忆选择行动；以及自我修改功能，动态重新配置行为原则和内部组件。基于这一结构，研究提出了一种分阶段的自主性模型，包括反应性、弱自主性和强自主性层次，并讨论了其底层设计原则和发展方面的内容。研究还探讨了这些功能与现有人工智能设计方法的关系，探讨了它们作为通用智能基础的潜力，并考虑了未来应用和伦理影响。通过提供一种独立于具体技术方法的理论框架，本工作加深了对自主性的理解，并为设计具有强自主性的未来人工实体奠定了基础。', 'title_zh': '构成人类拟态自主人工智能的要素'}
{'arxiv_id': 'arXiv:2506.12812', 'title': 'Federated Neuroevolution O-RAN: Enhancing the Robustness of Deep Reinforcement Learning xApps', 'authors': 'Mohammadreza Kouchaki, Aly Sabri Abdalla, Vuk Marojevic', 'link': 'https://arxiv.org/abs/2506.12812', 'abstract': 'The open radio access network (O-RAN) architecture introduces RAN intelligent controllers (RICs) to facilitate the management and optimization of the disaggregated RAN. Reinforcement learning (RL) and its advanced form, deep RL (DRL), are increasingly employed for designing intelligent controllers, or xApps, to be deployed in the near-real time (near-RT) RIC. These models often encounter local optima, which raise concerns about their reliability for RAN intelligent control. We therefore introduce Federated O-RAN enabled Neuroevolution (NE)-enhanced DRL (F-ONRL) that deploys an NE-based optimizer xApp in parallel to the RAN controller xApps. This NE-DRL xApp framework enables effective exploration and exploitation in the near-RT RIC without disrupting RAN operations. We implement the NE xApp along with a DRL xApp and deploy them on Open AI Cellular (OAIC) platform and present numerical results that demonstrate the improved robustness of xApps while effectively balancing the additional computational load.', 'abstract_zh': '基于Federated O-RAN的NE增强DRL（F-ONRL）智能控制器架构', 'title_zh': '联邦神经进化O-RAN：增强深度强化学习x应用程序的稳健性'}
{'arxiv_id': 'arXiv:2506.12666', 'title': 'LIFELONG SOTOPIA: Evaluating Social Intelligence of Language Agents Over Lifelong Social Interactions', 'authors': 'Hitesh Goel, Hao Zhu', 'link': 'https://arxiv.org/abs/2506.12666', 'abstract': "Humans engage in lifelong social interactions through interacting with different people under different scenarios for different social goals. This requires social intelligence to gather information through a long time span and use it to navigate various social contexts effectively. Whether AI systems are also capable of this is understudied in the existing research. In this paper, we present a novel benchmark, LIFELONG-SOTOPIA, to perform a comprehensive evaluation of language agents by simulating multi-episode interactions. In each episode, the language agents role-play characters to achieve their respective social goals in randomly sampled social tasks. With LIFELONG-SOTOPIA, we find that goal achievement and believability of all of the language models that we test decline through the whole interaction. Although using an advanced memory method improves the agents' performance, the best agents still achieve a significantly lower goal completion rate than humans on scenarios requiring an explicit understanding of interaction history. These findings show that we can use LIFELONG-SOTOPIA to evaluate the social intelligence of language agents over lifelong social interactions.", 'abstract_zh': '人类通过在不同场景下与不同的人进行长期社会互动来实现不同的社会目标，这要求具备社会智能以长时间跨度收集信息，并在各种社会情境中有效导航。现有研究中，AI系统是否也具备这种能力尚未充分探讨。在本文中，我们提出一个名为LIFELONG-SOTOPIA的新基准，通过模拟多期互动全面评估语言代理。在每一期中，语言代理扮演角色以实现各自的社会目标，在随机抽样的社会任务中。通过LIFELONG-SOTOPIA，我们发现我们测试的所有语言模型在整个互动过程中目标达成率和可信度下降。尽管使用先进的记忆方法可以改善代理的表现，但最佳代理在需要理解互动历史的场景中的目标完成率仍然显著低于人类。这些发现表明，我们可以使用LIFELONG-SOTOPIA来评估语言代理在终身社会互动中的社会智能。', 'title_zh': '终身社交智能：语言代理在终身社交互动中的社会智能评估'}
{'arxiv_id': 'arXiv:2506.12664', 'title': 'Behavioral Generative Agents for Energy Operations', 'authors': 'Cong Chen, Omer Karaduman, Xu Kuang', 'link': 'https://arxiv.org/abs/2506.12664', 'abstract': 'Accurately modeling consumer behavior in energy operations remains challenging due to inherent uncertainties, behavioral complexities, and limited empirical data. This paper introduces a novel approach leveraging generative agents--artificial agents powered by large language models--to realistically simulate customer decision-making in dynamic energy operations. We demonstrate that these agents behave more optimally and rationally in simpler market scenarios, while their performance becomes more variable and suboptimal as task complexity rises. Furthermore, the agents exhibit heterogeneous customer preferences, consistently maintaining distinct, persona-driven reasoning patterns. Our findings highlight the potential value of integrating generative agents into energy management simulations to improve the design and effectiveness of energy policies and incentive programs.', 'abstract_zh': '准确建模能源运营中的消费者行为仍具挑战性，由于固有的不确定性、行为复杂性和有限的实证数据。本文介绍了一种利用生成代理（由大型语言模型驱动的虚拟代理）来真实模拟动态能源运营中客户决策的新方法。我们发现，这些代理在简单市场情境中表现得更接近最优和理性，而随着任务复杂性的增加，其性能变得更具变异性且更加次优。此外，这些代理表现出异质的消费者偏好，并保持一致的、以人物驱动的推理模式。我们的研究结果强调了将生成代理整合到能源管理模拟中以提高能源政策和激励计划设计与有效性的潜在价值。', 'title_zh': '能源运营中的行为生成代理'}
{'arxiv_id': 'arXiv:2506.12486', 'title': 'DinoCompanion: An Attachment-Theory Informed Multimodal Robot for Emotionally Responsive Child-AI Interaction', 'authors': 'Boyang Wang, Yuhao Song, Jinyuan Cao, Peng Yu, Hongcheng Guo, Zhoujun Li', 'link': 'https://arxiv.org/abs/2506.12486', 'abstract': "Children's emotional development fundamentally relies on secure attachment relationships, yet current AI companions lack the theoretical foundation to provide developmentally appropriate emotional support. We introduce DinoCompanion, the first attachment-theory-grounded multimodal robot for emotionally responsive child-AI interaction. We address three critical challenges in child-AI systems: the absence of developmentally-informed AI architectures, the need to balance engagement with safety, and the lack of standardized evaluation frameworks for attachment-based capabilities. Our contributions include: (i) a multimodal dataset of 128 caregiver-child dyads containing 125,382 annotated clips with paired preference-risk labels, (ii) CARPO (Child-Aware Risk-calibrated Preference Optimization), a novel training objective that maximizes engagement while applying epistemic-uncertainty-weighted risk penalties, and (iii) AttachSecure-Bench, a comprehensive evaluation benchmark covering ten attachment-centric competencies with strong expert consensus (\\k{appa}=0.81). DinoCompanion achieves state-of-the-art performance (57.15%), outperforming GPT-4o (50.29%) and Claude-3.7-Sonnet (53.43%), with exceptional secure base behaviors (72.99%, approaching human expert levels of 78.4%) and superior attachment risk detection (69.73%). Ablations validate the critical importance of multimodal fusion, uncertainty-aware risk modeling, and hierarchical memory for coherent, emotionally attuned interactions.", 'abstract_zh': '基于依恋理论的多模态儿童AI情感伴侣DinoCompanion：克服儿童AI系统的关键挑战', 'title_zh': 'DinoCompanion：基于依附理论的多模态情感响应机器人-childAI互动'}
{'arxiv_id': 'arXiv:2506.12482', 'title': 'Tiered Agentic Oversight: A Hierarchical Multi-Agent System for AI Safety in Healthcare', 'authors': 'Yubin Kim, Hyewon Jeong, Chanwoo Park, Eugene Park, Haipeng Zhang, Xin Liu, Hyeonhoon Lee, Daniel McDuff, Marzyeh Ghassemi, Cynthia Breazeal, Samir Tulebaev, Hae Won Park', 'link': 'https://arxiv.org/abs/2506.12482', 'abstract': "Current large language models (LLMs), despite their power, can introduce safety risks in clinical settings due to limitations such as poor error detection and single point of failure. To address this, we propose Tiered Agentic Oversight (TAO), a hierarchical multi-agent framework that enhances AI safety through layered, automated supervision. Inspired by clinical hierarchies (e.g., nurse, physician, specialist), TAO conducts agent routing based on task complexity and agent roles. Leveraging automated inter- and intra-tier collaboration and role-playing, TAO creates a robust safety framework. Ablation studies reveal that TAO's superior performance is driven by its adaptive tiered architecture, which improves safety by over 3.2% compared to static single-tier configurations; the critical role of its lower tiers, particularly tier 1, whose removal most significantly impacts safety; and the strategic assignment of more advanced LLM to these initial tiers, which boosts performance by over 2% compared to less optimal allocations while achieving near-peak safety efficiently. These mechanisms enable TAO to outperform single-agent and multi-agent frameworks in 4 out of 5 healthcare safety benchmarks, showing up to an 8.2% improvement over the next-best methods in these evaluations. Finally, we validate TAO via an auxiliary clinician-in-the-loop study where integrating expert feedback improved TAO's accuracy in medical triage from 40% to 60%.", 'abstract_zh': '当前的大语言模型（LLMs）尽管功能强大，但在临床环境中由于错误检测能力差和单一故障点等因素，仍可能引入安全风险。为解决这一问题，我们提出分层代理监督（TAO）框架，这是一种通过分层自动化监督来增强AI安全性的多层次多代理体系结构。TAO借鉴了临床环境中的层级结构（如护士、医生、专科医生）进行代理路由，基于任务复杂度和代理角色。通过自动跨级和同级协作及角色扮演，TAO建立起一个稳健的安全框架。消融研究显示，TAO的优越性能归因于其适应性的分层架构，这种架构相比静态单一层次配置提高了超过3.2%的安全性；下层尤其是第一层代理的至关重要性，其缺失对安全影响最大；以及将更先进的大型语言模型分配至初始层次带来的策略性优势，这类分配在提高性能超过2%的同时，能够高效实现接近峰值的安全性。这些机制使得TAO在4个临床安全基准测试中优于单一代理和多代理框架，相较于次优方法，这些评估中最佳方法的性能提高了高达8.2%。最后，通过辅助临床医生在环研究验证TAO，结果显示整合专家反馈使TAO在医疗分诊中的准确性从40%提高到60%。', 'title_zh': '分层代理监督：面向医疗健康领域AI安全的分级多代理系统'}
{'arxiv_id': 'arXiv:2506.13599', 'title': 'CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation', 'authors': 'Yuwei Du, Jie Feng, Jian Yuan, Yong Li', 'link': 'https://arxiv.org/abs/2506.13599', 'abstract': 'Human mobility simulation plays a crucial role in various real-world applications. Recently, to address the limitations of traditional data-driven approaches, researchers have explored leveraging the commonsense knowledge and reasoning capabilities of large language models (LLMs) to accelerate human mobility simulation. However, these methods suffer from several critical shortcomings, including inadequate modeling of urban spaces and poor integration with both individual mobility patterns and collective mobility distributions. To address these challenges, we propose \\textbf{C}ityGPT-Powered \\textbf{A}gentic framework for \\textbf{M}obility \\textbf{S}imulation (\\textbf{CAMS}), an agentic framework that leverages the language based urban foundation model to simulate human mobility in urban space. \\textbf{CAMS} comprises three core modules, including MobExtractor to extract template mobility patterns and synthesize new ones based on user profiles, GeoGenerator to generate anchor points considering collective knowledge and generate candidate urban geospatial knowledge using an enhanced version of CityGPT, TrajEnhancer to retrieve spatial knowledge based on mobility patterns and generate trajectories with real trajectory preference alignment via DPO. Experiments on real-world datasets show that \\textbf{CAMS} achieves superior performance without relying on externally provided geospatial information. Moreover, by holistically modeling both individual mobility patterns and collective mobility constraints, \\textbf{CAMS} generates more realistic and plausible trajectories. In general, \\textbf{CAMS} establishes a new paradigm that integrates the agentic framework with urban-knowledgeable LLMs for human mobility simulation.', 'abstract_zh': '基于CityGPT的城市代理性移动模拟框架（CAMS）', 'title_zh': 'CAMS：一个由CityGPT驱动的 urbans人类移动模拟代理框架'}
{'arxiv_id': 'arXiv:2506.13523', 'title': 'The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products', 'authors': 'YuQing Xie, Ameya Daigavane, Mit Kotak, Tess Smidt', 'link': 'https://arxiv.org/abs/2506.13523', 'abstract': '$E(3)$-equivariant neural networks have demonstrated success across a wide range of 3D modelling tasks. A fundamental operation in these networks is the tensor product, which interacts two geometric features in an equivariant manner to create new features. Due to the high computational complexity of the tensor product, significant effort has been invested to optimize the runtime of this operation. For example, Luo et al. (2024) recently proposed the Gaunt tensor product (GTP) which promises a significant speedup. In this work, we provide a careful, systematic analysis of a number of tensor product operations. In particular, we emphasize that different tensor products are not performing the same operation. The reported speedups typically come at the cost of expressivity. We introduce measures of expressivity and interactability to characterize these differences. In addition, we realized the original implementation of GTP can be greatly simplified by directly using a spherical grid at no cost in asymptotic runtime. This spherical grid approach is faster on our benchmarks and in actual training of the MACE interatomic potential by 30\\%. Finally, we provide the first systematic microbenchmarks of the various tensor product operations. We find that the theoretical runtime guarantees can differ wildly from empirical performance, demonstrating the need for careful application-specific benchmarking. Code is available at \\href{this https URL}{this https URL}', 'abstract_zh': '$E(3)$-对称神经网络在广泛三维建模任务中取得了成功。这些网络中的一个基本操作是张量积，它以对称方式相互作用两个几何特征以生成新的特征。由于张量积计算复杂度高，投入了大量努力来优化此操作的运行时。例如，Luo等（2024）最近提出了Gaunt张量积（GTP），承诺显著提高运行速度。在本文中，我们对几种张量积操作进行了细致的系统分析。特别是，我们强调不同张量积并未执行相同的操作。所报告的加速通常是以表达能力为代价的。我们引入了表达能力和交互性的度量来表征这些差异。此外，我们发现GTP的原始实现可以通过直接使用球形网格大大简化，且不影响渐进运行时。在我们的基准测试和MACE原子间势能的实际训练中，这种球形网格方法比原始实现快30%。最后，我们提供了各种张量积操作的第一套系统微基准测试。我们发现理论上的运行时保证与实际表现之间可能存在巨大差异，突显了详细应用特定基准测试的必要性。代码可在<这个超链接>获得。', 'title_zh': '自由的价格：探索不变张量乘积的表达能力和运行时-tradeoff$username\nuser\n把下面的论文内容或标题翻译成中文：Reinforcement Learning as Intrinsic Motivation for Exploration in Heterogeneous Groups.'}
{'arxiv_id': 'arXiv:2506.13111', 'title': 'Overcoming Overfitting in Reinforcement Learning via Gaussian Process Diffusion Policy', 'authors': 'Amornyos Horprasert, Esa Apriaskar, Xingyu Liu, Lanlan Su, Lyudmila S. Mihaylova', 'link': 'https://arxiv.org/abs/2506.13111', 'abstract': "One of the key challenges that Reinforcement Learning (RL) faces is its limited capability to adapt to a change of data distribution caused by uncertainties. This challenge arises especially in RL systems using deep neural networks as decision makers or policies, which are prone to overfitting after prolonged training on fixed environments. To address this challenge, this paper proposes Gaussian Process Diffusion Policy (GPDP), a new algorithm that integrates diffusion models and Gaussian Process Regression (GPR) to represent the policy. GPR guides diffusion models to generate actions that maximize learned Q-function, resembling the policy improvement in RL. Furthermore, the kernel-based nature of GPR enhances the policy's exploration efficiency under distribution shifts at test time, increasing the chance of discovering new behaviors and mitigating overfitting. Simulation results on the Walker2d benchmark show that our approach outperforms state-of-the-art algorithms under distribution shift condition by achieving around 67.74% to 123.18% improvement in the RL's objective function while maintaining comparable performance under normal conditions.", 'abstract_zh': '基于高斯过程扩散模型的强化学习政策改进方法：应对数据分布变化的挑战', 'title_zh': '通过高斯过程扩散策略克服强化学习中的过拟合'}
{'arxiv_id': 'arXiv:2506.12735', 'title': 'Revealing the Challenges of Sim-to-Real Transfer in Model-Based Reinforcement Learning via Latent Space Modeling', 'authors': 'Zhilin Lin, Shiliang Sun', 'link': 'https://arxiv.org/abs/2506.12735', 'abstract': 'Reinforcement learning (RL) is playing an increasingly important role in fields such as robotic control and autonomous driving. However, the gap between simulation and the real environment remains a major obstacle to the practical deployment of RL. Agents trained in simulators often struggle to maintain performance when transferred to real-world physical environments. In this paper, we propose a latent space based approach to analyze the impact of simulation on real-world policy improvement in model-based settings. As a natural extension of model-based methods, our approach enables an intuitive observation of the challenges faced by model-based methods in sim-to-real transfer. Experiments conducted in the MuJoCo environment evaluate the performance of our method in both measuring and mitigating the sim-to-real gap. The experiments also highlight the various challenges that remain in overcoming the sim-to-real gap, especially for model-based methods.', 'abstract_zh': '基于潜在空间的方法在模型导向设置中分析模拟对实际政策改进的影响：MuJoCo环境中的实测与缓解sim-to-real差距的实验', 'title_zh': '基于潜空间建模揭示模型导向强化学习中从仿真到现实转移的挑战'}
{'arxiv_id': 'arXiv:2506.12469', 'title': 'Levels of Autonomy for AI Agents', 'authors': 'K. J. Kevin Feng, David W. McDonald, Amy X. Zhang', 'link': 'https://arxiv.org/abs/2506.12469', 'abstract': "Autonomy is a double-edged sword for AI agents, simultaneously unlocking transformative possibilities and serious risks. How can agent developers calibrate the appropriate levels of autonomy at which their agents should operate? We argue that an agent's level of autonomy can be treated as a deliberate design decision, separate from its capability and operational environment. In this work, we define five levels of escalating agent autonomy, characterized by the roles a user can take when interacting with an agent: operator, collaborator, consultant, approver, and observer. Within each level, we describe the ways by which a user can exert control over the agent and open questions for how to design the nature of user-agent interaction. We then highlight a potential application of our framework towards AI autonomy certificates to govern agent behavior in single- and multi-agent systems. We conclude by proposing early ideas for evaluating agents' autonomy. Our work aims to contribute meaningful, practical steps towards responsibly deployed and useful AI agents in the real world.", 'abstract_zh': '自主性是AI代理的双刃剑，同时开启变革性潜力和严重风险。代理开发者应如何校准代理应操作的适当自主水平？我们argue自主水平可以作为故意的设计决策，与代理的能力和运行环境分开。在此工作中，我们定义了五级递增的代理自主性级别，由用户在与代理互动时可以扮演的角色来表征：操作员、合作者、顾问、审批人和观察者。在每一级中，我们描述了用户控制代理的方式，并提出了有关如何设计用户-代理交互本质的问题。然后，我们强调了将我们的框架应用于AI自主性证书，以管理单个和多个代理系统的代理行为的潜在应用。最后，我们提出了评估代理自主性的初步想法。我们的工作旨在为负责任地部署和实用的AI代理在现实世界中做出有意义和实用的贡献。', 'title_zh': 'AI代理的自主水平'}
{'arxiv_id': 'arXiv:2506.12437', 'title': 'Feeling Machines: Ethics, Culture, and the Rise of Emotional AI', 'authors': 'Vivek Chavan, Arsen Cenaj, Shuyuan Shen, Ariane Bar, Srishti Binwani, Tommaso Del Becaro, Marius Funk, Lynn Greschner, Roberto Hung, Stina Klein, Romina Kleiner, Stefanie Krause, Sylwia Olbrych, Vishvapalsinhji Parmar, Jaleh Sarafraz, Daria Soroko, Daksitha Withanage Don, Chang Zhou, Hoang Thuy Duong Vu, Parastoo Semnani, Daniel Weinhardt, Elisabeth Andre, Jörg Krüger, Xavier Fresquet', 'link': 'https://arxiv.org/abs/2506.12437', 'abstract': 'This paper explores the growing presence of emotionally responsive artificial intelligence through a critical and interdisciplinary lens. Bringing together the voices of early-career researchers from multiple fields, it explores how AI systems that simulate or interpret human emotions are reshaping our interactions in areas such as education, healthcare, mental health, caregiving, and digital life. The analysis is structured around four central themes: the ethical implications of emotional AI, the cultural dynamics of human-machine interaction, the risks and opportunities for vulnerable populations, and the emerging regulatory, design, and technical considerations. The authors highlight the potential of affective AI to support mental well-being, enhance learning, and reduce loneliness, as well as the risks of emotional manipulation, over-reliance, misrepresentation, and cultural bias. Key challenges include simulating empathy without genuine understanding, encoding dominant sociocultural norms into AI systems, and insufficient safeguards for individuals in sensitive or high-risk contexts. Special attention is given to children, elderly users, and individuals with mental health challenges, who may interact with AI in emotionally significant ways. However, there remains a lack of cognitive or legal protections which are necessary to navigate such engagements safely. The report concludes with ten recommendations, including the need for transparency, certification frameworks, region-specific fine-tuning, human oversight, and longitudinal research. A curated supplementary section provides practical tools, models, and datasets to support further work in this domain.', 'abstract_zh': '本文通过跨学科的批判性视角探讨情绪响应人工智能日益增长的存在。汇集了来自多个领域的早期职业研究人员的声音，探讨模拟或解释人类情绪的人工智能系统如何重塑教育、医疗、心理健康、照护以及数字生活等领域中的互动。分析围绕四个核心主题展开：情绪人工智能的伦理影响、人机互动的文化动态、脆弱群体面临的风险与机遇，以及新兴的监管、设计和技术考量。作者强调了情感人工智能支持心理健康、增强学习和减轻孤独的潜力，同时也提到了情感操控、过度依赖、误导和文化偏见的风险。关键挑战包括在没有真正理解的情况下模拟共情、将主导的社文化规范编码进人工智能系统，以及在敏感或高风险情境中缺乏足够的保护措施。特别关注儿童、老年用户以及心理健康挑战者，他们与人工智能在情感上可能存在重要互动。然而，对于这些互动仍缺乏足够的认知或法律保护措施，以确保安全地参与其中。报告最后提出十项建议，包括透明度、认证框架、区域特定微调、人类监督以及纵向研究的需要。一个精选补充部分提供了实用工具、模型和数据集，以支持该领域的进一步研究工作。', 'title_zh': '情感机器：伦理、文化与情绪人工智能的兴起'}
