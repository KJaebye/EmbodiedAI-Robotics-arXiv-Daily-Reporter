{'arxiv_id': 'arXiv:2503.07576', 'title': 'Analyzing Symmetries of Swarms of Mobile Robots Using Equivariant Dynamical Systems', 'authors': 'Raphael Gerlach, Sören von der Gracht', 'link': 'https://arxiv.org/abs/2503.07576', 'abstract': 'In this article, we investigate symmetry properties of distributed systems of mobile robots. We consider a swarm of $n\\in\\mathbb{N}$ robots in the $\\mathcal{OBLOT}$ model and analyze their collective $\\mathcal{F}$sync dynamics using of equivariant dynamical systems theory. To this end, we show that the corresponding evolution function commutes with rotational and reflective transformations of $\\mathbb{R}^2$. These form a group that is isomorphic to $\\mathbf{O}(2) \\times S_n$, the product group of the orthogonal group and the permutation on $n$ elements. The theory of equivariant dynamical systems is used to deduce a hierarchy along which symmetries of a robot swarm can potentially increase following an arbitrary protocol. By decoupling the Look phase from the Compute and Move phases in the mathematical description of an LCM cycle, this hierarchy can be characterized in terms of automorphisms of connectivity graphs. In particular, we find all possible types of symmetry increase, if the decoupled Compute and Move phase is invertible. Finally, we apply our results to protocols which induce state-dependent linear dynamics, where the reduced system consisting of only the Compute and Move phase is linear.', 'abstract_zh': '分布式移动机器人系统的对称性性质研究：基于等变动力系统理论的群集同步动态分析', 'title_zh': '分析移动机器人群体的对称性using等变动力系统'}
{'arxiv_id': 'arXiv:2503.07557', 'title': 'AutoSpatial: Visual-Language Reasoning for Social Robot Navigation through Efficient Spatial Reasoning Learning', 'authors': 'Yangzhe Kong, Daeun Song, Jing Liang, Dinesh Manocha, Ziyu Yao, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.07557', 'abstract': "We present a novel method, AutoSpatial, an efficient approach with structured spatial grounding to enhance VLMs' spatial reasoning. By combining minimal manual supervision with large-scale Visual Question-Answering (VQA) pairs auto-labeling, our approach tackles the challenge of VLMs' limited spatial understanding in social navigation tasks. By applying a hierarchical two-round VQA strategy during training, AutoSpatial achieves both global and detailed understanding of scenarios, demonstrating more accurate spatial perception, movement prediction, Chain of Thought (CoT) reasoning, final action, and explanation compared to other SOTA approaches. These five components are essential for comprehensive social navigation reasoning. Our approach was evaluated using both expert systems (GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet) that provided cross-validation scores and human evaluators who assigned relative rankings to compare model performances across four key aspects. Augmented by the enhanced spatial reasoning capabilities, AutoSpatial demonstrates substantial improvements by averaged cross-validation score from expert systems in: perception & prediction (up to 10.71%), reasoning (up to 16.26%), action (up to 20.50%), and explanation (up to 18.73%) compared to baseline models trained only on manually annotated data.", 'abstract_zh': '一种新型方法：AutoSpatial，一种结合结构化空间接地的高效途径，以增强VLMs的空间推理能力', 'title_zh': 'AutoSpatial: 通过高效的空间推理学习实现社会机器人导航的视觉-语言推理'}
{'arxiv_id': 'arXiv:2503.07547', 'title': 'Bi-Directional Mental Model Reconciliation for Human-Robot Interaction with Large Language Models', 'authors': 'Nina Moorman, Michelle Zhao, Matthew B. Luebbers, Sanne Van Waveren, Reid Simmons, Henny Admoni, Sonia Chernova, Matthew Gombolay', 'link': 'https://arxiv.org/abs/2503.07547', 'abstract': "In human-robot interactions, human and robot agents maintain internal mental models of their environment, their shared task, and each other. The accuracy of these representations depends on each agent's ability to perform theory of mind, i.e. to understand the knowledge, preferences, and intentions of their teammate. When mental models diverge to the extent that it affects task execution, reconciliation becomes necessary to prevent the degradation of interaction. We propose a framework for bi-directional mental model reconciliation, leveraging large language models to facilitate alignment through semi-structured natural language dialogue. Our framework relaxes the assumption of prior model reconciliation work that either the human or robot agent begins with a correct model for the other agent to align to. Through our framework, both humans and robots are able to identify and communicate missing task-relevant context during interaction, iteratively progressing toward a shared mental model.", 'abstract_zh': '人类与机器人交互中的双向心智模型 reconciliation 框架：利用大规模语言模型促进半结构化自然语言对话中的对齐', 'title_zh': '双向心智模型调和：面向大规模语言模型的人机交互'}
{'arxiv_id': 'arXiv:2503.07541', 'title': 'Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm', 'authors': 'Zhao-Heng Yin, Changhao Wang, Luis Pineda, Krishna Bodduluri, Tingfan Wu, Pieter Abbeel, Mustafa Mukadam', 'link': 'https://arxiv.org/abs/2503.07541', 'abstract': 'We introduce Geometric Retargeting (GeoRT), an ultrafast, and principled neural hand retargeting algorithm for teleoperation, developed as part of our recent Dexterity Gen (DexGen) system. GeoRT converts human finger keypoints to robot hand keypoints at 1KHz, achieving state-of-the-art speed and accuracy with significantly fewer hyperparameters. This high-speed capability enables flexible postprocessing, such as leveraging a foundational controller for action correction like DexGen. GeoRT is trained in an unsupervised manner, eliminating the need for manual annotation of hand pairs. The core of GeoRT lies in novel geometric objective functions that capture the essence of retargeting: preserving motion fidelity, ensuring configuration space (C-space) coverage, maintaining uniform response through high flatness, pinch correspondence and preventing self-collisions. This approach is free from intensive test-time optimization, offering a more scalable and practical solution for real-time hand retargeting.', 'abstract_zh': '几何重塑（GeoRT）：一种用于遥操作的超快速和原理性的神经手部重塑算法', 'title_zh': '几何重塑：一个原则性的超快速神经手部重塑算法'}
{'arxiv_id': 'arXiv:2503.07511', 'title': 'PointVLA: Injecting the 3D World into Vision-Language-Action Models', 'authors': 'Chengmeng Li, Junjie Wen, Yan Peng, Yaxin Peng, Feifei Feng, Yichen Zhu', 'link': 'https://arxiv.org/abs/2503.07511', 'abstract': 'Vision-Language-Action (VLA) models excel at robotic tasks by leveraging large-scale 2D vision-language pretraining, but their reliance on RGB images limits spatial reasoning critical for real-world interaction. Retraining these models with 3D data is computationally prohibitive, while discarding existing 2D datasets wastes valuable resources. To bridge this gap, we propose PointVLA, a framework that enhances pre-trained VLAs with point cloud inputs without requiring retraining. Our method freezes the vanilla action expert and injects 3D features via a lightweight modular block. To identify the most effective way of integrating point cloud representations, we conduct a skip-block analysis to pinpoint less useful blocks in the vanilla action expert, ensuring that 3D features are injected only into these blocks--minimizing disruption to pre-trained representations.\nExtensive experiments demonstrate that PointVLA outperforms state-of-the-art 2D imitation learning methods, such as OpenVLA, Diffusion Policy and DexVLA, across both simulated and real-world robotic tasks. Specifically, we highlight several key advantages of PointVLA enabled by point cloud integration: (1) Few-shot multi-tasking, where PointVLA successfully performs four different tasks using only 20 demonstrations each; (2) Real-vs-photo discrimination, where PointVLA distinguishes real objects from their images, leveraging 3D world knowledge to improve safety and reliability; (3) Height adaptability, Unlike conventional 2D imitation learning methods, PointVLA enables robots to adapt to objects at varying table height that unseen in train data. Furthermore, PointVLA achieves strong performance in long-horizon tasks, such as picking and packing objects from a moving conveyor belt, showcasing its ability to generalize across complex, dynamic environments.', 'abstract_zh': '基于点云的视觉-语言-动作（PointVLA）模型通过结合大规模2D视觉语言预训练在机器人任务中表现出色，但其依赖于RGB图像限制了其在现实世界交互中的空间推理能力。通过3D数据重新训练这些模型在计算上是不可行的，而丢弃现有的2D数据集则会浪费宝贵的资源。为此，我们提出了一种PointVLA框架，无需重新训练即可增强预训练的VLAs模型，并通过一个轻量级模块注入3D特征。为了确定集成点云表示的最有效方式，我们进行了跳块分析以识别范式动作专家中不太有用的块，从而确保仅将3D特征注入这些块中，以最小化对预训练表示的干扰。\n\n广泛的实验表明，PointVLA在模拟和真实世界机器人任务中均优于最先进的2Dimitation学习方法，如OpenVLA、Diffusion Policy和DexVLA。具体而言，PointVLA通过点云集成提供了几个关键优势：（1）少样本多任务处理，PointVLA仅使用每项任务20个演示就成功执行了四种不同任务；（2）真实物体与照片区分，PointVLA利用3D世界知识区分真实物体与其图像，从而提高安全性和可靠性；（3）不同高度适应性，不同于传统的2Dimitation学习方法，PointVLA使机器人能够适应训练数据中未见过的高度不同的物体。此外，PointVLA在长时间任务中表现出色，如从移动传送带上抓取和打包物体，展示了其在复杂动态环境中的泛化能力。', 'title_zh': 'PointVLA: 将三维世界注入视觉-语言-行动模型'}
{'arxiv_id': 'arXiv:2503.07504', 'title': 'PIPE Planner: Pathwise Information Gain with Map Predictions for Indoor Robot Exploration', 'authors': 'Seungjae Baek, Brady Moon, Seungchan Kim, Muqing Cao, Cherie Ho, Sebastian Scherer, Jeong hwan Jeon', 'link': 'https://arxiv.org/abs/2503.07504', 'abstract': 'Autonomous exploration in unknown environments requires estimating the information gain of an action to guide planning decisions. While prior approaches often compute information gain at discrete waypoints, pathwise integration offers a more comprehensive estimation but is often computationally challenging or infeasible and prone to overestimation. In this work, we propose the Pathwise Information Gain with Map Prediction for Exploration (PIPE) planner, which integrates cumulative sensor coverage along planned trajectories while leveraging map prediction to mitigate overestimation. To enable efficient pathwise coverage computation, we introduce a method to efficiently calculate the expected observation mask along the planned path, significantly reducing computational overhead. We validate PIPE on real-world floorplan datasets, demonstrating its superior performance over state-of-the-art baselines. Our results highlight the benefits of integrating predictive mapping with pathwise information gain for efficient and informed exploration.', 'abstract_zh': '基于地图预测的路径信息增益规划（PIPE）', 'title_zh': '基于地图预测的路径信息增益室内机器人探索方法'}
{'arxiv_id': 'arXiv:2503.07497', 'title': 'Force Aware Branch Manipulation To Assist Agricultural Tasks', 'authors': 'Madhav Rijal, Rashik Shrestha, Trevor Smith, Yu Gu', 'link': 'https://arxiv.org/abs/2503.07497', 'abstract': 'This study presents a methodology to safely manipulate branches to aid various agricultural tasks. Humans in a real agricultural environment often manipulate branches to perform agricultural tasks effectively, but current agricultural robots lack this capability. This proposed strategy to manipulate branches can aid in different precision agriculture tasks, such as fruit picking in dense foliage, pollinating flowers under occlusion, and moving overhanging vines and branches for navigation. The proposed method modifies RRT* to plan a path that satisfies the branch geometric constraints and obeys branch deformable characteristics. Re-planning is done to obtain a path that helps the robot exert force within a desired range so that branches are not damaged during manipulation. Experimentally, this method achieved a success rate of 78\\% across 50 trials, successfully moving a branch from different starting points to a target region.', 'abstract_zh': '本研究提出了一种安全操作树枝的方法以辅助各种农业任务。', 'title_zh': '基于力感知的分支操作以辅助农业任务'}
{'arxiv_id': 'arXiv:2503.07492', 'title': 'Blind-Wayfarer: A Minimalist, Probing-Driven Framework for Resilient Navigation in Perception-Degraded Environments', 'authors': 'Yanran Xu, Klaus-Peter Zauner, Danesh Tarapore', 'link': 'https://arxiv.org/abs/2503.07492', 'abstract': 'Navigating autonomous robots through dense forests and rugged terrains is especially daunting when exteroceptive sensors -- such as cameras and LiDAR sensors -- fail under occlusions, low-light conditions, or sensor noise. We present Blind-Wayfarer, a probing-driven navigation framework inspired by maze-solving algorithms that relies primarily on a compass to robustly traverse complex, unstructured environments. In 1,000 simulated forest experiments, Blind-Wayfarer achieved a 99.7% success rate. In real-world tests in two distinct scenarios -- with rover platforms of different sizes -- our approach successfully escaped forest entrapments in all 20 trials. Remarkably, our framework also enabled a robot to escape a dense woodland, traveling from 45 m inside the forest to a paved pathway at its edge. These findings highlight the potential of probing-based methods for reliable navigation in challenging perception-degraded field conditions. Videos and code are available on our website this https URL', 'abstract_zh': '自主机器人穿越茂密森林和崎岖地形的探索导航：当相机和LiDAR传感器在遮挡、低光照条件或传感器噪声下失效时尤为具有挑战性。基于迷宫求解算法的探查驱动导航框架Blind-Wayfarer及其应用研究', 'title_zh': 'Blind-Wayfarer: 一种针对感知降级环境的简约探查驱动鲁棒导航框架'}
{'arxiv_id': 'arXiv:2503.07481', 'title': 'Learning Physics-Based Full-Body Human Reaching and Grasping from Brief Walking References', 'authors': 'Yitang Li, Mingxian Lin, Zhuo Lin, Yipeng Deng, Yue Cao, Li Yi', 'link': 'https://arxiv.org/abs/2503.07481', 'abstract': 'Existing motion generation methods based on mocap data are often limited by data quality and coverage. In this work, we propose a framework that generates diverse, physically feasible full-body human reaching and grasping motions using only brief walking mocap data. Base on the observation that walking data captures valuable movement patterns transferable across tasks and, on the other hand, the advanced kinematic methods can generate diverse grasping poses, which can then be interpolated into motions to serve as task-specific guidance. Our approach incorporates an active data generation strategy to maximize the utility of the generated motions, along with a local feature alignment mechanism that transfers natural movement patterns from walking data to enhance both the success rate and naturalness of the synthesized motions. By combining the fidelity and stability of natural walking with the flexibility and generalizability of task-specific generated data, our method demonstrates strong performance and robust adaptability in diverse scenes and with unseen objects.', 'abstract_zh': '基于 mocap 数据生成多样且物理可行的全身人体抓取运动的框架', 'title_zh': '基于物理的全身体姿抓取学习从短暂行走参考中学习'}
{'arxiv_id': 'arXiv:2503.07479', 'title': 'QBIT: Quality-Aware Cloud-Based Benchmarking for Robotic Insertion Tasks', 'authors': 'Constantin Schempp, Yongzhou Zhang, Christian Friedrich, Bjorn Hein', 'link': 'https://arxiv.org/abs/2503.07479', 'abstract': 'Insertion tasks are fundamental yet challenging for robots, particularly in autonomous operations, due to their continuous interaction with the environment. AI-based approaches appear to be up to the challenge, but in production they must not only achieve high success rates. They must also ensure insertion quality and reliability. To address this, we introduce QBIT, a quality-aware benchmarking framework that incorporates additional metrics such as force energy, force smoothness and completion time to provide a comprehensive assessment. To ensure statistical significance and minimize the sim-to-real gap, we randomize contact parameters in the MuJoCo simulator, account for perceptual uncertainty, and conduct large-scale experiments on a Kubernetes-based infrastructure. Our microservice-oriented architecture ensures extensibility, broad applicability, and improved reproducibility. To facilitate seamless transitions to physical robotic testing, we use ROS2 with containerization to reduce integration barriers. We evaluate QBIT using three insertion approaches: geometricbased, force-based, and learning-based, in both simulated and real-world environments. In simulation, we compare the accuracy of contact simulation using different mesh decomposition techniques. Our results demonstrate the effectiveness of QBIT in comparing different insertion approaches and accelerating the transition from laboratory to real-world applications. Code is available on GitHub.', 'abstract_zh': '基于质量感知的插入任务基准框架QBIT：针对自主操作的评估与优化', 'title_zh': 'QBIT: 基于质量aware的云平台机器人插入任务基准测试'}
{'arxiv_id': 'arXiv:2503.07473', 'title': 'Augmented Carpentry: Computer Vision-assisted Framework for Manual Fabrication', 'authors': 'Andrea Settimi, Julien Gamerro, Yves Weinand', 'link': 'https://arxiv.org/abs/2503.07473', 'abstract': 'Ordinary electric woodworking tools are integrated into a multiple-object-aware augmented framework to assist operators in fabrication tasks. This study presents an advanced evaluation of the developed open-source fabrication software Augmented Carpentry (AC), focusing on the technical challenges, potential bottlenecks, and precision of the proposed system, which is designed to recognize both objects and tools. In the workflow, computer vision tools and sensors implement inside-out tracking techniques for the retrofitting tools. This method enables operators to perform precise saw-cutting and drilling tasks using computer-generated feedback. In the design and manufacturing process pipeline, manual fabrication tasks are performed directly from the computer-aided design environment, as computer numerical control machines are widely used in the timber construction industry. Traditional non-digital methods employing execution drawings, markings, and jigs can now be replaced, and manual labor can be directly integrated into the digital value chain. First, this paper introduces the developed methodology and explains its devices and functional phases in detail. Second, the fabrication methodology is evaluated by experimentally scanning the produced one-to-one scale mock-up elements and comparing the discrepancies with their respective three-dimensional execution models. Finally, improvements and limitations in the tool-aware fabrication process, as well as the potential impact of AC in the digital timber fabrication landscape, are discussed.', 'abstract_zh': '普通电动 woodworking 工具被集成到多目标aware 的增强现实框架中，以辅助操作者完成制造任务。本文对所开发的开源制造软件 Augmented Carpentry (AC) 进行了高级评估，重点讨论了技术挑战、潜在瓶颈和所提议系统的精度，该系统旨在识别物体和工具。在工作流程中，计算机视觉工具和传感器实施了inside-out 跟踪技术以改造工具。该方法使操作者能够通过计算机生成的反馈执行精确的锯割和钻孔任务。在设计和制造流程管道中，直接从计算机辅助设计环境中执行手动制造任务，因为在木质建筑行业中广泛使用计算机数控机床。现在，传统的非数字化方法，包括执行图纸、标记和夹具，可以被替换，并且手动劳动可以直接集成到数字化的价值链中。本文首先介绍了所开发的方法，并详细解释了其设备和功能阶段。其次，通过实验扫描制造的等比例原型元件并与各自的三维执行模型进行比较，来评估制造方法。最后，讨论了aware 制造过程中改进和限制，以及AC 对数字化木质制造景观的潜在影响。', 'title_zh': '增强木工工艺：计算机视觉辅助的手工制造框架'}
{'arxiv_id': 'arXiv:2503.07425', 'title': 'CATPlan: Loss-based Collision Prediction in End-to-End Autonomous Driving', 'authors': 'Ziliang Xiong, Shipeng Liu, Nathaniel Helgesen, Joakim Johnander, Per-Erik Forssen', 'link': 'https://arxiv.org/abs/2503.07425', 'abstract': 'In recent years, there has been increased interest in the design, training, and evaluation of end-to-end autonomous driving (AD) systems. One often overlooked aspect is the uncertainty of planned trajectories predicted by these systems, despite awareness of their own uncertainty being key to achieve safety and robustness. We propose to estimate this uncertainty by adapting loss prediction from the uncertainty quantification literature. To this end, we introduce a novel light-weight module, dubbed CATPlan, that is trained to decode motion and planning embeddings into estimates of the collision loss used to partially supervise end-to-end AD systems. During inference, these estimates are interpreted as collision risk. We evaluate CATPlan on the safety-critical, nerf-based, closed-loop benchmark NeuroNCAP and find that it manages to detect collisions with a $54.8\\%$ relative improvement to average precision over a GMM-based baseline in which the predicted trajectory is compared to the forecasted trajectories of other road users. Our findings indicate that the addition of CATPlan can lead to safer end-to-end AD systems and hope that our work will spark increased interest in uncertainty quantification for such systems.', 'abstract_zh': '近年来，人们对端到端自动驾驶（AD）系统的设计、训练和评估表现出了浓厚的兴趣。一个经常被忽视的问题是，尽管意识到自身的不确定性对于实现安全和鲁棒性至关重要，但这些系统预测的轨迹不确定性往往被忽视。为此，我们提议通过适应不确定性量化领域的损失预测方法来估计这种不确定性。为此，我们引入了一个新颖的轻量级模块，称为CATPlan，该模块被训练为将运动和规划嵌入解码为用于部分监督端到端AD系统的碰撞损失估计。在推理过程中，这些估计值被解释为碰撞风险。我们使用安全至关重要的、基于nerf的闭环基准NeuroNCAP对CATPlan进行了评估，并发现它在平均精确率上相比基于GMM的基线方法，能够以54.8%的相对改进检测到碰撞。我们的研究结果表明，CATPlan的添加可以使端到端AD系统更加安全，希望我们的工作能够引发对这类系统中不确定性量化更广泛的兴趣。', 'title_zh': 'CATPlan: 基于损失的端到端自主驾驶碰撞预测'}
{'arxiv_id': 'arXiv:2503.07423', 'title': 'Advances in Hybrid Modular Climbing Robots: Design Principles and Refinement Strategies', 'authors': 'Ryan Poon, Ian Hunter', 'link': 'https://arxiv.org/abs/2503.07423', 'abstract': "This paper explores the design strategies for hybrid pole- or trunk-climbing robots, focusing on methods to inform design decisions and assess metrics such as adaptability and performance. A wheeled-grasping hybrid robot with modular, tendon-driven grasping arms and a wheeled drive system mounted on a turret was developed to climb columns of varying diameters. Here, the key innovation is the underactuated arms that can be adjusted to different column sizes by adding or removing modular linkages, though the robot also features capabilities like self-locking (the ability of the robot to stay on the column by friction without power), autonomous grasping, and rotation around the column axis. Mathematical models describe conditions for self-locking and vertical climbing. Experimental results demonstrate the robot's efficacy in climbing and self-locking, validating the proposed models and highlighting the potential for fully automated solutions in industrial applications. This work provides a comprehensive framework for evaluating and designing hybrid climbing robots, contributing to advancements in autonomous robotics for environments where climbing tall structures is critical.", 'abstract_zh': '本文探讨了混合杆攀爬或树攀爬机器人设计策略，重点关注设计决策的指导方法和适应性、性能等评估指标。开发了一种具有模块化、肌腱驱动抓取臂和安装在转塔上的轮式驱动系统的轮式抓取混合机器人，以适应不同直径的柱子攀爬。关键创新在于欠驱动臂可通过增加或减少模块化链接来调整以适应不同柱子尺寸，尽管该机器人还具备自锁（通过摩擦力在无动力情况下保持在柱子上）、自主抓取和柱轴旋转等能力。数学模型描述了自锁和垂直攀爬的条件。实验结果证明了该机器人在攀爬和自锁方面的有效性，验证了所提出模型，并突显了在工业应用中实现完全自动化解决方案的潜力。本文提供了评估和设计混合攀爬机器人的全面框架，推动了在攀爬高大结构至关重要的环境中自主机器人技术的发展。', 'title_zh': '混合模块化攀爬机器人进展：设计原则与优化策略'}
{'arxiv_id': 'arXiv:2503.07411', 'title': 'PER-DPP Sampling Framework and Its Application in Path Planning', 'authors': 'Junzhe Wang', 'link': 'https://arxiv.org/abs/2503.07411', 'abstract': 'Autonomous navigation in intelligent mobile systems represents a core research focus within artificial intelligence-driven robotics. Contemporary path planning approaches face constraints in dynamic environmental responsiveness and multi-objective task scalability, limiting their capacity to address growing intelligent operation requirements. Decision-centric reinforcement learning frameworks, capitalizing on their unique strengths in adaptive environmental interaction and self-optimization, have gained prominence in advanced control system research. This investigation introduces methodological improvements to address sample homogeneity challenges in reinforcement learning experience replay mechanisms. By incorporating determinant point processes (DPP) for diversity assessment, we develop a dual-criteria sampling framework with adaptive selection protocols. This approach resolves representation bias in conventional prioritized experience replay (PER) systems while preserving algorithmic interoperability, offering improved decision optimization for dynamic operational scenarios. Key contributions comprise: Develop a hybrid sampling paradigm (PER-DPP) combining priority sequencing with diversity this http URL on this,create an integrated optimization scheme (PER-DPP-Elastic DQN) merging diversity-aware sampling with adaptive step-size regulation. Comparative simulations in 2D navigation scenarios demonstrate that the elastic step-size component temporarily delays initial convergence speed but synergistically enhances final-stage optimization with PER-DPP integration. The synthesized method generates navigation paths with optimized length efficiency and directional stability.', 'abstract_zh': '基于自主导航的智能移动系统中的强化学习方法改进研究', 'title_zh': 'PER-DPP采样框架及其在路径规划中的应用'}
{'arxiv_id': 'arXiv:2503.07404', 'title': 'Towards Safe Robot Foundation Models', 'authors': 'Maximilian Tölle, Theo Gruner, Daniel Palenicek, Jonas Günster, Puze Liu, Joe Watson, Davide Tateo, Jan Peters', 'link': 'https://arxiv.org/abs/2503.07404', 'abstract': "Robot foundation models hold the potential for deployment across diverse environments, from industrial applications to household tasks. While current research focuses primarily on the policies' generalization capabilities across a variety of tasks, it fails to address safety, a critical requirement for deployment on real-world systems. In this paper, we introduce a safety layer designed to constrain the action space of any generalist policy appropriately. Our approach uses ATACOM, a safe reinforcement learning algorithm that creates a safe action space and, therefore, ensures safe state transitions. By extending ATACOM to generalist policies, our method facilitates their deployment in safety-critical scenarios without requiring any specific safety fine-tuning. We demonstrate the effectiveness of this safety layer in an air hockey environment, where it prevents a puck-hitting agent from colliding with its surroundings, a failure observed in generalist policies.", 'abstract_zh': '机器人基础模型在从工业应用到家庭任务的多种环境中具有部署潜力。虽然当前研究主要关注策略在各种任务间的泛化能力，但未能解决安全性这一在实际系统部署中的关键要求。本文提出了一种安全层，旨在适当地约束任何通用策略的动作空间。我们的方法利用ATACOM安全强化学习算法，创建一个安全的动作空间，从而确保状态的安全部署。通过将ATACOM扩展到通用策略，我们的方法在其无需任何特定安全微调的情况下，能够促进其在安全关键场景中的部署。在桌上冰球环境中，我们展示了这种安全层的有效性，它防止了击球代理与周围环境发生碰撞，这是通用策略中观察到的一种失败情况。', 'title_zh': '面向安全的机器人基础模型研究'}
{'arxiv_id': 'arXiv:2503.07360', 'title': 'AffordDexGrasp: Open-set Language-guided Dexterous Grasp with Generalizable-Instructive Affordance', 'authors': 'Yi-Lin Wei, Mu Lin, Yuhao Lin, Jian-Jian Jiang, Xiao-Ming Wu, Ling-An Zeng, Wei-Shi Zheng', 'link': 'https://arxiv.org/abs/2503.07360', 'abstract': "Language-guided robot dexterous generation enables robots to grasp and manipulate objects based on human commands. However, previous data-driven methods are hard to understand intention and execute grasping with unseen categories in the open set. In this work, we explore a new task, Open-set Language-guided Dexterous Grasp, and find that the main challenge is the huge gap between high-level human language semantics and low-level robot actions. To solve this problem, we propose an Affordance Dexterous Grasp (AffordDexGrasp) framework, with the insight of bridging the gap with a new generalizable-instructive affordance representation. This affordance can generalize to unseen categories by leveraging the object's local structure and category-agnostic semantic attributes, thereby effectively guiding dexterous grasp generation. Built upon the affordance, our framework introduces Affordacne Flow Matching (AFM) for affordance generation with language as input, and Grasp Flow Matching (GFM) for generating dexterous grasp with affordance as input. To evaluate our framework, we build an open-set table-top language-guided dexterous grasp dataset. Extensive experiments in the simulation and real worlds show that our framework surpasses all previous methods in open-set generalization.", 'abstract_zh': '开放集语言引导灵巧抓取', 'title_zh': 'AffordDexGrasp: 开集语言引导的通用指导性抓取'}
{'arxiv_id': 'arXiv:2503.07340', 'title': 'Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning', 'authors': 'Yiting Mao, Dajun Tao, Shengyuan Zhang, Tian Qi, Keqin Li', 'link': 'https://arxiv.org/abs/2503.07340', 'abstract': 'In the field of robot target recognition research driven by artificial intelligence (AI), factors such as the disordered distribution of targets, the complexity of the environment, the massive scale of data, and noise interference have significantly restricted the improvement of target recognition accuracy. Against the backdrop of the continuous iteration and upgrading of current AI technologies, to meet the demand for accurate recognition of disordered targets by intelligent robots in complex and changeable scenarios, this study innovatively proposes an AI - based intelligent robot disordered target recognition method using reinforcement learning. This method processes the collected target images with the bilateral filtering algorithm, decomposing them into low - illumination images and reflection images. Subsequently, it adopts differentiated AI strategies, compressing the illumination images and enhancing the reflection images respectively, and then fuses the two parts of images to generate a new image. On this basis, this study deeply integrates deep learning, a core AI technology, with the reinforcement learning algorithm. The enhanced target images are input into a deep reinforcement learning model for training, ultimately enabling the AI - based intelligent robot to efficiently recognize disordered targets. Experimental results show that the proposed method can not only significantly improve the quality of target images but also enable the AI - based intelligent robot to complete the recognition task of disordered targets with higher efficiency and accuracy, demonstrating extremely high application value and broad development prospects in the field of AI robots.', 'abstract_zh': '基于人工智能的智能机器人乱序目标识别方法：融合增强学习的双边滤波与深度学习技术', 'title_zh': '基于强化学习的机器人无序目标智能识别研究与设计'}
{'arxiv_id': 'arXiv:2503.07338', 'title': 'Temporal Triplane Transformers as Occupancy World Models', 'authors': 'Haoran Xu, Peixi Peng, Guang Tan, Yiqian Chang, Yisen Zhao, Yonghong Tian', 'link': 'https://arxiv.org/abs/2503.07338', 'abstract': "Recent years have seen significant advances in world models, which primarily focus on learning fine-grained correlations between an agent's motion trajectory and the resulting changes in its surrounding environment. However, existing methods often struggle to capture such fine-grained correlations and achieve real-time predictions. To address this, we propose a new 4D occupancy world model for autonomous driving, termed T$^3$Former. T$^3$Former begins by pre-training a compact triplane representation that efficiently compresses the 3D semantically occupied environment. Next, T$^3$Former extracts multi-scale temporal motion features from the historical triplane and employs an autoregressive approach to iteratively predict the next triplane changes. Finally, T$^3$Former combines the triplane changes with the previous ones to decode them into future occupancy results and ego-motion trajectories. Experimental results demonstrate the superiority of T$^3$Former, achieving 1.44$\\times$ faster inference speed (26 FPS), while improving the mean IoU to 36.09 and reducing the mean absolute planning error to 1.0 meters.", 'abstract_zh': 'recent几年来，世界模型取得了显著进展，主要关注于学习智能体运动轨迹与其周围环境变化之间的细粒度相关性。然而，现有方法往往难以捕捉这些细粒度的相关性并实现实时预测。为解决这一问题，我们提出了一种新的4D占用世界模型，名为T$^3$Former。T$^3$Former首先通过预训练一个紧凑的三平面表示来高效地压缩3D语义占用环境。接着，T$^3$Former从历史三平面中提取多尺度时空运动特征，并采用自回归方法迭代预测下一个三平面的变化。最后，T$^3$Former将三平面变化与之前的变化结合，解码为未来占用结果和自我运动轨迹。实验结果表明，T$^3$Former在保持26 FPS的1.44倍更快推理速度的同时，将平均IoU提高到36.09，将平均绝对规划误差降低到1.0米。', 'title_zh': '时空三平面变压器作为占用世界模型'}
{'arxiv_id': 'arXiv:2503.07323', 'title': 'Dynamic Path Navigation for Motion Agents with LLM Reasoning', 'authors': 'Yubo Zhao, Qi Wu, Yifan Wang, Yu-Wing Tai, Chi-Keung Tang', 'link': 'https://arxiv.org/abs/2503.07323', 'abstract': "Large Language Models (LLMs) have demonstrated strong generalizable reasoning and planning capabilities. However, their efficacies in spatial path planning and obstacle-free trajectory generation remain underexplored. Leveraging LLMs for navigation holds significant potential, given LLMs' ability to handle unseen scenarios, support user-agent interactions, and provide global control across complex systems, making them well-suited for agentic planning and humanoid motion generation. As one of the first studies in this domain, we explore the zero-shot navigation and path generation capabilities of LLMs by constructing a dataset and proposing an evaluation protocol. Specifically, we represent paths using anchor points connected by straight lines, enabling movement in various directions. This approach offers greater flexibility and practicality compared to previous methods while remaining simple and intuitive for LLMs. We demonstrate that, when tasks are well-structured in this manner, modern LLMs exhibit substantial planning proficiency in avoiding obstacles while autonomously refining navigation with the generated motion to reach the target. Further, this spatial reasoning ability of a single LLM motion agent interacting in a static environment can be seamlessly generalized in multi-motion agents coordination in dynamic environments. Unlike traditional approaches that rely on single-step planning or local policies, our training-free LLM-based method enables global, dynamic, closed-loop planning, and autonomously resolving collision issues.", 'abstract_zh': '大规模语言模型（LLMs）在展现较强的泛化推理和规划能力方面取得了显著成效，但在空间路径规划和无障碍轨迹生成方面的效能研究尚显不足。利用LLMs进行导航具有巨大的潜力，因为LLMs能够处理未见过的情景，支持用户-代理互动，并在全球范围内控制复杂的系统，使它们非常适合智能体规划和类人动作生成。作为该领域的最早研究之一，我们通过构建数据集并提出评估协议，探索LLMs的零样本导航和路径生成能力。具体地，我们使用连接直线条段的基准点表示路径，允许向各个方向移动。这种方法相较于以往方法更具灵活性和实用性，同时对LLMs来说仍保持简单直观。我们证明，在这种结构良好的任务中，现代LLMs在自主优化生成动作以避开障碍并自主改进导航至目标方面表现出显著的规划能力。此外，单个LLMs动作智能体在其静态环境中的空间推理能力可以无缝推广到动态环境中多动作智能体的协调规划。与依赖单步规划或局部政策的传统方法不同，我们的无训练LLMs方法能够实现全局、动态、闭环规划，并自主解决碰撞问题。', 'title_zh': '基于LLM推理的动态路径导航方法'}
{'arxiv_id': 'arXiv:2503.07321', 'title': 'A Decapod Robot with Rotary Bellows-Enclosed Soft Transmissions', 'authors': 'Yiming He, Yuchen Wang, Yunjia Zhang, Shuguang Li', 'link': 'https://arxiv.org/abs/2503.07321', 'abstract': "Soft crawling robots exhibit efficient locomotion across various terrains and demonstrate robustness to diverse environmental conditions. Here, we propose a valveless soft-legged robot that integrates a pair of rotary bellows-enclosed soft transmission systems (R-BESTS). The proposed R-BESTS can directly transmit the servo rotation into leg swing motion. A timing belt controls the pair of R-BESTS to maintain synchronous rotation in opposite phases, realizing alternating tripod gaits of walking and turning. We explored several designs to understand the role of a reinforcement skeleton in twisting the R-BESTS' input bellows units. The bending sequences of the robot legs are controlled through structural design for the output bellows units. Finally, we demonstrate untethered locomotion with the soft robotic decapod. Experimental results show that our robot can walk at 1.75 centimeters per second (0.07 body length per second) for 90 min, turn with a 15-centimeter (0.6 BL) radius, carry a payload of 200 g, and adapt to different terrains.", 'abstract_zh': '无阀软腿机器人结合了一对旋转椭囊封装的软传动系统（R-BESTS），展现了在多种地形上高效移动并具备对不同环境条件的鲁棒性。', 'title_zh': '一种配备旋转活塞式软传动的十足足机器人'}
{'arxiv_id': 'arXiv:2503.07317', 'title': 'Self-Corrective Task Planning by Inverse Prompting with Large Language Models', 'authors': 'Jiho Lee, Hayun Lee, Jonghyeon Kim, Kyungjae Lee, Eunwoo Kim', 'link': 'https://arxiv.org/abs/2503.07317', 'abstract': 'In robot task planning, large language models (LLMs) have shown significant promise in generating complex and long-horizon action sequences. However, it is observed that LLMs often produce responses that sound plausible but are not accurate. To address these problems, existing methods typically employ predefined error sets or external knowledge sources, requiring human efforts and computation resources. Recently, self-correction approaches have emerged, where LLM generates and refines plans, identifying errors by itself. Despite their effectiveness, they are more prone to failures in correction due to insufficient reasoning. In this paper, we introduce InversePrompt, a novel self-corrective task planning approach that leverages inverse prompting to enhance interpretability. Our method incorporates reasoning steps to provide clear, interpretable feedback. It generates inverse actions corresponding to the initially generated actions and verifies whether these inverse actions can restore the system to its original state, explicitly validating the logical coherence of the generated this http URL results on benchmark datasets show an average 16.3% higher success rate over existing LLM-based task planning methods. Our approach offers clearer justifications for feedback in real-world environments, resulting in more successful task completion than existing self-correction approaches across various scenarios.', 'abstract_zh': '基于逆提示的自纠错任务规划方法', 'title_zh': '基于逆提示词的大语言模型自我修正任务规划'}
{'arxiv_id': 'arXiv:2503.07312', 'title': 'Bioinspired Sensing of Undulatory Flow Fields Generated by Leg Kicks in Swimming', 'authors': 'Jun Wang, Tongsheng Shen, Dexin Zhao, Feitian Zhang', 'link': 'https://arxiv.org/abs/2503.07312', 'abstract': "The artificial lateral line (ALL) is a bioinspired flow sensing system for underwater robots, comprising of distributed flow sensors. The ALL has been successfully applied to detect the undulatory flow fields generated by body undulation and tail-flapping of bioinspired robotic fish. However, its feasibility and performance in sensing the undulatory flow fields produced by human leg kicks during swimming has not been systematically tested and studied. This paper presents a novel sensing framework to investigate the undulatory flow field generated by swimmer's leg kicks, leveraging bioinspired ALL sensing. To evaluate the feasibility of using the ALL system for sensing the undulatory flow fields generated by swimmer leg kicks, this paper designs an experimental platform integrating an ALL system and a lab-fabricated human leg model. To enhance the accuracy of flow sensing, this paper proposes a feature extraction method that dynamically fuses time-domain and time-frequency characteristics. Specifically, time-domain features are extracted using one-dimensional convolutional neural networks and bidirectional long short-term memory networks (1DCNN-BiLSTM), while time-frequency features are extracted using short-term Fourier transform and two-dimensional convolutional neural networks (STFT-2DCNN). These features are then dynamically fused based on attention mechanisms to achieve accurate sensing of the undulatory flow field. Furthermore, extensive experiments are conducted to test various scenarios inspired by human swimming, such as leg kick pattern recognition and kicking leg localization, achieving satisfactory results.", 'abstract_zh': '基于生物启发的人工侧线系统的泳姿腿部踢动诱导波动流场感知框架', 'title_zh': '仿生感知游泳过程中腿踢产生的波动流场'}
{'arxiv_id': 'arXiv:2503.07278', 'title': 'Multi-Robot System for Cooperative Exploration in Unknown Environments: A Survey', 'authors': "Chuqi Wang, Chao Yu, Xin Xu, Yuman Gao, Xinyi Yang, Wenhao Tang, Shu'ang Yu, Yinuo Chen, Feng Gao, ZhuoZhu Jian, Xinlei Chen, Fei Gao, Boyu Zhou, Yu Wang", 'link': 'https://arxiv.org/abs/2503.07278', 'abstract': 'With the advancement of multi-robot technology, cooperative exploration tasks have garnered increasing attention. This paper presents a comprehensive review of multi-robot cooperative exploration systems. First, we review the evolution of robotic exploration and introduce a modular research framework tailored for multi-robot cooperative exploration. Based on this framework, we systematically categorize and summarize key system components. As a foundational module for multi-robot exploration, the localization and mapping module is primarily introduced by focusing on global and relative pose estimation, as well as multi-robot map merging techniques. The cooperative motion module is further divided into learning-based approaches and multi-stage planning, with the latter encompassing target generation, task allocation, and motion planning strategies. Given the communication constraints of real-world environments, we also analyze the communication module, emphasizing how robots exchange information within local communication ranges and under limited transmission capabilities. Finally, we discuss the challenges and future research directions for multi-robot cooperative exploration in light of real-world trends. This review aims to serve as a valuable reference for researchers and practitioners in the field.', 'abstract_zh': '随着多机器人技术的发展，协同探索任务受到了越来越多的关注。本文综述了多机器人协同探索系统。首先，我们回顾了机器人探索的发展，并介绍了一个适用于多机器人协同探索的模块化研究框架。基于这一框架，我们系统地分类和总结了关键系统组件。作为多机器人探索的基础模块，定位与建图模块主要介绍全球和相对位姿估计以及多机器人地图合并技术。协同运动模块进一步分为基于学习的方法和多阶段规划，后者包括目标生成、任务分配和运动规划策略。鉴于实际环境中的通信约束，我们还分析了通信模块，强调机器人在局部通信范围内以及在有限传输能力下的信息交换方式。最后，依据实际趋势，我们讨论了多机器人协同探索所面临的挑战及未来研究方向。本综述旨在为该领域的研究人员和实践者提供有价值的参考。', 'title_zh': '未知环境中的协同探索多机器人系统：一篇综述'}
{'arxiv_id': 'arXiv:2503.07245', 'title': 'WHERE-Bot: a Wheel-less Helical-ring Everting Robot Capable of Omnidirectional Locomotion', 'authors': 'Siyuan Feng, Dengfeng Yan, Jin Liu, Haotong Han, Alexandra Kühl, Shuguang Li', 'link': 'https://arxiv.org/abs/2503.07245', 'abstract': "Compared to conventional wheeled transportation systems designed for flat surfaces, soft robots exhibit exceptional adaptability to various terrains, enabling stable movement in complex environments. However, due to the risk of collision with obstacles and barriers, most soft robots rely on sensors for navigation in unstructured environments with uncertain boundaries. In this work, we present the WHERE-Bot, a wheel-less everting soft robot capable of omnidirectional locomotion. Our WHERE-Bot can navigate through unstructured environments by leveraging its structural and motion advantages rather than relying on sensors for boundary detection. By configuring a spring toy ``Slinky'' into a loop shape, the WHERE-Bot performs multiple rotational motions: spiral-rotating along the hub circumference, self-rotating around the hub's center, and orbiting around a certain point. The robot's trajectories can be reprogrammed by actively altering its mass distribution. The WHERE-Bot shows significant potential for boundary exploration in unstructured environments.", 'abstract_zh': '与设计用于平坦表面的传统轮式运输系统相比，软机器人在各种地形上展现出卓越的适应性，能够在复杂环境中实现稳定的运动。然而，由于存在与障碍物碰撞的风险，大多数软机器人依赖传感器在结构不确定的环境进行导航。在这种工作中，我们介绍了WHERE-Bot，一种无轮的反转软机器人，具备全向运动能力。WHERE-Bot能够通过利用其结构和运动优势来导航无结构环境，而无需依赖传感器进行边界检测。通过将“Slinky”弹簧玩具配置成环形，WHERE-Bot执行多种旋转运动：沿轴 circumference 螺旋旋转、围绕轴心自旋以及围绕某一点轨道运动。通过主动改变其质量分布，可以重新编程机器人的轨迹。WHERE-Bot在无结构环境中具有显著的边界探索潜力。', 'title_zh': 'WHERE-Bot：一种无轮全向移动蜗形推移机器人'}
{'arxiv_id': 'arXiv:2503.07238', 'title': 'Learning and planning for optimal synergistic human-robot coordination in manufacturing contexts', 'authors': 'Samuele Sandrini, Marco Faroni, Nicola Pedrocchi', 'link': 'https://arxiv.org/abs/2503.07238', 'abstract': "Collaborative robotics cells leverage heterogeneous agents to provide agile production solutions. Effective coordination is essential to prevent inefficiencies and risks for human operators working alongside robots. This paper proposes a human-aware task allocation and scheduling model based on Mixed Integer Nonlinear Programming to optimize efficiency and safety starting from task planning stages. The approach exploits synergies that encode the coupling effects between pairs of tasks executed in parallel by the agents, arising from the safety constraints imposed on robot agents. These terms are learned from previous executions using a Bayesian estimation; the inference of the posterior probability distribution of the synergy coefficients is performed using the Markov Chain Monte Carlo method. The synergy enhances task planning by adapting the nominal duration of the plan according to the effect of the operator's presence. Simulations and experimental results demonstrate that the proposed method produces improved human-aware task plans, reducing unuseful interference between agents, increasing human-robot distance, and achieving up to an 18\\% reduction in process execution time.", 'abstract_zh': '协作机器人细胞利用异构代理提供敏捷生产解决方案。基于混合整数非线性规划的人机aware任务分配与调度模型在任务规划阶段优化效率与安全。该方法利用编码了作业组合效用的协同效应，这些效应源自对机器人作业的安全约束，并通过贝叶斯估计从先前执行中学习；后验概率分布的推断使用马尔可夫链蒙特卡洛方法进行。协同作用通过根据操作员存在效应调整计划的名义持续时间来增强任务规划。仿真和实验结果表明，所提方法生成了更合适的人机aware任务计划，减少了代理之间的无用干扰，增加了人机距离，并实现了最高18%的工艺执行时间减少。', 'title_zh': '学习与规划以实现最优协同的人机制造协作'}
{'arxiv_id': 'arXiv:2503.07210', 'title': 'Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping', 'authors': 'Jacob Swindell, Madeleine Darbyshire, Marija Popovic, Riccardo Polvara', 'link': 'https://arxiv.org/abs/2503.07210', 'abstract': 'Accurate agricultural weed mapping using UAVs is crucial for precision farming applications. Traditional methods rely on orthomosaic stitching from rigid flight paths, which is computationally intensive and time-consuming. Gaussian Process (GP)-based mapping offers continuous modelling of the underlying variable (i.e. weed distribution) but requires discretisation for practical tasks like path planning or visualisation. Current implementations often default to quadtrees or gridmaps without systematically evaluating alternatives. This study compares five discretisation methods: quadtrees, wedgelets, top-down binary space partition (BSP) trees using least square error (LSE), bottom-up BSP trees using graph merging, and variable-resolution hexagonal grids. Evaluations on real-world weed distributions measure visual similarity, mean squared error (MSE), and computational efficiency. Results show quadtrees perform best overall, but alternatives excel in specific scenarios: hexagons or BSP LSE suit fields with large, dominant weed patches, while quadtrees are optimal for dispersed small-scale distributions. These findings highlight the need to tailor discretisation approaches to weed distribution patterns (patch size, density, coverage) rather than relying on default methods. By choosing representations based on the underlying distribution, we can improve mapping accuracy and efficiency for precision agriculture applications.', 'abstract_zh': '使用无人机进行精准农业杂草分布准确建模至关重要：比较五种分块方法的优劣', 'title_zh': '基于UAV的精确杂草Mapping优化的离散高斯过程表示方法'}
{'arxiv_id': 'arXiv:2503.07192', 'title': 'Reactive and Safety-Aware Path Replanning for Collaborative Applications', 'authors': 'Cesare Tonola, Marco Faroni, Saeed Abdolshah, Mazin Hamad, Sami Haddadin, Nicola Pedrocchi, Manuel Beschi', 'link': 'https://arxiv.org/abs/2503.07192', 'abstract': "This paper addresses motion replanning in human-robot collaborative scenarios, emphasizing reactivity and safety-compliant efficiency. While existing human-aware motion planners are effective in structured environments, they often struggle with unpredictable human behavior, leading to safety measures that limit robot performance and throughput. In this study, we combine reactive path replanning and a safety-aware cost function, allowing the robot to adjust its path to changes in the human state. This solution reduces the execution time and the need for trajectory slowdowns without sacrificing safety. Simulations and real-world experiments show the method's effectiveness compared to standard human-robot cooperation approaches, with efficiency enhancements of up to 60\\%.", 'abstract_zh': '本文探讨了人在环机器人协作场景中的运动重规划问题，强调了反应性和安全合规的效率。虽然现有的考虑人类的运动规划器在结构化环境中有效，但在应对不可预测的人类行为时往往力不从心，导致安全措施限制了机器人的性能和 throughput。在本研究中，我们将反应性路径重规划和安全性感知的成本函数结合，使机器人能够根据人类状态的变化调整其路径。该解决方案减少了执行时间，并减少了轨迹减速的需求，同时不牺牲安全性。仿真和实际实验表明，与标准的人机协作方法相比，该方法在效率上提高了最多60%。', 'title_zh': '主动响应与安全意识导向的路径重规划方法及其应用'}
{'arxiv_id': 'arXiv:2503.07135', 'title': 'VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation', 'authors': 'Hanzhi Chen, Boyang Sun, Anran Zhang, Marc Pollefeys, Stefan Leutenegger', 'link': 'https://arxiv.org/abs/2503.07135', 'abstract': 'Future robots are envisioned as versatile systems capable of performing a variety of household tasks. The big question remains, how can we bridge the embodiment gap while minimizing physical robot learning, which fundamentally does not scale well. We argue that learning from in-the-wild human videos offers a promising solution for robotic manipulation tasks, as vast amounts of relevant data already exist on the internet. In this work, we present VidBot, a framework enabling zero-shot robotic manipulation using learned 3D affordance from in-the-wild monocular RGB-only human videos. VidBot leverages a pipeline to extract explicit representations from them, namely 3D hand trajectories from videos, combining a depth foundation model with structure-from-motion techniques to reconstruct temporally consistent, metric-scale 3D affordance representations agnostic to embodiments. We introduce a coarse-to-fine affordance learning model that first identifies coarse actions from the pixel space and then generates fine-grained interaction trajectories with a diffusion model, conditioned on coarse actions and guided by test-time constraints for context-aware interaction planning, enabling substantial generalization to novel scenes and embodiments. Extensive experiments demonstrate the efficacy of VidBot, which significantly outperforms counterparts across 13 manipulation tasks in zero-shot settings and can be seamlessly deployed across robot systems in real-world environments. VidBot paves the way for leveraging everyday human videos to make robot learning more scalable.', 'abstract_zh': '未来机器人被视为能够执行多种家庭任务的多功能系统。如何在最小化物理机器人学习的同时跨越体素差距，仍是亟待解决的大问题。我们argue认为，通过学习野生人类视频中的经验为机械臂操作任务提供了一种有前景的解决方案，因为互联网上已有大量相关数据。在本文中，我们提出了一种VidBot框架，该框架利用连续的单目RGB人类视频来实现零样本机械臂操作，并从中学习三维用途。VidBot采用了一种管道来从中显式提取表示，即从视频中提取三维手轨迹，结合深度基础模型和结构光恢复技术，构建时空一致的、以米为单位的三维用途表示，不受体素限制。我们引入了一种从粗到细的用途学习模型，首先从像素空间中识别粗粒度的动作，然后利用扩散模型在给定粗粒度动作和测试时约束的引导下，生成细粒度的交互轨迹，使机械臂能够对新颖场景和体素进行意识交互规划，从而实现显著的泛化。广泛的经验表明，VidBot在零样本设置下的13项操作任务中优于对手，并且可以在现实世界环境中无缝部署到各种机器人系统中。VidBot为利用日常人类视频使机器人学习更具可扩展性铺平了道路。', 'title_zh': 'VidBot: 从野生2D人体视频中学习通用的3D动作以实现零样本机器人 manipulation'}
{'arxiv_id': 'arXiv:2503.07111', 'title': 'PoseLess: Depth-Free Vision-to-Joint Control via Direct Image Mapping with VLM', 'authors': 'Alan Dao, Dinh Bach Vu, Tuan Le Duc Anh, Bui Quang Huy', 'link': 'https://arxiv.org/abs/2503.07111', 'abstract': 'This paper introduces PoseLess, a novel framework for robot hand control that eliminates the need for explicit pose estimation by directly mapping 2D images to joint angles using tokenized representations. Our approach leverages synthetic training data generated through randomized joint configurations, enabling zero-shot generalization to real-world scenarios and cross-morphology transfer from robotic to human hands. By tokenizing visual inputs and employing a transformer-based decoder, PoseLess achieves robust, low-latency control while addressing challenges such as depth ambiguity and data scarcity. Experimental results demonstrate competitive performance in joint angle prediction accuracy without relying on any human-labelled dataset.', 'abstract_zh': 'PoseLess：一种无需显式姿态估计的机器人手控制新型框架', 'title_zh': 'PoseLess: 无需深度的视图到关节控制直接图像映射ewith VLM'}
{'arxiv_id': 'arXiv:2503.07087', 'title': 'iManip: Skill-Incremental Learning for Robotic Manipulation', 'authors': 'Zexin Zheng, Jia-Feng Cai, Xiao-Ming Wu, Yi-Lin Wei, Yu-Ming Tang, Wei-Shi Zheng', 'link': 'https://arxiv.org/abs/2503.07087', 'abstract': 'The development of a generalist agent with adaptive multiple manipulation skills has been a long-standing goal in the robotics community. In this paper, we explore a crucial task, skill-incremental learning, in robotic manipulation, which is to endow the robots with the ability to learn new manipulation skills based on the previous learned knowledge without re-training. First, we build a skill-incremental environment based on the RLBench benchmark, and explore how traditional incremental methods perform in this setting. We find that they suffer from severe catastrophic forgetting due to the previous methods on classification overlooking the characteristics of temporality and action complexity in robotic manipulation tasks. Towards this end, we propose an incremental Manip}ulation framework, termed iManip, to mitigate the above issues. We firstly design a temporal replay strategy to maintain the integrity of old skills when learning new skill. Moreover, we propose the extendable PerceiverIO, consisting of an action prompt with extendable weight to adapt to new action primitives in new skill. Extensive experiments show that our framework performs well in Skill-Incremental Learning. Codes of the skill-incremental environment with our framework will be open-source.', 'abstract_zh': '通用机器人在适配性多技能学习下的发展一直是机器人研究领域的长期目标。本文探索了机器人操作中关键任务——技能增量学习，旨在使机器人能够在不重新训练的情况下，基于先前学习的知识来学习新的操作技能。首先，基于RLBench基准，构建了一个技能增量环境，并探讨了传统增量方法在这种环境中的表现。我们发现，由于传统方法在分类任务中忽略了机器人操作任务中的时间和动作复杂性特征，导致了严重的灾难性遗忘现象。为此，我们提出了一种增量操作框架iManip，以缓解上述问题。我们首先设计了一种时间回放策略，以在学习新技能时保持旧技能的完整性。此外，我们提出了可扩展的PerceiverIO，其中包括一个可扩展的动作提示，以便适应新技能中的新动作基元。广泛的实验表明，我们的框架在技能增量学习中表现良好。我们的框架下的技能增量环境代码将开源。', 'title_zh': 'iManip: 基于技能递增学习的机器人操作contri贡献力量。'}
{'arxiv_id': 'arXiv:2503.07085', 'title': 'RS2V-L: Vehicle-Mounted LiDAR Data Generation from Roadside Sensor Observations', 'authors': 'Ruidan Xing, Runyi Huang, Qing Xu, Lei He', 'link': 'https://arxiv.org/abs/2503.07085', 'abstract': "End-to-end autonomous driving solutions, which process multi-modal sensory data to directly generate refined control commands, have become a dominant paradigm in autonomous driving research. However, these approaches predominantly depend on single-vehicle data collection for model training and optimization, resulting in significant challenges such as high data acquisition and annotation costs, the scarcity of critical driving scenarios, and fragmented datasets that impede model generalization. To mitigate these limitations, we introduce RS2V-L, a novel framework for reconstructing and synthesizing vehicle-mounted LiDAR data from roadside sensor observations. Specifically, our method transforms roadside LiDAR point clouds into the vehicle-mounted LiDAR coordinate system by leveraging the target vehicle's relative pose. Subsequently, high-fidelity vehicle-mounted LiDAR data is synthesized through virtual LiDAR modeling, point cloud classification, and resampling techniques. To the best of our knowledge, this is the first approach to reconstruct vehicle-mounted LiDAR data from roadside sensor inputs. Extensive experimental evaluations demonstrate that incorporating the generated data into model training-complementing the KITTI dataset-enhances 3D object detection accuracy by over \\text{30\\%} while improving the efficiency of end-to-end autonomous driving data generation by more than an order of magnitude. These findings strongly validate the effectiveness of the proposed method and underscore its potential in reducing dependence on costly vehicle-mounted data collection while improving the robustness of autonomous driving models.", 'abstract_zh': '基于路边传感器观测重建和合成车载LiDAR数据的RS2V-L框架', 'title_zh': 'RS2V-L：基于路边传感器观测数据的车载激光雷达数据生成'}
{'arxiv_id': 'arXiv:2503.07049', 'title': 'VMTS: Vision-Assisted Teacher-Student Reinforcement Learning for Multi-Terrain Locomotion in Bipedal Robots', 'authors': 'Fu Chen, Rui Wan, Peidong Liu, Nanxing Zheng, Bo Zhou', 'link': 'https://arxiv.org/abs/2503.07049', 'abstract': "Bipedal robots, due to their anthropomorphic design, offer substantial potential across various applications, yet their control is hindered by the complexity of their structure. Currently, most research focuses on proprioception-based methods, which lack the capability to overcome complex terrain. While visual perception is vital for operation in human-centric environments, its integration complicates control further. Recent reinforcement learning (RL) approaches have shown promise in enhancing legged robot locomotion, particularly with proprioception-based methods. However, terrain adaptability, especially for bipedal robots, remains a significant challenge, with most research focusing on flat-terrain scenarios. In this paper, we introduce a novel mixture of experts teacher-student network RL strategy, which enhances the performance of teacher-student policies based on visual inputs through a simple yet effective approach. Our method combines terrain selection strategies with the teacher policy, resulting in superior performance compared to traditional models. Additionally, we introduce an alignment loss between the teacher and student networks, rather than enforcing strict similarity, to improve the student's ability to navigate diverse terrains. We validate our approach experimentally on the Limx Dynamic P1 bipedal robot, demonstrating its feasibility and robustness across multiple terrain types.", 'abstract_zh': '双足机器人由于其类人的设计，在各类应用中具备巨大潜力，但其控制受到结构复杂性的阻碍。目前，大多研究集中在基于 proprioception 的方法上，这些方法难以克服复杂地形。尽管视觉感知对于人在中心环境的操作至关重要，但其集成会进一步增加控制的复杂性。最近的强化学习（RL）方法在提高-legged机器人行走能力方面显示出前景，特别是在基于 proprioception 的方法上。然而，地形适应性，尤其是对于双足机器人，仍然是一个重大挑战，目前大多数研究集中在平坦地形场景上。本文我们提出了一种新颖的专家混合教师-学生网络 RL 策略，通过一个简单而有效的方法增强了基于视觉输入的教师-学生策略的表现。我们的方法结合了地形选择策略与教师策略，相比传统模型表现出更优的性能。此外，我们引入了教师网络与学生网络之间的对齐损失，而非强制严格相似性，以提高学生网络在多变地形下的导航能力。我们在 Limx Dynamic P1 双足机器人上进行了实验验证，展示了其在多种地形类型下的可行性和鲁棒性。', 'title_zh': '视觉辅助师徒强化学习在双足机器人多地形运动中的应用'}
{'arxiv_id': 'arXiv:2503.07020', 'title': 'Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense', 'authors': 'Yuting Hu, Chenhui Xu, Ruiyang Qin, Dancheng Liu, Amir Nassereldine, Yiyu Shi, Jinjun Xiong', 'link': 'https://arxiv.org/abs/2503.07020', 'abstract': 'Partial perception deficits can compromise autonomous vehicle safety by disrupting environmental understanding. Current protocols typically respond with immediate stops or minimal-risk maneuvers, worsening traffic flow and lacking flexibility for rare driving scenarios. In this paper, we propose LLM-RCO, a framework leveraging large language models to integrate human-like driving commonsense into autonomous systems facing perception deficits. LLM-RCO features four key modules: hazard inference, short-term motion planner, action condition verifier, and safety constraint generator. These modules interact with the dynamic driving environment, enabling proactive and context-aware control actions to override the original control policy of autonomous agents. To improve safety in such challenging conditions, we construct DriveLM-Deficit, a dataset of 53,895 video clips featuring deficits of safety-critical objects, complete with annotations for LLM-based hazard inference and motion planning fine-tuning. Extensive experiments in adverse driving conditions with the CARLA simulator demonstrate that systems equipped with LLM-RCO significantly improve driving performance, highlighting its potential for enhancing autonomous driving resilience against adverse perception deficits. Our results also show that LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements instead of conservative stops in the context of perception deficits.', 'abstract_zh': '部分感知缺陷会导致自动驾驶汽车安全受损，因为它会破坏对环境的理解。当前的方案通常会引发立即停车或最低风险的操作，这会恶化交通流量且缺乏针对罕见驾驶场景的灵活性。本文提出了一种名为LLM-RCO的框架，该框架利用大型语言模型将类似人类驾驶的常识性知识整合到面对感知缺陷的自主系统中。LLM-RCO包含四个关键模块：风险推理、短期运动规划器、动作条件验证器和安全约束生成器。这些模块与动态驾驶环境互动，能够主动且情境感知地控制操作以覆盖原始的自主代理控制策略。为了在这些具有挑战性的条件下改善安全性，我们构建了DriveLM-Deficit数据集，包含53,895段视频片段，展示了关键安全对象的缺陷，并附有人类语言模型（LLM）风险推理和运动规划微调的注释。使用CARLA模拟器在不利驾驶条件下的广泛实验表明，配备LLM-RCO的系统能够显著提高驾驶性能，突显了其在抵御不良感知缺陷方面增强自动驾驶鲁棒性的潜力。我们的研究表明，使用DriveLM-Deficit微调的LLM能够在感知缺陷的情境下使汽车采取更为积极的行动，而非保守的停止。', 'title_zh': '基于多模态大语言模型常识对抗自动驾驶中的部分感知缺陷'}
{'arxiv_id': 'arXiv:2503.07017', 'title': 'How to Train Your Robots? The Impact of Demonstration Modality on Imitation Learning', 'authors': 'Haozhuo Li, Yuchen Cui, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2503.07017', 'abstract': 'Imitation learning is a promising approach for learning robot policies with user-provided data. The way demonstrations are provided, i.e., demonstration modality, influences the quality of the data. While existing research shows that kinesthetic teaching (physically guiding the robot) is preferred by users for the intuitiveness and ease of use, the majority of existing manipulation datasets were collected through teleoperation via a VR controller or spacemouse. In this work, we investigate how different demonstration modalities impact downstream learning performance as well as user experience. Specifically, we compare low-cost demonstration modalities including kinesthetic teaching, teleoperation with a VR controller, and teleoperation with a spacemouse controller. We experiment with three table-top manipulation tasks with different motion constraints. We evaluate and compare imitation learning performance using data from different demonstration modalities, and collected subjective feedback on user experience. Our results show that kinesthetic teaching is rated the most intuitive for controlling the robot and provides cleanest data for best downstream learning performance. However, it is not preferred as the way for large-scale data collection due to the physical load. Based on such insight, we propose a simple data collection scheme that relies on a small number of kinesthetic demonstrations mixed with data collected through teleoperation to achieve the best overall learning performance while maintaining low data-collection effort.', 'abstract_zh': '基于不同演示模态的模仿学习研究：从用户提供的数据中学习机器人策略', 'title_zh': '如何训练你的机器人？示范模态对模仿学习的影响'}
{'arxiv_id': 'arXiv:2503.07013', 'title': 'Learning Nash Equilibrial Hamiltonian for Two-Player Collision-Avoiding Interactions', 'authors': 'Lei Zhang, Siddharth Das, Tanner Merry, Wenlong Zhang, Yi Ren', 'link': 'https://arxiv.org/abs/2503.07013', 'abstract': "We consider the problem of learning Nash equilibrial policies for two-player risk-sensitive collision-avoiding interactions. Solving the Hamilton-Jacobi-Isaacs equations of such general-sum differential games in real time is an open challenge due to the discontinuity of equilibrium values on the state space. A common solution is to learn a neural network that approximates the equilibrium Hamiltonian for given system states and actions. The learning, however, is usually supervised and requires a large amount of sample equilibrium policies from different initial states in order to mitigate the risks of collisions. This paper claims two contributions towards more data-efficient learning of equilibrium policies: First, instead of computing Hamiltonian through a value network, we show that the equilibrium co-states have simple structures when collision avoidance dominates the agents' loss functions and system dynamics is linear, and therefore are more data-efficient to learn. Second, we introduce theory-driven active learning to guide data sampling, where the acquisition function measures the compliance of the predicted co-states to Pontryagin's Maximum Principle. On an uncontrolled intersection case, the proposed method leads to more generalizable approximation of the equilibrium policies, and in turn, lower collision probabilities, than the state-of-the-art under the same data acquisition budget.", 'abstract_zh': '我们考虑两-player风险敏感碰撞避免交互中学习纳什均衡策略的问题。由于均衡值在状态空间上的非连续性，实时求解此类常和微分博弈的哈密尔顿-雅可比-伊斯阿斯方程仍然是一个开放挑战。一种常见的解决方案是学习一个神经网络来近似给定系统状态和动作的均衡哈密尔顿量。然而，这种学习通常是监督式的，需要大量不同初始状态下的样本均衡策略以减轻碰撞风险。本文提出了两种更高效学习均衡策略的贡献：首先，当避免碰撞是代理损失函数和系统动力学的主要因素时，我们证明均衡共态具有简单的结构，因此更具数据效率。其次，我们引入理论驱动的主动学习来指导数据采样，其中获取函数衡量预测共态与庞特里亚金最大原则的一致性。在无控交叉口情况下，所提出的方法在相同的数据采集预算下，其均衡策略的泛化性更强，从而降低了碰撞概率，优于现有方法。', 'title_zh': '学习两玩家避碰交互的纳什均衡哈密尔顿量'}
{'arxiv_id': 'arXiv:2503.07006', 'title': 'HELM: Human-Preferred Exploration with Language Models', 'authors': 'Shuhao Liao, Xuxin Lv, Yuhong Cao, Jeric Lew, Wenjun Wu, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2503.07006', 'abstract': 'In autonomous exploration tasks, robots are required to explore and map unknown environments while efficiently planning in dynamic and uncertain conditions. Given the significant variability of environments, human operators often have specific preference requirements for exploration, such as prioritizing certain areas or optimizing for different aspects of efficiency. However, existing methods struggle to accommodate these human preferences adaptively, often requiring extensive parameter tuning or network retraining. With the recent advancements in Large Language Models (LLMs), which have been widely applied to text-based planning and complex reasoning, their potential for enhancing autonomous exploration is becoming increasingly promising. Motivated by this, we propose an LLM-based human-preferred exploration framework that seamlessly integrates a mobile robot system with LLMs. By leveraging the reasoning and adaptability of LLMs, our approach enables intuitive and flexible preference control through natural language while maintaining a task success rate comparable to state-of-the-art traditional methods. Experimental results demonstrate that our framework effectively bridges the gap between human intent and policy preference in autonomous exploration, offering a more user-friendly and adaptable solution for real-world robotic applications.', 'abstract_zh': '基于大语言模型的人类偏好自主探索框架', 'title_zh': 'HELM: 人类喜好的探索与语言模型'}
{'arxiv_id': 'arXiv:2503.06995', 'title': 'Physics-informed Neural Network Predictive Control for Quadruped Locomotion', 'authors': 'Haolin Li, Yikang Chai, Bailin Lv, Lecheng Ruan, Hang Zhao, Ye Zhao, Jianwen Luo', 'link': 'https://arxiv.org/abs/2503.06995', 'abstract': "This study introduces a unified control framework that addresses the challenge of precise quadruped locomotion with unknown payloads, named as online payload identification-based physics-informed neural network predictive control (OPI-PINNPC). By integrating online payload identification with physics-informed neural networks (PINNs), our approach embeds identified mass parameters directly into the neural network's loss function, ensuring physical consistency while adapting to changing load conditions. The physics-constrained neural representation serves as an efficient surrogate model within our nonlinear model predictive controller, enabling real-time optimization despite the complex dynamics of legged locomotion. Experimental validation on our quadruped robot platform demonstrates 35% improvement in position and orientation tracking accuracy across diverse payload conditions (25-100 kg), with substantially faster convergence compared to previous adaptive control methods. Our framework provides a adaptive solution for maintaining locomotion performance under variable payload conditions without sacrificing computational efficiency.", 'abstract_zh': '基于在线负载识别的物理约束神经网络预测控制（OPI-PINNPC）的统一控制框架', 'title_zh': '基于物理信息的神经网络预测控制在四足运动中的应用'}
{'arxiv_id': 'arXiv:2503.06994', 'title': 'Parametric Value Approximation for General-sum Differential Games with State Constraints', 'authors': 'Lei Zhang, Mukesh Ghimire, Wenlong Zhang, Zhe Xu, Yi Ren', 'link': 'https://arxiv.org/abs/2503.06994', 'abstract': 'General-sum differential games can approximate values solved by Hamilton-Jacobi-Isaacs (HJI) equations for efficient inference when information is incomplete. However, solving such games through conventional methods encounters the curse of dimensionality (CoD). Physics-informed neural networks (PINNs) offer a scalable approach to alleviate the CoD and approximate values, but there exist convergence issues for value approximations through vanilla PINNs when state constraints lead to values with large Lipschitz constants, particularly in safety-critical applications. In addition to addressing CoD, it is necessary to learn a generalizable value across a parametric space of games, rather than training multiple ones for each specific player-type configuration. To overcome these challenges, we propose a Hybrid Neural Operator (HNO), which is an operator that can map parameter functions for games to value functions. HNO leverages informative supervised data and samples PDE-driven data across entire spatial-temporal space for model refinement. We evaluate HNO on 9D and 13D scenarios with nonlinear dynamics and state constraints, comparing it against a Supervised Neural Operator (a variant of DeepONet). Under the same computational budget and training data, HNO outperforms SNO for safety performance. This work provides a step toward scalable and generalizable value function approximation, enabling real-time inference for complex human-robot or multi-agent interactions.', 'abstract_zh': '一般和差博弈可以通过Hamilton-Jacobi-Isaacs (HJI) 方程近似求解值，从而在信息不完备时实现高效推理。然而，通过传统方法解决此类博弈会遭遇维数灾。物理信息神经网络（PINNs）提供了一种可扩展的方法来缓解维数灾并近似求解值，但对于受状态约束导致Lipschitz常数较大的值，vanilla PINNs存在收敛问题，特别是在关键安全应用中。除了解决维数灾之外，还需要在一个参数化的博弈空间中学习泛化的值，而不是为每个特定玩家配置训练多个模型。为克服这些挑战，我们提出了一种混合神经算子（HNO），它可以将博弈的参数函数映射到值函数。HNO利用有信息的监督数据并采样来自整个时空域的PDE驱动数据以进行模型校准。我们在具有非线性动力学和状态约束的9D和13D场景中评估了HNO，并将其与监督神经算子（SNO，DeepONet的变体）进行了对比。在相同的计算预算和训练数据下，HNO在安全性性能上优于SNO。这项工作为可扩展和可泛化的值函数近似提供了一个方向，从而实现在复杂的人机交互或多智能体交互中的实时推理。', 'title_zh': '带有状态约束的一般和微分博弈的参数值近似估计'}
{'arxiv_id': 'arXiv:2503.06953', 'title': 'MERLION: Marine ExploRation with Language guIded Online iNformative Visual Sampling and Enhancement', 'authors': 'Shrutika Vishal Thengane, Marcel Bartholomeus Prasetyo, Yu Xiang Tan, Malika Meghjani', 'link': 'https://arxiv.org/abs/2503.06953', 'abstract': "Autonomous and targeted underwater visual monitoring and exploration using Autonomous Underwater Vehicles (AUVs) can be a challenging task due to both online and offline constraints. The online constraints comprise limited onboard storage capacity and communication bandwidth to the surface, whereas the offline constraints entail the time and effort required for the selection of desired key frames from the video data. An example use case of targeted underwater visual monitoring is finding the most interesting visual frames of fish in a long sequence of an AUV's visual experience. This challenge of targeted informative sampling is further aggravated in murky waters with poor visibility. In this paper, we present MERLION, a novel framework that provides semantically aligned and visually enhanced summaries for murky underwater marine environment monitoring and exploration. Specifically, our framework integrates (a) an image-text model for semantically aligning the visual samples to the users' needs, (b) an image enhancement model for murky water visual data and (c) an informative sampler for summarizing the monitoring experience. We validate our proposed MERLION framework on real-world data with user studies and present qualitative and quantitative results using our evaluation metric and show improved results compared to the state-of-the-art approaches. We have open-sourced the code for MERLION at the following link this https URL.", 'abstract_zh': '使用自主水下机器人（AUVs）进行自主和定向的水下视觉监控与探索是一项由于在线和离线约束而具有挑战性的任务。在线约束包括有限的机载存储容量和与水面的通信带宽，而离线约束则涉及从视频数据中选择所需关键帧所需的时间和努力。定向水下视觉监控的一个示例用例是在AUV长时间视觉体验序列中找到鱼类的最有趣视觉帧。在能见度差的浑浊水域中，这一以信息为导向的采样挑战更为严峻。本文提出了一种名为MERLION的新型框架，提供了语义对齐且视觉增强的摘要，用于浑浊水下海洋环境的监控与探索。具体而言，我们的框架融合了(a) 图像-文本模型，用于语义对齐视觉样本以满足用户需求，(b) 浑浊水可视化数据增强模型，以及(c) 信息性采样器，用于总结监控体验。我们通过用户研究在实际数据上验证了我们提出的MERLION框架，并使用评价指标展示了定性和定量结果，结果优于现有最先进的方法。我们已开源MERLION的代码，链接如下：https://github.com/<your-repo-name>。', 'title_zh': 'MERLION: 海洋探索与语言引导的在线信息性视觉采样和增强'}
{'arxiv_id': 'arXiv:2503.06937', 'title': 'Handle Object Navigation as Weighted Traveling Repairman Problem', 'authors': 'Ruimeng Liu, Xinhang Xu, Shenghai Yuan, Lihua Xie', 'link': 'https://arxiv.org/abs/2503.06937', 'abstract': 'Zero-Shot Object Navigation (ZSON) requires agents to navigate to objects specified via open-ended natural language without predefined categories or prior environmental knowledge. While recent methods leverage foundation models or multi-modal maps, they often rely on 2D representations and greedy strategies or require additional training or modules with high computation load, limiting performance in complex environments and real applications. We propose WTRP-Searcher, a novel framework that formulates ZSON as a Weighted Traveling Repairman Problem (WTRP), minimizing the weighted waiting time of viewpoints. Using a Vision-Language Model (VLM), we score viewpoints based on object-description similarity, projected onto a 2D map with depth information. An open-vocabulary detector identifies targets, dynamically updating goals, while a 3D embedding feature map enhances spatial awareness and environmental recall. WTRP-Searcher outperforms existing methods, offering efficient global planning and improved performance in complex ZSON tasks. Code and more demos will be avaliable on this https URL.', 'abstract_zh': '零样本对象导航（ZSON）要求智能体依据开放领域自然语言描述导航至指定对象，无需预定义类别或先验环境知识。尽管近期方法利用基础模型或多模态地图，但它们常常依赖2D表示和贪婪策略，或需要额外训练和具有高计算负载的模块，从而在复杂环境和实际应用中限制了性能。我们提出了WTRP-Searcher，一种将ZSON形式化为加权旅行修复员问题（WTRP）的新框架，以最小化视点的加权等待时间。利用视觉-语言模型（VLM），我们基于对象描述相似性对视点进行评分，并投影到具有深度信息的2D地图上。开放词汇检测器识别目标，动态更新目标，而3D嵌入特征图增强空间感知和环境记忆。WTRP-Searcher在现有方法中表现出色，提供高效的全局规划并改善了复杂ZSON任务的性能。相关代码和更多演示可在以下链接获取：this https URL。', 'title_zh': '处理对象导航问题作为加权旅行修理工问题'}
{'arxiv_id': 'arXiv:2503.06922', 'title': 'Accelerated Quasi-Static FEM for Real-Time Modeling of Continuum Robots with Multiple Contacts and Large Deformation', 'authors': 'Hao Chen, Jian Chen, Xinran Liu, Zihui Zhang, Yuanrui Huang, Zhongkai Zhang, Hongbin Liu', 'link': 'https://arxiv.org/abs/2503.06922', 'abstract': 'Continuum robots offer high flexibility and multiple degrees of freedom, making them ideal for navigating narrow lumens. However, accurately modeling their behavior under large deformations and frequent environmental contacts remains challenging. Current methods for solving the deformation of these robots, such as the Model Order Reduction and Gauss-Seidel (GS) methods, suffer from significant drawbacks. They experience reduced computational speed as the number of contact points increases and struggle to balance speed with model accuracy. To overcome these limitations, we introduce a novel finite element method (FEM) named Acc-FEM. Acc-FEM employs a large deformation quasi-static finite element model and integrates an accelerated solver scheme to handle multi-contact simulations efficiently. Additionally, it utilizes parallel computing with Graphics Processing Units (GPU) for real-time updates of the finite element models and collision detection. Extensive numerical experiments demonstrate that Acc-FEM significantly improves computational efficiency in modeling continuum robots with multiple contacts while achieving satisfactory accuracy, addressing the deficiencies of existing methods.', 'abstract_zh': '连续体机器人提供了高灵活性和多自由度，使其特别适用于狭窄管道的导航。然而，准确 modeling 其在大变形和频繁环境接触情况下的行为仍然是具有挑战性的。当前用于解决这些机器人变形的方法，如模型降阶和高斯-赛德尔方法，存在显著的缺点。它们会随着接触点数量的增加而计算速度显著下降，并且难以在速度和模型精度之间取得平衡。为克服这些局限性，我们提出了一个新的有限元方法（FEM）——Acc-FEM。Acc-FEM 利用大变形准静态有限元模型，并结合了加速求解方案来高效处理多接触仿真。此外，它利用图形处理单元（GPU）进行并行计算，以实现实时有限元模型更新和碰撞检测。大量数值实验表明，Acc-FEM 在建模具有多个接触点的连续体机器人时显著提高了计算效率，同时实现了满意的精度，解决了现有方法的缺陷。', 'title_zh': '加速准静态有限元法在多重接触与大变形下实时建模连续体机器人'}
{'arxiv_id': 'arXiv:2503.06892', 'title': 'SafePlan: Leveraging Formal Logic and Chain-of-Thought Reasoning for Enhanced Safety in LLM-based Robotic Task Planning', 'authors': 'Ike Obi, Vishnunandan L.N. Venkatesh, Weizheng Wang, Ruiqi Wang, Dayoon Suh, Temitope I. Amosa, Wonse Jo, Byung-Cheol Min', 'link': 'https://arxiv.org/abs/2503.06892', 'abstract': 'Robotics researchers increasingly leverage large language models (LLM) in robotics systems, using them as interfaces to receive task commands, generate task plans, form team coalitions, and allocate tasks among multi-robot and human agents. However, despite their benefits, the growing adoption of LLM in robotics has raised several safety concerns, particularly regarding executing malicious or unsafe natural language prompts. In addition, ensuring that task plans, team formation, and task allocation outputs from LLMs are adequately examined, refined, or rejected is crucial for maintaining system integrity. In this paper, we introduce SafePlan, a multi-component framework that combines formal logic and chain-of-thought reasoners for enhancing the safety of LLM-based robotics systems. Using the components of SafePlan, including Prompt Sanity COT Reasoner and Invariant, Precondition, and Postcondition COT reasoners, we examined the safety of natural language task prompts, task plans, and task allocation outputs generated by LLM-based robotic systems as means of investigating and enhancing system safety profile. Our results show that SafePlan outperforms baseline models by leading to 90.5% reduction in harmful task prompt acceptance while still maintaining reasonable acceptance of safe tasks.', 'abstract_zh': '基于大型语言模型的机器人系统安全性增强框架SafePlan', 'title_zh': 'SafePlan: 利用形式逻辑和链式推理提高基于LLM的机器人任务规划安全性'}
{'arxiv_id': 'arXiv:2503.06891', 'title': 'AKF-LIO: LiDAR-Inertial Odometry with Gaussian Map by Adaptive Kalman Filter', 'authors': 'Xupeng Xie, Ruoyu Geng, Jun Ma, Boyu Zhou', 'link': 'https://arxiv.org/abs/2503.06891', 'abstract': 'Existing LiDAR-Inertial Odometry (LIO) systems typically use sensor-specific or environment-dependent measurement covariances during state estimation, leading to laborious parameter tuning and suboptimal performance in challenging conditions (e.g., sensor degeneracy and noisy observations). Therefore, we propose an Adaptive Kalman Filter (AKF) framework that dynamically estimates time-varying noise covariances of LiDAR and Inertial Measurement Unit (IMU) measurements, enabling context-aware confidence weighting between sensors. During LiDAR degeneracy, the system prioritizes IMU data while suppressing contributions from unreliable inputs like moving objects or noisy point clouds. Furthermore, a compact Gaussian-based map representation is introduced to model environmental planarity and spatial noise. A correlated registration strategy ensures accurate plane normal estimation via pseudo-merge, even in unstructured environments like forests. Extensive experiments validate the robustness of the proposed system across diverse environments, including dynamic scenes and geometrically degraded scenarios. Our method achieves reliable localization results across all MARS-LVIG sequences and ranks 8th on the KITTI Odometry Benchmark. The code will be released at this https URL.', 'abstract_zh': '现有的激光雷达-惯性里程计（LIO）系统通常在状态估计过程中使用特定于传感器或环境依赖性的测量协方差，导致繁琐的参数调整并在具有挑战性的情况下（例如传感器退化和观测噪声）表现出非最优性能。因此，我们提出了一种自适应卡尔曼滤波器（AKF）框架，该框架动态估计激光雷达和惯性测量单元（IMU）测量的时间变化噪声协方差，使传感器之间的信心加权具有上下文感知能力。在激光雷达退化期间，系统优先采用IMU数据，抑制来自不可靠输入（如移动物体或噪声点云）的贡献。此外，引入了一种紧凑的基于高斯的映射表示法来建模环境的平面性和空间噪声。通过伪合并的协同注册策略即使在未结构化的环境中（如森林）也能确保准确的平面法线估计。广泛的实验验证了所提出系统的鲁棒性，覆盖了各种环境，包括动态场景和几何降级的情况。我们的方法在所有MARS-LVIG序列中实现了可靠的定位结果，并在KITTI里程计基准测试中排名第8。代码将在此处发布：https://xxxxx。', 'title_zh': 'AKF-LIO：基于自适应卡尔曼滤波的激光雷达-惯性里程计'}
{'arxiv_id': 'arXiv:2503.06890', 'title': 'AirSwarm: Enabling Cost-Effective Multi-UAV Research with COTS drones', 'authors': 'Xiaowei Li, Kuan Xu, Fen Liu, Ruofei Bai, Shenghai Yuan, Lihua Xie', 'link': 'https://arxiv.org/abs/2503.06890', 'abstract': 'Traditional unmanned aerial vehicle (UAV) swarm missions rely heavily on expensive custom-made drones with onboard perception or external positioning systems, limiting their widespread adoption in research and education. To address this issue, we propose AirSwarm. AirSwarm democratizes multi-drone coordination using low-cost commercially available drones such as Tello or Anafi, enabling affordable swarm aerial robotics research and education. Key innovations include a hierarchical control architecture for reliable multi-UAV coordination, an infrastructure-free visual SLAM system for precise localization without external motion capture, and a ROS-based software framework for simplified swarm development. Experiments demonstrate cm-level tracking accuracy, low-latency control, communication failure resistance, formation flight, and trajectory tracking. By reducing financial and technical barriers, AirSwarm makes multi-robot education and research more accessible. The complete instructions and open source code will be available at', 'abstract_zh': '传统的无人机集群任务高度依赖昂贵的定制无人机或外部定位系统，限制了其在研究和教育中的广泛应用。为了解决这一问题，我们提出了AirSwarm。AirSwarm利用低成本的商用无人机（如Tello或Anafi）实现多无人机协调的民主化，从而促进可负担的集群空中机器人研究和教育。关键创新包括用于可靠多无人机协同的分层控制架构、无需外部动作捕捉的基础设施免费视觉SLAM系统以及基于ROS的软件框架以简化集群开发。实验展示了厘米级追踪精度、低延迟控制、通信故障冗余、编队飞行和轨迹跟踪。通过降低财务和技术障碍，AirSwarm使多机器人教育和研究更加普及。完整的使用说明和开源代码将在。', 'title_zh': 'AirSwarm: 使多无人机研究成本有效的商用现货无人机平台'}
{'arxiv_id': 'arXiv:2503.06869', 'title': 'Collective Behavior Clone with Visual Attention via Neural Interaction Graph Prediction', 'authors': 'Kai Li, Zhao Ma, Liang Li, Shiyu Zhao', 'link': 'https://arxiv.org/abs/2503.06869', 'abstract': 'In this paper, we propose a framework, collective behavioral cloning (CBC), to learn the underlying interaction mechanism and control policy of a swarm system. Given the trajectory data of a swarm system, we propose a graph variational autoencoder (GVAE) to learn the local interaction graph. Based on the interaction graph and swarm trajectory, we use behavioral cloning to learn the control policy of the swarm system. To demonstrate the practicality of CBC, we deploy it on a real-world decentralized vision-based robot swarm system. A visual attention network is trained based on the learned interaction graph for online neighbor selection. Experimental results show that our method outperforms previous approaches in predicting both the interaction graph and swarm actions with higher accuracy. This work offers a promising approach for understanding interaction mechanisms and swarm dynamics in future swarm robotics research. Code and data are available.', 'abstract_zh': '本文提出了一种框架，集体行为克隆(CBC)，用于学习群体系统中的潜在交互机制和控制策略。_given_群体系统的轨迹数据，我们提出了一种图变分自编码器(GVAE)来学习局部交互图。基于交互图和群体轨迹，我们使用行为克隆来学习群体系统的控制策略。为了展示CBC的实际应用价值，我们在一个实际的去中心化视觉机器人群体系统中部署了该框架。基于学习到的交互图训练了一个视觉注意力网络，用于在线邻居选择。实验结果表明，我们的方法在预测交互图和群体动作方面比先前的方法具有更高的准确性。本工作为未来群体机器人研究中理解交互机制和群体动力学提供了有前景的方法。代码和数据已公开。', 'title_zh': '基于神经交互图预测的视觉注意力集体行为克隆'}
{'arxiv_id': 'arXiv:2503.06866', 'title': 'Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception', 'authors': 'Wanjing Huang, Tongjie Pan, Yalan Ye', 'link': 'https://arxiv.org/abs/2503.06866', 'abstract': 'Recent advancements in large language models (LLMs) have expanded their role in robotic task planning. However, while LLMs have been explored for generating feasible task sequences, their ability to ensure safe task execution remains underdeveloped. Existing methods struggle with structured risk perception, making them inadequate for safety-critical applications where low-latency hazard adaptation is required. To address this limitation, we propose a Graphormer-enhanced risk-aware task planning framework that combines LLM-based decision-making with structured safety modeling. Our approach constructs a dynamic spatio-semantic safety graph, capturing spatial and contextual risk factors to enable online hazard detection and adaptive task refinement. Unlike existing methods that rely on predefined safety constraints, our framework introduces a context-aware risk perception module that continuously refines safety predictions based on real-time task execution. This enables a more flexible and scalable approach to robotic planning, allowing for adaptive safety compliance beyond static rules. To validate our framework, we conduct experiments in the AI2-THOR environment. The experiments results validates improvements in risk detection accuracy, rising safety notice, and task adaptability of our framework in continuous environments compared to static rule-based and LLM-only baselines. Our project is available at this https URL', 'abstract_zh': 'recent 进展在大语言模型（LLMs）已在机器人任务规划中扩展了其角色。然而，虽然LLMs 已被探索用于生成可行的任务序列，但它们确保安全任务执行的能力仍不够发达。现有方法在结构化风险感知方面存在困难，使其在需要低延迟风险适应的安全关键应用中不够充分。为解决这一局限性，我们提出了一种结合基于LLM 的决策与结构化安全建模的Graphormer增强风险感知任务规划框架。该方法构建了一个动态空间语义安全图，捕捉空间和上下文风险因素，以实现在线风险检测和自适应任务优化。与依赖预定义安全约束的方法不同，我们的框架引入了一个上下文感知的风险感知模块，基于实时任务执行持续优化安全预测。这使得机器人规划方法更具灵活性和扩展性，能够超出静态规则实现自适应安全合规。为了验证我们的框架，我们在AI2-THOR环境中进行了实验。实验结果验证了与基于静态规则和仅LLM基准相比，我们的框架在持续环境中风险检测准确性、安全警觉性以及任务适应性方面的改进。更多信息请参见此网页：［给定的URL］。', 'title_zh': 'Graphormer引导的任务规划：超越静态规则，具备LLM安全性感知'}
{'arxiv_id': 'arXiv:2503.06863', 'title': 'HIF: Height Interval Filtering for Efficient Dynamic Points Removal', 'authors': 'Shufang Zhang, Tao Jiang, Jiazheng Wu, Ziyu Meng, Ziyang Zhang, Shan An', 'link': 'https://arxiv.org/abs/2503.06863', 'abstract': '3D point cloud mapping plays a essential role in localization and autonomous navigation. However, dynamic objects often leave residual traces during the map construction process, which undermine the performance of subsequent tasks. Therefore, dynamic object removal has become a critical challenge in point cloud based map construction within dynamic scenarios. Existing approaches, however, often incur significant computational overhead, making it difficult to meet the real-time processing requirements. To address this issue, we introduce the Height Interval Filtering (HIF) method. This approach constructs pillar-based height interval representations to probabilistically model the vertical dimension, with interval probabilities updated through Bayesian inference. It ensures real-time performance while achieving high accuracy and improving robustness in complex environments. Additionally, we propose a low-height preservation strategy that enhances the detection of unknown spaces, reducing misclassification in areas blocked by obstacles (occluded regions). Experiments on public datasets demonstrate that HIF delivers a 7.7 times improvement in time efficiency with comparable accuracy to existing SOTA methods. The code will be publicly available.', 'abstract_zh': '3D点云建图在定位和自主导航中起着重要作用。然而，在地图构建过程中，动态物体往往会留下残留痕迹，这会损害后续任务的性能。因此，在动态场景下基于点云地图构建中，动态物体移除成为了一个关键挑战。现有方法通常会带来显著的计算开销，难以满足实时处理的要求。为解决这一问题，我们提出了高度区间过滤（HIF）方法。该方法通过构建基于柱体的高度区间表示，以贝叶斯 inference 更新区间概率，从而在保证实时性能的同时实现高精度并增强在复杂环境中的鲁棒性。此外，我们还提出了一种低高度保留策略，以增强未知空间的检测，减少障碍物遮挡区域的误分类。公开数据集上的实验表明，HIF 在保持与现有领先方法相当精度的同时，性能提高了7.7倍。代码将公开。', 'title_zh': 'HIF: 高度区间过滤算法用于高效动态点移除'}
{'arxiv_id': 'arXiv:2503.06848', 'title': 'Eye-in-Finger: Smart Fingers for Delicate Assembly and Disassembly of LEGO', 'authors': 'Zhenran Tang, Ruixuan Liu, Changliu Liu', 'link': 'https://arxiv.org/abs/2503.06848', 'abstract': 'Manipulation and insertion of small and tight-toleranced objects in robotic assembly remain a critical challenge for vision-based robotics systems due to the required precision and cluttered environment. Conventional global or wrist-mounted cameras often suffer from occlusions when either assembling or disassembling from an existing structure. To address the challenge, this paper introduces "Eye-in-Finger", a novel tool design approach that enhances robotic manipulation by embedding low-cost, high-resolution perception directly at the tool tip. We validate our approach using LEGO assembly and disassembly tasks, which require the robot to manipulate in a cluttered environment and achieve sub-millimeter accuracy and robust error correction due to the tight tolerances. Experimental results demonstrate that our proposed system enables real-time, fine corrections to alignment error, increasing the tolerance of calibration error from 0.4mm to up to 2.0mm for the LEGO manipulation robot.', 'abstract_zh': '基于视觉的机器人系统中，小尺寸且公差严格的物体操作与插入仍然是一个关键挑战，由于所需的精确度和复杂的环境背景。传统的全局或腕部摄像头在组装或拆卸现有结构时常常受到遮挡。为应对这一挑战，本文提出了“指尖摄像头”这一新颖的工具设计方法，通过在工具尖端嵌入低成本的高分辨率感知系统来提升机器人操作的精度。我们利用LEGO组装和拆卸任务进行了验证，这些任务要求机器人在复杂环境中操作，并达到亚毫米级的精度和稳健的误差校正，以适应严格的公差要求。实验结果表明，我们提出的方法能够实现实时、精细的对准误差校正，将LEGO操作机器人的校准误差容忍度从0.4mm提高到2.0mm。', 'title_zh': 'Eye-in-Finger: 智能手指用于LEGO的精细装配与拆卸'}
{'arxiv_id': 'arXiv:2503.06844', 'title': 'A2I-Calib: An Anti-noise Active Multi-IMU Spatial-temporal Calibration Framework for Legged Robots', 'authors': 'Chaoran Xiong, Fangyu Jiang, Kehui Ma, Zhen Sun, Zeyu Zhang, Ling Pei', 'link': 'https://arxiv.org/abs/2503.06844', 'abstract': 'Recently, multi-node inertial measurement unit (IMU)-based odometry for legged robots has gained attention due to its cost-effectiveness, power efficiency, and high accuracy. However, the spatial and temporal misalignment between foot-end motion derived from forward kinematics and foot IMU measurements can introduce inconsistent constraints, resulting in odometry drift. Therefore, accurate spatial-temporal calibration is crucial for the multi-IMU systems. Although existing multi-IMU calibration methods have addressed passive single-rigid-body sensor calibration, they are inadequate for legged systems. This is due to the insufficient excitation from traditional gaits for calibration, and enlarged sensitivity to IMU noise during kinematic chain transformations. To address these challenges, we propose A$^2$I-Calib, an anti-noise active multi-IMU calibration framework enabling autonomous spatial-temporal calibration for arbitrary foot-mounted IMUs. Our A$^2$I-Calib includes: 1) an anti-noise trajectory generator leveraging a proposed basis function selection theorem to minimize the condition number in correlation analysis, thus reducing noise sensitivity, and 2) a reinforcement learning (RL)-based controller that ensures robust execution of calibration motions. Furthermore, A$^2$I-Calib is validated on simulation and real-world quadruped robot platforms with various multi-IMU settings, which demonstrates a significant reduction in noise sensitivity and calibration errors, thereby improving the overall multi-IMU odometry performance.', 'abstract_zh': 'Anti-Noise Active Multi-IMU Calibration Framework for Legged Robots', 'title_zh': 'A2I-Calib: 一种抗噪声主动多IMU时空校准框架用于 legged 机器人'}
{'arxiv_id': 'arXiv:2503.06831', 'title': 'One-Shot Dual-Arm Imitation Learning', 'authors': 'Yilong Wang, Edward Johns', 'link': 'https://arxiv.org/abs/2503.06831', 'abstract': 'We introduce One-Shot Dual-Arm Imitation Learning (ODIL), which enables dual-arm robots to learn precise and coordinated everyday tasks from just a single demonstration of the task. ODIL uses a new three-stage visual servoing (3-VS) method for precise alignment between the end-effector and target object, after which replay of the demonstration trajectory is sufficient to perform the task. This is achieved without requiring prior task or object knowledge, or additional data collection and training following the single demonstration. Furthermore, we propose a new dual-arm coordination paradigm for learning dual-arm tasks from a single demonstration. ODIL was tested on a real-world dual-arm robot, demonstrating state-of-the-art performance across six precise and coordinated tasks in both 4-DoF and 6-DoF settings, and showing robustness in the presence of distractor objects and partial occlusions. Videos are available at: this https URL.', 'abstract_zh': 'One-Shot 双臂模仿学习 (ODIL): 仅从单一示范学习精确协调的双臂日常任务', 'title_zh': '单次学习双臂模仿学习'}
{'arxiv_id': 'arXiv:2503.06814', 'title': 'Unlocking Generalization for Robotics via Modularity and Scale', 'authors': 'Murtaza Dalal', 'link': 'https://arxiv.org/abs/2503.06814', 'abstract': 'How can we build generalist robot systems? Scale may not be enough due to the significant multimodality of robotics tasks, lack of easily accessible data and the challenges of deploying on physical hardware. Meanwhile, most deployed robotic systems today are inherently modular and can leverage the independent generalization capabilities of each module to perform well. Therefore, this thesis seeks to tackle the task of building generalist robot agents by integrating these components into one: combining modularity with large-scale learning for general purpose robot control. The first question we consider is: how can we build modularity and hierarchy into learning systems? Our key insight is that rather than having the agent learn hierarchy and low-level control end-to-end, we can enforce modularity via planning to enable more efficient and capable robot learners. Next, we come to the role of scale in building generalist robot systems. To scale, neural networks require vast amounts of diverse data, expressive architectures to fit the data and a source of supervision to generate the data. We leverage a powerful supervision source: classical planning, which can generalize, but is expensive to run and requires access to privileged information to perform well in practice. We use these planners to supervise large-scale policy learning in simulation to produce generalist agents. Finally, we consider how to unify modularity with large-scale policy learning to build real-world robot systems capable of performing zero-shot manipulation. We do so by tightly integrating key ingredients of modular high and mid-level planning, learned local control, procedural scene generation and large-scale policy learning for sim2real transfer. We demonstrate that this recipe can produce a single, generalist agent that can solve challenging long-horizon manipulation tasks in the real world.', 'abstract_zh': '如何构建通用机器人系统？由于机器人任务的多元性、易于获取的数据缺乏以及物理硬件部署的挑战，规模可能不够。目前部署的大多数机器人系统本质上是模块化的，可以通过利用每个模块的独立泛化能力来表现出色。因此，本论文旨在通过将这些组件整合起来构建通用机器人代理：结合模块化与大规模学习以实现通用机器人控制。首先，我们考虑的问题是：如何将模块化和层次结构融入学习系统中？我们的关键洞察是，而不是让代理端到端地学习层次结构和低级控制，可以通过规划来强制实施模块化，从而使机器人学习者更加高效和强大。接着，我们探讨构建通用机器人系统中的规模作用。为了扩大规模，神经网络需要大量多样化的数据、表达能力强的架构以及数据的监督源。我们利用一个强大的监督源：经典规划，它可以泛化但运行成本高且需要访问特权信息才能在实践中表现良好。我们使用这些规划者在仿真中监督大规模策略学习，以生成通用代理。最后，我们探讨如何将模块化与大规模策略学习统一起来，构建能够执行零样本操作的现实世界机器人系统。我们通过紧密整合模块化高层和中层规划的关键成分、学习局部控制、程序化场景生成以及大规模策略学习，实现仿真实际转换。我们证明这种方案可以产生一个通用的代理，能够在现实世界中解决具有挑战性的长期操作任务。', 'title_zh': '通过模块化和规模实现机器人领域的泛化能力突破'}
{'arxiv_id': 'arXiv:2503.06802', 'title': 'A Physically Consistent Stiffness Formulation for Contact-Rich Manipulation', 'authors': 'Johannes Lachner, Moses C. Nah, Neville Hogan', 'link': 'https://arxiv.org/abs/2503.06802', 'abstract': 'Ensuring symmetric stiffness in impedance-controlled robots is crucial for physically meaningful and stable interaction in contact-rich manipulation. Conventional approaches neglect the change of basis vectors in curved spaces, leading to an asymmetric joint-space stiffness matrix that violates passivity and conservation principles. In this work, we derive a physically consistent, symmetric joint-space stiffness formulation directly from the task-space stiffness matrix by explicitly incorporating Christoffel symbols. This correction resolves long-standing inconsistencies in stiffness modeling, ensuring energy conservation and stability. We validate our approach experimentally on a robotic system, demonstrating that omitting these correction terms results in significant asymmetric stiffness errors. Our findings bridge theoretical insights with practical control applications, offering a robust framework for stable and interpretable robotic interactions.', 'abstract_zh': '确保 impedance 控制机器人中的对称刚度对于接触丰富操作中的物理意义和稳定交互至关重要。传统的方法忽略了曲空间中基向量的变化，导致关节空间刚度矩阵不对称，违背了主动性和守恒原理。在本项工作中，我们直接从任务空间刚度矩阵出发，通过明确引入克里斯托夫符号推导出一个物理上一致的、对称的关节空间刚度公式。这一修正解决了刚度建模中长期存在的不一致性问题，确保能量守恒和稳定性。我们在一个机器人系统上进行了实验验证，证明忽略这些修正项会导致显著的不对称刚度误差。我们的研究将理论洞察与实际控制应用相结合，提供了一个稳定且可解释的机器人交互的稳健框架。', 'title_zh': '接触丰富操作的物理一致刚度公式化'}
{'arxiv_id': 'arXiv:2503.06796', 'title': 'RoboDesign1M: A Large-scale Dataset for Robot Design Understanding', 'authors': 'Tri Le, Toan Nguyen, Quang Tran, Quang Nguyen, Baoru Huang, Hoan Nguyen, Minh Nhat Vu, Tung D. Ta, Anh Nguyen', 'link': 'https://arxiv.org/abs/2503.06796', 'abstract': 'Robot design is a complex and time-consuming process that requires specialized expertise. Gaining a deeper understanding of robot design data can enable various applications, including automated design generation, retrieving example designs from text, and developing AI-powered design assistants. While recent advancements in foundation models present promising approaches to addressing these challenges, progress in this field is hindered by the lack of large-scale design datasets. In this paper, we introduce RoboDesign1M, a large-scale dataset comprising 1 million samples. Our dataset features multimodal data collected from scientific literature, covering various robotics domains. We propose a semi-automated data collection pipeline, enabling efficient and diverse data acquisition. To assess the effectiveness of RoboDesign1M, we conduct extensive experiments across multiple tasks, including design image generation, visual question answering about designs, and design image retrieval. The results demonstrate that our dataset serves as a challenging new benchmark for design understanding tasks and has the potential to advance research in this field. RoboDesign1M will be released to support further developments in AI-driven robotic design automation.', 'abstract_zh': '机器人设计是一个复杂且耗时的过程，需要专门的技术知识。对机器人设计数据的深入理解能够促进自动化设计生成、从文本检索样例设计以及开发AI辅助设计助手等应用。尽管基础模型的最新进展为解决这些挑战提供了有前景的方法，但该领域的发展受到大型设计数据集缺乏的阻碍。本文介绍了RoboDesign1M，这是一个包含100万样本的大型数据集，涵盖了多模态数据，来自科学文献，涉及多种机器人领域。我们提出了一种半自动数据收集管道，以实现高效且多样化的数据获取。为了评估RoboDesign1M的有效性，我们在多个任务上进行了广泛实验，包括设计图像生成、关于设计的视觉问答以及设计图像检索。实验结果表明，我们的数据集是一个具有挑战性的新基准，能够促进该领域的研究，并具有推动研究发展的潜力。RoboDesign1M将被发布以支持基于AI的机器人设计自动化的进一步发展。', 'title_zh': 'RoboDesign1M: 机器人设计理解的大规模数据集'}
{'arxiv_id': 'arXiv:2503.06795', 'title': 'Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms', 'authors': 'Lidia Al-Zogbi, Deepak Raina, Vinciya Pandian, Thorsten Fleiter, Axel Krieger', 'link': 'https://arxiv.org/abs/2503.06795', 'abstract': 'Femoral artery access is essential for numerous clinical procedures, including diagnostic angiography, therapeutic catheterization, and emergency interventions. Despite its critical role, successful vascular access remains challenging due to anatomical variability, overlying adipose tissue, and the need for precise ultrasound (US) guidance. Errors in needle placement can lead to severe complications, restricting the procedure to highly skilled clinicians in controlled hospital settings. While robotic systems have shown promise in addressing these challenges through autonomous scanning and vessel reconstruction, clinical translation remains limited due to reliance on simplified phantom models that fail to capture human anatomical complexity. In this work, we present a method for autonomous robotic US scanning of bifurcated femoral arteries, and validate it on five vascular phantoms created from real patient computed tomography (CT) data. Additionally, we introduce a video-based deep learning US segmentation network tailored for vascular imaging, enabling improved 3D arterial reconstruction. The proposed network achieves a Dice score of 89.21% and an Intersection over Union of 80.54% on a newly developed vascular dataset. The quality of the reconstructed artery centerline is evaluated against ground truth CT data, demonstrating an average L2 deviation of 0.91+/-0.70 mm, with an average Hausdorff distance of 4.36+/-1.11mm. This study is the first to validate an autonomous robotic system for US scanning of the femoral artery on a diverse set of patient-specific phantoms, introducing a more advanced framework for evaluating robotic performance in vascular imaging and intervention.', 'abstract_zh': '自主机器人超声扫描在分叉股动脉成像中的应用及其在真实患者CT数据构建的人体模体上的验证', 'title_zh': '基于解剖学代表性的 Phantom 的机器人超声引导股动脉重建研究'}
{'arxiv_id': 'arXiv:2503.06791', 'title': 'AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot', 'authors': 'Xiao Wang, Lu Dong, Sahana Rangasrinivasan, Ifeoma Nwogu, Srirangaraj Setlur, Venugopal Govindaraju', 'link': 'https://arxiv.org/abs/2503.06791', 'abstract': "The social robot's open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty's effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-4o and ChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly released through the webpage: this https URL", 'abstract_zh': '基于大规模语言模型的多代理协作框架AutoMisty：从自然语言指令无缝生成可执行的Misty机器人代码', 'title_zh': 'AutoMisty: 一种用于Misty社交机器人自动化代码生成的多代理大语言模型框架'}
{'arxiv_id': 'arXiv:2503.06779', 'title': 'Chance-Constrained Trajectory Planning with Multimodal Environmental Uncertainty', 'authors': 'Kai Ren, Heejin Ahn, Maryam Kamgarpour', 'link': 'https://arxiv.org/abs/2503.06779', 'abstract': "We tackle safe trajectory planning under Gaussian mixture model (GMM) uncertainty. Specifically, we use a GMM to model the multimodal behaviors of obstacles' uncertain states. Then, we develop a mixed-integer conic approximation to the chance-constrained trajectory planning problem with deterministic linear systems and polyhedral obstacles. When the GMM moments are estimated via finite samples, we develop a tight concentration bound to ensure the chance constraint with a desired confidence. Moreover, to limit the amount of constraint violation, we develop a Conditional Value-at-Risk (CVaR) approach corresponding to the chance constraints and derive a tractable approximation for known and estimated GMM moments. We verify our methods with state-of-the-art trajectory prediction algorithms and autonomous driving datasets.", 'abstract_zh': '基于高斯混合模型不确定性下的安全轨迹规划', 'title_zh': '多模态环境不确定性下的机会约束轨迹规划'}
{'arxiv_id': 'arXiv:2503.06776', 'title': 'Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty', 'authors': 'Kai Ren, Giulio Salizzoni, Mustafa Emre Gürsoy, Maryam Kamgarpour', 'link': 'https://arxiv.org/abs/2503.06776', 'abstract': 'We address safe multi-robot interaction under uncertainty. In particular, we formulate a chance-constrained linear quadratic Gaussian game with coupling constraints and system uncertainties. We find a tractable reformulation of the game and propose a dual ascent algorithm. We prove that the algorithm converges to a generalized Nash equilibrium of the reformulated game, ensuring the satisfaction of the chance constraints. We test our method in driving simulations and real-world robot experiments. Our method ensures safety under uncertainty and generates less conservative trajectories than single-agent model predictive control.', 'abstract_zh': '我们研究了不确定条件下多机器人安全交互问题。特别地，我们提出了一个带有耦合约束和系统不确定性的一般化纳什均衡的机会约束线性二次高斯博弈。我们找到了博弈的可处理重写形式，并提出了一种对偶上升算法。我们证明该算法能够收敛到重写博弈的广义纳什均衡，确保机会约束的满足。我们该方法在驾驶模拟和实际机器人实验中进行了测试。该方法在不确定性条件下确保安全，并生成比单智能体模型预测控制更为保守的轨迹。', 'title_zh': '线性二次高斯游戏的不确定性下多机器人交互机会约束模型'}
{'arxiv_id': 'arXiv:2503.06771', 'title': 'Task-Oriented Connectivity for Networked Robotics with Generative AI and Semantic Communications', 'authors': 'Peizheng Li, Adnan Aijaz', 'link': 'https://arxiv.org/abs/2503.06771', 'abstract': 'The convergence of robotics, advanced communication networks, and artificial intelligence (AI) holds the promise of transforming industries through fully automated and intelligent operations. In this work, we introduce a novel co-working framework for robots that unifies goal-oriented semantic communication (SemCom) with a Generative AI (GenAI)-agent under a semantic-aware network. SemCom prioritizes the exchange of meaningful information among robots and the network, thereby reducing overhead and latency. Meanwhile, the GenAI-agent leverages generative AI models to interpret high-level task instructions, allocate resources, and adapt to dynamic changes in both network and robotic environments. This agent-driven paradigm ushers in a new level of autonomy and intelligence, enabling complex tasks of networked robots to be conducted with minimal human intervention. We validate our approach through a multi-robot anomaly detection use-case simulation, where robots detect, compress, and transmit relevant information for classification. Simulation results confirm that SemCom significantly reduces data traffic while preserving critical semantic details, and the GenAI-agent ensures task coordination and network adaptation. This synergy provides a robust, efficient, and scalable solution for modern industrial environments.', 'abstract_zh': '机器人、先进通信网络和人工智能融合的共融框架：基于语义感知网络的目标导向语义通信与生成式AI代理一体化方法', 'title_zh': '任务导向连通性：结合生成AI与语义通信的网络化机器人技术'}
{'arxiv_id': 'arXiv:2503.06757', 'title': 'pRRTC: GPU-Parallel RRT-Connect for Fast, Consistent, and Low-Cost Motion Planning', 'authors': 'Chih H. Huang, Pranav Jadhav, Brian Plancher, Zachary Kingston', 'link': 'https://arxiv.org/abs/2503.06757', 'abstract': 'Sampling-based motion planning algorithms, like the Rapidly-Exploring Random Tree (RRT) and its widely used variant, RRT-Connect, provide efficient solutions for high-dimensional planning problems faced by real-world robots. However, these methods remain computationally intensive, particularly in complex environments that require many collision checks. As such, to improve performance, recent efforts have explored parallelizing specific components of RRT, such as collision checking or running multiple planners independently, but no prior work has integrated parallelism at multiple levels of the algorithm for robotic manipulation. In this work, we present pRRTC, a GPU-accelerated implementation of RRT-Connect that achieves parallelism across the entire algorithm through multithreaded expansion and connection, SIMT-optimized collision checking, and hierarchical parallelism optimization, improving efficiency, consistency, and initial solution cost. We evaluate the effectiveness of pRRTC on the MotionBenchMaker dataset using robots with 7, 8, and 14 degrees-of-freedom, demonstrating up to 6x average speedup on constrained reaching tasks at high collision checking resolution compared to state-of-the-art. pRRTC also demonstrates a 5x reduction in solution time variance and 1.5x improvement in initial path costs compared to state-of-the-art motion planners in complex environments across all robots.', 'abstract_zh': '基于采样的运动规划算法，如快速扩展随机树（RRT）及其广泛应用的变体RRT-Connect，为真实世界机器人面临的高维规划问题提供了高效的解决方案。然而，这些方法在复杂的环境需求下仍计算密集，特别是需要进行大量碰撞检测的情况。因此，为了提高性能，近期研究探索了并行化RRT的具体组件，如碰撞检测或独立运行多个规划器，但此前没有任何研究在算法的多个层次集成并行性以提高机器人的操作效率。在这项工作中，我们提出了pRRTC，这是一种基于GPU加速的RRT-Connect实现，通过多线程扩展和连接、SIMT优化的碰撞检测以及分层并行性优化，在整个算法中实现并行化，提高效率、一致性和初始解成本。我们使用具有7、8和14自由度的MotionBenchMaker数据集评估pRRTC的有效性，与最先进的方法相比，在高碰撞检测分辨率下执行受限拾取任务时平均提速6倍。pRRTC还在所有机器人中展示了5倍的解时间方差减少和1.5倍的初始路径成本改进，这些改进在复杂环境中表现尤为显著。', 'title_zh': 'PRTTC：GPU并行RRT-Connect算法实现快速、一致且低成本的运动规划'}
{'arxiv_id': 'arXiv:2503.06736', 'title': 'Safe, Task-Consistent Manipulation with Operational Space Control Barrier Functions', 'authors': 'Daniel Morton, Marco Pavone', 'link': 'https://arxiv.org/abs/2503.06736', 'abstract': 'Safe real-time control of robotic manipulators in unstructured environments requires handling numerous safety constraints without compromising task performance. Traditional approaches, such as artificial potential fields (APFs), suffer from local minima, oscillations, and limited scalability, while model predictive control (MPC) can be computationally expensive. Control barrier functions (CBFs) offer a promising alternative due to their high level of robustness and low computational cost, but these safety filters must be carefully designed to avoid significant reductions in the overall performance of the manipulator. In this work, we introduce an Operational Space Control Barrier Function (OSCBF) framework that integrates safety constraints while preserving task-consistent behavior. Our approach scales to hundreds of simultaneous constraints while retaining real-time control rates, ensuring collision avoidance, singularity prevention, and workspace containment even in highly cluttered and dynamic settings. By explicitly accounting for the task hierarchy in the CBF objective, we prevent degraded performance across both joint-space and operational-space tasks, when at the limit of safety. Our open-source, high-performance software will be available at our project webpage, this https URL', 'abstract_zh': 'Safe实时控制机器人 manipulators 在未结构化环境中的稳健实现要求处理大量安全约束同时不牺牲任务性能。传统的方法，如人工势场法（APFs），存在局部极小值、振荡和计算效率有限的问题，而模型预测控制（MPC）则计算成本较高。控制屏障函数（CBFs）因其高度的鲁棒性和较低的计算成本提供了有前景的替代方案，但这些安全过滤器必须精心设计以避免显著降低 manipulator 的整体性能。在此工作中，我们提出了一个操作空间控制屏障函数（OSCBF）框架，该框架在保留任务一致性行为的同时整合了安全约束。我们的方法可以扩展到数百个同时约束，同时保持实时控制速率，确保即使在高度拥挤和动态设置下也能实现防碰撞、防奇异性和工作空间限制。通过明确考虑到CBF目标中的任务层次结构，我们防止了在安全极限下关节空间和操作空间任务的性能退化。我们的开源高性能软件将在我们的项目网页上提供，此链接为：此httpsURL。', 'title_zh': '基于操作空间控制屏障函数的安全且任务一致的操作Manipulation'}
{'arxiv_id': 'arXiv:2503.06733', 'title': 'Embodied multi-modal sensing with a soft modular arm powered by physical reservoir computing', 'authors': 'Jun Wang, Suyi Li', 'link': 'https://arxiv.org/abs/2503.06733', 'abstract': "Soft robots have become increasingly popular for complex manipulation tasks requiring gentle and safe contact. However, their softness makes accurate control challenging, and high-fidelity sensing is a prerequisite to adequate control performance. To this end, many flexible and embedded sensors have been created over the past decade, but they inevitably increase the robot's complexity and stiffness. This study demonstrates a novel approach that uses simple bending strain gauges embedded inside a modular arm to extract complex information regarding its deformation and working conditions. The core idea is based on physical reservoir computing (PRC): A soft body's rich nonlinear dynamic responses, captured by the inter-connected bending sensor network, could be utilized for complex multi-modal sensing with a simple linear regression algorithm. Our results show that the soft modular arm reservoir can accurately predict body posture (bending angle), estimate payload weight, determine payload orientation, and even differentiate two payloads with only minimal difference in weight -- all using minimal digital computing power.", 'abstract_zh': '软体机器人的复杂操作任务需要温柔安全的接触，但其柔软性使得精确控制极具挑战性，高保真感知是实现充足控制性能的前提。为此，近年来开发了许多柔性和嵌入式传感器，但它们不可避免地增加了机器人的复杂性和刚性。本研究展示了一种新颖的方法，即在模块化手臂内部嵌入简单弯曲应变片以提取其变形和工作状态的复杂信息。核心思想基于物理蓄流计算（PRC）：通过互联的弯曲传感器网络捕捉软体生物体丰富的非线性动态响应，可以使用简单的线性回归算法实现复杂多模态感知。我们的研究表明，软模块臂蓄流器能够准确预测身体姿态（弯曲角度）、估计负载重量、确定负载方向，并且在重量仅有微小差异的情况下还能区分两个负载，这全部只需最少的数字计算能力。', 'title_zh': '软模块化机械臂基于物理存储池计算的动力化多模态传感'}
{'arxiv_id': 'arXiv:2503.06669', 'title': 'AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems', 'authors': 'AgiBot-World-Contributors, Qingwen Bu, Jisong Cai, Li Chen, Xiuqi Cui, Yan Ding, Siyuan Feng, Shenyuan Gao, Xindong He, Xu Huang, Shu Jiang, Yuxin Jiang, Cheng Jing, Hongyang Li, Jialu Li, Chiming Liu, Yi Liu, Yuxiang Lu, Jianlan Luo, Ping Luo, Yao Mu, Yuehan Niu, Yixuan Pan, Jiangmiao Pang, Yu Qiao, Guanghui Ren, Cheng Ruan, Jiaqi Shan, Yongjian Shen, Chengshi Shi, Mingkang Shi, Modi Shi, Chonghao Sima, Jianheng Song, Huijie Wang, Wenhao Wang, Dafeng Wei, Chengen Xie, Guo Xu, Junchi Yan, Cunbiao Yang, Lei Yang, Shukai Yang, Maoqing Yao, Jia Zeng, Chi Zhang, Qinglin Zhang, Bin Zhao, Chengyue Zhao, Jiaqi Zhao, Jianchao Zhu', 'link': 'https://arxiv.org/abs/2503.06669', 'abstract': 'We explore how scalable robot data can address real-world challenges for generalized robotic manipulation. Introducing AgiBot World, a large-scale platform comprising over 1 million trajectories across 217 tasks in five deployment scenarios, we achieve an order-of-magnitude increase in data scale compared to existing datasets. Accelerated by a standardized collection pipeline with human-in-the-loop verification, AgiBot World guarantees high-quality and diverse data distribution. It is extensible from grippers to dexterous hands and visuo-tactile sensors for fine-grained skill acquisition. Building on top of data, we introduce Genie Operator-1 (GO-1), a novel generalist policy that leverages latent action representations to maximize data utilization, demonstrating predictable performance scaling with increased data volume. Policies pre-trained on our dataset achieve an average performance improvement of 30% over those trained on Open X-Embodiment, both in in-domain and out-of-distribution scenarios. GO-1 exhibits exceptional capability in real-world dexterous and long-horizon tasks, achieving over 60% success rate on complex tasks and outperforming prior RDT approach by 32%. By open-sourcing the dataset, tools, and models, we aim to democratize access to large-scale, high-quality robot data, advancing the pursuit of scalable and general-purpose intelligence.', 'abstract_zh': '我们探索可扩展的机器人数据如何解决通用机器人操作的实际挑战。通过引入包含超过100万条轨迹的AgiBot World平台，该平台涵盖了五种部署场景下的217项任务，我们实现了与现有数据集相比量级的数据规模提升。借助标准化的数据收集管道和人工在环验证，AgiBot World确保了高质量和多样性的数据分布。该平台支持从抓取器扩展到灵巧手以及视觉-触觉传感器，以实现精细技能的学习。基于数据，我们提出了Genie Operator-1（GO-1），这是一种新颖的一般主义策略，利用潜在动作表示来最大化数据利用，展示了随数据量增加而可预测的性能提升。在我们的数据集上预训练的策略在同域和异域场景下的性能平均提高了30%，优于Open X-Embodiment。GO-1在现实世界的灵巧和长期任务中表现出色，复杂任务的成功率超过60%，比之前的RDT方法性能高出32%。通过开源数据集、工具和模型，我们旨在普及大规模高质量机器人数据的使用，推动可扩展和通用人工智能的发展。', 'title_zh': 'AgiBot 世界角斗场：大规模 manipulation 平台，用于可扩展和智能的具身系统'}
{'arxiv_id': 'arXiv:2503.06578', 'title': 'Non-Equilibrium MAV-Capture-MAV via Time-Optimal Planning and Reinforcement Learning', 'authors': 'Canlun Zheng, Zhanyu Guo, Zikang Yin, Chunyu Wang, Zhikun Wang, Shiyu Zhao', 'link': 'https://arxiv.org/abs/2503.06578', 'abstract': 'The capture of flying MAVs (micro aerial vehicles) has garnered increasing research attention due to its intriguing challenges and promising applications. Despite recent advancements, a key limitation of existing work is that capture strategies are often relatively simple and constrained by platform performance. This paper addresses control strategies capable of capturing high-maneuverability targets. The unique challenge of achieving target capture under unstable conditions distinguishes this task from traditional pursuit-evasion and guidance problems. In this study, we transition from larger MAV platforms to a specially designed, compact capture MAV equipped with a custom launching device while maintaining high maneuverability. We explore both time-optimal planning (TOP) and reinforcement learning (RL) methods. Simulations demonstrate that TOP offers highly maneuverable and shorter trajectories, while RL excels in real-time adaptability and stability. Moreover, the RL method has been tested in real-world scenarios, successfully achieving target capture even in unstable states.', 'abstract_zh': '基于高机动目标捕获的飞行微小型无人机控制策略研究', 'title_zh': '非平衡 MAV 抓取 MAV 的时间最优计划与强化学习'}
{'arxiv_id': 'arXiv:2503.06516', 'title': 'Abdominal Undulation with Compliant Mechanism Improves Flight Performance of Biomimetic Robotic Butterfly', 'authors': 'Xuyi Lian, Mingyu Luo, Te Lin, Chen Qian, Tiefeng Li', 'link': 'https://arxiv.org/abs/2503.06516', 'abstract': 'Abdominal Undulation with Compliant Mechanism Improves Flight Performance of Biomimetic Robotic ButterflThis paper presents the design, modeling, and experimental validation of a biomimetic robotic butterfly (BRB) that integrates a compliant mechanism to achieve coupled wing-abdomen motion. Drawing inspiration from the natural f light dynamics of butterflies, a theoretical model is developed to investigate the impact of abdominal undulation on flight performance. To validate the model, motion capture experi ments are conducted on three configurations: a BRB without an abdomen, with a fixed abdomen, and with an undulating abdomen. The results demonstrate that abdominal undulation enhances lift generation, extends flight duration, and stabilizes pitch oscillations, thereby improving overall flight performance. These findings underscore the significance of wing-abdomen interaction in flapping-wing aerial vehicles (FWAVs) and lay the groundwork for future advancements in energy-efficient biomimetic flight designs.', 'abstract_zh': '模仿腹动机制的腹部摆动提高仿生机器人蝴蝶飞行性能', 'title_zh': '具有 compliant 机制的腹部波动提高仿生蝴蝶机器人飞行性能'}
{'arxiv_id': 'arXiv:2503.06412', 'title': 'Vision-Based Cooperative MAV-Capturing-MAV', 'authors': 'Canlun Zheng, Yize Mi, Hanqing Guo, Huaben Chen, Shiyu Zhao', 'link': 'https://arxiv.org/abs/2503.06412', 'abstract': 'MAV-capturing-MAV (MCM) is one of the few effective methods for physically countering misused or malicious this http URL paper presents a vision-based cooperative MCM system, where multiple pursuer MAVs equipped with onboard vision systems detect, localize, and pursue a target MAV. To enhance robustness, a distributed state estimation and control framework enables the pursuer MAVs to autonomously coordinate their actions. Pursuer trajectories are optimized using Model Predictive Control (MPC) and executed via a low-level SO(3) controller, ensuring smooth and stable pursuit. Once the capture conditions are satisfied, the pursuer MAVs automatically deploy a flying net to intercept the target. These capture conditions are determined based on the predicted motion of the net. To enable real-time decision-making, we propose a lightweight computational method to approximate the net motion, avoiding the prohibitive cost of solving the full net dynamics. The effectiveness of the proposed system is validated through simulations and real-world experiments. In real-world tests, our approach successfully captures a moving target traveling at 4 meters per second with an acceleration of 1 meter per square second, achieving a success rate of 64.7 percent.', 'abstract_zh': '基于视觉的多旋翼捕获系统：自主协调的 MAV-capturing-MAV (MCM) 方法', 'title_zh': '基于视觉的合作MAV-捕获MAV'}
{'arxiv_id': 'arXiv:2503.06402', 'title': 'Reduced-Order Model-Based Gait Generation for Snake Robot Locomotion using NMPC', 'authors': 'Adarsh Salagame, Eric Sihite, Milad Ramezani, Alireza Ramezani', 'link': 'https://arxiv.org/abs/2503.06402', 'abstract': "This paper presents an optimization-based motion planning methodology for snake robots operating in constrained environments. By using a reduced-order model, the proposed approach simplifies the planning process, enabling the optimizer to autonomously generate gaits while constraining the robot's footprint within tight spaces. The method is validated through high-fidelity simulations that accurately model contact dynamics and the robot's motion. Key locomotion strategies are identified and further demonstrated through hardware experiments, including successful navigation through narrow corridors.", 'abstract_zh': '基于优化的蛇形机器人在受限环境中的运动规划方法', 'title_zh': '基于降阶模型的蛇形机器人运动规划的NMPC步态生成'}
{'arxiv_id': 'arXiv:2503.06359', 'title': 'Deep Reinforcement Learning-Based Semi-Autonomous Control for Magnetic Micro-robot Navigation with Immersive Manipulation', 'authors': 'Yudong Mao, Dandan Zhang', 'link': 'https://arxiv.org/abs/2503.06359', 'abstract': 'Magnetic micro-robots have demonstrated immense potential in biomedical applications, such as in vivo drug delivery, non-invasive diagnostics, and cell-based therapies, owing to their precise maneuverability and small size. However, current micromanipulation techniques often rely solely on a two-dimensional (2D) microscopic view as sensory feedback, while traditional control interfaces do not provide an intuitive manner for operators to manipulate micro-robots. These limitations increase the cognitive load on operators, who must interpret limited feedback and translate it into effective control actions. To address these challenges, we propose a Deep Reinforcement Learning-Based Semi-Autonomous Control (DRL-SC) framework for magnetic micro-robot navigation in a simulated microvascular system. Our framework integrates Mixed Reality (MR) to facilitate immersive manipulation of micro-robots, thereby enhancing situational awareness and control precision. Simulation and experimental results demonstrate that our approach significantly improves navigation efficiency, reduces control errors, and enhances the overall robustness of the system in simulated microvascular environments.', 'abstract_zh': '基于深度 reinforcement 学习的混合现实辅助磁微机器人自主导航框架', 'title_zh': '基于深度强化学习的半自主控制方法及其在沉浸式微磁机器人导航中的应用'}
{'arxiv_id': 'arXiv:2503.06309', 'title': 'On the Fly Adaptation of Behavior Tree-Based Policies through Reinforcement Learning', 'authors': 'Marco Iannotta, Johannes A. Stork, Erik Schaffernicht, Todor Stoyanov', 'link': 'https://arxiv.org/abs/2503.06309', 'abstract': 'With the rising demand for flexible manufacturing, robots are increasingly expected to operate in dynamic environments where local -- such as slight offsets or size differences in workpieces -- are common. We propose to address the problem of adapting robot behaviors to these task variations with a sample-efficient hierarchical reinforcement learning approach adapting Behavior Tree (BT)-based policies. We maintain the core BT properties as an interpretable, modular framework for structuring reactive behaviors, but extend their use beyond static tasks by inherently accommodating local task variations. To show the efficiency and effectiveness of our approach, we conduct experiments both in simulation and on a Franka Emika Panda 7-DoF, with the manipulator adapting to different obstacle avoidance and pivoting tasks.', 'abstract_zh': '随着对灵活制造的需求不断增长，机器人被期望在局部任务差异（如工件的轻微偏移或尺寸差异）常见的动态环境中操作。我们提出了一种样本高效层次强化学习方法，通过调整行为树（BT）基于的策略来解决机器人行为适应这些任务变化的问题。我们保留行为树的核心属性作为可解释的模块化框架来结构化反应性行为，并通过固有地适应局部任务变化来扩展其用途。为了展示我们方法的效率和有效性，我们在仿真和Franka Emika Panda 7-DoF机械臂上进行了实验，机械臂适应了不同的障碍物规避和旋转任务。', 'title_zh': '基于强化学习的行为树策略-flyadaptation'}
{'arxiv_id': 'arXiv:2503.06300', 'title': 'Efficient Gradient-Based Inference for Manipulation Planning in Contact Factor Graphs', 'authors': 'Jeongmin Lee, Sunkyung Park, Minji Lee, Dongjun Lee', 'link': 'https://arxiv.org/abs/2503.06300', 'abstract': 'This paper presents a framework designed to tackle a range of planning problems arise in manipulation, which typically involve complex geometric-physical reasoning related to contact and dynamic constraints. We introduce the Contact Factor Graph (CFG) to graphically model these diverse factors, enabling us to perform inference on the graphs to approximate the distribution and sample appropriate solutions. We propose a novel approach that can incorporate various phenomena of contact manipulation as differentiable factors, and develop an efficient inference algorithm for CFG that leverages this differentiability along with the conditional probabilities arising from the structured nature of contact. Our results demonstrate the capability of our framework in generating viable samples and approximating posterior distributions for various manipulation scenarios.', 'abstract_zh': '本文提出了一种框架，用于解决 manipulation 中出现的一系列规划问题，这些问题通常涉及复杂的几何-物理推理，包括接触和动态约束。我们引入了接触因子图（CFG）来图形化建模这些多样化的因素，从而能够在图上进行推理以近似分布并采样合适的解。我们提出了一种新的方法，可以将接触操作的各种现象作为可微分因子进行整合，并开发了一种利用这些可微分性和接触结构化性质产生的条件概率的高效推理算法。我们的结果表明，该框架在各种操作场景中生成有效样本和近似后验分布的能力。', 'title_zh': '基于梯度的高效推理在接触因子图中的操作规划'}
{'arxiv_id': 'arXiv:2503.06241', 'title': 'A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A Field Experiment', 'authors': 'Koji Inoue, Yuki Okafuji, Jun Baba, Yoshiki Ohira, Katsuya Hyodo, Tatsuya Kawahara', 'link': 'https://arxiv.org/abs/2503.06241', 'abstract': 'Turn-taking is a crucial aspect of human-robot interaction, directly influencing conversational fluidity and user engagement. While previous research has explored turn-taking models in controlled environments, their robustness in real-world settings remains underexplored. In this study, we propose a noise-robust voice activity projection (VAP) model, based on a Transformer architecture, to enhance real-time turn-taking in dialogue robots. To evaluate the effectiveness of the proposed system, we conducted a field experiment in a shopping mall, comparing the VAP system with a conventional cloud-based speech recognition system. Our analysis covered both subjective user evaluations and objective behavioral analysis. The results showed that the proposed system significantly reduced response latency, leading to a more natural conversation where both the robot and users responded faster. The subjective evaluations suggested that faster responses contribute to a better interaction experience.', 'abstract_zh': '人类-机器人对话轮换是影响对话流畅性和用户参与度的关键因素，在现实世界环境中，先前研究提出的轮换模型的 robust 性仍然有待探索。本文提出基于变压器架构的噪声鲁棒语音活动投影（VAP）模型，以增强对话机器人的实时轮换能力。为了评估该系统的效果，我们在购物中心进行了实地实验，将 VAP 系统与传统的云基语音识别系统进行了比较。分析涵盖了主观用户评价和客观行为分析。结果表明，所提出系统显著减少了响应延迟，使对话更加自然，机器人和用户都能更快地响应。这种更快速的响应被主观评价认为改善了交互体验。', 'title_zh': '一种适用于真实对话机器人的抗噪声轮流说话系统：一个实地实验'}
{'arxiv_id': 'arXiv:2503.06227', 'title': 'GAT-Grasp: Gesture-Driven Affordance Transfer for Task-Aware Robotic Grasping', 'authors': 'Ruixiang Wang, Huayi Zhou, Xinyue Yao, Guiliang Liu, Kui Jia', 'link': 'https://arxiv.org/abs/2503.06227', 'abstract': 'Achieving precise and generalizable grasping across diverse objects and environments is essential for intelligent and collaborative robotic systems. However, existing approaches often struggle with ambiguous affordance reasoning and limited adaptability to unseen objects, leading to suboptimal grasp execution. In this work, we propose GAT-Grasp, a gesture-driven grasping framework that directly utilizes human hand gestures to guide the generation of task-specific grasp poses with appropriate positioning and orientation. Specifically, we introduce a retrieval-based affordance transfer paradigm, leveraging the implicit correlation between hand gestures and object affordances to extract grasping knowledge from large-scale human-object interaction videos. By eliminating the reliance on pre-given object priors, GAT-Grasp enables zero-shot generalization to novel objects and cluttered environments. Real-world evaluations confirm its robustness across diverse and unseen scenarios, demonstrating reliable grasp execution in complex task settings.', 'abstract_zh': '实现多样物体和环境下的精确且通用的抓取是智能化协作机器人系统的关键。然而，现有方法往往在模糊的用途推理和对未见物体的适应性方面存在局限，导致抓取执行效果不佳。为此，我们提出了一种基于手势的抓取框架GAT-Grasp，该框架直接利用人类手部手势来引导生成具有适当定位和方向的任务特定抓取姿态。具体而言，我们引入了一种检索驱动的用途转移 paradigm，利用手部手势与物体用途之间的隐式关联，从大规模的人机交互视频中抽取抓取知识。通过消除对先验物体知识的依赖，GAT-Grasp 实现了对新型物体和杂乱环境的零样本泛化。实际世界评估证实了其在各种未见过的复杂场景中的稳健性，展示了在复杂任务设置中可靠的抓取执行能力。', 'title_zh': 'GAT-Grasp: 基于手势驱动的适应任务的抓取精度传递'}
{'arxiv_id': 'arXiv:2503.06135', 'title': 'FlowMP: Learning Motion Fields for Robot Planning with Conditional Flow Matching', 'authors': 'Khang Nguyen, An T. Le, Tien Pham, Manfred Huber, Jan Peters, Minh Nhat Vu', 'link': 'https://arxiv.org/abs/2503.06135', 'abstract': 'Prior flow matching methods in robotics have primarily learned velocity fields to morph one distribution of trajectories into another. In this work, we extend flow matching to capture second-order trajectory dynamics, incorporating acceleration effects either explicitly in the model or implicitly through the learning objective. Unlike diffusion models, which rely on a noisy forward process and iterative denoising steps, flow matching trains a continuous transformation (flow) that directly maps a simple prior distribution to the target trajectory distribution without any denoising procedure. By modeling trajectories with second-order dynamics, our approach ensures that generated robot motions are smooth and physically executable, avoiding the jerky or dynamically infeasible trajectories that first-order models might produce. We empirically demonstrate that this second-order conditional flow matching yields superior performance on motion planning benchmarks, achieving smoother trajectories and higher success rates than baseline planners. These findings highlight the advantage of learning acceleration-aware motion fields, as our method outperforms existing motion planning methods in terms of trajectory quality and planning success.', 'abstract_zh': '机器人领域的先验流匹配方法主要学习速度场以将一个轨迹分布转换为另一个分布。在本工作中，我们将流匹配扩展到捕获轨迹的二阶动力学，通过显式地在模型中或通过学习目标隐式地纳入加速度效果。与依赖于噪声前向过程和去噪步骤的扩散模型不同，流匹配训练一个连续变换（流），直接将简单的先验分布映射为目标轨迹分布，而无需任何去噪过程。通过建模二阶动力学，我们的方法确保生成的机器人运动平滑且物理可执行，避免了由一阶模型可能产生的生硬或动力学不可行的轨迹。我们实验证明，这种二阶条件流匹配在运动规划基准测试中表现出更优性能，生成更平滑的轨迹并具有更高的成功率。这些发现强调了学习加速度感知运动场的优势，我们的方法在轨迹质量和规划成功率方面优于现有运动规划方法。', 'title_zh': 'FlowMP：基于条件流匹配的学习运动场方法用于机器人规划'}
{'arxiv_id': 'arXiv:2503.06083', 'title': 'T-CBF: Traversability-based Control Barrier Function to Navigate Vertically Challenging Terrain', 'authors': 'Manas Gupta, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.06083', 'abstract': 'Safety has been of paramount importance in motion planning and control techniques and is an active area of research in the past few years. Most safety research for mobile robots target at maintaining safety with the notion of collision avoidance. However, safety goes beyond just avoiding collisions, especially when robots have to navigate unstructured, vertically challenging, off-road terrain, where vehicle rollover and immobilization is as critical as collisions. In this work, we introduce a novel Traversability-based Control Barrier Function (T-CBF), in which we use neural Control Barrier Functions (CBFs) to achieve safety beyond collision avoidance on unstructured vertically challenging terrain by reasoning about new safety aspects in terms of traversability. The neural T-CBF trained on safe and unsafe observations specific to traversability safety is then used to generate safe trajectories. Furthermore, we present experimental results in simulation and on a physical Verti-4 Wheeler (V4W) platform, demonstrating that T-CBF can provide traversability safety while reaching the goal position. T-CBF planner outperforms previously developed planners by 30\\% in terms of keeping the robot safe and mobile when navigating on real world vertically challenging terrain.', 'abstract_zh': '基于通行性的控制壁垒函数在垂直挑战性非结构化地形上的安全性研究', 'title_zh': '基于通过性控制屏障函数的导航垂直挑战地形方法'}
{'arxiv_id': 'arXiv:2503.06075', 'title': 'FSDP: Fast and Safe Data-Driven Overtaking Trajectory Planning for Head-to-Head Autonomous Racing Competitions', 'authors': 'Cheng Hu, Jihao Huang, Wule Mao, Yonghao Fu, Xuemin Chi, Haotong Qin, Nicolas Baumann, Zhitao Liu, Michele Magno, Lei Xie', 'link': 'https://arxiv.org/abs/2503.06075', 'abstract': "Generating overtaking trajectories in autonomous racing is a challenging task, as the trajectory must satisfy the vehicle's dynamics and ensure safety and real-time performance running on resource-constrained hardware. This work proposes the Fast and Safe Data-Driven Planner to address this challenge. Sparse Gaussian predictions are introduced to improve both the computational efficiency and accuracy of opponent predictions. Furthermore, the proposed approach employs a bi-level quadratic programming framework to generate an overtaking trajectory leveraging the opponent predictions. The first level uses polynomial fitting to generate a rough trajectory, from which reference states and control inputs are derived for the second level. The second level formulates a model predictive control optimization problem in the Frenet frame, generating a trajectory that satisfies both kinematic feasibility and safety. Experimental results on the F1TENTH platform show that our method outperforms the State-of-the-Art, achieving an 8.93% higher overtaking success rate, allowing the maximum opponent speed, ensuring a smoother ego trajectory, and reducing 74.04% computational time compared to the Predictive Spliner method. The code is available at: this https URL.", 'abstract_zh': '基于数据驱动的快速与安全超车路径规划：一种面向自主赛车的解决方案', 'title_zh': 'FSDP: 快速安全的数据驱动超车轨迹规划用于头对头自动驾驶赛车比赛'}
{'arxiv_id': 'arXiv:2503.06060', 'title': 'STAR: A Foundation Model-driven Framework for Robust Task Planning and Failure Recovery in Robotic Systems', 'authors': 'Md Sadman Sakib, Yu Sun', 'link': 'https://arxiv.org/abs/2503.06060', 'abstract': "Modern robotic systems, deployed across domains from industrial automation to domestic assistance, face a critical challenge: executing tasks with precision and adaptability in dynamic, unpredictable environments. To address this, we propose STAR (Smart Task Adaptation and Recovery), a novel framework that synergizes Foundation Models (FMs) with dynamically expanding Knowledge Graphs (KGs) to enable resilient task planning and autonomous failure recovery. While FMs offer remarkable generalization and contextual reasoning, their limitations, including computational inefficiency, hallucinations, and output inconsistencies hinder reliable deployment. STAR mitigates these issues by embedding learned knowledge into structured, reusable KGs, which streamline information retrieval, reduce redundant FM computations, and provide precise, scenario-specific insights. The framework leverages FM-driven reasoning to diagnose failures, generate context-aware recovery strategies, and execute corrective actions without human intervention or system restarts. Unlike conventional approaches that rely on rigid protocols, STAR dynamically expands its KG with experiential knowledge, ensuring continuous adaptation to novel scenarios. To evaluate the effectiveness of this approach, we developed a comprehensive dataset that includes various robotic tasks and failure scenarios. Through extensive experimentation, STAR demonstrated an 86% task planning accuracy and 78% recovery success rate, showing significant improvements over baseline methods. The framework's ability to continuously learn from experience while maintaining structured knowledge representation makes it particularly suitable for long-term deployment in real-world applications.", 'abstract_zh': '现代机器人系统在从工业自动化到家庭协助等多个领域部署时，面临一个关键挑战：在动态且不可预测的环境中实现精确和适应性的任务执行。为此，我们提出了一种名为STAR（智能任务适应与恢复）的新颖框架，该框架将基础模型（FMs）与动态扩展的知识图谱（KGs）相结合，以实现鲁棒的任务规划和自主故障恢复。虽然FMs提供了出色的泛化能力和上下文推理能力，但其计算效率低下、幻觉和输出不一致等问题限制了其可靠部署。STAR通过将学习的知识嵌入到结构化、可重复使用的KG中，简化信息检索、减少冗余的FM计算，并提供精确且场景特定的洞察，解决了这些问题。该框架利用FM驱动的推理进行故障诊断、生成上下文感知的恢复策略，并在无需人工干预或系统重启的情况下执行纠正动作。与依赖于刚性协议的常规方法不同，STAR动态扩展其KG以获取经验知识，确保其能够持续适应新的场景。为了评估该方法的有效性，我们开发了一个全面的数据集，其中包括各种机器人任务和故障场景。通过广泛的实验，STAR展示了86%的任务规划准确率和78%的恢复成功率，显著优于基准方法。框架具备持续学习经验并将知识表示结构化的特性，使其特别适用于在实际应用中的长期部署。', 'title_zh': 'STAR：一种基于基础模型的任务规划和故障恢复框架在机器人系统中的应用'}
{'arxiv_id': 'arXiv:2503.06050', 'title': 'Energy-Efficient Motion Planner for Legged Robots', 'authors': 'Alexander Schperberg, Marcel Menner, Stefano Di Cairano', 'link': 'https://arxiv.org/abs/2503.06050', 'abstract': "We propose an online motion planner for legged robot locomotion with the primary objective of achieving energy efficiency. The conceptual idea is to leverage a placement set of footstep positions based on the robot's body position to determine when and how to execute steps. In particular, the proposed planner uses virtual placement sets beneath the hip joints of the legs and executes a step when the foot is outside of such placement set. Furthermore, we propose a parameter design framework that considers both energy-efficiency and robustness measures to optimize the gait by changing the shape of the placement set along with other parameters, such as step height and swing time, as a function of walking speed. We show that the planner produces trajectories that have a low Cost of Transport (CoT) and high robustness measure, and evaluate our approach against model-free Reinforcement Learning (RL) and motion imitation using biological dog motion priors as the reference. Overall, within low to medium velocity range, we show a 50.4% improvement in CoT and improved robustness over model-free RL, our best performing baseline. Finally, we show ability to handle slippery surfaces, gait transitions, and disturbances in simulation and hardware with the Unitree A1 robot.", 'abstract_zh': '一种基于腿部位置的在线运动规划算法：实现能效与鲁棒性的优化', 'title_zh': '腿式机器人节能运动规划'}
{'arxiv_id': 'arXiv:2503.06026', 'title': 'Zero-Shot Peg Insertion: Identifying Mating Holes and Estimating SE(2) Poses with Vision-Language Models', 'authors': 'Masaru Yajima, Kei Ota, Asako Kanezaki, Rei Kawakami', 'link': 'https://arxiv.org/abs/2503.06026', 'abstract': 'Achieving zero-shot peg insertion, where inserting an arbitrary peg into an unseen hole without task-specific training, remains a fundamental challenge in robotics. This task demands a highly generalizable perception system capable of detecting potential holes, selecting the correct mating hole from multiple candidates, estimating its precise pose, and executing insertion despite uncertainties. While learning-based methods have been applied to peg insertion, they often fail to generalize beyond the specific peg-hole pairs encountered during training. Recent advancements in Vision-Language Models (VLMs) offer a promising alternative, leveraging large-scale datasets to enable robust generalization across diverse tasks. Inspired by their success, we introduce a novel zero-shot peg insertion framework that utilizes a VLM to identify mating holes and estimate their poses without prior knowledge of their geometry. Extensive experiments demonstrate that our method achieves 90.2% accuracy, significantly outperforming baselines in identifying the correct mating hole across a wide range of previously unseen peg-hole pairs, including 3D-printed objects, toy puzzles, and industrial connectors. Furthermore, we validate the effectiveness of our approach in a real-world connector insertion task on a backpanel of a PC, where our system successfully detects holes, identifies the correct mating hole, estimates its pose, and completes the insertion with a success rate of 88.3%. These results highlight the potential of VLM-driven zero-shot reasoning for enabling robust and generalizable robotic assembly.', 'abstract_zh': '实现零样本钉销插入，即在未进行特定任务训练的情况下将任意钉销插入未见的孔中，仍然是机器人技术中的一个基本挑战。该任务要求具备高度普适性的感知系统，能够检测潜在的孔，从多个候选孔中选择正确的配对孔，估计其精确的姿态，并在存在不确定性的情况下执行插入。尽管基于学习的方法已被应用于钉销插入，但它们常常无法泛化到训练过程中未遇到的特定钉销-孔对。最近在视觉-语言模型（VLMs）方面的进展提供了一种有前景的替代方案，通过大规模数据集实现了对各种任务的稳健泛化。受到它们成功的启发，我们提出了一种新的零样本钉销插入框架，利用VLM来识别配对孔及其姿态，无需了解其几何形状。广泛实验表明，我们的方法在识别正确配对孔方面达到了90.2%的准确率，在包括3D打印物体、玩具拼图和工业连接器在内的广泛未见钉销-孔对中显著优于基线方法。此外，我们在PC背板上的实际连接器插入任务中验证了我们方法的有效性，我们的系统成功检测到孔、识别正确的配对孔、估计其姿态，并以88.3%的成功率完成了插入。这些结果突显了VLM驱动的零样本推理在实现鲁棒且普适的机器人装配方面的潜力。', 'title_zh': '零样本针孔插入：使用视觉-语言模型识别配合孔并估计SE(2)姿态'}
{'arxiv_id': 'arXiv:2503.06010', 'title': 'InfoFusion Controller: Informed TRRT Star with Mutual Information based on Fusion of Pure Pursuit and MPC for Enhanced Path Planning', 'authors': 'Seongjun Choi, Youngbum Kim, Nam Woo Kim, Mansun Shin, Byunggi Chae, Sungjin Lee', 'link': 'https://arxiv.org/abs/2503.06010', 'abstract': 'In this paper, we propose the InfoFusion Controller, an advanced path planning algorithm that integrates both global and local planning strategies to enhance autonomous driving in complex urban environments. The global planner utilizes the informed Theta-Rapidly-exploring Random Tree Star (Informed-TRRT*) algorithm to generate an optimal reference path, while the local planner combines Model Predictive Control (MPC) and Pure Pursuit algorithms. Mutual Information (MI) is employed to fuse the outputs of the MPC and Pure Pursuit controllers, effectively balancing their strengths and compensating for their weaknesses. The proposed method addresses the challenges of navigating in dynamic environments with unpredictable obstacles by reducing uncertainty in local path planning and improving dynamic obstacle avoidance capabilities. Experimental results demonstrate that the InfoFusion Controller outperforms traditional methods in terms of safety, stability, and efficiency across various scenarios, including complex maps generated using SLAM techniques.\nThe code for the InfoFusion Controller is available at https: //github.com/DrawingProcess/InfoFusionController.', 'abstract_zh': '本文提出了一种名为InfoFusion Controller的高级路径规划算法，该算法结合全局和局部规划策略以增强在复杂城市环境中的自主驾驶能力。全局规划器采用知情Theta-Rapidly-exploring Random Tree Star (Informed-TRRT*) 算法生成最优参考路径，局部规划器结合了模型预测控制（MPC）和纯追踪算法。通过互信息（MI）融合MPC和纯追踪控制器的输出，有效平衡其优势并弥补其不足。所提出的方法通过减少局部路径规划中的不确定性并提高动态障碍物避免能力，解决了动态环境中不可预测障碍物的导航挑战。实验结果表明，在各种场景下，包括使用SLAM技术生成的复杂地图情景中，InfoFusion Controller在安全性、稳定性和效率方面均优于传统方法。', 'title_zh': '基于纯追迹与模型预测控制融合的互信息引导TRRT星型信息融合控制器：增强路径规划'}
{'arxiv_id': 'arXiv:2503.05997', 'title': 'Learning to Drive by Imitating Surrounding Vehicles', 'authors': 'Yasin Sonmez, Hanna Krasowski, Murat Arcak', 'link': 'https://arxiv.org/abs/2503.05997', 'abstract': "Imitation learning is a promising approach for training autonomous vehicles (AV) to navigate complex traffic environments by mimicking expert driver behaviors. However, a major challenge in this paradigm lies in effectively utilizing available driving data, as collecting new data is resource-intensive and often limited in its ability to cover diverse driving scenarios. While existing imitation learning frameworks focus on leveraging expert demonstrations, they often overlook the potential of additional complex driving data from surrounding traffic participants. In this paper, we propose a data augmentation strategy that enhances imitation learning by leveraging the observed trajectories of nearby vehicles, captured through the AV's sensors, as additional expert demonstrations. We introduce a vehicle selection sampling strategy that prioritizes informative and diverse driving behaviors, contributing to a richer and more diverse dataset for training. We evaluate our approach using the state-of-the-art learning-based planning method PLUTO on the nuPlan dataset and demonstrate that our augmentation method leads to improved performance in complex driving scenarios. Specifically, our method reduces collision rates and improves safety metrics compared to the baseline. Notably, even when using only 10% of the original dataset, our method achieves performance comparable to that of the full dataset, with improved collision rates. Our findings highlight the importance of leveraging diverse real-world trajectory data in imitation learning and provide insights into data augmentation strategies for autonomous driving.", 'abstract_zh': '利用附近车辆的观测轨迹进行数据增强以提升自主车辆的模仿学习性能', 'title_zh': '通过模仿周围车辆学习驾驶'}
{'arxiv_id': 'arXiv:2503.05995', 'title': 'ReJSHand: Efficient Real-Time Hand Pose Estimation and Mesh Reconstruction Using Refined Joint and Skeleton Features', 'authors': 'Shan An, Shipeng Dai, Mahrukh Ansari, Yu Liang, Ming Zeng, Konstantinos A. Tsintotas, Changhong Fu, Hong Zhang', 'link': 'https://arxiv.org/abs/2503.05995', 'abstract': "Accurate hand pose estimation is vital in robotics, advancing dexterous manipulation in human-computer interaction. Toward this goal, this paper presents ReJSHand (which stands for Refined Joint and Skeleton Features), a cutting-edge network formulated for real-time hand pose estimation and mesh reconstruction. The proposed framework is designed to accurately predict 3D hand gestures under real-time constraints, which is essential for systems that demand agile and responsive hand motion tracking. The network's design prioritizes computational efficiency without compromising accuracy, a prerequisite for instantaneous robotic interactions. Specifically, ReJSHand comprises a 2D keypoint generator, a 3D keypoint generator, an expansion block, and a feature interaction block for meticulously reconstructing 3D hand poses from 2D imagery. In addition, the multi-head self-attention mechanism and a coordinate attention layer enhance feature representation, streamlining the creation of hand mesh vertices through sophisticated feature mapping and linear transformation. Regarding performance, comprehensive evaluations on the FreiHand dataset demonstrate ReJSHand's computational prowess. It achieves a frame rate of 72 frames per second while maintaining a PA-MPJPE (Position-Accurate Mean Per Joint Position Error) of 6.3 mm and a PA-MPVPE (Position-Accurate Mean Per Vertex Position Error) of 6.4 mm. Moreover, our model reaches scores of 0.756 for F@05 and 0.984 for F@15, surpassing modern pipelines and solidifying its position at the forefront of robotic hand pose estimators. To facilitate future studies, we provide our source code at ~\\url{this https URL}.", 'abstract_zh': '精确的手部姿态估计对于机器人技术至关重要，能够推动人类与计算机交互中的灵巧操作。为了实现这一目标，本文提出了ReJSHand（即精炼关节与骨架特征），这是一种专为实时手部姿态估计和网格重建设计的先进网络。该提出的框架旨在在实时约束条件下准确预测3D手部手势，这对于需要敏捷且响应式手部动作追踪的系统至关重要。网络的设计优先考虑计算效率，同时不牺牲准确性，这是即时机器人交互的先决条件。具体而言，ReJSHand 包括一个2D关键点生成器、一个3D关键点生成器、一个扩展块和一个特征交互块，用于细致地从2D图像重构3D手部姿态。此外，多头自注意机制和坐标注意层增强了特征表示，通过复杂的特征映射和线性变换简化了手部网格顶点的创建。关于性能，在FreiHand数据集上的综合评估表明，ReJSHand具有出色的计算能力。它在保持PA-MPJPE（位置准确的每关节位置误差）为6.3 mm和PA-MPVPE（位置准确的每顶点位置误差）为6.4 mm的同时，帧率为每秒72帧。此外，我们的模型在F@05和F@15上的得分为0.756和0.984，超越了现代流水线，巩固了其在机器人手部姿态估计器中的领先地位。为了促进未来的研究，我们已提供了一致的源代码：\\url{this https URL}。', 'title_zh': 'ReJSHand: 采用精炼关节和骨架特征的高效实时手部姿态估计与网格重建'}
{'arxiv_id': 'arXiv:2503.05972', 'title': 'Optimal sensor deception in stochastic environments with partial observability to mislead a robot to a decoy goal', 'authors': 'Hazhar Rahmani, Mukulika Ghosh, Syed Md Hasnayeen', 'link': 'https://arxiv.org/abs/2503.05972', 'abstract': "Deception is a common strategy adapted by autonomous systems in adversarial settings. Existing deception methods primarily focus on increasing opacity or misdirecting agents away from their goal or itinerary. In this work, we propose a deception problem aiming to mislead the robot towards a decoy goal through altering sensor events under a constrained budget of alteration. The environment along with the robot's interaction with it is modeled as a Partially Observable Markov Decision Process (POMDP), and the robot's action selection is governed by a Finite State Controller (FSC). Given a constrained budget for sensor event modifications, the objective is to compute a sensor alteration that maximizes the probability of the robot reaching a decoy goal. We establish the computational hardness of the problem by a reduction from the $0/1$ Knapsack problem and propose a Mixed Integer Linear Programming (MILP) formulation to compute optimal deception strategies. We show the efficacy of our MILP formulation via a sequence of experiments.", 'abstract_zh': '自主系统在对抗环境中采用欺骗策略是一种常见手段。现有欺骗方法主要集中在增加透明度或误导代理偏离其目标或行程。在本工作中，我们提出了一种欺骗问题，旨在通过在有限的事件修改预算下改变传感器事件来引导机器人达到一个诱饵目标。将环境以及机器人与其的交互建模为部分可观测马尔可夫决策过程（POMDP），机器人的动作选择由有限状态控制器（FSC）支配。给定一个传感器事件修改的预算，目标是计算一个能最大化机器人达到诱饵目标概率的传感器修改。通过从0/1背包问题归约证明该问题的计算难度，并提出混合整数线性规划（MILP）公式来计算最优欺骗策略。通过一系列实验展示了我们MILP公式的有效性。', 'title_zh': '部分可观测随机环境中传感器欺骗的最优策略：误导机器人达到诱饵目标'}
{'arxiv_id': 'arXiv:2503.05953', 'title': 'Differentiable Rendering-based Pose Estimation for Surgical Robotic Instruments', 'authors': 'Zekai Liang, Zih-Yun Chiu, Florian Richter, Michael C. Yip', 'link': 'https://arxiv.org/abs/2503.05953', 'abstract': 'Robot pose estimation is a challenging and crucial task for vision-based surgical robotic automation. Typical robotic calibration approaches, however, are not applicable to surgical robots, such as the da Vinci Research Kit (dVRK), due to joint angle measurement errors from cable-drives and the partially visible kinematic chain. Hence, previous works in surgical robotic automation used tracking algorithms to estimate the pose of the surgical tool in real-time and compensate for the joint angle errors. However, a big limitation of these previous tracking works is the initialization step which relied on only keypoints and SolvePnP. In this work, we fully explore the potential of geometric primitives beyond just keypoints with differentiable rendering, cylinders, and construct a versatile pose matching pipeline in a novel pose hypothesis space. We demonstrate the state-of-the-art performance of our single-shot calibration method with both calibration consistency and real surgical tasks. As a result, this marker-less calibration approach proves to be a robust and generalizable initialization step for surgical tool tracking.', 'abstract_zh': '基于视觉的手术机器人自动化中的机器人姿态估计是具有挑战性和关键性的任务。然而，传统的一些机器人标定方法不适用于如da Vinci Research Kit (dVRK)这样的手术机器人，这主要是由于电缆驱动产生的关节角度测量误差以及部分可见的运动链。因此，手术机器人自动化领域的先前工作使用跟踪算法实时估计手术工具的姿态并补偿关节角度误差。然而，这些先前跟踪工作的主要限制在于其初始化步骤，该步骤仅依赖关键点和SolvePnP。在本工作中，我们利用可微渲染和圆柱体等几何原语，全面探索了超越关键点的潜力，并构建了一个全新的姿态假设空间中的多功能姿态匹配管道。我们展示了我们的单次校准方法在校准一致性和实际手术任务中的先进性能。由此，此无标记校准方法证明是一种稳健且通用的初始化步骤，适用于手术工具跟踪。', 'title_zh': '基于可微渲染的姿态估计方法在手术机器人器械中的应用'}
{'arxiv_id': 'arXiv:2503.05939', 'title': 'Universal Framework to Evaluate Automotive Perception Sensor Impact on Perception Functions', 'authors': 'A Gamage, V Donzella', 'link': 'https://arxiv.org/abs/2503.05939', 'abstract': 'Current research on automotive perception systems predominantly focusses on either improving the sensors for data quality or enhancing the performance of perception functions in isolation. Although automotive perception sensors form a fundamental part of the perception system, value addition in sensor data quality in isolation is questionable. However, the end goal for most perception systems is the accuracy of high-level functions such as trajectory prediction of surrounding vehicles. High-level perception functions are increasingly based on deep learning (DL) models due to their improved performance and generalisability compared to traditional algorithms. Innately, DL models develop a performance bias on the comprehensiveness of the training data. Despite the vital need to evaluate the performance of DL-based perception functions under real-world conditions using onboard sensor inputs, there is a lack of frameworks to facilitate systematic evaluations. This paper presents a versatile and cost-effective framework to evaluate the impact of perception sensor modalities and parameter settings on DL-based perception functions. Using a simulation environment, the framework facilitates sensor modality testing and parameter tuning under different environmental conditions. Its effectiveness is demonstrated through a case study involving a state-of-the-art surround trajectory prediction model, highlighting performance differences across sensor modalities and recommending optimal parameter settings. The proposed framework offers valuable insights for designing the perception sensor suite, contributing to the development of robust perception systems for autonomous vehicles.', 'abstract_zh': '基于传感器模态和参数设置对_DL驱动的感知函数影响的综合评价框架', 'title_zh': '通用框架评估汽车感知传感器对感知功能的影响'}
{'arxiv_id': 'arXiv:2503.05911', 'title': 'Generalizable Image Repair for Robust Visual Autonomous Racing', 'authors': 'Carson Sobolewski, Zhenjiang Mao, Kshitij Vejre, Ivan Ruchkin', 'link': 'https://arxiv.org/abs/2503.05911', 'abstract': 'Vision-based autonomous racing relies on accurate perception for robust control. However, image distribution changes caused by sensor noise, adverse weather, and dynamic lighting can degrade perception, leading to suboptimal control decisions. Existing approaches, including domain adaptation and adversarial training, improve robustness but struggle to generalize to unseen corruptions while introducing computational overhead. To address this challenge, we propose a real-time image repair module that restores corrupted images before they are used by the controller. Our method leverages generative adversarial models, specifically CycleGAN and pix2pix, for image repair. CycleGAN enables unpaired image-to-image translation to adapt to novel corruptions, while pix2pix exploits paired image data when available to improve the quality. To ensure alignment with control performance, we introduce a control-focused loss function that prioritizes perceptual consistency in repaired images. We evaluated our method in a simulated autonomous racing environment with various visual corruptions. The results show that our approach significantly improves performance compared to baselines, mitigating distribution shift and enhancing controller reliability.', 'abstract_zh': '基于视觉的自动驾驶赛车依赖于准确的感知以实现稳健的控制。然而，由于传感器噪声、不良天气和动态光照引起图像分布的变化会降低感知质量，导致次优化的控制决策。现有方法，包括领域适应和对抗训练，在提高稳健性的同时，难以泛化到未见过的损坏场景，并且会增加计算开销。为了解决这一挑战，我们提出了一种实时图像修复模块，在控制器使用图像之前对其进行修复。我们的方法利用生成对抗模型，特别是CycleGAN和pix2pix进行图像修复。CycleGAN允许无配对的图像到图像的翻译以适应新型损坏，而pix2pix在可用时利用配对图像数据提高图像质量。为了确保与控制性能的对齐，我们引入了一种以控制为重点的损失函数，以优先考虑修复图像中的感知一致性。我们在具有各种视觉损坏的真实自动驾驶赛车环境中评估了该方法。结果表明，与基线方法相比，我们的方法显著提高了性能，减轻了分布转移并增强了控制器的可靠性。', 'title_zh': '通用图像修复以提高视觉自主赛车的 robustness'}
{'arxiv_id': 'arXiv:2503.05904', 'title': 'REACT: Multi Robot Energy-Aware Orchestrator for Indoor Search and Rescue Critical Tasks', 'authors': 'Fabio Maresca, Arnau Romero, Carmen Delgado, Vincenzo Sciancalepore, Josep Paradells, Xavier Costa-Pérez', 'link': 'https://arxiv.org/abs/2503.05904', 'abstract': 'Smart factories enhance production efficiency and sustainability, but emergencies like human errors, machinery failures and natural disasters pose significant risks. In critical situations, such as fires or earthquakes, collaborative robots can assist first-responders by entering damaged buildings and locating missing persons, mitigating potential losses. Unlike previous solutions that overlook the critical aspect of energy management, in this paper we propose REACT, a smart energy-aware orchestrator that optimizes the exploration phase, ensuring prolonged operational time and effective area coverage. Our solution leverages a fleet of collaborative robots equipped with advanced sensors and communication capabilities to explore and navigate unknown indoor environments, such as smart factories affected by fires or earthquakes, with high density of obstacles. By leveraging real-time data exchange and cooperative algorithms, the robots dynamically adjust their paths, minimize redundant movements and reduce energy consumption. Extensive simulations confirm that our approach significantly improves the efficiency and reliability of search and rescue missions in complex indoor environments, improving the exploration rate by 10% over existing methods and reaching a map coverage of 97% under time critical operations, up to nearly 100% under relaxed time constraint.', 'abstract_zh': '智能工厂提高生产效率和可持续性，但人类错误、机械设备故障和自然灾害等突发事件会带来重大风险。在火灾或地震等关键时刻，协作机器人可以通过进入受损建筑并定位失踪人员，减轻潜在损失。有别于以往忽视能源管理关键因素的解决方案，本文提出REACT，一种智能能源感知调度器，优化探索阶段，确保延长操作时间和有效覆盖范围。该解决方案利用配备先进传感器和通信能力的协作机器人队列，高效探索和导航复杂障碍物环境，如受火灾或地震影响的智能工厂。通过实时数据交换和协作算法，机器人动态调整路径，减少冗余运动并降低能耗。广泛模拟证实，本方法显著提高了复杂室内环境中搜索和救援任务的效率和可靠性，探索率较现有方法提高10%，在时间紧迫操作下达到97%的地图覆盖率，在较宽松时间约束下接近100%。', 'title_zh': 'REACT：多机器人室内搜索救援关键任务能量感知调度器'}
{'arxiv_id': 'arXiv:2503.05887', 'title': 'MatchMaker: Automated Asset Generation for Robotic Assembly', 'authors': 'Yian Wang, Bingjie Tang, Chuang Gan, Dieter Fox, Kaichun Mo, Yashraj Narang, Iretiayo Akinola', 'link': 'https://arxiv.org/abs/2503.05887', 'abstract': 'Robotic assembly remains a significant challenge due to complexities in visual perception, functional grasping, contact-rich manipulation, and performing high-precision tasks. Simulation-based learning and sim-to-real transfer have led to recent success in solving assembly tasks in the presence of object pose variation, perception noise, and control error; however, the development of a generalist (i.e., multi-task) agent for a broad range of assembly tasks has been limited by the need to manually curate assembly assets, which greatly constrains the number and diversity of assembly problems that can be used for policy learning. Inspired by recent success of using generative AI to scale up robot learning, we propose MatchMaker, a pipeline to automatically generate diverse, simulation-compatible assembly asset pairs to facilitate learning assembly skills. Specifically, MatchMaker can 1) take a simulation-incompatible, interpenetrating asset pair as input, and automatically convert it into a simulation-compatible, interpenetration-free pair, 2) take an arbitrary single asset as input, and generate a geometrically-mating asset to create an asset pair, 3) automatically erode contact surfaces from (1) or (2) according to a user-specified clearance parameter to generate realistic parts. We demonstrate that data generated by MatchMaker outperforms previous work in terms of diversity and effectiveness for downstream assembly skill learning. For videos and additional details, please see our project website: this https URL.', 'abstract_zh': '基于视觉感知、功能抓取、高接触操作以及执行高精度任务的复杂性，机器人装配仍是一项重大挑战。基于模拟的学习和从模拟到现实的迁移已成功解决了因物体姿态变化、感知噪声和控制误差导致的装配任务；然而，开发适用于广泛装配任务的通用型（即多任务）智能体受到手动编排装配资源的限制，大大制约了可用的装配问题数量及其多样性，从而影响策略学习。受使用生成式AI扩大机器人学习规模的最新成果启发，我们提出MatchMaker，一种自动生成多样化、可模拟装配资产对的管道，以便于装配技能的学习。具体而言，MatchMaker可以1）将一个不兼容模拟、相互穿插的资产对作为输入，并自动转换为兼容模拟、无穿插的资产对；2）将任意单个资产作为输入，生成几何互补的资产以创建资产对；3）根据用户指定的间隙参数，自动对（1）或（2）中的接触面进行侵蚀，生成具有现实感的部件。我们证明，由MatchMaker生成的数据在下游装配技能学习方面在多样性和效果上优于先前的工作。更多视频和细节，请参见我们的项目网站：this https URL。', 'title_zh': 'MatchMaker：自动资产生成用于机器人装配'}
{'arxiv_id': 'arXiv:2503.05853', 'title': 'Enhancing Thin-Film Wafer Inspection With A Multi-Sensor Array And Robot Constraint Maintenance', 'authors': 'Néstor Eduardo Sánchez-Arriaga, Ethan Canzini, Nathan John Espley-Plumb, Michael Farnsworth, Simon Pope, Adrian Leyland, Ashutosh Tiwari', 'link': 'https://arxiv.org/abs/2503.05853', 'abstract': 'Thin-film inspection on large-area substrates in coating manufacture remains a critical parameter to ensure product quality; however, extending the inspection process precisely over a large area presents major challenges, due to the limitations of the available inspection equipment. An additional manipulation problem arises when automating the inspection process, as the silicon wafer requires movement constraints to ensure accurate measurements and to prevent damage. Furthermore, there are other increasingly important large-area industrial applications, such as Roll-to-Roll (R2R) manufacturing where coating thickness inspection introduces additional challenges. This paper presents an autonomous inspection system using a robotic manipulator with a novel learned constraint manifold to control a wafer to its calibration point, and a novel multi-sensor array with high potential for scalability into large substrate areas. We demonstrate that the manipulator can perform required motions whilst adhering to movement constraints. We further demonstrate that the sensor array can perform thickness measurements statically with an error of $<2\\%$ compared to a commercial reflectometer, and through the use of a manipulator can dynamically detect angle variations $>0.5^\\circ$ from the calibration point whilst monitoring the RMSE and $R^2$ over 1406 data points. These features are potentially useful for detecting displacement variations in R2R manufacturing processes.', 'abstract_zh': '基于机器人操作器的新型约束流形自主检测系统在大面积基底上的薄膜厚度检测', 'title_zh': '增强薄片晶圆检测的多传感器阵列与机器人约束维护'}
{'arxiv_id': 'arXiv:2503.05848', 'title': 'Merry-Go-Round: Safe Control of Decentralized Multi-Robot Systems with Deadlock Prevention', 'authors': 'Wonjong Lee, Joonyeol Sim, Joonkyung Kim, Siwon Jo, Wenhao Luo, Changjoo Nam', 'link': 'https://arxiv.org/abs/2503.05848', 'abstract': 'We propose a hybrid approach for decentralized multi-robot navigation that ensures both safety and deadlock prevention. Building on a standard control formulation, we add a lightweight deadlock prevention mechanism by forming temporary "roundabouts" (circular reference paths). Each robot relies only on local, peer-to-peer communication and a controller for base collision avoidance; a roundabout is generated or joined on demand to avert deadlocks. Robots in the roundabout travel in one direction until an escape condition is met, allowing them to return to goal-oriented motion. Unlike classical decentralized methods that lack explicit deadlock resolution, our roundabout maneuver ensures system-wide forward progress while preserving safety constraints. Extensive simulations and physical robot experiments show that our method consistently outperforms or matches the success and arrival rates of other decentralized control approaches, particularly in cluttered or high-density scenarios, all with minimal centralized coordination.', 'abstract_zh': '基于安全性与死锁预防的分布式多机器人导航混合方法', 'title_zh': '旋转木马：具备死锁预防的分布式多机器人系统安全控制'}
{'arxiv_id': 'arXiv:2503.05833', 'title': 'Refined Policy Distillation: From VLA Generalists to RL Experts', 'authors': 'Tobias Jülg, Wolfram Burgard, Florian Walter', 'link': 'https://arxiv.org/abs/2503.05833', 'abstract': "Recent generalist Vision-Language-Action Models (VLAs) can perform a variety of tasks on real robots with remarkable generalization capabilities. However, reported success rates are often not on par with those of expert policies. Moreover, VLAs usually do not work out of the box and often must be fine-tuned as they are sensitive to setup changes. In this work, we present Refined Policy Distillation (RPD), an RL-based policy refinement method that enables the distillation of large generalist models into small, high-performing expert policies. The student policy is guided during the RL exploration by actions of a teacher VLA for increased sample efficiency and faster convergence. Different from previous work that focuses on applying VLAs to real-world experiments, we create fine-tuned versions of Octo and OpenVLA for ManiSkill2 to evaluate RPD in simulation. As our results for different manipulation tasks demonstrate, RPD enables the RL agent to learn expert policies that surpass the teacher's performance in both dense and sparse reward settings. Our approach is even robust to changes in the camera perspective and can generalize to task variations that the underlying VLA cannot solve.", 'abstract_zh': 'recent 通用视觉-语言-行动模型 (VLAs) 在现实机器人上可以执行多种任务，并展现出显著的泛化能力。然而，报道的成功率往往不如专家策略。此外，VLAs 通常无法开箱即用，并且往往需要微调，因为它们对环境设置变化极为敏感。在本工作中，我们提出了一种基于强化学习 (RL) 的策略精炼方法 Refined Policy Distillation (RPD)，该方法能够将大规模通用模型精炼为小规模、高性能的专家策略。学生策略在 RL 探索过程中由教师 VLA 的行动引导，以提高样本效率并加快收敛速度。与以往专注于将 VLAs 应用于实际实验的工作不同，我们为 ManiSkill2 创建了 Octo 和 OpenVLA 的微调版本，以评估 RPD 在仿真中的效果。我们的结果显示，在不同的操作任务中，RPD 使 RL 剂能够学习出超越教师策略性能的专家策略，无论是在稠密奖励设置还是稀疏奖励设置中。此外，我们的方法甚至对相机视角的变化具有鲁棒性，并且能够泛化到基础 VLA 无法解决的任务变化。', 'title_zh': '精炼的策略蒸馏：从多领域专家到RL专家'}
{'arxiv_id': 'arXiv:2503.05825', 'title': 'A Human-In-The-Loop Simulation Framework for Evaluating Control Strategies in Gait Assistive Robots', 'authors': 'Yifan Wang, Sherwin Stephen Chan, Mingyuan Lei, Lek Syn Lim, Henry Johan, Bingran Zuo, Wei Tech Ang', 'link': 'https://arxiv.org/abs/2503.05825', 'abstract': "As the global population ages, effective rehabilitation and mobility aids will become increasingly critical. Gait assistive robots are promising solutions, but designing adaptable controllers for various impairments poses a significant challenge. This paper presented a Human-In-The-Loop (HITL) simulation framework tailored specifically for gait assistive robots, addressing unique challenges posed by passive support systems. We incorporated a realistic physical human-robot interaction (pHRI) model to enable a quantitative evaluation of robot control strategies, highlighting the performance of a speed-adaptive controller compared to a conventional PID controller in maintaining compliance and reducing gait distortion. We assessed the accuracy of the simulated interactions against that of the real-world data and revealed discrepancies in the adaptation strategies taken by the human and their effect on the human's gait. This work underscored the potential of HITL simulation as a versatile tool for developing and fine-tuning personalized control policies for various users.", 'abstract_zh': '随着全球人口老龄化，有效的康复和移动辅助工具将变得越来越重要。步态辅助机器人是很有前景的解决方案，但设计适用于各种障碍的适应性控制器面临着重大挑战。本文介绍了一个针对步态辅助机器人的循环多人在回路（HITL）仿真框架，专门解决了被动支持系统所带来的独特挑战。我们整合了一个真实的物理人机交互（pHRI）模型，以定量评估机器人控制策略，突出了速度自适应控制器与传统PID控制器在保持顺应性和减少步态扭曲方面的性能差异。我们评估了模拟交互的准确性与现实世界数据的准确性，并揭示了人类在适应策略上的差异及其对人类步态的影响。本项工作强调了HITL仿真作为开发和微调适用于各种用户个性化控制策略的多功能工具的潜力。', 'title_zh': '带有闭环的人机仿真框架：评估辅助行走机器人控制策略的有效性'}
{'arxiv_id': 'arXiv:2503.05817', 'title': 'GraphGarment: Learning Garment Dynamics for Bimanual Cloth Manipulation Tasks', 'authors': 'Wei Chen, Kelin Li, Dongmyoung Lee, Xiaoshuai Chen, Rui Zong, Petar Kormushev', 'link': 'https://arxiv.org/abs/2503.05817', 'abstract': 'Physical manipulation of garments is often crucial when performing fabric-related tasks, such as hanging garments. However, due to the deformable nature of fabrics, these operations remain a significant challenge for robots in household, healthcare, and industrial environments. In this paper, we propose GraphGarment, a novel approach that models garment dynamics based on robot control inputs and applies the learned dynamics model to facilitate garment manipulation tasks such as hanging. Specifically, we use graphs to represent the interactions between the robot end-effector and the garment. GraphGarment uses a graph neural network (GNN) to learn a dynamics model that can predict the next garment state given the current state and input action in simulation. To address the substantial sim-to-real gap, we propose a residual model that compensates for garment state prediction errors, thereby improving real-world this http URL garment dynamics model is then applied to a model-based action sampling strategy, where it is utilized to manipulate the garment to a reference pre-hanging configuration for garment-hanging tasks. We conducted four experiments using six types of garments to validate our approach in both simulation and real-world settings. In simulation experiments, GraphGarment achieves better garment state prediction performance, with a prediction error 0.46 cm lower than the best this http URL approach also demonstrates improved performance in the garment-hanging simulation experiment with enhancements of 12%, 24%, and 10%, respectively. Moreover, real-world robot experiments confirm the robustness of sim-to-real transfer, with an error increase of 0.17 cm compared to simulation results. Supplementary material is available at:this https URL.', 'abstract_zh': '基于图的衣物动力学建模与现实转移方法：衣物悬挂任务中的物理操作', 'title_zh': 'GraphGarment: 学习双手法布操作中的服装动力学'}
{'arxiv_id': 'arXiv:2503.07608', 'title': 'AlphaDrive: Unleashing the Power of VLMs in Autonomous Driving via Reinforcement Learning and Reasoning', 'authors': 'Bo Jiang, Shaoyu Chen, Qian Zhang, Wenyu Liu, Xinggang Wang', 'link': 'https://arxiv.org/abs/2503.07608', 'abstract': 'OpenAI o1 and DeepSeek R1 achieve or even surpass human expert-level performance in complex domains like mathematics and science, with reinforcement learning (RL) and reasoning playing a crucial role. In autonomous driving, recent end-to-end models have greatly improved planning performance but still struggle with long-tailed problems due to limited common sense and reasoning abilities. Some studies integrate vision-language models (VLMs) into autonomous driving, but they typically rely on pre-trained models with simple supervised fine-tuning (SFT) on driving data, without further exploration of training strategies or optimizations specifically tailored for planning. In this paper, we propose AlphaDrive, a RL and reasoning framework for VLMs in autonomous driving. AlphaDrive introduces four GRPO-based RL rewards tailored for planning and employs a two-stage planning reasoning training strategy that combines SFT with RL. As a result, AlphaDrive significantly improves both planning performance and training efficiency compared to using only SFT or without reasoning. Moreover, we are also excited to discover that, following RL training, AlphaDrive exhibits some emergent multimodal planning capabilities, which is critical for improving driving safety and efficiency. To the best of our knowledge, AlphaDrive is the first to integrate GRPO-based RL with planning reasoning into autonomous driving. Code will be released to facilitate future research.', 'abstract_zh': 'AlphaDrive：一种结合RL和推理的 Vision-Language 模型自主驾驶框架', 'title_zh': 'AlphaDrive：通过强化学习和推理释放大规模预训练模型在自动驾驶中的潜力'}
{'arxiv_id': 'arXiv:2503.07600', 'title': 'A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI', 'authors': 'Rolf Pfister', 'link': 'https://arxiv.org/abs/2503.07600', 'abstract': 'The article analyses foundational principles relevant to the creation of artificial general intelligence (AGI). Intelligence is understood as the ability to create novel skills that allow to achieve goals under previously unknown conditions. To this end, intelligence utilises reasoning methods such as deduction, induction and abduction as well as other methods such as abstraction and classification to develop a world model. The methods are applied to indirect and incomplete representations of the world, which are obtained through perception, for example, and which do not depict the world but only correspond to it. Due to these limitations and the uncertain and contingent nature of reasoning, the world model is constructivist. Its value is functionally determined by its viability, i.e., its potential to achieve the desired goals. In consequence, meaning is assigned to representations by attributing them a function that makes it possible to achieve a goal. This representational and functional conception of intelligence enables a naturalistic interpretation that does not presuppose mental features, such as intentionality and consciousness, which are regarded as independent of intelligence. Based on a phenomenological analysis, it is shown that AGI can gain a more fundamental access to the world than humans, although it is limited by the No Free Lunch theorems, which require assumptions to be made.', 'abstract_zh': '文章分析了与人工通用智能（AGI）创造相关的基础原理。智能被视为在未知条件下实现目标所需的创造新型技能的能力。为此，智能利用演绎、归纳和 abduction 等推理方法以及其他方法如抽象和分类来建立世界模型。这些方法应用于通过感知等途径获得的间接且不完整的世界表征，这些表征不完全描绘世界，而是与世界相符合。由于这些限制和推理的不确定性和偶然性，世界模型是建构主义的。其价值功能上由其实现所需目标的潜力决定。因此，意义通过赋予表征功能来实现，该功能使得能够实现目标。这种表征和功能的智能观念提供了一种自然主义的解释，无需预设如意向性和意识等mental特征，这些特征被认为是独立于智能之外的。基于现象学分析，研究表明尽管受到No Free Lunch定理的限制，AGI仍可以更基础地接近世界。', 'title_zh': '作为AGI基础的代表主义、功能主义和自然主义的智能观念'}
{'arxiv_id': 'arXiv:2503.07587', 'title': 'Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru', 'authors': 'Dunant Cusipuma, David Ortega, Victor Flores-Benites, Arturo Deza', 'link': 'https://arxiv.org/abs/2503.07587', 'abstract': 'As multimodal foundational models start being deployed experimentally in Self-Driving cars, a reasonable question we ask ourselves is how similar to humans do these systems respond in certain driving situations -- especially those that are out-of-distribution? To study this, we create the Robusto-1 dataset that uses dashcam video data from Peru, a country with one of the worst (aggressive) drivers in the world, a high traffic index, and a high ratio of bizarre to non-bizarre street objects likely never seen in training. In particular, to preliminarly test at a cognitive level how well Foundational Visual Language Models (VLMs) compare to Humans in Driving, we move away from bounding boxes, segmentation maps, occupancy maps or trajectory estimation to multi-modal Visual Question Answering (VQA) comparing both humans and machines through a popular method in systems neuroscience known as Representational Similarity Analysis (RSA). Depending on the type of questions we ask and the answers these systems give, we will show in what cases do VLMs and Humans converge or diverge allowing us to probe on their cognitive alignment. We find that the degree of alignment varies significantly depending on the type of questions asked to each type of system (Humans vs VLMs), highlighting a gap in their alignment.', 'abstract_zh': '当多模态基础模型开始在自动驾驶汽车中实验部署时，我们合理地自问这些系统在某些驾驶情景下与人类的响应有多相似，尤其是在那些超出训练分布的情景下。为了研究这一问题，我们创建了Robusto-1数据集，该数据集使用了秘鲁（世界上驾驶行为最 aggressive 的国家之一）的行车记录仪视频数据，具有高交通密度和高比例的古怪街道物体，这些物体很可能从未出现在训练中。特别是，为了初步测试基础视觉语言模型（VLMs）与人类在驾驶情景下的认知水平表现，我们从边界框、分割图、占用地图或轨迹估计转向多模态视觉问答（VQA），并通过系统神经科学中的一种流行方法——表征相似性分析（RSA），对比人类和机器的回答。根据我们提出的问题类型及系统给出的回答，我们将展示在哪些情况下基础视觉语言模型和人类会趋于一致或存在分歧，从而使我们能够探究它们的认知对齐情况。我们发现，响应的一致性程度取决于对不同类型系统（人类 vs VLMs）提出的问题类型，突显了它们之间认知对齐的差距。', 'title_zh': 'Robusto-1 数据集：将人类与多模态预训练模型在来自秘鲁的实际分布外自主驾驶问答任务中进行比较'}
{'arxiv_id': 'arXiv:2503.07528', 'title': 'Real-Time Structural Deflection Estimation in Hydraulically Actuated Systems Using 3D Flexible Multibody Simulation and DNNs', 'authors': 'Qasim Khadim, Peter Manzl, Emil Kurvinen, Aki Mikkola, Grzegorz Orzechowski, Johannes Gerstmayr', 'link': 'https://arxiv.org/abs/2503.07528', 'abstract': 'The precision, stability, and performance of lightweight high-strength steel structures in heavy machinery is affected by their highly nonlinear dynamics. This, in turn, makes control more difficult, simulation more computationally intensive, and achieving real-time autonomy, using standard approaches, impossible. Machine learning through data-driven, physics-informed and physics-inspired networks, however, promises more computationally efficient and accurate solutions to nonlinear dynamic problems. This study proposes a novel framework that has been developed to estimate real-time structural deflection in hydraulically actuated three-dimensional systems. It is based on SLIDE, a machine-learning-based method to estimate dynamic responses of mechanical systems subjected to forced excitations.~Further, an algorithm is introduced for the data acquisition from a hydraulically actuated system using randomized initial configurations and hydraulic pressures.~The new framework was tested on a hydraulically actuated flexible boom with various sensor combinations and lifting various payloads. The neural network was successfully trained in less time using standard parameters from PyTorch, ADAM optimizer, the various sensor inputs, and minimal output data. The SLIDE-trained neural network accelerated deflection estimation solutions by a factor of $10^7$ in reference to flexible multibody simulation batches and provided reasonable accuracy. These results support the studies goal of providing robust, real-time solutions for control, robotic manipulators, structural health monitoring, and automation problems.', 'abstract_zh': '轻型高强钢结构在重型机械中的精度、稳定性和性能受其高度非线性动力学的影响，这使得控制更加困难，仿真计算更加耗时，使用标准方法实现实时自主控制成为不可能。然而，通过基于数据驱动、物理信息和物理启发的机器学习网络，有望为非线性动力学问题提供更高效和准确的解决方案。本研究提出了一种新的框架，旨在实时估计液压驱动的三维系统中的结构位移。该框架基于一种基于机器学习的方法SLIDE，用于估计受到强制激励的机械系统动力学响应。此外，介绍了一种算法，用于通过随机初始配置和液压压力从液压驱动系统中获取数据。新框架在多种传感器组合和不同负载下测试于一个液压驱动的柔性臂上。神经网络使用标准的PyTorch参数、ADAM优化器和多种传感器输入在较短的时间内成功训练，且少量输出数据即可。SLIDE训练的神经网络将位移估计解决方案的速度提高了$10^7$倍，并提供了合理的精度。这些结果支持了本研究旨在为控制、机器人 manipulator、结构健康监测和自动化问题提供稳健的实时解决方案的目标。', 'title_zh': '使用3D柔性多体仿真和DNNs的液压驱动系统实时结构挠度估计'}
{'arxiv_id': 'arXiv:2503.07376', 'title': 'AttentionSwarm: Reinforcement Learning with Attention Control Barier Function for Crazyflie Drones in Dynamic Environments', 'authors': 'Grik Tadevosyan, Valerii Serpiva, Aleksey Fedoseev, Roohan Ahmed Khan, Demetros Aschu, Faryal Batool, Nickolay Efanov, Artem Mikhaylov, Dzmitry Tsetserukou', 'link': 'https://arxiv.org/abs/2503.07376', 'abstract': 'We introduce AttentionSwarm, a novel benchmark designed to evaluate safe and efficient swarm control across three challenging environments: a landing environment with obstacles, a competitive drone game setting, and a dynamic drone racing scenario. Central to our approach is the Attention Model Based Control Barrier Function (CBF) framework, which integrates attention mechanisms with safety-critical control theory to enable real-time collision avoidance and trajectory optimization. This framework dynamically prioritizes critical obstacles and agents in the swarms vicinity using attention weights, while CBFs formally guarantee safety by enforcing collision-free constraints. The safe attention net algorithm was developed and evaluated using a swarm of Crazyflie 2.1 micro quadrotors, which were tested indoors with the Vicon motion capture system to ensure precise localization and control. Experimental results show that our system achieves landing accuracy of 3.02 cm with a mean time of 23 s and collision-free landings in a dynamic landing environment, 100% and collision-free navigation in a drone game environment, and 95% and collision-free navigation for a dynamic multiagent drone racing environment, underscoring its effectiveness and robustness in real-world scenarios. This work offers a promising foundation for applications in dynamic environments where safety and fastness are paramount.', 'abstract_zh': '我们引入了AttentionSwarm，这是一种新型基准，用于评估在三个具有挑战性的环境中安全且高效的群控制：包含障碍物的降落环境、竞争型无人机游戏设置以及动态无人机竞速场景。我们方法的核心是基于注意力机制的控制障碍函数（CBF）框架，该框架将注意力机制与关键的安全控制理论相结合，以实现实时碰撞 avoidance 和轨迹优化。该框架通过使用注意力权重动态优先处理群周围的关键障碍物和个体，同时通过施加无碰撞约束条件来正式保证安全性。安全注意力网络算法是在室内使用Vicon运动捕捉系统测距的Crazyflie 2.1 微型四旋翼无人机群上开发和验证的。实验结果表明，我们的系统在动态降落环境中的着陆精度为3.02 cm，平均时间为23秒，并实现了无碰撞着陆；在无人机游戏环境中实现了100%的无碰撞导航；在动态多智能体无人机竞速环境中实现了95%的无碰撞导航，证明了其在实际场景中的有效性和鲁棒性。这项工作为在安全性和快速性至关重要的动态环境中应用提供了有前景的基础。', 'title_zh': 'AttentionSwarm: 基于注意力控制屏障函数的动态环境中 Crazyflie 无人机的强化学习'}
{'arxiv_id': 'arXiv:2503.07319', 'title': 'Human Machine Co-Adaptation Model and Its Convergence Analysis', 'authors': 'Steven W. Su, Yaqi Li, Kairui Guo, Rob Duffield', 'link': 'https://arxiv.org/abs/2503.07319', 'abstract': "The key to robot-assisted rehabilitation lies in the design of the human-machine interface, which must accommodate the needs of both patients and machines. Current interface designs primarily focus on machine control algorithms, often requiring patients to spend considerable time adapting. In this paper, we introduce a novel approach based on the Cooperative Adaptive Markov Decision Process (CAMDPs) model to address the fundamental aspects of the interactive learning process, offering theoretical insights and practical guidance. We establish sufficient conditions for the convergence of CAMDPs and ensure the uniqueness of Nash equilibrium points. Leveraging these conditions, we guarantee the system's convergence to a unique Nash equilibrium point. Furthermore, we explore scenarios with multiple Nash equilibrium points, devising strategies to adjust both Value Evaluation and Policy Improvement algorithms to enhance the likelihood of converging to the global minimal Nash equilibrium point. Through numerical experiments, we illustrate the effectiveness of the proposed conditions and algorithms, demonstrating their applicability and robustness in practical settings. The proposed conditions for convergence and the identification of a unique optimal Nash equilibrium contribute to the development of more effective adaptive systems for human users in robot-assisted rehabilitation.", 'abstract_zh': '机器人辅助康复的关键在于人类机界面的设计，必须兼顾患者和机器的需求。当前的接口设计主要集中在机器控制算法上，往往需要患者花费较多时间适应。本文提出了一种基于合作自适应马尔可夫决策过程（CAMDP）模型的新方法，以解决交互学习过程中的基本问题，提供理论洞见和实用指导。我们建立了CAMDP收敛的充分条件，并确保纳什均衡点的唯一性。利用这些条件，我们保证系统收敛于唯一的纳什均衡点。此外，我们探讨了存在多个纳什均衡点的情况，设计策略调整价值评估和策略改进算法，以提高收敛到全局最小纳什均衡点的可能性。通过数值实验，我们展示了所提条件和算法的有效性及其在实际应用中的适用性和鲁棒性。提出的收敛条件和唯一最优纳什均衡的识别有助于开发更有效的适应性系统，以供机器人辅助康复中的人类用户使用。', 'title_zh': '人类机器协同适应模型及其收敛性分析'}
{'arxiv_id': 'arXiv:2503.07268', 'title': 'A High Efficient and Scalable Obstacle-Avoiding VLSI Global Routing Flow', 'authors': 'Junhao Guo, Hongxin Kong, Lang Feng', 'link': 'https://arxiv.org/abs/2503.07268', 'abstract': 'Routing is a crucial step in the VLSI design flow. With the advancement of manufacturing technologies, more constraints have emerged in design rules, particularly regarding obstacles during routing, leading to increased routing complexity. Unfortunately, many global routers struggle to efficiently generate obstacle-free solutions due to the lack of scalable obstacle-avoiding tree generation methods and the capability of handling modern designs with complex obstacles and nets. In this work, we propose an efficient obstacle-aware global routing flow for VLSI designs with obstacles. The flow includes a rule-based obstacle-avoiding rectilinear Steiner minimal tree (OARSMT) algorithm during the tree generation phase. This algorithm is both scalable and fast to provide tree topologies avoiding obstacles in the early stage globally. With its guidance, OARSMT-guided and obstacle-aware sparse maze routing are proposed in the later stages to minimize obstacle violations further and reduce overflow costs. Compared to advanced methods on the benchmark with obstacles, our approach successfully eliminates obstacle violations, and reduces wirelength and overflow cost, while sacrificing only a limited number of via counts and runtime overhead.', 'abstract_zh': 'VLSI 设计中具有障碍感知的高效全局布线流程', 'title_zh': '一种高效可扩展的避障VLSI全局路由流程'}
{'arxiv_id': 'arXiv:2503.07234', 'title': 'CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting', 'authors': 'Haicheng Liao, Hanlin Kong, Bonan Wang, Chengyue Wang, Wang Ye, Zhengbing He, Chengzhong Xu, Zhenning Li', 'link': 'https://arxiv.org/abs/2503.07234', 'abstract': "Accurate motion forecasting is crucial for safe autonomous driving (AD). This study proposes CoT-Drive, a novel approach that enhances motion forecasting by leveraging large language models (LLMs) and a chain-of-thought (CoT) prompting method. We introduce a teacher-student knowledge distillation strategy to effectively transfer LLMs' advanced scene understanding capabilities to lightweight language models (LMs), ensuring that CoT-Drive operates in real-time on edge devices while maintaining comprehensive scene understanding and generalization capabilities. By leveraging CoT prompting techniques for LLMs without additional training, CoT-Drive generates semantic annotations that significantly improve the understanding of complex traffic environments, thereby boosting the accuracy and robustness of predictions. Additionally, we present two new scene description datasets, Highway-Text and Urban-Text, designed for fine-tuning lightweight LMs to generate context-specific semantic annotations. Comprehensive evaluations of five real-world datasets demonstrate that CoT-Drive outperforms existing models, highlighting its effectiveness and efficiency in handling complex traffic scenarios. Overall, this study is the first to consider the practical application of LLMs in this field. It pioneers the training and use of a lightweight LLM surrogate for motion forecasting, setting a new benchmark and showcasing the potential of integrating LLMs into AD systems.", 'abstract_zh': '准确的运动预测对于安全的自动驾驶（AD）至关重要。本文提出了一种名为CoT-Drive的新方法，该方法通过利用大型语言模型（LLMs）和链式思考（CoT）提示方法来增强运动预测。我们引入了一种教师-学生知识蒸馏策略，以有效将LLMs的高级场景理解能力转移至轻量级语言模型（LMs），确保CoT-Drive能够在边缘设备上实时运行，同时保持全面的场景理解和泛化能力。通过利用LLMs的CoT提示技术生成语义注释，CoT-Drive显著提高了对复杂交通环境的理解，从而提升了预测的准确性和鲁棒性。此外，我们还提出了两种新的场景描述数据集——Highway-Text和Urban-Text，用于微调轻量级LMs以生成特定情境的语义注释。对五种真实世界数据集的全面评估表明，CoT-Drive在复杂交通场景处理方面优于现有模型，突显了其效果和效率。总体而言，本研究是首次探讨在该领域应用LLMs的尝试，它开启了轻量级LLM代理在运动预测训练与应用中的先河，树立了新的基准，并展示了将LLMs整合到AD系统中的潜力。', 'title_zh': 'CoT-Drive: 通过LLMs和链式思维提示实现高效的自动驾驶运动预测'}
{'arxiv_id': 'arXiv:2503.07167', 'title': 'Temporal Overlapping Prediction: A Self-supervised Pre-training Method for LiDAR Moving Object Segmentation', 'authors': 'Ziliang Miao, Runjian Chen, Yixi Cai, Buwei He, Wenquan Zhao, Wenqi Shao, Bo Zhang, Fu Zhang', 'link': 'https://arxiv.org/abs/2503.07167', 'abstract': 'Moving object segmentation (MOS) on LiDAR point clouds is crucial for autonomous systems like self-driving vehicles. Previous supervised approaches rely heavily on costly manual annotations, while LiDAR sequences naturally capture temporal motion cues that can be leveraged for self-supervised learning. In this paper, we propose \\textbf{T}emporal \\textbf{O}verlapping \\textbf{P}rediction (\\textbf{TOP}), a self-supervised pre-training method that alleviate the labeling burden for MOS. \\textbf{TOP} explores the temporal overlapping points that commonly observed by current and adjacent scans, and learns spatiotemporal representations by predicting the occupancy states of temporal overlapping points. Moreover, we utilize current occupancy reconstruction as an auxiliary pre-training objective, which enhances the current structural awareness of the model. We conduct extensive experiments and observe that the conventional metric Intersection-over-Union (IoU) shows strong bias to objects with more scanned points, which might neglect small or distant objects. To compensate for this bias, we introduce an additional metric called $\\text{mIoU}_{\\text{obj}}$ to evaluate object-level performance. Experiments on nuScenes and SemanticKITTI show that \\textbf{TOP} outperforms both supervised training-from-scratch baseline and other self-supervised pre-training baselines by up to 28.77\\% relative improvement, demonstrating strong transferability across LiDAR setups and generalization to other tasks. Code and pre-trained models will be publicly available upon publication.', 'abstract_zh': '基于LiDAR点云的运动对象分割（MOS）自监督预训练方法：Temporal Overlapping Prediction (TOP)', 'title_zh': '时间重叠预测：一种用于LiDAR移动目标分割的自监督预训练方法'}
{'arxiv_id': 'arXiv:2503.07127', 'title': 'Performance-driven Constrained Optimal Auto-Tuner for MPC', 'authors': 'Albert Gassol Puigjaner, Manish Prajapat, Andrea Carron, Andreas Krause, Melanie N. Zeilinger', 'link': 'https://arxiv.org/abs/2503.07127', 'abstract': "A key challenge in tuning Model Predictive Control (MPC) cost function parameters is to ensure that the system performance stays consistently above a certain threshold. To address this challenge, we propose a novel method, COAT-MPC, Constrained Optimal Auto-Tuner for MPC. With every tuning iteration, COAT-MPC gathers performance data and learns by updating its posterior belief. It explores the tuning parameters' domain towards optimistic parameters in a goal-directed fashion, which is key to its sample efficiency. We theoretically analyze COAT-MPC, showing that it satisfies performance constraints with arbitrarily high probability at all times and provably converges to the optimum performance within finite time. Through comprehensive simulations and comparative analyses with a hardware platform, we demonstrate the effectiveness of COAT-MPC in comparison to classical Bayesian Optimization (BO) and other state-of-the-art methods. When applied to autonomous racing, our approach outperforms baselines in terms of constraint violations and cumulative regret over time.", 'abstract_zh': '自适应约束优化调谐器COAT-MPC：模型预测控制的成本函数参数调谐方法', 'title_zh': '基于性能驱动的约束最优自动化调谐器for MPC'}
{'arxiv_id': 'arXiv:2503.06983', 'title': 'Griffin: Aerial-Ground Cooperative Detection and Tracking Dataset and Benchmark', 'authors': 'Jiahao Wang, Xiangyu Cao, Jiaru Zhong, Yuner Zhang, Haibao Yu, Lei He, Shaobing Xu', 'link': 'https://arxiv.org/abs/2503.06983', 'abstract': "Despite significant advancements, autonomous driving systems continue to struggle with occluded objects and long-range detection due to the inherent limitations of single-perspective sensing. Aerial-ground cooperation offers a promising solution by integrating UAVs' aerial views with ground vehicles' local observations. However, progress in this emerging field has been hindered by the absence of public datasets and standardized evaluation benchmarks. To address this gap, this paper presents a comprehensive solution for aerial-ground cooperative 3D perception through three key contributions: (1) Griffin, a large-scale multi-modal dataset featuring over 200 dynamic scenes (30k+ frames) with varied UAV altitudes (20-60m), diverse weather conditions, and occlusion-aware 3D annotations, enhanced by CARLA-AirSim co-simulation for realistic UAV dynamics; (2) A unified benchmarking framework for aerial-ground cooperative detection and tracking tasks, including protocols for evaluating communication efficiency, latency tolerance, and altitude adaptability; (3) AGILE, an instance-level intermediate fusion baseline that dynamically aligns cross-view features through query-based interaction, achieving an advantageous balance between communication overhead and perception accuracy. Extensive experiments prove the effectiveness of aerial-ground cooperative perception and demonstrate the direction of further research. The dataset and codes are available at this https URL.", 'abstract_zh': '尽管取得了显著进展，自动驾驶系统仍然受到遮挡物体和长距离检测的挑战，这归因于单一视角感知的固有限制。空地合作为通过结合无人机的空中视角和地面车辆的本地观测提供了一种有希望的解决方案。然而，该新兴领域的发展受到了缺乏公共数据集和标准化评估基准的影响。为了解决这一差距，本文提出了空中-地面合作三维感知的全面解决方案，包括三个关键贡献：Griffin，一个大规模多模态数据集，包含超过200个动态场景（超过30,000帧）和多样化的无人机高度（20-60米）、天气条件以及注释清晰的遮挡感知三维标注，增强版CARLA-AirSim联合仿真用于现实的无人机动力学；统一的空地合作检测与跟踪任务基准框架，包括评估通信效率、延迟容忍和高度适应性的协议；AGILE，一种实例级中间融合基准，通过查询式交互动态对齐跨视图特征，实现在通信开销和感知精度之间的优势平衡。广泛实验验证了空中-地面合作感知的有效性，并展示了进一步研究的方向。数据集和代码可在以下链接获取。', 'title_zh': 'Griffin：空中-地面协同检测与跟踪数据集及基准'}
{'arxiv_id': 'arXiv:2503.06978', 'title': 'Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition', 'authors': 'Xinyu Xi, Hua Yang, Shentai Zhang, Yijie Liu, Sijin Sun, Xiuju Fu', 'link': 'https://arxiv.org/abs/2503.06978', 'abstract': 'Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of intelligent marine robotics, particularly in applications such as marine conservation, environmental monitoring, and disaster response. However, this task presents significant challenges due to environmental interference, where marine conditions degrade image quality, and the complexity of maritime scenes, which requires deeper reasoning for accurate recognition. Pure vision models alone are insufficient to address these issues. To overcome these limitations, we propose a novel multimodal Artificial Intelligence (AI) framework that integrates image data, textual descriptions and classification vectors generated by a Multimodal Large Language Model (MLLM), to provide richer semantic understanding and improve recognition accuracy. Our framework employs an efficient multimodal fusion mechanism to further enhance model robustness and adaptability in complex maritime environments. Experimental results show that our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by 3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt activation-aware weight quantization (AWQ) as a lightweight technique, reducing the model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly lowering computational overhead. This work provides a high-performance solution for real-time maritime scene recognition, enabling Autonomous Surface Vehicles (ASVs) to support environmental monitoring and disaster response in resource-limited settings.', 'abstract_zh': '海上多场景识别对提高智能海洋机器人能力至关重要，特别是在海洋保护、环境监测和灾害响应等应用中。然而，由于环境干扰，海洋条件会降低图像质量，而海上场景的复杂性又要求更深入的推理以实现准确识别。仅依赖纯视觉模型不足以应对这些挑战。为克服这些限制，我们提出了一种新型的多模态人工智能框架，该框架整合了图像数据、由多模态大型语言模型（MLLM）生成的文本描述和分类向量，从而提供更丰富的语义理解和提高识别准确性。该框架采用高效的多模态融合机制，进一步增强模型在复杂海洋环境中的鲁棒性和适应性。实验结果表明，我们的模型准确率达到98%，超过 previous SOTA 模型3.5%。为优化在资源受限平台上的部署，我们采用了激活感知权重量化（AWQ）作为一种轻量级技术，将模型大小减少至68.75MB，同时准确率仅下降0.5%，显著降低了计算开销。本工作提供了一种高性能的实时海上场景识别解决方案，使自主水面车辆（ASVs）能够在资源受限环境中支持环境监测和灾害响应。', 'title_zh': 'maritime多场景识别的轻量级多模态人工智能框架'}
{'arxiv_id': 'arXiv:2503.06960', 'title': 'A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning', 'authors': 'Xin Wen, Bingchen Zhao, Yilun Chen, Jiangmiao Pang, Xiaojuan Qi', 'link': 'https://arxiv.org/abs/2503.06960', 'abstract': 'Pre-trained vision models (PVMs) are fundamental to modern robotics, yet their optimal configuration remains unclear. Through systematic evaluation, we find that while DINO and iBOT outperform MAE across visuomotor control and perception tasks, they struggle when trained on non-(single-)object-centric (NOC) data--a limitation strongly correlated with their diminished ability to learn object-centric representations. This investigation indicates that the ability to form object-centric representations from the non-object-centric robotics dataset is the key to success for PVMs. Motivated by this discovery, we designed SlotMIM, a method that induces object-centric representations by introducing a semantic bottleneck to reduce the number of prototypes to encourage the emergence of objectness as well as cross-view consistency regularization for encouraging multiview invariance. Our experiments encompass pre-training on object-centric, scene-centric, web-crawled, and ego-centric data. Across all settings, our approach learns transferrable representations and achieves significant improvements over prior work in image recognition, scene understanding, and robot learning evaluations. When scaled up with million-scale datasets, our method also demonstrates superior data efficiency and scalability. Our code and models are publicly available at this https URL.', 'abstract_zh': '预训练视觉模型（PVMs）是现代机器人技术的基础，但其最优配置尚不明确。通过系统评估，我们发现虽然DINO和iBOT在视觉运动控制和感知任务中优于MAE，但在非物体中心（NOC）数据上的训练上表现出色受限——这一限制与其学习物体中心表示的能力下降紧密相关。这项研究表明，从非物体中心的机器人数据集中形成物体中心表示的能力是PVMs成功的关键。受这一发现的启发，我们设计了SlotMIM方法，通过引入语义瓶颈减少原型的数量，以促进物体性的出现以及跨视图一致性正则化以促进多视图不变性。我们的实验涵盖了基于物体中心、场景中心、网络爬取和自我中心数据的预训练。在所有设置中，我们的方法学习到可迁移的表示，并在图像识别、场景理解以及机器人学习评估中实现了显著改进。当扩展到大规模数据集时，我们的方法还展示了更高的数据效率和可扩展性。我们的代码和模型已在该网址公开。', 'title_zh': '基于数据的预训练视觉模型在机器人学习中的 revisit'}
{'arxiv_id': 'arXiv:2503.06821', 'title': 'HierDAMap: Towards Universal Domain Adaptive BEV Mapping via Hierarchical Perspective Priors', 'authors': 'Siyu Li, Yihong Cao, Hao Shi, Yongsheng Zang, Xuan He, Kailun Yang, Zhiyong Li', 'link': 'https://arxiv.org/abs/2503.06821', 'abstract': "The exploration of Bird's-Eye View (BEV) mapping technology has driven significant innovation in visual perception technology for autonomous driving. BEV mapping models need to be applied to the unlabeled real world, making the study of unsupervised domain adaptation models an essential path. However, research on unsupervised domain adaptation for BEV mapping remains limited and cannot perfectly accommodate all BEV mapping tasks. To address this gap, this paper proposes HierDAMap, a universal and holistic BEV domain adaptation framework with hierarchical perspective priors. Unlike existing research that solely focuses on image-level learning using prior knowledge, this paper explores the guiding role of perspective prior knowledge across three distinct levels: global, sparse, and instance levels. With these priors, HierDA consists of three essential components, including Semantic-Guided Pseudo Supervision (SGPS), Dynamic-Aware Coherence Learning (DACL), and Cross-Domain Frustum Mixing (CDFM). SGPS constrains the cross-domain consistency of perspective feature distribution through pseudo labels generated by vision foundation models in 2D space. To mitigate feature distribution discrepancies caused by spatial variations, DACL employs uncertainty-aware predicted depth as an intermediary to derive dynamic BEV labels from perspective pseudo-labels, thereby constraining the coarse BEV features derived from corresponding perspective features. CDFM, on the other hand, leverages perspective masks of view frustum to mix multi-view perspective images from both domains, which guides cross-domain view transformation and encoding learning through mixed BEV labels. The proposed method is verified on multiple BEV mapping tasks, such as BEV semantic segmentation, high-definition semantic, and vectorized mapping. The source code will be made publicly available at this https URL.", 'abstract_zh': '基于层次视角先验的BEV领域自适应框架HierDAMap', 'title_zh': 'HierDAMap: 通过分层级视角先验 toward 通用领域适应性BEV映射'}
{'arxiv_id': 'arXiv:2503.06784', 'title': 'Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain Generation by Latent Fractal Diffusion Models', 'authors': 'Tianyi Zhang, Weiming Zhi, Joshua Mangelson, Matthew Johnson-Roberson', 'link': 'https://arxiv.org/abs/2503.06784', 'abstract': 'This paper tackles the problem of generating representations of underwater 3D terrain. Off-the-shelf generative models, trained on Internet-scale data but not on specialized underwater images, exhibit downgraded realism, as images of the seafloor are relatively uncommon. To this end, we introduce DreamSea, a generative model to generate hyper-realistic underwater scenes. DreamSea is trained on real-world image databases collected from underwater robot surveys. Images from these surveys contain massive real seafloor observations and covering large areas, but are prone to noise and artifacts from the real world. We extract 3D geometry and semantics from the data with visual foundation models, and train a diffusion model that generates realistic seafloor images in RGBD channels, conditioned on novel fractal distribution-based latent embeddings. We then fuse the generated images into a 3D map, building a 3DGS model supervised by 2D diffusion priors which allows photorealistic novel view rendering. DreamSea is rigorously evaluated, demonstrating the ability to robustly generate large-scale underwater scenes that are consistent, diverse, and photorealistic. Our work drives impact in multiple domains, spanning filming, gaming, and robot simulation.', 'abstract_zh': '本文解决了生成海底3D地形表示的问题。现成的生成模型虽然在互联网规模的数据上进行训练，但未针对专门的 underwater 图像进行训练，因此在生成海底图像时表现出较低的现实感，因为海底的图像相对较少。为此，我们引入了 DreamSea，一种生成模型，用于生成超逼真的水下场景。DreamSea 在从水下机器人调查中收集的实际图像数据库上进行训练。这些调查中的图像包含大量的真实海底观察，并覆盖了大面积的区域，但往往会受到现实世界噪声和伪影的影响。我们利用视觉基础模型从数据中提取3D几何和语义，并训练一个以新颖分形分布为基础的潜空间嵌入生成现实感海底图像的扩散模型。然后，我们将生成的图像融合到3D地图中，构建一个由2D扩散先验监督的3DGS模型，允许生成逼真的新颖视图渲染。DreamSea 严格评估，展示了其稳健生成大规模一致、多样且接近真实的水下场景的能力。我们的工作在多个领域产生了影响，包括拍摄、游戏和机器人模拟。', 'title_zh': '海洋无穷联盟：由潜空间分形扩散模型生成的逼真3D海底地形'}
{'arxiv_id': 'arXiv:2503.06501', 'title': 'TextInPlace: Indoor Visual Place Recognition in Repetitive Structures with Scene Text Spotting and Verification', 'authors': 'Huaqi Tao, Bingxi Liu, Calvin Chen, Tingjun Huang, He Li, Jinqiang Cui, Hong Zhang', 'link': 'https://arxiv.org/abs/2503.06501', 'abstract': 'Visual Place Recognition (VPR) is a crucial capability for long-term autonomous robots, enabling them to identify previously visited locations using visual information. However, existing methods remain limited in indoor settings due to the highly repetitive structures inherent in such environments. We observe that scene text typically appears in indoor spaces, serving to distinguish visually similar but different places. This inspires us to propose TextInPlace, a simple yet effective VPR framework that integrates Scene Text Spotting (STS) to mitigate visual perceptual ambiguity in repetitive indoor environments. Specifically, TextInPlace adopts a dual-branch architecture within a local parameter sharing network. The VPR branch employs attention-based aggregation to extract global descriptors for coarse-grained retrieval, while the STS branch utilizes a bridging text spotter to detect and recognize scene text. Finally, the discriminative text is filtered to compute text similarity and re-rank the top-K retrieved images. To bridge the gap between current text-based repetitive indoor scene datasets and the typical scenarios encountered in robot navigation, we establish an indoor VPR benchmark dataset, called Maze-with-Text. Extensive experiments on both custom and public datasets demonstrate that TextInPlace achieves superior performance over existing methods that rely solely on appearance information. The dataset, code, and trained models are publicly available at this https URL.', 'abstract_zh': '基于场景文本的室内视觉场所识别（TextInPlace）：一种缓解重复室内环境中视觉感知模糊性的简单有效框架', 'title_zh': 'TextInPlace: 在重复结构中基于场景文本检测与验证的室内视觉场所识别'}
{'arxiv_id': 'arXiv:2503.06313', 'title': 'Advancing Autonomous Vehicle Intelligence: Deep Learning and Multimodal LLM for Traffic Sign Recognition and Robust Lane Detection', 'authors': 'Chandan Kumar Sah, Ankit Kumar Shaw, Xiaoli Lian, Arsalan Shahid Baig, Tuopu Wen, Kun Jiang, Mengmeng Yang, Diange Yang', 'link': 'https://arxiv.org/abs/2503.06313', 'abstract': 'Autonomous vehicles (AVs) require reliable traffic sign recognition and robust lane detection capabilities to ensure safe navigation in complex and dynamic environments. This paper introduces an integrated approach combining advanced deep learning techniques and Multimodal Large Language Models (MLLMs) for comprehensive road perception. For traffic sign recognition, we systematically evaluate ResNet-50, YOLOv8, and RT-DETR, achieving state-of-the-art performance of 99.8% with ResNet-50, 98.0% accuracy with YOLOv8, and achieved 96.6% accuracy in RT-DETR despite its higher computational complexity. For lane detection, we propose a CNN-based segmentation method enhanced by polynomial curve fitting, which delivers high accuracy under favorable conditions. Furthermore, we introduce a lightweight, Multimodal, LLM-based framework that directly undergoes instruction tuning using small yet diverse datasets, eliminating the need for initial pretraining. This framework effectively handles various lane types, complex intersections, and merging zones, significantly enhancing lane detection reliability by reasoning under adverse conditions. Despite constraints in available training resources, our multimodal approach demonstrates advanced reasoning capabilities, achieving a Frame Overall Accuracy (FRM) of 53.87%, a Question Overall Accuracy (QNS) of 82.83%, lane detection accuracies of 99.6% in clear conditions and 93.0% at night, and robust performance in reasoning about lane invisibility due to rain (88.4%) or road degradation (95.6%). The proposed comprehensive framework markedly enhances AV perception reliability, thus contributing significantly to safer autonomous driving across diverse and challenging road scenarios.', 'abstract_zh': '自主驾驶车辆需要可靠的交通标志识别能力和稳健的车道检测能力，以确保在复杂多变环境中的安全导航。本文介绍了一种结合先进深度学习技术和多模态大语言模型（MLLMs）的综合方法，用于全面的道路感知。在交通标志识别方面，我们系统地评估了ResNet-50、YOLOv8和RT-DETR，分别实现了99.8%、98.0%和96.6%的准确率。对于车道检测，我们提出了一种基于CNN的分割方法，并结合多项式曲线拟合，以在有利条件下保持高准确性。此外，我们引入了一种轻量级、基于多模态大语言模型的框架，可以直接使用小而多样的数据集进行指令调优，消除了初始预训练的需要。该框架能够有效处理各种类型的车道、复杂的交叉口和合并区，显著提高在恶劣条件下的车道检测可靠性。尽管可用的训练资源有限，但我们的多模态方法展示了先进的推理能力，实现了53.87%的帧总体准确性、82.83%的问题总体准确性、在清晰条件下99.6%的车道检测准确率、夜间检测准确率93.0%，以及在雨水导致车道不可见（88.4%）或道路退化（95.6%）情况下推理的稳健性能。所提出的综合框架显著增强了自主车辆的道路感知可靠性，从而在多样且具有挑战性的道路场景中为更安全的自动驾驶做出了重要贡献。', 'title_zh': '提升自动驾驶智能：深度学习与多模态LLM在交通标志识别和稳健车道检测中的应用'}
{'arxiv_id': 'arXiv:2503.06170', 'title': 'Object-Centric World Model for Language-Guided Manipulation', 'authors': 'Youngjoon Jeong, Junha Chun, Soonwoo Cha, Taesup Kim', 'link': 'https://arxiv.org/abs/2503.06170', 'abstract': 'A world model is essential for an agent to predict the future and plan in domains such as autonomous driving and robotics. To achieve this, recent advancements have focused on video generation, which has gained significant attention due to the impressive success of diffusion models. However, these models require substantial computational resources. To address these challenges, we propose a world model leveraging object-centric representation space using slot attention, guided by language instructions. Our model perceives the current state as an object-centric representation and predicts future states in this representation space conditioned on natural language instructions. This approach results in a more compact and computationally efficient model compared to diffusion-based generative alternatives. Furthermore, it flexibly predicts future states based on language instructions, and offers a significant advantage in manipulation tasks where object recognition is crucial. In this paper, we demonstrate that our latent predictive world model surpasses generative world models in visuo-linguo-motor control tasks, achieving superior sample and computation efficiency. We also investigate the generalization performance of the proposed method and explore various strategies for predicting actions using object-centric representations.', 'abstract_zh': '一种世界模型对于智能体在自动驾驶和机器人等领域预测未来和规划至关重要。为实现这一目标，近期的研究重点在于视频生成，这得益于扩散模型的令人瞩目的成功，但这些模型需要大量的计算资源。为应对这些挑战，我们提出了一种利用对象为中心表示空间的世界模型，该模型由语言指令引导，通过槽注意机制工作。该模型将当前状态视为对象为中心的表示，并根据自然语言指令对此表示空间中的未来状态进行预测。这种方法相比于基于扩散的生成模型更为紧凑且计算高效。此外，它能够灵活地根据语言指令预测未来的状态，特别是在依赖于物体识别的操作任务中具有显著优势。在本文中，我们证明了我们提出的方法在视觉-语言-运动控制任务中的潜在预测世界模型优于生成世界模型，并实现了更好的样本和计算效率。我们还研究了所提出方法的泛化性能，并探索了利用对象为中心表示预测动作的各种策略。', 'title_zh': '基于对象的世界模型：语言指导的操作规划'}
{'arxiv_id': 'arXiv:2503.06138', 'title': 'System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems', 'authors': 'Tadahiro Taniguchi, Yasushi Hirai, Masahiro Suzuki, Shingo Murata, Takato Horii, Kazutoshi Tanaka', 'link': 'https://arxiv.org/abs/2503.06138', 'abstract': "This paper introduces the System 0/1/2/3 framework as an extension of dual-process theory, employing a quad-process model of cognition. Expanding upon System 1 (fast, intuitive thinking) and System 2 (slow, deliberative thinking), we incorporate System 0, which represents pre-cognitive embodied processes, and System 3, which encompasses collective intelligence and symbol emergence. We contextualize this model within Bergson's philosophy by adopting multi-scale time theory to unify the diverse temporal dynamics of cognition. System 0 emphasizes morphological computation and passive dynamics, illustrating how physical embodiment enables adaptive behavior without explicit neural processing. Systems 1 and 2 are explained from a constructive perspective, incorporating neurodynamical and AI viewpoints. In System 3, we introduce collective predictive coding to explain how societal-level adaptation and symbol emergence operate over extended timescales. This comprehensive framework ranges from rapid embodied reactions to slow-evolving collective intelligence, offering a unified perspective on cognition across multiple timescales, levels of abstraction, and forms of human intelligence. The System 0/1/2/3 model provides a novel theoretical foundation for understanding the interplay between adaptive and cognitive processes, thereby opening new avenues for research in cognitive science, AI, robotics, and collective intelligence.", 'abstract_zh': 'System 0/1/2/3框架：一种扩展的两过程理论及其多尺度认知统一模型', 'title_zh': '系统0/1/2/3：多时间尺度 embodied集体认知系统的四过程理论'}
{'arxiv_id': 'arXiv:2503.06089', 'title': 'Fish2Mesh Transformer: 3D Human Mesh Recovery from Egocentric Vision', 'authors': 'David C. Jeong, Aditya Puranik, James Vong, Vrushabh Abhijit Deogirikar, Ryan Fell, Julianna Dietrich, Maria Kyrarini, Christopher Kitts', 'link': 'https://arxiv.org/abs/2503.06089', 'abstract': "Egocentric human body estimation allows for the inference of user body pose and shape from a wearable camera's first-person perspective. Although research has used pose estimation techniques to overcome self-occlusions and image distortions caused by head-mounted fisheye images, similar advances in 3D human mesh recovery (HMR) techniques have been limited. We introduce Fish2Mesh, a fisheye-aware transformer-based model designed for 3D egocentric human mesh recovery. We propose an egocentric position embedding block to generate an ego-specific position table for the Swin Transformer to reduce fisheye image distortion. Our model utilizes multi-task heads for SMPL parametric regression and camera translations, estimating 3D and 2D joints as auxiliary loss to support model training. To address the scarcity of egocentric camera data, we create a training dataset by employing the pre-trained 4D-Human model and third-person cameras for weak supervision. Our experiments demonstrate that Fish2Mesh outperforms previous state-of-the-art 3D HMR models.", 'abstract_zh': '基于 fisheye 意识的变压器模型在第一人称视角下的3D人体网格恢复', 'title_zh': 'Fish2Mesh Transformer: 从第一人称视角恢复3D人体网格模型'}
{'arxiv_id': 'arXiv:2503.06014', 'title': 'Towards Ambiguity-Free Spatial Foundation Model: Rethinking and Decoupling Depth Ambiguity', 'authors': 'Xiaohao Xu, Feng Xue, Xiang Li, Haowei Li, Shusheng Yang, Tianyi Zhang, Matthew Johnson-Roberson, Xiaonan Huang', 'link': 'https://arxiv.org/abs/2503.06014', 'abstract': 'Depth ambiguity is a fundamental challenge in spatial scene understanding, especially in transparent scenes where single-depth estimates fail to capture full 3D structure. Existing models, limited to deterministic predictions, overlook real-world multi-layer depth. To address this, we introduce a paradigm shift from single-prediction to multi-hypothesis spatial foundation models. We first present \\texttt{MD-3k}, a benchmark exposing depth biases in expert and foundational models through multi-layer spatial relationship labels and new metrics. To resolve depth ambiguity, we propose Laplacian Visual Prompting (LVP), a training-free spectral prompting technique that extracts hidden depth from pre-trained models via Laplacian-transformed RGB inputs. By integrating LVP-inferred depth with standard RGB-based estimates, our approach elicits multi-layer depth without model retraining. Extensive experiments validate the effectiveness of LVP in zero-shot multi-layer depth estimation, unlocking more robust and comprehensive geometry-conditioned visual generation, 3D-grounded spatial reasoning, and temporally consistent video-level depth inference. Our benchmark and code will be available at this https URL.', 'abstract_zh': '深度歧义是空间场景理解中的一个基本挑战，尤其是在透明场景中，单深度估计无法捕捉完整的3D结构。现有的模型局限于确定性预测，忽视了现实世界的多层深度。为了解决这一问题，我们从单预测转向多假设空间基础模型引入了一种范式转变。我们首先介绍了一个基准 \\texttt{MD-3k}，通过多层空间关系标签和新的度量标准，暴露了专家模型和基础模型中的深度偏差。为了解决深度歧义，我们提出了拉普拉斯视觉提示（LVP），这是一种无需训练的频谱提示技术，通过拉普拉斯变换的RGB输入从预训练模型中提取隐藏的深度信息。通过将LVP推理出的深度与基于RGB的标准深度估计结合，我们的方法可以在不重新训练模型的情况下获取多层深度。广泛的经验研究表明，LVP在零样本多层深度估计中有效，从而解锁了更稳健且全面的几何条件下的视觉生成、三维接地的空间推理以及时序一致的视频级深度推理。我们的基准和代码可在此<https://example.com> 获取。', 'title_zh': '面向无歧义的空间基础模型：重新思考并解耦深度歧义'}
{'arxiv_id': 'arXiv:2503.05842', 'title': 'The Multi-Trip Time-Dependent Mix Vehicle Routing Problem for Hybrid Autonomous Shared Delivery Location and Traditional Door-to-Door Delivery Modes', 'authors': 'Jingyi Zhao, Jiayu Yang, Haoxiang Yang', 'link': 'https://arxiv.org/abs/2503.05842', 'abstract': "Rising labor costs and increasing logistical demands pose significant challenges to modern delivery systems. Automated Electric Vehicles (AEVs) could reduce reliance on delivery personnel and increase route flexibility, but their adoption is limited due to varying customer acceptance and integration complexities. Shared Distribution Locations (SDLs) offer an alternative to door-to-door (D2D) delivery by providing a wider delivery window and serving multiple community customers, thereby improving last-mile logistics through reduced delivery time, lower costs, and higher customer this http URL paper introduces the Multi-Trip Time-Dependent Hybrid Vehicle Routing Problem (MTTD-MVRP), a challenging variant of the Vehicle Routing Problem (VRP) that combines Autonomous Electric Vehicles (AEVs) with conventional vehicles. The problem's complexity arises from factors such as time-dependent travel speeds, strict time windows, battery limitations, and driver labor constraints, while integrating both SDLs and D2D deliveries. To solve the MTTD-MVRP efficiently, we develop a tailored meta-heuristic based on Adaptive Large Neighborhood Search (ALNS) augmented with column generation (CG). This approach intensively explores the solution space using problem-specific operators and adaptively refines solutions, balancing high-quality outcomes with computational effort. Extensive experiments show that the proposed method delivers near-optimal solutions for large-scale instances within practical time this http URL a managerial perspective, our findings highlight the importance of integrating autonomous and human-driven vehicles in last-mile logistics. Decision-makers can leverage SDLs to reduce operational costs and carbon footprints while still accommodating customers who require or prefer D2D services.", 'abstract_zh': 'Rising劳动成本和不断增加的物流需求对现代配送系统构成了重大挑战。自动化电动车辆（AEVs）可以减少对配送人员的依赖并增加路线灵活性，但其采用受限于客户接受度的差异性和集成复杂性。共享配送中心（SDLs）通过提供更宽的配送窗口并服务多个社区客户，为门到门（D2D）配送提供了替代方案，从而通过减少配送时间、降低配送成本和提高客户满意度来改善最后一英里物流。本文引入了多行程时间依赖混合车辆路径问题（MTTD-MVRP），这是车辆路径问题（VRP）的一个具有挑战性的变体，结合了自主电动车辆（AEVs）和传统车辆。该问题的复杂性来自于时间依赖的行驶速度、严格的时间窗口、电池限制和司机劳动力约束等因素，同时整合了SDLs和D2D配送。为了高效解决MTTD-MVRP，我们基于自适应大邻域搜索（ALNS）并结合列生成（CG）开发了一种定制的元启发式算法。该方法通过特定的问题操作深入探索解空间，并适应性地优化解决方案，旨在平衡高质量结果与计算努力。大量实验表明，所提出的方法可以在实际时间限制内为大规模实例提供近似最优解。从管理角度来看，我们的发现强调了在最后一英里物流中整合自主和人驱动车辆的重要性。决策者可以利用SDLs降低运营成本和碳足迹，同时仍能满足需要或偏好D2D服务的客户。', 'title_zh': '多行程时间依赖混合自主共享配送与传统门到门配送模式混合车辆路线问题'}
{'arxiv_id': 'arXiv:2503.05836', 'title': 'Safe Distributed Learning-Enhanced Predictive Control for Multiple Quadrupedal Robots', 'authors': 'Weishu Zhan, Zheng Liang, Hongyu Song, Wei Pan', 'link': 'https://arxiv.org/abs/2503.05836', 'abstract': 'Quadrupedal robots exhibit remarkable adaptability in unstructured environments, making them well-suited for formation control in real-world applications. However, keeping stable formations while ensuring collision-free navigation presents significant challenges due to dynamic obstacles, communication constraints, and the complexity of legged locomotion. This paper proposes a distributed model predictive control framework for multi-quadruped formation control, integrating Control Lyapunov Functions to ensure formation stability and Control Barrier Functions for decentralized safety enforcement. To address the challenge of dynamically changing team structures, we introduce Scale-Adaptive Permutation-Invariant Encoding (SAPIE), which enables robust feature encoding of neighboring robots while preserving permutation invariance. Additionally, we develop a low-latency Data Distribution Service-based communication protocol and an event-triggered deadlock resolution mechanism to enhance real-time coordination and prevent motion stagnation in constrained spaces. Our framework is validated through high-fidelity simulations in NVIDIA Omniverse Isaac Sim and real-world experiments using our custom quadrupedal robotic system, XG. Results demonstrate stable formation control, real-time feasibility, and effective collision avoidance, validating its potential for large-scale deployment.', 'abstract_zh': '四足机器人在未结构化环境中表现出显著的适应能力，使其非常适合实际应用中的编队控制。然而，在确保无碰撞导航的同时保持稳定编队面临着由于动态障碍物、通信限制和腿足运动复杂性所带来的重大挑战。本文提出了一种分布式模型预测控制框架，用于多四足机器人编队控制，结合使用Control Lyapunov函数确保编队稳定性并使用Control Barrier函数进行去中心化安全性执行。为应对团队结构动态变化的挑战，引入了可缩放自适应排列不变编码（SAPIE），该方法能够在保持排列不变性的同时，实现邻近机器人鲁棒特征编码。此外，我们还开发了一种基于低延迟数据分布服务的通信协议和事件触发的死锁解决机制，以增强实时协调并防止在受限空间中运动停滞。本文框架通过在NVIDIA Omniverse Isaac Sim进行高保真仿真及使用我们定制的四足机器人系统XG进行实地实验进行了验证。结果表明，该框架实现了稳定的编队控制、实时可行性以及有效的碰撞避免，验证了其在大规模部署中的潜力。', 'title_zh': '安全分布式学习增强预测控制 for 多足机器人'}
{'arxiv_id': 'arXiv:2503.05835', 'title': 'A Novel Control Strategy for Offset Points Tracking in the Context of Agricultural Robotics', 'authors': 'Stephane Ngnepiepaye Wembe, Vincent Rousseau, Johann Laconte, Roland Lenain', 'link': 'https://arxiv.org/abs/2503.05835', 'abstract': "In this paper, we present a novel method to control a rigidly connected location on the vehicle, such as a point on the implement in case of agricultural tasks. Agricultural robots are transforming modern farming by enabling precise and efficient operations, replacing humans in arduous tasks while reducing the use of chemicals. Traditionnaly, path_following algorithms are designed to guide the vehicle's center along a predefined trajetory. However, since the actual agronomic task is performed by the implement, it is essential to control a specific point on the implement itself rather than vehicle's center. As such, we present in this paper two approaches for achieving the control of an offset point on the robot. The first approach adapts existing control laws, initially inteded for rear axle's midpoint, to manage the desired lateral deviation. The second approach employs backstepping control techniques to create a control law that directly targets the implement. We conduct real-world experiments, highlighting the limitations of traditional approaches for offset points control, and demonstrating the strengths and weaknesses of the proposed methods.", 'abstract_zh': '本文提出了一种新颖的方法来控制车辆上刚性连接的位置，例如农业任务中实施装置上的特定点。农业机器人通过实现精确和高效的操作，正在改变现代农业，替代人类完成艰苦的任务，同时减少化学物质的使用。传统地，路径跟随算法设计用于沿预定义轨迹引导车辆的中心。然而，由于实际的农艺任务是由实施装置执行的，因此控制实施装置本身上的特定点而不是车辆的中心是必不可少的。因此，本文提出了两种方法来控制机器人上的偏移点。第一种方法是将现有的初衷用于后轴中点的控制律进行调整，以管理所需的横向偏差。第二种方法采用回步控制技术来创建直接针对实施装置的控制律。我们进行了实地试验，指出了传统方法对于偏移点控制的局限性，并展示了所提出的控制方法的优势和不足。', 'title_zh': '农业机器人环境中偏移点跟踪的新型控制策略'}
{'arxiv_id': 'arXiv:2503.05819', 'title': 'An Unsupervised C-Uniform Trajectory Sampler with Applications to Model Predictive Path Integral Control', 'authors': 'O. Goktug Poyrazoglu, Rahul Moorthy, Yukang Cao, William Chastek, Volkan Isler', 'link': 'https://arxiv.org/abs/2503.05819', 'abstract': 'Sampling-based model predictive controllers generate trajectories by sampling control inputs from a fixed, simple distribution such as the normal or uniform distributions. This sampling method yields trajectory samples that are tightly clustered around a mean trajectory. This clustering behavior in turn, limits the exploration capability of the controller and reduces the likelihood of finding feasible solutions in complex environments. Recent work has attempted to address this problem by either reshaping the resulting trajectory distribution or increasing the sample entropy to enhance diversity and promote exploration. In our recent work, we introduced the concept of C-Uniform trajectory generation [1] which allows the computation of control input probabilities to generate trajectories that sample the configuration space uniformly. In this work, we first address the main limitation of this method: lack of scalability due to computational complexity. We introduce Neural C-Uniform, an unsupervised C-Uniform trajectory sampler that mitigates scalability issues by computing control input probabilities without relying on a discretized configuration space. Experiments show that Neural C-Uniform achieves a similar uniformity ratio to the original C-Uniform approach and generates trajectories over a longer time horizon while preserving uniformity. Next, we present CU-MPPI, which integrates Neural C-Uniform sampling into existing MPPI variants. We analyze the performance of CU-MPPI in simulation and real-world experiments. Our results indicate that in settings where the optimal solution has high curvature, CU-MPPI leads to drastic improvements in performance.', 'abstract_zh': '基于采样的模型预测控制器通过从固定简单的分布（如正态分布或均匀分布）中采样控制输入来生成轨迹。这种采样方法产生了紧密围绕均值轨迹的轨迹样本。这种聚类行为反过来限制了控制器的探索能力，并减少了在复杂环境中找到可行解的几率。最近的工作试图通过重塑生成的轨迹分布或增加样本熵来增强多样性并促进探索来解决这个问题。在我们最近的工作中，我们介绍了C-Uniform轨迹生成的概念，该概念允许计算控制输入概率以生成均匀覆盖配置空间的轨迹。在本文中，我们首先解决这种方法的主要局限性：由于计算复杂性导致的不具扩展性。我们引入了一种无需依赖离散化配置空间即可计算控制输入概率的无监督神经C-Uniform轨迹采样器，从而缓解了可扩展性问题。实验表明，神经C-Uniform实现了与原始C-Uniform方法相似的均匀性比率，并且可以在更长的时间框架内生成轨迹，同时保持均匀性。接下来，我们提出了CU-MPPI，将神经C-Uniform采样融入现有的MPPI变体中。我们在仿真和真实世界实验中分析了CU-MPPI的性能。我们的结果表明，在最优解具有高曲率的情况下，CU-MPPI在性能上会产生显著的改进。', 'title_zh': '无监督C-均匀轨迹采样及其在模型预测路径积分控制中的应用'}
{'arxiv_id': 'arXiv:2503.05818', 'title': 'Closing the Intent-to-Reality Gap via Fulfillment Priority Logic', 'authors': 'Bassel El Mabsout, Abdelrahman AbdelGawad, Renato Mancuso', 'link': 'https://arxiv.org/abs/2503.05818', 'abstract': 'Practitioners designing reinforcement learning policies face a fundamental challenge: translating intended behavioral objectives into representative reward functions. This challenge stems from behavioral intent requiring simultaneous achievement of multiple competing objectives, typically addressed through labor-intensive linear reward composition that yields brittle results. Consider the ubiquitous robotics scenario where performance maximization directly conflicts with energy conservation. Such competitive dynamics are resistant to simple linear reward combinations. In this paper, we present the concept of objective fulfillment upon which we build Fulfillment Priority Logic (FPL). FPL allows practitioners to define logical formula representing their intentions and priorities within multi-objective reinforcement learning. Our novel Balanced Policy Gradient algorithm leverages FPL specifications to achieve up to 500\\% better sample efficiency compared to Soft Actor Critic. Notably, this work constitutes the first implementation of non-linear utility scalarization design, specifically for continuous control problems.', 'abstract_zh': '实践者在设计强化学习策略时面临一个基本挑战：将意图行为目标转化为代表性的奖励函数。此挑战源于行为意图需要同时实现多个竞争性目标，通常通过劳动密集型的线性奖励组合来解决，但结果往往是脆弱的。以普遍存在的机器人场景为例，性能最大化与能量 conservation直接冲突。这种竞争性动态难以通过简单的线性奖励组合来解决。本文介绍了目标履行的概念，并在此基础上构建了履行优先逻辑（FPL）。FPL 允许实践者在多目标强化学习中定义逻辑公式来表示他们的意图和优先级。我们提出的平衡策略梯度算法利用 FPL 规范，与 Soft Actor-Critic 相比，实现了高达 500% 的样本效率提升。值得注意的是，本项工作是首次为连续控制问题设计非线性效用标量化的方法。', 'title_zh': '通过履行优先逻辑缩小意图与现实之间的差距'}
{'arxiv_id': 'arXiv:2503.05808', 'title': 'DriveGen: Towards Infinite Diverse Traffic Scenarios with Large Models', 'authors': 'Shenyu Zhang, Jiaguo Tian, Zhengbang Zhu, Shan Huang, Jucheng Yang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2503.05808', 'abstract': "Microscopic traffic simulation has become an important tool for autonomous driving training and testing. Although recent data-driven approaches advance realistic behavior generation, their learning still relies primarily on a single real-world dataset, which limits their diversity and thereby hinders downstream algorithm optimization. In this paper, we propose DriveGen, a novel traffic simulation framework with large models for more diverse traffic generation that supports further customized designs. DriveGen consists of two internal stages: the initialization stage uses large language model and retrieval technique to generate map and vehicle assets; the rollout stage outputs trajectories with selected waypoint goals from visual language model and a specific designed diffusion planner. Through this two-staged process, DriveGen fully utilizes large models' high-level cognition and reasoning of driving behavior, obtaining greater diversity beyond datasets while maintaining high realism. To support effective downstream optimization, we additionally develop DriveGen-CS, an automatic corner case generation pipeline that uses failures of the driving algorithm as additional prompt knowledge for large models without the need for retraining or fine-tuning. Experiments show that our generated scenarios and corner cases have a superior performance compared to state-of-the-art baselines. Downstream experiments further verify that the synthesized traffic of DriveGen provides better optimization of the performance of typical driving algorithms, demonstrating the effectiveness of our framework.", 'abstract_zh': 'DriveGen：一种用于生成多样化交通场景的大模型驱动交通仿真框架', 'title_zh': 'DriveGen: 向无限多样的交通场景进发，借助大规模模型'}
{'arxiv_id': 'arXiv:2503.05791', 'title': 'Collaborative Drill Alignment in Surgical Robotics', 'authors': 'Daniel Larby, Joshua Kershaw, Matthew Allen, Fulvio Forni', 'link': 'https://arxiv.org/abs/2503.05791', 'abstract': "Robotic assistance allows surgeries to be reliably and accurately executed while still under direct supervision of the surgeon, combining the strengths of robotic technology with the surgeon's expertise. This paper describes a robotic system designed to assist in surgical procedures by implementing a virtual drill guide. The system integrates virtual-fixture functionality using a novel virtual-mechanism controller with additional visual feedback. The controller constrains the tool to the desired axis, while allowing axial motion to remain under the surgeon's control. Compared to prior virtual-fixture approaches -- which primarily perform pure energy-shaping and damping injection with linear springs and dampers -- our controller uses a virtual prismatic joint to which the robot is constrained by nonlinear springs, allowing us to easily shape the dynamics of the system. We detail the calibration procedures required to achieve sufficient precision, and describe the implementation of the controller. We apply this system to a veterinary procedure: drilling for transcondylar screw placement in dogs. The results of the trials on 3D-printed bone models demonstrate sufficient precision to perform the procedure and suggest improved angular accuracy and reduced exit translation errors compared to patient specific guides (PSG). Discussion and future improvements follow.", 'abstract_zh': '机器人辅助使手术在外科医生直接监督下可靠且准确地执行，结合了机器人技术的优势和外科医生的专业知识。本文描述了一种旨在通过实施虚拟钻导向辅助手术程序的机器人系统。该系统使用新型虚拟机制控制器集成虚拟固定装置功能，并提供附加的视觉反馈。控制器将工具约束在所需轴上，同时使轴向运动保持在外科医生的控制之下。与先前主要通过线性弹簧和阻尼器进行纯能量整形和阻尼注入的虚拟固定装置方法相比，我们的控制器使用由非线性弹簧约束机器人的虚拟棱柱关节，使我们能够轻松地塑造系统的动力学。我们详细描述了实现足够精度所需的校准程序，并介绍了控制器的实现。我们将其应用于兽医学程序：在狗身上进行经髁螺钉置入的钻孔。对3D打印骨骼模型的试验结果表明了足够的精度以执行该程序，并且与患者特定导板（PSG）相比，表现出更好的角度准确性和较低的退出平移误差。讨论和未来改进随之进行。', 'title_zh': '手术机器人中的协作钻孔对齐'}
