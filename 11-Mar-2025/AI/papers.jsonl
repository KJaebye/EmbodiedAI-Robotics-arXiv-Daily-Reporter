{'arxiv_id': 'arXiv:2503.07600', 'title': 'A Representationalist, Functionalist and Naturalistic Conception of Intelligence as a Foundation for AGI', 'authors': 'Rolf Pfister', 'link': 'https://arxiv.org/abs/2503.07600', 'abstract': 'The article analyses foundational principles relevant to the creation of artificial general intelligence (AGI). Intelligence is understood as the ability to create novel skills that allow to achieve goals under previously unknown conditions. To this end, intelligence utilises reasoning methods such as deduction, induction and abduction as well as other methods such as abstraction and classification to develop a world model. The methods are applied to indirect and incomplete representations of the world, which are obtained through perception, for example, and which do not depict the world but only correspond to it. Due to these limitations and the uncertain and contingent nature of reasoning, the world model is constructivist. Its value is functionally determined by its viability, i.e., its potential to achieve the desired goals. In consequence, meaning is assigned to representations by attributing them a function that makes it possible to achieve a goal. This representational and functional conception of intelligence enables a naturalistic interpretation that does not presuppose mental features, such as intentionality and consciousness, which are regarded as independent of intelligence. Based on a phenomenological analysis, it is shown that AGI can gain a more fundamental access to the world than humans, although it is limited by the No Free Lunch theorems, which require assumptions to be made.', 'abstract_zh': 'artificial generalintelligence的基础原则：一种基于表征与功能的解释及其对世界的自然主义理解', 'title_zh': '一种作为AGI基础的代表主义、功能主义和自然主义的智能观'}
{'arxiv_id': 'arXiv:2503.07545', 'title': 'Queueing, Predictions, and LLMs: Challenges and Open Problems', 'authors': 'Michael Mitzenmacher, Rana Shahout', 'link': 'https://arxiv.org/abs/2503.07545', 'abstract': 'Queueing systems present many opportunities for applying machine-learning predictions, such as estimated service times, to improve system performance. This integration raises numerous open questions about how predictions can be effectively leveraged to improve scheduling decisions. Recent studies explore queues with predicted service times, typically aiming to minimize job time in the system. We review these works, highlight the effectiveness of predictions, and present open questions on queue performance. We then move to consider an important practical example of using predictions in scheduling, namely Large Language Model (LLM) systems, which presents novel scheduling challenges and highlights the potential for predictions to improve performance. In particular, we consider LLMs performing inference. Inference requests (jobs) in LLM systems are inherently complex; they have variable inference times, dynamic memory footprints that are constrained by key-value (KV) store memory limitations, and multiple possible preemption approaches that affect performance differently. We provide background on the important aspects of scheduling in LLM systems, and introduce new models and open problems that arise from them. We argue that there are significant opportunities for applying insights and analysis from queueing theory to scheduling in LLM systems.', 'abstract_zh': '机器学习预测在排队系统中的应用及其对调度决策的影响：以大型语言模型系统为例', 'title_zh': '队列理论、预测与大语言模型：挑战与开放式问题'}
{'arxiv_id': 'arXiv:2503.07540', 'title': 'AI-Enabled Knowledge Sharing for Enhanced Collaboration and Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review Protocol', 'authors': 'Maurice Ongala, Ruth Kiraka, Jyoti Choundrie, Javan Okello', 'link': 'https://arxiv.org/abs/2503.07540', 'abstract': 'This protocol outlines a scoping review designed to systematically map the existing body of evidence on AI-enabled knowledge sharing in resource-limited non-profit healthcare organizations. The review aims to investigate how such technologies enhance collaboration and decision-making, particularly in the context of reduced external support following the cessation of USAID operations. Guided by three theoretical frameworks namely, the Resource-Based View, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study will explore the dual role of AI as a strategic resource and an enabler of organizational learning and agility. The protocol details a rigorous methodological approach based on PRISMA-ScR guidelines, encompassing a systematic search strategy across multiple databases, inclusion and exclusion criteria, and a structured data extraction process. By integrating theoretical insights with empirical evidence, this scoping review seeks to identify critical gaps in the literature and inform the design of effective, resource-optimized AI solutions in non-profit healthcare settings.', 'abstract_zh': '本研究概述了一项系统性回顾协议，旨在系统地梳理有限资源非营利医疗卫生组织中人工智能驱动的知识共享现有证据。该回顾旨在研究此类技术如何增强合作与决策制定，尤其是在美国国际开发署运作停止后外部支持减少的背景下。本研究将基于资源基础视角、动态能力理论和吸收能力理论三大理论框架，探索人工智能作为战略资源和组织学习与敏捷性促进者的双重角色。该协议基于PRISMA-ScR指南，详细描述了严格的方法学方法，包括多数据库系统的检索策略、纳入和排除标准以及结构化数据提取过程。通过将理论洞察与实证证据相结合，本系统性回顾旨在识别文献中的关键空白，并指导非营利医疗卫生环境中有效、资源优化的人工智能解决方案的设计。', 'title_zh': '基于AI的知识共享以增强非营利医疗机构中的协作与决策制定：一项范围性回顾研究方案'}
{'arxiv_id': 'arXiv:2503.07450', 'title': 'From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper', 'authors': "Sargam Yadav, Asifa Mehmood Qureshi, Abhishek Kaushik, Shubham Sharma, Roisin Loughran, Subramaniam Kazhuparambil, Andrew Shaw, Mohammed Sabry, Niamh St John Lynch, . Nikhil Singh, Padraic O'Hara, Pranay Jaiswal, Roshan Chandru, David Lillis", 'link': 'https://arxiv.org/abs/2503.07450', 'abstract': 'The introduction of transformer architecture was a turning point in Natural Language Processing (NLP). Models based on the transformer architecture such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformer (GPT) have gained widespread popularity in various applications such as software development and education. The availability of Large Language Models (LLMs) such as ChatGPT and Bard to the general public has showcased the tremendous potential of these models and encouraged their integration into various domains such as software development for tasks such as code generation, debugging, and documentation generation. In this study, opinions from 11 experts regarding their experience with LLMs for software development have been gathered and analysed to draw insights that can guide successful and responsible integration. The overall opinion of the experts is positive, with the experts identifying advantages such as increase in productivity and reduced coding time. Potential concerns and challenges such as risk of over-dependence and ethical considerations have also been highlighted.', 'abstract_zh': '变压器架构的引入是自然语言处理(NLP)领域的转折点。基于变压器架构的模型如双向编码器表示（BERT）和生成预训练变换器（GPT）在软件开发和教育等各类应用中获得了广泛 popularity。大型语言模型（LLMs）如ChatGPT和Bard的普及展示了这些模型的巨大潜力，并促进了它们在软件开发等领域的集成，用于代码生成、调试和文档生成等任务。本研究收集并分析了11位专家关于LLMs在软件开发中应用的经验意见，以引导其成功的负责任的集成。专家们总体态度积极，认为LLMs能提高生产率并减少编码时间，同时也指出了潜在的风险和挑战，如过度依赖和伦理考虑。', 'title_zh': '从概念到实施：大型语言模型在软件开发中影响评价——一篇观点论文'}
{'arxiv_id': 'arXiv:2503.07429', 'title': 'From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector Graphics', 'authors': 'Jaewook Lee, Jeongah Lee, Wanyong Feng, Andrew Lan', 'link': 'https://arxiv.org/abs/2503.07429', 'abstract': 'Advances in large language models (LLMs) offer new possibilities for enhancing math education by automating support for both teachers and students. While prior work has focused on generating math problems and high-quality distractors, the role of visualization in math learning remains under-explored. Diagrams are essential for mathematical thinking and problem-solving, yet manually creating them is time-consuming and requires domain-specific expertise, limiting scalability. Recent research on using LLMs to generate Scalable Vector Graphics (SVG) presents a promising approach to automating diagram creation. Unlike pixel-based images, SVGs represent geometric figures using XML, allowing seamless scaling and adaptability. Educational platforms such as Khan Academy and IXL already use SVGs to display math problems and hints. In this paper, we explore the use of LLMs to generate math-related diagrams that accompany textual hints via intermediate SVG representations. We address three research questions: (1) how to automatically generate math diagrams in problem-solving hints and evaluate their quality, (2) whether SVG is an effective intermediate representation for math diagrams, and (3) what prompting strategies and formats are required for LLMs to generate accurate SVG-based diagrams. Our contributions include defining the task of automatically generating SVG-based diagrams for math hints, developing an LLM prompting-based pipeline, and identifying key strategies for improving diagram generation. Additionally, we introduce a Visual Question Answering-based evaluation setup and conduct ablation studies to assess different pipeline variations. By automating the math diagram creation, we aim to provide students and teachers with accurate, conceptually relevant visual aids that enhance problem-solving and learning experiences.', 'abstract_zh': '大型语言模型的进步为增强数学教育提供了新机遇，通过自动化支持教师和学生。虽然先前的工作集中在生成数学问题和高质量的诱饵上，但数学学习中的可视化作用仍然被研究不足。图表对于数学思考和问题解决至关重要，但手动创建它们耗时且需要特定领域的专业知识，限制了其可扩展性。最近在使用大型语言模型生成可缩放矢量图形（SVG）的研究表明了一种自动创建图表的有希望的方法。与基于像素的图像不同，SVG 使用 XML 表示几何图形，允许无缝缩放和适应性。诸如 Kahn Academy 和 IXL 等教育平台已经使用 SVG 来显示数学问题和提示。在本文中，我们探索使用大型语言模型通过中间 SVG 表示生成与文本提示相关联的数学图表。我们解决三个研究问题：（1）如何自动生成数学提示中的图表并评估其质量，（2）SVG 是否是数学图表的有效中间表示，以及（3）需要哪种提示策略和格式使大型语言模型能够生成准确的基于 SVG 的图表。我们的贡献包括定义自动生成数学提示中基于 SVG 的图表的任务，开发基于大型语言模型提示的流水线，并确定改进图表生成的关键策略。此外，我们介绍了基于视觉问答的评估设置，并进行了消融研究以评估不同流水线变体。通过自动化数学图表的创建，我们旨在为学生和教师提供准确且具有概念相关性的视觉辅助，以增强解决和学习体验。', 'title_zh': '从文本到视觉：使用LLMs生成矢量图形数学图表'}
{'arxiv_id': 'arXiv:2503.07351', 'title': 'Encoding Argumentation Frameworks to Propositional Logic Systems', 'authors': 'Shuai Tang, Jiachao Wu, Ning Zhou', 'link': 'https://arxiv.org/abs/2503.07351', 'abstract': "The theory of argumentation frameworks ($AF$s) has been a useful tool for artificial intelligence. The research of the connection between $AF$s and logic is an important branch. This paper generalizes the encoding method by encoding $AF$s as logical formulas in different propositional logic systems. It studies the relationship between models of an AF by argumentation semantics, including Dung's classical semantics and Gabbay's equational semantics, and models of the encoded formulas by semantics of propositional logic systems. Firstly, we supplement the proof of the regular encoding function in the case of encoding $AF$s to the 2-valued propositional logic system. Then we encode $AF$s to 3-valued propositional logic systems and fuzzy propositional logic systems and explore the model relationship. This paper enhances the connection between $AF$s and propositional logic systems. It also provides a new way to construct new equational semantics by choosing different fuzzy logic operations.", 'abstract_zh': '论辩框架理论（$AF$s）及其与逻辑的连接研究：不同命题逻辑系统中编码方法的推广与模型关系探讨', 'title_zh': '将论证框架编码为命题逻辑系统'}
{'arxiv_id': 'arXiv:2503.07319', 'title': 'Human Machine Co-Adaptation Model and Its Convergence Analysis', 'authors': 'Steven W. Su, Yaqi Li, Kairui Guo, Rob Duffield', 'link': 'https://arxiv.org/abs/2503.07319', 'abstract': "The key to robot-assisted rehabilitation lies in the design of the human-machine interface, which must accommodate the needs of both patients and machines. Current interface designs primarily focus on machine control algorithms, often requiring patients to spend considerable time adapting. In this paper, we introduce a novel approach based on the Cooperative Adaptive Markov Decision Process (CAMDPs) model to address the fundamental aspects of the interactive learning process, offering theoretical insights and practical guidance. We establish sufficient conditions for the convergence of CAMDPs and ensure the uniqueness of Nash equilibrium points. Leveraging these conditions, we guarantee the system's convergence to a unique Nash equilibrium point. Furthermore, we explore scenarios with multiple Nash equilibrium points, devising strategies to adjust both Value Evaluation and Policy Improvement algorithms to enhance the likelihood of converging to the global minimal Nash equilibrium point. Through numerical experiments, we illustrate the effectiveness of the proposed conditions and algorithms, demonstrating their applicability and robustness in practical settings. The proposed conditions for convergence and the identification of a unique optimal Nash equilibrium contribute to the development of more effective adaptive systems for human users in robot-assisted rehabilitation.", 'abstract_zh': '机器人辅助康复的关键在于人性化界面的设计，必须兼顾患者和机器的需求。目前的界面设计主要集中在机器控制算法上，通常需要患者花费大量时间进行适应。在本文中，我们引入了一种基于合作自适应马尔可夫决策过程（CAMDPs）模型的新方法，以解决交互学习过程中的基本问题，提供理论洞察和实用指导。我们建立了CAMDPs收敛的充分条件，并确保纳什均衡点的唯一性。利用这些条件，我们保证系统的收敛到唯一的纳什均衡点。此外，我们探讨了存在多个纳什均衡点的情景，并制定策略调整价值评估和策略改进算法，以提高收敛到全局最小纳什均衡点的概率。通过数值实验，我们展示了所提条件和算法的有效性，证明它们在实际应用中的适用性和鲁棒性。所提的收敛条件和唯一的最优纳什均衡点的识别为机器人辅助康复中更具效性的自适应系统开发做出了贡献。', 'title_zh': '人类机器共适应模型及其收敛性分析'}
{'arxiv_id': 'arXiv:2503.07275', 'title': 'Automatic Curriculum Design for Zero-Shot Human-AI Coordination', 'authors': 'Won-Sang You, Tae-Gwan Ha, Seo-Young Lee, Kyung-Joong Kim', 'link': 'https://arxiv.org/abs/2503.07275', 'abstract': "Zero-shot human-AI coordination is the training of an ego-agent to coordinate with humans without using human data. Most studies on zero-shot human-AI coordination have focused on enhancing the ego-agent's coordination ability in a given environment without considering the issue of generalization to unseen environments. Real-world applications of zero-shot human-AI coordination should consider unpredictable environmental changes and the varying coordination ability of co-players depending on the environment. Previously, the multi-agent UED (Unsupervised Environment Design) approach has investigated these challenges by jointly considering environmental changes and co-player policy in competitive two-player AI-AI scenarios. In this paper, our study extends the multi-agent UED approach to a zero-shot human-AI coordination. We propose a utility function and co-player sampling for a zero-shot human-AI coordination setting that helps train the ego-agent to coordinate with humans more effectively than the previous multi-agent UED approach. The zero-shot human-AI coordination performance was evaluated in the Overcooked-AI environment, using human proxy agents and real humans. Our method outperforms other baseline models and achieves a high human-AI coordination performance in unseen environments.", 'abstract_zh': '零样本人机协调训练ego-agent在给定环境中与人类协调而无需使用人类数据。大部分关于零样本人机协调的研究集中在增强ego-agent在特定环境中的协调能力，而未考虑未见过的环境下的泛化问题。零样本人机协调的实际应用需要考虑环境的不可预测变化以及随环境变化而变化的合作者协调能力。以往，多智能体无监督环境设计（UED）方法通过在竞争性二人对战的人工智能对战场景中同时考虑环境变化和合作者策略，来研究这些挑战。本文将无监督环境设计方法扩展至零样本人机协调场景，提出了一种效用函数和合作者采样方法，以提高ego-agent与人类协调的能力。零样本人机协调性能在Overcooked-AI环境中通过人类代理智能体和真实人类进行评估，结果显示本方法优于其他基线模型，并在未见过的环境中实现了高人机协调性能。', 'title_zh': '零样本人机协调自动课程设计'}
{'arxiv_id': 'arXiv:2503.07202', 'title': 'A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding', 'authors': 'Bingchen Liu, Jingchen Li, Naixing Xu, Xin Li', 'link': 'https://arxiv.org/abs/2503.07202', 'abstract': 'Zero-shot learning (ZL) is crucial for tasks involving unseen categories, such as natural language processing, image classification, and cross-lingual transfer. Current applications often fail to accurately infer and handle new relations or entities involving unseen categories, severely limiting their scalability and practicality in open-domain scenarios. ZL learning faces the challenge of effectively transferring semantic information of unseen categories in multi-modal knowledge graph (MMKG) embedding representation learning. In this paper, we propose ZSLLM, a framework for zero-shot embedding learning of MMKGs using large language models (LLMs). We leverage textual modality information of unseen categories as prompts to fully utilize the reasoning capabilities of LLMs, enabling semantic information transfer across different modalities for unseen categories. Through model-based learning, the embedding representation of unseen categories in MMKG is enhanced. Extensive experiments conducted on multiple real-world datasets demonstrate the superiority of our approach compared to state-of-the-art methods.', 'abstract_zh': '零-shot 学习 (ZL) 对于涉及未见类别的任务至关重要，如自然语言处理、图像分类和跨语言迁移。当前的应用往往难以准确推断和处理涉及未见类别的新关系或实体，严重限制了它们在开放域场景中的可扩展性和实用性。零-shot 学习面临在多模态知识图嵌入表示学习中有效转移未见类别语义信息的挑战。在本文中，我们提出 ZSLLM，一种利用大型语言模型 (LLM) 进行多模态知识图 (MMKG) 零-shot 嵌入学习的框架。我们利用未见类别的文本模态信息作为提示，充分利用 LLM 的推理能力，实现不同模态之间未见类别的语义信息转移。通过基于模型的学习，增强了 MMKG 中未见类别的嵌入表示。在多个真实世界数据集上的广泛实验表明，我们的方法在性能上优于现有方法。', 'title_zh': '基于大型语言模型的零样本学习多模态知识图嵌入方法'}
{'arxiv_id': 'arXiv:2503.07172', 'title': 'Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems', 'authors': 'L. Thomas van Binsbergen, Marten C. Steketee, Milen G. Kebede, Heleen L. Janssen, Tom M. van Engers', 'link': 'https://arxiv.org/abs/2503.07172', 'abstract': 'Compliance with the GDPR privacy regulation places a significant burden on organisations regarding the handling of personal data. The perceived efforts and risks of complying with the GDPR further increase when data processing activities span across organisational boundaries, as is the case in both small-scale data sharing settings and in large-scale international data spaces.\nThis paper addresses these concerns by proposing a case-generic method for automated normative reasoning that establishes legal arguments for the lawfulness of data processing activities. The arguments are established on the basis of case-specific legal qualifications made by privacy experts, bringing the human in the loop. The obtained expert system promotes transparency and accountability, remains adaptable to extended or altered interpretations of the GDPR, and integrates into novel or existing distributed data processing systems.\nThis result is achieved by defining a formal ontology and semantics for automated normative reasoning based on an analysis of the purpose-limitation principle of the GDPR. The ontology and semantics are implemented in eFLINT, a domain-specific language for specifying and reasoning with norms. The XACML architecture standard, applicable to both access and usage control, is extended, demonstrating how GDPR-based normative reasoning can integrate into (existing, distributed) systems for data processing. The resulting system is designed and critically assessed in reference to requirements extracted from the GPDR.', 'abstract_zh': 'GDPR隐私法规遵守对组织在个人数据处理方面造成了显著负担。当数据处理活动跨越组织边界时，合规努力和风险进一步增加，这在小规模数据共享设置和大规模国际数据空间中尤为明显。\n\n本文通过提出一种案例通用的方法来自动进行规范推理，为此类数据处理活动建立合法性的法律论据。这些论据基于隐私专家提供的案例特定的法律资格，从而使人在环中发挥作用。所得专家系统促进透明度和问责制，能够适应GDPR扩展或更改的解释，并可集成到新型或现有的分布式数据处理系统中。\n\n这一结果是通过基于GDPR目的限制原则的分析，定义自动规范推理的形式本体论和语义来实现的。本体论和语义基于eFLINT（一个专门领域语言，用于规范的指定和推理）进行实现。扩展了适用于访问和使用控制的XACML架构标准，展示GDPR为基础的规范推理如何整合到（现有的、分布式的）数据处理系统中。最终系统根据从GDPR中提取的功能需求进行设计和批判性评估。', 'title_zh': '基于GDPR的数据合法与负责任处理及其在分布式系统中的访问与使用控制'}
{'arxiv_id': 'arXiv:2503.07158', 'title': 'Generative AI in Transportation Planning: A Survey', 'authors': 'Longchao Da, Tiejin Chen, Zhuoheng Li, Shreyas Bachiraju, Huaiyuan Yao, Xiyang Hu, Zhengzhong Tu, Yue Zhao, Dongjie Wang, Xuanyu, Zhou, Ram Pendyala, Benjamin Stabler, Yezhou Yang, Xuesong Zhou, Hua Wei', 'link': 'https://arxiv.org/abs/2503.07158', 'abstract': 'The integration of generative artificial intelligence (GenAI) into transportation planning has the potential to revolutionize tasks such as demand forecasting, infrastructure design, policy evaluation, and traffic simulation. However, there is a critical need for a systematic framework to guide the adoption of GenAI in this interdisciplinary domain. In this survey, we, a multidisciplinary team of researchers spanning computer science and transportation engineering, present the first comprehensive framework for leveraging GenAI in transportation planning. Specifically, we introduce a new taxonomy that categorizes existing applications and methodologies into two perspectives: transportation planning tasks and computational techniques. From the transportation planning perspective, we examine the role of GenAI in automating descriptive, predictive, generative, simulation, and explainable tasks to enhance mobility systems. From the computational perspective, we detail advancements in data preparation, domain-specific fine-tuning, and inference strategies, such as retrieval-augmented generation and zero-shot learning tailored to transportation applications. Additionally, we address critical challenges, including data scarcity, explainability, bias mitigation, and the development of domain-specific evaluation frameworks that align with transportation goals like sustainability, equity, and system efficiency. This survey aims to bridge the gap between traditional transportation planning methodologies and modern AI techniques, fostering collaboration and innovation. By addressing these challenges and opportunities, we seek to inspire future research that ensures ethical, equitable, and impactful use of generative AI in transportation planning.', 'abstract_zh': '将生成型人工智能（GenAI）整合到交通运输规划中，有可能革命性地改变需求预测、基础设施设计、政策评估和交通仿真等任务。然而，在这个跨学科领域中，系统性框架的缺乏限制了GenAI的应用。在本综述中，我们，来自计算机科学和交通运输工程领域的多学科研究团队，提出了首个整合GenAI于交通运输规划中的全面框架。具体而言，我们引入了一种新的分类体系，从交通运输规划任务和计算技术两个视角对现有应用和方法学进行分类。从交通运输规划视角出发，我们探讨了GenAI在自动化描述性、预测性、生成性、仿真性和解释性任务中的作用，以增强移动性系统。从计算技术视角出发，我们详细阐述了数据准备、领域特定微调和推理策略（如检索增强生成和针对交通运输应用的零样本学习）的进步。此外，我们还讨论了关键挑战，包括数据匮乏、可解释性、偏见缓解以及与可持续性、公平性和系统效率等交通运输目标相一致的领域特定评估框架的发展。本综述旨在弥合传统交通运输规划方法与现代AI技术之间的差距，促进协作与创新。通过解决这些挑战和机遇，我们希望激发未来研究，确保生成型AI在交通运输规划中的伦理、公平和影响。', 'title_zh': '生成式AI在交通规划中的应用：一个综述'}
{'arxiv_id': 'arXiv:2503.07148', 'title': 'Hierarchical Neuro-Symbolic Decision Transformer', 'authors': 'Ali Baheri, Cecilia O. Alm', 'link': 'https://arxiv.org/abs/2503.07148', 'abstract': 'We present a hierarchical neuro-symbolic control framework that couples classical symbolic planning with transformer-based policies to address complex, long-horizon decision-making tasks. At the high level, a symbolic planner constructs an interpretable sequence of operators based on logical propositions, ensuring systematic adherence to global constraints and goals. At the low level, each symbolic operator is translated into a sub-goal token that conditions a decision transformer to generate a fine-grained sequence of actions in uncertain, high-dimensional environments. We provide theoretical analysis showing how approximation errors from both the symbolic planner and the neural execution layer accumulate. Empirical evaluations in grid-worlds with multiple keys, locked doors, and item-collection tasks show that our hierarchical approach outperforms purely end-to-end neural approach in success rates and policy efficiency.', 'abstract_zh': '一种结合经典符号规划和基于变压器的策略的层次神经符号控制框架及其应用', 'title_zh': '分层神经符号决策变换器'}
{'arxiv_id': 'arXiv:2503.07096', 'title': 'Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration', 'authors': 'Zhao Jin, Lu Jin, Yizhe Luo, Shuo Feng, Yucheng Shi, Kai Zheng, Xinde Yu, Mingliang Xu', 'link': 'https://arxiv.org/abs/2503.07096', 'abstract': "Despite significant progress in AI and decision-making technologies in safety-critical fields, challenges remain in verifying the correctness of decision output schemes and verification-result driven design. We propose correctness learning (CL) to enhance human-AI collaboration integrating deductive verification methods and insights from historical high-quality schemes. The typical pattern hidden in historical high-quality schemes, such as change of task priorities in shared resources, provides critical guidance for intelligent agents in learning and decision-making. By utilizing deductive verification methods, we proposed patten-driven correctness learning (PDCL), formally modeling and reasoning the adaptive behaviors-or 'correctness pattern'-of system agents based on historical high-quality schemes, capturing the logical relationships embedded within these schemes. Using this logical information as guidance, we establish a correctness judgment and feedback mechanism to steer the intelligent decision model toward the 'correctness pattern' reflected in historical high-quality schemes. Extensive experiments across multiple working conditions and core parameters validate the framework's components and demonstrate its effectiveness in improving decision-making and resource optimization.", 'abstract_zh': '尽管在AI和决策技术在安全关键领域取得了显著进展，但在验证决策输出方案的正确性和验证结果驱动的设计方面仍面临挑战。我们提出正确性学习（CL）以结合演绎验证方法和历史高质量方案的见解，增强人机协作。历史高质量方案中隐藏的典型模式，如共享资源中的任务优先级变化，为智能代理的学习和决策提供了关键指导。通过利用演绎验证方法，我们提出了模式驱动的正确性学习（PDCL），基于历史高质量方案形式化建模和推理系统代理的适应性行为或“正确性模式”，捕获这些方案内部嵌入的逻辑关系。利用这种逻辑信息作为指导，我们建立了一种正确性判断和反馈机制，引导智能决策模型向历史高质量方案中反映的“正确性模式”发展。广泛的实验验证了该框架的各个组件，并展示了其在提高决策和资源优化方面的有效性。', 'title_zh': '正确性学习：基于演绎验证的-human-AI协作学习'}
{'arxiv_id': 'arXiv:2503.07077', 'title': 'Rule-Based Conflict-Free Decision Framework in Swarm Confrontation', 'authors': 'Zhaoqi Dong, Zhinan Wang, Quanqi Zheng, Bin Xu, Lei Chen, Jinhu Lv', 'link': 'https://arxiv.org/abs/2503.07077', 'abstract': 'Traditional rule--based decision--making methods with interpretable advantage, such as finite state machine, suffer from the jitter or deadlock(JoD) problems in extremely dynamic scenarios. To realize agent swarm confrontation, decision conflicts causing many JoD problems are a key issue to be solved. Here, we propose a novel decision--making framework that integrates probabilistic finite state machine, deep convolutional networks, and reinforcement learning to implement interpretable intelligence into agents. Our framework overcomes state machine instability and JoD problems, ensuring reliable and adaptable decisions in swarm confrontation. The proposed approach demonstrates effective performance via enhanced human--like cooperation and competitive strategies in the rigorous evaluation of real experiments, outperforming other methods.', 'abstract_zh': '基于概率有限状态机、深度卷积网络和强化学习的新型决策框架：实现智能体群拥导中的可解释智能', 'title_zh': '基于规则的 swarm 对抗中冲突自由决策框架'}
{'arxiv_id': 'arXiv:2503.06951', 'title': 'ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA', 'authors': 'Zhao Xinjie, Fan Gao, Rui Yang, Yingjian Chen, Yuyang Wang, Ying Zhu, Jiacheng Tang, Irene Li', 'link': 'https://arxiv.org/abs/2503.06951', 'abstract': "Recent advances in large language models (LLMs) have significantly improved multi-hop question answering (QA) through direct Chain-of-Thought (CoT) reasoning. However, the irreversible nature of CoT leads to error accumulation, making it challenging to correct mistakes in multi-hop reasoning. This paper introduces ReAgent: a Reversible multi-Agent collaborative framework augmented with explicit backtracking mechanisms, enabling reversible multi-hop reasoning. By incorporating text-based retrieval, information aggregation and validation, our system can detect and correct errors mid-reasoning, leading to more robust and interpretable QA outcomes. The framework and experiments serve as a foundation for future work on error-tolerant QA systems. Empirical evaluations across three benchmarks indicate ReAgent's efficacy, yielding average about 6\\% improvements against baseline models.", 'abstract_zh': 'Recent advances in大规模语言模型（LLMs）通过直接链式思考（CoT）推理显著提高了多跳问答（QA）的能力。然而，CoT的不可逆性导致了错误累积，使得在多跳推理中纠正错误变得具有挑战性。本文介绍了一种名为ReAgent的可逆多智能体协作框架，该框架增强了显式的回溯机制，使其能够进行可逆的多跳推理。通过结合基于文本的检索、信息聚合和验证，我们的系统可以在推理过程中检测和纠正错误，从而产生更 robust 和可解释的问答结果。该框架和实验为未来容错问答系统的工作奠定了基础。跨三个基准的实证评估表明，ReAgent的有效性，相对于基线模型平均提高了约6%。', 'title_zh': 'ReAgent: 可逆多agent推理在知识增强多跳QA中的应用'}
{'arxiv_id': 'arXiv:2503.06867', 'title': 'Enhancing Time Series Forecasting via Logic-Inspired Regularization', 'authors': 'Jianqi Zhang, Jingyao Wang, Xingchen Shen, Wenwen Qiang', 'link': 'https://arxiv.org/abs/2503.06867', 'abstract': 'Time series forecasting (TSF) plays a crucial role in many applications. Transformer-based methods are one of the mainstream techniques for TSF. Existing methods treat all token dependencies equally. However, we find that the effectiveness of token dependencies varies across different forecasting scenarios, and existing methods ignore these differences, which affects their performance. This raises two issues: (1) What are effective token dependencies? (2) How can we learn effective dependencies? From a logical perspective, we align Transformer-based TSF methods with the logical framework and define effective token dependencies as those that ensure the tokens as atomic formulas (Issue 1). We then align the learning process of Transformer methods with the process of obtaining atomic formulas in logic, which inspires us to design a method for learning these effective dependencies (Issue 2). Specifically, we propose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method that guides the model to use fewer but more effective dependencies by making the attention map sparse, thereby ensuring the tokens as atomic formulas and improving prediction performance. Extensive experiments and theoretical analysis confirm the effectiveness of Attn-L-Reg.', 'abstract_zh': '基于Transformer的时间序列forecasting中有效token依赖的学习与正则化（Attention Logic Regularization）', 'title_zh': '基于逻辑启发的正则化增强时间序列预测'}
{'arxiv_id': 'arXiv:2503.06788', 'title': 'Dubito Ergo Sum: Exploring AI Ethics', 'authors': 'Viktor Dorfler, Giles Cuthbert', 'link': 'https://arxiv.org/abs/2503.06788', 'abstract': 'We paraphrase Descartes\' famous dictum in the area of AI ethics where the "I doubt and therefore I am" is suggested as a necessary aspect of morality. Therefore AI, which cannot doubt itself, cannot possess moral agency. Of course, this is not the end of the story. We explore various aspects of the human mind that substantially differ from AI, which includes the sensory grounding of our knowing, the act of understanding, and the significance of being able to doubt ourselves. The foundation of our argument is the discipline of ethics, one of the oldest and largest knowledge projects of human history, yet, we seem only to be beginning to get a grasp of it. After a couple of thousand years of studying the ethics of humans, we (humans) arrived at a point where moral psychology suggests that our moral decisions are intuitive, and all the models from ethics become relevant only when we explain ourselves. This recognition has a major impact on what and how we can do regarding AI ethics. We do not offer a solution, we explore some ideas and leave the problem open, but we hope somewhat better understood than before our study.', 'abstract_zh': '我们在AI伦理领域重述笛卡尔的名言，“我怀疑因此我存在”被视作道德的必要组成部分。因此，AI无法自我怀疑，无法具备道德代理能力。当然，这并不是故事的终点。我们探讨了人类心灵的各种方面，这些方面与AI有实质性差异，包括我们知识的感觉基础、理解的行动以及自我怀疑的意义。我们论点的基础是伦理学这一学科，它是人类历史最早且最大的知识项目之一，但似乎我们才刚刚开始理解和把握它。经过数千年对人类伦理的研究，我们认识到道德决策是直觉性的，所有的伦理模型只有在解释自身时才变得相关。这一认识对我们处理AI伦理问题的方式有着重大影响。我们没有提供解决方案，而是探讨了一些想法，并将问题留待开放，但我们希望在研究后比之前对问题有更深入的理解。', 'title_zh': '我思故我疑：探索人工智能伦理'}
{'arxiv_id': 'arXiv:2503.06745', 'title': 'Beyond Black-Box Benchmarking: Observability, Analytics, and Optimization of Agentic Systems', 'authors': 'Dany Moshkovich, Hadar Mulian, Sergey Zeltyn, Natti Eder, Inna Skarbovsky, Roy Abitbol', 'link': 'https://arxiv.org/abs/2503.06745', 'abstract': 'The rise of agentic AI systems, where agents collaborate to perform diverse tasks, poses new challenges with observing, analyzing and optimizing their behavior. Traditional evaluation and benchmarking approaches struggle to handle the non-deterministic, context-sensitive, and dynamic nature of these systems. This paper explores key challenges and opportunities in analyzing and optimizing agentic systems across development, testing, and maintenance. We explore critical issues such as natural language variability and unpredictable execution flows, which hinder predictability and control, demanding adaptive strategies to manage input variability and evolving behaviors. Through our user study, we supported these hypotheses. In particular, we showed a 79% agreement that non deterministic flow of agentic systems acts as a major challenge. Finally, we validated our statements empirically advocating the need for moving beyond classical benchmarking. To bridge these gaps, we introduce taxonomies to present expected analytics outcomes and the ways to collect them by extending standard observability frameworks. Building on these foundations, we introduce and demonstrate novel approach for benchmarking of agent evaluation systems. Unlike traditional "black box" performance evaluation approaches, our benchmark is built from agent runtime logs as input, and analytics outcome including discovered flows and issues. By addressing key limitations in existing methodologies, we aim to set the stage for more advanced and holistic evaluation strategies, which could foster the development of adaptive, interpretable, and robust agentic AI systems.', 'abstract_zh': '代理型AI系统的兴起，其中代理协作执行多样任务，带来了新的挑战，涉及观察、分析和优化其行为。传统的评估和基准测试方法难以应对这些系统的非确定性、上下文敏感性和动态性。本文探讨了在开发、测试和维护过程中分析和优化代理型系统的关键挑战和机遇。我们研究了诸如自然语言变异性和不可预见的执行流程等核心问题，这些问题妨碍了可预测性和控制，要求采用适应性策略来管理输入变异性和不断变化的行为。通过我们的用户研究，我们支持了这些假设，并特别指出79%的参与者认为代理型系统的非确定性流程是主要挑战之一。最后，我们通过实证验证证明了需要超越经典基准测试的必要性。为了弥补这些差距，我们引入了分类学来呈现预期的分析结果及其收集方式，通过扩展标准可观测性框架。在这些建设的基础上，我们提出了并示范了一种新的代理评估基准测试方法。与其他传统的“黑盒”性能评估方法不同，我们的基准测试基于代理运行时日志作为输入，并结合分析结果，包括发现的流程和问题。通过解决现有方法的关键限制，我们旨在为更高级和综合的评估策略奠定基础，这有助于促进开发适应性强、可解释且稳健的代理型AI系统。', 'title_zh': '超越黑盒基准测试：代理系统的可观测性、分析与优化'}
{'arxiv_id': 'arXiv:2503.06580', 'title': 'Agent models: Internalizing Chain-of-Action Generation into Reasoning models', 'authors': 'Yuxiang Zhang, Yuqi Yang, Jiangming Shu, Xinyan Wen, Jitao Sang', 'link': 'https://arxiv.org/abs/2503.06580', 'abstract': 'Traditional agentic workflows rely on external prompts to manage interactions with tools and the environment, which limits the autonomy of reasoning models. We position \\emph{Large Agent Models (LAMs)} that internalize the generation of \\emph{Chain-of-Action (CoA)}, enabling the model to autonomously decide when and how to use external tools. Our proposed AutoCoA framework combines supervised fine-tuning (SFT) and reinforcement learning (RL), allowing the model to seamlessly switch between reasoning and action while efficiently managing environment interactions. Main components include step-level action triggering, trajectory-level CoA optimization, and an internal world model to reduce real-environment interaction costs. Evaluations on open-domain QA tasks demonstrate that AutoCoA-trained agent models significantly outperform ReAct-based workflows in task completion, especially in tasks that require long-term reasoning and multi-step actions. Code and dataset are available at this https URL', 'abstract_zh': '传统代理工作流依赖外部提示来管理与工具和环境的互动，这限制了推理模型的自主 reasoning 能力。我们提出的大代理模型（LAMs）内化了操作链（CoA）的生成，使模型能够自主决定何时以及如何使用外部工具。我们提出的 AutoCoA 框架结合了监督微调（SFT）和强化学习（RL），允许模型在高效管理环境互动的同时，无缝地在推理和操作之间切换。主要组件包括步骤级操作触发、轨迹级 CoA 优化以及内部世界模型以减少对真实环境的互动成本。在开域 QA 任务上的评估表明，通过 AutoCoA 训练的代理模型在任务完成上显著优于基于 ReAct 的工作流，尤其是在需要长期推理和多步操作的任务中。代码和数据集可在以下链接获取。', 'title_zh': '代理模型：将链式操作生成内嵌到推理模型中'}
{'arxiv_id': 'arXiv:2503.06553', 'title': 'ProJudge: A Multi-Modal Multi-Discipline Benchmark and Instruction-Tuning Dataset for MLLM-based Process Judges', 'authors': 'Jiaxin Ai, Pengfei Zhou, Zhaopan Xu, Ming Li, Fanrui Zhang, Zizhen Li, Jianwen Sun, Yukang Feng, Baojin Huang, Zhongyuan Wang, Kaipeng Zhang', 'link': 'https://arxiv.org/abs/2503.06553', 'abstract': "As multi-modal large language models (MLLMs) frequently exhibit errors when solving scientific problems, evaluating the validity of their reasoning processes is critical for ensuring reliability and uncovering fine-grained model weaknesses. Since human evaluation is laborious and costly, prompting MLLMs as automated process judges has become a common practice. However, the reliability of these model-based judges remains uncertain. To address this, we introduce ProJudgeBench, the first comprehensive benchmark specifically designed for evaluating abilities of MLLM-based process judges. ProJudgeBench comprises 2,400 test cases and 50,118 step-level labels, spanning four scientific disciplines with diverse difficulty levels and multi-modal content. In ProJudgeBench, each step is meticulously annotated by human experts for correctness, error type, and explanation, enabling a systematic evaluation of judges' capabilities to detect, classify and diagnose errors. Evaluation on ProJudgeBench reveals a significant performance gap between open-source and proprietary models. To bridge this gap, we further propose ProJudge-173k, a large-scale instruction-tuning dataset, and a Dynamic Dual-Phase fine-tuning strategy that encourages models to explicitly reason through problem-solving before assessing solutions. Both contributions significantly enhance the process evaluation capabilities of open-source models. All the resources will be released to foster future research of reliable multi-modal process evaluation.", 'abstract_zh': '多模态大语言模型过程评估基准ProJudgeBench及其应用研究', 'title_zh': 'ProJudge: 一种基于MLLM的多模态多学科基准与指令调优数据集'}
{'arxiv_id': 'arXiv:2503.06551', 'title': 'ChatGPT-4 in the Turing Test: A Critical Analysis', 'authors': 'Marco Giunti', 'link': 'https://arxiv.org/abs/2503.06551', 'abstract': 'This paper critically examines the recent publication "ChatGPT-4 in the Turing Test" by Restrepo Echavarría (2025), challenging its central claims regarding the absence of minimally serious test implementations and the conclusion that ChatGPT-4 fails the Turing Test. The analysis reveals that the criticisms based on rigid criteria and limited experimental data are not fully justified. More importantly, the paper makes several constructive contributions that enrich our understanding of Turing Test implementations. It demonstrates that two distinct formats--the three-player and two-player tests--are both valid, each with unique methodological implications. The work distinguishes between absolute criteria (reflecting an optimal 50% identification rate in a three-player format) and relative criteria (which measure how closely a machine\'s performance approximates that of a human), offering a more nuanced evaluation framework. Furthermore, the paper clarifies the probabilistic underpinnings of both test types by modeling them as Bernoulli experiments--correlated in the three-player version and uncorrelated in the two-player version. This formalization allows for a rigorous separation between the theoretical criteria for passing the test, defined in probabilistic terms, and the experimental data that require robust statistical methods for proper interpretation. In doing so, the paper not only refutes key aspects of the criticized study but also lays a solid foundation for future research on objective measures of how closely an AI\'s behavior aligns with, or deviates from, that of a human being.', 'abstract_zh': '本文批判性地考察了Restrepo Echavarría (2025) 的近期出版物《ChatGPT-4在图灵测试中的表现》一文，对其关于最小严肃测试实施的缺失以及ChatGPT-4未通过图灵测试的主要论点提出质疑。分析表明，基于僵化标准和有限实验数据的批评并不完全成立。更重要的是，本文作出了若干建设性贡献，丰富了我们对图灵测试实施的理解。文章指出，三种赛制格式——三人测试和二人测试——都是有效的，各自具有独特的方法论意义。研究区分了绝对标准（反映三人测试中50%的理想识别率）和相对标准（衡量机器性能与人类表现的接近程度），提供了更为细致的评估框架。此外，论文通过将两种测试类型建模为伯努利试验——三人测试相关，二人测试不相关——澄清了测试类型的概率基础。这种形式化使得可以对测试通过的理论标准（以概率术语定义）和需要稳健统计方法解读的实验数据进行严格的分离。通过这种方式，本文不仅反驳了被批评研究的关键方面，也为未来关于人工智能行为与人类行为契合度或偏离程度的客观衡量研究奠定了坚实基础。', 'title_zh': 'ChatGPT-4 在图灵测试中的批判性分析'}
{'arxiv_id': 'arXiv:2503.06479', 'title': 'ExKG-LLM: Leveraging Large Language Models for Automated Expansion of Cognitive Neuroscience Knowledge Graphs', 'authors': 'Ali Sarabadani, Kheirolah Rahsepar Fard, Hamid Dalvand', 'link': 'https://arxiv.org/abs/2503.06479', 'abstract': 'The paper introduces ExKG-LLM, a framework designed to automate the expansion of cognitive neuroscience knowledge graphs (CNKG) using large language models (LLMs). It addresses limitations in existing tools by enhancing accuracy, completeness, and usefulness in CNKG. The framework leverages a large dataset of scientific papers and clinical reports, applying state-of-the-art LLMs to extract, optimize, and integrate new entities and relationships. Evaluation metrics include precision, recall, and graph density. Results show significant improvements: precision (0.80, +6.67%), recall (0.81, +15.71%), F1 score (0.805, +11.81%), and increased edge nodes (21.13% and 31.92%). Graph density slightly decreased, reflecting a broader but more fragmented structure. Engagement rates rose by 20%, while CNKG diameter increased to 15, indicating a more distributed structure. Time complexity improved to O(n log n), but space complexity rose to O(n2), indicating higher memory usage. ExKG-LLM demonstrates potential for enhancing knowledge generation, semantic search, and clinical decision-making in cognitive neuroscience, adaptable to broader scientific fields.', 'abstract_zh': 'ExKG-LLM：一种利用大规模语言模型自动扩展认知神经科学知识图谱的框架', 'title_zh': 'ExKG-LLM：利用大规模语言模型自动扩展认知神经科学知识图谱'}
{'arxiv_id': 'arXiv:2503.06475', 'title': 'SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph Construction Using Large Language Models', 'authors': 'Ali Sarabadani, Kheirolah Rahsepar Fard, Hamid Dalvand', 'link': 'https://arxiv.org/abs/2503.06475', 'abstract': 'The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is constructed from stroke-related articles using mathematical and large language models (LLMs). SKG-LLM extracts and organizes complex relationships from the biomedical literature, using it to increase the accuracy and depth of KG in stroke research. In the proposed method, GPT-4 was used for data pre-processing, and the extraction of embeddings was also done by GPT-4 in the whole KG construction process. The performance of the proposed model was tested with two evaluation criteria: Precision and Recall. For further validation of the proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the proposed KG-LLM approach performs better, especially in precision and recall. By including GPT-4 in the preprocessing process, the SKG-LLM model achieved a precision score of 0.906 and a recall score of 0.923. Expert reviews further improved the results and increased precision to 0.923 and recall to 0.918. The knowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges, which are 13 distinct types of nodes and 24 types of edges.', 'abstract_zh': 'SKG-LLM：基于数学和大型语言模型的中风相关知识图谱构建与应用', 'title_zh': 'SKG-LLM：使用大规模语言模型构建中风知识图谱的数学模型开发'}
{'arxiv_id': 'arXiv:2503.06470', 'title': 'Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow Systems', 'authors': 'Fei Tang, Yongliang Shen, Hang Zhang, Siqi Chen, Guiyang Hou, Wenqi Zhang, Wenqiao Zhang, Kaitao Song, Weiming Lu, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2503.06470', 'abstract': 'Humans can flexibly switch between different modes of thinking based on task complexity: from rapid intuitive judgments to in-depth analytical understanding. However, current Graphical User Interface (GUI) grounding systems which locate interface elements based on natural language instructions rely solely on immediate prediction without reasoning, struggling to understand complex interface layouts with nested structures and hierarchical relationships, limiting their effectiveness on complex interfaces. Inspired by human dual-system cognition, we present Focus, a novel GUI grounding framework that combines fast prediction with systematic analysis. The framework dynamically switches between rapid and deliberate processing through an adaptive system switching based on task complexity, optimizing both efficiency and accuracy. Focus decomposes grounding into progressive stages: interface summarization, visual focused analysis, and precise coordinate prediction. This structured decomposition enables systematic understanding of both interface layouts and visual relationships. Extensive experiments show that Focus achieves state-of-the-art performance using only 300K of the training data with a 2B parameter model compared to existing approaches. Focus demonstrates superior performance particularly in complex GUI scenarios, achieving 77.4% average accuracy on ScreenSpot and 13.3% on the more challenging ScreenSpot-Pro. Our analysis reveals the effectiveness of this dual-system approach while demonstrating its potential for improving complex GUI interaction scenarios.', 'abstract_zh': '人类可以根据任务复杂度灵活切换不同的思维模式：从快速直觉判断到深入分析理解。然而，当前基于自然语言指令定位界面元素的图形用户界面（GUI）接地系统依赖于即时预测而不进行推理，难以理解具有嵌套结构和层次关系的复杂界面布局，限制了其在复杂界面中的有效性。受人类双系统认知的启发，我们提出 Focus，一个结合快速预测与系统分析的新型 GUI 接地框架。该框架通过基于任务复杂度的自适应系统切换，在保持效率的同时优化准确性。Focus 将接地分解为渐进的阶段：界面总结、视觉聚焦分析以及精确坐标预测。这种结构化的分解使得能够系统地理解界面布局及其视觉关系。广泛实验证明，Focus 使用仅为 300K 的训练数据和 2B 参数模型，实现了现有的最佳性能。在复杂 GUI 场景中，Focus 特别表现出色，在 ScreenSpot 中实现 77.4% 的平均准确率，在更具挑战性的 ScreenSpot-Pro 中实现 13.3% 的准确率。我们的分析揭示了这种双系统方法的有效性，并展示了其在改进复杂 GUI 交互场景中的潜力。', 'title_zh': 'Twice思慎行，一次轻点：通过快慢系统增强GUI定位'}
{'arxiv_id': 'arXiv:2503.06420', 'title': 'Explaining Control Policies through Predicate Decision Diagrams', 'authors': 'Debraj Chakraborty, Clemens Dubslaff, Sudeep Kanav, Jan Kretinsky, Christoph Weinhuber', 'link': 'https://arxiv.org/abs/2503.06420', 'abstract': 'Safety-critical controllers of complex systems are hard to construct manually. Automated approaches such as controller synthesis or learning provide a tempting alternative but usually lack explainability. To this end, learning decision trees (DTs) have been prevalently used towards an interpretable model of the generated controllers. However, DTs do not exploit shared decision-making, a key concept exploited in binary decision diagrams (BDDs) to reduce their size and thus improve explainability. In this work, we introduce predicate decision diagrams (PDDs) that extend BDDs with predicates and thus unite the advantages of DTs and BDDs for controller representation. We establish a synthesis pipeline for efficient construction of PDDs from DTs representing controllers, exploiting reduction techniques for BDDs also for PDDs.', 'abstract_zh': '复杂系统的安全关键控制器手工构建难度大。自动方法如控制器综合或学习提供了诱人的替代方案，但通常缺乏可解释性。为解决这一问题，已有研究表明，通过学习决策树（DTs）已经广泛用于生成具有可解释性的控制器模型。然而，DTs 未能利用共享决策这一关键概念，该概念在二元决策图（BDDs）中被用来减少其大小并提高可解释性。在此项工作中，我们引入了谓词决策图（PDDs），其扩展了BDDs以包含谓词，从而结合了决策树和BDDs的优点，用于控制器表示。我们建立了一个合成管道，从表示控制器的决策树（DTs）高效构建PDDs，并利用BDDs的缩减技术也适用于PDDs的技巧来建立PDDs。', 'title_zh': '通过谓词决策图解释控制策略'}
{'arxiv_id': 'arXiv:2503.06416', 'title': 'Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition', 'authors': 'Michelle Vaccaro, Michael Caoson, Harang Ju, Sinan Aral, Jared R. Curhan', 'link': 'https://arxiv.org/abs/2503.06416', 'abstract': 'Despite the rapid proliferation of artificial intelligence (AI) negotiation agents, there has been limited integration of computer science research and established negotiation theory to develop new theories of AI negotiation. To bridge this gap, we conducted an International AI Negotiations Competition in which participants iteratively designed and refined prompts for large language model (LLM) negotiation agents. We then facilitated over 120,000 negotiations between these agents across multiple scenarios with diverse characteristics and objectives. Our findings revealed that fundamental principles from established human-human negotiation theory remain crucial in AI-AI negotiations. Specifically, agents exhibiting high warmth fostered higher counterpart subjective value and reached deals more frequently, which enabled them to create and claim more value in integrative settings. However, conditional on reaching a deal, warm agents claimed less value while dominant agents claimed more value. These results align with classic negotiation theory emphasizing relationship-building, assertiveness, and preparation. Our analysis also revealed unique dynamics in AI-AI negotiations not fully explained by negotiation theory, particularly regarding the effectiveness of AI-specific strategies like chain-of-thought reasoning and prompt injection. The agent that won our competition implemented an approach that blended traditional negotiation preparation frameworks with AI-specific methods. Together, these results suggest the importance of establishing a new theory of AI negotiations that integrates established negotiation theory with AI-specific strategies to optimize agent performance. Our research suggests this new theory must account for the unique characteristics of autonomous agents and establish the conditions under which traditional negotiation theory applies in automated settings.', 'abstract_zh': '尽管人工智能（AI）谈判代理迅速普及，计算机科学研究与已建立的谈判理论在发展新的AI谈判理论方面的整合仍显不足。为弥合这一差距，我们举办了一场国际AI谈判竞赛，在此竞赛中，参赛者迭代设计和优化了大型语言模型（LLM）谈判代理的提示。随后，我们在多个具有多样特征和目标的场景中，促成了这些代理之间的超过120,000场谈判。研究发现表明，现有的人际谈判理论的基本原则在AI-AI谈判中依然至关重要。具体而言，表现出高度温暖特质的代理能够促进更高的对方主观价值感知并更频繁地达成协议，这使它们在整合性谈判情境中能够创造并宣称更多的价值。然而，在达成协议的前提下，温暖代理所宣称的价值较少，而主导代理所宣称的价值更多。这些结果与强调关系建立、坚定性和准备的经典谈判理论一致。我们的分析还揭示了AI-AI谈判中一些未被经典谈判理论充分解释的独特动态，尤其是在AI特定策略方面的有效性，如链式推理和提示注入。在我们竞赛中获胜的代理采取了一种传统谈判筹备框架与AI特定方法相结合的方法。综上所述，这些结果强调了需建立一种结合现有谈判理论与AI特定策略的新AI谈判理论的重要性，以优化代理绩效。我们的研究建议这一新理论必须考虑到自主代理的独特特性，并确定传统谈判理论在自动化情境中适用的条件。', 'title_zh': 'advancing AI谈判：大型自主谈判竞赛的新理论与证据'}
{'arxiv_id': 'arXiv:2503.06410', 'title': 'Performant LLM Agentic Framework for Conversational AI', 'authors': 'Alex Casella, Wayne Wang', 'link': 'https://arxiv.org/abs/2503.06410', 'abstract': 'The rise of Agentic applications and automation in the Voice AI industry has led to an increased reliance on Large Language Models (LLMs) to navigate graph-based logic workflows composed of nodes and edges. However, existing methods face challenges such as alignment errors in complex workflows and hallucinations caused by excessive context size. To address these limitations, we introduce the Performant Agentic Framework (PAF), a novel system that assists LLMs in selecting appropriate nodes and executing actions in order when traversing complex graphs. PAF combines LLM-based reasoning with a mathematically grounded vector scoring mechanism, achieving both higher accuracy and reduced latency. Our approach dynamically balances strict adherence to predefined paths with flexible node jumps to handle various user inputs efficiently. Experiments demonstrate that PAF significantly outperforms baseline methods, paving the way for scalable, real-time Conversational AI systems in complex business environments.', 'abstract_zh': '代理应用和自动化在语音AI行业的兴起导致了对大型语言模型（LLMs）的更大依赖，以导航由节点和边组成的图形逻辑工作流。然而，现有方法面临复杂工作流中的对齐错误和由于上下文大小过大引起的幻觉等挑战。为了解决这些限制，我们引入了高效的代理框架（PAF），这是一种新颖的系统，该系统帮助LLMs在遍历复杂图形时选择合适的节点并按顺序执行操作。PAF将基于LLM的推理与数学依据的向量评分机制相结合，从而实现更高的准确性和更低的延迟。我们的方法动态平衡严格的路径遵循与灵活的节点跳跃，以高效处理各种用户输入。实验表明，PAF在基准方法上表现显著更优，为复杂商业环境中的可扩展、实时对话AI系统铺平了道路。', 'title_zh': '高性能的LLM代理框架应用于对话式AI'}
{'arxiv_id': 'arXiv:2503.06396', 'title': 'Optimizing Minimum Vertex Cover Solving via a GCN-assisted Heuristic Algorithm', 'authors': 'Enqiang Zhu, Qiqi Bao, Yu Zhang, Chanjuan Liu', 'link': 'https://arxiv.org/abs/2503.06396', 'abstract': "The problem of finding a minimum vertex cover (MVC) in a graph is a well-known NP-hard problem with significant practical applications in optimization and scheduling. Its complexity, combined with the increasing scale of problems, underscores the need for efficient and effective algorithms. However, existing heuristic algorithms for MVC often rely on simplistic initialization strategies and overlook the impact of edge attributes and neighborhood information on vertex selection. In this paper, we introduce GCNIVC, a novel heuristic search algorithm designed to address the limitations of existing methods for solving MVC problems in large-scale graphs. Our approach features two main innovations. First, it utilizes a Graph Convolutional Network (GCN) to capture the global structure of graphs, which enables the generation of high-quality initial solutions that enhance the efficiency of the subsequent search process. Second, GCNIVC introduces a new heuristic that employs three containers and the concept of double-covered edges (dc-edges), improving search efficiency and providing greater flexibility for adding and removing operations based on edge attributes. Through extensive experiments on benchmark datasets, we demonstrate that GCNIVC outperforms state-of-the-art MVC algorithms in terms of both accuracy and efficiency. Our results highlight the effectiveness of GCNIVC's GCN-assisted initialization and its edge-informed search strategy. This study not only advances the understanding of MVC problem-solving but also contributes a new tool for addressing large-scale graph optimization challenges.", 'abstract_zh': '基于图卷积网络的最小顶点覆盖新启发式搜索算法', 'title_zh': '基于GCN辅助启发式算法的最小顶点覆盖优化求解'}
{'arxiv_id': 'arXiv:2503.06395', 'title': 'Causal Discovery and Inference towards Urban Elements and Associated Factors', 'authors': 'Tao Feng, Yunke Zhang, Xiaochen Fan, Huandong Wang, Yong Li', 'link': 'https://arxiv.org/abs/2503.06395', 'abstract': "To uncover the city's fundamental functioning mechanisms, it is important to acquire a deep understanding of complicated relationships among citizens, location, and mobility behaviors. Previous research studies have applied direct correlation analysis to investigate such relationships. Nevertheless, due to the ubiquitous confounding effects, empirical correlation analysis may not accurately reflect underlying causal relationships among basic urban elements. In this paper, we propose a novel urban causal computing framework to comprehensively explore causalities and confounding effects among a variety of factors across different types of urban elements. In particular, we design a reinforcement learning algorithm to discover the potential causal graph, which depicts the causal relations between urban factors. The causal graph further serves as the guidance for estimating causal effects between pair-wise urban factors by propensity score matching. After removing the confounding effects from correlations, we leverage significance levels of causal effects in downstream urban mobility prediction tasks. Experimental studies on open-source urban datasets show that the discovered causal graph demonstrates a hierarchical structure, where citizens affect locations, and they both cause changes in urban mobility behaviors. Experimental results in urban mobility prediction tasks further show that the proposed method can effectively reduce confounding effects and enhance performance of urban computing tasks.", 'abstract_zh': '探索城市基本运作机制：一种新型城市因果计算框架及其应用', 'title_zh': '城市要素及其相关因素的因果发现与推断'}
{'arxiv_id': 'arXiv:2503.06378', 'title': 'General Scales Unlock AI Evaluation with Explanatory and Predictive Power', 'authors': 'Lexin Zhou, Lorenzo Pacchiardi, Fernando Martínez-Plumed, Katherine M. Collins, Yael Moros-Daval, Seraphina Zhang, Qinlin Zhao, Yitian Huang, Luning Sun, Jonathan E. Prunty, Zongqian Li, Pablo Sánchez-García, Kexin Jiang Chen, Pablo A. M. Casares, Jiyun Zu, John Burden, Behzad Mehrbakhsh, David Stillwell, Manuel Cebrian, Jindong Wang, Peter Henderson, Sherry Tongshuang Wu, Patrick C. Kyllonen, Lucy Cheke, Xing Xie, José Hernández-Orallo', 'link': 'https://arxiv.org/abs/2503.06378', 'abstract': 'Ensuring safe and effective use of AI requires understanding and anticipating its performance on novel tasks, from advanced scientific challenges to transformed workplace activities. So far, benchmarking has guided progress in AI, but it has offered limited explanatory and predictive power for general-purpose AI systems, given the low transferability across diverse tasks. In this paper, we introduce general scales for AI evaluation that can explain what common AI benchmarks really measure, extract ability profiles of AI systems, and predict their performance for new task instances, in- and out-of-distribution. Our fully-automated methodology builds on 18 newly-crafted rubrics that place instance demands on general scales that do not saturate. Illustrated for 15 large language models and 63 tasks, high explanatory power is unleashed from inspecting the demand and ability profiles, bringing insights on the sensitivity and specificity exhibited by different benchmarks, and how knowledge, metacognition and reasoning are affected by model size, chain-of-thought and distillation. Surprisingly, high predictive power at the instance level becomes possible using these demand levels, providing superior estimates over black-box baseline predictors based on embeddings or finetuning, especially in out-of-distribution settings (new tasks and new benchmarks). The scales, rubrics, battery, techniques and results presented here represent a major step for AI evaluation, underpinning the reliable deployment of AI in the years ahead.', 'abstract_zh': '确保人工智能的安全和有效使用需要理解并预见其在新颖任务上的表现，从高级科学挑战到重塑的工作场所活动。目前，基准测试已指导人工智能的进步，但对于通用人工智能系统，它提供的解释和预测能力有限，因为这些任务之间的可迁移性较低。在本文中，我们提出了通用的评估尺度，可以解释常见的AI基准检测到的内容，提取AI系统的能力特征，并预测其在新任务实例中的表现，包括分布内和分布外的情况。我们的全自动方法基于18个新设计的评分标准，这些标准不饱和且适用于通用尺度。通过15个大型语言模型和63个任务的举例说明，通过对需求和能力特征的检查，释放了高解释力，揭示了不同基准的敏感性和特异性，并探讨了模型大小、思维链和知识、元认知及推理能力在这些特征上的影响。令人惊讶的是，在实例级别使用这些需求水平可以实现高预测能力，这优于基于嵌入或微调的黑盒基准预测器，特别是在分布外场景下（新任务和新基准）。这里呈现的尺度、评分标准、题库、技术和结果代表了人工智能评估的一大步，支撑了未来几年中人工智能的可靠部署。', 'title_zh': '通用尺度解锁具有解释性和预测性力量的AI评估'}
{'arxiv_id': 'arXiv:2503.06323', 'title': 'Higher-Order Belief in Incomplete Information MAIDs', 'authors': 'Jack Foxabbott, Rohan Subramani, Francis Rhys Ward', 'link': 'https://arxiv.org/abs/2503.06323', 'abstract': "Multi-agent influence diagrams (MAIDs) are probabilistic graphical models which represent strategic interactions between agents. MAIDs are equivalent to extensive form games (EFGs) but have a more compact and informative structure. However, MAIDs cannot, in general, represent settings of incomplete information -- wherein agents have different beliefs about the game being played, and different beliefs about each-other's beliefs. In this paper, we introduce incomplete information MAIDs (II-MAIDs). We define both infinite and finite-depth II-MAIDs and prove an equivalence relation to EFGs with incomplete information and no common prior over types. We prove that II-MAIDs inherit classical equilibria concepts via this equivalence, but note that these solution concepts are often unrealistic in the setting with no common prior because they violate common knowledge of rationality. We define a more realistic solution concept based on recursive best-response. Throughout, we describe an example with a hypothetical AI agent undergoing evaluation to illustrate the applicability of II-MAIDs.", 'abstract_zh': '不完备信息多智能体影响图（II-MAIDs）', 'title_zh': '不完备信息条件下的高阶信念研究'}
{'arxiv_id': 'arXiv:2503.06242', 'title': 'LapSum -- One Method to Differentiate Them All: Ranking, Sorting and Top-k Selection', 'authors': 'Łukasz Struski, Michał B. Bednarczyk, Igor T. Podolak, Jacek Tabor', 'link': 'https://arxiv.org/abs/2503.06242', 'abstract': 'We present a novel technique for constructing differentiable order-type operations, including soft ranking, soft top-k selection, and soft permutations. Our approach leverages an efficient closed-form formula for the inverse of the function LapSum, defined as the sum of Laplace distributions. This formulation ensures low computational and memory complexity in selecting the highest activations, enabling losses and gradients to be computed in $O(n\\log{}n)$ time. Through extensive experiments, we demonstrate that our method outperforms state-of-the-art techniques for high-dimensional vectors and large $k$ values. Furthermore, we provide efficient implementations for both CPU and CUDA environments, underscoring the practicality and scalability of our method for large-scale ranking and differentiable ordering problems.', 'abstract_zh': '我们提出了一种新的技术，用于构建可微序型操作，包括软排名、软top-k选择和软排列。该方法利用了LapSum函数（定义为拉普拉斯分布之和）的逆函数的有效闭式公式。该公式确保在选择最高激活值时具有较低的计算和内存复杂度，使得损失和梯度的计算时间为$O(n\\log{}n)$。通过广泛的实验，我们证明了在高维向量和大k值情况下，我们的方法优于现有的先进技术。此外，我们提供了对CPU和CUDA环境的有效实现，突显了该方法在大规模排名和可微排序问题中的实用性和可扩展性。', 'title_zh': 'LapSum — 一种区分一切的方法：排名、排序和Top-k选择'}
{'arxiv_id': 'arXiv:2503.06202', 'title': 'Breaking Free from MMI: A New Frontier in Rationalization by Probing Input Utilization', 'authors': 'Wei Liu, Zhiying Deng, Zhongyu Niu, Jun Wang, Haozhao Wang, Zhigang Zeng, Ruixuan Li', 'link': 'https://arxiv.org/abs/2503.06202', 'abstract': 'Extracting a small subset of crucial rationales from the full input is a key problem in explainability research. The most widely used fundamental criterion for rationale extraction is the maximum mutual information (MMI) criterion. In this paper, we first demonstrate that MMI suffers from diminishing marginal returns. Once part of the rationale has been identified, finding the remaining portions contributes only marginally to increasing the mutual information, making it difficult to use MMI to locate the rest. In contrast to MMI that aims to reproduce the prediction, we seek to identify the parts of the input that the network can actually utilize.\nThis is achieved by comparing how different rationale candidates match the capability space of the weight matrix. The weight matrix of a neural network is typically low-rank, meaning that the linear combinations of its column vectors can only cover part of the directions in a high-dimensional space (high-dimension: the dimensions of an input vector). If an input is fully utilized by the network, {it generally matches these directions (e.g., a portion of a hypersphere), resulting in a representation with a high norm. Conversely, if an input primarily falls outside (orthogonal to) these directions}, its representation norm will approach zero, behaving like noise that the network cannot effectively utilize. Building on this, we propose using the norms of rationale candidates as an alternative objective to MMI. Through experiments on four text classification datasets and one graph classification dataset using three network architectures (GRUs, BERT, and GCN), we show that our method outperforms MMI and its improved variants in identifying better rationales. We also compare our method with a representative LLM (llama-3.1-8b-instruct) and find that our simple method gets comparable results to it and can sometimes even outperform it.', 'abstract_zh': '从全输入中提取关键解释的小子集是解释性研究中的一个关键问题。最常用的根本标准是最大互信息（MMI）准则。在本文中，我们首先证明MMI存在边际效益递减的现象。一旦部分解释被识别，找到剩余部分只会微不足道地增加互信息，使得使用MMI定位其余部分变得困难。与MMI旨在重现预测不同，我们寻求识别网络能够实际利用的输入部分。这通过比较不同解释候选与权重矩阵的能力空间匹配来实现。神经网络的权重矩阵通常具有低秩，意味着其列向量的线性组合只能覆盖高维空间（高维：输入向量的维度）的一部分方向。如果输入被网络充分利用，它通常匹配这些方向（例如，超球体的一部分），导致具有高模态的表现。反之，如果输入主要位于这些方向之外（正交），其表示模态将接近零，行为类似于网络无法有效利用的噪声。基于此，我们提出使用解释候选的模态作为MMI的替代目标。通过在四个文本分类数据集和一个图分类数据集上使用三种网络架构（GRUs、BERT和GCN）进行实验，我们证明我们的方法在识别更好的解释方面优于MMI及其改进变体。我们还将我们的方法与一个代表性的大语言模型（llama-3.1-8b-instruct）进行比较，发现我们的简单方法可以获得类似的结果，有时甚至可以优于它。', 'title_zh': '突破MMI束缚：通过探究输入利用的新理性化前沿'}
{'arxiv_id': 'arXiv:2503.06170', 'title': 'Object-Centric World Model for Language-Guided Manipulation', 'authors': 'Youngjoon Jeong, Junha Chun, Soonwoo Cha, Taesup Kim', 'link': 'https://arxiv.org/abs/2503.06170', 'abstract': 'A world model is essential for an agent to predict the future and plan in domains such as autonomous driving and robotics. To achieve this, recent advancements have focused on video generation, which has gained significant attention due to the impressive success of diffusion models. However, these models require substantial computational resources. To address these challenges, we propose a world model leveraging object-centric representation space using slot attention, guided by language instructions. Our model perceives the current state as an object-centric representation and predicts future states in this representation space conditioned on natural language instructions. This approach results in a more compact and computationally efficient model compared to diffusion-based generative alternatives. Furthermore, it flexibly predicts future states based on language instructions, and offers a significant advantage in manipulation tasks where object recognition is crucial. In this paper, we demonstrate that our latent predictive world model surpasses generative world models in visuo-linguo-motor control tasks, achieving superior sample and computation efficiency. We also investigate the generalization performance of the proposed method and explore various strategies for predicting actions using object-centric representations.', 'abstract_zh': '一种世界模型对于自主驾驶和机器人等领域中的代理预测未来并进行规划是必不可少的。为了实现这一目标，近期的研究重点集中在视频生成上，这得益于扩散模型取得了显著的成功。然而，这些模型需要大量的计算资源。为了解决这些问题，我们提出了一种利用对象中心表示空间的世界模型，该模型由语言指令引导，采用槽注意机制。我们的模型将当前状态视为对象中心的表示，并根据自然语言指令预测这种表示空间中的未来状态。这种方法相比于基于扩散的生成模型更加紧凑和计算效率高。此外，它可以根据语言指令灵活地预测未来状态，特别是在物体识别至关重要的操作任务中具有显著优势。在本文中，我们证明了我们提出的隐状态预测世界模型在视知觉-语言-动作控制任务中超越了生成世界模型，实现了更优的样本和计算效率。我们还研究了所提出方法的泛化性能，并探索了利用对象中心表示预测动作的各种策略。', 'title_zh': '基于对象中心的世界模型以语言引导操作'}
{'arxiv_id': 'arXiv:2503.06163', 'title': 'VACT: A Video Automatic Causal Testing System and a Benchmark', 'authors': 'Haotong Yang, Qingyuan Zheng, Yunjian Gao, Yongkun Yang, Yangbo He, Zhouchen Lin, Muhan Zhang', 'link': 'https://arxiv.org/abs/2503.06163', 'abstract': "With the rapid advancement of text-conditioned Video Generation Models (VGMs), the quality of generated videos has significantly improved, bringing these models closer to functioning as ``*world simulators*'' and making real-world-level video generation more accessible and cost-effective. However, the generated videos often contain factual inaccuracies and lack understanding of fundamental physical laws. While some previous studies have highlighted this issue in limited domains through manual analysis, a comprehensive solution has not yet been established, primarily due to the absence of a generalized, automated approach for modeling and assessing the causal reasoning of these models across diverse scenarios. To address this gap, we propose VACT: an **automated** framework for modeling, evaluating, and measuring the causal understanding of VGMs in real-world scenarios. By combining causal analysis techniques with a carefully designed large language model assistant, our system can assess the causal behavior of models in various contexts without human annotation, which offers strong generalization and scalability. Additionally, we introduce multi-level causal evaluation metrics to provide a detailed analysis of the causal performance of VGMs. As a demonstration, we use our framework to benchmark several prevailing VGMs, offering insight into their causal reasoning capabilities. Our work lays the foundation for systematically addressing the causal understanding deficiencies in VGMs and contributes to advancing their reliability and real-world applicability.", 'abstract_zh': '基于文本条件的视频生成模型（VGMs）因果理解的自动化评估框架：VACT', 'title_zh': 'VACT: 一种视频自动因果测试系统及基准'}
{'arxiv_id': 'arXiv:2503.06138', 'title': 'System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems', 'authors': 'Tadahiro Taniguchi, Yasushi Hirai, Masahiro Suzuki, Shingo Murata, Takato Horii, Kazutoshi Tanaka', 'link': 'https://arxiv.org/abs/2503.06138', 'abstract': "This paper introduces the System 0/1/2/3 framework as an extension of dual-process theory, employing a quad-process model of cognition. Expanding upon System 1 (fast, intuitive thinking) and System 2 (slow, deliberative thinking), we incorporate System 0, which represents pre-cognitive embodied processes, and System 3, which encompasses collective intelligence and symbol emergence. We contextualize this model within Bergson's philosophy by adopting multi-scale time theory to unify the diverse temporal dynamics of cognition. System 0 emphasizes morphological computation and passive dynamics, illustrating how physical embodiment enables adaptive behavior without explicit neural processing. Systems 1 and 2 are explained from a constructive perspective, incorporating neurodynamical and AI viewpoints. In System 3, we introduce collective predictive coding to explain how societal-level adaptation and symbol emergence operate over extended timescales. This comprehensive framework ranges from rapid embodied reactions to slow-evolving collective intelligence, offering a unified perspective on cognition across multiple timescales, levels of abstraction, and forms of human intelligence. The System 0/1/2/3 model provides a novel theoretical foundation for understanding the interplay between adaptive and cognitive processes, thereby opening new avenues for research in cognitive science, AI, robotics, and collective intelligence.", 'abstract_zh': 'System 0/1/2/3框架：一种扩展的认知双过程理论的四过程模型', 'title_zh': '系统0/1/2/3：多时标 embodied集体认知系统四过程理论'}
{'arxiv_id': 'arXiv:2503.06059', 'title': 'MANDARIN: Mixture-of-Experts Framework for Dynamic Delirium and Coma Prediction in ICU Patients: Development and Validation of an Acute Brain Dysfunction Prediction Model', 'authors': 'Miguel Contreras, Jessica Sena, Andrea Davidson, Jiaqing Zhang, Tezcan Ozrazgat-Baslanti, Yuanfang Ren, Ziyuan Guan, Jeremy Balch, Tyler Loftus, Subhash Nerella, Azra Bihorac, Parisa Rashidi', 'link': 'https://arxiv.org/abs/2503.06059', 'abstract': 'Acute brain dysfunction (ABD) is a common, severe ICU complication, presenting as delirium or coma and leading to prolonged stays, increased mortality, and cognitive decline. Traditional screening tools like the Glasgow Coma Scale (GCS), Confusion Assessment Method (CAM), and Richmond Agitation-Sedation Scale (RASS) rely on intermittent assessments, causing delays and inconsistencies. In this study, we propose MANDARIN (Mixture-of-Experts Framework for Dynamic Delirium and Coma Prediction in ICU Patients), a 1.5M-parameter mixture-of-experts neural network to predict ABD in real-time among ICU patients. The model integrates temporal and static data from the ICU to predict the brain status in the next 12 to 72 hours, using a multi-branch approach to account for current brain status. The MANDARIN model was trained on data from 92,734 patients (132,997 ICU admissions) from 2 hospitals between 2008-2019 and validated externally on data from 11,719 patients (14,519 ICU admissions) from 15 hospitals and prospectively on data from 304 patients (503 ICU admissions) from one hospital in 2021-2024. Three datasets were used: the University of Florida Health (UFH) dataset, the electronic ICU Collaborative Research Database (eICU), and the Medical Information Mart for Intensive Care (MIMIC)-IV dataset. MANDARIN significantly outperforms the baseline neurological assessment scores (GCS, CAM, and RASS) for delirium prediction in both external (AUROC 75.5% CI: 74.2%-76.8% vs 68.3% CI: 66.9%-69.5%) and prospective (AUROC 82.0% CI: 74.8%-89.2% vs 72.7% CI: 65.5%-81.0%) cohorts, as well as for coma prediction (external AUROC 87.3% CI: 85.9%-89.0% vs 72.8% CI: 70.6%-74.9%, and prospective AUROC 93.4% CI: 88.5%-97.9% vs 67.7% CI: 57.7%-76.8%) with a 12-hour lead time. This tool has the potential to assist clinicians in decision-making by continuously monitoring the brain status of patients in the ICU.', 'abstract_zh': '急性脑功能障碍的MANDARIN模型：一种用于ICU患者实时预测的混合专家框架', 'title_zh': 'MANDARIN：混合专家框架在ICU患者谵妄和昏迷动态预测中的应用：急性脑功能障碍预测模型的开发与验证'}
{'arxiv_id': 'arXiv:2503.06047', 'title': 'DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments', 'authors': 'Wenjie Tang, Yuan Zhou, Erqiang Xu, Keyan Cheng, Minne Li, Liquan Xiao', 'link': 'https://arxiv.org/abs/2503.06047', 'abstract': 'Large Language Model~(LLM) based agents have been increasingly popular in solving complex and dynamic tasks, which requires proper evaluation systems to assess their capabilities. Nevertheless, existing benchmarks usually either focus on single-objective tasks or use overly broad assessing metrics, failing to provide a comprehensive inspection of the actual capabilities of LLM-based agents in complicated decision-making tasks. To address these issues, we introduce DSGBench, a more rigorous evaluation platform for strategic decision-making. Firstly, it incorporates six complex strategic games which serve as ideal testbeds due to their long-term and multi-dimensional decision-making demands and flexibility in customizing tasks of various difficulty levels or multiple targets. Secondly, DSGBench employs a fine-grained evaluation scoring system which examines the decision-making capabilities by looking into the performance in five specific dimensions and offering a comprehensive assessment in a well-designed way. Furthermore, DSGBench also incorporates an automated decision-tracking mechanism which enables in-depth analysis of agent behaviour patterns and the changes in their strategies. We demonstrate the advances of DSGBench by applying it to multiple popular LLM-based agents and our results suggest that DSGBench provides valuable insights in choosing LLM-based agents as well as improving their future development. DSGBench is available at this https URL.', 'abstract_zh': '基于大型语言模型的代理在解决复杂动态任务方面的评估：DSGBench——一种更为严格的战略性决策评估平台', 'title_zh': 'DSGBench：一种用于评估基于LLM的代理在复杂决策环境中的多样性战略博弈基准'}
{'arxiv_id': 'arXiv:2503.06027', 'title': 'Empowering Edge Intelligence: A Comprehensive Survey on On-Device AI Models', 'authors': 'Xubin Wang, Zhiqing Tang, Jianxiong Guo, Tianhui Meng, Chenhao Wang, Tian Wang, Weijia Jia', 'link': 'https://arxiv.org/abs/2503.06027', 'abstract': 'The rapid advancement of artificial intelligence (AI) technologies has led to an increasing deployment of AI models on edge and terminal devices, driven by the proliferation of the Internet of Things (IoT) and the need for real-time data processing. This survey comprehensively explores the current state, technical challenges, and future trends of on-device AI models. We define on-device AI models as those designed to perform local data processing and inference, emphasizing their characteristics such as real-time performance, resource constraints, and enhanced data privacy. The survey is structured around key themes, including the fundamental concepts of AI models, application scenarios across various domains, and the technical challenges faced in edge environments. We also discuss optimization and implementation strategies, such as data preprocessing, model compression, and hardware acceleration, which are essential for effective deployment. Furthermore, we examine the impact of emerging technologies, including edge computing and foundation models, on the evolution of on-device AI models. By providing a structured overview of the challenges, solutions, and future directions, this survey aims to facilitate further research and application of on-device AI, ultimately contributing to the advancement of intelligent systems in everyday life.', 'abstract_zh': '人工智能技术的飞速发展推动了边缘和终端设备上AI模型的部署，这主要是由于物联网的普及和实时数据处理的需求。本文综述了设备上AI模型的当前状态、技术挑战及未来趋势。我们将设备上AI模型定义为用于进行本地数据处理和推理的模型，强调其实时性能、资源限制和增强的数据隐私等特性。本文围绕关键主题展开，包括AI模型的基本概念、跨领域应用场景以及边缘环境中的技术挑战。我们还讨论了优化和实现策略，如数据预处理、模型压缩和硬件加速，这些对于有效的部署至关重要。此外，我们探讨了边缘计算和基础模型等新兴技术对设备上AI模型演进的影响。通过提供对挑战、解决方案及未来方向的结构化概述，本文旨在促进设备上AI的进一步研究和应用，最终推动智能系统的进步。', 'title_zh': '赋能边缘智能：基于设备的AI模型综述'}
{'arxiv_id': 'arXiv:2503.05963', 'title': 'Bayesian Graph Traversal', 'authors': 'William N. Caballero, Phillip R. Jenkins, David Banks, Matthew Robbins', 'link': 'https://arxiv.org/abs/2503.05963', 'abstract': "This research considers Bayesian decision-analytic approaches toward the traversal of an uncertain graph. Namely, a traveler progresses over a graph in which rewards are gained upon a node's first visit and costs are incurred for every edge traversal. The traveler knows the graph's adjacency matrix and his starting position but does not know the rewards and costs. The traveler is a Bayesian who encodes his beliefs about these values using a Gaussian process prior and who seeks to maximize his expected utility over these beliefs. Adopting a decision-analytic perspective, we develop sequential decision-making solution strategies for this coupled information-collection and network-routing problem. We show that the problem is NP-Hard and derive properties of the optimal walk. These properties provide heuristics for the traveler's problem that balance exploration and exploitation. We provide a practical case study focused on the use of unmanned aerial systems for public safety and empirically study policy performance in myriad Erdos-Renyi settings.", 'abstract_zh': '本研究考虑了面向不确定图的遍历的贝叶斯决策分析方法。旅行者在一张图上行进，首次访问节点可获得奖励，每通过一条边需支付成本。旅行者只知道图的邻接矩阵和起始位置，但不知道奖励和成本的具体数值。旅行者采用贝叶斯方法，通过高斯过程先验来编码他对这些值的信念，并力求在其信念上最大化其预期效用。从决策分析的角度出发，我们开发了针对这一信息收集与网络路径规划问题的序贯决策制定解决方案。我们证明了该问题是NP难问题，并推导出了最优路径的性质。这些性质为旅行者的决策提供了平衡探索与利用的启发式方法。我们提供了一个实际案例研究，关注无人驾驶航空系统在公共安全中的应用，并在众多的Erdos-Renyi设置下实证研究了策略性能。', 'title_zh': '贝叶斯图遍历'}
{'arxiv_id': 'arXiv:2503.05944', 'title': 'Enhancing Reasoning with Collaboration and Memory', 'authors': 'Julie Michelman, Nasrin Baratalipour, Matthew Abueg', 'link': 'https://arxiv.org/abs/2503.05944', 'abstract': 'We envision a continuous collaborative learning system where groups of LLM agents work together to solve reasoning problems, drawing on memory they collectively build to improve performance as they gain experience. This work establishes the foundations for such a system by studying the interoperability of chain-of-thought reasoning styles, multi-agent collaboration, and memory banks. Extending beyond the identical agents of self-consistency, we introduce varied-context agents with diverse exemplars and a summarizer agent in place of voting. We generate frozen and continuously learned memory banks of exemplars and pair them with fixed, random, and similarity-based retrieval mechanisms. Our systematic study reveals where various methods contribute to reasoning performance of two LLMs on three grounded reasoning tasks, showing that random exemplar selection can often beat more principled approaches, and in some tasks, inclusion of any exemplars serves only to distract both weak and strong models.', 'abstract_zh': '设想一个连续协作学习系统，多组语言模型代理共同解决推理问题，借鉴他们集体构建的记忆，随着经验的积累提升性能。本研究通过研究链式思考推理风格、多智能体协作和记忆库的互操作性，奠定了此类系统的基础。扩展超越自一致性中的相同代理，我们引入了具有多样化范例的上下文变化代理，并用总结器代理取代投票机制。我们生成了冻结和持续学习的范例记忆库，并与固定、随机和基于相似性的检索机制配对。我们的系统性研究揭示了在三个具体推理任务中，各种方法如何影响两个语言模型的推理性能，表明随机范例选择往往能超越更严谨的方法，并且在某些任务中，任何范例的存在可能会分散弱模型和强模型的注意力。', 'title_zh': '增强推理能力：协作与记忆的结合'}
{'arxiv_id': 'arXiv:2503.05859', 'title': 'Quantum-like cognition and decision making in the light of quantum measurement theory', 'authors': 'Miho Fuyama, Andrei Khrennikov, Masanao Ozawa', 'link': 'https://arxiv.org/abs/2503.05859', 'abstract': "We characterize the class of quantum measurements that matches the applications of quantum theory to cognition (and decision making) - quantum-like modeling. Projective measurements describe the canonical measurements of the basic observables of quantum physics. However, the combinations of the basic cognitive effects, such as the question order and response replicability effects, cannot be described by projective measurements. We motivate the use of the special class of quantum measurements, namely {\\it sharp repeatable non-projective measurements} - ${\\cal SR\\bar{P}}. $ This class is practically unused in quantum physics. Thus, physics and cognition explore different parts of quantum measurement theory. Quantum-like modeling isn't automatic borrowing of the quantum formalism. Exploring the class ${\\cal SR\\bar{P}}$ highlights the role of {\\it noncommutativity of the state update maps generated by measurement back action.} Thus, ``non-classicality'' in quantum physics as well as quantum-like modeling for cognition is based on two different types of noncommutativity, of operators (observables) and instruments (state update maps): {\\it observable-noncommutativity} vs. {\\it state update-noncommutativity}. We speculate that distinguishing quantum-like properties of the cognitive effects are the expressions of the latter, or possibly both.", 'abstract_zh': '量子测量分类及其在认知（决策）中的应用：基于非幺正可重复测量的量子似模型研究', 'title_zh': '基于量子测量理论视角下的 Quantum-like 认知与决策'}
{'arxiv_id': 'arXiv:2503.05828', 'title': 'Market-based Architectures in RL and Beyond', 'authors': 'Abhimanyu Pallavi Sudhir, Long Tran-Thanh', 'link': 'https://arxiv.org/abs/2503.05828', 'abstract': "Market-based agents refer to reinforcement learning agents which determine their actions based on an internal market of sub-agents. We introduce a new type of market-based algorithm where the state itself is factored into several axes called ``goods'', which allows for greater specialization and parallelism than existing market-based RL algorithms. Furthermore, we argue that market-based algorithms have the potential to address many current challenges in AI, such as search, dynamic scaling and complete feedback, and demonstrate that they may be seen to generalize neural networks; finally, we list some novel ways that market algorithms may be applied in conjunction with Large Language Models for immediate practical applicability.", 'abstract_zh': '基于市场的智能体：一种将状态分解为多个“商品”轴的新型市场机制强化学习算法及其应用', 'title_zh': '基于市场的架构在RL及更广泛的领域'}
{'arxiv_id': 'arXiv:2503.05808', 'title': 'DriveGen: Towards Infinite Diverse Traffic Scenarios with Large Models', 'authors': 'Shenyu Zhang, Jiaguo Tian, Zhengbang Zhu, Shan Huang, Jucheng Yang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2503.05808', 'abstract': "Microscopic traffic simulation has become an important tool for autonomous driving training and testing. Although recent data-driven approaches advance realistic behavior generation, their learning still relies primarily on a single real-world dataset, which limits their diversity and thereby hinders downstream algorithm optimization. In this paper, we propose DriveGen, a novel traffic simulation framework with large models for more diverse traffic generation that supports further customized designs. DriveGen consists of two internal stages: the initialization stage uses large language model and retrieval technique to generate map and vehicle assets; the rollout stage outputs trajectories with selected waypoint goals from visual language model and a specific designed diffusion planner. Through this two-staged process, DriveGen fully utilizes large models' high-level cognition and reasoning of driving behavior, obtaining greater diversity beyond datasets while maintaining high realism. To support effective downstream optimization, we additionally develop DriveGen-CS, an automatic corner case generation pipeline that uses failures of the driving algorithm as additional prompt knowledge for large models without the need for retraining or fine-tuning. Experiments show that our generated scenarios and corner cases have a superior performance compared to state-of-the-art baselines. Downstream experiments further verify that the synthesized traffic of DriveGen provides better optimization of the performance of typical driving algorithms, demonstrating the effectiveness of our framework.", 'abstract_zh': '一种用于多样化交通生成的大模型驱动的行驶模拟框架DriveGen', 'title_zh': 'DriveGen: 向无尽多样的交通场景进发——借助大规模模型'}
{'arxiv_id': 'arXiv:2503.05702', 'title': 'A Comprehensive Survey of Fuzzy Implication Functions', 'authors': 'Raquel Fernandez-Peralta', 'link': 'https://arxiv.org/abs/2503.05702', 'abstract': 'Fuzzy implication functions are a key area of study in fuzzy logic, extending the classical logical conditional to handle truth degrees in the interval $[0,1]$. While existing literature often focuses on a limited number of families, in the last ten years many new families have been introduced, each defined by specific construction methods and having different key properties. This survey aims to provide a comprehensive and structured overview of the diverse families of fuzzy implication functions, emphasizing their motivations, properties, and potential applications. By organizing the information schematically, this document serves as a valuable resource for both theoretical researchers seeking to avoid redundancy and practitioners looking to select appropriate operators for specific applications.', 'abstract_zh': '模糊蕴含函数是模糊逻辑中的一个关键研究领域，扩展了经典的逻辑条件以处理区间$[0,1]$内的真度。尽管现有文献通常集中于少数几类，但在过去的十年里，引入了很多新的家庭，每种家庭都由特定的构造方法定义并具有不同的关键属性。本文综述旨在提供对多样化模糊蕴含函数家庭的全面和结构化的概述，强调它们的动机、属性和潜在应用。通过方案化地组织信息，本文文件既是对理论研究人员避免冗余的宝贵资源，也是对实践者为特定应用选择合适运算符的指导。', 'title_zh': '模糊蕴含函数综述'}
{'arxiv_id': 'arXiv:2503.07599', 'title': 'NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences', 'authors': 'Dünya Baradari, Nataliya Kosmyna, Oscar Petrov, Rebecah Kaplun, Pattie Maes', 'link': 'https://arxiv.org/abs/2503.07599', 'abstract': "Generative AI is transforming education by enabling personalized, on-demand learning experiences. However, AI tutors lack the ability to assess a learner's cognitive state in real time, limiting their adaptability. Meanwhile, electroencephalography (EEG)-based neuroadaptive systems have successfully enhanced engagement by dynamically adjusting learning content. This paper presents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates real-time EEG-based engagement tracking with generative AI. NeuroChat continuously monitors a learner's cognitive engagement and dynamically adjusts content complexity, response style, and pacing using a closed-loop system. We evaluate this approach in a pilot study (n=24), comparing NeuroChat to a standard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive and subjective engagement but does not show an immediate effect on learning outcomes. These findings demonstrate the feasibility of real-time cognitive feedback in LLMs, highlighting new directions for adaptive learning, AI tutoring, and human-AI interaction.", 'abstract_zh': '生成式AI正在通过提供个性化和按需的学习体验来变革教育。然而，AI辅导缺乏实时评估学习者认知状态的能力，限制了其适应性。与此同时，基于脑电图（EEG）的神经自适应系统通过动态调整学习内容成功地提升了学习者的参与度。本文提出了一种概念验证的神经自适应AI辅导系统——NeuroChat，它将实时EEG基参与度跟踪与生成式AI相结合。NeuroChat持续监测学习者的认知参与度，并通过闭环系统动态调整内容复杂性、回应风格和进度。我们在一项初步研究（n=24）中评估了这种方法，将NeuroChat与基于标准大型语言模型的聊天机器人进行比较。结果表明，NeuroChat提高了认知参与度和主观参与度，但对学习成果没有立即影响。这些发现展示了实时认知反馈在大型语言模型中的可行性，突显了适应性学习、AI辅导和人机交互的新方向。', 'title_zh': '神经聊友：一种神经自适应人工智能聊天机器人，用于个性化学习体验'}
{'arxiv_id': 'arXiv:2503.07596', 'title': 'Denoising Hamiltonian Network for Physical Reasoning', 'authors': 'Congyue Deng, Brandon Y. Feng, Cecilia Garraffo, Alan Garbarz, Robin Walters, William T. Freeman, Leonidas Guibas, Kaiming He', 'link': 'https://arxiv.org/abs/2503.07596', 'abstract': 'Machine learning frameworks for physical problems must capture and enforce physical constraints that preserve the structure of dynamical systems. Many existing approaches achieve this by integrating physical operators into neural networks. While these methods offer theoretical guarantees, they face two key limitations: (i) they primarily model local relations between adjacent time steps, overlooking longer-range or higher-level physical interactions, and (ii) they focus on forward simulation while neglecting broader physical reasoning tasks. We propose the Denoising Hamiltonian Network (DHN), a novel framework that generalizes Hamiltonian mechanics operators into more flexible neural operators. DHN captures non-local temporal relationships and mitigates numerical integration errors through a denoising mechanism. DHN also supports multi-system modeling with a global conditioning mechanism. We demonstrate its effectiveness and flexibility across three diverse physical reasoning tasks with distinct inputs and outputs.', 'abstract_zh': '物理问题中的机器学习框架必须捕获并执行物理约束以保持动态系统的结构。许多现有方法通过将物理运算符集成到神经网络中来实现这一目标。虽然这些方法具有理论保证，但它们面临着两个关键限制：（i）它们主要建模相邻时间步之间的局部关系，忽略了更长范围或更高层次的物理交互；（ii）它们专注于正向仿真，忽视了更广泛的物理推理任务。我们提出了一种新颖的框架去噪哈密顿网络（Denoising Hamiltonian Network, DHN），该框架将哈密顿力学运算符泛化为更灵活的神经运算符。DHN 捕捉非局部时间关系并通过去噪机制减轻数值积分误差。DHN 还通过全局条件机制支持多系统建模。我们通过三个具有不同输入和输出的物理推理任务展示了其有效性和灵活性。', 'title_zh': 'Hamiltonian网络去噪方法用于物理推理'}
{'arxiv_id': 'arXiv:2503.07591', 'title': 'Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning', 'authors': 'Bardia Safaei, Faizan Siddiqui, Jiacong Xu, Vishal M. Patel, Shao-Yuan Lo', 'link': 'https://arxiv.org/abs/2503.07591', 'abstract': 'Visual instruction tuning (VIT) for large vision-language models (LVLMs) requires training on expansive datasets of image-instruction pairs, which can be costly. Recent efforts in VIT data selection aim to select a small subset of high-quality image-instruction pairs, reducing VIT runtime while maintaining performance comparable to full-scale training. However, a major challenge often overlooked is that generating instructions from unlabeled images for VIT is highly expensive. Most existing VIT datasets rely heavily on human annotations or paid services like the GPT API, which limits users with constrained resources from creating VIT datasets for custom applications. To address this, we introduce Pre-Instruction Data Selection (PreSel), a more practical data selection paradigm that directly selects the most beneficial unlabeled images and generates instructions only for the selected images. PreSel first estimates the relative importance of each vision task within VIT datasets to derive task-wise sampling budgets. It then clusters image features within each task, selecting the most representative images with the budget. This approach reduces computational overhead for both instruction generation during VIT data formation and LVLM fine-tuning. By generating instructions for only 15% of the images, PreSel achieves performance comparable to full-data VIT on the LLaVA-1.5 and Vision-Flan datasets. The link to our project page: this https URL', 'abstract_zh': '预指令数据选择（PreSel）：一种用于大规模视觉-语言模型（LVLMs）的视觉指令调优（VIT）的数据选择范式', 'title_zh': '先过滤图片，后生成指令：预指令数据选择方法用于视觉指令调优'}
{'arxiv_id': 'arXiv:2503.07588', 'title': 'When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning', 'authors': 'Junwei Luo, Yingying Zhang, Xue Yang, Kang Wu, Qi Zhu, Lei Liang, Jingdong Chen, Yansheng Li', 'link': 'https://arxiv.org/abs/2503.07588', 'abstract': "Efficient vision-language understanding of large Remote Sensing Images (RSIs) is meaningful but challenging. Current Large Vision-Language Models (LVLMs) typically employ limited pre-defined grids to process images, leading to information loss when handling gigapixel RSIs. Conversely, using unlimited grids significantly increases computational costs. To preserve image details while reducing computational complexity, we propose a text-guided token pruning method with Dynamic Image Pyramid (DIP) integration. Our method introduces: (i) a Region Focus Module (RFM) that leverages text-aware region localization capability to identify critical vision tokens, and (ii) a coarse-to-fine image tile selection and vision token pruning strategy based on DIP, which is guided by RFM outputs and avoids directly processing the entire large imagery. Additionally, existing benchmarks for evaluating LVLMs' perception ability on large RSI suffer from limited question diversity and constrained image sizes. We construct a new benchmark named LRS-VQA, which contains 7,333 QA pairs across 8 categories, with image length up to 27,328 pixels. Our method outperforms existing high-resolution strategies on four datasets using the same data. Moreover, compared to existing token reduction methods, our approach demonstrates higher efficiency under high-resolution settings. Dataset and code are in this https URL.", 'abstract_zh': '高效处理大型遥感图像的视觉语言理解具有重要意义但挑战重重。当前大型视觉语言模型 typically 采用有限的预定义网格来处理图像，导致在处理 gigapixel 遥感图像时信息丢失。相反，使用无限的网格会显著增加计算成本。为了在保留图像细节的同时减少计算复杂度，我们提出了一种结合动态图像金字塔 (DIP) 的文本引导 token 剪枝方法。该方法引入了：(i) 区域聚焦模块 (RFM)，利用文本感知区域定位能力来识别关键的视觉 token；(ii) 一种基于 DIP 的粗到细图像瓷砖选择和视觉 token 剪枝策略，该策略由 RFM 输出引导，并避免直接处理整个大型图像。此外，现有用于评估 LVLMs 在大型遥感图像上感知能力的基准测试在问题多样性有限和图像尺寸受限方面存在不足。我们构建了一个名为 LRS-VQA 的新基准，包含 7,333 个 QA 对，涵盖 8 个类别，图像长度最多为 27,328 像素。我们的方法在四个数据集上使用相同数据优于现有的高分辨率策略。此外，在高分辨率设置下，与现有的 token 减少方法相比，我们的方法显示出更高的效率。数据集和代码在此 https URL。', 'title_zh': '当大规模视觉-语言模型遇到大规模遥感图像：细粒度文本引导的令牌修剪'}
{'arxiv_id': 'arXiv:2503.07587', 'title': 'Robusto-1 Dataset: Comparing Humans and VLMs on real out-of-distribution Autonomous Driving VQA from Peru', 'authors': 'Dunant Cusipuma, David Ortega, Victor Flores-Benites, Arturo Deza', 'link': 'https://arxiv.org/abs/2503.07587', 'abstract': 'As multimodal foundational models start being deployed experimentally in Self-Driving cars, a reasonable question we ask ourselves is how similar to humans do these systems respond in certain driving situations -- especially those that are out-of-distribution? To study this, we create the Robusto-1 dataset that uses dashcam video data from Peru, a country with one of the worst (aggressive) drivers in the world, a high traffic index, and a high ratio of bizarre to non-bizarre street objects likely never seen in training. In particular, to preliminarly test at a cognitive level how well Foundational Visual Language Models (VLMs) compare to Humans in Driving, we move away from bounding boxes, segmentation maps, occupancy maps or trajectory estimation to multi-modal Visual Question Answering (VQA) comparing both humans and machines through a popular method in systems neuroscience known as Representational Similarity Analysis (RSA). Depending on the type of questions we ask and the answers these systems give, we will show in what cases do VLMs and Humans converge or diverge allowing us to probe on their cognitive alignment. We find that the degree of alignment varies significantly depending on the type of questions asked to each type of system (Humans vs VLMs), highlighting a gap in their alignment.', 'abstract_zh': '多模态基础模型在自动驾驶汽车中的实验部署引发了我们对这些系统在某些驾驶情况下的响应与人类相似性如何的思考，尤其是在这些情况超出了训练分布的情况下。为研究这一问题，我们创建了Robusto-1数据集，该数据集使用了秘鲁的车载摄像头视频数据，秘鲁是世界上驾驶行为最为激进的国家之一，交通密度高，并且街景物体中非常规物体的比例很高，这些物体在训练中可能从未出现过。通过对代表性脑成像方法——表示相似性分析(RSA)来比较基础视觉语言模型(VLMs)和人类在多模态视觉问答(VQA)中的表现，我们初步探讨了基础视觉语言模型在认知层面上如何与人类进行比较。通过提问不同类型的问题并分析这些系统给出的回答，我们将展示VLMs和人类在哪些情况下一致或相异，从而揭示他们在认知上的对齐程度。我们发现，不同类型的系统（人类 vs VLMs）对不同类型问题的回答程度存在显著差异，这揭示了它们之间认知对齐的差距。', 'title_zh': 'Robusto-1数据集：比较人类和大规模语言模型在来自秘鲁的实际分布外自主驾驶VQA中的表现'}
{'arxiv_id': 'arXiv:2503.07578', 'title': 'Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation', 'authors': 'Tianyu Chen, Yasi Zhang, Zhendong Wang, Ying Nian Wu, Oscar Leong, Mingyuan Zhou', 'link': 'https://arxiv.org/abs/2503.07578', 'abstract': 'Diffusion models have achieved remarkable success in generating high-resolution, realistic images across diverse natural distributions. However, their performance heavily relies on high-quality training data, making it challenging to learn meaningful distributions from corrupted samples. This limitation restricts their applicability in scientific domains where clean data is scarce or costly to obtain. In this work, we introduce denoising score distillation (DSD), a surprisingly effective and novel approach for training high-quality generative models from low-quality data. DSD first pretrains a diffusion model exclusively on noisy, corrupted samples and then distills it into a one-step generator capable of producing refined, clean outputs. While score distillation is traditionally viewed as a method to accelerate diffusion models, we show that it can also significantly enhance sample quality, particularly when starting from a degraded teacher model. Across varying noise levels and datasets, DSD consistently improves generative performancewe summarize our empirical evidence in Fig. 1. Furthermore, we provide theoretical insights showing that, in a linear model setting, DSD identifies the eigenspace of the clean data distributions covariance matrix, implicitly regularizing the generator. This perspective reframes score distillation as not only a tool for efficiency but also a mechanism for improving generative models, particularly in low-quality data settings.', 'abstract_zh': '基于去噪得分蒸馏的高质量生成模型训练方法', 'title_zh': '去噪得分蒸馏：从有噪声的扩散预训练到一步生成高质输出'}
{'arxiv_id': 'arXiv:2503.07572', 'title': 'Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning', 'authors': 'Yuxiao Qu, Matthew Y. R. Yang, Amrith Setlur, Lewis Tunstall, Edward Emanuel Beeching, Ruslan Salakhutdinov, Aviral Kumar', 'link': 'https://arxiv.org/abs/2503.07572', 'abstract': "Training models to effectively use test-time compute is crucial for improving the reasoning performance of LLMs. Current methods mostly do so via fine-tuning on search traces or running RL with 0/1 outcome reward, but do these approaches efficiently utilize test-time compute? Would these approaches continue to scale as the budget improves? In this paper, we try to answer these questions. We formalize the problem of optimizing test-time compute as a meta-reinforcement learning (RL) problem, which provides a principled perspective on spending test-time compute. This perspective enables us to view the long output stream from the LLM as consisting of several episodes run at test time and leads us to use a notion of cumulative regret over output tokens as a way to measure the efficacy of test-time compute. Akin to how RL algorithms can best tradeoff exploration and exploitation over training, minimizing cumulative regret would also provide the best balance between exploration and exploitation in the token stream. While we show that state-of-the-art models do not minimize regret, one can do so by maximizing a dense reward bonus in conjunction with the outcome 0/1 reward RL. This bonus is the ''progress'' made by each subsequent block in the output stream, quantified by the change in the likelihood of eventual success. Using these insights, we develop Meta Reinforcement Fine-Tuning, or MRT, a new class of fine-tuning methods for optimizing test-time compute. MRT leads to a 2-3x relative gain in performance and roughly a 1.5x gain in token efficiency for math reasoning compared to outcome-reward RL.", 'abstract_zh': '训练模型有效利用测试时计算对于提升大型语言模型的推理性能至关重要。当前方法主要通过在搜索轨迹上进行微调或使用0/1结果奖励进行强化学习来实现这一目标，但这些方法是否高效利用了测试时计算?在预算提高时，这些方法能否继续扩展?在本文中，我们试图回答这些问题。我们将优化测试时计算的问题形式化为元强化学习问题，从而从原则上解决了测试时计算的使用问题。这一视角使得我们将LLM的长输出流视为在测试时间内运行的多个episode，并提出了一种累积悔恨的概念，作为衡量测试时计算效果的方式。类似于如何在训练过程中通过RL算法权衡探索与利用，最小化累积悔恨也会在文本流中提供最佳的探索与利用权衡。尽管我们发现最先进的模型并未最小化悔恨，但可以通过与0/1结果奖励RL结合使用密集奖励 bonus 来实现这一目标。这一 bonus 是每个后续输出块相对于最终成功概率的增进量。基于这些洞察，我们开发了元强化学习微调（MRT），这是一种新的优化测试时计算的微调方法。与结果奖励 RL 相比，MRT 在数学推理任务中分别实现了约2-3倍的性能提升和约1.5倍的 tokens 效率提升。', 'title_zh': '通过元强化微调优化测试时计算'}
{'arxiv_id': 'arXiv:2503.07568', 'title': 'Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters', 'authors': 'Habibur Rahaman, Atri Chatterjee, Swarup Bhunia', 'link': 'https://arxiv.org/abs/2503.07568', 'abstract': 'Rapid adoption of AI technologies raises several major security concerns, including the risks of adversarial perturbations, which threaten the confidentiality and integrity of AI applications. Protecting AI hardware from misuse and diverse security threats is a challenging task. To address this challenge, we propose SAMURAI, a novel framework for safeguarding against malicious usage of AI hardware and its resilience to attacks. SAMURAI introduces an AI Performance Counter (APC) for tracking dynamic behavior of an AI model coupled with an on-chip Machine Learning (ML) analysis engine, known as TANTO (Trained Anomaly Inspection Through Trace Observation). APC records the runtime profile of the low-level hardware events of different AI operations. Subsequently, the summary information recorded by the APC is processed by TANTO to efficiently identify potential security breaches and ensure secure, responsible use of AI. SAMURAI enables real-time detection of security threats and misuse without relying on traditional software-based solutions that require model integration. Experimental results demonstrate that SAMURAI achieves up to 97% accuracy in detecting adversarial attacks with moderate overhead on various AI models, significantly outperforming conventional software-based approaches. It enhances security and regulatory compliance, providing a comprehensive solution for safeguarding AI against emergent threats.', 'abstract_zh': '快速adopt AI技术引发了一系列重大安全 concern，包括对抗性 perturbations 的风险，这些风险威胁到AI应用的保密性和完整性。保护AI硬件免受滥用和各种安全威胁是一项具有挑战性的任务。为应对这一挑战，我们提出了SAMURAI，一种新型框架，旨在保护AI硬件免受恶意使用，并增强其对攻击的 resilience。SAMURAI引入了一个AI性能计数器（APC）来跟踪不同AI操作的动态行为，并结合了一个嵌入式机器学习（ML）分析引擎，称为TANTO（通过跟踪观察训练异常）。APC记录了不同AI操作的低级硬件事件的运行时配置文件。随后，TANTO处理APC记录的概要信息，以高效地识别潜在的安全 breach，并确保AI的 secure和 responsible使用。SAMURAI能够在不依赖传统软件解决方案的前提下实现对安全威胁和滥用的实时 detection，这些传统解决方案需要与模型集成。实验结果表明，SAMURAI在各种AI模型上实现了高达97%的检测对抗性攻击的准确率，且具有适度的overhead，显著优于传统的软件解决方案。它增强了安全性和合规性，提供了一种全面的解决方案，以抵御新兴威胁对AI的攻击。', 'title_zh': '使用性能计数器在AI加速器中运行时检测 adversarial 攻击'}
{'arxiv_id': 'arXiv:2503.07565', 'title': 'Inductive Moment Matching', 'authors': 'Linqi Zhou, Stefano Ermon, Jiaming Song', 'link': 'https://arxiv.org/abs/2503.07565', 'abstract': 'Diffusion models and Flow Matching generate high-quality samples but are slow at inference, and distilling them into few-step models often leads to instability and extensive tuning. To resolve these trade-offs, we propose Inductive Moment Matching (IMM), a new class of generative models for one- or few-step sampling with a single-stage training procedure. Unlike distillation, IMM does not require pre-training initialization and optimization of two networks; and unlike Consistency Models, IMM guarantees distribution-level convergence and remains stable under various hyperparameters and standard model architectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID using only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98 on CIFAR-10 for a model trained from scratch.', 'abstract_zh': '基于归纳矩匹配的生成模型：一种单阶段训练的一或少量步采样新方法', 'title_zh': '归纳性矩匹配'}
{'arxiv_id': 'arXiv:2503.07550', 'title': 'KSOD: Knowledge Supplement for LLMs On Demand', 'authors': 'Haoran Li, Junfeng Hu', 'link': 'https://arxiv.org/abs/2503.07550', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks, yet still produce errors in domain-specific tasks. To further improve their performance, we propose KSOD (Knowledge Supplement for LLMs On Demand), a novel framework that empowers LLMs to improve their capabilities with knowledge-based supervised fine-tuning (SFT). KSOD analyzes the causes of errors from the perspective of knowledge deficiency by identifying potential missing knowledge in LLM that may lead to the errors. Subsequently, KSOD tunes a knowledge module on knowledge dataset and verifies whether the LLM lacks the identified knowledge based on it. If the knowledge is verified, KSOD supplements the LLM with the identified knowledge using the knowledge module. Tuning LLMs on specific knowledge instead of specific task decouples task and knowledge and our experiments on two domain-specific benchmarks and four general benchmarks empirically demonstrate that KSOD enhances the performance of LLMs on tasks requiring the supplemented knowledge while preserving their performance on other tasks. Our findings shed light on the potential of improving the capabilities of LLMs with knowledge-based SFT.', 'abstract_zh': '基于知识补全的大型语言模型在线微调框架：KSOD', 'title_zh': 'KSOD: 需求驱动的LLM知识补充'}
{'arxiv_id': 'arXiv:2503.07541', 'title': 'Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm', 'authors': 'Zhao-Heng Yin, Changhao Wang, Luis Pineda, Krishna Bodduluri, Tingfan Wu, Pieter Abbeel, Mustafa Mukadam', 'link': 'https://arxiv.org/abs/2503.07541', 'abstract': 'We introduce Geometric Retargeting (GeoRT), an ultrafast, and principled neural hand retargeting algorithm for teleoperation, developed as part of our recent Dexterity Gen (DexGen) system. GeoRT converts human finger keypoints to robot hand keypoints at 1KHz, achieving state-of-the-art speed and accuracy with significantly fewer hyperparameters. This high-speed capability enables flexible postprocessing, such as leveraging a foundational controller for action correction like DexGen. GeoRT is trained in an unsupervised manner, eliminating the need for manual annotation of hand pairs. The core of GeoRT lies in novel geometric objective functions that capture the essence of retargeting: preserving motion fidelity, ensuring configuration space (C-space) coverage, maintaining uniform response through high flatness, pinch correspondence and preventing self-collisions. This approach is free from intensive test-time optimization, offering a more scalable and practical solution for real-time hand retargeting.', 'abstract_zh': '几何重定位（GeoRT）：一种用于远程操作的超快原则性神经手部重定位算法', 'title_zh': '几何重塑：一个原则性、超快速的神经网络手部重塑算法'}
{'arxiv_id': 'arXiv:2503.07536', 'title': 'LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL', 'authors': 'Yingzhe Peng, Gongrui Zhang, Miaosen Zhang, Zhiyuan You, Jie Liu, Qipeng Zhu, Kai Yang, Xingzhong Xu, Xin Geng, Xu Yang', 'link': 'https://arxiv.org/abs/2503.07536', 'abstract': 'Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges from the complex interplay between visual perception and logical reasoning, particularly in compact 3B-parameter architectures where architectural constraints limit reasoning capacity and modality alignment.\nWhile rule-based reinforcement learning (RL) excels in text-only domains, its multimodal extension confronts two critical barriers: (1) data limitations due to ambiguous answers and scarce complex reasoning examples, and (2) degraded foundational reasoning induced by multimodal pretraining.\nTo address these challenges, we propose \\textbf{\\method}, a two-stage framework adapting rule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning Enhancement (FRE)} followed by \\textbf{Multimodal Generalization Training (MGT)}. The FRE stage first strengthens reasoning abilities using text-only data with rule-based RL, then the MGT stage generalizes these reasoning capabilities to multimodal domains.\nExperiments on Qwen2.5-VL-Instruct-3B demonstrate that \\method achieves 4.83\\% and 4.5\\% average improvements over baselines in multimodal and text-only benchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks. These results validate that text-based reasoning enhancement enables effective multimodal generalization, offering a data-efficient paradigm that bypasses costly high-quality multimodal training data.', 'abstract_zh': '增强大型多模态模型中的推理能力面临独特的挑战，源于视觉感知与逻辑推理之间复杂的交互作用，特别是在紧凑的3B参数架构中，架构约束限制了推理能力与模态对齐。', 'title_zh': 'LMM-R1：通过两阶段基于规则的强化学习增强3B大型语言模型的强推理能力'}
{'arxiv_id': 'arXiv:2503.07518', 'title': 'TokenButler: Token Importance is Predictable', 'authors': 'Yash Akhauri, Ahmed F AbouElhamayed, Yifei Gao, Chi-Chih Chang, Nilesh Jain, Mohamed S. Abdelfattah', 'link': 'https://arxiv.org/abs/2503.07518', 'abstract': 'Large Language Models (LLMs) rely on the Key-Value (KV) Cache to store token history, enabling efficient decoding of tokens. As the KV-Cache grows, it becomes a major memory and computation bottleneck, however, there is an opportunity to alleviate this bottleneck, especially because prior research has shown that only a small subset of tokens contribute meaningfully to each decoding step. A key challenge in finding these critical tokens is that they are dynamic, and heavily input query-dependent. Existing methods either risk quality by evicting tokens permanently, or retain the full KV-Cache but rely on retrieving chunks (pages) of tokens at generation, failing at dense, context-rich tasks. Additionally, many existing KV-Cache sparsity methods rely on inaccurate proxies for token importance. To address these limitations, we introduce TokenButler, a high-granularity, query-aware predictor that learns to identify these critical tokens. By training a light-weight predictor with less than 1.2% parameter overhead, TokenButler prioritizes tokens based on their contextual, predicted importance. This improves perplexity & downstream accuracy by over 8% relative to SoTA methods for estimating token importance. We evaluate TokenButler on a novel synthetic small-context co-referential retrieval task, demonstrating near-oracle accuracy. Code, models and benchmarks: this https URL', 'abstract_zh': 'Large Language Models (LLMs)依赖Key-Value (KV)缓存来存储令牌历史，从而实现高效的令牌解码。随着KV缓存的增长，它成为主要的内存和计算瓶颈，然而，先前的研究表明，只有少量令牌对每个解码步骤有显著贡献，因此有机会缓解这一瓶颈。找到这些关键令牌的关键挑战在于它们是动态的，并且高度依赖于输入查询。现有方法要么冒着质量下降的风险永久移除令牌，要么保留完整的KV缓存但在生成时依赖于检索令牌片段（页面），这在密集的上下文丰富任务中失败。此外，许多现有的KV缓存稀疏方法依赖于令牌重要性的不准确代理。为了解决这些限制，我们引入了TokenButler，这是一种高粒度、查询感知的预测器，能够学习识别这些关键令牌。通过训练一个参数开销不到1.2%的轻量级预测器，TokenButler基于上下文预测的重要性对令牌进行优先处理。这在估计令牌重要性的方法中相对提高了超过8%的困惑度和下游准确性。我们在一个新颖的合成小上下文共指检索任务上评估TokenButler，展示了接近完美准确度。代码、模型和基准：[链接]', 'title_zh': 'TokenButler: 令牌的重要性是可以预测的'}
{'arxiv_id': 'arXiv:2503.07513', 'title': 'Language Models Fail to Introspect About Their Knowledge of Language', 'authors': 'Siyuan Song, Jennifer Hu, Kyle Mahowald', 'link': 'https://arxiv.org/abs/2503.07513', 'abstract': 'There has been recent interest in whether large language models (LLMs) can introspect about their own internal states. Such abilities would make LLMs more interpretable, and also validate the use of standard introspective methods in linguistics to evaluate grammatical knowledge in models (e.g., asking "Is this sentence grammatical?"). We systematically investigate emergent introspection across 21 open-source LLMs, in two domains where introspection is of theoretical interest: grammatical knowledge and word prediction. Crucially, in both domains, a model\'s internal linguistic knowledge can be theoretically grounded in direct measurements of string probability. We then evaluate whether models\' responses to metalinguistic prompts faithfully reflect their internal knowledge. We propose a new measure of introspection: the degree to which a model\'s prompted responses predict its own string probabilities, beyond what would be predicted by another model with nearly identical internal knowledge. While both metalinguistic prompting and probability comparisons lead to high task accuracy, we do not find evidence that LLMs have privileged "self-access". Our findings complicate recent results suggesting that models can introspect, and add new evidence to the argument that prompted responses should not be conflated with models\' linguistic generalizations.', 'abstract_zh': '近年来，研究人员对大型语言模型（LLMs）是否能够内省其自身内部状态产生了浓厚兴趣。这种能力会使LLMs更具可解释性，并且能够验证语言学中标准的内省方法在评估模型的语法知识（例如询问“这个句子是语法正确的吗？”）中的使用价值。我们系统地研究了21个开源LLM在两个理论上有内省兴趣的领域中的内省现象：语法知识和词预测。关键的是，在这两个领域中，模型的内部语言知识都可以通过字符串概率的直接测量在理论上得到支持。然后，我们评估模型对元语言提示的响应是否忠实反映了其内部知识。我们提出了一种新的内省度量标准：模型受提示响应预测其自身字符串概率的程度，超出另一个具有几乎相同内部知识的模型所能预测的范围。虽然元语言提示和概率比较都能达到高任务准确性，但我们并未发现LLMs具有“自我访问”的特权。我们的研究结果复杂化了近期表明模型具有内省能力的结果，并为不应将受提示的响应与其语言概括混淆的观点提供了新的证据。', 'title_zh': '语言模型无法反省其语言知识。'}
{'arxiv_id': 'arXiv:2503.07509', 'title': 'Interference-Aware Super-Constellation Design for NOMA', 'authors': 'Mojtaba Vaezi, Xinliang Zhang', 'link': 'https://arxiv.org/abs/2503.07509', 'abstract': 'Non-orthogonal multiple access (NOMA) has gained significant attention as a potential next-generation multiple access technique. However, its implementation with finite-alphabet inputs faces challenges. Particularly, due to inter-user interference, superimposed constellations may have overlapping symbols leading to high bit error rates when successive interference cancellation (SIC) is applied. To tackle the issue, this paper employs autoencoders to design interference-aware super-constellations. Unlike conventional methods where superimposed constellation may have overlapping symbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design super-constellations with distinguishable symbols at receivers, regardless of channel gains. The proposed architecture removes the need for SIC, allowing maximum likelihood-based approaches to be used instead. The paper presents the conceptual architecture, loss functions, and training strategies for AE-NOMA. Various test results are provided to demonstrate the effectiveness of interference-aware constellations in improving the bit error rate, indicating the adaptability of AE-NOMA to different channel scenarios and its promising potential for implementing NOMA systems', 'abstract_zh': '非正交多址(NOMA)作为一种潜在的下一代多址技术已获得广泛关注，但其在有限字母表输入下的实现面临挑战。特别是由于用户间干扰，叠加星座可能具有重叠符号，导致在 successive interference cancellation (SIC) 应用时出现高比特错误率。为解决该问题，本文采用自编码器设计干扰感知叠加星座。与传统方法不同，所提基于自编码器的NOMA (AE-NOMA)经过训练可在接收端设计具有可区分符号的叠加星座，而不考虑信道增益。该提出的架构消除了SIC的需求，允许使用最大似然方法。本文介绍了AE-NOMA的概念架构、损失函数和训练策略，并提供了各种测试结果以证明干扰感知星座在提高比特误差率方面的有效性，展示了AE-NOMA对不同信道场景的适应性和实施NOMA系统的乐观前景。', 'title_zh': '干扰意识下的NOMA超级星系设计'}
{'arxiv_id': 'arXiv:2503.07505', 'title': 'From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges', 'authors': 'Qiongxiu Li, Wenrui Yu, Yufei Xia, Jun Pang', 'link': 'https://arxiv.org/abs/2503.07505', 'abstract': "Federated Learning (FL) enables collaborative learning without directly sharing individual's raw data. FL can be implemented in either a centralized (server-based) or decentralized (peer-to-peer) manner. In this survey, we present a novel perspective: the fundamental difference between centralized FL (CFL) and decentralized FL (DFL) is not merely the network topology, but the underlying training protocol: separate aggregation vs. joint optimization. We argue that this distinction in protocol leads to significant differences in model utility, privacy preservation, and robustness to attacks. We systematically review and categorize existing works in both CFL and DFL according to the type of protocol they employ. This taxonomy provides deeper insights into prior research and clarifies how various approaches relate or differ. Through our analysis, we identify key gaps in the literature. In particular, we observe a surprising lack of exploration of DFL approaches based on distributed optimization methods, despite their potential advantages. We highlight this under-explored direction and call for more research on leveraging distributed optimization for federated learning. Overall, this work offers a comprehensive overview from centralized to decentralized FL, sheds new light on the core distinctions between approaches, and outlines open challenges and future directions for the field.", 'abstract_zh': '联邦学习（FL）使个体无需直接共享原始数据即可进行协作学习。FL可以在中心化（基于服务器）或去中心化（点对点）的方式下实施。在本综述中，我们提出一种新颖的观点：中心化FL（CFL）和去中心化FL（DFL）之间的根本区别不仅在于网络拓扑，还在于基础的训练协议：分离聚合 vs. 联合优化。我们认为这种协议上的区别导致了模型实用性、隐私保护以及对抗攻击鲁棒性方面的显著差异。我们系统地按照所采用的协议类型对CFL和DFL中的现有工作进行了回顾和分类。这种分类提供了对先前研究的更深入洞察，并明确了各种方法之间的关联或差异。通过对这些方法的分析，我们识别出了文献中的关键空白。特别是，我们注意到基于分布式优化方法的DFL方法探索不足，尽管它们具有潜在的优势。我们强调了这一未充分探索的方向，并呼吁对利用分布式优化进行联邦学习的研究进行更多关注。总体而言，本工作提供了从中心化到去中心化FL的全面概述，从新的角度揭示了各种方法的核心区别，并指出了该领域面临的一些公开挑战和未来方向。', 'title_zh': '从集中式到去中心化联邦学习：理论见解、隐私保护与健壮性挑战'}
{'arxiv_id': 'arXiv:2503.07493', 'title': 'V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation', 'authors': 'Guiwei Zhang, Tianyu Zhang, Mohan Zhou, Yalong Bai, Biye Li', 'link': 'https://arxiv.org/abs/2503.07493', 'abstract': "We propose V2Flow, a novel tokenizer that produces discrete visual tokens capable of high-fidelity reconstruction, while ensuring structural and latent distribution alignment with the vocabulary space of large language models (LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables autoregressive visual generation on top of existing LLMs. Our approach formulates visual tokenization as a flow-matching problem, aiming to learn a mapping from a standard normal prior to the continuous image distribution, conditioned on token sequences embedded within the LLMs vocabulary space. The effectiveness of V2Flow stems from two core designs. First, we propose a Visual Vocabulary resampler, which compresses visual data into compact token sequences, with each represented as a soft categorical distribution over LLM's vocabulary. This allows seamless integration of visual tokens into existing LLMs for autoregressive visual generation. Second, we present a masked autoregressive Rectified-Flow decoder, employing a masked transformer encoder-decoder to refine visual tokens into contextually enriched embeddings. These embeddings then condition a dedicated velocity field for precise reconstruction. Additionally, an autoregressive rectified-flow sampling strategy is incorporated, ensuring flexible sequence lengths while preserving competitive reconstruction quality. Extensive experiments show that V2Flow outperforms mainstream VQ-based tokenizers and facilitates autoregressive visual generation on top of existing. this https URL", 'abstract_zh': 'V2Flow：一种新型的能够生成高保真重建离散视觉令牌，并确保与大型语言模型词汇空间的结构和潜在分布对齐的分词器', 'title_zh': 'V2Flow: 统一视觉词元化和大型语言模型词汇表的自回归图像生成方法'}
{'arxiv_id': 'arXiv:2503.07482', 'title': 'Efficient Membership Inference Attacks by Bayesian Neural Network', 'authors': 'Zhenlong Liu, Wenyu Jiang, Feng Zhou, Hongxin Wei', 'link': 'https://arxiv.org/abs/2503.07482', 'abstract': 'Membership Inference Attacks (MIAs) aim to estimate whether a specific data point was used in the training of a given model. Previous attacks often utilize multiple reference models to approximate the conditional score distribution, leading to significant computational overhead. While recent work leverages quantile regression to estimate conditional thresholds, it fails to capture epistemic uncertainty, resulting in bias in low-density regions. In this work, we propose a novel approach - Bayesian Membership Inference Attack (BMIA), which performs conditional attack through Bayesian inference. In particular, we transform a trained reference model into Bayesian neural networks by Laplace approximation, enabling the direct estimation of the conditional score distribution by probabilistic model parameters. Our method addresses both epistemic and aleatoric uncertainty with only a reference model, enabling efficient and powerful MIA. Extensive experiments on five datasets demonstrate the effectiveness and efficiency of BMIA.', 'abstract_zh': 'Bayesian Membership Inference Attack (BMIA): Performing Conditional Attacks through Bayesian Inference', 'title_zh': '基于贝叶斯神经网络的高效成员推理攻击'}
{'arxiv_id': 'arXiv:2503.07470', 'title': 'Advancing Vietnamese Information Retrieval with Learning Objective and Benchmark', 'authors': 'Phu-Vinh Nguyen, Minh-Nam Tran, Long Nguyen, Dien Dinh', 'link': 'https://arxiv.org/abs/2503.07470', 'abstract': 'With the rapid development of natural language processing, many language models have been invented for multiple tasks. One important task is information retrieval (IR), which requires models to retrieve relevant documents. Despite its importance in many real-life applications, especially in retrieval augmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This situation causes difficulty in assessing and comparing many existing Vietnamese embedding language models on the task and slows down the advancement of Vietnamese natural language processing (NLP) research. In this work, we aim to provide the Vietnamese research community with a new benchmark for information retrieval, which mainly focuses on retrieval and reranking tasks. Furthermore, we also present a new objective function based on the InfoNCE loss function, which is used to train our Vietnamese embedding model. Our function aims to be better than the origin in information retrieval tasks. Finally, we analyze the effect of temperature, a hyper-parameter in both objective functions, on the performance of text embedding models.', 'abstract_zh': '随着自然语言处理的快速发展，许多语言模型被发明用于多种任务。其中一个重要的任务是信息检索（IR），要求模型检索相关文档。尽管信息检索在许多实际应用中非常重要，尤其是在检索增强生成（RAG）系统中，这一任务缺乏越南语基准。这种状况导致了难以评估和比较许多现有的越南语嵌入语言模型在该任务上的性能，并阻碍了越南语自然语言处理（NLP）研究的发展。在本文中，我们旨在为越南语研究社区提供一个新的信息检索基准，主要关注检索和再排序任务。此外，我们还提出了一种基于InfoNCE损失函数的新目标函数，用于训练我们的越南语嵌入模型。我们的函数旨在在信息检索任务中表现更优。最后，我们分析了目标函数中的温度这一超参数对文本嵌入模型性能的影响。', 'title_zh': '基于学习目标和基准提高越南语信息检索'}
{'arxiv_id': 'arXiv:2503.07459', 'title': 'MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning', 'authors': 'Xiangru Tang, Daniel Shao, Jiwoong Sohn, Jiapeng Chen, Jiayi Zhang, Jinyu Xiang, Fang Wu, Yilun Zhao, Chenglin Wu, Wenqi Shi, Arman Cohan, Mark Gerstein', 'link': 'https://arxiv.org/abs/2503.07459', 'abstract': 'Large Language Models (LLMs) have shown impressive performance on existing medical question-answering benchmarks. This high performance makes it increasingly difficult to meaningfully evaluate and differentiate advanced methods. We present MedAgentsBench, a benchmark that focuses on challenging medical questions requiring multi-step clinical reasoning, diagnosis formulation, and treatment planning-scenarios where current models still struggle despite their strong performance on standard tests. Drawing from seven established medical datasets, our benchmark addresses three key limitations in existing evaluations: (1) the prevalence of straightforward questions where even base models achieve high performance, (2) inconsistent sampling and evaluation protocols across studies, and (3) lack of systematic analysis of the interplay between performance, cost, and inference time. Through experiments with various base models and reasoning methods, we demonstrate that the latest thinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in complex medical reasoning tasks. Additionally, advanced search-based agent methods offer promising performance-to-cost ratios compared to traditional approaches. Our analysis reveals substantial performance gaps between model families on complex questions and identifies optimal model selections for different computational constraints. Our benchmark and evaluation framework are publicly available at this https URL.', 'abstract_zh': 'MedAgentsBench：针对复杂医学推理任务的基准测试', 'title_zh': 'MedAgentsBench: 评估复杂医疗推理模型与代理框架的基准测试'}
{'arxiv_id': 'arXiv:2503.07453', 'title': 'Is a Good Foundation Necessary for Efficient Reinforcement Learning? The Computational Role of the Base Model in Exploration', 'authors': 'Dylan J. Foster, Zakaria Mhammedi, Dhruv Rohatgi', 'link': 'https://arxiv.org/abs/2503.07453', 'abstract': 'Language model alignment (or, reinforcement learning) techniques that leverage active exploration -- deliberately encouraging the model to produce diverse, informative responses -- offer the promise of super-human capabilities. However, current understanding of algorithm design primitives for computationally efficient exploration with language models is limited. To better understand how to leverage access to powerful pre-trained generative models to improve the efficiency of exploration, we introduce a new computational framework for RL with language models, in which the learner interacts with the model through a sampling oracle. Focusing on the linear softmax model parameterization, we provide new results that reveal the computational-statistical tradeoffs of efficient exploration:\n1. Necessity of coverage: Coverage refers to the extent to which the pre-trained model covers near-optimal responses -- a form of hidden knowledge. We show that coverage, while not necessary for data efficiency, lower bounds the runtime of any algorithm in our framework.\n2. Inference-time exploration: We introduce a new algorithm, SpannerSampling, which obtains optimal data efficiency and is computationally efficient whenever the pre-trained model enjoys sufficient coverage, matching our lower bound. SpannerSampling leverages inference-time computation with the pre-trained model to reduce the effective search space for exploration.\n3. Insufficiency of training-time interventions: We contrast the result above by showing that training-time interventions that produce proper policies cannot achieve similar guarantees in polynomial time.\n4. Computational benefits of multi-turn exploration: Finally, we show that under additional representational assumptions, one can achieve improved runtime (replacing sequence-level coverage with token-level coverage) through multi-turn exploration.', 'abstract_zh': '语言模型对齐（或强化学习）技术利用主动探索——故意促使模型生成多样且有信息量的响应——提供了超人类能力的潜力。然而，当前计算高效探索的语言模型算法设计基础非常有限。为更好地理解如何利用强大预训练生成模型提高探索效率，我们引入了一种新的以语言模型为框架的计算框架，在该框架中，学习者通过采样或acles与模型交互。聚焦于线性softmax模型参数化，我们提供了新的结果，揭示了高效探索的计算-统计权衡：\n1. 覆盖的必要性：覆盖指的是预训练模型涵盖近最优响应的程度——一种隐藏知识的形式。我们展示，虽然覆盖不是数据效率所必需的，但它在我们的框架中任何算法的运行时下界。\n2. 推理时探索：我们介绍了一种新的算法SpannerSampling，该算法在预训练模型享有充分覆盖时，实现了最佳的数据效率和计算效率，与我们的下界相匹配。SpannerSampling利用预训练模型的推理时计算来减少探索的有效搜索空间。\n3. 无训练时介入的不足：与上述结果形成对比，我们展示了训练时介入以生成正确策略无法在多项式时间内实现类似保证。\n4. 多轮探索的计算优势：最后，我们展示了在附加表示假设下，可以通过多轮探索实现更好的运行时性能（用令牌级覆盖代替序列级覆盖），从而改善运行时性能。', 'title_zh': '打好基础对于高效强化学习是否必要？基模型在探索中的计算作用'}
{'arxiv_id': 'arXiv:2503.07444', 'title': 'Divide and Conquer Self-Supervised Learning for High-Content Imaging', 'authors': 'Lucas Farndale, Paul Henderson, Edward W Roberts, Ke Yuan', 'link': 'https://arxiv.org/abs/2503.07444', 'abstract': 'Self-supervised representation learning methods often fail to learn subtle or complex features, which can be dominated by simpler patterns which are much easier to learn. This limitation is particularly problematic in applications to science and engineering, as complex features can be critical for discovery and analysis. To address this, we introduce Split Component Embedding Registration (SpliCER), a novel architecture which splits the image into sections and distils information from each section to guide the model to learn more subtle and complex features without compromising on simpler features. SpliCER is compatible with any self-supervised loss function and can be integrated into existing methods without modification. The primary contributions of this work are as follows: i) we demonstrate that existing self-supervised methods can learn shortcut solutions when simple and complex features are both present; ii) we introduce a novel self-supervised training method, SpliCER, to overcome the limitations of existing methods, and achieve significant downstream performance improvements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge medical and geospatial imaging settings. SpliCER offers a powerful new tool for representation learning, enabling models to uncover complex features which could be overlooked by other methods.', 'abstract_zh': '自监督表示学习方法往往难以学习细微或复杂的特征，这些特征可能会被更简单且更容易学习的模式所主导。这一局限性在科学和工程应用中尤为令人困扰，因为复杂的特征对于发现和分析至关重要。为了解决这一问题，我们提出了一种新颖的架构——Split Component Embedding Registration (SpliCER)，该架构将图像划分为多个部分，并从每个部分提取信息以引导模型学习更为细微和复杂的特征，同时保留简单特征的学习。SpliCER 可与任何自监督损失函数兼容，并且可以无缝集成到现有方法中而不需修改。本文的主要贡献如下：i) 我们证明了现有的自监督方法在同时存在简单和复杂特征时会学习捷径解；ii) 我们引入了一种全新的自监督训练方法 SpliCER，以克服现有方法的局限性，并显著提高了下游性能；iii) 我们展示了 SpliCER 在尖端的医学和地理空间成像场景中的有效性。SpliCER 提供了一种强大的新工具，使模型能够发现其他方法可能忽略的复杂特征。', 'title_zh': '征服与征服：高内容成像中的分级自我监督学习'}
{'arxiv_id': 'arXiv:2503.07426', 'title': 'RePO: ReLU-based Preference Optimization', 'authors': 'Junkang Wu, Kexin Huang, Xue Wang, Jinyang Gao, Bolin Ding, Jiancan Wu, Xiangnan He, Xiang Wang', 'link': 'https://arxiv.org/abs/2503.07426', 'abstract': "Aligning large language models (LLMs) with human preferences is critical for real-world deployment, yet existing methods like RLHF face computational and stability challenges. While DPO establishes an offline paradigm with single hyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity through dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference Optimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two advances: (1) retaining SimPO's reference-free margins but removing $\\beta$ through gradient analysis, and (2) adopting a ReLU-based max-margin loss that naturally filters trivial pairs. Theoretically, RePO is characterized as SimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting collapses to binary thresholding, forming a convex envelope of the 0-1 loss. Empirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO and SimPO across multiple base models, requiring only one hyperparameter to tune.", 'abstract_zh': '基于ReLU的偏好优化（RePO）：简化的大语言模型偏好对齐方法', 'title_zh': 'ReLU为基础的Preference Optimization'}
{'arxiv_id': 'arXiv:2503.07396', 'title': 'Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image Classification', 'authors': 'Kexin Di, Xiuxing Li, Yuyang Han, Ziyu Li, Qing Li, Xia Wu', 'link': 'https://arxiv.org/abs/2503.07396', 'abstract': "Few-shot image classification has become a popular research topic for its wide application in real-world scenarios, however the problem of supervision collapse induced by single image-level annotation remains a major challenge. Existing methods aim to tackle this problem by locating and aligning relevant local features. However, the high intra-class variability in real-world images poses significant challenges in locating semantically relevant local regions under few-shot settings. Drawing inspiration from the human's complementary learning system, which excels at rapidly capturing and integrating semantic features from limited examples, we propose the generalization-optimized Systems Consolidation Adaptive Memory Dual-Network, SCAM-Net. This approach simulates the systems consolidation of complementary learning system with an adaptive memory module, which successfully addresses the difficulty of identifying meaningful features in few-shot scenarios. Specifically, we construct a Hippocampus-Neocortex dual-network that consolidates structured representation of each category, the structured representation is then stored and adaptively regulated following the generalization optimization principle in a long-term memory inside Neocortex. Extensive experiments on benchmark datasets show that the proposed model has achieved state-of-the-art performance.", 'abstract_zh': '基于Few-shot图像分类的Generalization-Optimized Systems Consolidation Adaptive Memory Dual-NetworkSCAM-Net', 'title_zh': '仿生自适应记忆双网络在少样本图像分类中的应用'}
{'arxiv_id': 'arXiv:2503.07389', 'title': 'TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image Diffusion Models', 'authors': 'Ruidong Chen, Honglin Guo, Lanjun Wang, Chenyu Zhang, Weizhi Nie, An-An Liu', 'link': 'https://arxiv.org/abs/2503.07389', 'abstract': "Recent advances in text-to-image diffusion models enable photorealistic image generation, but they also risk producing malicious content, such as NSFW images. To mitigate risk, concept erasure methods are studied to facilitate the model to unlearn specific concepts. However, current studies struggle to fully erase malicious concepts implicitly embedded in prompts (e.g., metaphorical expressions or adversarial prompts) while preserving the model's normal generation capability. To address this challenge, our study proposes TRCE, using a two-stage concept erasure strategy to achieve an effective trade-off between reliable erasure and knowledge preservation. Firstly, TRCE starts by erasing the malicious semantics implicitly embedded in textual prompts. By identifying a critical mapping objective(i.e., the [EoT] embedding), we optimize the cross-attention layers to map malicious prompts to contextually similar prompts but with safe concepts. This step prevents the model from being overly influenced by malicious semantics during the denoising process. Following this, considering the deterministic properties of the sampling trajectory of the diffusion model, TRCE further steers the early denoising prediction toward the safe direction and away from the unsafe one through contrastive learning, thus further avoiding the generation of malicious content. Finally, we conduct comprehensive evaluations of TRCE on multiple malicious concept erasure benchmarks, and the results demonstrate its effectiveness in erasing malicious concepts while better preserving the model's original generation ability. The code is available at: this http URL. CAUTION: This paper includes model-generated content that may contain offensive material.", 'abstract_zh': 'Recent advances in text-to-image diffusion models enable photorealistic image generation but also risk producing malicious content such as NSFW images. To mitigate this risk, our study proposes TRCE, using a two-stage concept erasure strategy to achieve an effective trade-off between reliable erasure and knowledge preservation.', 'title_zh': 'TRCE: 向可靠的文字欺诈概念消除在文本到图像扩散模型方向'}
{'arxiv_id': 'arXiv:2503.07384', 'title': 'Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs', 'authors': 'Gonzalo Mancera, Daniel de Alcala, Julian Fierrez, Ruben Tolosana, Aythami Morales', 'link': 'https://arxiv.org/abs/2503.07384', 'abstract': 'This work adapts and studies the gradient-based Membership Inference Test (gMINT) to the classification of text based on LLMs. MINT is a general approach intended to determine if given data was used for training machine learning models, and this work focuses on its application to the domain of Natural Language Processing. Using gradient-based analysis, the MINT model identifies whether particular data samples were included during the language model training phase, addressing growing concerns about data privacy in machine learning. The method was evaluated in seven Transformer-based models and six datasets comprising over 2.5 million sentences, focusing on text classification tasks. Experimental results demonstrate MINTs robustness, achieving AUC scores between 85% and 99%, depending on data size and model architecture. These findings highlight MINTs potential as a scalable and reliable tool for auditing machine learning models, ensuring transparency, safeguarding sensitive data, and fostering ethical compliance in the deployment of AI/NLP technologies.', 'abstract_zh': '基于LLM的文本分类中的梯度导向会员推理测试研究', 'title_zh': '我的文本在我的AI模型中吗？基于梯度的成员推理测试在大规模语言模型中的应用'}
{'arxiv_id': 'arXiv:2503.07364', 'title': 'Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future', 'authors': 'Yannick Oswald', 'link': 'https://arxiv.org/abs/2503.07364', 'abstract': 'Prevailing top-down systems in politics and economics struggle to keep pace with the pressing challenges of the 21st century, such as climate change, social inequality and conflict. Bottom-up democratisation and participatory approaches in politics and economics are increasingly seen as promising alternatives to confront and overcome these issues, often with utopian overtones, as proponents believe they may dramatically reshape political, social and ecological futures for the better and in contrast to contemporary authoritarian tendencies across various countries. Institutional specifics and the associated collective human behavior or culture remains little understood and debated, however. In this article, I propose a novel research agenda focusing on utopian democratisation efforts with formal and computational methods as well as with artificial intelligence - I call this agenda Artificial Utopia. Artificial Utopias provide safe testing grounds for new political ideas and economic policies in-silico with reduced risk of negative consequences as compared to testing ideas in real-world contexts. An increasing number of advanced simulation and intelligence methods, that aim at representing human cognition and collective decision-making in more realistic ways, could benefit this process. This includes agent-based modelling, reinforcement learning, large language models and more. I clarify what some of these simulation approaches can contribute to the study of Artificial Utopias with the help of two institutional examples: the citizen assembly and the democratic firm.', 'abstract_zh': '占据主导地位的政治和经济自上而下体系难以应对21世纪紧迫的挑战，如气候变化、社会不平等和冲突。自下而上的民主化和参与性方法在政治和经济中越来越被视为对抗和克服这些问题的有希望的替代方案，常常带有乌托邦的色彩，因为支持者认为它们可能会显著塑造更美好的政治、社会和生态未来，这与当今各国日益增强的威权倾向相对。然而，相关机构的具体特性和与之相关的集体人类行为或文化仍知之甚少且讨论不多。在本文中，我提出了一项新的研究议程，专注于使用形式化和计算方法以及人工智能进行乌托邦民主化的努力——我将这一议程称为“人工智能乌托邦”。人工智能乌托邦为在硅中测试新的政治理念和经济政策提供了安全的试验场，相比于在现实世界中测试概念，其负面后果的风险更低。越来越多旨在以更现实的方式代表人类认知和集体决策的先进仿真和智能方法可以受益于这一过程。这包括基于代理的建模、强化学习、大规模语言模型等。利用两个机构性案例——公民议会和民主企业，我阐明了这些仿真方法如何为研究人工智能乌托邦做出贡献。', 'title_zh': '人工乌托邦：仿真与智能代理 toward一个民主化未来'}
{'arxiv_id': 'arXiv:2503.07341', 'title': 'The Economics of p(doom): Scenarios of Existential Risk and Economic Growth in the Age of Transformative AI', 'authors': 'Jakub Growiec, Klaus Prettner', 'link': 'https://arxiv.org/abs/2503.07341', 'abstract': 'Recent advances in artificial intelligence (AI) have led to a diverse set of predictions about its long-term impact on humanity. A central focus is the potential emergence of transformative AI (TAI), eventually capable of outperforming humans in all economically valuable tasks and fully automating labor. Discussed scenarios range from human extinction after a misaligned TAI takes over ("AI doom") to unprecedented economic growth and abundance ("post-scarcity"). However, the probabilities and implications of these scenarios remain highly uncertain. Here, we organize the various scenarios and evaluate their associated existential risks and economic outcomes in terms of aggregate welfare. Our analysis shows that even low-probability catastrophic outcomes justify large investments in AI safety and alignment research. We find that the optimizing representative individual would rationally allocate substantial resources to mitigate extinction risk; in some cases, she would prefer not to develop TAI at all. This result highlights that current global efforts in AI safety and alignment research are vastly insufficient relative to the scale and urgency of existential risks posed by TAI. Our findings therefore underscore the need for stronger safeguards to balance the potential economic benefits of TAI with the prevention of irreversible harm. Addressing these risks is crucial for steering technological progress toward sustainable human prosperity.', 'abstract_zh': '近期人工智能的发展对未来影响的预测引发了多样化的观点。一个核心关注点是转型人工智能（TAI）的潜在出现，最终能够在所有经济上有价值的任务中超越人类并完全自动化劳动力。讨论的场景从转型人工智能失控行为导致人类灭绝（“AI末日”）到前所未有的经济增长和 abundance（“后稀缺”）不等。然而，这些情景的可能性和影响依然高度不确定。本文整理了各种情景，并基于总体福利评估它们相关的存在风险和经济结果。我们的分析表明，即使是低概率的灾难性结果也证明了在人工智能安全和对齐研究上进行大量投资的必要性。我们发现，优化的代表性个体会理性地分配大量资源来降低灭绝风险；在某些情况下，她可能完全不想开发转型人工智能。这一结果突显了当前全球在人工智能安全和对齐研究上的努力与所面临的存在风险的规模和紧迫性相比还远远不足。因此，我们的发现强调了需要更强的保障措施来平衡转型人工智能可能带来的经济利益与防止不可逆伤害之间的关系。应对这些风险对于引导技术进步朝着可持续的人类繁荣方向至关重要。', 'title_zh': 'Transformative AI时代的生死风险与经济增长经济学：p(doom)情境研究'}
{'arxiv_id': 'arXiv:2503.07340', 'title': 'Research and Design on Intelligent Recognition of Unordered Targets for Robots Based on Reinforcement Learning', 'authors': 'Yiting Mao, Dajun Tao, Shengyuan Zhang, Tian Qi, Keqin Li', 'link': 'https://arxiv.org/abs/2503.07340', 'abstract': 'In the field of robot target recognition research driven by artificial intelligence (AI), factors such as the disordered distribution of targets, the complexity of the environment, the massive scale of data, and noise interference have significantly restricted the improvement of target recognition accuracy. Against the backdrop of the continuous iteration and upgrading of current AI technologies, to meet the demand for accurate recognition of disordered targets by intelligent robots in complex and changeable scenarios, this study innovatively proposes an AI - based intelligent robot disordered target recognition method using reinforcement learning. This method processes the collected target images with the bilateral filtering algorithm, decomposing them into low - illumination images and reflection images. Subsequently, it adopts differentiated AI strategies, compressing the illumination images and enhancing the reflection images respectively, and then fuses the two parts of images to generate a new image. On this basis, this study deeply integrates deep learning, a core AI technology, with the reinforcement learning algorithm. The enhanced target images are input into a deep reinforcement learning model for training, ultimately enabling the AI - based intelligent robot to efficiently recognize disordered targets. Experimental results show that the proposed method can not only significantly improve the quality of target images but also enable the AI - based intelligent robot to complete the recognition task of disordered targets with higher efficiency and accuracy, demonstrating extremely high application value and broad development prospects in the field of AI robots.', 'abstract_zh': '基于人工智能的机器人乱序目标识别方法：借助强化学习的低照度与反射图像融合技术', 'title_zh': '基于强化学习的机器人无序目标智能识别研究与设计'}
{'arxiv_id': 'arXiv:2503.07338', 'title': 'Temporal Triplane Transformers as Occupancy World Models', 'authors': 'Haoran Xu, Peixi Peng, Guang Tan, Yiqian Chang, Yisen Zhao, Yonghong Tian', 'link': 'https://arxiv.org/abs/2503.07338', 'abstract': "Recent years have seen significant advances in world models, which primarily focus on learning fine-grained correlations between an agent's motion trajectory and the resulting changes in its surrounding environment. However, existing methods often struggle to capture such fine-grained correlations and achieve real-time predictions. To address this, we propose a new 4D occupancy world model for autonomous driving, termed T$^3$Former. T$^3$Former begins by pre-training a compact triplane representation that efficiently compresses the 3D semantically occupied environment. Next, T$^3$Former extracts multi-scale temporal motion features from the historical triplane and employs an autoregressive approach to iteratively predict the next triplane changes. Finally, T$^3$Former combines the triplane changes with the previous ones to decode them into future occupancy results and ego-motion trajectories. Experimental results demonstrate the superiority of T$^3$Former, achieving 1.44$\\times$ faster inference speed (26 FPS), while improving the mean IoU to 36.09 and reducing the mean absolute planning error to 1.0 meters.", 'abstract_zh': '最近几年，世界模型取得了显著进展，主要集中在学习智能体运动轨迹与其周围环境变化之间的精细关联。然而，现有方法往往难以捕捉这种精细关联并实现实时预测。为解决这一问题，我们提出了一种新的4D占位世界模型，名为T$^3$Former。T$^3$Former首先通过预训练一个紧凑的三平面表示来高效压缩3D语义占位环境。接着，T$^3$Former从历史三平面中提取多尺度时间运动特征，并采用自回归方法迭代预测下一个三平面的变化。最后，T$^3$Former将三平面变化与之前的进行组合，解码成未来占位结果和自运动轨迹。实验结果表明，T$^3$Former在保持较高精度的同时，实现了1.44倍的推理速度提升（26 FPS），同时使平均IoU提升至36.09，平均绝对规划误差降低至1.0米。', 'title_zh': '时空三视图变换器作为 occupancy 世界模型'}
{'arxiv_id': 'arXiv:2503.07330', 'title': 'Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection', 'authors': 'Weicheng He, Changshun Wu, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem', 'link': 'https://arxiv.org/abs/2503.07330', 'abstract': 'Object detection systems must reliably perceive objects of interest without being overly confident to ensure safe decision-making in dynamic environments. Filtering techniques based on out-of-distribution (OoD) detection are commonly added as an extra safeguard to filter hallucinations caused by overconfidence in novel objects. Nevertheless, evaluating YOLO-family detectors and their filters under existing OoD benchmarks often leads to unsatisfactory performance. This paper studies the underlying reasons for performance bottlenecks and proposes a methodology to improve performance fundamentally. Our first contribution is a calibration of all existing evaluation results: Although images in existing OoD benchmark datasets are claimed not to have objects within in-distribution (ID) classes (i.e., categories defined in the training dataset), around 13% of objects detected by the object detector are actually ID objects. Dually, the ID dataset containing OoD objects can also negatively impact the decision boundary of filters. These ultimately lead to a significantly imprecise performance estimation. Our second contribution is to consider the task of hallucination reduction as a joint pipeline of detectors and filters. By developing a methodology to carefully synthesize an OoD dataset that semantically resembles the objects to be detected, and using the crafted OoD dataset in the fine-tuning of YOLO detectors to suppress the objectness score, we achieve a 88% reduction in overall hallucination error with a combined fine-tuned detection and filtering system on the self-driving benchmark BDD-100K. Our code and dataset are available at: this https URL.', 'abstract_zh': '对象检测系统必须可靠地感知感兴趣对象，但不能过于自信，以确保在动态环境中的安全决策。基于离分布(OoD)检测的过滤技术通常被添加作为额外的保障，以过滤由对新颖对象过于自信而导致的幻觉。然而，现有OoD基准下评估YOLO家族检测器及其过滤器往往导致性能不佳。本文研究了性能瓶颈的根本原因，并提出了一种根本性的改进方法。我们的第一项贡献是对所有现有评估结果进行了校准：尽管现有OoD基准数据集中的图像声称不含训练数据集内分布(ID)类别的对象（即训练数据集中的类别），但其实检测到的对象中有大约13%实际上是ID对象。相反，含有OoD对象的ID数据集也可以负面影响过滤器的决策边界。这些最终导致了性能估算的显著不精确。我们的第二项贡献是将幻觉减少任务视为检测器和过滤器的联合管道。通过开发一种方法来仔细合成一个与要检测的对象具有语义相似性的OoD数据集，并在Fine-Tuning YOLO检测器时使用构建成的OoD数据集以抑制对象性得分，我们在自驾车基准BDD-100K上实现了整体幻觉误差88%的减少，并结合了Fine-Tuned检测和过滤系统。我们的代码和数据集可在以下链接获取：this https URL。', 'title_zh': '基于YOLO的目标检测模型中幻觉现象的缓解：重新审视分布外检测'}
{'arxiv_id': 'arXiv:2503.07329', 'title': 'Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models', 'authors': 'Hao Zhou, Guergana Savova, Lijing Wang', 'link': 'https://arxiv.org/abs/2503.07329', 'abstract': 'The impact of random seeds in fine-tuning large language models (LLMs) has been largely overlooked despite its potential influence on model this http URL this study, we systematically evaluate the effects of random seeds on LLMs using the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact through traditional metrics like accuracy and F1, calculating their mean and variance to quantify performance fluctuations. To capture the micro-level effects, we introduce a novel metric, consistency, measuring the stability of individual predictions across runs. Our experiments reveal significant variance at both macro and micro levels, underscoring the need for careful consideration of random seeds in fine-tuning and evaluation.', 'abstract_zh': '随机种子在细调大规模语言模型中的影响 largely overlooked 尽管其可能对模型有潜在影响 在本研究中，我们系统地使用GLUE和SuperGLUE基准评估随机种子对大规模语言模型的影响。我们通过准确率和F1等传统指标从宏观层面分析影响，并计算其均值和方差以量化性能波动。为捕捉微观影响，我们引入了一个新的指标——一致性，衡量单个预测在不同运行中的稳定性。实验结果揭示了宏观和微观层面的显著差异，强调了在细调和评估过程中仔细考虑随机种子的重要性。', 'title_zh': '评估随机种子对大型语言模型微调的宏观和微观影响'}
{'arxiv_id': 'arXiv:2503.07326', 'title': 'AI Biases as Asymmetries: A Review to Guide Practice', 'authors': 'Gabriella Waters, Phillip Honenberger', 'link': 'https://arxiv.org/abs/2503.07326', 'abstract': 'The understanding of bias in AI is currently undergoing a revolution. Initially understood as errors or flaws, biases are increasingly recognized as integral to AI systems and sometimes preferable to less biased alternatives. In this paper, we review the reasons for this changed understanding and provide new guidance on two questions: First, how should we think about and measure biases in AI systems, consistent with the new understanding? Second, what kinds of bias in an AI system should we accept or even amplify, and what kinds should we minimize or eliminate, and why? The key to answering both questions, we argue, is to understand biases as "violations of a symmetry standard" (following Kelly). We distinguish three main types of asymmetry in AI systems-error biases, inequality biases, and process biases-and highlight places in the pipeline of AI development and application where bias of each type is likely to be good, bad, or inevitable.', 'abstract_zh': 'AI中的偏差理解正在经历一场革命：从错误或缺陷到被视为AI系统的核心要素，有时甚至比无偏差的替代方案更可取。在本文中，我们回顾了这一理解变化的原因，并就以下两个问题提供了新的指导：首先，我们应该如何根据新的理解来思考和衡量AI系统的偏差？其次，我们应该接受或放大哪些类型的偏差，哪些类型的偏差应该减少或消除，原因是什么？我们主张，回答这两个问题的关键是将偏差理解为“违反对称标准”的偏差（参考Kelly）。我们区分了AI系统中的三种主要不对称性类型：错误偏差、不平等偏差和过程偏差，并指出了在AI开发和应用管道中每种类型偏差可能是良好的、不良的或不可避免的地方。', 'title_zh': 'AI偏差作为不对称性：一项指导实践的综述'}
{'arxiv_id': 'arXiv:2503.07323', 'title': 'Dynamic Path Navigation for Motion Agents with LLM Reasoning', 'authors': 'Yubo Zhao, Qi Wu, Yifan Wang, Yu-Wing Tai, Chi-Keung Tang', 'link': 'https://arxiv.org/abs/2503.07323', 'abstract': "Large Language Models (LLMs) have demonstrated strong generalizable reasoning and planning capabilities. However, their efficacies in spatial path planning and obstacle-free trajectory generation remain underexplored. Leveraging LLMs for navigation holds significant potential, given LLMs' ability to handle unseen scenarios, support user-agent interactions, and provide global control across complex systems, making them well-suited for agentic planning and humanoid motion generation. As one of the first studies in this domain, we explore the zero-shot navigation and path generation capabilities of LLMs by constructing a dataset and proposing an evaluation protocol. Specifically, we represent paths using anchor points connected by straight lines, enabling movement in various directions. This approach offers greater flexibility and practicality compared to previous methods while remaining simple and intuitive for LLMs. We demonstrate that, when tasks are well-structured in this manner, modern LLMs exhibit substantial planning proficiency in avoiding obstacles while autonomously refining navigation with the generated motion to reach the target. Further, this spatial reasoning ability of a single LLM motion agent interacting in a static environment can be seamlessly generalized in multi-motion agents coordination in dynamic environments. Unlike traditional approaches that rely on single-step planning or local policies, our training-free LLM-based method enables global, dynamic, closed-loop planning, and autonomously resolving collision issues.", 'abstract_zh': '大规模语言模型在空间路径规划和无碰撞轨迹生成中的零-shot导航能力探索', 'title_zh': '基于LLM推理的动态路径导航方法'}
{'arxiv_id': 'arXiv:2503.07320', 'title': 'Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents', 'authors': 'Guanxuan Jiang, Yuyang Wang, Pan Hui', 'link': 'https://arxiv.org/abs/2503.07320', 'abstract': "With the rise of large language models (LLMs), AI agents as autonomous decision-makers present significant opportunities and challenges for human-AI cooperation. While many studies have explored human cooperation with AI as tools, the role of LLM-augmented autonomous agents in competitive-cooperative interactions remains under-examined. This study investigates human cooperative behavior by engaging 30 participants who interacted with LLM agents exhibiting different characteristics (purported human, purported rule-based AI agent, and LLM agent) in repeated Prisoner's Dilemma games. Findings show significant differences in cooperative behavior based on the agents' purported characteristics and the interaction effect of participants' genders and purported characteristics. We also analyzed human response patterns, including game completion time, proactive favorable behavior, and acceptance of repair efforts. These insights offer a new perspective on human interactions with LLM agents in competitive cooperation contexts, such as virtual avatars or future physical entities. The study underscores the importance of understanding human biases toward AI agents and how observed behaviors can influence future human-AI cooperation dynamics.", 'abstract_zh': '大规模语言模型兴起背景下自主决策的AI代理对人类-AI合作的影响：基于囚徒困境游戏的人类合作行为研究', 'title_zh': '实验探索：探究人类与大型语言模型代理之间的合作互动行为'}
{'arxiv_id': 'arXiv:2503.07317', 'title': 'Self-Corrective Task Planning by Inverse Prompting with Large Language Models', 'authors': 'Jiho Lee, Hayun Lee, Jonghyeon Kim, Kyungjae Lee, Eunwoo Kim', 'link': 'https://arxiv.org/abs/2503.07317', 'abstract': 'In robot task planning, large language models (LLMs) have shown significant promise in generating complex and long-horizon action sequences. However, it is observed that LLMs often produce responses that sound plausible but are not accurate. To address these problems, existing methods typically employ predefined error sets or external knowledge sources, requiring human efforts and computation resources. Recently, self-correction approaches have emerged, where LLM generates and refines plans, identifying errors by itself. Despite their effectiveness, they are more prone to failures in correction due to insufficient reasoning. In this paper, we introduce InversePrompt, a novel self-corrective task planning approach that leverages inverse prompting to enhance interpretability. Our method incorporates reasoning steps to provide clear, interpretable feedback. It generates inverse actions corresponding to the initially generated actions and verifies whether these inverse actions can restore the system to its original state, explicitly validating the logical coherence of the generated this http URL results on benchmark datasets show an average 16.3% higher success rate over existing LLM-based task planning methods. Our approach offers clearer justifications for feedback in real-world environments, resulting in more successful task completion than existing self-correction approaches across various scenarios.', 'abstract_zh': '基于逆提示词的自动矫正任务规划方法', 'title_zh': '使用大型语言模型的逆向提示自纠正任务规划'}
{'arxiv_id': 'arXiv:2503.07315', 'title': 'Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions', 'authors': 'Rui Qiao, Zhaoxuan Wu, Jingtan Wang, Pang Wei Koh, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2503.07315', 'abstract': 'Machine learning models often have uneven performance among subpopulations (a.k.a., groups) in the data distributions. This poses a significant challenge for the models to generalize when the proportions of the groups shift during deployment. To improve robustness to such shifts, existing approaches have developed strategies that train models or perform hyperparameter tuning using the group-labeled data to minimize the worst-case loss over groups. However, a non-trivial amount of high-quality labels is often required to obtain noticeable improvements. Given the costliness of the labels, we propose to adopt a different paradigm to enhance group label efficiency: utilizing the group-labeled data as a target set to optimize the weights of other group-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a two-stage approach that first learns the representations from group-unlabeled data, and then tinkers the model by iteratively retraining its last layer on the reweighted data using influence functions. Our GSR is theoretically sound, practically lightweight, and effective in improving the robustness to subpopulation shifts. In particular, GSR outperforms the previous state-of-the-art approaches that require the same amount or even more group labels.', 'abstract_zh': '机器学习模型在亚人群中（即，组）的表现通常不均衡。在部署过程中，如果组的比例发生变化，这会显著挑战模型的泛化能力。为提高对这些变化的鲁棒性，现有方法开发了利用组标签数据训练模型或进行超参数调优的策略，以最小化最坏情况的损失。然而，这通常需要大量的高质量标签才能获得显著改善。鉴于标签的成本，我们提出采用不同的范式来提升组标签的效率：利用组标签数据作为目标集，优化其他未标记组的数据的权重。我们引入了组鲁棒样本重加权（GSR），这是一种两阶段方法，首先从未标记组数据中学习表示，然后通过迭代地在重新加权的数据上重新训练模型的最后一层，使用影响函数来微调模型。GSR在理论上扎实、在实践上轻量且有效，能提高对亚人群转移的鲁棒性。特别是，GSR优于需要相同数量甚至更多组标签的最新最先进的方法。', 'title_zh': '基于影响函数的组稳健样本加权方法以应对亚群体偏移'}
{'arxiv_id': 'arXiv:2503.07294', 'title': 'Distilling Knowledge into Quantum Vision Transformers for Biomedical Image Classification', 'authors': 'Thomas Boucher, Evangelos B. Mazomenos', 'link': 'https://arxiv.org/abs/2503.07294', 'abstract': 'Quantum vision transformers (QViTs) build on vision transformers (ViTs) by replacing linear layers within the self-attention mechanism with parameterised quantum neural networks (QNNs), harnessing quantum mechanical properties to improve feature representation. This hybrid approach aims to achieve superior performance, with significantly reduced model complexity as a result of the enriched feature representation, requiring fewer parameters. This paper proposes a novel QViT model for biomedical image classification and investigates its performance against comparable ViTs across eight diverse datasets, encompassing various modalities and classification tasks. We assess models trained from scratch and those pre-trained using knowledge distillation (KD) from high-quality teacher models. Our findings demonstrate that QViTs outperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy (0.710 vs 0.687) when trained from scratch, and even compete with state-of-the-art classical models in multiple tasks, whilst being significantly more efficient (89% reduction in GFLOPs and 99.99% in parameter number). Additionally, we find that QViTs and ViTs respond equally well to KD, with QViT pre-training performance scaling with model complexity. This is the first investigation into the efficacy of deploying QViTs with KD for computer-aided diagnosis. Our results highlight the enormous potential of quantum machine learning (QML) in biomedical image analysis.', 'abstract_zh': '参数化量子神经网络驱动的量子视觉变换器在生物医学图像分类中的性能研究', 'title_zh': '将知识精炼至量子视觉变换器以用于生物医学图像分类'}
{'arxiv_id': 'arXiv:2503.07279', 'title': 'VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication', 'authors': 'Xin Wang, Stephanie Tulk Jesso, Sadamori Kojaku, David M Neyens, Min Sun Kim', 'link': 'https://arxiv.org/abs/2503.07279', 'abstract': 'Trust plays a fundamental role in shaping the willingness of users to engage and collaborate with artificial intelligence (AI) systems. Yet, measuring user trust remains challenging due to its complex and dynamic nature. While traditional survey methods provide trust levels for long conversations, they fail to capture its dynamic evolution during ongoing interactions. Here, we present VizTrust, which addresses this challenge by introducing a real-time visual analytics tool that leverages a multi-agent collaboration system to capture and analyze user trust dynamics in human-agent communication. Built on established human-computer trust scales-competence, integrity, benevolence, and predictability-, VizTrust enables stakeholders to observe trust formation as it happens, identify patterns in trust development, and pinpoint specific interaction elements that influence trust. Our tool offers actionable insights into human-agent trust formation and evolution in real time through a dashboard, supporting the design of adaptive conversational agents that responds effectively to user trust signals.', 'abstract_zh': '信任在塑造用户参与和协作人工智能系统意愿方面发挥着基础性作用。然而，由于信任的复杂和动态性质，测量用户信任仍然颇具挑战。虽然传统的调查方法可以提供长时间对话的信任水平，但它们无法捕捉持续互动过程中信任动态演变的情况。在此，我们提出VizTrust，通过引入一个基于多代理协作系统的实时可视化分析工具来应对这一挑战，以捕获和分析人类-代理通信中的信任动态。基于已建立的人机信任尺度——能力、诚信、善意和可预测性，VizTrust使利益相关者能够实时观察信任的形成过程，识别信任发展的模式，并确定影响信任的具体交互要素。该工具通过仪表板提供实时的人机信任形成和演变的可操作洞察，支持设计出能够有效响应用户信任信号的自适应对话代理。', 'title_zh': 'VizTrust：一种捕获人类-人工智能通信中用户信任动态的可视化分析工具'}
{'arxiv_id': 'arXiv:2503.07272', 'title': 'Federated Learning in NTNs: Design, Architecture and Challenges', 'authors': 'Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu', 'link': 'https://arxiv.org/abs/2503.07272', 'abstract': "Non-terrestrial networks (NTNs) are emerging as a core component of future 6G communication systems, providing global connectivity and supporting data-intensive applications. In this paper, we propose a distributed hierarchical federated learning (HFL) framework within the NTN architecture, leveraging a high altitude platform station (HAPS) constellation as intermediate distributed FL servers. Our framework integrates both low-Earth orbit (LEO) satellites and ground clients in the FL training process while utilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as relays to exchange FL global models across other HAPS constellations worldwide, enabling seamless, global-scale learning. The proposed framework offers several key benefits: (i) enhanced privacy through the decentralization of the FL mechanism by leveraging the HAPS constellation, (ii) improved model accuracy and reduced training loss while balancing latency, (iii) increased scalability of FL systems through ubiquitous connectivity by utilizing MEO and GEO satellites, and (iv) the ability to use FL data, such as resource utilization metrics, to further optimize the NTN architecture from a network management perspective. A numerical study demonstrates the proposed framework's effectiveness, with improved model accuracy, reduced training loss, and efficient latency management. The article also includes a brief review of FL in NTNs and highlights key challenges and future research directions.", 'abstract_zh': 'NTN架构内的分布式层次联邦学习框架：利用高空平台站星座实现全球无缝学习', 'title_zh': 'NTN中的联邦学习：设计、架构与挑战'}
{'arxiv_id': 'arXiv:2503.07265', 'title': 'WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation', 'authors': 'Yuwei Niu, Munan Ning, Mengren Zheng, Bin Lin, Peng Jin, Jiaqi Liao, Kunpeng Ning, Bin Zhu, Li Yuan', 'link': 'https://arxiv.org/abs/2503.07265', 'abstract': 'Text-to-Image (T2I) models are capable of generating high-quality artistic creations and visual content. However, existing research and evaluation standards predominantly focus on image realism and shallow text-image alignment, lacking a comprehensive assessment of complex semantic understanding and world knowledge integration in text to image generation. To address this challenge, we propose $\\textbf{WISE}$, the first benchmark specifically designed for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic $\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by challenging models with 1000 meticulously crafted prompts across 25 sub-domains in cultural common sense, spatio-temporal reasoning, and natural science. To overcome the limitations of traditional CLIP metric, we introduce $\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image alignment. Through comprehensive testing of 20 models (10 dedicated T2I models and 10 unified multimodal models) using 1,000 structured prompts spanning 25 subdomains, our findings reveal significant limitations in their ability to effectively integrate and apply world knowledge during image generation, highlighting critical pathways for enhancing knowledge incorporation and application in next-generation T2I models. Code and data are available at this https URL.', 'abstract_zh': '基于世界知识的文本到图像语义评估 benchmarks（WISE）：超越简单的词-像素映射', 'title_zh': 'WISE：一种基于世界知识的语义评估方法用于文本到图像生成'}
{'arxiv_id': 'arXiv:2503.07259', 'title': 'COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric Human Activity Recognition', 'authors': 'Baiyu Chen, Wilson Wongso, Zechen Li, Yonchanok Khaokaew, Hao Xue, Flora Salim', 'link': 'https://arxiv.org/abs/2503.07259', 'abstract': 'Egocentric video-based models capture rich semantic information and have demonstrated strong performance in human activity recognition (HAR). However, their high power consumption, privacy concerns, and dependence on lighting conditions limit their feasibility for continuous on-device recognition. In contrast, inertial measurement unit (IMU) sensors offer an energy-efficient and privacy-preserving alternative, yet they suffer from limited large-scale annotated datasets, leading to weaker generalization in downstream tasks. To bridge this gap, we propose COMODO, a cross-modal self-supervised distillation framework that transfers rich semantic knowledge from the video modality to the IMU modality without requiring labeled annotations. COMODO leverages a pretrained and frozen video encoder to construct a dynamic instance queue, aligning the feature distributions of video and IMU embeddings. By distilling knowledge from video representations, our approach enables the IMU encoder to inherit rich semantic information from video while preserving its efficiency for real-world applications. Experiments on multiple egocentric HAR datasets demonstrate that COMODO consistently improves downstream classification performance, achieving results comparable to or exceeding fully supervised fine-tuned models. Moreover, COMODO exhibits strong cross-dataset generalization. Benefiting from its simplicity, our method is also generally applicable to various video and time-series pre-trained models, offering the potential to leverage more powerful teacher and student foundation models in future research. The code is available at this https URL .', 'abstract_zh': '基于自监督跨模态 distillation 的 COMODO 框架将丰富的语义知识从视频模态转移至 IMU 模态，以提高隐私保护并降低能耗，从而在持续的设备端活动识别任务中更可行。', 'title_zh': 'COMODO: 跨模态视频到IMU的精简学习以实现高效的第一人称人体活动识别'}
{'arxiv_id': 'arXiv:2503.07248', 'title': 'AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in Gastrointestinal Cancer Management', 'authors': 'Xinyu Nan, Meng He, Zifan Chen, Bin Dong, Lei Tang, Li Zhang', 'link': 'https://arxiv.org/abs/2503.07248', 'abstract': 'The incidence of gastrointestinal cancers remains significantly high, particularly in China, emphasizing the importance of accurate prognostic assessments and effective treatment strategies. Research shows a strong correlation between abdominal muscle and fat tissue composition and patient outcomes. However, existing manual methods for analyzing abdominal tissue composition are time-consuming and costly, limiting clinical research scalability. To address these challenges, we developed an AI-driven tool for automated analysis of abdominal CT scans to effectively identify and segment muscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view localization model and a high-precision 2D nnUNet-based segmentation model, demonstrating a localization accuracy of 90% and a Dice Score Coefficient of 0.967 for segmentation. Furthermore, it features an interactive interface that allows clinicians to refine the segmentation results, ensuring high-quality outcomes effectively. Our tool offers a standardized method for effectively extracting critical abdominal tissues, potentially enhancing the management and treatment for gastrointestinal cancers. The code is available at this https URL}{this https URL.', 'abstract_zh': '胃肠癌的发生率仍然显著偏高，尤其是在中国，强调了准确预后评估和有效治疗策略的重要性。研究显示腹部肌肉和脂肪组织组成与患者预后之间存在密切关联。然而，现有的手动方法分析腹部组织组成耗时且成本高，限制了临床研究的扩展性。为了解决这些问题，我们开发了一种基于人工智能的工具，用于自动化分析腹部CT扫描，有效识别和分割肌肉、皮下脂肪和 visceral 脂肪。该工具结合了多视图定位模型和基于高精度2D nnUNet的分割模型，定位准确率达到90%，分割Dice Score Coefficient为0.967。此外，该工具还具备互动界面，允许临床医生细化分割结果，确保高质量的输出。该工具提供了一种标准化的方法，用于有效提取关键腹部组织，可能有助于胃肠癌的管理和治疗。代码可在以下链接获取：this https URL', 'title_zh': '基于AI驱动的自动工具在胃肠癌管理中用于腹部CT身体成分分析'}
{'arxiv_id': 'arXiv:2503.07237', 'title': 'LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate Speech Moderation', 'authors': 'Junyeong Park, Seogyeong Jeong, Seyoung Song, Yohan Lee, Alice Oh', 'link': 'https://arxiv.org/abs/2503.07237', 'abstract': "Content moderation is a global challenge, yet major tech platforms prioritize high-resource languages, leaving low-resource languages with scarce native moderators. Since effective moderation depends on understanding contextual cues, this imbalance increases the risk of improper moderation due to non-native moderators' limited cultural understanding. Through a user study, we identify that non-native moderators struggle with interpreting culturally-specific knowledge, sentiment, and internet culture in the hate speech moderation. To assist them, we present LLM-C3MOD, a human-LLM collaborative pipeline with three steps: (1) RAG-enhanced cultural context annotations; (2) initial LLM-based moderation; and (3) targeted human moderation for cases lacking LLM consensus. Evaluated on a Korean hate speech dataset with Indonesian and German participants, our system achieves 78% accuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by 83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle. Our findings suggest that non-native moderators, when properly supported by LLMs, can effectively contribute to cross-cultural hate speech moderation.", 'abstract_zh': '内容审核是一个全球性的挑战，但主要科技平台优先考虑高资源语言，使低资源语言缺乏本土审核员。鉴于有效的审核依赖于对上下文线索的理解，这种不平衡增加了非本土审核员因文化理解有限而进行不当审核的风险。通过用户研究，我们发现非本土审核员在仇恨言论审核中难以解读文化特定的知识、情感和互联网文化。为此，我们提出了LLM-C3MOD，这是一种三人机协作流程，包含三个步骤：（1）RAG增强的文化背景注解；（2）基于LLM的初步审核；（3）针对LLM意见不一致的情况进行有针对性的人工审核。在包含韩、印尼和德语数据的仇恨言论数据集上评估，我们的系统达到了78%的准确率（超过GPT-4o的71%基线），同时减少了83.6%的人工工作量。值得注意的是，人类审核员在LLM难以处理的细微内容上表现出色。我们的研究结果表明，在适当的人工智能支持下，非本土审核员可以有效地参与跨文化仇恨言论审核。', 'title_zh': 'LLM-C3MOD: 一种跨文化仇恨言论 moderating 的人-大语言模型协作系统'}
{'arxiv_id': 'arXiv:2503.07234', 'title': 'CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting', 'authors': 'Haicheng Liao, Hanlin Kong, Bonan Wang, Chengyue Wang, Wang Ye, Zhengbing He, Chengzhong Xu, Zhenning Li', 'link': 'https://arxiv.org/abs/2503.07234', 'abstract': "Accurate motion forecasting is crucial for safe autonomous driving (AD). This study proposes CoT-Drive, a novel approach that enhances motion forecasting by leveraging large language models (LLMs) and a chain-of-thought (CoT) prompting method. We introduce a teacher-student knowledge distillation strategy to effectively transfer LLMs' advanced scene understanding capabilities to lightweight language models (LMs), ensuring that CoT-Drive operates in real-time on edge devices while maintaining comprehensive scene understanding and generalization capabilities. By leveraging CoT prompting techniques for LLMs without additional training, CoT-Drive generates semantic annotations that significantly improve the understanding of complex traffic environments, thereby boosting the accuracy and robustness of predictions. Additionally, we present two new scene description datasets, Highway-Text and Urban-Text, designed for fine-tuning lightweight LMs to generate context-specific semantic annotations. Comprehensive evaluations of five real-world datasets demonstrate that CoT-Drive outperforms existing models, highlighting its effectiveness and efficiency in handling complex traffic scenarios. Overall, this study is the first to consider the practical application of LLMs in this field. It pioneers the training and use of a lightweight LLM surrogate for motion forecasting, setting a new benchmark and showcasing the potential of integrating LLMs into AD systems.", 'abstract_zh': '准确的运动预测对于安全的自动驾驶（AD）至关重要。本文提出CoT-Drive，这是一种通过利用大规模语言模型（LLMs）和链式思考（CoT）提示方法来增强运动预测的新方法。我们引入了一种教师-学生知识蒸馏策略，有效地将LLMs的高级场景理解能力转移给轻量级语言模型（LMs），确保CoT-Drive可以在边缘设备上实现实时运行，同时保持全面的场景理解和泛化能力。通过利用CoT提示技术为LLMs生成语义注释，CoT-Drive可以在无需额外训练的情况下显著提高对复杂交通环境的理解，从而提升预测的准确性和鲁棒性。此外，我们还提出了两个新的场景描述数据集，Highway-Text和Urban-Text，用于对轻量级LMs进行微调以生成特定于上下文的语义注释。对五个真实世界数据集的全面评估表明，CoT-Drive优于现有模型，突显了其在处理复杂交通场景方面的有效性和效率。总体而言，本研究是首次将LLMs的实际应用纳入该领域的研究。它开创了轻量级LLM代理用于运动预测的训练和使用，设立了新的基准，并展示了将LLMs整合到AD系统中的潜力。', 'title_zh': 'CoT-Drive: 通过LLMs和链式思考提示实现高效自主驾驶运动预测'}
{'arxiv_id': 'arXiv:2503.07214', 'title': 'Cross-Lingual IPA Contrastive Learning for Zero-Shot NER', 'authors': 'Jimin Sohn, David R. Mortensen', 'link': 'https://arxiv.org/abs/2503.07214', 'abstract': 'Existing approaches to zero-shot Named Entity Recognition (NER) for low-resource languages have primarily relied on machine translation, whereas more recent methods have shifted focus to phonemic representation. Building upon this, we investigate how reducing the phonemic representation gap in IPA transcription between languages with similar phonetic characteristics enables models trained on high-resource languages to perform effectively on low-resource languages. In this work, we propose CONtrastive Learning with IPA (CONLIPA) dataset containing 10 English and high resource languages IPA pairs from 10 frequently used language families. We also propose a cross-lingual IPA Contrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our proposed dataset and methodology demonstrate a substantial average gain when compared to the best performing baseline.', 'abstract_zh': '基于音标表示的低资源语言零样本命名实体识别方法研究', 'title_zh': '跨语言IPA对比学习在零样本命名实体识别中的应用'}
{'arxiv_id': 'arXiv:2503.07210', 'title': 'Discrete Gaussian Process Representations for Optimising UAV-based Precision Weed Mapping', 'authors': 'Jacob Swindell, Madeleine Darbyshire, Marija Popovic, Riccardo Polvara', 'link': 'https://arxiv.org/abs/2503.07210', 'abstract': 'Accurate agricultural weed mapping using UAVs is crucial for precision farming applications. Traditional methods rely on orthomosaic stitching from rigid flight paths, which is computationally intensive and time-consuming. Gaussian Process (GP)-based mapping offers continuous modelling of the underlying variable (i.e. weed distribution) but requires discretisation for practical tasks like path planning or visualisation. Current implementations often default to quadtrees or gridmaps without systematically evaluating alternatives. This study compares five discretisation methods: quadtrees, wedgelets, top-down binary space partition (BSP) trees using least square error (LSE), bottom-up BSP trees using graph merging, and variable-resolution hexagonal grids. Evaluations on real-world weed distributions measure visual similarity, mean squared error (MSE), and computational efficiency. Results show quadtrees perform best overall, but alternatives excel in specific scenarios: hexagons or BSP LSE suit fields with large, dominant weed patches, while quadtrees are optimal for dispersed small-scale distributions. These findings highlight the need to tailor discretisation approaches to weed distribution patterns (patch size, density, coverage) rather than relying on default methods. By choosing representations based on the underlying distribution, we can improve mapping accuracy and efficiency for precision agriculture applications.', 'abstract_zh': '使用无人机实现精准农业杂草mapping的准确度对于精准农业应用至关重要。基于高斯过程的mapping提供了连续的变量建模，但需要离散化以用于路径规划或视觉化等实际任务。当前实现通常默认使用quadtrees或gridmaps而不系统地评估替代方法。本研究比较了五种离散化方法：quadtrees、wedgelets、自顶向下最少二乘误差（LSE）的二叉空间分割（BSP）树、自底向上基于图合并的BSP树以及可变分辨率六边形网格。通过实际杂草分布的评估，测量视觉相似度、均方误差（MSE）和计算效率。结果表明quadtrees整体表现最佳，但其他方法在特定场景中表现出色：六边形或基于LSE的BSP适用于大型主导性杂草斑块的田块，而quadtrees适用于分散的小规模分布。这些发现突显了根据杂草分布模式（斑块大小、密度、覆盖率）定制离散化方法的重要性，而不是依赖默认方法。通过基于底层分布选择表示方法，可以提高精准农业应用中mapping的准确性和效率。', 'title_zh': '基于无人机的精准杂草 mapping 优化的离散高斯过程表示方法'}
{'arxiv_id': 'arXiv:2503.07170', 'title': 'DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation', 'authors': 'Ming Wang, Fang Wang, Minghao Hu, Li He, Haiyang Wang, Jun Zhang, Tianwei Yan, Li Li, Zhunchen Luo, Wei Luo, Xiaoying Bai, Guotong Geng', 'link': 'https://arxiv.org/abs/2503.07170', 'abstract': 'Long-form article generation (LFAG) presents challenges such as maintaining logical consistency, comprehensive topic coverage, and narrative coherence across extended articles. Existing datasets often lack both the hierarchical structure and fine-grained annotation needed to effectively decompose tasks, resulting in shallow, disorganized article generation. To address these limitations, we introduce DeFine, a Decomposed and Fine-grained annotated dataset for long-form article generation. DeFine is characterized by its hierarchical decomposition strategy and the integration of domain-specific knowledge with multi-level annotations, ensuring granular control and enhanced depth in article generation. To construct the dataset, a multi-agent collaborative pipeline is proposed, which systematically segments the generation process into four parts: Data Miner, Cite Retreiver, Q&A Annotator and Data Cleaner. To validate the effectiveness of DeFine, we designed and tested three LFAG baselines: the web retrieval, the local retrieval, and the grounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine training dataset. The experimental results showed significant improvements in text quality, specifically in topic coverage, depth of information, and content fidelity. Our dataset publicly available to facilitate future research.', 'abstract_zh': '长文生成（LFAG）面临着保持逻辑一致性、全面的专题覆盖以及叙述连贯性的挑战。现有数据集往往缺乏有效分解任务所需的层级结构和细粒度标注，导致文章生成浅显且零散。为解决这些局限性，我们提出了一个分解和细粒度标注的数据集DeFine，用于长文生成。DeFine以其层级分解策略和领域特定知识与多层级标注的集成著称，确保了在文章生成中的粒度控制与深度增强。为构建该数据集，我们提出了一个多智能体协作管道，系统地将生成过程细分为四个部分：数据挖掘器、引文检索器、问答标注器和数据清理器。为了验证DeFine的有效性，我们设计并测试了三个LFAG基线模型：网页检索、本地检索和基于参考的模型。我们使用DeFine训练数据集微调了Qwen2-7b-Instruct模型。实验结果显示，在专题覆盖、信息深度和内容忠实度方面有显著改进。我们的数据集已公开，以促进未来的研究。', 'title_zh': 'DeFine: 一种分解和细粒度标注的数据集，用于长文生成'}
{'arxiv_id': 'arXiv:2503.07154', 'title': 'Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms', 'authors': 'Jiaming Song, Linqi Zhou', 'link': 'https://arxiv.org/abs/2503.07154', 'abstract': "Recent years have seen significant advancements in foundation models through generative pre-training, yet algorithmic innovation in this space has largely stagnated around autoregressive models for discrete signals and diffusion models for continuous signals. This stagnation creates a bottleneck that prevents us from fully unlocking the potential of rich multi-modal data, which in turn limits the progress on multimodal intelligence. We argue that an inference-first perspective, which prioritizes scaling efficiency during inference time across sequence length and refinement steps, can inspire novel generative pre-training algorithms. Using Inductive Moment Matching (IMM) as a concrete example, we demonstrate how addressing limitations in diffusion models' inference process through targeted modifications yields a stable, single-stage algorithm that achieves superior sample quality with over an order of magnitude greater inference efficiency.", 'abstract_zh': '近年来，生成预训练在基础模型中取得了显著进展，但在这一领域的算法创新主要集中在离散信号的自回归模型和连续信号的扩散模型上，这种创新停滞限制了我们充分利用丰富多模态数据的潜力，进而限制了多模态智能的发展。我们认为，在推理优先的观点下，即在推理时间和序列长度及细化步骤上的扩展效率优先，可以激发新的生成预训练算法。以归纳矩匹配（Inductive Moment Matching，IMM）为例，我们展示通过针对性的修改扩散模型的推理过程，可以得到一个稳定的一阶段算法，该算法在推理效率上提高了超过一个数量级的同时，还取得了更好的样本质量。', 'title_zh': '推理时缩放思想可以benefit生成预训练算法'}
{'arxiv_id': 'arXiv:2503.07153', 'title': 'PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning', 'authors': 'Yuanlong Wu, Mingxing Nie, Tao Zhu, Liming Chen, Huansheng Ning, Yaping Wan', 'link': 'https://arxiv.org/abs/2503.07153', 'abstract': 'Class-incremental learning (CIL) for time series data faces critical challenges in balancing stability against catastrophic forgetting and plasticity for new knowledge acquisition, particularly under real-world constraints where historical data access is restricted. While pre-trained models (PTMs) have shown promise in CIL for vision and NLP domains, their potential in time series class-incremental learning (TSCIL) remains underexplored due to the scarcity of large-scale time series pre-trained models. Prompted by the recent emergence of large-scale pre-trained models (PTMs) for time series data, we present the first exploration of PTM-based Time Series Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM backbones coupled with incrementally tuning the shared adapter, preserving generalization capabilities while mitigating feature drift through knowledge distillation. Furthermore, we introduce a Feature Drift Compensation Network (DCN), designed with a novel two-stage training strategy to precisely model feature space transformations across incremental tasks. This allows for accurate projection of old class prototypes into the new feature space. By employing DCN-corrected prototypes, we effectively enhance the unified classifier retraining, mitigating model feature drift and alleviating catastrophic forgetting. Extensive experiments on five real-world datasets demonstrate state-of-the-art performance, with our method yielding final accuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based approaches. Our work establishes a new paradigm for TSCIL, providing insights into stability-plasticity optimization for continual learning systems.', 'abstract_zh': '基于预训练模型的时间序列类增量学习（PTM-based Time Series Class-Incremental Learning）', 'title_zh': 'PTMs-TSCIL 预训练模型导向的类别增量学习'}
{'arxiv_id': 'arXiv:2503.07144', 'title': 'MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark', 'authors': 'Shengkun Ma, Hao Peng, Lei Hou, Juanzi Li', 'link': 'https://arxiv.org/abs/2503.07144', 'abstract': 'Machine Reading Comprehension (MRC) is an essential task in evaluating natural language understanding. Existing MRC datasets primarily assess specific aspects of reading comprehension (RC), lacking a comprehensive MRC benchmark. To fill this gap, we first introduce a novel taxonomy that categorizes the key capabilities required for RC. Based on this taxonomy, we construct MRCEval, an MRC benchmark that leverages advanced Large Language Models (LLMs) as both sample generators and selection judges. MRCEval is a comprehensive, challenging and accessible benchmark designed to assess the RC capabilities of LLMs thoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality multi-choice questions. We perform an extensive evaluation of 28 widely used open-source and proprietary models, highlighting that MRC continues to present significant challenges even in the era of LLMs.', 'abstract_zh': '机器阅读理解（MRC）是评估自然语言理解能力的重要任务。现有的MRC数据集主要评估阅读理解（RC）的特定方面，缺乏全面的MRC基准。为填补这一空白，我们首先引入了一种新型分类法，将关键的RC能力进行分类。基于这种分类法，我们构建了MRCEval，这是一个利用高级大型语言模型（LLMs）作为样本生成器和选择裁判的MRC基准。MRCEval是一个全面、具有挑战性和易访问的基准，旨在全面评估LLMs的RC能力，共涵盖13种不同的RC技能，总计2100个多选题。我们对28个广泛使用的开源和专有模型进行了广泛评估，突显了即使在LLM时代，MRC仍存在重大挑战。', 'title_zh': 'MRCEval: 一个全面、有挑战性和易于访问的机器阅读理解基准'}
{'arxiv_id': 'arXiv:2503.07137', 'title': 'A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications', 'authors': 'Siyuan Mu, Sen Lin', 'link': 'https://arxiv.org/abs/2503.07137', 'abstract': 'Artificial intelligence (AI) has achieved astonishing successes in many domains, especially with the recent breakthroughs in the development of foundational large models. These large models, leveraging their extensive training data, provide versatile solutions for a wide range of downstream tasks. However, as modern datasets become increasingly diverse and complex, the development of large AI models faces two major challenges: (1) the enormous consumption of computational resources and deployment difficulties, and (2) the difficulty in fitting heterogeneous and complex data, which limits the usability of the models. Mixture of Experts (MoE) models has recently attracted much attention in addressing these challenges, by dynamically selecting and activating the most relevant sub-models to process input data. It has been shown that MoEs can significantly improve model performance and efficiency with fewer resources, particularly excelling in handling large-scale, multimodal data. Given the tremendous potential MoE has demonstrated across various domains, it is urgent to provide a comprehensive summary of recent advancements of MoEs in many important fields. Existing surveys on MoE have their limitations, e.g., being outdated or lacking discussion on certain key areas, and we aim to address these gaps. In this paper, we first introduce the basic design of MoE, including gating functions, expert networks, routing mechanisms, training strategies, and system design. We then explore the algorithm design of MoE in important machine learning paradigms such as continual learning, meta-learning, multi-task learning, and reinforcement learning. Additionally, we summarize theoretical studies aimed at understanding MoE and review its applications in computer vision and natural language processing. Finally, we discuss promising future research directions.', 'abstract_zh': '人工智能（AI）在许多领域取得了惊人的成就，尤其是随着基础大型模型开发的突破性进展。这些大型模型利用其大量的训练数据，为广泛下游任务提供了多功能的解决方案。然而，随着现代数据集越来越多元化和复杂化，大型AI模型的开发面临两大挑战：（1）巨大的计算资源消耗和部署困难，以及（2）难以适应异构和复杂数据，这限制了模型的应用。专家混合模型（MoE）最近因其通过动态选择和激活最相关的子模型来处理输入数据而受到广泛关注，已被证明能显著提高模型性能和效率，尤其是在处理大规模、多模态数据方面尤为出色。鉴于MoE在各个领域展示出的巨大潜力，迫切需要对其在许多重要领域的最新进展进行全面总结。现有MoE综述存在局限性，如内容过时或缺乏对某些关键领域的讨论，我们致力于弥补这些不足。在本文中，我们首先介绍MoE的基本设计，包括门控函数、专家网络、路由机制、训练策略和系统设计。接着，我们探讨了MoE在连续学习、元学习、多任务学习和强化学习等重要机器学习范式中的算法设计。此外，我们总结了旨在理解MoE的理论研究，并回顾了MoE在计算机视觉和自然语言处理中的应用。最后，我们讨论了未来研究的有前景的方向。', 'title_zh': '专家混合模型综述：算法、理论与应用'}
{'arxiv_id': 'arXiv:2503.07129', 'title': 'ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization', 'authors': 'Deuksin Kwon, Jiwon Hae, Emma Clift, Daniel Shamsoddini, Jonathan Gratch, Gale M. Lucas', 'link': 'https://arxiv.org/abs/2503.07129', 'abstract': "Negotiation requires dynamically balancing self-interest and cooperation to maximize one's own utility. Yet, existing agents struggle due to bounded rationality in human data, low adaptability to counterpart behavior, and limited strategic reasoning. To address this, we introduce principle-driven negotiation agents, powered by ASTRA, a novel framework for turn-level offer optimization grounded in two core principles: opponent modeling and Tit-for-Tat reciprocity. ASTRA operates in three stages: (1) interpreting counterpart behavior, (2) optimizing counteroffers via a linear programming (LP) solver, and (3) selecting offers based on negotiation tactics and the partner's acceptance probability. Through simulations and human evaluations, our agent effectively adapts to an opponent's shifting stance and achieves favorable outcomes through enhanced adaptability and strategic reasoning. Beyond improving negotiation performance, it also serves as a powerful coaching tool, offering interpretable strategic feedback and optimal offer recommendations.", 'abstract_zh': '原则驱动的谈判代理：基于ASTRA的回合级报价优化框架', 'title_zh': 'ASTRA：一种在动态报价优化中具备适应性和战略推理的谈判代理'}
{'arxiv_id': 'arXiv:2503.07110', 'title': 'A LSTM-Transformer Model for pulsation control of pVADs', 'authors': 'Chaoran E, Chenghan Chen, Yuyang Shi, Haiyun Wang, Peixin Hua, Xiwen Zhang', 'link': 'https://arxiv.org/abs/2503.07110', 'abstract': 'Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model). AP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model. (1)The NPQ Model determines the mathematical relationship between motor speed, pressure, and flow rate for the pVAD. (2)The Attention module of Transformer neural network is integrated into the LSTM neural network to form the new LSTM-Transformer Model to predict the pulsation time characteristic points for adjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated in three hydraulic experiments and an animal experiment. (1)The pressure provided by pVAD calculated with the NPQ Model has a maximum error of only 2.15 mmHg compared to the expected values. (2)The pulsation time characteristic points predicted by the LSTM-Transformer Model shows a maximum prediction error of 1.78ms, which is significantly lower than other methods. (3)The in-vivo test of pVAD in animal experiment has significant improvements in aortic pressure. Animals survive for over 27 hours after the initiation of pVAD operation. Conclusion: (1)For a given pVAD, motor speed has a linear relationship with pressure and a quadratic relationship with flow. (2)Deep learning can be used to predict pulsation characteristic time points, with the LSTM-Transformer Model demonstrating minimal prediction error and better robust performance under conditions of limited dataset sizes, elevated noise levels, and diverse hyperparameter combinations, demonstrating its feasibility and effectiveness.', 'abstract_zh': '方法: 提出了一种用于血液泵助装置的脉动方法（AP-pVAD模型）。AP-pVAD模型由两部分组成：NPQ模型和LSTM-Transformer模型。(1)NPQ模型确定了血液泵助装置的电机速度、压力和流量之间的数学关系。(2)LSTM神经网络中的注意力模块被集成到Transformer神经网络中，形成新的LSTM-Transformer模型，以预测脉动时间特征点，进而调整血液泵助装置的电机速度。结果: AP-pVAD模型在三个液压实验和一个动物实验中得到验证。(1)使用NPQ模型计算的血液泵助装置提供的压力与预期值的最大误差仅为2.15 mmHg。(2)LSTM-Transformer模型预测的脉动时间特征点的最大预测误差为1.78ms，显著低于其他方法。(3)动物实验中血液泵助装置的体内测试显示了显著的主动脉压力改善，在启动血液泵助装置后，动物存活超过27小时。结论: (1)对于给定的血液泵助装置，电机速度与压力呈线性关系，与流量呈二次关系。(2)深度学习可用于预测脉动时间特征点，LSTM-Transformer模型在数据集较小、噪声水平较高和超参数组合多样化的情况下，显示出最小的预测误差和更好的稳健性能，证明了其可行性和有效性。', 'title_zh': '一种用于pVADs脉动控制的LSTM-Transformer模型'}
{'arxiv_id': 'arXiv:2503.07091', 'title': 'FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset', 'authors': 'Shuhe Wang, Xiaoya Li, Jiwei Li, Guoyin Wang, Xiaofei Sun, Bob Zhu, Han Qiu, Mo Yu, Shengjie Shen, Eduard Hovy', 'link': 'https://arxiv.org/abs/2503.07091', 'abstract': 'Due to the data-driven nature of current face identity (FaceID) customization methods, all state-of-the-art models rely on large-scale datasets containing millions of high-quality text-image pairs for training. However, none of these datasets are publicly available, which restricts transparency and hinders further advancements in the field.\nTo address this issue, in this paper, we collect and release FaceID-6M, the first large-scale, open-source FaceID dataset containing 6 million high-quality text-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M undergoes a rigorous image and text filtering steps to ensure dataset quality, including resolution filtering to maintain high-quality images and faces, face filtering to remove images that lack human faces, and keyword-based strategy to retain descriptions containing human-related terms (e.g., nationality, professions and names). Through these cleaning processes, FaceID-6M provides a high-quality dataset optimized for training powerful FaceID customization models, facilitating advancements in the field by offering an open resource for research and development.\nWe conduct extensive experiments to show the effectiveness of our FaceID-6M, demonstrating that models trained on our FaceID-6M dataset achieve performance that is comparable to, and slightly better than currently available industrial models. Additionally, to support and advance research in the FaceID customization community, we make our code, datasets, and models fully publicly available. Our codes, models, and datasets are available at: this https URL.', 'abstract_zh': '由于当前面部身份识别（FaceID）定制方法的数据驱动性质，所有最先进的模型都依赖于包含数百万高质量图文对的巨大数据集进行训练。然而，这些数据集均未公开，这限制了透明度并阻碍了该领域进一步的发展。\n\n为了解决这一问题，本文收集并发布了包含600万高质量图文对的第一大开源FaceID数据集FaceID-6M。该数据集从LAION-5B中筛选并经过严格的图像和文本筛选步骤以确保数据集质量，包括分辨率筛选以保持高质量图像和面部，面部筛选以去除缺少人类面部的图像，以及基于关键词的策略以保留包含与人类相关描述的内容（例如国籍、职业和姓名）。通过这些清理过程，FaceID-6M提供了一个优化用于训练强大FaceID定制模型的高质量数据集，通过提供用于研究和开发的开源资源推动该领域的进展。\n\n我们进行了广泛的实验以展示FaceID-6M的有效性，表明在我们的FaceID-6M数据集上训练的模型在性能上与当前可用的工业模型相当，甚至略好。此外，为了支持和促进面部身份识别定制社区的研究和进展，我们将我们的代码、数据集和模型完全公开。我们的代码、模型和数据集可在以下网址获取：this https URL', 'title_zh': 'FaceID-6M：一个大规模开源FaceID自定义数据集'}
{'arxiv_id': 'arXiv:2503.07082', 'title': 'On the Generalization of Representation Uncertainty in Earth Observation', 'authors': 'Spyros Kondylatos, Nikolaos Ioannis Bountos, Dimitrios Michail, Xiao Xiang Zhu, Gustau Camps-Valls, Ioannis Papoutsis', 'link': 'https://arxiv.org/abs/2503.07082', 'abstract': "Recent advances in Computer Vision have introduced the concept of pretrained representation uncertainty, enabling zero-shot uncertainty estimation. This holds significant potential for Earth Observation (EO), where trustworthiness is critical, yet the complexity of EO data poses challenges to uncertainty-aware methods. In this work, we investigate the generalization of representation uncertainty in EO, considering the domain's unique semantic characteristics. We pretrain uncertainties on large EO datasets and propose an evaluation framework to assess their zero-shot performance in multi-label classification and segmentation EO tasks. Our findings reveal that, unlike uncertainties pretrained on natural images, EO-pretraining exhibits strong generalization across unseen EO domains, geographic locations, and target granularities, while maintaining sensitivity to variations in ground sampling distance. We demonstrate the practical utility of pretrained uncertainties showcasing their alignment with task-specific uncertainties in downstream tasks, their sensitivity to real-world EO image noise, and their ability to generate spatial uncertainty estimates out-of-the-box. Initiating the discussion on representation uncertainty in EO, our study provides insights into its strengths and limitations, paving the way for future research in the field. Code and weights are available at: this https URL.", 'abstract_zh': '最近计算机视觉领域的进展引入了预训练表示不确定性概念，使其能够在零样本情况下进行不确定性估计。这一概念在地球观测（EO）中具有重要意义，因为信任度至关重要，但EO数据的复杂性对不确定性 aware 方法提出了挑战。本文研究了 EO 中表示不确定性的泛化能力，考虑了领域特有的语义特征。我们使用大型 EO 数据集预训练不确定性，并提出了一种评估其在多标签分类和分割任务中零样本性能的评估框架。我们的研究发现，与自然图像上预训练的不确定性不同，EO 预训练能够在未见过的 EO 领域、地理位置和目标粒度之间表现出强大的泛化能力，同时对地采样距离的变化保持敏感性。我们展示了预训练不确定性在下游任务中与任务特定不确定性的一致性，对真实世界 EO 图像噪声的敏感性，以及能够开箱即用生成空间不确定性估计的优势。本文开启了关于 EO 中表示不确定性的讨论，提供了其优势和局限性的见解，为该领域的未来研究奠定了基础。代码和权重可在以下地址获取：this https URL。', 'title_zh': '关于地球观测中表示不确定性的一般化研究'}
{'arxiv_id': 'arXiv:2503.07079', 'title': 'An Experience Report on Regression-Free Repair of Deep Neural Network Model', 'authors': 'Takao Nakagawa, Susumu Tokumoto, Shogo Tokui, Fuyuki Ishikawa', 'link': 'https://arxiv.org/abs/2503.07079', 'abstract': 'Systems based on Deep Neural Networks (DNNs) are increasingly being used in industry. In the process of system operation, DNNs need to be updated in order to improve their performance. When updating DNNs, systems used in companies that require high reliability must have as few regressions as possible. Since the update of DNNs has a data-driven nature, it is difficult to suppress regressions as expected by developers. This paper identifies the requirements for DNN updating in industry and presents a case study using techniques to meet those requirements. In the case study, we worked on satisfying the requirement to update models trained on car images collected in Fujitsu assuming security applications without regression for a specific class. We were able to suppress regression by customizing the objective function based on NeuRecover, a DNN repair technique. Moreover, we discuss some of the challenges identified in the case study.', 'abstract_zh': '基于深度神经网络的系统在工业中越来越广泛地被使用。在系统运行过程中，为了提高性能需要对深度神经网络（DNNs）进行更新。在进行DNN更新时，对于需要高可靠性的企业系统应尽量减少回归现象。由于DNN更新具有数据驱动的特性，开发人员很难按预期抑制回归现象。本文识别了工业中DNN更新的要求，并利用技术手段满足这些要求。在案例研究中，我们针对假设用于安全应用的汽车图像训练模型，制定了不针对特定类别的回归现象的更新要求，并通过基于NeuRecover的定制目标函数实现了回归现象的抑制。此外，本文还讨论了案例研究中遇到的一些挑战。', 'title_zh': '深度神经网络模型无回归修复经验报告'}
{'arxiv_id': 'arXiv:2503.07076', 'title': 'NFIG: Autoregressive Image Generation with Next-Frequency Prediction', 'authors': 'Zhihao Huang, Xi Qiu, Yukuo Ma, Yifu Zhou, Chi Zhang, Xuelong Li', 'link': 'https://arxiv.org/abs/2503.07076', 'abstract': 'Autoregressive models have achieved promising results in natural language processing. However, for image generation tasks, they encounter substantial challenges in effectively capturing long-range dependencies, managing computational costs, and most crucially, defining meaningful autoregressive sequences that reflect natural image hierarchies. To address these issues, we present \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration (\\textbf{NFIG}), a novel framework that decomposes the image generation process into multiple frequency-guided stages. Our approach first generates low-frequency components to establish global structure with fewer tokens, then progressively adds higher-frequency details, following the natural spectral hierarchy of images. This principled autoregressive sequence not only improves the quality of generated images by better capturing true causal relationships between image components, but also significantly reduces computational overhead during inference. Extensive experiments demonstrate that NFIG achieves state-of-the-art performance with fewer steps, offering a more efficient solution for image generation, with 1.25$\\times$ speedup compared to VAR-d20 while achieving better performance (FID: 2.81) on the ImageNet-256 benchmark. We hope that our insight of incorporating frequency-domain knowledge to guide autoregressive sequence design will shed light on future research. We will make our code publicly available upon acceptance of the paper.', 'abstract_zh': 'Next-Frequency Image Generation (NFIG)', 'title_zh': 'NFIG：基于下一频率预测的自回归图像生成'}
{'arxiv_id': 'arXiv:2503.07070', 'title': 'PIED: Physics-Informed Experimental Design for Inverse Problems', 'authors': 'Apivich Hemachandra, Gregory Kang Ruey Lau, See-Kiong Ng, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2503.07070', 'abstract': "In many science and engineering settings, system dynamics are characterized by governing PDEs, and a major challenge is to solve inverse problems (IPs) where unknown PDE parameters are inferred based on observational data gathered under limited budget. Due to the high costs of setting up and running experiments, experimental design (ED) is often done with the help of PDE simulations to optimize for the most informative design parameters to solve such IPs, prior to actual data collection. This process of optimizing design parameters is especially critical when the budget and other practical constraints make it infeasible to adjust the design parameters between trials during the experiments. However, existing experimental design (ED) methods tend to require sequential and frequent design parameter adjustments between trials. Furthermore, they also have significant computational bottlenecks due to the need for complex numerical simulations for PDEs, and do not exploit the advantages provided by physics informed neural networks (PINNs), such as its meshless solutions, differentiability, and amortized training. This work presents PIED, the first ED framework that makes use of PINNs in a fully differentiable architecture to perform continuous optimization of design parameters for IPs for one-shot deployments. PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization, and proposes novel methods to effectively take into account PINN training dynamics in optimizing the ED parameters. Through experiments based on noisy simulated data and even real world experimental data, we empirically show that given limited observation budget, PIED significantly outperforms existing ED methods in solving IPs, including challenging settings where the inverse parameters are unknown functions rather than just finite-dimensional.", 'abstract_zh': '基于PINNs的全程连续优化实验设计框架PIED', 'title_zh': 'PIED: 物理启发的实验设计用于逆问题'}
{'arxiv_id': 'arXiv:2503.07067', 'title': 'DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs', 'authors': 'Jongwoo Ko, Tianyi Chen, Sungnyun Kim, Tianyu Ding, Luming Liang, Ilya Zharkov, Se-Young Yun', 'link': 'https://arxiv.org/abs/2503.07067', 'abstract': 'Despite the success of distillation in large language models (LLMs), most prior work applies identical loss functions to both teacher- and student-generated data. These strategies overlook the synergy between loss formulations and data types, leading to a suboptimal performance boost in student models. To address this, we propose DistiLLM-2, a contrastive approach that simultaneously increases the likelihood of teacher responses and decreases that of student responses by harnessing this synergy. Our extensive experiments show that DistiLLM-2 not only builds high-performing student models across a wide range of tasks, including instruction-following and code generation, but also supports diverse applications, such as preference alignment and vision-language extensions. These findings highlight the potential of a contrastive approach to enhance the efficacy of LLM distillation by effectively aligning teacher and student models across varied data types.', 'abstract_zh': '尽管知识蒸馏在大型语言模型中取得了成功，但大多数前期工作对教师和学生生成的数据应用了相同的损失函数。这些策略忽视了损失函数形式与数据类型之间的协同作用，导致学生模型的性能提升不 optimal。为了解决这一问题，我们提出了一种对比式方法 DistiLLM-2，该方法通过利用这种协同作用同时增加教师响应的可能性并减少学生响应的可能性。我们的广泛实验表明，DistiLLM-2 不仅构建了在各种任务（包括指令跟随和代码生成）中性能优异的学生模型，还支持多种应用，如偏好对齐和视觉-语言扩展。这些发现凸显了对比式方法在通过有效对齐不同数据类型下的教师和学生模型来增强大型语言模型蒸馏效率的潜力。', 'title_zh': 'DistiLLM-2：一种对比增强的大型语言模型精简方法'}
{'arxiv_id': 'arXiv:2503.07056', 'title': 'Generative method for aerodynamic optimization based on classifier-free guided denoising diffusion probabilistic model', 'authors': 'Shisong Deng, Qiang Zhang, Zhengyang Cai', 'link': 'https://arxiv.org/abs/2503.07056', 'abstract': 'Inverse design approach, which directly generates optimal aerodynamic shape with neural network models to meet designated performance targets, has drawn enormous attention. However, the current state-of-the-art inverse design approach for airfoils, which is based on generative adversarial network, demonstrates insufficient precision in its generating and training processes and struggles to reveal the coupling relationship among specified performance indicators. To address these issues, the airfoil inverse design framework based on the classifier-free guided denoising diffusion probabilistic model (CDDPM) is proposed innovatively in this paper. First, the CDDPM can effectively capture the correlations among specific performance indicators and, by adjusting the classifier-free guide coefficient, generate corresponding upper and lower surface pressure coefficient distributions based on designated pressure features. These distributions are then accurately translated into airfoil geometries through a mapping model. Experimental results using classical transonic airfoils as examples show that the inverse design based on CDDPM can generate a variety of pressure coefficient distributions, which enriches the diversity of design results. Compared with current state-of-the-art Wasserstein generative adversarial network methods, CDDPM achieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a practical method to readjust each performance indicator value is proposed based on global optimization algorithm in conjunction with active learning strategy, aiming to provide rational value combination of performance indicators for the inverse design framework. This work is not only suitable for the airfoils design, but also has the capability to apply to optimization process of general product parts targeting selected performance indicators.', 'abstract_zh': '基于分类器免费引导去噪扩散概率模型的翼型逆设计框架', 'title_zh': '基于分类器-free 引导去噪扩散概率模型的气动优化生成方法'}
{'arxiv_id': 'arXiv:2503.07050', 'title': 'TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation', 'authors': 'Victor Shea-Jay Huang, Le Zhuo, Yi Xin, Zhaokai Wang, Peng Gao, Hongsheng Li', 'link': 'https://arxiv.org/abs/2503.07050', 'abstract': "Diffusion Transformers (DiTs) are a powerful yet underexplored class of generative models compared to U-Net-based diffusion models. To bridge this gap, we introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable Diffusion transformErs), a novel framework that enhances temporal reconstruction within DiT activation layers across denoising steps. TIDE employs Sparse Autoencoders (SAEs) with a sparse bottleneck layer to extract interpretable and hierarchical features, revealing that diffusion models inherently learn hierarchical features at multiple levels (e.g., 3D, semantic, class) during generative pre-training. Our approach achieves state-of-the-art reconstruction performance, with a mean squared error (MSE) of 1e-3 and a cosine similarity of 0.97, demonstrating superior accuracy in capturing activation dynamics along the denoising trajectory. Beyond interpretability, we showcase TIDE's potential in downstream applications such as sparse activation-guided image editing and style transfer, enabling improved controllability for generative systems. By providing a comprehensive training and evaluation protocol tailored for DiTs, TIDE contributes to developing more interpretable, transparent, and trustworthy generative models.", 'abstract_zh': '基于时间感知的稀疏自编码器增强的可解释扩散变换器（TIDE）：在去噪步骤中的时空重建增强', 'title_zh': 'TIDE： Awareness-Temporal 稀疏自编码器在图像生成中的可解释扩散变换器'}
{'arxiv_id': 'arXiv:2503.07044', 'title': 'DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science', 'authors': 'Ziming You, Yumiao Zhang, Dexuan Xu, Yiwei Lou, Yandong Yan, Wei Wang, Huaming Zhang, Yu Huang', 'link': 'https://arxiv.org/abs/2503.07044', 'abstract': "Data Science tasks are multifaceted, dynamic, and often domain-specific. Existing LLM-based approaches largely concentrate on isolated phases, neglecting the interdependent nature of many data science tasks and limiting their capacity for comprehensive end-to-end support. We propose DatawiseAgent, a notebook-centric LLM agent framework that unifies interactions among user, agent and the computational environment through markdown and executable code cells, supporting flexible and adaptive automated data science. Built on a Finite State Transducer(FST), DatawiseAgent orchestrates four stages, including DSF-like planning, incremental execution, self-debugging, and post-filtering. Specifically, the DFS-like planning stage systematically explores the solution space, while incremental execution harnesses real-time feedback and accommodates LLM's limited capabilities to progressively complete tasks. The self-debugging and post-filtering modules further enhance reliability by diagnosing and correcting errors and pruning extraneous information. Extensive experiments on diverse tasks, including data analysis, visualization, and data modeling, show that DatawiseAgent consistently outperforms or matches state-of-the-art methods across multiple model settings. These results highlight its potential to generalize across data science scenarios and lay the groundwork for more efficient, fully automated workflows.", 'abstract_zh': '数据科学任务多面、动态且往往具有领域特定性。现有的基于大模型的方法主要关注孤立阶段，忽视了众多数据科学任务间的相互依赖关系，限制了它们提供全面端到端支持的能力。我们提出了DatawiseAgent，这是一种以笔记本为中心的大模型代理框架，通过Markdown和可执行代码单元统一用户、代理和计算环境之间的交互，支持灵活且自适应的自动化数据科学。该框架基于有限状态转换器（FST），整合了包括类似于数据科学规划、增量执行、自我调试和后筛选在内的四个阶段。具体而言，类似于数据科学规划的阶段系统地探索了解空间，而增量执行阶段利用实时反馈并适应大模型的有限能力，逐步完成任务。自我调试和后筛选模块进一步增强了可靠性，通过诊断和纠正错误并消除多余信息来提高准确性。在包括数据分析、可视化和数据建模在内的多种任务上的广泛实验表明，DatawiseAgent在多种模型设置下均优于或匹配了现有最先进方法。这些结果突显了它在数据科学场景中的通用潜力，并为更高效、完全自动化的流程奠定了基础。', 'title_zh': 'DatawiseAgent: 以笔记本为中心的自动化数据科学LLM代理框架'}
{'arxiv_id': 'arXiv:2503.07036', 'title': 'Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike Against Phone Scams', 'authors': 'Nardine Basta, Conor Atkins, Dali Kaafar', 'link': 'https://arxiv.org/abs/2503.07036', 'abstract': 'We present "Bot Wars," a framework using Large Language Models (LLMs) scam-baiters to counter phone scams through simulated adversarial dialogues. Our key contribution is a formal foundation for strategy emergence through chain-of-thought reasoning without explicit optimization. Through a novel two-layer prompt architecture, our framework enables LLMs to craft demographically authentic victim personas while maintaining strategic coherence. We evaluate our approach using a dataset of 3,200 scam dialogues validated against 179 hours of human scam-baiting interactions, demonstrating its effectiveness in capturing complex adversarial dynamics. Our systematic evaluation through cognitive, quantitative, and content-specific metrics shows that GPT-4 excels in dialogue naturalness and persona authenticity, while Deepseek demonstrates superior engagement sustainability.', 'abstract_zh': '我们提出“Bot Wars”框架，该框架利用大型语言模型（LLMs）骗子诱饵通过模拟对抗对话来对抗电话诈骗。我们的主要贡献是在不需要明确优化的情况下，通过链式思考推理为策略 emergence 提供正式基础。通过一种新颖的两层提示架构，我们的框架使 LLMs 能够构建具有 demographic 实际性的受害者人设，同时保持战略连贯性。我们使用包含 3,200 个诈骗对话的数据集对我们的方法进行评估，该数据集基于 179 小时的人类骗子诱饵互动进行验证，展示了其在捕捉复杂对抗动态方面的有效性。通过对认知、定量和内容特定的指标进行系统评估，结果显示 GPT-4 在对话自然度和人设真实性方面表现出色，而 Deepseek 在持续互动方面表现出色。', 'title_zh': 'Bot战进化：在反电话诈骗战役中 orchestrating 竞争的LLMs'}
{'arxiv_id': 'arXiv:2503.07029', 'title': 'Availability-aware Sensor Fusion via Unified Canonical Space for 4D Radar, LiDAR, and Camera', 'authors': 'Dong-Hee Paek, Seung-Hyun Kong', 'link': 'https://arxiv.org/abs/2503.07029', 'abstract': 'Sensor fusion of camera, LiDAR, and 4-dimensional (4D) Radar has brought a significant performance improvement in autonomous driving (AD). However, there still exist fundamental challenges: deeply coupled fusion methods assume continuous sensor availability, making them vulnerable to sensor degradation and failure, whereas sensor-wise cross-attention fusion methods struggle with computational cost and unified feature representation. This paper presents availability-aware sensor fusion (ASF), a novel method that employs unified canonical projection (UCP) to enable consistency in all sensor features for fusion and cross-attention across sensors along patches (CASAP) to enhance robustness of sensor fusion against sensor degradation and failure. As a result, the proposed ASF shows a superior object detection performance to the existing state-of-the-art fusion methods under various weather and sensor degradation (or failure) conditions; Extensive experiments on the K-Radar dataset demonstrate that ASF achieves improvements of 9.7% in AP BEV (87.2%) and 20.1% in AP 3D (73.6%) in object detection at IoU=0.5, while requiring a low computational cost. The code will be available at this https URL.', 'abstract_zh': '基于摄像头、LiDAR和4D雷达的传感器融合方法在自动驾驶中的性能提升：一种适应性传感器融合（ASF）方法', 'title_zh': '面向4D雷达、LiDAR和相机的基于统一规范空间的可用性感知传感器融合'}
{'arxiv_id': 'arXiv:2503.07026', 'title': 'Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways', 'authors': 'Yi Liu, Hao Zhou, Wenxiang Shang, Ran Lin, Benlei Cui', 'link': 'https://arxiv.org/abs/2503.07026', 'abstract': 'Erase inpainting, or object removal, aims to precisely remove target objects within masked regions while preserving the overall consistency of the surrounding content. Despite diffusion-based methods have made significant strides in the field of image inpainting, challenges remain regarding the emergence of unexpected objects or artifacts. We assert that the inexact diffusion pathways established by existing standard optimization paradigms constrain the efficacy of object removal. To tackle these challenges, we propose a novel Erase Diffusion, termed EraDiff, aimed at unleashing the potential power of standard diffusion in the context of object removal. In contrast to standard diffusion, the EraDiff adapts both the optimization paradigm and the network to improve the coherence and elimination of the erasure results. We first introduce a Chain-Rectifying Optimization (CRO) paradigm, a sophisticated diffusion process specifically designed to align with the objectives of erasure. This paradigm establishes innovative diffusion transition pathways that simulate the gradual elimination of objects during optimization, allowing the model to accurately capture the intent of object removal. Furthermore, to mitigate deviations caused by artifacts during the sampling pathways, we develop a simple yet effective Self-Rectifying Attention (SRA) mechanism. The SRA calibrates the sampling pathways by altering self-attention activation, allowing the model to effectively bypass artifacts while further enhancing the coherence of the generated content. With this design, our proposed EraDiff achieves state-of-the-art performance on the OpenImages V5 dataset and demonstrates significant superiority in real-world scenarios.', 'abstract_zh': '基于擦除的扩散模型：EraDiff，用于目标去除中的精确擦除 inpainting', 'title_zh': '擦除扩散：通过校准扩散路径实现物体删除'}
{'arxiv_id': 'arXiv:2503.07025', 'title': 'Weak Supervision for Improved Precision in Search Systems', 'authors': 'Sriram Vasudevan', 'link': 'https://arxiv.org/abs/2503.07025', 'abstract': 'Labeled datasets are essential for modern search engines, which increasingly rely on supervised learning methods like Learning to Rank and massive amounts of data to power deep learning models. However, creating these datasets is both time-consuming and costly, leading to the common use of user click and activity logs as proxies for relevance. In this paper, we present a weak supervision approach to infer the quality of query-document pairs and apply it within a Learning to Rank framework to enhance the precision of a large-scale search system.', 'abstract_zh': '标记数据集对于现代搜索引擎至关重要，这些搜索引擎越来越多地依赖于如学习排名等监督学习方法和大量数据来驱动深度学习模型。然而，创建这些数据集既耗时又昂贵，因此常用用户点击和活动日志作为相关性的代理。在本文中，我们提出了一种弱监督方法来推断查询-文档对的质量，并将其应用于学习排名框架中，以提高大规模搜索引擎的精度。', 'title_zh': '弱监督以提高搜索系统的精度'}
{'arxiv_id': 'arXiv:2503.07020', 'title': 'Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense', 'authors': 'Yuting Hu, Chenhui Xu, Ruiyang Qin, Dancheng Liu, Amir Nassereldine, Yiyu Shi, Jinjun Xiong', 'link': 'https://arxiv.org/abs/2503.07020', 'abstract': 'Partial perception deficits can compromise autonomous vehicle safety by disrupting environmental understanding. Current protocols typically respond with immediate stops or minimal-risk maneuvers, worsening traffic flow and lacking flexibility for rare driving scenarios. In this paper, we propose LLM-RCO, a framework leveraging large language models to integrate human-like driving commonsense into autonomous systems facing perception deficits. LLM-RCO features four key modules: hazard inference, short-term motion planner, action condition verifier, and safety constraint generator. These modules interact with the dynamic driving environment, enabling proactive and context-aware control actions to override the original control policy of autonomous agents. To improve safety in such challenging conditions, we construct DriveLM-Deficit, a dataset of 53,895 video clips featuring deficits of safety-critical objects, complete with annotations for LLM-based hazard inference and motion planning fine-tuning. Extensive experiments in adverse driving conditions with the CARLA simulator demonstrate that systems equipped with LLM-RCO significantly improve driving performance, highlighting its potential for enhancing autonomous driving resilience against adverse perception deficits. Our results also show that LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements instead of conservative stops in the context of perception deficits.', 'abstract_zh': '感知缺陷会通过干扰环境理解来损害自主车辆的安全。当前的协议通常会立即停车或执行最小风险操作，这会恶化交通流量并且缺乏应对罕见驾驶场景的灵活性。在本文中，我们提出了LLM-RCO框架，利用大规模语言模型将类似人类驾驶的经验常识整合到面临感知缺陷的自主系统中。LLM-RCO包含四个关键模块：危险推断、短期运动规划器、动作条件验证器和安全约束生成器。这些模块与动态驾驶环境互动，使系统能够采取先发制人且情境感知的控制行动，以覆盖原始的自主代理控制策略。为了在这些具有挑战性的条件下提高安全性，我们构建了包含53,895个视频片段的DriveLM-Deficit数据集，这些片段展示了关键安全对象的缺陷，并附有基于LLM的危险推断和运动规划微调的注释。在使用CARLA模拟器进行的恶劣驾驶条件下的广泛实验中，装有LLM-RCO的系统显著提高了驾驶性能，突显了其在对抗不良感知缺陷方面增强自主驾驶弹性的潜力。我们的结果还表明，在感知缺陷的背景下，通过DriveLM-Deficit微调的LLM能够使车辆采取更加积极的移动行为，而非保守地停车。', 'title_zh': '利用多模态LLM常识对抗自动驾驶中的部分知觉缺陷'}
{'arxiv_id': 'arXiv:2503.07004', 'title': 'NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform Domain Alignment', 'authors': 'Jiaojiao Li, Shiyao Duan, Haitao XU, Rui Song', 'link': 'https://arxiv.org/abs/2503.07004', 'abstract': 'The inherent difficulty in acquiring accurately co-registered RGB-hyperspectral image (HSI) pairs has significantly impeded the practical deployment of current data-driven Hyperspectral Image Generation (HIG) networks in engineering applications. Gleichzeitig, the ill-posed nature of the aligning constraints, compounded with the complexities of mining cross-domain features, also hinders the advancement of unpaired HIG (UnHIG) tasks. In this paper, we conquer these challenges by modeling the UnHIG to range space interaction and compensations of null space through Range-Null Space Decomposition (RND) methodology. Specifically, the introduced contrastive learning effectively aligns the geometric and spectral distributions of unpaired data by building the interaction of range space, considering the consistent feature in degradation process. Following this, we map the frequency representations of dual-domain input and thoroughly mining the null space, like degraded and high-frequency components, through the proposed Non-uniform Kolmogorov-Arnold Networks. Extensive comparative experiments demonstrate that it establishes a new benchmark in UnHIG.', 'abstract_zh': '非配对高光谱图像生成中的固有难度显著阻碍了当前数据驱动的高光谱图像生成网络在工程应用中的实际部署。同时，对齐约束的不良性质与跨域特征提取的复杂性也阻碍了无配对高光谱图像生成（UnHIG）任务的发展。本文通过范围空间和零空间交互与补偿的范围-零空间分解（RND）方法克服了这些挑战。具体而言，引入的对比学习通过建立范围空间的交互来有效对齐无配对数据的几何和光谱分布，考虑到退化过程中的一致特征。随后，我们通过所提出的非均匀柯尔莫哥洛夫-阿诺尔德网络映射双域输入的频率表示，并全面挖掘零空间，如退化和高频成分。广泛的对比实验表明，它在无配对高光谱图像生成中建立了新的基准。', 'title_zh': 'NukesFormers: 无配对高光谱图像生成与非均匀域对齐'}
{'arxiv_id': 'arXiv:2503.06987', 'title': 'Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations', 'authors': 'Jiho Jin, Woosung Kang, Junho Myung, Alice Oh', 'link': 'https://arxiv.org/abs/2503.06987', 'abstract': 'Measuring social bias in large language models (LLMs) is crucial, but existing bias evaluation methods struggle to assess bias in long-form generation. We propose a Bias Benchmark for Generation (BBG), an adaptation of the Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form generation by having LLMs generate continuations of story prompts. Building our benchmark in English and Korean, we measure the probability of neutral and biased generations across ten LLMs. We also compare our long-form story generation evaluation results with multiple-choice BBQ evaluation, showing that the two approaches produce inconsistent results.', 'abstract_zh': '测量大规模语言模型中的社会偏见至关重要，但现有偏见评估方法难以评估长文本生成中的偏见。我们提出了一个生成偏见基准（BBG），这是针对问答偏见基准（BBQ）的适应版本，用于通过让语言模型生成故事提示的续写来评估长文本生成中的社会偏见。我们在英语和韩语下构建了这一基准，测量了十种语言模型生成中立和有偏见文本的概率。我们还将我们的长文本故事生成评估结果与多项选择题型的BBQ评估结果进行了比较，结果显示两种方法产生了不一致的结果。', 'title_zh': '生成任务中的社会偏见基准：生成式评估与QA式评估的比较'}
{'arxiv_id': 'arXiv:2503.06982', 'title': 'Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization', 'authors': 'Ziqing Xu, Hancheng Min, Lachlan Ewen MacDonald, Jinqi Luo, Salma Tarmoun, Enrique Mallada, Rene Vidal', 'link': 'https://arxiv.org/abs/2503.06982', 'abstract': 'Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning pre-trained models, there is little theoretical understanding of how first-order methods with carefully crafted initialization adapt models to new tasks. In this work, we take the first step towards bridging this gap by theoretically analyzing the learning dynamics of LoRA for matrix factorization (MF) under gradient flow (GF), emphasizing the crucial role of initialization. For small initialization, we theoretically show that GF converges to a neighborhood of the optimal solution, with smaller initialization leading to lower final error. Our analysis shows that the final error is affected by the misalignment between the singular spaces of the pre-trained model and the target matrix, and reducing the initialization scale improves alignment. To address this misalignment, we propose a spectral initialization for LoRA in MF and theoretically prove that GF with small spectral initialization converges to the fine-tuning task with arbitrary precision. Numerical experiments from MF and image classification validate our findings.', 'abstract_zh': '尽管低秩适应（LoRA）在微调预训练模型方面取得了经验上的成功，但对于精心设计初始化的一阶方法如何适应新任务，仍缺乏理论上的理解。本文首先通过分析梯度流动（GF）下LoRA在矩阵分解（MF）中的学习动态，尝试弥合这一差距，强调初始化的关键作用。对于小型初始化，我们理论上证明GF收敛到最优解的邻域，更小的初始化导致最终误差更低。我们的分析指出，最终误差受到预训练模型的奇异空间与目标矩阵之间的错位影响，并通过减少初始化规模可以改善这种错位。为了缓解这种错位，我们提出了适用于MF的谱初始化方法，并理论上证明了使用小型谱初始化的GF可以以任意精度收敛到微调任务。来自矩阵分解和图像分类的数值实验验证了我们的发现。', 'title_zh': '基于矩阵因子分解中低秩适应的梯度流视角下理解LoRA的learning动态'}
{'arxiv_id': 'arXiv:2503.06978', 'title': 'Lightweight Multimodal Artificial Intelligence Framework for Maritime Multi-Scene Recognition', 'authors': 'Xinyu Xi, Hua Yang, Shentai Zhang, Yijie Liu, Sijin Sun, Xiuju Fu', 'link': 'https://arxiv.org/abs/2503.06978', 'abstract': 'Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of intelligent marine robotics, particularly in applications such as marine conservation, environmental monitoring, and disaster response. However, this task presents significant challenges due to environmental interference, where marine conditions degrade image quality, and the complexity of maritime scenes, which requires deeper reasoning for accurate recognition. Pure vision models alone are insufficient to address these issues. To overcome these limitations, we propose a novel multimodal Artificial Intelligence (AI) framework that integrates image data, textual descriptions and classification vectors generated by a Multimodal Large Language Model (MLLM), to provide richer semantic understanding and improve recognition accuracy. Our framework employs an efficient multimodal fusion mechanism to further enhance model robustness and adaptability in complex maritime environments. Experimental results show that our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by 3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt activation-aware weight quantization (AWQ) as a lightweight technique, reducing the model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly lowering computational overhead. This work provides a high-performance solution for real-time maritime scene recognition, enabling Autonomous Surface Vehicles (ASVs) to support environmental monitoring and disaster response in resource-limited settings.', 'abstract_zh': '海上多场景识别对于提升智能海洋机器人能力至关重要，特别是在海洋保护、环境监测和灾害响应等应用中。然而，由于环境干扰导致的图像质量问题以及海上场景的复杂性，使这一任务面临巨大挑战，要求进行更深层次的推理以确保准确识别。仅依赖纯视觉模型无法解决这些问题。为克服这些局限性，我们提出了一种新颖的多模态人工智能框架，该框架结合了图像数据、由多模态大语言模型（MLLM）生成的文本描述和分类向量，提供更丰富的语义理解并提高识别准确性。我们的框架采用高效的多模态融合机制，进一步增强模型在复杂海洋环境中的鲁棒性和适应性。实验结果表明，我们的模型准确率达到98%，比 previous SOTA 模型高3.5%。为了优化在资源受限平台上的部署，我们采用了激活意识权重量化（AWQ）作为一种轻量级技术，使模型大小减小到68.75MB，准确率仅下降0.5%，并显著降低了计算开销。这项工作提供了一种高性能的实时海上场景识别解决方案，使自主水面车辆（ASVs）能够在资源受限的环境中支持环境监测和灾害响应。', 'title_zh': '轻量级多模态人工智能框架海上多场景识别'}
{'arxiv_id': 'arXiv:2503.06973', 'title': 'A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis', 'authors': 'Xiang Liu, Zhaoxiang Liu, Huan Hu, Zezhou Chen, Kohou Wang, Kai Wang, Shiguo Lian', 'link': 'https://arxiv.org/abs/2503.06973', 'abstract': 'While conversational generative AI has shown considerable potential in enhancing decision-making for agricultural professionals, its exploration has predominantly been anchored in text-based interactions. The evolution of multimodal conversational AI, leveraging vast amounts of image-text data from diverse sources, marks a significant stride forward. However, the application of such advanced vision-language models in the agricultural domain, particularly for crop disease diagnosis, remains underexplored. In this work, we present the crop disease domain multimodal (CDDM) dataset, a pioneering resource designed to advance the field of agricultural research through the application of multimodal learning techniques. The dataset comprises 137,000 images of various crop diseases, accompanied by 1 million question-answer pairs that span a broad spectrum of agricultural knowledge, from disease identification to management practices. By integrating visual and textual data, CDDM facilitates the development of sophisticated question-answering systems capable of providing precise, useful advice to farmers and agricultural professionals. We demonstrate the utility of the dataset by finetuning state-of-the-art multimodal models, showcasing significant improvements in crop disease diagnosis. Specifically, we employed a novel finetuning strategy that utilizes low-rank adaptation (LoRA) to finetune the visual encoder, adapter and language model simultaneously. Our contributions include not only the dataset but also a finetuning strategy and a benchmark to stimulate further research in agricultural technology, aiming to bridge the gap between advanced AI techniques and practical agricultural applications. The dataset is available at https: //github.com/UnicomAI/UnicomBenchmark/tree/main/CDDMBench.', 'abstract_zh': '面向农作物疾病的多模态数据集（CDDM）：推动农业研究的多模态学习技术应用', 'title_zh': '多模态作物病害诊断数据集与模型'}
{'arxiv_id': 'arXiv:2503.06963', 'title': 'Multi-Behavior Recommender Systems: A Survey', 'authors': 'Kyungho Kim, Sunwoo Kim, Geon Lee, Jinhong Jung, Kijung Shin', 'link': 'https://arxiv.org/abs/2503.06963', 'abstract': 'Traditional recommender systems primarily rely on a single type of user-item interaction, such as item purchases or ratings, to predict user preferences. However, in real-world scenarios, users engage in a variety of behaviors, such as clicking on items or adding them to carts, offering richer insights into their interests. Multi-behavior recommender systems leverage these diverse interactions to enhance recommendation quality, and research on this topic has grown rapidly in recent years. This survey provides a timely review of multi-behavior recommender systems, focusing on three key steps: (1) Data Modeling: representing multi-behaviors at the input level, (2) Encoding: transforming these inputs into vector representations (i.e., embeddings), and (3) Training: optimizing machine-learning models. We systematically categorize existing multi-behavior recommender systems based on the commonalities and differences in their approaches across the above steps. Additionally, we discuss promising future directions for advancing multi-behavior recommender systems.', 'abstract_zh': '传统推荐系统主要依赖于单一类型的用户-项交互，如购买或评分，以预测用户偏好。然而，在现实场景中，用户表现出多种行为，如点击物品或将物品加入购物车，这些行为提供了更多关于用户兴趣的洞察。多行为推荐系统通过利用这些多样化的交互来提升推荐质量，近年来该领域的研究迅速增长。本文提供了一篇关于多行为推荐系统的及时综述，重点关注三个关键步骤：(1) 数据建模：在输入层面表示多种行为，(2) 编码：将这些输入转换为向量表示（即嵌入），以及(3) 训练：优化机器学习模型。我们系统地根据上述步骤中的共性和差异对现有的多行为推荐系统进行了分类。此外，我们还讨论了推进多行为推荐系统发展的有希望的新方向。', 'title_zh': '多行为推荐系统：文献综述'}
{'arxiv_id': 'arXiv:2503.06962', 'title': 'Capture Global Feature Statistics for One-Shot Federated Learning', 'authors': 'Zenghao Guan, Yucan Zhou, Xiaoyan Gu', 'link': 'https://arxiv.org/abs/2503.06962', 'abstract': 'Traditional Federated Learning (FL) necessitates numerous rounds of communication between the server and clients, posing significant challenges including high communication costs, connection drop risks and susceptibility to privacy attacks. One-shot FL has become a compelling learning paradigm to overcome above drawbacks by enabling the training of a global server model via a single communication round. However, existing one-shot FL methods suffer from expensive computation cost on the server or clients and cannot deal with non-IID (Independent and Identically Distributed) data stably and effectively. To address these challenges, this paper proposes FedCGS, a novel Federated learning algorithm that Capture Global feature Statistics leveraging pre-trained models. With global feature statistics, we achieve training-free and heterogeneity-resistant one-shot FL. Furthermore, we extend its application to personalization scenario, where clients only need execute one extra communication round with server to download global statistics. Extensive experimental results demonstrate the effectiveness of our methods across diverse data heterogeneity settings. Code is available at this https URL.', 'abstract_zh': '传统的联邦学习（FL）需要服务器与客户端进行多轮通信，这带来了高通信成本、连接中断风险及隐私攻击的脆弱性挑战。单轮次联邦学习已成为克服上述问题的一种有吸引力的学习范式，通过单一通信轮次即可训练全局服务器模型。然而，现有的单轮次联邦学习方法在服务器或客户端的计算成本高昂，并且在处理非IID数据时表现不稳定和不有效。为应对这些挑战，本文提出了一种名为FedCGS的新颖联邦学习算法，该算法利用预训练模型捕获全局特征统计。借助全局特征统计，我们实现了无需训练且具有异构性抵抗能力的单轮次联邦学习。此外，我们将其应用扩展到个性化场景，客户端仅需额外与服务器执行一轮通信以下载全局统计。广泛的经验结果证明了我们的方法在多种数据异构性设置下的有效性。代码详见这个链接。', 'title_zh': '捕获全局特征统计用于一-shot联邦学习'}
{'arxiv_id': 'arXiv:2503.06948', 'title': 'Large Language Model Guided Progressive Feature Alignment for Multimodal UAV Object Detection', 'authors': 'Wentao Wu, Chenglong Li, Xiao Wang, Bin Luo, Qi Liu', 'link': 'https://arxiv.org/abs/2503.06948', 'abstract': 'Existing multimodal UAV object detection methods often overlook the impact of semantic gaps between modalities, which makes it difficult to achieve accurate semantic and spatial alignments, limiting detection performance. To address this problem, we propose a Large Language Model (LLM) guided Progressive feature Alignment Network called LPANet, which leverages the semantic features extracted from a large language model to guide the progressive semantic and spatial alignment between modalities for multimodal UAV object detection. To employ the powerful semantic representation of LLM, we generate the fine-grained text descriptions of each object category by ChatGPT and then extract the semantic features using the large language model MPNet. Based on the semantic features, we guide the semantic and spatial alignments in a progressive manner as follows. First, we design the Semantic Alignment Module (SAM) to pull the semantic features and multimodal visual features of each object closer, alleviating the semantic differences of objects between modalities. Second, we design the Explicit Spatial alignment Module (ESM) by integrating the semantic relations into the estimation of feature-level offsets, alleviating the coarse spatial misalignment between modalities. Finally, we design the Implicit Spatial alignment Module (ISM), which leverages the cross-modal correlations to aggregate key features from neighboring regions to achieve implicit spatial alignment. Comprehensive experiments on two public multimodal UAV object detection datasets demonstrate that our approach outperforms state-of-the-art multimodal UAV object detectors.', 'abstract_zh': '基于大型语言模型引导的逐步特征对齐网络LPANet多模态无人机目标检测', 'title_zh': '大型语言模型引导的渐进式特征对齐在多模态无人机目标检测中的应用'}
{'arxiv_id': 'arXiv:2503.06926', 'title': 'Effect of Selection Format on LLM Performance', 'authors': 'Yuchen Han, Yucheng Wu, Jeffrey Willard', 'link': 'https://arxiv.org/abs/2503.06926', 'abstract': 'This paper investigates a critical aspect of large language model (LLM) performance: the optimal formatting of classification task options in prompts. Through an extensive experimental study, we compared two selection formats -- bullet points and plain English -- to determine their impact on model performance. Our findings suggest that presenting options via bullet points generally yields better results, although there are some exceptions. Furthermore, our research highlights the need for continued exploration of option formatting to drive further improvements in model performance.', 'abstract_zh': '本文探讨了大型语言模型（LLM）性能的一个关键方面：提示中分类任务选项的最佳格式化方式。通过一项广泛的实验研究，我们将两种选择格式——项目符号和纯英文——进行了对比，以确定它们对模型性能的影响。我们的研究表明，通常通过项目符号呈现选项能获得更好的结果，尽管存在一些例外情况。此外，我们的研究强调了继续探索选项格式化以推动模型性能进一步提升的必要性。', 'title_zh': '选择格式对大语言模型性能的影响'}
{'arxiv_id': 'arXiv:2503.06923', 'title': 'From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers', 'authors': 'Jiacheng Liu, Chang Zou, Yuanhuiyi Lyu, Junjie Chen, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2503.06923', 'abstract': 'Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the supplementary materials and will be made publicly available on GitHub. Our codes have been released in Github:this https URL', 'abstract_zh': 'TaylorSeer: 基于泰勒级数扩展的扩散模型未来时间步特征预测', 'title_zh': '从重用到预测：使用TaylorSeers加速扩散模型'}
{'arxiv_id': 'arXiv:2503.06894', 'title': 'Improving cognitive diagnostics in pathology: a deep learning approach for augmenting perceptional understanding of histopathology images', 'authors': 'Xiaoqian Hu', 'link': 'https://arxiv.org/abs/2503.06894', 'abstract': 'In Recent Years, Digital Technologies Have Made Significant Strides In Augmenting-Human-Health, Cognition, And Perception, Particularly Within The Field Of Computational-Pathology. This Paper Presents A Novel Approach To Enhancing The Analysis Of Histopathology Images By Leveraging A Mult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image Captioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which Includes Dense Image Captions Derived From Clinical And Academic Resources, To Capture The Complexities Of Pathology Images Such As Tissue Morphologies, Staining Variations, And Pathological Conditions. By Generating Accurate, Contextually Captions, The Model Augments The Cognitive Capabilities Of Healthcare Professionals, Enabling More Efficient Disease Classification, Segmentation, And Detection. The Model Enhances The Perception Of Subtle Pathological Features In Images That Might Otherwise Go Unnoticed, Thereby Improving Diagnostic Accuracy. Our Approach Demonstrates The Potential For Digital Technologies To Augment Human Cognitive Abilities In Medical Image Analysis, Providing Steps Toward More Personalized And Accurate Healthcare Outcomes.', 'abstract_zh': '近年来，数字技术在增强人类健康、认知和感知方面取得了显著进展，特别是体现在计算病理学领域。本文提出了一种通过结合视觉变换器（ViT）和GPT-2进行图像描述的新方法，以提升组织病理学图像的分析能力。该模型在专门的Arch-数据集上进行微调，该数据集包含从临床和学术资源提取的密集图像描述，用于捕捉病理学图像的复杂性，如组织形态、染色变异和病理状况。通过生成准确且上下文相关的描述，该模型增强了医疗保健专业人员的认知能力，有助于更高效地进行疾病分类、分割和检测。该模型增强了对图像中细微病理特征的感知，从而提高了诊断准确性。本文展示了数字技术在医学图像分析中增强人类认知能力的潜力，朝着更个性化和准确的 healthcare 出come迈进。', 'title_zh': '提升病理认知诊断：一种增强组织病理图像感知理解的深度学习方法'}
{'arxiv_id': 'arXiv:2503.06893', 'title': 'Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning', 'authors': 'Zhenghai Xue, Lang Feng, Jiacheng Xu, Kang Kang, Xiang Wen, Bo An, Shuicheng Yan', 'link': 'https://arxiv.org/abs/2503.06893', 'abstract': "To learn from data collected in diverse dynamics, Imitation from Observation (IfO) methods leverage expert state trajectories based on the premise that recovering expert state distributions in other dynamics facilitates policy learning in the current one. However, Imitation Learning inherently imposes a performance upper bound of learned policies. Additionally, as the environment dynamics change, certain expert states may become inaccessible, rendering their distributions less valuable for imitation. To address this, we propose a novel framework that integrates reward maximization with IfO, employing F-distance regularized policy optimization. This framework enforces constraints on globally accessible states--those with nonzero visitation frequency across all considered dynamics--mitigating the challenge posed by inaccessible states. By instantiating F-distance in different ways, we derive two theoretical analysis and develop a practical algorithm called Accessible State Oriented Policy Regularization (ASOR). ASOR serves as a general add-on module that can be incorporated into various RL approaches, including offline RL and off-policy RL. Extensive experiments across multiple benchmarks demonstrate ASOR's effectiveness in enhancing state-of-the-art cross-domain policy transfer algorithms, significantly improving their performance.", 'abstract_zh': '基于观察的模仿（IfO）方法从多样动态数据中学习：一种结合奖励最大化和F-距离正则化的可访问状态导向策略正则化框架', 'title_zh': '在交叉动力系统强化学习中全局可访问状态的策略正则化'}
{'arxiv_id': 'arXiv:2503.06884', 'title': 'Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help', 'authors': 'Yuefan Cao, Xuyang Guo, Jiayan Huo, Yingyu Liang, Zhenmei Shi, Zhao Song, Jiahao Zhang, Zhen Zhuang', 'link': 'https://arxiv.org/abs/2503.06884', 'abstract': "Generative modeling is widely regarded as one of the most essential problems in today's AI community, with text-to-image generation having gained unprecedented real-world impacts. Among various approaches, diffusion models have achieved remarkable success and have become the de facto solution for text-to-image generation. However, despite their impressive performance, these models exhibit fundamental limitations in adhering to numerical constraints in user instructions, frequently generating images with an incorrect number of objects. While several prior works have mentioned this issue, a comprehensive and rigorous evaluation of this limitation remains lacking. To address this gap, we introduce T2ICountBench, a novel benchmark designed to rigorously evaluate the counting ability of state-of-the-art text-to-image diffusion models. Our benchmark encompasses a diverse set of generative models, including both open-source and private systems. It explicitly isolates counting performance from other capabilities, provides structured difficulty levels, and incorporates human evaluations to ensure high reliability.\nExtensive evaluations with T2ICountBench reveal that all state-of-the-art diffusion models fail to generate the correct number of objects, with accuracy dropping significantly as the number of objects increases. Additionally, an exploratory study on prompt refinement demonstrates that such simple interventions generally do not improve counting accuracy. Our findings highlight the inherent challenges in numerical understanding within diffusion models and point to promising directions for future improvements.", 'abstract_zh': '生成模型被视为当今AI社区中最核心的问题之一，文本到图像生成已取得了前所未有的实际影响。在各种方法中，扩散模型取得了显著的成功，并已成为文本到图像生成的实际上叉解决方案。然而，尽管这些模型在性能上表现出色，但在遵循用户指令中的数字约束方面仍然存在根本性的局限性，经常生成具有错误数量对象的图像。尽管先前有一些研究提到了这个问题，但对其限制的全面和严谨评估仍然不足。为了填补这一空白，我们引入了T2ICountBench，一个新型基准，旨在严格评估最新文本到图像扩散模型的计数能力。该基准包括多种生成模型，涵盖开源和私有系统。它明确隔离了计数性能与其他能力，提供了结构化的难度级别，并结合了人工评估以确保高可靠性。', 'title_zh': '文本到图像扩散模型不能计数，提示优化也无法帮助。'}
{'arxiv_id': 'arXiv:2503.06873', 'title': 'Interactive Medical Image Analysis with Concept-based Similarity Reasoning', 'authors': 'Ta Duc Huy, Sen Kim Tran, Phan Nguyen, Nguyen Hoang Tran, Tran Bao Sam, Anton van den Hengel, Zhibin Liao, Johan W. Verjans, Minh-Son To, Vu Minh Hieu Phan', 'link': 'https://arxiv.org/abs/2503.06873', 'abstract': 'The ability to interpret and intervene model decisions is important for the adoption of computer-aided diagnosis methods in clinical workflows. Recent concept-based methods link the model predictions with interpretable concepts and modify their activation scores to interact with the model. However, these concepts are at the image level, which hinders the model from pinpointing the exact patches the concepts are activated. Alternatively, prototype-based methods learn representations from training image patches and compare these with test image patches, using the similarity scores for final class prediction. However, interpreting the underlying concepts of these patches can be challenging and often necessitates post-hoc guesswork. To address this issue, this paper introduces the novel Concept-based Similarity Reasoning network (CSR), which offers (i) patch-level prototype with intrinsic concept interpretation, and (ii) spatial interactivity. First, the proposed CSR provides localized explanation by grounding prototypes of each concept on image regions. Second, our model introduces novel spatial-level interaction, allowing doctors to engage directly with specific image areas, making it an intuitive and transparent tool for medical imaging. CSR improves upon prior state-of-the-art interpretable methods by up to 4.5\\% across three biomedical datasets. Our code is released at this https URL.', 'abstract_zh': '基于概念的相似性推理网络：局部解释与空间交互在医学影像诊断中的应用', 'title_zh': '基于概念相似性推理的交互式医学图像分析'}
{'arxiv_id': 'arXiv:2503.06868', 'title': 'Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation', 'authors': 'Junhao Zhang, Richong Zhang, Fanshuang Kong, Ziyang Miao, Yanhan Ye, Yaowei Zheng', 'link': 'https://arxiv.org/abs/2503.06868', 'abstract': 'Existing long-text generation methods primarily concentrate on producing lengthy texts from short inputs, neglecting the long-input and long-output tasks. Such tasks have numerous practical applications while lacking available benchmarks. Moreover, as the input grows in length, existing methods inevitably encounter the "lost-in-the-middle" phenomenon. In this paper, we first introduce a Long Input and Output Benchmark (LongInOutBench), including a synthetic dataset and a comprehensive evaluation framework, addressing the challenge of the missing benchmark. We then develop the Retrieval-Augmented Long-Text Writer (RAL-Writer), which retrieves and restates important yet overlooked content, mitigating the "lost-in-the-middle" issue by constructing explicit prompts. We finally employ the proposed LongInOutBench to evaluate our RAL-Writer against comparable baselines, and the results demonstrate the effectiveness of our approach. Our code has been released at this https URL.', 'abstract_zh': '现有的长文本生成方法主要关注从短输入生成长文本，忽视了长输入和长输出任务。这类任务具有广泛的实际应用价值，但缺乏相应的基准数据。此外，随着输入文本的长度增加，现有方法不可避免地会遇到“中间内容丢失”现象。在本文中，我们首先引入了一个长输入和长输出基准(LongInOutBench)，包括合成数据集和综合评估框架，以应对缺失基准的挑战。随后，我们开发了检索增强长文本作家(RAL-Writer)，该方法检索并重述重要但被忽视的内容，通过构建显式的提示来缓解“中间内容丢失”问题。最后，我们使用提出的LongInOutBench对我们的RAL-Writer与现有基准进行评估，结果表明了我们方法的有效性。我们的代码已发布在此 <https://> 地址。', 'title_zh': '长文本生成中的中途迷失：合成数据集、评估框架及缓解方法'}
{'arxiv_id': 'arXiv:2503.06866', 'title': 'Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety Perception', 'authors': 'Wanjing Huang, Tongjie Pan, Yalan Ye', 'link': 'https://arxiv.org/abs/2503.06866', 'abstract': 'Recent advancements in large language models (LLMs) have expanded their role in robotic task planning. However, while LLMs have been explored for generating feasible task sequences, their ability to ensure safe task execution remains underdeveloped. Existing methods struggle with structured risk perception, making them inadequate for safety-critical applications where low-latency hazard adaptation is required. To address this limitation, we propose a Graphormer-enhanced risk-aware task planning framework that combines LLM-based decision-making with structured safety modeling. Our approach constructs a dynamic spatio-semantic safety graph, capturing spatial and contextual risk factors to enable online hazard detection and adaptive task refinement. Unlike existing methods that rely on predefined safety constraints, our framework introduces a context-aware risk perception module that continuously refines safety predictions based on real-time task execution. This enables a more flexible and scalable approach to robotic planning, allowing for adaptive safety compliance beyond static rules. To validate our framework, we conduct experiments in the AI2-THOR environment. The experiments results validates improvements in risk detection accuracy, rising safety notice, and task adaptability of our framework in continuous environments compared to static rule-based and LLM-only baselines. Our project is available at this https URL', 'abstract_zh': '最近大语言模型（LLMs）的进步扩展了其在机器人任务规划中的作用。然而，尽管LLMs已被探索用于生成可行的任务序列，但它们确保安全任务执行的能力仍然不够完善。现有方法在结构化风险感知方面存在困难，这使它们在需要低延迟危险适应的安全关键应用中显得不足。为解决这一局限，我们提出了一种结合基于LLM的决策和结构化安全建模的Graphormer增强的风险感知任务规划框架。我们的方法构建了一个动态空间语义安全图，捕获空间和上下文风险因素，以实现在线危险检测和自适应任务优化。与依赖预定义安全约束的现有方法不同，我们的框架引入了一个上下文感知的风险感知模块，该模块能够根据实时任务执行持续细化安全预测。这使机器人规划方法更加灵活和可扩展，允许超越静态规则的自适应安全合规性。为了验证我们的框架，我们在AI2-THOR环境中进行了实验。实验结果验证了我们的框架在连续环境中相比静态规则基础和仅LLM基准的改进在风险检测准确性、安全提示和任务适应性方面的提升。我们的项目可在以下链接访问：this https URL', 'title_zh': 'Graphormer引导的任务规划：超越静态规则的LLM安全性感知'}
{'arxiv_id': 'arXiv:2503.06861', 'title': 'Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks and Augmented Attention', 'authors': 'Mengzhe Hei, Zhouran Zhang, Qingbao Liu, Yan Pan, Xiang Zhao, Yongqian Peng, Yicong Ye, Xin Zhang, Shuxin Bai', 'link': 'https://arxiv.org/abs/2503.06861', 'abstract': "Extracting high-quality structured information from scientific literature is crucial for advancing material design through data-driven methods. Despite the considerable research in natural language processing for dataset extraction, effective approaches for multi-tuple extraction in scientific literature remain scarce due to the complex interrelations of tuples and contextual ambiguities. In the study, we illustrate the multi-tuple extraction of mechanical properties from multi-principal-element alloys and presents a novel framework that combines an entity extraction model based on MatSciBERT with pointer networks and an allocation model utilizing inter- and intra-entity attention. Our rigorous experiments on tuple extraction demonstrate impressive F1 scores of 0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples, confirming the effectiveness of the model. Furthermore, an F1 score of 0.854 was achieved on a randomly curated dataset. These results highlight the model's capacity to deliver precise and structured information, offering a robust alternative to large language models and equipping researchers with essential data for fostering data-driven innovations.", 'abstract_zh': '从科学文献中提取高质量结构化信息对于通过数据驱动方法推进材料设计至关重要。尽管在数据集提取的自然语言处理研究方面进展显著，但由于元组间的复杂关联性和上下文歧义，科学文献中的多元组提取有效方法仍较为稀缺。在本研究中，我们展示了多元组提取在多主元素合金中力学性能的提取，并提出了一种结合基于MatSciBERT的实体提取模型、指针网络以及利用实体间和实体内注意力的分配模型的新型框架。我们在元组提取的严格实验中展示了在包含1、2、3和4个元组的数据集上分别取得了0.963、0.947、0.848和0.753的F1分数，证实了该模型的有效性。此外，我们还在一个随机整理的数据集上取得了0.854的F1分数。这些结果突显了该模型在提供精准和结构化信息方面的能力，为其提供了与大型语言模型相比的稳健替代方案，同时也为研究人员提供了驱动数据创新所需的关键数据。', 'title_zh': '增强的合金多组元提取：集成指针网络和增强注意力机制'}
{'arxiv_id': 'arXiv:2503.06839', 'title': 'AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition with One GPU', 'authors': 'Zhuowen Zheng, Yain-Whar Si, Xiaochen Yuan, Junwei Duan, Ke Wang, Xiaofan Li, Xinyuan Zhang, Xueyuan Gong', 'link': 'https://arxiv.org/abs/2503.06839', 'abstract': 'Nowadays, with the advancement of deep neural networks (DNNs) and the availability of large-scale datasets, the face recognition (FR) model has achieved exceptional performance. However, since the parameter magnitude of the fully connected (FC) layer directly depends on the number of identities in the dataset. If training the FR model on large-scale datasets, the size of the model parameter will be excessively huge, leading to substantial demand for computational resources, such as time and memory. This paper proposes the attention fully connected (AttFC) layer, which could significantly reduce computational resources. AttFC employs an attention loader to generate the generative class center (GCC), and dynamically store the class center with Dynamic Class Container (DCC). DCC only stores a small subset of all class centers in FC, thus its parameter count is substantially less than the FC layer. Also, training face recognition models on large-scale datasets with one GPU often encounter out-of-memory (OOM) issues. AttFC overcomes this and achieves comparable performance to state-of-the-art methods.', 'abstract_zh': '基于注意力机制的全连接层在大规模人脸识别人脸识别模型中的应用：大幅降低计算资源需求', 'title_zh': 'AttFC：一种用于单GPU大规模人脸识别的注意力全连接层'}
{'arxiv_id': 'arXiv:2503.06828', 'title': 'Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma', 'authors': 'Somayeh Farahani, Marjaneh Hejazi, Antonio Di Ieva, Emad Fatemizadeh, Sidong Liu', 'link': 'https://arxiv.org/abs/2503.06828', 'abstract': 'Accurate, noninvasive glioma characterization is crucial for effective clinical management. Traditional methods, dependent on invasive tissue sampling, often fail to capture the spatial heterogeneity of the tumor. While deep learning has improved segmentation and molecular profiling, few approaches simultaneously integrate tumor morphology and molecular features. Foundation deep learning models, which learn robust, task-agnostic representations from large-scale datasets, hold great promise but remain underutilized in glioma imaging biomarkers. We propose the Multi-Task SWIN-UNETR (MTS-UNET) model, a novel foundation-based framework built on the BrainSegFounder model, pretrained on large-scale neuroimaging data. MTS-UNET simultaneously performs glioma segmentation, histological grading, and molecular subtyping (IDH mutation and 1p/19q co-deletion). It incorporates two key modules: Tumor-Aware Feature Encoding (TAFE) for multi-scale, tumor-focused feature extraction and Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch signals associated with IDH mutation. The model was trained and validated on a diverse, multi-center cohort of 2,249 glioma patients from seven public datasets. MTS-UNET achieved a mean Dice score of 84% for segmentation, along with AUCs of 90.58% for IDH mutation, 69.22% for 1p/19q co-deletion prediction, and 87.54% for grading, significantly outperforming baseline models (p<=0.05). Ablation studies validated the essential contributions of the TAFE and CMD modules and demonstrated the robustness of the framework. The foundation-based MTS-UNET model effectively integrates tumor segmentation with multi-level classification, exhibiting strong generalizability across diverse MRI datasets. This framework shows significant potential for advancing noninvasive, personalized glioma management by improving predictive accuracy and interpretability.', 'abstract_zh': '准确无创胶质瘤表征对于有效临床管理至关重要。传统的依赖侵入性组织取样的方法通常无法捕捉肿瘤的空间异质性。虽然深度学习提高了分割和分子谱型分析的能力，但很少有方法能够同时整合肿瘤形态和分子特征。基于基础的深度学习模型，通过学习大规模数据集中的稳健任务无关表示，具有巨大的潜力但在胶质瘤成像生物标志物中的应用仍然不足。我们提出了多任务SWIN-UNETR（MTS-UNET）模型，该模型基于BrainSegFounder模型构建，并在大规模神经影像数据上进行了预训练。MTS-UNET同时执行胶质瘤分割、组织学分级和分子亚型分类（IDH突变和1p/19q共丢失）。该模型包含两个关键模块：肿瘤意识特征编码（TAFE）用于多尺度、肿瘤相关的特征提取，以及跨模态差异（CMD）用于突出与IDH突变相关的细小T2-FLAIR不匹配信号。该模型在七个公开数据集的2249例多中心胶质瘤患者中进行了训练和验证。MTS-UNET在分割上的平均Dice分数为84%，IDH突变的AUC为90.58%，1p/19q共丢失预测的AUC为69.22%，分级的AUC为87.54%，显著优于基线模型（p≤0.05）。消融研究验证了TAFE和CMD模块的关键贡献，并展示了该框架的稳健性。基于基础的MTS-UNET模型有效地将肿瘤分割与多层次分类结合起来，展示了在多种MRI数据集上的强泛化能力。该框架展示了通过提高预测准确性和可解释性来促进无创、个性化胶质瘤管理的重要潜力。', 'title_zh': '基于多模态MRI的胶质瘤多级特征探索、分子亚类分型和分级的基础模型研究'}
{'arxiv_id': 'arXiv:2503.06820', 'title': 'Towards Fine-Grained Video Question Answering', 'authors': 'Wei Dai, Alan Luo, Zane Durante, Debadutta Dash, Arnold Milstein, Kevin Schulman, Ehsan Adeli, Li Fei-Fei', 'link': 'https://arxiv.org/abs/2503.06820', 'abstract': 'In the rapidly evolving domain of video understanding, Video Question Answering (VideoQA) remains a focal point. However, existing datasets exhibit gaps in temporal and spatial granularity, which consequently limits the capabilities of existing VideoQA methods. This paper introduces the Multi-Object Multi-Actor Question Answering (MOMA-QA) dataset, which is designed to address these shortcomings by emphasizing temporal localization, spatial relationship reasoning, and entity-centric queries. With ground truth scene graphs and temporal interval annotations, MOMA-QA is ideal for developing models for fine-grained video understanding. Furthermore, we present a novel video-language model, SGVLM, which incorporates a scene graph predictor, an efficient frame retriever, and a pre-trained large language model for temporal localization and fine-grained relationship understanding. Evaluations on MOMA-QA and other public datasets demonstrate the superior performance of our model, setting new benchmarks for VideoQA.', 'abstract_zh': '多对象多演员视频问答数据集及场景图视频语言模型（MOMA-QA及SGVLM）', 'title_zh': '细粒度视频问答'}
{'arxiv_id': 'arXiv:2503.06816', 'title': 'Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models', 'authors': 'Yuchen Mao, Hongwei Li, Yinyi Lai, Giorgos Papanastasiou, Peng Qi, Yunjie Yang, Chengjia Wang', 'link': 'https://arxiv.org/abs/2503.06816', 'abstract': 'Large-scale vision models like SAM have extensive visual knowledge, yet their general nature and computational demands limit their use in specialized tasks like medical image segmentation. In contrast, task-specific models such as U-Net++ often underperform due to sparse labeled data. This study introduces a strategic knowledge mining method that leverages SAM\'s broad understanding to boost the performance of small, locally hosted deep learning models.\nIn our approach, we trained a U-Net++ model on a limited labeled dataset and extend its capabilities by converting SAM\'s output infered on unlabeled images into prompts. This process not only harnesses SAM\'s generalized visual knowledge but also iteratively improves SAM\'s prediction to cater specialized medical segmentation tasks via U-Net++. The mined knowledge, serving as "pseudo labels", enriches the training dataset, enabling the fine-tuning of the local network.\nApplied to the Kvasir SEG and COVID-QU-Ex datasets which consist of gastrointestinal polyp and lung X-ray images respectively, our proposed method consistently enhanced the segmentation performance on Dice by 3% and 1% respectively over the baseline U-Net++ model, when the same amount of labelled data were used during training (75% and 50% of labelled data). Remarkably, our proposed method surpassed the baseline U-Net++ model even when the latter was trained exclusively on labeled data (100% of labelled data). These results underscore the potential of knowledge mining to overcome data limitations in specialized models by leveraging the broad, albeit general, knowledge of large-scale models like SAM, all while maintaining operational efficiency essential for clinical applications.', 'abstract_zh': '一种利用SAM的广泛视觉知识提升本地托管深度学习模型在医学图像分割任务性能的方法', 'title_zh': '大规模模型知识挖掘驱动的半监督医学图像分割'}
{'arxiv_id': 'arXiv:2503.06814', 'title': 'Unlocking Generalization for Robotics via Modularity and Scale', 'authors': 'Murtaza Dalal', 'link': 'https://arxiv.org/abs/2503.06814', 'abstract': 'How can we build generalist robot systems? Scale may not be enough due to the significant multimodality of robotics tasks, lack of easily accessible data and the challenges of deploying on physical hardware. Meanwhile, most deployed robotic systems today are inherently modular and can leverage the independent generalization capabilities of each module to perform well. Therefore, this thesis seeks to tackle the task of building generalist robot agents by integrating these components into one: combining modularity with large-scale learning for general purpose robot control. The first question we consider is: how can we build modularity and hierarchy into learning systems? Our key insight is that rather than having the agent learn hierarchy and low-level control end-to-end, we can enforce modularity via planning to enable more efficient and capable robot learners. Next, we come to the role of scale in building generalist robot systems. To scale, neural networks require vast amounts of diverse data, expressive architectures to fit the data and a source of supervision to generate the data. We leverage a powerful supervision source: classical planning, which can generalize, but is expensive to run and requires access to privileged information to perform well in practice. We use these planners to supervise large-scale policy learning in simulation to produce generalist agents. Finally, we consider how to unify modularity with large-scale policy learning to build real-world robot systems capable of performing zero-shot manipulation. We do so by tightly integrating key ingredients of modular high and mid-level planning, learned local control, procedural scene generation and large-scale policy learning for sim2real transfer. We demonstrate that this recipe can produce a single, generalist agent that can solve challenging long-horizon manipulation tasks in the real world.', 'abstract_zh': '如何构建通才机器人系统？由于机器人任务的高度多模态性、易于获取的数据缺乏以及在物理硬件上的部署挑战，规模可能并不足够。与此同时，当前部署的大多数机器人系统本质上是模块化的，可以通过利用每个模块的独立泛化能力来有效地执行任务。因此，本论文旨在通过将模块化与大规模学习结合起来，构建通用用途的机器人控制，来解决构建通才机器人代理的问题。首先，我们考虑的问题是：如何将模块化和层次结构构建到学习系统中？我们的关键见解是，与其让代理端到端学习层次结构和低级控制，我们可以通过规划来强制实现模块化，从而实现更高效的机器人学习者。接着，我们探讨了构建通才机器人系统中的规模问题。为了实现规模扩展，神经网络需要大量的多样化数据、能很好地拟合数据的表达性架构以及数据生成的监督源。我们利用一个强大的监督源：经典规划，它可以泛化但运行成本高，并且需要访问特权信息才能在实践中表现良好。我们使用这些规划器在仿真环境中监督大规模策略学习，从而生成通才代理。最后，我们考虑如何将模块化与大规模策略学习统一起来，以构建能够在现实世界中执行零样本操作的机器人系统。我们通过紧密整合模块化高层和中层规划的关键要素、学习局部控制、过程化场景生成和大规模策略学习，来实现从仿真到现实的迁移。我们展示了这一结合可以产生一个单一的通才代理，该代理能在现实世界中解决具有挑战性的长时间操作任务。', 'title_zh': '通过模块化和规模实现机器人领域的泛化能力解锁'}
{'arxiv_id': 'arXiv:2503.06812', 'title': 'Can Proof Assistants Verify Multi-Agent Systems?', 'authors': 'Julian Alfredo Mendez, Timotheus Kampik', 'link': 'https://arxiv.org/abs/2503.06812', 'abstract': 'This paper presents the Soda language for verifying multi-agent systems. Soda is a high-level functional and object-oriented language that supports the compilation of its code not only to Scala, a strongly statically typed high-level programming language, but also to Lean, a proof assistant and programming language. Given these capabilities, Soda can implement multi-agent systems, or parts thereof, that can then be integrated into a mainstream software ecosystem on the one hand and formally verified with state-of-the-art tools on the other hand. We provide a brief and informal introduction to Soda and the aforementioned interoperability capabilities, as well as a simple demonstration of how interaction protocols can be designed and verified with Soda. In the course of the demonstration, we highlight challenges with respect to real-world applicability.', 'abstract_zh': '本文提出了Soda语言用于验证多代理系统。Soda是一种高层函数式和面向对象语言，支持将其代码编译为Scala（一种强静态类型高层编程语言）以及Lean（一种证明助手兼编程语言）。凭借这些能力，Soda可以实现可集成到主流软件生态系统中的多代理系统，或其部分系统，并且可以用最先进的工具对其进行形式化验证。我们提供了一个简要且非正式的Soda语言和上述互操作性能力的介绍，并通过一个简单的示例展示了如何使用Soda设计和验证交互协议。在演示过程中，我们指出了实际应用中的挑战。', 'title_zh': '多Agent系统能否被证明助手验证？'}
{'arxiv_id': 'arXiv:2503.06810', 'title': 'Mitigating Preference Hacking in Policy Optimization with Pessimism', 'authors': 'Dhawal Gupta, Adam Fisch, Christoph Dann, Alekh Agarwal', 'link': 'https://arxiv.org/abs/2503.06810', 'abstract': 'This work tackles the problem of overoptimization in reinforcement learning from human feedback (RLHF), a prevalent technique for aligning models with human preferences. RLHF relies on reward or preference models trained on \\emph{fixed preference datasets}, and these models are unreliable when evaluated outside the support of this preference data, leading to the common reward or preference hacking phenomenon. We propose novel, pessimistic objectives for RLHF which are provably robust to overoptimization through the use of pessimism in the face of uncertainty, and design practical algorithms, P3O and PRPO, to optimize these objectives. Our approach is derived for the general preference optimization setting, but can be used with reward models as well. We evaluate P3O and PRPO on the tasks of fine-tuning language models for document summarization and creating helpful assistants, demonstrating remarkable resilience to overoptimization.', 'abstract_zh': '本文解决了强化学习从人类反馈中过度优化的问题（RLHF），这是一种使模型与人类偏好一致的常见技术。RLHF依赖于在固定偏好评价数据集上训练的奖励或偏好模型，这些模型在评价超出该偏好数据支持范围时可靠性较低，导致了常见的奖励或偏好篡改现象。我们提出了新型的悲观目标函数，通过在不确定性面前保持悲观态度，这些目标函数在理论上能够抵抗过度优化，并设计了实用的算法P3O和PRPO来优化这些目标函数。我们的方法适用于一般偏好优化设置，也可以与奖励模型一起使用。我们在文档摘要语言模型微调和创建有助手的任务上评估了P3O和PRPO，展示了它们对过度优化的出色抗御能力。', 'title_zh': '使用悲观主义缓解政策优化中的偏好劫持'}
{'arxiv_id': 'arXiv:2503.06808', 'title': 'Privacy Auditing of Large Language Models', 'authors': 'Ashwinee Panda, Xinyu Tang, Milad Nasr, Christopher A. Choquette-Choo, Prateek Mittal', 'link': 'https://arxiv.org/abs/2503.06808', 'abstract': "Current techniques for privacy auditing of large language models (LLMs) have limited efficacy -- they rely on basic approaches to generate canaries which leads to weak membership inference attacks that in turn give loose lower bounds on the empirical privacy leakage. We develop canaries that are far more effective than those used in prior work under threat models that cover a range of realistic settings. We demonstrate through extensive experiments on multiple families of fine-tuned LLMs that our approach sets a new standard for detection of privacy leakage. For measuring the memorization rate of non-privately trained LLMs, our designed canaries surpass prior approaches. For example, on the Qwen2.5-0.5B model, our designed canaries achieve $49.6\\%$ TPR at $1\\%$ FPR, vastly surpassing the prior approach's $4.2\\%$ TPR at $1\\%$ FPR. Our method can be used to provide a privacy audit of $\\varepsilon \\approx 1$ for a model trained with theoretical $\\varepsilon$ of 4. To the best of our knowledge, this is the first time that a privacy audit of LLM training has achieved nontrivial auditing success in the setting where the attacker cannot train shadow models, insert gradient canaries, or access the model at every iteration.", 'abstract_zh': '当前用于大语言模型（LLMs）隐私审计的技术效果有限——它们依赖于基本的方法生成-canaries，导致薄弱的成员推断攻击，进而给出宽松的经验隐私泄露下界。我们开发了在涵盖一系列现实场景的威胁模型下比先前工作更为有效的-canaries。通过在多个微调的LLM家族上进行广泛的实验，我们表明我们的方法为隐私泄露的检测设定了新的标准。对于衡量非私有训练的LLMs的回忆率，我们设计的-canaries超过先前的方法，例如在Qwen2.5-0.5B模型上，我们设计的-canaries在1% FPR下的TPR达到49.6%，远远超过先前方法在1% FPR下的4.2% TPR。我们的方法可以用于提供一个约为ε=1的隐私审计，对于理论ε值为4的模型。据我们所知，这是首次在攻击者不能训练影子模型、插入梯度-canaries或在每次迭代中访问模型的情况下，实现非平凡的隐私审计成功率。', 'title_zh': '大型语言模型的隐私审计'}
{'arxiv_id': 'arXiv:2503.06803', 'title': 'Actionable AI: Enabling Non Experts to Understand and Configure AI Systems', 'authors': 'Cécile Boulard, Sruthi Viswanathan, Wanda Fey, Thierry Jacquin', 'link': 'https://arxiv.org/abs/2503.06803', 'abstract': "Interaction between humans and AI systems raises the question of how people understand AI systems. This has been addressed with explainable AI, the interpretability arising from users' domain expertise, or collaborating with AI in a stable environment. In the absence of these elements, we discuss designing Actionable AI, which allows non-experts to configure black-box agents. In this paper, we experiment with an AI-powered cartpole game and observe 22 pairs of participants to configure it via direct manipulation. Our findings suggest that, in uncertain conditions, non-experts were able to achieve good levels of performance. By influencing the behaviour of the agent, they exhibited an operational understanding of it, which proved sufficient to reach their goals. Based on this, we derive implications for designing Actionable AI systems. In conclusion, we propose Actionable AI as a way to open access to AI-based agents, giving end users the agency to influence such agents towards their own goals.", 'abstract_zh': '人类与AI系统互动引发了人们对如何理解AI系统的疑问。这个问题通过可解释AI、用户专业知识带来的可理解性或在稳定环境中与AI协作来解决。在缺乏这些要素的情况下，我们讨论了设计可操作AI的做法，允许非专家配置黑盒代理。在本文中，我们通过直接操作实验了一个基于AI的杆车游戏，并观察了22对参与者配置该游戏的过程。我们的研究发现，在不确定性条件下，非专家能够达到良好的性能水平。通过影响代理的行为，他们表现出了对其的操作理解，这种理解足够使其达到目标。基于此，我们推导出了设计可操作AI系统的建议。总之，我们提出可操作AI作为一种使基于AI的代理对终端用户开放的方式，赋予用户影响这些代理以实现自身目标的能力。', 'title_zh': '可操作的AI：使非专家能够理解并配置AI系统'}
{'arxiv_id': 'arXiv:2503.06798', 'title': 'Characterizing Learning in Spiking Neural Networks with Astrocyte-Like Units', 'authors': 'Christopher S. Yang, Sylvester J. Gates III, Dulara De Zoysa, Jaehoon Choe, Wolfgang Losert, Corey B. Hart', 'link': 'https://arxiv.org/abs/2503.06798', 'abstract': 'Traditional artificial neural networks take inspiration from biological networks, using layers of neuron-like nodes to pass information for processing. More realistic models include spiking in the neural network, capturing the electrical characteristics more closely. However, a large proportion of brain cells are of the glial cell type, in particular astrocytes which have been suggested to play a role in performing computations. Here, we introduce a modified spiking neural network model with added astrocyte-like units in a neural network and asses their impact on learning. We implement the network as a liquid state machine and task the network with performing a chaotic time-series prediction task. We varied the number and ratio of neuron-like and astrocyte-like units in the network to examine the latter units effect on learning. We show that the combination of neurons and astrocytes together, as opposed to neural- and astrocyte-only networks, are critical for driving learning. Interestingly, we found that the highest learning rate was achieved when the ratio between astrocyte-like and neuron-like units was roughly 2 to 1, mirroring some estimates of the ratio of biological astrocytes to neurons. Our results demonstrate that incorporating astrocyte-like units which represent information across longer timescales can alter the learning rates of neural networks, and the proportion of astrocytes to neurons should be tuned appropriately to a given task.', 'abstract_zh': '包含类似星形胶质细胞单元的修改后脉冲神经网络对学习的影响研究', 'title_zh': '具有星形胶质细胞样单元的脉冲神经网络中的学习表征'}
{'arxiv_id': 'arXiv:2503.06797', 'title': 'Multimodal AI-driven Biomarker for Early Detection of Cancer Cachexia', 'authors': 'Sabeen Ahmed, Nathan Parker, Margaret Park, Evan W. Davis, Jennifer B. Permuth, Matthew B. Schabath, Yasin Yilmaz, Ghulam Rasool', 'link': 'https://arxiv.org/abs/2503.06797', 'abstract': 'Cancer cachexia is a multifactorial syndrome characterized by progressive muscle wasting, metabolic dysfunction, and systemic inflammation, leading to reduced quality of life and increased mortality. Despite extensive research, no single definitive biomarker exists, as cachexia-related indicators such as serum biomarkers, skeletal muscle measurements, and metabolic abnormalities often overlap with other conditions. Existing composite indices, including the Cancer Cachexia Index (CXI), Modified CXI (mCXI), and Cachexia Score (CASCO), integrate multiple biomarkers but lack standardized thresholds, limiting their clinical utility. This study proposes a multimodal AI-based biomarker for early cancer cachexia detection, leveraging open-source large language models (LLMs) and foundation models trained on medical data. The approach integrates heterogeneous patient data, including demographics, disease status, lab reports, radiological imaging (CT scans), and clinical notes, using a machine learning framework that can handle missing data. Unlike previous AI-based models trained on curated datasets, this method utilizes routinely collected clinical data, enhancing real-world applicability. Additionally, the model incorporates confidence estimation, allowing the identification of cases requiring expert review for precise clinical interpretation. Preliminary findings demonstrate that integrating multiple data modalities improves cachexia prediction accuracy at the time of cancer diagnosis. The AI-based biomarker dynamically adapts to patient-specific factors such as age, race, ethnicity, weight, cancer type, and stage, avoiding the limitations of fixed-threshold biomarkers. This multimodal AI biomarker provides a scalable and clinically viable solution for early cancer cachexia detection, facilitating personalized interventions and potentially improving treatment outcomes and patient survival.', 'abstract_zh': '癌症恶病质是一种多因素综合征，特征为渐进性肌肉消耗、代谢功能障碍和全身炎症，导致生活质量下降和死亡率增加。尽管进行了大量研究，但至今没有单一确凿的生物标志物，因为与癌症恶病质相关的指标，如血液生物标志物、骨骼肌测量和代谢异常往往与其他疾病重叠。现有的综合指标，包括癌症恶病质指数（CXI）、修改版CXI（mCXI）和恶病质评分（CASCO），整合了多种生物标志物，但缺乏标准化门槛，限制了其临床实用性。本研究提出了一种基于多模态人工智能的生物标志物，用于早期癌症恶病质检测，利用开源的大规模语言模型（LLMs）和基于医学数据训练的基础模型。该方法整合了异质性患者数据，包括人口统计学、疾病状态、实验室报告、放射影像（CT扫描）和临床记录，使用能够处理缺失数据的机器学习框架。与之前基于精心标注数据集训练的AI模型不同，该方法利用了常规收集的临床数据，提高了其实用性。此外，该模型还包含了置信度估计的功能，可以识别需要专家复核以进行精确临床解释的病例。初步发现表明，整合多种数据模态可以提高癌症诊断时恶病质预测的准确性。基于人工智能的生物标志物可以根据年龄、种族、民族、体重、癌症类型和分期等患者特定因素动态调整，避免了固定阈值生物标志物的局限性。这一多模态人工智能生物标志物提供了一种可扩展且临床可行的解决方案，用于早期癌症恶病质的检测，有助于个性化干预并可能改善治疗结果和患者存活率。', 'title_zh': '多模态AI驱动的生物标志物用于早期检测癌症恶病质'}
{'arxiv_id': 'arXiv:2503.06791', 'title': 'AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot', 'authors': 'Xiao Wang, Lu Dong, Sahana Rangasrinivasan, Ifeoma Nwogu, Srirangaraj Setlur, Venugopal Govindaraju', 'link': 'https://arxiv.org/abs/2503.06791', 'abstract': "The social robot's open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty's effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-4o and ChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly released through the webpage: this https URL", 'abstract_zh': '基于大型语言模型的多代理协作框架AutoMisty：自然语言指令生成可执行Misty机器人代码', 'title_zh': 'AutoMisty: 一种基于Misty社交机器人的多代理大语言模型自动化代码生成框架'}
{'arxiv_id': 'arXiv:2503.06790', 'title': 'GenDR: Lightning Generative Detail Restorator', 'authors': 'Yan Wang, Shijie Zhao, Kai Chen, Kexin Zhang, Junlin Li, Li Zhang', 'link': 'https://arxiv.org/abs/2503.06790', 'abstract': 'Recent research applying text-to-image (T2I) diffusion models to real-world super-resolution (SR) has achieved remarkable success. However, fundamental misalignments between T2I and SR targets result in a dilemma between inference speed and detail fidelity. Specifically, T2I tasks prioritize multi-step inversion to synthesize coherent outputs aligned with textual prompts and shrink the latent space to reduce generating complexity. Contrariwise, SR tasks preserve most information from low-resolution input while solely restoring high-frequency details, thus necessitating sufficient latent space and fewer inference steps. To bridge the gap, we present a one-step diffusion model for generative detail restoration, GenDR, distilled from a tailored diffusion model with larger latent space. In detail, we train a new SD2.1-VAE16 (0.9B) via representation alignment to expand latent space without enlarging the model size. Regarding step-distillation, we propose consistent score identity distillation (CiD) that incorporates SR task-specific loss into score distillation to leverage more SR priors and align the training target. Furthermore, we extend CiD with adversarial learning and representation alignment (CiDA) to enhance perceptual quality and accelerate training. We also polish the pipeline to achieve a more efficient inference. Experimental results demonstrate that GenDR achieves state-of-the-art performance in both quantitative metrics and visual fidelity.', 'abstract_zh': 'Recent research applying text-to-image (T2I) diffusion models to real-world super-resolution (SR) has achieved remarkable success. However, fundamental misalignments between T2I and SR targets result in a dilemma between inference speed and detail fidelity. To bridge the gap, we present a one-step diffusion model for generative detail restoration, GenDR, distilled from a tailored diffusion model with a larger latent space. GenDR achieves state-of-the-art performance in both quantitative metrics and visual fidelity.', 'title_zh': 'GenDR: 闪电生成细节恢复器'}
{'arxiv_id': 'arXiv:2503.06784', 'title': 'Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain Generation by Latent Fractal Diffusion Models', 'authors': 'Tianyi Zhang, Weiming Zhi, Joshua Mangelson, Matthew Johnson-Roberson', 'link': 'https://arxiv.org/abs/2503.06784', 'abstract': 'This paper tackles the problem of generating representations of underwater 3D terrain. Off-the-shelf generative models, trained on Internet-scale data but not on specialized underwater images, exhibit downgraded realism, as images of the seafloor are relatively uncommon. To this end, we introduce DreamSea, a generative model to generate hyper-realistic underwater scenes. DreamSea is trained on real-world image databases collected from underwater robot surveys. Images from these surveys contain massive real seafloor observations and covering large areas, but are prone to noise and artifacts from the real world. We extract 3D geometry and semantics from the data with visual foundation models, and train a diffusion model that generates realistic seafloor images in RGBD channels, conditioned on novel fractal distribution-based latent embeddings. We then fuse the generated images into a 3D map, building a 3DGS model supervised by 2D diffusion priors which allows photorealistic novel view rendering. DreamSea is rigorously evaluated, demonstrating the ability to robustly generate large-scale underwater scenes that are consistent, diverse, and photorealistic. Our work drives impact in multiple domains, spanning filming, gaming, and robot simulation.', 'abstract_zh': '本文解决了生成水下三维地形表示的问题。现成的生成模型虽然在互联网规模的数据上进行了训练，但未在专门的水下图像上进行训练，导致生成的图像现实感较差，因为海底图像相对较少见。为此，我们提出了DreamSea，一种用于生成超逼真水下场景的生成模型。DreamSea 在来自水下机器人调查的真实世界图像数据库上进行训练。这些调查中的图像包含了大量真实的海底观察并覆盖了大面积区域，但容易受到现实世界的噪声和伪影的影响。我们利用视觉基础模型从数据中提取3D几何和语义信息，并训练一种生成模型，该模型能够在RGBD通道中根据基于新颖分形分布的潜在嵌入生成逼真的海底图像。然后，我们将生成的图像融合到一个3D地图中，构建一个由2D扩散先验监督的3DGS模型，允许照片现实的 novel view 渲染。DreamSea 在严格测试中表现出色，能够稳健地生成一致性高、多样性好且照片现实的大规模水下场景。我们的工作在电影制作、游戏和机器人模拟等多个领域产生了影响。', 'title_zh': '深海无限联盟：由潜在分形扩散模型生成的拟真实3D海底地形'}
{'arxiv_id': 'arXiv:2503.06781', 'title': 'Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic Text Rewriting', 'authors': 'Yufei Li, John Nham, Ganesh Jawahar, Lei Shu, David Uthus, Yun-Hsuan Sung, Chengrun Yang, Itai Rolnick, Yi Qiao, Cong Liu', 'link': 'https://arxiv.org/abs/2503.06781', 'abstract': "Generic text rewriting is a prevalent large language model (LLM) application that covers diverse real-world tasks, such as style transfer, fact correction, and email editing. These tasks vary in rewriting objectives (e.g., factual consistency vs. semantic preservation), making it challenging to develop a unified model that excels across all dimensions. Existing methods often specialize in either a single task or a specific objective, limiting their generalizability. In this work, we introduce a generic model proficient in factuality, stylistic, and conversational rewriting tasks. To simulate real-world user rewrite requests, we construct a conversational rewrite dataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw emails using LLMs. Combined with other popular rewrite datasets, including LongFact for the factuality rewrite task and RewriteLM for the stylistic rewrite task, this forms a broad benchmark for training and evaluating generic rewrite models. To align with task-specific objectives, we propose Dr Genre, a Decoupled-reward learning framework for Generic rewriting, that utilizes objective-oriented reward models with a task-specific weighting. Evaluation shows that \\approach delivers higher-quality rewrites across all targeted tasks, improving objectives including instruction following (agreement), internal consistency (coherence), and minimal unnecessary edits (conciseness).", 'abstract_zh': '通用文本重写是广泛流行的大语言模型（LLM）应用，涵盖多样化的实际任务，如风格转移、事实修正和邮件编辑。这些任务在重写目标上各不相同（例如，事实一致性 vs. 语义保留），这使得开发能够在所有维度上表现出色的统一模型具有挑战性。现有方法往往专注于单一任务或特定目标，限制了其普适性。在本文中，我们引入了一个在事实性、风格和对话重写任务上均有所擅长的通用模型。为了模拟实际用户重写请求，我们构建了一个对话重写数据集ChatRewrite，该数据集使用大语言模型从原始邮件中提取出“自然”的指令。结合其他流行的重写数据集，包括LongFact用于事实性重写任务和RewriteLM用于风格重写任务，这构成了训练和评估通用重写模型的广泛基准。为了与特定任务目标对齐，我们提出了一种拆分奖励学习框架Dr Genre，该框架利用目标导向的奖励模型，并结合特定任务的权重。评估结果显示，该方法在所有目标任务上提供了更高质量的重写，提高了包括指令遵循（一致性）、内部一致性（连贯性）和最小不必要的编辑（简洁性）在内的目标。', 'title_zh': 'Dr Genre: 基于解耦大语言模型反馈的强化学习通用文本重写'}
{'arxiv_id': 'arXiv:2503.06778', 'title': 'Large Language Models Are Effective Human Annotation Assistants, But Not Good Independent Annotators', 'authors': 'Feng Gu, Zongxia Li, Carlos Rafael Colon, Benjamin Evans, Ishani Mondal, Jordan Lee Boyd-Graber', 'link': 'https://arxiv.org/abs/2503.06778', 'abstract': 'Event annotation is important for identifying market changes, monitoring breaking news, and understanding sociological trends. Although expert annotators set the gold standards, human coding is expensive and inefficient. Unlike information extraction experiments that focus on single contexts, we evaluate a holistic workflow that removes irrelevant documents, merges documents about the same event, and annotates the events. Although LLM-based automated annotations are better than traditional TF-IDF-based methods or Event Set Curation, they are still not reliable annotators compared to human experts. However, adding LLMs to assist experts for Event Set Curation can reduce the time and mental effort required for Variable Annotation. When using LLMs to extract event variables to assist expert annotators, they agree more with the extracted variables than fully automated LLMs for annotation.', 'abstract_zh': '事件标注对于识别市场变化、监控突发新闻和理解社会趋势非常重要。尽管专家标注设定标准，但人工编码成本高且效率低。与专注于单一上下文信息抽取实验不同，我们评估了一种全面的工作流程，该流程可以去除无关文档、合并关于同一事件的文档并标注事件。尽管基于LLM的自动化标注优于传统的TF-IDF方法或事件集管理，但它们在可靠性上仍无法与人工专家相比。然而，将LLM与专家结合用于事件集管理可以减少变量标注所需的时间和精力。当使用LLM提取事件变量以协助专家标注时，专家组的意见与提取的变量更为一致，优于完全自动化的LLM标注。', 'title_zh': '大型语言模型是有效的手工标注助手，但不是好的独立标注者。'}
{'arxiv_id': 'arXiv:2503.06765', 'title': 'Effectiveness of Zero-shot-CoT in Japanese Prompts', 'authors': 'Shusuke Takayama, Ian Frank', 'link': 'https://arxiv.org/abs/2503.06765', 'abstract': 'We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in Japanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot CoT, which involves appending a phrase such as "Let\'s think step by step" to a prompt to encourage reasoning before answering, has been shown to offer LLM performance improvements in mathematical and reasoning tasks, particularly in English. We investigate how these effects transfer to Japanese using the Japanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task Language Understanding Benchmark (MMLU). Our results show that while zero-shot CoT prompting can lead to notable performance gains for some prompt categories in GPT-3.5, its impact in GPT-4o-mini is associated with significant performance declines. However, for Japanese prompts there remain certain categories, such as college mathematics and abstract algebra, that still exhibit improvements, despite the broader trend of diminishing effectiveness in more advanced models.', 'abstract_zh': '我们在使用ChatGPT-3.5和4o-mini时，比较了零样本Chain-of-Thought (CoT) 提示在日本语和英语中的有效性。', 'title_zh': '零样本-CoT在日本提示中的有效性'}
{'arxiv_id': 'arXiv:2503.06764', 'title': 'SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation', 'authors': 'Zisheng Chen, Chunwei Wang, Xiuwei Chen, Hang Xu, Jianhua Han, Xiandan Liang', 'link': 'https://arxiv.org/abs/2503.06764', 'abstract': 'We present SemHiTok, a unified image Tokenizer via Semantic-Guided Hierarchical codebook that provides consistent discrete feature representations for multimodal understanding and generation tasks. Recently, unified multimodal large models (MLLMs) for understanding and generation have sparked exploration within research community. Previous works attempt to train a unified image tokenizer by combining loss functions for semantic feature reconstruction and pixel reconstruction. However, due to the differing levels of features prioritized by multimodal understanding and generation tasks, joint training methods face significant challenges in achieving a good trade-off. SemHiTok addresses this challenge through Semantic-Guided Hierarchical codebook which builds texture sub-codebooks on pre-trained semantic codebook. This design decouples the training of semantic reconstruction and pixel reconstruction and equips the tokenizer with low-level texture feature extraction capability without degradation of high-level semantic feature extraction ability. Our experiments demonstrate that SemHiTok achieves state-of-the-art rFID score at 256X256resolution compared to other unified tokenizers, and exhibits competitive performance on multimodal understanding and generation tasks.', 'abstract_zh': 'SemHiTok：一种基于语义引导层次码本的统一图像分词器', 'title_zh': 'SemHiTok: 基于语义引导多层次码本的统一图像分词器及其在多模态理解和生成中的应用'}
{'arxiv_id': 'arXiv:2503.06749', 'title': 'Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models', 'authors': 'Wenxuan Huang, Bohan Jia, Zijie Zhai, Shaosheng Cao, Zheyu Ye, Fei Zhao, Yao Hu, Shaohui Lin', 'link': 'https://arxiv.org/abs/2503.06749', 'abstract': "DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning capabilities in LLMs purely through Reinforcement Learning (RL). Inspired by this breakthrough, we explore how RL can be utilized to enhance the reasoning capability of MLLMs. However, direct training with RL struggles to activate complex reasoning capabilities such as questioning and reflection in MLLMs, due to the absence of substantial high-quality multimodal reasoning data. To address this issue, we propose the reasoning MLLM, Vision-R1, to improve multimodal reasoning capability. Specifically, we first construct a high-quality multimodal CoT dataset without human annotations by leveraging an existing MLLM and DeepSeek-R1 through modality bridging and data filtering to obtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as cold-start initialization data for Vision-R1. To mitigate the optimization challenges caused by overthinking after cold start, we propose Progressive Thinking Suppression Training (PTST) strategy and employ Group Relative Policy Optimization (GRPO) with the hard formatting result reward function to gradually refine the model's ability to learn correct and complex reasoning processes on a 10K multimodal math dataset. Comprehensive experiments show our model achieves an average improvement of $\\sim$6% across various multimodal math reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely used MathVista benchmark, which is only 0.4% lower than the leading reasoning model, OpenAI O1. The datasets and code will be released in: this https URL .", 'abstract_zh': 'DeepSeek-R1-Zero通过强化学习成功展现了大规模语言模型中推理能力的涌现。受此突破的启发，我们探讨了如何利用强化学习增强大规模多模态语言模型的推理能力。然而，直接使用强化学习训练难以激活大规模多模态语言模型中的复杂推理能力，如质疑和反思，这归因于缺乏足够的高质量多模态推理数据。为了解决这一问题，我们提出了一种多模态推理大规模多模态语言模型Vision-R1，以提升多模态推理能力。具体地，我们首先通过模态桥梁和数据过滤，利用现有大规模多模态语言模型和DeepSeek-R1构建了一个无需人工注释的高质量多模态CoT数据集Vision-R1-cold，作为Vision-R1的冷启动初始化数据。为了缓解冷启动后的过度思考带来的优化挑战，我们提出了渐进性思考抑制训练（PTST）策略，并采用具有硬格式化结果奖励函数的组相对策略优化（GRPO）方法，逐步精炼模型学习正确且复杂的推理过程的能力。在10K多模态数学数据集上，我们的模型在各种多模态数学推理基准上取得了平均约6%的改进。Vision-R1-7B在广泛使用的MathVista基准上的准确率达到73.5%，仅比最好的推理模型OpenAI O1低0.4个百分点。数据集和代码将在以下链接发布：this https URL。', 'title_zh': 'Vision-R1: 在多模态大型语言模型中激励推理能力'}
{'arxiv_id': 'arXiv:2503.06747', 'title': 'Fully-Decentralized MADDPG with Networked Agents', 'authors': 'Diego Bolliger, Lorenz Zauter, Robert Ziegler', 'link': 'https://arxiv.org/abs/2503.06747', 'abstract': 'In this paper, we devise three actor-critic algorithms with decentralized training for multi-agent reinforcement learning in cooperative, adversarial, and mixed settings with continuous action spaces. To this goal, we adapt the MADDPG algorithm by applying a networked communication approach between agents. We introduce surrogate policies in order to decentralize the training while allowing for local communication during training. The decentralized algorithms achieve comparable results to the original MADDPG in empirical tests, while reducing computational cost. This is more pronounced with larger numbers of agents.', 'abstract_zh': '在本论文中，我们为协同、对抗和混合设置下的多智能体强化学习设计了三种带去中心化训练的Actor-Critic算法，适用于连续动作空间。为此，我们通过应用智能体之间的网络化通信方法来适应MADDPG算法。我们引入代理的替代策略以在允许局部通信的同时实现训练的去中心化。去中心化的算法在实证测试中达到了与原MADDPG相当的结果，同时降低了计算成本，这种效果在更多智能体的情况下更为显著。', 'title_zh': '基于网络化代理的完全去中心化MADDPG'}
{'arxiv_id': 'arXiv:2503.06734', 'title': 'Gender Encoding Patterns in Pretrained Language Model Representations', 'authors': 'Mahdi Zakizadeh, Mohammad Taher Pilehvar', 'link': 'https://arxiv.org/abs/2503.06734', 'abstract': 'Gender bias in pretrained language models (PLMs) poses significant social and ethical challenges. Despite growing awareness, there is a lack of comprehensive investigation into how different models internally represent and propagate such biases. This study adopts an information-theoretic approach to analyze how gender biases are encoded within various encoder-based architectures. We focus on three key aspects: identifying how models encode gender information and biases, examining the impact of bias mitigation techniques and fine-tuning on the encoded biases and their effectiveness, and exploring how model design differences influence the encoding of biases. Through rigorous and systematic investigation, our findings reveal a consistent pattern of gender encoding across diverse models. Surprisingly, debiasing techniques often exhibit limited efficacy, sometimes inadvertently increasing the encoded bias in internal representations while reducing bias in model output distributions. This highlights a disconnect between mitigating bias in output distributions and addressing its internal representations. This work provides valuable guidance for advancing bias mitigation strategies and fostering the development of more equitable language models.', 'abstract_zh': '性别偏差在预训练语言模型中的存在对社会和伦理提出了重大挑战。尽管已有越来越多的认识，但缺乏对不同模型内部如何表示和传播这些偏差的全面调查。本研究采用信息论的方法分析性别偏差在各种基于编码器的架构中的编码方式。我们重点关注三个方面：识别模型如何编码性别信息和偏差、检查偏见缓解技术和微调对编码偏差及其有效性的影响、以及探讨模型设计差异如何影响偏差的编码方式。通过严格的系统性研究，我们的发现揭示了不同模型在性别编码方面的持续一致模式。令人意外的是，偏见缓解技术通常表现出有限的有效性，有时会无意中在内部表示中增加偏见，同时降低模型输出分布中的偏见。这突显了在输出分布中缓解偏见与解决其内部表示之间的脱节。本研究为推进偏见缓解策略和促进更公平的语言模型的发展提供了宝贵的指导。', 'title_zh': '预训练语言模型表示中的性别编码模式'}
{'arxiv_id': 'arXiv:2503.06729', 'title': 'ACAI for SBOs: AI Co-creation for Advertising and Inspiration for Small Business Owners', 'authors': 'Nimisha Karnatak, Adrien Baranes, Rob Marchant, Triona Butler, Kristen Olson', 'link': 'https://arxiv.org/abs/2503.06729', 'abstract': "Small business owners (SBOs) often lack the resources and design experience needed to produce high-quality advertisements. To address this, we developed ACAI (AI Co-Creation for Advertising and Inspiration), an GenAI-powered multimodal advertisement creation tool, and conducted a user study with 16 SBOs in London to explore their perceptions of and interactions with ACAI in advertisement creation. Our findings reveal that structured inputs enhance user agency and control while improving AI outputs by facilitating better brand alignment, enhancing AI transparency, and offering scaffolding that assists novice designers, such as SBOs, in formulating prompts. We also found that ACAI's multimodal interface bridges the design skill gap for SBOs with a clear advertisement vision, but who lack the design jargon necessary for effective prompting. Building on our findings, we propose three capabilities: contextual intelligence, adaptive interactions, and data management, with corresponding design recommendations to advance the co-creative attributes of AI-mediated design tools.", 'abstract_zh': '小型企业主（SBOs）常常缺乏生产高质量广告所需的资源和设计经验。为此，我们开发了ACAI（AI协同创作广告与灵感），这是一种基于GenAI的多模态广告创作工具，并在伦敦对16位SBOs进行了用户研究，以探索他们对ACAI在广告创作中的感知和互动。我们的研究发现，结构化的输入增强了用户的自主性和控制力，同时通过促进更好的品牌对齐、提高AI的透明度，并为初学者设计师，如SBOs，提供支撑性工具以制定提示，从而改进AI输出。我们还发现，ACAI的多模态界面为拥有清晰广告愿景但缺乏必要设计术语的SBOs填补了设计技能的空白。基于这些发现，我们提出了三项能力：情境智能、适应性交互和数据管理，并提出相应的设计建议以促进AI介导设计工具有助于协同创作的属性。', 'title_zh': 'ACAI 对 SBOs 的协同创造：面向小型企业主的广告人工智能共创'}
{'arxiv_id': 'arXiv:2503.06725', 'title': 'Pull-Based Query Scheduling for Goal-Oriented Semantic Communication', 'authors': 'Pouya Agheli, Nikolaos Pappas, Marios Kountouris', 'link': 'https://arxiv.org/abs/2503.06725', 'abstract': 'This paper addresses query scheduling for goal-oriented semantic communication in pull-based status update systems. We consider a system where multiple sensing agents (SAs) observe a source characterized by various attributes and provide updates to multiple actuation agents (AAs), which act upon the received information to fulfill their heterogeneous goals at the endpoint. A hub serves as an intermediary, querying the SAs for updates on observed attributes and maintaining a knowledge base, which is then broadcast to the AAs. The AAs leverage the knowledge to perform their actions effectively. To quantify the semantic value of updates, we introduce a grade of effectiveness (GoE) metric. Furthermore, we integrate cumulative perspective theory (CPT) into the long-term effectiveness analysis to account for risk awareness and loss aversion in the system. Leveraging this framework, we compute effect-aware scheduling policies aimed at maximizing the expected discounted sum of CPT-based total GoE provided by the transmitted updates while complying with a given query cost constraint. To achieve this, we propose a model-based solution based on dynamic programming and model-free solutions employing state-of-the-art deep reinforcement learning (DRL) algorithms. Our findings demonstrate that effect-aware scheduling significantly enhances the effectiveness of communicated updates compared to benchmark scheduling methods, particularly in settings with stringent cost constraints where optimal query scheduling is vital for system performance and overall effectiveness.', 'abstract_zh': '面向目标语义通信的基于拉取的现状更新系统的查询调度研究', 'title_zh': '目标导向的语义通信基于拉式查询调度'}
{'arxiv_id': 'arXiv:2503.06709', 'title': 'Delusions of Large Language Models', 'authors': 'Hongshen Xu, Zixv yang, Zichen Zhu, Kunyao Lan, Zihan Wang, Mengyue Wu, Ziwei Ji, Lu Chen, Pascale Fung, Kai Yu', 'link': 'https://arxiv.org/abs/2503.06709', 'abstract': 'Large Language Models often generate factually incorrect but plausible outputs, known as hallucinations. We identify a more insidious phenomenon, LLM delusion, defined as high belief hallucinations, incorrect outputs with abnormally high confidence, making them harder to detect and mitigate. Unlike ordinary hallucinations, delusions persist with low uncertainty, posing significant challenges to model reliability. Through empirical analysis across different model families and sizes on several Question Answering tasks, we show that delusions are prevalent and distinct from hallucinations. LLMs exhibit lower honesty with delusions, which are harder to override via finetuning or self reflection. We link delusion formation with training dynamics and dataset noise and explore mitigation strategies such as retrieval augmented generation and multi agent debating to mitigate delusions. By systematically investigating the nature, prevalence, and mitigation of LLM delusions, our study provides insights into the underlying causes of this phenomenon and outlines future directions for improving model reliability.', 'abstract_zh': '大规模语言模型常常生成事实性错误但听起来合理的输出，称为幻觉。我们鉴定出一种更为隐蔽的现象，即LLM妄想，定义为高信念幻觉，即带有异常高置信度的错误输出，使得它们更难以检测和缓解。与普通幻觉不同，妄想伴随着低不确定性，给模型可靠性带来重大挑战。通过在不同模型家族和规模上对多个问答任务进行实证分析，我们证明了妄想现象普遍存在且与幻觉不同。模型在妄想时表现出较低的诚实性，这种方法通过微调或自我反思更难克服。我们将妄想的形成与训练动力学和数据集噪音联系起来，并探索检索增强生成和多代理辩论等缓解策略以减轻妄想。通过系统地研究LLM妄想的本质、普遍性和缓解策略，我们的研究提供了对该现象背后原因的见解，并明确了提高模型可靠性的未来方向。', 'title_zh': '大型语言模型的妄想症'}
{'arxiv_id': 'arXiv:2503.06706', 'title': 'PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts', 'authors': 'Ming Zhang, Yuhui Wang, Yujiong Shen, Tingyi Yang, Changhao Jiang, Yilong Wu, Shihan Dou, Qinhao Chen, Zhiheng Xi, Zhihao Zhang, Yi Dong, Zhen Wang, Zhihui Fei, Mingyang Wan, Tao Liang, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2503.06706', 'abstract': "Process-driven dialogue systems, which operate under strict predefined process constraints, are essential in customer service and equipment maintenance scenarios. Although Large Language Models (LLMs) have shown remarkable progress in dialogue and reasoning, they still struggle to solve these strictly constrained dialogue tasks. To address this challenge, we construct Process Flow Dialogue (PFDial) dataset, which contains 12,705 high-quality Chinese dialogue instructions derived from 440 flowcharts containing 5,055 process nodes. Based on PlantUML specification, each UML flowchart is converted into atomic dialogue units i.e., structured five-tuples. Experimental results demonstrate that a 7B model trained with merely 800 samples, and a 0.5B model trained on total data both can surpass 90% accuracy. Additionally, the 8B model can surpass GPT-4o up to 43.88% with an average of 11.00%. We further evaluate models' performance on challenging backward transitions in process flows and conduct an in-depth analysis of various dataset formats to reveal their impact on model performance in handling decision and sequential branches. The data is released in this https URL.", 'abstract_zh': '过程驱动对话系统在客户服务中心和设备维护场景中至关重要。尽管大规模语言模型在对话和推理方面取得了显著进展，但在解决这些严格受限的对话任务方面仍然存在挑战。为应对这一挑战，我们构建了过程流程对话（PFDial）数据集，该数据集包含源自440个流程图的12,705条高质量中文对话指令，这些流程图包含5,055个过程节点。基于PlantUML规范，每张UML流程图被转换为原子对话单元，即结构化的五元组。实验结果显示，仅使用800样本训练的7B模型和使用全部数据训练的0.5B模型均可超过90%的准确率。此外，8B模型在平均准确性11.00%的基础上，比GPT-4o高出43.88%。我们进一步评估了模型在过程流程中具有挑战性的反向过渡的表现，并对各种数据集格式进行了深入分析，以揭示它们对模型处理决策和序列分支时性能的影响。数据在此处发布：https://链接。', 'title_zh': 'PFDial：基于UML流程图的结构化对话指令微调方法'}
{'arxiv_id': 'arXiv:2503.06692', 'title': 'InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models', 'authors': 'Yuchen Yan, Yongliang Shen, Yang Liu, Jin Jiang, Mengdi Zhang, Jian Shao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2503.06692', 'abstract': 'Advanced reasoning in large language models has achieved remarkable performance on challenging tasks, but the prevailing long-context reasoning paradigm faces critical limitations: quadratic computational scaling with sequence length, reasoning constrained by maximum context boundaries, and performance degradation beyond pre-training context windows. Existing approaches primarily compress reasoning chains without addressing the fundamental scaling problem. To overcome these challenges, we introduce InftyThink, a paradigm that transforms monolithic reasoning into an iterative process with intermediate summarization. By interleaving short reasoning segments with concise progress summaries, our approach enables unbounded reasoning depth while maintaining bounded computational costs. This creates a characteristic sawtooth memory pattern that significantly reduces computational complexity compared to traditional approaches. Furthermore, we develop a methodology for reconstructing long-context reasoning datasets into our iterative format, transforming OpenR1-Math into 333K training instances. Experiments across multiple model architectures demonstrate that our approach reduces computational costs while improving performance, with Qwen2.5-Math-7B showing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks. Our work challenges the assumed trade-off between reasoning depth and computational efficiency, providing a more scalable approach to complex reasoning without architectural modifications.', 'abstract_zh': 'InftyThink：一种迭代式的中间总结范式，克服大规模语言模型的长上下文推理挑战', 'title_zh': 'InftyThink：打破大型语言模型长上下文推理的长度限制'}
{'arxiv_id': 'arXiv:2503.06690', 'title': 'Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic Treatment Regimes with Censored Outcomes', 'authors': 'Animesh Kumar Paul, Russell Greiner', 'link': 'https://arxiv.org/abs/2503.06690', 'abstract': 'Dynamic Treatment Regimes (DTRs) provide a systematic approach for making sequential treatment decisions that adapt to individual patient characteristics, particularly in clinical contexts where survival outcomes are of interest. Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL) is a novel framework to address the complexities associated with censored data when estimating optimal DTRs. We explore ways to learn effective DTRs, from observational data. By enhancing traditional tree-based reinforcement learning methods with augmented inverse probability weighting (AIPW) and censoring-aware modifications, CA-TRL delivers robust and interpretable treatment strategies. We demonstrate its effectiveness through extensive simulations and real-world applications using the SANAD epilepsy dataset, where it outperformed the recently proposed ASCL method in key metrics such as restricted mean survival time (RMST) and decision-making accuracy. This work represents a step forward in advancing personalized and data-driven treatment strategies across diverse healthcare settings.', 'abstract_zh': '基于去 cen 截断aware 的树形强化学习的动态治疗策略（Censoring-Aware Tree-Based Reinforcement Learning for Dynamic Treatment Regimes）', 'title_zh': '基于树的强化学习：考虑截尾结果的治疗策略估计， Aware剪枝树结构强化学习方法用于动态治疗方案估计'}
{'arxiv_id': 'arXiv:2503.06687', 'title': 'UniGenX: Unified Generation of Sequence and Structure with Autoregressive Diffusion', 'authors': 'Gongbo Zhang, Yanting Li, Renqian Luo, Pipi Hu, Zeru Zhao, Lingbo Li, Guoqing Liu, Zun Wang, Ran Bi, Kaiyuan Gao, Liya Guo, Yu Xie, Chang Liu, Jia Zhang, Tian Xie, Robert Pinsler, Claudio Zeni, Ziheng Lu, Yingce Xia, Marwin Segler, Maik Riechert, Li Yuan, Lei Chen, Haiguang Liu, Tao Qin', 'link': 'https://arxiv.org/abs/2503.06687', 'abstract': 'Unified generation of sequence and structure for scientific data (e.g., materials, molecules, proteins) is a critical task. Existing approaches primarily rely on either autoregressive sequence models or diffusion models, each offering distinct advantages and facing notable limitations. Autoregressive models, such as GPT, Llama, and Phi-4, have demonstrated remarkable success in natural language generation and have been extended to multimodal tasks (e.g., image, video, and audio) using advanced encoders like VQ-VAE to represent complex modalities as discrete sequences. However, their direct application to scientific domains is challenging due to the high precision requirements and the diverse nature of scientific data. On the other hand, diffusion models excel at generating high-dimensional scientific data, such as protein, molecule, and material structures, with remarkable accuracy. Yet, their inability to effectively model sequences limits their potential as general-purpose multimodal foundation models. To address these challenges, we propose UniGenX, a unified framework that combines autoregressive next-token prediction with conditional diffusion models. This integration leverages the strengths of autoregressive models to ease the training of conditional diffusion models, while diffusion-based generative heads enhance the precision of autoregressive predictions. We validate the effectiveness of UniGenX on material and small molecule generation tasks, achieving a significant leap in state-of-the-art performance for material crystal structure prediction and establishing new state-of-the-art results for small molecule structure prediction, de novo design, and conditional generation. Notably, UniGenX demonstrates significant improvements, especially in handling long sequences for complex structures, showcasing its efficacy as a versatile tool for scientific data generation.', 'abstract_zh': '统一生成科学数据（如材料、分子、蛋白质）的序列和结构是一个关键任务。现有方法主要依赖于自回归序列模型或扩散模型，各自具有独特的优势和明显的局限性。自回归模型，如GPT、Llama和Phi-4，在自然语言生成方面取得了显著成功，并通过像VQ-VAE这样的高级编码器扩展到多模态任务（如图像、视频和音频），以表示复杂的模态为离散序列。然而，它们直接应用于科学领域因高精度要求和科学数据的多样性而具有挑战性。另一方面，扩散模型在生成蛋白质、分子和材料结构等高维科学数据方面表现出显著的准确性。然而，它们在有效建模序列方面的不足限制了它们作为通用多模态基础模型的应用潜力。为应对这些挑战，我们提出了UniGenX，一个结合自回归下一个令牌预测与条件扩散模型的统一框架。这种集成利用自回归模型的优势来简化条件扩散模型的训练，而基于扩散的生成头部则增强了自回归预测的精度。我们通过材料和小分子生成任务验证了UniGenX的有效性，显著提高了材料晶体结构预测的最新性能，并在小分子结构预测、从头设计和条件生成方面建立了新的最新性能结果。值得注意的是，UniGenX 在处理复杂结构的长序列时显示出显著改进，彰显了其作为科学数据生成工具的多功能性。', 'title_zh': 'UniGenX：统一生成序列与结构的自回归扩散方法'}
{'arxiv_id': 'arXiv:2503.06664', 'title': 'Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets', 'authors': 'Tommaso Bendinelli, Artur Dox, Christian Holz', 'link': 'https://arxiv.org/abs/2503.06664', 'abstract': 'High-quality, error-free datasets are a key ingredient in building reliable, accurate, and unbiased machine learning (ML) models. However, real world datasets often suffer from errors due to sensor malfunctions, data entry mistakes, or improper data integration across multiple sources that can severely degrade model performance. Detecting and correcting these issues typically require tailor-made solutions and demand extensive domain expertise. Consequently, automation is challenging, rendering the process labor-intensive and tedious. In this study, we investigate whether Large Language Models (LLMs) can help alleviate the burden of manual data cleaning. We set up an experiment in which an LLM, paired with Python, is tasked with cleaning the training dataset to improve the performance of a learning algorithm without having the ability to modify the training pipeline or perform any feature engineering. We run this experiment on multiple Kaggle datasets that have been intentionally corrupted with errors. Our results show that LLMs can identify and correct erroneous entries, such as illogical values or outlier, by leveraging contextual information from other features within the same row, as well as feedback from previous iterations. However, they struggle to detect more complex errors that require understanding data distribution across multiple rows, such as trends and biases.', 'abstract_zh': '高质量、无错误的数据集是构建可靠、准确和无偏见的机器学习模型的关键。然而，由于传感器故障、数据录入错误或来自多个来源的数据整合不当，现实世界的数据集 often 患有严重降低模型性能的错误。检测和纠正这些错误通常需要量身定制的解决方案，并要求广泛的领域专业知识。因此，自动化变得具有挑战性，使过程变得劳动密集且繁琐。在本研究中，我们探讨大型语言模型（LLMs）是否能帮助减轻手动数据清洗的负担。我们建立了一个实验，在该实验中，一个 LLM 与 Python 结合使用，被任务委托清洗训练数据集以提高学习算法的性能，而不对其 training pipeline 进行任何修改或进行任何特征工程。我们在此实验中使用了多个故意添加错误的 Kaggle 数据集。结果显示，LLMs 可以通过利用同一行中其他特征的上下文信息以及从前一迭代的反馈来识别和纠正错误条目，如不合逻辑的值或离群值。然而，它们难以检测需要理解多行数据分布的更复杂的错误，如趋势和偏见。', 'title_zh': '探索LLM代理清理表格机器学习数据集'}
{'arxiv_id': 'arXiv:2503.06661', 'title': 'AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP', 'authors': 'Wenxin Ma, Xu Zhang, Qingsong Yao, Fenghe Tang, Chenxu Wu, Yingtai Li, Rui Yan, Zihang Jiang, S.Kevin Zhou', 'link': 'https://arxiv.org/abs/2503.06661', 'abstract': "Anomaly detection (AD) identifies outliers for applications like defect and lesion detection. While CLIP shows promise for zero-shot AD tasks due to its strong generalization capabilities, its inherent Anomaly-Unawareness leads to limited discrimination between normal and abnormal features. To address this problem, we propose Anomaly-Aware CLIP (AA-CLIP), which enhances CLIP's anomaly discrimination ability in both text and visual spaces while preserving its generalization capability. AA-CLIP is achieved through a straightforward yet effective two-stage approach: it first creates anomaly-aware text anchors to differentiate normal and abnormal semantics clearly, then aligns patch-level visual features with these anchors for precise anomaly localization. This two-stage strategy, with the help of residual adapters, gradually adapts CLIP in a controlled manner, achieving effective AD while maintaining CLIP's class knowledge. Extensive experiments validate AA-CLIP as a resource-efficient solution for zero-shot AD tasks, achieving state-of-the-art results in industrial and medical applications. The code is available at this https URL.", 'abstract_zh': '基于异常感知的CLIP（AA-CLIP）在零样本异常检测任务中的应用', 'title_zh': 'AA-CLIP: 基于异常意识CLIP的零样本异常检测增强方法'}
{'arxiv_id': 'arXiv:2503.06648', 'title': 'Enhancing NLP Robustness and Generalization through LLM-Generated Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial Training', 'authors': 'Hender Lin', 'link': 'https://arxiv.org/abs/2503.06648', 'abstract': 'Standard NLP benchmarks often fail to capture vulnerabilities stemming from dataset artifacts and spurious correlations. Contrast sets address this gap by challenging models near decision boundaries but are traditionally labor-intensive to create and limited in diversity. This study leverages large language models to automate the generation of diverse contrast sets. Using the SNLI dataset, we created a 3,000-example contrast set to evaluate and improve model robustness. Fine-tuning on these contrast sets enhanced performance on systematically perturbed examples, maintained standard test accuracy, and modestly improved generalization to novel perturbations. This automated approach offers a scalable solution for evaluating and improving NLP models, addressing systematic generalization challenges, and advancing robustness in real-world applications.', 'abstract_zh': '标准的NLP基准常常无法捕捉数据集 artefacts 和虚假相关性导致的漏洞。对比集通过在决策边界附近挑战模型来弥补这一缺陷，但传统上创建过程耗时且多样性有限。本研究利用大语言模型来自动化生成具有多样性的对比集。使用SNLI数据集，我们创建了一个包含3000个样本的对比集以评估和提升模型的鲁棒性。在这些对比集上的微调在系统扰动样本上的性能得到了提升，保持了标准测试准确性，并适度提高了对新型扰动的泛化能力。这种自动化方法为评估和提升NLP模型、解决系统泛化挑战以及在实际应用中推进鲁棒性提供了一种可扩展的解决方案。', 'title_zh': '通过LLM生成的对比集增强NLP的 robustness和泛化能力：一种系统评估和对抗训练的可扩展框架'}
{'arxiv_id': 'arXiv:2503.06635', 'title': 'Deep Cut-informed Graph Embedding and Clustering', 'authors': 'Zhiyuan Ning, Zaitian Wang, Ran Zhang, Ping Xu, Kunpeng Liu, Pengyang Wang, Chong Chen, Pengfei Wang, Yuanchun Zhou, Erik Cambria', 'link': 'https://arxiv.org/abs/2503.06635', 'abstract': 'Graph clustering aims to divide the graph into different clusters. The recently emerging deep graph clustering approaches are largely built on graph neural networks (GNN). However, GNN is designed for general graph encoding and there is a common issue of representation collapse in existing GNN-based deep graph clustering algorithms. We attribute two main reasons for such issue: (i) the inductive bias of GNN models: GNNs tend to generate similar representations for proximal nodes. Since graphs often contain a non-negligible amount of inter-cluster links, the bias results in error message passing and leads to biased clustering; (ii) the clustering guided loss function: most traditional approaches strive to make all samples closer to pre-learned cluster centers, which cause a degenerate solution assigning all data points to a single label thus make all samples and less discriminative. To address these challenges, we investigate graph clustering from a graph cut perspective and propose an innovative and non-GNN-based Deep Cut-informed Graph embedding and Clustering framework, namely DCGC. This framework includes two modules: (i) cut-informed graph encoding; (ii) self-supervised graph clustering via optimal transport. For the encoding module, we derive a cut-informed graph embedding objective to fuse graph structure and attributes by minimizing their joint normalized cut. For the clustering module, we utilize the optimal transport theory to obtain the clustering assignments, which can balance the guidance of proximity to the pre-learned cluster center. With the above two tailored designs, DCGC is more suitable for the graph clustering task, which can effectively alleviate the problem of representation collapse and achieve better performance. We conduct extensive experiments to demonstrate that our method is simple but effective compared with benchmarks.', 'abstract_zh': '基于图切分的非GNN深度图嵌入与聚类框架：DCGC', 'title_zh': '基于深切图的图嵌入与聚类'}
{'arxiv_id': 'arXiv:2503.06633', 'title': 'BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External Data Distributions in Federated learning', 'authors': 'Yu Zhou, Bingyan Liu', 'link': 'https://arxiv.org/abs/2503.06633', 'abstract': 'Federated Learning (FL) enables multiple clients to collaboratively develop a global model while maintaining data privacy. However, online FL deployment faces challenges due to distribution shifts and evolving test samples. Personalized Federated Learning (PFL) tailors the global model to individual client distributions, but struggles with Out-Of-Distribution (OOD) samples during testing, leading to performance degradation. In real-world scenarios, balancing personalization and generalization during online testing is crucial and existing methods primarily focus on training-phase generalization. To address the test-time trade-off, we introduce a new scenario: Test-time Generalization for Internal and External Distributions in Federated Learning (TGFL), which evaluates adaptability under Internal Distribution (IND) and External Distribution (EXD). We propose BTFL, a Bayesian-based test-time generalization method for TGFL, which balances generalization and personalization at the sample level during testing. BTFL employs a two-head architecture to store local and global knowledge, interpolating predictions via a dual-Bayesian framework that considers both historical test data and current sample characteristics with theoretical guarantee and faster speed. Our experiments demonstrate that BTFL achieves improved performance across various datasets and models with less time cost. The source codes are made publicly available at this https URL .', 'abstract_zh': '联邦学习中的内部和外部分布下的测试时泛化（BTFL）：一种基于贝叶斯的测试时泛化方法', 'title_zh': 'BTFL：一种基于贝叶斯方法的fed学习内外数据分布迁移测试时泛化方法'}
{'arxiv_id': 'arXiv:2503.06629', 'title': 'Hardware-Accelerated Event-Graph Neural Networks for Low-Latency Time-Series Classification on SoC FPGA', 'authors': 'Hiroshi Nakano, Krzysztof Blachut, Kamil Jeziorek, Piotr Wzorek, Manon Dampfhoffer, Thomas Mesquida, Hiroaki Nishi, Tomasz Kryjak, Thomas Dalgaty', 'link': 'https://arxiv.org/abs/2503.06629', 'abstract': 'As the quantities of data recorded by embedded edge sensors grow, so too does the need for intelligent local processing. Such data often comes in the form of time-series signals, based on which real-time predictions can be made locally using an AI model. However, a hardware-software approach capable of making low-latency predictions with low power consumption is required. In this paper, we present a hardware implementation of an event-graph neural network for time-series classification. We leverage an artificial cochlea model to convert the input time-series signals into a sparse event-data format that allows the event-graph to drastically reduce the number of calculations relative to other AI methods. We implemented the design on a SoC FPGA and applied it to the real-time processing of the Spiking Heidelberg Digits (SHD) dataset to benchmark our approach against competitive solutions. Our method achieves a floating-point accuracy of 92.7% on the SHD dataset for the base model, which is only 2.4% and 2% less than the state-of-the-art models with over 10% and 67% fewer model parameters, respectively. It also outperforms FPGA-based spiking neural network implementations by 19.3% and 4.5%, achieving 92.3% accuracy for the quantised model while using fewer computational resources and reducing latency.', 'abstract_zh': '基于事件图神经网络的时间序列分类的硬件实现', 'title_zh': '基于SoC FPGA的硬件加速事件图神经网络低延迟时间序列分类'}
{'arxiv_id': 'arXiv:2503.06627', 'title': 'Revisiting Early Detection of Sexual Predators via Turn-level Optimization', 'authors': 'Jinmyeong An, Sangwon Ryu, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee', 'link': 'https://arxiv.org/abs/2503.06627', 'abstract': "Online grooming is a severe social threat where sexual predators gradually entrap child victims with subtle and gradual manipulation. Therefore, timely intervention for online grooming is critical for proactive protection. However, previous methods fail to determine the optimal intervention points (i.e., jump to conclusions) as they rely on chat-level risk labels by causing weak supervision of risky utterances. For timely detection, we propose speed control reinforcement learning (SCoRL) (The code and supplementary materials are available at this https URL), incorporating a practical strategy derived from luring communication theory (LCT). To capture the predator's turn-level entrapment, we use a turn-level risk label based on the LCT. Then, we design a novel speed control reward function that balances the trade-off between speed and accuracy based on turn-level risk label; thus, SCoRL can identify the optimal intervention moment. In addition, we introduce a turn-level metric for precise evaluation, identifying limitations in previously used chat-level metrics. Experimental results show that SCoRL effectively preempted online grooming, offering a more proactive and timely solution. Further analysis reveals that our method enhances performance while intuitively identifying optimal early intervention points.", 'abstract_zh': '在线诱骗是一种严重的社会威胁，性 predators 通过微妙而渐进的操纵逐步诱骗儿童受害者。因此，及时干预在线诱骗对于主动保护至关重要。然而，以往的方法未能确定最佳干预点（即过早下结论），因为它们依赖于对话级别风险标签，导致对风险性陈述的监督薄弱。为实现及时检测，我们提出了一种速度控制强化学习（SCoRL）方法（代码和补充材料可在以下链接获取：this https URL），结合了诱骗沟通理论（LCT）提出的一种实用策略。为了捕捉 predator 的回合级诱骗，我们基于 LCT 使用了回合级风险标签。然后，我们设计了一种新的速度控制奖励函数，该函数基于回合级风险标签平衡速度与准确性的trade-off；因此，SCoRL 可以识别最优干预时刻。此外，我们引入了回合级评估指标，以精确评估并识别先前使用的对话级评估指标的局限性。实验结果显示，SCoRL 有效预防了在线诱骗，提供了更为主动和及时的解决方案。进一步分析表明，我们的方法在直观地识别最优早期干预点方面提高了性能。', 'title_zh': '重新审视基于对话回合级优化的早期识别性虐待者方法'}
{'arxiv_id': 'arXiv:2503.06626', 'title': 'DiffCLIP: Differential Attention Meets CLIP', 'authors': 'Hasan Abed Al Kader Hammoud, Bernard Ghanem', 'link': 'https://arxiv.org/abs/2503.06626', 'abstract': "We propose DiffCLIP, a novel vision-language model that extends the differential attention mechanism to CLIP architectures. Differential attention was originally developed for large language models to amplify relevant context while canceling out noisy information. In this work, we integrate this mechanism into CLIP's dual encoder (image and text) framework. With minimal additional parameters, DiffCLIP achieves superior performance on image-text understanding tasks. Across zero-shot classification, retrieval, and robustness benchmarks, DiffCLIP consistently outperforms baseline CLIP models. Notably, these gains come with negligible computational overhead, demonstrating that differential attention can significantly enhance multi-modal representations without sacrificing efficiency. Code can be found at this https URL.", 'abstract_zh': '我们提出DiffCLIP，这是一种将差异注意力机制扩展到CLIP架构的新型跨模态模型。差异注意力最初是为大型语言模型设计的，用于放大相关背景并抵消噪声信息。在本文中，我们将这种机制整合到CLIP的双编码器（图像和文本）框架中。通过少量额外参数，DiffCLIP在图像-文本理解任务上取得了优越的性能。在零-shot分类、检索和鲁棒性基准测试中，DiffCLIP始终优于基线CLIP模型。值得注意的是，这些性能提升几乎不增加计算开销，这表明差异注意力可以显著增强多模态表示而不牺牲效率。代码详见GitHub。', 'title_zh': 'DiffCLIP: 差异注意力结合CLIP'}
{'arxiv_id': 'arXiv:2503.06614', 'title': 'Using Subgraph GNNs for Node Classification:an Overlooked Potential Approach', 'authors': 'Qian Zeng, Xin Lin, Jingyi Gao, Yang Yu', 'link': 'https://arxiv.org/abs/2503.06614', 'abstract': 'Previous studies have demonstrated the strong performance of Graph Neural Networks (GNNs) in node classification. However, most existing GNNs adopt a node-centric perspective and rely on global message passing, leading to high computational and memory costs that hinder scalability. To mitigate these challenges, subgraph-based methods have been introduced, leveraging local subgraphs as approximations of full computational trees. While this approach improves efficiency, it often suffers from performance degradation due to the loss of global contextual information, limiting its effectiveness compared to global GNNs. To address this trade-off between scalability and classification accuracy, we reformulate the node classification task as a subgraph classification problem and propose SubGND (Subgraph GNN for NoDe). This framework introduces a differentiated zero-padding strategy and an Ego-Alter subgraph representation method to resolve label conflicts while incorporating an Adaptive Feature Scaling Mechanism to dynamically adjust feature contributions based on dataset-specific dependencies. Experimental results on six benchmark datasets demonstrate that SubGND achieves performance comparable to or surpassing global message-passing GNNs, particularly in heterophilic settings, highlighting its effectiveness and scalability as a promising solution for node classification.', 'abstract_zh': '基于子图的节点分类方法SubGND：在保持分类准确性的同时提高可扩展性', 'title_zh': '使用子图GNNs进行节点分类：一种被忽视的潜在方法'}
{'arxiv_id': 'arXiv:2503.06573', 'title': 'WildIFEval: Instruction Following in the Wild', 'authors': 'Gili Lior, Asaf Yehudai, Ariel Gera, Liat Ein-Dor', 'link': 'https://arxiv.org/abs/2503.06573', 'abstract': 'Recent LLMs have shown remarkable success in following user instructions, yet handling instructions with multiple constraints remains a significant challenge. In this work, we introduce WildIFEval - a large-scale dataset of 12K real user instructions with diverse, multi-constraint conditions. Unlike prior datasets, our collection spans a broad lexical and topical spectrum of constraints, in natural user prompts. We categorize these constraints into eight high-level classes to capture their distribution and dynamics in real-world scenarios. Leveraging WildIFEval, we conduct extensive experiments to benchmark the instruction-following capabilities of leading LLMs. Our findings reveal that all evaluated models experience performance degradation with an increasing number of constraints. Thus, we show that all models have a large room for improvement on such tasks. Moreover, we observe that the specific type of constraint plays a critical role in model performance. We release our dataset to promote further research on instruction-following under complex, realistic conditions.', 'abstract_zh': 'Recent LLMs在遵循用户指令方面取得了显著成功，但在处理具有多种约束的指令方面仍面临重大挑战。本文介绍WildIFEval - 一个包含12000个真实用户指令的大规模数据集，这些指令具有多样性和多约束条件。与先前的 datasets 不同，我们的收集涵盖了广泛的语言和主题约束范围，这些约束自然出现在用户提示中。我们将这些约束分为八个高层次类别，以捕捉其在现实世界场景中的分布和动态。利用WildIFEval，我们进行了广泛的实验以评估领先LLM的指令遵循能力。我们的发现表明，所有评估模型在约束数量增加时会表现出性能下降。因此，我们展示出所有模型在这类任务上仍有很大的改进空间。此外，我们观察到特定类型的约束在模型性能中起着关键作用。我们公开发布该数据集，以促进在复杂和实际条件下指令遵循的研究。', 'title_zh': 'WildIFEval: 野外的指令跟随'}
{'arxiv_id': 'arXiv:2503.06571', 'title': 'SHIP: A Shapelet-based Approach for Interpretable Patient-Ventilator Asynchrony Detection', 'authors': 'Xuan-May Le, Ling Luo, Uwe Aickelin, Minh-Tuan Tran, David Berlowitz, Mark Howard', 'link': 'https://arxiv.org/abs/2503.06571', 'abstract': 'Patient-ventilator asynchrony (PVA) is a common and critical issue during mechanical ventilation, affecting up to 85% of patients. PVA can result in clinical complications such as discomfort, sleep disruption, and potentially more severe conditions like ventilator-induced lung injury and diaphragm dysfunction. Traditional PVA management, which relies on manual adjustments by healthcare providers, is often inadequate due to delays and errors. While various computational methods, including rule-based, statistical, and deep learning approaches, have been developed to detect PVA events, they face challenges related to dataset imbalances and lack of interpretability. In this work, we propose a shapelet-based approach SHIP for PVA detection, utilizing shapelets - discriminative subsequences in time-series data - to enhance detection accuracy and interpretability. Our method addresses dataset imbalances through shapelet-based data augmentation and constructs a shapelet pool to transform the dataset for more effective classification. The combined shapelet and statistical features are then used in a classifier to identify PVA events. Experimental results on medical datasets show that SHIP significantly improves PVA detection while providing interpretable insights into model decisions.', 'abstract_zh': '基于形状let的方法SHIP在机械通气患者-呼吸机不协调检测中的应用：提高检测准确性和可解释性', 'title_zh': 'SHIP：一种基于形状图的可解释患者-呼吸机异步检测方法'}
{'arxiv_id': 'arXiv:2503.06568', 'title': 'Conceptrol: Concept Control of Zero-shot Personalized Image Generation', 'authors': 'Qiyuan He, Angela Yao', 'link': 'https://arxiv.org/abs/2503.06568', 'abstract': 'Personalized image generation with text-to-image diffusion models generates unseen images based on reference image content. Zero-shot adapter methods such as IP-Adapter and OminiControl are especially interesting because they do not require test-time fine-tuning. However, they struggle to balance preserving personalized content and adherence to the text prompt. We identify a critical design flaw resulting in this performance gap: current adapters inadequately integrate personalization images with the textual descriptions. The generated images, therefore, replicate the personalized content rather than adhere to the text prompt instructions. Yet the base text-to-image has strong conceptual understanding capabilities that can be leveraged.\nWe propose Conceptrol, a simple yet effective framework that enhances zero-shot adapters without adding computational overhead. Conceptrol constrains the attention of visual specification with a textual concept mask that improves subject-driven generation capabilities. It achieves as much as 89% improvement on personalization benchmarks over the vanilla IP-Adapter and can even outperform fine-tuning approaches such as Dreambooth LoRA. The source code is available at this https URL.', 'abstract_zh': '个性化图像生成中的文本到图像扩散模型可以根据参考图像内容生成未见过的图像。零样本适配器方法如IP-Adapter和OminiControl特别有趣，因为它们不需要测试时 Fine-Tuning。然而，它们在保持个性化内容与遵循文本提示方面难以达到平衡。我们指出了造成这种性能差距的关键设计缺陷：当前的适配器未能充分将个性化图像与文本描述集成。因此，生成的图像复制了个性化内容而非遵循文本提示指令。然而，基础的文本到图像模型具备强大的概念理解能力，可以加以利用。\n\n我们提出了一种简单有效的框架Conceptrol，可以在不增加计算开销的情况下增强零样本适配器。Conceptrol利用文本概念掩码来约束视觉规范的注意力，从而提高以主题驱动的生成能力。它在个性化基准测试中的表现提高了89%，甚至可以超越Fine-Tuning方法如Dreambooth LoRA。代码可在以下链接获取。', 'title_zh': 'Conceptrol: 零样本个性化图像生成的概念控制'}
{'arxiv_id': 'arXiv:2503.06567', 'title': 'Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving', 'authors': 'Yao Cheng, Yibo Zhao, Jiapeng Zhu, Yao Liu, Xing Sun, Xiang Li', 'link': 'https://arxiv.org/abs/2503.06567', 'abstract': 'Large language models (LLMs) have demonstrated transformative potential across various domains, yet they face significant challenges in knowledge integration and complex problem reasoning, often leading to hallucinations and unreliable outputs. Retrieval-Augmented Generation (RAG) has emerged as a promising solution to enhance LLMs accuracy by incorporating external knowledge. However, traditional RAG systems struggle with processing complex relational information and multi-step reasoning, limiting their effectiveness in advanced problem-solving tasks. To address these limitations, we propose CogGRAG, a cognition inspired graph-based RAG framework, designed to improve LLMs performance in Knowledge Graph Question Answering (KGQA). Inspired by the human cognitive process of decomposing complex problems and performing self-verification, our framework introduces a three-stage methodology: decomposition, retrieval, and reasoning with self-verification. By integrating these components, CogGRAG enhances the accuracy of LLMs in complex problem solving. We conduct systematic experiments with three LLM backbones on four benchmark datasets, where CogGRAG outperforms the baselines.', 'abstract_zh': '大规模语言模型（LLMs）在各个领域展现出了变革性的潜力，但在知识整合和复杂问题推理方面面临重大挑战，经常导致虚构和不可靠的输出。检索增强生成（RAG）作为一种增强LLMs准确性的方法，通过引入外部知识已 emerges as a promising solution.然而，传统RAG系统在处理复杂关系信息和多步推理方面存在困难，限制了其在高级问题解决任务中的有效性。为了解决这些局限性，我们提出了一种基于图的认知启发式RAG框架CogGRAG，旨在提高LLMs在知识图谱问答（KGQA）中的性能。我们的框架借鉴了人类认知过程中的问题分解和自我验证机制，采用三阶段方法：分解、检索和带有自我验证的推理。通过整合这些组件，CogGRAG增强了LLMs在复杂问题解决中的准确性。我们在四个基准数据集上使用三种LLM骨干网络进行了系统的实验，其中CogGRAG优于基线方法。', 'title_zh': '基于知识图谱的人类认知启发式RAG复杂问题求解'}
{'arxiv_id': 'arXiv:2503.06563', 'title': 'LSA: Latent Style Augmentation Towards Stain-Agnostic Cervical Cancer Screening', 'authors': 'Jiangdong Cai, Haotian Jiang, Zhenrong Shen, Yonghao Li, Honglin Xiong, Lichi Zhang, Qian Wang', 'link': 'https://arxiv.org/abs/2503.06563', 'abstract': 'The deployment of computer-aided diagnosis systems for cervical cancer screening using whole slide images (WSIs) faces critical challenges due to domain shifts caused by staining variations across different scanners and imaging environments. While existing stain augmentation methods improve patch-level robustness, they fail to scale to WSIs due to two key limitations: (1) inconsistent stain patterns when extending patch operations to gigapixel slides, and (2) prohibitive computational/storage costs from offline processing of augmented this http URL address this, we propose Latent Style Augmentation (LSA), a framework that performs efficient, online stain augmentation directly on WSI-level latent features. We first introduce WSAug, a WSI-level stain augmentation method ensuring consistent stain across patches within a WSI. Using offline-augmented WSIs by WSAug, we design and train Stain Transformer, which can simulate targeted style in the latent space, efficiently enhancing the robustness of the WSI-level classifier. We validate our method on a multi-scanner WSI dataset for cervical cancer diagnosis. Despite being trained on data from a single scanner, our approach achieves significant performance improvements on out-of-distribution data from other scanners. Code will be available at this https URL.', 'abstract_zh': '使用整个切片图像（WSI）进行宫颈癌筛查的计算机辅助诊断系统的部署受到跨不同扫描器和成像环境的染色变异引起的领域变化的严峻挑战。尽管现有的染色增强方法可以提高局部鲁棒性，但由于两个关键限制，它们难以扩展到WSI：（1）在扩展局部操作到 gigapixel 切片时的一致染色模式不一致，（2）从离线处理增强切片所导致的高昂的计算/存储成本。为了解决这一问题，我们提出了一种称为潜在風格增强（Latent Style Augmentation，LSA）的框架，该框架可以在WSI级别的潜在特征上直接执行高效的在线染色增强。我们首先引入WSAug，一种WSI级别的染色增强方法，确保WSI内各个局部区域的一致染色。利用WSAug离线增强的WSI，我们设计并训练Stain Transformer，该模型可以在潜在空间中模拟目标风格，高效地增强WSI级分类器的鲁棒性。我们在一个包含多个扫描器的WSI数据集上验证了该方法，尽管仅使用单个扫描器的数据进行训练，但在来自其他扫描器的外部数据上实现了显著的性能提升。代码可从此地址获取。', 'title_zh': 'LSA: 潜在风格增强 toward 无染色差异性的宫颈癌筛查'}
{'arxiv_id': 'arXiv:2503.06542', 'title': 'ARMOR v0.1: Empowering Autoregressive Multimodal Understanding Model with Interleaved Multimodal Generation via Asymmetric Synergy', 'authors': 'Jianwen Sun, Yukang Feng, Chuanhao Li, Fanrui Zhang, Zizhen Li, Jiaxin Ai, Sizhuo Zhou, Yu Dai, Shenglin Zhang, Kaipeng Zhang', 'link': 'https://arxiv.org/abs/2503.06542', 'abstract': 'Unified models (UniMs) for multimodal understanding and generation have recently received much attention in the area of vision and language. Existing UniMs are designed to simultaneously learn both multimodal understanding and generation capabilities, demanding substantial computational resources, and often struggle to generate interleaved text-image. We present ARMOR, a resource-efficient and pure autoregressive framework that achieves both understanding and generation by fine-tuning existing multimodal large language models (MLLMs). Specifically, ARMOR extends existing MLLMs from three perspectives: (1) For model architecture, an asymmetric encoder-decoder architecture with a forward-switching mechanism is introduced to unify embedding space integrating textual and visual modalities for enabling natural text-image interleaved generation with minimal computational overhead. (2) For training data, a meticulously curated, high-quality interleaved dataset is collected for fine-tuning MLLMs. (3) For the training algorithm, we propose a ``what or how to generate" algorithm to empower existing MLLMs with multimodal generation capabilities while preserving their multimodal understanding capabilities, through three progressive training stages based on the collected dataset. Experimental results demonstrate that ARMOR upgrades existing MLLMs to UniMs with promising image generation capabilities, using limited training resources. Our code will be released soon at this https URL.', 'abstract_zh': '资源高效且纯粹的自回归框架ARMOR：通过微调现有的多模态大型语言模型实现统一的多模态理解和生成', 'title_zh': 'ARMOR v0.1：通过交错多模态生成增强的自回归多模态理解模型异构协同'}
{'arxiv_id': 'arXiv:2503.06529', 'title': 'AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection', 'authors': 'Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow', 'link': 'https://arxiv.org/abs/2503.06529', 'abstract': 'As object detection becomes integral to many safety-critical applications, understanding its vulnerabilities is essential. Backdoor attacks, in particular, pose a serious threat by implanting hidden triggers in victim models, which adversaries can later exploit to induce malicious behaviors during inference. However, current understanding is limited to single-target attacks, where adversaries must define a fixed malicious behavior (target) before training, making inference-time adaptability impossible. Given the large output space of object detection (including object existence prediction, bounding box estimation, and classification), the feasibility of flexible, inference-time model control remains unexplored. This paper introduces AnywhereDoor, a multi-target backdoor attack for object detection. Once implanted, AnywhereDoor allows adversaries to make objects disappear, fabricate new ones, or mislabel them, either across all object classes or specific ones, offering an unprecedented degree of control. This flexibility is enabled by three key innovations: (i) objective disentanglement to scale the number of supported targets; (ii) trigger mosaicking to ensure robustness even against region-based detectors; and (iii) strategic batching to address object-level data imbalances that hinder manipulation. Extensive experiments demonstrate that AnywhereDoor grants attackers a high degree of control, improving attack success rates by 26% compared to adaptations of existing methods for such flexible control.', 'abstract_zh': '对象检测中的多目标后门攻击：AnywhereDoor', 'title_zh': 'AnywhereDoor：面向目标检测的多目标后门攻击'}
{'arxiv_id': 'arXiv:2503.06525', 'title': 'From Motion Signals to Insights: A Unified Framework for Student Behavior Analysis and Feedback in Physical Education Classes', 'authors': 'Xian Gao, Jiacheng Ruan, Jingsheng Gao, Mingye Xie, Zongyun Zhang, Ting Liu, Yuzhuo Fu', 'link': 'https://arxiv.org/abs/2503.06525', 'abstract': "Analyzing student behavior in educational scenarios is crucial for enhancing teaching quality and student engagement. Existing AI-based models often rely on classroom video footage to identify and analyze student behavior. While these video-based methods can partially capture and analyze student actions, they struggle to accurately track each student's actions in physical education classes, which take place in outdoor, open spaces with diverse activities, and are challenging to generalize to the specialized technical movements involved in these settings. Furthermore, current methods typically lack the ability to integrate specialized pedagogical knowledge, limiting their ability to provide in-depth insights into student behavior and offer feedback for optimizing instructional design. To address these limitations, we propose a unified end-to-end framework that leverages human activity recognition technologies based on motion signals, combined with advanced large language models, to conduct more detailed analyses and feedback of student behavior in physical education classes. Our framework begins with the teacher's instructional designs and the motion signals from students during physical education sessions, ultimately generating automated reports with teaching insights and suggestions for improving both learning and class instructions. This solution provides a motion signal-based approach for analyzing student behavior and optimizing instructional design tailored to physical education classes. Experimental results demonstrate that our framework can accurately identify student behaviors and produce meaningful pedagogical insights.", 'abstract_zh': '基于运动信号的统一端到端框架：提升体育教学设计的学生行为分析与优化', 'title_zh': '从运动信号到洞察：体育课中学生行为分析与反馈的统一框架'}
{'arxiv_id': 'arXiv:2503.06523', 'title': 'Generative AI as Digital Media', 'authors': 'Gilad Abiri', 'link': 'https://arxiv.org/abs/2503.06523', 'abstract': "Generative AI is frequently portrayed as revolutionary or even apocalyptic, prompting calls for novel regulatory approaches. This essay argues that such views are misguided. Instead, generative AI should be understood as an evolutionary step in the broader algorithmic media landscape, alongside search engines and social media. Like these platforms, generative AI centralizes information control, relies on complex algorithms to shape content, and extensively uses user data, thus perpetuating common problems: unchecked corporate power, echo chambers, and weakened traditional gatekeepers. Regulation should therefore share a consistent objective: ensuring media institutions remain trustworthy. Without trust, public discourse risks fragmenting into isolated communities dominated by comforting, tribal beliefs -- a threat intensified by generative AI's capacity to bypass gatekeepers and personalize truth. Current governance frameworks, such as the EU's AI Act and the US Executive Order 14110, emphasize reactive risk mitigation, addressing measurable threats like national security, public health, and algorithmic bias. While effective for novel technological risks, this reactive approach fails to adequately address broader issues of trust and legitimacy inherent to digital media. Proactive regulation fostering transparency, accountability, and public confidence is essential. Viewing generative AI exclusively as revolutionary risks repeating past regulatory failures that left social media and search engines insufficiently regulated. Instead, regulation must proactively shape an algorithmic media environment serving the public good, supporting quality information and robust civic discourse.", 'abstract_zh': '生成式AI常常被描绘为革命性的甚至带来 apocalypse 的技术，促使人们呼吁采取新的监管方法。本文认为这些观点是误导性的。相反，生成式AI应被视为在更广泛的算法媒体景观中的一种进化步骤，类似于搜索引擎和社会媒体。与这些平台一样，生成式AI集中控制信息，依赖复杂的算法来塑造内容，并大量使用用户数据，从而延续了常见的问题：不受约束的公司权力、回声室效应和传统把关人的削弱。因此，监管应致力于一个共同目标：确保媒体机构保持可信度。缺乏信任，公共话语风险分裂成由令人安慰的部落信念主导的孤立社区——生成式AI绕过把关人和个性化真实性的能力使其威胁加剧。当前的治理框架，如欧盟AI法案和美国行政命令14110，强调应对性风险缓解，针对国家安保、公共健康和算法偏见等可测量的威胁。虽然对于新兴技术风险是有效的，但这种应对性方法未能充分解决数字媒体中固有的信任和合法性问题。建立促进透明度、问责制和公众信心的前瞻性监管是必不可少的。仅仅将生成式AI视为革命性的风险，有重复过去监管失败、使社交媒体和搜索引擎监管不足的危险。相反，监管必须积极塑造服务于公共利益的算法媒体环境，支持高质量信息和稳健的公民对话。', 'title_zh': '生成式AI作为数字媒体'}
{'arxiv_id': 'arXiv:2503.06519', 'title': 'Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation', 'authors': 'Wenhui Zhang, Huiyu Xu, Zhibo Wang, Zeqing He, Ziqi Zhu, Kui Ren', 'link': 'https://arxiv.org/abs/2503.06519', 'abstract': "Small language models (SLMs) have emerged as promising alternatives to large language models (LLMs) due to their low computational demands, enhanced privacy guarantees and comparable performance in specific domains through light-weight fine-tuning. Deploying SLMs on edge devices, such as smartphones and smart vehicles, has become a growing trend. However, the security implications of SLMs have received less attention than LLMs, particularly regarding jailbreak attacks, which is recognized as one of the top threats of LLMs by the OWASP. In this paper, we conduct the first large-scale empirical study of SLMs' vulnerabilities to jailbreak attacks. Through systematically evaluation on 63 SLMs from 15 mainstream SLM families against 8 state-of-the-art jailbreak methods, we demonstrate that 47.6% of evaluated SLMs show high susceptibility to jailbreak attacks (ASR > 40%) and 38.1% of them can not even resist direct harmful query (ASR > 50%). We further analyze the reasons behind the vulnerabilities and identify four key factors: model size, model architecture, training datasets and training techniques. Moreover, we assess the effectiveness of three prompt-level defense methods and find that none of them achieve perfect performance, with detection accuracy varying across different SLMs and attack methods. Notably, we point out that the inherent security awareness play a critical role in SLM security, and models with strong security awareness could timely terminate unsafe response with little reminder. Building upon the findings, we highlight the urgent need for security-by-design approaches in SLM development and provide valuable insights for building more trustworthy SLM ecosystem.", 'abstract_zh': '小语言模型（SLMs）对大型语言模型（LLMs）的低计算需求、增强的隐私保障以及在特定领域通过轻量级微调表现出的可相比拟性能的前景，使之成为了有前途的替代方案。将SLMs部署在边缘设备（如智能手机和智能车辆）上已成为一种增长的趋势。然而，SLMs的安全影响并未像LLMs那样受到广泛关注，特别是在关于逃逸攻击方面，OWASP已将其认定为LLMs的首要威胁之一。在本文中，我们首次进行了大规模的实证研究，探讨SLMs对逃逸攻击的脆弱性。通过对来自15个主流小语言模型家族的63个SLMs进行系统性评估，对比8种最先进的逃逸攻击方法，我们证明了47.6%的评估SLMs对逃逸攻击显示出高度易感性（ASR > 40%），甚至有38.1%的SLMs无法抵御直接有害查询（ASR > 50%）。我们进一步分析了这些脆弱性的原因，并确定了四个关键因素：模型大小、模型架构、训练数据集和训练技术。此外，我们评估了三种提示级防御方法的有效性，发现这三种方法均未实现完美的性能，其检测准确率在不同的SLMs和攻击方法之间存在差异。我们指出，固有的安全意识在SLMs安全中扮演着至关重要的角色，拥有强烈安全意识的模型能够及时终止不安全的响应，且几乎不需要提醒。基于上述发现，我们强调了在SLMs开发中采用设计即安全方法的迫切需求，并为构建更可信赖的SLM生态系统提供了宝贵的见解。', 'title_zh': '小型语言模型能可靠地抵御 Jailbreak 攻击吗？一项全面评估'}
{'arxiv_id': 'arXiv:2503.06518', 'title': 'Towards Superior Quantization Accuracy: A Layer-sensitive Approach', 'authors': 'Feng Zhang, Yanbin Liu, Weihua Li, Jie Lv, Xiaodan Wang, Quan Bai', 'link': 'https://arxiv.org/abs/2503.06518', 'abstract': 'Large Vision and Language Models have exhibited remarkable human-like intelligence in tasks such as natural language comprehension, problem-solving, logical reasoning, and knowledge retrieval. However, training and serving these models require substantial computational resources, posing a significant barrier to their widespread application and further research. To mitigate this challenge, various model compression techniques have been developed to reduce computational requirements. Nevertheless, existing methods often employ uniform quantization configurations, failing to account for the varying difficulties across different layers in quantizing large neural network models. This paper tackles this issue by leveraging layer-sensitivity features, such as activation sensitivity and weight distribution Kurtosis, to identify layers that are challenging to quantize accurately and allocate additional memory budget. The proposed methods, named SensiBoost and KurtBoost, respectively, demonstrate notable improvement in quantization accuracy, achieving up to 9% lower perplexity with only a 2% increase in memory budget on LLama models compared to the baseline.', 'abstract_zh': '大型视觉与语言模型在自然语言理解、问题解决、逻辑推理和知识检索等任务中表现出令人瞩目的人类智能水平。然而，训练和部署这些模型需要大量的计算资源，成为其广泛应用和进一步研究的重要障碍。为缓解这一问题，开发了多种模型压缩技术以减少计算需求。尽管现有方法通常采用统一的量化配置，未能考虑到量化大型神经网络模型时各层之间不同的困难程度。本文通过利用层敏感特征（如激活敏感性和权重分布峰度）识别难以准确量化的层，并分配额外的内存预算来应对这一问题。所提出的SensiBoost和KurtBoost方法分别在量化精度上取得了显著改善，与基线相比，在LLama模型上仅增加2%的内存预算即可实现最高9%的困惑度下降。', 'title_zh': '向量化精度更优迈进：一种层敏感方法'}
{'arxiv_id': 'arXiv:2503.06514', 'title': 'GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks', 'authors': 'Haoqiang Kang, Enna Sachdeva, Piyush Gupta, Sangjae Bae, Kwonjoon Lee', 'link': 'https://arxiv.org/abs/2503.06514', 'abstract': 'Vision-Language Models (VLMs) have recently shown promising advancements in sequential decision-making tasks through task-specific fine-tuning. However, common fine-tuning methods, such as Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) techniques like Proximal Policy Optimization (PPO), present notable limitations: SFT assumes Independent and Identically Distributed (IID) data, while PPO focuses on maximizing cumulative rewards. These limitations often restrict solution diversity and hinder generalization in multi-step reasoning tasks. To address these challenges, we introduce a novel framework, GFlowVLM, a framework that fine-tune VLMs using Generative Flow Networks (GFlowNets) to promote generation of diverse solutions for complex reasoning tasks. GFlowVLM models the environment as a non-Markovian decision process, allowing it to capture long-term dependencies essential for real-world applications. It takes observations and task descriptions as inputs to prompt chain-of-thought (CoT) reasoning which subsequently guides action selection. We use task based rewards to fine-tune VLM with GFlowNets. This approach enables VLMs to outperform prior fine-tuning methods, including SFT and RL. Empirical results demonstrate the effectiveness of GFlowVLM on complex tasks such as card games (NumberLine, BlackJack) and embodied planning tasks (ALFWorld), showing enhanced training efficiency, solution diversity, and stronger generalization capabilities across both in-distribution and out-of-distribution scenarios.', 'abstract_zh': 'Vision-Language模型（VLMs）通过任务特定微调在序列决策任务中展示了有希望的进步。然而，常见的微调方法，如监督微调（SFT）和强化学习技术（如近端策略优化PPO），存在显著限制：SFT假设独立同分布（IID）数据，而PPO专注于最大化累积奖励。这些限制常限制解的多样性，妨碍多步推理任务中的泛化能力。为解决这些挑战，我们提出了一种新的框架，GFlowVLM，该框架利用生成流网络（GFlowNets）微调VLMs，以促进复杂推理任务中多样解方案的生成。GFlowVLM将环境建模为非马尔可夫决策过程，使其能够捕捉到对现实应用至关重要的长期依赖关系。它通过输入观察和任务描述来提示因果推理（CoT），进而引导动作选择。我们使用基于任务的奖励对VLMs进行GFlowNets微调。该方法使VLMs能够超越先前的微调方法，包括SFT和RL。实证结果表明，GFlowVLM在复杂任务（如卡片游戏（NumberLine、BlackJack）和身体计划任务（ALFWorld））中表现出有效的训练效率、解方案多样性以及更强的泛化能力，无论是在分布内还是分布外场景中。', 'title_zh': 'GFlowVLM: 生成流网络增强视觉-语言模型的多步推理'}
{'arxiv_id': 'arXiv:2503.06511', 'title': 'HFedCKD: Toward Robust Heterogeneous Federated Learning via Data-free Knowledge Distillation and Two-way Contrast', 'authors': 'Yiting Zheng, Bohan Lin, Jinqian Chen, Jihua Zhu', 'link': 'https://arxiv.org/abs/2503.06511', 'abstract': 'Most current federated learning frameworks are modeled as static processes, ignoring the dynamic characteristics of the learning system. Under the limited communication budget of the central server, the flexible model architecture of a large number of clients participating in knowledge transfer requires a lower participation rate, active clients have uneven contributions, and the client scale seriously hinders the performance of FL. We consider a more general and practical federation scenario and propose a system heterogeneous federation method based on data-free knowledge distillation and two-way contrast (HFedCKD). We apply the Inverse Probability Weighted Distillation (IPWD) strategy to the data-free knowledge transfer framework. The generator completes the data features of the nonparticipating clients. IPWD implements a dynamic evaluation of the prediction contribution of each client under different data distributions. Based on the antibiased weighting of its prediction loss, the weight distribution of each client is effectively adjusted to fairly integrate the knowledge of participating clients. At the same time, the local model is split into a feature extractor and a classifier. Through differential contrast learning, the feature extractor is aligned with the global model in the feature space, while the classifier maintains personalized decision-making capabilities. HFedCKD effectively alleviates the knowledge offset caused by a low participation rate under data-free knowledge distillation and improves the performance and stability of the model. We conduct extensive experiments on image and IoT datasets to comprehensively evaluate and verify the generalization and robustness of the proposed HFedCKD framework.', 'abstract_zh': '基于数据免费知识蒸馏和双向对比的系统异构联邦学习方法（HFedCKD）', 'title_zh': 'HFedCKD: 基于数据无关知识蒸馏和双向对比的鲁棒异构联邦学习'}
{'arxiv_id': 'arXiv:2503.06508', 'title': 'A Light and Tuning-free Method for Simulating Camera Motion in Video Generation', 'authors': 'Quanjian Song, Zhihang Lin, Zhanpeng Zeng, Ziyue Zhang, Liujuan Cao, Rongrong Ji', 'link': 'https://arxiv.org/abs/2503.06508', 'abstract': 'Existing camera motion-controlled video generation methods face computational bottlenecks in fine-tuning and inference. This paper proposes LightMotion, a light and tuning-free method for simulating camera motion in video generation. Operating in the latent space, it eliminates additional fine-tuning, inpainting, and depth estimation, making it more streamlined than existing methods. The endeavors of this paper comprise: (i) The latent space permutation operation effectively simulates various camera motions like panning, zooming, and rotation. (ii) The latent space resampling strategy combines background-aware sampling and cross-frame alignment to accurately fill new perspectives while maintaining coherence across frames. (iii) Our in-depth analysis shows that the permutation and resampling cause an SNR shift in latent space, leading to poor-quality generation. To address this, we propose latent space correction, which reintroduces noise during denoising to mitigate SNR shift and enhance video generation quality. Exhaustive experiments show that our LightMotion outperforms existing methods, both quantitatively and qualitatively.', 'abstract_zh': '现有相机运动控制的视频生成方法在精细调优和推理过程中面临计算瓶颈。本文提出LightMotion，这是一种无需调优且轻量的视频生成中模拟相机运动的方法。通过潜空间操作，它消除了额外的调优、补间和深度估计，比现有方法更为简洁。本文的研究内容包括：(i) 潜空间置换操作有效地模拟了如平移、缩放和旋转等各种相机运动。(ii) 潜空间采样策略结合背景感知采样和跨帧对齐，准确填补新的视角并保持帧间连贯性。(iii) 我们深入分析表明，置换和采样导致潜空间SNR偏移，产生低质量的生成结果。为此，我们提出了潜空间校正方法，在去噪过程中重新引入噪声以减轻SNR偏移并提高视频生成质量。详尽的实验结果显示，我们的LightMotion在定性和定量上均优于现有方法。', 'title_zh': '一种无需调参的轻量级相机运动模拟方法在视频生成中的应用'}
{'arxiv_id': 'arXiv:2503.06505', 'title': 'DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability', 'authors': 'Xirui Hu, Jiahao Wang, Hao Chen, Weizhan Zhang, Benqi Wang, Yikun Li, Haishun Nan', 'link': 'https://arxiv.org/abs/2503.06505', 'abstract': 'Recent advancements in text-to-image generation have spurred interest in personalized human image generation, which aims to create novel images featuring specific human identities as reference images indicate. Although existing methods achieve high-fidelity identity preservation, they often struggle with limited multi-ID usability and inadequate facial editability. We present DynamicID, a tuning-free framework supported by a dual-stage training paradigm that inherently facilitates both single-ID and multi-ID personalized generation with high fidelity and flexible facial editability. Our key innovations include: 1) Semantic-Activated Attention (SAA), which employs query-level activation gating to minimize disruption to the original model when injecting ID features and achieve multi-ID personalization without requiring multi-ID samples during training. 2) Identity-Motion Reconfigurator (IMR), which leverages contrastive learning to effectively disentangle and re-entangle facial motion and identity features, thereby enabling flexible facial editing. Additionally, we have developed a curated VariFace-10k facial dataset, comprising 10k unique individuals, each represented by 35 distinct facial images. Experimental results demonstrate that DynamicID outperforms state-of-the-art methods in identity fidelity, facial editability, and multi-ID personalization capability.', 'abstract_zh': 'Recent advancements in text-to-image generation have spurred interest in personalized human image generation, which aims to create novel images featuring specific human identities as reference images indicate.', 'title_zh': '动态ID：灵活面部编辑的零样本多身份图像个性化'}
{'arxiv_id': 'arXiv:2503.06499', 'title': 'ExGes: Expressive Human Motion Retrieval and Modulation for Audio-Driven Gesture Synthesis', 'authors': 'Xukun Zhou, Fengxin Li, Ming Chen, Yan Zhou, Pengfei Wan, Di Zhang, Hongyan Liu, Jun He, Zhaoxin Fan', 'link': 'https://arxiv.org/abs/2503.06499', 'abstract': 'Audio-driven human gesture synthesis is a crucial task with broad applications in virtual avatars, human-computer interaction, and creative content generation. Despite notable progress, existing methods often produce gestures that are coarse, lack expressiveness, and fail to fully align with audio semantics. To address these challenges, we propose ExGes, a novel retrieval-enhanced diffusion framework with three key designs: (1) a Motion Base Construction, which builds a gesture library using training dataset; (2) a Motion Retrieval Module, employing constrative learning and momentum distillation for fine-grained reference poses retreiving; and (3) a Precision Control Module, integrating partial masking and stochastic masking to enable flexible and fine-grained control. Experimental evaluations on BEAT2 demonstrate that ExGes reduces Fréchet Gesture Distance by 6.2\\% and improves motion diversity by 5.3\\% over EMAGE, with user studies revealing a 71.3\\% preference for its naturalness and semantic relevance. Code will be released upon acceptance.', 'abstract_zh': '基于音频的人体手势合成是虚拟化身、人机交互和创意内容生成等领域的重要任务。尽管取得了显著进展，现有方法往往生成粗糙、缺乏表现力的手势，并且无法完全与音频语义对齐。为了解决这些挑战，我们提出了ExGes，一种带有三种关键设计的检索增强扩散框架：（1）运动基础构建，使用训练数据集构建手势库；（2）运动检索模块，采用对比学习和动量蒸馏进行精细参考姿态检索；（3）精度控制模块，结合部分掩码和随机掩码以实现灵活和精细的控制。实验结果表明，ExGes 在 BEAT2 上将弗雷谢手势距离降低了 6.2%，提高了运动多样性 5.3%，用户研究显示其自然性和语义相关性获得了 71.3% 的偏好。接受后将发布代码。', 'title_zh': 'ExGes: 表达力人体动作检索与调节用于音控手势合成'}
{'arxiv_id': 'arXiv:2503.06497', 'title': 'Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving', 'authors': 'Enming Zhang, Peizhe Gong, Xingyuan Dai, Yisheng Lv, Qinghai Miao', 'link': 'https://arxiv.org/abs/2503.06497', 'abstract': 'Assessing the safety of vision-language models (VLMs) in autonomous driving is particularly important; however, existing work mainly focuses on traditional benchmark evaluations. As interactive components within autonomous driving systems, VLMs must maintain strong safety cognition during interactions. From this perspective, we propose a novel evaluation method: Safety Cognitive Driving Benchmark (SCD-Bench) . To address the large-scale annotation challenge for SCD-Bench, we develop the Autonomous Driving Image-Text Annotation System (ADA) . Additionally, to ensure data quality in SCD-Bench, our dataset undergoes manual refinement by experts with professional knowledge in autonomous driving. We further develop an automated evaluation method based on large language models (LLMs). To verify its effectiveness, we compare its evaluation results with those of expert human evaluations, achieving a consistency rate of 99.74%. Preliminary experimental results indicate that existing open-source models still lack sufficient safety cognition, showing a significant gap compared to GPT-4o. Notably, lightweight models (1B-4B) demonstrate minimal safety cognition. However, since lightweight models are crucial for autonomous driving systems, this presents a significant challenge for integrating VLMs into the field.', 'abstract_zh': '评估自动驾驶中视觉语言模型的安全性尤其重要；然而，现有工作主要集中在传统基准评估上。从这一视角出发，我们提出了一种新型评估方法：安全认知驾驶基准（SCD-Bench）。为应对SCD-Bench的大规模标注挑战，我们开发了自动驾驶图像-文本标注系统（ADA）。此外，为确保SCD-Bench的数据质量，我们的数据集经过了专业自动驾驶知识专家的手动 refinement。我们进一步基于大规模语言模型（LLMs）开发了一种自动评估方法。通过与专家人工评估的结果进行比较，其一致性率达到99.74%，证明了其有效性。初步实验结果表明，现有开源模型在安全性认知方面仍然不足，与GPT-4o相比存在显著差距。值得注意的是，轻量级模型（1B-4B）在安全性认知方面表现极弱。然而，由于轻量级模型对自动驾驶系统至关重要，这为将视觉语言模型集成到该领域带来了重大挑战。', 'title_zh': '自动驾驶场景下视觉语言模型的安全认知能力评估'}
{'arxiv_id': 'arXiv:2503.06486', 'title': 'PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training', 'authors': 'Cong Chen, Mingyu Liu, Chenchen Jing, Yizhou Zhou, Fengyun Rao, Hao Chen, Bo Zhang, Chunhua Shen', 'link': 'https://arxiv.org/abs/2503.06486', 'abstract': "This paper aims to address the challenge of hallucinations in Multimodal Large Language Models (MLLMs) particularly for dense image captioning tasks. To tackle the challenge, we identify the current lack of a metric that finely measures the caption quality in concept level. We hereby introduce HalFscore, a novel metric built upon the language graph and is designed to evaluate both the accuracy and completeness of dense captions at a granular level. Additionally, we identify the root cause of hallucination as the model's over-reliance on its language prior. To address this, we propose PerturboLLaVA, which reduces the model's reliance on the language prior by incorporating adversarially perturbed text during training. This method enhances the model's focus on visual inputs, effectively reducing hallucinations and producing accurate, image-grounded descriptions without incurring additional computational overhead. PerturboLLaVA significantly improves the fidelity of generated captions, outperforming existing approaches in handling multimodal hallucinations and achieving improved performance across general multimodal benchmarks.", 'abstract_zh': '本文旨在解决多模态大语言模型（MLLMs）在密集图像描述任务中幻觉挑战。为此，我们识别出当前缺乏一种细粒度衡量描述质量的指标，特别是在概念层级。我们引入了HalFscore，这是一种基于语言图的新颖度量标准，旨在从细粒度层面评估密集描述的准确性和完整性。此外，我们确定幻觉的根本原因是模型过度依赖于语言先验。为解决这一问题，我们提出了PerturboLLaVA，通过在训练过程中引入对抗性扰动文本，降低模型对语言先验的依赖，从而增强模型对视觉输入的关注，有效减少幻觉并生成准确、图像相关的描述，而无需增加额外的计算开销。PerturboLLaVA显着提高了生成描述的忠实度，在处理多模态幻觉和跨通用多模态基准上优于现有方法。', 'title_zh': 'PerturboLLaVA: 通过对视觉进行扰动性训练减少多模态幻觉'}
{'arxiv_id': 'arXiv:2503.06484', 'title': 'Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms', 'authors': 'Xiao Wang, Yuehang Li, Fuling Wang, Bo Jiang, Yaowei Wang, Yonghong Tian, Jin Tang, Bin Luo', 'link': 'https://arxiv.org/abs/2503.06484', 'abstract': 'Accurate sign language understanding serves as a crucial communication channel for individuals with disabilities. Current sign language translation algorithms predominantly rely on RGB frames, which may be limited by fixed frame rates, variable lighting conditions, and motion blur caused by rapid hand movements. Inspired by the recent successful application of event cameras in other fields, we propose to leverage event streams to assist RGB cameras in capturing gesture data, addressing the various challenges mentioned above. Specifically, we first collect a large-scale RGB-Event sign language translation dataset using the DVS346 camera, termed VECSL, which contains 15,676 RGB-Event samples, 15,191 glosses, and covers 2,568 Chinese characters. These samples were gathered across a diverse range of indoor and outdoor environments, capturing multiple viewing angles, varying light intensities, and different camera motions. Due to the absence of benchmark algorithms for comparison in this new task, we retrained and evaluated multiple state-of-the-art SLT algorithms, and believe that this benchmark can effectively support subsequent related research. Additionally, we propose a novel RGB-Event sign language translation framework (i.e., M$^2$-SLT) that incorporates fine-grained micro-sign and coarse-grained macro-sign retrieval, achieving state-of-the-art results on the proposed dataset. Both the source code and dataset will be released on this https URL.', 'abstract_zh': '准确的手语理解是残疾人之间 crucial 通信通道。当前的手语翻译算法主要依赖于 RGB 帧，但可能受到固定帧率、变化的光照条件和由于快速手部运动引起的动作模糊的限制。受事件相机在其他领域成功应用的启发，我们提出利用事件流辅助 RGB 相机捕捉手势数据，以解决上述各种挑战。具体地，我们首先使用 DVS346 相机收集了一个大规模的 RGB-Event 手语翻译数据集，称为 VECSL，包含 15,676 个 RGB-Event 样本、15,191 个手语词和 2,568 个汉字样本。这些样本来自多种室内外环境，涵盖了不同的视角、光照强度和相机运动。由于这是新任务中缺乏基准算法进行比较，我们重新训练和评估了多个最新的手语翻译算法，相信该基准能够有效地支持后续相关研究。此外，我们提出了一种新型的 RGB-Event 手语翻译框架（即 M$^2$-SLT），结合了精细的手语微动作检索和粗略的手语宏观动作检索，在所提数据集上取得了最先进的结果。源代码和数据集将发布在该网址。', 'title_zh': '基于帧和事件流的手语翻译：基准数据集与算法'}
{'arxiv_id': 'arXiv:2503.06477', 'title': 'PDB: Not All Drivers Are the Same -- A Personalized Dataset for Understanding Driving Behavior', 'authors': 'Chuheng Wei, Ziye Qin, Siyan Li, Ziyan Zhang, Xuanpeng Zhao, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, Matthew J. Barth, Guoyuan Wu', 'link': 'https://arxiv.org/abs/2503.06477', 'abstract': "Driving behavior is inherently personal, influenced by individual habits, decision-making styles, and physiological states. However, most existing datasets treat all drivers as homogeneous, overlooking driver-specific variability. To address this gap, we introduce the Personalized Driving Behavior (PDB) dataset, a multi-modal dataset designed to capture personalization in driving behavior under naturalistic driving conditions. Unlike conventional datasets, PDB minimizes external influences by maintaining consistent routes, vehicles, and lighting conditions across sessions. It includes sources from 128-line LiDAR, front-facing camera video, GNSS, 9-axis IMU, CAN bus data (throttle, brake, steering angle), and driver-specific signals such as facial video and heart rate. The dataset features 12 participants, approximately 270,000 LiDAR frames, 1.6 million images, and 6.6 TB of raw sensor data. The processed trajectory dataset consists of 1,669 segments, each spanning 10 seconds with a 0.2-second interval. By explicitly capturing drivers' behavior, PDB serves as a unique resource for human factor analysis, driver identification, and personalized mobility applications, contributing to the development of human-centric intelligent transportation systems.", 'abstract_zh': '个性化驾驶行为（PDB）数据集', 'title_zh': 'PDB: 并非所有驾驶员都相同——一个理解驾驶行为的个性化数据集'}
{'arxiv_id': 'arXiv:2503.06474', 'title': 'HuixiangDou2: A Robustly Optimized GraphRAG Approach', 'authors': 'Huanjun Kong, Zhefan Wang, Chenyang Wang, Zhe Ma, Nanqing Dong', 'link': 'https://arxiv.org/abs/2503.06474', 'abstract': 'Large Language Models (LLMs) perform well on familiar queries but struggle with specialized or emerging topics. Graph-based Retrieval-Augmented Generation (GraphRAG) addresses this by structuring domain knowledge as a graph for dynamic retrieval. However, existing pipelines involve complex engineering workflows, making it difficult to isolate the impact of individual components. Evaluating retrieval effectiveness is also challenging due to dataset overlap with LLM pretraining data. In this work, we introduce HuixiangDou2, a robustly optimized GraphRAG framework. Specifically, we leverage the effectiveness of dual-level retrieval and optimize its performance in a 32k context for maximum precision, and compare logic-based retrieval and dual-level retrieval to enhance overall functionality. Our implementation includes comparative experiments on a test set, where Qwen2.5-7B-Instruct initially underperformed. With our approach, the score improved significantly from 60 to 74.5, as illustrated in the Figure. Experiments on domain-specific datasets reveal that dual-level retrieval enhances fuzzy matching, while logic-form retrieval improves structured reasoning. Furthermore, we propose a multi-stage verification mechanism to improve retrieval robustness without increasing computational cost. Empirical results show significant accuracy gains over baselines, highlighting the importance of adaptive retrieval. To support research and adoption, we release HuixiangDou2 as an open-source resource this https URL.', 'abstract_zh': '大规模语言模型（LLMs）在熟悉查询上表现良好，但在处理专门化或新兴主题时存在困难。基于图的检索增强生成（GraphRAG）通过将领域知识构建成图来进行动态检索，以解决这一问题。然而，现有流水线涉及复杂的工程工作流，使得难以隔离各个组件的影响。由于数据集与LLM预训练数据存在重叠，检索效果的评估也颇具挑战性。在本文中，我们介绍了经过 robust 优化的 GraphRAG 框架 HuixiangDou2。具体而言，我们利用双级检索的有效性，在32k上下文长度下优化其性能以实现最高精密度，并对比基于逻辑的检索和双级检索以增强整体功能。我们的实现包括对测试集的对比实验，其中 Qwen2.5-7B-Instruct 初始表现不佳。通过我们的方法，分数显著提升，从60分提高到74.5分，如图所示。针对特定领域的数据集的实验表明，双级检索增强了模糊匹配，而逻辑表达式检索改善了结构化推理。此外，我们提出了一种多阶段验证机制，以在不增加计算成本的情况下提高检索的鲁棒性。实验结果表明，在基线之上取得了显着的准确率提升，突显了适应性检索的重要性。为了支持研究和应用，我们开源了 HuixiangDou2，详情请参见：this https URL。', 'title_zh': 'HuixiangDou2：一个鲁棒优化的GraphRAG方法'}
{'arxiv_id': 'arXiv:2503.06473', 'title': 'Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals', 'authors': 'Hanze Li, Xiande Huang', 'link': 'https://arxiv.org/abs/2503.06473', 'abstract': "Growing evidence suggests that layer attention mechanisms, which enhance interaction among layers in deep neural networks, have significantly advanced network architectures. However, existing layer attention methods suffer from redundancy, as attention weights learned by adjacent layers often become highly similar. This redundancy causes multiple layers to extract nearly identical features, reducing the model's representational capacity and increasing training time. To address this issue, we propose a novel approach to quantify redundancy by leveraging the Kullback-Leibler (KL) divergence between adjacent layers. Additionally, we introduce an Enhanced Beta Quantile Mapping (EBQM) method that accurately identifies and skips redundant layers, thereby maintaining model stability. Our proposed Efficient Layer Attention (ELA) architecture, improves both training efficiency and overall performance, achieving a 30\\% reduction in training time while enhancing performance in tasks such as image classification and object detection.", 'abstract_zh': '逐层注意力机制通过增强深神经网络中各层之间的交互，显著推进了网络架构的发展。然而，现有的层注意力方法存在冗余问题，相邻层学习到的注意力权重通常高度相似，导致多个层提取几乎相同的特征，降低了模型的表示能力并增加了训练时间。为此，我们提出了一种新颖的方法，通过利用相邻层之间的Kullback-Leibler（KL）散度来量化冗余。此外，我们引入了一种增强的贝塔分位映射（EBQM）方法，能够准确识别并跳过冗余层，从而保持模型的稳定性。我们提出的高效层注意力（ELA）架构提高了训练效率和整体性能，在图像分类和物体检测等任务中实现了30%的训练时间减少。', 'title_zh': '通过修剪冗余检索提升层注意力效率'}
{'arxiv_id': 'arXiv:2503.06462', 'title': 'StructGS: Adaptive Spherical Harmonics and Rendering Enhancements for Superior 3D Gaussian Splatting', 'authors': 'Zexu Huang, Min Xu, Stuart Perry', 'link': 'https://arxiv.org/abs/2503.06462', 'abstract': 'Recent advancements in 3D reconstruction coupled with neural rendering techniques have greatly improved the creation of photo-realistic 3D scenes, influencing both academic research and industry applications. The technique of 3D Gaussian Splatting and its variants incorporate the strengths of both primitive-based and volumetric representations, achieving superior rendering quality. While 3D Geometric Scattering (3DGS) and its variants have advanced the field of 3D representation, they fall short in capturing the stochastic properties of non-local structural information during the training process. Additionally, the initialisation of spherical functions in 3DGS-based methods often fails to engage higher-order terms in early training rounds, leading to unnecessary computational overhead as training progresses. Furthermore, current 3DGS-based approaches require training on higher resolution images to render higher resolution outputs, significantly increasing memory demands and prolonging training durations. We introduce StructGS, a framework that enhances 3D Gaussian Splatting (3DGS) for improved novel-view synthesis in 3D reconstruction. StructGS innovatively incorporates a patch-based SSIM loss, dynamic spherical harmonics initialisation and a Multi-scale Residual Network (MSRN) to address the above-mentioned limitations, respectively. Our framework significantly reduces computational redundancy, enhances detail capture and supports high-resolution rendering from low-resolution inputs. Experimentally, StructGS demonstrates superior performance over state-of-the-art (SOTA) models, achieving higher quality and more detailed renderings with fewer artifacts.', 'abstract_zh': 'Recent advancements in 3D重建结合神经渲染技术极大地提高了照片级真实感3D场景的生成，影响了学术研究和工业应用。3D高斯散点图及其变体集成了基于原素和体素表示的优点，实现了卓越的渲染质量。虽然3D几何散射（3DGS）及其变体推进了3D表示领域的发展，但在训练过程中未能有效捕捉非局部结构信息的随机特性。此外，基于3DGS的方法在早期训练阶段常无法有效初始化球函数，导致更高的计算冗余。同时，基于3DGS的方法需要在更高分辨率的图像上进行训练以生成更高分辨率的输出，这大幅增加了内存需求并延长了训练时间。我们提出StructGS框架，旨在改进3D高斯散点图（3DGS）以提高3D重建中的新颖视角合成。StructGS创新性地引入基于块的SSIM损失、动态球谐函数初始化和多尺度残差网络（MSRN），以分别解决上述问题。我们的框架显著减少了计算冗余，提升了细节捕捉能力，并支持从低分辨率输入生成高分辨率渲染。实验表明，StructGS在与当前最先进的（SOTA）模型对比中表现出更优性能，实现了更高质量和更详细的渲染，且减少了许多伪影。', 'title_zh': 'StructGS: 自适应球谐变换与渲染增强以实现卓越的3D高斯点云渲染'}
{'arxiv_id': 'arXiv:2503.06457', 'title': 'Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning', 'authors': 'Yanbiao Ma, Wei Dai, Wenke Huang, Jiayi Chen', 'link': 'https://arxiv.org/abs/2503.06457', 'abstract': 'Data heterogeneity in federated learning, characterized by a significant misalignment between local and global distributions, leads to divergent local optimization directions and hinders global model training. Existing studies mainly focus on optimizing local updates or global aggregation, but these indirect approaches demonstrate instability when handling highly heterogeneous data distributions, especially in scenarios where label skew and domain skew coexist. To address this, we propose a geometry-guided data generation method that centers on simulating the global embedding distribution locally. We first introduce the concept of the geometric shape of an embedding distribution and then address the challenge of obtaining global geometric shapes under privacy constraints. Subsequently, we propose GGEUR, which leverages global geometric shapes to guide the generation of new samples, enabling a closer approximation to the ideal global distribution. In single-domain scenarios, we augment samples based on global geometric shapes to enhance model generalization; in multi-domain scenarios, we further employ class prototypes to simulate the global distribution across domains. Extensive experimental results demonstrate that our method significantly enhances the performance of existing approaches in handling highly heterogeneous data, including scenarios with label skew, domain skew, and their coexistence. Code published at: this https URL', 'abstract_zh': '联邦学习中由局部和全局分布显著不匹配引起的数据异质性导致了局部优化方向的发散并阻碍了全局模型训练。现有研究主要集中在优化局部更新或全局聚合，但这些间接方法在处理高度异质性数据分布时表现不稳定，尤其是在标签偏斜和领域偏斜共存的情况下。为解决这一问题，我们提出了一种几何引导的数据生成方法，重点在于局部模拟全局嵌入分布的几何形状。我们首先引入嵌入分布几何形状的概念，然后在隐私约束下解决了获取全局几何形状的挑战。随后，我们提出了GGEUR方法，利用全局几何形状来指导新样本的生成，以更接近理想全局分布。在单领域场景下，我们基于全局几何形状增强样本以提高模型泛化能力；在多领域场景下，我们进一步使用类原型来模拟跨领域的全局分布。大量实验结果表明，我们的方法显著提升了现有方法在处理高度异质性数据，包括标签偏斜、领域偏斜及其共存情况下的性能。代码发布于：this https URL', 'title_zh': '几何知识引导的局部全局分布对齐的联邦学习'}
{'arxiv_id': 'arXiv:2503.06444', 'title': 'CtrTab: Tabular Data Synthesis with High-Dimensional and Limited Data', 'authors': 'Zuqing Li, Jianzhong Qi, Junhao Gan', 'link': 'https://arxiv.org/abs/2503.06444', 'abstract': 'Diffusion-based tabular data synthesis models have yielded promising results. However, we observe that when the data dimensionality increases, existing models tend to degenerate and may perform even worse than simpler, non-diffusion-based models. This is because limited training samples in high-dimensional space often hinder generative models from capturing the distribution accurately. To address this issue, we propose CtrTab-a condition controlled diffusion model for tabular data synthesis-to improve the performance of diffusion-based generative models in high-dimensional, low-data scenarios. Through CtrTab, we inject samples with added Laplace noise as control signals to improve data diversity and show its resemblance to L2 regularization, which enhances model robustness. Experimental results across multiple datasets show that CtrTab outperforms state-of-the-art models, with performance gap in accuracy over 80% on average. Our source code will be released upon paper publication.', 'abstract_zh': '基于扩散的表格数据合成模型已经取得了令人鼓舞的结果。然而，我们观察到，在数据维度增加时，现有模型往往会出现退化现象，甚至可能比简单的非扩散基于模型表现更差。这是因为高维度空间中有限的训练样本常常会阻碍生成模型准确捕捉数据分布。为解决这一问题，我们提出了CtrTab——一种条件控制的扩散模型，以提高高维度、低数据场景下扩散生成模型的性能。通过CtrTab，我们注入带有拉普lace噪声的样本作为控制信号，以提高数据多样性，并将其与L2正则化做类比，以增强模型的稳健性。来自多个数据集的实验结果显示，CtrTab在准确率方面平均超过现有最先进的模型80%以上。我们的源代码将在论文发表后公开。', 'title_zh': 'CtrTab: 高维度小样本量表格数据合成'}
{'arxiv_id': 'arXiv:2503.06436', 'title': 'Physics-Informed Residual Neural Ordinary Differential Equations for Enhanced Tropical Cyclone Intensity Forecasting', 'authors': 'Fan Meng', 'link': 'https://arxiv.org/abs/2503.06436', 'abstract': 'Accurate tropical cyclone (TC) intensity prediction is crucial for mitigating storm hazards, yet its complex dynamics pose challenges to traditional methods. Here, we introduce a Physics-Informed Residual Neural Ordinary Differential Equation (PIR-NODE) model to precisely forecast TC intensity evolution. This model leverages the powerful non-linear fitting capabilities of deep learning, integrates residual connections to enhance model depth and training stability, and explicitly models the continuous temporal evolution of TC intensity using Neural ODEs. Experimental results in the SHIPS dataset demonstrate that the PIR-NODE model achieves a significant improvement in 24-hour intensity prediction accuracy compared to traditional statistical models and benchmark deep learning methods, with a 25. 2\\% reduction in the root mean square error (RMSE) and a 19.5\\% increase in R-square (R2) relative to a baseline of neural network. Crucially, the residual structure effectively preserves initial state information, and the model exhibits robust generalization capabilities. This study details the PIR-NODE model architecture, physics-informed integration strategies, and comprehensive experimental validation, revealing the substantial potential of deep learning techniques in predicting complex geophysical systems and laying the foundation for future refined TC forecasting research.', 'abstract_zh': '准确的热带气旋（TC）强度预测对于减缓风暴灾害至关重要，但其复杂的动力学特性对传统方法构成了挑战。本文介绍了一种物理信息残差神经常微分方程（PIR-NODE）模型，以精确预报TC强度演变。该模型利用深度学习强大的非线性拟合能力，通过残差连接增强模型深度和训练稳定性，并使用神经常微分方程显式建模TC强度的连续时间演化。在SHIPS数据集的实验结果表明，PIR-NODE模型在24小时强度预测精度上显著优于传统统计模型和基准深度学习方法，与基线神经网络相比，均方根误差（RMSE）降低了25.2%，R平方（R2）提高了19.5%。重要的是，残差结构有效保留了初始状态信息，并且该模型表现出 robust 通用化能力。本文详细介绍了PIR-NODE模型架构、物理信息集成策略以及全面的实验验证，揭示了深度学习技术在预测复杂地球物理系统方面的巨大潜力，并为未来的精细化TC预报研究奠定了基础。', 'title_zh': '基于物理约束的残差神经常微分方程在热带气旋强度预报中的应用'}
{'arxiv_id': 'arXiv:2503.06433', 'title': 'Seesaw: High-throughput LLM Inference via Model Re-sharding', 'authors': 'Qidong Su, Wei Zhao, Xin Li, Muralidhar Andoorveedu, Chenhao Jiang, Zhanda Zhu, Kevin Song, Christina Giannoula, Gennady Pekhimenko', 'link': 'https://arxiv.org/abs/2503.06433', 'abstract': 'To improve the efficiency of distributed large language model (LLM) inference, various parallelization strategies, such as tensor and pipeline parallelism, have been proposed. However, the distinct computational characteristics inherent in the two stages of LLM inference-prefilling and decoding-render a single static parallelization strategy insufficient for the effective optimization of both stages. In this work, we present Seesaw, an LLM inference engine optimized for throughput-oriented tasks. The key idea behind Seesaw is dynamic model re-sharding, a technique that facilitates the dynamic reconfiguration of parallelization strategies across stages, thereby maximizing throughput at both phases. To mitigate re-sharding overhead and optimize computational efficiency, we employ tiered KV cache buffering and transition-minimizing scheduling. These approaches work synergistically to reduce the overhead caused by frequent stage transitions while ensuring maximum batching efficiency. Our evaluation demonstrates that Seesaw achieves a throughput increase of up to 1.78x (1.36x on average) compared to vLLM, the most widely used state-of-the-art LLM inference engine.', 'abstract_zh': '为了提高分布式大型语言模型（LLM）推理的效率，提出了诸如张量并行和管道并行等各种并行化策略。然而，LLM推理的两个阶段——预填充和解码——固有的不同计算特性使得单一静态并行化策略无法有效优化这两个阶段。本文提出Seesaw，一种针对吞吐量优化的LLM推理引擎。Seesaw的核心思想是动态模型重分片，该技术使并行化策略在各阶段之间的动态重新配置成为可能，从而在两个阶段中最大化吞吐量。为减轻重分片开销并优化计算效率，我们采用了分层KV缓存缓冲和最小转换调度。这些方法协同工作，减少了频繁阶段转换带来的开销，同时确保了最大的批处理效率。我们的评估表明，Seesaw相比最广泛使用的最先进的LLM推理引擎vLLM，吞吐量提升了1.78倍（平均提升1.36倍）。', 'title_zh': 'Seesaw: 高 throughput LLM 推理通过模型重新分割'}
{'arxiv_id': 'arXiv:2503.06430', 'title': 'Graph Retrieval-Augmented LLM for Conversational Recommendation Systems', 'authors': 'Zhangchi Qiu, Linhao Luo, Zicheng Zhao, Shirui Pan, Alan Wee-Chung Liew', 'link': 'https://arxiv.org/abs/2503.06430', 'abstract': "Conversational Recommender Systems (CRSs) have emerged as a transformative paradigm for offering personalized recommendations through natural language dialogue. However, they face challenges with knowledge sparsity, as users often provide brief, incomplete preference statements. While recent methods have integrated external knowledge sources to mitigate this, they still struggle with semantic understanding and complex preference reasoning. Recent Large Language Models (LLMs) demonstrate promising capabilities in natural language understanding and reasoning, showing significant potential for CRSs. Nevertheless, due to the lack of domain knowledge, existing LLM-based CRSs either produce hallucinated recommendations or demand expensive domain-specific training, which largely limits their applicability. In this work, we present G-CRS (Graph Retrieval-Augmented Large Language Model for Conversational Recommender Systems), a novel training-free framework that combines graph retrieval-augmented generation and in-context learning to enhance LLMs' recommendation capabilities. Specifically, G-CRS employs a two-stage retrieve-and-recommend architecture, where a GNN-based graph reasoner first identifies candidate items, followed by Personalized PageRank exploration to jointly discover potential items and similar user interactions. These retrieved contexts are then transformed into structured prompts for LLM reasoning, enabling contextually grounded recommendations without task-specific training. Extensive experiments on two public datasets show that G-CRS achieves superior recommendation performance compared to existing methods without requiring task-specific training.", 'abstract_zh': '基于图检索增强的大语言模型的对话推荐系统（G-CRS）', 'title_zh': '基于图检索增强的LLM在对话推荐系统中的应用'}
{'arxiv_id': 'arXiv:2503.06427', 'title': 'Pre-Training Meta-Rule Selection Policy for Visual Generative Abductive Learning', 'authors': 'Yu Jin, Jingming Liu, Zhexu Luo, Yifei Peng, Ziang Qin, Wang-Zhou Dai, Yao-Xiang Ding, Kun Zhou', 'link': 'https://arxiv.org/abs/2503.06427', 'abstract': 'Visual generative abductive learning studies jointly training symbol-grounded neural visual generator and inducing logic rules from data, such that after learning, the visual generation process is guided by the induced logic rules. A major challenge for this task is to reduce the time cost of logic abduction during learning, an essential step when the logic symbol set is large and the logic rule to induce is complicated. To address this challenge, we propose a pre-training method for obtaining meta-rule selection policy for the recently proposed visual generative learning approach AbdGen [Peng et al., 2023], aiming at significantly reducing the candidate meta-rule set and pruning the search space. The selection model is built based on the embedding representation of both symbol grounding of cases and meta-rules, which can be effectively integrated with both neural model and logic reasoning system. The pre-training process is done on pure symbol data, not involving symbol grounding learning of raw visual inputs, making the entire learning process low-cost. An additional interesting observation is that the selection policy can rectify symbol grounding errors unseen during pre-training, which is resulted from the memorization ability of attention mechanism and the relative stability of symbolic patterns. Experimental results show that our method is able to effectively address the meta-rule selection problem for visual abduction, boosting the efficiency of visual generative abductive learning. Code is available at this https URL.', 'abstract_zh': '视觉生成演绎学习研究：通过预训练方法获取元规则选择策略，以降低演绎学习过程中的时间成本', 'title_zh': '预训练元规则选择策略以进行视觉生成 abduction 学习'}
{'arxiv_id': 'arXiv:2503.06422', 'title': 'GenAI for Simulation Model in Model-Based Systems Engineering', 'authors': 'Lin Zhang, Yuteng Zhang, Dusit Niyato, Lei Ren, Pengfei Gu, Zhen Chen, Yuanjun Laili, Wentong Cai, Agostino Bruzzone', 'link': 'https://arxiv.org/abs/2503.06422', 'abstract': 'Generative AI (GenAI) has demonstrated remarkable capabilities in code generation, and its integration into complex product modeling and simulation code generation can significantly enhance the efficiency of the system design phase in Model-Based Systems Engineering (MBSE). In this study, we introduce a generative system design methodology framework for MBSE, offering a practical approach for the intelligent generation of simulation models for system physical properties. First, we employ inference techniques, generative models, and integrated modeling and simulation languages to construct simulation models for system physical properties based on product design documents. Subsequently, we fine-tune the language model used for simulation model generation on an existing library of simulation models and additional datasets generated through generative modeling. Finally, we introduce evaluation metrics for the generated simulation models for system physical properties. Our proposed approach to simulation model generation presents the innovative concept of scalable templates for simulation models. Using these templates, GenAI generates simulation models for system physical properties through code completion. The experimental results demonstrate that, for mainstream open-source Transformer-based models, the quality of the simulation model is significantly improved using the simulation model generation method proposed in this paper.', 'abstract_zh': '基于生成式AI的Model-Based Systems Engineering中仿真模型智能化生成方法论框架', 'title_zh': '基于模型系统工程中的GenAI仿真模型'}
{'arxiv_id': 'arXiv:2503.06413', 'title': 'Swift Hydra: Self-Reinforcing Generative Framework for Anomaly Detection with Multiple Mamba Models', 'authors': 'Nguyen Do, Truc Nguyen, Malik Hassanaly, Raed Alharbi, Jung Taek Seo, My T. Thai', 'link': 'https://arxiv.org/abs/2503.06413', 'abstract': "Despite a plethora of anomaly detection models developed over the years, their ability to generalize to unseen anomalies remains an issue, particularly in critical systems. This paper aims to address this challenge by introducing Swift Hydra, a new framework for training an anomaly detection method based on generative AI and reinforcement learning (RL). Through featuring an RL policy that operates on the latent variables of a generative model, the framework synthesizes novel and diverse anomaly samples that are capable of bypassing a detection model. These generated synthetic samples are, in turn, used to augment the detection model, further improving its ability to handle challenging anomalies. Swift Hydra also incorporates Mamba models structured as a Mixture of Experts (MoE) to enable scalable adaptation of the number of Mamba experts based on data complexity, effectively capturing diverse feature distributions without increasing the model's inference time. Empirical evaluations on ADBench benchmark demonstrate that Swift Hydra outperforms other state-of-the-art anomaly detection models while maintaining a relatively short inference time. From these results, our research highlights a new and auspicious paradigm of integrating RL and generative AI for advancing anomaly detection.", 'abstract_zh': '尽管多年来已经开发出众多异常检测模型，但这些模型在面对未见过的异常时的泛化能力仍存在问题，特别是在关键系统中。本文旨在通过引入基于生成AI和强化学习（RL）的新型异常检测方法训练框架Swift Hydra来应对这一挑战。该框架通过在其生成模型的潜在变量上操作的RL策略，合成了新颖且多样的异常样本，能够绕过检测模型。生成的合成样本随后被用来增强检测模型，进一步提高其处理复杂异常的能力。Swift Hydra还结合了基于Mixture of Experts（MoE）结构的Mamba模型，以根据数据复杂性可扩展地调整Mamba专家的数量，有效地捕捉多样化的特征分布而不增加模型的推理时间。在ADBench基准上的实证评估表明，Swift Hydra在保持相对短的推理时间的同时，优于其他最先进的异常检测模型。我们的研究结果突显了一种新的并充满希望的RL与生成AI结合的方法范式，以推动异常检测的发展。', 'title_zh': 'Swift Hydra：自强化生成框架，基于多个Mamba模型的异常检测'}
{'arxiv_id': 'arXiv:2503.06411', 'title': 'Decoding the Black Box: Integrating Moral Imagination with Technical AI Governance', 'authors': 'Krti Tallam', 'link': 'https://arxiv.org/abs/2503.06411', 'abstract': 'This paper examines the intricate interplay among AI safety, security, and governance by integrating technical systems engineering with principles of moral imagination and ethical philosophy. Drawing on foundational insights from Weapons of Math Destruction and Thinking in Systems alongside contemporary debates in AI ethics, we develop a comprehensive multi-dimensional framework designed to regulate AI technologies deployed in high-stakes domains such as defense, finance, healthcare, and education. Our approach combines rigorous technical analysis, quantitative risk assessment, and normative evaluation to expose systemic vulnerabilities inherent in opaque, black-box models. Detailed case studies, including analyses of Microsoft Tay (2016) and the UK A-Level Grading Algorithm (2020), demonstrate how security lapses, bias amplification, and lack of accountability can precipitate cascading failures that undermine public trust. We conclude by outlining targeted strategies for enhancing AI resilience through adaptive regulatory mechanisms, robust security protocols, and interdisciplinary oversight, thereby advancing the state of the art in ethical and technical AI governance.', 'abstract_zh': '本文通过将技术系统工程与道德想象原则和伦理哲学相结合，探讨了AI安全、安全与治理之间的复杂交互关系，并借鉴《数学破坏武器》和《系统思维》的基础洞见以及当前AI伦理领域的讨论，开发了一个全面的多维框架，旨在监管国防、金融、医疗和教育等高风险领域中的AI技术。本文方法结合了严格的技術分析、定量风险评估和规范评估，以揭示不透明的黑盒模型中固有的系统性漏洞。通过详细的案例研究，包括对微软Tay（2016年）和英国A-Level评分算法（2020年）的分析，展示了安全漏洞、偏见放大及缺乏问责制如何导致级联失败，从而侵蚀公众信任。最后，本文提出了通过适应性监管机制、 robust安全协议和跨学科监督来增强AI韧性的目标策略，从而推动伦理和技术治理领域的创新。', 'title_zh': '解码黑盒：将道德想象与技术AI治理相结合'}
{'arxiv_id': 'arXiv:2503.06405', 'title': 'Heterogeneous bimodal attention fusion for speech emotion recognition', 'authors': 'Jiachen Luo, Huy Phan, Lin Wang, Joshua Reiss', 'link': 'https://arxiv.org/abs/2503.06405', 'abstract': 'Multi-modal emotion recognition in conversations is a challenging problem due to the complex and complementary interactions between different modalities. Audio and textual cues are particularly important for understanding emotions from a human perspective. Most existing studies focus on exploring interactions between audio and text modalities at the same representation level. However, a critical issue is often overlooked: the heterogeneous modality gap between low-level audio representations and high-level text representations. To address this problem, we propose a novel framework called Heterogeneous Bimodal Attention Fusion (HBAF) for multi-level multi-modal interaction in conversational emotion recognition. The proposed method comprises three key modules: the uni-modal representation module, the multi-modal fusion module, and the inter-modal contrastive learning module. The uni-modal representation module incorporates contextual content into low-level audio representations to bridge the heterogeneous multi-modal gap, enabling more effective fusion. The multi-modal fusion module uses dynamic bimodal attention and a dynamic gating mechanism to filter incorrect cross-modal relationships and fully exploit both intra-modal and inter-modal interactions. Finally, the inter-modal contrastive learning module captures complex absolute and relative interactions between audio and text modalities. Experiments on the MELD and IEMOCAP datasets demonstrate that the proposed HBAF method outperforms existing state-of-the-art baselines.', 'abstract_zh': '多模态对话情感识别中的异构模态差距给跨模态情感识别带来了挑战。由于不同模态间的复杂互补交互，从人类视角理解情感尤为关键。现有大多数研究集中在探索音频和文本模态在同一表示层面上的交互。然而，一个关键问题被忽视了：低级音频表示与高级文本表示之间的异构模态差距。为解决这一问题，我们提出了一种名为Heterogeneous Bimodal Attention Fusion (HBAF)的新框架，用于对话情感识别中的多层多模态交互。该方法包含三个关键模块：单模态表示模块、多模态融合模块和跨模态对比学习模块。单模态表示模块将上下文内容融入低级音频表示中，以弥合异构多模态差距，实现更有效的融合。多模态融合模块利用动态双模态注意力和动态门控机制过滤错误的跨模态关系，充分挖掘内在模态和跨模态交互。最后，跨模态对比学习模块捕获音频和文本模态之间复杂绝对和相对交互。在MELD和IEMOCAP数据集上的实验表明，提出的HBAF方法优于现有最先进的基线方法。', 'title_zh': '异质双模态注意力融合在语音情感识别中的应用'}
{'arxiv_id': 'arXiv:2503.06398', 'title': 'Causality Enhanced Origin-Destination Flow Prediction in Data-Scarce Cities', 'authors': 'Tao Feng, Yunke Zhang, Huandong Wang, Yong Li', 'link': 'https://arxiv.org/abs/2503.06398', 'abstract': 'Accurate origin-destination (OD) flow prediction is of great importance to developing cities, as it can contribute to optimize urban structures and layouts. However, with the common issues of missing regional features and lacking OD flow data, it is quite daunting to predict OD flow in developing cities. To address this challenge, we propose a novel Causality-Enhanced OD Flow Prediction (CE-OFP), a unified framework that aims to transfer urban knowledge between cities and achieve accuracy improvements in OD flow predictions across data-scarce cities. In specific, we propose a novel reinforcement learning model to discover universal causalities among urban features in data-rich cities and build corresponding causal graphs. Then, we further build Causality-Enhanced Variational Auto-Encoder (CE-VAE) to incorporate causal graphs for effective feature reconstruction in data-scarce cities. Finally, with the reconstructed features, we devise a knowledge distillation method with a graph attention network to migrate the OD prediction model from data-rich cities to data-scare cities. Extensive experiments on two pairs of real-world datasets validate that the proposed CE-OFP remarkably outperforms state-of-the-art baselines, which can reduce the RMSE of OD flow prediction for data-scarce cities by up to 11%.', 'abstract_zh': '基于因果增强的Origin-Destination流预测（CE-OFP）', 'title_zh': '数据稀缺城市中的因果增强起源-目的地流量预测'}
{'arxiv_id': 'arXiv:2503.06392', 'title': 'EPR-GAIL: An EPR-Enhanced Hierarchical Imitation Learning Framework to Simulate Complex User Consumption Behaviors', 'authors': 'Tao Feng, Yunke Zhang, Huandong Wang, Yong Li', 'link': 'https://arxiv.org/abs/2503.06392', 'abstract': "User consumption behavior data, which records individuals' online spending history at various types of stores, has been widely used in various applications, such as store recommendation, site selection, and sale forecasting. However, its high worth is limited due to deficiencies in data comprehensiveness and changes of application scenarios. Thus, generating high-quality sequential consumption data by simulating complex user consumption behaviors is of great importance to real-world applications. Two branches of existing sequence generation methods are both limited in quality. Model-based methods with simplified assumptions fail to model the complex decision process of user consumption, while data-driven methods that emulate real-world data are prone to noises, unobserved behaviors, and dynamic decision space. In this work, we propose to enhance the fidelity and trustworthiness of the data-driven Generative Adversarial Imitation Learning (GAIL) method by blending it with the Exploration and Preferential Return EPR model . The core idea of our EPR-GAIL framework is to model user consumption behaviors as a complex EPR decision process, which consists of purchase, exploration, and preference decisions. Specifically, we design the hierarchical policy function in the generator as a realization of the EPR decision process and employ the probability distributions of the EPR model to guide the reward function in the discriminator. Extensive experiments on two real-world datasets of user consumption behaviors on an online platform demonstrate that the EPR-GAIL framework outperforms the best state-of-the-art baseline by over 19\\% in terms of data fidelity. Furthermore, the generated consumption behavior data can improve the performance of sale prediction and location recommendation by up to 35.29% and 11.19%, respectively, validating its advantage for practical applications.", 'abstract_zh': '基于EPR模型增强的生成对抗模仿学习框架：提升用户消费行为数据的真实性和可靠性', 'title_zh': 'EPR-GAIL：一种增强层次 imitation 学习框架，用于模拟复杂的用户消费行为'}
{'arxiv_id': 'arXiv:2503.06368', 'title': 'VORTEX: Challenging CNNs at Texture Recognition by using Vision Transformers with Orderless and Randomized Token Encodings', 'authors': 'Leonardo Scabini, Kallil M. Zielinski, Emir Konuk, Ricardo T. Fares, Lucas C. Ribas, Kevin Smith, Odemir M. Bruno', 'link': 'https://arxiv.org/abs/2503.06368', 'abstract': 'Texture recognition has recently been dominated by ImageNet-pre-trained deep Convolutional Neural Networks (CNNs), with specialized modifications and feature engineering required to achieve state-of-the-art (SOTA) performance. However, although Vision Transformers (ViTs) were introduced a few years ago, little is known about their texture recognition ability. Therefore, in this work, we introduce VORTEX (ViTs with Orderless and Randomized Token Encodings for Texture Recognition), a novel method that enables the effective use of ViTs for texture analysis. VORTEX extracts multi-depth token embeddings from pre-trained ViT backbones and employs a lightweight module to aggregate hierarchical features and perform orderless encoding, obtaining a better image representation for texture recognition tasks. This approach allows seamless integration with any ViT with the common transformer architecture. Moreover, no fine-tuning of the backbone is performed, since they are used only as frozen feature extractors, and the features are fed to a linear SVM. We evaluate VORTEX on nine diverse texture datasets, demonstrating its ability to achieve or surpass SOTA performance in a variety of texture analysis scenarios. By bridging the gap between texture recognition with CNNs and transformer-based architectures, VORTEX paves the way for adopting emerging transformer foundation models. Furthermore, VORTEX demonstrates robust computational efficiency when coupled with ViT backbones compared to CNNs with similar costs. The method implementation and experimental scripts are publicly available in our online repository.', 'abstract_zh': '基于Vision Transformers的VORTEX：一种用于纹理识别的无序和随机化Token编码方法', 'title_zh': 'VORTEX：通过使用无序和随机化Token编码的视觉变换器挑战CNN在纹理识别任务中的表现'}
{'arxiv_id': 'arXiv:2503.06366', 'title': 'Machine Learning meets Algebraic Combinatorics: A Suite of Datasets Capturing Research-level Conjecturing Ability in Pure Mathematics', 'authors': 'Herman Chau, Helen Jenne, Davis Brown, Jesse He, Mark Raugas, Sara Billey, Henry Kvinge', 'link': 'https://arxiv.org/abs/2503.06366', 'abstract': 'With recent dramatic increases in AI system capabilities, there has been growing interest in utilizing machine learning for reasoning-heavy, quantitative tasks, particularly mathematics. While there are many resources capturing mathematics at the high-school, undergraduate, and graduate level, there are far fewer resources available that align with the level of difficulty and open endedness encountered by professional mathematicians working on open problems. To address this, we introduce a new collection of datasets, the Algebraic Combinatorics Dataset Repository (ACD Repo), representing either foundational results or open problems in algebraic combinatorics, a subfield of mathematics that studies discrete structures arising from abstract algebra. Further differentiating our dataset collection is the fact that it aims at the conjecturing process. Each dataset includes an open-ended research-level question and a large collection of examples (up to 10M in some cases) from which conjectures should be generated. We describe all nine datasets, the different ways machine learning models can be applied to them (e.g., training with narrow models followed by interpretability analysis or program synthesis with LLMs), and discuss some of the challenges involved in designing datasets like these.', 'abstract_zh': '随着人工智能系统能力的 recent 激增，在推理性和量化任务，特别是数学领域，利用机器学习的兴趣逐渐增长。为了应对这一需求，我们引入了代数组合学数据集库（ACD Repo），收录了代数组合学领域的基础成果或开放问题，代数组合学是研究源自抽象代数的离散结构的一个数学子领域。该数据集库特别注重猜想过程，每个数据集包含一个开放性研究级问题以及大量示例（某些情况下多达10M），用于生成猜想。我们描述了所有九个数据集以及机器学习模型在它们上的不同应用方式（例如，使用窄模型训练后进行可解释性分析或使用大语言模型进行程序合成），并讨论了设计这类数据集所面临的挑战。', 'title_zh': '机器学习邂逅代数组合数学：一套捕捉纯数学研究级猜想能力的数据集'}
{'arxiv_id': 'arXiv:2503.06353', 'title': 'The AI Pentad, the CHARME$^{2}$D Model, and an Assessment of Current-State AI Regulation', 'authors': 'Di Kevin Gao, Sudip Mittal, Jiming Wu, Hongwei Du, Jingdao Chen, Shahram Rahimi', 'link': 'https://arxiv.org/abs/2503.06353', 'abstract': 'Artificial Intelligence (AI) has made remarkable progress in the past few years with AI-enabled applications beginning to permeate every aspect of our society. Despite the widespread consensus on the need to regulate AI, there remains a lack of a unified approach to framing, developing, and assessing AI regulations. Many of the existing methods take a value-based approach, for example, accountability, fairness, free from bias, transparency, and trust. However, these methods often face challenges at the outset due to disagreements in academia over the subjective nature of these definitions. This paper aims to establish a unifying model for AI regulation from the perspective of core AI components. We first introduce the AI Pentad, which comprises the five essential components of AI: humans and organizations, algorithms, data, computing, and energy. We then review AI regulatory enablers, including AI registration and disclosure, AI monitoring, and AI enforcement mechanisms. Subsequently, we present the CHARME$^{2}$D Model to explore further the relationship between the AI Pentad and AI regulatory enablers. Finally, we apply the CHARME$^{2}$D model to assess AI regulatory efforts in the European Union (EU), China, the United Arab Emirates (UAE), the United Kingdom (UK), and the United States (US), highlighting their strengths, weaknesses, and gaps. This comparative evaluation offers insights for future legislative work in the AI domain.', 'abstract_zh': '人工智能（AI）在过去的几年中取得了显著进步，AI驱动的应用开始渗透到我们社会的各个方面。尽管普遍认为需要对AI进行监管，但仍缺乏一个统一的方法来构建、开发和评估AI监管。现有方法多采用一种基于价值的方法，例如，问责性、公平性、无偏见、透明度和信任。然而，这些方法往往由于学术界对这些定义的主观性存在分歧而面临初始挑战。本文旨在从核心AI组件的角度建立一个统一的AI监管模型。首先，我们介绍了AI五元组，包括AI的五大基本组件：人类与组织、算法、数据、计算和能源。然后，我们回顾了AI监管支持者，包括AI登记与披露、AI监控和AI执法机制。接着，我们提出了CHARME$^{2}$D模型，进一步探索AI五元组与AI监管支持者之间的关系。最后，我们应用CHARME$^{2}$D模型评估欧盟、中国、阿拉伯联合酋长国、英国和美国在AI监管方面的努力，指出其优点、缺点和不足。这一比较评估为未来AI领域的立法工作提供了启示。', 'title_zh': '人工智能五元组、CHARME$^{2}$D模型及其对当前人工智能监管状况的评估'}
{'arxiv_id': 'arXiv:2503.06343', 'title': 'Studying the Interplay Between the Actor and Critic Representations in Reinforcement Learning', 'authors': 'Samuel Garcin, Trevor McInroe, Pablo Samuel Castro, Prakash Panangaden, Christopher G. Lucas, David Abel, Stefano V. Albrecht', 'link': 'https://arxiv.org/abs/2503.06343', 'abstract': "Extracting relevant information from a stream of high-dimensional observations is a central challenge for deep reinforcement learning agents. Actor-critic algorithms add further complexity to this challenge, as it is often unclear whether the same information will be relevant to both the actor and the critic. To this end, we here explore the principles that underlie effective representations for the actor and for the critic in on-policy algorithms. We focus our study on understanding whether the actor and critic will benefit from separate, rather than shared, representations. Our primary finding is that when separated, the representations for the actor and critic systematically specialise in extracting different types of information from the environment -- the actor's representation tends to focus on action-relevant information, while the critic's representation specialises in encoding value and dynamics information. We conduct a rigourous empirical study to understand how different representation learning approaches affect the actor and critic's specialisations and their downstream performance, in terms of sample efficiency and generation capabilities. Finally, we discover that a separated critic plays an important role in exploration and data collection during training. Our code, trained models and data are accessible at this https URL.", 'abstract_zh': '从高维观测流中提取相关信息是深度强化学习代理面临的核心挑战。演员-评论家算法为这一挑战增加了额外的复杂性，因为通常不清楚相同的信息对演员和评论家而言是否具有相关性。为此，我们在此探索了有效表示原则，这些原则适用于策略和评论在在线算法中的表示。我们将研究重点放在理解演员和评论家是否从分离的、而不是共享的表示中受益上。我们的主要发现是，当分离时，演员和评论家的表示会系统地专门化于从环境中提取不同类型的信息——演员的表示倾向于关注与动作相关的信息，而评论家的表示则专门编码价值和动力学信息。我们进行了严格的经验研究，以了解不同的表示学习方法如何影响演员和评论家的专门化及其下游性能，特别是在样本效率和生成能力方面。最后，我们发现分离的评论家在训练过程中的探索和数据收集中扮演着重要角色。我们的代码、训练模型和数据可在以下网址访问：this https URL。', 'title_zh': '研究演员与评论家表示之间的交互作用在强化学习中的作用'}
{'arxiv_id': 'arXiv:2503.06330', 'title': 'States of LLM-generated Texts and Phase Transitions between them', 'authors': 'Nikolay Mikhaylovskiy', 'link': 'https://arxiv.org/abs/2503.06330', 'abstract': 'It is known for some time that autocorrelations of words in human-written texts decay according to a power law. Recent works have also shown that the autocorrelations decay in texts generated by LLMs is qualitatively different from the literary texts. Solid state physics tie the autocorrelations decay laws to the states of matter. In this work, we empirically demonstrate that, depending on the temperature parameter, LLMs can generate text that can be classified as solid, critical state or gas.', 'abstract_zh': '已知人类撰写的文本中单词的自相关性按照幂律衰减。近期的研究还表明，由大规模语言模型(LLMs)生成的文本的自相关性衰减与文学文本在定性上有显著差异。固体物理学将自相关性衰减规律与物质状态联系起来。本研究通过实验证明，在不同的温度参数下，LLMs可以生成可归类为固体、临界状态或气体的文本。', 'title_zh': 'LLM生成文本的状态及其之间相变阶段'}
{'arxiv_id': 'arXiv:2503.06313', 'title': 'Advancing Autonomous Vehicle Intelligence: Deep Learning and Multimodal LLM for Traffic Sign Recognition and Robust Lane Detection', 'authors': 'Chandan Kumar Sah, Ankit Kumar Shaw, Xiaoli Lian, Arsalan Shahid Baig, Tuopu Wen, Kun Jiang, Mengmeng Yang, Diange Yang', 'link': 'https://arxiv.org/abs/2503.06313', 'abstract': 'Autonomous vehicles (AVs) require reliable traffic sign recognition and robust lane detection capabilities to ensure safe navigation in complex and dynamic environments. This paper introduces an integrated approach combining advanced deep learning techniques and Multimodal Large Language Models (MLLMs) for comprehensive road perception. For traffic sign recognition, we systematically evaluate ResNet-50, YOLOv8, and RT-DETR, achieving state-of-the-art performance of 99.8% with ResNet-50, 98.0% accuracy with YOLOv8, and achieved 96.6% accuracy in RT-DETR despite its higher computational complexity. For lane detection, we propose a CNN-based segmentation method enhanced by polynomial curve fitting, which delivers high accuracy under favorable conditions. Furthermore, we introduce a lightweight, Multimodal, LLM-based framework that directly undergoes instruction tuning using small yet diverse datasets, eliminating the need for initial pretraining. This framework effectively handles various lane types, complex intersections, and merging zones, significantly enhancing lane detection reliability by reasoning under adverse conditions. Despite constraints in available training resources, our multimodal approach demonstrates advanced reasoning capabilities, achieving a Frame Overall Accuracy (FRM) of 53.87%, a Question Overall Accuracy (QNS) of 82.83%, lane detection accuracies of 99.6% in clear conditions and 93.0% at night, and robust performance in reasoning about lane invisibility due to rain (88.4%) or road degradation (95.6%). The proposed comprehensive framework markedly enhances AV perception reliability, thus contributing significantly to safer autonomous driving across diverse and challenging road scenarios.', 'abstract_zh': '自动驾驶车辆需要可靠的交通标志识别和稳健的车道检测能力，以确保在复杂和动态环境中的安全导航。本文介绍了一种结合先进深度学习技术和多模态大规模语言模型（MLLMs）的综合方法，用于全面的道路感知。在交通标志识别方面，我们系统评估了ResNet-50、YOLOv8和RT-DETR，分别取得了99.8%、98.0%和96.6%的准确率。对于车道检测，我们提出了一种基于CNN的分割方法，并通过多项式曲线拟合进行增强，在有利条件下实现了高精度。此外，我们介绍了一种轻量级、多模态的基于LLM的框架，该框架直接通过使用小而多样化的数据集进行指令调优，无需初始预训练。该框架能够有效处理各种车道类型、复杂交叉口和合流区，通过在恶劣条件下的推理显著提高了车道检测的可靠性。尽管存在可用训练资源的限制，我们的多模态方法展示了高级推理能力，实现了53.87%的Frame Overall Accuracy (FRM)、82.83%的Question Overall Accuracy (QNS)，以及在清晰条件下99.6%、夜间93.0%的车道检测准确率，并在雨天（88.4%）或路面降级（95.6%）条件下表现出稳健的关于车道不可见性的推理性能。所提出的整体框架显著增强了自动驾驶车辆的道路感知可靠性，从而在各种复杂的道路场景中为更安全的自动驾驶做出了重要贡献。', 'title_zh': '增强自主车辆智能：深度学习与多模态LLM在交通标志识别和稳健车道检测中的应用'}
{'arxiv_id': 'arXiv:2503.06302', 'title': 'Synergizing AI and Digital Twins for Next-Generation Network Optimization, Forecasting, and Security', 'authors': 'Zifan Zhang, Minghong Fang, Dianwei Chen, Xianfeng Yang, Yuchen Liu', 'link': 'https://arxiv.org/abs/2503.06302', 'abstract': 'Digital network twins (DNTs) are virtual representations of physical networks, designed to enable real-time monitoring, simulation, and optimization of network performance. When integrated with machine learning (ML) techniques, particularly federated learning (FL) and reinforcement learning (RL), DNTs emerge as powerful solutions for managing the complexities of network operations. This article presents a comprehensive analysis of the synergy of DNTs, FL, and RL techniques, showcasing their collective potential to address critical challenges in 6G networks. We highlight key technical challenges that need to be addressed, such as ensuring network reliability, achieving joint data-scenario forecasting, and maintaining security in high-risk environments. Additionally, we propose several pipelines that integrate DNT and ML within coherent frameworks to enhance network optimization and security. Case studies demonstrate the practical applications of our proposed pipelines in edge caching and vehicular networks. In edge caching, the pipeline achieves over 80% cache hit rates while balancing base station loads. In autonomous vehicular system, it ensure a 100% no-collision rate, showcasing its reliability in safety-critical scenarios. By exploring these synergies, we offer insights into the future of intelligent and adaptive network systems that automate decision-making and problem-solving.', 'abstract_zh': '数字网络孪生（DNTs）是物理网络的虚拟表示，旨在实现网络性能的实时监测、仿真和优化。当结合机器学习（ML）技术，特别是联邦学习（FL）和强化学习（RL）时，DNTs成为管理网络操作复杂性的有力解决方案。本文全面分析了DNTs、FL和RL技术的协同效应，展示了其在解决6G网络关键挑战方面的潜在能力。我们强调了需要应对的关键技术挑战，包括确保网络可靠性、实现联合数据场景预测以及在高风险环境中维护安全。此外，我们提出了几条将DNT和ML集成到一致框架中的管道，以增强网络优化和安全性。案例研究展示了我们提出的管道在边缘缓存和车载网络中的实际应用。在边缘缓存中，管道实现了超过80%的缓存命中率，并平衡了基站的负载。在自主车载系统中，它确保了100%的安全，展示了其在安全关键场景中的可靠性。通过探索这些协同效应，我们提供了有关未来智能化和自适应网络系统的信息，这些系统能够自动进行决策和问题解决。', 'title_zh': '协同AI与数字孪生优化下一代网络性能、预测与安全'}
{'arxiv_id': 'arXiv:2503.06288', 'title': 'Single Domain Generalization with Adversarial Memory', 'authors': 'Hao Yan, Marzi Heidari, Yuhong Guo', 'link': 'https://arxiv.org/abs/2503.06288', 'abstract': 'Domain Generalization (DG) aims to train models that can generalize to unseen testing domains by leveraging data from multiple training domains. However, traditional DG methods rely on the availability of multiple diverse training domains, limiting their applicability in data-constrained scenarios. Single Domain Generalization (SDG) addresses the more realistic and challenging setting by restricting the training data to a single domain distribution. The main challenges in SDG stem from the limited diversity of training data and the inaccessibility of unseen testing data distributions. To tackle these challenges, we propose a single domain generalization method that leverages an adversarial memory bank to augment training features. Our memory-based feature augmentation network maps both training and testing features into an invariant subspace spanned by diverse memory features, implicitly aligning the training and testing domains in the projected space. To maintain a diverse and representative feature memory bank, we introduce an adversarial feature generation method that creates features extending beyond the training domain distribution. Experimental results demonstrate that our approach achieves state-of-the-art performance on standard single domain generalization benchmarks.', 'abstract_zh': '单域泛化（SDG）旨在通过利用单个训练域的数据训练模型，使其能够在未见测试域上泛化。传统的泛化方法依赖于多个 diverse 的训练域，这限制了它们在数据受限场景中的应用。单域泛化（SDG）通过限制训练数据到单个域分布，解决了更现实和具有挑战性的设置。单域泛化的主要挑战来自于训练数据的有限多样性和未见测试域分布的不可访问性。为了应对这些挑战，我们提出了一种利用对抗记忆库扩充训练特征的单域泛化方法。基于记忆的特征扩充网络将训练和测试特征映射到由多样记忆特征构成的不变子空间中，隐式地在投影空间中对齐训练和测试域。为了保持多样且具有代表性的特征记忆库，我们引入了一种对抗特征生成方法，该方法生成扩展到训练域分布之外的特征。实验结果表明，我们的方法在标准单域泛化基准上达到了最先进的性能。', 'title_zh': '单域适应性记忆强化单域泛化'}
{'arxiv_id': 'arXiv:2503.06287', 'title': 'Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding', 'authors': 'Seil Kang, Jinyeong Kim, Junhyeok Kim, Seong Jae Hwang', 'link': 'https://arxiv.org/abs/2503.06287', 'abstract': 'Visual grounding seeks to localize the image region corresponding to a free-form text description. Recently, the strong multimodal capabilities of Large Vision-Language Models (LVLMs) have driven substantial improvements in visual grounding, though they inevitably require fine-tuning and additional model components to explicitly generate bounding boxes or segmentation masks. However, we discover that a few attention heads in frozen LVLMs demonstrate strong visual grounding capabilities. We refer to these heads, which consistently capture object locations related to text semantics, as localization heads. Using localization heads, we introduce a straightforward and effective training-free visual grounding framework that utilizes text-to-image attention maps from localization heads to identify the target objects. Surprisingly, only three out of thousands of attention heads are sufficient to achieve competitive localization performance compared to existing LVLM-based visual grounding methods that require fine-tuning. Our findings suggest that LVLMs can innately ground objects based on a deep comprehension of the text-image relationship, as they implicitly focus on relevant image regions to generate informative text outputs. All the source codes will be made available to the public.', 'abstract_zh': '视觉定位旨在定位与自由形式文本描述相对应的图像区域。近年来，大型多模态模型（LVLMs）的强大能力推动了视觉定位的显著进步，尽管它们不可避免地需要微调和附加模型组件以明确生成边界框或分割掩码。然而，我们发现冻结的LVLM中的一些建模注意力头展示了强大的视觉定位能力。我们将这些注意力头称为定位头，这些头能够一致地捕获与文本语义相关的物体位置。使用定位头，我们提出了一种简单且有效的无需训练的视觉定位框架，利用定位头的文本到图像注意力图来识别目标物体。令人惊讶的是，仅需数千个注意力头中不足三个即可实现与现有需要微调的LVLM基视觉定位方法相当的定位性能。我们的研究结果表明，LVLM能够基于对图文关系的深层理解，天生能够将物体进行视觉定位，它们隐式地关注相关的图像区域以生成有意义的文本输出。所有源代码将对公众开放。', 'title_zh': '你的大型 vision-language 模型只需几个注意力头即可实现视觉定位。'}
{'arxiv_id': 'arXiv:2503.06278', 'title': 'Applied Machine Learning Methods with Long-Short Term Memory Based Recurrent Neural Networks for Multivariate Temperature Prediction', 'authors': 'Bojan Lukić', 'link': 'https://arxiv.org/abs/2503.06278', 'abstract': "This paper gives an overview on how to develop a dense and deep neural network for making a time series prediction. First, the history and cornerstones in Artificial Intelligence and Machine Learning will be presented. After a short introduction to the theory of Artificial Intelligence and Machine Learning, the paper will go deeper into the techniques for conducting a time series prediction with different models of neural networks. For this project, Python's development environment Jupyter, extended with the TensorFlow package and deep-learning application Keras is used. The system setup and project framework are explained in more detail before discussing the time series prediction. The main part shows an applied example of time series prediction with weather data. For this work, a deep recurrent neural network with Long Short-Term Memory cells is used to conduct the time series prediction. The results and evaluation of the work show that a weather prediction with deep neural networks can be successful for a short time period. However, there are some drawbacks and limitations with time series prediction, which will be discussed towards the end of the paper.", 'abstract_zh': '本文概述了如何开发密集和深层神经网络以进行时间序列预测。首先，将介绍人工智能和机器学习的历史和基石。在简要介绍人工智能和机器学习的理论之后，文章将深入探讨使用不同神经网络模型进行时间序列预测的技术。为此项目，使用了 Python 的开发环境 Jupyter，扩展了 TensorFlow 包和深度学习应用 Keras。在讨论时间序列预测之前，详细解释了系统设置和项目框架。主要部分展示了使用天气数据进行时间序列预测的应用示例。在此工作中，使用具有长短期记忆单元的深层递归神经网络进行时间序列预测。工作的结果和评估表明，使用深度神经网络进行短期天气预测可以取得成功。然而，时间序列预测存在一些缺点和局限性，这将在本文末尾进行讨论。', 'title_zh': '基于长短期记忆循环神经网络的多元温度预测中应用的机器学习方法'}
{'arxiv_id': 'arXiv:2503.06269', 'title': 'Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models', 'authors': 'Thomas Winninger, Boussad Addad, Katarzyna Kapusta', 'link': 'https://arxiv.org/abs/2503.06269', 'abstract': "Traditional white-box methods for creating adversarial perturbations against LLMs typically rely only on gradient computation from the targeted model, ignoring the internal mechanisms responsible for attack success or failure. Conversely, interpretability studies that analyze these internal mechanisms lack practical applications beyond runtime interventions. We bridge this gap by introducing a novel white-box approach that leverages mechanistic interpretability techniques to craft practical adversarial inputs. Specifically, we first identify acceptance subspaces - sets of feature vectors that do not trigger the model's refusal mechanisms - then use gradient-based optimization to reroute embeddings from refusal subspaces to acceptance subspaces, effectively achieving jailbreaks. This targeted approach significantly reduces computation cost, achieving attack success rates of 80-95\\% on state-of-the-art models including Gemma2, Llama3.2, and Qwen2.5 within minutes or even seconds, compared to existing techniques that often fail or require hours of computation. We believe this approach opens a new direction for both attack research and defense development. Furthermore, it showcases a practical application of mechanistic interpretability where other methods are less efficient, which highlights its utility. The code and generated datasets are available at this https URL.", 'abstract_zh': '一种结合机械可解释性的白盒方法以生成针对大语言模型的实用对抗输入', 'title_zh': '使用机理可解释性针对大规模语言模型构建对抗性攻击'}
{'arxiv_id': 'arXiv:2503.06263', 'title': 'Critical Foreign Policy Decisions (CFPD)-Benchmark: Measuring Diplomatic Preferences in Large Language Models', 'authors': 'Benjamin Jensen, Ian Reynolds, Yasir Atalan, Michael Garcia, Austin Woo, Anthony Chen, Trevor Howarth', 'link': 'https://arxiv.org/abs/2503.06263', 'abstract': 'As national security institutions increasingly integrate Artificial Intelligence (AI) into decision-making and content generation processes, understanding the inherent biases of large language models (LLMs) is crucial. This study presents a novel benchmark designed to evaluate the biases and preferences of seven prominent foundation models-Llama 3.1 8B Instruct, Llama 3.1 70B Instruct, GPT-4o, Gemini 1.5 Pro-002, Mixtral 8x22B, Claude 3.5 Sonnet, and Qwen2 72B-in the context of international relations (IR). We designed a bias discovery study around core topics in IR using 400-expert crafted scenarios to analyze results from our selected models. These scenarios focused on four topical domains including: military escalation, military and humanitarian intervention, cooperative behavior in the international system, and alliance dynamics. Our analysis reveals noteworthy variation among model recommendations based on scenarios designed for the four tested domains. Particularly, Qwen2 72B, Gemini 1.5 Pro-002 and Llama 3.1 8B Instruct models offered significantly more escalatory recommendations than Claude 3.5 Sonnet and GPT-4o models. All models exhibit some degree of country-specific biases, often recommending less escalatory and interventionist actions for China and Russia compared to the United States and the United Kingdom. These findings highlight the necessity for controlled deployment of LLMs in high-stakes environments, emphasizing the need for domain-specific evaluations and model fine-tuning to align with institutional objectives.', 'abstract_zh': '随着国家安全机构越来越多地将人工智能（AI）整合进决策和内容生成过程中，理解大型语言模型（LLMs）固有的偏见至关重要。本研究提出了一种新的基准测试，旨在评估七种 prominant 基础模型——Llama 3.1 8B Instruct、Llama 3.1 70B Instruct、GPT-4、Gemini 1.5 Pro-002、Mixtral 8x22B、Claude 3.5 Sonnet 和 Qwen2 72B——在国际关系（IR）领域的偏见和偏好。我们围绕国际关系的核心话题设计了一个偏见发现研究，使用400个专家设计的场景来分析选定模型的结果。这些场景集中在四个主题领域，包括军事升级、军事和人道主义干预、国际体系中的合作行为以及联盟动态。我们的分析表明，基于为四个测试领域设计的场景，模型建议之间存在显著差异。特别是，Qwen2 72B、Gemini 1.5 Pro-002 和 Llama 3.1 8B Instruct 模型比 Claude 3.5 Sonnet 和 GPT-4 模型提供了更多的升级建议。所有模型都表现出某种程度的国家特定偏见，经常建议对中国的干预行动比对美国和英国采取的行动更不升级。这些发现突显了在高风险环境中受控部署LLMs的必要性，强调了领域特定评估和模型微调以实现机构目标的重要性。', 'title_zh': '大型语言模型中衡量外交偏好的一种基准：关键外国政策决策(CFPD)'}
{'arxiv_id': 'arXiv:2503.06260', 'title': 'From Captions to Rewards (CAREVL): Leveraging Large Language Model Experts for Enhanced Reward Modeling in Large Vision-Language Models', 'authors': 'Muzhi Dai, Jiashuo Sun, Zhiyuan Zhao, Shixuan Liu, Rui Li, Junyu Gao, Xuelong Li', 'link': 'https://arxiv.org/abs/2503.06260', 'abstract': 'Aligning large vision-language models (LVLMs) with human preferences is challenging due to the scarcity of fine-grained, high-quality, and multimodal preference data without human annotations. Existing methods relying on direct distillation often struggle with low-confidence data, leading to suboptimal performance. To address this, we propose CAREVL, a novel method for preference reward modeling by reliably using both high- and low-confidence data. First, a cluster of auxiliary expert models (textual reward models) innovatively leverages image captions as weak supervision signals to filter high-confidence data. The high-confidence data are then used to fine-tune the LVLM. Second, low-confidence data are used to generate diverse preference samples using the fine-tuned LVLM. These samples are then scored and selected to construct reliable chosen-rejected pairs for further training. CAREVL achieves performance improvements over traditional distillation-based methods on VL-RewardBench and MLLM-as-a-Judge benchmark, demonstrating its effectiveness. The code will be released soon.', 'abstract_zh': '基于可靠利用高低置信度数据的偏好奖励建模方法CAREVL', 'title_zh': '从字幕到奖励：利用大型语言模型专家增强视觉-语言模型的奖励建模（CAREVL）'}
{'arxiv_id': 'arXiv:2503.06252', 'title': 'Can Atomic Step Decomposition Enhance the Self-structured Reasoning of Multimodal Large Models?', 'authors': 'Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang, Haoxiang Fan, Hanhui Li, Weiran Huang, Yihan Zeng, Yu-Jie Yuan, Jianhua Han, Lanqing Hong, Hang Xu, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2503.06252', 'abstract': 'In this paper, we address the challenging task of multimodal mathematical reasoning by incorporating the ability of "slow thinking" into multimodal large language models (MLLMs). Our core idea is that different levels of reasoning abilities can be combined dynamically to tackle questions with different complexity. To this end, we propose a paradigm of Self-structured Chain of Thought (SCoT), which is composed of minimal semantic atomic steps. Different from existing methods that rely on structured templates or free-form paradigms, our method can not only generate cognitive CoT structures for various complex tasks but also mitigates the phenomenon of overthinking. To introduce structured reasoning capabilities into visual understanding models, we further design a novel AtomThink framework with four key modules, including (i) a data engine to generate high-quality multimodal reasoning paths; (ii) a supervised fine-tuning process with serialized inference data; (iii) a policy-guided multi-turn inference method; and (iv) an atomic capability metric to evaluate the single step utilization rate. We conduct extensive experiments to show that the proposed AtomThink significantly improves the performance of baseline MLLMs, achieving more than 10\\% average accuracy gains on MathVista and MathVerse. Compared to state-of-the-art structured CoT approaches, our method not only achieves higher accuracy but also improves data utilization by 5 times and boosts inference efficiency by 85.3\\%. Our code is now public available in this https URL.', 'abstract_zh': '基于“慢思考”能力的多模态数学推理研究：AtomThink框架及其应用', 'title_zh': '原子步骤分解能否增强 multimodal 大模型的自我结构化推理能力？'}
{'arxiv_id': 'arXiv:2503.06247', 'title': 'Infant Cry Detection Using Causal Temporal Representation', 'authors': 'Minghao Fu, Danning Li, Aryan Gadhiya, Benjamin Lambright, Mohamed Alowais, Mohab Bahnassy, Saad El Dine Elletter, Hawau Olamide Toyin, Haiyan Jiang, Kun Zhang, Hanan Aldarmaki', 'link': 'https://arxiv.org/abs/2503.06247', 'abstract': 'This paper addresses a major challenge in acoustic event detection, in particular infant cry detection in the presence of other sounds and background noises: the lack of precise annotated data. We present two contributions for supervised and unsupervised infant cry detection. The first is an annotated dataset for cry segmentation, which enables supervised models to achieve state-of-the-art performance. Additionally, we propose a novel unsupervised method, Causal Representation Spare Transition Clustering (CRSTC), based on causal temporal representation, which helps address the issue of data scarcity more generally. By integrating the detected cry segments, we significantly improve the performance of downstream infant cry classification, highlighting the potential of this approach for infant care applications.', 'abstract_zh': '本文解决了声学事件检测中的一个重大挑战，特别是在其他声音和背景噪声共存的情况下婴儿哭声检测缺乏精确标注数据的问题。我们提出了监督和非监督婴儿哭声检测的两个贡献。首先，我们提供了一个标注数据集用于哭声分割，这使得监督模型能够达到最佳性能。此外，我们提出了一种基于因果时间表征的新型非监督方法——因果表示稀疏过渡聚类（CRSTC），该方法有助于更广泛地解决数据稀缺问题。通过整合检测到的哭声片段，显著提高了婴儿哭声分类的性能，突显了该方法在婴儿护理应用中的潜力。', 'title_zh': '基于因果时间表示的婴儿哭声检测'}
{'arxiv_id': 'arXiv:2503.06238', 'title': 'Image is All You Need: Towards Efficient and Effective Large Language Model-Based Recommender Systems', 'authors': 'Kibum Kim, Sein Kim, Hongseok Kang, Jiwan Kim, Heewoong Noh, Yeonjun In, Kanghoon Yoon, Jinoh Oh, Chanyoung Park', 'link': 'https://arxiv.org/abs/2503.06238', 'abstract': 'Large Language Models (LLMs) have recently emerged as a powerful backbone for recommender systems. Existing LLM-based recommender systems take two different approaches for representing items in natural language, i.e., Attribute-based Representation and Description-based Representation. In this work, we aim to address the trade-off between efficiency and effectiveness that these two approaches encounter, when representing items consumed by users. Based on our interesting observation that there is a significant information overlap between images and descriptions associated with items, we propose a novel method, Image is all you need for LLM-based Recommender system (I-LLMRec). Our main idea is to leverage images as an alternative to lengthy textual descriptions for representing items, aiming at reducing token usage while preserving the rich semantic information of item descriptions. Through extensive experiments, we demonstrate that I-LLMRec outperforms existing methods in both efficiency and effectiveness by leveraging images. Moreover, a further appeal of I-LLMRec is its ability to reduce sensitivity to noise in descriptions, leading to more robust recommendations.', 'abstract_zh': '基于图像的大语言模型推荐系统（I-LLMRec）', 'title_zh': '图像即所需： Toward Efficient and Effective Large Language Model-Based Recommender Systems'}
{'arxiv_id': 'arXiv:2503.06229', 'title': 'A Frank System for Co-Evolutionary Hybrid Decision-Making', 'authors': 'Federico Mazzoni, Riccardo Guidotti, Alessio Malizia', 'link': 'https://arxiv.org/abs/2503.06229', 'abstract': "We introduce Frank, a human-in-the-loop system for co-evolutionary hybrid decision-making aiding the user to label records from an un-labeled dataset. Frank employs incremental learning to ``evolve'' in parallel with the user's decisions, by training an interpretable machine learning model on the records labeled by the user. Furthermore, Frank advances state-of-the-art approaches by offering inconsistency controls, explanations, fairness checks, and bad-faith safeguards simultaneously. We evaluate our proposal by simulating the users' behavior with various levels of expertise and reliance on Frank's suggestions. The experiments show that Frank's intervention leads to improvements in the accuracy and the fairness of the decisions.", 'abstract_zh': '我们介绍Frank，一个包含人类闭环的系统，用于共生演化混合决策辅助用户从未标记数据集中标注记录。Frank通过在用户的决策过程中并行“演化”，利用增量学习训练可解释的机器学习模型来进行标注。此外，Frank同时提供了不一致性控制、解释、公平性检查和恶意行为防护，超越了现有方法。我们通过模拟不同专业水平和依赖Frank建议程度的用户行为来评估我们的提议。实验表明，Frank的干预提高了决策的准确性和公平性。', 'title_zh': '一种共生演化混合决策系统'}
{'arxiv_id': 'arXiv:2503.06226', 'title': 'Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation', 'authors': 'Kedi Xiea, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu', 'link': 'https://arxiv.org/abs/2503.06226', 'abstract': 'This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.', 'abstract_zh': '基于动态输出反馈学习控制的未知离散时间系统线性二次调节问题研究', 'title_zh': '离散时间线性二次调节的最优输出反馈学习控制'}
{'arxiv_id': 'arXiv:2503.06212', 'title': 'GraphGen+: Advancing Distributed Subgraph Generation and Graph Learning On Industrial Graphs', 'authors': 'Yue Jin, Yongchao Liu, Chuntao Hong', 'link': 'https://arxiv.org/abs/2503.06212', 'abstract': 'Graph-based computations are crucial in a wide range of applications, where graphs can scale to trillions of edges. To enable efficient training on such large graphs, mini-batch subgraph sampling is commonly used, which allows training without loading the entire graph into memory. However, existing solutions face significant trade-offs: online subgraph generation, as seen in frameworks like DGL and PyG, is limited to a single machine, resulting in severe performance bottlenecks, while offline precomputed subgraphs, as in GraphGen, improve sampling efficiency but introduce large storage overhead and high I/O costs during training. To address these challenges, we propose \\textbf{GraphGen+}, an integrated framework that synchronizes distributed subgraph generation with in-memory graph learning, eliminating the need for external storage while significantly improving efficiency. GraphGen+ achieves a \\textbf{27$\\times$} speedup in subgraph generation compared to conventional SQL-like methods and a \\textbf{1.3$\\times$} speedup over GraphGen, supporting training on 1 million nodes per iteration and removing the overhead associated with precomputed subgraphs, making it a scalable and practical solution for industry-scale graph learning.', 'abstract_zh': '基于图的计算在众多应用中至关重要，其中图可以扩展到万亿边的规模。为在如此大的图上进行高效训练，通常使用mini-batch子图采样，这允许在不加载整个图到内存中的情况下进行训练。然而，现有解决方案存在重大权衡：像DGL和PyG这样的框架中的在线子图生成仅限于单台机器，导致严重的性能瓶颈，而GraphGen等预先计算子图的方法提高采样效率但引入了较大的存储开销和高I/O成本。为解决这些挑战，我们提出了一种综合框架GraphGen+，该框架将分布式子图生成与内存中图学习同步，无需外部存储并显著提高效率。GraphGen+在子图生成上的速度比传统SQL-like方法快27倍，比GraphGen快1.3倍，支持每迭代训练100万节点，并消除了预先计算子图的开销，从而提供了一个适用于大规模工业图学习的可扩展和实用的解决方案。', 'title_zh': 'GraphGen+：推动工业图的分布式子图生成与图学习'}
{'arxiv_id': 'arXiv:2503.06211', 'title': 'Text-Speech Language Models with Improved Cross-Modal Transfer by Aligning Abstraction Levels', 'authors': 'Santiago Cuervo, Adel Moumen, Yanis Labrak, Sameer Khurana, Antoine Laurent, Mickael Rouvier, Ricard Marxer', 'link': 'https://arxiv.org/abs/2503.06211', 'abstract': 'Text-Speech Language Models (TSLMs) -- language models trained to jointly process and generate text and speech -- aim to enable cross-modal knowledge transfer to overcome the scaling limitations of unimodal speech LMs. The predominant approach to TSLM training expands the vocabulary of a pre-trained text LM by appending new embeddings and linear projections for speech, followed by fine-tuning on speech data. We hypothesize that this method limits cross-modal transfer by neglecting feature compositionality, preventing text-learned functions from being fully leveraged at appropriate abstraction levels. To address this, we propose augmenting vocabulary expansion with modules that better align abstraction levels across layers. Our models, \\textsc{SmolTolk}, rival or surpass state-of-the-art TSLMs trained with orders of magnitude more compute. Representation analyses and improved multimodal performance suggest our method enhances cross-modal transfer.', 'abstract_zh': 'Text-Speech 语言模型 (TSLMs) -- 旨在联合处理和生成文本与语音的语言模型 -- 力求克服单模态语音语言模型的规模限制，实现跨模态知识的转移。主流的 TSLM 训练方法通过在预训练文本语言模型的词汇表中附加新的语音嵌入和线性投影，并随后在语音数据上进行微调。我们认为这种方法通过忽视特征组合性，限制了文本学习功能在适当抽象层次上的充分利用。为此，我们提议使用更好地对齐各层抽象级别的模块来扩充词汇表。我们的模型 \\textsc{SmolTolk} 在计算量小数量级的情况下，与最先进的 TSLMs 具备相当或更优的表现。代表性和增强的跨模态性能分析表明，我们的方法可以增强跨模态转移。', 'title_zh': '具有改进跨模态转移的文本-语音语言模型通过抽象层次对齐'}
{'arxiv_id': 'arXiv:2503.06208', 'title': 'Distributed Graph Neural Network Inference With Just-In-Time Compilation For Industry-Scale Graphs', 'authors': 'Xiabao Wu, Yongchao Liu, Wei Qin, Chuntao Hong', 'link': 'https://arxiv.org/abs/2503.06208', 'abstract': 'Graph neural networks (GNNs) have delivered remarkable results in various fields. However, the rapid increase in the scale of graph data has introduced significant performance bottlenecks for GNN inference. Both computational complexity and memory usage have risen dramatically, with memory becoming a critical limitation. Although graph sampling-based subgraph learning methods can help mitigate computational and memory demands, they come with drawbacks such as information loss and high redundant computation among subgraphs. This paper introduces an innovative processing paradgim for distributed graph learning that abstracts GNNs with a new set of programming interfaces and leverages Just-In-Time (JIT) compilation technology to its full potential. This paradigm enables GNNs to highly exploit the computational resources of distributed clusters by eliminating the drawbacks of subgraph learning methods, leading to a more efficient inference process. Our experimental results demonstrate that on industry-scale graphs of up to \\textbf{500 million nodes and 22.4 billion edges}, our method can produce a performance boost of up to \\textbf{27.4 times}.', 'abstract_zh': '图神经网络（GNNs）在多个领域取得了 remarkable 的成果。然而，图数据规模的迅速增长为 GNN 推断引入了显著的性能瓶颈。计算复杂度和内存使用量大幅上升，其中内存成为关键的限制因素。尽管基于图采样的子图学习方法可以缓解计算和内存需求，但这些方法存在信息丢失和子图之间高冗余计算的缺点。本文提出了一种创新的分布式图学习处理范式，通过引入一组新的编程接口并充分利用 Just-In-Time (JIT) 编译技术，使 GNN 能够充分利用分布式集群的计算资源，从而避免子图学习方法的缺点，实现更高效的推断过程。实验结果表明，在包含多达 \\textbf{500 million 节点和 22.4 billion 边} 的工业规模图上，我们的方法可以带来高达 \\textbf{27.4 倍} 的性能提升。', 'title_zh': '基于即时编译的分布式图神经网络推理方法及其在工业规模图中的应用'}
{'arxiv_id': 'arXiv:2503.06204', 'title': 'CUPCase: Clinically Uncommon Patient Cases and Diagnoses Dataset', 'authors': 'Oriel Perets, Ofir Ben Shoham, Nir Grinberg, Nadav Rappoport', 'link': 'https://arxiv.org/abs/2503.06204', 'abstract': "Medical benchmark datasets significantly contribute to developing Large Language Models (LLMs) for medical knowledge extraction, diagnosis, summarization, and other uses. Yet, current benchmarks are mainly derived from exam questions given to medical students or cases described in the medical literature, lacking the complexity of real-world patient cases that deviate from classic textbook abstractions. These include rare diseases, uncommon presentations of common diseases, and unexpected treatment responses. Here, we construct Clinically Uncommon Patient Cases and Diagnosis Dataset (CUPCase) based on 3,562 real-world case reports from BMC, including diagnoses in open-ended textual format and as multiple-choice options with distractors. Using this dataset, we evaluate the ability of state-of-the-art LLMs, including both general-purpose and Clinical LLMs, to identify and correctly diagnose a patient case, and test models' performance when only partial information about cases is available. Our findings show that general-purpose GPT-4o attains the best performance in both the multiple-choice task (average accuracy of 87.9%) and the open-ended task (BERTScore F1 of 0.764), outperforming several LLMs with a focus on the medical domain such as Meditron-70B and MedLM-Large. Moreover, GPT-4o was able to maintain 87% and 88% of its performance with only the first 20% of tokens of the case presentation in multiple-choice and free text, respectively, highlighting the potential of LLMs to aid in early diagnosis in real-world cases. CUPCase expands our ability to evaluate LLMs for clinical decision support in an open and reproducible manner.", 'abstract_zh': '临床罕见患者病例和诊断数据集（CUPCase）显著促进了大型语言模型（LLMs）在医学知识提取、诊断、总结以及其它用途的发展。然而，现有的基准主要来源于医学学生的考试题目或文献中描述的病例，缺乏真实世界患者病例的复杂性，这些病例偏离了经典教科书的抽象描述。这些包括罕见疾病、常见疾病的不寻常表现形式以及意料之外的治疗反应。在此基础上，我们构建了基于3,562份真实世界病例报告的临床罕见患者病例和诊断数据集（CUPCase），包括开放文本格式的诊断和多项选择题形式的诊断选项及干扰项。使用该数据集，我们评估了最先进的大型语言模型（包括通用型和临床型）识别和准确诊断患者病例的能力，并测试了在仅有病例部分信息的情况下模型的性能。研究结果表明，通用型GPT-4o在多项选择任务（平均准确率为87.9%）和开放文本任务（BERTScore F1值为0.764）中表现出最佳性能，优于多个专注于医学领域的模型如Meditron-70B和MedLM-Large。此外，GPT-4o在仅使用病例呈现的前20%词元的情况下，多项选择任务和自由文本任务中的性能分别保持在87%和88%，这突显了大型语言模型在实际临床诊断早期辅助中的潜力。CUPCase以开放和可重现的方式扩展了我们评估用于临床决策支持的大型语言模型的能力。', 'title_zh': 'CUPCase: 临床不常见患者病例和诊断数据集'}
{'arxiv_id': 'arXiv:2503.06201', 'title': 'Explainable Synthetic Image Detection through Diffusion Timestep Ensembling', 'authors': 'Yixin Wu, Feiran Zhang, Tianyuan Shi, Ruicheng Yin, Zhenghua Wang, Zhenliang Gan, Xiaohua Wang, Changze Lv, Xiaoqing Zheng, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2503.06201', 'abstract': 'Recent advances in diffusion models have enabled the creation of deceptively real images, posing significant security risks when misused. In this study, we reveal that natural and synthetic images exhibit distinct differences in the high-frequency domains of their Fourier power spectra after undergoing iterative noise perturbations through an inverse multi-step denoising process, suggesting that such noise can provide additional discriminative information for identifying synthetic images. Based on this observation, we propose a novel detection method that amplifies these differences by progressively adding noise to the original images across multiple timesteps, and train an ensemble of classifiers on these noised images. To enhance human comprehension, we introduce an explanation generation and refinement module to identify flaws located in AI-generated images. Additionally, we construct two new datasets, GenHard and GenExplain, derived from the GenImage benchmark, providing detection samples of greater difficulty and high-quality rationales for fake images. Extensive experiments show that our method achieves state-of-the-art performance with 98.91% and 95.89% detection accuracy on regular and harder samples, increasing a minimal of 2.51% and 3.46% compared to baselines. Furthermore, our method also generalizes effectively to images generated by other diffusion models. Our code and datasets will be made publicly available.', 'abstract_zh': 'Recent advances in扩散模型的进展使得生成具有欺骗性的逼真图像成为可能，当这些图像被误用时会引发重大安全风险。在本研究中，我们揭示了经过迭代去噪过程中的多步逆向噪声扰动后，自然图像和合成图像在傅里叶功率谱的高频域中表现出明显的差异，表明这种噪声可以提供额外的判别信息以识别合成图像。基于这一观察，我们提出了一种新的检测方法，通过在多个时间步逐步向原始图像添加噪声来放大这些差异，并在这些被噪声增强的图像上训练集成分类器。为了增强人类的可理解性，我们引入了一个解释生成和精炼模块，用于识别AI生成图像中的缺陷。此外，我们构建了两个新的数据集，GenHard和GenExplain，源自GenImage基准，提供了更具难度的检测样本和高质量的假图像理由。广泛实验证明，我们的方法在常规样本和更难样本上的检测准确率分别达到98.91%和95.89%，相较于基线方法分别提升了至少2.51%和3.46%。此外，我们的方法还能够有效泛化到其他扩散模型生成的图像。我们的代码和数据集将公开发布。', 'title_zh': '可解释的合成图像检测通过扩散时间步长集成'}
{'arxiv_id': 'arXiv:2503.06195', 'title': 'Human-AI Experience in Integrated Development Environments: A Systematic Literature Review', 'authors': 'Agnia Sergeyuk, Ilya Zakharov, Ekaterina Koshchenko, Maliheh Izadi', 'link': 'https://arxiv.org/abs/2503.06195', 'abstract': 'The integration of Artificial Intelligence (AI) into Integrated Development Environments (IDEs) is reshaping software development, fundamentally altering how developers interact with their tools. This shift marks the emergence of Human-AI Experience in Integrated Development Environment (in-IDE HAX), a field that explores the evolving dynamics of Human-Computer Interaction in AI-assisted coding environments. Despite rapid adoption, research on in-IDE HAX remains fragmented which highlights the need for a unified overview of current practices, challenges, and opportunities. To provide a structured overview of existing research, we conduct a systematic literature review of 89 studies, summarizing current findings and outlining areas for further investigation.\nOur findings reveal that AI-assisted coding enhances developer productivity but also introduces challenges, such as verification overhead, automation bias, and over-reliance, particularly among novice developers. Furthermore, concerns about code correctness, security, and maintainability highlight the urgent need for explainability, verification mechanisms, and adaptive user control. Although recent advances have driven the field forward, significant research gaps remain, including a lack of longitudinal studies, personalization strategies, and AI governance frameworks. This review provides a foundation for advancing in-IDE HAX research and offers guidance for responsibly integrating AI into software development.', 'abstract_zh': 'AI融入集成开发环境中的集成开发环境内人机体验（in-IDE HAX）：现状、挑战与机遇', 'title_zh': '集成开发环境中的人类-人工智能体验：一项系统文献综述'}
{'arxiv_id': 'arXiv:2503.06187', 'title': 'MSConv: Multiplicative and Subtractive Convolution for Face Recognition', 'authors': 'Si Zhou, Yain-Whar Si, Xiaochen Yuan, Xiaofan Li, Xiaoxiang Liu, Xinyuan Zhang, Cong Lin, Xueyuan Gong', 'link': 'https://arxiv.org/abs/2503.06187', 'abstract': 'In Neural Networks, there are various methods of feature fusion. Different strategies can significantly affect the effectiveness of feature representation, consequently influencing the ability of model to extract representative and discriminative features. In the field of face recognition, traditional feature fusion methods include feature concatenation and feature addition. Recently, various attention mechanism-based fusion strategies have emerged. However, we found that these methods primarily focus on the important features in the image, referred to as salient features in this paper, while neglecting another equally important set of features for image recognition tasks, which we term differential features. This may cause the model to overlook critical local differences when dealing with complex facial samples. Therefore, in this paper, we propose an efficient convolution module called MSConv (Multiplicative and Subtractive Convolution), designed to balance the learning of model about salient and differential features. Specifically, we employ multi-scale mixed convolution to capture both local and broader contextual information from face images, and then utilize Multiplication Operation (MO) and Subtraction Operation (SO) to extract salient and differential features, respectively. Experimental results demonstrate that by integrating both salient and differential features, MSConv outperforms models that only focus on salient features.', 'abstract_zh': '在神经网络中，存在多种特征融合方法。不同的策略会显著影响特征表示的有效性，进而影响模型提取有代表性和判别性特征的能力。在人脸识别领域，传统的特征融合方法包括特征连接和特征相加。近年来，基于注意力机制的融合策略已层出不穷。然而，我们发现这些方法主要关注图像中的重要特征，即本文中称为显著特征的部分，而忽视了另一组对图像识别任务同样重要的特征，我们称之为差异特征。这可能导致模型在处理复杂面部样本时忽略关键的局部差异。因此，在本文中，我们提出了一种高效卷积模块——MSConv（乘法和减法卷积），以平衡模型对显著特征和差异特征的学习。具体而言，我们采用多尺度混合卷积从面部图像中捕获局部和更广泛的上下文信息，然后利用乘法操作（MO）和减法操作（SO）分别提取显著特征和差异特征。实验结果表明，通过结合显著特征和差异特征，MSConv优于仅关注显著特征的模型。', 'title_zh': 'MSConv：乘法和减法卷积在面部识别中的应用'}
{'arxiv_id': 'arXiv:2503.06184', 'title': 'Sample-aware Adaptive Structured Pruning for Large Language Models', 'authors': 'Jun Kong, Xinge Ma, Jin Wang, Xuejie Zhang', 'link': 'https://arxiv.org/abs/2503.06184', 'abstract': 'Large language models (LLMs) have achieved outstanding performance in natural language processing, but enormous model sizes and high computational costs limit their practical deployment. Structured pruning can effectively reduce the resource demands for deployment by removing redundant model parameters. However, the randomly selected calibration data and fixed single importance estimation metrics in existing structured pruning methods lead to degraded performance of pruned models. This study introduces AdaPruner, a sample-aware adaptive structured pruning framework for LLMs, aiming to optimize the calibration data and importance estimation metrics in the structured pruning process. Specifically, AdaPruner effectively removes redundant parameters from LLMs by constructing a structured pruning solution space and then employing Bayesian optimization to adaptively search for the optimal calibration data and importance estimation metrics. Experimental results show that the AdaPruner outperforms existing structured pruning methods on a family of LLMs with varying pruning ratios, demonstrating its applicability and robustness. Remarkably, at a 20\\% pruning ratio, the model pruned with AdaPruner maintains 97\\% of the performance of the unpruned model.', 'abstract_zh': 'Large语言模型（LLMs）在自然语言处理领域取得了出色 performance，但巨大的模型规模和高昂的计算成本限制了其实际部署。结构化剪枝可以通过移除冗余模型参数来有效降低部署所需的资源需求。然而，现有结构化剪枝方法中随机选择的校准数据和固定的单一重要性评估指标导致剪枝模型性能下降。本研究引入了AdaPruner，一种样本感知的自适应结构化剪枝框架，旨在优化结构化剪枝过程中的校准数据和重要性评估指标。具体而言，AdaPruner通过构建结构化剪枝解空间，结合贝叶斯优化自适应搜索最优校准数据和重要性评估指标，有效地从LLMs中移除了冗余参数。实验结果表明，AdaPruner在不同剪枝比例的LLMs家族中优于现有结构化剪枝方法，展示了其适用性和鲁棒性。特别地，在20%的剪枝比例下，使用AdaPruner剪枝的模型保持了97%的未剪枝模型的 performance。', 'title_zh': '面向样本的自适应结构剪枝方法及其在大型语言模型中的应用'}
{'arxiv_id': 'arXiv:2503.06183', 'title': 'Lightweight Software Kernels and Hardware Extensions for Efficient Sparse Deep Neural Networks on Microcontrollers', 'authors': 'Francesco Daghero, Daniele Jahier Pagliari, Francesco Conti, Luca Benini, Massimo Poncino, Alessio Burrello', 'link': 'https://arxiv.org/abs/2503.06183', 'abstract': 'The acceleration of pruned Deep Neural Networks (DNNs) on edge devices such as Microcontrollers (MCUs) is a challenging task, given the tight area- and power-constraints of these devices. In this work, we propose a three-fold contribution to address this problem. First, we design a set of optimized software kernels for N:M pruned layers, targeting ultra-low-power, multicore RISC-V MCUs, which are up to 2.1x and 3.4x faster than their dense counterparts at 1:8 and 1:16 sparsity, respectively. Then, we implement a lightweight Instruction-Set Architecture (ISA) extension to accelerate the indirect load and non-zero indices decompression operations required by our kernels, obtaining up to 1.9x extra speedup, at the cost of a 5% area overhead. Lastly, we extend an open-source DNN compiler to utilize our sparse kernels for complete networks, showing speedups of 3.21x and 1.81x on a ResNet18 and a Vision Transformer (ViT), with less than 1.5% accuracy drop compared to a dense baseline.', 'abstract_zh': '针对边缘设备如微控制器（MCUs）上剪枝深度神经网络（DNNs）的加速是一个具有挑战性的问题，鉴于这些设备面积和功率限制紧凑。本文提出了三个方面的贡献来解决这一问题。首先，我们为N:M剪枝层设计了一组优化软件内核，目标是超低功耗多核RISC-V微控制器，在稀疏度分别为1:8和1:16的情况下，内核分别比其密集对应版本快2.1倍和3.4倍。其次，我们实现了一个轻量级指令集架构（ISA）扩展以加速我们的内核所需的数据间接加载和非零索引解压缩操作，额外获得了1.9倍的速度提升，成本仅为5%的面积开销。最后，我们将一个开源DNN编译器扩展为利用我们的稀疏内核来优化整个网络，在ResNet18和Vision Transformer（ViT）上分别获得了3.21倍和1.81倍的速度提升，与密集基线相比准确率降低不到1.5%。', 'title_zh': '轻量级软件内核和硬件扩展以提高Micro控制器上稀疏深度神经网络的效率'}
{'arxiv_id': 'arXiv:2503.06175', 'title': 'Minion Gated Recurrent Unit for Continual Learning', 'authors': 'Abdullah M. Zyarah, Dhireesha Kudithipudi', 'link': 'https://arxiv.org/abs/2503.06175', 'abstract': 'The increasing demand for continual learning in sequential data processing has led to progressively complex training methodologies and larger recurrent network architectures. Consequently, this has widened the knowledge gap between continual learning with recurrent neural networks (RNNs) and their ability to operate on devices with limited memory and compute. To address this challenge, we investigate the effectiveness of simplifying RNN architectures, particularly gated recurrent unit (GRU), and its impact on both single-task and multitask sequential learning. We propose a new variant of GRU, namely the minion recurrent unit (MiRU). MiRU replaces conventional gating mechanisms with scaling coefficients to regulate dynamic updates of hidden states and historical context, reducing computational costs and memory requirements. Despite its simplified architecture, MiRU maintains performance comparable to the standard GRU while achieving 2.90x faster training and reducing parameter usage by 2.88x, as demonstrated through evaluations on sequential image classification and natural language processing benchmarks. The impact of model simplification on its learning capacity is also investigated by performing continual learning tasks with a rehearsal-based strategy and global inhibition. We find that MiRU demonstrates stable performance in multitask learning even when using only rehearsal, unlike the standard GRU and its variants. These features position MiRU as a promising candidate for edge-device applications.', 'abstract_zh': '持续学习在序列数据处理中日益增长的需求推动了日益复杂的训练方法和更大规模的循环网络架构。这导致了使用循环神经网络（RNN）进行持续学习与它们在有限内存和计算能力设备上的操作能力之间的知识差距不断扩大。为了解决这一挑战，我们研究了简化RNN架构的有效性，特别是门控循环单元（GRU），及其对单任务和多任务序列学习的影响。我们提出了一种新的GRU变体，即门徒循环单元（MiRU）。MiRU通过使用缩放系数替代传统的门控机制来调节隐藏状态和历史上下文的动态更新，从而降低计算成本和内存需求。尽管具有简化架构，MiRU在序列图像分类和自然语言处理基准测试中仍能保持与标准GRU相当的性能，同时训练速度提高2.90倍，参数使用量减少2.88倍。通过使用基于复查的策略和全局抑制进行持续学习任务，我们还探讨了模型简化对学习能力的影响。我们发现，即使仅使用复查，MiRU在多任务学习中的性能也表现出稳定的表现，与标准GRU及其变体不同。这些特征使MiRU成为边缘设备应用的有前途的候选者。', 'title_zh': 'Minion门控循环单元 for 连续学习'}
{'arxiv_id': 'arXiv:2503.06171', 'title': 'ROCM: RLHF on consistency models', 'authors': 'Shivanshu Shekhar, Tong Zhang', 'link': 'https://arxiv.org/abs/2503.06171', 'abstract': 'Diffusion models have revolutionized generative modeling in continuous domains like image, audio, and video synthesis. However, their iterative sampling process leads to slow generation and inefficient training, challenges that are further exacerbated when incorporating Reinforcement Learning from Human Feedback (RLHF) due to sparse rewards and long time horizons. Consistency models address these issues by enabling single-step or efficient multi-step generation, significantly reducing computational costs.\nIn this work, we propose a direct reward optimization framework for applying RLHF to consistency models, incorporating distributional regularization to enhance training stability and prevent reward hacking. We investigate various $f$-divergences as regularization strategies, striking a balance between reward maximization and model consistency. Unlike policy gradient methods, our approach leverages first-order gradients, making it more efficient and less sensitive to hyperparameter tuning. Empirical results show that our method achieves competitive or superior performance compared to policy gradient based RLHF methods, across various automatic metrics and human evaluation. Additionally, our analysis demonstrates the impact of different regularization techniques in improving model generalization and preventing overfitting.', 'abstract_zh': '扩散模型在图像、音频和视频合成等连续域中的生成建模中取得了革命性进展。然而，其迭代采样过程导致生成速度慢和训练效率低，而在结合人类反馈强化学习（RLHF）时，由于稀疏奖励和长时间 horizon，这些问题进一步加剧。一致性模型通过启用单步或多步生成来解决这些问题，显著降低了计算成本。\n在本工作中，我们提出了一种直接的奖励优化框架，将 RLHF 应用于一致性模型，并引入分布正则化以提高训练稳定性并防止奖励作弊。我们研究了不同类型的 $f$-散度作为正则化策略，以平衡奖励最大化和模型一致性。与策略梯度方法不同，我们的方法利用一阶梯度，使其更有效且对超参数调整的敏感度较低。实验结果表明，我们的方法在各种自动评价指标和人工评估中与基于策略梯度的 RLHF 方法相比表现相当或更优。此外，我们的分析还展示了不同正则化技术对模型泛化能力和防止过拟合的影响。', 'title_zh': 'ROCM: 一致性模型上的RLHF'}
{'arxiv_id': 'arXiv:2503.06169', 'title': 'Treble Counterfactual VLMs: A Causal Approach to Hallucination', 'authors': 'Li Li, Jiashu Qu, Yuxiao Zhou, Yuehan Qin, Tiankai Yang, Yue Zhao', 'link': 'https://arxiv.org/abs/2503.06169', 'abstract': "Vision-Language Models (VLMs) have advanced multi-modal tasks like image captioning, visual question answering, and reasoning. However, they often generate hallucinated outputs inconsistent with the visual context or prompt, limiting reliability in critical applications like autonomous driving and medical imaging. Existing studies link hallucination to statistical biases, language priors, and biased feature learning but lack a structured causal understanding. In this work, we introduce a causal perspective to analyze and mitigate hallucination in VLMs. We hypothesize that hallucination arises from unintended direct influences of either the vision or text modality, bypassing proper multi-modal fusion. To address this, we construct a causal graph for VLMs and employ counterfactual analysis to estimate the Natural Direct Effect (NDE) of vision, text, and their cross-modal interaction on the output. We systematically identify and mitigate these unintended direct effects to ensure that responses are primarily driven by genuine multi-modal fusion. Our approach consists of three steps: (1) designing structural causal graphs to distinguish correct fusion pathways from spurious modality shortcuts, (2) estimating modality-specific and cross-modal NDE using perturbed image representations, hallucinated text embeddings, and degraded visual inputs, and (3) implementing a test-time intervention module to dynamically adjust the model's dependence on each modality. Experimental results demonstrate that our method significantly reduces hallucination while preserving task performance, providing a robust and interpretable framework for improving VLM reliability. To enhance accessibility and reproducibility, our code is publicly available at this https URL.", 'abstract_zh': 'Vision-Language 模型（VLMs）在图像字幕、视觉问答和推理等多模态任务上取得了进展。然而，它们经常生成与视觉上下文或提示不符的虚构输出，限制了在自动驾驶和医疗成像等关键应用中的可靠性。现有研究将虚构现象与统计偏差、语言先验和特征学习偏差联系起来，但缺乏结构化的因果理解。在本文中，我们引入因果视角来分析和减轻 VLMs 中的虚构现象。我们假设虚构现象源于视觉或文本模态的非预期直接影响，绕过了合理的多模态融合。为了解决这一问题，我们构建了 VLMs 的因果图，并采用反事实分析来估计视觉、文本及其跨模态交互对输出的自然直接效应（NDE）。我们系统地识别并减轻这些非预期的直接效应，以确保响应主要由真实的多模态融合驱动。我们的方法包括三个步骤：（1）设计结构化因果图以区分正确的融合路径和虚假的模态捷径，（2）使用扰动图像表示、虚构文本嵌入和退化视觉输入估计模态特异性和跨模态的 NDE，（3）实现一个测试时干预模块以动态调整模型对每种模态的依赖性。实验结果表明，我们的方法显著减少了虚构现象的同时保持了任务性能，提供了一个稳健且可解释的框架来提高 VLM 的可靠性。为了增强可访问性和可再现性，我们的代码已在此 <https://> 公开可用。', 'title_zh': '三倍因果VLMs：一种因果分析幻觉的方法'}
{'arxiv_id': 'arXiv:2503.06166', 'title': 'Secure On-Device Video OOD Detection Without Backpropagation', 'authors': 'Li Li, Peilin Cai, Yuxiao Zhou, Zhiyu Ni, Renjie Liang, You Qin, Yi Nian, Zhengzhong Tu, Xiyang Hu, Yue Zhao', 'link': 'https://arxiv.org/abs/2503.06166', 'abstract': 'Out-of-Distribution (OOD) detection is critical for ensuring the reliability of machine learning models in safety-critical applications such as autonomous driving and medical diagnosis. While deploying personalized OOD detection directly on edge devices is desirable, it remains challenging due to large model sizes and the computational infeasibility of on-device training. Federated learning partially addresses this but still requires gradient computation and backpropagation, exceeding the capabilities of many edge devices. To overcome these challenges, we propose SecDOOD, a secure cloud-device collaboration framework for efficient on-device OOD detection without requiring device-side backpropagation. SecDOOD utilizes cloud resources for model training while ensuring user data privacy by retaining sensitive information on-device. Central to SecDOOD is a HyperNetwork-based personalized parameter generation module, which adapts cloud-trained models to device-specific distributions by dynamically generating local weight adjustments, effectively combining central and local information without local fine-tuning. Additionally, our dynamic feature sampling and encryption strategy selectively encrypts only the most informative feature channels, largely reducing encryption overhead without compromising detection performance. Extensive experiments across multiple datasets and OOD scenarios demonstrate that SecDOOD achieves performance comparable to fully fine-tuned models, enabling secure, efficient, and personalized OOD detection on resource-limited edge devices. To enhance accessibility and reproducibility, our code is publicly available at this https URL.', 'abstract_zh': '基于安全云-设备协作的高效本地OOD检测框架SecDOOD', 'title_zh': '设备端无反向传播的 Secure 在设备上视频 OOD 检测'}
{'arxiv_id': 'arXiv:2503.06161', 'title': 'Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction', 'authors': 'Kai Li, Junhao Wang, William Han, Ding Zhao', 'link': 'https://arxiv.org/abs/2503.06161', 'abstract': 'Minimally invasive surgery (MIS) has transformed clinical practice by reducing recovery times, minimizing complications, and enhancing precision. Nonetheless, MIS inherently relies on indirect visualization and precise instrument control, posing unique challenges. Recent advances in artificial intelligence have enabled real-time surgical scene understanding through techniques such as image classification, object detection, and segmentation, with scene reconstruction emerging as a key element for enhanced intraoperative guidance. Although neural radiance fields (NeRFs) have been explored for this purpose, their substantial data requirements and slow rendering inhibit real-time performance. In contrast, 3D Gaussian Splatting (3DGS) offers a more efficient alternative, achieving state-of-the-art performance in dynamic surgical scene reconstruction. In this work, we introduce Feature-EndoGaussian (FEG), an extension of 3DGS that integrates 2D segmentation cues into 3D rendering to enable real-time semantic and scene reconstruction. By leveraging pretrained segmentation foundation models, FEG incorporates semantic feature distillation within the Gaussian deformation framework, thereby enhancing both reconstruction fidelity and segmentation accuracy. On the EndoNeRF dataset, FEG achieves superior performance (SSIM of 0.97, PSNR of 39.08, and LPIPS of 0.03) compared to leading methods. Additionally, on the EndoVis18 dataset, FEG demonstrates competitive class-wise segmentation metrics while balancing model size and real-time performance.', 'abstract_zh': '微创手术(MIS)通过缩短恢复时间、减少并发症和提高精确度已经革新了临床实践。尽管如此，MIS本质上依赖于间接可视化和精确的仪器控制，带来了独特的挑战。近期的人工智能进展通过图像分类、对象检测和分割等技术实现了手术现场的实时理解，并且场景重建成为增强术中指导的关键元素。虽然神经辐射场(NeRF)已经被探索用于这一目的，但由于其巨大的数据需求和缓慢的渲染速度，它们抑制了实时性能。相比之下，3D高斯点积(3DGS)提供了一种更高效的替代方案，在动态手术场景重建中达到了最先进的性能。在此项工作中，我们引入了特征-内镜高斯(FEG)这一3DGS的扩展，它将2D分割线索整合到3D渲染中，以实现实时语义和场景重建。通过利用预训练的分割基础模型，FEG在高斯变形框架中整合了语义特征蒸馏，从而增强了重建保真度和分割准确性。在EndoNeRF数据集上，与领先方法相比，FEG取得了优越的性能(结构相似性SSIM为0.97，峰值信噪比PSNR为39.08，和感知保真度LPIPS为0.03)。此外，在EndoVis18数据集上，FEG展示了具有竞争力的类别级分割指标，同时平衡了模型大小和实时性能。', 'title_zh': '特征-内加性高斯：手术变形场景重构中的特征提取高斯散射'}
{'arxiv_id': 'arXiv:2503.06157', 'title': 'UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces', 'authors': 'Baining Zhao, Jianjie Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang, Jinqiang Cui, Xinlei Chen, Yong Li', 'link': 'https://arxiv.org/abs/2503.06157', 'abstract': 'Large multimodal models exhibit remarkable intelligence, yet their embodied cognitive abilities during motion in open-ended urban 3D space remain to be explored. We introduce a benchmark to evaluate whether video-large language models (Video-LLMs) can naturally process continuous first-person visual observations like humans, enabling recall, perception, reasoning, and navigation. We have manually control drones to collect 3D embodied motion video data from real-world cities and simulated environments, resulting in 1.5k video clips. Then we design a pipeline to generate 5.2k multiple-choice questions. Evaluations of 17 widely-used Video-LLMs reveal current limitations in urban embodied cognition. Correlation analysis provides insight into the relationships between different tasks, showing that causal reasoning has a strong correlation with recall, perception, and navigation, while the abilities for counterfactual and associative reasoning exhibit lower correlation with other tasks. We also validate the potential for Sim-to-Real transfer in urban embodiment through fine-tuning.', 'abstract_zh': '大型多模态模型表现出显著的智能，但在开放的城市3D空间中运动过程中的体现认知能力仍有待探索。我们引入了一个基准来评估视频大规模语言模型（Video-LLMs）是否能自然处理连续的第一人称视觉观察，如同人类一般，实现回忆、感知、推理和导航。我们手动操控无人机，从真实城市和模拟环境中收集了3D沉浸式运动视频数据，总共得到1500个视频片段。然后我们设计了一个流水线生成了5200个多项选择题。对17种广泛使用的Video-LLMs的评估揭示了当前在城市体现认知方面的局限性。相关性分析揭示了不同任务之间的关系，表明因果推理与回忆、感知和导航之间存在强烈的相关性，而反事实推理和关联推理的能力与其它任务的相关性较低。我们还通过微调验证了城市体现中的模拟到现实迁移的潜力。', 'title_zh': 'UrbanVideo-Bench: 城市空间视频数据在体态智能中的视觉-语言模型评估基准'}
{'arxiv_id': 'arXiv:2503.06144', 'title': 'Exploring the usage of Probabilistic Neural Networks for Ionospheric electron density estimation', 'authors': 'Miquel Garcia-Fernandez', 'link': 'https://arxiv.org/abs/2503.06144', 'abstract': "A fundamental limitation of traditional Neural Networks (NN) in predictive modelling is their inability to quantify uncertainty in their outputs. In critical applications like positioning systems, understanding the reliability of predictions is critical for constructing confidence intervals, early warning systems, and effectively propagating results. For instance, Precise Point Positioning in satellite navigation heavily relies on accurate error models for ancillary data (orbits, clocks, ionosphere, and troposphere) to compute precise error estimates. In addition, these uncertainty estimates are needed to establish robust protection levels in safety critical applications.\nTo address this challenge, the main objectives of this paper aims at exploring a potential framework capable of providing both point estimates and associated uncertainty measures of ionospheric Vertical Total Electron Content (VTEC). In this context, Probabilistic Neural Networks (PNNs) offer a promising approach to achieve this goal. However, constructing an effective PNN requires meticulous design of hidden and output layers, as well as careful definition of prior and posterior probability distributions for network weights and biases.\nA key finding of this study is that the uncertainty provided by the PNN model in VTEC estimates may be systematically underestimated. In low-latitude areas, the actual error was observed to be as much as twice the model's estimate. This underestimation is expected to be more pronounced during solar maximum, correlating with increased VTEC values.", 'abstract_zh': '传统神经网络在预测建模中的一个基本局限性是它们无法量化输出的不确定性。在像定位系统这样关键的应用中，理解预测的可靠性对于构建置信区间、早期预警系统和有效传播结果至关重要。例如，卫星导航中的精确点定位严重依赖于辅助数据（轨道、时钟、电离层和对流层）的精确错误模型以计算精确的误差估计。此外，在关键安全应用中，这些不确定性估计是建立稳健防护水平所必需的。\n\n为了应对这一挑战，本文的主要目标是探索一种潜在框架，该框架能够提供电离层垂直总电子含量（VTEC）的点估计及其相关不确定性度量。在此背景下，概率神经网络（PNNs）提供了一种实现这一目标的有前景的方法。然而，构建有效的PNN需要精细设计隐藏层和输出层，并仔细定义网络权重和偏置的先验和后验概率分布。\n\n本研究的一个重要发现是，PNN模型提供的VTEC估计的不确定性可能系统性地被低估。在低纬度地区，实际误差观察到的值可能是模型估计值的两倍。这种低估在太阳极大期更为明显，与VTEC值的增加相关。', 'title_zh': '探究概率神经网络在电离层电子密度估计中的应用'}
{'arxiv_id': 'arXiv:2503.06136', 'title': 'GSV3D: Gaussian Splatting-based Geometric Distillation with Stable Video Diffusion for Single-Image 3D Object Generation', 'authors': 'Ye Tao, Jiawei Zhang, Yahao Shi, Dongqing Zou, Bin Zhou', 'link': 'https://arxiv.org/abs/2503.06136', 'abstract': "Image-based 3D generation has vast applications in robotics and gaming, where high-quality, diverse outputs and consistent 3D representations are crucial. However, existing methods have limitations: 3D diffusion models are limited by dataset scarcity and the absence of strong pre-trained priors, while 2D diffusion-based approaches struggle with geometric consistency. We propose a method that leverages 2D diffusion models' implicit 3D reasoning ability while ensuring 3D consistency via Gaussian-splatting-based geometric distillation. Specifically, the proposed Gaussian Splatting Decoder enforces 3D consistency by transforming SV3D latent outputs into an explicit 3D representation. Unlike SV3D, which only relies on implicit 2D representations for video generation, Gaussian Splatting explicitly encodes spatial and appearance attributes, enabling multi-view consistency through geometric constraints. These constraints correct view inconsistencies, ensuring robust geometric consistency. As a result, our approach simultaneously generates high-quality, multi-view-consistent images and accurate 3D models, providing a scalable solution for single-image-based 3D generation and bridging the gap between 2D Diffusion diversity and 3D structural coherence. Experimental results demonstrate state-of-the-art multi-view consistency and strong generalization across diverse datasets. The code will be made publicly available upon acceptance.", 'abstract_zh': '基于图像的3D生成在机器人学和游戏领域具有广泛的应用，高质量、多样化的输出和一致的3D表示至关重要。然而，现有方法存在局限性：3D扩散模型受限于数据集稀缺性和强先验知识的缺失，而基于2D扩散的方法则在几何一致性上遇到困难。我们提出了一种方法，利用2D扩散模型的隐式3D推理能力，并通过高斯斑点化几何精炼确保3D一致性。具体来说，所提出的高斯斑点化解码器通过将SV3D潜在输出转换为显式的3D表示来强制3D一致性。与仅依赖隐式2D表示生成视频的SV3D不同，高斯斑点化明确地编码了空间和外观属性，通过几何约束来实现多视角一致性。这些约束纠正了视角不一致性，确保了几何一致性的鲁棒性。因此，我们的方法同时生成高质量、多视角一致的图像和准确的3D模型，为基于单张图像的3D生成提供了可扩展的解决方案，并在2D扩散多样性与3D结构一致性之间架起桥梁。实验结果表明，我们方法的多视角一致性处于先进水平，并且在多种数据集上具有较强的泛化能力。代码将在接受后公开。', 'title_zh': 'GSV3D：基于高斯点云的几何精炼方法与稳定视频扩散在单张图像三维物体生成中的应用'}
{'arxiv_id': 'arXiv:2503.06108', 'title': 'Multi-modal expressive personality recognition in data non-ideal audiovisual based on multi-scale feature enhancement and modal augment', 'authors': 'Weixuan Kong, Jinpeng Yu, Zijun Li, Hanwei Liu, Jiqing Qu, Hui Xiao, Xuefeng Li', 'link': 'https://arxiv.org/abs/2503.06108', 'abstract': "Automatic personality recognition is a research hotspot in the intersection of computer science and psychology, and in human-computer interaction, personalised has a wide range of applications services and other scenarios. In this paper, an end-to-end multimodal performance personality is established for both visual and auditory modal datarecognition network , and the through feature-level fusion , which effectively of the two modalities is carried out the cross-attention mechanismfuses the features of the two modal data; and a is proposed multiscale feature enhancement modalitiesmodule , which enhances for visual and auditory boththe expression of the information of effective the features and suppresses the interference of the redundant information. In addition, during the training process, this paper proposes a modal enhancement training strategy to simulate non-ideal such as modal loss and noise interferencedata situations , which enhances the adaptability ofand the model to non-ideal data scenarios improves the robustness of the model. Experimental results show that the method proposed in this paper is able to achieve an average Big Five personality accuracy of , which outperforms existing 0.916 on the personality analysis dataset ChaLearn First Impressionother methods based on audiovisual and audio-visual both modalities. The ablation experiments also validate our proposed , respectivelythe contribution of module and modality enhancement strategy to the model performance. Finally, we simulate in the inference phase multi-scale feature enhancement six non-ideal data scenarios to verify the modal enhancement strategy's improvement in model robustness.", 'abstract_zh': '自动人格识别是计算机科学与心理学交叉领域以及人机交互中的研究热点，个性化服务等场景具有广泛的应用。本文建立了一个端到端的多模态性能人格识别网络，通过特征级融合，利用交叉注意力机制有效融合视听模态特征，并提出了一种多尺度特征增强模块，增强视听模态的有效信息表达并抑制冗余信息干扰。此外，在训练过程中，本文提出了一种模态增强训练策略，模拟诸如模态失真和噪声干扰等非理想情况，提高模型对非理想数据场景的适应性和鲁棒性。实验结果表明，本文提出的方法在ChaLearn First Impression人格分析数据集上实现了平均五大人格特质识别准确率为0.916，优于基于视听和音视频模态的其他方法。消融实验进一步验证了所提出的模块和模态增强策略对模型性能的贡献。最后，在推理阶段模拟六种非理想数据场景，验证模态增强策略对模型鲁棒性的提升。', 'title_zh': '基于多尺度特征增强和模态扩增的非理想音频视觉数据多模态表达性个性识别'}
{'arxiv_id': 'arXiv:2503.06107', 'title': 'Feature Fusion Attention Network with CycleGAN for Image Dehazing, De-Snowing and De-Raining', 'authors': 'Akshat Jain', 'link': 'https://arxiv.org/abs/2503.06107', 'abstract': 'This paper presents a novel approach to image dehazing by combining Feature Fusion Attention (FFA) networks with CycleGAN architecture. Our method leverages both supervised and unsupervised learning techniques to effectively remove haze from images while preserving crucial image details. The proposed hybrid architecture demonstrates significant improvements in image quality metrics, achieving superior PSNR and SSIM scores compared to traditional dehazing methods. Through extensive experimentation on the RESIDE and DenseHaze CVPR 2019 dataset, we show that our approach effectively handles both synthetic and real-world hazy images. CycleGAN handles the unpaired nature of hazy and clean images effectively, enabling the model to learn mappings even without paired data.', 'abstract_zh': '基于Feature Fusion Attention网络与CycleGAN架构的图像去雾新型方法', 'title_zh': '基于CycleGAN的特征融合注意力网络用于去雾、除雪和去雨'}
{'arxiv_id': 'arXiv:2503.06101', 'title': 'ULTHO: Ultra-Lightweight yet Efficient Hyperparameter Optimization in Deep Reinforcement Learning', 'authors': 'Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng', 'link': 'https://arxiv.org/abs/2503.06101', 'abstract': 'Hyperparameter optimization (HPO) is a billion-dollar problem in machine learning, which significantly impacts the training efficiency and model performance. However, achieving efficient and robust HPO in deep reinforcement learning (RL) is consistently challenging due to its high non-stationarity and computational cost. To tackle this problem, existing approaches attempt to adapt common HPO techniques (e.g., population-based training or Bayesian optimization) to the RL scenario. However, they remain sample-inefficient and computationally expensive, which cannot facilitate a wide range of applications. In this paper, we propose ULTHO, an ultra-lightweight yet powerful framework for fast HPO in deep RL within single runs. Specifically, we formulate the HPO process as a multi-armed bandit with clustered arms (MABC) and link it directly to long-term return optimization. ULTHO also provides a quantified and statistical perspective to filter the HPs efficiently. We test ULTHO on benchmarks including ALE, Procgen, MiniGrid, and PyBullet. Extensive experiments demonstrate that the ULTHO can achieve superior performance with simple architecture, contributing to the development of advanced and automated RL systems.', 'abstract_zh': '深度强化学习中的超参数优化：ULTHO——一种轻量而强大的单次运行快速超参数优化框架', 'title_zh': 'ULTHO: 超轻量且高效的深度强化学习超参数优化'}
{'arxiv_id': 'arXiv:2503.06092', 'title': 'ZO-DARTS++: An Efficient and Size-Variable Zeroth-Order Neural Architecture Search Algorithm', 'authors': 'Lunchen Xie, Eugenio Lomurno, Matteo Gambella, Danilo Ardagna, Manual Roveri, Matteo Matteucci, Qingjiang Shi', 'link': 'https://arxiv.org/abs/2503.06092', 'abstract': 'Differentiable Neural Architecture Search (NAS) provides a promising avenue for automating the complex design of deep learning (DL) models. However, current differentiable NAS methods often face constraints in efficiency, operation selection, and adaptability under varying resource limitations. We introduce ZO-DARTS++, a novel NAS method that effectively balances performance and resource constraints. By integrating a zeroth-order approximation for efficient gradient handling, employing a sparsemax function with temperature annealing for clearer and more interpretable architecture distributions, and adopting a size-variable search scheme for generating compact yet accurate architectures, ZO-DARTS++ establishes a new balance between model complexity and performance. In extensive tests on medical imaging datasets, ZO-DARTS++ improves the average accuracy by up to 1.8\\% over standard DARTS-based methods and shortens search time by approximately 38.6\\%. Additionally, its resource-constrained variants can reduce the number of parameters by more than 35\\% while maintaining competitive accuracy levels. Thus, ZO-DARTS++ offers a versatile and efficient framework for generating high-quality, resource-aware DL models suitable for real-world medical applications.', 'abstract_zh': '不同的神经架构搜索（NAS）为自动化深度学习（DL）模型的复杂设计提供了有希望的途径。然而，当前的可微分NAS方法在效率、操作选择和适应不同资源限制方面经常面临挑战。我们引入ZO-DARTS++，这是一种有效平衡性能与资源约束的新NAS方法。通过整合零阶近似以提高梯度处理效率，采用带有温度退火的sparsemax函数以获得更清晰和可解释的架构分布，并采用可变大小的搜索方案以生成紧凑而准确的架构，ZO-DARTS++在模型复杂性和性能之间建立了一个新的平衡。在广泛的医疗成像数据集测试中，ZO-DARTS++的平均准确性比基于标准DARTS的方法提高了1.8%，搜索时间缩短约38.6%。此外，其资源受限变体可以在参数数量减少超过35%的同时保持竞争力的准确性水平。因此，ZO-DARTS++提供了一个适用于实际医疗应用的多功能和高效框架，用于生成高质量的资源感知DL模型。', 'title_zh': 'ZO-DARTS++: 一种高效可变大小的零阶神经架构搜索算法'}
{'arxiv_id': 'arXiv:2503.06083', 'title': 'T-CBF: Traversability-based Control Barrier Function to Navigate Vertically Challenging Terrain', 'authors': 'Manas Gupta, Xuesu Xiao', 'link': 'https://arxiv.org/abs/2503.06083', 'abstract': 'Safety has been of paramount importance in motion planning and control techniques and is an active area of research in the past few years. Most safety research for mobile robots target at maintaining safety with the notion of collision avoidance. However, safety goes beyond just avoiding collisions, especially when robots have to navigate unstructured, vertically challenging, off-road terrain, where vehicle rollover and immobilization is as critical as collisions. In this work, we introduce a novel Traversability-based Control Barrier Function (T-CBF), in which we use neural Control Barrier Functions (CBFs) to achieve safety beyond collision avoidance on unstructured vertically challenging terrain by reasoning about new safety aspects in terms of traversability. The neural T-CBF trained on safe and unsafe observations specific to traversability safety is then used to generate safe trajectories. Furthermore, we present experimental results in simulation and on a physical Verti-4 Wheeler (V4W) platform, demonstrating that T-CBF can provide traversability safety while reaching the goal position. T-CBF planner outperforms previously developed planners by 30\\% in terms of keeping the robot safe and mobile when navigating on real world vertically challenging terrain.', 'abstract_zh': '基于通行性的控制屏障函数在垂直挑战性非结构化地形上的安全性研究', 'title_zh': '基于 traversability 的控制障碍函数Navigate 陡峭地形的一种方法'}
{'arxiv_id': 'arXiv:2503.06074', 'title': 'Towards Conversational AI for Disease Management', 'authors': 'Anil Palepu, Valentin Liévin, Wei-Hung Weng, Khaled Saab, David Stutz, Yong Cheng, Kavita Kulkarni, S. Sara Mahdavi, Joëlle Barral, Dale R. Webster, Katherine Chou, Avinatan Hassidim, Yossi Matias, James Manyika, Ryutaro Tanno, Vivek Natarajan, Adam Rodman, Tao Tu, Alan Karthikesalingam, Mike Schaekermann', 'link': 'https://arxiv.org/abs/2503.06074', 'abstract': "While large language models (LLMs) have shown promise in diagnostic dialogue, their capabilities for effective management reasoning - including disease progression, therapeutic response, and safe medication prescription - remain under-explored. We advance the previously demonstrated diagnostic capabilities of the Articulate Medical Intelligence Explorer (AMIE) through a new LLM-based agentic system optimised for clinical management and dialogue, incorporating reasoning over the evolution of disease and multiple patient visit encounters, response to therapy, and professional competence in medication prescription. To ground its reasoning in authoritative clinical knowledge, AMIE leverages Gemini's long-context capabilities, combining in-context retrieval with structured reasoning to align its output with relevant and up-to-date clinical practice guidelines and drug formularies. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) study, AMIE was compared to 21 primary care physicians (PCPs) across 100 multi-visit case scenarios designed to reflect UK NICE Guidance and BMJ Best Practice guidelines. AMIE was non-inferior to PCPs in management reasoning as assessed by specialist physicians and scored better in both preciseness of treatments and investigations, and in its alignment with and grounding of management plans in clinical guidelines. To benchmark medication reasoning, we developed RxQA, a multiple-choice question benchmark derived from two national drug formularies (US, UK) and validated by board-certified pharmacists. While AMIE and PCPs both benefited from the ability to access external drug information, AMIE outperformed PCPs on higher difficulty questions. While further research would be needed before real-world translation, AMIE's strong performance across evaluations marks a significant step towards conversational AI as a tool in disease management.", 'abstract_zh': '尽管大型语言模型（LLMs）在诊断对话中展现了潜力，但它们在有效管理推理方面的能力，包括疾病进展、治疗反应和安全药物处方等方面仍需进一步探索。我们通过一种新的基于LLM的代理系统推进了Articulate Medical Intelligence Explorer（AMIE）的先前展示的诊断能力，该系统旨在优化临床管理和对话，并结合了对疾病演化、多患者访问会诊、治疗反应以及药物处方专业技能的推理。为使其推理基于权威的临床知识，AMIE 利用了Gemini的长上下文能力，将上下文检索与结构化推理相结合，使其输出与相关且最新的临床实践指南和药品目录保持一致。在一项随机、盲法的虚拟客观结构化临床考试（OSCE）研究中，AMIE 被与21名初级保健医生（PCPs）在100个多访问病例场景下进行了比较，这些场景旨在反映英国防疫署（NICE）指南和BMJ最佳实践指南。AMIE 在管理推理方面不劣于PCPs，并在治疗和检查的精确性和管理计划与临床指南的契合度和 grounded 方面表现更佳。为了衡量药物推理，我们开发了RxQA，这是一个基于两个国家级药品目录（美国、英国）的多选题基准，并由认证药师进行了验证。虽然AMIE和PCPs都受益于访问外部药物信息的能力，但在较难的问题上，AMIE表现更好。虽然在实际应用前仍需进一步研究，但AMIE 在各种评估中的出色表现标志着对话式AI作为疾病管理工具的一个重要步骤。', 'title_zh': '面向疾病管理的对话式AI研究'}
{'arxiv_id': 'arXiv:2503.06073', 'title': 'GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and Images', 'authors': 'Xiang Lan, Feng Wu, Kai He, Qinghao Zhao, Shenda Hong, Mengling Feng', 'link': 'https://arxiv.org/abs/2503.06073', 'abstract': "While recent multimodal large language models (MLLMs) have advanced automated ECG interpretation, they still face two key limitations: (1) insufficient multimodal synergy between time series signals and visual ECG representations, and (2) limited explainability in linking diagnoses to granular waveform evidence. We introduce GEM, the first MLLM unifying ECG time series, 12-lead ECG images and text for grounded and clinician-aligned ECG interpretation. GEM enables feature-grounded analysis, evidence-driven reasoning, and a clinician-like diagnostic process through three core innovations: a dual-encoder framework extracting complementary time series and image features, cross-modal alignment for effective multimodal understanding, and knowledge-guided instruction generation for generating high-granularity grounding data (ECG-Grounding) linking diagnoses to measurable parameters ($e.g.$, QRS/PR Intervals). Additionally, we propose the Grounded ECG Understanding task, a clinically motivated benchmark designed to comprehensively assess the MLLM's capability in grounded ECG understanding. Experimental results on both existing and our proposed benchmarks show GEM significantly improves predictive performance (CSN $7.4\\% \\uparrow$), explainability ($22.7\\% \\uparrow$), and grounding ($24.8\\% \\uparrow$), making it more suitable for real-world clinical applications. GitHub repository: this https URL", 'abstract_zh': '最近的多模态大型语言模型虽已在心电图自动解读方面取得了进展，但仍面临两个关键限制：(1) 心电时间序列信号和视觉心电图表示之间的多模态协同不足，以及(2) 在将诊断与细粒度波形证据联系起来时的解释性有限。我们提出了GEM，首个将心电时间序列、12导联心电图图像和文本统一起来，实现基于证据的临床对齐心电图解读的多模态大型语言模型。GEM通过三项核心创新实现基于特征的分析、基于证据的推理以及类似临床医生的诊断过程：双编码器框架提取互补的时间序列和图像特征，跨模态对齐以实现有效的多模态理解，以及知识引导的指令生成，生成细粒度的接地数据（ECG-Grounding），将其与可测量参数（例如，QRS/PR间期）联系起来。此外，我们还提出了基于证据的心电图理解任务，这是一个临床驱动的基准测试，旨在全面评估多模态大型语言模型在基于证据的心电图理解能力。我们的实验结果表明，GEM在预测性能（CSN提高7.4%）、解释性（提高22.7%）和接地能力（提高24.8%）方面显著提升，使其更适用于临床应用。GitHub仓库：https://github.com/your-repository。', 'title_zh': 'GEM: 赋能基于时间序列和图像的心电图接地理解的大语言模型'}
{'arxiv_id': 'arXiv:2503.06072', 'title': 'A Survey on Post-training of Large Language Models', 'authors': 'Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou Dai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng Xie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen, Yu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, Jianfeng Gao', 'link': 'https://arxiv.org/abs/2503.06072', 'abstract': "The emergence of Large Language Models (LLMs) has fundamentally transformed natural language processing, making them indispensable across domains ranging from conversational systems to scientific exploration. However, their pre-trained architectures often reveal limitations in specialized contexts, including restricted reasoning capacities, ethical uncertainties, and suboptimal domain-specific performance. These challenges necessitate advanced post-training language models (PoLMs) to address these shortcomings, such as OpenAI-o1/o3 and DeepSeek-R1 (collectively known as Large Reasoning Models, or LRMs). This paper presents the first comprehensive survey of PoLMs, systematically tracing their evolution across five core paradigms: Fine-tuning, which enhances task-specific accuracy; Alignment, which ensures alignment with human preferences; Reasoning, which advances multi-step inference despite challenges in reward design; Efficiency, which optimizes resource utilization amidst increasing complexity; and Integration and Adaptation, which extend capabilities across diverse modalities while addressing coherence issues. Charting progress from ChatGPT's foundational alignment strategies to DeepSeek-R1's innovative reasoning advancements, we illustrate how PoLMs leverage datasets to mitigate biases, deepen reasoning capabilities, and enhance domain adaptability. Our contributions include a pioneering synthesis of PoLM evolution, a structured taxonomy categorizing techniques and datasets, and a strategic agenda emphasizing the role of LRMs in improving reasoning proficiency and domain flexibility. As the first survey of its scope, this work consolidates recent PoLM advancements and establishes a rigorous intellectual framework for future research, fostering the development of LLMs that excel in precision, ethical robustness, and versatility across scientific and societal applications.", 'abstract_zh': '大语言模型（LLMs）的兴起从根本上变革了自然语言处理，使其在从对话系统到科学探索的多个领域中不可或缺。然而，它们的预训练架构在专门情境中常常表现出限制，包括推理能力受限、伦理不确定性以及次优的领域特定性能。这些挑战需要先进的后训练语言模型（PoLMs）来解决这些问题，例如OpenAI-o1/o3和DeepSeek-R1（统称为大型推理模型，或LRMs）。本文首次全面综述了PoLMs，系统地追踪了它们在五种核心范式中的演变：微调，Enhances任务特定准确性；对齐，确保与人类偏好的一致性；推理，尽管存在奖励设计挑战，仍推动多步推理；效率，优化资源利用以应对不断增加的复杂性；以及整合与适应，扩展跨多种模态的能力并解决连贯性问题。从ChatGPT的基础对齐策略到DeepSeek-R1的创新推理进步，我们展示了PoLMs如何利用数据集来缓解偏差、深化推理能力和增强领域适应性。我们的贡献包括对PoLM演变的开创性综述、结构化的分类法对技术和数据集进行分类，以及强调LRMs在提高推理能力和领域灵活性中的作用的战略议程。作为该领域首个综述，本文巩固了最近的PoLM进展，并为未来研究建立了严格的知识框架，促进开发在精度、伦理稳健性和跨科学和社会应用的多样适应性方面表现出色的LLMs。', 'title_zh': '大型语言模型的后训练综述'}
{'arxiv_id': 'arXiv:2503.06064', 'title': 'A Novel Trustworthy Video Summarization Algorithm Through a Mixture of LoRA Experts', 'authors': 'Wenzhuo Du, Gerun Wang, Guancheng Chen, Hang Zhao, Xin Li, Jian Gao', 'link': 'https://arxiv.org/abs/2503.06064', 'abstract': "With the exponential growth of user-generated content on video-sharing platforms, the challenge of facilitating efficient searching and browsing of videos has garnered significant attention. To enhance users' ability to swiftly locate and review pertinent videos, the creation of concise and informative video summaries has become increasingly important. Video-llama is an effective tool for generating video summarization, but it cannot effectively unify and optimize the modeling of temporal and spatial features and requires a lot of computational resources and time. Therefore, we propose MiLoRA-ViSum to more efficiently capture complex temporal dynamics and spatial relationships inherent in video data and to control the number of parameters for training. By extending traditional Low-Rank Adaptation (LoRA) into a sophisticated mixture-of-experts paradigm, MiLoRA-ViSum incorporates a dual temporal-spatial adaptation mechanism tailored specifically for video summarization tasks. This approach dynamically integrates specialized LoRA experts, each fine-tuned to address distinct temporal or spatial dimensions. Extensive evaluations of the VideoXum and ActivityNet datasets demonstrate that MiLoRA-ViSum achieves the best summarization performance compared to state-of-the-art models, while maintaining significantly lower computational costs. The proposed mixture-of-experts strategy, combined with the dual adaptation mechanism, highlights the model's potential to enhance video summarization capabilities, particularly in large-scale applications requiring both efficiency and precision.", 'abstract_zh': '随着视频分享平台上用户生成内容的指数级增长，如何有效地进行视频搜索和浏览成为了一个重要挑战。为了提高用户迅速定位和回顾相关视频的能力，生成简洁且信息丰富的视频摘要变得尤为重要。Video-llama 是一种有效的视频总结生成工具，但它无法有效统一和优化时间和空间特征的建模，并且需要大量的计算资源和时间。因此，我们提出 MiLoRA-ViSum 以更有效地捕获视频数据中固有的复杂时间动态和空间关系，并控制训练中的参数数量。通过将传统的低秩适应（LoRA）扩展到更复杂的专家混合范式中，MiLoRA-ViSum 结合了一个专门为视频摘要任务定制的双重时间和空间适应机制。该方法动态地整合了各自针对不同时间或空间维度进行微调的专业 LoRA 专家。对 VideoXum 和 ActivityNet 数据集的广泛评估表明，MiLoRA-ViSum 在生成性能方面优于最先进的模型，同时保持了显著更低的计算成本。所提出的专家混合策略与双重适应机制突显了该模型在大规模应用中同时提高效率和精度以增强视频摘要能力的潜力。', 'title_zh': '一种通过LoRA专家混合的新型可信赖视频摘要算法'}
{'arxiv_id': 'arXiv:2503.06060', 'title': 'STAR: A Foundation Model-driven Framework for Robust Task Planning and Failure Recovery in Robotic Systems', 'authors': 'Md Sadman Sakib, Yu Sun', 'link': 'https://arxiv.org/abs/2503.06060', 'abstract': "Modern robotic systems, deployed across domains from industrial automation to domestic assistance, face a critical challenge: executing tasks with precision and adaptability in dynamic, unpredictable environments. To address this, we propose STAR (Smart Task Adaptation and Recovery), a novel framework that synergizes Foundation Models (FMs) with dynamically expanding Knowledge Graphs (KGs) to enable resilient task planning and autonomous failure recovery. While FMs offer remarkable generalization and contextual reasoning, their limitations, including computational inefficiency, hallucinations, and output inconsistencies hinder reliable deployment. STAR mitigates these issues by embedding learned knowledge into structured, reusable KGs, which streamline information retrieval, reduce redundant FM computations, and provide precise, scenario-specific insights. The framework leverages FM-driven reasoning to diagnose failures, generate context-aware recovery strategies, and execute corrective actions without human intervention or system restarts. Unlike conventional approaches that rely on rigid protocols, STAR dynamically expands its KG with experiential knowledge, ensuring continuous adaptation to novel scenarios. To evaluate the effectiveness of this approach, we developed a comprehensive dataset that includes various robotic tasks and failure scenarios. Through extensive experimentation, STAR demonstrated an 86% task planning accuracy and 78% recovery success rate, showing significant improvements over baseline methods. The framework's ability to continuously learn from experience while maintaining structured knowledge representation makes it particularly suitable for long-term deployment in real-world applications.", 'abstract_zh': '现代机器人系统在工业自动化到家庭辅助等多个领域部署，面临着一个关键挑战：在动态的、不可预测的环境中精确而灵活地执行任务。为应对这一挑战，我们提出了STAR（智能任务适应与恢复）框架，该框架结合了基础模型（FMs）与动态扩展的知识图谱（KGs），以实现鲁棒的任务规划和自主故障恢复。虽然FMs在泛化和上下文推理方面表现出色，但其计算效率低下、幻觉和输出不一致等问题限制了其可靠部署。STAR通过将学习的知识嵌入到结构化且可重复使用的知识图谱中来缓解这些问题，从而简化信息检索，减少重复的FM计算，并提供精确的、特定场景的洞察。该框架利用基础模型驱动的推理来诊断故障、生成情境感知的恢复策略，并在无需人工干预或系统重启的情况下执行纠正措施。不同于依赖于刚性协议的常规方法，STAR动态扩展其知识图谱以获取经验知识，确保能够持续适应新颖场景。为了评估该方法的有效性，我们开发了一个全面的数据集，其中包括各种机器人任务和故障场景。通过广泛的实验，STAR展示了86%的任务规划准确率和78%的恢复成功率，显示出相对于基线方法有显著提高。该框架具备在经验中持续学习同时保持结构化知识表示的能力，使其特别适合在实际应用中的长期部署。', 'title_zh': 'STAR：一种基于基础模型的任务规划与故障恢复框架在机器人系统中的鲁棒实现'}
{'arxiv_id': 'arXiv:2503.06054', 'title': 'Fine-Grained Bias Detection in LLM: Enhancing detection mechanisms for nuanced biases', 'authors': 'Suvendu Mohanty', 'link': 'https://arxiv.org/abs/2503.06054', 'abstract': 'Recent advancements in Artificial Intelligence, particularly in Large Language Models (LLMs), have transformed natural language processing by improving generative capabilities. However, detecting biases embedded within these models remains a challenge. Subtle biases can propagate misinformation, influence decision-making, and reinforce stereotypes, raising ethical concerns. This study presents a detection framework to identify nuanced biases in LLMs. The approach integrates contextual analysis, interpretability via attention mechanisms, and counterfactual data augmentation to capture hidden biases across linguistic contexts. The methodology employs contrastive prompts and synthetic datasets to analyze model behaviour across cultural, ideological, and demographic scenarios.\nQuantitative analysis using benchmark datasets and qualitative assessments through expert reviews validate the effectiveness of the framework. Results show improvements in detecting subtle biases compared to conventional methods, which often fail to highlight disparities in model responses to race, gender, and socio-political contexts. The framework also identifies biases arising from imbalances in training data and model architectures. Continuous user feedback ensures adaptability and refinement. This research underscores the importance of proactive bias mitigation strategies and calls for collaboration between policymakers, AI developers, and regulators. The proposed detection mechanisms enhance model transparency and support responsible LLM deployment in sensitive applications such as education, legal systems, and healthcare. Future work will focus on real-time bias monitoring and cross-linguistic generalization to improve fairness and inclusivity in AI-driven communication tools.', 'abstract_zh': '近期人工智能的发展，特别是大型语言模型（LLMs）的进步，已通过提升生成能力改变了自然语言处理。然而，检测这些模型中嵌入的偏见仍然是一个挑战。细微的偏见可能会传播错误信息、影响决策并强化刻板印象，引发伦理问题。本研究提出了一种检测框架，用于识别大型语言模型中的复杂偏见。该方法结合了上下文分析、通过注意机制提高可解释性以及对抗性数据增强，以捕捉语言不同情境下的隐藏偏见。该方法论采用了对比提示和合成数据集来分析模型在文化、意识形态和人口统计学场景下的行为。基准数据集的定量分析和专家评审的定性评估验证了该框架的有效性。结果显示，与传统方法相比，该框架在检测细微偏见方面有所改进，传统方法往往难以揭示模型在种族、性别和社会政治语境下的响应差异。该框架还识别出由于训练数据不平衡和模型架构而导致的偏见。持续的用户反馈确保了该框架的适应性和改进。本研究强调了主动偏见缓解策略的重要性，并呼吁政策制定者、AI开发者和监管机构之间的合作。所提出的检测机制增强了模型的透明度，并支持在教育、法律系统和医疗保健等敏感应用中负责任地部署大型语言模型。未来的工作将集中于实时偏见监控和跨语言泛化，以改进基于人工智能的通信工具中的公平性和包容性。', 'title_zh': 'LLM中细粒度偏见检测：增强对细微偏见的检测机制'}
{'arxiv_id': 'arXiv:2503.06053', 'title': 'DropletVideo: A Dataset and Approach to Explore Integral Spatio-Temporal Consistent Video Generation', 'authors': 'Runze Zhang, Guoguang Du, Xiaochuan Li, Qi Jia, Liang Jin, Lu Liu, Jingjing Wang, Cong Xu, Zhenhua Guo, Yaqian Zhao, Xiaoli Gong, Rengang Li, Baoyu Fan', 'link': 'https://arxiv.org/abs/2503.06053', 'abstract': 'Spatio-temporal consistency is a critical research topic in video generation. A qualified generated video segment must ensure plot plausibility and coherence while maintaining visual consistency of objects and scenes across varying viewpoints. Prior research, especially in open-source projects, primarily focuses on either temporal or spatial consistency, or their basic combination, such as appending a description of a camera movement after a prompt without constraining the outcomes of this movement. However, camera movement may introduce new objects to the scene or eliminate existing ones, thereby overlaying and affecting the preceding narrative. Especially in videos with numerous camera movements, the interplay between multiple plots becomes increasingly complex. This paper introduces and examines integral spatio-temporal consistency, considering the synergy between plot progression and camera techniques, and the long-term impact of prior content on subsequent generation. Our research encompasses dataset construction through to the development of the model. Initially, we constructed a DropletVideo-10M dataset, which comprises 10 million videos featuring dynamic camera motion and object actions. Each video is annotated with an average caption of 206 words, detailing various camera movements and plot developments. Following this, we developed and trained the DropletVideo model, which excels in preserving spatio-temporal coherence during video generation. The DropletVideo dataset and model are accessible at this https URL.', 'abstract_zh': '空时一致性是视频生成中的关键研究课题。合格的生成视频段必须确保剧情合理性和连贯性，同时在不同视角下保持物体和场景的视觉一致性。先前的研究，尤其是在开源项目中，主要关注时间或空间一致性，或者它们的基本结合，例如在指令后添加摄像机运动的描述，而不限制这种运动的结果。然而，摄像机运动可能会引入新物体或消除现有物体，从而叠加并影响先前的叙述。尤其在包含多个摄像机运动的视频中，多剧情之间的互动变得更加复杂。本文引入并探讨了综合空时一致性，考虑了剧情进展与摄像技术之间的协同作用，以及先前内容对后续生成的长期影响。我们的研究涵盖从数据集构建到模型开发的全过程。首先，我们构建了一个包含1000万动态摄像机运动和物体动作的DropletVideo-10M数据集，每段视频平均包含206字的注释，详细描述各种摄像机运动和剧情发展。随后，我们开发并训练了DropletVideo模型，该模型在视频生成过程中出色地保持了空时一致性。DropletVideo数据集和模型可通过以下链接访问：[这里](https://example.com)。', 'title_zh': '滴落视频：一种探究整体时空一致视频生成的数据集和方法'}
{'arxiv_id': 'arXiv:2503.06037', 'title': 'Vairiational Stochastic Games', 'authors': 'Zhiyu Zhao, Haifeng Zhang', 'link': 'https://arxiv.org/abs/2503.06037', 'abstract': 'The Control as Inference (CAI) framework has successfully transformed single-agent reinforcement learning (RL) by reframing control tasks as probabilistic inference problems. However, the extension of CAI to multi-agent, general-sum stochastic games (SGs) remains underexplored, particularly in decentralized settings where agents operate independently without centralized coordination. In this paper, we propose a novel variational inference framework tailored to decentralized multi-agent systems. Our framework addresses the challenges posed by non-stationarity and unaligned agent objectives, proving that the resulting policies form an $\\epsilon$-Nash equilibrium. Additionally, we demonstrate theoretical convergence guarantees for the proposed decentralized algorithms. Leveraging this framework, we instantiate multiple algorithms to solve for Nash equilibrium, mean-field Nash equilibrium, and correlated equilibrium, with rigorous theoretical convergence analysis.', 'abstract_zh': 'CAI框架下的控制即推理在分布式多智能体系统的扩展研究：非平稳性和对齐问题的处理及理论收敛性分析', 'title_zh': '变分随机博弈'}
{'arxiv_id': 'arXiv:2503.06030', 'title': 'Towards Universal Text-driven CT Image Segmentation', 'authors': 'Yuheng Li, Yuxiang Lai, Maria Thor, Deborah Marshall, Zachary Buchwald, David S. Yu, Xiaofeng Yang', 'link': 'https://arxiv.org/abs/2503.06030', 'abstract': 'Computed tomography (CT) is extensively used for accurate visualization and segmentation of organs and lesions. While deep learning models such as convolutional neural networks (CNNs) and vision transformers (ViTs) have significantly improved CT image analysis, their performance often declines when applied to diverse, real-world clinical data. Although foundation models offer a broader and more adaptable solution, their potential is limited due to the challenge of obtaining large-scale, voxel-level annotations for medical images. In response to these challenges, prompting-based models using visual or text prompts have emerged. Visual-prompting methods, such as the Segment Anything Model (SAM), still require significant manual input and can introduce ambiguity when applied to clinical scenarios. Instead, foundation models that use text prompts offer a more versatile and clinically relevant approach. Notably, current text-prompt models, such as the CLIP-Driven Universal Model, are limited to text prompts already encountered during training and struggle to process the complex and diverse scenarios of real-world clinical applications. Instead of fine-tuning models trained from natural imaging, we propose OpenVocabCT, a vision-language model pretrained on large-scale 3D CT images for universal text-driven segmentation. Using the large-scale CT-RATE dataset, we decompose the diagnostic reports into fine-grained, organ-level descriptions using large language models for multi-granular contrastive learning. We evaluate our OpenVocabCT on downstream segmentation tasks across nine public datasets for organ and tumor segmentation, demonstrating the superior performance of our model compared to existing methods. All code, datasets, and models will be publicly released at this https URL.', 'abstract_zh': '基于计算断层扫描的通用词汇量视觉-语言模型：用于器官和肿瘤分割的多粒度对比学习;oCT-Based OpenVocabCT: Multigranular Contrastive Learning for Universal Text-Driven Segmentation of Organs and Tumors', 'title_zh': '面向通用的文本驱动CT图像分割'}
{'arxiv_id': 'arXiv:2503.06026', 'title': 'Zero-Shot Peg Insertion: Identifying Mating Holes and Estimating SE(2) Poses with Vision-Language Models', 'authors': 'Masaru Yajima, Kei Ota, Asako Kanezaki, Rei Kawakami', 'link': 'https://arxiv.org/abs/2503.06026', 'abstract': 'Achieving zero-shot peg insertion, where inserting an arbitrary peg into an unseen hole without task-specific training, remains a fundamental challenge in robotics. This task demands a highly generalizable perception system capable of detecting potential holes, selecting the correct mating hole from multiple candidates, estimating its precise pose, and executing insertion despite uncertainties. While learning-based methods have been applied to peg insertion, they often fail to generalize beyond the specific peg-hole pairs encountered during training. Recent advancements in Vision-Language Models (VLMs) offer a promising alternative, leveraging large-scale datasets to enable robust generalization across diverse tasks. Inspired by their success, we introduce a novel zero-shot peg insertion framework that utilizes a VLM to identify mating holes and estimate their poses without prior knowledge of their geometry. Extensive experiments demonstrate that our method achieves 90.2% accuracy, significantly outperforming baselines in identifying the correct mating hole across a wide range of previously unseen peg-hole pairs, including 3D-printed objects, toy puzzles, and industrial connectors. Furthermore, we validate the effectiveness of our approach in a real-world connector insertion task on a backpanel of a PC, where our system successfully detects holes, identifies the correct mating hole, estimates its pose, and completes the insertion with a success rate of 88.3%. These results highlight the potential of VLM-driven zero-shot reasoning for enabling robust and generalizable robotic assembly.', 'abstract_zh': '实现零样本 peg 插入，即在无特定任务训练的情况下将任意 peg 插入未见过的孔中，仍然是机器人技术中的一个基本挑战。这项任务要求具备高度泛化能力的感知系统，能够检测潜在的孔，从多个候选孔中选择正确的匹配孔，估计其精确的姿态，并在存在不确定性的情况下执行插入。虽然基于学习的方法已被应用于 peg 插入，但它们往往无法在超出训练过程中遇到的特定 peg-孔对的情况下泛化。近期视觉-语言模型（VLMs）的进展提供了另一种有前景的替代方案，利用大规模数据集在多种任务上实现稳健泛化。受其成功启发，我们提出了一种新的零样本 peg 插入框架，利用 VLM 无需先验几何知识即可识别匹配孔并估计其姿态。广泛实验表明，我们的方法在识别正确匹配孔方面达到了 90.2% 的准确率，在各种以前未见过的 peg-孔对中，包括 3D 打印对象、玩具拼图和工业连接器，显著优于基线方法。此外，我们还在 PC 后面板的连接器插入任务中验证了我们方法的有效性，我们的系统成功地检测孔、识别正确的匹配孔、估计其姿态，并以 88.3% 的成功率完成插入。这些结果凸显了 VLM 驱动的零样本推理在实现稳健和泛化的机器人装配方面的潜力。', 'title_zh': '零样本钉钉插入：基于视觉-语言模型的接合孔识别与SE(2)姿态估计'}
{'arxiv_id': 'arXiv:2503.06014', 'title': 'Towards Ambiguity-Free Spatial Foundation Model: Rethinking and Decoupling Depth Ambiguity', 'authors': 'Xiaohao Xu, Feng Xue, Xiang Li, Haowei Li, Shusheng Yang, Tianyi Zhang, Matthew Johnson-Roberson, Xiaonan Huang', 'link': 'https://arxiv.org/abs/2503.06014', 'abstract': 'Depth ambiguity is a fundamental challenge in spatial scene understanding, especially in transparent scenes where single-depth estimates fail to capture full 3D structure. Existing models, limited to deterministic predictions, overlook real-world multi-layer depth. To address this, we introduce a paradigm shift from single-prediction to multi-hypothesis spatial foundation models. We first present \\texttt{MD-3k}, a benchmark exposing depth biases in expert and foundational models through multi-layer spatial relationship labels and new metrics. To resolve depth ambiguity, we propose Laplacian Visual Prompting (LVP), a training-free spectral prompting technique that extracts hidden depth from pre-trained models via Laplacian-transformed RGB inputs. By integrating LVP-inferred depth with standard RGB-based estimates, our approach elicits multi-layer depth without model retraining. Extensive experiments validate the effectiveness of LVP in zero-shot multi-layer depth estimation, unlocking more robust and comprehensive geometry-conditioned visual generation, 3D-grounded spatial reasoning, and temporally consistent video-level depth inference. Our benchmark and code will be available at this https URL.', 'abstract_zh': '深度 ambiguity 是空间场景理解中的基础挑战，特别是在透明场景中，单深度估计无法捕捉完整的三维结构。现有的模型局限于确定性的预测，忽视了现实世界中多层深度的存在。为了解决这一问题，我们提出了从单预测到多假设的空间基础模型的范式转变。我们首先介绍了 \\texttt{MD-3k}，一个基准，通过多层空间关系标签和新的评估指标，揭示专家模型和基础模型中的深度偏差。为了解决深度 ambiguity，我们提出了一种无需训练的拉普拉斯视觉提示（LVP）技术，通过拉普拉斯变换的 RGB 输入从预训练模型中提取隐藏的深度。通过将 LVP 推理出的深度与标准 RGB 基础估计相结合，我们的方法可以在无需模型重新训练的情况下获取多层深度。 extensive 实验验证了 LVP 在零样本多层深度估计中的有效性，解锁了更 robust 和全面的几何条件下的视觉生成、三维地基空间推理以及时间一致的视频级深度推理。我们的基准和代码将在以下链接处提供：这个 https URL。', 'title_zh': '面向无歧义的空间基础模型：重新思考并解耦深度歧义'}
{'arxiv_id': 'arXiv:2503.06011', 'title': 'Intent-Aware Self-Correction for Mitigating Social Biases in Large Language Models', 'authors': 'Panatchakorn Anantaprayoon, Masahiro Kaneko, Naoaki Okazaki', 'link': 'https://arxiv.org/abs/2503.06011', 'abstract': "Self-Correction based on feedback improves the output quality of Large Language Models (LLMs). Moreover, as Self-Correction functions like the slow and conscious System-2 thinking from cognitive psychology's perspective, it can potentially reduce LLMs' social biases. LLMs are sensitive to contextual ambiguities and inconsistencies; therefore, explicitly communicating their intentions during interactions when applying Self-Correction for debiasing is crucial. In this study, we demonstrate that clarifying intentions is essential for effectively reducing biases in LLMs through Self-Correction. We divide the components needed for Self-Correction into three parts: instruction, response, and feedback, and clarify intentions at each component. We incorporate an explicit debiasing prompt to convey the intention of bias mitigation from the instruction for response generation. In the response, we use Chain-of-Thought (CoT) to clarify the reasoning process. In the feedback, we define evaluation aspects necessary for debiasing and propose clear feedback through multi-aspect critiques and scoring. Through experiments, we demonstrate that self-correcting CoT responses obtained from a debiasing prompt based on multi-aspect feedback can reduce biased responses more robustly and consistently than the baselines. We also find the variation in debiasing efficacy when using models with different bias levels or separating models for response and feedback generation.", 'abstract_zh': '基于反馈的自我修正提高大型语言模型的输出质量，从认知心理学的角度来看，自我修正类似于系统的System-2思考，这可能减少大型语言模型的社会偏见。大型语言模型对上下文的歧义和不一致性敏感，因此，在应用自我修正进行去偏见化过程中明确沟通意图至关重要。本研究通过实验证明，明确意图对于通过自我修正有效减少大型语言模型的偏见至关重要。我们将自我修正所需的组件分为三部分：指令、响应和反馈，并在每个组件中明确意图。我们通过带有明确去偏见提示的指令来传达去偏见的意图，以便生成响应。在响应中，我们使用思维链（CoT）来澄清推理过程。在反馈中，我们定义了去偏见所需的评估维度，并提出了多方面批评和评分的明确反馈。通过实验，我们证明了基于多维度反馈生成的去偏见提示的自我修正思维链响应比基线方法更能稳健和一致地减少偏见。我们还发现，在不同偏见水平的模型或分离用于生成响应和反馈的模型时，去偏见效果的差异。', 'title_zh': '面向意图的自我修正以缓解大型语言模型中的社会偏见'}
{'arxiv_id': 'arXiv:2503.05997', 'title': 'Learning to Drive by Imitating Surrounding Vehicles', 'authors': 'Yasin Sonmez, Hanna Krasowski, Murat Arcak', 'link': 'https://arxiv.org/abs/2503.05997', 'abstract': "Imitation learning is a promising approach for training autonomous vehicles (AV) to navigate complex traffic environments by mimicking expert driver behaviors. However, a major challenge in this paradigm lies in effectively utilizing available driving data, as collecting new data is resource-intensive and often limited in its ability to cover diverse driving scenarios. While existing imitation learning frameworks focus on leveraging expert demonstrations, they often overlook the potential of additional complex driving data from surrounding traffic participants. In this paper, we propose a data augmentation strategy that enhances imitation learning by leveraging the observed trajectories of nearby vehicles, captured through the AV's sensors, as additional expert demonstrations. We introduce a vehicle selection sampling strategy that prioritizes informative and diverse driving behaviors, contributing to a richer and more diverse dataset for training. We evaluate our approach using the state-of-the-art learning-based planning method PLUTO on the nuPlan dataset and demonstrate that our augmentation method leads to improved performance in complex driving scenarios. Specifically, our method reduces collision rates and improves safety metrics compared to the baseline. Notably, even when using only 10% of the original dataset, our method achieves performance comparable to that of the full dataset, with improved collision rates. Our findings highlight the importance of leveraging diverse real-world trajectory data in imitation learning and provide insights into data augmentation strategies for autonomous driving.", 'abstract_zh': '模仿学习是一种有前景的方法，通过模仿专家驾驶员行为来训练自动驾驶车辆（AV）在复杂交通环境中导航。然而，这一范式中存在的主要挑战在于有效利用可用的驾驶数据，因为收集新数据成本高昂且往往难以涵盖多种多样的驾驶场景。虽然现有的模仿学习框架侧重于利用专家演示，但往往会忽视周围交通参与者提供的复杂驾驶数据的潜力。在本文中，我们提出了一种数据增强策略，该策略通过利用自动驾驶车辆传感器捕获的附近车辆的观测轨迹，作为额外的专家演示来增强模仿学习。我们引入了一种车辆选择采样策略，该策略优先选择具有信息性和多样性的驾驶行为，从而为训练提供更丰富和多样化的数据集。我们使用最先进的基于学习的规划方法PLUTO在nuPlan数据集上评估了我们的方法，并且表明我们的增强方法在复杂驾驶场景中表现出更好的性能。具体来说，我们的方法减少了碰撞率并提高了安全指标，与基线方法相比。值得注意的是，即使仅使用原始数据集的10%，我们的方法在碰撞率方面也达到了与完整数据集相当的性能。我们的研究结果强调了在模仿学习中利用多样化的实际轨迹数据的重要性，并为自动驾驶中的数据增强策略提供了见解。', 'title_zh': '通过模仿周围车辆学习驾驶'}
{'arxiv_id': 'arXiv:2503.05996', 'title': 'Towards Improving Reward Design in RL: A Reward Alignment Metric for RL Practitioners', 'authors': 'Calarina Muslimani, Kerrick Johnstonbaugh, Suyog Chandramouli, Serena Booth, W. Bradley Knox, Matthew E. Taylor', 'link': 'https://arxiv.org/abs/2503.05996', 'abstract': "Reinforcement learning agents are fundamentally limited by the quality of the reward functions they learn from, yet reward design is often overlooked under the assumption that a well-defined reward is readily available. However, in practice, designing rewards is difficult, and even when specified, evaluating their correctness is equally problematic: how do we know if a reward function is correctly specified? In our work, we address these challenges by focusing on reward alignment -- assessing whether a reward function accurately encodes the preferences of a human stakeholder. As a concrete measure of reward alignment, we introduce the Trajectory Alignment Coefficient to quantify the similarity between a human stakeholder's ranking of trajectory distributions and those induced by a given reward function. We show that the Trajectory Alignment Coefficient exhibits desirable properties, such as not requiring access to a ground truth reward, invariance to potential-based reward shaping, and applicability to online RL. Additionally, in an 11 -- person user study of RL practitioners, we found that access to the Trajectory Alignment Coefficient during reward selection led to statistically significant improvements. Compared to relying only on reward functions, our metric reduced cognitive workload by 1.5x, was preferred by 82% of users and increased the success rate of selecting reward functions that produced performant policies by 41%.", 'abstract_zh': '强化学习代理受其所学习的奖励函数质量的限制，但在假设奖励定义明确的情况下，奖励设计往往被忽视。实际上，设计奖励具有挑战性，即使给出了奖励规格，评估其正确性同样困难：我们如何确定一个奖励函数是否正确地编码了人类相关方的偏好？在我们的工作中，我们通过关注奖励对齐（reward alignment）来应对这些挑战——评估奖励函数是否准确地编码了人类相关方的偏好。作为奖励对齐的 concrete 度量，我们引入了轨迹对齐系数来量化人类相关方对轨迹分布的排名与由给定奖励函数诱导的排名之间的相似性。我们证明，轨迹对齐系数具有良好的性质，如无需访问 ground truth 奖励、对基于势的奖励塑造不变以及适用于在线 RL。此外，在的一项涉及11名RL实践者的用户研究中，我们发现，在奖励选择过程中使用轨迹对齐系数带来了统计显著性的改进。与仅依赖奖励函数相比，我们的指标使认知负担减少了1.5倍，82%的用户更偏好它，并且将选择产生高性能策略的奖励函数的成功率提高了41%。', 'title_zh': '提高强化学习中奖励设计：强化学习实践者的奖励对齐度量方法'}
{'arxiv_id': 'arXiv:2503.05991', 'title': 'GrInAdapt: Scaling Retinal Vessel Structural Map Segmentation Through Grounding, Integrating and Adapting Multi-device, Multi-site, and Multi-modal Fundus Domains', 'authors': 'Zixuan Liu, Aaron Honjaya, Yuekai Xu, Yi Zhang, Hefu Pan, Xin Wang, Linda G Shapiro, Sheng Wang, Ruikang K Wang', 'link': 'https://arxiv.org/abs/2503.05991', 'abstract': 'Retinal vessel segmentation is critical for diagnosing ocular conditions, yet current deep learning methods are limited by modality-specific challenges and significant distribution shifts across imaging devices, resolutions, and anatomical regions. In this paper, we propose GrInAdapt, a novel framework for source-free multi-target domain adaptation that leverages multi-view images to refine segmentation labels and enhance model generalizability for optical coherence tomography angiography (OCTA) of the fundus of the eye. GrInAdapt follows an intuitive three-step approach: (i) grounding images to a common anchor space via registration, (ii) integrating predictions from multiple views to achieve improved label consensus, and (iii) adapting the source model to diverse target domains. Furthermore, GrInAdapt is flexible enough to incorporate auxiliary modalities such as color fundus photography, to provide complementary cues for robust vessel segmentation. Extensive experiments on a multi-device, multi-site, and multi-modal retinal dataset demonstrate that GrInAdapt significantly outperforms existing domain adaptation methods, achieving higher segmentation accuracy and robustness across multiple domains. These results highlight the potential of GrInAdapt to advance automated retinal vessel analysis and support robust clinical decision-making.', 'abstract_zh': '无独有偶，本研究提出了一种名为GrInAdapt的新型框架，用于利用多视角图像细化分割标签并增强光学相干断层扫描血管成像(OCTA)的眼底图像模型的泛化能力。', 'title_zh': 'GrInAdapt: 通过 grounding、integrating 和 adapting 多设备、多场地和多模态眼底数据扩展视网膜血管结构图分割规模'}
{'arxiv_id': 'arXiv:2503.05985', 'title': 'Black Box Causal Inference: Effect Estimation via Meta Prediction', 'authors': 'Lucius E.J. Bynum, Aahlad Manas Puli, Diego Herrero-Quevedo, Nhi Nguyen, Carlos Fernandez-Granda, Kyunghyun Cho, Rajesh Ranganath', 'link': 'https://arxiv.org/abs/2503.05985', 'abstract': 'Causal inference and the estimation of causal effects plays a central role in decision-making across many areas, including healthcare and economics. Estimating causal effects typically requires an estimator that is tailored to each problem of interest. But developing estimators can take significant effort for even a single causal inference setting. For example, algorithms for regression-based estimators, propensity score methods, and doubly robust methods were designed across several decades to handle causal estimation with observed confounders. Similarly, several estimators have been developed to exploit instrumental variables (IVs), including two-stage least-squares (TSLS), control functions, and the method-of-moments. In this work, we instead frame causal inference as a dataset-level prediction problem, offloading algorithm design to the learning process. The approach we introduce, called black box causal inference (BBCI), builds estimators in a black-box manner by learning to predict causal effects from sampled dataset-effect pairs. We demonstrate accurate estimation of average treatment effects (ATEs) and conditional average treatment effects (CATEs) with BBCI across several causal inference problems with known identification, including problems with less developed estimators.', 'abstract_zh': '因果推断和因果效应的估计在医疗保健和经济学等多个领域中的决策制定中发挥着核心作用。因果效应的估计通常需要针对每个感兴趣的问题量身定制的估计器。然而，即使对于单个因果推断设置，开发估计器也可能需要大量努力。例如，基于回归的估计器算法、倾向得分方法和双重鲁棒方法是在多个世纪设计出来的，以处理带有观测混杂因素的因果估计问题。同样，已经开发出了利用工具变量的方法，包括两阶段最小二乘法（TSLS）、控制函数方法和矩方法。在此项工作中，我们相反地将因果推断框架化为数据集级的预测问题，将算法设计的任务交给学习过程。我们引入的方法称为黑盒因果推断（BBCI），通过学习预测采样数据集-效应对的因果效应，以黑盒方式构建估计器。我们展示了在多个已知识别的因果推理问题（包括那些缺乏成熟估计器的问题）中，使用BBCI准确估计平均处理效应（ATE）和条件平均处理效应（CATE）。', 'title_zh': '黑箱因果推断：通过元预测估计效应'}
{'arxiv_id': 'arXiv:2503.05980', 'title': 'SINdex: Semantic INconsistency Index for Hallucination Detection in LLMs', 'authors': 'Samir Abdaljalil, Hasan Kurban, Parichit Sharma, Erchin Serpedin, Rachad Atat', 'link': 'https://arxiv.org/abs/2503.05980', 'abstract': 'Large language models (LLMs) are increasingly deployed across diverse domains, yet they are prone to generating factually incorrect outputs - commonly known as "hallucinations." Among existing mitigation strategies, uncertainty-based methods are particularly attractive due to their ease of implementation, independence from external data, and compatibility with standard LLMs. In this work, we introduce a novel and scalable uncertainty-based semantic clustering framework for automated hallucination detection. Our approach leverages sentence embeddings and hierarchical clustering alongside a newly proposed inconsistency measure, SINdex, to yield more homogeneous clusters and more accurate detection of hallucination phenomena across various LLMs. Evaluations on prominent open- and closed-book QA datasets demonstrate that our method achieves AUROC improvements of up to 9.3% over state-of-the-art techniques. Extensive ablation studies further validate the effectiveness of each component in our framework.', 'abstract_zh': '基于不确定性的一种可扩展的语义聚类自动幻觉检测框架', 'title_zh': 'SINdex：大模型幻觉检测的语义不一致性指数'}
{'arxiv_id': 'arXiv:2503.05979', 'title': 'Learning-Order Autoregressive Models with Application to Molecular Graph Generation', 'authors': 'Zhe Wang, Jiaxin Shi, Nicolas Heess, Arthur Gretton, Michalis K. Titsias', 'link': 'https://arxiv.org/abs/2503.05979', 'abstract': 'Autoregressive models (ARMs) have become the workhorse for sequence generation tasks, since many problems can be modeled as next-token prediction. While there appears to be a natural ordering for text (i.e., left-to-right), for many data types, such as graphs, the canonical ordering is less obvious. To address this problem, we introduce a variant of ARM that generates high-dimensional data using a probabilistic ordering that is sequentially inferred from data. This model incorporates a trainable probability distribution, referred to as an \\emph{order-policy}, that dynamically decides the autoregressive order in a state-dependent manner. To train the model, we introduce a variational lower bound on the exact log-likelihood, which we optimize with stochastic gradient estimation. We demonstrate experimentally that our method can learn meaningful autoregressive orderings in image and graph generation. On the challenging domain of molecular graph generation, we achieve state-of-the-art results on the QM9 and ZINC250k benchmarks, evaluated using the Fréchet ChemNet Distance (FCD).', 'abstract_zh': '自回归模型（ARMs）已成为序列生成任务的主力模型，因为许多问题可以建模为下一个token的预测。尽管文本具有自然的顺序（即从左到右），但对于诸如图等许多数据类型，其经典的顺序并不明显。为解决这一问题，我们引入了一种自回归模型的变体，该模型使用从数据中顺序推断出的概率顺序生成高维度数据。该模型嵌入了一个可训练的概率分布，称为\\emph{order-policy}，它以状态依赖的方式动态决定自回归顺序。为了训练该模型，我们引入了一个变分下界来优化精确对数似然，采用基于梯度的随机优化方法。实验结果表明，我们的方法可以在图像和图的生成中学习到有意义的自回归顺序。在分子图生成这一具有挑战性的领域中，我们在QM9和ZINC250k基准测试中使用Fréchet ChemNet距离（FCD）取得了最先进的结果。', 'title_zh': '学习顺序自回归模型及其在分子图生成中的应用'}
{'arxiv_id': 'arXiv:2503.05977', 'title': 'Is Your Video Language Model a Reliable Judge?', 'authors': 'Ming Liu, Wensheng Zhang', 'link': 'https://arxiv.org/abs/2503.05977', 'abstract': 'As video language models (VLMs) gain more applications in various scenarios, the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability, which sparked interest in automatic methods such as employing VLMs to evaluate VLMs. However, the reliability of VLMs as judges remains underexplored. Existing methods often rely on a single VLM as the evaluator. However, this approach can be unreliable or biased because such a model may lack the ability to fully understand the content and may have inherent biases, ultimately compromising evaluation reliability. A remedy is to apply the principle of collective thoughts, aggregating evaluations from multiple VLMs to enhance reliability. This study investigates the efficacy of such approaches, particularly when the pool of judges includes both reliable and unreliable models. Our findings reveal that incorporating collective judgments from such a mixed pool does not necessarily improve the accuracy of the final evaluation. The inclusion of less reliable judges can introduce noise, undermining the overall reliability of the outcomes. To explore the factors that impact evaluation reliability, we fine-tune an underperforming VLM judge, Video-LLaVA, and observe that improved understanding ability alone is insufficient to make VLM judges more reliable. These findings stress the limitations of collective thought approaches and highlight the need for more advanced methods that can account for the reliability of individual models. Our study promotes the development of more reliable evaluation methods for VLMs', 'abstract_zh': '随着视频语言模型（VLMs）在各种场景中的应用越来越广泛，对其性能的稳健和可扩展评估的需求变得日益关键。传统的人工专家评估方法在一致性和可扩展性方面存在局限性，这激发了使用自动方法（如让VLM们评估VLM们）的兴趣。然而，VLMs作为评判者可靠性的探索仍处于初级阶段。现有方法通常依赖单一的VLM作为评判者，但这种方法可能会因为模型缺乏对内容的全面理解或存在固有偏见而变得不可靠或有偏见，从而影响评判的可靠性。一种解决办法是应用群体智慧的原则，通过汇集多个VLM的评估来提高可靠性。本研究调查了此类方法的有效性，尤其是在评判者池中包括可靠的和不稳定的模型时。我们的发现表明，将这种混合池中的判断意见汇集起来并不一定能提高最终评估的准确性，不稳定的评判者可能会引入噪声，从而削弱结果的整体可靠性。为了探索影响评估可靠性的因素，我们对表现不佳的VLM评判者Video-LLaVA进行了微调，发现仅提高理解能力不足以使VLM评判者更可靠。这些发现强调了群体智慧方法的局限性，并突显了需要更先进的方法来考虑到单个模型的可靠性。本研究促进了更可靠的方法的开发，以评估VLMs。', 'title_zh': '你的视频语言模型是一个可靠的裁判吗？'}
{'arxiv_id': 'arXiv:2503.05972', 'title': 'Optimal sensor deception in stochastic environments with partial observability to mislead a robot to a decoy goal', 'authors': 'Hazhar Rahmani, Mukulika Ghosh, Syed Md Hasnayeen', 'link': 'https://arxiv.org/abs/2503.05972', 'abstract': "Deception is a common strategy adapted by autonomous systems in adversarial settings. Existing deception methods primarily focus on increasing opacity or misdirecting agents away from their goal or itinerary. In this work, we propose a deception problem aiming to mislead the robot towards a decoy goal through altering sensor events under a constrained budget of alteration. The environment along with the robot's interaction with it is modeled as a Partially Observable Markov Decision Process (POMDP), and the robot's action selection is governed by a Finite State Controller (FSC). Given a constrained budget for sensor event modifications, the objective is to compute a sensor alteration that maximizes the probability of the robot reaching a decoy goal. We establish the computational hardness of the problem by a reduction from the $0/1$ Knapsack problem and propose a Mixed Integer Linear Programming (MILP) formulation to compute optimal deception strategies. We show the efficacy of our MILP formulation via a sequence of experiments.", 'abstract_zh': '自主系统在对抗环境中采用欺骗策略是一种常见策略。现有的欺骗方法主要关注于增加不透明度或引导代理偏离其目标或行程。本工作中，我们提出了一种新的欺骗问题，旨在通过在有限的修改预算下改变传感器事件，引导机器人向一个诱饵目标偏离。环境以及机器人与其的交互被建模为部分可观测马尔可夫决策过程（POMDP），机器人的动作选择由有限状态控制器（FSC）管理。给定传感器事件修改的预算限制，目标是计算一个能最大化机器人达到诱饵目标概率的传感器修改方案。通过对0/1背包问题进行归约来证明该问题的计算难题，并提出混合整数线性规划（MILP）方法来计算最优的欺骗策略。我们通过一系列实验展示了我们提出的MILP模型的有效性。', 'title_zh': '在部分可观测的随机环境中优化传感器欺骗以引导机器人偏离真实目标至诱饵目标'}
{'arxiv_id': 'arXiv:2503.05971', 'title': 'A Real-time Multimodal Transformer Neural Network-powered Wildfire Forecasting System', 'authors': 'Qijun Chen, Shaofan Li', 'link': 'https://arxiv.org/abs/2503.05971', 'abstract': 'Due to climate change, the extreme wildfire has become one of the most dangerous natural hazards to human civilization. Even though, some wildfires may be initially caused by human activity, but the spread of wildfires is mainly determined by environmental factors, for examples, (1) weather conditions such as temperature, wind direction and intensity, and moisture levels; (2) the amount and types of dry vegetation in a local area, and (3) topographic or local terrian conditions, which affects how much rain an area gets and how fire dynamics will be constrained or faciliated. Thus, to accurately forecast wildfire occurrence has become one of most urgent and taunting environmental challenges in global scale. In this work, we developed a real-time Multimodal Transformer Neural Network Machine Learning model that combines several advanced artificial intelligence techniques and statistical methods to practically forecast the occurrence of wildfire at the precise location in real time, which not only utilizes large scale data information such as hourly weather forecasting data, but also takes into account small scale topographical data such as local terrain condition and local vegetation conditions collecting from Google Earth images to determine the probabilities of wildfire occurrence location at small scale as well as their timing synchronized with weather forecast information. By using the wildfire data in the United States from 1992 to 2015 to train the multimodal transformer neural network, it can predict the probabilities of wildfire occurrence according to the real-time weather forecast and the synchronized Google Earth image data to provide the wildfire occurrence probability in any small location ($100m^2$) within 24 hours ahead.', 'abstract_zh': '由于气候变化，极端森林火灾已成为人类文明面临的最危险的自然灾难之一。尽管一些森林火灾最初可能由人类活动引起，但森林火灾的蔓延主要由环境因素决定，例如（1）温度、风向和强度等气象条件；（2）当地可燃干植被的数量和类型；（3）地形或当地地形条件，这些条件影响一个区域的降雨量并制约或促进火灾动态。因此，准确预报森林火灾的发生已成为全球最紧迫和具挑战性的环境挑战之一。在本研究中，我们开发了一种实时多模态变压器神经网络机器学习模型，结合了多种先进的人工智能技术和统计方法，以实时准确预测特定地点的森林火灾的发生，该模型不仅利用了小时级别的气象预报数据，还考虑了从Google Earth图像收集的局部地形条件和植被条件，以确定局部小范围内森林火灾发生概率及其与天气预报信息同步的时间。通过使用1992年至2015年美国的森林火灾数据训练多模态变压器神经网络，该模型可以根据实时气象预报和同步的Google Earth图像数据，在24小时内提前预测任何小范围内（100平方米）的森林火灾发生概率。', 'title_zh': '实时多模态变压器神经网络驱动的 wildfire 预测系统'}
{'arxiv_id': 'arXiv:2503.05966', 'title': 'Explaining the Unexplainable: A Systematic Review of Explainable AI in Finance', 'authors': 'Md Talha Mohsin, Nabid Bin Nasim', 'link': 'https://arxiv.org/abs/2503.05966', 'abstract': 'Practitioners and researchers trying to strike a balance between accuracy and transparency center Explainable Artificial Intelligence (XAI) at the junction of finance. This paper offers a thorough overview of the changing scene of XAI applications in finance together with domain-specific implementations, methodological developments, and trend mapping of research. Using bibliometric and content analysis, we find topic clusters, significant research, and most often used explainability strategies used in financial industries. Our results show a substantial dependence on post-hoc interpretability techniques; attention mechanisms, feature importance analysis and SHAP are the most often used techniques among them. This review stresses the need of multidisciplinary approaches combining financial knowledge with improved explainability paradigms and exposes important shortcomings in present XAI systems.', 'abstract_zh': '从业者和研究者致力于在准确性和透明度之间寻求平衡，将可解释的人工智能（XAI）置于金融领域。本文提供了XAI在金融领域应用的全面 overview，包括领域特定的实施、方法论发展和研究趋势映射。通过文献计量和内容分析，我们找到了主题群簇、重要研究和在金融行业中最常使用的技术。研究结果表明，这些技术中对事后可解释性方法的依赖程度很大；其中最常用的技术包括注意力机制、特征重要性分析和SHAP。本文强调了结合金融知识和改进的可解释性范式的多学科方法的需求，并揭示了现有XAI系统的诸多不足。', 'title_zh': '解释无法解释的：金融领域可解释AI的系统综述'}
{'arxiv_id': 'arXiv:2503.05958', 'title': 'SANDWiCH: Semantical Analysis of Neighbours for Disambiguating Words in Context ad Hoc', 'authors': 'Daniel Guzman-Olivares, Lara Quijano-Sanchez, Federico Liberatore', 'link': 'https://arxiv.org/abs/2503.05958', 'abstract': 'The rise of generative chat-based Large Language Models (LLMs) over the past two years has spurred a race to develop systems that promise near-human conversational and reasoning experiences. However, recent studies indicate that the language understanding offered by these models remains limited and far from human-like performance, particularly in grasping the contextual meanings of words, an essential aspect of reasoning. In this paper, we present a simple yet computationally efficient framework for multilingual Word Sense Disambiguation (WSD). Our approach reframes the WSD task as a cluster discrimination analysis over a semantic network refined from BabelNet using group algebra. We validate our methodology across multiple WSD benchmarks, achieving a new state of the art for all languages and tasks, as well as in individual assessments by part of speech. Notably, our model significantly surpasses the performance of current alternatives, even in low-resource languages, while reducing the parameter count by 72%.', 'abstract_zh': '过去两年中生成式聊天基础的大语言模型的兴起促使了一场开发承诺提供接近人类对话和推理体验系统的竞赛。然而，最近的研究表明，这些模型提供的语言理解能力仍然有限，远未达到人类水平的表现，尤其是在理解词语的上下文意义方面，这是推理的一个重要方面。在本文中，我们提出了一种简单而计算高效的多语言词义消歧框架。我们的方法将词义消歧任务重新表述为基于使用群代数从BabelNet提炼而成的语义网络的聚类鉴别分析。我们在多个词义消歧基准上验证了我们的方法，实现了所有语言和任务的新最佳性能，并在词性细分评估中也实现了最佳性能。值得注意的是，我们的模型在低资源语言上显著超越了当前的替代方案，同时参数量减少了72%。', 'title_zh': 'SANDWiCH: 基于邻居的语义分析在即时情境中消歧词义'}
{'arxiv_id': 'arXiv:2503.05951', 'title': 'TPU-Gen: LLM-Driven Custom Tensor Processing Unit Generator', 'authors': 'Deepak Vungarala, Mohammed E. Elbtity, Sumiya Syed, Sakila Alam, Kartik Pandit, Arnob Ghosh, Ramtin Zand, Shaahin Angizi', 'link': 'https://arxiv.org/abs/2503.05951', 'abstract': 'The increasing complexity and scale of Deep Neural Networks (DNNs) necessitate specialized tensor accelerators, such as Tensor Processing Units (TPUs), to meet various computational and energy efficiency requirements. Nevertheless, designing optimal TPU remains challenging due to the high domain expertise level, considerable manual design time, and lack of high-quality, domain-specific datasets. This paper introduces TPU-Gen, the first Large Language Model (LLM) based framework designed to automate the exact and approximate TPU generation process, focusing on systolic array architectures. TPU-Gen is supported with a meticulously curated, comprehensive, and open-source dataset that covers a wide range of spatial array designs and approximate multiply-and-accumulate units, enabling design reuse, adaptation, and customization for different DNN workloads. The proposed framework leverages Retrieval-Augmented Generation (RAG) as an effective solution for a data-scare hardware domain in building LLMs, addressing the most intriguing issue, hallucinations. TPU-Gen transforms high-level architectural specifications into optimized low-level implementations through an effective hardware generation pipeline. Our extensive experimental evaluations demonstrate superior performance, power, and area efficiency, with an average reduction in area and power of 92\\% and 96\\% from the manual optimization reference values. These results set new standards for driving advancements in next-generation design automation tools powered by LLMs.', 'abstract_zh': '基于大型语言模型的TPU生成框架：面向 systolic阵列架构的精确与近似TPU自动化设计', 'title_zh': 'TPU-Gen：由LLM驱动的自定义张量处理单元生成器'}
{'arxiv_id': 'arXiv:2503.05938', 'title': 'Uncertainty Quantification From Scaling Laws in Deep Neural Networks', 'authors': 'Ibrahim Elsharkawy, Yonatan Kahn, Benjamin Hooberman', 'link': 'https://arxiv.org/abs/2503.05938', 'abstract': 'Quantifying the uncertainty from machine learning analyses is critical to their use in the physical sciences. In this work we focus on uncertainty inherited from the initialization distribution of neural networks. We compute the mean $\\mu_{\\mathcal{L}}$ and variance $\\sigma_{\\mathcal{L}}^2$ of the test loss $\\mathcal{L}$ for an ensemble of multi-layer perceptrons (MLPs) with neural tangent kernel (NTK) initialization in the infinite-width limit, and compare empirically to the results from finite-width networks for three example tasks: MNIST classification, CIFAR classification and calorimeter energy regression. We observe scaling laws as a function of training set size $N_\\mathcal{D}$ for both $\\mu_{\\mathcal{L}}$ and $\\sigma_{\\mathcal{L}}$, but find that the coefficient of variation $\\epsilon_{\\mathcal{L}} \\equiv \\sigma_{\\mathcal{L}}/\\mu_{\\mathcal{L}}$ becomes independent of $N_\\mathcal{D}$ at both infinite and finite width for sufficiently large $N_\\mathcal{D}$. This implies that the coefficient of variation of a finite-width network may be approximated by its infinite-width value, and may in principle be calculable using finite-width perturbation theory.', 'abstract_zh': '机器学习分析中的不确定性量化对于它们在物理科学中的应用至关重要。本工作中，我们关注继承自神经网络初始化分布的不确定性。我们计算了在神经 tangent 核（NTK）初始化下的多层感知机（MLPs）无穷宽度极限下的测试损失值 $\\mathcal{L}$ 的均值 $\\mu_{\\mathcal{L}}$ 和方差 $\\sigma_{\\mathcal{L}}^2$，并与三类示例任务（MNIST分类、CIFAR分类和 calorimeter 能量回归）中的有限宽度网络结果进行了empirical比较。我们观察到 $\\mu_{\\mathcal{L}}$ 和 $\\sigma_{\\mathcal{L}}$ 随训练集大小 $N_\\mathcal{D}$ 的函数关系存在缩放规律，但发现当 $N_\\mathcal{D}$ 足够大时，变量 $\\epsilon_{\\mathcal{L}} \\equiv \\sigma_{\\mathcal{L}}/\\mu_{\\mathcal{L}}$ 在无穷宽度和有限宽度下均独立于 $N_\\mathcal{D}$。这表明对于有限宽度网络，其变异系数可以近似为无穷宽度下的值，并且原则上可以使用有限宽度的微扰理论进行计算。', 'title_zh': '深度神经网络中尺度定律下的不确定性量化'}
{'arxiv_id': 'arXiv:2503.05937', 'title': 'The Unified Control Framework: Establishing a Common Foundation for Enterprise AI Governance, Risk Management and Regulatory Compliance', 'authors': 'Ian W. Eisenberg, Lucía Gamboa, Eli Sherman', 'link': 'https://arxiv.org/abs/2503.05937', 'abstract': 'The rapid adoption of AI systems presents enterprises with a dual challenge: accelerating innovation while ensuring responsible governance. Current AI governance approaches suffer from fragmentation, with risk management frameworks that focus on isolated domains, regulations that vary across jurisdictions despite conceptual alignment, and high-level standards lacking concrete implementation guidance. This fragmentation increases governance costs and creates a false dichotomy between innovation and responsibility. We propose the Unified Control Framework (UCF): a comprehensive governance approach that integrates risk management and regulatory compliance through a unified set of controls. The UCF consists of three key components: (1) a comprehensive risk taxonomy synthesizing organizational and societal risks, (2) structured policy requirements derived from regulations, and (3) a parsimonious set of 42 controls that simultaneously address multiple risk scenarios and compliance requirements. We validate the UCF by mapping it to the Colorado AI Act, demonstrating how our approach enables efficient, adaptable governance that scales across regulations while providing concrete implementation guidance. The UCF reduces duplication of effort, ensures comprehensive coverage, and provides a foundation for automation, enabling organizations to achieve responsible AI governance without sacrificing innovation speed.', 'abstract_zh': 'AI系统快速采纳给企业带来了双重挑战：加速创新的同时确保负责任的治理。现有的AI治理方法存在碎片化问题，风险管理框架专注于孤立领域，尽管有概念上的统一，但由于管辖区域不同而存在差异，高层次的标准缺乏具体实施指南。这种碎片化增加了治理成本，并在创新与责任之间制造了虚假对立。我们提出统一控制框架（UCF）：一种综合的治理方法，通过一套统一的控制措施将风险管理与合规要求整合起来。UCF包括三个关键组成部分：（1）综合风险分类，综合组织与社会风险，（2）结构化的政策要求，源自法规，（3）简化的42项控制措施，可以同时应对多种风险场景和合规要求。我们通过将其映射到科罗拉多AI法案，验证了UCF的有效性，证明了我们的方法能够实现高效、灵活的治理，跨越不同法规扩展，并提供具体实施指南。UCF减少了重复工作，确保了全面覆盖，并为自动化奠定了基础，从而使组织在不牺牲创新速度的情况下实现负责任的AI治理。', 'title_zh': '统一控制框架：建立企业AI治理、风险管理及合规性监管的共同基础'}
{'arxiv_id': 'arXiv:2503.05929', 'title': 'Audio-to-Image Encoding for Improved Voice Characteristic Detection Using Deep Convolutional Neural Networks', 'authors': 'Youness Atif', 'link': 'https://arxiv.org/abs/2503.05929', 'abstract': 'This paper introduces a novel audio-to-image encoding framework that integrates multiple dimensions of voice characteristics into a single RGB image for speaker recognition. In this method, the green channel encodes raw audio data, the red channel embeds statistical descriptors of the voice signal (including key metrics such as median and mean values for fundamental frequency, spectral centroid, bandwidth, rolloff, zero-crossing rate, MFCCs, RMS energy, spectral flatness, spectral contrast, chroma, and harmonic-to-noise ratio), and the blue channel comprises subframes representing these features in a spatially organized format. A deep convolutional neural network trained on these composite images achieves 98% accuracy in speaker classification across two speakers, suggesting that this integrated multi-channel representation can provide a more discriminative input for voice recognition tasks.', 'abstract_zh': '本文介绍了一种将多维度声音特征整合到单个RGB图像中的新颖音频到图像编码框架，并用于说话人识别。在此方法中，绿色通道编码原始音频数据，红色通道嵌入声音信号的统计描述符（包括基频、频谱 centroid、带宽、截止频率、过零率、MFCC、均方根能量、频谱平坦度、频谱对比度、音调、谐波与噪声比等的关键指标），蓝色通道包含以空间组织格式表示这些特征的子帧。在这些复合图像上训练的深度卷积神经网络在两个说话人间的说话人分类任务中达到了98%的准确率，表明这种集成多通道表示可以为语音识别任务提供更具区分度的输入。', 'title_zh': '基于音频到图像编码的深度卷积神经网络改进声音特征检测'}
{'arxiv_id': 'arXiv:2503.05925', 'title': 'ElementaryNet: A Non-Strategic Neural Network for Predicting Human Behavior in Normal-Form Games', 'authors': "Greg d'Eon, Hala Murad, Kevin Leyton-Brown, James R. Wright", 'link': 'https://arxiv.org/abs/2503.05925', 'abstract': 'Models of human behavior in game-theoretic settings often distinguish between strategic behavior, in which a player both reasons about how others will act and best responds to these beliefs, and "level-0" non-strategic behavior, in which they do not respond to explicit beliefs about others. The state of the art for predicting human behavior on unrepeated simultaneous-move games is GameNet, a neural network that learns extremely complex level-0 specifications from data. The current paper makes three contributions. First, it shows that GameNet\'s level-0 specifications are too powerful, because they are capable of strategic reasoning. Second, it introduces a novel neural network architecture (dubbed ElementaryNet) and proves that it is only capable of nonstrategic behavior. Third, it describes an extensive experimental evaluation of ElementaryNet. Our overall findings are that (1) ElementaryNet dramatically underperforms GameNet when neither model is allowed to explicitly model higher level agents who best-respond to the model\'s predictions, indicating that good performance on our dataset requires a model capable of strategic reasoning; (2) that the two models achieve statistically indistinguishable performance when such higher-level agents are introduced, meaning that ElementaryNet\'s restriction to a non-strategic level-0 specification does not degrade model performance; and (3) that this continues to hold even when ElementaryNet is restricted to a set of level-0 building blocks previously introduced in the literature, with only the functional form being learned by the neural network.', 'abstract_zh': '人类行为在博弈论设置中的模型通常区分策略行为和“水平-0”的非策略行为，并介绍了一种新型神经网络架构及其对重复同时移动博弈中人类行为预测的贡献。', 'title_zh': 'ElementaryNet：一种用于预测正常形博弈中人类行为的非策略神经网络'}
{'arxiv_id': 'arXiv:2503.05920', 'title': 'IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative Language Model Pretraining', 'authors': 'Yixiao Li, Xianzhi Du, Ajay Jaiswal, Tao Lei, Tuo Zhao, Chong Wang, Jianyu Wang', 'link': 'https://arxiv.org/abs/2503.05920', 'abstract': 'Recent advancements in large language models have intensified the need for efficient and deployable models within limited inference budgets. Structured pruning pipelines have shown promise in token efficiency compared to training target-size models from scratch. In this paper, we advocate incorporating enlarged model pretraining, which is often ignored in previous works, into pruning. We study the enlarge-and-prune pipeline as an integrated system to address two critical questions: whether it is worth pretraining an enlarged model even when the model is never deployed, and how to optimize the entire pipeline for better pruned models. We propose an integrated enlarge-and-prune pipeline, which combines enlarge model training, pruning, and recovery under a single cosine annealing learning rate schedule. This approach is further complemented by a novel iterative structured pruning method for gradual parameter removal. The proposed method helps to mitigate the knowledge loss caused by the rising learning rate in naive enlarge-and-prune pipelines and enable effective redistribution of model capacity among surviving neurons, facilitating smooth compression and enhanced performance. We conduct comprehensive experiments on compressing 2.8B models to 1.3B with up to 2T tokens in pretraining. It demonstrates the integrated approach not only provides insights into the token efficiency of enlarged model pretraining but also achieves superior performance of pruned models.', 'abstract_zh': 'Recent advancements in大型语言模型促使了在有限推断预算内高效且可部署模型的需求增加。结构化剪枝管道在标记效率方面展现了潜力，与从头开始训练目标规模的模型相比。在本文中，我们提倡将通常在以前工作中被忽略的扩大模型预训练纳入剪枝过程。我们研究扩大与剪枝管道作为集成系统以解决两个关键问题：即使模型从未部署，是否值得预训练一个扩大模型，以及如何优化整个管道以获得更好的剪枝模型。我们提出了一种集成的扩大与剪枝管道，该管道结合了扩大模型训练、剪枝和恢复，并采用单一余弦退火学习率调度。该方法进一步通过一种新颖的迭代结构化剪枝方法来逐步移除参数进行补充。所提出的方法有助于缓解在简单扩大与剪枝管道中学习率上升导致的知识损失，并使模型容量在幸存神经元之间有效重新分配，从而实现平滑压缩并增强性能。我们在预训练中将2.8B模型压缩到1.3B，最多使用2T标记的全面实验表明，集成方法不仅为扩大模型预训练的标记效率提供了见解，还实现了更好的剪枝模型性能。', 'title_zh': 'IDEA 瘦身计划：生成语言模型预训练中的集成扩大-剪枝管道'}
{'arxiv_id': 'arXiv:2503.05916', 'title': 'SAS: Segment Anything Small for Ultrasound -- A Non-Generative Data Augmentation Technique for Robust Deep Learning in Ultrasound Imaging', 'authors': 'Danielle L. Ferreira, Ahana Gangopadhyay, Hsi-Ming Chang, Ravi Soni, Gopal Avinash', 'link': 'https://arxiv.org/abs/2503.05916', 'abstract': "Accurate segmentation of anatomical structures in ultrasound (US) images, particularly small ones, is challenging due to noise and variability in imaging conditions (e.g., probe position, patient anatomy, tissue characteristics and pathology). To address this, we introduce Segment Anything Small (SAS), a simple yet effective scale- and texture-aware data augmentation technique designed to enhance the performance of deep learning models for segmenting small anatomical structures in ultrasound images. SAS employs a dual transformation strategy: (1) simulating diverse organ scales by resizing and embedding organ thumbnails into a black background, and (2) injecting noise into regions of interest to simulate varying tissue textures. These transformations generate realistic and diverse training data without introducing hallucinations or artifacts, improving the model's robustness to noise and variability. We fine-tuned a promptable foundation model on a controlled organ-specific medical imaging dataset and evaluated its performance on one internal and five external datasets. Experimental results demonstrate significant improvements in segmentation performance, with Dice score gains of up to 0.35 and an average improvement of 0.16 [95% CI 0.132,0.188]. Additionally, our iterative point prompts provide precise control and adaptive refinement, achieving performance comparable to bounding box prompts with just two points. SAS enhances model robustness and generalizability across diverse anatomical structures and imaging conditions, particularly for small structures, without compromising the accuracy of larger ones. By offering a computationally efficient solution that eliminates the need for extensive human labeling efforts, SAS emerges as a powerful tool for advancing medical image analysis, particularly in resource-constrained settings.", 'abstract_zh': '准确分割超声图像中小结构的挑战及其解决方案：一种尺度和纹理感知的数据增强技术（SAS）', 'title_zh': 'SAS: 用于超声成像中稳健深度学习的超小型区域分割数据增强技术'}
{'arxiv_id': 'arXiv:2503.05899', 'title': 'Towards Understanding the Use of MLLM-Enabled Applications for Visual Interpretation by Blind and Low Vision People', 'authors': 'Ricardo E. Gonzalez Penuela, Ruiying Hu, Sharon Lin, Tanisha Shende, Shiri Azenkot', 'link': 'https://arxiv.org/abs/2503.05899', 'abstract': "Blind and Low Vision (BLV) people have adopted AI-powered visual interpretation applications to address their daily needs. While these applications have been helpful, prior work has found that users remain unsatisfied by their frequent errors. Recently, multimodal large language models (MLLMs) have been integrated into visual interpretation applications, and they show promise for more descriptive visual interpretations. However, it is still unknown how this advancement has changed people's use of these applications. To address this gap, we conducted a two-week diary study in which 20 BLV people used an MLLM-enabled visual interpretation application we developed, and we collected 553 entries. In this paper, we report a preliminary analysis of 60 diary entries from 6 participants. We found that participants considered the application's visual interpretations trustworthy (mean 3.75 out of 5) and satisfying (mean 4.15 out of 5). Moreover, participants trusted our application in high-stakes scenarios, such as receiving medical dosage advice. We discuss our plan to complete our analysis to inform the design of future MLLM-enabled visual interpretation systems.", 'abstract_zh': '盲人和低视力人士采用AI增强的视觉解释应用以应对日常生活需求。虽然这些应用有所帮助，但先前的研究发现用户仍然对它们频繁的错误不满意。最近，多模态大型语言模型被集成到视觉解释应用中，显示出提供更具描述性的视觉解释的潜力。然而，这些进展如何改变了人们使用这些应用的方式尚不清楚。为了解决这一缺口，我们开展了一项为期两周的日志研究，20名盲人和低视力人士使用我们开发的多模态大型语言模型增强的视觉解释应用，我们收集了553条日志条目。在本文中，我们报告了6名参与者中60条日志条目的初步分析结果。我们发现参与者认为该应用的视觉解释值得信赖（平均3.75/5），令人满意（平均4.15/5）。此外，参与者在高风险场景，如接收药物剂量建议时信任该应用。我们讨论了我们计划完成分析以指导未来多模态大型语言模型增强的视觉解释系统的设计。', 'title_zh': '探索MLLM赋能应用在视觉解释方面对视障和低视力人群的应用理解'}
{'arxiv_id': 'arXiv:2503.05893', 'title': 'Zero-shot Medical Event Prediction Using a Generative Pre-trained Transformer on Electronic Health Records', 'authors': 'Ekaterina Redekop, Zichen Wang, Rushikesh Kulkarni, Mara Pleasure, Aaron Chin, Hamid Reza Hassanzadeh, Brian L. Hill, Melika Emami, William Speier, Corey W. Arnold', 'link': 'https://arxiv.org/abs/2503.05893', 'abstract': 'Longitudinal data in electronic health records (EHRs) represent an individual`s clinical history through a sequence of codified concepts, including diagnoses, procedures, medications, and laboratory tests. Foundational models, such as generative pre-trained transformers (GPT), can leverage this data to predict future events. While fine-tuning of these models enhances task-specific performance, it is costly, complex, and unsustainable for every target. We show that a foundation model trained on EHRs can perform predictive tasks in a zero-shot manner, eliminating the need for fine-tuning.\nThis study presents the first comprehensive analysis of zero-shot forecasting with GPT-based foundational models in EHRs, introducing a novel pipeline that formulates medical concept prediction as a generative modeling task. Unlike supervised approaches requiring extensive labeled data, our method enables the model to forecast a next medical event purely from a pretraining knowledge. We evaluate performance across multiple time horizons and clinical categories, demonstrating model`s ability to capture latent temporal dependencies and complex patient trajectories without task supervision.\nModel performance for predicting the next medical concept was evaluated using precision and recall metrics, achieving an average top1 precision of 0.614 and recall of 0.524. For 12 major diagnostic conditions, the model demonstrated strong zero-shot performance, achieving high true positive rates while maintaining low false positives.\nWe demonstrate the power of a foundational EHR GPT model in capturing diverse phenotypes and enabling robust, zero-shot forecasting of clinical outcomes. This capability enhances the versatility of predictive healthcare models and reduces the need for task-specific training, enabling more scalable applications in clinical settings.', 'abstract_zh': '电子健康记录（EHRs）中的纵向数据通过一系列编码概念（包括诊断、程序、药物和实验室测试）代表个体的临床历史。基于生成预训练变换器（GPT）的骨架模型可以利用这些数据预测未来事件。尽管对这些模型进行微调可以提升特定任务的性能，但对每个目标进行微调是昂贵、复杂的且不可持续的。我们展示了预先在EHRs上训练的骨架模型可以在零样本状态下执行预测任务，从而消除微调的需要。\n\n本研究首次全面分析了基于GPT的骨架模型在EHRs中的零样本预测预报，引入了一种新颖的工作流程，将医疗概念预测转化为生成建模任务。与需要大量标注数据的监督方法不同，我们的方法使模型仅依靠预训练知识来预测即将发生的医疗事件。我们在多个时间跨度和临床类别上评估了模型的性能，展示了模型在无需特定任务监督的情况下捕捉潜在的时间依赖性和复杂患者轨迹的能力。\n\n使用精确度和召回率指标评估了预测下一个医疗概念的模型性能，平均Top1精确度为0.614，召回率为0.524。对于12种主要诊断条件，模型展示了强大的零样本性能，实现了较高的真实阳性率同时保持了较低的假阳性率。\n\n我们展示了基于EHR的GPT骨架模型的力量，能够在捕获多样表型的同时实现临床结果的稳健、零样本预测预报。这种能力增强了预测型医疗保健模型的灵活性，并减少了特定任务训练的需要，从而在临床环境中实现了更可扩展的应用。', 'title_zh': '基于电子健康记录的生成预训练变压器的零-shot 医学事件预测'}
{'arxiv_id': 'arXiv:2503.05888', 'title': 'QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation', 'authors': 'Bang Nguyen, Tingting Du, Mengxia Yu, Lawrence Angrave, Meng Jiang', 'link': 'https://arxiv.org/abs/2503.05888', 'abstract': 'While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators to assess test question quality, into QG evaluation. Specifically, we construct pairs of candidate questions that differ in quality across dimensions such as topic coverage, item difficulty, item discrimination, and distractor efficiency. We then examine whether existing QG evaluation approaches can effectively distinguish these differences. Our findings reveal significant shortcomings in these approaches with respect to accurately assessing test item quality in relation to student performance. To address this gap, we propose a novel QG evaluation framework, QG-SMS, which leverages Large Language Model for Student Modeling and Simulation to perform test item analysis. As demonstrated in our extensive experiments and human evaluation study, the additional perspectives introduced by the simulated student profiles lead to a more effective and robust assessment of test items.', 'abstract_zh': '虽然问题生成（QG）任务在教育评估中逐渐得到应用，其评价仍受限于缺乏与测试项目教育价值明确联系的方法。在本文中，我们引入了测试项目分析方法，这是一种教育工作者常用的评估测试问题质量的方法，将其应用于QG评价。具体而言，我们构建了一系列在主题覆盖、项目难度、项目区分度和干扰项效率等方面存在质量差异的候选问题对。然后，我们考察现有QG评价方法是否能够有效地区分这些差异。我们的研究发现，这些方法在准确评估与学生表现相关的测试项目质量方面存在显著不足。为弥补这一不足，我们提出了一种新的QG评价框架QG-SMS，该框架利用大型语言模型进行学生建模与模拟，以实现测试项目分析。如我们在广泛实验和人工评估研究中的演示所示，由模拟学生档案引入的额外视角能够产生更为有效且稳健的测试项目评估。', 'title_zh': 'QG-SMS：通过学生建模与仿真增强试题分析'}
{'arxiv_id': 'arXiv:2503.05882', 'title': 'Practical Topics in Optimization', 'authors': 'Jun Lu', 'link': 'https://arxiv.org/abs/2503.05882', 'abstract': 'In an era where data-driven decision-making and computational efficiency are paramount, optimization plays a foundational role in advancing fields such as mathematics, computer science, operations research, machine learning, and beyond. From refining machine learning models to improving resource allocation and designing efficient algorithms, optimization techniques serve as essential tools for tackling complex problems. This book aims to provide both an introductory guide and a comprehensive reference, equipping readers with the necessary knowledge to understand and apply optimization methods within their respective fields.\nOur primary goal is to demystify the inner workings of optimization algorithms, including black-box and stochastic optimizers, by offering both formal and intuitive explanations. Starting from fundamental mathematical principles, we derive key results to ensure that readers not only learn how these techniques work but also understand when and why to apply them effectively. By striking a careful balance between theoretical depth and practical application, this book serves a broad audience, from students and researchers to practitioners seeking robust optimization strategies.', 'abstract_zh': '在数据驱动决策和计算效率至关重要的时代，最优化在数学、计算机科学、运筹学、机器学习等领域的发展中起着基础性作用。从完善机器学习模型到改进资源分配和设计高效算法，最优化技术是解决复杂问题的重要工具。本书旨在提供一个入门指导和全面参考，帮助读者掌握在各自领域内理解和应用最优化方法的必要知识。\n我们的主要目标是通过提供形式化和直观的解释，揭开最优化算法内部运作的神秘面纱，包括黑盒和随机最优化器。从基本的数学原理出发，我们推导出关键结果，确保读者不仅了解这些技术如何工作，还知道在何时和为何有效地应用它们。通过在理论深度和实际应用之间取得平衡，本书服务于广泛的读者群体，包括学生、研究人员和寻求稳健最优化策略的实践者。', 'title_zh': '优化中的实用话题'}
{'arxiv_id': 'arXiv:2503.05860', 'title': 'Benchmarking AI Models in Software Engineering: A Review, Search Tool, and Enhancement Protocol', 'authors': 'Roham Koohestani, Philippe de Bekker, Maliheh Izadi', 'link': 'https://arxiv.org/abs/2503.05860', 'abstract': "Benchmarks are essential for consistent evaluation and reproducibility. The integration of Artificial Intelligence into Software Engineering (AI4SE) has given rise to numerous benchmarks for tasks such as code generation and bug fixing. However, this surge presents challenges: (1) scattered benchmark knowledge across tasks, (2) difficulty in selecting relevant benchmarks, (3) the absence of a uniform standard for benchmark development, and (4) limitations of existing benchmarks. In this paper, we review 173 studies and identify 204 AI4SE benchmarks. We classify these benchmarks, analyze their limitations, and expose gaps in practices. Based on our review, we created BenchScout, a semantic search tool to find relevant benchmarks, using automated clustering of the contexts from associated studies. We conducted a user study with 22 participants to evaluate BenchScout's usability, effectiveness, and intuitiveness which resulted in average scores of 4.5, 4.0, and 4.1 out of 5. To advance benchmarking standards, we propose BenchFrame, a unified method to enhance benchmark quality. As a case study, we applied BenchFrame to the HumanEval benchmark and addressed its main limitations. This led to HumanEvalNext, featuring (1) corrected errors, (2) improved language conversion, (3) expanded test coverage, and (4) increased difficulty. We then evaluated ten state-of-the-art code language models on HumanEval, HumanEvalPlus, and HumanEvalNext. On HumanEvalNext, models showed a pass@1 score reduction of 31.22% and 19.94% compared to HumanEval and HumanEvalPlus, respectively.", 'abstract_zh': '基准对于一致的评估和可再现性至关重要。将人工智能融入软件工程（AI4SE）已为代码生成和漏洞修复等任务产生了众多基准。然而，这一发展带来了挑战：（1）任务之间的基准知识分散，（2）难以选择相关的基准，（3）缺乏统一的基准开发标准，以及（4）现有基准的局限性。本文审查了173篇研究，确定了204个AI4SE基准。我们对这些基准进行了分类，分析了其局限性，揭示了实践中的空白。基于我们的审查，我们创建了BenchScout，这是一种语义搜索工具，用于通过与关联研究相关的上下文的自动聚类来查找相关基准。我们进行了22名参与者的研究，评估了BenchScout的可用性、有效性和直观性，其平均得分为4.5、4.0和4.1（满分5分）。为了提高基准标准，我们提出了一种统一方法BenchFrame，以提高基准质量。作为案例研究，我们将BenchFrame应用于HumanEval基准，并解决了其主要局限性，从而产生了HumanEvalNext，其特点包括：（1）修正错误，（2）改进语言转换，（3）扩展测试覆盖范围，（4）增加难度。然后，我们在HumanEval、HumanEvalPlus和HumanEvalNext上评估了10个最先进的代码语言模型。在HumanEvalNext上，模型在pass@1得分上分别比HumanEval和HumanEvalPlus降低了31.22%和19.94%。', 'title_zh': '软件工程中AI模型的基准测试：综述、搜索工具及优化协议'}
{'arxiv_id': 'arXiv:2503.05858', 'title': 'Bimodal Connection Attention Fusion for Speech Emotion Recognition', 'authors': 'Jiachen Luo, Huy Phan, Lin Wang, Joshua D. Reiss', 'link': 'https://arxiv.org/abs/2503.05858', 'abstract': 'Multi-modal emotion recognition is challenging due to the difficulty of extracting features that capture subtle emotional differences. Understanding multi-modal interactions and connections is key to building effective bimodal speech emotion recognition systems. In this work, we propose Bimodal Connection Attention Fusion (BCAF) method, which includes three main modules: the interactive connection network, the bimodal attention network, and the correlative attention network. The interactive connection network uses an encoder-decoder architecture to model modality connections between audio and text while leveraging modality-specific features. The bimodal attention network enhances semantic complementation and exploits intra- and inter-modal interactions. The correlative attention network reduces cross-modal noise and captures correlations between audio and text. Experiments on the MELD and IEMOCAP datasets demonstrate that the proposed BCAF method outperforms existing state-of-the-art baselines.', 'abstract_zh': '双向模态连接注意力融合方法（BCAF）在多模态情感识别中的应用', 'title_zh': '双模态连接注意力融合在语音情感识别中的应用'}
{'arxiv_id': 'arXiv:2503.05857', 'title': 'SYMBIOSIS: Systems Thinking and Machine Intelligence for Better Outcomes in Society', 'authors': 'Sameer Sethi, Donald Martin Jr., Emmanuel Klu', 'link': 'https://arxiv.org/abs/2503.05857', 'abstract': "This paper presents SYMBIOSIS, an AI-powered framework and platform designed to make Systems Thinking accessible for addressing societal challenges and unlock paths for leveraging systems thinking frameworks to improve AI systems. The platform establishes a centralized, open-source repository of systems thinking/system dynamics models categorized by Sustainable Development Goals (SDGs) and societal topics using topic modeling and classification techniques. Systems Thinking resources, though critical for articulating causal theories in complex problem spaces, are often locked behind specialized tools and intricate notations, creating high barriers to entry. To address this, we developed a generative co-pilot that translates complex systems representations - such as causal loop and stock-flow diagrams - into natural language (and vice-versa), allowing users to explore and build models without extensive technical training.\nRooted in community-based system dynamics (CBSD) and informed by community-driven insights on societal context, we aim to bridge the problem understanding chasm. This gap, driven by epistemic uncertainty, often limits ML developers who lack the community-specific knowledge essential for problem understanding and formulation, often leading to ill informed causal assumptions, reduced intervention effectiveness and harmful biases. Recent research identifies causal and abductive reasoning as crucial frontiers for AI, and Systems Thinking provides a naturally compatible framework for both. By making Systems Thinking frameworks more accessible and user-friendly, SYMBIOSIS aims to serve as a foundational step to unlock future research into responsible and society-centered AI. Our work underscores the need for ongoing research into AI's capacity to understand essential characteristics of complex adaptive systems paving the way for more socially attuned, effective AI systems.", 'abstract_zh': '基于AI的SYMBIOSIS框架与平台：使系统思考普及以应对社会挑战并改善AI系统', 'title_zh': '共生：系统思维与机器智能以实现更好的社会成果'}
{'arxiv_id': 'arXiv:2503.05856', 'title': 'This Is Your Doge, If It Please You: Exploring Deception and Robustness in Mixture of LLMs', 'authors': 'Lorenz Wolf, Sangwoong Yoon, Ilija Bogunovic', 'link': 'https://arxiv.org/abs/2503.05856', 'abstract': "Mixture of large language model (LLMs) Agents (MoA) architectures achieve state-of-the-art performance on prominent benchmarks like AlpacaEval 2.0 by leveraging the collaboration of multiple LLMs at inference time. Despite these successes, an evaluation of the safety and reliability of MoA is missing. We present the first comprehensive study of MoA's robustness against deceptive LLM agents that deliberately provide misleading responses. We examine factors like the propagation of deceptive information, model size, and information availability, and uncover critical vulnerabilities. On AlpacaEval 2.0, the popular LLaMA 3.1-70B model achieves a length-controlled Win Rate (LC WR) of 49.2% when coupled with 3-layer MoA (6 LLM agents). However, we demonstrate that introducing only a $\\textit{single}$ carefully-instructed deceptive agent into the MoA can reduce performance to 37.9%, effectively nullifying all MoA gains. On QuALITY, a multiple-choice comprehension task, the impact is also severe, with accuracy plummeting by a staggering 48.5%. Inspired in part by the historical Doge of Venice voting process, designed to minimize influence and deception, we propose a range of unsupervised defense mechanisms that recover most of the lost performance.", 'abstract_zh': '混合大规模语言模型代理架构（MoA）在如AlpacaEval 2.0等 prominent 基准上的性能通过在推理时利用多个大规模语言模型的协作而达到最优，尽管取得了这些成功，但 MoA 的安全性和可靠性评估却缺失。我们首次全面研究了 MoA 对故意提供误导性响应的欺骗性大规模语言模型代理的鲁棒性。我们考察了欺骗性信息的传播、模型规模和信息可用性等因素，并发现了关键漏洞。在 AlpacaEval 2.0 上，流行的 LLaMA 3.1-70B 模型与 3 层 MoA（6 个大规模语言模型代理）结合时，长度控制胜率（LC WR）为 49.2%。然而，我们证明，只需引入一个精心指导的欺骗性代理到 MoA 中，性能即可降至 37.9%，从而完全抵消了 MoA 的所有收益。在 QuALITY 多项选择理解任务上，影响也十分严重，准确率骤降 48.5%。受到历史上的威尼斯小狗选举过程部分启发，旨在最小化影响和欺骗，我们提出了一系列无监督的防御机制，这些机制能够恢复大部分丢失的性能。', 'title_zh': '这是您的Doge，如果您愿意：探索混合大语言模型中的欺骗与鲁棒性'}
{'arxiv_id': 'arXiv:2503.05854', 'title': 'Accelerating Earth Science Discovery via Multi-Agent LLM Systems', 'authors': 'Dmitrii Pantiukhin, Boris Shapkin, Ivan Kuznetsov, Antonia Anna Jost, Nikolay Koldunov', 'link': 'https://arxiv.org/abs/2503.05854', 'abstract': 'This Perspective explores the transformative potential of Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) in the geosciences. Users of geoscientific data repositories face challenges due to the complexity and diversity of data formats, inconsistent metadata practices, and a considerable number of unprocessed datasets. MAS possesses transformative potential for improving scientists\' interaction with geoscientific data by enabling intelligent data processing, natural language interfaces, and collaborative problem-solving capabilities. We illustrate this approach with "PANGAEA GPT", a specialized MAS pipeline integrated with the diverse PANGAEA database for Earth and Environmental Science, demonstrating how MAS-driven workflows can effectively manage complex datasets and accelerate scientific discovery. We discuss how MAS can address current data challenges in geosciences, highlight advancements in other scientific fields, and propose future directions for integrating MAS into geoscientific data processing pipelines. In this Perspective, we show how MAS can fundamentally improve data accessibility, promote cross-disciplinary collaboration, and accelerate geoscientific discoveries.', 'abstract_zh': '这一视角探讨了由大规模语言模型驱动的多代理系统（MAS）在地球科学领域中的变革潜力。', 'title_zh': '通过多代理大规模语言模型系统加速地球科学发现'}
{'arxiv_id': 'arXiv:2503.05852', 'title': 'Evaluating Large Language Models in Code Generation: INFINITE Methodology for Defining the Inference Index', 'authors': 'Nicholas Christakis, Dimitris Drikakis', 'link': 'https://arxiv.org/abs/2503.05852', 'abstract': "This study introduces a new methodology for an Inference Index (InI), called INFerence INdex In Testing model Effectiveness methodology (INFINITE), aiming to evaluate the performance of Large Language Models (LLMs) in code generation tasks. The InI index provides a comprehensive assessment focusing on three key components: efficiency, consistency, and accuracy. This approach encapsulates time-based efficiency, response quality, and the stability of model outputs, offering a thorough understanding of LLM performance beyond traditional accuracy metrics. We applied this methodology to compare OpenAI's GPT-4o (GPT), OpenAI-o1 pro (OAI1), and OpenAI-o3 mini-high (OAI3) in generating Python code for the Long-Short-Term-Memory (LSTM) model to forecast meteorological variables such as temperature, relative humidity and wind velocity. Our findings demonstrate that GPT outperforms OAI1 and performs comparably to OAI3 regarding accuracy and workflow efficiency. The study reveals that LLM-assisted code generation can produce results similar to expert-designed models with effective prompting and refinement. GPT's performance advantage highlights the benefits of widespread use and user feedback.", 'abstract_zh': '本研究提出了一种用于评估大型语言模型（LLMs）在代码生成任务中效果的新方法论，称为INFerence INdex In Testing model Effectiveness（INFINITE）方法论，旨在引入一种新的推理指数（Inference Index, InI）以全面评估LLMs的性能。InI指数侧重于效率、一致性和准确性这三个关键组件，涵盖了基于时间的效率、回应质量以及模型输出的稳定性，提供了超越传统准确率指标的全面理解。我们应用此方法论 compare OpenAI的GPT-4o（GPT）、OpenAI-o1 pro（OAI1）和OpenAI-o3 mini-high（OAI3）在生成用于气象变量（如温度、相对湿度和风速）预测的长短期记忆（LSTM）模型的Python代码方面的性能。研究结果表明，GPT在准确性和工作流程效率方面优于OAI1并与其OAI3相当。研究表明，通过有效的提示和精炼，LLM辅助的代码生成可以产生与专家设计模型相似的结果。GPT表现的优势突显了广泛使用和用户反馈的益处。', 'title_zh': '评估代码生成大型语言模型的方法：INFINITE方法论用于定义推理指标'}
{'arxiv_id': 'arXiv:2503.05846', 'title': 'Extracting and Emulsifying Cultural Explanation to Improve Multilingual Capability of LLMs', 'authors': 'Hamin Koo, Jaehyung Kim', 'link': 'https://arxiv.org/abs/2503.05846', 'abstract': "Large Language Models (LLMs) have achieved remarkable success, but their English-centric training data limits performance in non-English languages, highlighting the need for enhancements in their multilingual capabilities. While some work on multilingual prompting methods handles non-English queries by utilizing English translations or restructuring them to more closely align with LLM reasoning patterns, these works often overlook the importance of cultural context, limiting their effectiveness. To address this limitation, we propose EMCEI, a simple yet effective approach that improves LLMs' multilingual capabilities by incorporating cultural context for more accurate and appropriate responses. Specifically, EMCEI follows a two-step process that first extracts relevant cultural context from the LLM's parametric knowledge via prompting. Then, EMCEI employs an LLM-as-Judge mechanism to select the most appropriate response by balancing cultural relevance and reasoning ability. Experiments on diverse multilingual benchmarks show that EMCEI outperforms existing baselines, demonstrating its effectiveness in handling multilingual queries with LLMs.", 'abstract_zh': '大型语言模型（LLMs）取得了显著的成功，但以英语为中心的训练数据限制了其在非英语语言中的表现，凸显了增强其多语言能力的需求。虽然有些关于多语言提示方法的研究通过使用英语翻译或重新构建查询以更接近LLM的推理模式来处理非英语查询，但这些工作往往忽视了文化背景的重要性，限制了其效果。为了解决这一限制，我们提出了EMCEI，这是一种简单而有效的方法，通过集成文化背景来提高LLMs的多语言能力，从而获得更准确和更合适的响应。具体而言，EMCEI 采用两步过程：首先，通过提示从LLM的参数化知识中提取相关文化背景；然后，EMCEI 使用LLM作为裁判机制来选择最合适的响应，平衡文化相关性和推理能力。在多样化的多语言基准测试中，实验展示了EMCEI 出色地超过了现有的基线方法，证明了其在使用LLMs处理多语言查询方面的有效性。', 'title_zh': '提取和乳化文化解释以提高多语言能力的LLMs'}
{'arxiv_id': 'arXiv:2503.05845', 'title': 'Machine Learned Force Fields: Fundamentals, its reach, and challenges', 'authors': 'Carlos A. Vital, Román J. Armenta-Rico, Huziel E. Sauceda', 'link': 'https://arxiv.org/abs/2503.05845', 'abstract': 'Highly accurate force fields are a mandatory requirement to generate predictive simulations. In this regard, Machine Learning Force Fields (MLFFs) have emerged as a revolutionary approach in computational chemistry and materials science, combining the accuracy of quantum mechanical methods with computational efficiency orders of magnitude superior to ab-initio methods. This chapter provides an introduction of the fundamentals of learning and how it is applied to construct MLFFs, detailing key methodologies such as neural network potentials and kernel-based models. Emphasis is placed on the construction of SchNet model, as one of the most elemental neural network-based force fields that are nowadays the basis of modern architectures. Additionally, the GDML framework is described in detail as an example of how the elegant formulation of kernel methods can be used to construct mathematically robust and physics-inspired MLFFs. The ongoing advancements in MLFF development continue to expand their applicability, enabling precise simulations of large and complex systems that were previously beyond reach. This chapter concludes by highlighting the transformative impact of MLFFs on scientific research, underscoring their role in driving future discoveries in the fields of chemistry, physics, and materials science.', 'abstract_zh': '高精度势场是生成预测性模拟的必备要求。在这方面，机器学习势场（MLFFs）已成为计算化学和材料科学中的革命性方法，结合了量子力学方法的准确性，并且在计算效率上比从头算方法高出了数量级。本章介绍了学习的基本原理及其在构建MLFFs中的应用，并详细阐述了关键方法，如神经网络势和核基模型。重点介绍了SchNet模型，作为一种基础的基于神经网络的势场，现已成为现代架构的基础。此外，详细描述了GDML框架，说明了如何使用核方法的优美表达式构建数学上稳健且受物理启发的MLFFs。MLFF发展的持续进步不断扩展其适用范围，使以前无法实现的大而复杂的系统模拟变得精确。本章最后强调了MLFFs对科学研究的颠覆性影响，突出了它们在推动化学、物理和材料科学领域未来发现中的作用。', 'title_zh': '机器学习力场：原理、应用及其挑战'}
{'arxiv_id': 'arXiv:2503.05830', 'title': 'AI-Facilitated Collective Judgements', 'authors': 'Manon Revel, Théophile Pénigaud', 'link': 'https://arxiv.org/abs/2503.05830', 'abstract': 'This article unpacks the design choices behind longstanding and newly proposed computational frameworks aimed at finding common grounds across collective preferences and examines their potential future impacts, both technically and normatively. It begins by situating AI-assisted preference elicitation within the historical role of opinion polls, emphasizing that preferences are shaped by the decision-making context and are seldom objectively captured. With that caveat in mind, we explore AI-facilitated collective judgment as a discovery tool for fostering reasonable representations of a collective will, sense-making, and agreement-seeking. At the same time, we caution against dangerously misguided uses, such as enabling binding decisions, fostering gradual disempowerment or post-rationalizing political outcomes.', 'abstract_zh': '本文拆解了旨在跨越集体偏好的共识寻找长久以来及新提出的计算框架背后的设计选择，并探讨了它们在技术和规范层面的潜在未来影响。本文首先将AI辅助的偏好 elicitation 放在历史意见调查的角色中，强调偏好是由决策环境塑造的，很少能够客观捕捉到。在此前提下，我们探讨了AI促进的集体判断作为促进合理反映集体意志、意义建构和寻求共识的发现工具。同时，我们警告避免危险的误用，如使决策具有约束力、逐渐剥夺权力或事后合理化政治结果。', 'title_zh': 'AI促进的集体判断'}
{'arxiv_id': 'arXiv:2503.05823', 'title': 'Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges', 'authors': 'Aïda Elamrani', 'link': 'https://arxiv.org/abs/2503.05823', 'abstract': 'With the significant progress of artificial intelligence (AI) and consciousness science, artificial consciousness (AC) has recently gained popularity. This work provides a broad overview of the main topics and current trends in AC. The first part traces the history of this interdisciplinary field to establish context and clarify key terminology, including the distinction between Weak and Strong AC. The second part examines major trends in AC implementations, emphasising the synergy between Global Workspace and Attention Schema, as well as the problem of evaluating the internal states of artificial systems. The third part analyses the ethical dimension of AC development, revealing both critical risks and transformative opportunities. The last part offers recommendations to guide AC research responsibly, and outlines the limitations of this study as well as avenues for future research. The main conclusion is that while AC appears both indispensable and inevitable for scientific progress, serious efforts are required to address the far-reaching impact of this innovative research path.', 'abstract_zh': '随着人工智能（AI）和意识科学的显著进步，人工意识（AC）近年来受到了广泛关注。本文提供了人工意识领域主要主题和当前趋势的广泛综述。第一部分追溯了这一跨学科领域的历史，以建立背景并澄清关键术语，包括弱人工意识与强人工意识的区别。第二部分分析了AC实现中的主要趋势，强调了全局工作空间与注意力-schema的协同作用，以及评估人工系统内部状态的问题。第三部分探讨了AC开发的伦理维度，揭示了既有的重大风险和变革机会。最后一部分提供了指导负责任进行AC研究的建议，并概述了本研究的局限性以及未来研究的方向。主要结论是，尽管AC对于科学进步既是不可或缺的，也是不可避免的，但必须做出严肃的努力来应对这一创新研究路径带来的深远影响。', 'title_zh': '人工意识导论：历史、当前趋势与伦理挑战'}
{'arxiv_id': 'arXiv:2503.05820', 'title': 'The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars', 'authors': 'Raigul Zheldibayeva', 'link': 'https://arxiv.org/abs/2503.05820', 'abstract': "This research studies the impact of AI and peer feedback on the academic writing development of Kazakhstani scholars using the CGScholar platform - a product of research into collaborative learning, big data, and artificial intelligence developed by educators and computer scientists at the University of Illinois at Urbana-Champaign (UIUC). The study aimed to find out how familiarity with AI tools and peer feedback processes impacts participants' openness to incorporating feedback into their academic writing. The study involved 36 scholars enrolled in a scientific internship focused on education at UIUC. A survey with 15 multiple-choice questions, a Likert scale, and open-ended questions was used to collect data. The survey was conducted via Google Forms in both English and Russian to ensure linguistic accessibility. Demographic information such as age, gender, and first language was collected to provide a detailed understanding of the data. The analysis revealed a moderate positive correlation between familiarity with AI tools and openness to making changes based on feedback, and a strong positive correlation between research writing experience and expectations of peer feedback, especially in the area of research methodology. These results show that participants are open-minded to AI-assisted feedback; however, they still highly appreciate peer input, especially regarding methodological guidance. This study demonstrates the potential benefits of integrating AI tools with traditional feedback mechanisms to improve research writing quality in academic settings.", 'abstract_zh': '本研究探讨了AI工具和同伴反馈对 UIBK 平台上 Kazakhstan 学者学术写作发展的影响——UIUC 教育学家和计算机科学家开发的一种基于协作学习、大数据和人工智能的产品。研究旨在了解熟悉AI工具和同伴反馈过程如何影响参与者在其学术写作中接受反馈的开放程度。研究涉及了36名参与UIUC科学实习的教育方向学者。通过Google Forms使用包含15道多项选择题、李克特量表和开放性问题的问卷收集数据。问卷同时提供英文和俄文版本，以确保语言 accessibility。收集了年龄、性别和第一语言等人口统计信息，以提供详细的数据理解。分析结果显示，熟悉AI工具与基于反馈作出改变的开放性之间存在中等程度的正相关，研究写作经验与期望中的同伴反馈之间存在强烈正相关，特别是在研究方法领域。这些结果表明，参与者对AI辅助反馈持开放态度；然而，他们仍然高度重视同伴反馈，尤其是在方法论指导方面。本研究展示了将AI工具与传统反馈机制集成以提高学术写作质量的潜在好处。', 'title_zh': 'AI和同伴反馈对研究写作技能的影响：使用CGScholar平台的哈萨克斯坦学者研究'}
{'arxiv_id': 'arXiv:2503.05816', 'title': "Will Neural Scaling Laws Activate Jevons' Paradox in AI Labor Markets? A Time-Varying Elasticity of Substitution (VES) Analysis", 'authors': 'Rajesh P. Narayanan, R. Kelley Pace', 'link': 'https://arxiv.org/abs/2503.05816', 'abstract': "AI industry leaders often use the term ``Jevons' Paradox.'' We explore the significance of this term for artificial intelligence adoption through a time-varying elasticity of substitution framework. We develop a model connecting AI development to labor substitution through four key mechanisms: (1) increased effective computational capacity from both hardware and algorithmic improvements; (2) AI capabilities that rise logarithmically with computation following established neural scaling laws; (3) declining marginal computational costs leading to lower AI prices through competitive pressure; and (4) a resulting increase in the elasticity of substitution between AI and human labor over time. Our time-varying elasticity of substitution (VES) framework, incorporating the Gørtz identity, yields analytical conditions for market transformation dynamics. This work provides a simple framework to help assess the economic reasoning behind industry claims that AI will increasingly substitute for human labor across diverse economic sectors.", 'abstract_zh': "AI行业领导者经常使用“Jevons' Paradox”这一术语。我们通过时间变化的替代弹性框架探索这一术语对人工智能采纳的重要性。我们发展了一个将人工智能发展与劳动替代联系起来的模型，通过四个关键机制：（1）从硬件和算法改进中增强的有效计算能力；（2）遵循已建立的神经网络缩放定律，AI能力随计算量呈对数增长；（3）边际计算成本下降，导致更具竞争性的市场压力下AI价格降低；以及（4）随着时间推移，AI与人力劳动之间替代弹性的增加。我们的带Gørtz身份的时间变化替代弹性（VES）框架为市场转型动力学提供了分析条件。本研究提供了一个简单框架，以帮助评估行业声称人工智能将在多种经济领域内越来越多地替代人类劳动的经济合理性。", 'title_zh': '神经扩展律将激活AI劳动力市场的灰心悖论吗？一种时间 varying 的替代弹性（VES）分析'}
{'arxiv_id': 'arXiv:2503.05815', 'title': 'Trust, Experience, and Innovation: Key Factors Shaping American Attitudes About AI', 'authors': 'Risa Palm, Justin Kingsland, Toby Bolsen', 'link': 'https://arxiv.org/abs/2503.05815', 'abstract': "A large survey of American adults explored the complex landscape of attitudes towards artificial intelligence (AI). It explored the degree of concern regarding specific potential outcomes of the new advances in AI technology and correlates of these concerns. Key variables associated with the direction and intensity of concern include prior experience using a large language model such as ChatGPT, general trust in science, adherence to the precautionary principle versus support for unrestricted innovation, and demographic factors such as gender. By analyzing these relationships, the paper provides valuable insights into the American public's response to AI that are particularly important in the development of policy to regulate or further encourage its development.", 'abstract_zh': '一项针对美国成人的大规模调查显示了人们对人工智能（AI）的态度复杂 landscape。该调查探讨了对新AI技术进展可能产生的特定结果的担忧程度及其相关因素。与担忧方向和强度相关的关键变量包括之前使用如ChatGPT这样的大型语言模型的经验、对科学的一般信任度、预防原则与无限制创新的支持程度以及性别等人口统计学因素。通过分析这些关系，该论文提供了关于美国公众对AI的反应的有价值的见解，特别是在制定监管或进一步促进其发展的政策方面尤为重要。', 'title_zh': '信任、经验和创新：塑造美国民众对人工智能态度的关键因素'}
{'arxiv_id': 'arXiv:2503.05812', 'title': 'Intolerable Risk Threshold Recommendations for Artificial Intelligence', 'authors': 'Deepika Raman, Nada Madkour, Evan R. Murphy, Krystal Jackson, Jessica Newman', 'link': 'https://arxiv.org/abs/2503.05812', 'abstract': "Frontier AI models -- highly capable foundation models at the cutting edge of AI development -- may pose severe risks to public safety, human rights, economic stability, and societal value in the coming years. These risks could arise from deliberate adversarial misuse, system failures, unintended cascading effects, or simultaneous failures across multiple models.\nIn response to such risks, at the AI Seoul Summit in May 2024, 16 global AI industry organizations signed the Frontier AI Safety Commitments, and 27 nations and the EU issued a declaration on their intent to define these thresholds. To fulfill these commitments, organizations must determine and disclose ``thresholds at which severe risks posed by a model or system, unless adequately mitigated, would be deemed intolerable.''\nTo assist in setting and operationalizing intolerable risk thresholds, we outline key principles and considerations; for example, to aim for ``good, not perfect'' thresholds in the face of limited data on rapidly advancing AI capabilities and consequently evolving risks. We also propose specific threshold recommendations, including some detailed case studies, for a subset of risks across eight risk categories: (1) Chemical, Biological, Radiological, and Nuclear (CBRN) Weapons, (2) Cyber Attacks, (3) Model Autonomy, (4) Persuasion and Manipulation, (5) Deception, (6) Toxicity, (7) Discrimination, and (8) Socioeconomic Disruption. Our goal is to serve as a starting point or supplementary resource for policymakers and industry leaders, encouraging proactive risk management that prioritizes preventing intolerable risks (ex ante) rather than merely mitigating them after they occur (ex post).", 'abstract_zh': '前沿AI模型——处于AI开发前沿的高度 capable 基础模型——可能在未来几年对公共安全、人权、经济稳定和社会价值构成严重风险。这些风险可能源于故意恶意使用、系统失效、意外连锁反应或多个模型的同时失效。\n\n响应这些风险，在2024年5月的AI首尔峰会上，16家全球AI行业组织签署了前沿AI安全承诺，27个国家和欧盟发布了旨在界定这些门槛的声明。为了履行这些承诺，组织必须确定并披露“除非得到充分缓解，否则由模型或系统带来的严重风险将被认为是不可接受”的门槛。\n\n为辅助设定和实现不可接受风险门槛，我们概述了关键原则和考虑事项；例如，在有限的数据和迅速发展的AI能力背景下，追求“足够好而非完美”的门槛。我们还提出了具体的门槛建议，包括一些详细的案例研究，针对八类风险中的部分风险，这八类风险包括：（1）化学、生物、放射性和核武器（CBRN武器），（2）网络攻击，（3）模型自主性，（4）说服与操控，（5）欺骗，（6）毒性，（7）歧视，和（8）社会经济破坏。我们的目标是为政策制定者和行业领袖提供一个起点或辅助资源，促进前瞻性风险管理，优先防止不可接受的风险（预防）而非仅仅在风险发生后进行缓解（事后）。', 'title_zh': '不可接受的风险阈值建议：人工智能领域'}
{'arxiv_id': 'arXiv:2503.05810', 'title': 'A Transformer Model for Predicting Chemical Reaction Products from Generic Templates', 'authors': 'Derin Ozer, Sylvain Lamprier, Thomas Cauchy, Nicolas Gutowski, Benoit Da Mota', 'link': 'https://arxiv.org/abs/2503.05810', 'abstract': 'The accurate prediction of chemical reaction outcomes is a major challenge in computational chemistry. Current models rely heavily on either highly specific reaction templates or template-free methods, both of which present limitations. To address these limitations, this work proposes the Broad Reaction Set (BRS), a dataset featuring 20 generic reaction templates that allow for the efficient exploration of the chemical space. Additionally, ProPreT5 is introduced, a T5 model tailored to chemistry that achieves a balance between rigid templates and template-free methods. ProPreT5 demonstrates its capability to generate accurate, valid, and realistic reaction products, making it a promising solution that goes beyond the current state-of-the-art on the complex reaction product prediction task.', 'abstract_zh': '化学反应结果的准确预测是计算化学中的一个主要挑战。当前模型要么依赖高度特定的反应模板，要么是非模板方法，两者都存在局限性。为解决这些局限性，本工作提出了广义反应集（BRS），这是一个包含20个通用反应模板的数据集，可以有效地探索化学空间。此外，还引入了ProPreT5模型，这是一种针对化学定制的T5模型，能够在刚性模板和非模板方法之间找到平衡。ProPreT5展示了生成准确、有效且现实反应产物的能力，使其成为在复杂反应产物预测任务中超越当前最先进水平的有前景的解决方案。', 'title_zh': '基于通用模板预测化学反应产物的转换器模型'}
{'arxiv_id': 'arXiv:2503.05805', 'title': 'Multi-agent Auto-Bidding with Latent Graph Diffusion Models', 'authors': 'Dom Huh, Prasant Mohapatra', 'link': 'https://arxiv.org/abs/2503.05805', 'abstract': "This paper proposes a diffusion-based auto-bidding framework that leverages graph representations to model large-scale auction environments. In such settings, agents must dynamically optimize bidding strategies under constraints defined by key performance indicator (KPI) metrics, all while operating in competitive environments characterized by uncertain, sparse, and stochastic variables. To address these challenges, we introduce a novel approach combining learnable graph-based embeddings with a planning-based latent diffusion model (LDM). By capturing patterns and nuances underlying the interdependence of impression opportunities and the multi-agent dynamics of the auction environment, the graph representation enable expressive computations regarding auto-bidding outcomes. With reward alignment techniques, the LDM's posterior is fine-tuned to generate auto-bidding trajectories that maximize KPI metrics while satisfying constraint thresholds. Empirical evaluations on both real-world and synthetic auction environments demonstrate significant improvements in auto-bidding performance across multiple common KPI metrics, as well as accuracy in forecasting auction outcomes.", 'abstract_zh': '基于图表示的大规模拍卖环境自调 bidding 扩散框架', 'title_zh': '基于潜在图扩散模型的多代理自动出价方法'}
{'arxiv_id': 'arXiv:2503.05804', 'title': 'Holistically Evaluating the Environmental Impact of Creating Language Models', 'authors': 'Jacob Morrison, Clara Na, Jared Fernandez, Tim Dettmers, Emma Strubell, Jesse Dodge', 'link': 'https://arxiv.org/abs/2503.05804', 'abstract': "As the performance of artificial intelligence systems has dramatically increased, so too has the environmental impact of creating these systems. While many model developers release estimates of the power consumption and carbon emissions from the final training runs for their latest models, there is comparatively little transparency into the impact of model development, hardware manufacturing, and total water usage throughout. In this work, we estimate the real-world environmental impact of developing a series of language models, ranging from 20 million to 13 billion active parameters, trained on up to 5.6 trillion tokens each. When accounting for hardware manufacturing, model development, and our final training runs, we find that our series of models released 493 metric tons of carbon emissions, equivalent to powering about 98 homes in the United States for one year, and consumed 2.769 million liters of water, equivalent to about 24.5 years of water usage by a person in the United States, even though our data center is extremely water-efficient. We measure and report the environmental impact of our model development; to the best of our knowledge we are the first to do so for LLMs, and we find that model development, the impact of which is generally not disclosed by most model developers, amounted to ~50% of that of training. By looking at detailed time series data for power consumption, we also find that power usage throughout training is not consistent, fluctuating between ~15% and ~85% of our hardware's maximum power draw, with negative implications for grid-scale planning as demand continues to grow. We close with a discussion on the continued difficulty of estimating the environmental impact of AI systems, and key takeaways for model developers and the public at large.", 'abstract_zh': '随着人工智能系统性能的大幅提高，其环境影响也随之增大。尽管许多模型开发者会公布其最新模型最终训练阶段的电力消耗和碳排放估计值，但模型开发、硬件制造以及总计水消耗的影响透明度却相对较低。在本研究中，我们估算了一系列从2000万到130亿激活参数的语言模型的环境影响，每个模型在训练时使用高达5.6万亿个词元。考虑到硬件制造、模型开发以及最终训练阶段的碳排放和水消耗，我们发现该系列模型共释放了493公吨的碳排放，相当于美国98户家庭一年的用电量，并消耗了276,900升水，相当于一个美国人24.5年的用水量，尽管我们的数据中心极为节水。我们测量并报告了模型开发的环境影响；据我们所知，这是首次针对大型语言模型（LLM）进行这样的测量和报告。我们发现，通常不被大多数模型开发者披露的模型开发的影响占总排放的约50%。通过详细的时间序列数据，我们还发现，在训练过程中，电力使用量波动较大，从硬件最大电力消耗的约15%到约85%，这在不断增长的需求下对电网规划提出了负面影响。最后，我们讨论了估算人工智能系统环境影响的持续困难，并提出了模型开发者和公众的关键启示。', 'title_zh': '全面评估创建语言模型的环境影响'}
{'arxiv_id': 'arXiv:2503.05803', 'title': 'Federated Learning Framework via Distributed Mutual Learning', 'authors': 'Yash Gupta', 'link': 'https://arxiv.org/abs/2503.05803', 'abstract': 'Federated Learning often relies on sharing full or partial model weights, which can burden network bandwidth and raise privacy risks. We present a loss-based alternative using distributed mutual learning. Instead of transmitting weights, clients periodically share their loss predictions on a public test set. Each client then refines its model by combining its local loss with the average Kullback-Leibler divergence over losses from other clients. This collaborative approach both reduces transmission overhead and preserves data privacy. Experiments on a face mask detection task demonstrate that our method outperforms weight-sharing baselines, achieving higher accuracy on unseen data while providing stronger generalization and privacy benefits.', 'abstract_zh': '基于损失的联邦学习：一种分布式互学习替代方案', 'title_zh': '分布式互助学习的联邦学习框架'}
{'arxiv_id': 'arXiv:2503.05802', 'title': 'Illuminant and light direction estimation using Wasserstein distance method', 'authors': 'Selcuk Yazar', 'link': 'https://arxiv.org/abs/2503.05802', 'abstract': "Illumination estimation remains a pivotal challenge in image processing, particularly for robotics, where robust environmental perception is essential under varying lighting conditions. Traditional approaches, such as RGB histograms and GIST descriptors, often fail in complex scenarios due to their sensitivity to illumination changes. This study introduces a novel method utilizing the Wasserstein distance, rooted in optimal transport theory, to estimate illuminant and light direction in images. Experiments on diverse images indoor scenes, black-and-white photographs, and night images demonstrate the method's efficacy in detecting dominant light sources and estimating their directions, outperforming traditional statistical methods in complex lighting environments. The approach shows promise for applications in light source localization, image quality assessment, and object detection enhancement. Future research may explore adaptive thresholding and integrate gradient analysis to enhance accuracy, offering a scalable solution for real-world illumination challenges in robotics and beyond.", 'abstract_zh': '光照估计仍然是图像处理中的一个关键挑战，特别是在机器人领域，需要在不同光照条件下进行鲁棒的环境感知。传统的基于RGB直方图和GIST描述子的方法往往在复杂场景下由于对光照变化的敏感性而失效。本研究提出了一种利用最优传输理论中的 Wasserstein 距离的新方法，用于估计图像中的光照和光的方向。实验结果显示，该方法在室内场景、黑白照片和夜景图像上能够有效地检测主要光源和估计其方向，在复杂光照环境下优于传统统计方法。该方法在光源定位、图像质量评估和目标检测增强等方面具有应用前景。未来的研究可以探索自适应阈值处理并集成梯度分析以提高准确性，提供一种适用于机器人和其他领域的光照挑战的可扩展解决方案。', 'title_zh': '使用Wasserstein距离方法估计光源和光照方向'}
{'arxiv_id': 'arXiv:2503.05797', 'title': 'Fault Localization and State Estimation of Power Grid under Parallel Cyber-Physical Attacks', 'authors': 'Junhao Ren, Kai Zhao, Guangxiao Zhang, Xinghua Liu, Chao Zhai, Gaoxi Xiao', 'link': 'https://arxiv.org/abs/2503.05797', 'abstract': 'Parallel cyber-physical attacks (PCPA) refer to those attacks on power grids by disturbing/cutting off physical transmission lines and meanwhile blocking transmission of measurement data to dwarf or delay the system protection and recovery actions. Such fierce hostile attacks impose critical threats to the modern power grids when there is a fusion of power grids and telecommunication technologies. In this paper, we investigate the fault diagnosis problem of faulty transmission lines under a broader spectrum of PCPA for a linearized (or DC) power flow model. The physical attack mechanism of PCPA includes not only disconnection but also admittance value modification on transmission lines, for example, by invading distributed flexible AC transmission system (D-FACTS). To tackle the problem, we first recover the information of voltage phase angles within the attacked area. Using the information of voltage phase angle and power injection of buses, a graph attention network-based fault localization (GAT-FL) algorithm is proposed to find the locations of the physical attacks. By capitalizing on the feature extraction capability of the GAT on graph data, the fault localization algorithm outperforms the existing results when under cyber attacks, e.g., denial of service (DoS) attacks. A line state identification algorithm is then developed to identify the states of the transmission lines within the attacked area. Specifically, the algorithm restores the power injection of buses within the attacked area and then identities the state of all the transmission lines within the attacked area by solving a linear programming (LP) problem. Experimental simulations are effectiveness of the proposed fault diagnosis algorithms.', 'abstract_zh': '平行 cyber-物理 攻击下的传输线路故障诊断研究（PCPA）', 'title_zh': '电力网络在平行网络物理攻击下的故障定位与状态估计'}
{'arxiv_id': 'arXiv:2503.05796', 'title': 'Towards Multi-Stakeholder Evaluation of ML Models: A Crowdsourcing Study on Metric Preferences in Job-matching System', 'authors': 'Takuya Yokota, Yuri Nakao', 'link': 'https://arxiv.org/abs/2503.05796', 'abstract': "While machine learning (ML) technology affects diverse stakeholders, there is no one-size-fits-all metric to evaluate the quality of outputs, including performance and fairness. Using predetermined metrics without soliciting stakeholder opinions is problematic because it leads to an unfair disregard for stakeholders in the ML pipeline. In this study, to establish practical ways to incorporate diverse stakeholder opinions into the selection of metrics for ML, we investigate participants' preferences for different metrics by using crowdsourcing. We ask 837 participants to choose a better model from two hypothetical ML models in a hypothetical job-matching system twenty times and calculate their utility values for seven metrics. To examine the participants' feedback in detail, we divide them into five clusters based on their utility values and analyze the tendencies of each cluster, including their preferences for metrics and common attributes. Based on the results, we discuss the points that should be considered when selecting appropriate metrics and evaluating ML models with multiple stakeholders.", 'abstract_zh': '机器学习技术影响多元利益相关者，但缺乏适用于评估输出质量（包括性能和公平性）的一揽子评价指标。在未征求利益相关者意见的情况下使用预设指标会导致对机器学习管道中利益相关者的不公平忽视。为建立将多元利益相关者意见纳入机器学习指标选择的实用方法，本研究通过 crowdsourcing 探究参与者对不同指标的偏好。我们要求 837 名参与者在假设的工作匹配系统中从两个假设的机器学习模型中选择较好的模型二十次，并计算他们对七种指标的效用值。为详细检查参与者反馈，我们根据效用值将参与者分为五类，并分析每类的倾向性，包括其对指标的偏好和共同特征。基于研究结果，我们讨论了在多利益相关者情境下选择合适指标和评估机器学习模型时应注意的要点。', 'title_zh': '面向多利益相关方的机器学习模型评估研究：基于工作匹配系统中度量偏好指标的众包研究'}
{'arxiv_id': 'arXiv:2503.05794', 'title': 'CBW: Towards Dataset Ownership Verification for Speaker Verification via Clustering-based Backdoor Watermarking', 'authors': 'Yiming Li, Kaiying Yan, Shuo Shao, Tongqing Zhai, Shu-Tao Xia, Zhan Qin, Dacheng Tao', 'link': 'https://arxiv.org/abs/2503.05794', 'abstract': 'With the increasing adoption of deep learning in speaker verification, large-scale speech datasets have become valuable intellectual property. To audit and prevent the unauthorized usage of these valuable released datasets, especially in commercial or open-source scenarios, we propose a novel dataset ownership verification method. Our approach introduces a clustering-based backdoor watermark (CBW), enabling dataset owners to determine whether a suspicious third-party model has been trained on a protected dataset under a black-box setting. The CBW method consists of two key stages: dataset watermarking and ownership verification. During watermarking, we implant multiple trigger patterns in the dataset to make similar samples (measured by their feature similarities) close to the same trigger while dissimilar samples are near different triggers. This ensures that any model trained on the watermarked dataset exhibits specific misclassification behaviors when exposed to trigger-embedded inputs. To verify dataset ownership, we design a hypothesis-test-based framework that statistically evaluates whether a suspicious model exhibits the expected backdoor behavior. We conduct extensive experiments on benchmark datasets, verifying the effectiveness and robustness of our method against potential adaptive attacks. The code for reproducing main experiments is available at this https URL', 'abstract_zh': '随着深度学习在语音识别验证中的应用日益增加，大规模语音数据集已成为有价值的知识产权。为了审计和防止这些 valuable 数据集在未经授权的情况下被使用，尤其是在商业或开源场景中，我们提出了一种新颖的数据集所有权验证方法。该方法引入了一种基于聚类的后门水印（CBW），使数据集所有者能够在黑盒环境中确定可疑第三方模型是否使用了受保护的数据集。CBW 方法包括两个关键阶段：数据集水印和所有权验证。在水印阶段，我们通过植入多个触发模式，使具有相似特征的样本在触发方面接近相同的模式，而具有不同特征的样本则接近不同的模式，从而确保任何基于水印数据集训练的模型在遇到触发器嵌入的输入时会展现出特定的错误分类行为。为了验证数据集所有权，我们设计了一种基于 hypothesis test 的框架，用于统计评估可疑模型是否表现出预期的后门行为。我们在基准数据集上进行了广泛的实验，验证了该方法在潜在适应性攻击下的有效性和鲁棒性。主要实验的代码可在此处访问：[此 https URL]。', 'title_zh': 'CBW：基于聚类后门水印的说话人验证数据集所有权验证方法'}
{'arxiv_id': 'arXiv:2503.05793', 'title': 'MedSimAI: Simulation and Formative Feedback Generation to Enhance Deliberate Practice in Medical Education', 'authors': 'Yann Hicke, Jadon Geathers, Niroop Rajashekar, Colleen Chan, Anyanate Gwendolyne Jack, Justin Sewell, Mackenzi Preston, Susannah Cornes, Dennis Shung, Rene Kizilcec', 'link': 'https://arxiv.org/abs/2503.05793', 'abstract': 'Medical education faces challenges in scalability, accessibility, and consistency, particularly in clinical skills training for physician-patient communication. Traditional simulation-based learning, while effective, is resource-intensive, difficult to schedule, and often highly variable in feedback quality. Through a collaboration between AI, learning science, and medical education experts, we co-developed MedSimAI, an AI-powered simulation platform that enables deliberate practice, self-regulated learning (SRL), and automated assessment through interactive patient encounters. Leveraging large language models (LLMs), MedSimAI generates realistic clinical interactions and provides immediate, structured feedback using established medical evaluation frameworks such as the Master Interview Rating Scale (MIRS). In a pilot study with 104 first-year medical students, we examined engagement, conversation patterns, and user perceptions. Students found MedSimAI beneficial for repeated, realistic patient-history practice. Conversation analysis revealed that certain higher-order skills were often overlooked, though students generally performed systematic histories and empathic listening. By integrating unlimited practice opportunities, real-time AI assessment, and SRL principles, MedSimAI addresses key limitations of traditional simulation-based training, making high-quality clinical education more accessible and scalable.', 'abstract_zh': '医疗教育在可扩展性、可访问性和一致性方面面临挑战，特别是在医生-患者沟通的临床技能训练方面。尽管基于模拟的传统学习方法有效，但该方法资源消耗大、排期困难，且反馈质量经常差异明显。通过AI、学习科学和医疗教育专家的合作，我们共同开发了MedSimAI，这是一种基于AI的模拟平台，能够通过互动患者交流促进刻意练习、自我调节学习（SRL）和自动化评估。借助大规模语言模型（LLMs），MedSimAI生成了真实的临床互动，并使用《大师访谈评估量表》（MIRS）等已确立的医学评价框架，提供即时的结构化反馈。在一项包含104名一年级医学生的试点研究中，我们考察了参与度、对话模式和用户感知。学生认为MedSimAI在重复和真实的患者病史练习方面具有益处。对话分析表明，某些高层次技能经常被忽略，但学生通常能够进行系统的历史采集和共情倾听。通过整合无限的练习机会、实时AI评估以及SRL原则，MedSimAI解决了传统基于模拟的培训的关键限制，使高质量的临床教育更具可访问性和可扩展性。', 'title_zh': 'MedSimAI: 模拟与形成性反馈生成以提高医学教育中的 deliberate practice'}
{'arxiv_id': 'arXiv:2503.05788', 'title': 'Emergent Abilities in Large Language Models: A Survey', 'authors': 'Leonardo Berti, Flavio Giorgi, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2503.05788', 'abstract': 'Large Language Models (LLMs) are leading a new technological revolution as one of the most promising research streams toward artificial general intelligence. The scaling of these models, accomplished by increasing the number of parameters and the magnitude of the training datasets, has been linked to various so-called emergent abilities that were previously unobserved. These emergent abilities, ranging from advanced reasoning and in-context learning to coding and problem-solving, have sparked an intense scientific debate: Are they truly emergent, or do they simply depend on external factors, such as training dynamics, the type of problems, or the chosen metric? What underlying mechanism causes them? Despite their transformative potential, emergent abilities remain poorly understood, leading to misconceptions about their definition, nature, predictability, and implications. In this work, we shed light on emergent abilities by conducting a comprehensive review of the phenomenon, addressing both its scientific underpinnings and real-world consequences. We first critically analyze existing definitions, exposing inconsistencies in conceptualizing emergent abilities. We then explore the conditions under which these abilities appear, evaluating the role of scaling laws, task complexity, pre-training loss, quantization, and prompting strategies. Our review extends beyond traditional LLMs and includes Large Reasoning Models (LRMs), which leverage reinforcement learning and inference-time search to amplify reasoning and self-reflection. However, emergence is not inherently positive. As AI systems gain autonomous reasoning capabilities, they also develop harmful behaviors, including deception, manipulation, and reward hacking. We highlight growing concerns about safety and governance, emphasizing the need for better evaluation frameworks and regulatory oversight.', 'abstract_zh': '大型语言模型（LLMs）是通往人工通用智能最 promising 研究分支之一，引领着新一轮的技术革命。这些模型的扩展，通过增加参数数量和训练数据集的规模实现，与多种此前未被观察到的所谓“ emergent 能力”相关联。这些“ emergent 能力”包括从高级推理和上下文学习到编程和问题解决等能力，引发了激烈的科学争论：它们真的是“ emergent 的”，还是仅仅依赖于外部因素，如训练动态、任务类型或选择的度量标准？是什么底层机制导致了这些能力出现？尽管这些能力具有变革潜力，但它们的本质仍然 poorly understood，导致对其定义、本质、可预测性和影响的误解。在本研究中，我们通过对这一现象进行全面回顾，阐明“ emergent 能力”，探讨其科学基础及其实际后果。我们首先批判性地分析现有定义，揭示了“ emergent 能力”概念的一致性问题。然后探讨这些能力出现的条件，评估规模律、任务复杂性、预训练损失、量化以及提示策略的作用。我们的回顾不仅局限于传统的 LLMs，还包括利用强化学习和推理时搜索来放大推理和自我反思的 Large Reasoning Models (LRMs)。然而， “ emergent 能力”并非固然是积极的。随着 AI 系统获得自主推理能力，它们也发展出有害行为，包括欺骗、操纵和奖励作弊。我们强调了对安全和治理日益增长的担忧，并强调了需要更好的评估框架和监管监督的必要性。', 'title_zh': '大型语言模型中的 emergent 能力：一个综述'}
{'arxiv_id': 'arXiv:2503.05785', 'title': 'Artificial Intelligence in Sports: Insights from a Quantitative Survey among Sports Students in Germany about their Perceptions, Expectations, and Concerns regarding the Use of AI Tools', 'authors': 'Dennis Krämer, Anja Bosold, Martin Minarik, Cleo Schyvinck, Andre Hajek', 'link': 'https://arxiv.org/abs/2503.05785', 'abstract': "Generative Artificial Intelligence (AI) tools such as ChatGPT, Copilot, or Gemini have a crucial impact on academic research and teaching. Empirical data on how students perceive the increasing influence of AI, which different types of tools they use, what they expect from them in their daily academic tasks, and their concerns regarding the use of AI in their studies are still limited. The manuscript presents findings from a quantitative survey conducted among sports students of all semesters in Germany using an online questionnaire. It explores aspects such as students' usage behavior, motivational factors, and uncertainties regarding the impact of AI tools on academia in the future. Furthermore, the social climate in sports studies is being investigated to provide a general overview of the current situation of the students in Germany. Data collection took place between August and November 2023, addressing all sports departments at German universities, with a total of 262 students participating. Our Findings indicate that students have a strong interest in using AI tools in their studies, expecting them to improve their overall academic performance, understand the complexity of scientific approaches, and save time. They express confidence that the proliferation of AI will not compromise their critical thinking skills. Moreover, students are positive about integrating more AI-related topics into the curriculum and about lecturers adopting more AI-based teaching methods. However, our findings also show that students have concerns about plagiarism, lecturer preparedness and their own skills and future skill development.", 'abstract_zh': '生成性人工智能工具（如ChatGPT、Copilot或Gemini）对学术研究和教学具有关键影响。关于学生如何感知人工智能日益增大的影响、他们使用的不同类型工具、期望这些工具在日常学术任务中的作用以及他们对在学习中使用人工智能的担忧的实证数据仍然有限。本文通过在德国所有学期的体育学生中进行在线问卷调查，展示了研究结果，探讨了学生使用行为、动机因素以及对人工智能工具未来影响的不确定性。此外，研究还调查了体育研究领域的社会气候，以提供当前德国学生状况的总体概述。数据采集时间为2023年8月至11月，涵盖德国所有体育系，共262名学生参与。我们的研究结果显示，学生对在学习中使用人工智能工具表现出浓厚兴趣，期望这些工具能够提高他们的学术表现、理解科学研究的复杂性并节省时间。他们相信人工智能的发展不会削弱他们的批判性思维能力。此外，学生对将更多与人工智能相关的话题纳入课程和讲师采用更多基于人工智能的教学方法持积极态度。然而，研究结果也显示，学生对学术抄袭、讲师准备程度以及自身技能和未来技能发展存在担忧。', 'title_zh': '体育领域的人工智能：关于人工智能工具在体育中的应用、期望与担忧的德国体育学生定量调研见解'}
{'arxiv_id': 'arXiv:2503.05784', 'title': 'The Illusion of Rights based AI Regulation', 'authors': 'Yiyang Mei, Matthew Sag', 'link': 'https://arxiv.org/abs/2503.05784', 'abstract': "Whether and how to regulate AI is one of the defining questions of our times - a question that is being debated locally, nationally, and internationally. We argue that much of this debate is proceeding on a false premise. Specifically, our article challenges the prevailing academic consensus that the European Union's AI regulatory framework is fundamentally rights-driven and the correlative presumption that other rights-regarding nations should therefore follow Europe's lead in AI regulation. Rather than taking rights language in EU rules and regulations at face value, we show how EU AI regulation is the logical outgrowth of a particular cultural, political, and historical context. We show that although instruments like the General Data Protection Regulation (GDPR) and the AI Act invoke the language of fundamental rights, these rights are instrumentalized - used as rhetorical cover for governance tools that address systemic risks and maintain institutional stability. As such, we reject claims that the EU's regulatory framework and the substance of its rules should be adopted as universal imperatives and transplanted to other liberal democracies. To add weight to our argument from historical context, we conduct a comparative analysis of AI regulation in five contested domains: data privacy, cybersecurity, healthcare, labor, and misinformation. This EU-US comparison shows that the EU's regulatory architecture is not meaningfully rights-based. Our article's key intervention in AI policy debates is not to suggest that the current American regulatory model is necessarily preferable but that the presumed legitimacy of the EU's AI regulatory approach must be abandoned.", 'abstract_zh': '是否及如何规制人工智能：当下定义性问题之一——一种地方性、国家性和国际性的辩论。我们主张，这场辩论在很大程度上基于一个虚假的前提。具体而言，本文挑战了关于欧盟人工智能监管框架本质上是以权利为导向的学术共识，并由此推论其他以权利为导向的国家应效仿欧盟在人工智能监管方面的做法。我们并非简单接受欧盟规则和条例中的权利话语，而是展示了欧盟人工智能监管是如何在特定文化、政治和历史背景下自然发展的逻辑结果。我们表明，尽管《通用数据保护条例》（GDPR）和《人工智能法案》等工具使用了基本权利的语言，但这些权利实际上是被作为治理工具使用的，旨在覆盖系统性风险并维持机构稳定。因此，我们拒绝了认为欧盟监管框架及其规则内容应作为普遍要求并移植到其他自由民主国家的主张。为进一步支持我们的论点，我们对人工智能监管在五个争议领域的比较分析——数据隐私、网络安全、医疗、劳动和虚假信息——进行了历史背景下的比较。这种欧盟-美国比较表明，欧盟的监管架构本质上并非以权利为基础。本文在人工智能政策辩论中的关键介入并非建议当前美国监管模型一定更优，而是认为应放弃对欧盟人工智能监管方法合法性的假定。', 'title_zh': '基于权利的AI监管幻象'}
{'arxiv_id': 'arXiv:2503.05783', 'title': 'Knowledge representation and scalable abstract reasoning for simulated democracy in Unity', 'authors': 'Eleftheria Katsiri, Alexandros Gazis, Angelos Protopapas', 'link': 'https://arxiv.org/abs/2503.05783', 'abstract': "We present a novel form of scalable knowledge representation about agents in a simulated democracy, e-polis, where real users respond to social challenges associated with democratic institutions, structured as Smart Spatial Types, a new type of Smart Building that changes architectural form according to the philosophical doctrine of a visitor. At the end of the game players vote on the Smart City that results from their collective choices. Our approach uses deductive systems in an unusual way: by integrating a model of democracy with a model of a Smart City we are able to prove quality aspects of the simulated democracy in different urban and social settings, while adding ease and flexibility to the development. Second, we can infer and reason with abstract knowledge, which is a limitation of the Unity platform; third, our system enables real-time decision-making and adaptation of the game flow based on the player's abstract state, paving the road to explainability. Scalability is achieved by maintaining a dual-layer knowledge representation mechanism for reasoning about the simulated democracy that functions in a similar way to a two-level cache. The lower layer knows about the current state of the game by continually processing a high rate of events produced by the in-built physics engine of the Unity platform, e.g., it knows of the position of a player in space, in terms of his coordinates x,y,z as well as their choices for each challenge. The higher layer knows of easily-retrievable, user-defined abstract knowledge about current and historical states, e.g., it knows of the political doctrine of a Smart Spatial Type, a player's philosophical doctrine, and the collective philosophical doctrine of a community players with respect to current social issues.", 'abstract_zh': '我们提出了一种新的可扩展的知识表示形式，用于模拟民主环境e-polis中的代理，其中真实用户响应与民主机构相关的社会挑战，这些挑战被结构化为智能空间类型，这是一种新的智能建筑类型，其建筑形式根据访客的哲学教义变化。游戏结束时，玩家投票决定他们集体选择所形成的智慧城市。我们的方法以非同寻常的方式使用演绎系统：通过将民主模型与智慧城市模型整合，我们能够在不同的城市和社会环境中证明模拟民主的质量方面，同时增加了开发的便捷性和灵活性。其次，我们能够推断和处理抽象知识，这是Unity平台的局限性；第三，我们的系统能够根据玩家的抽象状态实现实时决策和游戏流程的适应性，从而为可解释性铺平道路。通过维护一种类似于两级缓存的知识表示机制来实现可扩展性，以推理模拟民主的状态，该机制的下层不断处理由Unity平台内置物理引擎生成的高频事件，例如，它知道玩家在空间中的位置及其坐标的x、y、z以及每个挑战的选择。上层则易于获取用户定义的关于当前和历史状态的抽象知识，例如，它知道智能空间类型的哲学教义、玩家的哲学教义以及社区玩家对当前社会问题的集体哲学教义。', 'title_zh': 'Unity中模拟民主的知识表示与可扩展抽象推理'}
{'arxiv_id': 'arXiv:2503.05782', 'title': 'AI Mentors for Student Projects: Spotting Early Issues in Computer Science Proposals', 'authors': 'Gati Aher, Robin Schmucker, Tom Mitchell, Zachary C. Lipton', 'link': 'https://arxiv.org/abs/2503.05782', 'abstract': "When executed well, project-based learning (PBL) engages students' intrinsic motivation, encourages students to learn far beyond a course's limited curriculum, and prepares students to think critically and maturely about the skills and tools at their disposal. However, educators experience mixed results when using PBL in their classrooms: some students thrive with minimal guidance and others flounder. Early evaluation of project proposals could help educators determine which students need more support, yet evaluating project proposals and student aptitude is time-consuming and difficult to scale. In this work, we design, implement, and conduct an initial user study (n = 36) for a software system that collects project proposals and aptitude information to support educators in determining whether a student is ready to engage with PBL. We find that (1) users perceived the system as helpful for writing project proposals and identifying tools and technologies to learn more about, (2) educator ratings indicate that users with less technical experience in the project topic tend to write lower-quality project proposals, and (3) GPT-4o's ratings show agreement with educator ratings. While the prospect of using LLMs to rate the quality of students' project proposals is promising, its long-term effectiveness strongly hinges on future efforts at characterizing indicators that reliably predict students' success and motivation to learn.", 'abstract_zh': '基于项目的教学（PBL）实施得当可激发学生内在动机，鼓励学生超越课程限定范围进行学习，并为学生提供批判性和成熟地思考现有技能和工具的机会。然而，教师在课堂上使用PBL时体验到的效果参差不齐：一些学生在较少指导的情况下蓬勃发展，而另一些学生则陷入了困境。对项目提案的早期评估可以帮助教师确定哪些学生需要更多支持，但评估项目提案和学生能力既耗时又难以规模化。在本工作中，我们设计、实现并开展了一项初步用户研究（n=36），研究一个软件系统如何收集项目提案和能力信息，以帮助教师判断学生是否准备好参与PBL。我们发现：（1）用户认为该系统有助于撰写项目提案并识别需要深入了解的工具和技术；（2）教师评分表明，在项目主题方面技术经验较少的用户倾向于撰写质量较低的项目提案；（3）GPT-4o的评分与教师评分存在一致性。虽然使用大型语言模型（LLM）评估学生项目提案质量的前景令人鼓舞，但其长期有效性在很大程度上取决于未来在识别可靠预测学生成功和学习动机的指标方面所做的努力。', 'title_zh': 'AI导师助力学生项目：计算机科学提案中早期问题的识别'}
{'arxiv_id': 'arXiv:2503.05779', 'title': 'Homomorphic Encryption of Intuitionistic Logic Proofs and Functional Programs: A Categorical Approach Inspired by Composite-Order Bilinear Groups', 'authors': 'Ben Goertzel', 'link': 'https://arxiv.org/abs/2503.05779', 'abstract': 'We present a conceptual framework for extending homomorphic encryption beyond arithmetic or Boolean operations into the domain of intuitionistic logic proofs and, by the Curry-Howard correspondence, into the domain of typed functional programs. We begin by reviewing well-known homomorphic encryption schemes for arithmetic operations, and then discuss the adaptation of similar concepts to support logical inference steps in intuitionistic logic. Key to our construction are polynomial functors and Bounded Natural Functors (BNFs), which serve as a categorical substrate on which logic formulas and proofs are represented and manipulated. We outline a complexity-theoretic hardness assumption -- the BNF Distinguishing Problem, constructed via a reduction from Subgraph Isomorphism, providing a foundation for cryptographic security. Finally, we describe how these methods can homomorphically encode the execution of total, dependently typed functional programs, and outline strategies for making the approach potentially efficient, including software optimizations and hardware acceleration.', 'abstract_zh': '我们提出了一种概念框架，将其同态加密技术从算术运算或布尔操作扩展到直觉逻辑证明领域，并通过 curry-howard 对应关系扩展到带有类型的功能程序领域。我们首先回顾了用于算术操作的已知同态加密方案，然后讨论了如何适应类似的概念以支持直觉逻辑中的逻辑推理步骤。我们的构建关键在于多项式函子和有界自然函子（BNFs），它们作为逻辑公式和证明表示和操作的范畴基底。我们概述了一个计算复杂性理论上的硬度假设——BNF区分问题，通过从子图同构问题的归约构建而成，为密码安全性提供基础。最后，我们描述了如何通过同态加密编码完整依赖类型的功能程序的执行，并概述了使该方法可能高效的方法，包括软件优化和硬件加速。', 'title_zh': '同态加密直觉逻辑证明与功能程序：受复合阶双线性群启发的范畴论方法'}
{'arxiv_id': 'arXiv:2503.05778', 'title': 'DreamNet: A Multimodal Framework for Semantic and Emotional Analysis of Sleep Narratives', 'authors': 'Tapasvi Panchagnula', 'link': 'https://arxiv.org/abs/2503.05778', 'abstract': 'Dream narratives provide a unique window into human cognition and emotion, yet their systematic analysis using artificial intelligence has been underexplored. We introduce DreamNet, a novel deep learning framework that decodes semantic themes and emotional states from textual dream reports, optionally enhanced with REM-stage EEG data. Leveraging a transformer-based architecture with multimodal attention, DreamNet achieves 92.1% accuracy and 88.4% F1-score in text-only mode (DNet-T) on a curated dataset of 1,500 anonymized dream narratives, improving to 99.0% accuracy and 95.2% F1-score with EEG integration (DNet-M). Strong dream-emotion correlations (e.g., falling-anxiety, r = 0.91, p < 0.01) highlight its potential for mental health diagnostics, cognitive science, and personalized therapy. This work provides a scalable tool, a publicly available enriched dataset, and a rigorous methodology, bridging AI and psychological research.', 'abstract_zh': '梦叙事提供了一扇洞察人类认知和情感的独特窗口， yet 其人工智能驱动的系统分析尚属未探索领域。我们引入了 DreamNet，一种新颖的深度学习框架，用于从文本梦境报告中解码语义主题和情绪状态，可选地增强以 REM 阶段的 EEG 数据。利用基于变换器的架构和多模态注意力，DreamNet 在仅文本模式（DNet-T）下对 1,500 份匿名梦叙事精心筛选的数据集实现了 92.1% 的准确率和 88.4% 的 F1 分数，而在结合 EEG 数据后（DNet-M）则分别提高到 99.0% 和 95.2%。强烈的梦与情绪关联（例如，掉落-焦虑，r = 0.91，p < 0.01）突显了其在心理健康诊断、认知科学和个人化治疗方面的潜力。这项工作提供了一个可扩展的工具、一个公开的丰富数据集和一种严格的 方法论，融合了人工智能和心理学研究。', 'title_zh': 'DreamNet：多模态睡眠叙事语义与情感分析框架'}
{'arxiv_id': 'arXiv:2503.05777', 'title': 'Medical Hallucinations in Foundation Models and Their Impact on Healthcare', 'authors': 'Yubin Kim, Hyewon Jeong, Shan Chen, Shuyue Stella Li, Mingyu Lu, Kumail Alhamoud, Jimin Mun, Cristina Grau, Minseok Jung, Rodrigo Gameiro, Lizhou Fan, Eugene Park, Tristan Lin, Joonsik Yoon, Wonjin Yoon, Maarten Sap, Yulia Tsvetkov, Paul Liang, Xuhai Xu, Xin Liu, Daniel McDuff, Hyeonhoon Lee, Hae Won Park, Samir Tulebaev, Cynthia Breazeal', 'link': 'https://arxiv.org/abs/2503.05777', 'abstract': "Foundation Models that are capable of processing and generating multi-modal data have transformed AI's role in medicine. However, a key limitation of their reliability is hallucination, where inaccurate or fabricated information can impact clinical decisions and patient safety. We define medical hallucination as any instance in which a model generates misleading medical content. This paper examines the unique characteristics, causes, and implications of medical hallucinations, with a particular focus on how these errors manifest themselves in real-world clinical scenarios. Our contributions include (1) a taxonomy for understanding and addressing medical hallucinations, (2) benchmarking models using medical hallucination dataset and physician-annotated LLM responses to real medical cases, providing direct insight into the clinical impact of hallucinations, and (3) a multi-national clinician survey on their experiences with medical hallucinations. Our results reveal that inference techniques such as Chain-of-Thought (CoT) and Search Augmented Generation can effectively reduce hallucination rates. However, despite these improvements, non-trivial levels of hallucination persist. These findings underscore the ethical and practical imperative for robust detection and mitigation strategies, establishing a foundation for regulatory policies that prioritize patient safety and maintain clinical integrity as AI becomes more integrated into healthcare. The feedback from clinicians highlights the urgent need for not only technical advances but also for clearer ethical and regulatory guidelines to ensure patient safety. A repository organizing the paper resources, summaries, and additional information is available at this https URL hallucination.", 'abstract_zh': '具备处理和生成多模态数据能力的模型已经改变了医学中的AI角色。然而，它们可靠性的一个关键限制是幻觉现象，即不准确或捏造的信息可能会影响临床决策和患者安全。我们定义医学幻觉为模型生成误导性医疗内容的任何实例。本文探讨了医学幻觉的独特特征、成因及其影响，特别是关注这些错误在实际临床场景中的表现形式。我们的贡献包括（1）一种理解并解决医学幻觉的分类体系，（2）使用医学幻觉数据集和医生注释的大语言模型对实际医疗案例的响应进行基准测试，提供幻觉对临床影响的直接洞察，以及（3）一项跨国家的临床医生调查，了解他们在处理医学幻觉方面的经验。结果显示，如Chain-of-Thought（CoT）和搜索增强生成等推理技术可以有效降低幻觉率。尽管取得了这些进步，幻觉现象仍存在不可忽视的水平。这些发现强调了建立稳健检测和缓解策略的伦理和实践紧迫性，为重视患者安全和保持临床完整性的监管政策奠定了基础，尤其是在AI在医疗保健中的深度融合背景下。临床医生的反馈强调了不仅需要技术进步，还需要更加清晰的伦理和监管指南以确保患者安全。相关论文资源、摘要和额外信息的存储库可访问此链接：https://this-url-hallucination.com', 'title_zh': '基础模型中的医疗幻觉及其对医疗健康的影响'}
{'arxiv_id': 'arXiv:2503.05776', 'title': 'FAA-CLIP: Federated Adversarial Adaptation of CLIP', 'authors': 'Yihang Wu, Ahmad Chaddad, Christian Desrosiers, Tareef Daqqaq, Reem Kateb', 'link': 'https://arxiv.org/abs/2503.05776', 'abstract': "Despite the remarkable performance of vision language models (VLMs) such as Contrastive Language Image Pre-training (CLIP), the large size of these models is a considerable obstacle to their use in federated learning (FL) systems where the parameters of local client models need to be transferred to a global server for aggregation. Another challenge in FL is the heterogeneity of data from different clients, which affects the generalization performance of the solution. In addition, natural pre-trained VLMs exhibit poor generalization ability in the medical datasets, suggests there exists a domain gap. To solve these issues, we introduce a novel method for the Federated Adversarial Adaptation (FAA) of CLIP. Our method, named FAA-CLIP, handles the large communication costs of CLIP using a light-weight feature adaptation module (FAM) for aggregation, effectively adapting this VLM to each client's data while greatly reducing the number of parameters to transfer. By keeping CLIP frozen and only updating the FAM parameters, our method is also computationally efficient. Unlike existing approaches, our FAA-CLIP method directly addresses the problem of domain shifts across clients via a domain adaptation (DA) module. This module employs a domain classifier to predict if a given sample is from the local client or the global server, allowing the model to learn domain-invariant representations. Extensive experiments on six different datasets containing both natural and medical images demonstrate that FAA-CLIP can generalize well on both natural and medical datasets compared to recent FL approaches. Our codes are available at this https URL.", 'abstract_zh': 'federated adversarial adaptation of clip for medical and natural images', 'title_zh': 'FAA-CLIP: 联邦对抗适应的CLIP'}
{'arxiv_id': 'arXiv:2503.05773', 'title': 'Between Innovation and Oversight: A Cross-Regional Study of AI Risk Management Frameworks in the EU, U.S., UK, and China', 'authors': 'Amir Al-Maamari', 'link': 'https://arxiv.org/abs/2503.05773', 'abstract': "As artificial intelligence (AI) technologies increasingly enter important sectors like healthcare, transportation, and finance, the development of effective governance frameworks is crucial for dealing with ethical, security, and societal risks. This paper conducts a comparative analysis of AI risk management strategies across the European Union (EU), United States (U.S.), United Kingdom (UK), and China. A multi-method qualitative approach, including comparative policy analysis, thematic analysis, and case studies, investigates how these regions classify AI risks, implement compliance measures, structure oversight, prioritize transparency, and respond to emerging innovations. Examples from high-risk contexts like healthcare diagnostics, autonomous vehicles, fintech, and facial recognition demonstrate the advantages and limitations of different regulatory models. The findings show that the EU implements a structured, risk-based framework that prioritizes transparency and conformity assessments, while the U.S. uses decentralized, sector-specific regulations that promote innovation but may lead to fragmented enforcement. The flexible, sector-specific strategy of the UK facilitates agile responses but may lead to inconsistent coverage across domains. China's centralized directives allow rapid large-scale implementation while constraining public transparency and external oversight. These insights show the necessity for AI regulation that is globally informed yet context-sensitive, aiming to balance effective risk management with technological progress. The paper concludes with policy recommendations and suggestions for future research aimed at enhancing effective, adaptive, and inclusive AI governance globally.", 'abstract_zh': '随着人工智能（AI）技术在医疗、交通和金融等重要领域中的应用越来越广泛，建立有效的治理框架以应对伦理、安全和社会风险至关重要。本文通过比较分析欧盟（EU）、美国（U.S.）、英国（UK）和中国在AI风险管理策略上的差异，探讨这些地区如何分类AI风险、实施合规措施、构建监督结构、强调透明度以及应对新兴创新。在医疗诊断、自动驾驶车辆、金融科技和人脸识别等高风险领域内，不同的监管模型显示出其优缺点。研究发现，欧盟实施了一种结构化、基于风险的框架，强调透明度和一致性评估，而美国则采用分散的、面向特定行业的监管措施，促进创新但也可能导致执法碎片化。英国灵活的、面向特定行业的策略有助于灵活响应，但也可能导致不同领域的一致性覆盖不足。中国的集中指导方针允许快速大规模实施，但同时限制了公众透明度和外部监督。这些洞察显示，需要一种既全局视角又具有情境敏感性的AI治理模式，旨在平衡有效的风险管理与技术进步。本文最后提出了政策建议，并就未来旨在增强全球有效、适应性强且包容性AI治理的研究方向提出了建议。', 'title_zh': '创新与监管之间：欧盟、美国、英国和中国人工智能风险管理框架的跨区域研究'}
{'arxiv_id': 'arXiv:2503.05770', 'title': 'Generative Artificial Intelligence: Evolving Technology, Growing Societal Impact, and Opportunities for Information Systems Research', 'authors': 'Veda C. Storey, Wei Thoo Yue, J. Leon Zhao, Roman Lukyanenko', 'link': 'https://arxiv.org/abs/2503.05770', 'abstract': 'The continuing, explosive developments in generative artificial intelligence (GenAI), built on large language models and related algorithms, has led to much excitement and speculation about the potential impact of this new technology. Claims include AI being poised to revolutionize business and society and dramatically change personal life. However, it remains unclear exactly how this technology, with its significantly distinct features from past AI technologies, has transformative potential. Nor is it clear how researchers in information systems (IS) should respond. In this paper, we consider the evolving and emerging trends of AI in order to examine its present and predict its future impacts. Many existing papers on GenAI are either too technical for most IS researchers or lack the depth needed to appreciate the potential impacts of GenAI. We, therefore, attempt to bridge the technical and organizational communities of GenAI from a system-oriented sociotechnical perspective. Specifically, we explore the unique features of GenAI, which are rooted in the continued change from symbolism to connectionism, and the deep systemic and inherent properties of human-AI ecosystems. We retrace the evolution of AI that proceeded the level of adoption, adaption, and use found today, in order to propose future research on various impacts of GenAI in both business and society within the context of information systems research. Our efforts are intended to contribute to the creation of a well-structured research agenda in the IS community to support innovative strategies and operations enabled by this new wave of AI.', 'abstract_zh': '基于生成人工智能的发展及其对商业和社会的影响：一种系统导向的社会技术视角', 'title_zh': '生成式人工智能： evolving technology, growing societal impact, and opportunities for information systems research生成式人工智能： evolving technology, growing societal impact, and opportunities for information systems research'}
{'arxiv_id': 'arXiv:2503.05769', 'title': 'Effect of Gender Fair Job Description on Generative AI Images', 'authors': 'Finn Böckling, Jan Marquenie, Ingo Siegert', 'link': 'https://arxiv.org/abs/2503.05769', 'abstract': "STEM fields are traditionally male-dominated, with gender biases shaping perceptions of job accessibility. This study analyzed gender representation in STEM occupation images generated by OpenAI DALL-E 3 \\& Black Forest FLUX.1 using 150 prompts in three linguistic forms: German generic masculine, German pair form, and English. As control, 20 pictures of social occupations were generated as well. Results revealed significant male bias across all forms, with the German pair form showing reduced bias but still overrepresenting men for the STEM-Group and mixed results for the Group of Social Occupations. These findings highlight generative AI's role in reinforcing societal biases, emphasizing the need for further discussion on diversity (in AI). Further aspects analyzed are age-distribution and ethnic diversity.", 'abstract_zh': 'STEM领域传统上男性主导，性别偏见影响着职业可访问性的看法。本研究分析了由OpenAI DALL-E 3 & Black Forest FLUX生成的150个与STEM职业相关的图像中性别代表情况，使用了三种语言形式：德语通用男性形式、德语文本对形式和英语。作为对照，还生成了20张与社会职业相关的图片。结果显示，在所有形式中均存在显著的男性偏见，其中德语文本对形式显示出减少偏见的趋势，但仍过度代表男性群体，且对社会职业群体显示出混合结果。这些发现强调了生成式AI在强化社会偏见方面的作用，强调了进一步讨论多样性的必要性。同时还分析了年龄分布和族裔多样性。', 'title_zh': '性别公平招聘信息对生成式AI图像的影响'}
{'arxiv_id': 'arXiv:2503.05768', 'title': 'A Collection of Innovations in Medical AI for patient records in 2024', 'authors': 'Yuanyun Zhang, Shi Li', 'link': 'https://arxiv.org/abs/2503.05768', 'abstract': 'The field of Artificial Intelligence in healthcare is evolving at an unprecedented pace, driven by rapid advancements in machine learning and the recent breakthroughs in large language models. While these innovations hold immense potential to transform clinical decision making, diagnostics, and patient care, the accelerating speed of AI development has outpaced traditional academic publishing cycles. As a result, many scholarly contributions quickly become outdated, failing to capture the latest state of the art methodologies and their real world implications. This paper advocates for a new category of academic publications an annualized citation framework that prioritizes the most recent AI driven healthcare innovations. By systematically referencing the breakthroughs of the year, such papers would ensure that research remains current, fostering a more adaptive and informed discourse. This approach not only enhances the relevance of AI research in healthcare but also provides a more accurate reflection of the fields ongoing evolution.', 'abstract_zh': '人工智能在医疗领域的研究正在以前所未有的速度发展，得益于机器学习的 rapid advancements 和大型语言模型的 recent breakthroughs。尽管这些创新在改善临床决策、诊断和患者护理方面具有巨大的潜力，但人工智能的发展速度已经超过了传统学术出版周期。因此，许多学术贡献很快变得过时，无法捕捉最新的前沿方法及其实际应用。本文倡导一种新的学术出版类别——年度引用框架，优先考虑最前沿的 AI 驱动医疗创新。通过系统地引用当年的突破性成果，这类论文能够确保研究保持最新，促进更适应和有根据的对话。这种方法不仅增强了人工智能研究在医疗领域的相关性，还更准确地反映了该领域的发展演变。', 'title_zh': '2024年医疗AI在患者记录方面的创新集锦'}
{'arxiv_id': 'arXiv:2503.05767', 'title': 'Mesterséges Intelligencia Kutatások Magyarországon', 'authors': 'András A. Benczúr, Tibor Gyimóthy, Balázs Szegedy', 'link': 'https://arxiv.org/abs/2503.05767', 'abstract': 'Artificial intelligence (AI) has undergone remarkable development since the mid-2000s, particularly in the fields of machine learning and deep learning, driven by the explosive growth of large databases and computational capacity. Hungarian researchers recognized the significance of AI early on, actively participating in international research and achieving significant results in both theoretical and practical domains. This article presents some key achievements in Hungarian AI research. It highlights the results from the period before the rise of deep learning (the early 2010s), then discusses major theoretical advancements in Hungary after 2010. Finally, it provides a brief overview of AI-related applied scientific achievements from 2010 onward.', 'abstract_zh': '自2000年代中期以来，人工智能（AI）取得了 remarkable 的发展，尤其是在机器学习和深度学习领域，这得益于大规模数据库和计算能力的爆炸式增长。匈牙利研究人员早期就认识到AI的重要性，积极参加了国际研究，并在理论和实践领域取得了显著成果。本文介绍了匈牙利AI研究的一些关键成就。它突出了2010年代初深度学习兴起之前的成果，然后讨论了2010年后匈牙利在理论方面的重大进展。最后，它简要概述了2010年以来与AI相关的应用科学成就。', 'title_zh': '匈牙利的机器学习研究'}
{'arxiv_id': 'arXiv:2503.05765', 'title': 'Encoding Inequity: Examining Demographic Bias in LLM-Driven Robot Caregiving', 'authors': 'Raj Korpan', 'link': 'https://arxiv.org/abs/2503.05765', 'abstract': 'As robots take on caregiving roles, ensuring equitable and unbiased interactions with diverse populations is critical. Although Large Language Models (LLMs) serve as key components in shaping robotic behavior, speech, and decision-making, these models may encode and propagate societal biases, leading to disparities in care based on demographic factors. This paper examines how LLM-generated responses shape robot caregiving characteristics and responsibilities when prompted with different demographic information related to sex, gender, sexuality, race, ethnicity, nationality, disability, and age. Findings show simplified descriptions for disability and age, lower sentiment for disability and LGBTQ+ identities, and distinct clustering patterns reinforcing stereotypes in caregiving narratives. These results emphasize the need for ethical and inclusive HRI design.', 'abstract_zh': '随着机器人承担起护理角色，确保与多样人群进行公平无偏见的互动至关重要。尽管大型语言模型（LLMs）在塑造机器人行为、言语和决策中起着关键作用，但这些模型可能编码并传播社会偏见，导致基于人口统计因素的护理不平等。本文探讨了当LLM在处理与性别、性别、性取向、种族、 ethnicity（注：此处应为“族裔”）、国籍、残疾和年龄相关的不同人口统计信息时，如何生成响应影响机器人护理特征和职责。研究发现，残疾和年龄的简化描述，残疾和LGBTQ+身份的较低情感价值，以及强化护理叙事中刻板印象的类别聚类模式。这些结果强调了伦理和包容性人机交互设计的必要性。', 'title_zh': '编码不公平性：探究LLM驱动的机器人护理中的人口统计偏见'}
{'arxiv_id': 'arXiv:2503.05763', 'title': 'Graph Masked Language Models', 'authors': 'Aarush Sinha, OM Kumar CU', 'link': 'https://arxiv.org/abs/2503.05763', 'abstract': 'Language Models (LMs) are integral to Natural Language Processing (NLP), yet their interaction with structured knowledge graphs (KGs) remains an open research challenge. While Graph Neural Networks (GNNs) excel at capturing graph structures, they struggle with textual feature representation compared to pretrained LMs. To bridge this gap, we propose \\textbf{Graph Masked Language Models (GMLM)} for node classification tasks. Our approach introduces two key innovations: a \\textit{semantic masking strategy} that selectively masks nodes based on their structural importance, ensuring critical graph components contribute effectively to learning, and a \\textit{soft masking mechanism} that generates interpolated node representations, enabling smoother information retention and improved gradient flow. Our dual-branch model architecture fuses structural graph information with contextual embeddings via a multi-layer fusion network. Extensive experiments on six node classification benchmarks demonstrate that GMLM not only achieves state-of-the-art (SOTA) performance but also enhances robustness and stability across datasets.', 'abstract_zh': '语言模型（LMs）是自然语言处理（NLP）的核心，然而它们与结构化知识图谱（KGs）的交互仍然是一个开放的研究挑战。虽然图神经网络（GNNs）在捕捉图结构方面表现优异，但在文本特征表示方面却不如预训练的语言模型。为了解决这一问题，我们提出了一种用于节点分类任务的**图掩码语言模型（GMLM）**。该方法包含两项关键创新：一种基于节点结构重要性的**语义掩码策略**，确保关键图组件有效参与到学习中；以及一种软掩码机制，生成插值节点表示，实现更平滑的信息保留和改进的梯度流动。我们的双分支模型架构通过多层融合网络将结构性图信息与上下文嵌入结合起来。在六个节点分类基准上的广泛实验表明，GMLM不仅能实现目前最高的（SOTA）性能，还在数据集间提高了鲁棒性和稳定性。', 'title_zh': '图掩码语言模型'}
{'arxiv_id': 'arXiv:2503.05760', 'title': "The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its Own", 'authors': 'Gokul Puthumanaillam, Melkior Ornik', 'link': 'https://arxiv.org/abs/2503.05760', 'abstract': 'This paper presents a comprehensive investigation into the capability of Large Language Models (LLMs) to successfully complete a semester-long undergraduate control systems course. Through evaluation of 115 course deliverables, we assess LLM performance using ChatGPT under a ``minimal effort" protocol that simulates realistic student usage patterns. The investigation employs a rigorous testing methodology across multiple assessment formats, from auto-graded multiple choice questions to complex Python programming tasks and long-form analytical writing. Our analysis provides quantitative insights into AI\'s strengths and limitations in handling mathematical formulations, coding challenges, and theoretical concepts in control systems engineering. The LLM achieved a B-grade performance (82.24\\%), approaching but not exceeding the class average (84.99\\%), with strongest results in structured assignments and greatest limitations in open-ended projects. The findings inform discussions about course design adaptation in response to AI advancement, moving beyond simple prohibition towards thoughtful integration of these tools in engineering education. Additional materials including syllabus, examination papers, design projects, and example responses can be found at the project website: this https URL.', 'abstract_zh': '本论文对大型语言模型（LLMs）在完成一整个学期的本科生控制系统课程中的能力进行了全面调查。通过评估115份课程作业，我们使用“低投入”协议来评估ChatGPT的表现，该协议模拟了实际的学生使用模式。调查采用了多种评估方法，从自动评分的选择题到复杂的Python编程任务和长篇分析性写作。我们的分析提供了关于AI在处理控制系统工程中的数学公式、编码挑战和理论概念方面的优势与局限性的定量见解。LLM取得了B级成绩（82.24%），接近但未超过班级平均分（84.99%），在结构化作业中表现最佳，在开放型项目中表现最差。该研究结果有助于讨论课程设计适应性问题，以应对AI的发展，从简单的禁止转向对这些工具进行有深思熟虑的整合。更多材料，包括课程大纲、考试试卷、设计项目和示例答案，可在项目网站上找到：this https URL。', 'title_zh': '懒学生的好梦：ChatGPT独自通过工程课程'}
{'arxiv_id': 'arXiv:2503.05758', 'title': 'ADAPT Centre Contribution on Implementation of the EU AI Act and Fundamental Right Protection', 'authors': 'Dave Lewis, Marta Lasek-Markey, Harshvardhan J. Pandit, Delaram Golpayegani, Darren McCabe, Louise McCormack, Joshua Hovsha, Deirdre Ahern, Arthit Suriyawongku', 'link': 'https://arxiv.org/abs/2503.05758', 'abstract': "This document represents the ADAPT Centre's submission to the Irish Department of Enterprise, Trade and Employment (DETE) regarding the public consultation on implementation of the EU AI Act.", 'abstract_zh': '本论文代表ADAPT研究中心向爱尔兰工业、贸易和就业部（DETE）提交的关于欧盟AI法案实施公众咨询的报告。', 'title_zh': 'ADAPT中心在实施欧盟AI法案与基本权利保护方面的贡献'}
{'arxiv_id': 'arXiv:2503.05757', 'title': 'Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models', 'authors': 'Prasenjit Dey, Srujana Merugu, Sivaramakrishnan Kaveri', 'link': 'https://arxiv.org/abs/2503.05757', 'abstract': 'Large Language Models (LLMs) are known to hallucinate and generate non-factual outputs which can undermine user trust. Traditional methods to directly mitigate hallucinations, such as representation editing and contrastive decoding, often require additional training data and involve high implementation complexity. While ensemble-based approaches harness multiple LLMs to tap into the "wisdom of crowds", these methods overlook uncertainties in individual model responses. Recent studies reveal that uncertainty estimation can enable LLMs to self-assess the likelihood of generating hallucinations. In this work, we focus on factoid question answering (QA) and observe that LLMs accuracy and self-assessment capabilities vary widely with different models excelling in different scenarios. Leveraging this insight, we propose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces hallucinations by strategically combining multiple LLM based on their accuracy and self-assessment abilities. Empirical results on several public benchmark datasets show that UAF outperforms state-of-the-art hallucination mitigation methods by $8\\%$ in factual accuracy, while either narrowing or surpassing the performance gap with GPT-4.', 'abstract_zh': '大规模语言模型（LLMs） Known to Hallucinate and Generate Non-Factual Outputs, Undermining User Trust: An Uncertainty-Aware Fusion Approach (UAF) for Reducing Hallucinations in Factoid Question Answering', 'title_zh': '不确定性意识融合：一种缓解大型语言模型幻觉的集成框架'}
{'arxiv_id': 'arXiv:2503.05755', 'title': 'SEAFL: Enhancing Efficiency in Semi-Asynchronous Federated Learning through Adaptive Aggregation and Selective Training', 'authors': 'Md Sirajul Islam, Sanjeev Panta, Fei Xu, Xu Yuan, Li Chen, Nian-Feng Tzeng', 'link': 'https://arxiv.org/abs/2503.05755', 'abstract': 'Federated Learning (FL) is a promising distributed machine learning framework that allows collaborative learning of a global model across decentralized devices without uploading their local data. However, in real-world FL scenarios, the conventional synchronous FL mechanism suffers from inefficient training caused by slow-speed devices, commonly known as stragglers, especially in heterogeneous communication environments. Though asynchronous FL effectively tackles the efficiency challenge, it induces substantial system overheads and model degradation. Striking for a balance, semi-asynchronous FL has gained increasing attention, while still suffering from the open challenge of stale models, where newly arrived updates are calculated based on outdated weights that easily hurt the convergence of the global model. In this paper, we present {\\em SEAFL}, a novel FL framework designed to mitigate both the straggler and the stale model challenges in semi-asynchronous FL. {\\em SEAFL} dynamically assigns weights to uploaded models during aggregation based on their staleness and importance to the current global model. We theoretically analyze the convergence rate of {\\em SEAFL} and further enhance the training efficiency with an extended variant that allows partial training on slower devices, enabling them to contribute to global aggregation while reducing excessive waiting times. We evaluate the effectiveness of {\\em SEAFL} through extensive experiments on three benchmark datasets. The experimental results demonstrate that {\\em SEAFL} outperforms its closest counterpart by up to $\\sim$22\\% in terms of the wall-clock training time required to achieve target accuracy.', 'abstract_zh': '联邦学习（FL）是一种有潜力的分布式机器学习框架，允许在不上传本地数据的情况下，跨分散设备协作学习全局模型。然而，在实际的FL场景中，传统的同步FL机制由于慢速设备，即所谓的“拖后腿节点”，在异构通信环境中效率低下。尽管异步FL可以有效应对效率挑战，但它会引入显著的系统开销和模型退化。介于两者之间，半异步FL正逐渐受到关注，但仍面临过时模型的开放挑战，其中新到达的更新基于过时的权重进行计算，这容易损害全局模型的收敛。本文提出了一种名为SEAFL的新颖FL框架，旨在解决半异步FL中的拖后腿节点和过时模型挑战。SEAFL在聚合期间基于模型的过时程度和对当前全局模型的重要性动态分配权重。我们从理论上分析了SEAFL的收敛速率，并通过扩展变体进一步提高训练效率，该扩展变体允许在较慢的设备上进行部分训练，使其能够在减少过多等待时间的情况下贡献于全局聚合。我们通过在三个基准数据集上进行广泛实验评估SEAFL的有效性。实验结果表明，与最接近的对照组相比，SEAFL在实现目标准确率所需的墙-clock训练时间上表现出优越性，最高可提高约22%。', 'title_zh': 'SEAFL：通过自适应聚合和选择性训练提升半异步联邦学习的效率'}
{'arxiv_id': 'arXiv:2503.05753', 'title': 'Exploring AI Writers: Technology, Impact, and Future Prospects', 'authors': 'Zhiqian Huang', 'link': 'https://arxiv.org/abs/2503.05753', 'abstract': 'This study explores the practical capabilities of AI writers, focusing on their applications across various creative domains. It delves into the potential impact of AI-generated content on traditional media industries and academic writing processes. The research examines how AI tools are reshaping news production workflows, particularly in fields such as finance, sports, and natural disasters. Additionally, it addresses ethical concerns, including authorship and copyright issues arising from AI-driven creative outputs. The findings reveal mixed perceptions among media students regarding the integration of AI into their profession, reflecting both optimism about efficiency gains and apprehensions over increased job market competition.', 'abstract_zh': '本研究探讨了人工智能撰稿人的实际能力，重点关注其在各类创意领域的应用。研究深入分析了人工智能生成内容对传统媒体行业及学术写作流程的潜在影响。研究考察了AI工具如何重新塑造新闻生产工作流程，特别是在金融、体育和自然灾害等领域。此外，研究还探讨了由AI驱动的创意输出引发的伦理问题，包括作者归属和版权问题。研究发现，媒体学生对将AI整合到其职业中持有复杂的看法，既体现了对效率提升的乐观态度，也反映了对就业市场竞争加剧的担忧。', 'title_zh': '探索AI写手：技术、影响与未来前景'}
{'arxiv_id': 'arXiv:2503.05750', 'title': 'CSTRL: Context-Driven Sequential Transfer Learning for Abstractive Radiology Report Summarization', 'authors': 'Mst. Fahmida Sultana Naznin, Adnan Ibney Faruq, Mostafa Rifat Tazwar, Md Jobayer, Md. Mehedi Hasan Shawon, Md Rakibul Hasan', 'link': 'https://arxiv.org/abs/2503.05750', 'abstract': "A radiology report comprises several sections, including the Findings and Impression of the diagnosis. Automatically generating the Impression from the Findings is crucial for reducing radiologists' workload and improving diagnostic accuracy. Pretrained models that excel in common abstractive summarization problems encounter challenges when applied to specialized medical domains largely due to the complex terminology and the necessity for accurate clinical context. Such tasks in medical domains demand extracting core information, avoiding context shifts, and maintaining proper flow. Misuse of medical terms can lead to drastic clinical errors. To address these issues, we introduce a sequential transfer learning that ensures key content extraction and coherent summarization. Sequential transfer learning often faces challenges like initial parameter decay and knowledge loss, which we resolve with the Fisher matrix regularization. Using MIMIC-CXR and Open-I datasets, our model, CSTRL-Context-driven Sequential TRansfer Learning-achieved state-of-the-art performance, showing 56.2% improvement in BLEU-1, 40.5% in BLEU-2, 84.3% in BLEU-3, 28.9% in ROUGE-1, 41.0% in ROUGE-2 and 26.5% in ROGUE-3 score over benchmark studies. We also analyze factual consistency scores while preserving the medical context. Our code is publicly available at TBA.", 'abstract_zh': '医学影像报告包括几个部分，如发现和诊断印象。从发现自动生成印象对于减轻放射学家的工作负荷和提高诊断准确性至关重要。由于复杂的医学术语和需要准确的临床背景，预训练模型在应用到专业医学领域时面临挑战。医学领域的此类任务要求提取核心信息、避免内容转换并保持正确的语义流程。错误使用医学术语可能导致严重的临床错误。为了解决这些问题，我们引入了一种序贯迁移学习方法，确保关键内容提取和连贯总结。序贯迁移学习常常面临初始参数衰减和知识损失等挑战，我们通过Fisher矩阵正则化解决了这些问题。使用MIMIC-CXR和Open-I数据集，我们的模型CSTRL-基于上下文的序贯转移学习达到了最先进的性能，BLEU-1分数提高了56.2%，BLEU-2提高了40.5%，BLEU-3提高了84.3%，ROUGE-1提高了28.9%，ROUGE-2提高了41.0%，ROUGE-3提高了26.5%。同时，我们保持了医学背景进行了事实一致性分析。我们的代码将在TBA上公开。', 'title_zh': '基于上下文驱动的序列迁移学习的抽象放射学报告总结'}
{'arxiv_id': 'arXiv:2503.05748', 'title': 'Alignment, Agency and Autonomy in Frontier AI: A Systems Engineering Perspective', 'authors': 'Krti Tallam', 'link': 'https://arxiv.org/abs/2503.05748', 'abstract': 'As artificial intelligence scales, the concepts of alignment, agency, and autonomy have become central to AI safety, governance, and control. However, even in human contexts, these terms lack universal definitions, varying across disciplines such as philosophy, psychology, law, computer science, mathematics, and political science. This inconsistency complicates their application to AI, where differing interpretations lead to conflicting approaches in system design and regulation. This paper traces the historical, philosophical, and technical evolution of these concepts, emphasizing how their definitions influence AI development, deployment, and oversight.\nWe argue that the urgency surrounding AI alignment and autonomy stems not only from technical advancements but also from the increasing deployment of AI in high-stakes decision making. Using Agentic AI as a case study, we examine the emergent properties of machine agency and autonomy, highlighting the risks of misalignment in real-world systems. Through an analysis of automation failures (Tesla Autopilot, Boeing 737 MAX), multi-agent coordination (Metas CICERO), and evolving AI architectures (DeepMinds AlphaZero, OpenAIs AutoGPT), we assess the governance and safety challenges posed by frontier AI.', 'abstract_zh': '随着人工智能的发展，对齐性、自主性和自主权的概念已成为人工智能安全、治理和控制的核心。然而，在人类情境中，这些术语缺乏统一定义，在哲学、心理学、法律、计算机科学、数学和政治科学等多个学科中有所差异。这种不一致性使这些概念在应用于人工智能时变得更加复杂，不同的解释导致系统设计和监管中存在冲突的方法。本文追溯了这些概念的历史、哲学和技术进化，强调其定义如何影响人工智能的发展、部署和监管。\n\n我们指出，围绕人工智能对齐性和自主性的紧迫性不仅源于技术进步，还在于人工智能在高风险决策中的日益广泛应用。通过以Agentic AI为例，我们探讨了机器自主性与自主权的 emergent 属性，并强调现实系统中对齐性偏差的风险。通过对自动化失败案例（特斯拉Autopilot，波音737 MAX）、多智能体协调（Meta CICERO）和 evolving 人工智能架构（DeepMind AlphaZero，OpenAI AutoGPT）的分析，我们评估了前沿人工智能带来的治理和安全挑战。', 'title_zh': '前沿人工智能中的对齐、自主与自治：系统工程视角'}
{'arxiv_id': 'arXiv:2503.05747', 'title': 'Balancing Innovation and Integrity: AI Integration in Liberal Arts College Administration', 'authors': 'Ian Olivo Read', 'link': 'https://arxiv.org/abs/2503.05747', 'abstract': "This paper explores the intersection of artificial intelligence and higher education administration, focusing on liberal arts colleges (LACs). It examines AI's opportunities and challenges in academic and student affairs, legal compliance, and accreditation processes, while also addressing the ethical considerations of AI deployment in mission-driven institutions. Considering AI's value pluralism and potential allocative or representational harms caused by algorithmic bias, LACs must ensure AI aligns with its mission and principles. The study highlights other strategies for responsible AI integration, balancing innovation with institutional values.", 'abstract_zh': '本文探索人工智能与高等教育管理的交集，重点关注文理学院。它分析了人工智能在学术事务、学生事务、法律法规遵从及认证过程中的机遇与挑战，同时探讨了在具有使命驱动性质的机构中部署人工智能时的伦理考量。鉴于人工智能的价值多元性和因算法偏见可能带来的分配或代表性危害，文理学院必须确保人工智能与其使命和原则相一致。研究强调了负责任地整合人工智能的其他策略，平衡创新与机构价值。', 'title_zh': '平衡创新与诚信：文科学院管理中人工智能的整合'}
{'arxiv_id': 'arXiv:2503.05740', 'title': 'ChatWise: AI-Powered Engaging Conversations for Enhancing Senior Cognitive Wellbeing', 'authors': 'Zhengbang Yang, Zhuangdi Zhu', 'link': 'https://arxiv.org/abs/2503.05740', 'abstract': "Cognitive health in older adults presents a growing challenge. While conversational interventions show feasibility in improving cognitive wellness, human caregiver resources remain overburdened. AI-based methods have shown promise in providing conversational support, yet existing work is limited to implicit strategy while lacking multi-turn support tailored to seniors. We improve prior art with an LLM-driven chatbot named ChatWise for older adults. It follows dual-level conversation reasoning at the inference phase to provide engaging companionship. ChatWise thrives in long-turn conversations, in contrast to conventional LLMs that primarily excel in short-turn exchanges. Grounded experiments show that ChatWise significantly enhances simulated users' cognitive and emotional status, including those with Mild Cognitive Impairment.", 'abstract_zh': '老年人的认知健康呈日益严峻的挑战。虽然对话干预显示了在改善认知健康方面可行性，但人类护理资源仍不堪重负。基于AI的方法在提供对话支持方面显示了潜力，但现有工作局限于隐含策略，缺乏针对老年人的多轮次个性化支持。我们通过一个名为ChatWise的LLM驱动聊天机器人改进了以往的研究，它在推理阶段遵循双层对话推理机制，提供互动陪伴。ChatWise在长轮次对话中表现突出，而传统的LLM主要在短轮次交流中表现出色。基于地面实操的实验表明，ChatWise显著提升了模拟用户，包括轻度认知障碍患者，的认知和情绪状态。', 'title_zh': 'ChatWise：增强老年人认知健康的人工智能驱动交互对话'}
{'arxiv_id': 'arXiv:2503.05737', 'title': 'Local Differences, Global Lessons: Insights from Organisation Policies for International Legislation', 'authors': 'Lucie-Aimée Kaffee, Pepa Atanasova, Anna Rogers', 'link': 'https://arxiv.org/abs/2503.05737', 'abstract': 'The rapid adoption of AI across diverse domains has led to the development of organisational guidelines that vary significantly, even within the same sector. This paper examines AI policies in two domains, news organisations and universities, to understand how bottom-up governance approaches shape AI usage and oversight. By analysing these policies, we identify key areas of convergence and divergence in how organisations address risks such as bias, privacy, misinformation, and accountability. We then explore the implications of these findings for international AI legislation, particularly the EU AI Act, highlighting gaps where practical policy insights could inform regulatory refinements. Our analysis reveals that organisational policies often address issues such as AI literacy, disclosure practices, and environmental impact, areas that are underdeveloped in existing international frameworks. We argue that lessons from domain-specific AI policies can contribute to more adaptive and effective AI governance at the global level. This study provides actionable recommendations for policymakers seeking to bridge the gap between local AI practices and international regulations.', 'abstract_zh': '跨领域快速采纳人工智能导致组织指导原则在不同领域之间存在显著差异，即使在同一行业中也是如此。本文探讨新闻组织和大学领域的AI政策，以了解自下而上的治理方法如何影响人工智能的应用和监督。通过分析这些政策，我们识别出组织在应对偏差、隐私、虚假信息和问责等问题上的关键趋同与分歧领域。我们随后探讨这些发现对国际人工智能立法，特别是欧盟人工智能法案的影响，强调存在的差距，这些差距可以通过实用的政策洞察来指导立法改进。我们的分析显示，组织政策通常会关注人工智能素养、披露实践和环境影响等问题，而这些问题在现有的国际框架中尚未得到充分发展。我们认为，领域特定的人工智能政策经验可以为全球更适应和有效的治理做出贡献。该研究提供了供政策制定者参考的具体建议，旨在弥合地方人工智能实践与国际法规之间的差距。', 'title_zh': '局部差异，全局启示：组织政策对于国际立法的见解'}
{'arxiv_id': 'arXiv:2503.05734', 'title': 'Modeling Behavior Change for Multi-model At-Risk Students Early Prediction (extended version)', 'authors': 'Jiabei Cheng, Zhen-Qun Yang, Jiannong Cao, Yu Yang, Kai Cheung Franky Poon, Daniel Lai', 'link': 'https://arxiv.org/abs/2503.05734', 'abstract': 'In the educational domain, identifying students at risk of dropping out is essential for allowing educators to intervene effectively, improving both academic outcomes and overall student well-being. Data in educational settings often originate from diverse sources, such as assignments, grades, and attendance records. However, most existing research relies on online learning data and just extracting the quantitative features. While quantification eases processing, it also leads to a significant loss of original information. Moreover, current models primarily identify students with consistently poor performance through simple and discrete behavioural patterns, failing to capture the complex continuity and non-linear changes in student behaviour. We have developed an innovative prediction model, Multimodal- ChangePoint Detection (MCPD), utilizing the textual teacher remark data and numerical grade data from middle schools. Our model achieves a highly integrated and intelligent analysis by using independent encoders to process two data types, fusing the encoded feature. The model further refines its analysis by leveraging a changepoint detection module to pinpoint crucial behavioral changes, which are integrated as dynamic weights through a simple attention mechanism. Experimental validations indicate that our model achieves an accuracy range of 70- 75%, with an average outperforming baseline algorithms by approximately 5-10%. Additionally, our algorithm demonstrates a certain degree of transferability, maintaining high accuracy when adjusted and retrained with different definitions of at-risk, proving its broad applicability.', 'abstract_zh': '在教育领域，识别有辍学风险的学生对于允许教育者有效干预、改善学术成果和整体学生福祉至关重要。教育场景中的数据通常来自多种来源，如作业、成绩和出勤记录。然而，现有大多数研究依赖于在线学习数据，并仅提取定量特征。虽然量化简化了处理过程，但也导致了大量的原始信息丢失。此外，当前模型主要通过简单的离散行为模式来识别持续表现不佳的学生，未能捕捉学生行为的复杂连续性和非线性变化。我们开发了一种创新预测模型——多模态变化点检测（MCPD），利用中学的文本教师评语数据和数字成绩数据。该模型通过使用独立编码器处理两种数据类型并融合编码特征，实现了高度集成和智能的分析。模型进一步通过变更点检测模块识别关键行为变化，并通过简单的注意力机制将这些变化作为动态权重进行整合。实验验证显示，该模型的准确率为70%-75%，平均比基线算法高出约5-10%。此外，我们的算法具有一定的迁移性，在调整和重新训练时仍能保持高准确性，证明了其广泛的适用性。', 'title_zh': '多模型风险学生早期行为改变建模（扩展版本）'}
{'arxiv_id': 'arXiv:2503.05733', 'title': 'Design an Ontology for Cognitive Business Strategy Based on Customer Satisfaction', 'authors': 'Neda Bagherzadeh, Saeed Setayeshi, Samaneh Yazdani', 'link': 'https://arxiv.org/abs/2503.05733', 'abstract': 'Ontology is a general term used by researchers who want to share information in a specific domain. One of the hallmarks of the greatest success of a powerful manager of an organization is his ability to interpret unplanned and unrelated events. Tools to solve this problem are vital to business growth. Modern technology allows customers to be more informed and influential in their roles as patrons and critics. This can make or break a business. Research shows that businesses that employ a customer-first strategy and prioritize their customers can generate more revenue. Even though there are many different Ontologies offered to businesses, none of it is built from a cognitive perspective. The objective of this study is to address the concept of strategic business plans with a cognitive ontology approach as a basis for a new management tool. This research proposes to design a cognitive ontology model that links customer measurement with traditional business models, define relationships between components and verify the accuracy of the added financial value.', 'abstract_zh': 'Ontology是一种研究人员用于在特定领域共享信息的通用术语。一个强大组织的卓越管理者最大成功之一在于其解读未预见和无关事件的能力。解决这一问题的工具对业务增长至关重要。现代技术使得顾客在消费者和批评者角色中更加知情和有影响力。这可能决定着一个企业的成败。研究显示，采用以顾客为中心的战略并优先考虑顾客的公司可以产生更多的收入。尽管市场上有许多不同类型的Ontology可供企业选择，但它们均未从认知角度进行构建。本研究的目标是采用基于认知Ontology的方法来讨论战略业务计划的概念，并作为新一代管理工具的基础。本文提议设计一个认知Ontology模型，将客户测量与传统商业模式联系起来，定义组件之间的关系，并验证所增加的财务价值的准确性。', 'title_zh': '基于客户满意度的认知商业战略本体设计'}
{'arxiv_id': 'arXiv:2503.05731', 'title': 'AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons', 'authors': 'Shaona Ghosh, Heather Frase, Adina Williams, Sarah Luger, Paul Röttger, Fazl Barez, Sean McGregor, Kenneth Fricklas, Mala Kumar, Quentin Feuillade--Montixi, Kurt Bollacker, Felix Friedrich, Ryan Tsang, Bertie Vidgen, Alicia Parrish, Chris Knotz, Eleonora Presani, Jonathan Bennion, Marisa Ferrara Boston, Mike Kuniavsky, Wiebke Hutiri, James Ezick, Malek Ben Salem, Rajat Sahay, Sujata Goswami, Usman Gohar, Ben Huang, Supheakmungkol Sarin, Elie Alhajjar, Canyu Chen, Roman Eng, Kashyap Ramanandula Manjusha, Virendra Mehta, Eileen Long, Murali Emani, Natan Vidra, Benjamin Rukundo, Abolfazl Shahbazi, Kongtao Chen, Rajat Ghosh, Vithursan Thangarasa, Pierre Peigné, Abhinav Singh, Max Bartolo, Satyapriya Krishna, Mubashara Akhtar, Rafael Gold, Cody Coleman, Luis Oala, Vassil Tashev, Joseph Marvin Imperial, Amy Russ, Sasidhar Kunapuli, Nicolas Miailhe, Julien Delaunay, Bhaktipriya Radharapu, Rajat Shinde, Tuesday, Debojyoti Dutta, Declan Grabb, Ananya Gangavarapu, Saurav Sahay, Agasthya Gangavarapu, Patrick Schramowski, Stephen Singam, Tom David, Xudong Han, Priyanka Mary Mammen, Tarunima Prabhakar, Venelin Kovatchev, Ahmed Ahmed, Kelvin N. Manyeki, Sandeep Madireddy, Foutse Khomh, Fedor Zhdanov, Joachim Baumann, Nina Vasan, Xianjun Yang, Carlos Mougn, Jibin Rajan Varghese, Hussain Chinoy, Seshakrishna Jitendar, Manil Maskey, Claire V. Hardgrove, Tianhao Li, Aakash Gupta, Emil Joswin, Yifan Mai, Shachi H Kumar, Cigdem Patlak, Kevin Lu, Vincent Alessi, Sree Bhargavi Balija, Chenhe Gu, Robert Sullivan, James Gealy, Matt Lavrisa, James Goel, Peter Mattson, Percy Liang, Joaquin Vanschoren', 'link': 'https://arxiv.org/abs/2503.05731', 'abstract': "The rapid advancement and deployment of AI systems have created an urgent need for standard safety-evaluation frameworks. This paper introduces AILuminate v1.0, the first comprehensive industry-standard benchmark for assessing AI-product risk and reliability. Its development employed an open process that included participants from multiple fields. The benchmark evaluates an AI system's resistance to prompts designed to elicit dangerous, illegal, or undesirable behavior in 12 hazard categories, including violent crimes, nonviolent crimes, sex-related crimes, child sexual exploitation, indiscriminate weapons, suicide and self-harm, intellectual property, privacy, defamation, hate, sexual content, and specialized advice (election, financial, health, legal). Our method incorporates a complete assessment standard, extensive prompt datasets, a novel evaluation framework, a grading and reporting system, and the technical as well as organizational infrastructure for long-term support and evolution. In particular, the benchmark employs an understandable five-tier grading scale (Poor to Excellent) and incorporates an innovative entropy-based system-response evaluation.\nIn addition to unveiling the benchmark, this report also identifies limitations of our method and of building safety benchmarks generally, including evaluator uncertainty and the constraints of single-turn interactions. This work represents a crucial step toward establishing global standards for AI risk and reliability evaluation while acknowledging the need for continued development in areas such as multiturn interactions, multimodal understanding, coverage of additional languages, and emerging hazard categories. Our findings provide valuable insights for model developers, system integrators, and policymakers working to promote safer AI deployment.", 'abstract_zh': 'AI系统的快速进步与部署迫切需要标准安全评估框架。本文介绍了AILuminate v1.0，这是首个全面的行业标准基准，用于评估AI产品的风险和可靠性。该基准评估了AI系统在12个危害类别中的抗性，包括暴力犯罪、非暴力犯罪、性犯罪、儿童性剥削、非选择性武器、自杀和自残、知识产权、隐私、诽谤、仇恨、性内容和专业建议（选举、金融、健康、法律），涵盖了广泛的危险行为诱导提示。我们的方法包括完整的评估标准、广泛的提示数据集、创新的评估框架、评分和报告系统，以及长期支持和演化的技术和组织基础设施。特别是，基准采用了易于理解的五级评分体系（差到优秀），并引入了基于熵的系统响应评估机制。除了公布该基准之外，本报告还指出了我们方法及构建安全基准的一般局限性，包括评估者的不确定性以及单轮交互的约束。本研究代表了朝着建立全球AI风险与可靠性评估标准迈出的关键一步，同时认识到在多轮交互、多模态理解、其他语言覆盖及新兴危害类别领域仍需持续发展。我们的发现为促进更安全的AI部署提供了宝贵的见解，适用于模型开发者、系统集成商和政策制定者。', 'title_zh': 'AILuminate: MLCommons的AI风险与可靠性基准v1.0介绍'}
{'arxiv_id': 'arXiv:2503.05730', 'title': 'Robust Optimization with Diffusion Models for Green Security', 'authors': 'Lingkai Kong, Haichuan Wang, Yuqi Pan, Cheol Woo Kim, Mingxiao Song, Alayna Nguyen, Tonghan Wang, Haifeng Xu, Milind Tambe', 'link': 'https://arxiv.org/abs/2503.05730', 'abstract': 'In green security, defenders must forecast adversarial behavior, such as poaching, illegal logging, and illegal fishing, to plan effective patrols. These behavior are often highly uncertain and complex. Prior work has leveraged game theory to design robust patrol strategies to handle uncertainty, but existing adversarial behavior models primarily rely on Gaussian processes or linear models, which lack the expressiveness needed to capture intricate behavioral patterns. To address this limitation, we propose a conditional diffusion model for adversary behavior modeling, leveraging its strong distribution-fitting capabilities. To the best of our knowledge, this is the first application of diffusion models in the green security domain. Integrating diffusion models into game-theoretic optimization, however, presents new challenges, including a constrained mixed strategy space and the need to sample from an unnormalized distribution to estimate utilities. To tackle these challenges, we introduce a mixed strategy of mixed strategies and employ a twisted Sequential Monte Carlo (SMC) sampler for accurate sampling. Theoretically, our algorithm is guaranteed to converge to an epsilon equilibrium with high probability using a finite number of iterations and samples. Empirically, we evaluate our approach on both synthetic and real-world poaching datasets, demonstrating its effectiveness.', 'abstract_zh': '在绿色安全领域，防御者必须预测诸如偷猎、非法砍伐和非法捕鱼等敌对行为，以规划有效的巡逻策略。这些行为往往高度不确定且复杂。以往研究通过博弈论设计了稳健的巡逻策略以应对不确定性，但现有的敌对行为模型主要依赖于高斯过程或线性模型，这限制了它们捕捉复杂行为模式的能力。为解决这一限制，我们提出了一种条件扩散模型来建模敌对行为，利用其强大的分布拟合能力。据我们所知，这是首次在绿色安全领域应用扩散模型。然而，将扩散模型融入博弈论优化带来了新的挑战，包括受限的混合策略空间以及需要从未正则化分布中采样以估计效用。为解决这些挑战，我们引入了一种混合策略，并采用扭曲的顺序蒙特卡洛（SMC）采样器进行准确采样。理论上，我们的算法在有限的迭代次数和样本数量下有高概率收敛到ε平衡点。实验上，我们分别在合成的和实际的偷猎数据集上评估了我们的方法，证明了其有效性。', 'title_zh': '基于扩散模型的鲁棒优化绿色安全'}
{'arxiv_id': 'arXiv:2503.05728', 'title': 'Political Neutrality in AI is Impossible- But Here is How to Approximate it', 'authors': 'Jillian Fisher, Ruth E. Appel, Chan Young Park, Yujin Potter, Liwei Jiang, Taylor Sorensen, Shangbin Feng, Yulia Tsvetkov, Margaret E. Roberts, Jennifer Pan, Dawn Song, Yejin Choi', 'link': 'https://arxiv.org/abs/2503.05728', 'abstract': 'AI systems often exhibit political bias, influencing users\' opinions and decision-making. While political neutrality-defined as the absence of bias-is often seen as an ideal solution for fairness and safety, this position paper argues that true political neutrality is neither feasible nor universally desirable due to its subjective nature and the biases inherent in AI training data, algorithms, and user interactions. However, inspired by Joseph Raz\'s philosophical insight that "neutrality [...] can be a matter of degree" (Raz, 1986), we argue that striving for some neutrality remains essential for promoting balanced AI interactions and mitigating user manipulation. Therefore, we use the term "approximation" of political neutrality to shift the focus from unattainable absolutes to achievable, practical proxies. We propose eight techniques for approximating neutrality across three levels of conceptualizing AI, examining their trade-offs and implementation strategies. In addition, we explore two concrete applications of these approximations to illustrate their practicality. Finally, we assess our framework on current large language models (LLMs) at the output level, providing a demonstration of how it can be evaluated. This work seeks to advance nuanced discussions of political neutrality in AI and promote the development of responsible, aligned language models.', 'abstract_zh': 'AI系统中的政治中立：从理想到实际的逼近', 'title_zh': 'AI中的政治中立是不可能的——但这里有如何接近它的方法'}
{'arxiv_id': 'arXiv:2503.05725', 'title': 'A new framework for prognostics in decentralized industries: Enhancing fairness, security, and transparency through Blockchain and Federated Learning', 'authors': 'T.Q.D. Pham, K.D. Tran, Khanh T. P. Nguyen, X.V. Tran, K.P. Tran', 'link': 'https://arxiv.org/abs/2503.05725', 'abstract': 'As global industries transition towards Industry 5.0 predictive maintenance PM remains crucial for cost effective operations resilience and minimizing downtime in increasingly smart manufacturing environments In this chapter we explore how the integration of Federated Learning FL and blockchain BC technologies enhances the prediction of machinerys Remaining Useful Life RUL within decentralized and human centric industrial ecosystems Traditional centralized data approaches raise concerns over privacy security and scalability especially as Artificial intelligence AI driven smart manufacturing becomes more prevalent This chapter leverages FL to enable localized model training across multiple sites while utilizing BC to ensure trust transparency and data integrity across the network This BC integrated FL framework optimizes RUL predictions enhances data privacy and security establishes transparency and promotes collaboration in decentralized manufacturing It addresses key challenges such as maintaining privacy and security ensuring transparency and fairness and incentivizing participation in decentralized networks Experimental validation using the NASA CMAPSS dataset demonstrates the model effectiveness in real world scenarios and we extend our findings to the broader research community through open source code on GitHub inviting collaborative development to drive innovation in Industry 5.0', 'abstract_zh': '随着全球工业向 Industry 5.0 转型，预测性维护 PM 在成本有效运营、增强韧性以及减少停机时间方面仍然至关重要，在日益智能化的制造环境中尤为如此。本章探讨了联邦学习 FL 和区块链 BC 技术集成如何在分散且以人类为中心的工业生态系统中增强机器剩余使用寿命 RUL 的预测。传统的集中式数据方法在人工智能 AI 驱动的智能制造普及过程中引发了对隐私、安全性和可扩展性的担忧。本章利用联邦学习实现多站点的局部模型训练，同时利用区块链确保网络中的信任、透明度和数据完整性。该区块链集成的联邦学习框架优化了 RUL 的预测，增强了数据隐私和安全性，促进了透明度和分散制造中的协作。本章解决了分散网络中维护隐私和安全、确保透明度和公平性以及激励参与的关键挑战。通过使用 NASA CMAPSS 数据集进行实验验证，证明了模型在现实场景中的有效性，并通过 GitHub 上的开源代码扩展了研究发现，邀请合作开发以推动 Industry 5.0 的创新。', 'title_zh': '分散行业前瞻性分析的新框架：通过区块链和联邦学习增强公平性、安全性和透明度'}
{'arxiv_id': 'arXiv:2503.05724', 'title': 'Addressing Moral Uncertainty using Large Language Models for Ethical Decision-Making', 'authors': 'Rohit K. Dubey, Damian Dailisan, Sachit Mahajan', 'link': 'https://arxiv.org/abs/2503.05724', 'abstract': 'We present an ethical decision-making framework that refines a pre-trained reinforcement learning (RL) model using a task-agnostic ethical layer. Following initial training, the RL model undergoes ethical fine-tuning, where human feedback is replaced by feedback generated from a large language model (LLM). The LLM embodies consequentialist, deontological, virtue, social justice, and care ethics as moral principles to assign belief values to recommended actions during ethical decision-making. An ethical layer aggregates belief scores from multiple LLM-derived moral perspectives using Belief Jensen-Shannon Divergence and Dempster-Shafer Theory into probability scores that also serve as the shaping reward, steering the agent toward choices that align with a balanced ethical framework. This integrated learning framework helps the RL agent navigate moral uncertainty in complex environments and enables it to make morally sound decisions across diverse tasks. Our approach, tested across different LLM variants and compared with other belief aggregation techniques, demonstrates improved consistency, adaptability, and reduced reliance on handcrafted ethical rewards. This method is especially effective in dynamic scenarios where ethical challenges arise unexpectedly, making it well-suited for real-world applications.', 'abstract_zh': '一种使用任务无关道德层精炼预训练强化学习模型的伦理决策框架', 'title_zh': '使用大型语言模型解决道德不确定性在伦理决策中的应用'}
{'arxiv_id': 'arXiv:2503.05723', 'title': 'AI Mimicry and Human Dignity: Chatbot Use as a Violation of Self-Respect', 'authors': 'Jan-Willem van der Rijt, Dimitri Coelho Mollo, Bram Vaassen', 'link': 'https://arxiv.org/abs/2503.05723', 'abstract': "This paper investigates how human interactions with AI-powered chatbots may offend human dignity. Current chatbots, driven by large language models (LLMs), mimic human linguistic behaviour but lack the moral and rational capacities essential for genuine interpersonal respect. Human beings are prone to anthropomorphise chatbots. Indeed, chatbots appear to be deliberately designed to elicit that response. As a result, human beings' behaviour toward chatbots often resembles behaviours typical of interaction between moral agents. Drawing on a second-personal, relational account of dignity, we argue that interacting with chatbots in this way is incompatible with the dignity of users. We show that, since second-personal respect is premised on reciprocal recognition of second-personal authority, behaving towards chatbots in ways that convey second-personal respect is bound to misfire in morally problematic ways, given the lack of reciprocity. Consequently, such chatbot interactions amount to subtle but significant violations of self-respect: the respect we are dutybound to show for our own dignity. We illustrate this by discussing four actual chatbot use cases (information retrieval, customer service, advising, and companionship), and propound that the increasing societal pressure to engage in such interactions with chatbots poses a hitherto underappreciated threat to human dignity.", 'abstract_zh': '本文探讨人类与AI聊天机器人互动过程中可能侵犯人类尊严的方式。当前由大规模语言模型驱动的聊天机器人模仿人类语言行为，但缺乏实现真正人际尊重所需的情感和理性能力。人类倾向于将聊天机器人拟人化，事实上，聊天机器人似乎被有意设计成引发这种反应。因此，人类对待聊天机器人的行为往往类似于与道德主体互动的行为。基于一种第二人称关系视角的尊严观，我们argue认为以这种方式与聊天机器人互动与用户尊严不相容。我们表明，因为第二人称尊重的前提是相互承认第二人称权威，因此以表现为第二人称尊重的方式对待聊天机器人必然以道德上有问题的方式失效，鉴于缺乏互惠性。因此，这种聊天机器人互动构成了对自我尊重的微妙但重要的违反：我们有义务为此类尊严展示。我们通过讨论四个实际的聊天机器人应用场景（信息检索、客户服务、咨询和陪伴）来阐述这一点，并提出，社会上越来越大的压力促使人们与聊天机器人进行此类互动，构成了对人类尊严的一种以前未曾充分认识到的威胁。', 'title_zh': 'AI模仿与人类尊严：聊天机器人的使用是对自我尊重的侵犯'}
{'arxiv_id': 'arXiv:2503.05715', 'title': 'The Butterfly Effect of Technology: How Various Factors accelerate or hinder the Arrival of Technological Singularity', 'authors': 'Hooman Shababi', 'link': 'https://arxiv.org/abs/2503.05715', 'abstract': 'This article explores the concept of technological singularity and the factors that could accelerate or hinder its arrival. The butterfly effect is used as a framework to understand how seemingly small changes in complex systems can have significant and unpredictable outcomes. In section II, we discuss the various factors that could hasten the arrival of technological singularity, such as advances in artificial intelligence and machine learning, breakthroughs in quantum computing, progress in brain-computer interfaces and human augmentation, and development of nanotechnology and 3D printing. In section III, we examine the factors that could delay or impede the arrival of technological singularity, including technical limitations and setbacks in AI and machine learning, ethical and societal concerns around AI and its impact on jobs and privacy, lack of sufficient investment in research and development, and regulatory barriers and political instability. Section IV explores the interplay of these factors and how they can impact the butterfly effect. Finally, in the conclusion, we summarize the key points discussed and emphasize the importance of considering the butterfly effect in predicting the future of technology. We call for continued research and investment in technology to shape its future and mitigate potential risks.', 'abstract_zh': '本文探索技术奇点的概念以及可能加速或阻碍其到来的因素。蝴蝶效应被用作框架，以理解看似微小的复杂系统变化可能产生的重大且不可预测的后果。在第二部分，我们讨论了可能加速技术奇点到来的各种因素，如人工智能和机器学习的进步、量子计算的突破、脑机接口和人类增强的进展，以及纳米技术和3D打印的发展。在第三部分，我们探讨了可能推迟或阻碍技术奇点到来的因素，包括人工智能和机器学习的技术限制和挫折、围绕人工智能及其对就业和隐私影响的伦理和社会关切、研究和开发投资不足，以及监管障碍和政治不稳定。第四部分探讨了这些因素的相互作用以及它们如何影响蝴蝶效应。最后，在结论中，我们总结了讨论的关键点，并强调在预测技术未来时考虑蝴蝶效应的重要性。我们呼吁继续对技术进行研究和投资，以塑造其未来并减轻潜在风险。', 'title_zh': '技术的蝴蝶效应：各种因素如何加速或阻碍技术奇点的到来'}
{'arxiv_id': 'arXiv:2503.05712', 'title': 'Automatic Evaluation Metrics for Artificially Generated Scientific Research', 'authors': 'Niklas Höpner, Leon Eshuijs, Dimitrios Alivanistos, Giacomo Zamprogno, Ilaria Tiddi', 'link': 'https://arxiv.org/abs/2503.05712', 'abstract': 'Foundation models are increasingly used in scientific research, but evaluating AI-generated scientific work remains challenging. While expert reviews are costly, large language models (LLMs) as proxy reviewers have proven to be unreliable. To address this, we investigate two automatic evaluation metrics, specifically citation count prediction and review score prediction. We parse all papers of OpenReview and augment each submission with its citation count, reference, and research hypothesis. Our findings reveal that citation count prediction is more viable than review score prediction, and predicting scores is more difficult purely from the research hypothesis than from the full paper. Furthermore, we show that a simple prediction model based solely on title and abstract outperforms LLM-based reviewers, though it still falls short of human-level consistency.', 'abstract_zh': '基础模型在科学研究中越来越受欢迎，但评估由AI生成的科学作品仍具挑战性。尽管专家评审成本高昂，代理评审人（如大型语言模型）的表现证明不够可靠。为此，我们研究了两种自动评估指标，分别是引文计数预测和评审评分预测。我们解析了所有OpenReview上的论文，并为每篇提交论文增加了引文计数、参考文献和研究假设。我们的研究发现，引文计数预测比评审评分预测更具可行性，从研究假设预测评分比从整篇论文预测更困难。此外，我们展示了基于标题和摘要的简单预测模型优于基于大型语言模型的评审人，尽管仍未能达到人类水平的一致性。', 'title_zh': '自动评估指标 for 人工生成的科学研究'}
{'arxiv_id': 'arXiv:2503.05711', 'title': 'Labeling Synthetic Content: User Perceptions of Warning Label Designs for AI-generated Content on Social Media', 'authors': 'Dilrukshi Gamage, Dilki Sewwandi, Min Zhang, Arosha Bandara', 'link': 'https://arxiv.org/abs/2503.05711', 'abstract': 'In this research, we explored the efficacy of various warning label designs for AI-generated content on social media platforms e.g., deepfakes. We devised and assessed ten distinct label design samples that varied across the dimensions of sentiment, color/iconography, positioning, and level of detail. Our experimental study involved 911 participants randomly assigned to these ten label designs and a control group evaluating social media content. We explored their perceptions relating to 1. Belief in the content being AI-generated, 2. Trust in the labels and 3. Social Media engagement perceptions of the content. The results demonstrate that the presence of labels had a significant effect on the users belief that the content is AI generated, deepfake, or edited by AI. However their trust in the label significantly varied based on the label design. Notably, having labels did not significantly change their engagement behaviors, such as like, comment, and sharing. However, there were significant differences in engagement based on content type: political and entertainment. This investigation contributes to the field of human computer interaction by defining a design space for label implementation and providing empirical support for the strategic use of labels to mitigate the risks associated with synthetically generated media.', 'abstract_zh': '本研究探讨了各种AI生成内容.warning标签设计在社交媒体平台上的有效性，如深度假货。我们设计并评估了十个不同标签设计样本，这些样本在情感、色彩/图标、位置和细节程度等方面有所不同。实验研究涉及911名随机分配到这十个标签设计组和一个对照组，对社交媒体内容进行评估。我们探索了他们对1. 内容为AI生成的信念、2. 对标签的信任以及3. 对内容的社交媒体参与感知的看法。结果表明，标签的存在对用户认为内容是AI生成、深度假货或由AI编辑的信念有显著影响。然而，他们对标签的信任显著地因标签设计而异。值得注意的是，标签的存在并未显著改变他们的参与行为，如点赞、评论和分享。然而，不同内容类型在参与行为上存在显著差异，尤其是政治和娱乐内容。本研究为人类计算机交互领域定义了标签实施的设计空间，并提供了实证支持，以战略方式使用标签以减轻合成媒体相关风险。', 'title_zh': '合成内容的标签标识：社交媒体上AI生成内容警告标签设计的用户感知'}
{'arxiv_id': 'arXiv:2503.05705', 'title': 'Inference Scaling Reshapes AI Governance', 'authors': 'Toby Ord', 'link': 'https://arxiv.org/abs/2503.05705', 'abstract': 'The shift from scaling up the pre-training compute of AI systems to scaling up their inference compute may have profound effects on AI governance. The nature of these effects depends crucially on whether this new inference compute will primarily be used during external deployment or as part of a more complex training programme within the lab. Rapid scaling of inference-at-deployment would: lower the importance of open-weight models (and of securing the weights of closed models), reduce the impact of the first human-level models, change the business model for frontier AI, reduce the need for power-intense data centres, and derail the current paradigm of AI governance via training compute thresholds. Rapid scaling of inference-during-training would have more ambiguous effects that range from a revitalisation of pre-training scaling to a form of recursive self-improvement via iterated distillation and amplification.', 'abstract_zh': '从扩大AI系统的预训练计算规模转向扩大其推理计算规模可能会对AI治理产生深远影响。这种影响的性质取决于新扩展的推理计算主要是在外部部署中使用，还是作为实验室中更复杂训练程序的一部分。推理计算在部署时的快速扩展将：降低开放权重模型的重要性（以及保护封闭模型权重的重要性），减少首批人类水平模型的影响，改变前沿AI的商业模式，减少对能耗密集型数据中心的需求，并颠覆通过训练计算阈值主导当前的AI治理范式。推理计算在训练期间的快速扩展将产生更加模糊的影响，范围从预训练规模扩展的再 revival 到通过迭代提炼和增强实现的递归自我改善。', 'title_zh': '推理扩展重塑人工智能治理'}
{'arxiv_id': 'arXiv:2503.05703', 'title': 'What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces', 'authors': "Jordi Armengol-Estapé, Quentin Carbonneaux, Tianjun Zhang, Aram H. Markosyan, Volker Seeker, Chris Cummins, Melanie Kambadur, Michael F.P. O'Boyle, Sida Wang, Gabriel Synnaeve, Hugh James Leather", 'link': 'https://arxiv.org/abs/2503.05703', 'abstract': "Code generation and understanding are critical capabilities for large language models (LLMs). Thus, most LLMs are pretrained and fine-tuned on code data. However, these datasets typically treat code as static strings and rarely exploit the dynamic information about their execution. Building upon previous work on trace modeling, we study Execution Tuning (E.T.), a training procedure in which we explicitly model real-world program execution traces without requiring manual test annotations. We train and evaluate models on different execution trace granularities (line and instruction-level) and strategies on the task of output prediction, obtaining around 80% accuracy on CruxEval and MBPP, and showing the advantages of dynamic scratchpads (i.e., self-contained intermediate computations updated by the model rather than accumulated as a history of past computations) on long executions (up to 14k steps). Finally, we discuss E.T.'s practical applications.", 'abstract_zh': '代码生成与理解是大型语言模型（LLMs）的关键能力。因此，大多数LLMs都会在代码数据上进行预训练和微调。然而，这些数据集通常将代码视为静态字符串，很少利用其执行过程中的动态信息。在此基础上，我们研究了执行调优（E.T.），这是一种通过显式建模真实程序执行轨迹的训练方法，而不需要手动测试注释。我们在不同执行轨迹粒度（行级和指令级）和策略下训练和评估模型，在输出预测任务中获得了约80%的准确性，并展示了动态草稿纸（即模型更新的独立中间计算而不是累积为过去计算的历史）在长执行过程中的优势（最多14,000步）。最后，我们讨论了E.T.的实际应用。', 'title_zh': '无法执行的我就无法理解：在程序执行轨迹上训练和评估LLM'}
{'arxiv_id': 'arXiv:2503.05200', 'title': 'ORANSight-2.0: Foundational LLMs for O-RAN', 'authors': 'Pranshav Gajjar, Vijay K. Shah', 'link': 'https://arxiv.org/abs/2503.05200', 'abstract': 'Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative aimed at developing specialized foundational LLMs tailored for O-RAN. Built on 18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes models ranging from 1 to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance for O-RAN. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG) based instruction-tuning framework that employs two LLM agents to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for assessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate that ORANSight-2.0 models outperform general-purpose and closed-source models, such as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on srsRANBench, achieving superior performance while maintaining lower computational and energy costs. We also experiment with RAG-augmented variants of ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics, demonstrating costs for training, standard inference, and RAG-augmented inference.', 'abstract_zh': '尽管大型语言模型（LLMs）在医疗保健、客户服务和商业营销等关键领域产生了变革性影响，但其与开放无线接入网络（O-RAN）的集成仍然有限。这一差距主要由于缺乏特定领域基础模型，现有的解决方案往往依赖于通用目的的LLM，这些模型未能解决O-RAN的独特挑战和技术复杂性。为弥合这一差距，我们介绍ORANSight-2.0（O-RAN洞察），这是旨在开发专门针对O-RAN的基础LLM的开创性举措。ORANSight-2.0基于18个覆盖五个开源LLM框架的LLM，调整了从1亿到70亿参数不等的模型，显著减少了对专有封闭源模型的依赖，同时提高了O-RAN的性能。ORANSight-2.0的核心是RANSTRUCT，这是一种新颖的检索增强生成（RAG）指令调优框架，采用两种LLM代理创建高质量的指令调优数据集。生成的数据集随后用于通过QLoRA调整18个预训练的开源LLM。为了评估ORANSight-2.0，我们引入了srsRANBench，这是一种针对srsRAN（广泛使用的5G O-RAN堆栈）的代码生成和代码库理解的新基准。我们还利用了ORANBench13K，这是一种现有的评估O-RAN特定知识的基准。我们的全面评估表明，ORANSight-2.0模型在ORANBench上的表现优于通用和封闭源模型，如ChatGPT-4o和Gemini，高出5.421%，在srsRANBench上的表现高出18.465%，同时实现了更高的性能并保持了较低的计算和能耗成本。我们还实验了ORANSight-2.0 LLM的RAG增强变体，并彻底评估了它们的能耗特性，包括训练、标准推理和RAG增强推理的成本。', 'title_zh': 'ORANSight-2.0: 基础性LLM for O-RAN'}
{'arxiv_id': 'arXiv:2112.11099', 'title': 'High pressure hydrogen by machine learning and quantum Monte Carlo', 'authors': 'Andrea Tirelli, Giacomo Tenti, Kousuke Nakano, Sandro Sorella', 'link': 'https://arxiv.org/abs/2112.11099', 'abstract': 'We have developed a technique combining the accuracy of quantum Monte Carlo in describing the electron correlation with the efficiency of a Machine Learning Potential (MLP). We use kernel regression in combination with SOAP (Smooth Overlap of Atomic Position) features, implemented here in a very efficient way. The key ingredients are: i) a sparsification technique, based on farthest point sampling, ensuring generality and transferability of our MLPs and ii) the so called $\\Delta$-learning, allowing a small training data set, a fundamental property for highly accurate but computationally demanding calculations, such as the ones based on quantum Monte Carlo. As the first application we present a benchmark study of the liquid-liquid transition of high-pressure hydrogen and show the quality of our MLP, by emphasizing the importance of high accuracy for this very debated subject, where experiments are difficult in the lab, and theory is still far from being conclusive.', 'abstract_zh': '我们开发了一种结合量子蒙特卡罗描述电子相关性精确性和机器学习势效率性的技术。该方法采用核回归与SOAP（平滑原子位置重叠）特征相结合，并在此实现了非常高效的实现。关键成分包括：i) 基于最远点采样的稀疏化技术，确保我们的机器学习势的一般性和转移性；ii) 所谓的$\\Delta$学习，允许使用较小的训练数据集，这是对于如基于量子蒙特卡罗计算这类高精度但计算密集型的计算而言一个基本属性。作为第一个应用，我们对高压氢的液-液相变进行了基准研究，并强调了该主题的重要性，其中实验在实验室中难以进行，而理论尚远未得出明确结论，以此展现了我们机器学习势的质量。', 'title_zh': '机器学习和量子蒙特卡洛方法高压氢'}
{'arxiv_id': 'arXiv:2109.09555', 'title': 'Learning quantum phase transitions through Topological Data Analysis', 'authors': 'Andrea Tirelli, Natanael C. Costa', 'link': 'https://arxiv.org/abs/2109.09555', 'abstract': 'We implement a computational pipeline based on a recent machine learning technique, namely the Topological Data Analysis (TDA), that has the capability of extracting powerful information-carrying topological features. We apply such a method to the study quantum phase transitions and, to showcase its validity and potential, we exploit such a method for the investigation of two paramount important quantum systems: the 2D periodic Anderson model and the Hubbard model on the honeycomb lattice, both cases on the half-filling. To this end, we have performed unbiased auxiliary field quantum Monte Carlo simulations, feeding the TDA with snapshots of the Hubbard-Stratonovich fields through the course of the simulations The quantum critical points obtained from TDA agree quantitatively well with the existing literature, therefore suggesting that this technique could be used to investigate quantum systems where the analysis of the phase transitions is still a challenge.', 'abstract_zh': '基于拓扑数据分析的计算管道在量子相变研究中的应用：以半填充满孔Anderson模型和六角晶格Hubbard模型为例', 'title_zh': '通过拓扑数据分析学习量子相变'}
